{"id": 257496129, "updated": "2023-12-11 11:01:32.573", "metadata": {"title": "Representation Learning for Stack Overflow Posts: How Far are We?", "authors": "[{\"first\":\"Junda\",\"last\":\"He\",\"middle\":[]},{\"first\":\"Zhou\",\"last\":\"Xin\",\"middle\":[]},{\"first\":\"Bowen\",\"last\":\"Xu\",\"middle\":[]},{\"first\":\"Ting\",\"last\":\"Zhang\",\"middle\":[]},{\"first\":\"Kisub\",\"last\":\"Kim\",\"middle\":[]},{\"first\":\"Zhou\",\"last\":\"Yang\",\"middle\":[]},{\"first\":\"Ferdian\",\"last\":\"Thung\",\"middle\":[]},{\"first\":\"Ivana\",\"last\":\"Irsan\",\"middle\":[]},{\"first\":\"David\",\"last\":\"Lo\",\"middle\":[]}]", "venue": "ACM Transactions on Software Engineering and Methodology", "journal": "ACM Transactions on Software Engineering and Methodology", "publication_date": {"year": 2023, "month": null, "day": null}, "abstract": "The tremendous success of Stack Overflow has accumulated an extensive corpus of software engineering knowledge, thus motivating researchers to propose various solutions for analyzing its content.The performance of such solutions hinges significantly on the selection of representation model for Stack Overflow posts. As the volume of literature on Stack Overflow continues to burgeon, it highlights the need for a powerful Stack Overflow post representation model and drives researchers' interest in developing specialized representation models that can adeptly capture the intricacies of Stack Overflow posts. The state-of-the-art (SOTA) Stack Overflow post representation models are Post2Vec and BERTOverflow, which are built upon trendy neural networks such as convolutional neural network (CNN) and Transformer architecture (e.g., BERT). Despite their promising results, these representation methods have not been evaluated in the same experimental setting. To fill the research gap, we first empirically compare the performance of the representation models designed specifically for Stack Overflow posts (Post2Vec and BERTOverflow) in a wide range of related tasks, i.e., tag recommendation, relatedness prediction, and API recommendation. To find more suitable representation models for the posts, we further explore a diverse set of BERT-based models, including (1) general domain language models (RoBERTa and Longformer) and (2) language models built with software engineering-related textual artifacts (CodeBERT, GraphCodeBERT, and seBERT). However, it also illustrates the ``No Silver Bullet'' concept, as none of the models consistently wins against all the others. Inspired by the findings, we propose SOBERT, which employs a simple-yet-effective strategy to improve the best-performing model by continuing the pre-training phase with the textual artifact from Stack Overflow.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/corr/abs-2303-06853", "doi": "10.1145/3635711"}}, "content": {"source": {"pdf_hash": "b07112533752dd3cbb2a4613e0f7c2a967af5b9f", "pdf_src": "Arxiv", "pdf_uri": "[\"https://export.arxiv.org/pdf/2303.06853v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "897a75176cbf1cb120b3fd55b2221b8900d40cd1", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/b07112533752dd3cbb2a4613e0f7c2a967af5b9f.txt", "contents": "\nRepresentation Learning for Stack Overflow Posts: How Far are We?\n13 Mar 2023\n\nJunda He \nZhou Xin \nBowen Xu \nTing Zhang \nZhou Yang \nDavid Lo \nJunda He \nZhou Xin \nBowen Xu \nTing Zhang \nKisub Kim \nZhou Yang \nFerdian Thung \nIvana Irsan \nDavid Lo \nJunda He \nZhou Xin \nBowen Xu \nTing Zhang \nKisub Kim \nZhou Yang \nFerdian Thung \nIvana Irsan \nDavid \n\nSingapore Management University\nSingapore\n\n\nSingapore Management University\nSingapore\n\n\nSingapore Management University\nSingapore\n\n\nSingapore Management University\nSingapore\n\n\nKISUB KIM\nSingapore\n\n\nManagement University\nSingapore\n\n\nFERDIAN THUNG\nSingapore Management University\nSingapore, Singapore\n\n\nIVANA IRSAN\nManagement University\nSingapore, Singapore\n\n\nManagement University\nSingapore\n\n\nACM Reference Format\nSingapore Management University\nSingapore\n\nRepresentation Learning for Stack Overflow Posts: How Far are We?\n13 Mar 202310.1145/nnnnnnn.nnnnnnnACM ISBN 978-x-xxxx-xxxx-x/YY/MM. . . $15.00 ACM TOSEM, ACM TOSEM Representation Learning for Stack Overflow Posts: How Far are We?. In ,. ACM, New York, NY, USA, 21 pages. https://doi.org/10.1145/nnnnnnn.nnnnnnnCCS Concepts:Computing methodologies \u2192 Knowledge representation and reasoning;Software and its engineering \u2192 Empirical software validation Additional Key Words and Phrases: Stack Overflow, Transformers, Pre-trained Models\nThe tremendous success of Stack Overflow has accumulated an extensive corpus of software engineering knowledge, thus motivating researchers to propose various solutions for analyzing its content. The performance of such solutions hinges significantly on the selection of representation model for Stack Overflow posts. As the volume of literature on Stack Overflow continues to burgeon, it highlights the need for a powerful Stack Overflow post representation model and drives researchers' interest in developing specialized representation models that can adeptly capture the intricacies of Stack Overflow posts.The state-of-the-art (SOTA) Stack Overflow post representation models are Post2Vec and BERTOverflow, which are built upon trendy neural networks such as convolutional neural network (CNN) and Transformer architecture (e.g., BERT). Despite their promising results, these representation methods have not been evaluated in the same experimental setting. To fill the research gap, we first empirically compare the performance of the representation models designed specifically for Stack Overflow posts (Post2Vec and BERTOverflow) in a wide range of related tasks, i.e., tag recommendation, relatedness prediction, and API recommendation. The results show that the Post2Vec cannot further improve each state-of-the-art technique of downstream tasks, and BERTOverflow shows surprisingly poor effectiveness. To find more suitable representation models for the posts, we further explore a diverse set of BERT-based models, including (1) general domain language models (RoBERTa and Longformer) and (2) language models built with software engineering-related textual artifacts (CodeBERT, GraphCodeBERT, and seBERT). This exploration shows that CodeBERT and RoBERTa are generally the most suitable for representing Stack Overflow posts. However, it also illustrates the \"No Silver Bullet\" concept, as none of the models consistently wins against all the others. Inspired by the findings, we propose SOBERT, which employs a simple-yet-effective strategy to improve the best-performing model by continuing the pre-training phase with the textual artifact from Stack Overflow. The overall experimental results demonstrate that SOBERT can consistently outperform the considered models and increase the stateof-the-art performance by a significant margin for all the downstream tasks.\n\nINTRODUCTION\n\nServing as the most popular software question and answer (SQA) forum, Stack Overflow (SO) has dramatically influenced modern software development practice. As of March 2023, the forum has accumulated more than 24 million questions and 35 million answers 1 . Stack Overflow is broadly recognized as an invaluable knowledge base and supplemental resource for the software engineering (SE) domain [4,11,41,44], which triggered the increased interest of researchers and software developers in a wide range of Stack Overflow post-related tasks, for example, recommendation of post tags (aka. tag recommendation) [11], recommendation of APIs according to a natural language query (aka. API recommendation) [4], and the identification of related posts (aka. relatedness prediction) [44].\n\nAn essential step in yielding promising results for these Stack Overflow-related tasks is to obtain suitable representations of the posts. A beneficial Stack Overflow representation model can capture the semantic concept of the posts and reveal more explanatory features from the hidden dimensions. As the volume of SE literature on solving Stack Overflow-related tasks [11,41,44] cotinues to burgeon, it has underscored the demand for a quality Stack Overflow representation.\n\nOver the years, numerous representation models have been specifically proposed for modeling Stack Overflow posts. Xu et al. proposed Post2Vec [43], a CNN-based [18] representation model that leverages the tags of a post to guide the learning process and models the post as the combination of three complementary components (i.e., title, description, and code snippet). Their experimental results demonstrate that it can substantially boost the performance for a wide range of Stack Overflow posts-related tasks [1,4,32]. Tabassum et al. [34] leveraged the more advanced BERTbased architecture and pre-trained BERTOverflow based on 152 million sentences from Stack Overflow. Results showed that the embedding generated by BERTOverflow led to a significant improvement over other off-the-shelf models (e.g., ELMo [24] and BERT [6]) in the software named entity recognition (NER) task.\n\nAlthough these existing Stack Overflow-specific methods have been proven to be beneficial, the effectiveness of Post2Vec is only evaluated on limited solutions (i.e., Support Vector Machine [44] and Random Forest [3]) and BERTOverflow only experimented for the NER task. These motivate us to further study the performance of existing Stack Overflow-specific representation models on a diverse set of tasks. Unexpectedly, we found that both Post2Vec and BERTOverflow perform poorly. Such findings motivate us to explore the effectiveness of a larger array of representation techniques in modeling Stack Overflow posts.\n\nIn addition to the aforementioned Stack Overflow-specific representation models, we further consider five BERT-based language models which could be potentially suitable for post representation learning. They are CodeBERT [7], GraphCodeBERT [9], seBERT [38], RoBERTa [21], and Longformer [2]. CodeBERT is a SE knowledge-enriched BERT-based language model that utilizes CodeSearchNet [15] dataset at the pre-training stage. GraphCodeBERT further incorporates data flow graphs and structure-aware pre-training (i.e., edge prediction and node alignment) and it outperforms CodeBERT in various code-related tasks. Different from the previous models which are based on a BERT Base architecture, seBERT is a BERT Large model and is pre-trained with data from GitHub commit messages and issues, Jira issues, and Stack Overflow posts. CodeBERT, Graph-CodeBERT, and seBERT are considered to be better at capturing the semantics of technical jargon of the SE domain. Finally, we also include models from the general domain as they are usually trained with a more diverse amount of data than domain-specific models. RoBERTa is one of the most popular BERT-based language models. It is trained with larger batch size and learning rates compared with the original BERT. Longformer is also considered as it overcomes the input length limit of conventional BERT-based language models. While BERT-based language models could maximumly accept an input length of 512 tokens, more than 50% of the Stack Overflow posts have the surpass 512 limit [11]. In contrast, Longformer could accept a maximum of 4,096 tokens as its input.\n\nWe evaluate the performance of the aforementioned representation models on multiple Stack Overflow-related downstream tasks (i.e., tag recommendation, API recommendation, and relatedness prediction). Furthermore, we build SOBERT, a stronger BERT-based language model for modeling Stack Overflow posts. Our experimental results reveal several interesting findings: (1) Existing Stack Overflow post representation techniques fail to improve the SOTA performance of considered tasks. Xu et al. demonstrated that the addition of the feature vectors generated by Post2Vec is beneficial for improving the post representation for traditional machine learning techniques. However, we discover that appending the feature vectors from Post2Vec [43] does not derive a beneficial effect on considered deep neural networks. Furthermore, we reveal that the embedding generated by BERTOverflow could only achieve reasonable performance in the API recommendation task and give surprisingly poor performance in the tag recommendation task.\n\n(2) Among all the considered models, none of them can always perform the best. According to our experiment results, although the newly considered models can outperform the SOTA approaches, none of them can always perform the best. It motivates us to build an extensive model. Overall, CodeBERT produces the most promising representation among the considered models, and Longformer fails to beat conventional BERT-based language models, although it is expected to be capable of accepting a longer input. (3) Continued pre-training based on Stack Overflow textual artifact develops a consistently better model. We propose SOBERT by further pre-training with Stack Overflow data. The overall results show that SOBERT consistently boosts the performance in all three considered tasks, implying a better representation. Overall, we summarize the contributions of our empirical study as follows:\n\n(1) We comprehensively evaluate the effectiveness of seven representation models for Stack Overflow posts in three downstream tasks. (2) We propose SOBERT by pre-training based on 20 million posts from Stack Overflow and show that SOBERT consistently outperforms other representation models in multiple downstream tasks. (3) We derive several insightful lessons from the experimental results to the software engineering community. The rest of the paper is organized as follows. Section 2 categorizes representation learning models into three groups and briefly describes them. We formulate the downstream tasks (i.e., tag recommendation, API recommendation, relatedness prediction) and their corresponding stateof-the-art method in Section 3. Section 4 introduces our research questions and the experiment settings. In Section 5, we answer the research question and report the experiment results. Section 6 further analyzes the result and elaborates the insights with evidence. Section 7 describes related works, and Section 8 summarizes this study.\n\n\nREPRESENTATION LEARNING MODELS\n\nIn this section, we summarize the considered representation models for this paper. We explore a wide range of techniques across the spectrum of representing Stack Overflow posts, including two Transformer-based Pre-trained Models (PTM) from the general domain (RoBERTa [21] and Longformer [2]), three SE-domain specific PTMs (CodeBERT [7], GraphCodeBERT [9], and se-BERT [38]) and two Stack Overflow-specific post representation models (BERTOverflow [34] and Post2Vec [43]).\n\n\nBERT-based Language Models\n\nBERT (Bidirectional Encoder Representations from Transformers) [6] based language models have revolutionized the representation learning of natural language [2,6,17,21,30,37] by achieving phenomenal performance in a wide range of natural language processing (NLP) tasks, such as sentiment analysis [33], POS tagging [35], question answering [26]. BERT-based language models inherit the Transformer [37] architecture, whose self-attention mechanism can learn a bidirectional contextual representation of text. These models usually perform the Masked Language Modeling (MLM) task in the pre-training phase. It initially corrupts the input data by randomly masking 15% of the tokens, and then it teaches the model to reconstruct the original data by predicting the masked words. BERT-based models are extensively pre-trained on large-scale datasets, which learn a meaningful representation that is reusable for various tasks, thus eliminating the process of training language models from scratch and saving a drastic amount of time and resources.\n\n\nExisting Models for Stack Overflow Posts\n\nBERTOverflow [34] keeps the original BERT architecture, and it leverages 152 million sentences and 2.3 billion tokens from Stack Overflow to pre-train Stack Overflow-specific word embeddings. The authors have leveraged the embedding generated by BERTOverflow to implement a software-related named entity recognizer (SoftNER). The performance of SoftNER is experimented with the name entity recognition (NER) task for the software engineering domain, focusing on identifying code tokens or programming-related named entities that appear within SQA sites like Stack Overflow. The results show that BERTOverflow outperforms all other models in the proposed task. Post2Vec [43] is the latest approach proposed specifically for Stack Overflow post representation learning [43]. Unlike the existing models, Post2Vec is designed with a triplet architecture. Post2Vec leverages CNNs as feature extractors for each post to encode three components (i.e., title, text, and code snippets) separately from the post. The corresponding three output feature vectors are then fed to a feature fusion layer to produce the representation of the post. In the end, Post2Vec uses tag information of the post, which is considered as the post's general semantic meaning to supervise the representation learning process. The representation learned by Post2Vec is then leveraged by enhancing the feature vectors in Stack Overflow-related downstream tasks (e.g., relatedness prediction and API recommendation). For each downstream task, in [43], the vector representation learned by Post2Vec is combined with the feature vector produced by the corresponding stateof-the-art approach to form a new feature vector. Finally, the new feature vector is used to boost the performance of the corresponding model for the task. Following the experiment settings of Xu et al., we use Post2Vec as a complementary feature vector to the state-of-the-art approach in this paper. We concatenate the post representation generated by Post2Vec to the original feature vector of the state-of-the-art approach. We then leverage the concatenated feature vector in further training.\n\n\nModels from General Domain\n\nRoBERTa [21] is a replication study on the pre-training objectives, along with the impact of several key hyper-parameters of BERT [6]. They then proposed their improved model on BERT, namely RoBERTa. In comparison with BERT, RoBERTa has made several modifications to the pre-training stage, including: (1) training with larger batch size, more data, and longer training time; (2) abandoning the next sentence prediction (NSP) task of BERT and showed that removal of NSP slightly improves the model efficiency; (3) training with longer sequences; (4) masking the training data dynamically rather than statically.\n\nPre-trained models like BERT [6] and RoBERTa [21] only accept a maximum input of 512 tokens. However, according to the statistics conducted by He et al. [11], more than half of the Stack Overflow questions have more tokens than the given 512 limit. A simple workaround is to truncate the given input sequence to the acceptable length restriction. However, it increases the risk of losing vital information. The self-attention mechanism suffers from the ( 2 ) quadratic computational complexity problem, which restricts the ability of Transformer-based models to model long sequences. Longformer [2] aims to alleviate the limitation in processing long sequences. It leverages a combination of sliding window attention and global attention mechanism such that the computational memory consumption scales linearly as the sequence becomes longer. In contrast to models like RoBERTa and CodeBERT, which could only accept a maximum of 512 tokens as input, Longformer supports sequences of length up to 4,096. Similar to CNN [18], Longformer lets each input token only attends to surrounding neighbors that are within a fixed window size. Denoting the window size as , each token could only attend to 1 2 tokens on both sides, thus decreasing the computation complexity to ( \u00d7 ).\n\nHowever, the sliding window may compromise the performance as it cannot capture the whole context. To compensate for the side-effect, global tokens are selected. Such tokens are implemented with global attention, which attends to all other tokens, and other tokens also attend to the global tokens. As previous work showed that more than 50% of the Stack Overflow posts exceed the size limit of conventional BERT-based models (512), it motivates us to explore whether Longformer is better at representing Stack Overflow posts.\n\n\nModels from SE domain\n\nCodeBERT [7] The strong versatility and capability of Transformer-based representational models drive researchers' interest in adopting them to the SE domain. CodeBERT [7] is a SE knowledgeenriched bi-modal pre-trained model, which is capable of modeling both natural languages (NL) and programming languages (PL). CodeBERT inherits the architecture of BERT [6], and it continues pre-training based on the checkpoint of RoBERTa [21] with the NL-PL data pairs obtained from the CodeSearchNet dataset [15]. It has two pre-training objectives: Masked Language Modeling (MLM) and Replaced Token Detection (RTD). The eventual loss function for CodeBERT at the pre-training stage is the combination of both MLM and RTD objectives, where denotes the model parameters:\nmini(L ( ) + L ( ))(1)\nThe CodeBERT model has shown great effectiveness in a diverse range of SE domain-specific activities, for example, code search [7], traceability prediction [20], and code translation [5].\n\nGraphCodeBERT [9] incorporates a hybrid representation in source code modeling. Apart from addressing the pre-training process over NL and PL, GraphCodeBERT utilizes the data flow graph of source code as additional inputs and considers two structure-aware pre-training tasks (i.e., Edge Prediction and Node Alignment) aside from the MLM prediction task. GraphCodeBERT is evaluated in code search [7], clone detection [40], code translation [5], and code refinement [36],respectively. It outperforms CodeBERT and all the other baselines, including RoBERTa (code version) [9], Transformer [37], LSTM [12], under their experimental setting. seBERT [38] aims to advance the previous PTMs in the SE context with a larger model architecture and more diverse pre-training data. The authors pre-trained seBERT with the BERT architecture, i.e., with 24 layers, a hidden layer size of 1024, and 16 self-attention heads, with a total of 340 million parameters. seBERT is pre-trained with more than 119GB of data from four data sources, i.e., Stack Overflow posts, Github issues, Jira issues, and Github commit messages. The model's effectiveness is verified in three classification tasks, i.e., issue type prediction, commit intent prediction, and sentiment mining. Results showed that seBERT is significantly better than BERToverflow in these tasks.\n\n\nDOWNSTREAM TASKS\n\nIn this section, we formulate the target problems that are used to measure the effectiveness of the representation models and then describe the corresponding state-of-the-art solution. We select multiple Stack Overflow-related downstream tasks, which have been popular research topics for Stack Overflow posts. To be more specific, we consider: Tag Recommendation [11,43], API Recommendation [4,41] and Relatedness Prediction [23,44], covering a multi-label classification problem, a multi-class classification problem, and a ranking problem. All selected tasks operate on the abstraction of a post, which could be benefited from a high-quality Stack Overflow post representation.\n\n\nTag Recommendation\n\nThe user-annotated tags of a Stack Overflow post serve as helpful metadata and have a critical role in organizing the contents of Stack Overflow posts across different topics. Suitable tags precisely summarize the message of a post, while redundant tags and synonym tags make it more difficult in maintaining the content of the site. A tag recommendation system could effectively simplify the tagging process and minimize the effect of manual errors, therefore, avoiding problems like tag synonyms and tag redundancy.\n\n\nTask Formulation.\n\nWe formulate the tag recommendation task as a multi-label classification problem. Given X as a corpus of Stack Overflow posts, and Y denotes the total collection of tags, we represent each post as , where 0 \u2264 \u2264 | |, \u2208 N and the tag of each post as \u2282 Y. The goal is to recommend the most relevant set of tags to .\n\n\nState-of-the-art technique.\n\nPTM4Tag [11] leverages three pre-trained models to solve the tag recommendation problem. PTM4Tag leverages three pre-trained models, which are responsible for modeling the title, description, and code snippet, independently.\n\n\nAPI Recommendation\n\nQuestions related to Application Programming Interfaces (APIs) are one of the most viewed topics on Stack Overflow [13]. Stack Overflow consists of an enormous amount of discussion about API usage. Developers are more intended to search for relevant Stack Overflow posts and pick out the APIs that seem useful in the discussions [14] rather than checking API documentation, which makes Stack Overflow the primary source for building a dataset of the API recommendation task. The modern software development process heavily relies on third-party APIs, which leads to the research of an automated API recommendation approach that is intended to simplify API search [42].\n\n\nTask Formulation.\n\nWe follow the exact task definition as the previous literature [8,13,41], with the goal of recommending relevant APIs that answer the question or implement the function for a given NL query.\n\n3.2.2 State-of-the-art technique. Wei et al. [41] proposed CLEAR, an automated approach that recommends API by embedding queries and Stack Overflow posts with a BERT-based PTM (distilled version of the RoBERTa 2 ). To be more specific, given a natural language query, CLEAR initially picks a sub-set of candidate Stack Overflow posts based on the embedding similarity to reduce the search space. Then, CLEAR ranks the candidate Stack Overflow posts and recommends the APIs from the top-ranked Stack Overflow posts.\n\n\nRelatedness Prediction\n\nThe notion of a Knowledge Unit (KU) is defined as a set containing a question along with all its answers [32,44]. To find a comprehensive technical solution for a given problem, developers usually need to summarize the information from multiple related KUs. However, searching for related KUs can be time-consuming as the same question can be rephrased in many different ways. Thus, researchers have proposed several techniques to automate the process of identifying the related KUs [23,32,44], which could significantly improve the efficiency of the software development cycle.\n\n\nTask Formulation.\n\nThe task is commonly formulated as a multi-class classification problem [23,32,44]. The relatedness between questions is classified into four classes, from the most relevant to irrelevant, which are:\n\n\u2022 Duplicate: The Two KUs correspond to a pair of semantically equivalent questions. The answer of one KU can also be used to answer another KU. \n\n\nRESEARCH QUESTIONS AND EXPERIMENTAL SETTINGS\n\nIn this section, we first introduce our research questions and then describe the corresponding experiment settings.\n\n\nResearch Questions\n\nRQ1. How effective are the existing Stack Overflow post representation models? Various methods have been proposed in modeling Stack Overflow posts. However, there is still a lack of analysis of the existing Stack Overflow-specific representation methods. For instance, Xu et al. [43] have demonstrated that Post2Vec is effective in boosting the performance of traditional machine learning algorithms, i.e., support vector machine (SVM) and Random Forest. However, the efficacy of Post2Vec in facilitating deep learning-based models has not yet been investigated. Moreover, Tabassum et al. [34] only leveraged the embeddings from BERTOverflow in the software-related NER task, but not for other popular Stack Overflow-related tasks. In light of this research gap, we aim to evaluate the current Stack Overflow-specific representation methods for popular Stack Overflow-related tasks under the same setting for this research question.\n\nRQ2. How effective are the popular BERT-based language models for the targeted downstream tasks? In addition to the existing Stack Overflow representation models, we explore the effectiveness of a wider spectrum of representation models. BERT-based language models have shown great performance and generalizability in representation learning. Representations generated by such models have demonstrated promising performance in a broad range of tasks with datasets of varying sizes and origins. Borrowing the best-performing representation models from various domains and investigating their performance can derive interesting results, as recent literature [46,47] have revealed that they are potentially great candidates for representing posts as well. This motivates us to employ RoBERTa [21] and Longformer [2] from the general domain and CodeBERT [7], GraphCodeBERT [9], and seBERT [38] from the SE domain. We set up the exact same experimental settings for each model.\n\n\nRQ3\n\n. Is further pre-training on Stack Overflow data helpful in building a better model? Further pre-trained models with domain-specific corpus have been common practice in the NLP domain, however, their effectiveness is not verified for representing Stack Overflow posts. In this RQ, we introduce SOBERT, which is obtained by continuing the pre-training process on CodeBERT with Stack Overflow data, and we aim to investigate whether further pre-training with Stack Overflow data improves the performance.\n\n\nExperimental Settings\n\n\nTag Recommendation.\n\nDataset. The dataset used by He et al. [11] in the training of PTM4Tag only includes the Stack Overflow posts dated before September 5, 2018. To address this limitation, we use the Stack Overflow data dump released in August of 2022 to construct a new dataset for our experiment. Idealy, a tag recommendation approach should only learn from high-quality questions. Therefore, we remove the low-quality questions when constructing the dataset. According to the classificaition of question quality defined by Ponzanelli et al. [25], we first filter out the questions which do not have an accepted answer and further removed the questions with a score of less than 10.\n\nMoreover, we remove the rare tags and rare posts. Previous literature in tag recommendation [11,43] has defined a tag as rare if it occurs less than 50 times within the dataset, and a post is considered rare if all of its tags are rare tags. The usage of rare tags is discouraged since it implies the unawareness of the tag among developers. We follow the same definition as the previous literature and set the frequency threshold for rare tags as 50.\n\nIn the end, we obtain a dataset of 527,717 posts and 3,207 tags. We split the dataset into a training set, a validation set, and a test set according to the 8:1:1 ratio, which corresponds to 422,173, 52,772, and 52,772 posts, respectively.\n\n\nEvaluation Metrics.\n\nWe report the performance for this task using Precision@k, Recall@k, and F1-score@k, where k indicates the top-k recommendations. Such metrics are extensively used in previous works [11,19,43,48], and we calculate the average score for each of them. Mathematically speaking, the evaluation metrics are computed as follows:\n@ = |Tag True \u2229 Tag Predict | @ = |Tag True \u2229Tag Predict | if |Tag True | > |Tag True \u2229Tag Predict | |Tag True | if |Tag True | \u2264 1- @ = 2 \u00d7 @ \u00d7 @ @ + @\nIn the above formulas, Tag True refers to the ground truth tags and Tag Predict refers to the predicted tags. Notice that the above formula of Recall@k is determined by conditions since Recall@k naturally disfavors small k. The revisited Recall@k has been widely adopted in previous experiments of tag recommendation [11,43,48]. Since Stack Overflow posts cannot have more than 5 tags, we report the results by setting the k as 1,3,and 5.\n\n\nImplementation Details.\n\nFor Longformer, we set the maximum accepted input sequence as 1,024, and for other BERT-based language models (i.e., RoBERTa, CodeBERT, BERTOverflow, and SOBERT) the maximum input sequence is set as 512.\n\nWe set the learning rate as 5e-5, batch size as 512, epoch number as 30, and use the Adam optimizer to update the parameters. We save the model at the end of each epoch and select the model with the smallest validation loss to run the evaluation.\n\n\nAPI Recommendation.\n\n\nDataset.\n\nWe reuse the BIKER dataset leveraged by Wei et al. [41]. The training dataset contains 33K questions with corresponding relevant APIs in the accepted answers. The test dataset contains 413 manually labeled questions from Stack Overflow, which are looking for API to solve programming problems, and labeled the ground-truth API for these questions based on their accepted answers. The dataset is constructed by selecting posts satisfying three criteria: (1) the question has a positive score, (2) at least one answer to the question contains API entities (3) the answer has a positive score.\n\n\nEvaluation Metrics.\n\nWe use the same evaluation metrics as previous literature [13,41] for the API recommendation task. The metrics are: Mean Reciprocal Rank (MRR), Mean Average Precision (MAP), Precision@k and Recall@k. Different from tag recommendation, the API recommendation task is not a multi-label classification task, and the Recall@k metrics used in this task follow the conventional definition, which is: @ = |API True \u2229 API Predict | |API True | To be consistent with Wei et al. [41], we use k \u2208 1, 3, 5.\n\n\nImplementation Details.\n\nCLEAR shows state-of-the-art performance in the API recommendation task by leveraging BERT sentence embedding and contrastive learning. The original architecture of CLEAR is implemented based on DistilRoBERTa 3 during the training process. In this study, we also explore the effectiveness of other representation methods by replacing the embedding of DistilRoBERTa in CLEAR. For Post2Vec, we concatenate the post representation from Post2Vec to the original implementation of CLEAR.\n\nFor this task, we set the batch size as 256, and the epoch number as 30. Same to the description in Sec 4.2.1, we select the model with the smallest validation loss to run the test set.\n\n\nRelatedness Prediction.\n\n\nDataset.\n\nThe experiments are conducted based on the KUs dataset provided by Shirani et al. [32]. This dataset contains 347,372 pairs of KUs. To ensure a fair comparison with the prior work [23], we use the same data for training, validation, and testing, containing 208,423, 347,37, and 104,211 pairs of KU, respectively.\n\n\nEvaluation Metrics.\n\nFollowing prior work [23], we adopt the micro-averaging method to calculate Micro-precision, Micro-recall, and Micro-F1 as evaluation metrics.\n\n\nImplementation Details.\n\nWe concatenate a pair of posts as the input to train a multi-class classifier. We fine-tuned Longformer on a sequence length of 1,024 and fine-tuned other pre-trained models on a sequence length of 512. For all experiments, we set the batch size as 32 and the epoch number as 5. We select the model with the smallest validation loss to run the evaluation.\n\n\nEXPERIMENTAL RESULTS\n\nThis section describes the experiment results and answers our research questions. The experimental results are summarized in Table 1, 2, and 3 respectively.\n\n\nRQ1: How effective are the existing Stack Overflow post representation models?\n\nThe experimental results for the tag recommendation task are summarized in Table 1. PTM4Tag originally achieves a performance of 0.417, 0.805, and 0.526 in terms of Precision@5, Recall@5, and F1-score@5. However, the extra inclusion of Post2Vec lowers the performance to 0.416, 0.804, and 0.525, respectively. BERTOverflow struggles in the task with scores of 0.083, 0.163, and 0.105.\n\nFor API recommendation (Table 2), combining Post2Vec with the state-of-the-art approach CLEAR also fails to boost the performance. CLEAR itself could obtain a score of 0.739 and 0.753 in MRR and MAP, while the performance drop to 0.735 and 0.745 when Post2Vec is added. BERTOverflow obtained a performance of 0.753 and 0.778. In the relatedness prediction task (Table 3), the integration of Post2Vec with ASIM slightly lowers the performance from 0.785 to 0.768 in F1-score. BERTOverflow fails to beat ASIM with an F1-score of 0.697.\n\nOverall, Post2Vec can not improve the performance of the state-of-the-art solutions in our downstream tasks. BERTOverflow performs poorly in classification tasks and only achieves comparable performance with the state-of-the-art solution in API recommendation.\n\nAnswer to RQ1: The existing Stack Overflow representation methods fail to improve state-of-the-art performance from the three targeted downstream tasks.   Table 2 shows that CLEAR is no longer the best-performing method in API recommendation. Replacing the embedding of Distilled RoBERTa in the original design of CLEAR with other BERTbased language models increases the performance. In terms of MRR and MAP, seBERT scores 0.754 and 0.777. In contrast, CodeBERT, RoBERTa, GraphCodeBERT, and Longformer are all able to achieve higher scores than 0.767 and 0.782. In particular, GraphCodeBERT boosts the performance of CLEAR by 3.8% and 5.0% in terms of MRR and MAP. For Precision@1,3,5 and Recall@1,3,5, GraphCodeBERT outperforms CLEAR by 6.7% 22.0%.\n\nFrom Table 3, we observe that ASIM, the state-of-the-art technique in relatedness prediction, is outperformed by other BERT-based language models. While ASIM achieves a score of 0.785 in F1-score, CodeBERT drives forward the state-of-the-art performance by 2.3% with an F1-score of 0.803. Moreover, RoBERTa, GraphCodeBERT, Longformer, and seBERT have an F1-score of 0.787, 0.801, 0.786, and 0.799.\n\nOverall, models like CodeBERT can consistently give promising representations in all three tasks, proving its generalizability and effectiveness in a wide range of SE-related tasks.\n\nAnswer to RQ2: Representations generated by CodeBERT and RoBERTa consistently outperform each state-of-the-art technique from the targeted downstream tasks. However, none of the models can always be the best performer. Overall, CodeBERT is the most promising representation model.\n\n\nRQ3: Is further pre-training on Stack Overflow data helpful in building a better model?\n\nOur experimental results show that there is no \"one-size-fits-all\" model in representing Stack Overflow posts, which could consistently outperform others in the considered tasks. Such a phenomenon delivers an intuition that there is an improvement opportunity in the representation technique for Stack Overflow. Based on such intuition and common practice that a second phase of in-domain pre-training leads to performance gains [10], we conduct additional pre-training for a BERT-based model (i.e., CodeBERT) with the Stack Overflow dataset. We name it SOBERT. Pre-training Details We have leveraged the Stack Overflow dump dated August 2022 (which includes posts from July 2008 to August 2022) and selected 22 million question posts as the training corpus. The raw dataset has a size of approximately 67G. Many previous works have removed the code snippets of a Stack Overflow post during pre-processing stage [19,48]. According to the statistics conducted by Xu et al. [43], more than 70% of the Stack Overflow contains at least one code snippet. As a result, the removal of code snippets would result in losing a significant of information, and they should be considered to learn an effective post representation. As the code snippets within the body of a post are enclosed in HTML tags < >< > and < \\ >< \\ >, we cleaned the redundant HTML tags with regular expression < >< > ([\\s\\S]*?) < \\\\ >< \\\\ >. We have initialized SOBERT based on the checkpoint of the CodeBERT model and pre-trained SOBERT using the MLM objective with a standard masking rate of 15%. The batch size is set as 256, and the learning rate is 1e-4. The training process takes 100 hours for eight Nvidia V100 GPUs with 16 GB of memory to complete. The detailed code used is included in the replication package provided.\n\nThe experimental results show that SOBERT achieves the best performance for every downstream task. For tag recommendation, SOBERT achieves an F1-score@5 of 0.544 and beats the CodeBERT and RoBERTa by 3.2%; for API recommendation, SOBERT performs with 0.809 in terms of MRR and outperforms GraphCodeBERT by 3.2%.; and for relatedness prediction, it accomplishes an F1-score of 0.824 and outperforms CodeBERT by 2.6%.\n\nWe conduct the Wilcoxon Signed Rank at a 95% significance level (i.e., p-value < 0.05) on the paired data corresponding to SOBERT and the best-performing representation model in each task (i.e., CodeBERT and RoBERTa in tag recommendation, GraphCodeBERT in API recommendation, and CodeBERT in relatedness prediction). The significance test has been conducted on the values of evaluation metrics. We observe that SOBERT significantly outperforms the comparing model.  Answer to RQ3: Further pre-training of CodeBERT with the Stack Overflow data improves the original performance and consistently outperforms state-of-the-art performance in all the targeted downstream tasks.\n\n\nDISCUSSION\n\n\nLessons Learned\n\nLesson #1. Incorporating post embeddings from an external approach does not boost the performance of neural network models. Xu et al. [43] demonstrated that appending the distributed post representation learned by Post2Vec to the manually crafted feature vector can increase the performance of traditional machine learning algorithms, for example, Support Vector Machine [44] and Random Forest [3], in a set of Stack Overflow-related tasks. However, these benefits are not observed for the state-of-the-art techniques that are based on deep neural networks. This is potentially caused by the design of neural networks that automatically extract feature vectors and continuously optimize the representations. It indicates that deep neural networks may lose the effectiveness of external embeddings while optimizing the parameters of the feature extractor.\n\nLesson #2. Models with broader background knowledge derive better results than those with specific knowledge.\n\nTextual artifacts from different domains follow dissimilar word distributions. BERTOverflow is expected to produce the desired Stack Overflow post representation as it is specifically designed for Stack Overflow data.\n\nA major difference between the models for post representation and others is the vocabulary. As BERTOverflow is pre-trained from scratch with the Stack Overflow data, its vocabulary should be more suitable than general domain models. Notice that since CodeBERT, GraphCodeBERT, and Longformer are initialized on the checkpoint of RoBERTa, these models inherit the same vocabulary as RoBERTa. Table 4 presents five examples of the tokenization result of BERTOverflow and RoBERTa. \"MongoDB\" is separated into three sub-words (\"M\", \"ongo\", and \"DB\") by RoBERTa, but BERTOverflow is capable of representing as a whole word. It confirms our hypothesis that BERTOverflow has a more suitable vocabulary for representing the SE domain technical terms.\n\nSurprisingly, our experiment results show that other BERT-based language models outperform BERTOverflow by a substantial margin across all three tasks. It gives an extremely poor performance in the tag recommendation task. By inspecting the prediction results of BERTOverflow in the tag prediction task, we notice that the top-5 predictions made by BERTOverflow are always the most frequent tags ('python', 'java', 'c#', 'java-script', and 'android') from the dataset. We observe seBERT has similar performance as BERTOverflow in the tag recommendation task. We perceive that it is potentially because these models lack a sufficient amount of pre-training to perform well. Beause seBERT and BERTOverflow are trained from scratch and requires much more pre-training effort than continued pre-training with extant models. To prove this concept, we performed additional pre-training on BERTOverflow with the same pre-training corpus as SOBERT. The further training was with the same hyper-parameters as SOBERT, and it took 23 hours for us to finish with 4 GPUs containing 16GB Nvidia V100 each. We demote this new model as BERTOverflow NEW , and we notice its notable performance improvements compared to BERTOverflow. The results are reported in Table 5. 4 Overall, our experiments have shown that, in all three tasks, vocabulary has a subdued effect, and the more important factor tends to be the scale for pre-training. Also, pre-training from scratch is commonly considered as an expensive process. Initializing new representation models based on the checkpoint of an existing decent model lowers the risk and the tag recommendation task is a good indicator to demonstrate the generalizability and the sufficiency of pre-training for pre-trained models.\n\nLesson #3. Despite considering a longer input length, Longformer does not produce better representations for posts.\n\nConventional BERT-based models like CodeBERT and RoBERTa are unable to handle long sequences due to the quadratic complexity of the self-attention mechanism [37] and accept a maximum of 512 sub-token as the input. However, more than 50% of Stack Overflow posts are longer than this given limit [11]. Truncation is normally employed to deal with this limitation; however, applying truncation increases the risk of losing information. It motivates us to investigate Longformer as it is designed to handle long-length input with a maximum size of 4,096 tokens.\n\nAs all of our evaluations demonstrated, Longformer fails to perform better than the other model that belongs to the general domain (i.e., RoBERTa) as well as models from the SE domain, even though it takes more time and resources for training. We further compare the performance of Longformer by varying the input size considering the first 512 and 1,024 tokens. The additional experimental results are shown in Table 5. These additional settings do not differ in performance. It indicates that diversifying the input size does not affect Longformer's performance on post representation. A potential interpretation would be the important features for representing Stack Overflow posts lie in the first part of each post (e.g., Title serves as a succinct summary of the post). It is not worth trying Longformer unless one strictly needs the entire content of Stack Overflow posts.\n\nLesson #4. We advocate future studies related to Stack Overflow consider the SOBERT as the underlying baseline.  Our experiment results demonstrate that further pre-training based on in-domain data leads to better Stack Overflow post representation. By initializing SOBERT with the CodeBERT checkpoint and performing further pre-training on Stack Overflow data, we have noticed that SOBERT consistently outperforms the original CodeBERT and produces new state-of-the-art performance for all three tasks.\n\nIn Table 6, we present three examples of the prediction results of CodeBERT and SOBERT for the tag recommendation task. We observe that CodeBERT is making wrong predictions like \".net\" and \"c#\" when the question is about \"haskell\" while SOBERT is capable of making the correct predictions. CodeBERT may lack knowledge of programming languages like Haskell and Lua since it is pre-trained on artifacts from Python, Java, JavaScript, PHP, Ruby and Go. Taking the Stack Overflow post with ID 13202867 as another example, the question is about Flexslider, a jQuery slider plugin. In the given example, SOBERT could successfully make connections to tags like 'jQuery' and 'css' while CodeBERT struggles to give meaningful predictions.\n\nOverall, by continuing the pre-training process on Stack Overflow data, SOBERT outperforms CodeBERT in three popular Stack Overflow-related tasks.\n\nFurthermore, Figure 1 shows the learning curve of different representation models in the tag recommendation task (i.e., evaluated on the test data) by varying the number of epochs. SOBERT not only achieves state-of-the-art effectiveness, but it also converges faster than the other models. The same pattern is observed in the API recommendation and the relatedness prediction tasks. In practice, a model with a faster convergence speed is preferred as the fine-tuning stage would require less amount of resources, and it implies that the model provides a good initialization for the learning tasks. We advocate future studies to consider SOBERT as their underlying baseline. To facilitate the usage of the enhanced CodeBERT model proposed in this work, we plan to release it to HuggingFace 5 so that it can be used by simply calling the interface.\n\n\nThreats to Validity\n\nThreats to internal validity. To ensure the correct implementation of the baseline methods (i.e., Post2Vec, PTM4Tag, CLEAR, and ASIM), we reused the replication package released by the original authors. 6,7,8,9 When investigating the effectiveness of various pre-trained models, we used the implementation of each from the popular open-source community HuggingFace. Junda  Threats to external validity. One threat to external validity relates our results may not generalize to those newly emerging topics or other Stack Overflow-related downstream tasks. We have minimized this threat by considering multiple downstream tasks. Threats to construct validity. We reuse the same evaluation metrics in our baseline methods [11,23,41]. To further reduce the risk, we conduct the Wilcoxon signed-rank statistical hypothesis test to check whether the output between the two competing approaches is significant.\n\n\nRELATED WORK\n\nIn this section, we review two lines of research that most relate to our work: pre-trained models for SE and mining Stack Overflow posts.\n\n\nPre-trained Models for Software Engineering\n\nInspired by the success of pre-trained models achieved in the field of artificial intelligence, there is emerging research interest in exploring pre-training tasks and applying pre-trained models in SE [16,20,22,39,47]. One set of research focuses on learning semantic and contextual representations of source code; after pre-training, these models can be fine-tuned to solve SE downstream tasks. Note that the three Stack Overflow tasks considered in our work are understanding tasks. Thus, we focus on the encoder-based models (i.e., the Transformer Encoder component). In the literature, there are other types of PTMs that can be used for generation tasks. They are based on the Transformer decoder component (e.g., CodeGPT [22]) or encoder-decoder architecture (e.g., CodeT5 [39]). In this part, we review one model from each category. ContraCode [16] is another encoder-based model, which adopts a contrastive pre-training task to learn code functionality. They organize programs into positive pairs (i.e., functionally similar) and negative pairs (i.e., functionally dissimilar). During contrastive pre-training, query programs are used to retrieve positive programs. Positive programs are pushed together, while negative ones have been pushed away. CodeGPT [22] pre-trains a Transformer-decoder-based language model GPT [27] on program languages. It consists of 12 layers of Transformer decoders. CodeGPT has been pre-trained in Python and Java corpora from the CodeSearchNet dataset, which contains 1.1M Python functions and 1.6M Java methods. It can be used for code completion and code generation tasks [22]. Wang et al. [39] present CodeT5, a pre-trained encoder-decoder Transformer model that better leverages the code semantics conveyed from the developer-assigned identifiers. Similar to T5, CodeT5 pre-trains on the masking span prediction task, which randomly masks spans with arbitrary length in the source sequence and then predicts the masked spans. In addition, CodeT5 also pre-trains with two tasks to fuse code-specific structural information into the model, i.e., identifier tagging and masked identifier prediction.\n\nThe other set of research focuses on fine-tuning the pre-trained models to tackle SE challenges [20,47]. Zhang et al. [47] conduct a comparative study on PTM with prior SE-specific tools in sentiment analysis for SE. The experimental results show that PTM is more ready for real use than the prior tools. Lin et al. [20] find that BERT can boost the performance of traceability tasks in open-source projects. They investigate three BERT architectures, i.e., Single-BERT, Siamese-BERT, and Twin-BERT. The results indicate that the single-BERT can generate the most accurate links, while a Siamese-BERT architecture produced comparable effectiveness with significantly better efficiency. In this paper, we conducted a comprehensive study on multiple SOTA PTMs for mining Stack Overflow tasks. Different from these works, ours is more comprehensive and covers several common tasks other than focusing on one specific task. Except for fine-tuning PTMs, we also further pretrained CodeBERT on Stack Overflow data.\n\n\nMining Stack Overflow Posts\n\nWe address tag recommendation [11,43], API recommendation [4,41], and relatedness prediction [23,44] in this work. Others also explored other tasks for mining Stack Overflow posts to support software developers, such as post recommendation [29], multi-answer summarization [45], and controversial discussions [28].\n\nRubei et al. [29] propose an approach named PostFinder, which aims to retrieve Stack Overflow posts that are relevant to API function calls that have been invoked. They make use of Apache Lucene to index the textual content and code in Stack Overflow to improve efficiency. In both the data collection and query phase, they make use of the data available at hand to optimize the search process. Specifically, they retrieve and augment posts with additional data to make them more exposed to queries. Besides, they boost the context code to construct a query that contains the essential information to match the stored indexes.\n\nXu et al. [45] investigate the multi-answer posts summarization task for a given input question, which aims to help developers get the key points of several answer posts before they dive into the details of the results. They propose an approach AnswerBot, which contains three main steps, i.e., relevant question retrieval, useful answer paragraph selection, and diverse answer summary generation.\n\nRen et al. [28] investigate the controversial discussions in Stack Overflow. They find that there is a large scale of controversies in Stack Overflow, which indicates that many answers are wrong, less optimal, and out-of-date. Our work and their work are complementary to each other, and all aim to boost automation in understanding and utilizing Stack Overflow contents.\n\n\nCONCLUSION AND FUTURE WORK\n\nIn this paper, we empirically study the effectiveness of varying techniques for modeling Stack Overflow posts, including approaches that are specially designed for Stack Overflow posts (i.e., Post2Vec and BERTOverflow), SE domain representation models (i.e., CodeBERT, GraphCodeBERT, and seBERT) and general domain representation models (i.e., RoBERTa, and LongFormer). We evaluate the performance of these representation models on three popular and representative Stack Overflow-related tasks, which are tag recommendation, API recommendation, and relatedness prediction.\n\nOur experimental results show that Post2Vec is unable to enhance the representations that are automatically extracted by deep learning-based methods and BERTOverflow performs surprisingly worse than other BERT-based language models. Furthermore, there does not exist one representation technique that could consistently outperform other representation models. Our findings indicate the current research gap in representing Stack Overflow posts. Thus, we propose SOBERT with a simple-yet-effective strategy. We initialize SOBERT with the checkpoint of CodeBERT and continue the pre-training process with 22 million posts from Stack Overflow. As a result, SOBERT improves the performance of the original CodeBERT and consistently outperforms other models on all three tasks, confirming that further pre-training on Stack Overflow data is helpful for building Stack Overflow representation.\n\nIn the future, we would also extend our research to other SQA sites, such as AskUbuntu 10 . Moreover, we show that Longformer and BERTOverflow do not generate better representations for Stack Overflow posts, therefore exploring better representation models which could handle noise in a longer input and with a Stack Overflow vocabulary is still a possible direction to explore.\n\n\nDATA AVAILABILITY\n\nThe replication package of the data and code used in this paper is available at https://figshare. com/s/7f80db836305607b89f3.\n\n\u2022\nDirect: One KU is beneficial in answering the question in another KU, for example, by explaining certain concepts and giving examples. \u2022 Indirect: One KU provides relevant information but does not directly answer the questions of another KU. \u2022 Isolated: The two KUs are semantically uncorrelated. 3.3.2 State-of-the-art technique. Recently, Pei et al. introduced ASIM [23], which yielded stateof-the-art performance in the relatedness prediction task. Pei et al. pre-trained word embeddings specialized to model Stack Overflow posts with a corpus collected from the Stack Overflow data dump. Then ASIM uses BiLSTM [31] to extract features from Stack Overflow posts and implements the attention mechanism to capture the semantic interaction among the KUs.\n\n\nTable 2. Experimental Results for API Recommendation TaskGroup \nRepresentation \nP@1 R@1 F1@1 P@3 R@3 F1@3 \nP@5 \nR@5 \nF1@5 \nSOTA \nPTM4Tag \n0.875 0.875 0.875 0.586 0.756 0.641 \n0.417 \n0.805 \n0.526 \n\nSO-Specific \nPost2Vec \n0.875 0.875 0.875 0.585 0.754 0.639 \n0.416 \n0.804 \n0.525 \nBERTOverflow \n0.088 0.088 0.088 0.089 0.094 0.095 \n0.083 \n0.163 \n0.105 \nGeneral \ndomain \n\nRoBERTa \n0.878 0.878 0.878 0.591 0.761 0.646 \n0.418 \n0.804 \n0.527 \nLongformer \n0.852 0.852 0.852 0.559 0.721 0.612 \n0.397 \n0.769 \n0.502 \n\nSE \ndomain \n\nCodeBERT \n0.876 0.876 0.876 0.588 0.758 0.642 \n0.418 \n0.805 \n0.527 \nGraphCodeBERT 0.874 0.875 0.875 0.582 0.751 0.636 \n0.410 \n0.791 \n0.517 \nseBERT \n0.088 0.088 0.088 0.089 0.094 0.095 \n0.083 \n0.163 \n0.105 \nOur Model \nSOBERT \n0.896 0.896 0.896 0.610 0.784 0.666 0.431(+3.1%) 0.830(+3.1%) 0.544(+3.2%) \n\nTable 1. Experiment Results for Tag Recommendation Task \n\nGroup \nRepresentation \nMRR \nMAP \nP@1 P@3 P@5 R@1 R@3 R@5 \nSOTA \nCLEAR \n0.739 \n0.753 \n0.482 0.560 0.562 0.629 0.766 0.793 \n\nSO-Specific \nPost2Vec \n0.735 \n0.745 \n0.471 0.560 0.556 0.625 0.774 0.801 \nBERTOverflow \n0.753 \n0.778 \n0.521 0.639 0.651 0.681 0.774 0.762 \n\nGeneral domain \nRoBERTa \n0.777 \n0.790 \n0.537 0.640 0.653 0.689 0.782 0.815 \nLongformer \n0.767 \n0.782 \n0.525 0.623 0.646 0.683 0.772 0.793 \n\nSE domain \n\nCodeBERT \n0.781 \n0.800 \n0.564 0.641 0.659 0.712 0.772 0.793 \nGraphCodeBERT \n0.784 \n0.804 \n0.537 0.652 0.663 0.693 0.803 0.829 \nseBERT \n0.754 \n0.777 \n0.525 0.624 0.635 0.678 0.749 0.772 \nOur Model \nSOBERT \n0.809(+3.2%) 0.827(+2.9%) 0.571 0.681 0.687 0.728 0.824 0.849 \n\nGroup \nRepresentation \nF1-Score \nPrecision \nRecall \nSOTA \nASIM \n0.785 \n0.785 \n0.785 \n\nSO-Specific \nPost2Vec \n0.768 \n0.768 \n0.768 \nBERTOverflow \n0.697 \n0.697 \n0.697 \n\nGeneral Domain \nRoBERTa \n0.787 \n0.787 \n0.787 \nLongformer \n0.786 \n0.786 \n0.786 \n\nSE domain \n\nCodeBERT \n0.803 \n0.803 \n0.803 \nGraphCodeBERT \n0.801 \n0.801 \n0.801 \nseBERT \n0.799 \n0.799 \n0.799 \nOur Model \nSOBERT \n0.824(+2.6%) 0.824(+2.6%) 0.824(+2.6%) \n\n\n\nTable 3 .\n3Experiment Result for Relatedness Prediction TaskRQ2: How effective are the popular BERT-based language models for the targeted \ndownstream tasks? \nFor tag recommendation (Table 1), the F1-score@5 for state-of-the-art approach PTM4Tag is 0.526. \nCodeBERT and RoBERTa can both achieve a higher F1-score@5 of 0.527. For Longformer and \nGraphCodeBERT, their F1-score@5 are 0.502 and 0.517, respectively. Like BERTOverflow, seBERT \nstruggles in this task with an F1-score@5 of 0.105. \n\n\nTable 4 .\n4Examples of the tokenization of software-related technical words by CodeBERT and BERTOverflow\n\nTable 6 .\n6Examples of predictions made by CodeBERT and SOBERT in the tag recommendation task\n\n\nHe, Zhou Xin, Bowen Xu, Ting Zhang, Kisub Kim, Zhou Yang, Ferdian Thung, Ivana Irsan, and David Lo Fig. 1. Performance of pre-trained models on tag prediction during trainingThe Number of Epoch \n\nF1@5 \n\n0.0 \n\n0.2 \n\n0.4 \n\n0.6 \n\n2 \n4 \n6 \n8 \n10 \n12 \n14 \n16 \n18 \n20 \n22 \n24 \n26 \n28 \n30 \n\nCodeBERT \nSOBERT \nGraphCodeBERT \nLongformer \nRoBERTa \n\n\nhttps://stackexchange.com/sites?view=list#traffic\nhttps://huggingface.co/distilroberta-base\nhttps://huggingface.co/distilroberta-base\nPlease note that we could not apply further pre-training to seBERT due to the constraints of limited resources to handle BERT Large architecture.\nhttps://huggingface.co/ 6 https://github.com/maxxbw54/Post2Vec 7 https://github.com/soarsmu/PTM4Tag 8 https://github.com/Moshiii/CLEAR-replication 9 https://github.com/Anonymousmsr/ASIM\nhttps://askubuntu.com/\n\nClassifying stack overflow posts on API issues. Md Ahasanuzzaman, Muhammad Asaduzzaman, K Chanchal, Kevin A Roy, Schneider, IEEE 25th international conference on software analysis, evolution and reengineering (SANER). IEEEMd Ahasanuzzaman, Muhammad Asaduzzaman, Chanchal K Roy, and Kevin A Schneider. 2018. Classifying stack overflow posts on API issues. In 2018 IEEE 25th international conference on software analysis, evolution and reengineering (SANER). IEEE, 244-254.\n\nLongformer: The Long-Document Transformer. Iz Beltagy, Matthew E Peters, Arman Cohan, arXiv:2004.05150Iz Beltagy, Matthew E. Peters, and Arman Cohan. 2020. Longformer: The Long-Document Transformer. CoRR abs/2004.05150 (2020). arXiv:2004.05150 https://arxiv.org/abs/2004.05150\n\nAutomatically classifying posts into question categories on stack overflow. Stefanie Beyer, Christian Macho, Massimiliano Di Penta, Martin Pinzger, 2018 IEEE/ACM 26th International Conference on Program Comprehension (ICPC). IEEEStefanie Beyer, Christian Macho, Massimiliano Di Penta, and Martin Pinzger. 2018. Automatically classifying posts into question categories on stack overflow. In 2018 IEEE/ACM 26th International Conference on Program Comprehension (ICPC). IEEE, 211-21110.\n\nBIKER: a tool for Bi-information source based API method recommendation. Liang Cai, Haoye Wang, Qiao Huang, Xin Xia, Zhenchang Xing, David Lo, 10.1145/3338906.3341174Proceedings of the ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/SIGSOFT FSE 2019. Marlon Dumas, Dietmar Pfahl, Sven Apel, and Alessandra Russothe ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/SIGSOFT FSE 2019Tallinn, EstoniaACMLiang Cai, Haoye Wang, Qiao Huang, Xin Xia, Zhenchang Xing, and David Lo. 2019. BIKER: a tool for Bi-information source based API method recommendation. In Proceedings of the ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/SIGSOFT FSE 2019, Tallinn, Estonia, August 26-30, 2019, Marlon Dumas, Dietmar Pfahl, Sven Apel, and Alessandra Russo (Eds.). ACM, 1075-1079. https: //doi.org/10.1145/3338906.3341174\n\nTree-to-tree Neural Networks for Program Translation. Xinyun Chen, Chang Liu, Dawn Song, ; Montr\u00e9al, Canada , Samy Bengio, Hanna M Wallach, Hugo Larochelle, Advances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems. Kristen Grauman, Nicol\u00f2 Cesa-Bianchi, and Roman GarnettNeurIPSXinyun Chen, Chang Liu, and Dawn Song. 2018. Tree-to-tree Neural Networks for Program Translation. In Ad- vances in Neural Information Processing Systems 31: Annual Conference on Neural Information Processing Systems 2018, NeurIPS 2018, December 3-8, 2018, Montr\u00e9al, Canada, Samy Bengio, Hanna M. Wallach, Hugo Larochelle, Kristen Grauman, Nicol\u00f2 Cesa-Bianchi, and Roman Garnett (Eds.). 2552-2562. https://proceedings.neurips.cc/paper/2018/ hash/d759175de8ea5b1d9a2660e45554894f-Abstract.html\n\nBERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, 10.18653/v1/n19-1423Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019. Jill Burstein, Christy Doran, and Thamar Soloriothe 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019Minneapolis, MN, USAAssociation for Computational Linguistics1Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers), Jill Burstein, Christy Doran, and Thamar Solorio (Eds.). Association for Computational Linguistics, 4171-4186. https://doi.org/10.18653/v1/n19-1423\n\nCodeBERT: A Pre-Trained Model for Programming and Natural Languages. Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong, Linjun Shou, Bing Qin, Ting Liu, Daxin Jiang, Ming Zhou, 10.18653/v1/2020.findings-emnlp.139Findings of the Association for Computational Linguistics: EMNLP 2020, Online Event. Trevor Cohn, Yulan He, and Yang LiuAssociation for Computational Linguistics2020Findings of ACLZhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong, Linjun Shou, Bing Qin, Ting Liu, Daxin Jiang, and Ming Zhou. 2020. CodeBERT: A Pre-Trained Model for Programming and Natural Languages. In Findings of the Association for Computational Linguistics: EMNLP 2020, Online Event, 16-20 November 2020 (Findings of ACL, Vol. EMNLP 2020), Trevor Cohn, Yulan He, and Yang Liu (Eds.). Association for Computational Linguistics, 1536-1547. https://doi.org/10.18653/v1/2020.findings-emnlp.139\n\nDeep API learning. Xiaodong Gu, Hongyu Zhang, D Zhang, Sunghun Kim, Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering. the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software EngineeringXiaodong Gu, Hongyu Zhang, D. Zhang, and Sunghun Kim. 2016. Deep API learning. Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering (2016).\n\nGraphCodeBERT: Pre-training Code Representations with Data Flow. Daya Guo, Shuai Shuo Ren, Zhangyin Lu, Duyu Feng, Shujie Tang, Long Liu, Nan Zhou, Alexey Duan, Shengyu Svyatkovskiy, Michele Fu, Tufano, Colin B Shao Kun Deng, Dawn Clement, Neel Drain, Jian Sundaresan, Daxin Yin, Ming Jiang, Zhou, 9th International Conference on Learning Representations, ICLR 2021, Virtual Event. AustriaDaya Guo, Shuo Ren, Shuai Lu, Zhangyin Feng, Duyu Tang, Shujie Liu, Long Zhou, Nan Duan, Alexey Svyatkovskiy, Shengyu Fu, Michele Tufano, Shao Kun Deng, Colin B. Clement, Dawn Drain, Neel Sundaresan, Jian Yin, Daxin Jiang, and Ming Zhou. 2021. GraphCodeBERT: Pre-training Code Representations with Data Flow. In 9th International Conference on Learning Representations, ICLR 2021, Virtual Event, Austria, May 3-7, 2021. OpenReview.net. https: //openreview.net/forum?id=jLoC4ez43PZ\n\nAna Suchin Gururangan, Swabha Marasovi\u0107, Kyle Swayamdipta, Iz Lo, Doug Beltagy, Noah A Downey, Smith, arXiv:2004.109642020. Don't stop pretraining: adapt language models to domains and tasks. arXiv preprintSuchin Gururangan, Ana Marasovi\u0107, Swabha Swayamdipta, Kyle Lo, Iz Beltagy, Doug Downey, and Noah A Smith. 2020. Don't stop pretraining: adapt language models to domains and tasks. arXiv preprint arXiv:2004.10964 (2020).\n\nPTM4Tag: Sharpening Tag Recommendation of Stack Overflow Posts with Pre-trained Models. Junda He, Bowen Xu, Zhou Yang, Donggyun Han, Chengran Yang, David Lo, 10.48550/arXiv.2203.10965arXiv:2203.10965Junda He, Bowen Xu, Zhou Yang, DongGyun Han, Chengran Yang, and David Lo. 2022. PTM4Tag: Sharpening Tag Recommendation of Stack Overflow Posts with Pre-trained Models. CoRR abs/2203.10965 (2022). https://doi.org/10. 48550/arXiv.2203.10965 arXiv:2203.10965\n\nLong short-term memory. Sepp Hochreiter, J\u00fcrgen Schmidhuber, Neural computation. 9Sepp Hochreiter and J\u00fcrgen Schmidhuber. 1997. Long short-term memory. Neural computation 9, 8 (1997), 1735-1780.\n\nAPI Method Recommendation without Worrying about the Task-API Knowledge Gap. Qiao Huang, Xin Xia, Zhenchang Xing, D Lo, Xinyu Wang, 33rd IEEE/ACM International Conference on Automated Software Engineering (ASE). Qiao Huang, Xin Xia, Zhenchang Xing, D. Lo, and Xinyu Wang. 2018. API Method Recommendation without Worrying about the Task-API Knowledge Gap. 2018 33rd IEEE/ACM International Conference on Automated Software Engineering (ASE) (2018), 293-304.\n\nAPI method recommendation without worrying about the task-API knowledge gap. Qiao Huang, Xin Xia, Zhenchang Xing, David Lo, Xinyu Wang, 10.1145/3238147.3238191Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering, ASE 2018. Marianne Huchard, Christian K\u00e4stner, and Gordon Fraserthe 33rd ACM/IEEE International Conference on Automated Software Engineering, ASE 2018Montpellier, FranceACMQiao Huang, Xin Xia, Zhenchang Xing, David Lo, and Xinyu Wang. 2018. API method recommendation without worrying about the task-API knowledge gap. In Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering, ASE 2018, Montpellier, France, September 3-7, 2018, Marianne Huchard, Christian K\u00e4stner, and Gordon Fraser (Eds.). ACM, 293-304. https://doi.org/10.1145/3238147.3238191\n\nCodeSearchNet Challenge: Evaluating the State of Semantic Code Search. Hamel Husain, Ho-Hsiang Wu, Tiferet Gazit, Miltiadis Allamanis, Marc Brockschmidt, arXiv:1909.09436Hamel Husain, Ho-Hsiang Wu, Tiferet Gazit, Miltiadis Allamanis, and Marc Brockschmidt. 2019. CodeSearchNet Challenge: Evaluating the State of Semantic Code Search. CoRR abs/1909.09436 (2019). arXiv:1909.09436 http: //arxiv.org/abs/1909.09436\n\nContrastive Code Representation Learning. Paras Jain, Ajay Jain, Tianjun Zhang, Pieter Abbeel, Joseph Gonzalez, Ion Stoica, 10.18653/v1/2021.emnlp-main.482Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. Marie-Francine Moens, Xuanjing Huang, Lucia Specia, and Scott Wen-tau Yihthe 2021 Conference on Empirical Methods in Natural Language ProcessingDominican RepublicAssociation for Computational Linguistics2021Virtual Event / Punta CanaParas Jain, Ajay Jain, Tianjun Zhang, Pieter Abbeel, Joseph Gonzalez, and Ion Stoica. 2021. Contrastive Code Representation Learning. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana, Dominican Republic, 7-11 November, 2021, Marie-Francine Moens, Xuanjing Huang, Lucia Specia, and Scott Wen-tau Yih (Eds.). Association for Computational Linguistics, 5954-5971. https: //doi.org/10.18653/v1/2021.emnlp-main.482\n\nALBERT: A Lite BERT for Self-supervised Learning of Language Representations. Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, Radu Soricut, 8th International Conference on Learning Representations. Addis Ababa, Ethiopia2020Zhenzhong Lan, Mingda Chen, Sebastian Goodman, Kevin Gimpel, Piyush Sharma, and Radu Soricut. 2020. ALBERT: A Lite BERT for Self-supervised Learning of Language Representations. In 8th International Conference on Learning Representations, ICLR 2020, Addis Ababa, Ethiopia, April 26-30, 2020. OpenReview.net. https://openreview.net/forum? id=H1eA7AEtvS\n\nDeep learning. Yann Lecun, Yoshua Bengio, Geoffrey Hinton, nature. 521Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. 2015. Deep learning. nature 521, 7553 (2015), 436-444.\n\nTagDC: A tag recommendation method for software information sites with a combination of deep learning and collaborative filtering. Can Li, Ling Xu, Meng Yan, Yan Lei, 10.1016/j.jss.2020.110783J. Syst. Softw. 170110783Can Li, Ling Xu, Meng Yan, and Yan Lei. 2020. TagDC: A tag recommendation method for software information sites with a combination of deep learning and collaborative filtering. J. Syst. Softw. 170 (2020), 110783. https: //doi.org/10.1016/j.jss.2020.110783\n\nTraceability Transformed: Generating more Accurate Links with Pre-Trained BERT Models. Jinfeng Lin, Yalin Liu, Qingkai Zeng, Meng Jiang, Jane Cleland-Huang, 10.1109/ICSE43902.2021.0004043rd IEEE/ACM International Conference on Software Engineering, ICSE 2021. Madrid, SpainIEEEJinfeng Lin, Yalin Liu, Qingkai Zeng, Meng Jiang, and Jane Cleland-Huang. 2021. Traceability Transformed: Generating more Accurate Links with Pre-Trained BERT Models. In 43rd IEEE/ACM International Conference on Software Engineering, ICSE 2021, Madrid, Spain, 22-30 May 2021. IEEE, 324-335. https://doi.org/10.1109/ICSE43902.2021.00040\n\nRoBERTa: A Robustly Optimized BERT Pretraining Approach. Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov, arXiv:1907.11692Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. RoBERTa: A Robustly Optimized BERT Pretraining Approach. CoRR abs/1907.11692 (2019). arXiv:1907.11692 http://arxiv.org/abs/1907.11692\n\nCodexglue: A machine learning benchmark dataset for code understanding and generation. Shuai Lu, Daya Guo, Shuo Ren, Junjie Huang, Alexey Svyatkovskiy, Ambrosio Blanco, Colin Clement, Dawn Drain, Daxin Jiang, Duyu Tang, arXiv:2102.04664arXiv preprintShuai Lu, Daya Guo, Shuo Ren, Junjie Huang, Alexey Svyatkovskiy, Ambrosio Blanco, Colin Clement, Dawn Drain, Daxin Jiang, Duyu Tang, et al. 2021. Codexglue: A machine learning benchmark dataset for code understanding and generation. arXiv preprint arXiv:2102.04664 (2021).\n\nAttention-based model for predicting question relatedness on Stack Overflow. Jiayan Pei, Yimin Wu, Zishan Qin, Yao Cong, Jingtao Guan, IEEE/ACM 18th International Conference on Mining Software Repositories (MSR) (2021). Jiayan Pei, Yimin Wu, Zishan Qin, Yao Cong, and Jingtao Guan. 2021. Attention-based model for predicting question relatedness on Stack Overflow. 2021 IEEE/ACM 18th International Conference on Mining Software Repositories (MSR) (2021), 97-107.\n\nDeep Contextualized Word Representations. Matthew E Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, Luke Zettlemoyer, 10.18653/v1/n18-1202Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2018. Marilyn A. Walker, Heng Ji, and Amanda Stentthe 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2018New Orleans, Louisiana, USAAssociation for Computational Linguistics1Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and Luke Zettlemoyer. 2018. Deep Contextualized Word Representations. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2018, New Orleans, Louisiana, USA, June 1-6, 2018, Volume 1 (Long Papers), Marilyn A. Walker, Heng Ji, and Amanda Stent (Eds.). Association for Computational Linguistics, 2227-2237. https://doi.org/10.18653/v1/n18-1202\n\nImproving Low Quality Stack Overflow Post Detection. Luca Ponzanelli, Andrea Mocci, Alberto Bacchelli, Michele Lanza, David Fullerton, 10.1109/ICSME.2014.9030th IEEE International Conference on Software Maintenance and Evolution. Victoria, BC, CanadaIEEE Computer SocietyLuca Ponzanelli, Andrea Mocci, Alberto Bacchelli, Michele Lanza, and David Fullerton. 2014. Improving Low Quality Stack Overflow Post Detection. In 30th IEEE International Conference on Software Maintenance and Evolution, Victoria, BC, Canada, September 29 -October 3, 2014. IEEE Computer Society, 541-544. https://doi.org/10.1109/ICSME.2014.90\n\nBERT with History Answer Embedding for Conversational Question Answering. Chen Qu, Liu Yang, Minghui Qiu, W Bruce Croft, Yongfeng Zhang, Mohit Iyyer, 10.1145/3331184.3331341Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2019. Benjamin Piwowarski, Max Chevalier, \u00c9ric Gaussier, Yoelle Maarek, Jian-Yun Nie, and Falk Scholerthe 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2019Paris, FranceACMChen Qu, Liu Yang, Minghui Qiu, W. Bruce Croft, Yongfeng Zhang, and Mohit Iyyer. 2019. BERT with History Answer Embedding for Conversational Question Answering. In Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2019, Paris, France, July 21-25, 2019, Benjamin Piwowarski, Max Chevalier, \u00c9ric Gaussier, Yoelle Maarek, Jian-Yun Nie, and Falk Scholer (Eds.). ACM, 1133-1136. https://doi.org/10.1145/3331184.3331341\n\nLanguage models are unsupervised multitask learners. Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, OpenAI blog. 19Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. 2019. Language models are unsupervised multitask learners. OpenAI blog 1, 8 (2019), 9.\n\nDiscovering, explaining and summarizing controversial discussions in community q&a sites. Xiaoxue Ren, Zhenchang Xing, Xin Xia, Guoqiang Li, Jianling Sun, 34th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEEXiaoxue Ren, Zhenchang Xing, Xin Xia, Guoqiang Li, and Jianling Sun. 2019. Discovering, explaining and summarizing controversial discussions in community q&a sites. In 2019 34th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, 151-162.\n\nPostFinder: Mining Stack Overflow posts to support software developers. Riccardo Rubei, Claudio Di Sipio, Phuong Thanh Nguyen, Juri Di Rocco, Davide Di Ruscio, 10.1016/j.infsof.2020.106367Inf. Softw. Technol. 127106367Riccardo Rubei, Claudio Di Sipio, Phuong Thanh Nguyen, Juri Di Rocco, and Davide Di Ruscio. 2020. PostFinder: Mining Stack Overflow posts to support software developers. Inf. Softw. Technol. 127 (2020), 106367. https://doi.org/10. 1016/j.infsof.2020.106367\n\nDistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter. Victor Sanh, Lysandre Debut, Julien Chaumond, Thomas Wolf, arXiv:1910.01108Victor Sanh, Lysandre Debut, Julien Chaumond, and Thomas Wolf. 2019. DistilBERT, a distilled version of BERT: smaller, faster, cheaper and lighter. CoRR abs/1910.01108 (2019). arXiv:1910.01108 http://arxiv.org/abs/1910.01108\n\nBidirectional recurrent neural networks. Mike Schuster, K Kuldip, Paliwal, IEEE transactions on Signal Processing. 45Mike Schuster and Kuldip K Paliwal. 1997. Bidirectional recurrent neural networks. IEEE transactions on Signal Processing 45, 11 (1997), 2673-2681.\n\nAmirreza Shirani, Bowen Xu, David Lo, Thamar Solorio, Mohammad Amin Alipour, ArXiv abs/1905.01966Question Relatedness on Stack Overflow: The Task, Dataset, and Corpus-inspired Models. Amirreza Shirani, Bowen Xu, David Lo, Thamar Solorio, and Mohammad Amin Alipour. 2019. Question Relatedness on Stack Overflow: The Task, Dataset, and Corpus-inspired Models. ArXiv abs/1905.01966 (2019).\n\nUtilizing BERT for Aspect-Based Sentiment Analysis via Constructing Auxiliary Sentence. Chi Sun, Luyao Huang, Xipeng Qiu, 10.18653/v1/n19-1035Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019. Jill Burstein, Christy Doran, and Thamar Soloriothe 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2019Minneapolis, MN, USAAssociation for Computational Linguistics1Chi Sun, Luyao Huang, and Xipeng Qiu. 2019. Utilizing BERT for Aspect-Based Sentiment Analysis via Constructing Auxiliary Sentence. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computa- tional Linguistics: Human Language Technologies, NAACL-HLT 2019, Minneapolis, MN, USA, June 2-7, 2019, Volume 1 (Long and Short Papers), Jill Burstein, Christy Doran, and Thamar Solorio (Eds.). Association for Computational Linguistics, 380-385. https://doi.org/10.18653/v1/n19-1035\n\nCode and Named Entity Recognition in Stack-Overflow. Jeniya Tabassum, Mounica Maddela, Wei Xu, Alan Ritter, 10.18653/v1/2020.acl-main.443Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. the 58th Annual Meeting of the Association for Computational LinguisticsAssociation for Computational LinguisticsJeniya Tabassum, Mounica Maddela, Wei Xu, and Alan Ritter. 2020. Code and Named Entity Recognition in Stack- Overflow. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics, Online, 4913-4926. https://doi.org/10.18653/v1/2020.acl-main.443\n\nSmall and Practical BERT Models for Sequence Labeling. Henry Tsai, Jason Riesa, Melvin Johnson, Naveen Arivazhagan, Xin Li, Amelia Archer, 10.18653/v1/D19-1374Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing. Kentaro Inui, Jing Jiang, Vincent Ng, and Xiaojun Wanthe 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language ProcessingHong Kong, ChinaAssociation for Computational LinguisticsHenry Tsai, Jason Riesa, Melvin Johnson, Naveen Arivazhagan, Xin Li, and Amelia Archer. 2019. Small and Practical BERT Models for Sequence Labeling. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing, EMNLP-IJCNLP 2019, Hong Kong, China, November 3-7, 2019, Kentaro Inui, Jing Jiang, Vincent Ng, and Xiaojun Wan (Eds.). Association for Computational Linguistics, 3630-3634. https://doi.org/10.18653/v1/D19-1374\n\nAn Empirical Study on Learning Bug-Fixing Patches in the Wild via Neural Machine Translation. Michele Tufano, Cody Watson, Gabriele Bavota, Massimiliano Di Penta, Martin White, Denys Poshyvanyk, 10.1145/3340544ACM Trans. Softw. Eng. Methodol. 2829Michele Tufano, Cody Watson, Gabriele Bavota, Massimiliano Di Penta, Martin White, and Denys Poshyvanyk. 2019. An Empirical Study on Learning Bug-Fixing Patches in the Wild via Neural Machine Translation. ACM Trans. Softw. Eng. Methodol. 28, 4 (2019), 19:1-19:29. https://doi.org/10.1145/3340544\n\nAttention is All you Need. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, Illia Polosukhin, Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems. Luxburg, Samy Bengio, Hanna M. Wallach, Rob Fergus, S. V. N. Vishwanathan, and Roman GarnettLong Beach, CA, USA, Isabelle GuyonAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is All you Need. In Advances in Neural Information Processing Systems 30: Annual Conference on Neural Information Processing Systems 2017, December 4-9, 2017, Long Beach, CA, USA, Isabelle Guyon, Ulrike von Luxburg, Samy Bengio, Hanna M. Wallach, Rob Fergus, S. V. N. Vishwanathan, and Roman Garnett (Eds.). 5998-6008. https://proceedings.neurips.cc/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html\n\nOn the validity of pre-trained transformers for natural language processing in the software engineering domain. Julian Von Der Mosel, Alexander Trautsch, Steffen Herbold, 10.1109/TSE.2022.3178469IEEE Transactions on Software Engineering. Julian Von der Mosel, Alexander Trautsch, and Steffen Herbold. 2022. On the validity of pre-trained transformers for natural language processing in the software engineering domain. IEEE Transactions on Software Engineering (2022), 1-1. https://doi.org/10.1109/TSE.2022.3178469\n\nCodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation. Yue Wang, Weishi Wang, R Shafiq, Steven C H Joty, Hoi, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. the 2021 Conference on Empirical Methods in Natural Language ProcessingDominican Republic2021Virtual Event / Punta CanaYue Wang, Weishi Wang, Shafiq R. Joty, and Steven C. H. Hoi. 2021. CodeT5: Identifier-aware Unified Pre-trained Encoder-Decoder Models for Code Understanding and Generation. In Proceedings of the 2021 Conference on Em- pirical Methods in Natural Language Processing, EMNLP 2021, Virtual Event / Punta Cana, Dominican Republic, 7-11\n\n10.18653/v1/2021.emnlp-main.685Association for Computational Linguistics. Marie-Francine Moens, Xuanjing Huang, Lucia Specia, and Scott Wen-tau YihNovember, 2021, Marie-Francine Moens, Xuanjing Huang, Lucia Specia, and Scott Wen-tau Yih (Eds.). Association for Computational Linguistics, 8696-8708. https://doi.org/10.18653/v1/2021.emnlp-main.685\n\nSupervised Deep Features for Software Functional Clone Detection by Exploiting Lexical and Syntactical Information in Source Code. Huihui Wei, Ming Li, 10.24963/ijcai.2017/423Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence. Carles Sierrathe Twenty-Sixth International Joint Conference on Artificial IntelligenceMelbourne, Australiaijcai.orgHuihui Wei and Ming Li. 2017. Supervised Deep Features for Software Functional Clone Detection by Exploiting Lexical and Syntactical Information in Source Code. In Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence, IJCAI 2017, Melbourne, Australia, August 19-25, 2017, Carles Sierra (Ed.). ijcai.org, 3034-3040. https://doi.org/10.24963/ijcai.2017/423\n\nCLEAR: Contrastive Learning for API Recommendation. Moshi Wei, Nima Shiri Harzevili, Junjie Wang Yuchao, Song Huang, Wang, 44th International Conference on Software Engineering (ICSE. Moshi Wei, Nima Shiri Harzevili, Junjie Wang Yuchao Huang, and Song Wang. 2022. CLEAR: Contrastive Learning for API Recommendation. 44th International Conference on Software Engineering (ICSE) (2022).\n\nWhat do developers search for on the web?. Xin Xia, Lingfeng Bao, D Lo, Pavneet Singh Kochhar, A Hassan, Zhenchang Xing, Empirical Software Engineering. 22Xin Xia, Lingfeng Bao, D. Lo, Pavneet Singh Kochhar, A. Hassan, and Zhenchang Xing. 2017. What do developers search for on the web? Empirical Software Engineering 22 (2017), 3149-3185.\n\nPost2Vec: Learning Distributed Representations of Stack Overflow Posts. Bowen Xu, Thong Hoang, Abhishek Sharma, Chengran Yang, Xin Xia, David Lo, 10.1109/TSE.2021.3093761IEEE Transactions on Software Engineering. Bowen Xu, Thong Hoang, Abhishek Sharma, Chengran Yang, Xin Xia, and David Lo. 2021. Post2Vec: Learning Distributed Representations of Stack Overflow Posts. IEEE Transactions on Software Engineering (2021), 1-1. https: //doi.org/10.1109/TSE.2021.3093761\n\nPrediction of relatedness in stack overflow: deep learning vs. Bowen Xu, Amirreza Shirani, David Lo, Mohammad Amin Alipour, 10.1145/3239235.3240503Proceedings of the 12th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement, ESEM 2018. Markku Oivo, Daniel M\u00e9ndez Fern\u00e1ndez, and Audris Mockusthe 12th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement, ESEM 2018Oulu, FinlandACM21SVM: a reproducibility studyBowen Xu, Amirreza Shirani, David Lo, and Mohammad Amin Alipour. 2018. Prediction of relatedness in stack overflow: deep learning vs. SVM: a reproducibility study. In Proceedings of the 12th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement, ESEM 2018, Oulu, Finland, October 11-12, 2018, Markku Oivo, Daniel M\u00e9ndez Fern\u00e1ndez, and Audris Mockus (Eds.). ACM, 21:1-21:10. https://doi.org/10.1145/3239235.3240503\n\nAnswerBot: Automated generation of answer summary to developers' technical questions. Bowen Xu, Zhenchang Xing, Xin Xia, David Lo, 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEEBowen Xu, Zhenchang Xing, Xin Xia, and David Lo. 2017. AnswerBot: Automated generation of answer summary to developers' technical questions. In 2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, 706-716.\n\nAspect-Based API Review Classification: How Far Can Pre-Trained Transformer Model Go. Chengran Yang, Bowen Xu, Junaed Younus Khan, Gias Uddin, Donggyun Han, Zhou Yang, David Lo, 2022 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER). IEEE Computer SocietyChengran Yang, Bowen Xu, Junaed Younus Khan, Gias Uddin, Donggyun Han, Zhou Yang, and David Lo. 2022. Aspect-Based API Review Classification: How Far Can Pre-Trained Transformer Model Go?. In 2022 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER). IEEE Computer Society.\n\nSentiment analysis for software engineering: How far can pre-trained transformer models go. Ting Zhang, Bowen Xu, Ferdian Thung, Agus Stefanus, David Haryono, Lingxiao Lo, Jiang, 2020 IEEE International Conference on Software Maintenance and Evolution (ICSME). IEEETing Zhang, Bowen Xu, Ferdian Thung, Stefanus Agus Haryono, David Lo, and Lingxiao Jiang. 2020. Sentiment analysis for software engineering: How far can pre-trained transformer models go?. In 2020 IEEE International Conference on Software Maintenance and Evolution (ICSME). IEEE, 70-80.\n\nIs deep learning better than traditional approaches in tag recommendation for software information sites?. Pingyi Zhou, Jin Liu, Xiao Liu, Zijiang Yang, John C Grundy, 10.1016/j.infsof.2019.01.002Inf. Softw. Technol. 109Pingyi Zhou, Jin Liu, Xiao Liu, Zijiang Yang, and John C. Grundy. 2019. Is deep learning better than traditional approaches in tag recommendation for software information sites? Inf. Softw. Technol. 109 (2019), 1-13. https: //doi.org/10.1016/j.infsof.2019.01.002\n", "annotations": {"author": "[{\"end\":89,\"start\":80},{\"end\":99,\"start\":90},{\"end\":109,\"start\":100},{\"end\":121,\"start\":110},{\"end\":132,\"start\":122},{\"end\":142,\"start\":133},{\"end\":152,\"start\":143},{\"end\":162,\"start\":153},{\"end\":172,\"start\":163},{\"end\":184,\"start\":173},{\"end\":195,\"start\":185},{\"end\":206,\"start\":196},{\"end\":221,\"start\":207},{\"end\":234,\"start\":222},{\"end\":244,\"start\":235},{\"end\":254,\"start\":245},{\"end\":264,\"start\":255},{\"end\":274,\"start\":265},{\"end\":286,\"start\":275},{\"end\":297,\"start\":287},{\"end\":308,\"start\":298},{\"end\":323,\"start\":309},{\"end\":336,\"start\":324},{\"end\":343,\"start\":337},{\"end\":387,\"start\":344},{\"end\":431,\"start\":388},{\"end\":475,\"start\":432},{\"end\":519,\"start\":476},{\"end\":541,\"start\":520},{\"end\":575,\"start\":542},{\"end\":644,\"start\":576},{\"end\":701,\"start\":645},{\"end\":735,\"start\":702},{\"end\":800,\"start\":736}]", "publisher": null, "author_last_name": "[{\"end\":88,\"start\":86},{\"end\":98,\"start\":95},{\"end\":108,\"start\":106},{\"end\":120,\"start\":115},{\"end\":131,\"start\":127},{\"end\":141,\"start\":139},{\"end\":151,\"start\":149},{\"end\":161,\"start\":158},{\"end\":171,\"start\":169},{\"end\":183,\"start\":178},{\"end\":194,\"start\":191},{\"end\":205,\"start\":201},{\"end\":220,\"start\":215},{\"end\":233,\"start\":228},{\"end\":243,\"start\":241},{\"end\":253,\"start\":251},{\"end\":263,\"start\":260},{\"end\":273,\"start\":271},{\"end\":285,\"start\":280},{\"end\":296,\"start\":293},{\"end\":307,\"start\":303},{\"end\":322,\"start\":317},{\"end\":335,\"start\":330}]", "author_first_name": "[{\"end\":85,\"start\":80},{\"end\":94,\"start\":90},{\"end\":105,\"start\":100},{\"end\":114,\"start\":110},{\"end\":126,\"start\":122},{\"end\":138,\"start\":133},{\"end\":148,\"start\":143},{\"end\":157,\"start\":153},{\"end\":168,\"start\":163},{\"end\":177,\"start\":173},{\"end\":190,\"start\":185},{\"end\":200,\"start\":196},{\"end\":214,\"start\":207},{\"end\":227,\"start\":222},{\"end\":240,\"start\":235},{\"end\":250,\"start\":245},{\"end\":259,\"start\":255},{\"end\":270,\"start\":265},{\"end\":279,\"start\":275},{\"end\":292,\"start\":287},{\"end\":302,\"start\":298},{\"end\":316,\"start\":309},{\"end\":329,\"start\":324},{\"end\":342,\"start\":337}]", "author_affiliation": "[{\"end\":386,\"start\":345},{\"end\":430,\"start\":389},{\"end\":474,\"start\":433},{\"end\":518,\"start\":477},{\"end\":540,\"start\":521},{\"end\":574,\"start\":543},{\"end\":643,\"start\":577},{\"end\":700,\"start\":646},{\"end\":734,\"start\":703},{\"end\":799,\"start\":737}]", "title": "[{\"end\":66,\"start\":1},{\"end\":866,\"start\":801}]", "venue": null, "abstract": "[{\"end\":3714,\"start\":1335}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b3\"},\"end\":4127,\"start\":4124},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":4130,\"start\":4127},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":4133,\"start\":4130},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":4136,\"start\":4133},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":4341,\"start\":4337},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":4433,\"start\":4430},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":4509,\"start\":4505},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":4886,\"start\":4882},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":4889,\"start\":4886},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":4892,\"start\":4889},{\"end\":5113,\"start\":5104},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":5136,\"start\":5132},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":5154,\"start\":5150},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":5504,\"start\":5501},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":5506,\"start\":5504},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":5509,\"start\":5506},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":5531,\"start\":5527},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":5805,\"start\":5801},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":5818,\"start\":5815},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":6068,\"start\":6064},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":6090,\"start\":6087},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":6717,\"start\":6714},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":6736,\"start\":6733},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":6749,\"start\":6745},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":6763,\"start\":6759},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":6783,\"start\":6780},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":6879,\"start\":6875},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":8022,\"start\":8018},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":8840,\"start\":8836},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":11374,\"start\":11370},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":11393,\"start\":11390},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":11439,\"start\":11436},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":11458,\"start\":11455},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":11476,\"start\":11472},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":11555,\"start\":11551},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":11573,\"start\":11569},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":11672,\"start\":11669},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":11766,\"start\":11763},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":11768,\"start\":11766},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":11771,\"start\":11768},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":11774,\"start\":11771},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":11777,\"start\":11774},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":11780,\"start\":11777},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":11908,\"start\":11904},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":11926,\"start\":11922},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":11951,\"start\":11947},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":12008,\"start\":12004},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":12711,\"start\":12707},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":13367,\"start\":13363},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":13465,\"start\":13461},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":14211,\"start\":14207},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":14870,\"start\":14866},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":14991,\"start\":14988},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":15503,\"start\":15500},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":15520,\"start\":15516},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":15628,\"start\":15624},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":16069,\"start\":16066},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":16493,\"start\":16489},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":17309,\"start\":17306},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":17468,\"start\":17465},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":17658,\"start\":17655},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":17729,\"start\":17725},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":17800,\"start\":17796},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":18211,\"start\":18208},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":18241,\"start\":18237},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":18267,\"start\":18264},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":18287,\"start\":18284},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":18669,\"start\":18666},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":18691,\"start\":18687},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":18713,\"start\":18710},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":18739,\"start\":18735},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":18843,\"start\":18840},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":18861,\"start\":18857},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":18872,\"start\":18868},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":18919,\"start\":18915},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":19998,\"start\":19994},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":20001,\"start\":19998},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":20025,\"start\":20022},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":20028,\"start\":20025},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":20060,\"start\":20056},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":20063,\"start\":20060},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":21228,\"start\":21224},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":21582,\"start\":21578},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":21796,\"start\":21792},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":22130,\"start\":22126},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":22219,\"start\":22216},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":22222,\"start\":22219},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":22225,\"start\":22222},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":22394,\"start\":22390},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":22995,\"start\":22991},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":22998,\"start\":22995},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":23373,\"start\":23369},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":23376,\"start\":23373},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":23379,\"start\":23376},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":23562,\"start\":23558},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":23565,\"start\":23562},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":23568,\"start\":23565},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":24301,\"start\":24297},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":24611,\"start\":24607},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":25612,\"start\":25608},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":25615,\"start\":25612},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":25745,\"start\":25741},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":25764,\"start\":25761},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":25805,\"start\":25802},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":25824,\"start\":25821},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":25841,\"start\":25837},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":26525,\"start\":26521},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":27011,\"start\":27007},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":27245,\"start\":27241},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":27248,\"start\":27245},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":28051,\"start\":28047},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":28054,\"start\":28051},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":28057,\"start\":28054},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":28060,\"start\":28057},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":28662,\"start\":28658},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":28665,\"start\":28662},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":28668,\"start\":28665},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":29348,\"start\":29344},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":29788,\"start\":29785},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":29969,\"start\":29965},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":29972,\"start\":29969},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":30380,\"start\":30376},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":31223,\"start\":31219},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":31321,\"start\":31317},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":31498,\"start\":31494},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":35583,\"start\":35579},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":36066,\"start\":36062},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":36069,\"start\":36066},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":36126,\"start\":36122},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":38204,\"start\":38200},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":38441,\"start\":38437},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":38463,\"start\":38460},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":41249,\"start\":41248},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":42029,\"start\":42025},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":42166,\"start\":42162},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":45768,\"start\":45766},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":45770,\"start\":45768},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":45772,\"start\":45770},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":45773,\"start\":45772},{\"end\":45934,\"start\":45929},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":46286,\"start\":46282},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":46289,\"start\":46286},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":46292,\"start\":46289},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":46874,\"start\":46870},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":46877,\"start\":46874},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":46880,\"start\":46877},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":46883,\"start\":46880},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":46886,\"start\":46883},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":47399,\"start\":47395},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":47451,\"start\":47447},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":47523,\"start\":47519},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":47936,\"start\":47932},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":47999,\"start\":47995},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":48285,\"start\":48281},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":48303,\"start\":48299},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":48909,\"start\":48905},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":48912,\"start\":48909},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":48931,\"start\":48927},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":49129,\"start\":49125},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":49883,\"start\":49879},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":49886,\"start\":49883},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":49910,\"start\":49907},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":49913,\"start\":49910},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":49946,\"start\":49942},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":49949,\"start\":49946},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":50093,\"start\":50089},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":50126,\"start\":50122},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":50162,\"start\":50158},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":50182,\"start\":50178},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":50807,\"start\":50803},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":51207,\"start\":51203},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":53146,\"start\":53144}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":54340,\"start\":53583},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":56320,\"start\":54341},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":56814,\"start\":56321},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":56920,\"start\":56815},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":57015,\"start\":56921},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":57357,\"start\":57016}]", "paragraph": "[{\"end\":4510,\"start\":3730},{\"end\":4988,\"start\":4512},{\"end\":5872,\"start\":4990},{\"end\":6491,\"start\":5874},{\"end\":8100,\"start\":6493},{\"end\":9124,\"start\":8102},{\"end\":10015,\"start\":9126},{\"end\":11066,\"start\":10017},{\"end\":11575,\"start\":11101},{\"end\":12649,\"start\":11606},{\"end\":14827,\"start\":12694},{\"end\":15469,\"start\":14858},{\"end\":16743,\"start\":15471},{\"end\":17271,\"start\":16745},{\"end\":18057,\"start\":17297},{\"end\":18268,\"start\":18081},{\"end\":19609,\"start\":18270},{\"end\":20310,\"start\":19630},{\"end\":20850,\"start\":20333},{\"end\":21184,\"start\":20872},{\"end\":21440,\"start\":21216},{\"end\":22131,\"start\":21463},{\"end\":22343,\"start\":22153},{\"end\":22859,\"start\":22345},{\"end\":23464,\"start\":22886},{\"end\":23685,\"start\":23486},{\"end\":23831,\"start\":23687},{\"end\":23995,\"start\":23880},{\"end\":24950,\"start\":24018},{\"end\":25924,\"start\":24952},{\"end\":26434,\"start\":25932},{\"end\":27147,\"start\":26482},{\"end\":27600,\"start\":27149},{\"end\":27841,\"start\":27602},{\"end\":28187,\"start\":27865},{\"end\":28779,\"start\":28341},{\"end\":29010,\"start\":28807},{\"end\":29258,\"start\":29012},{\"end\":29883,\"start\":29293},{\"end\":30401,\"start\":29907},{\"end\":30911,\"start\":30429},{\"end\":31098,\"start\":30913},{\"end\":31449,\"start\":31137},{\"end\":31615,\"start\":31473},{\"end\":31998,\"start\":31643},{\"end\":32179,\"start\":32023},{\"end\":32646,\"start\":32262},{\"end\":33181,\"start\":32648},{\"end\":33443,\"start\":33183},{\"end\":34194,\"start\":33445},{\"end\":34593,\"start\":34196},{\"end\":34776,\"start\":34595},{\"end\":35058,\"start\":34778},{\"end\":36942,\"start\":35150},{\"end\":37359,\"start\":36944},{\"end\":38033,\"start\":37361},{\"end\":38920,\"start\":38066},{\"end\":39031,\"start\":38922},{\"end\":39250,\"start\":39033},{\"end\":39993,\"start\":39252},{\"end\":41749,\"start\":39995},{\"end\":41866,\"start\":41751},{\"end\":42425,\"start\":41868},{\"end\":43306,\"start\":42427},{\"end\":43811,\"start\":43308},{\"end\":44542,\"start\":43813},{\"end\":44690,\"start\":44544},{\"end\":45539,\"start\":44692},{\"end\":46466,\"start\":45563},{\"end\":46620,\"start\":46483},{\"end\":48807,\"start\":46668},{\"end\":49817,\"start\":48809},{\"end\":50163,\"start\":49849},{\"end\":50791,\"start\":50165},{\"end\":51190,\"start\":50793},{\"end\":51563,\"start\":51192},{\"end\":52166,\"start\":51594},{\"end\":53055,\"start\":52168},{\"end\":53435,\"start\":53057},{\"end\":53582,\"start\":53457}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":18080,\"start\":18058},{\"attributes\":{\"id\":\"formula_1\"},\"end\":28340,\"start\":28188}]", "table_ref": "[{\"end\":32155,\"start\":32148},{\"end\":32344,\"start\":32337},{\"end\":32680,\"start\":32671},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":33018,\"start\":33009},{\"end\":33607,\"start\":33600},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":34208,\"start\":34201},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":39649,\"start\":39642},{\"end\":41246,\"start\":41239},{\"end\":42846,\"start\":42839},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":43823,\"start\":43816}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":3728,\"start\":3716},{\"attributes\":{\"n\":\"2\"},\"end\":11099,\"start\":11069},{\"attributes\":{\"n\":\"2.1\"},\"end\":11604,\"start\":11578},{\"attributes\":{\"n\":\"2.2\"},\"end\":12692,\"start\":12652},{\"attributes\":{\"n\":\"2.3\"},\"end\":14856,\"start\":14830},{\"attributes\":{\"n\":\"2.4\"},\"end\":17295,\"start\":17274},{\"attributes\":{\"n\":\"3\"},\"end\":19628,\"start\":19612},{\"attributes\":{\"n\":\"3.1\"},\"end\":20331,\"start\":20313},{\"attributes\":{\"n\":\"3.1.1\"},\"end\":20870,\"start\":20853},{\"attributes\":{\"n\":\"3.1.2\"},\"end\":21214,\"start\":21187},{\"attributes\":{\"n\":\"3.2\"},\"end\":21461,\"start\":21443},{\"attributes\":{\"n\":\"3.2.1\"},\"end\":22151,\"start\":22134},{\"attributes\":{\"n\":\"3.3\"},\"end\":22884,\"start\":22862},{\"attributes\":{\"n\":\"3.3.1\"},\"end\":23484,\"start\":23467},{\"attributes\":{\"n\":\"4\"},\"end\":23878,\"start\":23834},{\"attributes\":{\"n\":\"4.1\"},\"end\":24016,\"start\":23998},{\"end\":25930,\"start\":25927},{\"attributes\":{\"n\":\"4.2\"},\"end\":26458,\"start\":26437},{\"attributes\":{\"n\":\"4.2.1\"},\"end\":26480,\"start\":26461},{\"end\":27863,\"start\":27844},{\"end\":28805,\"start\":28782},{\"attributes\":{\"n\":\"4.2.2\"},\"end\":29280,\"start\":29261},{\"end\":29291,\"start\":29283},{\"end\":29905,\"start\":29886},{\"end\":30427,\"start\":30404},{\"attributes\":{\"n\":\"4.2.3\"},\"end\":31124,\"start\":31101},{\"end\":31135,\"start\":31127},{\"end\":31471,\"start\":31452},{\"end\":31641,\"start\":31618},{\"attributes\":{\"n\":\"5\"},\"end\":32021,\"start\":32001},{\"end\":32260,\"start\":32182},{\"end\":35148,\"start\":35061},{\"attributes\":{\"n\":\"6\"},\"end\":38046,\"start\":38036},{\"attributes\":{\"n\":\"6.1\"},\"end\":38064,\"start\":38049},{\"attributes\":{\"n\":\"6.2\"},\"end\":45561,\"start\":45542},{\"attributes\":{\"n\":\"7\"},\"end\":46481,\"start\":46469},{\"attributes\":{\"n\":\"7.1\"},\"end\":46666,\"start\":46623},{\"attributes\":{\"n\":\"7.2\"},\"end\":49847,\"start\":49820},{\"attributes\":{\"n\":\"8\"},\"end\":51592,\"start\":51566},{\"attributes\":{\"n\":\"9\"},\"end\":53455,\"start\":53438},{\"end\":53585,\"start\":53584},{\"end\":56331,\"start\":56322},{\"end\":56825,\"start\":56816},{\"end\":56931,\"start\":56922}]", "table": "[{\"end\":56320,\"start\":54400},{\"end\":56814,\"start\":56382},{\"end\":57357,\"start\":57192}]", "figure_caption": "[{\"end\":54340,\"start\":53586},{\"end\":54400,\"start\":54343},{\"end\":56382,\"start\":56333},{\"end\":56920,\"start\":56827},{\"end\":57015,\"start\":56933},{\"end\":57192,\"start\":57018}]", "figure_ref": "[{\"end\":44713,\"start\":44705}]", "bib_author_first_name": "[{\"end\":57898,\"start\":57896},{\"end\":57922,\"start\":57914},{\"end\":57937,\"start\":57936},{\"end\":57953,\"start\":57948},{\"end\":57955,\"start\":57954},{\"end\":58366,\"start\":58364},{\"end\":58383,\"start\":58376},{\"end\":58385,\"start\":58384},{\"end\":58399,\"start\":58394},{\"end\":58683,\"start\":58675},{\"end\":58700,\"start\":58691},{\"end\":58720,\"start\":58708},{\"end\":58737,\"start\":58731},{\"end\":59162,\"start\":59157},{\"end\":59173,\"start\":59168},{\"end\":59184,\"start\":59180},{\"end\":59195,\"start\":59192},{\"end\":59210,\"start\":59201},{\"end\":59222,\"start\":59217},{\"end\":60179,\"start\":60173},{\"end\":60191,\"start\":60186},{\"end\":60201,\"start\":60197},{\"end\":60209,\"start\":60208},{\"end\":60226,\"start\":60220},{\"end\":60233,\"start\":60229},{\"end\":60247,\"start\":60242},{\"end\":60249,\"start\":60248},{\"end\":60263,\"start\":60259},{\"end\":61033,\"start\":61028},{\"end\":61050,\"start\":61042},{\"end\":61064,\"start\":61058},{\"end\":61078,\"start\":61070},{\"end\":62138,\"start\":62130},{\"end\":62149,\"start\":62145},{\"end\":62159,\"start\":62155},{\"end\":62169,\"start\":62166},{\"end\":62185,\"start\":62176},{\"end\":62196,\"start\":62192},{\"end\":62209,\"start\":62203},{\"end\":62220,\"start\":62216},{\"end\":62230,\"start\":62226},{\"end\":62241,\"start\":62236},{\"end\":62253,\"start\":62249},{\"end\":63006,\"start\":62998},{\"end\":63017,\"start\":63011},{\"end\":63026,\"start\":63025},{\"end\":63041,\"start\":63034},{\"end\":63501,\"start\":63497},{\"end\":63512,\"start\":63507},{\"end\":63531,\"start\":63523},{\"end\":63540,\"start\":63536},{\"end\":63553,\"start\":63547},{\"end\":63564,\"start\":63560},{\"end\":63573,\"start\":63570},{\"end\":63586,\"start\":63580},{\"end\":63600,\"start\":63593},{\"end\":63622,\"start\":63615},{\"end\":63640,\"start\":63635},{\"end\":63642,\"start\":63641},{\"end\":63662,\"start\":63658},{\"end\":63676,\"start\":63672},{\"end\":63688,\"start\":63684},{\"end\":63706,\"start\":63701},{\"end\":63716,\"start\":63712},{\"end\":64306,\"start\":64303},{\"end\":64332,\"start\":64326},{\"end\":64348,\"start\":64344},{\"end\":64364,\"start\":64362},{\"end\":64373,\"start\":64369},{\"end\":64389,\"start\":64383},{\"end\":64823,\"start\":64818},{\"end\":64833,\"start\":64828},{\"end\":64842,\"start\":64838},{\"end\":64857,\"start\":64849},{\"end\":64871,\"start\":64863},{\"end\":64883,\"start\":64878},{\"end\":65214,\"start\":65210},{\"end\":65233,\"start\":65227},{\"end\":65463,\"start\":65459},{\"end\":65474,\"start\":65471},{\"end\":65489,\"start\":65480},{\"end\":65497,\"start\":65496},{\"end\":65507,\"start\":65502},{\"end\":65920,\"start\":65916},{\"end\":65931,\"start\":65928},{\"end\":65946,\"start\":65937},{\"end\":65958,\"start\":65953},{\"end\":65968,\"start\":65963},{\"end\":66751,\"start\":66746},{\"end\":66769,\"start\":66760},{\"end\":66781,\"start\":66774},{\"end\":66798,\"start\":66789},{\"end\":66814,\"start\":66810},{\"end\":67135,\"start\":67130},{\"end\":67146,\"start\":67142},{\"end\":67160,\"start\":67153},{\"end\":67174,\"start\":67168},{\"end\":67189,\"start\":67183},{\"end\":67203,\"start\":67200},{\"end\":68143,\"start\":68134},{\"end\":68155,\"start\":68149},{\"end\":68171,\"start\":68162},{\"end\":68186,\"start\":68181},{\"end\":68201,\"start\":68195},{\"end\":68214,\"start\":68210},{\"end\":68679,\"start\":68675},{\"end\":68693,\"start\":68687},{\"end\":68710,\"start\":68702},{\"end\":68968,\"start\":68965},{\"end\":68977,\"start\":68973},{\"end\":68986,\"start\":68982},{\"end\":68995,\"start\":68992},{\"end\":69402,\"start\":69395},{\"end\":69413,\"start\":69408},{\"end\":69426,\"start\":69419},{\"end\":69437,\"start\":69433},{\"end\":69449,\"start\":69445},{\"end\":69985,\"start\":69979},{\"end\":69995,\"start\":69991},{\"end\":70006,\"start\":70001},{\"end\":70021,\"start\":70014},{\"end\":70032,\"start\":70026},{\"end\":70045,\"start\":70040},{\"end\":70056,\"start\":70052},{\"end\":70067,\"start\":70063},{\"end\":70079,\"start\":70075},{\"end\":70100,\"start\":70093},{\"end\":70496,\"start\":70491},{\"end\":70505,\"start\":70501},{\"end\":70515,\"start\":70511},{\"end\":70527,\"start\":70521},{\"end\":70541,\"start\":70535},{\"end\":70564,\"start\":70556},{\"end\":70578,\"start\":70573},{\"end\":70592,\"start\":70588},{\"end\":70605,\"start\":70600},{\"end\":70617,\"start\":70613},{\"end\":71011,\"start\":71005},{\"end\":71022,\"start\":71017},{\"end\":71033,\"start\":71027},{\"end\":71042,\"start\":71039},{\"end\":71056,\"start\":71049},{\"end\":71441,\"start\":71434},{\"end\":71443,\"start\":71442},{\"end\":71456,\"start\":71452},{\"end\":71471,\"start\":71466},{\"end\":71483,\"start\":71479},{\"end\":71504,\"start\":71493},{\"end\":71518,\"start\":71512},{\"end\":71528,\"start\":71524},{\"end\":72573,\"start\":72569},{\"end\":72592,\"start\":72586},{\"end\":72607,\"start\":72600},{\"end\":72626,\"start\":72619},{\"end\":72639,\"start\":72634},{\"end\":73211,\"start\":73207},{\"end\":73219,\"start\":73216},{\"end\":73233,\"start\":73226},{\"end\":73240,\"start\":73239},{\"end\":73246,\"start\":73241},{\"end\":73262,\"start\":73254},{\"end\":73275,\"start\":73270},{\"end\":74192,\"start\":74188},{\"end\":74209,\"start\":74202},{\"end\":74219,\"start\":74214},{\"end\":74232,\"start\":74227},{\"end\":74244,\"start\":74239},{\"end\":74257,\"start\":74253},{\"end\":74557,\"start\":74550},{\"end\":74572,\"start\":74563},{\"end\":74582,\"start\":74579},{\"end\":74596,\"start\":74588},{\"end\":74609,\"start\":74601},{\"end\":75048,\"start\":75040},{\"end\":75063,\"start\":75056},{\"end\":75066,\"start\":75064},{\"end\":75080,\"start\":75074},{\"end\":75086,\"start\":75081},{\"end\":75099,\"start\":75095},{\"end\":75116,\"start\":75110},{\"end\":75119,\"start\":75117},{\"end\":75529,\"start\":75523},{\"end\":75544,\"start\":75536},{\"end\":75558,\"start\":75552},{\"end\":75575,\"start\":75569},{\"end\":75869,\"start\":75865},{\"end\":75881,\"start\":75880},{\"end\":76098,\"start\":76090},{\"end\":76113,\"start\":76108},{\"end\":76123,\"start\":76118},{\"end\":76134,\"start\":76128},{\"end\":76152,\"start\":76144},{\"end\":76569,\"start\":76566},{\"end\":76580,\"start\":76575},{\"end\":76594,\"start\":76588},{\"end\":77608,\"start\":77602},{\"end\":77626,\"start\":77619},{\"end\":77639,\"start\":77636},{\"end\":77648,\"start\":77644},{\"end\":78268,\"start\":78263},{\"end\":78280,\"start\":78275},{\"end\":78294,\"start\":78288},{\"end\":78310,\"start\":78304},{\"end\":78327,\"start\":78324},{\"end\":78338,\"start\":78332},{\"end\":79410,\"start\":79403},{\"end\":79423,\"start\":79419},{\"end\":79440,\"start\":79432},{\"end\":79461,\"start\":79449},{\"end\":79464,\"start\":79462},{\"end\":79478,\"start\":79472},{\"end\":79491,\"start\":79486},{\"end\":79886,\"start\":79880},{\"end\":79900,\"start\":79896},{\"end\":79914,\"start\":79910},{\"end\":79928,\"start\":79923},{\"end\":79945,\"start\":79940},{\"end\":79958,\"start\":79953},{\"end\":79960,\"start\":79959},{\"end\":79974,\"start\":79968},{\"end\":79988,\"start\":79983},{\"end\":80916,\"start\":80910},{\"end\":80941,\"start\":80932},{\"end\":80959,\"start\":80952},{\"end\":81424,\"start\":81421},{\"end\":81437,\"start\":81431},{\"end\":81445,\"start\":81444},{\"end\":81460,\"start\":81454},{\"end\":81464,\"start\":81461},{\"end\":82501,\"start\":82495},{\"end\":82511,\"start\":82507},{\"end\":83196,\"start\":83191},{\"end\":83206,\"start\":83202},{\"end\":83230,\"start\":83224},{\"end\":83248,\"start\":83244},{\"end\":83571,\"start\":83568},{\"end\":83585,\"start\":83577},{\"end\":83592,\"start\":83591},{\"end\":83604,\"start\":83597},{\"end\":83621,\"start\":83620},{\"end\":83639,\"start\":83630},{\"end\":83943,\"start\":83938},{\"end\":83953,\"start\":83948},{\"end\":83969,\"start\":83961},{\"end\":83986,\"start\":83978},{\"end\":83996,\"start\":83993},{\"end\":84007,\"start\":84002},{\"end\":84401,\"start\":84396},{\"end\":84414,\"start\":84406},{\"end\":84429,\"start\":84424},{\"end\":84442,\"start\":84434},{\"end\":85337,\"start\":85332},{\"end\":85351,\"start\":85342},{\"end\":85361,\"start\":85358},{\"end\":85372,\"start\":85367},{\"end\":85800,\"start\":85792},{\"end\":85812,\"start\":85807},{\"end\":85823,\"start\":85817},{\"end\":85841,\"start\":85837},{\"end\":85857,\"start\":85849},{\"end\":85867,\"start\":85863},{\"end\":85879,\"start\":85874},{\"end\":86405,\"start\":86401},{\"end\":86418,\"start\":86413},{\"end\":86430,\"start\":86423},{\"end\":86442,\"start\":86438},{\"end\":86458,\"start\":86453},{\"end\":86476,\"start\":86468},{\"end\":86975,\"start\":86969},{\"end\":86985,\"start\":86982},{\"end\":86995,\"start\":86991},{\"end\":87008,\"start\":87001},{\"end\":87019,\"start\":87015},{\"end\":87021,\"start\":87020}]", "bib_author_last_name": "[{\"end\":57912,\"start\":57899},{\"end\":57934,\"start\":57923},{\"end\":57946,\"start\":57938},{\"end\":57959,\"start\":57956},{\"end\":57970,\"start\":57961},{\"end\":58374,\"start\":58367},{\"end\":58392,\"start\":58386},{\"end\":58405,\"start\":58400},{\"end\":58689,\"start\":58684},{\"end\":58706,\"start\":58701},{\"end\":58729,\"start\":58721},{\"end\":58745,\"start\":58738},{\"end\":59166,\"start\":59163},{\"end\":59178,\"start\":59174},{\"end\":59190,\"start\":59185},{\"end\":59199,\"start\":59196},{\"end\":59215,\"start\":59211},{\"end\":59225,\"start\":59223},{\"end\":60184,\"start\":60180},{\"end\":60195,\"start\":60192},{\"end\":60206,\"start\":60202},{\"end\":60218,\"start\":60210},{\"end\":60240,\"start\":60234},{\"end\":60257,\"start\":60250},{\"end\":60274,\"start\":60264},{\"end\":61040,\"start\":61034},{\"end\":61056,\"start\":61051},{\"end\":61068,\"start\":61065},{\"end\":61088,\"start\":61079},{\"end\":62143,\"start\":62139},{\"end\":62153,\"start\":62150},{\"end\":62164,\"start\":62160},{\"end\":62174,\"start\":62170},{\"end\":62190,\"start\":62186},{\"end\":62201,\"start\":62197},{\"end\":62214,\"start\":62210},{\"end\":62224,\"start\":62221},{\"end\":62234,\"start\":62231},{\"end\":62247,\"start\":62242},{\"end\":62258,\"start\":62254},{\"end\":63009,\"start\":63007},{\"end\":63023,\"start\":63018},{\"end\":63032,\"start\":63027},{\"end\":63045,\"start\":63042},{\"end\":63505,\"start\":63502},{\"end\":63521,\"start\":63513},{\"end\":63534,\"start\":63532},{\"end\":63545,\"start\":63541},{\"end\":63558,\"start\":63554},{\"end\":63568,\"start\":63565},{\"end\":63578,\"start\":63574},{\"end\":63591,\"start\":63587},{\"end\":63613,\"start\":63601},{\"end\":63625,\"start\":63623},{\"end\":63633,\"start\":63627},{\"end\":63656,\"start\":63643},{\"end\":63670,\"start\":63663},{\"end\":63682,\"start\":63677},{\"end\":63699,\"start\":63689},{\"end\":63710,\"start\":63707},{\"end\":63722,\"start\":63717},{\"end\":63728,\"start\":63724},{\"end\":64324,\"start\":64307},{\"end\":64342,\"start\":64333},{\"end\":64360,\"start\":64349},{\"end\":64367,\"start\":64365},{\"end\":64381,\"start\":64374},{\"end\":64396,\"start\":64390},{\"end\":64403,\"start\":64398},{\"end\":64826,\"start\":64824},{\"end\":64836,\"start\":64834},{\"end\":64847,\"start\":64843},{\"end\":64861,\"start\":64858},{\"end\":64876,\"start\":64872},{\"end\":64886,\"start\":64884},{\"end\":65225,\"start\":65215},{\"end\":65245,\"start\":65234},{\"end\":65469,\"start\":65464},{\"end\":65478,\"start\":65475},{\"end\":65494,\"start\":65490},{\"end\":65500,\"start\":65498},{\"end\":65512,\"start\":65508},{\"end\":65926,\"start\":65921},{\"end\":65935,\"start\":65932},{\"end\":65951,\"start\":65947},{\"end\":65961,\"start\":65959},{\"end\":65973,\"start\":65969},{\"end\":66758,\"start\":66752},{\"end\":66772,\"start\":66770},{\"end\":66787,\"start\":66782},{\"end\":66808,\"start\":66799},{\"end\":66827,\"start\":66815},{\"end\":67140,\"start\":67136},{\"end\":67151,\"start\":67147},{\"end\":67166,\"start\":67161},{\"end\":67181,\"start\":67175},{\"end\":67198,\"start\":67190},{\"end\":67210,\"start\":67204},{\"end\":68147,\"start\":68144},{\"end\":68160,\"start\":68156},{\"end\":68179,\"start\":68172},{\"end\":68193,\"start\":68187},{\"end\":68208,\"start\":68202},{\"end\":68222,\"start\":68215},{\"end\":68685,\"start\":68680},{\"end\":68700,\"start\":68694},{\"end\":68717,\"start\":68711},{\"end\":68971,\"start\":68969},{\"end\":68980,\"start\":68978},{\"end\":68990,\"start\":68987},{\"end\":68999,\"start\":68996},{\"end\":69406,\"start\":69403},{\"end\":69417,\"start\":69414},{\"end\":69431,\"start\":69427},{\"end\":69443,\"start\":69438},{\"end\":69463,\"start\":69450},{\"end\":69989,\"start\":69986},{\"end\":69999,\"start\":69996},{\"end\":70012,\"start\":70007},{\"end\":70024,\"start\":70022},{\"end\":70038,\"start\":70033},{\"end\":70050,\"start\":70046},{\"end\":70061,\"start\":70057},{\"end\":70073,\"start\":70068},{\"end\":70091,\"start\":70080},{\"end\":70109,\"start\":70101},{\"end\":70499,\"start\":70497},{\"end\":70509,\"start\":70506},{\"end\":70519,\"start\":70516},{\"end\":70533,\"start\":70528},{\"end\":70554,\"start\":70542},{\"end\":70571,\"start\":70565},{\"end\":70586,\"start\":70579},{\"end\":70598,\"start\":70593},{\"end\":70611,\"start\":70606},{\"end\":70622,\"start\":70618},{\"end\":71015,\"start\":71012},{\"end\":71025,\"start\":71023},{\"end\":71037,\"start\":71034},{\"end\":71047,\"start\":71043},{\"end\":71061,\"start\":71057},{\"end\":71450,\"start\":71444},{\"end\":71464,\"start\":71457},{\"end\":71477,\"start\":71472},{\"end\":71491,\"start\":71484},{\"end\":71510,\"start\":71505},{\"end\":71522,\"start\":71519},{\"end\":71540,\"start\":71529},{\"end\":72584,\"start\":72574},{\"end\":72598,\"start\":72593},{\"end\":72617,\"start\":72608},{\"end\":72632,\"start\":72627},{\"end\":72649,\"start\":72640},{\"end\":73214,\"start\":73212},{\"end\":73224,\"start\":73220},{\"end\":73237,\"start\":73234},{\"end\":73252,\"start\":73247},{\"end\":73268,\"start\":73263},{\"end\":73281,\"start\":73276},{\"end\":74200,\"start\":74193},{\"end\":74212,\"start\":74210},{\"end\":74225,\"start\":74220},{\"end\":74237,\"start\":74233},{\"end\":74251,\"start\":74245},{\"end\":74267,\"start\":74258},{\"end\":74561,\"start\":74558},{\"end\":74577,\"start\":74573},{\"end\":74586,\"start\":74583},{\"end\":74599,\"start\":74597},{\"end\":74613,\"start\":74610},{\"end\":75054,\"start\":75049},{\"end\":75072,\"start\":75067},{\"end\":75093,\"start\":75087},{\"end\":75108,\"start\":75100},{\"end\":75126,\"start\":75120},{\"end\":75534,\"start\":75530},{\"end\":75550,\"start\":75545},{\"end\":75567,\"start\":75559},{\"end\":75580,\"start\":75576},{\"end\":75878,\"start\":75870},{\"end\":75888,\"start\":75882},{\"end\":75897,\"start\":75890},{\"end\":76106,\"start\":76099},{\"end\":76116,\"start\":76114},{\"end\":76126,\"start\":76124},{\"end\":76142,\"start\":76135},{\"end\":76165,\"start\":76153},{\"end\":76573,\"start\":76570},{\"end\":76586,\"start\":76581},{\"end\":76598,\"start\":76595},{\"end\":77617,\"start\":77609},{\"end\":77634,\"start\":77627},{\"end\":77642,\"start\":77640},{\"end\":77655,\"start\":77649},{\"end\":78273,\"start\":78269},{\"end\":78286,\"start\":78281},{\"end\":78302,\"start\":78295},{\"end\":78322,\"start\":78311},{\"end\":78330,\"start\":78328},{\"end\":78345,\"start\":78339},{\"end\":79417,\"start\":79411},{\"end\":79430,\"start\":79424},{\"end\":79447,\"start\":79441},{\"end\":79470,\"start\":79465},{\"end\":79484,\"start\":79479},{\"end\":79502,\"start\":79492},{\"end\":79894,\"start\":79887},{\"end\":79908,\"start\":79901},{\"end\":79921,\"start\":79915},{\"end\":79938,\"start\":79929},{\"end\":79951,\"start\":79946},{\"end\":79966,\"start\":79961},{\"end\":79981,\"start\":79975},{\"end\":79999,\"start\":79989},{\"end\":80930,\"start\":80917},{\"end\":80950,\"start\":80942},{\"end\":80967,\"start\":80960},{\"end\":81429,\"start\":81425},{\"end\":81442,\"start\":81438},{\"end\":81452,\"start\":81446},{\"end\":81469,\"start\":81465},{\"end\":81474,\"start\":81471},{\"end\":82505,\"start\":82502},{\"end\":82514,\"start\":82512},{\"end\":83200,\"start\":83197},{\"end\":83222,\"start\":83207},{\"end\":83242,\"start\":83231},{\"end\":83254,\"start\":83249},{\"end\":83260,\"start\":83256},{\"end\":83575,\"start\":83572},{\"end\":83589,\"start\":83586},{\"end\":83595,\"start\":83593},{\"end\":83618,\"start\":83605},{\"end\":83628,\"start\":83622},{\"end\":83644,\"start\":83640},{\"end\":83946,\"start\":83944},{\"end\":83959,\"start\":83954},{\"end\":83976,\"start\":83970},{\"end\":83991,\"start\":83987},{\"end\":84000,\"start\":83997},{\"end\":84010,\"start\":84008},{\"end\":84404,\"start\":84402},{\"end\":84422,\"start\":84415},{\"end\":84432,\"start\":84430},{\"end\":84455,\"start\":84443},{\"end\":85340,\"start\":85338},{\"end\":85356,\"start\":85352},{\"end\":85365,\"start\":85362},{\"end\":85375,\"start\":85373},{\"end\":85805,\"start\":85801},{\"end\":85815,\"start\":85813},{\"end\":85835,\"start\":85824},{\"end\":85847,\"start\":85842},{\"end\":85861,\"start\":85858},{\"end\":85872,\"start\":85868},{\"end\":85882,\"start\":85880},{\"end\":86411,\"start\":86406},{\"end\":86421,\"start\":86419},{\"end\":86436,\"start\":86431},{\"end\":86451,\"start\":86443},{\"end\":86466,\"start\":86459},{\"end\":86479,\"start\":86477},{\"end\":86486,\"start\":86481},{\"end\":86980,\"start\":86976},{\"end\":86989,\"start\":86986},{\"end\":86999,\"start\":86996},{\"end\":87013,\"start\":87009},{\"end\":87028,\"start\":87022}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":4596370},\"end\":58319,\"start\":57848},{\"attributes\":{\"doi\":\"arXiv:2004.05150\",\"id\":\"b1\"},\"end\":58597,\"start\":58321},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":50774217},\"end\":59082,\"start\":58599},{\"attributes\":{\"doi\":\"10.1145/3338906.3341174\",\"id\":\"b3\",\"matched_paper_id\":199501891},\"end\":60117,\"start\":59084},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":600040},\"end\":60944,\"start\":60119},{\"attributes\":{\"doi\":\"10.18653/v1/n19-1423\",\"id\":\"b5\",\"matched_paper_id\":52967399},\"end\":62059,\"start\":60946},{\"attributes\":{\"doi\":\"10.18653/v1/2020.findings-emnlp.139\",\"id\":\"b6\",\"matched_paper_id\":211171605},\"end\":62977,\"start\":62061},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":11540100},\"end\":63430,\"start\":62979},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":221761146},\"end\":64301,\"start\":63432},{\"attributes\":{\"doi\":\"arXiv:2004.10964\",\"id\":\"b9\"},\"end\":64728,\"start\":64303},{\"attributes\":{\"doi\":\"10.48550/arXiv.2203.10965\",\"id\":\"b10\"},\"end\":65184,\"start\":64730},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":1915014},\"end\":65380,\"start\":65186},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":52069064},\"end\":65837,\"start\":65382},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":52069064},\"end\":66673,\"start\":65839},{\"attributes\":{\"id\":\"b14\"},\"end\":67086,\"start\":66675},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":220425360},\"end\":68054,\"start\":67088},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":202888986},\"end\":68658,\"start\":68056},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":1779661},\"end\":68832,\"start\":68660},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":224771123},\"end\":69306,\"start\":68834},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":231846746},\"end\":69920,\"start\":69308},{\"attributes\":{\"id\":\"b20\"},\"end\":70402,\"start\":69922},{\"attributes\":{\"id\":\"b21\"},\"end\":70926,\"start\":70404},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":232290475},\"end\":71390,\"start\":70928},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":3626819},\"end\":72514,\"start\":71392},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":12034478},\"end\":73131,\"start\":72516},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":153312701},\"end\":74133,\"start\":73133},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":160025533},\"end\":74458,\"start\":74135},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":210693220},\"end\":74966,\"start\":74460},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":221980289},\"end\":75442,\"start\":74968},{\"attributes\":{\"id\":\"b29\"},\"end\":75822,\"start\":75444},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":18375389},\"end\":76088,\"start\":75824},{\"attributes\":{\"id\":\"b31\"},\"end\":76476,\"start\":76090},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":85459677},\"end\":77547,\"start\":76478},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":218487168},\"end\":78206,\"start\":77549},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":202122780},\"end\":79307,\"start\":78208},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":56517510},\"end\":79851,\"start\":79309},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":13756489},\"end\":80796,\"start\":79853},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":237485425},\"end\":81312,\"start\":80798},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":237386541},\"end\":82014,\"start\":81314},{\"attributes\":{\"id\":\"b39\"},\"end\":82362,\"start\":82016},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":23029303},\"end\":83137,\"start\":82364},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":247079554},\"end\":83523,\"start\":83139},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":36237266},\"end\":83864,\"start\":83525},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":237970588},\"end\":84331,\"start\":83866},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":52939211},\"end\":85244,\"start\":84333},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":10064728},\"end\":85704,\"start\":85246},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":246294988},\"end\":86307,\"start\":85706},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":226267095},\"end\":86860,\"start\":86309},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":67891926},\"end\":87344,\"start\":86862}]", "bib_title": "[{\"end\":57894,\"start\":57848},{\"end\":58673,\"start\":58599},{\"end\":59155,\"start\":59084},{\"end\":60171,\"start\":60119},{\"end\":61026,\"start\":60946},{\"end\":62128,\"start\":62061},{\"end\":62996,\"start\":62979},{\"end\":63495,\"start\":63432},{\"end\":65208,\"start\":65186},{\"end\":65457,\"start\":65382},{\"end\":65914,\"start\":65839},{\"end\":67128,\"start\":67088},{\"end\":68132,\"start\":68056},{\"end\":68673,\"start\":68660},{\"end\":68963,\"start\":68834},{\"end\":69393,\"start\":69308},{\"end\":71003,\"start\":70928},{\"end\":71432,\"start\":71392},{\"end\":72567,\"start\":72516},{\"end\":73205,\"start\":73133},{\"end\":74186,\"start\":74135},{\"end\":74548,\"start\":74460},{\"end\":75038,\"start\":74968},{\"end\":75863,\"start\":75824},{\"end\":76564,\"start\":76478},{\"end\":77600,\"start\":77549},{\"end\":78261,\"start\":78208},{\"end\":79401,\"start\":79309},{\"end\":79878,\"start\":79853},{\"end\":80908,\"start\":80798},{\"end\":81419,\"start\":81314},{\"end\":82493,\"start\":82364},{\"end\":83189,\"start\":83139},{\"end\":83566,\"start\":83525},{\"end\":83936,\"start\":83866},{\"end\":84394,\"start\":84333},{\"end\":85330,\"start\":85246},{\"end\":85790,\"start\":85706},{\"end\":86399,\"start\":86309},{\"end\":86967,\"start\":86862}]", "bib_author": "[{\"end\":57914,\"start\":57896},{\"end\":57936,\"start\":57914},{\"end\":57948,\"start\":57936},{\"end\":57961,\"start\":57948},{\"end\":57972,\"start\":57961},{\"end\":58376,\"start\":58364},{\"end\":58394,\"start\":58376},{\"end\":58407,\"start\":58394},{\"end\":58691,\"start\":58675},{\"end\":58708,\"start\":58691},{\"end\":58731,\"start\":58708},{\"end\":58747,\"start\":58731},{\"end\":59168,\"start\":59157},{\"end\":59180,\"start\":59168},{\"end\":59192,\"start\":59180},{\"end\":59201,\"start\":59192},{\"end\":59217,\"start\":59201},{\"end\":59227,\"start\":59217},{\"end\":60186,\"start\":60173},{\"end\":60197,\"start\":60186},{\"end\":60208,\"start\":60197},{\"end\":60220,\"start\":60208},{\"end\":60229,\"start\":60220},{\"end\":60242,\"start\":60229},{\"end\":60259,\"start\":60242},{\"end\":60276,\"start\":60259},{\"end\":61042,\"start\":61028},{\"end\":61058,\"start\":61042},{\"end\":61070,\"start\":61058},{\"end\":61090,\"start\":61070},{\"end\":62145,\"start\":62130},{\"end\":62155,\"start\":62145},{\"end\":62166,\"start\":62155},{\"end\":62176,\"start\":62166},{\"end\":62192,\"start\":62176},{\"end\":62203,\"start\":62192},{\"end\":62216,\"start\":62203},{\"end\":62226,\"start\":62216},{\"end\":62236,\"start\":62226},{\"end\":62249,\"start\":62236},{\"end\":62260,\"start\":62249},{\"end\":63011,\"start\":62998},{\"end\":63025,\"start\":63011},{\"end\":63034,\"start\":63025},{\"end\":63047,\"start\":63034},{\"end\":63507,\"start\":63497},{\"end\":63523,\"start\":63507},{\"end\":63536,\"start\":63523},{\"end\":63547,\"start\":63536},{\"end\":63560,\"start\":63547},{\"end\":63570,\"start\":63560},{\"end\":63580,\"start\":63570},{\"end\":63593,\"start\":63580},{\"end\":63615,\"start\":63593},{\"end\":63627,\"start\":63615},{\"end\":63635,\"start\":63627},{\"end\":63658,\"start\":63635},{\"end\":63672,\"start\":63658},{\"end\":63684,\"start\":63672},{\"end\":63701,\"start\":63684},{\"end\":63712,\"start\":63701},{\"end\":63724,\"start\":63712},{\"end\":63730,\"start\":63724},{\"end\":64326,\"start\":64303},{\"end\":64344,\"start\":64326},{\"end\":64362,\"start\":64344},{\"end\":64369,\"start\":64362},{\"end\":64383,\"start\":64369},{\"end\":64398,\"start\":64383},{\"end\":64405,\"start\":64398},{\"end\":64828,\"start\":64818},{\"end\":64838,\"start\":64828},{\"end\":64849,\"start\":64838},{\"end\":64863,\"start\":64849},{\"end\":64878,\"start\":64863},{\"end\":64888,\"start\":64878},{\"end\":65227,\"start\":65210},{\"end\":65247,\"start\":65227},{\"end\":65471,\"start\":65459},{\"end\":65480,\"start\":65471},{\"end\":65496,\"start\":65480},{\"end\":65502,\"start\":65496},{\"end\":65514,\"start\":65502},{\"end\":65928,\"start\":65916},{\"end\":65937,\"start\":65928},{\"end\":65953,\"start\":65937},{\"end\":65963,\"start\":65953},{\"end\":65975,\"start\":65963},{\"end\":66760,\"start\":66746},{\"end\":66774,\"start\":66760},{\"end\":66789,\"start\":66774},{\"end\":66810,\"start\":66789},{\"end\":66829,\"start\":66810},{\"end\":67142,\"start\":67130},{\"end\":67153,\"start\":67142},{\"end\":67168,\"start\":67153},{\"end\":67183,\"start\":67168},{\"end\":67200,\"start\":67183},{\"end\":67212,\"start\":67200},{\"end\":68149,\"start\":68134},{\"end\":68162,\"start\":68149},{\"end\":68181,\"start\":68162},{\"end\":68195,\"start\":68181},{\"end\":68210,\"start\":68195},{\"end\":68224,\"start\":68210},{\"end\":68687,\"start\":68675},{\"end\":68702,\"start\":68687},{\"end\":68719,\"start\":68702},{\"end\":68973,\"start\":68965},{\"end\":68982,\"start\":68973},{\"end\":68992,\"start\":68982},{\"end\":69001,\"start\":68992},{\"end\":69408,\"start\":69395},{\"end\":69419,\"start\":69408},{\"end\":69433,\"start\":69419},{\"end\":69445,\"start\":69433},{\"end\":69465,\"start\":69445},{\"end\":69991,\"start\":69979},{\"end\":70001,\"start\":69991},{\"end\":70014,\"start\":70001},{\"end\":70026,\"start\":70014},{\"end\":70040,\"start\":70026},{\"end\":70052,\"start\":70040},{\"end\":70063,\"start\":70052},{\"end\":70075,\"start\":70063},{\"end\":70093,\"start\":70075},{\"end\":70111,\"start\":70093},{\"end\":70501,\"start\":70491},{\"end\":70511,\"start\":70501},{\"end\":70521,\"start\":70511},{\"end\":70535,\"start\":70521},{\"end\":70556,\"start\":70535},{\"end\":70573,\"start\":70556},{\"end\":70588,\"start\":70573},{\"end\":70600,\"start\":70588},{\"end\":70613,\"start\":70600},{\"end\":70624,\"start\":70613},{\"end\":71017,\"start\":71005},{\"end\":71027,\"start\":71017},{\"end\":71039,\"start\":71027},{\"end\":71049,\"start\":71039},{\"end\":71063,\"start\":71049},{\"end\":71452,\"start\":71434},{\"end\":71466,\"start\":71452},{\"end\":71479,\"start\":71466},{\"end\":71493,\"start\":71479},{\"end\":71512,\"start\":71493},{\"end\":71524,\"start\":71512},{\"end\":71542,\"start\":71524},{\"end\":72586,\"start\":72569},{\"end\":72600,\"start\":72586},{\"end\":72619,\"start\":72600},{\"end\":72634,\"start\":72619},{\"end\":72651,\"start\":72634},{\"end\":73216,\"start\":73207},{\"end\":73226,\"start\":73216},{\"end\":73239,\"start\":73226},{\"end\":73254,\"start\":73239},{\"end\":73270,\"start\":73254},{\"end\":73283,\"start\":73270},{\"end\":74202,\"start\":74188},{\"end\":74214,\"start\":74202},{\"end\":74227,\"start\":74214},{\"end\":74239,\"start\":74227},{\"end\":74253,\"start\":74239},{\"end\":74269,\"start\":74253},{\"end\":74563,\"start\":74550},{\"end\":74579,\"start\":74563},{\"end\":74588,\"start\":74579},{\"end\":74601,\"start\":74588},{\"end\":74615,\"start\":74601},{\"end\":75056,\"start\":75040},{\"end\":75074,\"start\":75056},{\"end\":75095,\"start\":75074},{\"end\":75110,\"start\":75095},{\"end\":75128,\"start\":75110},{\"end\":75536,\"start\":75523},{\"end\":75552,\"start\":75536},{\"end\":75569,\"start\":75552},{\"end\":75582,\"start\":75569},{\"end\":75880,\"start\":75865},{\"end\":75890,\"start\":75880},{\"end\":75899,\"start\":75890},{\"end\":76108,\"start\":76090},{\"end\":76118,\"start\":76108},{\"end\":76128,\"start\":76118},{\"end\":76144,\"start\":76128},{\"end\":76167,\"start\":76144},{\"end\":76575,\"start\":76566},{\"end\":76588,\"start\":76575},{\"end\":76600,\"start\":76588},{\"end\":77619,\"start\":77602},{\"end\":77636,\"start\":77619},{\"end\":77644,\"start\":77636},{\"end\":77657,\"start\":77644},{\"end\":78275,\"start\":78263},{\"end\":78288,\"start\":78275},{\"end\":78304,\"start\":78288},{\"end\":78324,\"start\":78304},{\"end\":78332,\"start\":78324},{\"end\":78347,\"start\":78332},{\"end\":79419,\"start\":79403},{\"end\":79432,\"start\":79419},{\"end\":79449,\"start\":79432},{\"end\":79472,\"start\":79449},{\"end\":79486,\"start\":79472},{\"end\":79504,\"start\":79486},{\"end\":79896,\"start\":79880},{\"end\":79910,\"start\":79896},{\"end\":79923,\"start\":79910},{\"end\":79940,\"start\":79923},{\"end\":79953,\"start\":79940},{\"end\":79968,\"start\":79953},{\"end\":79983,\"start\":79968},{\"end\":80001,\"start\":79983},{\"end\":80932,\"start\":80910},{\"end\":80952,\"start\":80932},{\"end\":80969,\"start\":80952},{\"end\":81431,\"start\":81421},{\"end\":81444,\"start\":81431},{\"end\":81454,\"start\":81444},{\"end\":81471,\"start\":81454},{\"end\":81476,\"start\":81471},{\"end\":82507,\"start\":82495},{\"end\":82516,\"start\":82507},{\"end\":83202,\"start\":83191},{\"end\":83224,\"start\":83202},{\"end\":83244,\"start\":83224},{\"end\":83256,\"start\":83244},{\"end\":83262,\"start\":83256},{\"end\":83577,\"start\":83568},{\"end\":83591,\"start\":83577},{\"end\":83597,\"start\":83591},{\"end\":83620,\"start\":83597},{\"end\":83630,\"start\":83620},{\"end\":83646,\"start\":83630},{\"end\":83948,\"start\":83938},{\"end\":83961,\"start\":83948},{\"end\":83978,\"start\":83961},{\"end\":83993,\"start\":83978},{\"end\":84002,\"start\":83993},{\"end\":84012,\"start\":84002},{\"end\":84406,\"start\":84396},{\"end\":84424,\"start\":84406},{\"end\":84434,\"start\":84424},{\"end\":84457,\"start\":84434},{\"end\":85342,\"start\":85332},{\"end\":85358,\"start\":85342},{\"end\":85367,\"start\":85358},{\"end\":85377,\"start\":85367},{\"end\":85807,\"start\":85792},{\"end\":85817,\"start\":85807},{\"end\":85837,\"start\":85817},{\"end\":85849,\"start\":85837},{\"end\":85863,\"start\":85849},{\"end\":85874,\"start\":85863},{\"end\":85884,\"start\":85874},{\"end\":86413,\"start\":86401},{\"end\":86423,\"start\":86413},{\"end\":86438,\"start\":86423},{\"end\":86453,\"start\":86438},{\"end\":86468,\"start\":86453},{\"end\":86481,\"start\":86468},{\"end\":86488,\"start\":86481},{\"end\":86982,\"start\":86969},{\"end\":86991,\"start\":86982},{\"end\":87001,\"start\":86991},{\"end\":87015,\"start\":87001},{\"end\":87030,\"start\":87015}]", "bib_venue": "[{\"end\":59633,\"start\":59472},{\"end\":60452,\"start\":60445},{\"end\":61481,\"start\":61318},{\"end\":63240,\"start\":63152},{\"end\":63821,\"start\":63814},{\"end\":66260,\"start\":66155},{\"end\":67493,\"start\":67404},{\"end\":68303,\"start\":68282},{\"end\":69581,\"start\":69568},{\"end\":71936,\"start\":71766},{\"end\":72766,\"start\":72746},{\"end\":73648,\"start\":73527},{\"end\":76991,\"start\":76828},{\"end\":77847,\"start\":77775},{\"end\":78743,\"start\":78582},{\"end\":80242,\"start\":80207},{\"end\":81653,\"start\":81564},{\"end\":82737,\"start\":82643},{\"end\":84769,\"start\":84654},{\"end\":58064,\"start\":57972},{\"end\":58362,\"start\":58321},{\"end\":58822,\"start\":58747},{\"end\":59410,\"start\":59250},{\"end\":60388,\"start\":60276},{\"end\":61268,\"start\":61110},{\"end\":62378,\"start\":62295},{\"end\":63150,\"start\":63047},{\"end\":63812,\"start\":63730},{\"end\":64493,\"start\":64421},{\"end\":64816,\"start\":64730},{\"end\":65265,\"start\":65247},{\"end\":65592,\"start\":65514},{\"end\":66099,\"start\":65998},{\"end\":66744,\"start\":66675},{\"end\":67329,\"start\":67243},{\"end\":68280,\"start\":68224},{\"end\":68725,\"start\":68719},{\"end\":69040,\"start\":69026},{\"end\":69566,\"start\":69493},{\"end\":69977,\"start\":69922},{\"end\":70489,\"start\":70404},{\"end\":71146,\"start\":71063},{\"end\":71720,\"start\":71562},{\"end\":72744,\"start\":72672},{\"end\":73429,\"start\":73306},{\"end\":74280,\"start\":74269},{\"end\":74693,\"start\":74615},{\"end\":75175,\"start\":75156},{\"end\":75521,\"start\":75444},{\"end\":75937,\"start\":75899},{\"end\":76272,\"start\":76187},{\"end\":76778,\"start\":76620},{\"end\":77773,\"start\":77686},{\"end\":78527,\"start\":78367},{\"end\":79550,\"start\":79519},{\"end\":80113,\"start\":80001},{\"end\":81034,\"start\":80993},{\"end\":81562,\"start\":81476},{\"end\":82088,\"start\":82047},{\"end\":82628,\"start\":82539},{\"end\":83321,\"start\":83262},{\"end\":83676,\"start\":83646},{\"end\":84077,\"start\":84036},{\"end\":84597,\"start\":84480},{\"end\":85455,\"start\":85377},{\"end\":85976,\"start\":85884},{\"end\":86568,\"start\":86488},{\"end\":87077,\"start\":87058}]"}}}, "year": 2023, "month": 12, "day": 17}