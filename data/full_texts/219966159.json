{"id": 219966159, "updated": "2023-10-06 14:28:47.856", "metadata": {"title": "Predicting Temporal Sets with Deep Neural Networks", "authors": "[{\"first\":\"Le\",\"last\":\"Yu\",\"middle\":[]},{\"first\":\"Leilei\",\"last\":\"Sun\",\"middle\":[]},{\"first\":\"Bowen\",\"last\":\"Du\",\"middle\":[]},{\"first\":\"Chuanren\",\"last\":\"Liu\",\"middle\":[]},{\"first\":\"Hui\",\"last\":\"Xiong\",\"middle\":[]},{\"first\":\"Weifeng\",\"last\":\"Lv\",\"middle\":[]}]", "venue": null, "journal": "Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining", "publication_date": {"year": 2020, "month": 6, "day": 20}, "abstract": "Given a sequence of sets, where each set contains an arbitrary number of elements, the problem of temporal sets prediction aims to predict the elements in the subsequent set. In practice, temporal sets prediction is much more complex than predictive modelling of temporal events and time series, and is still an open problem. Many possible existing methods, if adapted for the problem of temporal sets prediction, usually follow a two-step strategy by first projecting temporal sets into latent representations and then learning a predictive model with the latent representations. The two-step approach often leads to information loss and unsatisfactory prediction performance. In this paper, we propose an integrated solution based on the deep neural networks for temporal sets prediction. A unique perspective of our approach is to learn element relationship by constructing set-level co-occurrence graph and then perform graph convolutions on the dynamic relationship graphs. Moreover, we design an attention-based module to adaptively learn the temporal dependency of elements and sets. Finally, we provide a gated updating mechanism to find the hidden shared patterns in different sequences and fuse both static and dynamic information to improve the prediction performance. Experiments on real-world data sets demonstrate that our approach can achieve competitive performances even with a portion of the training data and can outperform existing methods with a significant margin.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2006.11483", "mag": "3106400975", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/kdd/YuSDL0L20", "doi": "10.1145/3394486.3403152"}}, "content": {"source": {"pdf_hash": "4011b0ffd53283576ba72583810c6b450734dbf1", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2006.11483v4.pdf\"]", "oa_url_match": true, "oa_info": {"license": null, "open_access_url": "http://arxiv.org/pdf/2006.11483", "status": "GREEN"}}, "grobid": {"id": "00587b4fec8674d27bca5fa10b0fc1161591fbef", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/4011b0ffd53283576ba72583810c6b450734dbf1.txt", "contents": "\nPredicting Temporal Sets with Deep Neural Networks\nVirtual EventCopyright Virtual Event2020. August 23-27, 2020. August 23-27, 2020\n\nLe Yu \nSKLSDE and BDBC Lab\nBeihang University\n100083BeijingChina\n\nLeilei Sun \nSKLSDE and BDBC Lab\nBeihang University\n100083BeijingChina\n\nBowen Du \nSKLSDE and BDBC Lab\nBeihang University\n100083BeijingChina\n\nChuanren Liu \nDepartment of Business Analytics and Statistics\nUniversity of Tennessee\nKnoxvilleUSA\n\nHui Xiong 3hxiong@rutgers.edu \nDepartment of Management Science and Information Systems\nACM Reference Format\nRutgers University\nUSA\n\nWeifeng Lv \nSKLSDE and BDBC Lab\nBeihang University\n100083BeijingChina\n\nLe Yu \nSKLSDE and BDBC Lab\nBeihang University\n100083BeijingChina\n\nLeilei Sun \nSKLSDE and BDBC Lab\nBeihang University\n100083BeijingChina\n\nBowen Du \nSKLSDE and BDBC Lab\nBeihang University\n100083BeijingChina\n\nChuanren Liu \nDepartment of Business Analytics and Statistics\nUniversity of Tennessee\nKnoxvilleUSA\n\nHui Xiong \nDepartment of Management Science and Information Systems\nACM Reference Format\nRutgers University\nUSA\n\nWeifeng Lv \nSKLSDE and BDBC Lab\nBeihang University\n100083BeijingChina\n\nPredicting Temporal Sets with Deep Neural Networks\n\nProceedings of the 26th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD '20)\nthe 26th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD '20)Virtual Event, CA, USA KDD '20; CA, USAVirtual Event2020. August 23-27, 2020. August 23-27, 202010.1145/3394486.3403152. ACM, New York, NY, USA, 9 pages. https://doi.org/10.1145/3394486.3403152 * Corresponding author. ACM ISBN 978-1-4503-7998-4/20/08. . . $15.00Temporal SetsTemporal DataGraph ConvolutionsSequence Learning\nGiven a sequence of sets, where each set contains an arbitrary number of elements, the problem of temporal sets prediction aims to predict the elements in the subsequent set. In practice, temporal sets prediction is much more complex than predictive modelling of temporal events and time series, and is still an open problem. Many possible existing methods, if adapted for the problem of temporal sets prediction, usually follow a two-step strategy by first projecting temporal sets into latent representations and then learning a predictive model with the latent representations. The two-step approach often leads to information loss and unsatisfactory prediction performance. In this paper, we propose an integrated solution based on the deep neural networks for temporal sets prediction. A unique perspective of our approach is to learn element relationship by constructing set-level co-occurrence graph and then perform graph convolutions on the dynamic relationship graphs. Moreover, we design an attention-based module to adaptively learn the temporal dependency of elements and sets. Finally, we provide a gated updating mechanism to find the hidden shared patterns in different sequences and fuse both static and dynamic information to improve the prediction performance. Experiments on real-world data sets demonstrate that our approach can achieve competitive performances even with a portion of the training data and can outperform existing methods with a significant margin.CCS CONCEPTS\u2022 Information systems \u2192 Data mining.\n\nINTRODUCTION\n\nTemporal data record the objects vary over time and the timeoriented nature of such data makes them valuable. Mining the underlying patterns and dynamics in temporal data could help people make better decisions or plans. For example, forecasting the speed of traffic flow provides better strategies for transportation departments [19]. Predicting the labor mobility contributes to human resource reallocation in labor markets [18]. Due to the importance of temporal data, a great number of temporal data mining methods have been proposed [7,16]. However, most of the existing methods were designed for time series [3,4] or temporal events [18,21]. This paper studies the prediction of a new type of temporal data, namely, temporal sets [2]. If time series could be seen as a sequence of numerical values recorded with timestamps, temporal events could be seen as a sequence of nominal events with timestamps, and then temporal sets are a sequence of sets with timestamps, where each set contains an arbitrary number of elements, see Figure 1. In fact, temporal sets are very pervasive in real-world scenarios. For example, a customer's purchase behaviors could be formalized as a sequence of sets, where each set includes a number of goods and corresponds to a purchase at a supermarket. Forecasting student's next-semester courses selection [24] and predicting patient's next-period prescriptions [12,23] also deal with this type of temporal data. It is no doubt that temporal sets prediction is of great importance. Take the above scenarios as instances, prediction of next-period basket could help stores dispatch products in advance, and predicting next-semester courses could help universities make better decisions about course setting. However, the existing temporal data prediction method designed for time series or temporal events could not be directly used for temporal sets because time series prediction method can not handle semantic relationships among elements, while temporal events prediction method cannot deal with multiple elements within a set.\n\nRecent literature has reported a few methods for temporal sets prediction [5,10,26]. These methods were designed under a twostage framework, which first projected each set into a latent vector and then predicted the subsequent set based on the sequences of embedded sets. Choi et al. [5] introduced a variant of Skip-gram model to learn the representations of sets according to the co-occurrence of elements, and a softmax classifier was utilized to predict the subsequent set within a context window. Yu et al. [26] and Hu and He [10] first embedded sets into structured vectors by pooling operations and then learned dynamic hidden patterns in sequential behaviors by Recurrent Neural Networks (RNNs). However, the two-step methods suffered from information loss during the set representation process, which resulted in unsatisfactory prediction performance. Although in recent years, a lot of works on representation learning of set-based data have been proposed [17,27], the learned representations were mainly applied to downstream tasks, which did not take the dynamic sequential behaviors into consideration. Hence, for the task of temporal sets prediction, it is difficult to learn latent representations of sets and then mine sequential patterns based on the learned representations.\n\nTo address the above issues, we propose a novel Deep Neural Network for Temporal Sets Prediction, namely DNNTSP, which consists of three components: element relationship learning, attentionbased temporal dependency learning and gated information fusing. In the proposed model, we consider the interactions of elements not only in the same set, but also among different sets. Different from the existing temporal sets prediction methods, we first propose a weighted graph convolutional network on dynamic graphs which aims to learn the relationships among elements in each set by information propagation. Then for the sequence of each appearing element, an attention-based module is designed to learn temporal dependency among different sets and aggregate historical hidden states into a latent vector. Finally, a gated updating mechanism is provided to fuse both the static and dynamic information of elements, which could achieve high prediction performance according to the comprehensive information it integrates. In summary, this paper has the following contributions:\n\n\u2022 Different from the existing research which turns the temporal sets prediction problem into a conventional predictive modelling problem by a set embedding procedure, our method founds on comprehensive element representation which first captures element relationship by constructing set-level co-occurrence graph and then performs graph convolutions on the dynamic relationship graphs. \u2022 An attention-based temporal dependency learning module is provided, which is able to capture the most important temporal dependencies among elements in the historical sequence of sets and then aggregate the temporal information by a weighted summation adaptively. \u2022 A gated updating mechanism is designed to fuse both the static and dynamic representations of elements, which improves the prediction performance by mining the shared dynamic temporal patterns among elements.\n\n\nPROBLEM FORMALIZATION\n\nThis section first presents the definition of the temporal sets and then provides formalization of the studied problem.\n\nDefinition 2.1. Temporal Sets: Temporal sets can be treated as a sequence of sets, where each set consists of an arbitrary number of elements and also a timestamp.\n\nIt is worth noting that temporal sets are quite pervasive in practice, because in many real-world scenarios, a number of individual or group behaviors are recorded with a same time label. For example, purchasing a collection of goods at a visit to a supermarket, selecting a number of courses at a semester, etc. As a new category of temporal data, temporal sets are more complicated than time series and temporal events.\n\nThe studied problem of this paper, temporal sets prediction, could be formalized as follows. Let U = {u 1 , \u00b7 \u00b7 \u00b7 , u n } and V = {v 1 , \u00b7 \u00b7 \u00b7 , v m } be the collections of n users and m elements respectively. A set S is a collection of elements, S \u2282 V. Given a sequence of sets S i = S 1 i , S 2 i , \u00b7 \u00b7 \u00b7 , S T i that records the historical behaviors of user u i \u2208 U, the goal of temporal sets prediction is to predict the subsequent set according to the historical records, that is,\nS T +1 i = f (S 1 i , S 2 i , \u00b7 \u00b7 \u00b7 , S T i ,W )\n, where W represents the trainable parameters. To solve the above problem, one needs to consider the relationships among elements and the temporal dependency underlying the set sequence. Therefore, existing temporal data prediction methods for time series and temporal events cannot be applied to temporal sets directly.\n\n\nMETHODOLOGY\n\nThis section first presents the framework of the proposed model and then introduces the components step by step. The framework of the proposed model is shown in Figure 2, which consists of three components: element relationship learning, attention-based temporal dependency learning and gated information fusing. The first component is designed to learn set-level element relationship, which first constructs weighted graphs based on the co-occurrence of elements, then propagates information among elements on dynamic graphs, and finally obtains each element's updated representation based on the received information. The second component aims to learn temporal dependency of each element in different sets. This component first takes the sequence of element's representations as the input and uses the attention mechanism to learn the temporal dependencies of sets and elements from the past sequences. Then it provides an aggregation of historical states of elements to the next component. The third component assumes that the interactions of elements could be shared among different sequences. It fuses static and dynamic representations together by a gated updating mechanism, which could improve the final prediction performance by considering all the collected information comprehensively.\n\n\nElement Relationship Learning\n\nMost of the existing temporal sets prediction methods have two main components: set embedding and temporal dependency learning, where set embedding turns the temporal sets prediction problem into a conventional predictive modelling problem. However, the set embedding step suffers from information loss problem caused by the pooling operation, which reduces the final prediction accuracy.\n\nIn order to leverage the useful information in element relationship as much as possible, this paper founds on element representation according to set-level relationship learning. In particular, we propose a weighted graph convolutional network on dynamic graphs, which first constructs weighted graphs based on the cooccurrence of elements and then propagates information between elements in each graph. Let E \u2208 R m\u00d7F denote the embedding matrix of all elements 1 , where F is the dimension of element representation. Then we learn the relationships of elements by the following two steps.\n\nWeighted Graphs Construction. The process of constructing weighted graphs is shown in Figure 3. For S t i \u2208 S i , the t-th set of user u i , we first generate the pairs of every two elements in S t i and each pair denotes a co-occurrence relationship of two elements in S t i . For example, let Figure 3(a). After generating pairs of elements for each set in S i , we could obtain a collection of all pairs. Then we select all unique pairs and assign value to each pair based on its appearing frequency. We add self-connection for each element appearing in S i by treating its appearing frequency as 1, which is used to reduce the information loss for rarely appearing elements in the sequence as the information of such elements would decrease dramatically in long sequences without the self-connection during the following convolutional operations, see Figure 3(b). After that, we normalize the value of each pair between 0 and 1 to denote the weights among different elements as shown in Figure 3(c). Finally, we construct the graph for each set based on the calculated weights and assign representation to each element by its corresponding representation in E, see Figure 3(d). Following the above steps, we could 1 The embedding matrix E is initialized from the standard normal distribution. constructT weighted dynamic graphs\nS 1 i = {v i,1 , v i,2 , v i,3 } and the generated pairs are (v i,1 , v i,2 ), (v i,2 , v i,1 ), (v i,1 , v i,3 ), (v i,3 , v i,1 ), (v i,2 , v i,3 ) and (v i,3 , v i,2 ), seeG i = G 1 i , G 2 i , \u00b7 \u00b7 \u00b7 , G T i . The t-th graph G t i = (V i , E t i ) is a weighted undirected graph with a weighted matrix A t i \u2208 R |V i |\u00d7|V i | ,\nwhere V i denotes the set of appearing elements in S i and E t i denotes the set of edges in G t i . In the following parts, we use e t i, j \u2208 R F to denote the representation of element v i, j \u2208 V i at time t.\n\nWeighted Convolutions on Dynamic Graphs. This paper designs a novel module to perform weighted convolutions on the constructed dynamic graphs. The input of this module is a sequence of dynamic graphs\nG i = G 1 i , G 2 i , \u00b7 \u00b7 \u00b7 , G T i , where graph G t i \u2208 G i has a sequence of elements represented as e t i, j \u2208 R F , \u2200v i, j \u2208 V i . For graph G t\ni , the output of this module is a new sequence of element representation, which could be denoted as\nc t i, j \u2208 R F \u2032 , \u2200v i, j \u2208 V i , where each element is denoted with F \u2032 dimensions.\nThe weighted convolutions are implemented by propagating information of elements in each dynamic graph as follows. Take graph G t i as an instance,\nc t,l +1 i, j = \u03c3 b t,l + k \u2208N t i, j \u222a{j } A t i [j, k] \u00b7 W t,l c t,l i,k ,(1)\nwhere A t i [j, k] represents the item at the j-th row and k-th column of matrix A t i , which is the edge weight of v i, j and v i,k in graph G t i , W t,l \u2208 R F l \u00d7F l \u22121 and b t,l \u2208 R F l are trainable parameters of the l-th convolutional layer at time t, and c t,l i, j denotes the representation of v i, j \u2208 V i in the l-th layer at time t. F l denotes the output dimension of the l-th layer and F 0 is equal to F . N t i, j are neighbors' indices of the j-th element in graph G t i . To reduce the parameter scale and also make our method flexible to deal with sequences with variable lengths, a parameter sharing strategy is adopted, Equation (1) is rewritten as\nc t,l +1 i, j = \u03c3 b l + k \u2208N t i, j \u222a{j } A t i [j, k] \u00b7 W l c t,l i,k ,(2)\nwhich means that we utilize shared parameters for convolutional layers across different timestamps. In the first layer, c t,0 i, j is initialized from the standard normal distribution, which is actually the representation of v i, j in E. The output dimension of the last layer is set to F \u2032 . Due to the weighted convolutions on dynamic graphs, each element in the graphs could not only receive the information from itself, but also receive the information from its neighbours. The representation of each element is updated by all the received information. After the information propagating thoroughly, we achieve a stable representation of each element, which comprehensively considers the relationships of all elements in the graphs.\nFormally, we use C i, j = c 1 i, j , c 2 i, j , \u00b7 \u00b7 \u00b7 , c T i, j to denote the sequence of v i, j , where c t i, j \u2208 R F \u2032 is the output of the last convolutional layer.\n\nAttention-based Temporal Dependency Learning\n\nFor the studied problem, it has been reported that some elements appear quite frequently and regularly in a sequence, while the other elements appear irregularly and occasionally [10], which makes the temporal dependency among a sequence dynamic and complicated. Traditional RNNs fail to handle such temporal dependency, even some gated model have been proposed (e.g. LSTM [9], GRU [6]). The reason is that RNNs only propagate information sequentially, which limits the perception field of temporal dependency learning [13]. Different from the RNNs, the self-attention mechanism could provide a model with the ability to capture the temporal dependency without such limitation [20,22]. In our model, we extend the selfattention mechanism to capture temporal dependency.\n\nTo learn the dynamic and evolutionary patterns in sequences, a temporal dependency learning component is proposed in this paper. The inputs of this component are the sequences of all elements' representations in V i , which could be denoted as\nC i = C i,1 , C i,2 , \u00b7 \u00b7 \u00b7 , C i, | V i | , where C i, j = c 1 i, j , c 2 i, j , \u00b7 \u00b7 \u00b7 , c T i, j are the representations of element v i, j over time. We use C i, j \u2208 R T \u00d7F \u2032 to denote the stacked matrix representation of C i, j , where the t-th row of C i, j is c t i, j .\nThe outputs of this component are aggregated and compact representations of elements in V i , that is,\nZ i = {z i,1 , z i,2 , \u00b7 \u00b7 \u00b7 , z i, | V i | }, where z i, j \u2208 R F \u2032\u2032 denotes the repre- sentation of element v i, j \u2208 V i .\nThis subsection first introduces how to aggregate the stacked representations C i, j into new representations Z i, j with consideration of temporal dependency, and then discusses how to compress the new representations into a compact representation of v i, j , denoted as z i, j .\n\nThe self-attention is used to learn temporal dependency of the stacked representations for each element. The new representations with consideration of temporal dependency are computed as\nZ i, j = so f tmax (C i, j W q ) \u00b7 (C i, j W k ) \u22a4 \u221a F \u2032\u2032 + M i \u00b7 C i, j W v , (3) where W q \u2208 R F \u2032 \u00d7F \u2032\u2032 , W k \u2208 R F \u2032 \u00d7F \u2032\u2032 , W v \u2208 R F \u2032 \u00d7F \u2032\u2032 are trainable\nparameters to calculate queries, keys and values for elements in the sequence,\nZ i, j \u2208 R T \u00d7F \u2032\u2032 is the stacked representation of v i, j 's sequence. M i \u2208 R T\n\u00d7T is a masked matrix, which is used to avoid the future information leakage and guarantee that the state of each timestamp is only affected by its previous states. It is defined as\nM t,t \u2032 i = 0 if t \u2264 t \u2032 , \u2212\u221e otherwise.\nThen we aggregate the sequential information into a vectorized representation by the following weighted aggregation equation,\nz i, j = Z i, j \u00b7 w a\u0434\u0434 \u22a4 \u00b7 Z i, j \u22a4 ,(4)\nwhere w a\u0434\u0434 \u2208 R F \u2032\u2032 is a trainable parameter to learn the importance of different timestamps adaptively. z i, j \u2208 R F \u2032\u2032 is a compact representation for element v i, j that considers all the possible temporal dependencies. In this paper, we set F \u2032\u2032 = F to make the calculation in the following part more convenient.\n\n\nGated Information Fusing\n\nOur model predicts the subsequent set based solely on the historical behaviors, without using any other auxiliary information (e.g. the attributes of users). This indicates that different users may share the same patterns in their sequential behaviors. Mining the shared patterns could not only make our method suitable for sparse data but also improve the robustness of the prediction result.\n\nTo discover the shared hidden patterns and also to combine the static and dynamic information together, A gated information fusing component is provided here. The input of this component has two parts: the shared element representation matrix E and the compact representations of elements w.r.t. user u i , Z i = {z i,1 , z i,2 , \u00b7 \u00b7 \u00b7 , z i, |V i | }. The first part E could be treated as the static representations of elements as it is shared by all the users. The second part Z i could be seen as the dynamic representations of elements appearing in V i because it considers both the co-occurrence relationships and the temporal dependency of the elements. We use E i to denote the hidden state of user i, which is initialized as E. The most recent state E updat e i, I (j) is achieved by updating the user state E i iteratively as follows,\nE updat e i, I (j) = (1 \u2212 \u03b2 i, I (j) \u00b7 \u03b3 I (j) ) \u00b7 E i, I (j) + (\u03b2 i, I (j) \u00b7 \u03b3 I (j) ) \u00b7 z i, j ,(5)\nwhere I (\u00b7) is a function that maps element v i, j to its corresponding index in E i , \u03b2 i, j and \u03b3 j are the j-th dimension of \u03b2 i and \u03b3 . \u03b2 i \u2208 R m is a indicator vector composed of 0 or 1, where the entry with value 1 means the corresponding element is in V i . \u03b3 \u2208 R m is the trainable parameter of an updating gate which controls the importance of the static and dynamic representations. In Equation (5), the representations of elements appearing in V i are updated according to both the static and dynamic information. For the other elements, we just maintain its original static representations.\n\n\nThe Prediction Layer\n\nFinally, the possibilities of all elements appearing in the next-period set could be computed according to the user's current state,\ny i = si\u0434moid(E updat e i \u00b7 w o + b o ),(6)\nwhere w o \u2208 R F and b o \u2208 R are trainable parameters to provide the final prediction result.\n\n\nThe Learning Process\n\nTo construct our temporal sets prediction model, we first stack multiple weighted convolutional layers with shared parameters and propagate information of elements on the dynamic graphs to learn set-level element relationship. Then we provide an attentionbased temporal dependency learning module to learn the temporal dependency with a complete receptive field, and aggregate the temporal information into a latent representation for each element using the weighted aggregation. In order to enhance the learning capacity of this component, we use multiple heads to identify the most influencing modes, and concatenate the representations of different heads to get a joint representation. Moreover, we employ the gated information fusing component to take in the output of temporal dependency learning module and the embedding matrix to explore the shared patterns in different sequences. Finally, the prediction layer provides the final result.\n\nIn the training process, predicting next-period set could be treated as a multi-label learning problem, so we adopt the loss function with L 2 regularization technique as follows,\nL = \u2212 1 N N i 1 m m j y i, j log(\u0177 i, j ) + (1 \u2212 y i, j ) log(1 \u2212\u0177 i, j ) + \u03bb\u2225W \u2225 2 ,(7)\nwhere W denotes all the trainable parameters in our model, N is the number of training samples, \u03bb is a hyperparameter to control the importance of L 2 regularization, y i, j and\u0177 i, j denote the j-th dimension of the ground truth and the predicted appearing possibility of j-th element in the next set of user u i . We optimize the proposed model by minimizing Equation (7) until convergence.\n\n\nEXPERIMENTS\n\nThis section evaluates the performance of the proposed method by experiments on real-world data sets. Both classical and state-of-theart methods are implemented to provide baseline performance, and multiple metrics are used to provide comprehensive evaluation.\n\n\nDescription of Datasets\n\nWe conduct experiments on four real-world datesets:\n\n\u2022 TaFeng 2 : TaFeng is a public dataset which contains four months of shopping transactions at a Chinese grocery store. This dataset was recorded at day-level, and we treat products purchased in the same day by the same customer as a set. \u2022 Dunnhumby-Carbo (DC) 3 : DC contains two years of transactions from households at a retailer which could be available online. Products purchased in the same transaction are treated as a set. We select the transactions during the first two months to conduct experiments because it's costly to train on the original dataset due to its large scale. \u2022 TaoBao 4 : TaoBao contains lots of users who have four types of behaviors including clicking, purchasing, adding products to shopping carts and marking products as favor online. We select all purchasing behaviors and treat products bought in the same transaction as a set. \u2022 Tags-Math-Sx (TMS) 5 \n\n\nCompared Methods\n\nWe compare our model with the following baselines, including both classical and the state-of-the-art methods:\n\n\u2022 TOP: It uses the most popular elements appearing in the training set as the prediction for users in the test set. \u2022 PersonalTOP: It sorts the most popular elements that appear in historical sets of a given user, and then recommends them to the user as the prediction result. \u2022 ElementTransfer: ElementTransfer first learns transfer relationships between elements based on adjacent behaviors of a given user. Then it provides elements which are more likely to appear in the next-period based on the last status of the user using the learned transfer relationships. \u2022 DREAM: This method considers both dynamic representations of users and global interactions among sets based on neural networks for next-basket recommendation [26]. DREAM uses max pooling operations to generate representations of baskets. Then the sequence of baskets is fed into an RNN structure which predicts the next-period basket. \u2022 Sets2Sets: Sets2Sets [10] uses the average pooling operation to map sets into structured vectors and designs an encoderdecoder framework to complete multi-period sets prediction based on the attention mechanism. It also takes the repeated patterns in user behaviors into consideration.  \n\n\nEvaluation Metrics\n\nTo get a comprehensive evaluation of the proposed method, three metrics: Recall, Normalized Discounted Cumulative Gain (NDCG) and Personal Hit Ratio (PHR) are adopted as evaluation metrics.\n\nRecall is widely used in estimating model performance which measures the model\u00e2\u0102\u0179s ability to find all relevant elements. For user u i , Recall is calculated by\nRecall@K(u i ) = |\u015c i \u2229 S i | |S i | ,\nwhere\u015c i and S i are the predicted top-K elements and the ground truth of user u i respectively, |S | denotes the size of set S. We adopt the average recall of all users as a metric. NDCG is a measure of ranking quality which considers the order of elements in a list. For user u i , NDCG is calculated by\nNDCG@K(u i ) = K k =1 \u03b4 (\u015c k i ,S i ) log 2 (k +1) min(K, |S i |) k =1 1 log 2 (k +1) ,\nwhere \u03b4 (v, S) returns 1 when the element v is in the set S, otherwise 0. The average NDCG of all users is adopted as another metric.\n\nPHR pays attention to the performance at user level which represents the ratio of users whose predicted sets contain the elements appearing in the ground truth. PHR is calculated by\nPHR@K = N \u2032 i=1 1 |\u015c i \u2229 S i | N \u2032 ,\nwhere N \u2032 denotes the number of testing samples, 1 (x) is an indicator function which returns 1 when x \u2265 0, otherwise 0.\n\n\nExperimental Settings\n\nFor evaluation, we generate a ranking list of top-K elements from the output and K is set to 10, 20, 30 and 40 respectively. We divide each dataset into train, validation and test set across users with the ratios of 70%, 10% and 20% to do experiments. After partitioning the data, we train our model on the training data for a fix number of epochs (e.g. 100 epochs), and choose the model which achieves the best performance on the validation set for testing. Adam [14] is adopted as the optimizer in our experiment. We utilize batch normalization [11] technique between weighted convolutional layers to accelerate the training speed. The learning rate on TaFeng, TaoBao and TMS datasets is set to 0.001, and it is set to 0.005 on DC dataset. We stack 2 weighted convolutional layers and employ 4 attention heads on all four datasets. The hidden dimension F and batch size are set to 32 and 64 respectively. The model is implemented with the PyTorch framework. We make the code and data publicly available on GitHub platform 6 .\n\n\nExperimental Results and Analysis\n\nThe comparisons of DNNTSP with other methods on Top-K performance are reported in Table 2. By analyzing the results, some conclusions could be summarized. Firstly, PersonalTOP achieves competitive or even better performance than other baselines in some cases although it does not consider the temporal dependency. This is because that users tend to interact with some elements repeatedly due to their preferences, which are not affected by the time. PersonalTOP performs better  than TOP because it could provide personalized results for different users. TOP gets worse metrics as it always provides the same elements for all users.\n\nSecondly, ElementTransfer performs worse than DREAM as it only considers adjacent temporal dependency, while DREAM focuses on the whole sequence due to RNN structures. It indicates that users' behaviors are temporally dependent. So learning the temporal dependency from the whole sequence of the users could obtain better prediction performance.\n\nThirdly, Sets2Sets achieves better performance than other baselines in most cases because it learns temporal dependency by RNNs combined with the attention mechanism, which helps to select the most useful temporal dependencies in the sequence. What's more, it considers the frequent behaviors of users by modelling the repeated patterns, which also improves the prediction performance.\n\nFinally, the proposed DNNTSP outperforms all other methods significantly in most cases. Compared with TOP and PersonalTOP, DNNTSP learns dynamic temporal dependency in users' sequential behaviors. Compared with ElementTransfer and DREAM, DNNTSP focuses on the temporal dependency of the whole sequence and leverages attention mechanism to adaptively select the most important temporal dependencies. Compared with Sets2Sets, DNNTSP learns set-level element relationship, which could maintain useful information as much as possible. What's more, DNNTSP learns the interactions of elements from a global perspective by mining shared patterns in different sequences. We also observe that DNNTSP could not outperform Sets2Sets completely in TMS dataset, especially on the NDCG metric. We infer that the repeated behaviors in TMS dataset are more obvious than that in other datasets, which result in a higher ranking quality. We will investigate this phenomenon in a further step in Section 4.8.\n\nIn order to compare our method with baselines more comprehensively, we also show the performance of the proposed model when top-K varies in consecutive values. Due to space limitations, we just show the results on TaFeng dataset. As shown in Figure 4, we can see that DNNTSP outperforms other baselines consistently when the value of K changes from 1 to 40. This indicates that our method could provide more precise predictions without the influence of the capacity of predicted sets.\n\n\nAblation Study\n\nTo investigate the effects of element relationship learning and temporal dependency learning components, we conduct the ablation study by removing the two components manually and comparing the performance with the original DNNTSP.\n\nSpecifically, three-fold ablation experiments have been implemented: 1) We remove the Element Relationship Learning component by stacking the representations of appearing elements in the sequence based on the sequence's length (denoted as DNNTSP w/o ERL), which means that we ignore the relationships between elements and and do not propagate information among elements. 2) We replace the Temporal Dependency Learning component by simply aggregating the sequence of each appearing element using average pooling (denoted as DNNTSP w/o TDL), which means that we do not consider the evolutionary pattern in the sequence and lose some temporal information. 3) Moreover, we remove both the two components simultaneously (denoted as DNNTSP w/o both) to conduct experiments. Experimental results on TaFeng dataset are shown in Figure 5.\n\nFrom the results, we could conclude that the performance of DNNTSP decreases when any component is abandoned, because the ERL component takes element relationship into consideration and the TDL module learns dynamic temporal dependency from the whole sequence and selects the most important dependencies adaptively. DNNTSP w/o ERL ignores the element relationship and DNNTSP w/o TDL omits the evolution of dynamic changes in the sequence, so they both obtain worse performance. DNNTSP (w/o   \n\n\nEffects of the Training Data Ratio\n\nTo demonstrate the effectiveness of the gated information fusing component, we train our model on training set with varying sizes. Specifically, we randomly choose data in the original training set by changing the ratio from 10% to 100% with 10% increment each time. Finally, we could generate 10 training sets with different sizes and train the model on each dataset.\n\nExperimental results on TaFeng dataset are shown in Figure 6. From the results, we could observe that our model performs better when the size of training data increases. More importantly, our model is able to achieve competitive performance when it is trained with only forty percent of the training data. This proves that the gated information fusing component helps our model discover the shared patterns in different sequences, and therefore our model could get satisfactory results with only a portion of the training data. The results illustrate that our model is applicable to the scenarios with sparse data.\n\n\nEffects of Modelling the Repeated Behaviors in Temporal Sets Prediction\n\nSince our model could not outperform Sets2Sets in some metrics on the TMS dataset, we conclude that the repeated behaviors have a greater impact on the TMS dataset and the component of modelling such behaviors in Sets2Sets helps Sets2Sets achieve better performance. So we study the effects of modelling the repeated behaviors in temporal sets prediction and use the TMS dataset to conduct experiments. Specifically, we first remove the repeated behaviors modelling component in Sets2Sets and denote the model as Sets2Sets-. Then we incorporate this component into our DNNTSP and denote it as DNNTSP+. Experimental results of the modified models are shown in Table 3.\n\nFrom the results, we could conclude that in the same condition, the proposed DNNTSP performs better than Sets2Sets. On the one hand, without modelling repeated behaviors, DNNTSP achieves better results than Sets2Sets-, which shows the superiority of DNNTSP over Sets2Sets in temporal sets prediction when no empirical information is added. On the other hand, DNNTSP+ also outperforms Sets2Sets, which proves the effectiveness of modelling the repeated behaviors in temporal sets prediction and also demonstrates that our model is able to achieve the best performance by incorporating the repeated behaviors modelling component.\n\n\nRELATED WORK\n\nThis section reviews the existing literature related to our work, and also points out the differences of previous studies with our research.\n\nNext-period Set Prediction. In the field of retail, Yu et al. [26] used pooling operations among products in each basket to get its representation and employed an RNN structure to learn the dynamic evolves in the sequence of customer's behaviors. In field of health care, Choi et al. [5] focused more on the relationships of drugs and introduced a variant of Skip-gram model to learn drugs' co-occurrence information. Based on the learned relationships, they generated representations of prescriptions and used a softmax classifier to predict subsequent prescriptions within a context window. More generally, Benson et al. [2] studied the repeated behaviors in sequences of sets and provided a stochastic model to mine the hidden patterns. However, their model assumed that only the repeated elements would appear in next-period set and the model became prohibitive when the size of set gets larger. Hu and He [10] obtained the representations of sets by pooling operations and proposed an encoder-decoder framework to make multi-period sets prediction. Moreover, they considered the repeated user behaviors to improve the model performance. We could find that most of the existing methods first embedded sets into latent vectors and then predicted future sets based on the sequences of embedded sets. However, the two-step learning process usually leads to the loss of elements' information, so we provide a new perspective to deal with the temporal sets prediction problem in this paper.\n\nRelationship Learning Based on Graph Neural Networks. Graph Network Networks (GNNs) have shown the effectiveness in learning representations with consideration of multiple complex relationships. GNNs first propagate information among each node and its neighbours, and then produce a representation for each node in the relationship graph based on received information [28]. According to different convolutional operations on the graphs, GNNs could be divided into spectral-based methods [15] and spatial-based methods [8]. In the studied problem, the size-variant characteristic makes sets arbitrary-sized, so we design a weighted graph convolutional network to deal with dynamic graphs.\n\nTemporal Dependency Learning Based on the Attention Mechanism. Since the proposition of the attention mechanism in neural networks, it has achieved great success in various tasks such as image caption [25] and machine translation [1]. Inspired by the fact that people usually pay much attention on the important part of the whole perception space, attention mechanisms provide neural networks with the ability to assign larger weights on the most useful parts of the collected information. Recently, a novel framework based solely on attention mechanism, namely Transformer, has been proposed to apply in sequential tasks successfully without using any recurrent or convolutional architectures [22]. Since the self-attention mechanism has a strong ability to capture both short and long-term dependency by allowing the model to access any part of historical records without the constraint of distance, we extend the self-attention mechanism in our model to learn dynamic temporal dependency in different sequences.\n\n\nCONCLUSION\n\nThis paper studies predictive modelling of a new type of temporal data, namely, temporal sets. Different from the existing methods, which adopt a set embedding procedure to turn the temporal sets prediction problem into a conventional prediction problem, our method is founded on the multiple and comprehensive set-level element representations. In particular, our method consists of three components: 1) an element relationship learning module to capture multiple set-level element relationships; 2) an attention-based temporal dependency learning module to learn the temporal dependencies of the sets and elements from the whole sequence; and 3) a gated information fusing module to discover the shared patterns among different sequences and fuse both the static and dynamic information. Experimental results demonstrate that our method could circumvent the information loss problem suffered by the set-embedding based methods, and achieve higher prediction performance than the state-of-the-art methods.\n\nFigure 1 :\n1Prediction of three types of temporal data: time series, temporal events and temporal sets.\n\nFigure 2 :\n2Framework of the proposed model.\n\nFigure 3 :\n3The process of weighted graphs construction.\n\n\n0.5601 0.4061 0.7594 0.6145 0.4204 0.8131 0.6627 0.4321 0.8570 DNNTSP 0.4693 0.3473 0.6825 0.5826 0.3839 0.7880 0.6440 0.4000 0.8439 0.6840 0.4097 0.8748\n\nFigure 4 :\n4The performance of DNNTSP on different values of top-K on TaFeng dataset.\n\nFigure 5 :\n5Effects of the ERL and TDL components on TaFeng dataset, and K is set to 10, 20, 30 and 40 respectively.\n\nFigure 6 :\n6The performance of DNNTSP on different ratios of the training data on TaFeng dataset.\n\n\nachieves the worst results as it does not consider either the element relationship or temporal dependency in the sequence.\n\nTable 1 :\n1Statistics of the datasets.Datasets \n#sets \n#users #elements #E/S #S/U \nTaFeng \n73,355 \n9,841 \n4,935 \n5.41 \n7.45 \nDC \n42,905 \n9,010 \n217 \n1.52 \n4.76 \nTaoBao 628,618 113,347 \n689 \n1.10 \n5.55 \nTMS \n243,394 15,726 \n1,565 \n2.19 15.48 \n\n\n\nTable 2 :\n2Comparisons with different methods on Top-K performance. Recall NDCG PHR Recall NDCG PHR Recall NDCG PHR Recall NDCG PHRDatasets \nMethods \nK=10 \nK=20 \nK=30 \nK=40 \n\n\nTable 3 :\n3Effects of the repeated behaviors modelling component on TMS dataset. Recall NDCG PHR Recall NDCG PHR Recall NDCG PHR Recall NDCG PHRDataset \nMethods \nK=10 \nK=20 \nK=30 \nK=40 \n\nhttps://www.kaggle.com/chiranjivdas09/ta-feng-grocery-dataset 3 https://www.dunnhumby.com/careers/engineering/sourcefiles\nhttps://tianchi.aliyun.com/dataset/dataDetail?dataId=649 5 https://math.stackexchange.com\nCode and data are available at https://github.com/yule-BUAA/DNNTSP.\nACKNOWLEDGMENTSThe authors would like to thank the anonymous reviewers for their constructive comments on this research work. This work is supported by the National Natural Science Foundation of China\nNeural Machine Translation by Jointly Learning to Align and Translate. Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio, ICLR. Dzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. 2015. Neural Machine Translation by Jointly Learning to Align and Translate. In ICLR.\n\nSequences of Sets. Austin R Benson, Ravi Kumar, Andrew Tomkins, SIGKDD. Austin R. Benson, Ravi Kumar, and Andrew Tomkins. 2018. Sequences of Sets. In SIGKDD. 1148-1157.\n\nIntroduction to time series and forecasting. J Peter, Richard A Brockwell, Matthew V Davis, Calder, Springer2Peter J Brockwell, Richard A Davis, and Matthew V Calder. 2002. Introduction to time series and forecasting. Vol. 2. Springer.\n\nRecurrent neural networks for multivariate time series with missing values. Zhengping Che, Sanjay Purushotham, Kyunghyun Cho, David Sontag, Yan Liu, Scientific reports. 86085Zhengping Che, Sanjay Purushotham, Kyunghyun Cho, David Sontag, and Yan Liu. 2018. Recurrent neural networks for multivariate time series with missing values. Scientific reports 8, 1 (2018), 6085.\n\nMultilayer representation learning for medical concepts. Edward Choi, Mohammad Taha Bahadori, Elizabeth Searles, Catherine Coffey, Michael Thompson, James Bost, SIGKDD. ACM. Javier Tejedor-Sojo, and Jimeng SunEdward Choi, Mohammad Taha Bahadori, Elizabeth Searles, Catherine Coffey, Michael Thompson, James Bost, Javier Tejedor-Sojo, and Jimeng Sun. 2016. Multi- layer representation learning for medical concepts. In SIGKDD. ACM, 1495-1504.\n\nEmpirical evaluation of gated recurrent neural networks on sequence modeling. Junyoung Chung, Caglar Gulcehre, Kyunghyun Cho, Yoshua Bengio, arXiv:1412.3555arXiv preprintJunyoung Chung, Caglar Gulcehre, KyungHyun Cho, and Yoshua Bengio. 2014. Empirical evaluation of gated recurrent neural networks on sequence modeling. arXiv preprint arXiv:1412.3555 (2014).\n\nOutlier Detection for Temporal Data: A Survey. Manish Gupta, Jing Gao, C Charu, Jiawei Aggarwal, Han, IEEE Trans. Knowl. Data Eng. 26Manish Gupta, Jing Gao, Charu C. Aggarwal, and Jiawei Han. 2014. Outlier Detection for Temporal Data: A Survey. IEEE Trans. Knowl. Data Eng. 26, 9 (2014), 2250-2267.\n\nInductive Representation Learning on Large Graphs. William L Hamilton, Zhitao Ying, Jure Leskovec, Advances in Neural Information Processing Systems. William L. Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive Represen- tation Learning on Large Graphs. In Advances in Neural Information Processing Systems. 1024-1034.\n\nLong Short-Term Memory. Sepp Hochreiter, J\u00fcrgen Schmidhuber, Neural Computation. 9Sepp Hochreiter and J\u00fcrgen Schmidhuber. 1997. Long Short-Term Memory. Neural Computation 9, 8 (1997), 1735-1780.\n\nSets2Sets: Learning from Sequential Sets with Neural Networks. Haoji Hu, Xiangnan He, SIGKDD. Haoji Hu and Xiangnan He. 2019. Sets2Sets: Learning from Sequential Sets with Neural Networks. In SIGKDD. 1491-1499.\n\nBatch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift. Sergey Ioffe, Christian Szegedy, ICML. Sergey Ioffe and Christian Szegedy. 2015. Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift. In ICML. 448-456.\n\nA treatment engine by predicting next-period prescriptions. Bo Jin, Haoyu Yang, Leilei Sun, Chuanren Liu, Yue Qu, Jianing Tong, SIGKDD. Bo Jin, Haoyu Yang, Leilei Sun, Chuanren Liu, Yue Qu, and Jianing Tong. 2018. A treatment engine by predicting next-period prescriptions. In SIGKDD. 1608-1616.\n\nUrvashi Khandelwal, He He, Peng Qi, Dan Jurafsky, Sharp Nearby, Fuzzy Far Away: How Neural Language Models Use Context. In ACL. Urvashi Khandelwal, He He, Peng Qi, and Dan Jurafsky. 2018. Sharp Nearby, Fuzzy Far Away: How Neural Language Models Use Context. In ACL. 284-294.\n\nAdam: A method for stochastic optimization. P Diederik, Jimmy Kingma, Ba, arXiv:1412.6980arXiv preprintDiederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic opti- mization. arXiv preprint arXiv:1412.6980 (2014).\n\nSemi-Supervised Classification with Graph Convolutional Networks. N Thomas, Max Kipf, Welling, ICLR. Thomas N. Kipf and Max Welling. 2017. Semi-Supervised Classification with Graph Convolutional Networks. In ICLR.\n\nA survey of temporal data mining. Srivatsan Laxman, Shanti Sastry, Sadhana. 312Srivatsan Laxman and P Shanti Sastry. 2006. A survey of temporal data mining. Sadhana 31, 2 (2006), 173-198.\n\nSet Transformer: A Framework for Attention-based Permutation-Invariant Neural Networks. Juho Lee, Yoonho Lee, Jungtaek Kim, Adam R Kosiorek, Seungjin Choi, Yee Whye Teh, Juho Lee, Yoonho Lee, Jungtaek Kim, Adam R. Kosiorek, Seungjin Choi, and Yee Whye Teh. 2019. Set Transformer: A Framework for Attention-based Permutation-Invariant Neural Networks. In ICML. 3744-3753.\n\nNemo: Next career move prediction with contextual embedding. Liangyue Li, How Jing, Hanghang Tong, Jaewon Yang, Qi He, Bee-Chung Chen, Proceedings of the 26th International Conference on World Wide Web Companion. International World Wide Web Conferences Steering Committee. the 26th International Conference on World Wide Web Companion. International World Wide Web Conferences Steering CommitteeLiangyue Li, How Jing, Hanghang Tong, Jaewon Yang, Qi He, and Bee-Chung Chen. 2017. Nemo: Next career move prediction with contextual embedding. In Proceedings of the 26th International Conference on World Wide Web Companion. International World Wide Web Conferences Steering Committee, 505-513.\n\nDiffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting. Yaguang Li, Rose Yu, Cyrus Shahabi, Yan Liu, ICLR. Yaguang Li, Rose Yu, Cyrus Shahabi, and Yan Liu. 2018. Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting. In ICLR.\n\nDynamic Graph Representation Learning via Self-Attention Networks. Aravind Sankar, Yanhong Wu, Liang Gou, Wei Zhang, Hao Yang, arXiv:1812.09430arXiv preprintAravind Sankar, Yanhong Wu, Liang Gou, Wei Zhang, and Hao Yang. 2018. Dynamic Graph Representation Learning via Self-Attention Networks. arXiv preprint arXiv:1812.09430 (2018).\n\nData-driven automatic treatment regimen development and recommendation. Leilei Sun, Chuanren Liu, Chonghui Guo, Hui Xiong, Yanming Xie, SIGKDD. Leilei Sun, Chuanren Liu, Chonghui Guo, Hui Xiong, and Yanming Xie. 2016. Data-driven automatic treatment regimen development and recommendation. In SIGKDD. 1865-1874.\n\nAttention is all you need. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, Illia Polosukhin, Advances in neural information processing systems. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in neural information processing systems. 5998-6008.\n\nSupervised reinforcement learning with recurrent neural network for dynamic treatment recommendation. Lu Wang, Wei Zhang, SIGKDD. ACM. Xiaofeng He, and Hongyuan ZhaLu Wang, Wei Zhang, Xiaofeng He, and Hongyuan Zha. 2018. Supervised re- inforcement learning with recurrent neural network for dynamic treatment recommendation. In SIGKDD. ACM, 2447-2456.\n\nPersonalized course sequence recommendations. Jie Xu, Tianwei Xing, Mihaela Van Der, Schaar, IEEE Transactions on Signal Processing. 64Jie Xu, Tianwei Xing, and Mihaela Van Der Schaar. 2016. Personalized course sequence recommendations. IEEE Transactions on Signal Processing 64, 20 (2016), 5340-5352.\n\nShow, Attend and Tell: Neural Image Caption Generation with Visual Attention. Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron C Courville, Ruslan Salakhutdinov, Richard S Zemel, Yoshua Bengio, Kelvin Xu, Jimmy Ba, Ryan Kiros, Kyunghyun Cho, Aaron C. Courville, Ruslan Salakhutdinov, Richard S. Zemel, and Yoshua Bengio. 2015. Show, Attend and Tell: Neural Image Caption Generation with Visual Attention. In ICML. 2048-2057.\n\nA dynamic recurrent model for next basket recommendation. Feng Yu, Qiang Liu, Shu Wu, Liang Wang, Tieniu Tan, SIGIR. ACM. Feng Yu, Qiang Liu, Shu Wu, Liang Wang, and Tieniu Tan. 2016. A dynamic recurrent model for next basket recommendation. In SIGIR. ACM, 729-732.\n\nDeep sets. Manzil Zaheer, Satwik Kottur, Siamak Ravanbakhsh, Barnabas Poczos, R Ruslan, Alexander J Salakhutdinov, Smola, Advances in neural information processing systems. Manzil Zaheer, Satwik Kottur, Siamak Ravanbakhsh, Barnabas Poczos, Ruslan R Salakhutdinov, and Alexander J Smola. 2017. Deep sets. In Advances in neural information processing systems. 3391-3401.\n\nGraph Neural Networks: A Review of Methods and Applications. Jie Zhou, Ganqu Cui, Zhengyan Zhang, Cheng Yang, Zhiyuan Liu, Maosong Sun, CoRR abs/1812.08434Jie Zhou, Ganqu Cui, Zhengyan Zhang, Cheng Yang, Zhiyuan Liu, and Maosong Sun. 2018. Graph Neural Networks: A Review of Methods and Applications. CoRR abs/1812.08434 (2018).\n", "annotations": {"author": "[{\"end\":199,\"start\":134},{\"end\":270,\"start\":200},{\"end\":339,\"start\":271},{\"end\":439,\"start\":340},{\"end\":572,\"start\":440},{\"end\":643,\"start\":573},{\"end\":709,\"start\":644},{\"end\":780,\"start\":710},{\"end\":849,\"start\":781},{\"end\":949,\"start\":850},{\"end\":1062,\"start\":950},{\"end\":1133,\"start\":1063}]", "publisher": "[{\"end\":65,\"start\":52},{\"end\":1412,\"start\":1399}]", "author_last_name": "[{\"end\":139,\"start\":137},{\"end\":210,\"start\":207},{\"end\":279,\"start\":277},{\"end\":352,\"start\":349},{\"end\":449,\"start\":444},{\"end\":583,\"start\":581},{\"end\":649,\"start\":647},{\"end\":720,\"start\":717},{\"end\":789,\"start\":787},{\"end\":862,\"start\":859},{\"end\":959,\"start\":954},{\"end\":1073,\"start\":1071}]", "author_first_name": "[{\"end\":136,\"start\":134},{\"end\":206,\"start\":200},{\"end\":276,\"start\":271},{\"end\":348,\"start\":340},{\"end\":443,\"start\":440},{\"end\":580,\"start\":573},{\"end\":646,\"start\":644},{\"end\":716,\"start\":710},{\"end\":786,\"start\":781},{\"end\":858,\"start\":850},{\"end\":953,\"start\":950},{\"end\":1070,\"start\":1063}]", "author_affiliation": "[{\"end\":198,\"start\":141},{\"end\":269,\"start\":212},{\"end\":338,\"start\":281},{\"end\":438,\"start\":354},{\"end\":571,\"start\":471},{\"end\":642,\"start\":585},{\"end\":708,\"start\":651},{\"end\":779,\"start\":722},{\"end\":848,\"start\":791},{\"end\":948,\"start\":864},{\"end\":1061,\"start\":961},{\"end\":1132,\"start\":1075}]", "title": "[{\"end\":51,\"start\":1},{\"end\":1184,\"start\":1134}]", "venue": "[{\"end\":1280,\"start\":1186}]", "abstract": "[{\"end\":3218,\"start\":1684}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b18\"},\"end\":3568,\"start\":3564},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":3664,\"start\":3660},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":3775,\"start\":3772},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":3778,\"start\":3775},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3851,\"start\":3848},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3853,\"start\":3851},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":3877,\"start\":3873},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":3880,\"start\":3877},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3973,\"start\":3970},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":4580,\"start\":4576},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":4636,\"start\":4632},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":4639,\"start\":4636},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":5379,\"start\":5376},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":5382,\"start\":5379},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":5385,\"start\":5382},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":5589,\"start\":5586},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":5818,\"start\":5814},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":5837,\"start\":5833},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":6272,\"start\":6268},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":6275,\"start\":6272},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":13669,\"start\":13668},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":16973,\"start\":16969},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":17166,\"start\":17163},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":17175,\"start\":17172},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":17313,\"start\":17309},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":17471,\"start\":17467},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":17474,\"start\":17471},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":21585,\"start\":21582},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":24947,\"start\":24946},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":25810,\"start\":25806},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":26010,\"start\":26006},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":28048,\"start\":28044},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":28131,\"start\":28127},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":35682,\"start\":35678},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":35903,\"start\":35900},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":36242,\"start\":36239},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":36530,\"start\":36526},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":37479,\"start\":37475},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":37598,\"start\":37594},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":37628,\"start\":37625},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":38001,\"start\":37997},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":38029,\"start\":38026},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":38494,\"start\":38490}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":39936,\"start\":39832},{\"attributes\":{\"id\":\"fig_1\"},\"end\":39982,\"start\":39937},{\"attributes\":{\"id\":\"fig_2\"},\"end\":40040,\"start\":39983},{\"attributes\":{\"id\":\"fig_3\"},\"end\":40196,\"start\":40041},{\"attributes\":{\"id\":\"fig_4\"},\"end\":40283,\"start\":40197},{\"attributes\":{\"id\":\"fig_5\"},\"end\":40401,\"start\":40284},{\"attributes\":{\"id\":\"fig_6\"},\"end\":40500,\"start\":40402},{\"attributes\":{\"id\":\"fig_7\"},\"end\":40625,\"start\":40501},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":40870,\"start\":40626},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":41046,\"start\":40871},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":41234,\"start\":41047}]", "paragraph": "[{\"end\":5300,\"start\":3234},{\"end\":6594,\"start\":5302},{\"end\":7668,\"start\":6596},{\"end\":8532,\"start\":7670},{\"end\":8677,\"start\":8558},{\"end\":8842,\"start\":8679},{\"end\":9265,\"start\":8844},{\"end\":9752,\"start\":9267},{\"end\":10122,\"start\":9802},{\"end\":11435,\"start\":10138},{\"end\":11857,\"start\":11469},{\"end\":12448,\"start\":11859},{\"end\":13781,\"start\":12450},{\"end\":14323,\"start\":14113},{\"end\":14524,\"start\":14325},{\"end\":14776,\"start\":14676},{\"end\":15010,\"start\":14863},{\"end\":15760,\"start\":15091},{\"end\":16572,\"start\":15837},{\"end\":17559,\"start\":16790},{\"end\":17804,\"start\":17561},{\"end\":18183,\"start\":18081},{\"end\":18588,\"start\":18308},{\"end\":18776,\"start\":18590},{\"end\":19016,\"start\":18938},{\"end\":19280,\"start\":19099},{\"end\":19447,\"start\":19322},{\"end\":19807,\"start\":19490},{\"end\":20229,\"start\":19836},{\"end\":21074,\"start\":20231},{\"end\":21779,\"start\":21177},{\"end\":21936,\"start\":21804},{\"end\":22073,\"start\":21981},{\"end\":23043,\"start\":22098},{\"end\":23224,\"start\":23045},{\"end\":23706,\"start\":23314},{\"end\":23982,\"start\":23722},{\"end\":24061,\"start\":24010},{\"end\":24948,\"start\":24063},{\"end\":25078,\"start\":24969},{\"end\":26272,\"start\":25080},{\"end\":26484,\"start\":26295},{\"end\":26646,\"start\":26486},{\"end\":26991,\"start\":26686},{\"end\":27213,\"start\":27080},{\"end\":27396,\"start\":27215},{\"end\":27554,\"start\":27434},{\"end\":28607,\"start\":27580},{\"end\":29277,\"start\":28645},{\"end\":29624,\"start\":29279},{\"end\":30011,\"start\":29626},{\"end\":31002,\"start\":30013},{\"end\":31488,\"start\":31004},{\"end\":31737,\"start\":31507},{\"end\":32568,\"start\":31739},{\"end\":33062,\"start\":32570},{\"end\":33469,\"start\":33101},{\"end\":34085,\"start\":33471},{\"end\":34828,\"start\":34161},{\"end\":35457,\"start\":34830},{\"end\":35614,\"start\":35474},{\"end\":37105,\"start\":35616},{\"end\":37794,\"start\":37107},{\"end\":38810,\"start\":37796},{\"end\":39831,\"start\":38825}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":9801,\"start\":9753},{\"attributes\":{\"id\":\"formula_1\"},\"end\":13957,\"start\":13782},{\"attributes\":{\"id\":\"formula_2\"},\"end\":14112,\"start\":13957},{\"attributes\":{\"id\":\"formula_3\"},\"end\":14675,\"start\":14525},{\"attributes\":{\"id\":\"formula_4\"},\"end\":14862,\"start\":14777},{\"attributes\":{\"id\":\"formula_5\"},\"end\":15090,\"start\":15011},{\"attributes\":{\"id\":\"formula_6\"},\"end\":15836,\"start\":15761},{\"attributes\":{\"id\":\"formula_7\"},\"end\":16742,\"start\":16573},{\"attributes\":{\"id\":\"formula_8\"},\"end\":18080,\"start\":17805},{\"attributes\":{\"id\":\"formula_9\"},\"end\":18307,\"start\":18184},{\"attributes\":{\"id\":\"formula_10\"},\"end\":18937,\"start\":18777},{\"attributes\":{\"id\":\"formula_11\"},\"end\":19098,\"start\":19017},{\"attributes\":{\"id\":\"formula_12\"},\"end\":19321,\"start\":19281},{\"attributes\":{\"id\":\"formula_13\"},\"end\":19489,\"start\":19448},{\"attributes\":{\"id\":\"formula_14\"},\"end\":21176,\"start\":21075},{\"attributes\":{\"id\":\"formula_15\"},\"end\":21980,\"start\":21937},{\"attributes\":{\"id\":\"formula_16\"},\"end\":23313,\"start\":23225},{\"attributes\":{\"id\":\"formula_17\"},\"end\":26685,\"start\":26647},{\"attributes\":{\"id\":\"formula_18\"},\"end\":27079,\"start\":26992},{\"attributes\":{\"id\":\"formula_19\"},\"end\":27433,\"start\":27397}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":28734,\"start\":28727},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":34827,\"start\":34820}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":3232,\"start\":3220},{\"attributes\":{\"n\":\"2\"},\"end\":8556,\"start\":8535},{\"attributes\":{\"n\":\"3\"},\"end\":10136,\"start\":10125},{\"attributes\":{\"n\":\"3.1\"},\"end\":11467,\"start\":11438},{\"attributes\":{\"n\":\"3.2\"},\"end\":16788,\"start\":16744},{\"attributes\":{\"n\":\"3.3\"},\"end\":19834,\"start\":19810},{\"attributes\":{\"n\":\"3.4\"},\"end\":21802,\"start\":21782},{\"attributes\":{\"n\":\"3.5\"},\"end\":22096,\"start\":22076},{\"attributes\":{\"n\":\"4\"},\"end\":23720,\"start\":23709},{\"attributes\":{\"n\":\"4.1\"},\"end\":24008,\"start\":23985},{\"attributes\":{\"n\":\"4.2\"},\"end\":24967,\"start\":24951},{\"attributes\":{\"n\":\"4.3\"},\"end\":26293,\"start\":26275},{\"attributes\":{\"n\":\"4.4\"},\"end\":27578,\"start\":27557},{\"attributes\":{\"n\":\"4.5\"},\"end\":28643,\"start\":28610},{\"attributes\":{\"n\":\"4.6\"},\"end\":31505,\"start\":31491},{\"attributes\":{\"n\":\"4.7\"},\"end\":33099,\"start\":33065},{\"attributes\":{\"n\":\"4.8\"},\"end\":34159,\"start\":34088},{\"attributes\":{\"n\":\"5\"},\"end\":35472,\"start\":35460},{\"attributes\":{\"n\":\"6\"},\"end\":38823,\"start\":38813},{\"end\":39843,\"start\":39833},{\"end\":39948,\"start\":39938},{\"end\":39994,\"start\":39984},{\"end\":40208,\"start\":40198},{\"end\":40295,\"start\":40285},{\"end\":40413,\"start\":40403},{\"end\":40636,\"start\":40627},{\"end\":40881,\"start\":40872},{\"end\":41057,\"start\":41048}]", "table": "[{\"end\":40870,\"start\":40665},{\"end\":41046,\"start\":41003},{\"end\":41234,\"start\":41192}]", "figure_caption": "[{\"end\":39936,\"start\":39845},{\"end\":39982,\"start\":39950},{\"end\":40040,\"start\":39996},{\"end\":40196,\"start\":40043},{\"end\":40283,\"start\":40210},{\"end\":40401,\"start\":40297},{\"end\":40500,\"start\":40415},{\"end\":40625,\"start\":40503},{\"end\":40665,\"start\":40638},{\"end\":41003,\"start\":40883},{\"end\":41192,\"start\":41059}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":4275,\"start\":4267},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":10307,\"start\":10299},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":12544,\"start\":12536},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":12753,\"start\":12745},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":13313,\"start\":13305},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":13449,\"start\":13441},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":13627,\"start\":13619},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":31254,\"start\":31246},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":32567,\"start\":32559},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":33531,\"start\":33523}]", "bib_author_first_name": "[{\"end\":41794,\"start\":41787},{\"end\":41814,\"start\":41805},{\"end\":41826,\"start\":41820},{\"end\":42005,\"start\":41999},{\"end\":42007,\"start\":42006},{\"end\":42020,\"start\":42016},{\"end\":42034,\"start\":42028},{\"end\":42196,\"start\":42195},{\"end\":42211,\"start\":42204},{\"end\":42213,\"start\":42212},{\"end\":42234,\"start\":42225},{\"end\":42472,\"start\":42463},{\"end\":42484,\"start\":42478},{\"end\":42507,\"start\":42498},{\"end\":42518,\"start\":42513},{\"end\":42530,\"start\":42527},{\"end\":42822,\"start\":42816},{\"end\":42837,\"start\":42829},{\"end\":42842,\"start\":42838},{\"end\":42862,\"start\":42853},{\"end\":42881,\"start\":42872},{\"end\":42897,\"start\":42890},{\"end\":42913,\"start\":42908},{\"end\":43288,\"start\":43280},{\"end\":43302,\"start\":43296},{\"end\":43322,\"start\":43313},{\"end\":43334,\"start\":43328},{\"end\":43616,\"start\":43610},{\"end\":43628,\"start\":43624},{\"end\":43635,\"start\":43634},{\"end\":43649,\"start\":43643},{\"end\":43921,\"start\":43914},{\"end\":43923,\"start\":43922},{\"end\":43940,\"start\":43934},{\"end\":43951,\"start\":43947},{\"end\":44219,\"start\":44215},{\"end\":44238,\"start\":44232},{\"end\":44455,\"start\":44450},{\"end\":44468,\"start\":44460},{\"end\":44699,\"start\":44693},{\"end\":44716,\"start\":44707},{\"end\":44949,\"start\":44947},{\"end\":44960,\"start\":44955},{\"end\":44973,\"start\":44967},{\"end\":44987,\"start\":44979},{\"end\":44996,\"start\":44993},{\"end\":45008,\"start\":45001},{\"end\":45191,\"start\":45184},{\"end\":45206,\"start\":45204},{\"end\":45215,\"start\":45211},{\"end\":45223,\"start\":45220},{\"end\":45505,\"start\":45504},{\"end\":45521,\"start\":45516},{\"end\":45754,\"start\":45753},{\"end\":45766,\"start\":45763},{\"end\":45945,\"start\":45936},{\"end\":45960,\"start\":45954},{\"end\":46183,\"start\":46179},{\"end\":46195,\"start\":46189},{\"end\":46209,\"start\":46201},{\"end\":46219,\"start\":46215},{\"end\":46221,\"start\":46220},{\"end\":46240,\"start\":46232},{\"end\":46255,\"start\":46247},{\"end\":46532,\"start\":46524},{\"end\":46540,\"start\":46537},{\"end\":46555,\"start\":46547},{\"end\":46568,\"start\":46562},{\"end\":46577,\"start\":46575},{\"end\":46591,\"start\":46582},{\"end\":47246,\"start\":47239},{\"end\":47255,\"start\":47251},{\"end\":47265,\"start\":47260},{\"end\":47278,\"start\":47275},{\"end\":47512,\"start\":47505},{\"end\":47528,\"start\":47521},{\"end\":47538,\"start\":47533},{\"end\":47547,\"start\":47544},{\"end\":47558,\"start\":47555},{\"end\":47851,\"start\":47845},{\"end\":47865,\"start\":47857},{\"end\":47879,\"start\":47871},{\"end\":47888,\"start\":47885},{\"end\":47903,\"start\":47896},{\"end\":48119,\"start\":48113},{\"end\":48133,\"start\":48129},{\"end\":48147,\"start\":48143},{\"end\":48161,\"start\":48156},{\"end\":48178,\"start\":48173},{\"end\":48191,\"start\":48186},{\"end\":48193,\"start\":48192},{\"end\":48207,\"start\":48201},{\"end\":48221,\"start\":48216},{\"end\":48613,\"start\":48611},{\"end\":48623,\"start\":48620},{\"end\":48911,\"start\":48908},{\"end\":48923,\"start\":48916},{\"end\":48937,\"start\":48930},{\"end\":49249,\"start\":49243},{\"end\":49259,\"start\":49254},{\"end\":49268,\"start\":49264},{\"end\":49285,\"start\":49276},{\"end\":49296,\"start\":49291},{\"end\":49298,\"start\":49297},{\"end\":49316,\"start\":49310},{\"end\":49339,\"start\":49332},{\"end\":49341,\"start\":49340},{\"end\":49355,\"start\":49349},{\"end\":49658,\"start\":49654},{\"end\":49668,\"start\":49663},{\"end\":49677,\"start\":49674},{\"end\":49687,\"start\":49682},{\"end\":49700,\"start\":49694},{\"end\":49880,\"start\":49874},{\"end\":49895,\"start\":49889},{\"end\":49910,\"start\":49904},{\"end\":49932,\"start\":49924},{\"end\":49942,\"start\":49941},{\"end\":49960,\"start\":49951},{\"end\":49962,\"start\":49961},{\"end\":50297,\"start\":50294},{\"end\":50309,\"start\":50304},{\"end\":50323,\"start\":50315},{\"end\":50336,\"start\":50331},{\"end\":50350,\"start\":50343},{\"end\":50363,\"start\":50356}]", "bib_author_last_name": "[{\"end\":41803,\"start\":41795},{\"end\":41818,\"start\":41815},{\"end\":41833,\"start\":41827},{\"end\":42014,\"start\":42008},{\"end\":42026,\"start\":42021},{\"end\":42042,\"start\":42035},{\"end\":42202,\"start\":42197},{\"end\":42223,\"start\":42214},{\"end\":42240,\"start\":42235},{\"end\":42248,\"start\":42242},{\"end\":42476,\"start\":42473},{\"end\":42496,\"start\":42485},{\"end\":42511,\"start\":42508},{\"end\":42525,\"start\":42519},{\"end\":42534,\"start\":42531},{\"end\":42827,\"start\":42823},{\"end\":42851,\"start\":42843},{\"end\":42870,\"start\":42863},{\"end\":42888,\"start\":42882},{\"end\":42906,\"start\":42898},{\"end\":42918,\"start\":42914},{\"end\":43294,\"start\":43289},{\"end\":43311,\"start\":43303},{\"end\":43326,\"start\":43323},{\"end\":43341,\"start\":43335},{\"end\":43622,\"start\":43617},{\"end\":43632,\"start\":43629},{\"end\":43641,\"start\":43636},{\"end\":43658,\"start\":43650},{\"end\":43663,\"start\":43660},{\"end\":43932,\"start\":43924},{\"end\":43945,\"start\":43941},{\"end\":43960,\"start\":43952},{\"end\":44230,\"start\":44220},{\"end\":44250,\"start\":44239},{\"end\":44458,\"start\":44456},{\"end\":44471,\"start\":44469},{\"end\":44705,\"start\":44700},{\"end\":44724,\"start\":44717},{\"end\":44953,\"start\":44950},{\"end\":44965,\"start\":44961},{\"end\":44977,\"start\":44974},{\"end\":44991,\"start\":44988},{\"end\":44999,\"start\":44997},{\"end\":45013,\"start\":45009},{\"end\":45202,\"start\":45192},{\"end\":45209,\"start\":45207},{\"end\":45218,\"start\":45216},{\"end\":45232,\"start\":45224},{\"end\":45514,\"start\":45506},{\"end\":45528,\"start\":45522},{\"end\":45532,\"start\":45530},{\"end\":45761,\"start\":45755},{\"end\":45771,\"start\":45767},{\"end\":45780,\"start\":45773},{\"end\":45952,\"start\":45946},{\"end\":45967,\"start\":45961},{\"end\":46187,\"start\":46184},{\"end\":46199,\"start\":46196},{\"end\":46213,\"start\":46210},{\"end\":46230,\"start\":46222},{\"end\":46245,\"start\":46241},{\"end\":46259,\"start\":46256},{\"end\":46535,\"start\":46533},{\"end\":46545,\"start\":46541},{\"end\":46560,\"start\":46556},{\"end\":46573,\"start\":46569},{\"end\":46580,\"start\":46578},{\"end\":46596,\"start\":46592},{\"end\":47249,\"start\":47247},{\"end\":47258,\"start\":47256},{\"end\":47273,\"start\":47266},{\"end\":47282,\"start\":47279},{\"end\":47519,\"start\":47513},{\"end\":47531,\"start\":47529},{\"end\":47542,\"start\":47539},{\"end\":47553,\"start\":47548},{\"end\":47563,\"start\":47559},{\"end\":47855,\"start\":47852},{\"end\":47869,\"start\":47866},{\"end\":47883,\"start\":47880},{\"end\":47894,\"start\":47889},{\"end\":47907,\"start\":47904},{\"end\":48127,\"start\":48120},{\"end\":48141,\"start\":48134},{\"end\":48154,\"start\":48148},{\"end\":48171,\"start\":48162},{\"end\":48184,\"start\":48179},{\"end\":48199,\"start\":48194},{\"end\":48214,\"start\":48208},{\"end\":48232,\"start\":48222},{\"end\":48618,\"start\":48614},{\"end\":48629,\"start\":48624},{\"end\":48914,\"start\":48912},{\"end\":48928,\"start\":48924},{\"end\":48945,\"start\":48938},{\"end\":48953,\"start\":48947},{\"end\":49252,\"start\":49250},{\"end\":49262,\"start\":49260},{\"end\":49274,\"start\":49269},{\"end\":49289,\"start\":49286},{\"end\":49308,\"start\":49299},{\"end\":49330,\"start\":49317},{\"end\":49347,\"start\":49342},{\"end\":49362,\"start\":49356},{\"end\":49661,\"start\":49659},{\"end\":49672,\"start\":49669},{\"end\":49680,\"start\":49678},{\"end\":49692,\"start\":49688},{\"end\":49704,\"start\":49701},{\"end\":49887,\"start\":49881},{\"end\":49902,\"start\":49896},{\"end\":49922,\"start\":49911},{\"end\":49939,\"start\":49933},{\"end\":49949,\"start\":49943},{\"end\":49976,\"start\":49963},{\"end\":49983,\"start\":49978},{\"end\":50302,\"start\":50298},{\"end\":50313,\"start\":50310},{\"end\":50329,\"start\":50324},{\"end\":50341,\"start\":50337},{\"end\":50354,\"start\":50351},{\"end\":50367,\"start\":50364}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":11212020},\"end\":41978,\"start\":41716},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":46939182},\"end\":42148,\"start\":41980},{\"attributes\":{\"id\":\"b2\"},\"end\":42385,\"start\":42150},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":4900015},\"end\":42757,\"start\":42387},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":17891422},\"end\":43200,\"start\":42759},{\"attributes\":{\"doi\":\"arXiv:1412.3555\",\"id\":\"b5\"},\"end\":43561,\"start\":43202},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":8642370},\"end\":43861,\"start\":43563},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":4755450},\"end\":44189,\"start\":43863},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":1915014},\"end\":44385,\"start\":44191},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":196177434},\"end\":44597,\"start\":44387},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":5808102},\"end\":44885,\"start\":44599},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":50766897},\"end\":45182,\"start\":44887},{\"attributes\":{\"id\":\"b12\"},\"end\":45458,\"start\":45184},{\"attributes\":{\"doi\":\"arXiv:1412.6980\",\"id\":\"b13\"},\"end\":45685,\"start\":45460},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":3144218},\"end\":45900,\"start\":45687},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":16156203},\"end\":46089,\"start\":45902},{\"attributes\":{\"id\":\"b16\"},\"end\":46461,\"start\":46091},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":13256064},\"end\":47154,\"start\":46463},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":3508727},\"end\":47436,\"start\":47156},{\"attributes\":{\"doi\":\"arXiv:1812.09430\",\"id\":\"b19\"},\"end\":47771,\"start\":47438},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":14006234},\"end\":48084,\"start\":47773},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":13756489},\"end\":48507,\"start\":48086},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":49567896},\"end\":48860,\"start\":48509},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":11076030},\"end\":49163,\"start\":48862},{\"attributes\":{\"id\":\"b24\"},\"end\":49594,\"start\":49165},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":2023817},\"end\":49861,\"start\":49596},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":4870287},\"end\":50231,\"start\":49863},{\"attributes\":{\"doi\":\"CoRR abs/1812.08434\",\"id\":\"b27\"},\"end\":50561,\"start\":50233}]", "bib_title": "[{\"end\":41785,\"start\":41716},{\"end\":41997,\"start\":41980},{\"end\":42461,\"start\":42387},{\"end\":42814,\"start\":42759},{\"end\":43608,\"start\":43563},{\"end\":43912,\"start\":43863},{\"end\":44213,\"start\":44191},{\"end\":44448,\"start\":44387},{\"end\":44691,\"start\":44599},{\"end\":44945,\"start\":44887},{\"end\":45751,\"start\":45687},{\"end\":45934,\"start\":45902},{\"end\":46522,\"start\":46463},{\"end\":47237,\"start\":47156},{\"end\":47843,\"start\":47773},{\"end\":48111,\"start\":48086},{\"end\":48609,\"start\":48509},{\"end\":48906,\"start\":48862},{\"end\":49652,\"start\":49596},{\"end\":49872,\"start\":49863}]", "bib_author": "[{\"end\":41805,\"start\":41787},{\"end\":41820,\"start\":41805},{\"end\":41835,\"start\":41820},{\"end\":42016,\"start\":41999},{\"end\":42028,\"start\":42016},{\"end\":42044,\"start\":42028},{\"end\":42204,\"start\":42195},{\"end\":42225,\"start\":42204},{\"end\":42242,\"start\":42225},{\"end\":42250,\"start\":42242},{\"end\":42478,\"start\":42463},{\"end\":42498,\"start\":42478},{\"end\":42513,\"start\":42498},{\"end\":42527,\"start\":42513},{\"end\":42536,\"start\":42527},{\"end\":42829,\"start\":42816},{\"end\":42853,\"start\":42829},{\"end\":42872,\"start\":42853},{\"end\":42890,\"start\":42872},{\"end\":42908,\"start\":42890},{\"end\":42920,\"start\":42908},{\"end\":43296,\"start\":43280},{\"end\":43313,\"start\":43296},{\"end\":43328,\"start\":43313},{\"end\":43343,\"start\":43328},{\"end\":43624,\"start\":43610},{\"end\":43634,\"start\":43624},{\"end\":43643,\"start\":43634},{\"end\":43660,\"start\":43643},{\"end\":43665,\"start\":43660},{\"end\":43934,\"start\":43914},{\"end\":43947,\"start\":43934},{\"end\":43962,\"start\":43947},{\"end\":44232,\"start\":44215},{\"end\":44252,\"start\":44232},{\"end\":44460,\"start\":44450},{\"end\":44473,\"start\":44460},{\"end\":44707,\"start\":44693},{\"end\":44726,\"start\":44707},{\"end\":44955,\"start\":44947},{\"end\":44967,\"start\":44955},{\"end\":44979,\"start\":44967},{\"end\":44993,\"start\":44979},{\"end\":45001,\"start\":44993},{\"end\":45015,\"start\":45001},{\"end\":45204,\"start\":45184},{\"end\":45211,\"start\":45204},{\"end\":45220,\"start\":45211},{\"end\":45234,\"start\":45220},{\"end\":45516,\"start\":45504},{\"end\":45530,\"start\":45516},{\"end\":45534,\"start\":45530},{\"end\":45763,\"start\":45753},{\"end\":45773,\"start\":45763},{\"end\":45782,\"start\":45773},{\"end\":45954,\"start\":45936},{\"end\":45969,\"start\":45954},{\"end\":46189,\"start\":46179},{\"end\":46201,\"start\":46189},{\"end\":46215,\"start\":46201},{\"end\":46232,\"start\":46215},{\"end\":46247,\"start\":46232},{\"end\":46261,\"start\":46247},{\"end\":46537,\"start\":46524},{\"end\":46547,\"start\":46537},{\"end\":46562,\"start\":46547},{\"end\":46575,\"start\":46562},{\"end\":46582,\"start\":46575},{\"end\":46598,\"start\":46582},{\"end\":47251,\"start\":47239},{\"end\":47260,\"start\":47251},{\"end\":47275,\"start\":47260},{\"end\":47284,\"start\":47275},{\"end\":47521,\"start\":47505},{\"end\":47533,\"start\":47521},{\"end\":47544,\"start\":47533},{\"end\":47555,\"start\":47544},{\"end\":47565,\"start\":47555},{\"end\":47857,\"start\":47845},{\"end\":47871,\"start\":47857},{\"end\":47885,\"start\":47871},{\"end\":47896,\"start\":47885},{\"end\":47909,\"start\":47896},{\"end\":48129,\"start\":48113},{\"end\":48143,\"start\":48129},{\"end\":48156,\"start\":48143},{\"end\":48173,\"start\":48156},{\"end\":48186,\"start\":48173},{\"end\":48201,\"start\":48186},{\"end\":48216,\"start\":48201},{\"end\":48234,\"start\":48216},{\"end\":48620,\"start\":48611},{\"end\":48631,\"start\":48620},{\"end\":48916,\"start\":48908},{\"end\":48930,\"start\":48916},{\"end\":48947,\"start\":48930},{\"end\":48955,\"start\":48947},{\"end\":49254,\"start\":49243},{\"end\":49264,\"start\":49254},{\"end\":49276,\"start\":49264},{\"end\":49291,\"start\":49276},{\"end\":49310,\"start\":49291},{\"end\":49332,\"start\":49310},{\"end\":49349,\"start\":49332},{\"end\":49364,\"start\":49349},{\"end\":49663,\"start\":49654},{\"end\":49674,\"start\":49663},{\"end\":49682,\"start\":49674},{\"end\":49694,\"start\":49682},{\"end\":49706,\"start\":49694},{\"end\":49889,\"start\":49874},{\"end\":49904,\"start\":49889},{\"end\":49924,\"start\":49904},{\"end\":49941,\"start\":49924},{\"end\":49951,\"start\":49941},{\"end\":49978,\"start\":49951},{\"end\":49985,\"start\":49978},{\"end\":50304,\"start\":50294},{\"end\":50315,\"start\":50304},{\"end\":50331,\"start\":50315},{\"end\":50343,\"start\":50331},{\"end\":50356,\"start\":50343},{\"end\":50369,\"start\":50356}]", "bib_venue": "[{\"end\":41839,\"start\":41835},{\"end\":42050,\"start\":42044},{\"end\":42193,\"start\":42150},{\"end\":42554,\"start\":42536},{\"end\":42931,\"start\":42920},{\"end\":43278,\"start\":43202},{\"end\":43692,\"start\":43665},{\"end\":44011,\"start\":43962},{\"end\":44270,\"start\":44252},{\"end\":44479,\"start\":44473},{\"end\":44730,\"start\":44726},{\"end\":45021,\"start\":45015},{\"end\":45310,\"start\":45234},{\"end\":45502,\"start\":45460},{\"end\":45786,\"start\":45782},{\"end\":45976,\"start\":45969},{\"end\":46177,\"start\":46091},{\"end\":46735,\"start\":46598},{\"end\":47288,\"start\":47284},{\"end\":47503,\"start\":47438},{\"end\":47915,\"start\":47909},{\"end\":48283,\"start\":48234},{\"end\":48642,\"start\":48631},{\"end\":48993,\"start\":48955},{\"end\":49241,\"start\":49165},{\"end\":49716,\"start\":49706},{\"end\":50034,\"start\":49985},{\"end\":50292,\"start\":50233},{\"end\":46859,\"start\":46737}]"}}}, "year": 2023, "month": 12, "day": 17}