{"id": 233967791, "updated": "2023-10-19 07:47:28.282", "metadata": {"title": "Multi-path dilated convolution network for haze and glow removal in nighttime images", "authors": "[{\"first\":\"Shiba\",\"last\":\"Kuanar\",\"middle\":[]},{\"first\":\"Dwarikanath\",\"last\":\"Mahapatra\",\"middle\":[]},{\"first\":\"Monalisa\",\"last\":\"Bilas\",\"middle\":[]},{\"first\":\"K.\",\"last\":\"Rao\",\"middle\":[\"R.\"]}]", "venue": "The Visual Computer", "journal": "The Visual Computer", "publication_date": {"year": 2021, "month": 2, "day": 16}, "abstract": "In this paper, we address the single-image haze removal problem in nighttime scenes. The night haze removal is a severely ill-posed problem due to the presence of various visible night light sources with varying colors and non-uniform illumination. These light sources are of different shapes and introduce a noticeable amount of glow in the night scenes. To overcome these effects, we introduce a deep learning-based DeGlow\u2013DeHaze iterative model which accounts for varying colors and glows. The proposed model is a linear combination of three terms: the direct transmission attenuation, airlight and glow. First, a multi-path dilated convolution DeGlow network is introduced to interactively learn the local features with different reception fields and reduce the glow effect. The glow term is estimated by a binary mask that informs the location of the illumination source. As a result, the nighttime image is only left with only direct transmission and airlight terms. Finally, a separate post-processing DeHaze network is included to remove the haze effect from the reduced glow image. For our model training, we collected the night hazy images from internal and external resources, synthesized transmission maps from the NYU depth datasets, and consequently restored the haze-free images. The quantitative and qualitative evaluations show the effectiveness of our model on several real and synthetic images and compare our results with existing night haze models. The experimental results demonstrate that our multi-path CNN model outperforms other state-of-the-art methods in terms of PSNR (19.25 dB), SSIM (0.9958) evaluation parameters and computation time.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": "3129534753", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/vc/KuanarMBR22", "doi": "10.1007/s00371-021-02071-z"}}, "content": {"source": {"pdf_hash": "0674b3c92caec937fb7ad68e25a07612c916578c", "pdf_src": "SpringerNature", "pdf_uri": null, "oa_url_match": false, "oa_info": {"license": null, "open_access_url": "https://link.springer.com/content/pdf/10.1007/s00371-021-02071-z.pdf", "status": "BRONZE"}}, "grobid": {"id": "3d649ca6832e7f0a77b80aff3ac2dfa9987ce0fe", "type": "plain-text", "url": "s3://ai2-s2-science-parse-plus-prod/parse-results/s2orc_worker/0674b3c92caec937fb7ad68e25a07612c916578c.txt", "contents": "\nMulti-path dilated convolution network for haze and glow removal in nighttime images\n2022\n\nShiba Kuanar \nDwarikanath Mahapatra \n\u00b7 Monalisa Bilas \n\u00b7 K R Rao \nMulti-path dilated convolution network for haze and glow removal in nighttime images\n\nThe Visual Computer\n38202210.1007/s00371-021-02071-zAccepted: 20 January 2021 / Published online: 16 February 2021O R I G I N A L A R T I C L ECNN \u00b7 DeGlow \u00b7 DeHaze \u00b7 Depth \u00b7 Dilated convolution\nIn this paper, we address the single-image haze removal problem in nighttime scenes. The night haze removal is a severely ill-posed problem due to the presence of various visible night light sources with varying colors and non-uniform illumination. These light sources are of different shapes and introduce a noticeable amount of glow in the night scenes. To overcome these effects, we introduce a deep learning-based DeGlow-DeHaze iterative model which accounts for varying colors and glows. The proposed model is a linear combination of three terms: the direct transmission attenuation, airlight and glow. First, a multi-path dilated convolution DeGlow network is introduced to interactively learn the local features with different reception fields and reduce the glow effect. The glow term is estimated by a binary mask that informs the location of the illumination source. As a result, the nighttime image is only left with only direct transmission and airlight terms. Finally, a separate post-processing DeHaze network is included to remove the haze effect from the reduced glow image. For our model training, we collected the night hazy images from internal and external resources, synthesized transmission maps from the NYU depth datasets, and consequently restored the haze-free images. The quantitative and qualitative evaluations show the effectiveness of our model on several real and synthetic images and compare our results with existing night haze models. The experimental results demonstrate that our multi-path CNN model outperforms other state-of-the-art methods in terms of PSNR (19.25 dB), SSIM (0.9958) evaluation parameters and computation time.\n\nIntroduction\n\nHaze is an atmospheric phenomenon where mist, fog, dew, dust and other tiny particles obscure the atmosphere clarity and reduce the contrast of daytime or nighttime images. The above degradation is mainly due to light scattering phenomena in the atmosphere. The aerosols floating in the atmosphere deflect the light from its original course of propagation. As a result, the multiple reflected light rays scatter out to all directions and attenuate the screen reflection with distance. Therefore, the light rays from light sources scat-B Shiba Kuanar shiba.kuanar@mavs.uta.edu 1 Electrical Engineering, University of Texas at Arlington, Arlington, TX, USA 2 Inception Institute of Artificial Intelligence, Abu Dhabi, United Arab Emirates 3 Information Systems, University of Texas at Dallas, Richardson, TX, USA ter into the line-of-sight of the camera sensor, create airlight or veiling light ( Fig. 1) and wash out scene visibility. These combined scattering effects adversely affect scene visibility and impacts the subsequent low-level computer vision processing and computational photography applications.\n\nIn recent years, numerous daytime haze removal models have been proposed to address the hazy image visibility enhancement. The key to their success mostly relies on the correct estimation of various image priors and atmospheric light. The standard haze model described by Middleton in [1,2] illustrates the hazing process as a linear combination of airlight [3] and direct transmission. The direct transmission represents the scene reflection whose intensity reduces by the scattering out process. Alternatively, the airlight represents intensity resulted from the scattering in process of the light sources present in the surrounding atmosphere. Therefore, the transmission light conveys a fraction of the scene reflection and reaches the camera. Besides that, most of the daytime haze models assume that the atmospheric light present in the input image can be estimated by the brightest Fig. 1 Block-diagram of proposed nighttime haze base model. Airlight: ambient light reflected from atmospheric objects and aligned into line of sight. The dark circular structure on image represents the Glow effect of light sources image region with a strong approximation. After estimating the atmospheric light, the daytime haze methods calculate the transmission light by using various cues such as dark channel [4], local contrast [5], image fusion [6] and statistical independence between the albedo and shading [7]. The main implementation differences between these methods are due to various cues incorporated with transmission light estimations.\n\nThe effectiveness of these daytime haze methods is not well demonstrated to correct the nighttime scenes. The main reason might be that the daytime haze model priors do not hold well for the complex night scenes. The night scenes commonly have diverse colored light sources, e.g., building, vehicle, street lights, etc. which results in non-uniform illumination. These illuminations make the ambient light estimation inaccurate and cause the image priors to become invalid. Besides that, the night sources introduce more brightness to existing atmospheric light, boosts intensity and causes a prominent glow to the scene (Fig. 1). The atmospheric light in the night scenes is not assumed to be globally uniform and cannot be calculated from the brightest region of the night image. As a result, the atmospheric light approximation can differ significantly from that of the brightest intensity in the scene. Consequently, we normalize the input image with reference to the brightest region intensity. The normalization process then introduced a prominent color shift in the input image. Our main contributions are summarized as follows. Contribution: We acknowledge the nighttime scene dehaze problem as an ill-posed problem and dissociate the glow effects from images. Therefore, a systematic analysis is required to incorporate a CNN-based night haze model that includes the glow effect in addition to airlight and the direct transmission. In brief, the important contributions of our paper are summarized below.\n\n-A new DeGlow-DeHaze haze model is included to optimize in an end-to-end framework and embeds different sub-modules. The network allows us to estimate the transmission map, atmospheric light, glow map and dehazed image in a joint fashion. The sub-modules of the glow map include: (1) glow mask detection, (2) glow estimation and (3) glow removed haze image. -Our proposed contextual dilated network enlarges the receptive field and retrieves local contextual features on each iteration. The extracted features are enhanced progressively in each recurrence by aggregating information from several dilated convolutions. -The dilated network helps to boost glow localization in circumstances where targets are highly crowded with huge illumination variations. Our estimated scene reflection shows that it has better image visibility with reduced haze and glow effect and does not suffer much from color shifts.\n\nThe rest of the paper is organized as follows. Section 2 describes the related works and reviews the recent heuristic learning-based approaches for image dehazing. Section 3 presents an overview of the nighttime haze model design and introduces the CNN architecture with a dilated network for glow, haze removal and model training. Section 4 outlines the data preparation and model training details. Section 5 describes the experimental results on image datasets, outlines various evaluation trade-offs and reports the results. Finally, Sect. 6 concludes the paper.\n\n\nRelated work\n\nIn recent years, many approaches have been proposed in the literature to solve the conventional ill-posed hazing effect from a single daytime image [4,5,[7][8][9][10][11]. These heuristic methods use the standard haze model described in [3] and estimate the atmospheric light from the brightest region of an input image. He et al. [4] proposed the famous dark channel prior to estimating the depth map and achieved better dehaze results. Tan et al. [5] produced haze-free image by maximizing the contrast of the image, but that approach suffered from color distortions. Zhu et al. [12] created a linear model, esti-mated the scene depth of a hazy image with color attenuation priors and used a supervised learning method to evaluate the model parameters. With haze image depth map, they estimated the transmission map, restored the scene radiance and effectively removed the haze from a single image. Meng et al. [10] proposed a practical regularization method to restore the haze-free images by exploring the boundary constraints on the transmission function. Combined with a weighted L 1 norm, the optimization problem had a closed-form solution in each iteration by using variable splitting tricks. As a result, the proposed algorithm was able to restore a high-quality haze-free image with better colors and fine image details. Based on the color lines pixel regularity in natural images, Fattal et al. [7] presented a single-image dehazing method. He derived a local Gaussian Markov random field model that considers the hazy scene regularity and estimated the scene transmission. To improve the dehaze quality, Nishino et al. [13] introduced a novel Bayesian probabilistic method that defogs the single foggy image by fully leveraging their latent statistical structures. The algorithm models the input image with a factorial Markov random field in which the scene albedo and depth are assumed as two statistically independent latent layers and jointly estimate the priors. Kim et al. [14] introduced a dehaze algorithm based on optimized contrast enhancement and proposed a hierarchical quad-tree subdivision search to determine the transmission values. The block-wise contrast was maximized by minimizing information loss due to pixel truncation. Later they extended the algorithm to videos by adding the temporal coherence measures.\n\nMore recently, several machine learning techniques such as random forest regression, decision tree and convolutional neural networks have been proposed in the domain of image dehazing. Tang et al. [8] introduced a random forest model and investigated different haze-relevant features to identify the best feature combinations for image dehazing. Cai et al. [15] adopted a CNN-based DehazeNet architecture and improved the quality of the recovered haze-free image. Most recently, Ren et al. [16] proposed a multi-layer neural network to learn the mapping between hazy images. Though these CNN-based techniques achieve better performance over the conventional haze removal methods, they limit their capabilities by learning a mapping between the transmission maps and input hazy images. This is mainly due to the fact that the haze models assume a constant atmospheric light.\n\nHowever, these daytime dehaze methods may not be applicable for night hazy images due to non-uniform and multicolored illumination during nighttime. There has been a relatively small number of published methods about night haze removal in the past decade. Pei and Lee [17] proposed a color transfer method on a separate pre-processed step and mapped colors of a night haze image onto a daytime haze image using a dark channel prior technique. Zhang et al. [18] proposed a nighttime dehazing method by including color correction, histogram stretching and gamma correction post-processing steps for final output image enhancement. Srinivasa et al. [19] analyzed the glow effect of light sources and modeled the glow effect as an atmospheric point spread function (APSF). Li et al. [20] modified the daytime haze model by adding an APSF component to the night glow effect and applied a layer separation algorithm to decompose glow from the input image. Recently Ancuti et al. [21] introduced a fusion-based approach to enhance the night hazy scene visibility. To the best of our knowledge, comparatively little attention has been provided to the CNN-based nighttime haze removal tasks. In this paper, a deep dilated CNN-based architecture is introduced to detect and remove the glow effect from the night scenes and produce a haze-free image with better visibility.\n\n\nNighttime Haze model\n\nIn this section, we briefly review the commonly used dehaze model equations and subsequently introduced a novel Deglow term into analysis that captures glow accumulation of having different shapes and directions. Unlike atmospheric light in daytime scenes, the nighttime images have the presence of visible multicolored light sources and their associated glow due to the scattering effect. As stated in Narasimhan et al. [19], the widely used daytime dehaze model assumes that the scattered atmosphere light captured by the camera is a linear combination of the airlight and direct transmission. They model the glow effect as an atmospheric point spread function. Motivated by this, we model our nighttime haze scenes by adding the glow effect into the slightly modified standard date-time haze model as presented in Eq. (1). Figure 1 displays the standard night haze model diagram with the presence of night light sources. In our model, the atmospheric airlight is assumed to be globally uniform and contributes to the brightness of the light. The direct transmission term describes the light traveling from object reflection and making its way to the camera image plane. In addition to airlight and direct transmission, the model also includes a glow term. The glow effect represents the light from artificial night sources, gets scattered multiple times from different directions and reaches the camera plane. These night light sources have varying colors and illumination and potentially contribute to the appearance of airlight. In a nighttime haze environment, the radiated lights from light sources scatter in all arbitrary directions and change smoothly in space. These scattered lights aggregate and lead to smoothly changing light. As a result, the active light sources generate glow on nighttime scenes with the presence of substantial atmospheric particles. We reviewed the recent night dehaze models [17,[19][20][21] and generalize to include glow terms in Fig. 2 Synthesized data, training and testing steps of our proposed nighttime single image \"DeGlow-DeHaze\" model. L(x) represents the atmospheric light, R(x) clear scene reflection, t(x) transmission map,\u011c represents binary mask indicating the region of visible glow spots and S k (x) term represents the shape and illumination direction of a glow source our night haze CNN model formulation. The model incorporates two terms: (1) glow detection and (2) glow removal, along with the daytime haze model described in [4,5,7,8]. Therefore, we formulate our night haze model equation as below:\nI (x) = Formulation for classic Daytime Haze model Direct transmission attenuation R(x) * t(x) + Airlight L(x) * (1 \u2212 t(x)) + Glow term n k=1 S k (x) * G Glow Contaminated Haze Image(1)\nIn the above equation, I (x) is an observed haze image at each pixel position x, and R(x) is a clear scene reflection in the absence of glow or haze particles. The transmission map t(x) = e \u2212\u03b2\u00b7d(x) indicates the portion of reflection that has not scattered out and reaches the camera sensor. Term \u03b2 is the scattering coefficient of the atmosphere and d represents the scene depth between the camera and the object. The term L(x) is the global atmospheric light and {L(x) \u00b7 (1 \u2212 t(x))} represents the particle veil (Airlight) induced by scattering in the process. We incorporated S k (x) and\u011c terms in Eq.\n\n(1) for our glow analysis. Each S k (x) term represents the shape and illumination direction of a glow source. The subscript k represents the overlapping glow numbers ranging from 1 to n, where n is the number of atmospheric glow sources. The variable\u011c indicates the visible glow spots on the image regions and takes a binary mask where 1: indicates glow region and 0: non-glow region. Separately modeling the glow terms\u011c and S k (x) provides two benefits: (i) facilitates additional information to detect glow regions and (ii) allows the network to act separately on glow and non-glow regions without affecting the background details of haze images.\n\n\nEquations for glow detection and removal\n\nThe light glow regions are highly heterogeneous and much denser than those of the background regions. Therefore, it is hard to model the glow effect with a uniform sparsitylevel assumption, which is needed for most of the existing sparsity-based techniques. In Eq. (2), the glow term needs to model both locations (image regions) and intensity map of glow spots. Therefore, it is hard for the existing methods to jointly localize and remove the number of glow streaks. To overcome these shortcomings, we introduce a generalized deglow model in Eq. (1). In the nighttime, the airlight obtains its energy from natural atmospheric lights and from active light sources. The strong light from light sources travels directly to the image, and some of that light manages to reach the camera sensor after collision with the surrounding objects [20]. Because of the above collision processes, light sources create their own presence in the scene and manifest themselves as glow. As a result, the glow detection and removal become a relevant part of night dehaze applications. Therefore, the night haze model equation in Eq. (1) can be re-written as:\nI (x) = J (x) + n k=1 S k (x) * G(2)\nIn the above equation,\nJ (x) = R(x) * t(x)+L(x) * (1 \u2212 t(x))\nis the night haze image without glow and n k=1 S k (x) * G is the newly included glow term. Based on the above dehaze equation, the deglow removal is regarded as a two-step separation problem. Our goal is to estimate the scene reflection R(x) for every input image pixel I (x) and recover the haze- Fig. 3 Our convolution neural network-based recurrent dilated network, for night haze and glow removal. In each recurrence (in the blue dash box), a multi-path network performs a joint glow detection and removal. The contextualized dilated network extracts glow features X t from the input night image I 0 (x). Then,\u011c t (binary image),\u015c t and\u0134 t are predicted to perform the joint glow detection, estimation and removal. The dilated network has two features: (I) a recurrent architecture to progressively refine the extracted features, (II) in each recursion the output features are concentrated from three convolution paths (P1, P2, P3) with different dilated factors and receptive fields free image. First, we detect the glow effect and subsequently remove the glow term from the input image by using our proposed recurrent dilated network as shown in Fig. 3. Later we decompose the glow image G(x) from I (x) and obtain the hazy image, i.e.,\nJ (x) = I (x) \u2212 G(x).\nFinally, a standard daytime dehaze model [15] is included to remove the haze effect from J (x) and obtain a balanced color image. Our end-to-end DeGlow-DeHaze framework calculates the transmission map t(x). To recover the dehazed image R(x), we separately estimate the atmospheric light L(x) from t(x) during the model testing (Fig. 2). We follow the steps described in [4,15] and calculate the atmosphere light L(x) by picking the top 0.1% darkest pixels in a transmission map t(x) [4]. Among the above pixels, one with the highest intensity in J (x) is selected as atmospheric light as shown in Fig. 2. \n\n\nContextual dilated network\n\nIn CNN models, the contextual information is augmented conventionally through the expansion of the receptive fields and filter size. One of the ways to achieve this objective is to increase the network depth. But the increase in depth structure decreases the computational efficiency and typically results in vanishing gradients. Alternatively, the enlargement of the kernel size likewise raises computational burden and training time. To overcome this problem, Yu and Koltun [22] proposed dilated convolutions for multi-scale context aggregation in semantic segmentation and show that the dilated convolution operation increases the image segmentation accuracy. Motivated by their work, we also proposed a multi-layer contextual dilated network for our nighttime image dehaze problem through multiple recurrences.\n\nThe dilated convolution network in our model learns the glow feature and aggregates contextual information at multiple scales [22,23]. The motivation of using the dilated convolutions is to support the exponentially expanding receptive fields without losing resolution and leverage more contextual information without losing the local details. Our network retrieves the contextual information in two steps: (1) a recurrent structure which provides an exponentially expanding receptive field on subsequent layers, and (2) in each recurrence the output features X t are obtained by aggregating the representations from three dilated convolution paths. Our model first transforms input night hazy images to a feature space through a series of convolutions (Fig. 3). The dilated convolution weighs the pixels with a step size equal to the dilated factor (DF) and increases the receptive field without losing resolution. Three dilated paths P1, P2 and P3 are shown in Fig. 3, and each consists of three convolutions with a kernel size of 3 \u00d7 3. The above path uses different DFs, i.e., DF = 1, DF = 2, DF = 3 and obtains their expanded receptive field as 7 \u00d7 7, 13 \u00d7 13 and 17 \u00d7 17, respectively [22].\n\n\nCNN-based recurrent DeGlow network\n\nOur model follows a fully convolutional network with filter sizes of 3 \u00d7 3 and uses dilated kernels to deliver the larger reception fields. A convolutional multi-task network is introduced to remove the glow effect in our model. Based on Eq. (2), our model solves an inverse ill-posed problem through recursive learning. As detailed in Fig. 3, our dilated convolution extracts the discriminative features, facilitates the glow removal from the haze image and finally calculates the transmission map t(x). Given the observed night glow image I (x), our goal is to estimate the J (x), S(x), G(x) terms which are ill-posed. Therefore, to make the problem well-posed and tractable, a joint probability of J (x), S(x), and G(x) is included by using the maximum-a-posteriori (MAP) estimation technique. So our MAP output maximizes the probability P(J , S, G | I ) \u221d P(I | J , S, G) \u00b7 P(J ) \u00b7 P(S) \u00b7 P(G), under the assumption that J , S, and G are independent as stated in [24] and [25]. With the algebraic manipulation in the negative log, we used the below energy minimization equation for our estimation:\nmin J ,S k ,R ||I \u2212 J \u2212\u015c k \u2212\u011c|| 2 2 +P j (J )+P s (\u015c k )+P g (\u011c)(3)\nHere, P j (J ), P s (\u015c k ), P g (\u011c) are enforced layer priors on J ,\u015c k (x) and\u011c, respectively. The priors implicitly included to regularize the network and learn from the training datasets. The estimations of J ,\u015c k (x), and\u011c are intrinsically correlated. Thus, the estimation of I (x) benefits from the recurrent S k and\u011c predictions. We first utilize a dilated network to extract the Glow features X t from the input image I 0 (x) as shown in Fig. 3. The intermediate loss components for priors are computed as follows: (1)L G is estimated by a 3 \u00d7 3 conv on X t vector, (ii)L S is predicted from two 3 \u00d7 3 convolutions on [X,\u011c] concatenation vector, and (iii) finallyL J is computed from a 3 \u00d7 3 conv on [X ,\u011c,\u015c k (x), I \u2212\u011c \u00d7\u015c k (x)] vector. The above three steps follow a continuous recursive glow removal process. In each iteration, the results from the three paths aggregate along with input features from the previous recurrence through a feedback path.\n\nOur recurrent model can be interpreted as a cascade of convolutional glow detection networks that performs progressive glow removal and recovers the image with increasingly better visibility. The blue dash box in Fig. 3 exhibits the recursive process of our network. On each recurrence, the residual image between I (x) and J (x) is generated and designated as f (.). Subsequently, glow detection and removal works as follows:\n[ t , G t , S t ] = f (I t ) t = I t \u2212 J t or J t = I t \u2212 t I t+1 = J t(4)\nIn Eq. (4), it is observed that the estimated glow mask G t and glow steak S t are not casted directly into the next recurrence. In Eq. (5), the term \u03c4 denotes the total number of iterations. In each iteration, the predicted residue f (I t ) accumulates and propagates to the final estimation by updating the I t and J t values. I 0 in Eq. (5) represents the initial input value and update to I t+1 in each training iteration (Fig. 3). The final estimation of J t term can be expressed as:\nJ (\u03c4 ) t = I 0 + \u03c4 k=1 t ,(5)\nSubsequently, the above process removes the glow spots based on the intermediate results from the previous steps. The complexity of the glow removal is reduced progressively in each iteration by enabling better estimation typically in the presence of heavy night light.\n\n\nDeGlow network\n\nLet F G (\u00b7), F S (\u00b7), and F J (\u00b7) denote the inverse recovery functions modeled by the learned network in Fig. 3 and, respectively, generate the output\u011c k ,\u015c k , J (x) from input I 0 (x). We use \u03b8 to represent the network weight and bias parameters, i.e., \u03b8 = {W , b} and n sets of data (I k , J k ,\u011c k ,\u015c k ) are included for our training, where set k varies from 1 to n. The loss function is parameterized by the \u03b8 term so that it jointly estimates G, S, and J based on glow image I . Finally, the model loss function expressed in the below equation form, and the individual component names superscribed on top of the distinct components:\nL(\u03b8 ) = 1 n n k=1 ( Direct error term ||I k \u2212 J k || 2 2 + \u03bb 1\nLoss term due to priors \n(||F S (I k , \u03b8) \u2212\u015c k || 2 ) + ||F J (I k , \u03b8) \u2212 J k || 2 )(log\u011c k,1 * \u011c k + log (1 \u2212\u011c k,2 )(1 \u2212 G k,2 ) ) where,\u011c k,m = exp {F S,m (I k , \u03b8)} 2 k=1 exp {F S,i (I k , \u03b8)} Glow region map expression , m \u2208 {1, 2}, binar y(6)\nAs the network works recursively, it introduces an additional time variable t to the above loss function L(\u03b8 ) in (3.4). As a result, our time-varying Loss function is represented as L(\u03b8 t , t). At time t = 0, L(\u03b8 0 , 0) is equal to L(\u03b8 0 ) and at t > 1, L(\u03b8 t , t) is equivalent to L(x\u03b8 ) which replaces I i and \u03b8 by I i,t and \u03b8 t , respectively. The I i,t is generated from the tth iterations of the process given by Eq. (4) with an initial value I i . Therefore, the total time-varying loss function L Iter is given by:\nL Iter (\u03b8 0 , ...\u03b8 \u03c4 ) = \u03c4 k=1 L(\u03b8 t , t).(7)\n\nDehazing with multi-scale CNN network\n\nAfter the glow effect is removed by our DeGlow model, the haziness still persists on its output J (x). To overcome these haze effects, a separate dehaze procedure is included as a post-processing technique. The dehaze procedure detects the bright region and enhances the contrast by reducing intensity. Our DeHaze model is based on the structure of the contextualized dilated framework and performed with one recurrence only, unlike multiple iterations in DeGlow framework. For our network training, we follow the steps discussed in the existing daytime haze model designed by Cai et al. [15]. The overall DeHaze network contains a cascaded dilated convolution and pooling layers with necessary nonlinear activation maps and jointly operates in an end-to-end framework. Dilated convolution exponentially increases the global view of the network with linear parameter accretion, learns the desired mapping with lower depth and captures more image clues. Therefore, it finds usage in dehaze applications that cares more about integrating knowledge on a wider context with less cost. The dilated filter learns the spatial information through activation maps, and down-sample the input image contents into better feature abstractions. The intermediate convolution layers act as a feature extractor, captures the primary object components and reduces the latent noise features. The features extracted on the contextualized dilated network (Fig. 3) are quite noisy. Therefore, we incorporated a few immediate convolution steps for feature de-noising, spatial feature mapping and feature enhancement layer for cleaning the low-level attributes. The model training is performed with the synthesized images and estimated the scene transmission map t(x) in Fig. 3 (second row and end). As a result, the DeHaze post-processing step suppresses the bright glow effects and enhances the image contrast and visibility.\n\n\nExperiments\n\nConventionally, it is computationally expensive to accumulate a vast amount of labeled datasets for the deep CNN model training. At the same time, there are no publicly available night haze datasets with pairs of night hazy images and their associated intermediate transmission maps. Consequently, we resort to synthesize the training data based on the physical haze formation model described in [16]. Besides that, we also gathered foggy and hazy images from publicly available sources with various file formats and quality and night glow images from the author at [20]. For our model parameter learning, we collected a diversified dataset that contains hundreds of haze images with different textures, object shapes, structures and colors. These hazy images not only capture people's daily life activities but also include natural topography and city landscapes. We believe that these diverse training samples will help to learn the filter weights efficiently in a dilated recurrent network.\n\n\nTraining data\n\nThe realistic training data generation is a major challenge for nighttime haze removal task where ground truth data cannot be easily collected. Nighttime haze and glow removal datasets are very rare. Alternatively, we gathered our datasets in three ways (1) created synthetic images (70%), (2) glowbased images through internet web scraping (10%) and ( from NYU depth dataset [26]. Given the clear image R(x) and ground truth depth, we synthesized the haze image using the physical model given in Eq. (1). For our validation, we synthesized a set of 2k hazy images from the Middlebury stereo database [27][28][29]. We generated the random atmospheric light L(t) = [t, t, t], where t \u2208 [0.5, 1.0]. Then we sampled three random scattering medium coefficients \u03b2 \u2208 [0.5, 1.5] for every image. We followed the radiative transfer equation on [19] and approximated the attenuation of night glow illumination using a negative exponential form as\u015c = exp \u2212q\u00d7d where variable q was the forward scattering parameter and constant d is represented as normalized distance between the light source and scene point. Since d was large, we considered the first-order Taylor series expansion and approximated it as (1 \u2212 d \u00d7 q). In our experiment, we took the values from q \u2208 [0.2, 0.9]. Overall, we had 45000 hazy images and transmission maps for the model training (5000 \u00d7 3 \u03b2_terms \u00d7 3 q_values) and re-sized images to a 320 \u00d7 240 resolution.\n\n\nTraining details\n\nWe use a recursive feedback method to train the DeGlow-DeHaze model. As explained in Eq. (1), we breakdown our problem into three sub-sections and accordingly formulated our loss function in Sect. 3.4. The loss function in Eq. (3.4) is non-convex due to the presence of priors. We optimize our scheme based on the regularization explained in [24,31,32].\n\nHere \u03bb 1 and \u03bb 2 are the regularization parameters used to balance the loss terms in Eq. 3.4. The loss function L(\u03b8 ) is minimized using stochastic gradient descent with standard back-propagation. The weight matrices of each layer are initialized by randomly drawing from a Gaussian distribution with mean = 0 and standard deviation = 0.0001. The weight matrices are updated in terms of learning rate and weight gradients. The Bayesian optimization was implemented to feed sets of hyper-parameters to the framework, iteratively optimized, evaluated their performance and finally selected the best hyper-parameter set for model training. The momentum parameter is set to 0.9. The batch size sets to 64 images, and the training was regulated by a weight decay of 0.001. The learning rate decreased by a factor of ten when the validation set accuracy stopped improving. Our implementation is derived from the publicly available python-based Tensorflow framework [33]. The training is performed on an stand-alone NVIDIA K40 GPU machine. The Multi-core training operation is carried out by splitting the training images into batches and parallely scheduling the task at each core. The network parameters converge after around twelve hundred iterations. Our entire training process took approximately eleven hours on our GPU system. In reality, training multi-layer CNN models from scratch is relatively rare because of inadequate annotated and labeled datasets. Alternatively, it is common to use a pre-train model on a smaller dataset and use it either as a fixed feature extractor or an initialization for various image analysis tasks. We also experienced a similar convergence problem during our model training and systematically investigated several transfer settings between our DeGlow-DeHaze architecture. First, the Deglow model is trained separately by our training datasets with a certain number of epochs and iteration. The trained weights are saved individually after each iteration. After completion of the Deglow network training, the Dehaze post-processing operation initialized. Usually, the features learned in different convolution layers and tasks are always common in nature. These feature patterns therefore can be reused during the fine-tuning process and converge the network a little faster. Therefore, our DeHaze model uses the same contextualized dilated framework designed for the DeGlow framework and follows a single iteration. This is because in first few interactions, the model captures universal features like blobs, corners, curves and edges that are rele- Fig. 6 Quantitative evaluation by using various Dehaze CNN models on the sampled synthetic images. The large SSIM [30] value of our model implies its closeness to the ground truth than others Fig. 7 Visual qualitative comparison of our \"DeGlow-DeHaze\" model w.r.t other DeHaze CNN models. Left and right most columns show the input real image and output, respectively. The presence of color and glow effect in haze images are reduced essentially and localized vant to our image enhancement problem. We want to keep those weights intact and focus on learning data specific features in the subsequent layers. The Dehaze model weights are initialized from the saved Deglow network weights, finetuned the layer weight parameters and followed the training procedure described in [15]. Finally, two separate networks are combined into a unified model and perform the image Deglow-Dehaze reconstruction task seen in Fig. 3.\n\n\nExperimental results\n\nTo verify the model performance, we evaluated the PSNR and SSIM metrics on test images, analyzed the convergence and compared it with existing methods in Table 1. A set of forty natural hazy glow images was randomly selected from the newly collected dataset and kept aside for our average runtime evaluation. We evaluated the time complexity results of our model, compared it with other recent night haze models and summarized in Table 2. All the execution time is computed at different image resolutions in the Keras TesorFlow framework and GPU mode only. One can notice from Table 2 that the Pie-and Lee's [17]-based dehaze approach has a time overhead among the five models in GPU mode. However, benefiting from the GPU acceleration, our DeGlow-DeHaze iterative model is faster (1.86 s/frame) than the Li at al. [20] (6.37 s/frame) and got a modest improvement compared to the Zhang at al. [18] performance (5.34 s/frame) and H. Zhang et al. [34] (5.84 s/frame). From the above analysis, we observe that the proposed DeGlow-DeHaze model network consumes less time in all network configurations and can be a holistic approach in terms of time complexity. However, the image dehaze reconstruction time did not meet the required real-time application requirements and need further careful optimization.\n\nGiven an input hazy nighttime image, the model objective is to show the importance of the glow decomposition from the hazy image, then process the haze image using a conventional daytime haze method and show the importance of varying atmospheric light. As described in Eqs. (1) and (2), the input image I (x) decomposed into binary-weighted glow image G(x) and nighttime haze image J (x). Additionally, we included Figs. 4 and 5 to display the output glow image G and haze image J effect, respectively, and compared our model performance. The dehazed results from our model indicates a better estimation of the transmission for the glow recovery (G) and haze restoration (J ). Our deglow result quality in Fig. 4 shows the less varying colors of the atmospheric night lights and similar to input image except the upper part of the street lamp light in the screen becomes dark. However, when the glow intensity and varying colors from number of nightlight sources are significantly visible, the color shift problem becomes more apparent (in Fig. 5). The back ground of the screen in Zhang et al. [18], Li et al. [20] become bright and faded its color to light blueish. On another note, our results shown in the right column of Figs. 4 and 5 retained the colors of the scenes to a greater extend.\n\n\nQualitative and quantitative comparison on real night images\n\nThe quality assessment for the reconstructed image are usually measured both in terms of the objective and subjective point of view. The standard objective measurements are performed mathematically by using pixel differences between a dehazed image compared to that of a reference image. These difference values usually provide the mathematical correctness of the measurement. To further evaluate our DeGlow-DeHaze model performance, we presented our results on both synthetic and real night images in Figs. 6 and 7, respectively. In our image dehaze analysis experiment, we evaluated our and other state-of-the-art methods and addressed the objective measurements in terms of two major quantitative criteria: peak signal-to-noise ratio (PSNR) and structure similarity (SSIM). Figure 6 shows the synthesized images with glow artifacts around light sources. Our approach was able to remove the glow artifacts considerably and restore the image with better color balance. We randomly collected real night images with illumination and glow effect, row-wise inspected the results in Fig. 8, and compared outputs with Zhang et al. [18] and Li et al. [20] respectively. The Zhang et al. method generated high intensity in some regions due to an additional post-processing step and introduced the blur effect at corners. Though Li et al. method was able to remove the night glow effect to a great extent, it could not handle color distortion well around the elliptical edge locations (Fig. 8). It generated fringing artifacts in the surrounding areas of light sources. On the other hand, our proposed approach was able to estimate the glow effect, normalize the color distortion and enhanced the visibility with subtle artifacts. The last row in Fig. 8 includes the Seattle Aquarium night image with bright light illumination at the center. It is observed that our model was able to reduce the illumination effect and color correction (sky region) substantially in the last row Moreover, we performed a quantitative evaluation using SSIM [30] on synthetic images and compared it with other CNN models in Table 3. Our method shows the highest SSIM index and implies that it is more close to the input ground truth. Besides that, we have shown the glow decomposition results with input real images on the left-most column in Fig. 7. The middle and right columns are showing the estimated haze images by various CNN models and our method, respectively. The presence of glow in haze images is reduced gradually along the row. Overall, our proposed algorithm outperforms other CNN models both on real-image cases. To generalize the model assessment, a systematic model training is required with a diversified datasets and will be targeted in our future work.\n\n\nAblation study of DeHaze model\n\nIn this section, we have demonstrated more ablation experiments from various perspectives to justify the design of our DeGlow-DeHaze method. To assess the effectiveness of the conjunction of network components, we conducted a detailed performance analysis and presented the result in Table 4. After the substantial glow effect is removed by our DeGlow dilated model, a standard dehaze method is included to remove the haze effect. To understand the DeHaze performance, other state-of-the-art daytime dehaze methods are included in our analysis. An ablation study was carried out to demonstrate the effectiveness of each dehaze model and evaluated the output results. Consequently, we come up with eleven networks with different components and listed them in the first column of  [34] and Zhang et al. [35] are tested. The experimental results are provided in Table (Net: 1 -11). Note that in Table 4, base Net \"1\" with all given network components, corresponding to DeHaze-DeGlow, achieves the best performance in terms of image dehaze reconstruction. One can note in Table 4 that the base Net enquote1 with all given network components, corresponding to the DeHaze-DeGlow model, achieves the best performance in terms of image dehaze reconstruction. Comparing Net-1 and Net-4 suggests that the \"Contextual Dilated Network\" plays a pivotal role in DeGlow model learning. The glow detection, estimation, removal probability map provides the low-label distortion information to the network and helps the converge faster with better reconstruction output.\n\n\nFailure case\n\nAlthough our model works well in large number of the test images, it fails to work in certain situations in which the images are taken in heavy fog or glow presence. One failure example is shown in Fig. 9 where the proposed scheme generates color distortions for objects such as roads and leaves. Another limitation of our algorithm is occlusion where a small-scene object is surrounded by a large object or the  object is hidden by some other scene parts. In such situations, our method failed and the output is shown in Fig. 9d (left to right). In the night haze environment, the light radiated from sources change smoothly in space except at occlusion positions and result in sudden changes between shade and bright parts. As a result, the object boundaries become very sparse in the whole image locations. In Fig. 9 d, one can observe that the light glows are merged behind the bus and blow out in street light locations rather than eliminated. In both cases, our model has failed to completely clear the glow effects, especially when the haze is moderately thick. In future work, we would like to address this problem by more advanced color constancy techniques [36,37], and other occlusion removal techniques.\n\n\nConclusion\n\nIn this paper, a deep learning-based iterative model is introduced to learn the glow effect from a nighttime scene. Based on this model, a multi-path dilated convolutional network is included that jointly detects and removes the scene glow. The glow regions are first detected by the DeGlow network and provide additional information for glow removal. To restore the images captured in night illumination, we introduced a recurrent network that progressively removes the Glow effect and embedded a DeHaze network to remove the atmospheric veils. The experimental evaluation of real and synthetic images demonstrates that our model outperforms the state-of-the-art methods in terms of PSNR and SSIM metrics and computation time. As a future direction, we would like to experiment on unsupervised generative models with  . 9 Failure cases of our method in night hazy image and color distortion with occlusion unlabeled datasets and analyze the performance in terms of various evaluation metrics.\n\nFig. 8\n8Visual\n\nTable 1\n1PSNR (dB) and SSIM results on the natural hazy images and show the comparison with several image dehazing techniques Our model result implies that it generally performs better in terms of two quantitative measuresAverage metrics \nHaze image \nPie and Lee's [17] \nZhang et al. [18] \nL ie ta l .[ 20] \nAncuti et al. [21] \nOur model \n\nPSNR \n14.32 \n14.92 \n16.23 \n17.41 \n18.22 \n19.25 \n\nSSIM \n0.991 \n0.9927 \n0.9925 \n0.9934 \n0.9941 \n0.9958 \n\n\n\nTable 2\n2Average runtime comparisons in seconds per image resolution on various night haze modelsImage resolution \nPie and Lee's [17] \nAncuti et al. [21] \nZhang et al. [18] \nLi et al. [20] \nZhang et al. [34] \nOur model \n\n427 \u00d7 370 \n10.61 \n7.43 \n5.34 \n6.37 \n5.84 \n1.86 \n\n640 \u00d7 480 \n19.49 \n14.62 \n9.03 \n9.55 \n11.36 \n2.06 \n\n\u2212 \u03bb 2 \n\nLoss term due to Glow (binary) \n\n\n\nTable 4 .\n4The output of DeGlow was used as an input to each of the selected DeHaze models. For each Ablation experiments, we fixed our original DeGlow network output and evaluated the computation time, PSNR and SSIM parameter on test datasets. To demonstrate the effectiveness of DeHaze network, eight state-of-the-art DeHaze architectures: Cai et al. [15], He et al.[4], Tang et al. [8], Ren et al. [16], Fattal et al. [7], Tan et al. [5], Zhang et al.\n\nTable 3\n3Average PSNR and SSIM values of dehazed results on synthetic dataset and compared with state-of-the-art nighttime dehaze methodsAverage metrics \nHe et al. [4] \nZhang et al. [18] \nRen et al. [16] \nLi et al. [20] \nCai et al. [15] \nZhang et al. [34] \nOur model \n\nPSNR \n14.31 \n14.88 \n26.13 \n17.46 \n19.14 \n13.19 \n19.36 \n\nSSIM \n0.983 \n0.991 \n0.9922 \n0.9937 \n0.9956 \n0.9851 \n0.9982 \n\n\n\nTable 4\n4Ablation study on different network component combinations in DeGlow-DeHaze model and performance evaluation on the test datasetNet \nDeGlow model steps \n\n\nPublisher's Note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.\nVision Through the Atmosphere. W E K Middleton, University of Toronto PressTorontoMiddleton, W.E.K.: Vision Through the Atmosphere. University of Toronto Press, Toronto (1952)\n\nE J Mccartney, Optics of the Atmosphere: Scattering by Molecules and Particles. New YorkWileyMcCartney, E.J.: Optics of the Atmosphere: Scattering by Molecules and Particles. Wiley, New York (1976)\n\nH Koschmieder, Theorie der horizontalen Sichtweite: Kontrast und Sichtweite. Keim & Nemnich. MunichKoschmieder, H.: Theorie der horizontalen Sichtweite: Kontrast und Sichtweite. Keim & Nemnich, Munich (1925)\n\nSingle image haze removal using dark channel Prio. K He, J Sun, X Tang, IEEE Computer Vision and Pattern Recognition (CVPR). Miami, USAHe, K., Sun, J., Tang, X.: Single image haze removal using dark channel Prio. In: IEEE Computer Vision and Pattern Recognition (CVPR), 1956-1963, Miami, USA (Aug. 2009)\n\nVisibility in bad weather from a single image. R T Tan, IEEECVPR, AK, USATan, R.T.: Visibility in bad weather from a single image. In: IEEE, CVPR, AK, USA (2008)\n\nSingle image dehazing by multi-scale fusion. C O Ancuti, C Ancuti, IEEE Trans. Image Process. (TIP). 22Ancuti, C.O., Ancuti, C.: Single image dehazing by multi-scale fusion. IEEE Trans. Image Process. (TIP) 22, 3271-3282 (2013)\n\nDehazing using color-lines. R Fattal, ACM Trans. Graph. 341Fattal, R.: Dehazing using color-lines. ACM Trans. Graph. 34, 1 (2014)\n\nInvestigating haze relevant features in a learning framework for image dehazing. K Tang, J Yang, J Wang, IEEE Computer Vision and Pattern Recognition. Columbus, OhioTang, K., Yang, J., Wang, J.: Investigating haze relevant features in a learning framework for image dehazing. In: IEEE Computer Vision and Pattern Recognition, 2995-3002. Columbus, Ohio (2014)\n\nMarkov random field model for single image defogging. L Caraffa, J P Tarel, IEEE Intelligent Vehicles Symposium. Gold Coast, AustraliaCaraffa, L., Tarel, J.P.: Markov random field model for single image defogging. In: IEEE Intelligent Vehicles Symposium, Gold Coast, Australia (2013)\n\nEfficient image dehazing with boundary constraint and contextual regularization. G Meng, Y Wang, J Duan, S Xiang, C Pan, IEEEWashington, DC, USAMeng, G., Wang, Y., Duan, J., Xiang, S., Pan, C.: Efficient image dehazing with boundary constraint and contextual regularization. In: IEEE, ICCV, pp. 617-624, Washington, DC, USA (Dec. 2013)\n\nRestoring an image taken through a window covered with dirt or rain. D Eigen, D Krishnan, R Fergus, IEEEAustralia, SydneyEigen, D., Krishnan, D., Fergus, R.: Restoring an image taken through a window covered with dirt or rain. In: IEEE, ICCV, pp. 633-640. Australia, Sydney (2013)\n\nA fast single image haze removal algorithm using color attenuation prior. Q Zhu, J Mai, L Shao, IEEE Trans. Image Process. 2Zhu, Q., Mai, J., Shao, L.: A fast single image haze removal algo- rithm using color attenuation prior. IEEE Trans. Image Process. 2, 3522-3533 (2015)\n\nBayesian defogging. K Nishino, L Kratz, S Lombardi, Int. J. Comput. Vis. 983Nishino, K., Kratz, L., Lombardi, S.: Bayesian defogging. Int. J. Comput. Vis. 98(3), 263-278 (2012)\n\nOptimized contrast enhancement for real-time image and video dehazing. J H Kim, W D Jang, J Y Sim, C S Kim, J. Vis. Commun. Image Represent. 24Kim, J.H., Jang, W.D., Sim, J.Y., Kim, C.S.: Optimized contrast enhancement for real-time image and video dehazing. J. Vis. Com- mun. Image Represent. 24, 410-425 (2013)\n\nDehazeNet: an endto-end system for single image haze removal. B Cai, X Xu, K Jia, C Qing, D Tao, IEEE Trans. Image Process. Cai, B., Xu, X., Jia, K., Qing, C., Tao, D.: DehazeNet: an end- to-end system for single image haze removal. IEEE Trans. Image Process. 2016, 5187-5198 (2016)\n\nW Ren, S Liu, H Zhang, J Pan, X Cao, M.-H Yang, Single image dehazing via multi-scale convolutional neural networks. In: IEEE European Conference on Computer Vision (ECCV). AmsterdamRen, W., Liu, S., Zhang, H., Pan, J., Cao, X., Yang, M.-H.: Single image dehazing via multi-scale convolutional neural networks. In: IEEE European Conference on Computer Vision (ECCV), pp. 154- 169, Amsterdam (Oct. 2016)\n\nNighttime haze removal using color transfer pre-processing and dark channel prior. S.-C Pei, T.-Y Lee, IEEEOrlando, USAPei, S.-C., Lee, T.-Y.: Nighttime haze removal using color transfer pre-processing and dark channel prior. In: IEEE, ICIP, Orlando, USA (Oct. 2012)\n\nFast haze removal for nighttime image using maximum reflectance prior. J Zhang, Y Cao, S Fang, Y Kang, C W Chen, M.-H Yang, IEEEZhang, J., Cao, Y., Fang, S., Kang, Y., Chen, C. W., Yang, M.-H.: Fast haze removal for nighttime image using maximum reflectance prior. In: IEEE, CVPR, pp. 7418-7426 (July 2016)\n\nShedding light on the weather. S Narasimhan, S K Nayar, IEEE CVPR. Wisconsin, USANarasimhan, S., Nayar, S.K.: Shedding light on the weather. In: IEEE CVPR, 665-672. Wisconsin, USA (2003)\n\nNighttime haze removal with glow and multiple light colors. Y Li, R T Tan, M S Brown, IEEE International Conference on Computer Vision (ICCV). Santiago ChileLi, Y., Tan, R.T., Brown, M.S.: Nighttime haze removal with glow and multiple light colors. In: IEEE International Conference on Computer Vision (ICCV), pp. 226-234, Santiago Chile (Dec. 2015)\n\nDay and night-time dehazing by local airlight estimationg. C O Ancuti, C Ancuti, C De Vleeschouwer, A C Bovick, IEEE Trans. Image Process. 29Ancuti, C.O., Ancuti, C., De Vleeschouwer, C., Bovick, A.C.: Day and night-time dehazing by local airlight estimationg. IEEE Trans. Image Process. 29, 6264-6275 (2020)\n\nMulti-scale context aggregation by dilated convolutions. F Yu, V Koltun, International Conference on Learning Representations, (ICLR). Puerto RicoYu, F., Koltun, V.: Multi-scale context aggregation by dilated convolutions. In: International Conference on Learning Represen- tations, (ICLR), Puerto Rico (Apr. 2016)\n\nCSRNet: dilated convolutional neural networks for understanding the highly congested scenes. Y Li, X Zhang, D Chen, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionSalt Lake City, USALi, Y., Zhang, X., Chen, D.: CSRNet: dilated convolutional neural networks for understanding the highly congested scenes. In: Pro- ceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pp. 1091-1100, Salt Lake City, USA (2018)\n\nFrom learning models of natural image patches to whole image restoration. D Zoran, Y Weiss, IEEEBarcelona, SpainZoran, D., Weiss, Y.: From learning models of natural image patches to whole image restoration. In: IEEE, ICCV, Barcelona, Spain (2011)\n\nW Yang, R T Tan, J Feng, J Liu, Z Guo, S Yan, M.-H Yang, Deep joint rain detection and removal from a single image. Hawaii, USAIEEEYang, W., Tan, R.T., Feng, J., Liu, J., Guo, Z., Yan, S., Yang, M.- H.: Deep joint rain detection and removal from a single image. In: IEEE, CVPR, Hawaii, USA (2017)\n\nIndoor segmentation and support inference from RGBD images. N Silberman, D Hoiem, P Kohli, R Fergus, IEEE European Conference on Computer Vision (ECCV). ItalySilberman, N., Hoiem, D., Kohli, P., Fergus, R.: Indoor segmenta- tion and support inference from RGBD images. In: IEEE European Conference on Computer Vision (ECCV), 746-760, Italy (Oct. 2012)\n\nA taxonomy and evaluation of dense two-frame stereo correspondence algorithms. D Scharstein, R Szeliski, R Zabih, Int. J. Comput. Vis. (IJCV). 47Scharstein, D., Szeliski, R., Zabih, R.: A taxonomy and evalua- tion of dense two-frame stereo correspondence algorithms. Int. J. Comput. Vis. (IJCV) 47, 7-42 (2002)\n\nHigh-accuracy stereo depth maps using structured ligh. D Scharstein, R Szeliski, IEEEMadison, USAScharstein, D., Szeliski, R.: High-accuracy stereo depth maps using structured ligh. In: IEEE, CVPR, 195-202, Madison, USA (2003)\n\nEvaluation of cost functions for stereo matching. H Hirschm Uller, D Scharst, IEEE31Minneapolis, USAHirschm uller, H., Scharst, D.: Evaluation of cost functions for stereo matching. In: IEEE, CVPR, 31, 1582-1599, Minneapolis, USA (June 2007)\n\nImage quality assessment: from error visibility to structural similarity. Z Wang, A C Bovik, H R Sheikh, E P Simoncelli, IEEE Trans. Image Process. 13Wang, Z., Bovik, A.C., Sheikh, H.R., Simoncelli, E.P.: Image qual- ity assessment: from error visibility to structural similarity. IEEE Trans. Image Process. 13, 600-612 (2004)\n\nReflection removal using ghosting cues. Y Shih, D Krishnan, F Durand, W Freeman, IEEEBoston, USAShih, Y., Krishnan, D., Durand, F., Freeman, W.: Reflection removal using ghosting cues. In: IEEE, CVPR, pp. 3193-3201, Boston, USA (June 2015)\n\nNight time haze and glow removal using deep dilated convolutional network. S Kuanar, K R Rao, D Mahapatra, M Bilas, arXiv:1902.00855PreprintKuanar, S., Rao, K.R., Mahapatra, D., Bilas, M.: Night time haze and glow removal using deep dilated convolutional network. Preprint arXiv:1902.00855 (2019)\n\nTensorflow: large-scale machine learning on heterogeneous. M Abadi, arXiv:1603.04467distributed systemsAbadi, M., et al.: Tensorflow: large-scale machine learning on heterogeneous, distributed systems (2016). arXiv:1603.04467.pdf. Software available from www.tensorflow.org\n\nMulti-scale single image dehazing using perceptual pyramid deep network. H Zhang, V Sindagi, V Patel, IEEE Conference on Computer Vision and Pattern Recognition Workshops. Salt Lake City, USAZhang, H., Sindagi, V., Patel, V.: Multi-scale single image dehazing using perceptual pyramid deep network. In: IEEE Conference on Computer Vision and Pattern Recognition Workshops, pp. 902- 911, Salt Lake City, USA (2018)\n\nBeyond a Gaussian denoiser: residual learning of deep CNN for image denoising. K Zhang, W Zuo, Y Chen, D Meng, L Zhang, IEEE Trans. Image Process. 267Zhang, K., Zuo, W., Chen, Y., Meng, D., Zhang, L.: Beyond a Gaus- sian denoiser: residual learning of deep CNN for image denoising. IEEE Trans. Image Process. 26(7), 3142-3155 (2017)\n\nMultiple illuminant color estimation via statistical inference on factor graphs. L Mutimbu, A Robles-Kelly, IEEE Trans. Image Process. 25Mutimbu, L., Robles-Kelly, A.: Multiple illuminant color estima- tion via statistical inference on factor graphs. IEEE Trans. Image Process. 25, 5383-5396 (2016)\n\nReflectance and illumination recovery in the wild. S Lombardi, K Nishino, IEEE Trans. Pattern Anal. Mach. Intell. 38Lombardi, S., Nishino, K.: Reflectance and illumination recovery in the wild. IEEE Trans. Pattern Anal. Mach. Intell. 38, 129-141 (2016)\n", "annotations": {"author": "[{\"end\":105,\"start\":92},{\"end\":128,\"start\":106},{\"end\":146,\"start\":129},{\"end\":157,\"start\":147},{\"end\":105,\"start\":92},{\"end\":128,\"start\":106},{\"end\":146,\"start\":129},{\"end\":157,\"start\":147}]", "publisher": null, "author_last_name": "[{\"end\":104,\"start\":98},{\"end\":127,\"start\":118},{\"end\":145,\"start\":140},{\"end\":156,\"start\":153},{\"end\":104,\"start\":98},{\"end\":127,\"start\":118},{\"end\":145,\"start\":140},{\"end\":156,\"start\":153}]", "author_first_name": "[{\"end\":97,\"start\":92},{\"end\":117,\"start\":106},{\"end\":130,\"start\":129},{\"end\":139,\"start\":131},{\"end\":148,\"start\":147},{\"end\":152,\"start\":149},{\"end\":97,\"start\":92},{\"end\":117,\"start\":106},{\"end\":130,\"start\":129},{\"end\":139,\"start\":131},{\"end\":148,\"start\":147},{\"end\":152,\"start\":149}]", "author_affiliation": null, "title": "[{\"end\":85,\"start\":1},{\"end\":242,\"start\":158},{\"end\":85,\"start\":1},{\"end\":242,\"start\":158}]", "venue": "[{\"end\":263,\"start\":244},{\"end\":263,\"start\":244}]", "abstract": "[{\"end\":2105,\"start\":439},{\"end\":2105,\"start\":439}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2698,\"start\":2697},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2777,\"start\":2776},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2859,\"start\":2858},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":3520,\"start\":3517},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3522,\"start\":3520},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3593,\"start\":3590},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":4539,\"start\":4536},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":4559,\"start\":4556},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":4577,\"start\":4574},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":4641,\"start\":4638},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":7933,\"start\":7930},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":7935,\"start\":7933},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":7938,\"start\":7935},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":7941,\"start\":7938},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":7944,\"start\":7941},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":7948,\"start\":7944},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":7952,\"start\":7948},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":8022,\"start\":8019},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":8116,\"start\":8113},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":8234,\"start\":8231},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":8367,\"start\":8363},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":8699,\"start\":8695},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":9192,\"start\":9189},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":9418,\"start\":9414},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":9777,\"start\":9773},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":10325,\"start\":10322},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":10486,\"start\":10482},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":10619,\"start\":10615},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":11272,\"start\":11268},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":11460,\"start\":11456},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":11650,\"start\":11646},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":11783,\"start\":11779},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":11977,\"start\":11973},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":12812,\"start\":12808},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":14304,\"start\":14300},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":14308,\"start\":14304},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":14312,\"start\":14308},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":14316,\"start\":14312},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":14875,\"start\":14872},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":14877,\"start\":14875},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":14879,\"start\":14877},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":14881,\"start\":14879},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":17274,\"start\":17270},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":18984,\"start\":18980},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":19312,\"start\":19309},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":19315,\"start\":19312},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":19425,\"start\":19422},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":20055,\"start\":20051},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":20521,\"start\":20517},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":20524,\"start\":20521},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":21586,\"start\":21582},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":22597,\"start\":22593},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":22606,\"start\":22602},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":27222,\"start\":27218},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":28949,\"start\":28945},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":29119,\"start\":29115},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":29940,\"start\":29936},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":30064,\"start\":30061},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":30165,\"start\":30161},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":30169,\"start\":30165},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":30173,\"start\":30169},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":30400,\"start\":30396},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":31351,\"start\":31347},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":31354,\"start\":31351},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":31357,\"start\":31354},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":32323,\"start\":32319},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":34063,\"start\":34059},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":34723,\"start\":34719},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":35498,\"start\":35494},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":35705,\"start\":35701},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":35783,\"start\":35779},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":35835,\"start\":35831},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":36475,\"start\":36472},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":37289,\"start\":37285},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":37305,\"start\":37301},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":38679,\"start\":38675},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":38698,\"start\":38694},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":39584,\"start\":39580},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":41113,\"start\":41109},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":41135,\"start\":41131},{\"end\":41207,\"start\":41203},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":43070,\"start\":43066},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":43073,\"start\":43070},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2698,\"start\":2697},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2777,\"start\":2776},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2859,\"start\":2858},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":3520,\"start\":3517},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3522,\"start\":3520},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3593,\"start\":3590},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":4539,\"start\":4536},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":4559,\"start\":4556},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":4577,\"start\":4574},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":4641,\"start\":4638},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":7933,\"start\":7930},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":7935,\"start\":7933},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":7938,\"start\":7935},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":7941,\"start\":7938},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":7944,\"start\":7941},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":7948,\"start\":7944},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":7952,\"start\":7948},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":8022,\"start\":8019},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":8116,\"start\":8113},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":8234,\"start\":8231},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":8367,\"start\":8363},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":8699,\"start\":8695},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":9192,\"start\":9189},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":9418,\"start\":9414},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":9777,\"start\":9773},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":10325,\"start\":10322},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":10486,\"start\":10482},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":10619,\"start\":10615},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":11272,\"start\":11268},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":11460,\"start\":11456},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":11650,\"start\":11646},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":11783,\"start\":11779},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":11977,\"start\":11973},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":12812,\"start\":12808},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":14304,\"start\":14300},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":14308,\"start\":14304},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":14312,\"start\":14308},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":14316,\"start\":14312},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":14875,\"start\":14872},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":14877,\"start\":14875},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":14879,\"start\":14877},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":14881,\"start\":14879},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":17274,\"start\":17270},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":18984,\"start\":18980},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":19312,\"start\":19309},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":19315,\"start\":19312},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":19425,\"start\":19422},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":20055,\"start\":20051},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":20521,\"start\":20517},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":20524,\"start\":20521},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":21586,\"start\":21582},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":22597,\"start\":22593},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":22606,\"start\":22602},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":27222,\"start\":27218},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":28949,\"start\":28945},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":29119,\"start\":29115},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":29940,\"start\":29936},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":30064,\"start\":30061},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":30165,\"start\":30161},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":30169,\"start\":30165},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":30173,\"start\":30169},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":30400,\"start\":30396},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":31351,\"start\":31347},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":31354,\"start\":31351},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":31357,\"start\":31354},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":32323,\"start\":32319},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":34063,\"start\":34059},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":34723,\"start\":34719},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":35498,\"start\":35494},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":35705,\"start\":35701},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":35783,\"start\":35779},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":35835,\"start\":35831},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":36475,\"start\":36472},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":37289,\"start\":37285},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":37305,\"start\":37301},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":38679,\"start\":38675},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":38698,\"start\":38694},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":39584,\"start\":39580},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":41113,\"start\":41109},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":41135,\"start\":41131},{\"end\":41207,\"start\":41203},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":43070,\"start\":43066},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":43073,\"start\":43070}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":44138,\"start\":44123},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":44583,\"start\":44139},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":44947,\"start\":44584},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":45403,\"start\":44948},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":45791,\"start\":45404},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":45956,\"start\":45792},{\"attributes\":{\"id\":\"fig_0\"},\"end\":44138,\"start\":44123},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":44583,\"start\":44139},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":44947,\"start\":44584},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":45403,\"start\":44948},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":45791,\"start\":45404},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":45956,\"start\":45792}]", "paragraph": "[{\"end\":3230,\"start\":2121},{\"end\":4774,\"start\":3232},{\"end\":6289,\"start\":4776},{\"end\":7198,\"start\":6291},{\"end\":7765,\"start\":7200},{\"end\":10123,\"start\":7782},{\"end\":10998,\"start\":10125},{\"end\":12362,\"start\":11000},{\"end\":14946,\"start\":12387},{\"end\":15737,\"start\":15133},{\"end\":16389,\"start\":15739},{\"end\":17574,\"start\":16434},{\"end\":17634,\"start\":17612},{\"end\":18916,\"start\":17673},{\"end\":19544,\"start\":18939},{\"end\":20389,\"start\":19575},{\"end\":21587,\"start\":20391},{\"end\":22727,\"start\":21626},{\"end\":23757,\"start\":22796},{\"end\":24185,\"start\":23759},{\"end\":24750,\"start\":24261},{\"end\":25050,\"start\":24781},{\"end\":25709,\"start\":25069},{\"end\":25797,\"start\":25773},{\"end\":26543,\"start\":26021},{\"end\":28533,\"start\":26630},{\"end\":29542,\"start\":28549},{\"end\":30984,\"start\":29560},{\"end\":31358,\"start\":31005},{\"end\":34861,\"start\":31360},{\"end\":36188,\"start\":34886},{\"end\":37484,\"start\":36190},{\"end\":40295,\"start\":37549},{\"end\":41882,\"start\":40330},{\"end\":43114,\"start\":41899},{\"end\":44122,\"start\":43129},{\"end\":3230,\"start\":2121},{\"end\":4774,\"start\":3232},{\"end\":6289,\"start\":4776},{\"end\":7198,\"start\":6291},{\"end\":7765,\"start\":7200},{\"end\":10123,\"start\":7782},{\"end\":10998,\"start\":10125},{\"end\":12362,\"start\":11000},{\"end\":14946,\"start\":12387},{\"end\":15737,\"start\":15133},{\"end\":16389,\"start\":15739},{\"end\":17574,\"start\":16434},{\"end\":17634,\"start\":17612},{\"end\":18916,\"start\":17673},{\"end\":19544,\"start\":18939},{\"end\":20389,\"start\":19575},{\"end\":21587,\"start\":20391},{\"end\":22727,\"start\":21626},{\"end\":23757,\"start\":22796},{\"end\":24185,\"start\":23759},{\"end\":24750,\"start\":24261},{\"end\":25050,\"start\":24781},{\"end\":25709,\"start\":25069},{\"end\":25797,\"start\":25773},{\"end\":26543,\"start\":26021},{\"end\":28533,\"start\":26630},{\"end\":29542,\"start\":28549},{\"end\":30984,\"start\":29560},{\"end\":31358,\"start\":31005},{\"end\":34861,\"start\":31360},{\"end\":36188,\"start\":34886},{\"end\":37484,\"start\":36190},{\"end\":40295,\"start\":37549},{\"end\":41882,\"start\":40330},{\"end\":43114,\"start\":41899},{\"end\":44122,\"start\":43129}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":15132,\"start\":14947},{\"attributes\":{\"id\":\"formula_1\"},\"end\":17611,\"start\":17575},{\"attributes\":{\"id\":\"formula_2\"},\"end\":17672,\"start\":17635},{\"attributes\":{\"id\":\"formula_3\"},\"end\":18938,\"start\":18917},{\"attributes\":{\"id\":\"formula_4\"},\"end\":22795,\"start\":22728},{\"attributes\":{\"id\":\"formula_5\"},\"end\":24260,\"start\":24186},{\"attributes\":{\"id\":\"formula_6\"},\"end\":24780,\"start\":24751},{\"attributes\":{\"id\":\"formula_7\"},\"end\":25772,\"start\":25710},{\"attributes\":{\"id\":\"formula_8\"},\"end\":25857,\"start\":25798},{\"attributes\":{\"id\":\"formula_9\"},\"end\":26020,\"start\":25857},{\"attributes\":{\"id\":\"formula_10\"},\"end\":26589,\"start\":26544},{\"attributes\":{\"id\":\"formula_0\"},\"end\":15132,\"start\":14947},{\"attributes\":{\"id\":\"formula_1\"},\"end\":17611,\"start\":17575},{\"attributes\":{\"id\":\"formula_2\"},\"end\":17672,\"start\":17635},{\"attributes\":{\"id\":\"formula_3\"},\"end\":18938,\"start\":18917},{\"attributes\":{\"id\":\"formula_4\"},\"end\":22795,\"start\":22728},{\"attributes\":{\"id\":\"formula_5\"},\"end\":24260,\"start\":24186},{\"attributes\":{\"id\":\"formula_6\"},\"end\":24780,\"start\":24751},{\"attributes\":{\"id\":\"formula_7\"},\"end\":25772,\"start\":25710},{\"attributes\":{\"id\":\"formula_8\"},\"end\":25857,\"start\":25798},{\"attributes\":{\"id\":\"formula_9\"},\"end\":26020,\"start\":25857},{\"attributes\":{\"id\":\"formula_10\"},\"end\":26589,\"start\":26544}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":35047,\"start\":35040},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":35323,\"start\":35316},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":35470,\"start\":35463},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":39653,\"start\":39646},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":40621,\"start\":40614},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":41202,\"start\":41189},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":41229,\"start\":41222},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":41405,\"start\":41398},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":35047,\"start\":35040},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":35323,\"start\":35316},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":35470,\"start\":35463},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":39653,\"start\":39646},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":40621,\"start\":40614},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":41202,\"start\":41189},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":41229,\"start\":41222},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":41405,\"start\":41398}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2119,\"start\":2107},{\"attributes\":{\"n\":\"2\"},\"end\":7780,\"start\":7768},{\"attributes\":{\"n\":\"3\"},\"end\":12385,\"start\":12365},{\"attributes\":{\"n\":\"3.1\"},\"end\":16432,\"start\":16392},{\"attributes\":{\"n\":\"3.2\"},\"end\":19573,\"start\":19547},{\"attributes\":{\"n\":\"3.3\"},\"end\":21624,\"start\":21590},{\"attributes\":{\"n\":\"3.4\"},\"end\":25067,\"start\":25053},{\"attributes\":{\"n\":\"3.5\"},\"end\":26628,\"start\":26591},{\"attributes\":{\"n\":\"4\"},\"end\":28547,\"start\":28536},{\"attributes\":{\"n\":\"4.1\"},\"end\":29558,\"start\":29545},{\"attributes\":{\"n\":\"4.2\"},\"end\":31003,\"start\":30987},{\"attributes\":{\"n\":\"5\"},\"end\":34884,\"start\":34864},{\"attributes\":{\"n\":\"5.1\"},\"end\":37547,\"start\":37487},{\"attributes\":{\"n\":\"5.2\"},\"end\":40328,\"start\":40298},{\"attributes\":{\"n\":\"5.3\"},\"end\":41897,\"start\":41885},{\"attributes\":{\"n\":\"6\"},\"end\":43127,\"start\":43117},{\"end\":44130,\"start\":44124},{\"end\":44147,\"start\":44140},{\"end\":44592,\"start\":44585},{\"end\":44958,\"start\":44949},{\"end\":45412,\"start\":45405},{\"end\":45800,\"start\":45793},{\"attributes\":{\"n\":\"1\"},\"end\":2119,\"start\":2107},{\"attributes\":{\"n\":\"2\"},\"end\":7780,\"start\":7768},{\"attributes\":{\"n\":\"3\"},\"end\":12385,\"start\":12365},{\"attributes\":{\"n\":\"3.1\"},\"end\":16432,\"start\":16392},{\"attributes\":{\"n\":\"3.2\"},\"end\":19573,\"start\":19547},{\"attributes\":{\"n\":\"3.3\"},\"end\":21624,\"start\":21590},{\"attributes\":{\"n\":\"3.4\"},\"end\":25067,\"start\":25053},{\"attributes\":{\"n\":\"3.5\"},\"end\":26628,\"start\":26591},{\"attributes\":{\"n\":\"4\"},\"end\":28547,\"start\":28536},{\"attributes\":{\"n\":\"4.1\"},\"end\":29558,\"start\":29545},{\"attributes\":{\"n\":\"4.2\"},\"end\":31003,\"start\":30987},{\"attributes\":{\"n\":\"5\"},\"end\":34884,\"start\":34864},{\"attributes\":{\"n\":\"5.1\"},\"end\":37547,\"start\":37487},{\"attributes\":{\"n\":\"5.2\"},\"end\":40328,\"start\":40298},{\"attributes\":{\"n\":\"5.3\"},\"end\":41897,\"start\":41885},{\"attributes\":{\"n\":\"6\"},\"end\":43127,\"start\":43117},{\"end\":44130,\"start\":44124},{\"end\":44147,\"start\":44140},{\"end\":44592,\"start\":44585},{\"end\":44958,\"start\":44949},{\"end\":45412,\"start\":45405},{\"end\":45800,\"start\":45793}]", "table": "[{\"end\":44583,\"start\":44362},{\"end\":44947,\"start\":44682},{\"end\":45791,\"start\":45542},{\"end\":45956,\"start\":45930},{\"end\":44583,\"start\":44362},{\"end\":44947,\"start\":44682},{\"end\":45791,\"start\":45542},{\"end\":45956,\"start\":45930}]", "figure_caption": "[{\"end\":44138,\"start\":44132},{\"end\":44362,\"start\":44149},{\"end\":44682,\"start\":44594},{\"end\":45403,\"start\":44960},{\"end\":45542,\"start\":45414},{\"end\":45930,\"start\":45802},{\"end\":44138,\"start\":44132},{\"end\":44362,\"start\":44149},{\"end\":44682,\"start\":44594},{\"end\":45403,\"start\":44960},{\"end\":45542,\"start\":45414},{\"end\":45930,\"start\":45802}]", "figure_ref": "[{\"end\":3022,\"start\":3016},{\"end\":4127,\"start\":4121},{\"end\":5405,\"start\":5397},{\"end\":13221,\"start\":13213},{\"end\":14363,\"start\":14357},{\"end\":17978,\"start\":17972},{\"end\":18832,\"start\":18826},{\"end\":19274,\"start\":19266},{\"end\":19543,\"start\":19536},{\"end\":21152,\"start\":21144},{\"end\":21360,\"start\":21354},{\"end\":21968,\"start\":21962},{\"end\":23248,\"start\":23242},{\"end\":23978,\"start\":23972},{\"end\":24695,\"start\":24687},{\"end\":25181,\"start\":25175},{\"end\":28072,\"start\":28064},{\"end\":28404,\"start\":28377},{\"end\":33951,\"start\":33945},{\"end\":34143,\"start\":34137},{\"end\":34860,\"start\":34854},{\"end\":36902,\"start\":36896},{\"end\":37236,\"start\":37230},{\"end\":38334,\"start\":38326},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":38634,\"start\":38628},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":39034,\"start\":39026},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":39294,\"start\":39288},{\"end\":39871,\"start\":39865},{\"end\":42103,\"start\":42097},{\"end\":42428,\"start\":42421},{\"end\":42718,\"start\":42712},{\"end\":43951,\"start\":43948},{\"end\":3022,\"start\":3016},{\"end\":4127,\"start\":4121},{\"end\":5405,\"start\":5397},{\"end\":13221,\"start\":13213},{\"end\":14363,\"start\":14357},{\"end\":17978,\"start\":17972},{\"end\":18832,\"start\":18826},{\"end\":19274,\"start\":19266},{\"end\":19543,\"start\":19536},{\"end\":21152,\"start\":21144},{\"end\":21360,\"start\":21354},{\"end\":21968,\"start\":21962},{\"end\":23248,\"start\":23242},{\"end\":23978,\"start\":23972},{\"end\":24695,\"start\":24687},{\"end\":25181,\"start\":25175},{\"end\":28072,\"start\":28064},{\"end\":28404,\"start\":28377},{\"end\":33951,\"start\":33945},{\"end\":34143,\"start\":34137},{\"end\":34860,\"start\":34854},{\"end\":36902,\"start\":36896},{\"end\":37236,\"start\":37230},{\"end\":38334,\"start\":38326},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":38634,\"start\":38628},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":39034,\"start\":39026},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":39294,\"start\":39288},{\"end\":39871,\"start\":39865},{\"end\":42103,\"start\":42097},{\"end\":42428,\"start\":42421},{\"end\":42718,\"start\":42712},{\"end\":43951,\"start\":43948}]", "bib_author_first_name": "[{\"end\":46125,\"start\":46124},{\"end\":46129,\"start\":46126},{\"end\":46271,\"start\":46270},{\"end\":46273,\"start\":46272},{\"end\":46470,\"start\":46469},{\"end\":46730,\"start\":46729},{\"end\":46736,\"start\":46735},{\"end\":46743,\"start\":46742},{\"end\":47031,\"start\":47030},{\"end\":47033,\"start\":47032},{\"end\":47192,\"start\":47191},{\"end\":47194,\"start\":47193},{\"end\":47204,\"start\":47203},{\"end\":47404,\"start\":47403},{\"end\":47588,\"start\":47587},{\"end\":47596,\"start\":47595},{\"end\":47604,\"start\":47603},{\"end\":47921,\"start\":47920},{\"end\":47932,\"start\":47931},{\"end\":47934,\"start\":47933},{\"end\":48233,\"start\":48232},{\"end\":48241,\"start\":48240},{\"end\":48249,\"start\":48248},{\"end\":48257,\"start\":48256},{\"end\":48266,\"start\":48265},{\"end\":48558,\"start\":48557},{\"end\":48567,\"start\":48566},{\"end\":48579,\"start\":48578},{\"end\":48845,\"start\":48844},{\"end\":48852,\"start\":48851},{\"end\":48859,\"start\":48858},{\"end\":49067,\"start\":49066},{\"end\":49078,\"start\":49077},{\"end\":49087,\"start\":49086},{\"end\":49296,\"start\":49295},{\"end\":49298,\"start\":49297},{\"end\":49305,\"start\":49304},{\"end\":49307,\"start\":49306},{\"end\":49315,\"start\":49314},{\"end\":49317,\"start\":49316},{\"end\":49324,\"start\":49323},{\"end\":49326,\"start\":49325},{\"end\":49601,\"start\":49600},{\"end\":49608,\"start\":49607},{\"end\":49614,\"start\":49613},{\"end\":49621,\"start\":49620},{\"end\":49629,\"start\":49628},{\"end\":49823,\"start\":49822},{\"end\":49830,\"start\":49829},{\"end\":49837,\"start\":49836},{\"end\":49846,\"start\":49845},{\"end\":49853,\"start\":49852},{\"end\":49863,\"start\":49859},{\"end\":50313,\"start\":50309},{\"end\":50323,\"start\":50319},{\"end\":50566,\"start\":50565},{\"end\":50575,\"start\":50574},{\"end\":50582,\"start\":50581},{\"end\":50590,\"start\":50589},{\"end\":50598,\"start\":50597},{\"end\":50600,\"start\":50599},{\"end\":50611,\"start\":50607},{\"end\":50834,\"start\":50833},{\"end\":50848,\"start\":50847},{\"end\":50850,\"start\":50849},{\"end\":51051,\"start\":51050},{\"end\":51057,\"start\":51056},{\"end\":51059,\"start\":51058},{\"end\":51066,\"start\":51065},{\"end\":51068,\"start\":51067},{\"end\":51401,\"start\":51400},{\"end\":51403,\"start\":51402},{\"end\":51413,\"start\":51412},{\"end\":51423,\"start\":51422},{\"end\":51442,\"start\":51441},{\"end\":51444,\"start\":51443},{\"end\":51709,\"start\":51708},{\"end\":51715,\"start\":51714},{\"end\":52061,\"start\":52060},{\"end\":52067,\"start\":52066},{\"end\":52076,\"start\":52075},{\"end\":52568,\"start\":52567},{\"end\":52577,\"start\":52576},{\"end\":52743,\"start\":52742},{\"end\":52751,\"start\":52750},{\"end\":52753,\"start\":52752},{\"end\":52760,\"start\":52759},{\"end\":52768,\"start\":52767},{\"end\":52775,\"start\":52774},{\"end\":52782,\"start\":52781},{\"end\":52792,\"start\":52788},{\"end\":53101,\"start\":53100},{\"end\":53114,\"start\":53113},{\"end\":53123,\"start\":53122},{\"end\":53132,\"start\":53131},{\"end\":53473,\"start\":53472},{\"end\":53487,\"start\":53486},{\"end\":53499,\"start\":53498},{\"end\":53761,\"start\":53760},{\"end\":53775,\"start\":53774},{\"end\":53984,\"start\":53983},{\"end\":54001,\"start\":54000},{\"end\":54251,\"start\":54250},{\"end\":54259,\"start\":54258},{\"end\":54261,\"start\":54260},{\"end\":54270,\"start\":54269},{\"end\":54272,\"start\":54271},{\"end\":54282,\"start\":54281},{\"end\":54284,\"start\":54283},{\"end\":54545,\"start\":54544},{\"end\":54553,\"start\":54552},{\"end\":54565,\"start\":54564},{\"end\":54575,\"start\":54574},{\"end\":54821,\"start\":54820},{\"end\":54831,\"start\":54830},{\"end\":54833,\"start\":54832},{\"end\":54840,\"start\":54839},{\"end\":54853,\"start\":54852},{\"end\":55103,\"start\":55102},{\"end\":55392,\"start\":55391},{\"end\":55401,\"start\":55400},{\"end\":55412,\"start\":55411},{\"end\":55813,\"start\":55812},{\"end\":55822,\"start\":55821},{\"end\":55829,\"start\":55828},{\"end\":55837,\"start\":55836},{\"end\":55845,\"start\":55844},{\"end\":56149,\"start\":56148},{\"end\":56160,\"start\":56159},{\"end\":56419,\"start\":56418},{\"end\":56431,\"start\":56430},{\"end\":46125,\"start\":46124},{\"end\":46129,\"start\":46126},{\"end\":46271,\"start\":46270},{\"end\":46273,\"start\":46272},{\"end\":46470,\"start\":46469},{\"end\":46730,\"start\":46729},{\"end\":46736,\"start\":46735},{\"end\":46743,\"start\":46742},{\"end\":47031,\"start\":47030},{\"end\":47033,\"start\":47032},{\"end\":47192,\"start\":47191},{\"end\":47194,\"start\":47193},{\"end\":47204,\"start\":47203},{\"end\":47404,\"start\":47403},{\"end\":47588,\"start\":47587},{\"end\":47596,\"start\":47595},{\"end\":47604,\"start\":47603},{\"end\":47921,\"start\":47920},{\"end\":47932,\"start\":47931},{\"end\":47934,\"start\":47933},{\"end\":48233,\"start\":48232},{\"end\":48241,\"start\":48240},{\"end\":48249,\"start\":48248},{\"end\":48257,\"start\":48256},{\"end\":48266,\"start\":48265},{\"end\":48558,\"start\":48557},{\"end\":48567,\"start\":48566},{\"end\":48579,\"start\":48578},{\"end\":48845,\"start\":48844},{\"end\":48852,\"start\":48851},{\"end\":48859,\"start\":48858},{\"end\":49067,\"start\":49066},{\"end\":49078,\"start\":49077},{\"end\":49087,\"start\":49086},{\"end\":49296,\"start\":49295},{\"end\":49298,\"start\":49297},{\"end\":49305,\"start\":49304},{\"end\":49307,\"start\":49306},{\"end\":49315,\"start\":49314},{\"end\":49317,\"start\":49316},{\"end\":49324,\"start\":49323},{\"end\":49326,\"start\":49325},{\"end\":49601,\"start\":49600},{\"end\":49608,\"start\":49607},{\"end\":49614,\"start\":49613},{\"end\":49621,\"start\":49620},{\"end\":49629,\"start\":49628},{\"end\":49823,\"start\":49822},{\"end\":49830,\"start\":49829},{\"end\":49837,\"start\":49836},{\"end\":49846,\"start\":49845},{\"end\":49853,\"start\":49852},{\"end\":49863,\"start\":49859},{\"end\":50313,\"start\":50309},{\"end\":50323,\"start\":50319},{\"end\":50566,\"start\":50565},{\"end\":50575,\"start\":50574},{\"end\":50582,\"start\":50581},{\"end\":50590,\"start\":50589},{\"end\":50598,\"start\":50597},{\"end\":50600,\"start\":50599},{\"end\":50611,\"start\":50607},{\"end\":50834,\"start\":50833},{\"end\":50848,\"start\":50847},{\"end\":50850,\"start\":50849},{\"end\":51051,\"start\":51050},{\"end\":51057,\"start\":51056},{\"end\":51059,\"start\":51058},{\"end\":51066,\"start\":51065},{\"end\":51068,\"start\":51067},{\"end\":51401,\"start\":51400},{\"end\":51403,\"start\":51402},{\"end\":51413,\"start\":51412},{\"end\":51423,\"start\":51422},{\"end\":51442,\"start\":51441},{\"end\":51444,\"start\":51443},{\"end\":51709,\"start\":51708},{\"end\":51715,\"start\":51714},{\"end\":52061,\"start\":52060},{\"end\":52067,\"start\":52066},{\"end\":52076,\"start\":52075},{\"end\":52568,\"start\":52567},{\"end\":52577,\"start\":52576},{\"end\":52743,\"start\":52742},{\"end\":52751,\"start\":52750},{\"end\":52753,\"start\":52752},{\"end\":52760,\"start\":52759},{\"end\":52768,\"start\":52767},{\"end\":52775,\"start\":52774},{\"end\":52782,\"start\":52781},{\"end\":52792,\"start\":52788},{\"end\":53101,\"start\":53100},{\"end\":53114,\"start\":53113},{\"end\":53123,\"start\":53122},{\"end\":53132,\"start\":53131},{\"end\":53473,\"start\":53472},{\"end\":53487,\"start\":53486},{\"end\":53499,\"start\":53498},{\"end\":53761,\"start\":53760},{\"end\":53775,\"start\":53774},{\"end\":53984,\"start\":53983},{\"end\":54001,\"start\":54000},{\"end\":54251,\"start\":54250},{\"end\":54259,\"start\":54258},{\"end\":54261,\"start\":54260},{\"end\":54270,\"start\":54269},{\"end\":54272,\"start\":54271},{\"end\":54282,\"start\":54281},{\"end\":54284,\"start\":54283},{\"end\":54545,\"start\":54544},{\"end\":54553,\"start\":54552},{\"end\":54565,\"start\":54564},{\"end\":54575,\"start\":54574},{\"end\":54821,\"start\":54820},{\"end\":54831,\"start\":54830},{\"end\":54833,\"start\":54832},{\"end\":54840,\"start\":54839},{\"end\":54853,\"start\":54852},{\"end\":55103,\"start\":55102},{\"end\":55392,\"start\":55391},{\"end\":55401,\"start\":55400},{\"end\":55412,\"start\":55411},{\"end\":55813,\"start\":55812},{\"end\":55822,\"start\":55821},{\"end\":55829,\"start\":55828},{\"end\":55837,\"start\":55836},{\"end\":55845,\"start\":55844},{\"end\":56149,\"start\":56148},{\"end\":56160,\"start\":56159},{\"end\":56419,\"start\":56418},{\"end\":56431,\"start\":56430}]", "bib_author_last_name": "[{\"end\":46139,\"start\":46130},{\"end\":46283,\"start\":46274},{\"end\":46482,\"start\":46471},{\"end\":46733,\"start\":46731},{\"end\":46740,\"start\":46737},{\"end\":46748,\"start\":46744},{\"end\":47037,\"start\":47034},{\"end\":47201,\"start\":47195},{\"end\":47211,\"start\":47205},{\"end\":47411,\"start\":47405},{\"end\":47593,\"start\":47589},{\"end\":47601,\"start\":47597},{\"end\":47609,\"start\":47605},{\"end\":47929,\"start\":47922},{\"end\":47940,\"start\":47935},{\"end\":48238,\"start\":48234},{\"end\":48246,\"start\":48242},{\"end\":48254,\"start\":48250},{\"end\":48263,\"start\":48258},{\"end\":48270,\"start\":48267},{\"end\":48564,\"start\":48559},{\"end\":48576,\"start\":48568},{\"end\":48586,\"start\":48580},{\"end\":48849,\"start\":48846},{\"end\":48856,\"start\":48853},{\"end\":48864,\"start\":48860},{\"end\":49075,\"start\":49068},{\"end\":49084,\"start\":49079},{\"end\":49096,\"start\":49088},{\"end\":49302,\"start\":49299},{\"end\":49312,\"start\":49308},{\"end\":49321,\"start\":49318},{\"end\":49330,\"start\":49327},{\"end\":49605,\"start\":49602},{\"end\":49611,\"start\":49609},{\"end\":49618,\"start\":49615},{\"end\":49626,\"start\":49622},{\"end\":49633,\"start\":49630},{\"end\":49827,\"start\":49824},{\"end\":49834,\"start\":49831},{\"end\":49843,\"start\":49838},{\"end\":49850,\"start\":49847},{\"end\":49857,\"start\":49854},{\"end\":49868,\"start\":49864},{\"end\":50317,\"start\":50314},{\"end\":50327,\"start\":50324},{\"end\":50572,\"start\":50567},{\"end\":50579,\"start\":50576},{\"end\":50587,\"start\":50583},{\"end\":50595,\"start\":50591},{\"end\":50605,\"start\":50601},{\"end\":50616,\"start\":50612},{\"end\":50845,\"start\":50835},{\"end\":50856,\"start\":50851},{\"end\":51054,\"start\":51052},{\"end\":51063,\"start\":51060},{\"end\":51074,\"start\":51069},{\"end\":51410,\"start\":51404},{\"end\":51420,\"start\":51414},{\"end\":51439,\"start\":51424},{\"end\":51451,\"start\":51445},{\"end\":51712,\"start\":51710},{\"end\":51722,\"start\":51716},{\"end\":52064,\"start\":52062},{\"end\":52073,\"start\":52068},{\"end\":52081,\"start\":52077},{\"end\":52574,\"start\":52569},{\"end\":52583,\"start\":52578},{\"end\":52748,\"start\":52744},{\"end\":52757,\"start\":52754},{\"end\":52765,\"start\":52761},{\"end\":52772,\"start\":52769},{\"end\":52779,\"start\":52776},{\"end\":52786,\"start\":52783},{\"end\":52797,\"start\":52793},{\"end\":53111,\"start\":53102},{\"end\":53120,\"start\":53115},{\"end\":53129,\"start\":53124},{\"end\":53139,\"start\":53133},{\"end\":53484,\"start\":53474},{\"end\":53496,\"start\":53488},{\"end\":53505,\"start\":53500},{\"end\":53772,\"start\":53762},{\"end\":53784,\"start\":53776},{\"end\":53998,\"start\":53985},{\"end\":54009,\"start\":54002},{\"end\":54256,\"start\":54252},{\"end\":54267,\"start\":54262},{\"end\":54279,\"start\":54273},{\"end\":54295,\"start\":54285},{\"end\":54550,\"start\":54546},{\"end\":54562,\"start\":54554},{\"end\":54572,\"start\":54566},{\"end\":54583,\"start\":54576},{\"end\":54828,\"start\":54822},{\"end\":54837,\"start\":54834},{\"end\":54850,\"start\":54841},{\"end\":54859,\"start\":54854},{\"end\":55109,\"start\":55104},{\"end\":55398,\"start\":55393},{\"end\":55409,\"start\":55402},{\"end\":55418,\"start\":55413},{\"end\":55819,\"start\":55814},{\"end\":55826,\"start\":55823},{\"end\":55834,\"start\":55830},{\"end\":55842,\"start\":55838},{\"end\":55851,\"start\":55846},{\"end\":56157,\"start\":56150},{\"end\":56173,\"start\":56161},{\"end\":56428,\"start\":56420},{\"end\":56439,\"start\":56432},{\"end\":46139,\"start\":46130},{\"end\":46283,\"start\":46274},{\"end\":46482,\"start\":46471},{\"end\":46733,\"start\":46731},{\"end\":46740,\"start\":46737},{\"end\":46748,\"start\":46744},{\"end\":47037,\"start\":47034},{\"end\":47201,\"start\":47195},{\"end\":47211,\"start\":47205},{\"end\":47411,\"start\":47405},{\"end\":47593,\"start\":47589},{\"end\":47601,\"start\":47597},{\"end\":47609,\"start\":47605},{\"end\":47929,\"start\":47922},{\"end\":47940,\"start\":47935},{\"end\":48238,\"start\":48234},{\"end\":48246,\"start\":48242},{\"end\":48254,\"start\":48250},{\"end\":48263,\"start\":48258},{\"end\":48270,\"start\":48267},{\"end\":48564,\"start\":48559},{\"end\":48576,\"start\":48568},{\"end\":48586,\"start\":48580},{\"end\":48849,\"start\":48846},{\"end\":48856,\"start\":48853},{\"end\":48864,\"start\":48860},{\"end\":49075,\"start\":49068},{\"end\":49084,\"start\":49079},{\"end\":49096,\"start\":49088},{\"end\":49302,\"start\":49299},{\"end\":49312,\"start\":49308},{\"end\":49321,\"start\":49318},{\"end\":49330,\"start\":49327},{\"end\":49605,\"start\":49602},{\"end\":49611,\"start\":49609},{\"end\":49618,\"start\":49615},{\"end\":49626,\"start\":49622},{\"end\":49633,\"start\":49630},{\"end\":49827,\"start\":49824},{\"end\":49834,\"start\":49831},{\"end\":49843,\"start\":49838},{\"end\":49850,\"start\":49847},{\"end\":49857,\"start\":49854},{\"end\":49868,\"start\":49864},{\"end\":50317,\"start\":50314},{\"end\":50327,\"start\":50324},{\"end\":50572,\"start\":50567},{\"end\":50579,\"start\":50576},{\"end\":50587,\"start\":50583},{\"end\":50595,\"start\":50591},{\"end\":50605,\"start\":50601},{\"end\":50616,\"start\":50612},{\"end\":50845,\"start\":50835},{\"end\":50856,\"start\":50851},{\"end\":51054,\"start\":51052},{\"end\":51063,\"start\":51060},{\"end\":51074,\"start\":51069},{\"end\":51410,\"start\":51404},{\"end\":51420,\"start\":51414},{\"end\":51439,\"start\":51424},{\"end\":51451,\"start\":51445},{\"end\":51712,\"start\":51710},{\"end\":51722,\"start\":51716},{\"end\":52064,\"start\":52062},{\"end\":52073,\"start\":52068},{\"end\":52081,\"start\":52077},{\"end\":52574,\"start\":52569},{\"end\":52583,\"start\":52578},{\"end\":52748,\"start\":52744},{\"end\":52757,\"start\":52754},{\"end\":52765,\"start\":52761},{\"end\":52772,\"start\":52769},{\"end\":52779,\"start\":52776},{\"end\":52786,\"start\":52783},{\"end\":52797,\"start\":52793},{\"end\":53111,\"start\":53102},{\"end\":53120,\"start\":53115},{\"end\":53129,\"start\":53124},{\"end\":53139,\"start\":53133},{\"end\":53484,\"start\":53474},{\"end\":53496,\"start\":53488},{\"end\":53505,\"start\":53500},{\"end\":53772,\"start\":53762},{\"end\":53784,\"start\":53776},{\"end\":53998,\"start\":53985},{\"end\":54009,\"start\":54002},{\"end\":54256,\"start\":54252},{\"end\":54267,\"start\":54262},{\"end\":54279,\"start\":54273},{\"end\":54295,\"start\":54285},{\"end\":54550,\"start\":54546},{\"end\":54562,\"start\":54554},{\"end\":54572,\"start\":54566},{\"end\":54583,\"start\":54576},{\"end\":54828,\"start\":54822},{\"end\":54837,\"start\":54834},{\"end\":54850,\"start\":54841},{\"end\":54859,\"start\":54854},{\"end\":55109,\"start\":55104},{\"end\":55398,\"start\":55393},{\"end\":55409,\"start\":55402},{\"end\":55418,\"start\":55413},{\"end\":55819,\"start\":55814},{\"end\":55826,\"start\":55823},{\"end\":55834,\"start\":55830},{\"end\":55842,\"start\":55838},{\"end\":55851,\"start\":55846},{\"end\":56157,\"start\":56150},{\"end\":56173,\"start\":56161},{\"end\":56428,\"start\":56420},{\"end\":56439,\"start\":56432}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":46268,\"start\":46093},{\"attributes\":{\"id\":\"b1\"},\"end\":46467,\"start\":46270},{\"attributes\":{\"id\":\"b2\"},\"end\":46676,\"start\":46469},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":62593599},\"end\":46981,\"start\":46678},{\"attributes\":{\"id\":\"b4\"},\"end\":47144,\"start\":46983},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":14713713},\"end\":47373,\"start\":47146},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":207217221},\"end\":47504,\"start\":47375},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":14684722},\"end\":47864,\"start\":47506},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":11900419},\"end\":48149,\"start\":47866},{\"attributes\":{\"id\":\"b9\"},\"end\":48486,\"start\":48151},{\"attributes\":{\"id\":\"b10\"},\"end\":48768,\"start\":48488},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":4252508},\"end\":49044,\"start\":48770},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":13955168},\"end\":49222,\"start\":49046},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":3006580},\"end\":49536,\"start\":49224},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":14092238},\"end\":49820,\"start\":49538},{\"attributes\":{\"id\":\"b15\"},\"end\":50224,\"start\":49822},{\"attributes\":{\"id\":\"b16\"},\"end\":50492,\"start\":50226},{\"attributes\":{\"id\":\"b17\"},\"end\":50800,\"start\":50494},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":6136326},\"end\":50988,\"start\":50802},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":17319211},\"end\":51339,\"start\":50990},{\"attributes\":{\"id\":\"b20\"},\"end\":51649,\"start\":51341},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":17127188},\"end\":51965,\"start\":51651},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":3645757},\"end\":52491,\"start\":51967},{\"attributes\":{\"id\":\"b23\"},\"end\":52740,\"start\":52493},{\"attributes\":{\"id\":\"b24\"},\"end\":53038,\"start\":52742},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":545361},\"end\":53391,\"start\":53040},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":195859047},\"end\":53703,\"start\":53393},{\"attributes\":{\"id\":\"b27\"},\"end\":53931,\"start\":53705},{\"attributes\":{\"id\":\"b28\"},\"end\":54174,\"start\":53933},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":207761262},\"end\":54502,\"start\":54176},{\"attributes\":{\"id\":\"b30\"},\"end\":54743,\"start\":54504},{\"attributes\":{\"doi\":\"arXiv:1902.00855\",\"id\":\"b31\"},\"end\":55041,\"start\":54745},{\"attributes\":{\"doi\":\"arXiv:1603.04467\",\"id\":\"b32\"},\"end\":55316,\"start\":55043},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":52860200},\"end\":55731,\"start\":55318},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":996788},\"end\":56065,\"start\":55733},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":12917245},\"end\":56365,\"start\":56067},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":17415797},\"end\":56619,\"start\":56367},{\"attributes\":{\"id\":\"b0\"},\"end\":46268,\"start\":46093},{\"attributes\":{\"id\":\"b1\"},\"end\":46467,\"start\":46270},{\"attributes\":{\"id\":\"b2\"},\"end\":46676,\"start\":46469},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":1509137},\"end\":46981,\"start\":46678},{\"attributes\":{\"id\":\"b4\"},\"end\":47144,\"start\":46983},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":14713713},\"end\":47373,\"start\":47146},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":207217221},\"end\":47504,\"start\":47375},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":14684722},\"end\":47864,\"start\":47506},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":260763132},\"end\":48149,\"start\":47866},{\"attributes\":{\"id\":\"b9\"},\"end\":48486,\"start\":48151},{\"attributes\":{\"id\":\"b10\"},\"end\":48768,\"start\":48488},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":4252508},\"end\":49044,\"start\":48770},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":13955168},\"end\":49222,\"start\":49046},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":3006580},\"end\":49536,\"start\":49224},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":14092238},\"end\":49820,\"start\":49538},{\"attributes\":{\"id\":\"b15\"},\"end\":50224,\"start\":49822},{\"attributes\":{\"id\":\"b16\"},\"end\":50492,\"start\":50226},{\"attributes\":{\"id\":\"b17\"},\"end\":50800,\"start\":50494},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":6136326},\"end\":50988,\"start\":50802},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":17319211},\"end\":51339,\"start\":50990},{\"attributes\":{\"id\":\"b20\"},\"end\":51649,\"start\":51341},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":17127188},\"end\":51965,\"start\":51651},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":3645757},\"end\":52491,\"start\":51967},{\"attributes\":{\"id\":\"b23\"},\"end\":52740,\"start\":52493},{\"attributes\":{\"id\":\"b24\"},\"end\":53038,\"start\":52742},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":545361},\"end\":53391,\"start\":53040},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":195859047},\"end\":53703,\"start\":53393},{\"attributes\":{\"id\":\"b27\"},\"end\":53931,\"start\":53705},{\"attributes\":{\"id\":\"b28\"},\"end\":54174,\"start\":53933},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":207761262},\"end\":54502,\"start\":54176},{\"attributes\":{\"id\":\"b30\"},\"end\":54743,\"start\":54504},{\"attributes\":{\"doi\":\"arXiv:1902.00855\",\"id\":\"b31\"},\"end\":55041,\"start\":54745},{\"attributes\":{\"doi\":\"arXiv:1603.04467\",\"id\":\"b32\"},\"end\":55316,\"start\":55043},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":52860200},\"end\":55731,\"start\":55318},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":996788},\"end\":56065,\"start\":55733},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":12917245},\"end\":56365,\"start\":56067},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":17415797},\"end\":56619,\"start\":56367}]", "bib_title": "[{\"end\":46727,\"start\":46678},{\"end\":47189,\"start\":47146},{\"end\":47401,\"start\":47375},{\"end\":47585,\"start\":47506},{\"end\":47918,\"start\":47866},{\"end\":48842,\"start\":48770},{\"end\":49064,\"start\":49046},{\"end\":49293,\"start\":49224},{\"end\":49598,\"start\":49538},{\"end\":50831,\"start\":50802},{\"end\":51048,\"start\":50990},{\"end\":51398,\"start\":51341},{\"end\":51706,\"start\":51651},{\"end\":52058,\"start\":51967},{\"end\":53098,\"start\":53040},{\"end\":53470,\"start\":53393},{\"end\":54248,\"start\":54176},{\"end\":55389,\"start\":55318},{\"end\":55810,\"start\":55733},{\"end\":56146,\"start\":56067},{\"end\":56416,\"start\":56367},{\"end\":46727,\"start\":46678},{\"end\":47189,\"start\":47146},{\"end\":47401,\"start\":47375},{\"end\":47585,\"start\":47506},{\"end\":47918,\"start\":47866},{\"end\":48842,\"start\":48770},{\"end\":49064,\"start\":49046},{\"end\":49293,\"start\":49224},{\"end\":49598,\"start\":49538},{\"end\":50831,\"start\":50802},{\"end\":51048,\"start\":50990},{\"end\":51398,\"start\":51341},{\"end\":51706,\"start\":51651},{\"end\":52058,\"start\":51967},{\"end\":53098,\"start\":53040},{\"end\":53470,\"start\":53393},{\"end\":54248,\"start\":54176},{\"end\":55389,\"start\":55318},{\"end\":55810,\"start\":55733},{\"end\":56146,\"start\":56067},{\"end\":56416,\"start\":56367}]", "bib_author": "[{\"end\":46141,\"start\":46124},{\"end\":46285,\"start\":46270},{\"end\":46484,\"start\":46469},{\"end\":46735,\"start\":46729},{\"end\":46742,\"start\":46735},{\"end\":46750,\"start\":46742},{\"end\":47039,\"start\":47030},{\"end\":47203,\"start\":47191},{\"end\":47213,\"start\":47203},{\"end\":47413,\"start\":47403},{\"end\":47595,\"start\":47587},{\"end\":47603,\"start\":47595},{\"end\":47611,\"start\":47603},{\"end\":47931,\"start\":47920},{\"end\":47942,\"start\":47931},{\"end\":48240,\"start\":48232},{\"end\":48248,\"start\":48240},{\"end\":48256,\"start\":48248},{\"end\":48265,\"start\":48256},{\"end\":48272,\"start\":48265},{\"end\":48566,\"start\":48557},{\"end\":48578,\"start\":48566},{\"end\":48588,\"start\":48578},{\"end\":48851,\"start\":48844},{\"end\":48858,\"start\":48851},{\"end\":48866,\"start\":48858},{\"end\":49077,\"start\":49066},{\"end\":49086,\"start\":49077},{\"end\":49098,\"start\":49086},{\"end\":49304,\"start\":49295},{\"end\":49314,\"start\":49304},{\"end\":49323,\"start\":49314},{\"end\":49332,\"start\":49323},{\"end\":49607,\"start\":49600},{\"end\":49613,\"start\":49607},{\"end\":49620,\"start\":49613},{\"end\":49628,\"start\":49620},{\"end\":49635,\"start\":49628},{\"end\":49829,\"start\":49822},{\"end\":49836,\"start\":49829},{\"end\":49845,\"start\":49836},{\"end\":49852,\"start\":49845},{\"end\":49859,\"start\":49852},{\"end\":49870,\"start\":49859},{\"end\":50319,\"start\":50309},{\"end\":50329,\"start\":50319},{\"end\":50574,\"start\":50565},{\"end\":50581,\"start\":50574},{\"end\":50589,\"start\":50581},{\"end\":50597,\"start\":50589},{\"end\":50607,\"start\":50597},{\"end\":50618,\"start\":50607},{\"end\":50847,\"start\":50833},{\"end\":50858,\"start\":50847},{\"end\":51056,\"start\":51050},{\"end\":51065,\"start\":51056},{\"end\":51076,\"start\":51065},{\"end\":51412,\"start\":51400},{\"end\":51422,\"start\":51412},{\"end\":51441,\"start\":51422},{\"end\":51453,\"start\":51441},{\"end\":51714,\"start\":51708},{\"end\":51724,\"start\":51714},{\"end\":52066,\"start\":52060},{\"end\":52075,\"start\":52066},{\"end\":52083,\"start\":52075},{\"end\":52576,\"start\":52567},{\"end\":52585,\"start\":52576},{\"end\":52750,\"start\":52742},{\"end\":52759,\"start\":52750},{\"end\":52767,\"start\":52759},{\"end\":52774,\"start\":52767},{\"end\":52781,\"start\":52774},{\"end\":52788,\"start\":52781},{\"end\":52799,\"start\":52788},{\"end\":53113,\"start\":53100},{\"end\":53122,\"start\":53113},{\"end\":53131,\"start\":53122},{\"end\":53141,\"start\":53131},{\"end\":53486,\"start\":53472},{\"end\":53498,\"start\":53486},{\"end\":53507,\"start\":53498},{\"end\":53774,\"start\":53760},{\"end\":53786,\"start\":53774},{\"end\":54000,\"start\":53983},{\"end\":54011,\"start\":54000},{\"end\":54258,\"start\":54250},{\"end\":54269,\"start\":54258},{\"end\":54281,\"start\":54269},{\"end\":54297,\"start\":54281},{\"end\":54552,\"start\":54544},{\"end\":54564,\"start\":54552},{\"end\":54574,\"start\":54564},{\"end\":54585,\"start\":54574},{\"end\":54830,\"start\":54820},{\"end\":54839,\"start\":54830},{\"end\":54852,\"start\":54839},{\"end\":54861,\"start\":54852},{\"end\":55111,\"start\":55102},{\"end\":55400,\"start\":55391},{\"end\":55411,\"start\":55400},{\"end\":55420,\"start\":55411},{\"end\":55821,\"start\":55812},{\"end\":55828,\"start\":55821},{\"end\":55836,\"start\":55828},{\"end\":55844,\"start\":55836},{\"end\":55853,\"start\":55844},{\"end\":56159,\"start\":56148},{\"end\":56175,\"start\":56159},{\"end\":56430,\"start\":56418},{\"end\":56441,\"start\":56430},{\"end\":46141,\"start\":46124},{\"end\":46285,\"start\":46270},{\"end\":46484,\"start\":46469},{\"end\":46735,\"start\":46729},{\"end\":46742,\"start\":46735},{\"end\":46750,\"start\":46742},{\"end\":47039,\"start\":47030},{\"end\":47203,\"start\":47191},{\"end\":47213,\"start\":47203},{\"end\":47413,\"start\":47403},{\"end\":47595,\"start\":47587},{\"end\":47603,\"start\":47595},{\"end\":47611,\"start\":47603},{\"end\":47931,\"start\":47920},{\"end\":47942,\"start\":47931},{\"end\":48240,\"start\":48232},{\"end\":48248,\"start\":48240},{\"end\":48256,\"start\":48248},{\"end\":48265,\"start\":48256},{\"end\":48272,\"start\":48265},{\"end\":48566,\"start\":48557},{\"end\":48578,\"start\":48566},{\"end\":48588,\"start\":48578},{\"end\":48851,\"start\":48844},{\"end\":48858,\"start\":48851},{\"end\":48866,\"start\":48858},{\"end\":49077,\"start\":49066},{\"end\":49086,\"start\":49077},{\"end\":49098,\"start\":49086},{\"end\":49304,\"start\":49295},{\"end\":49314,\"start\":49304},{\"end\":49323,\"start\":49314},{\"end\":49332,\"start\":49323},{\"end\":49607,\"start\":49600},{\"end\":49613,\"start\":49607},{\"end\":49620,\"start\":49613},{\"end\":49628,\"start\":49620},{\"end\":49635,\"start\":49628},{\"end\":49829,\"start\":49822},{\"end\":49836,\"start\":49829},{\"end\":49845,\"start\":49836},{\"end\":49852,\"start\":49845},{\"end\":49859,\"start\":49852},{\"end\":49870,\"start\":49859},{\"end\":50319,\"start\":50309},{\"end\":50329,\"start\":50319},{\"end\":50574,\"start\":50565},{\"end\":50581,\"start\":50574},{\"end\":50589,\"start\":50581},{\"end\":50597,\"start\":50589},{\"end\":50607,\"start\":50597},{\"end\":50618,\"start\":50607},{\"end\":50847,\"start\":50833},{\"end\":50858,\"start\":50847},{\"end\":51056,\"start\":51050},{\"end\":51065,\"start\":51056},{\"end\":51076,\"start\":51065},{\"end\":51412,\"start\":51400},{\"end\":51422,\"start\":51412},{\"end\":51441,\"start\":51422},{\"end\":51453,\"start\":51441},{\"end\":51714,\"start\":51708},{\"end\":51724,\"start\":51714},{\"end\":52066,\"start\":52060},{\"end\":52075,\"start\":52066},{\"end\":52083,\"start\":52075},{\"end\":52576,\"start\":52567},{\"end\":52585,\"start\":52576},{\"end\":52750,\"start\":52742},{\"end\":52759,\"start\":52750},{\"end\":52767,\"start\":52759},{\"end\":52774,\"start\":52767},{\"end\":52781,\"start\":52774},{\"end\":52788,\"start\":52781},{\"end\":52799,\"start\":52788},{\"end\":53113,\"start\":53100},{\"end\":53122,\"start\":53113},{\"end\":53131,\"start\":53122},{\"end\":53141,\"start\":53131},{\"end\":53486,\"start\":53472},{\"end\":53498,\"start\":53486},{\"end\":53507,\"start\":53498},{\"end\":53774,\"start\":53760},{\"end\":53786,\"start\":53774},{\"end\":54000,\"start\":53983},{\"end\":54011,\"start\":54000},{\"end\":54258,\"start\":54250},{\"end\":54269,\"start\":54258},{\"end\":54281,\"start\":54269},{\"end\":54297,\"start\":54281},{\"end\":54552,\"start\":54544},{\"end\":54564,\"start\":54552},{\"end\":54574,\"start\":54564},{\"end\":54585,\"start\":54574},{\"end\":54830,\"start\":54820},{\"end\":54839,\"start\":54830},{\"end\":54852,\"start\":54839},{\"end\":54861,\"start\":54852},{\"end\":55111,\"start\":55102},{\"end\":55400,\"start\":55391},{\"end\":55411,\"start\":55400},{\"end\":55420,\"start\":55411},{\"end\":55821,\"start\":55812},{\"end\":55828,\"start\":55821},{\"end\":55836,\"start\":55828},{\"end\":55844,\"start\":55836},{\"end\":55853,\"start\":55844},{\"end\":56159,\"start\":56148},{\"end\":56175,\"start\":56159},{\"end\":56430,\"start\":56418},{\"end\":56441,\"start\":56430}]", "bib_venue": "[{\"end\":46122,\"start\":46093},{\"end\":46348,\"start\":46285},{\"end\":46560,\"start\":46484},{\"end\":46801,\"start\":46750},{\"end\":47028,\"start\":46983},{\"end\":47245,\"start\":47213},{\"end\":47429,\"start\":47413},{\"end\":47655,\"start\":47611},{\"end\":47977,\"start\":47942},{\"end\":48230,\"start\":48151},{\"end\":48555,\"start\":48488},{\"end\":48891,\"start\":48866},{\"end\":49117,\"start\":49098},{\"end\":49363,\"start\":49332},{\"end\":49660,\"start\":49635},{\"end\":49993,\"start\":49870},{\"end\":50307,\"start\":50226},{\"end\":50563,\"start\":50494},{\"end\":50867,\"start\":50858},{\"end\":51131,\"start\":51076},{\"end\":51478,\"start\":51453},{\"end\":51784,\"start\":51724},{\"end\":52160,\"start\":52083},{\"end\":52565,\"start\":52493},{\"end\":52856,\"start\":52799},{\"end\":53191,\"start\":53141},{\"end\":53534,\"start\":53507},{\"end\":53758,\"start\":53705},{\"end\":53981,\"start\":53933},{\"end\":54322,\"start\":54297},{\"end\":54542,\"start\":54504},{\"end\":54818,\"start\":54745},{\"end\":55100,\"start\":55043},{\"end\":55488,\"start\":55420},{\"end\":55878,\"start\":55853},{\"end\":56200,\"start\":56175},{\"end\":56479,\"start\":56441},{\"end\":46122,\"start\":46093},{\"end\":46348,\"start\":46285},{\"end\":46560,\"start\":46484},{\"end\":46801,\"start\":46750},{\"end\":47028,\"start\":46983},{\"end\":47245,\"start\":47213},{\"end\":47429,\"start\":47413},{\"end\":47655,\"start\":47611},{\"end\":47977,\"start\":47942},{\"end\":48230,\"start\":48151},{\"end\":48555,\"start\":48488},{\"end\":48891,\"start\":48866},{\"end\":49117,\"start\":49098},{\"end\":49363,\"start\":49332},{\"end\":49660,\"start\":49635},{\"end\":49993,\"start\":49870},{\"end\":50307,\"start\":50226},{\"end\":50563,\"start\":50494},{\"end\":50867,\"start\":50858},{\"end\":51131,\"start\":51076},{\"end\":51478,\"start\":51453},{\"end\":51784,\"start\":51724},{\"end\":52160,\"start\":52083},{\"end\":52565,\"start\":52493},{\"end\":52856,\"start\":52799},{\"end\":53191,\"start\":53141},{\"end\":53534,\"start\":53507},{\"end\":53758,\"start\":53705},{\"end\":53981,\"start\":53933},{\"end\":54322,\"start\":54297},{\"end\":54542,\"start\":54504},{\"end\":54818,\"start\":54745},{\"end\":55100,\"start\":55043},{\"end\":55488,\"start\":55420},{\"end\":55878,\"start\":55853},{\"end\":56200,\"start\":56175},{\"end\":56479,\"start\":56441},{\"end\":46358,\"start\":46350},{\"end\":46568,\"start\":46562},{\"end\":46813,\"start\":46803},{\"end\":47671,\"start\":47657},{\"end\":48000,\"start\":47979},{\"end\":50004,\"start\":49995},{\"end\":50883,\"start\":50869},{\"end\":51147,\"start\":51133},{\"end\":51797,\"start\":51786},{\"end\":52243,\"start\":52162},{\"end\":52869,\"start\":52858},{\"end\":53198,\"start\":53193},{\"end\":55509,\"start\":55490},{\"end\":46358,\"start\":46350},{\"end\":46568,\"start\":46562},{\"end\":46813,\"start\":46803},{\"end\":47671,\"start\":47657},{\"end\":48000,\"start\":47979},{\"end\":50004,\"start\":49995},{\"end\":50883,\"start\":50869},{\"end\":51147,\"start\":51133},{\"end\":51797,\"start\":51786},{\"end\":52243,\"start\":52162},{\"end\":52869,\"start\":52858},{\"end\":53198,\"start\":53193},{\"end\":55509,\"start\":55490}]"}}}, "year": 2023, "month": 12, "day": 17}