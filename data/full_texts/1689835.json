{"id": 1689835, "updated": "2023-11-11 01:09:08.33", "metadata": {"title": "Layered Label Propagation: A MultiResolution Coordinate-Free Ordering for Compressing Social Networks", "authors": "[{\"first\":\"Paolo\",\"last\":\"Boldi\",\"middle\":[]},{\"first\":\"Marco\",\"last\":\"Rosa\",\"middle\":[]},{\"first\":\"Massimo\",\"last\":\"Santini\",\"middle\":[]},{\"first\":\"Sebastiano\",\"last\":\"Vigna\",\"middle\":[]}]", "venue": "ArXiv", "journal": "ArXiv", "publication_date": {"year": 2010, "month": 11, "day": 24}, "abstract": "We continue the line of research on graph compression started with WebGraph, but we move our focus to the compression of social networks in a proper sense (e.g., LiveJournal): the approaches that have been used for a long time to compress web graphs rely on a specific ordering of the nodes (lexicographical URL ordering) whose extension to general social networks is not trivial. In this paper, we propose a solution that mixes clusterings and orders, and devise a new algorithm, called Layered Label Propagation, that builds on previous work on scalable clustering and can be used to reorder very large graphs (billions of nodes). Our implementation uses overdecomposition to perform aggressively on multi-core architecture, making it possible to reorder graphs of more than 600 millions nodes in a few hours. Experiments performed on a wide array of web graphs and social networks show that combining the order produced by the proposed algorithm with the WebGraph compression framework provides a major increase in compression with respect to all currently known techniques, both on web graphs and on social networks. These improvements make it possible to analyse in main memory significantly larger graphs.", "fields_of_study": "[\"Computer Science\",\"Physics\"]", "external_ids": {"arxiv": null, "mag": "2949093975", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/corr/abs-1011-5425", "doi": "10.1145/1963405.1963488"}}, "content": {"source": {"pdf_hash": "1c49137518b8129f3a629c4411a549460fd8aa75", "pdf_src": "ArXiv", "pdf_uri": "[\"https://arxiv.org/pdf/1011.5425v2.pdf\"]", "oa_url_match": false, "oa_info": {"license": null, "open_access_url": null, "status": "CLOSED"}}, "grobid": {"id": "829ad3405321f835575a23330d048700c77da30f", "type": "plain-text", "url": "s3://ai2-s2-science-parse-plus-prod/parse-results/s2orc_worker/1c49137518b8129f3a629c4411a549460fd8aa75.txt", "contents": "\nLayered Label Propagation: A MultiResolution Coordinate-Free Ordering for Compressing Social Networks\nOctober 17, 2011\n\nPaolo Boldi \nDipartimento di Scienze dell'Informazione\nUniversit\u00e0 degli Studi di Milano\nItaly\n\nMarco Rosa \nDipartimento di Scienze dell'Informazione\nUniversit\u00e0 degli Studi di Milano\nItaly\n\nMassimo Santini \nDipartimento di Scienze dell'Informazione\nUniversit\u00e0 degli Studi di Milano\nItaly\n\nSebastiano Vigna \nDipartimento di Scienze dell'Informazione\nUniversit\u00e0 degli Studi di Milano\nItaly\n\nLayered Label Propagation: A MultiResolution Coordinate-Free Ordering for Compressing Social Networks\nOctober 17, 2011C590C91A4FC9171E7C47B9B1AC7F4F52arXiv:1011.5425v2[cs.DS]\nWe continue the line of research on graph compression started in [BV04], but we move our focus to the compression of social networks in a proper sense (e.g., LiveJournal): the approaches that have been used for a long time to compress web graphs rely on a specific ordering of the nodes (lexicographical URL ordering) whose extension to general social networks is not trivial.In this paper, we propose a solution that mixes clusterings and orders, and devise a new algorithm, called Layered Label Propagation, that builds on previous work on scalable clustering and can be used to reorder very large graphs (billions of nodes).Our implementation uses task decomposition to perform aggressively on multi-core architecture, making it possible to reorder graphs of more than 600 millions nodes in a few hours.Experiments performed on a wide array of web graphs and social networks show that combining the order produced by the proposed algorithm with the WebGraph compression framework provides a major increase in compression with respect to all currently known techniques, both on web graphs and on social networks.These improvements make it possible to analyse in main memory significantly larger graphs.\n\nIntroduction\n\nThe acquaintance structure underlying a social network contains a wealth of information about the network itself, and many data mining tasks can be accomplished from this information alone (e.g., detecting outlier nodes, identifying interest groups, estimating measures of centrality etc. [WFI94, KY08]).Many of these tasks translate into graph mining problems and can be solved through suitable (sometimes, variants of standard) graph algorithms that often assume that the graph is stored into the main memory.However, this assumption is far from trivial when large graphs are dealt with, and this is actually the case when social networks are considered; for instance, current estimates say that the indexable web contains at least 23.59 billion pages 1 , and in 2008 Google announced to have crawled 1 trillion unique URLs: the successor lists for such a graph would require hundreds of terabytes of memory!The situation is somewhat similar in other social networks; for example, as of October 2010 2 , Facebook has more than 500 millions users and 65 billions friendship relations.\n\nThe objective of this paper is to find effective techniques to store and access large graphs that can be applied fruitfully not only to web graphs but also to social networks of other kinds.The considerations above explain why this problem is lately emerging as one of the central algorithmic issues in the field of information retrieval [GL04, CKL + 09]; it should also be noted that improving the compression performance on a class of networks, apart for its obvious practical consequences, implies (and requires) a better understanding of the regularities and of the very structure of such networks.\n\nHere and in the following, we are thinking of compressed data structures.A compressed data structure for a graph must provide very fast amortised random access to an edge (link), say in the order of few hundreds of nanoseconds, as opposed to a \"compression scheme\", whose only evaluation criterion is the number of bits per link.While this definition is not formal, it excludes methods in which the successors of a node are not accessible unless, for instance, a large part of the graph is scanned.In a sense, compressed data structures are the empirical counterpart of succinct data structures (introduced by Jacobson [Jac89]), which store data using a number of bits equal to the information-theoretical lower bound, providing access asymptotically equivalent to a standard data structure.\n\nThe idea of using a compressed data structure to store social networks was already successfully exploited with application to web graphs [BV04], showing that such graphs may be stored using less than 3 bits/link; this impressive compression ratio is mostly obtained by making good use of two simple properties that can be experimentally observed when nodes are ordered lexicographically by URL [RSWW02]:\n\n\u2022 similarity: nodes that are close to each other in the order tend to have similar sets of neighbours;\n\n\u2022 locality: most links are between nodes that are close to each other in the order.\n\nThe fact that most compression algorithms exploit these (or analogous) properties explains why such algorithms are so sensible to the way nodes are ordered; the solution of ordering nodes lexicographically by URL is usually considered good enough for all practical purposes, and has the extra advantage that even the URL list can be compressed very efficiently via prefix omission.Analogous techniques, which use additional information besides the graph itself, are called extrinsic.One natural and important question is whether there exist any intrinsic order of the nodes (i.e., one that does not rely on any external data) that produces comparable, or maybe even better, compression ratios.This is particularly urgent for general social networks, where the very notion of URL does no longer apply and finding a natural extrinsic order is problematic [CKL + 09, BSV09].\n\n\nProblem Definition and Related Works\n\nThe general problem we consider may be stated as follows: a graph-compression algorithm A takes (the adjacency matrix of) a graph as input and stores it in a compressed data structure; the algorithm output depends on the specific numbering chosen for the nodes.We let \u03c1 A (G, \u03c0) be the number of bits per link needed by A to store the graph G under the given node numbering3 \u03c0 :\nV G \u2192 |V G |.\nThe overall objective is to find a numbering \u03c0 minimising \u03c1 A (G, \u03c0).In the following, we shall always assume that a graph G with n nodes has V G = n, so a node numbering is actually a permutation \u03c0 : n \u2192 n.\n\nOf course, the problem has different solutions depending on the specific compression algorithm A that is taken into consideration.In the following, we shall focus on the so-called BV compression scheme [BV04] used within the WebGraph framework, which incorporates the main ideas adopted in earlier systems and is a de facto standard for handling large web-like graphs.In particular, the framework strongly relies on similarity and locality to achieve its good compression results; for this reason, we believe that most compressed structures that are based on the same properties will probably display a similar behaviour.\n\nAs noted in [CKL + 09], even a very mild version of the above-stated optimisation problem turns out to be NP-hard, so we can only expect to devise heuristics that work well in most practical cases.Such heuristics may be intrinsic or extrinsic, depending on whether they only use the information contained in the graph itself or they also depend on some external knowledge.\n\nIn the class of intrinsic order heuristics, [RSWW02] proposes to choose the permutation \u03c0 that would sort the rows of the adjacency matrix A G in lexicographic order.This is an example of a more general kind of solution: fix some total ordering \u227a on the set of n-bit vectors (e.g., the lexicographic ordering), and let \u03c0 be the permutation that would sort the rows of the adjacency matrix A G according to4 \u227a.\n\nAnother possible solution in the same class, already mentioned in [RSWW02] and studied more deeply in [BSV09], consists in letting \u227a be a Gray ordering.Recall that [Knu05] an n-bit Gray ordering is a total order on the set of the 2 n binary n-bit vectors such that any two successive vectors differ in exactly one position.Although many n-bit Gray ordering exist, a very effective one (i.e., one that is manageable in practice because it is easy to decide which of two vectors come first in the order) is the so-called reflective n-bit Gray ordering, which was used in [BSV09]. 5hierichetti et al. [CKL + 09] propose a completely different intrinsic approach based on shingles that adopts ideas used for document similarity derived from min-wise independence.The compression results they get are comparable to those achieved through Gray ordering [BSV09].In the same paper they also discuss an alternative compression technique (called BL) that provides better ratios; however, while interesting as a compression scheme, BL does not provide a compressed data structure-recovering the successors of a node requires, in principle, decompressing the whole graph.\n\nRecently, Safro and Temkin [ST10] presented a multiscale approach for the network minimum logarithmic arrangement problem: their method searches for an intrinsic ordering that optimises directly the sum of the logarithms of the gaps (numerical difference between two successive neighbours).Although their work is not aimed at compression, their ordering is potentially useful for this task if combined with a compression scheme like BV.Indeed, some preliminary tests show that these orderings are promising especially on social networks; however, their implementation does not scale well to datasets with more that a few millions of nodes and so it is impractical for our purpose.\n\nAs far as extrinsic orderings are concerned, a central r\u00f4le is played by the URL-based ordering in a web graph.If G is a web graph, we can assume to have a permutation \u03c0 U of its nodes that sorts them according to the lexicographic URL ordering: this extrinsic heuristic dates back to [BBH + 98] and, as explained above, turns out to give very good compression, but it is clearly of no use in non-web social networks.Another effective way to exploit the host information is presented in [BSV09], where URLs from the same host are kept adjacent (within the same host, Gray ordering is used instead).\n\nIt is worth remarking that all the intrinsic techniques mentioned above produce different results (and, in particular, attain different compression ratios) depending on the initial numbering of the nodes, because they work on the adjacency matrix A G .This fact was overlooked in almost all previous literature, but it turns out to be very relevant: applying one of these intrinsic re-ordering to a randomly numbered graph (see Table 7) produces worse compression ratios than starting from a URL-ordered web graph (see Table 6).\n\nThis problem arises because even if the intrinsic techniques described above do not explicitly use any external information, the initial order of a graph is often obtained by means of some external information, so the compression performances cannot be really considered intrinsic.To make this point clear, throughout the paper we will speak of coordinate-free algorithms for those algorithms that achieve almost the same compression performances starting from any initial ordering; this adjective can be applied both to compression algorithms and to orderings+compression algorithm pairs.From an experimental viewpoint, this means that, unlike in the previous literature, we run all our tests starting from a random permutation of the original graph.We suggest this approach as a baseline for future research, as it avoids any dependency on the way in which the graph is presented initially.\n\nThe only coordinate-free compression algorithm we are aware of6 is that proposed by Apostolico and Drovandi in [AD09];7 they exploit a breadth-first search (BFS) to obtain an ordering of the graph and they devise a new compression scheme that takes full advantage of it.Their algorithm has a parameter, the level, which can be tuned to obtain different trade-offs between compression performance and time to retrieve the adjacency list of a node: at level 8 they attain better compression performances than those obtained by BV with Gray orderings and have a similar speed in retrieving the adjacency list.Even in this optimal setting, though, their approach is outperformed by the one we are going to present (see Table 5).\n\nFinally, Maserrat and Pei [MP10] propose a completely different approach that does not rely on a specific permutation of the graph.Their method compresses social networks by ex-ploiting Eulerian data structures and multi-position linearisations of directed graphs.Notably, their technique is able to answer both successor and predecessor queries: however, while querying for adjacency of two nodes is a fast operation, the cost per link of enumerating the successors and predecessors of a node is between one and two orders of magnitude larger than what we allowed.In other words, by the standards followed in this paper their algorithm does not qualify as a compressed data structure.\n\nWe must also remark that the comparison given in [MP10] of the compression ratio w.r.t.WebGraph's BV scheme is quite unfair: indeed, the authors argue that since their algorithm provides both predecessors and successors, the right comparison with the BV scheme requires roughly doubling the number of bits per link (as the BV scheme just returns successors).However, this bound is quite na\u00efve: consider a simple strategy that uses the set E sym of all symmetric edges, and let G sym = (V, E sym ) and G res = (V, E \\ E sym ).To be able to answer both successor and predecessor queries one can just store G sym , G res and G res transposed.Using this simple strategy and applying the ordering proposed in this paper to the datasets used in [CKL + 09] we obtain better compression ratios.\n\n\nOur Contribution\n\nIn this paper we give a number of algorithmic and experimental results:\n\n\u2022 We identify two measures of fitness for algorithms that try to recover the host structure of the web, and report experiments on large web graphs that suggest that the success of the best coordinate-free orderings is probably due to their capability of guessing the host structure.\n\n\u2022 Since the existing coordinate-free orderings do not work well on social networks, we propose a new algorithm, called Layered Label Propagation, that builds on previous work on scalable clustering by label propagation [RAK07, ?]; the algorithm can reorder very large graphs (billions of nodes), and unlike previous proposals, is free from parameters.\n\n\u2022 We report experiments on the compression of a wide array of web graphs and social networks using WebGraph after a reordering by Layered Label Propagation; the experiments show that our combination of techniques provides a major increase in compression with respect to all currently known approaches.This is particularly surprising in view of the fact that we obtain the best results both on web graphs and on social networks.Our largest graph contains more than 600 millions nodesone order of magnitude more than any published result in this area.\n\nAlmost all the datasets can be downloaded from the site http://law.dsi.unimi.it/(or from other public or free sources) and have been widely used in the previous literature to benchmark compression algorithms.The Java code for our new algorithm is distributed at the same URL under the GNU General Public License.\n\nWe remark that our new algorithm has also been applied with excellent results to the Minimum Logarithmic Arrangement Problem [ST10]8 .\n\n\nRecovering Host information from a Random Permutation\n\nAs a warm-up towards our new algorithm, we propose an empirical analysis that aims at determining objectively why existing approaches compress well web graphs.\n\nThe results presented in [BSV09] suggest that what is really important in order to achieve good compression performances on web graphs is not the URL ordering per se, but rather an ordering that keeps nodes from the same host close to one another.For this reason, we will be naturally interested to measure how much a given ordering \u03c0 respects the partition induced by the hosts, H .\n\nThe first measure we propose is the probability to have a host transition (HT):\nHT(H , \u03c0) = |V G |\u22121 i=1 \u03b4 H [\u03c0 \u22121 (i)], H [\u03c0 \u22121 (i \u2212 1)] |V G | \u2212 1\nwhere \u03b4 denotes the usual Kronecker's delta and H [x] is the equivalence class of node x (i.e., the set of all nodes that have the same host as x): this is simply the fraction of nodes that are followed, in the order \u03c0, by another node with a different host.\n\nAlternatively, we can reason as follows: the ordering induces a refinement of the original host partition, and the appropriateness of a given ordering can be measured by comparing the original partition with the refined one.More formally, let us denote with H |\u03c0 the partition induced by the reflexive and transitive closure of the relation \u03c1 defined by\nx \u03c1 y \u21d0\u21d2 |\u03c0(x) \u2212 \u03c0(y)| = 1 and H [x] = H [y].\nIntuitively, the classes of H |\u03c0 are made of nodes belonging to the same host and that are separated in the order only by nodes of the same host.Notice that this is always a refinement of the partition H .\n\nThe second measure that we have decided to employ to compare partitions is the Variation of Information (VI) proposed in [Mei05].Define the entropy associated with the partition S as:\nV I(H , H |\u03c0 ) = H(H |\u03c0 ) \u2212 H(H ).\nArmed with these definitions, we can determine how much different intrinsic orderings are able to identify the original host structure.We computed the two measures defined above on a number of web graphs (see Section 8) and using some different orderings described in the literature; more precisely, we considered:\n\n\u2022 Random: a random node order;\n\n\u2022 Natural : for web graphs, this is the URL-based ordering; for the other non-web social networks, it is the order in which nodes are presented, which is essentially arbitrary (and indeed produces compression ratios not very different from random);\n\n\u2022 Gray: the Gray order explained in [BSV09];\n\n\u2022 Shingle: the compression-friendly order described in [CKL + 09];\n\n\u2022 BFS : the breadth-first search traversal order, exploited in [AD09];\n\n\u2022 LLP : the Layered Label Propagation algorithm described in this paper (see Section 6 for details).\n\nThe results of this experiment are shown in Table 1; comparing them with the compression results of Table 7 (that shows the compression performances starting from a truly random order), it is clear that recovering the host structure from random is the key property that is needed for obtaining a real coordinate-free algorithm.However, the only ordering proposed so far that is able to do this is breadth-first search, and its capability to identify hosts seems actually a side effect of the very structure of the web.In the rest of the paper, we use BFS as a strong baseline against which our new results should be compared.9 .\n\n\nName\n\n\nLabel Propagation Algorithms\n\nMost of the intrinsic orderings proposed so far in the literature are unable to produce satisfactory compression ratios when applied to a randomly permuted graph, mainly because they mostly fail in reconstructing host information as we discussed in the last section.To overcome their limitations, we can try to approach this issue as a clustering problem.However, this attempt presents a number of difficulties that are rather peculiar.First of all, the size of the graphs we are dealing with imposes to use algorithms that scale linearly with the number of arcs (and there are very few of them; see [For10]).Moreover, we do not possess any prior information on the number of clusters we should expect and their sizes are going to be highly unbalanced.These difficulties strongly restrict the choice of the clustering algorithm.In the last years, a new family of clustering algorithms were developed starting from the label propagation algorithm presented in [RAK07], that use the network structure alone as their guide and require neither optimisation of a predefined objective function nor prior information about the communities.These algorithms are inherently local, linear in the number of edges, and require just few passes on the graph.\n\nThe main idea of label propagation algorithms is the following: the algorithms execute in rounds, and at the beginning of each round every node has a label representing the cluster that the node currently belongs (at the beginning, every node has a different label).At each round, every node will update its label according to some rule, the update order being chosen at random at the beginning of the round; the algorithm terminates as soon as no more updates take place.Label propagation algorithms differ from each other on the basis of the update rule.\n\nThe algorithm described in [RAK07] (hereafter referred to as standard label propagation or just label propagation) works on a purely local basis: every node takes the label that occurs that we expect in social networks, an algorithm as simple as a breadthfirst search can identify meaningful clusters (see again the BFS column of Table 7), and this leaves room for improvement.more frequently in its neighbourhood10 .Metaphorically, every node in the network chooses to join the largest neighbouring community (i.e., the one to which the maximum number of its neighbours belongs).As labels propagate, densely connected groups of nodes quickly reach a consensus on a unique label.When many such dense consensus groups are created throughout the network, they continue to expand outwards until it is possible to do so.At the end of the propagation process, nodes having the same labels are grouped together as one community.\n\nIt has been proved [TK08] that this kind of label propagation algorithm is formally equivalent to finding the local minima of the Hamiltonian for a kinetic Potts model.This problem has a trivial globally optimal solution when all the nodes have the same label; nonetheless, since the label-propagation optimisation procedure produces only local changes, the search for maxima in the Hamiltonian is prone to becoming trapped at a local optimum instead of reaching the global optimum.While normally a drawback of local search algorithms, this characteristic is essential to clustering: the trivial optimal solution is avoided by the dynamics of the local search algorithm, rather than through formal exclusion.\n\nDespite its efficiency, it was observed that the algorithm just described tends to produce one giant cluster containing the majority of nodes.The presence of this giant component is due to the very topology of social networks; to try to overcome this problem we have tested variants of the label propagation that introduce further constraints.One of the most interesting is the algorithm developed in [BC09], where the update rule is modified in such a way that the objective function being optimised becomes the modularity [NG04] of the resulting clustering.Unfortunately, modularity is not a good measure in very large graphs as pointed out by several authors (e.g., [FB07]) due to its resolution limit that makes it hardly usable on large networks.\n\nAnother variant, called Absolute Pott Model (APM) [?],\n\nintroduces a nonlocal discount based on a resolution parameter \u03b3.For a given node x, let \u03bb 1 , . . ., \u03bb k be the labels currently appearing on the neighbours of x, k i be the number of neighbours of x having label \u03bb i and v i be the overall number of nodes in the graph with label \u03bb i ; when x is updated, instead of choosing the label \u03bb i maximizing k i (as we would do in standard label propagation), we choose it as to maximise (see Algorithm 1)\nk i \u2212 \u03b3(v i \u2212 k i ).\nObserve that when \u03b3 = 0 the algorithm degenerates to label propagation; the reason behind the discount term is that when we decide to join a given community, we are increasing its density because of the k i new edges joining x to existing members of the community, but we are at the same time decreasing it because of v i \u2212 k i non-existing edges.Indeed, it can be shown that the density of the sparsest community at the end of the algorithm is never below \u03b3/(\u03b3 + 1).\n\nAlgorithm 1 The APM algorithm.\u03bb is a function that will provide, at the end, the cluster labels.For the sake of readability, we omitted the resolution of ties.\n\nRequire: G a graph, \u03b3 a density parameter 1: \u03c0 \u2190 a random permutation of G's nodes 2: for all x: \u03bb(x) \u2190 x, v(x) \u2190 1 3: while (some stopping criterion) do 4:\n\nfor i = 0, 1, . . ., n \u2212 1 do This algorithm demonstrated to be the best candidate for our needs.However it has two major drawbacks.The first is that there are no theoretical results that can be used to determine a priori the optimal value of \u03b3 (on the contrary, experiments show that such an optimal value is extremely changeable and does not depend on some obvious parameters like the network size or density).The second is that it tends to produce clusters with sizes that follow a heavy-tailed decreasing distribution, yielding both a huge number of clusters and clusters with a huge number of nodes (see Figure 1).Thus to obtain good compression performances we have to decide both the order between clusters and the order of the nodes that belong to the same cluster.\n\n\nLayered Label Propagation\n\nIn this section we present a new algorithm based on label propagation that yields a compression-friendly ordering.\n\nA run of the APM algorithm (discussed in the previous section) over a given graph and with a given value of the parameter \u03b3 produces as output a clustering, that may be represented as a labelling (mapping each node to the label of the cluster it belongs to).An important observation is that, intuitively, there is no notion of optimality for the tuning of \u03b3: every value of this parameter describes a different resolution of the given graph.Values of \u03b3 close to 0 highlight a coarse structure with few, big and sparse clusters, while, as \u03b3 grows, the clusters are small and dense, unveiling a finegrained structure.Ideally, we would like to find a way to compose clusterings obtained at different resolution levels. 11his intuition leads to the definition of Layered Label Propagation (LLP); this algorithm is iterative and produces a sequence of node orderings; at each iteration, the APM algorithm is run with a suitable value of \u03b3 and the resulting labelling is then turned into an ordering of the graph that keeps nodes with the same label close to one another; nodes within the same cluster are left in the same order they had before.\n\nTo determine the relative order among different clusters, it is worth observing that the actual label produced by the label propagation algorithm suggests a natural choice: since every cluster will be characterised by the initial label of the leader node (the node which flooded that portion of graph; see Algorithm 1), we can sort the clusters according to the order that the leader nodes had.\n\nMore formally, let a sequence \u03b3 0 , \u03b3 1 , \u03b3 2 , . . .and an initial ordering \u03c0 0 : V G \u2192 |V G | of the nodes of G be fixed; we define a sequence of orderings \u03c0 1 , \u03c0 2 , . . .: V G \u2192 |V G | and a sequence of labelling functions \u03bb 0 , \u03bb 1 , . . .: V G \u2192 |V G | as follows: \u03bb k is obtained by running the APM algorithm on the graph G with parameter \u03b3 k ; then we let \u03c0 k+1 be the ordering defined by\nx \u2264 k+1 y iff \u03c0 k (\u03bb k (x)) < \u03c0 k (\u03bb k (y)) or \u03bb k (x) = \u03bb k (y) \u03c0 k (x) \u2264 \u03c0 k (y).\nThe rationale behind this way of composing the newly obtained clustering with the previous ordering is explained above: elements in the same cluster (i.e., with the same label) are ordered as before; for elements with a different label, we use the order that the corresponding labels (i.e., leader nodes) had before.\n\nThe output of LLP actually depends on two elements: the initial ordering \u03c0 0 and the choice of the parameters \u03b3 k at each iteration.\n\nRegarding the choice of the \u03b3 k 's, instead of trying to find at each iteration an optimal value for the parameter we exploit the diverse resolution obtained through different choices of the parameter, thus finding a proper order between clusters that suitably mixes the clusterings obtained at all resolution levels.To obtain this effect, we choose every \u03b3 k uniformly at random in the set12 {0} \u222a {2 \u2212i , i = 0, . . ., K}.Since the APM algorithm is run at every step on the same graph G, it turns out that it is easier (and more efficient) to precompute the labelling function output by the APM algorithm for each \u03b3 in the above set, and then to re-use such labellings.\n\nThe surprising result is that the final ordering obtained by this mutilresolution strategy is better than the ordering obtained by applying the same strategy with K different clusterings generated with the same value of \u03b3 chosen after a grid search for the optimal value (as shown in Table 2), and a fortiori on the ordering induced by one single clustering generated with the optimal \u03b3.Moreover the final order obtained is essentially independent on the initial permutation \u03c0 0 of the graph (as one can see comparing Table 6 with Table 7).\n\nOne may wonder if this iterative strategy can be applied also to improve the performances of other intrinsic orderings.Our experiments rule out this hypothesis.Iterating Gray, lex, or BFS orderings does not produce a significant improvement.\n\n\nParallel Implementation\n\nLayered label propagation lends itself naturally to the taskdecomposition parallel-programming paradigm, which may dramatically improve performances on modern multicore architectures: since the update order is randomised, there is no obstacle in updating several nodes in parallel.Our implementation breaks the set of nodes into a very small number of tasks (in the order of thousands).A large number of threads picks up the first available task and solves it: as a result, we obtain a performance improvement that is linear in the number of cores.We are helped by WebGraph's facilities, which allows us to provide each thread with a lightweight copy of the graph that shares the bitstream and associated information with all other threads.\n\n\nExperiments\n\nFor our experiments, we considered a number of graphs with various sizes and characteristics; most of them are (directed or undirected) social graphs of some kind, but we also considered some web graphs for comparison (because for web graphs we can rely on the URLs as external source of information).More precisely, we used the following datasets (see also Table 3 and 4):\n\n\u2022 Hollywood : One of the most popular undirected social graphs, the graph of movie actors: vertices are actors, and two actors are joined by an edge whenever they appeared in a movie together.\n\n\u2022 DBLP : DBLP 13 is a bibliography service from which an undirected scientific collaboration network can be extracted: each vertex of this undirected graph represents a scientist and two vertices are connected if they have worked together on an article.\n\n\u2022 LiveJournal : LiveJournal 14 is a virtual community social site started in 1999: nodes are users and there is 13 http://www.informatik.uni-trier.de/~ley/db/ 14 http://www.livejournal.com/an arc from x to y if x registered y among his friends (it is not necessary to ask y permission, so the graph is directed ).We considered the same 2008 snapshot of LiveJournal used in [CKL + 09] for their experiments15 .\n\n\u2022 Amazon: This dataset describes similarity among books as reported by the Amazon store; more precisely the data was obtained16 in 2008 using the Amazon E-Commerce Service APIs using SimilarityLookup queries.\n\n\u2022 Enron: This dataset was made public by the Federal Energy Regulatory Commission during its investigations: it is a partially anonymised corpus of e-mail messages exchanged by some Enron employees (mostly part of the senior management).We turned this dataset into a directed graph, whose nodes represent people and with an arc from x to y whenever y was the recipient of (at least) a message sent by x.\n\n\u2022 Flickr : Flickr17 is an online community where users can share photographs and videos.In Flickr the notion of acquaintance is modelled through contacts; we used an undirected version of this network, where vertices correspond to users and there is an edge connecting x and y whenever either vertex is recorded as a contact of the other one.\n\n\u2022 For comparison, we considered five web graphs of various sizes (ranging from about 800 thousand nodes to more than 650 million nodes), available at the LAW web site http://law.dsi.unimi.it/.\n\n\u2022 Finally, the altavista-nd graph was obtained from the Altavista dataset distributed by Yahoo! within the Webscope program (AltaVista webpage connectivity dataset, version 1.018 ).With respect to the original dataset, we pruned all dangling nodes (\"nd\" stands for \"no dangling\").Each graph was compressed in the BV format using We-bGraph [BV04]20 and we measured the compression performance using the number of bits/link actually occupied by the graph file.\n\nWe also compared LLP+BV with the compression obtained using the algorithm proposed by Apostolico and Drovandi [AD09] at level 8 starting from a randomly permuted graph; the results, shown in Table 5, provide evidence that LLP+BV outperforms AD in all cases, and in a significant way on social networks and large web graphs.This is particularly relevant, since the compression algorithm of AD is designed to take full advantage of a specific ordering (the breadth-first search) and is the only known coordinate-free alternative we are aware of.In our comparison, contrarily to all other tables, we used the full compression power of the BV format, as our intent is to motivate LLP+BV as a very competitive coordinate-free compression algorithm.In the rest of the paper, as we already explained, we have turned off intervalisation, as our purpose is to study the effect of different permutations on locality and similarity: this explains why the bits per link found in A comment is needed about the bad performance the Apostolico-Drovandi method on the altavista-nd dataset.Apparently, the size of the dataset is such that scrambling it by a random permutation causes the method to use a bad naming for the nodes, in spite of the initial breadth-first visit.In our previous experiments, the Apostolico-Drovandi method did not show variations of more than 20% in compression due to random permutations, but clearly the issue needs to be investigated again.\n\n\nResults\n\nTables 6 and 7 present the number of bits per link required by our datasets under the different orderings discussed above and produced starting from the natural order and from a random order (the percentages shown in parenthesis give the gain w.r.t.breadth-first search ordering).Here are some observations that the experimental results suggest:\n\n\u2022 LLP provides always the best compression, with an average gain of 25% with respect to BFS, and largely outperforms both simple Gray [BSV09] and shingle orderings [CKL + 09].Some simple experiments not reported here shows that the same happen for transposed graphs: for instance, uk is compressed at 1.06 bits per link.This makes LLP+BV encoding by far the best compressed data structure available today.\n\n\u2022 LLP is extremely robust with respect to the initial ordering of nodes and its combination with BV provides actually a coordinate-free compressed data structure.Other orderings (in particular, Gray and shingle) are much more sensitive to the initial numbering, especially on web graphs.We urge researchers in this field to always generate permutations starting from a randomised copy of the graph, as \"useful\" ordering information in the original dataset can percolate as an artifact in the final results.\n\n\u2022 As already remarked elsewhere [CKL + 09], social networks seem to be harder to compress than web graphs: this fact would suggest that there should be some yet unexplained topological difference between the two kinds of graphs that accounts for the different compression ratio.\n\nDespite the great improvement in terms of compression results our technique remains highly scalable.All experiments are performed on a Linux server equipped with Intel Xeon X5660 CPUs (2.80 GHz, 12 MB cache size) for overall 24 cores and 128 GB of RAM; the server cost about 8 900 EUR in 2010.Our Java implementation of LLP sports a linear scaling in the number of arcs with an average speed of \u2248 80 000 000 arcs/s per iteration.The overall time cost of the algorithm depends on the number \u03b3's and on the stopping criterion.With our typical setting the overall speed of the algorithm is \u2248 800 000 arcs/s.\n\nThe algorithm is also very memory efficient (it uses 3n integers plus the space required by the graph21 ) and it is easy to distribute, making a good candidate for huge networks.Indeed, most of the time is spent on sampling values of \u03b3 to produce base clusterings,22 and this operation can be performed for each \u03b3 in a fully parallel way.Applying LLP to a web graph with 1 billion nodes and 50 billions arcs would require few hours in this setting.\n\nFor comparison, we also tried to compress our dataset using the alternative versions of LLP described in Section 5: in particular, we considered APM (with the optimal choice of \u03b3) and the combination APM+Gray (that sorts each APM cluster using Gray).Besides the number of bits per link, we also analysed two measures that quantify two different structural properties:\n\n\u2022 the average gap cost (i.e., the average of the base-2 logarithms of the gaps between the successors of a node: this is an approximate measure of the number of bits required to write the gaps using a universal variable-length code); this measure is intended to account for locality:\n\nthe average gap cost is small if the ordering tends to keep well-connected nodes close to one another;23\n\n\u2022 the percentage of copied arcs (i.e., the number of arcs that are not written explicitly but rather obtained by reference from a previous successor list); this is intended to account for similarity: this percentage is small if the ordering tends to keep nodes with similar successor lists close to one another.\n\nThe results obtained are presented in Table 8.In most cases APM copies a smaller percentage of arcs than APM+Gray, because Gray precisely aims at optimising similarity rather than locality; this phenomenon is less pronounced on web graphs, where anyway the overall number of copied arcs is larger; looking at the average gap cost, all clustering methods turn out to do a better job than Gray in improving locality (data not shown in the table).LLP usually copies less arcs than APM+Gray, but the difference is often negligible and definitely balanced by the gain in locality.\n\nWe would like to point out that, at least when using the best compression currently available (LLP+BV), the average gap cost is definitely more correlated with compression rates than the average distance cost, that is, the average of the logarithms of the (absolute) difference between the source and target of each arc (see Figure 2).Indeed, the correlation coefficient is 0.9681 between bits per link and average gap cost and 0.1742 between bits per link and average distance cost.In [CKL + 09] the problems MLogA and MLogGapA consist exactly in minimising the average distance and the average gap cost, respectively: that authors claim that both problems capture the essence of a good ordering, but our extensive experimentation suggests otherwise.\n\nAs a final remark, it is worth noticing that similarity and locality have a different impact in social networks than in web graphs: in web graphs the percentage of copied arcs is much larger (a clue of the presence of a better-defined structure) and in fact it completely determines the number of bits per link, whilst in social networks the compression ratio is entirely established by the gain of locality (measured, as usual, by the average gap cost).\n\n\nConclusions and Future Work\n\nWe have presented highly scalable techniques that improve compressed data structures for representing web graphs and social networks significantly beyond the current state-of-art.More importantly, we have shown that coordinate-free methods can outperform state-of-art extrinsic techniques on a large range of networks.The clustering techniques we have devised are scalable to billions of nodes, as they just require few linear passes over the graphs involved.In some cases (e.g., the uk dataset) we bring down the cost of a link to 1.8 bits.We remark again that our improvements are measured w.r.t. the BFS baseline, which is itself often an improvement when compared to the existing literature.\n\nFinally, we leave for future work a full investigation of the compression ratio that can be obtained when fast access is not required.For instance, uk compressed by LLP+BV at maximum compression requires only 1.21 bits per link-better, for instance, than the Apostolico-Drovandi method with maximum compression (1.44).Some partial experimental data suggests that we would obtain by far the highest compression ratio currently available.\n\nThe experiments that we report required several thousands of hours of computation: we plan to make available the results both under the form of WebGraph property files (which contain a wealth of statistical data) and under the form of comprehensive graphical representations.\n\n\n\nH(S ) = \u2212 S\u2208S P (S) log(P (S)) where P (S) = |S| |V G | and the mutual information between two partitions as: I(S , T ) = S\u2208S T \u2208T P (S, T ) log P (S, T ) P (S)P (T ) where P (S, T ) = |S\u2229T | |V G | .The Variation of information is then defined as V I(S , T ) = H(S ) + H(T ) \u2212 2 I(S , T ); notice that, in our setting, since H |\u03c0 is always a refinement of H , we have I(H , H |\u03c0 ) = H(H ) and so VI simplifies into\n\n\n5 :Figure 1 :\n51\nFigure 1: An example of the distribution of cluster sizes computed by APM.\n\n\nFigure 2 :\n2\nFigure 2: Bits per link against average gap (left) and distance (right) cost.points indicates web graphs while 3 points indicates social graph.\n\n\nTable 1 :\n1\nVarious measures to evaluate the ability of different orderings to recover host information.Smaller values indicate a better recovery.\nLLPBFSShingleGrayNaturalRandomHTVIHTVIHTVIHTVIHTVIHTVIeu1.58% 4.60 2.04% 4.60 20.12% 7.33 20.09% 7.55 0.05% 0.00 97.11% 13.80in1.83% 1.92 2.53% 2.32 15.83% 4.51 37.11% 6.76 0.32% 0.00 99.62% 11.37indochina 1.37% 1.61 1.99% 2.63 32.05% 6.03 30.96% 5.93 0.26% 0.00 99.93% 11.71it3.05% 2.63 2.93% 2.83 27.04% 5.32 26.18% 5.27 0.34% 0.00 99.99% 11.45uk2.52% 2.88 1.29% 2.65 20.64% 5.52 19.93% 5.46 0.11% 0.00 99.98% 13.76\n\nTable 2 :\n2\nComparison between LLP with different values of \u03b3 and LLP with the best value of \u03b3 only.Values are bits per link.\nNameLLPFixed LLPAmazon9.129.43(+3%)DBLP6.877.13(+3%)Enron6.456.90(+6%)Hollywood5.175.55(+7%)LiveJournal10.9511.40(+4%)Flickr8.99.27(+4%)indochina (hosts)5.576.25 (+12%)uk (hosts)6.356.79(+6%)eu3.884.46 (+14%)in2.442.99 (+22%)indochina1.681.92 (+14%)it2.052.59 (+26%)uk1.82.27 (+26%)\n\nTable 3 :\n3\nSocial graph description.\nThe original graph, indeed, contains 53.74%dangling nodes (a preposterous percentage [Vig07]),probably because it also considers the frontier of thecrawl-the nodes that have been discovered but not vis-ited. We eliminated (one level of) dangling nodes toapproximate the set of visited nodes, and also becausedangling nodes are of little importance in compression. 19\n\nTable 4 :\n4\nWeb graph description.\n\n\nTable 5 :\n5\nTable 5 are smaller than elsewhere in the paper.Comparison between LLP+BV compression (for this particular table, the full set of compression tecniques available in WebGraph has been used, including intervalisation) and the algorithm proposed by Apostolico and Drovandi (AD) at level 8. Values are bits per link.\nNameLLP+BVADAmazon9.1312.39(+36%)DBLP6.827.47(+10%)Enron6.077.74(+28%)Hollywood4.997.64(+53%)LiveJournal10.9114.97(+37%)Flickr8.911.19(+26%)indochina (hosts)5.426.83(+26%)uk (hosts)6.197.85(+27%)eu3.784.01(+6%)in2.242.39(+7%)indochina1.531.70(+11%)it1.912.31(+21%)uk1.722.32(+36%)altavista-nd5.1611.04 (+114%)\nThroughout this paper, we use von Neumann's notation n = { 0, 1, . . . , n \u2212 1 }.\nHere we are disregarding the problem that \u03c0 is not unique if the adjacency matrix contains duplicated rows. This issue turns out to have a negligible impact on compression and will be ignored in the following.\nSince in the rest of this paper we will only deal with this Gray ordering, we will simply omit the adjective \"reflective\" in the following.\nThe quite extensive survey in[BSV10] shows that many other approaches to web-graph compression, not quoted here, either fail to compress social networks, or are strongly dependent on the initial ordering of the\ngraph.7  Our experiments show in fact a very limited variation in compression (10-15%) when starting from URL ordering or from a random permutation, except for the altavista-nd dataset, which however is quite pathological.\nhttp://www.mcs.anl.gov/~safro/mloga.html. The authors had been provided a preliminary version of our code to perform their tests.\nIt is unlikely that, in presence of the more complicated structure\nIn the case of ties, a random choice is performed, unless the current label of the node is one of the most frequent in its neighbourhood, in which case the label is simply not changed.\nOf course, such a compositional approach could be applied also to other scalable clustering techniques: we have experimented with several alternatives[For10], and APM is by far the most interesting candidate.\nAlthough in theory \u03b3 could be larger than 1, such a choice would be of no practical use on large networks, because it would only yield a complete fragmentation of the graph.\nThe dataset was kindly provided by the authors of [CKL + 09].\nhttp://www.archive.org/details/amazon_similarity_isbn/\nhttp://www.flickr.com/; we thank Yahoo! for the experimental results on the Flickr graph.\nhttp://research.yahoo.com/Academic_Relations\nIt should be remarked by this graph, albeit widely used in the literature, is not a good dataset. As we already noted, most likely all nodes in the frontier of the crawler (and not only visited nodes) were added to the graph; moreover, the giant component is less than 4% of the whole graph.\nWe adopted the default window size (W = 7), disabled intervalisation and put a limit of 3 to the length of the possible reference chains (see[BSV09] for details on the r\u00f4le of this parameter). Observe that the latter two settings tend to deteriorate the compression results, but make decompression extremely efficient even when random access is required.\nIt is possible in principle to avoid keeping the graph in main memory, but the cost becomes O(n log n).\nThe combination of clusterings is extremely fast, as it is linear in the number of nodes, rather than in the number of arcs, and has little impact on the overall run time.\nWe remark that the average gap cost is essentially an amortised version of the standard gap measure used in the context of data-aware compressed data structures[GHSV07].\n\nGraph compression by BFS. Alberto Apostolico, Guido Drovandi, Algorithms. 232009\n\nThe Connectivity Server: fast access to linkage information on the Web. Computer Networks and ISDN Systems. ] K Bbh + 98, A Bharat, M Broder, P Henzinger, S Kumar, Venkatasubramanian, 199830\n\nDetecting network communities by propagating labels under constraints. J Michael, John W Barber, Clark, Phys. Rev. E. 80226129Aug 2009\n\nPermuting web graphs. Paolo Boldi, Massimo Santini, Sebastiano Vigna, WAW '09: Proceedings of the 6th International Workshop on Algorithms and Models for the Web-Graph. Berlin, HeidelbergSpringer-Verlag2009\n\nPermuting web and social graphs. Paolo Boldi, Massimo Santini, Sebastiano Vigna, Internet Math. 632010\n\nThe We-bGraph framework I: Compression techniques. Paolo Boldi, Sebastiano Vigna, Proc. of the Thirteenth International World Wide Web Conference. of the Thirteenth International World Wide Web ConferenceACM Press2004\n\nAlessandro Panconesi, and Prabhakar Raghavan. Flavio Chierichetti, Ravi Kumar, Silvio Lattanzi, Michael Mitzenmacher, CKL + 09KDD '09: Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining. New York, NY, USAACM2009On compressing social networks\n\nResolution limit in community detection. S Fortunato, M Barthelemy, Proceedings of the National Academy of Science. 104January 2007\n\nCommunity detection in graphs. S Fortunato, Physics Report. 486February 2010\n\nCompressed data structures: Dictionaries and data-aware measures. Ankur Gupta, Wing-Kai Hon, Rahul Shah, Jeffrey Scott Vitter, Theoret. Comput. Sci. 38732007\n\nCompressing network graphs. A C Gilbert, K Levchenko, Proceedings of the LinkKDD workshop at the 10th ACM Conference on KDD. the LinkKDD workshop at the 10th ACM Conference on KDDAugust 2004\n\nSpace-efficient static trees and graphs. Guy Jacobson, 30th Annual Symposium on Foundations of Computer Science. Research Triangle Park, North CarolinaIEEE1989\n\nFascicle 2: Generating All Tuples and Permutations (Art of Computer Programming). Donald E Knuth, 2005. 2008David Knoke and Song Yang. Social Network Analysis. Sage Publications, Inc4The Art of Computer Programming. second edition edition\n\nComparing clusterings: an axiomatic view. Marina Meil\u01ce, ICML '05: Proceedings of the 22nd international conference on Machine learning. New York, NY, USAACM2005\n\nNeighbor query friendly compression of social networks. H Maserrat, J Pei, Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining. the 16th ACM SIGKDD international conference on Knowledge discovery and data miningACM2010\n\nFinding and evaluating community structure in networks. M E J Newman, M Girvan, Phys. Rev. E. 69226113Feb 2004\n\nNear linear time algorithm to detect community structures in large-scale networks. Usha N Raghavan, R\u00e9ka Albert, Soundar Kumara, Physical Review E (Statistical, Nonlinear, and Soft Matter Physics). 7632007\n\nA highly accurate and resolution-limit-free Potts model for community detection. P Ronhovde, Z Nussinov, March 2008ArXiv e-prints\n\nThe Link Database: Fast access to graphs of the web. H Keith, Raymie Randall, Janet L Stata, Rajiv G Wiener, Wickremesinghe, Proceedings of the Data Compression Conference. the Data Compression ConferenceWashington, DC, USAIEEE Computer Society2002\n", "annotations": {"author": "[{\"end\":215,\"start\":121},{\"end\":309,\"start\":216},{\"end\":408,\"start\":310},{\"end\":508,\"start\":409}]", "publisher": null, "author_last_name": "[{\"end\":132,\"start\":127},{\"end\":226,\"start\":222},{\"end\":325,\"start\":318},{\"end\":425,\"start\":420}]", "author_first_name": "[{\"end\":126,\"start\":121},{\"end\":221,\"start\":216},{\"end\":317,\"start\":310},{\"end\":419,\"start\":409}]", "author_affiliation": "[{\"end\":214,\"start\":134},{\"end\":308,\"start\":228},{\"end\":407,\"start\":327},{\"end\":507,\"start\":427}]", "title": "[{\"end\":102,\"start\":1},{\"end\":610,\"start\":509}]", "venue": null, "abstract": "[{\"end\":1888,\"start\":684}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b11\"},\"end\":4221,\"start\":4214},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":4531,\"start\":4525},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":4790,\"start\":4782},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":6704,\"start\":6698},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":7545,\"start\":7537},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":7978,\"start\":7970},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":8013,\"start\":8006},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":8075,\"start\":8068},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":8480,\"start\":8473},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":8758,\"start\":8751},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":10241,\"start\":10234},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":11888,\"start\":11882},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":12529,\"start\":12523},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":15951,\"start\":15944},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":17448,\"start\":17441},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":18180,\"start\":18173},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":19700,\"start\":19693},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":20059,\"start\":20052},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":20930,\"start\":20923},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":22937,\"start\":22931},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":23205,\"start\":23199},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":33191,\"start\":33185},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":35028,\"start\":35021},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":44634,\"start\":44627},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":45571,\"start\":45564},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":46489,\"start\":46482},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":47140,\"start\":47132}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":41857,\"start\":41438},{\"attributes\":{\"id\":\"fig_1\"},\"end\":41951,\"start\":41858},{\"attributes\":{\"id\":\"fig_2\"},\"end\":42110,\"start\":41952},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":42676,\"start\":42111},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":43086,\"start\":42677},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":43492,\"start\":43087},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":43529,\"start\":43493},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":44165,\"start\":43530}]", "paragraph": "[{\"end\":2989,\"start\":1904},{\"end\":3593,\"start\":2991},{\"end\":4386,\"start\":3595},{\"end\":4791,\"start\":4388},{\"end\":4895,\"start\":4793},{\"end\":4980,\"start\":4897},{\"end\":5853,\"start\":4982},{\"end\":6272,\"start\":5894},{\"end\":6494,\"start\":6287},{\"end\":7117,\"start\":6496},{\"end\":7491,\"start\":7119},{\"end\":7902,\"start\":7493},{\"end\":9063,\"start\":7904},{\"end\":9745,\"start\":9065},{\"end\":10345,\"start\":9747},{\"end\":10875,\"start\":10347},{\"end\":11769,\"start\":10877},{\"end\":12495,\"start\":11771},{\"end\":13182,\"start\":12497},{\"end\":13970,\"start\":13184},{\"end\":14062,\"start\":13991},{\"end\":14346,\"start\":14064},{\"end\":14699,\"start\":14348},{\"end\":15250,\"start\":14701},{\"end\":15564,\"start\":15252},{\"end\":15700,\"start\":15566},{\"end\":15917,\"start\":15758},{\"end\":16302,\"start\":15919},{\"end\":16383,\"start\":16304},{\"end\":16711,\"start\":16453},{\"end\":17066,\"start\":16713},{\"end\":17318,\"start\":17113},{\"end\":17503,\"start\":17320},{\"end\":17853,\"start\":17539},{\"end\":17885,\"start\":17855},{\"end\":18135,\"start\":17887},{\"end\":18181,\"start\":18137},{\"end\":18249,\"start\":18183},{\"end\":18321,\"start\":18251},{\"end\":18423,\"start\":18323},{\"end\":19053,\"start\":18425},{\"end\":20336,\"start\":19093},{\"end\":20894,\"start\":20338},{\"end\":21818,\"start\":20896},{\"end\":22528,\"start\":21820},{\"end\":23281,\"start\":22530},{\"end\":23337,\"start\":23283},{\"end\":23787,\"start\":23339},{\"end\":24276,\"start\":23809},{\"end\":24437,\"start\":24278},{\"end\":24595,\"start\":24439},{\"end\":25370,\"start\":24597},{\"end\":25514,\"start\":25400},{\"end\":26655,\"start\":25516},{\"end\":27051,\"start\":26657},{\"end\":27450,\"start\":27053},{\"end\":27851,\"start\":27535},{\"end\":27985,\"start\":27853},{\"end\":28658,\"start\":27987},{\"end\":29200,\"start\":28660},{\"end\":29443,\"start\":29202},{\"end\":30211,\"start\":29471},{\"end\":30600,\"start\":30227},{\"end\":30794,\"start\":30602},{\"end\":31049,\"start\":30796},{\"end\":31460,\"start\":31051},{\"end\":31670,\"start\":31462},{\"end\":32075,\"start\":31672},{\"end\":32419,\"start\":32077},{\"end\":32613,\"start\":32421},{\"end\":33073,\"start\":32615},{\"end\":34528,\"start\":33075},{\"end\":34885,\"start\":34540},{\"end\":35292,\"start\":34887},{\"end\":35800,\"start\":35294},{\"end\":36080,\"start\":35802},{\"end\":36686,\"start\":36082},{\"end\":37136,\"start\":36688},{\"end\":37505,\"start\":37138},{\"end\":37790,\"start\":37507},{\"end\":37896,\"start\":37792},{\"end\":38209,\"start\":37898},{\"end\":38786,\"start\":38211},{\"end\":39539,\"start\":38788},{\"end\":39995,\"start\":39541},{\"end\":40722,\"start\":40027},{\"end\":41160,\"start\":40724},{\"end\":41437,\"start\":41162},{\"end\":41856,\"start\":41441},{\"end\":41950,\"start\":41876},{\"end\":42109,\"start\":41966},{\"end\":42258,\"start\":42124},{\"end\":42803,\"start\":42690},{\"end\":43125,\"start\":43100},{\"end\":43528,\"start\":43506},{\"end\":43855,\"start\":43543}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":6286,\"start\":6273},{\"attributes\":{\"id\":\"formula_1\"},\"end\":16452,\"start\":16384},{\"attributes\":{\"id\":\"formula_2\"},\"end\":17112,\"start\":17067},{\"attributes\":{\"id\":\"formula_3\"},\"end\":17538,\"start\":17504},{\"attributes\":{\"id\":\"formula_4\"},\"end\":23808,\"start\":23788},{\"attributes\":{\"id\":\"formula_5\"},\"end\":27534,\"start\":27451}]", "table_ref": "[{\"end\":10782,\"start\":10781},{\"end\":10873,\"start\":10872},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":12493,\"start\":12492},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":18476,\"start\":18475},{\"end\":18532,\"start\":18531},{\"end\":21233,\"start\":21232},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":28951,\"start\":28950},{\"end\":29185,\"start\":29184},{\"end\":29198,\"start\":29197},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":30592,\"start\":30591},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":33273,\"start\":33272},{\"end\":38256,\"start\":38255}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1902,\"start\":1890},{\"attributes\":{\"n\":\"2\"},\"end\":5892,\"start\":5856},{\"attributes\":{\"n\":\"3\"},\"end\":13989,\"start\":13973},{\"attributes\":{\"n\":\"4\"},\"end\":15756,\"start\":15703},{\"end\":19060,\"start\":19056},{\"attributes\":{\"n\":\"5\"},\"end\":19091,\"start\":19063},{\"attributes\":{\"n\":\"6\"},\"end\":25398,\"start\":25373},{\"attributes\":{\"n\":\"7\"},\"end\":29469,\"start\":29446},{\"attributes\":{\"n\":\"8\"},\"end\":30225,\"start\":30214},{\"attributes\":{\"n\":\"9\"},\"end\":34538,\"start\":34531},{\"attributes\":{\"n\":\"10\"},\"end\":40025,\"start\":39998},{\"end\":41872,\"start\":41859},{\"end\":41963,\"start\":41953},{\"end\":42121,\"start\":42112},{\"end\":42687,\"start\":42678},{\"end\":43097,\"start\":43088},{\"end\":43503,\"start\":43494},{\"end\":43540,\"start\":43531}]", "table": "[{\"end\":42676,\"start\":42259},{\"end\":43086,\"start\":42804},{\"end\":43492,\"start\":43126},{\"end\":44165,\"start\":43856}]", "figure_caption": "[{\"end\":41857,\"start\":41440},{\"end\":41951,\"start\":41875},{\"end\":42110,\"start\":41965},{\"end\":42259,\"start\":42123},{\"end\":42804,\"start\":42689},{\"end\":43126,\"start\":43099},{\"end\":43529,\"start\":43505},{\"end\":43856,\"start\":43542}]", "figure_ref": "[{\"end\":25214,\"start\":25213},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":39121,\"start\":39120}]", "bib_author_first_name": "[{\"end\":47176,\"start\":47169},{\"end\":47194,\"start\":47189},{\"end\":47334,\"start\":47333},{\"end\":47336,\"start\":47335},{\"end\":47348,\"start\":47347},{\"end\":47358,\"start\":47357},{\"end\":47368,\"start\":47367},{\"end\":47381,\"start\":47380},{\"end\":47489,\"start\":47488},{\"end\":47503,\"start\":47499},{\"end\":47505,\"start\":47504},{\"end\":47580,\"start\":47575},{\"end\":47595,\"start\":47588},{\"end\":47615,\"start\":47605},{\"end\":47799,\"start\":47794},{\"end\":47814,\"start\":47807},{\"end\":47834,\"start\":47824},{\"end\":47921,\"start\":47916},{\"end\":47939,\"start\":47929},{\"end\":48136,\"start\":48130},{\"end\":48155,\"start\":48151},{\"end\":48169,\"start\":48163},{\"end\":48187,\"start\":48180},{\"end\":48417,\"start\":48416},{\"end\":48430,\"start\":48429},{\"end\":48540,\"start\":48539},{\"end\":48657,\"start\":48652},{\"end\":48673,\"start\":48665},{\"end\":48684,\"start\":48679},{\"end\":48698,\"start\":48691},{\"end\":48704,\"start\":48699},{\"end\":48774,\"start\":48773},{\"end\":48776,\"start\":48775},{\"end\":48787,\"start\":48786},{\"end\":48981,\"start\":48978},{\"end\":49186,\"start\":49180},{\"end\":49188,\"start\":49187},{\"end\":49386,\"start\":49380},{\"end\":49557,\"start\":49556},{\"end\":49569,\"start\":49568},{\"end\":49824,\"start\":49823},{\"end\":49828,\"start\":49825},{\"end\":49838,\"start\":49837},{\"end\":49966,\"start\":49962},{\"end\":49968,\"start\":49967},{\"end\":49983,\"start\":49979},{\"end\":49999,\"start\":49992},{\"end\":50168,\"start\":50167},{\"end\":50180,\"start\":50179},{\"end\":50271,\"start\":50270},{\"end\":50285,\"start\":50279},{\"end\":50300,\"start\":50295},{\"end\":50302,\"start\":50301},{\"end\":50315,\"start\":50310},{\"end\":50317,\"start\":50316}]", "bib_author_last_name": "[{\"end\":47187,\"start\":47177},{\"end\":47203,\"start\":47195},{\"end\":47345,\"start\":47337},{\"end\":47355,\"start\":47349},{\"end\":47365,\"start\":47359},{\"end\":47378,\"start\":47369},{\"end\":47387,\"start\":47382},{\"end\":47407,\"start\":47389},{\"end\":47497,\"start\":47490},{\"end\":47512,\"start\":47506},{\"end\":47519,\"start\":47514},{\"end\":47586,\"start\":47581},{\"end\":47603,\"start\":47596},{\"end\":47621,\"start\":47616},{\"end\":47805,\"start\":47800},{\"end\":47822,\"start\":47815},{\"end\":47840,\"start\":47835},{\"end\":47927,\"start\":47922},{\"end\":47945,\"start\":47940},{\"end\":48149,\"start\":48137},{\"end\":48161,\"start\":48156},{\"end\":48178,\"start\":48170},{\"end\":48200,\"start\":48188},{\"end\":48427,\"start\":48418},{\"end\":48441,\"start\":48431},{\"end\":48550,\"start\":48541},{\"end\":48663,\"start\":48658},{\"end\":48677,\"start\":48674},{\"end\":48689,\"start\":48685},{\"end\":48711,\"start\":48705},{\"end\":48784,\"start\":48777},{\"end\":48797,\"start\":48788},{\"end\":48990,\"start\":48982},{\"end\":49194,\"start\":49189},{\"end\":49392,\"start\":49387},{\"end\":49566,\"start\":49558},{\"end\":49573,\"start\":49570},{\"end\":49835,\"start\":49829},{\"end\":49845,\"start\":49839},{\"end\":49977,\"start\":49969},{\"end\":49990,\"start\":49984},{\"end\":50006,\"start\":50000},{\"end\":50177,\"start\":50169},{\"end\":50189,\"start\":50181},{\"end\":50277,\"start\":50272},{\"end\":50293,\"start\":50286},{\"end\":50308,\"start\":50303},{\"end\":50324,\"start\":50318},{\"end\":50340,\"start\":50326}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":17517615},\"end\":47223,\"start\":47143},{\"attributes\":{\"id\":\"b1\"},\"end\":47415,\"start\":47225},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":33388193},\"end\":47551,\"start\":47417},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":17374739},\"end\":47759,\"start\":47553},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":16543597},\"end\":47863,\"start\":47761},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":14428620},\"end\":48082,\"start\":47865},{\"attributes\":{\"doi\":\"CKL + 09\",\"id\":\"b6\"},\"end\":48373,\"start\":48084},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":6937661},\"end\":48506,\"start\":48375},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":10211629},\"end\":48584,\"start\":48508},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":15766521},\"end\":48743,\"start\":48586},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":12451527},\"end\":48935,\"start\":48745},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":6867226},\"end\":49096,\"start\":48937},{\"attributes\":{\"id\":\"b12\"},\"end\":49336,\"start\":49098},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":578125},\"end\":49498,\"start\":49338},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":1509181},\"end\":49765,\"start\":49500},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":169860743},\"end\":49877,\"start\":49767},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":18741059},\"end\":50084,\"start\":49879},{\"attributes\":{\"id\":\"b17\"},\"end\":50215,\"start\":50086},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":7896593},\"end\":50465,\"start\":50217}]", "bib_title": "[{\"end\":47167,\"start\":47143},{\"end\":47486,\"start\":47417},{\"end\":47573,\"start\":47553},{\"end\":47792,\"start\":47761},{\"end\":47914,\"start\":47865},{\"end\":48128,\"start\":48084},{\"end\":48414,\"start\":48375},{\"end\":48537,\"start\":48508},{\"end\":48650,\"start\":48586},{\"end\":48771,\"start\":48745},{\"end\":48976,\"start\":48937},{\"end\":49378,\"start\":49338},{\"end\":49554,\"start\":49500},{\"end\":49821,\"start\":49767},{\"end\":49960,\"start\":49879},{\"end\":50268,\"start\":50217}]", "bib_author": "[{\"end\":47189,\"start\":47169},{\"end\":47205,\"start\":47189},{\"end\":47347,\"start\":47333},{\"end\":47357,\"start\":47347},{\"end\":47367,\"start\":47357},{\"end\":47380,\"start\":47367},{\"end\":47389,\"start\":47380},{\"end\":47409,\"start\":47389},{\"end\":47499,\"start\":47488},{\"end\":47514,\"start\":47499},{\"end\":47521,\"start\":47514},{\"end\":47588,\"start\":47575},{\"end\":47605,\"start\":47588},{\"end\":47623,\"start\":47605},{\"end\":47807,\"start\":47794},{\"end\":47824,\"start\":47807},{\"end\":47842,\"start\":47824},{\"end\":47929,\"start\":47916},{\"end\":47947,\"start\":47929},{\"end\":48151,\"start\":48130},{\"end\":48163,\"start\":48151},{\"end\":48180,\"start\":48163},{\"end\":48202,\"start\":48180},{\"end\":48429,\"start\":48416},{\"end\":48443,\"start\":48429},{\"end\":48552,\"start\":48539},{\"end\":48665,\"start\":48652},{\"end\":48679,\"start\":48665},{\"end\":48691,\"start\":48679},{\"end\":48713,\"start\":48691},{\"end\":48786,\"start\":48773},{\"end\":48799,\"start\":48786},{\"end\":48992,\"start\":48978},{\"end\":49196,\"start\":49180},{\"end\":49394,\"start\":49380},{\"end\":49568,\"start\":49556},{\"end\":49575,\"start\":49568},{\"end\":49837,\"start\":49823},{\"end\":49847,\"start\":49837},{\"end\":49979,\"start\":49962},{\"end\":49992,\"start\":49979},{\"end\":50008,\"start\":49992},{\"end\":50179,\"start\":50167},{\"end\":50191,\"start\":50179},{\"end\":50279,\"start\":50270},{\"end\":50295,\"start\":50279},{\"end\":50310,\"start\":50295},{\"end\":50326,\"start\":50310},{\"end\":50342,\"start\":50326}]", "bib_venue": "[{\"end\":47215,\"start\":47205},{\"end\":47331,\"start\":47225},{\"end\":47533,\"start\":47521},{\"end\":47720,\"start\":47623},{\"end\":47855,\"start\":47842},{\"end\":48010,\"start\":47947},{\"end\":48317,\"start\":48210},{\"end\":48489,\"start\":48443},{\"end\":48566,\"start\":48552},{\"end\":48733,\"start\":48713},{\"end\":48868,\"start\":48799},{\"end\":49048,\"start\":48992},{\"end\":49178,\"start\":49098},{\"end\":49472,\"start\":49394},{\"end\":49673,\"start\":49575},{\"end\":49859,\"start\":49847},{\"end\":50075,\"start\":50008},{\"end\":50165,\"start\":50086},{\"end\":50388,\"start\":50342},{\"end\":47740,\"start\":47722},{\"end\":48069,\"start\":48012},{\"end\":48336,\"start\":48319},{\"end\":48924,\"start\":48870},{\"end\":49088,\"start\":49050},{\"end\":49491,\"start\":49474},{\"end\":49758,\"start\":49675},{\"end\":50440,\"start\":50390}]"}}}, "year": 2023, "month": 12, "day": 17}