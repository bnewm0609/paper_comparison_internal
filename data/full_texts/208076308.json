{"id": 208076308, "updated": "2023-10-06 21:14:01.25", "metadata": {"title": "Single Image Reflection Removal through Cascaded Refinement", "authors": "[{\"first\":\"Chao\",\"last\":\"Li\",\"middle\":[]},{\"first\":\"Yixiao\",\"last\":\"Yang\",\"middle\":[]},{\"first\":\"Kun\",\"last\":\"He\",\"middle\":[]},{\"first\":\"Stephen\",\"last\":\"Lin\",\"middle\":[]},{\"first\":\"John\",\"last\":\"Hopcroft\",\"middle\":[\"E.\"]}]", "venue": "ArXiv", "journal": "2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)", "publication_date": {"year": 2019, "month": null, "day": null}, "abstract": "We address the problem of removing undesirable reflections from a single image captured through a glass surface, which is an ill-posed, challenging but practically important problem for photo enhancement. Inspired by iterative structure reduction for hidden community detection in social networks, we propose an Iterative Boost Convolutional LSTM Network (IBCLN) that enables cascaded prediction for reflection removal. IBCLN is a cascaded network that iteratively refines the estimates of transmission and reflection layers in a manner that they can boost the prediction quality to each other, and information across steps of the cascade is transferred using an LSTM. The intuition is that the transmission is the strong, dominant structure while the reflection is the weak, hidden structure. They are complementary to each other in a single image and thus a better estimate and reduction on one side from the original image leads to a more accurate estimate on the other side. To facilitate training over multiple cascade steps, we employ LSTM to address the vanishing gradient problem, and propose residual reconstruction loss as further training guidance. Besides, we create a dataset of real-world images with reflection and ground-truth transmission layers to mitigate the problem of insufficient data. Comprehensive experiments demonstrate that the proposed method can effectively remove reflections in real and synthetic images compared with state-of-the-art reflection removal methods.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "1911.06634", "mag": "3034647178", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/cvpr/LiY0LH20", "doi": "10.1109/cvpr42600.2020.00362"}}, "content": {"source": {"pdf_hash": "3541a9ef8c3a2eefc6ab7b6ff7d98687fe60f570", "pdf_src": "MergedPDFExtraction", "pdf_uri": "[\"https://arxiv.org/pdf/1911.06634v2.pdf\"]", "oa_url_match": true, "oa_info": {"license": null, "open_access_url": "http://arxiv.org/pdf/1911.06634", "status": "GREEN"}}, "grobid": {"id": "95accc0b81084b76ddb8b4ff77c5889d292eb931", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/3541a9ef8c3a2eefc6ab7b6ff7d98687fe60f570.txt", "contents": "\nSingle Image Reflection Removal through Cascaded Refinement\n\n\nChao Li \nSchool of Computer Science and Technology\nHuazhong University of Science and Technology\n\n\nYixiao Yang \nSchool of Computer Science and Technology\nHuazhong University of Science and Technology\n\n\nKun He \nSchool of Computer Science and Technology\nHuazhong University of Science and Technology\n\n\nStephen Lin \nMicrosoft Research Asia\n\n\nJohn E Hopcroft \nComputer Science Department\nCornell University\n\n\nSingle Image Reflection Removal through Cascaded Refinement\n\nWe address the problem of removing undesirable reflections from a single image captured through a glass surface, which is an ill-posed, challenging but practically important problem for photo enhancement. Inspired by iterative structure reduction for hidden community detection in social networks, we propose an Iterative Boost Convolutional LSTM Network (IBCLN) that enables cascaded prediction for reflection removal. IBCLN is a cascaded network that iteratively refines the estimates of transmission and reflection layers in a manner that they can boost the prediction quality to each other, and information across steps of the cascade is transferred using an LSTM. The intuition is that the transmission is the strong, dominant structure while the reflection is the weak, hidden structure. They are complementary to each other in a single image and thus a better estimate and reduction on one side from the original image leads to a more accurate estimate on the other side. To facilitate training over multiple cascade steps, we employ LSTM to address the vanishing gradient problem, and propose residual reconstruction loss as further training guidance. Besides, we create a dataset of real-world images with reflection and ground-truth transmission layers to mitigate the problem of insufficient data. Comprehensive experiments demonstrate that the proposed method can effectively remove reflections in real and synthetic images compared with state-of-the-art reflection removal methods.\n\nIntroduction\n\nUndesirable reflections from glass occur frequently in real-world photos. It not only significantly degrades the image quality, but also affects the performance of downstream computer vision tasks like object detection and semantic segmentation. As the reflection removal problem is ill-posed, early works primarily tackle it with multi-ple input images [24,19,16,32,6,23,5,7]. More recently, researchers attempt to address the more common and practically significant scenario of a single input image [14,15,16,17,28,22,1,25].\n\nFor single-image reflection removal (SIRR), researchers have observed that some handcrafted priors may help for distinguishing the transmission layer from the reflection layer in a single image. But these priors often do not generalize well to different types of reflections and scenes owing to disparate imaging conditions. In recent years, researchers apply data-driven learning to replace handcrafted priors via deep convolutional neural networks. With abundant labeled data, a network can be trained to perform effectively over a broad range of scenes. However, learning-based singleimage methods still have much room for improvement due to complications such as limited training data, disparate imaging conditions, varying scene content, limited physical understanding of this problem, and the performance limitation of various models.\n\nIn this work, inspired by the iterative structure reduction approach for hidden community detection in social networks [8,9], we introduce a cascaded neural network model for transmission and reflection decomposition. Figure 1 illustrates the cascade results in our model, where the transmission and reflection are progressively refined during the iterations. To the best of our knowledge, previous works on reflection removal did not utilize a cascaded refinement approach. Though some methods such as BDN [33] obtain predictions over a sequence of a few sub-networks, they do not iteratively refine the estimates, but rather they conduct a short alternating optimization, e.g., by estimating the reflection from the input image and the initial transmission layer, and then estimating the transmission from the input image and the estimated reflection layer. For a cascade model on SIRR, a simple approach is to employ one network to generate a predicted transmission that serves as the auxiliary information of the next network, and continue such process with subsequent networks to iteratively improve the prediction quality. With a long cascade, however, the training becomes difficult due to the vanishing gradient problem and limited training guidance at each step. To address this issue, we design a convolutional LSTM (Long Short-Term Memory) network, which saves information from the previous iteration (i.e. time step) and allows gradients to flow unchanged.\n\nIn our model, two sub-networks use identical convolutional LSTM architecture, one for transmission prediction and the other for reflection prediction. They share input information using the outputs of the previous time step to boost each others effectiveness. Here we propose a residual reconstruction loss as further training supervision at each cascade step. To simplify the reconstruction loss, we define a new concept of residual reflection, which will be described in Sec. 3.4.\n\nThough a few real-world datasets with ground-truth have been presented [26,34], the real-world data for SIRR is still insufficient due to the tremendously labor-intensive work. To help resolve the insufficiency of the real-world training data, we also collect a real dataset with densely-labeled ground truth in disparate imaging conditions and varying scenes.\n\nOur main contributions are as follows:\n\n\u2022 We propose a new network architecture, a cascaded network, with loss components that achieves state-ofthe-art quantitative results on real-world benchmarks for the single image reflection removal problem. \u2022 We design a residual reconstruction loss, which can form a closed loop with the linear method for synthesizing images with reflections, to expand the influence of the synthesis method across the whole network. \u2022 We collect a new real-world dataset containing images with densely-labeled ground-truth, which can serve as baseline data in future research.\n\n\nRelated Work\n\nMathematically speaking, SIRR operates on a captured image I, which is generally assumed to be a linear combination of a transmission layer T and a reflection layer R. The goal is to infer a transmission layer T that is free of reflections. In this work, we focus on deep learning-based SIRR, which has produced state-of-the-art results. Previous multiple-image methods [32,6,16,23,19,5,24,7] and single-image-priors based methods [15,17,14,22,1,28,16,25] are not considered here.\n\nDue to the advantages in robustness and performance, there is an emerging interest in applying neural networks to SIRR. Fan et al. [4] provide the first neural network model to solve this ill-posed problem. They propose a linear method for synthesizing images with reflection for training, and use an edge map as auxiliary information to guide the reflection removal. Wan et al. [27] develop two cooperative sub-networks, which predict the transmission layer intensity and gradients concurrently. Both of these works [4,27] utilize edge or gradient information of the captured layer I, motivated by the idea that the reflection layers are usually not in focus and thus blurry as compared to the transmission layers. From the edge information of the captured image I, the edge map of the transmission image T is predicted and used in estimating the transmission result. Instead, BDN [33] predicts reflection layers which are then used as auxiliary information in a subsequent network to estimate the transmission.\n\nIn several recent methods, improved formulations of the objective function are presented. These include the adoption of perceptual losses [11] to account for both low-level and high-level image information [3,10,34]. In these works, images are fed to a deep network pre-trained on Ima-geNet, and comparisons are made based on extracted multi-stage features. Adversarial losses have also been applied, specifically to improve the realism of predicted transmission layers [34,13,31,30].\n\nAnother direction of study focuses on datasets for training. Moving beyond improvements for the linear synthesis method in [4] and [34], Wen et al. [31] synthesize training data with learned non-linear alpha blending masks that better model the real-world imaging conditions. These masks are also used in forming a reconstruction loss that guides the prediction of transmission layers. To deal with the insufficiency of densely-labeled training data, Wei et al. [30] present a technique for utilizing misaligned real-world images as the training data, as they are less burdensome to acquire than aligned images and are more realistic than synthetic images.\n\n\nProposed Method\n\n\nMotivation\n\nThis work is motivated by research on hidden structures in social networks. He et al. [8,9] define a set of communities as hidden structure if most of the members also belong to other stronger communities. They propose an iterative boost approach to separate a set of strong, dominant communities and another set of weak, hidden communities, and boost the detection accuracy on both sides. The key idea is that, when they detect an approximate set of dominant communities using a base algorithm, and weaken their internal connection to the average connection of the overall graph, the dominant structure is reduced to boost the detection on the set of hidden communities, and vice versa.\n\nUnder the scenario of SIRR, a useful trick is to employ sub-networks to learn auxiliary information that can facilitate transmission layer prediction. The types of auxiliary information utilized in existing works include edge information [4,27] and predicted reflections [33]. The ideal auxiliary information would be the ground truth reflection-free version of the transmission layer, which is what we seek to predict. As this is not available at inference time, we instead use approximations to the ground-truth transmission in the form of predicted transmissions as the auxiliary information. Though certainly not as useful as the ground truth, it nevertheless provides strong guidance, especially as the transmission predictions improve. The key issue then becomes how to drive the transmission estimations closer and closer to the ground truth. Referring to the work of He et al. [8,9], we regard the transmission layer as the strong, dominant structure, and the reflection layer as the weak, hidden structure. By iteratively reducing the more accurate version of the counterpart, we could extract more accurate approximations on the two layers of images.\n\nOur model contains two sub-networks that can collaborate and boost each other's output by reducing the output of one side from the original image as effective auxiliary information for the other complementary side. Such collaborative cascaded refinement of the dominant image (transmission) and the weak image (reflection) is novel for the training of a neural network.\n\n\nGeneral Design Principles\n\nWe use two convolutional LSTM networks to separately generate the predicted transmission layers and the predicted reflection layers. The input of each sub-network includes the outputs of both the transmission and reflection subnetworks. Besides, the outputs of the two sub-networks are combined within a reconstruction loss to supervise the whole model at each time step. The synergy between the two sub-networks leads to a mutual boost in their predictions, resulting in progressive improvements of the auxiliary information and finally accurate estimates of the transmission.\n\nTo ensure that the transmission sub-network and the reflection sub-network generate complementary outputs, we enforce a reconstruction loss where the image\u00ce synthesized from the estimated transmission and reflection is expected to match the input image I.\n\nA related constraint is employed in RmNet [31], which synthesizes an image I from the ground-truth transmission layer with no reflection, the reflection layer used to produce reflections off the glass, and an alpha blending mask W. Thus,\nI = W \u2022 T + (1 \u2212 W) \u2022 R, where \u2022 denotes element-wise multiplication.\nThe reconstructed image\u00ce is then compared to the synthetic input image I. However, their alpha blending model only approximates the complex physical mechanisms involved in forming an actual input image with reflections, as it does not model effects such as spatially varying blurs and Gamma correction [2], which is used to correct for the differences between the way a camera captures content and the way our visual system processes light. This will limit reconstruction quality on real-world input images and consequently degrade prediction results as we found from experiments reported in Table 1.\n\nTo avoid the problem that RmNet encounters, we use a scale parameter \u03b1 instead of the element-wise mask matrix W, and we directly calculate the residual reflection R by I \u2212 \u03b1 \u00b7 T. In this way, we do not require modeling the complicated physical process involved in the formation of images with reflection, and our performance does not suffer from deficiencies in such a synthesis model. The benefit of predicting residual reflection instead of the reflection layer used to produce reflections off the glass is that image reconstruction becomes simplified as just the sum of the predicted transmission and the predicted residual reflection. Also, different from RmNet, all our linear operations are done in the linear color space, removing Gamma correction [2].  The images generated at each time step by the two sub-networks will be fed back at the next time step. The overall network is trained in an end-to-end manner.\n\n\nConcatenation\n\n\nResidual Reconstruction Loss\n\n\nNetwork Architecture\n\nThe architecture of the proposed network is illustrated in Figure 2 1 . IBCLN consists of two sub-networks: a transmission-prediction network G T and a reflectionprediction network G R . The two sub-networks are both convolutional LSTM networks with the same architecture but different goals. The former aims to learn the transmission T while the latter aims to learn the residual reflection R, so they learn completely different weight parameters. Each sub-network consists of an encoder with 11 Convrelu blocks that extract the features from the input image, a convolutional LSTM unit [20] and a decoder with 8 convolutional layers for generating the predicted transmission layer or the predicted residual reflection layer. Each convolutional layer is followed by a ReLU activation, except for the LSTM layers which are followed by a Sigmoid activation or a Tanh activation. In each sub-network, there are two skip connections between the encoder and the decoder to prevent blurred outputs. The convolutional layers and skip connections are similar to those of a contextual autoencoder [18]. Different from previous works, our objective function includes the proposed residual reconstruction loss and a multi-scale perceptual loss. previous time step. In the actual model, the convolutional LSTM unit is in the middle of the sub-network and connected with convolutional layers. The convolutional LSTM unit has four gates, including an input gate, a forget gate, an output gate, as well as a cell state. The cell state encodes the state information that will be fed to the next LSTM. The LSTMs output feature is fed into the next convolutional layer. More details can be found in ConvLSTM [20]. At time step t, both of the sub-networks take nine channels of input, specifically a concatenation of the synthetic image I, the predicted transmissionT t\u22121 and residual reflection R t\u22121 predicted at time step t \u2212 1 (1 < t \u2264 N ). T 0 is set to be the synthetic image I and R 0 is set to 0.1 for all entries. The output of the transmission prediction network G T at the final time step N serves as the final result.\n\nMany previous works consider auxiliary information to be important for predicting reflection-free transmission layers [4,33,27,31], since it indicates to the network where the removal should be focused on. In our work,T t\u22121 and R t\u22121 are saved to serve as the auxiliary information of step t (1 < t \u2264 N ). The auxiliary information will improve with increasing numbers of time steps (see Figure 1). Since the predicted transmissions represent what the network can infer at a given time step, using them as auxiliary information is effective. Additionally, the predicted residual reflection is complementary to the predicted transmission in an image, so it also contains meaningful information.\n\nConsidering that the iterative process may require a long cascade, using conventional convolutional networks as the sub-networks would make the full model hard to train. This motivates our use of two convolutional LSTM networks, each with a convolutional LSTM unit. The continuity among time steps makes the model easy to train. Additionally, a cascaded architecture has fewer parameters to learn, as both of the sub-networks are iterated multiple times and each instance of a sub-network shares the same weights. Moreover, a convolutional LSTM network has more complete information exchange either within itself or between the two sub-networks, which is more in line with our iterative boost idea.\n\n\nObjective Function\n\nResidual Reconstruction Loss. For the existing linear models [4,34] for generating synthetic images, the general steps are to perform a series of complex operations on a reflection image to produce a reflection layer R, then to generate a synthetic image I by a linear operation: I = clip(\u03b1 \u00b7 T + R). Usually \u03b1 \u2208 [0.8, 1] due to the slight attenuation of light as it passes through a glass plane. The weight of the reflection layer R is 1 as the original reflection image has been subtracted adaptively by the synthesis method. The clipping operation forces all values of the synthetic image to be in [0,1].\n\nWe introduce a new loss to the proposed network, called the residual reconstruction loss. We adopt the above synthesis model, but replace R with R, where R is determined from I and T. R offers more effective auxiliary information for transmission prediction, and a more convincing ground truth, as compared to the artificially constructed R. R is obtained by reverting the linear synthesis model, as\nR = I \u2212 \u03b1 \u00b7 T.\n(1)\n\nWith this definition of R, the clipping operation is not needed and we avoid its loss of information. After R is calculated, it can be used as the ground truth of G R to guide the generation of the predicted residual reflectionR. Then, we can simply revert Eq. (1) in the objective function, a\u015d\nI = \u03b1 \u00b7T +R,(2)\nwhereT,R and\u00ce are the predicted transmission, predicted residual reflection and the reconstructed image, respectively. \u03b1 is the same as in the synthesis model. Note that all the above linear operations are done in the linear color space, so the Gamma correction [2] on each image is removed before inclusion in linear operations.\n\nIt is intuitive that the reconstructed image\u00ce should be similar to the original input through a well-trained network. The residual reconstruction loss is defined as:\nL residual = I\u2208D N t=1 L M SE (I,\u00ce t ).\n(3)\n\nL M SE indicates the mean squared error. t denotes the time step of the two sub-networks. N represents the final time step whenT converges. The residual reconstruction loss works well experimentally. One potential reason is that the two sub-networks have the same architecture but complementary objectives. With the same architecture, they may be under-trained or overtrained concurrently. The complementary objectives within the residual reconstruction loss can balance the error from the two sub-networks. If both of the two sub-networks are either under-trained or over-trained, the error will be doubled in the residual reconstruction loss. Multi-scale Perceptual Loss. Multi-scale losses are effective in image decomposition tasks such as raindrop removal [18]. A multi-scale loss extracts the features from different decoder layers and feeds them into a convolutional layer to form outputs at different resolutions. The outputs are then compared to those of real images by their L M SE distance. By adopting such a loss in our task, we can capture more contextual information from various scales. We change the L M SE distance to the perceptual distance between the predicted image and the real image over different scales. This loss thus considers different scales of both lowlevel and high-level information. We define the loss function as:\nL M P = T,T 3 ,T 5 \u2208D (L V GG (T,T) + \u03b3 3 L V GG (T 3 ,T 3 ) + \u03b3 5 L V GG (T 5 ,T 5 )),(4)\nwhereT,T 3 ,T 5 indicate the outputs of the last, 3 rd last and 5 th last layers at time step N , whose sizes are 1, 1 2 and 1 4 of the original size, respectively. T, T 3 and T 5 indicate the ground truth that has the same scale as that of the outputs, respectively. Layers with smaller size are not considered since their information is relatively insignificant. We set \u03b3 3 = 0.8 and \u03b3 5 = 0.6. All the images are fed into the VGG19 network [21]. We compare the outputs of the layers 'conv1 2' and 'conv2 2 in the VGG19 network. Pixel Loss. To ensure that the outputs become as close to the ground truth as possible, we utilize the L M SE loss to measure the pixel-wise distance between them. Our pixel loss is defined as follows:\nL pixel = T \u2208D N t=1 [L M SE (T,T t ) + L M SE ( R,R t )],(5)\nwhere R is the residual reflection.T t andR t are the outputs at time step t. Adversarial Loss. To improve the realism of the generated transmission layers, we further add an adversarial loss. We define an opponent discriminator network D. The adversarial loss is defined as (refer to [34] for details):\nL adv = T \u2208D \u2212 log D(T,T).(6)\nOverall Loss. Overall, our objective function of IBCLN is defined as:\nL = \u03bb 1 L residual + \u03bb 2 L M P + \u03bb 3 L pixel + \u03bb 4 L adv ,(7)\nwhere we empirically set the weights as \u03bb 1 = 2, \u03bb 2 = 1, \u03bb 3 = 2, \u03bb 4 = 0.01 throughout our experiments.\n\n\nImplementation Details\n\nWe implement the proposed IBCLN in Pytorch on a PC with an Nvidia Geforce GTX 2080 Ti GPU. The overall model is trained for 80 epochs with a batch size of 2, using the Adam optimizer [12]. The learning rate for the overall network training is set to 0.0002. For the training data, we use 4000 images containing 2800 synthetic images and 1200 image patches of size 256 \u00d7 256 from 290 real-world training images, containing 200 images from our created dataset and 90 images from Zhang et al. [34]. Similar to current deep learning methods, our method requires a relatively large amount of data with ground truth for training. Our synthesis model is the same as the recently proposed linear method [34] except for the clipping operation. We utilize their synthetic dataset as well. In our experiments, different methods are evaluated on the publicly available real-world images from the SIR 2 datasets [26], Zhang et al. [34] and the real-world dataset we create.\n\n\nExperiments\n\n\nDataset Preparation\n\nOur created dataset, called Nature, contains 220 realworld image pairs: images with reflection and the corresponding ground-truth transmission layers (see samples in Figure 4). We use a Canon EOS 750D for image acquisition. Each ground-truth transmission layer is captured when the portable glass is removed. The dataset is randomly partitioned into a training set and a testing set. We use 200 images for training and 20 images for quantitative evaluation. Inspired by Zhang et al. [34], we captured the images with the following considerations to simulate diverse imaging conditions: 1) Environments: indoor and outdoor; 2) Lighting conditions: skylight, sunlight, and incandescent; \n\n\nComparison to State-of-the-art Methods\n\n\nQuantitative Evaluations\n\nWe compare our IBCLN against state-of-the-art methods including CEILNet [4], Zhang et al. [34], BDN [33], Rm-Net [31] and ERRNet [30]. For an apples-to-apples comparison, we finetune each model (if the model provides training code) on our training dataset and report the best result of the original pre-trained model and finetuned version (denoted with a suffix -F). RmNet [31] has three models for different reflection types, and we report the best result from among the three models. Table 1 summarizes results of all the competing methods on five real-world datasets, including three sub-datasets from SIR 2 [26], Zhang et al. [34] and our dataset. The number of images in each dataset is shown after the name. The quality metrics include PSNR and SSIM [29]. Larger values of PSNR and SSIM indicate better performance. IB-CLN achieves the best performance on four of the datasets, but not on 20 images of \"Zhang et al.\". As ERRNet [30] is developed based on model Zhang et al. [34], EERNet and Zhang et al. both have better performance on the dataset \"Zhang et al.\". In terms of overall performance over all the test datasets, IBCLN surpasses the other methods. Figure 5 presents visual results and the ground truth on realworld images from SIR 2 [26], Zhang et al. [34] and our dataset. We select two images from each dataset. It can be seen that Zhang et al. [34] tends to over-remove the reflection layer, while the other baseline methods tend to underremove. Our model is more accurate and removes most of the undesirable reflections.  \n\n\nQualitative Evaluations\n\n\nControlled Experiments\n\nFor better analyzing our network architecture and the objective function of IBCLN, we separately remove the subnetwork G R , the iteration step, and the three-loss terms one by one. Then we train new models with the modified networks. The results from these ablations on the architecture are given in Table 2. The result of a cascade network with-out LSTM is not shown in the table because it cannot be effectively trained. The ablation study on the loss terms is shown in Table 3. And visual comparisons among all the modified networks and IBCLN are displayed in Figure  6 and Figure 7. We observe that using two iterative subnetworks, time steps, L adv , L residual and L M P all enhance the performance of IBCLN, and all the blocks and the losses  To explore how many time steps are appropriate for the predicted transmission to converge, we train the model with different total time steps. Figure 8 exhibits the results. We see that the output approximately converges when total time steps are equal to 3. We experimented with having the net- work learn the total time steps automatically for different images, but we found that providing this much flexibility causes the performance to decay.\n\n\nConclusion\n\nWe present an Iterative Boost Convolutional LSTM Network (IBCLN) that can effectively remove the reflection from a single image in a cascaded fashion. To formulate an effective cascade network, we propose to iteratively refine the transmission and reflection layers at each step in a manner that they can boost prediction quality for each other, and to employ LSTM to facilitate training over multiple cascade steps. The intuition is that a better estimate of the complementary residual reflection can boost the prediction of the transmission, and vice versa. Besides, we incorporate a residual reconstruction loss as further training guidance at each cascade step. Moreover, we combine a multi-scale loss with the perceptual loss to form a multiscale perceptual loss. Quantitative and qualitative evaluations on five datasets (including ours) demonstrate that the proposed IBCLN outperforms state-of-the-art methods on the challenging single image reflection removal problem. In future work, we will try our cascaded prediction refinement approach on other image layer decomposition tasks such as raindrop removal, flare removal and dehazing.\n\nFigure 1 .\n1Visualization of results at different cascade steps of the two sub-networks in the proposed model. The estimates of transmissions and residual reflections become increasingly more accurate as they progress through the cascade. More results are in the suppl. material.\n\nFigure 2 .\n2The architecture of IBCLN. The cascaded network consists of a transmission generative sub-network G T and a reflection generative sub-network G R with skip connections, both of which are convolutional LSTM networks.\n\nFigure 3 illustratesFigure 3 .\n33IBCLN from a different perspective. All G T illustrated in this figure is exactly the same network with the same parameters, but at different time steps in the cascade. We connect G T at adjacent time steps with convolutional LSTM units that save information from the 1 Code and model: https://github.com/JHL-HUST/IBCLN/. Characterizing IBCLN with increasing number of time steps. All blocks labeled as G T indicate one sub-network and all blocks labeled as G R indicate another sub-network. The output at time step t \u2212 1 serves as the input at time step t.T1,T2, ...,TN are the predicted transmission.R1,R2, ...,RN are the predicted residual reflection.\n\nFigure 4 .\n4Samples from our real world Nature dataset. Top: images with reflection. Bottom: the corresponding ground-truth transmission layers.\n\n3 )\n3Thickness of the glass slabs: 3 mm and 8 mm; 4) Distance between the glass and the camera: 3 to 15 cm; 5) Camera viewing angles: front view and oblique view; 6) Camera exposure value: 8.0 -16.0; 7) Camera apertures (affecting the reflection blurriness): f/4.0 f/16.\n\nFigure 5 .\n5Visual comparison among state-of-the-art approaches and our method on images from three real-world image datasets, namely, Nature (Rows 1-2), SIR 2 (Rows 3-4) and Zhang et al.(Rows 5-6). More results can be found in the suppl. material.\n\nFigure 6 .Figure 7 .Figure 8 .\n678Visual comparison among IBCLN and versions with a modified loss on real-world images. More results are in the suppl. material. Visual comparison among IBCLN and versions with architecture modifications on real-world images. More results can be found in the suppl. material. Results using different total time steps N in IBCLN on SIR 2[26]. Total time steps N = 3 yields the best performance.\n\nTable 1 .\n1Quantitative comparison of different methods on three real-world benchmark datasets. The best results are in bold and orange color, and the second best results are underlined and in blue color. 'Average' is obtained by averaging the metric scores of all images from all the above real-world datasets.Dataset (size) \nIndex \n\nMethods \nCEILNet-F \nZhang et al. \nBDN-F \nRmNet \nERRNet-F \nIBCLN \n[4] \n[34] \n[33] \n[31] \n[30] \n\nObject (200) \nPSNR \n22.81 \n22.68 \n23.02 \n20.33 \n24.85 \n24.87 \nSSIM \n0.801 \n0.874 \n0.853 \n0.793 \n0.889 \n0.893 \n\nPostcard (199) \nPSNR \n20.08 \n16.81 \n20.71 \n19.71 \n21.99 \n23.39 \nSSIM \n0.810 \n0.797 \n0.857 \n0.808 \n0.874 \n0.875 \n\nWild (55) \nPSNR \n22.14 \n21.52 \n22.34 \n21.98 \n24.16 \n24.71 \nSSIM \n0.819 \n0.829 \n0.821 \n0.821 \n0.847 \n0.886 \n\nZhang et al. (20) \nPSNR \n18.79 \n22.42 \n19.47 \n18.77 \n23.35 \n21.86 \nSSIM \n0.749 \n0.792 \n0.720 \n0.681 \n0.811 \n0.762 \n\nNature (20) \nPSNR \n19.33 \n19.56 \n18.92 \n19.36 \n22.18 \n23.57 \nSSIM \n0.745 \n0.736 \n0.737 \n0.725 \n0.756 \n0.783 \n\nAverage (494) \nPSNR \n21.31 \n20.85 \n21.68 \n20.19 \n23.45 \n24.08 \nSSIM \n0.806 \n0.829 \n0.841 \n0.795 \n0.870 \n0.875 \n\n\n\nTable 2 .\n2Ablation study of IBCLN for architecture on three testing sets. w/o G R means training with only one sub-network G T . w/o iteration means the total time steps is 1. Each term contributes to the SIRR performance, and combining all achieves the best results. yield different contributions to the removal performance. The complete IBCLN with all structures and objective function terms yields the best results.Model \nNature \nZhang et al. \nSIR 2 \nPSNR SSIM PSNR SSIM PSNR SSIM \n\nw/o G R \n21.79 0.759 20.65 0.742 22.36 0.868 \nw/o iteration 21.82 0.764 20.49 0.739 23.09 0.872 \nComplete \n23.57 0.783 21.86 0.762 24.20 0.884 \n\n\n\nTable 3 .\n3Ablation study of IBCLN for loss terms on three testing sets. Each loss contributes to IBCLN's performance, and combining all achieves the best result. PSNR SSIM PSNR SSIM PSNR SSIMModel \nNature \nZhang et al. \nSIR 2 \nL pixel only \n21.98 0.739 19.54 0.722 22.91 0.843 \nw/o L adv \n23.24 0.746 21.74 0.755 23.86 0.885 \nw/o L residual 22.54 0.770 20.98 0.755 23.74 0.881 \nw/o L M P \n23.14 0.744 21.47 0.734 22.96 0.863 \nComplete \n23.57 0.783 21.86 0.762 24.20 0.884 \n\n\nAcknowledgmentsThis work is supported by the Fundamental Research Funds for the Central Universities (2019kfyXKJC021) and Microsoft Research Asia.\nSingle image reflection suppression. Nikolaos Arvanitopoulos, Radhakrishna Achanta, Sabine Susstrunk, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionNikolaos Arvanitopoulos, Radhakrishna Achanta, and Sabine Susstrunk. Single image reflection suppression. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 4498-4506, 2017.\n\nChapter 4 -digital picture formats and representations. David R Bull, editor, Communicating Pictures. David R. BullOxfordAcademic PressDavid R. Bull. Chapter 4 -digital picture formats and rep- resentations. In David R. Bull, editor, Communicating Pic- tures, pages 99 -132. Academic Press, Oxford, 2014.\n\nSingle image reflection removal using deep encoder-decoder network. Zhixiang Chi, Xiaolin Wu, Xiao Shu, Jinjin Gu, arXiv:1802.00094arXiv preprintZhixiang Chi, Xiaolin Wu, Xiao Shu, and Jinjin Gu. Single image reflection removal using deep encoder-decoder net- work. arXiv preprint arXiv:1802.00094, 2018.\n\nA generic deep architecture for single image reflection removal and image smoothing. Qingnan Fan, Jiaolong Yang, Gang Hua, Baoquan Chen, David Wipf, Proceedings of the IEEE International Conference on Computer Vision. the IEEE International Conference on Computer VisionQingnan Fan, Jiaolong Yang, Gang Hua, Baoquan Chen, and David Wipf. A generic deep architecture for single image re- flection removal and image smoothing. In Proceedings of the IEEE International Conference on Computer Vision, pages 3238-3247, 2017.\n\nBlind separation of superimposed moving images using image statistics. IEEE transactions on pattern analysis and machine intelligence. Kun Gai, Zhenwei Shi, Changshui Zhang, 34Kun Gai, Zhenwei Shi, and Changshui Zhang. Blind separa- tion of superimposed moving images using image statistics. IEEE transactions on pattern analysis and machine intelli- gence, 34(1):19-32, 2011.\n\nRobust separation of reflection from multiple images. Xiaojie Guo, Xiaochun Cao, Yi Ma, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionXiaojie Guo, Xiaochun Cao, and Yi Ma. Robust separation of reflection from multiple images. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recogni- tion, pages 2187-2194, 2014.\n\nReflection removal using low-rank matrix completion. Byeong-Ju Han, Jae-Young Sim, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionByeong-Ju Han and Jae-Young Sim. Reflection removal us- ing low-rank matrix completion. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 5438-5446, 2017.\n\nHidden community detection in social networks. Yingru Kun He, Sucheta Li, John E Soundarajan, Hopcroft, Information Sciences. 425Kun He, Yingru Li, Sucheta Soundarajan, and John E Hopcroft. Hidden community detection in social networks. Information Sciences, 425:92-106, 2018.\n\nRevealing multiple layers of hidden community structure in networks. Sucheta Kun He, Xuezhi Soundarajan, John E Cao, Menglong Hopcroft, Huang, abs/1501.05700CoRRKun He, Sucheta Soundarajan, Xuezhi Cao, John E. Hopcroft, and Menglong Huang. Revealing multiple lay- ers of hidden community structure in networks. CoRR, abs/1501.05700, 2015.\n\nLearning to see through reflections. Meiguang Jin, Sabine S\u00fcsstrunk, Paolo Favaro, 2018 IEEE International Conference on Computational Photography (ICCP). IEEEMeiguang Jin, Sabine S\u00fcsstrunk, and Paolo Favaro. Learn- ing to see through reflections. In 2018 IEEE International Conference on Computational Photography (ICCP), pages 1-12. IEEE, 2018.\n\nPerceptual losses for real-time style transfer and super-resolution. Justin Johnson, Alexandre Alahi, Li Fei-Fei, European conference on computer vision. SpringerJustin Johnson, Alexandre Alahi, and Li Fei-Fei. Perceptual losses for real-time style transfer and super-resolution. In European conference on computer vision, pages 694-711. Springer, 2016.\n\nAdam: A method for stochastic optimization. P Diederik, Jimmy Kingma, Ba, arXiv:1412.6980arXiv preprintDiederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014.\n\nGenerative single image reflection separation. Donghoon Lee, Ming-Hsuan Yang, Songhwai Oh, arXiv:1801.04102arXiv preprintDonghoon Lee, Ming-Hsuan Yang, and Songhwai Oh. Gen- erative single image reflection separation. arXiv preprint arXiv:1801.04102, 2018.\n\nLearning to perceive transparency from the statistics of natural scenes. Anat Levin, Assaf Zomet, Yair Weiss, Advances in Neural Information Processing Systems. Anat Levin, Assaf Zomet, and Yair Weiss. Learning to per- ceive transparency from the statistics of natural scenes. In Advances in Neural Information Processing Systems, pages 1271-1278, 2003.\n\nSeparating reflections from a single image using local features. Anat Levin, Assaf Zomet, Yair Weiss, Proceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition. the 2004 IEEE Computer Society Conference on Computer Vision and Pattern RecognitionIEEE1Anat Levin, Assaf Zomet, and Yair Weiss. Separating re- flections from a single image using local features. In Pro- ceedings of the 2004 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2004. CVPR 2004., volume 1, pages I-VIII. IEEE, 2004.\n\nExploiting reflection change for automatic reflection removal. Yu Li, Michael S Brown, Proceedings of the IEEE International Conference on Computer Vision. the IEEE International Conference on Computer VisionYu Li and Michael S Brown. Exploiting reflection change for automatic reflection removal. In Proceedings of the IEEE International Conference on Computer Vision, pages 2432- 2439, 2013.\n\nSingle image layer separation using relative smoothness. Yu Li, Michael S Brown, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionYu Li and Michael S Brown. Single image layer separation using relative smoothness. In Proceedings of the IEEE Con- ference on Computer Vision and Pattern Recognition, pages 2752-2759, 2014.\n\nAttentive generative adversarial network for raindrop removal from a single image. Rui Qian, Robby T Tan, Wenhan Yang, Jiajun Su, Jiaying Liu, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionRui Qian, Robby T Tan, Wenhan Yang, Jiajun Su, and Jiay- ing Liu. Attentive generative adversarial network for rain- drop removal from a single image. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recogni- tion, pages 2482-2491, 2018.\n\nSeparating transparent layers through layer information exchange. Bernard Sarel, Michal Irani, European Conference on Computer Vision. SpringerBernard Sarel and Michal Irani. Separating transparent lay- ers through layer information exchange. In European Con- ference on Computer Vision, pages 328-341. Springer, 2004.\n\nConvolutional lstm network: A machine learning approach for precipitation nowcasting. Shi Xingjian, Zhourong Chen, Hao Wang, Dit-Yan Yeung, Wai-Kin Wong, Wang-Chun Woo, Advances in neural information processing systems. Xingjian SHI, Zhourong Chen, Hao Wang, Dit-Yan Yeung, Wai-Kin Wong, and Wang-chun Woo. Convolutional lstm network: A machine learning approach for precipitation nowcasting. In Advances in neural information processing systems, pages 802-810, 2015.\n\nVery deep convolutional networks for large-scale image recognition. Karen Simonyan, Andrew Zisserman, arXiv:1409.1556arXiv preprintKaren Simonyan and Andrew Zisserman. Very deep convo- lutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556, 2014.\n\nReflection separation using guided annotation. Ofer Springer, Yair Weiss, 2017 IEEE International Conference on Image Processing (ICIP). IEEEOfer Springer and Yair Weiss. Reflection separation using guided annotation. In 2017 IEEE International Conference on Image Processing (ICIP), pages 1192-1196. IEEE, 2017.\n\nAutomatic reflection removal using gradient intensity and motion cues. Chao Sun, Shuaicheng Liu, Taotao Yang, Bing Zeng, Zhengning Wang, Guanghui Liu, Proceedings of the 24th ACM international conference on Multimedia. the 24th ACM international conference on MultimediaACMChao Sun, Shuaicheng Liu, Taotao Yang, Bing Zeng, Zhengning Wang, and Guanghui Liu. Automatic reflection removal using gradient intensity and motion cues. In Pro- ceedings of the 24th ACM international conference on Mul- timedia, pages 466-470. ACM, 2016.\n\nLayer extraction from multiple images containing reflections and transparency. Richard Szeliski, P Shai Avidan, Anandan, Proceedings IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No. PR00662). IEEE Conference on Computer Vision and Pattern Recognition. CVPR 2000 (Cat. No. PR00662)IEEE1Richard Szeliski, Shai Avidan, and P Anandan. Layer extraction from multiple images containing reflections and transparency. In Proceedings IEEE Conference on Com- puter Vision and Pattern Recognition. CVPR 2000 (Cat. No. PR00662), volume 1, pages 246-253. IEEE, 2000.\n\nGround reflection removal in compressive sensing ground penetrating radars. IEEE Geoscience and remote sensing letters. Mehmet Ali, Cagri Tuncer, Ali Cafer Gurbuz, 9Mehmet Ali Cagri Tuncer and Ali Cafer Gurbuz. Ground reflection removal in compressive sensing ground penetrat- ing radars. IEEE Geoscience and remote sensing letters, 9(1):23-27, 2011.\n\nBenchmarking single-image reflection removal algorithms. Renjie Wan, Boxin Shi, Ling-Yu Duan, Ah-Hwee Tan, Alex C Kot, Proceedings of the IEEE International Conference on Computer Vision. the IEEE International Conference on Computer VisionRenjie Wan, Boxin Shi, Ling-Yu Duan, Ah-Hwee Tan, and Alex C Kot. Benchmarking single-image reflection removal algorithms. In Proceedings of the IEEE International Con- ference on Computer Vision, pages 3922-3930, 2017.\n\nCrrn: Multi-scale guided concurrent reflection removal network. Renjie Wan, Boxin Shi, Ling-Yu Duan, Ah-Hwee Tan, Alex C Kot, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionRenjie Wan, Boxin Shi, Ling-Yu Duan, Ah-Hwee Tan, and Alex C Kot. Crrn: Multi-scale guided concurrent reflection removal network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 4777- 4785, 2018.\n\nDepth of field guided reflection removal. Renjie Wan, Boxin Shi, Tan Ah Hwee, Alex C Kot, 2016 IEEE International Conference on Image Processing (ICIP). IEEERenjie Wan, Boxin Shi, Tan Ah Hwee, and Alex C Kot. Depth of field guided reflection removal. In 2016 IEEE In- ternational Conference on Image Processing (ICIP), pages 21-25. IEEE, 2016.\n\nImage quality assessment: from error visibility to structural similarity. Zhou Wang, Alan C Bovik, R Hamid, Sheikh, P Eero, Simoncelli, IEEE Transactions on Image Processing. 134Zhou Wang, Alan C Bovik, Hamid R Sheikh, Eero P Simon- celli, et al. Image quality assessment: from error visibility to structural similarity. IEEE Transactions on Image Process- ing, 13(4):600-612, 2004.\n\nSingle image reflection removal exploiting misaligned training data and network enhancements. Kaixuan Wei, Jiaolong Yang, Ying Fu, David Wipf, Hua Huang, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionKaixuan Wei, Jiaolong Yang, Ying Fu, David Wipf, and Hua Huang. Single image reflection removal exploiting mis- aligned training data and network enhancements. In Pro- ceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 8178-8187, 2019.\n\nSingle image reflection removal beyond linearity. Qiang Wen, Yinjie Tan, Jing Qin, Wenxi Liu, Guoqiang Han, Shengfeng He, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionQiang Wen, Yinjie Tan, Jing Qin, Wenxi Liu, Guoqiang Han, and Shengfeng He. Single image reflection removal beyond linearity. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 3771- 3779, 2019.\n\nA computational approach for obstruction-free photography. Tianfan Xue, Michael Rubinstein, Ce Liu, William T Freeman, ACM Transactions on Graphics (TOG). 34479Tianfan Xue, Michael Rubinstein, Ce Liu, and William T Freeman. A computational approach for obstruction-free photography. ACM Transactions on Graphics (TOG), 34(4):79, 2015.\n\nSeeing deeply and bidirectionally: A deep learning approach for single image reflection removal. Jie Yang, Dong Gong, Lingqiao Liu, Qinfeng Shi, Proceedings of the European Conference on Computer Vision (ECCV). the European Conference on Computer Vision (ECCV)Jie Yang, Dong Gong, Lingqiao Liu, and Qinfeng Shi. See- ing deeply and bidirectionally: A deep learning approach for single image reflection removal. In Proceedings of the Eu- ropean Conference on Computer Vision (ECCV), pages 654- 669, 2018.\n\nSingle image reflection separation with perceptual losses. Xuaner Zhang, Ren Ng, Qifeng Chen, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionXuaner Zhang, Ren Ng, and Qifeng Chen. Single image re- flection separation with perceptual losses. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 4786-4794, 2018.\n", "annotations": {"author": "[{\"end\":161,\"start\":63},{\"end\":264,\"start\":162},{\"end\":362,\"start\":265},{\"end\":401,\"start\":363},{\"end\":467,\"start\":402},{\"end\":161,\"start\":63},{\"end\":264,\"start\":162},{\"end\":362,\"start\":265},{\"end\":401,\"start\":363},{\"end\":467,\"start\":402}]", "publisher": null, "author_last_name": "[{\"end\":70,\"start\":68},{\"end\":173,\"start\":169},{\"end\":271,\"start\":269},{\"end\":374,\"start\":371},{\"end\":417,\"start\":409},{\"end\":70,\"start\":68},{\"end\":173,\"start\":169},{\"end\":271,\"start\":269},{\"end\":374,\"start\":371},{\"end\":417,\"start\":409}]", "author_first_name": "[{\"end\":67,\"start\":63},{\"end\":168,\"start\":162},{\"end\":268,\"start\":265},{\"end\":370,\"start\":363},{\"end\":406,\"start\":402},{\"end\":408,\"start\":407},{\"end\":67,\"start\":63},{\"end\":168,\"start\":162},{\"end\":268,\"start\":265},{\"end\":370,\"start\":363},{\"end\":406,\"start\":402},{\"end\":408,\"start\":407}]", "author_affiliation": "[{\"end\":160,\"start\":72},{\"end\":263,\"start\":175},{\"end\":361,\"start\":273},{\"end\":400,\"start\":376},{\"end\":466,\"start\":419},{\"end\":160,\"start\":72},{\"end\":263,\"start\":175},{\"end\":361,\"start\":273},{\"end\":400,\"start\":376},{\"end\":466,\"start\":419}]", "title": "[{\"end\":60,\"start\":1},{\"end\":527,\"start\":468},{\"end\":60,\"start\":1},{\"end\":527,\"start\":468}]", "venue": null, "abstract": "[{\"end\":2023,\"start\":529},{\"end\":2023,\"start\":529}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b23\"},\"end\":2397,\"start\":2393},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":2400,\"start\":2397},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":2403,\"start\":2400},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":2406,\"start\":2403},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":2408,\"start\":2406},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":2411,\"start\":2408},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":2413,\"start\":2411},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":2415,\"start\":2413},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":2544,\"start\":2540},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":2547,\"start\":2544},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":2550,\"start\":2547},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":2553,\"start\":2550},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":2556,\"start\":2553},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":2559,\"start\":2556},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2561,\"start\":2559},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":2564,\"start\":2561},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":3531,\"start\":3528},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":3533,\"start\":3531},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":3920,\"start\":3916},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":5438,\"start\":5434},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":5441,\"start\":5438},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":6718,\"start\":6714},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":6720,\"start\":6718},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":6723,\"start\":6720},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":6726,\"start\":6723},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":6729,\"start\":6726},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":6731,\"start\":6729},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":6734,\"start\":6731},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":6736,\"start\":6734},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":6779,\"start\":6775},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":6782,\"start\":6779},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":6785,\"start\":6782},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":6788,\"start\":6785},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":6790,\"start\":6788},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":6793,\"start\":6790},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":6796,\"start\":6793},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":6799,\"start\":6796},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":6960,\"start\":6957},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":7209,\"start\":7205},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":7346,\"start\":7343},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":7349,\"start\":7346},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":7712,\"start\":7708},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":7982,\"start\":7978},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":8049,\"start\":8046},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":8052,\"start\":8049},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":8055,\"start\":8052},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":8314,\"start\":8310},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":8317,\"start\":8314},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":8320,\"start\":8317},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":8323,\"start\":8320},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":8452,\"start\":8449},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":8461,\"start\":8457},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":8478,\"start\":8474},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":8792,\"start\":8788},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":9104,\"start\":9101},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":9106,\"start\":9104},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":9945,\"start\":9942},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":9948,\"start\":9945},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":9979,\"start\":9975},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":10592,\"start\":10589},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":10594,\"start\":10592},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":12147,\"start\":12143},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":12714,\"start\":12711},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":13770,\"start\":13767},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":14594,\"start\":14590},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":15095,\"start\":15091},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":15697,\"start\":15693},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":16236,\"start\":16233},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":16239,\"start\":16236},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":16242,\"start\":16239},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":16245,\"start\":16242},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":17595,\"start\":17592},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":17598,\"start\":17595},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":19136,\"start\":19133},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":20178,\"start\":20174},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":21300,\"start\":21296},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":21937,\"start\":21933},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":22433,\"start\":22429},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":22740,\"start\":22736},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":22945,\"start\":22941},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":23149,\"start\":23145},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":23168,\"start\":23164},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":23731,\"start\":23727},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":24074,\"start\":24071},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":24093,\"start\":24089},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":24103,\"start\":24099},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":24116,\"start\":24112},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":24132,\"start\":24128},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":24376,\"start\":24372},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":24614,\"start\":24610},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":24633,\"start\":24629},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":24759,\"start\":24755},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":24937,\"start\":24933},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":24983,\"start\":24979},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":25253,\"start\":25249},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":25272,\"start\":25268},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":25367,\"start\":25363},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":30191,\"start\":30187},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":2397,\"start\":2393},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":2400,\"start\":2397},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":2403,\"start\":2400},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":2406,\"start\":2403},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":2408,\"start\":2406},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":2411,\"start\":2408},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":2413,\"start\":2411},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":2415,\"start\":2413},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":2544,\"start\":2540},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":2547,\"start\":2544},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":2550,\"start\":2547},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":2553,\"start\":2550},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":2556,\"start\":2553},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":2559,\"start\":2556},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2561,\"start\":2559},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":2564,\"start\":2561},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":3531,\"start\":3528},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":3533,\"start\":3531},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":3920,\"start\":3916},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":5438,\"start\":5434},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":5441,\"start\":5438},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":6718,\"start\":6714},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":6720,\"start\":6718},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":6723,\"start\":6720},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":6726,\"start\":6723},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":6729,\"start\":6726},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":6731,\"start\":6729},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":6734,\"start\":6731},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":6736,\"start\":6734},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":6779,\"start\":6775},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":6782,\"start\":6779},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":6785,\"start\":6782},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":6788,\"start\":6785},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":6790,\"start\":6788},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":6793,\"start\":6790},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":6796,\"start\":6793},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":6799,\"start\":6796},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":6960,\"start\":6957},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":7209,\"start\":7205},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":7346,\"start\":7343},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":7349,\"start\":7346},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":7712,\"start\":7708},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":7982,\"start\":7978},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":8049,\"start\":8046},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":8052,\"start\":8049},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":8055,\"start\":8052},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":8314,\"start\":8310},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":8317,\"start\":8314},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":8320,\"start\":8317},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":8323,\"start\":8320},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":8452,\"start\":8449},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":8461,\"start\":8457},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":8478,\"start\":8474},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":8792,\"start\":8788},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":9104,\"start\":9101},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":9106,\"start\":9104},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":9945,\"start\":9942},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":9948,\"start\":9945},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":9979,\"start\":9975},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":10592,\"start\":10589},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":10594,\"start\":10592},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":12147,\"start\":12143},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":12714,\"start\":12711},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":13770,\"start\":13767},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":14594,\"start\":14590},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":15095,\"start\":15091},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":15697,\"start\":15693},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":16236,\"start\":16233},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":16239,\"start\":16236},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":16242,\"start\":16239},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":16245,\"start\":16242},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":17595,\"start\":17592},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":17598,\"start\":17595},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":19136,\"start\":19133},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":20178,\"start\":20174},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":21300,\"start\":21296},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":21937,\"start\":21933},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":22433,\"start\":22429},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":22740,\"start\":22736},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":22945,\"start\":22941},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":23149,\"start\":23145},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":23168,\"start\":23164},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":23731,\"start\":23727},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":24074,\"start\":24071},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":24093,\"start\":24089},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":24103,\"start\":24099},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":24116,\"start\":24112},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":24132,\"start\":24128},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":24376,\"start\":24372},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":24614,\"start\":24610},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":24633,\"start\":24629},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":24759,\"start\":24755},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":24937,\"start\":24933},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":24983,\"start\":24979},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":25253,\"start\":25249},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":25272,\"start\":25268},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":25367,\"start\":25363},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":30191,\"start\":30187}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":28231,\"start\":27951},{\"attributes\":{\"id\":\"fig_1\"},\"end\":28460,\"start\":28232},{\"attributes\":{\"id\":\"fig_2\"},\"end\":29149,\"start\":28461},{\"attributes\":{\"id\":\"fig_3\"},\"end\":29295,\"start\":29150},{\"attributes\":{\"id\":\"fig_4\"},\"end\":29567,\"start\":29296},{\"attributes\":{\"id\":\"fig_5\"},\"end\":29817,\"start\":29568},{\"attributes\":{\"id\":\"fig_6\"},\"end\":30244,\"start\":29818},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":31346,\"start\":30245},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":31980,\"start\":31347},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":32457,\"start\":31981},{\"attributes\":{\"id\":\"fig_0\"},\"end\":28231,\"start\":27951},{\"attributes\":{\"id\":\"fig_1\"},\"end\":28460,\"start\":28232},{\"attributes\":{\"id\":\"fig_2\"},\"end\":29149,\"start\":28461},{\"attributes\":{\"id\":\"fig_3\"},\"end\":29295,\"start\":29150},{\"attributes\":{\"id\":\"fig_4\"},\"end\":29567,\"start\":29296},{\"attributes\":{\"id\":\"fig_5\"},\"end\":29817,\"start\":29568},{\"attributes\":{\"id\":\"fig_6\"},\"end\":30244,\"start\":29818},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":31346,\"start\":30245},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":31980,\"start\":31347},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":32457,\"start\":31981}]", "paragraph": "[{\"end\":2565,\"start\":2039},{\"end\":3407,\"start\":2567},{\"end\":4877,\"start\":3409},{\"end\":5361,\"start\":4879},{\"end\":5723,\"start\":5363},{\"end\":5763,\"start\":5725},{\"end\":6327,\"start\":5765},{\"end\":6824,\"start\":6344},{\"end\":7838,\"start\":6826},{\"end\":8324,\"start\":7840},{\"end\":8982,\"start\":8326},{\"end\":9702,\"start\":9015},{\"end\":10864,\"start\":9704},{\"end\":11235,\"start\":10866},{\"end\":11842,\"start\":11265},{\"end\":12099,\"start\":11844},{\"end\":12338,\"start\":12101},{\"end\":13009,\"start\":12409},{\"end\":13931,\"start\":13011},{\"end\":16113,\"start\":14003},{\"end\":16808,\"start\":16115},{\"end\":17508,\"start\":16810},{\"end\":18138,\"start\":17531},{\"end\":18539,\"start\":18140},{\"end\":18558,\"start\":18555},{\"end\":18854,\"start\":18560},{\"end\":19200,\"start\":18871},{\"end\":19367,\"start\":19202},{\"end\":19411,\"start\":19408},{\"end\":20761,\"start\":19413},{\"end\":21585,\"start\":20853},{\"end\":21951,\"start\":21648},{\"end\":22051,\"start\":21982},{\"end\":22219,\"start\":22114},{\"end\":23206,\"start\":22246},{\"end\":23929,\"start\":23244},{\"end\":25542,\"start\":23999},{\"end\":26792,\"start\":25595},{\"end\":27950,\"start\":26807},{\"end\":2565,\"start\":2039},{\"end\":3407,\"start\":2567},{\"end\":4877,\"start\":3409},{\"end\":5361,\"start\":4879},{\"end\":5723,\"start\":5363},{\"end\":5763,\"start\":5725},{\"end\":6327,\"start\":5765},{\"end\":6824,\"start\":6344},{\"end\":7838,\"start\":6826},{\"end\":8324,\"start\":7840},{\"end\":8982,\"start\":8326},{\"end\":9702,\"start\":9015},{\"end\":10864,\"start\":9704},{\"end\":11235,\"start\":10866},{\"end\":11842,\"start\":11265},{\"end\":12099,\"start\":11844},{\"end\":12338,\"start\":12101},{\"end\":13009,\"start\":12409},{\"end\":13931,\"start\":13011},{\"end\":16113,\"start\":14003},{\"end\":16808,\"start\":16115},{\"end\":17508,\"start\":16810},{\"end\":18138,\"start\":17531},{\"end\":18539,\"start\":18140},{\"end\":18558,\"start\":18555},{\"end\":18854,\"start\":18560},{\"end\":19200,\"start\":18871},{\"end\":19367,\"start\":19202},{\"end\":19411,\"start\":19408},{\"end\":20761,\"start\":19413},{\"end\":21585,\"start\":20853},{\"end\":21951,\"start\":21648},{\"end\":22051,\"start\":21982},{\"end\":22219,\"start\":22114},{\"end\":23206,\"start\":22246},{\"end\":23929,\"start\":23244},{\"end\":25542,\"start\":23999},{\"end\":26792,\"start\":25595},{\"end\":27950,\"start\":26807}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":12408,\"start\":12339},{\"attributes\":{\"id\":\"formula_1\"},\"end\":18554,\"start\":18540},{\"attributes\":{\"id\":\"formula_2\"},\"end\":18870,\"start\":18855},{\"attributes\":{\"id\":\"formula_3\"},\"end\":19407,\"start\":19368},{\"attributes\":{\"id\":\"formula_4\"},\"end\":20852,\"start\":20762},{\"attributes\":{\"id\":\"formula_5\"},\"end\":21647,\"start\":21586},{\"attributes\":{\"id\":\"formula_6\"},\"end\":21981,\"start\":21952},{\"attributes\":{\"id\":\"formula_7\"},\"end\":22113,\"start\":22052},{\"attributes\":{\"id\":\"formula_0\"},\"end\":12408,\"start\":12339},{\"attributes\":{\"id\":\"formula_1\"},\"end\":18554,\"start\":18540},{\"attributes\":{\"id\":\"formula_2\"},\"end\":18870,\"start\":18855},{\"attributes\":{\"id\":\"formula_3\"},\"end\":19407,\"start\":19368},{\"attributes\":{\"id\":\"formula_4\"},\"end\":20852,\"start\":20762},{\"attributes\":{\"id\":\"formula_5\"},\"end\":21647,\"start\":21586},{\"attributes\":{\"id\":\"formula_6\"},\"end\":21981,\"start\":21952},{\"attributes\":{\"id\":\"formula_7\"},\"end\":22113,\"start\":22052}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":13008,\"start\":13001},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":24492,\"start\":24485},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":25903,\"start\":25896},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":26075,\"start\":26068},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":13008,\"start\":13001},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":24492,\"start\":24485},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":25903,\"start\":25896},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":26075,\"start\":26068}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":2037,\"start\":2025},{\"attributes\":{\"n\":\"2.\"},\"end\":6342,\"start\":6330},{\"attributes\":{\"n\":\"3.\"},\"end\":9000,\"start\":8985},{\"attributes\":{\"n\":\"3.1.\"},\"end\":9013,\"start\":9003},{\"attributes\":{\"n\":\"3.2.\"},\"end\":11263,\"start\":11238},{\"end\":13947,\"start\":13934},{\"end\":13978,\"start\":13950},{\"attributes\":{\"n\":\"3.3.\"},\"end\":14001,\"start\":13981},{\"attributes\":{\"n\":\"3.4.\"},\"end\":17529,\"start\":17511},{\"attributes\":{\"n\":\"3.5.\"},\"end\":22244,\"start\":22222},{\"attributes\":{\"n\":\"4.\"},\"end\":23220,\"start\":23209},{\"attributes\":{\"n\":\"4.1.\"},\"end\":23242,\"start\":23223},{\"attributes\":{\"n\":\"4.2.\"},\"end\":23970,\"start\":23932},{\"attributes\":{\"n\":\"4.2.1\"},\"end\":23997,\"start\":23973},{\"attributes\":{\"n\":\"4.2.2\"},\"end\":25568,\"start\":25545},{\"attributes\":{\"n\":\"4.3.\"},\"end\":25593,\"start\":25571},{\"attributes\":{\"n\":\"5.\"},\"end\":26805,\"start\":26795},{\"end\":27962,\"start\":27952},{\"end\":28243,\"start\":28233},{\"end\":28492,\"start\":28462},{\"end\":29161,\"start\":29151},{\"end\":29300,\"start\":29297},{\"end\":29579,\"start\":29569},{\"end\":29849,\"start\":29819},{\"end\":30255,\"start\":30246},{\"end\":31357,\"start\":31348},{\"end\":31991,\"start\":31982},{\"attributes\":{\"n\":\"1.\"},\"end\":2037,\"start\":2025},{\"attributes\":{\"n\":\"2.\"},\"end\":6342,\"start\":6330},{\"attributes\":{\"n\":\"3.\"},\"end\":9000,\"start\":8985},{\"attributes\":{\"n\":\"3.1.\"},\"end\":9013,\"start\":9003},{\"attributes\":{\"n\":\"3.2.\"},\"end\":11263,\"start\":11238},{\"end\":13947,\"start\":13934},{\"end\":13978,\"start\":13950},{\"attributes\":{\"n\":\"3.3.\"},\"end\":14001,\"start\":13981},{\"attributes\":{\"n\":\"3.4.\"},\"end\":17529,\"start\":17511},{\"attributes\":{\"n\":\"3.5.\"},\"end\":22244,\"start\":22222},{\"attributes\":{\"n\":\"4.\"},\"end\":23220,\"start\":23209},{\"attributes\":{\"n\":\"4.1.\"},\"end\":23242,\"start\":23223},{\"attributes\":{\"n\":\"4.2.\"},\"end\":23970,\"start\":23932},{\"attributes\":{\"n\":\"4.2.1\"},\"end\":23997,\"start\":23973},{\"attributes\":{\"n\":\"4.2.2\"},\"end\":25568,\"start\":25545},{\"attributes\":{\"n\":\"4.3.\"},\"end\":25593,\"start\":25571},{\"attributes\":{\"n\":\"5.\"},\"end\":26805,\"start\":26795},{\"end\":27962,\"start\":27952},{\"end\":28243,\"start\":28233},{\"end\":28492,\"start\":28462},{\"end\":29161,\"start\":29151},{\"end\":29300,\"start\":29297},{\"end\":29579,\"start\":29569},{\"end\":29849,\"start\":29819},{\"end\":30255,\"start\":30246},{\"end\":31357,\"start\":31348},{\"end\":31991,\"start\":31982}]", "table": "[{\"end\":31346,\"start\":30557},{\"end\":31980,\"start\":31767},{\"end\":32457,\"start\":32174},{\"end\":31346,\"start\":30557},{\"end\":31980,\"start\":31767},{\"end\":32457,\"start\":32174}]", "figure_caption": "[{\"end\":28231,\"start\":27964},{\"end\":28460,\"start\":28245},{\"end\":29149,\"start\":28495},{\"end\":29295,\"start\":29163},{\"end\":29567,\"start\":29302},{\"end\":29817,\"start\":29581},{\"end\":30244,\"start\":29853},{\"end\":30557,\"start\":30257},{\"end\":31767,\"start\":31359},{\"end\":32174,\"start\":31993},{\"end\":28231,\"start\":27964},{\"end\":28460,\"start\":28245},{\"end\":29149,\"start\":28495},{\"end\":29295,\"start\":29163},{\"end\":29567,\"start\":29302},{\"end\":29817,\"start\":29581},{\"end\":30244,\"start\":29853},{\"end\":30557,\"start\":30257},{\"end\":31767,\"start\":31359},{\"end\":32174,\"start\":31993}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":3635,\"start\":3627},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":14070,\"start\":14062},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":16511,\"start\":16503},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":23418,\"start\":23410},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":25172,\"start\":25164},{\"end\":26168,\"start\":26159},{\"end\":26181,\"start\":26173},{\"end\":26497,\"start\":26489},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":3635,\"start\":3627},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":14070,\"start\":14062},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":16511,\"start\":16503},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":23418,\"start\":23410},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":25172,\"start\":25164},{\"end\":26168,\"start\":26159},{\"end\":26181,\"start\":26173},{\"end\":26497,\"start\":26489}]", "bib_author_first_name": "[{\"end\":32650,\"start\":32642},{\"end\":32679,\"start\":32667},{\"end\":32695,\"start\":32689},{\"end\":33121,\"start\":33116},{\"end\":33123,\"start\":33122},{\"end\":33442,\"start\":33434},{\"end\":33455,\"start\":33448},{\"end\":33464,\"start\":33460},{\"end\":33476,\"start\":33470},{\"end\":33764,\"start\":33757},{\"end\":33778,\"start\":33770},{\"end\":33789,\"start\":33785},{\"end\":33802,\"start\":33795},{\"end\":33814,\"start\":33809},{\"end\":34331,\"start\":34328},{\"end\":34344,\"start\":34337},{\"end\":34359,\"start\":34350},{\"end\":34632,\"start\":34625},{\"end\":34646,\"start\":34638},{\"end\":34654,\"start\":34652},{\"end\":35062,\"start\":35053},{\"end\":35077,\"start\":35068},{\"end\":35471,\"start\":35465},{\"end\":35487,\"start\":35480},{\"end\":35496,\"start\":35492},{\"end\":35498,\"start\":35497},{\"end\":35772,\"start\":35765},{\"end\":35787,\"start\":35781},{\"end\":35805,\"start\":35801},{\"end\":35807,\"start\":35806},{\"end\":35821,\"start\":35813},{\"end\":36081,\"start\":36073},{\"end\":36093,\"start\":36087},{\"end\":36110,\"start\":36105},{\"end\":36459,\"start\":36453},{\"end\":36478,\"start\":36469},{\"end\":36488,\"start\":36486},{\"end\":36784,\"start\":36783},{\"end\":36800,\"start\":36795},{\"end\":37012,\"start\":37004},{\"end\":37028,\"start\":37018},{\"end\":37043,\"start\":37035},{\"end\":37292,\"start\":37288},{\"end\":37305,\"start\":37300},{\"end\":37317,\"start\":37313},{\"end\":37639,\"start\":37635},{\"end\":37652,\"start\":37647},{\"end\":37664,\"start\":37660},{\"end\":38196,\"start\":38194},{\"end\":38585,\"start\":38583},{\"end\":39026,\"start\":39023},{\"end\":39038,\"start\":39033},{\"end\":39040,\"start\":39039},{\"end\":39052,\"start\":39046},{\"end\":39065,\"start\":39059},{\"end\":39077,\"start\":39070},{\"end\":39556,\"start\":39549},{\"end\":39570,\"start\":39564},{\"end\":39892,\"start\":39889},{\"end\":39911,\"start\":39903},{\"end\":39921,\"start\":39918},{\"end\":39935,\"start\":39928},{\"end\":39950,\"start\":39943},{\"end\":39966,\"start\":39957},{\"end\":40345,\"start\":40340},{\"end\":40362,\"start\":40356},{\"end\":40600,\"start\":40596},{\"end\":40615,\"start\":40611},{\"end\":40938,\"start\":40934},{\"end\":40954,\"start\":40944},{\"end\":40966,\"start\":40960},{\"end\":40977,\"start\":40973},{\"end\":40993,\"start\":40984},{\"end\":41008,\"start\":41000},{\"end\":41479,\"start\":41472},{\"end\":41491,\"start\":41490},{\"end\":42105,\"start\":42099},{\"end\":42116,\"start\":42111},{\"end\":42128,\"start\":42125},{\"end\":42394,\"start\":42388},{\"end\":42405,\"start\":42400},{\"end\":42418,\"start\":42411},{\"end\":42432,\"start\":42425},{\"end\":42442,\"start\":42438},{\"end\":42444,\"start\":42443},{\"end\":42862,\"start\":42856},{\"end\":42873,\"start\":42868},{\"end\":42886,\"start\":42879},{\"end\":42900,\"start\":42893},{\"end\":42910,\"start\":42906},{\"end\":42912,\"start\":42911},{\"end\":43344,\"start\":43338},{\"end\":43355,\"start\":43350},{\"end\":43364,\"start\":43361},{\"end\":43378,\"start\":43374},{\"end\":43380,\"start\":43379},{\"end\":43719,\"start\":43715},{\"end\":43730,\"start\":43726},{\"end\":43732,\"start\":43731},{\"end\":43741,\"start\":43740},{\"end\":43758,\"start\":43757},{\"end\":44126,\"start\":44119},{\"end\":44140,\"start\":44132},{\"end\":44151,\"start\":44147},{\"end\":44161,\"start\":44156},{\"end\":44171,\"start\":44168},{\"end\":44643,\"start\":44638},{\"end\":44655,\"start\":44649},{\"end\":44665,\"start\":44661},{\"end\":44676,\"start\":44671},{\"end\":44690,\"start\":44682},{\"end\":44705,\"start\":44696},{\"end\":45150,\"start\":45143},{\"end\":45163,\"start\":45156},{\"end\":45178,\"start\":45176},{\"end\":45193,\"start\":45184},{\"end\":45520,\"start\":45517},{\"end\":45531,\"start\":45527},{\"end\":45546,\"start\":45538},{\"end\":45559,\"start\":45552},{\"end\":45990,\"start\":45984},{\"end\":46001,\"start\":45998},{\"end\":46012,\"start\":46006},{\"end\":32650,\"start\":32642},{\"end\":32679,\"start\":32667},{\"end\":32695,\"start\":32689},{\"end\":33121,\"start\":33116},{\"end\":33123,\"start\":33122},{\"end\":33442,\"start\":33434},{\"end\":33455,\"start\":33448},{\"end\":33464,\"start\":33460},{\"end\":33476,\"start\":33470},{\"end\":33764,\"start\":33757},{\"end\":33778,\"start\":33770},{\"end\":33789,\"start\":33785},{\"end\":33802,\"start\":33795},{\"end\":33814,\"start\":33809},{\"end\":34331,\"start\":34328},{\"end\":34344,\"start\":34337},{\"end\":34359,\"start\":34350},{\"end\":34632,\"start\":34625},{\"end\":34646,\"start\":34638},{\"end\":34654,\"start\":34652},{\"end\":35062,\"start\":35053},{\"end\":35077,\"start\":35068},{\"end\":35471,\"start\":35465},{\"end\":35487,\"start\":35480},{\"end\":35496,\"start\":35492},{\"end\":35498,\"start\":35497},{\"end\":35772,\"start\":35765},{\"end\":35787,\"start\":35781},{\"end\":35805,\"start\":35801},{\"end\":35807,\"start\":35806},{\"end\":35821,\"start\":35813},{\"end\":36081,\"start\":36073},{\"end\":36093,\"start\":36087},{\"end\":36110,\"start\":36105},{\"end\":36459,\"start\":36453},{\"end\":36478,\"start\":36469},{\"end\":36488,\"start\":36486},{\"end\":36784,\"start\":36783},{\"end\":36800,\"start\":36795},{\"end\":37012,\"start\":37004},{\"end\":37028,\"start\":37018},{\"end\":37043,\"start\":37035},{\"end\":37292,\"start\":37288},{\"end\":37305,\"start\":37300},{\"end\":37317,\"start\":37313},{\"end\":37639,\"start\":37635},{\"end\":37652,\"start\":37647},{\"end\":37664,\"start\":37660},{\"end\":38196,\"start\":38194},{\"end\":38585,\"start\":38583},{\"end\":39026,\"start\":39023},{\"end\":39038,\"start\":39033},{\"end\":39040,\"start\":39039},{\"end\":39052,\"start\":39046},{\"end\":39065,\"start\":39059},{\"end\":39077,\"start\":39070},{\"end\":39556,\"start\":39549},{\"end\":39570,\"start\":39564},{\"end\":39892,\"start\":39889},{\"end\":39911,\"start\":39903},{\"end\":39921,\"start\":39918},{\"end\":39935,\"start\":39928},{\"end\":39950,\"start\":39943},{\"end\":39966,\"start\":39957},{\"end\":40345,\"start\":40340},{\"end\":40362,\"start\":40356},{\"end\":40600,\"start\":40596},{\"end\":40615,\"start\":40611},{\"end\":40938,\"start\":40934},{\"end\":40954,\"start\":40944},{\"end\":40966,\"start\":40960},{\"end\":40977,\"start\":40973},{\"end\":40993,\"start\":40984},{\"end\":41008,\"start\":41000},{\"end\":41479,\"start\":41472},{\"end\":41491,\"start\":41490},{\"end\":42105,\"start\":42099},{\"end\":42116,\"start\":42111},{\"end\":42128,\"start\":42125},{\"end\":42394,\"start\":42388},{\"end\":42405,\"start\":42400},{\"end\":42418,\"start\":42411},{\"end\":42432,\"start\":42425},{\"end\":42442,\"start\":42438},{\"end\":42444,\"start\":42443},{\"end\":42862,\"start\":42856},{\"end\":42873,\"start\":42868},{\"end\":42886,\"start\":42879},{\"end\":42900,\"start\":42893},{\"end\":42910,\"start\":42906},{\"end\":42912,\"start\":42911},{\"end\":43344,\"start\":43338},{\"end\":43355,\"start\":43350},{\"end\":43364,\"start\":43361},{\"end\":43378,\"start\":43374},{\"end\":43380,\"start\":43379},{\"end\":43719,\"start\":43715},{\"end\":43730,\"start\":43726},{\"end\":43732,\"start\":43731},{\"end\":43741,\"start\":43740},{\"end\":43758,\"start\":43757},{\"end\":44126,\"start\":44119},{\"end\":44140,\"start\":44132},{\"end\":44151,\"start\":44147},{\"end\":44161,\"start\":44156},{\"end\":44171,\"start\":44168},{\"end\":44643,\"start\":44638},{\"end\":44655,\"start\":44649},{\"end\":44665,\"start\":44661},{\"end\":44676,\"start\":44671},{\"end\":44690,\"start\":44682},{\"end\":44705,\"start\":44696},{\"end\":45150,\"start\":45143},{\"end\":45163,\"start\":45156},{\"end\":45178,\"start\":45176},{\"end\":45193,\"start\":45184},{\"end\":45520,\"start\":45517},{\"end\":45531,\"start\":45527},{\"end\":45546,\"start\":45538},{\"end\":45559,\"start\":45552},{\"end\":45990,\"start\":45984},{\"end\":46001,\"start\":45998},{\"end\":46012,\"start\":46006}]", "bib_author_last_name": "[{\"end\":32665,\"start\":32651},{\"end\":32687,\"start\":32680},{\"end\":32705,\"start\":32696},{\"end\":33128,\"start\":33124},{\"end\":33446,\"start\":33443},{\"end\":33458,\"start\":33456},{\"end\":33468,\"start\":33465},{\"end\":33479,\"start\":33477},{\"end\":33768,\"start\":33765},{\"end\":33783,\"start\":33779},{\"end\":33793,\"start\":33790},{\"end\":33807,\"start\":33803},{\"end\":33819,\"start\":33815},{\"end\":34335,\"start\":34332},{\"end\":34348,\"start\":34345},{\"end\":34365,\"start\":34360},{\"end\":34636,\"start\":34633},{\"end\":34650,\"start\":34647},{\"end\":34657,\"start\":34655},{\"end\":35066,\"start\":35063},{\"end\":35081,\"start\":35078},{\"end\":35478,\"start\":35472},{\"end\":35490,\"start\":35488},{\"end\":35510,\"start\":35499},{\"end\":35520,\"start\":35512},{\"end\":35779,\"start\":35773},{\"end\":35799,\"start\":35788},{\"end\":35811,\"start\":35808},{\"end\":35830,\"start\":35822},{\"end\":35837,\"start\":35832},{\"end\":36085,\"start\":36082},{\"end\":36103,\"start\":36094},{\"end\":36117,\"start\":36111},{\"end\":36467,\"start\":36460},{\"end\":36484,\"start\":36479},{\"end\":36496,\"start\":36489},{\"end\":36793,\"start\":36785},{\"end\":36807,\"start\":36801},{\"end\":36811,\"start\":36809},{\"end\":37016,\"start\":37013},{\"end\":37033,\"start\":37029},{\"end\":37046,\"start\":37044},{\"end\":37298,\"start\":37293},{\"end\":37311,\"start\":37306},{\"end\":37323,\"start\":37318},{\"end\":37645,\"start\":37640},{\"end\":37658,\"start\":37653},{\"end\":37670,\"start\":37665},{\"end\":38199,\"start\":38197},{\"end\":38216,\"start\":38201},{\"end\":38588,\"start\":38586},{\"end\":38605,\"start\":38590},{\"end\":39031,\"start\":39027},{\"end\":39044,\"start\":39041},{\"end\":39057,\"start\":39053},{\"end\":39068,\"start\":39066},{\"end\":39081,\"start\":39078},{\"end\":39562,\"start\":39557},{\"end\":39576,\"start\":39571},{\"end\":39901,\"start\":39893},{\"end\":39916,\"start\":39912},{\"end\":39926,\"start\":39922},{\"end\":39941,\"start\":39936},{\"end\":39955,\"start\":39951},{\"end\":39970,\"start\":39967},{\"end\":40354,\"start\":40346},{\"end\":40372,\"start\":40363},{\"end\":40609,\"start\":40601},{\"end\":40621,\"start\":40616},{\"end\":40942,\"start\":40939},{\"end\":40958,\"start\":40955},{\"end\":40971,\"start\":40967},{\"end\":40982,\"start\":40978},{\"end\":40998,\"start\":40994},{\"end\":41012,\"start\":41009},{\"end\":41488,\"start\":41480},{\"end\":41503,\"start\":41492},{\"end\":41512,\"start\":41505},{\"end\":42109,\"start\":42106},{\"end\":42123,\"start\":42117},{\"end\":42141,\"start\":42129},{\"end\":42398,\"start\":42395},{\"end\":42409,\"start\":42406},{\"end\":42423,\"start\":42419},{\"end\":42436,\"start\":42433},{\"end\":42448,\"start\":42445},{\"end\":42866,\"start\":42863},{\"end\":42877,\"start\":42874},{\"end\":42891,\"start\":42887},{\"end\":42904,\"start\":42901},{\"end\":42916,\"start\":42913},{\"end\":43348,\"start\":43345},{\"end\":43359,\"start\":43356},{\"end\":43372,\"start\":43365},{\"end\":43384,\"start\":43381},{\"end\":43724,\"start\":43720},{\"end\":43738,\"start\":43733},{\"end\":43747,\"start\":43742},{\"end\":43755,\"start\":43749},{\"end\":43763,\"start\":43759},{\"end\":43775,\"start\":43765},{\"end\":44130,\"start\":44127},{\"end\":44145,\"start\":44141},{\"end\":44154,\"start\":44152},{\"end\":44166,\"start\":44162},{\"end\":44177,\"start\":44172},{\"end\":44647,\"start\":44644},{\"end\":44659,\"start\":44656},{\"end\":44669,\"start\":44666},{\"end\":44680,\"start\":44677},{\"end\":44694,\"start\":44691},{\"end\":44708,\"start\":44706},{\"end\":45154,\"start\":45151},{\"end\":45174,\"start\":45164},{\"end\":45182,\"start\":45179},{\"end\":45201,\"start\":45194},{\"end\":45525,\"start\":45521},{\"end\":45536,\"start\":45532},{\"end\":45550,\"start\":45547},{\"end\":45563,\"start\":45560},{\"end\":45996,\"start\":45991},{\"end\":46004,\"start\":46002},{\"end\":46017,\"start\":46013},{\"end\":32665,\"start\":32651},{\"end\":32687,\"start\":32680},{\"end\":32705,\"start\":32696},{\"end\":33128,\"start\":33124},{\"end\":33446,\"start\":33443},{\"end\":33458,\"start\":33456},{\"end\":33468,\"start\":33465},{\"end\":33479,\"start\":33477},{\"end\":33768,\"start\":33765},{\"end\":33783,\"start\":33779},{\"end\":33793,\"start\":33790},{\"end\":33807,\"start\":33803},{\"end\":33819,\"start\":33815},{\"end\":34335,\"start\":34332},{\"end\":34348,\"start\":34345},{\"end\":34365,\"start\":34360},{\"end\":34636,\"start\":34633},{\"end\":34650,\"start\":34647},{\"end\":34657,\"start\":34655},{\"end\":35066,\"start\":35063},{\"end\":35081,\"start\":35078},{\"end\":35478,\"start\":35472},{\"end\":35490,\"start\":35488},{\"end\":35510,\"start\":35499},{\"end\":35520,\"start\":35512},{\"end\":35779,\"start\":35773},{\"end\":35799,\"start\":35788},{\"end\":35811,\"start\":35808},{\"end\":35830,\"start\":35822},{\"end\":35837,\"start\":35832},{\"end\":36085,\"start\":36082},{\"end\":36103,\"start\":36094},{\"end\":36117,\"start\":36111},{\"end\":36467,\"start\":36460},{\"end\":36484,\"start\":36479},{\"end\":36496,\"start\":36489},{\"end\":36793,\"start\":36785},{\"end\":36807,\"start\":36801},{\"end\":36811,\"start\":36809},{\"end\":37016,\"start\":37013},{\"end\":37033,\"start\":37029},{\"end\":37046,\"start\":37044},{\"end\":37298,\"start\":37293},{\"end\":37311,\"start\":37306},{\"end\":37323,\"start\":37318},{\"end\":37645,\"start\":37640},{\"end\":37658,\"start\":37653},{\"end\":37670,\"start\":37665},{\"end\":38199,\"start\":38197},{\"end\":38216,\"start\":38201},{\"end\":38588,\"start\":38586},{\"end\":38605,\"start\":38590},{\"end\":39031,\"start\":39027},{\"end\":39044,\"start\":39041},{\"end\":39057,\"start\":39053},{\"end\":39068,\"start\":39066},{\"end\":39081,\"start\":39078},{\"end\":39562,\"start\":39557},{\"end\":39576,\"start\":39571},{\"end\":39901,\"start\":39893},{\"end\":39916,\"start\":39912},{\"end\":39926,\"start\":39922},{\"end\":39941,\"start\":39936},{\"end\":39955,\"start\":39951},{\"end\":39970,\"start\":39967},{\"end\":40354,\"start\":40346},{\"end\":40372,\"start\":40363},{\"end\":40609,\"start\":40601},{\"end\":40621,\"start\":40616},{\"end\":40942,\"start\":40939},{\"end\":40958,\"start\":40955},{\"end\":40971,\"start\":40967},{\"end\":40982,\"start\":40978},{\"end\":40998,\"start\":40994},{\"end\":41012,\"start\":41009},{\"end\":41488,\"start\":41480},{\"end\":41503,\"start\":41492},{\"end\":41512,\"start\":41505},{\"end\":42109,\"start\":42106},{\"end\":42123,\"start\":42117},{\"end\":42141,\"start\":42129},{\"end\":42398,\"start\":42395},{\"end\":42409,\"start\":42406},{\"end\":42423,\"start\":42419},{\"end\":42436,\"start\":42433},{\"end\":42448,\"start\":42445},{\"end\":42866,\"start\":42863},{\"end\":42877,\"start\":42874},{\"end\":42891,\"start\":42887},{\"end\":42904,\"start\":42901},{\"end\":42916,\"start\":42913},{\"end\":43348,\"start\":43345},{\"end\":43359,\"start\":43356},{\"end\":43372,\"start\":43365},{\"end\":43384,\"start\":43381},{\"end\":43724,\"start\":43720},{\"end\":43738,\"start\":43733},{\"end\":43747,\"start\":43742},{\"end\":43755,\"start\":43749},{\"end\":43763,\"start\":43759},{\"end\":43775,\"start\":43765},{\"end\":44130,\"start\":44127},{\"end\":44145,\"start\":44141},{\"end\":44154,\"start\":44152},{\"end\":44166,\"start\":44162},{\"end\":44177,\"start\":44172},{\"end\":44647,\"start\":44644},{\"end\":44659,\"start\":44656},{\"end\":44669,\"start\":44666},{\"end\":44680,\"start\":44677},{\"end\":44694,\"start\":44691},{\"end\":44708,\"start\":44706},{\"end\":45154,\"start\":45151},{\"end\":45174,\"start\":45164},{\"end\":45182,\"start\":45179},{\"end\":45201,\"start\":45194},{\"end\":45525,\"start\":45521},{\"end\":45536,\"start\":45532},{\"end\":45550,\"start\":45547},{\"end\":45563,\"start\":45560},{\"end\":45996,\"start\":45991},{\"end\":46004,\"start\":46002},{\"end\":46017,\"start\":46013}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":13095034},\"end\":33058,\"start\":32605},{\"attributes\":{\"id\":\"b1\"},\"end\":33364,\"start\":33060},{\"attributes\":{\"doi\":\"arXiv:1802.00094\",\"id\":\"b2\"},\"end\":33670,\"start\":33366},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":8621123},\"end\":34191,\"start\":33672},{\"attributes\":{\"id\":\"b4\"},\"end\":34569,\"start\":34193},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":8976032},\"end\":34998,\"start\":34571},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":31926300},\"end\":35416,\"start\":35000},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":11193800},\"end\":35694,\"start\":35418},{\"attributes\":{\"doi\":\"abs/1501.05700\",\"id\":\"b8\"},\"end\":36034,\"start\":35696},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":44084774},\"end\":36382,\"start\":36036},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":980236},\"end\":36737,\"start\":36384},{\"attributes\":{\"doi\":\"arXiv:1412.6980\",\"id\":\"b11\"},\"end\":36955,\"start\":36739},{\"attributes\":{\"doi\":\"arXiv:1801.04102\",\"id\":\"b12\"},\"end\":37213,\"start\":36957},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":1500423},\"end\":37568,\"start\":37215},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":9779209},\"end\":38129,\"start\":37570},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":15044065},\"end\":38524,\"start\":38131},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":16165913},\"end\":38938,\"start\":38526},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":4539586},\"end\":39481,\"start\":38940},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":14798441},\"end\":39801,\"start\":39483},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":6352419},\"end\":40270,\"start\":39803},{\"attributes\":{\"doi\":\"arXiv:1409.1556\",\"id\":\"b20\"},\"end\":40547,\"start\":40272},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":3446098},\"end\":40861,\"start\":40549},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":4255150},\"end\":41391,\"start\":40863},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":8798317},\"end\":41977,\"start\":41393},{\"attributes\":{\"id\":\"b24\"},\"end\":42329,\"start\":41979},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":6158161},\"end\":42790,\"start\":42331},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":44176905},\"end\":43294,\"start\":42792},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":15198184},\"end\":43639,\"start\":43296},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":207761262},\"end\":44023,\"start\":43641},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":90259427},\"end\":44586,\"start\":44025},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":198333802},\"end\":45082,\"start\":44588},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":7600506},\"end\":45418,\"start\":45084},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":52957534},\"end\":45923,\"start\":45420},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":49209675},\"end\":46364,\"start\":45925},{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":13095034},\"end\":33058,\"start\":32605},{\"attributes\":{\"id\":\"b1\"},\"end\":33364,\"start\":33060},{\"attributes\":{\"doi\":\"arXiv:1802.00094\",\"id\":\"b2\"},\"end\":33670,\"start\":33366},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":8621123},\"end\":34191,\"start\":33672},{\"attributes\":{\"id\":\"b4\"},\"end\":34569,\"start\":34193},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":8976032},\"end\":34998,\"start\":34571},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":31926300},\"end\":35416,\"start\":35000},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":11193800},\"end\":35694,\"start\":35418},{\"attributes\":{\"doi\":\"abs/1501.05700\",\"id\":\"b8\"},\"end\":36034,\"start\":35696},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":44084774},\"end\":36382,\"start\":36036},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":980236},\"end\":36737,\"start\":36384},{\"attributes\":{\"doi\":\"arXiv:1412.6980\",\"id\":\"b11\"},\"end\":36955,\"start\":36739},{\"attributes\":{\"doi\":\"arXiv:1801.04102\",\"id\":\"b12\"},\"end\":37213,\"start\":36957},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":1500423},\"end\":37568,\"start\":37215},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":9779209},\"end\":38129,\"start\":37570},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":15044065},\"end\":38524,\"start\":38131},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":16165913},\"end\":38938,\"start\":38526},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":4539586},\"end\":39481,\"start\":38940},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":14798441},\"end\":39801,\"start\":39483},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":6352419},\"end\":40270,\"start\":39803},{\"attributes\":{\"doi\":\"arXiv:1409.1556\",\"id\":\"b20\"},\"end\":40547,\"start\":40272},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":3446098},\"end\":40861,\"start\":40549},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":4255150},\"end\":41391,\"start\":40863},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":8798317},\"end\":41977,\"start\":41393},{\"attributes\":{\"id\":\"b24\"},\"end\":42329,\"start\":41979},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":6158161},\"end\":42790,\"start\":42331},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":44176905},\"end\":43294,\"start\":42792},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":15198184},\"end\":43639,\"start\":43296},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":207761262},\"end\":44023,\"start\":43641},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":90259427},\"end\":44586,\"start\":44025},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":198333802},\"end\":45082,\"start\":44588},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":7600506},\"end\":45418,\"start\":45084},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":52957534},\"end\":45923,\"start\":45420},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":49209675},\"end\":46364,\"start\":45925}]", "bib_title": "[{\"end\":32640,\"start\":32605},{\"end\":33114,\"start\":33060},{\"end\":33755,\"start\":33672},{\"end\":34623,\"start\":34571},{\"end\":35051,\"start\":35000},{\"end\":35463,\"start\":35418},{\"end\":36071,\"start\":36036},{\"end\":36451,\"start\":36384},{\"end\":37286,\"start\":37215},{\"end\":37633,\"start\":37570},{\"end\":38192,\"start\":38131},{\"end\":38581,\"start\":38526},{\"end\":39021,\"start\":38940},{\"end\":39547,\"start\":39483},{\"end\":39887,\"start\":39803},{\"end\":40594,\"start\":40549},{\"end\":40932,\"start\":40863},{\"end\":41470,\"start\":41393},{\"end\":42386,\"start\":42331},{\"end\":42854,\"start\":42792},{\"end\":43336,\"start\":43296},{\"end\":43713,\"start\":43641},{\"end\":44117,\"start\":44025},{\"end\":44636,\"start\":44588},{\"end\":45141,\"start\":45084},{\"end\":45515,\"start\":45420},{\"end\":45982,\"start\":45925},{\"end\":32640,\"start\":32605},{\"end\":33114,\"start\":33060},{\"end\":33755,\"start\":33672},{\"end\":34623,\"start\":34571},{\"end\":35051,\"start\":35000},{\"end\":35463,\"start\":35418},{\"end\":36071,\"start\":36036},{\"end\":36451,\"start\":36384},{\"end\":37286,\"start\":37215},{\"end\":37633,\"start\":37570},{\"end\":38192,\"start\":38131},{\"end\":38581,\"start\":38526},{\"end\":39021,\"start\":38940},{\"end\":39547,\"start\":39483},{\"end\":39887,\"start\":39803},{\"end\":40594,\"start\":40549},{\"end\":40932,\"start\":40863},{\"end\":41470,\"start\":41393},{\"end\":42386,\"start\":42331},{\"end\":42854,\"start\":42792},{\"end\":43336,\"start\":43296},{\"end\":43713,\"start\":43641},{\"end\":44117,\"start\":44025},{\"end\":44636,\"start\":44588},{\"end\":45141,\"start\":45084},{\"end\":45515,\"start\":45420},{\"end\":45982,\"start\":45925}]", "bib_author": "[{\"end\":32667,\"start\":32642},{\"end\":32689,\"start\":32667},{\"end\":32707,\"start\":32689},{\"end\":33130,\"start\":33116},{\"end\":33448,\"start\":33434},{\"end\":33460,\"start\":33448},{\"end\":33470,\"start\":33460},{\"end\":33481,\"start\":33470},{\"end\":33770,\"start\":33757},{\"end\":33785,\"start\":33770},{\"end\":33795,\"start\":33785},{\"end\":33809,\"start\":33795},{\"end\":33821,\"start\":33809},{\"end\":34337,\"start\":34328},{\"end\":34350,\"start\":34337},{\"end\":34367,\"start\":34350},{\"end\":34638,\"start\":34625},{\"end\":34652,\"start\":34638},{\"end\":34659,\"start\":34652},{\"end\":35068,\"start\":35053},{\"end\":35083,\"start\":35068},{\"end\":35480,\"start\":35465},{\"end\":35492,\"start\":35480},{\"end\":35512,\"start\":35492},{\"end\":35522,\"start\":35512},{\"end\":35781,\"start\":35765},{\"end\":35801,\"start\":35781},{\"end\":35813,\"start\":35801},{\"end\":35832,\"start\":35813},{\"end\":35839,\"start\":35832},{\"end\":36087,\"start\":36073},{\"end\":36105,\"start\":36087},{\"end\":36119,\"start\":36105},{\"end\":36469,\"start\":36453},{\"end\":36486,\"start\":36469},{\"end\":36498,\"start\":36486},{\"end\":36795,\"start\":36783},{\"end\":36809,\"start\":36795},{\"end\":36813,\"start\":36809},{\"end\":37018,\"start\":37004},{\"end\":37035,\"start\":37018},{\"end\":37048,\"start\":37035},{\"end\":37300,\"start\":37288},{\"end\":37313,\"start\":37300},{\"end\":37325,\"start\":37313},{\"end\":37647,\"start\":37635},{\"end\":37660,\"start\":37647},{\"end\":37672,\"start\":37660},{\"end\":38201,\"start\":38194},{\"end\":38218,\"start\":38201},{\"end\":38590,\"start\":38583},{\"end\":38607,\"start\":38590},{\"end\":39033,\"start\":39023},{\"end\":39046,\"start\":39033},{\"end\":39059,\"start\":39046},{\"end\":39070,\"start\":39059},{\"end\":39083,\"start\":39070},{\"end\":39564,\"start\":39549},{\"end\":39578,\"start\":39564},{\"end\":39903,\"start\":39889},{\"end\":39918,\"start\":39903},{\"end\":39928,\"start\":39918},{\"end\":39943,\"start\":39928},{\"end\":39957,\"start\":39943},{\"end\":39972,\"start\":39957},{\"end\":40356,\"start\":40340},{\"end\":40374,\"start\":40356},{\"end\":40611,\"start\":40596},{\"end\":40623,\"start\":40611},{\"end\":40944,\"start\":40934},{\"end\":40960,\"start\":40944},{\"end\":40973,\"start\":40960},{\"end\":40984,\"start\":40973},{\"end\":41000,\"start\":40984},{\"end\":41014,\"start\":41000},{\"end\":41490,\"start\":41472},{\"end\":41505,\"start\":41490},{\"end\":41514,\"start\":41505},{\"end\":42111,\"start\":42099},{\"end\":42125,\"start\":42111},{\"end\":42143,\"start\":42125},{\"end\":42400,\"start\":42388},{\"end\":42411,\"start\":42400},{\"end\":42425,\"start\":42411},{\"end\":42438,\"start\":42425},{\"end\":42450,\"start\":42438},{\"end\":42868,\"start\":42856},{\"end\":42879,\"start\":42868},{\"end\":42893,\"start\":42879},{\"end\":42906,\"start\":42893},{\"end\":42918,\"start\":42906},{\"end\":43350,\"start\":43338},{\"end\":43361,\"start\":43350},{\"end\":43374,\"start\":43361},{\"end\":43386,\"start\":43374},{\"end\":43726,\"start\":43715},{\"end\":43740,\"start\":43726},{\"end\":43749,\"start\":43740},{\"end\":43757,\"start\":43749},{\"end\":43765,\"start\":43757},{\"end\":43777,\"start\":43765},{\"end\":44132,\"start\":44119},{\"end\":44147,\"start\":44132},{\"end\":44156,\"start\":44147},{\"end\":44168,\"start\":44156},{\"end\":44179,\"start\":44168},{\"end\":44649,\"start\":44638},{\"end\":44661,\"start\":44649},{\"end\":44671,\"start\":44661},{\"end\":44682,\"start\":44671},{\"end\":44696,\"start\":44682},{\"end\":44710,\"start\":44696},{\"end\":45156,\"start\":45143},{\"end\":45176,\"start\":45156},{\"end\":45184,\"start\":45176},{\"end\":45203,\"start\":45184},{\"end\":45527,\"start\":45517},{\"end\":45538,\"start\":45527},{\"end\":45552,\"start\":45538},{\"end\":45565,\"start\":45552},{\"end\":45998,\"start\":45984},{\"end\":46006,\"start\":45998},{\"end\":46019,\"start\":46006},{\"end\":32667,\"start\":32642},{\"end\":32689,\"start\":32667},{\"end\":32707,\"start\":32689},{\"end\":33130,\"start\":33116},{\"end\":33448,\"start\":33434},{\"end\":33460,\"start\":33448},{\"end\":33470,\"start\":33460},{\"end\":33481,\"start\":33470},{\"end\":33770,\"start\":33757},{\"end\":33785,\"start\":33770},{\"end\":33795,\"start\":33785},{\"end\":33809,\"start\":33795},{\"end\":33821,\"start\":33809},{\"end\":34337,\"start\":34328},{\"end\":34350,\"start\":34337},{\"end\":34367,\"start\":34350},{\"end\":34638,\"start\":34625},{\"end\":34652,\"start\":34638},{\"end\":34659,\"start\":34652},{\"end\":35068,\"start\":35053},{\"end\":35083,\"start\":35068},{\"end\":35480,\"start\":35465},{\"end\":35492,\"start\":35480},{\"end\":35512,\"start\":35492},{\"end\":35522,\"start\":35512},{\"end\":35781,\"start\":35765},{\"end\":35801,\"start\":35781},{\"end\":35813,\"start\":35801},{\"end\":35832,\"start\":35813},{\"end\":35839,\"start\":35832},{\"end\":36087,\"start\":36073},{\"end\":36105,\"start\":36087},{\"end\":36119,\"start\":36105},{\"end\":36469,\"start\":36453},{\"end\":36486,\"start\":36469},{\"end\":36498,\"start\":36486},{\"end\":36795,\"start\":36783},{\"end\":36809,\"start\":36795},{\"end\":36813,\"start\":36809},{\"end\":37018,\"start\":37004},{\"end\":37035,\"start\":37018},{\"end\":37048,\"start\":37035},{\"end\":37300,\"start\":37288},{\"end\":37313,\"start\":37300},{\"end\":37325,\"start\":37313},{\"end\":37647,\"start\":37635},{\"end\":37660,\"start\":37647},{\"end\":37672,\"start\":37660},{\"end\":38201,\"start\":38194},{\"end\":38218,\"start\":38201},{\"end\":38590,\"start\":38583},{\"end\":38607,\"start\":38590},{\"end\":39033,\"start\":39023},{\"end\":39046,\"start\":39033},{\"end\":39059,\"start\":39046},{\"end\":39070,\"start\":39059},{\"end\":39083,\"start\":39070},{\"end\":39564,\"start\":39549},{\"end\":39578,\"start\":39564},{\"end\":39903,\"start\":39889},{\"end\":39918,\"start\":39903},{\"end\":39928,\"start\":39918},{\"end\":39943,\"start\":39928},{\"end\":39957,\"start\":39943},{\"end\":39972,\"start\":39957},{\"end\":40356,\"start\":40340},{\"end\":40374,\"start\":40356},{\"end\":40611,\"start\":40596},{\"end\":40623,\"start\":40611},{\"end\":40944,\"start\":40934},{\"end\":40960,\"start\":40944},{\"end\":40973,\"start\":40960},{\"end\":40984,\"start\":40973},{\"end\":41000,\"start\":40984},{\"end\":41014,\"start\":41000},{\"end\":41490,\"start\":41472},{\"end\":41505,\"start\":41490},{\"end\":41514,\"start\":41505},{\"end\":42111,\"start\":42099},{\"end\":42125,\"start\":42111},{\"end\":42143,\"start\":42125},{\"end\":42400,\"start\":42388},{\"end\":42411,\"start\":42400},{\"end\":42425,\"start\":42411},{\"end\":42438,\"start\":42425},{\"end\":42450,\"start\":42438},{\"end\":42868,\"start\":42856},{\"end\":42879,\"start\":42868},{\"end\":42893,\"start\":42879},{\"end\":42906,\"start\":42893},{\"end\":42918,\"start\":42906},{\"end\":43350,\"start\":43338},{\"end\":43361,\"start\":43350},{\"end\":43374,\"start\":43361},{\"end\":43386,\"start\":43374},{\"end\":43726,\"start\":43715},{\"end\":43740,\"start\":43726},{\"end\":43749,\"start\":43740},{\"end\":43757,\"start\":43749},{\"end\":43765,\"start\":43757},{\"end\":43777,\"start\":43765},{\"end\":44132,\"start\":44119},{\"end\":44147,\"start\":44132},{\"end\":44156,\"start\":44147},{\"end\":44168,\"start\":44156},{\"end\":44179,\"start\":44168},{\"end\":44649,\"start\":44638},{\"end\":44661,\"start\":44649},{\"end\":44671,\"start\":44661},{\"end\":44682,\"start\":44671},{\"end\":44696,\"start\":44682},{\"end\":44710,\"start\":44696},{\"end\":45156,\"start\":45143},{\"end\":45176,\"start\":45156},{\"end\":45184,\"start\":45176},{\"end\":45203,\"start\":45184},{\"end\":45527,\"start\":45517},{\"end\":45538,\"start\":45527},{\"end\":45552,\"start\":45538},{\"end\":45565,\"start\":45552},{\"end\":45998,\"start\":45984},{\"end\":46006,\"start\":45998},{\"end\":46019,\"start\":46006}]", "bib_venue": "[{\"end\":32784,\"start\":32707},{\"end\":33160,\"start\":33130},{\"end\":33432,\"start\":33366},{\"end\":33888,\"start\":33821},{\"end\":34326,\"start\":34193},{\"end\":34736,\"start\":34659},{\"end\":35160,\"start\":35083},{\"end\":35542,\"start\":35522},{\"end\":35763,\"start\":35696},{\"end\":36189,\"start\":36119},{\"end\":36536,\"start\":36498},{\"end\":36781,\"start\":36739},{\"end\":37002,\"start\":36957},{\"end\":37374,\"start\":37325},{\"end\":37771,\"start\":37672},{\"end\":38285,\"start\":38218},{\"end\":38684,\"start\":38607},{\"end\":39160,\"start\":39083},{\"end\":39616,\"start\":39578},{\"end\":40021,\"start\":39972},{\"end\":40338,\"start\":40272},{\"end\":40684,\"start\":40623},{\"end\":41080,\"start\":41014},{\"end\":41614,\"start\":41514},{\"end\":42097,\"start\":41979},{\"end\":42517,\"start\":42450},{\"end\":42995,\"start\":42918},{\"end\":43447,\"start\":43386},{\"end\":43814,\"start\":43777},{\"end\":44256,\"start\":44179},{\"end\":44787,\"start\":44710},{\"end\":45237,\"start\":45203},{\"end\":45629,\"start\":45565},{\"end\":46096,\"start\":46019},{\"end\":32784,\"start\":32707},{\"end\":33160,\"start\":33130},{\"end\":33432,\"start\":33366},{\"end\":33888,\"start\":33821},{\"end\":34326,\"start\":34193},{\"end\":34736,\"start\":34659},{\"end\":35160,\"start\":35083},{\"end\":35542,\"start\":35522},{\"end\":35763,\"start\":35696},{\"end\":36189,\"start\":36119},{\"end\":36536,\"start\":36498},{\"end\":36781,\"start\":36739},{\"end\":37002,\"start\":36957},{\"end\":37374,\"start\":37325},{\"end\":37771,\"start\":37672},{\"end\":38285,\"start\":38218},{\"end\":38684,\"start\":38607},{\"end\":39160,\"start\":39083},{\"end\":39616,\"start\":39578},{\"end\":40021,\"start\":39972},{\"end\":40338,\"start\":40272},{\"end\":40684,\"start\":40623},{\"end\":41080,\"start\":41014},{\"end\":41614,\"start\":41514},{\"end\":42097,\"start\":41979},{\"end\":42517,\"start\":42450},{\"end\":42995,\"start\":42918},{\"end\":43447,\"start\":43386},{\"end\":43814,\"start\":43777},{\"end\":44256,\"start\":44179},{\"end\":44787,\"start\":44710},{\"end\":45237,\"start\":45203},{\"end\":45629,\"start\":45565},{\"end\":46096,\"start\":46019},{\"end\":32848,\"start\":32786},{\"end\":33181,\"start\":33175},{\"end\":33942,\"start\":33890},{\"end\":34800,\"start\":34738},{\"end\":35224,\"start\":35162},{\"end\":37857,\"start\":37773},{\"end\":38339,\"start\":38287},{\"end\":38748,\"start\":38686},{\"end\":39224,\"start\":39162},{\"end\":41133,\"start\":41082},{\"end\":41704,\"start\":41616},{\"end\":42571,\"start\":42519},{\"end\":43059,\"start\":42997},{\"end\":44320,\"start\":44258},{\"end\":44851,\"start\":44789},{\"end\":45680,\"start\":45631},{\"end\":46160,\"start\":46098},{\"end\":32848,\"start\":32786},{\"end\":33181,\"start\":33175},{\"end\":33942,\"start\":33890},{\"end\":34800,\"start\":34738},{\"end\":35224,\"start\":35162},{\"end\":37857,\"start\":37773},{\"end\":38339,\"start\":38287},{\"end\":38748,\"start\":38686},{\"end\":39224,\"start\":39162},{\"end\":41133,\"start\":41082},{\"end\":41704,\"start\":41616},{\"end\":42571,\"start\":42519},{\"end\":43059,\"start\":42997},{\"end\":44320,\"start\":44258},{\"end\":44851,\"start\":44789},{\"end\":45680,\"start\":45631},{\"end\":46160,\"start\":46098}]"}}}, "year": 2023, "month": 12, "day": 17}