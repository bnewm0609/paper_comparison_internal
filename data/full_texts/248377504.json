{"id": 248377504, "updated": "2023-10-05 15:00:46.126", "metadata": {"title": "STC-IDS: Spatial-Temporal Correlation Feature Analyzing based Intrusion Detection System for Intelligent Connected Vehicles", "authors": "[{\"first\":\"Pengzhou\",\"last\":\"Cheng\",\"middle\":[]},{\"first\":\"Mu\",\"last\":\"Han\",\"middle\":[]},{\"first\":\"Aoxue\",\"last\":\"Li\",\"middle\":[]},{\"first\":\"Fengwei\",\"last\":\"Zhang\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "Intrusion detection is an important defensive measure for automotive communications security. Accurate frame detection models assist vehicles to avoid malicious attacks. Uncertainty and diversity regarding attack methods make this task challenging. However, the existing works have the limitation of only considering local features or the weak feature mapping of multi-features. To address these limitations, we present a novel model for automotive intrusion detection by spatial-temporal correlation features of in-vehicle communication traffic (STC-IDS). Specifically, the proposed model exploits an encoding-detection architecture. In the encoder part, spatial and temporal relations are encoded simultaneously. To strengthen the relationship between features, the attention-based convolutional network still captures spatial and channel features to increase the receptive field, while attention-LSTM builds meaningful relationships from previous time series or crucial bytes. The encoded information is then passed to detector for generating forceful spatial-temporal attention features and enabling anomaly classification. In particular, single-frame and multi-frame models are constructed to present different advantages respectively. Under automatic hyper-parameter selection based on Bayesian optimization, the model is trained to attain the best performance. Extensive empirical studies based on a real-world vehicle attack dataset demonstrate that STC-IDS has outperformed baseline methods and obtains fewer false-alarm rates while maintaining efficiency.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2204.10990", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/ijis/ChengHLZ22", "doi": "10.1002/int.23012"}}, "content": {"source": {"pdf_hash": "816bc1846ace6cdc4197cde9bba2440c5949d6d8", "pdf_src": "Arxiv", "pdf_uri": "[\"https://export.arxiv.org/pdf/2204.10990v2.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "373416b40088c6b438c86f7c3d073eeb9413ab49", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/816bc1846ace6cdc4197cde9bba2440c5949d6d8.txt", "contents": "\nSTC-IDS: Spatial-Temporal Correlation Feature Analyzing based Intrusion Detection System for Intelligent Connected Vehicles\n\n\nMuPengzhou Cheng \nMember, IEEEHan * \nAoxue Li \nFengwei Zhang \nSTC-IDS: Spatial-Temporal Correlation Feature Analyzing based Intrusion Detection System for Intelligent Connected Vehicles\n1Index Terms-In-vehicle networks (IVNs)Control area net- work (CAN)Intrusion detection system (IDS)Spatial-temporal featuresAttention mechanism\nIntrusion detection is an important defensive measure for automotive communications security. Accurate frame detection models assist vehicles to avoid malicious attacks. Uncertainty and diversity regarding attack methods make this task challenging. However, the existing works have the limitation of only considering local features or the weak feature mapping of multi-features. To address these limitations, we present a novel model for automotive intrusion detection by spatial-temporal correlation features of in-vehicle communication traffic (STC-IDS). Specifically, the proposed model exploits an encodingdetection architecture. In the encoder part, spatial and temporal relations are encoded simultaneously. To strengthen the relationship between features, the attention-based convolutional network still captures spatial and channel features to increase the receptive field, while attention-LSTM builds meaningful relationships from previous time series or crucial bytes. The encoded information is then passed to detector for generating forceful spatial-temporal attention features and enabling anomaly classification. In particular, single-frame and multi-frame models are constructed to present different advantages respectively. Under automatic hyper-parameter selection based on Bayesian optimization, the model is trained to attain the best performance. Extensive empirical studies based on a real-world vehicle attack dataset demonstrate that STC-IDS has outperformed baseline methods and obtains fewer false-alarm rates while maintaining efficiency.\n\nI. INTRODUCTION\n\nNowadays, a large number of electronic control units (ECUs) have replaced the mechanical control units to manage the assorted functions of in-vehicle control systems. The ECUs are interconnected to exchange varied vehicle information with each other via networks referred to as in-vehicle networks (IVNs) such as controller area networks (CAN) [1]. Along with local interconnected network LIN and FlexRay, CAN is well-known and most employed as the de-factor standard for IVNs [2], [3]. It is noteworthy that CAN was developed as a broadcast-based communication protocol that supports the maximum baud rate up to 1Mb per-second. Furthermore, the fault-tolerant detection mechanism guarantees the stability of message transmission.\n\nHowever, the CAN bus is potentially vulnerable to attacks owing to the lack of security mechanisms such as encryption, access control, and authentication [4], [5], [6]. Cyber security is becoming a major concern for IVNs systems as increasingly more security researchers demonstrate their ability to launch attacks on actual vehicles [7]. What can be investigated is various attacks have been threatening several significant components of IVNs [4], [8], [9]. For instance, 360 cyberattack Lab adopted electronic radio-frequency technology to successfully hack into Tesla in 2015 [10]. Miller et al. invaded the Jeep Cherokee's IVNs system using an open Wi-Fi port and reprogrammed the firmware of ECU. They succeeded in taking control of a wide range of vehicle functions (e.g., disabling the brakes and stopping the engine), triggering a recall of 1.4 million vehicles [4]. Thereafter, the electric features lift, warning lights, airbag, and tire pressure monitoring system (TPMS) have also become the target of attack [11]. Incredibly, these attacks have multiple ways of being performed. As such, the study on the security of IVNs is attracting significant attention from security researchers [12], [13].\n\nThere are many available methods that have the ability to protect IVNs secure, where IDS as an effective defense method has attracted more attention from researchers [14], [15]. Currently, a host of IDS schemes are rule-based and statistical-based. Although accuracy and efficiency are excellent about some common attacks, the passive characteristic and the constant need for updates result in a certain restriction [16]. With the increase in vehicle computing power and the maturity in machine learning (ML) technology, they promote the further development of IDS [17]. Real-time, higher detection, and lower false-positive rates have been a fervent research problem for deep learning-based in-vehicle IDS. Simultaneously, inadequate feature extraction, complex network structure, and more parameters, also are pending breakthroughs [1], [18]. To address such limitations, variants of IDS based on deep learning have been proposed in recent years [1], [19], [20]. However, these variants merely consider the partial features, either time-series of CAN ID or CAN data field. Moreover, spatial-temporal correlation features have been shown to better capture the details of the message in anomaly detection [21], [22], [23], whereas how to create represent the relationship between spatial-temporal features becomes a vital concern to elevate detection performance in the automotive intrusion [24], [25].\n\nThus, the purpose of this paper is to provide STC-IDS (Spatial-Temporal Correlation Features Analyzing basedenhanced Intrusion Detection System). Based on an encodingdetection architecture, the intuition first trained a boosted convolutional LSTM parallel feature extraction model. Improved attention-based LSTM network (A-LSTM) captures the temporal features and builds important relationships from previous sequences or crucial bytes. Meanwhile, a reduced VGGNet network can learn the spatial features from CAN frames. Moreover, the attention convolutional block (A-Conv2D) enables attaining a broad perspective through multi-channel features to refine feature mapping.Unlike many previous methods, it can concentrate more on changes in crucial areas and ignore bytes that are regular and unchanging. Afterward, spatialtemporal correlations between features are established to feed into the detector as a two-class classification problem. Note that both single-frame and multi-frame models are considered in this paper to present different advantages respectively. This paper makes the following contributions.\n\n1) Based on analyzing spatial-temporal correlation features of CAN messages in detail, we propose an enhanced convolutional LSTM spatial-temporal feature encoder with attention. The single-frame model automatically captures the important byte relationships of each CAN frame and uses convolutional components to find where key bytes are. Moreover, the multi-frame model captures significant relationships from previous time series, in which the attention convolutional block, assisted by spatial attention and channel attention, is able to snap changes in crucial areas. 2) Further, the detector achieves anomaly detection for the constructed representative spatial-temporal correlation features after multi-view learning. We evaluated the detection performance of our scheme using a publicly available real vehicle CAN dataset. We also compare it with the baseline model and show a significant improvement in detection performance and a reduction in false-positive rates and error rates. 3) By performing the injection attack in the same way, we calculated the detection efficiency of the model on real vehicles. The multi-frame model has sufficient ability to satisfy real-time detection. In addition, the single-frame model combined with database retrieval has the ability to trace anomalous ECUs.\n\nThe rest of this paper is organized as follows. Section II presents a discussion of related work on CAN-based IDS. Section III introduces the CAN bus protocol, vulnerability, and analyzes the CAN frame with spatial-temporal. Section IV proposes the parallel network model based on spatial-temporal features analysis. The experiment result of the proposed model on the public real-vehicle dataset is described in Section V.\n\nFinally, we conclude this study and look ahead at in-vehicle IDS potential perspectives.\n\n\nII. RELATED WORK\n\nIn this section, we provide an in-depth discussion about the research situation in anomaly detection and intrusion detection for in-vehicle CAN communication systems. They are divided into four categories, namely specification-based, fingerprint-based, statistical-based and machine learning-based approaches, as summarized in Table I.\n\n\nA. Intrusion detection model based on specification\n\nThe specification-based IDS focuses on defining system specifications, such as protocols and frame formats. When packets mismatch the system specification, an exception alarm is raised. In 2016, Dagan et al. [27] introduced an antispoofing system that detects malicious messages using each ECU, i.e., by detecting CAN message ID that was not sent by the ECU itself. Thereafter, the ECU informs the IDS, and then an interrupt pulse is sent to the CAN bus to overwrite the spoofed message. However, each ECU undertakes the IDS role, which increases a certain burden on communication.\n\nIn 2018, Studnia et al. [26] presented a signature-based IDS which utilize a list of signature derived from CAN dataset. However, this method is subject to the limitation that the length of the CAN bus words may not be known a priori. Recently, Olufowobi et al. [20] proposed a real-time IDS based on specification. The algorithm extracted the timing model to detect anomalies through observing CAN traffic rather than depending on predefined specifications, yet exhibited relatively poor performance in the real attack dataset.\n\n\nB. Intrusion detection model based on fingerprint\n\nThe fingerprint-based approaches are mainly based on profiles defined by ECU characteristics to implement anomaly detection. In 2016, Cho and Shin [28] proposed clock-based IDS to analyze ECUs periodic frequency. The method established the ECUs clock baseline through the recursive least squares algorithm (RLS) to detect intrusion. But it workable only to periodic messages excluding non-periodic messages.\n\nInterestingly, Cho et al. [29] found a method to establish the electrical signal characteristics of each ECU using the physical layer data of CAN communication, and harness these signal characteristics as the fingerprint for each ECU. Regrettably, the electrical characteristics may change as the vehicle ages, and thus the IDS needs to keep updating.\n\n\nC. Intrusion detection model based on statistical\n\nUnlike previous methods, the statistics-based approach implements anomaly detection by means of statistical information obtained from CAN traffic at the network level. Song et al. [30] introduced a lightweight IDS in 2016 that detected anomalies by monitoring the abnormally shortened intervals between messages. Although the proposed algorithm could have highly sensitive to common injection attacks and low computing cost, it cannot detect irregular incoming messages. Furthermore, Young et al. [31] comprehensively analyzed the frequency characteristics of CAN messages in various driving modes, such as reverse, acceleration and hold speed, and then proposed a frequency-based intrusion detection system. In spite of the high detection accuracy, there is a high false alarm rate. Manifestly, an IDS based on conditional statistical relationship analysis to learn the normal behavior of the system can detect manipulations and incorrect payload values [37], but still does not satisfy the high detection rate and low latency required by present-day IVNs for anomalous traffic [38].\n\n\nD. Intrusion detection model based on deep learning\n\nMachine learning (ML) and Deep learning (DL) based intrusion detection systems are an excellent option for extracting and learning normal or abnormal behavior, which provide models with detect and predict ability [39], [40]. Kang et al. [32] constructed a deep confidence network under unsupervised learning to detect if anomalies deviate from normal. However, inefficient and only validation of simulation data is not sufficient.\n\nIn 2019, Pawelec et al. [35] proposed a 3-layer LSTM neural network to predict the data payload for each CAN ID, which avoided reverse engineering proprietary encoding. Similarly, Qin et al. [19] also implemented anomaly detection for CAN bus based on timing features by LSTM and re-considered two data formats of CAN frames. Although these methods are implemented at the CAN bits level, they only consider timing characteristics and have relatively poor detection performance. Recently, convolutional neural network (CNN) have been implemented for traffic detection and praised for their high detection efficiency [41].\n\nSong et al. [36] presented a reduced inception residual network to construct an IDS capable of detecting spoofing and denial of service (DoS) attacks in a continuous pattern of vehicular traffic. Since the assistance of spatial-temporal relation is not taken into account, there is still room for improvement in the false positive rate. In other studies, Tariq et al. [34] introduced a convolutional LSTM-based intrusion detection method. Although it displayed excellent detection performance in unknown attack than transfer learning, known attacks performance relatively worse that may be caused by the relevance of the CAN message features being discarded. Moreover, a multi-tiered hybrid IDS that incorporates a signaturebased IDS and an anomaly-based IDS is proposed to detect both known and unknown attacks on vehicular networks by Yang et al. [33] in 2021. Their model has been proven that is effective for attacks on both in-vehicle and external networks. However, modeling with spatial-temporal features might take performance a step further.\n\nHowever, these ML&DL-based methods have different in selecting the detection domain, typically the detection arbitration domain, the detection data domain, and the similar to our work that the spatial-temporal feature extraction. In a nutshell, traditional methods based on specification, fingerprint, and statistical, have limitations in terms of reliance on anomaly feature libraries, message frequency, message time domain, and fingerprint information. Instead, it is imperative in the ML&DL area to improve automotive IDS detection performance and reduce false positives by complementing spatial-temporal features in a limited message communication mode. Furthermore, the model trained with limited spatialtemporal features will not effectively improve the detection performance.\n\nConsidering the nature of attention mechanisms to capture essential features, the generation of spatial-temporal attention features is one of the potential ways to address the above problem [42]. Hence, modeling the normal behavior of CAN packets in combination with spatial-temporal attention features and then discovering the difference between anomalies and target traffic is still one of the ways to improve in-vehicle IDS.\n\n\nIII. AN IN-DEPTH OVERVIEW OF CAN BUS DATASET A. Vulnerabilities of in-vehicle networks\n\nIntelligent Connected Vehicles (ICVs), integrating modern computing and communication technologies, is designed to improve user experience and driving safety. As the most significant communication medium, the CAN is the most prevalent bus topology network employed in contemporary vehicles owing to its low cost and complexity, high reliability, and fault-tolerance characteristics [43], [44]. All ECUs, connected to the CAN bus, are capable of exchanging messages in the form of data frames [45], [46]. Fig 1 presents the structure of a CAN message, consisting of seven fields [47]: 1) start of frame (1 bit); 2) arbitration field (12 bits for standard frames, 29 bits for extended frames); 3) control field (6 bits); 4) data field (Maximally 8 bytes); 5) cyclic redundancy code (CRC) field; 6) acknowledge (ACK) field; and 7) end of frame.\n\nIn the entire CAN frame, the most important is the arbitration field and the data field, as the arbitration field determines the priority of the message [48], shown in Fig 2(a); the data field contains the actual transmitted data that defines the node actions. Moreover, if an error is detected by CRC field, the receiving node will discard the received error message, while the sending node will only assume a transient fault on the bus and enter arbitration to resend the message frame [49], [50], shown in Fig 2(b). To guarantee the system consistency, the ECU broadcasts messages at regular intervals in spite of the data values have not changed. However, security problems were poor-needy thought out at the beginning of the CAN bus design [51], including its broadcast transmission strategy, lack of authentication and encryption, and unsecured priority scheme. Hence, many network traffic injection attacks are possible. This directly motivates the adversary to attack in-vehicle networks in a variety of ways, as shown in Fig 3. Clearly, the adversary can not only through the OBD-II port for physical attacks but also implement a remote attack easily (e.g., Wi-Fi or Bluetooth) [10]. Types of such attacks include flooding the bus with messages designed to circumvent legitimate messages or using spoofed bus identifiers with invalid information [36]. Furthermore, there are more sophisticated and stealthy attacks [52]. These attacks appear to be legitimate traffic sequences that are tough to distinguish from normal messages [1].\nTime(t) 0x2a0 0x43f CAN\nOnce the attacker has successfully compromised, it has the opportunity to forge ECU nodes and take control of incumbent nodes to inject nefarious messages [53], [54]. In the CAN protocol, the connected nodes are synchronized with the current vehicle state by accepting the data field bits of the frame [36]. Consequently, in order to successfully deceive the ECU, the adversary must insert tampering messages in a high frequency and priority manner by following the target CAN ID message immediately after the message [55]. If the attacker injects a high-priority CAN frame, where the data field is populated with a status command to turn off the \"wiper\", the driver loses judgment and even serious traffic accidents in rainy conditions while driving at high speed [56].  B. Spatial-temporal correlation feature analyzing for CAN dataset\n\nIn this paper, we utilized car-hacking dataset which is published by Song et al. [52]. This data set is injected with four attacks, respectively DoS attack, fuzzy attack, spoofing attack including RPM and GEAR, as illustrated in  Table II indicates the number of normal and injected messages in each attack dataset. In order to summarize the spatialtemporal details of normal CAN bus traffic during the operation of a real vehicle, we first investigated the communication patterns of different CAN IDs. Since the dataset is not publicly available as to the receiving sender and receiver of the data, the paper analyzes the CAN protocol table of a brand from our laboratory. We find that an ECU has a fixed set of CAN IDs (e.g. EMS, containing 0x101, 0x278, 0x281) and that the recipients of the different CAN IDs are also fixed (e.g. 0x101, containing TCU, ESP, EPB, T-BOX). This is the initial purpose to design a single-frame detection model capable of tracking unauthorized ECUs and protecting non-attacked ECUs.\n\nAdditionally, the frequency of the different IDs is fixed by the vehicle manufacturer. It is worth noting that important automotive components have a higher priority. Hence, timeseries features are reflected in the ID of the CAN messages. Despite the fact that there are some event-triggered messages with variable frequency, the set of commands is also fixed. The details are shown in Table III.\n\nSpatial feature expression, especially the data field of the CAN frame, is most significant. Most new messages are generated at a steady rate over the period of data acquisition in the dataset. In this study, the spatial signature analysis was  0x101  EMS  10  TCU, ESP, EPB, T-BOX  0x278  EMS  10  TCU, GSM, ABS, ESP, EPS, EPB, PEPS  0x281  EMS  100  TCU, AC, ICU, HUD, T-BOX  0x1A0  TCU  10  EMS, GSM, ESP, EPB,   based on the data segment, and a single message often had a regular change in timing. We analyzed this and aggregated the messages of different periodic variation rules. Table IV displays some CAN message of different CAN IDs from the dataset, where the omissions represent same transferred bytes. We can observe that they have certain fixed byte constants (e.g., the first 7 bytes of ID=0x260), as well as fields that change more frequently (e.g., the third bytes of ID=0x316), but only in a certain range. There are distinct spatial characteristics of the data field, useful for modeling the normal behavior of the CAN packet, and also inspire the requirement to design attention convolutional blocks.\n\nTo more visually observe the byte change patterns, the data fields for each message are displayed in a heat map, as shown in Fig 5. In order to apparently visualize the differences in variation of the each byte, this paper presents 100 consecutive communication messages based on three important CAN IDs such as gear and speed. There is a certain period of color shade variation at ID = 0x260 and ID = 0x43F, while the messages sent by the RPM-specific IDs are clearly irregular, corresponding to the summary in Table IV. In conclusion, spatial-temporal details are useful for modeling the normal behavior of CAN packets, and attention also focuses on bytes that change frequently and time-series important relationships, thus helping the model to quickly detect violations and determine the targeted traffic. \n\n\nA. Dataset preprocessing\n\nIt is impractical to train an IDS based on the neural network on the original CAN dataset, so data pre-processing is a necessary part before model training. The payload field is 8 bytes as shown in Table IV, where each byte is represented by two numbers in hexadecimal format. In fact, the public source dataset was progressively judged and found to contain a large number of data frames that were inferior to 8 bytes or irregular. To ensure uniformity of model input, we filled in the missing data frames with \"00\" in two scenarios: 1) where the data frame is less than 8 bytes; 2) where only the single digit \"0\" is used to represent a byte. Afterward, we split and transformed the arbitration bits and data domain in the dataset into a trainable dataset containing 19 features, respectively 16 features in 8 bytes of the data domain. In particular, the CAN ID is partitioned into 3 bits in order to harmonize the operation with the split data field. On the one hands, the combination of hexadecimal features of the original multi-bit will not be too far removed from the data field features due to the introduction of temporal-frequency features; on the other hand, all messages provided by the public dataset have only 3 valid bits in hexadecimal.\n\nIn addition, the values of all features are converted to decimal from hexadecimal. After implementing missing data padding and decimal conversion to meet the basic inputs for the model, several additional data pre-processing steps still need to be completed. First, the CAN frame type is encoded using a label encoder, which is used to convert categorical features into numerical features owing to many ML&DLbased algorithms cannot directly support string features [33]. Thereafter, the network dataset is normalized by the Min-Max algorithm, as the features collected in network traffic data often have a wide range of differences that impose model deviations and emphasize only large-scale features. Furthermore, the ML&DL-based model is proven to perform more convergent easily on normalized dataset [57], [58]. Hence, the data normalization by the Min-Max method is calculated as:\nX norm = X \u2212 X min X max \u2212 X min(1)\nThe method implements equal scaling of the original data, where X norm is the normalized data, X is the original data, and X max and X min are the maximum and minimum values of the original dateset respectively.   In addition, the first two rows represent the distribution for normal CAN data features, while the distribution for injection attacks is the third row. For multi-frame detection, encoder requires an additional image conversion step that splits the collected data set into 64 \u00d7 19 2-D images. After the normalization completing, in order to prevent the same attacks from appearing in both the test and the segmented attack data, dataset division is for 10-fold cross-validation via StratifiedKFold function in sklearn library.\n\n\nB. STC-IDS model design\n\nThe STC-IDS consists of two steps: encoding and detection, respectively. The encoder is an analysis of the spatialtemporal characteristics of the CAN messages, and capturing the important relationships based on attention to it; the detector achieves anomaly classification to the valuable spatialtemporal features.\n\n1) STC-IDS for single-frame detection: From the perspective of single-frame intrusion detection, our aim is to retrieve the illegally controlled source ECU in conjunction with the CAN ID (i.e., accurate identification of every abnormal traffic). In training phase, we extract spatial features at onedimensional data by CNN. Since the input of the proposed model is defined as 1 \u00d7 19, the spatial component extracts valuable features only through three convolutional blocks and a global pooling layer in order to avoid invalidating features because of the deeper network. Each convolutional block consists of a 1-D convolutional layer, a batch-normalization layer, and an activation function ReLU. The batch-normalization allows the model to discard the learning of biases, and make the convolutional output of the model homogeneous particularly. The ReLU function makes the network realize nonlinear feature mapping, while the global pooling serves to assist the model in searching for where critical bytes are and reducing redundant information.\n\nAttention actually mimics a visual mechanism of the human brain, seen as an automatic weighting scheme [42]. Hence, an improved LSTM structure with the attention mechanism (A-LSTM) is designed as a temporal component. We recognize the input as a multivariate time series with a single time step that is initially handled by the dimensional shuffling layer to increase the multivariate processing speed. When the features Algorithm 1 STC-IDS for single-frame 1: Require: Input Data X, LSTM-Times = 2, Convolutional-Times = 3; 2: Temporal Phase: 3: X temporal = Dimension shuffle(X); 4: for Times to LSTM-Times do 5: h b = LSTM(X temporal ); 6:\nu b = tanh (W w h b + b w ); 7: a b = exp u T b * u w / b exp u T b * u w ; 8: v = t a b * h b ;\n9:\n\nX temporal = Dropout(v); 10: end for 11: Spatial Phase: 12: X spatial = X; 13: for Times to Convolutional-Times do X spatial = X 18: end for 19: X spatial = Global-Pooling(X spatial ) 20: X spatial-temporal = Concatenate(X spatial ,X temporal ) 21: X spatial-temporal = Dense(X spatial-temporal ) 22:\u0177 = Softmax(X spatial-temporal ) are fed into the A-LSTM blocks, it can mine significant temporal features. To prevent over-fitting, the discard layer plays a crucial role. Overall, the A-LSTM component could discover crucial byte changes, calculated as:\na b = exp u T b * u w / b exp u T b * u w(2)\nWhere u w is the weight matrix, and u b means the implicit representation of the hidden state h b at computation feature bit b. The u b is calculated as:\nu b = tanh (W w h b + b w )(3)\nWhere W w is the weight matrix and b w is the bias. Afterward, we attain the attention probability distribution value at each byte. Finally, the final feature vector v is calculated as:\nv = b a b * h b(4)\nIn Fig Fig.6, we present a parallel feature extraction classification model for single-frame detection. Both features are finally aggregated by the fully connected layers. We refer to it as the CAN valuable feature for spatial-temporal correlation under multi-view learning. Finally, it is fed into the final classification component, which specific elaboration in algorithm 1.\n\n2) STC-IDS for multi-frame detection: To further elevate the efficiency, multi-frame based IDS is constructed. In other words, the model retrieves a continuous CAN 2-D matrix, aggregated from 64 consecutive CAN messages during data pre-processing. The matrix height 64 represents the length of historical time series that the model could recall. For supervised learning, 2-D data frames that contain one or more injection messages are marked as attack CAN instance, while data frames that do not contain injection messages are marked as normal CAN instance.\n\nAs shown in Fig 7, the 2-D data frames are fed into the parallel networks. For the temporal feature extraction component, we remains the structure as same as the single-frame model, but the model input is a time series in 2-D so that A-LSTM can pay more attention to important relationships from previous time series. After the dimensional shuffling layer swap out the time dimension of the time series, the processed time-series are fed into the A-LSTM blocks. However, the three main parameters in the single-frame temporal attention model, i.e. u b ,h b ,a b , need to be redefined as u t , h t , a t . u t indicates the implicit representation of the hidden state h t at computation time t, while a t represents the final computed attention value.\n\nMoreover, the spatial feature extraction component is inspired by the VGGNet model. we keep feature extraction capability of the model, but modify the number of convolutional layers and channel to adapt CAN dataset. It is composed of three convolutional blocks, where a convolutional module consists of a 2-D convolutional layer, a batch normalization layer, and a max-pooling layer.\n\nSince the convolutional layer has the feature of shared weight, the proposed model reduce the complexity and improve the inference efficiency. For instance, if a 64 \u00d7 19 \u00d7 3 feature is mapped into a 62\u00d717\u00d76 volume, the full-connected layer requires (64 \u00d7 19 \u00d7 3) \u00d7 (62 \u00d7 17 \u00d7 6) = 22M weights, while the convolutional layer via 3 \u00d7 3 convolutional kernels only require (3 \u00d7 3 \u00d7 3) \u00d7 6 = 162 weights. Fig 8 illustrates the difference between convolutional and fully connected layer computations. The multi-frame detection also has the capability to remove redundant information, and reduce the computational effort with the help of max-pooling layer. The convolutional block maps the raw data to the hidden feature space, thereby performing the task of feature engineering to improve the performance of the spatial component. The fully connected layer serves to map the learned \"distributed feature representation\" to the sample markup space. Hence, spatial-temporal correlation features are extracted in a parallel network, and then aggregated by a fully connected layer to finish the classification task.\n\nMost importantly, the second convolutional component is enhanced with visual attention mechanism, called A-Conv2D. The core idea of the component is to help the network extract and represent the information most relevant to the target. For instance, we usually focus on significant information when viewing a photograph, and summarize it. Observing Table II and the heat map in Fig 5, there are clearly crucial information changes in the bytes as a 2-D data frames. Recently, channel and spatial attention are mentioned in the CNN [59]. Inspired by the idea, the proposed structure integrates such ways, which can assist the model to find where the key information is and where the channel features are learned. The mode has the capability to self-select important features and eliminate the feature engineering step. Hence, convolutional branches of the intermediate layer can obtain a convolutional feature with spatial attention and channel attention. This additional structure is essentially cascaded over the original network with the purpose of better extracting valuable features. In summary, attention convolutional module features are calculated as follows:\nF merge = M s (F c ) \u2297 F c = M s (M c (F ) \u2297 F ) \u2297 (M c (F ) \u2297 F )(5)\nwhere F merge is the aggregated feature. M c , M s are channel attention weight coefficients and spatial attention wight coefficients, respectively, while F is the input feature and F c is the channel attention feature. In Fig 9, the feature maps built by the first convolution block are extracted deep features and attention coefficients through the attention convolution component. Initially, the max-pooling and avg-pooling layers aggregate spatial attention information to generate two different spatial context descriptions. Immediately afterward, the two features are added together by the multi-layer perceptron (MLP). Note that the MLP is weightsharing to realize information sharing. Finally, the weight coefficients M c are obtained through the sigmoid activation function, which is calculated as:\nM c = \u03c3(MLP(AvgPool(F)) + M LP ( MaxPool (F))) = \u03c3 W 1 W 0 F c avg + W 1 ( W 0 ( F c max ))(6)\nAfter getting the weight coefficients M c , the channel attention features F c is calculated as follows:\nF c = M c (F ) \u2297 F(7)\nwhere \u03c3 is the activation function, W 0 and W 1 are the weight matrices of the convergence layer. The spatial attention module is a stable complement to channel attention information because of its ability to mine where the key features are. Similarly, given an H \u00d7 W \u00d7 C feature F c , two H\u00d7W \u00d71 channel descriptions are obtained by averaging pooling and max pooling in one channel dimension, respectively. Thereafter, the channel descriptions are stitched together based on the channel. Finally, a 2 \u00d7 2 convolutional layer with sigmoid activation function is applied to obtain the weight coefficients M s , which calculated as follows:\nM s = \u03c3 f 2\u00d72 ([AvgPool (F c ) ; MaxPool (F c )]) = \u03c3 f 2\u00d72 F s avg ; F s max(8)\nWhere the f 2\u00d72 (\u00b7) represents convolutional computation, F s avg and F s max represent two channel descriptions, respectively. Thus, the spatial-channel attention aggregation feature F merge is obtained by multiplying the weight coefficients M s with the feature F c . The feature F merge is continued calculated by the normal convolutional component, and then aggregated with the temporal feature to build the spatial-temporal features. The fully connected layer maps the spatial-temporal feature to sample markup space to finish the two-class classification task. Specifically, the multi-frame model is described in algorithm 2\n\n3) Classification loss: For the intrusion detection based on classification, the loss value can be obtained according to the comparison between the prediction label and the actual label. Based on this loss message, the loss calculation method are used for the two data formats as discriminant mark for detection. Hence, the predict values\u0177 i are calculated as follows.\u0177  Fig. 8: In the computation of neurons in the convolutional and fully connected layers, it is clear that the former is smaller than the latter, due to the dense connectivity.\ni = p(c = i | x) = softmax (w \u00b7 f x + b) ( for i = 0, 1)(\nWhere f x is the combining features, and\u0177 i present the probability distribution over target classes zero and one. With the fusion of two structures, the model becomes more complex generating over-fit phenomena easily. For better generalization of the model, L2 regularization is set in the network layer to limit the gradient. Besides, we need to continuously optimize by back propagation to reduce loss value, and fit the model to the best structure, in order to maximize the predicted probability p. The loss function is calculated as follows.\nL = 1 N i L i + \u03bb w 2 = 1 N i \u2212 [y i \u00b7 log (p i ) + (1 \u2212 y i ) \u00b7 log (1 \u2212 p i )] + \u03bb w 2(10)\n\nV. EVALUATION\n\nWe now validate that the spatial-temporal correlation feature can be used to detect anomaly frames, and evaluate the performance of a CAN bus prototype and real vehicles.\n\n\nA. Evaluation Metrics and Experiment Environment\n\nIn this paper, statistical metrics TP (true positive) and TN (true negative) are introduced to indicate the number of frames correctly classified as attack and normal, while metrics FP (false positive) and FN (false negative) are introduced to indicate the number of data frames that are misclassified as attack and normal. The model accuracy formula is as follows.\nAcc = (T P + T N )/(T P + F N + F P + T N )(11)\nPrecision (P) and recall (R) are considered as evaluation metrics to assess classification performance. Precision refers to the rate at which the actual data frame labels are detected correctly, while recall represents the proportion of all attack frame samples that end up in the attack frame class, which are calculated as follows.\nP = T P/(T P + F P )(12)\nand R = T P/(T P + F N )\n\nThe F1 score evaluation is also presented, which is a harmonic average based on the detection precision and completeness. Also, the F1 score is often used to measure classification performance when the data are unevenly distributed, which is calculated as follows. \nF 1 = 2 \u00d7 P \u00d7 R/(P + R)(14)\nAdditionally, the false negative rate (FNR) and the error rate (ER) are one way of assessing classification performance. The FNR is the proportion of frames that are not detected as belonging to the attack frame and the ER is the proportion of frames that are incorrectly classified, calculated as follows.\nF N R = F N/(T P + F N )(15)\nand ER = (F N + F P )/(T N + T P + F N + F P )\n\nThe two models designed in this paper were trained offline based on the dataset, while the testing phase was based on real vehicles, injected with malicious frames of the same rules, to check the performance and efficiency of the models. The following is the experimental training and testing environment. \n\n\nB. Hyperparameter Selection and Optimization\n\nThe selection of hyperparameters is a crucial step in network performance and inference efficiency. Currently, automated hyperparametric optimization (HPO) services and tool-kits address the constant trial-and-error steps of deep learning developers [60]. In this paper, bayesian optimization (BO) automatic parametric tuning is used in order to quickly determine hyperparameters. It is a typical method applied to global optimization problems. Compared to grid search and stochastic search, BO is more computationally efficient and requires fewer attempts to find the optimal set of hyperparameters [57]. Based on the BO optimization library provided by Kerastuner and on a 10-fold cross-validation dataset, we selected important hyperparameters such as learning rate (1e-2, 1e-3, 1e-4, 1e-5, 1e-6), optimizer (e.g., Adam, SGD, RMSprop), dropout rate, and filters. Afterward, we set the optimization goal to validate the accuracy (Val-Acc), a maximum number of trials of 10, and train the model 3 times per trial. Finally, the optimization results will present the set of top 3 hyperparameters for performance.\n\nAs shown in Table VI, the average accuracy on the crossvalidation set reaches 99.98% in the single-frame model when setting the learning rate is 1e-6, the dropout rate is 0.4, the filters are 16, 32, 128, the dense layer is 64, and the optimizer is Adam. Similarly, the accuracy is achieved up to 99.96% to the multi-frame model under the optimal hyperparameters.\n\nInterestingly, the inference speed of the model was sig-Algorithm 2 STC-IDS for multi-frame 1: Require: Input Data X, LSTM-Times = 2, Convolution-Times = 3; 2: Temporal Phase: 3: X temporal = Dimension shuffle(X); 4: for Times to LSTM-Times do 5: h t = LSTM(X temporal ); 6: \nu t = tanh (W w h t + b w ); 7: a t = exp u T t * u w / t exp u T t * u w ; 8: v = t a t * h t ;\n9:\n\nX temporal = Dropout(v); 10: end for 11: Spatial Phase: 12: X spatial = X; 13: for Times to Convolution-Times do end if 27: end for 28: X spatial = Dense(X spatial ) 29: X spatial-temporal = Concatenate(X spatial ,X temporal ) 30: X spatial-temporal = Dense(X spatial-temporal ) 31:\u0177 = Softmax(X spatial-temporal ) nificantly accelerated aided by the optimal hyperparameters. Despite the higher detection performance was obtained by the single-frame model, the inference speed is slower. Relative to multi-frame, it took 50 iterations to converge, whereas the multi-frame model only took 30 generations. Fig 10 shows the iterative training losses for each dataset. It can be observed that since the DoS attack disrupts the frequency of injection, both models learn the patterns and converge quickly. However, as the complexity of attack data increases, the fuzzy and spoofing attacks injected with random data converge slower in the single-frame model, while the training loss convergence fluctuates significantly in the multi-frame model.\n\n\nC. Detection Metrics Evaluation and Comparison\n\nAfter training the best two models according to the set hyperparameters, Fig 11 shows the detection performance of the models in terms of ER and FNR for the four-attack testing sets in 30 repeated experiments. The two proposed models, both in terms of FNR, and ER, presents stable performance to detect DoS attacks with mean values of 0.0047%, 0.0204%, 0.0159% and 0.0094%, respectively. On the contrary, the fuzzy attacks shows greater fluctuations in detection performance. The complexity of fuzzy attack data seems to be significantly higher than the other injected data, necessitating more training iterations to construct a stable model. Hence, the ultimate mean values of FNR are still 0.0328% and 0.0413%, as well as ER get 0.0435% and 0.0864%.\n\nAlthough FNR and ER on spoofing attacks are higher than DoS attacks, they achieve stable and better results compared to fuzzy attacks. The single-frame detector averages 0.0251% and 0.0353% for the Gear attack on both metrics, while the multi-frame detector obtains 0.0294% and 0.0704%. Similarly, the performance of both models is similar to Gear attacks when detecting RPM attacks. Notably, the single-frame detection model requires mining the characteristics of different CAN packets, thus exhibiting fluctuations in FNR and ER values that are greater than the multi-frame model. Despite the multiframe model with better detection efficiency, it has a higher false alarm rate than the former.\n\nTo reflect the advantages of our model, Table VII lists the detection performance of STC-IDS when compared to those of the other machine-learning techniques, where the highest performance values are highlighted in bold, and \"-\" only means that the scheme has not been tested on this metric. The results indicate clearly that the STC-IDS model outperforms the previous methods on all datasets. The false negative rate and error rate are significantly reduced. It can be seen that the model captures spatial-temporal details of network traffic remarkably well and enhances the anomaly detection ability satisfactorily.\n\nEvidently, we can observe that the STC-IDS for singleframe model achieves a stable precision (99.97%), a higher recall (99.96%), and an outstanding F1-score (99.96%) in average as compared to a threshold (OTIDS), classification (DCNN), prediction (3-LSTM), and clustering (DAE) based models. In contrast, the performance solely decreases by an average of 0.04% precision, 0.01% recall, and 0.03% in the F1score while maintaining efficiency in the multi-frame model.\n\nThe 3-LSTM scheme shows high accuracy and unstable recall because of the unconsidered spatial correlation, resulting in a low F1 score and a large gap between FNR and ER with our scheme and DCNN. DCNN is currently one of the best models for in-vehicle intrusion detection, but the stacking of convolutions is ineffective in capturing the temporal relationships of the inputs. As a result, the single-frame model reduces the FNR and ER by 90% and 33% over the DCNN scheme for DoS attacks, while the multi-frame model reduces the FNR by 80% and the ER by 66%. More notably, for complex Compared to the DAE model with a lack of labeling constraints, the proposed model has larger improvements in detection performance, while DAE only reaches 95.36% in F1score on DoS attacks, and obtains lower performance on other attacks. Similarly, the OTIDS exhibited a high accuracy rate and extremely low recall, resulting in an FNR of over 25%, reflecting a relatively low F1-score. Thus, the robust spatialtemporal correlation feature demonstrates sufficient benefits in terms of improving detection performance and reducing the false alarm rate.\n\n\nD. Time Cost in Real Vehicle\n\nThis work first implemented single frame detection in terms of security considerations. Although the performance is improved over previous algorithms, the efficiency is not guaranteed. Besides, time and resources are the major limitations to applying deep learning models to real-world vehicle IDS. Therefore, STC-IDS based on multi-frames also was proposed. Obviously, significant improvements were made in terms of model convergence time as shown in subsection V-B. To test the efficiency of proposed model a resource-constrained invehicle network, the model was tested on an in-vehicle class device the NVIDIA Jetson AGX Xavier. Note that only 4GB of video memory was allocated for testing. The CAN Test software injected the attack traffic by connecting to the OBD-II port, as shown in Fig 12. In Fig 13,   For example, 256 batch shows 0.54 ms time cost, which is superior to DCNN [36] and MTH-IDS [33]. Moreover, this truly indicates that the model is constantly learning as it reasoned, thus making it easier to catch malicious features later on. However, it can be estimated that the model can detect 1851 messages in 1s at the fastest detection time cost, while CAN frames transmit approximately 2000 messages in 1s. One limitation of this method is that they do not usually satisfy real-time detection.  To overcome this limitation, the multi-frame model presents prominent advantages that just need the average time cost of 0.09 ms, 0.09 ms, and 0.074 ms for three batches, respectively. Compared testing time of the previous models as listed in Fig 13, the proposed model not only present outstanding performance, but also improves about 5 times in terms of efficiency. This means that the model can infer about five times the number of CAN transmission messages in 1s. Hence, the proposed model has the feasibility for real-time detection. Unlike the DCNN [36] model, a crucial phenomenon is that the proposed model does not depends on batch size. The same result reflects on 3-LSTM model [35] and MTH-IDS [33]. But even so, we also suggest a suitable batch size needs to be determined, as large batches may delay anomaly alert.\n\n\nE. Discussion and Limitations\n\nThe study presents two enhanced spatial-temporal features analyzing IDS for detecting single CAN messages and consecutive CAN frames based on open injection attack datasets. Experiments indicates that the single-frame model exhibits good detection performance. Similarly, the STC-IDS for multiframe improves efficiency while ensuring performance.\n\nAlthough the detection efficiency of the single-frame model is right limited, we believe that the model will be suitable for real-time detection when using higher-performance computing devices. In fact, it is necessary to track unauthorized ECUs in conjunction with CAN ID indexing in further in-vehicle security development based on single-frame detection. It is worth noting that the time-cost detection of proposed methods is based on in-vehicle edge computing and autonomous driving platform from our research group. Although it has satisfied the requirement for real-time intrusion detection when in a real environment, it has some impact when all tasks are performed simultaneously. Hence, more research still needs to develop in terms of practical implementation.\n\nClearly, the spatial-temporal feature modeling in this study is based on observing the CAN ID domain, data field, and communication protocol of the specific brand vehicles. The generality consequence of the proposed model is demonstrated due to the fixed time-interval, sender and receiver, despite different vehicle companies making distinct communication protocols. In other words, model transfer only needs to be retrained on the new brand vehicle, which also can extract valuable spatial-temporal features, and obtains excellent detection performance.\n\nMoreover, the division of CAN ID in the scheme is limited to public datasets. In order to accommodate more realistic invehicle messages, the division should be completed in practice by considering both standard frames (11 bits) and extended frames (29 bits). However, it is straightforward only to modify the dimensionality of the input for the proposed model. Most importantly, the model has a fundamental limitation in terms of detecting unlearned types of attacks as it is based on supervised learning. To address this challenge, more research is needed on unknown attack detection using models with generative functions such as adversarial training, or autoencoder.\n\n\nVI. CONCLUSIONS\n\nThis work focuses on learning the temporal and spatial characteristics of in-vehicle network traffic in order to establish enhanced spatial-temporal correlation features, and then build an automotive intrusion detection model. The proposed model is implemented based on the encode-detection architecture. The encoding layer is constructed as a parallel network in both temporal and spatial terms base on LSTM and CNN. The introduction of A-LSTM and A-Conv2D helps the model uncover important relationships between keyword node variation and temporal order. Spatial-temporal correlation features are fed into the detection layer to complete anomaly detection.\n\nBoth models achieve optimal hyperparameter selection with Bayesian optimization, reducing the number of iterations and elevating accuracy. Compared to previous schemes, our model achieves a better performance on open source dataset, i.e., DoS, Fuzzy, Gear, and RPM, especially in the FNR and ER metrics.\n\nAlthough this study achieves security protection of the CAN bus, there is still much room for improvement, especially unknown attack detection. In future work, we will consider how to express realistic unknown attack messages, improving model robustness and generalization capabilities. Data annotation also is a tedious task, but unsupervised algorithms are one of the solutions, which still need continuous research to improve performance.\n\nFig. 1 :\n1Structure of a CAN 2.0A message frame.\n\nFig. 4 :\n4Illustration of the injection process of utilized in-vehicle intrusion dataset.\n\nFig 4 .\n4The detailed injection rules are as follows.1) DoS attack: DoS attacks in the dataset are to inject a high priority message with a '0x000' CAN ID every 0.3 milliseconds, with the data field populated with 0. 2) Fuzzy attack: Fuzzy attacks in dataset are injected every 0.5 milliseconds with CAN messages where the CAN ID and DATA values are forged randomly. 3) Spoofing attack: Spoofing attacks in dataset are injected messages every 1 millisecond with a specific CAN ID, e.g., related to RPM/Gear.\n\nFig. 5 :\n5Value distribution by heatmap in hexadecimal form of each bit of CAN frame for different ID includes ID = 0x260, ID = 0x316, and ID=0x43F.IV. IDS USING SPATIAL-TEMPORAL CORRELATION FEATURE\n\n\nis available as model input, where the former three columns are the CAN ID feature fields, the next eight columns in each message present 16 data domain fields, and the last column represents the label in digital form for each message.\n\nFig. 6 :\n6To illustrate the single-frame detection neural network.\n\nFig. 9 :\n9Schematic representation of the CAN image computed in the attention convolution module. The channel module utilizes the shared network to output the max-pooling and avg-pooling computed features; the spatial attention module pools the pooling output along the channel axis and computes the final features through the convolution layer.\n\nFig. 10 :\n10To illustrate training loss on each dataset in singleframe (a) and multi-frame (b) algorithms.\n\nFig. 12 :\n12To illustrate the testing experiment environment. of different batches compared to previous algorithms. The average detection time for single-frame model remains under 0.7 ms. Although small-batch requires the highest time cost, the detection time is decreased based on the increasingly batch.\n\nFig. 13 :\n13Testing time of proposed models on different batches for each message compared to other algorithms.\n\nTABLE I :\nIComparison of in-vehicle intrusion detection systems.Categories \nResearch work \nTechnique \nEvaluation Data \nContribution \nLimitation \n\nSpecification \nbased \n\nStudnia et al. [26] \na list of signatures derived from \nCAN data set \nreal \nautomatically generating a set of \nforbidden sequences \n\nthe length of CAN bus words may \nnot be known a priori \n\nDagan et al. [27] \n\nan anti-spoofing system detects \nCAN message IDs by each ECU \nthat are not sent by the ECU itself \n\nreal \nand simulation \n\neffective resistance to spoofing \nattacks \n\neach ECU takes on the IDS role, \nadding a certain burden to com-\nmunication \n\nOlufowobi et al. [20] \nworst-case response time analysis \nreal \nand synthesized \n\nreal-time parameter estimation al-\ngorithm developed in a black-box \napproach \n\nhigh false positive rate and relatively \nlow performance on open dataset \n\nFingerprint \nbased \n\nCho and Shin [28] \nanalyzed the clock skew of ECUs \nreal \nand simulation \n\nproposed an ECU pro-filing meth-\nod according to electrical signal \ncharacteristics \n\nworkable only to periodic messages \nexcluding non-periodic messages \n\nChoi et al. [29] \n\nestablished the electrical signal \nfeatures of each ECU based on \ntime domain and frequency domain \n\nreal \nand simulation \n\neffective of making a distinction \nbetween ECU malfunctions and \na bus-off attack \n\nthe electrical properties of the veh-\nicle may change as it ages, necessit-\nating correction. \n\nStatistics \nbased \n\nSong et al. [30] \nanalyzed the time-intervals of the \nCAN messages \n\nreal \nand synthesized \n\noffered effectiveness of the me-\nthod for injection attack detection \n\nworkable only to periodic messages \nexcluding non-periodic messages \n\nYoung et al. [31] \nanalyzed the time-intervals in the \nfrequency domain \nreal \nimproved frequency-based inject-\nion attack detection method \n\nhigh false positive rate, and only \nidentify injection attack \n\nML & DL \nbased \n\nKang et al. [32] \ndeep belief network (DBN) \nsimulation \n\npresented unsupervised statistical \nfeature extraction algorithms for \nECU messages \n\nextremely time-consuming in the \ntraining phase, evaluation only based \non simulation data \n\nYang et al. [33] \nsignature-based and anomaly-based \nmulti-layer hybrid IDS \nreal \n\nproposed an IDS that is effective \nfor attacks on both in-vehicle and \nexternal networks \n\nspatial-temporal features and important \nregional features are ignored \n\nTariq et al. [34] \nconvolutional LSTM Network \nand transfer learning \nreal \nimproved performance of unknown \nattack detection \n\nknown attacks have poor relative de-\ntection performance \n\nPawelec et al. [35] \nLSTM prediction at the bit level \nreal \navoided reverse engineering \nproprietary encodings \nlimited attack detection range \n\nQin et al. [19] \nLSTM network and five loss \nfunction \nreal \npresented two predicted model on \ndifferent data format \nrelatively poor detection accuracy \n\nSong et al. [36] \ndeep CNN \nreal \n\nreduced Inception-resent model \ncomplexity to adapt IDS and im-\nprove detection performance \n\nthe spatial-temporal relationship \nof CAN frames is ignored \n\nSTC-IDS (Ours) \nparallel convolutional LSTM \nattention network \nreal \n\nimportant concerns for spatial-\ntemporal features and crucial \nfeatures \n\nmore unknown attacks are ignored \n\n\n\n\nbus Fig. 3: The scenario in which an attacker performs an injection attack can be a remote attack or a physical attack can be implemented.0x43f \n0x2a0 \n\nHigher priority to get the \nbus transmission right \n\nCAN bus \n\n0x43f \n\n0x43f \n\n0x43f \n\nt0 \n\nError frame \n\nResend \ndiscard \n\n(a) \n\n(b) \n\nECU A \n\nECU B \nECU B \n\nECU B \n\nECU A \n\nFig. 2: Conceptual diagram of the message priority and CRC \ndetection. \n\nLTE \n\nRemote Access \n\nPhysical Access \n\nSend Forged Packets \n\nCAN Bus \n\nECU A \n\nOBD-II \n\nTelematics \n\nECU B \nECU C \n\n\n\nTABLE II :\nIIOverview of car-hacking dataset Attack type Normal messages Injected messagesDoS attack \n3078250 \n587521 \nFuzzy attack \n3347013 \n491847 \nRPM attack \n2766522 \n597252 \nGear attack \n2290185 \n654897 \n\n\n\nTABLE III :\nIIIPartial ECU transmission, reception and time cycle of an automotive brandID \nTransmitter periods Receiver \n\n\n\nTABLE IV :\nIVAnalyzing range statistics of message frameID \nTransmitter 1 \n2 \n3 \n4 \n5 \n6 \n7 \n8 \n\n0x260 \nN/A \n05 22 00 30 FF 99 63 38 \n0B \n1A \n29 \n0x316 \nRPM \n05 22 6A 0B 21 18 00 7F \n22 16 \n22 \n23 3A \n23 \n24 1A \n24 \n0x43F \nGEAR \n10 50 60 FF 46 28 0A 00 \n0C \n10 \nF0 \n\n\n\n\nTable V presents the CAN\n\nTABLE\n\n\nTABLE VI :\nVIEffect of hyperparameters on model performance under automated HPOModel type \nLearning rate \nDropout rate \nFilters \nDense Optimizer Val-Acc \n\nSingle Frame \n\n1e-6 \n0.4 \n16,32,128 \n64 \nAdam \n0.9998 \n\n1e-6 \n0.4 \n8,96,32 \n48 \nAdam \n0.9935 \n1e-6 \n0.4 \n8,16,192 \n80 \nAdam \n0.9869 \n\nMulti Frame \n\n1e-2 \n0.4 \n64,16,32 \n128 \nAdam \n0.9996 \n\n1e-2 \n0 \n8,16,32 \n128 \nAdam \n0.9993 \n1e-2 \n0 \n24,80,96 \n256 \nAdam \n0.9992 \n\n\n\n\nFig. 11: Box-plots of single-frame and multi-frame models measuring FNR and ER in 30 replicate experiments.fuzzy attacks, only 0.04% FNR and 0.05% ER are achieved on the single-frame model. In addition, the FNR is slightly improved on the Gear and RPM dataset. Meanwhile, the ER gets approximate performance compared with the DCNN model.DoS \nFuzzy \nGear \nRPM \n\n0.00 \n\n0.02 \n\n0.04 \n\n0.06 \n\nFNR(%) \n\nfor \n\nSingle \n\nFrame \n\nDoS \nFuzzy \nGear \nRPM \n\n0.00 \n\n0.02 \n\n0.04 \n\n0.06 \n\nER(%) \n\nfor \n\nSingle \n\nFrame \n\nDoS \nFuzzy \nGear \nRPM \n\n0.02 \n\n0.03 \n\n0.04 \n\n0.05 \n\nFNR(%) \n\nfor \n\nMulti \n\nFrame \n\nDoS \nFuzzy \nGear \nRPM \n\n0.00 \n\n0.03 \n\n0.06 \n\n0.09 \n\n0.12 \n\nER(%) \n\nfor \n\nMulti \n\nFrame \n\n0.0047 \n\n0.0328 \n\n0.0251 \n0.0258 \n\n0.0159 \n\n0.0435 \n\n0.0353 \n0.0358 \n\n0.0204 \n\n0.0413 \n\n0.0294 \n0.0298 \n\n0.0094 \n\n0.0864 \n\n0.0704 \n0.0712 \n\n\n\n\nwe present that the proposed model has lower time (in milliseconds) cost on anomaly detection in case NVIDIA Jetson AGX Xavier CAN Test Software OBD-II CAN bus interface\n\nTABLE VII :\nVIIIDS performance comparsion with baseline methodsDoS \nER (%) \nFNR (%) \nP (%) R (%) F1 (%) \n\nSTC-IDS for Single Frame \n0.02 \n0.01 \n99.95 \n99.99 \n99.96 \nSTC-IDS for Multi Frame \n0.01 \n0.02 \n99.91 \n99.97 \n99.94 \n3-LSTM [35] \n0.07 \n0.22 \n1.0 \n99.78 \n99.88 \nDCNN [36] \n0.03 \n0.10 \n1.0 \n99.89 \n99.95 \nDAE [61] \n-\n0.12 \n91.27 \n99.88 \n95.36 \nOTIDS [62] \n-\n26.2 \n99.90 \n73.80 \n84.88 \n\nFuzzy \nER (%) \nFNR (%) \nP (%) R (%) F1 (%) \n\nSTC-IDS for Single Frame \n0.05 \n0.04 \n99.97 \n99.95 \n99.96 \nSTC-IDS for Multi Frame \n0.09 \n0.07 \n99.90 \n99.92 \n99.91 \n3-LSTM [35] \n0.84 \n0.65 \n99.36 \n99.16 \n99.26 \nDCNN [36] \n0.18 \n0.35 \n99.95 \n99.65 \n99.80 \nDAE [61] \n-\n3.74 \n90.05 \n96.26 \n93.05 \nOTIDS [62] \n-\n29.79 \n99.14 \n70.21 \n82.20 \n\nGear \nER (%) \nFNR (%) \nP (%) R (%) F1 (%) \n\nSTC-IDS for Single Frame \n0.04 \n0.03 \n99.97 \n99.96 \n99.97 \nSTC-IDS for Multi Frame \n0.07 \n0.03 \n99.94 \n99.96 \n99.95 \n3-LSTM [35] \n0.24 \n0.32 \n99.75 \n99.68 \n99.72 \nDCNN [36] \n0.05 \n0.11 \n99.99 \n99.89 \n99.94 \nDAE [61] \n-\n18.2 \n94.63 \n81.80 \n87.75 \nOTIDS [62] \n-\n28.35 \n99.83 \n71.65 \n83.42 \n\nRPM \nER (%) \nFNR (%) \nP (%) R (%) F1 (%) \n\nSTC-IDS for Single Frame \n0.04 \n0.03 \n99.98 \n99.96 \n99.97 \nSTC-IDS for Multi Frame \n0.07 \n0.03 \n99.95 \n99.96 \n99.96 \n3-LSTM [35] \n0.13 \n0.30 \n1 \n99.71 \n99.85 \nDCNN [36] \n0.03 \n0.05 \n99.99 \n99.94 \n99.96 \nDAE [61] \n-\n4.27 \n95.73 \n95.73 \n92.10 \nOTIDS [62] \n-\n28.32 \n99.81 \n71.68 \n83.43 \n\n\n\nSelf-supervised anomaly detection for invehicle network using noised pseudo normal data. H M Song, H K Kim, IEEE Transactions on Vehicular Technology. 702H. M. Song and H. K. Kim, \"Self-supervised anomaly detection for in- vehicle network using noised pseudo normal data,\" IEEE Transactions on Vehicular Technology, vol. 70, no. 2, pp. 1098-1108, 2021.\n\nA gateway system for an automotive system: Lin, can, and flexray. S.-H Kim, S.-H Seo, J.-H Kim, T.-M Moon, C.-W Son, S.-H Hwang, J W Jeon, 6th IEEE International Conference on Industrial Informatics. IEEES.-H. Kim, S.-H. Seo, J.-H. Kim, T.-M. Moon, C.-W. Son, S.-H. Hwang, and J. W. Jeon, \"A gateway system for an automotive system: Lin, can, and flexray,\" in 2008 6th IEEE International Conference on Industrial Informatics. IEEE, 2008, pp. 967-972.\n\nSecurity threats to automotive can networks-practical examples and selected short-term countermeasures. T Hoppe, S Kiltz, J Dittmann, Reliability Engineering & System Safety. 961T. Hoppe, S. Kiltz, and J. Dittmann, \"Security threats to automotive can networks-practical examples and selected short-term countermeasures,\" Reliability Engineering & System Safety, vol. 96, no. 1, pp. 11-25, 2011.\n\nRemote exploitation of an unaltered passenger vehicle. C Miller, C Valasek, Black Hat USA. 2015SC. Miller and C. Valasek, \"Remote exploitation of an unaltered passenger vehicle,\" Black Hat USA, vol. 2015, no. S 91, 2015.\n\nEfficient and secure outsourcing of differentially private data publishing with multiple evaluators. J Li, H Ye, T Li, W Wang, W Lou, Y T Hou, J Liu, R Lu, IEEE Transactions on Dependable and Secure Computing. 191J. Li, H. Ye, T. Li, W. Wang, W. Lou, Y. T. Hou, J. Liu, and R. Lu, \"Efficient and secure outsourcing of differentially private data publishing with multiple evaluators,\" IEEE Transactions on Dependable and Secure Computing, vol. 19, no. 1, pp. 67-76, 2022.\n\nMasencryption and its applications in privacy-preserving classifiers. C Gao, J Li, S Xia, K.-K R Choo, W Lou, C Dong, IEEE Transactions on Knowledge and Data Engineering. C. Gao, J. Li, S. Xia, K.-K. R. Choo, W. Lou, and C. Dong, \"Mas- encryption and its applications in privacy-preserving classifiers,\" IEEE Transactions on Knowledge and Data Engineering, 2020.\n\nEurus: towards an efficient searchable symmetric encryption with size pattern protection. Z Liu, Y Huang, X Song, B Li, J Li, Y Yuan, C Dong, IEEE Transactions on Dependable and Secure Computing. Z. Liu, Y. Huang, X. Song, B. Li, J. Li, Y. Yuan, and C. Dong, \"Eurus: towards an efficient searchable symmetric encryption with size pattern protection,\" IEEE Transactions on Dependable and Secure Computing, 2020.\n\nComprehensive experimental analyses of automotive attack surfaces. S Checkoway, D Mccoy, B Kantor, D Anderson, H Shacham, S Savage, K Koscher, A Czeskis, F Roesner, T Kohno, 20th USENIX security symposium. USENIX Security 11S. Checkoway, D. McCoy, B. Kantor, D. Anderson, H. Shacham, S. Sav- age, K. Koscher, A. Czeskis, F. Roesner, and T. Kohno, \"Comprehensive experimental analyses of automotive attack surfaces,\" in 20th USENIX security symposium (USENIX Security 11), 2011.\n\nPotential cyberattacks on automated vehicles. J Petit, S E Shladover, IEEE Transactions on Intelligent transportation systems. 162J. Petit and S. E. Shladover, \"Potential cyberattacks on automated vehi- cles,\" IEEE Transactions on Intelligent transportation systems, vol. 16, no. 2, pp. 546-556, 2014.\n\nCyberattacks and countermeasures for in-vehicle networks. E Aliwa, O Rana, C Perera, P Burnap, ACM Computing Surveys (CSUR). 541E. Aliwa, O. Rana, C. Perera, and P. Burnap, \"Cyberattacks and countermeasures for in-vehicle networks,\" ACM Computing Surveys (CSUR), vol. 54, no. 1, pp. 1-37, 2021.\n\nSecurity and privacy vulnerabilities of {In-Car} wireless networks: A tire pressure monitoring system case study. I Rouf, R Miller, H Mustafa, T Taylor, S Oh, W Xu, M Gruteser, W Trappe, I Seskar, 19th USENIX Security Symposium (USENIX Security 10). I. Rouf, R. Miller, H. Mustafa, T. Taylor, S. Oh, W. Xu, M. Gruteser, W. Trappe, and I. Seskar, \"Security and privacy vulnerabilities of {In- Car} wireless networks: A tire pressure monitoring system case study,\" in 19th USENIX Security Symposium (USENIX Security 10), 2010.\n\nSecure video retrieval using image query on an untrusted cloud. H Yan, M Chen, L Hu, C Jia, Applied Soft Computing. 97106782H. Yan, M. Chen, L. Hu, and C. Jia, \"Secure video retrieval using image query on an untrusted cloud,\" Applied Soft Computing, vol. 97, p. 106782, 2020.\n\nCamdar-adv: generating adversarial patches on 3d object. C Chen, T Huang, International Journal of Intelligent Systems. 363C. Chen and T. Huang, \"Camdar-adv: generating adversarial patches on 3d object,\" International Journal of Intelligent Systems, vol. 36, no. 3, pp. 1441-1453, 2021.\n\nA survey of intrusion detection for in-vehicle networks. W Wu, R Li, G Xie, J An, Y Bai, J Zhou, K Li, IEEE Transactions on Intelligent Transportation Systems. 213W. Wu, R. Li, G. Xie, J. An, Y. Bai, J. Zhou, and K. Li, \"A survey of intrusion detection for in-vehicle networks,\" IEEE Transactions on Intelligent Transportation Systems, vol. 21, no. 3, pp. 919-933, 2019.\n\nResource allocation in iot edge computing via concurrent federated reinforcement learning. Z Tianqing, W Zhou, D Ye, Z Cheng, J Li, IEEE Internet of Things Journal. 92Z. Tianqing, W. Zhou, D. Ye, Z. Cheng, and J. Li, \"Resource allocation in iot edge computing via concurrent federated reinforcement learning,\" IEEE Internet of Things Journal, vol. 9, no. 2, pp. 1414-1426, 2021.\n\nHow effective are the prevailing attack-defense models for cybersecurity anyway?. D He, S Chan, Y Zhang, C Wu, B Wang, IEEE Intelligent Systems. 295D. He, S. Chan, Y. Zhang, C. Wu, and B. Wang, \"How effective are the prevailing attack-defense models for cybersecurity anyway?\" IEEE Intelligent Systems, vol. 29, no. 5, pp. 14-21, 2013.\n\nCapbad: Content-agnostic, payload-based anomaly detector for industrial control protocols. J Cai, Q Wang, J Luo, Y Liu, L Liao, IEEE Internet of Things Journal. J. Cai, Q. Wang, J. Luo, Y. Liu, and L. Liao, \"Capbad: Content-agnostic, payload-based anomaly detector for industrial control protocols,\" IEEE Internet of Things Journal, 2021.\n\nAttacking deep reinforcement learning with decoupled adversarial policy. K Mo, W Tang, J Li, X Yuan, IEEE Transactions on Dependable and Secure Computing. K. Mo, W. Tang, J. Li, and X. Yuan, \"Attacking deep reinforcement learning with decoupled adversarial policy,\" IEEE Transactions on Dependable and Secure Computing, 2022.\n\nApplication of controller area network (can) bus anomaly detection based on time series prediction. H Qin, M Yan, H Ji, Vehicular Communications. 27100291H. Qin, M. Yan, and H. Ji, \"Application of controller area network (can) bus anomaly detection based on time series prediction,\" Vehicular Communications, vol. 27, p. 100291, 2021.\n\nSaiducant: Specification-based automotive intrusion detection using controller area network (can) timing. H Olufowobi, C Young, J Zambreno, G Bloom, IEEE Transactions on Vehicular Technology. 692H. Olufowobi, C. Young, J. Zambreno, and G. Bloom, \"Saiducant: Specification-based automotive intrusion detection using controller area network (can) timing,\" IEEE Transactions on Vehicular Technology, vol. 69, no. 2, pp. 1484-1494, 2019.\n\nDetecting anomalies in space using multivariate convolutional lstm with mixtures of probabilistic pca. S Tariq, S Lee, Y Shin, M S Lee, O Jung, D Chung, S S Woo, Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery & data mining. the 25th ACM SIGKDD international conference on knowledge discovery & data miningS. Tariq, S. Lee, Y. Shin, M. S. Lee, O. Jung, D. Chung, and S. S. Woo, \"Detecting anomalies in space using multivariate convolutional lstm with mixtures of probabilistic pca,\" in Proceedings of the 25th ACM SIGKDD international conference on knowledge discovery & data mining, 2019, pp. 2123-2133.\n\nA deep neural network for unsupervised anomaly detection and diagnosis in multivariate time series data. C Zhang, D Song, Y Chen, X Feng, C Lumezanu, W Cheng, J Ni, B Zong, H Chen, N V Chawla, Proceedings of the AAAI conference on artificial intelligence. the AAAI conference on artificial intelligence33C. Zhang, D. Song, Y. Chen, X. Feng, C. Lumezanu, W. Cheng, J. Ni, B. Zong, H. Chen, and N. V. Chawla, \"A deep neural network for unsupervised anomaly detection and diagnosis in multivariate time series data,\" in Proceedings of the AAAI conference on artificial intelligence, vol. 33, no. 01, 2019, pp. 1409-1416.\n\nAnomaly detection for in-vehicle network using cnn-lstm with attention mechanism. H Sun, M Chen, J Weng, Z Liu, G Geng, IEEE Transactions on Vehicular Technology. 7010H. Sun, M. Chen, J. Weng, Z. Liu, and G. Geng, \"Anomaly detection for in-vehicle network using cnn-lstm with attention mechanism,\" IEEE Transactions on Vehicular Technology, vol. 70, no. 10, pp. 10 880- 10 893, 2021.\n\nDeepwaf: detecting web attacks based on cnn and lstm models. X Kuang, M Zhang, H Li, G Zhao, H Cao, Z Wu, X Wang, International Symposium on Cyberspace Safety and Security. SpringerX. Kuang, M. Zhang, H. Li, G. Zhao, H. Cao, Z. Wu, and X. Wang, \"Deepwaf: detecting web attacks based on cnn and lstm models,\" in International Symposium on Cyberspace Safety and Security. Springer, 2019, pp. 121-136.\n\nAppm: adaptive parallel processing mechanism for service function chains. J Cai, Z Huang, L Liao, J Luo, W.-X Liu, IEEE Transactions on Network and Service Management. 182J. Cai, Z. Huang, L. Liao, J. Luo, and W.-X. Liu, \"Appm: adaptive parallel processing mechanism for service function chains,\" IEEE Trans- actions on Network and Service Management, vol. 18, no. 2, pp. 1540- 1555, 2021.\n\nA language-based intrusion detection approach for automotive embedded networks. I Studnia, E Alata, V Nicomette, M Ka\u00e2niche, Y Laarouchi, International Journal of Embedded Systems. 101I. Studnia, E. Alata, V. Nicomette, M. Ka\u00e2niche, and Y. Laarouchi, \"A language-based intrusion detection approach for automotive embedded networks,\" International Journal of Embedded Systems, vol. 10, no. 1, 2018.\n\nParrot, a software-only anti-spoofing defense system for the can bus. T Dagan, A Wool, ESCAR EUROPE. 34T. Dagan and A. Wool, \"Parrot, a software-only anti-spoofing defense system for the can bus,\" ESCAR EUROPE, vol. 34, 2016.\n\nFingerprinting electronic control units for vehicle intrusion detection. K.-T Cho, K G Shin, 25th USENIX Security Symposium (USENIX Security 16. K.-T. Cho and K. G. Shin, \"Fingerprinting electronic control units for vehicle intrusion detection,\" in 25th USENIX Security Symposium (USENIX Security 16), 2016, pp. 911-927.\n\nVoltageids: Lowlevel communication characteristics for automotive intrusion detection system. W Choi, K Joo, H J Jo, M C Park, D H Lee, IEEE Transactions on Information Forensics and Security. 138W. Choi, K. Joo, H. J. Jo, M. C. Park, and D. H. Lee, \"Voltageids: Low- level communication characteristics for automotive intrusion detection system,\" IEEE Transactions on Information Forensics and Security, vol. 13, no. 8, pp. 2114-2129, 2018.\n\nIntrusion detection system based on the analysis of time intervals of can messages for in-vehicle network. H M Song, H R Kim, H K Kim, 2016 international conference on information networking (ICOIN). IEEEH. M. Song, H. R. Kim, and H. K. Kim, \"Intrusion detection system based on the analysis of time intervals of can messages for in-vehicle network,\" in 2016 international conference on information networking (ICOIN). IEEE, 2016, pp. 63-68.\n\nSurvey of automotive controller area network intrusion detection systems. C Young, J Zambreno, H Olufowobi, G Bloom, IEEE Design & Test. 366C. Young, J. Zambreno, H. Olufowobi, and G. Bloom, \"Survey of automotive controller area network intrusion detection systems,\" IEEE Design & Test, vol. 36, no. 6, pp. 48-55, 2019.\n\nIntrusion detection system using deep neural network for in-vehicle network security. M.-J Kang, J.-W Kang, PloS one. 116155781M.-J. Kang and J.-W. Kang, \"Intrusion detection system using deep neural network for in-vehicle network security,\" PloS one, vol. 11, no. 6, p. e0155781, 2016.\n\nMth-ids: a multitiered hybrid intrusion detection system for internet of vehicles. L Yang, A Moubayed, A Shami, IEEE Internet of Things Journal. 91L. Yang, A. Moubayed, and A. Shami, \"Mth-ids: a multitiered hybrid intrusion detection system for internet of vehicles,\" IEEE Internet of Things Journal, vol. 9, no. 1, pp. 616-632, 2021.\n\nCantransfer: Transfer learning based intrusion detection on a controller area network using convolutional lstm network. S Tariq, S Lee, S S Woo, Proceedings of the 35th annual ACM symposium on applied computing. the 35th annual ACM symposium on applied computingS. Tariq, S. Lee, and S. S. Woo, \"Cantransfer: Transfer learning based intrusion detection on a controller area network using convolutional lstm network,\" in Proceedings of the 35th annual ACM symposium on applied computing, 2020, pp. 1048-1055.\n\nTowards a can ids based on a neural network data field predictor. K Pawelec, R A Bridges, F L Combs, Proceedings of the ACM Workshop on Automotive Cybersecurity. the ACM Workshop on Automotive CybersecurityK. Pawelec, R. A. Bridges, and F. L. Combs, \"Towards a can ids based on a neural network data field predictor,\" in Proceedings of the ACM Workshop on Automotive Cybersecurity, 2019, pp. 31-34.\n\nIn-vehicle network intrusion detection using deep convolutional neural network. H M Song, J Woo, H K Kim, Vehicular Communications. 21100198H. M. Song, J. Woo, and H. K. Kim, \"In-vehicle network intrusion detection using deep convolutional neural network,\" Vehicular Commu- nications, vol. 21, p. 100198, 2020.\n\nTowards viable intrusion detection methods for the automotive controller area network. A Tomlinson, J Bryans, S A Shaikh, ACM Computer Science in Cars Symposium. A. Tomlinson, J. Bryans, and S. A. Shaikh, \"Towards viable intrusion detection methods for the automotive controller area network,\" in 2nd ACM Computer Science in Cars Symposium, 2018, pp. 1-9.\n\nDelay-optimized multicast tree packing in software-defined networks. X Zhang, Y Wang, G Geng, J Yu, IEEE Transactions on Services Computing. X. Zhang, Y. Wang, G. Geng, and J. Yu, \"Delay-optimized multicast tree packing in software-defined networks,\" IEEE Transactions on Services Computing, 2021.\n\nAdversarial perturbation in remote sensing image recognition. S Ai, A S V Koe, T Huang, Applied Soft Computing. 105107252S. Ai, A. S. V. Koe, and T. Huang, \"Adversarial perturbation in remote sensing image recognition,\" Applied Soft Computing, vol. 105, p. 107252, 2021.\n\nMhat: an efficient model-heterogenous aggregation training scheme for federated learning. L Hu, H Yan, L Li, Z Pan, X Liu, Z Zhang, Information Sciences. 560L. Hu, H. Yan, L. Li, Z. Pan, X. Liu, and Z. Zhang, \"Mhat: an efficient model-heterogenous aggregation training scheme for federated learning,\" Information Sciences, vol. 560, pp. 493-503, 2021.\n\nMalware traffic classification using convolutional neural network for representation learning. W Wang, M Zhu, X Zeng, X Ye, Y Sheng, 2017 International conference on information networking (ICOIN). IEEEW. Wang, M. Zhu, X. Zeng, X. Ye, and Y. Sheng, \"Malware traffic classification using convolutional neural network for representation learning,\" in 2017 International conference on information networking (ICOIN). IEEE, 2017, pp. 712-717.\n\nGatrust: A multi-aspect graph attention network model for trust assessment in osns. N Jiang, W Jie, J Li, X Liu, D Jin, IEEE Transactions on Knowledge and Data Engineering. N. Jiang, W. Jie, J. Li, X. Liu, and D. Jin, \"Gatrust: A multi-aspect graph attention network model for trust assessment in osns,\" IEEE Transactions on Knowledge and Data Engineering, 2022.\n\nTree-based intelligent intrusion detection system in internet of vehicles. L Yang, A Moubayed, I Hamieh, A Shami, 2019 IEEE global communications conference (GLOBECOM). IEEEL. Yang, A. Moubayed, I. Hamieh, and A. Shami, \"Tree-based intelligent intrusion detection system in internet of vehicles,\" in 2019 IEEE global communications conference (GLOBECOM). IEEE, 2019, pp. 1-6.\n\nEncodeore: reducing leakage and preserving practicality in orderrevealing encryption. Z Liu, J Li, S Lv, Y Huang, L Guo, Y Yuan, C Dong, IEEE Transactions on Dependable and Secure Computing. Z. Liu, J. Li, S. Lv, Y. Huang, L. Guo, Y. Yuan, and C. Dong, \"Encodeore: reducing leakage and preserving practicality in order- revealing encryption,\" IEEE Transactions on Dependable and Secure Computing, 2020.\n\nA review: control area network (can) based intelligent vehicle system for driver assistance using advanced risc machines (arm). A U Jadhav, N Wagdarikar, 2015 International Conference on Pervasive Computing (ICPC). IEEEA. U. Jadhav and N. Wagdarikar, \"A review: control area network (can) based intelligent vehicle system for driver assistance using advanced risc machines (arm),\" in 2015 International Conference on Pervasive Computing (ICPC). IEEE, 2015, pp. 1-3.\n\nSarm: Service function chain active reconfiguration mechanism based on load and demand prediction. J Cai, K Qian, J Luo, K Zhu, International Journal of Intelligent Systems. J. Cai, K. Qian, J. Luo, and K. Zhu, \"Sarm: Service function chain active reconfiguration mechanism based on load and demand prediction,\" International Journal of Intelligent Systems, 2022.\n\nIntrusion detection systems for intra-vehicle networks: A review. O Y Al-Jarrah, C Maple, M Dianati, D Oxtoby, A Mouzakitis, IEEE Access. 7O. Y. Al-Jarrah, C. Maple, M. Dianati, D. Oxtoby, and A. Mouzakitis, \"Intrusion detection systems for intra-vehicle networks: A review,\" IEEE Access, vol. 7, pp. 21 266-21 289, 2019.\n\nController area network (can) schedulability analysis: Refuted, revisited and revised. R I Davis, A Burns, R J Bril, J J Lukkien, Real-Time Systems. 353R. I. Davis, A. Burns, R. J. Bril, and J. J. Lukkien, \"Controller area network (can) schedulability analysis: Refuted, revisited and revised,\" Real-Time Systems, vol. 35, no. 3, pp. 239-272, 2007.\n\nCalculating controller area network (can) message response times. K Tindell, A Burns, A J Wellings, Control engineering practice. 38K. Tindell, A. Burns, and A. J. Wellings, \"Calculating controller area network (can) message response times,\" Control engineering practice, vol. 3, no. 8, pp. 1163-1169, 1995.\n\nResponse time analysis under errors for can. S Punnekkat, H Hansson, C Norstrom, Proceedings Sixth IEEE Real-Time Technology and Applications Symposium. RTAS. Sixth IEEE Real-Time Technology and Applications Symposium. RTASIEEES. Punnekkat, H. Hansson, and C. Norstrom, \"Response time analysis under errors for can,\" in Proceedings Sixth IEEE Real-Time Technology and Applications Symposium. RTAS 2000. IEEE, 2000, pp. 258-265.\n\nIntrusion detection for in-vehicle communication networks: An unsupervised kohonen som approach. V S Barletta, D Caivano, A Nannavecchia, M Scalera, Future Internet. 127119V. S. Barletta, D. Caivano, A. Nannavecchia, and M. Scalera, \"Intrusion detection for in-vehicle communication networks: An unsupervised kohonen som approach,\" Future Internet, vol. 12, no. 7, p. 119, 2020.\n\nGids: Gan based intrusion detection system for in-vehicle network. E Seo, H M Song, H K Kim, 2018 16th Annual Conference on Privacy, Security and Trust. IEEEE. Seo, H. M. Song, and H. K. Kim, \"Gids: Gan based intrusion detec- tion system for in-vehicle network,\" in 2018 16th Annual Conference on Privacy, Security and Trust (PST). IEEE, 2018, pp. 1-6.\n\nThe dynamic privacy-preserving mechanisms for online dynamic social networks. J Li, X Hu, P Xiong, W Zhou, IEEE Transactions on Knowledge and Data Engineering. J. Li, X. Hu, P. Xiong, W. Zhou et al., \"The dynamic privacy-preserving mechanisms for online dynamic social networks,\" IEEE Transactions on Knowledge and Data Engineering, 2020.\n\nCsrt rumor spreading model based on complex network. S Ai, S Hong, X Zheng, Y Wang, X Liu, International Journal of Intelligent Systems. 365S. Ai, S. Hong, X. Zheng, Y. Wang, and X. Liu, \"Csrt rumor spreading model based on complex network,\" International Journal of Intelligent Systems, vol. 36, no. 5, pp. 1903-1913, 2021.\n\nDeep reinforcement learning-based multitask hybrid computing offloading for multiaccess edge computing. J Cai, H Fu, Y Liu, International Journal of Intelligent Systems. J. Cai, H. Fu, and Y. Liu, \"Deep reinforcement learning-based multitask hybrid computing offloading for multiaccess edge computing,\" Interna- tional Journal of Intelligent Systems, 2022.\n\nPpcl: Privacypreserving collaborative learning for mitigating indirect information leakage. H Yan, L Hu, X Xiang, Z Liu, X Yuan, Information Sciences. 548H. Yan, L. Hu, X. Xiang, Z. Liu, and X. Yuan, \"Ppcl: Privacy- preserving collaborative learning for mitigating indirect information leakage,\" Information Sciences, vol. 548, pp. 423-437, 2021.\n\nOn hyperparameter optimization of machine learning algorithms: Theory and practice. L Yang, A Shami, Neurocomputing. 415L. Yang and A. Shami, \"On hyperparameter optimization of machine learning algorithms: Theory and practice,\" Neurocomputing, vol. 415, pp. 295-316, 2020.\n\nResearch on the coordination mechanism of traditional Chinese medicine medical record data standardization and characteristic protection under big data environment. F Yuan, S Chen, K Liang, L Xu, Shandong People's Publishing House12Shizhong District, Jinan, Shandong Province, China: Shandong1st ed., ser. 1. No.517 Shungong RoadF. Yuan, S. Chen, K. Liang, and L. Xu, Research on the coordination mechanism of traditional Chinese medicine medical record data stan- dardization and characteristic protection under big data environment, 1st ed., ser. 1. No.517 Shungong Road, Shizhong District, Jinan, Shandong Province, China: Shandong:Shandong People's Publishing House, 12 2021, vol. 1.\n\nCbam: Convolutional block attention module. S Woo, J Park, J.-Y. Lee, I S Kweon, Proceedings of the European conference on computer vision (ECCV). the European conference on computer vision (ECCV)S. Woo, J. Park, J.-Y. Lee, and I. S. Kweon, \"Cbam: Convolutional block attention module,\" in Proceedings of the European conference on computer vision (ECCV), 2018, pp. 3-19.\n\nHyper-parameter optimization: A review of algorithms and applications. T Yu, H Zhu, arXiv:2003.05689arXiv preprintT. Yu and H. Zhu, \"Hyper-parameter optimization: A review of algo- rithms and applications,\" arXiv preprint arXiv:2003.05689, 2020.\n\nUnsupervised novelty detection using deep autoencoders with density based clustering. T Amarbayasgalan, B Jargalsaikhan, K H Ryu, Applied Sciences. 891468T. Amarbayasgalan, B. Jargalsaikhan, and K. H. Ryu, \"Unsupervised novelty detection using deep autoencoders with density based cluster- ing,\" Applied Sciences, vol. 8, no. 9, p. 1468, 2018.\n\nOtids: A novel intrusion detection system for in-vehicle network by using remote frame. H Lee, S H Jeong, H K Kim, 15H. Lee, S. H. Jeong, and H. K. Kim, \"Otids: A novel intrusion detection system for in-vehicle network by using remote frame,\" in 2017 15th\n\nAnnual Conference on Privacy, Security and Trust (PST). IEEEAnnual Conference on Privacy, Security and Trust (PST). IEEE, 2017, pp. 57-5709.\n", "annotations": {"author": "[{\"end\":144,\"start\":127},{\"end\":163,\"start\":145},{\"end\":173,\"start\":164},{\"end\":188,\"start\":174}]", "publisher": null, "author_last_name": "[{\"end\":143,\"start\":138},{\"end\":172,\"start\":170},{\"end\":187,\"start\":182}]", "author_first_name": "[{\"end\":137,\"start\":129},{\"end\":160,\"start\":157},{\"end\":162,\"start\":161},{\"end\":169,\"start\":164},{\"end\":181,\"start\":174}]", "author_affiliation": null, "title": "[{\"end\":124,\"start\":1},{\"end\":312,\"start\":189}]", "venue": null, "abstract": "[{\"end\":2021,\"start\":457}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2387,\"start\":2384},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2520,\"start\":2517},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2525,\"start\":2522},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2929,\"start\":2926},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":2934,\"start\":2931},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":2939,\"start\":2936},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":3109,\"start\":3106},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3219,\"start\":3216},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":3224,\"start\":3221},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":3229,\"start\":3226},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3355,\"start\":3351},{\"end\":3370,\"start\":3357},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3645,\"start\":3642},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":3796,\"start\":3792},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":3972,\"start\":3968},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":3978,\"start\":3974},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":4151,\"start\":4147},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":4157,\"start\":4153},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":4401,\"start\":4397},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":4550,\"start\":4546},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":4818,\"start\":4815},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":4824,\"start\":4820},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":4932,\"start\":4929},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":4938,\"start\":4934},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":4944,\"start\":4940},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":5190,\"start\":5186},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":5196,\"start\":5192},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":5202,\"start\":5198},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":5376,\"start\":5372},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":5382,\"start\":5378},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":8937,\"start\":8933},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":9336,\"start\":9332},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":9574,\"start\":9570},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":10041,\"start\":10037},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":10329,\"start\":10325},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":10888,\"start\":10884},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":11205,\"start\":11201},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":11663,\"start\":11659},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":11787,\"start\":11783},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":12061,\"start\":12057},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":12067,\"start\":12063},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":12085,\"start\":12081},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":12304,\"start\":12300},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":12471,\"start\":12467},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":12895,\"start\":12891},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":12914,\"start\":12910},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":13270,\"start\":13266},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":13751,\"start\":13747},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":14929,\"start\":14925},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":15639,\"start\":15635},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":15645,\"start\":15641},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":15749,\"start\":15745},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":15755,\"start\":15751},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":15835,\"start\":15831},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":16253,\"start\":16249},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":16588,\"start\":16584},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":16594,\"start\":16590},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":16845,\"start\":16841},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":17287,\"start\":17283},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":17455,\"start\":17451},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":17524,\"start\":17520},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":17636,\"start\":17633},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":17821,\"start\":17817},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":17827,\"start\":17823},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":17968,\"start\":17964},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":18184,\"start\":18180},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":18431,\"start\":18427},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":18586,\"start\":18582},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":23598,\"start\":23594},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":23936,\"start\":23932},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":23942,\"start\":23938},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":26288,\"start\":26284},{\"end\":26765,\"start\":26763},{\"end\":26795,\"start\":26793},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":26822,\"start\":26821},{\"end\":27003,\"start\":27000},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":27224,\"start\":27222},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":31633,\"start\":31629},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":38285,\"start\":38281},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":38635,\"start\":38631},{\"end\":39725,\"start\":39723},{\"end\":39755,\"start\":39753},{\"end\":39783,\"start\":39781},{\"end\":39964,\"start\":39961},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":40167,\"start\":40165},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":45567,\"start\":45563},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":45584,\"start\":45580},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":46683,\"start\":46679},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":46700,\"start\":46696}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":50674,\"start\":50625},{\"attributes\":{\"id\":\"fig_1\"},\"end\":50765,\"start\":50675},{\"attributes\":{\"id\":\"fig_2\"},\"end\":51274,\"start\":50766},{\"attributes\":{\"id\":\"fig_3\"},\"end\":51474,\"start\":51275},{\"attributes\":{\"id\":\"fig_4\"},\"end\":51712,\"start\":51475},{\"attributes\":{\"id\":\"fig_6\"},\"end\":51780,\"start\":51713},{\"attributes\":{\"id\":\"fig_7\"},\"end\":52127,\"start\":51781},{\"attributes\":{\"id\":\"fig_10\"},\"end\":52235,\"start\":52128},{\"attributes\":{\"id\":\"fig_11\"},\"end\":52542,\"start\":52236},{\"attributes\":{\"id\":\"fig_12\"},\"end\":52655,\"start\":52543},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":55914,\"start\":52656},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":56435,\"start\":55915},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":56647,\"start\":56436},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":56772,\"start\":56648},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":57041,\"start\":56773},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":57068,\"start\":57042},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":57076,\"start\":57069},{\"attributes\":{\"id\":\"tab_9\",\"type\":\"table\"},\"end\":57498,\"start\":57077},{\"attributes\":{\"id\":\"tab_10\",\"type\":\"table\"},\"end\":58317,\"start\":57499},{\"attributes\":{\"id\":\"tab_11\",\"type\":\"table\"},\"end\":58489,\"start\":58318},{\"attributes\":{\"id\":\"tab_12\",\"type\":\"table\"},\"end\":59876,\"start\":58490}]", "paragraph": "[{\"end\":2770,\"start\":2040},{\"end\":3979,\"start\":2772},{\"end\":5383,\"start\":3981},{\"end\":6497,\"start\":5385},{\"end\":7799,\"start\":6499},{\"end\":8223,\"start\":7801},{\"end\":8313,\"start\":8225},{\"end\":8669,\"start\":8334},{\"end\":9306,\"start\":8725},{\"end\":9836,\"start\":9308},{\"end\":10297,\"start\":9890},{\"end\":10650,\"start\":10299},{\"end\":11788,\"start\":10704},{\"end\":12274,\"start\":11844},{\"end\":12896,\"start\":12276},{\"end\":13948,\"start\":12898},{\"end\":14733,\"start\":13950},{\"end\":15162,\"start\":14735},{\"end\":16094,\"start\":15253},{\"end\":17637,\"start\":16096},{\"end\":18499,\"start\":17662},{\"end\":19516,\"start\":18501},{\"end\":19914,\"start\":19518},{\"end\":21035,\"start\":19916},{\"end\":21847,\"start\":21037},{\"end\":23127,\"start\":21876},{\"end\":24013,\"start\":23129},{\"end\":24789,\"start\":24050},{\"end\":25131,\"start\":24817},{\"end\":26179,\"start\":25133},{\"end\":26823,\"start\":26181},{\"end\":26923,\"start\":26921},{\"end\":27479,\"start\":26925},{\"end\":27678,\"start\":27525},{\"end\":27895,\"start\":27710},{\"end\":28292,\"start\":27915},{\"end\":28851,\"start\":28294},{\"end\":29604,\"start\":28853},{\"end\":29989,\"start\":29606},{\"end\":31096,\"start\":29991},{\"end\":32264,\"start\":31098},{\"end\":33142,\"start\":32335},{\"end\":33342,\"start\":33238},{\"end\":34003,\"start\":33365},{\"end\":34715,\"start\":34085},{\"end\":35261,\"start\":34717},{\"end\":35866,\"start\":35320},{\"end\":36146,\"start\":35976},{\"end\":36564,\"start\":36199},{\"end\":36946,\"start\":36613},{\"end\":36996,\"start\":36972},{\"end\":37263,\"start\":36998},{\"end\":37598,\"start\":37292},{\"end\":37674,\"start\":37628},{\"end\":37982,\"start\":37676},{\"end\":39142,\"start\":38031},{\"end\":39507,\"start\":39144},{\"end\":39784,\"start\":39509},{\"end\":39884,\"start\":39882},{\"end\":40925,\"start\":39886},{\"end\":41727,\"start\":40976},{\"end\":42424,\"start\":41729},{\"end\":43042,\"start\":42426},{\"end\":43509,\"start\":43044},{\"end\":44645,\"start\":43511},{\"end\":46818,\"start\":44678},{\"end\":47198,\"start\":46852},{\"end\":47970,\"start\":47200},{\"end\":48527,\"start\":47972},{\"end\":49198,\"start\":48529},{\"end\":49876,\"start\":49218},{\"end\":50181,\"start\":49878},{\"end\":50624,\"start\":50183}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":17661,\"start\":17638},{\"attributes\":{\"id\":\"formula_1\"},\"end\":24049,\"start\":24014},{\"attributes\":{\"id\":\"formula_2\"},\"end\":26920,\"start\":26824},{\"attributes\":{\"id\":\"formula_3\"},\"end\":27524,\"start\":27480},{\"attributes\":{\"id\":\"formula_4\"},\"end\":27709,\"start\":27679},{\"attributes\":{\"id\":\"formula_5\"},\"end\":27914,\"start\":27896},{\"attributes\":{\"id\":\"formula_6\"},\"end\":32334,\"start\":32265},{\"attributes\":{\"id\":\"formula_7\"},\"end\":33237,\"start\":33143},{\"attributes\":{\"id\":\"formula_8\"},\"end\":33364,\"start\":33343},{\"attributes\":{\"id\":\"formula_9\"},\"end\":34084,\"start\":34004},{\"attributes\":{\"id\":\"formula_10\"},\"end\":35319,\"start\":35262},{\"attributes\":{\"id\":\"formula_11\"},\"end\":35959,\"start\":35867},{\"attributes\":{\"id\":\"formula_12\"},\"end\":36612,\"start\":36565},{\"attributes\":{\"id\":\"formula_13\"},\"end\":36971,\"start\":36947},{\"attributes\":{\"id\":\"formula_15\"},\"end\":37291,\"start\":37264},{\"attributes\":{\"id\":\"formula_16\"},\"end\":37627,\"start\":37599},{\"attributes\":{\"id\":\"formula_18\"},\"end\":39881,\"start\":39785}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":8668,\"start\":8661},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":18739,\"start\":18731},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":19913,\"start\":19904},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":20329,\"start\":20161},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":20510,\"start\":20502},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":21558,\"start\":21549},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":22082,\"start\":22074},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":31455,\"start\":31447},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":39164,\"start\":39156},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":42475,\"start\":42466}]", "section_header": "[{\"end\":2038,\"start\":2023},{\"end\":8332,\"start\":8316},{\"end\":8723,\"start\":8672},{\"end\":9888,\"start\":9839},{\"end\":10702,\"start\":10653},{\"end\":11842,\"start\":11791},{\"end\":15251,\"start\":15165},{\"end\":21874,\"start\":21850},{\"end\":24815,\"start\":24792},{\"end\":35974,\"start\":35961},{\"end\":36197,\"start\":36149},{\"end\":38029,\"start\":37985},{\"end\":40974,\"start\":40928},{\"end\":44676,\"start\":44648},{\"end\":46850,\"start\":46821},{\"end\":49216,\"start\":49201},{\"end\":50634,\"start\":50626},{\"end\":50684,\"start\":50676},{\"end\":50774,\"start\":50767},{\"end\":51284,\"start\":51276},{\"end\":51722,\"start\":51714},{\"end\":51790,\"start\":51782},{\"end\":52138,\"start\":52129},{\"end\":52246,\"start\":52237},{\"end\":52553,\"start\":52544},{\"end\":52666,\"start\":52657},{\"end\":56447,\"start\":56437},{\"end\":56660,\"start\":56649},{\"end\":56784,\"start\":56774},{\"end\":57075,\"start\":57070},{\"end\":57088,\"start\":57078},{\"end\":58502,\"start\":58491}]", "table": "[{\"end\":55914,\"start\":52721},{\"end\":56435,\"start\":56055},{\"end\":56647,\"start\":56527},{\"end\":56772,\"start\":56737},{\"end\":57041,\"start\":56830},{\"end\":57498,\"start\":57157},{\"end\":58317,\"start\":57838},{\"end\":59876,\"start\":58554}]", "figure_caption": "[{\"end\":50674,\"start\":50636},{\"end\":50765,\"start\":50686},{\"end\":51274,\"start\":50776},{\"end\":51474,\"start\":51286},{\"end\":51712,\"start\":51477},{\"end\":51780,\"start\":51724},{\"end\":52127,\"start\":51792},{\"end\":52235,\"start\":52141},{\"end\":52542,\"start\":52249},{\"end\":52655,\"start\":52556},{\"end\":52721,\"start\":52668},{\"end\":56055,\"start\":55917},{\"end\":56527,\"start\":56450},{\"end\":56737,\"start\":56664},{\"end\":56830,\"start\":56787},{\"end\":57068,\"start\":57044},{\"end\":57157,\"start\":57091},{\"end\":57838,\"start\":57501},{\"end\":58489,\"start\":58320},{\"end\":58554,\"start\":58506}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":15771,\"start\":15757},{\"end\":16272,\"start\":16264},{\"end\":16613,\"start\":16605},{\"end\":17132,\"start\":17126},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":21168,\"start\":21162},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":27927,\"start\":27918},{\"end\":28871,\"start\":28865},{\"end\":30408,\"start\":30391},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":31482,\"start\":31476},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":32564,\"start\":32558},{\"end\":35094,\"start\":35088},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":40502,\"start\":40490},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":41055,\"start\":41049},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":45475,\"start\":45468},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":45486,\"start\":45479},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":46241,\"start\":46234}]", "bib_author_first_name": "[{\"end\":59968,\"start\":59967},{\"end\":59970,\"start\":59969},{\"end\":59978,\"start\":59977},{\"end\":59980,\"start\":59979},{\"end\":60302,\"start\":60298},{\"end\":60312,\"start\":60308},{\"end\":60322,\"start\":60318},{\"end\":60332,\"start\":60328},{\"end\":60343,\"start\":60339},{\"end\":60353,\"start\":60349},{\"end\":60362,\"start\":60361},{\"end\":60364,\"start\":60363},{\"end\":60789,\"start\":60788},{\"end\":60798,\"start\":60797},{\"end\":60807,\"start\":60806},{\"end\":61136,\"start\":61135},{\"end\":61146,\"start\":61145},{\"end\":61404,\"start\":61403},{\"end\":61410,\"start\":61409},{\"end\":61416,\"start\":61415},{\"end\":61422,\"start\":61421},{\"end\":61430,\"start\":61429},{\"end\":61437,\"start\":61436},{\"end\":61439,\"start\":61438},{\"end\":61446,\"start\":61445},{\"end\":61453,\"start\":61452},{\"end\":61845,\"start\":61844},{\"end\":61852,\"start\":61851},{\"end\":61858,\"start\":61857},{\"end\":61868,\"start\":61864},{\"end\":61870,\"start\":61869},{\"end\":61878,\"start\":61877},{\"end\":61885,\"start\":61884},{\"end\":62229,\"start\":62228},{\"end\":62236,\"start\":62235},{\"end\":62245,\"start\":62244},{\"end\":62253,\"start\":62252},{\"end\":62259,\"start\":62258},{\"end\":62265,\"start\":62264},{\"end\":62273,\"start\":62272},{\"end\":62618,\"start\":62617},{\"end\":62631,\"start\":62630},{\"end\":62640,\"start\":62639},{\"end\":62650,\"start\":62649},{\"end\":62662,\"start\":62661},{\"end\":62673,\"start\":62672},{\"end\":62683,\"start\":62682},{\"end\":62694,\"start\":62693},{\"end\":62705,\"start\":62704},{\"end\":62716,\"start\":62715},{\"end\":63076,\"start\":63075},{\"end\":63085,\"start\":63084},{\"end\":63087,\"start\":63086},{\"end\":63391,\"start\":63390},{\"end\":63400,\"start\":63399},{\"end\":63408,\"start\":63407},{\"end\":63418,\"start\":63417},{\"end\":63743,\"start\":63742},{\"end\":63751,\"start\":63750},{\"end\":63761,\"start\":63760},{\"end\":63772,\"start\":63771},{\"end\":63782,\"start\":63781},{\"end\":63788,\"start\":63787},{\"end\":63794,\"start\":63793},{\"end\":63806,\"start\":63805},{\"end\":63816,\"start\":63815},{\"end\":64219,\"start\":64218},{\"end\":64226,\"start\":64225},{\"end\":64234,\"start\":64233},{\"end\":64240,\"start\":64239},{\"end\":64489,\"start\":64488},{\"end\":64497,\"start\":64496},{\"end\":64777,\"start\":64776},{\"end\":64783,\"start\":64782},{\"end\":64789,\"start\":64788},{\"end\":64796,\"start\":64795},{\"end\":64802,\"start\":64801},{\"end\":64809,\"start\":64808},{\"end\":64817,\"start\":64816},{\"end\":65183,\"start\":65182},{\"end\":65195,\"start\":65194},{\"end\":65203,\"start\":65202},{\"end\":65209,\"start\":65208},{\"end\":65218,\"start\":65217},{\"end\":65554,\"start\":65553},{\"end\":65560,\"start\":65559},{\"end\":65568,\"start\":65567},{\"end\":65577,\"start\":65576},{\"end\":65583,\"start\":65582},{\"end\":65900,\"start\":65899},{\"end\":65907,\"start\":65906},{\"end\":65915,\"start\":65914},{\"end\":65922,\"start\":65921},{\"end\":65929,\"start\":65928},{\"end\":66222,\"start\":66221},{\"end\":66228,\"start\":66227},{\"end\":66236,\"start\":66235},{\"end\":66242,\"start\":66241},{\"end\":66576,\"start\":66575},{\"end\":66583,\"start\":66582},{\"end\":66590,\"start\":66589},{\"end\":66918,\"start\":66917},{\"end\":66931,\"start\":66930},{\"end\":66940,\"start\":66939},{\"end\":66952,\"start\":66951},{\"end\":67350,\"start\":67349},{\"end\":67359,\"start\":67358},{\"end\":67366,\"start\":67365},{\"end\":67374,\"start\":67373},{\"end\":67376,\"start\":67375},{\"end\":67383,\"start\":67382},{\"end\":67391,\"start\":67390},{\"end\":67400,\"start\":67399},{\"end\":67402,\"start\":67401},{\"end\":67993,\"start\":67992},{\"end\":68002,\"start\":68001},{\"end\":68010,\"start\":68009},{\"end\":68018,\"start\":68017},{\"end\":68026,\"start\":68025},{\"end\":68038,\"start\":68037},{\"end\":68047,\"start\":68046},{\"end\":68053,\"start\":68052},{\"end\":68061,\"start\":68060},{\"end\":68069,\"start\":68068},{\"end\":68071,\"start\":68070},{\"end\":68589,\"start\":68588},{\"end\":68596,\"start\":68595},{\"end\":68604,\"start\":68603},{\"end\":68612,\"start\":68611},{\"end\":68619,\"start\":68618},{\"end\":68953,\"start\":68952},{\"end\":68962,\"start\":68961},{\"end\":68971,\"start\":68970},{\"end\":68977,\"start\":68976},{\"end\":68985,\"start\":68984},{\"end\":68992,\"start\":68991},{\"end\":68998,\"start\":68997},{\"end\":69366,\"start\":69365},{\"end\":69373,\"start\":69372},{\"end\":69382,\"start\":69381},{\"end\":69390,\"start\":69389},{\"end\":69400,\"start\":69396},{\"end\":69763,\"start\":69762},{\"end\":69774,\"start\":69773},{\"end\":69783,\"start\":69782},{\"end\":69796,\"start\":69795},{\"end\":69808,\"start\":69807},{\"end\":70152,\"start\":70151},{\"end\":70161,\"start\":70160},{\"end\":70385,\"start\":70381},{\"end\":70392,\"start\":70391},{\"end\":70394,\"start\":70393},{\"end\":70725,\"start\":70724},{\"end\":70733,\"start\":70732},{\"end\":70740,\"start\":70739},{\"end\":70742,\"start\":70741},{\"end\":70748,\"start\":70747},{\"end\":70750,\"start\":70749},{\"end\":70758,\"start\":70757},{\"end\":70760,\"start\":70759},{\"end\":71181,\"start\":71180},{\"end\":71183,\"start\":71182},{\"end\":71191,\"start\":71190},{\"end\":71193,\"start\":71192},{\"end\":71200,\"start\":71199},{\"end\":71202,\"start\":71201},{\"end\":71591,\"start\":71590},{\"end\":71600,\"start\":71599},{\"end\":71612,\"start\":71611},{\"end\":71625,\"start\":71624},{\"end\":71927,\"start\":71923},{\"end\":71938,\"start\":71934},{\"end\":72209,\"start\":72208},{\"end\":72217,\"start\":72216},{\"end\":72229,\"start\":72228},{\"end\":72582,\"start\":72581},{\"end\":72591,\"start\":72590},{\"end\":72598,\"start\":72597},{\"end\":72600,\"start\":72599},{\"end\":73037,\"start\":73036},{\"end\":73048,\"start\":73047},{\"end\":73050,\"start\":73049},{\"end\":73061,\"start\":73060},{\"end\":73063,\"start\":73062},{\"end\":73451,\"start\":73450},{\"end\":73453,\"start\":73452},{\"end\":73461,\"start\":73460},{\"end\":73468,\"start\":73467},{\"end\":73470,\"start\":73469},{\"end\":73770,\"start\":73769},{\"end\":73783,\"start\":73782},{\"end\":73793,\"start\":73792},{\"end\":73795,\"start\":73794},{\"end\":74109,\"start\":74108},{\"end\":74118,\"start\":74117},{\"end\":74126,\"start\":74125},{\"end\":74134,\"start\":74133},{\"end\":74401,\"start\":74400},{\"end\":74407,\"start\":74406},{\"end\":74411,\"start\":74408},{\"end\":74418,\"start\":74417},{\"end\":74701,\"start\":74700},{\"end\":74707,\"start\":74706},{\"end\":74714,\"start\":74713},{\"end\":74720,\"start\":74719},{\"end\":74727,\"start\":74726},{\"end\":74734,\"start\":74733},{\"end\":75059,\"start\":75058},{\"end\":75067,\"start\":75066},{\"end\":75074,\"start\":75073},{\"end\":75082,\"start\":75081},{\"end\":75088,\"start\":75087},{\"end\":75488,\"start\":75487},{\"end\":75497,\"start\":75496},{\"end\":75504,\"start\":75503},{\"end\":75510,\"start\":75509},{\"end\":75517,\"start\":75516},{\"end\":75843,\"start\":75842},{\"end\":75851,\"start\":75850},{\"end\":75863,\"start\":75862},{\"end\":75873,\"start\":75872},{\"end\":76231,\"start\":76230},{\"end\":76238,\"start\":76237},{\"end\":76244,\"start\":76243},{\"end\":76250,\"start\":76249},{\"end\":76259,\"start\":76258},{\"end\":76266,\"start\":76265},{\"end\":76274,\"start\":76273},{\"end\":76677,\"start\":76676},{\"end\":76679,\"start\":76678},{\"end\":76689,\"start\":76688},{\"end\":77115,\"start\":77114},{\"end\":77122,\"start\":77121},{\"end\":77130,\"start\":77129},{\"end\":77137,\"start\":77136},{\"end\":77447,\"start\":77446},{\"end\":77449,\"start\":77448},{\"end\":77462,\"start\":77461},{\"end\":77471,\"start\":77470},{\"end\":77482,\"start\":77481},{\"end\":77492,\"start\":77491},{\"end\":77791,\"start\":77790},{\"end\":77793,\"start\":77792},{\"end\":77802,\"start\":77801},{\"end\":77811,\"start\":77810},{\"end\":77813,\"start\":77812},{\"end\":77821,\"start\":77820},{\"end\":77823,\"start\":77822},{\"end\":78120,\"start\":78119},{\"end\":78131,\"start\":78130},{\"end\":78140,\"start\":78139},{\"end\":78142,\"start\":78141},{\"end\":78408,\"start\":78407},{\"end\":78421,\"start\":78420},{\"end\":78432,\"start\":78431},{\"end\":78889,\"start\":78888},{\"end\":78891,\"start\":78890},{\"end\":78903,\"start\":78902},{\"end\":78914,\"start\":78913},{\"end\":78930,\"start\":78929},{\"end\":79239,\"start\":79238},{\"end\":79246,\"start\":79245},{\"end\":79248,\"start\":79247},{\"end\":79256,\"start\":79255},{\"end\":79258,\"start\":79257},{\"end\":79604,\"start\":79603},{\"end\":79610,\"start\":79609},{\"end\":79616,\"start\":79615},{\"end\":79625,\"start\":79624},{\"end\":79919,\"start\":79918},{\"end\":79925,\"start\":79924},{\"end\":79933,\"start\":79932},{\"end\":79942,\"start\":79941},{\"end\":79950,\"start\":79949},{\"end\":80296,\"start\":80295},{\"end\":80303,\"start\":80302},{\"end\":80309,\"start\":80308},{\"end\":80642,\"start\":80641},{\"end\":80649,\"start\":80648},{\"end\":80655,\"start\":80654},{\"end\":80664,\"start\":80663},{\"end\":80671,\"start\":80670},{\"end\":80982,\"start\":80981},{\"end\":80990,\"start\":80989},{\"end\":81337,\"start\":81336},{\"end\":81345,\"start\":81344},{\"end\":81353,\"start\":81352},{\"end\":81362,\"start\":81361},{\"end\":81905,\"start\":81904},{\"end\":81912,\"start\":81911},{\"end\":81924,\"start\":81919},{\"end\":81931,\"start\":81930},{\"end\":81933,\"start\":81932},{\"end\":82305,\"start\":82304},{\"end\":82311,\"start\":82310},{\"end\":82567,\"start\":82566},{\"end\":82585,\"start\":82584},{\"end\":82602,\"start\":82601},{\"end\":82604,\"start\":82603},{\"end\":82914,\"start\":82913},{\"end\":82921,\"start\":82920},{\"end\":82923,\"start\":82922},{\"end\":82932,\"start\":82931},{\"end\":82934,\"start\":82933}]", "bib_author_last_name": "[{\"end\":59975,\"start\":59971},{\"end\":59984,\"start\":59981},{\"end\":60306,\"start\":60303},{\"end\":60316,\"start\":60313},{\"end\":60326,\"start\":60323},{\"end\":60337,\"start\":60333},{\"end\":60347,\"start\":60344},{\"end\":60359,\"start\":60354},{\"end\":60369,\"start\":60365},{\"end\":60795,\"start\":60790},{\"end\":60804,\"start\":60799},{\"end\":60816,\"start\":60808},{\"end\":61143,\"start\":61137},{\"end\":61154,\"start\":61147},{\"end\":61407,\"start\":61405},{\"end\":61413,\"start\":61411},{\"end\":61419,\"start\":61417},{\"end\":61427,\"start\":61423},{\"end\":61434,\"start\":61431},{\"end\":61443,\"start\":61440},{\"end\":61450,\"start\":61447},{\"end\":61456,\"start\":61454},{\"end\":61849,\"start\":61846},{\"end\":61855,\"start\":61853},{\"end\":61862,\"start\":61859},{\"end\":61875,\"start\":61871},{\"end\":61882,\"start\":61879},{\"end\":61890,\"start\":61886},{\"end\":62233,\"start\":62230},{\"end\":62242,\"start\":62237},{\"end\":62250,\"start\":62246},{\"end\":62256,\"start\":62254},{\"end\":62262,\"start\":62260},{\"end\":62270,\"start\":62266},{\"end\":62278,\"start\":62274},{\"end\":62628,\"start\":62619},{\"end\":62637,\"start\":62632},{\"end\":62647,\"start\":62641},{\"end\":62659,\"start\":62651},{\"end\":62670,\"start\":62663},{\"end\":62680,\"start\":62674},{\"end\":62691,\"start\":62684},{\"end\":62702,\"start\":62695},{\"end\":62713,\"start\":62706},{\"end\":62722,\"start\":62717},{\"end\":63082,\"start\":63077},{\"end\":63097,\"start\":63088},{\"end\":63397,\"start\":63392},{\"end\":63405,\"start\":63401},{\"end\":63415,\"start\":63409},{\"end\":63425,\"start\":63419},{\"end\":63748,\"start\":63744},{\"end\":63758,\"start\":63752},{\"end\":63769,\"start\":63762},{\"end\":63779,\"start\":63773},{\"end\":63785,\"start\":63783},{\"end\":63791,\"start\":63789},{\"end\":63803,\"start\":63795},{\"end\":63813,\"start\":63807},{\"end\":63823,\"start\":63817},{\"end\":64223,\"start\":64220},{\"end\":64231,\"start\":64227},{\"end\":64237,\"start\":64235},{\"end\":64244,\"start\":64241},{\"end\":64494,\"start\":64490},{\"end\":64503,\"start\":64498},{\"end\":64780,\"start\":64778},{\"end\":64786,\"start\":64784},{\"end\":64793,\"start\":64790},{\"end\":64799,\"start\":64797},{\"end\":64806,\"start\":64803},{\"end\":64814,\"start\":64810},{\"end\":64820,\"start\":64818},{\"end\":65192,\"start\":65184},{\"end\":65200,\"start\":65196},{\"end\":65206,\"start\":65204},{\"end\":65215,\"start\":65210},{\"end\":65221,\"start\":65219},{\"end\":65557,\"start\":65555},{\"end\":65565,\"start\":65561},{\"end\":65574,\"start\":65569},{\"end\":65580,\"start\":65578},{\"end\":65588,\"start\":65584},{\"end\":65904,\"start\":65901},{\"end\":65912,\"start\":65908},{\"end\":65919,\"start\":65916},{\"end\":65926,\"start\":65923},{\"end\":65934,\"start\":65930},{\"end\":66225,\"start\":66223},{\"end\":66233,\"start\":66229},{\"end\":66239,\"start\":66237},{\"end\":66247,\"start\":66243},{\"end\":66580,\"start\":66577},{\"end\":66587,\"start\":66584},{\"end\":66593,\"start\":66591},{\"end\":66928,\"start\":66919},{\"end\":66937,\"start\":66932},{\"end\":66949,\"start\":66941},{\"end\":66958,\"start\":66953},{\"end\":67356,\"start\":67351},{\"end\":67363,\"start\":67360},{\"end\":67371,\"start\":67367},{\"end\":67380,\"start\":67377},{\"end\":67388,\"start\":67384},{\"end\":67397,\"start\":67392},{\"end\":67406,\"start\":67403},{\"end\":67999,\"start\":67994},{\"end\":68007,\"start\":68003},{\"end\":68015,\"start\":68011},{\"end\":68023,\"start\":68019},{\"end\":68035,\"start\":68027},{\"end\":68044,\"start\":68039},{\"end\":68050,\"start\":68048},{\"end\":68058,\"start\":68054},{\"end\":68066,\"start\":68062},{\"end\":68078,\"start\":68072},{\"end\":68593,\"start\":68590},{\"end\":68601,\"start\":68597},{\"end\":68609,\"start\":68605},{\"end\":68616,\"start\":68613},{\"end\":68624,\"start\":68620},{\"end\":68959,\"start\":68954},{\"end\":68968,\"start\":68963},{\"end\":68974,\"start\":68972},{\"end\":68982,\"start\":68978},{\"end\":68989,\"start\":68986},{\"end\":68995,\"start\":68993},{\"end\":69003,\"start\":68999},{\"end\":69370,\"start\":69367},{\"end\":69379,\"start\":69374},{\"end\":69387,\"start\":69383},{\"end\":69394,\"start\":69391},{\"end\":69404,\"start\":69401},{\"end\":69771,\"start\":69764},{\"end\":69780,\"start\":69775},{\"end\":69793,\"start\":69784},{\"end\":69805,\"start\":69797},{\"end\":69818,\"start\":69809},{\"end\":70158,\"start\":70153},{\"end\":70166,\"start\":70162},{\"end\":70389,\"start\":70386},{\"end\":70399,\"start\":70395},{\"end\":70730,\"start\":70726},{\"end\":70737,\"start\":70734},{\"end\":70745,\"start\":70743},{\"end\":70755,\"start\":70751},{\"end\":70764,\"start\":70761},{\"end\":71188,\"start\":71184},{\"end\":71197,\"start\":71194},{\"end\":71206,\"start\":71203},{\"end\":71597,\"start\":71592},{\"end\":71609,\"start\":71601},{\"end\":71622,\"start\":71613},{\"end\":71631,\"start\":71626},{\"end\":71932,\"start\":71928},{\"end\":71943,\"start\":71939},{\"end\":72214,\"start\":72210},{\"end\":72226,\"start\":72218},{\"end\":72235,\"start\":72230},{\"end\":72588,\"start\":72583},{\"end\":72595,\"start\":72592},{\"end\":72604,\"start\":72601},{\"end\":73045,\"start\":73038},{\"end\":73058,\"start\":73051},{\"end\":73069,\"start\":73064},{\"end\":73458,\"start\":73454},{\"end\":73465,\"start\":73462},{\"end\":73474,\"start\":73471},{\"end\":73780,\"start\":73771},{\"end\":73790,\"start\":73784},{\"end\":73802,\"start\":73796},{\"end\":74115,\"start\":74110},{\"end\":74123,\"start\":74119},{\"end\":74131,\"start\":74127},{\"end\":74137,\"start\":74135},{\"end\":74404,\"start\":74402},{\"end\":74415,\"start\":74412},{\"end\":74424,\"start\":74419},{\"end\":74704,\"start\":74702},{\"end\":74711,\"start\":74708},{\"end\":74717,\"start\":74715},{\"end\":74724,\"start\":74721},{\"end\":74731,\"start\":74728},{\"end\":74740,\"start\":74735},{\"end\":75064,\"start\":75060},{\"end\":75071,\"start\":75068},{\"end\":75079,\"start\":75075},{\"end\":75085,\"start\":75083},{\"end\":75094,\"start\":75089},{\"end\":75494,\"start\":75489},{\"end\":75501,\"start\":75498},{\"end\":75507,\"start\":75505},{\"end\":75514,\"start\":75511},{\"end\":75521,\"start\":75518},{\"end\":75848,\"start\":75844},{\"end\":75860,\"start\":75852},{\"end\":75870,\"start\":75864},{\"end\":75879,\"start\":75874},{\"end\":76235,\"start\":76232},{\"end\":76241,\"start\":76239},{\"end\":76247,\"start\":76245},{\"end\":76256,\"start\":76251},{\"end\":76263,\"start\":76260},{\"end\":76271,\"start\":76267},{\"end\":76279,\"start\":76275},{\"end\":76686,\"start\":76680},{\"end\":76700,\"start\":76690},{\"end\":77119,\"start\":77116},{\"end\":77127,\"start\":77123},{\"end\":77134,\"start\":77131},{\"end\":77141,\"start\":77138},{\"end\":77459,\"start\":77450},{\"end\":77468,\"start\":77463},{\"end\":77479,\"start\":77472},{\"end\":77489,\"start\":77483},{\"end\":77503,\"start\":77493},{\"end\":77799,\"start\":77794},{\"end\":77808,\"start\":77803},{\"end\":77818,\"start\":77814},{\"end\":77831,\"start\":77824},{\"end\":78128,\"start\":78121},{\"end\":78137,\"start\":78132},{\"end\":78151,\"start\":78143},{\"end\":78418,\"start\":78409},{\"end\":78429,\"start\":78422},{\"end\":78441,\"start\":78433},{\"end\":78900,\"start\":78892},{\"end\":78911,\"start\":78904},{\"end\":78927,\"start\":78915},{\"end\":78938,\"start\":78931},{\"end\":79243,\"start\":79240},{\"end\":79253,\"start\":79249},{\"end\":79262,\"start\":79259},{\"end\":79607,\"start\":79605},{\"end\":79613,\"start\":79611},{\"end\":79622,\"start\":79617},{\"end\":79630,\"start\":79626},{\"end\":79922,\"start\":79920},{\"end\":79930,\"start\":79926},{\"end\":79939,\"start\":79934},{\"end\":79947,\"start\":79943},{\"end\":79954,\"start\":79951},{\"end\":80300,\"start\":80297},{\"end\":80306,\"start\":80304},{\"end\":80313,\"start\":80310},{\"end\":80646,\"start\":80643},{\"end\":80652,\"start\":80650},{\"end\":80661,\"start\":80656},{\"end\":80668,\"start\":80665},{\"end\":80676,\"start\":80672},{\"end\":80987,\"start\":80983},{\"end\":80996,\"start\":80991},{\"end\":81342,\"start\":81338},{\"end\":81350,\"start\":81346},{\"end\":81359,\"start\":81354},{\"end\":81365,\"start\":81363},{\"end\":81909,\"start\":81906},{\"end\":81917,\"start\":81913},{\"end\":81928,\"start\":81925},{\"end\":81939,\"start\":81934},{\"end\":82308,\"start\":82306},{\"end\":82315,\"start\":82312},{\"end\":82582,\"start\":82568},{\"end\":82599,\"start\":82586},{\"end\":82608,\"start\":82605},{\"end\":82918,\"start\":82915},{\"end\":82929,\"start\":82924},{\"end\":82938,\"start\":82935}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":232235061},\"end\":60230,\"start\":59878},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":390021},\"end\":60682,\"start\":60232},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":7830197},\"end\":61078,\"start\":60684},{\"attributes\":{\"id\":\"b3\"},\"end\":61300,\"start\":61080},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":226694038},\"end\":61772,\"start\":61302},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":226601720},\"end\":62136,\"start\":61774},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":230337186},\"end\":62548,\"start\":62138},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":15858039},\"end\":63027,\"start\":62550},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":15605711},\"end\":63330,\"start\":63029},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":216080590},\"end\":63626,\"start\":63332},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":8763355},\"end\":64152,\"start\":63628},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":225116117},\"end\":64429,\"start\":64154},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":231731487},\"end\":64717,\"start\":64431},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":181378262},\"end\":65089,\"start\":64719},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":236314670},\"end\":65469,\"start\":65091},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":15643377},\"end\":65806,\"start\":65471},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":245521387},\"end\":66146,\"start\":65808},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":246055923},\"end\":66473,\"start\":66148},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":225264248},\"end\":66809,\"start\":66475},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":210159293},\"end\":67244,\"start\":66811},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":196185160},\"end\":67885,\"start\":67246},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":53753975},\"end\":68504,\"start\":67887},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":238937629},\"end\":68889,\"start\":68506},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":210078700},\"end\":69289,\"start\":68891},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":234263235},\"end\":69680,\"start\":69291},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":3317262},\"end\":70079,\"start\":69682},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":35686377},\"end\":70306,\"start\":70081},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":14729648},\"end\":70628,\"start\":70308},{\"attributes\":{\"id\":\"b28\"},\"end\":71071,\"start\":70630},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":9333718},\"end\":71514,\"start\":71073},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":78088028},\"end\":71835,\"start\":71516},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":18256723},\"end\":72123,\"start\":71837},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":235212223},\"end\":72459,\"start\":72125},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":214694052},\"end\":72968,\"start\":72461},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":57189430},\"end\":73368,\"start\":72970},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":208091240},\"end\":73680,\"start\":73370},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":53122729},\"end\":74037,\"start\":73682},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":238851994},\"end\":74336,\"start\":74039},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":233664896},\"end\":74608,\"start\":74338},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":233313136},\"end\":74961,\"start\":74610},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":3725747},\"end\":75401,\"start\":74963},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":248713444},\"end\":75765,\"start\":75403},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":204800358},\"end\":76142,\"start\":75767},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":226599069},\"end\":76546,\"start\":76144},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":18780815},\"end\":77013,\"start\":76548},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":246860452},\"end\":77378,\"start\":77015},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":86751803},\"end\":77701,\"start\":77380},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":11759559},\"end\":78051,\"start\":77703},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":1635605},\"end\":78360,\"start\":78053},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":31860942},\"end\":78789,\"start\":78362},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":221356244},\"end\":79169,\"start\":78791},{\"attributes\":{\"id\":\"b51\",\"matched_paper_id\":53234493},\"end\":79523,\"start\":79171},{\"attributes\":{\"id\":\"b52\",\"matched_paper_id\":226572422},\"end\":79863,\"start\":79525},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":232432835},\"end\":80189,\"start\":79865},{\"attributes\":{\"id\":\"b54\",\"matched_paper_id\":246603046},\"end\":80547,\"start\":80191},{\"attributes\":{\"id\":\"b55\",\"matched_paper_id\":225104439},\"end\":80895,\"start\":80549},{\"attributes\":{\"id\":\"b56\",\"matched_paper_id\":220919678},\"end\":81169,\"start\":80897},{\"attributes\":{\"id\":\"b57\"},\"end\":81858,\"start\":81171},{\"attributes\":{\"id\":\"b58\",\"matched_paper_id\":49867180},\"end\":82231,\"start\":81860},{\"attributes\":{\"doi\":\"arXiv:2003.05689\",\"id\":\"b59\"},\"end\":82478,\"start\":82233},{\"attributes\":{\"id\":\"b60\",\"matched_paper_id\":115671315},\"end\":82823,\"start\":82480},{\"attributes\":{\"id\":\"b61\"},\"end\":83080,\"start\":82825},{\"attributes\":{\"id\":\"b62\"},\"end\":83222,\"start\":83082}]", "bib_title": "[{\"end\":59965,\"start\":59878},{\"end\":60296,\"start\":60232},{\"end\":60786,\"start\":60684},{\"end\":61133,\"start\":61080},{\"end\":61401,\"start\":61302},{\"end\":61842,\"start\":61774},{\"end\":62226,\"start\":62138},{\"end\":62615,\"start\":62550},{\"end\":63073,\"start\":63029},{\"end\":63388,\"start\":63332},{\"end\":63740,\"start\":63628},{\"end\":64216,\"start\":64154},{\"end\":64486,\"start\":64431},{\"end\":64774,\"start\":64719},{\"end\":65180,\"start\":65091},{\"end\":65551,\"start\":65471},{\"end\":65897,\"start\":65808},{\"end\":66219,\"start\":66148},{\"end\":66573,\"start\":66475},{\"end\":66915,\"start\":66811},{\"end\":67347,\"start\":67246},{\"end\":67990,\"start\":67887},{\"end\":68586,\"start\":68506},{\"end\":68950,\"start\":68891},{\"end\":69363,\"start\":69291},{\"end\":69760,\"start\":69682},{\"end\":70149,\"start\":70081},{\"end\":70379,\"start\":70308},{\"end\":70722,\"start\":70630},{\"end\":71178,\"start\":71073},{\"end\":71588,\"start\":71516},{\"end\":71921,\"start\":71837},{\"end\":72206,\"start\":72125},{\"end\":72579,\"start\":72461},{\"end\":73034,\"start\":72970},{\"end\":73448,\"start\":73370},{\"end\":73767,\"start\":73682},{\"end\":74106,\"start\":74039},{\"end\":74398,\"start\":74338},{\"end\":74698,\"start\":74610},{\"end\":75056,\"start\":74963},{\"end\":75485,\"start\":75403},{\"end\":75840,\"start\":75767},{\"end\":76228,\"start\":76144},{\"end\":76674,\"start\":76548},{\"end\":77112,\"start\":77015},{\"end\":77444,\"start\":77380},{\"end\":77788,\"start\":77703},{\"end\":78117,\"start\":78053},{\"end\":78405,\"start\":78362},{\"end\":78886,\"start\":78791},{\"end\":79236,\"start\":79171},{\"end\":79601,\"start\":79525},{\"end\":79916,\"start\":79865},{\"end\":80293,\"start\":80191},{\"end\":80639,\"start\":80549},{\"end\":80979,\"start\":80897},{\"end\":81902,\"start\":81860},{\"end\":82564,\"start\":82480}]", "bib_author": "[{\"end\":59977,\"start\":59967},{\"end\":59986,\"start\":59977},{\"end\":60308,\"start\":60298},{\"end\":60318,\"start\":60308},{\"end\":60328,\"start\":60318},{\"end\":60339,\"start\":60328},{\"end\":60349,\"start\":60339},{\"end\":60361,\"start\":60349},{\"end\":60371,\"start\":60361},{\"end\":60797,\"start\":60788},{\"end\":60806,\"start\":60797},{\"end\":60818,\"start\":60806},{\"end\":61145,\"start\":61135},{\"end\":61156,\"start\":61145},{\"end\":61409,\"start\":61403},{\"end\":61415,\"start\":61409},{\"end\":61421,\"start\":61415},{\"end\":61429,\"start\":61421},{\"end\":61436,\"start\":61429},{\"end\":61445,\"start\":61436},{\"end\":61452,\"start\":61445},{\"end\":61458,\"start\":61452},{\"end\":61851,\"start\":61844},{\"end\":61857,\"start\":61851},{\"end\":61864,\"start\":61857},{\"end\":61877,\"start\":61864},{\"end\":61884,\"start\":61877},{\"end\":61892,\"start\":61884},{\"end\":62235,\"start\":62228},{\"end\":62244,\"start\":62235},{\"end\":62252,\"start\":62244},{\"end\":62258,\"start\":62252},{\"end\":62264,\"start\":62258},{\"end\":62272,\"start\":62264},{\"end\":62280,\"start\":62272},{\"end\":62630,\"start\":62617},{\"end\":62639,\"start\":62630},{\"end\":62649,\"start\":62639},{\"end\":62661,\"start\":62649},{\"end\":62672,\"start\":62661},{\"end\":62682,\"start\":62672},{\"end\":62693,\"start\":62682},{\"end\":62704,\"start\":62693},{\"end\":62715,\"start\":62704},{\"end\":62724,\"start\":62715},{\"end\":63084,\"start\":63075},{\"end\":63099,\"start\":63084},{\"end\":63399,\"start\":63390},{\"end\":63407,\"start\":63399},{\"end\":63417,\"start\":63407},{\"end\":63427,\"start\":63417},{\"end\":63750,\"start\":63742},{\"end\":63760,\"start\":63750},{\"end\":63771,\"start\":63760},{\"end\":63781,\"start\":63771},{\"end\":63787,\"start\":63781},{\"end\":63793,\"start\":63787},{\"end\":63805,\"start\":63793},{\"end\":63815,\"start\":63805},{\"end\":63825,\"start\":63815},{\"end\":64225,\"start\":64218},{\"end\":64233,\"start\":64225},{\"end\":64239,\"start\":64233},{\"end\":64246,\"start\":64239},{\"end\":64496,\"start\":64488},{\"end\":64505,\"start\":64496},{\"end\":64782,\"start\":64776},{\"end\":64788,\"start\":64782},{\"end\":64795,\"start\":64788},{\"end\":64801,\"start\":64795},{\"end\":64808,\"start\":64801},{\"end\":64816,\"start\":64808},{\"end\":64822,\"start\":64816},{\"end\":65194,\"start\":65182},{\"end\":65202,\"start\":65194},{\"end\":65208,\"start\":65202},{\"end\":65217,\"start\":65208},{\"end\":65223,\"start\":65217},{\"end\":65559,\"start\":65553},{\"end\":65567,\"start\":65559},{\"end\":65576,\"start\":65567},{\"end\":65582,\"start\":65576},{\"end\":65590,\"start\":65582},{\"end\":65906,\"start\":65899},{\"end\":65914,\"start\":65906},{\"end\":65921,\"start\":65914},{\"end\":65928,\"start\":65921},{\"end\":65936,\"start\":65928},{\"end\":66227,\"start\":66221},{\"end\":66235,\"start\":66227},{\"end\":66241,\"start\":66235},{\"end\":66249,\"start\":66241},{\"end\":66582,\"start\":66575},{\"end\":66589,\"start\":66582},{\"end\":66595,\"start\":66589},{\"end\":66930,\"start\":66917},{\"end\":66939,\"start\":66930},{\"end\":66951,\"start\":66939},{\"end\":66960,\"start\":66951},{\"end\":67358,\"start\":67349},{\"end\":67365,\"start\":67358},{\"end\":67373,\"start\":67365},{\"end\":67382,\"start\":67373},{\"end\":67390,\"start\":67382},{\"end\":67399,\"start\":67390},{\"end\":67408,\"start\":67399},{\"end\":68001,\"start\":67992},{\"end\":68009,\"start\":68001},{\"end\":68017,\"start\":68009},{\"end\":68025,\"start\":68017},{\"end\":68037,\"start\":68025},{\"end\":68046,\"start\":68037},{\"end\":68052,\"start\":68046},{\"end\":68060,\"start\":68052},{\"end\":68068,\"start\":68060},{\"end\":68080,\"start\":68068},{\"end\":68595,\"start\":68588},{\"end\":68603,\"start\":68595},{\"end\":68611,\"start\":68603},{\"end\":68618,\"start\":68611},{\"end\":68626,\"start\":68618},{\"end\":68961,\"start\":68952},{\"end\":68970,\"start\":68961},{\"end\":68976,\"start\":68970},{\"end\":68984,\"start\":68976},{\"end\":68991,\"start\":68984},{\"end\":68997,\"start\":68991},{\"end\":69005,\"start\":68997},{\"end\":69372,\"start\":69365},{\"end\":69381,\"start\":69372},{\"end\":69389,\"start\":69381},{\"end\":69396,\"start\":69389},{\"end\":69406,\"start\":69396},{\"end\":69773,\"start\":69762},{\"end\":69782,\"start\":69773},{\"end\":69795,\"start\":69782},{\"end\":69807,\"start\":69795},{\"end\":69820,\"start\":69807},{\"end\":70160,\"start\":70151},{\"end\":70168,\"start\":70160},{\"end\":70391,\"start\":70381},{\"end\":70401,\"start\":70391},{\"end\":70732,\"start\":70724},{\"end\":70739,\"start\":70732},{\"end\":70747,\"start\":70739},{\"end\":70757,\"start\":70747},{\"end\":70766,\"start\":70757},{\"end\":71190,\"start\":71180},{\"end\":71199,\"start\":71190},{\"end\":71208,\"start\":71199},{\"end\":71599,\"start\":71590},{\"end\":71611,\"start\":71599},{\"end\":71624,\"start\":71611},{\"end\":71633,\"start\":71624},{\"end\":71934,\"start\":71923},{\"end\":71945,\"start\":71934},{\"end\":72216,\"start\":72208},{\"end\":72228,\"start\":72216},{\"end\":72237,\"start\":72228},{\"end\":72590,\"start\":72581},{\"end\":72597,\"start\":72590},{\"end\":72606,\"start\":72597},{\"end\":73047,\"start\":73036},{\"end\":73060,\"start\":73047},{\"end\":73071,\"start\":73060},{\"end\":73460,\"start\":73450},{\"end\":73467,\"start\":73460},{\"end\":73476,\"start\":73467},{\"end\":73782,\"start\":73769},{\"end\":73792,\"start\":73782},{\"end\":73804,\"start\":73792},{\"end\":74117,\"start\":74108},{\"end\":74125,\"start\":74117},{\"end\":74133,\"start\":74125},{\"end\":74139,\"start\":74133},{\"end\":74406,\"start\":74400},{\"end\":74417,\"start\":74406},{\"end\":74426,\"start\":74417},{\"end\":74706,\"start\":74700},{\"end\":74713,\"start\":74706},{\"end\":74719,\"start\":74713},{\"end\":74726,\"start\":74719},{\"end\":74733,\"start\":74726},{\"end\":74742,\"start\":74733},{\"end\":75066,\"start\":75058},{\"end\":75073,\"start\":75066},{\"end\":75081,\"start\":75073},{\"end\":75087,\"start\":75081},{\"end\":75096,\"start\":75087},{\"end\":75496,\"start\":75487},{\"end\":75503,\"start\":75496},{\"end\":75509,\"start\":75503},{\"end\":75516,\"start\":75509},{\"end\":75523,\"start\":75516},{\"end\":75850,\"start\":75842},{\"end\":75862,\"start\":75850},{\"end\":75872,\"start\":75862},{\"end\":75881,\"start\":75872},{\"end\":76237,\"start\":76230},{\"end\":76243,\"start\":76237},{\"end\":76249,\"start\":76243},{\"end\":76258,\"start\":76249},{\"end\":76265,\"start\":76258},{\"end\":76273,\"start\":76265},{\"end\":76281,\"start\":76273},{\"end\":76688,\"start\":76676},{\"end\":76702,\"start\":76688},{\"end\":77121,\"start\":77114},{\"end\":77129,\"start\":77121},{\"end\":77136,\"start\":77129},{\"end\":77143,\"start\":77136},{\"end\":77461,\"start\":77446},{\"end\":77470,\"start\":77461},{\"end\":77481,\"start\":77470},{\"end\":77491,\"start\":77481},{\"end\":77505,\"start\":77491},{\"end\":77801,\"start\":77790},{\"end\":77810,\"start\":77801},{\"end\":77820,\"start\":77810},{\"end\":77833,\"start\":77820},{\"end\":78130,\"start\":78119},{\"end\":78139,\"start\":78130},{\"end\":78153,\"start\":78139},{\"end\":78420,\"start\":78407},{\"end\":78431,\"start\":78420},{\"end\":78443,\"start\":78431},{\"end\":78902,\"start\":78888},{\"end\":78913,\"start\":78902},{\"end\":78929,\"start\":78913},{\"end\":78940,\"start\":78929},{\"end\":79245,\"start\":79238},{\"end\":79255,\"start\":79245},{\"end\":79264,\"start\":79255},{\"end\":79609,\"start\":79603},{\"end\":79615,\"start\":79609},{\"end\":79624,\"start\":79615},{\"end\":79632,\"start\":79624},{\"end\":79924,\"start\":79918},{\"end\":79932,\"start\":79924},{\"end\":79941,\"start\":79932},{\"end\":79949,\"start\":79941},{\"end\":79956,\"start\":79949},{\"end\":80302,\"start\":80295},{\"end\":80308,\"start\":80302},{\"end\":80315,\"start\":80308},{\"end\":80648,\"start\":80641},{\"end\":80654,\"start\":80648},{\"end\":80663,\"start\":80654},{\"end\":80670,\"start\":80663},{\"end\":80678,\"start\":80670},{\"end\":80989,\"start\":80981},{\"end\":80998,\"start\":80989},{\"end\":81344,\"start\":81336},{\"end\":81352,\"start\":81344},{\"end\":81361,\"start\":81352},{\"end\":81367,\"start\":81361},{\"end\":81911,\"start\":81904},{\"end\":81919,\"start\":81911},{\"end\":81930,\"start\":81919},{\"end\":81941,\"start\":81930},{\"end\":82310,\"start\":82304},{\"end\":82317,\"start\":82310},{\"end\":82584,\"start\":82566},{\"end\":82601,\"start\":82584},{\"end\":82610,\"start\":82601},{\"end\":82920,\"start\":82913},{\"end\":82931,\"start\":82920},{\"end\":82940,\"start\":82931}]", "bib_venue": "[{\"end\":67587,\"start\":67506},{\"end\":68189,\"start\":68143},{\"end\":72723,\"start\":72673},{\"end\":73176,\"start\":73132},{\"end\":78585,\"start\":78521},{\"end\":82056,\"start\":82007},{\"end\":60027,\"start\":59986},{\"end\":60430,\"start\":60371},{\"end\":60857,\"start\":60818},{\"end\":61169,\"start\":61156},{\"end\":61510,\"start\":61458},{\"end\":61943,\"start\":61892},{\"end\":62332,\"start\":62280},{\"end\":62754,\"start\":62724},{\"end\":63154,\"start\":63099},{\"end\":63455,\"start\":63427},{\"end\":63876,\"start\":63825},{\"end\":64268,\"start\":64246},{\"end\":64549,\"start\":64505},{\"end\":64877,\"start\":64822},{\"end\":65254,\"start\":65223},{\"end\":65614,\"start\":65590},{\"end\":65967,\"start\":65936},{\"end\":66301,\"start\":66249},{\"end\":66619,\"start\":66595},{\"end\":67001,\"start\":66960},{\"end\":67504,\"start\":67408},{\"end\":68141,\"start\":68080},{\"end\":68667,\"start\":68626},{\"end\":69062,\"start\":69005},{\"end\":69457,\"start\":69406},{\"end\":69861,\"start\":69820},{\"end\":70180,\"start\":70168},{\"end\":70451,\"start\":70401},{\"end\":70821,\"start\":70766},{\"end\":71271,\"start\":71208},{\"end\":71651,\"start\":71633},{\"end\":71953,\"start\":71945},{\"end\":72268,\"start\":72237},{\"end\":72671,\"start\":72606},{\"end\":73130,\"start\":73071},{\"end\":73500,\"start\":73476},{\"end\":73842,\"start\":73804},{\"end\":74178,\"start\":74139},{\"end\":74448,\"start\":74426},{\"end\":74762,\"start\":74742},{\"end\":75159,\"start\":75096},{\"end\":75574,\"start\":75523},{\"end\":75934,\"start\":75881},{\"end\":76333,\"start\":76281},{\"end\":76761,\"start\":76702},{\"end\":77187,\"start\":77143},{\"end\":77516,\"start\":77505},{\"end\":77850,\"start\":77833},{\"end\":78181,\"start\":78153},{\"end\":78519,\"start\":78443},{\"end\":78955,\"start\":78940},{\"end\":79322,\"start\":79264},{\"end\":79683,\"start\":79632},{\"end\":80000,\"start\":79956},{\"end\":80359,\"start\":80315},{\"end\":80698,\"start\":80678},{\"end\":81012,\"start\":80998},{\"end\":81334,\"start\":81171},{\"end\":82005,\"start\":81941},{\"end\":82302,\"start\":82233},{\"end\":82626,\"start\":82610},{\"end\":82911,\"start\":82825},{\"end\":83136,\"start\":83082}]"}}}, "year": 2023, "month": 12, "day": 17}