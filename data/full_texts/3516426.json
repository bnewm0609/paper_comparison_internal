{"id": 3516426, "updated": "2023-07-19 13:54:03.576", "metadata": {"title": "Identifying Medical Diagnoses and Treatable Diseases by Image-Based Deep Learning", "authors": "[{\"first\":\"Daniel\",\"last\":\"Kermany\",\"middle\":[\"S.\"]},{\"first\":\"Michael\",\"last\":\"Goldbaum\",\"middle\":[]},{\"first\":\"Wenjia\",\"last\":\"Cai\",\"middle\":[]},{\"first\":\"Carolina\",\"last\":\"Valentim\",\"middle\":[\"C.S.\"]},{\"first\":\"Huiying\",\"last\":\"Liang\",\"middle\":[]},{\"first\":\"Sally\",\"last\":\"Baxter\",\"middle\":[\"L.\"]},{\"first\":\"Alex\",\"last\":\"McKeown\",\"middle\":[]},{\"first\":\"Ge\",\"last\":\"Yang\",\"middle\":[]},{\"first\":\"Xiaokang\",\"last\":\"Wu\",\"middle\":[]},{\"first\":\"Fangbing\",\"last\":\"Yan\",\"middle\":[]},{\"first\":\"Justin\",\"last\":\"Dong\",\"middle\":[]},{\"first\":\"Made\",\"last\":\"Prasadha\",\"middle\":[\"K.\"]},{\"first\":\"Jacqueline\",\"last\":\"Pei\",\"middle\":[]},{\"first\":\"Magdalene\",\"last\":\"Ting\",\"middle\":[\"Y.L.\"]},{\"first\":\"Jie\",\"last\":\"Zhu\",\"middle\":[]},{\"first\":\"Christina\",\"last\":\"Li\",\"middle\":[]},{\"first\":\"Sierra\",\"last\":\"Hewett\",\"middle\":[]},{\"first\":\"Jason\",\"last\":\"Dong\",\"middle\":[]},{\"first\":\"Ian\",\"last\":\"Ziyar\",\"middle\":[]},{\"first\":\"Alexander\",\"last\":\"Shi\",\"middle\":[]},{\"first\":\"Runze\",\"last\":\"Zhang\",\"middle\":[]},{\"first\":\"Lianghong\",\"last\":\"Zheng\",\"middle\":[]},{\"first\":\"Rui\",\"last\":\"Hou\",\"middle\":[]},{\"first\":\"William\",\"last\":\"Shi\",\"middle\":[]},{\"first\":\"Xin\",\"last\":\"Fu\",\"middle\":[]},{\"first\":\"Yaou\",\"last\":\"Duan\",\"middle\":[]},{\"first\":\"Viet\",\"last\":\"Huu\",\"middle\":[\"A.N.\"]},{\"first\":\"Cindy\",\"last\":\"Wen\",\"middle\":[]},{\"first\":\"Edward\",\"last\":\"Zhang\",\"middle\":[\"D.\"]},{\"first\":\"Charlotte\",\"last\":\"Zhang\",\"middle\":[\"L.\"]},{\"first\":\"Oulan\",\"last\":\"Li\",\"middle\":[]},{\"first\":\"Xiaobo\",\"last\":\"Wang\",\"middle\":[]},{\"first\":\"Michael\",\"last\":\"Singer\",\"middle\":[\"A.\"]},{\"first\":\"Xiaodong\",\"last\":\"Sun\",\"middle\":[]},{\"first\":\"Jie\",\"last\":\"Xu\",\"middle\":[]},{\"first\":\"Ali\",\"last\":\"Tafreshi\",\"middle\":[]},{\"first\":\"M.\",\"last\":\"Lewis\",\"middle\":[\"Anthony\"]},{\"first\":\"Huimin\",\"last\":\"Xia\",\"middle\":[]},{\"first\":\"Kang\",\"last\":\"Zhang\",\"middle\":[]}]", "venue": "Cell", "journal": "Cell", "publication_date": {"year": 2018, "month": 2, "day": 22}, "abstract": "The implementation of clinical-decision support algorithms for medical imaging faces challenges with reliability and interpretability. Here, we establish a diagnostic tool based on a deep-learning framework for the screening of patients with common treatable blinding retinal diseases. Our framework utilizes transfer learning, which trains a neural network with a fraction of the data of conventional approaches. Applying this approach to a dataset of optical coherence tomography images, we demonstrate performance comparable to that of human experts in classifying age-related\u00a0macular degeneration and diabetic macular\u00a0edema. We also provide a more transparent and\u00a0interpretable diagnosis by highlighting the regions recognized by the neural network. We further demonstrate the general applicability of our AI system for diagnosis of pediatric pneumonia\u00a0using chest X-ray images. This tool may ultimately aid in expediting the diagnosis and referral\u00a0of these treatable conditions, thereby facilitating earlier treatment, resulting in improved clinical outcomes. VIDEO ABSTRACT.", "fields_of_study": "[\"Medicine\"]", "external_ids": {"arxiv": null, "mag": "2788633781", "acl": null, "pubmed": "29474911", "pubmedcentral": null, "dblp": null, "doi": "10.1016/j.cell.2018.02.010"}}, "content": {"source": {"pdf_hash": "5ad51545fe855138203e9584362765a5169967de", "pdf_src": "Elsevier", "pdf_uri": "[\"https://api.elsevier.com/content/article/pii/S0092867418301545\",\"https://www.sciencedirect.com/science/article/pii/S0092867418301545?dgcid=api_sd_search-api-endpoint\"]", "oa_url_match": false, "oa_info": {"license": "elsevier-specific: oa user license", "open_access_url": "http://www.cell.com/article/S0092867418301545/pdf", "status": "BRONZE"}}, "grobid": {"id": "9277b3d303c5e691aa0a69c84a90d0b64df1235a", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/5ad51545fe855138203e9584362765a5169967de.txt", "contents": "\nIdentifying Medical Diagnoses and Treatable Diseases by Image-Based Deep Learning Resource Identifying Medical Diagnoses and Treatable Diseases by Image-Based Deep Learning\n2018. 1122-1131 February 22. 2018\n\nDaniel S Kermany \nMichael Goldbaum \nWenjia Cai \nM Anthony Lewis \nHuimin Xia \nZhang Kang kang.zhang@gmail.com \nCorrespondence \nDaniel S Kermany \nGuangzhou Women and Children's Medical Center\nGuangzhou Medical University\n510005GuangzhouChina\n\nShiley Eye Institute\nInstitute for Engineering in Medicine\nInstitute for Genomic Medicine\nUniversity of California\nSan Diego, La Jolla92093CAUSA\n\nMichael Goldbaum \nShiley Eye Institute\nInstitute for Engineering in Medicine\nInstitute for Genomic Medicine\nUniversity of California\nSan Diego, La Jolla92093CAUSA\n\nWenjia Cai \nShiley Eye Institute\nInstitute for Engineering in Medicine\nInstitute for Genomic Medicine\nUniversity of California\nSan Diego, La Jolla92093CAUSA\n\nCarolina C S Valentim \nShiley Eye Institute\nInstitute for Engineering in Medicine\nInstitute for Genomic Medicine\nUniversity of California\nSan Diego, La Jolla92093CAUSA\n\nHuiying Liang \nGuangzhou Women and Children's Medical Center\nGuangzhou Medical University\n510005GuangzhouChina\n\nSally L Baxter \nShiley Eye Institute\nInstitute for Engineering in Medicine\nInstitute for Genomic Medicine\nUniversity of California\nSan Diego, La Jolla92093CAUSA\n\nAlex Mckeown \nHeidelberg Engineering\nHeidelbergGermany\n\nGe Yang \nShiley Eye Institute\nInstitute for Engineering in Medicine\nInstitute for Genomic Medicine\nUniversity of California\nSan Diego, La Jolla92093CAUSA\n\nXiaokang Wu \nMolecular Medicine Research Center\nThe National Clinical Research Center of Senile Disease\nState Key Laboratory of Biotherapy\nWest China Hospital\nSichuan University\nChengduChina\n\nFangbing Yan \nMolecular Medicine Research Center\nThe National Clinical Research Center of Senile Disease\nState Key Laboratory of Biotherapy\nWest China Hospital\nSichuan University\nChengduChina\n\nJustin Dong \nGuangzhou Women and Children's Medical Center\nGuangzhou Medical University\n510005GuangzhouChina\n\nMade K Prasadha \nShiley Eye Institute\nInstitute for Engineering in Medicine\nInstitute for Genomic Medicine\nUniversity of California\nSan Diego, La Jolla92093CAUSA\n\nJacqueline Pei \nGuangzhou Women and Children's Medical Center\nGuangzhou Medical University\n510005GuangzhouChina\n\nShiley Eye Institute\nInstitute for Engineering in Medicine\nInstitute for Genomic Medicine\nUniversity of California\nSan Diego, La Jolla92093CAUSA\n\nMagdalene Y L Ting \nShiley Eye Institute\nInstitute for Engineering in Medicine\nInstitute for Genomic Medicine\nUniversity of California\nSan Diego, La Jolla92093CAUSA\n\nJie Zhu \nGuangzhou Women and Children's Medical Center\nGuangzhou Medical University\n510005GuangzhouChina\n\nGuangzhou KangRui Biological Pharmaceutical Technology Company\n510005GuangzhouChina\n\nChristina Li \nShiley Eye Institute\nInstitute for Engineering in Medicine\nInstitute for Genomic Medicine\nUniversity of California\nSan Diego, La Jolla92093CAUSA\n\nSierra Hewett \nGuangzhou Women and Children's Medical Center\nGuangzhou Medical University\n510005GuangzhouChina\n\nShiley Eye Institute\nInstitute for Engineering in Medicine\nInstitute for Genomic Medicine\nUniversity of California\nSan Diego, La Jolla92093CAUSA\n\nJason Dong \nGuangzhou Women and Children's Medical Center\nGuangzhou Medical University\n510005GuangzhouChina\n\nIan Ziyar \nShiley Eye Institute\nInstitute for Engineering in Medicine\nInstitute for Genomic Medicine\nUniversity of California\nSan Diego, La Jolla92093CAUSA\n\nAlexander Shi \nShiley Eye Institute\nInstitute for Engineering in Medicine\nInstitute for Genomic Medicine\nUniversity of California\nSan Diego, La Jolla92093CAUSA\n\nRunze Zhang \nShiley Eye Institute\nInstitute for Engineering in Medicine\nInstitute for Genomic Medicine\nUniversity of California\nSan Diego, La Jolla92093CAUSA\n\nLianghong Zheng \nYouHealth AI\n510005GuangzhouChina\n\nRui Hou \nGuangzhou KangRui Biological Pharmaceutical Technology Company\n510005GuangzhouChina\n\nWilliam Shi \nShiley Eye Institute\nInstitute for Engineering in Medicine\nInstitute for Genomic Medicine\nUniversity of California\nSan Diego, La Jolla92093CAUSA\n\nXin Fu \nGuangzhou Women and Children's Medical Center\nGuangzhou Medical University\n510005GuangzhouChina\n\nShiley Eye Institute\nInstitute for Engineering in Medicine\nInstitute for Genomic Medicine\nUniversity of California\nSan Diego, La Jolla92093CAUSA\n\nYaou Duan \nShiley Eye Institute\nInstitute for Engineering in Medicine\nInstitute for Genomic Medicine\nUniversity of California\nSan Diego, La Jolla92093CAUSA\n\nViet A N Huu \nGuangzhou Women and Children's Medical Center\nGuangzhou Medical University\n510005GuangzhouChina\n\nShiley Eye Institute\nInstitute for Engineering in Medicine\nInstitute for Genomic Medicine\nUniversity of California\nSan Diego, La Jolla92093CAUSA\n\nCindy Wen \nShiley Eye Institute\nInstitute for Engineering in Medicine\nInstitute for Genomic Medicine\nUniversity of California\nSan Diego, La Jolla92093CAUSA\n\nEdward D Zhang \nGuangzhou Women and Children's Medical Center\nGuangzhou Medical University\n510005GuangzhouChina\n\nShiley Eye Institute\nInstitute for Engineering in Medicine\nInstitute for Genomic Medicine\nUniversity of California\nSan Diego, La Jolla92093CAUSA\n\nCharlotte L Zhang \nOulan Li \nGuangzhou Women and Children's Medical Center\nGuangzhou Medical University\n510005GuangzhouChina\n\nShiley Eye Institute\nInstitute for Engineering in Medicine\nInstitute for Genomic Medicine\nUniversity of California\nSan Diego, La Jolla92093CAUSA\n\nXiaobo Wang \nGuangzhou Women and Children's Medical Center\nGuangzhou Medical University\n510005GuangzhouChina\n\nShiley Eye Institute\nInstitute for Engineering in Medicine\nInstitute for Genomic Medicine\nUniversity of California\nSan Diego, La Jolla92093CAUSA\n\nBeihai Hospital\n116021DalianChina\n\nMichael A Singer \nDepartment of Ophthalmology\nUniversity of Texas Health Science Center\n78229San AntonioTXUSA\n\nXiaodong Sun \nShanghai Key Laboratory of Ocular Fundus Diseases\nShanghai General Hospital\nShanghai JiaoTong University\n200080ShanghaiChina\n\nJie Xu \nBeijing Instute of Ophthalmology\nBeijing Tongren Eye Center\nBeijing Tongren Hospital\nCapital Medical University\nBeijingChina\n\nAli Tafreshi \nHeidelberg Engineering\nHeidelbergGermany\n\nM Anthony Lewis \n92121Qualcomm, San DiegoCAUSA\n\nHuimin Xia \nGuangzhou Women and Children's Medical Center\nGuangzhou Medical University\n510005GuangzhouChina\n\nKang Zhang \nGuangzhou Women and Children's Medical Center\nGuangzhou Medical University\n510005GuangzhouChina\n\nShiley Eye Institute\nInstitute for Engineering in Medicine\nInstitute for Genomic Medicine\nUniversity of California\nSan Diego, La Jolla92093CAUSA\n\nMolecular Medicine Research Center\nThe National Clinical Research Center of Senile Disease\nState Key Laboratory of Biotherapy\nWest China Hospital\nSichuan University\nChengduChina\n\nGuangzhou Regenerative Medicine and Health Guangdong Laboratory\n510005GuangzhouChina\n\nVeterans Administration Healthcare System\n92037San DiegoCAUSA\n\nIdentifying Medical Diagnoses and Treatable Diseases by Image-Based Deep Learning Resource Identifying Medical Diagnoses and Treatable Diseases by Image-Based Deep Learning\n\nCell\n1722018. 1122-1131 February 22. 201810.1016/j.cell.2018.02.010Resource 14 These authors contributed equally 15 Lead Contact *Correspondence:\nGraphical AbstractHighlights d An artificial intelligence system using transfer learning techniques was developed d It effectively classified images for macular degeneration and diabetic retinopathy d It also accurately distinguished bacterial and viral pneumonia on chest X-rays d This has potential for generalized high-impact application in biomedical imaging\n\nCorrespondence\n kang.zhang@gmail.com \nIn Brief Image-based deep learning classifies macular degeneration and diabetic retinopathy using retinal optical coherence tomography images and has potential for generalized applications in biomedical image interpretation and medical decision making.\n\n\nSUMMARY\n\nThe implementation of clinical-decision support algorithms for medical imaging faces challenges with reliability and interpretability. Here, we establish a diagnostic tool based on a deep-learning framework for the screening of patients with common treatable blinding retinal diseases. Our framework utilizes transfer learning, which trains a neural network with a fraction of the data of conventional approaches. Applying this approach to a dataset of optical coherence tomography images, we demonstrate performance comparable to that of human experts in classifying agerelated macular degeneration and diabetic macular edema. We also provide a more transparent and interpretable diagnosis by highlighting the regions recognized by the neural network. We further demonstrate the general applicability of our AI system for diagnosis of pediatric pneumonia using chest X-ray images. This tool may ultimately aid in expediting the diagnosis and referral of these treatable conditions, thereby facilitating earlier treatment, resulting in improved clinical outcomes.\n\n\nINTRODUCTION\n\nArtificial intelligence (AI) has the potential to revolutionize disease diagnosis and management by performing classification difficult for human experts and by rapidly reviewing immense amounts of images. Despite its potential, clinical interpretability and feasible preparation of AI remains challenging.\n\nThe traditional algorithmic approach to image analysis for classification previously relied on (1) handcrafted object segmentation, followed by (2) identification of each segmented object using statistical classifiers or shallow neural computational machine-learning classifiers designed specifically for each class of objects, and finally (3) classification of the image (Goldbaum et al., 1996). Creating and refining multiple classifiers required many skilled people and much time and was computationally expensive (Chaudhuri et al., 1989;Hoover and Goldbaum, 2003;Hoover et al., 2000).\n\nThe development of convolutional neural network layers has allowed for significant gains in the ability to classify images and detect objects in a picture (Krizhevsky et al., 2017;Zeiler and Fergus, 2014). These are multiple processing layers to which image analysis filters, or convolutions, are applied. The abstracted representation of images within each layer is constructed by systematically convolving multiple filters across the image, producing a feature map that is used as input to the following layer. This architecture makes it possible to process images in the form of pixels as input and to give the desired classification as output. The image-to-classification approach in one classifier replaces the multiple steps of previous image analysis methods.\n\nOne method of addressing a lack of data in a given domain is to leverage data from a similar domain, a technique known as transfer learning. Transfer learning has proven to be a highly effective technique, particularly when faced with domains with limited data (Donahue et al., 2013;Razavian et al., 2014;Yosinski et al., 2014). Rather than training a completely blank network, by using a feed-forward approach to fix the weights in the lower levels already optimized to recognize the structures found in images in general and retraining the weights of the upper levels with back propagation, the model can recognize the distinguishing features of a specific category of images, such as images of the eye, much faster and with significantly fewer training examples and less computational power (Figure 1).\n\nIn this study, we sought to develop an effective transfer learning algorithm to process medical images to provide an accurate and timely diagnosis of key pathology in each image. The primary illustration of this technique involved optical coherence Schematic depicting how a convolutional neural network trained on the ImageNet dataset of 1,000 categories can be adapted to significantly increase the accuracy and shorten the training duration of a network trained on a novel dataset of OCT images. The locally connected (convolutional) layers are frozen and transferred into a new network, while the final, fully connected layers are recreated and retrained from random initialization on top of the transferred layers. tomography (OCT) images of the retina, but the algorithm was also tested in a cohort of pediatric chest radiographs to validate the generalizability of this technique across multiple imaging modalities.\n\n\nRESULTS\n\nThe primary application of our transfer learning algorithm was in the diagnosis of retinal OCT images. Spectral-domain OCT uses light to capture high-resolution in vivo optical cross sections of the retina that can be assembled into three-dimensional-volume images of living retinal tissue. It has become one of the most commonly performed medical imaging procedures, with approximately 30 million OCT scans performed each year worldwide (Swanson and Fujimoto, 2017). OCT imaging is now a standard of care for guiding the diagnosis and treatment of some of the leading causes of blindness worldwide: age-related macular degeneration (AMD) and diabetic macular edema. Almost 10 million individuals suffer from AMD in the United States, and each year, more than 200,000 people develop choroidal neovascularization, a severe blinding form of advanced AMD (Ferrara, 2010;Friedman et al., 2004;Wong et al., 2014). In addition, nearly 750,000 individuals aged 40 or older suffer from diabetic macular edema (Varma et al., 2014), a vision-threatening form of diabetic retinopathy that involves the accumulation of fluid in the central retina. The prevalence of these diseases will likely increase even further over time due to the aging population and the global diabetes epidemic. Fortunately, the advent and widespread utilization of anti-vascular endothelial growth factor (anti-VEGF) medications has revolutionized the treatment of exudative retinal diseases (Kaiser et al., 2007;Ferrara, 2010), allowing patients to retain useful vision and quality of life. OCT is critical to guiding the administration of anti-VEGF therapy by providing a clear cross-sectional representation of the retinal pathology in these conditions (Figure 2A), allowing visualization of individual retinal layers, which is impossible with clinical examination by the human eye or by color fundus photography.\n\n\nPatient and Image Characteristics\n\nWe initially obtained 207,130 OCT images. 108,312 images (37,206 with choroidal neovascularization, 11,349 with diabetic macular edema, 8,617 with drusen, and 51,140 normal) from 4,686 patients passed initial image quality review and were used to train the AI system. The model was tested with 1,000 images (250 from each category) from 633 patients. Patient characteristics for each diagnosis category are listed in Table S1. After 100 epochs (iterations through the entire dataset), the training was stopped due to the absence of further improvement in both accuracy ( Figure 3A) and cross-entropy loss ( Figure 3B).\n\n\nPerformance of the Model\n\nWe evaluated our AI system in diagnosing the most common blinding retinal diseases. This AI system categorized images with choroidal neovascularization and images with diabetic macular edema as ''urgent referrals.'' These conditions would demand relatively urgent referral to an ophthalmologist for definitive anti-VEGF treatment; if treatment is delayed, there is coherence tomography (OCT) images through the labeling and grading process followed by creation of the transfer learning model, which then underwent training and subsequent testing. The training dataset only included images that passed sufficient quality and diagnostic standards from the initial collected dataset. See also Table S1. increased risk of bleeding, scarring, or other downstream complications that cause irreversible vision impairment. The system categorized images with drusen, which are lipid deposits present in the dry form of macular degeneration, as ''routine referrals.'' Anti-VEGF medications are not indicated for dry macular degeneration; therefore, referral to an eye specialist for drusen is less urgent. Normal images were labeled for ''observation.'' In a multi-class comparison between choroidal neovascularization, diabetic macular edema, drusen, and normal, we achieved an accuracy of 96.6% (Figure 4), with a sensitivity of 97.8%, a specificity of 97.4%, and a weighted error of 6.6%. Receiver operating characteristic (ROC) curves were generated to evaluate the model's ability to distinguish urgent referrals (defined as choroidal neovascularization or diabetic macular edema) from drusen and normal exams. The area under the ROC curve was 99.9% ( Figure 4).\n\nWe also trained a ''limited model'' classifying between the same four categories but only using 1,000 images randomly selected from each class during training to compare transfer learning performance using limited data compared to results using a large dataset. Using the same testing images, the model achieved an accuracy of 93.4%, with a sensitivity of 96.6%, a specificity of 94.0%, and a weighted error of 12.7%. The ROC curves distinguishing urgent referrals (i.e., distinguishing images with choroidal neovascularization or diabetic macular edema from normal images had an area under the curve of 98.8%.\n\nBinary classifiers were also implemented to compare choroidal neovascularization/diabetic macular edema/drusen from normal Accuracy is plotted against the training step (A), and cross-entropy loss is plotted against the training step (B) during the length of the training of the multi-class classifier over the course of 10,000 steps. Plots were normalized with a smoothing factor of 0.6 to clearly visualize trends. The validation accuracy and loss show better performance, since images with more noise and lower quality were also included in the training set to reduce overfitting and help generalization of the classifier. Training dataset: orange. Validation dataset: blue. See also Figure S1.\n\nusing the same datasets in order to determine a breakdown of the model's performance ( Figure S1). The classifier distinguishing choroidal neovascularization images from normal images achieved an accuracy of 100.0%, with a sensitivity of 100.0% and specificity of 100.0%. The area under the ROC curve was 100.0% ( Figure S2A). The classifier distinguishing diabetic macular edema images from normal images achieved an accuracy of 98.2%, with a sensitivity of 96.8% and specificity of 99.6%. The area under the ROC curve was 99.87% ( Figure S2B). The classifier distinguishing drusen images from normal images achieved an accuracy of 99.0%, with a sensitivity of 98.0% and specificity of 99.2%. The area under the ROC curve was 99.96% ( Figure S2C).\n\n\nComparison of the Model with Human Experts\n\nAn independent test set of 1,000 images from 633 patients was used to compare the AI network's referral decisions with the decisions made by human experts. Six experts with significant clinical experience in an academic ophthalmology center were instructed to make a referral decision on each test patient using only the patient's OCT images. Performance on the clinically most important decision of distinguishing patients needing urgent referral (those with choroidal neovascularization or diabetic macular edema) compared to normal patients is displayed as a ROC curve, and this performance was comparable between the AI system and the human experts ( Figure 4A).\n\nHaving established a standard expert performance evaluation system, we next compared the potential impact of patient referral decisions between our network and human experts. The sensitivities and specificities of the experts were plotted on the ROC curve of the trained model, and the differences in diagnostic performance, measured by likelihood ratios, between the model and the human experts were determined to be statistically similar within a 95% confidence interval ( Figure S3). However, the pure error rate does not accurately reflect the impact that a wrong referral decision might have on the outcome of an individual patient. To illustrate, a false-positive result occurs when a patient is normal or has drusen but is inaccurately labeled as an urgent referral, and this can cause undue distress or unnecessary investigation for the patient and place extra burdens on the healthcare system. However, a false-negative result is far more serious, because in this instance, a patient with choroidal neovascularization or diabetic macular edema is not appropriately referred, which could result in irreversible visual loss. To account for these issues, weighted error scoring was incorporated during model evaluation and expert testing (Figure S4A). By assigning these penalty points to each decision made by the model and the experts, we computed the average error of each.\n\nThe best convolutional neural network model yielded a score of 6.6% under this weighted error system. The weighted error of the experts ranged from 0.4% to 10.5%, with a mean weighted error of 4.8% (Table S2). The exact breakdown of each expert's performance regarding the correlation of their predicted labels with the true labels is depicted as confusion matrices in Figure S4B. As seen in Figure 4, the best model outperformed some human experts based on this weighted scale and on the ROC curve.\n\n\nOcclusion Testing\n\nWe performed an occlusion test on 491 images to identify the areas contributing most to the neural network's assignment of the predicted diagnosis. This testing successfully identified the region of interest in 94.7% of images that contributed the highest importance to the deep-learning algorithm ( Figure 5A; see also Figure S5 for additional examples). Drusen were located correctly through occlusion testing in 100% of all the images, while choroidal neovascularization yielded an accuracy of 94.0% and diabetic macular edema yielded an accuracy of 91.0% (Table S3). Furthermore, these regions identified by occlusion testing were also verified by human experts to be the most clinically significant areas of pathology.\n\n\nApplication of the AI System for Pneumonia Detection Using Chest X-Ray Images\n\nTo investigate the generalizability of our AI system in the diagnosis of common diseases, we applied the same transfer learning framework to the diagnosis of pediatric pneumonia. According to the World Health Organization (WHO), pneumonia kills about 2 million children under 5 years old every year and is consistently estimated as the single leading cause of childhood mortality (Rudan et al., 2008), killing more children than HIV/AIDS, malaria, and measles combined (Adegbola, 2012). The WHO reports that nearly all cases (95%) of new-onset childhood clinical pneumonia occur in developing countries, particularly in Southeast Asia and Africa. Bacterial and viral pathogens are the two leading causes of pneumonia (Mcluckie, 2009) but require very different forms of management. Bacterial pneumonia requires urgent referral for immediate antibiotic treatment, while viral pneumonia is treated with supportive care. Therefore, accurate and timely diagnosis is imperative. One key element of diagnosis is radiographic data, since chest X-rays are routinely obtained as standard of care and can help differentiate between different types of pneumonia ( Figure S6). However, rapid radiologic interpretation of images is not always available, particularly in the low-resource settings where childhood pneumonia has the highest incidence and highest rates of mortality. To this end, we also investigated the effectiveness of our transfer learning framework in classifying pediatric chest X-rays to detect pneumonia and furthermore to distinguish viral and bacterial pneumonia to facilitate rapid referrals for children needing urgent intervention.\n\nWe collected and labeled a total of 5,232 chest X-ray images from children, including 3,883 characterized as depicting pneumonia (2,538 bacterial and 1,345 viral) and 1,349 normal, from a total of 5,856 patients to train the AI system. The model was then tested with 234 normal images and 390 pneumonia images (242 bacterial and 148 viral) from 624 patients. After 100 epochs (iterations through the entire dataset) of the model, the training was stopped due to the absence of further improvement in both loss and accuracy ( Figures 6A and 6B).\n\nIn the comparison of chest X-rays presenting as pneumonia versus normal, we achieved an accuracy of 92.8%, with a sensitivity of 93.2% and a specificity of 90.1%. The area under the ROC curve for detection of pneumonia from normal was 96.8% ( Figure 6E). Binary comparison of bacterial and viral pneumonia resulted in a test accuracy of 90.7%, with a sensitivity of 88.6% and a specificity of 90.9% (Figures 6C and 6D). The area under the ROC curve for distinguishing bacterial and viral pneumonia was 94.0% ( Figure 6F).\n\n\nDISCUSSION\n\nIn this study, we describe a general AI platform for the diagnosis and referral of two common causes of severe vision loss: diabetic macular edema and choroidal neovascularization seen in neovascular AMD. By employing a transfer learning algorithm, our model demonstrated competitive performance of OCT image analysis without the need for a highly specialized deeplearning machine and without a database of millions of example images (STAR Methods). Moreover, the model's performance in diagnosing retinal OCT images was comparable to that of human experts with significant clinical experience with retinal diseases. When the model was trained with a much smaller number of images (about 1,000 from each class), it retained high performance in accuracy, sensitivity, specificity, and area under the ROC curve for achieving the correct diagnosis and referral, thereby illustrating the power of the transfer learning system to make highly effective classifications, even with a very limited training dataset.\n\nAlthough our AI platform was trained and validated using the Heidelberg Spectralis imaging system, the Digital Imaging and Communications in Medicine (DICOM) standards make the OCT images from different manufacturers (e.g., Zeiss and Optovue) reasonably consistent. The goal of this preliminary approach was to develop a system and demonstrate the soundness of the methods. Future studies could entail the use of images from different manufacturers in both the training and testing datasets so that the system will be universally useful. Moreover, the efficacy of the transfer learning technique for image analysis very likely extends beyond the realm of OCT images and ophthalmology-in principle, the techniques we have described here could potentially be employed in a wide range of medical images across multiple disciplines, and in fact, we provide a direct illustration of its wide applicability by demonstrating its efficacy in analysis of chest X-ray images.\n\nOcclusion testing was performed to identify the areas of greatest importance used by the model in assigning a diagnosis. The greatest benefit of an occlusion test is that it reveals insights into the decisions of neural networks, which are infamously known as ''black boxes'' with no transparency. Since this test was performed after training was completed, it demystified the algorithm without affecting its results. The occlusion test also confirmed that the network made its decisions using accurate distinguishing features, which can be shared with a healthcare professional. All areas containing drusen were recognized correctly on all images used for testing, while the diabetic macular edema and choroidal neovascularization occlusion tests occasionally did not present a clear point of interest. This is likely due to the lesions and fluid pockets of choroidal neovascularization and diabetic macular edema sometimes presenting much larger than the occlusion window, while drusen tend to be smaller in size.\n\n\nFigure 5. Occlusion Maps and Longitudinal Follow-up OCT Images Comparing Retinal Structural Changes before and after Anti-VEGF Therapy\n\n(A) Occlusion maps highlighting areas of pathology in diabetic macular edema (left), choroidal neovascularization (middle), and drusen (right). An occlusion map was generated by convolving an occluding kernel across the input image. The occlusion map is created after prediction by assigning the softmax probability of the correct label to each occluded area. The occlusion map can then be superimposed on the input image to highlight the areas the model considered important in making its diagnosis. (B and C) Horizontal cross-section OCT images through the fovea of patients with wet AMD (B) or diabetic retinopathy with macular edema (C) before and after three monthly intravitreal injections of bevacizumab. Both intraretinal and subretinal fluid (white arrows) lessened after treatment. Scar tissue of choroidal neovascularization remained (arrow heads). All visual accurity (VA) was improved: 20/320 to 20/250, 5 months (patient 1); 20/40 to 20/32, 9 months (patient 2); 20/400 to 20/250, 3 months (patient 3); 20/80 to 20/50, 7 months (patient 4); 20/40 to 20/25; 7 months (patient 5); and 20/32 to 20/25, 7 months (patient 6). See also Figure S5 and Table S3.\n\nAlthough transfer learning allows the training of a highly accurate model with a relatively small training dataset, its performance would be inferior to that of a model trained from a random initialization on an extremely large dataset of OCT images, since even the internal weights can be directly optimized for OCT feature detection. However, in practice, a new convolutional neural network trained from random initialization, even with an unlimited supply of training data, would require weeks to achieve a good accuracy, whereas the multi-class holdout model implemented using transfer learning finished training and testing on different data in under 2 hr. Each binary classification and the limited model converged to a high accuracy in under 30 min. Since medical images are difficult to collect in the large amounts necessary to train a blank convolutional neural network, transfer learning using a pre-trained model trained on millions of various medical images would likely yield a more accurate model in much less time when retraining layers for other medical classifications.\n\nThe performance of our model depends highly on the weights of the pre-trained model. Therefore, the performance of this model would likely be enhanced when tested on a larger ImageNet dataset with more advanced deep-learning techniques and architecture. Further, the rapid progression and development of the field of convolutional neural networks applied outside of medical imaging would also improve the performance of our approach. Finally, as mentioned earlier, we use OCT imaging as a demonstration of a generalized approach in medical image interpretation and subsequent decision making. Our framework effectively identified potential pathology on a tissue map to make a referral decision with performance comparable to (and sometimes even better than) human experts, enabling timely diagnosis of the two most common causes of irreversible severe vision loss. OCT is particularly useful in the management of retinal diseases because it has become critical to guiding anti-VEGF treatment for the intraretinal and/or subretinal fluid seen in many retinal conditions. This fluid often cannot be clearly visualized by the examiner's eyes or by color fundus photography. In addition, the OCT appearance often correlates well with visual acuity. The presence of fluid is typically associated with worse visual acuity, which improves once the fluid is resolved with anti-VEGF treatment ( Figure 5B). As a testament to the value of this imaging modality, treatment decisions for exudative retinal diseases are now guided by OCT rather than by clinical examination or fundus photography, making this demonstration of AIguided classification of images more clinically relevant than prior studies that have analyzed retinal fundus photographs, such as that from Gulshan et al. (2016). Given that OCT imaging has played such a crucial role in guiding treatment, extending the application of AI beyond diagnosis or classification of images and into the realm of making treatment recommendations is a promising area of future investigation. Furthermore, our network represents a generalized platform that can potentially be applied to a wide range of medical imaging techniques (e.g., chest X-ray, MRI, computed tomography) to make a clinical diagnostic decision. We demonstrated this point by training our network on a dataset of chest X-ray images of pediatric pneumonia. Chest X-rays present a difficult classification task due to the relatively large amount of variable objects, specifically the imaged areas outside the lungs that are irrelevant to the diagnosis of pneumonia. The resulting high-accuracy model suggests that this AI system has the potential to effectively learn from increasingly complicated images with a high degree of generalization using a relatively small repository of data. By demonstrating efficacy with multiple imaging modalities and with a wide range of pathology, this transfer learning framework presents a compelling system for further exploration and analysis in biomedical imaging and more generalized application to an automated community-based AI system for the diagnosis and triage of common human diseases. By providing our data and codes in a publicly available database, we also hope that other biomedical researchers may use our work as a resource to improve the performance of future models and help drive the field forward. This could facilitate screening programs and create more efficient referral systems in all of medicine, particularly in remote or low-resource areas, leading to a broad clinical and public health impact.\n\n\nSTAR+METHODS\n\nDetailed methods are provided in the online version of this paper and include the following:  \nd KEY RESOURCES\n\nSTAR+METHODS KEY RESOURCES TABLE CONTACT FOR REAGENT AND RESOURCE SHARING\n\nFurther information and requests for resources and classifiers should be directed to and will be fulfilled by the Lead Contact, Kang Zhang (kang.zhang@gmail.com). There are no restrictions for use of the materials disclosed.\n\n\nEXPERIMENTAL MODEL AND SUBJECT DETAILS\n\n\nImages from Human Subjects\n\nOptical coherence tomography (OCT) images (Spectralis OCT, Heidelberg Engineering, Germany) were selected from retrospective cohorts of adult patients from the Shiley Eye Institute of the University of California San Diego, the California Retinal Research Foundation, Medical Center Ophthalmology Associates, the Shanghai First People's Hospital, and Beijing Tongren Eye Center between July 1, 2013 and March 1, 2017. All OCT imaging was performed as part of patients' routine clinical care. There were no exclusion criteria based on age, gender, or race. We searched local electronic medical record databases for diagnoses of choroidal neovascularization, diabetic macular edema, drusen and normal to initially assign images. A horizontal foveal cut of OCT scans was downloaded with a standard image format according to manufacure's softwares and instructions. Chest X-ray images (anterior-posterior) were selected from retrospective cohorts of pediatric patients of one to five years old from Guangzhou Women and Children's Medical Center, Guangzhou. All chest X-ray imaging was performed as part of patients' routine clinical care. Institutional Review Board (IRB)/Ethics Committee approvals were obtained. The work was conducted in a manner compliant with the United States Health Insurance Portability and Accountability Act (HIPAA) and was adherent to the tenets of the Declaration of Helsinki.\n\n\nMETHOD DETAILS\n\nOCT examinations were interpreted to confirm a diagnosis, and referral decisions were made thereafter (''urgent referral'' for diagnoses of choroidal neovascularization or diabetic macular edema, ''routine referral'' for drusen, and ''observation only'' for normal). The dataset represents the most common medical retina patients presenting and receiving treatment at all participating clinics.\n\nChest X-ray examinations were interpreted to confirm a diagnosis, and referral decisions were made thereafter (''urgent referral'' for diagnoses of bacterial pneumonia, ''supportive care'' for viral pneumonia, and ''observation only'' for normal).\n\n\nImage Labeling\n\nBefore training, each image went through a tiered grading system consisting of multiple layers of trained graders of increasing expertise for verification and correction of image labels. Each image imported into the database started with a label matching the most recent diagnosis of the patient. The first tier of graders consisted of undergraduate and medical students who had taken and passed an OCT interpretation course review. This first tier of graders conducted initial quality control and excluded OCT images containing severe artifacts or significant image resolution reductions. The second tier of graders consisted of four ophthalmologists who independently graded each image that had passed the first tier. The presence or absence of choroidal neovascularization (active or in the form of subretinal fibrosis), macular edema, drusen, and other pathologies visible on the OCT scan were recorded. Finally, a third tier of two senior independent retinal specialists, each with over 20 years of clinical retina experience, verified the true labels for each image. The dataset selection and stratification process is displayed in a CONSORT-style diagram in Figure 2B. To account for human error in grading, a validation subset of 993 scans was graded separately by two ophthalmologist graders, with disagreement in clinical labels arbitrated by a senior retinal specialist.\n\nFor the analysis of chest X-ray images, all chest radiographs were initially screened for quality control by removing all low quality or unreadable scans. The diagnoses for the images were then graded by two expert physicians before being cleared for training the AI system. In order to account for any grading errors, the evaluation set was also checked by a third expert. REAGENT \n\n\nTransfer Learning Methods\n\nUsing the Tensorflow we adapted an Inception V3 architecture pretrained on the ImageNet dataset (Szegedy et al., 2016). Retraining consisted of initializing the convolutional layers with loaded pretrained weights and retraining the final, softmax layer to recognize our classes from scratch. In this study, the convolutional layers were frozen and used as fixed feature extractors. The convolutional ''bottlenecks'' are the values of each training and testing images after they have passed through the frozen layers of our model and since the convolutional weights are not updated, these values are initially calculated and stored in order to reduce redundant processes and speed up training. The newly initialized network, then, takes the image bottlenecks as input and retrains to classify our specific categories. Attempts at ''fine-tuning'' the convolutional layers by unfreezing and updating the pretrained weights on our medical images using backpropagation tended to decrease model performance due to overfitting (Figure 1). The Inception model was trained on an Ubuntu 16.04 computer with 2 Intel Xeon CPUs, using a NVIDIA GTX 1080 8Gb GPU for training and testing, with 256Gb available in RAM memory. Training of layers was performed by stochastic gradient descent in batches of 1,000 images per step using an Adam Optimizer with a learning rate of 0.001. Training on all categories was run for 10,000 steps, or 100 epochs, since training of the final layers will have converged by then for all classes. Holdout method testing was performed after every step using a test partition containing images from patients independent of the patients represented in the training partition by passing each image through the network without performing gradient descent and backpropagation, and the best performing model was kept for analysis.\n\n\nExpert Comparisons\n\nIn order to evaluate our model in the context of clinical experts, a validation set of 1000 images (633 patients), independent of the patients in the training set, was used to compare our network referral decisions with the decisions made by human experts. Weighted error scoring was used to reflect the fact that a false negative result (failing to refer) is more detrimental than a false positive result (making a referral when it was not warranted). Using these weighted penalty points, error rates were computed for the model and for each of the human experts.\n\n\nOcclusion Test\n\nSimilarly to the methods described by Lee et al. and Zeiler and Fergus, an occlusion test was performed to identify the areas contributing the most to the neural network's assignment of the predicted diagnosis (Lee et al., 2016;Zeiler and Fergus, 2014). A blank 20x20 pixel box was systematically moved across every possible position in the image and the probabilities of the disease were recorded. The highest drop in the probability represents the region of interest that contributed the highest importance to the deep learning algorithm ( Figure 5A, see also Figure S5 for additional examples).\n\n\nQUANTIFICATION AND STATISTICAL ANALYSIS\n\nThe 207,130 images collected were reduced to the 108,312 OCT images (from 4686 patients) and used for training the AI platform. Another subset of 633 patients not in the training set was collected based on a sample size requirement of 583 patients to detect sensitivity and specificity at 0.05 marginal error and 95% confidence. The test images (n = 1000) were used to evaluate model and human expert performance. Receiver operating characteristics (ROC) curves plot the true positive rate (sensitivity) versus the false positive rate (1 -specificity). ROC curves were generated using classification probabilities of urgent referral versus otherwise and the true labels of each test image and the ROC function of the Python scikit-learn library. The area under the ROC curve is a measure of performance and the true positive rate (TPR or sensitivity) at some chosen true negative rate (TNR or specificity) on the ROC curve is the probability that the classifier will rank a randomly chosen ''urgent referral'' instance higher than a randomly chosen normal or drusen instance. Accuracy was measured by dividing the number of correctly labeled images by the total number of test images. Sensitivity and specificity were determined by dividing the total number of correctly labeled urgent referrals and the total number of correctly labeled non-urgent referrals, respectively, by the total number of test images.\n\n\nDATA AND SOFTWARE AVAILABILITY\n\nAll deep learning methods were implemented using either TensorFlow (https://www.tensorflow.org). ImageNet, a public database of images, can be found at https://www.image-net.org. Dataset on high resolution JPEG OCT and chest X-ray images are deposited into the public Mendeley database (https://doi.org/10.17632/rscbjbr9sj.3).\n\nCell 172, 1122-1131.e1-e2, February 22, 2018 e2\n\nFigure 1 .\n1Schematic\n\nFigure 2 .\n2Representative Optical Coherence Tomography Images and the Workflow Diagram (A) (Far left) choroidal neovascularization (CNV) with neovascular membrane (white arrowheads) and associated subretinal fluid (arrows). (Middle left) Diabetic macular edema (DME) with retinal-thickening-associated intraretinal fluid (arrows). (Middle right) Multiple drusen (arrowheads) present in early AMD. (Far right) Normal retina with preserved foveal contour and absence of any retinal fluid/edema. (B) Workflow diagram showing overall experimental design describing the flow of optical\n\nFigure 3 .\n3Plot Showing Performance in the Training and Validation Datasets Using TensorBoard\n\nFigure 4 .\n4Multi-class Comparison between Choroidal Neovascularization, Diabetic Macular Edema, Drusen, and Normal (A) Receiver operating characteristic (ROC) curve for ''urgent referrals'' (CNV and DME detection) with human expert performance for comparison. The area under the ROC curve was 99.9%. The zoomed area shows that the most accurate model demonstrates a performance that rivals that of six human experts. (B) Confusion table of best model's classification of the validation image set. The model successfully scored all urgent referrals as higher than observation. (C) Weighted error results based on penalties inFigure S4depicting neural networks in gold and human experts in blue. See alsoFigures S2, S3, and S4 andTable S2.\n\nFigure 6 .\n6Plots Depicting Performance of Pneumonia Diagnosis using Chest X-Ray Images in the Training and Validation Datasets Using TensorBoard (A-F) Comparisons were made for pneumonia versus normal (A) with cross-entropy loss plotted against the training step (B), as well as comparisons between bacterial pneumonia and viral pneumonia (C) and the associated cross-entropy loss (D). Plots were normalized with a smoothing factor of 0.6 in order to clearly visualize trends. The area under the ROC curve for detecting pneumonia versus normal was 96.8% (E). The area under the ROC curve for detecting bacterial versus viral pneumonia was 94.0% (F). Training dataset: orange. Validation dataset: blue. See alsoFigure S6.\n\nACKNOWLEDGMENTS\nThis study was funded by the National Key Research and Development Program of China (2017YFC1104600), National Natural Science Foundation of China (81771629 and 81700882), Guangzhou Women and Children's Medical Center, Guangzhou Regenerative Medicine and Health Guangdong Laboratory, the Richard Annesser Fund, the Michael Martin Fund, and the Dick and Carol Hertzberg Fund. AUTHOR CONTRIBUTIONS D.S.K., M.A.L., W.C., Justin Dong, C.C.S.V., G.Y., H.L., A.M., X. Wu, F.Y., J.Z., S.L.B., M.K.P., J.P., A.S., M.Y.L.T., C.L., S.H., Jason Dong, R.Z., L.Z., R.H., W.S., X.F., Y.D., V.A.N.H., I.Z., C.W., X. Wang, E.D.Z., C.L.Z., O.L., J.X., A.T., X.S., M.A.S., and H.X. collected and analyzed the data. K.Z. conceived the project. K.Z., D.S.K., M.G., and S.L.B. wrote the manuscript. All authors discussed the results and reviewed the manuscript.DECLARATION OF INTERESTSextraction, object classification, and inferencing in retinal images. Proceedings of 3rd IEEE International Conference on Image Processing 3, 695-698.\n\nTABLE d CONTACT\ndFOR REAGENT AND RESOURCE SHARINGd EXPERIMENTAL MODEL AND SUBJECT DETAILS \nB Images from Human Subjects \nd METHOD DETAILS \nB Image Labeling \nB Transfer Learning Methods \nB Expert Comparisons \nB Occlusion Test \nd QUANTIFICATION AND STATISTICAL ANALYSIS \nd DATA AND SOFTWARE AVAILABILITY \n\nSUPPLEMENTAL INFORMATION \n\nSupplemental Information includes six figures and three tables and can be \nfound with this article online at https://doi.org/10.1016/j.cell.2018.02.010. \nA video abstract is available at http://dx.doi.org/10.1016/j.cell.2018.02. \n010#mmc2. \n\n\nThe authors declare no competing interests.Figure S2. Receiver Operating Characteristic Curves for Binary Classifiers, Related toFigure 4The corresponding area under the ROC curve (AUROC) for the graphs are 100% for choroidal neovascularization (CNV) versus normal (A), 99.87% for diabetic macular edema (DME) versus normal (B), and 99.96% for drusen versus normal (C). The straight vertical and horizontal lines in (A) and the nearly straight lines in (B) and (C) demonstrate that the binary convolutional neural network models have a near perfect classification performance.Figure S3. Plots Depicting the Positive and Negative Likelihood Ratios with Their Corresponding 95% Confidence Intervals Marked, Related toFigure 4(A) The positive likelihood ratio is defined as the true positive rate over the false positive rate, so that an increasing likelihood ratio greater than 1 indicates increasing probability that the predicted result is associated with the disease. (B) The negative likelihood ratio is defined as the false negative rate over the true negative rate, so that a decreasing likelihood ratio less than 1 indicates increasing probability that the predicted result is associated with the absence of disease. The confidence intervals show that the best trained model demonstrated statistically similar screening performance in when compared to human experts.(legend on next page)     The normal chest X-ray (left panel) depicts clear lungs without any areas of abnormal opacification in the image. Bacterial pneumonia (middle) typically exhibits a focal lobar consolidation, in this case in the right upper lobe (white arrows), whereas viral pneumonia (right) manifests with a more diffuse ''interstitial'' pattern in both lungs.\nChildhood pneumonia as a global health priority and the strategic interest of the Bill & Melinda Gates Foundation. R A Adegbola, Clin. Infect. Dis. 542SupplAdegbola, R.A. (2012). Childhood pneumonia as a global health priority and the strategic interest of the Bill & Melinda Gates Foundation. Clin. Infect. Dis. 54 (Suppl 2 ), S89-S92.\n\nDetection of blood vessels in retinal images using two-dimensional matched filters. S Chaudhuri, S Chatterjee, N Katz, M Nelson, M Goldbaum, IEEE Trans. Med. Imaging. 8Chaudhuri, S., Chatterjee, S., Katz, N., Nelson, M., and Goldbaum, M. (1989). Detection of blood vessels in retinal images using two-dimensional matched filters. IEEE Trans. Med. Imaging 8, 263-269.\n\nDeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition. J Donahue, Y Jia, O Vinyals, J Hoffman, N Zhang, E Tzeng, Darrell , T , Proceedings of the 31st International Conference on Machine Learning. the 31st International Conference on Machine Learning32Donahue, J., Jia, Y., Vinyals, O., Hoffman, J., Zhang, N., Tzeng, E., and Darrell, T. (2013). DeCAF: A Deep Convolutional Activation Feature for Generic Visual Recognition. Proceedings of the 31st International Conference on Machine Learning 32, 647-655.\n\nVascular endothelial growth factor and age-related macular degeneration: from basic science to therapy. N Ferrara, Nat. Med. 16Ferrara, N. (2010). Vascular endothelial growth factor and age-related macular degeneration: from basic science to therapy. Nat. Med. 16, 1107-1111.\n\nPrevalence of age-related macular degeneration in the United States. D S Friedman, B J O&apos;colmain, B Mu\u00f1 Oz, S C Tomany, C Mccarty, P T De Jong, B Nemesure, P Mitchell, J Kempen, Arch. Ophthalmol. 122Eye Diseases Prevalence Research GroupFriedman, D.S., O'Colmain, B.J., Mu\u00f1 oz, B., Tomany, S.C., McCarty, C., de Jong, P.T., Nemesure, B., Mitchell, P., and Kempen, J.; Eye Diseases Prev- alence Research Group (2004). Prevalence of age-related macular degenera- tion in the United States. Arch. Ophthalmol. 122, 564-572.\n\nAutomated diagnosis and image understanding with object. M Goldbaum, S Moezzi, A Taylor, S Chatterjee, J Boyd, E Hunter, R Jain, Goldbaum, M., Moezzi, S., Taylor, A., Chatterjee, S., Boyd, J., Hunter, E., and Jain, R. (1996). Automated diagnosis and image understanding with object\n\nDevelopment and Validation of a Deep Learning Algorithm for Detection of Diabetic Retinopathy in Retinal Fundus Photographs. V Gulshan, L Peng, M Coram, M C Stumpe, D Wu, A Narayanaswamy, S Venugopalan, K Widner, T Madams, J Cuadros, JAMA. 316Gulshan, V., Peng, L., Coram, M., Stumpe, M.C., Wu, D., Narayanaswamy, A., Venugopalan, S., Widner, K., Madams, T., Cuadros, J., et al. (2016). Develop- ment and Validation of a Deep Learning Algorithm for Detection of Diabetic Retinopathy in Retinal Fundus Photographs. JAMA 316, 2402-2410.\n\n. A Hoover, M Goldbaum, Hoover, A., and Goldbaum, M. (2003).\n\nLocating blood vessels in retinal images by piecewise threshold probing of a matched filter response. A Hoover, V Kouznetsova, M Goldbaum, IEEE Trans. Med. Imaging. 19Hoover, A., Kouznetsova, V., and Goldbaum, M. (2000). Locating blood ves- sels in retinal images by piecewise threshold probing of a matched filter response. IEEE Trans. Med. Imaging 19, 203-210.\n\nRanibizumab for predominantly classic neovascular age-related macular degeneration: subgroup analysis of first-year ANCHOR results. P K Kaiser, D M Brown, K Zhang, H L Hudson, F G Holz, H Shapiro, S Schneider, N R Acharya, Am. J. Ophthalmol. 144Kaiser, P.K., Brown, D.M., Zhang, K., Hudson, H.L., Holz, F.G., Shapiro, H., Schneider, S., and Acharya, N.R. (2007). Ranibizumab for predominantly classic neovascular age-related macular degeneration: subgroup analysis of first-year ANCHOR results. Am. J. Ophthalmol. 144, 850-857.\n\nImageNet classification with deep convolutional neural networks. A Krizhevsky, I Sutskever, G E Hinton, Commun. ACM. 60Krizhevsky, A., Sutskever, I., and Hinton, G.E. (2017). ImageNet classification with deep convolutional neural networks. Commun. ACM 60, 84-90.\n\nDeep Learning Is Effective for the Classification of OCT Images of Normal versus Age-Related Macular Degeneration. C S Lee, D M Baughman, A Y Lee, Ophthamol. Retina. 1Lee, C.S., Baughman, D.M., and Lee, A.Y. (2016). Deep Learning Is Effective for the Classification of OCT Images of Normal versus Age-Related Macular Degeneration. Ophthamol. Retina 1, 322-327.\n\nRespiratory disease and its management. A Mcluckie, Springer57Mcluckie, A. (2009). Respiratory disease and its management, Volume 57 (Springer).\n\nCNN Features Off-the-Shelf: An Astounding Baseline for Recognition. A S Razavian, H Azizpour, J Sullivan, Carlsson , S , 2014 IEEE Conference on Computer Vision and Pattern Recognition Workshops. Razavian, A.S., Azizpour, H., Sullivan, J., and Carlsson, S. (2014). CNN Features Off-the-Shelf: An Astounding Baseline for Recognition. In 2014 IEEE Conference on Computer Vision and Pattern Recognition Workshops, pp. 512-519.\n\nEpidemiology and etiology of childhood pneumonia. I Rudan, C Boschi-Pinto, Z Biloglav, K Mulholland, H Campbell, Bull. World Health Organ. 86Rudan, I., Boschi-Pinto, C., Biloglav, Z., Mulholland, K., and Campbell, H. (2008). Epidemiology and etiology of childhood pneumonia. Bull. World Health Organ. 86, 408-416.\n\nThe ecosystem that powered the translation of OCT from fundamental research to clinical and commercial impact. E A Swanson, J G Fujimoto, InvitedSwanson, E.A., and Fujimoto, J.G. (2017). The ecosystem that powered the translation of OCT from fundamental research to clinical and commercial impact [Invited].\n\n. Biomed. Opt. Express. 8Biomed. Opt. Express 8, 1638-1664.\n\nRethinking the Inception Architecture for Computer Vision. C Szegedy, V Vanhoucke, S Ioffe, J Shlens, Z Wojna, 2016 IWWW Conference on Computer Vision and Pattern Recognition. Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., and Wojna, Z. (2016). Rethinking the Inception Architecture for Computer Vision. In 2016 IWWW Conference on Computer Vision and Pattern Recognition, pp. 2818-2826.\n\nPrevalence of and risk factors for diabetic macular edema in the United States. R Varma, N M Bressler, Q V Doan, M Gleeson, M Danese, J K Bower, E Selvin, C Dolan, J Fine, S Colman, A Turpcu, JAMA Ophthalmol. 132Varma, R., Bressler, N.M., Doan, Q.V., Gleeson, M., Danese, M., Bower, J.K., Selvin, E., Dolan, C., Fine, J., Colman, S., and Turpcu, A. (2014). Prevalence of and risk factors for diabetic macular edema in the United States. JAMA Ophthalmol. 132, 1334-1340.\n\nGlobal prevalence of age-related macular degeneration and disease burden projection for 2020 and 2040: a systematic review and meta-analysis. W L Wong, X Su, X Li, C M Cheung, R Klein, C Y Cheng, T Y Wong, Lancet Glob. Health. 2Wong, W.L., Su, X., Li, X., Cheung, C.M., Klein, R., Cheng, C.Y., and Wong, T.Y. (2014). Global prevalence of age-related macular degeneration and dis- ease burden projection for 2020 and 2040: a systematic review and meta-anal- ysis. Lancet Glob. Health 2, e106-e116.\n\nJ Yosinski, J Clune, Y Bengio, H Lipson, How transferable are features in deep neural networks? NIPS'14 Proceedings of the 27th International Conference on Neural Information Processing Systems. 2Yosinski, J., Clune, J., Bengio, Y., and Lipson, H. (2014). How transferable are features in deep neural networks? NIPS'14 Proceedings of the 27th Interna- tional Conference on Neural Information Processing Systems 2, 3320-3328.\n\nVisualizing and Understanding Convolutional Networks. M D Zeiler, Fergus , R , Lect. Notes Comput. Sci. 8689Zeiler, M.D., and Fergus, R. (2014). Visualizing and Understanding Convolu- tional Networks. Lect. Notes Comput. Sci. 8689, 818-833.\n\nSupplemental Figures Figure S1. Plots Showing Binary Performance in the Training and Validation Datasets Using TensorBoard. Related to Figure 3Supplemental Figures Figure S1. Plots Showing Binary Performance in the Training and Validation Datasets Using TensorBoard, Related to Figure 3\n\nPlots were normalized with a smoothing factor of 0.6 in order to clearly visualize trends. The validation accuracy and loss shows better performance since images with more noise and lower quality were also included in the training set to reduce overfitting and help generalization of the classifier. Comparisons were made for choroidal neovascularization (CNV) versus normal (A). diabetic macular edema (DME) versus normal (B), and drusen versus normal (C). Training dataset: orange. Validation dataset: blueComparisons were made for choroidal neovascularization (CNV) versus normal (A), diabetic macular edema (DME) versus normal (B), and drusen versus normal (C). Plots were normalized with a smoothing factor of 0.6 in order to clearly visualize trends. The validation accuracy and loss shows better performance since images with more noise and lower quality were also included in the training set to reduce overfitting and help generalization of the classifier. Training dataset: orange. Validation dataset: blue.\n", "annotations": {"author": "[{\"end\":226,\"start\":209},{\"end\":244,\"start\":227},{\"end\":256,\"start\":245},{\"end\":273,\"start\":257},{\"end\":285,\"start\":274},{\"end\":318,\"start\":286},{\"end\":334,\"start\":319},{\"end\":595,\"start\":335},{\"end\":759,\"start\":596},{\"end\":917,\"start\":760},{\"end\":1086,\"start\":918},{\"end\":1198,\"start\":1087},{\"end\":1360,\"start\":1199},{\"end\":1416,\"start\":1361},{\"end\":1571,\"start\":1417},{\"end\":1763,\"start\":1572},{\"end\":1956,\"start\":1764},{\"end\":2066,\"start\":1957},{\"end\":2229,\"start\":2067},{\"end\":2488,\"start\":2230},{\"end\":2654,\"start\":2489},{\"end\":2845,\"start\":2655},{\"end\":3005,\"start\":2846},{\"end\":3263,\"start\":3006},{\"end\":3372,\"start\":3264},{\"end\":3529,\"start\":3373},{\"end\":3690,\"start\":3530},{\"end\":3849,\"start\":3691},{\"end\":3901,\"start\":3850},{\"end\":3995,\"start\":3902},{\"end\":4154,\"start\":3996},{\"end\":4405,\"start\":4155},{\"end\":4562,\"start\":4406},{\"end\":4819,\"start\":4563},{\"end\":4976,\"start\":4820},{\"end\":5235,\"start\":4977},{\"end\":5254,\"start\":5236},{\"end\":5507,\"start\":5255},{\"end\":5798,\"start\":5508},{\"end\":5909,\"start\":5799},{\"end\":6049,\"start\":5910},{\"end\":6183,\"start\":6050},{\"end\":6239,\"start\":6184},{\"end\":6287,\"start\":6240},{\"end\":6396,\"start\":6288},{\"end\":6979,\"start\":6397},{\"end\":226,\"start\":209},{\"end\":244,\"start\":227},{\"end\":256,\"start\":245},{\"end\":273,\"start\":257},{\"end\":285,\"start\":274},{\"end\":318,\"start\":286},{\"end\":334,\"start\":319},{\"end\":595,\"start\":335},{\"end\":759,\"start\":596},{\"end\":917,\"start\":760},{\"end\":1086,\"start\":918},{\"end\":1198,\"start\":1087},{\"end\":1360,\"start\":1199},{\"end\":1416,\"start\":1361},{\"end\":1571,\"start\":1417},{\"end\":1763,\"start\":1572},{\"end\":1956,\"start\":1764},{\"end\":2066,\"start\":1957},{\"end\":2229,\"start\":2067},{\"end\":2488,\"start\":2230},{\"end\":2654,\"start\":2489},{\"end\":2845,\"start\":2655},{\"end\":3005,\"start\":2846},{\"end\":3263,\"start\":3006},{\"end\":3372,\"start\":3264},{\"end\":3529,\"start\":3373},{\"end\":3690,\"start\":3530},{\"end\":3849,\"start\":3691},{\"end\":3901,\"start\":3850},{\"end\":3995,\"start\":3902},{\"end\":4154,\"start\":3996},{\"end\":4405,\"start\":4155},{\"end\":4562,\"start\":4406},{\"end\":4819,\"start\":4563},{\"end\":4976,\"start\":4820},{\"end\":5235,\"start\":4977},{\"end\":5254,\"start\":5236},{\"end\":5507,\"start\":5255},{\"end\":5798,\"start\":5508},{\"end\":5909,\"start\":5799},{\"end\":6049,\"start\":5910},{\"end\":6183,\"start\":6050},{\"end\":6239,\"start\":6184},{\"end\":6287,\"start\":6240},{\"end\":6396,\"start\":6288},{\"end\":6979,\"start\":6397}]", "publisher": null, "author_last_name": "[{\"end\":225,\"start\":218},{\"end\":243,\"start\":235},{\"end\":255,\"start\":252},{\"end\":272,\"start\":267},{\"end\":284,\"start\":281},{\"end\":296,\"start\":292},{\"end\":333,\"start\":319},{\"end\":351,\"start\":344},{\"end\":612,\"start\":604},{\"end\":770,\"start\":767},{\"end\":939,\"start\":931},{\"end\":1100,\"start\":1095},{\"end\":1213,\"start\":1207},{\"end\":1373,\"start\":1366},{\"end\":1424,\"start\":1420},{\"end\":1583,\"start\":1581},{\"end\":1776,\"start\":1773},{\"end\":1968,\"start\":1964},{\"end\":2082,\"start\":2074},{\"end\":2244,\"start\":2241},{\"end\":2507,\"start\":2503},{\"end\":2662,\"start\":2659},{\"end\":2858,\"start\":2856},{\"end\":3019,\"start\":3013},{\"end\":3274,\"start\":3270},{\"end\":3382,\"start\":3377},{\"end\":3543,\"start\":3540},{\"end\":3702,\"start\":3697},{\"end\":3865,\"start\":3860},{\"end\":3909,\"start\":3906},{\"end\":4007,\"start\":4004},{\"end\":4161,\"start\":4159},{\"end\":4415,\"start\":4411},{\"end\":4575,\"start\":4572},{\"end\":4829,\"start\":4826},{\"end\":4991,\"start\":4986},{\"end\":5253,\"start\":5248},{\"end\":5263,\"start\":5261},{\"end\":5519,\"start\":5515},{\"end\":5815,\"start\":5809},{\"end\":5922,\"start\":5919},{\"end\":6056,\"start\":6054},{\"end\":6196,\"start\":6188},{\"end\":6255,\"start\":6250},{\"end\":6298,\"start\":6295},{\"end\":6407,\"start\":6402},{\"end\":225,\"start\":218},{\"end\":243,\"start\":235},{\"end\":255,\"start\":252},{\"end\":272,\"start\":267},{\"end\":284,\"start\":281},{\"end\":296,\"start\":292},{\"end\":333,\"start\":319},{\"end\":351,\"start\":344},{\"end\":612,\"start\":604},{\"end\":770,\"start\":767},{\"end\":939,\"start\":931},{\"end\":1100,\"start\":1095},{\"end\":1213,\"start\":1207},{\"end\":1373,\"start\":1366},{\"end\":1424,\"start\":1420},{\"end\":1583,\"start\":1581},{\"end\":1776,\"start\":1773},{\"end\":1968,\"start\":1964},{\"end\":2082,\"start\":2074},{\"end\":2244,\"start\":2241},{\"end\":2507,\"start\":2503},{\"end\":2662,\"start\":2659},{\"end\":2858,\"start\":2856},{\"end\":3019,\"start\":3013},{\"end\":3274,\"start\":3270},{\"end\":3382,\"start\":3377},{\"end\":3543,\"start\":3540},{\"end\":3702,\"start\":3697},{\"end\":3865,\"start\":3860},{\"end\":3909,\"start\":3906},{\"end\":4007,\"start\":4004},{\"end\":4161,\"start\":4159},{\"end\":4415,\"start\":4411},{\"end\":4575,\"start\":4572},{\"end\":4829,\"start\":4826},{\"end\":4991,\"start\":4986},{\"end\":5253,\"start\":5248},{\"end\":5263,\"start\":5261},{\"end\":5519,\"start\":5515},{\"end\":5815,\"start\":5809},{\"end\":5922,\"start\":5919},{\"end\":6056,\"start\":6054},{\"end\":6196,\"start\":6188},{\"end\":6255,\"start\":6250},{\"end\":6298,\"start\":6295},{\"end\":6407,\"start\":6402}]", "author_first_name": "[{\"end\":215,\"start\":209},{\"end\":217,\"start\":216},{\"end\":234,\"start\":227},{\"end\":251,\"start\":245},{\"end\":258,\"start\":257},{\"end\":266,\"start\":259},{\"end\":280,\"start\":274},{\"end\":291,\"start\":286},{\"end\":341,\"start\":335},{\"end\":343,\"start\":342},{\"end\":603,\"start\":596},{\"end\":766,\"start\":760},{\"end\":926,\"start\":918},{\"end\":930,\"start\":927},{\"end\":1094,\"start\":1087},{\"end\":1204,\"start\":1199},{\"end\":1206,\"start\":1205},{\"end\":1365,\"start\":1361},{\"end\":1419,\"start\":1417},{\"end\":1580,\"start\":1572},{\"end\":1772,\"start\":1764},{\"end\":1963,\"start\":1957},{\"end\":2071,\"start\":2067},{\"end\":2073,\"start\":2072},{\"end\":2240,\"start\":2230},{\"end\":2498,\"start\":2489},{\"end\":2502,\"start\":2499},{\"end\":2658,\"start\":2655},{\"end\":2855,\"start\":2846},{\"end\":3012,\"start\":3006},{\"end\":3269,\"start\":3264},{\"end\":3376,\"start\":3373},{\"end\":3539,\"start\":3530},{\"end\":3696,\"start\":3691},{\"end\":3859,\"start\":3850},{\"end\":3905,\"start\":3902},{\"end\":4003,\"start\":3996},{\"end\":4158,\"start\":4155},{\"end\":4410,\"start\":4406},{\"end\":4567,\"start\":4563},{\"end\":4571,\"start\":4568},{\"end\":4825,\"start\":4820},{\"end\":4983,\"start\":4977},{\"end\":4985,\"start\":4984},{\"end\":5245,\"start\":5236},{\"end\":5247,\"start\":5246},{\"end\":5260,\"start\":5255},{\"end\":5514,\"start\":5508},{\"end\":5806,\"start\":5799},{\"end\":5808,\"start\":5807},{\"end\":5918,\"start\":5910},{\"end\":6053,\"start\":6050},{\"end\":6187,\"start\":6184},{\"end\":6241,\"start\":6240},{\"end\":6249,\"start\":6242},{\"end\":6294,\"start\":6288},{\"end\":6401,\"start\":6397},{\"end\":215,\"start\":209},{\"end\":217,\"start\":216},{\"end\":234,\"start\":227},{\"end\":251,\"start\":245},{\"end\":258,\"start\":257},{\"end\":266,\"start\":259},{\"end\":280,\"start\":274},{\"end\":291,\"start\":286},{\"end\":341,\"start\":335},{\"end\":343,\"start\":342},{\"end\":603,\"start\":596},{\"end\":766,\"start\":760},{\"end\":926,\"start\":918},{\"end\":930,\"start\":927},{\"end\":1094,\"start\":1087},{\"end\":1204,\"start\":1199},{\"end\":1206,\"start\":1205},{\"end\":1365,\"start\":1361},{\"end\":1419,\"start\":1417},{\"end\":1580,\"start\":1572},{\"end\":1772,\"start\":1764},{\"end\":1963,\"start\":1957},{\"end\":2071,\"start\":2067},{\"end\":2073,\"start\":2072},{\"end\":2240,\"start\":2230},{\"end\":2498,\"start\":2489},{\"end\":2502,\"start\":2499},{\"end\":2658,\"start\":2655},{\"end\":2855,\"start\":2846},{\"end\":3012,\"start\":3006},{\"end\":3269,\"start\":3264},{\"end\":3376,\"start\":3373},{\"end\":3539,\"start\":3530},{\"end\":3696,\"start\":3691},{\"end\":3859,\"start\":3850},{\"end\":3905,\"start\":3902},{\"end\":4003,\"start\":3996},{\"end\":4158,\"start\":4155},{\"end\":4410,\"start\":4406},{\"end\":4567,\"start\":4563},{\"end\":4571,\"start\":4568},{\"end\":4825,\"start\":4820},{\"end\":4983,\"start\":4977},{\"end\":4985,\"start\":4984},{\"end\":5245,\"start\":5236},{\"end\":5247,\"start\":5246},{\"end\":5260,\"start\":5255},{\"end\":5514,\"start\":5508},{\"end\":5806,\"start\":5799},{\"end\":5808,\"start\":5807},{\"end\":5918,\"start\":5910},{\"end\":6053,\"start\":6050},{\"end\":6187,\"start\":6184},{\"end\":6241,\"start\":6240},{\"end\":6249,\"start\":6242},{\"end\":6294,\"start\":6288},{\"end\":6401,\"start\":6397}]", "author_affiliation": "[{\"end\":448,\"start\":353},{\"end\":594,\"start\":450},{\"end\":758,\"start\":614},{\"end\":916,\"start\":772},{\"end\":1085,\"start\":941},{\"end\":1197,\"start\":1102},{\"end\":1359,\"start\":1215},{\"end\":1415,\"start\":1375},{\"end\":1570,\"start\":1426},{\"end\":1762,\"start\":1585},{\"end\":1955,\"start\":1778},{\"end\":2065,\"start\":1970},{\"end\":2228,\"start\":2084},{\"end\":2341,\"start\":2246},{\"end\":2487,\"start\":2343},{\"end\":2653,\"start\":2509},{\"end\":2759,\"start\":2664},{\"end\":2844,\"start\":2761},{\"end\":3004,\"start\":2860},{\"end\":3116,\"start\":3021},{\"end\":3262,\"start\":3118},{\"end\":3371,\"start\":3276},{\"end\":3528,\"start\":3384},{\"end\":3689,\"start\":3545},{\"end\":3848,\"start\":3704},{\"end\":3900,\"start\":3867},{\"end\":3994,\"start\":3911},{\"end\":4153,\"start\":4009},{\"end\":4258,\"start\":4163},{\"end\":4404,\"start\":4260},{\"end\":4561,\"start\":4417},{\"end\":4672,\"start\":4577},{\"end\":4818,\"start\":4674},{\"end\":4975,\"start\":4831},{\"end\":5088,\"start\":4993},{\"end\":5234,\"start\":5090},{\"end\":5360,\"start\":5265},{\"end\":5506,\"start\":5362},{\"end\":5616,\"start\":5521},{\"end\":5762,\"start\":5618},{\"end\":5797,\"start\":5764},{\"end\":5908,\"start\":5817},{\"end\":6048,\"start\":5924},{\"end\":6182,\"start\":6058},{\"end\":6238,\"start\":6198},{\"end\":6286,\"start\":6257},{\"end\":6395,\"start\":6300},{\"end\":6504,\"start\":6409},{\"end\":6650,\"start\":6506},{\"end\":6829,\"start\":6652},{\"end\":6915,\"start\":6831},{\"end\":6978,\"start\":6917},{\"end\":448,\"start\":353},{\"end\":594,\"start\":450},{\"end\":758,\"start\":614},{\"end\":916,\"start\":772},{\"end\":1085,\"start\":941},{\"end\":1197,\"start\":1102},{\"end\":1359,\"start\":1215},{\"end\":1415,\"start\":1375},{\"end\":1570,\"start\":1426},{\"end\":1762,\"start\":1585},{\"end\":1955,\"start\":1778},{\"end\":2065,\"start\":1970},{\"end\":2228,\"start\":2084},{\"end\":2341,\"start\":2246},{\"end\":2487,\"start\":2343},{\"end\":2653,\"start\":2509},{\"end\":2759,\"start\":2664},{\"end\":2844,\"start\":2761},{\"end\":3004,\"start\":2860},{\"end\":3116,\"start\":3021},{\"end\":3262,\"start\":3118},{\"end\":3371,\"start\":3276},{\"end\":3528,\"start\":3384},{\"end\":3689,\"start\":3545},{\"end\":3848,\"start\":3704},{\"end\":3900,\"start\":3867},{\"end\":3994,\"start\":3911},{\"end\":4153,\"start\":4009},{\"end\":4258,\"start\":4163},{\"end\":4404,\"start\":4260},{\"end\":4561,\"start\":4417},{\"end\":4672,\"start\":4577},{\"end\":4818,\"start\":4674},{\"end\":4975,\"start\":4831},{\"end\":5088,\"start\":4993},{\"end\":5234,\"start\":5090},{\"end\":5360,\"start\":5265},{\"end\":5506,\"start\":5362},{\"end\":5616,\"start\":5521},{\"end\":5762,\"start\":5618},{\"end\":5797,\"start\":5764},{\"end\":5908,\"start\":5817},{\"end\":6048,\"start\":5924},{\"end\":6182,\"start\":6058},{\"end\":6238,\"start\":6198},{\"end\":6286,\"start\":6257},{\"end\":6395,\"start\":6300},{\"end\":6504,\"start\":6409},{\"end\":6650,\"start\":6506},{\"end\":6829,\"start\":6652},{\"end\":6915,\"start\":6831},{\"end\":6978,\"start\":6917}]", "title": "[{\"end\":173,\"start\":1},{\"end\":7152,\"start\":6980},{\"end\":173,\"start\":1},{\"end\":7152,\"start\":6980}]", "venue": "[{\"end\":7158,\"start\":7154},{\"end\":7158,\"start\":7154}]", "abstract": "[{\"end\":7662,\"start\":7300},{\"end\":7662,\"start\":7300}]", "bib_ref": "[{\"end\":7700,\"start\":7680},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":9749,\"start\":9726},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":9895,\"start\":9871},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":9921,\"start\":9895},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":9941,\"start\":9921},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":10124,\"start\":10099},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":10148,\"start\":10124},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":10995,\"start\":10973},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":11017,\"start\":10995},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":11039,\"start\":11017},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":12919,\"start\":12891},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":13320,\"start\":13305},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":13342,\"start\":13320},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":13360,\"start\":13342},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":13474,\"start\":13454},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":13930,\"start\":13909},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":13944,\"start\":13930},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":22561,\"start\":22541},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":22646,\"start\":22630},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":22894,\"start\":22878},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":32053,\"start\":32032},{\"end\":38186,\"start\":38179},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":38335,\"start\":38313},{\"end\":40725,\"start\":40700},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":40890,\"start\":40872},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":40914,\"start\":40890},{\"end\":7700,\"start\":7680},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":9749,\"start\":9726},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":9895,\"start\":9871},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":9921,\"start\":9895},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":9941,\"start\":9921},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":10124,\"start\":10099},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":10148,\"start\":10124},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":10995,\"start\":10973},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":11017,\"start\":10995},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":11039,\"start\":11017},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":12919,\"start\":12891},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":13320,\"start\":13305},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":13342,\"start\":13320},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":13360,\"start\":13342},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":13474,\"start\":13454},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":13930,\"start\":13909},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":13944,\"start\":13930},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":22561,\"start\":22541},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":22646,\"start\":22630},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":22894,\"start\":22878},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":32053,\"start\":32032},{\"end\":38186,\"start\":38179},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":38335,\"start\":38313},{\"end\":40725,\"start\":40700},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":40890,\"start\":40872},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":40914,\"start\":40890}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":43145,\"start\":43123},{\"attributes\":{\"id\":\"fig_1\"},\"end\":43728,\"start\":43146},{\"attributes\":{\"id\":\"fig_2\"},\"end\":43824,\"start\":43729},{\"attributes\":{\"id\":\"fig_3\"},\"end\":44564,\"start\":43825},{\"attributes\":{\"id\":\"fig_4\"},\"end\":45287,\"start\":44565},{\"attributes\":{\"id\":\"fig_5\"},\"end\":46319,\"start\":45288},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":46894,\"start\":46320},{\"attributes\":{\"id\":\"fig_0\"},\"end\":43145,\"start\":43123},{\"attributes\":{\"id\":\"fig_1\"},\"end\":43728,\"start\":43146},{\"attributes\":{\"id\":\"fig_2\"},\"end\":43824,\"start\":43729},{\"attributes\":{\"id\":\"fig_3\"},\"end\":44564,\"start\":43825},{\"attributes\":{\"id\":\"fig_4\"},\"end\":45287,\"start\":44565},{\"attributes\":{\"id\":\"fig_5\"},\"end\":46319,\"start\":45288},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":46894,\"start\":46320}]", "paragraph": "[{\"end\":7954,\"start\":7702},{\"end\":9029,\"start\":7966},{\"end\":9352,\"start\":9046},{\"end\":9942,\"start\":9354},{\"end\":10710,\"start\":9944},{\"end\":11517,\"start\":10712},{\"end\":12441,\"start\":11519},{\"end\":14333,\"start\":12453},{\"end\":14989,\"start\":14371},{\"end\":16675,\"start\":15018},{\"end\":17287,\"start\":16677},{\"end\":17986,\"start\":17289},{\"end\":18736,\"start\":17988},{\"end\":19449,\"start\":18783},{\"end\":20833,\"start\":19451},{\"end\":21334,\"start\":20835},{\"end\":22079,\"start\":21356},{\"end\":23805,\"start\":22161},{\"end\":24351,\"start\":23807},{\"end\":24874,\"start\":24353},{\"end\":25895,\"start\":24889},{\"end\":26862,\"start\":25897},{\"end\":27879,\"start\":26864},{\"end\":29185,\"start\":28018},{\"end\":30274,\"start\":29187},{\"end\":33841,\"start\":30276},{\"end\":33952,\"start\":33858},{\"end\":34269,\"start\":34045},{\"end\":35741,\"start\":34341},{\"end\":36154,\"start\":35760},{\"end\":36403,\"start\":36156},{\"end\":37803,\"start\":36422},{\"end\":38187,\"start\":37805},{\"end\":40056,\"start\":38217},{\"end\":40643,\"start\":40079},{\"end\":41259,\"start\":40662},{\"end\":42712,\"start\":41303},{\"end\":43073,\"start\":42747},{\"end\":43122,\"start\":43075},{\"end\":7954,\"start\":7702},{\"end\":9029,\"start\":7966},{\"end\":9352,\"start\":9046},{\"end\":9942,\"start\":9354},{\"end\":10710,\"start\":9944},{\"end\":11517,\"start\":10712},{\"end\":12441,\"start\":11519},{\"end\":14333,\"start\":12453},{\"end\":14989,\"start\":14371},{\"end\":16675,\"start\":15018},{\"end\":17287,\"start\":16677},{\"end\":17986,\"start\":17289},{\"end\":18736,\"start\":17988},{\"end\":19449,\"start\":18783},{\"end\":20833,\"start\":19451},{\"end\":21334,\"start\":20835},{\"end\":22079,\"start\":21356},{\"end\":23805,\"start\":22161},{\"end\":24351,\"start\":23807},{\"end\":24874,\"start\":24353},{\"end\":25895,\"start\":24889},{\"end\":26862,\"start\":25897},{\"end\":27879,\"start\":26864},{\"end\":29185,\"start\":28018},{\"end\":30274,\"start\":29187},{\"end\":33841,\"start\":30276},{\"end\":33952,\"start\":33858},{\"end\":34269,\"start\":34045},{\"end\":35741,\"start\":34341},{\"end\":36154,\"start\":35760},{\"end\":36403,\"start\":36156},{\"end\":37803,\"start\":36422},{\"end\":38187,\"start\":37805},{\"end\":40056,\"start\":38217},{\"end\":40643,\"start\":40079},{\"end\":41259,\"start\":40662},{\"end\":42712,\"start\":41303},{\"end\":43073,\"start\":42747},{\"end\":43122,\"start\":43075}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":33968,\"start\":33953},{\"attributes\":{\"id\":\"formula_0\"},\"end\":33968,\"start\":33953}]", "table_ref": "[{\"end\":14796,\"start\":14788},{\"end\":15717,\"start\":15708},{\"end\":21042,\"start\":21033},{\"end\":21925,\"start\":21915},{\"end\":29184,\"start\":29176},{\"end\":14796,\"start\":14788},{\"end\":15717,\"start\":15708},{\"end\":21042,\"start\":21033},{\"end\":21925,\"start\":21915},{\"end\":29184,\"start\":29176}]", "section_header": "[{\"end\":7678,\"start\":7664},{\"end\":7964,\"start\":7957},{\"end\":9044,\"start\":9032},{\"end\":12451,\"start\":12444},{\"end\":14369,\"start\":14336},{\"end\":15016,\"start\":14992},{\"end\":18781,\"start\":18739},{\"end\":21354,\"start\":21337},{\"end\":22159,\"start\":22082},{\"end\":24887,\"start\":24877},{\"end\":28016,\"start\":27882},{\"end\":33856,\"start\":33844},{\"end\":34043,\"start\":33970},{\"end\":34310,\"start\":34272},{\"end\":34339,\"start\":34313},{\"end\":35758,\"start\":35744},{\"end\":36420,\"start\":36406},{\"end\":38215,\"start\":38190},{\"end\":40077,\"start\":40059},{\"end\":40660,\"start\":40646},{\"end\":41301,\"start\":41262},{\"end\":42745,\"start\":42715},{\"end\":43134,\"start\":43124},{\"end\":43157,\"start\":43147},{\"end\":43740,\"start\":43730},{\"end\":43836,\"start\":43826},{\"end\":44576,\"start\":44566},{\"end\":45304,\"start\":45289},{\"end\":46336,\"start\":46321},{\"end\":7678,\"start\":7664},{\"end\":7964,\"start\":7957},{\"end\":9044,\"start\":9032},{\"end\":12451,\"start\":12444},{\"end\":14369,\"start\":14336},{\"end\":15016,\"start\":14992},{\"end\":18781,\"start\":18739},{\"end\":21354,\"start\":21337},{\"end\":22159,\"start\":22082},{\"end\":24887,\"start\":24877},{\"end\":28016,\"start\":27882},{\"end\":33856,\"start\":33844},{\"end\":34043,\"start\":33970},{\"end\":34310,\"start\":34272},{\"end\":34339,\"start\":34313},{\"end\":35758,\"start\":35744},{\"end\":36420,\"start\":36406},{\"end\":38215,\"start\":38190},{\"end\":40077,\"start\":40059},{\"end\":40660,\"start\":40646},{\"end\":41301,\"start\":41262},{\"end\":42745,\"start\":42715},{\"end\":43134,\"start\":43124},{\"end\":43157,\"start\":43147},{\"end\":43740,\"start\":43730},{\"end\":43836,\"start\":43826},{\"end\":44576,\"start\":44566},{\"end\":45304,\"start\":45289},{\"end\":46336,\"start\":46321}]", "table": "[{\"end\":46894,\"start\":46370},{\"end\":46894,\"start\":46370}]", "figure_caption": "[{\"end\":43145,\"start\":43136},{\"end\":43728,\"start\":43159},{\"end\":43824,\"start\":43742},{\"end\":44564,\"start\":43838},{\"end\":45287,\"start\":44578},{\"end\":46319,\"start\":45305},{\"end\":46370,\"start\":46338},{\"end\":43145,\"start\":43136},{\"end\":43728,\"start\":43159},{\"end\":43824,\"start\":43742},{\"end\":44564,\"start\":43838},{\"end\":45287,\"start\":44578},{\"end\":46319,\"start\":45305},{\"end\":46370,\"start\":46338}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":11516,\"start\":11506},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":14183,\"start\":14173},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":14951,\"start\":14942},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":14987,\"start\":14978},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":16315,\"start\":16305},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":16674,\"start\":16665},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":17985,\"start\":17976},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":18084,\"start\":18075},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":18312,\"start\":18302},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":18531,\"start\":18521},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":18734,\"start\":18724},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":19447,\"start\":19438},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":19935,\"start\":19926},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":20706,\"start\":20695},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":21214,\"start\":21204},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":21235,\"start\":21227},{\"end\":21665,\"start\":21656},{\"end\":21685,\"start\":21676},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":23323,\"start\":23314},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":24349,\"start\":24332},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":24605,\"start\":24596},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":24770,\"start\":24752},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":24872,\"start\":24863},{\"end\":29171,\"start\":29162},{\"end\":31671,\"start\":31662},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":37596,\"start\":37587},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":39246,\"start\":39237},{\"end\":41213,\"start\":41204},{\"end\":41233,\"start\":41224},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":11516,\"start\":11506},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":14183,\"start\":14173},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":14951,\"start\":14942},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":14987,\"start\":14978},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":16315,\"start\":16305},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":16674,\"start\":16665},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":17985,\"start\":17976},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":18084,\"start\":18075},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":18312,\"start\":18302},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":18531,\"start\":18521},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":18734,\"start\":18724},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":19447,\"start\":19438},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":19935,\"start\":19926},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":20706,\"start\":20695},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":21214,\"start\":21204},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":21235,\"start\":21227},{\"end\":21665,\"start\":21656},{\"end\":21685,\"start\":21676},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":23323,\"start\":23314},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":24349,\"start\":24332},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":24605,\"start\":24596},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":24770,\"start\":24752},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":24872,\"start\":24863},{\"end\":29171,\"start\":29162},{\"end\":31671,\"start\":31662},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":37596,\"start\":37587},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":39246,\"start\":39237},{\"end\":41213,\"start\":41204},{\"end\":41233,\"start\":41224}]", "bib_author_first_name": "[{\"end\":48754,\"start\":48753},{\"end\":48756,\"start\":48755},{\"end\":49061,\"start\":49060},{\"end\":49074,\"start\":49073},{\"end\":49088,\"start\":49087},{\"end\":49096,\"start\":49095},{\"end\":49106,\"start\":49105},{\"end\":49424,\"start\":49423},{\"end\":49435,\"start\":49434},{\"end\":49442,\"start\":49441},{\"end\":49453,\"start\":49452},{\"end\":49464,\"start\":49463},{\"end\":49473,\"start\":49472},{\"end\":49488,\"start\":49481},{\"end\":49492,\"start\":49491},{\"end\":49981,\"start\":49980},{\"end\":50223,\"start\":50222},{\"end\":50225,\"start\":50224},{\"end\":50237,\"start\":50236},{\"end\":50239,\"start\":50238},{\"end\":50257,\"start\":50256},{\"end\":50267,\"start\":50266},{\"end\":50269,\"start\":50268},{\"end\":50279,\"start\":50278},{\"end\":50290,\"start\":50289},{\"end\":50292,\"start\":50291},{\"end\":50303,\"start\":50302},{\"end\":50315,\"start\":50314},{\"end\":50327,\"start\":50326},{\"end\":50737,\"start\":50736},{\"end\":50749,\"start\":50748},{\"end\":50759,\"start\":50758},{\"end\":50769,\"start\":50768},{\"end\":50783,\"start\":50782},{\"end\":50791,\"start\":50790},{\"end\":50801,\"start\":50800},{\"end\":51088,\"start\":51087},{\"end\":51099,\"start\":51098},{\"end\":51107,\"start\":51106},{\"end\":51116,\"start\":51115},{\"end\":51118,\"start\":51117},{\"end\":51128,\"start\":51127},{\"end\":51134,\"start\":51133},{\"end\":51151,\"start\":51150},{\"end\":51166,\"start\":51165},{\"end\":51176,\"start\":51175},{\"end\":51186,\"start\":51185},{\"end\":51501,\"start\":51500},{\"end\":51511,\"start\":51510},{\"end\":51663,\"start\":51662},{\"end\":51673,\"start\":51672},{\"end\":51688,\"start\":51687},{\"end\":52057,\"start\":52056},{\"end\":52059,\"start\":52058},{\"end\":52069,\"start\":52068},{\"end\":52071,\"start\":52070},{\"end\":52080,\"start\":52079},{\"end\":52089,\"start\":52088},{\"end\":52091,\"start\":52090},{\"end\":52101,\"start\":52100},{\"end\":52103,\"start\":52102},{\"end\":52111,\"start\":52110},{\"end\":52122,\"start\":52121},{\"end\":52135,\"start\":52134},{\"end\":52137,\"start\":52136},{\"end\":52519,\"start\":52518},{\"end\":52533,\"start\":52532},{\"end\":52546,\"start\":52545},{\"end\":52548,\"start\":52547},{\"end\":52833,\"start\":52832},{\"end\":52835,\"start\":52834},{\"end\":52842,\"start\":52841},{\"end\":52844,\"start\":52843},{\"end\":52856,\"start\":52855},{\"end\":52858,\"start\":52857},{\"end\":53120,\"start\":53119},{\"end\":53294,\"start\":53293},{\"end\":53296,\"start\":53295},{\"end\":53308,\"start\":53307},{\"end\":53320,\"start\":53319},{\"end\":53339,\"start\":53331},{\"end\":53343,\"start\":53342},{\"end\":53701,\"start\":53700},{\"end\":53710,\"start\":53709},{\"end\":53726,\"start\":53725},{\"end\":53738,\"start\":53737},{\"end\":53752,\"start\":53751},{\"end\":54077,\"start\":54076},{\"end\":54079,\"start\":54078},{\"end\":54090,\"start\":54089},{\"end\":54092,\"start\":54091},{\"end\":54395,\"start\":54394},{\"end\":54406,\"start\":54405},{\"end\":54419,\"start\":54418},{\"end\":54428,\"start\":54427},{\"end\":54438,\"start\":54437},{\"end\":54808,\"start\":54807},{\"end\":54817,\"start\":54816},{\"end\":54819,\"start\":54818},{\"end\":54831,\"start\":54830},{\"end\":54833,\"start\":54832},{\"end\":54841,\"start\":54840},{\"end\":54852,\"start\":54851},{\"end\":54862,\"start\":54861},{\"end\":54864,\"start\":54863},{\"end\":54873,\"start\":54872},{\"end\":54883,\"start\":54882},{\"end\":54892,\"start\":54891},{\"end\":54900,\"start\":54899},{\"end\":54910,\"start\":54909},{\"end\":55341,\"start\":55340},{\"end\":55343,\"start\":55342},{\"end\":55351,\"start\":55350},{\"end\":55357,\"start\":55356},{\"end\":55363,\"start\":55362},{\"end\":55365,\"start\":55364},{\"end\":55375,\"start\":55374},{\"end\":55384,\"start\":55383},{\"end\":55386,\"start\":55385},{\"end\":55395,\"start\":55394},{\"end\":55397,\"start\":55396},{\"end\":55697,\"start\":55696},{\"end\":55709,\"start\":55708},{\"end\":55718,\"start\":55717},{\"end\":55728,\"start\":55727},{\"end\":56177,\"start\":56176},{\"end\":56179,\"start\":56178},{\"end\":56194,\"start\":56188},{\"end\":56198,\"start\":56197},{\"end\":48754,\"start\":48753},{\"end\":48756,\"start\":48755},{\"end\":49061,\"start\":49060},{\"end\":49074,\"start\":49073},{\"end\":49088,\"start\":49087},{\"end\":49096,\"start\":49095},{\"end\":49106,\"start\":49105},{\"end\":49424,\"start\":49423},{\"end\":49435,\"start\":49434},{\"end\":49442,\"start\":49441},{\"end\":49453,\"start\":49452},{\"end\":49464,\"start\":49463},{\"end\":49473,\"start\":49472},{\"end\":49488,\"start\":49481},{\"end\":49492,\"start\":49491},{\"end\":49981,\"start\":49980},{\"end\":50223,\"start\":50222},{\"end\":50225,\"start\":50224},{\"end\":50237,\"start\":50236},{\"end\":50239,\"start\":50238},{\"end\":50257,\"start\":50256},{\"end\":50267,\"start\":50266},{\"end\":50269,\"start\":50268},{\"end\":50279,\"start\":50278},{\"end\":50290,\"start\":50289},{\"end\":50292,\"start\":50291},{\"end\":50303,\"start\":50302},{\"end\":50315,\"start\":50314},{\"end\":50327,\"start\":50326},{\"end\":50737,\"start\":50736},{\"end\":50749,\"start\":50748},{\"end\":50759,\"start\":50758},{\"end\":50769,\"start\":50768},{\"end\":50783,\"start\":50782},{\"end\":50791,\"start\":50790},{\"end\":50801,\"start\":50800},{\"end\":51088,\"start\":51087},{\"end\":51099,\"start\":51098},{\"end\":51107,\"start\":51106},{\"end\":51116,\"start\":51115},{\"end\":51118,\"start\":51117},{\"end\":51128,\"start\":51127},{\"end\":51134,\"start\":51133},{\"end\":51151,\"start\":51150},{\"end\":51166,\"start\":51165},{\"end\":51176,\"start\":51175},{\"end\":51186,\"start\":51185},{\"end\":51501,\"start\":51500},{\"end\":51511,\"start\":51510},{\"end\":51663,\"start\":51662},{\"end\":51673,\"start\":51672},{\"end\":51688,\"start\":51687},{\"end\":52057,\"start\":52056},{\"end\":52059,\"start\":52058},{\"end\":52069,\"start\":52068},{\"end\":52071,\"start\":52070},{\"end\":52080,\"start\":52079},{\"end\":52089,\"start\":52088},{\"end\":52091,\"start\":52090},{\"end\":52101,\"start\":52100},{\"end\":52103,\"start\":52102},{\"end\":52111,\"start\":52110},{\"end\":52122,\"start\":52121},{\"end\":52135,\"start\":52134},{\"end\":52137,\"start\":52136},{\"end\":52519,\"start\":52518},{\"end\":52533,\"start\":52532},{\"end\":52546,\"start\":52545},{\"end\":52548,\"start\":52547},{\"end\":52833,\"start\":52832},{\"end\":52835,\"start\":52834},{\"end\":52842,\"start\":52841},{\"end\":52844,\"start\":52843},{\"end\":52856,\"start\":52855},{\"end\":52858,\"start\":52857},{\"end\":53120,\"start\":53119},{\"end\":53294,\"start\":53293},{\"end\":53296,\"start\":53295},{\"end\":53308,\"start\":53307},{\"end\":53320,\"start\":53319},{\"end\":53339,\"start\":53331},{\"end\":53343,\"start\":53342},{\"end\":53701,\"start\":53700},{\"end\":53710,\"start\":53709},{\"end\":53726,\"start\":53725},{\"end\":53738,\"start\":53737},{\"end\":53752,\"start\":53751},{\"end\":54077,\"start\":54076},{\"end\":54079,\"start\":54078},{\"end\":54090,\"start\":54089},{\"end\":54092,\"start\":54091},{\"end\":54395,\"start\":54394},{\"end\":54406,\"start\":54405},{\"end\":54419,\"start\":54418},{\"end\":54428,\"start\":54427},{\"end\":54438,\"start\":54437},{\"end\":54808,\"start\":54807},{\"end\":54817,\"start\":54816},{\"end\":54819,\"start\":54818},{\"end\":54831,\"start\":54830},{\"end\":54833,\"start\":54832},{\"end\":54841,\"start\":54840},{\"end\":54852,\"start\":54851},{\"end\":54862,\"start\":54861},{\"end\":54864,\"start\":54863},{\"end\":54873,\"start\":54872},{\"end\":54883,\"start\":54882},{\"end\":54892,\"start\":54891},{\"end\":54900,\"start\":54899},{\"end\":54910,\"start\":54909},{\"end\":55341,\"start\":55340},{\"end\":55343,\"start\":55342},{\"end\":55351,\"start\":55350},{\"end\":55357,\"start\":55356},{\"end\":55363,\"start\":55362},{\"end\":55365,\"start\":55364},{\"end\":55375,\"start\":55374},{\"end\":55384,\"start\":55383},{\"end\":55386,\"start\":55385},{\"end\":55395,\"start\":55394},{\"end\":55397,\"start\":55396},{\"end\":55697,\"start\":55696},{\"end\":55709,\"start\":55708},{\"end\":55718,\"start\":55717},{\"end\":55728,\"start\":55727},{\"end\":56177,\"start\":56176},{\"end\":56179,\"start\":56178},{\"end\":56194,\"start\":56188},{\"end\":56198,\"start\":56197}]", "bib_author_last_name": "[{\"end\":48765,\"start\":48757},{\"end\":49071,\"start\":49062},{\"end\":49085,\"start\":49075},{\"end\":49093,\"start\":49089},{\"end\":49103,\"start\":49097},{\"end\":49115,\"start\":49107},{\"end\":49432,\"start\":49425},{\"end\":49439,\"start\":49436},{\"end\":49450,\"start\":49443},{\"end\":49461,\"start\":49454},{\"end\":49470,\"start\":49465},{\"end\":49479,\"start\":49474},{\"end\":49989,\"start\":49982},{\"end\":50234,\"start\":50226},{\"end\":50254,\"start\":50240},{\"end\":50264,\"start\":50258},{\"end\":50276,\"start\":50270},{\"end\":50287,\"start\":50280},{\"end\":50300,\"start\":50293},{\"end\":50312,\"start\":50304},{\"end\":50324,\"start\":50316},{\"end\":50334,\"start\":50328},{\"end\":50746,\"start\":50738},{\"end\":50756,\"start\":50750},{\"end\":50766,\"start\":50760},{\"end\":50780,\"start\":50770},{\"end\":50788,\"start\":50784},{\"end\":50798,\"start\":50792},{\"end\":50806,\"start\":50802},{\"end\":51096,\"start\":51089},{\"end\":51104,\"start\":51100},{\"end\":51113,\"start\":51108},{\"end\":51125,\"start\":51119},{\"end\":51131,\"start\":51129},{\"end\":51148,\"start\":51135},{\"end\":51163,\"start\":51152},{\"end\":51173,\"start\":51167},{\"end\":51183,\"start\":51177},{\"end\":51194,\"start\":51187},{\"end\":51508,\"start\":51502},{\"end\":51520,\"start\":51512},{\"end\":51670,\"start\":51664},{\"end\":51685,\"start\":51674},{\"end\":51697,\"start\":51689},{\"end\":52066,\"start\":52060},{\"end\":52077,\"start\":52072},{\"end\":52086,\"start\":52081},{\"end\":52098,\"start\":52092},{\"end\":52108,\"start\":52104},{\"end\":52119,\"start\":52112},{\"end\":52132,\"start\":52123},{\"end\":52145,\"start\":52138},{\"end\":52530,\"start\":52520},{\"end\":52543,\"start\":52534},{\"end\":52555,\"start\":52549},{\"end\":52839,\"start\":52836},{\"end\":52853,\"start\":52845},{\"end\":52862,\"start\":52859},{\"end\":53129,\"start\":53121},{\"end\":53305,\"start\":53297},{\"end\":53317,\"start\":53309},{\"end\":53329,\"start\":53321},{\"end\":53707,\"start\":53702},{\"end\":53723,\"start\":53711},{\"end\":53735,\"start\":53727},{\"end\":53749,\"start\":53739},{\"end\":53761,\"start\":53753},{\"end\":54087,\"start\":54080},{\"end\":54101,\"start\":54093},{\"end\":54403,\"start\":54396},{\"end\":54416,\"start\":54407},{\"end\":54425,\"start\":54420},{\"end\":54435,\"start\":54429},{\"end\":54444,\"start\":54439},{\"end\":54814,\"start\":54809},{\"end\":54828,\"start\":54820},{\"end\":54838,\"start\":54834},{\"end\":54849,\"start\":54842},{\"end\":54859,\"start\":54853},{\"end\":54870,\"start\":54865},{\"end\":54880,\"start\":54874},{\"end\":54889,\"start\":54884},{\"end\":54897,\"start\":54893},{\"end\":54907,\"start\":54901},{\"end\":54917,\"start\":54911},{\"end\":55348,\"start\":55344},{\"end\":55354,\"start\":55352},{\"end\":55360,\"start\":55358},{\"end\":55372,\"start\":55366},{\"end\":55381,\"start\":55376},{\"end\":55392,\"start\":55387},{\"end\":55402,\"start\":55398},{\"end\":55706,\"start\":55698},{\"end\":55715,\"start\":55710},{\"end\":55725,\"start\":55719},{\"end\":55735,\"start\":55729},{\"end\":56186,\"start\":56180},{\"end\":48765,\"start\":48757},{\"end\":49071,\"start\":49062},{\"end\":49085,\"start\":49075},{\"end\":49093,\"start\":49089},{\"end\":49103,\"start\":49097},{\"end\":49115,\"start\":49107},{\"end\":49432,\"start\":49425},{\"end\":49439,\"start\":49436},{\"end\":49450,\"start\":49443},{\"end\":49461,\"start\":49454},{\"end\":49470,\"start\":49465},{\"end\":49479,\"start\":49474},{\"end\":49989,\"start\":49982},{\"end\":50234,\"start\":50226},{\"end\":50254,\"start\":50240},{\"end\":50264,\"start\":50258},{\"end\":50276,\"start\":50270},{\"end\":50287,\"start\":50280},{\"end\":50300,\"start\":50293},{\"end\":50312,\"start\":50304},{\"end\":50324,\"start\":50316},{\"end\":50334,\"start\":50328},{\"end\":50746,\"start\":50738},{\"end\":50756,\"start\":50750},{\"end\":50766,\"start\":50760},{\"end\":50780,\"start\":50770},{\"end\":50788,\"start\":50784},{\"end\":50798,\"start\":50792},{\"end\":50806,\"start\":50802},{\"end\":51096,\"start\":51089},{\"end\":51104,\"start\":51100},{\"end\":51113,\"start\":51108},{\"end\":51125,\"start\":51119},{\"end\":51131,\"start\":51129},{\"end\":51148,\"start\":51135},{\"end\":51163,\"start\":51152},{\"end\":51173,\"start\":51167},{\"end\":51183,\"start\":51177},{\"end\":51194,\"start\":51187},{\"end\":51508,\"start\":51502},{\"end\":51520,\"start\":51512},{\"end\":51670,\"start\":51664},{\"end\":51685,\"start\":51674},{\"end\":51697,\"start\":51689},{\"end\":52066,\"start\":52060},{\"end\":52077,\"start\":52072},{\"end\":52086,\"start\":52081},{\"end\":52098,\"start\":52092},{\"end\":52108,\"start\":52104},{\"end\":52119,\"start\":52112},{\"end\":52132,\"start\":52123},{\"end\":52145,\"start\":52138},{\"end\":52530,\"start\":52520},{\"end\":52543,\"start\":52534},{\"end\":52555,\"start\":52549},{\"end\":52839,\"start\":52836},{\"end\":52853,\"start\":52845},{\"end\":52862,\"start\":52859},{\"end\":53129,\"start\":53121},{\"end\":53305,\"start\":53297},{\"end\":53317,\"start\":53309},{\"end\":53329,\"start\":53321},{\"end\":53707,\"start\":53702},{\"end\":53723,\"start\":53711},{\"end\":53735,\"start\":53727},{\"end\":53749,\"start\":53739},{\"end\":53761,\"start\":53753},{\"end\":54087,\"start\":54080},{\"end\":54101,\"start\":54093},{\"end\":54403,\"start\":54396},{\"end\":54416,\"start\":54407},{\"end\":54425,\"start\":54420},{\"end\":54435,\"start\":54429},{\"end\":54444,\"start\":54439},{\"end\":54814,\"start\":54809},{\"end\":54828,\"start\":54820},{\"end\":54838,\"start\":54834},{\"end\":54849,\"start\":54842},{\"end\":54859,\"start\":54853},{\"end\":54870,\"start\":54865},{\"end\":54880,\"start\":54874},{\"end\":54889,\"start\":54884},{\"end\":54897,\"start\":54893},{\"end\":54907,\"start\":54901},{\"end\":54917,\"start\":54911},{\"end\":55348,\"start\":55344},{\"end\":55354,\"start\":55352},{\"end\":55360,\"start\":55358},{\"end\":55372,\"start\":55366},{\"end\":55381,\"start\":55376},{\"end\":55392,\"start\":55387},{\"end\":55402,\"start\":55398},{\"end\":55706,\"start\":55698},{\"end\":55715,\"start\":55710},{\"end\":55725,\"start\":55719},{\"end\":55735,\"start\":55729},{\"end\":56186,\"start\":56180}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":607098},\"end\":48974,\"start\":48638},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":291078},\"end\":49342,\"start\":48976},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":6161478},\"end\":49874,\"start\":49344},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":26749162},\"end\":50151,\"start\":49876},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":20805801},\"end\":50677,\"start\":50153},{\"attributes\":{\"id\":\"b5\"},\"end\":50960,\"start\":50679},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":26657811},\"end\":51496,\"start\":50962},{\"attributes\":{\"id\":\"b7\"},\"end\":51558,\"start\":51498},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":1847734},\"end\":51922,\"start\":51560},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":34072634},\"end\":52451,\"start\":51924},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":195908774},\"end\":52715,\"start\":52453},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":5913352},\"end\":53077,\"start\":52717},{\"attributes\":{\"id\":\"b12\"},\"end\":53223,\"start\":53079},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":6383532},\"end\":53648,\"start\":53225},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":465584},\"end\":53963,\"start\":53650},{\"attributes\":{\"id\":\"b15\"},\"end\":54272,\"start\":53965},{\"attributes\":{\"id\":\"b16\"},\"end\":54333,\"start\":54274},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":206593880},\"end\":54725,\"start\":54335},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":29030737},\"end\":55196,\"start\":54727},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":35014672},\"end\":55694,\"start\":55198},{\"attributes\":{\"id\":\"b20\"},\"end\":56120,\"start\":55696},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":3960646},\"end\":56362,\"start\":56122},{\"attributes\":{\"id\":\"b22\"},\"end\":56650,\"start\":56364},{\"attributes\":{\"id\":\"b23\"},\"end\":57669,\"start\":56652},{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":607098},\"end\":48974,\"start\":48638},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":291078},\"end\":49342,\"start\":48976},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":6161478},\"end\":49874,\"start\":49344},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":26749162},\"end\":50151,\"start\":49876},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":20805801},\"end\":50677,\"start\":50153},{\"attributes\":{\"id\":\"b5\"},\"end\":50960,\"start\":50679},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":26657811},\"end\":51496,\"start\":50962},{\"attributes\":{\"id\":\"b7\"},\"end\":51558,\"start\":51498},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":1847734},\"end\":51922,\"start\":51560},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":34072634},\"end\":52451,\"start\":51924},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":195908774},\"end\":52715,\"start\":52453},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":5913352},\"end\":53077,\"start\":52717},{\"attributes\":{\"id\":\"b12\"},\"end\":53223,\"start\":53079},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":6383532},\"end\":53648,\"start\":53225},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":465584},\"end\":53963,\"start\":53650},{\"attributes\":{\"id\":\"b15\"},\"end\":54272,\"start\":53965},{\"attributes\":{\"id\":\"b16\"},\"end\":54333,\"start\":54274},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":206593880},\"end\":54725,\"start\":54335},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":29030737},\"end\":55196,\"start\":54727},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":35014672},\"end\":55694,\"start\":55198},{\"attributes\":{\"id\":\"b20\"},\"end\":56120,\"start\":55696},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":3960646},\"end\":56362,\"start\":56122},{\"attributes\":{\"id\":\"b22\"},\"end\":56650,\"start\":56364},{\"attributes\":{\"id\":\"b23\"},\"end\":57669,\"start\":56652}]", "bib_title": "[{\"end\":48751,\"start\":48638},{\"end\":49058,\"start\":48976},{\"end\":49421,\"start\":49344},{\"end\":49978,\"start\":49876},{\"end\":50220,\"start\":50153},{\"end\":51085,\"start\":50962},{\"end\":51660,\"start\":51560},{\"end\":52054,\"start\":51924},{\"end\":52516,\"start\":52453},{\"end\":52830,\"start\":52717},{\"end\":53291,\"start\":53225},{\"end\":53698,\"start\":53650},{\"end\":54392,\"start\":54335},{\"end\":54805,\"start\":54727},{\"end\":55338,\"start\":55198},{\"end\":56174,\"start\":56122},{\"end\":56950,\"start\":56652},{\"end\":48751,\"start\":48638},{\"end\":49058,\"start\":48976},{\"end\":49421,\"start\":49344},{\"end\":49978,\"start\":49876},{\"end\":50220,\"start\":50153},{\"end\":51085,\"start\":50962},{\"end\":51660,\"start\":51560},{\"end\":52054,\"start\":51924},{\"end\":52516,\"start\":52453},{\"end\":52830,\"start\":52717},{\"end\":53291,\"start\":53225},{\"end\":53698,\"start\":53650},{\"end\":54392,\"start\":54335},{\"end\":54805,\"start\":54727},{\"end\":55338,\"start\":55198},{\"end\":56174,\"start\":56122},{\"end\":56950,\"start\":56652}]", "bib_author": "[{\"end\":48767,\"start\":48753},{\"end\":49073,\"start\":49060},{\"end\":49087,\"start\":49073},{\"end\":49095,\"start\":49087},{\"end\":49105,\"start\":49095},{\"end\":49117,\"start\":49105},{\"end\":49434,\"start\":49423},{\"end\":49441,\"start\":49434},{\"end\":49452,\"start\":49441},{\"end\":49463,\"start\":49452},{\"end\":49472,\"start\":49463},{\"end\":49481,\"start\":49472},{\"end\":49491,\"start\":49481},{\"end\":49495,\"start\":49491},{\"end\":49991,\"start\":49980},{\"end\":50236,\"start\":50222},{\"end\":50256,\"start\":50236},{\"end\":50266,\"start\":50256},{\"end\":50278,\"start\":50266},{\"end\":50289,\"start\":50278},{\"end\":50302,\"start\":50289},{\"end\":50314,\"start\":50302},{\"end\":50326,\"start\":50314},{\"end\":50336,\"start\":50326},{\"end\":50748,\"start\":50736},{\"end\":50758,\"start\":50748},{\"end\":50768,\"start\":50758},{\"end\":50782,\"start\":50768},{\"end\":50790,\"start\":50782},{\"end\":50800,\"start\":50790},{\"end\":50808,\"start\":50800},{\"end\":51098,\"start\":51087},{\"end\":51106,\"start\":51098},{\"end\":51115,\"start\":51106},{\"end\":51127,\"start\":51115},{\"end\":51133,\"start\":51127},{\"end\":51150,\"start\":51133},{\"end\":51165,\"start\":51150},{\"end\":51175,\"start\":51165},{\"end\":51185,\"start\":51175},{\"end\":51196,\"start\":51185},{\"end\":51510,\"start\":51500},{\"end\":51522,\"start\":51510},{\"end\":51672,\"start\":51662},{\"end\":51687,\"start\":51672},{\"end\":51699,\"start\":51687},{\"end\":52068,\"start\":52056},{\"end\":52079,\"start\":52068},{\"end\":52088,\"start\":52079},{\"end\":52100,\"start\":52088},{\"end\":52110,\"start\":52100},{\"end\":52121,\"start\":52110},{\"end\":52134,\"start\":52121},{\"end\":52147,\"start\":52134},{\"end\":52532,\"start\":52518},{\"end\":52545,\"start\":52532},{\"end\":52557,\"start\":52545},{\"end\":52841,\"start\":52832},{\"end\":52855,\"start\":52841},{\"end\":52864,\"start\":52855},{\"end\":53131,\"start\":53119},{\"end\":53307,\"start\":53293},{\"end\":53319,\"start\":53307},{\"end\":53331,\"start\":53319},{\"end\":53342,\"start\":53331},{\"end\":53346,\"start\":53342},{\"end\":53709,\"start\":53700},{\"end\":53725,\"start\":53709},{\"end\":53737,\"start\":53725},{\"end\":53751,\"start\":53737},{\"end\":53763,\"start\":53751},{\"end\":54089,\"start\":54076},{\"end\":54103,\"start\":54089},{\"end\":54405,\"start\":54394},{\"end\":54418,\"start\":54405},{\"end\":54427,\"start\":54418},{\"end\":54437,\"start\":54427},{\"end\":54446,\"start\":54437},{\"end\":54816,\"start\":54807},{\"end\":54830,\"start\":54816},{\"end\":54840,\"start\":54830},{\"end\":54851,\"start\":54840},{\"end\":54861,\"start\":54851},{\"end\":54872,\"start\":54861},{\"end\":54882,\"start\":54872},{\"end\":54891,\"start\":54882},{\"end\":54899,\"start\":54891},{\"end\":54909,\"start\":54899},{\"end\":54919,\"start\":54909},{\"end\":55350,\"start\":55340},{\"end\":55356,\"start\":55350},{\"end\":55362,\"start\":55356},{\"end\":55374,\"start\":55362},{\"end\":55383,\"start\":55374},{\"end\":55394,\"start\":55383},{\"end\":55404,\"start\":55394},{\"end\":55708,\"start\":55696},{\"end\":55717,\"start\":55708},{\"end\":55727,\"start\":55717},{\"end\":55737,\"start\":55727},{\"end\":56188,\"start\":56176},{\"end\":56197,\"start\":56188},{\"end\":56201,\"start\":56197},{\"end\":48767,\"start\":48753},{\"end\":49073,\"start\":49060},{\"end\":49087,\"start\":49073},{\"end\":49095,\"start\":49087},{\"end\":49105,\"start\":49095},{\"end\":49117,\"start\":49105},{\"end\":49434,\"start\":49423},{\"end\":49441,\"start\":49434},{\"end\":49452,\"start\":49441},{\"end\":49463,\"start\":49452},{\"end\":49472,\"start\":49463},{\"end\":49481,\"start\":49472},{\"end\":49491,\"start\":49481},{\"end\":49495,\"start\":49491},{\"end\":49991,\"start\":49980},{\"end\":50236,\"start\":50222},{\"end\":50256,\"start\":50236},{\"end\":50266,\"start\":50256},{\"end\":50278,\"start\":50266},{\"end\":50289,\"start\":50278},{\"end\":50302,\"start\":50289},{\"end\":50314,\"start\":50302},{\"end\":50326,\"start\":50314},{\"end\":50336,\"start\":50326},{\"end\":50748,\"start\":50736},{\"end\":50758,\"start\":50748},{\"end\":50768,\"start\":50758},{\"end\":50782,\"start\":50768},{\"end\":50790,\"start\":50782},{\"end\":50800,\"start\":50790},{\"end\":50808,\"start\":50800},{\"end\":51098,\"start\":51087},{\"end\":51106,\"start\":51098},{\"end\":51115,\"start\":51106},{\"end\":51127,\"start\":51115},{\"end\":51133,\"start\":51127},{\"end\":51150,\"start\":51133},{\"end\":51165,\"start\":51150},{\"end\":51175,\"start\":51165},{\"end\":51185,\"start\":51175},{\"end\":51196,\"start\":51185},{\"end\":51510,\"start\":51500},{\"end\":51522,\"start\":51510},{\"end\":51672,\"start\":51662},{\"end\":51687,\"start\":51672},{\"end\":51699,\"start\":51687},{\"end\":52068,\"start\":52056},{\"end\":52079,\"start\":52068},{\"end\":52088,\"start\":52079},{\"end\":52100,\"start\":52088},{\"end\":52110,\"start\":52100},{\"end\":52121,\"start\":52110},{\"end\":52134,\"start\":52121},{\"end\":52147,\"start\":52134},{\"end\":52532,\"start\":52518},{\"end\":52545,\"start\":52532},{\"end\":52557,\"start\":52545},{\"end\":52841,\"start\":52832},{\"end\":52855,\"start\":52841},{\"end\":52864,\"start\":52855},{\"end\":53131,\"start\":53119},{\"end\":53307,\"start\":53293},{\"end\":53319,\"start\":53307},{\"end\":53331,\"start\":53319},{\"end\":53342,\"start\":53331},{\"end\":53346,\"start\":53342},{\"end\":53709,\"start\":53700},{\"end\":53725,\"start\":53709},{\"end\":53737,\"start\":53725},{\"end\":53751,\"start\":53737},{\"end\":53763,\"start\":53751},{\"end\":54089,\"start\":54076},{\"end\":54103,\"start\":54089},{\"end\":54405,\"start\":54394},{\"end\":54418,\"start\":54405},{\"end\":54427,\"start\":54418},{\"end\":54437,\"start\":54427},{\"end\":54446,\"start\":54437},{\"end\":54816,\"start\":54807},{\"end\":54830,\"start\":54816},{\"end\":54840,\"start\":54830},{\"end\":54851,\"start\":54840},{\"end\":54861,\"start\":54851},{\"end\":54872,\"start\":54861},{\"end\":54882,\"start\":54872},{\"end\":54891,\"start\":54882},{\"end\":54899,\"start\":54891},{\"end\":54909,\"start\":54899},{\"end\":54919,\"start\":54909},{\"end\":55350,\"start\":55340},{\"end\":55356,\"start\":55350},{\"end\":55362,\"start\":55356},{\"end\":55374,\"start\":55362},{\"end\":55383,\"start\":55374},{\"end\":55394,\"start\":55383},{\"end\":55404,\"start\":55394},{\"end\":55708,\"start\":55696},{\"end\":55717,\"start\":55708},{\"end\":55727,\"start\":55717},{\"end\":55737,\"start\":55727},{\"end\":56188,\"start\":56176},{\"end\":56197,\"start\":56188},{\"end\":56201,\"start\":56197}]", "bib_venue": "[{\"end\":49618,\"start\":49565},{\"end\":49618,\"start\":49565},{\"end\":48784,\"start\":48767},{\"end\":49141,\"start\":49117},{\"end\":49563,\"start\":49495},{\"end\":49999,\"start\":49991},{\"end\":50352,\"start\":50336},{\"end\":50734,\"start\":50679},{\"end\":51200,\"start\":51196},{\"end\":51723,\"start\":51699},{\"end\":52164,\"start\":52147},{\"end\":52568,\"start\":52557},{\"end\":52881,\"start\":52864},{\"end\":53117,\"start\":53079},{\"end\":53419,\"start\":53346},{\"end\":53787,\"start\":53763},{\"end\":54074,\"start\":53965},{\"end\":54296,\"start\":54276},{\"end\":54509,\"start\":54446},{\"end\":54934,\"start\":54919},{\"end\":55423,\"start\":55404},{\"end\":55889,\"start\":55737},{\"end\":56224,\"start\":56201},{\"end\":56486,\"start\":56364},{\"end\":57030,\"start\":56952},{\"end\":48784,\"start\":48767},{\"end\":49141,\"start\":49117},{\"end\":49563,\"start\":49495},{\"end\":49999,\"start\":49991},{\"end\":50352,\"start\":50336},{\"end\":50734,\"start\":50679},{\"end\":51200,\"start\":51196},{\"end\":51723,\"start\":51699},{\"end\":52164,\"start\":52147},{\"end\":52568,\"start\":52557},{\"end\":52881,\"start\":52864},{\"end\":53117,\"start\":53079},{\"end\":53419,\"start\":53346},{\"end\":53787,\"start\":53763},{\"end\":54074,\"start\":53965},{\"end\":54296,\"start\":54276},{\"end\":54509,\"start\":54446},{\"end\":54934,\"start\":54919},{\"end\":55423,\"start\":55404},{\"end\":55889,\"start\":55737},{\"end\":56224,\"start\":56201},{\"end\":56486,\"start\":56364},{\"end\":57030,\"start\":56952}]"}}}, "year": 2023, "month": 12, "day": 17}