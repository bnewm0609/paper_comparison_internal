{"id": 252967697, "updated": "2023-10-05 09:32:36.207", "metadata": {"title": "CAN-BERT do it? Controller Area Network Intrusion Detection System based on BERT Language Model", "authors": "[{\"first\":\"Natasha\",\"last\":\"Alkhatib\",\"middle\":[]},{\"first\":\"Maria\",\"last\":\"Mushtaq\",\"middle\":[]},{\"first\":\"Hadi\",\"last\":\"Ghauch\",\"middle\":[]},{\"first\":\"Jean-Luc\",\"last\":\"Danger\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "Due to the rising number of sophisticated customer functionalities, electronic control units (ECUs) are increasingly integrated into modern automotive systems. However, the high connectivity between the in-vehicle and the external networks paves the way for hackers who could exploit in-vehicle network protocols' vulnerabilities. Among these protocols, the Controller Area Network (CAN), known as the most widely used in-vehicle networking technology, lacks encryption and authentication mechanisms, making the communications delivered by distributed ECUs insecure. Inspired by the outstanding performance of bidirectional encoder representations from transformers (BERT) for improving many natural language processing tasks, we propose in this paper ``CAN-BERT\", a deep learning based network intrusion detection system, to detect cyber attacks on CAN bus protocol. We show that the BERT model can learn the sequence of arbitration identifiers (IDs) in the CAN bus for anomaly detection using the ``masked language model\"unsupervised training objective. The experimental results on the ``Car Hacking: Attack \\&Defense Challenge 2020\"dataset show that ``CAN-BERT\"outperforms state-of-the-art approaches. In addition to being able to identify in-vehicle intrusions in real-time within 0.8 ms to 3 ms w.r.t CAN ID sequence length, it can also detect a wide variety of cyberattacks with an F1-score of between 0.81 and 0.99.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2210.09439", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/aiccsa/AlkhatibMGD22", "doi": "10.1109/aiccsa56895.2022.10017800"}}, "content": {"source": {"pdf_hash": "1a205b0e91393d3f1837ce54fb2e44b56f12169a", "pdf_src": "Arxiv", "pdf_uri": "[\"https://export.arxiv.org/pdf/2210.09439v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "9fec9ad78d6e1dcf208e4de0ad4ac3a0603fee04", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/1a205b0e91393d3f1837ce54fb2e44b56f12169a.txt", "contents": "\nCAN-BERT do it? Controller Area Network Intrusion Detection System based on BERT Language Model\n\n\nNatasha Alkhatib natasha.alkhatib@telecom-paris.fr \nT\u00e9l\u00e9com Paris\nParis, PalaiseauIPFrance\n\nMaria Mushtaq maria.mushtaq@telecom-paris.fr \nT\u00e9l\u00e9com Paris\nParis, PalaiseauIPFrance\n\nHadi Ghauch hadi.ghauch@telecom-paris.fr \nT\u00e9l\u00e9com Paris\nParis, PalaiseauIPFrance\n\nJean-Luc Danger jean-luc.danger@telecom-paris.fr \nT\u00e9l\u00e9com Paris\nParis, PalaiseauIPFrance\n\nCAN-BERT do it? Controller Area Network Intrusion Detection System based on BERT Language Model\nIndex Terms-controller area networkCANIntrusion De- tectionbidirectional encoder representations from transformersBERTin-vehicle networkcyberattacks\nDue to the rising number of sophisticated customer functionalities, electronic control units (ECUs) are increasingly integrated into modern automotive systems. However, the high connectivity between the in-vehicle and the external networks paves the way for hackers who could exploit in-vehicle network protocols' vulnerabilities. Among these protocols, the Controller Area Network (CAN), known as the most widely used invehicle networking technology, lacks encryption and authentication mechanisms, making the communications delivered by distributed ECUs insecure. Inspired by the outstanding performance of bidirectional encoder representations from transformers (BERT) for improving many natural language processing tasks, we propose in this paper \"CAN-BERT\", a deep learning based network intrusion detection system, to detect cyber attacks on CAN bus protocol. We show that the BERT model can learn the sequence of arbitration identifiers (IDs) in the CAN bus for anomaly detection using the \"masked language model\" unsupervised training objective. The experimental results on the \"Car Hacking: Attack & Defense Challenge 2020\" dataset show that \"CAN-BERT\" outperforms state-of-the-art approaches. In addition to being able to identify in-vehicle intrusions in realtime within 0.8 ms to 3 ms w.r.t CAN ID sequence length, it can also detect a wide variety of cyberattacks with an F1-score of between 0.81 and 0.99.\n\nI. INTRODUCTION\n\nTo fulfill automotive features, the Controller Area Network (CAN) bus is widely used as the de-facto standard for message communication between different electronic control units (ECUs) in today's vehicles. It is sometimes referred to as a \"message-based\" system, since it focuses on the transmission of diagnostic, informative and controlling data through messages, also known as CAN data frames. In fact, while developing a vehicle, all conceivable CAN bus messages and their respective priority, encoded into an identifier called \"CAN ID\", must be determined beforehand. Due to the lack of authentication, any device can connect physically or wirelessly to the CAN bus, broadcast CAN data frames, and all the participants on the CAN bus can receive it without verifying its source. Consequently, since CAN security was not a design priority, many message injection attacks have become widely implemented. These attacks can interfere with the desired function of the system, shut down some connected nodes, and make the vehicle behave abnormally, putting at risk the safety of the driver and the passengers. To address these security flaws, researchers have proposed intrusion detection as a supplementary layer of protection to specialized security solutions. By monitoring the communication between different ECUs within a CAN bus system, a network intrusion detection system (N-IDS) can detect deviations from the normal message exchange behavior and, thereby, identify both anticipated and novel cyberattacks. The adoption of deep neural networks for in-vehicle intrusion detection have lately proliferated, with impressive results. Since a message injection attack can alter the normal order of occurence of several CAN IDs, researchers have deployed deep learning based sequential models, to model the CAN ID sequences. Some studies have proposed the use of autoregressive models that are trained to capture the patterns of regular CAN ID sequences by predicting the future CAN ID sequence based on the preceding one, such as recurrent neural network (RNN) models and its variants and the generative pretrained transformer (GPT). However, these models identify malicious network intrusions on CAN ID traffic by focusing primarily on the exchange of CAN ID messages from earlier steps rather than integrating the left and right context of a CAN ID sequence, limiting the model's capacity to grasp the whole context information representation. Additionally, these algorithms focus largely on the correlation between CAN ID messages in normal sequences, which would result in false alarms for intrusion detection whenever the correlation is breached. Hence, due to these limitations, the autoregressive models do not adequately depict the natural communication behavior between the various ECUs.\n\nTo address these challenges, we propose CAN-BERT, an intrusion detection system based on a language representation model called Bidirectional Encoder Representations from Transformers (BERT). CAN-BERT, in contrast to autoregressive models, is a self-supervised model which can successfully depict deep bidirectional representations from CAN ID sequences by conditioning on both left and right context in its various layers. By using the \"masked language model\" unsupervised training objective, CAN-BERT model masks some of the CAN IDs in the input at random, with the goal of predicting the conventional ID of the masked word based on its left and right context. We evaluate our approach using the recently published \"Car Hacking: Attack & Defense Challenge 2020\" collected from three different cars, Chevrolet Spark, Hyundai Sonata and Kia Soul and which contains diverse types of message injection attacks.\n\nOur contributions are summarized below:\n\n\u2022 Inspired by the outstanding performance of BERT model for improving many natural language processing tasks, we propose \"CAN-BERT\", a novel BERT-based intrusion detection system architecture which can detect known and unprecedented cyberattacks in CAN ID sequences. \u2022 We evaluate the performance of our approach with the recently published \"Car Hacking: Attack & Defense Challenge 2020\" collected from three different cars, Chevrolet Spark, Hyundai Sonata and KIA Soul and which contains diverse types of message injection attacks.\n\nWe also compare our model with other baseline models.\n\nTowards this end, our paper is organized into six sections.\n\nIn Section III, we present an overview of the Controller Area Network (CAN) and the Bidirectional Encoder Representations from Transformers model (BERT). In Section IV, we present an overview of our proposed framework \"CAN-BERT\". Section V discusses the launched experiments with the corresponding dataset and the proposed metrics for IDS' evaluation. In Section VI, we discuss the obtained results showing the proposed model accuracy and complexity. Finally, we conclude our paper with future work direction.\n\nII. RELATED WORK Intrusion Detection systems (IDSs) have been widely used to detect intrusions on the Controller Area Network (CAN). Intrusions can be detected either by inspecting the content or the signals transmitted by CAN data frames [19], or by examining the order by which different CAN data frames' identifiers are exchanged between the ECUs [20].\n\n\nIII. PRELIMINARIES\n\n\nA. Controller Area Network\n\nThe Controller Area Network (CAN), created by BOSCH in 1983, is a potent networking technology essential for the development of useful automotive features. Due to its robustness represented by its ability to allow various ECUs to be connected in almost all areas of a car, it still prevails in vehicles today. As seen in Figure, it is a bus system, meaning that all Electronic Control Units (ECUs) share the same wiring.\n\nIt is a \"message-based\" system in which messages, also known as CAN data frames, are transmitted between various ECUs. As depicted in Figure. 2, each CAN data frame is composed of the following elements: Start of frame (SOF), identifier (ID), Remote frame transmission field (RTR), control field, data, cyclic redundancy check (CRC), delimiters (DEL) and acknowledgment fields (ACK), and end of frame fields. Each CAN bus message has a priority that is represented by the arbitration identifier field (ID) that can either be composed of 11 or 29 bits, depending on the car manufacturer and which will be mainly used in our work for detecting in-vehicle intrusions.\n\nTo avoid contention between multiple ECUs willing to transmit CAN messages in the medium, CAN employs a priority-based mechanism which allows the ECU with the highest priority/lowest value identifier to transmit before others. The procedure is termed \"arbitration\" because the message with the highest priority wins out over competing messages with a lower priority at the time of transmission.\n\n1) Security Weaknesses: CAN does not prohibit several ECUs from sharing the same IDs. Moreover, CAN messages are broadcast and do not contain any sender's address. Consequently, any device linked to the CAN bus can use any predefined ID, communicate its message without authentication or encryption, and all associated ECUs can receive it. The receiver defines whether or not a message identification causes the receiving ECU to retain and process the given data. Consequently, an attacker is able to broadcast spoofed CAN messages, eavesdrop on all the CAN traffic and collect detailed information about it, resulting in Fuzzing and Malfunction attacks.\n\nAdditionally, as previously mentionned, the CAN bus leverages the arbitration method which discerns between \"dominant\" (0) and \"recessive\" (1) bits in the message identifiers. Therefore, if several ECUs begin transmitting simultaneously, the ECU whose message begins with a greater number of dominant \"0\" bits will take over the CAN bus. As soon as a unit detects that the message on the bus is no longer the message it is transmitting, it halts its transmission, waits for the real transmission to conclude, then waits for the interframe gap to expire and retransmits its message. This phenomenon carries the risk that a message with a lower priority will never be delivered if the network is very congested and can be exploited by attackers to launch denial of service (DoS)/ flooding attacks.\n\n\nB. BERT\n\nBidirectional Encoder Representations from Transformers (BERT), proposed by Devlin et al. [2], is a state-of-the-art language representation model which is designed to pretrain bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. Regarding its architecture, it is a multi-layer bidirectional Transformer encoder based on the original implementation proposed by Vaswani et al. [3].\n\nInspired by its outstanding performance in modeling sequential data, BERT is recently employed for sequence anomaly detection [6] [7] [8] [9] [10]. To the best of our knowledge, none of the previous works have evaluated the performance of the BERT model for in-vehicle intrusion detection on CAN protocol.\n\nIn order to detect anomalies in sequences, it's crucial to incorporate context from both left and right directions of the sequence. Sequential anomalies may be misdetected by traditional unidirectional models, such as OpenAI GPT and RNNs, where every token can only attend to context to its left. To solve this significant constraint, some researchers have proposed a shallow concatenation of both left-to-right and right-to-left architecture of the autoregressive models , such as Bi-RNN and Bi-GPT [5]. However, these approaches aren't as powerful as BERT which adopts a \"masked language model\" (MLM) training objective, in which input sequence tokens are randomly masked and the goal is to predict the original vocabulary id of the masked word based on its context. In contrast to denoising auto-encoders, BERT predicts the masked words instead of reconstructing the whole sequence [12].\n\n\nIV. PROPOSED FRAMEWORK: CAN-BERT\n\nWe propose \"CAN-BERT\", a pattern-based anomaly detection algorithmn, which leverages a BERT-based architecture to detect message injection intrusions in the CAN bus. As seen in Figure. 4, our model is composed of a multi-layer bidirectional Transformer encoder and is trained using the \"masked language model\" self-supervised task to model normal CAN ID sequences. The following subsections elaborately describe the suggested framework.\n\n\nA. Model description\n\nNote that S = [id 1 , ..., id t , ..., id T ] is an observed sequence of T CAN identifiers, arranged in their order of transmission in the CAN bus network, where an identifier id t \u2208 ID is an Mdimensional vector which denotes the CAN ID transmitted at time t by an ECU, ID indicates the set of CAN IDs extracted from CAN messages, and M is the size of the ID set.\n\nSince anomaly detection is an unsupervised learning-based technique in which only normal data are used for training, a collection of N CAN ID sequences, represented as D training = {S 1 , ..., S j , ..., S N }, is solely used as a training dataset. Identifier Embeddings To feed the appropriate input to the BERT model, each identifier id j t with size (M,1) in a CAN sequence S j is firstly projected into a d-dimensional space using a single linear layer, i.e.:\ne j t = W e id j t + b e , \u2200i \u2208 {1..T }, \u2200j \u2208 {1..N }(1)\nwhere e j t represents the identifier embedding with size (d,1), W e \u2208 R d\u00d7M is the input embedding weight matrix, and b e \u2208 R d denotes the bias. Both W e and b e are trainable parameters.\n\nSubsequently, the identifier's position is encoded into a d-dimensional positional embedding p j t using a sinusoidal function. To this end, the CAN ID, fed into the CAN-BERT model, is a summation of both the positional encoding and the input embedding :\nx j t = e j t + p j t(2)\nwhere x j t is the total embedding j-th identifier in the t-th CAN ID sequence id j t , thereby the convergence of the input\nsequence S j into X j = [x j 1 , ..x j t .., x j T ] T with X j a matrix with size T \u00d7 d.\nTransformer Encoder The encoded input X j is then delivered into a stack of L transformer encoder layers, each of which has two sub-layers: a multi-head self-attention mechanism and a position-wise feed-forward network [3]. A residual connection is employed around each of these two sub-layers, followed by layer normalization [4], as follows: where E (j,l) represents the output of the first sublayer for the l-th transformer encoder layer with size T \u00d7d, H (j,l) represents the output of the second sublayer for the l-th transformer encoder layer with size T \u00d7 d, g is the multi-head attention function, z is the position wise feed forward function, and f is the layer normalization function.\nE (j,l) = g(X (j,l) ) + f (X (j,l) + g(X (j,l) )) H (j,l) = z(E (j,l) ) + f (E (j,l) + z(E (j,l) )) X (j,l+1) = H (j,l) , \u2200l < L(3)\nAttention We use the scaled dot-product attention proposed by [3], requiring query Q (j,l) , key K (j,l) , and value V (j,l) representations, and which are projections of the embedded sequence X (j,l) \u2208 R T \u00d7d . In fact, we leverage the dot-product similarity to compare the query representation of a given CAN identifier to all other keys. Hence, if the query and key are comparable have a high attention weight, the matching value is deemed to be relevant. The output is therefore computed as a weighted sum of the values V:\nAttn(Q (j,l) , K (j,l) , V (j,l) ) = \u03c3( Q (j,l) K (j,l)T \u221a d )V (j,l)\nAttn(Q (j,l) , K (j,l) , V (j,l) ) = AV (j,l)\n\nwhere \u03c3 is the softmax function, A \u2208 R T \u00d7T denotes the attention weight matrix containing attention weights, and d is the dimension of the Q (j,l) , K (j,l) ,V (j,l) vectors. As described by [3], the multiple heads of attention allows the model to concurrently capture diverse aspect of data at distinct CAN IDs. Hence, we adopt a multi-head attention (MHA) mechanism in which the d-dimensional CAN identifers are projected into subspaces calculated by different attention heads n \u2208 {1, .., H}:\n\nQ (j,n,l) = X (j,l) W (Q,n) , Q (j,n,l) \u2208 R T \u00d7F K (j,n,l) = X (j,l) W (K,n) , K (j,n,l) \u2208 R T \u00d7F V (j,n,l) = X (j,l) W (V,n) , V (j,n,l) \u2208 R T \u00d7F (5) where Q (j,n,l) , K (j,n,l) and V (j,n,l) are the query, key and value vectors, respectively of the j \u2212 th CAN ID sequence for the l-th transformer encoder layer and which are calculated using the n-th attention head. The W (Q,n) , W (K,n) and W (V,n) are their corresponding trainable weight matrices \u2208 R d\u00d7F , and F is set to D/H. The results are then concatenated and projected back into representation space using the weight matrix W o \u2208 R HF \u00d7D as follows:\nhead (j,l) n = Attn(Q (j,n,l) , K (j,n,l) , V (j,n,l) )(6)X (j,l) = [head (j,l) 1 , ..head (j,l) n , .., head (j,l) H ]W O(7)\nwhere X (j,l) \u2208 R (T,d) .\n\nPosition-wise feed-forward A position-wise feed-forward network with a ReLU activation is thereby applied to each representation in each of the layers of our encoder, in addition to attention sub-layers, using the following equation:\nz(E (j,l) ) = [W 1 E (j,l) ] + \u2022 W 2(8)\nwhere E (j,l) is previously defined in (3), W 1 and W 2 are trainable projection matrices, where \u2022 is the hadarmard product, and [] + is the element-wise maximum. After passing through different transformer layers, the Lth contextual embedding vectors of the CAN IDs, denoted as h \nm j t = W m h (j,L) t + b m , \u2200i \u2208 {1..T }, \u2200j \u2208 {1..N }(9)\nwhere m j t represents the projected output with size (M ,1), W m \u2208 R M \u00d7d is the input embedding weight matrix, and b e \u2208 R M denotes the bias. Both W m and b m are trainable parameters.\n\n\nB. Training and Inference\n\nWe use the masked language model training method to train the CAN-BERT model on capturing the patterns of normal CAN ID sequences. Hence, CAN sequences with random mask as inputs, where we randomly replace a ratio of CAN IDs in a sequence with a specific MASK token, are fed into CAN-BERT. The purpose of training is to reliably anticipate the CAN IDs that have been randomly masked.\n\nTo achieve that, we feed the contextual embedding vector of the u-th MASK in the j-th CAN ID sequence m j M ASKu to a softmax function, which will return a probability distribution for the whole set of CAN IDs ID:\ny j [M ASKu] = \u03c3(W c m j [M ASKu] + b c )(10)\nwhere\u0177 j [M ASKu] is an m-dimensional vector, \u03c3 is the softmax function, m j [M ASKu] and b c are trainable parameters. CAN-BERT is trained to minimize the cross entropy loss over a batch of I sequences ( with I \u2264 N ), for masked CAN ID prediction, which is defined as:\nL M ASK = \u2212 1 IR N j=1 R u=1 y j [M ASKu] log\u0177 j [M ASKu](11)\nwhere the ground-truth u-th CAN ID in the j-th sequence is denoted as y j [M ASKu] , R is the total number of masked tokens in the j-th sequence, and N is the number of training samples.\n\nBy modeling the normal exchange of messages through CAN bus using CAN-BERT, our model is expected, after training, to predict a candidate set with the normal CAN IDs having the highest likelihood for each masked token. Hence, for a randomly masked testing sequence, we calculate the probability distribution represented in (10), for each masked CAN ID. Therefore, if the actual CAN ID is among the anticipated candidates, the corresponding CAN ID sequence is considered as normal. Otherwise, it is deemed abnormal.\n\n\nV. EXPERIMENTAL SETTINGS A. Dataset\n\nTo assess the proposed CAN-BERT, we leverage the \"In-Vehicle Network Intrusion Detection Challenge\" dataset [13] (presented in Table I), which was used at the \"In-vehicle Network Intrusion Detection track' of 'Information Security R&D Data Challenge 2019. It includes normal and abnormal in-vehicle network traffic data of HYUNDAI Sonata, KIA Soul, and CHEVROLET Spark vehicles collected during their stationary state. We have mainly used its preliminary dataset, which includes three types of attacks (Flooding, Fuzzy, and Malfunction). The dataset is labeled and each sample is represented by the following features: \"Timestamp\" representing the logging time, \"CAN ID\" representing the CAN Identifier, \"DLC\" indicating the Data length code, and the Payload indicating the \"CAN data\" field.\n\n1) Attacks: The dataset contains the following attacks:\n\n\u2022 Flooding Attack The flooding attack was carried out by injecting many messages with the CAN ID set to 0x000 into the CAN network. Consequently, an ECU that transmits CAN data frames with such CAN ID dominates the CAN bus, which could restrict the communications among the ECU nodes and impair normal in-vehicle functions.\n\n\u2022 Fuzzy Attack To implement fuzzy attacks, the attacker injected every 0.0003 seconds random CAN packets, for both the ID field and the Data field. This process lead to abnormal automotive functionalities behavior such as short beeping sound repeatedly occurring, the heater turning on, etc. \u2022 Malfunction Attack The malfunction attack was carried out by injecting messages with a specified CAN ID from among the extractable CAN IDs of a particular vehicle in order to disable relevant automotive functions, such as IDs 0\u00d7316, 0\u00d7153 and 0\u00d718E for the HYUNDAI YF Sonata, KIA Soul, and CHEVROLET Spark vehicles, respectively. As mentioned in Section IV, we aim to detect if a sequence of ordered CAN ID contains injected messages. Hence, in order to represent CAN ID sequences, we use the Feature-based Sliding Window (FSW) to group CAN IDs which belong to the dataset into subsequences with fixed window size T, where T \u2208 {16, 32, 64, 128, 256} and the slide size is 1. Moreover, each CAN ID sequence S = [id 1 , ..., id t , ..., id T ] has its corresponding labels represented by Y = [y 1 , ..., y t , ..., y T ] wherein each identifier id t \u2208 S is labeled as y t = 1 if id t is an injected identifier in S or as y t = 0 otherwise. However, to identify the state of each sequence, we have used the following criteria:\nz = 1 (abnormal) if \u2203y t = 1, \u2200t \u2208 {1, .., T } 0 (normal) otherwise\nwhere z is the CAN ID sequence's label.\n\n\nB. Benchmark Models\n\nThe benchmark models for evaluating the performance of different CAN ID sequence anomaly detection algorithms with CAN-BERT on the chosen dataset, are detailed in this section. should have more loss or reconstruction error than a normal sample. In other words, the loss sustained when an anomalous sample is processed by a PCA algorithm and projected back to its dimension using PCA also should be greater than when the same procedure is performed on a normal sample. \u2022 Isolation Forest (iForest): Isolation forest (IF), proposed by Liu at al. [15], detects anomalies using isolation rather than modelling the normal points. In fact, this technique presents a novel approach for isolating anomalies using binary trees, providing a new prospect for a speedier anomaly detector that directly targets abnormalities rather than profiling all regular instances. \u2022 Autoencoder (AE): The autoencoder, introduced by Rumelhart et al. [16], is a deep learning based algorithm which seeks to learn a low-dimensional feature representation space suitable for reconstructing the provided data instances. During the encoding process, the encoder maps the original data onto low-dimensional feature space, while the decoder tries to retrieve the original data from the projected low-dimensional space. Reconstruction loss functions are used to learn the parameters of the encoder and decoder networks. Its reconstruction error value must be minimized during the training of normal instances and therefore used during testing as an anomaly score. In other words, compared to the typical data reconstruction error, anomalies that differ from the majority of the data have a large data reconstruction error. In our experiments, we have tested Long short-term based memory (LSTM) and Bidirectional LSTM (BiLSTM) models with different network hyperparameters: BiLSTM-AE-4 (with 4 layers), LSTM-AE-4 (with 4 layers), and LSTM-AE-8 (with 8 layers).\n\n\nC. Evaluation metrics\n\nFor measuring the performance of different anomaly-based IDS, we use the F1-score metric, a weighted average result of both metrics precision and recall and which is specifically used when the dataset is imbalanced. The model has a large predictive power if the F1-score is near 1.0.\n\nPrecision is the ratio of correctly classified predicted abnormal observations of all the observations in the predicted class.\n\nP recision = T P T P + F P\n\nRecall is the ratio of correctly predicted abnormal observations of all observations in the actual class.\nRecall = T P T P + F N(13)\nHence, the F1-score is calculated using the following equation:\nF 1 \u2212 score = 2 \u00b7 P recision \u00b7 Recall P recision + Recall(14)\nWhere: TP= True Positive; FP=False Positive; TN= True Negative; FN=False Negative.\n\n\nVI. RESULTS\n\nTo evaluate our model, we leverage the Python deep learning framework Pytorch [17]. We train and evaluate them on NVIDIA\u00ae Tesla\u00ae V100S with 32 GB HBM2 memory.\n\n\nA. Model Configuration & Hyperparameter tuning\n\nAs presented in Table II, for CAN-BERT, we have chosen the total number of transformer encoder layers as 4. In each transformer layer, the position-wise feed forward network is composed of two dense layers where the first one projects d=256 dimensional CAN identifier embedding into d f f =512 dimensional space, followed by a ReLU activation. The second dense layer maps back the 512-dimensional vector into the ddimensional space. For training, we use a batch size of 32, a learning rate of 0.001 and the Adam optimizer [18] with its default parameters \u03b2 1 = 0.9 and \u03b2 2 = 0.999. To avoid overfitting, we employ the same dropout of P drop =0.1 for all dropout layers in our network. Moreover, we apply early stopping for a total number of 200 epochs and a patience of 10 epochs as a form of regularization used to avoid overfitting.  The hyperparameters, including the ratio of masked CAN IDs in a sequence m, and h the number of attention heads are tuned based on a validation set for the three car types and the different message injection attacks. As seen in Figure 5, raising the ratios of masked CAN IDs in the sequences from 0.1 to 0.45 somewhat improves F1 scores, however increasing the ratios further degrades performance, as is the case for m=0.65. Furthermore, the model performance is relatively stable by setting different attention head h \u2208 {1, 2, 4, 8} values for each mask ratio m \u2208 {0.15, 0.3, 0.45, 0.6}. Therefore, in our invehicle intrusion detection use case, a single attention head is sufficiant to detect different types of intrusions. Note that, in our experiments, we use the same ratio of masked CAN IDS m=0.45 and h=1 for both training and inference phases.\n\n\nB. Model Accuracy\n\nAs seen in Figure 6, we compare performance of the CAN-BERT model with other baselines approaches for different sequence length T using the F1-score metric. In fact, we varied the sequence length among values of 16, 32, 64, 128 and 256 CAN IDs per sequence in the experiments. If our approaches could identify a message injection attack in a shorter sequence length, it would be more advantageous in a practical situation. The traditional machine learning algorithms such as Isolation Forest (iForest), and Principal Component Analysis (PCA) perform poorly and maintain the same F1score metric w.r.t sequence length. Because these models presume small datasets with a limited number of features, they fail to discover abnormalities in high-dimensional datasets. Because of this, a significant fraction of irrelevant features may effectively disguise the underlying abnormalities in the input data, resulting in poor anomaly identification performance when dealing with large input dimensions. Meanwhile, both deep learning based models autoencoder (AE) and CAN-BERT outperformed the traditional anomaly detection models over different window sizes. However, when the length of the CAN ID sequence is increased, both models performed oppositely. In contrast to the baseline models, our suggested model, CAN-BERT, significantly outperforms them by huge margins and obtains respectable F1 scores \u2208 [0.85, 0.99], demonstrating the usefulness of using BERT-based models to capture the patterns of CAN ID sequences when T \u2265 32. However, on short sequence length as is the case for T = 16, the model performs modestly with F1-score \u2208 [0.6, 0.9] for different kind of attacks. These experiments, therefore, reveal that by using self-supervised training tasks, CAN-BERT can effectively model medium to long normal CAN ID sequences and accurately detect anomalous sequences.\n\n\nC. Model Complexity\n\nFrom a practical point of view, we must assess not only the classification performance but also the model complexity to check if the model's ability for real-time in-vehicle intrusion detection in CAN networks. Therefore, we assessed the inference time per sample as well as the number of parameters for the CAN-BERT model w.r.t different car types. As depicted in  Table III, the intrusion detection inference time varies between 0.8 and 3.1 ms w.r.t CAN ID sequence length. Hence, when considering a sequence length of 32 CAN IDs, our model detects an intrusion in 0.9 to 1 ms, which is suitable for realtime detection. Furthermore, having a size between 20MB and 70 MB and a number of parameters ranging between 2 to 3 millions, our model can be either deployed in performant ECU or even on a cloud server wirelessly connected to the vehicle.\n\nVII. CONCLUSION Identification of intrusions within the vehicle is critical for defending it against malicious cyberattacks. In this paper, we suggest CAN-BERT, a self-supervised intrusion detection system based on BERT model, for in-vehicle intrusion detection. Experimental results on benchmark datasets for different CAN ID sequence length have shown that CAN-BERT surpasses state-of-the-art techniques for CAN ID sequence anomaly detection with an F1-score ranging between 0.81 and 0.99 for different type of attacks and is appropriate for real-time detection with an inference time ranging between 0.8 and 3 ms w.r.t CAN ID sequence length. For future work, we aim to deploy our model on embedded electronic control units (ECU) and test the model efficiency in a real vehicle environment.\n\nFig. 1 .\n1A CAN bus network exploited by attackers through different physical and wireless interfaces.\n\nFig. 2 .\n2CAN packet structure.\n\nFig. 3 .\n3ECU devices connected through CAN bus, source[1].\n\nFig. 4 .\n4CAN-BERT model architecture\n\n]\nT , are fed into a single linear layer which projects them back to the Mdimensional layer, as follows:\n\n\u2022Fig. 5 .\n5Principal Component Analysis (PCA): PCA[14] is a feature selection model which can be used to reduce data features from m dimensions to n. Inverting the PCA transform does not retrieve the data lost during the application of the transform. The essence of PCAbased anomaly identification is that an anomalous Hyperparameter tuning the mask ratio m and the number of attention heads h on the \"CHEVROLET Spark\" dataset for T =32. We have obtained similar behavior pattern for the results w.r.t other sequence length and car types.\n\nFig. 6 .\n6Comparision of the CAN-BERT model with other anomaly detection baselines using the F1-score percentage metric, for different message injection attacks applied on different car models w.r.t sequence length T .\n\nTABLE I\nIIN-VEHICLE NETWORK INTRUSION DETECTION DATASETVehicle \nDataset \n# Normal \n# Abnormal \nSize \npackets \npackets \n(MB) \nAttack Free \n136,933 \nN/A \n6.2 \nCHEVROLET \nFlooding \n70,001 \n14,999 \n4.2 \nSpark \nFuzzy \n37,957 \n3,043 \n2.0 \nMalfunction \n47,005 \n3,995 \n2.5 \nAttack Free \n117,172 \nN/A \n5.8 \nHYUNDAI \nFlooding \n78,907 \n17,093 \n4.9 \nSonata \nFuzzy \n78,905 \n9,095 \n4.5 \nMalfunction \n78,798 \n8,202 \n4.5 \nAttack Free \n192,515 \nN/A \n9.3 \nKIA \nFlooding \n103,928 \n16,072 \n6.2 \nSoul \nFuzzy \n122,387 \n21,613 \n7.4 \nMalfunction \n108,230 \n4,770 \n5.8 \n\n\n\nTABLE II CAN\nII-BERT MODEL CONFIGURATIONParameter \nValue \nN \n4 \nd model \n256 \nd f f \n512 \nh \n1 \nP drop \n0.1 \nm \n0.45 \n# Candidates \n5 \nOptimizer \nAdam \nAdam \u03b2 1 \n0.9 \nAdam \u03b2 2 \n0.999 \nLearning rate \n0.001 \nBatch size \n32 \n# Epochs \n200 \nPatience \n10 \n\n\n\nTABLE III CAN\nIII-BERT MODEL COMPLEXITYVehicle \nFeatures \nValues \n\nCHEVROLET Spark \n\nNumber of Parameters \n2,937,422 \nModel Size (MB) \n[20, 70] \nInference Time (ms) \n[0.8, 3.1] \n\nHYUNDAI Sonata \n\nNumber of Parameters \n3,149,291 \nModel Size (MB) \n[20, 70] \nInference Time (ms) \n[0.8, 3.5] \n\nKIA Soul \n\nNumber of Parameters \n3,163,142 \nModel Size (MB) \n[20, 70] \nInference Time (ms) \n[0.8, 3.8] \n\n\n\nAutomotive ethernet. Kirsten Matheus, Thomas K\u00f6nigseder, Cambridge University PressMatheus, Kirsten, and Thomas K\u00f6nigseder. Automotive ethernet. Cam- bridge University Press, 2021.\n\nBert: Pre-training of deep bidirectional transformers for language understanding. Jacob Devlin, arXiv:1810.04805arXiv preprintDevlin, Jacob, et al. \"Bert: Pre-training of deep bidirectional transformers for language understanding.\" arXiv preprint arXiv:1810.04805 (2018).\n\nAdvances in neural information processing systems. Ashish Vaswani, 30Attention is all you needVaswani, Ashish, et al. \"Attention is all you need.\" Advances in neural information processing systems 30 (2017).\n\nLayer normalization. Jimmy Ba, Jamie Ryan Lei, Geoffrey E Kiros, Hinton, arXiv:1607.06450arXiv preprintBa, Jimmy Lei, Jamie Ryan Kiros, and Geoffrey E. Hinton. \"Layer normalization.\" arXiv preprint arXiv:1607.06450 (2016).\n\nIntrusion detection method using bi-directional GPT for in-vehicle controller area networks. Minki Nam, Seungyoung Park, Duk Soo Kim, IEEE Access. 9Nam, Minki, Seungyoung Park, and Duk Soo Kim. \"Intrusion detection method using bi-directional GPT for in-vehicle controller area networks.\" IEEE Access 9 (2021): 124931-124944.\n\nHow is BERT surprised? Layerwise detection of linguistic anomalies. Bai Li, arXiv:2105.07452arXiv preprintLi, Bai, et al. \"How is BERT surprised? Layerwise detection of linguistic anomalies.\" arXiv preprint arXiv:2105.07452 (2021).\n\nLogbert: Log anomaly detection via bert. Haixuan Guo, Shuhan Yuan, Xintao Wu, 2021 International Joint Conference on Neural Networks (IJCNN). IEEEGuo, Haixuan, Shuhan Yuan, and Xintao Wu. \"Logbert: Log anomaly de- tection via bert.\" 2021 International Joint Conference on Neural Networks (IJCNN). IEEE, 2021.\n\nYukyung Lee, Jina Kim, Pilsung Kang, arXiv:2111.09564LAnoBERT: System Log Anomaly Detection based on BERT Masked Language Model. arXiv preprintLee, Yukyung, Jina Kim, and Pilsung Kang. \"LAnoBERT: System Log Anomaly Detection based on BERT Masked Language Model.\" arXiv preprint arXiv:2111.09564 (2021).\n\nLog-based anomaly detection without log parsing. Le, Hongyu Van-Hoang, Zhang, 36th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEELe, Van-Hoang, and Hongyu Zhang. \"Log-based anomaly detection without log parsing.\" 2021 36th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEE, 2021.\n\nSecuring critical infrastructures: Deep-Learning-Based threat detection in IIoT. Keping Yu, IEEE Communications Magazine. 59Yu, Keping, et al. \"Securing critical infrastructures: Deep-Learning- Based threat detection in IIoT.\" IEEE Communications Magazine 59.10 (2021): 76-82.\n\nTS-Bert: Time Series Anomaly Detection via Pretraining Model Bert. Weixia Dang, International Conference on Computational Science. ChamSpringer2021Dang, Weixia, et al. \"TS-Bert: Time Series Anomaly Detection via Pre- training Model Bert.\" International Conference on Computational Science. Springer, Cham, 2021.\n\nExtracting and composing robust features with denoising autoencoders. Pascal Vincent, Proceedings of the 25th international conference on Machine learning. the 25th international conference on Machine learningVincent, Pascal, et al. \"Extracting and composing robust features with denoising autoencoders.\" Proceedings of the 25th international conference on Machine learning. 2008.\n\nCar Hacking: Attack & Defense Challenge 2020 Dataset. Hyunjae Kang, Young Hun Byung Il Kwak, Haneol Lee, Hwejae Lee, Huy Kang Lee, Kim, 10.21227/qvr7-n418IEEE Dataport. Hyunjae Kang, Byung Il Kwak, Young Hun Lee, Haneol Lee, Hwejae Lee, Huy Kang Kim, February 3, 2021, \"Car Hacking: Attack & Defense Challenge 2020 Dataset\", IEEE Dataport, doi: https://dx.doi.org/10.21227/ qvr7-n418\n\nPrincipal component analysis. Herv\u00e9 Abdi, Lynne J Williams, Wiley interdisciplinary reviews: computational statistics. 2Abdi, Herv\u00e9, and Lynne J. Williams. \"Principal component analysis.\" Wiley interdisciplinary reviews: computational statistics 2.4 (2010): 433- 459.\n\nIsolation-based anomaly detection. Fei Liu, Tony, Kai Ting, Ming, Zhou, Zhi-Hua, ACM Transactions on Knowledge Discovery from Data (TKDD). 63Liu, Fei Tony, Ting, Kai Ming and Zhou, Zhi-Hua. \"Isolation-based anomaly detection.\" ACM Transactions on Knowledge Discovery from Data (TKDD) 6.1 (2012): 3.\n\nLearning representations by back-propagating errors. David E Rumelhart, Geoffrey E Hinton, Ronald J Williams, nature. 323Rumelhart, David E., Geoffrey E. Hinton, and Ronald J. Williams. \"Learning representations by back-propagating errors.\" nature 323.6088 (1986): 533-536.\n\nAdam: A method for stochastic optimization. Diederik P Kingma, Jimmy Ba, arXiv:1412.6980arXiv preprintKingma, Diederik P., and Jimmy Ba. \"Adam: A method for stochastic optimization.\" arXiv preprint arXiv:1412.6980 (2014).\n\nCANet: An unsupervised intrusion detection system for high dimensional CAN bus data. Markus Hanselmann, Ieee Access. 8Hanselmann, Markus, et al. \"CANet: An unsupervised intrusion detec- tion system for high dimensional CAN bus data.\" Ieee Access 8 (2020): 58194-58205.\n\nIn-vehicle network intrusion detection using deep convolutional neural network. Hyun Song, Jiyoung Min, Huy Kang Woo, Kim, Vehicular Communications. 21100198Song, Hyun Min, Jiyoung Woo, and Huy Kang Kim. \"In-vehicle network intrusion detection using deep convolutional neural network.\" Vehicular Communications 21 (2020): 100198.\n", "annotations": {"author": "[{\"end\":190,\"start\":99},{\"end\":276,\"start\":191},{\"end\":358,\"start\":277},{\"end\":448,\"start\":359}]", "publisher": null, "author_last_name": "[{\"end\":115,\"start\":107},{\"end\":204,\"start\":197},{\"end\":288,\"start\":282},{\"end\":374,\"start\":368}]", "author_first_name": "[{\"end\":106,\"start\":99},{\"end\":196,\"start\":191},{\"end\":281,\"start\":277},{\"end\":367,\"start\":359}]", "author_affiliation": "[{\"end\":189,\"start\":151},{\"end\":275,\"start\":237},{\"end\":357,\"start\":319},{\"end\":447,\"start\":409}]", "title": "[{\"end\":96,\"start\":1},{\"end\":544,\"start\":449}]", "venue": null, "abstract": "[{\"end\":2113,\"start\":694}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b17\"},\"end\":7289,\"start\":7285},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":7400,\"start\":7396},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":10493,\"start\":10490},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":10846,\"start\":10843},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":10978,\"start\":10975},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":10986,\"start\":10983},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":10995,\"start\":10991},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":11659,\"start\":11656},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":12045,\"start\":12041},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":14338,\"start\":14335},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":14446,\"start\":14443},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":15008,\"start\":15005},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":15782,\"start\":15779},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":16234,\"start\":16231},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":19514,\"start\":19510},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":22574,\"start\":22570},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":22955,\"start\":22951},{\"end\":24858,\"start\":24854},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":25511,\"start\":25507},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":30419,\"start\":30416},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":30621,\"start\":30617}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":30326,\"start\":30223},{\"attributes\":{\"id\":\"fig_1\"},\"end\":30359,\"start\":30327},{\"attributes\":{\"id\":\"fig_2\"},\"end\":30420,\"start\":30360},{\"attributes\":{\"id\":\"fig_3\"},\"end\":30459,\"start\":30421},{\"attributes\":{\"id\":\"fig_4\"},\"end\":30565,\"start\":30460},{\"attributes\":{\"id\":\"fig_5\"},\"end\":31105,\"start\":30566},{\"attributes\":{\"id\":\"fig_6\"},\"end\":31325,\"start\":31106},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":31872,\"start\":31326},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":32126,\"start\":31873},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":32523,\"start\":32127}]", "paragraph": "[{\"end\":4932,\"start\":2132},{\"end\":5842,\"start\":4934},{\"end\":5883,\"start\":5844},{\"end\":6417,\"start\":5885},{\"end\":6472,\"start\":6419},{\"end\":6533,\"start\":6474},{\"end\":7044,\"start\":6535},{\"end\":7401,\"start\":7046},{\"end\":7873,\"start\":7453},{\"end\":8539,\"start\":7875},{\"end\":8935,\"start\":8541},{\"end\":9591,\"start\":8937},{\"end\":10388,\"start\":9593},{\"end\":10847,\"start\":10400},{\"end\":11154,\"start\":10849},{\"end\":12046,\"start\":11156},{\"end\":12519,\"start\":12083},{\"end\":12907,\"start\":12544},{\"end\":13372,\"start\":12909},{\"end\":13619,\"start\":13430},{\"end\":13875,\"start\":13621},{\"end\":14025,\"start\":13901},{\"end\":14810,\"start\":14116},{\"end\":15469,\"start\":14943},{\"end\":15585,\"start\":15540},{\"end\":16082,\"start\":15587},{\"end\":16696,\"start\":16084},{\"end\":16848,\"start\":16823},{\"end\":17083,\"start\":16850},{\"end\":17405,\"start\":17124},{\"end\":17653,\"start\":17466},{\"end\":18066,\"start\":17683},{\"end\":18281,\"start\":18068},{\"end\":18597,\"start\":18328},{\"end\":18846,\"start\":18660},{\"end\":19362,\"start\":18848},{\"end\":20193,\"start\":19402},{\"end\":20250,\"start\":20195},{\"end\":20575,\"start\":20252},{\"end\":21894,\"start\":20577},{\"end\":22002,\"start\":21963},{\"end\":23952,\"start\":22026},{\"end\":24261,\"start\":23978},{\"end\":24389,\"start\":24263},{\"end\":24417,\"start\":24391},{\"end\":24524,\"start\":24419},{\"end\":24615,\"start\":24552},{\"end\":24760,\"start\":24678},{\"end\":24934,\"start\":24776},{\"end\":26672,\"start\":24985},{\"end\":28558,\"start\":26694},{\"end\":29427,\"start\":28582},{\"end\":30222,\"start\":29429}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":13429,\"start\":13373},{\"attributes\":{\"id\":\"formula_1\"},\"end\":13900,\"start\":13876},{\"attributes\":{\"id\":\"formula_2\"},\"end\":14115,\"start\":14026},{\"attributes\":{\"id\":\"formula_3\"},\"end\":14942,\"start\":14811},{\"attributes\":{\"id\":\"formula_4\"},\"end\":15539,\"start\":15470},{\"attributes\":{\"id\":\"formula_6\"},\"end\":16755,\"start\":16697},{\"attributes\":{\"id\":\"formula_7\"},\"end\":16822,\"start\":16755},{\"attributes\":{\"id\":\"formula_8\"},\"end\":17123,\"start\":17084},{\"attributes\":{\"id\":\"formula_9\"},\"end\":17465,\"start\":17406},{\"attributes\":{\"id\":\"formula_10\"},\"end\":18327,\"start\":18282},{\"attributes\":{\"id\":\"formula_11\"},\"end\":18659,\"start\":18598},{\"attributes\":{\"id\":\"formula_12\"},\"end\":21962,\"start\":21895},{\"attributes\":{\"id\":\"formula_14\"},\"end\":24551,\"start\":24525},{\"attributes\":{\"id\":\"formula_15\"},\"end\":24677,\"start\":24616}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":19536,\"start\":19529},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":25009,\"start\":25001},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":28957,\"start\":28948}]", "section_header": "[{\"end\":2130,\"start\":2115},{\"end\":7422,\"start\":7404},{\"end\":7451,\"start\":7425},{\"end\":10398,\"start\":10391},{\"end\":12081,\"start\":12049},{\"end\":12542,\"start\":12522},{\"end\":17681,\"start\":17656},{\"end\":19400,\"start\":19365},{\"end\":22024,\"start\":22005},{\"end\":23976,\"start\":23955},{\"end\":24774,\"start\":24763},{\"end\":24983,\"start\":24937},{\"end\":26692,\"start\":26675},{\"end\":28580,\"start\":28561},{\"end\":30232,\"start\":30224},{\"end\":30336,\"start\":30328},{\"end\":30369,\"start\":30361},{\"end\":30430,\"start\":30422},{\"end\":30462,\"start\":30461},{\"end\":30576,\"start\":30567},{\"end\":31115,\"start\":31107},{\"end\":31334,\"start\":31327},{\"end\":31886,\"start\":31874},{\"end\":32141,\"start\":32128}]", "table": "[{\"end\":31872,\"start\":31382},{\"end\":32126,\"start\":31914},{\"end\":32523,\"start\":32167}]", "figure_caption": "[{\"end\":30326,\"start\":30234},{\"end\":30359,\"start\":30338},{\"end\":30420,\"start\":30371},{\"end\":30459,\"start\":30432},{\"end\":30565,\"start\":30463},{\"end\":31105,\"start\":30578},{\"end\":31325,\"start\":31117},{\"end\":31382,\"start\":31336},{\"end\":31914,\"start\":31889},{\"end\":32167,\"start\":32145}]", "figure_ref": "[{\"end\":7781,\"start\":7774},{\"end\":8016,\"start\":8009},{\"end\":12267,\"start\":12260},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":26057,\"start\":26049},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":26713,\"start\":26705}]", "bib_author_first_name": "[{\"end\":32553,\"start\":32546},{\"end\":32569,\"start\":32563},{\"end\":32794,\"start\":32789},{\"end\":33037,\"start\":33031},{\"end\":33215,\"start\":33210},{\"end\":33225,\"start\":33220},{\"end\":33230,\"start\":33226},{\"end\":33244,\"start\":33236},{\"end\":33246,\"start\":33245},{\"end\":33511,\"start\":33506},{\"end\":33527,\"start\":33517},{\"end\":33541,\"start\":33534},{\"end\":33811,\"start\":33808},{\"end\":34021,\"start\":34014},{\"end\":34033,\"start\":34027},{\"end\":34046,\"start\":34040},{\"end\":34290,\"start\":34283},{\"end\":34300,\"start\":34296},{\"end\":34313,\"start\":34306},{\"end\":34646,\"start\":34640},{\"end\":35018,\"start\":35012},{\"end\":35282,\"start\":35276},{\"end\":35598,\"start\":35592},{\"end\":35965,\"start\":35958},{\"end\":35977,\"start\":35972},{\"end\":35981,\"start\":35978},{\"end\":36003,\"start\":35997},{\"end\":36015,\"start\":36009},{\"end\":36029,\"start\":36021},{\"end\":36324,\"start\":36319},{\"end\":36336,\"start\":36331},{\"end\":36338,\"start\":36337},{\"end\":36596,\"start\":36593},{\"end\":36611,\"start\":36608},{\"end\":36916,\"start\":36911},{\"end\":36918,\"start\":36917},{\"end\":36938,\"start\":36930},{\"end\":36940,\"start\":36939},{\"end\":36955,\"start\":36949},{\"end\":36957,\"start\":36956},{\"end\":37185,\"start\":37177},{\"end\":37187,\"start\":37186},{\"end\":37201,\"start\":37196},{\"end\":37447,\"start\":37441},{\"end\":37710,\"start\":37706},{\"end\":37724,\"start\":37717},{\"end\":37738,\"start\":37730}]", "bib_author_last_name": "[{\"end\":32561,\"start\":32554},{\"end\":32580,\"start\":32570},{\"end\":32801,\"start\":32795},{\"end\":33045,\"start\":33038},{\"end\":33218,\"start\":33216},{\"end\":33234,\"start\":33231},{\"end\":33252,\"start\":33247},{\"end\":33260,\"start\":33254},{\"end\":33515,\"start\":33512},{\"end\":33532,\"start\":33528},{\"end\":33545,\"start\":33542},{\"end\":33814,\"start\":33812},{\"end\":34025,\"start\":34022},{\"end\":34038,\"start\":34034},{\"end\":34049,\"start\":34047},{\"end\":34294,\"start\":34291},{\"end\":34304,\"start\":34301},{\"end\":34318,\"start\":34314},{\"end\":34638,\"start\":34636},{\"end\":34656,\"start\":34647},{\"end\":34663,\"start\":34658},{\"end\":35021,\"start\":35019},{\"end\":35287,\"start\":35283},{\"end\":35606,\"start\":35599},{\"end\":35970,\"start\":35966},{\"end\":35995,\"start\":35982},{\"end\":36007,\"start\":36004},{\"end\":36019,\"start\":36016},{\"end\":36033,\"start\":36030},{\"end\":36038,\"start\":36035},{\"end\":36329,\"start\":36325},{\"end\":36347,\"start\":36339},{\"end\":36600,\"start\":36597},{\"end\":36606,\"start\":36602},{\"end\":36616,\"start\":36612},{\"end\":36622,\"start\":36618},{\"end\":36628,\"start\":36624},{\"end\":36637,\"start\":36630},{\"end\":36928,\"start\":36919},{\"end\":36947,\"start\":36941},{\"end\":36966,\"start\":36958},{\"end\":37194,\"start\":37188},{\"end\":37204,\"start\":37202},{\"end\":37458,\"start\":37448},{\"end\":37715,\"start\":37711},{\"end\":37728,\"start\":37725},{\"end\":37742,\"start\":37739},{\"end\":37747,\"start\":37744}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":32705,\"start\":32525},{\"attributes\":{\"doi\":\"arXiv:1810.04805\",\"id\":\"b1\"},\"end\":32978,\"start\":32707},{\"attributes\":{\"id\":\"b2\"},\"end\":33187,\"start\":32980},{\"attributes\":{\"doi\":\"arXiv:1607.06450\",\"id\":\"b3\"},\"end\":33411,\"start\":33189},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":237519710},\"end\":33738,\"start\":33413},{\"attributes\":{\"doi\":\"arXiv:2105.07452\",\"id\":\"b5\"},\"end\":33971,\"start\":33740},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":232146842},\"end\":34281,\"start\":33973},{\"attributes\":{\"doi\":\"arXiv:2111.09564\",\"id\":\"b7\"},\"end\":34585,\"start\":34283},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":236912995},\"end\":34929,\"start\":34587},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":244663531},\"end\":35207,\"start\":34931},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":235428328},\"end\":35520,\"start\":35209},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":207168299},\"end\":35902,\"start\":35522},{\"attributes\":{\"doi\":\"10.21227/qvr7-n418\",\"id\":\"b12\"},\"end\":36287,\"start\":35904},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":2534141},\"end\":36556,\"start\":36289},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":207193045},\"end\":36856,\"start\":36558},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":205001834},\"end\":37131,\"start\":36858},{\"attributes\":{\"doi\":\"arXiv:1412.6980\",\"id\":\"b16\"},\"end\":37354,\"start\":37133},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":174803009},\"end\":37624,\"start\":37356},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":208091240},\"end\":37955,\"start\":37626}]", "bib_title": "[{\"end\":33504,\"start\":33413},{\"end\":34012,\"start\":33973},{\"end\":34634,\"start\":34587},{\"end\":35010,\"start\":34931},{\"end\":35274,\"start\":35209},{\"end\":35590,\"start\":35522},{\"end\":35956,\"start\":35904},{\"end\":36317,\"start\":36289},{\"end\":36591,\"start\":36558},{\"end\":36909,\"start\":36858},{\"end\":37439,\"start\":37356},{\"end\":37704,\"start\":37626}]", "bib_author": "[{\"end\":32563,\"start\":32546},{\"end\":32582,\"start\":32563},{\"end\":32803,\"start\":32789},{\"end\":33047,\"start\":33031},{\"end\":33220,\"start\":33210},{\"end\":33236,\"start\":33220},{\"end\":33254,\"start\":33236},{\"end\":33262,\"start\":33254},{\"end\":33517,\"start\":33506},{\"end\":33534,\"start\":33517},{\"end\":33547,\"start\":33534},{\"end\":33816,\"start\":33808},{\"end\":34027,\"start\":34014},{\"end\":34040,\"start\":34027},{\"end\":34051,\"start\":34040},{\"end\":34296,\"start\":34283},{\"end\":34306,\"start\":34296},{\"end\":34320,\"start\":34306},{\"end\":34640,\"start\":34636},{\"end\":34658,\"start\":34640},{\"end\":34665,\"start\":34658},{\"end\":35023,\"start\":35012},{\"end\":35289,\"start\":35276},{\"end\":35608,\"start\":35592},{\"end\":35972,\"start\":35958},{\"end\":35997,\"start\":35972},{\"end\":36009,\"start\":35997},{\"end\":36021,\"start\":36009},{\"end\":36035,\"start\":36021},{\"end\":36040,\"start\":36035},{\"end\":36331,\"start\":36319},{\"end\":36349,\"start\":36331},{\"end\":36602,\"start\":36593},{\"end\":36608,\"start\":36602},{\"end\":36618,\"start\":36608},{\"end\":36624,\"start\":36618},{\"end\":36630,\"start\":36624},{\"end\":36639,\"start\":36630},{\"end\":36930,\"start\":36911},{\"end\":36949,\"start\":36930},{\"end\":36968,\"start\":36949},{\"end\":37196,\"start\":37177},{\"end\":37206,\"start\":37196},{\"end\":37460,\"start\":37441},{\"end\":37717,\"start\":37706},{\"end\":37730,\"start\":37717},{\"end\":37744,\"start\":37730},{\"end\":37749,\"start\":37744}]", "bib_venue": "[{\"end\":35344,\"start\":35340},{\"end\":35731,\"start\":35678},{\"end\":32544,\"start\":32525},{\"end\":32787,\"start\":32707},{\"end\":33029,\"start\":32980},{\"end\":33208,\"start\":33189},{\"end\":33558,\"start\":33547},{\"end\":33806,\"start\":33740},{\"end\":34113,\"start\":34051},{\"end\":34410,\"start\":34336},{\"end\":34743,\"start\":34665},{\"end\":35051,\"start\":35023},{\"end\":35338,\"start\":35289},{\"end\":35676,\"start\":35608},{\"end\":36071,\"start\":36058},{\"end\":36406,\"start\":36349},{\"end\":36695,\"start\":36639},{\"end\":36974,\"start\":36968},{\"end\":37175,\"start\":37133},{\"end\":37471,\"start\":37460},{\"end\":37773,\"start\":37749}]"}}}, "year": 2023, "month": 12, "day": 17}