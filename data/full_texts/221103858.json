{"id": 221103858, "updated": "2023-12-10 20:43:42.657", "metadata": {"title": "Local Temperature Scaling for Probability Calibration", "authors": "[{\"first\":\"Zhipeng\",\"last\":\"Ding\",\"middle\":[]},{\"first\":\"Xu\",\"last\":\"Han\",\"middle\":[]},{\"first\":\"Peirong\",\"last\":\"Liu\",\"middle\":[]},{\"first\":\"Marc\",\"last\":\"Niethammer\",\"middle\":[]}]", "venue": "2021 IEEE/CVF International Conference on Computer Vision (ICCV)", "journal": "2021 IEEE/CVF International Conference on Computer Vision (ICCV)", "publication_date": {"year": 2021, "month": 10, "day": 1}, "abstract": "For semantic segmentation, label probabilities are often uncalibrated as they are typically only the by-product of a segmentation task. Intersection over Union (IoU) and Dice score are often used as criteria for segmentation success, while metrics related to label probabilities are not often explored. However, probability calibration approaches have been studied, which match probability outputs with experimentally observed errors. These approaches mainly focus on classification tasks, but not on semantic segmentation. Thus, we propose a learning-based calibration method that focuses on multi-label semantic segmentation. Specifically, we adopt a convolutional neural network to predict local temperature values for probability calibration. One advantage of our approach is that it does not change prediction accuracy, hence allowing for calibration as a postprocessing step. Experiments on the COCO, CamVid, and LPBA40 datasets demonstrate improved calibration performance for a range of different metrics. We also demonstrate the good performance of our method for multi-atlas brain segmentation from magnetic resonance images.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": "3048873595", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/iccv/DingHLN21", "doi": "10.1109/iccv48922.2021.00681"}}, "content": {"source": {"pdf_hash": "03ef8f38532e358a44bbdec7c78a97d980ecb316", "pdf_src": "IEEE", "pdf_uri": "[\"https://arxiv.org/pdf/2008.05105v2.pdf\"]", "oa_url_match": false, "oa_info": {"license": null, "open_access_url": "https://arxiv.org/pdf/2008.05105", "status": "GREEN"}}, "grobid": {"id": "5af52a2c65fc3dd1e7b1d1534bf8dd45e8e65563", "type": "plain-text", "url": "s3://ai2-s2-science-parse-plus-prod/parse-results/s2orc_worker/03ef8f38532e358a44bbdec7c78a97d980ecb316.txt", "contents": "\nLocal Temperature Scaling for Probability Calibration\n\n\nZhipeng Ding zp-ding@cs.unc.edu \nUniversity of North Carolina at Chapel Hill\nChapel HillUSA\n\nXu Han \nUniversity of North Carolina at Chapel Hill\nChapel HillUSA\n\nPeirong Liu peirong@cs.unc.edu \nUniversity of North Carolina at Chapel Hill\nChapel HillUSA\n\nMarc Niethammer \nUniversity of North Carolina at Chapel Hill\nChapel HillUSA\n\nLocal Temperature Scaling for Probability Calibration\n10.1109/ICCV48922.2021.00681\nFor semantic segmentation, label probabilities are often uncalibrated as they are typically only the by-product of a segmentation task. Intersection over Union (IoU) and Dice score are often used as criteria for segmentation success, while metrics related to label probabilities are not often explored. However, probability calibration approaches have been studied, which match probability outputs with experimentally observed errors. These approaches mainly focus on classification tasks, but not on semantic segmentation. Thus, we propose a learning-based calibration method that focuses on multi-label semantic segmentation. Specifically, we adopt a convolutional neural network to predict local temperature values for probability calibration. One advantage of our approach is that it does not change prediction accuracy, hence allowing for calibration as a postprocessing step. Experiments on the COCO, CamVid, and LPBA40 datasets demonstrate improved calibration performance for a range of different metrics. We also demonstrate the good performance of our method for multi-atlas brain segmentation from magnetic resonance images.\n\nIntroduction\n\nWith the development of deep convolutional neural networks (CNNs), the accuracy of semantic segmentation has improved dramatically [9,43]. However, ideally semantic segmentation networks should not only be accurate, but should also indicate when they are likely incorrect. For example, an autonomous driving system might use deep convolutional neural networks to analyze a real-time scene from a camera [5], the associated semantic segmentation of street scenes should provide accurate detections of pedestrians and other vehicles, and the system should recognize when such predictions are unreliable. Another example is the segmentation of brain tumors with a CNN [22]. If the segmentation network can not confidently segment critical regions of the brain, then a medical expert should decide or be alerted to such doubtful regions. Thus, it is important for semantic segmentation networks to generate both accurate label predictions and accurate confidence measures.\n\nHowever, due to overfitting, CNNs for semantic segmentation tend to be overconfident about predicted labels [17,20,29,41]. Approaches for joint prediction and calibration exist [36,44,48,52]. However, they require changing the learning task and typically strive for calibration, but do not guarantee it. An alternative approach is to calibrate the resulting probabilities of a model via postprocessing so that they better reflect the true probabilities of being correct. This is the kind of approach we consider here as it easily applies to pre-trained networks and can even benfit joint prediction/calibration approaches. Probability calibration, first studied for classification [58], generally addresses this problem via a hold-out validation dataset.\n\nExisting calibration approaches still have several limitations: (1) Most of the probability calibration approaches are designed for classification, thus are not guaranteed to work well for semantic segmentation (where it is also more challenging to annotate on a pixel/voxel level); (2) While there is limited work discussing probability calibration for semantic segmentation, this work either only applies to specific types of models (e.g., Bayesian neural networks [29]) or only implicitly improves calibration performance (e.g., via model ensembling [47] or multi-task learning [31]); (3) Most methods are designed to work for binary classifications and approach multi-class problems by a decomposition into k one-vs-rest binary calibrations (where k denotes the number of classes). However, such a decomposition does not guarantee overall calibration (only for the individual subproblems before normalization) and the classification accuracy of the trained model may change after calibration as the probability order of labels may change.\n\nOur goal is to develop a post-processing calibration method for multi-label semantic segmentation, which retains label probability order and, therefore, a model's segmentation accuracy. Our work is inspired by temperature scaling (TS) [20] for classification probability calibration. As TS determines only one global scaling constant, it cannot capture spatial miscalibration changes in images. We therefore (1) extend TS to multi-label semantic segmentation and (2) make it adaptive to local image changes.\n\nOur contributions are: (1) Spatially localized probability calibration: We propose a learning-based local TS method that predicts a separate temperature scale for each pixel/voxel. (2) Completely separated accuracy-preserving post-processing: Our approach is completely separated from the segmentation task, leaving the prediction accuracy unchanged. (3) Theoretical justification: We provide a theoretical analysis for the effectiveness of our approach. (4) Comprehensive analysis: We provide definitions and evaluation metrics for probability calibration for semantic segmentation and validate our approach both qualitatively and quantitatively. (5) Practical application: We successfully apply our calibrated probabilities for multi-atlas segmentation label fusion in the field of medical image analysis.\n\n\nRelated Work\n\nA variety of calibration approaches have been proposed, but none addresses our target setting.\n\nBin-based Approaches. Non-parametric histogram binning [67] uses the average number of positive-class samples in each bin as the calibrated probability. Isotonic regression [68] extends this approach by jointly optimizing bin boundaries and bin predictions; it is one of the most popular non-parametric calibration methods. ENIR [55] further extends isotonic regression by relaxing the monotonicity assumption of isotonic regression. These bin-based methods do not consider correlations among neighboring pixels/voxels in semantic segmentation, while our proposed method captures correlations via convolutional filters.\n\nTemperature Scaling Approaches. Platt scaling [58] uses logistic regression for probability calibration. Matrix scaling [20], vector scaling [20], and temperature scaling [25,20] all generalize Platt scaling to multi-class calibration, among which temperature scaling is both effective and the simplest. ATS [51] extends temperature scaling by using the conditional distribution on each class to address the calibration challenge on small validation datasets, for noisy labels, and highly accurate networks. BTS [30] extends temperature scaling to a bin-wise setting and also uses data augmentation inside each bin to improve the calibration performance. However, unlike our approach (which extends temperature scaling) none of these approaches considers spatial variations for probability calibration.\n\nBayesian Approaches. BBQ [54] extends binning via Bayesian averaging of the probabilities produced by all possible binning schemes. Bayes-Iso [1] extends isotonic regression by using Bayesian isotonic calibration to allow for more flexibility in the monotonic fitting and smoothness. Jena et al. [29] proposed to use a utility function focusing on the intermediate-layers of a Bayesian deep neural network to calibrate probabilities for image segmentation. Maronas et al. [46] proposed decoupled Bayesian neural networks to calibrate classification probabilities. Bin-based Bayesian methods do not consider pixel/voxel correlations. Bayesian neural networks can capture spatial correlations, but require a Bayesian formulation in the first place. Furthermore, while Bayesian uncertainty quantification [32] helps probability calibration, it may also not achieve it (Appx. A). Instead, our approach considers pixel/voxel correlations and can be used as a post-processing approach for any semantic segmentation method which generates probability outputs.\n\nOther Approaches. Mehrtash et al. [47] found that model ensembling improves confidence calibration for medical image segmentation. A similar conclusion was also found in [38,69], where an ensemble is used to produce good predictive uncertainty estimates. Karimi et al. [31] showed that multi-task learning can yield better-calibrated predictions than dedicated models trained separately. Note that ensembling or multi-task learning does not directly address probability calibration, instead they provide insights on how to obtain a better calibrated segmentation model. Leathart et al. [39] improved the calibration of classification tasks by building a decision tree over input tabular data, where the leaf nodes correspond to different calibration models. Further, beta calibration [35] extends logistic calibration to overcome the situation where per-class score distributions are heavily skewed. Dirichlet calibration [34] uses the Dirichlet distribution to generalize beta calibration to multi-class problems. Rahimi et al. [59] proposed to use neural network based intra order-preserving functions for calibration. These methods are also not directly designed for probability calibration of semantic segmentation, but focus on classification. Learning algorithms [36,44,48,52] that jointly consider prediction and calibration also exist. Although they can help mitigate miscalibrations, they typically cannot entirely remove it. In fact, they can also benefit from our post-processing approach ( \u00a74.2).\n\n\nMethodology\n\n\nProblem Statement\n\nOur goal is the calibration of the predicted probabilities of deep semantic segmentation CNNs. Assume there is a pre-trained neural network F, with an image I as the input, which outputs a vector of logits at each location x. Each logit corresponds to a label, and the logit value reflects the label confidence. The predicted label is the one with the largest logit value; the corresponding confidence (probability of correctness) for each pixel/voxel is usually obtained via softmax of the logits. Specifically, the predicted confidence map and the corresponding segmentation map ar\u00ea\nP (x) = max l2L SM (z(x)) (l) = max l2L exp(z(x) (l) ) P j2L exp(z(x) (j) ) , S(x) = arg max l2L z(x) (l) ,(3.1)\nwhere SM is the softmax function, x denotes position, L is the set of all labels, l is the label index and z(x) (l) = z l (x) is the logit that corresponds to label l at location x. The goal of probability calibration is to ensure that the confidence mapP represents a true probability. For example, given a 10 \u21e5 10 image, with label confidence of 0.7 for each pixel, we would expect that 70 pixels should be correctly segmented. This can be formalized as follows:\nDefinition 1. A semantic segmentation is perfectly cali- brated in region \u2326 if P(\u015c(x) = S(x)|P (x) = p) = p, 8p 2 [0, 1], x 2 \u2326 (3.2)\nwhere S(x) and\u015c(x) are the true and predicted segmentations at location x, respectively,P (x) is the confidence of the prediction\u015c(x), and P is the probability measure.\n\nIn short, if the observed probability is the true probability, then the semantic segmentation model is wellcalibrated. As it is difficult to work directly with this definition to assess miscalibration, we extend several visual and quantitative metrics [11,53,54,56,57], which have previously been proposed in the context of classification.\n\n\nCalibration Setup\n\nAssume the data split for a semantic segmentation network F is D train / D val / D test , i.e. F is trained on the D train dataset, validated on the D val dataset to choose the best model, and finally tested on the D test dataset. Note that D train , D val , and D test are disjoint datasets. Miscalibration can be observed when evaluating F on D test for probability-related measures. Our goal is to calibrate the probability output of F on D test . To this end, we train a calibration model C on the hold-out validation dataset D val via cross entropy loss, to obtain a better calibrated probability output of F on D test .\n\n\nTS for Probability Calibration\n\nTemperature scaling [20] has been proposed as a simple extension of Platt scaling [58] for post-hoc probability calibration for multi-class classifications. Specifically, temperature scaling estimates a single scalar parameter T 2 R + , i.e., the temperature, to calibrate probabilities:q = max l2L SM (z/T ) (l) , whereq is the calibrated probability.\n\nWe can directly extend temperature scaling to semantic segmentation by estimating one global parameter T 2 R + for all pixels/voxels of all images:Q i (x, T ) = max l2L SM (z i (x)/T ) (l) , whereQ i is the calibrated probability map for the i-th image. As in [20], we obtain this optimal value for T by minimizing the following negative log-likelihood (NLL) w.r.t. a hold-out validation dataset: where \u2326 denotes the image space and n the number of training images. However, temperature scaling in this way assumes that each image has the same distribution (i.e., the same temperature, T , for all images), which is unrealistic. We therefore propose to relax this assumption as follows:\nT \u21e4 = arg min T n X i=1 X x2\u2326 log \u21e3 SM z i (x)/T (Si(x)) \u2318 ! s.t. T > 0, (3.3)\nDefinition 2. Image-based temperature scaling (IBTS):\nQ i (x, T i ) = max l2L SM (z i (x)/T i ) (l) , (3.4) where T i 2 R + is image-dependent.\nWhile this at first seems like a minor change to the standard temperature scaling approach, it is important to note that moving to an image-based temperature value, T i requires us to learn a regressor which predicts this temperature value for each image, I. Therefore, we use a CNN [19] to learn a mapping from (z i , I i ) to T i . Suppose the network is F , then the optimization is (3.5) where \u2713 are the parameters of the network F . The calibrated probability can be obtained by substituting\n\u2713 \u21e4 = arg min \u2713 n X i=1 X x2\u2326 log \u21e3 SM z i (x) F (\u2713, z i , I i ) (Si(x)) \u2318 s.t. F (\u2713, z i , I i ) > 0,T \u21e4 i = F (\u2713 \u21e4 , z i , I i ) in Eq. (3.4).\n\nLocal TS for Probability Calibration\n\nProbabilities predicted by a deep CNN vary by location. Fig. 1 illustrates that object interiors can usually be accurately predicted while predictions on boundary or nearboundary locations are more ambiguous. Thus the optimal temperature value may vary across locations. However, using a global parameter, T , or an image-based parameter, T i , cannot account for such spatial variations. That this is a practical concern is illustrated in the uncalibrated reliability diagrams of Fig. 2 which shows that the confidence-vsaccuracy relation may indeed vary across an image. Hence, spatial variations should be considered for semantic segmentation. Therefore, we propose the following local temperature scaling (LTS) approach. \nQ i (x, T i (x)) = max l2L SM (z i (x)/T i (x)) (l) , (3.6)\nwhere T i (x) 2 R + is image and location dependent.\n\nFor T i (x) = 1, no calibration occurs as the logits z i (x) do not change. For T i (x) > 1, confidence will be reduced, which helps counteract overconfident predictions. As T i (x) ! 1, the calibrated probabilities will approach 1/|L|, which represents maximum uncertainty. For T i (x) < 1, prediction confidence will be increased. This will be helpful to counteract underconfident predictions. Lastly, as T i (x) ! 0, the calibrated probabilities will become binary (2 {0, 1}), which represents minimum uncertainty. As T i (x) is positive, such a local scaling does not change the ordering of the probabilities over the different classes. Hence, the segmentation accuracy remains unchanged.\n\nAnother network H , with parameter \u21b5, can be used to learn this local mapping from (z i , Fig. 3 illustrates our high-level design for probability calibration. The input is a logit map z, usually obtained by a segmentation network (Seg). Together with the image I, it is then passed to an optimization unit or a prediction unit to generate the temperature map. These temperature values are used to calibrate the logit map. The calibrated probabilities are, in turn, obtained via a softmax on the calibrated logits. Class labels do not change under this process and can still be obtained by determining the class with the largest predicted probability. Appx. B details the implementation. Training details are described in Appx. C.\nI i ) to T i (x). The op- timization follows Eq. (3.5), with F (\u2713, z i , I i ) replaced by H (\u21b5, z i , I i , x), where x indicates the spatial locations. Fi- nally, we obtain T i (x) \u21e4 = H (\u21b5 \u21e4 , z i , I i , x).\n\nTheoretical Justification\n\nWhy does miscalibration happen? One usually uses the loss corresponding to the negative log-likelihood (NLL) of the multinomial distribution [3,15] (i.e., the multi-class cross-entropy loss) to train semantic segmentation networks because minimizing it will minimize the Kullback-Leibler (KL) divergence between the ground-truth probability distribution and the predicted probability distribution. The minimum loss is achieved if and only if the predicted probability distribution recovers the ground-truth probability dis-tribution [3,15]. For semantic segmentation, the NLL loss is minimized whenP (x) = 1 and\u015c(x) = S(x), for all x. The segmentation error is minimized when z(x) (S(x)) > z(x) (l) for all l 2 L and l 6 = S(x). This indicates that even if the segmentation error is minimized to zero, the NLL loss may still be positive and the optimization will consequently try to continue reducing it to zero by pushingP (x) to one for\u015c(x) = S(x). This explains how overconfidence occurs in the context of semantic segmentation. Note that this overconfidence also results in low-entropy distributions.\n\nHow to eliminate miscalibration? As indicated in [52] encouraging the predicted distribution to have higher entropy can help avoid overconfident predictions for deep CNNs, and can thereby improve calibration. Thus, to calibrate an overconfident semantic segmentation network, we need to simultaneously minimize the NLL loss w.r.t. the to-be-learned calibration parameters while assuring that the corresponding entropy of the calibrated probabilities stays sufficiently large to probabilistically describe empirically observable segmentation errors. Note that we minimize the NLL loss for the same reason as for segmentation (above): because the goal is to recover the true probability distribution. The difference is that for segmentation we optimize w.r.t. the segmentation network parameters while for calibration we optimize w.r.t. the calibration model parameters.\n\nWhy do we use (local) TS to calibrate probabilities? Overconfident networks usually exhibit the phenomenon that the entropy of the output probabilities is much lower than the cross entropy on the testing dataset as shown in [20,52]. Thus, we define overconfidence as entropy being lower than the cross entropy of probabilities (Appx. E; and similarly for underconfidence). Specifically, we show the following theorem in Appx. E. Theorem 4. When the to-be-calibrated segmentation network is overconfident, minimizing NLL w.r.t. TS, IBTS, and LTS results in solutions that are also the solutions of maximizing entropy of the calibrated probability w.r.t. TS, IBTS and LTS under the condition of overconfidence.\n\nFor example, for TS, the above theorem can be mathematically expressed as follows,\narg min T n X i=1 X x2\u2326 log \u21e3 SM z i (x)/T (Si(x)) \u2318 m arg max T n X i=1 X x2\u2326 L X l=1 SM z i (x) T (l) log \u21e3 SM z i (x) T (l) \u2318 s.t. n X i=1 X x2\u2326 L X l=1 z i (x) (l) SM z i (x) T (l) n X i=1 X x2\u2326 z i (x) (Si(x))\nwhere T > 0. Hence, our three different variants for probability calibration via temperature scaling (TS, IBTS, LTS) will counteract the tendency of entropy minimization caused by the NLL loss discussed above. Training the segmentation network via the NLL loss followed by post-hoc probability calibration via temperature scaling is an effective approach to obtain high segmentation accuracy while avoiding overconfidence of the resulting label probabilities. \u00a74.1- \u00a74. 4 show experiments to support this claim.\n\n\nExperiments\n\nWe show the performance and behavior of our proposed TS approaches for semantic segmentation on the COCO dataset ( \u00a74.1), CamVid dataset ( \u00a74.2) and LPBA40 dataset (a dataset of magnetic resonance (MR) images of the human brain) ( \u00a74.3). We further show how our probability calibration may influence downstream tasks, by exploring it in the context of multi-atlas segmentation on LPBA40 ( \u00a74.4).\n\nEvaluation Metrics. To assess the performance of probability calibration, we use five metrics, which were originally designed for classification, for semantic segmentation. Specifically, they are the reliability diagram [11,53,56], expected calibration error [54] (ECE), maximum calibration error [54] (MCE), static calibration error [57] (SCE), and adaptive calibration error [57] (ACE). To make the above metrics applicable to semantic segmentation, we consider the predicted probabilities for each pixel/voxel as separate samples. We use 10 equally-sized (probability or sample size) bins to compute all these metrics. In \u00a74.4, we additionally use average surface distance (ASD), surface Dice (SD), the 95-th percentile of the maximum symmetric distance (95MD), and average volume Dice (VD) to measure segmentation performance. Detailed definitions are in Appx. F. Baseline Methods. To illustrate the effectiveness of our proposed LTS approach (see Eq. (3.6)), we compare it to standard TS and IBTS (see Eq. (3.4)), where we directly assess if local adjustments can be properly predicted and if they are beneficial. While other probability calibration methods exist, as discussed in \u00a72, most are for classification and not for semantic segmentation. This is an important difference. For example, in semantic segmentation, nearby pixels/voxels are correlated with each other, whereas such relations do not apply to classification. Thus, simply considering each pixel/voxel as a classification data point is not appropriate. For completeness, however, we still choose several classic methods ( \u00a74.1) to compare against, i.e. isotonic regression (IsoReg) [68], vector scaling (VS) [20], ensemble temperature scaling (ETS) [69], and Dirichlet calibration with off-diagonal regularization (DirODIR) [34]. Furthermore, to illustrate that our method is also beneficial for joint training ( \u00a74.2), we show the performance before and after using LTS for models trained with maximum mean calibration loss (MMCE) [36] and focal loss (FL) [52]. All methods are fine-tuned with the best parameters via grid search. Details are in Appx. C.\n\nEvaluation Regions. Since label boundaries are difficult to segment, these are the regions where most of the relevant miscalibrations are expected to occur (see also Fig. 1). For a refined analysis, we extract boundaries and their nearby regions (i.e., regions up to 2 pixels/voxels away from the boundary). We denote this evaluation region by Boundary in all experiments. We also evaluate performance within label regions (excluding the background, but including the respective Boundary region). We denote this large region as All. It is expected that the calibration inside the Boundary region will be more challenging (as the prediction is more ambiguous) than the calibration inside the bigger All region. Appx. G shows examples of these regions for a 3D brain MR image. Furthermore, to evaluate the local probability calibration performance for an image segmentation, we also randomly select 10 small patches (72\u21e572 for 2D, 72\u21e572\u21e572 for 3D) and compute the same metrics as for the entire image. We report average performance (denoted Local-Avg) and the worst case performance (denoted Local-Max) across 10 patches. Appx. H shows results for different patch sizes. Note that results in the All region reflect the overall calibration performance for an image segmentation; results in the Boundary region reflect the most challenging calibration performance for an image segmentation; results in the Local region generally reflect whether the calibration method can handle spatial variations. Downstream MAS setting. Multi-atlas segmentation (MAS) relies on transferring segmentations from a set of atlas images to a target image via deformable registration. The segmentation in the target space is then obtained by a label fusion method, which establishes a consensus among the registered atlas labels. We use the label fusion strategy by Wang et al. [64], which takes advantage of the label probabilities. Hence, better-calibrated probabilities should lead to better fusion accuracy (i.e., segmentation accuracy).\n\nStatistical Considerations. To indicate the success of probability calibration, we use a Mann-Whitney U-test [45] to check for significant differences between the result of LTS and the results for all other baseline methods (UC, TS, IBTS, etc.). We use the Benjamini/Hochberg correction [4] for multiple comparisons with a false discovery rate of 0.05. Results are highlighted in green when LTS performs significantly better than the corresponding method (no color means no statistically significant differences).\n\n\nDatasets.\n\nWe use three datasets for our experiments: The Common Object in Context (COCO) [42] dataset, the Cambridge-driving Labeled Video Database (CamVid) [7,6], and the LONI Probabilistic Brain Atlas (LPBA40) [62] dataset. Detailed descriptions and the training/validation/testing splits are in Appx. C.\n\n\nFCN semantic segmentation on COCO\n\nGeneral: We use a Fully-Convolutional Network (FCN) [43] with a ResNet-101 [23] backbone for seman-tic segmentation on the COCO dataset. Tab. 1 shows our quantitative evaluation results for calibrating such a segmentation model. In the All region, TS and IBTS do not improve calibration performance, possibly because the natural images in the COCO dataset are complex and vary significantly in type and shape, yet TS uses a global temperature value for all images. IBTS performs slightly better than TS on average because it uses an image-dependent temperature scaling to capture image variations, though it cannot explain the spatial image variations in the All region. Furthermore, we observe that LTS is in general significantly better than classical methods, i.e. IsoReg [68], VS [20], ETS [69] and DirODIR [34]. This is likely because these classical methods treat each pixel/voxel independently without considering their spatial correlations in semantic segmentation.\n\nBoundary: The relatively low segmentation performance of the segmentation network suggests that such spatial variations might matter. Specifically, semantic segmentation results in a mean IOU of 63.7%, indicating how challenging this dataset is. Further, all methods except VS [20] show significant improvements in the Boundary region. This indicates that (1) these boundary regions share common miscalibration patterns, which can be captured by most methods, and (2) miscalibration effects are indeed, as expected, more pronounced in these boundary regions.\n\nLocal: Different from the All region, the Local region is based on randomly extracted small patches of an image. Specifically, Local-Avg reflects the average performance of local probability calibration while Local-Max reflects the calibration performance in the most uncalibrated patch region thus measuring the worst-case calibration result. Results in ECE, SCE and ACE all suggests that LTS can calibrate the entire image region as well as local image regions. Other approaches result in significantly worse calibrations.\n\nMCE: Further, the MCE results illustrate that probability calibration for semantic segmentation is indeed very challenging compared with classification. This is because classification annotation is typically very accurate while per-pixel/voxel annotation of semantic segmentation can be difficult, especially at object boundaries. For example, in the extreme case, if one pixel/voxel is annotated wrong but predicted correct (or vice versa), then the accuracy is 0 while the prediction confidence is nearly 100%. This will result in MCE values close to 100% for bin based evaluation. Usually, these outliers make up only a small portion of all pixels/voxels in an image. Examples for such outliers can be observed in Fig. 2 uncalibrated patch 1 and 3 \n\n\nTiramisu semantic segmentation on CamVid\n\nGeneral: We use the Tiramisu segmentation model [28] on the CamVid dataset. Tab. 1 shows quantitative results for calibrating this segmentation model. Compared with the results for the COCO dataset, all four metrics are reduced greatly. This is mainly because the images in CamVid only contain 11 class street scenes and the images are relatively consistent for such scenes. Instead, images from the COCO dataset show different objects in different images. See Appx. I for details. Results are consistent with the COCO dataset. Specifically, (1) LTS can calibrate both the All region probabilities as well as the local regions inside an image; (2) LTS is, in general, significantly better than TS and IBTS for most comparisons.\n\nJoint Prediction and Calibration: Further, we show that our approach is beneficial for methods that jointly optimize prediction and calibration [36,52]. MMCE [36] and FL [52] both consider miscalibration when training semantic segmentation networks. Tab. 1 shows that compared to the uncalibrated results, both MMCE and FL work signif-icantly better. Furthermore, with LTS as a post-hoc calibration, calibration performance further consistently improves (except Boundary regions for FL). These findings are consistent with the results in [52] where TS is used as a post-hoc calibration method and the authors show that MMCE+TS and FL+TS work consistently better than MMCE and FL. Hence, this favors our LTS as a successful post-hoc calibration method for segmentation.\n\n\nU-Net segmentation on LPBA40\n\nGeneral: We use a customized 3D U-Net [9] for the segmentation of the LPBA40 dataset. Tab. 1 shows quantitative results for calibrating this segmentation model. All three methods calibrate the probabilities relatively well in this experiment. This might be because images have been affinely registered to a common atlas space, which reduces the variations of images and may make it easier for TS, IBTS and, LTS to calibrate both in the All region and the Boundary region. This might also explain the performance differences between the computer vision datasets and the medical imag-  Table 2: MAS label fusion results based on calibrated probabilities. #(\") indicates that lower(higher) values are better. mm denotes millimeter. UC denotes uncalibrated results. VC denotes voxel annotation changes between the uncalibrated approach to the corresponding method: w!c is from wrong voxel annotation to correct voxel annotation; c!w is from correct voxel annotation to wrong voxel annotation. Rate is calculated based on the number of changes out of the possible number of changes. (Note that many voxel annotations can not change because all atlas annotations give the same label, thus a change in probability would not change the voxel annotation.) LTS generally improves segmentations slightly. After LTS probability calibration, JLF changes more voxels than for TS and IBTS. Further, the difference between the correct conversion and the incorrect conversion is improved over TS and IBTS. This indicates that JLF can produce better segmentations with a better probability calibration and suggests that downstream tasks may in general benefit from better calibration.\n\ning dataset in Tab. 1. See Appx. I for details. Differences between calibration performance among TS and IBTS are relatively small. However, LTS still performs best with respect to most metrics. Spatial Variation: Furthermore, when it comes to the Local region analysis, LTS consistently works best. Fig. 2 visualizes such difference via reliability diagrams. The red arrows highlight that TS, IBTS and LTS calibrate probabilties for the whole image well but only LTS consistently performs well in the Local region. This indicates the superiority of LTS's spatially-variant probability calibration.\n\n\nDownstream MAS label fusion on LPBA40\n\nWe use a customized VoteNet+ [13] for multi-atlas segmentation on the LPBA40 dataset. In this approach, a network (VoteNet+) is trained to locally predict if a labeled atlas that has been registered to the target image space should be considered trustworthy or not. Label fusion (among the registered atlas images) can then make use of these probabilities to obtain the multi-atlas segmentation results. It is these VoteNet+ probabilities that we seek to calibrate.\n\nCalibration Metrics: Tab. 1 shows our quantitative calibration results. Different from the U-Net experiments in \u00a74.3, we observe bigger differences between the calibration approaches. This might be because the VoteNet+ calibration experiment has sufficient training data (as multi-atlas segmentation performs image registrations from each atlas image to each target image) whereas the experiments in \u00a74.3 are much more data-starved. Besides, as the labeled atlases are registered to the target image space via a flexible non-parametric registration approach, data variance is further reduced in comparison to the affine registrations used as preprocessing in \u00a74.3. Tab. 1 shows that all three methods calibrate probabilities well, and that performance order is consistent with model complexity. I.e., LTS performs better than IBTS, and IBTS performs better than TS. These differences are statistically significant. Label Fusion with Probability: Tab. 1 only demonstrates that the calibration approaches can improve the calibration of the VoteNet+ output. To obtain the multi-atlas segmentation result, we need to use label fusion. As the joint label fusion (JLF) approach [64] we use for this purpose can make use of the VoteNet+ label probabilities, it is natural to ask if improved calibration results translate to improved segmentations via JLF. Tab. 2 shows that while differences are small, consistent improvements can indeed be observed. Hence, our proposed LTS not only shows good calibration performance on traditional metrics (i.e. ECE, MCE, SCE and ACE), but can also benefit downstream tasks that are sensitive to accurate probabilities. For comparison, we also show two theoretical upper bounds. The Best Fusion bound, which is obtained by assigning the correct label to the segmentation result if at least one atlas provides the right label; and the Best Calibration bound, which is obtained by assigning a probability of 1 if the prediction by VoteNet+ is correct and 1/|L| otherwise, followed by JLF. We observe that there is still a large room to improve probability calibration as the obtained results are far from the two upper bounds.\n\n\nConclusion and Future Work\n\nWe introduced LTS, a general temperature scaling method that allows for spatially-varying probability calibration for multi-label semantic segmentation. Experiments on the COCO, CamVid and LPBA40 datasets show that LTS outperforms probability calibration approaches which cannot account for spatially-varying miscalibration. LTS not only works for standard segmentation models but can also benefit models that aim to jointly optimize prediction and calibration. Further, using a multi-atlas brain segmentation experiment we demonstrated that downstream tasks may benefit from improved probability calibration. Future work could focus on further calibration improvements. For example, LTS could be easily extended to a bin-wise setting as in [30] or use distributions conditioned on classes as in [51].\n\nFigure 1 :\n1Left: Predicted probabilities (confidence) by a U-Net in \u00a74.3. Middle: Average accuracy of each bin for 10 bins of reliability diagram with an equal bin width indicating different probability ranges that need to be optimized for different locations. Right: Temperature value map obtained via optimization, revealing different optimal localized TS values at different locations.\n\nFigure 2 :\n2An example of global and local reliability diagrams for different methods for a U-Net segmentation experiment ( \u00a74.3). I is the image,P is the predicted uncalibrated probability, and\u015c is the predicted segmentation. Figures are displayed in couples, where the left figure is the probability distribution of pixels/voxels while the right figure is the reliability diagram (See Appx. F for definitions). The top row shows the global reliability diagrams for different methods for the entire image. The three rows underneath correspond to local reliability diagrams for the different methods for different local patches. Note that TS and IBTS can calibrate probabilities well across the entire image. Visually, they are only slightly worse than LTS. However, when it comes to local patches, LTS can still successfully calibrate probabilities while TS and IBTS can not. In general, LTS improves local probability calibrations. More results are in Appx. D. Definition 3. Local temperature scaling (LTS):\n\nFigure 3 :\n3Architecture for probability calibration via (local) temperature scaling. The output logit map of a pre-trained semantic segmentation network (Seg) is locally scaled to produces the calibrated probabilities. OP denotes optimization or prediction via a deep convolutional network to obtain the (local) temperature values. Details of this OP unit can be found in Appx. B.\n\n\nat the lowest confidence point, where the percentage of samples is very small, but the accuracy-confidence difference is notable. Thus, for all experiments, we expect that MCE can be very high compared to the classification probability calibration literature. LTS can improve MCE values, but may still result in large MCE values.Dataset \n\nMethod \n\nECE(%)# \nMCE(%)# \nSCE(%)# \nACE(%)# \n\nAll \nBoundary \nLocal-Avg \nAll \nBoundary \nLocal-Avg \nAll \nBoundary \nLocal-Avg \nAll \nBoundary \nLocal-Avg \n[Local-Max] \n[ Local-Max] \n[ Local-Max] \n[ Local-Max] \n\nFCN \nCOCO \n(1000) \n\nUC \n12.44(17.87) 24.41(7.23) \n14.48(20.89) \n27.66(22.23) 38.61(7.22) \n34.90(23.89) \n20.24(18.75) 24.97(7.07) \n20.05(21.67) \n20.19(18.73) 24.46(7.26) \n19.86(21.68) \n[33.14(26.83)] \n[58.73(19.66)] \n[39.66(24.30)] \n[39.16(24.62)] \n\nIsoReg [68] \n12.55(14.22) 16.27(6.62) \n15.35(16.81) \n27.58(21.06) 33.36(10.01) \n31.76(20.05) \n22.28(15.35) 17.20(6.42) \n21.65(17.77) \n22.19(15.35) 16.40(6.77) \n21.41(17.82) \n[29.26(22.36)] \n[43.24(23.70)] \n[37.13(19.38)] \n[36.69(19.69)] \n\nVS [20] \n12.70(17.22) 24.60(6.98) \n14.57(20.26) \n38.40(16.92) 38.96(7.45) \n41.20(20.23) \n18.05(18.25) 25.00(6.90) \n18.13(21.07) \n17.98(18.25) 24.55(7.09) \n17.92(21.07) \n[29.89(17.28)] \n[50.42(25.40)] \n[32.31(18.43)] \n[32.22(18.40)] \n\nETS [69] \n12.54(14.27) 15.68(6.79) \n15.42(16.88) \n27.36(21.01) 33.27(10.09) \n30.92(20.34) \n22.37(15.42) 16.72(6.58) \n21.80(17.83) \n22.29(15.41) 15.82(6.93) \n21.57(17.87) \n[29.41(22.44)] \n[42.72(24.68)] \n[37.33(19.41)] \n[36.85(19.75)] \n\nDirODIR [34] \n11.32(12.61) 14.17(17.73) \n15.09(18.99) \n26.66(18.43) 34.04(12.88) \n32.54(24.79) \n19.59(13.16) 15.27(7.75) \n18.55(19.44) \n19.67(13.15) 15.33(7.47) \n18.71(19.34) \n[26.85(23.36)] \n[46.07(18.04)] \n[34.48(23.17)] \n[34.46(23.18)] \n\nTS [20] \n12.53(14.28) 15.69(6.79) \n15.41(16.89) \n27.27(20.95) 33.27(10.17) \n30.91(20.32) \n22.36(15.42) 16.73(6.59) \n21.78(17.85) \n22.28(15.42) 15.83(6.94) \n21.56(17.88) \n[29.37(22.47)] \n[42.71(24.66)] \n[37.34(19.42)] \n[36.85(19.76)] \n\nIBTS \n11.92(13.83) 16.35(7.13) \n14.80(16.63) \n26.25(20.26) 33.29(9.96) \n31.19(19.97) \n21.68(15.31) 17.31(6.90) \n21.06(17.81) \n21.62(15.29) 16.40(7.33) \n20.82(17.84) \n[28.89(21.99)] \n[43.45(23.27)] \n[36.62(19.32)] \n[36.09(19.63)] \n\nLTS \n10.04(11.54) 13.44(6.23) \n12.26(14.74) \n26.17(15.67) 35.18(12.31) \n31.66(17.66) \n16.92(13.89) 14.53(6.18) \n16.78(16.38) \n16.91(13.93) 15.16(5.92) \n16.85(16.45) \n[24.31(18.63)] \n[ 40.13(20.39)] \n[ 30.05(17.45)] \n[ 30.21(17.60)] \n\nTiramisu \nCamVid \n(233) \n\nUC \n7.79(4.94) \n22.79(5.76) \n9.23(10.63) \n22.64(12.72) 30.42(10.65) \n30.33(16.63) \n9.91(5.02) \n24.62(5.69) \n13.16(11.72) \n9.90(5.01) \n24.43(5.75) \n13.15(11.73) \n[25.35(12.80)] \n[56.15(14.61)] \n[30.60(12.48)] \n[30.60(12.46)] \n\nTS [20] \n3.45(3.52) \n12.66(5.43) \n7.31(7.72) \n16.02(11.09) 23.57(12.88) \n27.29(16.23) \n9.42(3.90) \n17.85(4.55) \n13.50(10.14) \n9.44(3.92) \n17.61(4.59) \n13.50(10.17) \n[17.69(11.91)] \n[37.25(18.98)] \n[27.72(11.37)] \n[27.76(11.33)] \n\nIBTS \n3.63(3.65) \n12.57(6.07) \n7.25(7.67) \n16.01(10.21) 23.24(13.00) \n27.04(15.94) \n9.47(3.89) \n17.98(4.88) \n13.48(10.12) \n9.49(3.91) \n17.75(4.92) \n13.48(10.16) \n[17.60(11.91)] \n[37.61(19.27)] \n[27.69(11.38)] \n[27.76(11.33)] \n\nLTS \n3.40(3.59) \n11.80(5.20) \n6.89(7.64) \n12.44(7.48) \n22.17(9.53) \n27.64(16.67) \n8.76(4.05) \n17.77(4.26) \n12.66(10.04) \n8.73(4.03) \n17.32(4.32) \n12.61(10.07) \n[16.61(11.81)] \n[37.92(20.47)] \n[26.78(11.22)] \n[26.76(11.22)] \n\nMMCE [36] \n4.45(4.03) \n-\n-\n18.83(10.82) \n-\n-\n8.59(5.98) \n-\n-\n8.50(5.00) \n-\n-\n[-] \n[-] \n[-] \n[-] \n\nMMCE [36]+LTS \n4.15(3.54) \n-\n-\n17.98(10.69) \n-\n-\n7.28(3.80) \n-\n-\n7.17(3.84) \n-\n-\n[-] \n[-] \n[-] \n[-] \n\nFL [52] \n3.47(3.11) \n8.68(5.45) \n9.01(7.19) \n14.77(13.28) 17.62(13.53) \n28.37(15.86) \n7.46(3.43) \n14.08(4.49) \n14.09(9.78) \n7.43(3.45) \n13.63(4.57) \n14.06(9.83) \n[13.84(11.67)] \n[33.33(18.08)] \n[23.60(12.11)] \n[23.62(12.05)] \n\nFL [52]+LTS \n3.13(3.64) \n11.06(5.55) \n6.96(8.21) \n14.51(11.07) 19.61(9.82) \n26.91(16.06) \n6.78(4.05) \n15.28(4.76) \n11.85(10.69) \n6.73(4.05) \n14.76(4.84) \n11.83(10.73) \n[12.66(12.87)] \n[ 32.27(19.08)] \n[ 22.04(13.05)] \n[ 22.10(12.96)] \n\nU-Net \nLPBA40 \n(40) \n\n\nTable 1 :\n1Calibration results for 4 different segmentation models on 4 different tasks. Results are reported in mean(std) format. The number of testing samples are listed in parentheses underneath each dataset name. UC denotes the uncalibrated result. # denotes that lower is better. Best results are bolded and green indicates statistically significant differences w.r.t. LTS (FL+LTS for CamVid). Note that due to GPU memory limits, results of MMCE and MMCE+LTS are for downsampled images, thus can not be directly compared with other methods. The goal of including them is to show that LTS can improve MMCE. LTS generally achieves the best performance on almost all metrics in the All region, Boundary region and Local region. Additional results are in Appx. J.\nAcknowledgements. This work was supported by NI-AMS 1R01-AR072013, NIMH 2R42MH118845, and NSF EECS-1711776; it expresses the views of the authors, not of NIH/NSF. The authors have no conflicts of interest.\nNon-parametric Bayesian isotonic calibration: Fighting over-confidence in binary classification. Mari-Liis Allikivi, Meelis Kull, Joint European Conference on Machine Learning and Knowledge Discovery in Databases. SpringerMari-Liis Allikivi and Meelis Kull. Non-parametric Bayesian isotonic calibration: Fighting over-confidence in binary classification. In Joint European Conference on Ma- chine Learning and Knowledge Discovery in Databases, pages 103-120. Springer, 2019. 2\n\nCombination strategies in multi-atlas image segmentation: application to brain MR data. Xabier Artaechevarria, Arrate Munoz-Barrutia, Carlos Ortiz-De Sol\u00f3rzano, IEEE transactions on medical imaging. 28841Xabier Artaechevarria, Arrate Munoz-Barrutia, and Carlos Ortiz-de Sol\u00f3rzano. Combination strategies in multi-atlas image segmentation: application to brain MR data. IEEE transactions on medical imaging, 28(8):1266-1277, 2009. 40, 41\n\nDeep learning. Yoshua Bengio, Ian Goodfellow, Aaron Courville, MIT press15Yoshua Bengio, Ian Goodfellow, and Aaron Courville. Deep learning, volume 1. MIT press, 2017. 4, 5\n\nControlling the false discovery rate: a practical and powerful approach to multiple testing. Yoav Benjamini, Yosef Hochberg, Journal of the Royal statistical society: series B (Methodological). 571Yoav Benjamini and Yosef Hochberg. Controlling the false discovery rate: a practical and powerful approach to multiple testing. Journal of the Royal statistical society: series B (Methodological), 57(1):289-300, 1995. 6\n\nEnd to end learning for self-driving cars. Mariusz Bojarski, Davide Del Testa, Daniel Dworakowski, Bernhard Firner, Beat Flepp, Prasoon Goyal, D Lawrence, Mathew Jackel, Urs Monfort, Jiakai Muller, Zhang, arXiv:1604.07316arXiv preprintMariusz Bojarski, Davide Del Testa, Daniel Dworakowski, Bernhard Firner, Beat Flepp, Prasoon Goyal, Lawrence D Jackel, Mathew Monfort, Urs Muller, Jiakai Zhang, et al. End to end learning for self-driving cars. arXiv preprint arXiv:1604.07316, 2016. 1\n\nSemantic object classes in video: A high-definition ground truth database. J Gabriel, Julien Brostow, Roberto Fauqueur, Cipolla, Pattern Recognition Letters. 30214Gabriel J Brostow, Julien Fauqueur, and Roberto Cipolla. Semantic object classes in video: A high-definition ground truth database. Pattern Recognition Letters, 30(2):88-97, 2009. 6, 14\n\nSegmentation and recognition using structure from motion point clouds. J Gabriel, Jamie Brostow, Julien Shotton, Roberto Fauqueur, Cipolla, European conference on computer vision. Springer614Gabriel J Brostow, Jamie Shotton, Julien Fauqueur, and Roberto Cipolla. Segmentation and recognition using struc- ture from motion point clouds. In European conference on computer vision, pages 44-57. Springer, 2008. 6, 14\n\nCocostuff: Thing and stuff classes in context. Holger Caesar, Jasper Uijlings, Vittorio Ferrari, Computer vision and pattern recognition (CVPR). 14Holger Caesar, Jasper Uijlings, and Vittorio Ferrari. Coco- stuff: Thing and stuff classes in context. In Computer vision and pattern recognition (CVPR), 2018 IEEE conference on. IEEE, 2018. 14\n\n3D U-Net: learning dense volumetric segmentation from sparse annotation. Ahmed \u00d6zg\u00fcn \u00c7 I\u00e7ek, Abdulkadir, S Soeren, Thomas Lienkamp, Olaf Brox, Ronneberger, International conference on medical image computing and computer-assisted intervention. Springer17\u00d6zg\u00fcn \u00c7 i\u00e7ek, Ahmed Abdulkadir, Soeren S Lienkamp, Thomas Brox, and Olaf Ronneberger. 3D U-Net: learning dense volumetric segmentation from sparse annotation. In International conference on medical image computing and computer-assisted intervention, pages 424-432. Springer, 2016. 1, 7\n\nPatchbased segmentation using expert priors: Application to hippocampus and ventricle segmentation. Pierrick Coup\u00e9, Vladimir Jos\u00e9 V Manj\u00f3n, Jens Fonov, Montserrat Pruessner, D Louis Robles, Collins, NeuroImage. 54241Pierrick Coup\u00e9, Jos\u00e9 V Manj\u00f3n, Vladimir Fonov, Jens Pruessner, Montserrat Robles, and D Louis Collins. Patch- based segmentation using expert priors: Application to hippocampus and ventricle segmentation. NeuroImage, 54(2):940-954, 2011. 40, 41\n\nThe comparison and evaluation of forecasters. H Morris, Stephen E Degroot, Fienberg, Journal of the Royal Statistical Society: Series D (The Statistician). 321-235Morris H DeGroot and Stephen E Fienberg. The comparison and evaluation of forecasters. Journal of the Royal Statistical Society: Series D (The Statistician), 32(1-2):12-22, 1983. 3, 5, 35\n\nVotenet: A deep learning label fusion method for multi-atlas segmentation. Zhipeng Ding, Xu Han, Marc Niethammer, International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer1541Zhipeng Ding, Xu Han, and Marc Niethammer. Votenet: A deep learning label fusion method for multi-atlas segmenta- tion. In International Conference on Medical Image Com- puting and Computer-Assisted Intervention, pages 202-210. Springer, 2019. 15, 41\n\nVotenet+: An improved deep learning label fusion method for multiatlas segmentation. Zhipeng Ding, Xu Han, Marc Niethammer, 2020 IEEE 17th International Symposium on Biomedical Imaging (ISBI). IEEE1541Zhipeng Ding, Xu Han, and Marc Niethammer. Votenet+: An improved deep learning label fusion method for multi- atlas segmentation. In 2020 IEEE 17th International Sympo- sium on Biomedical Imaging (ISBI), pages 363-367. IEEE, 2020. 8, 15, 41\n\nThe Pascal visual object classes challenge: A retrospective. International journal of computer vision. Mark Everingham, Ali Eslami, Luc Van Gool, K I Christopher, John Williams, Andrew Winn, Zisserman, 11115Mark Everingham, SM Ali Eslami, Luc Van Gool, Christo- pher KI Williams, John Winn, and Andrew Zisserman. The Pascal visual object classes challenge: A retrospective. Inter- national journal of computer vision, 111(1):98-136, 2015. 14, 15\n\nThe elements of statistical learning. Jerome Friedman, Trevor Hastie, Robert Tibshirani, Springer series in statistics. New York15Jerome Friedman, Trevor Hastie, and Robert Tibshirani. The elements of statistical learning, volume 1. Springer series in statistics New York, 2001. 4, 5\n\nDropout as a Bayesian approximation: Representing model uncertainty in deep learning. Yarin Gal, Zoubin Ghahramani, PMLRinternational conference on machine learning. Yarin Gal and Zoubin Ghahramani. Dropout as a Bayesian approximation: Representing model uncertainty in deep learning. In international conference on machine learning, pages 1050-1059. PMLR, 2016. 13\n\nA review on deep learning techniques applied to semantic segmentation. Alberto Garcia-Garcia, Sergio Orts-Escolano, Sergiu Oprea, Victor Villena-Martinez, Jose Garcia-Rodriguez, arXiv:1704.06857arXiv preprintAlberto Garcia-Garcia, Sergio Orts-Escolano, Sergiu Oprea, Victor Villena-Martinez, and Jose Garcia-Rodriguez. A re- view on deep learning techniques applied to semantic seg- mentation. arXiv preprint arXiv:1704.06857, 2017. 1\n\nSymmetric atlasing and model based segmentation: an application to the hippocampus in older adults. G\u0159nther Grabner, L Andrew, Janke, M Marc, David Budge, Jens Smith, D Louis Pruessner, Collins, International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer14G\u0158nther Grabner, Andrew L Janke, Marc M Budge, David Smith, Jens Pruessner, and D Louis Collins. Symmetric at- lasing and model based segmentation: an application to the hippocampus in older adults. In International Conference on Medical Image Computing and Computer-Assisted Interven- tion, pages 58-66. Springer, 2006. 14\n\nRecent advances in convolutional neural networks. Jiuxiang Gu, Zhenhua Wang, Jason Kuen, Lianyang Ma, Amir Shahroudy, Bing Shuai, Ting Liu, Xingxing Wang, Gang Wang, Jianfei Cai, Pattern Recognition. 773Jiuxiang Gu, Zhenhua Wang, Jason Kuen, Lianyang Ma, Amir Shahroudy, Bing Shuai, Ting Liu, Xingxing Wang, Gang Wang, Jianfei Cai, et al. Recent advances in convo- lutional neural networks. Pattern Recognition, 77:354-377, 2018. 3\n\nOn calibration of modern neural networks. Chuan Guo, Geoff Pleiss, Yu Sun, Kilian Q Weinberger, Proceedings of the 34th International Conference on Machine Learning. the 34th International Conference on Machine Learning7040Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q Weinberger. On calibration of modern neural networks. In Proceedings of the 34th International Conference on Machine Learning- Volume 70, pages 1321-1330. JMLR. org, 2017. 1, 2, 3, 5, 6, 7, 15, 16, 36, 38, 40\n\nNeural network ensembles. Lars Kai Hansen, Peter Salamon, IEEE transactions on pattern analysis and machine intelligence. 121040Lars Kai Hansen and Peter Salamon. Neural network en- sembles. IEEE transactions on pattern analysis and machine intelligence, 12(10):993-1001, 1990. 40\n\nBrain tumor segmentation with deep neural networks. Mohammad Havaei, Axel Davy, David Warde-Farley, Antoine Biard, Aaron Courville, Yoshua Bengio, Chris Pal, Pierre-Marc Jodoin, Hugo Larochelle, Medical image analysis. 351Mohammad Havaei, Axel Davy, David Warde-Farley, An- toine Biard, Aaron Courville, Yoshua Bengio, Chris Pal, Pierre-Marc Jodoin, and Hugo Larochelle. Brain tumor seg- mentation with deep neural networks. Medical image analy- sis, 35:18-31, 2017. 1\n\nDeep residual learning for image recognition. Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognition614Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceed- ings of the IEEE conference on computer vision and pattern recognition, pages 770-778, 2016. 6, 14\n\nAutomatic anatomical brain MRI segmentation combining label propagation and decision fusion. A Rolf, Joseph V Heckemann, Paul Hajnal, Daniel Aljabar, Alexander Rueckert, Hammers, NeuroImage. 33140Rolf A Heckemann, Joseph V Hajnal, Paul Aljabar, Daniel Rueckert, and Alexander Hammers. Automatic anatomical brain MRI segmentation combining label propagation and decision fusion. NeuroImage, 33(1):115-126, 2006. 40\n\nGeoffrey Hinton, Oriol Vinyals, Jeff Dean, arXiv:1503.02531Distilling the knowledge in a neural network. arXiv preprintGeoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distill- ing the knowledge in a neural network. arXiv preprint arXiv:1503.02531, 2015. 2\n\nMulti-atlas segmentation of biomedical images: a survey. Juan Eugenio Iglesias, R Mert, Sabuncu, Medical image analysis. 24139Juan Eugenio Iglesias and Mert R Sabuncu. Multi-atlas seg- mentation of biomedical images: a survey. Medical image analysis, 24(1):205-219, 2015. 38, 39\n\nAutoencoder trees. Ozan Irsoy, Ethem Alpaydin, Asian Conference on Machine Learning. Ozan Irsoy and Ethem Alpaydin. Autoencoder trees. In Asian Conference on Machine Learning, pages 378-390, 2016. 13\n\nThe one hundred layers tiramisu: Fully convolutional densenets for semantic segmentation. Simon J\u00e9gou, Michal Drozdzal, David Vazquez, Adriana Romero, Yoshua Bengio, Proceedings of the IEEE conference on computer vision and pattern recognition workshops. the IEEE conference on computer vision and pattern recognition workshops1415Simon J\u00e9gou, Michal Drozdzal, David Vazquez, Adriana Romero, and Yoshua Bengio. The one hundred layers tiramisu: Fully convolutional densenets for semantic seg- mentation. In Proceedings of the IEEE conference on com- puter vision and pattern recognition workshops, pages 11- 19, 2017. 7, 14, 15\n\nA Bayesian neural net to segment images with uncertainty estimates and good calibration. Rohit Jena, Suyash P Awate, International Conference on Information Processing in Medical Imaging. Springer13Rohit Jena and Suyash P Awate. A Bayesian neural net to segment images with uncertainty estimates and good calibra- tion. In International Conference on Information Processing in Medical Imaging, pages 3-15. Springer, 2019. 1, 2, 13\n\nBin-wise temperature scaling (BTS): Improvement in confidence calibration performance through simple scaling techniques. Byeongmoon Ji, Hyemin Jung, Jihyeun Yoon, Kyungyul Kim, Younghak Shin, arXiv:1908.115282arXiv preprintByeongmoon Ji, Hyemin Jung, Jihyeun Yoon, Kyungyul Kim, and Younghak Shin. Bin-wise temperature scal- ing (BTS): Improvement in confidence calibration perfor- mance through simple scaling techniques. arXiv preprint arXiv:1908.11528, 2019. 2, 8\n\nImproving calibration and out-of-distribution detection in medical image segmentation with convolutional neural networks. Davood Karimi, Ali Gholipour, arXiv:2004.065691arXiv preprintDavood Karimi and Ali Gholipour. Improving calibration and out-of-distribution detection in medical image segmen- tation with convolutional neural networks. arXiv preprint arXiv:2004.06569, 2020. 1, 2\n\nWhat uncertainties do we need in Bayesian deep learning for computer vision?. Alex Kendall, Yarin Gal, Proceedings of the 31st International Conference on Neural Information Processing Systems. the 31st International Conference on Neural Information Processing Systems213Alex Kendall and Yarin Gal. What uncertainties do we need in Bayesian deep learning for computer vision? In Proceed- ings of the 31st International Conference on Neural Infor- mation Processing Systems, pages 5580-5590, 2017. 2, 13\n\nAdam: A method for stochastic optimization. P Diederik, Jimmy Kingma, Ba, arXiv:1412.698015arXiv preprintDiederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014. 15\n\nBeyond temperature scaling: Obtaining well-calibrated multi-class probabilities with Dirichlet calibration. Meelis Kull, Miquel Perello Nieto, Markus K\u00e4ngsepp, Telmo Silva Filho, Hao Song, Peter Flach, Advances in Neural Information Processing Systems. 3840Meelis Kull, Miquel Perello Nieto, Markus K\u00e4ngsepp, Telmo Silva Filho, Hao Song, and Peter Flach. Beyond tem- perature scaling: Obtaining well-calibrated multi-class prob- abilities with Dirichlet calibration. In Advances in Neural Information Processing Systems, pages 12295-12305, 2019. 2, 5, 6, 7, 15, 38, 40\n\nBeyond sigmoids: How to obtain well-calibrated probabilities from binary classifiers with beta calibration. Meelis Kull, Telmo M Silva, Peter Filho, Flach, Electronic Journal of Statistics. 112Meelis Kull, Telmo M Silva Filho, Peter Flach, et al. Beyond sigmoids: How to obtain well-calibrated probabilities from binary classifiers with beta calibration. Electronic Journal of Statistics, 11(2):5052-5080, 2017. 2\n\nTrainable calibration measures for neural networks from kernel mean embeddings. Aviral Kumar, Sunita Sarawagi, Ujjwal Jain, International Conference on Machine Learning. 740Aviral Kumar, Sunita Sarawagi, and Ujjwal Jain. Train- able calibration measures for neural networks from kernel mean embeddings. In International Conference on Machine Learning, pages 2805-2814, 2018. 1, 2, 5, 7, 40\n\nSimple and scalable predictive uncertainty estimation using deep ensembles. Balaji Lakshminarayanan, Alexander Pritzel, Charles Blundell, arXiv:1612.01474arXiv preprintBalaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell. Simple and scalable predictive uncertainty estimation using deep ensembles. arXiv preprint arXiv:1612.01474, 2016. 13\n\nSimple and scalable predictive uncertainty estimation using deep ensembles. Balaji Lakshminarayanan, Alexander Pritzel, Charles Blundell, Advances in neural information processing systems. Balaji Lakshminarayanan, Alexander Pritzel, and Charles Blundell. Simple and scalable predictive uncertainty esti- mation using deep ensembles. In Advances in neural infor- mation processing systems, pages 6402-6413, 2017. 2\n\nProbability calibration trees. Tim Leathart, Eibe Frank, Geoffrey Holmes, Bernhard Pfahringer, PMLRAsian Conference on Machine Learning. Tim Leathart, Eibe Frank, Geoffrey Holmes, and Bernhard Pfahringer. Probability calibration trees. In Asian Confer- ence on Machine Learning, pages 145-160. PMLR, 2017. 2\n\nChen-Yu Lee, Patrick Gallagher, Zhuowen Tu, Generalizing pooling functions in CNNs: Mixed, gated, and tree. IEEE transactions on pattern analysis and machine intelligence. 4013Chen-Yu Lee, Patrick Gallagher, and Zhuowen Tu. Gener- alizing pooling functions in CNNs: Mixed, gated, and tree. IEEE transactions on pattern analysis and machine intelli- gence, 40(4):863-875, 2017. 12, 13\n\nOverfitting of neural nets under class imbalance: Analysis and improvements for segmentation. Zeju Li, Konstantinos Kamnitsas, Ben Glocker, International Conference on Medical Image Computing and Computer-Assisted Intervention. SpringerZeju Li, Konstantinos Kamnitsas, and Ben Glocker. Overfit- ting of neural nets under class imbalance: Analysis and im- provements for segmentation. In International Conference on Medical Image Computing and Computer-Assisted Inter- vention, pages 402-410. Springer, 2019. 1\n\nMicrosoft COCO: Common objects in context. Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll\u00e1r, C Lawrence Zitnick, European conference on computer vision. Springer614Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll\u00e1r, and C Lawrence Zitnick. Microsoft COCO: Common objects in context. In European conference on computer vision, pages 740-755. Springer, 2014. 6, 14\n\nFully convolutional networks for semantic segmentation. Jonathan Long, Evan Shelhamer, Trevor Darrell, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognition614Jonathan Long, Evan Shelhamer, and Trevor Darrell. Fully convolutional networks for semantic segmentation. In Pro- ceedings of the IEEE conference on computer vision and pat- tern recognition, pages 3431-3440, 2015. 1, 6, 14\n\nA simple baseline for Bayesian uncertainty in deep learning. J Wesley, Pavel Maddox, Timur Izmailov, Garipov, P Dmitry, Andrew Gordon Vetrov, Wilson, Advances in Neural Information Processing Systems. 1Wesley J Maddox, Pavel Izmailov, Timur Garipov, Dmitry P Vetrov, and Andrew Gordon Wilson. A simple baseline for Bayesian uncertainty in deep learning. In Advances in Neural Information Processing Systems, pages 13132-13143, 2019. 1, 2\n\nOn a test of whether one of two random variables is stochastically larger than the other. The annals of mathematical statistics. B Henry, Donald R Mann, Whitney, Henry B Mann and Donald R Whitney. On a test of whether one of two random variables is stochastically larger than the other. The annals of mathematical statistics, pages 50-60, 1947. 6\n\nCalibration of deep probabilistic models with decoupled Bayesian neural networks. Juan Maro\u00f1as, Roberto Paredes, Daniel Ramos, Neurocomputing. 213Juan Maro\u00f1as, Roberto Paredes, and Daniel Ramos. Calibra- tion of deep probabilistic models with decoupled Bayesian neural networks. Neurocomputing, 2020. 2, 13\n\nConfidence calibration and predictive uncertainty estimation for deep medical image segmentation. Alireza Mehrtash, M William, Iii Wells, Clare M Tempany, Purang Abolmaesumi, Tina Kapur, arXiv:1911.132731arXiv preprintAlireza Mehrtash, William M Wells III, Clare M Tempany, Purang Abolmaesumi, and Tina Kapur. Confidence cali- bration and predictive uncertainty estimation for deep med- ical image segmentation. arXiv preprint arXiv:1911.13273, 2019. 1, 2\n\nDirichlet-based Gaussian processes for large-scale calibrated classification. Dimitrios Milios, Raffaello Camoriano, Pietro Michiardi, Lorenzo Rosasco, Maurizio Filippone, arXiv:1805.1091513arXiv preprintDimitrios Milios, Raffaello Camoriano, Pietro Michiardi, Lorenzo Rosasco, and Maurizio Filippone. Dirichlet-based Gaussian processes for large-scale calibrated classification. arXiv preprint arXiv:1805.10915, 2018. 1, 2, 13\n\nGlobal image registration using a symmetric block-matching approach. Marc Modat, M David, Pankaj Cash, Daga, P Gavin, John S Winston, S\u00e9bastien Duncan, Ourselin, Journal of Medical Imaging. 1214Marc Modat, David M Cash, Pankaj Daga, Gavin P Winston, John S Duncan, and S\u00e9bastien Ourselin. Global image regis- tration using a symmetric block-matching approach. Journal of Medical Imaging, 1(2):024003, 2014. 14\n\nFast free-form deformation using graphics processing units. Computer methods and programs in biomedicine. Marc Modat, Gerard R Ridgway, A Zeike, Manja Taylor, Josephine Lehmann, Barnes, J David, Nick C Hawkes, S\u00e9bastien Fox, Ourselin, 9814Marc Modat, Gerard R Ridgway, Zeike A Taylor, Manja Lehmann, Josephine Barnes, David J Hawkes, Nick C Fox, and S\u00e9bastien Ourselin. Fast free-form deformation using graphics processing units. Computer methods and programs in biomedicine, 98(3):278-284, 2010. 14\n\nAttended temperature scaling: A practical approach for calibrating deep neural networks. Azadeh Sadat Mozafari, Hugo Siqueira Gomes, Wilson Le\u00e3o, Steeven Janny, Christian Gagn\u00e9, arXiv:1810.115862arXiv preprintAzadeh Sadat Mozafari, Hugo Siqueira Gomes, Wilson Le\u00e3o, Steeven Janny, and Christian Gagn\u00e9. Attended tem- perature scaling: A practical approach for calibrating deep neural networks. arXiv preprint arXiv:1810.11586, 2018. 2, 8\n\nJishnu Mukhoti, Viveka Kulharia, Amartya Sanyal, Stuart Golodetz, H S Philip, Puneet K Torr, Dokania, arXiv:2002.09437Calibrating deep neural networks using focal loss. 1940arXiv preprintJishnu Mukhoti, Viveka Kulharia, Amartya Sanyal, Stuart Golodetz, Philip HS Torr, and Puneet K Dokania. Calibrat- ing deep neural networks using focal loss. arXiv preprint arXiv:2002.09437, 2020. 1, 2, 5, 7, 15, 19, 40\n\nReliability of subjective probability forecasts of precipitation and temperature. H Allan, Robert L Murphy, Winkler, Journal of the Royal Statistical Society: Series C (Applied Statistics). 26135Allan H Murphy and Robert L Winkler. Reliability of sub- jective probability forecasts of precipitation and temperature. Journal of the Royal Statistical Society: Series C (Applied Statistics), 26(1):41-47, 1977. 3, 5, 35\n\nObtaining well calibrated probabilities using Bayesian binning. Gregory Mahdi Pakdaman Naeini, Milos Cooper, Hauskrecht, Twenty-Ninth AAAI Conference on Artificial Intelligence. 536Mahdi Pakdaman Naeini, Gregory Cooper, and Milos Hauskrecht. Obtaining well calibrated probabilities using Bayesian binning. In Twenty-Ninth AAAI Conference on Ar- tificial Intelligence, 2015. 2, 3, 5, 36\n\nBinary classifier calibration using an ensemble of near isotonic regression models. Gregory F Mahdi Pakdaman Naeini, Cooper, 2016 IEEE 16th International Conference on Data Mining (ICDM). Mahdi Pakdaman Naeini and Gregory F Cooper. Binary clas- sifier calibration using an ensemble of near isotonic regres- sion models. In 2016 IEEE 16th International Conference on Data Mining (ICDM), pages 360-369. IEEE, 2016. 2\n\nPredicting good probabilities with supervised learning. Alexandru Niculescu, - Mizil, Rich Caruana, Proceedings of the 22nd international conference on Machine learning. the 22nd international conference on Machine learning335Alexandru Niculescu-Mizil and Rich Caruana. Predicting good probabilities with supervised learning. In Proceedings of the 22nd international conference on Machine learning, pages 625-632, 2005. 3, 5, 35\n\nMeasuring calibration in deep learning. Jeremy Nixon, Mike Dusenberry, Linchuan Zhang, Ghassen Jerfel, Dustin Tran, arXiv:1904.016853637arXiv preprintJeremy Nixon, Mike Dusenberry, Linchuan Zhang, Ghassen Jerfel, and Dustin Tran. Measuring calibration in deep learn- ing. arXiv preprint arXiv:1904.01685, 2019. 3, 5, 36, 37\n\nProbabilistic outputs for support vector machines and comparisons to regularized likelihood methods. John Platt, Advances in large margin classifiers. 1033John Platt et al. Probabilistic outputs for support vector ma- chines and comparisons to regularized likelihood methods. Advances in large margin classifiers, 10(3):61-74, 1999. 1, 2, 3\n\nIntra order-preserving functions for calibration of multi-class neural networks. Amir Rahimi, Amirreza Shaban, Ching-An Cheng, Byron Boots, Richard Hartley, arXiv:2003.06820arXiv preprintAmir Rahimi, Amirreza Shaban, Ching-An Cheng, Byron Boots, and Richard Hartley. Intra order-preserving functions for calibration of multi-class neural networks. arXiv preprint arXiv:2003.06820, 2020. 2\n\nNonrigid registration using free-form deformations: application to breast MR images. Daniel Rueckert, I Luke, Carmel Sonoda, Hayes, L G Derek, Hill, O Martin, David J Leach, Hawkes, IEEE transactions on medical imaging. 18814Daniel Rueckert, Luke I Sonoda, Carmel Hayes, Derek LG Hill, Martin O Leach, and David J Hawkes. Nonrigid registration using free-form deformations: application to breast MR images. IEEE transactions on medical imaging, 18(8):712-721, 1999. 14\n\nA generative model for image segmentation based on label fusion. Mert R Sabuncu, Koen Bt Thomas Yeo, Bruce Van Leemput, Polina Fischl, Golland, IEEE transactions on medical imaging. 291041Mert R Sabuncu, BT Thomas Yeo, Koen Van Leemput, Bruce Fischl, and Polina Golland. A generative model for image segmentation based on label fusion. IEEE transac- tions on medical imaging, 29(10):1714-1729, 2010. 40, 41\n\nConstruction of a 3D probabilistic atlas of human cortical structures. W David, Mubeena Shattuck, Vitria Mirza, Cornelius Adisetiyo, Georges Hojatkashani, Katherine L Salamon, Russell A Narr, Poldrack, M Robert, Arthur W Bilder, Toga, Neuroimage. 39314David W Shattuck, Mubeena Mirza, Vitria Adisetiyo, Cor- nelius Hojatkashani, Georges Salamon, Katherine L Narr, Russell A Poldrack, Robert M Bilder, and Arthur W Toga. Construction of a 3D probabilistic atlas of human cortical structures. Neuroimage, 39(3):1064-1080, 2008. 6, 14\n\nCalibrating deep convolutional gaussian processes. Gia-Lac Tran, Edwin V Bonilla, John Cunningham, Pietro Michiardi, Maurizio Filippone, PMLRThe 22nd International Conference on Artificial Intelligence and Statistics. Gia-Lac Tran, Edwin V Bonilla, John Cunningham, Pietro Michiardi, and Maurizio Filippone. Calibrating deep convo- lutional gaussian processes. In The 22nd International Con- ference on Artificial Intelligence and Statistics, pages 1554- 1563. PMLR, 2019. 13\n\nMulti-atlas segmentation with joint label fusion. Hongzhi Wang, W Jung, Suh, R Sandhitsu, John B Das, Caryne Pluta, Paul A Craige, Yushkevich, IEEE transactions on pattern analysis and machine intelligence. 3541Hongzhi Wang, Jung W Suh, Sandhitsu R Das, John B Pluta, Caryne Craige, and Paul A Yushkevich. Multi-atlas segmen- tation with joint label fusion. IEEE transactions on pattern analysis and machine intelligence, 35(3):611-623, 2012. 6, 8, 15, 40, 41\n\nNon-parametric calibration for classification. Jonathan Wenger, Hedvig Kjellstr\u00f6m, Rudolph Triebel, PMLR, 2020. 13International Conference on Artificial Intelligence and Statistics. Jonathan Wenger, Hedvig Kjellstr\u00f6m, and Rudolph Triebel. Non-parametric calibration for classification. In Interna- tional Conference on Artificial Intelligence and Statistics, pages 178-190. PMLR, 2020. 13\n\nImproving multi-atlas segmentation by convolutional neural network based patch error estimation. Long Xie, Jiancong Wang, Mengjin Dong, A David, Paul A Wolk, Yushkevich, International Conference on Medical Image Computing and Computer-Assisted Intervention. Springer41Long Xie, Jiancong Wang, Mengjin Dong, David A Wolk, and Paul A Yushkevich. Improving multi-atlas segmentation by convolutional neural network based patch error estima- tion. In International Conference on Medical Image Com- puting and Computer-Assisted Intervention, pages 347-355. Springer, 2019. 41\n\nObtaining calibrated probability estimates from decision trees and naive Bayesian classifiers. Bianca Zadrozny, Charles Elkan, ICML. 1Bianca Zadrozny and Charles Elkan. Obtaining calibrated probability estimates from decision trees and naive Bayesian classifiers. In ICML, volume 1, pages 609-616. Citeseer, 2001. 2\n\nTransforming classifier scores into accurate multiclass probability estimates. Bianca Zadrozny, Charles Elkan, Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining. the eighth ACM SIGKDD international conference on Knowledge discovery and data mining3840Bianca Zadrozny and Charles Elkan. Transforming classifier scores into accurate multiclass probability estimates. In Pro- ceedings of the eighth ACM SIGKDD international confer- ence on Knowledge discovery and data mining, pages 694- 699, 2002. 2, 5, 6, 7, 15, 38, 40\n\nMix-n-match: Ensemble and compositional methods for uncertainty calibration in deep learning. Jize Zhang, Bhavya Kailkhura, T Han, arXiv:2003.073293840arXiv preprintJize Zhang, Bhavya Kailkhura, and T Han. Mix-n-match: Ensemble and compositional methods for uncertainty cali- bration in deep learning. arXiv preprint arXiv:2003.07329, 2020. 2, 5, 6, 7, 15, 38, 40\n", "annotations": {"author": "[{\"end\":149,\"start\":57},{\"end\":217,\"start\":150},{\"end\":309,\"start\":218},{\"end\":386,\"start\":310}]", "publisher": null, "author_last_name": "[{\"end\":69,\"start\":65},{\"end\":156,\"start\":153},{\"end\":229,\"start\":226},{\"end\":325,\"start\":315}]", "author_first_name": "[{\"end\":64,\"start\":57},{\"end\":152,\"start\":150},{\"end\":225,\"start\":218},{\"end\":314,\"start\":310}]", "author_affiliation": "[{\"end\":148,\"start\":90},{\"end\":216,\"start\":158},{\"end\":308,\"start\":250},{\"end\":385,\"start\":327}]", "title": "[{\"end\":54,\"start\":1},{\"end\":440,\"start\":387}]", "venue": null, "abstract": "[{\"end\":1605,\"start\":470}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b8\"},\"end\":1755,\"start\":1752},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":1758,\"start\":1755},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":2027,\"start\":2024},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":2290,\"start\":2286},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":2703,\"start\":2699},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":2706,\"start\":2703},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":2709,\"start\":2706},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":2712,\"start\":2709},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":2772,\"start\":2768},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":2775,\"start\":2772},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":2778,\"start\":2775},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":2781,\"start\":2778},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":3276,\"start\":3272},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":3818,\"start\":3814},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":3904,\"start\":3900},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":3932,\"start\":3928},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3938,\"start\":3935},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":4630,\"start\":4626},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":5084,\"start\":5081},{\"attributes\":{\"ref_id\":\"b66\"},\"end\":5879,\"start\":5875},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":5997,\"start\":5993},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":6153,\"start\":6149},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":6491,\"start\":6487},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":6565,\"start\":6561},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":6586,\"start\":6582},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":6616,\"start\":6612},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":6619,\"start\":6616},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":6753,\"start\":6749},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":6957,\"start\":6953},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":7274,\"start\":7270},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":7390,\"start\":7387},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":7545,\"start\":7541},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":7721,\"start\":7717},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":8051,\"start\":8047},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":8337,\"start\":8333},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":8473,\"start\":8469},{\"attributes\":{\"ref_id\":\"b68\"},\"end\":8476,\"start\":8473},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":8572,\"start\":8568},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":8889,\"start\":8885},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":9087,\"start\":9083},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":9225,\"start\":9221},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":9332,\"start\":9328},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":9572,\"start\":9568},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":9575,\"start\":9572},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":9578,\"start\":9575},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":9581,\"start\":9578},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":11566,\"start\":11562},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":11569,\"start\":11566},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":11572,\"start\":11569},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":11575,\"start\":11572},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":11578,\"start\":11575},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":12355,\"start\":12351},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":12417,\"start\":12413},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":12949,\"start\":12945},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":13882,\"start\":13878},{\"end\":13986,\"start\":13981},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":16925,\"start\":16922},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":16928,\"start\":16925},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":17317,\"start\":17314},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":17320,\"start\":17317},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":17940,\"start\":17936},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":18985,\"start\":18981},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":18988,\"start\":18985},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":20236,\"start\":20235},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":20913,\"start\":20909},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":20916,\"start\":20913},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":20919,\"start\":20916},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":20952,\"start\":20948},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":20990,\"start\":20986},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":21027,\"start\":21023},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":21070,\"start\":21066},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":22348,\"start\":22344},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":22374,\"start\":22370},{\"attributes\":{\"ref_id\":\"b68\"},\"end\":22415,\"start\":22411},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":22490,\"start\":22486},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":22698,\"start\":22694},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":22723,\"start\":22719},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":24677,\"start\":24673},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":24951,\"start\":24947},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":25128,\"start\":25125},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":25448,\"start\":25444},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":25515,\"start\":25512},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":25517,\"start\":25515},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":25571,\"start\":25567},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":25755,\"start\":25751},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":25778,\"start\":25774},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":26478,\"start\":26474},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":26487,\"start\":26483},{\"attributes\":{\"ref_id\":\"b68\"},\"end\":26497,\"start\":26493},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":26514,\"start\":26510},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":26955,\"start\":26951},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":28608,\"start\":28604},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":29433,\"start\":29429},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":29436,\"start\":29433},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":29447,\"start\":29443},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":29459,\"start\":29455},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":29827,\"start\":29823},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":30127,\"start\":30124},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":32427,\"start\":32423},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":34037,\"start\":34033},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":35790,\"start\":35786},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":35845,\"start\":35841}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":36237,\"start\":35847},{\"attributes\":{\"id\":\"fig_1\"},\"end\":37248,\"start\":36238},{\"attributes\":{\"id\":\"fig_2\"},\"end\":37631,\"start\":37249},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":41696,\"start\":37632},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":42462,\"start\":41697}]", "paragraph": "[{\"end\":2589,\"start\":1621},{\"end\":3345,\"start\":2591},{\"end\":4389,\"start\":3347},{\"end\":4898,\"start\":4391},{\"end\":5707,\"start\":4900},{\"end\":5818,\"start\":5724},{\"end\":6439,\"start\":5820},{\"end\":7243,\"start\":6441},{\"end\":8297,\"start\":7245},{\"end\":9807,\"start\":8299},{\"end\":10427,\"start\":9843},{\"end\":11005,\"start\":10541},{\"end\":11308,\"start\":11140},{\"end\":11649,\"start\":11310},{\"end\":12296,\"start\":11671},{\"end\":12683,\"start\":12331},{\"end\":13371,\"start\":12685},{\"end\":13504,\"start\":13451},{\"end\":14091,\"start\":13595},{\"end\":15001,\"start\":14276},{\"end\":15114,\"start\":15062},{\"end\":15808,\"start\":15116},{\"end\":16540,\"start\":15810},{\"end\":17885,\"start\":16781},{\"end\":18755,\"start\":17887},{\"end\":19465,\"start\":18757},{\"end\":19549,\"start\":19467},{\"end\":20276,\"start\":19765},{\"end\":20687,\"start\":20292},{\"end\":22817,\"start\":20689},{\"end\":24836,\"start\":22819},{\"end\":25351,\"start\":24838},{\"end\":25661,\"start\":25365},{\"end\":26672,\"start\":25699},{\"end\":27232,\"start\":26674},{\"end\":27758,\"start\":27234},{\"end\":28511,\"start\":27760},{\"end\":29283,\"start\":28556},{\"end\":30053,\"start\":29285},{\"end\":31752,\"start\":30086},{\"end\":32352,\"start\":31754},{\"end\":32859,\"start\":32394},{\"end\":35014,\"start\":32861},{\"end\":35846,\"start\":35045}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":10540,\"start\":10428},{\"attributes\":{\"id\":\"formula_1\"},\"end\":11139,\"start\":11006},{\"attributes\":{\"id\":\"formula_2\"},\"end\":13450,\"start\":13372},{\"attributes\":{\"id\":\"formula_3\"},\"end\":13594,\"start\":13505},{\"attributes\":{\"id\":\"formula_4\"},\"end\":14194,\"start\":14092},{\"attributes\":{\"id\":\"formula_5\"},\"end\":14236,\"start\":14194},{\"attributes\":{\"id\":\"formula_6\"},\"end\":15061,\"start\":15002},{\"attributes\":{\"id\":\"formula_7\"},\"end\":16752,\"start\":16541},{\"attributes\":{\"id\":\"formula_8\"},\"end\":19764,\"start\":19550}]", "table_ref": "[{\"end\":30677,\"start\":30670}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":1619,\"start\":1607},{\"attributes\":{\"n\":\"2.\"},\"end\":5722,\"start\":5710},{\"attributes\":{\"n\":\"3.\"},\"end\":9821,\"start\":9810},{\"attributes\":{\"n\":\"3.1.\"},\"end\":9841,\"start\":9824},{\"attributes\":{\"n\":\"3.2.\"},\"end\":11669,\"start\":11652},{\"attributes\":{\"n\":\"3.3.\"},\"end\":12329,\"start\":12299},{\"attributes\":{\"n\":\"3.4.\"},\"end\":14274,\"start\":14238},{\"attributes\":{\"n\":\"3.5.\"},\"end\":16779,\"start\":16754},{\"attributes\":{\"n\":\"4.\"},\"end\":20290,\"start\":20279},{\"end\":25363,\"start\":25354},{\"attributes\":{\"n\":\"4.1.\"},\"end\":25697,\"start\":25664},{\"attributes\":{\"n\":\"4.2.\"},\"end\":28554,\"start\":28514},{\"attributes\":{\"n\":\"4.3.\"},\"end\":30084,\"start\":30056},{\"attributes\":{\"n\":\"4.4.\"},\"end\":32392,\"start\":32355},{\"attributes\":{\"n\":\"5.\"},\"end\":35043,\"start\":35017},{\"end\":35858,\"start\":35848},{\"end\":36249,\"start\":36239},{\"end\":37260,\"start\":37250},{\"end\":41707,\"start\":41698}]", "table": "[{\"end\":41696,\"start\":37963}]", "figure_caption": "[{\"end\":36237,\"start\":35860},{\"end\":37248,\"start\":36251},{\"end\":37631,\"start\":37262},{\"end\":37963,\"start\":37634},{\"end\":42462,\"start\":41709}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":14338,\"start\":14332},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":14763,\"start\":14757},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":15906,\"start\":15900},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":22992,\"start\":22985},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":28510,\"start\":28477},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":32060,\"start\":32054}]", "bib_author_first_name": "[{\"end\":42775,\"start\":42766},{\"end\":42792,\"start\":42786},{\"end\":43241,\"start\":43235},{\"end\":43264,\"start\":43258},{\"end\":43287,\"start\":43281},{\"end\":43606,\"start\":43600},{\"end\":43618,\"start\":43615},{\"end\":43636,\"start\":43631},{\"end\":43856,\"start\":43852},{\"end\":43873,\"start\":43868},{\"end\":44227,\"start\":44220},{\"end\":44244,\"start\":44238},{\"end\":44248,\"start\":44245},{\"end\":44262,\"start\":44256},{\"end\":44284,\"start\":44276},{\"end\":44297,\"start\":44293},{\"end\":44312,\"start\":44305},{\"end\":44321,\"start\":44320},{\"end\":44338,\"start\":44332},{\"end\":44350,\"start\":44347},{\"end\":44366,\"start\":44360},{\"end\":44741,\"start\":44740},{\"end\":44757,\"start\":44751},{\"end\":44774,\"start\":44767},{\"end\":45087,\"start\":45086},{\"end\":45102,\"start\":45097},{\"end\":45118,\"start\":45112},{\"end\":45135,\"start\":45128},{\"end\":45483,\"start\":45477},{\"end\":45498,\"start\":45492},{\"end\":45517,\"start\":45509},{\"end\":45850,\"start\":45845},{\"end\":45878,\"start\":45877},{\"end\":45893,\"start\":45887},{\"end\":45908,\"start\":45904},{\"end\":46421,\"start\":46413},{\"end\":46437,\"start\":46429},{\"end\":46457,\"start\":46453},{\"end\":46475,\"start\":46465},{\"end\":46494,\"start\":46487},{\"end\":46822,\"start\":46821},{\"end\":46838,\"start\":46831},{\"end\":46840,\"start\":46839},{\"end\":47209,\"start\":47202},{\"end\":47218,\"start\":47216},{\"end\":47228,\"start\":47224},{\"end\":47685,\"start\":47678},{\"end\":47694,\"start\":47692},{\"end\":47704,\"start\":47700},{\"end\":48143,\"start\":48139},{\"end\":48159,\"start\":48156},{\"end\":48171,\"start\":48168},{\"end\":48183,\"start\":48182},{\"end\":48185,\"start\":48184},{\"end\":48203,\"start\":48199},{\"end\":48220,\"start\":48214},{\"end\":48527,\"start\":48521},{\"end\":48544,\"start\":48538},{\"end\":48559,\"start\":48553},{\"end\":48859,\"start\":48854},{\"end\":48871,\"start\":48865},{\"end\":49213,\"start\":49206},{\"end\":49235,\"start\":49229},{\"end\":49257,\"start\":49251},{\"end\":49271,\"start\":49265},{\"end\":49294,\"start\":49290},{\"end\":49678,\"start\":49671},{\"end\":49689,\"start\":49688},{\"end\":49706,\"start\":49705},{\"end\":49718,\"start\":49713},{\"end\":49730,\"start\":49726},{\"end\":49745,\"start\":49738},{\"end\":50247,\"start\":50239},{\"end\":50259,\"start\":50252},{\"end\":50271,\"start\":50266},{\"end\":50286,\"start\":50278},{\"end\":50295,\"start\":50291},{\"end\":50311,\"start\":50307},{\"end\":50323,\"start\":50319},{\"end\":50337,\"start\":50329},{\"end\":50348,\"start\":50344},{\"end\":50362,\"start\":50355},{\"end\":50669,\"start\":50664},{\"end\":50680,\"start\":50675},{\"end\":50691,\"start\":50689},{\"end\":50705,\"start\":50697},{\"end\":51131,\"start\":51127},{\"end\":51135,\"start\":51132},{\"end\":51149,\"start\":51144},{\"end\":51443,\"start\":51435},{\"end\":51456,\"start\":51452},{\"end\":51468,\"start\":51463},{\"end\":51490,\"start\":51483},{\"end\":51503,\"start\":51498},{\"end\":51521,\"start\":51515},{\"end\":51535,\"start\":51530},{\"end\":51552,\"start\":51541},{\"end\":51565,\"start\":51561},{\"end\":51906,\"start\":51899},{\"end\":51918,\"start\":51911},{\"end\":51934,\"start\":51926},{\"end\":51944,\"start\":51940},{\"end\":52401,\"start\":52400},{\"end\":52414,\"start\":52408},{\"end\":52416,\"start\":52415},{\"end\":52432,\"start\":52428},{\"end\":52447,\"start\":52441},{\"end\":52466,\"start\":52457},{\"end\":52730,\"start\":52722},{\"end\":52744,\"start\":52739},{\"end\":52758,\"start\":52754},{\"end\":53039,\"start\":53035},{\"end\":53047,\"start\":53040},{\"end\":53059,\"start\":53058},{\"end\":53281,\"start\":53277},{\"end\":53294,\"start\":53289},{\"end\":53554,\"start\":53549},{\"end\":53568,\"start\":53562},{\"end\":53584,\"start\":53579},{\"end\":53601,\"start\":53594},{\"end\":53616,\"start\":53610},{\"end\":54181,\"start\":54176},{\"end\":54650,\"start\":54640},{\"end\":54661,\"start\":54655},{\"end\":54675,\"start\":54668},{\"end\":54690,\"start\":54682},{\"end\":54704,\"start\":54696},{\"end\":55115,\"start\":55109},{\"end\":55127,\"start\":55124},{\"end\":55454,\"start\":55450},{\"end\":55469,\"start\":55464},{\"end\":55921,\"start\":55920},{\"end\":55937,\"start\":55932},{\"end\":56213,\"start\":56207},{\"end\":56226,\"start\":56220},{\"end\":56234,\"start\":56227},{\"end\":56248,\"start\":56242},{\"end\":56264,\"start\":56259},{\"end\":56281,\"start\":56278},{\"end\":56293,\"start\":56288},{\"end\":56783,\"start\":56777},{\"end\":56810,\"start\":56805},{\"end\":57170,\"start\":57164},{\"end\":57184,\"start\":57178},{\"end\":57201,\"start\":57195},{\"end\":57557,\"start\":57551},{\"end\":57585,\"start\":57576},{\"end\":57602,\"start\":57595},{\"end\":57910,\"start\":57904},{\"end\":57938,\"start\":57929},{\"end\":57955,\"start\":57948},{\"end\":58277,\"start\":58274},{\"end\":58292,\"start\":58288},{\"end\":58308,\"start\":58300},{\"end\":58325,\"start\":58317},{\"end\":58559,\"start\":58552},{\"end\":58572,\"start\":58565},{\"end\":58591,\"start\":58584},{\"end\":59035,\"start\":59031},{\"end\":59052,\"start\":59040},{\"end\":59067,\"start\":59064},{\"end\":59499,\"start\":59491},{\"end\":59512,\"start\":59505},{\"end\":59525,\"start\":59520},{\"end\":59541,\"start\":59536},{\"end\":59554,\"start\":59548},{\"end\":59567,\"start\":59563},{\"end\":59582,\"start\":59577},{\"end\":59601,\"start\":59591},{\"end\":59974,\"start\":59966},{\"end\":59985,\"start\":59981},{\"end\":60003,\"start\":59997},{\"end\":60445,\"start\":60444},{\"end\":60459,\"start\":60454},{\"end\":60473,\"start\":60468},{\"end\":60494,\"start\":60493},{\"end\":60509,\"start\":60503},{\"end\":60516,\"start\":60510},{\"end\":60952,\"start\":60951},{\"end\":60968,\"start\":60960},{\"end\":61256,\"start\":61252},{\"end\":61273,\"start\":61266},{\"end\":61289,\"start\":61283},{\"end\":61583,\"start\":61576},{\"end\":61595,\"start\":61594},{\"end\":61608,\"start\":61605},{\"end\":61621,\"start\":61616},{\"end\":61623,\"start\":61622},{\"end\":61639,\"start\":61633},{\"end\":61657,\"start\":61653},{\"end\":62022,\"start\":62013},{\"end\":62040,\"start\":62031},{\"end\":62058,\"start\":62052},{\"end\":62077,\"start\":62070},{\"end\":62095,\"start\":62087},{\"end\":62437,\"start\":62433},{\"end\":62446,\"start\":62445},{\"end\":62460,\"start\":62454},{\"end\":62474,\"start\":62473},{\"end\":62486,\"start\":62482},{\"end\":62488,\"start\":62487},{\"end\":62507,\"start\":62498},{\"end\":62885,\"start\":62881},{\"end\":62912,\"start\":62911},{\"end\":62925,\"start\":62920},{\"end\":62943,\"start\":62934},{\"end\":62962,\"start\":62961},{\"end\":62974,\"start\":62970},{\"end\":62976,\"start\":62975},{\"end\":62994,\"start\":62985},{\"end\":63371,\"start\":63365},{\"end\":63392,\"start\":63388},{\"end\":63401,\"start\":63393},{\"end\":63415,\"start\":63409},{\"end\":63429,\"start\":63422},{\"end\":63446,\"start\":63437},{\"end\":63720,\"start\":63714},{\"end\":63736,\"start\":63730},{\"end\":63754,\"start\":63747},{\"end\":63769,\"start\":63763},{\"end\":63781,\"start\":63780},{\"end\":63783,\"start\":63782},{\"end\":63800,\"start\":63792},{\"end\":64204,\"start\":64203},{\"end\":64220,\"start\":64212},{\"end\":64610,\"start\":64603},{\"end\":64639,\"start\":64634},{\"end\":65019,\"start\":65010},{\"end\":65407,\"start\":65398},{\"end\":65420,\"start\":65419},{\"end\":65432,\"start\":65428},{\"end\":65818,\"start\":65812},{\"end\":65830,\"start\":65826},{\"end\":65851,\"start\":65843},{\"end\":65866,\"start\":65859},{\"end\":65881,\"start\":65875},{\"end\":66202,\"start\":66198},{\"end\":66524,\"start\":66520},{\"end\":66541,\"start\":66533},{\"end\":66558,\"start\":66550},{\"end\":66571,\"start\":66566},{\"end\":66586,\"start\":66579},{\"end\":66920,\"start\":66914},{\"end\":66932,\"start\":66931},{\"end\":66945,\"start\":66939},{\"end\":66962,\"start\":66961},{\"end\":66964,\"start\":66963},{\"end\":66979,\"start\":66978},{\"end\":66995,\"start\":66988},{\"end\":67384,\"start\":67380},{\"end\":67405,\"start\":67400},{\"end\":67425,\"start\":67419},{\"end\":67779,\"start\":67778},{\"end\":67794,\"start\":67787},{\"end\":67811,\"start\":67805},{\"end\":67828,\"start\":67819},{\"end\":67847,\"start\":67840},{\"end\":67871,\"start\":67862},{\"end\":67873,\"start\":67872},{\"end\":67890,\"start\":67883},{\"end\":67892,\"start\":67891},{\"end\":67910,\"start\":67909},{\"end\":67925,\"start\":67919},{\"end\":67927,\"start\":67926},{\"end\":68298,\"start\":68291},{\"end\":68310,\"start\":68305},{\"end\":68312,\"start\":68311},{\"end\":68326,\"start\":68322},{\"end\":68345,\"start\":68339},{\"end\":68365,\"start\":68357},{\"end\":68774,\"start\":68767},{\"end\":68782,\"start\":68781},{\"end\":68795,\"start\":68794},{\"end\":68811,\"start\":68807},{\"end\":68813,\"start\":68812},{\"end\":68825,\"start\":68819},{\"end\":68837,\"start\":68833},{\"end\":68839,\"start\":68838},{\"end\":69233,\"start\":69225},{\"end\":69248,\"start\":69242},{\"end\":69268,\"start\":69261},{\"end\":69669,\"start\":69665},{\"end\":69683,\"start\":69675},{\"end\":69697,\"start\":69690},{\"end\":69705,\"start\":69704},{\"end\":69717,\"start\":69713},{\"end\":69719,\"start\":69718},{\"end\":70240,\"start\":70234},{\"end\":70258,\"start\":70251},{\"end\":70541,\"start\":70535},{\"end\":70559,\"start\":70552},{\"end\":71125,\"start\":71121},{\"end\":71139,\"start\":71133},{\"end\":71152,\"start\":71151}]", "bib_author_last_name": "[{\"end\":42784,\"start\":42776},{\"end\":42797,\"start\":42793},{\"end\":43256,\"start\":43242},{\"end\":43279,\"start\":43265},{\"end\":43306,\"start\":43288},{\"end\":43613,\"start\":43607},{\"end\":43629,\"start\":43619},{\"end\":43646,\"start\":43637},{\"end\":43866,\"start\":43857},{\"end\":43882,\"start\":43874},{\"end\":44236,\"start\":44228},{\"end\":44254,\"start\":44249},{\"end\":44274,\"start\":44263},{\"end\":44291,\"start\":44285},{\"end\":44303,\"start\":44298},{\"end\":44318,\"start\":44313},{\"end\":44330,\"start\":44322},{\"end\":44345,\"start\":44339},{\"end\":44358,\"start\":44351},{\"end\":44373,\"start\":44367},{\"end\":44380,\"start\":44375},{\"end\":44749,\"start\":44742},{\"end\":44765,\"start\":44758},{\"end\":44783,\"start\":44775},{\"end\":44792,\"start\":44785},{\"end\":45095,\"start\":45088},{\"end\":45110,\"start\":45103},{\"end\":45126,\"start\":45119},{\"end\":45144,\"start\":45136},{\"end\":45153,\"start\":45146},{\"end\":45490,\"start\":45484},{\"end\":45507,\"start\":45499},{\"end\":45525,\"start\":45518},{\"end\":45863,\"start\":45851},{\"end\":45875,\"start\":45865},{\"end\":45885,\"start\":45879},{\"end\":45902,\"start\":45894},{\"end\":45913,\"start\":45909},{\"end\":45926,\"start\":45915},{\"end\":46427,\"start\":46422},{\"end\":46451,\"start\":46438},{\"end\":46463,\"start\":46458},{\"end\":46485,\"start\":46476},{\"end\":46501,\"start\":46495},{\"end\":46510,\"start\":46503},{\"end\":46829,\"start\":46823},{\"end\":46848,\"start\":46841},{\"end\":46858,\"start\":46850},{\"end\":47214,\"start\":47210},{\"end\":47222,\"start\":47219},{\"end\":47239,\"start\":47229},{\"end\":47690,\"start\":47686},{\"end\":47698,\"start\":47695},{\"end\":47715,\"start\":47705},{\"end\":48154,\"start\":48144},{\"end\":48166,\"start\":48160},{\"end\":48180,\"start\":48172},{\"end\":48197,\"start\":48186},{\"end\":48212,\"start\":48204},{\"end\":48225,\"start\":48221},{\"end\":48236,\"start\":48227},{\"end\":48536,\"start\":48528},{\"end\":48551,\"start\":48545},{\"end\":48570,\"start\":48560},{\"end\":48863,\"start\":48860},{\"end\":48882,\"start\":48872},{\"end\":49227,\"start\":49214},{\"end\":49249,\"start\":49236},{\"end\":49263,\"start\":49258},{\"end\":49288,\"start\":49272},{\"end\":49311,\"start\":49295},{\"end\":49686,\"start\":49679},{\"end\":49696,\"start\":49690},{\"end\":49703,\"start\":49698},{\"end\":49711,\"start\":49707},{\"end\":49724,\"start\":49719},{\"end\":49736,\"start\":49731},{\"end\":49755,\"start\":49746},{\"end\":49764,\"start\":49757},{\"end\":50250,\"start\":50248},{\"end\":50264,\"start\":50260},{\"end\":50276,\"start\":50272},{\"end\":50289,\"start\":50287},{\"end\":50305,\"start\":50296},{\"end\":50317,\"start\":50312},{\"end\":50327,\"start\":50324},{\"end\":50342,\"start\":50338},{\"end\":50353,\"start\":50349},{\"end\":50366,\"start\":50363},{\"end\":50673,\"start\":50670},{\"end\":50687,\"start\":50681},{\"end\":50695,\"start\":50692},{\"end\":50716,\"start\":50706},{\"end\":51142,\"start\":51136},{\"end\":51157,\"start\":51150},{\"end\":51450,\"start\":51444},{\"end\":51461,\"start\":51457},{\"end\":51481,\"start\":51469},{\"end\":51496,\"start\":51491},{\"end\":51513,\"start\":51504},{\"end\":51528,\"start\":51522},{\"end\":51539,\"start\":51536},{\"end\":51559,\"start\":51553},{\"end\":51576,\"start\":51566},{\"end\":51909,\"start\":51907},{\"end\":51924,\"start\":51919},{\"end\":51938,\"start\":51935},{\"end\":51948,\"start\":51945},{\"end\":52406,\"start\":52402},{\"end\":52426,\"start\":52417},{\"end\":52439,\"start\":52433},{\"end\":52455,\"start\":52448},{\"end\":52475,\"start\":52467},{\"end\":52484,\"start\":52477},{\"end\":52737,\"start\":52731},{\"end\":52752,\"start\":52745},{\"end\":52763,\"start\":52759},{\"end\":53056,\"start\":53048},{\"end\":53064,\"start\":53060},{\"end\":53073,\"start\":53066},{\"end\":53287,\"start\":53282},{\"end\":53303,\"start\":53295},{\"end\":53560,\"start\":53555},{\"end\":53577,\"start\":53569},{\"end\":53592,\"start\":53585},{\"end\":53608,\"start\":53602},{\"end\":53623,\"start\":53617},{\"end\":54186,\"start\":54182},{\"end\":54202,\"start\":54188},{\"end\":54653,\"start\":54651},{\"end\":54666,\"start\":54662},{\"end\":54680,\"start\":54676},{\"end\":54694,\"start\":54691},{\"end\":54709,\"start\":54705},{\"end\":55122,\"start\":55116},{\"end\":55137,\"start\":55128},{\"end\":55462,\"start\":55455},{\"end\":55473,\"start\":55470},{\"end\":55930,\"start\":55922},{\"end\":55944,\"start\":55938},{\"end\":55948,\"start\":55946},{\"end\":56218,\"start\":56214},{\"end\":56240,\"start\":56235},{\"end\":56257,\"start\":56249},{\"end\":56276,\"start\":56265},{\"end\":56286,\"start\":56282},{\"end\":56299,\"start\":56294},{\"end\":56788,\"start\":56784},{\"end\":56803,\"start\":56790},{\"end\":56816,\"start\":56811},{\"end\":56823,\"start\":56818},{\"end\":57176,\"start\":57171},{\"end\":57193,\"start\":57185},{\"end\":57206,\"start\":57202},{\"end\":57574,\"start\":57558},{\"end\":57593,\"start\":57586},{\"end\":57611,\"start\":57603},{\"end\":57927,\"start\":57911},{\"end\":57946,\"start\":57939},{\"end\":57964,\"start\":57956},{\"end\":58286,\"start\":58278},{\"end\":58298,\"start\":58293},{\"end\":58315,\"start\":58309},{\"end\":58336,\"start\":58326},{\"end\":58563,\"start\":58560},{\"end\":58582,\"start\":58573},{\"end\":58594,\"start\":58592},{\"end\":59038,\"start\":59036},{\"end\":59062,\"start\":59053},{\"end\":59075,\"start\":59068},{\"end\":59503,\"start\":59500},{\"end\":59518,\"start\":59513},{\"end\":59534,\"start\":59526},{\"end\":59546,\"start\":59542},{\"end\":59561,\"start\":59555},{\"end\":59575,\"start\":59568},{\"end\":59589,\"start\":59583},{\"end\":59609,\"start\":59602},{\"end\":59979,\"start\":59975},{\"end\":59995,\"start\":59986},{\"end\":60011,\"start\":60004},{\"end\":60452,\"start\":60446},{\"end\":60466,\"start\":60460},{\"end\":60482,\"start\":60474},{\"end\":60491,\"start\":60484},{\"end\":60501,\"start\":60495},{\"end\":60523,\"start\":60517},{\"end\":60531,\"start\":60525},{\"end\":60958,\"start\":60953},{\"end\":60973,\"start\":60969},{\"end\":60982,\"start\":60975},{\"end\":61264,\"start\":61257},{\"end\":61281,\"start\":61274},{\"end\":61295,\"start\":61290},{\"end\":61592,\"start\":61584},{\"end\":61603,\"start\":61596},{\"end\":61614,\"start\":61609},{\"end\":61631,\"start\":61624},{\"end\":61651,\"start\":61640},{\"end\":61663,\"start\":61658},{\"end\":62029,\"start\":62023},{\"end\":62050,\"start\":62041},{\"end\":62068,\"start\":62059},{\"end\":62085,\"start\":62078},{\"end\":62105,\"start\":62096},{\"end\":62443,\"start\":62438},{\"end\":62452,\"start\":62447},{\"end\":62465,\"start\":62461},{\"end\":62471,\"start\":62467},{\"end\":62480,\"start\":62475},{\"end\":62496,\"start\":62489},{\"end\":62514,\"start\":62508},{\"end\":62524,\"start\":62516},{\"end\":62891,\"start\":62886},{\"end\":62909,\"start\":62893},{\"end\":62918,\"start\":62913},{\"end\":62932,\"start\":62926},{\"end\":62951,\"start\":62944},{\"end\":62959,\"start\":62953},{\"end\":62968,\"start\":62963},{\"end\":62983,\"start\":62977},{\"end\":62998,\"start\":62995},{\"end\":63008,\"start\":63000},{\"end\":63386,\"start\":63372},{\"end\":63407,\"start\":63402},{\"end\":63420,\"start\":63416},{\"end\":63435,\"start\":63430},{\"end\":63452,\"start\":63447},{\"end\":63728,\"start\":63721},{\"end\":63745,\"start\":63737},{\"end\":63761,\"start\":63755},{\"end\":63778,\"start\":63770},{\"end\":63790,\"start\":63784},{\"end\":63805,\"start\":63801},{\"end\":63814,\"start\":63807},{\"end\":64210,\"start\":64205},{\"end\":64227,\"start\":64221},{\"end\":64236,\"start\":64229},{\"end\":64632,\"start\":64611},{\"end\":64646,\"start\":64640},{\"end\":64658,\"start\":64648},{\"end\":65041,\"start\":65020},{\"end\":65049,\"start\":65043},{\"end\":65417,\"start\":65408},{\"end\":65426,\"start\":65421},{\"end\":65440,\"start\":65433},{\"end\":65824,\"start\":65819},{\"end\":65841,\"start\":65831},{\"end\":65857,\"start\":65852},{\"end\":65873,\"start\":65867},{\"end\":65886,\"start\":65882},{\"end\":66208,\"start\":66203},{\"end\":66531,\"start\":66525},{\"end\":66548,\"start\":66542},{\"end\":66564,\"start\":66559},{\"end\":66577,\"start\":66572},{\"end\":66594,\"start\":66587},{\"end\":66929,\"start\":66921},{\"end\":66937,\"start\":66933},{\"end\":66952,\"start\":66946},{\"end\":66959,\"start\":66954},{\"end\":66970,\"start\":66965},{\"end\":66976,\"start\":66972},{\"end\":66986,\"start\":66980},{\"end\":67001,\"start\":66996},{\"end\":67009,\"start\":67003},{\"end\":67378,\"start\":67364},{\"end\":67398,\"start\":67385},{\"end\":67417,\"start\":67406},{\"end\":67432,\"start\":67426},{\"end\":67441,\"start\":67434},{\"end\":67785,\"start\":67780},{\"end\":67803,\"start\":67795},{\"end\":67817,\"start\":67812},{\"end\":67838,\"start\":67829},{\"end\":67860,\"start\":67848},{\"end\":67881,\"start\":67874},{\"end\":67897,\"start\":67893},{\"end\":67907,\"start\":67899},{\"end\":67917,\"start\":67911},{\"end\":67934,\"start\":67928},{\"end\":67940,\"start\":67936},{\"end\":68303,\"start\":68299},{\"end\":68320,\"start\":68313},{\"end\":68337,\"start\":68327},{\"end\":68355,\"start\":68346},{\"end\":68375,\"start\":68366},{\"end\":68779,\"start\":68775},{\"end\":68787,\"start\":68783},{\"end\":68792,\"start\":68789},{\"end\":68805,\"start\":68796},{\"end\":68817,\"start\":68814},{\"end\":68831,\"start\":68826},{\"end\":68846,\"start\":68840},{\"end\":68858,\"start\":68848},{\"end\":69240,\"start\":69234},{\"end\":69259,\"start\":69249},{\"end\":69276,\"start\":69269},{\"end\":69673,\"start\":69670},{\"end\":69688,\"start\":69684},{\"end\":69702,\"start\":69698},{\"end\":69711,\"start\":69706},{\"end\":69724,\"start\":69720},{\"end\":69736,\"start\":69726},{\"end\":70249,\"start\":70241},{\"end\":70264,\"start\":70259},{\"end\":70550,\"start\":70542},{\"end\":70565,\"start\":70560},{\"end\":71131,\"start\":71126},{\"end\":71149,\"start\":71140},{\"end\":71156,\"start\":71153}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":204805743},\"end\":43145,\"start\":42669},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":10998222},\"end\":43583,\"start\":43147},{\"attributes\":{\"id\":\"b2\"},\"end\":43757,\"start\":43585},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":45174121},\"end\":44175,\"start\":43759},{\"attributes\":{\"doi\":\"arXiv:1604.07316\",\"id\":\"b4\"},\"end\":44663,\"start\":44177},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":10759568},\"end\":45013,\"start\":44665},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":13813737},\"end\":45428,\"start\":45015},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":4396518},\"end\":45770,\"start\":45430},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":2164893},\"end\":46311,\"start\":45772},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":14246679},\"end\":46773,\"start\":46313},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":109884250},\"end\":47125,\"start\":46775},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":126148497},\"end\":47591,\"start\":47127},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":207869924},\"end\":48034,\"start\":47593},{\"attributes\":{\"id\":\"b13\"},\"end\":48481,\"start\":48036},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":46701966},\"end\":48766,\"start\":48483},{\"attributes\":{\"doi\":\"PMLR\",\"id\":\"b15\",\"matched_paper_id\":160705},\"end\":49133,\"start\":48768},{\"attributes\":{\"doi\":\"arXiv:1704.06857\",\"id\":\"b16\"},\"end\":49569,\"start\":49135},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":5923742},\"end\":50187,\"start\":49571},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":3879949},\"end\":50620,\"start\":50189},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":28671436},\"end\":51099,\"start\":50622},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":993561},\"end\":51381,\"start\":51101},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":247457},\"end\":51851,\"start\":51383},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":206594692},\"end\":52305,\"start\":51853},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":207165453},\"end\":52720,\"start\":52307},{\"attributes\":{\"doi\":\"arXiv:1503.02531\",\"id\":\"b24\"},\"end\":52976,\"start\":52722},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":3644401},\"end\":53256,\"start\":52978},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":13434324},\"end\":53457,\"start\":53258},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":206597918},\"end\":54085,\"start\":53459},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":162169353},\"end\":54517,\"start\":54087},{\"attributes\":{\"doi\":\"arXiv:1908.11528\",\"id\":\"b29\"},\"end\":54985,\"start\":54519},{\"attributes\":{\"doi\":\"arXiv:2004.06569\",\"id\":\"b30\"},\"end\":55370,\"start\":54987},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":71134},\"end\":55874,\"start\":55372},{\"attributes\":{\"doi\":\"arXiv:1412.6980\",\"id\":\"b32\"},\"end\":56097,\"start\":55876},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":202773833},\"end\":56667,\"start\":56099},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":85546658},\"end\":57082,\"start\":56669},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":49314079},\"end\":57473,\"start\":57084},{\"attributes\":{\"doi\":\"arXiv:1612.01474\",\"id\":\"b36\"},\"end\":57826,\"start\":57475},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":6294674},\"end\":58241,\"start\":57828},{\"attributes\":{\"doi\":\"PMLR\",\"id\":\"b38\",\"matched_paper_id\":30288801},\"end\":58550,\"start\":58243},{\"attributes\":{\"id\":\"b39\"},\"end\":58935,\"start\":58552},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":198893663},\"end\":59446,\"start\":58937},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":14113767},\"end\":59908,\"start\":59448},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":1629541},\"end\":60381,\"start\":59910},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":59608823},\"end\":60820,\"start\":60383},{\"attributes\":{\"id\":\"b44\"},\"end\":61168,\"start\":60822},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":201666124},\"end\":61476,\"start\":61170},{\"attributes\":{\"doi\":\"arXiv:1911.13273\",\"id\":\"b46\"},\"end\":61933,\"start\":61478},{\"attributes\":{\"doi\":\"arXiv:1805.10915\",\"id\":\"b47\"},\"end\":62362,\"start\":61935},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":32203953},\"end\":62773,\"start\":62364},{\"attributes\":{\"id\":\"b49\"},\"end\":63274,\"start\":62775},{\"attributes\":{\"doi\":\"arXiv:1810.11586\",\"id\":\"b50\"},\"end\":63712,\"start\":63276},{\"attributes\":{\"doi\":\"arXiv:2002.09437\",\"id\":\"b51\"},\"end\":64119,\"start\":63714},{\"attributes\":{\"id\":\"b52\",\"matched_paper_id\":127203550},\"end\":64537,\"start\":64121},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":6292807},\"end\":64924,\"start\":64539},{\"attributes\":{\"id\":\"b54\",\"matched_paper_id\":636054},\"end\":65340,\"start\":64926},{\"attributes\":{\"id\":\"b55\",\"matched_paper_id\":207158152},\"end\":65770,\"start\":65342},{\"attributes\":{\"doi\":\"arXiv:1904.01685\",\"id\":\"b56\"},\"end\":66095,\"start\":65772},{\"attributes\":{\"id\":\"b57\",\"matched_paper_id\":56563878},\"end\":66437,\"start\":66097},{\"attributes\":{\"doi\":\"arXiv:2003.06820\",\"id\":\"b58\"},\"end\":66827,\"start\":66439},{\"attributes\":{\"id\":\"b59\",\"matched_paper_id\":330039},\"end\":67297,\"start\":66829},{\"attributes\":{\"id\":\"b60\",\"matched_paper_id\":14322900},\"end\":67705,\"start\":67299},{\"attributes\":{\"id\":\"b61\",\"matched_paper_id\":16691577},\"end\":68238,\"start\":67707},{\"attributes\":{\"doi\":\"PMLR\",\"id\":\"b62\",\"matched_paper_id\":44154616},\"end\":68715,\"start\":68240},{\"attributes\":{\"id\":\"b63\",\"matched_paper_id\":16295841},\"end\":69176,\"start\":68717},{\"attributes\":{\"doi\":\"PMLR, 2020. 13\",\"id\":\"b64\",\"matched_paper_id\":186206977},\"end\":69566,\"start\":69178},{\"attributes\":{\"id\":\"b65\",\"matched_paper_id\":204027409},\"end\":70137,\"start\":69568},{\"attributes\":{\"id\":\"b66\",\"matched_paper_id\":9594071},\"end\":70454,\"start\":70139},{\"attributes\":{\"id\":\"b67\",\"matched_paper_id\":3349576},\"end\":71025,\"start\":70456},{\"attributes\":{\"doi\":\"arXiv:2003.07329\",\"id\":\"b68\"},\"end\":71390,\"start\":71027}]", "bib_title": "[{\"end\":42764,\"start\":42669},{\"end\":43233,\"start\":43147},{\"end\":43850,\"start\":43759},{\"end\":44738,\"start\":44665},{\"end\":45084,\"start\":45015},{\"end\":45475,\"start\":45430},{\"end\":45843,\"start\":45772},{\"end\":46411,\"start\":46313},{\"end\":46819,\"start\":46775},{\"end\":47200,\"start\":47127},{\"end\":47676,\"start\":47593},{\"end\":48519,\"start\":48483},{\"end\":48852,\"start\":48768},{\"end\":49669,\"start\":49571},{\"end\":50237,\"start\":50189},{\"end\":50662,\"start\":50622},{\"end\":51125,\"start\":51101},{\"end\":51433,\"start\":51383},{\"end\":51897,\"start\":51853},{\"end\":52398,\"start\":52307},{\"end\":53033,\"start\":52978},{\"end\":53275,\"start\":53258},{\"end\":53547,\"start\":53459},{\"end\":54174,\"start\":54087},{\"end\":55448,\"start\":55372},{\"end\":56205,\"start\":56099},{\"end\":56775,\"start\":56669},{\"end\":57162,\"start\":57084},{\"end\":57902,\"start\":57828},{\"end\":58272,\"start\":58243},{\"end\":59029,\"start\":58937},{\"end\":59489,\"start\":59448},{\"end\":59964,\"start\":59910},{\"end\":60442,\"start\":60383},{\"end\":61250,\"start\":61170},{\"end\":62431,\"start\":62364},{\"end\":64201,\"start\":64121},{\"end\":64601,\"start\":64539},{\"end\":65008,\"start\":64926},{\"end\":65396,\"start\":65342},{\"end\":66196,\"start\":66097},{\"end\":66912,\"start\":66829},{\"end\":67362,\"start\":67299},{\"end\":67776,\"start\":67707},{\"end\":68289,\"start\":68240},{\"end\":68765,\"start\":68717},{\"end\":69223,\"start\":69178},{\"end\":69663,\"start\":69568},{\"end\":70232,\"start\":70139},{\"end\":70533,\"start\":70456}]", "bib_author": "[{\"end\":42786,\"start\":42766},{\"end\":42799,\"start\":42786},{\"end\":43258,\"start\":43235},{\"end\":43281,\"start\":43258},{\"end\":43308,\"start\":43281},{\"end\":43615,\"start\":43600},{\"end\":43631,\"start\":43615},{\"end\":43648,\"start\":43631},{\"end\":43868,\"start\":43852},{\"end\":43884,\"start\":43868},{\"end\":44238,\"start\":44220},{\"end\":44256,\"start\":44238},{\"end\":44276,\"start\":44256},{\"end\":44293,\"start\":44276},{\"end\":44305,\"start\":44293},{\"end\":44320,\"start\":44305},{\"end\":44332,\"start\":44320},{\"end\":44347,\"start\":44332},{\"end\":44360,\"start\":44347},{\"end\":44375,\"start\":44360},{\"end\":44382,\"start\":44375},{\"end\":44751,\"start\":44740},{\"end\":44767,\"start\":44751},{\"end\":44785,\"start\":44767},{\"end\":44794,\"start\":44785},{\"end\":45097,\"start\":45086},{\"end\":45112,\"start\":45097},{\"end\":45128,\"start\":45112},{\"end\":45146,\"start\":45128},{\"end\":45155,\"start\":45146},{\"end\":45492,\"start\":45477},{\"end\":45509,\"start\":45492},{\"end\":45527,\"start\":45509},{\"end\":45865,\"start\":45845},{\"end\":45877,\"start\":45865},{\"end\":45887,\"start\":45877},{\"end\":45904,\"start\":45887},{\"end\":45915,\"start\":45904},{\"end\":45928,\"start\":45915},{\"end\":46429,\"start\":46413},{\"end\":46453,\"start\":46429},{\"end\":46465,\"start\":46453},{\"end\":46487,\"start\":46465},{\"end\":46503,\"start\":46487},{\"end\":46512,\"start\":46503},{\"end\":46831,\"start\":46821},{\"end\":46850,\"start\":46831},{\"end\":46860,\"start\":46850},{\"end\":47216,\"start\":47202},{\"end\":47224,\"start\":47216},{\"end\":47241,\"start\":47224},{\"end\":47692,\"start\":47678},{\"end\":47700,\"start\":47692},{\"end\":47717,\"start\":47700},{\"end\":48156,\"start\":48139},{\"end\":48168,\"start\":48156},{\"end\":48182,\"start\":48168},{\"end\":48199,\"start\":48182},{\"end\":48214,\"start\":48199},{\"end\":48227,\"start\":48214},{\"end\":48238,\"start\":48227},{\"end\":48538,\"start\":48521},{\"end\":48553,\"start\":48538},{\"end\":48572,\"start\":48553},{\"end\":48865,\"start\":48854},{\"end\":48884,\"start\":48865},{\"end\":49229,\"start\":49206},{\"end\":49251,\"start\":49229},{\"end\":49265,\"start\":49251},{\"end\":49290,\"start\":49265},{\"end\":49313,\"start\":49290},{\"end\":49688,\"start\":49671},{\"end\":49698,\"start\":49688},{\"end\":49705,\"start\":49698},{\"end\":49713,\"start\":49705},{\"end\":49726,\"start\":49713},{\"end\":49738,\"start\":49726},{\"end\":49757,\"start\":49738},{\"end\":49766,\"start\":49757},{\"end\":50252,\"start\":50239},{\"end\":50266,\"start\":50252},{\"end\":50278,\"start\":50266},{\"end\":50291,\"start\":50278},{\"end\":50307,\"start\":50291},{\"end\":50319,\"start\":50307},{\"end\":50329,\"start\":50319},{\"end\":50344,\"start\":50329},{\"end\":50355,\"start\":50344},{\"end\":50368,\"start\":50355},{\"end\":50675,\"start\":50664},{\"end\":50689,\"start\":50675},{\"end\":50697,\"start\":50689},{\"end\":50718,\"start\":50697},{\"end\":51144,\"start\":51127},{\"end\":51159,\"start\":51144},{\"end\":51452,\"start\":51435},{\"end\":51463,\"start\":51452},{\"end\":51483,\"start\":51463},{\"end\":51498,\"start\":51483},{\"end\":51515,\"start\":51498},{\"end\":51530,\"start\":51515},{\"end\":51541,\"start\":51530},{\"end\":51561,\"start\":51541},{\"end\":51578,\"start\":51561},{\"end\":51911,\"start\":51899},{\"end\":51926,\"start\":51911},{\"end\":51940,\"start\":51926},{\"end\":51950,\"start\":51940},{\"end\":52408,\"start\":52400},{\"end\":52428,\"start\":52408},{\"end\":52441,\"start\":52428},{\"end\":52457,\"start\":52441},{\"end\":52477,\"start\":52457},{\"end\":52486,\"start\":52477},{\"end\":52739,\"start\":52722},{\"end\":52754,\"start\":52739},{\"end\":52765,\"start\":52754},{\"end\":53058,\"start\":53035},{\"end\":53066,\"start\":53058},{\"end\":53075,\"start\":53066},{\"end\":53289,\"start\":53277},{\"end\":53305,\"start\":53289},{\"end\":53562,\"start\":53549},{\"end\":53579,\"start\":53562},{\"end\":53594,\"start\":53579},{\"end\":53610,\"start\":53594},{\"end\":53625,\"start\":53610},{\"end\":54188,\"start\":54176},{\"end\":54204,\"start\":54188},{\"end\":54655,\"start\":54640},{\"end\":54668,\"start\":54655},{\"end\":54682,\"start\":54668},{\"end\":54696,\"start\":54682},{\"end\":54711,\"start\":54696},{\"end\":55124,\"start\":55109},{\"end\":55139,\"start\":55124},{\"end\":55464,\"start\":55450},{\"end\":55475,\"start\":55464},{\"end\":55932,\"start\":55920},{\"end\":55946,\"start\":55932},{\"end\":55950,\"start\":55946},{\"end\":56220,\"start\":56207},{\"end\":56242,\"start\":56220},{\"end\":56259,\"start\":56242},{\"end\":56278,\"start\":56259},{\"end\":56288,\"start\":56278},{\"end\":56301,\"start\":56288},{\"end\":56790,\"start\":56777},{\"end\":56805,\"start\":56790},{\"end\":56818,\"start\":56805},{\"end\":56825,\"start\":56818},{\"end\":57178,\"start\":57164},{\"end\":57195,\"start\":57178},{\"end\":57208,\"start\":57195},{\"end\":57576,\"start\":57551},{\"end\":57595,\"start\":57576},{\"end\":57613,\"start\":57595},{\"end\":57929,\"start\":57904},{\"end\":57948,\"start\":57929},{\"end\":57966,\"start\":57948},{\"end\":58288,\"start\":58274},{\"end\":58300,\"start\":58288},{\"end\":58317,\"start\":58300},{\"end\":58338,\"start\":58317},{\"end\":58565,\"start\":58552},{\"end\":58584,\"start\":58565},{\"end\":58596,\"start\":58584},{\"end\":59040,\"start\":59031},{\"end\":59064,\"start\":59040},{\"end\":59077,\"start\":59064},{\"end\":59505,\"start\":59491},{\"end\":59520,\"start\":59505},{\"end\":59536,\"start\":59520},{\"end\":59548,\"start\":59536},{\"end\":59563,\"start\":59548},{\"end\":59577,\"start\":59563},{\"end\":59591,\"start\":59577},{\"end\":59611,\"start\":59591},{\"end\":59981,\"start\":59966},{\"end\":59997,\"start\":59981},{\"end\":60013,\"start\":59997},{\"end\":60454,\"start\":60444},{\"end\":60468,\"start\":60454},{\"end\":60484,\"start\":60468},{\"end\":60493,\"start\":60484},{\"end\":60503,\"start\":60493},{\"end\":60525,\"start\":60503},{\"end\":60533,\"start\":60525},{\"end\":60960,\"start\":60951},{\"end\":60975,\"start\":60960},{\"end\":60984,\"start\":60975},{\"end\":61266,\"start\":61252},{\"end\":61283,\"start\":61266},{\"end\":61297,\"start\":61283},{\"end\":61594,\"start\":61576},{\"end\":61605,\"start\":61594},{\"end\":61616,\"start\":61605},{\"end\":61633,\"start\":61616},{\"end\":61653,\"start\":61633},{\"end\":61665,\"start\":61653},{\"end\":62031,\"start\":62013},{\"end\":62052,\"start\":62031},{\"end\":62070,\"start\":62052},{\"end\":62087,\"start\":62070},{\"end\":62107,\"start\":62087},{\"end\":62445,\"start\":62433},{\"end\":62454,\"start\":62445},{\"end\":62467,\"start\":62454},{\"end\":62473,\"start\":62467},{\"end\":62482,\"start\":62473},{\"end\":62498,\"start\":62482},{\"end\":62516,\"start\":62498},{\"end\":62526,\"start\":62516},{\"end\":62893,\"start\":62881},{\"end\":62911,\"start\":62893},{\"end\":62920,\"start\":62911},{\"end\":62934,\"start\":62920},{\"end\":62953,\"start\":62934},{\"end\":62961,\"start\":62953},{\"end\":62970,\"start\":62961},{\"end\":62985,\"start\":62970},{\"end\":63000,\"start\":62985},{\"end\":63010,\"start\":63000},{\"end\":63388,\"start\":63365},{\"end\":63409,\"start\":63388},{\"end\":63422,\"start\":63409},{\"end\":63437,\"start\":63422},{\"end\":63454,\"start\":63437},{\"end\":63730,\"start\":63714},{\"end\":63747,\"start\":63730},{\"end\":63763,\"start\":63747},{\"end\":63780,\"start\":63763},{\"end\":63792,\"start\":63780},{\"end\":63807,\"start\":63792},{\"end\":63816,\"start\":63807},{\"end\":64212,\"start\":64203},{\"end\":64229,\"start\":64212},{\"end\":64238,\"start\":64229},{\"end\":64634,\"start\":64603},{\"end\":64648,\"start\":64634},{\"end\":64660,\"start\":64648},{\"end\":65043,\"start\":65010},{\"end\":65051,\"start\":65043},{\"end\":65419,\"start\":65398},{\"end\":65428,\"start\":65419},{\"end\":65442,\"start\":65428},{\"end\":65826,\"start\":65812},{\"end\":65843,\"start\":65826},{\"end\":65859,\"start\":65843},{\"end\":65875,\"start\":65859},{\"end\":65888,\"start\":65875},{\"end\":66210,\"start\":66198},{\"end\":66533,\"start\":66520},{\"end\":66550,\"start\":66533},{\"end\":66566,\"start\":66550},{\"end\":66579,\"start\":66566},{\"end\":66596,\"start\":66579},{\"end\":66931,\"start\":66914},{\"end\":66939,\"start\":66931},{\"end\":66954,\"start\":66939},{\"end\":66961,\"start\":66954},{\"end\":66972,\"start\":66961},{\"end\":66978,\"start\":66972},{\"end\":66988,\"start\":66978},{\"end\":67003,\"start\":66988},{\"end\":67011,\"start\":67003},{\"end\":67380,\"start\":67364},{\"end\":67400,\"start\":67380},{\"end\":67419,\"start\":67400},{\"end\":67434,\"start\":67419},{\"end\":67443,\"start\":67434},{\"end\":67787,\"start\":67778},{\"end\":67805,\"start\":67787},{\"end\":67819,\"start\":67805},{\"end\":67840,\"start\":67819},{\"end\":67862,\"start\":67840},{\"end\":67883,\"start\":67862},{\"end\":67899,\"start\":67883},{\"end\":67909,\"start\":67899},{\"end\":67919,\"start\":67909},{\"end\":67936,\"start\":67919},{\"end\":67942,\"start\":67936},{\"end\":68305,\"start\":68291},{\"end\":68322,\"start\":68305},{\"end\":68339,\"start\":68322},{\"end\":68357,\"start\":68339},{\"end\":68377,\"start\":68357},{\"end\":68781,\"start\":68767},{\"end\":68789,\"start\":68781},{\"end\":68794,\"start\":68789},{\"end\":68807,\"start\":68794},{\"end\":68819,\"start\":68807},{\"end\":68833,\"start\":68819},{\"end\":68848,\"start\":68833},{\"end\":68860,\"start\":68848},{\"end\":69242,\"start\":69225},{\"end\":69261,\"start\":69242},{\"end\":69278,\"start\":69261},{\"end\":69675,\"start\":69665},{\"end\":69690,\"start\":69675},{\"end\":69704,\"start\":69690},{\"end\":69713,\"start\":69704},{\"end\":69726,\"start\":69713},{\"end\":69738,\"start\":69726},{\"end\":70251,\"start\":70234},{\"end\":70266,\"start\":70251},{\"end\":70552,\"start\":70535},{\"end\":70567,\"start\":70552},{\"end\":71133,\"start\":71121},{\"end\":71151,\"start\":71133},{\"end\":71158,\"start\":71151}]", "bib_venue": "[{\"end\":48611,\"start\":48603},{\"end\":50841,\"start\":50788},{\"end\":52091,\"start\":52029},{\"end\":53786,\"start\":53714},{\"end\":55640,\"start\":55566},{\"end\":60154,\"start\":60092},{\"end\":65565,\"start\":65512},{\"end\":70754,\"start\":70669},{\"end\":42881,\"start\":42799},{\"end\":43344,\"start\":43308},{\"end\":43598,\"start\":43585},{\"end\":43951,\"start\":43884},{\"end\":44218,\"start\":44177},{\"end\":44821,\"start\":44794},{\"end\":45193,\"start\":45155},{\"end\":45573,\"start\":45527},{\"end\":46014,\"start\":45928},{\"end\":46522,\"start\":46512},{\"end\":46929,\"start\":46860},{\"end\":47327,\"start\":47241},{\"end\":47784,\"start\":47717},{\"end\":48137,\"start\":48036},{\"end\":48601,\"start\":48572},{\"end\":48932,\"start\":48888},{\"end\":49204,\"start\":49135},{\"end\":49852,\"start\":49766},{\"end\":50387,\"start\":50368},{\"end\":50786,\"start\":50718},{\"end\":51221,\"start\":51159},{\"end\":51600,\"start\":51578},{\"end\":52027,\"start\":51950},{\"end\":52496,\"start\":52486},{\"end\":52825,\"start\":52781},{\"end\":53097,\"start\":53075},{\"end\":53341,\"start\":53305},{\"end\":53712,\"start\":53625},{\"end\":54273,\"start\":54204},{\"end\":54638,\"start\":54519},{\"end\":55107,\"start\":54987},{\"end\":55564,\"start\":55475},{\"end\":55918,\"start\":55876},{\"end\":56350,\"start\":56301},{\"end\":56857,\"start\":56825},{\"end\":57252,\"start\":57208},{\"end\":57549,\"start\":57475},{\"end\":58015,\"start\":57966},{\"end\":58378,\"start\":58342},{\"end\":58722,\"start\":58596},{\"end\":59163,\"start\":59077},{\"end\":59649,\"start\":59611},{\"end\":60090,\"start\":60013},{\"end\":60582,\"start\":60533},{\"end\":60949,\"start\":60822},{\"end\":61311,\"start\":61297},{\"end\":61574,\"start\":61478},{\"end\":62011,\"start\":61935},{\"end\":62552,\"start\":62526},{\"end\":62879,\"start\":62775},{\"end\":63363,\"start\":63276},{\"end\":63881,\"start\":63832},{\"end\":64309,\"start\":64238},{\"end\":64715,\"start\":64660},{\"end\":65112,\"start\":65051},{\"end\":65510,\"start\":65442},{\"end\":65810,\"start\":65772},{\"end\":66246,\"start\":66210},{\"end\":66518,\"start\":66439},{\"end\":67047,\"start\":67011},{\"end\":67479,\"start\":67443},{\"end\":67952,\"start\":67942},{\"end\":68456,\"start\":68381},{\"end\":68922,\"start\":68860},{\"end\":69358,\"start\":69292},{\"end\":69824,\"start\":69738},{\"end\":70270,\"start\":70266},{\"end\":70667,\"start\":70567},{\"end\":71119,\"start\":71027}]"}}}, "year": 2023, "month": 12, "day": 17}