{"id": 198953410, "updated": "2023-10-07 00:10:58.684", "metadata": {"title": "Analog forecasting of extreme-causing weather patterns using deep learning", "authors": "[{\"first\":\"Ashesh\",\"last\":\"Chattopadhyay\",\"middle\":[]},{\"first\":\"Ebrahim\",\"last\":\"Nabizadeh\",\"middle\":[]},{\"first\":\"Pedram\",\"last\":\"Hassanzadeh\",\"middle\":[]}]", "venue": "ArXiv", "journal": "ArXiv", "publication_date": {"year": 2019, "month": null, "day": null}, "abstract": "Numerical weather prediction (NWP) models require ever-growing computing time/resources, but still, have difficulties with predicting weather extremes. Here we introduce a data-driven framework that is based on analog forecasting (prediction using past similar patterns) and employs a novel deep learning pattern-recognition technique (capsule neural networks, CapsNets) and impact-based auto-labeling strategy. CapsNets are trained on mid-tropospheric large-scale circulation patterns (Z500) labeled $0-4$ depending on the existence and geographical region of surface temperature extremes over North America several days ahead. The trained networks predict the occurrence/region of cold or heat waves, only using Z500, with accuracies (recalls) of $69\\%-45\\%$ $(77\\%-48\\%)$ or $62\\%-41\\%$ $(73\\%-47\\%)$ $1-5$ days ahead. CapsNets outperform simpler techniques such as convolutional neural networks and logistic regression. Using both temperature and Z500, accuracies (recalls) with CapsNets increase to $\\sim 80\\%$ $(88\\%)$, showing the promises of multi-modal data-driven frameworks for accurate/fast extreme weather predictions, which can augment NWP efforts in providing early warnings.", "fields_of_study": "[\"Physics\",\"Computer Science\"]", "external_ids": {"arxiv": "1907.11617", "mag": "3100535421", "acl": null, "pubmed": "32714491", "pubmedcentral": "7375135", "dblp": "journals/corr/abs-1907-11617", "doi": "10.1029/2019ms001958"}}, "content": {"source": {"pdf_hash": "141b9a4a529d017d38e7fe355192705828011156", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/1907.11617v2.pdf\"]", "oa_url_match": false, "oa_info": {"license": "CCBY", "open_access_url": "https://agupubs.onlinelibrary.wiley.com/doi/pdfdirect/10.1029/2019MS001958", "status": "GOLD"}}, "grobid": {"id": "e54d965257d3874b664eb91f6d897d1c5e0c5fe0", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/141b9a4a529d017d38e7fe355192705828011156.txt", "contents": "\nAnalog forecasting of extreme-causing weather patterns using deep learning\nJanuary 14, 2020\n\nAshesh Chattopadhyay \nDepartment of Mechanical Engineering\nRice University\n\n\nEbrahim Nabizadeh \nDepartment of Mechanical Engineering\nRice University\n\n\nPedram Hassanzadeh \nDepartment of Mechanical Engineering\nRice University\n\n\nDepartment of Earth, Environmental and Planetary Sciences\nRice University\n\n\nAnalog forecasting of extreme-causing weather patterns using deep learning\nJanuary 14, 2020\nNumerical weather prediction (NWP) models require ever-growing computing time and resources, but still, have sometimes difficulties with predicting weather extremes. We introduce a data-driven framework that is based on analog forecasting (prediction using past similar patterns), and employs a novel deep learning pattern-recognition technique (capsule neural networks, CapsNets) and an impact-based auto-labeling strategy. Using data from a large-ensemble fully coupled Earth system model, CapsNets are trained on mid-tropospheric large-scale circulation patterns (Z500) labeled 0 \u2212 4 depending on the existence and geographical region of surface temperature extremes over North America several days ahead. The trained networks predict the occurrence/region of cold or heat waves, only using Z500, with accuracies (recalls) of 69% \u2212 45% (77% \u2212 48%) or 62% \u2212 41% (73% \u2212 47%) 1 \u2212 5 days ahead. Using both surface temperature and Z500, accuracies (recalls) with CapsNets increase to \u223c 80% (88%). In both cases, CapsNets outperform simpler techniques such as convolutional neural networks and logistic regression, and their accuracy is least affected as the size of the training set is reduced. The results show the promises of multi-variate data-driven frameworks for accurate and fast extreme weather predictions, which can potentially augment NWP efforts in providing early warnings.\n\nIntroduction\n\nPredicting extreme weather events such as heat waves and cold spells is of significant scientific and societal importance. However, despite decades of progress in weather prediction, mostly through improving computationally-demanding numerical weather prediction (NWP) models and data-assimilation techniques [1,2], forecasting the anomalous atmospheric circulation patterns that often drive these extreme events has remained a challenge. For example, blocking events, which are large-scale, persistent, high-pressure systems that block/divert the usual eastward winds [3], have caused some of the most devastating natural disasters in recent times such as the 2003 and 2010 heat waves in Europe [4,3]. Yet, the state-of-the-art NWP models have difficulties with accurately predicting the formation and persistence of blocking events [5,6,7]. Overall, the key characteristics of extreme-causing weather patterns, their dynamics, and conditions that favor their formation (i.e., precursors) are not well understood [3,8,9,10,11,12,13,14,15].\n\nRecent advances in artificial intelligence have revolutionized how problems in various domains of business and science are approached [16,17]. For example, in climate science, using machine learning techniques to accurately and efficiently represent unresolved physical processes in the atmosphere and ocean has produced promising results [18,19,20,21,22], and has the potential to significantly improve climate modeling and long-term climate projections in the coming years [23,24,25,26]. Moreover, deep learning techniques have been very successful in predicting some types of sequential data [17]. Consequently, whether such techniques can be used for data-driven forecasting of the spatio-temporal evolution of the weather systems (and their extreme events), e.g., after training on high-resolution NWP model outputs or observational data, has become an active area of research. Recent efforts pursuing this approach, which essentially requires a 1 neural network to accurately, for some time, emulate the high-dimensional nonlinear dynamics governing the evolution of the turbulent atmospheric circulation, have shown the promises and challenges of this approach [27,28,29,30,31,26].\n\nIn the current study, for data-driven prediction of extreme-causing weather patterns, we introduce an alternative framework that is based on analog forecasting, i.e., making prediction by finding similar pattern(s), or analog(s), in the past [32,33]. In the historical context, before the advent of powerful electronic computers and stable numerical schemes for integrating the partial differential equations of the NWP models, analog forecasting was a key tool in weather prediction; e.g., it was used in the planning of the D-Day for the 1944 Normandy invasion [34]. Analog forecasting was used less frequently in later decades, due to the challenges in finding useful analogs and the rapid growth of NWP [33], although the approach has the potential for a comeback given the rapid increase in data and emergence of new auxiliary methods [34,35].\n\nHere, we build our data-driven framework on analog forecasting because the patterns of the circulation, e.g., the relative positions of high-and low-pressure systems, play a key role in the spatio-temporal evolution of the circulation and the initiation of extreme events at the surface, and analog forecasting essentially casts weather prediction as a complex pattern-recognition problem, an area that has been truly revolutionized by deep learning in recent years [16,17]. Rather than looking for one perfect analog or a combination of near-perfect analogs that are identified for example based on pattern correlation or Euclidean distance in the grid space, as pursued in traditional analog forecasting [36,33], our framework employs deep learning techniques to classify the patterns based on their key, likely a low-dimensional, set of features and decipher the complex relationship between this feature space (at the altitude of \u223c 5km) and the extreme events (at the surface) among all training samples. The purpose of this paper is to provide a proof-of-concept for this framework.\n\nThe structure of the paper is as follows. In Section 2.1, the data and definitions of extreme events and their onsets are presented. In Section 3, the data-driven extreme weather prediction framework, including the labeling, training, and testing procedures, are discussed. Results are presented in Section 4 followed by Discussion in Section 5.\n\n\nData\n\n\nLENS Data\n\nWe use daily data from the Large-Ensemble (LENS) Community Project [37], which consists of a 40-member ensemble of fully-coupled atmosphere-ocean-land-ice Community Earth System Model version 1 (CESM1) simulations with 1920 \u2212 2005 historical radiative forcing. For each ensemble member, the same historical radiative forcing is used, but random, weak perturbations are added to the initial state of each member to create an ensemble. To ensure abundant training samples for the purpose of demonstrating a proof-ofconcept for the framework, we choose to use data from a large-ensemble climate model, rather than reanalysis data (see Discussion). Still, the simulated atmospheric circulation is non-stationary, turbulent, and multiscale, with complexities similar to those of the real atmosphere, thus providing a challenging testbed for our data-driven extreme weather prediction framework.\n\nFrom this dataset, we use surface air temperature, measured as temperature at 2m above ground (T2m), and geopotential height at 500mb (Z500). We use the daily-averaged T2m and Z500 from 1920-2005 for the months of June-August (boreal summer) and December-February (boreal winter) from all 40 ensemble members.\n\n\nExtreme hot and cold events and their onsets\n\nWe focus on extreme temperature events over the North American continent in the subtropical and midlatitude regions between 30 o N and 60 o N. For a given calendar date in a given ensemble member, the T2m anomalies are computed by removing the climatological mean, defined as the 15-day running mean of T2m centered around that date and averaged over all ensemble members. Following Chan et al. [38], heat waves (cold spells) are defined as land grid points over North America in summer (winter) with daily T2m anomaly in the 99 (1) percentile and larger (smaller) than 3K (\u22121K) for a sequence of at least 5 consecutive days. We then identify the onsets of these extreme temperature events as the first day of each sequence.\n\nUnlike data commonly used in deep learning applications, climate data have spatio-temporal correlations, which can affect the training process (e.g., by reducing the effective sample size) and/or can lead to artificially high accuracies during testing (e.g., if the training and testing sets have strongly correlated samples). Here we aim to choose distinct samples of onsets with minimal correlations within and across the training and testing sets. In constructing the dataset onsets to be used for training/testing, we follow these criteria: We include an onset if there is no other extreme events within the earlier 5 days and if it is not followed by another extreme event within the next 10 days (i.e., maximum of one onset in each 16-day window over North America). This procedure substantially removes potentially (temporally) correlated Z500 patterns corresponding to persistent heat waves/cold spells that may artificially enhance prediction skills. We have experimented with the size of this window ranging from 16 \u2212 24 and found no noticeable changes in the reported accuracies. For non-extreme events, we ensure that their T2m anomaly is not in the 99 (1) percentile and that they are not chosen from the events in the 16-day windows defined above.\n\nAs discussed later, we randomly divide the samples in this dataset of onsets (generated using all 40 ensemble members) to a training set and a testing set. To absolutely ensure that the reported accuracies are not contaminated by any temporal correlation between the samples in the training and testing sets (even after the procedure described above), we conduct another analysis in which data from 30 ensemble members are used in the training set and data from the 10 remaining ensemble members are used in the testing set (thus, absolutely no temporal correlation between the training and testing samples). The analysis demonstrates the same accuracies as those reported in the paper.\n\n\nGeographical clustering of the extreme events' onsets\n\nWe cluster the onsets of extreme events into four distinct yet cohesive geographical regions, separately for winters and for summers. Following Viguad et al. [39], an empirical orthogonal function analysis is first performed on the T2m patterns on the onset days and the first 22 principal components (PCs), which explain over 90% of the variance, are retained. The K-means algorithm [40] is then used on the retained PCs and repeated 1000 times with new initial cluster centroid positions, and a cluster index 1, 2, 3 or 4 is assigned to each day. Rows 1 and 3 of Figure 1 show the cluster centers (in terms of T2m).\n\nThe aim of our data-driven framework is to predict whether in a few days, a Z500 pattern would lead to no extreme event (assigned cluster 0) or an extreme event in the geographical regions corresponding to clusters 1 \u2212 4. Note that here we focused on four clusters to have a balance between too many clusters that may not be distinct, or too few that would not effectively separate the geographical regions, and demonstrate the effectiveness of the proposed data-driven extreme weather event prediction framework. Also, here we use Kmeans, a simple unsupervised algorithm, but other methods such as hierarchical clustering or self-organizing maps [11,41,42] could be used instead.\n\n\nMethodology\n\n\nDeep Learning Techniques: ConvNet and CapsNet\n\nWe use two state-of-the-art deep learning techniques for pattern recognition: Convolutional neural network (ConvNet or CNN) [16,17] and a more advanced method, capsule neural network (CapsNet) [43]. The key advantage of both methods over traditional image-processing techniques is that the filters used for feature extraction are learned for each dataset through an algorithm called backpropagation [17], rather than being hand-engineered and specified beforehand. ConvNet is the groundbreaking method that has transformed image processing since 2011, but because of a property called equivariance that is discussed later, CapsNet is expected to work even better for our spatio-temporal climate data. Figure 2 shows the architecture of the CapsNet schematically. Details of the ConvNet and CapsNet architectures are presented in A and B, respectively.\n\n3.2 Impact-based auto-labeling of daily Z500 patterns Both ConvNet and CapsNet are supervised methods, meaning that they have to be first trained on labeled patterns. However, given the incomplete understanding of extreme-causing weather patterns and their . S0 (W0) shows the average of T2m and Z500 patterns from days with no heat wave (cold spell). S1-S4 and W1-W4 are obtained from K-means clustering the anomalous T2m patterns at onsets into four classes, which roughly separates the extreme events into four geographical regions: Northern Canada (S1), Western US-Canada (S2), Southern US (S3), and Eastern US-Canada (S4) in summers, and North-West US-Canada (W1), Alaska (W2), North-East US-Canada (W3), and Northern Canada (W4) in winters. Rows 1 and 3 show the cluster centers while rows 2 and 4 show the average of Z500 patterns 3 days before the onsets for each cluster.\n\ncomplexities, expert-labeled data are not useful for our objective. For example, indices designed to find blocking patterns in the Z500 field based on their presumed properties are known to perform poorly, e.g., in identifying extreme-causing patterns even on the same day as the heat or cold extreme events [38]. Expertlabeling becomes even less effective for the purpose of prediction, which requires accounting for the nonlinear spatio-temporal evolution of the atmospheric circulation over several days or longer.\n\nTo overcome this challenge, here we devise an impact-based auto-labeling strategy: Knowing the surface temperature over North America on a given day, the Z500 pattern of several days earlier is labeled as 0 (no extreme onset) or 1, 2, 3 or 4 (the cluster indices of T2m extremes). For example, for predicting heat waves in summers with a lead time of 3 days, the Z500 patterns 3 days before the onsets are labeled S0-S4 based on the cluster index of the T2m at the onsets. Rows 2 and 4 of Figure 1 show the average of Z500 patterns with the same labels for 3-day prediction. For the Z500 patterns, we use two domains with the same latitudinal\n(30 \u2022 N-90 \u2022 N) but different longitudinal extends: 195 \u2022 E-315 \u2022 E (small domain, shown in Figures 2-1) and 145 \u2022 E-340 \u2022 E (large domain).\nFor winters, at prediction lead time beyond 2 days, we have found higher accuracy and recall with the large domain, which is likely due to the dominance of zonal advection and Rossby wave propagation in the evolution of weather patterns. For summers, we have found higher accuracy with the small domain for all prediction lead times. The results in Figures 3-6 are with large (small) domain for winters (summers).\n\nWe highlight that in conventional deep learning applications, labeling and training/testing are all conducted on the same feature map; however, in the impact-based labeling strategy introduced here, we label based on differences in one feature map (T2m) but train/test on another feature map (Z500), in order to predict the original feature map (T2m). While more challenging, the impact-based auto-labeling strategy circumvents the need for a full understanding of the complex and nonlinear relationship between the predictor (Z500) and the impact of interest (T2m). 4 \n\n\nTraining and testing datasets\n\nFor each season and prediction lead time, we build a dataset of M labeled Z500 patterns per cluster. While the number of onsets vary among the clusters and there are many more non-extreme events than extreme events, to avoid class imbalance, we choose M near the smallest number of onsets among the four clusters of extreme events. For both summer and winter, we use M = 1000 for prediction lead times of 1 and 2 days, and M = 900 for longer lead times. For each pair of training and testing sets, we randomly choose N = 3M/4 samples per cluster for the training set and the remaining M/4 samples for the testing set. Note that the total number of samples in the training and testing sets (\u223c 4500 \u2212 5000) is much lower than the total number of summer or winter days (316480 and 306000, respectively) in the LENS dataset, because we are focusing on the rare events (i.e., onsets of extremes in the 99 or 1 percentile). We also report the accuracies with smaller training sets of sizes 3N/4, N/2, and N/4 samples per cluster in \n\n\nData-driven extreme weather prediction framework\n\nThe schematic of the entire data-driven prediction framework is shown in Figure 2. Separate CapsNets (or ConvNets) are trained and used for different seasons and prediction lead times (referred to as Cases hereafter). For example, Figure 2 shows the framework with CapsNet for prediction of cold spells in winter with a 3-day lead time. During the training phase, the same number of Z500 patterns (N per cluster) and their cluster indices from the training set are inputted into the CapsNet. The trained CapsNet can then predict the cluster index of a never-seen-before Z500 pattern inputted from the testing set. If the output of CapsNet is index W0, then no cold spell anywhere over North America (between 30 \u2022 N-60 \u2022 N) is forecasted in 3 days, while other outputs indicate prediction of a cold spell in 3 days over North-West US-Canada (W1), Alaska (W2), North-East US-Canada (W3), or Northern Canada (W4).\n\nThe above framework for predicting the extreme-causing weather patterns (just based on information from Z500) is used for the results of Figures 3 and 5. To further demonstrate the potentials of this datadriven framework in predicting the extreme events in a multi-variate approach, we have also shown results in Figures 4 and 6 with an extended framework, in which the inputs consist of the patterns of both Z500 and anomalous T2m stacked together in two different channels. Due to the difference in their mean and variability, standardization is performed on each channel separately.\n\n\nTraining and testing procedure and accuracy/recall calculations\n\nFor each Case, the M labeled samples are randomly divided into a training set and testing set (with ratio of 3 : 1, as discussed above) four times to create four pairs of training/testing sets. One pair is used as a validation set to explore the CapsNet and ConvNets' hyperparameters such as kernel size, regularization constant, and dropout probability. For each Case, once a suitable set of hyperparameters is found, the CapsNet (or ConvNet) is trained and tested just once on each of the remaining three pairs of the training/testing sets (to emphasize, the hyperparameters are not changed for these three pairs, but the weights of the filters are learned independently each time). The accuracies and recalls reported in Figures 3-6 and in the text are computed as the average of results with these three pairs of datasets. We have adopted this approach to examine the robustness of the results despite the relatively small size of the labeled dataset.\n\nWe report the prediction skills in terms of the total accuracy of the testing set, computed as the number of test samples from all 5 clusters whose cluster index is correctly predicted divided by the total number of test samples, and recall, computed as the number of test samples from the four clusters with extreme events (1\u22124) whose cluster index is correctly predicted divided by the total number of test samples in clusters 1\u22124. We computed the recall because for extreme weather prediction, missed events are much more undesirable than false alarms. Together, accuracy and recall fully quantify the skills of the framework for a multi-class prediction. Note that the accuracy for individual clusters, computed as the number of correctly predicted test samples from that cluster divided by the total number of test samples from that cluster, is the receiver operating characteristic (ROC) score, a common forecast skill metric [44,13].\n\n5 Figure 3 shows the performance of CapsNet for predicting cold spells and heat waves using the Z500 patterns from 1 \u2212 5 days earlier. The accuracies for lead times of 1 to 5 days are between 68.8% \u00b1 0.3% and 45.1% \u00b1 0.1% in winter, and 61.6% \u00b1 0.0% and 40.6% \u00b1 0.1% in summer, against a 20% random chance in a 5-class prediction. The recalls are consistently higher, between 77.2% \u00b1 0.3% and 48.1% \u00b1 0.1% in winter and 72.8% \u00b1 0.1% and 46.6% \u00b1 0.1% in summer. Examining the prediction accuracy for individual clusters shows that the inaccuracies largely result from false alarms due to non-extreme-events (cluster 0) incorrectly predicted as an extreme event somewhere in North America (clusters 1 \u2212 4). False alarms can be reduced by adding more constraints on Z500 during labeling, e.g., requiring daily Z500 anomalies to exceed 1.5 standard deviation (SD); however, we choose to avoid subjective criteria and only use the impact (i.e., T2m extreme) for labeling. Furthermore, we focus on minimally pre-processed inputs, e.g., we do not de-trend Z500 patterns and instead use the full Z500 patterns (see Section 3.2), which are non-stationary due to low-frequency coupled atmosphere-ocean modes of climate variability and changes in the radiative forcing from 1920 \u2212 2005.\n\nThe results in Figures 3(a)-(b) are obtained with a training set containing N = 750 samples from each of the 5 clusters. Figures 3(c)-(d) show that as the size of the training set is reduced, the accuracies for winter barely decline. Even when the number of training samples per cluster is reduced almost by a factor of 4 to 187 or 168 (depending on the lag), the largest decrease in accuracy is 4.7% (for day \u22124). In summer, the effect of the size of the training set is more pronounced especially at longer lead times, e.g., the accuracy for 5-day prediction declines by 9.5% when the training set is reduced by a factor of 4. Overall, the weak dependence of the accuracy on the size of the training set is encouraging for practical purposes (see Discussion), but it also suggests that likely, higher accuracies could not be achieved even if we had more training samples (see below).\n\nThe prediction skills in summers are lower than those in winters. Figure 1 shows that the Z500 patterns corresponding to different clusters are much more similar in summers than in winters, suggesting that it should be harder to identify the correct cluster of a pattern in summer. Still, that CapsNet can differentiate between patterns that have such similar averages (i.e., cluster centers) with the accuracy (recall) of 48.2% \u00b1 0.1% (55.6% \u00b1 0.1%) shows the effectiveness of the framework. Furthermore, dynamics of heat waves are more complex than cold spells and the mid-tropospheric circulation patterns (the only predictor here) are not the only driver: Cold spells are mostly due to equatorward advection of cold air from higher latitudes while the heat waves are caused by a combination of horizontal advection and adiabatic and clear-sky radiative warmings [45,46,47]. Moreover, land-atmosphere feedbacks play a role in the dynamics of heat waves [48].\n\nThe results of Figure 3 show the power of our data-driven framework for predicting the surface temperature extreme events using a single variable (Z500) that represents mid-tropospheric circulation, i.e., predicting extreme-causing weather patterns. The above discussions on the weak dependence of accuracy on the size of the training set and the dynamics of the extreme temperature events suggest that including more variables as the predictor and pursuing a multi-variate framework would lead to better prediction skills for the extreme temperature events, particularly at longer lead times. It should be highlighted that even for winters, where meridional advection dominates, including information from other altitudes of troposphere and stratosphere (e.g., to account for polar vortex variability) are expected to improve the prediction skills (see Discussion).\n\nTo demonstrate the promises of such multi-variate data-driven frameworks, we repeat the analysis of Figure 3 but by inputting the patterns of Z500 and anomalous T2m together into CapsNet in the training and testing phases. Figure 4 shows that the accuracies (recalls) for lead times of 1 to 5 days rise to between 82.0% \u00b1 1.5% (87.8% \u00b1 1.4%) and 76.7% \u00b1 2.5% (88.2% \u00b1 2.3%) in winter and 79.3% \u00b1 1.6%(87.2% \u00b1 1.7%) and 75.8% \u00b1 2.7% (87.2% \u00b1 2.6%) in summer, significantly improving the prediction skills, particularly in the longer lead times. With T2m included, the false alarms decline in most cases, and the accuracies/recalls hardly change with lead time or size of the training set. It should be highlighted that the high prediction skills with Z500+T2m are not simply due to the temporal memory as a result of including T2m of earlier days. With N = 750, training and testing the CapsNets on T2m alone result in accuracies that are consistently lower, between 0.6%\u22125.2% (1.5%\u22124.5%), than the accuracies with Z500+T2m in winter (summer), showing that information about the atmospheric circulation adds to the prediction skills.\n\nThe accurate and robust 1 to 5-day predictions in Figure 4 suggest that the multi-variate framework 6 using Z500+T2m, or even more variables (see Discussion), might have high prediction skills for lead times beyond 5 days. However, such longer predictions will require using Z500 patterns (and some of the other variables) at the planetary-scales, which, for the best performance of the framework, needs CapsNet (and ConvNet) architectures capable of accounting for the Earth's spherical geometry, e.g., the zonal periodicity and decrease of area with latitude. Extending the framework to planetary-scales and longer prediction lead times is left for future work, which will benefit from recent advances in developing spherical ConvNets [49,50]. We also conduct the analyses in Figures 3 and 4 with CapsNet replaced with two simpler methods: i) ConvNet, which is a deep learning method of growing interest in climate science (and other disciplines) and was used, for example, by Liu et al. [51] to identify tropical cyclones and atmospheric rivers and by Ham et al. [52] for multi-year ENSO prediction, and ii) Logistic regression [17], which is a widely-used machine learning method that has been employed in some past weather forecasting efforts [53,54,55,56]. Figures 5  and 6 show that the CapsNets consistently outperform the ConvNets (except for one Case: 4-day lead time in summer). For predictions with Z500 (Z500+T2m), the accuracies of CapsNets are, on average, higher than ConvNets by 2.8% (7.7%) in winters and 0.7% (7.1%) in summers. More importantly, as the size of the training set is reduced, the accuracy of ConvNets degrades more than that of CapsNet, particularly in the multi-variate approach with Z500+T2m ( Figures 5-6(c)-(d)). Due to their different architectures (see A and B), CapsNets extract more features and information from each pattern compared to ConvNets, and are thus expected to work well even with relatively small training sets. Moreover, CapsNets account for the relative position and orientation of features (a property called equivariance) [43]. Relative positions of features in spatio-temporal climate data are important, e.g., high-pressure systems on the poleward side of low-pressure systems might stall and cause weather extremes, while low-pressure systems on the poleward side of high-pressure system often move eastward without causing extreme events.\n\nThe accuracy of logistic regression is consistently lower than that of ConvNets (and thus CapsNet), see . For predictions with Z500, the accuracies of CapsNets are, on average, higher than those of logistic regression by 11.4% (19.6%) in winters (summers). These results show the advantage of more advanced deep learning techniques over simpler ones such as ConvNet and logistic regression, and suggest that future studies in climate and environmental sciences might benefit from using CapsNets (and might benefit even more from deep learning techniques designed specifically for multi-scale, spatio-temporal, chaotic data).\n\nNote that we did not compare the performance of our framework with persistence or climatology, which are two common baseline methods [57], because they could not be formulated to predict T2m extremes based on inputs of Z500 patterns, and that by definition, there is no T2m extreme within 5 days of the onsets (see C).\n\n\nDiscussion\n\nThe results of Figure 3 show the skills of the data-driven framework in predicting high-impact events (e.g., T2m extremes) only through limited information about the events's driver (or one of the key drivers), i.e., Z500 patterns in this case, and without any information about the impact itself. This skillful prediction of extreme-causing weather patterns provides a proof-of-concept for the framework (Figure 2). We emphasize that the key components of this data-driven framework are the novel impact-based auto-labeling technique and the power of CapsNets in pattern recognition, which together enable the framework to decipher the relationship between the T2m and Z500 patterns, and the temporal evolution of Z500 patterns, despite challenges such as sensitivity of nonlinear systems to small perturbations in initial conditions [32] and the rarity of perfect analogs in climate data [36,33].\n\nBased on the results of Figure 4, the multi-modal framework (in which both Z500 and T2m are used together), once equipped with spherical CapsNets for planetary-scale inputs, may offer a promising datadriven approach to prediction. Higher accuracies and longer prediction lead times (at the weekly to seasonal time-scales, which are of the most utility and interest) might be achievable by including variables such as geopotential heights at more tropospheric levels, soil moisture, and outgoing longwave radiation, as well as information from the slow-varying boundaries of the troposphere such as tropical and extratropical seasurface temperature (e.g., from Pacific Ocean), tropical atmosphere (e.g., Madden-Julien Oscillation), sea ice, and stratosphere, which are all known to enhance predictive skills for the midlatitude extreme events [13,58,59].\n\nThe data-driven extreme event prediction framework introduced here can be useful in (at least) two ways: 1) To provide early warnings of extreme events and guide the public and NWP efforts, and 2) To identify the precursors of extreme events using ideas from interpretable machine learning [60]. Regarding the former, one of the most appealing and powerful aspects of a data-driven framework is the possibility of training on observational data. Here, the main challenges in using observed climate data for training are that such records are short, and the data are non-stationary in time. Reanalysis products are available for as early as 1850, although the data from before 1979 are derived from limited direct observations. The LENS data used in this study have complexity and non-stationarity similar to that of the reanalysis data, however, the 40-member ensemble simulations provide, e.g., \u223c 300000 days of data in winters, which is much larger than what can be obtained from reanalysis datasets. Given our focus on the onsets of extreme events in the 1 or 99 percentile, from the LENS data, we only used as high as 750 and as low as 168 samples per cluster for training. Figures 3 and 4 show that even with the smallest training set, skillful multi-class predictions are obtained. Furthermore, transfer learning can be used to first train the CapsNet (or ConvNet) on a large set of modeled data and then on a small set of reanalysis, as for example, recently done by Ham et al. [52] for ENSO forecasts. The above discussion suggests that it might be possible to use data derived from observations (and not just NWP or climate models) for training of the data-driven framework. We highlight again that the purpose of this paper is to provide a proof-of-concept for the framework. Evaluating the performance of the framework trained on reanalysis data, and comparing the forecast skills with those of the NWP models, are admittedly the essential and important next steps, and are currently underway.\n\nData from large-ensemble, high-resolution NWP model simulations can also be used for training. The very high-resolution NWP models, which need prohibitive computing time/resources to run continuously, simulate the atmospheric circulation, and in particular extreme-causing patterns, with higher fidelity compared to the simulations with lower resolutions [2,61]. The advantage of using the data-driven framework, trained on high-resolution NWP models, is that it can yield extremely fast and inexpensive regional predictions, which can provide early warnings and guide the deployment of computing and sensing resources for large-ensemble, high-resolution NWP of a region predicted to experience an extreme event in several days (or longer).\n\nIn this study we conducted 5-class predictions based on extreme events over North America clustered (using K-means algorithm) into 4 geographical regions. However, other clustering algorithms, number of clusters etc. could be used, or alternatively, separate data-driven frameworks can be developed for binary (yes/no) extreme predictions in each region of interest, e.g., around Greater Houston, Bay Area, Greater Boston. Understanding which of the approaches discussed above (differing in training data and framework design) lead to the best data-driven prediction skills and better handle practical limitations requires extensive research and should be addressed in future studies.\n\nPrecursors of extreme-causing weather patterns such as blocking events are not well understood [3,12,14] and identifying them can lead to a better dynamical understanding of extreme events and potentially improving weather and climate models. Given that CapsNets show skills in predicting the extreme-causing weather patterns, it is of interest to understand how the neural network has learned what key features to look for. However, understanding how deep neural networks work is known to be challenging and an active area of research. In future work, the feature maps and filters should be examined to seek an understanding of how CapsNets differentiate between patterns that in a few days lead to different T2m clusters. Recent papers by Ham et al. [52] and Mcgovern et al.citemcgovern2019making present promising results and discuss interesting ideas on interpretation of ConvNets and other machine learning methods applied to climate data.\n\nFinally, our data-driven framework can be readily generalized for prediction of other high-impact climatic and environmental phenomena, e.g., extreme precipitation or severe air pollution events, just to name a few. The impact-based auto-labeling strategy circumvents the need for a full understanding of the relationship between the impact of interest and its driver(s). Needless to say, domain expertise is still critical in designing the auto-labeling strategy, e.g., in choosing the relevant variables and spatio-temporal scales.\n\n\n8\n\n\nA Convolutional Neural Network (ConvNet)\n\nConvNet has transformed image processing and pattern recognition in recent years, particularly after its performance in analyzing the ImageNet dataset in 2011 [62], a turning point in the history of deep learning [16,17]. The main components of a ConvNet algorithm are: convolutional layers, in which a specified number of filters with specified sizes extract the key features in the data and produce feature maps; Rectified Linear Unit (ReLU) layers, in which the activation function f (x) = max(0, x) is applied to the feature maps to introduce nonlinearity; pooling layers, which reduce the dimensions of the feature maps by taking the maximum or average of adjacent data points, are applied to increase computing efficiency, control overfitting, and induce translational and scale invariance; and fully connected layers [16,17]. During the training phase, patterns and their labels are inputted into ConvNet and the filters (i.e., their weights) are learned using backpropagation.\n\nFor the small (large) domain, the Z500 patterns are on a 97 \u00d7 66 (157 \u00d7 66) longitude-latitude grid. In our earlier work on applying ConvNet to the LENS dataset [56], we found the training/testing on the full-size patterns challenging. This is because the high-frequency, small-scale variability, e.g., associated with baroclinic waves, is highly chaotic and the ConvNets' attempts in learning these features are futile and lead to substantial overfitting and inaccuracies. We further found that this problem can be resolved by first down-sampling the data to 28 \u00d7 28 (using bicubic interpolation), which only retains the large-scale features. See Chattopadhyay et al. [56] for further discussions. The down-sampled patterns are then standardized by removing the mean and normalizing by the standard deviations computed over the training and testing sets combined.\n\nOur ConvNet architecture is similar to the one used in Chattopadhyay et al. [56]. There are four convolutional layers, which have 8, 16, 32 and 64 filters, respectively, and each filter has a kernel size of 5 \u00d7 5. Zero padding is used to maintain the size of patterns before and after applying the filters. Each convolutional layer is followed with a ReLU activation function. For the last two convolutional layers, the ReLU layers are followed by max-pooling layers that have a kernel size of 2 \u00d7 2 and stride of 1. The output feature is fed into a fully connected neural network with 200 neurons. The cross-entropy cost function is accompanied by a L 2 regularization term, and to prevent overfitting, dropout regularization has been used in the fully connected layer. An adaptive learning rate is implemented through the ADAM optimizer [63]. The final output is the probability of the input pattern belonging to each cluster. A softmax layer assigns the pattern to the cluster index with the highest probability. Chattopadhyay et al. [56] provide further details on the hyperparameter choices, optimizing the ConvNet, and the effect of the number of convolutional layers (e.g., using only two layers reduces the performance while using eight leads to overfitting).\n\n\nB Capsule Neural Network (CapsNet)\n\nDespite its groundbreaking performance and ever-growing popularity, ConvNets face difficulty in dealing with some types of problems where the spatial relationship of key features become critical; e.g., a cubist painting of a face that has the position of one eye and the mouth switched has the right features of a face but not at the right relative positions. The ConvNet's challenge in dealing with these problems is due to the pooling layers, which as mentioned earlier, take the maximum or average of the adjacent data points to introduce translational and scale invariances in the deeper layers, so that ConvNet can recognize the same object at a somewhat different location or with a different size. To address this issue, Sabour et al. [43] have introduced CapsNet, which does not have pooling layers, but have capsules, which are nested sets of neural layers. Unlike a neuron whose output is a real-valued scalar (e.g., likelihood of a certain feature), the output of a capsule is a vector consisting of more information (e.g., position, relative distances, poses, orientation etc.). Rather than invariance, CapsNet seeks equivariance, meaning that the relative positions of features are encoded in the feature maps.\n\nOne might expect CapsNet to be more suitable than ConvNet for our data-driven extreme weather prediction framework (and other climate and environmental problems), because of the importance of the relative position of features. For example, a high-pressure system on the poleward side of a low-pressure system, or a high-pressure system on the poleward side of two weaker low-pressure systems in an Omega-shape configuration, are the signature structures of persistent and extreme-causing blocking events [3]; however, the opposite configurations, e.g., a low-pressure system on the poleward side of a high-pressure system, often progress eastward and do not cause extreme events.\n\nThe architecture of our CapsNet is similar to that of Sabour et al. [43] and is shown in Figure 1. There are two convolutional layers with 32 and 64 filters with kernel sizes 5 \u00d7 5, followed by ReLU layers. These are followed by a primary capsule layer (with 8 capsules, each with 8 convolution layers) that encodes the information of the features in the form of high-dimensional tensors. Via the routing-by-agreement algorithm, the information is sent from the primary capsule layer to a secondary capsule layer, where the probability of each cluster is predicted. At each capsule, non-linearity is introduced by a squash function [43] that enforces the output to have a magnitude less than one while preserving its orientation. There is also a decoding layer, a novel regularization algorithm, in which the pattern is reconstructed using 3 fully connected layers to its original size (28 \u00d7 28) to penalize the loss function to enforce the search for feature maps that can closely reconstruct the original pattern.\n\n\nC Other skill metrics: Persistence and climatology\n\nTwo commonly used baseline methods for forecasting skills are climatology (wherein a variable on a particular date is forecasted as the long-term average of that variable on that particular calendar date from previous years) and persistence (where we assume that the variable remains the same over the period the forecast is performed) [57]. We have not compared the performance of our framework with these baseline methods because our objective could not be formulated in terms of these methods.\n\nTo predict T2m based on Z500 alone, climatology and persistence are inapplicable because they can predict Z500 patterns (or cluster) based on earlier Z500 patterns, but cannot predict T2m pattern (or cluster) based on the input of Z500 patterns, which is our objective here. To predict T2m based on Z500+T2m, persistence could not be used because by definition, there is no T2m extreme within 5 days of any temperature extreme onset. Climatology cannot be used because we have defined extremes as the 1 or 99 percentile of climatological temperature, far from the average. Figure 2: Schematic of the data-driven framework for prediction of cold spells based on Z500 patterns of 3 days earlier. Using the impact-based auto-labeling strategy, Z500 patterns are labeled W0, W1, W2, W3, or W4, depending on the cluster index of T2m three days ahead. The panels at the top show examples of T2m patterns at the onset and the corresponding Z500 patterns (from three days earlier) for each cluster. Only the Z500 patterns and their labels are inputted into the CapsNet during training. Once trained, the CapsNet can predict, from a given Z500 pattern, the T2m cluster index of three days later, thus predicting the occurrence and geographical region of cold spells. For the shown test example, a cold spell in W3 in 3 days is predicted. Note that for winters, Z500 patterns over a larger domain that extends across the Pacific Ocean to 145 \u2022 E are inputted into the CapsNets, but a smaller domain is shown in this figure for better illustration (see Section 3.2). Separate CapsNets are trained for each season and each prediction lead time.   Figure 3 but for the performance of ConvNets and logistic regression in predicting heat waves and cold spells using Z500 patterns at various lead times. In (a)-(b), the symbols and black lines correspond to ConvNets, while the green lines correspond to logistic regression. In (c)-(d), the solid (dashed) lines correspond to ConvNets (logistic regression).  Figure 4 but for the performance of ConvNets and logistic regression in predicting heat waves and cold spells using both T2m and Z500 patterns at various lead times. In (a)-(b), the symbols and black lines correspond to ConvNets, while the green lines correspond to logistic regression. In (c)-(d), the solid (dashed) lines correspond to ConvNets (logistic regression).\n\nFigure 1 :\n1Cluster centers of T2m anomalies at the onsets and Z500 patterns of 3 days earlier. The top (bottom) two rows correspond to summers (winters)\n\n\nFigures 3-6 (the number of samples in the testing set is kept as M/4 regardless of the size of the training set).\n\nFigure 3 : 16 Figure 4 :\n3164Performance of CapsNets in predicting heat waves and cold spells using Z500 patterns at various lead times. (a)-(b) The symbols show the accuracy at different lead times for each cluster: star (0), triangle (1), square (2), diamond (3), and circle (4). The solid (dashed) lines show the total accuracy (recall). (c)-(d) Total accuracy at prediction lead times 1, 3, and 5 days versus the size of the training set (N = 750; fractions are rounded to the nearest integer if needed). Results in (a)-(b) are obtained with the largest training set.The symbols show the accuracy averaged over 3 randomly-drawn pairs of training/testing sets. The lines and their shading depict the mean and \u00b11SD of accuracy or recall computed for the 3 pairs; the shadings are narrow, demonstrating the small SD and robustness of the results. Same asFigure 3but for the performance of CapsNets in predicting heat waves and cold spells using both T2m and Z500 patterns. The shadings show \u00b11SD; the SD values are higher in the multi-variate approach. In (c)-(d), the change of accuracies with the size of the training set is small for lead times of 1, 3, and 5 days (labels not shown).\n\nFigure 5 :\n5Same as\n\nFigure 6 :\n6Same as\n\nThe quiet revolution of numerical weather prediction. Peter Bauer, Alan Thorpe, Gilbert Brunet, Nature. 525756747Peter Bauer, Alan Thorpe, and Gilbert Brunet. The quiet revolution of numerical weather prediction. Nature, 525(7567):47, 2015.\n\nAdvances in weather prediction. Kerry A Richard B Alley, Fuqing Emanuel, Zhang, Science. 3636425Richard B Alley, Kerry A Emanuel, and Fuqing Zhang. Advances in weather prediction. Science, 363(6425):342-344, 2019.\n\nBlocking and its response to climate change. Tim Woollings, David Barriopedro, John Methven, Seok-Woo Son, Olivia Martius, Ben Harvey, Jana Sillmann, Sonia Anthony R Lupo, Seneviratne, Current Climate Change Reports. 43Tim Woollings, David Barriopedro, John Methven, Seok-Woo Son, Olivia Martius, Ben Harvey, Jana Sillmann, Anthony R Lupo, and Sonia Seneviratne. Blocking and its response to climate change. Current Climate Change Reports, 4(3):287-300, 2018.\n\nThe hot summer of 2010: redrawing the temperature record map of Europe. David Barriopedro, M Erich, J\u00fcrg Fischer, Ricardo M Luterbacher, Ricardo Trigo, Garc\u00eda-Herrera, Science. 3326026David Barriopedro, Erich M Fischer, J\u00fcrg Luterbacher, Ricardo M Trigo, and Ricardo Garc\u00eda-Herrera. The hot summer of 2010: redrawing the temperature record map of Europe. Science, 332(6026):220-224, 2011.\n\nFlow-dependent verification of the ECMWF ensemble over the Euro-Atlantic sector. Laura Ferranti, Susanna Corti, Martin Janousek, Quarterly Journal of the Royal Meteorological Society. 141688Laura Ferranti, Susanna Corti, and Martin Janousek. Flow-dependent verification of the ECMWF ensemble over the Euro-Atlantic sector. Quarterly Journal of the Royal Meteorological Society, 141(688):916-924, 2015.\n\nPredictability of Euro-Russian blocking in summer of 2010. Mio Matsueda, Geophysical Research Letters. 386Mio Matsueda. Predictability of Euro-Russian blocking in summer of 2010. Geophysical Research Letters, 38(6), 2011.\n\nHow well does the ECMWF ensemble prediction system predict blocking?. L Joanna, Brian J Pelly, Hoskins, Quarterly Journal of the Royal Meteorological Society. 129590Joanna L Pelly and Brian J Hoskins. How well does the ECMWF ensemble prediction system predict blocking? Quarterly Journal of the Royal Meteorological Society, 129(590):1683-1702, 2003.\n\nProbability of us heat waves affected by a subseasonal planetary wave pattern. Haiyan Teng, Grant Branstator, Hailan Wang, A Gerald, Warren M Meehl, Washington, Nature Geoscience. 6121056Haiyan Teng, Grant Branstator, Hailan Wang, Gerald A Meehl, and Warren M Washington. Probability of us heat waves affected by a subseasonal planetary wave pattern. Nature Geoscience, 6(12):1056, 2013.\n\nResponses of midlatitude blocks and wave amplitude to changes in the meridional temperature gradient in an idealized dry gcm. Pedram Hassanzadeh, Zhiming Kuang, Brian F Farrell, Geophysical Research Letters. 4114Pedram Hassanzadeh, Zhiming Kuang, and Brian F Farrell. Responses of midlatitude blocks and wave amplitude to changes in the meridional temperature gradient in an idealized dry gcm. Geophysical Research Letters, 41(14):5223-5232, 2014.\n\nThe weakening summer circulation in the Northern Hemisphere mid-latitudes. Dim Coumou, Jascha Lehmann, Johanna Beckmann, Science. 3486232Dim Coumou, Jascha Lehmann, and Johanna Beckmann. The weakening summer circulation in the Northern Hemisphere mid-latitudes. Science, 348(6232):324-327, 2015.\n\nContribution of changes in atmospheric circulation patterns to extreme temperature trends. Nathaniel C Daniel E Horton, Deepti Johnson, Singh, L Daniel, Bala Swain, Noah S Rajaratnam, Diffenbaugh, Nature. 5227557465Daniel E Horton, Nathaniel C Johnson, Deepti Singh, Daniel L Swain, Bala Rajaratnam, and Noah S Diffenbaugh. Contribution of changes in atmospheric circulation patterns to extreme temperature trends. Nature, 522(7557):465, 2015.\n\nBlocking variability: Arctic amplification versus Arctic oscillation. Pedram Hassanzadeh, Zhiming Kuang, Geophysical Research Letters. 4220Pedram Hassanzadeh and Zhiming Kuang. Blocking variability: Arctic amplification versus Arctic oscillation. Geophysical Research Letters, 42(20):8586-8595, 2015.\n\nLong-lead predictions of eastern united states hot days from Pacific sea surface temperatures. Karen Aline Mckinnon, Rhines, P Mp Tingley, Huybers, Nature Geoscience. 95389Karen Aline McKinnon, A Rhines, MP Tingley, and P Huybers. Long-lead predictions of eastern united states hot days from Pacific sea surface temperatures. Nature Geoscience, 9(5):389, 2016.\n\nAtmospheric blocking as a traffic jam in the jet stream. Noboru Nakamura, Clare Sy Huang, Science. 3616397Noboru Nakamura and Clare SY Huang. Atmospheric blocking as a traffic jam in the jet stream. Science, 361(6397):42-47, 2018.\n\nSize of the atmospheric blocking events: Scaling law and response to climate change. Ebrahim Nabizadeh, Pedram Hassanzadeh, Da Yang, Elizabeth A Barnes, Geophysical Research Letters. 46Ebrahim Nabizadeh, Pedram Hassanzadeh, Da Yang, and Elizabeth A. Barnes. Size of the atmospheric blocking events: Scaling law and response to climate change. Geophysical Research Letters, 46, 2019.\n\nDeep learning. nature. Yann Lecun, Yoshua Bengio, Geoffrey Hinton, 521436Yann LeCun, Yoshua Bengio, and Geoffrey Hinton. Deep learning. nature, 521(7553):436, 2015.\n\nDeep learning. Ian Goodfellow, Yoshua Bengio, Aaron Courville, MIT pressIan Goodfellow, Yoshua Bengio, and Aaron Courville. Deep learning. MIT press, 2016.\n\nDeep learning to represent subgrid processes in climate models. Stephan Rasp, S Michael, Pierre Pritchard, Gentine, Proceedings of the National Academy of Sciences. 11539Stephan Rasp, Michael S Pritchard, and Pierre Gentine. Deep learning to represent subgrid processes in climate models. Proceedings of the National Academy of Sciences, 115(39):9684-9689, 2018.\n\nPrognostic validation of a neural network unified physics parameterization. D Noah, Brenowitz, Christopher S Bretherton, Geophysical Research Letters. 4512Noah D Brenowitz and Christopher S Bretherton. Prognostic validation of a neural network unified physics parameterization. Geophysical Research Letters, 45(12):6289-6298, 2018.\n\nUsing machine learning to parameterize moist convection: Potential for modeling of climate, climate change, and extreme events. A Paul, John G O&apos;gorman, Dwyer, Journal of Advances in Modeling Earth Systems. 1010Paul A O'Gorman and John G Dwyer. Using machine learning to parameterize moist convection: Potential for modeling of climate, climate change, and extreme events. Journal of Advances in Modeling Earth Systems, 10(10):2548-2563, 2018.\n\nApplications of deep learning to ocean data inference and subgrid parameterization. Thomas Bolton, Laure Zanna, Journal of Advances in Modeling Earth Systems. 111Thomas Bolton and Laure Zanna. Applications of deep learning to ocean data inference and subgrid parameterization. Journal of Advances in Modeling Earth Systems, 11(1):376-399, 2019.\n\nDeep learning of mixing by two atoms of stratified turbulence. Hesam Salehipour, Richard Peltier, Journal of Fluid Mechanics. 861Hesam Salehipour and W Richard Peltier. Deep learning of mixing by two atoms of stratified turbulence. Journal of Fluid Mechanics, 861, 2019.\n\nEarth system modeling 2.0: A blueprint for models that learn from observations and targeted high-resolution simulations. Tapio Schneider, Shiwei Lan, Andrew Stuart, Jo\u00e3o Teixeira, Geophysical Research Letters. 4424Tapio Schneider, Shiwei Lan, Andrew Stuart, and Jo\u00e3o Teixeira. Earth system modeling 2.0: A blueprint for models that learn from observations and targeted high-resolution simulations. Geophysical Research Letters, 44(24), 2017.\n\nCould machine learning break the convection parameterization deadlock?. Pierre Gentine, Mike Pritchard, Stephan Rasp, Gael Reinaudi, Galen Yacalis, Geophysical Research Letters. 451111Pierre Gentine, Mike Pritchard, Stephan Rasp, Gael Reinaudi, and Galen Yacalis. Could machine learning break the convection parameterization deadlock? Geophysical Research Letters, 45(11):5742- 5751, 2018. 11\n\nNuno Carvalhais, and Prabhat. Deep learning and process understanding for data-driven Earth system science. Markus Reichstein, Gustau Camps-Valls, Bjorn Stevens, Martin Jung, Joachim Denzler, Nature. 5667743195Markus Reichstein, Gustau Camps-Valls, Bjorn Stevens, Martin Jung, Joachim Denzler, Nuno Car- valhais, and Prabhat. Deep learning and process understanding for data-driven Earth system science. Nature, 566(7743):195, 2019.\n\nData-driven prediction of a multi-scale Lorenz 96 chaotic system using a hierarchy of deep learning methods: Reservoir computing. Ashesh Chattopadhyay, Pedram Hassanzadeh, Krishna Palem, Devika Subramanian, ; Ann, Rnn-Lstm , arXiv:1906.08829v2arXiv preprintAshesh Chattopadhyay, Pedram Hassanzadeh, Krishna Palem, and Devika Subramanian. Data-driven prediction of a multi-scale Lorenz 96 chaotic system using a hierarchy of deep learning methods: Reser- voir computing, ANN, and RNN-LSTM. arXiv preprint arXiv:1906.08829v2, 2019.\n\nChallenges and design choices for global weather and climate models based on machine learning. D Peter, Peter Dueben, Bauer, Geoscientific Model Development. 1110Peter D Dueben and Peter Bauer. Challenges and design choices for global weather and climate models based on machine learning. Geoscientific Model Development, 11(10):3999-4009, 2018.\n\nThemistoklis P Sapsis, and Petros Koumoutsakos. Data-driven forecasting of high-dimensional chaotic systems with long short-term memory networks. Wonmin Pantelis R Vlachas, Byeon, Y Zhong, Wan, Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences. 47420170844Pantelis R Vlachas, Wonmin Byeon, Zhong Y Wan, Themistoklis P Sapsis, and Petros Koumout- sakos. Data-driven forecasting of high-dimensional chaotic systems with long short-term memory networks. Proceedings of the Royal Society A: Mathematical, Physical and Engineering Sciences, 474(2213):20170844, 2018.\n\nToward data-driven weather and climate forecasting: Approximating a simple general circulation model with deep learning. Sebastian Scher, Geophysical Research Letters. 4522Sebastian Scher. Toward data-driven weather and climate forecasting: Approximating a simple general circulation model with deep learning. Geophysical Research Letters, 45(22):12-616, 2018.\n\nCan machines learn to predict weather? Using deep learning to predict gridded 500-hPa geopotential height from historical weather data. Jonathan A Weyn, Rich Dale R Durran, Caruana, Journal of Advances in Modeling Earth Systems. 108Jonathan A Weyn, Dale R Durran, and Rich Caruana. Can machines learn to predict weather? Using deep learning to predict gridded 500-hPa geopotential height from historical weather data. Journal of Advances in Modeling Earth Systems, 10(8):2680-2693, 2019.\n\nWeather and climate forecasting with neural networks: using general circulation models (GCMs) with different complexity as a study ground. Sebastian Scher, Gabriele Messori, Geoscientific Model Development. 127Sebastian Scher and Gabriele Messori. Weather and climate forecasting with neural networks: using general circulation models (GCMs) with different complexity as a study ground. Geoscientific Model Development, 12(7):2797-2809, 2019.\n\nAtmospheric predictability as revealed by naturally occurring analogues. N Edward, Lorenz, Journal of the Atmospheric sciences. 264Edward N Lorenz. Atmospheric predictability as revealed by naturally occurring analogues. Journal of the Atmospheric sciences, 26(4):636-646, 1969.\n\nHuug Van den Dool. Empirical methods in short-term climate prediction. Oxford University PressHuug Van den Dool. Empirical methods in short-term climate prediction. Oxford University Press, 2007.\n\nA model-based approach for analog spatio-temporal dynamic forecasting. L Patrick, Mcdermott, Christopher K Wikle, Environmetrics. 272Patrick L McDermott and Christopher K Wikle. A model-based approach for analog spatio-temporal dynamic forecasting. Environmetrics, 27(2):70-82, 2016.\n\nAnalog forecasting with dynamics-adapted kernels. Zhizhen Zhao, Dimitrios Giannakis, Nonlinearity. 2992888Zhizhen Zhao and Dimitrios Giannakis. Analog forecasting with dynamics-adapted kernels. Nonlinearity, 29(9):2888, 2016.\n\nSearching for analogues, how long must we wait?. Hm Van Den Dool, Tellus A. 463HM Van den Dool. Searching for analogues, how long must we wait? Tellus A, 46(3):314-324, 1994.\n\nThe community earth system model (CESM) large ensemble project: A community resource for studying climate change in the presence of internal climate variability. Je Kay, Deser, Phillips, C Mai, G Hannay, Strand, Arblaster, G Bates, Danabasoglu, M Edwards, Holland, J.-F Kushner, D Lamarque, Lawrence, A Lindsay, Middleton, R Munoz, K Neale, L Oleson, M Polvani, Vertenstein, Bulletin of the American Meteorological Society. 968JE Kay, C Deser, A Phillips, A Mai, C Hannay, G Strand, JM Arblaster, SC Bates, G Danabasoglu, J Edwards, M Holland, P Kushner, J.-F. Lamarque, D. Lawrence, K Lindsay, A. Middleton, E Munoz, R. Neale, K. Oleson, L. Polvani, and M Vertenstein. The community earth system model (CESM) large ensemble project: A community resource for studying climate change in the presence of internal climate variability. Bulletin of the American Meteorological Society, 96(8):1333-1349, 2015.\n\nEvaluating indices of blocking anticyclones in terms of their linear relations with surface hot extremes. Pedram Pak-Wah Chan, Zhiming Hassanzadeh, Kuang, Geophysical Research Letters. 46Pak-Wah Chan, Pedram Hassanzadeh, and Zhiming Kuang. Evaluating indices of blocking anticyclones in terms of their linear relations with surface hot extremes. Geophysical Research Letters, 46, 2019.\n\nMultiscale variability in North American summer maximum temperatures and modulations from the North Atlantic simulated by an AGCM. Nicolas Vigaud, Mingfang Ting, D-E Lee, G Anthony, Yochanan Barnston, Kushnir, Journal of Climate. 317Nicolas Vigaud, Mingfang Ting, D-E Lee, Anthony G Barnston, and Yochanan Kushnir. Multiscale variability in North American summer maximum temperatures and modulations from the North Atlantic simulated by an AGCM. Journal of Climate, 31(7):2549-2562, 2018.\n\nLeast squares quantization in PCM. Stuart Lloyd, IEEE Transactions on Information Theory. 282Stuart Lloyd. Least squares quantization in PCM. IEEE Transactions on Information Theory, 28(2):129-137, 1982.\n\nCluster analysis of multiple planetary flow regimes. Kingtse Mo, Michael Ghil, Journal of Geophysical Research: Atmospheres. 93D9Kingtse Mo and Michael Ghil. Cluster analysis of multiple planetary flow regimes. Journal of Geophysical Research: Atmospheres, 93(D9):10927-10952, 1988.\n\nCluster analysis of the Northern Hemisphere wintertime 500-hpa height field: Spatial patterns. Xinhua Cheng, John M Wallace, Journal of the Atmospheric Sciences. 5016Xinhua Cheng and John M Wallace. Cluster analysis of the Northern Hemisphere wintertime 500-hpa height field: Spatial patterns. Journal of the Atmospheric Sciences, 50(16):2674-2696, 1993.\n\nDynamic routing between capsules. Sara Sabour, Nicholas Frosst, Geoffrey E Hinton, Advances in neural information processing systems. Sara Sabour, Nicholas Frosst, and Geoffrey E Hinton. Dynamic routing between capsules. In Advances in neural information processing systems, pages 3856-3866, 2017.\n\nAn introduction to ROC analysis. Tom Fawcett, Pattern Recognition Letters. 278Tom Fawcett. An introduction to ROC analysis. Pattern Recognition Letters, 27(8):861-874, 2006.\n\nWas there a basis for anticipating the 2010 russian heat wave?. Randall Dole, Martin Hoerling, Judith Perlwitz, Jon Eischeid, Philip Pegion, Tao Zhang, Xiao-Wei Quan, Taiyi Xu, Donald Murray, Geophysical Research Letters. 386Randall Dole, Martin Hoerling, Judith Perlwitz, Jon Eischeid, Philip Pegion, Tao Zhang, Xiao-Wei Quan, Taiyi Xu, and Donald Murray. Was there a basis for anticipating the 2010 russian heat wave? Geophysical Research Letters, 38(6), 2011.\n\nQuantifying the relevance of atmospheric blocking for co-located temperature extremes in the Northern Hemisphere on (sub-) daily time scales. S Pfahl, H Wernli, Geophysical Research Letters. 3912S Pfahl and H Wernli. Quantifying the relevance of atmospheric blocking for co-located temperature extremes in the Northern Hemisphere on (sub-) daily time scales. Geophysical Research Letters, 39(12), 2012.\n\nPhysics of changes in synoptic midlatitude temperature variability. Tapio Schneider, Tobias Bischoff, Hanna P Lotka, Journal of Climate. 286Tapio Schneider, Tobias Bischoff, and Hanna P lotka. Physics of changes in synoptic midlatitude tem- perature variability. Journal of Climate, 28(6):2312-2331, 2015.\n\nMega-heatwave temperatures due to combined soil desiccation and atmospheric heat accumulation. Diego G Miralles, J Adriaan, Teuling, Jordi Vila-Guerau De Van Heerwaarden, Arellano, Nature Geoscience. 75345Diego G Miralles, Adriaan J Teuling, Chiel C Van Heerwaarden, and Jordi Vila-Guerau De Arellano. Mega-heatwave temperatures due to combined soil desiccation and atmospheric heat accumulation. Nature Geoscience, 7(5):345, 2014.\n\n. Mario Taco S Cohen, Jonas Geiger, Max K\u00f6hler, Welling, arXiv:1801.10130Spherical CNNs. arXiv preprintTaco S Cohen, Mario Geiger, Jonas K\u00f6hler, and Max Welling. Spherical CNNs. arXiv preprint arXiv:1801.10130, 2018.\n\nChiyu Jiang, Jingwei Huang, Karthik Kashinath, Philip Marcus, Matthias Niessner, arXiv:1901.02039Spherical CNNs on unstructured grids. arXiv preprintChiyu Jiang, Jingwei Huang, Karthik Kashinath, Philip Marcus, and Matthias Niessner. Spherical CNNs on unstructured grids. arXiv preprint arXiv:1901.02039, 2019.\n\nApplication of deep convolutional neural networks for detecting extreme weather in climate datasets. Yunjie Liu, Evan Racah, Joaquin Correa, Amir Khosrowshahi, David Lavers, Kenneth Kunkel, Michael Wehner, William Collins, arXiv:1605.01156arXiv preprintYunjie Liu, Evan Racah, Joaquin Correa, Amir Khosrowshahi, David Lavers, Kenneth Kunkel, Michael Wehner, and William Collins. Application of deep convolutional neural networks for detecting extreme weather in climate datasets. arXiv preprint arXiv:1605.01156, 2016.\n\nDeep learning for multi-year ENSO forecasts. Yoo-Geun Ham, Jeong-Hwan Kim, Jing-Jia Luo, Nature. 5737775Yoo-Geun Ham, Jeong-Hwan Kim, and Jing-Jia Luo. Deep learning for multi-year ENSO forecasts. Nature, 573(7775):568-572, 2019.\n\nComparison of methodologies for probabilistic quantitative precipitation forecasting. Scott Applequist, E Gregory, Richard L Gahrs, Xu-Feng Pfeffer, Niu, Weather and Forecasting17Scott Applequist, Gregory E Gahrs, Richard L Pfeffer, and Xu-Feng Niu. Comparison of methodologies for probabilistic quantitative precipitation forecasting. Weather and Forecasting, 17(4):783-799, 2002.\n\nMoney doesn't grow on trees, but forecasts do: Forecasting extreme precipitation with random forests. R Gregory, Russ S Herman, Schumacher, Monthly Weather Review. 1465Gregory R Herman and Russ S Schumacher. Money doesn't grow on trees, but forecasts do: Forecasting extreme precipitation with random forests. Monthly Weather Review, 146(5):1571-1600, 2018.\n\nComparing area probability forecasts of (extreme) local precipitation using parametric and machine learning statistical postprocessing methods. Kirien Whan, Maurice Schmeits, Monthly Weather Review. 14611Kirien Whan and Maurice Schmeits. Comparing area probability forecasts of (extreme) local precip- itation using parametric and machine learning statistical postprocessing methods. Monthly Weather Review, 146(11):3651-3673, 2018.\n\nPredicting clustered weather patterns: A test case for applications of convolutional neural networks to spatio-temporal climate data. Ashesh Chattopadhyay, Pedram Hassanzadeh, Saba Pasha, arXiv:1811.04817arXiv preprintAshesh Chattopadhyay, Pedram Hassanzadeh, and Saba Pasha. Predicting clustered weather patterns: A test case for applications of convolutional neural networks to spatio-temporal climate data. arXiv preprint arXiv:1811.04817, 2018.\n\nClimatology, persistence, and their linear combination as standards of reference in skill scores. H Allan, Murphy, Weather and Forecasting. 74Allan H Murphy. Climatology, persistence, and their linear combination as standards of reference in skill scores. Weather and Forecasting, 7(4):692-698, 1992.\n\nStratospheric harbingers of anomalous weather regimes. P Mark, Timothy J Baldwin, Dunkerton, Science. 2945542Mark P Baldwin and Timothy J Dunkerton. Stratospheric harbingers of anomalous weather regimes. Science, 294(5542):581-584, 2001.\n\nSkillful empirical subseasonal prediction of landfalling atmospheric river activity using the Madden-Julian oscillation and quasi-biennial oscillation. Elizabeth A Bryan D Mundhenk, Eric D Barnes, Cory F Maloney, Baggett, Climate and Atmospheric Science. 117Bryan D Mundhenk, Elizabeth A Barnes, Eric D Maloney, and Cory F Baggett. Skillful empirical subseasonal prediction of landfalling atmospheric river activity using the Madden-Julian oscillation and quasi-biennial oscillation. npj Climate and Atmospheric Science, 1(1):7, 2018.\n\nVisualizing and understanding convolutional networks. D Matthew, Rob Zeiler, Fergus, European Conference on Computer Vision. SpringerMatthew D Zeiler and Rob Fergus. Visualizing and understanding convolutional networks. In European Conference on Computer Vision, pages 818-833. Springer, 2014.\n\nHigh-resolution global climate simulations with the ECMWF model in Project Athena: Experimental design, model climate, and seasonal forecast skill. Thomas Jung, Miller, Palmer, Towers, Wedi, Achuthavarier, Adams, El Altshuler, Ba Cash, L Jl Kinter Iii, C Marx, K I Stan, Hodges, Journal of Climate. 259Thomas Jung, MJ Miller, TN Palmer, P Towers, N Wedi, D Achuthavarier, JM Adams, EL Altshuler, BA Cash, JL Kinter Iii, L. Marx, C. Stan, and K. I. Hodges. High-resolution global climate simulations with the ECMWF model in Project Athena: Experimental design, model climate, and seasonal forecast skill. Journal of Climate, 25(9):3155-3172, 2012.\n\nImagenet classification with deep convolutional neural networks. Alex Krizhevsky, Ilya Sutskever, Geoffrey E Hinton, Advances in neural information processing systems. Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convolutional neural networks. In Advances in neural information processing systems, pages 1097-1105, 2012.\n\nAdam: A method for stochastic optimization. P Diederik, Jimmy Kingma, Ba, arXiv:1412.6980arXiv preprintDiederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014.\n", "annotations": {"author": "[{\"end\":170,\"start\":94},{\"end\":244,\"start\":171},{\"end\":395,\"start\":245}]", "publisher": null, "author_last_name": "[{\"end\":114,\"start\":101},{\"end\":188,\"start\":179},{\"end\":263,\"start\":252}]", "author_first_name": "[{\"end\":100,\"start\":94},{\"end\":178,\"start\":171},{\"end\":251,\"start\":245}]", "author_affiliation": "[{\"end\":169,\"start\":116},{\"end\":243,\"start\":190},{\"end\":318,\"start\":265},{\"end\":394,\"start\":320}]", "title": "[{\"end\":75,\"start\":1},{\"end\":470,\"start\":396}]", "venue": null, "abstract": "[{\"end\":1872,\"start\":488}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2200,\"start\":2197},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2202,\"start\":2200},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2460,\"start\":2457},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2587,\"start\":2584},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2589,\"start\":2587},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":2725,\"start\":2722},{\"end\":2727,\"start\":2725},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":2729,\"start\":2727},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2905,\"start\":2902},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":2907,\"start\":2905},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":2909,\"start\":2907},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":2912,\"start\":2909},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":2915,\"start\":2912},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":2918,\"start\":2915},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":2921,\"start\":2918},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":2924,\"start\":2921},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":2927,\"start\":2924},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":3068,\"start\":3064},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":3071,\"start\":3068},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":3273,\"start\":3269},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":3276,\"start\":3273},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":3279,\"start\":3276},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":3282,\"start\":3279},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":3285,\"start\":3282},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":3409,\"start\":3405},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":3412,\"start\":3409},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":3415,\"start\":3412},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":3418,\"start\":3415},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":3529,\"start\":3525},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":4102,\"start\":4098},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":4105,\"start\":4102},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":4108,\"start\":4105},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":4111,\"start\":4108},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":4114,\"start\":4111},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":4117,\"start\":4114},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":4366,\"start\":4362},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":4369,\"start\":4366},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":4687,\"start\":4683},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":4831,\"start\":4827},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":4964,\"start\":4960},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":4967,\"start\":4964},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":5440,\"start\":5436},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":5443,\"start\":5440},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":5680,\"start\":5676},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":5683,\"start\":5680},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":6496,\"start\":6492},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":8073,\"start\":8069},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":10569,\"start\":10565},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":10795,\"start\":10791},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":11677,\"start\":11673},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":11680,\"start\":11677},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":11683,\"start\":11680},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":11898,\"start\":11894},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":11901,\"start\":11898},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":11967,\"start\":11963},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":12173,\"start\":12169},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":13817,\"start\":13813},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":15791,\"start\":15790},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":20363,\"start\":20359},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":20365,\"start\":20363},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":23403,\"start\":23399},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":23406,\"start\":23403},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":23409,\"start\":23406},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":23493,\"start\":23489},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":26239,\"start\":26235},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":26242,\"start\":26239},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":26492,\"start\":26488},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":26568,\"start\":26564},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":26633,\"start\":26629},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":26750,\"start\":26746},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":26753,\"start\":26750},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":26756,\"start\":26753},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":26759,\"start\":26756},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":27582,\"start\":27578},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":28663,\"start\":28659},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":29698,\"start\":29694},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":29753,\"start\":29749},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":29756,\"start\":29753},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":30605,\"start\":30601},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":30608,\"start\":30605},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":30611,\"start\":30608},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":30908,\"start\":30904},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":32103,\"start\":32099},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":32978,\"start\":32975},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":32981,\"start\":32978},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":34146,\"start\":34143},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":34149,\"start\":34146},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":34152,\"start\":34149},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":34804,\"start\":34800},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":35739,\"start\":35735},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":35793,\"start\":35789},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":35796,\"start\":35793},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":36404,\"start\":36400},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":36407,\"start\":36404},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":36727,\"start\":36723},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":37235,\"start\":37231},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":37508,\"start\":37504},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":38271,\"start\":38267},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":38469,\"start\":38465},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":39480,\"start\":39476},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":40466,\"start\":40463},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":40712,\"start\":40708},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":41276,\"start\":41272},{\"end\":41535,\"start\":41526},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":42050,\"start\":42046}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":44725,\"start\":44571},{\"attributes\":{\"id\":\"fig_1\"},\"end\":44841,\"start\":44726},{\"attributes\":{\"id\":\"fig_2\"},\"end\":46031,\"start\":44842},{\"attributes\":{\"id\":\"fig_3\"},\"end\":46052,\"start\":46032},{\"attributes\":{\"id\":\"fig_4\"},\"end\":46073,\"start\":46053}]", "paragraph": "[{\"end\":2928,\"start\":1888},{\"end\":4118,\"start\":2930},{\"end\":4968,\"start\":4120},{\"end\":6057,\"start\":4970},{\"end\":6404,\"start\":6059},{\"end\":7314,\"start\":6425},{\"end\":7625,\"start\":7316},{\"end\":8398,\"start\":7674},{\"end\":9661,\"start\":8400},{\"end\":10349,\"start\":9663},{\"end\":11024,\"start\":10407},{\"end\":11706,\"start\":11026},{\"end\":12621,\"start\":11770},{\"end\":13503,\"start\":12623},{\"end\":14022,\"start\":13505},{\"end\":14666,\"start\":14024},{\"end\":15221,\"start\":14808},{\"end\":15792,\"start\":15223},{\"end\":16852,\"start\":15826},{\"end\":17815,\"start\":16905},{\"end\":18402,\"start\":17817},{\"end\":19425,\"start\":18470},{\"end\":20367,\"start\":19427},{\"end\":21644,\"start\":20369},{\"end\":22531,\"start\":21646},{\"end\":23494,\"start\":22533},{\"end\":24362,\"start\":23496},{\"end\":25496,\"start\":24364},{\"end\":27898,\"start\":25498},{\"end\":28524,\"start\":27900},{\"end\":28844,\"start\":28526},{\"end\":29757,\"start\":28859},{\"end\":30612,\"start\":29759},{\"end\":32618,\"start\":30614},{\"end\":33360,\"start\":32620},{\"end\":34046,\"start\":33362},{\"end\":34992,\"start\":34048},{\"end\":35527,\"start\":34994},{\"end\":36560,\"start\":35576},{\"end\":37426,\"start\":36562},{\"end\":38695,\"start\":37428},{\"end\":39957,\"start\":38734},{\"end\":40638,\"start\":39959},{\"end\":41655,\"start\":40640},{\"end\":42206,\"start\":41710},{\"end\":44570,\"start\":42208}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":14807,\"start\":14667}]", "table_ref": null, "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1886,\"start\":1874},{\"attributes\":{\"n\":\"2\"},\"end\":6411,\"start\":6407},{\"attributes\":{\"n\":\"2.1\"},\"end\":6423,\"start\":6414},{\"attributes\":{\"n\":\"2.2\"},\"end\":7672,\"start\":7628},{\"attributes\":{\"n\":\"2.3\"},\"end\":10405,\"start\":10352},{\"attributes\":{\"n\":\"3\"},\"end\":11720,\"start\":11709},{\"attributes\":{\"n\":\"3.1\"},\"end\":11768,\"start\":11723},{\"attributes\":{\"n\":\"3.3\"},\"end\":15824,\"start\":15795},{\"attributes\":{\"n\":\"3.4\"},\"end\":16903,\"start\":16855},{\"attributes\":{\"n\":\"3.5\"},\"end\":18468,\"start\":18405},{\"attributes\":{\"n\":\"5\"},\"end\":28857,\"start\":28847},{\"end\":35531,\"start\":35530},{\"end\":35574,\"start\":35534},{\"end\":38732,\"start\":38698},{\"end\":41708,\"start\":41658},{\"end\":44582,\"start\":44572},{\"end\":44867,\"start\":44843},{\"end\":46043,\"start\":46033},{\"end\":46064,\"start\":46054}]", "table": null, "figure_caption": "[{\"end\":44725,\"start\":44584},{\"end\":44841,\"start\":44728},{\"end\":46031,\"start\":44872},{\"end\":46052,\"start\":46045},{\"end\":46073,\"start\":46066}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":10980,\"start\":10972},{\"end\":12479,\"start\":12471},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":14521,\"start\":14513},{\"end\":16986,\"start\":16978},{\"end\":17144,\"start\":17136},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":18145,\"start\":18130},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":19205,\"start\":19194},{\"end\":20379,\"start\":20371},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":21072,\"start\":21056},{\"end\":21677,\"start\":21661},{\"end\":21783,\"start\":21767},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":22607,\"start\":22599},{\"end\":23519,\"start\":23511},{\"end\":24472,\"start\":24464},{\"end\":24595,\"start\":24587},{\"end\":25556,\"start\":25548},{\"end\":26291,\"start\":26276},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":26777,\"start\":26761},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":27238,\"start\":27227},{\"end\":28882,\"start\":28874},{\"end\":29273,\"start\":29264},{\"end\":29791,\"start\":29783},{\"end\":31807,\"start\":31792},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":40737,\"start\":40729},{\"end\":42789,\"start\":42781},{\"end\":43851,\"start\":43843},{\"end\":44209,\"start\":44201}]", "bib_author_first_name": "[{\"end\":46134,\"start\":46129},{\"end\":46146,\"start\":46142},{\"end\":46162,\"start\":46155},{\"end\":46354,\"start\":46349},{\"end\":46356,\"start\":46355},{\"end\":46380,\"start\":46374},{\"end\":46580,\"start\":46577},{\"end\":46597,\"start\":46592},{\"end\":46615,\"start\":46611},{\"end\":46633,\"start\":46625},{\"end\":46645,\"start\":46639},{\"end\":46658,\"start\":46655},{\"end\":46671,\"start\":46667},{\"end\":46687,\"start\":46682},{\"end\":47070,\"start\":47065},{\"end\":47085,\"start\":47084},{\"end\":47097,\"start\":47093},{\"end\":47114,\"start\":47107},{\"end\":47116,\"start\":47115},{\"end\":47137,\"start\":47130},{\"end\":47469,\"start\":47464},{\"end\":47487,\"start\":47480},{\"end\":47501,\"start\":47495},{\"end\":47848,\"start\":47845},{\"end\":48080,\"start\":48079},{\"end\":48094,\"start\":48089},{\"end\":48096,\"start\":48095},{\"end\":48446,\"start\":48440},{\"end\":48458,\"start\":48453},{\"end\":48477,\"start\":48471},{\"end\":48485,\"start\":48484},{\"end\":48502,\"start\":48494},{\"end\":48882,\"start\":48876},{\"end\":48903,\"start\":48896},{\"end\":48916,\"start\":48911},{\"end\":48918,\"start\":48917},{\"end\":49277,\"start\":49274},{\"end\":49292,\"start\":49286},{\"end\":49309,\"start\":49302},{\"end\":49596,\"start\":49587},{\"end\":49598,\"start\":49597},{\"end\":49622,\"start\":49616},{\"end\":49640,\"start\":49639},{\"end\":49653,\"start\":49649},{\"end\":49665,\"start\":49661},{\"end\":49667,\"start\":49666},{\"end\":50017,\"start\":50011},{\"end\":50038,\"start\":50031},{\"end\":50343,\"start\":50338},{\"end\":50349,\"start\":50344},{\"end\":50369,\"start\":50368},{\"end\":50668,\"start\":50662},{\"end\":50687,\"start\":50679},{\"end\":50929,\"start\":50922},{\"end\":50947,\"start\":50941},{\"end\":50963,\"start\":50961},{\"end\":50979,\"start\":50970},{\"end\":50981,\"start\":50980},{\"end\":51248,\"start\":51244},{\"end\":51262,\"start\":51256},{\"end\":51279,\"start\":51271},{\"end\":51405,\"start\":51402},{\"end\":51424,\"start\":51418},{\"end\":51438,\"start\":51433},{\"end\":51615,\"start\":51608},{\"end\":51623,\"start\":51622},{\"end\":51639,\"start\":51633},{\"end\":51985,\"start\":51984},{\"end\":52370,\"start\":52369},{\"end\":52383,\"start\":52377},{\"end\":52781,\"start\":52775},{\"end\":52795,\"start\":52790},{\"end\":53105,\"start\":53100},{\"end\":53125,\"start\":53118},{\"end\":53435,\"start\":53430},{\"end\":53453,\"start\":53447},{\"end\":53465,\"start\":53459},{\"end\":53478,\"start\":53474},{\"end\":53830,\"start\":53824},{\"end\":53844,\"start\":53840},{\"end\":53863,\"start\":53856},{\"end\":53874,\"start\":53870},{\"end\":53890,\"start\":53885},{\"end\":54260,\"start\":54254},{\"end\":54279,\"start\":54273},{\"end\":54298,\"start\":54293},{\"end\":54314,\"start\":54308},{\"end\":54328,\"start\":54321},{\"end\":54716,\"start\":54710},{\"end\":54738,\"start\":54732},{\"end\":54759,\"start\":54752},{\"end\":54773,\"start\":54767},{\"end\":54788,\"start\":54787},{\"end\":54802,\"start\":54794},{\"end\":55207,\"start\":55206},{\"end\":55220,\"start\":55215},{\"end\":55610,\"start\":55604},{\"end\":55639,\"start\":55638},{\"end\":56185,\"start\":56176},{\"end\":56574,\"start\":56570},{\"end\":57054,\"start\":57045},{\"end\":57070,\"start\":57062},{\"end\":57424,\"start\":57423},{\"end\":57899,\"start\":57898},{\"end\":58169,\"start\":58162},{\"end\":58185,\"start\":58176},{\"end\":58703,\"start\":58702},{\"end\":58710,\"start\":58709},{\"end\":58739,\"start\":58738},{\"end\":58761,\"start\":58760},{\"end\":58784,\"start\":58780},{\"end\":58795,\"start\":58794},{\"end\":58817,\"start\":58816},{\"end\":58839,\"start\":58838},{\"end\":58848,\"start\":58847},{\"end\":58857,\"start\":58856},{\"end\":58867,\"start\":58866},{\"end\":59532,\"start\":59526},{\"end\":59554,\"start\":59547},{\"end\":59945,\"start\":59938},{\"end\":59962,\"start\":59954},{\"end\":59972,\"start\":59969},{\"end\":59979,\"start\":59978},{\"end\":59997,\"start\":59989},{\"end\":60338,\"start\":60332},{\"end\":60562,\"start\":60555},{\"end\":60574,\"start\":60567},{\"end\":60887,\"start\":60881},{\"end\":60901,\"start\":60895},{\"end\":61180,\"start\":61176},{\"end\":61197,\"start\":61189},{\"end\":61214,\"start\":61206},{\"end\":61216,\"start\":61215},{\"end\":61477,\"start\":61474},{\"end\":61687,\"start\":61680},{\"end\":61700,\"start\":61694},{\"end\":61717,\"start\":61711},{\"end\":61731,\"start\":61728},{\"end\":61748,\"start\":61742},{\"end\":61760,\"start\":61757},{\"end\":61776,\"start\":61768},{\"end\":61788,\"start\":61783},{\"end\":61799,\"start\":61793},{\"end\":62223,\"start\":62222},{\"end\":62232,\"start\":62231},{\"end\":62557,\"start\":62552},{\"end\":62575,\"start\":62569},{\"end\":62591,\"start\":62586},{\"end\":62593,\"start\":62592},{\"end\":62905,\"start\":62904},{\"end\":62944,\"start\":62924},{\"end\":63231,\"start\":63226},{\"end\":63251,\"start\":63246},{\"end\":63263,\"start\":63260},{\"end\":63447,\"start\":63442},{\"end\":63462,\"start\":63455},{\"end\":63477,\"start\":63470},{\"end\":63495,\"start\":63489},{\"end\":63512,\"start\":63504},{\"end\":63861,\"start\":63855},{\"end\":63871,\"start\":63867},{\"end\":63886,\"start\":63879},{\"end\":63899,\"start\":63895},{\"end\":63919,\"start\":63914},{\"end\":63935,\"start\":63928},{\"end\":63951,\"start\":63944},{\"end\":63967,\"start\":63960},{\"end\":64327,\"start\":64319},{\"end\":64343,\"start\":64333},{\"end\":64357,\"start\":64349},{\"end\":64596,\"start\":64591},{\"end\":64610,\"start\":64609},{\"end\":64627,\"start\":64620},{\"end\":64629,\"start\":64628},{\"end\":64644,\"start\":64637},{\"end\":64991,\"start\":64990},{\"end\":65007,\"start\":65001},{\"end\":65397,\"start\":65391},{\"end\":65411,\"start\":65404},{\"end\":65821,\"start\":65815},{\"end\":65843,\"start\":65837},{\"end\":65861,\"start\":65857},{\"end\":66230,\"start\":66229},{\"end\":66489,\"start\":66488},{\"end\":66503,\"start\":66496},{\"end\":66505,\"start\":66504},{\"end\":66833,\"start\":66824},{\"end\":66835,\"start\":66834},{\"end\":66858,\"start\":66854},{\"end\":66860,\"start\":66859},{\"end\":66873,\"start\":66869},{\"end\":66875,\"start\":66874},{\"end\":67263,\"start\":67262},{\"end\":67276,\"start\":67273},{\"end\":67657,\"start\":67651},{\"end\":67740,\"start\":67739},{\"end\":67757,\"start\":67756},{\"end\":67765,\"start\":67764},{\"end\":67767,\"start\":67766},{\"end\":68220,\"start\":68216},{\"end\":68237,\"start\":68233},{\"end\":68257,\"start\":68249},{\"end\":68259,\"start\":68258},{\"end\":68563,\"start\":68562},{\"end\":68579,\"start\":68574}]", "bib_author_last_name": "[{\"end\":46140,\"start\":46135},{\"end\":46153,\"start\":46147},{\"end\":46169,\"start\":46163},{\"end\":46372,\"start\":46357},{\"end\":46388,\"start\":46381},{\"end\":46395,\"start\":46390},{\"end\":46590,\"start\":46581},{\"end\":46609,\"start\":46598},{\"end\":46623,\"start\":46616},{\"end\":46637,\"start\":46634},{\"end\":46653,\"start\":46646},{\"end\":46665,\"start\":46659},{\"end\":46680,\"start\":46672},{\"end\":46702,\"start\":46688},{\"end\":46715,\"start\":46704},{\"end\":47082,\"start\":47071},{\"end\":47091,\"start\":47086},{\"end\":47105,\"start\":47098},{\"end\":47128,\"start\":47117},{\"end\":47143,\"start\":47138},{\"end\":47159,\"start\":47145},{\"end\":47478,\"start\":47470},{\"end\":47493,\"start\":47488},{\"end\":47510,\"start\":47502},{\"end\":47857,\"start\":47849},{\"end\":48087,\"start\":48081},{\"end\":48102,\"start\":48097},{\"end\":48111,\"start\":48104},{\"end\":48451,\"start\":48447},{\"end\":48469,\"start\":48459},{\"end\":48482,\"start\":48478},{\"end\":48492,\"start\":48486},{\"end\":48508,\"start\":48503},{\"end\":48520,\"start\":48510},{\"end\":48894,\"start\":48883},{\"end\":48909,\"start\":48904},{\"end\":48926,\"start\":48919},{\"end\":49284,\"start\":49278},{\"end\":49300,\"start\":49293},{\"end\":49318,\"start\":49310},{\"end\":49614,\"start\":49599},{\"end\":49630,\"start\":49623},{\"end\":49637,\"start\":49632},{\"end\":49647,\"start\":49641},{\"end\":49659,\"start\":49654},{\"end\":49678,\"start\":49668},{\"end\":49691,\"start\":49680},{\"end\":50029,\"start\":50018},{\"end\":50044,\"start\":50039},{\"end\":50358,\"start\":50350},{\"end\":50366,\"start\":50360},{\"end\":50380,\"start\":50370},{\"end\":50389,\"start\":50382},{\"end\":50677,\"start\":50669},{\"end\":50693,\"start\":50688},{\"end\":50939,\"start\":50930},{\"end\":50959,\"start\":50948},{\"end\":50968,\"start\":50964},{\"end\":50988,\"start\":50982},{\"end\":51254,\"start\":51249},{\"end\":51269,\"start\":51263},{\"end\":51286,\"start\":51280},{\"end\":51416,\"start\":51406},{\"end\":51431,\"start\":51425},{\"end\":51448,\"start\":51439},{\"end\":51620,\"start\":51616},{\"end\":51631,\"start\":51624},{\"end\":51649,\"start\":51640},{\"end\":51658,\"start\":51651},{\"end\":51990,\"start\":51986},{\"end\":52001,\"start\":51992},{\"end\":52027,\"start\":52003},{\"end\":52375,\"start\":52371},{\"end\":52397,\"start\":52384},{\"end\":52404,\"start\":52399},{\"end\":52788,\"start\":52782},{\"end\":52801,\"start\":52796},{\"end\":53116,\"start\":53106},{\"end\":53133,\"start\":53126},{\"end\":53445,\"start\":53436},{\"end\":53457,\"start\":53454},{\"end\":53472,\"start\":53466},{\"end\":53487,\"start\":53479},{\"end\":53838,\"start\":53831},{\"end\":53854,\"start\":53845},{\"end\":53868,\"start\":53864},{\"end\":53883,\"start\":53875},{\"end\":53898,\"start\":53891},{\"end\":54271,\"start\":54261},{\"end\":54291,\"start\":54280},{\"end\":54306,\"start\":54299},{\"end\":54319,\"start\":54315},{\"end\":54336,\"start\":54329},{\"end\":54730,\"start\":54717},{\"end\":54750,\"start\":54739},{\"end\":54765,\"start\":54760},{\"end\":54785,\"start\":54774},{\"end\":54792,\"start\":54789},{\"end\":55213,\"start\":55208},{\"end\":55227,\"start\":55221},{\"end\":55234,\"start\":55229},{\"end\":55629,\"start\":55611},{\"end\":55636,\"start\":55631},{\"end\":55645,\"start\":55640},{\"end\":55650,\"start\":55647},{\"end\":56191,\"start\":56186},{\"end\":56568,\"start\":56553},{\"end\":56588,\"start\":56575},{\"end\":56597,\"start\":56590},{\"end\":57060,\"start\":57055},{\"end\":57078,\"start\":57071},{\"end\":57431,\"start\":57425},{\"end\":57439,\"start\":57433},{\"end\":57907,\"start\":57900},{\"end\":57918,\"start\":57909},{\"end\":57939,\"start\":57920},{\"end\":58174,\"start\":58170},{\"end\":58195,\"start\":58186},{\"end\":58403,\"start\":58388},{\"end\":58683,\"start\":58677},{\"end\":58690,\"start\":58685},{\"end\":58700,\"start\":58692},{\"end\":58707,\"start\":58704},{\"end\":58717,\"start\":58711},{\"end\":58725,\"start\":58719},{\"end\":58736,\"start\":58727},{\"end\":58745,\"start\":58740},{\"end\":58758,\"start\":58747},{\"end\":58769,\"start\":58762},{\"end\":58778,\"start\":58771},{\"end\":58792,\"start\":58785},{\"end\":58804,\"start\":58796},{\"end\":58814,\"start\":58806},{\"end\":58825,\"start\":58818},{\"end\":58836,\"start\":58827},{\"end\":58845,\"start\":58840},{\"end\":58854,\"start\":58849},{\"end\":58864,\"start\":58858},{\"end\":58875,\"start\":58868},{\"end\":58888,\"start\":58877},{\"end\":59545,\"start\":59533},{\"end\":59566,\"start\":59555},{\"end\":59573,\"start\":59568},{\"end\":59952,\"start\":59946},{\"end\":59967,\"start\":59963},{\"end\":59976,\"start\":59973},{\"end\":59987,\"start\":59980},{\"end\":60006,\"start\":59998},{\"end\":60015,\"start\":60008},{\"end\":60344,\"start\":60339},{\"end\":60565,\"start\":60563},{\"end\":60579,\"start\":60575},{\"end\":60893,\"start\":60888},{\"end\":60909,\"start\":60902},{\"end\":61187,\"start\":61181},{\"end\":61204,\"start\":61198},{\"end\":61223,\"start\":61217},{\"end\":61485,\"start\":61478},{\"end\":61692,\"start\":61688},{\"end\":61709,\"start\":61701},{\"end\":61726,\"start\":61718},{\"end\":61740,\"start\":61732},{\"end\":61755,\"start\":61749},{\"end\":61766,\"start\":61761},{\"end\":61781,\"start\":61777},{\"end\":61791,\"start\":61789},{\"end\":61806,\"start\":61800},{\"end\":62229,\"start\":62224},{\"end\":62239,\"start\":62233},{\"end\":62567,\"start\":62558},{\"end\":62584,\"start\":62576},{\"end\":62599,\"start\":62594},{\"end\":62902,\"start\":62886},{\"end\":62913,\"start\":62906},{\"end\":62922,\"start\":62915},{\"end\":62960,\"start\":62945},{\"end\":62970,\"start\":62962},{\"end\":63244,\"start\":63232},{\"end\":63258,\"start\":63252},{\"end\":63270,\"start\":63264},{\"end\":63279,\"start\":63272},{\"end\":63453,\"start\":63448},{\"end\":63468,\"start\":63463},{\"end\":63487,\"start\":63478},{\"end\":63502,\"start\":63496},{\"end\":63521,\"start\":63513},{\"end\":63865,\"start\":63862},{\"end\":63877,\"start\":63872},{\"end\":63893,\"start\":63887},{\"end\":63912,\"start\":63900},{\"end\":63926,\"start\":63920},{\"end\":63942,\"start\":63936},{\"end\":63958,\"start\":63952},{\"end\":63975,\"start\":63968},{\"end\":64331,\"start\":64328},{\"end\":64347,\"start\":64344},{\"end\":64361,\"start\":64358},{\"end\":64607,\"start\":64597},{\"end\":64618,\"start\":64611},{\"end\":64635,\"start\":64630},{\"end\":64652,\"start\":64645},{\"end\":64657,\"start\":64654},{\"end\":64999,\"start\":64992},{\"end\":65014,\"start\":65008},{\"end\":65026,\"start\":65016},{\"end\":65402,\"start\":65398},{\"end\":65420,\"start\":65412},{\"end\":65835,\"start\":65822},{\"end\":65855,\"start\":65844},{\"end\":65867,\"start\":65862},{\"end\":66236,\"start\":66231},{\"end\":66244,\"start\":66238},{\"end\":66494,\"start\":66490},{\"end\":66513,\"start\":66506},{\"end\":66524,\"start\":66515},{\"end\":66852,\"start\":66836},{\"end\":66867,\"start\":66861},{\"end\":66883,\"start\":66876},{\"end\":66892,\"start\":66885},{\"end\":67271,\"start\":67264},{\"end\":67283,\"start\":67277},{\"end\":67291,\"start\":67285},{\"end\":67662,\"start\":67658},{\"end\":67670,\"start\":67664},{\"end\":67678,\"start\":67672},{\"end\":67686,\"start\":67680},{\"end\":67692,\"start\":67688},{\"end\":67707,\"start\":67694},{\"end\":67714,\"start\":67709},{\"end\":67728,\"start\":67716},{\"end\":67737,\"start\":67730},{\"end\":67754,\"start\":67741},{\"end\":67762,\"start\":67758},{\"end\":67772,\"start\":67768},{\"end\":67780,\"start\":67774},{\"end\":68231,\"start\":68221},{\"end\":68247,\"start\":68238},{\"end\":68266,\"start\":68260},{\"end\":68572,\"start\":68564},{\"end\":68586,\"start\":68580},{\"end\":68590,\"start\":68588}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":46315,\"start\":46075},{\"attributes\":{\"id\":\"b1\"},\"end\":46530,\"start\":46317},{\"attributes\":{\"id\":\"b2\"},\"end\":46991,\"start\":46532},{\"attributes\":{\"id\":\"b3\"},\"end\":47381,\"start\":46993},{\"attributes\":{\"id\":\"b4\"},\"end\":47784,\"start\":47383},{\"attributes\":{\"id\":\"b5\"},\"end\":48007,\"start\":47786},{\"attributes\":{\"id\":\"b6\"},\"end\":48359,\"start\":48009},{\"attributes\":{\"id\":\"b7\"},\"end\":48748,\"start\":48361},{\"attributes\":{\"id\":\"b8\"},\"end\":49197,\"start\":48750},{\"attributes\":{\"id\":\"b9\"},\"end\":49494,\"start\":49199},{\"attributes\":{\"id\":\"b10\"},\"end\":49939,\"start\":49496},{\"attributes\":{\"id\":\"b11\"},\"end\":50241,\"start\":49941},{\"attributes\":{\"id\":\"b12\"},\"end\":50603,\"start\":50243},{\"attributes\":{\"id\":\"b13\"},\"end\":50835,\"start\":50605},{\"attributes\":{\"id\":\"b14\"},\"end\":51219,\"start\":50837},{\"attributes\":{\"id\":\"b15\"},\"end\":51385,\"start\":51221},{\"attributes\":{\"id\":\"b16\"},\"end\":51542,\"start\":51387},{\"attributes\":{\"id\":\"b17\"},\"end\":51906,\"start\":51544},{\"attributes\":{\"id\":\"b18\"},\"end\":52239,\"start\":51908},{\"attributes\":{\"id\":\"b19\"},\"end\":52689,\"start\":52241},{\"attributes\":{\"id\":\"b20\"},\"end\":53035,\"start\":52691},{\"attributes\":{\"id\":\"b21\"},\"end\":53307,\"start\":53037},{\"attributes\":{\"id\":\"b22\"},\"end\":53750,\"start\":53309},{\"attributes\":{\"id\":\"b23\"},\"end\":54144,\"start\":53752},{\"attributes\":{\"id\":\"b24\"},\"end\":54578,\"start\":54146},{\"attributes\":{\"id\":\"b25\"},\"end\":55109,\"start\":54580},{\"attributes\":{\"id\":\"b26\"},\"end\":55456,\"start\":55111},{\"attributes\":{\"id\":\"b27\"},\"end\":56053,\"start\":55458},{\"attributes\":{\"id\":\"b28\"},\"end\":56415,\"start\":56055},{\"attributes\":{\"id\":\"b29\"},\"end\":56904,\"start\":56417},{\"attributes\":{\"id\":\"b30\"},\"end\":57348,\"start\":56906},{\"attributes\":{\"id\":\"b31\"},\"end\":57628,\"start\":57350},{\"attributes\":{\"id\":\"b32\"},\"end\":57825,\"start\":57630},{\"attributes\":{\"id\":\"b33\"},\"end\":58110,\"start\":57827},{\"attributes\":{\"id\":\"b34\"},\"end\":58337,\"start\":58112},{\"attributes\":{\"id\":\"b35\"},\"end\":58513,\"start\":58339},{\"attributes\":{\"id\":\"b36\"},\"end\":59418,\"start\":58515},{\"attributes\":{\"id\":\"b37\"},\"end\":59805,\"start\":59420},{\"attributes\":{\"id\":\"b38\"},\"end\":60295,\"start\":59807},{\"attributes\":{\"id\":\"b39\"},\"end\":60500,\"start\":60297},{\"attributes\":{\"id\":\"b40\"},\"end\":60784,\"start\":60502},{\"attributes\":{\"id\":\"b41\"},\"end\":61140,\"start\":60786},{\"attributes\":{\"id\":\"b42\"},\"end\":61439,\"start\":61142},{\"attributes\":{\"id\":\"b43\"},\"end\":61614,\"start\":61441},{\"attributes\":{\"id\":\"b44\"},\"end\":62078,\"start\":61616},{\"attributes\":{\"id\":\"b45\"},\"end\":62482,\"start\":62080},{\"attributes\":{\"id\":\"b46\"},\"end\":62789,\"start\":62484},{\"attributes\":{\"id\":\"b47\"},\"end\":63222,\"start\":62791},{\"attributes\":{\"id\":\"b48\"},\"end\":63440,\"start\":63224},{\"attributes\":{\"id\":\"b49\"},\"end\":63752,\"start\":63442},{\"attributes\":{\"id\":\"b50\"},\"end\":64272,\"start\":63754},{\"attributes\":{\"id\":\"b51\"},\"end\":64503,\"start\":64274},{\"attributes\":{\"id\":\"b52\"},\"end\":64886,\"start\":64505},{\"attributes\":{\"id\":\"b53\"},\"end\":65245,\"start\":64888},{\"attributes\":{\"id\":\"b54\"},\"end\":65679,\"start\":65247},{\"attributes\":{\"id\":\"b55\"},\"end\":66129,\"start\":65681},{\"attributes\":{\"id\":\"b56\"},\"end\":66431,\"start\":66131},{\"attributes\":{\"id\":\"b57\"},\"end\":66670,\"start\":66433},{\"attributes\":{\"id\":\"b58\"},\"end\":67206,\"start\":66672},{\"attributes\":{\"id\":\"b59\"},\"end\":67501,\"start\":67208},{\"attributes\":{\"id\":\"b60\"},\"end\":68149,\"start\":67503},{\"attributes\":{\"id\":\"b61\"},\"end\":68516,\"start\":68151},{\"attributes\":{\"id\":\"b62\"},\"end\":68734,\"start\":68518}]", "bib_title": "[{\"end\":46127,\"start\":46075},{\"end\":46347,\"start\":46317},{\"end\":46575,\"start\":46532},{\"end\":47063,\"start\":46993},{\"end\":47462,\"start\":47383},{\"end\":47843,\"start\":47786},{\"end\":48077,\"start\":48009},{\"end\":48438,\"start\":48361},{\"end\":48874,\"start\":48750},{\"end\":49272,\"start\":49199},{\"end\":49585,\"start\":49496},{\"end\":50009,\"start\":49941},{\"end\":50336,\"start\":50243},{\"end\":50660,\"start\":50605},{\"end\":50920,\"start\":50837},{\"end\":51606,\"start\":51544},{\"end\":51982,\"start\":51908},{\"end\":52367,\"start\":52241},{\"end\":52773,\"start\":52691},{\"end\":53098,\"start\":53037},{\"end\":53428,\"start\":53309},{\"end\":53822,\"start\":53752},{\"end\":54252,\"start\":54146},{\"end\":55204,\"start\":55111},{\"end\":55602,\"start\":55458},{\"end\":56174,\"start\":56055},{\"end\":56551,\"start\":56417},{\"end\":57043,\"start\":56906},{\"end\":57421,\"start\":57350},{\"end\":57896,\"start\":57827},{\"end\":58160,\"start\":58112},{\"end\":58386,\"start\":58339},{\"end\":58675,\"start\":58515},{\"end\":59524,\"start\":59420},{\"end\":59936,\"start\":59807},{\"end\":60330,\"start\":60297},{\"end\":60553,\"start\":60502},{\"end\":60879,\"start\":60786},{\"end\":61174,\"start\":61142},{\"end\":61472,\"start\":61441},{\"end\":61678,\"start\":61616},{\"end\":62220,\"start\":62080},{\"end\":62550,\"start\":62484},{\"end\":62884,\"start\":62791},{\"end\":64317,\"start\":64274},{\"end\":64988,\"start\":64888},{\"end\":65389,\"start\":65247},{\"end\":66227,\"start\":66131},{\"end\":66486,\"start\":66433},{\"end\":66822,\"start\":66672},{\"end\":67260,\"start\":67208},{\"end\":67649,\"start\":67503},{\"end\":68214,\"start\":68151}]", "bib_author": "[{\"end\":46142,\"start\":46129},{\"end\":46155,\"start\":46142},{\"end\":46171,\"start\":46155},{\"end\":46374,\"start\":46349},{\"end\":46390,\"start\":46374},{\"end\":46397,\"start\":46390},{\"end\":46592,\"start\":46577},{\"end\":46611,\"start\":46592},{\"end\":46625,\"start\":46611},{\"end\":46639,\"start\":46625},{\"end\":46655,\"start\":46639},{\"end\":46667,\"start\":46655},{\"end\":46682,\"start\":46667},{\"end\":46704,\"start\":46682},{\"end\":46717,\"start\":46704},{\"end\":47084,\"start\":47065},{\"end\":47093,\"start\":47084},{\"end\":47107,\"start\":47093},{\"end\":47130,\"start\":47107},{\"end\":47145,\"start\":47130},{\"end\":47161,\"start\":47145},{\"end\":47480,\"start\":47464},{\"end\":47495,\"start\":47480},{\"end\":47512,\"start\":47495},{\"end\":47859,\"start\":47845},{\"end\":48089,\"start\":48079},{\"end\":48104,\"start\":48089},{\"end\":48113,\"start\":48104},{\"end\":48453,\"start\":48440},{\"end\":48471,\"start\":48453},{\"end\":48484,\"start\":48471},{\"end\":48494,\"start\":48484},{\"end\":48510,\"start\":48494},{\"end\":48522,\"start\":48510},{\"end\":48896,\"start\":48876},{\"end\":48911,\"start\":48896},{\"end\":48928,\"start\":48911},{\"end\":49286,\"start\":49274},{\"end\":49302,\"start\":49286},{\"end\":49320,\"start\":49302},{\"end\":49616,\"start\":49587},{\"end\":49632,\"start\":49616},{\"end\":49639,\"start\":49632},{\"end\":49649,\"start\":49639},{\"end\":49661,\"start\":49649},{\"end\":49680,\"start\":49661},{\"end\":49693,\"start\":49680},{\"end\":50031,\"start\":50011},{\"end\":50046,\"start\":50031},{\"end\":50360,\"start\":50338},{\"end\":50368,\"start\":50360},{\"end\":50382,\"start\":50368},{\"end\":50391,\"start\":50382},{\"end\":50679,\"start\":50662},{\"end\":50695,\"start\":50679},{\"end\":50941,\"start\":50922},{\"end\":50961,\"start\":50941},{\"end\":50970,\"start\":50961},{\"end\":50990,\"start\":50970},{\"end\":51256,\"start\":51244},{\"end\":51271,\"start\":51256},{\"end\":51288,\"start\":51271},{\"end\":51418,\"start\":51402},{\"end\":51433,\"start\":51418},{\"end\":51450,\"start\":51433},{\"end\":51622,\"start\":51608},{\"end\":51633,\"start\":51622},{\"end\":51651,\"start\":51633},{\"end\":51660,\"start\":51651},{\"end\":51992,\"start\":51984},{\"end\":52003,\"start\":51992},{\"end\":52029,\"start\":52003},{\"end\":52377,\"start\":52369},{\"end\":52399,\"start\":52377},{\"end\":52406,\"start\":52399},{\"end\":52790,\"start\":52775},{\"end\":52803,\"start\":52790},{\"end\":53118,\"start\":53100},{\"end\":53135,\"start\":53118},{\"end\":53447,\"start\":53430},{\"end\":53459,\"start\":53447},{\"end\":53474,\"start\":53459},{\"end\":53489,\"start\":53474},{\"end\":53840,\"start\":53824},{\"end\":53856,\"start\":53840},{\"end\":53870,\"start\":53856},{\"end\":53885,\"start\":53870},{\"end\":53900,\"start\":53885},{\"end\":54273,\"start\":54254},{\"end\":54293,\"start\":54273},{\"end\":54308,\"start\":54293},{\"end\":54321,\"start\":54308},{\"end\":54338,\"start\":54321},{\"end\":54732,\"start\":54710},{\"end\":54752,\"start\":54732},{\"end\":54767,\"start\":54752},{\"end\":54787,\"start\":54767},{\"end\":54794,\"start\":54787},{\"end\":54805,\"start\":54794},{\"end\":55215,\"start\":55206},{\"end\":55229,\"start\":55215},{\"end\":55236,\"start\":55229},{\"end\":55631,\"start\":55604},{\"end\":55638,\"start\":55631},{\"end\":55647,\"start\":55638},{\"end\":55652,\"start\":55647},{\"end\":56193,\"start\":56176},{\"end\":56570,\"start\":56553},{\"end\":56590,\"start\":56570},{\"end\":56599,\"start\":56590},{\"end\":57062,\"start\":57045},{\"end\":57080,\"start\":57062},{\"end\":57433,\"start\":57423},{\"end\":57441,\"start\":57433},{\"end\":57909,\"start\":57898},{\"end\":57920,\"start\":57909},{\"end\":57941,\"start\":57920},{\"end\":58176,\"start\":58162},{\"end\":58197,\"start\":58176},{\"end\":58405,\"start\":58388},{\"end\":58685,\"start\":58677},{\"end\":58692,\"start\":58685},{\"end\":58702,\"start\":58692},{\"end\":58709,\"start\":58702},{\"end\":58719,\"start\":58709},{\"end\":58727,\"start\":58719},{\"end\":58738,\"start\":58727},{\"end\":58747,\"start\":58738},{\"end\":58760,\"start\":58747},{\"end\":58771,\"start\":58760},{\"end\":58780,\"start\":58771},{\"end\":58794,\"start\":58780},{\"end\":58806,\"start\":58794},{\"end\":58816,\"start\":58806},{\"end\":58827,\"start\":58816},{\"end\":58838,\"start\":58827},{\"end\":58847,\"start\":58838},{\"end\":58856,\"start\":58847},{\"end\":58866,\"start\":58856},{\"end\":58877,\"start\":58866},{\"end\":58890,\"start\":58877},{\"end\":59547,\"start\":59526},{\"end\":59568,\"start\":59547},{\"end\":59575,\"start\":59568},{\"end\":59954,\"start\":59938},{\"end\":59969,\"start\":59954},{\"end\":59978,\"start\":59969},{\"end\":59989,\"start\":59978},{\"end\":60008,\"start\":59989},{\"end\":60017,\"start\":60008},{\"end\":60346,\"start\":60332},{\"end\":60567,\"start\":60555},{\"end\":60581,\"start\":60567},{\"end\":60895,\"start\":60881},{\"end\":60911,\"start\":60895},{\"end\":61189,\"start\":61176},{\"end\":61206,\"start\":61189},{\"end\":61225,\"start\":61206},{\"end\":61487,\"start\":61474},{\"end\":61694,\"start\":61680},{\"end\":61711,\"start\":61694},{\"end\":61728,\"start\":61711},{\"end\":61742,\"start\":61728},{\"end\":61757,\"start\":61742},{\"end\":61768,\"start\":61757},{\"end\":61783,\"start\":61768},{\"end\":61793,\"start\":61783},{\"end\":61808,\"start\":61793},{\"end\":62231,\"start\":62222},{\"end\":62241,\"start\":62231},{\"end\":62569,\"start\":62552},{\"end\":62586,\"start\":62569},{\"end\":62601,\"start\":62586},{\"end\":62904,\"start\":62886},{\"end\":62915,\"start\":62904},{\"end\":62924,\"start\":62915},{\"end\":62962,\"start\":62924},{\"end\":62972,\"start\":62962},{\"end\":63246,\"start\":63226},{\"end\":63260,\"start\":63246},{\"end\":63272,\"start\":63260},{\"end\":63281,\"start\":63272},{\"end\":63455,\"start\":63442},{\"end\":63470,\"start\":63455},{\"end\":63489,\"start\":63470},{\"end\":63504,\"start\":63489},{\"end\":63523,\"start\":63504},{\"end\":63867,\"start\":63855},{\"end\":63879,\"start\":63867},{\"end\":63895,\"start\":63879},{\"end\":63914,\"start\":63895},{\"end\":63928,\"start\":63914},{\"end\":63944,\"start\":63928},{\"end\":63960,\"start\":63944},{\"end\":63977,\"start\":63960},{\"end\":64333,\"start\":64319},{\"end\":64349,\"start\":64333},{\"end\":64363,\"start\":64349},{\"end\":64609,\"start\":64591},{\"end\":64620,\"start\":64609},{\"end\":64637,\"start\":64620},{\"end\":64654,\"start\":64637},{\"end\":64659,\"start\":64654},{\"end\":65001,\"start\":64990},{\"end\":65016,\"start\":65001},{\"end\":65028,\"start\":65016},{\"end\":65404,\"start\":65391},{\"end\":65422,\"start\":65404},{\"end\":65837,\"start\":65815},{\"end\":65857,\"start\":65837},{\"end\":65869,\"start\":65857},{\"end\":66238,\"start\":66229},{\"end\":66246,\"start\":66238},{\"end\":66496,\"start\":66488},{\"end\":66515,\"start\":66496},{\"end\":66526,\"start\":66515},{\"end\":66854,\"start\":66824},{\"end\":66869,\"start\":66854},{\"end\":66885,\"start\":66869},{\"end\":66894,\"start\":66885},{\"end\":67273,\"start\":67262},{\"end\":67285,\"start\":67273},{\"end\":67293,\"start\":67285},{\"end\":67664,\"start\":67651},{\"end\":67672,\"start\":67664},{\"end\":67680,\"start\":67672},{\"end\":67688,\"start\":67680},{\"end\":67694,\"start\":67688},{\"end\":67709,\"start\":67694},{\"end\":67716,\"start\":67709},{\"end\":67730,\"start\":67716},{\"end\":67739,\"start\":67730},{\"end\":67756,\"start\":67739},{\"end\":67764,\"start\":67756},{\"end\":67774,\"start\":67764},{\"end\":67782,\"start\":67774},{\"end\":68233,\"start\":68216},{\"end\":68249,\"start\":68233},{\"end\":68268,\"start\":68249},{\"end\":68574,\"start\":68562},{\"end\":68588,\"start\":68574},{\"end\":68592,\"start\":68588}]", "bib_venue": "[{\"end\":46177,\"start\":46171},{\"end\":46404,\"start\":46397},{\"end\":46747,\"start\":46717},{\"end\":47168,\"start\":47161},{\"end\":47565,\"start\":47512},{\"end\":47887,\"start\":47859},{\"end\":48166,\"start\":48113},{\"end\":48539,\"start\":48522},{\"end\":48956,\"start\":48928},{\"end\":49327,\"start\":49320},{\"end\":49699,\"start\":49693},{\"end\":50074,\"start\":50046},{\"end\":50408,\"start\":50391},{\"end\":50702,\"start\":50695},{\"end\":51018,\"start\":50990},{\"end\":51242,\"start\":51221},{\"end\":51400,\"start\":51387},{\"end\":51707,\"start\":51660},{\"end\":52057,\"start\":52029},{\"end\":52451,\"start\":52406},{\"end\":52848,\"start\":52803},{\"end\":53161,\"start\":53135},{\"end\":53517,\"start\":53489},{\"end\":53928,\"start\":53900},{\"end\":54344,\"start\":54338},{\"end\":54708,\"start\":54580},{\"end\":55267,\"start\":55236},{\"end\":55735,\"start\":55652},{\"end\":56221,\"start\":56193},{\"end\":56644,\"start\":56599},{\"end\":57111,\"start\":57080},{\"end\":57476,\"start\":57441},{\"end\":57699,\"start\":57630},{\"end\":57955,\"start\":57941},{\"end\":58209,\"start\":58197},{\"end\":58413,\"start\":58405},{\"end\":58937,\"start\":58890},{\"end\":59603,\"start\":59575},{\"end\":60035,\"start\":60017},{\"end\":60385,\"start\":60346},{\"end\":60625,\"start\":60581},{\"end\":60946,\"start\":60911},{\"end\":61274,\"start\":61225},{\"end\":61514,\"start\":61487},{\"end\":61836,\"start\":61808},{\"end\":62269,\"start\":62241},{\"end\":62619,\"start\":62601},{\"end\":62989,\"start\":62972},{\"end\":63575,\"start\":63539},{\"end\":63853,\"start\":63754},{\"end\":64369,\"start\":64363},{\"end\":64589,\"start\":64505},{\"end\":65050,\"start\":65028},{\"end\":65444,\"start\":65422},{\"end\":65813,\"start\":65681},{\"end\":66269,\"start\":66246},{\"end\":66533,\"start\":66526},{\"end\":66925,\"start\":66894},{\"end\":67331,\"start\":67293},{\"end\":67800,\"start\":67782},{\"end\":68317,\"start\":68268},{\"end\":68560,\"start\":68518}]"}}}, "year": 2023, "month": 12, "day": 17}