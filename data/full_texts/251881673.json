{"id": 251881673, "updated": "2023-10-05 11:20:38.388", "metadata": {"title": "SVD-GCN: A Simplified Graph Convolution Paradigm for Recommendation", "authors": "[{\"first\":\"Shaowen\",\"last\":\"Peng\",\"middle\":[]},{\"first\":\"Kazunari\",\"last\":\"Sugiyama\",\"middle\":[]},{\"first\":\"Tsunenori\",\"last\":\"Mine\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "With the tremendous success of Graph Convolutional Networks (GCNs), they have been widely applied to recommender systems and have shown promising performance. However, most GCN-based methods rigorously stick to a common GCN learning paradigm and suffer from two limitations: (1) the limited scalability due to the high computational cost and slow training convergence; (2) the notorious over-smoothing issue which reduces performance as stacking graph convolution layers. We argue that the above limitations are due to the lack of a deep understanding of GCN-based methods. To this end, we first investigate what design makes GCN effective for recommendation. By simplifying LightGCN, we show the close connection between GCN-based and low-rank methods such as Singular Value Decomposition (SVD) and Matrix Factorization (MF), where stacking graph convolution layers is to learn a low-rank representation by emphasizing (suppressing) components with larger (smaller) singular values. Based on this observation, we replace the core design of GCN-based methods with a flexible truncated SVD and propose a simplified GCN learning paradigm dubbed SVD-GCN, which only exploits $K$-largest singular vectors for recommendation. To alleviate the over-smoothing issue, we propose a renormalization trick to adjust the singular value gap, resulting in significant improvement. Extensive experiments on three real-world datasets show that our proposed SVD-GCN not only significantly outperforms state-of-the-arts but also achieves over 100x and 10x speedups over LightGCN and MF, respectively.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2208.12689", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/cikm/PengSM22", "doi": "10.1145/3511808.3557462"}}, "content": {"source": {"pdf_hash": "3217578b96a18317b084a85c7210f9357a421f31", "pdf_src": "Arxiv", "pdf_uri": "[\"https://export.arxiv.org/pdf/2208.12689v2.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "543db119ac1cb08c7c78f127f5d8aadd7bd6b843", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/3217578b96a18317b084a85c7210f9357a421f31.txt", "contents": "\nSVD-GCN: A Simplified Graph Convolution Paradigm for Recommendation\nOctober 17-21, 2022\n\nShaowen Peng swpeng95@gmail.com \nKazunari Sugiyama kaz.sugiyama@i.kyoto-u.ac.jp \n\nKyoto University Kyoto\nJapan\n\n\nTsunenori Mine\nKyoto University\nJapan\n\n\nKyushu University Fukuoka\nJapan\n\nSVD-GCN: A Simplified Graph Convolution Paradigm for Recommendation\n\nCIKM '22\nAtlanta, GA, USAOctober 17-21, 202210.1145/3511808.3557462ACM Reference Format: Shaowen Peng, Kazunari Sugiyama, and Tsunenori Mine. 2022. SVD-GCN: A Simplified Graph Convolution Paradigm for Recommendation. In Proceed-ings of the 31st ACM International Conference on Information and Knowledge Management (CIKM '22), October 17-21, 2022, Atlanta, GA, USA. ACM, New York, NY, USA, 10 pages. https://Collaborative Filtering, Graph Convolutional Network\nWith the tremendous success of Graph Convolutional Networks (GCNs), they have been widely applied to recommender systems and have shown promising performance. However, most GCNbased methods rigorously stick to a common GCN learning paradigm and suffer from two limitations: (1) the limited scalability due to the high computational cost and slow training convergence; (2) the notorious over-smoothing issue which reduces performance as stacking graph convolution layers. We argue that the above limitations are due to the lack of a deep understanding of GCN-based methods. To this end, we first investigate what design makes GCN effective for recommendation. By simplifying LightGCN, we show the close connection between GCN-based and low-rank methods such as Singular Value Decomposition (SVD) and Matrix Factorization (MF), where stacking graph convolution layers is to learn a low-rank representation by emphasizing (suppressing) components with larger (smaller) singular values. Based on this observation, we replace the core design of GCN-based methods with a flexible truncated SVD and propose a simplified GCN learning paradigm dubbed SVD-GCN, which only exploits -largest singular vectors for recommendation. To alleviate the over-smoothing issue, we propose a renormalization trick to adjust the singular value gap, resulting in significant improvement. Extensive experiments on three real-world datasets show that our proposed SVD-GCN not only significantly outperforms state-of-the-arts but also achieves over 100x and 10x speedups over LightGCN and MF, respectively.CCS CONCEPTS\u2022 Information systems \u2192 Recommender systems.\n\nINTRODUCTION\n\nWith rapid development of the Internet and web services, recommender systems have been playing an important role in people's daily life. As a fundamental task for recommendation, Collaborative Filtering (CF) focuses on digging out the user preference from past user-item interactions, and has received much attention for decades. One of the most widely used CF methods, low-rank matrix factorization (MF) [21], characterizes user/item as latent vectors in an embedding space and estimates ratings as the cosine similarity between user and item latent vectors. To overcome the drawback of MF that a linear function is inefficient to capture complex user behaviour, subsequent works incorporate side information (e.g., user reviews, image data, temporal information, etc.) [3,6,16] and exploit advanced algorithms [11,30,33] to infer user preference.\n\nHowever, traditional CF methods heavily rely upon the quality of interactions as they can only learn the direct user-item relations. Therefore, they always show poor performance due to the common data sparsity issue in practice. Recently, Graph Convolutional Networks (GCNs) [19] have shown great potential in various fields including social network analysis [5,36] and recommender systems [2,38]. Much research effort has been devoted to adapt GCNs for recommendation, such as augmenting GCNs with other advanced algorithms [15,31,35], simplifying GCNs to improve training efficiency and model effectiveness [4,10,24], and so on. By representing user-item interactions as a bipartite graph, the core idea of GCNs is to repeatedly propagate user and item embeddings on the graph to aggregate higher-order collaborative signals, thereby learning high quality embeddings even with limited interactions. Despite its effectiveness, most existing GCN-based methods suffer from the following limitations:\n\n\u2022 The core step of GCNs is implemented by repeatedly multiplying by an adjacency matrix, resulting in high computational cost and poor scalability. \u2022 As shown in many works [22,40], stacking graph convolution layers tends to cause the overs-smoothing issue, resulting in similar user/item representations and reducing the recommendation accuracy. As a result, most existing GCN-based CF methods remain shallow (two, three layers at most). \u2022 Unlike traditional CF methods, user/item representations are contributed from tremendous higher-order neighborhood, making the model difficult to train. Some GCN-based CF methods such as LightGCN requires about 800 epochs to reach the best accuracy, which further increases the training cost.\n\nWe argue that the above limitations are due to the lack of a deep understanding of GCNs. Thus, in this work, we aim to figure out: what is the core design making GCNs effective for recommendation?\n\nBased on our answer to this question, we propose a scalable and simple GCN learning paradigm without above limitations.\n\nTo this end, we first dissect LightGCN, a linear GCN-based CF method which only exploits neighborhood aggregation and removes other designs. By simplifying LightGCN, we show that it is closely related to low-rank CF methods such as Singular Value Decomposition (SVD) and low-rank Matrix Factorization (MF), where stacking graph convolution layers is to learn a low-rank representation by emphasizing (suppressing) the components with larger (smaller) singular values. With empirical analysis, we further show that only a very few components corresponding to -largest singular values contribute to recommendation performance, whereas most information (over 95% on the tested data) are noisy and can be removed. Based on the above analysis, we replace the core component of GCNs (i.e., neighborhood aggregation) with a flexible truncated SVD and propose a simplified GCN learning paradigm dubbed SVD-GCN. Specifically, SVD-GCN only requires a very few ( -largest) singular values (vectors) and model parameters (less than 1% of MF's on the tested data) for prediction. To alleviate the over-smoothing issue, we propose a renormalization trick to adjust the singular value gap, making important features of interactions well preserved, thereby resulting in significant improvement. Furthermore, to make the best of interactions, we augment SVD-GCN with user-user and item-item relations, leading to further improvement. Since the superiority of GCNs over traditional CF methods lies in the ability to augment interactions with higher-order collaborative signals, we only use 20% of the interactions for training to evaluate the robustness and effectiveness of GCN designs. The main contributions of this work are summarized as follows:\n\n\u2022 By showing the connection between GCN-based and low-rank CF methods, we provide deep insight into GCN-based CF methods, that they contribute to recommendation in the same way as low-rank methods. \u2022 Distinct from the GCN learning paradigm that most GCN-based methods rigorously sticking to, we propose a simplified formulation of GCNs dubbed SVD-GCN, which only exploits -largest singular values and vectors and is equipped with a lighter structure than MF. \u2022 To tackle the over-smoothing issue, we propose a renormalization trick to adjust the singular value gap to assure that important features from interactions are well preserved, leading to significant improvement. \u2022 Extensive experiments on three datasets show that our proposed SVD-GCN outperforms state-of-the-art with higher training efficiency and less running time.\n\n\nPRELIMINARIES 2.1 GCN learning paradigm for CF\n\nWe summarize a common GCN learning paradigm for CF. Given the user set U, item set I and an interaction matrix R \u2208 {0, 1} | U |\u00d7 | I | , we define a bipartite graph G = (V, E), where the node set V = U \u222a I contains all users and items, the edge set E = R + is represented by observed interactions, where R + = { = 1| \u2208 U, \u2208 I}. Each user/item is considered as a node on the graph and parameterized as an embedding vector e /e \u2208 R . The core idea of GCNs is to update user and item embeddings by propagating them on the graph. The adjacency relations are represented as:\nA = 0 R R 0 .(1)\nThe updating rule of GCNs is formulated as follows:\nH ( +1) = \u00c3 H ( ) W ( +1) ,(2)\nwhere\u00c3 = D -1 2 AD -1 2 is a symmetric normalized adjacency matrix, D is a diagonal node degree matrix. The initial state is\nH (0) = E,\nwhere E \u2208 R ( | U |+|I |)\u00d7 contains users' and items' embedding vectors. Recent works [4,10] show the non-linear activation function (\u00b7) and feature transformations W ( +1) are redundant for CF , the above updating rule can be simplified as follows:\nH ( ) =\u00c3 E.(3)\nThe final embeddings are generated by accumulating the embeddings at each layer through a pooling function:\nO = pooling H ( ) | = {0, 1, \u00b7 \u00b7 \u00b7 , } .(4)\nFinally, an interaction is estimated as the inner product between a user's and an item's final embedding:\n= o o .(5)\n\nLow-Rank Methods\n\nLow rank representation plays a fundamental role in modern recommender systems [17]. The core idea of low-rank methods is inspired by Singular Value Decomposition (SVD):\nR = U ( ) V \u2248 \u2211\ufe01 =1 u v .(6)\nThe interaction matrix can be decomposed to three matrices, where the column of [U and V (i.e., u and v )] and are [left and right singular vectors] and singular value, respectively; 1 > 2 > \u00b7 \u00b7 \u00b7 \u2265 0; (\u00b7) is the diagonalization operation. Since the components with larger (smaller) singular values contribute more (less) to interactions, we can approximate R with only -largest singular values. Alternatively, we can learn low-rank representations in a dynamical way through matrix factorization (MF) [21]:\nmin \u2211\ufe01 ( , ) \u2208R + \u2212 e e 2 2 + \u2225e \u2225 2 2 + \u2225e \u2225 2 2 ,(7)\nwhere is the strength for regularization. Each user and item is represented as a trainable vector with dimension \u2264 min(|U| , |V |). By optimizing the following objective function, the model is expected to learn important features from interactions (e.g., components corresponding to -largest singular values).\n\n\nMETHODOLOGY 3.1 Connections Between GCNs and SVD\n\nAs activation functions and feature transformations have been shown ineffective for CF [10], we focus on LightGCN whose final embeddings are generated as follows:  where the pooling function is 1 +1 . If we take a closer look at the power of adjacency matrix\u00c3 , we have the following observation:\nO = \u2211\ufe01 =0 H ( ) + 1 = \u2211\ufe01 =0\u00c3 + 1 E,(8)A = \uf8f1 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f2 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f3 \uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 RR 2 0 0 RR 2 \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb = {0, 2, 4, \u00b7 \u00b7 \u00b7 } \uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 0R RR -1 2 R RR -1 2 0 \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb = {1, 3, 5, \u00b7 \u00b7 \u00b7 }.(9)\nFollowing the definition of\u00c3,R = D\n-1 2 RD -1 2 ,\nwhere D and D are the node degree matrices for users and items, respectively. Then, we can split Equation (8) as follows:\nO = ={0,2,4,\u00b7\u00b7\u00b7 } RR 2 E + ={1,3,5,\u00b7\u00b7\u00b7 }R RR -1 2 E + 1 , O = ={0,2,4,\u00b7\u00b7\u00b7 } RR 2 E + ={1,3,5,\u00b7\u00b7\u00b7 }R RR -1 2 E + 1 .(10)\nThe first and second terms represent the messages from homogeneous (even-hops) and heterogeneous (odd-hops) neighborhood, O and O are final embeddings for user and items, E and E are embedding matrices for users and items, respectively. Similar to the definition in Section 2.2, let P, Q, and denote the stacked left, right singular vectors, and singular value forR, respectively, and we formulate the following theorem. Theorem 1. The adjacency relations in Equation (10) can be rewritten as the following forms:\nRR = P 2 P , RR = Q 2 Q ,(11)\nR RR\n-1 2 = P Q , R RR -1 2 = Q P .(12)\nFollowing Theorem 1, we can rewrite Equation (10) as: can be considered as weights of singular vectors when considering even and odd hop neighbors, respectively. We illustrate the normalized weights in Figure 2 (a) and (b), and make the following observation: Observation 1. As stacking more graph convolution layers, the goal of GCNs is to learn a low-rank representation by stressing (suppressing) more components with larger (smaller) singular values.\nO = P ={0,2,\u00b7\u00b7\u00b7 } + 1 P E + P ={1,3,\u00b7\u00b7\u00b7 } + 1 Q E , O = Q ={0,2,\u00b7\u00b7\u00b7 } + 1 Q E + Q ={1,3,\u00b7\u00b7\u00b7 } + 1 P E .(13)\nWe further observe that:\nO = p * \u2299 ={0,2,\u00b7\u00b7\u00b7 } + 1 P E + p * \u2299 ={1,3,\u00b7\u00b7\u00b7 } + 1 Q E ,(15)\nwhere is a vector containing all singular values, p * is the -th row vector, \u2299 represents the element-wise multiplication. We can see P E and Q E are common terms for distinct users/items, what makes representations unique lies in the term in parentheses.\nAssumption 1. P E and Q E are redundant.\nOn the other hand, the above two terms play a important role constituting the core design of GCNs (i.e., neighborhood aggregation), replacing or removing them leads to a new learning paradigm without explicitly aggregating neighborhood. To verify this assumption, we evaluate three models: (1) the original model Equation (13);\n\n(2) we simply replace P E and P E with two different weight matrices; (3) we use a shared weight matrix based on (2).\n\nThe results in Figure 1     aggregation is not necessary for GCNs; (2) The power of GCNs for CF does not heavily rely on model parameters, since reducing parameters (by half) does not reduce the accuracy and even results in faster convergence. Based on the model (3), we can merge the two terms in Equation (13) and simplify it as:\nO = P =0 + 1 W, O = Q =0 + 1 W,(16)\nand name it SVD-LightGCN. We can interpret it as a two-step procedure. We first obtain a weighted singular matrices by assigning the weight =0 +1 to singular vectors (i.e., p and q ); then, we learn a condensed embeddings of the singular vectors through a feature transformation W. Figure 2 (c) shows the goal of SVD-LightGCN is also to learn a low-rank representation, where the weights of singular vectors are adjustable through . We also observe that: Observation 2. SVD is a special case of SVD-LightGCN where W = I and = = 1 2 (fixed to a square root).\n\n\nAnalysis on SVD-LightGCN\n\nTraining Efficiency. Observation 1 provides an alternative way to build GCNs, that we can directly focus on the weights over singular vectors instead of stacking layers. However, retrieving all singular vectors is computationally expensive and not applicable on large datasets as well. On the other hand, Observation 1 implies that most small singular values are not so helpful for recommendation. To further verify this observation, we compare SVD-LightGCN and SVD-LightGCN-T which only exploits -largest singular values and vectors, and report the accuracy of them in Figure 1 (c) and (d), where x-axis represents the singular vector ratio: min( | U |, |I |) .\n\nWe can see SVD-LightGCN-T with only the top 1% largest singular values and vectors outperforms SVD-LightGCN which exploits all singular vectors, and the best accuracy is achieved at 4% on Ci-teULike, 6% on ML-100K. This finding not only shows that most small singular values and vectors are noisy that even reduces the performance, but also helps largely reduce the training cost and improve the training efficiency. For instance, retrieving 4% of the singular vectors and values only takes 1.8s on CiteULike, the learning parameters ( ) are merely 1% of that of MF and LightGCN (|U| + |I| ).\n\nOver-Smoothing. Users and items tend to have the same representations when the model layer is large enough [22]. Theorem 2. The maximum singular value ofR is 1.\n\nAs shown from Figure 2 (b), the larger singular values are further emphasized as increasing the model layers. Following Theorem 2, if we further increase the layer :\nlim \u2192\u221e = =0 +1 =0 max +1 \u2192 0,(17)\nwhere the weights of any singular vectors are reduced to 0 compared with the largest one max , where user/item representations are only contributed by the largest singular vector. Thus, increasing model layers does not necessarily lead to better representations and might instead cause information loss. The over-smoothing issue lies in the gap between singular values, where it is enlarged as stacking layers, which suppresses some important information that matters for recommendation. To alleviate this issue, we define a renormalized interaction matrix as:\nR = (D + I) -1 2 R(D + I) -1 2 where \u2265 0. Theorem 3. Given the singular value of R, max \u2264 max max+\nwhere max is the maximum node degree.\n\nThe maximum singular value becomes smaller as increasing , indicating a smaller gap. On the other hand, a too small gap fails to emphasize the difference of importance of different components (i.e., the component with a larger singular value is more important). Thus, we can adjust to regulate the gap to assure that important information is well preserved and to adapt to different datasets.\n\nFurthermore, the weighting function is a crucial design as it controls the weights of singular vectors, while LightGCN adopts a polynomial in a heuristic way. Let (\u00b7) denotes the weighting function. Basically, we can parameterize (\u00b7) with advanced algorithms to dynamically learn the weights of singular vectors. Alternatively, if we consider (\u00b7) as a static continuous function of singular values , it is expected to weight the singular vectors through a function with easy-to-adjust hyperparameters instead of by repeatedly increasing the model layer . In addition, by replacing the polynomial in LightGCN with (\u00b7), following the Taylor series ( ) = =0 , we can rewrite Equation (8) as:\nO = \u2211\ufe01 =0\u00c3 E,(18)\nwhere is ( )'s -th order derivative at 0, is (\u00b7)'s highest order. From a spatial perspective, is also the contribution of -th order neighborhood, and corresponds to the farthest neighborhood being incorporated. Intuitively, it is expected that user/item representations are constructed from as many positive neighborhood signals as possible (i.e., > 0 and \u2192 \u221e), implying that (\u00b7) is infinitely differentiable with any-order derivatives positive.\n\n\nSVD-GCN\n\nBased on the analysis in Section 3.2, we formulate the user and item representations as follows:\nO = P ( ) ( ( )) W, O = Q ( ) ( ( )) W,(19)\nwhere P ( ) and Q ( ) are composed of -largest left and right singular vectors of R, respectively. Our initial attempt is to dynamically model the importance of singular vectors through a neural network given singular values as the input. However, we found that such a design underperforms static designs in most cases, and speculate that the reason is due to the data sparsity on CF. Unlike other recommendation tasks with rich side information, the only available data is the user/item ID besides interactions, which increases the difficulty to learn the intrinsic data characteristics. Based on previous analysis in Section 3.2, extensive experiments show that an exponential kernel [20] achieves superior accuracy on the tested data, thus we set ( ) = , where is a hyperparameter to adjust the extent of emphasis over larger singular values (i.e., a larger (smaller) emphasizes the importance of larger (smaller) singular values more). We will also compare different (\u00b7) designs in Section 4.3. Unlike conventional GCNs updating all user/item embeddings simultaneously in a matrix form resulting in a large spatial complexity, we can train SVD-GCN in a node form with more flexibility as:\no = p \u2299 W, o = q \u2299 W,(20)\nwhere p and q are the rows of P ( ) and Q ( ) , respectively; is a vector containing all singular values. Note that the elementwise multiplication does not involve parameters thus can be precomputed. Then, inspired by BPR loss [26], we formulate the loss function as follows:\nL = \u2211\ufe01 \u2208U \u2211\ufe01 ( , + ) \u2208R + ,( , -)\u2209R + ln o o + \u2212 o o -.(21)\nAs shown in Equation (10) Similarly, we learn the relations on G via the following loss:\nL = \u2211\ufe01 \u2208I \u2211\ufe01 ( , + ) \u2208E ,( , -)\u2209E ln o o + \u2212 o o -.(23)\nFinally, we propose the following four SVD-GCN variants:\nSVD-GCN-B : L = L main + \u2225\u0398\u2225 2 2 , SVD-GCN-U : L = L main + L user + \u2225\u0398\u2225 2 2 , SVD-GCN-I : L = L main + L item + \u2225\u0398\u2225 2 2 , SVD-GCN-M : L = L main + L user + L item + \u2225\u0398\u2225 2 2 ,(24)\nwhere \u0398 denotes the model parameters. Besides the above variants, to evaluate the effect of the feature transformation, we propose a non-parametric method SVD-GCN-S by removing W.\n\n\nDiscussion\n\n\nModel\n\nComplexity. The complexity of SVD-GCN mainly comes from two parts. We first retrieve singular vectors through SVD for the low-rank matrix [8], with a complexity as: O ( R + + 2 |U| + 2 |I|). We run the algorithm on GPU and only require a very few singular vectors, which only costs several seconds. Except for SVD-GCN-S, other variants require training with time complexity as O ( R + ( + 1) ), which is comparable to MF: R + , where denotes the number of epochs. On the other hand, the model parameters of MF is | U |+|I | time that of GCN-SVD. Overall, SVD-GCN is lighter than MF, and we will show more quantitative results in terms of efficiency in Section 4.2.\n\n\nComparison with GCN-based CF Methods.\n\nCompared with conventional GCN-based methods, GCN-SVD replaces neighborhood aggregation with a truncated SVD and significantly reduces the model parameters. Overall, SVD-GCN is equipped with a lighter structure and more scalable. Recent proposed work UltraGCN [24] simplifies LightGCN by replacing neighborhood aggregation with a weighted MF and shows lower complexity:\nmax \u2211\ufe01 \u2208U, \u2208N , e e ,(25)\nwhere , is obtained from single-layer LightGCN. However, Ul-traGCN improves based on single-layer LightGCN, which can only exploit the first order neighborhood and losses the ability of incorporating high-order neighborhood to augment training interactions. On the other hand, SVD-GCN is derived from any-layer LightGCN and we further generalize it to the situation of infinite layers, hence maximizes the power of GCNs.\n\n\nEXPERIMENTS\n\nIn this section, we comprehensively evaluate our proposed SVD-GCN. The rest of this section is organized as follows: we introduce experimental settings in Section 4.1, compare baselines with SVD-GCN in terms of recommendation accuracy and training efficiency in Section 4.2; in Section 4.3, we dissect SVD-GCN to show the effectiveness of our proposed designs and how different hyperparameter settings (i.e., , , , , and ) affect performance.  Figure 1 are based on CiteULike 1 and ML-100K [9]. To demonstrate the effectiveness of our proposed methods on more datasets and to justify the previous analysis, we evaluate SVD-GCN on three other datasets: Gowalla [34], Yelp [12], and ML-1M [9]. Since we focus on implicit feedback, we only keep user/item ID and transform feedbacks to binary ratings. Table 1 lists statistics of datasets. We adopt two widely-used metrics: Recall and nDCG [14] to evaluate our methods. Recall measures the ratio of the relevant items in the recommended list to all relevant items in test sets, while nDCG takes the ranking into consideration by assigning higher scores to items ranking higher. The recommendation list is generated by ranking unobserved items and truncating at position . Since the advantage of GCN-based methods over traditional CF methods is the ability of leveraging high-order neighborhood to augment training data, thereby alleviating the data sparsity, we only use 20% of interactions for training and leave the remaining for test to evaluate the model robustness and stability; we randomly select 5% from the training set as validation set for hyper-parameter tuning and report the average accuracy on test sets.\n\n\nBaselines.\n\nWe compare our methods with the following competing baselines, where the hyperparameter settings are based on the results of the original papers:\n\n\u2022 BPR [26]: This is a stable and classic MF-based method, exploiting a Bayesian personalized ranking loss for personalized rankings. \u2022 EASE [29]: This is a neighborhood-based method with a closed form solution and show superior performance to many traditional CF methods. \u2022 LightGCN [10]: This method uses a light GCN architecture for CF by removing activations functions and feature transformation. We use a three-layer architecture as the baseline. \u2022 LCFN [39]: This model replaces the original graph convolution with a low pass graph convolution to remove the noise from interactions for recommendation. We set = 0.005 and use a single-layer architecture. \u2022 SGL-ED [35]: This model generates different node views by randomly removing the edge connections and maximizes their agreements, and the proposed self-supervised loss is implemented on LightGCN [10]. We set = 0.2, 1 = 0.1, = 0.1, and use a three-layer architecture.\n\n\u2022 UltraGCN [24]: This model simplifies LightGCN by replacing neighborhood aggregation with a weighted MF, which shows faster convergence and less complexity. We remove some popular GCN-based methods such as Pinsage [38], NGCF [34], and SpectralCF [41] as aforementioned baselines have already shown superiority over them.\n\n\nImplementation Details.\n\nWe implemented the proposed model based on PyTorch 2 and released the code on Github 3 . For all models, We use SGD as the optimizer, the embedding size is set to 64, the regularization rate is set to 0.01 on all datasets, the learning rate is tuned amongst {0.001, 0.005, 0.01, \u00b7 \u00b7 \u00b7 , 1}; without specification, the model parameters are initialized with Xavier Initialization [7]; the batch size is set to 256. We report other hyperparameter settings in the next subsection.\n\n\nComparison\n\n\nPerformance.\n\nWe report the accuracy of baselines and our proposed GCN-SVD variants in Table 2, and have the following observations:\n\n\u2022 Overall, GCN-based methods outperforms traditional CF methods, indicating the effectiveness of GCNs for CF and demonstrating the importance of augmenting training interactions by incorporating high-order neighborhood information, thereby alleviating data sparsity. \u2022 Among all baselines, SGL-ED achieves the best across all datasets, while our proposed SVD-GCNs show consistent improvements over SGL-ED, indicating the effectiveness and superiority over conventional GCN designs. UltraGCN shows relatively poor performance among GCN-based methods. As shown in our previous analysis in Section 3.4.2, UltraGCN improves based on single-layer GCN which fails to leverage the higher-order neighborhood, thus cannot perform stably with limited interactions. \u2022 Since our key contribution is to replace neighborhood aggregation, the improvement is more clear if we compare with pure GCN-based methods such as LightGCN. SVD-GCN outperforms LightGCN on Yelp, ML-1M, and Gowalla by 53.6%, 11.7%, and 29.0%, respectively, in terms of nDCG@10. The improvements over sparse data tend to be more significant, indicating the stability of SVD-GCN under extreme data sparsity. \u2022 Among SVD-GCN variants, the basic model SVD-GCN-B and SVD-GCN-S already outperform all baselines by a large margin. In addition, introducing user-user and item-item relations results in further improvement. We also notice that mixing user-user and item-item relations does not necessarily leads to better accuracy, and we speculate that the reason might be related to the data density. On the dense data such as ML-1M where the user-item interactions are relatively sufficient, the improvement by introducing user-user and item-item relations is not as significant as that of sparser datasets, and incorporating both relations even performs worse; while on the sparest data Gowalla, introducing auxiliary relations shows consistent improvements.\n\n\nTraining Efficiency.\n\nThe results shown in this subsection are obtained on a machine equipped with AMD Ryzen 9 5950X and    GeForce RTX 3090. Figure 3 shows how the preprocessing time and accuracy change with , where SOTA is the best baseline. The best accuracy is achieved at = 90, = 60, and = 60, where the preprocessing time is 3.07s, 0.82s, and 1.74s, on Gowalla, ML-1M, and Yelp, respectively. Overall, only 1% singular vectors are required on ML-1M, and less than 0.5% singular vectors are required on Gowalla and Yelp, when the model reaches the best accuracy. Table 3     constantly increasing the value of and . The best accuracy is achieved at = 0.5, while the optimal (0.9 on Gowalla and 0.7 on Yelp) is larger than . One reasonable explanation is that item-item relations are usually sparser (0.21% on Gowalla and 0.33% on Yelp) than user-user relations (0.41% on Gowalla and 0.48% on Yelp).\n=10 =20 =10 =20 =10 =20 =10 =20 =10 =20 =10 =20 BPR 0.\n\nDo\n\nWe Need Feature Transformation? By comparing SVD-GCN-S and SVD-GCN-B, we can see W results in worse accuracy on Gowalla and Yelp and only a slight improvement on ML-1M, which shows that feature transformation does not help much learn user-item interactions. On the other hand, we can identify the positive effect of W when incorporating user-user and item-item relations, which leads to improvement compared with SVD-GCN-B. We speculate that the ineffectiveness of feature transformation is related to the data density, where the intrinsic characteristic of sparse data such as user-item interactions is difficult to learn, while user-user and item-item relations are much denser thus is easier to learn. Overall, SVD-GCN can achieve superior accuracy without any model training, implying that the key design making GCN effective for recommendation lies in a good low-rank representation.   . Surprisingly, we have the same observation on other datasets. Theoretical analysis on this interesting phenomenon is beyond the scope of this work, we leave it for future work. Figure 6 shows the accuracy with varying . The accuracy first increases as increasing , then starts dropping after reaching the best performance at = 2.5 on ML-1M, = 6.0 on Gwoalla; there is a similar trend on Yelp that the best accuracy is achieved at = 4.0. We observe that tends to be larger on sparser data, implying that the large singular values are more important on the sparser data. We speculate that there is less useful information on sparser datasets, thus the small singular values contain more noise and should be depressed more than denser datasets.  Table 4. For dynamic designs, we use a neural network to attempt to model the importance of singular vectors with singular values as the input, while it underperforms most static designs, showing that the dynamic design is not suitable for the weighting function. For   \n\n\nEffect of .\n) 0.0882 \u2713 \u00d7 \u2713 0.0899 \u2713 \u2713 \u00d7 1 1\u2212 0.0919 \u2713 \u2713 \u2713 ( > 0) 0.0919 \u2713 \u2713 \u2713 ( < 0) 0.0828 \u00d7 \u00d7 \u2713 Dynamic Neural Network 0.0850\nstatic designs, following the previous analysis in Section 3.2, we list some properties that matter to accuracy: (from left to right) if the function (1) is increasing, (2) has positive taylor coefficients, (3) is infinitely differentiable, and evaluate some functions, where the setting of is based on the best accuracy of each function. We can see the importance of the three properties is (1)\u226b(2)>(3). (1) implies that the larger singular values are assigned higher weights, which is important according to the previous analysis; (2) and (3) suggest if the model can capture neighborhood from any-hops with positive contributions. Overall, the importance of the three properties is (1)\u226b(2)>(3), and the functions satisfying all three properties perform the best.\n\n\nRELATED WORK\n\nCollaborative Filtering (CF) is an extensively used technique in modern recommender systems. Early memory-based CF methods [27] predict user preference by computing the similarity between users or items. Later on, model-based methods become prevalent [21] which characterizes users and items as latent vectors and calculate their dot products to predict the unobserved ratings. Subsequent works focus on modeling complex user-item interactions with advanced algorithms, such as neural network [11,37], attention mechanism [18], transformer [30], and so on. Behind the learning in Euclidean space, some methods [32] explore the potential of learning in non-Euclidean space. On another line, auxiliary information such as social relations [23], review data [1], temporal information [18] etc. is also well incorporated to obtain a better understanding of user preference. The data sparsity issue on recommendation datasets limits the aforementioned traditional CF methods. The development of GCNs helps alleviate this issue by incorporating higher-order neighborhood to facilitate user/item representations, and thus much effort has been made to adapt GCNs to recommendation. Early work such as GC-MC [2] accumulates messages from different neighbors based on the rating for explicit feedbacks; SpectralCF [41] adapts the original graph convolution to CF with implicit feedbacks; NGCF [34] improves based on vanilla GCN [19] by additionally encoding the interactions via an element-wise multiplication. To improve the scalability on large-scale datasets, Ying et al. [38] defines a flexible graph convolution on spatial domain without passing messages with adjacency matrix. By showing the redundancy of feature transformation and non-linear activation function, LightGCN [10] only keeps neighborhood aggregation for recommendation. Recent works fuse other research topics into GCNs, such as contrastive learning [35,42], learning in hyperbolic space [31], negative sampling [13], graph signal processing [25], etc. and achieves further success.\n\nDespite the superior performance that the aforementioned GCNbased methods have achieved, the computational cost of GCNs is much larger than traditional CF methods, making them unscalable on large-scale datasets. Although some works [4,10] reduces the cost to some extent by removing feature transformation and nonlinear activation functions, while the complexity mainly comes from the neighborhood aggregation, which is implemented by multiplying by an adjacency matrix. One recent work UltraGCN [24] further simplifies GCNs by replacing the neighborhood aggregation with a weighted MF, where the weight is obtained from a single-layer LightGCN, which significantly reduces the complexity. However, such a simplification degrades the power of GCNs as it can only capture the first-order neighborhood, and the experimental results also show its ineffectiveness under extreme sparsity. On the other hand, our proposed SVD-GCN is based on comprehensive theoretical and empirical analysis on LightGCN with any layers, whose superiority and effectiveness have been demonstrated through extensive experimental results.\n\n\nCONCLUSION\n\nIn this work, we proposed a simplified and scalable GCN learning paradigm for CF. We first investigated what design makes GCN effective. Particularly, by further simplifying LightGCN, we showed that stacking graph convolution layers is to learn a low-rank representation by emphasizing (suppressing) more components with larger (smaller) singular values. Based on the close connection between GCN-based and low-rank methods, we proposed a simplified GCN formulation by replacing neighborhood aggregation with a truncated SVD, which only exploits -largest singular values and vectors for recommendation. To alleviate over-smoothing issue, we proposed a renormalization trick to adjust the singular value gap, resulting in significant improvement. Extensive experimental results demonstrated the training efficiency and effectiveness of our propose methods.\n\nWe leave two questions for future work. Firstly, since SVD-GCN-S already achieves superior performance and feature transformation only shows positive effect learning user-user and item-item relations, we aim to incorporate user-user and item-item relations without introducing any model parameters (i.e., we improve based on SVD-GCN-S). In addition, we attempt to explain the phenomenon in Section 4.3.3, that why shrinking the singular value gap causes singular values to drop more quickly, thereby making important information to be concentrated in fewer singular vectors.\n\n\nPROOFS 7.1 Proofs of Theorem 1\n\nProof. Following SVD, we know any two singular vectors are orthonormal (i.e., PP = I and QQ = I), thus it is easy to derive the following equations:\nRR = P 2 P , RR = Q 2 Q .(26)\nBy repeating the above Equations times, we obtain Equation (11).\n\nFor simplicity, we let R \u2032 =R RR -1 2 , and R \u2032 = R RR -1 2 . We let P \u2032 , Q \u2032 and \u2032 denote the stacked left singular vectors, right singular vectors and singular value for R \u2032 , respectively. Following Equation (26), we can derive the following equations:\nR \u2032 R \u2032 = RR = P 2 P = P \u2032 \u20322 P \u2032 , R \u2032 R \u2032 = RR = Q 2 Q = Q \u2032 \u20322 Q \u2032 .(27)\nIt is easy to observe that P \u2032 = P, Q \u2032 = Q and \u2032 = . Then, according to SVD, we derive Equation (12). \u25a1\n\n\nProofs of Theorem 2 and 3\n\nProof. We first introduce Rayleigh quotients [28]:\nmin \u2264 x\u00c3x \u2264 max . . |x| = 1,(28)\nwhere min and max are the minimum and maximum eigenvalues of\u00c3, respectively. Then, we can show max = 1:\n1 \u2212 x\u00c3x = x x \u2212 x\u00c3x = \u2211\ufe01 ( , ) \u2208E \u221a \u2212 \u221a 2 \u2265 0.(29)\nIn the meanwhile, we have the following observation:\nA p q = R q R p = p q ,(30)\nwhich implies that \u2208 { min , \u00b7 \u00b7 \u00b7 , max } \u2264 1 with [p , q ] as the eigenvector. By observing the eigenvector of max , if max is also a singular value, we have: p = \u221a D 1 and q = \u221a D 1 where 1 is a vector with all 1 elements. It is easy to verify the solution satisfies SVD:Rq = p , thus max = 1.\n\nGiven R, we can define the corresponding adjacency matrix A. Since the relation in Equation (30) still holds between R and A, we only need to prove max \u2264 max max + .\n\nx Ax = \u2211\ufe01 \n\nFigure 1 :\n1Some empirical results on two datasets (CiteULike and ML-100K).\n\n\n(a) and(b)  show that the performance of the three models are fairly close, and thus: (\n\nFigure 2 :\n2Normalized weights of singular vectors.\n\n\n, in GCN-based CF methods, user/item representations are contributed from three kinds of information flows: user-item, user-user, and item-item relations. Thus, besides the user-item relations, homogeneous (i.e., user-user and item-item) relations also help increase model effectiveness. We define a user-user G = (V , E ), and an item-item graph G = (V , E ), where V = U and V = I; E = {( , )| \u2208 N , \u2208 N } and E = {( , \u210e)|\u210e \u2208 N , \u2208 N },where N and N are the sets of directly connected neighbors for and , respectively. Naturally, we can define the normalized adjacency matrix of G and G as R = R R and R = R R , respectively. According to Equation(26) in Section 7, the eigenvectors of R and R are actually R's left and right singular vectors, respectively; and the eigenvalues are both the square of R's singular values. Thus, G, G and G are closely connected. We formulate the following loss to learn the relations on G :L = \u2211\ufe01 \u2208U \u2211\ufe01 ( , + ) \u2208 E ,( , -)\u2209E ln o o + \u2212 o o -. (22)\n\n\nshows the training time and running epochs of several methods, where the running time includes both preprocessing and training time. Overall, LightGCN is the most time consuming model (3,858s) as it is a conventional GCN model; SVD-GCN-S is the most time efficient model (3.07s) since it does not require model optimization and shows over 1000x speed-up over LightGCN. BPR is the fastest model (1.04s) in terms of training time per epoch, while it still requires hundreds epochs to reach the best accuracy due to the large amount of parameters need to be optimized. Although SVD-GCN variants (excluding SVD-GCN-S) are slightly slower than BPR on training time per epoch, they show fast training convergence as the model parameters are only 0.08% of that of BPR.\n\n\nHomogeneous Relations Affect Performance? The direct comparison between SVD-GCN-B and SVD-GCN-U, SVD-GCN-I, and SVD-GCN-M demonstrates the positive effect of homogeneous relations. Furthermore,Figure 4shows how different and affect the accuracy, where the accuracy increases first then drops as\n\nFigure 3 :\n3How the preprocessing time and accuracy (nDCG@10) vary on on SVD-GCN-B.\n\n\n4.3.3 Effect of Renormalization Trick. We have two observations from Figure 5 (a): as increasing (i.e., shrinking the singular value gap), (1) the accuracy increases first then drops, reaches the best at\n\nFigure 4 :\n4Effect of top 100 singular values with varying .\n\nFigure 5 :\n5Effect of renormalization trick on Yelp. = 3; (2) the model tends to require fewer singular vectors. In Figure 5 (b), as increasing , (1) the maximum singular value becomes smaller, which is consistent with Theorem 3; (2) singular values drops more quickly, which explains why fewer singular vectors are required. For instance, the model with = 0 has more large singular values which contribute significantly to the interactions compared with the model with > 0, thus more singular vectors are required; while the important large singular values are fewer as increasing . In other words, the important information is concentrated in fewer top singular values when we constantly increase\n\n\nChoice of Weighting Function. We show the accuracy of SVD-GCN-S with different weighting functions in\n\nFigure 6 :\n6Effect of on SVD-GCN-S.\n\n=\nholds when = 0. When > 0, max < max max + , since x takes different values at ( ,\n\n\nNow the final embeddings are contributed fromR's singular vectors and values instead of neighborhood. Note that:P \n\n={0,2,\u00b7\u00b7\u00b7 } \n\n+ 1 \nP = \n\u2211\ufe01 ={0,2,\u00b7\u00b7\u00b7 } \n+ 1 \np p . (14) \n\n={0,2,\u00b7\u00b7\u00b7 } \n\n+1 \n\nand ={1,3,\u00b7\u00b7\u00b7 } \n\n+1 \n\n\n\nTable 1 :\n1Statistics of datasetsDatasets \n#User #Item #Interactions Density% \n\nCiteULike 5,551 16,981 \n210,537 \n0.223 \nML-100K \n943 \n1,682 \n100,000 \n6.305 \n\nML-1M \n6,040 \n3,952 \n1,000,209 \n4.190 \nYelp \n25,677 25,815 \n731,672 \n0.109 \nGowalla \n29,858 40,981 \n1,027,370 \n0.084 \n\n4.1 Experimental Settings \n\n4.1.1 Datasets and Evaluation Metrics. We use five public datasets \nin this work, where the results of \n\nTable 2 :\n2Overall performance comparison.Yelp \nML-1M \nGowalla \nnDCG@ \nRecall@ \nnDCG@ \nRecall@ \nnDCG@ \nRecall@ \n\n\nTable 3 :\n3Training time comparison on Gowalla.Model \nTime/Epoch Epochs Running Time Parameters \nLightGCN \n6.43s \n600 \n3,858s \n4.5m \nUltraGCN \n2.55s \n90 \n229.5s \n4.5m \nBPR \n1.04s \n250 \n260.0s \n4.5m \nSVD-GCN-S \n0.00s \n0 \n3.07s \n0.0k \nSVD-GCN-B \n1.28s \n8 \n13.31s \n5.7k \nSVD-GCN-U \n2.06s \n8 \n19.55s \n5.7k \nSVD-GCN-I \n2.18s \n8 \n20.51s \n5.7k \nSVD-GCN-M \n3.05s \n8 \n27.47s \n5.7k \n\n\n\nTable 4 :\n4Accuracy of different weighting functions on Yelp.Design \nFunction \nnDCG@10 \n\nProperty \n(1) \n(2) \n(3) \nIncreasing Pos Coef. Infinite \n\nStatic \n\nlog( \n\nhttps://github.com/js05212/citeulike-a\nhttps://pytorch.org/ 3 https://github.com/tanatosuu/svd_gcn\n\nTopicmf: Simultaneously exploiting ratings and reviews for recommendation. Yang Bao, Hui Fang, Jie Zhang, Proceedings of the 31st AAAI Conference on Artificial Intelligence (AAAI-14. the 31st AAAI Conference on Artificial Intelligence (AAAI-14Yang Bao, Hui Fang, and Jie Zhang. 2014. Topicmf: Simultaneously exploiting rat- ings and reviews for recommendation. In Proceedings of the 31st AAAI Conference on Artificial Intelligence (AAAI-14). 2-8.\n\nRianne Van Den, Thomas N Berg, Max Kipf, Welling, arXiv:1706.02263Graph convolutional matrix completion. arXiv preprintRianne van den Berg, Thomas N Kipf, and Max Welling. 2017. Graph convolu- tional matrix completion. arXiv preprint arXiv:1706.02263 (2017).\n\nAttentive Collaborative Filtering: Multimedia Recommendation with Item-and Component-Level Attention. Jingyuan Chen, Hanwang Zhang, Xiangnan He, Liqiang Nie, Wei Liu, Tat-Seng Chua, Proceedings of the 40th International ACM SIGIR conference on Research and Development in Information Retrieval (SIGIR'17. the 40th International ACM SIGIR conference on Research and Development in Information Retrieval (SIGIR'17Jingyuan Chen, Hanwang Zhang, Xiangnan He, Liqiang Nie, Wei Liu, and Tat- Seng Chua. 2017. Attentive Collaborative Filtering: Multimedia Recommendation with Item-and Component-Level Attention. In Proceedings of the 40th Interna- tional ACM SIGIR conference on Research and Development in Information Retrieval (SIGIR'17). 335-344.\n\nRevisiting graph based collaborative filtering: A linear residual graph convolutional network approach. Lei Chen, Le Wu, Richang Hong, Kun Zhang, Meng Wang, Proceedings of the 34th AAAI Conference on Artificial Intelligence (AAAI-20). the 34th AAAI Conference on Artificial Intelligence (AAAI-20)Lei Chen, Le Wu, Richang Hong, Kun Zhang, and Meng Wang. 2020. Revisiting graph based collaborative filtering: A linear residual graph convolutional network approach. In Proceedings of the 34th AAAI Conference on Artificial Intelligence (AAAI-20). 27-34.\n\nGraph Neural Networks for Social Recommendation. Wenqi Fan, Yao Ma, Qing Li, Yuan He, Eric Zhao, Jiliang Tang, Dawei Yin, Proceedings of the 28th International Conference on World Wide Web (WWW'19. the 28th International Conference on World Wide Web (WWW'19Wenqi Fan, Yao Ma, Qing Li, Yuan He, Eric Zhao, Jiliang Tang, and Dawei Yin. 2019. Graph Neural Networks for Social Recommendation. In Proceedings of the 28th International Conference on World Wide Web (WWW'19). 417-426.\n\nPoi2vec: Geographical Latent Representation for Predicting Future Visitors. Shanshan Feng, Gao Cong, Bo An, Yeow Meng Chee, Proceedings of the 28th AAAI Conference on Artificial Intelligence (AAAI-17. the 28th AAAI Conference on Artificial Intelligence (AAAI-17Shanshan Feng, Gao Cong, Bo An, and Yeow Meng Chee. 2017. Poi2vec: Geo- graphical Latent Representation for Predicting Future Visitors. In Proceedings of the 28th AAAI Conference on Artificial Intelligence (AAAI-17). 102-108.\n\nUnderstanding the difficulty of training deep feedforward neural networks. Xavier Glorot, Yoshua Bengio, Proceedings of the 13th International Conference on Artificial Intelligence and Statistics (AISTATS'10. the 13th International Conference on Artificial Intelligence and Statistics (AISTATS'10Xavier Glorot and Yoshua Bengio. 2010. Understanding the difficulty of train- ing deep feedforward neural networks. In Proceedings of the 13th International Conference on Artificial Intelligence and Statistics (AISTATS'10). 249-256.\n\nFinding Structure with Randomness: Probabilistic Algorithms for Constructing Approximate Matrix Decompositions. Nathan Halko, Joel A Per-Gunnar Martinsson, Tropp, SIAM review. 53Nathan Halko, Per-Gunnar Martinsson, and Joel A Tropp. 2011. Finding Structure with Randomness: Probabilistic Algorithms for Constructing Approximate Matrix Decompositions. SIAM review 53, 2 (2011), 217-288.\n\nThe MovieLens Datasets: History and Context. Maxwell Harper, Joseph A Konstan, ACM Transactions on Interactive Intelligent Systems (TiiS). 5F Maxwell Harper and Joseph A Konstan. 2015. The MovieLens Datasets: History and Context. ACM Transactions on Interactive Intelligent Systems (TiiS) 5, 4 (2015), 1-19.\n\nLightGCN: Simplifying and Powering Graph Convolution Network for Recommendation. Xiangnan He, Kuan Deng, Xiang Wang, Yan Li, Yongdong Zhang, Meng Wang, Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR'20. the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR'20Xiangnan He, Kuan Deng, Xiang Wang, Yan Li, Yongdong Zhang, and Meng Wang. 2020. LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation. In Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR'20). 639-648.\n\nNeural Collaborative Filtering. Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, Tat-Seng Chua, Proceedings of the 26th International Conference on World Wide Web (WWW'17. the 26th International Conference on World Wide Web (WWW'17Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. Neural Collaborative Filtering. In Proceedings of the 26th International Conference on World Wide Web (WWW'17). 173-182.\n\nFast Matrix Factorization for Online Recommendation with Implicit Feedback. Xiangnan He, Hanwang Zhang, Min-Yen Kan, Tat-Seng Chua, Proceedings of the 39th international ACM SIGIR conference on Research and development in Information Retrieval (SIGIR'16. the 39th international ACM SIGIR conference on Research and development in Information Retrieval (SIGIR'16Xiangnan He, Hanwang Zhang, Min-Yen Kan, and Tat-Seng Chua. 2016. Fast Matrix Factorization for Online Recommendation with Implicit Feedback. In Proceedings of the 39th international ACM SIGIR conference on Research and devel- opment in Information Retrieval (SIGIR'16). 549-558.\n\nMixGCF: An Improved Training Method for Graph Neural Network-based Recommender Systems. Tinglin Huang, Yuxiao Dong, Ming Ding, Zhen Yang, Wenzheng Feng, Xinyu Wang, Jie Tang, Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining (KDD'21. the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining (KDD'21Tinglin Huang, Yuxiao Dong, Ming Ding, Zhen Yang, Wenzheng Feng, Xinyu Wang, and Jie Tang. 2021. MixGCF: An Improved Training Method for Graph Neural Network-based Recommender Systems. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining (KDD'21). 665-674.\n\nCumulated Gain-Based Evaluation of IR Techniques. Kalervo J\u00e4rvelin, Jaana Kek\u00e4l\u00e4inen, ACM Transactions on Information Systems (TOIS). 20Kalervo J\u00e4rvelin and Jaana Kek\u00e4l\u00e4inen. 2002. Cumulated Gain-Based Evaluation of IR Techniques. ACM Transactions on Information Systems (TOIS) 20, 4 (2002), 422-446.\n\nDual channel hypergraph collaborative filtering. Shuyi Ji, Yifan Feng, Rongrong Ji, Xibin Zhao, Wanwan Tang, Yue Gao, Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (KDD'20. the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (KDD'20Shuyi Ji, Yifan Feng, Rongrong Ji, Xibin Zhao, Wanwan Tang, and Yue Gao. 2020. Dual channel hypergraph collaborative filtering. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (KDD'20). 2020-2029.\n\nSocial Contextual Recommendation. Meng Jiang, Peng Cui, Rui Liu, Qiang Yang, Fei Wang, Wenwu Zhu, Shiqiang Yang, Proceedings of the 21st ACM International Conference on Information and Knowledge Management (CIKM'12. the 21st ACM International Conference on Information and Knowledge Management (CIKM'12Meng Jiang, Peng Cui, Rui Liu, Qiang Yang, Fei Wang, Wenwu Zhu, and Shiqiang Yang. 2012. Social Contextual Recommendation. In Proceedings of the 21st ACM International Conference on Information and Knowledge Management (CIKM'12). 45-54.\n\nTowards a Better Understanding of Linear Models for Recommendation. Ruoming Jin, Dong Li, Jing Gao, Zhi Liu, Li Chen, Yang Zhou, Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining (KDD'21. the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining (KDD'21Ruoming Jin, Dong Li, Jing Gao, Zhi Liu, Li Chen, and Yang Zhou. 2021. Towards a Better Understanding of Linear Models for Recommendation. In Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining (KDD'21). 776-785.\n\nSelf-attentive Sequential Recommendation. Wang-Cheng Kang, Julian Mcauley, Proceedings of IEEE International Conference on Data Mining (ICDM'18. IEEE International Conference on Data Mining (ICDM'18Wang-Cheng Kang and Julian McAuley. 2018. Self-attentive Sequential Recom- mendation. In In Proceedings of IEEE International Conference on Data Mining (ICDM'18). 197-206.\n\nSemi-Supervised Classification with Graph Convolutional Networks. N Thomas, Max Kipf, Welling, Proceedings of the 5th International Conference on Learning Representations (ICLR'17). the 5th International Conference on Learning Representations (ICLR'17)Thomas N. Kipf and Max Welling. 2017. Semi-Supervised Classification with Graph Convolutional Networks. In Proceedings of the 5th International Conference on Learning Representations (ICLR'17).\n\nDiffusion Kernels on Graphs and Other Discrete Input Spaces. Imre Risi, John D Kondor, Lafferty, Proceedings of the 19th International Conference on Machine Learning (ICML'02. the 19th International Conference on Machine Learning (ICML'02Risi Imre Kondor and John D. Lafferty. 2002. Diffusion Kernels on Graphs and Other Discrete Input Spaces. In Proceedings of the 19th International Conference on Machine Learning (ICML'02). 315-322.\n\nMatrix Factorization Techniques for Recommender Systems. Yehuda Koren, Robert Bell, Chris Volinsky, Computer. 8Yehuda Koren, Robert Bell, and Chris Volinsky. 2009. Matrix Factorization Tech- niques for Recommender Systems. Computer 8 (2009), 30-37.\n\nDeeper Insights into Graph Convolutional Networks for Semi-Supervised Learning. Qimai Li, Zhichao Han, Xiao-Ming Wu, Proceedings of the 32nd AAAI Conference on Artificial Intelligence (AAAI-18. the 32nd AAAI Conference on Artificial Intelligence (AAAI-18Qimai Li, Zhichao Han, and Xiao-Ming Wu. 2018. Deeper Insights into Graph Convolutional Networks for Semi-Supervised Learning. In Proceedings of the 32nd AAAI Conference on Artificial Intelligence (AAAI-18). 3538-3545.\n\nSorec: Social Recommendation Using Probabilistic Matrix Factorization. Hao Ma, Haixuan Yang, Irwin Michael R Lyu, King, Proceedings of the 17th ACM conference on Information and Knowledge Management (ICDM'08. the 17th ACM conference on Information and Knowledge Management (ICDM'08Hao Ma, Haixuan Yang, Michael R Lyu, and Irwin King. 2008. Sorec: Social Recommendation Using Probabilistic Matrix Factorization. In Proceedings of the 17th ACM conference on Information and Knowledge Management (ICDM'08. 931- 940.\n\nUltraGCN: Ultra Simplification of Graph Convolutional Networks for Recommendation. Kelong Mao, Jieming Zhu, Xi Xiao, Biao Lu, Zhaowei Wang, Xiuqiang He, Proceedings of the 30th ACM International Conference on Information & Knowledge Management (CIKM'21. the 30th ACM International Conference on Information & Knowledge Management (CIKM'21Kelong Mao, Jieming Zhu, Xi Xiao, Biao Lu, Zhaowei Wang, and Xiuqiang He. 2021. UltraGCN: Ultra Simplification of Graph Convolutional Networks for Recommendation. In Proceedings of the 30th ACM International Conference on Information & Knowledge Management (CIKM'21). 1253-1262.\n\nLess is More: Reweighting Important Spectral Graph Features for Recommendation. Shaowen Peng, Kazunari Sugiyama, Tsunenori Mine, Proceedings of the 45th International ACM SIGIR conference on Research and Development in Information Retrieval (SIGIR'22. the 45th International ACM SIGIR conference on Research and Development in Information Retrieval (SIGIR'22Shaowen Peng, Kazunari Sugiyama, and Tsunenori Mine. 2022. Less is More: Reweighting Important Spectral Graph Features for Recommendation. In Proceed- ings of the 45th International ACM SIGIR conference on Research and Development in Information Retrieval (SIGIR'22). 1273-1282.\n\nBPR: Bayesian personalized ranking from implicit feedback. Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, Lars Schmidt-Thieme, Proceedings of the 25th Conference on Uncertainty in Artificial Intelligence (UAI'09. the 25th Conference on Uncertainty in Artificial Intelligence (UAI'09Steffen Rendle, Christoph Freudenthaler, Zeno Gantner, and Lars Schmidt-Thieme. 2009. BPR: Bayesian personalized ranking from implicit feedback. In Proceedings of the 25th Conference on Uncertainty in Artificial Intelligence (UAI'09). 452-461.\n\nItem-based Collaborative Filtering Recommendation Algorithms. Badrul Sarwar, George Karypis, Joseph Konstan, John Riedl, Proceedings of the 10th International Conference on World Wide Web (WWW'01. the 10th International Conference on World Wide Web (WWW'01Badrul Sarwar, George Karypis, Joseph Konstan, and John Riedl. 2001. Item-based Collaborative Filtering Recommendation Algorithms. In Proceedings of the 10th International Conference on World Wide Web (WWW'01). 285-295.\n\nDaniel Spielman, Spectral graph theory. Combinatorial scientific computing. 18Daniel Spielman. 2012. Spectral graph theory. Combinatorial scientific computing 18 (2012).\n\nEmbarrassingly shallow autoencoders for sparse data. Harald Steck, Proceedings of the 28th International Conference on World Wide Web (WWW'19. the 28th International Conference on World Wide Web (WWW'19Harald Steck. 2019. Embarrassingly shallow autoencoders for sparse data. In Proceedings of the 28th International Conference on World Wide Web (WWW'19). 3251-3257.\n\nBERT4Rec: Sequential Recommendation with Bidirectional Encoder Representations from Transformer. Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, Peng Jiang, Proceedings of the 28th ACM International Conference on Information and Knowledge Management (CIKM'19. the 28th ACM International Conference on Information and Knowledge Management (CIKM'19Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang. 2019. BERT4Rec: Sequential Recommendation with Bidirectional Encoder Rep- resentations from Transformer. In Proceedings of the 28th ACM International Conference on Information and Knowledge Management (CIKM'19). 1441-1450.\n\nHGCF: Hyperbolic Graph Convolution Networks for Collaborative Filtering. Jianing Sun, Zhaoyue Cheng, Saba Zuberi, Felipe P\u00e9rez, Maksims Volkovs, Proceedings of the 30th International Conference on World Wide Web (WWW '21. the 30th International Conference on World Wide Web (WWW '21Jianing Sun, Zhaoyue Cheng, Saba Zuberi, Felipe P\u00e9rez, and Maksims Volkovs. 2021. HGCF: Hyperbolic Graph Convolution Networks for Collaborative Filtering. In Proceedings of the 30th International Conference on World Wide Web (WWW '21). 593-601.\n\nHyperML: A Boosting Metric Learning Approach in Hyperbolic Space for Recommender Systems. Yi Lucas Vinh Tran, Shuai Tay, Gao Zhang, Xiaoli Cong, Li, Proceedings of the 13th International Conference on Web Search and Data Mining (WSDM'20. the 13th International Conference on Web Search and Data Mining (WSDM'20Lucas Vinh Tran, Yi Tay, Shuai Zhang, Gao Cong, and Xiaoli Li. 2020. HyperML: A Boosting Metric Learning Approach in Hyperbolic Space for Recommender Systems. In Proceedings of the 13th International Conference on Web Search and Data Mining (WSDM'20). 609-617.\n\nIrgan: A Minimax Game for Unifying Generative and Discriminative Information Retrieval Models. Jun Wang, Lantao Yu, Weinan Zhang, Yu Gong, Yinghui Xu, Benyou Wang, Peng Zhang, Dell Zhang, Proceedings of the 40th International ACM SIGIR conference on Research and Development in Information Retrieval (SIGIR'17. the 40th International ACM SIGIR conference on Research and Development in Information Retrieval (SIGIR'17Jun Wang, Lantao Yu, Weinan Zhang, Yu Gong, Yinghui Xu, Benyou Wang, Peng Zhang, and Dell Zhang. 2017. Irgan: A Minimax Game for Unifying Generative and Discriminative Information Retrieval Models. In Proceedings of the 40th International ACM SIGIR conference on Research and Development in Information Retrieval (SIGIR'17). 515-524.\n\nNeural Graph Collaborative Filtering. Xiang Wang, Xiangnan He, Meng Wang, Fuli Feng, Tat-Seng Chua, Proceedings of the 42nd international ACM SIGIR conference on Research and development in Information Retrieval (SIGIR'19. the 42nd international ACM SIGIR conference on Research and development in Information Retrieval (SIGIR'19Xiang Wang, Xiangnan He, Meng Wang, Fuli Feng, and Tat-Seng Chua. 2019. Neural Graph Collaborative Filtering. In Proceedings of the 42nd international ACM SIGIR conference on Research and development in Information Retrieval (SIGIR'19). 165-174.\n\nSelf-Supervised Graph Learning for Recommendation. Jiancan Wu, Xiang Wang, Fuli Feng, Xiangnan He, Liang Chen, Jianxun Lian, Xing Xie, Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR'21. the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR'21Jiancan Wu, Xiang Wang, Fuli Feng, Xiangnan He, Liang Chen, Jianxun Lian, and Xing Xie. 2021. Self-Supervised Graph Learning for Recommendation. In Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR'21). 726-735.\n\nA Neural Influence Diffusion Model for Social Recommendation. Le Wu, Peijie Sun, Yanjie Fu, Richang Hong, Xiting Wang, Meng Wang, Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR'19. the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR'19Le Wu, Peijie Sun, Yanjie Fu, Richang Hong, Xiting Wang, and Meng Wang. 2019. A Neural Influence Diffusion Model for Social Recommendation. In Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR'19). 235-244.\n\nDeep Matrix Factorization Models for Recommender Systems. Xinyu Hong-Jian Xue, Dai, Proceedings of the 26th International Joint Conference on Artificial Intelligence (IJCAI-17. the 26th International Joint Conference on Artificial Intelligence (IJCAI-17Hong-Jian Xue, Xinyu Dai, et al. 2017. Deep Matrix Factorization Models for Recommender Systems. In Proceedings of the 26th International Joint Conference on Artificial Intelligence (IJCAI-17). 3203-3209.\n\nGraph Convolutional Neural Networks for Web-Scale Recommender Systems. Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, L William, Jure Hamilton, Leskovec, Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (KDD'18. the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (KDD'18Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L Hamilton, and Jure Leskovec. 2018. Graph Convolutional Neural Networks for Web-Scale Recommender Systems. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (KDD'18). 974-983.\n\nGraph Convolutional Network for Recommendation with Low-pass Collaborative Filters. Wenhui Yu, Zheng Qin, Proceedings of the 37th International Conference on Machine Learning (ICML'20. the 37th International Conference on Machine Learning (ICML'20Wenhui Yu and Zheng Qin. 2020. Graph Convolutional Network for Recommen- dation with Low-pass Collaborative Filters. In Proceedings of the 37th International Conference on Machine Learning (ICML'20). 10936-10945.\n\nPairNorm: Tackling Oversmoothing in GNNs. Lingxiao Zhao, Leman Akoglu, Proceedings of the 8th International Conference on Learning Representations. the 8th International Conference on Learning RepresentationsICLR'20Lingxiao Zhao and Leman Akoglu. 2020. PairNorm: Tackling Oversmoothing in GNNs. In Proceedings of the 8th International Conference on Learning Representa- tions (ICLR'20).\n\nSpectral Collaborative Filtering. Lei Zheng, Chun-Ta Lu, Fei Jiang, Jiawei Zhang, Philip S Yu, Proceedings of the 12th ACM Conference on Recommender Systems (RecSys'18. the 12th ACM Conference on Recommender Systems (RecSys'18Lei Zheng, Chun-Ta Lu, Fei Jiang, Jiawei Zhang, and Philip S Yu. 2018. Spectral Collaborative Filtering. In Proceedings of the 12th ACM Conference on Recom- mender Systems (RecSys'18). 311-319.\n\nMulti-Level Cross-View Contrastive Learning for Knowledge-Aware Recommender System. Ding Zou, Wei Wei, Xian-Ling Mao, Ziyang Wang, Minghui Qiu, Feida Zhu, Xin Cao, Proceedings of the 45th International ACM SI-GIR Conference on Research and Development in Information Retrieval (SIGIR'22. the 45th International ACM SI-GIR Conference on Research and Development in Information Retrieval (SIGIR'22Ding Zou, Wei Wei, Xian-Ling Mao, Ziyang Wang, Minghui Qiu, Feida Zhu, and Xin Cao. 2022. Multi-Level Cross-View Contrastive Learning for Knowledge- Aware Recommender System. In Proceedings of the 45th International ACM SI- GIR Conference on Research and Development in Information Retrieval (SIGIR'22). 1358-1368.\n", "annotations": {"author": "[{\"end\":122,\"start\":90},{\"end\":170,\"start\":123},{\"end\":201,\"start\":171},{\"end\":241,\"start\":202},{\"end\":275,\"start\":242},{\"end\":122,\"start\":90},{\"end\":170,\"start\":123},{\"end\":201,\"start\":171},{\"end\":241,\"start\":202},{\"end\":275,\"start\":242}]", "publisher": null, "author_last_name": "[{\"end\":102,\"start\":98},{\"end\":140,\"start\":132},{\"end\":102,\"start\":98},{\"end\":140,\"start\":132}]", "author_first_name": "[{\"end\":97,\"start\":90},{\"end\":131,\"start\":123},{\"end\":97,\"start\":90},{\"end\":131,\"start\":123}]", "author_affiliation": "[{\"end\":200,\"start\":172},{\"end\":240,\"start\":203},{\"end\":274,\"start\":243},{\"end\":200,\"start\":172},{\"end\":240,\"start\":203},{\"end\":274,\"start\":243}]", "title": "[{\"end\":68,\"start\":1},{\"end\":343,\"start\":276},{\"end\":68,\"start\":1},{\"end\":343,\"start\":276}]", "venue": "[{\"end\":353,\"start\":345},{\"end\":353,\"start\":345}]", "abstract": "[{\"end\":2439,\"start\":805},{\"end\":2439,\"start\":805}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b20\"},\"end\":2864,\"start\":2860},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3229,\"start\":3226},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3231,\"start\":3229},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":3234,\"start\":3231},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":3271,\"start\":3267},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":3274,\"start\":3271},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":3277,\"start\":3274},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":3584,\"start\":3580},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":3667,\"start\":3664},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":3670,\"start\":3667},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3698,\"start\":3695},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":3701,\"start\":3698},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":3834,\"start\":3830},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":3837,\"start\":3834},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":3840,\"start\":3837},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3917,\"start\":3914},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3920,\"start\":3917},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":3923,\"start\":3920},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":4482,\"start\":4478},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":4485,\"start\":4482},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":8868,\"start\":8865},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":8871,\"start\":8868},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":9415,\"start\":9411},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":10037,\"start\":10033},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":10547,\"start\":10543},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":13256,\"start\":13253},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":15582,\"start\":15578},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":18921,\"start\":18917},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":19681,\"start\":19677},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":20511,\"start\":20508},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":21340,\"start\":21336},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":22401,\"start\":22398},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":22572,\"start\":22568},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":22583,\"start\":22579},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":22598,\"start\":22595},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":22798,\"start\":22794},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":23745,\"start\":23741},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":23879,\"start\":23875},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":24022,\"start\":24018},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":24197,\"start\":24193},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":24407,\"start\":24403},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":24594,\"start\":24590},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":24678,\"start\":24674},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":24882,\"start\":24878},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":24893,\"start\":24889},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":24914,\"start\":24910},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":25393,\"start\":25390},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":30959,\"start\":30956},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":31087,\"start\":31084},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":31460,\"start\":31456},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":31588,\"start\":31584},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":31830,\"start\":31826},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":31833,\"start\":31830},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":31859,\"start\":31855},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":31877,\"start\":31873},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":31947,\"start\":31943},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":32074,\"start\":32070},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":32091,\"start\":32088},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":32118,\"start\":32114},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":32535,\"start\":32532},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":32641,\"start\":32637},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":32720,\"start\":32716},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":32755,\"start\":32751},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":32902,\"start\":32898},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":33107,\"start\":33103},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":33248,\"start\":33244},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":33251,\"start\":33248},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":33286,\"start\":33282},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":33310,\"start\":33306},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":33340,\"start\":33336},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":33613,\"start\":33610},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":33616,\"start\":33613},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":33878,\"start\":33874},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":36213,\"start\":36209},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":36650,\"start\":36646},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":36732,\"start\":36728},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":37397,\"start\":37393},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":38354,\"start\":38350},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":2864,\"start\":2860},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3229,\"start\":3226},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3231,\"start\":3229},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":3234,\"start\":3231},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":3271,\"start\":3267},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":3274,\"start\":3271},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":3277,\"start\":3274},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":3584,\"start\":3580},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":3667,\"start\":3664},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":3670,\"start\":3667},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3698,\"start\":3695},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":3701,\"start\":3698},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":3834,\"start\":3830},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":3837,\"start\":3834},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":3840,\"start\":3837},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3917,\"start\":3914},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3920,\"start\":3917},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":3923,\"start\":3920},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":4482,\"start\":4478},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":4485,\"start\":4482},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":8868,\"start\":8865},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":8871,\"start\":8868},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":9415,\"start\":9411},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":10037,\"start\":10033},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":10547,\"start\":10543},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":13256,\"start\":13253},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":15582,\"start\":15578},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":18921,\"start\":18917},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":19681,\"start\":19677},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":20511,\"start\":20508},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":21340,\"start\":21336},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":22401,\"start\":22398},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":22572,\"start\":22568},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":22583,\"start\":22579},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":22598,\"start\":22595},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":22798,\"start\":22794},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":23745,\"start\":23741},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":23879,\"start\":23875},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":24022,\"start\":24018},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":24197,\"start\":24193},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":24407,\"start\":24403},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":24594,\"start\":24590},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":24678,\"start\":24674},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":24882,\"start\":24878},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":24893,\"start\":24889},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":24914,\"start\":24910},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":25393,\"start\":25390},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":30959,\"start\":30956},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":31087,\"start\":31084},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":31460,\"start\":31456},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":31588,\"start\":31584},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":31830,\"start\":31826},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":31833,\"start\":31830},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":31859,\"start\":31855},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":31877,\"start\":31873},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":31947,\"start\":31943},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":32074,\"start\":32070},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":32091,\"start\":32088},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":32118,\"start\":32114},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":32535,\"start\":32532},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":32641,\"start\":32637},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":32720,\"start\":32716},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":32755,\"start\":32751},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":32902,\"start\":32898},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":33107,\"start\":33103},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":33248,\"start\":33244},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":33251,\"start\":33248},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":33286,\"start\":33282},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":33310,\"start\":33306},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":33340,\"start\":33336},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":33613,\"start\":33610},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":33616,\"start\":33613},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":33878,\"start\":33874},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":36213,\"start\":36209},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":36650,\"start\":36646},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":36732,\"start\":36728},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":37397,\"start\":37393},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":38354,\"start\":38350}]", "figure": "[{\"attributes\":{\"id\":\"fig_1\"},\"end\":37555,\"start\":37479},{\"attributes\":{\"id\":\"fig_2\"},\"end\":37645,\"start\":37556},{\"attributes\":{\"id\":\"fig_5\"},\"end\":37698,\"start\":37646},{\"attributes\":{\"id\":\"fig_6\"},\"end\":38683,\"start\":37699},{\"attributes\":{\"id\":\"fig_8\"},\"end\":39447,\"start\":38684},{\"attributes\":{\"id\":\"fig_9\"},\"end\":39744,\"start\":39448},{\"attributes\":{\"id\":\"fig_11\"},\"end\":39829,\"start\":39745},{\"attributes\":{\"id\":\"fig_12\"},\"end\":40035,\"start\":39830},{\"attributes\":{\"id\":\"fig_13\"},\"end\":40097,\"start\":40036},{\"attributes\":{\"id\":\"fig_14\"},\"end\":40797,\"start\":40098},{\"attributes\":{\"id\":\"fig_15\"},\"end\":40901,\"start\":40798},{\"attributes\":{\"id\":\"fig_17\"},\"end\":40938,\"start\":40902},{\"attributes\":{\"id\":\"fig_18\"},\"end\":41023,\"start\":40939},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":41242,\"start\":41024},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":41652,\"start\":41243},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":41766,\"start\":41653},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":42142,\"start\":41767},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":42305,\"start\":42143},{\"attributes\":{\"id\":\"fig_1\"},\"end\":37555,\"start\":37479},{\"attributes\":{\"id\":\"fig_2\"},\"end\":37645,\"start\":37556},{\"attributes\":{\"id\":\"fig_5\"},\"end\":37698,\"start\":37646},{\"attributes\":{\"id\":\"fig_6\"},\"end\":38683,\"start\":37699},{\"attributes\":{\"id\":\"fig_8\"},\"end\":39447,\"start\":38684},{\"attributes\":{\"id\":\"fig_9\"},\"end\":39744,\"start\":39448},{\"attributes\":{\"id\":\"fig_11\"},\"end\":39829,\"start\":39745},{\"attributes\":{\"id\":\"fig_12\"},\"end\":40035,\"start\":39830},{\"attributes\":{\"id\":\"fig_13\"},\"end\":40097,\"start\":40036},{\"attributes\":{\"id\":\"fig_14\"},\"end\":40797,\"start\":40098},{\"attributes\":{\"id\":\"fig_15\"},\"end\":40901,\"start\":40798},{\"attributes\":{\"id\":\"fig_17\"},\"end\":40938,\"start\":40902},{\"attributes\":{\"id\":\"fig_18\"},\"end\":41023,\"start\":40939},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":41242,\"start\":41024},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":41652,\"start\":41243},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":41766,\"start\":41653},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":42142,\"start\":41767},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":42305,\"start\":42143}]", "paragraph": "[{\"end\":3303,\"start\":2455},{\"end\":4303,\"start\":3305},{\"end\":5038,\"start\":4305},{\"end\":5236,\"start\":5040},{\"end\":5357,\"start\":5238},{\"end\":7091,\"start\":5359},{\"end\":7922,\"start\":7093},{\"end\":8542,\"start\":7973},{\"end\":8611,\"start\":8560},{\"end\":8767,\"start\":8643},{\"end\":9028,\"start\":8779},{\"end\":9151,\"start\":9044},{\"end\":9301,\"start\":9196},{\"end\":9501,\"start\":9332},{\"end\":10038,\"start\":9531},{\"end\":10403,\"start\":10094},{\"end\":10752,\"start\":10456},{\"end\":11020,\"start\":10986},{\"end\":11157,\"start\":11036},{\"end\":11791,\"start\":11278},{\"end\":11826,\"start\":11822},{\"end\":12316,\"start\":11862},{\"end\":12449,\"start\":12425},{\"end\":12769,\"start\":12514},{\"end\":13138,\"start\":12811},{\"end\":13257,\"start\":13140},{\"end\":13590,\"start\":13259},{\"end\":14184,\"start\":13627},{\"end\":14875,\"start\":14213},{\"end\":15469,\"start\":14877},{\"end\":15631,\"start\":15471},{\"end\":15798,\"start\":15633},{\"end\":16393,\"start\":15833},{\"end\":16530,\"start\":16493},{\"end\":16924,\"start\":16532},{\"end\":17614,\"start\":16926},{\"end\":18078,\"start\":17633},{\"end\":18186,\"start\":18090},{\"end\":19423,\"start\":18231},{\"end\":19725,\"start\":19450},{\"end\":19874,\"start\":19786},{\"end\":19987,\"start\":19931},{\"end\":20347,\"start\":20168},{\"end\":21034,\"start\":20370},{\"end\":21445,\"start\":21076},{\"end\":21892,\"start\":21472},{\"end\":23573,\"start\":21908},{\"end\":23733,\"start\":23588},{\"end\":24661,\"start\":23735},{\"end\":24984,\"start\":24663},{\"end\":25488,\"start\":25012},{\"end\":25636,\"start\":25518},{\"end\":27547,\"start\":25638},{\"end\":28453,\"start\":27572},{\"end\":30420,\"start\":28514},{\"end\":31316,\"start\":30551},{\"end\":33376,\"start\":31333},{\"end\":34490,\"start\":33378},{\"end\":35360,\"start\":34505},{\"end\":35936,\"start\":35362},{\"end\":36119,\"start\":35971},{\"end\":36214,\"start\":36150},{\"end\":36472,\"start\":36216},{\"end\":36653,\"start\":36549},{\"end\":36733,\"start\":36683},{\"end\":36870,\"start\":36767},{\"end\":36974,\"start\":36922},{\"end\":37299,\"start\":37003},{\"end\":37466,\"start\":37301},{\"end\":37478,\"start\":37468},{\"end\":3303,\"start\":2455},{\"end\":4303,\"start\":3305},{\"end\":5038,\"start\":4305},{\"end\":5236,\"start\":5040},{\"end\":5357,\"start\":5238},{\"end\":7091,\"start\":5359},{\"end\":7922,\"start\":7093},{\"end\":8542,\"start\":7973},{\"end\":8611,\"start\":8560},{\"end\":8767,\"start\":8643},{\"end\":9028,\"start\":8779},{\"end\":9151,\"start\":9044},{\"end\":9301,\"start\":9196},{\"end\":9501,\"start\":9332},{\"end\":10038,\"start\":9531},{\"end\":10403,\"start\":10094},{\"end\":10752,\"start\":10456},{\"end\":11020,\"start\":10986},{\"end\":11157,\"start\":11036},{\"end\":11791,\"start\":11278},{\"end\":11826,\"start\":11822},{\"end\":12316,\"start\":11862},{\"end\":12449,\"start\":12425},{\"end\":12769,\"start\":12514},{\"end\":13138,\"start\":12811},{\"end\":13257,\"start\":13140},{\"end\":13590,\"start\":13259},{\"end\":14184,\"start\":13627},{\"end\":14875,\"start\":14213},{\"end\":15469,\"start\":14877},{\"end\":15631,\"start\":15471},{\"end\":15798,\"start\":15633},{\"end\":16393,\"start\":15833},{\"end\":16530,\"start\":16493},{\"end\":16924,\"start\":16532},{\"end\":17614,\"start\":16926},{\"end\":18078,\"start\":17633},{\"end\":18186,\"start\":18090},{\"end\":19423,\"start\":18231},{\"end\":19725,\"start\":19450},{\"end\":19874,\"start\":19786},{\"end\":19987,\"start\":19931},{\"end\":20347,\"start\":20168},{\"end\":21034,\"start\":20370},{\"end\":21445,\"start\":21076},{\"end\":21892,\"start\":21472},{\"end\":23573,\"start\":21908},{\"end\":23733,\"start\":23588},{\"end\":24661,\"start\":23735},{\"end\":24984,\"start\":24663},{\"end\":25488,\"start\":25012},{\"end\":25636,\"start\":25518},{\"end\":27547,\"start\":25638},{\"end\":28453,\"start\":27572},{\"end\":30420,\"start\":28514},{\"end\":31316,\"start\":30551},{\"end\":33376,\"start\":31333},{\"end\":34490,\"start\":33378},{\"end\":35360,\"start\":34505},{\"end\":35936,\"start\":35362},{\"end\":36119,\"start\":35971},{\"end\":36214,\"start\":36150},{\"end\":36472,\"start\":36216},{\"end\":36653,\"start\":36549},{\"end\":36733,\"start\":36683},{\"end\":36870,\"start\":36767},{\"end\":36974,\"start\":36922},{\"end\":37299,\"start\":37003},{\"end\":37466,\"start\":37301},{\"end\":37478,\"start\":37468}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":8559,\"start\":8543},{\"attributes\":{\"id\":\"formula_1\"},\"end\":8642,\"start\":8612},{\"attributes\":{\"id\":\"formula_2\"},\"end\":8778,\"start\":8768},{\"attributes\":{\"id\":\"formula_3\"},\"end\":9043,\"start\":9029},{\"attributes\":{\"id\":\"formula_4\"},\"end\":9195,\"start\":9152},{\"attributes\":{\"id\":\"formula_5\"},\"end\":9312,\"start\":9302},{\"attributes\":{\"id\":\"formula_6\"},\"end\":9530,\"start\":9502},{\"attributes\":{\"id\":\"formula_7\"},\"end\":10093,\"start\":10039},{\"attributes\":{\"id\":\"formula_8\"},\"end\":10791,\"start\":10753},{\"attributes\":{\"id\":\"formula_9\"},\"end\":10985,\"start\":10791},{\"attributes\":{\"id\":\"formula_10\"},\"end\":11035,\"start\":11021},{\"attributes\":{\"id\":\"formula_11\"},\"end\":11277,\"start\":11158},{\"attributes\":{\"id\":\"formula_12\"},\"end\":11821,\"start\":11792},{\"attributes\":{\"id\":\"formula_13\"},\"end\":11861,\"start\":11827},{\"attributes\":{\"id\":\"formula_14\"},\"end\":12424,\"start\":12317},{\"attributes\":{\"id\":\"formula_15\"},\"end\":12513,\"start\":12450},{\"attributes\":{\"id\":\"formula_16\"},\"end\":12810,\"start\":12770},{\"attributes\":{\"id\":\"formula_17\"},\"end\":13626,\"start\":13591},{\"attributes\":{\"id\":\"formula_18\"},\"end\":15832,\"start\":15799},{\"attributes\":{\"id\":\"formula_19\"},\"end\":16492,\"start\":16394},{\"attributes\":{\"id\":\"formula_20\"},\"end\":17632,\"start\":17615},{\"attributes\":{\"id\":\"formula_21\"},\"end\":18230,\"start\":18187},{\"attributes\":{\"id\":\"formula_22\"},\"end\":19449,\"start\":19424},{\"attributes\":{\"id\":\"formula_23\"},\"end\":19785,\"start\":19726},{\"attributes\":{\"id\":\"formula_24\"},\"end\":19930,\"start\":19875},{\"attributes\":{\"id\":\"formula_25\"},\"end\":20167,\"start\":19988},{\"attributes\":{\"id\":\"formula_26\"},\"end\":21471,\"start\":21446},{\"attributes\":{\"id\":\"formula_27\"},\"end\":28508,\"start\":28454},{\"attributes\":{\"id\":\"formula_28\"},\"end\":30550,\"start\":30435},{\"attributes\":{\"id\":\"formula_29\"},\"end\":36149,\"start\":36120},{\"attributes\":{\"id\":\"formula_30\"},\"end\":36548,\"start\":36473},{\"attributes\":{\"id\":\"formula_31\"},\"end\":36766,\"start\":36734},{\"attributes\":{\"id\":\"formula_32\"},\"end\":36921,\"start\":36871},{\"attributes\":{\"id\":\"formula_33\"},\"end\":37002,\"start\":36975},{\"attributes\":{\"id\":\"formula_0\"},\"end\":8559,\"start\":8543},{\"attributes\":{\"id\":\"formula_1\"},\"end\":8642,\"start\":8612},{\"attributes\":{\"id\":\"formula_2\"},\"end\":8778,\"start\":8768},{\"attributes\":{\"id\":\"formula_3\"},\"end\":9043,\"start\":9029},{\"attributes\":{\"id\":\"formula_4\"},\"end\":9195,\"start\":9152},{\"attributes\":{\"id\":\"formula_5\"},\"end\":9312,\"start\":9302},{\"attributes\":{\"id\":\"formula_6\"},\"end\":9530,\"start\":9502},{\"attributes\":{\"id\":\"formula_7\"},\"end\":10093,\"start\":10039},{\"attributes\":{\"id\":\"formula_8\"},\"end\":10791,\"start\":10753},{\"attributes\":{\"id\":\"formula_9\"},\"end\":10985,\"start\":10791},{\"attributes\":{\"id\":\"formula_10\"},\"end\":11035,\"start\":11021},{\"attributes\":{\"id\":\"formula_11\"},\"end\":11277,\"start\":11158},{\"attributes\":{\"id\":\"formula_12\"},\"end\":11821,\"start\":11792},{\"attributes\":{\"id\":\"formula_13\"},\"end\":11861,\"start\":11827},{\"attributes\":{\"id\":\"formula_14\"},\"end\":12424,\"start\":12317},{\"attributes\":{\"id\":\"formula_15\"},\"end\":12513,\"start\":12450},{\"attributes\":{\"id\":\"formula_16\"},\"end\":12810,\"start\":12770},{\"attributes\":{\"id\":\"formula_17\"},\"end\":13626,\"start\":13591},{\"attributes\":{\"id\":\"formula_18\"},\"end\":15832,\"start\":15799},{\"attributes\":{\"id\":\"formula_19\"},\"end\":16492,\"start\":16394},{\"attributes\":{\"id\":\"formula_20\"},\"end\":17632,\"start\":17615},{\"attributes\":{\"id\":\"formula_21\"},\"end\":18230,\"start\":18187},{\"attributes\":{\"id\":\"formula_22\"},\"end\":19449,\"start\":19424},{\"attributes\":{\"id\":\"formula_23\"},\"end\":19785,\"start\":19726},{\"attributes\":{\"id\":\"formula_24\"},\"end\":19930,\"start\":19875},{\"attributes\":{\"id\":\"formula_25\"},\"end\":20167,\"start\":19988},{\"attributes\":{\"id\":\"formula_26\"},\"end\":21471,\"start\":21446},{\"attributes\":{\"id\":\"formula_27\"},\"end\":28508,\"start\":28454},{\"attributes\":{\"id\":\"formula_28\"},\"end\":30550,\"start\":30435},{\"attributes\":{\"id\":\"formula_29\"},\"end\":36149,\"start\":36120},{\"attributes\":{\"id\":\"formula_30\"},\"end\":36548,\"start\":36473},{\"attributes\":{\"id\":\"formula_31\"},\"end\":36766,\"start\":36734},{\"attributes\":{\"id\":\"formula_32\"},\"end\":36921,\"start\":36871},{\"attributes\":{\"id\":\"formula_33\"},\"end\":37002,\"start\":36975}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":22713,\"start\":22706},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":25598,\"start\":25591},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":28125,\"start\":28118},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":30157,\"start\":30150},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":22713,\"start\":22706},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":25598,\"start\":25591},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":28125,\"start\":28118},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":30157,\"start\":30150}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2453,\"start\":2441},{\"attributes\":{\"n\":\"2\"},\"end\":7971,\"start\":7925},{\"attributes\":{\"n\":\"2.2\"},\"end\":9330,\"start\":9314},{\"attributes\":{\"n\":\"3\"},\"end\":10454,\"start\":10406},{\"attributes\":{\"n\":\"3.2\"},\"end\":14211,\"start\":14187},{\"attributes\":{\"n\":\"3.3\"},\"end\":18088,\"start\":18081},{\"attributes\":{\"n\":\"3.4\"},\"end\":20360,\"start\":20350},{\"attributes\":{\"n\":\"3.4.1\"},\"end\":20368,\"start\":20363},{\"attributes\":{\"n\":\"3.4.2\"},\"end\":21074,\"start\":21037},{\"attributes\":{\"n\":\"4\"},\"end\":21906,\"start\":21895},{\"attributes\":{\"n\":\"4.1.2\"},\"end\":23586,\"start\":23576},{\"attributes\":{\"n\":\"4.1.3\"},\"end\":25010,\"start\":24987},{\"attributes\":{\"n\":\"4.2\"},\"end\":25501,\"start\":25491},{\"attributes\":{\"n\":\"4.2.1\"},\"end\":25516,\"start\":25504},{\"attributes\":{\"n\":\"4.2.2\"},\"end\":27570,\"start\":27550},{\"attributes\":{\"n\":\"4.3.2\"},\"end\":28512,\"start\":28510},{\"attributes\":{\"n\":\"4.3.4\"},\"end\":30434,\"start\":30423},{\"attributes\":{\"n\":\"5\"},\"end\":31331,\"start\":31319},{\"attributes\":{\"n\":\"6\"},\"end\":34503,\"start\":34493},{\"attributes\":{\"n\":\"7\"},\"end\":35969,\"start\":35939},{\"attributes\":{\"n\":\"7.2\"},\"end\":36681,\"start\":36656},{\"end\":37490,\"start\":37480},{\"end\":37657,\"start\":37647},{\"end\":39756,\"start\":39746},{\"end\":40047,\"start\":40037},{\"end\":40109,\"start\":40099},{\"end\":40913,\"start\":40903},{\"end\":40941,\"start\":40940},{\"end\":41253,\"start\":41244},{\"end\":41663,\"start\":41654},{\"end\":41777,\"start\":41768},{\"end\":42153,\"start\":42144},{\"attributes\":{\"n\":\"1\"},\"end\":2453,\"start\":2441},{\"attributes\":{\"n\":\"2\"},\"end\":7971,\"start\":7925},{\"attributes\":{\"n\":\"2.2\"},\"end\":9330,\"start\":9314},{\"attributes\":{\"n\":\"3\"},\"end\":10454,\"start\":10406},{\"attributes\":{\"n\":\"3.2\"},\"end\":14211,\"start\":14187},{\"attributes\":{\"n\":\"3.3\"},\"end\":18088,\"start\":18081},{\"attributes\":{\"n\":\"3.4\"},\"end\":20360,\"start\":20350},{\"attributes\":{\"n\":\"3.4.1\"},\"end\":20368,\"start\":20363},{\"attributes\":{\"n\":\"3.4.2\"},\"end\":21074,\"start\":21037},{\"attributes\":{\"n\":\"4\"},\"end\":21906,\"start\":21895},{\"attributes\":{\"n\":\"4.1.2\"},\"end\":23586,\"start\":23576},{\"attributes\":{\"n\":\"4.1.3\"},\"end\":25010,\"start\":24987},{\"attributes\":{\"n\":\"4.2\"},\"end\":25501,\"start\":25491},{\"attributes\":{\"n\":\"4.2.1\"},\"end\":25516,\"start\":25504},{\"attributes\":{\"n\":\"4.2.2\"},\"end\":27570,\"start\":27550},{\"attributes\":{\"n\":\"4.3.2\"},\"end\":28512,\"start\":28510},{\"attributes\":{\"n\":\"4.3.4\"},\"end\":30434,\"start\":30423},{\"attributes\":{\"n\":\"5\"},\"end\":31331,\"start\":31319},{\"attributes\":{\"n\":\"6\"},\"end\":34503,\"start\":34493},{\"attributes\":{\"n\":\"7\"},\"end\":35969,\"start\":35939},{\"attributes\":{\"n\":\"7.2\"},\"end\":36681,\"start\":36656},{\"end\":37490,\"start\":37480},{\"end\":37657,\"start\":37647},{\"end\":39756,\"start\":39746},{\"end\":40047,\"start\":40037},{\"end\":40109,\"start\":40099},{\"end\":40913,\"start\":40903},{\"end\":40941,\"start\":40940},{\"end\":41253,\"start\":41244},{\"end\":41663,\"start\":41654},{\"end\":41777,\"start\":41768},{\"end\":42153,\"start\":42144}]", "table": "[{\"end\":41242,\"start\":41138},{\"end\":41652,\"start\":41277},{\"end\":41766,\"start\":41696},{\"end\":42142,\"start\":41815},{\"end\":42305,\"start\":42205},{\"end\":41242,\"start\":41138},{\"end\":41652,\"start\":41277},{\"end\":41766,\"start\":41696},{\"end\":42142,\"start\":41815},{\"end\":42305,\"start\":42205}]", "figure_caption": "[{\"end\":37555,\"start\":37492},{\"end\":37645,\"start\":37558},{\"end\":37698,\"start\":37659},{\"end\":38683,\"start\":37701},{\"end\":39447,\"start\":38686},{\"end\":39744,\"start\":39450},{\"end\":39829,\"start\":39758},{\"end\":40035,\"start\":39832},{\"end\":40097,\"start\":40049},{\"end\":40797,\"start\":40111},{\"end\":40901,\"start\":40800},{\"end\":40938,\"start\":40915},{\"end\":41023,\"start\":40942},{\"end\":41138,\"start\":41026},{\"end\":41277,\"start\":41255},{\"end\":41696,\"start\":41665},{\"end\":41815,\"start\":41779},{\"end\":42205,\"start\":42155},{\"end\":37555,\"start\":37492},{\"end\":37645,\"start\":37558},{\"end\":37698,\"start\":37659},{\"end\":38683,\"start\":37701},{\"end\":39447,\"start\":38686},{\"end\":39744,\"start\":39450},{\"end\":39829,\"start\":39758},{\"end\":40035,\"start\":39832},{\"end\":40097,\"start\":40049},{\"end\":40797,\"start\":40111},{\"end\":40901,\"start\":40800},{\"end\":40938,\"start\":40915},{\"end\":41023,\"start\":40942},{\"end\":41138,\"start\":41026},{\"end\":41277,\"start\":41255},{\"end\":41696,\"start\":41665},{\"end\":41815,\"start\":41779},{\"end\":42205,\"start\":42155}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":12072,\"start\":12064},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":13282,\"start\":13274},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":13917,\"start\":13909},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":14791,\"start\":14783},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":15655,\"start\":15647},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":22360,\"start\":22352},{\"attributes\":{\"ref_id\":\"fig_11\"},\"end\":27700,\"start\":27692},{\"attributes\":{\"ref_id\":\"fig_17\"},\"end\":29592,\"start\":29584},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":12072,\"start\":12064},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":13282,\"start\":13274},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":13917,\"start\":13909},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":14791,\"start\":14783},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":15655,\"start\":15647},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":22360,\"start\":22352},{\"attributes\":{\"ref_id\":\"fig_11\"},\"end\":27700,\"start\":27692},{\"attributes\":{\"ref_id\":\"fig_17\"},\"end\":29592,\"start\":29584}]", "bib_author_first_name": "[{\"end\":42485,\"start\":42481},{\"end\":42494,\"start\":42491},{\"end\":42504,\"start\":42501},{\"end\":42860,\"start\":42854},{\"end\":42876,\"start\":42870},{\"end\":42878,\"start\":42877},{\"end\":42888,\"start\":42885},{\"end\":43224,\"start\":43216},{\"end\":43238,\"start\":43231},{\"end\":43254,\"start\":43246},{\"end\":43266,\"start\":43259},{\"end\":43275,\"start\":43272},{\"end\":43289,\"start\":43281},{\"end\":43964,\"start\":43961},{\"end\":43973,\"start\":43971},{\"end\":43985,\"start\":43978},{\"end\":43995,\"start\":43992},{\"end\":44007,\"start\":44003},{\"end\":44463,\"start\":44458},{\"end\":44472,\"start\":44469},{\"end\":44481,\"start\":44477},{\"end\":44490,\"start\":44486},{\"end\":44499,\"start\":44495},{\"end\":44513,\"start\":44506},{\"end\":44525,\"start\":44520},{\"end\":44972,\"start\":44964},{\"end\":44982,\"start\":44979},{\"end\":44991,\"start\":44989},{\"end\":45005,\"start\":44996},{\"end\":45457,\"start\":45451},{\"end\":45472,\"start\":45466},{\"end\":46024,\"start\":46018},{\"end\":46036,\"start\":46032},{\"end\":46038,\"start\":46037},{\"end\":46345,\"start\":46338},{\"end\":46360,\"start\":46354},{\"end\":46362,\"start\":46361},{\"end\":46691,\"start\":46683},{\"end\":46700,\"start\":46696},{\"end\":46712,\"start\":46707},{\"end\":46722,\"start\":46719},{\"end\":46735,\"start\":46727},{\"end\":46747,\"start\":46743},{\"end\":47322,\"start\":47314},{\"end\":47331,\"start\":47327},{\"end\":47345,\"start\":47338},{\"end\":47360,\"start\":47353},{\"end\":47369,\"start\":47366},{\"end\":47382,\"start\":47374},{\"end\":47815,\"start\":47807},{\"end\":47827,\"start\":47820},{\"end\":47842,\"start\":47835},{\"end\":47856,\"start\":47848},{\"end\":48468,\"start\":48461},{\"end\":48482,\"start\":48476},{\"end\":48493,\"start\":48489},{\"end\":48504,\"start\":48500},{\"end\":48519,\"start\":48511},{\"end\":48531,\"start\":48526},{\"end\":48541,\"start\":48538},{\"end\":49063,\"start\":49056},{\"end\":49079,\"start\":49074},{\"end\":49362,\"start\":49357},{\"end\":49372,\"start\":49367},{\"end\":49387,\"start\":49379},{\"end\":49397,\"start\":49392},{\"end\":49410,\"start\":49404},{\"end\":49420,\"start\":49417},{\"end\":49909,\"start\":49905},{\"end\":49921,\"start\":49917},{\"end\":49930,\"start\":49927},{\"end\":49941,\"start\":49936},{\"end\":49951,\"start\":49948},{\"end\":49963,\"start\":49958},{\"end\":49977,\"start\":49969},{\"end\":50486,\"start\":50479},{\"end\":50496,\"start\":50492},{\"end\":50505,\"start\":50501},{\"end\":50514,\"start\":50511},{\"end\":50522,\"start\":50520},{\"end\":50533,\"start\":50529},{\"end\":51004,\"start\":50994},{\"end\":51017,\"start\":51011},{\"end\":51390,\"start\":51389},{\"end\":51402,\"start\":51399},{\"end\":51835,\"start\":51831},{\"end\":51846,\"start\":51842},{\"end\":51848,\"start\":51847},{\"end\":52270,\"start\":52264},{\"end\":52284,\"start\":52278},{\"end\":52296,\"start\":52291},{\"end\":52542,\"start\":52537},{\"end\":52554,\"start\":52547},{\"end\":52569,\"start\":52560},{\"end\":53005,\"start\":53002},{\"end\":53017,\"start\":53010},{\"end\":53029,\"start\":53024},{\"end\":53534,\"start\":53528},{\"end\":53547,\"start\":53540},{\"end\":53555,\"start\":53553},{\"end\":53566,\"start\":53562},{\"end\":53578,\"start\":53571},{\"end\":53593,\"start\":53585},{\"end\":54150,\"start\":54143},{\"end\":54165,\"start\":54157},{\"end\":54185,\"start\":54176},{\"end\":54767,\"start\":54760},{\"end\":54785,\"start\":54776},{\"end\":54805,\"start\":54801},{\"end\":54819,\"start\":54815},{\"end\":55304,\"start\":55298},{\"end\":55319,\"start\":55313},{\"end\":55335,\"start\":55329},{\"end\":55349,\"start\":55345},{\"end\":55719,\"start\":55713},{\"end\":55943,\"start\":55937},{\"end\":56351,\"start\":56348},{\"end\":56360,\"start\":56357},{\"end\":56370,\"start\":56366},{\"end\":56383,\"start\":56375},{\"end\":56393,\"start\":56389},{\"end\":56404,\"start\":56399},{\"end\":56413,\"start\":56409},{\"end\":56991,\"start\":56984},{\"end\":57004,\"start\":56997},{\"end\":57016,\"start\":57012},{\"end\":57031,\"start\":57025},{\"end\":57046,\"start\":57039},{\"end\":57531,\"start\":57529},{\"end\":57554,\"start\":57549},{\"end\":57563,\"start\":57560},{\"end\":57577,\"start\":57571},{\"end\":58109,\"start\":58106},{\"end\":58122,\"start\":58116},{\"end\":58133,\"start\":58127},{\"end\":58143,\"start\":58141},{\"end\":58157,\"start\":58150},{\"end\":58168,\"start\":58162},{\"end\":58179,\"start\":58175},{\"end\":58191,\"start\":58187},{\"end\":58806,\"start\":58801},{\"end\":58821,\"start\":58813},{\"end\":58830,\"start\":58826},{\"end\":58841,\"start\":58837},{\"end\":58856,\"start\":58848},{\"end\":59397,\"start\":59390},{\"end\":59407,\"start\":59402},{\"end\":59418,\"start\":59414},{\"end\":59433,\"start\":59425},{\"end\":59443,\"start\":59438},{\"end\":59457,\"start\":59450},{\"end\":59468,\"start\":59464},{\"end\":60049,\"start\":60047},{\"end\":60060,\"start\":60054},{\"end\":60072,\"start\":60066},{\"end\":60084,\"start\":60077},{\"end\":60097,\"start\":60091},{\"end\":60108,\"start\":60104},{\"end\":60684,\"start\":60679},{\"end\":61154,\"start\":61151},{\"end\":61168,\"start\":61161},{\"end\":61180,\"start\":61173},{\"end\":61191,\"start\":61187},{\"end\":61207,\"start\":61206},{\"end\":61221,\"start\":61217},{\"end\":61818,\"start\":61812},{\"end\":61828,\"start\":61823},{\"end\":62239,\"start\":62231},{\"end\":62251,\"start\":62246},{\"end\":62614,\"start\":62611},{\"end\":62629,\"start\":62622},{\"end\":62637,\"start\":62634},{\"end\":62651,\"start\":62645},{\"end\":62667,\"start\":62659},{\"end\":63086,\"start\":63082},{\"end\":63095,\"start\":63092},{\"end\":63110,\"start\":63101},{\"end\":63122,\"start\":63116},{\"end\":63136,\"start\":63129},{\"end\":63147,\"start\":63142},{\"end\":63156,\"start\":63153},{\"end\":42485,\"start\":42481},{\"end\":42494,\"start\":42491},{\"end\":42504,\"start\":42501},{\"end\":42860,\"start\":42854},{\"end\":42876,\"start\":42870},{\"end\":42878,\"start\":42877},{\"end\":42888,\"start\":42885},{\"end\":43224,\"start\":43216},{\"end\":43238,\"start\":43231},{\"end\":43254,\"start\":43246},{\"end\":43266,\"start\":43259},{\"end\":43275,\"start\":43272},{\"end\":43289,\"start\":43281},{\"end\":43964,\"start\":43961},{\"end\":43973,\"start\":43971},{\"end\":43985,\"start\":43978},{\"end\":43995,\"start\":43992},{\"end\":44007,\"start\":44003},{\"end\":44463,\"start\":44458},{\"end\":44472,\"start\":44469},{\"end\":44481,\"start\":44477},{\"end\":44490,\"start\":44486},{\"end\":44499,\"start\":44495},{\"end\":44513,\"start\":44506},{\"end\":44525,\"start\":44520},{\"end\":44972,\"start\":44964},{\"end\":44982,\"start\":44979},{\"end\":44991,\"start\":44989},{\"end\":45005,\"start\":44996},{\"end\":45457,\"start\":45451},{\"end\":45472,\"start\":45466},{\"end\":46024,\"start\":46018},{\"end\":46036,\"start\":46032},{\"end\":46038,\"start\":46037},{\"end\":46345,\"start\":46338},{\"end\":46360,\"start\":46354},{\"end\":46362,\"start\":46361},{\"end\":46691,\"start\":46683},{\"end\":46700,\"start\":46696},{\"end\":46712,\"start\":46707},{\"end\":46722,\"start\":46719},{\"end\":46735,\"start\":46727},{\"end\":46747,\"start\":46743},{\"end\":47322,\"start\":47314},{\"end\":47331,\"start\":47327},{\"end\":47345,\"start\":47338},{\"end\":47360,\"start\":47353},{\"end\":47369,\"start\":47366},{\"end\":47382,\"start\":47374},{\"end\":47815,\"start\":47807},{\"end\":47827,\"start\":47820},{\"end\":47842,\"start\":47835},{\"end\":47856,\"start\":47848},{\"end\":48468,\"start\":48461},{\"end\":48482,\"start\":48476},{\"end\":48493,\"start\":48489},{\"end\":48504,\"start\":48500},{\"end\":48519,\"start\":48511},{\"end\":48531,\"start\":48526},{\"end\":48541,\"start\":48538},{\"end\":49063,\"start\":49056},{\"end\":49079,\"start\":49074},{\"end\":49362,\"start\":49357},{\"end\":49372,\"start\":49367},{\"end\":49387,\"start\":49379},{\"end\":49397,\"start\":49392},{\"end\":49410,\"start\":49404},{\"end\":49420,\"start\":49417},{\"end\":49909,\"start\":49905},{\"end\":49921,\"start\":49917},{\"end\":49930,\"start\":49927},{\"end\":49941,\"start\":49936},{\"end\":49951,\"start\":49948},{\"end\":49963,\"start\":49958},{\"end\":49977,\"start\":49969},{\"end\":50486,\"start\":50479},{\"end\":50496,\"start\":50492},{\"end\":50505,\"start\":50501},{\"end\":50514,\"start\":50511},{\"end\":50522,\"start\":50520},{\"end\":50533,\"start\":50529},{\"end\":51004,\"start\":50994},{\"end\":51017,\"start\":51011},{\"end\":51390,\"start\":51389},{\"end\":51402,\"start\":51399},{\"end\":51835,\"start\":51831},{\"end\":51846,\"start\":51842},{\"end\":51848,\"start\":51847},{\"end\":52270,\"start\":52264},{\"end\":52284,\"start\":52278},{\"end\":52296,\"start\":52291},{\"end\":52542,\"start\":52537},{\"end\":52554,\"start\":52547},{\"end\":52569,\"start\":52560},{\"end\":53005,\"start\":53002},{\"end\":53017,\"start\":53010},{\"end\":53029,\"start\":53024},{\"end\":53534,\"start\":53528},{\"end\":53547,\"start\":53540},{\"end\":53555,\"start\":53553},{\"end\":53566,\"start\":53562},{\"end\":53578,\"start\":53571},{\"end\":53593,\"start\":53585},{\"end\":54150,\"start\":54143},{\"end\":54165,\"start\":54157},{\"end\":54185,\"start\":54176},{\"end\":54767,\"start\":54760},{\"end\":54785,\"start\":54776},{\"end\":54805,\"start\":54801},{\"end\":54819,\"start\":54815},{\"end\":55304,\"start\":55298},{\"end\":55319,\"start\":55313},{\"end\":55335,\"start\":55329},{\"end\":55349,\"start\":55345},{\"end\":55719,\"start\":55713},{\"end\":55943,\"start\":55937},{\"end\":56351,\"start\":56348},{\"end\":56360,\"start\":56357},{\"end\":56370,\"start\":56366},{\"end\":56383,\"start\":56375},{\"end\":56393,\"start\":56389},{\"end\":56404,\"start\":56399},{\"end\":56413,\"start\":56409},{\"end\":56991,\"start\":56984},{\"end\":57004,\"start\":56997},{\"end\":57016,\"start\":57012},{\"end\":57031,\"start\":57025},{\"end\":57046,\"start\":57039},{\"end\":57531,\"start\":57529},{\"end\":57554,\"start\":57549},{\"end\":57563,\"start\":57560},{\"end\":57577,\"start\":57571},{\"end\":58109,\"start\":58106},{\"end\":58122,\"start\":58116},{\"end\":58133,\"start\":58127},{\"end\":58143,\"start\":58141},{\"end\":58157,\"start\":58150},{\"end\":58168,\"start\":58162},{\"end\":58179,\"start\":58175},{\"end\":58191,\"start\":58187},{\"end\":58806,\"start\":58801},{\"end\":58821,\"start\":58813},{\"end\":58830,\"start\":58826},{\"end\":58841,\"start\":58837},{\"end\":58856,\"start\":58848},{\"end\":59397,\"start\":59390},{\"end\":59407,\"start\":59402},{\"end\":59418,\"start\":59414},{\"end\":59433,\"start\":59425},{\"end\":59443,\"start\":59438},{\"end\":59457,\"start\":59450},{\"end\":59468,\"start\":59464},{\"end\":60049,\"start\":60047},{\"end\":60060,\"start\":60054},{\"end\":60072,\"start\":60066},{\"end\":60084,\"start\":60077},{\"end\":60097,\"start\":60091},{\"end\":60108,\"start\":60104},{\"end\":60684,\"start\":60679},{\"end\":61154,\"start\":61151},{\"end\":61168,\"start\":61161},{\"end\":61180,\"start\":61173},{\"end\":61191,\"start\":61187},{\"end\":61207,\"start\":61206},{\"end\":61221,\"start\":61217},{\"end\":61818,\"start\":61812},{\"end\":61828,\"start\":61823},{\"end\":62239,\"start\":62231},{\"end\":62251,\"start\":62246},{\"end\":62614,\"start\":62611},{\"end\":62629,\"start\":62622},{\"end\":62637,\"start\":62634},{\"end\":62651,\"start\":62645},{\"end\":62667,\"start\":62659},{\"end\":63086,\"start\":63082},{\"end\":63095,\"start\":63092},{\"end\":63110,\"start\":63101},{\"end\":63122,\"start\":63116},{\"end\":63136,\"start\":63129},{\"end\":63147,\"start\":63142},{\"end\":63156,\"start\":63153}]", "bib_author_last_name": "[{\"end\":42489,\"start\":42486},{\"end\":42499,\"start\":42495},{\"end\":42510,\"start\":42505},{\"end\":42868,\"start\":42861},{\"end\":42883,\"start\":42879},{\"end\":42893,\"start\":42889},{\"end\":42902,\"start\":42895},{\"end\":43229,\"start\":43225},{\"end\":43244,\"start\":43239},{\"end\":43257,\"start\":43255},{\"end\":43270,\"start\":43267},{\"end\":43279,\"start\":43276},{\"end\":43294,\"start\":43290},{\"end\":43969,\"start\":43965},{\"end\":43976,\"start\":43974},{\"end\":43990,\"start\":43986},{\"end\":44001,\"start\":43996},{\"end\":44012,\"start\":44008},{\"end\":44467,\"start\":44464},{\"end\":44475,\"start\":44473},{\"end\":44484,\"start\":44482},{\"end\":44493,\"start\":44491},{\"end\":44504,\"start\":44500},{\"end\":44518,\"start\":44514},{\"end\":44529,\"start\":44526},{\"end\":44977,\"start\":44973},{\"end\":44987,\"start\":44983},{\"end\":44994,\"start\":44992},{\"end\":45010,\"start\":45006},{\"end\":45464,\"start\":45458},{\"end\":45479,\"start\":45473},{\"end\":46030,\"start\":46025},{\"end\":46060,\"start\":46039},{\"end\":46067,\"start\":46062},{\"end\":46352,\"start\":46346},{\"end\":46370,\"start\":46363},{\"end\":46694,\"start\":46692},{\"end\":46705,\"start\":46701},{\"end\":46717,\"start\":46713},{\"end\":46725,\"start\":46723},{\"end\":46741,\"start\":46736},{\"end\":46752,\"start\":46748},{\"end\":47325,\"start\":47323},{\"end\":47336,\"start\":47332},{\"end\":47351,\"start\":47346},{\"end\":47364,\"start\":47361},{\"end\":47372,\"start\":47370},{\"end\":47387,\"start\":47383},{\"end\":47818,\"start\":47816},{\"end\":47833,\"start\":47828},{\"end\":47846,\"start\":47843},{\"end\":47861,\"start\":47857},{\"end\":48474,\"start\":48469},{\"end\":48487,\"start\":48483},{\"end\":48498,\"start\":48494},{\"end\":48509,\"start\":48505},{\"end\":48524,\"start\":48520},{\"end\":48536,\"start\":48532},{\"end\":48546,\"start\":48542},{\"end\":49072,\"start\":49064},{\"end\":49090,\"start\":49080},{\"end\":49365,\"start\":49363},{\"end\":49377,\"start\":49373},{\"end\":49390,\"start\":49388},{\"end\":49402,\"start\":49398},{\"end\":49415,\"start\":49411},{\"end\":49424,\"start\":49421},{\"end\":49915,\"start\":49910},{\"end\":49925,\"start\":49922},{\"end\":49934,\"start\":49931},{\"end\":49946,\"start\":49942},{\"end\":49956,\"start\":49952},{\"end\":49967,\"start\":49964},{\"end\":49982,\"start\":49978},{\"end\":50490,\"start\":50487},{\"end\":50499,\"start\":50497},{\"end\":50509,\"start\":50506},{\"end\":50518,\"start\":50515},{\"end\":50527,\"start\":50523},{\"end\":50538,\"start\":50534},{\"end\":51009,\"start\":51005},{\"end\":51025,\"start\":51018},{\"end\":51397,\"start\":51391},{\"end\":51407,\"start\":51403},{\"end\":51416,\"start\":51409},{\"end\":51840,\"start\":51836},{\"end\":51855,\"start\":51849},{\"end\":51865,\"start\":51857},{\"end\":52276,\"start\":52271},{\"end\":52289,\"start\":52285},{\"end\":52305,\"start\":52297},{\"end\":52545,\"start\":52543},{\"end\":52558,\"start\":52555},{\"end\":52572,\"start\":52570},{\"end\":53008,\"start\":53006},{\"end\":53022,\"start\":53018},{\"end\":53043,\"start\":53030},{\"end\":53049,\"start\":53045},{\"end\":53538,\"start\":53535},{\"end\":53551,\"start\":53548},{\"end\":53560,\"start\":53556},{\"end\":53569,\"start\":53567},{\"end\":53583,\"start\":53579},{\"end\":53596,\"start\":53594},{\"end\":54155,\"start\":54151},{\"end\":54174,\"start\":54166},{\"end\":54190,\"start\":54186},{\"end\":54774,\"start\":54768},{\"end\":54799,\"start\":54786},{\"end\":54813,\"start\":54806},{\"end\":54834,\"start\":54820},{\"end\":55311,\"start\":55305},{\"end\":55327,\"start\":55320},{\"end\":55343,\"start\":55336},{\"end\":55355,\"start\":55350},{\"end\":55728,\"start\":55720},{\"end\":55949,\"start\":55944},{\"end\":56355,\"start\":56352},{\"end\":56364,\"start\":56361},{\"end\":56373,\"start\":56371},{\"end\":56387,\"start\":56384},{\"end\":56397,\"start\":56394},{\"end\":56407,\"start\":56405},{\"end\":56419,\"start\":56414},{\"end\":56995,\"start\":56992},{\"end\":57010,\"start\":57005},{\"end\":57023,\"start\":57017},{\"end\":57037,\"start\":57032},{\"end\":57054,\"start\":57047},{\"end\":57547,\"start\":57532},{\"end\":57558,\"start\":57555},{\"end\":57569,\"start\":57564},{\"end\":57582,\"start\":57578},{\"end\":57586,\"start\":57584},{\"end\":58114,\"start\":58110},{\"end\":58125,\"start\":58123},{\"end\":58139,\"start\":58134},{\"end\":58148,\"start\":58144},{\"end\":58160,\"start\":58158},{\"end\":58173,\"start\":58169},{\"end\":58185,\"start\":58180},{\"end\":58197,\"start\":58192},{\"end\":58811,\"start\":58807},{\"end\":58824,\"start\":58822},{\"end\":58835,\"start\":58831},{\"end\":58846,\"start\":58842},{\"end\":58861,\"start\":58857},{\"end\":59400,\"start\":59398},{\"end\":59412,\"start\":59408},{\"end\":59423,\"start\":59419},{\"end\":59436,\"start\":59434},{\"end\":59448,\"start\":59444},{\"end\":59462,\"start\":59458},{\"end\":59472,\"start\":59469},{\"end\":60052,\"start\":60050},{\"end\":60064,\"start\":60061},{\"end\":60075,\"start\":60073},{\"end\":60089,\"start\":60085},{\"end\":60102,\"start\":60098},{\"end\":60113,\"start\":60109},{\"end\":60698,\"start\":60685},{\"end\":60703,\"start\":60700},{\"end\":61159,\"start\":61155},{\"end\":61171,\"start\":61169},{\"end\":61185,\"start\":61181},{\"end\":61204,\"start\":61192},{\"end\":61215,\"start\":61208},{\"end\":61230,\"start\":61222},{\"end\":61240,\"start\":61232},{\"end\":61821,\"start\":61819},{\"end\":61832,\"start\":61829},{\"end\":62244,\"start\":62240},{\"end\":62258,\"start\":62252},{\"end\":62620,\"start\":62615},{\"end\":62632,\"start\":62630},{\"end\":62643,\"start\":62638},{\"end\":62657,\"start\":62652},{\"end\":62670,\"start\":62668},{\"end\":63090,\"start\":63087},{\"end\":63099,\"start\":63096},{\"end\":63114,\"start\":63111},{\"end\":63127,\"start\":63123},{\"end\":63140,\"start\":63137},{\"end\":63151,\"start\":63148},{\"end\":63160,\"start\":63157},{\"end\":42489,\"start\":42486},{\"end\":42499,\"start\":42495},{\"end\":42510,\"start\":42505},{\"end\":42868,\"start\":42861},{\"end\":42883,\"start\":42879},{\"end\":42893,\"start\":42889},{\"end\":42902,\"start\":42895},{\"end\":43229,\"start\":43225},{\"end\":43244,\"start\":43239},{\"end\":43257,\"start\":43255},{\"end\":43270,\"start\":43267},{\"end\":43279,\"start\":43276},{\"end\":43294,\"start\":43290},{\"end\":43969,\"start\":43965},{\"end\":43976,\"start\":43974},{\"end\":43990,\"start\":43986},{\"end\":44001,\"start\":43996},{\"end\":44012,\"start\":44008},{\"end\":44467,\"start\":44464},{\"end\":44475,\"start\":44473},{\"end\":44484,\"start\":44482},{\"end\":44493,\"start\":44491},{\"end\":44504,\"start\":44500},{\"end\":44518,\"start\":44514},{\"end\":44529,\"start\":44526},{\"end\":44977,\"start\":44973},{\"end\":44987,\"start\":44983},{\"end\":44994,\"start\":44992},{\"end\":45010,\"start\":45006},{\"end\":45464,\"start\":45458},{\"end\":45479,\"start\":45473},{\"end\":46030,\"start\":46025},{\"end\":46060,\"start\":46039},{\"end\":46067,\"start\":46062},{\"end\":46352,\"start\":46346},{\"end\":46370,\"start\":46363},{\"end\":46694,\"start\":46692},{\"end\":46705,\"start\":46701},{\"end\":46717,\"start\":46713},{\"end\":46725,\"start\":46723},{\"end\":46741,\"start\":46736},{\"end\":46752,\"start\":46748},{\"end\":47325,\"start\":47323},{\"end\":47336,\"start\":47332},{\"end\":47351,\"start\":47346},{\"end\":47364,\"start\":47361},{\"end\":47372,\"start\":47370},{\"end\":47387,\"start\":47383},{\"end\":47818,\"start\":47816},{\"end\":47833,\"start\":47828},{\"end\":47846,\"start\":47843},{\"end\":47861,\"start\":47857},{\"end\":48474,\"start\":48469},{\"end\":48487,\"start\":48483},{\"end\":48498,\"start\":48494},{\"end\":48509,\"start\":48505},{\"end\":48524,\"start\":48520},{\"end\":48536,\"start\":48532},{\"end\":48546,\"start\":48542},{\"end\":49072,\"start\":49064},{\"end\":49090,\"start\":49080},{\"end\":49365,\"start\":49363},{\"end\":49377,\"start\":49373},{\"end\":49390,\"start\":49388},{\"end\":49402,\"start\":49398},{\"end\":49415,\"start\":49411},{\"end\":49424,\"start\":49421},{\"end\":49915,\"start\":49910},{\"end\":49925,\"start\":49922},{\"end\":49934,\"start\":49931},{\"end\":49946,\"start\":49942},{\"end\":49956,\"start\":49952},{\"end\":49967,\"start\":49964},{\"end\":49982,\"start\":49978},{\"end\":50490,\"start\":50487},{\"end\":50499,\"start\":50497},{\"end\":50509,\"start\":50506},{\"end\":50518,\"start\":50515},{\"end\":50527,\"start\":50523},{\"end\":50538,\"start\":50534},{\"end\":51009,\"start\":51005},{\"end\":51025,\"start\":51018},{\"end\":51397,\"start\":51391},{\"end\":51407,\"start\":51403},{\"end\":51416,\"start\":51409},{\"end\":51840,\"start\":51836},{\"end\":51855,\"start\":51849},{\"end\":51865,\"start\":51857},{\"end\":52276,\"start\":52271},{\"end\":52289,\"start\":52285},{\"end\":52305,\"start\":52297},{\"end\":52545,\"start\":52543},{\"end\":52558,\"start\":52555},{\"end\":52572,\"start\":52570},{\"end\":53008,\"start\":53006},{\"end\":53022,\"start\":53018},{\"end\":53043,\"start\":53030},{\"end\":53049,\"start\":53045},{\"end\":53538,\"start\":53535},{\"end\":53551,\"start\":53548},{\"end\":53560,\"start\":53556},{\"end\":53569,\"start\":53567},{\"end\":53583,\"start\":53579},{\"end\":53596,\"start\":53594},{\"end\":54155,\"start\":54151},{\"end\":54174,\"start\":54166},{\"end\":54190,\"start\":54186},{\"end\":54774,\"start\":54768},{\"end\":54799,\"start\":54786},{\"end\":54813,\"start\":54806},{\"end\":54834,\"start\":54820},{\"end\":55311,\"start\":55305},{\"end\":55327,\"start\":55320},{\"end\":55343,\"start\":55336},{\"end\":55355,\"start\":55350},{\"end\":55728,\"start\":55720},{\"end\":55949,\"start\":55944},{\"end\":56355,\"start\":56352},{\"end\":56364,\"start\":56361},{\"end\":56373,\"start\":56371},{\"end\":56387,\"start\":56384},{\"end\":56397,\"start\":56394},{\"end\":56407,\"start\":56405},{\"end\":56419,\"start\":56414},{\"end\":56995,\"start\":56992},{\"end\":57010,\"start\":57005},{\"end\":57023,\"start\":57017},{\"end\":57037,\"start\":57032},{\"end\":57054,\"start\":57047},{\"end\":57547,\"start\":57532},{\"end\":57558,\"start\":57555},{\"end\":57569,\"start\":57564},{\"end\":57582,\"start\":57578},{\"end\":57586,\"start\":57584},{\"end\":58114,\"start\":58110},{\"end\":58125,\"start\":58123},{\"end\":58139,\"start\":58134},{\"end\":58148,\"start\":58144},{\"end\":58160,\"start\":58158},{\"end\":58173,\"start\":58169},{\"end\":58185,\"start\":58180},{\"end\":58197,\"start\":58192},{\"end\":58811,\"start\":58807},{\"end\":58824,\"start\":58822},{\"end\":58835,\"start\":58831},{\"end\":58846,\"start\":58842},{\"end\":58861,\"start\":58857},{\"end\":59400,\"start\":59398},{\"end\":59412,\"start\":59408},{\"end\":59423,\"start\":59419},{\"end\":59436,\"start\":59434},{\"end\":59448,\"start\":59444},{\"end\":59462,\"start\":59458},{\"end\":59472,\"start\":59469},{\"end\":60052,\"start\":60050},{\"end\":60064,\"start\":60061},{\"end\":60075,\"start\":60073},{\"end\":60089,\"start\":60085},{\"end\":60102,\"start\":60098},{\"end\":60113,\"start\":60109},{\"end\":60698,\"start\":60685},{\"end\":60703,\"start\":60700},{\"end\":61159,\"start\":61155},{\"end\":61171,\"start\":61169},{\"end\":61185,\"start\":61181},{\"end\":61204,\"start\":61192},{\"end\":61215,\"start\":61208},{\"end\":61230,\"start\":61222},{\"end\":61240,\"start\":61232},{\"end\":61821,\"start\":61819},{\"end\":61832,\"start\":61829},{\"end\":62244,\"start\":62240},{\"end\":62258,\"start\":62252},{\"end\":62620,\"start\":62615},{\"end\":62632,\"start\":62630},{\"end\":62643,\"start\":62638},{\"end\":62657,\"start\":62652},{\"end\":62670,\"start\":62668},{\"end\":63090,\"start\":63087},{\"end\":63099,\"start\":63096},{\"end\":63114,\"start\":63111},{\"end\":63127,\"start\":63123},{\"end\":63140,\"start\":63137},{\"end\":63151,\"start\":63148},{\"end\":63160,\"start\":63157}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":15067034},\"end\":42852,\"start\":42406},{\"attributes\":{\"doi\":\"arXiv:1706.02263\",\"id\":\"b1\"},\"end\":43112,\"start\":42854},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":20970043},\"end\":43855,\"start\":43114},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":210932292},\"end\":44407,\"start\":43857},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":67769538},\"end\":44886,\"start\":44409},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":12010590},\"end\":45374,\"start\":44888},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":5575601},\"end\":45904,\"start\":45376},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":88251},\"end\":46291,\"start\":45906},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":16619709},\"end\":46600,\"start\":46293},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":211043589},\"end\":47280,\"start\":46602},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":13907106},\"end\":47729,\"start\":47282},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":2896685},\"end\":48371,\"start\":47731},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":236980247},\"end\":49004,\"start\":48373},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":1981391},\"end\":49306,\"start\":49006},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":221191170},\"end\":49869,\"start\":49308},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":16486901},\"end\":50409,\"start\":49871},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":235212063},\"end\":50950,\"start\":50411},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":52127932},\"end\":51321,\"start\":50952},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":3144218},\"end\":51768,\"start\":51323},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":5525836},\"end\":52205,\"start\":51770},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":58370896},\"end\":52455,\"start\":52207},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":11118105},\"end\":52929,\"start\":52457},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":1909293},\"end\":53443,\"start\":52931},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":240070722},\"end\":54061,\"start\":53445},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":248377277},\"end\":54699,\"start\":54063},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":10795036},\"end\":55234,\"start\":54701},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":8047550},\"end\":55711,\"start\":55236},{\"attributes\":{\"id\":\"b27\"},\"end\":55882,\"start\":55713},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":86711251},\"end\":56249,\"start\":55884},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":119181611},\"end\":56909,\"start\":56251},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":235324826},\"end\":57437,\"start\":56911},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":208268313},\"end\":58009,\"start\":57439},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":3331356},\"end\":58761,\"start\":58011},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":150380651},\"end\":59337,\"start\":58763},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":224814335},\"end\":59983,\"start\":59339},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":128358994},\"end\":60619,\"start\":59985},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":27308776},\"end\":61078,\"start\":60621},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":46949657},\"end\":61726,\"start\":61080},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":220250619},\"end\":62187,\"start\":61728},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":202888772},\"end\":62575,\"start\":62189},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":52145692},\"end\":62996,\"start\":62577},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":248239751},\"end\":63707,\"start\":62998},{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":15067034},\"end\":42852,\"start\":42406},{\"attributes\":{\"doi\":\"arXiv:1706.02263\",\"id\":\"b1\"},\"end\":43112,\"start\":42854},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":20970043},\"end\":43855,\"start\":43114},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":210932292},\"end\":44407,\"start\":43857},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":67769538},\"end\":44886,\"start\":44409},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":12010590},\"end\":45374,\"start\":44888},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":5575601},\"end\":45904,\"start\":45376},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":88251},\"end\":46291,\"start\":45906},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":16619709},\"end\":46600,\"start\":46293},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":211043589},\"end\":47280,\"start\":46602},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":13907106},\"end\":47729,\"start\":47282},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":2896685},\"end\":48371,\"start\":47731},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":236980247},\"end\":49004,\"start\":48373},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":1981391},\"end\":49306,\"start\":49006},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":221191170},\"end\":49869,\"start\":49308},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":16486901},\"end\":50409,\"start\":49871},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":235212063},\"end\":50950,\"start\":50411},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":52127932},\"end\":51321,\"start\":50952},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":3144218},\"end\":51768,\"start\":51323},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":5525836},\"end\":52205,\"start\":51770},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":58370896},\"end\":52455,\"start\":52207},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":11118105},\"end\":52929,\"start\":52457},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":1909293},\"end\":53443,\"start\":52931},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":240070722},\"end\":54061,\"start\":53445},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":248377277},\"end\":54699,\"start\":54063},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":10795036},\"end\":55234,\"start\":54701},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":8047550},\"end\":55711,\"start\":55236},{\"attributes\":{\"id\":\"b27\"},\"end\":55882,\"start\":55713},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":86711251},\"end\":56249,\"start\":55884},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":119181611},\"end\":56909,\"start\":56251},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":235324826},\"end\":57437,\"start\":56911},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":208268313},\"end\":58009,\"start\":57439},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":3331356},\"end\":58761,\"start\":58011},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":150380651},\"end\":59337,\"start\":58763},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":224814335},\"end\":59983,\"start\":59339},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":128358994},\"end\":60619,\"start\":59985},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":27308776},\"end\":61078,\"start\":60621},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":46949657},\"end\":61726,\"start\":61080},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":220250619},\"end\":62187,\"start\":61728},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":202888772},\"end\":62575,\"start\":62189},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":52145692},\"end\":62996,\"start\":62577},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":248239751},\"end\":63707,\"start\":62998}]", "bib_title": "[{\"end\":42479,\"start\":42406},{\"end\":43214,\"start\":43114},{\"end\":43959,\"start\":43857},{\"end\":44456,\"start\":44409},{\"end\":44962,\"start\":44888},{\"end\":45449,\"start\":45376},{\"end\":46016,\"start\":45906},{\"end\":46336,\"start\":46293},{\"end\":46681,\"start\":46602},{\"end\":47312,\"start\":47282},{\"end\":47805,\"start\":47731},{\"end\":48459,\"start\":48373},{\"end\":49054,\"start\":49006},{\"end\":49355,\"start\":49308},{\"end\":49903,\"start\":49871},{\"end\":50477,\"start\":50411},{\"end\":50992,\"start\":50952},{\"end\":51387,\"start\":51323},{\"end\":51829,\"start\":51770},{\"end\":52262,\"start\":52207},{\"end\":52535,\"start\":52457},{\"end\":53000,\"start\":52931},{\"end\":53526,\"start\":53445},{\"end\":54141,\"start\":54063},{\"end\":54758,\"start\":54701},{\"end\":55296,\"start\":55236},{\"end\":55935,\"start\":55884},{\"end\":56346,\"start\":56251},{\"end\":56982,\"start\":56911},{\"end\":57527,\"start\":57439},{\"end\":58104,\"start\":58011},{\"end\":58799,\"start\":58763},{\"end\":59388,\"start\":59339},{\"end\":60045,\"start\":59985},{\"end\":60677,\"start\":60621},{\"end\":61149,\"start\":61080},{\"end\":61810,\"start\":61728},{\"end\":62229,\"start\":62189},{\"end\":62609,\"start\":62577},{\"end\":63080,\"start\":62998},{\"end\":42479,\"start\":42406},{\"end\":43214,\"start\":43114},{\"end\":43959,\"start\":43857},{\"end\":44456,\"start\":44409},{\"end\":44962,\"start\":44888},{\"end\":45449,\"start\":45376},{\"end\":46016,\"start\":45906},{\"end\":46336,\"start\":46293},{\"end\":46681,\"start\":46602},{\"end\":47312,\"start\":47282},{\"end\":47805,\"start\":47731},{\"end\":48459,\"start\":48373},{\"end\":49054,\"start\":49006},{\"end\":49355,\"start\":49308},{\"end\":49903,\"start\":49871},{\"end\":50477,\"start\":50411},{\"end\":50992,\"start\":50952},{\"end\":51387,\"start\":51323},{\"end\":51829,\"start\":51770},{\"end\":52262,\"start\":52207},{\"end\":52535,\"start\":52457},{\"end\":53000,\"start\":52931},{\"end\":53526,\"start\":53445},{\"end\":54141,\"start\":54063},{\"end\":54758,\"start\":54701},{\"end\":55296,\"start\":55236},{\"end\":55935,\"start\":55884},{\"end\":56346,\"start\":56251},{\"end\":56982,\"start\":56911},{\"end\":57527,\"start\":57439},{\"end\":58104,\"start\":58011},{\"end\":58799,\"start\":58763},{\"end\":59388,\"start\":59339},{\"end\":60045,\"start\":59985},{\"end\":60677,\"start\":60621},{\"end\":61149,\"start\":61080},{\"end\":61810,\"start\":61728},{\"end\":62229,\"start\":62189},{\"end\":62609,\"start\":62577},{\"end\":63080,\"start\":62998}]", "bib_author": "[{\"end\":42491,\"start\":42481},{\"end\":42501,\"start\":42491},{\"end\":42512,\"start\":42501},{\"end\":42870,\"start\":42854},{\"end\":42885,\"start\":42870},{\"end\":42895,\"start\":42885},{\"end\":42904,\"start\":42895},{\"end\":43231,\"start\":43216},{\"end\":43246,\"start\":43231},{\"end\":43259,\"start\":43246},{\"end\":43272,\"start\":43259},{\"end\":43281,\"start\":43272},{\"end\":43296,\"start\":43281},{\"end\":43971,\"start\":43961},{\"end\":43978,\"start\":43971},{\"end\":43992,\"start\":43978},{\"end\":44003,\"start\":43992},{\"end\":44014,\"start\":44003},{\"end\":44469,\"start\":44458},{\"end\":44477,\"start\":44469},{\"end\":44486,\"start\":44477},{\"end\":44495,\"start\":44486},{\"end\":44506,\"start\":44495},{\"end\":44520,\"start\":44506},{\"end\":44531,\"start\":44520},{\"end\":44979,\"start\":44964},{\"end\":44989,\"start\":44979},{\"end\":44996,\"start\":44989},{\"end\":45012,\"start\":44996},{\"end\":45466,\"start\":45451},{\"end\":45481,\"start\":45466},{\"end\":46032,\"start\":46018},{\"end\":46062,\"start\":46032},{\"end\":46069,\"start\":46062},{\"end\":46354,\"start\":46338},{\"end\":46372,\"start\":46354},{\"end\":46696,\"start\":46683},{\"end\":46707,\"start\":46696},{\"end\":46719,\"start\":46707},{\"end\":46727,\"start\":46719},{\"end\":46743,\"start\":46727},{\"end\":46754,\"start\":46743},{\"end\":47327,\"start\":47314},{\"end\":47338,\"start\":47327},{\"end\":47353,\"start\":47338},{\"end\":47366,\"start\":47353},{\"end\":47374,\"start\":47366},{\"end\":47389,\"start\":47374},{\"end\":47820,\"start\":47807},{\"end\":47835,\"start\":47820},{\"end\":47848,\"start\":47835},{\"end\":47863,\"start\":47848},{\"end\":48476,\"start\":48461},{\"end\":48489,\"start\":48476},{\"end\":48500,\"start\":48489},{\"end\":48511,\"start\":48500},{\"end\":48526,\"start\":48511},{\"end\":48538,\"start\":48526},{\"end\":48548,\"start\":48538},{\"end\":49074,\"start\":49056},{\"end\":49092,\"start\":49074},{\"end\":49367,\"start\":49357},{\"end\":49379,\"start\":49367},{\"end\":49392,\"start\":49379},{\"end\":49404,\"start\":49392},{\"end\":49417,\"start\":49404},{\"end\":49426,\"start\":49417},{\"end\":49917,\"start\":49905},{\"end\":49927,\"start\":49917},{\"end\":49936,\"start\":49927},{\"end\":49948,\"start\":49936},{\"end\":49958,\"start\":49948},{\"end\":49969,\"start\":49958},{\"end\":49984,\"start\":49969},{\"end\":50492,\"start\":50479},{\"end\":50501,\"start\":50492},{\"end\":50511,\"start\":50501},{\"end\":50520,\"start\":50511},{\"end\":50529,\"start\":50520},{\"end\":50540,\"start\":50529},{\"end\":51011,\"start\":50994},{\"end\":51027,\"start\":51011},{\"end\":51399,\"start\":51389},{\"end\":51409,\"start\":51399},{\"end\":51418,\"start\":51409},{\"end\":51842,\"start\":51831},{\"end\":51857,\"start\":51842},{\"end\":51867,\"start\":51857},{\"end\":52278,\"start\":52264},{\"end\":52291,\"start\":52278},{\"end\":52307,\"start\":52291},{\"end\":52547,\"start\":52537},{\"end\":52560,\"start\":52547},{\"end\":52574,\"start\":52560},{\"end\":53010,\"start\":53002},{\"end\":53024,\"start\":53010},{\"end\":53045,\"start\":53024},{\"end\":53051,\"start\":53045},{\"end\":53540,\"start\":53528},{\"end\":53553,\"start\":53540},{\"end\":53562,\"start\":53553},{\"end\":53571,\"start\":53562},{\"end\":53585,\"start\":53571},{\"end\":53598,\"start\":53585},{\"end\":54157,\"start\":54143},{\"end\":54176,\"start\":54157},{\"end\":54192,\"start\":54176},{\"end\":54776,\"start\":54760},{\"end\":54801,\"start\":54776},{\"end\":54815,\"start\":54801},{\"end\":54836,\"start\":54815},{\"end\":55313,\"start\":55298},{\"end\":55329,\"start\":55313},{\"end\":55345,\"start\":55329},{\"end\":55357,\"start\":55345},{\"end\":55730,\"start\":55713},{\"end\":55951,\"start\":55937},{\"end\":56357,\"start\":56348},{\"end\":56366,\"start\":56357},{\"end\":56375,\"start\":56366},{\"end\":56389,\"start\":56375},{\"end\":56399,\"start\":56389},{\"end\":56409,\"start\":56399},{\"end\":56421,\"start\":56409},{\"end\":56997,\"start\":56984},{\"end\":57012,\"start\":56997},{\"end\":57025,\"start\":57012},{\"end\":57039,\"start\":57025},{\"end\":57056,\"start\":57039},{\"end\":57549,\"start\":57529},{\"end\":57560,\"start\":57549},{\"end\":57571,\"start\":57560},{\"end\":57584,\"start\":57571},{\"end\":57588,\"start\":57584},{\"end\":58116,\"start\":58106},{\"end\":58127,\"start\":58116},{\"end\":58141,\"start\":58127},{\"end\":58150,\"start\":58141},{\"end\":58162,\"start\":58150},{\"end\":58175,\"start\":58162},{\"end\":58187,\"start\":58175},{\"end\":58199,\"start\":58187},{\"end\":58813,\"start\":58801},{\"end\":58826,\"start\":58813},{\"end\":58837,\"start\":58826},{\"end\":58848,\"start\":58837},{\"end\":58863,\"start\":58848},{\"end\":59402,\"start\":59390},{\"end\":59414,\"start\":59402},{\"end\":59425,\"start\":59414},{\"end\":59438,\"start\":59425},{\"end\":59450,\"start\":59438},{\"end\":59464,\"start\":59450},{\"end\":59474,\"start\":59464},{\"end\":60054,\"start\":60047},{\"end\":60066,\"start\":60054},{\"end\":60077,\"start\":60066},{\"end\":60091,\"start\":60077},{\"end\":60104,\"start\":60091},{\"end\":60115,\"start\":60104},{\"end\":60700,\"start\":60679},{\"end\":60705,\"start\":60700},{\"end\":61161,\"start\":61151},{\"end\":61173,\"start\":61161},{\"end\":61187,\"start\":61173},{\"end\":61206,\"start\":61187},{\"end\":61217,\"start\":61206},{\"end\":61232,\"start\":61217},{\"end\":61242,\"start\":61232},{\"end\":61823,\"start\":61812},{\"end\":61834,\"start\":61823},{\"end\":62246,\"start\":62231},{\"end\":62260,\"start\":62246},{\"end\":62622,\"start\":62611},{\"end\":62634,\"start\":62622},{\"end\":62645,\"start\":62634},{\"end\":62659,\"start\":62645},{\"end\":62672,\"start\":62659},{\"end\":63092,\"start\":63082},{\"end\":63101,\"start\":63092},{\"end\":63116,\"start\":63101},{\"end\":63129,\"start\":63116},{\"end\":63142,\"start\":63129},{\"end\":63153,\"start\":63142},{\"end\":63162,\"start\":63153},{\"end\":42491,\"start\":42481},{\"end\":42501,\"start\":42491},{\"end\":42512,\"start\":42501},{\"end\":42870,\"start\":42854},{\"end\":42885,\"start\":42870},{\"end\":42895,\"start\":42885},{\"end\":42904,\"start\":42895},{\"end\":43231,\"start\":43216},{\"end\":43246,\"start\":43231},{\"end\":43259,\"start\":43246},{\"end\":43272,\"start\":43259},{\"end\":43281,\"start\":43272},{\"end\":43296,\"start\":43281},{\"end\":43971,\"start\":43961},{\"end\":43978,\"start\":43971},{\"end\":43992,\"start\":43978},{\"end\":44003,\"start\":43992},{\"end\":44014,\"start\":44003},{\"end\":44469,\"start\":44458},{\"end\":44477,\"start\":44469},{\"end\":44486,\"start\":44477},{\"end\":44495,\"start\":44486},{\"end\":44506,\"start\":44495},{\"end\":44520,\"start\":44506},{\"end\":44531,\"start\":44520},{\"end\":44979,\"start\":44964},{\"end\":44989,\"start\":44979},{\"end\":44996,\"start\":44989},{\"end\":45012,\"start\":44996},{\"end\":45466,\"start\":45451},{\"end\":45481,\"start\":45466},{\"end\":46032,\"start\":46018},{\"end\":46062,\"start\":46032},{\"end\":46069,\"start\":46062},{\"end\":46354,\"start\":46338},{\"end\":46372,\"start\":46354},{\"end\":46696,\"start\":46683},{\"end\":46707,\"start\":46696},{\"end\":46719,\"start\":46707},{\"end\":46727,\"start\":46719},{\"end\":46743,\"start\":46727},{\"end\":46754,\"start\":46743},{\"end\":47327,\"start\":47314},{\"end\":47338,\"start\":47327},{\"end\":47353,\"start\":47338},{\"end\":47366,\"start\":47353},{\"end\":47374,\"start\":47366},{\"end\":47389,\"start\":47374},{\"end\":47820,\"start\":47807},{\"end\":47835,\"start\":47820},{\"end\":47848,\"start\":47835},{\"end\":47863,\"start\":47848},{\"end\":48476,\"start\":48461},{\"end\":48489,\"start\":48476},{\"end\":48500,\"start\":48489},{\"end\":48511,\"start\":48500},{\"end\":48526,\"start\":48511},{\"end\":48538,\"start\":48526},{\"end\":48548,\"start\":48538},{\"end\":49074,\"start\":49056},{\"end\":49092,\"start\":49074},{\"end\":49367,\"start\":49357},{\"end\":49379,\"start\":49367},{\"end\":49392,\"start\":49379},{\"end\":49404,\"start\":49392},{\"end\":49417,\"start\":49404},{\"end\":49426,\"start\":49417},{\"end\":49917,\"start\":49905},{\"end\":49927,\"start\":49917},{\"end\":49936,\"start\":49927},{\"end\":49948,\"start\":49936},{\"end\":49958,\"start\":49948},{\"end\":49969,\"start\":49958},{\"end\":49984,\"start\":49969},{\"end\":50492,\"start\":50479},{\"end\":50501,\"start\":50492},{\"end\":50511,\"start\":50501},{\"end\":50520,\"start\":50511},{\"end\":50529,\"start\":50520},{\"end\":50540,\"start\":50529},{\"end\":51011,\"start\":50994},{\"end\":51027,\"start\":51011},{\"end\":51399,\"start\":51389},{\"end\":51409,\"start\":51399},{\"end\":51418,\"start\":51409},{\"end\":51842,\"start\":51831},{\"end\":51857,\"start\":51842},{\"end\":51867,\"start\":51857},{\"end\":52278,\"start\":52264},{\"end\":52291,\"start\":52278},{\"end\":52307,\"start\":52291},{\"end\":52547,\"start\":52537},{\"end\":52560,\"start\":52547},{\"end\":52574,\"start\":52560},{\"end\":53010,\"start\":53002},{\"end\":53024,\"start\":53010},{\"end\":53045,\"start\":53024},{\"end\":53051,\"start\":53045},{\"end\":53540,\"start\":53528},{\"end\":53553,\"start\":53540},{\"end\":53562,\"start\":53553},{\"end\":53571,\"start\":53562},{\"end\":53585,\"start\":53571},{\"end\":53598,\"start\":53585},{\"end\":54157,\"start\":54143},{\"end\":54176,\"start\":54157},{\"end\":54192,\"start\":54176},{\"end\":54776,\"start\":54760},{\"end\":54801,\"start\":54776},{\"end\":54815,\"start\":54801},{\"end\":54836,\"start\":54815},{\"end\":55313,\"start\":55298},{\"end\":55329,\"start\":55313},{\"end\":55345,\"start\":55329},{\"end\":55357,\"start\":55345},{\"end\":55730,\"start\":55713},{\"end\":55951,\"start\":55937},{\"end\":56357,\"start\":56348},{\"end\":56366,\"start\":56357},{\"end\":56375,\"start\":56366},{\"end\":56389,\"start\":56375},{\"end\":56399,\"start\":56389},{\"end\":56409,\"start\":56399},{\"end\":56421,\"start\":56409},{\"end\":56997,\"start\":56984},{\"end\":57012,\"start\":56997},{\"end\":57025,\"start\":57012},{\"end\":57039,\"start\":57025},{\"end\":57056,\"start\":57039},{\"end\":57549,\"start\":57529},{\"end\":57560,\"start\":57549},{\"end\":57571,\"start\":57560},{\"end\":57584,\"start\":57571},{\"end\":57588,\"start\":57584},{\"end\":58116,\"start\":58106},{\"end\":58127,\"start\":58116},{\"end\":58141,\"start\":58127},{\"end\":58150,\"start\":58141},{\"end\":58162,\"start\":58150},{\"end\":58175,\"start\":58162},{\"end\":58187,\"start\":58175},{\"end\":58199,\"start\":58187},{\"end\":58813,\"start\":58801},{\"end\":58826,\"start\":58813},{\"end\":58837,\"start\":58826},{\"end\":58848,\"start\":58837},{\"end\":58863,\"start\":58848},{\"end\":59402,\"start\":59390},{\"end\":59414,\"start\":59402},{\"end\":59425,\"start\":59414},{\"end\":59438,\"start\":59425},{\"end\":59450,\"start\":59438},{\"end\":59464,\"start\":59450},{\"end\":59474,\"start\":59464},{\"end\":60054,\"start\":60047},{\"end\":60066,\"start\":60054},{\"end\":60077,\"start\":60066},{\"end\":60091,\"start\":60077},{\"end\":60104,\"start\":60091},{\"end\":60115,\"start\":60104},{\"end\":60700,\"start\":60679},{\"end\":60705,\"start\":60700},{\"end\":61161,\"start\":61151},{\"end\":61173,\"start\":61161},{\"end\":61187,\"start\":61173},{\"end\":61206,\"start\":61187},{\"end\":61217,\"start\":61206},{\"end\":61232,\"start\":61217},{\"end\":61242,\"start\":61232},{\"end\":61823,\"start\":61812},{\"end\":61834,\"start\":61823},{\"end\":62246,\"start\":62231},{\"end\":62260,\"start\":62246},{\"end\":62622,\"start\":62611},{\"end\":62634,\"start\":62622},{\"end\":62645,\"start\":62634},{\"end\":62659,\"start\":62645},{\"end\":62672,\"start\":62659},{\"end\":63092,\"start\":63082},{\"end\":63101,\"start\":63092},{\"end\":63116,\"start\":63101},{\"end\":63129,\"start\":63116},{\"end\":63142,\"start\":63129},{\"end\":63153,\"start\":63142},{\"end\":63162,\"start\":63153}]", "bib_venue": "[{\"end\":42649,\"start\":42589},{\"end\":43525,\"start\":43419},{\"end\":44153,\"start\":44092},{\"end\":44666,\"start\":44607},{\"end\":45149,\"start\":45089},{\"end\":45672,\"start\":45585},{\"end\":46983,\"start\":46877},{\"end\":47524,\"start\":47465},{\"end\":48092,\"start\":47986},{\"end\":48715,\"start\":48640},{\"end\":49621,\"start\":49532},{\"end\":50173,\"start\":50087},{\"end\":50707,\"start\":50632},{\"end\":51150,\"start\":51097},{\"end\":51575,\"start\":51505},{\"end\":52008,\"start\":51946},{\"end\":52711,\"start\":52651},{\"end\":53212,\"start\":53140},{\"end\":53783,\"start\":53699},{\"end\":54421,\"start\":54315},{\"end\":54991,\"start\":54922},{\"end\":55492,\"start\":55433},{\"end\":56086,\"start\":56027},{\"end\":56610,\"start\":56524},{\"end\":57193,\"start\":57133},{\"end\":57749,\"start\":57677},{\"end\":58428,\"start\":58322},{\"end\":59092,\"start\":58986},{\"end\":59703,\"start\":59597},{\"end\":60344,\"start\":60238},{\"end\":60874,\"start\":60798},{\"end\":61437,\"start\":61348},{\"end\":61975,\"start\":61913},{\"end\":62397,\"start\":62337},{\"end\":62803,\"start\":62746},{\"end\":63393,\"start\":63286},{\"end\":42649,\"start\":42589},{\"end\":43525,\"start\":43419},{\"end\":44153,\"start\":44092},{\"end\":44666,\"start\":44607},{\"end\":45149,\"start\":45089},{\"end\":45672,\"start\":45585},{\"end\":46983,\"start\":46877},{\"end\":47524,\"start\":47465},{\"end\":48092,\"start\":47986},{\"end\":48715,\"start\":48640},{\"end\":49621,\"start\":49532},{\"end\":50173,\"start\":50087},{\"end\":50707,\"start\":50632},{\"end\":51150,\"start\":51097},{\"end\":51575,\"start\":51505},{\"end\":52008,\"start\":51946},{\"end\":52711,\"start\":52651},{\"end\":53212,\"start\":53140},{\"end\":53783,\"start\":53699},{\"end\":54421,\"start\":54315},{\"end\":54991,\"start\":54922},{\"end\":55492,\"start\":55433},{\"end\":56086,\"start\":56027},{\"end\":56610,\"start\":56524},{\"end\":57193,\"start\":57133},{\"end\":57749,\"start\":57677},{\"end\":58428,\"start\":58322},{\"end\":59092,\"start\":58986},{\"end\":59703,\"start\":59597},{\"end\":60344,\"start\":60238},{\"end\":60874,\"start\":60798},{\"end\":61437,\"start\":61348},{\"end\":61975,\"start\":61913},{\"end\":62397,\"start\":62337},{\"end\":62803,\"start\":62746},{\"end\":63393,\"start\":63286},{\"end\":42587,\"start\":42512},{\"end\":42957,\"start\":42920},{\"end\":43417,\"start\":43296},{\"end\":44090,\"start\":44014},{\"end\":44605,\"start\":44531},{\"end\":45087,\"start\":45012},{\"end\":45583,\"start\":45481},{\"end\":46080,\"start\":46069},{\"end\":46430,\"start\":46372},{\"end\":46875,\"start\":46754},{\"end\":47463,\"start\":47389},{\"end\":47984,\"start\":47863},{\"end\":48638,\"start\":48548},{\"end\":49138,\"start\":49092},{\"end\":49530,\"start\":49426},{\"end\":50085,\"start\":49984},{\"end\":50630,\"start\":50540},{\"end\":51095,\"start\":51027},{\"end\":51503,\"start\":51418},{\"end\":51944,\"start\":51867},{\"end\":52315,\"start\":52307},{\"end\":52649,\"start\":52574},{\"end\":53138,\"start\":53051},{\"end\":53697,\"start\":53598},{\"end\":54313,\"start\":54192},{\"end\":54920,\"start\":54836},{\"end\":55431,\"start\":55357},{\"end\":55787,\"start\":55730},{\"end\":56025,\"start\":55951},{\"end\":56522,\"start\":56421},{\"end\":57131,\"start\":57056},{\"end\":57675,\"start\":57588},{\"end\":58320,\"start\":58199},{\"end\":58984,\"start\":58863},{\"end\":59595,\"start\":59474},{\"end\":60236,\"start\":60115},{\"end\":60796,\"start\":60705},{\"end\":61346,\"start\":61242},{\"end\":61911,\"start\":61834},{\"end\":62335,\"start\":62260},{\"end\":62744,\"start\":62672},{\"end\":63284,\"start\":63162},{\"end\":42587,\"start\":42512},{\"end\":42957,\"start\":42920},{\"end\":43417,\"start\":43296},{\"end\":44090,\"start\":44014},{\"end\":44605,\"start\":44531},{\"end\":45087,\"start\":45012},{\"end\":45583,\"start\":45481},{\"end\":46080,\"start\":46069},{\"end\":46430,\"start\":46372},{\"end\":46875,\"start\":46754},{\"end\":47463,\"start\":47389},{\"end\":47984,\"start\":47863},{\"end\":48638,\"start\":48548},{\"end\":49138,\"start\":49092},{\"end\":49530,\"start\":49426},{\"end\":50085,\"start\":49984},{\"end\":50630,\"start\":50540},{\"end\":51095,\"start\":51027},{\"end\":51503,\"start\":51418},{\"end\":51944,\"start\":51867},{\"end\":52315,\"start\":52307},{\"end\":52649,\"start\":52574},{\"end\":53138,\"start\":53051},{\"end\":53697,\"start\":53598},{\"end\":54313,\"start\":54192},{\"end\":54920,\"start\":54836},{\"end\":55431,\"start\":55357},{\"end\":55787,\"start\":55730},{\"end\":56025,\"start\":55951},{\"end\":56522,\"start\":56421},{\"end\":57131,\"start\":57056},{\"end\":57675,\"start\":57588},{\"end\":58320,\"start\":58199},{\"end\":58984,\"start\":58863},{\"end\":59595,\"start\":59474},{\"end\":60236,\"start\":60115},{\"end\":60796,\"start\":60705},{\"end\":61346,\"start\":61242},{\"end\":61911,\"start\":61834},{\"end\":62335,\"start\":62260},{\"end\":62744,\"start\":62672},{\"end\":63284,\"start\":63162}]"}}}, "year": 2023, "month": 12, "day": 17}