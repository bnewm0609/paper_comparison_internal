{"id": 244302997, "updated": "2022-10-20 13:25:18.432", "metadata": {"title": "Aha! Adaptive History-driven Attack for Decision-based Black-box Models", "authors": "[{\"first\":\"Jie\",\"last\":\"Li\",\"middle\":[]},{\"first\":\"Rongrong\",\"last\":\"Ji\",\"middle\":[]},{\"first\":\"Peixian\",\"last\":\"Chen\",\"middle\":[]},{\"first\":\"Baochang\",\"last\":\"Zhang\",\"middle\":[]},{\"first\":\"Xiaopeng\",\"last\":\"Hong\",\"middle\":[]},{\"first\":\"Ruixin\",\"last\":\"Zhang\",\"middle\":[]},{\"first\":\"Shaoxin\",\"last\":\"Li\",\"middle\":[]},{\"first\":\"Jilin\",\"last\":\"Li\",\"middle\":[]},{\"first\":\"Feiyue\",\"last\":\"Huang\",\"middle\":[]},{\"first\":\"Yongjian\",\"last\":\"Wu\",\"middle\":[]}]", "venue": "2021 IEEE/CVF International Conference on Computer Vision (ICCV)", "journal": "2021 IEEE/CVF International Conference on Computer Vision (ICCV)", "publication_date": {"year": 2021, "month": null, "day": null}, "abstract": "The decision-based black-box attack means to craft adversarial examples with only the top-1 label of the victim model available. A common practice is to start from a large perturbation and then iteratively reduce it with a deterministic direction and a random one while keeping it adversarial. The limited information obtained from each query and inefficient direction sampling impede attack efficiency, making it hard to obtain a small enough perturbation within a limited number of queries. To tackle this problem, we propose a novel attack method termed Adaptive History-driven Attack (AHA) which gathers information from all historical queries as the prior for current sampling. Moreover, to balance between the deterministic direction and the random one, we dynamically adjust the coefficient according to the ratio of the actual magnitude reduction to the expected one. Such a strategy improves the success rate of queries during optimization, letting adversarial examples move swiftly along the decision boundary. Our method can also integrate with subspace optimization like dimension reduction to further improve efficiency. Extensive experiments on both ImageNet and CelebA datasets demonstrate that our method achieves at least 24.3% lower magnitude of perturbation on average with the same number of queries. Finally, we prove the practical potential of our method by evaluating it on popular defense methods and a real-world system provided by MEGVII Face++.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/iccv/LiJC0HZLLHW21", "doi": "10.1109/iccv48922.2021.01586"}}, "content": {"source": {"pdf_hash": "4462624dad535fa956d2a7eda98fc2d5ac313c64", "pdf_src": "IEEE", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "0655f8eb9c522b9a4f939e5357d7c2973b8f1eda", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/4462624dad535fa956d2a7eda98fc2d5ac313c64.txt", "contents": "\nAha! Adaptive History-driven Attack for Decision-based Black-box Models\n\n\nJie Li \nSchool of Informatics\nMAC Lab\nXiamen University\n\n\nRongrong Ji \nSchool of Informatics\nMAC Lab\nXiamen University\n\n\nPeng Cheng Lab\n\n\nInstitute of Artificial Intelligence\nXiamen University\n\n\nPeixian Chen \nSchool of Informatics\nMAC Lab\nXiamen University\n\n\nYoutu Lab\nTencent\n\nBaochang Zhang \nBeihang University\n\n\nXiaopeng Hong \nXi'an Jiaotong University\n\n\nRuixin Zhang \nYoutu Lab\nTencent\n\nShaoxin Li \nYoutu Lab\nTencent\n\nJilin Li \nYoutu Lab\nTencent\n\nFeiyue Huang \nYoutu Lab\nTencent\n\nYongjian Wu \nYoutu Lab\nTencent\n\nAha! Adaptive History-driven Attack for Decision-based Black-box Models\n10.1109/ICCV48922.2021.01586\nThe decision-based black-box attack means to craft adversarial examples with only the top-1 label of the victim model available. A common practice is to start from a large perturbation and then iteratively reduce it with a deterministic direction and a random one while keeping it adversarial. The limited information obtained from each query and inefficient direction sampling impede attack efficiency, making it hard to obtain a small enough perturbation within a limited number of queries. To tackle this problem, we propose a novel attack method termed Adaptive History-driven Attack (AHA) which gathers information from all historical queries as the prior for current sampling. Moreover, to balance between the deterministic direction and the random one, we dynamically adjust the coefficient according to the ratio of the actual magnitude reduction to the expected one. Such a strategy improves the success rate of queries during optimization, letting adversarial examples move swiftly along the decision boundary. Our method can also integrate with subspace optimization like dimension reduction to further improve efficiency. Extensive experiments on both Im-ageNet and CelebA datasets demonstrate that our method achieves at least 24.3% lower magnitude of perturbation on average with the same number of queries. Finally, we prove the practical potential of our method by evaluating it on popular defense methods and a real-world system provided by MEGVII Face++.\n\nIntroduction\n\nWith the rapid development and the dominant performance, deep neural networks (DNNs) have been successfully deployed to improve productivity in many fields, e.g., the voice assistant in smart speakers, image recognition APIs on the cloud, and automatic pilot in vehicles. Though many effort have been put into explaining the DNNs [1,18,19,43], DNNs are still far from full control-* R. Ji (rrji@xmu.edu.cn) is the corresponding author. lable and have been proven to be vulnerable to carefully crafted imperceptible perturbations, i.e., adversarial perturbations [41], which poses threats to the application of DNNs in security scenarios.\n\nTherefore, many methods have been proposed to evaluate the robustness of the DNNs under different settings [13,4,21]. Among all the settings, the black-box setting is the most practical but challenging one since only the corresponding outputs are available. Some attack methods [29,38,37] craft adversarial examples on white-box models and transfer them to the victim model. These transfer-based methods consume fewer resources but can not guarantee a high attack success rate. Some adversaries turn to query the model repeatedly. Depending on the form of the outputs, query-based black-box attack methods can be further divided into the score-based attack and decisionbased attack. Outputs of the former one are usually continuous and floating numbers (e.g., class probabilities) responding to the change of input rapidly, which is able to guide the perturbation generation step by step. The decision-based attack setting is more challenging where the adversary can only fetch the result whether the input belongs to the same class as the target sample or not. Such a setting usually is correlated to a target attack whose goal is to craft an adversarial example classified as a target one.\n\nThe most classic decision-based attack, Boundary Attack [2], starts from an adversarial example and search along two directions: the source direction towards the source image directly for reducing perturbation and the spherical direction randomly sampled from the normal distribution for exploring. However, this method mainly depends on random sampling without utilizing information from prior queries efficiently, resulting in an enormous number of queries. Many methods have been proposed to improve it. Biased Boundary Attack [3] introduces three biases to improve the efficiency of direction sampling. Evolutionary Attack [10] reduces the solution space and models the local geometry via successful queries with (1+1)-CMA-ES optimization. However, without taking full advantage of all information from all queries, these methods still re-quire a large number of queries to reduce the magnitude of the perturbations. Moreover, the trade-off of the two directions also impacts a lot. We argue that large coefficient for the direction reducing the perturbation brings more queries crossing the boundary and then failing, but large coefficient for the exploring direction will increase the number of queries. Existing methods adjust the corresponding coefficients based on whether the query is adversarial. Such a binary value gives a coarse guide thereby leaving coefficient adjustment inflexible.\n\nIn this paper, towards obtaining perturbations with smaller magnitude under fewer queries, we propose the Adaptive History-driven Attack (AHA) which makes use of information from all queries with an adaptive coefficient adjustment strategy. Following the boundary attack, AHA starts from a large perturbation, and then reduces it iteratively with a determinate direction (i.e., source direction) and a random direction. Instead of randomly sampling from a standard normal distribution for the random direction, we gather information from historical queries and apply it as the prior for current sampling. Such a method is simple yet efficient without extra computation cost added. To balance between the source direction and the direction driven by historical queries, considering that the purpose of coefficient adjusting is to reduce the magnitude of the perturbations as much as possible, we dynamically adjust the coefficient based on the ratio of the actual reduction on perturbation's magnitude to the expected one. This strategy reduces the chance of getting stuck into the decision boundary. Besides, the optimization method is orthogonal to the existing subspace method like dimension reduction. These methods can be integrated to further improve performance. We conduct extensive experiments on various models including a real-world online system to demonstrate the efficiency of the proposed AHA. We conclude our contributions as:\n\n\u2022 We propose a simple yet efficient decision-based attack method, termed Adaptive History-driven Attack (AHA), which utilizes information of both successful and failed historical queries as the prior for current sampling without complex optimization and extra computation cost added.\n\n\u2022 To balance between two directions during the optimization process, we design a novel strategy to adjust the coefficient dynamically. Instead of on how often the optimization successes, the coefficient is adjusted based on the degree of the actual reduction on the magnitude compared with the expected one, which increases the probability of finding valid queries.\n\n\u2022 Finally, we evaluate AHA on models for natural images and human faces. The perturbations generated by AHA are smaller than the state-of-the-art method with the same number of queries. Furthermore, the effectiveness of AHA on the real-world system, i.e., face verification API from MEGVII Face++, is also verified with 24.9% smaller perturbations than baseline.\n\n\nRelated Work\n\nScore-based Attack. Due to the fact that outputs fetched are continuous and floating numbers, every small change in input will give an instant response. It is natural to estimate the value of the gradient, and then perform the white-box attack. ZOO [6] estimates the value of the gradient using the finite-difference method. With such a dimension-wise way, it takes 2d queries each time to estimate the gradient. Instead of the finite-difference method, NES [20] utilizes the natural evolutionary strategy with random vectors sampled from the normal distribution to reduce the required number of queries. Bandits T D [21] method further introduces a data-dependent and a time-dependent prior to improve the efficiency of gradient estimation. Instead of gradient estimation, some methods adopt random search strategies. SimBA [15] crafts a set of orthonormal vectors first, then randomly picks one from the set and adds or subtracts it if the objective function decreases. PPBA [24] reduces the dimension with low-frequency constraint and performs random walk optimization on the low dimension space.\n\nDecision-based Attack. Unlike the score-based attack, the outputs of models in the decision-based attack are only the labels. Such a hard-label setting increases the difficulty since the tiny change of the input may not reflect on the output. Opt-Attack [7] re-formulates this problem as a continuous optimization problem w.r.t the direction and distance to the decision boundary, and performs gradient estimation on it. However, this method is ineffective since the distance calculation and gradient estimation on the large dimension will consume an enormous number of queries. HSJA [5] directly performs the gradient estimation on the decision boundary with binary outputs. And QEBA [23] further improves the performance by adopted subspace on HSJA. However, hundreds of queries are needed for one time gradient estimation, which makes these methods still inefficient. Boundary attack [2] starts from a large adversarial perturbation and simultaneously reduces it with source direction and spherical direction. It bases on random walk optimization and rejects updating when not adversarial. This method is simple but the usage of standard normal distribution impedes efficiency. Biased Boundary Attack [3] introduces some biases to improve the boundary attack. Instead of the normal distribution, the Perlin distribution is adopted for low-frequency constraint, and the difference between the adversarial example and the source image is used as the weight for pixels. This method reduces the solution space, but it is not enough. Evolutionary method [10] replaces the normal distribution with a custom variance. The variance is updated with (1+1)-CMA-ES when sampling is successful to model the weight for each pixel. However, the variance is sign-independent, which makes the sampling unstable. CAB [32] uses the square of the difference between the adversarial example and the source image as variance and accumulates the directions when failed for the mean. SurFree [28] tries to move along diverse directions guided by the geometrical properties of the decision boundary. Though these optimization methods are well-designed, they are complex and still not efficient enough.\n\n\nProposed Method\n\nThroughout this paper, we focus on reducing the magnitude of the perturbations within limited queries under the decision-based target black-box attack setting. Based on the boundary attack, we perform the random walk optimization with historical queries as prior as detailed in Sec. 3.2. Coefficients of the two search directions play an important role as to move towards the source input more or to learn from the history more. To balance them, a novel adaptive adjusting strategy is proposed in Sec. 3.3. The optimization method can be further improved with the help of the subspace optimization as in Sec. 3.4. In the rest of this section, we will first introduce the preliminary knowledge and then give a thorough description of our proposed method.\n\n\nPreliminaries\n\nSuppose we have a source input sample x s , a target one x t , and a deep neural network based function f (x 1 , x 2 ) : X \u00d7 X \u2192 Y to determine whether the two input sample belong to the same class, where X = [0, 1] d is the space for images with d-dimension and Y = {0, 1} (1 denotes the two inputs share the same class). The aim of decision-based target attack is to find an adversarial example x that close to the source input x s as far as possible while keep f (x , x t ) = 1. We have a objective function as:\nmin x L(x ) = D(x , x s ) + \u03bb \u00b7 (1 \u2212 f (x , x t )), (1)\nwhere \u03bb is a very large number to make sure L(x ) large enough when the adversarial objective is unsatisfied, and D(\u00b7, \u00b7) is the distance function. In this paper, we select L 2 norm as the distance function, i.e.,\nD(x , x s ) = x \u2212x s 2 .\nFollowing the common practice [2, 10], we start from an adversarial sample (with the same class as the target one), e.g., the target sample x t , and then move it close to the original sample x s as much as possible iteratively with a constraint on the number of queries. A common update formula can be represented as:\nx k+1 = x k + \u03b1 \u00b7 xs \u2212 x k xs \u2212 x k 2 + \u03b2 \u00b7 \u03b7 \u03b7 2 , \u03b7 \u223c N (0, I) (2)\nwhere x k is the adversarial example at the k-th steps and x s is the source input, (x s \u2212 x k ) and \u03b7 are the source direc-tion and spherical direction, respectively. \u03b1 and \u03b2 are the corresponding coefficients. The update value can be further multiplied by the distance between the current sample and the original sample to reduce the update value iteratively for better convergence:\nx k+1 = x k + (\u03b1 \u00b7 x s \u2212 x k x s \u2212 x k 2 + \u03b2 \u00b7 \u03b7 \u03b7 2 ) \u00b7 x s \u2212 x k 2 = x k + \u03b1 \u00b7 (x s \u2212 x k ) + \u03b2 \u00b7 \u03b7 \u03b7 2 \u00b7 x s \u2212 x k 2 .(3)\nHere a query is called a successful query if the x k+1 is still adversarial, and it will be called a failed one otherwise. Note that in some previous works, x k+1 will be accepted only if L(x k+1 ) is less than or equal to L(x k ) as the common practice in the random walk optimization. To avoid falling into the local optimum, we only reject failed samples. If the x k+1 is rejected, then we set x k+1 = x k for the ease of representation.\n\n\nHistorical Prior Based Optimization\n\nReexamining Eq. 3 carefully, the only uncertainty lies in the random direction which influences the efficiency of the optimization method greatly. Previous methods also made efforts on it. The key question is that how to make the random direction sampled more efficiently. Some previous works have proven that the decision boundaries of deep neural networks have a quite small curvature in the vicinity of data samples [12], which indicates that the decision boundary at the neighborhood of adversarial example can be approximated locally with a hyperplane [25,30]. Since the boundary is flat, we can confidently assume the current random direction and one of the last iteration or even more early iterations are consistent to some degree. Also, there are some previous works showing that historical information is helpful for current sampling [10,21,24,32]. However, we argue that the exist methods utilizing historical prior is complicate and not thoroughgoing. For example, Evolutionary Attack [10] utilizes only successful queries while CAB [32] utilizes only failed queries, and Bandits T D [21] utilizes all queries but does not distinguish successful and failed queries well.\n\nThe flat boundaries and the lack of making the best of historical information motivate us to use a more simple but efficient way to guide the random direction. As [2,10], we treat the historical prior as a custom gaussian distribution. Though the variance of the distribution can model the importance of each pixel naturally, modifying the variance also introduces instability since the variance is signindependent which can not guide the direction well. Instead of variance, we focus on the mean \u00b5 of the distribution and embed the information of both successful historical queries and failed ones in it. For the successful query x k+1 where f (x k+1 , x t ) = 1, as talked above, the next direction will succeed with a high probability if they share similar direction since the decision boundary is flat. While for the failed query, as stated in [32], it also contains information about the decision boundary since the failed query crosses through the boundary. Similar to [32], its opposite direction is considered. In particular, we update the mean \u00b5 with:\n\u00b5 = (1 \u2212 \u03b3) \u00b7 \u00b5 + \u03b3 \u00b7 \u03b7, f (x k+1 , x t ) = 1 (1 \u2212 \u03b3) \u00b7 \u00b5 \u2212 \u03b3 \u00b7 \u03b7, f (x k+1 , x t ) = 0 ,(4)\nwhere \u03b3 \u2208 (0, 1) is a coefficient to control how fast to forget the older information since the geometry properties of the decision boundary will change along with the shift of the adversarial example. Since the direction is driven by the historical queries, we named it the history-driven direction.\n\n\nCoefficient Adaptive Adjusting\n\nAnother significant issue is how to balance between the source direction and the history-driven direction. A large coefficient \u03b1 for source direction is helpful to reduce the magnitude of the perturbations quickly, while it raises the probability to hit the decision boundary and thereby leading to a failed query. On the contrary, a small \u03b1 allows the optimization method to explore the decision boundary much, while it will decelerate the progress of approaching the source input and increase the number of queries. Therefore, an adaptive adjusting strategy is needed.\n\nPrevious methods also noticed such a problem and put effort into it. The boundary attack method samples more points with orthogonal directions to test the success rate, and reduce the coefficient if the success rate is much lower or increase it if the success rate is close to 50% or higher. The Biased Boundary Attack uses large coefficients at the beginning and decreases it when the number of failed queries increased. The coefficients are reset when a successful query occurs. As a evolution strategy, the evolutionary method utilizes a traditional method for hyper-parameter control in evolution strategies termed 1/5th success rule [31] to update the coefficient by multiplying exp(P success \u2212 1/5), where P success denotes the success rate of several past iterations. Note that the existing methods are all based on the success rate, and every query can only offer coarse binary feedback (i.e., successful or not).\n\nConsidering that the purpose of coefficient adjusting is to reduce the magnitude of the perturbations as much as possible, it motivates us to consider how the magnitude of perturbations is reduced. Therefore, instead of considering the success rate, we adjust the coefficient \u03b1 based on the ratio of the actual magnitude reduction to the expected one. The actual magnitude reduction can be calculated straightly with the difference between the two distance as:\nR actual = D(x k , x s ) \u2212 D(x k+1 , x s ) = x k \u2212 x s 2 \u2212 x k+1 \u2212 x s 2 .(5)\nFor the expected reduction, we then view the length of the projection of update part on the source direction as the expected reduction:\nR expected = \u03b1 \u00b7 (x s \u2212 x k ) + \u03b2 \u00b7 \u03b7 \u03b7 2 x s \u2212 x k 2 T x s \u2212 x k x s \u2212 x k 2 =\u03b1 \u00b7 x s \u2212 x k 2 + \u03b2 \u00b7 \u03b7 T (x s \u2212 x k ) \u03b7 2 .(6)\nDepending on the value of R actual , there are three situations. When R actual = 0, we know that a failed query occurs and we should explore more by reducing \u03b1. When R actual > 0, we are moving towards the source sample and now 0 < R actual \u2264 R expected . So the larger the R actual /R expected is, the more important the source direction is, and the larger the corresponding coefficient, i.e., \u03b1, should be. When R actual < 0, it is most likely that the optimization method gets stuck in local optimum, and should turn away from the source sample to escape it. In such a situation, R actual \u2264 R expected < 0. We calculate the ratio as R expected /R actual for a value belonging to [0, 1]. Similarly, we prefer small \u03b1 for a small ratio to help escape from the local optimum and large \u03b1 for a large ratio to prevent the optimization method from keeping moving away from the source sample. Based on above discussion, we unify the ratio of R actual and R expected as: r = min abs(R actual ), abs(R expected ) max abs(R actual ), abs(R expected ) .\n\nNote that the ratio r \u2208 [0, 1], and we should increase the coefficient \u03b1 when r is large and decrease \u03b1 otherwise. And for the failed query where x k+1 = x k , the R actual and the ratio r are equal to zero. Therefore, we can find that the success rate based method is just a particular case of our method when r is mapped as sign(r). Note that too small \u03b1 may result in forever exploring. So we reset the value of \u03b1 when it is less than a threshold. Finally, we update the coefficient \u03b1 as:\n\u03b1 = \u03b1 \u00b7 h(r), \u03b1 = \u03b1, \u03b1 > \u03b1 threshold \u03b1 initial , otherwise ,(8)\nwherer is the mean of ratios r's over several past iterations, h(\u00b7) : [0, 1] \u2192 R + is a function that maps the ratio to a suitable value, \u03b1 threshold is the value preventing too small \u03b1, and \u03b1 initial is the initial value for \u03b1. h(\u00b7) should be monotonically increasing with 0 < h(0) < 1 and h(1) > 1. In this paper, we experimentally select h(\u00b7) as h(r) = (r + 0.8) 2 .\n\n\nAlgorithm 1: Adaptive History-driven Attack\n\nInput: Victim model f (\u00b7, \u00b7), source image x s , target image x t , maximum number of queries Q, initial direction coefficients \u03b1 and \u03b2, coefficients \u03b3, and interval i.\nOutput: Adversarial example x . 1 Initialize q \u2190 0, q last \u2190 0, x \u2190 x t , \u00b5 \u2190 0,r \u2190 0 2 while q < Q do 3 Sample \u03b7 \u223c N (\u00b5, I) 4 Upscale \u03b7 to the same dimension of x for \u03b7 5 x temp \u2190 x +\u03b1\u00b7(x s \u2212x )+\u03b2 \u00b7 \u03b7 \u03b7 2 \u00b7 x s \u2212x 2 6 if f (x temp , x ) = 1 then 7 x \u2190 x temp 8 \u00b5 \u2190 (1 \u2212 \u03b3) \u00b7 \u00b5 + \u03b3 \u00b7 \u03b7 9 else 10 \u00b5 \u2190 (1 \u2212 \u03b3) \u00b7 \u00b5 \u2212 \u03b3 \u00b7 \u03b7 11\nCalculate r according to Eq. 7\n\n\n12\n\n// Calculate the running mean\n13r \u2190 q\u2212qlast q\u2212qlast+1 \u00b7r + 1 q\u2212qlast+1 \u00b7 r 14 if q \u2212 q last = i then 15\nUpdate \u03b1 by Eq. 8 16 q last \u2190 q 17r \u2190 0 18 q \u2190 q + 1 19 end 20 return x\n\n\nSubspace Sampling\n\nThe large solution space is most blamed in black-box attacks, and many methods including dimension reduction [21,10,23] and low-frequency constraints [3,24] have been proposed to reduce it and these methods do accelerate the attack process. These subspace optimization methods are orthogonal to our method and can be integrated to further improve the performance. Considering that dimension reduction with bilinear interpolation is more simple and fast compared with the other methods, we sample the direction \u03b7 in the low dimensional space and then upscale it with bilinear interpolation to original input space. Following [23], the dimension of low space will be 1/16 of the original one.\n\nWe refer to the method combining the three parts mentioned above as Adaptive History-driven Attack (AHA), and conclude the details in Alg. 1.\n\n\nExperiments\n\n\nExperimental Setups\n\nDatasets and Victim Models. We mainly evaluate the effectiveness on the natural image dataset ImageNet [8] and human face dataset CelabA [26]. For the ImageNet dataset, we select the widely used pre-trained models including VGG-16 [33], ResNet50 [17], and Inception-V3 [35] as the victim models. We randomly select 100 pairs of images from the validation set for evaluation. The images in each pair are from different classes and are classified correctly by all three models. The input image size is 224 \u00d7 224 \u00d7 3 for VGG-16 and ResNet50, and 299 \u00d7 299 \u00d7 3 for Inception-V3, respectively. For the CelebA dataset, we evaluate the attack methods on state-of-the-art face recognition models, i.e., CosFace [36] and ArcFace [9]. Both models are trained on MS1M dataset [16] with Inception-ResNet-152 [34] as backbone 1 . Similar to the ImageNet dataset, we also randomly select 100 pairs of faces from 200 different people that are distinguished well by the two models. These face images are pre-processed by MTCNN [42] with size of 112 \u00d7 112 \u00d7 3. For defense methods, we perform attacks on 100 images randomly sampled from the CIFAR-10 dataset [22] with the Wide ResNets [40] as the target model. For the online model, we test the robustness of the face verification API proposed by Face++ 2 . We choose 10 pairs of face images randomly from the CelebA with the same settings as the offline face verification experiments.\n\nEvaluation Metrics. To judge how efficient an attack method is, we mainly check the mean L 2 -norm of the final adversarial perturbations under the same number of queries since the adversarial example is guaranteed to be adversarial. The smaller the L 2 -norm is, the more efficient the attack method is. To show how fast the optimization method can find a small perturbation, we depict the curve of the mean L 2 -norm versus the number of queries. For quantitative comparison, we calculate the area under the curve (AUC), where the lower value denotes better performance. The attack success rate (ASR) is also a common metric for the adversarial attack. Considering that dimensions of the input image and degree of difficulty for different tasks are different, we define a successful adversarial example with dimension d as the one whose L 2 -norm of the perturbation is less than \u221a 0.001 \u00b7 d for the ImageNet dataset and \u221a 0.0001 \u00b7 d for the CelebA dataset. We report the attack success rate on the final adversarial examples.\n\nCompared Methods and Hyper-parameters Settings. We mainly compare our proposed AHA with four popular decision-based attack methods, i.e., HSJA [5], QEBA [23], Biased Boundary Attack (BBA) [3], Evolutionary Attack [10], and SurFree [28]. For all the baselines, we use the source code kindly provided by the authors and the default parameters announced in their papers.  model. And we select QEBA-S for QEBA due to its best performance as shown in their paper. For hyper-parameters in our AHA, we set both the \u03b1 and \u03b2 to 0.01 initially following [2,10]. We also set \u03b3 as 0.01 and the interval i as 30.\n\nFollowing [5,23], we set the maximum number of queries as 20, 000 for ImageNet and CelabA models. The maximum number of queries for the defense methods is set as 50, 000. Considering that querying real-world online systems is costly and time-consuming, we limit the maximum number of queries for the online system to 5, 000.\n\n\nResults on ImageNet and CelabA Models\n\nWe evaluate the performance of our proposed AHA along with the baselines in Tab. 1 for the ImageNet dataset and in Tab. 2 for the CelebA dataset, respectively. As in the Tab. 1 for the ImageNet dataset, we can find that our proposed AHA achieves the best performance on all three widely-used models. Particularly, the mean L 2 -norm of perturbations found by our method is 27.6%, 24.7%, and 24.3% less than the second-best method, i.e., the Evolutionary attack, on the VGG-16, ResNet50, and Inception-V3 respectively. The value of AUC represents how fast the optimization method can reduce the magnitude of the perturbation. It is worth noting that though the final mean L 2 is not small enough, the AUCs of the QEBA are less than other baselines. However, our proposed method still achieves a smaller AUC compared with the QEBA method with 10.1%, 11.8%, and 13.3% less. This can also be concluded from Fig. 1 where the curves of our method are at the bottom. The attack success rate represents how often the optimization method can find a valid adversarial example. From Tab. 1, we also find our proposed AHA achieves the highest attack success rate among the attack methods, which demonstrates most of the adversarial examples found by AHA are valid. For example, for Inception-V3, our method achieves a 91% attack success rate, which is 27% higher than the state-of-the-art method. To give a more direct comparison, we draw the curves of attack success rates versus the number of queries in Fig. 2. At the beginning, the BBA method works well. And then after nearly 10, 000 queries, with enough historical accumulation, the attack success rate of our proposed AHA increases steeply and is higher than baselines. We also test the performance on the CelebA dataset in the Tab. 2. From the Tab. 2, we can conclude that AHA is not just efficient on the natural image dataset but also efficient on the human face dataset. Though the AUC on the ArcFace model of our AHA is larger than the one of the BBA method, our proposed method still achieves nearly the best performance over the three metrics. Also, we find that the CosFace model is more robust than the ArcFace against such a hard-label black-box attack. It is also interesting that the AUC of the QEBA method is lower than the HSJA while the mean L 2 -norm and attack success rate of QEBA show no superiority for both datasets. Note that the QEBA can be viewed as the HSJA combined with the subspace optimization. We conclude that the subspace optimization helps faster convergence but leads to suboptimal results. So an adaptive subspace optimization will be helpful and we leave it as future work.\n\n\nAttack Against Defense Methods\n\nAlong with the development of the attack methods, many studies proposed defense methods to protect their models. To verify the effectiveness of our AHA method under this setting, we evaluate the performance of AHA along with some baselines on 100 images randomly sampled from the CIFAR-10 test set with 10 images per class. For each image, we randomly select another image from the 100 images as the target. And we use the Wide ResNets architecture with 28 layers and a width multiplier of 10 (denoted as WRN-28-10) as the target model. For defense methods, we utilize widely used bit-depth reduction [39], JPEG compression [11] and adversarial training [27]. The resutls are presented in Tab. 3 where None denotes the vanilla model without defense. We can conclude that our proposed AHA still works well for all defense methods. For example, for the adversarial training model, the mean L 2 -norm of our perturbations is 1.8825, which is 28.5% less than HSJA and  36.0% less than Evolutionary.\n\n\nResults on Online System\n\nTurning attention to the robustness of real-world systems, we finally test the effectiveness of our method against the online system, i.e., face verification API provided by MEGVII Face++. This API allows users to upload two face images and then returns a similarity score of them along with some thresholds. And two faces are recognized as the same person to some degree when the similarity score is higher than the corresponding threshold. Here we use the highest threshold returned and the attack method can only obtain whether the two faces belong to the same identity or not instead of the similarity score. Considering the querying is costly, we only attack this API using the Evolutionary and AHA on 10 pairs randomly selected and set the maximum query time to 5, 000. The final mean L 2norm of the perturbations for the Evolutionary and ours are 14.544 and 10.910, respectively. We also give visual examples in Fig. 3 showing adversarial face images with different queries. Such results demonstrate that AHA is practical for real-world systems.\n\n\nAblation Study\n\nIn this subsection, we will examine how much the coefficient adaptive adjusting strategy and the subspace optimization contribute to the final performance. For the coefficient adjusting strategy, we compare the 1/5th Success Rule with our strategy on AHA. To save computing resources, we select some simple formulas for h(\u00b7) as listed in Tab. 4. We first find that with the 1/5th Success Rule, AHA is still more efficient than baselines like the Evolutionary. And our coefficient adjusting strategy, with proper h(\u00b7), can further improve the performance. Here we select h(r) = (r+0.8) 2 for its stable AUC. To further prove the effectiveness of the proposed coefficient adjusting strategy, we check how often the optimization method can find a successful query. Therefore, we depict the curves of success rate versus the number of queries in Fig. 4 for the Evolutionary, our method with 1/5th Success Rule, and our method with the proposed adjusting strategy. For better visualization, we smooth the curves by drawing the mean of an interval of 40. The success rate of our proposed adjusting strategy increases sustainably and is higher than others, which helps the optimization method move along the decision boundary swiftly. As mentioned in Sec. 3.4, the subspace optimization method is orthogonal to our method and can be combined for better performance. Note that some of the baselines also use the subspace optimization method to improve performance. The QEBA and the Evolutionary methods use bilinear interpolation for dimensionality reduction, and the BBA uses Perlin noise for the low-frequency space constraint. Here we check the influence of two widely used subspace optimization methods, i.e., bilinear interpolation for dimensionality reduction (abbreviated as DR), and lowpass filtering via DCT (similar to Perlin noise but more simple). Following [23,14], we set scale factor as 4 for both DR and DCT. The results of our proposed AHA with or without subspace optimization can be found in the Tab. 5. We can conclude that with single subspace optimization, performance can be improved significantly, e.g., mean L 2 -norm  Table 5. Results with/without subspace optimization. reduced from 10.823 to 6.203. DR works similar to DCT. However, the time DCT consumes is approximately 4 times longer than DR, which makes DR more competitive. We also find that combining DR and DCT results in the worst performance, we guess that too many constraints limit the optimization method. Based on the above observations, we choose DR as a part of our method.\n\nWe also give a brief study on using different historial queries. We evaluated the average of L 2 norm for ResNet50 on ImageNet of two cases, i.e., only using failed queries (6.950) and only using successful queries (7.465). Since the success rate for queries is lower than 30% as shown in Fig. 4 and more queries tend to be failed, the former case utilizes more informative queries and performs better than the latter one. Besides, our method using all queries (6.203) is the best among them. We can conclude that utilizing more informative queries leads to higher performance, which also supports our motivation.\n\n\nConclusion\n\nIn this paper, we propose a simple yet efficient decisionbased black-box attack method termed Adaptive Historydriven Attack (AHA), which mainly utilizes information of historical queries as a prior to improve the random walk optimization. To balance between two directions during optimization, a novel coefficient adaptive adjusting strategy is also proposed based on how the magnitude of the perturbation is reduced. We evaluate our proposed method on both the natural image dataset and the human face dataset and show a higher attack performance of AHA compared with the state-of-the-art methods. Finally, we also check the effectiveness of our proposed method against some popular defense methods and a real-world face verification system provided by Face++. Our work shows that though difficult, the decision-based black-box attack is still achievable without any complicated method. We hope this work can serve as an inspiration in designing more robust models.\n\nFigure 1 .Figure 2 .\n12The curves of mean L2-norm versus the number of queries for the ImageNet dataset. (Lower is better) The curves of attack success rate versus the number of queries for the ImageNet dataset. (Higher is better)\n\nFigure 3 .\n3The example of AHA and Evolutionary on Face++ API. (Best view zoomed in)\n\n\nNote that for a fair comparison, we do not utilize any extra surrogate model for all methods, thereby no surrogate model bias for the BBA. We believe all methods can benefit from the extra surrogateTable 1. Results of our proposed AHA and baselines on the ImageNet dataset. Note that the AUC denotes the area under the curve of L2-norm versus the number of queries and ASR denotes the attack success rate of the final adversarial example.Methods \n\nVGG-16 \nResNet50 \nInception-V3 \nmean L 2 \nAUC \nASR mean L 2 \nAUC \nASR mean L 2 \nAUC \nASR \nHSJA \n11.833 \n580609.2 75% \n12.009 \n613671.2 65% \n32.145 \n1161506.0 19% \nQEBA \n11.350 \n430284.8 67% \n12.074 \n441363.8 57% \n19.807 \n710941.6 \n27% \nBBA \n15.141 \n660683.2 70% \n13.183 \n523421.3 64% \n20.328 \n746100.3 \n57% \nEvolutionary \n8.305 \n445020.9 93% \n8.238 \n451534.7 89% \n14.494 \n725262.1 \n64% \nSurFree \n6.579 \n564050.6 93% \n8.451 \n607074.5 81% \n14.081 \n810286.5 \n71% \nOurs \n6.013 \n386623.6 96% \n6.203 \n389357.9 96% \n10.976 \n616167.4 91% \n\n\n\n\nFigure 4. The curves of success rate for queries versus the number of queries. The curves are smoothed for better visualization. Ours 1/5 denotes our historical prior with the 1/5th Success Rule. (Best view in color)Strategies \n\nResNet50 \nInception-V3 \nmean L 2 \nAUC \nmean L 2 \nAUC \n1/5th Success Rule \n6.638 \n404310.2 \n11.507 \n643280.9 \nh(r) = exp(r \u2212 0.2) \n6.154 \n398307.0 \n11.222 \n641313.8 \nh(r) =r + 0.8 \n6.168 \n393999.3 \n10.751 \n620673.0 \nh(r) = (r + 0.6) 2 \n20.813 \n652617.2 \n29.989 \n953790.4 \nh(r) = (r + 0.7) 2 \n8.329 \n427764.1 \n13.654 \n660240.3 \nh(r) = (r + 0.8) 2 \n6.203 \n389357.9 \n10.976 \n616167.4 \nh(r) = (r + 0.9) 2 \n9.643 \n506123.7 \n16.604 \n782229.9 \nh(r) = (r + 0.8) 3 \n6.396 \n400115.1 \n11.211 \n628122.4 \n\nTable 4. Results for different coefficient adjusting strategies. \n\n(a) VGG-16 \n(b) ResNet50 \n\n\nThese models are trained following https://github.com/ ZhaoJ9014/face.evoLVe.PyTorch 2 https://www.faceplusplus.com/face-comparing/\nAcknowledgements. This work is supported by the National Sci-\nNetwork dissection: Quantifying interpretability of deep visual representations. David Bau, Bolei Zhou, Aditya Khosla, Aude Oliva, Antonio Torralba, IEEE Conference on Computer Vision and Pattern Recognition. David Bau, Bolei Zhou, Aditya Khosla, Aude Oliva, and Antonio Torralba. Network dissection: Quantifying inter- pretability of deep visual representations. In IEEE Confer- ence on Computer Vision and Pattern Recognition, 2017.\n\nDecision-based adversarial attacks: Reliable attacks against black-box machine learning models. Wieland Brendel, Jonas Rauber, Matthias Bethge, International Conference on Learning Representations. Wieland Brendel, Jonas Rauber, and Matthias Bethge. Decision-based adversarial attacks: Reliable attacks against black-box machine learning models. In International Con- ference on Learning Representations, 2018.\n\nGuessing smart: Biased sampling for efficient black-box adversarial attacks. Thomas Brunner, Frederik Diehl, Michael Truong Le, Alois Knoll, IEEE International Conference on Computer Vision. Thomas Brunner, Frederik Diehl, Michael Truong Le, and Alois Knoll. Guessing smart: Biased sampling for efficient black-box adversarial attacks. In IEEE International Confer- ence on Computer Vision, 2019.\n\nTowards evaluating the robustness of neural networks. Nicholas Carlini, David Wagner, IEEE Symposium on Security and Privacy. Nicholas Carlini and David Wagner. Towards evaluating the robustness of neural networks. In IEEE Symposium on Secu- rity and Privacy, 2017.\n\nHopskipjumpattack: A query-efficient decision-based attack. Jianbo Chen, Michael I Jordan, Martin J Wainwright, IEEE Symposium on Security and Privacy. Jianbo Chen, Michael I. Jordan, and Martin J. Wainwright. Hopskipjumpattack: A query-efficient decision-based attack. In IEEE Symposium on Security and Privacy, 2020.\n\nZoo: Zeroth order optimization based blackbox attacks to deep neural networks without training substitute models. Pin-Yu Chen, Huan Zhang, Yash Sharma, Jinfeng Yi, Cho-Jui Hsieh, ACM Workshop on Artificial Intelligence and Security. Pin-Yu Chen, Huan Zhang, Yash Sharma, Jinfeng Yi, and Cho-Jui Hsieh. Zoo: Zeroth order optimization based black- box attacks to deep neural networks without training substi- tute models. In ACM Workshop on Artificial Intelligence and Security, 2017.\n\nQuery-efficient hard-label black-box attack: An optimization-based approach. Minhao Cheng, Thong Le, Pin-Yu Chen, Huan Zhang, Jin-Feng Yi, Cho-Jui Hsieh, International Conference on Learning Representations. Minhao Cheng, Thong Le, Pin-Yu Chen, Huan Zhang, Jin- Feng Yi, and Cho-Jui Hsieh. Query-efficient hard-label black-box attack: An optimization-based approach. In In- ternational Conference on Learning Representations, 2019.\n\nImagenet: A large-scale hierarchical image database. Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, Li Fei-Fei, IEEE Conference on Computer Vision and Pattern Recognition. Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In IEEE Conference on Computer Vision and Pat- tern Recognition, 2009.\n\nArcface: Additive angular margin loss for deep face recognition. Jiankang Deng, Jia Guo, Niannan Xue, Stefanos Zafeiriou, IEEE Conference on Computer Vision and Pattern Recognition. Jiankang Deng, Jia Guo, Niannan Xue, and Stefanos Zafeiriou. Arcface: Additive angular margin loss for deep face recognition. In IEEE Conference on Computer Vision and Pattern Recognition, 2019.\n\nEfficient decision-based blackbox adversarial attacks on face recognition. Yinpeng Dong, Hang Su, Baoyuan Wu, Zhifeng Li, Wei Liu, Tong Zhang, Jun Zhu, IEEE Conference on Computer Vision and Pattern Recognition. Yinpeng Dong, Hang Su, Baoyuan Wu, Zhifeng Li, Wei Liu, Tong Zhang, and Jun Zhu. Efficient decision-based black- box adversarial attacks on face recognition. In IEEE Confer- ence on Computer Vision and Pattern Recognition, 2019.\n\nZoubin Gintare Karolina Dziugaite, Daniel M Ghahramani, Roy, arXiv:1608.00853A study of the effect of jpg compression on adversarial images. arXiv preprintGintare Karolina Dziugaite, Zoubin Ghahramani, and Daniel M Roy. A study of the effect of jpg compression on adversarial images. arXiv preprint arXiv:1608.00853, 2016.\n\nRobustness of classifiers: from adversarial to random noise. Alhussein Fawzi, Pascal Seyed-Mohsen Moosavi-Dezfooli, Frossard, Advances in Neural Information Processing Systems. Alhussein Fawzi, Seyed-Mohsen Moosavi-Dezfooli, and Pascal Frossard. Robustness of classifiers: from adversarial to random noise. In Advances in Neural Information Pro- cessing Systems, 2016.\n\nExplaining and harnessing adversarial examples. J Ian, Jonathon Goodfellow, Christian Shlens, Szegedy, International Conference on Learning Representations. Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples. In Interna- tional Conference on Learning Representations, 2015.\n\nLow frequency adversarial perturbation. Chuan Guo, Jared S Frank, Kilian Q Weinberger, Conference on Uncertainty in Artificial Intelligence. Chuan Guo, Jared S. Frank, and Kilian Q. Weinberger. Low frequency adversarial perturbation. In Conference on Uncer- tainty in Artificial Intelligence, 2019.\n\nSimple black-box adversarial attacks. Chuan Guo, Jacob Gardner, Yurong You, Andrew Gordon Wilson, Kilian Weinberger, International Conference on Machine Learning. Chuan Guo, Jacob Gardner, Yurong You, Andrew Gordon Wilson, and Kilian Weinberger. Simple black-box adversar- ial attacks. In International Conference on Machine Learn- ing, 2019.\n\nMs-celeb-1m: A dataset and benchmark for large-scale face recognition. Yandong Guo, Lei Zhang, Yuxiao Hu, Xiaodong He, Jianfeng Gao, European Conference on Computer Vision. Yandong Guo, Lei Zhang, Yuxiao Hu, Xiaodong He, and Jianfeng Gao. Ms-celeb-1m: A dataset and benchmark for large-scale face recognition. In European Conference on Computer Vision, 2016.\n\nDeep residual learning for image recognition. Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, IEEE Conference on Computer Vision and Pattern Recognition. Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In IEEE Con- ference on Computer Vision and Pattern Recognition, 2016.\n\nArchitecture disentanglement for deep neural networks. Jie Hu, Liujuan Cao, Qixiang Ye, Tong Tong, Shengchuan Zhang, Ke Li, Feiyue Huang, Rongrong Ji, Ling Shao, IEEE International Conference on Computer Vision. Jie Hu, Liujuan Cao, Qixiang Ye, Tong Tong, ShengChuan Zhang, Ke Li, Feiyue Huang, Rongrong Ji, and Ling Shao. Architecture disentanglement for deep neural networks. In IEEE International Conference on Computer Vision, 2021.\n\nInformation competing process for learning diversified representations. Jie Hu, Rongrong Ji, Shengchuan Zhang, Xiaoshuai Sun, Qixiang Ye, Chia-Wen Lin, Qi Tian, Advances in Neural Information Processing Systems. Jie Hu, Rongrong Ji, ShengChuan Zhang, Xiaoshuai Sun, Qixiang Ye, Chia-Wen Lin, and Qi Tian. Information com- peting process for learning diversified representations. In Ad- vances in Neural Information Processing Systems, 2019.\n\nBlack-box adversarial attacks with limited queries and information. Andrew Ilyas, Logan Engstrom, Anish Athalye, Jessy Lin, International Conference on Machine Learning. Andrew Ilyas, Logan Engstrom, Anish Athalye, and Jessy Lin. Black-box adversarial attacks with limited queries and information. In International Conference on Machine Learn- ing, 2018.\n\nPrior convictions: Black-box adversarial attacks with bandits and priors. Andrew Ilyas, Logan Engstrom, Aleksander Madry, International Conference on Learning Representations. Andrew Ilyas, Logan Engstrom, and Aleksander Madry. Prior convictions: Black-box adversarial attacks with bandits and priors. In International Conference on Learning Repre- sentations, 2019.\n\nLearning multiple layers of features from tiny images. Alex Krizhevsky, Geoffrey Hinton, Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009.\n\nQeba: Query-efficient boundary-based blackbox attack. Huichen Li, Xiaojun Xu, Xiaolu Zhang, Shuang Yang, Bo Li, IEEE Conference on Computer Vision and Pattern Recognition. Huichen Li, Xiaojun Xu, Xiaolu Zhang, Shuang Yang, and Bo Li. Qeba: Query-efficient boundary-based blackbox at- tack. In IEEE Conference on Computer Vision and Pattern Recognition, 2020.\n\nProjection & probabilitydriven black-box attack. Jie Li, Rongrong Ji, Hong Liu, Jianzhuang Liu, Bineng Zhong, Cheng Deng, Qi Tian, IEEE Conference on Computer Vision and Pattern Recognition. Jie Li, Rongrong Ji, Hong Liu, Jianzhuang Liu, Bineng Zhong, Cheng Deng, and Qi Tian. Projection & probability- driven black-box attack. In IEEE Conference on Computer Vision and Pattern Recognition, 2020.\n\nA geometry-inspired decision-based attack. Yujia Liu, Seyed-Mohsen Moosavi-Dezfooli, Pascal Frossard, IEEE International Conference on Computer Vision. Yujia Liu, Seyed-Mohsen Moosavi-Dezfooli, and Pascal Frossard. A geometry-inspired decision-based attack. In IEEE International Conference on Computer Vision, 2019.\n\nDeep learning face attributes in the wild. Ziwei Liu, Ping Luo, Xiaogang Wang, Xiaoou Tang, IEEE International Conference on Computer Vision. Ziwei Liu, Ping Luo, Xiaogang Wang, and Xiaoou Tang. Deep learning face attributes in the wild. In IEEE Interna- tional Conference on Computer Vision, 2015.\n\nTowards deep learning models resistant to adversarial attacks. Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, Adrian Vladu, International Conference on Learning Representations. Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu. Towards deep learn- ing models resistant to adversarial attacks. In International Conference on Learning Representations, 2018.\n\nSurfree: a fast surrogate-free black-box attack. Thibault Maho, Teddy Furon, Erwan Le Merrer, IEEE Conference on Computer Vision and Pattern Recognition. Thibault Maho, Teddy Furon, and Erwan Le Merrer. Surfree: a fast surrogate-free black-box attack. In IEEE Conference on Computer Vision and Pattern Recognition, 2021.\n\nUniversal adversarial perturbations. Alhussein Seyed-Mohsen Moosavi-Dezfooli, Omar Fawzi, Pascal Fawzi, Frossard, Conference on Computer Vision and Pattern Recognition. Seyed-Mohsen Moosavi-Dezfooli, Alhussein Fawzi, Omar Fawzi, and Pascal Frossard. Universal adversarial perturba- tions. In Conference on Computer Vision and Pattern Recog- nition, 2017.\n\nGeoda: A geometric framework for black-box adversarial attacks. Ali Rahmati, Pascal Seyed-Mohsen Moosavi-Dezfooli, Huaiyu Frossard, Dai, IEEE Conference on Computer Vision and Pattern Recognition. Ali Rahmati, Seyed-Mohsen Moosavi-Dezfooli, Pascal Frossard, and Huaiyu Dai. Geoda: A geometric framework for black-box adversarial attacks. In IEEE Conference on Computer Vision and Pattern Recognition, 2020.\n\nIngo Rechenberg, Evolutionsstrategien, Simulationsmethoden in der Medizin und Biologie. Ingo Rechenberg. Evolutionsstrategien. In Simulationsmeth- oden in der Medizin und Biologie. 1978.\n\nPolishing decisionbased adversarial noise with a customized sampling. Yucheng Shi, Yahong Han, Qi Tian, IEEE Conference on Computer Vision and Pattern Recognition. Yucheng Shi, Yahong Han, and Qi Tian. Polishing decision- based adversarial noise with a customized sampling. In IEEE Conference on Computer Vision and Pattern Recognition, 2020.\n\nVery deep convolutional networks for large-scale image recognition. Karen Simonyan, Andrew Zisserman, International Conference on Learning Representations. Karen Simonyan and Andrew Zisserman. Very deep convo- lutional networks for large-scale image recognition. In Inter- national Conference on Learning Representations, 2015.\n\nInception-v4, inception-resnet and the impact of residual connections on learning. Christian Szegedy, Sergey Ioffe, Vincent Vanhoucke, Alex Alemi, AAAI Conference on Artificial Intelligence. Christian Szegedy, Sergey Ioffe, Vincent Vanhoucke, and Alex Alemi. Inception-v4, inception-resnet and the impact of residual connections on learning. In AAAI Conference on Artificial Intelligence, 2016.\n\nRethinking the inception architecture for computer vision. Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, Zbigniew Wojna, IEEE Conference on Computer Vision and Pattern Recognition. Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, and Zbigniew Wojna. Rethinking the inception ar- chitecture for computer vision. In IEEE Conference on Com- puter Vision and Pattern Recognition, 2016.\n\nCosface: Large margin cosine loss for deep face recognition. Hao Wang, Yitong Wang, Zheng Zhou, Xing Ji, Dihong Gong, Jingchao Zhou, Zhifeng Li, Wei Liu, IEEE Conference on Computer Vision and Pattern Recognition. Hao Wang, Yitong Wang, Zheng Zhou, Xing Ji, Dihong Gong, Jingchao Zhou, Zhifeng Li, and Wei Liu. Cosface: Large margin cosine loss for deep face recognition. In IEEE Conference on Computer Vision and Pattern Recognition, 2018.\n\nBlack-box dissector: Towards erasing-based hard-label model stealing attack. Yixu Wang, Jie Li, Hong Liu, Yongjian Wu, Rongrong Ji, arXiv:2105.00623arXiv preprintYixu Wang, Jie Li, Hong Liu, Yongjian Wu, and Rongrong Ji. Black-box dissector: Towards erasing-based hard-label model stealing attack. arXiv preprint arXiv:2105.00623, 2021.\n\nImproving transferability of adversarial examples with input diversity. Cihang Xie, Zhishuai Zhang, Yuyin Zhou, Song Bai, Jianyu Wang, Alan L Zhou Ren, Yuille, Conference on Computer Vision and Pattern Recognition. Cihang Xie, Zhishuai Zhang, Yuyin Zhou, Song Bai, Jianyu Wang, Zhou Ren, and Alan L Yuille. Improving transferabil- ity of adversarial examples with input diversity. In Confer- ence on Computer Vision and Pattern Recognition, 2019.\n\nFeature squeezing: Detecting adversarial examples in deep neural networks. Weilin Xu, David Evans, Yanjun Qi, Network and Distributed System Security Symposium. Weilin Xu, David Evans, and Yanjun Qi. Feature squeezing: Detecting adversarial examples in deep neural networks. In Network and Distributed System Security Symposium, 2018.\n\nWide residual networks. Sergey Zagoruyko, Nikos Komodakis, British Machine Vision Conference. Sergey Zagoruyko and Nikos Komodakis. Wide residual net- works. In British Machine Vision Conference, 2016.\n\nIntriguing properties of neural networks. Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, Rob Fergus, International Conference on Learning Representations. Christian Szegedy Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, and Rob Fergus. In- triguing properties of neural networks. In International Con- ference on Learning Representations, 2014.\n\nJoint face detection and alignment using multitask cascaded convolutional networks. Kaipeng Zhang, Zhanpeng Zhang, Zhifeng Li, Yu Qiao, IEEE Signal Processing Letters. Kaipeng Zhang, Zhanpeng Zhang, Zhifeng Li, and Yu Qiao. Joint face detection and alignment using multitask cascaded convolutional networks. IEEE Signal Processing Letters, 2016.\n\nInterpreting cnn knowledge via an explanatory graph. Quanshi Zhang, Ruiming Cao, Feng Shi, Ying Nian Wu, Song-Chun Zhu, AAAI Conference on Artificial Intelligence. Quanshi Zhang, Ruiming Cao, Feng Shi, Ying Nian Wu, and Song-Chun Zhu. Interpreting cnn knowledge via an explana- tory graph. In AAAI Conference on Artificial Intelligence, 2018.\n", "annotations": {"author": "[{\"end\":132,\"start\":75},{\"end\":269,\"start\":133},{\"end\":352,\"start\":270},{\"end\":389,\"start\":353},{\"end\":432,\"start\":390},{\"end\":465,\"start\":433},{\"end\":496,\"start\":466},{\"end\":525,\"start\":497},{\"end\":558,\"start\":526},{\"end\":590,\"start\":559}]", "publisher": null, "author_last_name": "[{\"end\":81,\"start\":79},{\"end\":144,\"start\":142},{\"end\":282,\"start\":278},{\"end\":367,\"start\":362},{\"end\":403,\"start\":399},{\"end\":445,\"start\":440},{\"end\":476,\"start\":474},{\"end\":505,\"start\":503},{\"end\":538,\"start\":533},{\"end\":570,\"start\":568}]", "author_first_name": "[{\"end\":78,\"start\":75},{\"end\":141,\"start\":133},{\"end\":277,\"start\":270},{\"end\":361,\"start\":353},{\"end\":398,\"start\":390},{\"end\":439,\"start\":433},{\"end\":473,\"start\":466},{\"end\":502,\"start\":497},{\"end\":532,\"start\":526},{\"end\":567,\"start\":559}]", "author_affiliation": "[{\"end\":131,\"start\":83},{\"end\":194,\"start\":146},{\"end\":211,\"start\":196},{\"end\":268,\"start\":213},{\"end\":332,\"start\":284},{\"end\":351,\"start\":334},{\"end\":388,\"start\":369},{\"end\":431,\"start\":405},{\"end\":464,\"start\":447},{\"end\":495,\"start\":478},{\"end\":524,\"start\":507},{\"end\":557,\"start\":540},{\"end\":589,\"start\":572}]", "title": "[{\"end\":72,\"start\":1},{\"end\":662,\"start\":591}]", "venue": null, "abstract": "[{\"end\":2164,\"start\":692}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2513,\"start\":2510},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":2516,\"start\":2513},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":2519,\"start\":2516},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":2522,\"start\":2519},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":2746,\"start\":2742},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":2930,\"start\":2926},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2932,\"start\":2930},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":2935,\"start\":2932},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":3101,\"start\":3097},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":3104,\"start\":3101},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":3107,\"start\":3104},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":4071,\"start\":4068},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":4545,\"start\":4542},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":4643,\"start\":4639},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":8139,\"start\":8136},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":8349,\"start\":8345},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":8508,\"start\":8504},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":8716,\"start\":8712},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":8868,\"start\":8864},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":9245,\"start\":9242},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":9575,\"start\":9572},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":9677,\"start\":9673},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":9878,\"start\":9875},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":10195,\"start\":10192},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":10544,\"start\":10540},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":10794,\"start\":10790},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":10963,\"start\":10959},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":14569,\"start\":14565},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":14707,\"start\":14703},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":14710,\"start\":14707},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":14994,\"start\":14990},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":14997,\"start\":14994},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":15000,\"start\":14997},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":15003,\"start\":15000},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":15147,\"start\":15143},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":15195,\"start\":15191},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":15246,\"start\":15242},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":15496,\"start\":15493},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":15499,\"start\":15496},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":16182,\"start\":16178},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":16309,\"start\":16305},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":18033,\"start\":18029},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":21789,\"start\":21787},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":21975,\"start\":21971},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":21978,\"start\":21975},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":21981,\"start\":21978},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":22015,\"start\":22012},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":22018,\"start\":22015},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":22490,\"start\":22486},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":22839,\"start\":22836},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":22874,\"start\":22870},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":22968,\"start\":22964},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":22983,\"start\":22979},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":23006,\"start\":23002},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":23440,\"start\":23436},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":23456,\"start\":23453},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":23502,\"start\":23498},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":23533,\"start\":23529},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":23547,\"start\":23546},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":23748,\"start\":23744},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":23878,\"start\":23874},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":23905,\"start\":23901},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":25329,\"start\":25326},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":25340,\"start\":25336},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":25374,\"start\":25371},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":25400,\"start\":25396},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":25418,\"start\":25414},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":25730,\"start\":25727},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":25733,\"start\":25730},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":25797,\"start\":25794},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":25800,\"start\":25797},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":29444,\"start\":29440},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":29467,\"start\":29463},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":29497,\"start\":29493},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":32799,\"start\":32795},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":32802,\"start\":32799}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":35319,\"start\":35088},{\"attributes\":{\"id\":\"fig_1\"},\"end\":35405,\"start\":35320},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":36388,\"start\":35406},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":37206,\"start\":36389}]", "paragraph": "[{\"end\":2817,\"start\":2180},{\"end\":4010,\"start\":2819},{\"end\":5411,\"start\":4012},{\"end\":6854,\"start\":5413},{\"end\":7139,\"start\":6856},{\"end\":7506,\"start\":7141},{\"end\":7870,\"start\":7508},{\"end\":8986,\"start\":7887},{\"end\":11167,\"start\":8988},{\"end\":11940,\"start\":11187},{\"end\":12472,\"start\":11958},{\"end\":12742,\"start\":12529},{\"end\":13086,\"start\":12768},{\"end\":13540,\"start\":13156},{\"end\":14106,\"start\":13666},{\"end\":15328,\"start\":14146},{\"end\":16390,\"start\":15330},{\"end\":16784,\"start\":16484},{\"end\":17389,\"start\":16819},{\"end\":18312,\"start\":17391},{\"end\":18774,\"start\":18314},{\"end\":18988,\"start\":18853},{\"end\":20161,\"start\":19116},{\"end\":20654,\"start\":20163},{\"end\":21088,\"start\":20719},{\"end\":21304,\"start\":21136},{\"end\":21658,\"start\":21628},{\"end\":21694,\"start\":21665},{\"end\":21840,\"start\":21769},{\"end\":22552,\"start\":21862},{\"end\":22695,\"start\":22554},{\"end\":24151,\"start\":22733},{\"end\":25181,\"start\":24153},{\"end\":25782,\"start\":25183},{\"end\":26108,\"start\":25784},{\"end\":28804,\"start\":26150},{\"end\":29833,\"start\":28839},{\"end\":30914,\"start\":29862},{\"end\":33491,\"start\":30933},{\"end\":34106,\"start\":33493},{\"end\":35087,\"start\":34121}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":12528,\"start\":12473},{\"attributes\":{\"id\":\"formula_1\"},\"end\":12767,\"start\":12743},{\"attributes\":{\"id\":\"formula_2\"},\"end\":13155,\"start\":13087},{\"attributes\":{\"id\":\"formula_3\"},\"end\":13665,\"start\":13541},{\"attributes\":{\"id\":\"formula_4\"},\"end\":16483,\"start\":16391},{\"attributes\":{\"id\":\"formula_5\"},\"end\":18852,\"start\":18775},{\"attributes\":{\"id\":\"formula_6\"},\"end\":19115,\"start\":18989},{\"attributes\":{\"id\":\"formula_8\"},\"end\":20718,\"start\":20655},{\"attributes\":{\"id\":\"formula_9\"},\"end\":21627,\"start\":21305},{\"attributes\":{\"id\":\"formula_10\"},\"end\":21768,\"start\":21695}]", "table_ref": "[{\"end\":33076,\"start\":33069}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":2178,\"start\":2166},{\"attributes\":{\"n\":\"2.\"},\"end\":7885,\"start\":7873},{\"attributes\":{\"n\":\"3.\"},\"end\":11185,\"start\":11170},{\"attributes\":{\"n\":\"3.1.\"},\"end\":11956,\"start\":11943},{\"attributes\":{\"n\":\"3.2.\"},\"end\":14144,\"start\":14109},{\"attributes\":{\"n\":\"3.3.\"},\"end\":16817,\"start\":16787},{\"end\":21134,\"start\":21091},{\"end\":21663,\"start\":21661},{\"attributes\":{\"n\":\"3.4.\"},\"end\":21860,\"start\":21843},{\"attributes\":{\"n\":\"4.\"},\"end\":22709,\"start\":22698},{\"attributes\":{\"n\":\"4.1.\"},\"end\":22731,\"start\":22712},{\"attributes\":{\"n\":\"4.2.\"},\"end\":26148,\"start\":26111},{\"attributes\":{\"n\":\"4.3.\"},\"end\":28837,\"start\":28807},{\"attributes\":{\"n\":\"4.4.\"},\"end\":29860,\"start\":29836},{\"attributes\":{\"n\":\"4.5.\"},\"end\":30931,\"start\":30917},{\"attributes\":{\"n\":\"5.\"},\"end\":34119,\"start\":34109},{\"end\":35109,\"start\":35089},{\"end\":35331,\"start\":35321}]", "table": "[{\"end\":36388,\"start\":35846},{\"end\":37206,\"start\":36607}]", "figure_caption": "[{\"end\":35319,\"start\":35112},{\"end\":35405,\"start\":35333},{\"end\":35846,\"start\":35408},{\"end\":36607,\"start\":36391}]", "figure_ref": "[{\"end\":27059,\"start\":27053},{\"end\":27650,\"start\":27644},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":30787,\"start\":30781},{\"end\":31781,\"start\":31775},{\"end\":33788,\"start\":33782}]", "bib_author_first_name": "[{\"end\":37487,\"start\":37482},{\"end\":37498,\"start\":37493},{\"end\":37511,\"start\":37505},{\"end\":37524,\"start\":37520},{\"end\":37539,\"start\":37532},{\"end\":37940,\"start\":37933},{\"end\":37955,\"start\":37950},{\"end\":37972,\"start\":37964},{\"end\":38332,\"start\":38326},{\"end\":38350,\"start\":38342},{\"end\":38365,\"start\":38358},{\"end\":38382,\"start\":38377},{\"end\":38709,\"start\":38701},{\"end\":38724,\"start\":38719},{\"end\":38980,\"start\":38974},{\"end\":38994,\"start\":38987},{\"end\":38996,\"start\":38995},{\"end\":39011,\"start\":39005},{\"end\":39013,\"start\":39012},{\"end\":39354,\"start\":39348},{\"end\":39365,\"start\":39361},{\"end\":39377,\"start\":39373},{\"end\":39393,\"start\":39386},{\"end\":39405,\"start\":39398},{\"end\":39801,\"start\":39795},{\"end\":39814,\"start\":39809},{\"end\":39825,\"start\":39819},{\"end\":39836,\"start\":39832},{\"end\":39852,\"start\":39844},{\"end\":39864,\"start\":39857},{\"end\":40207,\"start\":40204},{\"end\":40217,\"start\":40214},{\"end\":40231,\"start\":40224},{\"end\":40246,\"start\":40240},{\"end\":40254,\"start\":40251},{\"end\":40261,\"start\":40259},{\"end\":40600,\"start\":40592},{\"end\":40610,\"start\":40607},{\"end\":40623,\"start\":40616},{\"end\":40637,\"start\":40629},{\"end\":40987,\"start\":40980},{\"end\":40998,\"start\":40994},{\"end\":41010,\"start\":41003},{\"end\":41022,\"start\":41015},{\"end\":41030,\"start\":41027},{\"end\":41040,\"start\":41036},{\"end\":41051,\"start\":41048},{\"end\":41353,\"start\":41347},{\"end\":41390,\"start\":41382},{\"end\":41741,\"start\":41732},{\"end\":41755,\"start\":41749},{\"end\":42090,\"start\":42089},{\"end\":42104,\"start\":42096},{\"end\":42126,\"start\":42117},{\"end\":42415,\"start\":42410},{\"end\":42426,\"start\":42421},{\"end\":42428,\"start\":42427},{\"end\":42442,\"start\":42436},{\"end\":42444,\"start\":42443},{\"end\":42713,\"start\":42708},{\"end\":42724,\"start\":42719},{\"end\":42740,\"start\":42734},{\"end\":42752,\"start\":42746},{\"end\":42759,\"start\":42753},{\"end\":42774,\"start\":42768},{\"end\":43092,\"start\":43085},{\"end\":43101,\"start\":43098},{\"end\":43115,\"start\":43109},{\"end\":43128,\"start\":43120},{\"end\":43141,\"start\":43133},{\"end\":43427,\"start\":43420},{\"end\":43439,\"start\":43432},{\"end\":43455,\"start\":43447},{\"end\":43465,\"start\":43461},{\"end\":43762,\"start\":43759},{\"end\":43774,\"start\":43767},{\"end\":43787,\"start\":43780},{\"end\":43796,\"start\":43792},{\"end\":43813,\"start\":43803},{\"end\":43823,\"start\":43821},{\"end\":43834,\"start\":43828},{\"end\":43850,\"start\":43842},{\"end\":43859,\"start\":43855},{\"end\":44217,\"start\":44214},{\"end\":44230,\"start\":44222},{\"end\":44245,\"start\":44235},{\"end\":44262,\"start\":44253},{\"end\":44275,\"start\":44268},{\"end\":44288,\"start\":44280},{\"end\":44296,\"start\":44294},{\"end\":44658,\"start\":44652},{\"end\":44671,\"start\":44666},{\"end\":44687,\"start\":44682},{\"end\":44702,\"start\":44697},{\"end\":45020,\"start\":45014},{\"end\":45033,\"start\":45028},{\"end\":45054,\"start\":45044},{\"end\":45367,\"start\":45363},{\"end\":45388,\"start\":45380},{\"end\":45561,\"start\":45554},{\"end\":45573,\"start\":45566},{\"end\":45584,\"start\":45578},{\"end\":45598,\"start\":45592},{\"end\":45607,\"start\":45605},{\"end\":45912,\"start\":45909},{\"end\":45925,\"start\":45917},{\"end\":45934,\"start\":45930},{\"end\":45950,\"start\":45940},{\"end\":45962,\"start\":45956},{\"end\":45975,\"start\":45970},{\"end\":45984,\"start\":45982},{\"end\":46306,\"start\":46301},{\"end\":46324,\"start\":46312},{\"end\":46349,\"start\":46343},{\"end\":46624,\"start\":46619},{\"end\":46634,\"start\":46630},{\"end\":46648,\"start\":46640},{\"end\":46661,\"start\":46655},{\"end\":46949,\"start\":46939},{\"end\":46967,\"start\":46957},{\"end\":46983,\"start\":46977},{\"end\":47001,\"start\":46993},{\"end\":47017,\"start\":47011},{\"end\":47355,\"start\":47347},{\"end\":47367,\"start\":47362},{\"end\":47383,\"start\":47375},{\"end\":47666,\"start\":47657},{\"end\":47702,\"start\":47698},{\"end\":47716,\"start\":47710},{\"end\":48043,\"start\":48040},{\"end\":48059,\"start\":48053},{\"end\":48097,\"start\":48091},{\"end\":48388,\"start\":48384},{\"end\":48649,\"start\":48642},{\"end\":48661,\"start\":48655},{\"end\":48669,\"start\":48667},{\"end\":48989,\"start\":48984},{\"end\":49006,\"start\":49000},{\"end\":49337,\"start\":49328},{\"end\":49353,\"start\":49347},{\"end\":49368,\"start\":49361},{\"end\":49384,\"start\":49380},{\"end\":49709,\"start\":49700},{\"end\":49726,\"start\":49719},{\"end\":49744,\"start\":49738},{\"end\":49755,\"start\":49752},{\"end\":49772,\"start\":49764},{\"end\":50121,\"start\":50118},{\"end\":50134,\"start\":50128},{\"end\":50146,\"start\":50141},{\"end\":50157,\"start\":50153},{\"end\":50168,\"start\":50162},{\"end\":50183,\"start\":50175},{\"end\":50197,\"start\":50190},{\"end\":50205,\"start\":50202},{\"end\":50580,\"start\":50576},{\"end\":50590,\"start\":50587},{\"end\":50599,\"start\":50595},{\"end\":50613,\"start\":50605},{\"end\":50626,\"start\":50618},{\"end\":50915,\"start\":50909},{\"end\":50929,\"start\":50921},{\"end\":50942,\"start\":50937},{\"end\":50953,\"start\":50949},{\"end\":50965,\"start\":50959},{\"end\":50976,\"start\":50972},{\"end\":50978,\"start\":50977},{\"end\":51366,\"start\":51360},{\"end\":51376,\"start\":51371},{\"end\":51390,\"start\":51384},{\"end\":51651,\"start\":51645},{\"end\":51668,\"start\":51663},{\"end\":51875,\"start\":51866},{\"end\":51893,\"start\":51885},{\"end\":51907,\"start\":51903},{\"end\":51923,\"start\":51919},{\"end\":51938,\"start\":51931},{\"end\":51949,\"start\":51946},{\"end\":51965,\"start\":51962},{\"end\":52340,\"start\":52333},{\"end\":52356,\"start\":52348},{\"end\":52371,\"start\":52364},{\"end\":52378,\"start\":52376},{\"end\":52656,\"start\":52649},{\"end\":52671,\"start\":52664},{\"end\":52681,\"start\":52677},{\"end\":52691,\"start\":52687},{\"end\":52696,\"start\":52692},{\"end\":52710,\"start\":52701}]", "bib_author_last_name": "[{\"end\":37491,\"start\":37488},{\"end\":37503,\"start\":37499},{\"end\":37518,\"start\":37512},{\"end\":37530,\"start\":37525},{\"end\":37548,\"start\":37540},{\"end\":37948,\"start\":37941},{\"end\":37962,\"start\":37956},{\"end\":37979,\"start\":37973},{\"end\":38340,\"start\":38333},{\"end\":38356,\"start\":38351},{\"end\":38375,\"start\":38366},{\"end\":38388,\"start\":38383},{\"end\":38717,\"start\":38710},{\"end\":38731,\"start\":38725},{\"end\":38985,\"start\":38981},{\"end\":39003,\"start\":38997},{\"end\":39024,\"start\":39014},{\"end\":39359,\"start\":39355},{\"end\":39371,\"start\":39366},{\"end\":39384,\"start\":39378},{\"end\":39396,\"start\":39394},{\"end\":39411,\"start\":39406},{\"end\":39807,\"start\":39802},{\"end\":39817,\"start\":39815},{\"end\":39830,\"start\":39826},{\"end\":39842,\"start\":39837},{\"end\":39855,\"start\":39853},{\"end\":39870,\"start\":39865},{\"end\":40212,\"start\":40208},{\"end\":40222,\"start\":40218},{\"end\":40238,\"start\":40232},{\"end\":40249,\"start\":40247},{\"end\":40257,\"start\":40255},{\"end\":40269,\"start\":40262},{\"end\":40605,\"start\":40601},{\"end\":40614,\"start\":40611},{\"end\":40627,\"start\":40624},{\"end\":40647,\"start\":40638},{\"end\":40992,\"start\":40988},{\"end\":41001,\"start\":40999},{\"end\":41013,\"start\":41011},{\"end\":41025,\"start\":41023},{\"end\":41034,\"start\":41031},{\"end\":41046,\"start\":41041},{\"end\":41055,\"start\":41052},{\"end\":41380,\"start\":41354},{\"end\":41401,\"start\":41391},{\"end\":41406,\"start\":41403},{\"end\":41747,\"start\":41742},{\"end\":41785,\"start\":41756},{\"end\":41795,\"start\":41787},{\"end\":42094,\"start\":42091},{\"end\":42115,\"start\":42105},{\"end\":42133,\"start\":42127},{\"end\":42142,\"start\":42135},{\"end\":42419,\"start\":42416},{\"end\":42434,\"start\":42429},{\"end\":42455,\"start\":42445},{\"end\":42717,\"start\":42714},{\"end\":42732,\"start\":42725},{\"end\":42744,\"start\":42741},{\"end\":42766,\"start\":42760},{\"end\":42785,\"start\":42775},{\"end\":43096,\"start\":43093},{\"end\":43107,\"start\":43102},{\"end\":43118,\"start\":43116},{\"end\":43131,\"start\":43129},{\"end\":43145,\"start\":43142},{\"end\":43430,\"start\":43428},{\"end\":43445,\"start\":43440},{\"end\":43459,\"start\":43456},{\"end\":43469,\"start\":43466},{\"end\":43765,\"start\":43763},{\"end\":43778,\"start\":43775},{\"end\":43790,\"start\":43788},{\"end\":43801,\"start\":43797},{\"end\":43819,\"start\":43814},{\"end\":43826,\"start\":43824},{\"end\":43840,\"start\":43835},{\"end\":43853,\"start\":43851},{\"end\":43864,\"start\":43860},{\"end\":44220,\"start\":44218},{\"end\":44233,\"start\":44231},{\"end\":44251,\"start\":44246},{\"end\":44266,\"start\":44263},{\"end\":44278,\"start\":44276},{\"end\":44292,\"start\":44289},{\"end\":44301,\"start\":44297},{\"end\":44664,\"start\":44659},{\"end\":44680,\"start\":44672},{\"end\":44695,\"start\":44688},{\"end\":44706,\"start\":44703},{\"end\":45026,\"start\":45021},{\"end\":45042,\"start\":45034},{\"end\":45060,\"start\":45055},{\"end\":45378,\"start\":45368},{\"end\":45395,\"start\":45389},{\"end\":45564,\"start\":45562},{\"end\":45576,\"start\":45574},{\"end\":45590,\"start\":45585},{\"end\":45603,\"start\":45599},{\"end\":45610,\"start\":45608},{\"end\":45915,\"start\":45913},{\"end\":45928,\"start\":45926},{\"end\":45938,\"start\":45935},{\"end\":45954,\"start\":45951},{\"end\":45968,\"start\":45963},{\"end\":45980,\"start\":45976},{\"end\":45989,\"start\":45985},{\"end\":46310,\"start\":46307},{\"end\":46341,\"start\":46325},{\"end\":46358,\"start\":46350},{\"end\":46628,\"start\":46625},{\"end\":46638,\"start\":46635},{\"end\":46653,\"start\":46649},{\"end\":46666,\"start\":46662},{\"end\":46955,\"start\":46950},{\"end\":46975,\"start\":46968},{\"end\":46991,\"start\":46984},{\"end\":47009,\"start\":47002},{\"end\":47023,\"start\":47018},{\"end\":47360,\"start\":47356},{\"end\":47373,\"start\":47368},{\"end\":47390,\"start\":47384},{\"end\":47696,\"start\":47667},{\"end\":47708,\"start\":47703},{\"end\":47722,\"start\":47717},{\"end\":47732,\"start\":47724},{\"end\":48051,\"start\":48044},{\"end\":48089,\"start\":48060},{\"end\":48106,\"start\":48098},{\"end\":48111,\"start\":48108},{\"end\":48399,\"start\":48389},{\"end\":48421,\"start\":48401},{\"end\":48653,\"start\":48650},{\"end\":48665,\"start\":48662},{\"end\":48674,\"start\":48670},{\"end\":48998,\"start\":48990},{\"end\":49016,\"start\":49007},{\"end\":49345,\"start\":49338},{\"end\":49359,\"start\":49354},{\"end\":49378,\"start\":49369},{\"end\":49390,\"start\":49385},{\"end\":49717,\"start\":49710},{\"end\":49736,\"start\":49727},{\"end\":49750,\"start\":49745},{\"end\":49762,\"start\":49756},{\"end\":49778,\"start\":49773},{\"end\":50126,\"start\":50122},{\"end\":50139,\"start\":50135},{\"end\":50151,\"start\":50147},{\"end\":50160,\"start\":50158},{\"end\":50173,\"start\":50169},{\"end\":50188,\"start\":50184},{\"end\":50200,\"start\":50198},{\"end\":50209,\"start\":50206},{\"end\":50585,\"start\":50581},{\"end\":50593,\"start\":50591},{\"end\":50603,\"start\":50600},{\"end\":50616,\"start\":50614},{\"end\":50629,\"start\":50627},{\"end\":50919,\"start\":50916},{\"end\":50935,\"start\":50930},{\"end\":50947,\"start\":50943},{\"end\":50957,\"start\":50954},{\"end\":50970,\"start\":50966},{\"end\":50987,\"start\":50979},{\"end\":50995,\"start\":50989},{\"end\":51369,\"start\":51367},{\"end\":51382,\"start\":51377},{\"end\":51393,\"start\":51391},{\"end\":51661,\"start\":51652},{\"end\":51678,\"start\":51669},{\"end\":51883,\"start\":51876},{\"end\":51901,\"start\":51894},{\"end\":51917,\"start\":51908},{\"end\":51929,\"start\":51924},{\"end\":51944,\"start\":51939},{\"end\":51960,\"start\":51950},{\"end\":51972,\"start\":51966},{\"end\":52346,\"start\":52341},{\"end\":52362,\"start\":52357},{\"end\":52374,\"start\":52372},{\"end\":52383,\"start\":52379},{\"end\":52662,\"start\":52657},{\"end\":52675,\"start\":52672},{\"end\":52685,\"start\":52682},{\"end\":52699,\"start\":52697},{\"end\":52714,\"start\":52711}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":378410},\"end\":37835,\"start\":37401},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":2410333},\"end\":38247,\"start\":37837},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":56895282},\"end\":38645,\"start\":38249},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":2893830},\"end\":38912,\"start\":38647},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":173991158},\"end\":39232,\"start\":38914},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":2179389},\"end\":39716,\"start\":39234},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":49672236},\"end\":40149,\"start\":39718},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":57246310},\"end\":40525,\"start\":40151},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":8923541},\"end\":40903,\"start\":40527},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":104291897},\"end\":41345,\"start\":40905},{\"attributes\":{\"doi\":\"arXiv:1608.00853\",\"id\":\"b10\"},\"end\":41669,\"start\":41347},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":13451211},\"end\":42039,\"start\":41671},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":6706414},\"end\":42368,\"start\":42041},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":52814523},\"end\":42668,\"start\":42370},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":86541092},\"end\":43012,\"start\":42670},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":2908606},\"end\":43372,\"start\":43014},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":206594692},\"end\":43702,\"start\":43374},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":214714368},\"end\":44140,\"start\":43704},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":174797995},\"end\":44582,\"start\":44142},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":5046541},\"end\":44938,\"start\":44584},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":49907212},\"end\":45306,\"start\":44940},{\"attributes\":{\"id\":\"b21\"},\"end\":45498,\"start\":45308},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":218972155},\"end\":45858,\"start\":45500},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":218571079},\"end\":46256,\"start\":45860},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":85518037},\"end\":46574,\"start\":46258},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":459456},\"end\":46874,\"start\":46576},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":3488815},\"end\":47296,\"start\":46876},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":227162679},\"end\":47618,\"start\":47298},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":11558223},\"end\":47974,\"start\":47620},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":212725250},\"end\":48382,\"start\":47976},{\"attributes\":{\"id\":\"b30\"},\"end\":48570,\"start\":48384},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":219619122},\"end\":48914,\"start\":48572},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":14124313},\"end\":49243,\"start\":48916},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":1023605},\"end\":49639,\"start\":49245},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":206593880},\"end\":50055,\"start\":49641},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":68589},\"end\":50497,\"start\":50057},{\"attributes\":{\"doi\":\"arXiv:2105.00623\",\"id\":\"b36\"},\"end\":50835,\"start\":50499},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":3972825},\"end\":51283,\"start\":50837},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":3851184},\"end\":51619,\"start\":51285},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":15276198},\"end\":51822,\"start\":51621},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":604334},\"end\":52247,\"start\":51824},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":10585115},\"end\":52594,\"start\":52249},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":9333065},\"end\":52938,\"start\":52596}]", "bib_title": "[{\"end\":37480,\"start\":37401},{\"end\":37931,\"start\":37837},{\"end\":38324,\"start\":38249},{\"end\":38699,\"start\":38647},{\"end\":38972,\"start\":38914},{\"end\":39346,\"start\":39234},{\"end\":39793,\"start\":39718},{\"end\":40202,\"start\":40151},{\"end\":40590,\"start\":40527},{\"end\":40978,\"start\":40905},{\"end\":41730,\"start\":41671},{\"end\":42087,\"start\":42041},{\"end\":42408,\"start\":42370},{\"end\":42706,\"start\":42670},{\"end\":43083,\"start\":43014},{\"end\":43418,\"start\":43374},{\"end\":43757,\"start\":43704},{\"end\":44212,\"start\":44142},{\"end\":44650,\"start\":44584},{\"end\":45012,\"start\":44940},{\"end\":45552,\"start\":45500},{\"end\":45907,\"start\":45860},{\"end\":46299,\"start\":46258},{\"end\":46617,\"start\":46576},{\"end\":46937,\"start\":46876},{\"end\":47345,\"start\":47298},{\"end\":47655,\"start\":47620},{\"end\":48038,\"start\":47976},{\"end\":48640,\"start\":48572},{\"end\":48982,\"start\":48916},{\"end\":49326,\"start\":49245},{\"end\":49698,\"start\":49641},{\"end\":50116,\"start\":50057},{\"end\":50907,\"start\":50837},{\"end\":51358,\"start\":51285},{\"end\":51643,\"start\":51621},{\"end\":51864,\"start\":51824},{\"end\":52331,\"start\":52249},{\"end\":52647,\"start\":52596}]", "bib_author": "[{\"end\":37493,\"start\":37482},{\"end\":37505,\"start\":37493},{\"end\":37520,\"start\":37505},{\"end\":37532,\"start\":37520},{\"end\":37550,\"start\":37532},{\"end\":37950,\"start\":37933},{\"end\":37964,\"start\":37950},{\"end\":37981,\"start\":37964},{\"end\":38342,\"start\":38326},{\"end\":38358,\"start\":38342},{\"end\":38377,\"start\":38358},{\"end\":38390,\"start\":38377},{\"end\":38719,\"start\":38701},{\"end\":38733,\"start\":38719},{\"end\":38987,\"start\":38974},{\"end\":39005,\"start\":38987},{\"end\":39026,\"start\":39005},{\"end\":39361,\"start\":39348},{\"end\":39373,\"start\":39361},{\"end\":39386,\"start\":39373},{\"end\":39398,\"start\":39386},{\"end\":39413,\"start\":39398},{\"end\":39809,\"start\":39795},{\"end\":39819,\"start\":39809},{\"end\":39832,\"start\":39819},{\"end\":39844,\"start\":39832},{\"end\":39857,\"start\":39844},{\"end\":39872,\"start\":39857},{\"end\":40214,\"start\":40204},{\"end\":40224,\"start\":40214},{\"end\":40240,\"start\":40224},{\"end\":40251,\"start\":40240},{\"end\":40259,\"start\":40251},{\"end\":40271,\"start\":40259},{\"end\":40607,\"start\":40592},{\"end\":40616,\"start\":40607},{\"end\":40629,\"start\":40616},{\"end\":40649,\"start\":40629},{\"end\":40994,\"start\":40980},{\"end\":41003,\"start\":40994},{\"end\":41015,\"start\":41003},{\"end\":41027,\"start\":41015},{\"end\":41036,\"start\":41027},{\"end\":41048,\"start\":41036},{\"end\":41057,\"start\":41048},{\"end\":41382,\"start\":41347},{\"end\":41403,\"start\":41382},{\"end\":41408,\"start\":41403},{\"end\":41749,\"start\":41732},{\"end\":41787,\"start\":41749},{\"end\":41797,\"start\":41787},{\"end\":42096,\"start\":42089},{\"end\":42117,\"start\":42096},{\"end\":42135,\"start\":42117},{\"end\":42144,\"start\":42135},{\"end\":42421,\"start\":42410},{\"end\":42436,\"start\":42421},{\"end\":42457,\"start\":42436},{\"end\":42719,\"start\":42708},{\"end\":42734,\"start\":42719},{\"end\":42746,\"start\":42734},{\"end\":42768,\"start\":42746},{\"end\":42787,\"start\":42768},{\"end\":43098,\"start\":43085},{\"end\":43109,\"start\":43098},{\"end\":43120,\"start\":43109},{\"end\":43133,\"start\":43120},{\"end\":43147,\"start\":43133},{\"end\":43432,\"start\":43420},{\"end\":43447,\"start\":43432},{\"end\":43461,\"start\":43447},{\"end\":43471,\"start\":43461},{\"end\":43767,\"start\":43759},{\"end\":43780,\"start\":43767},{\"end\":43792,\"start\":43780},{\"end\":43803,\"start\":43792},{\"end\":43821,\"start\":43803},{\"end\":43828,\"start\":43821},{\"end\":43842,\"start\":43828},{\"end\":43855,\"start\":43842},{\"end\":43866,\"start\":43855},{\"end\":44222,\"start\":44214},{\"end\":44235,\"start\":44222},{\"end\":44253,\"start\":44235},{\"end\":44268,\"start\":44253},{\"end\":44280,\"start\":44268},{\"end\":44294,\"start\":44280},{\"end\":44303,\"start\":44294},{\"end\":44666,\"start\":44652},{\"end\":44682,\"start\":44666},{\"end\":44697,\"start\":44682},{\"end\":44708,\"start\":44697},{\"end\":45028,\"start\":45014},{\"end\":45044,\"start\":45028},{\"end\":45062,\"start\":45044},{\"end\":45380,\"start\":45363},{\"end\":45397,\"start\":45380},{\"end\":45566,\"start\":45554},{\"end\":45578,\"start\":45566},{\"end\":45592,\"start\":45578},{\"end\":45605,\"start\":45592},{\"end\":45612,\"start\":45605},{\"end\":45917,\"start\":45909},{\"end\":45930,\"start\":45917},{\"end\":45940,\"start\":45930},{\"end\":45956,\"start\":45940},{\"end\":45970,\"start\":45956},{\"end\":45982,\"start\":45970},{\"end\":45991,\"start\":45982},{\"end\":46312,\"start\":46301},{\"end\":46343,\"start\":46312},{\"end\":46360,\"start\":46343},{\"end\":46630,\"start\":46619},{\"end\":46640,\"start\":46630},{\"end\":46655,\"start\":46640},{\"end\":46668,\"start\":46655},{\"end\":46957,\"start\":46939},{\"end\":46977,\"start\":46957},{\"end\":46993,\"start\":46977},{\"end\":47011,\"start\":46993},{\"end\":47025,\"start\":47011},{\"end\":47362,\"start\":47347},{\"end\":47375,\"start\":47362},{\"end\":47392,\"start\":47375},{\"end\":47698,\"start\":47657},{\"end\":47710,\"start\":47698},{\"end\":47724,\"start\":47710},{\"end\":47734,\"start\":47724},{\"end\":48053,\"start\":48040},{\"end\":48091,\"start\":48053},{\"end\":48108,\"start\":48091},{\"end\":48113,\"start\":48108},{\"end\":48401,\"start\":48384},{\"end\":48423,\"start\":48401},{\"end\":48655,\"start\":48642},{\"end\":48667,\"start\":48655},{\"end\":48676,\"start\":48667},{\"end\":49000,\"start\":48984},{\"end\":49018,\"start\":49000},{\"end\":49347,\"start\":49328},{\"end\":49361,\"start\":49347},{\"end\":49380,\"start\":49361},{\"end\":49392,\"start\":49380},{\"end\":49719,\"start\":49700},{\"end\":49738,\"start\":49719},{\"end\":49752,\"start\":49738},{\"end\":49764,\"start\":49752},{\"end\":49780,\"start\":49764},{\"end\":50128,\"start\":50118},{\"end\":50141,\"start\":50128},{\"end\":50153,\"start\":50141},{\"end\":50162,\"start\":50153},{\"end\":50175,\"start\":50162},{\"end\":50190,\"start\":50175},{\"end\":50202,\"start\":50190},{\"end\":50211,\"start\":50202},{\"end\":50587,\"start\":50576},{\"end\":50595,\"start\":50587},{\"end\":50605,\"start\":50595},{\"end\":50618,\"start\":50605},{\"end\":50631,\"start\":50618},{\"end\":50921,\"start\":50909},{\"end\":50937,\"start\":50921},{\"end\":50949,\"start\":50937},{\"end\":50959,\"start\":50949},{\"end\":50972,\"start\":50959},{\"end\":50989,\"start\":50972},{\"end\":50997,\"start\":50989},{\"end\":51371,\"start\":51360},{\"end\":51384,\"start\":51371},{\"end\":51395,\"start\":51384},{\"end\":51663,\"start\":51645},{\"end\":51680,\"start\":51663},{\"end\":51885,\"start\":51866},{\"end\":51903,\"start\":51885},{\"end\":51919,\"start\":51903},{\"end\":51931,\"start\":51919},{\"end\":51946,\"start\":51931},{\"end\":51962,\"start\":51946},{\"end\":51974,\"start\":51962},{\"end\":52348,\"start\":52333},{\"end\":52364,\"start\":52348},{\"end\":52376,\"start\":52364},{\"end\":52385,\"start\":52376},{\"end\":52664,\"start\":52649},{\"end\":52677,\"start\":52664},{\"end\":52687,\"start\":52677},{\"end\":52701,\"start\":52687},{\"end\":52716,\"start\":52701}]", "bib_venue": "[{\"end\":37608,\"start\":37550},{\"end\":38033,\"start\":37981},{\"end\":38438,\"start\":38390},{\"end\":38771,\"start\":38733},{\"end\":39064,\"start\":39026},{\"end\":39465,\"start\":39413},{\"end\":39924,\"start\":39872},{\"end\":40329,\"start\":40271},{\"end\":40707,\"start\":40649},{\"end\":41115,\"start\":41057},{\"end\":41486,\"start\":41424},{\"end\":41846,\"start\":41797},{\"end\":42196,\"start\":42144},{\"end\":42509,\"start\":42457},{\"end\":42831,\"start\":42787},{\"end\":43185,\"start\":43147},{\"end\":43529,\"start\":43471},{\"end\":43914,\"start\":43866},{\"end\":44352,\"start\":44303},{\"end\":44752,\"start\":44708},{\"end\":45114,\"start\":45062},{\"end\":45361,\"start\":45308},{\"end\":45670,\"start\":45612},{\"end\":46049,\"start\":45991},{\"end\":46408,\"start\":46360},{\"end\":46716,\"start\":46668},{\"end\":47077,\"start\":47025},{\"end\":47450,\"start\":47392},{\"end\":47787,\"start\":47734},{\"end\":48171,\"start\":48113},{\"end\":48470,\"start\":48423},{\"end\":48734,\"start\":48676},{\"end\":49070,\"start\":49018},{\"end\":49434,\"start\":49392},{\"end\":49838,\"start\":49780},{\"end\":50269,\"start\":50211},{\"end\":50574,\"start\":50499},{\"end\":51050,\"start\":50997},{\"end\":51444,\"start\":51395},{\"end\":51713,\"start\":51680},{\"end\":52026,\"start\":51974},{\"end\":52415,\"start\":52385},{\"end\":52758,\"start\":52716}]"}}}, "year": 2023, "month": 12, "day": 17}