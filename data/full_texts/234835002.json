{"id": 234835002, "updated": "2023-10-30 17:42:29.182", "metadata": {"title": "Physics-Augmented Deep Learning to Improve Tropical Cyclone Intensity and Size Estimation from Satellite Imagery", "authors": "[{\"first\":\"J\",\"last\":\"HUO\",\"middle\":[\"ING\",\"-Y\",\"I\",\"Z\"]},{\"first\":\"AN\",\"last\":\"ZHE-MINT\",\"middle\":[]}]", "venue": null, "journal": "Monthly Weather Review", "publication_date": {"year": 2021, "month": null, "day": null}, "abstract": ": A deep learning\u2013based method augmented by prior knowledge of tropical cyclones (TCs), called DeepTCNet, is introduced to estimate TC intensity and wind radii from infrared (IR) imagery over the North Atlantic Ocean. While standard deep learning practices have many advantages over conventional analysis approaches and can produce reliable estimates of TCs, the data-driven models informed by machine-readable physical knowledge of TCs could achieve higher performance. To this end, two approaches are explored to develop the physics-augmented DeepTCNet: (i) infusing the auxiliary physical information of TCs into models for single-task learning and (ii) learning auxiliary physical tasks for multitask learning. More speci\ufb01cally, augmented by auxiliary information of TC fullness (a measure of the radial decay of the TC wind \ufb01eld), the DeepTCNet yields a 12% improvement in estimating TC intensity over the nonaugmented one. By learning TC wind radii and auxiliary TC intensity task simultaneously, the model\u2019s wind radii estimation skill is improved by 6% over only learning four wind radii tasks and by 9% over separately learning a single wind radii task. The evaluation results showed that the DeepTCNet is in-line with the Satellite Consensus technique (SATCON) but systematically outperforms the advanced Dvorak technique (ADT) at all intensity scales with an averaged 39% enhancement in TC intensity estimation. The DeepTCNet also surpasses the Multiplatform Tropical Cyclone Surface Wind Analysis technique (MTCSWA) with an average improvement of 32% in wind radii estimation.", "fields_of_study": null, "external_ids": {"arxiv": null, "mag": "3155667800", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": null, "doi": "10.1175/mwr-d-20-0333.1"}}, "content": {"source": {"pdf_hash": "aed0efd2eebebcf8454018ea77a1e0dbaf17891e", "pdf_src": "ScienceParsePlus", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "8d94aef9b2aa0951db7893edbaaf1a1dcad94320", "type": "plain-text", "url": "s3://ai2-s2-science-parse-plus-prod/parse-results/s2orc_worker/aed0efd2eebebcf8454018ea77a1e0dbaf17891e.txt", "contents": "\nPhysics-Augmented Deep Learning to Improve Tropical Cyclone Intensity and Size Estimation from Satellite Imagery\n\n\nJing-Yi Zhuo \nKey Laboratory of Mesoscale Severe Weather/Ministry of Education\nNanjing University\nNanjingChina\n\nSchool of Atmospheric Sciences\nNanjing University\nNanjingChina\n\nZhe-Min Tan zmtan@nju.edu.cn \nKey Laboratory of Mesoscale Severe Weather/Ministry of Education\nNanjing University\nNanjingChina\n\nSchool of Atmospheric Sciences\nNanjing University\nNanjingChina\n\nPhysics-Augmented Deep Learning to Improve Tropical Cyclone Intensity and Size Estimation from Satellite Imagery\n8AA21CC14A06C33DCA4A4A4830B5A9E510.1175/MWR-D-20-0333.1received 12 October 2020, in final form 7 April 2021Tropical cyclonesSatellite observationsNeural networksDeep learning\nA deep learning-based method augmented by prior knowledge of tropical cyclones (TCs), called DeepTCNet, is introduced to estimate TC intensity and wind radii from infrared (IR) imagery over the North Atlantic Ocean.While standard deep learning practices have many advantages over conventional analysis approaches and can produce reliable estimates of TCs, the data-driven models informed by machine-readable physical knowledge of TCs could achieve higher performance.To this end, two approaches are explored to develop the physics-augmented DeepTCNet: (i) infusing the auxiliary physical information of TCs into models for single-task learning and (ii) learning auxiliary physical tasks for multitask learning.More specifically, augmented by auxiliary information of TC fullness (a measure of the radial decay of the TC wind field), the DeepTCNet yields a 12% improvement in estimating TC intensity over the nonaugmented one.By learning TC wind radii and auxiliary TC intensity task simultaneously, the model's wind radii estimation skill is improved by 6% over only learning four wind radii tasks and by 9% over separately learning a single wind radii task.The evaluation results showed that the DeepTCNet is in-line with the Satellite Consensus technique (SATCON) but systematically outperforms the advanced Dvorak technique (ADT) at all intensity scales with an averaged 39% enhancement in TC intensity estimation.The DeepTCNet also surpasses the Multiplatform Tropical Cyclone Surface Wind Analysis technique (MTCSWA) with an average improvement of 32% in wind radii estimation.\n\nIntroduction\n\nEstimating the intensity and wind radii of tropical cyclones (TCs) is the first step in the process of monitoring and forecasting these destructive systems.However, making accurate estimates of TC intensity and size has been a long-standing challenge in tropical meteorology, and is limited by the available observations and technologies (e.g., Landsea and Franklin 2013;Knaff and Sampson 2015).Besides, global TC warning centers routinely require multiple measures of TC characteristics.These include two measures of TC intensity, the maximum sustained surface wind (MSW) and minimum sea level pressure (MSLP), together with different TC size measures, generally provided by forecast centers as ''wind radii,'' including the gale-force (34 kt; 1 kt 5 0.51 m s 21 ; R34), stormforce (50 kt; R50), and hurricane-force (64 kt; R64) wind radii in geographic quadrants (i.e., in the northeast, southeast, southwest, and northwest directions), and the radius of maximum wind (RMW).The production of such a large number of estimates in real time may be difficult and time-consuming (Sampson et al. 2018).\n\nOperational TC intensity estimation still relies primarily on the Dvorak technique (Velden et al. 2006), which uses the cloud features in infrared (IR) and/or visible satellite images to assign TC intensity.As the complex TC dynamics have been comprehensively abstracted as cloud features, the Dvorak technique can provide relatively reliable intensity estimates, and has been one of the most successful satellite applications for TC analysis over more than four decades (Velden et al. 2006).Nonetheless, this technique is subjective, so its estimation accuracy depends on the skills of analysts.To increase the objectivity and the automatization of IR-based intensity analysis, advanced versions of the Dvorak technique (e.g., Olander and Velden 2007;2019) and many other algorithms have been proposed (e.g., Kossin et al. 2007;Ritchie et al. 2012;Fetanat et al. 2013).However, most of these algorithms have proved to be less reliable than the Dvorak technique, mainly because they are based on conventional algorithms, such as principal component analysis, which extract only very limited features from the satellite data.The situation is similar in other satellite-based TC intensity estimation methods (e.g., Demuth et al. 2004Demuth et al. , 2006;;Jiang et al. 2019).The method that has the best accuracy in TC intensity estimation at present is the Satellite Consensus technique (SATCON), which is a weighted consensus algorithm designed to optimize the strengths and minimize the weaknesses of multiple IR-based and microwave-based techniques (Velden and Herndon 2020).The typical qualitative uncertainty level of the Dvorak technique, ADT and SATCON is around 10 kt for intensity in wind (Knaff et al. 2010;Olander and Velden 2019;Velden and Herndon 2020).\n\nThe satellite-based estimation of TC wind radii is more difficult.There is no such widely applied technique as the Dvorak method for wind radii estimation, given that the physical relationship between the convection and the wind field is less clear (e.g., Lajoie and Walsh 2008).The outer-core wind radii (e.g., R34) are among the more tractable TC wind radii and the scatterometer is one of the best spaceborne instruments for estimating outer-core wind radii (e.g., Brennan et al. 2009).\n\nScatterometer measurements operating at Ku-band have an issue to be affected by heavy rain in TCs and saturate for wind speeds near 50 kt (Brennan et al. 2009), but the lower C-band frequencies are less sensitive to rain and saturate at slightly higher wind speeds, which is close to 70 kt (Stoffelen 1998;Stoffelen et al. 2017).The L-band radiometers, which do not suffer from signal saturation at high winds and are minimally affected by rain, are important tools to determining the R34, R50, and R64 in TCs (e.g., Reul et al. 2017).Other methods that show skill in deriving TC wind radii include IR representations (e.g., Mueller et al. 2006;Kossin et al. 2007;Knaff et al. 2016;Dolling et al. 2016), microwave sounder proxies (e.g., Demuth et al. 2006), multi-satellite-platform analysis (Knaff et al. 2011), and the reflectometry-based technique (Morris and Ruf 2017).The estimation of the radius of maximum wind, which poses difficulties for observation because of the turbulent nature of the inner core of a TC (e.g., Chavas et al. 2015), however, remains a challenge.\n\nErrors in the best track intensity have been estimated to be ;10%-20%, and the errors for best track wind radii could be as high as 40%, depending on the quality and quantity of the available observations (Landsea and Franklin 2013;Knaff and Sampson 2015).However, accurate TC intensity and wind radii estimates are crucial to making forecasts and mitigate the losses due to TC-related hazards (e.g., Sampson et al. 2010;Torn and Snyder 2012;DeMaria et al. 2014;Bender et al. 2017), and translate to the postprocessed guidance such as wind speed probabilities (e.g., DeMaria et al. 2013).Therefore, more accurate estimations of TC intensity and wind radii are still badly needed.Moreover, with the recent advances in the satellite observations of TCs, updating the analysis technique, especially objective algorithms that can interpret complex TC dynamics from the satellite observations, is of vital importance.\n\nDeep learning is a type of artificial intelligence algorithm that has revolutionized computer vision, language recognition, game strategy and many research fields (e.g., Hinton et al. 2012;LeCun et al. 2015;Silver et al. 2016;Krizhevsky et al. 2017).More recently, deep learning is also providing insights into atmospheric science with broad applications, which cover pattern detection, physical parameterization, and state prediction (e.g., Rasp et al. 2018;Ham et al. 2019;Reichstein et al. 2019).Recent works have also begun to apply deep learning to TC intensity estimation.Pradhan et al. (2018) is among the earliest applications of deep learning to estimate TC intensity from IR imagery.However, this work is somewhat incomplete because they did not use an independent dataset for evaluation.Chen et al. (2019) used a larger amount of dataset (global TC cases) than Pradhan et al. (2018) and utilized IR imagery and passive microwave-retrieved precipitation to train deep learning models.However, the optimal estimates of Chen et al. (2019) are not available in real time due to the intermittent microwave rain-rate data and postanalysis smoothing required.Wimmers et al. (2019) estimated TC intensity from passive microwave imagery, which has a major advantage in showing convective features of TCs.However, at present, there is no deep learning application for TC size estimation.Moreover, despite the challenges of deep learning, such as the high cost of data acquisition and making mistakes on what would appear trivial to a human for lacking any general knowledge of the world, little work has successfully capitalized on physical or prior knowledge to improve deep learning for TC applications.The main target of this study is to harness deep learning to produce more accurate estimations of both TC intensity and wind radii from IR imagery.Moreover, we endeavor to augment the deep learning models by incorporating prior knowledge of TCs into the model.\n\nThe rest of this paper is organized as follows.In the next section, we present a description of the data and the deep learning backbone we selected to build our method.We then describe the approaches to augment deep learning models for intensity estimation and evaluate model performance in section 3. Section 4 provides the augmented deep learning for wind radii estimation as well as the evaluation.The discussion on our method and the summaries of the findings are presented in sections 5 and 6.\n\n\nData and method\n\n\na. Data\n\nNecessary information is required to set up the input-output pairs to train the deep learning models.In this paper, the outputs/labels given to the models were the TC intensity (MSW and MSLP) and wind radii (R34, R50, R64, and RMW) from the postseason/final best track dataset.These data were obtained from the IBTrACS database (Knapp et al. 2010).The primary inputs of the models are the TC-centered IR images, which were from the Hurricane Satellite dataset (HURSAT-B1; 3-h interval; 8-km resolution; Knapp and Kossin 2007).As the HURSAT-B1 images are only available up to 2016, we used the IR images from the GridSat-B1 archive (Knapp et al. 2011) from then onward.GridSat-B1 has the same temporal and spatial resolution as the HURSAT-B1 but at a global scale.Geostationary satellite IR imagery was used for its real-time availability and high spatial and temporal resolution.We also use auxiliary storm information as inputs.These include the TC fullness (Guo and Tan 2017), location and motion of a storm.The TC fullness is a new concept of TC structure, which is defined as the normalized extent of the outer-core wind skirt, i.e., (R34 2 RMW)/R34.The auxiliary information was obtained from the operational Tropical Cyclone Vitals Database (TC Vitals1 ) used for initializing numerical weather prediction model guidance (e.g., Tallapragada et al. 2014;Bender et al. 2017).For the cases with invalid wind radii estimates from TC Vitals, the corresponding TC fullness is set as zero.Only North Atlantic TCs with a lifetime-maximum intensity of at least 34 kt (i.e., tropical storms) are considered.Extratropical systems and tropical waves were removed.\n\nIn the data preprocessing, sample-specific normalization was applied to IR images by subtracting the average and dividing by the standard deviation.The IR images were then cropped only to include the center area.For intensity estimation, images of 58 3 58 pixels were used, which is found to work well and effectively in our practice.For size estimation, larger images of 156 3 156 pixels were used to include the outer-range cloud information, which is shown to be necessary to produce quality outer-core wind radii estimates.Given the R34, R50, and R64 are recorded for each quadrant (NE, SE, SW, and NW) in the IBTrACS database, the nonzero-azimuthal average was applied to get the wind radii labels.Note that the R34, R50, and R64 denote the azimuthally averaged wind radii data hereafter.As there is no guarantee that all of the wind radii labels from IBTrACS are physically consistent; for example, the R50 may be smaller than the R64, even though this arrangement is not physically possible.Therefore, wind radii labels that did not satisfy the relationship R34 .R50 .R64 and R34 $ RMW, R50 $ RMW, R64 $ RMW (Kossin et al. 2007) were removed.\n\nThe data were then split into three blocks (  and 3d).The best track fixes have aircraft reconnaissance observations within 3 h (reconaided hereafter) in the test set, which have higher quality, therefore, are used as ''ground truth'' to evaluate the performance of the DeepTCNet in sections 3d and 4b.\n\n\nb. Selection of the DeepTCNet's architecture\n\nIn this study, convolutional neural networks (CNNs) (LeCun et al. 2015) are selected as the deep learning backbone of DeepTCNet to estimate TC intensity and wind radii from IR imagery.CNNs are a particular class of artificial neural networks considered to be the state-of-the-art tool for analyzing image data (Simonyan and Zisserman 2014;Krizhevsky et al. 2017).CNNs assign importance to and transfer various aspects in the input image through stacks of convolutional, pooling, and fully connected layers.Overall, the whole network approximates a nonlinear differentiable function between the input and the outcome of interest.Taking advantage of the convolutional filters, the hierarchical cascade, and other specific designs in the architecture, CNNs are very good at capturing the spatial dependencies and extracting intricate patterns in an image.They are also useful in uncovering new properties in the data (LeCun et al. 2015).Moreover, they also have the great advantage of requiring little manual feature design/extraction compared to other conventional machine learning algorithms (LeCun et al. 2015;Goodfellow et al. 2016).CNNs now have growing applications in atmospheric science, for example, to detect various weather phenomena in observations and climate models (e.g., Liu et al. 2016;Lagerquist et al. 2019;McGovern et al. 2019), represent subgrid-scale processes (e.g., Bolton and Zanna 2019;Han et al. 2020) and improve the weather predictions and climate projections (e.g., Ham et al. 2019;S\u00f8nderby et al. 2020;Weyn et al. 2020).Considering the efficacies and advantages of CNNs, we decided to use them for modeling TC intensity and wind radii from IR imagery.\n\nDifferent CNNs have different architectures, in terms of the types of layers (e.g., convolutional, pooling, and fully connected layers), depth (the number of layers which have trainable parameters), and the number and kernel size of convolutional filters (the kernel size refers to the width 3 height of the filter mask) of these layers (Goodfellow et al. 2016;Ebert-Uphoff and Hilburn 2020).Many heuristics of the CNNs have been developed, for example, as the networks go deeper (have more trainable layers), they could learn more abstract representations that disentangle and hide explanatory factors of variation behind data (e.g., Goodfellow et al. 2016).A working architecture, however, is usually found by trial and error.To select a principal architecture from the wide choices of network configurations for our application, we tested five modern architectures at or near the state-of-the-art (Table 2) (Simonyan and Zisserman 2014;Szegedy et al. 2016;He et al. 2016;Krizhevsky et al. 2017;Chollet 2017), and assessed the influences of two important aspects of CNN design, i.e., the depth and the kernel size in the first convolutional layer.Because the performance of the model varies slightly even with the same training scenario, we trained the model five times for each scenario with the 2005-15 training data.The averaged performance with respect to the test dataset was then used to represent the grouping.The results (Tables 2  and 3) show that the configuration that yielded the best performance was VGGNet with 13 layers and small (3 3 3) convolutional filters, which therefore was selected as the backbone of the DeepTCNet.Given the infinite number of CNN hyperparameters combined, our proposed architecture could still be suboptimal, but it works well in practice.\n\nAs shown in Fig. 1, the architecture of DeepTCNet consists of 10 convolutional layers (CONV1-10) and 3 fully connected layers (FC11-13).The channel depths of CONV1-10 are 64, 64, 128, 128, 256, 256, 512, 512, 512, and 512, respectively, and the sizes of FC11-13 are 128, 64, and 1, respectively.There is a 3 3 3 patched maxpooling layer following every two CONV.Flattening is applied before\n\n\nc. Development and evaluation of the DeepTCNet\n\nAs represented in Fig. 1, DeepTCNet is built up in the single-task (STL) and multitask learning (MTL) frameworks.STL is a standard methodology that trains deep learning models to be optimized for one desired task and usually performs well given abundant training data.MTL, however, learns multiple tasks simultaneously.The unique advantage of MTL is that it can leverage shared information and/or the relationship contained in related tasks.Therefore, MTL could improve the accuracy and generality of the model, especially when the training data are scarce (e.g., Zhang and Yang 2017).In this study, STL is applied for intensity (MSW and MSLP) estimation and MTL for critical wind radii (RMW, R64, R50, and R34) estimation, for larger number of high-quality TC intensity samples is available for training than the TC wind radii (Table 1).Besides, the use of MTL to train the model for learning the wind radii simultaneously could also benefit from the underlying physical relationship of the integral TC wind field structure.In MTL, the fully connected layers were separated into multiple flows to learn task-specific model parameters, which could be essential in considering the independent features among inner-and outer-core wind radii tasks (e.g., Weatherford and Gray 1988;Chavas et al. 2015).However, the subnets before the fully connected layers in MTL share the same parameters among tasks to learn transferable features across different tasks.As also displayed in Fig. 1, auxiliary input/information, if present, was concatenated to model in the first fully connected layer.\n\nOne challenge in the applications of CNNs to many TCrelated research problems is the large amount of training data that required may not be available.The fact of being purely data-driven and black box also makes the CNNs not easy to obtain predictions with high accuracy and reasonableness.To alleviate these problems, research efforts have been made by integrating prior knowledge/physics into the model development (e.g., Raissi et al. 2019;Snaiki and Wu 2019).Instead of leveraging physics-based formulas as constraints, this study developed a more general physics-augmented deep learning by expanding the input/output learning space.More specifically, auxiliary physical information was used to augment the intensity estimation model (section 3), while learning an auxiliary physical task in MTL was applied to augment the size estimation model (section 4).Since the DeepTCNet approximates a function between the input data and output targets, extending either the input, i.e., incorporating auxiliary physical information or output space, i.e., introducing auxiliary physical tasks based on prior knowledge of TCs could augment the model to learn a more physically generalized function.\n\nAll the models were trained by minimizing the loss function, i.e., the mean absolute error (MAE) between the network's outputs and the best track labels.We used MAE as the loss function for it is robust to abnormal data.For MTL-based networks, a weighted sum of the losses of multiple tasks was used, whose weights were trainable and self-updated during training (Cipolla et al. 2018).The advantage of this loss is that it can bring all losses to the same scale to avoid one task dominating the overall loss.Besides, the multitask learning model learns to output inner-to outer-core wind radii, which means that a multitask label is required for each data case.Therefore, when a storm has not reached a specific wind threshold, the missing radii label was set as the RMW.For example, if the case has an intensity of 60 kt, the corresponding multitask label is set as [RMW, RMW, R50, R34].For such a case, the multitask learning model still learns to search for proper features that can produce reliable inner-to outer-wind radii estimation.\n\nOther hyperparameters and evaluations for the model development are as follows.As also noted in section 2a, each model in this paper was trained five times in each scenario and the averaged performance (in terms of MAE) with respect to the test dataset is selected to represent the model.The model was trained for 200 epochs, and only the learned parameters with the lowest MAE on the validation dataset were saved.In sections 3d and 4b, the mean estimate of intensity or size for each TC case, which was obtained by the five-times-repeated TABLE 2. Performance and key configuration of different convolutional neural network architectures for the DeepTCNet model.The second and third columns are the network depth and the kernel size in the first convolutional layer, respectively.MAE is the mean absolute error for TC intensity (maximum surface wind; kt) estimation counted with the test dataset.AlexNet is a landmark CNN architecture that almost halves the object recognition error rate (Krizhevsky et al. 2017).VGGNet is a deeper network than AlexNet and uses more efficient 3 3 3 convolutional kernels (Simonyan and Zisserman 2014).GoogLeNet introduces parallel towers of convolutional kernels with different sizes (Szegedy et al. 2016).ResNet enables CNNs to go very deep by using skip connection (He et al. 2016).Xception is an adaption of GoogLeNet but depthwise separable convolutions are included and it has much lighter parameters (Chollet 2017) training, was used to present the final estimate of the optimal model.The Adam optimization scheme (Kingma and Ba 2014) with default configuration parameters was used as the learning strategy.The learning rate was fixed as 1 3 10 -3 .The batch size (meaning that the data are randomly packed into small groups to be fed to the network) was empirically set 48.The algorithms were built using the open-source Python library Keras (https:// keras.io)with Tensorflow (http://www.tensorflow.org)as the backend and all experiments were run on a graphics processing unit (Nvidia Tesla V100).\n\n\nDeepTCNet for intensity estimation\n\nThe sensitivity test applied in the previous section to select the architecture of DeepTCNet has demonstrated a baseline configuration, i.e., the VGGNet with 13 layers and very small 3 3 3 convolutional kernels, can obtain reliable intensity estimates of TCs from IR imagery.However, such a model could be data inefficient, which means that they are essentially dependent on the quantity and quality of training data yet lack physical knowledge of the natural world.To improve the model for estimating TC intensity, we first address a method to incorporate auxiliary physical information of TCs for augmentation in this section.Sequential IR images, which represent the continuous TC development, are then introduced to improve intensity estimation.In addition, the influence of the amount of training data is discussed.Finally, we will finally integrate all the positive settings to build up an optimal DeepTCNet model for TC intensity estimation.\n\n\na. Auxiliary physical information augments learning\n\nAn effective and practical approach to capitalizing on prior physical knowledge of TCs is explored to alleviate the risks of the deep learning model for naively memorizing training data, such as the pseudo features and data bias in the IR imagery and the intensity labels.The hypothesis is that the auxiliary physical information of TCs introduces an additional physical relationship between the input space and the output TC intensity target; therefore, it could constrain the model to produce better TC intensity estimates.\n\nThe auxiliary physical information used in this study include the surface information (i.e., a factor valued 0 or 1 to indicate whether the TC is over land or not), the storm age (the period since the TC become a named storm in the unit of the hour; Unauthenticated | Downloaded 09/28/23 01:59 AM UTC e.g., Kossin et al. 2007), the storm's translation speed (Mei et al. 2012) and the TC fullness (Guo and Tan 2017).The TC fullness is defined as the ratio of the extent of the outer-core wind skirt to the outer-core size of the TC, i.e., (R34 2 RMW)/R34, which is a new concept for the representation of the storm wind structure and has a good physical relationship with TC intensity and intensification (Guo and Tan 2017).\n\nTo compare the effect of the auxiliary physical information, the model (VGGNet in Table 2) that only takes in the current IR imagery and output the MSW intensity is used as the control run (CNTL) model.Its estimation error on the test dataset (MAE 5 10.3 kt) thus serves as the error baseline.As illustrated by the learning curves in Fig. 2a, integrating the auxiliary physical information made the model achieve better performance than the CNTL on the validation dataset.Moreover, the performance with respect to the test set for models augmented by the landfall information, storm speed, storm age, the TC fullness, and the combination of all the auxiliary information is 10.2, 10.3, 9.6, 9.1, and 8.6 kt, respectively.The results show that incorporating TC wind radii structure description, i.e., the TC fullness, caused the largest error reduction (12%) in estimating TC intensity over the CNTL.Although it is impossible to derive TC intensity from the TC fullness directly, the TC fullness has shown to be a very useful auxiliary information to augment the model for intensity estimation.Since there exists a good physical relationship between the intensity and the radial wind structure of TCs, i.e., the TC fullness (Guo and Tan 2017), adding the TC fullness as an auxiliary input factor is equivalent to imposing a constraint between the TC wind field structure and the targeted output intensity, which could be the cause of the improvement.The storm age also contributed to a 7% error reduction in estimating MSW compared to the CNTL.A general characteristic of TC intensity evolution conveyed by the storm age could be the reason.That is, the model could be constrained by the early storm age to carefully give low-value estimates of intensity instead of starting with larger ones.The storm speed and surface information have a small contribution in improving the TC intensity.Overall, the model augmented by the auxiliary information combined achieved the best performance on the test set (17% improved than the CNTL).Besides, Fig. 2a illustrates that adding auxiliary physical information resulted in the estimation errors decreasing at an early stage of the learning.This suggests that the physical information may also help discard some implausible features in the data, hence accelerating the learning.\n\n\nb. Sequential IR imagery helps to improve\n\nMeteorologists track cloud features through successive periods of TC development to help determine the intensity (Velden et al. 2006).Therefore, it is natural to ask whether the deep learning model can improve accuracy by including recent images of a TC.In this study, we used a sequence of IR images at 6-h intervals from the previous 18, 12, or 6 h before the current image.\n\nAs shown in Fig. 2b, MSW estimation errors consistently decrease when previous IR images were included, and the result holds on the test set.The highest performance was achieved by using a sequence of images covering an 18-h period, and this has led to an error reduction of 6% lower than CNTL (with respect to the test set).This confirms that physical information on how the TC changes with time in the sequential images can benefit the intensity estimation.Likewise, the risk of important features disappearing in one IR image is also alleviated.However, note that using images that are too old (e.g., 24 h or earlier) does not improve the estimation and may even harm the estimation skill as the systems undergo rapid intensity change.Better results may be achieved by using hourly or even higher-frequency IR data (e.g., Himawari-8, GOES-16/-17 with 10-min global coverage) and including a channel-wise attention module to improve the representation power of the model by focusing information of interest (e.g., Woo et al. 2018).\n\n\nc. Sensitivity to the amount of training data\n\nThe backbone of DeepTCNet is CNN of complex architecture and heavy parameters (;10 million trainable parameters), which usually rely on a large-sample-size dataset and many strategies to perform well (e.g., Goodfellow et al. 2016).However, the large labeled datasets used in computer vision, such as the ImageNet could not be available in Earth science.Therefore, it is important to ask how the training data size could impact the intensity estimation of TCs.\n\nTo test the impact of training data size, more intensity records from the IBTrACS database from 1990 to 2004 were also included as training data (Table 1).The 4000, 8000, 12 000, and 16 000 instances were then sampled from the whole 1990-2015 training data.These samplings follow an identical distribution in which the ratio of the number of tropical depressions and tropical storms (MSW , 64 kt), minor hurricanes (64 # MSW , 96 kt), and major hurricanes (MSW $ 96 kt) is 0.7:0.2:0.1.Moreover, the influence of the rotation augmentation, which is a commonly applied data augmentation technique in the context of deep learning, is also explored.\n\nAs illustrated in Fig. 3, more training data leads the model to achieve lower intensity estimation errors, as expected.Besides, the model trained with the rotation augmentation had a further enhancement in estimating the TC intensity.The model trained with 16 000 samples together with the rotation augmentation has the lowest estimation error on the test dataset (9.0 kt), which is in-line with the model trained with the 2005-15 training data and augmented by the TC fullness.Figure 3 also shows that the model's improvement gained by including more observational samples is more evident than by rotation augmentation.This result suggests that enlarging the training dataset by observational cases is key to improving the deep learning-based model.Likewise, this sensitivity test was based on the intensity, which has more quality-consistent data than wind radii.We found that including more training samples of the wind radii labels obtained from the TC Vitals database, which is not postanalyzed thus could be of poor quality, does not help to improve model performance, meaning that data quality is also important.\n\n\nd. Performance evaluation\n\nA final intensity estimation model named DeepTCNet-I is developed by combining all the beneficial training settings.The settings include using the auxiliary information combined (storm age, storm speed, surface information and the TC fullness), multichannel images of IR sequence (previous 18, 12, 6 h, and current IR), more training data (the best track intensity labels from IBTrACS database for the TCs in 1990-2015) and the rotation augmentation.\n\nThe promising accuracy of the DeepTCNet-I across nearly all TC intensity scales is illustrated in Fig. 4. The Pearson correlation coefficient (R) between the DeepTCNet-based MSW (MSLP) and the recon-aided best track ''ground truth'' in the test set is 0.97 (0.97).The accuracy also holds with respect to the test set of 1463 samples (R 5 0.97).To better evaluate the intensity estimation accuracy of the DeepTCNet method, we compared the DeepTCNet-I with two benchmark intensity estimation methods, the IR-based ADT method (Olander and Velden 2019) and the multi-satellite-based SATCON method (Velden and Herndon 2020).As revealed in Fig. 5, the DeepTCNet systematically outperforms the ADT method for all intensity categories.The overall improvement of the DeepTCNet over the ADT is 39% for MSW and 33% for MSLP estimation (Table 4).These improvements are significantly different from zeros with a 99% confidence level in the Kolmogorov-Smirnov test.Since both the DeepTCNet and ADT are primarily based on IR imageries, the result implies that the DeepTCNet method can dramatically improve the efficacy of information in the IR observations.The DeepTCNet overall is in comparison with the SATCON.However, it tends to handle weaker systems (TD/TS and minor hurricanes) better than the SATCON.The negative bias for the MSW estimation for category-5 hurricanes is evident for DeepTCNet.The high percentage of tiny unresolved eyes at the strong intensities could be a cause for this underestimation.Given the microwave sensors can detect clear eye structure in strong intensities, SATCON would have better estimates of the intense TCs and thus outperforms the DeepTCNet and ADT for these cases.The underestimation of intense hurricanes could also reveal a real bias of the best track intensity dataset used to train the DeepTCNet.That is, we are detecting higher intensities than before as observations increase.Since the DeepTCNet-I was trained on historical data of TCs in the 1990-2015 seasons, it would also lack the ability to produce newly observed large intensity estimates based on highertemporal/-spatial-resolution IR data and improved aircraft reconnaissance.\n\nAs the DeepTCNet-I is trained with the best track intensity data of Atlantic TCs, and 70% of the data were solely supported by satellite observations (Landsea and Franklin 2013;Torn and Snyder 2012), it is natural to speculate that the best DeepTCNet-I can do is to reproduce the Dvorak method (Velden et al. 2006;Knaff et al. 2010).However, Table 5 shows that the DeepTCNet-I also performs better than the subjective Dvorak2 method based on 2 years of homogeneous testing data.Furthermore, the relative error levels of DeepTCNet-I are counted and compared with the intrinsic data uncertainty in the best track (Fig. 6).For aircraft/satellite monitoring and for U.S. landfalling cyclones, the relative uncertainty is about 15% for tropical storms, ;10% for category-1 and -2 hurricanes, ;8% for major hurricanes, and ;10% for all categories (Landsea and Franklin 2013).In comparison, the relative error of the DeepTCNet-based MSW for the recon-aided testing cases (N 5 485) is ;10% for tropical storms, ;10% for category-1 and -2 hurricanes, ;7% for major hurricanes, and ;8% for all categories, which is near the uncertainty in the recon-aided best track intensity data.For the best track cases without aircraft reconnaissance fixes within 63 h in the testing dataset (N 5 978), the relative error of the DeepTCNet-based MSW is 10%, which is lower than the inherent uncertainty of the satellite-only best track estimates (Fig. 6).This suggests that the DeepTCNet has the potential to improve the accuracy of intensity estimates when it is incorporated in the poststorm intensity analysis.In addition, a more accurate version of DeepTCNet-I could be obtained by fine-tuning/transfer learning with the recon-aided best track intensity labels in future work.\n\nTo note, however, the data uncertainties of best track were obtained subjectively (Landsea and Franklin 2013).\n\nThe error metrics for the MSW estimation of DeepTCNet-I also suggest a comparatively better performance over the previous deep learning-based intensity estimation methods.The root-mean-square estimation errors (RMSE) of MSW in Pradhan et al. (2018) is 10.2 kt (11.4 kt for a recon-aided dataset).Chen et al. (2019) conducted post smoothing procure to improve their intensity estimation accuracy.That is, the RMSE decreased from 10.4 to 8.7 kt (20% improvement) by applying a five-point weighted average.Given such postanalysis smoothing requires the past and future intensity estimates, which is not valid for near-real-time estimation, and the other deep learning applications do not apply postanalysis, we used the 10.4 kt to represent Chen et al. (2019).And note that Chen et al. (2019) reported a 32% improvement than the ADT technique by a homogeneous comparison based on 144 samples of TCs in 2017.Wimmers et al. (2019)'s RMSE of MSW as 14.3 kt (10.6 kt on a recon-influenced dataset).In comparison, the RMSE of DeepTCNet-I on the validation dataset is 7.7 kt (8.7 kt on the recon-aided test dataset), which is lower than the other deep learning methods.The superiority of DeepTCNet-I in terms of the lowest RMSE could because of incorporating some physics of TC into algorithms.However, an objective comparison of all the deep learning-based models using homogeneous testing data is required in the future.\n\n\nDeepTCNet for wind radii estimation\n\nThis section sets up the DeepTCNet to estimate critical wind radii (R34, R50, R64, and RMW) of TCs from IR imagery.Though the four wind radii estimates could be separately obtained by training four independent networks as we applied for TC intensity estimation and augmented information could also be incorporated to enhance the model, we explored another approach based on multitask learning (MTL).MTL is selected for its advantages in leveraging useful information contained in multiple related learning tasks (Zhang and Yang 2017), which would help alleviate the data sparsity problem in wind radii estimation.In the rest of this section, the efficacy of MTL is first explored, after which the performance of DeepTCNet for wind radii estimation is then evaluated.Note that rotation data augmentation is already applied to training all the wind radii estimation models.\n\n\na. Multiple physical-related tasks augment learning\n\nThe virtue of jointly learning from multiple tasks was shown by comparing MTL-based models with four STL-based models that separately estimate RMW, R64, R50, and R34.As illustrated in Fig. 7, the proposed MTL4 that solves four wind radii tasks (RMW, R64, R50, and R34) simultaneously outperforms each STL that only models a single wind radius task.Since the four critical wind radii approximate the integrated wind field of TCs, the result implies that the DeepTCNet could benefit from learning physically related tasks.One possible explanation is that multiple physically related wind radii tasks might impose the model to learn more useful and generalized features from data.Therefore, the model can produce more reliable size estimations from the IR imagery.\n\nMoreover, we added TC intensity, i.e., MSW and MSLP, as auxiliary tasks to explore if learning with TC intensity could enhance the wind radii estimation.As displayed in Fig. 7, the estimation errors on the test dataset for four wind radii parameters all decreased by learning MSW as the auxiliary task (the MTL5).Besides, it is interesting to observe that using MSW as the auxiliary task contributes more improvement in the innercore wind radii estimations (RMW and R64), whereas using MSLP as the auxiliary task (not shown) mainly boosted the estimations of the outer-core wind radii (R34 and R50).The improvement on RMW and R64 by the auxiliary MSW learning task could because they are both primarily determined by the inner-core dynamics of TCs (Emanuel and Rotunno 2011;Weatherford and Gray 1988).Whereas, since the MSLP also depends on the radial integral of the wind field (Knaff and Zehr 2007;Courtney and Knaff 2009), which could be approximated from radial momentum equation by assuming cylindrical gradient wind balance in TCs (e.g., Chavas et al. 2017), the model could have capitalized on the physical relationship between MSLP and R34 to support learning the outer-core wind radii (R34).Hence, both MSW and MSLP are included as auxiliary learning tasks to augment modeling critical wind radii, RMW, R64, R50, and R34, which is hereafter referred to as MTL6.As also shown in Fig. 7, the MTL6 model has the overall best performance.Overall, the MTL6 has reduced the wind radii estimation error by 6% than the MTL4 and by 12% over the STL.This result suggests that the MTL-based DeepTCNet could take advantage of the physical relationship(s) between the TC intensity and wind structure described by critical wind radii to yield improvement.This augmentation is similar to the significant improvement in MSW estimation obtained by introducing the auxiliary physical information of TC structure, i.e., TC fullness (Fig. 2a), to the intensity estimation model.Moreover, since the TC intensity (MSW and MSLP) and the wind fields expressed by critical wind radii (R34, R50, R64, and RMW) together empirically approximate the wind-pressure relationship of TCs (Knaff and Zehr 2007;Courtney and Knaff 2009;Chavas et al. 2017), the wind-pressure relationship could be the reason that FIG. 7. Sensitivity of wind radii estimation absolute errors (n mi; 1 n mi ' 1.85 km) to single-task learning (STL) and multitask learning (MTL).The MTL4 denotes a model jointly learns four wind radii tasks: RMW, R64, R50, and R34.The MTL5 jointly learns five tasks for wind radii and intensity estimation: RMW, R64, R50, R34, and MSW.The MTL6 model jointly learns six tasks for wind radii and intensity estimation: RMW, R64, R50, R34, MSW, and MSLP.The metrics were counted with the test dataset listed in Table 1.MTL6 performs best among the size estimation models.Note that although the MTL6 also estimates TC intensity, in this study it can only apply to the storms which have intensities larger than 34 kt.\n\n\nb. Performance evaluation\n\nGiven the impressive performance of the MTL6, it is selected as the final wind radii estimation model named DeepTCNet-R.Scatterplots of the wind radii estimates produced by the DeepTCNet-R against the recon-aided best track ''ground truth'' are also shown in Fig. 4. The overall performance of the DeepTCNet-R is quite impressive.Especially, the R34 estimations given by the DeepTCNet-R compare well to the best track data (R 5 0.87).However, it is worth noting that the scatter of the size estimation points shown in Fig. 4 is much larger than the intensity estimations.The smaller sample size training dataset used to train the DeepTCNet-R and the more considerable wind radii data uncertainty could be the causes.\n\nAs shown in Table 6, the DeepTCNet-R outperforms the coincident operational wind radii estimates from the Multiplatform Tropical Cyclone Surface Wind Analysis technique (MTCSWA; Knaff et al. 2011) with an average improvement of 32% (32%, 25%, 28%, and 38% for RMW, R64, R50, and R34, respectively).These differences also passed the Kolmogorov-Smirnov test with a 99% confidence level.Given the DeepTCNet-R only relies on IR imagery to estimate wind radii while the MTSCWA is based on multiple satellite channels, including more satellite channels into DeepTCNet-R is likely to further increase wind radii estimations' accuracy.This is very important because there still is large uncertainty in the satellite-based wind radii estimations (Knaff and Sampson 2015).As shown in Fig. 6, the relative wind radii estimation errors provided by the DeepTCNet-R is much lower than relative uncertainty of the satellite-only-based wind radii observations.The DeepTCNet-R gives the most accurate estimation for R34, then are R50 and R64.However, the DeepTCNet-derived RMW estimates have the highest relative errors among the wind radii estimates, suggesting that endeavors are still required to estimate this most difficult-to-measure TC inner-core feature.To the authors' knowledge, DeepTCNet is the first deep learning application for the real-time estimation of TC wind radii.Moreover, the unique point of DeepTCNet is that it can produce multiple wind radii simultaneously.Although this paper only discussed the symmetric wind radii estimation, the DeepTCNet can also be applied to estimate the TC wind field's asymmetries when asymmetric features (such as storm motion and vertical wind shear) are included as the auxiliary information of the model.A subjective comparison suggests that the DeepTCNet also outperforms or in line with the previous techniques (Table 7) though a homogeneous comparison is needed in the future.\n\n\nDiscussion\n\n\na. Interpretation and visualization of DeepTCNet\n\nThe backbone algorithm of DeepTCNet is the deep convolutional neural networks (CNNs), which are often treated as black boxes.That is, CNNs pick and decide features that they think essential from input data, thus usually left little ideas to the humans.However, the interpretation of CNNs is useful for establishing trust and confidence in users and suggesting the models' signs of disabilities.To provide the readers some information about how the DeepTCNet makes the decision, we implemented saliency maps (Smilkov et al. 2017) and Layerwise relevance propagation (LRP; Montavon et al. 2017Montavon et al. , 2018) ) to attribute what features of an input are responsible for the model's output.The saliency maps method uses the gradient of one output with respect to individual pixels of the IR image to reflect their influence on the final intensity or size estimation.The saliency value can be either positive or negative.And in this study, the SmoothGrad (Smilkov et al. 2017) was used to help visually sharpen the gradient-based saliency maps.One disadvantage of the saliency method is that it only looks at local gradients in the input space, which could be limiting (Montavon et al. 2017).The LRP explains the decision of a model by propagating the prediction from the output to the input using local redistribution rules.Since LRP does not rely on gradients, it does not suffer from problems such as gradient shattering and explanation discontinuities (Montavon et al. 2018), which also appear when plotting the saliency maps for DeepTCNet.One should note that LRP was designed for classification networks by backpropagating the activation scores of the target class to the input space.In the extensible regression setting (for the DeepTCNet), a larger LRP value represents that one feature has higher relevance to increasing the model's output intensity or size.\n\nConsider the example in Fig. 8, the saliency (SmoothGrad) and the LRP reveal that the model (DeepTCNet-R in this case) has learned different features for estimating diverse TC parameters.The saliency results show that the increase of bright temperature in the eye of Irma ( 2017) can cause the model to produce a higher intensity (MSW).The decrease of temperature around the storm's eye, which means the deeper convections in the eyewall region, can also increase the value of intensity (MSW) estimation.The saliency map for the MSLP tells the same story, i.e., the MSLP drops (i.e., intensity raises) with a warmer eye and colder eyewall.The saliency features in the outer region seem fuzzy and not physically meaningful.In addition, the estimated RMW of DeepTCNet-R (denoted by the blue ring in Fig. A1c) locates near the center region where saliency values transfer from negative to positive, meaning that the model might have learned that the concentration and expansion of the eye/eyewall directly determine the TC's RMW.The estimated R34 is located at a ring region where the bubblelike saliency features change into roll-like patterns.It is also interesting to observe from the saliency maps near the center that the model assigns more importance to axisymmetric cloud features for estimating the inner-core parameters (MSW, MSLP, RMW, and R64), while the important features for outer-core wind radii (R50 and R34) are asymmetric.As the supplement, the LRP reveals that the intensity is largely determined by the IR properties near the center (e.g., eye and the coldest clouds), wind radii of R34 is dependent on diverse clouds, convections and rainbands features in the inner-to outer-core regions, while the MSLP is determined by a combination of that information.Moreover, we further compare the LRP patterns of R34 for the smallest (25% quantile) and the largest (75% quantile) TCs in the testing dataset.As shown in Fig. 9, there is an obvious difference in the R34's LRP results for the large and small TCs, that is the larger TCs have wider spread LRP relevance values.This result gives us more confidence that the DeepTCNet might have learned physically important features from the IR images.The interpretation maps of the DeepTCNet-I, which uses the small inner-coreregion image for estimating intensity, are also shown (inserted graphs in Figs.8a,b,g,h), and showing similar descriptions with the interpretation maps of the DeepTCNet-R.These results suggest that the CNNs applied with proper interpretation methods could be useful for exploring more complex TC mechanisms, while future studies and more advanced and suitable interpretation techniques are warranted.\n\n\nb. Broader applications and limitations of DeepTCNet\n\nSection 3a shows that including auxiliary information, especially the TC fullness, can help the model improve estimating TC intensity from IR imagery, the TC fullness hence was used to develop a final intensity estimation model (DeepTCNet-I).Here we further discuss how the auxiliary information of TC fullness could influence the accuracy of TC   (Smilkov et al. 2017) and (g)-(l) LRP (Montavon et al. 2018) for Hurricane Irma at 0900 UTC intensity estimates in an operational setting when the realtime TC Vitals data are unavailable.As displayed in Table 8, the intensity errors increase when the TC fullness from the real-time MTCSWA database is used.This is expected since the model was trained with the TC Vitals-based TC fullness but used the MTCSWA-based TC fullness for application.From a more convenient application perspective of the DeepTCNet method, it is also a nice choice to use TC fullness derived from MTL4 and MTL6 as the auxiliary augmentation information.In this case, the DeepTCNet could rely on frequently available IR observations to produce TC intensity estimates of high temporal resolution.Table 8 shows that using the MTL6-based TC fullness as auxiliary information can produce better intensity estimation than the MTL4-and MTCSWA-based TC fullness, yet the differences are small and not statistically significant.As a comparison, we also used the best tracked TC fullness obtained from the IBTrACS to make TC intensity estimation.As expected, the intensity estimation errors further decreased to 6.7 kt when the more accurate TC fullness was used in place (Table 8).These error metrics obtained with best tracked TC fullness could be regarded as a potential performance of DeepTCNet-I when more accurate physical auxiliary information of TC fullness was available in real time.Besides, the model augmented with the real-time-available TC fullness data still yields better performance over without using this auxiliary information (Table 8).\n\nWhile the DeepTCNet was developed and evaluated with the TC cases in the Atlantic basin, where reconnaissance aircraft data are available, the methods discussed could extend to other ocean basins.Our preliminary testing results show that DeepTCNet developed with the Atlantic data can be applied to the western North Pacific basin with reliable intensity and size estimation performances and retraining the model with the Northern Hemisphere data can result in better results.The ability of DeepTCNet to generalize to other basins is essential in that these regions rely extensively on satellites for monitoring and forecasting the TCs.In another important way, DeepTCNet can contribute to TC intensity and size analysis in poststorm assessments and the best track procedures.This could be particularly important for the TC size analysis because most operational agencies just started to produce quality-controlled estimates of wind radii since 2004 (e.g., National Hurricane Center) or even more recent since 2016 at Joint Typhoon Warning Center (Sampson et al. 2018).Moreover, there are no quality-controlled estimates of RMW provided by these operational agencies (Sampson et al. 2018).All of these are primarily caused by the challenges faced with observing surface wind fields from space, and no reliable method like the Dvorak is widely applied for size estimation.Given the best track data are widely used to build or validate TC analysis algorithms and forecasting, more efforts to produce higher-quality best tracks of intensity and wind radii are still of vital concern.\n\nAlthough the evaluation results show that DeepTCNet has outstanding performance for estimating both intensity and wind radii of TCs, there are some limitations of the DeepTCNet.The first is that the model built up for intensity estimation underperforms for very intense TCs.The high percentage of unresolved tiny eyes in the IR imagery for strong intensities as well as the relatively low number of these cases for the model to learn from could be the causes.Whereas, this underestimation bias at intense TCs could reveal an observational bias in the best track.That is, we are observing more intense hurricanes than before.Furthermore, since the DeepTCNet is trained on historical data of TCs before 2016, it would lack the ability to produce large intensity estimates as recently observed.The utility of microwave-based satellite observations and more accurate reconaided data could boost the estimation of TC intensity and size.\n\n\nSummary\n\nDeepTCNet is a deep convolutional neural network as a backend method designed to capitalize on physical knowledge of TCs to produce accurate intensity (MSW and MSLP) and wind radii estimates (R34, R50, R64, and RMW) of TCs from IR imagery.Introducing auxiliary physical information is an effective approach to improve the model for intensity estimation.It is demonstrated that incorporating TC fullness, which describes the critical structure of TCs, to the model can significantly enhance its performance for intensity estimation.Multitask learning, which has the advantage of sharing different and more general features among tasks was applied to improve the model for wind radii estimation.Our results show that learning multiple wind radii tasks simultaneously can yield more accurate wind radii estimation than separately learn a single wind radii task.Moreover, we also found that the model trained to estimate two intensity measures (MSW and MSLP) and four critical wind field measures (R34, R50, R64, and RMW) simultaneously yields the best wind radii estimates.The inherent wind-pressure relationship approximated by these tasks could be a cause.Besides, results show that including continuous IR images from near-previous times benefited the model for intensity estimation.\n\nThe evaluation results based on homogeneous testing samples showed that the DeepTCNet is in-line with SATCON, but systematically outperforms the ADT by 39% improvement for MSW and 33% improvement for MSLP estimation.The DeepTCNet also exceeds the Dvorak method for TC intensity estimation.Besides, DeepTCNet also surpasses MTCSWA in estimating critical wind radii of TCs, by 32%, 25%, 28%, and 38% for RMW, R64, R50, and R34, respectively.These results demonstrate that DeepTCNet can fundamentally improve the mining of IR imagery for TC intensity and wind radii estimation.Therefore, there is reason to believe the DeepTCNet method can be applied to enhancing the utilization of other observations of TCs.\n\nMore training samples with high-quality to build up deep learning models, such as aircraft observations, are particularly crucial for intensity and size estimates.However, the dilemma of data limitation for deep learning methods would be tough in the short term, especially in the research area of extreme weather systems like TCs.Therefore, exploring and developing appropriate approaches to incorporating physical knowledge of TCs into deep learning algorithms is the essential further direction.Besides, introducing the microwave sensor-based observations into the DeepTCNet could be crucial for producing more accurate estimates.\n\nFIG. 1 .\n1\nFIG. 1.The configuration of DeepTCNet in both single-task and multitask learning frameworks.\n\n\nFIG. 2 .\n2\nFIG. 2. Learning curves, i.e., mean absolute errors for the intensity estimation on the validation set during each training epoch of DeepTCNet developed with (a) different auxiliary information and (b) successive IR sequences of different time span.\n\n\nFIG. 3 .\n3\nFIG. 3. Mean absolute errors of MSW (kt) on the test dataset produced by the DeepTCNet obtained by different training data sizes.The model trained with rotation augmentation is denoted as ROT (dashed line).\n\n\nFIG. 5 .\n5\nFIG. 5. Performance of (a) DeepTCNet MSW estimates (kt) and (b) MSLP estimates (hPa) against ADT and SATCON as a function of TC intensity (MSW) bins (kt; x axis).The metrics are counted using the 63-h recon-aided best track records for the Atlantic TCs in 2017 and 2019, with 95% confidence intervals obtained by bootstrapping.\n\n\nFIG. 6 .\n6\nFIG. 6.Relative uncertainty in the best tracks (blue and green bars) and the percentage relative estimation errors of the DeepTCNet (red bars) for MSW, MSLP, R34, R50, R64, and RMW.The statistics of best track uncertainty (if available) were taken from Landsea and Franklin (2013) as references.The verification of DeepTCNet was based on 2017 and 2019 cases in the Atlantic basin with 63-h aircraft reconnaissance fixes.\n\n\nFIG. 8 .\n8\nFIG. 8.The (top left) input imagery and (a)-(l) interpretation heatmaps of DeepTCNet for estimating intensity and wind radii.The heat maps were obtained by (a)-(f) SmoothGrad (Smilkov et al. 2017) and (g)-(l) LRP (Montavon et al. 2018) for Hurricane Irma at 0900 UTC 5 Sep 2017 with an intensity of 142 kt.The inserted boxes denote the small IR image and the corresponding heat maps [(a),(b),(g),(h)] for the DeepTCNet-I, while the larger ones are for the DeepTCNet-R.The black rings and blue rings in (c)-(f) and (i)-(l) represent the best track wind radii and the DeepTCNet-estimated wind radii, respectively.The relative error for each estimated parameter was ,1% compared with the best track observation.The LRP and saliency maps are calculated using the iNNvestigate package (Alber et al. 2019), and LRP is applied with the a 5 1 and b 5 0.\n\n\nFIG. 9 .\n9\nFIG. 9. Composite average IR bright temperature and LRP heat maps for DeepTCNet-R to estimate the R34 for the (left) small TCs and (right) large TCs.The 25% quantile samples of the R34 in the recon-aided testing dataset were used to compose small TCs (N 5 110, m 5 54 n mi), while the 75% quantile samples composed the large TCs (N 5 112, m 5 165 n mi).The black rings and blue rings in LRP represent the averaged best track R34 and the averaged DeepTCNet-estimated R34, respectively.\n\n\nTable 1\n1): the\n\nTABLE 1 .\n1\nThe data size of the labels of training, validation, and test datasets for 1-min maximum sustained surface winds (MSW), minimum sea level pressure (MSLP), radius of maximum wind (RMW), and radii of 64-, 50-, and 34-kt winds (R64, R50, and R34).The units for MSW and MSLP are kt and hPa, respectively.The units for RMW, R64, R50, and R34 are n mi (1 n mi ' 1.85 km).\nTraining dataset:ValidationTestTC2005-15dataset:dataset:parameter(1990-2015)2016, 20182017, 2019MSW6695 (16 136)14351463MSLP6695 (16 136)14351463RMW484110851168R641707380567R502897622775R34484110851168\nUnauthenticated | Downloaded 09/28/23 01:59 AM UTC the fully connected layers and ReLu activation functions are used.\n\n\nTABLE 3 .\n3\n. The lowest error is shown in boldface.The mean absolute errors on the test dataset for TC intensity estimation (MAE; unit: kt) for different depths and kernel sizes in the first convolutional layer of the VGGNet.The architectures of networks tested are the same as VGGNet in Table2, but for the depth or kernel size.The MAEs are counted with the validation dataset.The depth and kernel size settings with the lowest estimation error are shown in boldface.\nDepthMAE (kt)Kernel sizeMAE (kt)810.6310.31310.3510.42211.2710.53411.0910.83711.31110.9CNN architectureDepthKernel sizeMAE (kt)AlexNet81212.0VGGNet13310.3GoogLeNet22711.4ResNet34712.2Xception37310.6\n\nTABLE 4 .\n4\nHomogeneous comparison between the ADT, SATCON, and DeepTCNet estimates of Atlantic TC intensity in 2017 and 2019 against the recon-aided best track for MSW (kt) and MSLP (hPa) (N 5 450).\nBiasMAERMSEADT 2 MSW24.511.214.2SATCON 2 MSW0.17.39.4DeepTCNet 2 MSW22.36.88.7ADT 2 MSLP2.68.010.2SATCON 2 MSLP20.44.86.0DeepTCNet 2 MSLP1.85.47.0\n\nTABLE 5 .\n5\nHomogeneous comparison between the subjective Dvorak and DeepTCNet estimates of Atlantic TC intensity in 2017 and 2019 against the recon-aided best track for MSW (kt).The subjective Dvorak intensity estimates were obtained from the ATCF fixes files in which the intensities are indicated as DVTS in the fifth column (N 5 333).\nBiasMAERMSEDvorak 2 MSW24.97.69.4DeepTCNet 2 MSW21.46.38.1\nUnauthenticated | Downloaded 09/28/23 01:59 AM UTC\n\n\nTABLE 6 .\n6\nHomogeneous comparison between the MTCSWA and DeepTCNet estimates of Atlantic TC wind radii in 2017 and 2019 against the recon-aided best track for RMW, R64, R50 and R34 (n mi; 1 n mi ' 1.85 km).\nParameterTechniqueBiasMAERMSERMW (N 5 381)MTCSWA4.611.718.2DeepTCNet21.37.311.0R64 (N 5 216)MTCSWA4.510.213.1DeepTCNet20.87.310.0R50 (N 5 313)MTCSWA20.815.820.7DeepTCNet23.111.815.5R34 (N 5 382)MTCSWA27.426.433.0DeepTCNet2.717.221.8\n\nTABLE 7 .\n7\nMean absolute errors (unit: n mi; 1 n mi ' 1.85 km) of wind radii estimates derived by DeepTCNet and other methods, as well as the satellite technique used for each method.The metrics of DeepTCNet are counted with Atlantic TC wind radii in 2017 and 2019 against the recon-aided best track for R34, R50, R64, and RMW.Note that the statistics for the existing size estimation models are taken from the original papers and their evaluation samples are inconsistent.\nSatelliteMethodtechniqueRMW R64 R50 R34Demuth et al. (2006) AMSU-6.8 13.3 16.9Kossin et al. (2007) IR11.4 14.5 19.8 24.2Knaff et al. (2011)IR, Scatterometer,-13.0 17.8 36.5AMSUKnaff et al. (2016)IR-12.0 20.0 37.0Dolling et al. (2016) IR-7.3 12.5 20.8DeepTCNetIR7.69.2 12.5 17.0\n\nTABLE 8 .\n8\nMAE and RMSE of the DeepTCNet-I estimates given different data sources of TC fullness.''No TC fullness'' denotes the comparison model that was built up with the identical model settings of the DeepTCNet-I but without using TC fullness as auxiliary information.The statistics are calculated with the recon-aided best track for MSW (kt) for Atlantic TCs in 2017 and 2019 (N 5 485).\nData source of TC fullnessMAE (kt)RMSE (kt)TC Vitals6.88.8MTCSWA7.59.6MTL47.49.4MTL67.29.2Best track6.78.7No TC fullness8.010.5\nUnauthenticated | Downloaded 09/28/23 01:59 AM UTC\n\nIn the Automated Tropical Cyclone Forecast System(Sampson  and Schrader  \n), these are the CARQ entries in the aid deck (adeck). The TC Vitals has also been referred to as ''the bogus'' in past literature.\nThe subjective Dvorak intensity estimates were obtained from the ATCF fixes files in which the intensities are indicated as DVTS in the fifth column.\nUnauthenticated | Downloaded 09/28/23 01:59 AM UTC\nSep 2017 with an intensity of 142 kt. The inserted boxes denote the small IR image and the corresponding heat maps [(a),(b),(g),(h)] for the DeepTCNet-I, while the larger ones are for the DeepTCNet-R. The black rings and blue rings in (c)-(f) and (i)-(l) represent the best track wind radii and the DeepTCNet-estimated wind radii, respectively. The relative error for each estimated parameter was ,1% compared with the best track observation. The LRP and saliency maps are calculated using the iNNvestigate package (Alber et al. 2019), and LRP is applied with the a 5 1 and b 5 0.\nAcknowledgments.We acknowledge John Knaff and Haiyan Jiang for valuable feedback that greatly improved this work.We also thank Clark Evans for helping to improve this manuscript.One anonymous reviewer also enhanced this manuscript.This study is jointly supported by the National Key Research and Development Program of China under Grant 2017YFC1501604 and the National Natural Science Foundation of China under Grant 61827901.Data availability statement.The intensity estimates of SATCON and ADT are downloaded from http:// tropic.ssec.wisc.edu.Both the subjective Dvorak estimates and the TC Vitals data can be downloaded from https:// ftp.nhc.noaa.gov/atcf/archive/.The MTCSWA data are obtained from https://rammb-data.cira.colostate.edu/tc_realtime.Interested readers can contact Jing-Yi Zhuo (jyzhuo@smail.nju.edu.cn) to obtain the data underlying the findings of this paper.\n2019: iNNvestigate neural networks!. M Alber, Coauthors , J. Mach. Learn. Res. 20\n\nImpact of storm size on prediction of storm track and intensity using the 2016 operational GFDL hurricane model. M A Bender, T P Marchok, C R Sampson, J A Knaff, M J Morin, 10.1175/WAF-D-16-0220.1Wea. Forecasting. 322017\n\nApplications of deep learning to ocean data inference and subgrid parameterization. T Bolton, L Zanna, 10.1029/2018MS001472J. Adv. Model. Earth Syst. 112019\n\nThe operational use of QuikSCAT ocean surface vector winds at the National Hurricane Center. M J Brennan, C C Hennon, R D Knabb, 10.1175/2008WAF2222188.1Wea. Forecasting. 242009\n\nA model for the complete radial structure of the tropical cyclone wind field. Part I: Comparison with observed structure. D R Chavas, N Lin, K Emanuel, 10.1038/s41467-017-01546-9J. Atmos. Sci. K. A. Reed, and J. A. Knaff7213602015Nat. Commun.\n\nEstimating tropical cyclone intensity by satellite imagery utilizing convolutional neural networks. B F Chen, B Chen, H T Lin, R L Elsberry, 10.1175/WAF-D-18-0136.1Wea. Forecasting. 342019\n\nXception: Deep learning with depthwise separable convolutions. F Chollet, 10.1109/CVPR.2017.195IEEE Conf. on Computer Vision and Pattern Recognition. Honolulu, HI, IEEE2017. 2017\n\nMulti-task learning using uncertainty to weigh losses for scene geometry and semantics. R Cipolla, Y Gal, A Kendall, 10.1109/CVPR.2018.00781Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR). IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)Salt Lake City, UT2018\n\nAdapting the Knaff and Zehr wind-pressure relationship for operational use in tropical cyclone warning centres. J Courtney, J A Knaff, 10.22499/2.5803.002Aust. Meteor. Oceanogr. J. 582009\n\nImprovements to the operational tropical cyclone wind speed probability model. M Demaria, C R Coauthors, J A Sampson, K D Knaff, Musgrave, 10.1175/BAMS-D-12-00240.1Bull. Amer. Meteor. Soc. 282013. 2014Wea. ForecastingIs tropical cyclone intensity guidance improving?\n\nImprovement of Advanced Microwave Sounding Unit tropical cyclone intensity and size estimation algorithms. J L Demuth, M Demaria, J A Knaff, T H Vonder Haar, 10.1175/JAM2429.10282:EOAMSU.2.0J. Appl. Meteor. Climatol. 432004. 2004. 2006J. Appl. Meteor.\n\n2016: The use of the deviation angle variance technique on geostationary satellite imagery to estimate tropical cyclone size parameters. K Dolling, E A Ritchie, J S Tyo, 10.1175/WAF-D-16-0056.1Wea. Forecasting. 31\n\n2020: Evaluation, tuning, and interpretation of neural networks for working with images in meteorological applications. I Ebert-Uphoff, K Hilburn, 10.1175/BAMS-D-20-0097.1Bull. Amer. Meteor. Soc. 101\n\nObjective tropical cyclone intensity estimation using analogs of spatial features in satellite data. K Emanuel, R Rotunno ; Fetanat, G , A Homaifar, K R Knapp, 10.1175/WAF-D-13-00006.1Wea. Forecasting. 682011. 2013J. Atmos. Sci.\n\nI Goodfellow, Y Bengio, A Courville, Deep Learning. MIT Press2016800\n\nTropical cyclone fullness: A new concept for interpreting storm intensity. X Guo, Z.-M Tan, 10.1002/2017GL073680Geophys. Res. Lett. 442017\n\nDeep learning for multiyear ENSO forecasts. Y G Ham, J H Kim, J J Luo, 10.1038/s41586-019-1559-7Nature. 5732019\n\n2020: A moist physics parameterization based on deep learning. Y Han, G J Zhang, X Huang, Y Wang, 10.1029/2020MS002076J. Adv. Model. Earth Syst. 12\n\nDeep residual learning for image recognition. K He, X Zhang, S Ren, J Sun, 10.1109/CVPR.2016.90Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR). IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)Las Vegas, NV, IEEE2016\n\nDeep neural networks for acoustic modeling in speech recognition. G Hinton, Coauthors , 10.1109/MSP.2012.2205597IEEE Signal Process. Mag. 292012\n\nEstimation of tropical cyclone intensity in the North Atlantic and northeastern Pacific Basins using TRMM satellite passive microwave observations. H Jiang, C Tao, Y Pei, 10.1175/JAMC-D-18-0094.1J. Appl. Meteor. Climatol. 582019\n\nD P Kingma, J Ba, Adam: A method for stochastic optimization. 2014\n\nAfter a decade are Atlantic tropical cyclone gale force wind radii forecasts now skillful? Wea. Forecasting. J A Knaff, R M Zehr, C R Sampson, D P Brown, J Courtney, G M Gallina, J L Beven, ; M Demaria, D A Molenar, C R Sampson, M G Seybold, 10.1175/MWR-D-15-0267.1J. Appl. Meteor. Climatol. C. J. Slocum, K. D. Musgrave, C. R. Sampson, and B. R. Strahl222007. 2015. 2010. 2016Wea. ForecastingMon. Wea. Rev.\n\nNew global tropical cyclone data set from ISCCP B1 geostationary satellite observations. K R Knapp, J P Kossin, M C Kruk, D H Levinson, H J Diamond, C J Neumann, 10.1175/2011BAMS3039.1The International Best Track Archive for Climate Stewardship (IBTrACS). 2007. 2010. 20111Bull. Amer. Meteor. Soc.\n\nEstimating hurricane wind structure in the absence of aircraft reconnaissance. J P Kossin, Coauthors ; Utc Krizhevsky, A , I Sutskever, G E Hinton, 10.1145/306538609/28/23 01:59 AMCommun. ACM. 222007. 2017Wea. ForecastingImageNet classification with deep convolutional neural networks\n\nDeep learning for spatially explicit prediction of synoptic-scale fronts. R Lagerquist, A Mcgovern, D J Gagne, I I , 10.1175/WAF-D-18-0183.1Wea. Forecasting. 342019\n\nA technique to determine the radius of maximum wind of a tropical cyclone. F Lajoie, K Walsh, 10.1175/2008WAF2007077.1Wea. Forecasting. 232008\n\nAtlantic hurricane database uncertainty and presentation of a new database format. Mon. C W Landsea, J L Franklin, 10.1175/MWR-D-12-00254.1Wea. Rev. 1412013\n\nDeep learning. Y Lecun, Y Bengio, G Hinton, 10.1038/nature14539Nature. 5212015\n\nApplication of deep convolutional neural networks for detecting extreme weather in climate datasets. Y Liu, Coauthors , 2016\n\nMaking the black box more transparent: Understanding the physical implications of machine learning. A Mcgovern, R A Lagerquist, D J Gagne, G E Jergensen, K L Elmore, C R Homeyer, T Smith, 10.1175/BAMS-D-18-0195.1Bull. Amer. Meteor. Soc. 1002019\n\nThe effect of translation speed upon the intensity of tropical cyclones over the tropical ocean. W Mei, C Pasquero, F Primeau, 10.1029/2011GL050765Geophys. Res. Lett. 39L078012012\n\nExplaining nonlinear classification decisions with deep Taylor decomposition. G Montavon, S Lapuschkin, A Binder, W Samek, K.-R M\u00fcller, K.-R Samek, M\u00fcller, 10.1016/j.dsp.2017.10.011Methods for interpreting and understanding deep neural networks. 2017. 201865Pattern Recognit.\n\nDetermining tropical cyclone surface wind speed structure and intensity with the CYGNSS satellite constellation. M Morris, C S Ruf, 10.1175/JAMC-D-16-0375.1J. Appl. Meteor. Climatol. 562017\n\nObjective estimation of tropical cyclone wind structure from infrared satellite data. K J Mueller, M Demaria, J Knaff, J P Kossin, T H Vonder Haar, 10.1175/WAF955.1Wea. Forecasting. 212006\n\nThe advanced Dvorak technique: Continued development of an objective scheme to estimate tropical cyclone intensity using geostationary infrared satellite imagery. T L Olander, C S Velden, 10.1175/WAF-D-19-0007.1Wea. Forecasting. 222007Wea. Forecasting2019: The advanced Dvorak technique (ADT) for estimating tropical cyclone intensity: Update and new capabilities\n\nTropical cyclone intensity estimation using a deep convolutional neural network. R Pradhan, R S Aygun, M Maskey, R Ramachandran, D J Cecil, 10.1109/TIP.2017.2766358IEEE Trans. Image Process. 272018\n\nPhysics-informed neural networks: A deep learning framework for solving forward and inverse problems involving nonlinear partial differential equations. M Raissi, P Perdikaris, G E Karniadakis, 10.1016/j.jcp.2018.10.045J. Comput. Phys. 3782019\n\nDeep learning to represent subgrid processes in climate models. S Rasp, M S Pritchard, P Gentine, 10.1073/pnas.1810286115Proc. Natl. Acad. Sci. USA. Natl. Acad. Sci. USA2018115\n\nDeep learning and process understanding for data-driven earth system science. M Reichstein, G Camps-Valls, B Stevens, M Jung, J Denzler, N Carvalhais, 10.1038/s41586-019-0912-1Nature. 5662019\n\nA new generation of tropical cyclone size measurements from space. N Reul, Coauthors , 10.1175/BAMS-D-15-00291.1Bull. Amer. Meteor. Soc. 982017\n\n2012: Tropical cyclone intensity estimation in the North Atlantic basin using an improved deviation angle variance technique. E A Ritchie, G Valliere-Kelley, M F Pi\u00f1eros, J S Tyo, 10.1175/WAF-D-11-00156.1Wea. Forecasting. 27\n\nTropical cyclone gale wind radii estimates, forecasts, and error forecasts for the western North Pacific. C R Sampson, A J Schrader, P A Wittmann, H L Tolman, 10.1175/WAF-D-17-0153.11231:TATCFS.2.3The Automated Tropical Cyclone Forecasting System. J S Goerss, J A Knaff, B R Strahl, E M Fukada, E A Serra, Wea. Forecasting2000. 2010. 201881Consistent tropical cyclone wind and wave forecasts for the U\n\nMastering the game of Go with deep neural networks and tree search. D Silver, Coauthors , 10.1038/nature16961Nature. 5292016\n\nK Simonyan, A Zisserman, Very deep convolutional networks for large-scale image recognition. 2014\n\nD Smilkov, N Thorat, B Kim, F Vi\u00e9gas, M Wattenberg, SmoothGrad: Removing noise by adding noise. 2017\n\nKnowledge-enhanced deep learning for simulation of tropical cyclone boundary-layer winds. R Snaiki, T Wu, 10.1016/j.jweia.2019.103983J. Wind Eng. Ind. Aerodyn. 1941039832019\n\nC K S\u00f8nderby, Coauthors , MetNet: A neural weather model for precipitation forecasting. 2020\n\n2017: The CMOD7 geophysical model function for ASCAT and ERS wind retrievals. A Stoffelen, A J Verspeek, J Vogelzang, A Verhoef, 10.1109/JSTARS.2017.2681806IEEE J. Sel. Top. Appl. Earth Obs. 101998. 195ScatterometryUniversity of UtrechtPh.D. thesis\n\nRethinking the inception architecture for computer vision. C Szegedy, V Vanhoucke, S Ioffe, J Shlens, Z Wojna, 10.1109/CVPR.2016.308Proc. IEEE Conf. on Computer Vision and Pattern Recognition (CVPR). IEEE Conf. on Computer Vision and Pattern Recognition (CVPR)Las Vegas, NV, IEEE2016\n\nHurricane Weather Research and Forecasting (HWRF) model: 2014 scientific documentation. V Tallapragada, Coauthors , 2014Developmental Testbed Center105\n\nUncertainty of tropical cyclone best-track information. R D Torn, C Snyder, 10.1175/WAF-D-11-00085.1Wea. Forecasting. 272012\n\nThe Dvorak tropical cyclone intensity estimation technique: A satellite-based method that has endured for over 30 years. C Velden, D Herndon, 10.1175/BAMS-87-9-1195Bull. Amer. Meteor. Soc. 352006SATCON. Wea. Forecasting2020: A consensus approach for estimating tropical cyclone intensity from meteorological satellites\n\nTyphoon structure as revealed by aircraft reconnaissance. Part I: Data analysis and climatology. C Weatherford, W Gray, 10.1175/1520-0493(1988)116<1032:TSARBA>2.0.CO;2Mon. Wea. Rev. 1161988\n\nImproving datadriven global weather prediction using deep convolutional neural networks on a cubed sphere. J A Weyn, D R Durran, R Caruana, 10.1029/2020MS002109J. Adv. Model. Earth Syst. 122020\n\nUsing deep learning to estimate tropical cyclone intensity from satellite passive microwave imagery. A Wimmers, C Velden, J H Cossuth, 10.1175/MWR-D-18-0391.1Mon. Wea. Rev. 1472019\n\nS Woo, J Park, J Y Lee, I S Kweon, 10.1007/978-3-030-01234-2_1CBAM: Convolutional block attention module. European Conf. on Computer Vision (ECCV). Munich, Germany, ECCV2018\n\nAn overview of multi-task learning. Y Zhang, Q Yang, 10.1093/nsr/nwx105Natl. Sci. Rev. 52017\n", "annotations": {"author": "[{\"end\":291,\"start\":116},{\"end\":483,\"start\":292}]", "publisher": null, "author_last_name": "[{\"end\":128,\"start\":124},{\"end\":303,\"start\":300}]", "author_first_name": "[{\"end\":123,\"start\":116},{\"end\":299,\"start\":292}]", "author_affiliation": "[{\"end\":226,\"start\":130},{\"end\":290,\"start\":228},{\"end\":418,\"start\":322},{\"end\":482,\"start\":420}]", "title": "[{\"end\":113,\"start\":1},{\"end\":596,\"start\":484}]", "venue": null, "abstract": "[{\"end\":2354,\"start\":772}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b27\"},\"end\":2741,\"start\":2715},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":2764,\"start\":2741},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":3467,\"start\":3446},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":3573,\"start\":3553},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":3961,\"start\":3941},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":4222,\"start\":4198},{\"end\":4227,\"start\":4222},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":4299,\"start\":4280},{\"end\":4319,\"start\":4299},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":4339,\"start\":4319},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":4701,\"start\":4683},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":4723,\"start\":4701},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":4741,\"start\":4723},{\"end\":5045,\"start\":5020},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":5185,\"start\":5166},{\"end\":5209,\"start\":5185},{\"end\":5233,\"start\":5209},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":5514,\"start\":5492},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":5724,\"start\":5704},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":5885,\"start\":5865},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":6033,\"start\":6017},{\"end\":6055,\"start\":6033},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":6261,\"start\":6244},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":6372,\"start\":6352},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":6391,\"start\":6372},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":6409,\"start\":6391},{\"end\":6429,\"start\":6409},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":6483,\"start\":6464},{\"end\":6538,\"start\":6519},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":6599,\"start\":6578},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":6771,\"start\":6752},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":7036,\"start\":7009},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":7059,\"start\":7036},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":7225,\"start\":7205},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":7246,\"start\":7225},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":7266,\"start\":7246},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":7285,\"start\":7266},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":7391,\"start\":7371},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":7907,\"start\":7888},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":7925,\"start\":7907},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":7944,\"start\":7925},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":7967,\"start\":7944},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":8177,\"start\":8160},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":8193,\"start\":8177},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":8216,\"start\":8193},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":8317,\"start\":8296},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":8534,\"start\":8516},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":8611,\"start\":8590},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":8764,\"start\":8746},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":8902,\"start\":8881},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":10561,\"start\":10542},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":10739,\"start\":10717},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":10863,\"start\":10845},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":11191,\"start\":11173},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":11573,\"start\":11548},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":11592,\"start\":11573},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":13008,\"start\":12988},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":13446,\"start\":13427},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":13714,\"start\":13685},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":13737,\"start\":13714},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":14308,\"start\":14289},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":14485,\"start\":14466},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":14508,\"start\":14485},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":14675,\"start\":14659},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":14698,\"start\":14675},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":14719,\"start\":14698},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":14784,\"start\":14762},{\"end\":14799,\"start\":14784},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":14884,\"start\":14868},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":14905,\"start\":14884},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":14922,\"start\":14905},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":15417,\"start\":15393},{\"end\":15447,\"start\":15417},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":15714,\"start\":15691},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":15995,\"start\":15966},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":16015,\"start\":15995},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":16030,\"start\":16015},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":16053,\"start\":16030},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":16066,\"start\":16053},{\"end\":17061,\"start\":17011},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":17865,\"start\":17845},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":18559,\"start\":18533},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":18578,\"start\":18559},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":19309,\"start\":19290},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":19328,\"start\":19309},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":20443,\"start\":20422},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":22115,\"start\":22091},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":22237,\"start\":22208},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":22342,\"start\":22321},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":22420,\"start\":22404},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":22557,\"start\":22543},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":22677,\"start\":22657},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":25038,\"start\":25019},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":25086,\"start\":25070},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":25126,\"start\":25108},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":25434,\"start\":25416},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":26678,\"start\":26660},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":27933,\"start\":27913},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":29210,\"start\":29194},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":29490,\"start\":29468},{\"end\":32517,\"start\":32493},{\"end\":32588,\"start\":32563},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":34316,\"start\":34289},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":34337,\"start\":34316},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":34453,\"start\":34433},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":34470,\"start\":34453},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":35007,\"start\":34980},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":36006,\"start\":35979},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":36257,\"start\":36236},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":36323,\"start\":36305},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":36765,\"start\":36747},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":36798,\"start\":36780},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":36934,\"start\":36913},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":37995,\"start\":37974},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":39926,\"start\":39900},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":39952,\"start\":39926},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":40052,\"start\":40031},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":40076,\"start\":40052},{\"end\":40215,\"start\":40196},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":41337,\"start\":41316},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":41361,\"start\":41337},{\"end\":41380,\"start\":41361},{\"end\":43093,\"start\":43075},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":43658,\"start\":43634},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":45407,\"start\":45387},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":45471,\"start\":45451},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":45496,\"start\":45471},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":45859,\"start\":45839},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":46075,\"start\":46053},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":46362,\"start\":46340},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":49860,\"start\":49840},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":49900,\"start\":49878},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":52530,\"start\":52509},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":52650,\"start\":52629}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":56719,\"start\":56614},{\"attributes\":{\"id\":\"fig_1\"},\"end\":56982,\"start\":56720},{\"attributes\":{\"id\":\"fig_2\"},\"end\":57202,\"start\":56983},{\"attributes\":{\"id\":\"fig_3\"},\"end\":57543,\"start\":57203},{\"attributes\":{\"id\":\"fig_4\"},\"end\":57977,\"start\":57544},{\"attributes\":{\"id\":\"fig_5\"},\"end\":58836,\"start\":57978},{\"attributes\":{\"id\":\"fig_6\"},\"end\":59334,\"start\":58837},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":59351,\"start\":59335},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":60051,\"start\":59352},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":60721,\"start\":60052},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":61069,\"start\":60722},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":61520,\"start\":61070},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":61962,\"start\":61521},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":62716,\"start\":61963},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":63289,\"start\":62717}]", "paragraph": "[{\"end\":3468,\"start\":2370},{\"end\":5234,\"start\":3470},{\"end\":5725,\"start\":5236},{\"end\":6802,\"start\":5727},{\"end\":7716,\"start\":6804},{\"end\":9684,\"start\":7718},{\"end\":10184,\"start\":9686},{\"end\":11871,\"start\":10214},{\"end\":13022,\"start\":11873},{\"end\":13326,\"start\":13024},{\"end\":15054,\"start\":13375},{\"end\":16838,\"start\":15056},{\"end\":17230,\"start\":16840},{\"end\":18864,\"start\":17281},{\"end\":20057,\"start\":18866},{\"end\":21099,\"start\":20059},{\"end\":23142,\"start\":21101},{\"end\":24129,\"start\":23181},{\"end\":24710,\"start\":24185},{\"end\":25435,\"start\":24712},{\"end\":27754,\"start\":25437},{\"end\":28176,\"start\":27800},{\"end\":29211,\"start\":28178},{\"end\":29720,\"start\":29261},{\"end\":30367,\"start\":29722},{\"end\":31488,\"start\":30369},{\"end\":31968,\"start\":31518},{\"end\":34137,\"start\":31970},{\"end\":35895,\"start\":34139},{\"end\":36007,\"start\":35897},{\"end\":37422,\"start\":36009},{\"end\":38333,\"start\":37462},{\"end\":39150,\"start\":38389},{\"end\":42149,\"start\":39152},{\"end\":42895,\"start\":42179},{\"end\":44814,\"start\":42897},{\"end\":46751,\"start\":44880},{\"end\":49435,\"start\":46753},{\"end\":51460,\"start\":49492},{\"end\":53042,\"start\":51462},{\"end\":53975,\"start\":53044},{\"end\":55270,\"start\":53987},{\"end\":55978,\"start\":55272},{\"end\":56613,\"start\":55980},{\"end\":56718,\"start\":56626},{\"end\":56981,\"start\":56732},{\"end\":57201,\"start\":56995},{\"end\":57542,\"start\":57215},{\"end\":57976,\"start\":57556},{\"end\":58835,\"start\":57990},{\"end\":59333,\"start\":58849},{\"end\":59730,\"start\":59365},{\"end\":60050,\"start\":59933},{\"end\":60522,\"start\":60065},{\"end\":60922,\"start\":60735},{\"end\":61409,\"start\":61083},{\"end\":61519,\"start\":61469},{\"end\":61729,\"start\":61534},{\"end\":62438,\"start\":61976},{\"end\":63109,\"start\":62730},{\"end\":63288,\"start\":63238}]", "formula": null, "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":13076,\"start\":13070},{\"end\":15964,\"start\":15963},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":16503,\"start\":16495},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":18117,\"start\":18116},{\"end\":25526,\"start\":25525},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":29875,\"start\":29874},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":32802,\"start\":32801},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":34488,\"start\":34487},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":41952,\"start\":41951},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":42916,\"start\":42915},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":44756,\"start\":44755},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":50050,\"start\":50049},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":50615,\"start\":50614},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":51084,\"start\":51083},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":51458,\"start\":51457}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":2368,\"start\":2356},{\"attributes\":{\"n\":\"2.\"},\"end\":10202,\"start\":10187},{\"end\":10212,\"start\":10205},{\"end\":13373,\"start\":13329},{\"end\":17279,\"start\":17233},{\"attributes\":{\"n\":\"3.\"},\"end\":23179,\"start\":23145},{\"end\":24183,\"start\":24132},{\"end\":27798,\"start\":27757},{\"end\":29259,\"start\":29214},{\"end\":31516,\"start\":31491},{\"attributes\":{\"n\":\"4.\"},\"end\":37460,\"start\":37425},{\"end\":38387,\"start\":38336},{\"end\":42177,\"start\":42152},{\"attributes\":{\"n\":\"5.\"},\"end\":44827,\"start\":44817},{\"end\":44878,\"start\":44830},{\"end\":49490,\"start\":49438},{\"attributes\":{\"n\":\"6.\"},\"end\":53985,\"start\":53978},{\"end\":56623,\"start\":56615},{\"end\":56729,\"start\":56721},{\"end\":56992,\"start\":56984},{\"end\":57212,\"start\":57204},{\"end\":57553,\"start\":57545},{\"end\":57987,\"start\":57979},{\"end\":58846,\"start\":58838},{\"end\":59343,\"start\":59336},{\"end\":59362,\"start\":59353},{\"end\":60062,\"start\":60053},{\"end\":60732,\"start\":60723},{\"end\":61080,\"start\":61071},{\"end\":61531,\"start\":61522},{\"end\":61973,\"start\":61964},{\"end\":62727,\"start\":62718}]", "table": "[{\"end\":59351,\"start\":59345},{\"end\":59932,\"start\":59731},{\"end\":60721,\"start\":60523},{\"end\":61069,\"start\":60923},{\"end\":61468,\"start\":61410},{\"end\":61962,\"start\":61730},{\"end\":62716,\"start\":62439},{\"end\":63237,\"start\":63110}]", "figure_caption": "[{\"end\":56719,\"start\":56625},{\"end\":56982,\"start\":56731},{\"end\":57202,\"start\":56994},{\"end\":57543,\"start\":57214},{\"end\":57977,\"start\":57555},{\"end\":58836,\"start\":57989},{\"end\":59334,\"start\":58848},{\"end\":59731,\"start\":59364},{\"end\":60523,\"start\":60064},{\"end\":60923,\"start\":60734},{\"end\":61410,\"start\":61082},{\"end\":61730,\"start\":61533},{\"end\":62439,\"start\":61975},{\"end\":63110,\"start\":62729}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":16858,\"start\":16857},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":17305,\"start\":17304},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":18760,\"start\":18759},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":25778,\"start\":25776},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":27482,\"start\":27480},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":28197,\"start\":28195},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":30393,\"start\":30392},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":30855,\"start\":30854},{\"end\":32074,\"start\":32073},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":32610,\"start\":32609},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":34757,\"start\":34756},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":35568,\"start\":35567},{\"end\":38579,\"start\":38578},{\"end\":39327,\"start\":39326},{\"end\":40545,\"start\":40544},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":41082,\"start\":41080},{\"end\":41444,\"start\":41443},{\"end\":42444,\"start\":42443},{\"end\":42703,\"start\":42702},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":43677,\"start\":43676},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":46783,\"start\":46782},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":47558,\"start\":47555},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":48687,\"start\":48686}]", "bib_author_first_name": "[{\"end\":65196,\"start\":65195},{\"end\":65213,\"start\":65204},{\"end\":65355,\"start\":65354},{\"end\":65357,\"start\":65356},{\"end\":65367,\"start\":65366},{\"end\":65369,\"start\":65368},{\"end\":65380,\"start\":65379},{\"end\":65382,\"start\":65381},{\"end\":65393,\"start\":65392},{\"end\":65395,\"start\":65394},{\"end\":65404,\"start\":65403},{\"end\":65406,\"start\":65405},{\"end\":65548,\"start\":65547},{\"end\":65558,\"start\":65557},{\"end\":65715,\"start\":65714},{\"end\":65717,\"start\":65716},{\"end\":65728,\"start\":65727},{\"end\":65730,\"start\":65729},{\"end\":65740,\"start\":65739},{\"end\":65742,\"start\":65741},{\"end\":65923,\"start\":65922},{\"end\":65925,\"start\":65924},{\"end\":65935,\"start\":65934},{\"end\":65942,\"start\":65941},{\"end\":66145,\"start\":66144},{\"end\":66147,\"start\":66146},{\"end\":66155,\"start\":66154},{\"end\":66163,\"start\":66162},{\"end\":66165,\"start\":66164},{\"end\":66172,\"start\":66171},{\"end\":66174,\"start\":66173},{\"end\":66298,\"start\":66297},{\"end\":66503,\"start\":66502},{\"end\":66514,\"start\":66513},{\"end\":66521,\"start\":66520},{\"end\":66819,\"start\":66818},{\"end\":66831,\"start\":66830},{\"end\":66833,\"start\":66832},{\"end\":66975,\"start\":66974},{\"end\":66986,\"start\":66985},{\"end\":66988,\"start\":66987},{\"end\":67001,\"start\":67000},{\"end\":67003,\"start\":67002},{\"end\":67014,\"start\":67013},{\"end\":67016,\"start\":67015},{\"end\":67271,\"start\":67270},{\"end\":67273,\"start\":67272},{\"end\":67283,\"start\":67282},{\"end\":67294,\"start\":67293},{\"end\":67296,\"start\":67295},{\"end\":67305,\"start\":67304},{\"end\":67307,\"start\":67306},{\"end\":67554,\"start\":67553},{\"end\":67565,\"start\":67564},{\"end\":67567,\"start\":67566},{\"end\":67578,\"start\":67577},{\"end\":67580,\"start\":67579},{\"end\":67752,\"start\":67751},{\"end\":67768,\"start\":67767},{\"end\":67934,\"start\":67933},{\"end\":67945,\"start\":67944},{\"end\":67966,\"start\":67965},{\"end\":67970,\"start\":67969},{\"end\":67982,\"start\":67981},{\"end\":67984,\"start\":67983},{\"end\":68063,\"start\":68062},{\"end\":68077,\"start\":68076},{\"end\":68087,\"start\":68086},{\"end\":68208,\"start\":68207},{\"end\":68218,\"start\":68214},{\"end\":68317,\"start\":68316},{\"end\":68319,\"start\":68318},{\"end\":68326,\"start\":68325},{\"end\":68328,\"start\":68327},{\"end\":68335,\"start\":68334},{\"end\":68337,\"start\":68336},{\"end\":68449,\"start\":68448},{\"end\":68456,\"start\":68455},{\"end\":68458,\"start\":68457},{\"end\":68467,\"start\":68466},{\"end\":68476,\"start\":68475},{\"end\":68581,\"start\":68580},{\"end\":68587,\"start\":68586},{\"end\":68596,\"start\":68595},{\"end\":68603,\"start\":68602},{\"end\":68849,\"start\":68848},{\"end\":68867,\"start\":68858},{\"end\":69077,\"start\":69076},{\"end\":69086,\"start\":69085},{\"end\":69093,\"start\":69092},{\"end\":69159,\"start\":69158},{\"end\":69161,\"start\":69160},{\"end\":69171,\"start\":69170},{\"end\":69336,\"start\":69335},{\"end\":69338,\"start\":69337},{\"end\":69347,\"start\":69346},{\"end\":69349,\"start\":69348},{\"end\":69357,\"start\":69356},{\"end\":69359,\"start\":69358},{\"end\":69370,\"start\":69369},{\"end\":69372,\"start\":69371},{\"end\":69381,\"start\":69380},{\"end\":69393,\"start\":69392},{\"end\":69395,\"start\":69394},{\"end\":69406,\"start\":69405},{\"end\":69408,\"start\":69407},{\"end\":69417,\"start\":69416},{\"end\":69419,\"start\":69418},{\"end\":69430,\"start\":69429},{\"end\":69432,\"start\":69431},{\"end\":69443,\"start\":69442},{\"end\":69445,\"start\":69444},{\"end\":69456,\"start\":69455},{\"end\":69458,\"start\":69457},{\"end\":69725,\"start\":69724},{\"end\":69727,\"start\":69726},{\"end\":69736,\"start\":69735},{\"end\":69738,\"start\":69737},{\"end\":69748,\"start\":69747},{\"end\":69750,\"start\":69749},{\"end\":69758,\"start\":69757},{\"end\":69760,\"start\":69759},{\"end\":69772,\"start\":69771},{\"end\":69774,\"start\":69773},{\"end\":69785,\"start\":69784},{\"end\":69787,\"start\":69786},{\"end\":70014,\"start\":70013},{\"end\":70016,\"start\":70015},{\"end\":70040,\"start\":70025},{\"end\":70054,\"start\":70053},{\"end\":70058,\"start\":70057},{\"end\":70071,\"start\":70070},{\"end\":70073,\"start\":70072},{\"end\":70295,\"start\":70294},{\"end\":70309,\"start\":70308},{\"end\":70321,\"start\":70320},{\"end\":70323,\"start\":70322},{\"end\":70332,\"start\":70331},{\"end\":70334,\"start\":70333},{\"end\":70462,\"start\":70461},{\"end\":70472,\"start\":70471},{\"end\":70619,\"start\":70618},{\"end\":70621,\"start\":70620},{\"end\":70632,\"start\":70631},{\"end\":70634,\"start\":70633},{\"end\":70704,\"start\":70703},{\"end\":70713,\"start\":70712},{\"end\":70723,\"start\":70722},{\"end\":70870,\"start\":70869},{\"end\":70885,\"start\":70876},{\"end\":70995,\"start\":70994},{\"end\":71007,\"start\":71006},{\"end\":71009,\"start\":71008},{\"end\":71023,\"start\":71022},{\"end\":71025,\"start\":71024},{\"end\":71034,\"start\":71033},{\"end\":71036,\"start\":71035},{\"end\":71049,\"start\":71048},{\"end\":71051,\"start\":71050},{\"end\":71061,\"start\":71060},{\"end\":71063,\"start\":71062},{\"end\":71074,\"start\":71073},{\"end\":71238,\"start\":71237},{\"end\":71245,\"start\":71244},{\"end\":71257,\"start\":71256},{\"end\":71400,\"start\":71399},{\"end\":71412,\"start\":71411},{\"end\":71426,\"start\":71425},{\"end\":71436,\"start\":71435},{\"end\":71448,\"start\":71444},{\"end\":71461,\"start\":71457},{\"end\":71712,\"start\":71711},{\"end\":71722,\"start\":71721},{\"end\":71724,\"start\":71723},{\"end\":71876,\"start\":71875},{\"end\":71878,\"start\":71877},{\"end\":71889,\"start\":71888},{\"end\":71900,\"start\":71899},{\"end\":71909,\"start\":71908},{\"end\":71911,\"start\":71910},{\"end\":71921,\"start\":71920},{\"end\":71923,\"start\":71922},{\"end\":72143,\"start\":72142},{\"end\":72145,\"start\":72144},{\"end\":72156,\"start\":72155},{\"end\":72158,\"start\":72157},{\"end\":72426,\"start\":72425},{\"end\":72437,\"start\":72436},{\"end\":72439,\"start\":72438},{\"end\":72448,\"start\":72447},{\"end\":72458,\"start\":72457},{\"end\":72474,\"start\":72473},{\"end\":72476,\"start\":72475},{\"end\":72697,\"start\":72696},{\"end\":72707,\"start\":72706},{\"end\":72721,\"start\":72720},{\"end\":72723,\"start\":72722},{\"end\":72853,\"start\":72852},{\"end\":72861,\"start\":72860},{\"end\":72863,\"start\":72862},{\"end\":72876,\"start\":72875},{\"end\":73045,\"start\":73044},{\"end\":73059,\"start\":73058},{\"end\":73074,\"start\":73073},{\"end\":73085,\"start\":73084},{\"end\":73093,\"start\":73092},{\"end\":73104,\"start\":73103},{\"end\":73227,\"start\":73226},{\"end\":73243,\"start\":73234},{\"end\":73431,\"start\":73430},{\"end\":73433,\"start\":73432},{\"end\":73444,\"start\":73443},{\"end\":73463,\"start\":73462},{\"end\":73465,\"start\":73464},{\"end\":73476,\"start\":73475},{\"end\":73478,\"start\":73477},{\"end\":73637,\"start\":73636},{\"end\":73639,\"start\":73638},{\"end\":73650,\"start\":73649},{\"end\":73652,\"start\":73651},{\"end\":73664,\"start\":73663},{\"end\":73666,\"start\":73665},{\"end\":73678,\"start\":73677},{\"end\":73680,\"start\":73679},{\"end\":73779,\"start\":73778},{\"end\":73781,\"start\":73780},{\"end\":73791,\"start\":73790},{\"end\":73793,\"start\":73792},{\"end\":73802,\"start\":73801},{\"end\":73804,\"start\":73803},{\"end\":73814,\"start\":73813},{\"end\":73816,\"start\":73815},{\"end\":73826,\"start\":73825},{\"end\":73828,\"start\":73827},{\"end\":74002,\"start\":74001},{\"end\":74020,\"start\":74011},{\"end\":74060,\"start\":74059},{\"end\":74072,\"start\":74071},{\"end\":74159,\"start\":74158},{\"end\":74170,\"start\":74169},{\"end\":74180,\"start\":74179},{\"end\":74187,\"start\":74186},{\"end\":74197,\"start\":74196},{\"end\":74351,\"start\":74350},{\"end\":74361,\"start\":74360},{\"end\":74436,\"start\":74435},{\"end\":74438,\"start\":74437},{\"end\":74458,\"start\":74449},{\"end\":74608,\"start\":74607},{\"end\":74621,\"start\":74620},{\"end\":74623,\"start\":74622},{\"end\":74635,\"start\":74634},{\"end\":74648,\"start\":74647},{\"end\":74839,\"start\":74838},{\"end\":74850,\"start\":74849},{\"end\":74863,\"start\":74862},{\"end\":74872,\"start\":74871},{\"end\":74882,\"start\":74881},{\"end\":75153,\"start\":75152},{\"end\":75177,\"start\":75168},{\"end\":75274,\"start\":75273},{\"end\":75276,\"start\":75275},{\"end\":75284,\"start\":75283},{\"end\":75465,\"start\":75464},{\"end\":75475,\"start\":75474},{\"end\":75761,\"start\":75760},{\"end\":75776,\"start\":75775},{\"end\":75962,\"start\":75961},{\"end\":75964,\"start\":75963},{\"end\":75972,\"start\":75971},{\"end\":75974,\"start\":75973},{\"end\":75984,\"start\":75983},{\"end\":76151,\"start\":76150},{\"end\":76162,\"start\":76161},{\"end\":76172,\"start\":76171},{\"end\":76174,\"start\":76173},{\"end\":76232,\"start\":76231},{\"end\":76239,\"start\":76238},{\"end\":76247,\"start\":76246},{\"end\":76249,\"start\":76248},{\"end\":76256,\"start\":76255},{\"end\":76258,\"start\":76257},{\"end\":76443,\"start\":76442},{\"end\":76452,\"start\":76451}]", "bib_author_last_name": "[{\"end\":65202,\"start\":65197},{\"end\":65364,\"start\":65358},{\"end\":65377,\"start\":65370},{\"end\":65390,\"start\":65383},{\"end\":65401,\"start\":65396},{\"end\":65412,\"start\":65407},{\"end\":65555,\"start\":65549},{\"end\":65564,\"start\":65559},{\"end\":65725,\"start\":65718},{\"end\":65737,\"start\":65731},{\"end\":65748,\"start\":65743},{\"end\":65932,\"start\":65926},{\"end\":65939,\"start\":65936},{\"end\":65950,\"start\":65943},{\"end\":66152,\"start\":66148},{\"end\":66160,\"start\":66156},{\"end\":66169,\"start\":66166},{\"end\":66183,\"start\":66175},{\"end\":66306,\"start\":66299},{\"end\":66511,\"start\":66504},{\"end\":66518,\"start\":66515},{\"end\":66529,\"start\":66522},{\"end\":66828,\"start\":66820},{\"end\":66839,\"start\":66834},{\"end\":66983,\"start\":66976},{\"end\":66998,\"start\":66989},{\"end\":67011,\"start\":67004},{\"end\":67022,\"start\":67017},{\"end\":67032,\"start\":67024},{\"end\":67280,\"start\":67274},{\"end\":67291,\"start\":67284},{\"end\":67302,\"start\":67297},{\"end\":67319,\"start\":67308},{\"end\":67562,\"start\":67555},{\"end\":67575,\"start\":67568},{\"end\":67584,\"start\":67581},{\"end\":67765,\"start\":67753},{\"end\":67776,\"start\":67769},{\"end\":67942,\"start\":67935},{\"end\":67963,\"start\":67946},{\"end\":67979,\"start\":67971},{\"end\":67990,\"start\":67985},{\"end\":68074,\"start\":68064},{\"end\":68084,\"start\":68078},{\"end\":68097,\"start\":68088},{\"end\":68212,\"start\":68209},{\"end\":68222,\"start\":68219},{\"end\":68323,\"start\":68320},{\"end\":68332,\"start\":68329},{\"end\":68341,\"start\":68338},{\"end\":68453,\"start\":68450},{\"end\":68464,\"start\":68459},{\"end\":68473,\"start\":68468},{\"end\":68481,\"start\":68477},{\"end\":68584,\"start\":68582},{\"end\":68593,\"start\":68588},{\"end\":68600,\"start\":68597},{\"end\":68607,\"start\":68604},{\"end\":68856,\"start\":68850},{\"end\":69083,\"start\":69078},{\"end\":69090,\"start\":69087},{\"end\":69097,\"start\":69094},{\"end\":69168,\"start\":69162},{\"end\":69174,\"start\":69172},{\"end\":69344,\"start\":69339},{\"end\":69354,\"start\":69350},{\"end\":69367,\"start\":69360},{\"end\":69378,\"start\":69373},{\"end\":69390,\"start\":69382},{\"end\":69403,\"start\":69396},{\"end\":69414,\"start\":69409},{\"end\":69427,\"start\":69420},{\"end\":69440,\"start\":69433},{\"end\":69453,\"start\":69446},{\"end\":69466,\"start\":69459},{\"end\":69733,\"start\":69728},{\"end\":69745,\"start\":69739},{\"end\":69755,\"start\":69751},{\"end\":69769,\"start\":69761},{\"end\":69782,\"start\":69775},{\"end\":69795,\"start\":69788},{\"end\":70023,\"start\":70017},{\"end\":70051,\"start\":70041},{\"end\":70068,\"start\":70059},{\"end\":70080,\"start\":70074},{\"end\":70306,\"start\":70296},{\"end\":70318,\"start\":70310},{\"end\":70329,\"start\":70324},{\"end\":70469,\"start\":70463},{\"end\":70478,\"start\":70473},{\"end\":70629,\"start\":70622},{\"end\":70643,\"start\":70635},{\"end\":70710,\"start\":70705},{\"end\":70720,\"start\":70714},{\"end\":70730,\"start\":70724},{\"end\":70874,\"start\":70871},{\"end\":71004,\"start\":70996},{\"end\":71020,\"start\":71010},{\"end\":71031,\"start\":71026},{\"end\":71046,\"start\":71037},{\"end\":71058,\"start\":71052},{\"end\":71071,\"start\":71064},{\"end\":71080,\"start\":71075},{\"end\":71242,\"start\":71239},{\"end\":71254,\"start\":71246},{\"end\":71265,\"start\":71258},{\"end\":71409,\"start\":71401},{\"end\":71423,\"start\":71413},{\"end\":71433,\"start\":71427},{\"end\":71442,\"start\":71437},{\"end\":71455,\"start\":71449},{\"end\":71467,\"start\":71462},{\"end\":71475,\"start\":71469},{\"end\":71719,\"start\":71713},{\"end\":71728,\"start\":71725},{\"end\":71886,\"start\":71879},{\"end\":71897,\"start\":71890},{\"end\":71906,\"start\":71901},{\"end\":71918,\"start\":71912},{\"end\":71935,\"start\":71924},{\"end\":72153,\"start\":72146},{\"end\":72165,\"start\":72159},{\"end\":72434,\"start\":72427},{\"end\":72445,\"start\":72440},{\"end\":72455,\"start\":72449},{\"end\":72471,\"start\":72459},{\"end\":72482,\"start\":72477},{\"end\":72704,\"start\":72698},{\"end\":72718,\"start\":72708},{\"end\":72735,\"start\":72724},{\"end\":72858,\"start\":72854},{\"end\":72873,\"start\":72864},{\"end\":72884,\"start\":72877},{\"end\":73056,\"start\":73046},{\"end\":73071,\"start\":73060},{\"end\":73082,\"start\":73075},{\"end\":73090,\"start\":73086},{\"end\":73101,\"start\":73094},{\"end\":73115,\"start\":73105},{\"end\":73232,\"start\":73228},{\"end\":73441,\"start\":73434},{\"end\":73460,\"start\":73445},{\"end\":73473,\"start\":73466},{\"end\":73482,\"start\":73479},{\"end\":73647,\"start\":73640},{\"end\":73661,\"start\":73653},{\"end\":73675,\"start\":73667},{\"end\":73687,\"start\":73681},{\"end\":73788,\"start\":73782},{\"end\":73799,\"start\":73794},{\"end\":73811,\"start\":73805},{\"end\":73823,\"start\":73817},{\"end\":73834,\"start\":73829},{\"end\":74009,\"start\":74003},{\"end\":74069,\"start\":74061},{\"end\":74082,\"start\":74073},{\"end\":74167,\"start\":74160},{\"end\":74177,\"start\":74171},{\"end\":74184,\"start\":74181},{\"end\":74194,\"start\":74188},{\"end\":74208,\"start\":74198},{\"end\":74358,\"start\":74352},{\"end\":74364,\"start\":74362},{\"end\":74447,\"start\":74439},{\"end\":74618,\"start\":74609},{\"end\":74632,\"start\":74624},{\"end\":74645,\"start\":74636},{\"end\":74656,\"start\":74649},{\"end\":74847,\"start\":74840},{\"end\":74860,\"start\":74851},{\"end\":74869,\"start\":74864},{\"end\":74879,\"start\":74873},{\"end\":74888,\"start\":74883},{\"end\":75166,\"start\":75154},{\"end\":75281,\"start\":75277},{\"end\":75291,\"start\":75285},{\"end\":75472,\"start\":75466},{\"end\":75483,\"start\":75476},{\"end\":75773,\"start\":75762},{\"end\":75781,\"start\":75777},{\"end\":75969,\"start\":75965},{\"end\":75981,\"start\":75975},{\"end\":75992,\"start\":75985},{\"end\":76159,\"start\":76152},{\"end\":76169,\"start\":76163},{\"end\":76182,\"start\":76175},{\"end\":76236,\"start\":76233},{\"end\":76244,\"start\":76240},{\"end\":76253,\"start\":76250},{\"end\":76264,\"start\":76259},{\"end\":76449,\"start\":76444},{\"end\":76457,\"start\":76453}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":65239,\"start\":65158},{\"attributes\":{\"id\":\"b1\"},\"end\":65461,\"start\":65241},{\"attributes\":{\"id\":\"b2\"},\"end\":65619,\"start\":65463},{\"attributes\":{\"id\":\"b3\"},\"end\":65798,\"start\":65621},{\"attributes\":{\"id\":\"b4\"},\"end\":66042,\"start\":65800},{\"attributes\":{\"id\":\"b5\"},\"end\":66232,\"start\":66044},{\"attributes\":{\"id\":\"b6\"},\"end\":66412,\"start\":66234},{\"attributes\":{\"id\":\"b7\"},\"end\":66704,\"start\":66414},{\"attributes\":{\"id\":\"b8\"},\"end\":66893,\"start\":66706},{\"attributes\":{\"id\":\"b9\"},\"end\":67161,\"start\":66895},{\"attributes\":{\"id\":\"b10\"},\"end\":67414,\"start\":67163},{\"attributes\":{\"id\":\"b11\"},\"end\":67629,\"start\":67416},{\"attributes\":{\"id\":\"b12\"},\"end\":67830,\"start\":67631},{\"attributes\":{\"id\":\"b13\"},\"end\":68060,\"start\":67832},{\"attributes\":{\"id\":\"b14\"},\"end\":68130,\"start\":68062},{\"attributes\":{\"id\":\"b15\"},\"end\":68270,\"start\":68132},{\"attributes\":{\"id\":\"b16\"},\"end\":68383,\"start\":68272},{\"attributes\":{\"id\":\"b17\"},\"end\":68532,\"start\":68385},{\"attributes\":{\"id\":\"b18\"},\"end\":68780,\"start\":68534},{\"attributes\":{\"id\":\"b19\"},\"end\":68926,\"start\":68782},{\"attributes\":{\"id\":\"b20\"},\"end\":69156,\"start\":68928},{\"attributes\":{\"id\":\"b21\"},\"end\":69224,\"start\":69158},{\"attributes\":{\"id\":\"b22\"},\"end\":69633,\"start\":69226},{\"attributes\":{\"id\":\"b23\"},\"end\":69932,\"start\":69635},{\"attributes\":{\"id\":\"b24\"},\"end\":70218,\"start\":69934},{\"attributes\":{\"id\":\"b25\"},\"end\":70384,\"start\":70220},{\"attributes\":{\"id\":\"b26\"},\"end\":70528,\"start\":70386},{\"attributes\":{\"id\":\"b27\"},\"end\":70686,\"start\":70530},{\"attributes\":{\"id\":\"b28\"},\"end\":70766,\"start\":70688},{\"attributes\":{\"id\":\"b29\"},\"end\":70892,\"start\":70768},{\"attributes\":{\"id\":\"b30\"},\"end\":71138,\"start\":70894},{\"attributes\":{\"id\":\"b31\"},\"end\":71319,\"start\":71140},{\"attributes\":{\"id\":\"b32\"},\"end\":71596,\"start\":71321},{\"attributes\":{\"id\":\"b33\"},\"end\":71787,\"start\":71598},{\"attributes\":{\"id\":\"b34\"},\"end\":71977,\"start\":71789},{\"attributes\":{\"id\":\"b35\"},\"end\":72342,\"start\":71979},{\"attributes\":{\"id\":\"b36\"},\"end\":72541,\"start\":72344},{\"attributes\":{\"id\":\"b37\"},\"end\":72786,\"start\":72543},{\"attributes\":{\"id\":\"b38\"},\"end\":72964,\"start\":72788},{\"attributes\":{\"id\":\"b39\"},\"end\":73157,\"start\":72966},{\"attributes\":{\"id\":\"b40\"},\"end\":73302,\"start\":73159},{\"attributes\":{\"id\":\"b41\"},\"end\":73528,\"start\":73304},{\"attributes\":{\"id\":\"b42\"},\"end\":73931,\"start\":73530},{\"attributes\":{\"id\":\"b43\"},\"end\":74057,\"start\":73933},{\"attributes\":{\"id\":\"b44\"},\"end\":74156,\"start\":74059},{\"attributes\":{\"id\":\"b45\"},\"end\":74258,\"start\":74158},{\"attributes\":{\"id\":\"b46\"},\"end\":74433,\"start\":74260},{\"attributes\":{\"id\":\"b47\"},\"end\":74527,\"start\":74435},{\"attributes\":{\"id\":\"b48\"},\"end\":74777,\"start\":74529},{\"attributes\":{\"id\":\"b49\"},\"end\":75062,\"start\":74779},{\"attributes\":{\"id\":\"b50\"},\"end\":75215,\"start\":75064},{\"attributes\":{\"id\":\"b51\"},\"end\":75341,\"start\":75217},{\"attributes\":{\"id\":\"b52\"},\"end\":75661,\"start\":75343},{\"attributes\":{\"id\":\"b53\"},\"end\":75852,\"start\":75663},{\"attributes\":{\"id\":\"b54\"},\"end\":76047,\"start\":75854},{\"attributes\":{\"id\":\"b55\"},\"end\":76229,\"start\":76049},{\"attributes\":{\"id\":\"b56\"},\"end\":76404,\"start\":76231},{\"attributes\":{\"id\":\"b57\"},\"end\":76498,\"start\":76406}]", "bib_title": "[{\"end\":65193,\"start\":65158},{\"end\":65352,\"start\":65241},{\"end\":65545,\"start\":65463},{\"end\":65712,\"start\":65621},{\"end\":65920,\"start\":65800},{\"end\":66142,\"start\":66044},{\"end\":66295,\"start\":66234},{\"end\":66500,\"start\":66414},{\"end\":66816,\"start\":66706},{\"end\":66972,\"start\":66895},{\"end\":67268,\"start\":67163},{\"end\":67551,\"start\":67416},{\"end\":67749,\"start\":67631},{\"end\":67931,\"start\":67832},{\"end\":68205,\"start\":68132},{\"end\":68314,\"start\":68272},{\"end\":68446,\"start\":68385},{\"end\":68578,\"start\":68534},{\"end\":68846,\"start\":68782},{\"end\":69074,\"start\":68928},{\"end\":69333,\"start\":69226},{\"end\":69722,\"start\":69635},{\"end\":70011,\"start\":69934},{\"end\":70292,\"start\":70220},{\"end\":70459,\"start\":70386},{\"end\":70616,\"start\":70530},{\"end\":70701,\"start\":70688},{\"end\":70992,\"start\":70894},{\"end\":71235,\"start\":71140},{\"end\":71397,\"start\":71321},{\"end\":71709,\"start\":71598},{\"end\":71873,\"start\":71789},{\"end\":72140,\"start\":71979},{\"end\":72423,\"start\":72344},{\"end\":72694,\"start\":72543},{\"end\":72850,\"start\":72788},{\"end\":73042,\"start\":72966},{\"end\":73224,\"start\":73159},{\"end\":73428,\"start\":73304},{\"end\":73634,\"start\":73530},{\"end\":73999,\"start\":73933},{\"end\":74348,\"start\":74260},{\"end\":74605,\"start\":74529},{\"end\":74836,\"start\":74779},{\"end\":75271,\"start\":75217},{\"end\":75462,\"start\":75343},{\"end\":75758,\"start\":75663},{\"end\":75959,\"start\":75854},{\"end\":76148,\"start\":76049},{\"end\":76440,\"start\":76406}]", "bib_author": "[{\"end\":65204,\"start\":65195},{\"end\":65216,\"start\":65204},{\"end\":65366,\"start\":65354},{\"end\":65379,\"start\":65366},{\"end\":65392,\"start\":65379},{\"end\":65403,\"start\":65392},{\"end\":65414,\"start\":65403},{\"end\":65557,\"start\":65547},{\"end\":65566,\"start\":65557},{\"end\":65727,\"start\":65714},{\"end\":65739,\"start\":65727},{\"end\":65750,\"start\":65739},{\"end\":65934,\"start\":65922},{\"end\":65941,\"start\":65934},{\"end\":65952,\"start\":65941},{\"end\":66154,\"start\":66144},{\"end\":66162,\"start\":66154},{\"end\":66171,\"start\":66162},{\"end\":66185,\"start\":66171},{\"end\":66308,\"start\":66297},{\"end\":66513,\"start\":66502},{\"end\":66520,\"start\":66513},{\"end\":66531,\"start\":66520},{\"end\":66830,\"start\":66818},{\"end\":66841,\"start\":66830},{\"end\":66985,\"start\":66974},{\"end\":67000,\"start\":66985},{\"end\":67013,\"start\":67000},{\"end\":67024,\"start\":67013},{\"end\":67034,\"start\":67024},{\"end\":67282,\"start\":67270},{\"end\":67293,\"start\":67282},{\"end\":67304,\"start\":67293},{\"end\":67321,\"start\":67304},{\"end\":67564,\"start\":67553},{\"end\":67577,\"start\":67564},{\"end\":67586,\"start\":67577},{\"end\":67767,\"start\":67751},{\"end\":67778,\"start\":67767},{\"end\":67944,\"start\":67933},{\"end\":67965,\"start\":67944},{\"end\":67969,\"start\":67965},{\"end\":67981,\"start\":67969},{\"end\":67992,\"start\":67981},{\"end\":68076,\"start\":68062},{\"end\":68086,\"start\":68076},{\"end\":68099,\"start\":68086},{\"end\":68214,\"start\":68207},{\"end\":68224,\"start\":68214},{\"end\":68325,\"start\":68316},{\"end\":68334,\"start\":68325},{\"end\":68343,\"start\":68334},{\"end\":68455,\"start\":68448},{\"end\":68466,\"start\":68455},{\"end\":68475,\"start\":68466},{\"end\":68483,\"start\":68475},{\"end\":68586,\"start\":68580},{\"end\":68595,\"start\":68586},{\"end\":68602,\"start\":68595},{\"end\":68609,\"start\":68602},{\"end\":68858,\"start\":68848},{\"end\":68870,\"start\":68858},{\"end\":69085,\"start\":69076},{\"end\":69092,\"start\":69085},{\"end\":69099,\"start\":69092},{\"end\":69170,\"start\":69158},{\"end\":69176,\"start\":69170},{\"end\":69346,\"start\":69335},{\"end\":69356,\"start\":69346},{\"end\":69369,\"start\":69356},{\"end\":69380,\"start\":69369},{\"end\":69392,\"start\":69380},{\"end\":69405,\"start\":69392},{\"end\":69416,\"start\":69405},{\"end\":69429,\"start\":69416},{\"end\":69442,\"start\":69429},{\"end\":69455,\"start\":69442},{\"end\":69468,\"start\":69455},{\"end\":69735,\"start\":69724},{\"end\":69747,\"start\":69735},{\"end\":69757,\"start\":69747},{\"end\":69771,\"start\":69757},{\"end\":69784,\"start\":69771},{\"end\":69797,\"start\":69784},{\"end\":70025,\"start\":70013},{\"end\":70053,\"start\":70025},{\"end\":70057,\"start\":70053},{\"end\":70070,\"start\":70057},{\"end\":70082,\"start\":70070},{\"end\":70308,\"start\":70294},{\"end\":70320,\"start\":70308},{\"end\":70331,\"start\":70320},{\"end\":70337,\"start\":70331},{\"end\":70471,\"start\":70461},{\"end\":70480,\"start\":70471},{\"end\":70631,\"start\":70618},{\"end\":70645,\"start\":70631},{\"end\":70712,\"start\":70703},{\"end\":70722,\"start\":70712},{\"end\":70732,\"start\":70722},{\"end\":70876,\"start\":70869},{\"end\":70888,\"start\":70876},{\"end\":71006,\"start\":70994},{\"end\":71022,\"start\":71006},{\"end\":71033,\"start\":71022},{\"end\":71048,\"start\":71033},{\"end\":71060,\"start\":71048},{\"end\":71073,\"start\":71060},{\"end\":71082,\"start\":71073},{\"end\":71244,\"start\":71237},{\"end\":71256,\"start\":71244},{\"end\":71267,\"start\":71256},{\"end\":71411,\"start\":71399},{\"end\":71425,\"start\":71411},{\"end\":71435,\"start\":71425},{\"end\":71444,\"start\":71435},{\"end\":71457,\"start\":71444},{\"end\":71469,\"start\":71457},{\"end\":71477,\"start\":71469},{\"end\":71721,\"start\":71711},{\"end\":71730,\"start\":71721},{\"end\":71888,\"start\":71875},{\"end\":71899,\"start\":71888},{\"end\":71908,\"start\":71899},{\"end\":71920,\"start\":71908},{\"end\":71937,\"start\":71920},{\"end\":72155,\"start\":72142},{\"end\":72167,\"start\":72155},{\"end\":72436,\"start\":72425},{\"end\":72447,\"start\":72436},{\"end\":72457,\"start\":72447},{\"end\":72473,\"start\":72457},{\"end\":72484,\"start\":72473},{\"end\":72706,\"start\":72696},{\"end\":72720,\"start\":72706},{\"end\":72737,\"start\":72720},{\"end\":72860,\"start\":72852},{\"end\":72875,\"start\":72860},{\"end\":72886,\"start\":72875},{\"end\":73058,\"start\":73044},{\"end\":73073,\"start\":73058},{\"end\":73084,\"start\":73073},{\"end\":73092,\"start\":73084},{\"end\":73103,\"start\":73092},{\"end\":73117,\"start\":73103},{\"end\":73234,\"start\":73226},{\"end\":73246,\"start\":73234},{\"end\":73443,\"start\":73430},{\"end\":73462,\"start\":73443},{\"end\":73475,\"start\":73462},{\"end\":73484,\"start\":73475},{\"end\":73649,\"start\":73636},{\"end\":73663,\"start\":73649},{\"end\":73677,\"start\":73663},{\"end\":73689,\"start\":73677},{\"end\":74011,\"start\":74001},{\"end\":74023,\"start\":74011},{\"end\":74071,\"start\":74059},{\"end\":74084,\"start\":74071},{\"end\":74169,\"start\":74158},{\"end\":74179,\"start\":74169},{\"end\":74186,\"start\":74179},{\"end\":74196,\"start\":74186},{\"end\":74210,\"start\":74196},{\"end\":74360,\"start\":74350},{\"end\":74366,\"start\":74360},{\"end\":74449,\"start\":74435},{\"end\":74461,\"start\":74449},{\"end\":74620,\"start\":74607},{\"end\":74634,\"start\":74620},{\"end\":74647,\"start\":74634},{\"end\":74658,\"start\":74647},{\"end\":74849,\"start\":74838},{\"end\":74862,\"start\":74849},{\"end\":74871,\"start\":74862},{\"end\":74881,\"start\":74871},{\"end\":74890,\"start\":74881},{\"end\":75168,\"start\":75152},{\"end\":75180,\"start\":75168},{\"end\":75283,\"start\":75273},{\"end\":75293,\"start\":75283},{\"end\":75474,\"start\":75464},{\"end\":75485,\"start\":75474},{\"end\":75775,\"start\":75760},{\"end\":75783,\"start\":75775},{\"end\":75971,\"start\":75961},{\"end\":75983,\"start\":75971},{\"end\":75994,\"start\":75983},{\"end\":76161,\"start\":76150},{\"end\":76171,\"start\":76161},{\"end\":76184,\"start\":76171},{\"end\":76238,\"start\":76231},{\"end\":76246,\"start\":76238},{\"end\":76255,\"start\":76246},{\"end\":76266,\"start\":76255},{\"end\":76451,\"start\":76442},{\"end\":76459,\"start\":76451}]", "bib_venue": "[{\"end\":65235,\"start\":65216},{\"end\":65453,\"start\":65437},{\"end\":65611,\"start\":65586},{\"end\":65790,\"start\":65774},{\"end\":65991,\"start\":65978},{\"end\":66224,\"start\":66208},{\"end\":66382,\"start\":66329},{\"end\":66620,\"start\":66554},{\"end\":66885,\"start\":66860},{\"end\":67082,\"start\":67059},{\"end\":67378,\"start\":67353},{\"end\":67625,\"start\":67609},{\"end\":67825,\"start\":67802},{\"end\":68032,\"start\":68016},{\"end\":68112,\"start\":68099},{\"end\":68262,\"start\":68244},{\"end\":68374,\"start\":68368},{\"end\":68528,\"start\":68503},{\"end\":68695,\"start\":68629},{\"end\":68918,\"start\":68894},{\"end\":69148,\"start\":69123},{\"end\":69218,\"start\":69176},{\"end\":69516,\"start\":69491},{\"end\":69889,\"start\":69819},{\"end\":70125,\"start\":70114},{\"end\":70376,\"start\":70360},{\"end\":70520,\"start\":70504},{\"end\":70677,\"start\":70669},{\"end\":70757,\"start\":70751},{\"end\":70867,\"start\":70768},{\"end\":71129,\"start\":71106},{\"end\":71305,\"start\":71287},{\"end\":71565,\"start\":71502},{\"end\":71779,\"start\":71754},{\"end\":71969,\"start\":71953},{\"end\":72206,\"start\":72190},{\"end\":72533,\"start\":72508},{\"end\":72777,\"start\":72762},{\"end\":72935,\"start\":72909},{\"end\":73148,\"start\":73142},{\"end\":73294,\"start\":73271},{\"end\":73524,\"start\":73508},{\"end\":73776,\"start\":73727},{\"end\":74048,\"start\":74042},{\"end\":74150,\"start\":74084},{\"end\":74252,\"start\":74210},{\"end\":74418,\"start\":74393},{\"end\":74521,\"start\":74461},{\"end\":74718,\"start\":74685},{\"end\":74977,\"start\":74911},{\"end\":75150,\"start\":75064},{\"end\":75333,\"start\":75317},{\"end\":75530,\"start\":75507},{\"end\":75843,\"start\":75830},{\"end\":76039,\"start\":76014},{\"end\":76220,\"start\":76207},{\"end\":76377,\"start\":76293},{\"end\":76491,\"start\":76477},{\"end\":66402,\"start\":66384},{\"end\":66700,\"start\":66622},{\"end\":68776,\"start\":68697},{\"end\":72957,\"start\":72937},{\"end\":75058,\"start\":74979},{\"end\":76400,\"start\":76379}]"}}}, "year": 2023, "month": 12, "day": 17}