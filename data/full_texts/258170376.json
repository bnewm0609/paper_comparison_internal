{"id": 258170376, "updated": "2023-10-05 01:51:25.164", "metadata": {"title": "DCFace: Synthetic Face Generation with Dual Condition Diffusion Model", "authors": "[{\"first\":\"Minchul\",\"last\":\"Kim\",\"middle\":[]},{\"first\":\"Feng\",\"last\":\"Liu\",\"middle\":[]},{\"first\":\"Anil\",\"last\":\"Jain\",\"middle\":[]},{\"first\":\"Xiaoming\",\"last\":\"Liu\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2023, "month": null, "day": null}, "abstract": "Generating synthetic datasets for training face recognition models is challenging because dataset generation entails more than creating high fidelity images. It involves generating multiple images of same subjects under different factors (\\textit{e.g.}, variations in pose, illumination, expression, aging and occlusion) which follows the real image conditional distribution. Previous works have studied the generation of synthetic datasets using GAN or 3D models. In this work, we approach the problem from the aspect of combining subject appearance (ID) and external factor (style) conditions. These two conditions provide a direct way to control the inter-class and intra-class variations. To this end, we propose a Dual Condition Face Generator (DCFace) based on a diffusion model. Our novel Patch-wise style extractor and Time-step dependent ID loss enables DCFace to consistently produce face images of the same subject under different styles with precise control. Face recognition models trained on synthetic images from the proposed DCFace provide higher verification accuracies compared to previous works by $6.11\\%$ on average in $4$ out of $5$ test datasets, LFW, CFP-FP, CPLFW, AgeDB and CALFW. Code is available at https://github.com/mk-minchul/dcface", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2304.07060", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/cvpr/Kim00023", "doi": "10.1109/cvpr52729.2023.01223"}}, "content": {"source": {"pdf_hash": "6a6c0736a4e9e850db15a30ea8ff180c2080ba4f", "pdf_src": "Arxiv", "pdf_uri": "[\"https://export.arxiv.org/pdf/2304.07060v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "1e51272e38281b7dde010b8e331d3505e126d793", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/6a6c0736a4e9e850db15a30ea8ff180c2080ba4f.txt", "contents": "\nDCFace: Synthetic Face Generation with Dual Condition Diffusion Model\n\n\nMinchul Kim \nMichigan State University East Lansing\n48824MI\n\nFeng Liu liufeng6@msu.edu \nMichigan State University East Lansing\n48824MI\n\nAnil Jain jain@msu.edu \nMichigan State University East Lansing\n48824MI\n\nXiaoming Liu \nMichigan State University East Lansing\n48824MI\n\nDCFace: Synthetic Face Generation with Dual Condition Diffusion Model\n\nGenerating synthetic datasets for training face recognition models is challenging because dataset generation entails more than creating high fidelity images. It involves generating multiple images of same subjects under different factors (e.g., variations in pose, illumination, expression, aging and occlusion) which follows the real image conditional distribution. Previous works have studied the generation of synthetic datasets using GAN or 3D models. In this work, we approach the problem from the aspect of combining subject appearance (ID) and external factor (style) conditions. These two conditions provide a direct way to control the inter-class and intra-class variations. To this end, we propose a Dual Condition Face Generator (DCFace) based on a diffusion model. Our novel Patch-wise style extractor and Time-step dependent ID loss enables DCFace to consistently produce face images of the same subject under different styles with precise control. Face recognition models trained on synthetic images from the proposed DCFace provide higher verification accuracies compared to previous works by 6.11% on average in 4 out of 5 test datasets, LFW, CFP-FP, CPLFW, AgeDB and CALFW. Code Link GNorm SiLU Conv GNorm + Scaling feature with + Figure 2. Illustration of DDPM U-Net with conditioning operations highlighted. The red arrow indicates how the dual conditions are injected into the intermediate features of U-Net using cross-attention layers. For clarity, up-sampling stages are not illustrated, but they are symmetric to the down-sampling stages. On the right is a detailed illustration of the Residual Block with timestep and ID condition. t emb and f id from E id are added together and used to scale the output of the Residual Block.\n\nIntroduction\n\nWhat does it take to create a good training dataset for visual recognition? An ideal training dataset for recognition tasks would have 1) large inter-class variation, 2) large intra-class variation and 3) small label noise. In the context of face recognition (FR), it means, the dataset has a large number of unique subjects, large intra-subject variations, and reliable subject labels. For instance, large-scale face datasets such as WebFace4M [89] contain over 1M subjects and large number of images/subject. Both the number of subjects and the number of images per subject are important for training FR models [14,39]. Also, datasets amassed by crawling the web are not free from label noise [9,89].\n\nIn various domains, synthetic datasets are traditionally used to help generalize deep models when only limited real datasets could be collected [17,28,72,90] or when bias exists in the real dataset [42,73]. Lately, more attention has been drawn to training with only synthetic datasets in the face domain, as synthetic data can avoid leaking the privacy of real individuals. This is important as real face datasets have been under scrutiny for their lack of informed consent, as web-crawling is the primary means of large-scale data collection [22,29,89]. Also, synthetic training datasets can remedy some long-standing issues in real datasets, e.g. the long tail distribution, demographic bias, etc.\n\nWhen it comes to generating synthetic training datasets, the following questions should be raised. (i) How many novel subjects can be synthesized (ii) How well can we mimic the distribution of real images in the target domain and (iii) How well can we consistently generate multiple images of the same subjects? We start with the hypothesis that face dataset generation can be formulated as a problem that maximizes these criteria together.\n\nPrevious efforts in generating synthetic face datasets touch on one of the three aspects but do not consider all of them together [5,57]. SynFace [57] generates high-fidelity face images based on DiscoFaceGAN [15], coming close to real images in terms of FID metric [24]. However, we were\n\n\nSampling Stage 2. Mixing Stage\n\n\nIdentity Generator\n\nA B C Labeled Dataset Figure 2. Two stage dataset generation paradigm. In the sampling stage, 1) G id generates a high-quality face image X id that defines how a person looks and 2) the style bank selects a style image Xsty that defines the overall style of the final image. The mixing stage generates image with identity from X id and style from Xsty. Repeating this process multiple times, one can generate a labeled synthetic face dataset.\n\nsurprised to find that the actual number of unique subjects that can be generated by DiscoFaceGAN is less than 500, a finding that will be discussed in Sec. 3.1. The recent state of the art (SoTA), DigiFace [5], can generate 1M large-scale synthetic face images with many unique subjects based on 3D parametric model rendering. However, it falls short in matching the quality and style of real face images. We propose a new data generation scheme that addresses all three criteria, i.e. the large number of novel subjects (uniqueness), real dataset style matching (diversity) and label consistency (consistency). In Fig. 1, we illustrate the high-level idea by showcasing some of our generated face samples. The key motivation of our paper is that the synthetic dataset generator needs to control the number of unique subjects, match the training dataset's style distribution and be consistent in the subject label.\n\nIn light of this, we formulate the face image generation as a dual condition inverse problem, retrieving the unknown image Y from the observable Identity condition X id and Style condition X sty . Specifically, X id specifies how a person looks and X sty specifies how X id should be portrayed in an image. X sty contains identity-independent information such as pose, expression, and image quality.\n\nOur choice of dual conditions (identity and style) is important in how we generate a synthetic dataset as ID and style conditions are controllable factors that govern the dataset's characteristics. To achieve this, we propose a two-stage generation paradigm. First, we generate a highquality face image X id using a face image generator and sample a style image X sty from a style bank. Secondly, we mix these two conditions using a dual condition generator which predicts an image that has the ID of X id and a style of X sty . An illustration is given in Fig. 2.\n\nTraining the mixing generator in stage 2 is not trivial as it would require a triplet of (X A id , X B sty , X A sty ) where X A sty is a hypothetical combination of the ID of subject A and the style of subject B. To solve this problem, we propose a new dual condition generator that can learn from (X A id , X A sty ), a tuple of same subject images that can always be obtained in a labeled dataset. The novelty lies in our style condi-tion extractor and ID loss which prevents the training from falling into a degenerate solution. We modify the diffusion model [25,64] to take in dual conditions and apply an auxiliary time-dependent ID loss that can control the balance between sample diversity and label consistency.\n\nWe show that our Dual Condition Face Dataset Generator (DCFace) is capable of surpassing the previous methods in terms of FR performance, establishing a new benchmark in face recognition with synthetic face datasets. We also show the roles dataset subject uniqueness, diversity and consistency play in face recognition performance.\n\nThe followings are the contributions of the paper.\n\n\u2022 We propose a two-stage face dataset generator that controls subject uniqueness, diversity and consistency. \u2022 For this, we propose a dual condition generator that mixes the two independent conditions X id and X sty . \u2022 We propose uniqueness, consistency and diversity metrics that quantify the respective properties of a given dataset, useful measures that allow one to compare datasets apart from the recognition performance. \u2022 We achieve SoTA in FR with 0.5M image synthetic training dataset by surpassing the previous methods by 6.11% on average in 5 popular test datasets.\n\n\nRelated Works\n\nFace Recognition. Face Recognition (FR) is the task of matching query imagery to an enrolled identity database. SoTA FR models are trained on large-scale web-crawled datasets [14,22,89] with margin-based softmax losses [14,31,39,47,76]. The FR performance is measured on various benchmark datasets such as LFW [30], CFP-FP [61], CPLFW [87], AgeDB [51] and CALFW [88]. These datasets are designed to measure factors such as pose changes and age variations. Performance on these datasets for models trained on large-scale datasets such as Web-Face260M is well above 97% [39] in verification accuracy.\n\nSynthetic Face Generation. Recent advances in generative models allow high fidelity synthetic face image generations [8,11,25,[35][36][37]65]. GANs have been widely used to manipulate, animate or enhance face images [11,15,27,45,56,70,71,83]. They typically learn disentangled representations in GAN latent space that control desired face properties. On the contrary, some works leverage the 3D face prior from 3D datasets (e.g., 3DMM [6]) for controllable synthesis [12,18,19,38,50,52,54,63]. These methods have advantages in the fine-grained control over face generation and 3D consistency yet lack in style or domain variation. Recent advances in the latent variable models such as diffusion or score-based models have shown great success in high-quality image generation with a more stable and simple objective of MSE loss [25,53,[64][65][66][67][68]. Diffusion models have advanced the conditional image generation in tasks such as text-conditional image generation, inpainting, etc [7,58,59,78]. We adopt the diffusion model as a backbone and explore how the two image characteristics, namely ID and style images, can control complementary information, the subject appearance and the style of an image.\n\nFace Recognition with Synthetic Dataset. Synthetic training datasets offer an advantage over real datasets with regards to ethical issues and class imbalance problems as large-scale face datasets have been criticized for lacking informed consent and reflecting racial biases [5,14,84,89]. Despite the benefit, use of synthetic datasets as the sole training data is not widely adopted due to the resulting low recognition performance. In various domains such as face recognition [5,46,57], fingerprint recognition [17,82], and anti-spoofing [48,69], synthetic datasets have been shown to improve recognition when combined with real images.\n\nIn the face domain, SynFace [57] studied the efficacy of using DiscoFaceGAN [15] for synthetic face generation. Recently, DigiFace-1M [5] studied the efficacy of 3D model based face rendering in combination with image augmentations to create a synthetic dataset. We propose a face dataset generation method that can generate both a large number of subjects and diverse styles that are close to the real dataset.\n\n\nProposed Approach\n\nWe propose Dual Condition Face Dataset Generator (DCFace), a two-stage dataset generator (see Fig. 2). Stage 1 is the Condition Sampling Stage, generating a highquality ID image (X id ) of a novel subject and selects one arbitrary style image (X sty ) from the bank of real training data. Stage 2 is the Mixing Stage which combines the two images using the Dual Condition Generator.\n\nFor trainable models in each stage, Stage 1 requires training an ID image generator G id . For the style bank, we can conveniently use any real face dataset that we wish generated samples to follow. Stage 2 requires training a dual condition mixer G mix . Both G id and G mix are based on diffusion models [25]. We describe each component and the associated training procedure in the following subsections.  Figure 3. Comparison of the number of unique subjects generated by DiscoFaceGAN [15] and unconditional DDPM [25]. Uniqueness is the number of unique subjects measured by a face recognition model. By varying the threshold which determines a match between two subjects, we plot the number of unique subjects as defined in Eq. 11. Unconditional DDPM and DiscoFaceGAN are trained on FFHQ [36] and each generates 10, 000 samples. The ability to generate novel subjects is larger for DDPM. Refer to Supp.E for additional details on the threshold.\n\n\nPreliminary\n\nDiffusion models [25,64] are a class of denoising generative models that are trained to predict an image from random noise through a gradual denoising process. One notable difference from the class of GAN-based generators [21] is in the objective function and the sampling procedure. The forward process as expressed in Eq. 1 corrupts the input X using variance controlled Gaussian noise over t time-steps,\nq (X t |X t\u22121 ) = N X t ; 1 \u2212 \u03b2 t X t\u22121 , \u03b2 t I ,(1)\nand the denoising is done by training a model \u03f5 \u03b8 (X t , t) to predict the initial noise \u03f5 with an L 2 objective,\nL = E t,X0,\u03f5 \u03f5 \u03b8 ( \u221a \u03b1 t X 0 + \u221a 1 \u2212 \u03b1 t \u03f5 Xt , t) \u2212 \u03f5 2 2 . (2)\n\u03b2 t and \u03b1 t are pre-set variance scheduling scalars. The denoising diffusion model (DDPM) has shown success in producing diverse samples in text-conditioned image generation [58]. We find that in unconditional face generation, DDPM is also capable of generating many unique subjects. For instance, Fig. 3 compares DiscoFaceGAN [15] with DDPM [25] in their capacity to generate different subjects for every sample. It shows that DDPM [25] is a good model choice for G id and G mix as it can generate many unique subjects. For G id , we adopt the unconditional DDPM trained on FFHQ [36], having observed that it is capable of generating a large number of unique subject images.\n\n\nDual Condition Generator G mix\n\nThe two-stage data generation requires Dual Condition Generator G mix which is a conditional DDPM. Two conditions X id and X sty are injected into the denoiser \u03f5 \u03b8 (X t , t, E id (X id ), E sty (X sty )) using trainable feature \n\n\n2. b) Patch-wise Style Extractor ( ) c) Time-step Dependent ID Loss ( )\n= = 0 ! \u2212 , ( \u2212( \u2212 )\n, (\n\n\na) Training Dual Condition Generator\n\n. Figure 4. a) A diagram of Gmix during training. At each step, we draw two labeled images from the labeled training dataset and use them as X id and Xsty. We ensure X id to be the good-quality frontal view image. t emb is the time-step embedding in DDPM [25]. Xsty also serves as a target image and we apply Gaussian noise \u03f5 to Xsty to create Xt as DDPM specifies. Then \u03f5 \u03b8 (Xt, t, X id , Xsty) is trained to predict \u03f5 using LMSE, conceptually equivalent to the reconstruction loss to recover Xsty. We also apply LID as in Eq. 10 for the dependence on X id . b) Patch-wise Style Extractor generates style vectors from small patches of images. Style vectors are architecturally constrained from containing full ID information. c) Time-step dependent ID Loss is a linear interpolation between the X id and Xsty in the recognition feature space. It forces \u03f5 \u03b8 to rely on X id to extract the subject's appearance and gradually shift the style to Xsty.\n\n\nSame person\n\nextractors E id and E sty and cross-attentions. G mix is responsible for the operation X A id + X B sty \u2192 X A sty , a mixing of an image of a novel subject A and an arbitrary style image of different subject B.\n\nNaive training would require the reference image X A sty , an image of subject A in the style of X B sty . This reference is absent in the labeled training dataset. As such, we modify the operation to X A id + X A sty \u2192 X A sty , using two different images from the same subject as illustrated in Fig. 4(a). But this formulation is prone to a trivial solution of ignoring X A id , making the ID condition unused during test time. To mitigate this issue, we propose the following two elements. Patch-wise Style Extractor E sty . The motivation of Style Extractor is to map an image X sty to a feature that contains little ID information, forcing G mix to rely on X id for ID information. In prior works such as StyleGAN, 1 st and 2 nd order statistics of a feature are shown to resemble the image style [36,40,44]. Yet, resulting statistics are reduced in spatial dimensions and consequently without spatially local informations such as pose.\n\nWe propose a module that can extract style information without losing spatial information. Specifically, consider a pretrained and fixed face recognition model F s and its intermediate feature F s (X sty ) = I sty \u2208 R C\u00d7H\u00d7W . We divide the feature into a k \u00d7 k grid. For each element in the grid I ki sty \u2208 R C\u00d7 H k \u00d7 W k , we perform non-linear mapping on the mean and variance of I ki sty . Specifically,\nI ki = BN(Conv(ReLU(Dropout(I ki sty )))),(3)\u00b5 ki sty = SpatialMean(\u00ce ki ), \u03c3 ki sty = SpatialStd(\u00ce ki ), (4) s ki = LN (W 1 \u2299 \u00b5 ki sty + W 2 \u2299 \u03c3 ki sty ) + P emb ,(5)E sty (X sty ) := s = [s 1 , s 2 , s ki ..., s k\u00d7k , s \u2032 ],(6)\nwhere s \u2032 corresponds to I ki sty being a global feature, where k = 1. The final output s is a concatenation of all style vectors for each patch. Each s ki is a mean and variance of local information which is constrained from containing full pixel-level details with the ID information. And P emb is a learned position embedding to let the model differentiate different patch locations. BN and LN are BatchNorm [32] and LayerNorm [4]. F s is a shallow CNN taken from the early layers of a pretrained FR model. It is fixed and not updated to prevent it from optimizing I sty , serving only to create style information. By varying the grid size k\u00d7k, we can represent style at different spatial locations. An illustration of E sty can be found in Fig. 4(b). Time-step Dependent ID Loss. To train Dual Condition Generator G mix , the original DDPM objective of L 2 loss, Eq. 2 is not sufficient to guarantee the consistency in subject identity between the ID condition X id and the prediction, X 0 . To ensure the ID consistency, one could devise a loss function to maximize the similarity between X id and the predicted denoised imageX 0 , in the ID feature space using a pretrained FR model, F . Specifically, following the Eq.15 of DDPM [25], one-step prediction of the original image i\u015d\nX 0 = (X t \u2212 \u221a 1 \u2212\u1fb1 t \u03f5 \u03b8 (X t , t, X id , X sty ))/ \u221a\u1fb1 t . (7) A simple ID loss to increase cosine similarity (CS) is L naive1 = \u2212CS F (X id ), F (X 0 )) .(8)\nHowever, this loss is in conflict with MSE loss and is empirically observed to reduce the predicted image quality. This is because the FR model, F is not invariant to image style; some style of X id has to match in order to completely reduce L naive1 . In contrast, one could also use as during training the label of X sty and X id are the same. However, L naive2 causes the model to depend on X sty for ID information. Thus, during evaluation, when X sty and X id are different subjects, the label consistency in the generated dataset is compromised. We show this in Tab. 2. Instead, we propose to interpolate between F (X id ) and F (X sty ) across diffusion time-steps. Specifically,\nL naive2 = \u2212CS F (X sty ), F (X 0 )) ,(9)L ID = \u2212 \u03b3 t CS F (X id ), F (X 0 )) \u2212 (1 \u2212 \u03b3 t )CS F (X sty ), F (X 0 )) ,(10)\nwhere \u03b3 t = t T is a time-dependent weight that linearly changes from 0 to 1. When t = T , \u03f5 \u03b8 is predicting X t\u22121 from random noise, and we let the model fully exploit the ID information of X id . Gradually as t increases, we let the model's prediction walk into the direction of X sty . Note that during training, the actual label of X sty and X id are the same. So the interpolation in the loss forces the prediction to be the same in identity but gradually shifting in style toward X sty . This loss allows \u03f5 \u03b8 (X t , t, X id , X sty )) to play different roles depending on t. For t \u2248 T , \u03f5 \u03b8 will exploit X id to infer front-view ID rich image. And as t \u2192 0, it will change the image's style to match the style of X sty . The final loss is L M SE + \u03bbL ID with \u03bb as a scaling parameter. E id and Conditioning Mechanism. Following the success text-conditional image generation and inpainting using DDPM [55,58,78], we adopt a similar architecture for inserting conditions into the model. We concatenate E id (X id ) and E sty (X sty ) and put in \u03f5 \u03b8 using cross-attention and adaptive group normalization layers (AdaGN) [55]. E id is a CNN, with the same architecture as a small FR model (e.g. ResNet50). And E id is trained end-to-end with \u03f5 \u03b8 to extract useful ID feature for \u03f5 \u03b8 . More training details can be found in Supp.\n\n\nCondition Sampling Strategy\n\nID Image Sampling. For sampling ID images, we generate 200, 000 facial images from G ID , from which we remove faces that are wearing sunglasses or too similar to the subjects in CASIA-WebFace with the Cosine Similarity threshold of 0.3 using F eval . We are left with 105, 446 images. Then we narrow them down to 62, 570 images that are unique according to uniqueness, Eq. 11 using F eval and r = 0.3. Then we explore two different options, 1) random sampling and 2) gender/ethnicity balanced sampling as G id has a skewed distribution towards White subjects as shown in Tab. 1. We use [2] to classify the ethnicity and use [33,80] to detect sunglasses. We denote the sampling option 1 as random and 2 as balance.\n\nStyle Image Sampling. For style sampling, for each X id , we randomly sample X sty from the style bank. We denote this option as random. We also explore the option of sampling X sty from the pool of images whose gender/ethnicity matches that of X id . We denote this option as match.\n\n\nDataset Evaluation\n\nIn evaluating the synthesized dataset, one often adopts 1) FID [24] for evaluating the distribution similarity to the real images and 2) subsequent recognition performance. In this section, we propose three class-dependent metrics that aid us in understanding the property of generated labeled datasets. We let F eval be an recognition model used for evaluating synthesized face datasets. Note that this is different from F in ID loss. F is a model for training loss and F eval is for evaluating metrics. The more generalizable F eval is, the more accurate the metrics become in capturing the identity and diversity of the synthesized dataset.\n\nLet y c be a class label, and f i = F eval (X i ). Let d(f i , f j ) be the distance between two images in F eval feature space. Uniqueness. Consider the following non-overlapping rball in F eval space,\nU = {f i : d(f i , f j ) > r, j < i, i, j \u2208 {1, .., N }},(11)\nwhere d(f i , f j ) is the cosine distance. Then |U | is the count of unique subjects determined by the threshold r in an un-labeled dataset. Note that the set U is equivalent to sequentially adding a r-ball into F eval -space until you cannot add more without collision. |U | is subject to both r and F eval . In FR, r is a threshold in the FR model that is set to determine match or non-match.\n\nFor a labeled synthetic dataset, one generates multiple feature sets {f c i } for the same label. To count the number of unique subjects, we calculate the number of unique centers, f c = 1\n\nNc Nc i f c i for c \u2208 {1, ..., C}, where C is the number of subjects and N c is the number of images per subject. Then we define the number of unique subjects in a labeled dataset with |U c | where U c is\nU c = {f c : d(f cn , f cm ) > r, m < n, n, m \u2208 {1, .., C}},(12)\nFor the metric, we use U class = |U c |/C, the ratio between the number of unique subjects and the number of labels. Intra-class Consistency. It measures how consistent the generated samples are in adhering to the label condition, as\nC intra = 1 C C c=1 1 N c Nc i=1 d(f c i , f c ) < r,(13)\nwhich is the ratio of individual features f c i being close to the class center f c . For a given threshold r, higher values of C intra mean the samples are more likely to be the same subject under the same label. Intra-class Diversity. It measures how diverse the generated samples are under the same label condition. Note that the diversity is in the style of an image, not in the subject's identity. We define the style space as a vector space defined by Inception Network [60] features pretrained on Im-ageNet [13] following the convention of [43], denoting the real and generated image inception vectors as {s c i }, {\u015d c j }. For intra-class diversity, we measure how many real images fall into the style space manifold defined by the generated images under the same label condition. We compute this by extending the Improved Recall Metric [43], from comparing the unconditional distributions of real and fake images to comparing the label-conditional distributions. Specifically, for a set of real and generated feature vectors {s c i }, {\u015d c j } under the same label condition y c , we define knearest feature distance r k as\nr k = d \u015d c j \u2212NN k \u015d c j , {\u015d c j } , where NN k returns the k-nearest feature vector in {\u015d c j } and I(s c i , {\u015d c j }) = 1, \u2203\u015d c j \u2208 {\u015d c j } s.t. d s c i \u2212\u015d c j \u2264 r k 0, otherwise.(14)\nd(\u00b7) is an Euclidean distance. Then diversity is defined by\nD intra = 1 C 1 N C c=1 Nc i=1 I(s c i , {\u015d c j }),(15)\nwhich is the fraction of real image styles manifold covered by the generated image style manifold as defined by Consistency / Diversity Tradeoff Figure 6. A plot of FR performance on 5 synthetic datasets with respect to Consistency and Diversity metrics. Color intensity and circle size denotes the FR accuracy.\n\nk-nearest neighbor ball. If the style variation is small, then r k becomes small, reducing the chance of d s c i \u2212\u015d c j \u2264 r k . We compute the recall per class to capture style variation conditional on the subject label.\n\nIn Fig. 5, we illustrate different scenarios of conditional generation and how these metrics can capture the shortcomings in each scenario. In Sec. 5 and Fig. 6, we measure the metrics on our generated datasets and compare with previous synthetic datasets [5,57]. We find that FR performance is at best when consistency and diversity are balanced. Also, we find SynFace and DigiFace have high C intra and low D intra compared to our method in Fig. 5.\n\n\nExperiments\n\nFor G id which generates ID images, we adopt the publicly released unconditional DDPM [25] trained on FFHQ [36]. For G mix , we train it on CASIA-WebFace [29] after initializing weights from G id . Although using all of CASIA-WebFace is a valid setting, we split it into a 95-5 split between train and validation sets. The validation set is used as a real dataset in measuring the uniqueness, consistency and diversity metrics. G mix is trained for 10 epochs with a batch-size of 256 using AdamW Optimizer [41,49] with the learning rate of 0.001. Training takes 8 hours using two A100 GPUs. Once G mix is trained, we use G id , G mix and a style bank to generate a synthetic labeled dataset. The style bank is the CASIA-WebFace training set. For sampling, we use DDIM [65] with 200 intervals. Generating 500K samples takes about 20 hours using one A100 GPU.\n\nTo train FR models, for a fair comparison, we adopt the training scheme of [5,57] using IR-SE-50 [14] as a backbone and AdaFace [39] as a loss function. We evaluate the trained FR models on five datasets, LFW [30], CFP-FP [61], CPLFW [87], AgeDB [51] and CALFW [88]. CFP-FP and CPLFW are designed to measure the FR in the large pose variation and AgeDB and CALFW are for the large age variation. To measure the consistency, diversity and uniqueness during evaluation, we adopt F eval as IR101 [14] model trained on WebFace4M [89] with AdaFace [39] loss.  Table 2. Model Ablation. For FR performance, we generate a synthetic dataset of 10K subjects with 50 images per subject using (random, random) ID and style sampling strategy. Blue color indicates the adopted setting for subsequent experiments.\n\n\nModel Ablation\n\nTo show the efficacy of our proposed modules, we ablate on 1) the grid size in Style extractor E sty , 2) Time-step dependent ID loss and 3) the ID loss backbone F 's. The number of samples we generate for the ablation are 10K subjects with 50 images per subject, similar to CASIA-WebFace image counts. We report the FR performance with the synthetic data by averaging the 5 validation set verification accuracies. To measure U class , C intra and D intra , we use 500 subjects with 20 real images from the held-out validation set of CASIA-WebFace and generate an equivalent number of images from each method.\n\nGrid Size. We choose 4 grid sizes ranging from 1\u00d71 to 7\u00d77. Note that 1\u00d71 corresponds to the style vector of a whole image. We expect to see higher spatial control in X sty as the grid size increases. In Tab. 2, we report the three metrics U class , C intra and D intra . As the grid size increases, E sty features contain more fine-grained information, possibly related to ID, lowering the consistency. However, the diversity increases, making the conditional distribution similar to the real dataset. The subsequent FR performance using the model is the best in the setting 5\u00d75, which is a good compromise between consistency and diversity. In Fig. 7, we show the effect of the grid size with examples.\n\nID Loss. For ID loss, we compare L ID with L naive1 and L naive2 in Tab. 2. Using L naive1 or L naive2 both suffer from lower FR performance, but for different reasons. L naive1 has low diversity because it is optimized to be similar to X id of front-view high quality face images. L naive2 has low consistency because of the lack of dependence on X id , making the resulting dataset with random labels. FR performance of 0.5 means the model diverged and is returning random predictions. L ID , a linear interpolation of the L naive1 and L naive2 across time-steps results in the best performance.  ablate F bigger , a model pretrained on a larger dataset, Web-Face4M [89]. Tab. 2 shows that a better FR backbone induce the generator to synthesize better datasets, even without explicitly showing WebFace4M images to generators. But for fairness in comparing to the real CASIA-WebFace dataset, we do not use F bigger for subsequent analysis.\n\n\nID Loss Backbone\n\n\nSampling Ablation\n\nUsing the sampling strategy defined in Sec. 3.3, we ablate on the ID sampling options (random, balance) and style sampling methods (random, match) in Tab. 3. We find that either balancing the gender/ethnicity distribution or making the gender/ethnicity of style image equal to that of ID images does not bring significant performance gain.\n\nOn the other hand, to compensate for lower label consistency compared to the real dataset, we include the same X id for 5 additional times for each label. This has the effect of oversampling X id during training FR model. When we add the oversampling option to (balance, match) setting, we observe an average verification accuracy of 89.56%, 0.52% increase over the (random, random) setting.\n\n\nComparison with Previous Methods\n\nFor training FR models with synthetic datasets, we compare with SynFace [57] and DigiFace [5]. We compare 0.5M and 1.2M image count settings. The first setting corresponds to the size of the CASIA-WebFace real dataset. The second setting is to evaluate the effect of increasing the training dataset size. In Tab. 4, we show the verification accuracies of 5 validation sets. In 0.5M regime, our DC-Face can surpass DigiFace in 4 out of 5 datasets with an improvement of 6.11% on average. In CFP-FP dataset with extremely large pose variation, DigiFace performs better, showing the merit of 3D consistent face synthesis using 3D models. DCFace has a good balance of consistency and diversity with many unique subjects, leading to a better FR performance in general. Note the larger style variation compared to SynFace and DigiFace in Fig. 7.\n\nThe last column of Tab. 4 shows the gap between synthetic and real, calculated as (REAL \u2212 SYN)/SYN, e.g. 5.65% = 94.62\u221289.56 89.56 . It indicates how much improvement is needed to be on par with the real dataset. In 0.5M setting, DCFace reduces the gap to real performance by 57% over the SoTA. When we use more synthetic data as in 1.2M  Figure 7. An example of SynFace and DigiFace in rows 1-2 and DCFace with different grid size settings in rows 3-7. SynFace (DiscoFace-GAN) generates mostly frontal-view high-quality images and DigiFace contains synthetic face images with unrealistic texture compared to real images. Our grid size ablation changes the contribution of Xsty and X id . A good FR performance is a compromise in-between, 5\u00d75. Note that our method can have diverse styles such as low lighting, pose, glassses, hat, etc. Using X id to query subjects in CASIA-WebFace and DCFace datasets returns top 5 most similar subjects. We see X id sufficiently different from other (real or fake) subjects.  regime, the synthetic dataset performance comes closer to that of the real dataset (3.74% in gap), a 60.9% improvement from the previous method (9.55% in gap).\n\n\nConclusion\n\nThis paper presents a method for creating a synthetic training dataset for face recognition. Dataset generation is studied from the perspective of generating many unique subjects with large style diversity and label consistency. We propose the Dual Condition Face Generator to this end and show its large FR performance gain over previous methods on synthetic dataset generation. We believe our approach takes one step towards matching the performance of real training datasets with synthetic training datasets.\n\nLimitations. This work addresses the problem of generating label consistent and diverse datasets for face recognition model training. In our model ablation, we find that sacrificing label consistency for diversity to some degree is beneficial for the FR model training. However, this is not ideal; for instance, our synthetic face generator lacks 3D consistency across pose, which is an advantage of generative models with 3D priors. Secondly, the goal of our research is to release a synthetic face dataset that alleviates the dependence on large-scale web-crawled images. As shown in our experiments, there is still some performance gap between real and synthetic training datasets. In this work, we take one step towards the goal and hope that the continued research will introduce a standalone synthetic face dataset.\n\n\nSupplementary Material\n\n\nA. Training Details\n\n\nA.1. Architecture Detals\n\nThe dual condition generator G mix is a modification of DDPM [25] to incorporate two conditions. We insert two conditions X id and X sty into the denoising U-Net \u03f5 \u03b8 (X t , t, X id , X sty ). Conditioning images X sty and X id are mapped to features using E sty and E id , respectively. According to Eq. 6 of the main paper, the style information E sty (X sty ) is the concatenation of style vectors at different k\u00d7k patch locations,\nE sty (X sty ) := s = s 1 , s 2 , s ki ..., s k\u00d7k , s \u2032 \u2208 R (k 2 +1)\u00d7C .(1)\nOn the other hand, ID information is a concatenation of features extracted from a trainable CNN (e.g. ResNet50 [23]), which produces an intermediate feature I id of shape R 7\u00d77\u00d7512 and a feature vector f id of shape R 512 . Specifically,\nE id (X id ) := i = [Flatten(I id ), f id ] + P emb \u2208 R 50\u00d7C ,(2)\nwhere Flatten refers to removing the H\u00d7W spatial dimension and R 50\u00d7C is from concatenating features of length 7 * 7 and 1. P emb is a learnable position embedding for distinguishing each feature position for the subsequent cross-attention operation. Detailed illustrations of E sty (X sty ) and E id (X id ) are shown in Fig. 1. C for the channel dimension of E sty (X sty ) and E id (X id ) is 512. Figure 1. Left: An illustration of Xsty. The key property of Xsty is in restricting the information in Xsty from flowing freely to the next layer. The fixed feature encoder Fs and the patch-wise spatial mean-variance operation destroy the detailed ID information while preserving the style of an image. We create an output of size R (k 2 +1)\u00d7C . Right: A simple CNN based on ResNet50. We take intermediate representation and the last feature vector and concatenate them together to create a output of size R 50\u00d7C .\n\n\nPatch-wise Style Extractor ( )\n. . \u00d7 \u2026 . , ID Extractor ( ) \u2208 \u211d ( * 0 )\u00d7 \u2026 \u2026 \u2026 \u2026 \u2208 \u211d \u00d7 \u2208 \u211d \u00d7 \u2208 \u211d\n\nB. More Experiment Results\n\n\nB.1. Adding Real Dataset\n\nWe include additional experiment results that involve adding real images. Although the motivation of the paper is to use an only-synthetic dataset to train a face recognition model, the performance comparison with an addition of a subset of the real dataset has its merits; it shows 1) whether the synthetic dataset is complementary to the real dataset and 2) whether the synthetic dataset can work as an augmentation for real images.\n\nTab. 1 shows the performance comparison between DigiFace [5] and our proposed DCFace when 1) a few real images are added and 2) both synthetic datasets are combined. The performance gap for DigiFace is large, jumping from 86.37 to 92.67 on average when 2K real subjects with 20 images per subject are added. In contrast, ours show a relatively less dramatic gain, 91.21 to 92.90 when few real images are added. This indicates that DigiFace [5] is quite different from the real images and ours is similar to the real images. This is in-line with our expectation as we have created a synthetic dataset that tries to mimic the style distribution of the training dataset, whereas DigiFace simulates image styles using 3D models.\n\n\nB.2. Combining Multiple Synthetic Datasets\n\nIn the second to the last row of Tab. 1, when we combined the two synthetic datasets without the real images, the performance is the highest, reaching 93.06 on average. This result indicates that different synthetic datasets can be complementary when they are generated using different methods.  C.2 Feature Plot. In Fig. 4, we show the 2D t-SNE [74] plot of synthetic images generated by 3 different methods (Dis-coFaceGAN [15], DigiFace [5] and proposed DCFace). The red circles represent real images from CASIA-WebFace. We extract the features from each image using a pre-trained face recognition model, IR101 [14] trained on WebFace4M [89].  \n\n\nC.3 Comparison with Classifier Free Guidance.\n\nWhen \u03f5(x t , c) learns to use the condition c, the difference \u03f5(x t , c)\u2212\u03f5(x t ) can give further guidance during sampling to increase the dependence on c. But, in our case, the ID condition is the fine-grained facial difference that is hard to learn with MSE loss. Proposed Time-dependent ID loss, L ID helps the model learn this directly. Row 3 vs 4 of Tab. 2 shows that L ID is more effective than CFG.\n\n\nConditions\n\nTrain Loss Sampling FR.Perf \u2191 1 CNN(X id ), CNN(X sty ) MSE + Guide 73.38\n\n2 CNN(X id ), E sty (X sty ) MSE \u00d7 82.30 3 CNN(X id ), E sty (X sty ) MSE + Guide 84.05 4 CNN(X id ), E sty (X sty ) MSE+L ID \u00d7 89.56 Table 2. Green Esty and LID indicates the novelty of our paper. For guidance, we adopt 10% condition masking during training and the guidance scale of 3 during sampling. FR.Perf is an average of 5 face recognition performances as in the main paper.\n\nInterestingly, with a large guidance scale, CFG becomes harmful. CFG decreases diversity as pointed out by [26]. We observe that guidance with X id leads to consistent ID but with little facial variation, the same phenomenon in DCFace with grid-size 1x1 in E sty , in Tab. 2 (main). Good FR datasets need both large intra and inter-subject variability and we combine E sty and L ID to achieve this.\n\nC.4 FID Scores. Note that our generated data is not high-res images like FFHQ when compared to how SynFace is similar to FFHQ. (Tab. 3 row 5 vs 6). But, we point out that our aim is not to create HQ images but to create a database with realistic inter/intra-subject variations. In that regard, we have successfully approximated the distribution of the popular FR training dataset CASIA-WebFace (FID=13.67).  Table 3. FID scores of synthetic vs real datasets. For synthetic datasets, we randomly sampled 10, 000 images. See Line 630 for Casia-WebFace Train and Val set split. All images are aligend and cropped to 112\u00d7112 to be in accordance with CASIA-WebFace.\n\nHaving said this, we note FID is not comprehensive in evaluating labeled datasets. It cannot capture the label consistency nor directly relate to the FR performance. As such, SynFace/DigiFace do not report FID. We propose U,D,C metrics that enable holistic analysis of labeled datasets.\n\nC.5 Does DCFace change gender?. DCFace combines X ID and X sty , while adhering to the subject ID as defined by a pre-trained FR model. Factors weakly related to ID, such as age and hair style, can vary. Biometric ambiguity can occur due to makeup, wig, weight change, etc. even in real life. The perceived gender may change, but changes such as hair are less relevant to subject ID for the FR model. C.6 Why DCFace is better in U,D,C metrics?. We note DCFace is not better in all U,D,C. Fig. 6 (main) shows SynFace has the highest consistency (C). But, DCFace excels in the tradeoff between C and D. In other words, style similarity to the real dataset (i.e. D) is lacking in other datasets and it is as important as ID consistency. As such, U,D,C metrics reveal weak/strong points of synthetic datasets. Fig. 5 shows how DDPM generates output at each time-step. The far left column shows X sty , the desired style of an image. The far right column shows X id , the desired ID image of choice. In early time-steps, the network reconstructs the front-view image with an ID of X id . And gradually, it interpolates the image into the desired style of X sty . The gradual transition can be in the pose, hair-style, expression, etc. \n\n\nD. Visualizations\n\n\nD.1. Time-step Visualizaton\n\n\n= =\n\n\nD.2. Interpolation\n\nIn Fig. 6, we show the plot of interpolation in X sty . While keeping the same identity X id , we take two style images X sty1 and X sty2 . We interpolate with \u03b1 in \u03b1E stry (X sty1 ) + (1 \u2212 \u03b1)E stry (X sty2 ) with \u03b1 increasing linearly from 0 to 1. The interpolation is smooth, creating an intermediate pose and expression that did not exist before. \n\nFigure 1 .\n1Illustration of three factors that characterize a labeled face dataset. It contains large subject variation, style variation and label consistency. Synthetic face datasets should be created with all three factors in mind. Face images in this figure are samples generated by our proposed method which combines arbitrary ID condition with style condition while preserving subject identity.\n\nFigure 5 .\n5Illustration of conditional distributions in 2D space. Colored regions represent the true data distribution with individual colors representing different labels. Colored triangles represent generated samples with corresponding labels. For each scenario except (a), the generated distribution does not follow the true distribution. Consistency, diversity and uniqueness analysis can quantify the shortcomings.\n\nFigure 3 .\n3Plot of unique subject count as the number of samples from G id is increased from 1000 to 200, 000. At 200, 000, one additional sample has approximately 15% chance of being unique. And the rate decreases with more samples.\n\n(b) 1\n1We show two settings we sample (a) 50 subjects with 1 image per subject and (b) 1 subject with 50 images per subject. Note that the proximity of DCFace image features is closer to CASIA-WebFace image features, highlighted in a circle. For each setting, we show the features extracted from an intermediate layer of IR101 and the last layer. As the layer becomes deeper, the features become suitable for recognition, as shown in the last column of the figure. Subject 50 Images (Intra-class Dist.) (a) 50 Subject 1 Images (Inter-class Dist.)\n\nFigure 4 .\n4(a) the t-SNE plot of features from synthetic and real datasets of 50 subjects per dataset. It shows how 50 randomly sampled subjects from each dataset are distributed. The distribution between real (red) and DCFace (green) is the closest. (b) the t-SNE plot of features from synthetic and real datasets of 1 subject per dataset with 50 images. We randomly sample 1 subject from each dataset. The last layer features are well separated as the model is a face recognition model that separates the features of different subjects.\n\nFigure 5 .\n5A plot of DCFace outputs at each time-step.\n\nFigure 6 .\n6A plot of DCFace output with style interpolation.\n\n\nLossLoss Model U class Cintra Dintra FR Perf.Grid Size \n\nSynFace \n-\n-\n0.080 0.9966 \n0.131 \n74.75 \nDigiFace \n-\n-\n0.178 0.9973 \n0.297 \n83.45 \n\n1\u00d71 \n\nL ID \nF \n\n0.978 0.9987 0.4418 \n79.28 \n3\u00d73 \n0.956 0.9809 0.7030 \n85.79 \n5\u00d75 \n0.924 0.9035 0.7734 89.04 \n7\u00d77 \n0.690 0.5937 0.7950 50.00 \n\n5\u00d75 \n\nLnaive1 \nF \n\n0.988 0.9996 0.6546 \n84.75 \nLnaive2 \n0.866 0.8046 0.7835 \n50.00 \nL ID \n0.924 0.9035 0.7734 89.04 \n\n5\u00d75 \nL ID \nF \n0.924 0.9035 0.7734 \n89.04 \nF bigger \n0.954 0.9197 0.7715 89.89 \n\n\n\n\nF . ID Loss requires a pretrained FR model, F . For all of our experiments, we use F as IR50 trained on CASIA-WebFace. But, we are curious if there is a benefit to have a better representation from F . For this, weID \nStyle \nLFW CFPFP CPLFW AGEDB CALFW \nAVG \nrandom random 98.05 84.17 82.20 \n89.38 \n91.40 \n89.04 \nrandom \nmatch \n98.28 84.61 82.32 \n89.12 \n91.28 \n89.12 \nbalance random 98.30 83.27 81.60 \n89.40 \n91.27 \n88.77 \nbalance \nmatch \n98.38 84.06 82.45 \n89.30 \n91.38 \n89.11 \nbalance over smpl 98.55 85.33 82.62 89.70 91.60 \n89.56 \n\n\n\nTable 3 .\n3Sampling Ablation. We generate a synthetic dataset of 10K subjects with 50 images per subject, using the setting indicated by the blue text in Tab. 2. over smpl is over-sampling X id during training for showing more front-view faces.\n\nTable 4 .\n4Verificationaccuracies of FR models trained with SoTA synthetic training datasets. SynFace [57] is a GAN-based dataset with a \nlatent space mixup technique. DigiFace [5] is a 3D model-based dataset with heavy image augmentation. DCFace uses the model setting \nfrom the ablation study, Tab. 2, 3 indicated by blue colors. FR backbone is IR-SE50 [14] + AdaFace [39] to match the setting of DigiFace. \n\n\n\n\nTable 1. Verification accuracies of FR models trained with synthetic datasets and subset of real datasets. In all settings, the backbone is set to IR50[14] model with AdaFace loss[39] for a fair comparison.C. Analysis C.1 Unique Subject Counts. InFig. 3, we plot the number of unique subjects that can be sampled as we increase the sample size. The blue curve shows that the number of unique samples that can be generated by a DDPM of our choice does not saturate when we sample 200, 000 samples. At 200, 000 samples, the unique subjects are about 60, 000. And by extrapolating the curve, we estimate the number might reach 80, 000 with more samples. Our DDPM of choice is trained on FFHQ[36] dataset which contains 70, 000 unlabeled high-quality images. The orange line shows the number of unique samples that are sufficiently different from the subjects in the CASIA-WebFace dataset. The green line shows the number of unique samples left after filtering images that contain sunglasses. The flat region is due to the filtering stage reducing the total candidates. The plot shows that DDPM trained on FFHQ dataset can sufficiently generate a large number of unique and new samples that are different from CASIA-WebFace dataset. However, with more samples, eventually there is a limit to the number of unique samples that can be generated. When the number of total generated samples is 100, 000, one additional sample has approximately 24% chance of being unique, whereas, at 200, 000, the probability is 15%. The rate of sampling another unique subject decreases with more samples. The model used for evaluating the uniqueness is IR101[14] trained on the WebFace4M[89] dataset. And we use the threshold of 0.3. We would like to note a typo in Sec. 3.3 of the main paper, where the number of unique subjects should be corrected from 62, 570 to 42, 763.# Synthetic Imgs \n# Real Imgs LFW CFPFP CPLFW AGEDB CALFW \nAVG \nGap to \nReal \nDigiFace 1.2M (10K\u00d772+100K\u00d75) \n0 \n96.17 \n89.81 \n82.23 \n81.10 \n82.55 \n86.37 \n8.72 \nDigiFace 1.2M (10K\u00d772+100K\u00d75) \n2K\u00d720 \n99.17 \n94.63 \n88.1 \n90.5 \n90.97 \n92.67 \n2.06 \n\nDCFace \n1.2M (20K\u00d750+40K\u00d75) \n0 \n98.58 \n88.61 \n85.07 \n90.97 \n92.82 \n91.21 \n3.61 \nDCFace \n1.2M (20K\u00d750+40K\u00d75) \n2K\u00d720 \n98.97 \n94.01 \n86.78 \n91.80 \n92.95 \n92.90 \n1.82 \n\nDCFace+DigiFace (2.4M) \n0 \n99.20 \n93.63 \n87.25 \n92.25 \n92.95 \n93.06 \n1.65 \n\nCASIA \n0 \n0.5M \n99.42 \n96.56 \n89.73 \n94.08 \n93.32 \n94.62 \n0 \n\nNumber of Samples \n\nUniqueness Count \n\n\n\n\nGenerator Train Data Source (real/syn)Target (real) \nFID \u2193 \n1 \n-\nCASIA (train) \nCASIA (val) \n9.57 \n\n2 \nCASIA (train) \nDCFace \nCASIA (val) \n13.67 \n3 \nFFHQ+3DMM \nSynFace \nCASIA (val) \n38.48 \n4 \n3D Face Capture \nDIGIFACE1M \nCASIA (val) \n71.65 \n\n5 \nCASIA (train) \nDCFace \nFFHQ (train+val) 35.45 \n6 \nFFHQ+3DMM \nSynFace \nFFHQ (train+val) 21.75 \n7 \n3D Face Capture \nDIGIFACE1M FFHQ (train+val) 68.67 \n\n\nAcknowledgments. This research is based upon work supported in part by the Office of the Director of National Intelligence (ODNI), Intelligence Advanced Research Projects Activity (IARPA), via 2022-21102100004. The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of ODNI, IARPA, or the U.S. Government. The U.S. Gov. is authorized to reproduce and distribute reprints for governmental purposes notwithstanding any copyright annotation therein.A.2. Training Hyper-ParametersThe final loss for training the model end-to-end is L M SE + \u03bbL ID with \u03bb as a scaling parameter. We set \u03bb = 0.05 to compensate for the different scale between L2 and Cosine Similarity. All our input image sizes are 112\u00d7112, following the convention of SoTA face recognition model datasets[14,29,89]. And our code is implemented in Pytorch.When E sty (X sty ) and E id (X id ) is prepared, they together form (k 2 +1)+50 vectors of shape 512. These can be injected into the U-Net \u03f5 \u03b8 by following the convention of the DDPM based text-conditional image generators[58]. Specifically, cross attention operation can be written as a modification of attention equation[75]with query Q, key K and value V with additional query Q c , key K c .where W q , W k and W v are learnable weights and [\u00b7] refers to concatenation operation. In our case, Q = K = V are an arbitrary intermediate feature in the U-Net. And K c = V c are conditions generated by E sty (X sty ) and E id (X id ), concatenated together. This operation allows the model to update the intermediate features with the conditions if necessary. We insert the cross-attention module in the last two DownSampling Residual Blocks in the U-Net, as shown inFig. 2.To increase the effect of X id in the conditioning operation, we also add f id to the time-step embedding t emb . As shown in the right side ofFig. 2, the Residual Block in the U-Net modulates the intermediate features according to the scaling vector provided by f id + t emb . GNorm[81]refers to Group Normalization and SiLU refers to Sigmoid Linear Units[16]. Adding f id to t emb for the Residual Block allows more paths for X id to change the output of U-Net.\n. Tface, TFace. https://github.com/Tencent/TFace. git. Accessed: 2021-10-3. 7\n\n. V\u00edtor Albiero, V\u00edtor Albiero. Face analysis pytorch. https://github. com / vitoralbiero / face _ analysis _ pytorch, 2022. 5\n\nProactive image manipulation detection. Vishal Asnani, Xi Yin, Tal Hassner, Sijia Liu, Xiaoming Liu, CVPR. Vishal Asnani, Xi Yin, Tal Hassner, Sijia Liu, and Xiaom- ing Liu. Proactive image manipulation detection. In CVPR, 2022. 7\n\n. Jimmy Lei Ba, Jamie Ryan Kiros, Geoffrey E Hin, arXiv:1607.06450ton. Layer normalization. arXiv preprintJimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hin- ton. Layer normalization. arXiv preprint arXiv:1607.06450, 2016. 4\n\nDigiface-1m: 1 million digital face images for face recognition. Gwangbin Bae, Martin De La Gorce, Tadas Baltrusaitis, Charlie Hewitt, Dong Chen, Julien Valentin, Roberto Cipolla, Jingjing Shen, WACV. 84Gwangbin Bae, Martin de La Gorce, Tadas Baltrusaitis, Charlie Hewitt, Dong Chen, Julien Valentin, Roberto Cipolla, and Jingjing Shen. Digiface-1m: 1 million digital face images for face recognition. In WACV, 2023. 1, 2, 3, 6, 7, 8, 4\n\nA morphable model for the synthesis of 3D faces. Volker Blanz, Thomas Vetter, SIGGRAPH. Volker Blanz and Thomas Vetter. A morphable model for the synthesis of 3D faces. In SIGGRAPH, 1999. 3\n\nRetrieval-augmented diffusion models. Andreas Blattmann, Robin Rombach, Kaan Oktay, Bj\u00f6rn Ommer, arXiv:2204.118242022arXiv preprintAndreas Blattmann, Robin Rombach, Kaan Oktay, and Bj\u00f6rn Ommer. Retrieval-augmented diffusion models. arXiv preprint arXiv:2204.11824, 2022. 3\n\nLarge scale gan training for high fidelity natural image synthesis. Andrew Brock, Jeff Donahue, Karen Simonyan, arXiv:1809.11096arXiv preprintAndrew Brock, Jeff Donahue, and Karen Simonyan. Large scale gan training for high fidelity natural image synthesis. arXiv preprint arXiv:1809.11096, 2018. 2\n\nVGGFace2: A dataset for recognising faces across pose and age. Qiong Cao, Li Shen, Weidi Xie, M Omkar, Andrew Parkhi, Zisserman, FG. Qiong Cao, Li Shen, Weidi Xie, Omkar M Parkhi, and An- drew Zisserman. VGGFace2: A dataset for recognising faces across pose and age. In FG, 2018. 1\n\nLowresolution face recognition. Zhiyi Cheng, Xiatian Zhu, Shaogang Gong, ACCV. Zhiyi Cheng, Xiatian Zhu, and Shaogang Gong. Low- resolution face recognition. In ACCV, 2018. 7\n\nStarGAN: Unified generative adversarial networks for multi-domain image-to-image translation. Yunjey Choi, Minje Choi, Munyoung Kim, Jung-Woo Ha, Sunghun Kim, Jaegul Choo, In CVPR. 23Yunjey Choi, Minje Choi, Munyoung Kim, Jung-Woo Ha, Sunghun Kim, and Jaegul Choo. StarGAN: Unified gener- ative adversarial networks for multi-domain image-to-image translation. In CVPR, 2018. 2, 3\n\nUV-GAN: Adversarial facial uv map completion for pose-invariant face recognition. Jiankang Deng, Shiyang Cheng, Niannan Xue, Yuxiang Zhou, Stefanos Zafeiriou, In CVPR. 3Jiankang Deng, Shiyang Cheng, Niannan Xue, Yuxiang Zhou, and Stefanos Zafeiriou. UV-GAN: Adversarial facial uv map completion for pose-invariant face recognition. In CVPR, 2018. 3\n\nImagenet: A large-scale hierarchical image database. Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, Li Fei-Fei, CVPR. Ieee. Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In CVPR. Ieee, 2009. 6\n\nArcFace: Additive angular margin loss for deep face recognition. Jiankang Deng, Jia Guo, Niannan Xue, Stefanos Zafeiriou, CVPR. 84Jiankang Deng, Jia Guo, Niannan Xue, and Stefanos Zafeiriou. ArcFace: Additive angular margin loss for deep face recognition. In CVPR, 2019. 1, 2, 3, 6, 8, 4\n\nDisentangled and controllable face image generation via 3D imitative-contrastive learning. Yu Deng, Jiaolong Yang, Dong Chen, Fang Wen, Xin Tong, CVPR, 2020. 1. 34Yu Deng, Jiaolong Yang, Dong Chen, Fang Wen, and Xin Tong. Disentangled and controllable face image generation via 3D imitative-contrastive learning. In CVPR, 2020. 1, 3, 4\n\nSigmoidweighted linear units for neural network function approximation in reinforcement learning. Stefan Elfwing, Eiji Uchibe, Kenji Doya, Neural Networks. 1072Stefan Elfwing, Eiji Uchibe, and Kenji Doya. Sigmoid- weighted linear units for neural network function approxima- tion in reinforcement learning. Neural Networks, 107, 2018. 2\n\nPrintsgan: synthetic fingerprint generator. TPAMI. J Joshua, Engelsma, A Steven, Grosz, Jain, 13Joshua J Engelsma, Steven A Grosz, and Anil K Jain. Prints- gan: synthetic fingerprint generator. TPAMI, 2022. 1, 3\n\nSemi-supervised adversarial learning to generate photorealistic face images of new identities from 3D morphable model. Baris Gecer, Binod Bhattarai, Josef Kittler, Tae-Kyun Kim, In ECCV. 3Baris Gecer, Binod Bhattarai, Josef Kittler, and Tae-Kyun Kim. Semi-supervised adversarial learning to generate pho- torealistic face images of new identities from 3D morphable model. In ECCV, 2018. 3\n\n3D guided fine-grained face manipulation. Zhenglin Geng, Chen Cao, Sergey Tulyakov, CVPR. Zhenglin Geng, Chen Cao, and Sergey Tulyakov. 3D guided fine-grained face manipulation. In CVPR, 2019. 3\n\nSai Saketh Rambhatla, and Abhinav Shrivastava. Towards discovery and attribution of open-world gan generated images. Sharath Girish, Saksham Suri, ICCV. Sharath Girish, Saksham Suri, Sai Saketh Rambhatla, and Abhinav Shrivastava. Towards discovery and attribution of open-world gan generated images. In ICCV, 2021. 7\n\n. Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio, 2020. 3Generative adversarial networks. Communications of the ACM. 6311Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio. Generative adversarial networks. Commu- nications of the ACM, 63(11), 2020. 3\n\nMS-Celeb-1M: A dataset and benchmark for large-scale face recognition. Yandong Guo, Lei Zhang, Yuxiao Hu, Xiaodong He, Jianfeng Gao, ECCV. 1Yandong Guo, Lei Zhang, Yuxiao Hu, Xiaodong He, and Jianfeng Gao. MS-Celeb-1M: A dataset and benchmark for large-scale face recognition. In ECCV, 2016. 1, 2\n\nDeep residual learning for image recognition. Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, CVPR. Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In CVPR, 2016. 1\n\nGans trained by a two time-scale update rule converge to a local nash equilibrium. NeurIPS, 30. Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, Sepp Hochreiter, 15Martin Heusel, Hubert Ramsauer, Thomas Unterthiner, Bernhard Nessler, and Sepp Hochreiter. Gans trained by a two time-scale update rule converge to a local nash equilib- rium. NeurIPS, 30, 2017. 1, 5\n\nDenoising diffusion probabilistic models. Jonathan Ho, Ajay Jain, Pieter Abbeel, NeurIPS. 331Jonathan Ho, Ajay Jain, and Pieter Abbeel. Denoising dif- fusion probabilistic models. NeurIPS, 33, 2020. 2, 3, 4, 6, 1\n\n. Jonathan Ho, Tim Salimans, arXiv:2207.12598Classifier-free diffusion guidance. arXiv preprintJonathan Ho and Tim Salimans. Classifier-free diffusion guidance. arXiv preprint arXiv:2207.12598, 2022. 5\n\nDisentangling factors of variation by mixing them. Qiyang Hu, Attila Szab\u00f3, Tiziano Portenier, Paolo Favaro, Matthias Zwicker, CVPR. Qiyang Hu, Attila Szab\u00f3, Tiziano Portenier, Paolo Favaro, and Matthias Zwicker. Disentangling factors of variation by mixing them. In CVPR, 2018. 3\n\nSail-vos 3d: A synthetic dataset and baselines for object detection and 3d mesh reconstruction from video data. Yuan-Ting Hu, Jiahong Wang, A Raymond, Alexander G Yeh, Schwing, CVPR. Yuan-Ting Hu, Jiahong Wang, Raymond A Yeh, and Alexan- der G Schwing. Sail-vos 3d: A synthetic dataset and base- lines for object detection and 3d mesh reconstruction from video data. In CVPR, 2021. 1\n\nLearning to align from scratch. Gary Huang, Marwan Mattar, Honglak Lee, Erik Learned-Miller, NeurIPS. 257Gary Huang, Marwan Mattar, Honglak Lee, and Erik Learned-Miller. Learning to align from scratch. NeurIPS, 25, 2012. 1, 6, 2, 7\n\nLabeled Faces in the Wild: A database forstudying face recognition in unconstrained environments. B Gary, Marwan Huang, Tamara Mattar, Eric Berg, Learned-Miller, Workshop on Faces in'Real-Life'Images: Detection, Alignment, and Recognition. 67Gary B Huang, Marwan Mattar, Tamara Berg, and Eric Learned-Miller. Labeled Faces in the Wild: A database forstudying face recognition in unconstrained environments. In Workshop on Faces in'Real-Life'Images: Detection, Alignment, and Recognition, 2008. 2, 6, 7\n\nCurricularFace: adaptive curriculum learning loss for deep face recognition. Yuge Huang, Yuhan Wang, Ying Tai, Xiaoming Liu, Pengcheng Shen, Shaoxin Li, Jilin Li, Feiyue Huang, CVPR. Yuge Huang, Yuhan Wang, Ying Tai, Xiaoming Liu, Pengcheng Shen, Shaoxin Li, Jilin Li, and Feiyue Huang. CurricularFace: adaptive curriculum learning loss for deep face recognition. In CVPR, 2020. 2\n\nBatch normalization: Accelerating deep network training by reducing internal covariate shift. Sergey Ioffe, Christian Szegedy, ICML. Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by reducing internal co- variate shift. In ICML, 2015. 4\n\nTowards detection of glasses in facial images. Xiaoyi Jiang, Michael Binkert, Bernard Achermann, Horst Bunke, Pattern Analysis & Applications. 31Xiaoyi Jiang, Michael Binkert, Bernard Achermann, and Horst Bunke. Towards detection of glasses in facial images. Pattern Analysis & Applications, 3(1), 2000. 5\n\nIJB-S: IARPA Janus Surveillance Video Benchmark. Brianna Nathan D Kalka, Maze, A James, Kevin O Duncan, Stephen Connor, Kaleb Elliott, Julia Hebert, Bryan, Jain, In BTAS. 7Nathan D Kalka, Brianna Maze, James A Duncan, Kevin O'Connor, Stephen Elliott, Kaleb Hebert, Julia Bryan, and Anil K Jain. IJB-S: IARPA Janus Surveillance Video Bench- mark. In BTAS, 2018. 7\n\nProgressive growing of gans for improved quality, stability, and variation. Tero Karras, Timo Aila, Samuli Laine, Jaakko Lehtinen, In ICLR. 2Tero Karras, Timo Aila, Samuli Laine, and Jaakko Lehtinen. Progressive growing of gans for improved quality, stability, and variation. In ICLR, 2018. 2\n\nA style-based generator architecture for generative adversarial networks. Tero Karras, Samuli Laine, Timo Aila, CVPR. 56Tero Karras, Samuli Laine, and Timo Aila. A style-based generator architecture for generative adversarial networks. In CVPR, 2019. 2, 3, 4, 5, 6\n\nAnalyzing and improving the image quality of stylegan. Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, Timo Aila, CVPR. 2020Tero Karras, Samuli Laine, Miika Aittala, Janne Hellsten, Jaakko Lehtinen, and Timo Aila. Analyzing and improving the image quality of stylegan. In CVPR, 2020. 2\n\n. Hyeongwoo Kim, Pablo Garrido, Ayush Tewari, Weipeng Xu, Justus Thies, Matthias Niessner, Patrick P\u00e9rez, Christian Richardt, Michael Zollh\u00f6fer, Christian Theobalt, Deep video portraits. TOG. 3Hyeongwoo Kim, Pablo Garrido, Ayush Tewari, Weipeng Xu, Justus Thies, Matthias Niessner, Patrick P\u00e9rez, Christian Richardt, Michael Zollh\u00f6fer, and Christian Theobalt. Deep video portraits. TOG, 2018. 3\n\nAdaFace: Quality adaptive margin for face recognition. Minchul Kim, Xiaoming Jain, Liu, CVPR. Minchul Kim, Anil K Jain, and Xiaoming Liu. AdaFace: Quality adaptive margin for face recognition. In CVPR, 2022. 1, 2, 6, 8, 3, 7\n\nCluster and aggregate: Face recognition with large probe set. Minchul Kim, Feng Liu, Anil Jain, Xiaoming Liu, 2022. 4NeurIPS. Minchul Kim, Feng Liu, Anil Jain, and Xiaoming Liu. Clus- ter and aggregate: Face recognition with large probe set. NeurIPS, 2022. 4\n\nAdam: A method for stochastic optimization. P Diederik, Jimmy Kingma, Ba, ICLR. Diederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In ICLR, 2015. 6\n\nSolving the problem of imbalanced dataset with synthetic image generation for cell classification using deep learning. David Kupas, Balazs Harangi, EMBC. David Kupas and Balazs Harangi. Solving the problem of imbalanced dataset with synthetic image generation for cell classification using deep learning. In EMBC, 2021. 1\n\nImproved precision and recall metric for assessing generative models. Tuomas Kynk\u00e4\u00e4nniemi, Tero Karras, Samuli Laine, Jaakko Lehtinen, Timo Aila, NeurIPS. 326Tuomas Kynk\u00e4\u00e4nniemi, Tero Karras, Samuli Laine, Jaakko Lehtinen, and Timo Aila. Improved precision and recall met- ric for assessing generative models. NeurIPS, 32, 2019. 6\n\nSrm: A style-based recalibration module for convolutional neural networks. Hyunjae Lee, Hyo-Eun Kim, Hyeonseob Nam, ICCV. HyunJae Lee, Hyo-Eun Kim, and Hyeonseob Nam. Srm: A style-based recalibration module for convolutional neural networks. In ICCV, 2019. 4\n\nConditional image-to-image translation. Jianxin Lin, Yingce Xia, Tao Qin, Zhibo Chen, Tie-Yan Liu, CVPR. Jianxin Lin, Yingce Xia, Tao Qin, Zhibo Chen, and Tie- Yan Liu. Conditional image-to-image translation. In CVPR, 2018. 3\n\nControllable and guided face synthesis for unconstrained face recognition. Feng Liu, Minchul Kim, Anil Jain, Xiaoming Liu, ECCV. 2022Feng Liu, Minchul Kim, Anil Jain, and Xiaoming Liu. Con- trollable and guided face synthesis for unconstrained face recognition. In ECCV, 2022. 3\n\nSphereFace: Deep hypersphere embedding for face recognition. Weiyang Liu, Yandong Wen, Zhiding Yu, Ming Li, Bhiksha Raj, Le Song, CVPR. Weiyang Liu, Yandong Wen, Zhiding Yu, Ming Li, Bhiksha Raj, and Le Song. SphereFace: Deep hypersphere embed- ding for face recognition. In CVPR, 2017. 2\n\nSpoof trace disentanglement for generic face anti-spoofing. Yaojie Liu, Xiaoming Liu, 2023. 3TPAMI45Yaojie Liu and Xiaoming Liu. Spoof trace disentanglement for generic face anti-spoofing. TPAMI, 45(3), 2023. 3\n\n. Ilya Loshchilov, Frank Hutter, arXiv:1711.05101Decoupled weight decay regularization. arXiv preprintIlya Loshchilov and Frank Hutter. Decoupled weight decay regularization. arXiv preprint arXiv:1711.05101, 2017. 6\n\nMOST-GAN: 3d morphable stylegan for disentangled face image manipulation. C Safa, Bernhard Medin, Anoop Egger, Ye Cherian, Joshua B Wang, Xiaoming Tenenbaum, Tim K Liu, Marks, AAAI. 2022Safa C. Medin, Bernhard Egger, Anoop Cherian, Ye Wang, Joshua B. Tenenbaum, Xiaoming Liu, and Tim K. Marks. MOST-GAN: 3d morphable stylegan for disentangled face image manipulation. In AAAI, 2022. 3\n\nAGEDB: the first manually collected, in-the-wild age database. Stylianos Moschoglou, Athanasios Papaioannou, Christos Sagonas, Jiankang Deng, Irene Kotsia, Stefanos Zafeiriou, CVPRW. 7Stylianos Moschoglou, Athanasios Papaioannou, Chris- tos Sagonas, Jiankang Deng, Irene Kotsia, and Stefanos Zafeiriou. AGEDB: the first manually collected, in-the-wild age database. In CVPRW, 2017. 2, 6, 7\n\nHoloGAN: Unsupervised learning of 3d representations from natural images. Thu Nguyen-Phuoc, Chuan Li, Lucas Theis, Christian Richardt, Yong-Liang Yang, ICCV. Thu Nguyen-Phuoc, Chuan Li, Lucas Theis, Christian Richardt, and Yong-Liang Yang. HoloGAN: Unsupervised learning of 3d representations from natural images. In ICCV, 2019. 3\n\nImproved denoising diffusion probabilistic models. Alexander Quinn, Nichol , Prafulla Dhariwal, PMLR, 2021. 3ICML. Alexander Quinn Nichol and Prafulla Dhariwal. Improved denoising diffusion probabilistic models. In ICML, pages 8162-8171. PMLR, 2021. 3\n\nSemisupervised monocular 3D face reconstruction with end-toend shape-preserved domain transfer. Jingtan Piao, Chen Qian, Hongsheng Li, ICCV. Jingtan Piao, Chen Qian, and Hongsheng Li. Semi- supervised monocular 3D face reconstruction with end-to- end shape-preserved domain transfer. In ICCV, 2019. 3\n\nSuttisak Wizadwongsa, and Supasorn Suwajanakorn. Diffusion autoencoders: Toward a meaningful and decodable representation. Konpat Preechakul, Nattanat Chatthee, CVPR. 2022Konpat Preechakul, Nattanat Chatthee, Suttisak Wizad- wongsa, and Supasorn Suwajanakorn. Diffusion autoen- coders: Toward a meaningful and decodable representation. In CVPR, 2022. 5\n\nGanimation: Anatomically-aware facial animation from a single image. Albert Pumarola, Antonio Agudo, M Aleix, Alberto Martinez, Francesc Sanfeliu, Moreno-Noguer, In ECCV. 3Albert Pumarola, Antonio Agudo, Aleix M Martinez, Al- berto Sanfeliu, and Francesc Moreno-Noguer. Ganimation: Anatomically-aware facial animation from a single image. In ECCV, 2018. 3\n\nSynFace: Face recognition with synthetic data. Haibo Qiu, Baosheng Yu, Dihong Gong, Zhifeng Li, Wei Liu, Dacheng Tao, ICCV. 7Haibo Qiu, Baosheng Yu, Dihong Gong, Zhifeng Li, Wei Liu, and Dacheng Tao. SynFace: Face recognition with syn- thetic data. In ICCV, 2021. 1, 3, 6, 7, 8\n\nHierarchical text-conditional image generation with clip latents. Aditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, Mark Chen, arXiv:2204.061253arXiv preprintAditya Ramesh, Prafulla Dhariwal, Alex Nichol, Casey Chu, and Mark Chen. Hierarchical text-conditional image gen- eration with clip latents. arXiv preprint arXiv:2204.06125, 2022. 3, 5, 2\n\nHigh-resolution image synthesis with latent diffusion models. Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, Bj\u00f6rn Ommer, CVPR. 2022Robin Rombach, Andreas Blattmann, Dominik Lorenz, Patrick Esser, and Bj\u00f6rn Ommer. High-resolution image syn- thesis with latent diffusion models. In CVPR, 2022. 3\n\nImproved techniques for training gans. Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, Xi Chen, NeurIPS. 296Tim Salimans, Ian Goodfellow, Wojciech Zaremba, Vicki Cheung, Alec Radford, and Xi Chen. Improved techniques for training gans. NeurIPS, 29, 2016. 6\n\nFrontal to profile face verification in the wild. Soumyadip Sengupta, Jun-Cheng Chen, Carlos Castillo, M Vishal, Rama Patel, David W Chellappa, Jacobs, WACV. 7Soumyadip Sengupta, Jun-Cheng Chen, Carlos Castillo, Vishal M Patel, Rama Chellappa, and David W Jacobs. Frontal to profile face verification in the wild. In WACV, 2016. 2, 6, 7\n\nDefake: Detection and attribution of fake images generated by text-to-image diffusion models. Zeyang Sha, Zheng Li, Ning Yu, Yang Zhang, arXiv:2210.06998arXiv preprintZeyang Sha, Zheng Li, Ning Yu, and Yang Zhang. De- fake: Detection and attribution of fake images gener- ated by text-to-image diffusion models. arXiv preprint arXiv:2210.06998, 2022. 7\n\nFacefeat-GAN: a two-stage approach for identity-preserving face synthesis. Yujun Shen, Bolei Zhou, Ping Luo, Xiaoou Tang, arXiv:1812.01288arXiv preprintYujun Shen, Bolei Zhou, Ping Luo, and Xiaoou Tang. Facefeat-GAN: a two-stage approach for identity-preserving face synthesis. arXiv preprint arXiv:1812.01288, 2018. 3\n\nDeep unsupervised learning using nonequilibrium thermodynamics. Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, Surya Ganguli, ICML. 23Jascha Sohl-Dickstein, Eric Weiss, Niru Maheswaranathan, and Surya Ganguli. Deep unsupervised learning using nonequilibrium thermodynamics. In ICML, 2015. 2, 3\n\nDenoising diffusion implicit models. Jiaming Song, Chenlin Meng, Stefano Ermon, ICLR, 2021. 26Jiaming Song, Chenlin Meng, and Stefano Ermon. Denois- ing diffusion implicit models. In ICLR, 2021. 2, 3, 6\n\nMaximum likelihood training of score-based diffusion models. Yang Song, Conor Durkan, Iain Murray, Stefano Ermon, NeurIPS. 343Yang Song, Conor Durkan, Iain Murray, and Stefano Ermon. Maximum likelihood training of score-based diffusion mod- els. NeurIPS, 34, 2021. 3\n\nGenerative modeling by estimating gradients of the data distribution. Yang Song, Stefano Ermon, NeurIPS. 32Yang Song and Stefano Ermon. Generative modeling by esti- mating gradients of the data distribution. NeurIPS, 32, 2019.\n\nImproved techniques for training score-based generative models. Yang Song, Stefano Ermon, NeurIPS. 333Yang Song and Stefano Ermon. Improved techniques for training score-based generative models. NeurIPS, 33:12438- 12448, 2020. 3\n\nNoise modeling, synthesis and classification for generic object anti-spoofing. Joel Stehouwer, Amin Jourabloo, Yaojie Liu, Xiaoming Liu, CVPR. 2020Joel Stehouwer, Amin Jourabloo, Yaojie Liu, and Xiaoming Liu. Noise modeling, synthesis and classification for generic object anti-spoofing. In CVPR, 2020. 3\n\nSingle image portrait relighting. Tiancheng Sun, Jonathan T Barron, Yun-Ta Tsai, Zexiang Xu, Xueming Yu, Graham Fyffe, Christoph Rhemann, Jay Busch, Paul E Debevec, Ravi Ramamoorthi, TOG. 3Tiancheng Sun, Jonathan T Barron, Yun-Ta Tsai, Zexiang Xu, Xueming Yu, Graham Fyffe, Christoph Rhemann, Jay Busch, Paul E Debevec, and Ravi Ramamoorthi. Single im- age portrait relighting. TOG, 2019. 3\n\nDisentangled representation learning gan for pose-invariant face recognition. Luan Tran, Xi Yin, Xiaoming Liu, CVPR. Luan Tran, Xi Yin, and Xiaoming Liu. Disentangled repre- sentation learning gan for pose-invariant face recognition. In CVPR, 2017. 3\n\nCem Anil, Thang To, Eric Cameracci, Shaad Boochoon, and Stan Birchfield. Training deep networks with synthetic data: Bridging the reality gap by domain randomization. Jonathan Tremblay, Aayush Prakash, David Acuna, Mark Brophy, Varun Jampani, CVPRW. Jonathan Tremblay, Aayush Prakash, David Acuna, Mark Brophy, Varun Jampani, Cem Anil, Thang To, Eric Cam- eracci, Shaad Boochoon, and Stan Birchfield. Training deep networks with synthetic data: Bridging the reality gap by do- main randomization. In CVPRW, 2018. 1\n\nDecaf: Generating fair synthetic data using causally-aware generative networks. Trent Boris Van Breugel, Jeroen Kyono, Mihaela Berrevoets, Van Der Schaar, NeurIPS. 341Boris van Breugel, Trent Kyono, Jeroen Berrevoets, and Mihaela van der Schaar. Decaf: Generating fair synthetic data using causally-aware generative networks. NeurIPS, 34:22221-22233, 2021. 1\n\nVisualizing data using t-SNE. Laurens Van Der Maaten, Geoffrey Hinton, Journal of Machine Learning Research. 4Laurens Van der Maaten and Geoffrey Hinton. Visualizing data using t-SNE. Journal of Machine Learning Research, 2008. 4\n\nAttention is all you need. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, Illia Polosukhin, NeurIPS. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszko- reit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In NeurIPS, 2017. 2\n\nCosFace: Large margin cosine loss for deep face recognition. Hao Wang, Yitong Wang, Zheng Zhou, Xing Ji, Dihong Gong, Jingchao Zhou, Zhifeng Li, Wei Liu, CVPR. Hao Wang, Yitong Wang, Zheng Zhou, Xing Ji, Dihong Gong, Jingchao Zhou, Zhifeng Li, and Wei Liu. CosFace: Large margin cosine loss for deep face recognition. In CVPR, 2018. 2\n\nCnn-generated images are surprisingly easy to spot... for now. Sheng-Yu Wang, Oliver Wang, Richard Zhang, Andrew Owens, Alexei A Efros, CVPR. Sheng-Yu Wang, Oliver Wang, Richard Zhang, Andrew Owens, and Alexei A Efros. Cnn-generated images are sur- prisingly easy to spot... for now. In CVPR, 2020. 7\n\nPretraining is all you need for image-to-image translation. Tengfei Wang, Ting Zhang, Bo Zhang, Hao Ouyang, Dong Chen, Qifeng Chen, Fang Wen, arXiv:2205.1295235arXiv preprintTengfei Wang, Ting Zhang, Bo Zhang, Hao Ouyang, Dong Chen, Qifeng Chen, and Fang Wen. Pretraining is all you need for image-to-image translation. arXiv preprint arXiv:2205.12952, 2022. 3, 5\n\nIARPA Janus Benchmark-B face dataset. Cameron Whitelam, Emma Taborsky, Austin Blanton, Brianna Maze, Jocelyn Adams, Tim Miller, Nathan Kalka, K Anil, James A Jain, Kristen Duncan, Allen, CVPRW. Cameron Whitelam, Emma Taborsky, Austin Blanton, Bri- anna Maze, Jocelyn Adams, Tim Miller, Nathan Kalka, Anil K Jain, James A Duncan, Kristen Allen, et al. IARPA Janus Benchmark-B face dataset. In CVPRW, 2017. 7\n\nRealtime glasses detection. Tianxing Wu, Tianxing Wu. Realtime glasses detection. https:// github.com/TianxingWu/realtime-glasses- detection, 2022. 5\n\nGroup normalization. Yuxin Wu, Kaiming He, ECCV. Yuxin Wu and Kaiming He. Group normalization. In ECCV, 2018. 2\n\nSynthetic latent fingerprint generator. Andre Brasil, Vieira Wyzykowski, Jain, WACV. 2023Andre Brasil Vieira Wyzykowski and Anil K Jain. Synthetic latent fingerprint generator. In WACV, 2023. 3\n\nElegant: Exchanging latent encodings with GAN for transferring multiple face attributes. Taihong Xiao, Jiapeng Hong, Jinwen Ma, In ECCV. 3Taihong Xiao, Jiapeng Hong, and Jinwen Ma. Elegant: Ex- changing latent encodings with GAN for transferring multi- ple face attributes. In ECCV, 2018. 3\n\nDong Yi, Zhen Lei, Shengcai Liao, Stan Z Li, arXiv:1411.7923Learning face representation from scratch. arXiv preprintDong Yi, Zhen Lei, Shengcai Liao, and Stan Z Li. Learn- ing face representation from scratch. arXiv preprint arXiv:1411.7923, 2014. 3\n\nAttributing fake images to gans: Learning and analyzing gan fingerprints. Ning Yu, S Larry, Mario Davis, Fritz, ICCV. Ning Yu, Larry S Davis, and Mario Fritz. Attributing fake images to gans: Learning and analyzing gan fingerprints. In ICCV, 2019. 7\n\nJoint face detection and alignment using multitask cascaded convolutional networks. Kaipeng Zhang, Zhanpeng Zhang, Zhifeng Li, Yu Qiao, Signal Processing Letters. 7Kaipeng Zhang, Zhanpeng Zhang, Zhifeng Li, and Yu Qiao. Joint face detection and alignment using multitask cascaded convolutional networks. Signal Processing Letters, 2016. 7\n\nCross-Pose LFW: A database for studying cross-pose face recognition in unconstrained environments. Beijing University of Posts and Telecommunications. Tianyue Zheng, Weihong Deng, Tech. Rep. 57Tianyue Zheng and Weihong Deng. Cross-Pose LFW: A database for studying cross-pose face recognition in un- constrained environments. Beijing University of Posts and Telecommunications, Tech. Rep, 5, 2018. 2, 6, 7\n\nCross-Age LFW: A database for studying cross-age face recognition in unconstrained environments. Tianyue Zheng, Weihong Deng, Jiani Hu, abs/1708.08197CoRR67Tianyue Zheng, Weihong Deng, and Jiani Hu. Cross-Age LFW: A database for studying cross-age face recognition in unconstrained environments. CoRR, abs/1708.08197, 2017. 2, 6, 7\n\nWebFace260M: A benchmark unveiling the power of million-scale deep face recognition. Zheng Zhu, Guan Huang, Jiankang Deng, Yun Ye, Junjie Huang, Xinze Chen, Jiagang Zhu, Tian Yang, Jiwen Lu, Dalong Du, CVPR. 74Zheng Zhu, Guan Huang, Jiankang Deng, Yun Ye, Junjie Huang, Xinze Chen, Jiagang Zhu, Tian Yang, Jiwen Lu, Dalong Du, et al. WebFace260M: A benchmark unveiling the power of million-scale deep face recognition. In CVPR, 2021. 1, 2, 3, 6, 7, 4\n\nSynthesis of covid-19 chest x-rays using unpaired image-to-image translation. Social network analysis and mining. Hasib Zunair, Ben Hamza, 2021. 111Hasib Zunair and A Ben Hamza. Synthesis of covid-19 chest x-rays using unpaired image-to-image translation. Social network analysis and mining, 11(1), 2021. 1\n\nSimilarity threshold. Threshold=0.3 is based on FR evaluation model having a threshold of 0.3080 for verification with TPR@FPR=0. E Miscelaneous, 01% : 97.17% on IJB-B. 79E. Miscelaneous Similarity threshold. Threshold=0.3 is based on FR evaluation model having a threshold of 0.3080 for verification with TPR@FPR=0.01% : 97.17% on IJB-B [79].\n\nWe use the early layers of face recognition model for style extractor backbone. Our rationale for adopting the early layers of the FR model, as opposed to that of the ImageNet-trained model is that the early layers extract low-level features and we wanted features optimized with the face dataset. But, it is possible to take other models as long as it generates low-level features. Evaluation on Harder Datasets. We evaluate on harder datasets. FPR=0.01% is widely used in practice and the scale of similarity is (\u22121, 1). addition to Fig.7 mathcingX id with CASIA-WebFace. matching allX 0 (generated) images against CASIA-WebFace at threshold=0.3, we get 0.0026% FMR. This implies that only a small fraction of CAISA-WebFace images are similar to the generated imagesFPR=0.01% is widely used in practice and the scale of similarity is (\u22121, 1). At threshold=0.3, FFHQ has 200 (2%) more unique subjects than DDPM, signaling a similar level of uniqueness. Style Extracting Model. We use the early layers of face recognition model for style extractor backbone. Our rationale for adopting the early layers of the FR model, as opposed to that of the ImageNet-trained model is that the early layers extract low-level features and we wanted features optimized with the face dataset. But, it is possible to take other models as long as it generates low-level features. Evaluation on Harder Datasets. We evaluate on harder datasets, IJB-B [79] (TPR@FPR=0.01%: 75.12) and TinyFace [10] (Rank1: 41.66). We include this result for future works to evaluate on harder datasets. Real and Generated Similarity Analysis. In addition to Fig.7 mathcingX id with CASIA-WebFace, matching allX 0 (generated) images against CASIA-WebFace at threshold=0.3, we get 0.0026% FMR. This implies that only a small fraction of CAISA-WebFace images are similar to the generated images.\n\nOur work falls into the category of 1) image generation using generative models and 2) synthetic labeled dataset generation. In the field of image generation, unfortunately, there are numerous well-known malicious applications of generative models. Fake images can be used to impersonate high-profile figures and create fake news. Conditional image generation models make the malicious use cases easier to adapt to different use cases because of user controllability. Fortunately, GAN-based generators produce subtle artifacts in the. F , Concerns We believe that the Machine Learning and Computer Vision community should strive together to minimize the negative societal impact. generated samples that allow the visual forgery detection [3,20,77,85F. Societal Concerns We believe that the Machine Learning and Computer Vision community should strive together to minimize the negative societal impact. Our work falls into the category of 1) image generation using generative models and 2) synthetic labeled dataset generation. In the field of image generation, unfortunately, there are numerous well-known malicious applications of generative models. Fake images can be used to impersonate high-profile figures and create fake news. Conditional image gen- eration models make the malicious use cases easier to adapt to different use cases because of user controllability. Fortunately, GAN-based generators produce subtle artifacts in the generated samples that allow the visual forgery detection [3,20,77,85].\n\nWith the recent advance in DDPM, the community is optimistic about detecting forgeries in diffusion models [62]. It is also known that proactive treatments on generated images increase the forgery detection performance [3], and as generative models become more sophisticated, proactive measures may be advised whenever possible. Synthetic dataset generation is. an effort to avoid infringing the privacy of individuals on the webWith the recent advance in DDPM, the community is optimistic about detecting forgeries in diffusion models [62]. It is also known that proactive treatments on generated images increase the forgery detection performance [3], and as generative models become more sophisticated, proactive measures may be advised whenever possible. Synthetic dataset generation is, on the other hand, an effort to avoid infringing the privacy of individuals on the web.\n\nCollecting large-scale datasets with informed consent is prohibitively challenging and the community uses web-crawled datasets for the lack of an alternative option. Therefore, efforts to create synthetic datasets with synthetic subjects can be a practical solution to this problem. In our method, we still use real images to train the generative models. We hope that research in synthetic dataset generation will eventually replace real images, not just in the recognition task. Large-scale face dataset is collected without informed consent and only a few evaluation datasets such as IJB-S [34] has IRB compliance for safe and ethical research. but also in the generative tasks as well, removing the need for using real datasets in any formLarge-scale face dataset is collected without informed consent and only a few evaluation datasets such as IJB-S [34] has IRB compliance for safe and ethical research. Collecting large-scale datasets with informed consent is prohibitively challenging and the community uses web-crawled datasets for the lack of an alternative option. Therefore, efforts to create synthetic datasets with synthetic subjects can be a practical solution to this problem. In our method, we still use real images to train the generative models. We hope that research in synthetic dataset generation will eventually replace real images, not just in the recognition task, but also in the generative tasks as well, removing the need for using real datasets in any form.\n\nFor preprocessing the training data CASIA-WebFace [29], we reference AdaFace [39] and use MTCNN [86] for alignment and cropping faces. For the backbone model definition, TFace [1] and for evaluation of LFW [30. G , Implementation Details and Code The code will be. CFP-FP [61], CPLFW [87], AgeDB [51] and CALFW [88], we use AdaFace repository [39G. Implementation Details and Code The code will be released at https://github.com/mk-minchul/dcface. For preprocessing the training data CASIA-WebFace [29], we reference AdaFace [39] and use MTCNN [86] for alignment and cropping faces. For the backbone model definition, TFace [1] and for evaluation of LFW [30], CFP-FP [61], CPLFW [87], AgeDB [51] and CALFW [88], we use AdaFace repository [39].\n", "annotations": {"author": "[{\"end\":133,\"start\":73},{\"end\":208,\"start\":134},{\"end\":280,\"start\":209},{\"end\":342,\"start\":281}]", "publisher": null, "author_last_name": "[{\"end\":84,\"start\":81},{\"end\":142,\"start\":139},{\"end\":218,\"start\":214},{\"end\":293,\"start\":290}]", "author_first_name": "[{\"end\":80,\"start\":73},{\"end\":138,\"start\":134},{\"end\":213,\"start\":209},{\"end\":289,\"start\":281}]", "author_affiliation": "[{\"end\":132,\"start\":86},{\"end\":207,\"start\":161},{\"end\":279,\"start\":233},{\"end\":341,\"start\":295}]", "title": "[{\"end\":70,\"start\":1},{\"end\":412,\"start\":343}]", "venue": null, "abstract": "[{\"end\":2166,\"start\":414}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b88\"},\"end\":2631,\"start\":2627},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":2799,\"start\":2795},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":2802,\"start\":2799},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":2880,\"start\":2877},{\"attributes\":{\"ref_id\":\"b88\"},\"end\":2883,\"start\":2880},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":3034,\"start\":3030},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":3037,\"start\":3034},{\"attributes\":{\"ref_id\":\"b71\"},\"end\":3040,\"start\":3037},{\"attributes\":{\"ref_id\":\"b89\"},\"end\":3043,\"start\":3040},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":3088,\"start\":3084},{\"attributes\":{\"ref_id\":\"b72\"},\"end\":3091,\"start\":3088},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":3434,\"start\":3430},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":3437,\"start\":3434},{\"attributes\":{\"ref_id\":\"b88\"},\"end\":3440,\"start\":3437},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":4163,\"start\":4160},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":4166,\"start\":4163},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":4180,\"start\":4176},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":4243,\"start\":4239},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":4300,\"start\":4296},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":5028,\"start\":5025},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":7269,\"start\":7265},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":7272,\"start\":7269},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":8583,\"start\":8579},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":8586,\"start\":8583},{\"attributes\":{\"ref_id\":\"b88\"},\"end\":8589,\"start\":8586},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":8627,\"start\":8623},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":8630,\"start\":8627},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":8633,\"start\":8630},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":8636,\"start\":8633},{\"attributes\":{\"ref_id\":\"b75\"},\"end\":8639,\"start\":8636},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":8718,\"start\":8714},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":8731,\"start\":8727},{\"attributes\":{\"ref_id\":\"b86\"},\"end\":8743,\"start\":8739},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":8755,\"start\":8751},{\"attributes\":{\"ref_id\":\"b87\"},\"end\":8770,\"start\":8766},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":8976,\"start\":8972},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":9124,\"start\":9121},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":9127,\"start\":9124},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":9130,\"start\":9127},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":9134,\"start\":9130},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":9138,\"start\":9134},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":9142,\"start\":9138},{\"attributes\":{\"ref_id\":\"b64\"},\"end\":9145,\"start\":9142},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":9224,\"start\":9220},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":9227,\"start\":9224},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":9230,\"start\":9227},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":9233,\"start\":9230},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":9236,\"start\":9233},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":9239,\"start\":9236},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":9242,\"start\":9239},{\"attributes\":{\"ref_id\":\"b82\"},\"end\":9245,\"start\":9242},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":9442,\"start\":9439},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":9475,\"start\":9471},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":9478,\"start\":9475},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":9481,\"start\":9478},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":9484,\"start\":9481},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":9487,\"start\":9484},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":9490,\"start\":9487},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":9493,\"start\":9490},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":9496,\"start\":9493},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":9835,\"start\":9831},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":9838,\"start\":9835},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":9842,\"start\":9838},{\"attributes\":{\"ref_id\":\"b64\"},\"end\":9846,\"start\":9842},{\"attributes\":{\"ref_id\":\"b65\"},\"end\":9850,\"start\":9846},{\"attributes\":{\"ref_id\":\"b66\"},\"end\":9854,\"start\":9850},{\"end\":9858,\"start\":9854},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":9995,\"start\":9992},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":9998,\"start\":9995},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":10001,\"start\":9998},{\"attributes\":{\"ref_id\":\"b77\"},\"end\":10004,\"start\":10001},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":10492,\"start\":10489},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":10495,\"start\":10492},{\"attributes\":{\"ref_id\":\"b83\"},\"end\":10498,\"start\":10495},{\"attributes\":{\"ref_id\":\"b88\"},\"end\":10501,\"start\":10498},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":10695,\"start\":10692},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":10698,\"start\":10695},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":10701,\"start\":10698},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":10731,\"start\":10727},{\"attributes\":{\"ref_id\":\"b81\"},\"end\":10734,\"start\":10731},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":10758,\"start\":10754},{\"attributes\":{\"ref_id\":\"b68\"},\"end\":10761,\"start\":10758},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":10886,\"start\":10882},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":10934,\"start\":10930},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":10991,\"start\":10988},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":11981,\"start\":11977},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":12163,\"start\":12159},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":12191,\"start\":12187},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":12467,\"start\":12463},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":12656,\"start\":12652},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":12659,\"start\":12656},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":12861,\"start\":12857},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":13452,\"start\":13448},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":13605,\"start\":13601},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":13620,\"start\":13616},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":13711,\"start\":13707},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":13858,\"start\":13854},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":14611,\"start\":14607},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":16334,\"start\":16330},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":16337,\"start\":16334},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":16339,\"start\":16337},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":17523,\"start\":17519},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":17541,\"start\":17538},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":18348,\"start\":18344},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":20273,\"start\":20269},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":20276,\"start\":20273},{\"attributes\":{\"ref_id\":\"b77\"},\"end\":20279,\"start\":20276},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":20490,\"start\":20486},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":21315,\"start\":21312},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":21354,\"start\":21350},{\"attributes\":{\"ref_id\":\"b79\"},\"end\":21357,\"start\":21354},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":21814,\"start\":21810},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":24286,\"start\":24282},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":24324,\"start\":24320},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":24357,\"start\":24353},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":24656,\"start\":24652},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":26040,\"start\":26037},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":26043,\"start\":26040},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":26337,\"start\":26333},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":26358,\"start\":26354},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":26405,\"start\":26401},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":26757,\"start\":26753},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":26760,\"start\":26757},{\"attributes\":{\"ref_id\":\"b64\"},\"end\":27019,\"start\":27015},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":27184,\"start\":27181},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":27187,\"start\":27184},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":27207,\"start\":27203},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":27238,\"start\":27234},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":27319,\"start\":27315},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":27332,\"start\":27328},{\"attributes\":{\"ref_id\":\"b86\"},\"end\":27344,\"start\":27340},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":27356,\"start\":27352},{\"attributes\":{\"ref_id\":\"b87\"},\"end\":27371,\"start\":27367},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":27603,\"start\":27599},{\"attributes\":{\"ref_id\":\"b88\"},\"end\":27635,\"start\":27631},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":27653,\"start\":27649},{\"attributes\":{\"ref_id\":\"b88\"},\"end\":29911,\"start\":29907},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":31066,\"start\":31062},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":31083,\"start\":31080},{\"end\":31961,\"start\":31956},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":34492,\"start\":34488},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":35052,\"start\":35048},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":36808,\"start\":36805},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":37191,\"start\":37188},{\"attributes\":{\"ref_id\":\"b73\"},\"end\":37869,\"start\":37865},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":37947,\"start\":37943},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":37961,\"start\":37958},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":38136,\"start\":38132},{\"attributes\":{\"ref_id\":\"b88\"},\"end\":38162,\"start\":38158},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":39205,\"start\":39201},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":46211,\"start\":46207},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":46239,\"start\":46235},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":46748,\"start\":46744},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":47696,\"start\":47692},{\"attributes\":{\"ref_id\":\"b88\"},\"end\":47725,\"start\":47721}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":42504,\"start\":42104},{\"attributes\":{\"id\":\"fig_3\"},\"end\":42926,\"start\":42505},{\"attributes\":{\"id\":\"fig_4\"},\"end\":43162,\"start\":42927},{\"attributes\":{\"id\":\"fig_5\"},\"end\":43710,\"start\":43163},{\"attributes\":{\"id\":\"fig_6\"},\"end\":44251,\"start\":43711},{\"attributes\":{\"id\":\"fig_7\"},\"end\":44308,\"start\":44252},{\"attributes\":{\"id\":\"fig_8\"},\"end\":44371,\"start\":44309},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":44855,\"start\":44372},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":45394,\"start\":44856},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":45640,\"start\":45395},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":46053,\"start\":45641},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":48495,\"start\":46054},{\"attributes\":{\"id\":\"tab_9\",\"type\":\"table\"},\"end\":48893,\"start\":48496}]", "paragraph": "[{\"end\":2884,\"start\":2182},{\"end\":3586,\"start\":2886},{\"end\":4028,\"start\":3588},{\"end\":4318,\"start\":4030},{\"end\":4816,\"start\":4374},{\"end\":5733,\"start\":4818},{\"end\":6134,\"start\":5735},{\"end\":6700,\"start\":6136},{\"end\":7422,\"start\":6702},{\"end\":7755,\"start\":7424},{\"end\":7807,\"start\":7757},{\"end\":8386,\"start\":7809},{\"end\":9002,\"start\":8404},{\"end\":10212,\"start\":9004},{\"end\":10852,\"start\":10214},{\"end\":11265,\"start\":10854},{\"end\":11669,\"start\":11287},{\"end\":12619,\"start\":11671},{\"end\":13041,\"start\":12635},{\"end\":13208,\"start\":13095},{\"end\":13949,\"start\":13274},{\"end\":14212,\"start\":13984},{\"end\":14311,\"start\":14308},{\"end\":15300,\"start\":14352},{\"end\":15526,\"start\":15316},{\"end\":16469,\"start\":15528},{\"end\":16877,\"start\":16471},{\"end\":18394,\"start\":17108},{\"end\":19241,\"start\":18555},{\"end\":20693,\"start\":19363},{\"end\":21439,\"start\":20725},{\"end\":21724,\"start\":21441},{\"end\":22390,\"start\":21747},{\"end\":22594,\"start\":22392},{\"end\":23052,\"start\":22657},{\"end\":23242,\"start\":23054},{\"end\":23448,\"start\":23244},{\"end\":23747,\"start\":23514},{\"end\":24939,\"start\":23806},{\"end\":25189,\"start\":25130},{\"end\":25557,\"start\":25246},{\"end\":25779,\"start\":25559},{\"end\":26231,\"start\":25781},{\"end\":27104,\"start\":26247},{\"end\":27904,\"start\":27106},{\"end\":28532,\"start\":27923},{\"end\":29237,\"start\":28534},{\"end\":30180,\"start\":29239},{\"end\":30560,\"start\":30221},{\"end\":30953,\"start\":30562},{\"end\":31829,\"start\":30990},{\"end\":33002,\"start\":31831},{\"end\":33528,\"start\":33017},{\"end\":34351,\"start\":33530},{\"end\":34860,\"start\":34427},{\"end\":35174,\"start\":34937},{\"end\":36156,\"start\":35241},{\"end\":36746,\"start\":36312},{\"end\":37472,\"start\":36748},{\"end\":38165,\"start\":37519},{\"end\":38620,\"start\":38215},{\"end\":38708,\"start\":38635},{\"end\":39092,\"start\":38710},{\"end\":39492,\"start\":39094},{\"end\":40154,\"start\":39494},{\"end\":40442,\"start\":40156},{\"end\":41674,\"start\":40444},{\"end\":42103,\"start\":41753}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":13094,\"start\":13042},{\"attributes\":{\"id\":\"formula_1\"},\"end\":13273,\"start\":13209},{\"attributes\":{\"id\":\"formula_2\"},\"end\":14307,\"start\":14287},{\"attributes\":{\"id\":\"formula_3\"},\"end\":16923,\"start\":16878},{\"attributes\":{\"id\":\"formula_4\"},\"end\":17045,\"start\":16923},{\"attributes\":{\"id\":\"formula_5\"},\"end\":17107,\"start\":17045},{\"attributes\":{\"id\":\"formula_6\"},\"end\":18554,\"start\":18395},{\"attributes\":{\"id\":\"formula_7\"},\"end\":19283,\"start\":19242},{\"attributes\":{\"id\":\"formula_8\"},\"end\":19362,\"start\":19283},{\"attributes\":{\"id\":\"formula_9\"},\"end\":22656,\"start\":22595},{\"attributes\":{\"id\":\"formula_10\"},\"end\":23513,\"start\":23449},{\"attributes\":{\"id\":\"formula_11\"},\"end\":23805,\"start\":23748},{\"attributes\":{\"id\":\"formula_12\"},\"end\":25129,\"start\":24940},{\"attributes\":{\"id\":\"formula_13\"},\"end\":25245,\"start\":25190},{\"attributes\":{\"id\":\"formula_14\"},\"end\":34936,\"start\":34861},{\"attributes\":{\"id\":\"formula_15\"},\"end\":35240,\"start\":35175},{\"attributes\":{\"id\":\"formula_16\"},\"end\":36255,\"start\":36190}]", "table_ref": "[{\"end\":27668,\"start\":27661},{\"end\":38851,\"start\":38844},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":39909,\"start\":39902}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":2180,\"start\":2168},{\"attributes\":{\"n\":\"1.\"},\"end\":4351,\"start\":4321},{\"end\":4372,\"start\":4354},{\"attributes\":{\"n\":\"2.\"},\"end\":8402,\"start\":8389},{\"attributes\":{\"n\":\"3.\"},\"end\":11285,\"start\":11268},{\"attributes\":{\"n\":\"3.1.\"},\"end\":12633,\"start\":12622},{\"attributes\":{\"n\":\"3.2.\"},\"end\":13982,\"start\":13952},{\"attributes\":{\"n\":\"1.\"},\"end\":14286,\"start\":14215},{\"end\":14350,\"start\":14314},{\"end\":15314,\"start\":15303},{\"attributes\":{\"n\":\"3.3.\"},\"end\":20723,\"start\":20696},{\"attributes\":{\"n\":\"4.\"},\"end\":21745,\"start\":21727},{\"attributes\":{\"n\":\"5.\"},\"end\":26245,\"start\":26234},{\"attributes\":{\"n\":\"5.1.\"},\"end\":27921,\"start\":27907},{\"end\":30199,\"start\":30183},{\"attributes\":{\"n\":\"5.2.\"},\"end\":30219,\"start\":30202},{\"attributes\":{\"n\":\"5.3.\"},\"end\":30988,\"start\":30956},{\"attributes\":{\"n\":\"6.\"},\"end\":33015,\"start\":33005},{\"end\":34376,\"start\":34354},{\"end\":34398,\"start\":34379},{\"end\":34425,\"start\":34401},{\"end\":36189,\"start\":36159},{\"end\":36283,\"start\":36257},{\"end\":36310,\"start\":36286},{\"end\":37517,\"start\":37475},{\"end\":38213,\"start\":38168},{\"end\":38633,\"start\":38623},{\"end\":41694,\"start\":41677},{\"end\":41724,\"start\":41697},{\"end\":41730,\"start\":41727},{\"end\":41751,\"start\":41733},{\"end\":42115,\"start\":42105},{\"end\":42516,\"start\":42506},{\"end\":42938,\"start\":42928},{\"end\":43169,\"start\":43164},{\"end\":43722,\"start\":43712},{\"end\":44263,\"start\":44253},{\"end\":44320,\"start\":44310},{\"end\":45405,\"start\":45396},{\"end\":45651,\"start\":45642}]", "table": "[{\"end\":44855,\"start\":44419},{\"end\":45394,\"start\":45072},{\"end\":46053,\"start\":45665},{\"end\":48495,\"start\":47908},{\"end\":48893,\"start\":48536}]", "figure_caption": "[{\"end\":42504,\"start\":42117},{\"end\":42926,\"start\":42518},{\"end\":43162,\"start\":42940},{\"end\":43710,\"start\":43171},{\"end\":44251,\"start\":43724},{\"end\":44308,\"start\":44265},{\"end\":44371,\"start\":44322},{\"end\":44419,\"start\":44374},{\"end\":45072,\"start\":44858},{\"end\":45640,\"start\":45407},{\"end\":45665,\"start\":45653},{\"end\":47908,\"start\":46056},{\"end\":48536,\"start\":48498}]", "figure_ref": "[{\"end\":4404,\"start\":4396},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":5440,\"start\":5434},{\"end\":6699,\"start\":6693},{\"end\":11387,\"start\":11381},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":12087,\"start\":12079},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":13578,\"start\":13572},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":14362,\"start\":14354},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":15831,\"start\":15825},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":17861,\"start\":17852},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":25399,\"start\":25391},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":25790,\"start\":25784},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":25941,\"start\":25935},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":26230,\"start\":26224},{\"end\":29185,\"start\":29179},{\"end\":31828,\"start\":31822},{\"end\":32178,\"start\":32170},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":35569,\"start\":35563},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":35650,\"start\":35642},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":37842,\"start\":37836},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":40945,\"start\":40932},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":41256,\"start\":41250},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":41762,\"start\":41756}]", "bib_author_first_name": "[{\"end\":51257,\"start\":51252},{\"end\":51424,\"start\":51418},{\"end\":51435,\"start\":51433},{\"end\":51444,\"start\":51441},{\"end\":51459,\"start\":51454},{\"end\":51473,\"start\":51465},{\"end\":51617,\"start\":51612},{\"end\":51621,\"start\":51618},{\"end\":51631,\"start\":51626},{\"end\":51636,\"start\":51632},{\"end\":51652,\"start\":51644},{\"end\":51654,\"start\":51653},{\"end\":51909,\"start\":51901},{\"end\":51921,\"start\":51915},{\"end\":51940,\"start\":51935},{\"end\":51962,\"start\":51955},{\"end\":51975,\"start\":51971},{\"end\":51988,\"start\":51982},{\"end\":52006,\"start\":51999},{\"end\":52024,\"start\":52016},{\"end\":52329,\"start\":52323},{\"end\":52343,\"start\":52337},{\"end\":52510,\"start\":52503},{\"end\":52527,\"start\":52522},{\"end\":52541,\"start\":52537},{\"end\":52554,\"start\":52549},{\"end\":52813,\"start\":52807},{\"end\":52825,\"start\":52821},{\"end\":52840,\"start\":52835},{\"end\":53107,\"start\":53102},{\"end\":53115,\"start\":53113},{\"end\":53127,\"start\":53122},{\"end\":53134,\"start\":53133},{\"end\":53148,\"start\":53142},{\"end\":53359,\"start\":53354},{\"end\":53374,\"start\":53367},{\"end\":53388,\"start\":53380},{\"end\":53598,\"start\":53592},{\"end\":53610,\"start\":53605},{\"end\":53625,\"start\":53617},{\"end\":53639,\"start\":53631},{\"end\":53651,\"start\":53644},{\"end\":53663,\"start\":53657},{\"end\":53970,\"start\":53962},{\"end\":53984,\"start\":53977},{\"end\":53999,\"start\":53992},{\"end\":54012,\"start\":54005},{\"end\":54027,\"start\":54019},{\"end\":54286,\"start\":54283},{\"end\":54296,\"start\":54293},{\"end\":54310,\"start\":54303},{\"end\":54325,\"start\":54319},{\"end\":54333,\"start\":54330},{\"end\":54340,\"start\":54338},{\"end\":54583,\"start\":54575},{\"end\":54593,\"start\":54590},{\"end\":54606,\"start\":54599},{\"end\":54620,\"start\":54612},{\"end\":54892,\"start\":54890},{\"end\":54907,\"start\":54899},{\"end\":54918,\"start\":54914},{\"end\":54929,\"start\":54925},{\"end\":54938,\"start\":54935},{\"end\":55240,\"start\":55234},{\"end\":55254,\"start\":55250},{\"end\":55268,\"start\":55263},{\"end\":55526,\"start\":55525},{\"end\":55546,\"start\":55545},{\"end\":55811,\"start\":55806},{\"end\":55824,\"start\":55819},{\"end\":55841,\"start\":55836},{\"end\":55859,\"start\":55851},{\"end\":56127,\"start\":56119},{\"end\":56138,\"start\":56134},{\"end\":56150,\"start\":56144},{\"end\":56397,\"start\":56390},{\"end\":56413,\"start\":56406},{\"end\":56596,\"start\":56593},{\"end\":56613,\"start\":56609},{\"end\":56634,\"start\":56629},{\"end\":56646,\"start\":56642},{\"end\":56656,\"start\":56651},{\"end\":56678,\"start\":56671},{\"end\":56691,\"start\":56686},{\"end\":56709,\"start\":56703},{\"end\":57075,\"start\":57068},{\"end\":57084,\"start\":57081},{\"end\":57098,\"start\":57092},{\"end\":57111,\"start\":57103},{\"end\":57124,\"start\":57116},{\"end\":57348,\"start\":57341},{\"end\":57360,\"start\":57353},{\"end\":57376,\"start\":57368},{\"end\":57386,\"start\":57382},{\"end\":57619,\"start\":57613},{\"end\":57634,\"start\":57628},{\"end\":57651,\"start\":57645},{\"end\":57673,\"start\":57665},{\"end\":57687,\"start\":57683},{\"end\":57953,\"start\":57945},{\"end\":57962,\"start\":57958},{\"end\":57975,\"start\":57969},{\"end\":58127,\"start\":58119},{\"end\":58135,\"start\":58132},{\"end\":58377,\"start\":58371},{\"end\":58388,\"start\":58382},{\"end\":58403,\"start\":58396},{\"end\":58420,\"start\":58415},{\"end\":58437,\"start\":58429},{\"end\":58723,\"start\":58714},{\"end\":58735,\"start\":58728},{\"end\":58743,\"start\":58742},{\"end\":58762,\"start\":58753},{\"end\":58764,\"start\":58763},{\"end\":59023,\"start\":59019},{\"end\":59037,\"start\":59031},{\"end\":59053,\"start\":59046},{\"end\":59063,\"start\":59059},{\"end\":59319,\"start\":59318},{\"end\":59332,\"start\":59326},{\"end\":59346,\"start\":59340},{\"end\":59359,\"start\":59355},{\"end\":59804,\"start\":59800},{\"end\":59817,\"start\":59812},{\"end\":59828,\"start\":59824},{\"end\":59842,\"start\":59834},{\"end\":59857,\"start\":59848},{\"end\":59871,\"start\":59864},{\"end\":59881,\"start\":59876},{\"end\":59892,\"start\":59886},{\"end\":60205,\"start\":60199},{\"end\":60222,\"start\":60213},{\"end\":60441,\"start\":60435},{\"end\":60456,\"start\":60449},{\"end\":60473,\"start\":60466},{\"end\":60490,\"start\":60485},{\"end\":60751,\"start\":60744},{\"end\":60775,\"start\":60774},{\"end\":60788,\"start\":60783},{\"end\":60790,\"start\":60789},{\"end\":60806,\"start\":60799},{\"end\":60820,\"start\":60815},{\"end\":60835,\"start\":60830},{\"end\":61139,\"start\":61135},{\"end\":61152,\"start\":61148},{\"end\":61165,\"start\":61159},{\"end\":61179,\"start\":61173},{\"end\":61431,\"start\":61427},{\"end\":61446,\"start\":61440},{\"end\":61458,\"start\":61454},{\"end\":61678,\"start\":61674},{\"end\":61693,\"start\":61687},{\"end\":61706,\"start\":61701},{\"end\":61721,\"start\":61716},{\"end\":61738,\"start\":61732},{\"end\":61753,\"start\":61749},{\"end\":61944,\"start\":61935},{\"end\":61955,\"start\":61950},{\"end\":61970,\"start\":61965},{\"end\":61986,\"start\":61979},{\"end\":61997,\"start\":61991},{\"end\":62013,\"start\":62005},{\"end\":62031,\"start\":62024},{\"end\":62048,\"start\":62039},{\"end\":62066,\"start\":62059},{\"end\":62087,\"start\":62078},{\"end\":62391,\"start\":62384},{\"end\":62405,\"start\":62397},{\"end\":62624,\"start\":62617},{\"end\":62634,\"start\":62630},{\"end\":62644,\"start\":62640},{\"end\":62659,\"start\":62651},{\"end\":62860,\"start\":62859},{\"end\":62876,\"start\":62871},{\"end\":63113,\"start\":63108},{\"end\":63127,\"start\":63121},{\"end\":63388,\"start\":63382},{\"end\":63407,\"start\":63403},{\"end\":63422,\"start\":63416},{\"end\":63436,\"start\":63430},{\"end\":63451,\"start\":63447},{\"end\":63726,\"start\":63719},{\"end\":63739,\"start\":63732},{\"end\":63754,\"start\":63745},{\"end\":63951,\"start\":63944},{\"end\":63963,\"start\":63957},{\"end\":63972,\"start\":63969},{\"end\":63983,\"start\":63978},{\"end\":63997,\"start\":63990},{\"end\":64210,\"start\":64206},{\"end\":64223,\"start\":64216},{\"end\":64233,\"start\":64229},{\"end\":64248,\"start\":64240},{\"end\":64479,\"start\":64472},{\"end\":64492,\"start\":64485},{\"end\":64505,\"start\":64498},{\"end\":64514,\"start\":64510},{\"end\":64526,\"start\":64519},{\"end\":64534,\"start\":64532},{\"end\":64767,\"start\":64761},{\"end\":64781,\"start\":64773},{\"end\":64919,\"start\":64915},{\"end\":64937,\"start\":64932},{\"end\":65205,\"start\":65204},{\"end\":65220,\"start\":65212},{\"end\":65233,\"start\":65228},{\"end\":65243,\"start\":65241},{\"end\":65259,\"start\":65253},{\"end\":65261,\"start\":65260},{\"end\":65276,\"start\":65268},{\"end\":65291,\"start\":65288},{\"end\":65293,\"start\":65292},{\"end\":65588,\"start\":65579},{\"end\":65611,\"start\":65601},{\"end\":65633,\"start\":65625},{\"end\":65651,\"start\":65643},{\"end\":65663,\"start\":65658},{\"end\":65680,\"start\":65672},{\"end\":65984,\"start\":65981},{\"end\":66004,\"start\":65999},{\"end\":66014,\"start\":66009},{\"end\":66031,\"start\":66022},{\"end\":66052,\"start\":66042},{\"end\":66299,\"start\":66290},{\"end\":66313,\"start\":66307},{\"end\":66324,\"start\":66316},{\"end\":66595,\"start\":66588},{\"end\":66606,\"start\":66602},{\"end\":66622,\"start\":66613},{\"end\":66923,\"start\":66917},{\"end\":66944,\"start\":66936},{\"end\":67223,\"start\":67217},{\"end\":67241,\"start\":67234},{\"end\":67250,\"start\":67249},{\"end\":67265,\"start\":67258},{\"end\":67284,\"start\":67276},{\"end\":67557,\"start\":67552},{\"end\":67571,\"start\":67563},{\"end\":67582,\"start\":67576},{\"end\":67596,\"start\":67589},{\"end\":67604,\"start\":67601},{\"end\":67617,\"start\":67610},{\"end\":67856,\"start\":67850},{\"end\":67873,\"start\":67865},{\"end\":67888,\"start\":67884},{\"end\":67902,\"start\":67897},{\"end\":67912,\"start\":67908},{\"end\":68206,\"start\":68201},{\"end\":68223,\"start\":68216},{\"end\":68242,\"start\":68235},{\"end\":68258,\"start\":68251},{\"end\":68271,\"start\":68266},{\"end\":68495,\"start\":68492},{\"end\":68509,\"start\":68506},{\"end\":68530,\"start\":68522},{\"end\":68545,\"start\":68540},{\"end\":68558,\"start\":68554},{\"end\":68570,\"start\":68568},{\"end\":68798,\"start\":68789},{\"end\":68818,\"start\":68809},{\"end\":68831,\"start\":68825},{\"end\":68843,\"start\":68842},{\"end\":68856,\"start\":68852},{\"end\":68869,\"start\":68864},{\"end\":68871,\"start\":68870},{\"end\":69177,\"start\":69171},{\"end\":69188,\"start\":69183},{\"end\":69197,\"start\":69193},{\"end\":69206,\"start\":69202},{\"end\":69511,\"start\":69506},{\"end\":69523,\"start\":69518},{\"end\":69534,\"start\":69530},{\"end\":69546,\"start\":69540},{\"end\":69821,\"start\":69815},{\"end\":69842,\"start\":69838},{\"end\":69854,\"start\":69850},{\"end\":69877,\"start\":69872},{\"end\":70100,\"start\":70093},{\"end\":70114,\"start\":70107},{\"end\":70128,\"start\":70121},{\"end\":70325,\"start\":70321},{\"end\":70337,\"start\":70332},{\"end\":70350,\"start\":70346},{\"end\":70366,\"start\":70359},{\"end\":70602,\"start\":70598},{\"end\":70616,\"start\":70609},{\"end\":70824,\"start\":70820},{\"end\":70838,\"start\":70831},{\"end\":71069,\"start\":71065},{\"end\":71085,\"start\":71081},{\"end\":71103,\"start\":71097},{\"end\":71117,\"start\":71109},{\"end\":71335,\"start\":71326},{\"end\":71349,\"start\":71341},{\"end\":71351,\"start\":71350},{\"end\":71366,\"start\":71360},{\"end\":71380,\"start\":71373},{\"end\":71392,\"start\":71385},{\"end\":71403,\"start\":71397},{\"end\":71420,\"start\":71411},{\"end\":71433,\"start\":71430},{\"end\":71445,\"start\":71441},{\"end\":71447,\"start\":71446},{\"end\":71461,\"start\":71457},{\"end\":71766,\"start\":71762},{\"end\":71775,\"start\":71773},{\"end\":71789,\"start\":71781},{\"end\":72111,\"start\":72103},{\"end\":72128,\"start\":72122},{\"end\":72143,\"start\":72138},{\"end\":72155,\"start\":72151},{\"end\":72169,\"start\":72164},{\"end\":72537,\"start\":72532},{\"end\":72563,\"start\":72557},{\"end\":72578,\"start\":72571},{\"end\":72849,\"start\":72842},{\"end\":72874,\"start\":72866},{\"end\":73076,\"start\":73070},{\"end\":73090,\"start\":73086},{\"end\":73104,\"start\":73100},{\"end\":73118,\"start\":73113},{\"end\":73135,\"start\":73130},{\"end\":73148,\"start\":73143},{\"end\":73150,\"start\":73149},{\"end\":73164,\"start\":73158},{\"end\":73178,\"start\":73173},{\"end\":73439,\"start\":73436},{\"end\":73452,\"start\":73446},{\"end\":73464,\"start\":73459},{\"end\":73475,\"start\":73471},{\"end\":73486,\"start\":73480},{\"end\":73501,\"start\":73493},{\"end\":73515,\"start\":73508},{\"end\":73523,\"start\":73520},{\"end\":73782,\"start\":73774},{\"end\":73795,\"start\":73789},{\"end\":73809,\"start\":73802},{\"end\":73823,\"start\":73817},{\"end\":73837,\"start\":73831},{\"end\":73839,\"start\":73838},{\"end\":74080,\"start\":74073},{\"end\":74091,\"start\":74087},{\"end\":74101,\"start\":74099},{\"end\":74112,\"start\":74109},{\"end\":74125,\"start\":74121},{\"end\":74138,\"start\":74132},{\"end\":74149,\"start\":74145},{\"end\":74423,\"start\":74416},{\"end\":74438,\"start\":74434},{\"end\":74455,\"start\":74449},{\"end\":74472,\"start\":74465},{\"end\":74486,\"start\":74479},{\"end\":74497,\"start\":74494},{\"end\":74512,\"start\":74506},{\"end\":74521,\"start\":74520},{\"end\":74533,\"start\":74528},{\"end\":74535,\"start\":74534},{\"end\":74549,\"start\":74542},{\"end\":74822,\"start\":74814},{\"end\":74963,\"start\":74958},{\"end\":74975,\"start\":74968},{\"end\":75095,\"start\":75090},{\"end\":75110,\"start\":75104},{\"end\":75341,\"start\":75334},{\"end\":75355,\"start\":75348},{\"end\":75368,\"start\":75362},{\"end\":75541,\"start\":75537},{\"end\":75550,\"start\":75546},{\"end\":75564,\"start\":75556},{\"end\":75575,\"start\":75571},{\"end\":75577,\"start\":75576},{\"end\":75867,\"start\":75863},{\"end\":75873,\"start\":75872},{\"end\":75886,\"start\":75881},{\"end\":76131,\"start\":76124},{\"end\":76147,\"start\":76139},{\"end\":76162,\"start\":76155},{\"end\":76169,\"start\":76167},{\"end\":76538,\"start\":76531},{\"end\":76553,\"start\":76546},{\"end\":76891,\"start\":76884},{\"end\":76906,\"start\":76899},{\"end\":76918,\"start\":76913},{\"end\":77210,\"start\":77205},{\"end\":77220,\"start\":77216},{\"end\":77236,\"start\":77228},{\"end\":77246,\"start\":77243},{\"end\":77257,\"start\":77251},{\"end\":77270,\"start\":77265},{\"end\":77284,\"start\":77277},{\"end\":77294,\"start\":77290},{\"end\":77306,\"start\":77301},{\"end\":77317,\"start\":77311},{\"end\":77691,\"start\":77686},{\"end\":78011,\"start\":78010},{\"end\":80616,\"start\":80615},{\"end\":84170,\"start\":84169}]", "bib_author_last_name": "[{\"end\":51178,\"start\":51173},{\"end\":51265,\"start\":51258},{\"end\":51431,\"start\":51425},{\"end\":51439,\"start\":51436},{\"end\":51452,\"start\":51445},{\"end\":51463,\"start\":51460},{\"end\":51477,\"start\":51474},{\"end\":51624,\"start\":51622},{\"end\":51642,\"start\":51637},{\"end\":51658,\"start\":51655},{\"end\":51913,\"start\":51910},{\"end\":51933,\"start\":51922},{\"end\":51953,\"start\":51941},{\"end\":51969,\"start\":51963},{\"end\":51980,\"start\":51976},{\"end\":51997,\"start\":51989},{\"end\":52014,\"start\":52007},{\"end\":52029,\"start\":52025},{\"end\":52335,\"start\":52330},{\"end\":52350,\"start\":52344},{\"end\":52520,\"start\":52511},{\"end\":52535,\"start\":52528},{\"end\":52547,\"start\":52542},{\"end\":52560,\"start\":52555},{\"end\":52819,\"start\":52814},{\"end\":52833,\"start\":52826},{\"end\":52849,\"start\":52841},{\"end\":53111,\"start\":53108},{\"end\":53120,\"start\":53116},{\"end\":53131,\"start\":53128},{\"end\":53140,\"start\":53135},{\"end\":53155,\"start\":53149},{\"end\":53166,\"start\":53157},{\"end\":53365,\"start\":53360},{\"end\":53378,\"start\":53375},{\"end\":53393,\"start\":53389},{\"end\":53603,\"start\":53599},{\"end\":53615,\"start\":53611},{\"end\":53629,\"start\":53626},{\"end\":53642,\"start\":53640},{\"end\":53655,\"start\":53652},{\"end\":53668,\"start\":53664},{\"end\":53975,\"start\":53971},{\"end\":53990,\"start\":53985},{\"end\":54003,\"start\":54000},{\"end\":54017,\"start\":54013},{\"end\":54037,\"start\":54028},{\"end\":54291,\"start\":54287},{\"end\":54301,\"start\":54297},{\"end\":54317,\"start\":54311},{\"end\":54328,\"start\":54326},{\"end\":54336,\"start\":54334},{\"end\":54348,\"start\":54341},{\"end\":54588,\"start\":54584},{\"end\":54597,\"start\":54594},{\"end\":54610,\"start\":54607},{\"end\":54630,\"start\":54621},{\"end\":54897,\"start\":54893},{\"end\":54912,\"start\":54908},{\"end\":54923,\"start\":54919},{\"end\":54933,\"start\":54930},{\"end\":54943,\"start\":54939},{\"end\":55248,\"start\":55241},{\"end\":55261,\"start\":55255},{\"end\":55273,\"start\":55269},{\"end\":55533,\"start\":55527},{\"end\":55543,\"start\":55535},{\"end\":55553,\"start\":55547},{\"end\":55560,\"start\":55555},{\"end\":55566,\"start\":55562},{\"end\":55817,\"start\":55812},{\"end\":55834,\"start\":55825},{\"end\":55849,\"start\":55842},{\"end\":55863,\"start\":55860},{\"end\":56132,\"start\":56128},{\"end\":56142,\"start\":56139},{\"end\":56159,\"start\":56151},{\"end\":56404,\"start\":56398},{\"end\":56418,\"start\":56414},{\"end\":56607,\"start\":56597},{\"end\":56627,\"start\":56614},{\"end\":56640,\"start\":56635},{\"end\":56649,\"start\":56647},{\"end\":56669,\"start\":56657},{\"end\":56684,\"start\":56679},{\"end\":56701,\"start\":56692},{\"end\":56716,\"start\":56710},{\"end\":57079,\"start\":57076},{\"end\":57090,\"start\":57085},{\"end\":57101,\"start\":57099},{\"end\":57114,\"start\":57112},{\"end\":57128,\"start\":57125},{\"end\":57351,\"start\":57349},{\"end\":57366,\"start\":57361},{\"end\":57380,\"start\":57377},{\"end\":57390,\"start\":57387},{\"end\":57626,\"start\":57620},{\"end\":57643,\"start\":57635},{\"end\":57663,\"start\":57652},{\"end\":57681,\"start\":57674},{\"end\":57698,\"start\":57688},{\"end\":57956,\"start\":57954},{\"end\":57967,\"start\":57963},{\"end\":57982,\"start\":57976},{\"end\":58130,\"start\":58128},{\"end\":58144,\"start\":58136},{\"end\":58380,\"start\":58378},{\"end\":58394,\"start\":58389},{\"end\":58413,\"start\":58404},{\"end\":58427,\"start\":58421},{\"end\":58445,\"start\":58438},{\"end\":58726,\"start\":58724},{\"end\":58740,\"start\":58736},{\"end\":58751,\"start\":58744},{\"end\":58768,\"start\":58765},{\"end\":58777,\"start\":58770},{\"end\":59029,\"start\":59024},{\"end\":59044,\"start\":59038},{\"end\":59057,\"start\":59054},{\"end\":59078,\"start\":59064},{\"end\":59324,\"start\":59320},{\"end\":59338,\"start\":59333},{\"end\":59353,\"start\":59347},{\"end\":59364,\"start\":59360},{\"end\":59380,\"start\":59366},{\"end\":59810,\"start\":59805},{\"end\":59822,\"start\":59818},{\"end\":59832,\"start\":59829},{\"end\":59846,\"start\":59843},{\"end\":59862,\"start\":59858},{\"end\":59874,\"start\":59872},{\"end\":59884,\"start\":59882},{\"end\":59898,\"start\":59893},{\"end\":60211,\"start\":60206},{\"end\":60230,\"start\":60223},{\"end\":60447,\"start\":60442},{\"end\":60464,\"start\":60457},{\"end\":60483,\"start\":60474},{\"end\":60496,\"start\":60491},{\"end\":60766,\"start\":60752},{\"end\":60772,\"start\":60768},{\"end\":60781,\"start\":60776},{\"end\":60797,\"start\":60791},{\"end\":60813,\"start\":60807},{\"end\":60828,\"start\":60821},{\"end\":60842,\"start\":60836},{\"end\":60849,\"start\":60844},{\"end\":60855,\"start\":60851},{\"end\":61146,\"start\":61140},{\"end\":61157,\"start\":61153},{\"end\":61171,\"start\":61166},{\"end\":61188,\"start\":61180},{\"end\":61438,\"start\":61432},{\"end\":61452,\"start\":61447},{\"end\":61463,\"start\":61459},{\"end\":61685,\"start\":61679},{\"end\":61699,\"start\":61694},{\"end\":61714,\"start\":61707},{\"end\":61730,\"start\":61722},{\"end\":61747,\"start\":61739},{\"end\":61758,\"start\":61754},{\"end\":61948,\"start\":61945},{\"end\":61963,\"start\":61956},{\"end\":61977,\"start\":61971},{\"end\":61989,\"start\":61987},{\"end\":62003,\"start\":61998},{\"end\":62022,\"start\":62014},{\"end\":62037,\"start\":62032},{\"end\":62057,\"start\":62049},{\"end\":62076,\"start\":62067},{\"end\":62096,\"start\":62088},{\"end\":62395,\"start\":62392},{\"end\":62410,\"start\":62406},{\"end\":62415,\"start\":62412},{\"end\":62628,\"start\":62625},{\"end\":62638,\"start\":62635},{\"end\":62649,\"start\":62645},{\"end\":62663,\"start\":62660},{\"end\":62869,\"start\":62861},{\"end\":62883,\"start\":62877},{\"end\":62887,\"start\":62885},{\"end\":63119,\"start\":63114},{\"end\":63135,\"start\":63128},{\"end\":63401,\"start\":63389},{\"end\":63414,\"start\":63408},{\"end\":63428,\"start\":63423},{\"end\":63445,\"start\":63437},{\"end\":63456,\"start\":63452},{\"end\":63730,\"start\":63727},{\"end\":63743,\"start\":63740},{\"end\":63758,\"start\":63755},{\"end\":63955,\"start\":63952},{\"end\":63967,\"start\":63964},{\"end\":63976,\"start\":63973},{\"end\":63988,\"start\":63984},{\"end\":64001,\"start\":63998},{\"end\":64214,\"start\":64211},{\"end\":64227,\"start\":64224},{\"end\":64238,\"start\":64234},{\"end\":64252,\"start\":64249},{\"end\":64483,\"start\":64480},{\"end\":64496,\"start\":64493},{\"end\":64508,\"start\":64506},{\"end\":64517,\"start\":64515},{\"end\":64530,\"start\":64527},{\"end\":64539,\"start\":64535},{\"end\":64771,\"start\":64768},{\"end\":64785,\"start\":64782},{\"end\":64930,\"start\":64920},{\"end\":64944,\"start\":64938},{\"end\":65210,\"start\":65206},{\"end\":65226,\"start\":65221},{\"end\":65239,\"start\":65234},{\"end\":65251,\"start\":65244},{\"end\":65266,\"start\":65262},{\"end\":65286,\"start\":65277},{\"end\":65297,\"start\":65294},{\"end\":65304,\"start\":65299},{\"end\":65599,\"start\":65589},{\"end\":65623,\"start\":65612},{\"end\":65641,\"start\":65634},{\"end\":65656,\"start\":65652},{\"end\":65670,\"start\":65664},{\"end\":65690,\"start\":65681},{\"end\":65997,\"start\":65985},{\"end\":66007,\"start\":66005},{\"end\":66020,\"start\":66015},{\"end\":66040,\"start\":66032},{\"end\":66057,\"start\":66053},{\"end\":66305,\"start\":66300},{\"end\":66333,\"start\":66325},{\"end\":66600,\"start\":66596},{\"end\":66611,\"start\":66607},{\"end\":66625,\"start\":66623},{\"end\":66934,\"start\":66924},{\"end\":66953,\"start\":66945},{\"end\":67232,\"start\":67224},{\"end\":67247,\"start\":67242},{\"end\":67256,\"start\":67251},{\"end\":67274,\"start\":67266},{\"end\":67293,\"start\":67285},{\"end\":67308,\"start\":67295},{\"end\":67561,\"start\":67558},{\"end\":67574,\"start\":67572},{\"end\":67587,\"start\":67583},{\"end\":67599,\"start\":67597},{\"end\":67608,\"start\":67605},{\"end\":67621,\"start\":67618},{\"end\":67863,\"start\":67857},{\"end\":67882,\"start\":67874},{\"end\":67895,\"start\":67889},{\"end\":67906,\"start\":67903},{\"end\":67917,\"start\":67913},{\"end\":68214,\"start\":68207},{\"end\":68233,\"start\":68224},{\"end\":68249,\"start\":68243},{\"end\":68264,\"start\":68259},{\"end\":68277,\"start\":68272},{\"end\":68504,\"start\":68496},{\"end\":68520,\"start\":68510},{\"end\":68538,\"start\":68531},{\"end\":68552,\"start\":68546},{\"end\":68566,\"start\":68559},{\"end\":68575,\"start\":68571},{\"end\":68807,\"start\":68799},{\"end\":68823,\"start\":68819},{\"end\":68840,\"start\":68832},{\"end\":68850,\"start\":68844},{\"end\":68862,\"start\":68857},{\"end\":68881,\"start\":68872},{\"end\":68889,\"start\":68883},{\"end\":69181,\"start\":69178},{\"end\":69191,\"start\":69189},{\"end\":69200,\"start\":69198},{\"end\":69212,\"start\":69207},{\"end\":69516,\"start\":69512},{\"end\":69528,\"start\":69524},{\"end\":69538,\"start\":69535},{\"end\":69551,\"start\":69547},{\"end\":69836,\"start\":69822},{\"end\":69848,\"start\":69843},{\"end\":69870,\"start\":69855},{\"end\":69885,\"start\":69878},{\"end\":70105,\"start\":70101},{\"end\":70119,\"start\":70115},{\"end\":70134,\"start\":70129},{\"end\":70330,\"start\":70326},{\"end\":70344,\"start\":70338},{\"end\":70357,\"start\":70351},{\"end\":70372,\"start\":70367},{\"end\":70607,\"start\":70603},{\"end\":70622,\"start\":70617},{\"end\":70829,\"start\":70825},{\"end\":70844,\"start\":70839},{\"end\":71079,\"start\":71070},{\"end\":71095,\"start\":71086},{\"end\":71107,\"start\":71104},{\"end\":71121,\"start\":71118},{\"end\":71339,\"start\":71336},{\"end\":71358,\"start\":71352},{\"end\":71371,\"start\":71367},{\"end\":71383,\"start\":71381},{\"end\":71395,\"start\":71393},{\"end\":71409,\"start\":71404},{\"end\":71428,\"start\":71421},{\"end\":71439,\"start\":71434},{\"end\":71455,\"start\":71448},{\"end\":71473,\"start\":71462},{\"end\":71771,\"start\":71767},{\"end\":71779,\"start\":71776},{\"end\":71793,\"start\":71790},{\"end\":72120,\"start\":72112},{\"end\":72136,\"start\":72129},{\"end\":72149,\"start\":72144},{\"end\":72162,\"start\":72156},{\"end\":72177,\"start\":72170},{\"end\":72555,\"start\":72538},{\"end\":72569,\"start\":72564},{\"end\":72589,\"start\":72579},{\"end\":72605,\"start\":72591},{\"end\":72864,\"start\":72850},{\"end\":72881,\"start\":72875},{\"end\":73084,\"start\":73077},{\"end\":73098,\"start\":73091},{\"end\":73111,\"start\":73105},{\"end\":73128,\"start\":73119},{\"end\":73141,\"start\":73136},{\"end\":73156,\"start\":73151},{\"end\":73171,\"start\":73165},{\"end\":73189,\"start\":73179},{\"end\":73444,\"start\":73440},{\"end\":73457,\"start\":73453},{\"end\":73469,\"start\":73465},{\"end\":73478,\"start\":73476},{\"end\":73491,\"start\":73487},{\"end\":73506,\"start\":73502},{\"end\":73518,\"start\":73516},{\"end\":73527,\"start\":73524},{\"end\":73787,\"start\":73783},{\"end\":73800,\"start\":73796},{\"end\":73815,\"start\":73810},{\"end\":73829,\"start\":73824},{\"end\":73845,\"start\":73840},{\"end\":74085,\"start\":74081},{\"end\":74097,\"start\":74092},{\"end\":74107,\"start\":74102},{\"end\":74119,\"start\":74113},{\"end\":74130,\"start\":74126},{\"end\":74143,\"start\":74139},{\"end\":74153,\"start\":74150},{\"end\":74432,\"start\":74424},{\"end\":74447,\"start\":74439},{\"end\":74463,\"start\":74456},{\"end\":74477,\"start\":74473},{\"end\":74492,\"start\":74487},{\"end\":74504,\"start\":74498},{\"end\":74518,\"start\":74513},{\"end\":74526,\"start\":74522},{\"end\":74540,\"start\":74536},{\"end\":74556,\"start\":74550},{\"end\":74563,\"start\":74558},{\"end\":74825,\"start\":74823},{\"end\":74966,\"start\":74964},{\"end\":74978,\"start\":74976},{\"end\":75102,\"start\":75096},{\"end\":75121,\"start\":75111},{\"end\":75127,\"start\":75123},{\"end\":75346,\"start\":75342},{\"end\":75360,\"start\":75356},{\"end\":75371,\"start\":75369},{\"end\":75544,\"start\":75542},{\"end\":75554,\"start\":75551},{\"end\":75569,\"start\":75565},{\"end\":75580,\"start\":75578},{\"end\":75870,\"start\":75868},{\"end\":75879,\"start\":75874},{\"end\":75892,\"start\":75887},{\"end\":75899,\"start\":75894},{\"end\":76137,\"start\":76132},{\"end\":76153,\"start\":76148},{\"end\":76165,\"start\":76163},{\"end\":76174,\"start\":76170},{\"end\":76544,\"start\":76539},{\"end\":76558,\"start\":76554},{\"end\":76897,\"start\":76892},{\"end\":76911,\"start\":76907},{\"end\":76921,\"start\":76919},{\"end\":77214,\"start\":77211},{\"end\":77226,\"start\":77221},{\"end\":77241,\"start\":77237},{\"end\":77249,\"start\":77247},{\"end\":77263,\"start\":77258},{\"end\":77275,\"start\":77271},{\"end\":77288,\"start\":77285},{\"end\":77299,\"start\":77295},{\"end\":77309,\"start\":77307},{\"end\":77320,\"start\":77318},{\"end\":77698,\"start\":77692},{\"end\":77709,\"start\":77700},{\"end\":78024,\"start\":78012}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":51248,\"start\":51171},{\"attributes\":{\"id\":\"b1\"},\"end\":51376,\"start\":51250},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":247793156},\"end\":51608,\"start\":51378},{\"attributes\":{\"doi\":\"arXiv:1607.06450\",\"id\":\"b3\"},\"end\":51834,\"start\":51610},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":252735071},\"end\":52272,\"start\":51836},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":203705211},\"end\":52463,\"start\":52274},{\"attributes\":{\"doi\":\"arXiv:2204.11824\",\"id\":\"b6\"},\"end\":52737,\"start\":52465},{\"attributes\":{\"doi\":\"arXiv:1809.11096\",\"id\":\"b7\"},\"end\":53037,\"start\":52739},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":216009},\"end\":53320,\"start\":53039},{\"attributes\":{\"id\":\"b9\"},\"end\":53496,\"start\":53322},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":9417016},\"end\":53878,\"start\":53498},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":4605056},\"end\":54228,\"start\":53880},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":57246310},\"end\":54508,\"start\":54230},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":8923541},\"end\":54797,\"start\":54510},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":216144533},\"end\":55134,\"start\":54799},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":6940861},\"end\":55472,\"start\":55136},{\"attributes\":{\"id\":\"b16\"},\"end\":55685,\"start\":55474},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":4806979},\"end\":56075,\"start\":55687},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":67855597},\"end\":56271,\"start\":56077},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":234357723},\"end\":56589,\"start\":56273},{\"attributes\":{\"doi\":\"2020. 3\",\"id\":\"b20\"},\"end\":56995,\"start\":56591},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":2908606},\"end\":57293,\"start\":56997},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":206594692},\"end\":57515,\"start\":57295},{\"attributes\":{\"id\":\"b23\"},\"end\":57901,\"start\":57517},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":219955663},\"end\":58115,\"start\":57903},{\"attributes\":{\"doi\":\"arXiv:2207.12598\",\"id\":\"b25\"},\"end\":58318,\"start\":58117},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":4379611},\"end\":58600,\"start\":58320},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":234763169},\"end\":58985,\"start\":58602},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":2226763},\"end\":59218,\"start\":58987},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":88166},\"end\":59721,\"start\":59220},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":209050760},\"end\":60103,\"start\":59723},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":5808102},\"end\":60386,\"start\":60105},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":34423795},\"end\":60693,\"start\":60388},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":51761520},\"end\":61057,\"start\":60695},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":3568073},\"end\":61351,\"start\":61059},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":54482423},\"end\":61617,\"start\":61353},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":209202273},\"end\":61931,\"start\":61619},{\"attributes\":{\"id\":\"b37\"},\"end\":62327,\"start\":61933},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":247940176},\"end\":62553,\"start\":62329},{\"attributes\":{\"doi\":\"2022. 4\",\"id\":\"b39\",\"matched_paper_id\":253018425},\"end\":62813,\"start\":62555},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":6628106},\"end\":62987,\"start\":62815},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":244798313},\"end\":63310,\"start\":62989},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":118648975},\"end\":63642,\"start\":63312},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":85518343},\"end\":63902,\"start\":63644},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":24462522},\"end\":64129,\"start\":63904},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":250920209},\"end\":64409,\"start\":64131},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":206596594},\"end\":64699,\"start\":64411},{\"attributes\":{\"doi\":\"2023. 3\",\"id\":\"b47\"},\"end\":64911,\"start\":64701},{\"attributes\":{\"doi\":\"arXiv:1711.05101\",\"id\":\"b48\"},\"end\":65128,\"start\":64913},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":240353691},\"end\":65514,\"start\":65130},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":1755257},\"end\":65905,\"start\":65516},{\"attributes\":{\"id\":\"b51\",\"matched_paper_id\":91184364},\"end\":66237,\"start\":65907},{\"attributes\":{\"doi\":\"PMLR, 2021. 3\",\"id\":\"b52\",\"matched_paper_id\":231979499},\"end\":66490,\"start\":66239},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":208003908},\"end\":66792,\"start\":66492},{\"attributes\":{\"id\":\"b54\",\"matched_paper_id\":244729224},\"end\":67146,\"start\":66794},{\"attributes\":{\"id\":\"b55\",\"matched_paper_id\":50769652},\"end\":67503,\"start\":67148},{\"attributes\":{\"id\":\"b56\",\"matched_paper_id\":237194623},\"end\":67782,\"start\":67505},{\"attributes\":{\"doi\":\"arXiv:2204.06125\",\"id\":\"b57\"},\"end\":68137,\"start\":67784},{\"attributes\":{\"id\":\"b58\",\"matched_paper_id\":245335280},\"end\":68451,\"start\":68139},{\"attributes\":{\"id\":\"b59\",\"matched_paper_id\":1687220},\"end\":68737,\"start\":68453},{\"attributes\":{\"id\":\"b60\",\"matched_paper_id\":6544744},\"end\":69075,\"start\":68739},{\"attributes\":{\"doi\":\"arXiv:2210.06998\",\"id\":\"b61\"},\"end\":69429,\"start\":69077},{\"attributes\":{\"doi\":\"arXiv:1812.01288\",\"id\":\"b62\"},\"end\":69749,\"start\":69431},{\"attributes\":{\"id\":\"b63\",\"matched_paper_id\":14888175},\"end\":70054,\"start\":69751},{\"attributes\":{\"id\":\"b64\",\"matched_paper_id\":222140788},\"end\":70258,\"start\":70056},{\"attributes\":{\"id\":\"b65\",\"matched_paper_id\":235352469},\"end\":70526,\"start\":70260},{\"attributes\":{\"id\":\"b66\",\"matched_paper_id\":196470871},\"end\":70754,\"start\":70528},{\"attributes\":{\"id\":\"b67\",\"matched_paper_id\":219708245},\"end\":70984,\"start\":70756},{\"attributes\":{\"id\":\"b68\",\"matched_paper_id\":214714120},\"end\":71290,\"start\":70986},{\"attributes\":{\"id\":\"b69\",\"matched_paper_id\":143426082},\"end\":71682,\"start\":71292},{\"attributes\":{\"id\":\"b70\",\"matched_paper_id\":21011865},\"end\":71934,\"start\":71684},{\"attributes\":{\"id\":\"b71\",\"matched_paper_id\":4929980},\"end\":72450,\"start\":71936},{\"attributes\":{\"id\":\"b72\",\"matched_paper_id\":239768540},\"end\":72810,\"start\":72452},{\"attributes\":{\"id\":\"b73\",\"matched_paper_id\":5855042},\"end\":73041,\"start\":72812},{\"attributes\":{\"id\":\"b74\",\"matched_paper_id\":13756489},\"end\":73373,\"start\":73043},{\"attributes\":{\"id\":\"b75\",\"matched_paper_id\":68589},\"end\":73709,\"start\":73375},{\"attributes\":{\"id\":\"b76\",\"matched_paper_id\":209444798},\"end\":74011,\"start\":73711},{\"attributes\":{\"doi\":\"arXiv:2205.12952\",\"id\":\"b77\"},\"end\":74376,\"start\":74013},{\"attributes\":{\"id\":\"b78\",\"matched_paper_id\":2141447},\"end\":74784,\"start\":74378},{\"attributes\":{\"id\":\"b79\"},\"end\":74935,\"start\":74786},{\"attributes\":{\"id\":\"b80\",\"matched_paper_id\":4076251},\"end\":75048,\"start\":74937},{\"attributes\":{\"id\":\"b81\",\"matched_paper_id\":251929107},\"end\":75243,\"start\":75050},{\"attributes\":{\"id\":\"b82\",\"matched_paper_id\":4393808},\"end\":75535,\"start\":75245},{\"attributes\":{\"doi\":\"arXiv:1411.7923\",\"id\":\"b83\"},\"end\":75787,\"start\":75537},{\"attributes\":{\"id\":\"b84\",\"matched_paper_id\":201058738},\"end\":76038,\"start\":75789},{\"attributes\":{\"id\":\"b85\",\"matched_paper_id\":10585115},\"end\":76378,\"start\":76040},{\"attributes\":{\"id\":\"b86\",\"matched_paper_id\":202721170},\"end\":76785,\"start\":76380},{\"attributes\":{\"doi\":\"abs/1708.08197\",\"id\":\"b87\"},\"end\":77118,\"start\":76787},{\"attributes\":{\"id\":\"b88\",\"matched_paper_id\":232148002},\"end\":77570,\"start\":77120},{\"attributes\":{\"doi\":\"2021. 1\",\"id\":\"b89\"},\"end\":77878,\"start\":77572},{\"attributes\":{\"id\":\"b90\"},\"end\":78223,\"start\":77880},{\"attributes\":{\"id\":\"b91\"},\"end\":80078,\"start\":78225},{\"attributes\":{\"id\":\"b92\"},\"end\":81589,\"start\":80080},{\"attributes\":{\"id\":\"b93\"},\"end\":82469,\"start\":81591},{\"attributes\":{\"id\":\"b94\"},\"end\":83956,\"start\":82471},{\"attributes\":{\"id\":\"b95\"},\"end\":84701,\"start\":83958}]", "bib_title": "[{\"end\":51416,\"start\":51378},{\"end\":51899,\"start\":51836},{\"end\":52321,\"start\":52274},{\"end\":53100,\"start\":53039},{\"end\":53352,\"start\":53322},{\"end\":53590,\"start\":53498},{\"end\":53960,\"start\":53880},{\"end\":54281,\"start\":54230},{\"end\":54573,\"start\":54510},{\"end\":54888,\"start\":54799},{\"end\":55232,\"start\":55136},{\"end\":55804,\"start\":55687},{\"end\":56117,\"start\":56077},{\"end\":56388,\"start\":56273},{\"end\":57066,\"start\":56997},{\"end\":57339,\"start\":57295},{\"end\":57943,\"start\":57903},{\"end\":58369,\"start\":58320},{\"end\":58712,\"start\":58602},{\"end\":59017,\"start\":58987},{\"end\":59316,\"start\":59220},{\"end\":59798,\"start\":59723},{\"end\":60197,\"start\":60105},{\"end\":60433,\"start\":60388},{\"end\":60742,\"start\":60695},{\"end\":61133,\"start\":61059},{\"end\":61425,\"start\":61353},{\"end\":61672,\"start\":61619},{\"end\":62382,\"start\":62329},{\"end\":62615,\"start\":62555},{\"end\":62857,\"start\":62815},{\"end\":63106,\"start\":62989},{\"end\":63380,\"start\":63312},{\"end\":63717,\"start\":63644},{\"end\":63942,\"start\":63904},{\"end\":64204,\"start\":64131},{\"end\":64470,\"start\":64411},{\"end\":65202,\"start\":65130},{\"end\":65577,\"start\":65516},{\"end\":65979,\"start\":65907},{\"end\":66288,\"start\":66239},{\"end\":66586,\"start\":66492},{\"end\":66915,\"start\":66794},{\"end\":67215,\"start\":67148},{\"end\":67550,\"start\":67505},{\"end\":68199,\"start\":68139},{\"end\":68490,\"start\":68453},{\"end\":68787,\"start\":68739},{\"end\":69813,\"start\":69751},{\"end\":70091,\"start\":70056},{\"end\":70319,\"start\":70260},{\"end\":70596,\"start\":70528},{\"end\":70818,\"start\":70756},{\"end\":71063,\"start\":70986},{\"end\":71324,\"start\":71292},{\"end\":71760,\"start\":71684},{\"end\":72101,\"start\":71936},{\"end\":72530,\"start\":72452},{\"end\":72840,\"start\":72812},{\"end\":73068,\"start\":73043},{\"end\":73434,\"start\":73375},{\"end\":73772,\"start\":73711},{\"end\":74414,\"start\":74378},{\"end\":74956,\"start\":74937},{\"end\":75088,\"start\":75050},{\"end\":75332,\"start\":75245},{\"end\":75861,\"start\":75789},{\"end\":76122,\"start\":76040},{\"end\":76529,\"start\":76380},{\"end\":77203,\"start\":77120},{\"end\":78008,\"start\":77880},{\"end\":78669,\"start\":78225},{\"end\":80613,\"start\":80080},{\"end\":82949,\"start\":82471}]", "bib_author": "[{\"end\":51180,\"start\":51173},{\"end\":51267,\"start\":51252},{\"end\":51433,\"start\":51418},{\"end\":51441,\"start\":51433},{\"end\":51454,\"start\":51441},{\"end\":51465,\"start\":51454},{\"end\":51479,\"start\":51465},{\"end\":51626,\"start\":51612},{\"end\":51644,\"start\":51626},{\"end\":51660,\"start\":51644},{\"end\":51915,\"start\":51901},{\"end\":51935,\"start\":51915},{\"end\":51955,\"start\":51935},{\"end\":51971,\"start\":51955},{\"end\":51982,\"start\":51971},{\"end\":51999,\"start\":51982},{\"end\":52016,\"start\":51999},{\"end\":52031,\"start\":52016},{\"end\":52337,\"start\":52323},{\"end\":52352,\"start\":52337},{\"end\":52522,\"start\":52503},{\"end\":52537,\"start\":52522},{\"end\":52549,\"start\":52537},{\"end\":52562,\"start\":52549},{\"end\":52821,\"start\":52807},{\"end\":52835,\"start\":52821},{\"end\":52851,\"start\":52835},{\"end\":53113,\"start\":53102},{\"end\":53122,\"start\":53113},{\"end\":53133,\"start\":53122},{\"end\":53142,\"start\":53133},{\"end\":53157,\"start\":53142},{\"end\":53168,\"start\":53157},{\"end\":53367,\"start\":53354},{\"end\":53380,\"start\":53367},{\"end\":53395,\"start\":53380},{\"end\":53605,\"start\":53592},{\"end\":53617,\"start\":53605},{\"end\":53631,\"start\":53617},{\"end\":53644,\"start\":53631},{\"end\":53657,\"start\":53644},{\"end\":53670,\"start\":53657},{\"end\":53977,\"start\":53962},{\"end\":53992,\"start\":53977},{\"end\":54005,\"start\":53992},{\"end\":54019,\"start\":54005},{\"end\":54039,\"start\":54019},{\"end\":54293,\"start\":54283},{\"end\":54303,\"start\":54293},{\"end\":54319,\"start\":54303},{\"end\":54330,\"start\":54319},{\"end\":54338,\"start\":54330},{\"end\":54350,\"start\":54338},{\"end\":54590,\"start\":54575},{\"end\":54599,\"start\":54590},{\"end\":54612,\"start\":54599},{\"end\":54632,\"start\":54612},{\"end\":54899,\"start\":54890},{\"end\":54914,\"start\":54899},{\"end\":54925,\"start\":54914},{\"end\":54935,\"start\":54925},{\"end\":54945,\"start\":54935},{\"end\":55250,\"start\":55234},{\"end\":55263,\"start\":55250},{\"end\":55275,\"start\":55263},{\"end\":55535,\"start\":55525},{\"end\":55545,\"start\":55535},{\"end\":55555,\"start\":55545},{\"end\":55562,\"start\":55555},{\"end\":55568,\"start\":55562},{\"end\":55819,\"start\":55806},{\"end\":55836,\"start\":55819},{\"end\":55851,\"start\":55836},{\"end\":55865,\"start\":55851},{\"end\":56134,\"start\":56119},{\"end\":56144,\"start\":56134},{\"end\":56161,\"start\":56144},{\"end\":56406,\"start\":56390},{\"end\":56420,\"start\":56406},{\"end\":56609,\"start\":56593},{\"end\":56629,\"start\":56609},{\"end\":56642,\"start\":56629},{\"end\":56651,\"start\":56642},{\"end\":56671,\"start\":56651},{\"end\":56686,\"start\":56671},{\"end\":56703,\"start\":56686},{\"end\":56718,\"start\":56703},{\"end\":57081,\"start\":57068},{\"end\":57092,\"start\":57081},{\"end\":57103,\"start\":57092},{\"end\":57116,\"start\":57103},{\"end\":57130,\"start\":57116},{\"end\":57353,\"start\":57341},{\"end\":57368,\"start\":57353},{\"end\":57382,\"start\":57368},{\"end\":57392,\"start\":57382},{\"end\":57628,\"start\":57613},{\"end\":57645,\"start\":57628},{\"end\":57665,\"start\":57645},{\"end\":57683,\"start\":57665},{\"end\":57700,\"start\":57683},{\"end\":57958,\"start\":57945},{\"end\":57969,\"start\":57958},{\"end\":57984,\"start\":57969},{\"end\":58132,\"start\":58119},{\"end\":58146,\"start\":58132},{\"end\":58382,\"start\":58371},{\"end\":58396,\"start\":58382},{\"end\":58415,\"start\":58396},{\"end\":58429,\"start\":58415},{\"end\":58447,\"start\":58429},{\"end\":58728,\"start\":58714},{\"end\":58742,\"start\":58728},{\"end\":58753,\"start\":58742},{\"end\":58770,\"start\":58753},{\"end\":58779,\"start\":58770},{\"end\":59031,\"start\":59019},{\"end\":59046,\"start\":59031},{\"end\":59059,\"start\":59046},{\"end\":59080,\"start\":59059},{\"end\":59326,\"start\":59318},{\"end\":59340,\"start\":59326},{\"end\":59355,\"start\":59340},{\"end\":59366,\"start\":59355},{\"end\":59382,\"start\":59366},{\"end\":59812,\"start\":59800},{\"end\":59824,\"start\":59812},{\"end\":59834,\"start\":59824},{\"end\":59848,\"start\":59834},{\"end\":59864,\"start\":59848},{\"end\":59876,\"start\":59864},{\"end\":59886,\"start\":59876},{\"end\":59900,\"start\":59886},{\"end\":60213,\"start\":60199},{\"end\":60232,\"start\":60213},{\"end\":60449,\"start\":60435},{\"end\":60466,\"start\":60449},{\"end\":60485,\"start\":60466},{\"end\":60498,\"start\":60485},{\"end\":60768,\"start\":60744},{\"end\":60774,\"start\":60768},{\"end\":60783,\"start\":60774},{\"end\":60799,\"start\":60783},{\"end\":60815,\"start\":60799},{\"end\":60830,\"start\":60815},{\"end\":60844,\"start\":60830},{\"end\":60851,\"start\":60844},{\"end\":60857,\"start\":60851},{\"end\":61148,\"start\":61135},{\"end\":61159,\"start\":61148},{\"end\":61173,\"start\":61159},{\"end\":61190,\"start\":61173},{\"end\":61440,\"start\":61427},{\"end\":61454,\"start\":61440},{\"end\":61465,\"start\":61454},{\"end\":61687,\"start\":61674},{\"end\":61701,\"start\":61687},{\"end\":61716,\"start\":61701},{\"end\":61732,\"start\":61716},{\"end\":61749,\"start\":61732},{\"end\":61760,\"start\":61749},{\"end\":61950,\"start\":61935},{\"end\":61965,\"start\":61950},{\"end\":61979,\"start\":61965},{\"end\":61991,\"start\":61979},{\"end\":62005,\"start\":61991},{\"end\":62024,\"start\":62005},{\"end\":62039,\"start\":62024},{\"end\":62059,\"start\":62039},{\"end\":62078,\"start\":62059},{\"end\":62098,\"start\":62078},{\"end\":62397,\"start\":62384},{\"end\":62412,\"start\":62397},{\"end\":62417,\"start\":62412},{\"end\":62630,\"start\":62617},{\"end\":62640,\"start\":62630},{\"end\":62651,\"start\":62640},{\"end\":62665,\"start\":62651},{\"end\":62871,\"start\":62859},{\"end\":62885,\"start\":62871},{\"end\":62889,\"start\":62885},{\"end\":63121,\"start\":63108},{\"end\":63137,\"start\":63121},{\"end\":63403,\"start\":63382},{\"end\":63416,\"start\":63403},{\"end\":63430,\"start\":63416},{\"end\":63447,\"start\":63430},{\"end\":63458,\"start\":63447},{\"end\":63732,\"start\":63719},{\"end\":63745,\"start\":63732},{\"end\":63760,\"start\":63745},{\"end\":63957,\"start\":63944},{\"end\":63969,\"start\":63957},{\"end\":63978,\"start\":63969},{\"end\":63990,\"start\":63978},{\"end\":64003,\"start\":63990},{\"end\":64216,\"start\":64206},{\"end\":64229,\"start\":64216},{\"end\":64240,\"start\":64229},{\"end\":64254,\"start\":64240},{\"end\":64485,\"start\":64472},{\"end\":64498,\"start\":64485},{\"end\":64510,\"start\":64498},{\"end\":64519,\"start\":64510},{\"end\":64532,\"start\":64519},{\"end\":64541,\"start\":64532},{\"end\":64773,\"start\":64761},{\"end\":64787,\"start\":64773},{\"end\":64932,\"start\":64915},{\"end\":64946,\"start\":64932},{\"end\":65212,\"start\":65204},{\"end\":65228,\"start\":65212},{\"end\":65241,\"start\":65228},{\"end\":65253,\"start\":65241},{\"end\":65268,\"start\":65253},{\"end\":65288,\"start\":65268},{\"end\":65299,\"start\":65288},{\"end\":65306,\"start\":65299},{\"end\":65601,\"start\":65579},{\"end\":65625,\"start\":65601},{\"end\":65643,\"start\":65625},{\"end\":65658,\"start\":65643},{\"end\":65672,\"start\":65658},{\"end\":65692,\"start\":65672},{\"end\":65999,\"start\":65981},{\"end\":66009,\"start\":65999},{\"end\":66022,\"start\":66009},{\"end\":66042,\"start\":66022},{\"end\":66059,\"start\":66042},{\"end\":66307,\"start\":66290},{\"end\":66316,\"start\":66307},{\"end\":66335,\"start\":66316},{\"end\":66602,\"start\":66588},{\"end\":66613,\"start\":66602},{\"end\":66627,\"start\":66613},{\"end\":66936,\"start\":66917},{\"end\":66955,\"start\":66936},{\"end\":67234,\"start\":67217},{\"end\":67249,\"start\":67234},{\"end\":67258,\"start\":67249},{\"end\":67276,\"start\":67258},{\"end\":67295,\"start\":67276},{\"end\":67310,\"start\":67295},{\"end\":67563,\"start\":67552},{\"end\":67576,\"start\":67563},{\"end\":67589,\"start\":67576},{\"end\":67601,\"start\":67589},{\"end\":67610,\"start\":67601},{\"end\":67623,\"start\":67610},{\"end\":67865,\"start\":67850},{\"end\":67884,\"start\":67865},{\"end\":67897,\"start\":67884},{\"end\":67908,\"start\":67897},{\"end\":67919,\"start\":67908},{\"end\":68216,\"start\":68201},{\"end\":68235,\"start\":68216},{\"end\":68251,\"start\":68235},{\"end\":68266,\"start\":68251},{\"end\":68279,\"start\":68266},{\"end\":68506,\"start\":68492},{\"end\":68522,\"start\":68506},{\"end\":68540,\"start\":68522},{\"end\":68554,\"start\":68540},{\"end\":68568,\"start\":68554},{\"end\":68577,\"start\":68568},{\"end\":68809,\"start\":68789},{\"end\":68825,\"start\":68809},{\"end\":68842,\"start\":68825},{\"end\":68852,\"start\":68842},{\"end\":68864,\"start\":68852},{\"end\":68883,\"start\":68864},{\"end\":68891,\"start\":68883},{\"end\":69183,\"start\":69171},{\"end\":69193,\"start\":69183},{\"end\":69202,\"start\":69193},{\"end\":69214,\"start\":69202},{\"end\":69518,\"start\":69506},{\"end\":69530,\"start\":69518},{\"end\":69540,\"start\":69530},{\"end\":69553,\"start\":69540},{\"end\":69838,\"start\":69815},{\"end\":69850,\"start\":69838},{\"end\":69872,\"start\":69850},{\"end\":69887,\"start\":69872},{\"end\":70107,\"start\":70093},{\"end\":70121,\"start\":70107},{\"end\":70136,\"start\":70121},{\"end\":70332,\"start\":70321},{\"end\":70346,\"start\":70332},{\"end\":70359,\"start\":70346},{\"end\":70374,\"start\":70359},{\"end\":70609,\"start\":70598},{\"end\":70624,\"start\":70609},{\"end\":70831,\"start\":70820},{\"end\":70846,\"start\":70831},{\"end\":71081,\"start\":71065},{\"end\":71097,\"start\":71081},{\"end\":71109,\"start\":71097},{\"end\":71123,\"start\":71109},{\"end\":71341,\"start\":71326},{\"end\":71360,\"start\":71341},{\"end\":71373,\"start\":71360},{\"end\":71385,\"start\":71373},{\"end\":71397,\"start\":71385},{\"end\":71411,\"start\":71397},{\"end\":71430,\"start\":71411},{\"end\":71441,\"start\":71430},{\"end\":71457,\"start\":71441},{\"end\":71475,\"start\":71457},{\"end\":71773,\"start\":71762},{\"end\":71781,\"start\":71773},{\"end\":71795,\"start\":71781},{\"end\":72122,\"start\":72103},{\"end\":72138,\"start\":72122},{\"end\":72151,\"start\":72138},{\"end\":72164,\"start\":72151},{\"end\":72179,\"start\":72164},{\"end\":72557,\"start\":72532},{\"end\":72571,\"start\":72557},{\"end\":72591,\"start\":72571},{\"end\":72607,\"start\":72591},{\"end\":72866,\"start\":72842},{\"end\":72883,\"start\":72866},{\"end\":73086,\"start\":73070},{\"end\":73100,\"start\":73086},{\"end\":73113,\"start\":73100},{\"end\":73130,\"start\":73113},{\"end\":73143,\"start\":73130},{\"end\":73158,\"start\":73143},{\"end\":73173,\"start\":73158},{\"end\":73191,\"start\":73173},{\"end\":73446,\"start\":73436},{\"end\":73459,\"start\":73446},{\"end\":73471,\"start\":73459},{\"end\":73480,\"start\":73471},{\"end\":73493,\"start\":73480},{\"end\":73508,\"start\":73493},{\"end\":73520,\"start\":73508},{\"end\":73529,\"start\":73520},{\"end\":73789,\"start\":73774},{\"end\":73802,\"start\":73789},{\"end\":73817,\"start\":73802},{\"end\":73831,\"start\":73817},{\"end\":73847,\"start\":73831},{\"end\":74087,\"start\":74073},{\"end\":74099,\"start\":74087},{\"end\":74109,\"start\":74099},{\"end\":74121,\"start\":74109},{\"end\":74132,\"start\":74121},{\"end\":74145,\"start\":74132},{\"end\":74155,\"start\":74145},{\"end\":74434,\"start\":74416},{\"end\":74449,\"start\":74434},{\"end\":74465,\"start\":74449},{\"end\":74479,\"start\":74465},{\"end\":74494,\"start\":74479},{\"end\":74506,\"start\":74494},{\"end\":74520,\"start\":74506},{\"end\":74528,\"start\":74520},{\"end\":74542,\"start\":74528},{\"end\":74558,\"start\":74542},{\"end\":74565,\"start\":74558},{\"end\":74827,\"start\":74814},{\"end\":74968,\"start\":74958},{\"end\":74980,\"start\":74968},{\"end\":75104,\"start\":75090},{\"end\":75123,\"start\":75104},{\"end\":75129,\"start\":75123},{\"end\":75348,\"start\":75334},{\"end\":75362,\"start\":75348},{\"end\":75373,\"start\":75362},{\"end\":75546,\"start\":75537},{\"end\":75556,\"start\":75546},{\"end\":75571,\"start\":75556},{\"end\":75582,\"start\":75571},{\"end\":75872,\"start\":75863},{\"end\":75881,\"start\":75872},{\"end\":75894,\"start\":75881},{\"end\":75901,\"start\":75894},{\"end\":76139,\"start\":76124},{\"end\":76155,\"start\":76139},{\"end\":76167,\"start\":76155},{\"end\":76176,\"start\":76167},{\"end\":76546,\"start\":76531},{\"end\":76560,\"start\":76546},{\"end\":76899,\"start\":76884},{\"end\":76913,\"start\":76899},{\"end\":76923,\"start\":76913},{\"end\":77216,\"start\":77205},{\"end\":77228,\"start\":77216},{\"end\":77243,\"start\":77228},{\"end\":77251,\"start\":77243},{\"end\":77265,\"start\":77251},{\"end\":77277,\"start\":77265},{\"end\":77290,\"start\":77277},{\"end\":77301,\"start\":77290},{\"end\":77311,\"start\":77301},{\"end\":77322,\"start\":77311},{\"end\":77700,\"start\":77686},{\"end\":77711,\"start\":77700},{\"end\":78026,\"start\":78010},{\"end\":80619,\"start\":80615},{\"end\":84173,\"start\":84169}]", "bib_venue": "[{\"end\":51483,\"start\":51479},{\"end\":52035,\"start\":52031},{\"end\":52360,\"start\":52352},{\"end\":52501,\"start\":52465},{\"end\":52805,\"start\":52739},{\"end\":53170,\"start\":53168},{\"end\":53399,\"start\":53395},{\"end\":53677,\"start\":53670},{\"end\":54046,\"start\":54039},{\"end\":54360,\"start\":54350},{\"end\":54636,\"start\":54632},{\"end\":54958,\"start\":54945},{\"end\":55290,\"start\":55275},{\"end\":55523,\"start\":55474},{\"end\":55872,\"start\":55865},{\"end\":56165,\"start\":56161},{\"end\":56424,\"start\":56420},{\"end\":56783,\"start\":56725},{\"end\":57134,\"start\":57130},{\"end\":57396,\"start\":57392},{\"end\":57611,\"start\":57517},{\"end\":57991,\"start\":57984},{\"end\":58451,\"start\":58447},{\"end\":58783,\"start\":58779},{\"end\":59087,\"start\":59080},{\"end\":59458,\"start\":59382},{\"end\":59904,\"start\":59900},{\"end\":60236,\"start\":60232},{\"end\":60529,\"start\":60498},{\"end\":60864,\"start\":60857},{\"end\":61197,\"start\":61190},{\"end\":61469,\"start\":61465},{\"end\":61764,\"start\":61760},{\"end\":62123,\"start\":62098},{\"end\":62421,\"start\":62417},{\"end\":62679,\"start\":62672},{\"end\":62893,\"start\":62889},{\"end\":63141,\"start\":63137},{\"end\":63465,\"start\":63458},{\"end\":63764,\"start\":63760},{\"end\":64007,\"start\":64003},{\"end\":64258,\"start\":64254},{\"end\":64545,\"start\":64541},{\"end\":64759,\"start\":64701},{\"end\":65310,\"start\":65306},{\"end\":65697,\"start\":65692},{\"end\":66063,\"start\":66059},{\"end\":66352,\"start\":66348},{\"end\":66631,\"start\":66627},{\"end\":66959,\"start\":66955},{\"end\":67317,\"start\":67310},{\"end\":67627,\"start\":67623},{\"end\":67848,\"start\":67784},{\"end\":68283,\"start\":68279},{\"end\":68584,\"start\":68577},{\"end\":68895,\"start\":68891},{\"end\":69169,\"start\":69077},{\"end\":69504,\"start\":69431},{\"end\":69891,\"start\":69887},{\"end\":70146,\"start\":70136},{\"end\":70381,\"start\":70374},{\"end\":70631,\"start\":70624},{\"end\":70853,\"start\":70846},{\"end\":71127,\"start\":71123},{\"end\":71478,\"start\":71475},{\"end\":71799,\"start\":71795},{\"end\":72184,\"start\":72179},{\"end\":72614,\"start\":72607},{\"end\":72919,\"start\":72883},{\"end\":73198,\"start\":73191},{\"end\":73533,\"start\":73529},{\"end\":73851,\"start\":73847},{\"end\":74071,\"start\":74013},{\"end\":74570,\"start\":74565},{\"end\":74812,\"start\":74786},{\"end\":74984,\"start\":74980},{\"end\":75133,\"start\":75129},{\"end\":75380,\"start\":75373},{\"end\":75638,\"start\":75597},{\"end\":75905,\"start\":75901},{\"end\":76201,\"start\":76176},{\"end\":76569,\"start\":76560},{\"end\":76882,\"start\":76787},{\"end\":77326,\"start\":77322},{\"end\":77684,\"start\":77572},{\"end\":78047,\"start\":78026},{\"end\":78746,\"start\":78671},{\"end\":80758,\"start\":80619},{\"end\":81951,\"start\":81591},{\"end\":83116,\"start\":82951},{\"end\":84167,\"start\":83958}]"}}}, "year": 2023, "month": 12, "day": 17}