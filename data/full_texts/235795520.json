{"id": 235795520, "updated": "2023-10-06 01:20:40.883", "metadata": {"title": "Denoising User-aware Memory Network for Recommendation", "authors": "[{\"first\":\"Zhi\",\"last\":\"Bian\",\"middle\":[]},{\"first\":\"Shaojun\",\"last\":\"Zhou\",\"middle\":[]},{\"first\":\"Hao\",\"last\":\"Fu\",\"middle\":[]},{\"first\":\"Qihong\",\"last\":\"Yang\",\"middle\":[]},{\"first\":\"Zhenqi\",\"last\":\"Sun\",\"middle\":[]},{\"first\":\"Junjie\",\"last\":\"Tang\",\"middle\":[]},{\"first\":\"Guiquan\",\"last\":\"Liu\",\"middle\":[]},{\"first\":\"Kaikui\",\"last\":\"Liu\",\"middle\":[]},{\"first\":\"Xiaolong\",\"last\":\"Li\",\"middle\":[]}]", "venue": null, "journal": "Proceedings of the 15th ACM Conference on Recommender Systems", "publication_date": {"year": 2021, "month": 7, "day": 12}, "abstract": "For better user satisfaction and business effectiveness, more and more attention has been paid to the sequence-based recommendation system, which is used to infer the evolution of users' dynamic preferences, and recent studies have noticed that the evolution of users' preferences can be better understood from the implicit and explicit feedback sequences. However, most of the existing recommendation techniques do not consider the noise contained in implicit feedback, which will lead to the biased representation of user interest and a suboptimal recommendation performance. Meanwhile, the existing methods utilize item sequence for capturing the evolution of user interest. The performance of these methods is limited by the length of the sequence, and can not effectively model the long-term interest in a long period of time. Based on this observation, we propose a novel CTR model named denoising user-aware memory network (DUMN). Specifically, the framework: (i) proposes a feature purification module based on orthogonal mapping, which use the representation of explicit feedback to purify the representation of implicit feedback, and effectively denoise the implicit feedback; (ii) designs a user memory network to model the long-term interests in a fine-grained way by improving the memory network, which is ignored by the existing methods; and (iii) develops a preference-aware interactive representation component to fuse the long-term and short-term interests of users based on gating to understand the evolution of unbiased preferences of users. Extensive experiments on two real e-commerce user behavior datasets show that DUMN has a significant improvement over the state-of-the-art baselines. The code of DUMN model has been uploaded as an additional material.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2107.05474", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/recsys/BianZFYSTLLL21", "doi": "10.1145/3460231.3474237"}}, "content": {"source": {"pdf_hash": "313128989830e0a0594386e56034e5054dbb5f9b", "pdf_src": "ACM", "pdf_uri": null, "oa_url_match": false, "oa_info": {"license": null, "open_access_url": "http://arxiv.org/pdf/2107.05474", "status": "GREEN"}}, "grobid": {"id": "f8ca85bdf1e2742043d193049f3c65f3ad4588c0", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/313128989830e0a0594386e56034e5054dbb5f9b.txt", "contents": "\nDenoising User-aware Memory Network for Recommendation\nACMCopyright ACMSeptember 27-October 1, 2021. 2021. September 27-October 1, 2021\n\nZhi Bian bianzhi.bz@alibaba-inc.com \nShaojun Zhou \nHao Fu \nQihong Yang \nZhenqi Sun sunzhenqi.szq@alibaba-inc.com \nJunjie Tang \nGuiquan Liu gqliu@ustc.edu.cn \nKaikui Liu \nXiaolong Li \nZhi Bian \nShaojun Zhou \nHao Fu \nQihong Yang \nZhenqi Sun \nJunjie Tang \nGuiquan Liu \nKaikui Liu \nXiaolong Li \n\nAlibaba Group\nBeijingChina\n\n\nAlibaba Group Beijing\nChina\n\n\nAlibaba Group Beijing\nChina\n\n\nAlibaba Group Beijing\nChina\n\n\nAlibaba Group Beijing\nChina\n\n\nAlibaba Group Beijing\nUniversity of Science and Technology of China Anhui\nChina, China\n\n\nAlibaba Group Beijing\nChina\n\n\nAlibaba Group Beijing\nChina\n\nDenoising User-aware Memory Network for Recommendation\n\nFifteenth ACM Conference on Recommender Systems (RecSys '21)\nAmsterdam, Netherlands; Amsterdam, Netherlands; New York, NY, USAACM11September 27-October 1, 2021. 2021. September 27-October 1, 202110.1145/3460231.3474237* Both authors contributed equally to this research. \u2020 Corresponding author./21/09. . . $15.00 ACM Reference Format:CCS CONCEPTS \u2022 Information systems \u2192 Recommender systemsPersonal- ization\u2022 Computing methodologies \u2192 Learning latent rep- resentations KEYWORDS recommender systems, neural networks, denoising\nFor better user satisfaction and business effectiveness, more and more attention has been paid to the sequence-based recommendation system, which is used to infer the evolution of users' dynamic preferences, and recent studies have noticed that the evolution of users' preferences can be better understood from the implicit and explicit feedback sequences. However, most of the existing recommendation techniques do not consider the noise contained in implicit feedback, which will lead to the biased representation of user interest and a suboptimal recommendation performance. Meanwhile, the existing methods utilize item sequence for capturing the evolution of user interest. The performance of these methods is limited by the length of the sequence, and can not effectively model the long-term interest in a long period of time. Based on this observation, we propose a novel CTR model named denoising user-aware memory network (DUMN). Specifically, the framework: (i) proposes a feature purification module based on orthogonal mapping, which use the representation of explicit feedback to purify the representation of implicit feedback, and effectively denoise the implicit feedback; (ii) designs a user memory network to model the long-term interests in a fine-grained way by improving the memory network, which is ignored by the existing methods; and (iii) develops a preference-aware interactive representation component to fuse the long-term and short-term interests of users based on gating to understand the evolution of unbiased preferences of users. Extensive experiments on two real e-commerce user behavior datasets show that DUMN has a significant improvement over the state-of-the-art baselines.\n\nINTRODUCTION\n\nLarge-scale e-commerce platforms such as Taobao and Amazon have hundreds of millions of users' interaction data every day. Click-Through Rate (CTR) prediction plays an important role in the personalized recommendation system [13,29,49,50]. It can recommend items consistent with users' interests and preferences by analyzing users' historical behavior data, thus greatly improving users' satisfaction and reducing information overload.\n\nThe key to CTR prediction is to understand the evolution of user preferences through historical behavior data. Traditional CTR prediction methods such as matrix factorization (MF) [21] and collaborative filtering (CF) [8] try to learn low-order cross features and capture the similarity between users and items through the user-item rating matrix constructed from user feedback data. With the rapid development of deep learning, CTR prediction method based on deep learning such as DeepFM [11] and Deep&Cross [41] and xDeepFM [25] can effectively capture the high-order cross features of users and items, and capture the evolution of users' interests through LSTM/GRU network modeling click sequence [18,22,38]. Methods such as DIEN [49] and DSIN [6], regard the user's click feedback data as sequence signals, and use RNN-based networks to summarize the user's preference. Recently, researchers point out that the modeling of click sequence can only focus on what users are interested in, but ignore the modeling of what users are not interested in, which leads to the captured user preferences are biased [44]. In view of this, the interaction data is subdivided into implicit and explicit feedback [10,44]. Among them, explicit feedback is defined as precise but relatively rare feedback that can directly indicate users' positive/negative preferences in the view page, such as rating and tagging like/dislike, while implicit feedback refers to rich but noisy feedback that contains noise and cannot directly indicate the user's preferences. Implicit feedback includes click and unclick. Click feedback indicates that the user clicks an item on the view page, while unclick feedback indicates that the user slides down but does not click. In general, click feedback may come from users accidentally clicking some wrong items; unclick feedback also includes items that the user may be interested in, but it scrolls too fast to notice. [26] and [12] model users' explicit negative feedback information through collaborative filtering (CF) and multi-task learning, which improves the performance of the model to a certain extent. [28], [44] and [47] consider modeling the unclicked sequence in the user's implicit negative feedback information.\n\nDespite these methods have achieved significant performance by modeling both implicit and explicit feedback to understand the evolution of users' unbiased preferences, we argue that the inherent noises of implicit feedback are not dealt with effectively. The existing noise purification methods use attention mechanism [44] and autoencoders [35] to increase the attention of related items, but the attention value itself may be inaccurate, which leads to room for improvement in the purification of noise features. Compared with the implicit feedback with noise, the explicit feedback can accurately indicate the user's preference. Therefore, the noise in the implicit feedback representation can be purified by the explicit feedback representation, and the user's preference can be more clearly described by the purified implicit representation and explicit representation, which has not been considered by existing methods.\n\nIn addition to the lack of noise purification, the existing methods are insufficient to represent the long-term preferences of users. Long-term preference refers to the behavior preference of users over a long period of time, which is usually relatively stable. The sequential recommendation methods, such as SDM [27], DIEN [49] and DSIN [6], try to increase the length of users' click sequence to capture users' stable long-term preferences. However, they have the following problems. First, the existing models of capturing long-term interest are all item-based methods, and the length of the item sequence used in these methods is often limited by the memory and computing resources, which leads to the gap between the model preference and the user's stable long-term preference. On the contrary, we argue that users' long-term interests should be characterized from the user level. Specifically, long-term interests should be sequence-independent and mainly related to the user profile. For example, people who own a pet cat may purchase certain cat food at intervals, which may not be related to their recent behavior sequences. Furthermore, the user's long-term interests characterized from a user-based perspective enables sequence decoupling, so as to ensure that the model is not limited to the length of the sequence. Second, the feedback information such as rating, click/unclick, like/dislike can reflect users' preference, and the preferences formed by different types of feedback are distinctive. Only by fine-grained modeling multiple types of sequential feedback can we better understand the long-term preferences of the user. MIMN [31] uses NTM [9] to maintain the latest interest state for each user and its update depends on the real-time user's click behavior to trigger events. However, all the methods mentioned above only use the click sequence to describe users' preferences, which leads to the incomplete description of user preferences. Based on the above analysis, it can be seen that user's long-term preference modeling and noise feature purification are both unsolved problems in CTR prediction, and without loss of generality, we define the preference representation learned from the limited length sequence as short-term interest.\n\nIn seeking to address these challenges, we propose DUMN for recommendation. First, we design a feature purification (FP) module based on vector orthogonal mapping [32] for short-term preference modeling. Specifically, we construct two sets of contrast pairs < click, dislike > and < unclick, like >, and map the first representation vector click and unclick of each pair to the vertical direction of the second representation vector dislike and like, and the mapped vector is used as the purified representation. Then, a user memory network (UMN) is proposed to understand the stable long-term preference of users in a fine-grained way. UMN improves the memory network used in NTM [9] to represent all types of feedback, and designs a novel triple loss to regularize the memory network, so that the content written in the memory network can truly express the user's preferences. Finally, a preference-aware interactive representation (PAIR) module is proposed to obtain the cross representation that can simultaneously aggregate user long-term and short-term preferences. Our contributions are summarized as follows:\n\n\u2022 We introduce a novel denoising user-aware memory network for CTR prediction task, which can understand the unbiased evolution of users' preferences by fine-grained modeling of users' feedback information. \u2022 We design a FP module for implicit feature purification. Through a novel vector orthogonal mapping method, the FP module can effectively extract the differences in two sets of contrast pairs < click, dislike > and < unclick, like >. \u2022 We propose UMN module and PAIR module for fine-grained longterm preference modeling and cross representation of long-term and short-term interests, respectively. \u2022 We conduct experiments on two real-world datasets. The experimental results show that our DUMN is superior to the existing state-of-the-art baselines, which verifies the effectiveness of our DUMN.\n\n\nRELATED WORK 2.1 Recommendation with Implicit Feedback\n\nUser feedback data contains both precise but relatively rare explicit feedback and rich but noisy implicit feedback. As mentioned in Introduction, we can obtain the user's unbiased preference presentation by modeling both explicit feedback and implicit feedback at the same time. A large number of existing works have also proved the improvement of system performance by using various feedback information such as implicit and explicit through experiments. [14] treats all unobserved items of users as negative instances and expresses the value of implicit feedback information as confidential. [20,26,35,46] fuses CF and various feedback information, and [16] uses weak supervision method to model feedback information. BINN [24] constructs a sequence of multiple interactive data of each user, and tries to use RNN to model the unbiased behavior of users. Furthermore, more algorithms use multi-task learning frameworks to jointly solve ranking and rating tasks by combining various explicit feedback and implicit feedback [12]. Recently, [42] constructs the multi-relational item graph for learning global item-to-item relations and develops the novel graph model MGNN-SPred to learns global item-to-item relations through graph neural network. GCN-based GRCN [43] is proposed to implement pruning of noisy edges in the graph constructed by users' feedback information on items. FAWMF [2] applies variational autoencoder to realize adaptive weight assignment of implicit feedback and effective model learning. To the best of our knowledge, we are the first to use the representation of explicit feedback to purify the representation of implicit feedback by orthogonal mapping.\n\n\nCTR Model\n\nEarly methods of CTR prediction construct the interactive data of users and items into a user-item rating matrix, and the user-based or item-based CF method [8] is used for rating prediction. In these methods, the user and item evaluation vectors are regarded as the presentation vectors of each user and item. Later, based on the cooccurrence matrix of CF algorithm, MF adds the concept of hidden vector to reduce the representation dimension of vector and enhance the ability of the model to deal with sparse matrix. MF based methods, such as singular value decomposition [21], non-negative matrix factorization [7] and probabilistic matrix factorization [32], are widely used in recommendation system. With the rapid development of deep learning in many fields, such as computer vision [15,34], natural language processing [5], there are more and more researches on personalized recommendation of jobs [1], music [39], news [30] and video [4] based on deep neural network. Different from the traditional CTR prediction models such as MF and CF, which capture the similarity between users and items through feature engineering, the CTR prediction method based on deep learning uses neural networks to capture the interaction between features, which can better capture high-order interactive features [23,25]. Wide&Deep [3] considers the wide part for memory and the deep part for generalization together, making the model have the advantages of both logistic regression and deep neural network. DIN [50] proposes an attention mechanism to capture the relative interest of candidates and obtain adaptive interest representation. Inspired by the success of the Transformer network in neural machine translation [40], ATRANK [48] invents an attention-based framework for CTR prediction. SASRec [18] uses self-attention to capture long-term semantics and makes the predictions based on relatively few actions. DIEN [49] proposes a two-layer RNN structure with an attention mechanism, which uses attention weights to control the second-layer RNN to activate the interests most relevant to the candidates. Furthermore, DSIN [6] captures the evolution of user preferences in the session by dividing the user's interactive behavior by session.\n\nIn recent years, inspired by the development of neural network graph embedding algorithm [19], more and more attention has been paid to graph structure development for various recommended scenarios [17,36]. [45] use different types of entity relationships in heterogeneous information networks to make use of the personalized recommendation framework. Recently, in order to address the early summarization issue on heterogeneous information networks, NIRec [17] is designed to capture and aggregate rich interactive patterns in both node-level and path-level.\n\n\nMETHOD\n\nIn this section, we present the technical details of DUMN. As shown in Fig. 1, DUMN mainly consists of four modules, namely embedding layer, FP layer, UMN layer and PAIR layer. First, the embedding layer takes user , ad, user's click, unclick, like and dislike sequences as input, and implements embedding for all input data. Secondly, FP uses the multi-head interaction-attention component shown in the lower right side of Fig. 1 to model the user's various implicit/explicit feedback sequences, and uses the representation of explicit feedback to purify the representation of implicit feedback by orthogonal mapping. Third, the UMN module captures users' fine-grained longterm interests by improving the memory network to all types of feedback. Finally, PAIR combines the short-term and the long-term interest representation to obtain the cross representation, and then uses the fully connected layer for CTR prediction.\n\n\nProblem Definition\n\nThe DUMN network is represented by the function F (x; \u03b8 ), where \u03b8 is the parameters and x is the input, which contains the initial representation of the user, target item and four sequences of user's click, unclick, like and dislike feedback. Our goal is to make the predicted value\u0177 of F (x; \u03b8 ) as close to the user's real click preference y \u2208 {0, 1} as possible by minimizing the specific loss L, so as to realize the purpose of CTR prediction.\n\n\nEmbedding Layer\n\nThe input of DUMN can be divided into three parts: user pro f ile, ad and user behavior sequences. The attribute fields of user pro f ile includes user_id, gender, age, etc. ad refers to the target item for CTR prediction, which includes item_id and brand_id. user behavior sequence is a list of items. In this paper, we model four kinds of behavior sequences, which are click sequence C =\n[C 1 , C 2 , ..., C T ] and unclick sequence U = [U 1 , U 2 , ..., U T ] of im- plicit feedback, dislike sequence D = [D 1 , D 2 , ..., D T ] and like se- quence L = [L 1 , L 2 , ..., L T ] of explicit feedback,\nwhere T is the maximum sequence length input to the model. As previously did [6,49], we use the embedding layer to transform the high dimensional sparse ids into low dimensional dense representations. The concatenate of different fields' embedding output from user pro f ile and ad form e user and e it em respectively. Accordingly, after embedding C, U, D and L, the outputs are e c \u2208 R T \u00d7E , e u \u2208 R T \u00d7E , Concat PAIR\n\n\nMulti-head Interaction-attention Component\n\n\nUNCK-SEQ\n\n\nMulti-head self-attention\n\n\nAttention\n\n\nCK-SEQ Attention\n\n\nMulti-head self-attention\n\n\nAttention\n\n\nDISLIKE-SEQ\n\n\nMulti-head self-attention\n\n\nAttention\n\n\nLIKE-SEQ\n\nMulti-head self-attention Figure 1: The overall architecture of denoising user-aware memory network. e d \u2208 R T \u00d7E and e l \u2208 R T \u00d7E , where E is the unified dimension of embedding.\n\n\nFeature Purification Layer\n\nThe feature purification layer takes the embedding lists e c and e u of implicit feedback, e l and e d of explicit feedback, e user of the user and e it em of the target item as inputs. Specially, the feature purification layer uses two components to learn the short-term interest expressed by the feedback sequences and purify the feature of implicit feedback by proposing a novel vector orthogonal mapping method.\n\n3.3.1 Multi-head Interaction-attention Component. Inspired by the potential of self-attention mechanism in data correlation learning [40], we model various feedback behaviors of users on the framework of multi-head self-attention network to obtain finegrained preference representation, and the whole process is shown in the lower right side of Fig. 1. We use e c as an example to introduce the working of multi-head self-attention network. Mathematically, we construct e c as a form with H heads, that is e c = [e c,1 , ..., e c,h , ..., e c, H ], where e c,h \u2208 R T \u00d7 1 H E is the h-th head of e c , H is the number of heads. The output of the multi-head selfattention network is calculated as follows:\nhead h = softmax( e c,h W Q c,h (e c,h W K c,h ) T \u221a T )e c,h W V c,h h = 1, 2, ..., H,(1)O c = Concat(head 1 , head 2 , ..., head H )W F(2)\nwhere W Q c,h , W K c,h and W V c,h are trainable linear matrices. Then, we calculate the attention value between the target ad item and the item representation of each position in the sequence representation through the full connection layer, as shown in the following formulas:\n\u03b1 j = ReLU(Concat(e user , e it em , o j c )W c ) j = 1, 2, ...,T ,(3)\u03b1 j = exp(\u03b1 j ) T j \u2032 =1 exp(\u03b1 j \u2032 ) j = 1, 2, ...,T ,(4)\nwhere o j c is the output representation of the j-th item through the multi-head self-attention network. W c is trainable linear matrix. ReLU(\u00b7) is the activation function. Then, the representation of the click sequence fused with the target item can be calculated as:\nf c = T j=1\u03b1 j o j c .(5)\nSimilarly, we can get the representations of unclick, like, and dislike sequences as f u , f l , and f d by using formulas (1)-(5).\n\n\nFeature Orthogonal Mapping Component.\n\nThe representations f c and f u of the implicit feedback contain inherent noise, and the goal of the feature orthogonal mapping component is to purify the representations f c and f u of implicit feedback. We argue that the explicit feedback representation which can definitely indicate user preferences can be used to purify the implicit feedback representation which can not directly indicate user preferences. So we extract two groups of orthogonal mapping pairs < click, dislike > and < unclick, like > with differences from implicit and explicit feedback, and their corresponding sequence representations are < f c , f d > and < f u , f l > respectively. Taking < f c , f d > as an example, in order to purify the representation of implicit feedback sequence with noise, we project the first element f c of the sequence representation pair onto the orthogonal direction of the second element f d . The original feature vector f c is projected into the orthogonal feature space to eliminate the noise features. Compared with the original vector, the orthogonal mapping vector contains pure and efficient user preferences.\n\nFormally, we describe the orthogonal mapping process of sequence pair < f c , f d > in a two-dimensional space shown in the middle of the right side of Fig. 1. The noise representation vector f p c in f c can be obtained by projecting the vector f c onto the vector\nf d : f p c = project(f c , f d ),(6)\nwhere project(a, b) = a \u00b7b |b | b |b | represent the projection function. a and b are vectors with the same dimension. Then, we can get the vector representation purified by orthogonal mapping as follows:\nf o c = f c \u2212 f p c .(7)\nObviously, according to formula (6), the representation of implicit feedback contains a mixture of user's click and dislike noise f \n\n\nUser Memory Network Layer\n\nIn order to get a more stable and fine-grained representation of long-term preference from the perspective of users than the itembased methods, we improve the memory network used in NTM [9]. Specifically, the memory network of NTM contains multiple slots to model the user's click sequence, and uses a controller to generate the key for reading or writing of the user's click sequence representation, so as to complete the operation of memory read and memory write for the memory network. Considering that memory network can store feature representation, and each slot has the characteristic of aggregating the same feature representation, we extend it to store user-level long-term interests, so that the user feature representation in the same slot can reflect the similar interests between users, and the long-term interest representation obtained in this way is more generalized than using only user_id embedding.\n\nWe improve the basic memory network as follows. First, in order to capture users' fine-grained unbiased long-term interests, we use four memory network M c , M u , M l and M d to save users' click, unclick, like and dislike preferences respectively, and each memory network contains m slots whose output dimension is Z . Second, the input of the controller is replaced by the concatenate of users' short-term representation obtained by FP and the embedding of user pro f ile from the representation of item to ensure that the model can learn the user level long-term interest representation.\n\nTaking M c as an example, memory read and memory write of M c are as follows.\n\nMemory read. Input the concatenate of f o c and e user , and the controller generates a read key k c to address the memory M c through a fully connected layer.\nk c = FFN(Concat(f o c , e user )),(8)\nwhere FFN(\u00b7) denotes the feed-forward network. Then, by traversing all memory slots, a weight vector w r c is generated:\nw r c (j) = exp(K(k c , M c (j))) m j \u2032 =1 exp(K(k c , M c (j \u2032 ))) j = 1, 2, ..., m,(9)K(k c , M c (j)) = k T c M c (j) \u2225k c \u2225 \u2225M c (j)\u2225 ,(10)\nfinally, the weighted memory summary is calculated as the output r c \u2208 R Z :\nr c = m j=1 w r c (j)M c (j).(11)\nMemory write. The generation of the weight vector w w c for memory write is similar to the memory read operation in equation (9). The controller also generates two additional keys, add vector add c and erase vector erase c , to control the update of memory.\nM c = (1 \u2212 E c ) \u2299 M c + A c ,(12)\nwhere E c = w w c \u2297 erase c is the erase matrix. A c = w w c \u2297 add c is the add matrix. \u2299 and \u2297 means dot product and outer product respectively.\n\nAccordingly, we can get four representations of users' long-term preferences: r c , r u , r l and r d .\n\n\nPreference-aware Interactive Representation Component\n\nIn order to get the cross representation of users' long-term and short-term interests, we design a gating mechanism to fuse the longterm and short-term representations of users' preferences with the same type. Similarly, we use the representation of click preference as an example to get the cross representation U c of long-term and short-term click preference through the following formula:\nU c = Concat(f o c * sigmoid(f o c W 1 ), r c * sigmoid(r c W 2 )),(13)\nwhere * is the Hadamard product. sigmoid(\u00b7) is the activation function and W is the dimension conversion matrix to ensure that the dimensions of the two vectors are consistent. The cross representation U u , U l and U d corresponding to unclick, like and dislike can also be obtained. Therefore, we get the deep cross representation interest representation of users:\nR cr oss = Concat(U c , U u , U l , U d ).(14)\nFinally, we concatenate the representations of user, target item, long-term interests, short-term interests and cross features as deep representations, and then use a fully connected layer with sigmoid(\u00b7) function to generate the predicted CTR as: y = sigmoid(FFN(Concat(e user , e it em , R cr oss ))).\n\n\nLoss Function\n\nIn our proposed model DUMN, we have two goals: 1) the predicted CTR of the target item should be as close to the true label as possible; and 2) we need to ensure that the content written into these 4 memory networks can truly express the user's long-term preferences of click, unclick, like and dislike. For goal 1), we achieve it by minimizing the average logistic loss as:\nL 1 = \u2212 1 N (x,y)\u2208 D (ylog(\u0177) + (1 \u2212 y)log(1 \u2212\u0177)),(16)\nwhere D is the training set of size N . x is the input of DUMN. y \u2208 {0, 1} represents whether the user clicks the target item. For goal 2), we propose an auxiliary loss based on triplet loss to help complete the memory write operation. Specifically, for each content update, we randomly sample an item from each of the four feedback sequences of click, unclick, like and dislike in each batch, and record their output s c , s u , s l and s d in the embedding layer. It is worth noting that the samples are sampled from the data of all user interactions, not only from the constructed sequence for short-term interest representation. Then, we construct positive and negative sample pairs < s c , s u >, < s u , s c >, < s l , s d > and < s d , s l > for M c , M u , M l and M d respectively. Without loss of generality, we use M c as an example to explain the proposed triplet loss:\nL c = max(d(q c , s c ) \u2212 d(q c , s u ) + mar\u0434in, 0),(17)q c = m j=1 w w c (j)M c (j),(18)d(a, b) = 1 \u2212 a \u00b7 b \u2225a\u2225 \u2225b \u2225 ,(19)\nwhere d(\u00b7, \u00b7) is the function to calculate the similarity, and cosine similarity is used in this paper. s c , s u and q c are positive sample, negative sample and anchor corresponding to the upper right side of Fig. 1, respectively. Similarly, we can get the triplet losses L u , L l and L d of M u , M l and M d , respectively. Furthermore, goal 2) can be achieved by accumulating these 4 auxiliary losses as:\nL 2 = L c + L u + L l + L d .(20)\nthen, the final loss function of DUMN is expressed as L = L 1 + L 2 .\n\n\nEXPERIMENTS\n\nIn this section, we conduct experiments on different datasets to prove the effectiveness of our DUMN by comparing with several state-of-the-art methods. We start with 3 research questions (RQ) to guide the experiment and the following discussion:\n\n\u2022 RQ1: Compared with state-of-the-art methods, can DUMN achieve better performance? \u2022 RQ2: What is the impact of modules designed in DUMN? Are the proposed feature purification layer and user memory network layer modules necessary for improving performance? \u2022 RQ3: What is the impact of hyper-parameter settings on CTR prediction performance in DUMN? We divide the above baselines into the following two categories: the first is the non-sequence method that does not construct feedback sequence to obtain cross features between users and items, including Wide&Deep, PNN and DeepFM; the second is the sequencebased method that uses feedback sequence information to capture   \n\n\nExperimental Setups\n\n\nParameter Settings. The DUMN model is implemented in\n\nPython based on the Tensorflow framework. All the experiments are conducted on a server machine equipped with a 16 GB NVIDIA Tesla V100 GPU. For hyper-parameters, the maximum length T of each feedback sequence is set to 100. The output dimension of the embedding layer is 16. The dimension of the feed-forward network used in the memory network is set to 512. The number of the slot in the memory network is set to 256 and the dimension of each slot is set to 64. During the training phase, we set the learning rate to 0.005 respectively, and use Adam as the optimizer. It is worth noting that the optimal parameters of DUMN are obtained by grid search, and the parameter sensitivity experiments of some important parameters are recorded in Section 4.4. For the performance of Alibaba dataset, the baseline methods such as AutoInt, DMT and DFN are implemented per their GitHub settings, and the rest baseline methods use the performance recorded in [6].\n\n\nResult Analysis (RQ1)\n\nWe evaluated the CTR prediction task on the datasets mentioned above. Specifically, the Area Under Curve (AUC) widely used in binary classification problems is used as the metric. The results of the evaluation on two datasets are recorded in Table 1. By comparing with several state-of-the-art baselines, the following three conclusions can be drawn: 1) Our proposed DUMN outperforms all baselines on these two datasets. The experimental results show that our proposed model is effective on the CTR prediction task, and the recommendation performance can be significantly improved by feature purification of implicit feedback representation and fusion of short-term and long-term interests. Compared with the best experimental results of baselines, the performances of DUMN on Alibaba dataset and Industrial dataset are improved by 1.18% and 0.97%, respectively. 2) Among the two kinds of baselines, most sequence-based methods (DIN, DIEN, DSIN, AutoInt, DMT and DFN) are better than non-sequence methods (Wide&Deep, PNN and DeepFM) in most cases, and an intuitive explanation is that these sequential methods can better capture the evolution of users' interests over time than non-sequential methods. It is worth noting that our DUMN also uses user feedback sequence, and uses attention mechanism to understand the evolution of user interest. 3) In the sequence-based method, DFN achieves relatively good results, which is close to the experimental results of DSIN. Specifically, it can better get the unbiased preference evolution of users by describing the user feedback data in a more fine-grained way. It is also worth noting that our DUMN further divides user interests into long-term interests and short-term interests, which can obtain more accurate and deeper unbiased user preference representation.\n\n\nAblation Study (RQ2)\n\nTo investigate the effectiveness of components in DUMN, we conduct extensive ablation studies on the two datasets.  Table 1, we can find that: It is effective to purify the noise by using the proposed orthogonal mapping method. An intuitive explanation is that the explicit representation can accurately represent a user's preference, and the orthogonal space obtained by it should also be a noise-free space, which can better describe the user's unbiased preferences.\n\n\nEffect of User Memory Network\n\nLayer. The user memory network layer is a fine-grained long-term interest characterization module based on user profile. In order to verify its effectiveness, we designed the following two models: DUMN-UMN which removes the user memory network layer and DUMN+UMN1 which replaces four memory networks with one memory network. Table 2 shows the evaluation results. It can be seen from the result that removing the representation of long-term interest or not distinguishing various feedback information will significantly reduce the prediction performance of the model, which is also in line with our previous hypothesis that only by fine-grained modeling multiple types of sequential feedback can we better understand the long-term preferences of the user. Then, we further explore whether the capture of long-term interest can improve other existing models. Therefore, we introduce the user memory network which can capture users' long-term interest into AutoInt and DFN to get models AutoInt+UMN and DFN+UMN. Table 3 shows the evaluation results, AutoInt+UMN and DFN+UMN beats AutoInt and DFN respectively, showing that the performance of existing methods has been improved after adding NUM module which can capture users' long-term interests, indicating that the integration of long-term and short-term interests can better understand the evolution of users' preferences.\n\n\nEffect of Preference-aware Interactive Representation\n\nComponent. The purpose of the preference-aware interactive representation component is to fuse short-term and long-term interests. In order to explore the impact of different fusion methods on CTR prediction performance, we design a variety of fusion methods and get the following four methods: DUMN CO N CAT which use concatenate operation, DUMN C RO S S which use cross operation, DUMN F F N which use the feed-forward network to represent first and then concatenate, and DUMN AT T E which use attention operation. Among them, concatenate operation represents the function Concat(\u00b7), and cross operation refers to the concatenate after the addition, subtraction and multiplication of the elements at the corresponding positions of two vectors. According to Table 4, the DUMN uses the gate-based method proposed in Section 3.5 can achieve the best performance on the fusion of long-term and short-term interest representation, which proves the feasibility of our proposed gate-based fusion method. In addition, we find that the cross and attention mechanism operations that can get high-order crossover features are better than the direct concatenate operation. The intuitive explanation is that the user's preference for the target item needs to be represented by both long-term interest and short-term interest, and the dependence of different items on the long-term and short-term is also different.\n\n\nEffect of the Proposed Triplet Loss.\n\nThe triplet loss is to ensure that the content written into the 4 memory networks can truly express the user's preferences. To evaluate the proposed triplet loss, we design a variety of comparison methods: DUMN-TL which removes the triplet loss from the loss function and DUMN RS which uses random sampling to sample positive and negative samples. It should be noted that our DUMN uses cosine similarity to find the hardest positive and negative samples in each batch. According to the results shown in Table 5, we can find that the performance of our DUMN is significantly reduced by removing the limit of triple loss, and different sampling samples also have an impact on the performance. Specifically, the more dissimilar the representations of the sample pairs are, the more effective it is to ensure that the contents written in the memory network are reliable.\n\n\nEffect of Implicit/Explicit\n\nFeedback. The intention of the finegrained description of various implicit and explicit feedback is to obtain unbiased user preferences. We design two models to evaluate the improvement of CTR prediction brought by fine-grained interest representation: DUMN I F which uses only implicit feedback and removes M l and M d in user memory network layer, DUMN AF which connects all types of feedback into a sequence through time.\n\nIt should be noted that these new models do not use orthogonal mapping to purify the representation of implicit feedback, and DUMN AF constructs a single sequence of all feedback information, which makes it difficult to capture the fine-grained interest representation formed by different types of user feedback. Table 6 shows the performance of the comparison methods, and we can find that DUMN AF that uses all types of the user's feedback information for interest characterization has better performance than the DUMN I F that only use implicit feedback. Furthermore, DUMN which finegrained description interest of users with various feedback can further improve the recommendation performance when compared with DUMN AF . It is intuitive that the user preferences indicated by different feedback are inconsistent, and the corresponding representation space should also be different. Accordingly, DUMN AF without fine-grained modeling of interest will lead to the relative confusion of multi-interest representation.\n\n\nParameter Sensitivity (RQ3)\n\nIn    Figure 3: Visualization of purification characteristics. Different color represent the representation results of different types of feedback in FP module, each \u22c6 represents the specific feedback generated by the user and item, and \u2666 represents the center of the interest representation cluster.\n\nrange of {16, 32, 64, 128, 256}. From Fig. 2, we can find that when m and Z in each memory network are 256 and 64 respectively, the performance of DUMN is the best. When m and Z are too large or too small, the effect of the model will be worse. The potential explanation for this phenomenon is that the parameters m and Z can directly reflect the storage capacity of the memory network.\n\nWhen the values of these parameters are small, the storage capacity is too weak to effectively store the long-term interests of users. If the values are too large, it may lead to overfitting.\n\n\nDislike Prediction\n\nThe above experiments show that the user's click preferences can be effectively predicted through DUMN, which is to predict the   Figure 5: Visualization of long-term and short-term interests.\n\n\u2022 represents the user's long-term interest, and the deepening of color represents the change process of user's long-term interest in the training process. \u22c6 denotes the user's shortterm interest.\n\nitems that the user is interested in. In this subsection, we further use DUMN to do the prediction task that users are not interested in, which is also a new prediction task recently proposed in DFN. It is dedicated to predicting whether users rate the target item as dislike, so as to avoid the model's prediction results from frustrating users. Table 7 records the experimental results of DUMN and DFN, from which we can find that DUMN can achieve better prediction results than the baseline experimental result, which indicates that our DUMN is more sensitive to the capture of disliked preferences, and the better experimental results come from our fine-grained preference modeling of user feedback.\n\n\nCase Study\n\nIn this section, we conduct case study to prove that the FP module FP of purifying implicit feedback representation and the PAIR module of capturing long-term interest is effective.\n\n4.6.1 Display of Purification Characteristics. First, we show the dimensionality reduction visualization of different short-term interest representations of the same user in Fig. 3. Specifically, it includes the click and the unclick representations before and after denoising, the like representation and the dislike representation. From the figure, we can find that the noise in implicit feedback representation is effectively removed, and the distance between the denoised representation and the representation of orthogonal mapping corresponding to explicit feedback is also far away. For example, compared with before purification, the presentation of click and unclick after purification is far away from that of dislike and like respectively.\n\n4.6.2 Display of Long-term Interest. Then, we visualized the representation of long-term interests obtained by multiple users from the memory network. It can be observed from Fig. 4 that the long-term interests of the same user are aggregated in the whole representation space, reflecting the stability of long-term interests, and the representations of long-term interests of different users can show intersection or no intersection. Among them, the non-intersection part reflects that users' interests are independent, and the intersection part indicates that users' long-term interests are partially similar.\n\n4.6.3 Display of Long-term and Short-term Interests. Last, we visualize the long-term interest representation and short-term interest representation in Fig. 5, and we can draw the following conclusions: 1) In the training process of DUMN, the user's long-term interest representation is gradually aggregated into a smaller space, reaching a more stable state; and 2) Compared with the relatively stable long-term interest representation learned, the short-term interest representation of the user presents a more dispersed state under the unified feature space, which reflects the difference between long-term and short-term interests. It is worth noting that our DUMN model can effectively capture users' long-term and short-term interests of users through the FP module and the UMN module.\n\n\nCONCLUSION\n\nIn this paper, we propose a novel denoising user-aware memory network (DUMN), which constructs four feedback sequences of users, namely click, unclick, like and dislike, to model users' preferences in a fine-grained way. DUMN uses feature purification layer and user memory network layer to purify the implicit feedback sequence representation of users and capture the stable long-term preference of users, respectively. A large number of experiments verify the effectiveness of the proposed model in the CTR prediction task. Experiments verify the effectiveness of the proposed model in the CTR prediction task. In the future, we intend to further explore the impact of noise purification and long-term interest in different recommendation scenarios, and subdivide the fine-grained representation of users on the basis of the existing to obtain more comprehensive unbiased preference representation of users.\n\n\nis filtered from the original representation f c , and the new pure feature f o c can effectively represent the user's pure click preference in orthogonal space, which is also in line with the assumption that the user's click and dislike representation should be distinctive. Similarly, according to formulas (6)-(7), we can get the orthogonal mapping vector f o u between the representation f u of unclick sequence and the representation f l of like sequence, and the purified vectors f o c and f o u can better describe the unbiased preferences of users.\n\n4.3. 1\n1Effect of Feature Purification. The purpose of feature purification can purify the presentation of implicit feedback sequences with noise. In order to explore the effectiveness of using explicit feedback representation to denoise implicit feedback representation by orthogonal mapping in the FP component, we design DUMN-FP which removes the FP component for denoising. The evaluation results of DUMN-FP in Alibaba dataset and Industrial dataset are 0.6417 and 0.7981 respectively. Comparing the results with those of DUMN reported in\n\nFigure 2 :\n2Impact of m and Z .\n\nFigure 4 :\n4Visualization of long-term interest. Different colors represent the long-term interest representation of different users, and each point refers to the user's long-term interest representation read from the memory network.long-t erm m em ory short -t erm behavior\n\n\n\u2022 Wide&deep: Wide&Deep[3] consists of two parts: wide module of memory and deep module of generalization. It can effectively capture the high-order cross features between users and items. \u2022 PNN: PNN[33] uses the product layer containing inner product and outer product to capture the interactive patterns between interfield categories. \u2022 DeepFM: DeepFM[11] is achieved by replacing the wide component in Wide&Deep with FM layer, which can also capture the cross features of users and items. \u2022 DIN: DIN[50] uses attention mechanism to activate related users' historical behaviors, which can fully exploits the relationship between users' historical behaviors and the target item. \u2022 DIEN: DIEN[49] uses two layers of GRU to extract latent temporal interests from user behaviors and models interests evolving process. \u2022 DSIN: DSIN[6] divides the user's historical click sequence into sessions, and then apply Bi-LSTM to model how users' interests evolve and interact among sessions. \u2022 AutoInt: AutoInt[37] introduces self-attentive neural network to find low-dimensional representations of the sparse and highdimensional raw features and their meaningful combinations. \u2022 DFN: DFN[44] jointly consider explicit and implicit feedback to learn user unbiased preferences for recommendation. Among them, the explicit feedback includes dislike sequence, and the implicit feedback includes click sequence and unclick sequence. \u2022 DMT: DMT[10] uses multiple Transformers to model users' multiple types of behavior sequences, including click sequence of items, cart sequence of items, and order sequence of items.4.1.1 Data Description. We evaluate the model on two real-world e-\ncommerce datasets, namely Alibaba dataset and Industrial dataset. \nFor the Alibaba dataset, it is a public dataset, collecting ad dis-\nplay/feedback logs of 1.14 million users in Taobao's recommenda-\ntion system. We have made statistics on the training set and test set \nof Alibaba dataset, including 26 million pieces of feedback records \nfrom 1.14 million users in 0.8 million items, and these items can \nbe divided into 12,960 categories. For Industrial dataset, it contains \n5.5 billion feedback records from 1.1 billion users and 91.0 million \nitems in 30 days. Records from 2020-12-25 to 2021-01-18 are for \ntraining, and records from 2021-01-19 to 2021-01-24 are for testing. \nIn particular, these two datasets contain a variety of implicit and \nexplicit feedback data, we record the items purchased, added to the \nshopping cart and labeled with like in the log feedback as explicit \nlike feedback, the items marked with dislike as explicit dislike feed-\nback, the items simply clicked by user as implicit click feedback, \nthe items displayed but not operated as implicit unclick feedback. \nSince we focus on the CTR prediction tasks, we treat all valid click \ninteractions with the label of 1. \n\n4.1.2 Compared Methods. We compared DUMN with following \nmainstream CTR prediction methods: \n\n\n\nTable 1 :\n1Performance comparison with different baselines.Model \nAlibaba Industrial \n\nWide&Deep 0.6326 \n0.7526 \nPNN \n0.6328 \n0.7602 \nDeepFM \n0.6347 \n0.7612 \nDIN \n0.6330 \n0.7653 \nDIEN \n0.6343 \n0.7803 \nDSIN \n0.6375 \n0.7873 \nAutoInt \n0.6360 \n0.7708 \nDFN \n0.6368 \n0.7884 \nDMT \n0.6378 \n0.8039 \n\nDUMN \n0.6496 \n0.8136 \n\n\n\nTable 2 :\n2Effect of user memory network layer.Model \nAlibaba Industrial \n\nDUMN-UMN \n0.6434 \n0.7966 \nDUMN+UMN1 0.6446 \n0.8073 \nDUMN \n0.6496 \n0.8136 \n\n\n\nTable 3 :\n3Effect of NTM.Model \nAlibaba Industrial \n\nAutoInt \n0.6360 \n0.7708 \nAutoInt+UMN 0.6396 \n0.7802 \n\nDFN \n0.6368 \n0.7884 \nDFN+UMN \n0.6437 \n0.7973 \n\nusers' interest evolution, including DIN, DIEN, DSIN, AutoInt, DMT \nand DFN. In particular, DMT and DFN are models based on implicit \nfeedback and explicit feedback. \n\n\n\nTable 4 :\n4Effect of PAIR.Model \nAlibaba Industrial \n\nDUMN CO N CAT \n0.6438 \n0.8023 \nDUMN C RO S S \n0.6487 \n0.8049 \nDUMN F F N \n0.6486 \n0.8037 \nDUMN AT T E \n0.6433 \n0.7966 \nDUMN \n0.6496 \n0.8136 \n\n\n\nTable 5 :\n5Effect of the proposed triplet loss.Model \nAlibaba Industrial \n\nDUMN-TL 0.6467 \n0.7969 \nDUMN RS \n0.6472 \n0.7991 \nDUMN \n0.6496 \n0.8136 \n\nTable 6: Effect of implicit feedback. \n\nModel \nAlibaba Industrial \n\nDUMN I F \n0.6392 \n0.8072 \nDUMN AF \n0.6394 \n0.8091 \nDUMN \n0.6496 \n0.8136 \n\n\n\n\nthis subsection, we investigate the impact of two hyperparameters in our developed DUMN framework: the number of slots m and dimension Z of slots. For conciseness, we report experimental results on Alibaba dataset. We make the number of slots m in DUMN varies in a range of {16, 32, 64, 128, 256} and let the dimension Z of each slot varies in a Memory Size (slot * dimension) AUC of different memory size0.647 \n\n0.648 \n\n0.649 \n\n0.65 \n\nAUC \n\n16*16 \n\n32*16 \n\n64*16 \n\n128*32 \n\n128*64 \n\n256*64 \n\n256*128 \n\n256*256 \n\n\n\nTable 7 :\n7Results of dislike prediction on Alibaba dataset.Model Alibaba-dislike Industrial-dislike \n\nDFN \n0.7609 \n0.7394 \nDUMN \n0.8062 \n0.7601 \n\nclick \n\nunclick \n\nlike \n\ndislike \n\ndistilled_click \n\ndistilled_unclick \n\n(a) \n(b) \n\n\n\nLiJAR: A system for job application redistribution towards efficient career marketplace. Fedor Borisyuk, Liang Zhang, Krishnaram Kenthapadi, Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data MiningFedor Borisyuk, Liang Zhang, and Krishnaram Kenthapadi. 2017. LiJAR: A system for job application redistribution towards efficient career marketplace. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. 1397-1406.\n\nFast adaptively weighted matrix factorization for recommendation with implicit feedback. Jiawei Chen, Can Wang, Sheng Zhou, Qihao Shi, Jingbang Chen, Yan Feng, Chun Chen, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence34Jiawei Chen, Can Wang, Sheng Zhou, Qihao Shi, Jingbang Chen, Yan Feng, and Chun Chen. 2020. Fast adaptively weighted matrix factorization for recommen- dation with implicit feedback. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 34. 3470-3477.\n\n. Heng-Tze, Levent Cheng, Jeremiah Koc, Tal Harmsen, Tushar Shaked, Hrishi Chandra, Glen Aradhye, Greg Anderson, Wei Corrado, Mustafa Chai, Ispir, Heng-Tze Cheng, Levent Koc, Jeremiah Harmsen, Tal Shaked, Tushar Chandra, Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, et al.\n\nWide & deep learning for recommender systems. Proceedings of the 1st workshop on deep learning for recommender systems. the 1st workshop on deep learning for recommender systemsWide & deep learning for recommender systems. In Proceedings of the 1st workshop on deep learning for recommender systems. 7-10.\n\nDeep neural networks for youtube recommendations. Paul Covington, Jay Adams, Emre Sargin, Proceedings of the 10th ACM conference on recommender systems. the 10th ACM conference on recommender systemsPaul Covington, Jay Adams, and Emre Sargin. 2016. Deep neural networks for youtube recommendations. In Proceedings of the 10th ACM conference on recommender systems. 191-198.\n\nBERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, NAACL-HLT. Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In NAACL-HLT (1).\n\nDeep Session Interest Network for Click-Through Rate Prediction. Yufei Feng, Fuyu Lv, Weichen Shen, Menghan Wang, Fei Sun, Yu Zhu, Keping Yang, IJCAI International Joint Conference on Artificial Intelligence, Sarit Kraus (Ed.). ijcai.org. Yufei Feng, Fuyu Lv, Weichen Shen, Menghan Wang, Fei Sun, Yu Zhu, and Keping Yang. 2019. Deep Session Interest Network for Click-Through Rate Prediction. In IJCAI International Joint Conference on Artificial Intelligence, Sarit Kraus (Ed.). ijcai.org, 2301-2307.\n\nAlgorithms for nonnegative matrix factorization with the \u03b2 -divergence. C\u00e9dric F\u00e9votte, J\u00e9r\u00f4me Idier, Neural computation. 23C\u00e9dric F\u00e9votte and J\u00e9r\u00f4me Idier. 2011. Algorithms for nonnegative matrix factor- ization with the \u03b2 -divergence. Neural computation 23, 9 (2011), 2421-2456.\n\nUsing collaborative filtering to weave an information tapestry. David Goldberg, David Nichols, M Brian, Douglas Oki, Terry, Commun. ACM. 35David Goldberg, David Nichols, Brian M Oki, and Douglas Terry. 1992. Using collaborative filtering to weave an information tapestry. Commun. ACM 35, 12 (1992), 61-70.\n\nAlex Graves, Greg Wayne, Ivo Danihelka, arXiv:1410.5401Neural turing machines. arXiv preprintAlex Graves, Greg Wayne, and Ivo Danihelka. 2014. Neural turing machines. arXiv preprint arXiv:1410.5401 (2014).\n\nDeep Multifaceted Transformers for Multi-objective Ranking in Large-Scale E-commerce Recommender Systems. Yulong Gu, Zhuoye Ding, Shuaiqiang Wang, Lixin Zou, Yiding Liu, Dawei Yin, Proceedings of the 29th ACM International Conference on Information & Knowledge Management. the 29th ACM International Conference on Information & Knowledge ManagementYulong Gu, Zhuoye Ding, Shuaiqiang Wang, Lixin Zou, Yiding Liu, and Dawei Yin. 2020. Deep Multifaceted Transformers for Multi-objective Ranking in Large-Scale E-commerce Recommender Systems. In Proceedings of the 29th ACM International Conference on Information & Knowledge Management. 2493-2500.\n\nDeepFM: a factorization-machine based neural network for CTR prediction. Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, Xiuqiang He, arXiv:1703.04247arXiv preprintHuifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, and Xiuqiang He. 2017. DeepFM: a factorization-machine based neural network for CTR prediction. arXiv preprint arXiv:1703.04247 (2017).\n\nRank and rate: multi-task learning for recommender systems. Guy Hadash, Oren Sar Shalom, Rita Osadchy, Proceedings of the 12th ACM Conference on Recommender Systems. the 12th ACM Conference on Recommender SystemsGuy Hadash, Oren Sar Shalom, and Rita Osadchy. 2018. Rank and rate: multi-task learning for recommender systems. In Proceedings of the 12th ACM Conference on Recommender Systems. 451-454.\n\nSession-based Recommendations with Recurrent Neural Networks. Bal\u00e1zs Hidasi, Alexandros Karatzoglou, 4th International Conference on Learning Representations. Linas Baltrunas, and Domonkos Tikk. ICLRBal\u00e1zs Hidasi, Alexandros Karatzoglou, Linas Baltrunas, and Domonkos Tikk. 2016. Session-based Recommendations with Recurrent Neural Networks. In 4th International Conference on Learning Representations (ICLR).\n\nCollaborative filtering for implicit feedback datasets. Yifan Hu, Yehuda Koren, Chris Volinsky, Eighth IEEE International Conference on Data Mining. IeeeYifan Hu, Yehuda Koren, and Chris Volinsky. 2008. Collaborative filtering for implicit feedback datasets. In 2008 Eighth IEEE International Conference on Data Mining. Ieee, 263-272.\n\nDensely connected convolutional networks. Gao Huang, Zhuang Liu, Laurens Van Der Maaten, Kilian Q Weinberger, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionGao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kilian Q Weinberger. 2017. Densely connected convolutional networks. In Proceedings of the IEEE conference on computer vision and pattern recognition. 4700-4708.\n\nUnifying explicit and implicit feedback for rating prediction and ranking recommendation tasks. H Amir, Craig Jadidinejad, Iadh Macdonald, Ounis, Proceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval. the 2019 ACM SIGIR International Conference on Theory of Information RetrievalAmir H Jadidinejad, Craig Macdonald, and Iadh Ounis. 2019. Unifying explicit and implicit feedback for rating prediction and ranking recommendation tasks. In Pro- ceedings of the 2019 ACM SIGIR International Conference on Theory of Information Retrieval. 149-156.\n\nAn Efficient Neighborhood-based Interaction Model for Recommendation on Heterogeneous Graph. Jiarui Jin, Jiarui Qin, Yuchen Fang, Kounianhua Du, Weinan Zhang, Yong Yu, Zheng Zhang, Alexander J Smola, Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data MiningJiarui Jin, Jiarui Qin, Yuchen Fang, Kounianhua Du, Weinan Zhang, Yong Yu, Zheng Zhang, and Alexander J Smola. 2020. An Efficient Neighborhood-based Interaction Model for Recommendation on Heterogeneous Graph. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 75-84.\n\nSelf-attentive sequential recommendation. Wang-Cheng Kang, Julian Mcauley, 2018 IEEE International Conference on Data Mining (ICDM). IEEEWang-Cheng Kang and Julian McAuley. 2018. Self-attentive sequential recom- mendation. In 2018 IEEE International Conference on Data Mining (ICDM). IEEE, 197-206.\n\nSemi-supervised classification with graph convolutional networks. N Thomas, Max Kipf, Welling, arXiv:1609.02907arXiv preprintThomas N Kipf and Max Welling. 2016. Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907 (2016).\n\nFactorization meets the neighborhood: a multifaceted collaborative filtering model. Yehuda Koren, Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining. the 14th ACM SIGKDD international conference on Knowledge discovery and data miningYehuda Koren. 2008. Factorization meets the neighborhood: a multifaceted collaborative filtering model. In Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining. 426-434.\n\nMatrix factorization techniques for recommender systems. Yehuda Koren, Robert Bell, Chris Volinsky, Computer. 42Yehuda Koren, Robert Bell, and Chris Volinsky. 2009. Matrix factorization tech- niques for recommender systems. Computer 42, 8 (2009), 30-37.\n\nNeural attentive session-based recommendation. Jing Li, Pengjie Ren, Zhumin Chen, Zhaochun Ren, Tao Lian, Jun Ma, Proceedings of the 2017 ACM on Conference on Information and Knowledge Management. the 2017 ACM on Conference on Information and Knowledge ManagementJing Li, Pengjie Ren, Zhumin Chen, Zhaochun Ren, Tao Lian, and Jun Ma. 2017. Neural attentive session-based recommendation. In Proceedings of the 2017 ACM on Conference on Information and Knowledge Management. 1419-1428.\n\nInterpretable Click-Through Rate Prediction through Hierarchical Attention. Zeyu Li, Wei Cheng, Yang Chen, Haifeng Chen, Wei Wang, Proceedings of the 13th International Conference on Web Search and Data Mining. the 13th International Conference on Web Search and Data MiningZeyu Li, Wei Cheng, Yang Chen, Haifeng Chen, and Wei Wang. 2020. Interpretable Click-Through Rate Prediction through Hierarchical Attention. In Proceedings of the 13th International Conference on Web Search and Data Mining. 313-321.\n\nLearning from history and present: Next-item recommendation via discriminatively exploiting user behaviors. Zhi Li, Hongke Zhao, Qi Liu, Zhenya Huang, Tao Mei, Enhong Chen, Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data MiningZhi Li, Hongke Zhao, Qi Liu, Zhenya Huang, Tao Mei, and Enhong Chen. 2018. Learning from history and present: Next-item recommendation via discrim- inatively exploiting user behaviors. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 1734-1743.\n\nxdeepfm: Combining explicit and implicit feature interactions for recommender systems. Jianxun Lian, Xiaohuan Zhou, Fuzheng Zhang, Zhongxia Chen, Xing Xie, Guangzhong Sun, Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data MiningJianxun Lian, Xiaohuan Zhou, Fuzheng Zhang, Zhongxia Chen, Xing Xie, and Guangzhong Sun. 2018. xdeepfm: Combining explicit and implicit feature in- teractions for recommender systems. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 1754-1763.\n\nUnifying explicit and implicit feedback for collaborative filtering. N Nathan, Evan W Liu, Min Xiang, Qiang Zhao, Yang, Proceedings of the 19th ACM international conference on Information and knowledge management. the 19th ACM international conference on Information and knowledge managementNathan N Liu, Evan W Xiang, Min Zhao, and Qiang Yang. 2010. Unifying explicit and implicit feedback for collaborative filtering. In Proceedings of the 19th ACM international conference on Information and knowledge management. 1445-1448.\n\nSDM: Sequential deep matching model for online large-scale recommender system. Fuyu Lv, Taiwei Jin, Changlong Yu, Fei Sun, Quan Lin, Proceedings of the 28th ACM International Conference on Information and Knowledge Management. the 28th ACM International Conference on Information and Knowledge ManagementKeping Yang, and Wilfred NgFuyu Lv, Taiwei Jin, Changlong Yu, Fei Sun, Quan Lin, Keping Yang, and Wil- fred Ng. 2019. SDM: Sequential deep matching model for online large-scale recommender system. In Proceedings of the 28th ACM International Conference on Information and Knowledge Management. 2635-2643.\n\nFuyu Lv, Mengxue Li, Tonglei Guo, Changlong Yu, Fei Sun, arXiv:2010.12837Taiwei Jin, and Keping Yang. 2020. Unclicked User Behaviors Enhanced SequentialRecommendation. arXiv preprintFuyu Lv, Mengxue Li, Tonglei Guo, Changlong Yu, Fei Sun, Taiwei Jin, and Keping Yang. 2020. Unclicked User Behaviors Enhanced SequentialRecommendation. arXiv preprint arXiv:2010.12837 (2020).\n\nPerceive your users in depth: Learning universal user representations from multiple e-commerce tasks. Yabo Ni, Dan Ou, Shichen Liu, Xiang Li, Wenwu Ou, Anxiang Zeng, Luo Si, Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data MiningYabo Ni, Dan Ou, Shichen Liu, Xiang Li, Wenwu Ou, Anxiang Zeng, and Luo Si. 2018. Perceive your users in depth: Learning universal user representations from multiple e-commerce tasks. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 596-605.\n\n. Kyo Joong Oh, Won Jo Lee, Chae Gyun Lim, Ho Jin Choi, Personalized news recommendation using classified keywords to capture user preferenceKyo Joong Oh, Won Jo Lee, Chae Gyun Lim, and Ho Jin Choi. 2014. Personalized news recommendation using classified keywords to capture user preference.\n\nPractice on long sequential user behavior modeling for click-through rate prediction. Qi Pi, Weijie Bian, Guorui Zhou, Xiaoqiang Zhu, Kun Gai, Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data MiningQi Pi, Weijie Bian, Guorui Zhou, Xiaoqiang Zhu, and Kun Gai. 2019. Practice on long sequential user behavior modeling for click-through rate prediction. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 2671-2679.\n\nFeature projection for improved text classification. Qi Qin, Wenpeng Hu, Bing Liu, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. the 58th Annual Meeting of the Association for Computational LinguisticsQi Qin, Wenpeng Hu, and Bing Liu. 2020. Feature projection for improved text classification. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. 8161-8171.\n\nProduct-based neural networks for user response prediction. Yanru Qu, Han Cai, Kan Ren, Weinan Zhang, Yong Yu, Ying Wen, Jun Wang, 2016 IEEE 16th International Conference on Data Mining (ICDM). IEEEYanru Qu, Han Cai, Kan Ren, Weinan Zhang, Yong Yu, Ying Wen, and Jun Wang. 2016. Product-based neural networks for user response prediction. In 2016 IEEE 16th International Conference on Data Mining (ICDM). IEEE, 1149-1154.\n\nYou only look once: Unified, real-time object detection. Joseph Redmon, Santosh Divvala, Ross Girshick, Ali Farhadi, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionJoseph Redmon, Santosh Divvala, Ross Girshick, and Ali Farhadi. 2016. You only look once: Unified, real-time object detection. In Proceedings of the IEEE conference on computer vision and pattern recognition. 779-788.\n\nRecVAE: A new variational autoencoder for Top-N recommendations with implicit feedback. Ilya Shenbin, Anton Alekseev, Elena Tutubalina, Valentin Malykh, Sergey, Nikolenko, Proceedings of the 13th International Conference on Web Search and Data Mining. the 13th International Conference on Web Search and Data MiningIlya Shenbin, Anton Alekseev, Elena Tutubalina, Valentin Malykh, and Sergey I Nikolenko. 2020. RecVAE: A new variational autoencoder for Top-N recommen- dations with implicit feedback. In Proceedings of the 13th International Conference on Web Search and Data Mining. 528-536.\n\nHeterogeneous information network embedding for recommendation. Chuan Shi, Binbin Hu, Wayne Xin Zhao, S Yu Philip, IEEE Transactions on Knowledge and Data Engineering. 31Chuan Shi, Binbin Hu, Wayne Xin Zhao, and S Yu Philip. 2018. Heterogeneous information network embedding for recommendation. IEEE Transactions on Knowledge and Data Engineering 31, 2 (2018), 357-370.\n\nAutoint: Automatic feature interaction learning via selfattentive neural networks. Weiping Song, Chence Shi, Zhiping Xiao, Zhijian Duan, Yewen Xu, Ming Zhang, Jian Tang, Proceedings of the 28th ACM International Conference on Information and Knowledge Management. the 28th ACM International Conference on Information and Knowledge ManagementWeiping Song, Chence Shi, Zhiping Xiao, Zhijian Duan, Yewen Xu, Ming Zhang, and Jian Tang. 2019. Autoint: Automatic feature interaction learning via self- attentive neural networks. In Proceedings of the 28th ACM International Conference on Information and Knowledge Management. 1161-1170.\n\nPersonalized top-n sequential recommendation via convolutional sequence embedding. Jiaxi Tang, Ke Wang, Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining. the Eleventh ACM International Conference on Web Search and Data MiningJiaxi Tang and Ke Wang. 2018. Personalized top-n sequential recommenda- tion via convolutional sequence embedding. In Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining. 565-573.\n\nDeep content-based music recommendation. A\u00e4ron Van Den, Sander Oord, Benjamin Dieleman, Schrauwen, Neural Information Processing Systems Conference (NIPS 2013). 26Neural Information Processing Systems Foundation (NIPS)A\u00e4ron Van Den Oord, Sander Dieleman, and Benjamin Schrauwen. 2013. Deep content-based music recommendation. In Neural Information Processing Systems Conference (NIPS 2013), Vol. 26. Neural Information Processing Systems Founda- tion (NIPS).\n\nAttention is All you Need. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, Illia Polosukhin, NIPS. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention is All you Need. In NIPS.\n\nDeep & cross network for ad click predictions. Ruoxi Wang, Bin Fu, Gang Fu, Mingliang Wang, Proceedings of the ADKDD'17. the ADKDD'17Ruoxi Wang, Bin Fu, Gang Fu, and Mingliang Wang. 2017. Deep & cross network for ad click predictions. In Proceedings of the ADKDD'17. 1-7.\n\nBeyond clicks: Modeling multi-relational item graph for session-based target behavior prediction. Wen Wang, Wei Zhang, Shukai Liu, Qi Liu, Bo Zhang, Leyu Lin, Hongyuan Zha, Proceedings of The Web Conference 2020. The Web Conference 2020Wen Wang, Wei Zhang, Shukai Liu, Qi Liu, Bo Zhang, Leyu Lin, and Hongyuan Zha. 2020. Beyond clicks: Modeling multi-relational item graph for session-based target behavior prediction. In Proceedings of The Web Conference 2020. 3056-3062.\n\nXiangnan He, and Tat-Seng Chua. 2020. Graph-Refined Convolutional Network for Multimedia Recommendation with Implicit Feedback. Yinwei Wei, Xiang Wang, Liqiang Nie, Proceedings of the 28th ACM International Conference on Multimedia. the 28th ACM International Conference on MultimediaYinwei Wei, Xiang Wang, Liqiang Nie, Xiangnan He, and Tat-Seng Chua. 2020. Graph-Refined Convolutional Network for Multimedia Recommendation with Implicit Feedback. In Proceedings of the 28th ACM International Conference on Multimedia. 3541-3549.\n\nRuobing Xie, Cheng Ling, Yalong Wang, Rui Wang, Feng Xia, and Leyu Lin. 2020. Deep Feedback Network for Recommendation. Proceedings of IJCAI-PRICAI. Ruobing Xie, Cheng Ling, Yalong Wang, Rui Wang, Feng Xia, and Leyu Lin. 2020. Deep Feedback Network for Recommendation. Proceedings of IJCAI-PRICAI (2020).\n\nPersonalized entity recommendation: A heterogeneous information network approach. Xiao Yu, Xiang Ren, Yizhou Sun, Quanquan Gu, Bradley Sturt, Urvashi Khandelwal, Brandon Norick, Jiawei Han, Proceedings of the 7th ACM international conference on Web search and data mining. the 7th ACM international conference on Web search and data miningXiao Yu, Xiang Ren, Yizhou Sun, Quanquan Gu, Bradley Sturt, Urvashi Khandel- wal, Brandon Norick, and Jiawei Han. 2014. Personalized entity recommendation: A heterogeneous information network approach. In Proceedings of the 7th ACM international conference on Web search and data mining. 283-292.\n\nCoupledcf: Learning explicit and implicit user-item couplings in recommendation for deep collaborative filtering. Quangui Zhang, Longbing Cao, Chengzhang Zhu, Zhiqiang Li, Jinguang Sun, IJCAI International Joint Conference on Artificial Intelligence. Quangui Zhang, Longbing Cao, Chengzhang Zhu, Zhiqiang Li, and Jinguang Sun. 2018. Coupledcf: Learning explicit and implicit user-item couplings in recommendation for deep collaborative filtering. In IJCAI International Joint Conference on Artificial Intelligence.\n\nRecommendations with negative feedback via pairwise deep reinforcement learning. Xiangyu Zhao, Liang Zhang, Zhuoye Ding, Long Xia, Jiliang Tang, Dawei Yin, Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data MiningXiangyu Zhao, Liang Zhang, Zhuoye Ding, Long Xia, Jiliang Tang, and Dawei Yin. 2018. Recommendations with negative feedback via pairwise deep reinforcement learning. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 1040-1048.\n\nAtrank: An attention-based user behavior modeling framework for recommendation. Chang Zhou, Jinze Bai, Junshuai Song, Xiaofei Liu, Zhengchao Zhao, Xiusi Chen, Jun Gao, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence32Chang Zhou, Jinze Bai, Junshuai Song, Xiaofei Liu, Zhengchao Zhao, Xiusi Chen, and Jun Gao. 2018. Atrank: An attention-based user behavior modeling frame- work for recommendation. In Proceedings of the AAAI Conference on Artificial Intelligence, Vol. 32.\n\nDeep interest evolution network for click-through rate prediction. Guorui Zhou, Na Mou, Ying Fan, Qi Pi, Weijie Bian, Chang Zhou, Xiaoqiang Zhu, Kun Gai, Proceedings of the AAAI conference on artificial intelligence. the AAAI conference on artificial intelligence33Guorui Zhou, Na Mou, Ying Fan, Qi Pi, Weijie Bian, Chang Zhou, Xiaoqiang Zhu, and Kun Gai. 2019. Deep interest evolution network for click-through rate prediction. In Proceedings of the AAAI conference on artificial intelligence, Vol. 33. 5941-5948.\n\nDeep interest network for click-through rate prediction. Guorui Zhou, Xiaoqiang Zhu, Chenru Song, Ying Fan, Han Zhu, Xiao Ma, Yanghui Yan, Junqi Jin, Han Li, Kun Gai, Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data MiningGuorui Zhou, Xiaoqiang Zhu, Chenru Song, Ying Fan, Han Zhu, Xiao Ma, Yanghui Yan, Junqi Jin, Han Li, and Kun Gai. 2018. Deep interest network for click-through rate prediction. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 1059-1068.\n", "annotations": {"author": "[{\"end\":174,\"start\":138},{\"end\":188,\"start\":175},{\"end\":196,\"start\":189},{\"end\":209,\"start\":197},{\"end\":251,\"start\":210},{\"end\":264,\"start\":252},{\"end\":295,\"start\":265},{\"end\":307,\"start\":296},{\"end\":320,\"start\":308},{\"end\":330,\"start\":321},{\"end\":344,\"start\":331},{\"end\":352,\"start\":345},{\"end\":365,\"start\":353},{\"end\":377,\"start\":366},{\"end\":390,\"start\":378},{\"end\":403,\"start\":391},{\"end\":415,\"start\":404},{\"end\":428,\"start\":416},{\"end\":457,\"start\":429},{\"end\":487,\"start\":458},{\"end\":517,\"start\":488},{\"end\":547,\"start\":518},{\"end\":577,\"start\":548},{\"end\":666,\"start\":578},{\"end\":696,\"start\":667},{\"end\":726,\"start\":697}]", "publisher": "[{\"end\":59,\"start\":56},{\"end\":912,\"start\":909}]", "author_last_name": "[{\"end\":146,\"start\":142},{\"end\":187,\"start\":183},{\"end\":195,\"start\":193},{\"end\":208,\"start\":204},{\"end\":220,\"start\":217},{\"end\":263,\"start\":259},{\"end\":276,\"start\":273},{\"end\":306,\"start\":303},{\"end\":319,\"start\":317},{\"end\":329,\"start\":325},{\"end\":343,\"start\":339},{\"end\":351,\"start\":349},{\"end\":364,\"start\":360},{\"end\":376,\"start\":373},{\"end\":389,\"start\":385},{\"end\":402,\"start\":399},{\"end\":414,\"start\":411}]", "author_first_name": "[{\"end\":141,\"start\":138},{\"end\":182,\"start\":175},{\"end\":192,\"start\":189},{\"end\":203,\"start\":197},{\"end\":216,\"start\":210},{\"end\":258,\"start\":252},{\"end\":272,\"start\":265},{\"end\":302,\"start\":296},{\"end\":316,\"start\":308},{\"end\":324,\"start\":321},{\"end\":338,\"start\":331},{\"end\":348,\"start\":345},{\"end\":359,\"start\":353},{\"end\":372,\"start\":366},{\"end\":384,\"start\":378},{\"end\":398,\"start\":391},{\"end\":410,\"start\":404},{\"end\":424,\"start\":416},{\"end\":427,\"start\":425}]", "author_affiliation": "[{\"end\":456,\"start\":430},{\"end\":486,\"start\":459},{\"end\":516,\"start\":489},{\"end\":546,\"start\":519},{\"end\":576,\"start\":549},{\"end\":665,\"start\":579},{\"end\":695,\"start\":668},{\"end\":725,\"start\":698}]", "title": "[{\"end\":55,\"start\":1},{\"end\":781,\"start\":727}]", "venue": "[{\"end\":843,\"start\":783}]", "abstract": "[{\"end\":3019,\"start\":1309}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b13\"},\"end\":3264,\"start\":3260},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":3267,\"start\":3264},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":3270,\"start\":3267},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":3273,\"start\":3270},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":3656,\"start\":3652},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":3693,\"start\":3690},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":3965,\"start\":3961},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":3985,\"start\":3981},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":4002,\"start\":3998},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":4176,\"start\":4172},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":4179,\"start\":4176},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":4182,\"start\":4179},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":4209,\"start\":4205},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":4222,\"start\":4219},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":4583,\"start\":4579},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":4677,\"start\":4673},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":4680,\"start\":4677},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":5413,\"start\":5409},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":5422,\"start\":5418},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":5606,\"start\":5602},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":5612,\"start\":5608},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":5621,\"start\":5617},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":6041,\"start\":6037},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":6063,\"start\":6059},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":6962,\"start\":6958},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":6973,\"start\":6969},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":6986,\"start\":6983},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":8297,\"start\":8293},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":8310,\"start\":8307},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":9076,\"start\":9072},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":9593,\"start\":9590},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":11351,\"start\":11347},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":11489,\"start\":11485},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":11492,\"start\":11489},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":11495,\"start\":11492},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":11498,\"start\":11495},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":11550,\"start\":11546},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":11620,\"start\":11616},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":11919,\"start\":11915},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":11935,\"start\":11931},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":12157,\"start\":12153},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":12281,\"start\":12278},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":12743,\"start\":12740},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":13161,\"start\":13157},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":13200,\"start\":13197},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":13244,\"start\":13240},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":13376,\"start\":13372},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":13379,\"start\":13376},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":13412,\"start\":13409},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":13491,\"start\":13488},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":13503,\"start\":13499},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":13514,\"start\":13510},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":13528,\"start\":13525},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":13889,\"start\":13885},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":13892,\"start\":13889},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":13907,\"start\":13904},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":14088,\"start\":14084},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":14298,\"start\":14294},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":14311,\"start\":14307},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":14380,\"start\":14376},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":14500,\"start\":14496},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":14706,\"start\":14703},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":14915,\"start\":14911},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":15024,\"start\":15020},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":15027,\"start\":15024},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":15033,\"start\":15029},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":15283,\"start\":15279},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":17487,\"start\":17484},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":17490,\"start\":17487},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":18814,\"start\":18810},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":22409,\"start\":22406},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":24514,\"start\":24511},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":30107,\"start\":30104},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":44434,\"start\":44431},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":44611,\"start\":44607},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":44765,\"start\":44761},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":44914,\"start\":44910},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":45104,\"start\":45100},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":45239,\"start\":45236},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":45411,\"start\":45407},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":45589,\"start\":45585},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":45840,\"start\":45836}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":43553,\"start\":42995},{\"attributes\":{\"id\":\"fig_1\"},\"end\":44097,\"start\":43554},{\"attributes\":{\"id\":\"fig_2\"},\"end\":44130,\"start\":44098},{\"attributes\":{\"id\":\"fig_3\"},\"end\":44406,\"start\":44131},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":47374,\"start\":44407},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":47690,\"start\":47375},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":47842,\"start\":47691},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":48166,\"start\":47843},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":48364,\"start\":48167},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":48655,\"start\":48365},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":49171,\"start\":48656},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":49404,\"start\":49172}]", "paragraph": "[{\"end\":3470,\"start\":3035},{\"end\":5716,\"start\":3472},{\"end\":6643,\"start\":5718},{\"end\":8907,\"start\":6645},{\"end\":10025,\"start\":8909},{\"end\":10831,\"start\":10027},{\"end\":12569,\"start\":10890},{\"end\":14820,\"start\":12583},{\"end\":15381,\"start\":14822},{\"end\":16314,\"start\":15392},{\"end\":16785,\"start\":16337},{\"end\":17194,\"start\":16805},{\"end\":17828,\"start\":17407},{\"end\":18229,\"start\":18050},{\"end\":18675,\"start\":18260},{\"end\":19380,\"start\":18677},{\"end\":19801,\"start\":19522},{\"end\":20198,\"start\":19930},{\"end\":20356,\"start\":20225},{\"end\":21522,\"start\":20398},{\"end\":21789,\"start\":21524},{\"end\":22032,\"start\":21828},{\"end\":22190,\"start\":22058},{\"end\":23137,\"start\":22220},{\"end\":23730,\"start\":23139},{\"end\":23809,\"start\":23732},{\"end\":23970,\"start\":23811},{\"end\":24130,\"start\":24010},{\"end\":24351,\"start\":24275},{\"end\":24643,\"start\":24386},{\"end\":24824,\"start\":24679},{\"end\":24929,\"start\":24826},{\"end\":25379,\"start\":24987},{\"end\":25818,\"start\":25452},{\"end\":26169,\"start\":25866},{\"end\":26561,\"start\":26187},{\"end\":27498,\"start\":26617},{\"end\":28034,\"start\":27624},{\"end\":28138,\"start\":28069},{\"end\":28400,\"start\":28154},{\"end\":29076,\"start\":28402},{\"end\":30108,\"start\":29155},{\"end\":31943,\"start\":30134},{\"end\":32436,\"start\":31968},{\"end\":33842,\"start\":32470},{\"end\":35303,\"start\":33900},{\"end\":36210,\"start\":35344},{\"end\":36666,\"start\":36242},{\"end\":37687,\"start\":36668},{\"end\":38019,\"start\":37719},{\"end\":38407,\"start\":38021},{\"end\":38600,\"start\":38409},{\"end\":38815,\"start\":38623},{\"end\":39012,\"start\":38817},{\"end\":39717,\"start\":39014},{\"end\":39913,\"start\":39732},{\"end\":40664,\"start\":39915},{\"end\":41277,\"start\":40666},{\"end\":42070,\"start\":41279},{\"end\":42994,\"start\":42085}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":17406,\"start\":17195},{\"attributes\":{\"id\":\"formula_1\"},\"end\":19471,\"start\":19381},{\"attributes\":{\"id\":\"formula_2\"},\"end\":19521,\"start\":19471},{\"attributes\":{\"id\":\"formula_3\"},\"end\":19872,\"start\":19802},{\"attributes\":{\"id\":\"formula_4\"},\"end\":19929,\"start\":19872},{\"attributes\":{\"id\":\"formula_5\"},\"end\":20224,\"start\":20199},{\"attributes\":{\"id\":\"formula_6\"},\"end\":21827,\"start\":21790},{\"attributes\":{\"id\":\"formula_7\"},\"end\":22057,\"start\":22033},{\"attributes\":{\"id\":\"formula_8\"},\"end\":24009,\"start\":23971},{\"attributes\":{\"id\":\"formula_9\"},\"end\":24219,\"start\":24131},{\"attributes\":{\"id\":\"formula_10\"},\"end\":24274,\"start\":24219},{\"attributes\":{\"id\":\"formula_11\"},\"end\":24385,\"start\":24352},{\"attributes\":{\"id\":\"formula_12\"},\"end\":24678,\"start\":24644},{\"attributes\":{\"id\":\"formula_13\"},\"end\":25451,\"start\":25380},{\"attributes\":{\"id\":\"formula_14\"},\"end\":25865,\"start\":25819},{\"attributes\":{\"id\":\"formula_16\"},\"end\":26616,\"start\":26562},{\"attributes\":{\"id\":\"formula_17\"},\"end\":27556,\"start\":27499},{\"attributes\":{\"id\":\"formula_18\"},\"end\":27589,\"start\":27556},{\"attributes\":{\"id\":\"formula_19\"},\"end\":27623,\"start\":27589},{\"attributes\":{\"id\":\"formula_20\"},\"end\":28068,\"start\":28035}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":30383,\"start\":30376},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":32091,\"start\":32084},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":32802,\"start\":32795},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":33486,\"start\":33479},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":34666,\"start\":34659},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":35854,\"start\":35847},{\"end\":36988,\"start\":36981},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":39368,\"start\":39361}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":3033,\"start\":3021},{\"attributes\":{\"n\":\"2\"},\"end\":10888,\"start\":10834},{\"attributes\":{\"n\":\"2.2\"},\"end\":12581,\"start\":12572},{\"attributes\":{\"n\":\"3\"},\"end\":15390,\"start\":15384},{\"attributes\":{\"n\":\"3.1\"},\"end\":16335,\"start\":16317},{\"attributes\":{\"n\":\"3.2\"},\"end\":16803,\"start\":16788},{\"end\":17873,\"start\":17831},{\"end\":17884,\"start\":17876},{\"end\":17912,\"start\":17887},{\"end\":17924,\"start\":17915},{\"end\":17943,\"start\":17927},{\"end\":17971,\"start\":17946},{\"end\":17983,\"start\":17974},{\"end\":17997,\"start\":17986},{\"end\":18025,\"start\":18000},{\"end\":18037,\"start\":18028},{\"end\":18048,\"start\":18040},{\"attributes\":{\"n\":\"3.3\"},\"end\":18258,\"start\":18232},{\"attributes\":{\"n\":\"3.3.2\"},\"end\":20396,\"start\":20359},{\"attributes\":{\"n\":\"3.4\"},\"end\":22218,\"start\":22193},{\"attributes\":{\"n\":\"3.5\"},\"end\":24985,\"start\":24932},{\"attributes\":{\"n\":\"3.6\"},\"end\":26185,\"start\":26172},{\"attributes\":{\"n\":\"4\"},\"end\":28152,\"start\":28141},{\"attributes\":{\"n\":\"4.1\"},\"end\":29098,\"start\":29079},{\"attributes\":{\"n\":\"4.1.3\"},\"end\":29153,\"start\":29101},{\"attributes\":{\"n\":\"4.2\"},\"end\":30132,\"start\":30111},{\"attributes\":{\"n\":\"4.3\"},\"end\":31966,\"start\":31946},{\"attributes\":{\"n\":\"4.3.2\"},\"end\":32468,\"start\":32439},{\"attributes\":{\"n\":\"4.3.3\"},\"end\":33898,\"start\":33845},{\"attributes\":{\"n\":\"4.3.4\"},\"end\":35342,\"start\":35306},{\"attributes\":{\"n\":\"4.3.5\"},\"end\":36240,\"start\":36213},{\"attributes\":{\"n\":\"4.4\"},\"end\":37717,\"start\":37690},{\"attributes\":{\"n\":\"4.5\"},\"end\":38621,\"start\":38603},{\"attributes\":{\"n\":\"4.6\"},\"end\":39730,\"start\":39720},{\"attributes\":{\"n\":\"5\"},\"end\":42083,\"start\":42073},{\"end\":43561,\"start\":43555},{\"end\":44109,\"start\":44099},{\"end\":44142,\"start\":44132},{\"end\":47385,\"start\":47376},{\"end\":47701,\"start\":47692},{\"end\":47853,\"start\":47844},{\"end\":48177,\"start\":48168},{\"end\":48375,\"start\":48366},{\"end\":49182,\"start\":49173}]", "table": "[{\"end\":47374,\"start\":46009},{\"end\":47690,\"start\":47435},{\"end\":47842,\"start\":47739},{\"end\":48166,\"start\":47869},{\"end\":48364,\"start\":48194},{\"end\":48655,\"start\":48413},{\"end\":49171,\"start\":49063},{\"end\":49404,\"start\":49233}]", "figure_caption": "[{\"end\":43553,\"start\":42997},{\"end\":44097,\"start\":43563},{\"end\":44130,\"start\":44111},{\"end\":44406,\"start\":44144},{\"end\":46009,\"start\":44409},{\"end\":47435,\"start\":47387},{\"end\":47739,\"start\":47703},{\"end\":47869,\"start\":47855},{\"end\":48194,\"start\":48179},{\"end\":48413,\"start\":48377},{\"end\":49063,\"start\":48658},{\"end\":49233,\"start\":49184}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":15469,\"start\":15463},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":15822,\"start\":15816},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":18084,\"start\":18076},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":19028,\"start\":19022},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":21682,\"start\":21676},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":27841,\"start\":27835},{\"end\":37733,\"start\":37725},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":38065,\"start\":38059},{\"end\":38761,\"start\":38753},{\"end\":40095,\"start\":40089},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":40847,\"start\":40841},{\"end\":41437,\"start\":41431}]", "bib_author_first_name": "[{\"end\":49500,\"start\":49495},{\"end\":49516,\"start\":49511},{\"end\":49534,\"start\":49524},{\"end\":50091,\"start\":50085},{\"end\":50101,\"start\":50098},{\"end\":50113,\"start\":50108},{\"end\":50125,\"start\":50120},{\"end\":50139,\"start\":50131},{\"end\":50149,\"start\":50146},{\"end\":50160,\"start\":50156},{\"end\":50566,\"start\":50560},{\"end\":50582,\"start\":50574},{\"end\":50591,\"start\":50588},{\"end\":50607,\"start\":50601},{\"end\":50622,\"start\":50616},{\"end\":50636,\"start\":50632},{\"end\":50650,\"start\":50646},{\"end\":50664,\"start\":50661},{\"end\":50681,\"start\":50674},{\"end\":51208,\"start\":51204},{\"end\":51223,\"start\":51220},{\"end\":51235,\"start\":51231},{\"end\":51616,\"start\":51611},{\"end\":51633,\"start\":51625},{\"end\":51647,\"start\":51641},{\"end\":51661,\"start\":51653},{\"end\":51927,\"start\":51922},{\"end\":51938,\"start\":51934},{\"end\":51950,\"start\":51943},{\"end\":51964,\"start\":51957},{\"end\":51974,\"start\":51971},{\"end\":51982,\"start\":51980},{\"end\":51994,\"start\":51988},{\"end\":52438,\"start\":52432},{\"end\":52454,\"start\":52448},{\"end\":52711,\"start\":52706},{\"end\":52727,\"start\":52722},{\"end\":52738,\"start\":52737},{\"end\":52753,\"start\":52746},{\"end\":52953,\"start\":52949},{\"end\":52966,\"start\":52962},{\"end\":52977,\"start\":52974},{\"end\":53268,\"start\":53262},{\"end\":53279,\"start\":53273},{\"end\":53296,\"start\":53286},{\"end\":53308,\"start\":53303},{\"end\":53320,\"start\":53314},{\"end\":53331,\"start\":53326},{\"end\":53882,\"start\":53875},{\"end\":53895,\"start\":53888},{\"end\":53909,\"start\":53902},{\"end\":53921,\"start\":53914},{\"end\":53934,\"start\":53926},{\"end\":54220,\"start\":54217},{\"end\":54233,\"start\":54229},{\"end\":54237,\"start\":54234},{\"end\":54250,\"start\":54246},{\"end\":54626,\"start\":54620},{\"end\":54645,\"start\":54635},{\"end\":55030,\"start\":55025},{\"end\":55041,\"start\":55035},{\"end\":55054,\"start\":55049},{\"end\":55350,\"start\":55347},{\"end\":55364,\"start\":55358},{\"end\":55377,\"start\":55370},{\"end\":55402,\"start\":55394},{\"end\":55867,\"start\":55866},{\"end\":55879,\"start\":55874},{\"end\":55897,\"start\":55893},{\"end\":56453,\"start\":56447},{\"end\":56465,\"start\":56459},{\"end\":56477,\"start\":56471},{\"end\":56494,\"start\":56484},{\"end\":56505,\"start\":56499},{\"end\":56517,\"start\":56513},{\"end\":56527,\"start\":56522},{\"end\":56544,\"start\":56535},{\"end\":56546,\"start\":56545},{\"end\":57104,\"start\":57094},{\"end\":57117,\"start\":57111},{\"end\":57419,\"start\":57418},{\"end\":57431,\"start\":57428},{\"end\":57711,\"start\":57705},{\"end\":58182,\"start\":58176},{\"end\":58196,\"start\":58190},{\"end\":58208,\"start\":58203},{\"end\":58425,\"start\":58421},{\"end\":58437,\"start\":58430},{\"end\":58449,\"start\":58443},{\"end\":58464,\"start\":58456},{\"end\":58473,\"start\":58470},{\"end\":58483,\"start\":58480},{\"end\":58939,\"start\":58935},{\"end\":58947,\"start\":58944},{\"end\":58959,\"start\":58955},{\"end\":58973,\"start\":58966},{\"end\":58983,\"start\":58980},{\"end\":59478,\"start\":59475},{\"end\":59489,\"start\":59483},{\"end\":59498,\"start\":59496},{\"end\":59510,\"start\":59504},{\"end\":59521,\"start\":59518},{\"end\":59533,\"start\":59527},{\"end\":60111,\"start\":60104},{\"end\":60126,\"start\":60118},{\"end\":60140,\"start\":60133},{\"end\":60156,\"start\":60148},{\"end\":60167,\"start\":60163},{\"end\":60183,\"start\":60173},{\"end\":60735,\"start\":60734},{\"end\":60748,\"start\":60744},{\"end\":60750,\"start\":60749},{\"end\":60759,\"start\":60756},{\"end\":60772,\"start\":60767},{\"end\":61277,\"start\":61273},{\"end\":61288,\"start\":61282},{\"end\":61303,\"start\":61294},{\"end\":61311,\"start\":61308},{\"end\":61321,\"start\":61317},{\"end\":61808,\"start\":61804},{\"end\":61820,\"start\":61813},{\"end\":61832,\"start\":61825},{\"end\":61847,\"start\":61838},{\"end\":61855,\"start\":61852},{\"end\":62285,\"start\":62281},{\"end\":62293,\"start\":62290},{\"end\":62305,\"start\":62298},{\"end\":62316,\"start\":62311},{\"end\":62326,\"start\":62321},{\"end\":62338,\"start\":62331},{\"end\":62348,\"start\":62345},{\"end\":62838,\"start\":62829},{\"end\":62849,\"start\":62843},{\"end\":62859,\"start\":62855},{\"end\":62864,\"start\":62860},{\"end\":62876,\"start\":62870},{\"end\":63208,\"start\":63206},{\"end\":63219,\"start\":63213},{\"end\":63232,\"start\":63226},{\"end\":63248,\"start\":63239},{\"end\":63257,\"start\":63254},{\"end\":63763,\"start\":63761},{\"end\":63776,\"start\":63769},{\"end\":63785,\"start\":63781},{\"end\":64214,\"start\":64209},{\"end\":64222,\"start\":64219},{\"end\":64231,\"start\":64228},{\"end\":64243,\"start\":64237},{\"end\":64255,\"start\":64251},{\"end\":64264,\"start\":64260},{\"end\":64273,\"start\":64270},{\"end\":64635,\"start\":64629},{\"end\":64651,\"start\":64644},{\"end\":64665,\"start\":64661},{\"end\":64679,\"start\":64676},{\"end\":65141,\"start\":65137},{\"end\":65156,\"start\":65151},{\"end\":65172,\"start\":65167},{\"end\":65193,\"start\":65185},{\"end\":65711,\"start\":65706},{\"end\":65723,\"start\":65717},{\"end\":65733,\"start\":65728},{\"end\":65737,\"start\":65734},{\"end\":65748,\"start\":65744},{\"end\":66103,\"start\":66096},{\"end\":66116,\"start\":66110},{\"end\":66129,\"start\":66122},{\"end\":66143,\"start\":66136},{\"end\":66155,\"start\":66150},{\"end\":66164,\"start\":66160},{\"end\":66176,\"start\":66172},{\"end\":66733,\"start\":66728},{\"end\":66742,\"start\":66740},{\"end\":67170,\"start\":67165},{\"end\":67186,\"start\":67180},{\"end\":67201,\"start\":67193},{\"end\":67617,\"start\":67611},{\"end\":67631,\"start\":67627},{\"end\":67645,\"start\":67641},{\"end\":67659,\"start\":67654},{\"end\":67676,\"start\":67671},{\"end\":67689,\"start\":67684},{\"end\":67691,\"start\":67690},{\"end\":67705,\"start\":67699},{\"end\":67719,\"start\":67714},{\"end\":67958,\"start\":67953},{\"end\":67968,\"start\":67965},{\"end\":67977,\"start\":67973},{\"end\":67991,\"start\":67982},{\"end\":68280,\"start\":68277},{\"end\":68290,\"start\":68287},{\"end\":68304,\"start\":68298},{\"end\":68312,\"start\":68310},{\"end\":68320,\"start\":68318},{\"end\":68332,\"start\":68328},{\"end\":68346,\"start\":68338},{\"end\":68787,\"start\":68781},{\"end\":68798,\"start\":68793},{\"end\":68812,\"start\":68805},{\"end\":69192,\"start\":69185},{\"end\":69203,\"start\":69198},{\"end\":69216,\"start\":69210},{\"end\":69226,\"start\":69223},{\"end\":69577,\"start\":69573},{\"end\":69587,\"start\":69582},{\"end\":69599,\"start\":69593},{\"end\":69613,\"start\":69605},{\"end\":69625,\"start\":69618},{\"end\":69640,\"start\":69633},{\"end\":69660,\"start\":69653},{\"end\":69675,\"start\":69669},{\"end\":70249,\"start\":70242},{\"end\":70265,\"start\":70257},{\"end\":70281,\"start\":70271},{\"end\":70295,\"start\":70287},{\"end\":70308,\"start\":70300},{\"end\":70732,\"start\":70725},{\"end\":70744,\"start\":70739},{\"end\":70758,\"start\":70752},{\"end\":70769,\"start\":70765},{\"end\":70782,\"start\":70775},{\"end\":70794,\"start\":70789},{\"end\":71343,\"start\":71338},{\"end\":71355,\"start\":71350},{\"end\":71369,\"start\":71361},{\"end\":71383,\"start\":71376},{\"end\":71398,\"start\":71389},{\"end\":71410,\"start\":71405},{\"end\":71420,\"start\":71417},{\"end\":71866,\"start\":71860},{\"end\":71875,\"start\":71873},{\"end\":71885,\"start\":71881},{\"end\":71893,\"start\":71891},{\"end\":71904,\"start\":71898},{\"end\":71916,\"start\":71911},{\"end\":71932,\"start\":71923},{\"end\":71941,\"start\":71938},{\"end\":72372,\"start\":72366},{\"end\":72388,\"start\":72379},{\"end\":72400,\"start\":72394},{\"end\":72411,\"start\":72407},{\"end\":72420,\"start\":72417},{\"end\":72430,\"start\":72426},{\"end\":72442,\"start\":72435},{\"end\":72453,\"start\":72448},{\"end\":72462,\"start\":72459},{\"end\":72470,\"start\":72467}]", "bib_author_last_name": "[{\"end\":49509,\"start\":49501},{\"end\":49522,\"start\":49517},{\"end\":49545,\"start\":49535},{\"end\":50096,\"start\":50092},{\"end\":50106,\"start\":50102},{\"end\":50118,\"start\":50114},{\"end\":50129,\"start\":50126},{\"end\":50144,\"start\":50140},{\"end\":50154,\"start\":50150},{\"end\":50165,\"start\":50161},{\"end\":50558,\"start\":50550},{\"end\":50572,\"start\":50567},{\"end\":50586,\"start\":50583},{\"end\":50599,\"start\":50592},{\"end\":50614,\"start\":50608},{\"end\":50630,\"start\":50623},{\"end\":50644,\"start\":50637},{\"end\":50659,\"start\":50651},{\"end\":50672,\"start\":50665},{\"end\":50686,\"start\":50682},{\"end\":50693,\"start\":50688},{\"end\":51218,\"start\":51209},{\"end\":51229,\"start\":51224},{\"end\":51242,\"start\":51236},{\"end\":51623,\"start\":51617},{\"end\":51639,\"start\":51634},{\"end\":51651,\"start\":51648},{\"end\":51671,\"start\":51662},{\"end\":51932,\"start\":51928},{\"end\":51941,\"start\":51939},{\"end\":51955,\"start\":51951},{\"end\":51969,\"start\":51965},{\"end\":51978,\"start\":51975},{\"end\":51986,\"start\":51983},{\"end\":51999,\"start\":51995},{\"end\":52446,\"start\":52439},{\"end\":52460,\"start\":52455},{\"end\":52720,\"start\":52712},{\"end\":52735,\"start\":52728},{\"end\":52744,\"start\":52739},{\"end\":52757,\"start\":52754},{\"end\":52764,\"start\":52759},{\"end\":52960,\"start\":52954},{\"end\":52972,\"start\":52967},{\"end\":52987,\"start\":52978},{\"end\":53271,\"start\":53269},{\"end\":53284,\"start\":53280},{\"end\":53301,\"start\":53297},{\"end\":53312,\"start\":53309},{\"end\":53324,\"start\":53321},{\"end\":53335,\"start\":53332},{\"end\":53886,\"start\":53883},{\"end\":53900,\"start\":53896},{\"end\":53912,\"start\":53910},{\"end\":53924,\"start\":53922},{\"end\":53937,\"start\":53935},{\"end\":54227,\"start\":54221},{\"end\":54244,\"start\":54238},{\"end\":54258,\"start\":54251},{\"end\":54633,\"start\":54627},{\"end\":54657,\"start\":54646},{\"end\":55033,\"start\":55031},{\"end\":55047,\"start\":55042},{\"end\":55063,\"start\":55055},{\"end\":55356,\"start\":55351},{\"end\":55368,\"start\":55365},{\"end\":55392,\"start\":55378},{\"end\":55413,\"start\":55403},{\"end\":55872,\"start\":55868},{\"end\":55891,\"start\":55880},{\"end\":55907,\"start\":55898},{\"end\":55914,\"start\":55909},{\"end\":56457,\"start\":56454},{\"end\":56469,\"start\":56466},{\"end\":56482,\"start\":56478},{\"end\":56497,\"start\":56495},{\"end\":56511,\"start\":56506},{\"end\":56520,\"start\":56518},{\"end\":56533,\"start\":56528},{\"end\":56552,\"start\":56547},{\"end\":57109,\"start\":57105},{\"end\":57125,\"start\":57118},{\"end\":57426,\"start\":57420},{\"end\":57436,\"start\":57432},{\"end\":57445,\"start\":57438},{\"end\":57717,\"start\":57712},{\"end\":58188,\"start\":58183},{\"end\":58201,\"start\":58197},{\"end\":58217,\"start\":58209},{\"end\":58428,\"start\":58426},{\"end\":58441,\"start\":58438},{\"end\":58454,\"start\":58450},{\"end\":58468,\"start\":58465},{\"end\":58478,\"start\":58474},{\"end\":58486,\"start\":58484},{\"end\":58942,\"start\":58940},{\"end\":58953,\"start\":58948},{\"end\":58964,\"start\":58960},{\"end\":58978,\"start\":58974},{\"end\":58988,\"start\":58984},{\"end\":59481,\"start\":59479},{\"end\":59494,\"start\":59490},{\"end\":59502,\"start\":59499},{\"end\":59516,\"start\":59511},{\"end\":59525,\"start\":59522},{\"end\":59538,\"start\":59534},{\"end\":60116,\"start\":60112},{\"end\":60131,\"start\":60127},{\"end\":60146,\"start\":60141},{\"end\":60161,\"start\":60157},{\"end\":60171,\"start\":60168},{\"end\":60187,\"start\":60184},{\"end\":60742,\"start\":60736},{\"end\":60754,\"start\":60751},{\"end\":60765,\"start\":60760},{\"end\":60777,\"start\":60773},{\"end\":60783,\"start\":60779},{\"end\":61280,\"start\":61278},{\"end\":61292,\"start\":61289},{\"end\":61306,\"start\":61304},{\"end\":61315,\"start\":61312},{\"end\":61325,\"start\":61322},{\"end\":61811,\"start\":61809},{\"end\":61823,\"start\":61821},{\"end\":61836,\"start\":61833},{\"end\":61850,\"start\":61848},{\"end\":61859,\"start\":61856},{\"end\":62288,\"start\":62286},{\"end\":62296,\"start\":62294},{\"end\":62309,\"start\":62306},{\"end\":62319,\"start\":62317},{\"end\":62329,\"start\":62327},{\"end\":62343,\"start\":62339},{\"end\":62351,\"start\":62349},{\"end\":62841,\"start\":62839},{\"end\":62853,\"start\":62850},{\"end\":62868,\"start\":62865},{\"end\":62881,\"start\":62877},{\"end\":63211,\"start\":63209},{\"end\":63224,\"start\":63220},{\"end\":63237,\"start\":63233},{\"end\":63252,\"start\":63249},{\"end\":63261,\"start\":63258},{\"end\":63767,\"start\":63764},{\"end\":63779,\"start\":63777},{\"end\":63789,\"start\":63786},{\"end\":64217,\"start\":64215},{\"end\":64226,\"start\":64223},{\"end\":64235,\"start\":64232},{\"end\":64249,\"start\":64244},{\"end\":64258,\"start\":64256},{\"end\":64268,\"start\":64265},{\"end\":64278,\"start\":64274},{\"end\":64642,\"start\":64636},{\"end\":64659,\"start\":64652},{\"end\":64674,\"start\":64666},{\"end\":64687,\"start\":64680},{\"end\":65149,\"start\":65142},{\"end\":65165,\"start\":65157},{\"end\":65183,\"start\":65173},{\"end\":65200,\"start\":65194},{\"end\":65208,\"start\":65202},{\"end\":65219,\"start\":65210},{\"end\":65715,\"start\":65712},{\"end\":65726,\"start\":65724},{\"end\":65742,\"start\":65738},{\"end\":65755,\"start\":65749},{\"end\":66108,\"start\":66104},{\"end\":66120,\"start\":66117},{\"end\":66134,\"start\":66130},{\"end\":66148,\"start\":66144},{\"end\":66158,\"start\":66156},{\"end\":66170,\"start\":66165},{\"end\":66181,\"start\":66177},{\"end\":66738,\"start\":66734},{\"end\":66747,\"start\":66743},{\"end\":67178,\"start\":67171},{\"end\":67191,\"start\":67187},{\"end\":67210,\"start\":67202},{\"end\":67221,\"start\":67212},{\"end\":67625,\"start\":67618},{\"end\":67639,\"start\":67632},{\"end\":67652,\"start\":67646},{\"end\":67669,\"start\":67660},{\"end\":67682,\"start\":67677},{\"end\":67697,\"start\":67692},{\"end\":67712,\"start\":67706},{\"end\":67730,\"start\":67720},{\"end\":67963,\"start\":67959},{\"end\":67971,\"start\":67969},{\"end\":67980,\"start\":67978},{\"end\":67996,\"start\":67992},{\"end\":68285,\"start\":68281},{\"end\":68296,\"start\":68291},{\"end\":68308,\"start\":68305},{\"end\":68316,\"start\":68313},{\"end\":68326,\"start\":68321},{\"end\":68336,\"start\":68333},{\"end\":68350,\"start\":68347},{\"end\":68791,\"start\":68788},{\"end\":68803,\"start\":68799},{\"end\":68816,\"start\":68813},{\"end\":69196,\"start\":69193},{\"end\":69208,\"start\":69204},{\"end\":69221,\"start\":69217},{\"end\":69231,\"start\":69227},{\"end\":69580,\"start\":69578},{\"end\":69591,\"start\":69588},{\"end\":69603,\"start\":69600},{\"end\":69616,\"start\":69614},{\"end\":69631,\"start\":69626},{\"end\":69651,\"start\":69641},{\"end\":69667,\"start\":69661},{\"end\":69679,\"start\":69676},{\"end\":70255,\"start\":70250},{\"end\":70269,\"start\":70266},{\"end\":70285,\"start\":70282},{\"end\":70298,\"start\":70296},{\"end\":70312,\"start\":70309},{\"end\":70737,\"start\":70733},{\"end\":70750,\"start\":70745},{\"end\":70763,\"start\":70759},{\"end\":70773,\"start\":70770},{\"end\":70787,\"start\":70783},{\"end\":70798,\"start\":70795},{\"end\":71348,\"start\":71344},{\"end\":71359,\"start\":71356},{\"end\":71374,\"start\":71370},{\"end\":71387,\"start\":71384},{\"end\":71403,\"start\":71399},{\"end\":71415,\"start\":71411},{\"end\":71424,\"start\":71421},{\"end\":71871,\"start\":71867},{\"end\":71879,\"start\":71876},{\"end\":71889,\"start\":71886},{\"end\":71896,\"start\":71894},{\"end\":71909,\"start\":71905},{\"end\":71921,\"start\":71917},{\"end\":71936,\"start\":71933},{\"end\":71945,\"start\":71942},{\"end\":72377,\"start\":72373},{\"end\":72392,\"start\":72389},{\"end\":72405,\"start\":72401},{\"end\":72415,\"start\":72412},{\"end\":72424,\"start\":72421},{\"end\":72433,\"start\":72431},{\"end\":72446,\"start\":72443},{\"end\":72457,\"start\":72454},{\"end\":72465,\"start\":72463},{\"end\":72474,\"start\":72471}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":41274193},\"end\":49994,\"start\":49406},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":211990496},\"end\":50546,\"start\":49996},{\"attributes\":{\"id\":\"b2\"},\"end\":50845,\"start\":50548},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":3352400},\"end\":51152,\"start\":50847},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":207240067},\"end\":51527,\"start\":51154},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":52967399},\"end\":51855,\"start\":51529},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":155099980},\"end\":52358,\"start\":51857},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":13244884},\"end\":52640,\"start\":52360},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":1591394},\"end\":52947,\"start\":52642},{\"attributes\":{\"doi\":\"arXiv:1410.5401\",\"id\":\"b9\"},\"end\":53154,\"start\":52949},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":224282883},\"end\":53800,\"start\":53156},{\"attributes\":{\"doi\":\"arXiv:1703.04247\",\"id\":\"b11\"},\"end\":54155,\"start\":53802},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":51888887},\"end\":54556,\"start\":54157},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":11810482},\"end\":54967,\"start\":54558},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":10537313},\"end\":55303,\"start\":54969},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":9433631},\"end\":55768,\"start\":55305},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":202787725},\"end\":56352,\"start\":55770},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":220280209},\"end\":57050,\"start\":56354},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":52127932},\"end\":57350,\"start\":57052},{\"attributes\":{\"doi\":\"arXiv:1609.02907\",\"id\":\"b19\"},\"end\":57619,\"start\":57352},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":207168823},\"end\":58117,\"start\":57621},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":58370896},\"end\":58372,\"start\":58119},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":21066930},\"end\":58857,\"start\":58374},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":210882156},\"end\":59365,\"start\":58859},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":50768534},\"end\":60015,\"start\":59367},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":3930042},\"end\":60663,\"start\":60017},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":14886100},\"end\":61192,\"start\":60665},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":202537994},\"end\":61802,\"start\":61194},{\"attributes\":{\"doi\":\"arXiv:2010.12837\",\"id\":\"b28\"},\"end\":62177,\"start\":61804},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":44145233},\"end\":62825,\"start\":62179},{\"attributes\":{\"id\":\"b30\"},\"end\":63118,\"start\":62827},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":162168680},\"end\":63706,\"start\":63120},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":220045833},\"end\":64147,\"start\":63708},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":3424778},\"end\":64570,\"start\":64149},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":206594738},\"end\":65047,\"start\":64572},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":209460796},\"end\":65640,\"start\":65049},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":2409634},\"end\":66011,\"start\":65642},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":53100214},\"end\":66643,\"start\":66013},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":39847715},\"end\":67122,\"start\":66645},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":7118498},\"end\":67582,\"start\":67124},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":13756489},\"end\":67904,\"start\":67584},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":6011288},\"end\":68177,\"start\":67906},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":211171550},\"end\":68651,\"start\":68179},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":222278410},\"end\":69183,\"start\":68653},{\"attributes\":{\"id\":\"b44\"},\"end\":69489,\"start\":69185},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":207209998},\"end\":70126,\"start\":69491},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":51604574},\"end\":70642,\"start\":70128},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":3350305},\"end\":71256,\"start\":70644},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":19112718},\"end\":71791,\"start\":71258},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":52188056},\"end\":72307,\"start\":71793},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":1637394},\"end\":72943,\"start\":72309}]", "bib_title": "[{\"end\":49493,\"start\":49406},{\"end\":50083,\"start\":49996},{\"end\":50891,\"start\":50847},{\"end\":51202,\"start\":51154},{\"end\":51609,\"start\":51529},{\"end\":51920,\"start\":51857},{\"end\":52430,\"start\":52360},{\"end\":52704,\"start\":52642},{\"end\":53260,\"start\":53156},{\"end\":54215,\"start\":54157},{\"end\":54618,\"start\":54558},{\"end\":55023,\"start\":54969},{\"end\":55345,\"start\":55305},{\"end\":55864,\"start\":55770},{\"end\":56445,\"start\":56354},{\"end\":57092,\"start\":57052},{\"end\":57703,\"start\":57621},{\"end\":58174,\"start\":58119},{\"end\":58419,\"start\":58374},{\"end\":58933,\"start\":58859},{\"end\":59473,\"start\":59367},{\"end\":60102,\"start\":60017},{\"end\":60732,\"start\":60665},{\"end\":61271,\"start\":61194},{\"end\":62279,\"start\":62179},{\"end\":63204,\"start\":63120},{\"end\":63759,\"start\":63708},{\"end\":64207,\"start\":64149},{\"end\":64627,\"start\":64572},{\"end\":65135,\"start\":65049},{\"end\":65704,\"start\":65642},{\"end\":66094,\"start\":66013},{\"end\":66726,\"start\":66645},{\"end\":67163,\"start\":67124},{\"end\":67609,\"start\":67584},{\"end\":67951,\"start\":67906},{\"end\":68275,\"start\":68179},{\"end\":68779,\"start\":68653},{\"end\":69571,\"start\":69491},{\"end\":70240,\"start\":70128},{\"end\":70723,\"start\":70644},{\"end\":71336,\"start\":71258},{\"end\":71858,\"start\":71793},{\"end\":72364,\"start\":72309}]", "bib_author": "[{\"end\":49511,\"start\":49495},{\"end\":49524,\"start\":49511},{\"end\":49547,\"start\":49524},{\"end\":50098,\"start\":50085},{\"end\":50108,\"start\":50098},{\"end\":50120,\"start\":50108},{\"end\":50131,\"start\":50120},{\"end\":50146,\"start\":50131},{\"end\":50156,\"start\":50146},{\"end\":50167,\"start\":50156},{\"end\":50560,\"start\":50550},{\"end\":50574,\"start\":50560},{\"end\":50588,\"start\":50574},{\"end\":50601,\"start\":50588},{\"end\":50616,\"start\":50601},{\"end\":50632,\"start\":50616},{\"end\":50646,\"start\":50632},{\"end\":50661,\"start\":50646},{\"end\":50674,\"start\":50661},{\"end\":50688,\"start\":50674},{\"end\":50695,\"start\":50688},{\"end\":51220,\"start\":51204},{\"end\":51231,\"start\":51220},{\"end\":51244,\"start\":51231},{\"end\":51625,\"start\":51611},{\"end\":51641,\"start\":51625},{\"end\":51653,\"start\":51641},{\"end\":51673,\"start\":51653},{\"end\":51934,\"start\":51922},{\"end\":51943,\"start\":51934},{\"end\":51957,\"start\":51943},{\"end\":51971,\"start\":51957},{\"end\":51980,\"start\":51971},{\"end\":51988,\"start\":51980},{\"end\":52001,\"start\":51988},{\"end\":52448,\"start\":52432},{\"end\":52462,\"start\":52448},{\"end\":52722,\"start\":52706},{\"end\":52737,\"start\":52722},{\"end\":52746,\"start\":52737},{\"end\":52759,\"start\":52746},{\"end\":52766,\"start\":52759},{\"end\":52962,\"start\":52949},{\"end\":52974,\"start\":52962},{\"end\":52989,\"start\":52974},{\"end\":53273,\"start\":53262},{\"end\":53286,\"start\":53273},{\"end\":53303,\"start\":53286},{\"end\":53314,\"start\":53303},{\"end\":53326,\"start\":53314},{\"end\":53337,\"start\":53326},{\"end\":53888,\"start\":53875},{\"end\":53902,\"start\":53888},{\"end\":53914,\"start\":53902},{\"end\":53926,\"start\":53914},{\"end\":53939,\"start\":53926},{\"end\":54229,\"start\":54217},{\"end\":54246,\"start\":54229},{\"end\":54260,\"start\":54246},{\"end\":54635,\"start\":54620},{\"end\":54659,\"start\":54635},{\"end\":55035,\"start\":55025},{\"end\":55049,\"start\":55035},{\"end\":55065,\"start\":55049},{\"end\":55358,\"start\":55347},{\"end\":55370,\"start\":55358},{\"end\":55394,\"start\":55370},{\"end\":55415,\"start\":55394},{\"end\":55874,\"start\":55866},{\"end\":55893,\"start\":55874},{\"end\":55909,\"start\":55893},{\"end\":55916,\"start\":55909},{\"end\":56459,\"start\":56447},{\"end\":56471,\"start\":56459},{\"end\":56484,\"start\":56471},{\"end\":56499,\"start\":56484},{\"end\":56513,\"start\":56499},{\"end\":56522,\"start\":56513},{\"end\":56535,\"start\":56522},{\"end\":56554,\"start\":56535},{\"end\":57111,\"start\":57094},{\"end\":57127,\"start\":57111},{\"end\":57428,\"start\":57418},{\"end\":57438,\"start\":57428},{\"end\":57447,\"start\":57438},{\"end\":57719,\"start\":57705},{\"end\":58190,\"start\":58176},{\"end\":58203,\"start\":58190},{\"end\":58219,\"start\":58203},{\"end\":58430,\"start\":58421},{\"end\":58443,\"start\":58430},{\"end\":58456,\"start\":58443},{\"end\":58470,\"start\":58456},{\"end\":58480,\"start\":58470},{\"end\":58488,\"start\":58480},{\"end\":58944,\"start\":58935},{\"end\":58955,\"start\":58944},{\"end\":58966,\"start\":58955},{\"end\":58980,\"start\":58966},{\"end\":58990,\"start\":58980},{\"end\":59483,\"start\":59475},{\"end\":59496,\"start\":59483},{\"end\":59504,\"start\":59496},{\"end\":59518,\"start\":59504},{\"end\":59527,\"start\":59518},{\"end\":59540,\"start\":59527},{\"end\":60118,\"start\":60104},{\"end\":60133,\"start\":60118},{\"end\":60148,\"start\":60133},{\"end\":60163,\"start\":60148},{\"end\":60173,\"start\":60163},{\"end\":60189,\"start\":60173},{\"end\":60744,\"start\":60734},{\"end\":60756,\"start\":60744},{\"end\":60767,\"start\":60756},{\"end\":60779,\"start\":60767},{\"end\":60785,\"start\":60779},{\"end\":61282,\"start\":61273},{\"end\":61294,\"start\":61282},{\"end\":61308,\"start\":61294},{\"end\":61317,\"start\":61308},{\"end\":61327,\"start\":61317},{\"end\":61813,\"start\":61804},{\"end\":61825,\"start\":61813},{\"end\":61838,\"start\":61825},{\"end\":61852,\"start\":61838},{\"end\":61861,\"start\":61852},{\"end\":62290,\"start\":62281},{\"end\":62298,\"start\":62290},{\"end\":62311,\"start\":62298},{\"end\":62321,\"start\":62311},{\"end\":62331,\"start\":62321},{\"end\":62345,\"start\":62331},{\"end\":62353,\"start\":62345},{\"end\":62843,\"start\":62829},{\"end\":62855,\"start\":62843},{\"end\":62870,\"start\":62855},{\"end\":62883,\"start\":62870},{\"end\":63213,\"start\":63206},{\"end\":63226,\"start\":63213},{\"end\":63239,\"start\":63226},{\"end\":63254,\"start\":63239},{\"end\":63263,\"start\":63254},{\"end\":63769,\"start\":63761},{\"end\":63781,\"start\":63769},{\"end\":63791,\"start\":63781},{\"end\":64219,\"start\":64209},{\"end\":64228,\"start\":64219},{\"end\":64237,\"start\":64228},{\"end\":64251,\"start\":64237},{\"end\":64260,\"start\":64251},{\"end\":64270,\"start\":64260},{\"end\":64280,\"start\":64270},{\"end\":64644,\"start\":64629},{\"end\":64661,\"start\":64644},{\"end\":64676,\"start\":64661},{\"end\":64689,\"start\":64676},{\"end\":65151,\"start\":65137},{\"end\":65167,\"start\":65151},{\"end\":65185,\"start\":65167},{\"end\":65202,\"start\":65185},{\"end\":65210,\"start\":65202},{\"end\":65221,\"start\":65210},{\"end\":65717,\"start\":65706},{\"end\":65728,\"start\":65717},{\"end\":65744,\"start\":65728},{\"end\":65757,\"start\":65744},{\"end\":66110,\"start\":66096},{\"end\":66122,\"start\":66110},{\"end\":66136,\"start\":66122},{\"end\":66150,\"start\":66136},{\"end\":66160,\"start\":66150},{\"end\":66172,\"start\":66160},{\"end\":66183,\"start\":66172},{\"end\":66740,\"start\":66728},{\"end\":66749,\"start\":66740},{\"end\":67180,\"start\":67165},{\"end\":67193,\"start\":67180},{\"end\":67212,\"start\":67193},{\"end\":67223,\"start\":67212},{\"end\":67627,\"start\":67611},{\"end\":67641,\"start\":67627},{\"end\":67654,\"start\":67641},{\"end\":67671,\"start\":67654},{\"end\":67684,\"start\":67671},{\"end\":67699,\"start\":67684},{\"end\":67714,\"start\":67699},{\"end\":67732,\"start\":67714},{\"end\":67965,\"start\":67953},{\"end\":67973,\"start\":67965},{\"end\":67982,\"start\":67973},{\"end\":67998,\"start\":67982},{\"end\":68287,\"start\":68277},{\"end\":68298,\"start\":68287},{\"end\":68310,\"start\":68298},{\"end\":68318,\"start\":68310},{\"end\":68328,\"start\":68318},{\"end\":68338,\"start\":68328},{\"end\":68352,\"start\":68338},{\"end\":68793,\"start\":68781},{\"end\":68805,\"start\":68793},{\"end\":68818,\"start\":68805},{\"end\":69198,\"start\":69185},{\"end\":69210,\"start\":69198},{\"end\":69223,\"start\":69210},{\"end\":69233,\"start\":69223},{\"end\":69582,\"start\":69573},{\"end\":69593,\"start\":69582},{\"end\":69605,\"start\":69593},{\"end\":69618,\"start\":69605},{\"end\":69633,\"start\":69618},{\"end\":69653,\"start\":69633},{\"end\":69669,\"start\":69653},{\"end\":69681,\"start\":69669},{\"end\":70257,\"start\":70242},{\"end\":70271,\"start\":70257},{\"end\":70287,\"start\":70271},{\"end\":70300,\"start\":70287},{\"end\":70314,\"start\":70300},{\"end\":70739,\"start\":70725},{\"end\":70752,\"start\":70739},{\"end\":70765,\"start\":70752},{\"end\":70775,\"start\":70765},{\"end\":70789,\"start\":70775},{\"end\":70800,\"start\":70789},{\"end\":71350,\"start\":71338},{\"end\":71361,\"start\":71350},{\"end\":71376,\"start\":71361},{\"end\":71389,\"start\":71376},{\"end\":71405,\"start\":71389},{\"end\":71417,\"start\":71405},{\"end\":71426,\"start\":71417},{\"end\":71873,\"start\":71860},{\"end\":71881,\"start\":71873},{\"end\":71891,\"start\":71881},{\"end\":71898,\"start\":71891},{\"end\":71911,\"start\":71898},{\"end\":71923,\"start\":71911},{\"end\":71938,\"start\":71923},{\"end\":71947,\"start\":71938},{\"end\":72379,\"start\":72366},{\"end\":72394,\"start\":72379},{\"end\":72407,\"start\":72394},{\"end\":72417,\"start\":72407},{\"end\":72426,\"start\":72417},{\"end\":72435,\"start\":72426},{\"end\":72448,\"start\":72435},{\"end\":72459,\"start\":72448},{\"end\":72467,\"start\":72459},{\"end\":72476,\"start\":72467}]", "bib_venue": "[{\"end\":49730,\"start\":49647},{\"end\":50276,\"start\":50230},{\"end\":51024,\"start\":50967},{\"end\":51353,\"start\":51307},{\"end\":53504,\"start\":53429},{\"end\":54369,\"start\":54323},{\"end\":55556,\"start\":55494},{\"end\":56089,\"start\":56011},{\"end\":56733,\"start\":56652},{\"end\":57902,\"start\":57819},{\"end\":58637,\"start\":58571},{\"end\":59133,\"start\":59070},{\"end\":59719,\"start\":59638},{\"end\":60368,\"start\":60287},{\"end\":60956,\"start\":60879},{\"end\":61498,\"start\":61421},{\"end\":62532,\"start\":62451},{\"end\":63442,\"start\":63361},{\"end\":63952,\"start\":63880},{\"end\":64830,\"start\":64768},{\"end\":65364,\"start\":65301},{\"end\":66354,\"start\":66277},{\"end\":66908,\"start\":66837},{\"end\":68039,\"start\":68027},{\"end\":68415,\"start\":68392},{\"end\":68937,\"start\":68886},{\"end\":69830,\"start\":69764},{\"end\":70979,\"start\":70898},{\"end\":71535,\"start\":71489},{\"end\":72056,\"start\":72010},{\"end\":72655,\"start\":72574},{\"end\":49645,\"start\":49547},{\"end\":50228,\"start\":50167},{\"end\":50965,\"start\":50893},{\"end\":51305,\"start\":51244},{\"end\":51682,\"start\":51673},{\"end\":52094,\"start\":52001},{\"end\":52480,\"start\":52462},{\"end\":52777,\"start\":52766},{\"end\":53026,\"start\":53004},{\"end\":53427,\"start\":53337},{\"end\":53873,\"start\":53802},{\"end\":54321,\"start\":54260},{\"end\":54715,\"start\":54659},{\"end\":55116,\"start\":55065},{\"end\":55492,\"start\":55415},{\"end\":56009,\"start\":55916},{\"end\":56650,\"start\":56554},{\"end\":57183,\"start\":57127},{\"end\":57416,\"start\":57352},{\"end\":57817,\"start\":57719},{\"end\":58227,\"start\":58219},{\"end\":58569,\"start\":58488},{\"end\":59068,\"start\":58990},{\"end\":59636,\"start\":59540},{\"end\":60285,\"start\":60189},{\"end\":60877,\"start\":60785},{\"end\":61419,\"start\":61327},{\"end\":61970,\"start\":61877},{\"end\":62449,\"start\":62353},{\"end\":63359,\"start\":63263},{\"end\":63878,\"start\":63791},{\"end\":64341,\"start\":64280},{\"end\":64766,\"start\":64689},{\"end\":65299,\"start\":65221},{\"end\":65808,\"start\":65757},{\"end\":66275,\"start\":66183},{\"end\":66835,\"start\":66749},{\"end\":67283,\"start\":67223},{\"end\":67736,\"start\":67732},{\"end\":68025,\"start\":67998},{\"end\":68390,\"start\":68352},{\"end\":68884,\"start\":68818},{\"end\":69332,\"start\":69233},{\"end\":69762,\"start\":69681},{\"end\":70377,\"start\":70314},{\"end\":70896,\"start\":70800},{\"end\":71487,\"start\":71426},{\"end\":72008,\"start\":71947},{\"end\":72572,\"start\":72476}]"}}}, "year": 2023, "month": 12, "day": 17}