{"id": 249926985, "updated": "2023-10-09 19:59:37.878", "metadata": {"title": "Questions Are All You Need to Train a Dense Passage Retriever", "authors": "[{\"first\":\"Devendra Singh\",\"last\":\"Sachan\",\"middle\":[]},{\"first\":\"Mike\",\"last\":\"Lewis\",\"middle\":[]},{\"first\":\"Dani\",\"last\":\"Yogatama\",\"middle\":[]},{\"first\":\"Luke\",\"last\":\"Zettlemoyer\",\"middle\":[]},{\"first\":\"Joelle\",\"last\":\"Pineau\",\"middle\":[]},{\"first\":\"Manzil\",\"last\":\"Zaheer\",\"middle\":[]}]", "venue": "TACL", "journal": "Transactions of the Association for Computational Linguistics, Volume 11", "publication_date": {"year": 2023, "month": null, "day": null}, "abstract": "We introduce ART, a new corpus-level autoencoding approach for training dense retrieval models that does not require any labeled training data. Dense retrieval is a central challenge for open-domain tasks, such as Open QA, where state-of-the-art methods typically require large supervised datasets with custom hard-negative mining and denoising of positive examples. ART, in contrast, only requires access to unpaired inputs and outputs (e.g., questions and potential answer passages). It uses a new passage-retrieval autoencoding scheme, where (1) an input question is used to retrieve a set of evidence passages, and (2) the passages are then used to compute the probability of reconstructing the original question. Training for retrieval based on question reconstruction enables effective unsupervised learning of both passage and question encoders, which can be later incorporated into complete Open QA systems without any further finetuning. Extensive experiments demonstrate that ART obtains state-of-the-art results on multiple QA retrieval benchmarks with only generic initialization from a pre-trained language model, removing the need for labeled data and task-specific losses.1 Our code and model checkpoints are available at: https://github.com/DevSinghSachan/art.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2206.10658", "mag": null, "acl": "2023.tacl-1.35", "pubmed": null, "pubmedcentral": null, "dblp": "journals/corr/abs-2206-10658", "doi": "10.1162/tacl_a_00564"}}, "content": {"source": {"pdf_hash": "46e35267a1a0331c26508d1d2e38bbff75403dbc", "pdf_src": "ACL", "pdf_uri": "[\"https://www.aclanthology.org/2023.tacl-1.35.pdf\"]", "oa_url_match": false, "oa_info": {"license": "CCBY", "open_access_url": "https://direct.mit.edu/tacl/article-pdf/doi/10.1162/tacl_a_00564/2134472/tacl_a_00564.pdf", "status": "GOLD"}}, "grobid": {"id": "df872a03e0313512cbbcf52c82f62aa0b55036a3", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/46e35267a1a0331c26508d1d2e38bbff75403dbc.txt", "contents": "\nQuestions Are All You Need to Train a Dense Passage Retriever\n\n\nDevendra Singh \nMcGill University\nCanada\n\nMila -Quebec AI Institute\nCanada\n\nSachan sachande@mila.quebec \nMike Lewis mikelewis@meta.com \nMeta AI\nUSA\n\nDani Yogatama \nGoogle DeepMind\nUSA\n\nLuke Zettlemoyer \nMeta AI\nUSA\n\nUniversity of Washington\nUSA\n\nJoelle Pineau jpineau@meta.com \nMcGill University\nCanada\n\nMila -Quebec AI Institute\nCanada\n\nMeta AI\nUSA\n\nManzil Zaheer manzilzaheer@google.com \nGoogle DeepMind\nUSA\n\nQuestions Are All You Need to Train a Dense Passage Retriever\n10.1162/tacl\nWe introduce ART, a new corpus-level autoencoding approach for training dense retrieval models that does not require any labeled training data. Dense retrieval is a central challenge for open-domain tasks, such as Open QA, where state-of-the-art methods typically require large supervised datasets with custom hard-negative mining and denoising of positive examples. ART, in contrast, only requires access to unpaired inputs and outputs (e.g., questions and potential answer passages). It uses a new passage-retrieval autoencoding scheme, where (1) an input question is used to retrieve a set of evidence passages, and (2) the passages are then used to compute the probability of reconstructing the original question. Training for retrieval based on question reconstruction enables effective unsupervised learning of both passage and question encoders, which can be later incorporated into complete Open QA systems without any further finetuning. Extensive experiments demonstrate that ART obtains state-of-the-art results on multiple QA retrieval benchmarks with only generic initialization from a pre-trained language model, removing the need for labeled data and taskspecific losses. 1\n\nIntroduction\n\nDense passage retrieval methods (Karpukhin et al., 2020;Xiong et al., 2021), initialized with encoders such as BERT  and trained using supervised contrastive losses (Oord et al., 2018), have surpassed the performance achieved by previously popular keyword-based approaches like BM25 (Robertson and Zaragoza, 2009). Such retrievers are core components in models for open-domain tasks, such as Open QA, where state-of-the-art methods typically require large supervised datasets with custom hardnegative mining and denoising of positive examples. In this paper, we introduce the first unsupervised method, based on a new corpus-level autoencoding approach, that can match or surpass strong supervised performance levels with no labeled training data or task-specific losses.\n\nWe propose ART, Autoencoding-based Retriever Training, which only assumes access to sets of unpaired questions and passages. Given an input question, ART first retrieves a small set of possible evidence passages. It then reconstructs the original question by attending to these passages (see Figure 1 for an overview). The key idea in ART is to consider the retrieved passages as a noisy representation of the original question and question reconstruction probability as a way of denoising that provides soft-labels for how likely each passage is to have been the correct result.\n\nTo bootstrap the training of a strong model, it is important to both have a strong initial retrieval model and to be able to compute reliable initial estimates of question reconstruction probability when conditioned on a (retrieved) passage. Although passage representations from BERTstyle models are known to be reasonable retrieval baselines, it is less clear how to do zero-shot question generation. We use a generative pre-trained language model (PLM) and prompt it with the passage as input to generate the question tokens using teacher-forcing. As finetuning of the questiongeneration PLM is not needed, only the retrieval model, ART can use large PLMs and obtain accurate soft-label estimates of which passages are likely to be the highest quality.\n\nThe retriever is trained to penalize the divergence of a passage likelihood from its soft-label score. For example, if the question is ''Where is the bowling hall of fame located?'' as shown in Figure 1, then the training process will boost the retrieval likelihood of the passage ''Bowling Hall of Fame is located in Arlington,'' as it is relevant and would lead to a higher question reconstruction likelihood, while the likelihood of the passage ''Hall of Fame is a song by ...'' would be penalized as it is irrelevant. In this manner, the training process encourages correct retrieval results and vice-versa, leading to an iterative improvement in passage retrieval.\n\nComprehensive experiments on five benchmark QA datasets demonstrate the usefulness of our proposed training approach. By simply using questions from the training set, ART outperforms models like DPR by an average of 5 points absolute in top-20 and 4 points absolute in top-100 accuracy. We also train using all the questions contained in the Natural Questions (NQ) dataset (Kwiatkowski et al., 2019) and find that even with a mix of answerable and unanswerable questions, ART achieves strong generalization on outof-distribution datasets due to relying on PLM. Our analysis further reveals that ART is highly sample-efficient, outperforming BM25 and DPR with just 100 and 1000 questions, respectively, on the NQ-Open dataset, and that scaling up to larger retriever models consistently improves performance.\n\n\nMethod\n\n\nProblem Definition\n\nWe focus on open-domain retrieval, where, given a question q, the task is to select a small set of matching passages (i.e., 20 or 100) from a large collection of evidence passages D = {d 1 , . . . , d m }. Our goal is to train a retriever in a zero-shot manner, that is, without using question-passage pairs, such that it retrieves relevant passages to answer the question. Our proposed approach consists of two core modeling components ( \u00a72.2, \u00a72.3) and a novel training method ( \u00a72.4).\n\n\nDual Encoder Retriever\n\nFor the retriever, we use the dual-encoder model (Bromley et al., 1994) which consists of two encoders, where\n\n\u2022 one encoder computes the question embedding f q (q; \u03a6 q ) : X \u2192 R d , and\n\n\u2022 the other encoder computes the passage\nembedding f d (d; \u03a6 d ) : X \u2192 R d .\nHere, X = V n denotes the universal set of text sequences, V denotes the vocabulary consisting of discrete tokens, and R d denotes the (latent) embedding space. We assume that both the question and passage embeddings lie in the same latent space. The retrieval score for a question-passage pair (q, d) is then defined as the inner product between their respective embeddings,\nscore(q, d i ; \u03a6) = f q (q; \u03a6 q ) \u00b7 f d (d i ; \u03a6 d ), \u2200d i \u2208 D,(1)\nwhere \u03a6 = [\u03a6 q , \u03a6 d ] denotes the retriever parameters. We select the top-K passages with maximum inner product scores and denote them as Z = {z 1 , . . . , z K }. 2 We use the transformer network (Vaswani et al., 2017) with BERT tokenization  to model both the encoders. To obtain the question or passage embedding, we do a forward pass through the transformer and select the last layer hidden state corresponding to the [CLS] token. As the input passage representation, we use both the passage title and text separated by [SEP] token.\n\n\nZero-Shot Cross-Attention Scorer\n\nWe obtain an estimate of the relevance score for a question-(retrieved) passage pair (q, z) by using a PLM. In order to do this in a zero-shot manner, we use a large generative PLM to compute the likelihood score of a passage conditioned on the question p(z | q).\n\nThe quantity p(z | q) can be better approximated by the autoregressive generation of question tokens conditioned on the passage and teacher-forcing (Sachan et al., 2022). More formally, this can be written as\nlog p(z | q; \u0398) = log p(q | z; \u0398) + log p(z) + c (2a) \u221d 1 |q| t log p(q t | q <t , z; \u0398),(2b)\nwhere \u0398 denotes the parameters of the PLM, c is a constant independent of the passage z, and |q| denotes the number of question tokens. Here, Eq. 2a follows from a simple application of Bayes' rule to p(z | q) and assuming that the passage prior p(z) in Eq. 2b is uniform for all z \u2208 Z. We hypothesize that calculating the relevance score using Eq. 2b would be accurate because it requires performing deep cross-attention involving all the question and passage tokens. In a large PLM, the cross-attention step is highly expressive, and in combination with teacher-forcing, requires the model to explain every token in the question resulting in a better estimation.\n\nAs the input passage representation, we concatenate the passage title and its text. In order to prompt the PLM for question generation, we follow Sachan et al. (2022) and append a simple natural language instruction ''Please write a question based on this passage.'' to the passage text.\n\n\nTraining Algorithm\n\nFor training the model, our only assumption is that a collection of questions (T ) and evidence passages (D) are provided as input. During training, the weights of the retriever are updated while the PLM is not finetuned, i.e., it is used in inference mode. Our training algorithm consists of five core steps. The first four steps are performed at every training iteration while the last step is performed every few hundred iterations. Figure 1 presents an illustration of our approach.\n\nStep 1: Top-K Passage Retrieval For fast retrieval, we pre-compute the evidence passage embedding using the initial retriever parameters (\u03a6 d ). Given a question q, we compute its embedding using the current question encoder parameters (\u03a6 q ) and then retrieve the top-K passages (Z) according to Eq. 1. We then embed these top-K passages using the current passage encoder parameters (\u03a6 d ) and compute fresh retriever scores as\nscore(q, z i ) = f q (q; \u03a6 q ) \u00b7 f d (z i ; \u03a6 d ), \u2200z i \u2208 Z.\nStep 2: Retriever Likelihood Calculation Computing the exact likelihood of the passage conditioned on the question requires normalizing over all the evidence passages\np(z i | q, D; \u03a6) = exp(score(q, z i )/\u03c4 ) m j=1 exp(score(q, d j )/\u03c4 ) ,\nwhere \u03c4 is a temperature hyperparameter. Computing this term is intractable, as this would require re-embedding all the evidence passages using \u03a6 d . Hence, we define a new distribution to approximate the likelihood of z i as\nq(z i | q, Z; \u03a6) = exp(score(q, z i )/\u03c4 ) K j=1 exp(score(q, z j )/\u03c4 ) ,(3)\nwhich we also refer to as the student distribution. We assume that passages beyond the top-K contribute a very small probability mass, so we only sum over all the retrieved passages Z in the denominator. While this approximation leads to a biased estimate of retrieved passage likelihood, it works well in practice. Computing Eq. 3 is tractable as it requires embedding and backpropagating through a much smaller set of passages.\n\nStep 3: PLM Relevance Score Estimation We compute the relevance score log p(z i | q) of all the passages in Z using a large PLM (\u0398). This requires scoring the question tokens using teacherforcing conditioned on a passage as described in \u00a72.3. We then define a teacher distribution by applying softmax to the relevance score\u015d\np(z i | q, Z) = exp(log p(z i | q; \u0398)) K j=1 exp (log p(z j | q; \u0398)) .\nStep 4: Loss Calculation and Optimization We train the retriever (\u03a6) by minimizing the KL divergence loss between the teacher distribution (obtained by PLM) and the student distribution (computed by retriever).\nL(\u03a6) = 1 |T | q\u2208T KL(p(z i | q, Z) || q(z i | q, Z; \u03a6))\nIntuitively, optimizing the KL divergence pushes the passage likelihood scores of the retriever to match the passage relevance scores from PLM by considering the relevance scores as soft-labels.\n\nStep 5: Updating Evidence Embeddings During training, we update the parameters of both the question encoder (\u03a6 q ) and passage encoder (\u03a6 d ). Due to this, the pre-computed evidence embeddings that was computed using initial retriever parameters (\u03a6 d ) becomes stale, which may affect top-K passage retrieval. To prevent staleness, we re-compute the evidence passage embeddings using current passage encoder parameters (\u03a6 d ) after every 500 training steps.\n\n\nART as an Autoencoder\n\nSince our encoder takes as input question q and the PLM scores (or reconstructs) the same question when computing the relevance score, we can consider our training algorithm as an autoencoder with a retrieved passage as the latent variable.\n\nIn the generative process, we start with an observed variable D (the collection of evidence passages), which is the support set for our latent variable. Given an input q, we generate an index i and retrieve the passage z i . This index generation and retrieval process is modeled by our dual encoder architecture. Given z i , we decode it back into the question using our PLM.\n\nRecall that our decoder (the PLM) is frozen and its parameters are not updated. However, the signal from the decoder output is used to train parameters of the dual encoder such that the log-likelihood of reconstructing the question q is maximized. In practice, this improves the dual encoder to select the best passage for a given question, since the only way to maximize the objective is by choosing the most relevant z i given the input q.\n\n\nExperimental Setup\n\nIn this section, we describe the datasets, evaluation protocol, implementation details, and baseline methods for our passage retrieval experiments.\n\n\nDatasets and Evaluation\n\nEvidence Passages The evidence corpus includes the preprocessed English Wikipedia dump from December 2018 (Karpukhin et al., 2020). Following convention, we split an article into nonoverlapping segments containing 100 words each, resulting in over 21 million passages. The same evidence is used for both training and evaluation.  Table 1 lists their training, development, and test set sizes.\n\n\nQuestion-Answering Datasets\n\nAll Questions Datasets For our transfer learning experiments, we use all the questions from Natural Questions (henceforth referred to as NQ-Full) and MS MARCO passage ranking (Bajaj et al., 2016) datasets. Table 1 lists the number of questions. The questions in NQ-Full are information-seeking, as they were asked by real users. Its size is four times that of NQ-Open. NQ-Full consists of questions having just long-form of answers such as paragraphs, all the questions in NQ-Open (which have both long-form and short-form answers), questions having yes/no answers, and questions that do not contain the answer or are unanswerable. For MS MARCO, we use its provided passage collection (around 8.8 million passages in total) as the evidence corpus.\n\nEvaluation To evaluate retriever performance, we report the conventional top-K accuracy metric. It is the fraction of questions for which at least one passage among the top-K retrieved passages contains a span of words that matches humanannotated answer(s) to the question.\n\n\nImplementation Details\n\nModel Sizes We use BERT base configuration  for the retriever, which consists of 12 layers, 12 attention heads, and 768 embedding dimensions, leading to around 220M trainable parameters. For the teacher PLM, we use two configurations: (i) T5-XL configuration (Raffel et al., 2020) consisting of 24 layers, 32 attention heads, and 2048 embedding dimensions, leading to 3B parameters, and (ii) a larger T5-XXL configuration consisting of 11B parameters.\n\n\nModel Initialization\n\nWe initialize the retriever with unsupervised masked salient spans (MSS) pre-training (Sachan et al., 2021a) as it provides an improved zero-shot retrieval over BERT pretraining. 3 We initialize the cross-attention (or teacher) PLM with the T5-lm-adapted (Lester et al., 2021) or instruction-tuned T0 (Sanh et al., 2022) language models, which have been shown to be effective zero-shot re-rankers for information retrieval tasks (Sachan et al., 2022).\n\nCompute Hardware We perform training on instances containing 8 or 16 A100 GPUs, each containing 40 GB RAM.\n\nPassage Retrieval To perform fast top-K passage retrieval at every training step, we pre-compute the embeddings of all the evidence passages. Computing embeddings of 21M passages takes roughly 10 minutes on 16 GPUs. The total size of these embeddings is around 30 GB (768-dimensional vectors in FP16 format). For scalable retrieval, we shard these embeddings across all the GPUs and perform exact maximum inner product search using distributed matrix multiplication.\n\nTraining Details When training with T0 (3B) PLM, for all the datasets except WebQ, we perform training for 10 epochs using Adam with a batch size of 64, 32 retrieved passages, dropout value of 0.1, and peak learning rate of 2 \u00d7 10 \u22125 with warmup and linear scheduling. Due to the smaller size of WebQ, we train for 20 epochs with a batch size of 16. When training with the T5-lm-adapted (11B) PLM, we use a smaller batch size of 32 with 16 retrieved passages. We save the retriever checkpoint every 500 steps and perform model selection by evaluating it on the development set. We use mixed precision training to train the retriever and perform inference over the PLM using bfloat16 format. We set the value of the temperature hyperparameter (\u03c4 ) using cross-validation.\n\n\nBaselines\n\nWe compare ART to both unsupervised and supervised models. Unsupervised models train a single retriever using unlabeled text corpus from the Internet while supervised models train a separate retriever for each dataset. We report the performance numbers from the original papers when the results are available or run their opensource implementations in case the results are not available.\n\nUnsupervised Models These include the popular BM25 algorithm (Robertson and Zaragoza, 2009) that is based on the sparse bag-of-words representation of text. Dense models typically use Wikipedia paragraphs to create (pseudo-) query and context pairs to perform contrastive training of the retriever. These differ in how the negative examples are obtained during contrastive training: They can be from the same batch (ICT; Sachan et al., 2021a), or contexts passages from previous batches (Contriever ;Izacard et al., 2022), or by using other passages in the same article (Spider; Ram et al., 2022). Context passages can also be sampled from articles connected via hyperlinks (HLP; Zhou et al., 2022).\n\nSupervised Models These consist of approaches that use questions and positive passages to perform contrastive training of the retriever.\n\nTo obtain improved performance an additional set of hard-negative passages is often used (DPR; Karpukhin et al., 2020), iterative mining of negative contexts is done using model weights (ANCE; Xiong et al., 2021), or the retriever is first initialized with ICT or MSS pre-training followed by DPR-style finetuning (ICT-DPR / MSS-DPR; Sachan et al., 2021a). The pre-trained retriever can be further trained by ANCE-style mining of hard-negative passages to further improve accuracy (coCondenser; Gao and Callan, 2022). Previous methods have also explored finetuning the cross-encoder PLM jointly with the retriever such that cross-encoder provides more accurate training signals to improve retrieval accuracy. Among them include the approaches of end-to-end training of PLM and retriever, which infuses supervision from the annotated answers to a question (EMDR 2 ; Sachan et al., 2021b), and a multi-stage mixed objective distillation approach to jointly train the re-ranker (Nogueira and Cho, 2019) and retriever (RocketQAv2; . A combination of adversarial and distillation-based training of re-ranker and retriever has been shown to obtain state-of-the-art performance (AR2; .\n\n\nExperiments and Results\n\n\nZero-Shot Passage Retrieval\n\nFor the passage retrieval task, we report results on SQuAD-Open, TriviaQA, NQ-Open, and WebQ and train ART under two settings. In the first setting, we train a separate retriever for each dataset using questions from their training set. In the second setting, to examine the robustness of ART training to different question types, we train a single retriever by combining the questions from all the four datasets, which we refer to as ART-Multi. For both these settings, we train ART using T5-lm-adapted (11B) and T0 (3B) cross-attention PLM scorers. As our training process does not require annotated passages for a question, we refer to this as zero-shot passage retrieval. Table 2 presents the top-20 and top-100 retrieval accuracy in these settings alongside recent baselines that train a similarly sized retriever (110M). All the variants of ART achieve substantially better performance than previous unsupervised approaches. For example, ART trained with T0 (3B) outperforms the recent Spider and Contriever models by an average of 9 points on top-20 and 6 points on top-100 accuracy. When comparing with supervised models, despite using just questions, ART outperforms strong baselines like DPR and ANCE and is on par or slightly better than pre-trained retrievers like MSS-DPR. In addition, ART-Multi obtains comparable performance to its single dataset version, a considerable advantage in practical applications as a single retriever can be deployed rather than training a custom retriever for each use case.\n\nART's performance also comes close to the state-of-the-art supervised models like AR2 and EMDR 2 , especially on the top-100 accuracy but lags behind in the top-20 accuracy. In addition to obtaining reasonable performance and not requiring aligned passages for training, ART's training process is much simpler than AR2. It also does not require cross-encoder finetuning and is thus faster to train. As generative language models continue to become more accurate (Chowdhery et al., 2022), we hypothesize that the performance gap between state-of-the-art supervised models and ART would further narrow down.\n\nOur results showcase that both the PLM scorers, T5-lm-adapt (11B) and T0 (3B), achieve strong results on the QA retrieval tasks, with T0 achieving higher performance gains. This illustrates that the relevance score estimates of candidate passages obtained in the zero-shot cross-attention step are accurate enough to provide strong supervision for retriever training. We believe that this is a direct consequence of the knowledge stored in the PLM weights. While T5-lm-adapt's knowledge is obtained by training on unsupervised text corpora, T0 was further finetuned using instruction-prompted datasets of tasks such as summarization, QA, text classification, etc. 4 Hence, in addition to learning from instructions, the performance gains from T0 can be attributed to the knowledge infused in its  Top-20 Top-100 Top-20 Top-100 Top-20 Top-100 Top-20 Top-  weights by (indirect) supervision from these manually curated datasets. Instruction-based finetuning is helpful in the case of smaller datasets like WebQ and especially in improving the performance on lower values of top-K accuracy (such as top-20). 5 Overall, our results suggest that an accurate and robust passage retrieval can be achieved by training with questions alone. This presents a considerably more favorable setting than the cur-5 \u00a74.5 includes more detailed comparisons of different PLMs as cross-encoders. rent approaches which require obtaining positive and hard-negative passages for such questions. Due to its better performance, we use the T0 (3B) PLM for subsequent experiments unless stated otherwise.\n\n\nSample Efficiency\n\nTo measure the sample efficiency of ART, we train the model by randomly selecting a varying number of questions from NQ-Open training questions and compute the top-K accuracy on its development set. These results are presented in Figure 2 and we also include the results of BM25 and DPR for comparison. We see that performance increases with the increase in questions until about 10k questions, after which the gains become less pronounced.\n\nWhen trained with just 100 questions, ART significantly outperforms BM25 and when trained with 1k questions, it matches DPR performance levels for top-{50, . . . , 100} accuracy. This demonstrates that ART in addition to using just questions is also much more data efficient than DPR, as it requires almost ten times fewer questions to reach a similar performance.\n\n\nZero-Shot Out-of-Distribution Transfer\n\nIn the previous experiments, both the training and test sets contained questions that were sampled from the same underlying distribution, a setting that we refer to as in-distribution training. However, obtaining in-domain questions for training is not always feasible in practice. Instead, a model trained on an existing collection of questions must be evaluated on new datasets, a setting that we refer to as out-of-distribution (OOD) transfer.\n\nWe train ART using NQ-Open and NQ-Full questions and then evaluate its performance on SQuAD-Open, TriviaQA, WebQ, and EQ datasets. It is desirable to train on answerable questions such as the ones included in NQ-Open, but this is not always possible, as real user questions are often imprecisely worded or ambiguous. Due to this, training on NQ-Full can be considered as a practical testbed for evaluating true OOD generalization as a majority of the questions (51%) were marked as unanswerable from Wikipedia by human annotators. 6 Table 3 presents OOD generalization results on the four QA datasets including the results of DPR and Spider models trained on NQ-Open. 7 ART trained on NQ-Open always performs significantly better than both DPR and Spider, showing that it is better at generalization than supervised models. When trained using NQ-Full, ART performance further improves by 3 and 0.5-1 points on EQ and other datasets, respectively, over NQ-Open. This highlights that in addition to questions annotated as having short answers, questions annotated with long answers also provide meaningful supervisory signals and unanswerable questions do not necessarily degrade performance.\n\nWe also train ART using MS MARCO questions and perform OOD evaluation. Due to the larger size of MS MARCO and a smaller number of evidence passages, we use a batch size of 512 and retrieve 8 passages for training. Quite surprisingly, it obtains much better performance than previous approaches including BM25 on EQ (more than 10 points gain on top-20 over training ART on NQ-Open). We suspect that this may be due to the similar nature of questions in MS MARCO and EQ. Further finetuning the pre-trained MS MARCO model on NQ-Full significantly improves performance on WebQ.\n\n\nScaling Model Size\n\nWe examine if scaling up the retriever parameters can offer further performance improvements. To this end, we train a retriever of BERT-large configuration (24 layers, 16 attention heads, 1024 embedding dimensions) containing around 650M parameters on NQ-Open and TriviaQA. Results are presented in Table 4 for both the development 6 The reasons for question unanswerability can be partly attributed to imprecise Wikipedia article retrieval during the annotation process, ambiguity in information-seeking questions, information required to answer not being localized to a single paragraph, etc. (Kwiatkowski et al., 2019). 7 We also include BM25 results for reference but do not directly compare with them because there is a high lexical overlap between question and passage tokens in the SQuAD-Open and EQ datasets which renders dense retrievers at a disadvantage over BM25, especially in the transfer setting.\n\n\nRetriever Training Dataset\n\n\nSQuAD-Open\n\nTriviaQA WebQ EQ   Top-20 Top-100 Top-20 Top-100 Top-20 Top-100 Top-20 Top-100 Training on answerable questions  Table 3: Top-20 and top-100 retrieval accuracy when evaluating zero-shot out-of-distribution (OOD) generalization of models on the test set of datasets. \u2020 denotes that these results are from Ram et al. (2022). ART generalizes better than supervised models on OOD evaluation even when trained on all the questions of the Natural Questions dataset, which contains a mix of answerable and unanswerable questions.  and test sets. We also include the results of other relevant baselines containing a similar number of trainable parameters. By scaling up the retriever size, we see small but consistent improvements in retrieval accuracy across both the datasets. Especially on Trivia-QA, ART matches or exceeds the performance of previous best models. On NQ-Open, it comes close to the performance of EMDR 2 (Sachan et al., 2021b), a supervised model trained using thousands of question-answer pairs.\n\nWe also attempted to use larger teacher PLMs such as T0 (11B). However, our initial experiments did not lead to any further improvements over the T0 (3B) PLM. We conjecture that this might be either specific to these QA datasets or that we need to increase the capacity of the teacher PLM even more to observe improvements. We leave an in-depth analysis of using larger teacher PLMs as part of the future work.\n\n\nAnalysis\n\nSensitivity to Retriever Initialization To examine how the convergence of ART training is affected by the initial retriever parameters, we initialize the retriever with (1) BERT weights, (2) ICT weights (as trained in Sachan et al., 2021a), and (3) MSS weights, and train using NQ-Open questions. Figure 3 displays the top-20 performance on the NQ development set as the training progresses. It reveals that ART training is not sensitive to the initial retriever parameters as all three initialization schemes converge to similar results. However, the convergence properties might be different under low-resource settings, an exploration of which we leave for future work. Table 5 quantifies the effect of the number of retrieved passages used during training on performance. A smaller number of retrieved passages Figure 3: Effect of retriever initialization on ART training. The plot reveals that the training process is not sensitive to initial retriever parameters.  A Closer Inspection of ART with Supervised Models In order to have a better understanding of the tradeoff between supervised models and ART, we examine their top-1 and top-5 accuracy in addition to the commonly reported top-20 and top-100 scores. Table 6 presents these results for ART (large) along with supervised models of DPR (large) and EMDR 2 . Supervised models achieve much better performance for top-K \u2208 {1, . . . , 5} passages, i.e., these models are more precise. This is likely because DPR is trained with hard-negative passages and EMDR 2 finetunes PLM using answers resulting in an accurate relevance feedback to the retriever. When considering top-K \u2208 {20, . . . , 100} passages, ART comes close or matches the performance of EMDR 2 . As top-performing models for knowledge-intensive tasks such as open-domain QA rely on a larger set of retrieved passages, such as top-K = 100 (Sachan et al., 2022), this justifies the argument to adopt zero-shot ART over supervised retrievers.\n\n\nEffect of the Number of Retrieved Passages\n\n\nRetrieved Passages\n\nWhy Training using Passage Retrieval? To assess the importance of passages in Z during the training process, we train the retriever under different settings by varying the passage types. Specifically, we train with a mix of positive, hard-negative, and uniformly sampled passages. We also perform in-batch training by defining Z to be the union of positive and hard-negative passages for all the questions in a batch. Results in Table 7 illustrate that when Z consists of uniformly sampled passages, it leads to poor performance. Including a (gold) positive passage in Z leads to good performance improvements. Results further improve with the inclusion of a hard-negative passage in Z. However, in-batch training leads to a slight drop in performance. As the gold passages are not always available, our method of selecting the top passages from evidence at every training step can be seen as an  Table 7: Effect of passage types on ART training when evaluated on the NQ-Open development set. P denotes a positive passage, N denotes a hard-negative passage (mined using BM25), U denotes that the passages are randomly sampled from the evidence, and IB denotes in-batch training.\n\napproximation to using the gold passages. With this, ART obtains even better results than the previous settings, an improvement by 4 points absolute in the top-20 accuracy.\n\n\nImpact of Language Model Training Strategy\n\nWe examine which PLMs can provide good cross-attention scores during training. We compare across PLMs trained using three different objectives: (i) generative denoising of masked spans (T5 series; Raffel et al., 2020), (ii) further pre-training using autoregressive language modeling objective (T5-lm-adapt series; Lester et al., 2021), and (iii) finetuning T5-lm-adapt models on unrelated tasks using instructions (T0 series; Sanh et al., 2022). Our results in Table 8 highlight that PLM training methodology and model size can have a large effect on retrieval performance. T5 base model leads to low scores possibly because pre-training using predicting masked spans is not ideal for question reconstruction. However, the accuracy improves with an increase in model size. T5-lm-adapt models are more stable and lead to improved performance with the best result achieved by the 11B model. Instruction finetuned T0 models outperforms the T5-lmadapt models. However, scaling up the size of T0 to 11B parameters does not result in meaningful improvements.\n\nAd-Hoc Retrieval Tasks While the previous experiments were conducted on QA datasets, here we examine the robustness of the ART model trained using questions to different ad-hoc retrieval tasks. For this analysis, we evaluate the performance of ART on the BEIR benchmark (Thakur et al., 2021). It is a heterogeneous col-  lection of many retrieval datasets, with each dataset consisting of test set queries, evidence documents, and gold document annotations. BEIR spans multiple domains and diverse retrieval tasks presenting a strong challenge suite, especially to the dense retrievers. We train ART using MS MARCO questions and report its nDCG@10 and Recall@100 scores on each dataset. For comparison, we include the results of three baselines: BM25, Contriever, and DPR trained using NQ-Open. Our results presented in Table 9 show strong generalization performance of ART as it outperforms DPR and Contriever results. ART also achieves at par results with the strong BM25 baseline outperforming BM25 on 8 out of the 15 datasets (according to nDCG@10 scores).\n\n\nRelated Work\n\nOur work is based on training a dense retriever using PLMs, which we have covered in previous sections. Here, we instead focus on other related approaches.\n\nA popular method to train the dual-encoder retriever is to optimize contrastive loss using in-batch negatives (Gillick et al., 2019) and hardnegatives (Karpukhin et al., 2020;Xiong et al., 2021). Alternatives to using hard-negatives such as sampling from cached evidence embeddings  Table 9: Results on the BEIR benchmark. #Q and #E denotes the size of the test set and evidence, respectively. Best scores for each dataset are highlighted in bold. ART is trained using MS MARCO questions. DPR is trained using NQ-Open. \u2020 denotes that these results are from Thakur et al. (2021).\n\nhave also shown to work well in practice (Lindgren et al., 2021). Multi-vector encoders for questions and passages are more accurate than dual-encoders, (Luan et al., 2021;Khattab and Zaharia, 2020;Humeau et al., 2020), although at the cost of an increased latency and storage requirements. PLMs have been shown to improve passage rankings as they can perform cross-attention between the question and the retrieved passages (Lin et al., 2021). Supervised approaches to rerank either finetune PLMs using question-passage pairs (Nogueira et al., 2020) or finetune PLMs to generate question conditioned on the passage (Nogueira dos Santos et al., 2020) while unsupervised re-rankers are based on zero-shot question scoring (Sachan et al., 2022). The re-ranking process is slow due to the cross-attention step and is bottlenecked by the accuracy of first-stage retrievers. To address these limitations, cross-attention distillation approaches from the PLM to retriever have been proposed . Such distillation can be performed either in a single endto-end training step (Guu et al., 2020;Sachan et al., 2021b) or in a multi-stage process (Khattab et al., 2021;Izacard and Grave, 2021).\n\nAn alternative approach to using PLMs is to generate data that can aid retrieval. The data can be either the title or an answer that provides more information about the question (Mao et al., 2021). Generating new questions to augment the training data has also been shown to improve performance (Ma et al., 2021;Bonifacio et al., 2022;Dai et al., 2022). In comparison, we do not generate new questions but train the retriever using existing questions and PLM feedback. Data augmentation is likely complementary, and can further improve accuracy.\n\n\nConclusions and Future Work\n\nWe introduced ART, a novel approach to train a dense passage retriever using only questions. ART does not require question-passage pairs or hardnegative examples for training and yet achieves state-of-the-art results. The key to making ART work is to optimize the retriever to select relevant passages such that conditioning on them, the question generation likelihood computed using a large pre-trained language model iteratively improves. Despite requiring much less supervision, ART substantially outperforms DPR when evaluated on multiple QA datasets and also generalizes better on out-of-distribution questions.\n\nART presents several directions for future work. It would be interesting to apply this approach in low-resource retrieval including multilingual (Clark et al., 2020) and cross-lingual question answering (Asai et al., 2021). Our training framework can also be extended to train cross-modality retrievers such as for image or code search (Li et al., 2022;Neelakantan et al., 2022) using textual queries. Finally, other directions worth exploring would be to make use of labeled data when available such as by finetuning PLM on passage-question aligned data and to train multi-vector retrievers (Luan et al., 2021) with ART.\n\nFigure 1 :\n1ART maximizes the retrieved passage likelihood computed from the dense retriever by considering the language model question reconstruction score conditioned on the passage as a soft-label. Colored blocks indicate trainable parameters. Red arrows show gradient flow during backpropagation.\n\n\nFollowing previous work, we use the open-retrieval version of Natural Questions (NQ-Open; Kwiatkowski et al., 2019), TriviaQA (Joshi et al., 2017), SQuAD-1.0 (SQuAD-Open; Rajpurkar et al., 2016), Web-Questions (WebQ; Berant et al., 2013), and Entity-Questions (EQ; Sciavolino et al., 2021) datasets.\n\nFigure 2 :\n2Top-K accuracy as the number of training questions (denoted as 'Q' in the legend) is varied. When trained with 100 questions, ART outperforms BM25 and when trained with 1k questions, it matches DPR's performance for top-K > 50 passages, illustrating that ART is highly sample efficient.\n\n\n100Unsupervised Approaches (trained using Wikipedia / Internet data) \n\nBERT \n5.2 \n13.5 \n7.2 \n17.8 \n9.4 \n20.3 \n3.7 \n12.8 \n\nICT \n45.1 \n65.2 \n57.5 \n73.6 \n50.6 \n66.8 \n43.4 \n65.7 \n\nMSS \nT5  *  (220M) \n51.3 \n68.4 \n68.2 \n79.4 \n59.8 \n74.9 \n49.2 \n68.4 \n\nBM25 \n71.1 \n81.8 \n76.4 \n83.2 \n62.9 \n78.3 \n62.4 \n75.5 \n\nContriever \n63.4 \n78.2 \n74.2 \n83.2 \n67.8 \n82.1 \n74.9 \n80.1 \n\nSpider \n61.0 \n76.0 \n75.8 \n83.5 \n68.3 \n81.2 \n65.9 \n79.7 \n\ncpt-text S  \u2020 \n-\n-\n75.1 \n81.7 \n65.5 \n77.2 \n-\n-\n\nHLP \n-\n-\n76.9 \n84.0 \n70.2 \n82.0 \n66.9 \n80.8 \n\nSupervised Approaches (trained using question-passage aligned data) \n\nDPR \n63.2 \n77.2 \n79.4 \n85.0 \n78.4 \n85.4 \n73.2 \n81.4 \n\nDPR-Multi  \u2021 \n51.6 \n67.6 \n78.8 \n84.7 \n79.4 \n86.0 \n75.0 \n82.9 \n\nANCE \n-\n-\n80.3 \n85.3 \n81.9 \n87.5 \n-\n-\n\nICT-DPR \n-\n-\n81.7 \n86.3 \n81.8 \n88.0 \n72.5 \n82.3 \n\nMSS-DPR \n73.1 \n84.5 \n81.8 \n86.6 \n82.1 \n87.8 \n76.9 \n84.6 \n\ncoCondenser \n-\n-\n83.2 \n87.3 \n84.3 \n89.0 \n-\n-\n\nRocketQAv2 ERNIE  *  (110M) \n-\n-\n-\n-\n83.7 \n89.0 \n-\n-\n\nEMDR 2\u2022 \nT5  *  (220M) \n-\n-\n83.4 \n87.3 \n85.3 \n89.7 \n79.1 \n85.2 \n\nAR2 \nERNIE  *  (330M) \n-\n-\n84.4 \n87.9 \n86.0 \n90.1 \n-\n-\n\nOur Approach (trained using questions and Wikipedia text) \n\nART \nT5-lm-adapt (11B) \n74.2 \n84.3 \n82.5 \n86.6 \n80.2 \n88.4 \n74.4 \n82.7 \n\nART-Multi \nT5-lm-adapt (11B) \n72.8 \n83.2 \n82.2 \n86.6 \n81.5 \n88.5 \n74.8 \n83.7 \n\nART \nT0 (3B) \n75.3 \n85.0 \n82.9 \n87.1 \n81.6 \n89.0 \n75.7 \n84.3 \n\nART-Multi \nT0 (3B) \n74.7 \n84.5 \n82.9 \n87.0 \n82.0 \n88.9 \n76.6 \n85.0 \n\n\n\nTable 2 :\n2Top-20 and top-100 retrieval accuracy on the test set of datasets. For more details regarding the unsupervised and supervised models, please see \u00a73.3 in the text. Best supervised results are highlighted in bold while best results from the our proposed model (ART) are underlined. ART substantially outperforms previous unsupervised models and comes close to or matches the performance of supervised models by just using questions during training. * indicates that the cross-attention PLM is finetuned. \u2020 denotes that 'cpt-text S' model(Neelakantan et al., 2022) contains around 300M parameters. \u2021 denotes that DPR-Multi was not trained on SQuAD-Open. indicates that the results on SQuAD-Open and WebQ are obtained by finetuning the open-source MSS checkpoint. \u2022 indicates that EMDR 2 results are obtained using their open-source checkpoints.\n\nTable 4 :\n4Top-20 and top-100 accuracy when train-\ning large configuration retriever, which contains \naround 650M parameters. EMDR 2 (base config-\nuration) (Sachan et al., 2021b) contains 440M \nparameters. Best supervised results are under-\nlined while the best unsupervised results are high-\nlighted in bold. \n\n\n\nTable 5 :\n5Effect of using a different number of \nretrieved passages during ART training as evalu-\nated on the NQ-Open development set. For each \ncase, we list the absolute gain or loss in top-K \naccuracy when compared to the setting utilizing \n32 retrieved passages. \n\nsuch as 2 or 4 leads to a somewhat better top-\n{1, 5} accuracy, at the expense of a drop in top-\n{20, 100} accuracy. Retrieving 32 passages offers \na reasonable middle ground and beyond that, the \ntop-K retrieval performance tends to drop. \n\n\n\n\nNQ-Open (dev)Language Model (\u0398) Top-1 Top-5 Top-20 Top-100Models trained using Denoising Masked SpansT5-base (250M) \n12.8 \n30.9 \n47.8 \n63.0 \n\nT5-xl (3B) \n25.0 \n53.9 \n74.4 \n85.3 \n\nT5-xxl (11B) \n29.5 \n59.8 \n77.8 \n86.3 \n\nModels trained using Language Modeling Objective \n\nT5-lm-adapt (250M) \n29.4 \n56.6 \n74.4 \n84.7 \n\nT5-lm-adapt (800M) \n30.9 \n59.1 \n76.5 \n85.9 \n\nT5-lm-adapt (3B) \n31.8 \n61.0 \n77.9 \n86.5 \n\nT5-lm-adapt (11B) \n32.7 \n62.6 \n78.6 \n87.0 \n\nModel trained using Natural Language Instructions \n\nT0 (3B) \n36.7 \n65.8 \n80.6 \n87.4 \n\nT0 (11B) \n34.3 \n64.5 \n79.8 \n87.2 \n\n\n\nTable 8 :\n8Comparison of different PLMs when used as cross-attention scorers during training ( \u00a72.3). T0 (3B) PLM achieves the highest accuracy among the compared PLMs showcasing that training language models using instruction-tuning provides accurate relevance scores.\n\n\nBM25 \u2020 Contriever ART DPR \u2020 BM25 \u2020 Contriever ARTDataset \n\n#Q \n#E \nnDCG@10 \nRecall@100 \nDPR  \u2020 Scifact \n300 \n5K \n31.8 \n66.5 \n64.9 \n55.2 \n72.7 \n90.8 \n92.6 \n88.0 \n\nScidocs \n1000 25K \n7.7 \n15.8 \n14.9 \n14.4 \n21.9 \n35.6 \n36.0 \n32.4 \n\nNfcorpus \n323 3.5K \n18.9 \n32.5 \n31.7 \n29.9 \n20.8 \n25.0 \n29.0 \n26.6 \n\nFIQA-2018 \n648 57K \n11.2 \n23.6 \n24.5 \n26.5 \n34.2 \n53.9 \n56.2 \n55.4 \n\nTrec-covid \n50 0.2M 33.2 \n65.5 \n27.4 \n50.3 \n21.2 \n49.8 \n17.2 \n36.9 \n\nTouche-2020 \n49 0.4M 13.1 \n36.8 \n19.3 \n16.2 \n30.1 \n53.8 \n22.5 \n44.7 \n\nNQ \n3452 2.7M 47.4 \n32.9 \n25.4 \n40.5 \n88.0 \n76.0 \n77.1 \n88.7 \n\nMS-Marco \n6980 8.8M 17.7 \n22.8 \n20.6 \n32.6 \n55.2 \n65.8 \n67.2 \n81.7 \n\nHotpotQA \n7405 5.2M 39.1 \n60.3 \n48.1 \n61.0 \n59.1 \n74.0 \n70.4 \n73.9 \n\nArguAna \n1406 8.7K \n17.5 \n31.5 \n37.9 \n32.2 \n75.1 \n94.2 \n90.1 \n95.3 \n\nCQADupStack 13145 0.5M 15.3 \n29.9 \n28.4 \n33.5 \n40.3 \n60.6 \n61.4 \n62.6 \n\nQuora \n10000 0.5M 24.8 \n78.9 \n83.5 \n84.2 \n47.0 \n97.3 \n98.7 \n98.8 \n\nDBpedia \n400 4.6M 26.3 \n31.3 \n29.2 \n36.3 \n34.9 \n39.8 \n45.3 \n47.2 \n\nFever \n6666 5.4M 56.2 \n75.3 \n68.2 \n72.4 \n84.0 \n93.1 \n93.6 \n93.1 \n\nClimate-Fever \n1535 5.4M 14.8 \n21.3 \n15.5 \n21.4 \n39.0 \n43.6 \n44.1 \n47.1 \n\nAverage Score \n25.0 \n41.6 \n36.0 \n40.4 \n48.2 \n63.6 \n60.1 \n64.8 \n\n\nOur code and model checkpoints are available at: https://github.com/DevSinghSachan/art.\nAs the selection operation requires performing innerproduct with millions of passage embeddings, this can be efficiently performed on accelerators such as GPUs.\nWe use the open-source MSS retriever checkpoint from https://github.com/DevSinghSachan/emdr2.\nHowever, we note that T0 was not finetuned on the question generation task and not trained on any of the datasets we have used in this work. We refer the reader to the original paper for more training details.\nAcknowledgmentsWe are grateful to the TACL action editor and the three anonymous reviewers for providing us valuable feedback and useful suggestions that helped to improve this work. We would also like to thank Elena Gribovskaya from DeepMind for providing us valuable comments to improve the paper.\nXOR QA: Cross-lingual open-retrieval question answering. Akari Asai, Jungo Kasai, Jonathan Clark, Kenton Lee, Eunsol Choi, Hannaneh Hajishirzi, 10.18653/v1/2021.naacl-main.46Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesAkari Asai, Jungo Kasai, Jonathan Clark, Kenton Lee, Eunsol Choi, and Hannaneh Hajishirzi. 2021. XOR QA: Cross-lingual open-retrieval question answering. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. https://doi .org/10.18653/v1/2021.naacl-main.46\n\nMS MARCO: A human generated machine reading comprehension dataset. Payal Bajaj, Daniel Campos, Nick Craswell, Li Deng, Jianfeng Gao, Xiaodong Liu, Rangan Majumder, Andrew Mcnamara, Bhaskar Mitra, Tri Nguyen, 10.48550/arXiv.1611.09268arXiv:1611.09268arXiv preprintPayal Bajaj, Daniel Campos, Nick Craswell, Li Deng, Jianfeng Gao, Xiaodong Liu, Rangan Majumder, Andrew McNamara, Bhaskar Mitra, Tri Nguyen, et al. 2016. MS MARCO: A hu- man generated machine reading comprehen- sion dataset. arXiv preprint arXiv:1611.09268. https://doi.org/10.48550/arXiv.1611 .09268\n\nSemantic parsing on Freebase from question-answer pairs. Jonathan Berant, Andrew Chou, Roy Frostig, Percy Liang, Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing. the 2013 Conference on Empirical Methods in Natural Language ProcessingJonathan Berant, Andrew Chou, Roy Frostig, and Percy Liang. 2013. Semantic parsing on Freebase from question-answer pairs. In Pro- ceedings of the 2013 Conference on Empirical Methods in Natural Language Processing.\n\nInpars: Unsupervised dataset generation for information retrieval. Luiz Bonifacio, Hugo Abonizio, Marzieh Fadaee, Rodrigo Nogueira, 10.1145/3477495.3531863Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval. the 45th International ACM SIGIR Conference on Research and Development in Information RetrievalLuiz Bonifacio, Hugo Abonizio, Marzieh Fadaee, and Rodrigo Nogueira. 2022. Inpars: Unsu- pervised dataset generation for information retrieval. In Proceedings of the 45th Interna- tional ACM SIGIR Conference on Research and Development in Information Retrieval. https://doi.org/10.1145/3477495 .3531863\n\nSignature verification using a ''siamese'' time delay neural network. Jane Bromley, Isabelle Guyon, Yann Lecun, Eduard S\u00e4ckinger, Roopak Shah, 10.1142/9789812797926_0003Advances in Neural Information Processing Systems. Jane Bromley, Isabelle Guyon, Yann LeCun, Eduard S\u00e4ckinger, and Roopak Shah. 1994. Signature verification using a ''siamese'' time delay neural network. In Advances in Neural Information Processing Systems. https:// doi.org/10.1142/9789812797926 0003\n\n. Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won, Charles Chung, Sebastian Sutton, Parker Gehrmann, Kensen Schuh, Sasha Shi, Joshua Tsvyashchenko, Abhishek Maynez, Parker Rao, Yi Barnes, Noam M Tay, Vinodkumar Shazeer, Emily Prabhakaran, Nan Reif, Benton C Du, Reiner Hutchinson, James Pope, Jacob Bradbury, Michael Austin, Guy Isard, Pengcheng Gur-Ari, Toju Yin, Anselm Duke, Sanjay Levskaya, Sunipa Ghemawat, Henryk Dev, Xavier Michalewski, Vedant Garcia, Kevin Misra, Liam Robinson, Denny Fedus, Daphne Zhou, David Ippolito, Hyeontaek Luan, Lim, 10.48550/arXiv.2204.02311Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica Oliveira Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathleen S. Meier-Hellstern, Douglas EckBarret Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick; Jeff Dean, Slav Petrovand Noah Fiedel. 2022. PaLM: Scaling language modeling with pathways. ArXiv, abs/2204.02311.Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes, Yi Tay, Noam M. Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Benton C. Hutchinson, Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin, Toju Duke, Anselm Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier Garcia, Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David Luan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani Agrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat, Aitor Lewkowycz, Erica Oliveira Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei Zhou, Xuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei, Kathleen S. Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, and Noah Fiedel. 2022. PaLM: Scaling language modeling with pathways. ArXiv, abs/2204.02311. https:// doi.org/10.48550/arXiv.2204.02311\n\nTyDi QA: A benchmark for information-seeking question answering in typologically diverse languages. Jonathan H Clark, Eunsol Choi, Michael Collins, Dan Garrette, Tom Kwiatkowski, Vitaly Nikolaev, Jennimaria Palomaki, 10.1162/tacl_a_00317Transactions of the Association for Computational Linguistics. 8Jonathan H. Clark, Eunsol Choi, Michael Collins, Dan Garrette, Tom Kwiatkowski, Vitaly Nikolaev, and Jennimaria Palomaki. 2020. TyDi QA: A benchmark for information-seeking question answering in typologically diverse languages. Transactions of the Association for Computational Linguistics, 8:454-470. https://doi.org/10.1162/tacl a 00317\n\nDialog inpainting: Turning documents into dialogs. Zhuyun Dai, Arun Tejasvi Chaganty, Vincent Y Zhao, Aida Amini, Mike Qazi Mamunur Rashid, Kelvin Green, Guu, Proceedings of the 39th International Conference on Machine Learning. the 39th International Conference on Machine LearningZhuyun Dai, Arun Tejasvi Chaganty, Vincent Y. Zhao, Aida Amini, Qazi Mamunur Rashid, Mike Green, and Kelvin Guu. 2022. Dialog inpainting: Turning documents into dialogs. In Proceedings of the 39th International Con- ference on Machine Learning.\n\nBERT: Pre-training of deep bidirectional transformers for language understanding. Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, 10.18653/v1/N19-1423Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies1Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguis- tics: Human Language Technologies, Volume 1 (Long and Short Papers). https://doi .org/10.18653/v1/N19-1423\n\nUnsupervised corpus aware language model pre-training for dense passage retrieval. Luyu Gao, Jamie Callan, 10.18653/v1/2022.acl-long.203Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics. the 60th Annual Meeting of the Association for Computational LinguisticsLong Papers1Luyu Gao and Jamie Callan. 2022. Unsupervised corpus aware language model pre-training for dense passage retrieval. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). https://doi.org/10.18653 /v1/2022.acl-long.203\n\nLearning dense representations for entity retrieval. Daniel Gillick, Sayali Kulkarni, Larry Lansing, Alessandro Presta, Jason Baldridge, Eugene Ie, Diego Garcia-Olano, 10.18653/v1/K19-1049Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL). the 23rd Conference on Computational Natural Language Learning (CoNLL)Daniel Gillick, Sayali Kulkarni, Larry Lansing, Alessandro Presta, Jason Baldridge, Eugene Ie, and Diego Garcia-Olano. 2019. Learning dense representations for entity retrieval. In Proceedings of the 23rd Conference on Compu- tational Natural Language Learning (CoNLL). https://doi.org/10.18653/v1/K19 -1049\n\nRetrieval augmented language model pre-training. Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, Mingwei Chang, Proceedings of the 37th International Conference on Machine Learning. the 37th International Conference on Machine LearningKelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Mingwei Chang. 2020. Retrieval augmented language model pre-training. In Proceedings of the 37th International Confer- ence on Machine Learning.\n\nPolyencoders: Architectures and pre-training strategies for fast and accurate multi-sentence scoring. Samuel Humeau, Kurt Shuster, Marie-Anne Lachaux, Jason Weston, International Conference on Learning Representations. Samuel Humeau, Kurt Shuster, Marie-Anne Lachaux, and Jason Weston. 2020. Poly- encoders: Architectures and pre-training strate- gies for fast and accurate multi-sentence scoring. In International Conference on Learning Representations.\n\nUnsupervised dense information retrieval with contrastive learning. Gautier Izacard, Mathilde Caron, Lucas Hosseini, Sebastian Riedel, Piotr Bojanowski, Armand Joulin, Edouard Grave, Transactions on Machine Learning Research. Gautier Izacard, Mathilde Caron, Lucas Hosseini, Sebastian Riedel, Piotr Bojanowski, Armand Joulin, and Edouard Grave. 2022. Unsupervised dense information retrieval with contrastive learning. Transactions on Machine Learning Research.\n\nDistilling knowledge from reader to retriever for question answering. Gautier Izacard, Edouard Grave, International Conference on Learning Representations. Gautier Izacard and Edouard Grave. 2021. Dis- tilling knowledge from reader to retriever for question answering. In International Confer- ence on Learning Representations.\n\nTriviaQA: A large scale distantly supervised challenge dataset for reading comprehension. Mandar Joshi, Eunsol Choi, Daniel Weld, Luke Zettlemoyer, 10.18653/v1/P17-1147Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. the 55th Annual Meeting of the Association for Computational LinguisticsLong Papers1Mandar Joshi, Eunsol Choi, Daniel Weld, and Luke Zettlemoyer. 2017. TriviaQA: A large scale distantly supervised challenge dataset for reading comprehension. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). https://doi.org/10.18653/v1 /P17-1147\n\nDense passage retrieval for open-domain question answering. Vladimir Karpukhin, Barlas Oguz, Sewon Min, Ledell Wu, Sergey Edunov, Danqi Chen, Wen-Tau Yih, 10.18653/v1/2020.emnlp-main.550Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing. the 2020 Conference on Empirical Methods in Natural Language ProcessingVladimir Karpukhin, Barlas Oguz, Sewon Min, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih. 2020. Dense passage re- trieval for open-domain question answering. In Proceedings of the 2020 Conference on Empir- ical Methods in Natural Language Processing (EMNLP). https://doi.org/10.18653 /v1/2020.emnlp-main.550\n\nRelevance-guided supervision for openqa with colbert. Omar Khattab, Christopher Potts, Matei Zaharia, 10.1162/tacl_a_00405Transactions of the Association for Computational Linguistics. 9Omar Khattab, Christopher Potts, and Matei Zaharia. 2021. Relevance-guided supervision for openqa with colbert. Transactions of the Association for Computational Linguistics, 9:929-944. https://doi.org/10.1162 /tacl_a_00405\n\nColbert: Efficient and effective passage search via contextualized late interaction over BERT. Omar Khattab, Matei Zaharia, 10.1145/3397271.3401075Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval. the 43rd International ACM SIGIR Conference on Research and Development in Information RetrievalOmar Khattab and Matei Zaharia. 2020. Col- bert: Efficient and effective passage search via contextualized late interaction over BERT. In Proceedings of the 43rd International ACM SIGIR Conference on Research and Develop- ment in Information Retrieval. https://doi .org/10.1145/3397271.3401075\n\nNatural questions: A benchmark for question answering research. Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Matthew Kelcey, Jacob Devlin, Kenton Lee, Kristina N Toutanova, Llion Jones, Ming-Wei Chang, Andrew Dai, Jakob Uszkoreit, Quoc Le, Slav Petrov, 10.1162/tacl_a_00276Transactions of the Association of Computational Linguistics. 7Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Matthew Kelcey, Jacob Devlin, Kenton Lee, Kristina N. Toutanova, Llion Jones, Ming-Wei Chang, Andrew Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov. 2019. Natural questions: A benchmark for question answering research. Transactions of the Association of Computa- tional Linguistics, 7:453-466. https://doi .org/10.1162/tacl_a_00276\n\nLatent retrieval for weakly supervised open domain question answering. Kenton Lee, Ming-Wei Chang, Kristina Toutanova, 10.18653/v1/P19-1612Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. the 57th Annual Meeting of the Association for Computational LinguisticsKenton Lee, Ming-Wei Chang, and Kristina Toutanova. 2019. Latent retrieval for weakly supervised open domain question answering. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. https://doi.org/10.18653/v1/P19 -1612\n\nThe power of scale for parameterefficient prompt tuning. Brian Lester, Rami Al-Rfou, Noah Constant, 10.18653/v1/2021.emnlp-main.243Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. the 2021 Conference on Empirical Methods in Natural Language ProcessingBrian Lester, Rami Al-Rfou, and Noah Constant. 2021. The power of scale for parameter- efficient prompt tuning. In Proceedings of the 2021 Conference on Empirical Methods in Nat- ural Language Processing. https://doi.org /10.18653/v1/2021.emnlp-main.243\n\nNando de Freitas, Koray Kavukcuoglu, and Oriol Vinyals. 2022. Competition-level code generation with alphacode. Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, R\u00e9mi Leblond, Tom Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, Thomas Hubert, Peter Choy, Cyprien De Masson D&apos;autume, Igor Babuschkin, Xinyun Chen, Po-Sen Huang, Johannes Welbl, Sven Gowal, Alexey Cherepanov, James Molloy, Daniel J Mankowitz, Esme Sutherland Robson, Pushmeet Kohli, 10.1126/science.abq1158Science. 378662436480631Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, R\u00e9mi Leblond, Tom Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, Thomas Hubert, Peter Choy, Cyprien de Masson d'Autume, Igor Babuschkin, Xinyun Chen, Po-Sen Huang, Johannes Welbl, Sven Gowal, Alexey Cherepanov, James Molloy, Daniel J. Mankowitz, Esme Sutherland Robson, Pushmeet Kohli, Nando de Freitas, Koray Kavukcuoglu, and Oriol Vinyals. 2022. Competition-level code generation with alphacode. Science, 378(6624):1092-1097. https://doi.org/10.1126/science .abq1158, PubMed: 36480631\n\nPretrained transformers for text ranking: BERT and beyond. Jimmy Lin, Rodrigo Nogueira, Andrew Yates, 10.2200/S01123ED1V01Y202108HLT053Synthesis Lectures on Human Language Technologies. 144Jimmy Lin, Rodrigo Nogueira, and Andrew Yates. 2021. Pretrained transformers for text rank- ing: BERT and beyond. Synthesis Lectures on Human Language Technologies, 14(4):1-325. https://doi.org/10.2200/S01123ED\n\n. 10.2200/S01123ED1V01Y202108HLT0531V01Y202108HLT053\n\nEfficient training of retrieval models using negative cache. Erik Lindgren, J Sashank, Ruiqi Reddi, Sanjiv Guo, Kumar, Advances in Neural Information Processing Systems. Erik Lindgren, Sashank J. Reddi, Ruiqi Guo, and Sanjiv Kumar. 2021. Efficient training of retrieval models using negative cache. In Advances in Neural Information Processing Systems.\n\nYi Luan, Jacob Eisenstein, Kristina Toutanova, Michael Collins, 10.1162/tacl_a_00369Sparse, dense, and attentional representations for text retrieval. Transactions of the Association for Computational Linguistics. 9Yi Luan, Jacob Eisenstein, Kristina Toutanova, and Michael Collins. 2021. Sparse, dense, and attentional representations for text retrieval. Transactions of the Association for Computa- tional Linguistics, 9:329-345. https://doi .org/10.1162/tacl_a_00369\n\nZero-shot neural passage retrieval via domain-targeted synthetic question generation. Ji Ma, Ivan Korotkov, Yinfei Yang, Keith Hall, Ryan Mcdonald, 10.18653/v1/2021.eacl-main.92Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume. the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main VolumeJi Ma, Ivan Korotkov, Yinfei Yang, Keith Hall, and Ryan McDonald. 2021. Zero-shot neural passage retrieval via domain-targeted synthetic question generation. In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguis- tics: Main Volume. https://doi.org/10 .18653/v1/2021.eacl-main.92\n\nGeneration-augmented retrieval for open-domain question answering. Yuning Mao, Pengcheng He, Xiaodong Liu, Yelong Shen, Jianfeng Gao, Jiawei Han, Weizhu Chen, 10.18653/v1/2021.acl-long.316Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing. the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language ProcessingLong Papers1Yuning Mao, Pengcheng He, Xiaodong Liu, Yelong Shen, Jianfeng Gao, Jiawei Han, and Weizhu Chen. 2021. Generation-augmented re- trieval for open-domain question answering. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers). https://doi.org/10.18653/v1 /2021.acl-long.316\n\nArvind Neelakantan, Tao Xu, Raul Puri, Alec Radford, Jesse Michael Han, Jerry Tworek, Qiming Yuan, Nikolas Tezak, Jong Wook Kim, Chris Hallacy, 10.48550/arXiv.2201.10005arXiv:2201.10005Text and code embeddings by contrastive pre-training. arXiv preprintArvind Neelakantan, Tao Xu, Raul Puri, Alec Radford, Jesse Michael Han, Jerry Tworek, Qiming Yuan, Nikolas Tezak, Jong Wook Kim, Chris Hallacy, et al. 2022. Text and code embeddings by contrastive pre-training. arXiv preprint arXiv:2201.10005. https://doi .org/10.48550/arXiv.2201.10005\n\nRodrigo Nogueira, Kyunghyun Cho, 10.48550/arXiv.1901.04085arXiv:1901.04085Passage re-ranking with BERT. arXiv preprintRodrigo Nogueira and Kyunghyun Cho. 2019. Passage re-ranking with BERT. arXiv preprint arXiv:1901.04085. https://doi.org/10 .48550/arXiv.1901.04085\n\nDocument ranking with a pretrained sequence-to-sequence model. Rodrigo Nogueira, Zhiying Jiang, Ronak Pradeep, Jimmy Lin, 10.18653/v1/2020.findings-emnlp.63Findings of the Association for Computational Linguistics: EMNLP 2020. Rodrigo Nogueira, Zhiying Jiang, Ronak Pradeep, and Jimmy Lin. 2020. Document ranking with a pretrained sequence-to-sequence model. In Findings of the Association for Computational Linguistics: EMNLP 2020. https://doi.org /10.18653/v1/2020.findings-emnlp.63\n\nZhiheng Huang, and Bing Xiang. 2020. Beyond [CLS] through ranking by generation. Cicero Nogueira Dos Santos, Xiaofei Ma, Ramesh Nallapati, 10.18653/v1/2020.emnlp-main.134Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing. the 2020 Conference on Empirical Methods in Natural Language ProcessingCicero Nogueira dos Santos, Xiaofei Ma, Ramesh Nallapati, Zhiheng Huang, and Bing Xiang. 2020. Beyond [CLS] through ranking by gen- eration. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). https://doi.org/10 .18653/v1/2020.emnlp-main.134\n\nAaron Van Den Oord, Yazhe Li, Oriol Vinyals, 10.48550/arXiv.1807.03748arXiv:1807.03748Representation learning with contrastive predictive coding. arXiv preprintAaron van den Oord, Yazhe Li, and Oriol Vinyals. 2018. Representation learning with contrastive predictive coding. arXiv preprint arXiv:1807.03748. https://doi.org/10 .48550/arXiv.1807.03748\n\nRocket-QA: An optimized training approach to dense passage retrieval for open-domain question answering. Yingqi Qu, Yuchen Ding, Jing Liu, Kai Liu, Ruiyang Ren, Wayne Xin Zhao, Daxiang Dong, Hua Wu, Haifeng Wang, 10.18653/v1/2021.naacl-main.466Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesYingqi Qu, Yuchen Ding, Jing Liu, Kai Liu, Ruiyang Ren, Wayne Xin Zhao, Daxiang Dong, Hua Wu, and Haifeng Wang. 2021. Rocket- QA: An optimized training approach to dense passage retrieval for open-domain question answering. In Proceedings of the 2021 Confer- ence of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. https:// doi.org/10.18653/v1/2021.naacl-main .466\n\nExploring the limits of transfer learning with a unified text-to-text transformer. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J Liu, Journal of Machine Learning Research. 21140Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2020. Exploring the limits of transfer learning with a unified text-to-text transformer. Journal of Machine Learning Research, 21(140):1-67.\n\nSQuAD: 100,000+ questions for machine comprehension of text. Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, Percy Liang, 10.18653/v1/D16-1264Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing. the 2016 Conference on Empirical Methods in Natural Language ProcessingPranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016. SQuAD: 100,000+ questions for machine comprehen- sion of text. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing. https://doi.org /10.18653/v1/D16-1264\n\nLearning to retrieve passages without supervision. Ori Ram, Omer Shachaf, Jonathan Levy, Amir Berant, Globerson, 10.18653/v1/2022.naacl-main.193Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesOri Ram, Gal Shachaf, Omer Levy, Jonathan Berant, and Amir Globerson. 2022. Learning to retrieve passages without supervision. In Pro- ceedings of the 2022 Conference of the North American Chapter of the Association for Com- putational Linguistics: Human Language Tech- nologies. https://doi.org/10.18653 /v1/2022.naacl-main.193\n\nRocketQAv2: A joint training method for dense passage retrieval and passage re-ranking. Ruiyang Ren, Yingqi Qu, Jing Liu, Wayne Xin Zhao, Qiaoqiao She, Hua Wu, Haifeng Wang, Ji-Rong Wen, 10.18653/v1/2021.emnlp-main.224Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. the 2021 Conference on Empirical Methods in Natural Language ProcessingRuiyang Ren, Yingqi Qu, Jing Liu, Wayne Xin Zhao, QiaoQiao She, Hua Wu, Haifeng Wang, and Ji-Rong Wen. 2021. RocketQAv2: A joint training method for dense passage retrieval and passage re-ranking. In Proceedings of the 2021 Conference on Empirical Methods in Nat- ural Language Processing. https://doi.org /10.18653/v1/2021.emnlp-main.224\n\nThe probabilistic relevance framework: BM25 and beyond. Foundations and Trends in Information Retrieval. Stephen Robertson, Hugo Zaragoza, 10.1561/1500000019Stephen Robertson and Hugo Zaragoza. 2009. The probabilistic relevance framework: BM25 and beyond. Foundations and Trends in Infor- mation Retrieval. https://doi.org/10 .1561/1500000019\n\nImproving passage retrieval with zero-shot question generation. Devendra Singh Sachan, Mike Lewis, Mandar Joshi, Armen Aghajanyan, Wen-Tau Yih, Joelle Pineau, Luke Zettlemoyer, 10.48550/arXiv.2204.07496Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing. the 2022 Conference on Empirical Methods in Natural Language ProcessingDevendra Singh Sachan, Mike Lewis, Mandar Joshi, Armen Aghajanyan, Wen-tau Yih, Joelle Pineau, and Luke Zettlemoyer. 2022. Improv- ing passage retrieval with zero-shot question generation. In Proceedings of the 2022 Con- ference on Empirical Methods in Natural Lan- guage Processing. https://doi.org/10 .48550/arXiv.2204.07496\n\nEnd-to-end training of neural retrievers for open-domain question answering. Devendra Singh Sachan, Mostofa Patwary, Mohammad Shoeybi, Neel Kant, Wei Ping, William L Hamilton, Bryan Catanzaro, 10.18653/v1/2021.acl-long.519Joint Conference of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (ACL-IJCNLP. Devendra Singh Sachan, Mostofa Patwary, Mohammad Shoeybi, Neel Kant, Wei Ping, William L. Hamilton, and Bryan Catanzaro. 2021a. End-to-end training of neural retriev- ers for open-domain question answering. In Joint Conference of the 59th Annual Meet- ing of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Process- ing (ACL-IJCNLP). https://doi.org/10 .18653/v1/2021.acl-long.519\n\nEnd-to-end training of multi-document reader and retriever for open-domain question answering. Devendra Singh Sachan, Siva Reddy, William L Hamilton, Chris Dyer, Dani Yogatama, Advances in Neural Information Processing Systems. Devendra Singh Sachan, Siva Reddy, William L. Hamilton, Chris Dyer, and Dani Yogatama. 2021b. End-to-end training of multi-document reader and retriever for open-domain question answering. In Advances in Neural Information Processing Systems.\n\nMultitask prompted training enables zero-shot task generalization. Victor Sanh, Albert Webson, Colin Raffel, Stephen Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Arun Raja, Manan Dey, Canwen Bari, Urmish Xu, Shanya Thakker, Eliza Sharma Sharma, Taewoon Szczechla, Gunjan Kim, Nihal Chhablani, Debajyoti Nayak, Jonathan Datta, Mike Chang, Tian-Jian, Han Jiang, Matteo Wang, Sheng Manica, Shen, International Conference on Learning Representations. Zheng Xin Yong, Harshit Pandey, Rachel Bawden, Thomas Wang, Trishala Neeraj, Jos Rozen, Abheesht Sharma, Andrea Santilli, Thibault Fevry, Jason Alan Fries, Ryan Teehan, Teven Le ScaoStella Biderman, Leo Gao, Thomas Wolf, and Alexander M. RushVictor Sanh, Albert Webson, Colin Raffel, Stephen Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Arun Raja, Manan Dey, M Saiful Bari, Canwen Xu, Urmish Thakker, Shanya Sharma Sharma, Eliza Szczechla, Taewoon Kim, Gunjan Chhablani, Nihal Nayak, Debajyoti Datta, Jonathan Chang, Mike Tian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen, Zheng Xin Yong, Harshit Pandey, Rachel Bawden, Thomas Wang, Trishala Neeraj, Jos Rozen, Abheesht Sharma, Andrea Santilli, Thibault Fevry, Jason Alan Fries, Ryan Teehan, Teven Le Scao, Stella Biderman, Leo Gao, Thomas Wolf, and Alexander M. Rush. 2022. Multi- task prompted training enables zero-shot task generalization. In International Conference on Learning Representations.\n\nSimple entitycentric questions challenge dense retrievers. Christopher Sciavolino, Zexuan Zhong, Jinhyuk Lee, Danqi Chen, 10.18653/v1/2021.emnlp-main.496Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. the 2021 Conference on Empirical Methods in Natural Language ProcessingChristopher Sciavolino, Zexuan Zhong, Jinhyuk Lee, and Danqi Chen. 2021. Simple entity- centric questions challenge dense retrievers. In Proceedings of the 2021 Conference on Empir- ical Methods in Natural Language Processing. https://doi.org/10.18653/v1/2021 .emnlp-main.496\n\nBEIR: A heterogeneous benchmark for zero-shot evaluation of information retrieval models. Nandan Thakur, Nils Reimers, Andreas R\u00fcckl\u00e9, Abhishek Srivastava, Iryna Gurevych, Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track. Round 2Nandan Thakur, Nils Reimers, Andreas R\u00fcckl\u00e9, Abhishek Srivastava, and Iryna Gurevych. 2021. BEIR: A heterogeneous benchmark for zero-shot evaluation of information retrieval models. In Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2).\n\nAttention is all you need. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, Illia Polosukhin, Advances in Neural Information Processing Systems. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. 2017. At- tention is all you need. In Advances in Neural Information Processing Systems.\n\nApproximate nearest neighbor negative contrastive learning for dense text retrieval. Lee Xiong, Chenyan Xiong, Ye Li, Kwok-Fung Tang, Jialin Liu, Paul N Bennett, Junaid Ahmed, Arnold Overwijk, International Conference on Learning Representations. Lee Xiong, Chenyan Xiong, Ye Li, Kwok-Fung Tang, Jialin Liu, Paul N. Bennett, Junaid Ahmed, and Arnold Overwijk. 2021. Approx- imate nearest neighbor negative contrastive learning for dense text retrieval. In International Conference on Learning Representations.\n\nAdversarial retriever-ranker for dense text retrieval. Hang Zhang, Yeyun Gong, Yelong Shen, Jiancheng Lv, Nan Duan, Weizhu Chen, International Conference on Learning Representations. Hang Zhang, Yeyun Gong, Yelong Shen, Jiancheng Lv, Nan Duan, and Weizhu Chen. 2022. Adversarial retriever-ranker for dense text retrieval. In International Conference on Learning Representations.\n\nHyperlinkinduced pre-training for passage retrieval in open-domain question answering. Jiawei Zhou, Xiaoguang Li, Lifeng Shang, Lan Luo, Ke Zhan, Enrui Hu, Xinyu Zhang, Hao Jiang, Zhao Cao, Fan Yu, Xin Jiang, Qun Liu, Lei Chen, 10.18653/v1/2022.acl-long.493Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics. the 60th Annual Meeting of the Association for Computational LinguisticsLong Papers1Jiawei Zhou, Xiaoguang Li, Lifeng Shang, Lan Luo, Ke Zhan, Enrui Hu, Xinyu Zhang, Hao Jiang, Zhao Cao, Fan Yu, Xin Jiang, Qun Liu, and Lei Chen. 2022. Hyperlink- induced pre-training for passage retrieval in open-domain question answering. In Proceed- ings of the 60th Annual Meeting of the Associa- tion for Computational Linguistics (Volume 1: Long Papers). https://doi.org/10.18653 /v1/2022.acl-long.493\n", "annotations": {"author": "[{\"end\":140,\"start\":65},{\"end\":169,\"start\":141},{\"end\":213,\"start\":170},{\"end\":249,\"start\":214},{\"end\":310,\"start\":250},{\"end\":415,\"start\":311},{\"end\":475,\"start\":416}]", "publisher": null, "author_last_name": "[{\"end\":79,\"start\":74},{\"end\":180,\"start\":175},{\"end\":227,\"start\":219},{\"end\":266,\"start\":255},{\"end\":324,\"start\":318},{\"end\":429,\"start\":423}]", "author_first_name": "[{\"end\":73,\"start\":65},{\"end\":147,\"start\":141},{\"end\":174,\"start\":170},{\"end\":218,\"start\":214},{\"end\":254,\"start\":250},{\"end\":317,\"start\":311},{\"end\":422,\"start\":416}]", "author_affiliation": "[{\"end\":105,\"start\":81},{\"end\":139,\"start\":107},{\"end\":212,\"start\":201},{\"end\":248,\"start\":229},{\"end\":279,\"start\":268},{\"end\":309,\"start\":281},{\"end\":367,\"start\":343},{\"end\":401,\"start\":369},{\"end\":414,\"start\":403},{\"end\":474,\"start\":455}]", "title": "[{\"end\":62,\"start\":1},{\"end\":537,\"start\":476}]", "venue": null, "abstract": "[{\"end\":1739,\"start\":551}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b16\"},\"end\":1811,\"start\":1787},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":1830,\"start\":1811},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":1939,\"start\":1920},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":2068,\"start\":2038},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":4936,\"start\":4910},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":5961,\"start\":5939},{\"end\":6764,\"start\":6763},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":6818,\"start\":6796},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":7606,\"start\":7585},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":8572,\"start\":8552},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":13398,\"start\":13374},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":13887,\"start\":13867},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":15021,\"start\":15000},{\"end\":15397,\"start\":15396},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":15493,\"start\":15472},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":15537,\"start\":15518},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":15667,\"start\":15646},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":17509,\"start\":17480},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":17861,\"start\":17840},{\"end\":17919,\"start\":17918},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":17940,\"start\":17919},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":18015,\"start\":17998},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":18117,\"start\":18099},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":18376,\"start\":18353},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":18470,\"start\":18451},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":18774,\"start\":18753},{\"end\":21500,\"start\":21476},{\"end\":26638,\"start\":26637},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":26926,\"start\":26900},{\"end\":26929,\"start\":26928},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":27581,\"start\":27564},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":30577,\"start\":30556},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":32341,\"start\":32321},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":32459,\"start\":32439},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":32569,\"start\":32551},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":33470,\"start\":33449},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":34545,\"start\":34523},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":34588,\"start\":34564},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":34607,\"start\":34588},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":34990,\"start\":34970},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":35057,\"start\":35034},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":35165,\"start\":35146},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":35191,\"start\":35165},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":35211,\"start\":35191},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":35435,\"start\":35417},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":35542,\"start\":35519},{\"end\":35642,\"start\":35608},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":35734,\"start\":35713},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":36075,\"start\":36057},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":36096,\"start\":36075},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":36147,\"start\":36125},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":36170,\"start\":36147},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":36370,\"start\":36352},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":36486,\"start\":36469},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":36509,\"start\":36486},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":36526,\"start\":36509},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":37534,\"start\":37514},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":37591,\"start\":37572},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":37722,\"start\":37705},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":37747,\"start\":37722},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":37980,\"start\":37961},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":40882,\"start\":40856}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":38292,\"start\":37991},{\"attributes\":{\"id\":\"fig_1\"},\"end\":38594,\"start\":38293},{\"attributes\":{\"id\":\"fig_3\"},\"end\":38894,\"start\":38595},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":40308,\"start\":38895},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":41162,\"start\":40309},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":41476,\"start\":41163},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":41990,\"start\":41477},{\"attributes\":{\"id\":\"tab_10\",\"type\":\"table\"},\"end\":42560,\"start\":41991},{\"attributes\":{\"id\":\"tab_11\",\"type\":\"table\"},\"end\":42831,\"start\":42561},{\"attributes\":{\"id\":\"tab_12\",\"type\":\"table\"},\"end\":44020,\"start\":42832}]", "paragraph": "[{\"end\":2526,\"start\":1755},{\"end\":3107,\"start\":2528},{\"end\":3864,\"start\":3109},{\"end\":4535,\"start\":3866},{\"end\":5344,\"start\":4537},{\"end\":5863,\"start\":5376},{\"end\":5999,\"start\":5890},{\"end\":6076,\"start\":6001},{\"end\":6118,\"start\":6078},{\"end\":6530,\"start\":6155},{\"end\":7135,\"start\":6598},{\"end\":7435,\"start\":7172},{\"end\":7645,\"start\":7437},{\"end\":8404,\"start\":7740},{\"end\":8693,\"start\":8406},{\"end\":9202,\"start\":8716},{\"end\":9632,\"start\":9204},{\"end\":9860,\"start\":9694},{\"end\":10159,\"start\":9934},{\"end\":10665,\"start\":10236},{\"end\":10991,\"start\":10667},{\"end\":11273,\"start\":11063},{\"end\":11524,\"start\":11330},{\"end\":11983,\"start\":11526},{\"end\":12249,\"start\":12009},{\"end\":12627,\"start\":12251},{\"end\":13070,\"start\":12629},{\"end\":13240,\"start\":13093},{\"end\":13660,\"start\":13268},{\"end\":14439,\"start\":13692},{\"end\":14714,\"start\":14441},{\"end\":15192,\"start\":14741},{\"end\":15668,\"start\":15217},{\"end\":15776,\"start\":15670},{\"end\":16244,\"start\":15778},{\"end\":17016,\"start\":16246},{\"end\":17417,\"start\":17030},{\"end\":18118,\"start\":17419},{\"end\":18256,\"start\":18120},{\"end\":19436,\"start\":18258},{\"end\":21012,\"start\":19494},{\"end\":21619,\"start\":21014},{\"end\":23198,\"start\":21621},{\"end\":23660,\"start\":23220},{\"end\":24026,\"start\":23662},{\"end\":24515,\"start\":24069},{\"end\":25707,\"start\":24517},{\"end\":26282,\"start\":25709},{\"end\":27216,\"start\":26305},{\"end\":28268,\"start\":27260},{\"end\":28680,\"start\":28270},{\"end\":30657,\"start\":28693},{\"end\":31903,\"start\":30725},{\"end\":32077,\"start\":31905},{\"end\":33177,\"start\":32124},{\"end\":34239,\"start\":33179},{\"end\":34411,\"start\":34256},{\"end\":34991,\"start\":34413},{\"end\":36172,\"start\":34993},{\"end\":36719,\"start\":36174},{\"end\":37367,\"start\":36751},{\"end\":37990,\"start\":37369}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":6154,\"start\":6119},{\"attributes\":{\"id\":\"formula_1\"},\"end\":6597,\"start\":6531},{\"attributes\":{\"id\":\"formula_2\"},\"end\":7739,\"start\":7646},{\"attributes\":{\"id\":\"formula_3\"},\"end\":9693,\"start\":9633},{\"attributes\":{\"id\":\"formula_4\"},\"end\":9933,\"start\":9861},{\"attributes\":{\"id\":\"formula_5\"},\"end\":10235,\"start\":10160},{\"attributes\":{\"id\":\"formula_6\"},\"end\":11062,\"start\":10992},{\"attributes\":{\"id\":\"formula_7\"},\"end\":11329,\"start\":11274}]", "table_ref": "[{\"end\":13605,\"start\":13598},{\"end\":13905,\"start\":13898},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":20177,\"start\":20170},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":22474,\"start\":22418},{\"end\":25057,\"start\":25050},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":26611,\"start\":26604},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":27338,\"start\":27274},{\"end\":27380,\"start\":27373},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":29373,\"start\":29366},{\"end\":29918,\"start\":29911},{\"end\":31161,\"start\":31154},{\"end\":31629,\"start\":31622},{\"attributes\":{\"ref_id\":\"tab_11\"},\"end\":32593,\"start\":32586},{\"end\":34006,\"start\":33999},{\"end\":34703,\"start\":34696}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1753,\"start\":1741},{\"attributes\":{\"n\":\"2\"},\"end\":5353,\"start\":5347},{\"attributes\":{\"n\":\"2.1\"},\"end\":5374,\"start\":5356},{\"attributes\":{\"n\":\"2.2\"},\"end\":5888,\"start\":5866},{\"attributes\":{\"n\":\"2.3\"},\"end\":7170,\"start\":7138},{\"attributes\":{\"n\":\"2.4\"},\"end\":8714,\"start\":8696},{\"attributes\":{\"n\":\"2.5\"},\"end\":12007,\"start\":11986},{\"attributes\":{\"n\":\"3\"},\"end\":13091,\"start\":13073},{\"attributes\":{\"n\":\"3.1\"},\"end\":13266,\"start\":13243},{\"end\":13690,\"start\":13663},{\"attributes\":{\"n\":\"3.2\"},\"end\":14739,\"start\":14717},{\"end\":15215,\"start\":15195},{\"attributes\":{\"n\":\"3.3\"},\"end\":17028,\"start\":17019},{\"attributes\":{\"n\":\"4\"},\"end\":19462,\"start\":19439},{\"attributes\":{\"n\":\"4.1\"},\"end\":19492,\"start\":19465},{\"attributes\":{\"n\":\"4.2\"},\"end\":23218,\"start\":23201},{\"attributes\":{\"n\":\"4.3\"},\"end\":24067,\"start\":24029},{\"attributes\":{\"n\":\"4.4\"},\"end\":26303,\"start\":26285},{\"end\":27245,\"start\":27219},{\"end\":27258,\"start\":27248},{\"attributes\":{\"n\":\"4.5\"},\"end\":28691,\"start\":28683},{\"end\":30702,\"start\":30660},{\"end\":30723,\"start\":30705},{\"end\":32122,\"start\":32080},{\"attributes\":{\"n\":\"5\"},\"end\":34254,\"start\":34242},{\"attributes\":{\"n\":\"6\"},\"end\":36749,\"start\":36722},{\"end\":38002,\"start\":37992},{\"end\":38606,\"start\":38596},{\"end\":40319,\"start\":40310},{\"end\":41173,\"start\":41164},{\"end\":41487,\"start\":41478},{\"end\":42571,\"start\":42562}]", "table": "[{\"end\":40308,\"start\":38900},{\"end\":41476,\"start\":41175},{\"end\":41990,\"start\":41489},{\"end\":42560,\"start\":42094},{\"end\":44020,\"start\":42883}]", "figure_caption": "[{\"end\":38292,\"start\":38004},{\"end\":38594,\"start\":38295},{\"end\":38894,\"start\":38608},{\"end\":38900,\"start\":38897},{\"end\":41162,\"start\":40321},{\"end\":42094,\"start\":41993},{\"end\":42831,\"start\":42573},{\"end\":42883,\"start\":42834}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":2828,\"start\":2820},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":4068,\"start\":4060},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":9160,\"start\":9152},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":23458,\"start\":23450},{\"end\":28998,\"start\":28990},{\"end\":29516,\"start\":29508}]", "bib_author_first_name": "[{\"end\":44936,\"start\":44931},{\"end\":44948,\"start\":44943},{\"end\":44964,\"start\":44956},{\"end\":44978,\"start\":44972},{\"end\":44990,\"start\":44984},{\"end\":45005,\"start\":44997},{\"end\":45741,\"start\":45736},{\"end\":45755,\"start\":45749},{\"end\":45768,\"start\":45764},{\"end\":45781,\"start\":45779},{\"end\":45796,\"start\":45788},{\"end\":45810,\"start\":45802},{\"end\":45822,\"start\":45816},{\"end\":45839,\"start\":45833},{\"end\":45857,\"start\":45850},{\"end\":45868,\"start\":45865},{\"end\":46299,\"start\":46291},{\"end\":46314,\"start\":46308},{\"end\":46324,\"start\":46321},{\"end\":46339,\"start\":46334},{\"end\":46794,\"start\":46790},{\"end\":46810,\"start\":46806},{\"end\":46828,\"start\":46821},{\"end\":46844,\"start\":46837},{\"end\":47465,\"start\":47461},{\"end\":47483,\"start\":47475},{\"end\":47495,\"start\":47491},{\"end\":47509,\"start\":47503},{\"end\":47527,\"start\":47521},{\"end\":47874,\"start\":47865},{\"end\":47892,\"start\":47886},{\"end\":47906,\"start\":47901},{\"end\":47922,\"start\":47915},{\"end\":47936,\"start\":47930},{\"end\":47949,\"start\":47945},{\"end\":47963,\"start\":47959},{\"end\":47990,\"start\":47983},{\"end\":48007,\"start\":47998},{\"end\":48022,\"start\":48016},{\"end\":48039,\"start\":48033},{\"end\":48052,\"start\":48047},{\"end\":48064,\"start\":48058},{\"end\":48088,\"start\":48080},{\"end\":48103,\"start\":48097},{\"end\":48111,\"start\":48109},{\"end\":48124,\"start\":48120},{\"end\":48126,\"start\":48125},{\"end\":48142,\"start\":48132},{\"end\":48157,\"start\":48152},{\"end\":48174,\"start\":48171},{\"end\":48187,\"start\":48181},{\"end\":48189,\"start\":48188},{\"end\":48200,\"start\":48194},{\"end\":48218,\"start\":48213},{\"end\":48230,\"start\":48225},{\"end\":48248,\"start\":48241},{\"end\":48260,\"start\":48257},{\"end\":48277,\"start\":48268},{\"end\":48291,\"start\":48287},{\"end\":48303,\"start\":48297},{\"end\":48316,\"start\":48310},{\"end\":48333,\"start\":48327},{\"end\":48350,\"start\":48344},{\"end\":48362,\"start\":48356},{\"end\":48382,\"start\":48376},{\"end\":48396,\"start\":48391},{\"end\":48408,\"start\":48404},{\"end\":48424,\"start\":48419},{\"end\":48438,\"start\":48432},{\"end\":48450,\"start\":48445},{\"end\":48470,\"start\":48461},{\"end\":50274,\"start\":50266},{\"end\":50276,\"start\":50275},{\"end\":50290,\"start\":50284},{\"end\":50304,\"start\":50297},{\"end\":50317,\"start\":50314},{\"end\":50331,\"start\":50328},{\"end\":50351,\"start\":50345},{\"end\":50372,\"start\":50362},{\"end\":50864,\"start\":50858},{\"end\":50874,\"start\":50870},{\"end\":50882,\"start\":50875},{\"end\":50900,\"start\":50893},{\"end\":50902,\"start\":50901},{\"end\":50913,\"start\":50909},{\"end\":50925,\"start\":50921},{\"end\":50953,\"start\":50947},{\"end\":51422,\"start\":51417},{\"end\":51439,\"start\":51431},{\"end\":51453,\"start\":51447},{\"end\":51467,\"start\":51459},{\"end\":52234,\"start\":52230},{\"end\":52245,\"start\":52240},{\"end\":52795,\"start\":52789},{\"end\":52811,\"start\":52805},{\"end\":52827,\"start\":52822},{\"end\":52847,\"start\":52837},{\"end\":52861,\"start\":52856},{\"end\":52879,\"start\":52873},{\"end\":52889,\"start\":52884},{\"end\":53445,\"start\":53439},{\"end\":53457,\"start\":53451},{\"end\":53467,\"start\":53463},{\"end\":53482,\"start\":53474},{\"end\":53499,\"start\":53492},{\"end\":53941,\"start\":53935},{\"end\":53954,\"start\":53950},{\"end\":53974,\"start\":53964},{\"end\":53989,\"start\":53984},{\"end\":54364,\"start\":54357},{\"end\":54382,\"start\":54374},{\"end\":54395,\"start\":54390},{\"end\":54415,\"start\":54406},{\"end\":54429,\"start\":54424},{\"end\":54448,\"start\":54442},{\"end\":54464,\"start\":54457},{\"end\":54829,\"start\":54822},{\"end\":54846,\"start\":54839},{\"end\":55177,\"start\":55171},{\"end\":55191,\"start\":55185},{\"end\":55204,\"start\":55198},{\"end\":55215,\"start\":55211},{\"end\":55803,\"start\":55795},{\"end\":55821,\"start\":55815},{\"end\":55833,\"start\":55828},{\"end\":55845,\"start\":55839},{\"end\":55856,\"start\":55850},{\"end\":55870,\"start\":55865},{\"end\":55884,\"start\":55877},{\"end\":56456,\"start\":56452},{\"end\":56477,\"start\":56466},{\"end\":56490,\"start\":56485},{\"end\":56908,\"start\":56904},{\"end\":56923,\"start\":56918},{\"end\":57527,\"start\":57524},{\"end\":57551,\"start\":57541},{\"end\":57568,\"start\":57562},{\"end\":57586,\"start\":57579},{\"end\":57601,\"start\":57596},{\"end\":57615,\"start\":57610},{\"end\":57633,\"start\":57625},{\"end\":57648,\"start\":57643},{\"end\":57668,\"start\":57661},{\"end\":57682,\"start\":57677},{\"end\":57697,\"start\":57691},{\"end\":57711,\"start\":57703},{\"end\":57713,\"start\":57712},{\"end\":57730,\"start\":57725},{\"end\":57746,\"start\":57738},{\"end\":57760,\"start\":57754},{\"end\":57771,\"start\":57766},{\"end\":57787,\"start\":57783},{\"end\":57796,\"start\":57792},{\"end\":58435,\"start\":58429},{\"end\":58449,\"start\":58441},{\"end\":58465,\"start\":58457},{\"end\":58980,\"start\":58975},{\"end\":58993,\"start\":58989},{\"end\":59007,\"start\":59003},{\"end\":59580,\"start\":59575},{\"end\":59590,\"start\":59585},{\"end\":59605,\"start\":59597},{\"end\":59617,\"start\":59613},{\"end\":59633,\"start\":59627},{\"end\":59653,\"start\":59649},{\"end\":59666,\"start\":59663},{\"end\":59680,\"start\":59675},{\"end\":59695,\"start\":59690},{\"end\":59711,\"start\":59704},{\"end\":59715,\"start\":59712},{\"end\":59728,\"start\":59722},{\"end\":59742,\"start\":59737},{\"end\":59756,\"start\":59749},{\"end\":59786,\"start\":59782},{\"end\":59805,\"start\":59799},{\"end\":59818,\"start\":59812},{\"end\":59834,\"start\":59826},{\"end\":59846,\"start\":59842},{\"end\":59860,\"start\":59854},{\"end\":59878,\"start\":59873},{\"end\":59893,\"start\":59887},{\"end\":59895,\"start\":59894},{\"end\":59911,\"start\":59907},{\"end\":59922,\"start\":59912},{\"end\":59939,\"start\":59931},{\"end\":60628,\"start\":60623},{\"end\":60641,\"start\":60634},{\"end\":60658,\"start\":60652},{\"end\":61084,\"start\":61080},{\"end\":61096,\"start\":61095},{\"end\":61111,\"start\":61106},{\"end\":61125,\"start\":61119},{\"end\":61375,\"start\":61373},{\"end\":61387,\"start\":61382},{\"end\":61408,\"start\":61400},{\"end\":61427,\"start\":61420},{\"end\":61932,\"start\":61930},{\"end\":61941,\"start\":61937},{\"end\":61958,\"start\":61952},{\"end\":61970,\"start\":61965},{\"end\":61981,\"start\":61977},{\"end\":62654,\"start\":62648},{\"end\":62669,\"start\":62660},{\"end\":62682,\"start\":62674},{\"end\":62694,\"start\":62688},{\"end\":62709,\"start\":62701},{\"end\":62721,\"start\":62715},{\"end\":62733,\"start\":62727},{\"end\":63508,\"start\":63502},{\"end\":63525,\"start\":63522},{\"end\":63534,\"start\":63530},{\"end\":63545,\"start\":63541},{\"end\":63560,\"start\":63555},{\"end\":63568,\"start\":63561},{\"end\":63579,\"start\":63574},{\"end\":63594,\"start\":63588},{\"end\":63608,\"start\":63601},{\"end\":63620,\"start\":63616},{\"end\":63625,\"start\":63621},{\"end\":63636,\"start\":63631},{\"end\":64050,\"start\":64043},{\"end\":64070,\"start\":64061},{\"end\":64380,\"start\":64373},{\"end\":64398,\"start\":64391},{\"end\":64411,\"start\":64406},{\"end\":64426,\"start\":64421},{\"end\":64883,\"start\":64877},{\"end\":64912,\"start\":64905},{\"end\":64923,\"start\":64917},{\"end\":65420,\"start\":65415},{\"end\":65440,\"start\":65435},{\"end\":65450,\"start\":65445},{\"end\":65878,\"start\":65872},{\"end\":65889,\"start\":65883},{\"end\":65900,\"start\":65896},{\"end\":65909,\"start\":65906},{\"end\":65922,\"start\":65915},{\"end\":65933,\"start\":65928},{\"end\":65937,\"start\":65934},{\"end\":65951,\"start\":65944},{\"end\":65961,\"start\":65958},{\"end\":65973,\"start\":65966},{\"end\":66794,\"start\":66789},{\"end\":66807,\"start\":66803},{\"end\":66821,\"start\":66817},{\"end\":66840,\"start\":66831},{\"end\":66852,\"start\":66846},{\"end\":66868,\"start\":66861},{\"end\":66882,\"start\":66877},{\"end\":66892,\"start\":66889},{\"end\":66902,\"start\":66897},{\"end\":66904,\"start\":66903},{\"end\":67288,\"start\":67282},{\"end\":67304,\"start\":67300},{\"end\":67322,\"start\":67312},{\"end\":67337,\"start\":67332},{\"end\":67844,\"start\":67841},{\"end\":67854,\"start\":67850},{\"end\":67872,\"start\":67864},{\"end\":67883,\"start\":67879},{\"end\":68630,\"start\":68623},{\"end\":68642,\"start\":68636},{\"end\":68651,\"start\":68647},{\"end\":68662,\"start\":68657},{\"end\":68666,\"start\":68663},{\"end\":68681,\"start\":68673},{\"end\":68690,\"start\":68687},{\"end\":68702,\"start\":68695},{\"end\":68716,\"start\":68709},{\"end\":69364,\"start\":69357},{\"end\":69380,\"start\":69376},{\"end\":69668,\"start\":69660},{\"end\":69687,\"start\":69683},{\"end\":69701,\"start\":69695},{\"end\":69714,\"start\":69709},{\"end\":69734,\"start\":69727},{\"end\":69746,\"start\":69740},{\"end\":69759,\"start\":69755},{\"end\":70370,\"start\":70362},{\"end\":70392,\"start\":70385},{\"end\":70410,\"start\":70402},{\"end\":70424,\"start\":70420},{\"end\":70434,\"start\":70431},{\"end\":70448,\"start\":70441},{\"end\":70450,\"start\":70449},{\"end\":70466,\"start\":70461},{\"end\":71235,\"start\":71227},{\"end\":71254,\"start\":71250},{\"end\":71269,\"start\":71262},{\"end\":71271,\"start\":71270},{\"end\":71287,\"start\":71282},{\"end\":71298,\"start\":71294},{\"end\":71677,\"start\":71671},{\"end\":71690,\"start\":71684},{\"end\":71704,\"start\":71699},{\"end\":71720,\"start\":71713},{\"end\":71734,\"start\":71727},{\"end\":71749,\"start\":71745},{\"end\":71767,\"start\":71760},{\"end\":71783,\"start\":71777},{\"end\":71798,\"start\":71794},{\"end\":71810,\"start\":71805},{\"end\":71822,\"start\":71816},{\"end\":71835,\"start\":71829},{\"end\":71846,\"start\":71840},{\"end\":71861,\"start\":71856},{\"end\":71884,\"start\":71877},{\"end\":71902,\"start\":71896},{\"end\":71913,\"start\":71908},{\"end\":71934,\"start\":71925},{\"end\":71950,\"start\":71942},{\"end\":71962,\"start\":71958},{\"end\":71984,\"start\":71981},{\"end\":71998,\"start\":71992},{\"end\":72010,\"start\":72005},{\"end\":73132,\"start\":73121},{\"end\":73151,\"start\":73145},{\"end\":73166,\"start\":73159},{\"end\":73177,\"start\":73172},{\"end\":73747,\"start\":73741},{\"end\":73760,\"start\":73756},{\"end\":73777,\"start\":73770},{\"end\":73794,\"start\":73786},{\"end\":73812,\"start\":73807},{\"end\":74251,\"start\":74245},{\"end\":74265,\"start\":74261},{\"end\":74279,\"start\":74275},{\"end\":74293,\"start\":74288},{\"end\":74310,\"start\":74305},{\"end\":74323,\"start\":74318},{\"end\":74325,\"start\":74324},{\"end\":74339,\"start\":74333},{\"end\":74353,\"start\":74348},{\"end\":74721,\"start\":74718},{\"end\":74736,\"start\":74729},{\"end\":74746,\"start\":74744},{\"end\":74760,\"start\":74751},{\"end\":74773,\"start\":74767},{\"end\":74783,\"start\":74779},{\"end\":74785,\"start\":74784},{\"end\":74801,\"start\":74795},{\"end\":74815,\"start\":74809},{\"end\":75203,\"start\":75199},{\"end\":75216,\"start\":75211},{\"end\":75229,\"start\":75223},{\"end\":75245,\"start\":75236},{\"end\":75253,\"start\":75250},{\"end\":75266,\"start\":75260},{\"end\":75617,\"start\":75611},{\"end\":75633,\"start\":75624},{\"end\":75644,\"start\":75638},{\"end\":75655,\"start\":75652},{\"end\":75663,\"start\":75661},{\"end\":75675,\"start\":75670},{\"end\":75685,\"start\":75680},{\"end\":75696,\"start\":75693},{\"end\":75708,\"start\":75704},{\"end\":75717,\"start\":75714},{\"end\":75725,\"start\":75722},{\"end\":75736,\"start\":75733},{\"end\":75745,\"start\":75742}]", "bib_author_last_name": "[{\"end\":44941,\"start\":44937},{\"end\":44954,\"start\":44949},{\"end\":44970,\"start\":44965},{\"end\":44982,\"start\":44979},{\"end\":44995,\"start\":44991},{\"end\":45016,\"start\":45006},{\"end\":45747,\"start\":45742},{\"end\":45762,\"start\":45756},{\"end\":45777,\"start\":45769},{\"end\":45786,\"start\":45782},{\"end\":45800,\"start\":45797},{\"end\":45814,\"start\":45811},{\"end\":45831,\"start\":45823},{\"end\":45848,\"start\":45840},{\"end\":45863,\"start\":45858},{\"end\":45875,\"start\":45869},{\"end\":46306,\"start\":46300},{\"end\":46319,\"start\":46315},{\"end\":46332,\"start\":46325},{\"end\":46345,\"start\":46340},{\"end\":46804,\"start\":46795},{\"end\":46819,\"start\":46811},{\"end\":46835,\"start\":46829},{\"end\":46853,\"start\":46845},{\"end\":47473,\"start\":47466},{\"end\":47489,\"start\":47484},{\"end\":47501,\"start\":47496},{\"end\":47519,\"start\":47510},{\"end\":47532,\"start\":47528},{\"end\":47884,\"start\":47875},{\"end\":47899,\"start\":47893},{\"end\":47913,\"start\":47907},{\"end\":47928,\"start\":47923},{\"end\":47943,\"start\":47937},{\"end\":47957,\"start\":47950},{\"end\":47970,\"start\":47964},{\"end\":47981,\"start\":47972},{\"end\":47996,\"start\":47991},{\"end\":48014,\"start\":48008},{\"end\":48031,\"start\":48023},{\"end\":48045,\"start\":48040},{\"end\":48056,\"start\":48053},{\"end\":48078,\"start\":48065},{\"end\":48095,\"start\":48089},{\"end\":48107,\"start\":48104},{\"end\":48118,\"start\":48112},{\"end\":48130,\"start\":48127},{\"end\":48150,\"start\":48143},{\"end\":48169,\"start\":48158},{\"end\":48179,\"start\":48175},{\"end\":48192,\"start\":48190},{\"end\":48211,\"start\":48201},{\"end\":48223,\"start\":48219},{\"end\":48239,\"start\":48231},{\"end\":48255,\"start\":48249},{\"end\":48266,\"start\":48261},{\"end\":48285,\"start\":48278},{\"end\":48295,\"start\":48292},{\"end\":48308,\"start\":48304},{\"end\":48325,\"start\":48317},{\"end\":48342,\"start\":48334},{\"end\":48354,\"start\":48351},{\"end\":48374,\"start\":48363},{\"end\":48389,\"start\":48383},{\"end\":48402,\"start\":48397},{\"end\":48417,\"start\":48409},{\"end\":48430,\"start\":48425},{\"end\":48443,\"start\":48439},{\"end\":48459,\"start\":48451},{\"end\":48475,\"start\":48471},{\"end\":48480,\"start\":48477},{\"end\":50282,\"start\":50277},{\"end\":50295,\"start\":50291},{\"end\":50312,\"start\":50305},{\"end\":50326,\"start\":50318},{\"end\":50343,\"start\":50332},{\"end\":50360,\"start\":50352},{\"end\":50381,\"start\":50373},{\"end\":50868,\"start\":50865},{\"end\":50891,\"start\":50883},{\"end\":50907,\"start\":50903},{\"end\":50919,\"start\":50914},{\"end\":50945,\"start\":50926},{\"end\":50959,\"start\":50954},{\"end\":50964,\"start\":50961},{\"end\":51429,\"start\":51423},{\"end\":51445,\"start\":51440},{\"end\":51457,\"start\":51454},{\"end\":51477,\"start\":51468},{\"end\":52238,\"start\":52235},{\"end\":52252,\"start\":52246},{\"end\":52803,\"start\":52796},{\"end\":52820,\"start\":52812},{\"end\":52835,\"start\":52828},{\"end\":52854,\"start\":52848},{\"end\":52871,\"start\":52862},{\"end\":52882,\"start\":52880},{\"end\":52902,\"start\":52890},{\"end\":53449,\"start\":53446},{\"end\":53461,\"start\":53458},{\"end\":53472,\"start\":53468},{\"end\":53490,\"start\":53483},{\"end\":53505,\"start\":53500},{\"end\":53948,\"start\":53942},{\"end\":53962,\"start\":53955},{\"end\":53982,\"start\":53975},{\"end\":53996,\"start\":53990},{\"end\":54372,\"start\":54365},{\"end\":54388,\"start\":54383},{\"end\":54404,\"start\":54396},{\"end\":54422,\"start\":54416},{\"end\":54440,\"start\":54430},{\"end\":54455,\"start\":54449},{\"end\":54470,\"start\":54465},{\"end\":54837,\"start\":54830},{\"end\":54852,\"start\":54847},{\"end\":55183,\"start\":55178},{\"end\":55196,\"start\":55192},{\"end\":55209,\"start\":55205},{\"end\":55227,\"start\":55216},{\"end\":55813,\"start\":55804},{\"end\":55826,\"start\":55822},{\"end\":55837,\"start\":55834},{\"end\":55848,\"start\":55846},{\"end\":55863,\"start\":55857},{\"end\":55875,\"start\":55871},{\"end\":55888,\"start\":55885},{\"end\":56464,\"start\":56457},{\"end\":56483,\"start\":56478},{\"end\":56498,\"start\":56491},{\"end\":56916,\"start\":56909},{\"end\":56931,\"start\":56924},{\"end\":57539,\"start\":57528},{\"end\":57560,\"start\":57552},{\"end\":57577,\"start\":57569},{\"end\":57594,\"start\":57587},{\"end\":57608,\"start\":57602},{\"end\":57623,\"start\":57616},{\"end\":57641,\"start\":57634},{\"end\":57659,\"start\":57649},{\"end\":57675,\"start\":57669},{\"end\":57689,\"start\":57683},{\"end\":57701,\"start\":57698},{\"end\":57723,\"start\":57714},{\"end\":57736,\"start\":57731},{\"end\":57752,\"start\":57747},{\"end\":57764,\"start\":57761},{\"end\":57781,\"start\":57772},{\"end\":57790,\"start\":57788},{\"end\":57803,\"start\":57797},{\"end\":58439,\"start\":58436},{\"end\":58455,\"start\":58450},{\"end\":58475,\"start\":58466},{\"end\":58987,\"start\":58981},{\"end\":59001,\"start\":58994},{\"end\":59016,\"start\":59008},{\"end\":59583,\"start\":59581},{\"end\":59595,\"start\":59591},{\"end\":59611,\"start\":59606},{\"end\":59625,\"start\":59618},{\"end\":59647,\"start\":59634},{\"end\":59661,\"start\":59654},{\"end\":59673,\"start\":59667},{\"end\":59688,\"start\":59681},{\"end\":59702,\"start\":59696},{\"end\":59720,\"start\":59716},{\"end\":59735,\"start\":59729},{\"end\":59747,\"start\":59743},{\"end\":59780,\"start\":59757},{\"end\":59797,\"start\":59787},{\"end\":59810,\"start\":59806},{\"end\":59824,\"start\":59819},{\"end\":59840,\"start\":59835},{\"end\":59852,\"start\":59847},{\"end\":59871,\"start\":59861},{\"end\":59885,\"start\":59879},{\"end\":59905,\"start\":59896},{\"end\":59929,\"start\":59923},{\"end\":59945,\"start\":59940},{\"end\":60632,\"start\":60629},{\"end\":60650,\"start\":60642},{\"end\":60664,\"start\":60659},{\"end\":61093,\"start\":61085},{\"end\":61104,\"start\":61097},{\"end\":61117,\"start\":61112},{\"end\":61129,\"start\":61126},{\"end\":61136,\"start\":61131},{\"end\":61380,\"start\":61376},{\"end\":61398,\"start\":61388},{\"end\":61418,\"start\":61409},{\"end\":61435,\"start\":61428},{\"end\":61935,\"start\":61933},{\"end\":61950,\"start\":61942},{\"end\":61963,\"start\":61959},{\"end\":61975,\"start\":61971},{\"end\":61990,\"start\":61982},{\"end\":62658,\"start\":62655},{\"end\":62672,\"start\":62670},{\"end\":62686,\"start\":62683},{\"end\":62699,\"start\":62695},{\"end\":62713,\"start\":62710},{\"end\":62725,\"start\":62722},{\"end\":62738,\"start\":62734},{\"end\":63520,\"start\":63509},{\"end\":63528,\"start\":63526},{\"end\":63539,\"start\":63535},{\"end\":63553,\"start\":63546},{\"end\":63572,\"start\":63569},{\"end\":63586,\"start\":63580},{\"end\":63599,\"start\":63595},{\"end\":63614,\"start\":63609},{\"end\":63629,\"start\":63626},{\"end\":63644,\"start\":63637},{\"end\":64059,\"start\":64051},{\"end\":64074,\"start\":64071},{\"end\":64389,\"start\":64381},{\"end\":64404,\"start\":64399},{\"end\":64419,\"start\":64412},{\"end\":64430,\"start\":64427},{\"end\":64903,\"start\":64884},{\"end\":64915,\"start\":64913},{\"end\":64933,\"start\":64924},{\"end\":65433,\"start\":65421},{\"end\":65443,\"start\":65441},{\"end\":65458,\"start\":65451},{\"end\":65881,\"start\":65879},{\"end\":65894,\"start\":65890},{\"end\":65904,\"start\":65901},{\"end\":65913,\"start\":65910},{\"end\":65926,\"start\":65923},{\"end\":65942,\"start\":65938},{\"end\":65956,\"start\":65952},{\"end\":65964,\"start\":65962},{\"end\":65978,\"start\":65974},{\"end\":66801,\"start\":66795},{\"end\":66815,\"start\":66808},{\"end\":66829,\"start\":66822},{\"end\":66844,\"start\":66841},{\"end\":66859,\"start\":66853},{\"end\":66875,\"start\":66869},{\"end\":66887,\"start\":66883},{\"end\":66895,\"start\":66893},{\"end\":66908,\"start\":66905},{\"end\":67298,\"start\":67289},{\"end\":67310,\"start\":67305},{\"end\":67330,\"start\":67323},{\"end\":67343,\"start\":67338},{\"end\":67848,\"start\":67845},{\"end\":67862,\"start\":67855},{\"end\":67877,\"start\":67873},{\"end\":67890,\"start\":67884},{\"end\":67901,\"start\":67892},{\"end\":68634,\"start\":68631},{\"end\":68645,\"start\":68643},{\"end\":68655,\"start\":68652},{\"end\":68671,\"start\":68667},{\"end\":68685,\"start\":68682},{\"end\":68693,\"start\":68691},{\"end\":68707,\"start\":68703},{\"end\":68720,\"start\":68717},{\"end\":69374,\"start\":69365},{\"end\":69389,\"start\":69381},{\"end\":69681,\"start\":69669},{\"end\":69693,\"start\":69688},{\"end\":69707,\"start\":69702},{\"end\":69725,\"start\":69715},{\"end\":69738,\"start\":69735},{\"end\":69753,\"start\":69747},{\"end\":69771,\"start\":69760},{\"end\":70383,\"start\":70371},{\"end\":70400,\"start\":70393},{\"end\":70418,\"start\":70411},{\"end\":70429,\"start\":70425},{\"end\":70439,\"start\":70435},{\"end\":70459,\"start\":70451},{\"end\":70476,\"start\":70467},{\"end\":71248,\"start\":71236},{\"end\":71260,\"start\":71255},{\"end\":71280,\"start\":71272},{\"end\":71292,\"start\":71288},{\"end\":71307,\"start\":71299},{\"end\":71682,\"start\":71678},{\"end\":71697,\"start\":71691},{\"end\":71711,\"start\":71705},{\"end\":71725,\"start\":71721},{\"end\":71743,\"start\":71735},{\"end\":71758,\"start\":71750},{\"end\":71775,\"start\":71768},{\"end\":71792,\"start\":71784},{\"end\":71803,\"start\":71799},{\"end\":71814,\"start\":71811},{\"end\":71827,\"start\":71823},{\"end\":71838,\"start\":71836},{\"end\":71854,\"start\":71847},{\"end\":71875,\"start\":71862},{\"end\":71894,\"start\":71885},{\"end\":71906,\"start\":71903},{\"end\":71923,\"start\":71914},{\"end\":71940,\"start\":71935},{\"end\":71956,\"start\":71951},{\"end\":71968,\"start\":71963},{\"end\":71979,\"start\":71970},{\"end\":71990,\"start\":71985},{\"end\":72003,\"start\":71999},{\"end\":72017,\"start\":72011},{\"end\":72023,\"start\":72019},{\"end\":73143,\"start\":73133},{\"end\":73157,\"start\":73152},{\"end\":73170,\"start\":73167},{\"end\":73182,\"start\":73178},{\"end\":73754,\"start\":73748},{\"end\":73768,\"start\":73761},{\"end\":73784,\"start\":73778},{\"end\":73805,\"start\":73795},{\"end\":73821,\"start\":73813},{\"end\":74259,\"start\":74252},{\"end\":74273,\"start\":74266},{\"end\":74286,\"start\":74280},{\"end\":74303,\"start\":74294},{\"end\":74316,\"start\":74311},{\"end\":74331,\"start\":74326},{\"end\":74346,\"start\":74340},{\"end\":74364,\"start\":74354},{\"end\":74727,\"start\":74722},{\"end\":74742,\"start\":74737},{\"end\":74749,\"start\":74747},{\"end\":74765,\"start\":74761},{\"end\":74777,\"start\":74774},{\"end\":74793,\"start\":74786},{\"end\":74807,\"start\":74802},{\"end\":74824,\"start\":74816},{\"end\":75209,\"start\":75204},{\"end\":75221,\"start\":75217},{\"end\":75234,\"start\":75230},{\"end\":75248,\"start\":75246},{\"end\":75258,\"start\":75254},{\"end\":75271,\"start\":75267},{\"end\":75622,\"start\":75618},{\"end\":75636,\"start\":75634},{\"end\":75650,\"start\":75645},{\"end\":75659,\"start\":75656},{\"end\":75668,\"start\":75664},{\"end\":75678,\"start\":75676},{\"end\":75691,\"start\":75686},{\"end\":75702,\"start\":75697},{\"end\":75712,\"start\":75709},{\"end\":75720,\"start\":75718},{\"end\":75731,\"start\":75726},{\"end\":75740,\"start\":75737},{\"end\":75750,\"start\":75746}]", "bib_entry": "[{\"attributes\":{\"doi\":\"10.18653/v1/2021.naacl-main.46\",\"id\":\"b0\",\"matched_paper_id\":225040672},\"end\":45667,\"start\":44874},{\"attributes\":{\"doi\":\"10.48550/arXiv.1611.09268\",\"id\":\"b1\"},\"end\":46232,\"start\":45669},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":6401679},\"end\":46721,\"start\":46234},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":250340449},\"end\":47389,\"start\":46723},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":16394033},\"end\":47861,\"start\":47391},{\"attributes\":{\"id\":\"b5\"},\"end\":50164,\"start\":47863},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":212657414},\"end\":50805,\"start\":50166},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":248863311},\"end\":51333,\"start\":50807},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":52967399},\"end\":52145,\"start\":51335},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":236987190},\"end\":52734,\"start\":52147},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":202718954},\"end\":53388,\"start\":52736},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":225626501},\"end\":53831,\"start\":53390},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":210063976},\"end\":54287,\"start\":53833},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":249097975},\"end\":54750,\"start\":54289},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":227746078},\"end\":55079,\"start\":54752},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":26501419},\"end\":55733,\"start\":55081},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":215737187},\"end\":56396,\"start\":55735},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":220302658},\"end\":56807,\"start\":56398},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":216553223},\"end\":57458,\"start\":56809},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":86611921},\"end\":58356,\"start\":57460},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":173990818},\"end\":58916,\"start\":58358},{\"attributes\":{\"id\":\"b21\"},\"end\":59461,\"start\":58918},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":246527904},\"end\":60562,\"start\":59463},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":222310837},\"end\":60963,\"start\":60564},{\"attributes\":{\"id\":\"b24\"},\"end\":61017,\"start\":60965},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":245018271},\"end\":61371,\"start\":61019},{\"attributes\":{\"id\":\"b26\"},\"end\":61842,\"start\":61373},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":231704318},\"end\":62579,\"start\":61844},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":221802772},\"end\":63500,\"start\":62581},{\"attributes\":{\"id\":\"b29\"},\"end\":64041,\"start\":63502},{\"attributes\":{\"id\":\"b30\"},\"end\":64308,\"start\":64043},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":212725651},\"end\":64794,\"start\":64310},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":222178252},\"end\":65413,\"start\":64796},{\"attributes\":{\"id\":\"b33\"},\"end\":65765,\"start\":65415},{\"attributes\":{\"id\":\"b34\"},\"end\":66704,\"start\":65767},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":204838007},\"end\":67219,\"start\":66706},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":11816014},\"end\":67788,\"start\":67221},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":245144844},\"end\":68533,\"start\":67790},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":238857121},\"end\":69250,\"start\":68535},{\"attributes\":{\"id\":\"b39\"},\"end\":69594,\"start\":69252},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":248218489},\"end\":70283,\"start\":69596},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":230437591},\"end\":71130,\"start\":70285},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":235390519},\"end\":71602,\"start\":71132},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":239009562},\"end\":73060,\"start\":71604},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":237562875},\"end\":73649,\"start\":73062},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":233296016},\"end\":74216,\"start\":73651},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":13756489},\"end\":74631,\"start\":74218},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":220302524},\"end\":75142,\"start\":74633},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":238419331},\"end\":75522,\"start\":75144},{\"attributes\":{\"id\":\"b49\"},\"end\":76360,\"start\":75524}]", "bib_title": "[{\"end\":44929,\"start\":44874},{\"end\":46289,\"start\":46234},{\"end\":46788,\"start\":46723},{\"end\":47459,\"start\":47391},{\"end\":50264,\"start\":50166},{\"end\":50856,\"start\":50807},{\"end\":51415,\"start\":51335},{\"end\":52228,\"start\":52147},{\"end\":52787,\"start\":52736},{\"end\":53437,\"start\":53390},{\"end\":53933,\"start\":53833},{\"end\":54355,\"start\":54289},{\"end\":54820,\"start\":54752},{\"end\":55169,\"start\":55081},{\"end\":55793,\"start\":55735},{\"end\":56450,\"start\":56398},{\"end\":56902,\"start\":56809},{\"end\":57522,\"start\":57460},{\"end\":58427,\"start\":58358},{\"end\":58973,\"start\":58918},{\"end\":59573,\"start\":59463},{\"end\":60621,\"start\":60564},{\"end\":61078,\"start\":61019},{\"end\":61928,\"start\":61844},{\"end\":62646,\"start\":62581},{\"end\":64371,\"start\":64310},{\"end\":64875,\"start\":64796},{\"end\":65870,\"start\":65767},{\"end\":66787,\"start\":66706},{\"end\":67280,\"start\":67221},{\"end\":67839,\"start\":67790},{\"end\":68621,\"start\":68535},{\"end\":69658,\"start\":69596},{\"end\":70360,\"start\":70285},{\"end\":71225,\"start\":71132},{\"end\":71669,\"start\":71604},{\"end\":73119,\"start\":73062},{\"end\":73739,\"start\":73651},{\"end\":74243,\"start\":74218},{\"end\":74716,\"start\":74633},{\"end\":75197,\"start\":75144},{\"end\":75609,\"start\":75524}]", "bib_author": "[{\"end\":44943,\"start\":44931},{\"end\":44956,\"start\":44943},{\"end\":44972,\"start\":44956},{\"end\":44984,\"start\":44972},{\"end\":44997,\"start\":44984},{\"end\":45018,\"start\":44997},{\"end\":45749,\"start\":45736},{\"end\":45764,\"start\":45749},{\"end\":45779,\"start\":45764},{\"end\":45788,\"start\":45779},{\"end\":45802,\"start\":45788},{\"end\":45816,\"start\":45802},{\"end\":45833,\"start\":45816},{\"end\":45850,\"start\":45833},{\"end\":45865,\"start\":45850},{\"end\":45877,\"start\":45865},{\"end\":46308,\"start\":46291},{\"end\":46321,\"start\":46308},{\"end\":46334,\"start\":46321},{\"end\":46347,\"start\":46334},{\"end\":46806,\"start\":46790},{\"end\":46821,\"start\":46806},{\"end\":46837,\"start\":46821},{\"end\":46855,\"start\":46837},{\"end\":47475,\"start\":47461},{\"end\":47491,\"start\":47475},{\"end\":47503,\"start\":47491},{\"end\":47521,\"start\":47503},{\"end\":47534,\"start\":47521},{\"end\":47886,\"start\":47865},{\"end\":47901,\"start\":47886},{\"end\":47915,\"start\":47901},{\"end\":47930,\"start\":47915},{\"end\":47945,\"start\":47930},{\"end\":47959,\"start\":47945},{\"end\":47972,\"start\":47959},{\"end\":47983,\"start\":47972},{\"end\":47998,\"start\":47983},{\"end\":48016,\"start\":47998},{\"end\":48033,\"start\":48016},{\"end\":48047,\"start\":48033},{\"end\":48058,\"start\":48047},{\"end\":48080,\"start\":48058},{\"end\":48097,\"start\":48080},{\"end\":48109,\"start\":48097},{\"end\":48120,\"start\":48109},{\"end\":48132,\"start\":48120},{\"end\":48152,\"start\":48132},{\"end\":48171,\"start\":48152},{\"end\":48181,\"start\":48171},{\"end\":48194,\"start\":48181},{\"end\":48213,\"start\":48194},{\"end\":48225,\"start\":48213},{\"end\":48241,\"start\":48225},{\"end\":48257,\"start\":48241},{\"end\":48268,\"start\":48257},{\"end\":48287,\"start\":48268},{\"end\":48297,\"start\":48287},{\"end\":48310,\"start\":48297},{\"end\":48327,\"start\":48310},{\"end\":48344,\"start\":48327},{\"end\":48356,\"start\":48344},{\"end\":48376,\"start\":48356},{\"end\":48391,\"start\":48376},{\"end\":48404,\"start\":48391},{\"end\":48419,\"start\":48404},{\"end\":48432,\"start\":48419},{\"end\":48445,\"start\":48432},{\"end\":48461,\"start\":48445},{\"end\":48477,\"start\":48461},{\"end\":48482,\"start\":48477},{\"end\":50284,\"start\":50266},{\"end\":50297,\"start\":50284},{\"end\":50314,\"start\":50297},{\"end\":50328,\"start\":50314},{\"end\":50345,\"start\":50328},{\"end\":50362,\"start\":50345},{\"end\":50383,\"start\":50362},{\"end\":50870,\"start\":50858},{\"end\":50893,\"start\":50870},{\"end\":50909,\"start\":50893},{\"end\":50921,\"start\":50909},{\"end\":50947,\"start\":50921},{\"end\":50961,\"start\":50947},{\"end\":50966,\"start\":50961},{\"end\":51431,\"start\":51417},{\"end\":51447,\"start\":51431},{\"end\":51459,\"start\":51447},{\"end\":51479,\"start\":51459},{\"end\":52240,\"start\":52230},{\"end\":52254,\"start\":52240},{\"end\":52805,\"start\":52789},{\"end\":52822,\"start\":52805},{\"end\":52837,\"start\":52822},{\"end\":52856,\"start\":52837},{\"end\":52873,\"start\":52856},{\"end\":52884,\"start\":52873},{\"end\":52904,\"start\":52884},{\"end\":53451,\"start\":53439},{\"end\":53463,\"start\":53451},{\"end\":53474,\"start\":53463},{\"end\":53492,\"start\":53474},{\"end\":53507,\"start\":53492},{\"end\":53950,\"start\":53935},{\"end\":53964,\"start\":53950},{\"end\":53984,\"start\":53964},{\"end\":53998,\"start\":53984},{\"end\":54374,\"start\":54357},{\"end\":54390,\"start\":54374},{\"end\":54406,\"start\":54390},{\"end\":54424,\"start\":54406},{\"end\":54442,\"start\":54424},{\"end\":54457,\"start\":54442},{\"end\":54472,\"start\":54457},{\"end\":54839,\"start\":54822},{\"end\":54854,\"start\":54839},{\"end\":55185,\"start\":55171},{\"end\":55198,\"start\":55185},{\"end\":55211,\"start\":55198},{\"end\":55229,\"start\":55211},{\"end\":55815,\"start\":55795},{\"end\":55828,\"start\":55815},{\"end\":55839,\"start\":55828},{\"end\":55850,\"start\":55839},{\"end\":55865,\"start\":55850},{\"end\":55877,\"start\":55865},{\"end\":55890,\"start\":55877},{\"end\":56466,\"start\":56452},{\"end\":56485,\"start\":56466},{\"end\":56500,\"start\":56485},{\"end\":56918,\"start\":56904},{\"end\":56933,\"start\":56918},{\"end\":57541,\"start\":57524},{\"end\":57562,\"start\":57541},{\"end\":57579,\"start\":57562},{\"end\":57596,\"start\":57579},{\"end\":57610,\"start\":57596},{\"end\":57625,\"start\":57610},{\"end\":57643,\"start\":57625},{\"end\":57661,\"start\":57643},{\"end\":57677,\"start\":57661},{\"end\":57691,\"start\":57677},{\"end\":57703,\"start\":57691},{\"end\":57725,\"start\":57703},{\"end\":57738,\"start\":57725},{\"end\":57754,\"start\":57738},{\"end\":57766,\"start\":57754},{\"end\":57783,\"start\":57766},{\"end\":57792,\"start\":57783},{\"end\":57805,\"start\":57792},{\"end\":58441,\"start\":58429},{\"end\":58457,\"start\":58441},{\"end\":58477,\"start\":58457},{\"end\":58989,\"start\":58975},{\"end\":59003,\"start\":58989},{\"end\":59018,\"start\":59003},{\"end\":59585,\"start\":59575},{\"end\":59597,\"start\":59585},{\"end\":59613,\"start\":59597},{\"end\":59627,\"start\":59613},{\"end\":59649,\"start\":59627},{\"end\":59663,\"start\":59649},{\"end\":59675,\"start\":59663},{\"end\":59690,\"start\":59675},{\"end\":59704,\"start\":59690},{\"end\":59722,\"start\":59704},{\"end\":59737,\"start\":59722},{\"end\":59749,\"start\":59737},{\"end\":59782,\"start\":59749},{\"end\":59799,\"start\":59782},{\"end\":59812,\"start\":59799},{\"end\":59826,\"start\":59812},{\"end\":59842,\"start\":59826},{\"end\":59854,\"start\":59842},{\"end\":59873,\"start\":59854},{\"end\":59887,\"start\":59873},{\"end\":59907,\"start\":59887},{\"end\":59931,\"start\":59907},{\"end\":59947,\"start\":59931},{\"end\":60634,\"start\":60623},{\"end\":60652,\"start\":60634},{\"end\":60666,\"start\":60652},{\"end\":61095,\"start\":61080},{\"end\":61106,\"start\":61095},{\"end\":61119,\"start\":61106},{\"end\":61131,\"start\":61119},{\"end\":61138,\"start\":61131},{\"end\":61382,\"start\":61373},{\"end\":61400,\"start\":61382},{\"end\":61420,\"start\":61400},{\"end\":61437,\"start\":61420},{\"end\":61937,\"start\":61930},{\"end\":61952,\"start\":61937},{\"end\":61965,\"start\":61952},{\"end\":61977,\"start\":61965},{\"end\":61992,\"start\":61977},{\"end\":62660,\"start\":62648},{\"end\":62674,\"start\":62660},{\"end\":62688,\"start\":62674},{\"end\":62701,\"start\":62688},{\"end\":62715,\"start\":62701},{\"end\":62727,\"start\":62715},{\"end\":62740,\"start\":62727},{\"end\":63522,\"start\":63502},{\"end\":63530,\"start\":63522},{\"end\":63541,\"start\":63530},{\"end\":63555,\"start\":63541},{\"end\":63574,\"start\":63555},{\"end\":63588,\"start\":63574},{\"end\":63601,\"start\":63588},{\"end\":63616,\"start\":63601},{\"end\":63631,\"start\":63616},{\"end\":63646,\"start\":63631},{\"end\":64061,\"start\":64043},{\"end\":64076,\"start\":64061},{\"end\":64391,\"start\":64373},{\"end\":64406,\"start\":64391},{\"end\":64421,\"start\":64406},{\"end\":64432,\"start\":64421},{\"end\":64905,\"start\":64877},{\"end\":64917,\"start\":64905},{\"end\":64935,\"start\":64917},{\"end\":65435,\"start\":65415},{\"end\":65445,\"start\":65435},{\"end\":65460,\"start\":65445},{\"end\":65883,\"start\":65872},{\"end\":65896,\"start\":65883},{\"end\":65906,\"start\":65896},{\"end\":65915,\"start\":65906},{\"end\":65928,\"start\":65915},{\"end\":65944,\"start\":65928},{\"end\":65958,\"start\":65944},{\"end\":65966,\"start\":65958},{\"end\":65980,\"start\":65966},{\"end\":66803,\"start\":66789},{\"end\":66817,\"start\":66803},{\"end\":66831,\"start\":66817},{\"end\":66846,\"start\":66831},{\"end\":66861,\"start\":66846},{\"end\":66877,\"start\":66861},{\"end\":66889,\"start\":66877},{\"end\":66897,\"start\":66889},{\"end\":66910,\"start\":66897},{\"end\":67300,\"start\":67282},{\"end\":67312,\"start\":67300},{\"end\":67332,\"start\":67312},{\"end\":67345,\"start\":67332},{\"end\":67850,\"start\":67841},{\"end\":67864,\"start\":67850},{\"end\":67879,\"start\":67864},{\"end\":67892,\"start\":67879},{\"end\":67903,\"start\":67892},{\"end\":68636,\"start\":68623},{\"end\":68647,\"start\":68636},{\"end\":68657,\"start\":68647},{\"end\":68673,\"start\":68657},{\"end\":68687,\"start\":68673},{\"end\":68695,\"start\":68687},{\"end\":68709,\"start\":68695},{\"end\":68722,\"start\":68709},{\"end\":69376,\"start\":69357},{\"end\":69391,\"start\":69376},{\"end\":69683,\"start\":69660},{\"end\":69695,\"start\":69683},{\"end\":69709,\"start\":69695},{\"end\":69727,\"start\":69709},{\"end\":69740,\"start\":69727},{\"end\":69755,\"start\":69740},{\"end\":69773,\"start\":69755},{\"end\":70385,\"start\":70362},{\"end\":70402,\"start\":70385},{\"end\":70420,\"start\":70402},{\"end\":70431,\"start\":70420},{\"end\":70441,\"start\":70431},{\"end\":70461,\"start\":70441},{\"end\":70478,\"start\":70461},{\"end\":71250,\"start\":71227},{\"end\":71262,\"start\":71250},{\"end\":71282,\"start\":71262},{\"end\":71294,\"start\":71282},{\"end\":71309,\"start\":71294},{\"end\":71684,\"start\":71671},{\"end\":71699,\"start\":71684},{\"end\":71713,\"start\":71699},{\"end\":71727,\"start\":71713},{\"end\":71745,\"start\":71727},{\"end\":71760,\"start\":71745},{\"end\":71777,\"start\":71760},{\"end\":71794,\"start\":71777},{\"end\":71805,\"start\":71794},{\"end\":71816,\"start\":71805},{\"end\":71829,\"start\":71816},{\"end\":71840,\"start\":71829},{\"end\":71856,\"start\":71840},{\"end\":71877,\"start\":71856},{\"end\":71896,\"start\":71877},{\"end\":71908,\"start\":71896},{\"end\":71925,\"start\":71908},{\"end\":71942,\"start\":71925},{\"end\":71958,\"start\":71942},{\"end\":71970,\"start\":71958},{\"end\":71981,\"start\":71970},{\"end\":71992,\"start\":71981},{\"end\":72005,\"start\":71992},{\"end\":72019,\"start\":72005},{\"end\":72025,\"start\":72019},{\"end\":73145,\"start\":73121},{\"end\":73159,\"start\":73145},{\"end\":73172,\"start\":73159},{\"end\":73184,\"start\":73172},{\"end\":73756,\"start\":73741},{\"end\":73770,\"start\":73756},{\"end\":73786,\"start\":73770},{\"end\":73807,\"start\":73786},{\"end\":73823,\"start\":73807},{\"end\":74261,\"start\":74245},{\"end\":74275,\"start\":74261},{\"end\":74288,\"start\":74275},{\"end\":74305,\"start\":74288},{\"end\":74318,\"start\":74305},{\"end\":74333,\"start\":74318},{\"end\":74348,\"start\":74333},{\"end\":74366,\"start\":74348},{\"end\":74729,\"start\":74718},{\"end\":74744,\"start\":74729},{\"end\":74751,\"start\":74744},{\"end\":74767,\"start\":74751},{\"end\":74779,\"start\":74767},{\"end\":74795,\"start\":74779},{\"end\":74809,\"start\":74795},{\"end\":74826,\"start\":74809},{\"end\":75211,\"start\":75199},{\"end\":75223,\"start\":75211},{\"end\":75236,\"start\":75223},{\"end\":75250,\"start\":75236},{\"end\":75260,\"start\":75250},{\"end\":75273,\"start\":75260},{\"end\":75624,\"start\":75611},{\"end\":75638,\"start\":75624},{\"end\":75652,\"start\":75638},{\"end\":75661,\"start\":75652},{\"end\":75670,\"start\":75661},{\"end\":75680,\"start\":75670},{\"end\":75693,\"start\":75680},{\"end\":75704,\"start\":75693},{\"end\":75714,\"start\":75704},{\"end\":75722,\"start\":75714},{\"end\":75733,\"start\":75722},{\"end\":75742,\"start\":75733},{\"end\":75752,\"start\":75742}]", "bib_venue": "[{\"end\":45319,\"start\":45192},{\"end\":46506,\"start\":46435},{\"end\":47087,\"start\":46991},{\"end\":51089,\"start\":51036},{\"end\":51770,\"start\":51643},{\"end\":52444,\"start\":52372},{\"end\":53081,\"start\":53011},{\"end\":53630,\"start\":53577},{\"end\":55410,\"start\":55338},{\"end\":56080,\"start\":56009},{\"end\":57165,\"start\":57069},{\"end\":58658,\"start\":58586},{\"end\":59208,\"start\":59137},{\"end\":62248,\"start\":62143},{\"end\":63080,\"start\":62933},{\"end\":65125,\"start\":65054},{\"end\":66282,\"start\":66155},{\"end\":67524,\"start\":67453},{\"end\":68205,\"start\":68078},{\"end\":68912,\"start\":68841},{\"end\":69957,\"start\":69886},{\"end\":72321,\"start\":72261},{\"end\":73374,\"start\":73303},{\"end\":75942,\"start\":75870},{\"end\":45190,\"start\":45048},{\"end\":45734,\"start\":45669},{\"end\":46433,\"start\":46347},{\"end\":46989,\"start\":46878},{\"end\":47609,\"start\":47560},{\"end\":50464,\"start\":50403},{\"end\":51034,\"start\":50966},{\"end\":51641,\"start\":51499},{\"end\":52370,\"start\":52283},{\"end\":53009,\"start\":52924},{\"end\":53575,\"start\":53507},{\"end\":54050,\"start\":53998},{\"end\":54513,\"start\":54472},{\"end\":54906,\"start\":54854},{\"end\":55336,\"start\":55249},{\"end\":56007,\"start\":55921},{\"end\":56581,\"start\":56520},{\"end\":57067,\"start\":56956},{\"end\":57885,\"start\":57825},{\"end\":58584,\"start\":58497},{\"end\":59135,\"start\":59049},{\"end\":59977,\"start\":59970},{\"end\":60748,\"start\":60699},{\"end\":61187,\"start\":61138},{\"end\":61585,\"start\":61457},{\"end\":62141,\"start\":62021},{\"end\":62931,\"start\":62769},{\"end\":63739,\"start\":63687},{\"end\":64145,\"start\":64117},{\"end\":64535,\"start\":64466},{\"end\":65052,\"start\":64966},{\"end\":65559,\"start\":65501},{\"end\":66153,\"start\":66011},{\"end\":66946,\"start\":66910},{\"end\":67451,\"start\":67365},{\"end\":68076,\"start\":67934},{\"end\":68839,\"start\":68753},{\"end\":69355,\"start\":69252},{\"end\":69884,\"start\":69798},{\"end\":70686,\"start\":70507},{\"end\":71358,\"start\":71309},{\"end\":72077,\"start\":72025},{\"end\":73301,\"start\":73215},{\"end\":73917,\"start\":73823},{\"end\":74415,\"start\":74366},{\"end\":74878,\"start\":74826},{\"end\":75325,\"start\":75273},{\"end\":75868,\"start\":75781}]"}}}, "year": 2023, "month": 12, "day": 17}