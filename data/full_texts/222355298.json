{"id": 222355298, "updated": "2022-01-21 04:25:44.604", "metadata": {"title": "Learning Fair and Transferable Representations with Theoretical Guarantees", "authors": "[{\"middle\":[],\"last\":\"Oneto\",\"first\":\"Luca\"},{\"middle\":[],\"last\":\"Donini\",\"first\":\"Michele\"},{\"middle\":[],\"last\":\"Pontil\",\"first\":\"Massimiliano\"},{\"middle\":[],\"last\":\"Maurer\",\"first\":\"Andreas\"}]", "venue": "2020 IEEE 7th International Conference on Data Science and Advanced Analytics (DSAA)", "journal": "2020 IEEE 7th International Conference on Data Science and Advanced Analytics (DSAA)", "publication_date": {"year": 2020, "month": null, "day": null}, "abstract": "Developing learning methods which do not discriminate subgroups in the population is the central goal of algorithmic fairness. One way to reach this goal is by modifying the data representation in order to satisfy prescribed fairness constraints. This allows to reuse the same representation in other context (tasks) without discriminate subgroups. In this work we measure fairness according to demographic parity, requiring the probability of the possible model decisions to be independent of the sensitive information. We argue that the goal of imposing demographic parity can be substantially facilitated within a multi-task learning setting. We leverage task similarities by encouraging a shared fair representation across the tasks via low rank matrix factorization. We derive learning bounds establishing that the learned representation transfers well to novel tasks both in terms of prediction performance and fairness metrics. We present experiments on three real world datasets, showing that the proposed method outperforms state-of-the-art approaches by a significant margin.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": "3089471696", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/dsaa/OnetoDPM20", "doi": "10.1109/dsaa49011.2020.00015"}}, "content": {"source": {"pdf_hash": "4a50774d50659285340113931a02d45d1e078672", "pdf_src": "IEEE", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "9f960c677a5e9acdfe15b7bc1178dd24089d6eaf", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/4a50774d50659285340113931a02d45d1e078672.txt", "contents": "\nLearning Fair and Transferable Representations with Theoretical Guarantees\n\n\nMember, IEEELuca Oneto \nMichele Donini \nMassimiliano Pontil \nAndreas Maurer \nLearning Fair and Transferable Representations with Theoretical Guarantees\n10.1109/DSAA49011.2020.00015Index Terms-Algorithmic FairnessLearning Fair Represen- tationDemographic ParityMulti-Task LearningTransfer Representation\nDeveloping learning methods which do not discriminate subgroups in the population is the central goal of algorithmic fairness. One way to reach this goal is by modifying the data representation in order to satisfy prescribed fairness constraints. This allows to reuse the same representation in other context (tasks) without discriminate subgroups. In this work we measure fairness according to demographic parity, requiring the probability of the possible model decisions to be independent of the sensitive information. We argue that the goal of imposing demographic parity can be substantially facilitated within a multi-task learning setting. We leverage task similarities by encouraging a shared fair representation across the tasks via low rank matrix factorization. We derive learning bounds establishing that the learned representation transfers well to novel tasks both in terms of prediction performance and fairness metrics. We present experiments on three real world datasets, showing that the proposed method outperforms state-of-the-art approaches by a significant margin.\n\nI. INTRODUCTION\n\nDuring the last decade, the widespread distribution of automatic systems for decision making is raising concerns about their potential for unfair behaviour [1]- [4]. As a consequence, machine learning models are often required to meet fairness requirements, ensuring the correction and limitation of -for example -racist or sexist decisions. In literature, it is possible to find a plethora of different methods to generate fair models with respect to one or more sensitive attributes (e.g. gender, ethnic group, age). These methods can be mainly divided in three families: (i) methods in the first family change a pre-trained model in order to make it more fair (while trying to maintain the classification performance) [5]- [8]; (ii) in the second family, we can find methods that enforce fairness directly during the training phase, e.g. [9]- [12]; (iii) the third family of methods implements fairness by modifying the data representation, and then employs standard machine learning methods [13], [14]. All methods in the previous families have in common the goal of creating a fair model from scratch on the specific task at hand. This solution may work well in specific cases, but in a large number of real world applications, using the same model (or at least part of it) over different tasks is helpful Luca  if not mandatory. For example, it is common to perform a fine tuning over pre-trained models [15], keeping fixed the internal representation. Indeed, most modern machine learning frameworks (especially the deep learning ones) offer a set of pre-trained models that are distributed in so-called model zoos 1 . Unfortunately, fine tuning pre-trained models on novel previously unseen tasks could lead to an unexpected unfairness behaviour, even starting from an apparently fair model for previous tasks, a phenomenon which is referred to as discriminatory transfer in [16] or negative legacy in [17], due to missing generalization guarantees concerning the fairness property of the model. In order to overcome the above problem, in this paper we embrace the framework of multi-task learning. We aim to leverage task similarities in order to learn a fair representation that generalizes well to unseen tasks. By this we mean that when the representation is used to learn novel tasks, it is guaranteed to learn a model that has both a small error and meets the fairness requirement. We measure fairness according to demographic parity [18] (for an extended analysis of the different fairness definitions see [9], [19]) that requires the probability of possible model decisions to be independent of the sensitive information. We argue that multi-task methods based on low rank matrix factorization are well suited to learn a shared fair representation according to demographic parity. We show theoretically that the learned representation transfers well to novel tasks both in terms of prediction performance and fairness metrics. Other papers in literature already pursued a similar goal [20]- [26]. They mainly rely on generating a model acting randomly when the internal representation is exploited to predict the sensitive variable. No actual constraint is imposed directly on the internal representation, but only over the output of the model. The main contribution of this paper is to augment multi-task learning methods based on low rank matrix factorization by imposing a fairness constraint directly on the representation factor matrix. We show empirically and theoretically, via learning bounds, that by imposing the fairness constraint within the multi-task learning method, the learned representation can be used to train new models over different (new and possibly unseen) tasks, maintaining the desiderata of an accurate and fair model. Our learning bound improves over previous bounds for learning-to-learn [27] and by being fully data dependent, it can be used to evaluate the transfer capability of the learned representation.\n\nThe paper is organized in the following manner. In Section II, we discuss previous related work aimed at learning fair representations. In Section III, we introduce the proposed method. In Section IV, we study the generalization properties of the method, embracing the framework of learning-to-learn. In Section V, we experimentally compare the proposed method against different baselines and state-of-the-art approaches on three real world datasets. Finally, in Section VII we discuss directions of future research.\n\nII. RELATED WORK Let us consider a composition of models f (g(x)) where x \u2208 R d is a vector of raw features (an element of the input space), g : R d \u2192 R r is a function mapping the input space into a new one, that we refer to as the representation. In other words, the function g synthesizes the information needed to solve a particular task (or a set of tasks) by learning a function f , chosen from a set of possible functions. In this work -and more generally in the current literature [13], [20]- [26], [28] -with fair representation we refer to the concept of learning a function g, which does not discriminate subgroups in the data. This approach is different from most commonly used approaches [7], [10], [11], in which the focus is to solve a task (or a set of tasks) without discriminating subgroups in the data, regardless of the fairness of the representation itself. That is, in the previously mentioned papers a fair model f : R r \u2192 R is learned directly from the raw data, without performing any explicit representation extraction.\n\nIn particular, in [20]- [26], the authors propose different neural network architectures together with modified learning strategies able to learn a representation that obscures or removes the sensitive variable. In the general case, all these methods have an input, a target variable (i.e. the task at hand) and a binary sensitive variable. The objective is to learn a representation that: (i) preserves information about the input space; (ii) is useful for predicting the target; (iii) is approximately independent of the sensitive variable. In practice, these methods pursue the goal of making the generated model act randomly when the internal representation is exploited to predict the sensitive variable. In this sense, no actual constraint is directly imposed on the internal representation, but only on the output of the model. In [28], instead, the authors show how to formulate the problem of counterfactual inference as a domain adaptation problem, and more specifically a covariate shift problem [29]. The authors derive two new families of representation algorithms for counterfactual inference. The first one is based on linear models and variable selection, and the other one on deep learning. The authors show that learning representations that encourage similarity (i.e. balance) between the treatment and control populations leads to better counterfactual inference; this is in contrast to many methods which attempt to create balance by re-weighting samples. Finally, in [13], the authors learn a representation of the data that is a probability distribution over clusters where learning the cluster of a datapoint contains no-information about the sensitive variable, namely fair clustering. In this sense, the clustering is learned to be fair and also discriminative for the prediction task at hand. Contrary to the described methods from literature, our proposal enforces the fairness constraint directly on the representation layer, i.e. not using indirect approaches such as different objective functions for the entire functional or adversarial methods. Moreover we support the proposed method with generalization guarantees in terms of both accuracy and fairness measure.\n\n\nIII. METHOD\n\nIn this section, we present our method to learn a shared fair representation from multiple tasks. We consider T supervised learning tasks (i.e. binary classification or regression problems). Each task t \u2208 {1, . . . , T } is identified by a probability distribution \u03bc t on X \u00d7 S \u00d7 Y, where X \u2282 R d is the set of non-sensitive input variables, S = {1, 2} is the set of values of a binary sensitive variable 2 and Y is the output space which is either {\u22121, 1} for binary classification or Y \u2282 R for regression. We let z t = (x t,i , s t,i , y t,i ) m i=1 \u2208 (X \u00d7 S \u00d7 Y) m be the training sequence for task t, which is sampled independently from \u03bc t . The goal is to learn a predictive model f t : X \u00d7 S \u2192 Y for each task t \u2208 {1, . . . , T }. Depending on the application at hand, the model may include (i.e. f : X \u00d7 S \u2192 Y) or not (i.e. f : X \u2192 Y) the sensitive feature in its functional form. In the following we consider the case that X = R d , the functions f t are linear, and to simplify the presentation we do not include s in the functional form of the model, that is, f t (x) = w t , x , where w t \u2208 R d is a vector of parameters. The case in which both x and s are used as predictors is obtained by adding two more components to x, representing the one-hot encoding of s, and letting w t \u2208 R d+2 . A general multi-task learning formulation (MTL) is based on minimizing the multi-task empirical error plus a regularization term which leverages similarities between the tasks. A natural choice for the regularizer which is considered in this paper is given by the trace norm, namely the sum of the singular values of the matrix W = [w 1 \u00b7 \u00b7 \u00b7 w T ] \u2208 R d\u00d7T . It is well know, that this problem is equivalent to the matrix factorization problem,\nmin A,B 1 T m T t=1 m i=1 y t,i \u2212 b t , A x t,i 2 + \u03bb 2 A 2 F + B 2 F (1) where A = [a 1 . . . a r ] \u2208 R d\u00d7r and B = [b 1 . . . b T ] \u2208 R r\u00d7T\nand \u00b7 F is the Frobenius norm, see e.g. [30] and references therein. Here r \u2208 N is the number of factors, that is the upper bound on the rank of W = AB. If r \u2265 min(d, T ) then Problem (1) is equivalent to trace norm regularization [31], see e.g. [32] and references therein 3 . We follow the formulation of Eq. (1) since it can easily be solved by gradient descent or alternate minimization as we discuss next. Once the problem is solved, the estimated parameters of the function w t for the tasks' linear models are simply computed as w t = Ab t . We also note that for simplicity the problem is stated with the square loss function, but our observations extended to the general case of proper convex loss functions. Note that the method can be interpreted as a 2-layer network with linear activation functions. Indeed, the matrix A applied to an input vector x \u2208 R d induces the linear representation A x = (a 1 x, \u00b7 \u00b7 \u00b7 , a r x) . We would like this representation to be fair w.r.t. the sensitive feature. Specifically, we require that each component of the representation vector satisfies the demographic parity constraint [19], [33] on each task. This means that, for every measurable subset C \u2282 R r , and for every t \u2208 {1, . . . , T }, we require that\nP(A x t \u2208 C |s = 1) = P(A x t \u2208 C |s = 2)(2)\nthat is the two conditional distributions are the same. We relax this constraint by requiring, for every t \u2208 {1, . . . , T }, that both distributions have the same mean. Furthermore, we compute the means from empirical data. For each training sequence z \u2208 (X \u00d7 Y) m and s \u2208 S, we use the notation\nI s (z) = {(x i , y i ) : s i = s}, define the empirical conditional means c(z) = 1 |I 1 (z)| i\u2208I1(z) x i \u2212 1 |I 2 (z)| i\u2208I2(z) x i(3)\nand then relax the constraint of Eq. (2) to\nA c(z t ) = 0.(4)\nThis is a crude approximation since it corresponds to requiring the first order moment of the two distributions to be the same. However, as we shall see, it works well in practice and has the major advantage of turning a non-convex constraint in a convex one. We note that a similar approximation has been considered in [34] in the case of fair regression, and reported to be empirically effective. Furthermore, in Appendix VIII-A, we discuss the quality of this approximation referring also the previous results in the literature [10], [34]. Based on the above reasoning, we propose to learn a fair linear representation as a solution to the optimization problem\nmin A,B 1 T m T t=1 m i=1 y t,i \u2212 b t , A x t,i 2 + \u03bb 2 ( A 2 F + B 2 F ) (5) A c t = 0, t \u2208 {1, . . . , T }.\nwhere we used the shorthand notation c t = c(z t ). There are many methods to tackle Problem (5). A natural approach is based on alternate minimization. We discuss the main steps below. Let y t = [y t,1 , . . . , y t,m ] , the vector formed by the outputs of task t, and let X t = [x t,1 , . . . , x t,m ] , the data matrix for task t.\n\nWhen we regard A as fixed and solve w.r.t. B, then Problem (5) can be reformulated as\nmin B \u23a1 \u23a2 \u23a3 y 1 . . . y T \u23a4 \u23a5 \u23a6\u2212 \u23a1 \u23a2 \u23a3 X 1 A 0 \u00b7 \u00b7 \u00b7 0 . . . . . . . . . . . . 0 \u00b7 \u00b7 \u00b7 0 X T A \u23a4 \u23a5 \u23a6 \u23a1 \u23a2 \u23a3 b 1 . . . b T \u23a4 \u23a5 \u23a6 2 +\u03bb \u23a1 \u23a2 \u23a3 b 1 . . . b T \u23a4 \u23a5 \u23a6 2\nwhich can be easily solved. In particular note that the problem decouples across the tasks, and each task specific problem amounts to run ridge regression on the data transformed by the representation matrix A . When instead B is fixed and we solve w.r.t. A, Problem (5) can be reformulated as\nmin A \u23a1 \u23a2 \u23a3 y 1 . . . y T \u23a4 \u23a5 \u23a6\u2212 \u23a1 \u23a2 \u23a3 b 1,1 X 1 \u00b7 \u00b7 \u00b7 b 1,r X 1 . . . b t,1 X T \u00b7 \u00b7 \u00b7 b t,r X T \u23a4 \u23a5 \u23a6 \u23a1 \u23a2 \u23a3 a 1 . . . a r \u23a4 \u23a5 \u23a6 2 +\u03bb \u23a1 \u23a2 \u23a3 a 1 . . . a r \u23a4 \u23a5 \u23a6 2 s.t. \u23a1 \u23a2 \u23a3 a T 1 . . . a T r \u23a4 \u23a5 \u23a6 \u2022 c 1 , . . . , c T = 0\nwhere \"\u2022\" is the Kronecker product for partitioned tensors (or Tracy-Singh product). Consequently by alternating minimization we can solve the original problem. Note also that we may relax the equality constraint as 1\nT T t=1 A c(z t ) 2 \u2264 ,\nwhere is some tolerance parameter. In fact, this may be required when the vectors c(z t ) span the whole input space. In this case we may also add a soft constraint in the regularizer. We conclude this section by noting that if demographic parity is satisfied at the representation level, i.e. Eq. (2) holds true, then every model built from such representation will satisfy demographic parity as well. Likewise if the representation satisfies the convex relaxation of Eq. (4), then it will also hold that w t , c(z t ) = b t , A c(z t ) = 0, that is the task weight vectors will satisfy the first order moment approximation of demographic parity. More importantly, as we will show in the next section, if the tasks are randomly observed, then demographic parity will also be satisfied on future tasks with high probability. In this sense our method can be interpreted as learning a fair transferable representation.\n\n\nIV. LEARNING BOUND\n\nThe intuition behind MTL and in particular the method presented above is that MTL works because of the effective increase in sample size and correspondingly improved generalization through simultaneous consideration of the samples of many related tasks. In this section, we rigorously study the learning ability of the proposed method. We consider the setting of learning-to-learn [35] (a.k.a. meta-learning), in which the training tasks (and their corresponding datasets) used to find a fair data representation are regarded as random variables from a meta-distribution. The learned representation matrix A is then transferred to a novel task, by applying ridge regression on the task dataset, in which the input x is transformed as A x. In [27] a learning bound is presented, linking the average risk of the method over tasks from the meta-distribution (the so-called transfer risk) to the multitask empirical error on the training tasks. We extend this analysis to the setting of algorithmic fairness, in which the performance of the algorithm is evaluated both relative to the risk and the fairness constraint. We show that both quantities can be bounded by their empirical counterparts evaluated on the training samples. To present our result we introduce some more notation 4 . We let R \u03bc (w) and R z (w) be the expected and empirical errors of a weight vector w, that is\nR \u03bc (w) = E (x,y)\u223c\u03bc [(y \u2212 w, x ) 2 ], R z (w) = 1 m m i=1 (y i \u2212 w, x i ) 2 .\nThroughout the paper sometimes we also refer to the expected error as the risk. Furthermore, for every matrix A \u2208 R d\u00d7r and for every data sample z = (\nx i , y i ) m i=1 , we define b A (z) = argmin b\u2208R r 1 m m i=1 (y i \u2212 b, A x i ) 2 + \u03bb b 2\nas the minimizer of ridge regression with modified data representation.\n\nIn the statistical learning-to-learn setting the tasks \u03bc 1 , . . . , \u03bc T are independently sampled from a meta-distribution \u03c1 on the set of probability distributions on X \u00d7 Y. In turn, for every task t \u2208 {1, . . . , T }, we are provided with a training dataset z t of m points sampled independently from \u03bc t . We also require the following assumption, which is standard in the learning-to-learn literature. Assumption 1: We assume that the input marginal distribution of random tasks from \u03c1 is supported on the unit sphere and that the outputs are in the interval [\u22121, 1], almost surely. Let\u0108 be the total (uncentered) empirical covariance of the input points of all tasks,\nC = 1 T T t=1 1 m m i=1 x t,i \u2297 x t,i .\nNotice that when the raw input is intrinsically high dimensional (hence learning is difficult without representation learning), the spectrum of\u0108 tends to be flat. In particular if the data are uniformly distributed on the unit d-dimensional sphere then with high probability\n\u0108 \u221e \u2264 1/d + O(1/T m),\nwhere \u00b7 \u221e is the spectral norm (largest singular value) of a matrix. We also define the empirical covariance of the difference of empirical means of the sensitive groups,\n\u03a3 = 1 T T t=1 c(z t ) \u2297 c(z t ).\nOur main result, presented in the theorem below, bounds with high probability the expected risk (transfer risk) and the expected violation of the fairness constraint for a new task drawn from the random environment, and gives a theoretical justification of the method used in the paper. Theorem 1: Let A be the representation learned by solving Problem (1) and renormalized so that A F = 1. Let r = min(d, T ). Then, for any \u03b4 \u2208 (0, 1] it holds with probability at least 1 \u2212 \u03b4 in the drawing of the datasets z 1 , . . . , z T , that\nE \u03bc\u223c\u03c1 E z\u223c\u03bc m R \u03bc w A (z) \u2212 1 T T t=1 R zt (w A (z t )) \u2264 4 \u03bb \u0108 \u221e m + 24 \u03bbm ln 8mT \u03b4 T + 14 \u03bb ln(mT ) \u0108 \u221e T + 2 ln 4 \u03b4 T and E \u03bc\u223c\u03c1 E z\u223c\u03bc m Ac(z) 2 \u2212 1 T T t=1 Ac(z t ) 2 \u2264 96 ln 8r 2 \u03b4 T + 6 \u03a3 \u221e ln 8r 2 \u03b4 T . Proof: Let D = 1 \u03bb A A.\nNote that the algorithm z \u2192 w D (z) = Ab A (z) is equivalent to running regularized least squares on the original dataset, constraining the parameter vector w to be in the range of D and using the regularizer w D + w, where \" + \" denotes the pseudoinverse. The first claim follows from Theorem 6 stated in the appendix, with D = {D 0, trD \u2264 1/\u03bb}, noting that the algorithm has kernel stability 2, M (K) = 2K + 1, and D \u221e \u2264 D 1 = 1/\u03bb. We then use the first inequality in Corollary 3 in the appendix to upper bound C \u221e by \u0108 \u221e + 6 (ln(4mT )/\u03b4)/(mT ) and a union bound. To prove the second claim we note that\n1 T T t=1\nAc(z t ) 2 = trD\u03a3 and similarly\nE \u03bc\u223c\u03c1 E z\u223c\u03bc m Ac(z) 2 = trD\u03a3\nwhere \u03a3 is the true covariance of the difference of the sensitive groups means,\n\u03a3 = E \u03bc\u223c\u03c1 E z\u223c\u03bc m c(z) \u2297 c(z). Then E \u03bc\u223c\u03c1 E z\u223c\u03bc m Ac(z) 2 \u2212 1 T T t=1 Ac(z t ) 2 = trD(\u03a3 \u2212\u03a3) \u2264 D 1 \u03a3 \u2212\u03a3 \u221e = \u03a3 \u2212\u03a3 \u221e .\nThe second inequality then follows immediately from inequality (10) in Corollary 3, with N = T and\nA t = (1/4)c(z t ) \u2297 c(z t ).\nWe make some remarks on the above result:\n\n1) The first bound in Theorem 1 improves Theorem 2 in [27], due to the introduction of the empirical total covariance in the third term in the RHS of the inequality. The result in [27] instead contains the term 1/T , which can be considerably larger when the raw input is distributed on a high dimensional manifold.\n\n2) The bounds in Theorem 1 can be extended to hold with variable sample size per task. However, in order to simplify the presentation, we assume that all datasets are composed of the same number of points m. The general setting can be addressed by letting the sample size be a random variable and introducing the slightly different definition of the transfer risk in which we also take the expectation w.r.t. the sample size.\n\n3) The hyperparameter \u03bb is regarded as fixed in the analysis.\n\nIn practice it will be chosen by cross-validation as in our experiments below. 4) The bound on the fairness measure contains two terms in the right hand side, in the spirit of Bernstein's inequality. The slow term O(1/ \u221a T ) contains the spectral norm of the covariance of difference of means across the sensitive groups. Notice that \u03a3 \u221e \u2264 1 but it can be much smaller when the means are close to each other, that is, when the original representation is already approximately fair. 5) Finally, we note that although the theorem provides a bound for the linear approximation of demographic parity, we may pass to a bound on demographic parity following the reasoning in [10]. This is discussed in detail in Appendix VIII-A, where we also address the quality of the above approximation.\n\n\nV. EXPERIMENTS\n\nIn this section, we compare the proposed method against different baselines and state-of-the-art-methods.\n\n\nA. Settings\n\nIn order to better understand the performance of the proposed method we performed two sets of experiments.\n\nIn the first set (Table I) we compare the following methods: (a) Unconstrained single task learning 5 (STL), (b) Fair constrained STL (i.e. STL with additional demographic parity constraint), (c) Unconstrained MTL, (d) Fair constrained MTL, that is the proposed method. We test each method either on the same tasks exploited during the training phase, or on novel tasks. Furthermore, we consider both the case where the sensitive feature is present, and not in the functional form of the model (i.e. the sensitive feature is known or not in the testing phase).\n\nIn the second set of experiments (Table II) we compare, in the same setting that we just described, (a) Standard MTL with the fairness constraints on the outputs (M1), (b) feedforward neural network (FFNN) with linear activation and the fair shared representation method presented in [23] (M2), (c) FFNN with linear activation by exploiting a fair shared representation as presented in [21] (M3), (d) Fair constrained MTL (Our Method). We used linear activation functions in FFNN for fair comparison, since the proposed method learns linear models. It is important to note that, for the sake of completeness, we performed all same experiments also in the non-linear case, namely the case when non-linear (sigmoid) activation function is exploited. The complete set of results for the non-linear case can be found in the supplementary material, Appendix VIII-B.\n\nConcerning the experiments on the same task setting, we train the model with all the tasks and then we measure results on an independent test set of the same tasks. In the case of novel task experiments, we train the model with all the tasks minus one (randomly selected). Then, we fix the representation found by our method and we use a subset of the data (70%) for the excluded task to train the last layer, maintaining fixed the representation layer. Finally, we used the remaining data (30%) of the novel task as test set, measuring both error and fairness measure. We repeated all the experiments both with and without the sensitive feature in the functional form of the model. We validated the hyperparameters using a grid search with \u03bb \u2208 {10 \u22126.0 , 10 \u22125.8 , \u00b7 \u00b7 \u00b7 , 10 +4.0 } and r \u2208 {2 j d | j = \u22124, \u22123, . . . , 10}, following the validation procedure in [10]. Specifically, in the first step, the classical 10-fold CV error for each of the combination of the hyperparameters is computed.\n\nIn the second step, we shortlist all the hyperparameters' combinations with error close to the best one (in our case, above 90% of the smallest error). Finally, from this list, we select the hyperparameters with the smallest fairness measure. Concerning the error (ERR) we used mean average precision error as the performance index, and concerning the unfairness of our model (UNFAIR), we compute the the difference of demographic parity as 1\n\n\n|Y|\n\ny\u2208Y |P (f (x) = y|s = 1) \u2212 P (f (x) = y|s = 2)|, since in our datasets the output space is finite. For all the experiments, we report performance over 30 repetitions with the corresponding standard deviation.\n\n\nB. Datasets\n\nIn our comparisons we used three datasets. The first one is the School data set [36] -made available by the Inner London Education Authority (ILEA) -formed by examination records from 139 secondary schools in years 1985, 1986 and 1987. It is a random 50% sample with 15362 students. Each task in this setting is to predict exam scores for students in one school, based on eight inputs. The first four inputs (year of the exam, gender, VR band and ethnic group) are studentdependent, the next four (percentage of students eligible for free school meals, percentage of students in VR band one, school gender -mixed or single-gender -and school denomination) are school-dependent. The categorical variables (year, ethnic group and school denomination) were split up in one-hot variables, one for each category, making a new total of 16 student-dependent inputs, and six school-dependent inputs. We scaled each covariate and output to have zero mean and unit variance. The sensitive attribute is the gender of the student. The second dataset we propose has been collected at the University of Genoa 6 (UNIV) and is also exploited in [34]. This dataset is a proprietary and highly sensitive   dataset containing all the data about the past and present students enrolled at the UNIV. In this study we take into consideration students who enrolled, in the academic year (a.y.) 2017-2018. The dataset contains 5000 instances, each one described by 35 attributes (both numeric and categorical) about ethnicity, gender, financial status, and previous school experience. The scope is to predict the grades at the end of the first semester being fair with respect to the gender of the student. Finally, the third dataset is Movielens [37]. Specifically, we considered Movielens 100k (ml100k), which consists of ratings (1 to 5) provided by 943 users for a set of 1682 movies, with a total of 100,000 ratings available. Additional features for each movie, such as the year of release or its genre, are provided. In this case, the sensitive attribute is the gender of the user.\n\n\nVI. DISCUSSION\n\nFrom our experimental results, different interesting aspects and comparisons can be extracted. Firstly, the results in Table I  confirm Table II for new tasks when the sensitive feature is not included in the functional form of the model.\n\nto STL, in that accuracy has a significant improvement, both on same and novel tasks, thanks to the shared representation. Achieving less error has the positive side effect of producing a more fair model, even in the unconstrained case (i.e. fair unaware).\n\nIn the case of constrained methods, learning a fair shared representation slightly increases the final error but brings a large decrease of the fairness measure. From Table I, we observe that this benefit is maintained also by tackling new and unseen (during the training of the shared representation) tasks. In this sense, our method (constrained MTL) obtains the best performance among all the others. In general, the same analysis of the results applies to both having and not having the sensitive feature in the functional form of the model. In order to better interpret our results, and due to our higher interest in the case of a fair constrained model without the sensitive feature in the functional form of the model, we compared in Figure 1 the constrained STL approach to the constrained MTL approach (our method) both on the same and the novel tasks. In this figure it is easier to note the benefits of our algorithm in decreasing both the error and the fairness measure. Finally, we compared our method with three different stateof-the-art methods. In Table II and Figure 2, we show these results. We note how our method, in all the possible settings, obtains better or comparable performance. In fact, it is able to maintain a larger accuracy (comparable to the other methods) and simultaneously a smaller fairness measure.\n\nAnalogous conclusions can be drawn for the non-linear scenario, where our method outperforms all the other ones in all the experiments except for M3 [23] on the UNIV dataset. Due to space constraint, the complete results are reported in Appendix VIII-B. We believe our method is able to achieve these results enforcing the fairness constraint directly on the representation layer, instead of using different objective functions for the entire functional, or with adversarial methods, and so indirectly. This is a key difference in our approach compared to the current state-of-the-art ones. Moreover, theoretical guarantees behind the generalization performance of our method, in terms of accuracy and fairness, also support our findings and promising results.\n\n\nVII. CONCLUSIONS\n\nWe presented a method to learn a fair shared representation among different tasks in a MTL setting. Within a metalearning setting, we argue theoretically that the learned representation transfers well to novel tasks, both in terms of accuracy and fairness. Up to our knowledge this is the first representation learning method that is supported by learning guarantees. We then studied the learning ability of our method in practice, in a number of experimental scenarios.\n\nThe obtained results corroborate our theoretical findings and proved that our approach overcomes common benchmark algorithms and current state-of-the-art methods. A valuable direction of future research would be to extend our learning bounds to deep neural networks, basically a generalization to the non-linear case of the proposed approach, with particular attention to the interpretability of the learned representation, in the context of transparency and trust of the final model.\n\n\nVIII. APPENDIX\n\n\nA. Approximation of Demographic Parity\n\nThe approximation of demographic parity that we employed in the paper corresponds to matching the first order moment, see Equations (2)-(4). As we have shown in Section V and Appendix VIII-B this approximation works well in practice and it allows us to outperform current state-of-the-art approaches. In the the rest of this section, we show one case in which the approximation is crude. Nevertheless, we will also show that the cases where the approximation fails can be easily detected computing an empirical quantity following the same reasoning in [10]. Let us introduce here our example. Exploiting the proposed method, every linear function based on a representation of x defined by Ax, will be orthogonal to c (z) and the mean of the conditional distributions of b, A x for both sensitive groups will be equal. But this does not guarantee demographic parity for binary classifiers obtained by thresholding b, A x at 0. To see this let the two conditional distributions of b, A x be for t \u2208 (0, 1/2)\np s=1 = t\u03b4 \u22121 + (1 \u2212 t) \u03b4 t/(1\u2212t) p s=2 = t\u03b4 1 + (1 \u2212 t) \u03b4 \u2212t/(1\u2212t) ,\nwhere \u03b4 i is the Dirac delta centered in i. Then both means are zero, but\nP { b, A x > 0|s = 1} = 1 \u2212 t = t = P { b, A x > 0|s = 2} .\nThe closer t is to zero, the more pronounced is the violation of demographic parity. On the other hand suppose that Eq. (2) holds only for all half-spaces C instead of for all measurable sets. This is then equivalent to demographic parity for all classifiers obtained by thresholding linear functions b, A x at 0. The relaxation of Eq. (4) does not ensure this, as shown by the above example, not even for the linear functions b A (z t ) found for the training data. The case when the approximation is crude can be detected computing an empirical quantity. In fact if\n1 2 g\u2208{1,2} E sign b, A x \u2212 b, A x s = g \u2264 \u0394,\nthen it also holds that\n|P { b, A x > 0|s = 1} \u2212 P { b, A x > 0|s = 2}| \u2264 |E { b, A x |s = 1} \u2212 E { b, A x |s = 2}| + \u0394. (6)\nIn the above mentioned case \u0394 = 1 which points out problems with the approximation. Note that the statement of Eq. (6) also hold in its empirical counterpart using\u0394. In many real scenarios, see [10], [34], this\u0394 has shown to be very small (smaller than 0.05), suggesting that cases like the artificial one depicted above are uncommon. Tables III and IV report the equivalent results of Tables I  and II when, in the representation layer, a sigmoidal non-linear activation functions is added. These new tables represent the non-linear counterpart of the results presented in the main text. As it is possible to see from the results, the same considerations derived from the linear case can be derived for the non-linear one, supporting the proposed method. Notice that the proposed method outperforms all state-of-the-art methods in all experiments except for M3 [23] on the UNIV dataset. The results are also visualized in Figures 3 and 4, which are the counterpart of Figures 1 and 2 for the non-linear case.  \n\n\nB. Results in the non-linear case\n\n\nSame Tasks\n\nSensitive feature not in the functional form of the model  Table IV for new tasks when the sensitive feature is not included in the functional form of the model.\n\n\nSensitive feature not in the functional form of the model School 12.34\u00b10.75 0.013\u00b10.001 13.44\u00b11.04 0.017\u00b10.002 12.93\u00b10.79 0.018\u00b10.002 11.78\u00b10.75 0.011\u00b10.001 UNIV 18.12\u00b10.98 0.012\u00b10.001 21.23\u00b11.34 0.021\u00b10.004 26.19\u00b11.76 0.027\u00b10.004 15.02\u00b10.54 0.010\u00b10.001 Movielens 17.12\u00b10.65 0.009\u00b10.001 19.21\u00b10.87 0.014\u00b10.002 18.01\u00b10.76 0.012\u00b10.002 17.27\u00b10.76 0.007\u00b10.001 Sensitive feature in the functional form of the model School 11.01\u00b10.91 0.020\u00b10.001 12.01\u00b11.01 0.022\u00b10.002 13.31\u00b11.23 0.025\u00b10.002 10.71\u00b10.52 0.019\u00b10.001 UNIV 13.75\u00b10.82 0.017\u00b10.001 20.13\u00b11.24 0.029\u00b10.005 25.92\u00b11.76 0.032\u00b10.006 13.65\u00b10.82 0.017\u00b10.001 Movielens 15.65\u00b10.73 0.010\u00b10.001 18.97\u00b10.67 0.017\u00b10.004 17.11\u00b10.78 0.015\u00b10.003 15.15\u00b10.73 0.011\u00b10.001 New Tasks Sensitive feature not in the functional form of the model School 15.64\u00b10.79 0.032\u00b10.002 16.43\u00b11.11 0.044\u00b10.004 17.21\u00b11.32 0.041\u00b10.004 14.84\u00b10.74 0.022\u00b10.001 UNIV 16.21\u00b10.97 0.021\u00b10.002 21.98\u00b11.47 0.029\u00b10.004 27.31\u00b11.23 0.033\u00b10.005 16.97\u00b10.70 0.015\u00b10.001 Movielens 19.20\u00b11.35 0.025\u00b10.002 21.21\u00b11.35 0.031\u00b10.004 20.12\u00b11.43 0.030\u00b10.003 20.30\u00b11.18 0.016\u00b10.001 Sensitive feature in the functional form of the model School 14.72\u00b10.87 0.038\u00b10.002 18.02\u00b11.07 0.042\u00b10.003 17.92\u00b10.87 0.056\u00b10.003 13.77\u00b10.76 0.030\u00b10.002 UNIV 15.89\u00b10.68 0.029\u00b10.002 19.21\u00b11.04 0.035\u00b10.005 25.87\u00b11.23 0.038\u00b10.006 15.60\u00b10.61 0.022\u00b10.001 Movielens 19.98\u00b10.74 0.038\u00b10.002 20.12\u00b11.12 0.037\u00b10.003 19.93\u00b11.53 0.038\u00b10.004 18.18\u00b10.79 0.027\u00b10.001\n\nFig. 1 :Fig. 2 :\n12the benefit of using a MTL approach in Graphical representation of the results inTable I, when the sensitive feature is not included in the functional form of the model and the fairness constraint is active. Graphical representation of the results in\n\nSchool 9 .\u00b1 0 Fig. 3 :Fig. 4 :\n903497 \u00b1 0.34 0.015 \u00b1 0.001 10.12 \u00b1 0.39 0.016 \u00b1 0.001 9.93 \u00b1 0.37 0.010 \u00b1 0.001 7.93 \u00b1 0.35 0.009 \u00b1 0.001 UNIV 10.89 \u00b1 0.55 0.091 \u00b1 0.005 11.12 \u00b1 0.55 0.099 \u00b1 0.006 12.43 \u00b1 0.55 0.101 \u00b1 0.007 10.39 \u00b1 0.55 0.091 \u00b1 0.005 Movielens 9.12 \u00b1 0.38 0.001 \u00b1 0.001 9.38 \u00b1 0.38 0.002 \u00b1 0.002 9.98 \u00b1 0.38 0.003 \u00b1 0.002 8.72 \u00b1 0.38 0.001 \u00b1 0.001 Sensitive feature in the functional form of the model School 9.41 \u00b1 0.31 0.021 \u00b1 0.001 9.21 \u00b1 0.49 0.019 \u00b1 0.003 8.98 \u00b1 0.44 0.019 \u00b1 0.002 7.21 \u00b1 0.39 0.015 \u00b1 0.001 UNIV 9.18 \u00b1 0.38 0.120 \u00b1 0.011 10.65 \u00b1 0.41 0.154 \u00b1 0.014 10.31 \u00b1 0.44 0.161 \u00b1 0.013 9.45 \u00b1 0.36 0.155 \u00b1 0.010 Movielens 8.11 \u00b1 0.34 0.009 \u00b1 0.001 7.02 \u00b1 0.21 0.007 \u00b1 0.001 7.34 \u00b1 0.23 0.008 \u00b1 0.001 7.65 \u00b1 0.29 0.008 \u00b1 0.001 New Tasks Sensitive feature not in the functional form of the model School 13.46 \u00b1 0.31 0.026 \u00b1 0.001 12.97 \u00b1 0.47 0.023 \u00b1 0.001 13.41 \u00b1 0.43 0.032 \u00b1 0.002 9.99 \u00b1 0.37 0.018 \u00b1 0.001 UNIV 12.14 \u00b1 0.73 0.142 \u00b1 0.007 12.98 \u00b1 0.79 0.160 \u00b1 0.011 11.02 \u00b1 0.59 0.101 \u00b1 0.003 11.74 \u00b1 0.64 0.136 \u00b1 0.007 Movielens 10.81 \u00b1 0.42 0.012 \u00b1 0.001 11.43 \u00b1 0.48 0.018 \u00b1 0.002 11.51 \u00b1 0.51 0.022 \u00b1 0.003 10.25 \u00b1 0.39 0.012 \u00b1 0.001 Sensitive feature in the functional form of the model School 12.12 \u00b1 0.37 0.032 \u00b1 0.001 11.97 \u00b1 0.48 0.034 \u00b1 0.002 11.46 \u00b1 0.47 0.025 \u00b1 0.001 9.27 \u00b1 0.38 0.024 \u00b1 0.001 UNIV 11.98 \u00b1 0.65 0.241 \u00b1 0.014 10.34 \u00b1 0.37 0.191 \u00b1 0.009 11.08 \u00b1 0.61 0.221 \u00b1 0.012 10.80 \u00b1 0.42 0.200 \u00b1 0.011 Movielens 9.97 \u00b1 0.52 0.022 \u00b1 0.001 10.23 \u00b1 0.67 0.028 \u00b1 0.003 10.07 \u00b1 0.63 0.024 \u00b1 0.003 9.18 \u00b1 0.44 0.020 Graphical representation of the results inTable III, when the sensitive feature is not included in the functional form of the model and the fairness constraint is active. Graphical representation of the results in\n\n\nOneto -University of Genoa, Italy (email: luca.oneto@unige.it). Michele Donini -Amazon Web Services, US (email: donini@amazon.com). Massimiliano Pontil, Istituto Italiano di Teconologia & University College London, Italy (email: massimiliano.pontil@iit.it). Andreas Maurer -Self Employed, Germany & Italy (email: am@andreas-maurer.eu).\n\nTABLE I :\nIFeed Forward Single Layered Neural Network with linear activation functions. (a) Unconstrained single task learning (STL), (b) Fair constrained STL, (c) Unconstrained MTL, (d) Fair constrained MTL, that is the proposed method.STL -UnCons \nSTL -Cons \nMTL -UnCons \nMTL -Cons \n\nDataset \nERR \nUNFAIR \nERR \nUNFAIR \nERR \nUNFAIR \nERR \nUNFAIR \n\nSame Tasks \n\nSensitive feature not in the functional form of the model \n\nSchool \n15.30\u00b10.60 0.110\u00b10.005 16.37\u00b10.34 0.044\u00b10.003 10.71\u00b10.57 0.077\u00b10.003 11.78\u00b10.75 0.011\u00b10.001 \n\nUNIV \n19.50\u00b10.94 0.100\u00b10.006 20.87\u00b11.16 0.040\u00b10.002 13.65\u00b10.47 0.070\u00b10.003 15.02\u00b10.54 0.010\u00b10.001 \n\nMovielens 30.30\u00b11.98 0.160\u00b10.008 32.42\u00b11.14 0.048\u00b10.002 15.15\u00b10.60 0.112\u00b10.008 17.27\u00b10.76 0.001\u00b10.001 \n\nSensitive feature in the functional form of the model \n\nSchool \n14.23\u00b10.70 0.118\u00b10.006 15.30\u00b10.81 0.052\u00b10.003 9.64\u00b10.40 0.085\u00b10.004 10.71\u00b10.52 0.019\u00b10.001 \n\nUNIV \n18.13\u00b10.83 0.107\u00b10.005 19.50\u00b10.71 0.047\u00b10.003 12.29\u00b10.67 0.077\u00b10.004 13.65\u00b10.82 0.017\u00b10.001 \n\nMovielens 28.18\u00b11.35 0.171\u00b10.010 30.30\u00b11.28 0.059\u00b10.002 13.03\u00b10.47 0.123\u00b10.007 15.15\u00b10.73 0.011\u00b10.001 \n\nNew Tasks \n\nSensitive feature not in the functional form of the model \n\nSchool \n18.36\u00b11.12 0.121\u00b10.007 19.43\u00b10.80 0.055\u00b10.003 13.77\u00b10.52 0.088\u00b10.003 14.84\u00b10.74 0.022\u00b10.001 \n\nUNIV \n21.45\u00b11.16 0.105\u00b10.006 22.82\u00b11.22 0.045\u00b10.002 15.60\u00b10.83 0.075\u00b10.003 16.97\u00b10.70 0.015\u00b10.001 \n\nMovielens 33.33\u00b12.14 0.176\u00b10.009 35.45\u00b11.84 0.064\u00b10.004 18.18\u00b10.76 0.128\u00b10.007 20.30\u00b11.18 0.016\u00b10.001 \n\nSensitive feature in the functional form of the model \n\nSchool \n17.29\u00b10.73 0.129\u00b10.007 18.36\u00b10.88 0.063\u00b10.004 12.70\u00b10.50 0.096\u00b10.005 13.77\u00b10.76 0.030\u00b10.002 \n\nUNIV \n20.08\u00b11.21 0.112\u00b10.005 21.45\u00b11.04 0.052\u00b10.002 14.23\u00b10.67 0.082\u00b10.001 15.60\u00b10.61 0.022\u00b10.001 \n\nMovielens 31.21\u00b11.63 0.187\u00b10.007 33.33\u00b11.28 0.075\u00b10.004 16.06\u00b10.92 0.139\u00b10.011 18.18\u00b10.79 0.027\u00b10.001 \n\n\n\nTABLE II :\nIIFeed Forward Single Layered Neural Network with linear activation functions. Comparison of the following methods: (M1) Standard MTL with the fairness constraints on the outputs, (M2) FFNN with the fair shared representation method presented in [23], (M3) FFNN with the fair shared representation method presented in [21], (M4) Fair constrained MTL (Our Method).M1 \nM2 \nM3 \nM4 (OURS) \n\nDataset \nERR \nUNFAIR \nERR \nUNFAIR \nERR \nUNFAIR \nERR \nUNFAIR \n\nSame Tasks \n\n\n\nTABLE III :\nIIIFeed Forward Single Layered Neural Network with sigmoidal non-linear activation functions. (a) Unconstrained single task learning (STL), (b) Fair constrained STL, (c) Unconstrained MTL, (d) Fair constrained MTL, that is the proposed method. Sensitive feature not in the functional form of the model Sensitive feature not in the functional form of the model UNIV 14.85 \u00b1 0.64 0.956 \u00b1 0.051 15.79 \u00b1 1.03 0.409 \u00b1 0.017 10.80 \u00b1 0.44 0.682 \u00b1 0.031 11.74 \u00b1 0.64 0.136 \u00b1 0.007 Movielens 16.83 \u00b1 0.64 0.132 \u00b1 0.009 17.90 \u00b1 0.99 0.048 \u00b1 0.003 9.18 \u00b1 0.42 0.096 \u00b1 0.003 10.25 \u00b1 0.39 0.012 \u00b1 0.001 Sensitive feature in the functional form of the model School 11.64 \u00b1 0.68 0.105 \u00b1 0.005 12.36 \u00b1 0.65 0.051 \u00b1 0.002 8.55 \u00b1 0.24 0.078 \u00b1 0.004 9.27 \u00b1 0.38 0.024 \u00b1 0.001 UNIV 13.90 \u00b1 0.56 1.019 \u00b1 0.035 14.85 \u00b1 0.69 0.473 \u00b1 0.023 9.85 \u00b1 0.44 0.746 \u00b1 0.035 10.80 \u00b1 0.42 0.200 \u00b1 0.011 Movielens 15.76 \u00b1 1.17 0.140 \u00b1 0.008 16.83 \u00b1 0.89 0.056 \u00b1 0.003 8.11 \u00b1 0.42 0.104 \u00b1 0.006 9.18 \u00b1 0.44 0.020 \u00b1 0.001STL -UnCons \nSTL -Cons \nMTL -UnCons \nMTL -Cons \n\nDataset \nERR \nUNFAIR \nERR \nUNFAIR \nERR \nUNFAIR \nERR \nUNFAIR \n\nSame Tasks \n\nSchool \n10.30 \u00b1 0.88 0.090 \u00b1 0.008 11.02 \u00b1 0.68 0.036 \u00b1 0.002 7.21 \u00b1 0.27 0.063 \u00b1 0.003 7.93 \u00b1 0.35 0.009 \u00b1 0.001 \n\nUNIV \n13.50 \u00b1 0.91 0.910 \u00b1 0.042 14.45 \u00b1 0.89 0.364 \u00b1 0.022 9.45 \u00b1 0.34 0.637 \u00b1 0.032 10.39 \u00b1 0.55 0.091 \u00b1 0.005 \n\nMovielens 15.30 \u00b1 0.43 0.120 \u00b1 0.006 16.37 \u00b1 0.93 0.036 \u00b1 0.001 7.65 \u00b1 0.38 0.084 \u00b1 0.004 8.72 \u00b1 0.38 0.001 \u00b1 0.001 \n\nSensitive feature in the functional form of the model \n\nSchool \n9.58 \u00b1 0.53 0.096 \u00b1 0.005 10.30 \u00b1 0.48 0.042 \u00b1 0.002 6.49 \u00b1 0.32 0.069 \u00b1 0.004 7.21 \u00b1 0.39 0.015 \u00b1 0.001 \n\nUNIV \n12.55 \u00b1 0.71 0.974 \u00b1 0.055 13.50 \u00b1 0.77 0.428 \u00b1 0.020 8.50 \u00b1 0.46 0.701 \u00b1 0.019 9.45 \u00b1 0.36 0.155 \u00b1 0.010 \n\nMovielens 14.23 \u00b1 0.77 0.128 \u00b1 0.005 15.30 \u00b1 0.89 0.044 \u00b1 0.003 6.58 \u00b1 0.35 0.092 \u00b1 0.005 7.65 \u00b1 0.29 0.008 \u00b1 0.001 \n\nNew Tasks \n\nSchool \n12.36 \u00b1 0.70 0.099 \u00b1 0.006 13.08 \u00b1 0.44 0.045 \u00b1 0.002 9.27 \u00b1 0.42 0.072 \u00b1 0.002 9.99 \u00b1 0.37 0.018 \u00b1 0.001 \n\n\n\nTABLE IV :\nIVFeed Forward Single Layered Neural Network with sigmoidal non-linear activation functions. Comparison of the following methods: (M1) Standard MTL with the fairness constraints on the outputs, (M2) FFNN with the fair shared representation method presented in [23], (M3) FFNN with the fair shared representation method presented in [21], (M4) Fair constrained MTL (Our Method).M1 \nM2 \nM3 \nM4 (OURS) \n\nDataset \nERR \nUNFAIR \nERR \nUNFAIR \nERR \nUNFAIR \nERR \nUNFAIR \n\n\nSee for example the Caffe Model Zoo: github.com/BVLC/caffe/ wiki/Model-Zoo\nOur method naturally extends to multiple sensitive variables but for ease of presentation we consider only the binary case in the paper.3 If r < min(d, T ) then Problem (1) is equivalent to trace norm regularization plus a rank constraint.\nSee also suplementary material here https://www.dropbox.com/ s/rt5q1buluv4l7wo/Sup.pdf\nSTL is equivalent to learning the tasks independently with no representation constraint.\nThe data and the research are related to the project DROP@UNIGE of the University of Genoa.\nACKNOWLEDGEMENTSThis work was supported in part by both SAP SE and Amazon Web Services.\nBig data's disparate impact. S Barocas, A D Selbst, California Law Review. 104671S. Barocas and A. D. Selbst, \"Big data's disparate impact,\" California Law Review, vol. 104, p. 671, 2016.\n\nActionable auditing: Investigating the impact of publicly naming biased performance results of commercial ai products. I D Raji, J Buolamwini, AAAI/ACM Conference on AI Ethics and Society. I. D. Raji and J. Buolamwini, \"Actionable auditing: Investigating the impact of publicly naming biased performance results of commercial ai products,\" in AAAI/ACM Conference on AI Ethics and Society, 2019.\n\nGender shades: Intersectional accuracy disparities in commercial gender classification. J Buolamwini, T Gebru, Conference on Fairness, Accountability and Transparency. J. Buolamwini and T. Gebru, \"Gender shades: Intersectional accuracy disparities in commercial gender classification,\" in Conference on Fairness, Accountability and Transparency, 2018.\n\nPath-specific counterfactual fairness. S Chiappa, AAAI Conference on Artificial Intelligence. S. Chiappa, \"Path-specific counterfactual fairness,\" in AAAI Conference on Artificial Intelligence, 2019.\n\nWasserstein fair classification. R Jiang, A Pacchiano, T Stepleton, H Jiang, S Chiappa, Uncertainty in Artificial Intelligence. R. Jiang, A. Pacchiano, T. Stepleton, H. Jiang, and S. Chiappa, \"Wasserstein fair classification,\" in Uncertainty in Artificial Intelligence, 2019.\n\nCertifying and removing disparate impact. M Feldman, S A Friedler, J Moeller, C Scheidegger, S Venkatasubramanian, ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. M. Feldman, S. A. Friedler, J. Moeller, C. Scheidegger, and S. Venkata- subramanian, \"Certifying and removing disparate impact,\" in ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, 2015.\n\nEquality of opportunity in supervised learning. M Hardt, E Price, N Srebro, Advances in neural information processing systems. M. Hardt, E. Price, and N. Srebro, \"Equality of opportunity in supervised learning,\" in Advances in neural information processing systems, 2016.\n\nOn fairness and calibration. G Pleiss, M Raghavan, F Wu, J Kleinberg, K Q Weinberger, Advances in Neural Information Processing Systems. G. Pleiss, M. Raghavan, F. Wu, J. Kleinberg, and K. Q. Weinberger, \"On fairness and calibration,\" in Advances in Neural Information Processing Systems, 2017.\n\nFairness constraints: A flexible approach for fair classification. M B Zafar, I Valera, M Gomez-Rodriguez, K P Gummadi, Journal of Machine Learning Research. 2075M. B. Zafar, I. Valera, M. Gomez-Rodriguez, and K. P. Gummadi, \"Fairness constraints: A flexible approach for fair classification,\" Journal of Machine Learning Research, vol. 20, no. 75, pp. 1-42, 2019.\n\nEmpirical risk minimization under fairness constraints. M Donini, L Oneto, S Ben-David, J S Shawe-Taylor, M Pontil, Advances in Neural Information Processing Systems. M. Donini, L. Oneto, S. Ben-David, J. S. Shawe-Taylor, and M. Pontil, \"Empirical risk minimization under fairness constraints,\" in Advances in Neural Information Processing Systems, 2018.\n\nFairness beyond disparate treatment & disparate impact: Learning classification without disparate mistreatment. M B Zafar, I Valera, M Gomez Rodriguez, K P Gummadi, International Conference on World Wide Web. M. B. Zafar, I. Valera, M. Gomez Rodriguez, and K. P. Gummadi, \"Fairness beyond disparate treatment & disparate impact: Learning clas- sification without disparate mistreatment,\" in International Conference on World Wide Web, 2017.\n\nA reductions approach to fair classification. A Agarwal, A Beygelzimer, M Dudik, J Langford, H Wallach, International Conference on Machine Learning. A. Agarwal, A. Beygelzimer, M. Dudik, J. Langford, and H. Wallach, \"A reductions approach to fair classification,\" in International Conference on Machine Learning, 2018.\n\nLearning fair representations. R Zemel, Y Wu, K Swersky, T Pitassi, C Dwork, International Conference on Machine Learning. R. Zemel, Y. Wu, K. Swersky, T. Pitassi, and C. Dwork, \"Learning fair representations,\" in International Conference on Machine Learning, 2013.\n\nOptimized pre-processing for discrimination prevention. F Calmon, D Wei, B Vinzamuri, K N Ramamurthy, K R Varshney, Advances in Neural Information Processing Systems. F. Calmon, D. Wei, B. Vinzamuri, K. N. Ramamurthy, and K. R. Varshney, \"Optimized pre-processing for discrimination prevention,\" in Advances in Neural Information Processing Systems, 2017.\n\nDecaf: A deep convolutional activation feature for generic visual recognition. J Donahue, Y Jia, O Vinyals, J Hoffman, N Zhang, E Tzeng, T Darrell, International conference on machine learning. J. Donahue, Y. Jia, O. Vinyals, J. Hoffman, N. Zhang, E. Tzeng, and T. Darrell, \"Decaf: A deep convolutional activation feature for generic visual recognition,\" in International conference on machine learning, 2014.\n\nDiscriminatory transfer. C Lan, J Huan, arXiv:1707.00780arXiv preprintC. Lan and J. Huan, \"Discriminatory transfer,\" arXiv preprint arXiv:1707.00780, 2017.\n\nFairness-aware classifier with prejudice remover regularizer. T Kamishima, S Akaho, H Asoh, J Sakuma, Joint European Conference on Machine Learning and Knowledge Discovery in Databases. T. Kamishima, S. Akaho, H. Asoh, and J. Sakuma, \"Fairness-aware clas- sifier with prejudice remover regularizer,\" in Joint European Conference on Machine Learning and Knowledge Discovery in Databases, 2012.\n\nBuilding classifiers with independency constraints. T Calders, F Kamiran, M Pechenizkiy, IEEE international conference on Data mining. T. Calders, F. Kamiran, and M. Pechenizkiy, \"Building classifiers with independency constraints,\" in IEEE international conference on Data mining, 2009.\n\nFairness definitions explained. S Verma, J Rubin, IEEE/ACM International Workshop on Software Fairness. S. Verma and J. Rubin, \"Fairness definitions explained,\" in IEEE/ACM International Workshop on Software Fairness, 2018.\n\nData decisions and theoretical implications when adversarially learning fair representations. A Beutel, J Chen, Z Zhao, E H Chi, arXiv:1707.00075arXiv preprintA. Beutel, J. Chen, Z. Zhao, and E. H. Chi, \"Data decisions and theoretical implications when adversarially learning fair representations,\" arXiv preprint arXiv:1707.00075, 2017.\n\nCensoring representations with an adversary. H Edwards, A Storkey, International Conference on Learning Representations. H. Edwards and A. Storkey, \"Censoring representations with an adversary,\" in International Conference on Learning Representations, 2016.\n\nThe variational fair autoencoder. C Louizos, K Swersky, Y Li, M Welling, R Zemel, arXiv:1511.00830arXiv preprintC. Louizos, K. Swersky, Y. Li, M. Welling, and R. Zemel, \"The variational fair autoencoder,\" arXiv preprint arXiv:1511.00830, 2015.\n\nLearning adversarially fair and transferable representations. D Madras, E Creager, T Pitassi, R Zemel, International Conference on Machine Learning. D. Madras, E. Creager, T. Pitassi, and R. Zemel, \"Learning adversarially fair and transferable representations,\" in International Conference on Machine Learning, 2018.\n\nProvably fair representations. D Mcnamara, C S Ong, R C Williamson, arXiv:1710.04394arXiv preprintD. McNamara, C. S. Ong, and R. C. Williamson, \"Provably fair representations,\" arXiv preprint arXiv:1710.04394, 2017.\n\nCosts and benefits of fair representation learning. D Mcnamara, C S Ong, B Williamson, AAAI Conference on Artificial Intelligence. D. McNamara, C. S. Ong, and B. Williamson, \"Costs and benefits of fair representation learning,\" in AAAI Conference on Artificial Intelligence, Ethics and Society, 2019.\n\nInvariant representations from adversarially censored autoencoders. Y Wang, T Koike-Akino, D Erdogmus, arXiv:1805.08097arXiv preprintY. Wang, T. Koike-Akino, and D. Erdogmus, \"Invariant represen- tations from adversarially censored autoencoders,\" arXiv preprint arXiv:1805.08097, 2018.\n\nTransfer bounds for linear feature learning. A Maurer, Machine learning. 753A. Maurer, \"Transfer bounds for linear feature learning,\" Machine learning, vol. 75, no. 3, pp. 327-350, 2009.\n\nLearning representations for counterfactual inference. F Johansson, U Shalit, D Sontag, International conference on machine learning. F. Johansson, U. Shalit, and D. Sontag, \"Learning representations for counterfactual inference,\" in International conference on machine learning, 2016.\n\nDataset shift in machine learning. J Quionero-Candela, M Sugiyama, A Schwaighofer, N D Lawrence, The MIT PressJ. Quionero-Candela, M. Sugiyama, A. Schwaighofer, and N. D. Lawrence, Dataset shift in machine learning. The MIT Press, 2009.\n\nLearning with matrix factorizations. N Srebro, Massachusetts Institute of TechnologyPhD thesisN. Srebro, \"Learning with matrix factorizations,\" PhD thesis, Massachusetts Institute of Technology, 2004.\n\nConvex multi-task feature learning. A Argyriou, T Evgeniou, M Pontil, Machine Learning. 73A. Argyriou, T. Evgeniou, and M. Pontil, \"Convex multi-task feature learning,\" Machine Learning, vol. 73, no. 3, pp. 243-272, 2008.\n\nReexamining low rank matrix factorization for trace norm regularization. C Ciliberto, D Stamos, M Pontil, arXiv:1706.08934arXiv preprintC. Ciliberto, D. Stamos, and M. Pontil, \"Reexamining low rank matrix factorization for trace norm regularization,\" arXiv preprint arXiv:1706.08934, 2017.\n\nOn formalizing fairness in prediction with machine learning. P Gajane, M Pechenizkiy, arXiv:1710.03184arXiv preprintP. Gajane and M. Pechenizkiy, \"On formalizing fairness in prediction with machine learning,\" arXiv preprint arXiv:1710.03184, 2017.\n\nGeneral fair empirical risk minimization. L Oneto, M Donini, M Pontil, arXiv:1901.10080arXiv preprintL. Oneto, M. Donini, and M. Pontil, \"General fair empirical risk minimization,\" arXiv preprint arXiv:1901.10080, 2019.\n\nA model of inductive bias learning. J Baxter, Journal of Artificial Intelligence Research. 123J. Baxter, \"A model of inductive bias learning,\" Journal of Artificial Intelligence Research, vol. 12, no. 149-198, p. 3, 2000.\n\nMultilevel modelling of survey data. H Goldstein, Journal of the Royal Statistical Society. Series D (The Statistician). 402H. Goldstein, \"Multilevel modelling of survey data,\" Journal of the Royal Statistical Society. Series D (The Statistician), vol. 40, no. 2, pp. 235-244, 1991.\n\nThe movielens datasets: History and context. F M Harper, J A Konstan, Acm transactions on interactive intelligent systems (tiis). 519F. M. Harper and J. A. Konstan, \"The movielens datasets: History and context,\" Acm transactions on interactive intelligent systems (tiis), vol. 5, no. 4, p. 19, 2016.\n\nExcess risk bounds for multitask learning with trace norm regularization. M Pontil, A Maurer, Conference on Learning Theory. M. Pontil and A. Maurer, \"Excess risk bounds for multitask learning with trace norm regularization,\" in Conference on Learning Theory, 2013.\n\nUser-friendly tail bounds for sums of random matrices. J A Tropp, Foundations of computational mathematics. 124J. A. Tropp, \"User-friendly tail bounds for sums of random matrices,\" Foundations of computational mathematics, vol. 12, no. 4, pp. 389-434, 2012.\n\nConcentration inequalities: A nonasymptotic theory of independence. S Boucheron, G Lugosi, P Massart, Oxford university pressS. Boucheron, G. Lugosi, and P. Massart, Concentration inequalities: A nonasymptotic theory of independence. Oxford university press, 2013.\n\nRademacher and gaussian complexities: Risk bounds and structural results. P L Bartlett, S Mendelson, Journal of Machine Learning Research. 3P. L. Bartlett and S. Mendelson, \"Rademacher and gaussian complexi- ties: Risk bounds and structural results,\" Journal of Machine Learning Research, vol. 3, no. Nov, pp. 463-482, 2002.\n", "annotations": {"author": "[{\"start\":\"78\",\"end\":\"101\"},{\"start\":\"102\",\"end\":\"117\"},{\"start\":\"118\",\"end\":\"138\"},{\"start\":\"139\",\"end\":\"154\"}]", "publisher": null, "author_last_name": "[{\"start\":\"95\",\"end\":\"100\"},{\"start\":\"110\",\"end\":\"116\"},{\"start\":\"131\",\"end\":\"137\"},{\"start\":\"147\",\"end\":\"153\"}]", "author_first_name": "[{\"start\":\"90\",\"end\":\"94\"},{\"start\":\"102\",\"end\":\"109\"},{\"start\":\"118\",\"end\":\"130\"},{\"start\":\"139\",\"end\":\"146\"}]", "author_affiliation": null, "title": "[{\"start\":\"1\",\"end\":\"75\"},{\"start\":\"155\",\"end\":\"229\"}]", "venue": null, "abstract": "[{\"start\":\"381\",\"end\":\"1466\"}]", "bib_ref": "[{\"start\":\"1641\",\"end\":\"1644\",\"attributes\":{\"ref_id\":\"b0\"}},{\"start\":\"1646\",\"end\":\"1649\",\"attributes\":{\"ref_id\":\"b3\"}},{\"start\":\"2206\",\"end\":\"2209\",\"attributes\":{\"ref_id\":\"b4\"}},{\"start\":\"2211\",\"end\":\"2214\",\"attributes\":{\"ref_id\":\"b7\"}},{\"start\":\"2326\",\"end\":\"2329\",\"attributes\":{\"ref_id\":\"b8\"}},{\"start\":\"2331\",\"end\":\"2335\",\"attributes\":{\"ref_id\":\"b11\"}},{\"start\":\"2480\",\"end\":\"2484\",\"attributes\":{\"ref_id\":\"b12\"}},{\"start\":\"2486\",\"end\":\"2490\",\"attributes\":{\"ref_id\":\"b13\"}},{\"start\":\"2796\",\"end\":\"2800\"},{\"start\":\"2895\",\"end\":\"2899\",\"attributes\":{\"ref_id\":\"b14\"}},{\"start\":\"3107\",\"end\":\"3108\",\"attributes\":{\"ref_id\":\"b0\"}},{\"start\":\"3368\",\"end\":\"3372\",\"attributes\":{\"ref_id\":\"b15\"}},{\"start\":\"3395\",\"end\":\"3399\",\"attributes\":{\"ref_id\":\"b16\"}},{\"start\":\"3933\",\"end\":\"3937\",\"attributes\":{\"ref_id\":\"b17\"}},{\"start\":\"4006\",\"end\":\"4009\",\"attributes\":{\"ref_id\":\"b8\"}},{\"start\":\"4011\",\"end\":\"4015\",\"attributes\":{\"ref_id\":\"b18\"}},{\"start\":\"4486\",\"end\":\"4490\",\"attributes\":{\"ref_id\":\"b19\"}},{\"start\":\"4492\",\"end\":\"4496\",\"attributes\":{\"ref_id\":\"b25\"}},{\"start\":\"5319\",\"end\":\"5323\",\"attributes\":{\"ref_id\":\"b26\"}},{\"start\":\"6449\",\"end\":\"6453\",\"attributes\":{\"ref_id\":\"b12\"}},{\"start\":\"6455\",\"end\":\"6459\",\"attributes\":{\"ref_id\":\"b19\"}},{\"start\":\"6461\",\"end\":\"6465\",\"attributes\":{\"ref_id\":\"b25\"}},{\"start\":\"6467\",\"end\":\"6471\",\"attributes\":{\"ref_id\":\"b27\"}},{\"start\":\"6661\",\"end\":\"6664\",\"attributes\":{\"ref_id\":\"b6\"}},{\"start\":\"6666\",\"end\":\"6670\",\"attributes\":{\"ref_id\":\"b9\"}},{\"start\":\"6672\",\"end\":\"6676\",\"attributes\":{\"ref_id\":\"b10\"}},{\"start\":\"7025\",\"end\":\"7029\",\"attributes\":{\"ref_id\":\"b19\"}},{\"start\":\"7031\",\"end\":\"7035\",\"attributes\":{\"ref_id\":\"b25\"}},{\"start\":\"7845\",\"end\":\"7849\",\"attributes\":{\"ref_id\":\"b27\"}},{\"start\":\"8014\",\"end\":\"8018\",\"attributes\":{\"ref_id\":\"b28\"}},{\"start\":\"8496\",\"end\":\"8500\",\"attributes\":{\"ref_id\":\"b12\"}},{\"start\":\"11148\",\"end\":\"11152\",\"attributes\":{\"ref_id\":\"b29\"}},{\"start\":\"11339\",\"end\":\"11343\",\"attributes\":{\"ref_id\":\"b30\"}},{\"start\":\"11354\",\"end\":\"11358\",\"attributes\":{\"ref_id\":\"b31\"}},{\"start\":\"12235\",\"end\":\"12239\",\"attributes\":{\"ref_id\":\"b18\"}},{\"start\":\"12241\",\"end\":\"12245\",\"attributes\":{\"ref_id\":\"b32\"}},{\"start\":\"13225\",\"end\":\"13229\",\"attributes\":{\"ref_id\":\"b33\"}},{\"start\":\"13436\",\"end\":\"13440\",\"attributes\":{\"ref_id\":\"b9\"}},{\"start\":\"13442\",\"end\":\"13446\",\"attributes\":{\"ref_id\":\"b33\"}},{\"start\":\"13772\",\"end\":\"13775\",\"attributes\":{\"ref_id\":\"b4\"}},{\"start\":\"16339\",\"end\":\"16343\",\"attributes\":{\"ref_id\":\"b34\"}},{\"start\":\"16700\",\"end\":\"16704\",\"attributes\":{\"ref_id\":\"b26\"}},{\"start\":\"17238\",\"end\":\"17239\",\"attributes\":{\"ref_id\":\"b3\"}},{\"start\":\"20647\",\"end\":\"20651\",\"attributes\":{\"ref_id\":\"b9\"}},{\"start\":\"20810\",\"end\":\"20814\",\"attributes\":{\"ref_id\":\"b26\"}},{\"start\":\"20936\",\"end\":\"20940\",\"attributes\":{\"ref_id\":\"b26\"}},{\"start\":\"22232\",\"end\":\"22236\",\"attributes\":{\"ref_id\":\"b9\"}},{\"start\":\"23441\",\"end\":\"23445\",\"attributes\":{\"ref_id\":\"b22\"}},{\"start\":\"23543\",\"end\":\"23547\",\"attributes\":{\"ref_id\":\"b20\"}},{\"start\":\"24883\",\"end\":\"24887\",\"attributes\":{\"ref_id\":\"b9\"}},{\"start\":\"25772\",\"end\":\"25776\",\"attributes\":{\"ref_id\":\"b35\"}},{\"start\":\"26821\",\"end\":\"26825\",\"attributes\":{\"ref_id\":\"b33\"}},{\"start\":\"27414\",\"end\":\"27418\",\"attributes\":{\"ref_id\":\"b36\"}},{\"start\":\"29759\",\"end\":\"29763\",\"attributes\":{\"ref_id\":\"b22\"}},{\"start\":\"31959\",\"end\":\"31963\",\"attributes\":{\"ref_id\":\"b9\"}},{\"start\":\"33550\",\"end\":\"33554\",\"attributes\":{\"ref_id\":\"b9\"}},{\"start\":\"33556\",\"end\":\"33560\",\"attributes\":{\"ref_id\":\"b33\"}},{\"start\":\"34218\",\"end\":\"34222\",\"attributes\":{\"ref_id\":\"b22\"}},{\"start\":\"43383\",\"end\":\"43384\",\"attributes\":{\"ref_id\":\"b2\"}}]", "figure": "[{\"start\":\"34580\",\"end\":\"36007\",\"attributes\":{\"id\":\"fig_0\"}},{\"start\":\"36008\",\"end\":\"36278\",\"attributes\":{\"id\":\"fig_1\"}},{\"start\":\"36279\",\"end\":\"38050\",\"attributes\":{\"id\":\"fig_2\"}},{\"start\":\"38051\",\"end\":\"38388\",\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"}},{\"start\":\"38389\",\"end\":\"40218\",\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"}},{\"start\":\"40219\",\"end\":\"40693\",\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"}},{\"start\":\"40694\",\"end\":\"42695\",\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"}},{\"start\":\"42696\",\"end\":\"43171\",\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"}}]", "paragraph": "[{\"start\":\"1485\",\"end\":\"5440\"},{\"start\":\"5442\",\"end\":\"5958\"},{\"start\":\"5960\",\"end\":\"7005\"},{\"start\":\"7007\",\"end\":\"9203\"},{\"start\":\"9219\",\"end\":\"10965\"},{\"start\":\"11108\",\"end\":\"12365\"},{\"start\":\"12411\",\"end\":\"12707\"},{\"start\":\"12843\",\"end\":\"12886\"},{\"start\":\"12905\",\"end\":\"13568\"},{\"start\":\"13679\",\"end\":\"14014\"},{\"start\":\"14016\",\"end\":\"14101\"},{\"start\":\"14262\",\"end\":\"14555\"},{\"start\":\"14777\",\"end\":\"14994\"},{\"start\":\"15019\",\"end\":\"15935\"},{\"start\":\"15958\",\"end\":\"17335\"},{\"start\":\"17414\",\"end\":\"17565\"},{\"start\":\"17657\",\"end\":\"17728\"},{\"start\":\"17730\",\"end\":\"18403\"},{\"start\":\"18444\",\"end\":\"18718\"},{\"start\":\"18741\",\"end\":\"18911\"},{\"start\":\"18945\",\"end\":\"19477\"},{\"start\":\"19711\",\"end\":\"20315\"},{\"start\":\"20326\",\"end\":\"20357\"},{\"start\":\"20387\",\"end\":\"20466\"},{\"start\":\"20584\",\"end\":\"20682\"},{\"start\":\"20713\",\"end\":\"20754\"},{\"start\":\"20756\",\"end\":\"21071\"},{\"start\":\"21073\",\"end\":\"21498\"},{\"start\":\"21500\",\"end\":\"21561\"},{\"start\":\"21563\",\"end\":\"22347\"},{\"start\":\"22366\",\"end\":\"22471\"},{\"start\":\"22487\",\"end\":\"22593\"},{\"start\":\"22595\",\"end\":\"23155\"},{\"start\":\"23157\",\"end\":\"24017\"},{\"start\":\"24019\",\"end\":\"25016\"},{\"start\":\"25018\",\"end\":\"25460\"},{\"start\":\"25468\",\"end\":\"25676\"},{\"start\":\"25692\",\"end\":\"27755\"},{\"start\":\"27774\",\"end\":\"28012\"},{\"start\":\"28014\",\"end\":\"28270\"},{\"start\":\"28272\",\"end\":\"29608\"},{\"start\":\"29610\",\"end\":\"30370\"},{\"start\":\"30391\",\"end\":\"30861\"},{\"start\":\"30863\",\"end\":\"31347\"},{\"start\":\"31407\",\"end\":\"32412\"},{\"start\":\"32483\",\"end\":\"32556\"},{\"start\":\"32617\",\"end\":\"33184\"},{\"start\":\"33231\",\"end\":\"33254\"},{\"start\":\"33356\",\"end\":\"34367\"},{\"start\":\"34418\",\"end\":\"34579\"}]", "formula": "[{\"start\":\"10966\",\"end\":\"11107\",\"attributes\":{\"id\":\"formula_0\"}},{\"start\":\"12366\",\"end\":\"12410\",\"attributes\":{\"id\":\"formula_1\"}},{\"start\":\"12708\",\"end\":\"12842\",\"attributes\":{\"id\":\"formula_2\"}},{\"start\":\"12887\",\"end\":\"12904\",\"attributes\":{\"id\":\"formula_3\"}},{\"start\":\"13569\",\"end\":\"13678\",\"attributes\":{\"id\":\"formula_4\"}},{\"start\":\"14102\",\"end\":\"14261\",\"attributes\":{\"id\":\"formula_5\"}},{\"start\":\"14556\",\"end\":\"14776\",\"attributes\":{\"id\":\"formula_6\"}},{\"start\":\"14995\",\"end\":\"15018\",\"attributes\":{\"id\":\"formula_7\"}},{\"start\":\"17336\",\"end\":\"17413\",\"attributes\":{\"id\":\"formula_8\"}},{\"start\":\"17566\",\"end\":\"17656\",\"attributes\":{\"id\":\"formula_9\"}},{\"start\":\"18404\",\"end\":\"18443\",\"attributes\":{\"id\":\"formula_10\"}},{\"start\":\"18719\",\"end\":\"18740\",\"attributes\":{\"id\":\"formula_11\"}},{\"start\":\"18912\",\"end\":\"18944\",\"attributes\":{\"id\":\"formula_12\"}},{\"start\":\"19478\",\"end\":\"19710\",\"attributes\":{\"id\":\"formula_13\"}},{\"start\":\"20316\",\"end\":\"20325\",\"attributes\":{\"id\":\"formula_14\"}},{\"start\":\"20358\",\"end\":\"20386\",\"attributes\":{\"id\":\"formula_15\"}},{\"start\":\"20467\",\"end\":\"20583\",\"attributes\":{\"id\":\"formula_16\"}},{\"start\":\"20683\",\"end\":\"20712\",\"attributes\":{\"id\":\"formula_17\"}},{\"start\":\"32413\",\"end\":\"32482\",\"attributes\":{\"id\":\"formula_18\"}},{\"start\":\"32557\",\"end\":\"32616\",\"attributes\":{\"id\":\"formula_19\"}},{\"start\":\"33185\",\"end\":\"33230\",\"attributes\":{\"id\":\"formula_20\"}},{\"start\":\"33255\",\"end\":\"33355\",\"attributes\":{\"id\":\"formula_21\"}}]", "table_ref": "[{\"start\":\"22612\",\"end\":\"22621\",\"attributes\":{\"ref_id\":\"tab_1\"}},{\"start\":\"23190\",\"end\":\"23200\",\"attributes\":{\"ref_id\":\"tab_1\"}},{\"start\":\"27893\",\"end\":\"27909\",\"attributes\":{\"ref_id\":\"tab_1\"}},{\"start\":\"27910\",\"end\":\"27918\",\"attributes\":{\"ref_id\":\"tab_1\"}},{\"start\":\"28439\",\"end\":\"28446\",\"attributes\":{\"ref_id\":\"tab_1\"}},{\"start\":\"29336\",\"end\":\"29344\",\"attributes\":{\"ref_id\":\"tab_1\"}},{\"start\":\"33691\",\"end\":\"33758\",\"attributes\":{\"ref_id\":\"tab_1\"}},{\"start\":\"34477\",\"end\":\"34485\",\"attributes\":{\"ref_id\":\"tab_1\"}}]", "section_header": "[{\"start\":\"1468\",\"end\":\"1483\"},{\"start\":\"9206\",\"end\":\"9217\"},{\"start\":\"15938\",\"end\":\"15956\"},{\"start\":\"22350\",\"end\":\"22364\"},{\"start\":\"22474\",\"end\":\"22485\"},{\"start\":\"25463\",\"end\":\"25466\"},{\"start\":\"25679\",\"end\":\"25690\"},{\"start\":\"27758\",\"end\":\"27772\"},{\"start\":\"30373\",\"end\":\"30389\"},{\"start\":\"31350\",\"end\":\"31364\"},{\"start\":\"31367\",\"end\":\"31405\"},{\"start\":\"34370\",\"end\":\"34403\"},{\"start\":\"34406\",\"end\":\"34416\"},{\"start\":\"36009\",\"end\":\"36025\"},{\"start\":\"36280\",\"end\":\"36310\"},{\"start\":\"38390\",\"end\":\"38399\"},{\"start\":\"40220\",\"end\":\"40230\"},{\"start\":\"40695\",\"end\":\"40706\"},{\"start\":\"42697\",\"end\":\"42707\"}]", "table": "[{\"start\":\"38627\",\"end\":\"40218\"},{\"start\":\"40594\",\"end\":\"40693\"},{\"start\":\"41691\",\"end\":\"42695\"},{\"start\":\"43085\",\"end\":\"43171\"}]", "figure_caption": "[{\"start\":\"34582\",\"end\":\"36007\"},{\"start\":\"36028\",\"end\":\"36278\"},{\"start\":\"36315\",\"end\":\"38050\"},{\"start\":\"38053\",\"end\":\"38388\"},{\"start\":\"38401\",\"end\":\"38627\"},{\"start\":\"40233\",\"end\":\"40594\"},{\"start\":\"40710\",\"end\":\"41691\"},{\"start\":\"42710\",\"end\":\"43085\"}]", "figure_ref": "[{\"start\":\"29013\",\"end\":\"29021\"},{\"start\":\"29349\",\"end\":\"29357\"},{\"start\":\"34279\",\"end\":\"34294\"},{\"start\":\"34325\",\"end\":\"34340\"}]", "bib_author_first_name": "[{\"start\":\"43872\",\"end\":\"43873\"},{\"start\":\"43883\",\"end\":\"43884\"},{\"start\":\"43885\",\"end\":\"43886\"},{\"start\":\"44151\",\"end\":\"44152\"},{\"start\":\"44153\",\"end\":\"44154\"},{\"start\":\"44161\",\"end\":\"44162\"},{\"start\":\"44516\",\"end\":\"44517\"},{\"start\":\"44530\",\"end\":\"44531\"},{\"start\":\"44820\",\"end\":\"44821\"},{\"start\":\"45015\",\"end\":\"45016\"},{\"start\":\"45024\",\"end\":\"45025\"},{\"start\":\"45037\",\"end\":\"45038\"},{\"start\":\"45050\",\"end\":\"45051\"},{\"start\":\"45059\",\"end\":\"45060\"},{\"start\":\"45301\",\"end\":\"45302\"},{\"start\":\"45312\",\"end\":\"45313\"},{\"start\":\"45314\",\"end\":\"45315\"},{\"start\":\"45326\",\"end\":\"45327\"},{\"start\":\"45337\",\"end\":\"45338\"},{\"start\":\"45352\",\"end\":\"45353\"},{\"start\":\"45713\",\"end\":\"45714\"},{\"start\":\"45722\",\"end\":\"45723\"},{\"start\":\"45731\",\"end\":\"45732\"},{\"start\":\"45967\",\"end\":\"45968\"},{\"start\":\"45977\",\"end\":\"45978\"},{\"start\":\"45989\",\"end\":\"45990\"},{\"start\":\"45995\",\"end\":\"45996\"},{\"start\":\"46008\",\"end\":\"46009\"},{\"start\":\"46010\",\"end\":\"46011\"},{\"start\":\"46301\",\"end\":\"46302\"},{\"start\":\"46303\",\"end\":\"46304\"},{\"start\":\"46312\",\"end\":\"46313\"},{\"start\":\"46322\",\"end\":\"46323\"},{\"start\":\"46341\",\"end\":\"46342\"},{\"start\":\"46343\",\"end\":\"46344\"},{\"start\":\"46656\",\"end\":\"46657\"},{\"start\":\"46666\",\"end\":\"46667\"},{\"start\":\"46675\",\"end\":\"46676\"},{\"start\":\"46688\",\"end\":\"46689\"},{\"start\":\"46690\",\"end\":\"46691\"},{\"start\":\"46706\",\"end\":\"46707\"},{\"start\":\"47068\",\"end\":\"47069\"},{\"start\":\"47070\",\"end\":\"47071\"},{\"start\":\"47079\",\"end\":\"47080\"},{\"start\":\"47089\",\"end\":\"47090\"},{\"start\":\"47091\",\"end\":\"47096\"},{\"start\":\"47108\",\"end\":\"47109\"},{\"start\":\"47110\",\"end\":\"47111\"},{\"start\":\"47444\",\"end\":\"47445\"},{\"start\":\"47455\",\"end\":\"47456\"},{\"start\":\"47470\",\"end\":\"47471\"},{\"start\":\"47479\",\"end\":\"47480\"},{\"start\":\"47491\",\"end\":\"47492\"},{\"start\":\"47750\",\"end\":\"47751\"},{\"start\":\"47759\",\"end\":\"47760\"},{\"start\":\"47765\",\"end\":\"47766\"},{\"start\":\"47776\",\"end\":\"47777\"},{\"start\":\"47787\",\"end\":\"47788\"},{\"start\":\"48042\",\"end\":\"48043\"},{\"start\":\"48052\",\"end\":\"48053\"},{\"start\":\"48059\",\"end\":\"48060\"},{\"start\":\"48072\",\"end\":\"48073\"},{\"start\":\"48074\",\"end\":\"48075\"},{\"start\":\"48088\",\"end\":\"48089\"},{\"start\":\"48090\",\"end\":\"48091\"},{\"start\":\"48422\",\"end\":\"48423\"},{\"start\":\"48433\",\"end\":\"48434\"},{\"start\":\"48440\",\"end\":\"48441\"},{\"start\":\"48451\",\"end\":\"48452\"},{\"start\":\"48462\",\"end\":\"48463\"},{\"start\":\"48471\",\"end\":\"48472\"},{\"start\":\"48480\",\"end\":\"48481\"},{\"start\":\"48779\",\"end\":\"48780\"},{\"start\":\"48786\",\"end\":\"48787\"},{\"start\":\"48973\",\"end\":\"48974\"},{\"start\":\"48986\",\"end\":\"48987\"},{\"start\":\"48995\",\"end\":\"48996\"},{\"start\":\"49003\",\"end\":\"49004\"},{\"start\":\"49357\",\"end\":\"49358\"},{\"start\":\"49368\",\"end\":\"49369\"},{\"start\":\"49379\",\"end\":\"49380\"},{\"start\":\"49626\",\"end\":\"49627\"},{\"start\":\"49635\",\"end\":\"49636\"},{\"start\":\"49913\",\"end\":\"49914\"},{\"start\":\"49923\",\"end\":\"49924\"},{\"start\":\"49931\",\"end\":\"49932\"},{\"start\":\"49939\",\"end\":\"49940\"},{\"start\":\"49941\",\"end\":\"49942\"},{\"start\":\"50203\",\"end\":\"50204\"},{\"start\":\"50214\",\"end\":\"50215\"},{\"start\":\"50451\",\"end\":\"50452\"},{\"start\":\"50462\",\"end\":\"50463\"},{\"start\":\"50473\",\"end\":\"50474\"},{\"start\":\"50479\",\"end\":\"50480\"},{\"start\":\"50490\",\"end\":\"50491\"},{\"start\":\"50724\",\"end\":\"50725\"},{\"start\":\"50734\",\"end\":\"50735\"},{\"start\":\"50745\",\"end\":\"50746\"},{\"start\":\"50756\",\"end\":\"50757\"},{\"start\":\"51011\",\"end\":\"51012\"},{\"start\":\"51023\",\"end\":\"51024\"},{\"start\":\"51025\",\"end\":\"51026\"},{\"start\":\"51032\",\"end\":\"51033\"},{\"start\":\"51034\",\"end\":\"51035\"},{\"start\":\"51249\",\"end\":\"51250\"},{\"start\":\"51261\",\"end\":\"51262\"},{\"start\":\"51263\",\"end\":\"51264\"},{\"start\":\"51270\",\"end\":\"51271\"},{\"start\":\"51567\",\"end\":\"51568\"},{\"start\":\"51575\",\"end\":\"51576\"},{\"start\":\"51590\",\"end\":\"51591\"},{\"start\":\"51831\",\"end\":\"51832\"},{\"start\":\"52029\",\"end\":\"52030\"},{\"start\":\"52042\",\"end\":\"52043\"},{\"start\":\"52052\",\"end\":\"52053\"},{\"start\":\"52296\",\"end\":\"52297\"},{\"start\":\"52316\",\"end\":\"52317\"},{\"start\":\"52328\",\"end\":\"52329\"},{\"start\":\"52344\",\"end\":\"52345\"},{\"start\":\"52346\",\"end\":\"52347\"},{\"start\":\"52536\",\"end\":\"52537\"},{\"start\":\"52737\",\"end\":\"52738\"},{\"start\":\"52749\",\"end\":\"52750\"},{\"start\":\"52761\",\"end\":\"52762\"},{\"start\":\"52997\",\"end\":\"52998\"},{\"start\":\"53010\",\"end\":\"53011\"},{\"start\":\"53020\",\"end\":\"53021\"},{\"start\":\"53276\",\"end\":\"53277\"},{\"start\":\"53286\",\"end\":\"53287\"},{\"start\":\"53506\",\"end\":\"53507\"},{\"start\":\"53515\",\"end\":\"53516\"},{\"start\":\"53525\",\"end\":\"53526\"},{\"start\":\"53721\",\"end\":\"53722\"},{\"start\":\"53945\",\"end\":\"53946\"},{\"start\":\"54237\",\"end\":\"54238\"},{\"start\":\"54239\",\"end\":\"54240\"},{\"start\":\"54249\",\"end\":\"54250\"},{\"start\":\"54251\",\"end\":\"54252\"},{\"start\":\"54567\",\"end\":\"54568\"},{\"start\":\"54577\",\"end\":\"54578\"},{\"start\":\"54815\",\"end\":\"54816\"},{\"start\":\"54817\",\"end\":\"54818\"},{\"start\":\"55087\",\"end\":\"55088\"},{\"start\":\"55100\",\"end\":\"55101\"},{\"start\":\"55110\",\"end\":\"55111\"},{\"start\":\"55359\",\"end\":\"55360\"},{\"start\":\"55361\",\"end\":\"55362\"},{\"start\":\"55373\",\"end\":\"55374\"}]", "bib_author_last_name": "[{\"start\":\"43874\",\"end\":\"43881\"},{\"start\":\"43887\",\"end\":\"43893\"},{\"start\":\"44155\",\"end\":\"44159\"},{\"start\":\"44163\",\"end\":\"44173\"},{\"start\":\"44518\",\"end\":\"44528\"},{\"start\":\"44532\",\"end\":\"44537\"},{\"start\":\"44822\",\"end\":\"44829\"},{\"start\":\"45017\",\"end\":\"45022\"},{\"start\":\"45026\",\"end\":\"45035\"},{\"start\":\"45039\",\"end\":\"45048\"},{\"start\":\"45052\",\"end\":\"45057\"},{\"start\":\"45061\",\"end\":\"45068\"},{\"start\":\"45303\",\"end\":\"45310\"},{\"start\":\"45316\",\"end\":\"45324\"},{\"start\":\"45328\",\"end\":\"45335\"},{\"start\":\"45339\",\"end\":\"45350\"},{\"start\":\"45354\",\"end\":\"45372\"},{\"start\":\"45715\",\"end\":\"45720\"},{\"start\":\"45724\",\"end\":\"45729\"},{\"start\":\"45733\",\"end\":\"45739\"},{\"start\":\"45969\",\"end\":\"45975\"},{\"start\":\"45979\",\"end\":\"45987\"},{\"start\":\"45991\",\"end\":\"45993\"},{\"start\":\"45997\",\"end\":\"46006\"},{\"start\":\"46012\",\"end\":\"46022\"},{\"start\":\"46305\",\"end\":\"46310\"},{\"start\":\"46314\",\"end\":\"46320\"},{\"start\":\"46324\",\"end\":\"46339\"},{\"start\":\"46345\",\"end\":\"46352\"},{\"start\":\"46658\",\"end\":\"46664\"},{\"start\":\"46668\",\"end\":\"46673\"},{\"start\":\"46677\",\"end\":\"46686\"},{\"start\":\"46692\",\"end\":\"46704\"},{\"start\":\"46708\",\"end\":\"46714\"},{\"start\":\"47072\",\"end\":\"47077\"},{\"start\":\"47081\",\"end\":\"47087\"},{\"start\":\"47097\",\"end\":\"47106\"},{\"start\":\"47112\",\"end\":\"47119\"},{\"start\":\"47446\",\"end\":\"47453\"},{\"start\":\"47457\",\"end\":\"47468\"},{\"start\":\"47472\",\"end\":\"47477\"},{\"start\":\"47481\",\"end\":\"47489\"},{\"start\":\"47493\",\"end\":\"47500\"},{\"start\":\"47752\",\"end\":\"47757\"},{\"start\":\"47761\",\"end\":\"47763\"},{\"start\":\"47767\",\"end\":\"47774\"},{\"start\":\"47778\",\"end\":\"47785\"},{\"start\":\"47789\",\"end\":\"47794\"},{\"start\":\"48044\",\"end\":\"48050\"},{\"start\":\"48054\",\"end\":\"48057\"},{\"start\":\"48061\",\"end\":\"48070\"},{\"start\":\"48076\",\"end\":\"48086\"},{\"start\":\"48092\",\"end\":\"48100\"},{\"start\":\"48424\",\"end\":\"48431\"},{\"start\":\"48435\",\"end\":\"48438\"},{\"start\":\"48442\",\"end\":\"48449\"},{\"start\":\"48453\",\"end\":\"48460\"},{\"start\":\"48464\",\"end\":\"48469\"},{\"start\":\"48473\",\"end\":\"48478\"},{\"start\":\"48482\",\"end\":\"48489\"},{\"start\":\"48781\",\"end\":\"48784\"},{\"start\":\"48788\",\"end\":\"48792\"},{\"start\":\"48975\",\"end\":\"48984\"},{\"start\":\"48988\",\"end\":\"48993\"},{\"start\":\"48997\",\"end\":\"49001\"},{\"start\":\"49005\",\"end\":\"49011\"},{\"start\":\"49359\",\"end\":\"49366\"},{\"start\":\"49370\",\"end\":\"49377\"},{\"start\":\"49381\",\"end\":\"49392\"},{\"start\":\"49628\",\"end\":\"49633\"},{\"start\":\"49637\",\"end\":\"49642\"},{\"start\":\"49915\",\"end\":\"49921\"},{\"start\":\"49925\",\"end\":\"49929\"},{\"start\":\"49933\",\"end\":\"49937\"},{\"start\":\"49943\",\"end\":\"49946\"},{\"start\":\"50205\",\"end\":\"50212\"},{\"start\":\"50216\",\"end\":\"50223\"},{\"start\":\"50453\",\"end\":\"50460\"},{\"start\":\"50464\",\"end\":\"50471\"},{\"start\":\"50475\",\"end\":\"50477\"},{\"start\":\"50481\",\"end\":\"50488\"},{\"start\":\"50492\",\"end\":\"50497\"},{\"start\":\"50726\",\"end\":\"50732\"},{\"start\":\"50736\",\"end\":\"50743\"},{\"start\":\"50747\",\"end\":\"50754\"},{\"start\":\"50758\",\"end\":\"50763\"},{\"start\":\"51013\",\"end\":\"51021\"},{\"start\":\"51027\",\"end\":\"51030\"},{\"start\":\"51036\",\"end\":\"51046\"},{\"start\":\"51251\",\"end\":\"51259\"},{\"start\":\"51265\",\"end\":\"51268\"},{\"start\":\"51272\",\"end\":\"51282\"},{\"start\":\"51569\",\"end\":\"51573\"},{\"start\":\"51577\",\"end\":\"51588\"},{\"start\":\"51592\",\"end\":\"51600\"},{\"start\":\"51833\",\"end\":\"51839\"},{\"start\":\"52031\",\"end\":\"52040\"},{\"start\":\"52044\",\"end\":\"52050\"},{\"start\":\"52054\",\"end\":\"52060\"},{\"start\":\"52298\",\"end\":\"52314\"},{\"start\":\"52318\",\"end\":\"52326\"},{\"start\":\"52330\",\"end\":\"52342\"},{\"start\":\"52348\",\"end\":\"52356\"},{\"start\":\"52538\",\"end\":\"52544\"},{\"start\":\"52739\",\"end\":\"52747\"},{\"start\":\"52751\",\"end\":\"52759\"},{\"start\":\"52763\",\"end\":\"52769\"},{\"start\":\"52999\",\"end\":\"53008\"},{\"start\":\"53012\",\"end\":\"53018\"},{\"start\":\"53022\",\"end\":\"53028\"},{\"start\":\"53278\",\"end\":\"53284\"},{\"start\":\"53288\",\"end\":\"53299\"},{\"start\":\"53508\",\"end\":\"53513\"},{\"start\":\"53517\",\"end\":\"53523\"},{\"start\":\"53527\",\"end\":\"53533\"},{\"start\":\"53723\",\"end\":\"53729\"},{\"start\":\"53947\",\"end\":\"53956\"},{\"start\":\"54241\",\"end\":\"54247\"},{\"start\":\"54253\",\"end\":\"54260\"},{\"start\":\"54569\",\"end\":\"54575\"},{\"start\":\"54579\",\"end\":\"54585\"},{\"start\":\"54819\",\"end\":\"54824\"},{\"start\":\"55089\",\"end\":\"55098\"},{\"start\":\"55102\",\"end\":\"55108\"},{\"start\":\"55112\",\"end\":\"55119\"},{\"start\":\"55363\",\"end\":\"55371\"},{\"start\":\"55375\",\"end\":\"55384\"}]", "bib_entry": "[{\"start\":\"43843\",\"end\":\"44030\",\"attributes\":{\"matched_paper_id\":\"143133374\",\"id\":\"b0\"}},{\"start\":\"44032\",\"end\":\"44426\",\"attributes\":{\"matched_paper_id\":\"91168921\",\"id\":\"b1\"}},{\"start\":\"44428\",\"end\":\"44779\",\"attributes\":{\"matched_paper_id\":\"3298854\",\"id\":\"b2\"}},{\"start\":\"44781\",\"end\":\"44980\",\"attributes\":{\"matched_paper_id\":\"67276027\",\"id\":\"b3\"}},{\"start\":\"44982\",\"end\":\"45257\",\"attributes\":{\"matched_paper_id\":\"197660230\",\"id\":\"b4\"}},{\"start\":\"45259\",\"end\":\"45663\",\"attributes\":{\"matched_paper_id\":\"2077168\",\"id\":\"b5\"}},{\"start\":\"45665\",\"end\":\"45936\",\"attributes\":{\"matched_paper_id\":\"7567061\",\"id\":\"b6\"}},{\"start\":\"45938\",\"end\":\"46232\",\"attributes\":{\"matched_paper_id\":\"75455\",\"id\":\"b7\"}},{\"start\":\"46234\",\"end\":\"46598\",\"attributes\":{\"matched_paper_id\":\"156056158\",\"id\":\"b8\"}},{\"start\":\"46600\",\"end\":\"46954\",\"attributes\":{\"matched_paper_id\":\"3535298\",\"id\":\"b9\"}},{\"start\":\"46956\",\"end\":\"47396\",\"attributes\":{\"matched_paper_id\":\"1911971\",\"id\":\"b10\"}},{\"start\":\"47398\",\"end\":\"47717\",\"attributes\":{\"matched_paper_id\":\"4725675\",\"id\":\"b11\"}},{\"start\":\"47719\",\"end\":\"47984\",\"attributes\":{\"matched_paper_id\":\"490669\",\"id\":\"b12\"}},{\"start\":\"47986\",\"end\":\"48341\",\"attributes\":{\"matched_paper_id\":\"3801798\",\"id\":\"b13\"}},{\"start\":\"48343\",\"end\":\"48752\",\"attributes\":{\"matched_paper_id\":\"6161478\",\"id\":\"b14\"}},{\"start\":\"48754\",\"end\":\"48909\",\"attributes\":{\"id\":\"b15\",\"doi\":\"arXiv:1707.00780\"}},{\"start\":\"48911\",\"end\":\"49303\",\"attributes\":{\"matched_paper_id\":\"10352172\",\"id\":\"b16\"}},{\"start\":\"49305\",\"end\":\"49592\",\"attributes\":{\"matched_paper_id\":\"3945595\",\"id\":\"b17\"}},{\"start\":\"49594\",\"end\":\"49817\",\"attributes\":{\"matched_paper_id\":\"49561627\",\"id\":\"b18\"}},{\"start\":\"49819\",\"end\":\"50156\",\"attributes\":{\"id\":\"b19\",\"doi\":\"arXiv:1707.00075\"}},{\"start\":\"50158\",\"end\":\"50415\",\"attributes\":{\"matched_paper_id\":\"4986726\",\"id\":\"b20\"}},{\"start\":\"50417\",\"end\":\"50660\",\"attributes\":{\"id\":\"b21\",\"doi\":\"arXiv:1511.00830\"}},{\"start\":\"50662\",\"end\":\"50978\",\"attributes\":{\"matched_paper_id\":\"3419504\",\"id\":\"b22\"}},{\"start\":\"50980\",\"end\":\"51195\",\"attributes\":{\"id\":\"b23\",\"doi\":\"arXiv:1710.04394\"}},{\"start\":\"51197\",\"end\":\"51497\",\"attributes\":{\"matched_paper_id\":\"173169110\",\"id\":\"b24\"}},{\"start\":\"51499\",\"end\":\"51784\",\"attributes\":{\"id\":\"b25\",\"doi\":\"arXiv:1805.08097\"}},{\"start\":\"51786\",\"end\":\"51972\",\"attributes\":{\"matched_paper_id\":\"14682470\",\"id\":\"b26\"}},{\"start\":\"51974\",\"end\":\"52259\",\"attributes\":{\"matched_paper_id\":\"8558103\",\"id\":\"b27\"}},{\"start\":\"52261\",\"end\":\"52497\",\"attributes\":{\"id\":\"b28\"}},{\"start\":\"52499\",\"end\":\"52699\",\"attributes\":{\"id\":\"b29\"}},{\"start\":\"52701\",\"end\":\"52922\",\"attributes\":{\"matched_paper_id\":\"6617228\",\"id\":\"b30\"}},{\"start\":\"52924\",\"end\":\"53213\",\"attributes\":{\"id\":\"b31\",\"doi\":\"arXiv:1706.08934\"}},{\"start\":\"53215\",\"end\":\"53462\",\"attributes\":{\"id\":\"b32\",\"doi\":\"arXiv:1710.03184\"}},{\"start\":\"53464\",\"end\":\"53683\",\"attributes\":{\"id\":\"b33\",\"doi\":\"arXiv:1901.10080\"}},{\"start\":\"53685\",\"end\":\"53906\",\"attributes\":{\"matched_paper_id\":\"9803204\",\"id\":\"b34\"}},{\"start\":\"53908\",\"end\":\"54190\",\"attributes\":{\"matched_paper_id\":\"15216083\",\"id\":\"b35\"}},{\"start\":\"54192\",\"end\":\"54491\",\"attributes\":{\"matched_paper_id\":\"16619709\",\"id\":\"b36\"}},{\"start\":\"54493\",\"end\":\"54758\",\"attributes\":{\"matched_paper_id\":\"602348\",\"id\":\"b37\"}},{\"start\":\"54760\",\"end\":\"55017\",\"attributes\":{\"matched_paper_id\":\"17735965\",\"id\":\"b38\"}},{\"start\":\"55019\",\"end\":\"55283\",\"attributes\":{\"id\":\"b39\"}},{\"start\":\"55285\",\"end\":\"55609\",\"attributes\":{\"matched_paper_id\":\"463216\",\"id\":\"b40\"}}]", "bib_title": "[{\"start\":\"43843\",\"end\":\"43870\"},{\"start\":\"44032\",\"end\":\"44149\"},{\"start\":\"44428\",\"end\":\"44514\"},{\"start\":\"44781\",\"end\":\"44818\"},{\"start\":\"44982\",\"end\":\"45013\"},{\"start\":\"45259\",\"end\":\"45299\"},{\"start\":\"45665\",\"end\":\"45711\"},{\"start\":\"45938\",\"end\":\"45965\"},{\"start\":\"46234\",\"end\":\"46299\"},{\"start\":\"46600\",\"end\":\"46654\"},{\"start\":\"46956\",\"end\":\"47066\"},{\"start\":\"47398\",\"end\":\"47442\"},{\"start\":\"47719\",\"end\":\"47748\"},{\"start\":\"47986\",\"end\":\"48040\"},{\"start\":\"48343\",\"end\":\"48420\"},{\"start\":\"48911\",\"end\":\"48971\"},{\"start\":\"49305\",\"end\":\"49355\"},{\"start\":\"49594\",\"end\":\"49624\"},{\"start\":\"50158\",\"end\":\"50201\"},{\"start\":\"50662\",\"end\":\"50722\"},{\"start\":\"51197\",\"end\":\"51247\"},{\"start\":\"51786\",\"end\":\"51829\"},{\"start\":\"51974\",\"end\":\"52027\"},{\"start\":\"52701\",\"end\":\"52735\"},{\"start\":\"53685\",\"end\":\"53719\"},{\"start\":\"53908\",\"end\":\"53943\"},{\"start\":\"54192\",\"end\":\"54235\"},{\"start\":\"54493\",\"end\":\"54565\"},{\"start\":\"54760\",\"end\":\"54813\"},{\"start\":\"55285\",\"end\":\"55357\"}]", "bib_author": "[{\"start\":\"43872\",\"end\":\"43883\"},{\"start\":\"43883\",\"end\":\"43895\"},{\"start\":\"44151\",\"end\":\"44161\"},{\"start\":\"44161\",\"end\":\"44175\"},{\"start\":\"44516\",\"end\":\"44530\"},{\"start\":\"44530\",\"end\":\"44539\"},{\"start\":\"44820\",\"end\":\"44831\"},{\"start\":\"45015\",\"end\":\"45024\"},{\"start\":\"45024\",\"end\":\"45037\"},{\"start\":\"45037\",\"end\":\"45050\"},{\"start\":\"45050\",\"end\":\"45059\"},{\"start\":\"45059\",\"end\":\"45070\"},{\"start\":\"45301\",\"end\":\"45312\"},{\"start\":\"45312\",\"end\":\"45326\"},{\"start\":\"45326\",\"end\":\"45337\"},{\"start\":\"45337\",\"end\":\"45352\"},{\"start\":\"45352\",\"end\":\"45374\"},{\"start\":\"45713\",\"end\":\"45722\"},{\"start\":\"45722\",\"end\":\"45731\"},{\"start\":\"45731\",\"end\":\"45741\"},{\"start\":\"45967\",\"end\":\"45977\"},{\"start\":\"45977\",\"end\":\"45989\"},{\"start\":\"45989\",\"end\":\"45995\"},{\"start\":\"45995\",\"end\":\"46008\"},{\"start\":\"46008\",\"end\":\"46024\"},{\"start\":\"46301\",\"end\":\"46312\"},{\"start\":\"46312\",\"end\":\"46322\"},{\"start\":\"46322\",\"end\":\"46341\"},{\"start\":\"46341\",\"end\":\"46354\"},{\"start\":\"46656\",\"end\":\"46666\"},{\"start\":\"46666\",\"end\":\"46675\"},{\"start\":\"46675\",\"end\":\"46688\"},{\"start\":\"46688\",\"end\":\"46706\"},{\"start\":\"46706\",\"end\":\"46716\"},{\"start\":\"47068\",\"end\":\"47079\"},{\"start\":\"47079\",\"end\":\"47089\"},{\"start\":\"47089\",\"end\":\"47108\"},{\"start\":\"47108\",\"end\":\"47121\"},{\"start\":\"47444\",\"end\":\"47455\"},{\"start\":\"47455\",\"end\":\"47470\"},{\"start\":\"47470\",\"end\":\"47479\"},{\"start\":\"47479\",\"end\":\"47491\"},{\"start\":\"47491\",\"end\":\"47502\"},{\"start\":\"47750\",\"end\":\"47759\"},{\"start\":\"47759\",\"end\":\"47765\"},{\"start\":\"47765\",\"end\":\"47776\"},{\"start\":\"47776\",\"end\":\"47787\"},{\"start\":\"47787\",\"end\":\"47796\"},{\"start\":\"48042\",\"end\":\"48052\"},{\"start\":\"48052\",\"end\":\"48059\"},{\"start\":\"48059\",\"end\":\"48072\"},{\"start\":\"48072\",\"end\":\"48088\"},{\"start\":\"48088\",\"end\":\"48102\"},{\"start\":\"48422\",\"end\":\"48433\"},{\"start\":\"48433\",\"end\":\"48440\"},{\"start\":\"48440\",\"end\":\"48451\"},{\"start\":\"48451\",\"end\":\"48462\"},{\"start\":\"48462\",\"end\":\"48471\"},{\"start\":\"48471\",\"end\":\"48480\"},{\"start\":\"48480\",\"end\":\"48491\"},{\"start\":\"48779\",\"end\":\"48786\"},{\"start\":\"48786\",\"end\":\"48794\"},{\"start\":\"48973\",\"end\":\"48986\"},{\"start\":\"48986\",\"end\":\"48995\"},{\"start\":\"48995\",\"end\":\"49003\"},{\"start\":\"49003\",\"end\":\"49013\"},{\"start\":\"49357\",\"end\":\"49368\"},{\"start\":\"49368\",\"end\":\"49379\"},{\"start\":\"49379\",\"end\":\"49394\"},{\"start\":\"49626\",\"end\":\"49635\"},{\"start\":\"49635\",\"end\":\"49644\"},{\"start\":\"49913\",\"end\":\"49923\"},{\"start\":\"49923\",\"end\":\"49931\"},{\"start\":\"49931\",\"end\":\"49939\"},{\"start\":\"49939\",\"end\":\"49948\"},{\"start\":\"50203\",\"end\":\"50214\"},{\"start\":\"50214\",\"end\":\"50225\"},{\"start\":\"50451\",\"end\":\"50462\"},{\"start\":\"50462\",\"end\":\"50473\"},{\"start\":\"50473\",\"end\":\"50479\"},{\"start\":\"50479\",\"end\":\"50490\"},{\"start\":\"50490\",\"end\":\"50499\"},{\"start\":\"50724\",\"end\":\"50734\"},{\"start\":\"50734\",\"end\":\"50745\"},{\"start\":\"50745\",\"end\":\"50756\"},{\"start\":\"50756\",\"end\":\"50765\"},{\"start\":\"51011\",\"end\":\"51023\"},{\"start\":\"51023\",\"end\":\"51032\"},{\"start\":\"51032\",\"end\":\"51048\"},{\"start\":\"51249\",\"end\":\"51261\"},{\"start\":\"51261\",\"end\":\"51270\"},{\"start\":\"51270\",\"end\":\"51284\"},{\"start\":\"51567\",\"end\":\"51575\"},{\"start\":\"51575\",\"end\":\"51590\"},{\"start\":\"51590\",\"end\":\"51602\"},{\"start\":\"51831\",\"end\":\"51841\"},{\"start\":\"52029\",\"end\":\"52042\"},{\"start\":\"52042\",\"end\":\"52052\"},{\"start\":\"52052\",\"end\":\"52062\"},{\"start\":\"52296\",\"end\":\"52316\"},{\"start\":\"52316\",\"end\":\"52328\"},{\"start\":\"52328\",\"end\":\"52344\"},{\"start\":\"52344\",\"end\":\"52358\"},{\"start\":\"52536\",\"end\":\"52546\"},{\"start\":\"52737\",\"end\":\"52749\"},{\"start\":\"52749\",\"end\":\"52761\"},{\"start\":\"52761\",\"end\":\"52771\"},{\"start\":\"52997\",\"end\":\"53010\"},{\"start\":\"53010\",\"end\":\"53020\"},{\"start\":\"53020\",\"end\":\"53030\"},{\"start\":\"53276\",\"end\":\"53286\"},{\"start\":\"53286\",\"end\":\"53301\"},{\"start\":\"53506\",\"end\":\"53515\"},{\"start\":\"53515\",\"end\":\"53525\"},{\"start\":\"53525\",\"end\":\"53535\"},{\"start\":\"53721\",\"end\":\"53731\"},{\"start\":\"53945\",\"end\":\"53958\"},{\"start\":\"54237\",\"end\":\"54249\"},{\"start\":\"54249\",\"end\":\"54262\"},{\"start\":\"54567\",\"end\":\"54577\"},{\"start\":\"54577\",\"end\":\"54587\"},{\"start\":\"54815\",\"end\":\"54826\"},{\"start\":\"55087\",\"end\":\"55100\"},{\"start\":\"55100\",\"end\":\"55110\"},{\"start\":\"55110\",\"end\":\"55121\"},{\"start\":\"55359\",\"end\":\"55373\"},{\"start\":\"55373\",\"end\":\"55386\"}]", "bib_venue": "[{\"start\":\"43895\",\"end\":\"43916\"},{\"start\":\"44175\",\"end\":\"44219\"},{\"start\":\"44539\",\"end\":\"44594\"},{\"start\":\"44831\",\"end\":\"44873\"},{\"start\":\"45070\",\"end\":\"45108\"},{\"start\":\"45374\",\"end\":\"45448\"},{\"start\":\"45741\",\"end\":\"45790\"},{\"start\":\"46024\",\"end\":\"46073\"},{\"start\":\"46354\",\"end\":\"46390\"},{\"start\":\"46716\",\"end\":\"46765\"},{\"start\":\"47121\",\"end\":\"47163\"},{\"start\":\"47502\",\"end\":\"47546\"},{\"start\":\"47796\",\"end\":\"47840\"},{\"start\":\"48102\",\"end\":\"48151\"},{\"start\":\"48491\",\"end\":\"48535\"},{\"start\":\"48754\",\"end\":\"48777\"},{\"start\":\"49013\",\"end\":\"49095\"},{\"start\":\"49394\",\"end\":\"49438\"},{\"start\":\"49644\",\"end\":\"49696\"},{\"start\":\"49819\",\"end\":\"49911\"},{\"start\":\"50225\",\"end\":\"50277\"},{\"start\":\"50417\",\"end\":\"50449\"},{\"start\":\"50765\",\"end\":\"50809\"},{\"start\":\"50980\",\"end\":\"51009\"},{\"start\":\"51284\",\"end\":\"51326\"},{\"start\":\"51499\",\"end\":\"51565\"},{\"start\":\"51841\",\"end\":\"51857\"},{\"start\":\"52062\",\"end\":\"52106\"},{\"start\":\"52261\",\"end\":\"52294\"},{\"start\":\"52499\",\"end\":\"52534\"},{\"start\":\"52771\",\"end\":\"52787\"},{\"start\":\"52924\",\"end\":\"52995\"},{\"start\":\"53215\",\"end\":\"53274\"},{\"start\":\"53464\",\"end\":\"53504\"},{\"start\":\"53731\",\"end\":\"53774\"},{\"start\":\"53958\",\"end\":\"54027\"},{\"start\":\"54262\",\"end\":\"54320\"},{\"start\":\"54587\",\"end\":\"54616\"},{\"start\":\"54826\",\"end\":\"54866\"},{\"start\":\"55019\",\"end\":\"55085\"},{\"start\":\"55386\",\"end\":\"55422\"}]"}}}, "year": 2023, "month": 12, "day": 17}