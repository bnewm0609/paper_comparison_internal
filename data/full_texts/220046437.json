{"id": 220046437, "updated": "2023-11-11 03:21:12.537", "metadata": {"title": "Connecting Embeddings for Knowledge Graph Entity Typing", "authors": "[{\"first\":\"Yu\",\"last\":\"Zhao\",\"middle\":[]},{\"first\":\"anxiang\",\"last\":\"zhang\",\"middle\":[]},{\"first\":\"Ruobing\",\"last\":\"Xie\",\"middle\":[]},{\"first\":\"Kang\",\"last\":\"Liu\",\"middle\":[]},{\"first\":\"Xiaojie\",\"last\":\"WANG\",\"middle\":[]}]", "venue": "ACL", "journal": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics", "publication_date": {"year": 2020, "month": null, "day": null}, "abstract": "Knowledge graph (KG) entity typing aims at inferring possible missing entity type instances in KG, which is a very significant but still under-explored subtask of knowledge graph completion. In this paper, we propose a novel approach for KG entity typing which is trained by jointly utilizing local typing knowledge from existing entity type assertions and global triple knowledge in KGs. Specifically, we present two distinct knowledge-driven effective mechanisms of entity type inference. Accordingly, we build two novel embedding models to realize the mechanisms. Afterward, a joint model via connecting them is used to infer missing entity type instances, which favors inferences that agree with both entity type instances and triple knowledge in KGs. Experimental results on two real-world datasets (Freebase and YAGO) demonstrate the effectiveness of our proposed mechanisms and models for improving KG entity typing. The source code and data of this paper can be obtained from: https://github.com/Adam1679/ConnectE .", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": "3044829529", "acl": "2020.acl-main.572", "pubmed": null, "pubmedcentral": null, "dblp": "journals/corr/abs-2007-10873", "doi": "10.18653/v1/2020.acl-main.572"}}, "content": {"source": {"pdf_hash": "6c9f582fcc048eaa5fe448837de62f1c6391f76b", "pdf_src": "ACL", "pdf_uri": "[\"https://www.aclweb.org/anthology/2020.acl-main.572.pdf\"]", "oa_url_match": true, "oa_info": {"license": "CCBY", "open_access_url": "https://www.aclweb.org/anthology/2020.acl-main.572.pdf", "status": "HYBRID"}}, "grobid": {"id": "b9bab1c1de8dde0463cdf8f8a974dde4a48d4752", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/6c9f582fcc048eaa5fe448837de62f1c6391f76b.txt", "contents": "\nConnecting Embeddings for Knowledge Graph Entity Typing\nAssociation for Computational LinguisticsCopyright Association for Computational LinguisticsJuly 5 -10, 2020. 2020\n\nYu Zhao \nFintech Innovation Center\nSchool of Economic Information Engineering\nSouthwestern University of Finance and Economics\nChengduChina\n\nAnxiang Zhang \nSchool of Computer Science\nCarnegie Mellon University\nPittsburghUSA\n\nRuobing Xie \nWeChat Search Application Department\nBeijingTencentChina\n\nKang Liu \nInstitute of Automation\nNational Laboratory of Pattern Recognition (NLPR)\nChinese Academy of Sciences\n100190BeijingChina\n\nUniversity of Chinese Academy of Sciences\n100049BeijingChina\n\nXiaojie Wang \nSchool of Computer Science\nBeijing University of Posts and Telecommunications\nBeijingChina\n\nConnecting Embeddings for Knowledge Graph Entity Typing\n\nProceedings of the 58th Annual Meeting of the Association for Computational Linguistics\nthe 58th Annual Meeting of the Association for Computational LinguisticsAssociation for Computational LinguisticsJuly 5 -10, 2020. 20206419 The source code and data of this paper can be obtained from: https://github.com/ Adam1679/ConnectE\nKnowledge graph (KG) entity typing aims at inferring possible missing entity type instances in KG, which is a very significant but still under-explored subtask of knowledge graph completion. In this paper, we propose a novel approach for KG entity typing which is trained by jointly utilizing local typing knowledge from existing entity type assertions and global triple knowledge from KGs. Specifically, we present two distinct knowledge-driven effective mechanisms of entity type inference. Accordingly, we build two novel embedding models to realize the mechanisms. Afterward, a joint model with them is used to infer missing entity type instances, which favors inferences that agree with both entity type instances and triple knowledge in KGs. Experimental results on two real-world datasets (Freebase and YAGO) demonstrate the effectiveness of our proposed mechanisms and models for improving KG entity typing. The source code and data of this paper can be obtained from: https://github.com/ Adam1679/ConnectE\n\nIntroduction\n\nThe past decade has witnessed great thrive in building web-scale knowledge graphs (KGs), such as Freebase (Bollacker et al., 2008), YAGO (Suchanek et al., 2007), Google Knowledge Graph (Dong et al., 2014), which usually consists of a huge amount of triples in the form of (head entity, relation, tail entity) (denoted (e, r,\u1ebd)). KGs usually suffer from incompleteness and miss important facts, jeopardizing their usefulness in downstream tasks such as question answering (Elsahar et al., 2018), semantic parsing (Berant et al., 2013), relation classification (Zeng et al., 2014). Hence, the task of * Equal Contribution. Corresponding author: Y. Zhao (zhaoyu@swufe.edu.cn). knowledge graph completion (KGC, i.e. completing knowledge graph entries) is extremely significant and attracts wide attention.\n\nThis paper concentrates on KG entity typing, i.e. inferring missing entity type instances in KGs, which is an important sub-problem of KGC. Entity type instances, each of which is in the formed of (entity, entity type) (denoted (e, t)), are essential entries of KGs and widely used in many NLP tasks such as relation extraction (Zhang et al., 2018;Jain et al., 2018), coreference resolution (Hajishirzi et al., 2013), entity linking (Gupta et al., 2017). Most previous works of KGC focus on inferring missing entities and relationships (Bordes et al., 2013;Wang et al., 2014;Lin et al., 2015;Dettmers et al., 2017;Ding et al., 2018;Nathani et al., 2019), paying less attention to entity type prediction. However, KGs also usually suffer from entity types incompleteness. For instance, 10% of entities in FB15k (Bordes et al., 2013), which have the /music/artist type, miss the /people/person type (Moon et al., 2017). KG entity type incompleteness leads to some type-involved algorithms in KG-driven tasks grossly inefficient or even unavailable.\n\nTo solve KG entity type incompleteness issue, in this paper we propose a novel embedding methodology to infer missing entity type instances that employs not only local typing knowledge from entity type assertions, as most conventional mod-els do, but also leverages global triple knowledge from KGs. Accordingly, we build two distinct knowledge-driven type inference mechanisms with these two kinds of structural knowledge.\n\nMechanism 1. Missing entity types of an entity can be found from other entities that are close to the entity in the embedding space, using local typing knowledge as in Fig.1(Mech.1).\n\nMechanism 2. Missing entity types of an (head or tail) entity can be inferred from the types of other (tail or head) entities through their relationships, using global triple knowledge as in Fig.1(Mech.2).\n\nThe main idea behind Mech.1 is based on the observation that the learned entities' embeddings by conventional KG embedding methods (Ji et al., 2016;Xie et al., 2016) cluster well according to their types in vector space. For instance, in Fig.1(Mech.1), given an entity Barack Obama, it's missing hierarchical type /people/person can be induced by the given hierarchical type of similar entity Donald Trump. In addition, the key motivation behind Mech.2 is that the relationship shall remain unchanged if the entities in a triple fact are replaced with their corresponding hierarchical types. For instance, given a global triple fact (Barack Obama, born in, Honolulu), under this assumption, we can induce a new type triple (/people/person, born in, /location/location) 1 . Formally, Honolulu \u2212 Barack Obama = /location/location \u2212 /people/person (= born in), which can be used to infer missing entity types, e.g. (Barack Obama, type=? ) via Barack Obama \u2212 Honolulu + /location/location = /people/person, as Mech.2 does. Fig.1 demonstrates a simple illustration of effective mechanisms of entity type inference. Both mechanisms are utilized to build our final composite model. Specifically, we build two embedding models to realize the two mechanisms respectively. First, considering entities and entity types are completely distinct objects, we build two distinct embedding spaces for them, i.e., entity space and entity type space. Accordingly, we encode (e, t) entity type instance by projecting the entity from entity space to entity type space with mapping matrix M, hence we have (1): M \u00b7 e t , called E2T. Moreover, we learn the plausibility of (t e , r, t\u1ebd) global type triple by newly generalizing from (e, r,\u1ebd) global triple fact, even though this type triple is not present originally. Following translating assumption (Bordes et al., 2013), we have (2): t\u1ebd \u2212 r \u2022 t e , called TRT. E2T and TRT are the implementation models of the two mechanisms. Fig.2 demonstrates a brief illustration of our models. A ranking-based embedding framework is used to train our models. Thereby, entities, entity hierarchical types, and relationships are all embedded into low-dimensional vector spaces, where the composite energy score of both E2T and TRT are computed and utilized to determine the optimal types for (entity, entity type=?) incomplete assertions. The experimental results on real-world datasets show that our composite model achieves significant and consistent improvement compared to all baselines in entity type prediction and achieves comparable performance in entity type classification.\n\nOur contributions are as follows:\n\n\u2022 We propose a novel framework for inferring missing entity type instances in KGs by connecting entity type instances and global triple information and correspondingly present two effective mechanisms.\n\n\u2022 Under these mechanisms, we propose two novel embedding-based models: one for predicting entity types given entities and another one to encode the interactions among entity types and relationships from KGs. A combination of both models are utilized to conduct entity type inference.\n\n\u2022 We conduct empirical experiments on two real-world datasets for entity type inference, which demonstrate our model can successfully take into account global triple information to improve KG entity typing.\n\n\nRelated Works\n\nEntity typing is valuable for many NLP tasks (Yaghoobzadeh et al., 2018), such as knowledge base population (Zhou et al., 2018), question answering (Elsahar et al., 2018), etc. In recent years, researchers attempt to mine fine-grained entity types (Yogatama et al., 2015;Choi et al., 2018;Xu and Barbosa, 2018;Yuan and Downey, 2018) with external text information, such as web search query logs (Pantel et al., 2012), the textual surface patterns (Yao et al., 2013), context representation (Abhishek et al., 2017), Wikipedia (Zhou et al., LM (Neelakantan et al., 2015) e t N/A e, t \u2208 R \u03ba entity type instances N/A PEM (Neelakantan et al., 2015) e UV t N/A e \u2208 R \u03ba , t \u2208 R , U \u2208 R \u03ba\u00d7d ,V \u2208 R \u00d7d entity type instance N/A RESCAL (Nickel et al., 2011) N/A e Mr\u1ebd e,\u1ebd \u2208 R \u03ba , Mr \u2208 R \u03ba\u00d7\u03ba mixed triple knowledge syn.\n\nRESCAL-ET (Moon et al., 2017) e \u2212 t 1 e Mr\u1ebd e,\u1ebd, t \u2208 R \u03ba , Mr \u2208 R \u03ba\u00d7\u03ba entity type inst./ triple know. asyn.\n\nHOLE (Nickel et al., 2016) N/A r (e \u1ebd) e, r,\u1ebd \u2208 R \u03ba mixed triple knowledge syn.\n\nHOLE-ET (Moon et al., 2017) e \u2212 t 1 r (e \u1ebd) e, r,\u1ebd, t \u2208 R \u03ba entity type inst./ triple know. asyn.\n\nTransE (Bordes et al., 2013) N/A e + r \u2212\u1ebd e, r,\u1ebd \u2208 R \u03ba mixed triple knowledge syn.\n\nTransE-ET (Moon et al., 2017) e \u2212 t 1 e + r \u2212\u1ebd e, r,\u1ebd, t \u2208 R \u03ba entity type inst./ triple know. asyn.\n\nETE (Moon et al., 2017) e \u2212 t 1 e +\u1ebd + c \u2212 r e, r,\u1ebd, c, t \u2208 R \u03ba entity type inst./ triple know. asyn.\nConnectE (our proposed) M \u00b7 e \u2212 t 2 2 e + r \u2212\u1ebd 2 2 , te + r \u2022 \u2212 t\u1ebd 2 2 e, r \u2208 R \u03ba , t, r \u2022 \u2208 R ,\nM \u2208 R \u00d7\u03ba entity type inst./ triple know. syn.\n\n2018). Despite their success, existing methods rely on additional external sources, which might not be feasible for some KGs.\n\nTo be more universal, Neelakantan et al. (2015) propose two embedding models, i.e. linear model (LM) and projection embedding model (PEM), which can infer missing entity types only with KG itself. Although PEM has more expressive power than LM, however, both of them ignore global triple knowledge, which could also be helpful for encoding entity type assertions via shared entities' embeddings. To address this issue, Moon et al. (2017) propose a state-of-the-art model (ETE) to combine triple knowledge and entity type instances for entity type prediction, and build two entity type embedding methodologies: (1) Synchronous training: treat (entity, entity type) assertions as special triple facts that have a unique relationship \"rdf:type\", e.g. (Barack Obama, \"rdf:type\", person), and encode all mixed triple facts (original triple data fused with all generated special ones) by conventional entity relation embedding models, such as RESCAL (Nickel et al., 2011), HOLE (Nickel et al., 2016) and TransE (Bordes et al., 2013). (2) Asynchronous training: first learn the entities' embeddings e by conventional entity relation embedding models mentioned above, and then only update entity types' embeddings t for min e \u2212 t 1 while keeping e fixed, called RESCAL-ET, HOLE-ET, TransE-ET and ETE. Although these approaches expect to explore global triple knowledge for entity type prediction, they still lack of expressive ability due to its simplicity of embeddings. In addition, they irrationally assume both the embeddings of entities and entity types being in the same latent space (\u2208 R \u03ba ). Since entities and entity types are completely distinct objects, it may not be reasonable to represent them in a common semantic space.\n\nIn this paper, we introduce an enhanced KG entity type embedding model with better expressing and reasoning capability considering both local entity typing information and global triple knowledge in KGs. Note that incorporating more external information (Jin et al., 2018;Neelakantan et al., 2015) is not the main focus in this paper, as we only consider the internal structural information in KGs instead, which correspondingly makes our work much more challenging but also more universal and flexible due to the limited information. Recently, (Lv et al., 2018;Hao et al., 2019) also attempt to embedding structural information in KG. However, the goals and models are very different from ours. They encodes the concepts, not hierarchical types. On the contrary, we focus on the latter not the former. Table 1 summarizes the energy functions and other different settings of entity type embedding models.\n\n\nEmbedding-based Framework\n\nWe consider a KG containing entity type instances of the form (e, t) \u2208 H (H is the training set consists of lots of (entity, entity type) assertions), where e \u2208 E (E is the set of all entities) is an entity in the KG with the type t \u2208 T (T is the set of all types). For example, e could be Barack Obama and t could be /people/person. As a single entity can have multiple types, entities in KG often miss some of their types. The aim of this work is to infer missing entity type instances in KGs.\n\nOur work concerns energy-based methods, which learn low-dimensional vector representations (embeddings) of atomic symbols (i.e. entities, entity hierarchical types, relationships). In this framework, we learn two submodels: (1) one for predicting entity types given entities, and (2) another one to encode the interactions among entity types and relationships from KGs. The joint action of both models in prediction allows us to use the connection between triple knowledge and entity type instances to perform KG entity typing.\n\n\nE2T: Mapping Entities to Types\n\nThe first model (E2T) of the framework concerns the learning of a function S e2t (e, t) with local typing knowledge from entity type instances, which is designed to score the similarity of an entity e and a type t. The main ideas behind this model are as follows:\n\n(1) Since the learned entity embeddings cluster well when they have the same or similar types, therefore, it is rather intuitive that the entity type embedding represents the projective common concept representation of a cluster of entities, i.e., f proj (e) t e , \u2200e \u2208 E. e (\u2208 R \u03ba ) is the embedding of the entity e, t e (\u2208 R ) is the embedding of the type t e . The entity type embedding represents common information of their entities, it thus should have fewer variates, i.e., < \u03ba. (2) Since the entities and entity types are totally distinct objects, we respectively build two embedding space for them, i.e., entity space and entity type space.\n\n(3) Inspired by the previous work TranSparse (Ji et al., 2016) projecting entities from entity space to relation space with operation matrix M, which we adapted, replacing relation space with entity type space, we thus define f proj (e) = M \u00b7 e ( t e ). Therefore, this model consists of first projecting entity embedding into entity type space, and then computing a similarity measure between this projection and an entity type embedding. The scoring function of E2T given (e, t) is:\nS e2t (e, t) = M \u00b7 e \u2212 t 2 2 ,(1)\nwhere M \u2208 R \u00d7\u03ba is a transfer matrix mapping entity embeddings into entity type space. The score is expected to be lower for a golden entity type instance and higher for an incorrect one.\n\n\nTRT: Encoding Triples in KGs\n\nUsing only entity type instances for training ignores much of relational knowledge that can leverage from triple facts in KGs. In order to connect this relational data with our model, we propose to learn entity type and relationship embeddings from global triple knowledge from KGs. The key motivations behind this model are: (1) As mentioned above, the entities cluster well according to their types. Therefore, we believe that an essential premise of a triple (head entity, relationship, tail entity) holds is that its corresponding entity types should first conform to this relationship. Hence, we can build a new entity type triple (head type, relationship, tail type) by replacing both head entity and tail entity with their corresponding types: i.e.\n\n(e, r,\u1ebd) replace \u2212\u2192 (t e , r, t\u1ebd). (e, r,\u1ebd) \u2208 D, D is the training set consists of a lot of triples. r \u2208 R (R is the set of relationships). t e and t\u1ebd stand for the hierarchical types of left entity e and right entity\u1ebd respectively. (2) Since the relationship r remains unchanged in replacement, we build two differentiated embeddings for the i-th relationship r i in two embedding spaces: r i (\u2208 R \u03ba ) in entity space and r \u2022 i (\u2208 R ) in entity type space.\n\n(3) Given entity type triple (t e , r, t\u1ebd), under translation assumption 2 as in (Bordes et al., 2013), we have: t\u1ebd \u2212 r \u2022 t e . Hence, the scoring function is defined as:\nS trt (t e , r, t\u1ebd) = t e + r \u2022 \u2212 t\u1ebd 2 2 ,(2)\nwhere t e , r \u2022 , t\u1ebd \u2208 R . The model returns a lower score if the two entity types is close under this relationship and a higher one otherwise. Fig.2 shows an illustration of E2T and TRT.\n\n\nImplementation for Entity Type Prediction\n\nOur framework can be used for entity type prediction in the following way. First, for each entity e that appears in the testing set, a prediction by E2T is performed with:\nt e = arg min t\u2208T S e2t (e, t).(3)\nIn addition, a composite score (E2T+TRT) by connecting entity type instances and entity type triples with embedding model, which we call ConnectE 3 , is defined as follows:\n\nS e2t+trt (e, t e ) = \u03bb \u00b7 S e2t (e, t e )+\n\n(1 \u2212 \u03bb) \u00b7 1 |P | t\u1ebd\u2208P S trt (t e , r, t\u1ebd)\n+ 1 |Q| t\u0113\u2208Q S trt (t\u0113, r, t e ) ,\nwhere \u03bb is a hyperparameter for the trade-off. P = {t\u1ebd|t\u1ebd \u2208 T , (e, r,\u1ebd) \u2208 D} (i.e. given e is head entity, P is the set of all corresponding tail entities' types.), and Q = {t\u0113|t\u0113 \u2208 T , (\u0113, r, e) \u2208 D} (i.e. given e is tail entity, Q is the set of all corresponding head entities' types.). |P | and |Q| represent the total number of entity types in P and Q respectively. A prediction is performed with:\nt e = arg min te\u2208T S e2t+trt (e, t e ).(4)\nHence, our final composite model ConnectE-(E2T+TRT) favors predictions that agree with both entity type instances and global triple information in KGs.\n\n\nOptimization\n\nWe use ranking loss algorithm for training ConnectE-(E2T+TRT), in which the parameter set \u0398 = {E, T, R , R \u2022 , M}. E, T stand for the collection of all entities' and types' embeddings respectively. (R , R \u2022 ) denotes the collections of relationships' differentiated embeddings. The ranking objectives are designed to assign lower scores to true facts (including (e, r,\u1ebd) triple facts, (e, t) entity type instances and (t e , r, t\u1ebd) type triples) versus any corrupt ones. We build three sub-objective functions, i.e., J 1 , J 2 , J 3 , and implement dynamic optimization strategy, i.e., fix a partial of parameters and only update the rest when minimizing each function.\n\n(1) J 1 : We choose TransE (see Bordes et al. (2013)) to model triple facts as S(e, r,\u1ebd), in which we update the embeddings of entities (\u2200e \u2208 E) and the embeddings of relationships (\u2200r \u2208 R ). (2) J 2 : We only update the embeddings of entity types (\u2200t \u2208 T) and projecting matrix M, not the entities' embeddings that have been trained in J 1 . (3) J 3 : We only update the embeddings of relationships (\u2200r \u2022 \u2208 R \u2022 ) while keeping the entity types' embeddings fixed. The training is performed using Adagrad (Kingma and Ba, 2014). All embeddings in \u0398 are initialized with uniform distribution. The procedure, from J 1 , J 2 to J 3 , is iterated for a given number of iterations. We have: \u222a{(e, t e )|(e, te) \u2208 H, t e \u2208 T , t e = te} , Z :={(t e , r, t\u1ebd)|(te, r, t\u1ebd) \u2208 Z, t e \u2208 T , t e = te} \u222a{(te, r, t \u1ebd )|(te, r, t\u1ebd) \u2208 Z, t \u1ebd \u2208 T , t \u1ebd = t\u1ebd} D, H are training datasets of triple facts and entity type instances in KG. Z is the training data of type triples, built by replacing entities in D with their corresponding entity types.\n\n\nExperiments\n\n\nDatasets\n\nWe conduct the experiments on two real-world datasets (D) widely used in KG embedding literature, i.e. FB15k (Bordes et al., 2013) and YAGO43k (Moon et al., 2017), which are subsets of Freebase (Bollacker et al., 2008) and YAGO (Suchanek et al., 2007) respectively. They consist of triples, each of which is formed as (left entity, relationship, right entity). We utilize two entity type data (H, each of it is formed as (entity, entity type)) built in (Moon et al., 2017), called FB15kET and YAGO43kET, in which the entity types are mapped to entities from FB15k and YAGO43k respectively. Moreover, we build new type triple datasets (Z, each one in it is formed as (head type, relationship, tail type)), to train our model. They are built based on D and H. First, for each triple (e, r,\u1ebd) \u2208 D, we replace the head and the tail with their types according to H. The generated datasets are called FB15kTRT(full) and YAGO43kTRT(full). Second, considering about the scalability of the proposed approach for full KGs, we further modify the generation method of type triples, which is the major training bottleneck. We discard newly generated ones with low-frequency (i.e. #frequency = 1). After that the size of both FB15kTRT(full) and YAGO43kTRT(full) decreased by about 90%, called FB15kTRT(disc.) and YAGO43kTRT(disc.) respectively. The statistics of the datasets are showed in Table 2. For saving space, we put more data processing details (include cleaning H, building Z, etc.) on our github website. \n\n\nEntity Type Prediction\n\nThis task concentrates to complete a pair (entity, entity type) when its type is missing, which aims to verify the capability of our model for inferring missing entity type instances. Evaluation Protocol. We focus on entity type prediction determined by Formula (3) and (4). We use ranking criteria for evaluation. Firstly for each test pair, we remove the type and replace it by each of the types in T in turn. The function value of the negative pairs would be computed by the related models and then sorted by ascending order. We can obtain the exact rank of the correct type in the candidates. Finally, we use two metrics for comparison: (1) the mean reciprocal rank (MRR), and (2) the proportion of correct entities ranked in the top 1/3/10 (HITS@1/3/10)(%). Since the evaluation setting of \"Raw\" is not as accurate as \"Filter\" (Bordes et al., 2013), we only report the experimental results with latter setting in this paper.\nM RR = 1 |C| |C| i=1 1 rank i ,\nwhere C is a set of test pairs, and rank i is the rank position of the true entity type for the i-th pair.\n\nImplementation. The results of entity type prediction are shown in Table 3, where the results for the baselines are directly taken from original literature (Moon et al., 2017). We do not choose LM and PEM (Neelakantan et al., 2015) as baselines since they do not utilize triple knowledge, thus it is not fair to compare with them. For training our model, we select the learning rate \u03b1 \u2208 {0.1, 0.05, 0.001}, the margins \u03b3 1 , \u03b3 2 , \u03b3 3 \u2208 {0.5, 1, 2, 5, 10}, the embedding dimension pairs (\u03ba, ) \u2208 {(100, 50), (150, 75), (200, 100), (250, 125)}, and the weight \u03bb \u2208 {0.5, 0.65, 0.85, 0.95}. We use negative sampling, and gradient descent with AdaGrad as our optimization approach to improve convergence performance. During the initialization process, each embedding vector of the entities, entity types and relationships is initialized with a random number following a uniform distribution \u2212 \u221a 6/(m + n), where n \u2208 {#Ent, #Type, #Rel} and m \u2208 {\u03ba, }. During the whole training process, we normalize the entity embeddings after each epoch.\n\nWe select the parameters based on MRR in valid dataset. The optimal configurations are: {\u03b1 = 0.1, \u03b3 1 = \u03b3 2 = \u03b3 3 = 2, \u03ba = 200, = 100, \u03bb = 0.85} on FB15k/ET/TRT; {\u03b1 = 0.1, \u03b3 1 = \u03b3 2 = \u03b3 3 = 1, \u03ba = 250, = 125, \u03bb = 0.85} on YAGO43k/ET/TRT. We run 800 epochs on both datasets, and the batch size is 4096.\n\nExperimental Results. We can see from Table  3 that our ConnectEs outperform all baselines for entity type prediction in terms of all metrics on FB15kET and YAGO43kET. It confirms the capability of ConnectEs in modeling with local typing and global triple knowledge and inferring missing entity type instances in KGs. The model ConnectE-(E2T+TRT)(full) achieves the highest scores.\n\n\nAnalysis.\n\n(1) In E2T, we utilize a mapping matrix M which compresses entity embeddings into type embedding space, considering that entity type embedding represents common information of all the entities which belong to this type. The type embedding should be in a sharing subspace of entity embeddings. The experimental results of E2T compared with the baselines demonstrate that this assumption would be quite reasonable.\n\n(2) In E2T+TRT, we build new type-relation-type data, and then connect them with entity type instances. This approach provides more direct useful information to (weakly) supervise entity type prediction. For example, given a fact that head entity Barack Obama belongs to type /people/person and the relationship born in, we could make the best guess of the type of tail entity Honolulu as /location/location. Hence, the addition of type triples in ConnectE-(E2T+TRT) provides superior performance than ConnectE-(E2T+0). (3) Concerning about the scalability of our approach for big KGs, we utilize FB15kTRT(disc.) and YAGO43kTRT(disc.) for prediction, the training time of which reduced by 90% as the training data size decreased by 90%. Moreover, the results of ConnectE-(E2T+TRT)(disc.) show that it's comparable with the best ConnectE-(E2T+TRT)(full).\n\n\nEntity Type Classification\n\nThis task aims to judge whether each entity type instance in testing data holds or not, which could be viewed as a binary classification problem. Evaluation Protocol. Since there are no explicit negative entity type instances in existing KGs, in order to create datasets for classification, we build negative facts by randomly switching type from entity type pairs in validation and testing set with equal number of positive and negative examples. Inspired by the evaluation metric of triple classification in (Socher et al., 2013), we calculate the scores of all entity type instances based on model energy function, and rank all instances in testing set with these scores. Those instances with lower scores are considered to be true. We use precision/recall curves to show the performances of all models. Moreover, we also compare the accuracy among different models. We first use validate set to find best threshold \u03b7. For instance, if the model score S e2t+trt (e, t e ) \u2264 \u03b7 in classification, the entity type instance will be classified to be positive, otherwise to be negative. The final accuracy is based on how many facts are classified correctly. Implementation. We utilize the source codes and parameter settings of several baselines provided by (Moon et al., 2017) for this task. The optimal parameter settings for our proposed models are:\n{\u03b1 = 0.1, \u03b3 1 = \u03b3 2 = \u03b3 3 = 2, \u03ba = 200, = 100, \u03bb = 0.85} on FB15kET; {\u03b1 = 0.1, \u03b3 1 = \u03b3 2 = \u03b3 3 = 1, \u03ba = 250, = 125, \u03bb = 0.85} on YAGO43kET.\nIn both datasets, we learn all the training data for 800 epochs and the batch size is 4096. After training, we firstly draw PR-curves with dynamic thresholds. We select the best threshold based on the accuracy in valid dataset, which is used to calculate the accuracy in test dataset.\n\nExperimental Results. We draw the PR-curves for type classification task on both datasets in Fig.3. Note that we only report the results of ConnectE-(E2T+TRT)(disc.) not ConnectE-(E2T+TRT)(full), since the learning speed of the former is much more faster than the latter and its results are close to the best results of the latter. We can see from Fig.3    pared to ETE is almost 1.51%. (2) Comparing to the improvement on YAGO43kET, the advantage ConnectE-(E2T+TRT)(disc.) has over ConnectE-(E2T+0) in this task on FB15kET seems to be insignificant, which indicates that the type triples in FB15kTRT have fewer contribution on entity type classification than ones in YAGO43kTRT. It may be partially caused by the fact that the number of relations in YAGO43k (#Rel=37) is far less than that in FB15k (#Rel=1,345), which could considerably influence the effectiveness of the type-relationtype training set. Due to the rareness of relationships in YAGO43k, each entity usually connects with a large number of other entities through one single relationships, which means that the magnitude of |P | and |Q| in the composite model scoring function are large. After averaging in ConnectE-(E2T+TRT)(disc.), it could achieve more stable and significant results on YAGO43kET.  Table 5 shows the examples of entity type prediction by our model from FB15k/ET/TRT, which demonstrate our motivation of Mech. 2 that head type and tail type really maintain the relationship between head entity and tail entity. Given entity Peter Berg, TRT can find HITS@1 type pre-diction /people/person for it via the existing entity type assertion (New Youk, /location/location) and the relationship (/loc./loc./people born here) between them, i.e. Peter Berg \u2212 New York + /location/location= /people/person. \n\n\nCase Study\n\n\nConclusion and Future Work\n\nIn this paper, we described a framework for leveraging global triple knowledge to improve KG entity typing by training not only on (entity, entity type) assertions but also using newly generated (head type, relationship, tail type) type triples. Specifically, we propose two novel embedding-based models to encode entity type instances and entity type triples respectively. The connection of both models is utilized to infer missing entity type instances.\n\nThe empirical experiments demonstrate the effectiveness of our proposed model. Our modeling method is general and should apply to other typeoriented tasks. Next, we are considering to use this framework to conduct KG entity type noise detection.\n\nFigure 1 :\n1Effective mechanisms of entity type inference with local typing knowledge and global triple knowledge.\n\nFigure 2 :\n2Simple illustration of E2T and TRT.\n\n++\nSe2t(e, te) \u2212 Se2t(e , t e )]+ , Strt(te, r, t\u1ebd) \u2212 Strt(t e , r, t \u1ebd )]+ \u03b3 1 , \u03b3 2 , \u03b3 3 > 0 are margin hyperparameters, and the corrupted datasets are built as follows: D :={(e , r,\u1ebd)|(e, r,\u1ebd) \u2208 D, e \u2208 E, e = e} \u222a{(e, r,\u1ebd )|(e, r,\u1ebd) \u2208 D,\u1ebd \u2208 E,\u1ebd =\u1ebd} , H :={(e , te)|(e, te) \u2208 H, e \u2208 E, e = e}\n\nFigure 3 :\n3Entity type classification results (Precision/Recall Curve). Evaluate on FB15kET, YAGO43kET.\n\nTable 1 :\n1Entity type embedding models.Models \nEnergy function \nParameters \nSources \nTraining \nstrategy \nSe2t(e, t) \nS triple (\u00b7) \n\n\n\nTable 2 :\n2Statistics of D, H, Z.Dataset \n#Ent \n#Rel \n#Train \n#Valid \n#Test \n\nFB15k \n14,951 \n1,345 \n483,142 \n50,000 \n59,071 \nYAGO43k \n42,335 \n37 \n331,687 \n29,599 \n29,593 \n\nDataset \n#Ent \n#Type \n#Train \n#Valid \n#Test \n\nFB15kET \n14,951 \n3,851 \n136,618 \n15,749 \n15,780 \n\nYAGO43kET \n\n41,723 \n45,182 \n375,853 \n42,739 \n42,750 \n\nDataset \n#Type \n#Rel \n#Train \nValid \nTest \n\nFB15kTRT(full) \n3,851 \n1,345 \n2,015,338 \n-\n-\nFB15kTRT(disc.) \n2,060 \n614 \n231,315 \n-\n-\nYAGO43kTRT(full) \n45,128 \n37 \n1,727,708 \n-\n-\nYAGO43kTRT(disc.) \n17,910 \n32 \n189,781 \n-\n-\n\n\n\nTable 3 :\n3Entity type prediction results. Evaluation of different models on FB15kET and YAGO43kET.DATASET \nFB15kET \nYAGO43kET \n\nMETRICS \nMRR \nHITS@1 \nHITS@3 \nHITS@10 \nMRR \nHITS@1 \nHITS@3 \nHITS@10 \n\nRESCAL (Nickel et al., 2011) \n0.19 \n9.71 \n19.58 \n37.58 \n0.08 \n4.24 \n8.31 \n15.31 \nRES.-ET (Moon et al., 2017) \n0.24 \n12.17 \n27.92 \n50.72 \n0.09 \n4.32 \n9.62 \n19.40 \nHOLE (Nickel et al., 2016) \n0.22 \n13.29 \n23.35 \n38.16 \n0.16 \n9.02 \n17.28 \n29.25 \nHOLE-ET (Moon et al., 2017) \n0.42 \n29.40 \n48.04 \n66.73 \n0.18 \n10.28 \n20.13 \n34.90 \nTransE (Bordes et al., 2013) \n0.45 \n31.51 \n51.45 \n73.93 \n0.21 \n12.63 \n23.24 \n38.93 \nTransE-ET (Moon et al., 2017) \n0.46 \n33.56 \n52.96 \n71.16 \n0.18 \n9.19 \n19.41 \n35.58 \nETE (Moon et al., 2017) \n0.50 \n38.51 \n55.33 \n71.93 \n0.23 \n13.73 \n26.28 \n42.18 \n\nConnectE-(E2T+0) \n0.57 +-.00 \n45.54 +-.28 \n62.31 +-.29 \n78.12 +-.12 \n0.24 +-.01 \n13.54 +-.12 \n26.20 +-.18 \n44.51 +-.09 \nConnectE-(E2T+TRT)(disc.) \n0.59 +-.01 \n48.54 +-.71 \n63.66 +-.39 \n78.27 +-.16 \n0.27 +-.01 \n15.1 +-.15 \n29.14 +-.13 \n47.08 +-.09 \nConnectE-(E2T+TRT)(full) \n0.59 +-.00 \n49.55 +-.62 \n64.32 +-.37 \n79.92 +-.14 \n0.28 +-.01 \n16.01 +-.12 \n30.85 +-.13 \n47.92 +-.07 \n\n\n\n\nthat when the recall rate is between 0.88 \u223c 0.97, ConnectE-(E2T+TRT)(disc.) model could achieve the highest precision rate on FB15kET. In other ranges, our ConnectE-(E2T+TRT)(disc.) model also shows comparable performance. The result is consistent on YAGO43kET. Specifically, ConnectE-(E2T+TRT)(disc.) achieves the best F1 score of 94.66% when recall = 94.27% and precision = 95.05% on FB15kET. Also, ConnectE-(E2T+TRT)(disc.) surpasses other models and gets F1 score of 92.13% when precision = 93.18% and recall = 91.11% on YAGO43kET. It confirms the capability of our model, for they could not only infer missing types in KGs, but also perform well in KG entity type classification.\n\nTable 4\n4demonstrates the evaluation accuracy results of entity type classification, from which we can observe that: (1) On FB15kET, ConnectE-(E2T+TRT)(disc.) achieves the best accuracy score (94.49%). Compared to the mostly related model ETE, our model shows 0.48% absolute performance improvement. On YAGO43kET, ConnectE-(E2T+TRT)(disc.) model outperforms other models as well. The improvement of our model com-\n\nTable 4 :\n4Entity type classification results (accuracy).Dataset \nFB15kET \nYAGO43kET \n\nRESCAL-ET \n90.02% \n82.28% \n\nHOLE-ET \n93.23% \n90.14% \n\nTransE-ET \n93.88% \n90.76% \n\nETE \n94.01% \n90.82% \n\nConnectE (E2T+0) \n94.45% \n91.78% \nConnectE (E2T+TRT)(disc.) \n94.49% \n92.33% \n\n\n\nTable 5 :\n5Entity type prediction examples. Extraction from FB15k/ET/TRT.Type prediction: \nHIT@1 \nRel \nTail type \n\n1 \n\ntype=? \n/people/person \n/location/location/ \npeople born here \n\n/location/location \n\nhead \nentity \n\nPeter Berg \nNew York \ntail \nentity \nGus Van Sant \nLouisville \n\n2 \n\ntype=? \n/americancomedy/movie \n/film/film/ \ndirected by \n\n/film/director \n\nhead \nentity \n\nVery Bad Things \nPeter Berg \ntail \nentity \nRush Hour \nBrett Ratner \n\n3 \n\ntype=? \n/medicine/disease \npeople/cause of \ndeath/people \n\n/people/person \n\nhead \nentity \n\nMyocardial \ninfarction \nDick Clark \ntail \nentity \nPancreatic \ncancer \nJohn Hurt \n\n\nFor more clarity, we represent it as (/location/location, born in \u22121 , /people/person) inFig.1(Mech.2).\nWe chose TransE in this paper, and it is not difficult for other enhanced translation-based methods to model triple knowledge, such as Trans(H, R, D and G)(Wang et al., 2017).\nWe also call it ConnectE-(E2T+TRT), and use ConnectE-(E2T+0) to denote E2T for uniformity in the experiments.\nAcknowledgmentsThe authors would like to thank all anonymous reviewers for their insightful comments. We also want to thank Zhiyuan Liu (Tsinghua University) and Linmei Hu (BUPT) for their useful suggestions and comments on early drafts. This work was supported by the National Natural Science\nFine-grained entity type classification by jointly learning representations and label embeddings. Abhishek Abhishek, Ashish Anand, Amit Awekar, Proceedings of EACL. EACL797807Abhishek Abhishek, Ashish Anand, and Amit Awekar. 2017. Fine-grained entity type classification by jointly learning representations and label embed- dings. In Proceedings of EACL, page 797807.\n\nSemantic parsing on freebase from question-answer pairs. Jonathan Berant, Andrew Chou, Roy Frostig, Percy Liang, Proceedings of EMNLP. EMNLPJonathan Berant, Andrew Chou, Roy Frostig, and Percy Liang. 2013. Semantic parsing on freebase from question-answer pairs. In Proceedings of EMNLP, pages 1533-1544.\n\nFreebase: A collaboratively created graph database for structuring human knowledge. Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, Jamie Taylor, Proceedings of SIGMOD. SIGMODKurt Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, and Jamie Taylor. 2008. Freebase: A collab- oratively created graph database for structuring hu- man knowledge. In Proceedings of SIGMOD, pages 1247-1250.\n\nTranslating embeddings for modeling multirelational data. Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran, Jason Weston, Oksana Yakhnenko, Proceedings of NeurIPS. NeurIPSAntoine Bordes, Nicolas Usunier, Alberto Garcia- Duran, Jason Weston, and Oksana Yakhnenko. 2013. Translating embeddings for modeling multi- relational data. In Proceedings of NeurIPS, pages 2787-2795.\n\nUltra-fine entity typing. Eunsol Choi, Omer Levy, Yejin Choi, Luke S Zettlemoyer, Proceddings of ACL. eddings of ACLEunsol Choi, Omer Levy, Yejin Choi, and Luke S. Zettlemoyer. 2018. Ultra-fine entity typing. In Pro- ceddings of ACL.\n\nConvolutional 2d knowledge graph embeddings. Tim Dettmers, Minervini Pasquale, Stenetorp Pontus, Sebastian Riedel, Proceedings of AAAI. AAAITim Dettmers, Minervini Pasquale, Stenetorp Pon- tus, and Sebastian Riedel. 2017. Convolutional 2d knowledge graph embeddings. In Proceedings of AAAI, pages 1811-1818.\n\nImproving knowledge graph embedding using simple constraints. Boyang Ding, Quan Wang, Bin Wang, Li Guo, Proceedings of ACL. ACLMelbourne, AustraliaBoyang Ding, Quan Wang, Bin Wang, and Li Guo. 2018. Improving knowledge graph embedding us- ing simple constraints. In Proceedings of ACL, pages 110-121, Melbourne, Australia.\n\nKnowledge vault: A web-scale approach to probabilistic knowledge fusion. Xin Dong, Evgeniy Gabrilovich, Geremy Heitz, Wilko Horn, Ni Lao, Kevin Murphy, Thomas Strohmann, Shaohua Sun, Wei Zhang, Proceedings of SIGKDD. SIGKDDXin Dong, Evgeniy Gabrilovich, Geremy Heitz, Wilko Horn, Ni Lao, Kevin Murphy, Thomas Strohmann, Shaohua Sun, and Wei Zhang. 2014. Knowledge vault: A web-scale approach to probabilistic knowl- edge fusion. In Proceedings of SIGKDD, pages 601- 610.\n\nZero-shot question generation from knowledge graphs for unseen predicates and entity types. Hady Elsahar, Christophe Gravier, Frederique Laforest, Proceedings of NAACL. NAACLHady Elsahar, Christophe Gravier, and Frederique Laforest. 2018. Zero-shot question generation from knowledge graphs for unseen predicates and entity types. In Proceedings of NAACL, pages 218-228.\n\nEntity linking via joint encoding of types, descriptions, and context. Nitish Gupta, Sameer Singh, Dan Roth, Proceedings of EMNLP. EMNLPNitish Gupta, Sameer Singh, and Dan Roth. 2017. En- tity linking via joint encoding of types, descrip- tions, and context. In Proceedings of EMNLP, pages 2681-2690.\n\nJoint coreference resolution and named-entity linking with multi-pass sieves. Hannaneh Hajishirzi, Leila Zilles, Daniel S Weld, Luke Zettlemoyer, Proceddings of EMNLP. eddings of EMNLPHannaneh Hajishirzi, Leila Zilles, Daniel S. Weld, and Luke Zettlemoyer. 2013. Joint coreference resolu- tion and named-entity linking with multi-pass sieves. In Proceddings of EMNLP, pages 289-299.\n\nUniversal representation learning of knowledge bases by jointly embedding instances and ontological concepts. Junheng Hao, Muhao Chen, Wenchao Yu, Yizhou Sun, Wei Wang, Proceedings of KDD. KDDJunheng Hao, Muhao Chen, Wenchao Yu, Yizhou Sun, , and Wei Wang. 2019. Universal representation learning of knowledge bases by jointly embedding instances and ontological concepts. In Proceedings of KDD 2019.\n\nType-sensitive knowledge base inference without explicit type supervision. Prachi Jain, Pankaj Kumar, Soumen Chakrabarti, Proceedings of ACL. ACLPrachi Jain, Pankaj Kumar, and Soumen Chakrabarti. 2018. Type-sensitive knowledge base inference without explicit type supervision. In Proceedings of ACL.\n\nKnowledge graph completion with adaptive sparse transfer matrix. Guoliang Ji, Kang Liu, Shizhu He, Jun Zhao, Proceddings of AAAI. eddings of AAAIGuoliang Ji, Kang Liu, Shizhu He, and Jun Zhao. 2016. Knowledge graph completion with adaptive sparse transfer matrix. In Proceddings of AAAI.\n\nAttributed and predictive entity embedding for finegrained entity typing in knowledge bases. Hailong Jin, Lei Hou, Juanzi Li, Tiansi Dong, Proceedings of COLING 2018. COLING 2018Hailong Jin, Lei Hou, Juanzi Li, and Tiansi Dong. 2018. Attributed and predictive entity embedding for fine- grained entity typing in knowledge bases. In Pro- ceedings of COLING 2018, pages 282-292.\n\nAdam: A method for stochastic optimization. P Diederik, Jimmy Kingma, Ba, arXiv:1412.6980In arXiv preprintDiederik P. Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. In arXiv preprint arXiv:1412.6980.\n\nLearning entity and relation embeddings for knowledge graph completion. Yankai Lin, Zhiyuan Liu, Maosong Sun, Yang Liu, Xuan Zhu, Proceedings of AAAI. AAAIYankai Lin, Zhiyuan Liu, Maosong Sun, Yang Liu, and Xuan Zhu. 2015. Learning entity and relation em- beddings for knowledge graph completion. In Pro- ceedings of AAAI, pages 2181-2187.\n\nDifferentiating concepts and instances for knowledge graph embedding. Xin Lv, Lei Hou, Juanzi Li, Zhiyuan Liu, Proceedings of EMNLP 2018. EMNLP 201819711979Xin Lv, Lei Hou, Juanzi Li, and Zhiyuan Liu. 2018. Differentiating concepts and instances for knowl- edge graph embedding. In Proceedings of EMNLP 2018, page 19711979.\n\nLearning entity type embeddings for knowledge graph completion. Chang Moon, Paul Jones, Nagiza F Samatova, Proceedings of CIKM. CIKMChang Moon, Paul Jones, and Nagiza F. Samatova. 2017. Learning entity type embeddings for knowl- edge graph completion. In Proceedings of CIKM, pages 2215-2218.\n\nLearning attention-based embeddings for relation prediction in knowledge graphs. Deepak Nathani, Jatin Chauhan, Charu Sharma, Manohar Kaul, Proceedings of ACL. ACLDeepak Nathani, Jatin Chauhan, Charu Sharma, and Manohar Kaul. 2019. Learning attention-based embeddings for relation prediction in knowledge graphs. In Proceedings of ACL.\n\nInferring missing entity type instances for knowledge base completion: New dataset and methods. Arvind Neelakantan, Ming-Wei Chang, Proceedings of NAACL 2012. NAACL 2012515525Arvind Neelakantan, Ming-Wei Chang, and . 2015. In- ferring missing entity type instances for knowledge base completion: New dataset and methods. In Pro- ceedings of NAACL 2012, page 515525.\n\nHolographic embeddings of knowledge graphs. Maximilian Nickel, Lorenzo Rosasco, Tomaso Poggio, Proceedings of AAAI. AAAIMaximilian Nickel, Lorenzo Rosasco, and Tomaso Poggio. 2016. Holographic embeddings of knowl- edge graphs. In Proceedings of AAAI, pages 1955- 1961.\n\nA three-way model for collective learning on multi-relational data. Maximilian Nickel, Hans-Peter Volker Tresp, Kriegel, Proceedings of ICML. ICMLMaximilian Nickel, Volker Tresp, and Hans-Peter Kriegel. 2011. A three-way model for collective learning on multi-relational data. In Proceedings of ICML, pages 809-816.\n\nMining entity types from query logs via user intent modeling. Patrick Pantel, Thomas Lin, Michael Gamon, Proceedings of ACL. ACLPatrick Pantel, Thomas Lin, and Michael Gamon. 2012. Mining entity types from query logs via user intent modeling. In Proceedings of ACL, pages 563-571.\n\nReasoning with neural tensor networks for knowledge base completion. Richard Socher, Danqi Chen, Christopher D Manning, Andrew Y Ng, Proceedings of NeurIPS. NeurIPSRichard Socher, Danqi Chen, Christopher D. Manning, and Andrew Y. Ng. 2013. Reasoning with neural tensor networks for knowledge base completion. In Proceedings of NeurIPS, pages 926-934.\n\nYago: a core of semantic knowledge. Fabian M Suchanek, Gjergji Kasneci, Gerhard Weikum, Proceedings of WWW. WWWFabian M. Suchanek, Gjergji Kasneci, and Gerhard Weikum. 2007. Yago: a core of semantic knowledge. In Proceedings of WWW, pages 697-706.\n\nKnowledge graph embedding: A survey of approaches and applications. Quan Wang, Zhendong Mao, Bin Wang, Li Guo, TKDE. 2912Quan Wang, Zhendong Mao, Bin Wang, and Li Guo. 2017. Knowledge graph embedding: A survey of approaches and applications. TKDE, 29(12):2724- 2743.\n\nKnowledge graph embedding by translating on hyperplanes. Zhen Wang, Jianwen Zhang, Jianlin Feng, Zheng Chen, Proceedings of AAAI. AAAIZhen Wang, Jianwen Zhang, Jianlin Feng, and Zheng Chen. 2014. Knowledge graph embedding by trans- lating on hyperplanes. In Proceedings of AAAI, pages 1112-1119.\n\nRepresentation learning of knowledge graphs with hierarchical types. Ruobing Xie, Zhiyuan Liu, Maosong Sun, Proceedings of IJCAI. IJCAIRuobing Xie, Zhiyuan Liu, and Maosong Sun. 2016. Representation learning of knowledge graphs with hierarchical types. In Proceedings of IJCAI, pages 2965-2971.\n\nNeural fine grained entity type classification with hierarchy aware loss. Peng Xu, Denilson Barbosa, Proceedings of NAACL. NAACLPeng Xu and Denilson Barbosa. 2018. Neural fine grained entity type classification with hierarchy aware loss. In Proceedings of NAACL.\n\nCorpus-level fine-grained entity typing. Yadollah Yaghoobzadeh, Heike Adel, Hinrich Schtze, Journal of Artificial Intelligence Research. 61Yadollah Yaghoobzadeh, Heike Adel, and Hinrich Schtze. 2018. Corpus-level fine-grained entity typ- ing. Journal of Artificial Intelligence Research, 61:835-862.\n\nUniversal schema for entity type prediction. Limin Yao, Sebastian Riedel, Andrew Mccallum, Proceedings of the 2013 Workshop on Automated Knowledge Base Construction. the 2013 Workshop on Automated Knowledge Base ConstructionLimin Yao, Sebastian Riedel, , and Andrew McCallum. 2013. Universal schema for entity type prediction. In Proceedings of the 2013 Workshop on Automated Knowledge Base Construction, pages 79-84.\n\nEmbedding methods for fine grained entity type classification. Dani Yogatama, Daniel Gillick, Nevena Lazic, Proceedings of ACL. ACL291296Dani Yogatama, Daniel Gillick, and Nevena Lazic. 2015. Embedding methods for fine grained entity type classification. In Proceedings of ACL, page 291296.\n\nOtyper: A neural architecture for open named entity typing. Zheng Yuan, Doug Downey, Proceddings of AAAI. eddings of AAAIZheng Yuan and Doug Downey. 2018. Otyper: A neu- ral architecture for open named entity typing. In Pro- ceddings of AAAI.\n\nRelation classification via convolutional deep neural network. Daojian Zeng, Kang Liu, Siwei Lai, Guangyou Zhou, Jun Zhao, Proceedings of COLING. COLINGDaojian Zeng, Kang Liu, Siwei Lai, Guangyou Zhou, and Jun Zhao. 2014. Relation classification via con- volutional deep neural network. In Proceedings of COLING, pages 23-29.\n\nEmbedding of hierarchically typed knowledge bases. Richong Zhang, Fanshuang Kong, Chenyue Wang, Yongyi Mao, Proceddings of AAAI. eddings of AAAIRichong Zhang, Fanshuang Kong, Chenyue Wang, and Yongyi Mao. 2018. Embedding of hierarchically typed knowledge bases. In Proceddings of AAAI.\n\nZero-shot open entity typing as typecompatible grounding. Ben Zhou, Daniel Khashabi, Chen-Tse Tsai, Dan Roth, Procedddings of EMNLP. edddings of EMNLPBen Zhou, Daniel Khashabi, Chen-Tse Tsai, and Dan Roth. 2018. Zero-shot open entity typing as type- compatible grounding. In Procedddings of EMNLP, pages 2065-2076.\n", "annotations": {"author": "[{\"end\":313,\"start\":173},{\"end\":397,\"start\":314},{\"end\":468,\"start\":398},{\"end\":662,\"start\":469},{\"end\":768,\"start\":663}]", "publisher": "[{\"end\":98,\"start\":57},{\"end\":1027,\"start\":986}]", "author_last_name": "[{\"end\":180,\"start\":176},{\"end\":327,\"start\":322},{\"end\":409,\"start\":406},{\"end\":477,\"start\":474},{\"end\":675,\"start\":671}]", "author_first_name": "[{\"end\":175,\"start\":173},{\"end\":321,\"start\":314},{\"end\":405,\"start\":398},{\"end\":473,\"start\":469},{\"end\":670,\"start\":663}]", "author_affiliation": "[{\"end\":312,\"start\":182},{\"end\":396,\"start\":329},{\"end\":467,\"start\":411},{\"end\":599,\"start\":479},{\"end\":661,\"start\":601},{\"end\":767,\"start\":677}]", "title": "[{\"end\":56,\"start\":1},{\"end\":824,\"start\":769}]", "venue": "[{\"end\":913,\"start\":826}]", "abstract": "[{\"end\":2167,\"start\":1153}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2313,\"start\":2289},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":2343,\"start\":2320},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":2387,\"start\":2368},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":2676,\"start\":2654},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2716,\"start\":2695},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":2761,\"start\":2742},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":3334,\"start\":3314},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":3352,\"start\":3334},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":3402,\"start\":3377},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3439,\"start\":3419},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3543,\"start\":3522},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":3561,\"start\":3543},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":3578,\"start\":3561},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3600,\"start\":3578},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":3618,\"start\":3600},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":3639,\"start\":3618},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3817,\"start\":3796},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":3902,\"start\":3883},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":4998,\"start\":4981},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":5015,\"start\":4998},{\"end\":5516,\"start\":5483},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":6699,\"start\":6678},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":8269,\"start\":8242},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":8324,\"start\":8305},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":8367,\"start\":8345},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":8468,\"start\":8445},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":8486,\"start\":8468},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":8507,\"start\":8486},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":8529,\"start\":8507},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":8613,\"start\":8592},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":8662,\"start\":8644},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":8710,\"start\":8687},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":8765,\"start\":8739},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":8841,\"start\":8815},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":8944,\"start\":8923},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":9036,\"start\":9017},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":9142,\"start\":9121},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":9224,\"start\":9205},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":9324,\"start\":9303},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":9409,\"start\":9390},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":9505,\"start\":9486},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":9902,\"start\":9877},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":10292,\"start\":10274},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":10820,\"start\":10799},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":10848,\"start\":10827},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":10881,\"start\":10860},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":11856,\"start\":11838},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":11881,\"start\":11856},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":12146,\"start\":12129},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":12163,\"start\":12146},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":14555,\"start\":14538},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":16549,\"start\":16528},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":18736,\"start\":18716},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":19868,\"start\":19847},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":19900,\"start\":19881},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":19956,\"start\":19932},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":19989,\"start\":19966},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":20210,\"start\":20191},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":22119,\"start\":22098},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":22511,\"start\":22492},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":22567,\"start\":22541},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":25898,\"start\":25877},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":26642,\"start\":26623},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":34346,\"start\":34327}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":29786,\"start\":29671},{\"attributes\":{\"id\":\"fig_1\"},\"end\":29835,\"start\":29787},{\"attributes\":{\"id\":\"fig_2\"},\"end\":30132,\"start\":29836},{\"attributes\":{\"id\":\"fig_3\"},\"end\":30238,\"start\":30133},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":30373,\"start\":30239},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":30918,\"start\":30374},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":32070,\"start\":30919},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":32757,\"start\":32071},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":33172,\"start\":32758},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":33443,\"start\":33173},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":34067,\"start\":33444}]", "paragraph": "[{\"end\":2984,\"start\":2183},{\"end\":4032,\"start\":2986},{\"end\":4457,\"start\":4034},{\"end\":4641,\"start\":4459},{\"end\":4848,\"start\":4643},{\"end\":7448,\"start\":4850},{\"end\":7483,\"start\":7450},{\"end\":7686,\"start\":7485},{\"end\":7971,\"start\":7688},{\"end\":8179,\"start\":7973},{\"end\":9005,\"start\":8197},{\"end\":9114,\"start\":9007},{\"end\":9195,\"start\":9116},{\"end\":9294,\"start\":9197},{\"end\":9378,\"start\":9296},{\"end\":9480,\"start\":9380},{\"end\":9583,\"start\":9482},{\"end\":9726,\"start\":9681},{\"end\":9853,\"start\":9728},{\"end\":11582,\"start\":9855},{\"end\":12488,\"start\":11584},{\"end\":13013,\"start\":12518},{\"end\":13542,\"start\":13015},{\"end\":13840,\"start\":13577},{\"end\":14491,\"start\":13842},{\"end\":14977,\"start\":14493},{\"end\":15198,\"start\":15012},{\"end\":15986,\"start\":15231},{\"end\":16445,\"start\":15988},{\"end\":16617,\"start\":16447},{\"end\":16851,\"start\":16664},{\"end\":17068,\"start\":16897},{\"end\":17276,\"start\":17104},{\"end\":17320,\"start\":17278},{\"end\":17363,\"start\":17322},{\"end\":17801,\"start\":17399},{\"end\":17996,\"start\":17845},{\"end\":18682,\"start\":18013},{\"end\":19711,\"start\":18684},{\"end\":21239,\"start\":19738},{\"end\":22195,\"start\":21266},{\"end\":22334,\"start\":22228},{\"end\":23369,\"start\":22336},{\"end\":23672,\"start\":23371},{\"end\":24055,\"start\":23674},{\"end\":24481,\"start\":24069},{\"end\":25336,\"start\":24483},{\"end\":26717,\"start\":25367},{\"end\":27142,\"start\":26858},{\"end\":28924,\"start\":27144},{\"end\":29423,\"start\":28968},{\"end\":29670,\"start\":29425}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":9680,\"start\":9584},{\"attributes\":{\"id\":\"formula_1\"},\"end\":15011,\"start\":14978},{\"attributes\":{\"id\":\"formula_2\"},\"end\":16663,\"start\":16618},{\"attributes\":{\"id\":\"formula_3\"},\"end\":17103,\"start\":17069},{\"attributes\":{\"id\":\"formula_4\"},\"end\":17398,\"start\":17364},{\"attributes\":{\"id\":\"formula_5\"},\"end\":17844,\"start\":17802},{\"attributes\":{\"id\":\"formula_6\"},\"end\":22227,\"start\":22196},{\"attributes\":{\"id\":\"formula_7\"},\"end\":26857,\"start\":26718}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":12394,\"start\":12387},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":21121,\"start\":21114},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":22410,\"start\":22403},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":23720,\"start\":23712},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":28419,\"start\":28412}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2181,\"start\":2169},{\"attributes\":{\"n\":\"2\"},\"end\":8195,\"start\":8182},{\"attributes\":{\"n\":\"3\"},\"end\":12516,\"start\":12491},{\"attributes\":{\"n\":\"3.1\"},\"end\":13575,\"start\":13545},{\"attributes\":{\"n\":\"3.2\"},\"end\":15229,\"start\":15201},{\"attributes\":{\"n\":\"3.3\"},\"end\":16895,\"start\":16854},{\"attributes\":{\"n\":\"3.4\"},\"end\":18011,\"start\":17999},{\"attributes\":{\"n\":\"4\"},\"end\":19725,\"start\":19714},{\"attributes\":{\"n\":\"4.1\"},\"end\":19736,\"start\":19728},{\"attributes\":{\"n\":\"4.2\"},\"end\":21264,\"start\":21242},{\"end\":24067,\"start\":24058},{\"attributes\":{\"n\":\"4.3\"},\"end\":25365,\"start\":25339},{\"attributes\":{\"n\":\"4.4\"},\"end\":28937,\"start\":28927},{\"attributes\":{\"n\":\"5\"},\"end\":28966,\"start\":28940},{\"end\":29682,\"start\":29672},{\"end\":29798,\"start\":29788},{\"end\":29839,\"start\":29837},{\"end\":30144,\"start\":30134},{\"end\":30249,\"start\":30240},{\"end\":30384,\"start\":30375},{\"end\":30929,\"start\":30920},{\"end\":32766,\"start\":32759},{\"end\":33183,\"start\":33174},{\"end\":33454,\"start\":33445}]", "table": "[{\"end\":30373,\"start\":30280},{\"end\":30918,\"start\":30408},{\"end\":32070,\"start\":31019},{\"end\":33443,\"start\":33231},{\"end\":34067,\"start\":33518}]", "figure_caption": "[{\"end\":29786,\"start\":29684},{\"end\":29835,\"start\":29800},{\"end\":30132,\"start\":29840},{\"end\":30238,\"start\":30146},{\"end\":30280,\"start\":30251},{\"end\":30408,\"start\":30386},{\"end\":31019,\"start\":30931},{\"end\":32757,\"start\":32073},{\"end\":33172,\"start\":32768},{\"end\":33231,\"start\":33185},{\"end\":33518,\"start\":33456}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":4640,\"start\":4627},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":4847,\"start\":4834},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":5093,\"start\":5088},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":5874,\"start\":5869},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":6811,\"start\":6806},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":16813,\"start\":16808},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":27242,\"start\":27237},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":27497,\"start\":27492}]", "bib_author_first_name": "[{\"end\":34858,\"start\":34850},{\"end\":34875,\"start\":34869},{\"end\":34887,\"start\":34883},{\"end\":35186,\"start\":35178},{\"end\":35201,\"start\":35195},{\"end\":35211,\"start\":35208},{\"end\":35226,\"start\":35221},{\"end\":35515,\"start\":35511},{\"end\":35532,\"start\":35527},{\"end\":35547,\"start\":35540},{\"end\":35561,\"start\":35558},{\"end\":35575,\"start\":35570},{\"end\":35893,\"start\":35886},{\"end\":35909,\"start\":35902},{\"end\":35926,\"start\":35919},{\"end\":35946,\"start\":35941},{\"end\":35961,\"start\":35955},{\"end\":36239,\"start\":36233},{\"end\":36250,\"start\":36246},{\"end\":36262,\"start\":36257},{\"end\":36273,\"start\":36269},{\"end\":36275,\"start\":36274},{\"end\":36490,\"start\":36487},{\"end\":36510,\"start\":36501},{\"end\":36530,\"start\":36521},{\"end\":36548,\"start\":36539},{\"end\":36819,\"start\":36813},{\"end\":36830,\"start\":36826},{\"end\":36840,\"start\":36837},{\"end\":36849,\"start\":36847},{\"end\":37151,\"start\":37148},{\"end\":37165,\"start\":37158},{\"end\":37185,\"start\":37179},{\"end\":37198,\"start\":37193},{\"end\":37207,\"start\":37205},{\"end\":37218,\"start\":37213},{\"end\":37233,\"start\":37227},{\"end\":37252,\"start\":37245},{\"end\":37261,\"start\":37258},{\"end\":37643,\"start\":37639},{\"end\":37663,\"start\":37653},{\"end\":37683,\"start\":37673},{\"end\":37996,\"start\":37990},{\"end\":38010,\"start\":38004},{\"end\":38021,\"start\":38018},{\"end\":38307,\"start\":38299},{\"end\":38325,\"start\":38320},{\"end\":38340,\"start\":38334},{\"end\":38342,\"start\":38341},{\"end\":38353,\"start\":38349},{\"end\":38722,\"start\":38715},{\"end\":38733,\"start\":38728},{\"end\":38747,\"start\":38740},{\"end\":38758,\"start\":38752},{\"end\":38767,\"start\":38764},{\"end\":39088,\"start\":39082},{\"end\":39101,\"start\":39095},{\"end\":39115,\"start\":39109},{\"end\":39381,\"start\":39373},{\"end\":39390,\"start\":39386},{\"end\":39402,\"start\":39396},{\"end\":39410,\"start\":39407},{\"end\":39697,\"start\":39690},{\"end\":39706,\"start\":39703},{\"end\":39718,\"start\":39712},{\"end\":39729,\"start\":39723},{\"end\":40020,\"start\":40019},{\"end\":40036,\"start\":40031},{\"end\":40278,\"start\":40272},{\"end\":40291,\"start\":40284},{\"end\":40304,\"start\":40297},{\"end\":40314,\"start\":40310},{\"end\":40324,\"start\":40320},{\"end\":40614,\"start\":40611},{\"end\":40622,\"start\":40619},{\"end\":40634,\"start\":40628},{\"end\":40646,\"start\":40639},{\"end\":40935,\"start\":40930},{\"end\":40946,\"start\":40942},{\"end\":40960,\"start\":40954},{\"end\":40962,\"start\":40961},{\"end\":41247,\"start\":41241},{\"end\":41262,\"start\":41257},{\"end\":41277,\"start\":41272},{\"end\":41293,\"start\":41286},{\"end\":41599,\"start\":41593},{\"end\":41621,\"start\":41613},{\"end\":41918,\"start\":41908},{\"end\":41934,\"start\":41927},{\"end\":41950,\"start\":41944},{\"end\":42212,\"start\":42202},{\"end\":42231,\"start\":42221},{\"end\":42520,\"start\":42513},{\"end\":42535,\"start\":42529},{\"end\":42548,\"start\":42541},{\"end\":42809,\"start\":42802},{\"end\":42823,\"start\":42818},{\"end\":42841,\"start\":42830},{\"end\":42843,\"start\":42842},{\"end\":42859,\"start\":42853},{\"end\":42861,\"start\":42860},{\"end\":43127,\"start\":43121},{\"end\":43129,\"start\":43128},{\"end\":43147,\"start\":43140},{\"end\":43164,\"start\":43157},{\"end\":43406,\"start\":43402},{\"end\":43421,\"start\":43413},{\"end\":43430,\"start\":43427},{\"end\":43439,\"start\":43437},{\"end\":43663,\"start\":43659},{\"end\":43677,\"start\":43670},{\"end\":43692,\"start\":43685},{\"end\":43704,\"start\":43699},{\"end\":43975,\"start\":43968},{\"end\":43988,\"start\":43981},{\"end\":44001,\"start\":43994},{\"end\":44273,\"start\":44269},{\"end\":44286,\"start\":44278},{\"end\":44508,\"start\":44500},{\"end\":44528,\"start\":44523},{\"end\":44542,\"start\":44535},{\"end\":44810,\"start\":44805},{\"end\":44825,\"start\":44816},{\"end\":44840,\"start\":44834},{\"end\":45246,\"start\":45242},{\"end\":45263,\"start\":45257},{\"end\":45279,\"start\":45273},{\"end\":45536,\"start\":45531},{\"end\":45547,\"start\":45543},{\"end\":45785,\"start\":45778},{\"end\":45796,\"start\":45792},{\"end\":45807,\"start\":45802},{\"end\":45821,\"start\":45813},{\"end\":45831,\"start\":45828},{\"end\":46100,\"start\":46093},{\"end\":46117,\"start\":46108},{\"end\":46131,\"start\":46124},{\"end\":46144,\"start\":46138},{\"end\":46390,\"start\":46387},{\"end\":46403,\"start\":46397},{\"end\":46422,\"start\":46414},{\"end\":46432,\"start\":46429}]", "bib_author_last_name": "[{\"end\":34867,\"start\":34859},{\"end\":34881,\"start\":34876},{\"end\":34894,\"start\":34888},{\"end\":35193,\"start\":35187},{\"end\":35206,\"start\":35202},{\"end\":35219,\"start\":35212},{\"end\":35232,\"start\":35227},{\"end\":35525,\"start\":35516},{\"end\":35538,\"start\":35533},{\"end\":35556,\"start\":35548},{\"end\":35568,\"start\":35562},{\"end\":35582,\"start\":35576},{\"end\":35900,\"start\":35894},{\"end\":35917,\"start\":35910},{\"end\":35939,\"start\":35927},{\"end\":35953,\"start\":35947},{\"end\":35971,\"start\":35962},{\"end\":36244,\"start\":36240},{\"end\":36255,\"start\":36251},{\"end\":36267,\"start\":36263},{\"end\":36287,\"start\":36276},{\"end\":36499,\"start\":36491},{\"end\":36519,\"start\":36511},{\"end\":36537,\"start\":36531},{\"end\":36555,\"start\":36549},{\"end\":36824,\"start\":36820},{\"end\":36835,\"start\":36831},{\"end\":36845,\"start\":36841},{\"end\":36853,\"start\":36850},{\"end\":37156,\"start\":37152},{\"end\":37177,\"start\":37166},{\"end\":37191,\"start\":37186},{\"end\":37203,\"start\":37199},{\"end\":37211,\"start\":37208},{\"end\":37225,\"start\":37219},{\"end\":37243,\"start\":37234},{\"end\":37256,\"start\":37253},{\"end\":37267,\"start\":37262},{\"end\":37651,\"start\":37644},{\"end\":37671,\"start\":37664},{\"end\":37692,\"start\":37684},{\"end\":38002,\"start\":37997},{\"end\":38016,\"start\":38011},{\"end\":38026,\"start\":38022},{\"end\":38318,\"start\":38308},{\"end\":38332,\"start\":38326},{\"end\":38347,\"start\":38343},{\"end\":38365,\"start\":38354},{\"end\":38726,\"start\":38723},{\"end\":38738,\"start\":38734},{\"end\":38750,\"start\":38748},{\"end\":38762,\"start\":38759},{\"end\":38772,\"start\":38768},{\"end\":39093,\"start\":39089},{\"end\":39107,\"start\":39102},{\"end\":39127,\"start\":39116},{\"end\":39384,\"start\":39382},{\"end\":39394,\"start\":39391},{\"end\":39405,\"start\":39403},{\"end\":39415,\"start\":39411},{\"end\":39701,\"start\":39698},{\"end\":39710,\"start\":39707},{\"end\":39721,\"start\":39719},{\"end\":39734,\"start\":39730},{\"end\":40029,\"start\":40021},{\"end\":40043,\"start\":40037},{\"end\":40047,\"start\":40045},{\"end\":40282,\"start\":40279},{\"end\":40295,\"start\":40292},{\"end\":40308,\"start\":40305},{\"end\":40318,\"start\":40315},{\"end\":40328,\"start\":40325},{\"end\":40617,\"start\":40615},{\"end\":40626,\"start\":40623},{\"end\":40637,\"start\":40635},{\"end\":40650,\"start\":40647},{\"end\":40940,\"start\":40936},{\"end\":40952,\"start\":40947},{\"end\":40971,\"start\":40963},{\"end\":41255,\"start\":41248},{\"end\":41270,\"start\":41263},{\"end\":41284,\"start\":41278},{\"end\":41298,\"start\":41294},{\"end\":41611,\"start\":41600},{\"end\":41627,\"start\":41622},{\"end\":41925,\"start\":41919},{\"end\":41942,\"start\":41935},{\"end\":41957,\"start\":41951},{\"end\":42219,\"start\":42213},{\"end\":42244,\"start\":42232},{\"end\":42253,\"start\":42246},{\"end\":42527,\"start\":42521},{\"end\":42539,\"start\":42536},{\"end\":42554,\"start\":42549},{\"end\":42816,\"start\":42810},{\"end\":42828,\"start\":42824},{\"end\":42851,\"start\":42844},{\"end\":42864,\"start\":42862},{\"end\":43138,\"start\":43130},{\"end\":43155,\"start\":43148},{\"end\":43171,\"start\":43165},{\"end\":43411,\"start\":43407},{\"end\":43425,\"start\":43422},{\"end\":43435,\"start\":43431},{\"end\":43443,\"start\":43440},{\"end\":43668,\"start\":43664},{\"end\":43683,\"start\":43678},{\"end\":43697,\"start\":43693},{\"end\":43709,\"start\":43705},{\"end\":43979,\"start\":43976},{\"end\":43992,\"start\":43989},{\"end\":44005,\"start\":44002},{\"end\":44276,\"start\":44274},{\"end\":44294,\"start\":44287},{\"end\":44521,\"start\":44509},{\"end\":44533,\"start\":44529},{\"end\":44549,\"start\":44543},{\"end\":44814,\"start\":44811},{\"end\":44832,\"start\":44826},{\"end\":44849,\"start\":44841},{\"end\":45255,\"start\":45247},{\"end\":45271,\"start\":45264},{\"end\":45285,\"start\":45280},{\"end\":45541,\"start\":45537},{\"end\":45554,\"start\":45548},{\"end\":45790,\"start\":45786},{\"end\":45800,\"start\":45797},{\"end\":45811,\"start\":45808},{\"end\":45826,\"start\":45822},{\"end\":45836,\"start\":45832},{\"end\":46106,\"start\":46101},{\"end\":46122,\"start\":46118},{\"end\":46136,\"start\":46132},{\"end\":46148,\"start\":46145},{\"end\":46395,\"start\":46391},{\"end\":46412,\"start\":46404},{\"end\":46427,\"start\":46423},{\"end\":46437,\"start\":46433}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":14148547},\"end\":35119,\"start\":34752},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":6401679},\"end\":35425,\"start\":35121},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":207167677},\"end\":35826,\"start\":35427},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":14941970},\"end\":36205,\"start\":35828},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":49212016},\"end\":36440,\"start\":36207},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":4328400},\"end\":36749,\"start\":36442},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":19187663},\"end\":37073,\"start\":36751},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":4557963},\"end\":37545,\"start\":37075},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":3444808},\"end\":37917,\"start\":37547},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":28784495},\"end\":38219,\"start\":37919},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":5716274},\"end\":38603,\"start\":38221},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":196187271},\"end\":39005,\"start\":38605},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":49563566},\"end\":39306,\"start\":39007},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":38485677},\"end\":39595,\"start\":39308},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":52012875},\"end\":39973,\"start\":39597},{\"attributes\":{\"doi\":\"arXiv:1412.6980\",\"id\":\"b15\"},\"end\":40198,\"start\":39975},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":2949428},\"end\":40539,\"start\":40200},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":53080423},\"end\":40864,\"start\":40541},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":28006229},\"end\":41158,\"start\":40866},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":174797737},\"end\":41495,\"start\":41160},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":298145},\"end\":41862,\"start\":41497},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":6071257},\"end\":42132,\"start\":41864},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":1157792},\"end\":42449,\"start\":42134},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":15810061},\"end\":42731,\"start\":42451},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":8429835},\"end\":43083,\"start\":42733},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":207163173},\"end\":43332,\"start\":43085},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":19135805},\"end\":43600,\"start\":43334},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":15027084},\"end\":43897,\"start\":43602},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":1743664},\"end\":44193,\"start\":43899},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":4732544},\"end\":44457,\"start\":44195},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":4941134},\"end\":44758,\"start\":44459},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":2667711},\"end\":45177,\"start\":44760},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":881437},\"end\":45469,\"start\":45179},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":13745445},\"end\":45713,\"start\":45471},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":12873739},\"end\":46040,\"start\":45715},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":19146235},\"end\":46327,\"start\":46042},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":52247458},\"end\":46643,\"start\":46329}]", "bib_title": "[{\"end\":34848,\"start\":34752},{\"end\":35176,\"start\":35121},{\"end\":35509,\"start\":35427},{\"end\":35884,\"start\":35828},{\"end\":36231,\"start\":36207},{\"end\":36485,\"start\":36442},{\"end\":36811,\"start\":36751},{\"end\":37146,\"start\":37075},{\"end\":37637,\"start\":37547},{\"end\":37988,\"start\":37919},{\"end\":38297,\"start\":38221},{\"end\":38713,\"start\":38605},{\"end\":39080,\"start\":39007},{\"end\":39371,\"start\":39308},{\"end\":39688,\"start\":39597},{\"end\":40270,\"start\":40200},{\"end\":40609,\"start\":40541},{\"end\":40928,\"start\":40866},{\"end\":41239,\"start\":41160},{\"end\":41591,\"start\":41497},{\"end\":41906,\"start\":41864},{\"end\":42200,\"start\":42134},{\"end\":42511,\"start\":42451},{\"end\":42800,\"start\":42733},{\"end\":43119,\"start\":43085},{\"end\":43400,\"start\":43334},{\"end\":43657,\"start\":43602},{\"end\":43966,\"start\":43899},{\"end\":44267,\"start\":44195},{\"end\":44498,\"start\":44459},{\"end\":44803,\"start\":44760},{\"end\":45240,\"start\":45179},{\"end\":45529,\"start\":45471},{\"end\":45776,\"start\":45715},{\"end\":46091,\"start\":46042},{\"end\":46385,\"start\":46329}]", "bib_author": "[{\"end\":34869,\"start\":34850},{\"end\":34883,\"start\":34869},{\"end\":34896,\"start\":34883},{\"end\":35195,\"start\":35178},{\"end\":35208,\"start\":35195},{\"end\":35221,\"start\":35208},{\"end\":35234,\"start\":35221},{\"end\":35527,\"start\":35511},{\"end\":35540,\"start\":35527},{\"end\":35558,\"start\":35540},{\"end\":35570,\"start\":35558},{\"end\":35584,\"start\":35570},{\"end\":35902,\"start\":35886},{\"end\":35919,\"start\":35902},{\"end\":35941,\"start\":35919},{\"end\":35955,\"start\":35941},{\"end\":35973,\"start\":35955},{\"end\":36246,\"start\":36233},{\"end\":36257,\"start\":36246},{\"end\":36269,\"start\":36257},{\"end\":36289,\"start\":36269},{\"end\":36501,\"start\":36487},{\"end\":36521,\"start\":36501},{\"end\":36539,\"start\":36521},{\"end\":36557,\"start\":36539},{\"end\":36826,\"start\":36813},{\"end\":36837,\"start\":36826},{\"end\":36847,\"start\":36837},{\"end\":36855,\"start\":36847},{\"end\":37158,\"start\":37148},{\"end\":37179,\"start\":37158},{\"end\":37193,\"start\":37179},{\"end\":37205,\"start\":37193},{\"end\":37213,\"start\":37205},{\"end\":37227,\"start\":37213},{\"end\":37245,\"start\":37227},{\"end\":37258,\"start\":37245},{\"end\":37269,\"start\":37258},{\"end\":37653,\"start\":37639},{\"end\":37673,\"start\":37653},{\"end\":37694,\"start\":37673},{\"end\":38004,\"start\":37990},{\"end\":38018,\"start\":38004},{\"end\":38028,\"start\":38018},{\"end\":38320,\"start\":38299},{\"end\":38334,\"start\":38320},{\"end\":38349,\"start\":38334},{\"end\":38367,\"start\":38349},{\"end\":38728,\"start\":38715},{\"end\":38740,\"start\":38728},{\"end\":38752,\"start\":38740},{\"end\":38764,\"start\":38752},{\"end\":38774,\"start\":38764},{\"end\":39095,\"start\":39082},{\"end\":39109,\"start\":39095},{\"end\":39129,\"start\":39109},{\"end\":39386,\"start\":39373},{\"end\":39396,\"start\":39386},{\"end\":39407,\"start\":39396},{\"end\":39417,\"start\":39407},{\"end\":39703,\"start\":39690},{\"end\":39712,\"start\":39703},{\"end\":39723,\"start\":39712},{\"end\":39736,\"start\":39723},{\"end\":40031,\"start\":40019},{\"end\":40045,\"start\":40031},{\"end\":40049,\"start\":40045},{\"end\":40284,\"start\":40272},{\"end\":40297,\"start\":40284},{\"end\":40310,\"start\":40297},{\"end\":40320,\"start\":40310},{\"end\":40330,\"start\":40320},{\"end\":40619,\"start\":40611},{\"end\":40628,\"start\":40619},{\"end\":40639,\"start\":40628},{\"end\":40652,\"start\":40639},{\"end\":40942,\"start\":40930},{\"end\":40954,\"start\":40942},{\"end\":40973,\"start\":40954},{\"end\":41257,\"start\":41241},{\"end\":41272,\"start\":41257},{\"end\":41286,\"start\":41272},{\"end\":41300,\"start\":41286},{\"end\":41613,\"start\":41593},{\"end\":41629,\"start\":41613},{\"end\":41927,\"start\":41908},{\"end\":41944,\"start\":41927},{\"end\":41959,\"start\":41944},{\"end\":42221,\"start\":42202},{\"end\":42246,\"start\":42221},{\"end\":42255,\"start\":42246},{\"end\":42529,\"start\":42513},{\"end\":42541,\"start\":42529},{\"end\":42556,\"start\":42541},{\"end\":42818,\"start\":42802},{\"end\":42830,\"start\":42818},{\"end\":42853,\"start\":42830},{\"end\":42866,\"start\":42853},{\"end\":43140,\"start\":43121},{\"end\":43157,\"start\":43140},{\"end\":43173,\"start\":43157},{\"end\":43413,\"start\":43402},{\"end\":43427,\"start\":43413},{\"end\":43437,\"start\":43427},{\"end\":43445,\"start\":43437},{\"end\":43670,\"start\":43659},{\"end\":43685,\"start\":43670},{\"end\":43699,\"start\":43685},{\"end\":43711,\"start\":43699},{\"end\":43981,\"start\":43968},{\"end\":43994,\"start\":43981},{\"end\":44007,\"start\":43994},{\"end\":44278,\"start\":44269},{\"end\":44296,\"start\":44278},{\"end\":44523,\"start\":44500},{\"end\":44535,\"start\":44523},{\"end\":44551,\"start\":44535},{\"end\":44816,\"start\":44805},{\"end\":44834,\"start\":44816},{\"end\":44851,\"start\":44834},{\"end\":45257,\"start\":45242},{\"end\":45273,\"start\":45257},{\"end\":45287,\"start\":45273},{\"end\":45543,\"start\":45531},{\"end\":45556,\"start\":45543},{\"end\":45792,\"start\":45778},{\"end\":45802,\"start\":45792},{\"end\":45813,\"start\":45802},{\"end\":45828,\"start\":45813},{\"end\":45838,\"start\":45828},{\"end\":46108,\"start\":46093},{\"end\":46124,\"start\":46108},{\"end\":46138,\"start\":46124},{\"end\":46150,\"start\":46138},{\"end\":46397,\"start\":46387},{\"end\":46414,\"start\":46397},{\"end\":46429,\"start\":46414},{\"end\":46439,\"start\":46429}]", "bib_venue": "[{\"end\":34915,\"start\":34896},{\"end\":35254,\"start\":35234},{\"end\":35605,\"start\":35584},{\"end\":35995,\"start\":35973},{\"end\":36307,\"start\":36289},{\"end\":36576,\"start\":36557},{\"end\":36873,\"start\":36855},{\"end\":37290,\"start\":37269},{\"end\":37714,\"start\":37694},{\"end\":38048,\"start\":38028},{\"end\":38387,\"start\":38367},{\"end\":38792,\"start\":38774},{\"end\":39147,\"start\":39129},{\"end\":39436,\"start\":39417},{\"end\":39762,\"start\":39736},{\"end\":40017,\"start\":39975},{\"end\":40349,\"start\":40330},{\"end\":40677,\"start\":40652},{\"end\":40992,\"start\":40973},{\"end\":41318,\"start\":41300},{\"end\":41654,\"start\":41629},{\"end\":41978,\"start\":41959},{\"end\":42274,\"start\":42255},{\"end\":42574,\"start\":42556},{\"end\":42888,\"start\":42866},{\"end\":43191,\"start\":43173},{\"end\":43449,\"start\":43445},{\"end\":43730,\"start\":43711},{\"end\":44027,\"start\":44007},{\"end\":44316,\"start\":44296},{\"end\":44594,\"start\":44551},{\"end\":44924,\"start\":44851},{\"end\":45305,\"start\":45287},{\"end\":45575,\"start\":45556},{\"end\":45859,\"start\":45838},{\"end\":46169,\"start\":46150},{\"end\":46460,\"start\":46439},{\"end\":34921,\"start\":34917},{\"end\":35261,\"start\":35256},{\"end\":35613,\"start\":35607},{\"end\":36004,\"start\":35997},{\"end\":36323,\"start\":36309},{\"end\":36582,\"start\":36578},{\"end\":36898,\"start\":36875},{\"end\":37298,\"start\":37292},{\"end\":37721,\"start\":37716},{\"end\":38055,\"start\":38050},{\"end\":38405,\"start\":38389},{\"end\":38797,\"start\":38794},{\"end\":39152,\"start\":39149},{\"end\":39453,\"start\":39438},{\"end\":39775,\"start\":39764},{\"end\":40355,\"start\":40351},{\"end\":40689,\"start\":40679},{\"end\":40998,\"start\":40994},{\"end\":41323,\"start\":41320},{\"end\":41666,\"start\":41656},{\"end\":41984,\"start\":41980},{\"end\":42280,\"start\":42276},{\"end\":42579,\"start\":42576},{\"end\":42897,\"start\":42890},{\"end\":43196,\"start\":43193},{\"end\":43736,\"start\":43732},{\"end\":44034,\"start\":44029},{\"end\":44323,\"start\":44318},{\"end\":44984,\"start\":44926},{\"end\":45310,\"start\":45307},{\"end\":45592,\"start\":45577},{\"end\":45867,\"start\":45861},{\"end\":46186,\"start\":46171},{\"end\":46479,\"start\":46462}]"}}}, "year": 2023, "month": 12, "day": 17}