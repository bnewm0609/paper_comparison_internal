{"id": 258865481, "updated": "2023-12-14 03:42:55.878", "metadata": {"title": "Dancing Between Success and Failure: Edit-level Simplification Evaluation using SALSA", "authors": "[{\"first\":\"David\",\"last\":\"Heineman\",\"middle\":[]},{\"first\":\"Yao\",\"last\":\"Dou\",\"middle\":[]},{\"first\":\"Mounica\",\"last\":\"Maddela\",\"middle\":[]},{\"first\":\"Wei\",\"last\":\"Xu\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2023, "month": null, "day": null}, "abstract": "Large language models (e.g., GPT-4) are uniquely capable of producing highly rated text simplification, yet current human evaluation methods fail to provide a clear understanding of systems' specific strengths and weaknesses. To address this limitation, we introduce SALSA, an edit-based human annotation framework that enables holistic and fine-grained text simplification evaluation. We develop twenty one linguistically grounded edit types, covering the full spectrum of success and failure across dimensions of conceptual, syntactic and lexical simplicity. Using SALSA, we collect 19K edit annotations on 840 simplifications, revealing discrepancies in the distribution of simplification strategies performed by fine-tuned models, prompted LLMs and humans, and find GPT-3.5 performs more quality edits than humans, but still exhibits frequent errors. Using our fine-grained annotations, we develop LENS-SALSA, a reference-free automatic simplification metric, trained to predict sentence- and word-level quality simultaneously. Additionally, we introduce word-level quality estimation for simplification and report promising baseline results. Our data, new metric, and annotation toolkit are available at https://salsa-eval.com.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/emnlp/HeinemanDMX23", "doi": "10.18653/v1/2023.emnlp-main.211"}}, "content": {"source": {"pdf_hash": "3d4a89217c8e361c2adc80dec773ff1607f88a43", "pdf_src": "Arxiv", "pdf_uri": "[\"https://export.arxiv.org/pdf/2305.14458v2.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "e13ccd76d25fbd9fd0e897b179a012e8a373e263", "type": "plain-text", "url": "s3://ai2-s2-science-parse-plus-prod/parse-results/s2orc_worker/3d4a89217c8e361c2adc80dec773ff1607f88a43.txt", "contents": "\nDancing Between Success and Failure: Edit-level Simplification Evaluation using SALSA\n\n\nDavid Heineman david.heineman@gatech.edu \nSchool of Interactive Computing\nGeorgia Institute of Technology\n\n\nYao Dou douy@gatech.edu \nSchool of Interactive Computing\nGeorgia Institute of Technology\n\n\nMounica Maddela mmaddela@gatech.edu \nSchool of Interactive Computing\nGeorgia Institute of Technology\n\n\nWei Xu wei.xu@cc.gatech.edu \nSchool of Interactive Computing\nGeorgia Institute of Technology\n\n\nT5 3b \nMore Information Less Information Same Information Reorder Sentence Split Structure All T5 11B MUSS Zero-shot\nGPT-3.5 Few-shot GPT-3.5 Human Error Quality 3 2 1 +0+1+2+3 Error Quality 3 2 1 +0+1+2+3 Error Quality 3 2 1 +0+1+2+3 Error Quality 3 2 1 +0+1+2+3 Error Quality 3 2 1 +0+1+2+3 Error Quality 3 2 1 +0+1+2+3 Error Quality 3 2 1 +0+1+2+3\n\nDancing Between Success and Failure: Edit-level Simplification Evaluation using SALSA\nDA276F995AFACA3A23ABC91E5790DEE6\nLarge language models (e.g., GPT-4) are uniquely capable of producing highly rated text simplification, yet current human evaluation methods fail to provide a clear understanding of systems' specific strengths and weaknesses.To address this limitation, we introduce SALSA, an edit-based human annotation framework that enables holistic and fine-grained text simplification evaluation.We develop twenty one linguistically grounded edit types, covering the full spectrum of success and failure across dimensions of conceptual, syntactic and lexical simplicity.Using SALSA, we collect 19K edit annotations on 840 simplifications, revealing discrepancies in the distribution of simplification strategies performed by fine-tuned models, prompted LLMs and humans, and find GPT-3.5 performs more quality edits than humans, but still exhibits frequent errors.Using our finegrained annotations, we develop LENS-SALSA, a reference-free automatic simplification metric, trained to predict sentence-and word-level quality simultaneously.Additionally, we introduce word-level quality estimation for simplification and report promising baseline results.Our data, new metric, and annotation toolkit are available at https://salsa-eval.com.This isEXAMPLEZero-shot GPT-3.5 On 14 November, an interview with journalist Piers Morgan was published, where Ronaldo said ... On 14 November, Piers Morgan interviewed Ronaldo, who expressed ...\n\nIntroduction\n\nText simplification aims to improve a text's readability or content accessibility while preserving its fundamental meaning (Stajner, 2021;Chandrasekar et al., 1996).Traditional human evaluation for text simplification often relies on individual, shallow sentence-level ratings (Sulem et al., 2018c;Alva-Manchego et al., 2021), easily affected by the annotator's preference or bias.Maddela et al. (2023) recently proposes a more reliable and consistent human evaluation method by ranking and rating multiple simplifications altogether.However, as text simplification involves performing a series of transformations, or edits, such as paraphrasing, removing irrelevant details, or splitting a long sen-  tence into multiple shorter ones (Xu et al., 2012), sentence-level scoring remains difficult to interpret since it is not reflective of detailed information about the types of edits being performed.\n\nFine-grained human evaluation through span selection has been explored for machine translation (Lommel et al., 2014) and open-ended text generation (Dou et al., 2022).Yet, these evaluation methods are error-driven -i.e., focusing solely on evaluating failure -which punishes creative and diverse generations with minor errors in favor of generic ones.Additionally, machine translation and open-ended generation tasks usually retain none of the input words, while text simplification must balance the editing and preservation of words in the original input (Xu et al., 2016).We thus evaluate simplification quality as the aggregation of edit successes and failures, as depicted in Figure 1.\n\nWe introduce SALSA -Success and FAiluredriven Linguistic Simplification Annotation -an arXiv:2305.14458v2[cs.CL] 22 Oct 2023 edit-level human evaluation framework capturing a broad range of simplification transformations.SALSA is built on a comprehensive typology ( \u00a72) containing 21 quality and error edit types.Using SALSA, we develop an interactive interface and collect 19K edit annotations of 840 simplifications written by eleven state-of-the-art language models and two humans.With these annotations, we conduct a large-scale analysis of model and automatic metric performance, and further introduce the automatic word-level quality estimation task for text simplification.Our main findings are as follows:\n\n\u2022 Few-shot GPT-3.5 far surpasses existing models, particularly in making syntax and content edits.However, its simplifications are not aligned to the types of operations performed by human.( \u00a74) \u2022 Some fine-tuned models such as the MUSS (Martin et al., 2022) produce more diverse edits than GPT-3.5, yet suffer from incredibly high errors, while others (T5, Raffel et al., 2020) learn to minimize loss by making very few changes.( \u00a74) \u2022 Open-source instruction fine-tuned models such as Alpaca (Taori et al., 2023) and Vicuna (Chiang et al., 2023) perform a similar number of edits as GPT-3.5, but at a cost of more conceptual errors due to the inherent limits of model imitation.( \u00a74) \u2022 Fine-tuned on SALSA annotations, our referencefree metric, LENS-SALSA, captures the subtleties of specific simplification approaches beyond existing automatic evaluation metrics.( \u00a75) \u2022 Leveraging our data, we present the automatic word-level quality estimation task for text simplification and establish several baseline approaches for future modeling efforts.( \u00a76)\n\nOur results demonstrate that SALSA provides an interpretable and exhaustive evaluation of text simplification.\n\n\nSALSA Framework\n\nWe introduce SALSA, an edit-based human evaluation framework for text simplification.SALSA is defined by a typology of 21 linguistically-grounded edit types with the aim of capturing both successes and failures (i.e., quality changes and errors, see Figure 1).The annotation methodology of SALSA is structured as a decision tree and implemented via an easy-to-use interface, illustrated in Figure 2. Our interface is designed with Thresh (Heineman et al., 2023), and we release our configuration to encourage adaptation to other text rewriting tasks  4) rating efficacy/severity.(Du et al., 2022) or collecting fine-grained human feedback (Wu et al., 2023) 1 .In the following, we describe each step of the annotation process.\n\n\nEdit Selection\n\nAnnotation begins with edit selection, where annotators identify the edits performed by the simplification and select the corresponding spans for each edit.We define six types of edit operations: single-operation insertion, deletion, substitution, word-/clause-reorder, and multi-operation sentence split and structure changes.An insertion or deletion edit exclusively modifies content, while a substitution either modifies or paraphrases content.Reorder, split, or structure edits perform a contextfree syntax transformation.As split and structure edits are multi-operation (i.e., require a combination of single operations), they are defined by a set of underlying single-operation constituent edits.For example, this structure change from passive to active voice made by zero-shot GPT-3.5 involves multiple constituent edits:\n\n\nCategorizing by Information Change\n\nEach selected edit is then labeled with its impact on the underlying sentence information: less, same, more or different information.Given the type of operation and change to information, we subsequently organize each edit into three linguistic families as defined by Siddharthan (2014): Lexical edits perform simple changes in \"wording\".This includes paraphrasing (i.e., substitution that keeps the same information) and inconsequential trivial changes (e.g., inserting 'the').Syntax edits capture transformations to the distribution of information, rather than substance.A split converts a candidate sentence to two sentences, a re-order edit re-arranges clauses or wording within a clause, and a structural edit modifies the voice, tense or clausal structure.Examples of structural edit sub-types are in Appendix B. Conceptual edits modify underlying ideas conveyed by the text.A conceptual edit requires elaboration to add clarifying information or generalization to delete unnecessary/complicated ideas.\n\n\nEdit Type Classification\n\nAfter being categorized into lexical, syntax, or conceptual edit families, we further classify each edit operation into 21 fine-grained success (quality), failure (error), or trivial edit types as listed in Figure 3. Successful edits simplify through diverse approaches, from paraphrasing complex spans, generalization of unnecessary information, or elaboration to add clarity and background context.E.g.,\n\n\nEXAMPLE (elaboration)\n\nVicuna 7B ... can be fitted to an exponentially decaying curve.\n\n... can be represented by a curve that gets smaller and smaller over time.\n\nOften small edits, particularly to syntactic structure, can improve clarity, such as this addition of a clear subject-verb structure through the inclusion of the relative pronoun 'who':\nEXAMPLE (structure change)\nGPT-4 Paltrow in turn claims he was the one crashing rather than the other way around.Paltrow says he was the one who crashed, not her.\n\nOr this conversion of the participial phrase to a relative clause to help explain significance: Sentence splitting or reordering information may clarify a sequence of events:\nEXAMPLE (component reorder)\nChatGPT Poland announces the closure of a major border crossing with Belarus \"until further notice\" amid heightened tensions between the two countries.Poland has closed a big border crossing with Belarus due to increased tensions between the two countries.The closure will remain in effect until further notice.\n\nFailure edits include any ablation from minor readability issues to hallucinations or deletions to sentence meaning.In the following example, the coreference error captures the deleted reference between the 'ICJ' and 'US' acronyms to their original definitions, useful contextual information:\nEXAMPLE (coreference error)\nChatGPT The International Court of Justice (ICJ) rules that the United States violated its ... The ICJ said that the US broke its ...And often multiple edits overlap, such as this information rewrite which successfully adds clarity via reordering, but botches the author's sarcasm: EXAMPLE (information rewrite) Alpaca 7B ... justifies a runtime nearing 3 hours (with a postcredits scene, no less), and it already opened to over $100 million worldwide... takes up almost 3 hours of the movie.The movie opened to over $100 million worldwide.A post-credits scene completes the story.\n\nWe also separately ask annotators to identify if the edit contains a grammar error.Appendix A provides an exhaustive description and examples for each edit type.\n\n\nRating Edit Efficacy / Severity\n\nAs each edit has a varying degree of impact on overall simplification quality, we finally ask annotators to rate the efficacy of quality edits or severity of error edits.We define three levels: 1 -minor, 2 -somewhat, and 3 -major.Examples of each severity level are included in Appendix A.3.\n\n\nData Collection\n\nWe describe our use of SALSA to collect 19K edit annotations covering 11.6K spans on 840 modelgenerated and human-written simplifications.\n\n\nSimplification Data\n\nData collection is performed on an extended version of SIMPEVAL 2022 (Maddela et al., 2023), including a train set covering state-of-the-art simplification systems and held-out test set of recent LLMs.We include a full description of each system in Appendix C.1.SALSA Train.We first extend the 360 simplifications from SIMPEVAL 2022 to 700 simplifications based on 100 complex sentences from Wikipedia articles dated between Oct 2022 and Dec 2022.The complex sentences are unseen during the training of the LLMs and were selected to be intentionally difficult (avg.length of 37.3 words) to enable an evaluation of the models' full capabilities in performing diverse simplification edits.Simplifications are generated by five models including fine-tuned T5-3B and T5-11B (Raffel et al., 2020), MUSS (Martin et al., 2022), a controllable BARTlarge model trained with unsupervised, mined paraphrases, zero-and few-shot GPT-3.5 (Ouyang et al., 2022), and two human-written references.For modeling experiments in \u00a75 and \u00a76, we divide the initial 700 simplifications by the complex sentence with a 70/30% train/dev split.SALSA Test.We further gather 20 more complex sentences from Wikipedia articles published in Mar 2023 and generate 140 simplifications using recent LLMs including GPT-3.5, ChatGPT, GPT-4, Alpaca-7B (Touvron et al., 2023) and Vicuna-7B (Chiang et al., 2023), along with T5-3B and T5-11B fine-tuned with control tokens.\n\n\nAnnotation\n\nAs crowd-sourced annotators have shown to have inconsistent quality (Shmueli et al., 2021), we hire 6 undergraduate students from a US university.Annotators were trained with an in-depth tutorial con- To concretely measure agreement for each stage of the SALSA framework, we collect annotations in three stages: (1) we have three annotators select edits, (2) a fourth annotator adjudicates the edits into a single selection and (3) the initial three annotators classify and rate the adjudicated edits.Figure 2 illustrates our annotation interface, with further screenshots of our tutorial included in Appendix G.\n\n\nInter-Annotator Agreement\n\nWe calculate edit selection agreement (i.e.agreement prior to adjudication) by each token, with Table 1 reporting agreement per edit, further broken down by their type of information change.We observe edit agreement is highly dependent on the edit type and type of information change being performed.High agreements are seen for deletion (\u03b1=0.75),paraphrase (substitution with the same information, \u03b1=0.53), and sentence splits (\u03b1=0.66).Substitution that introduces more information, however, exhibits lower agreement (\u03b1=0.15),due to the subjectivity among annotators on determining whether new tokens contain 'novel' information, as was often mixed up with insertion.Reordering (\u03b1=0.12) and structure edits (\u03b1=0.25) also report lower agreements.We fully explore the phenomenon of annotator disagreement in Appendix C.2, and find overlapping syntactic and content edits often have multiple correct interpretations, leading to an inherent disagreement.Additionally, we find our % rates for annotator agreement are similar to fine-grained evaluation frameworks in other text generation tasks (Dou et al., 2022).Figure 5: Failure edits per-model, organized by edit type.Compared to humans, both GPT-3.5 setups make more syntax and lexical errors.Although humans perform bad deletion errors at a higher frequency than GPT-3.5, this is reflective of the inherent ambiguity in judging the relevancy of the deleted content.\n\n\nKey Analysis\n\nWe use SALSA to evaluate state-of-the-art simplification by collecting annotations on our extended version of the SIMPEVAL corpus (Maddela et al., 2023), which includes fine-tuned, LLM-and human-written simplifications.Our resulting data collection includes 19K edit annotations across 840 simplifications.\n\nWe present our primary results in Figures 4, 5, and 6.Figures 4 and 5 illustrate the frequency of quality and error edit types.As edits vary in length, we calculate edit coverage: the length of each edit in proportion to the total length of the simplification and report the average edit coverage for different efficacy and severity ratings in 6, showing a view of edit ratings adjusted for length.Additionally, we include Figure 7, which compares simplifications generated by recent instruction fine-tuned language models.The following are our key findings: Models primarily write good edits, but still trail humans (Fig. 4, 5).We observe that 16% of modelgenerated edits are errors, with the best-performing model, few-shot GPT-3.5, producing errors in only 9% of edits.We find this still trails human simplifications, which have an error rate of 6%.MUSS and GPT-3.5 have a median count of 1 error per simplification and 63% of their simplifications contain at least one error, showing these errors are not concentrated in a few 'bad' simplifications but instead often occur among many good edits.\n\nLanguage models elaborate, while humans generalize (Fig. 4).When simplifying content, all models (excluding T5) tend to elaborate at a higher ratio than humans, for example, GPT-3.5 attempts to insert content 17% more often.As LLMs have shown to encode world knowledge in their parameters (Petroni et al., 2019;Brown et al., 2020), GPT-3.5 elaboration is far more effective than MUSS, for example:\n\n\nEXAMPLE\n\nFew-shot GPT-3.5After defeating PSD candidate Viorica D\u0203ncil\u0203 by a landslide in 2019, his second term..In 2019, Klaus Iohannis defeated PSD candidate Viorica D\u0203ncil\u0203 by a large margin.His second term.. GPT-3.5 writes quality edits at a higher frequency than humans, but human edits are longer and more effective (Fig. 4, 6).Both zeroshot and few-shot GPT-3.5 produce a larger number of edits, but human edits are more substantial, as demonstrated by the higher edit coverage across all efficacy levels, particularly for syntax and lexical edits.Human simplification typically deletes, paraphrases, or reorders entire clauses, while GPT-3.5 often edits single modifiers or words.\n\nFine-tuned T5-3B and T5-11B generate conservative simplifications (Fig. 4,5,6).Compared to all other systems, both T5 models make minimal changes in terms of frequency and edit coverage, Figure 6: Edit coverage of efficacy (+) and severity (-) ratings for each model, separated by simplification approach, with edit coverage defined as (len(e C ) + len(e S ))/(len(C) + len(S)) (see \u00a7A.4).Overall, humans make the longest quality edits and most infrequent error edits.We report the distribution of each edit rating in Figure 14.\n\nwhile still exhibiting high rates of error.This is likely due to their training data, Wiki-Auto (Jiang et al., 2020), containing shorter sentences, usually requiring simpler simplification techniques, making it difficult for models to generalize on longer and more complex sentences.Later in Appendix D, we show using control tokens (Martin et al., 2020) during training, as done by MUSS, can improve diversity but at the expense of increasing deletion and hallucination errors.Split edits are straightforward, Structure edits are far more complex (Fig. 4, 5).Surprisingly, sentence splitting is shown to be the easiest edit for all models to accomplish, with a similar number made by MUSS, GPT-3.5, and humans, with even the conservative T5 models making a comparable number of split edits.However, structure change and re-ordering edits are rarely seen in fine-tuned models.We speculate this may be attributed to (i) these types of edits are infrequent in the training data and (ii) GPT-3.5 has a unique ability to perform complicated syntax rewriting, echo with the findings in abstractive summarization (Goyal et al., 2022).Despite GPT-3.5'simprovement, the structure error rate demonstrates it has not yet reached human-level ability.Additionally, we observe zeroshot GPT-3.5 produces structure errors (see below example) at a 19% rate higher than few-shot.\n\n\nEXAMPLE\n\nZero-shot GPT-3.5The sentence included a fine of $400...You will receive a fine of $400...We find human simplifications are more conservative with re-ordering than models, yet attempts to simplify with re-ordering often appear arbitrary:\n\n\nEXAMPLE\n\nHuman written On 3 November 2022, the British Secretary... On November 3rd, 2022, the British Secretary... Humans appear to produce bad deletion errors, but these are often subjective (Fig. 5).Bad dele-tion constitutes 35% of error edits made by humans, compared to 8% by few-shot GPT-3.5.The anomaly of the bad deletion errors reveals an inherent subjectivity in assessing deletion:\n\n\nEXAMPLE\n\nHuman written Unlike the first film adaptation, in which director Samuel Fuller removed... Unlike the first film adaptation, Samuel Fuller removed...In this example, some annotators marked the edit as a bad deletion while others consider it appropriate.As the sentence discusses a book adaptation into a film, the description of 'Samuel Fuller' is helpful depending on the reader, which underscores the need for adaptive levels of simplification to accommodate each reader's needs.\n\nParaphrasing is a crucial, but tricky mechanism (Fig. 4, 5).MUSS, GPT-3.5, and humans all paraphrase in at least 75% of sentences.Despite low performance in conceptual and syntactic simplification, MUSS paraphrases at a human-like rate likely due to its training on over one million paraphrase sentence pairs mined from web crawl data.Although zero-/few-shot GPT-3.5 paraphrases at a higher rate than humans, these edits are often are unnecessary.For instance:\n\n\nEXAMPLE\n\nFew-shot GPT-3.5The club said on social media that customers subdued the gunman...The club reported on social media that customers were able...\n\nOpen-source LLMs are approaching GPT-3.5 simplifications, or are they (Fig. 7)?Given recent attention to ChatGPT (OpenAI, 2022), GPT-4 (OpenAI, 2023), and the emergence of instruction fine-tuning smaller language models on outputs from proprietary LLMs, we perform a supplementary evaluation on these systems.The open-source Alpaca (Taori et al., 2023) and Vicuna (Chiang et al., 2023) appear to perform a similar number of   quality and error edits to GPT-3.5.However, these systems tend to write far more bad elaboration errors such as factual errors or contradictions: EXAMPLE Alpaca 7B ... a controversial \"angel tax\" provision seeking to capture some of the income entering the country from foreign investors funding India's start-ups.... a controversial \"angel tax\" provision, which is aimed at stopping foreign investors from funneling money into India's startups.\n\nThis behavior suggests open-source instruction finetuned models mimic the style of their larger counterparts, but not their knowledge, a phenomenon observed by Gudibande et al. (2023).GPT-4 exhibits the best performance by making fewer content errors while producing a high number of quality edits, but still exhibits errors particularly when paraphrasing individual spans without considering the broader sentence meaning:\n\n\nEXAMPLE\n\nGPT-4 Grocery inflation in the United Kingdom reaches a record high of 17.1% ... The cost of groceries in the United Kingdom has increased to a record 17.1% ... While GPT-4 successfully paraphrases inflation by relating to cost, it fails to recognize the sentence is discussing inflation rate, rather than exact prices.\n\nWe include further analysis, discussion, and dataset statistics in Appendix D.\n\n\nEvaluating Metric Edit Sensitivity\n\nWhile automatic metrics are traditionally evaluated using correlation with sentence-level, Likert scale human ratings on dimensions of adequacy, fluency and simplicity, this fails to understand the ability of automatic metrics to capture the subtleties of lexical, syntactic, and conceptual simplification.With our SALSA annotations, we study how well current automatic metrics capture these distinct simplification approaches.Additionally, we introduce LENS-SALSA, a reference-free metric fine-tuned on SALSA annotations.Existing Automatic Metrics.We consider five automatic metrics: BLEU (Papineni et al., 2002), SARI (Xu et al., 2016), the most widely-used text simplification metric, BERTSCORE (Zhang et al., 2020), COMET-MQM, a machine translation metric (Rei et al., 2020) trained on MQM ratings (Freitag et al., 2021), and LENS (Maddela et al., 2023), a recently proposed text simplification metric finetuned on SIMPEVAL that contains rank-based human ratings of simplifications from 24 systems.LENS-SALSA.The automatic simplification metrics mentioned above require human-written references, which may not be available in every evaluation setting.To this end, we introduce LENS-SALSA, a reference-free simplification metric enabled by edit-level information.Based on the COMETKIWI machine translation metric design (Rei et al., 2022), we first pre-train LENS-SALSA on the sentence-level human ratings from SIMPE-VAL using UniTE (Wan et al., 2022), a multi-task learning method.Specifically, the metric is trained on the same score but from three input formats: Simp:Ref, Simp:Complex, and Simp:Complex:Ref, where \":\" denotes concatenation.Then, we finetune LENS-SALSA on SALSA annotations using a dual-objective to predict both the sentence-level score (calculated by LENS) and a word-level quality score \u0175i \u2208 [\u22123, 3], corresponding to the efficacy or severity rating ( \u00a72.4) of each word w i in the complex and simplified sentences.We use RoBERTa-large as the base model for LENS-SALSA, and 490, 210, and 140 sentence pairs for train, validation, and test, respectively.Implementation details are provided in Appendix F.2.\nB L E U S A R I B E R T S C O R E C O M E T -M Q M L E N S L E N S -S A L S A\nResults.As fine-grained MQM annotations in machine translation are considered a gold-standard in metric evaluation (Freitag et al., 2021), we adapt their method (detailed in \u00a7A.4) to collapse edit-level ratings to a single score, and calculate subscores by only considering certain edit types.Table 2 reports the Pearson correlation between metric scores and human sub-scores across each SALSA dimension.LENS-SALSA achieves the highest correlation in nearly all edit approaches, showing its capability to capture all forms of simplification.Overall, only LENS and LENS-SALSA obtain substantial correlation with the overall human SALSA scores (0.33 and 0.45 respectively), while other metrics have spurious and even negative correlations with human judgments.Interestingly, COMET-MQM, intended for machine translation, performs better than BLEU and BERTScore, which further underlines the value of span-based ratings for trained metrics.Despite strong performance, we find LENS mainly evaluates lexical and syntactic edits, rather than conceptual ones, which may be attributed to its training data consisting of shorter, paraphrasebased simplifications.Lastly, all metrics have substantially higher correlation with quality than error edits.We posit this is primarily due to the sparsity and wide range of errors exhibited in the generations of current high-performing systems.\n\n6 Word-Level Quality Estimation\n\nWord-level quality estimation (QE) is the task of predicting the quality of each token in a generation, and has substantial downstream application to evaluating and refining text simplification.Despite word-level QE being a well understood task in machine translation (Basu et al., 2018;Zerva et al., 2022), it has not yet been studied for text simplification due to a lack of appropriately annotated data.In this section, we use SALSA annotations to demonstrate baseline approaches and highlight potential for future work.\n\nTask.We define word-level simplification QE as classifying each token in the complex and simplified sentences as quality, error, or ok.To adapt SALSA for the QE task, we label each token by the average efficacy/severity rating of its associated edit: < 0 as error, = 0 as ok, and > 0 as quality.Words that are not part of any edits default to the ok label.We deconstruct split and structure edits into their constituent edits, only label the simplified spans for substitution edits, and exclude reorder edits due to their low frequency.Methods.We propose two approaches: End-toend, where a single model labels each token directly; and Two-stage, where a word aligner first identifies edits, then the model labels each token using the identified edit information.For end-to-end, we implement the following two methods: Tagging (Tag) is a native sequence tagging model with a classification head.\n\nTagging with Multi-task Loss (Tag-ML) is similar to the tagging method except trained with a multi-task loss function: L = L tag + L ec .L ec is an additional objective that classifies each token into none, deletion, substitution, or insertion.\n\nFor two-stage methods, we first apply a QAbased word aligner (Nagata et al., 2020) to the sentence pair and use a set of rules to convert word alignments to edits: consecutive non-aligned words in the original sentence are labeled as a deletion edit; consecutive non-aligned words in the simplified sentence are labeled as an insertion edit; and aligned words or spans that differ are labeled as a substitution edit.Here are three two-stage methods:\n\nTagging with Edit Information (Tag-EI) is a sequence tagging model with a classification head that takes the concatenation of the hidden states of both edit type and token as the input.The hidden states of the edit type are obtained via a linear layer.\n\nEdit Classification with Separate Classifiers (Ec-Sep) contains one classifier for each of the three edit operations.Each classifier is an encoder model with a feedforward neural network (FNN).The inputs to these FNNs are the hidden states of the [CLS] token and the max-pooled tokens from the edit spans (i.e., for substitution edit, one from the original span, and one from the simplified span).\n\nEdit Classification with One Classifier (Ec-One) is one classifier with three FNNs mentioned above.The difference is the encoder is trained collectively.\n\nAll methods (including the word aligner) use RoBERTa-large.Further implementation details and results are included in Appendix F.\n\nResults.Table 3 shows the test set performance for each label.Among the end-to-end methods, training with multi-task loss results in improvement on all three label F1 scores, achieving the second-best average F1 score overall.We find edit classification approaches detect error tokens more accurately than tagging approaches.Within edit classification methods, using one classifier outperforms multiple ones due to the benefit of joint encoder training.Overall, the edit classification with one classifier method performs the best with a gain of over 11 points on error F1 and a 4-point increase in average F1, compared to the base tagging model.\n\n\nRelated Work\n\nModel Evaluation.Simplification work broadly agrees some typology of simplification operations exists (Siddharthan, 2014), starting with early rulebased systems which explicitly defined specific syntax operations (Dras, 1999).Past work has experimented with designing models to control the extent of each operation by using a pipeline to perform simplification operations independently (Maddela et al., 2021;Raffel et al., 2020), predicting edit operations (Dong et al., 2019) or augmenting finetuned models with learned control tokens (Martin et al., 2020(Martin et al., , 2022)).However, evaluation only considers a sentence in its entirety rather than rating individual operations, either by automatic metrics (Kriz et al., 2020), shown to be an inadequate representation of quality (Alva-Manchego et al., 2021;Sulem et al., 2018a), or by surface-level Likert ratings, typically asking crowd-sourced annotators to rate on scales of fluency, adequacy, and simplicity.These scores are difficult to interpret and capture no detail into the type of simplification being written (Briakou et al., 2021;Hashimoto et al., 2019).Additionally, despite current systems' often producing simplification errors (Choshen and Abend, 2018), annotating error has primarily been performed through inspection, and has not been incorporated into human or automatic evaluation (Gooding, 2022).Linguistic Inspection.Manual inspection attempts to understand the behavior of simplification models or datasets, characterized by detailed typologies and often conducted by authors or domain experts.Cardon et al. (2022) performs detailed inspection of the ASSET simplification test corpus (Alva-Manchego et al., 2020a) to study the behavior of automatic metrics and Cumbicus-Pineda et al. (2021a) propose a framework for evaluating success and failure by answering a series of checklist items, with sentences given a capability score based on the number of requirements fulfilled.Yamaguchi et al. (2023) annotates simplifications of earlier models such as DRESS (Zhang and Lapata, 2017) and SUC (Sun et al., 2020) using a taxonomy of 62 error categories, but do not analyze the SOTA, MUSS, or LLMs.Stodden and Kallmeyer (2022) proposes an interactive linguistic inspection interface, but this interface is not designed for human evaluation of model outputs and does not provide ratings for measuring performance.\n\nFine-grained Human Evaluation.Human evaluation performed on a span-level has been previously proposed for a variety of NLP tasks.In translation, the Multidimensional Quality Metrics (MQM) (Lommel et al., 2014), categorizes error into accuracy and fluency sub-types and is later extended by Freitag et al. (2021) to weight errors by severity and combine into a single quality score.Dou et al. (2022) proposes SCARECROW to capture errors appearing in open-ended text generation.However, as these span-based evaluation schemes exclusively annotate error, they encourage generic outputs and punish interesting or diverse generations.For summarization, the FRANK typology (Pagnoni et al., 2021) aggregates errors into broader categories to benchmark metrics that measure factuality.Inspired by FRANK, Devaraj et al. (2022) introduces a framework to evaluate factuality for text simplification.\n\n\nConclusion\n\nIn this work, we introduce SALSA, a novel editbased evaluation framework incorporating error and quality evaluation, and dimensions of lexical, syntax and conceptual simplification and demonstrate SALSA benefits in granularity, accuracy, and consistency.We employ SALSA to collect a 19K edit annotation dataset and analyze the strengths and limitations of fine-tuned models, prompted LLMs, and human simplifications.Finally, we use SALSA annotations to develop a reference-free automatic metric for text simplification and demonstrate strong baselines for word-level quality estimation, showing promising avenues for the development of fine-grained human evaluation.\n\n\nLimitations\n\nOur annotation only represents a single use case of text simplification and we encourage an extension of SALSA to domain-specific simplification, such as medical (Joseph et al., 2023), legal (Garimella et al., 2022), or multi-lingual text (Ryan et al., 2023), and annotations by groups of specific downstream users (Stajner, 2021).The LENS-SALSA reference-free metric is trained exclusively on Wikipedia simplification, and we do not consider its cross-domain generalization or its ability to capture the simplification need to specific target communities.Additionally, while we demonstrate promising results on sentence-level evaluation, simplification is often a document-level task (Laban et al., 2021;Sun et al., 2021).Incorporating higherlevel operations such as sentence fusion, paragraph compression, and reordering would require an extension to SALSA and presents unique analytical challenges.Finally, detailed human evaluation inherently requires greater resources to produce a high granularity of annotations.While we show this process can be streamlined with a robust annotator training, SALSA requires a similar amount of resources as widely used fine-grained evaluation in other tasks such as MQM (Lommel et al., 2014) or FRANK (Pagnoni et al., 2021).\n\n\nEthics Statement\n\nOur annotations were performed using the SIMPE-VAL 2022 corpus, originally collected from publicly available Wikipedia articles (Maddela et al., 2023) and we further extend the dataset with complex sentences collecting using the same methodology from publicly available Wikipedia articles.As discussed in \u00a73.2, we perform data collection with in-house annotators from a US university.Annotators were all native English speakers and paid $15-$18/hour.We took care to manually review all data prior to annotation as to exclude any triggering or sensitive material from our annotation data.Annotators were informed that any data they felt uncomfortable with was not required to annotate.Our interface was built using the open-source Vue.js2 library, and training of our added T5-11B system was implemented using the open-source Hugging Face Transformers3 library.\n\n\nA Defining the SALSA Framework\n\nWe provide detail into the SALSA framework, including qualitative examples which helped guide design decisions when building the typology.Table 4 illustrates each final edit type, as organized by Figure 3.During development, we adjusted our scheme based on preliminary annotations with the final goal of SALSA's ability to evenly represent all modes of simplification and the full space of errors.\n\n\nA.1 Quality Evaluation\n\nWe organize quality edits by their approach to simplification, as real-world application and models' capability to simplify falls into tiers of conceptual, syntactic and lexical simplification (Stajner, 2021).An ideal simplification system demonstrates a balance of these 'tiers' and incorporates different techniques depending on the original text, context and users (Gooding and Tragut, 2022).Automatic simplification research initially focused on lexical paraphrasing (Siddharthan, 2014), but has since evolved to emphasize the importance of syntactic and conceptual editing (Alva-Manchego et al., 2020b).\n\n\nA.1.1 Conceptual Simplification\n\nThese edits modify the underlying sentence information or ideas, a prerequisite for simplifying complex domains.We consider 'conceptual simplification' to be interchangeable with 'semantic simplification' as used in some literature (Sulem et al., 2018b;Jiang et al., 2022).\n\nElaboration.An addition of meaningful, relevant and correct information (Siddharthan, 2006), such as clarifying vague terminology, providing background information on an entity or subject, or explicating general world knowledge unknown to the audience.Elaboration has been shown as a rare, but helpful mechanism in text generation (Cao et al., 2022) and we observe its careful use in human simplifications.Generalization.A deletion of unnecessary, irrelevant or complicated concepts.Although we ask annotators to rate the quality of elaboration by how it improves the readability of a sentence, we ask annotators to rate the quality of a generalization by the relevancy of the deleted information to the main idea of the sentence.As 'relevancy' is inherently subjective to the user, domain and annotator, determining the threshold for 'necessary information' is crucial to standardize (Devaraj et al., 2022).Deleting information will, by nature, contain some amount of information and SALSA instead focuses on ensuring the deleted information is not important sentence, context or users.Consider two candidate deletions: EXAMPLE Like so many hyped books before it, The Midnight Library excited me and gave me pause.Like so many hyped books before it, The Midnight Library excited me and gave me pause.\n\nAlthough the deletion of Midnight is shorter, it changed the subject of the sentence, and it is rated higher than the second deletion, which is not central to the main idea.Generalization using paraphrase is more often preferred than deleting full clauses.\n\nWe observe successful conceptual edits are often performed on the clause level.For example, adjunct removal via deletion: EXAMPLE Born into slavery in 1856, Booker T. Washington became an influential African American leader.Booker T. Washington became an influential African American leader.\n\nOr information insertion through an appositive or relative clause, although the prior is typically more common for the SIMPEVAL domain as it implies objective information: EXAMPLE \u00c9ric Gauthier is also a novella author... \u00c9ric Gauthier, famous for his soloist dancing career, is also a novella author...\n\n\nA.1.2 Syntactic Simplification\n\nSyntax is a crucial mechanism for fluent, highly modified simplification (\u0160tajner, 2016).Given recent attention in automatic simplification to syntaxaware datasets and systems (Cumbicus-Pineda et al., 2021b;Kumar et al., 2020;Alva-Manchego et al., 2020a;Scarton et al., 2017), SALSA standardizes the first explicit evaluation accounting for these operations.Information Reorder.We classify two levels of reorder, word-level reorder, which reorganizes modifiers within a phrase, and component-level reorder which moves clauses or content across a sentence (Siddharthan, 2006).A component-level re-order typically may be accompanied by a broader structure change or both re-order types may overlap, as in:\n\n\nEXAMPLE\n\nThe emergence of huge radio conglomerates is a direct consequence of the '96 Act.The '96 Act had a direct consequence of the emergence of huge radio conglomerates.\n\nWhen faced with two equivalent phrases (e.g.'A and B' \u2192 'B and A'), SALSA classifies the reordered span as the phrase more significant to the main idea of the sentence.In practice, we found this to be a helpful guideline, although annotators often simply selected the phrase appearing first in the candidate sentence.\n\nStructural Change.As this syntax modification necessarily includes some discourse preserving edits (Gooding, 2022), they are defined w.r.t.some combination of constituent edits (i.e.insertion, deletion, substitution, reorder).Further discussion of structure changes in \u00a7B, with examples of structural change sub-types used for manual inspection in Table 5.\n\nSentence Split.A sub-type of a structural edit.We automatically identify split changes prior to annotation, but annotators must first select constituent spans and then associate those spans with the corresponding sentence split.We find the importance of this edit is highly domain-dependent (Figure 13).\n\n\nA.1.3 Lexical Simplification\n\nParaphrase.Swapping complex spans with equivalent, simpler alternatives, is the most primitive, yet important, approach to simplification (Qiang et al., 2020) (also referred to as a hypernym, e.g.\u0160tajner, 2016).These are exclusively defined by substitutions marked as same information and positive impact.Trivial Change.Captures any minor modifications to wording, either through a synonym replacement, or inconsequential change in wording (e.g.the, a).Trivial changes are identified as trivial insertion, trivial deletion or trivial substitution.These edits differ from a content or syntax modification in that they adds no new or major modification to the presentation of information.However, Meister et al. (2020) exemplifies trivial changes should not be ignored as they may modify the information density and verbosity of a sentence.An example is famously shown by Jaeger and Levy (2006): EXAMPLE How big is the family you cook for?How big is the family that you cook for?\n\nThe relativizer 'that' creates no syntactic or conceptual simplicity, but adds clarity as to the identify of the subject.Trivial changes have previously been described with finer granularity, including subcategories like abbreviation, filler words, compound segmentation, anaphora (Stodden and Kallmeyer, 2022) or even changes in number/date formatting (Cardon et al., 2022) but we exclude these groups due to their sparsity and our focus on evaluating performance.\n\n\nA.2 Error Evaluation\n\nWe describe the SALSA error typology, with examples of each type in Table 4.Although despite their sparsity, errors have a far greater impact on fluency and adequacy than individual quality edits (Chen et al., 2023).We refined our definition of errors by focusing on minimizing the amount of error types while retaining the ability to capture the full possibility of simplification ablations.Notably, we specifically exclude a hallucination due to its ambiguous definition in related work (Ji et al., 2023), and instead define our error categories to capture any possible hallucination.\n\n\nA.2.1 Conceptual Errors\n\nWe identify six types of errors in content, with errors primarily being related to information insertion.\n\nBad deletion.As the overwhelmingly most common error, a bad deletion removes necessary and relevant content to the main idea of the sentence.As discussed in \u00a7A.1.1,the threshold for 'relevancy' is ambiguous.Coreference.More precisely a failure in coreference or anaphora resolution (Maddela et al., 2021), this determines whether an explicit entity reference is removed.This error is only observed on a deletion of information.or generating new information making the sentence contradict itself: EXAMPLE Dextrose adds flavor and texture to dishes, although its consumption is known for negative consequences.Dextrose adds flavor, texture and nutrition to dishes, although its consumption is known for negative consequences.\n\nFactual Error.We asked annotators to use their commonsense knowledge and limited research to evaluate factuality in edits.Unlike contradiction, these claims introduce information which must be externally verified beyond the sentence context.Although factual content is an established focus for summarization evaluation (Pagnoni et al., 2021;Maynez et al., 2020), adequately retaining information (i.e.minimizing bad deletion) is a far greater concern for simplification (Devaraj et al., 2022).\n\n\nEXAMPLE Hilary Clinton was born in 1947.\n\nHilary Clinton was born in 1947 outside the United States.\n\nIn the context of work studying hallucination in LLMs, our contradiction and factual error categories can be interpreted as intrinsic and extrinsic hallucination respectively (Ji et al., 2023).Irrelevant.A sub-type of a hallucination failing to insert information related to the main idea of the sentence, recognizing the threshold for 'relevancy' is ambiguous ( \u00a7A.1.1).For simplicity, we report irrelevancy alongside hallucination, as information insertion is generally a rare technique.\n\n\nA.2.2 Syntactic Errors\n\nBecause syntactic edits are identified by the impact of information distribution, they do not need a finegrained error typology like conceptual edits, which make a diverse set of modifications.We simply observe each type as a failed attempted at their respective transformations.Bad Reorder.Uses the same word-/phrase-level specification as quality reorder.We also observe that phrase-level reorder errors are almost exclusively observed to introduce a discontinuity to the syntax tree structure (Paetzold Specia, 2013).Bad Structure.We manually inspect structural errors according to the same sub-type specification as quality edits ( \u00a7B).Bad Sentence Split.Although sentence splitting is rarely rated as unhelpful, simplifications may unnecessarily segment ideas, or interrupt the flow of information.\n\n\nA.2.3 Lexical Errors\n\nUnrelated to information change, lexical errors evaluate primitive issues in fluency or wording.Complex Wording.An attempted paraphrase where the exact meaning is retained, but the replacement uses more complex semantics (also referred to as a hyponym, e.g.Stodden and Kallmeyer, 2022).\n\n\nEXAMPLE\n\nThe researchers conducted an investigation.\n\nThe researchers conducted an assay.\n\nInformation Rewrite.Some substituted span whose content concerns the same subject, but fails to substitute the wording correctly, either through misrepresenting or falsely interpreting the information.Although similar to a combination of information deletion and information insertion, the edit is still attempting to represent the same content.\n\nGrammar Error.The edit violates grammatical convention.Past error analysis combines fluency and grammar into the same error type (Maddela et al., 2021) as the two are interrelated.Grammar errors are unique as they can co-occur with other errors, or occur alongside a high quality edit, as sentence fluency is independent from adequacy (Siddharthan, 2014).\n\n\nA.3 Edit Severity / Efficacy Levels\n\nWe provide examples of each severity level, which are also included as part of annotator training:\n\n\nEXAMPLE\n\nSeverity: 1 -minor Like so many hyped books before it The Midnight Library excited me and gave me pause The Midnight Library excited me and gave me pause\n\nThe introductory clause 'Like so many hyped books before it,' situates the sentence within the context of 'hyped books.'However, it does not relate to the main idea of the sentence (the author's opinion on 'The Midnight Library').\n\n\nEXAMPLE\n\nSeverity: 2 -somewhat Two security flaws, dubbed Meltdown and Spectre by researchers, were made public on 29 January 2018.Two security flaws, dubbed Meltdown and Spectre by researchers, were made public.\n\nAlthough the sentence retains its core meaning without 'on 29 January 2018', the specific reference of when 'Meltdown' and 'Spectre' were 'made public' is lost.\n\n\nEXAMPLE\n\nSeverity: 3 -major If glycolysis evolved relatively late, it likely would not be as universal in organisms as it is.It likely would not be as universal in organisms as it is.\n\nSince the entity 'glycolysis' has been deleted, the coreference corresponding to the subject 'it' is lost.\n\n\nA.4 Overall simplification score\n\nSimilar to MQM (Lommel et al., 2014), we collapse edit annotations into a simplification score to allow for direct system comparison.We calculate the sentence-level score as a weighted sum of edit ratings:\ne\u2208E exp len(e C ) + len(e S ) len(C) + len(S) \u2022 w(e) \u2022 r(e)\nwhere S is the simplification of complex sentence C, E is the set of edits, e C and e S are the parts of edit e performed on C and S respectively, w(e) is the edit weight, r(e) is the edit rating (severity / The ability to capture nature scenes has been improving...The ability to capture nature scenes has seen improvement... denominalisation (adjective \u2192 verb)\n\nThe protesters turned violent when...The violent protesters...\n\n\nTense Change\n\nModifies verb modality or tense past perfect \u2192 past simple\n\nThe governor told reporters he had overseen a productive conversation.\n\nThe governor oversaw a productive conversation.\n\npresent \u2192 past We compute the Pearson correlation to asses annotation quality.\n\nWe computed the Pearson correlation when we assessed annotation quality.efficacy), and len denotes character length. 4For weight scheme w(e), we fit a linear regression by considering the sentence-level human ratings gathered in SIMPEVAL 2022 (Maddela et al., 2023) as a gold standard.As the type of simplification depends on the needs of each particular user group (Stajner, 2021), weights may be adjusted according to the simplification domain (Cemri et al., 2022;Basu et al., 2023;Joseph et al., 2023) or use case (Trienes et al., 2022).\n\n\nB Structural Edit Examples\n\nExamples of each structural edit sub-type are listed in Table 5.We find training annotators to label structure change sub-type improved their ability to identify structure changes.We include morphological changes (e.g., tense change) as structure edits since these typically require multiple disconnected edits to perform and impact sentence-level meaning.Additionally, other work (Barancikova and Bojar, 2020), specifically Stodden and Kallmeyer (2022) annotate with a larger array of structural changes, notably including separate directions as distinct categories (e.g.singular \u2192 plural and plural \u2192 singular) and including change in sentiment and personal/impersonal form.We exclude these types as they almost never occur in the entirety of the ASSET corpus (Cardon et al., 2022).However, a case study in Italian simplification (Brunato et al., 2022) shows this structural edit distribution may vary when adapted to the needs of other languages.Similarly, German simplification often converts genitive to dative noun cases, a feature not seen in English simplification (Stodden and Kallmeyer, 2022).\n\n\nC Data Collection Details\n\n\nC.1 Simplification Systems\n\nOur main corpus of 700 simplifications are from the following diverse simplification approaches: MUSS (Martin et al., 2022), a BART-large model conditioned on explicit parameter tokens from Martin et al. ( 2020), fine-tuned on Wiki-Large (Zhang and Lapata, 2017) and mined paraphrase data.MUSS is the SOTA model before GPT-3.5.T5 (Raffel et al., 2020), an encoder-decoder transformer pre-trained on 745 GB of web text.We use T5-3B and T5-11B variants and fine-tune on the aligned Wiki-Auto dataset (Jiang et al., 2020), shown to be higher quality than Wiki-Large.GPT-3.5, a series of GPT-3 models pre-trained on text and code dated before Q4 2021.We use the best available text-davinci-003 model, based on InstructGPT (Ouyang et al., 2022), fine-tuned with human demonstrations and reinforcement learning with human feedback.We include both zeroand few-shot (5-shot) generation, using the same prompt setup as SIMPEVAL 2022 (Maddela et al., 2023).\n\nHumans.We ask two in-house annotators to write simplifications for the 40 newly selected sentences, replicating instructions used in SIMPEVAL 2022 .We average the annotations of both human simplifications for dataset analysis.\n\nOur test set of 140 simplifications are from recent approaches, including open-source LLMs:\n\nT5 with ACCESS Tokens, we use the same training setup as our fine-tuned T5 model, but prepend the input with ACCESS control tokens (Martin et al., 2020): character length ratio, dependency tree depth ratio, character-level Levenshtein similarity, and inverse frequency ratio.During inference, we use 0.9 for the length ratio, and 0.75 for the other three control tokens, following the setup in (Maddela et al., 2023).\n\nAlpaca-7B (Taori et al., 2023), a fine-tuned LLaMA model (Touvron et al., 2023) on 52K GPT-3.5 outputs generated using the Self-Instruct technique (Wang et al., 2023).As we find the prompt used for GPT-3.5 is too complex for Alpaca, we use the following prompt:\n\n\"Rewrite the following complex sentence in order to make it easier to understand by non-native speakers of English.\"\n\nVicuna-7B (Chiang et al., 2023), a fine-tuned LLaMA model on 70K publicly shared ChatGPT conversations.As the training data for Vicuna includes prompts that are more diverse and complex than those used by Alpaca, Vicuna can manage longer prompts, but not at the level of GPT-3.5, so we use the following prompt:\n\n\"Rewrite the following complex sentence in order to make it easier to understand by non-native speakers of English.The final simplified sentence needs to be grammatical, fluent, and retain the main ideas of its original counterpart without altering its meaning.\"\n\nChatGPT, an optimized chat variant of GPT-3.5, the model we use is gpt-3.5-turbo-0301.GPT-4, a large multimodal model that performs better than GPT-3.5 models.We use the version of gpt-4-0314.\n\nFor ChatGPT and GPT-4, we use the same prompt as GPT-3.5:\n\n\"Rewrite the following complex sentence in order to make it easier to understand by non-native speakers of English.You can do so by replacing complex words with simpler synonyms (i.e.paraphrasing), deleting unimportant information (i.e.compression), and/or splitting a long complex sentence into several simpler ones.The final simplified sentence needs to be grammatical, fluent, and retain the main ideas of its original counterpart without altering its meaning.\"Humans.As existing automatic simplification evaluation metrics rely on human references, we include two human-written simplifications to use for metric evaluation, but do not collect annotations on these references.\n\n\nC.2 Interpreting Annotator Agreement\n\nAs the SIMPEVAL challenge dataset contains more edits than past simplification corpora, edit annotation becomes significantly more challenging as multiple groups of edits often overlap and simplifications contain more compression and sentencelevel transformations.Additionally, error-prone systems like MUSS make it challenging to disambiguate error and quality edits.Figure 8 illustrates an example of this disagreement, showing many of the same tokens are annotated, but with different edit spans.For example, observe the last clause in the sentence, which performs a rewrite:\n\nEXAMPLE that the fort stood out for its defenders' heroic resistance.and the defenders of the fort gave their lives to save the city.\n\nWe see three different, but valid understandings of this phrase: 1. Information was replaced -The information about the defenders' resistance is inherently different then the defenders' giving their lives to save the city and is therefore an add/deletion pair.The left includes all edits, while the right calculates agreement using the underlying constituent spans selected for structure and split edits.\n\n2. Information was retained, but paraphrased -The phrase heroic resistance being equivalent in meaning to gave their lives.3. Subject was modified and information was replaced -The subject swap between the subject of the clause being the fort to being the defenders.The rest being an add/deletion pair.\n\nVarying interpretations of the same edit leads to natural disagreement.However, often a clear annotation exists and is not captured.For example, although we instructed annotators to create separate edits for overlapping syntax and conceptual edits, this occurred inconsistently in practice: EXAMPLE it was during the siege of the city of Elvas Don Luis de Haro attacked the city of Elvas 1. Identified the edit as a structural change, because the noun siege was replaced with a verb, modifying the voice of the sentence 2. Identified a paraphrase, annotating siege as a more complex word than attacked 3. Correctly identified both edits occurred simultaneously\n\nWe find the largest source of disagreement comes from overlapping edits of multiple types, most often between structural changes and other types, because they often co-occur.Figure 9 demonstrates structural edits explain a significant portion of disagreement.Additionally, because structural edits are a composite edit, the same spans are captured by the structural edits' constituent spans and recalculating agreement using these spans, disagreement instead focuses on whether tokens are substituted.\n\nWithin individual sentences, we often observe multiple valid interpretations for span labeling, highlighting the inherit ambiguity in the task.Despite this, annotators still successfully communicated edit performance.All three annotators identified both the bad deletion and hallucination errors contained in the sentence.For the full SIMPEVAL dataset, we report error identification agreement in Table 6, finding syntax errors (e.g., bad structure, bad reorder) are far more difficult to identify than content or lexical errors.Particularly, complex wording and grammar errors exhibit both high fre-  quency and high agreement, as the definitions of these errors are unambiguous.Broadly, we find that high span-level agreement is not necessary for capturing overall, or even fine-grained sentence-level performance, a clear trade-off exists between the granularity of annotations and expected agreement.\n\n\nD Further Analysis\n\nHere, we report additional findings on the SIM-PEVAL dataset and model performance, alongside observations about edit-level evaluation as a task.\n\nFigure 11 reports the average edit coverage by each edit operation and error type.We find paraphrases are typically annotated as pairs of a few words, while conceptual edits typically occur on the clause level and are annotated together.Surprisingly, structure changes often occurred as a few words: EXAMPLE MUSS ... Corbin has expanded his business to include agritourism, using his farm to host weddings ... ... Corbin's business also offers agritourism and he uses his farm to host weddings ... The edit converts the beginning subordinate clause to a coordinate clause, yet only requires substituting a single word.Errors exhibited a significantly higher variance in size, which may be attributed to their sparsity, as no error except bad deletion occurs in more than 20% of outputs (Table 6).However, error sizes display the same trend as their quality counterparts, with conceptual errors typically being seen on the clause level.We also found single-word conceptual errors such as:\n\nEXAMPLE Zero-shot GPT-3.5 ... Arroyo released a statement that acted as an informal concession of sorts ... ... Arroyo released a statement that was like a formal concession.\n\n\nEXAMPLE\n\nFew-shot GPT-3.5The sentence included a fine of $400...They imposed a fine of $400... Were less frequent than hallucinating entirely new phrasing or ideas.This may be promising for error detection as it implies error spans are often clausal and occur among many adjacent tokens.Quality and Error Are Interrelated.Figure 10 displays sentence-level scores for our error typology across systems on SIMPEVAL.We find the existence of an error to be a consistent predictor of a lower quality sentence, even in human simplifications.However, we find some errors correlate with a higher score (e.g.bad structure, information rewrite), but this may be attributed to the multiclause complex sentences in SIMPEVAL having a a far greater number of positive edits when these corresponding errors occur.Broadly, we observe an inverse relationship between error and quality.\n\nAs the error score increases (a function of the severity, frequency and size of errors), the quality must decrease.Increased Edits Enables, But Does Not Guarantee Performance.Table 7 reports the mean and variance of sub-scores for the sentence-level SALSA score across each system.Edit-level scoring addresses the frequent evaluation concern that conservative systems may maximize their score by performing a minimal number of safe edits (Alva-Manchego et al., 2021).The qualitatively conservative simplifications of T5 and zero-shot GPT-3.5 often score low because they fail to make many edits.SALSA distinguishes the MUSS simplifications with many successes, but more failures than other systems.We find the extent of sentence editing is not heuristic, but is a prerequisite for high performance and that overall simplification performance is often determined by a small number of high-impact edits.\n\nSentence Length Impacts Edit Frequency.Previous linguistic annotation of the ASSET corpus (Cardon et al., 2022) reports that the number of modifications to a sentence does not correlate with input size.In Figure 13, we observe the same relationship on ASSET, however -because ASSET only represents simplifications of simpler sentences typically containing a single idea -when we extend the analysis to the more complex SIMPEVAL dataset, we see a clear relationship between the edit distance and the number of transformations in simplifications across all systems.This is also best exemplified by the split edit, which often signifies too many ideas are being contained within a single sentence.Figure 12 demonstrates the proportion of simplifications which exhibit a split across sentence lengths and edit distance.While split edits within ASSET were generally low, the much longer SIMPEVAL simplifications almost guaranteed all systems performed a sentence split.These findings highlight that performance measures should be length-agnostic, as to guarantee simplifications which simply contain more transformations due to a longer original sentence length are not arbitrarily rated as higher quality.\n\nComposite Edits.We report the breakdown of constituent edits in structure and split edits in Figure 15.Split edits typically need to rewrite the conjunction through inserting & deleting discourse tokens, while structure edits are typically performed some syntax transformation to the existing sentence tree, more often requiring substituted or reordered tokens.\n\nSALSA Test Set. Figure 16 reports the frequency of quality and error edits on the novel SALSA test set systems.While adding control tokens to T5 substantially improves the frequency of edits, we find it still underperforms both MUSS and LLMs.Additionally, T5-11B makes a surprising increase in error frequency relative to the increase in the number of edits it performs relative to T5-3B.Language models demonstrate a smooth increase in edits, with the exception of GPT-4 making significantly less conceptual edits.Manual analysis reveals its conceptual edits are often sentence-level operations, which are not reflected in edit counts.The LLaMA-based Alpaca and Vicuna demonstrate surprisingly strong performance despite their relatively small size and training setup, even outperforming the fine-tuned simplification models.SALSA Dataset Statistics.We report full statistics on all 840 simplifications in Table 8.Similar to FRANK (Pagnoni et al., 2021), we asked annotators to note edits that could not be annotated, and we observe less than 0.5% of edits were not captured by one of our edit types.We consider the SALSA framework complete.\n\n\nE Further Word-level QE Results\n\nWe include test set word-level F1 score on words in the original sentence, simplified sentence, and both sentences (same as Table 3) in Table 9.In the original sentence, only deletion edits are labeled.Thus, the performance in the original sentence column indicates the model's ability to identify quality or error deletion edits.The best-performing method, Ec-One, achieves over 50% in both quality and error F1.For the simplified sentence, which contains substitution and insertion edits, the model delivers better quality F1 but experiences a drop in error F1.This could be due to the higher proportion of error edits in deletion compared to substitution and insertion.In addition, the edit classification approach significantly improves the error F1 on the simplified sentence, compared to the tagging approaches, which reflects that tagging methods fail to capture multiple types of edits and those spanning both sentences like substitutions.\n\n\nF Implementation Details\n\nF.1 Generating Simplifications ( \u00a73.1)\n\nFor all prompted models, we follow the hyperparameters of SIMPEVAL 2022 (Maddela et al., 2023), using temperature=1.0 and top-p=0.95.For all T5 variants, we train them on the Wiki-Auto corpus (Jiang et al., 2020) using 8 A40 GPUs for 8 epochs with a batch size of 64.We use a learning rate of 3e-4 and AdamW (Loshchilov and Hutter, 2019) as the optimizer.For MUSS, we replicate the original setup (Martin et al., 2022).We use beam search with a beam size of 10 for these fine-tuned models.\n\n\nF.2 Automatic Metrics ( \u00a75)\n\nBaseline Automatic Metrics.\n\nWe use RoBERTa-large as the base model for BERTSCORE and the best available wmt21-comet-mqm as COMET-MQM.LENS-SALSA.Our implementation is based on the reference-less COMETKIWI metric for machine translation (Rei et al., 2022).We modify their task setup of predicting binary quality labels for each output word \u0177i \u2208 {OK, BAD} to a regression task using labels \u0177i \u2208 [\u22123, 3], corresponding to each word rating in their SALSA annotations, as we find it performs better than using binary or three class labels in our preliminary study.Our regression task optimizes MSE loss on the word rating objective, rather than Cross Entropy Loss.The training objective can be formalized as:\n\n\n\naffecting\n\n\nFigure 1 :\n1\nFigure 1: Simplification generated by GPT-4.Our editlevel SALSA reveals LLMs succeed across many edit types, but often fail to paraphrase and generalize.\n\n\nFigure 2 :\n2\nFigure 2: The SALSA annotation process consists of (1) selecting edits, (2) identifying information change, (3) classifying edit type and (4) rating efficacy/severity.\n\n\nFigure 3 :\n3\nFigure 3: The multi-stage SALSA edit evaluation framework.Spans are classified into twenty one success and failure types (trivial change counts as one type) using the interface shown in Figure 2.\n\n\nFigure 4 :\n4\nFigure4: Successful edits per-model, organized by edit type.MUSS outperforms fine-tuned T5 but fails to capture more complex simplification techniques.Compared to GPT-3.5, human written simplifications have more generalization , a similar distribution of syntax edits, and slightly less paraphrasing .\n\n\nFigure 7 :\n7\nFigure 7: Success and failure edits on simplifications by five recent instruction fine-tuned language models.\n\n\nFigure 8 :Figure 9 :\n89\nFigure 8: Edit selection between three annotators on a MUSS simplification.For complex examples, multiple valid interpretations for span labeling may exist, however we find annotator's overall judgements are consistent.\n\n\nFigure 10 :\n10\nFigure 10: Average sentence-level score across error sentences for each system.\n\n\nFigure 12 :\n12\nFigure12: Edit distance and number of annotated edits for 300 randomly sampled sentences from ASSET and SIMPEVAL.While past work found no relationship, by extending ASSET to more complex sentences we see a clear correlation arise.\n\n\nFigure 13 :\n13\nFigure13: Proportion of sentences containing at least a single split.Although ASSET has a much lower frequency of sentence splits (32%), a longer input sentence implies a sentence split is more likely to occur.\n\n\n\n\ni \u2212 \u0177i (\u03b8)) 2 L(\u03b8) = \u03bb s L sent (\u03b8) + \u03bb w L word (\u03b8)\n\n\nFigure 17 :\n17\nFigure 17: Landing page introducing annotators to each part of the task.The 10 stages organize different concepts in the SALSA typology.\n\n\nFigure 18 :\n18\nFigure 18: Example interactive allowing annotators to see different spans to understand different amounts of relevancy to the main idea of the sentence.\n\n\nFigure 19 :\n19\nFigure 19: One of the 100 sentence examples provided to annotators, highlighting different types of structure edits existing within the same sentence.\n\n\nTable 2 :\n2\nPearson correlation between automatic metrics and SALSA sub-scores ( \u00a7A.4) on the SALSA test set.All reference-based metrics use two human-written references.Best; Second Best.\nQualityLexical Syntax Conceptual 0.043 0.149 0.097 0.038 0.144 0.202 -0.167 0.126 0.025 0.120 0.407 0.443 0.013 0.204 0.147 0.122 0.306 0.356ErrorLexical Syntax Conceptual 0.047 0.150 0.279 0.228 0.207 0.107 -0.147 -0.026 -0.093 -0.068 -0.041 0.054 -0.104 -0.013 -0.043 -0.017 0.019 0.086All Error-0.121 0.067 0.117 0.127 0.161 0.169AllAll Quality -0.095 0.179 0.027 0.074 0.336 0.459All Edits-0.116 0.170 0.056 0.092 0.334 0.446\n\nTable 3 :\n3\nWord-level F1 scores of different methods on SALSA test set.Oracle uses annotated edit information.\nMethodQuality ErrorOkAverageEnd-to-endTag67.0028.2492.8862.71Tag-ML70.7330.0693.0964.62Two-stage (use word aligner to get edit information)Tag-EI69.0930.3793.0464.17Ec-Sep64.8736.1591.5664.20Ec-One68.7739.5091.9166.73Oracle (Ec-One)88.3169.4498.3585.47\nThe final label counts for our train, validation, test splits are: 6.8K/1.8K/27K,2.7K/627/11K, and 1.7K/484/6.9Kfor quality/error/ok respectively.\n\n\nTable 4 :\n4\nOverview of the SALSA edit-level evaluation typology.Original text for the examples: Many volatile organic chemicals are increasing in abundance in the lower troposphere.\n\n\n\n\nEXAMPLE Herbert Spencer's book makes the first... His book makes the first. . .... the New York City Police Department is a law enforcement agency ... ... the New York City Police Department is a police department ... Despite successfully paraphrasing, police department, simply copies content from earlier in the sentence, instead of generating unique information.EXAMPLE ... the Watergate burglars were convicted ... ... the Watergate burglars were not convicted ...\nRepetition. Some trivially additional informationwhich simply repeats knowledge already previouslycontained in the candidate sentence.Contradiction. A negation of the meaning of theoriginal sentence. This notably includes modify-ing an existing phrase to contradict the originalsentence:\nEXAMPLE\n\n\nTable 5 :\n5\nExamples of structural modification sub-types used for annotation.\n\n\nTable 6 :\n6\nFleiss kappa error identification agreement measured per-sentence alongside error frequencies.As errors were far more rare, we observe a strong relationship between frequency and expected agreement.\nFleiss kappa (\u03ba) 2 \u20443 Agree% % sentencesBad Deletion0.516435Complex Wording0.263220Information Rewrite0.272610Grammar Error0.171810Bad Structure0.02610Bad Reorder0.14199Irrelevant0.22268Bad Split0.13174Repetition0.33304Contradiction0.19251Coreference000\n\nTable 7 :\n7\nMean (\u00b5)and std.deviation (\u03c3) of average sentence-level SALSA sub-scores across systems.Human simplification may be interpreted as highly simplified (\u00b5 = 2.04) and highly diverse (\u03c3 = 2.16).\nLexicalSyntaxConceptualErrorQualityOverall\u00b5\u03c3\u00b5\u03c3\u00b5\u03c3\u00b5\u03c3\u00b5\u03c3\u00b5\u03c3MUSS0.81 1.23 0.45 0.64 0.97 1.73 0.66 1.03 1.00 1.04 1.77 1.66T5 3B0.24 0.56 0.18 0.38 0.65 1.92 0.34 0.97 0.39 0.62 0.76 1.15T5 11B0.22 0.44 0.17 0.92 0.61 1.78 0.36 1.30 0.32 0.71 0.71 1.51Zero-shot GPT-3.5 1.32 1.40 0.67 0.65 0.17 0.38 0.34 0.53 1.75 1.55 2.10 1.60Few-shot GPT-3.5 1.41 1.43 0.57 0.53 0.15 0.39 0.25 0.46 1.80 1.49 2.11 1.60Human1.25 1.85 0.60 0.86 0.32 0.83 0.25 0.62 1.67 1.64 2.04 2.16\n\nTable 8 :\n8\nBasic collected statistics on our edit-level SALSA annotations of SIMPEVAL.# tokens indicates tokens highlighted within each edit's spans.\n\n\nTable 9 :\n9\nOverview of success and failure edits on the SIMPEVAL test set, collected using held-out simplification models as detailed in \u00a7C.1.Word-level F1 scores of different methods on SALSA test set, organized by the edit belonging to the original or simplified sentence.\nLexical ErrorInformation RewriteGrammar ErrorComplex Wording\nhttps://vuejs.org/\nhttps://huggingface.co/\nWe normalize the edit length and use exp to add weight for longer edits.\nAcknowledgementsWe thank Tarek Naous, Nghia T. Le, Fan Bai, and Yang Chen for their helpful feedback on this work.We also thank Marcus Ma, Rachel Choi, Vishnesh J. Ramanathan, Elizabeth Liu, Govind Ramesh, Ayush Panda, Anton Lavrouk, Vinayak Athavale, and Kelly Smith for their help with human annotation.This research is supported in part by the NSF awards IIS-2144493 and IIS-2112633, ODNI and  IARPA via the HIATUS program (contract 2022-22072200004).The views and conclusions contained herein are those of the authors and should not be interpreted as necessarily representing the official policies, either expressed or implied, of NSF, ODNI, IARPA, or the U.S. Government.The U.S. Government is authorized to reproduce and distribute reprints for governmental purposes notwithstanding any copyright annotation therein.More InformationLess Information Figure14: Distribution of ratings of edits on SIMPEVAL per-model.Compared to edit coverage distributions (Fig.6), we see the same underlying relationship, but the difference in error and GPT vs. human quality is less exaggerated.This figure does not reflect the typically much longer human simplification spans and fine-tuned models' error spans.where \u03bb s and \u03bb w weight word-and sentence-level losses.We experimented with custom weighting for edit ratings, but did not fine performance improvements.For fine-tuning, we set \u03bb w = 0.9.Same Information Reorder Sentence Split Structure AllStructure EditsThe COMETKIWI design aggregates hidden states using a scalar mix module, and uses two feed forward networks for sentence-and wordlevel training.For pre-training, we optimize a RoBERTa-large model on the sentence-level SIM-PEVAL training data used to train LENS(Maddela et al., 2023), with the training setup using only a single MSE loss to predict the sentence-level score (i.e., \u03bb s = 1, \u03bb w = 0).We follow COMETKIWI and freeze parameter updates for the RoBERTa encoder for the first epoch and use a learning rate of 1e-5 and 3e-5 for pre-training and fine-tuning respectively.We pre-train and fine-tune for 5 epochs, using the model with the highest validation set performance.We report the corresponding validation performance in Table10.F.3 Edit Classification ( \u00a76).All experiments are conducted using 2 A40 GPUs.We use the AdamW optimizer with a weight decay = 0.01, and implement our models using the Hugging Face Transformers.Learning rate are swept over 1e-5, 2e-5, 5e-5, 8e-5 for each method.Each run is trained for eight epochs with a batch of 32.This results in training times of less than five minutes per run for tagging methods and less than 20 minutes per run for the edit classification methods.We perform an evaluation of the validation set at each training step and use the model that achieved the highest validation performance on the test set.For the word alignment model used in the twostage approach, we adopt the QA-based word aligner(Nagata et al., 2020), which formulates the task in a SQUAD style(Rajpurkar et al., 2018).We use RoBERTa-Large as the base model.We first pre-train it on monolingual word alignment datasets MultiMWA-Wiki and MultiMWA-Newsela from(Lan et al., 2021), and then fine-tune it on the SALSA annotations in the training set.During both pre-training and fine-tuning stages, we perform a learning rate sweep over {1e-5, 2e-5, 5e-5, 8e-5} and train for 5 epochs, and save checkpoint at the end of every epoch.The highest evaluated checkpoint (pre-train for 2 epochs and fine-tune for 2 epochs) is selected for testing, achieving 81.03 F1 on the validation set.On a side note, for the word that is tokenized into multiple tokens, we use its first token for prediction.G Annotation TutorialWe include screenshots to highlight the diversity of exercises and interactive elements in our detailed interface tutorial.\nASSET: A dataset for tuning and evaluation of sentence simplification models with multiple rewriting transformations. Fernando Alva-Manchego, Louis Martin, Antoine Bordes, Carolina Scarton, 10.18653/v1/2020.acl-main.424Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. the 58th Annual Meeting of the Association for Computational LinguisticsOnline. Association for Computational Linguistics2020aBeno\u00eet Sagot, and Lucia Specia\n\nData-driven sentence simplification: Survey and benchmark. Fernando Alva-Manchego, Carolina Scarton, Lucia Specia, 10.1162/coli_a_00370Computational Linguistics. 4612020b\n\nThe (un)suitability of automatic evaluation metrics for text simplification. Fernando Alva-Manchego, Carolina Scarton, Lucia Specia, 10.1162/coli_a_00418Computational Linguistics. 4742021\n\nCOSTRA 1.0: A dataset of complex sentence transformations. Petra Barancikova, Ond\u0159ej Bojar, Proceedings of the Twelfth Language Resources and Evaluation Conference. the Twelfth Language Resources and Evaluation ConferenceMarseille, FranceEuropean Language Resources Association2020\n\nMed-easi: Finely annotated dataset and models for controllable simplification of medical texts. Chandrayee Basu, Rosni Vasu, Michihiro Yasunaga, Qian Yang, arXiv:2302.091552023arXiv preprint\n\nKeep it or not: Word level quality estimation for post-editing. Prasenjit Basu, Santanu Pal, Sudip Kumar Naskar, 10.18653/v1/W18-6457Proceedings of the Third Conference on Machine Translation: Shared Task Papers. the Third Conference on Machine Translation: Shared Task PapersBelgium, BrusselsAssociation for Computational Linguistics2018\n\nA review of human evaluation for style transfer. Eleftheria Briakou, Sweta Agrawal, Ke Zhang, Joel Tetreault, Marine Carpuat, 10.18653/v1/2021.gem-1.6Proceedings of the 1st Workshop on Natural Language Generation, Evaluation, and Metrics (GEM 2021). the 1st Workshop on Natural Language Generation, Evaluation, and Metrics (GEM 2021)Online. Association for Computational Linguistics2021\n\nLanguage models are few-shot learners. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Advances in neural information processing systems. 202033\n\nLinguistically-based comparison of different approaches to building corpora for text simplification: A case study on Italian. Dominique Brunato, Felice Dell'orletta, Giulia Venturi, Frontiers in Psychology. 132022\n\nHallucinated but factual! inspecting the factuality of hallucinations in abstractive summarization. Meng Cao, Yue Dong, Jackie Cheung, 10.18653/v1/2022.acl-long.236Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics. Long Papers. the 60th Annual Meeting of the Association for Computational LinguisticsDublin, IrelandAssociation for Computational Linguistics20221\n\nLinguistic corpus annotation for automatic text simplification evaluation. R\u00e9mi Cardon, Adrien Bibal, Rodrigo Wilkens, David Alfter, Magali Norr\u00e9, Adeline M\u00fcller, Watrin Patrick, Thomas Fran\u00e7ois, 10.18653/v1/2022.emnlp-main.121Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing. the 2022 Conference on Empirical Methods in Natural Language ProcessingAbu Dhabi, United Arab EmiratesAssociation for Computational Linguistics2022\n\nUnsupervised simplification of legal texts. Mert Cemri, Tolga \u00c7ukur, Aykut Ko\u00e7, arXiv:2209.005572022arXiv preprint\n\nMotivations and methods for text simplification. R Chandrasekar, Christine Doran, B Srinivas, The 16th International Conference on Computational Linguistics. 19962COLING 1996\n\nConverge to the truth: Factual error correction via iterative constrained editing. Jiangjie Chen, Rui Xu, Wenxuan Zeng, Changzhi Sun, Lei Li, Yanghua Xiao, 10.1609/aaai.v37i11.26485Proceedings of the Thirty-Seventh AAAI Conference on Artificial Intelligence, AAAI'23. the Thirty-Seventh AAAI Conference on Artificial Intelligence, AAAI'23AAAI Press2023\n\nWei-Lin Chiang, Zhuohan Li, Zi Lin, Ying Sheng, Zhanghao Wu, Hao Zhang, Lianmin Zheng, Siyuan Zhuang, Yonghao Zhuang, Joseph E Gonzalez, Ion Stoica, and Eric P. Xing. 2023. Vicuna: An opensource chatbot impressing gpt-4 with 90%* chatgpt quality. \n\nInherent biases in reference-based evaluation for grammatical error correction. Leshem Choshen, Omri Abend, 10.18653/v1/P18-1059Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics. Long Papers. the 56th Annual Meeting of the Association for Computational LinguisticsMelbourne, AustraliaAssociation for Computational Linguistics20181\n\nLinguistic capabilities for a checklist-based evaluation in automatic text simplification. Oscar M Cumbicus-Pineda, Itziar Gonzalez-Dios, Aitor Soroa, CTTS@ SEPLN. 2021a\n\nA syntax-aware edit-based system for text simplification. M Oscar, Itziar Cumbicus-Pineda, Aitor Gonzalez-Dios, Soroa, Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2021). the International Conference on Recent Advances in Natural Language Processing (RANLP 2021)Held Online. INCOMA Ltd2021b\n\nEvaluating factuality in text simplification. Ashwin Devaraj, William Sheffield, Byron Wallace, Junyi Jessy Li, 10.18653/v1/2022.acl-long.506Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics. Long Papers. the 60th Annual Meeting of the Association for Computational LinguisticsDublin, Ireland20221Association for Computational Linguistics\n\nEditNTS: An neural programmer-interpreter model for sentence simplification through explicit editing. Yue Dong, Zichao Li, Mehdi Rezagholizadeh, Jackie Chi, Kit Cheung, 10.18653/v1/P19-1331Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. the 57th Annual Meeting of the Association for Computational LinguisticsFlorence, ItalyAssociation for Computational Linguistics2019\n\nIs GPT-3 text indistinguishable from human text? scarecrow: A framework for scrutinizing machine text. Yao Dou, Maxwell Forbes, Rik Koncel-Kedziorski, Noah A Smith, Yejin Choi, 10.18653/v1/2022.acl-long.501Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics. the 60th Annual Meeting of the Association for Computational LinguisticsDublin, IrelandAssociation for Computational Linguistics20221Long Papers)\n\nTree adjoining grammar and the reluctant paraphrasing of text. Mark Dras, 1999Macquarie University Sydney\n\nUnderstanding iterative revision from human-written text. Wanyu Du, Vipul Raheja, Dhruv Kumar, Myung Zae, Melissa Kim, Dongyeop Lopez, Kang, 10.18653/v1/2022.acl-long.250Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics. Long Papers. the 60th Annual Meeting of the Association for Computational LinguisticsDublin, IrelandAssociation for Computational Linguistics2022\n\nExperts, errors, and context: A large-scale study of human evaluation for machine translation. Markus Freitag, George Foster, David Grangier, Viresh Ratnakar, Qijun Tan, Wolfgang Macherey, 10.1162/tacl_a_00437Transactions of the Association for Computational Linguistics. 20219\n\nText simplification for legal domain: Insights and challenges. Aparna Garimella, Abhilasha Sancheti, Vinay Aggarwal, Ananya Ganesh, Niyati Chhaya, Nandakishore Kambhatla, 10.18653/v1/2022.nllp-1.28Proceedings of the Natural Legal Language Processing Workshop 2022. the Natural Legal Language Processing Workshop 2022Abu Dhabi, United Arab Emirates2022Association for Computational Linguistics\n\nOn the ethical considerations of text simplification. Sian Gooding, 10.18653/v1/2022.slpat-1.7Ninth Workshop on Speech and Language Processing for Assistive Technologies (SLPAT-2022). Dublin, IrelandAssociation for Computational Linguistics2022\n\nOne size does not fit all: The case for personalised word complexity models. Sian Gooding, Manuel Tragut, 10.18653/v1/2022.findings-naacl.27Findings of the Association for Computational Linguistics: NAACL 2022. Seattle, United StatesAssociation for Computational Linguistics2022\n\nTanya Goyal, Junyi , Jessy Li, Greg Durrett, arXiv:2209.12356News summarization and evaluation in the era of gpt-3. 2022arXiv preprint\n\nThe false promise of imitating proprietary llms. Arnav Gudibande, Eric Wallace, Charles Burton Snell, Xinyang Geng, P Hao Liu, Sergey Abbeel, Dawn Levine, Song, ArXiv, abs/2305.157172023\n\nUnifying human and statistical evaluation for natural language generation. B Tatsunori, Hugh Hashimoto, Percy Zhang, Liang, 10.18653/v1/N19-1169Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Long and Short Papers. the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesMinneapolisAssociation for Computational Linguistics20191\n\nThresh: A unified, customizable and deployable platform for fine-grained text evaluation. David Heineman, Yao Dou, Wei Xu, arXiv:2308.069532023arXiv preprint\n\nSpeakers optimize information density through syntactic reduction. Advances in neural information processing systems. T Jaeger, Roger Levy, 2006. 19\n\nSurvey of hallucination in natural language generation. Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Ye , Jin Bang, Andrea Madotto, Pascale Fung, 10.1145/3571730ACM Comput. Surv. 12552023\n\nNeural CRF model for sentence alignment in text simplification. Chao Jiang, Mounica Maddela, Wuwei Lan, Yang Zhong, Wei Xu, 10.18653/v1/2020.acl-main.709Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. the 58th Annual Meeting of the Association for Computational LinguisticsAssociation for Computational Linguistics2020\n\nSemantic simplification for sentiment classification. Xiaotong Jiang, Zhongqing Wang, Guodong Zhou, 10.18653/v1/2022.emnlp-main.757Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing. the 2022 Conference on Empirical Methods in Natural Language ProcessingAbu Dhabi, United Arab EmiratesAssociation for Computational Linguistics2022\n\nSebastian Joseph, Kathryn Kazanas, Keziah Reina, J Vishnesh, Wei Ramanathan, Byron C Xu, Junyi Jessy Wallace, Li, arXiv:2305.12532Multilingual simplification of medical texts. 2023arXiv preprint\n\nContent analysis: An introduction to its methodology. Klaus Krippendorff, 2018Sage publications\n\nReno Kriz, Marianna Apidianaki, Chris Callison-Burch, arXiv:2012.12382Simple-QE: Better automatic quality estimation for text simplification. 2020arXiv preprint\n\nIterative edit-based unsupervised sentence simplification. Dhruv Kumar, Lili Mou, Lukasz Golab, Olga Vechtomova, 10.18653/v1/2020.acl-main.707Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. the 58th Annual Meeting of the Association for Computational LinguisticsOnline. Association for Computational Linguistics2020\n\nKeep it simple: Unsupervised simplification of multi-paragraph text. Philippe Laban, Tobias Schnabel, Paul Bennett, Marti A Hearst, 10.18653/v1/2021.acl-long.498Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing. Long Papers. the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language ProcessingOnline. Association for Computational Linguistics20211\n\nNeural semi-Markov CRF for monolingual word alignment. Wuwei Lan, Chao Jiang, Wei Xu, 10.18653/v1/2021.acl-long.531Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing. Long Papers. the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language ProcessingOnline. Association for Computational Linguistics20211\n\nMultidimensional quality metrics (MQM): A framework for declaring and describing translation quality metrics. Arle Lommel, Hans Uszkoreit, Aljoscha Burchardt, Revista Tradum\u00e0tica: tecnologies de la traducci\u00f3. 122014\n\nDecoupled weight decay regularization. Ilya Loshchilov, Frank Hutter, International Conference on Learning Representations. 2019\n\nControllable text simplification with explicit paraphrasing. Mounica Maddela, Fernando Alva-Manchego, Wei Xu, 10.18653/v1/2021.naacl-main.277Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesOnline. Association for Computational Linguistics2021\n\nLENS: A learnable evaluation metric for text simplification. Mounica Maddela, Yao Dou, David Heineman, Wei Xu, 10.18653/v1/2023.acl-long.905Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics. Long Papers. the 61st Annual Meeting of the Association for Computational LinguisticsToronto, CanadaAssociation for Computational Linguistics20231\n\nControllable sentence simplification. Louis Martin, Proceedings of the Twelfth Language Resources and Evaluation Conference. the Twelfth Language Resources and Evaluation ConferenceMarseille, FranceEuropean Language Resources Association2020\u00c9ric de la Clergerie, Beno\u00eet Sagot, and Antoine Bordes\n\nMUSS: Multilingual unsupervised sentence simplification by mining paraphrases. Louis Martin, Angela Fan, Proceedings of the Thirteenth Language Resources and Evaluation Conference. the Thirteenth Language Resources and Evaluation ConferenceMarseille, FranceEuropean Language Resources Association2022\u00c9ric de la Clergerie, Antoine Bordes, and Beno\u00eet Sagot\n\nOn faithfulness and factuality in abstractive summarization. Joshua Maynez, Shashi Narayan, Bernd Bohnet, Ryan Mcdonald, 10.18653/v1/2020.acl-main.173Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. the 58th Annual Meeting of the Association for Computational LinguisticsAssociation for Computational Linguistics2020\n\nIf beam search is the answer, what was the question?. Clara Meister, Ryan Cotterell, Tim Vieira, 10.18653/v1/2020.emnlp-main.170Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)Online. Association for Computational Linguistics2020\n\nA supervised word alignment method based on cross-language span prediction using multilingual BERT. Masaaki Nagata, Katsuki Chousa, Masaaki Nishino, 10.18653/v1/2020.emnlp-main.41Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)Online. Association for Computational Linguistics2020\n\nChatGPT: Optimizing language models for dialogue. 2022OpenAI\n\narXiv:2303.08774GPT-4 technical report. 2023OpenAIarXiv preprint\n\nTraining language models to follow instructions with human feedback. Long Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, arXiv:2203.021552022arXiv preprint\n\nText simplification as tree transduction. Gustavo H Paetzold, Lucia Specia, Proceedings of the 9th Brazilian Symposium in Information and Human Language Technology. the 9th Brazilian Symposium in Information and Human Language Technology2013\n\nUnderstanding factuality in abstractive summarization with FRANK: A benchmark for factuality metrics. Artidoro Pagnoni, Vidhisha Balachandran, Yulia Tsvetkov, 10.18653/v1/2021.naacl-main.383Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesOnline. Association for Computational Linguistics2021\n\nBleu: a method for automatic evaluation of machine translation. Kishore Papineni, Salim Roukos, Todd Ward, Wei-Jing Zhu, 10.3115/1073083.1073135Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics. the 40th Annual Meeting of the Association for Computational LinguisticsPhiladelphia, Pennsylvania, USAAssociation for Computational Linguistics2002\n\nLanguage models as knowledge bases?. Fabio Petroni, Tim Rockt\u00e4schel, Sebastian Riedel, Patrick Lewis, Anton Bakhtin, Yuxiang Wu, Alexander Miller, 10.18653/v1/D19-1250Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)Hong Kong, ChinaAssociation for Computational Linguistics2019\n\nLexical simplification with pretrained encoders. Jipeng Qiang, Yun Li, Yi Zhu, Yunhao Yuan, Xindong Wu, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence202034\n\nExploring the limits of transfer learning with a unified text-to-text transformer. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J Liu, J. Mach. Learn. Res. 211402020\n\nKnow what you don't know: Unanswerable questions for SQuAD. Pranav Rajpurkar, Robin Jia, Percy Liang, 10.18653/v1/P18-2124Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics. the 56th Annual Meeting of the Association for Computational LinguisticsMelbourne, AustraliaAssociation for Computational Linguistics20182Short Papers)\n\nCOMET: A neural framework for MT evaluation. Ricardo Rei, Craig Stewart, Ana C Farinha, Alon Lavie, 10.18653/v1/2020.emnlp-main.213Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)Online. Association for Computational Linguistics2020\n\nCometKiwi: IST-unbabel 2022 submission for the quality estimation shared task. Ricardo Rei, Marcos Treviso, M Nuno, Chrysoula Guerreiro, Ana C Zerva, Christine Farinha, Maroti, G C Jos\u00e9, Taisiya De Souza, Duarte Glushkova, Luisa Alves, Alon Coheur, Lavie, F T Andr\u00e9, Martins, Proceedings of the Seventh Conference on Machine Translation (WMT). the Seventh Conference on Machine Translation (WMT)Abu Dhabi, United Arab EmiratesAssociation for Computational Linguistics2022\n\nRevisiting non-English text simplification: A unified multilingual benchmark. Michael Ryan, Tarek Naous, Wei Xu, 10.18653/v1/2023.acl-long.269Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics. Long Papers. the 61st Annual Meeting of the Association for Computational LinguisticsToronto, CanadaAssociation for Computational Linguistics20231\n\n. Carolina Scarton, Alessio Palmero Aprosio, Sara Tonelli, Tamara Mart\u00edn Wanton, Lucia Specia, \n\nMUSST: A multilingual syntactic simplification tool. Proceedings of the IJCNLP 2017, System Demonstrations. the IJCNLP 2017, System DemonstrationsTapei, TaiwanAssociation for Computational Linguistics\n\nBeyond fair pay: Ethical implications of NLP crowdsourcing. Boaz Shmueli, Jan Fell, Soumya Ray, Lun-Wei Ku, 10.18653/v1/2021.naacl-main.295Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesOnline. Association for Computational Linguistics2021\n\nSyntactic simplification and text cohesion. Advaith Siddharthan, Research on Language and Computation. 412006\n\nA survey of research on text simplification. Advaith Siddharthan, ITL-International Journal of Applied Linguistics. 16522014\n\nNew data-driven approaches to text simplification. Sanja \u0160tajner, 2016University of WolverhamptonPh.D. thesis\n\nAutomatic text simplification for social good: Progress and challenges. Sanja Stajner, 10.18653/v1/2021.findings-acl.233Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021. Online. Association for Computational Linguistics2021\n\nTS-ANNO: An annotation tool to build, annotate and evaluate text simplification corpora. Regina Stodden, Laura Kallmeyer, 10.18653/v1/2022.acl-demo.14Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: System Demonstrations. the 60th Annual Meeting of the Association for Computational Linguistics: System DemonstrationsDublin, IrelandAssociation for Computational Linguistics2022\n\nBLEU is not suitable for the evaluation of text simplification. Elior Sulem, Omri Abend, Ari Rappoport, 10.18653/v1/D18-1081Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing. the 2018 Conference on Empirical Methods in Natural Language ProcessingBrussels, BelgiumAssociation for Computational Linguistics2018a\n\nSemantic structural evaluation for text simplification. Elior Sulem, Omri Abend, Ari Rappoport, 10.18653/v1/N18-1063Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Long Papers. the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesLouisianaNew Orleans2018b1Association for Computational Linguistics\n\nSimple and effective text simplification using semantic and neural methods. Elior Sulem, Omri Abend, Ari Rappoport, 10.18653/v1/P18-1016Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics. Long Papers. the 56th Annual Meeting of the Association for Computational LinguisticsMelbourne, AustraliaAssociation for Computational Linguistics2018c1\n\nDocument-level text simplification: Dataset, criteria and baseline. Renliang Sun, Jin Hanqi, Xiaojun Wan, 10.18653/v1/2021.emnlp-main.630Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. the 2021 Conference on Empirical Methods in Natural Language ProcessingDominican Republic. Association for Computational Linguistics2021Online and Punta Cana\n\nOn the helpfulness of document context to sentence simplification. Renliang Sun, Zhe Lin, Xiaojun Wan, 10.18653/v1/2020.coling-main.121Proceedings of the 28th International Conference on Computational Linguistics. the 28th International Conference on Computational LinguisticsBarcelona, Spain (OnlineInternational Committee on Computational Linguistics2020\n\nRohan Taori, Ishaan Gulrajani, Tianyi Zhang, Yann Dubois, Xuechen Li, Carlos Guestrin, Percy Liang, Tatsunori B Hashimoto, Stanford Alpaca: An instruction-following LLaMA model. 2023\n\nThibaut Hugo Touvron, Gautier Lavril, Xavier Izacard, Marie-Anne Martinet, Timoth\u00e9e Lachaux, Baptiste Lacroix, Naman Rozi\u00e8re, Eric Goyal, Faisal Hambro, Azhar, arXiv:2302.13971LLaMA: Open and efficient foundation language models. 2023arXiv preprint\n\nPatient-friendly clinical notes: Towards a new text simplification dataset. Jan Trienes, J\u00f6rg Schl\u00f6tterer, Hans-Ulrich Schildhaus, Christin Seifert, 10.18653/v1/2022.tsar-1.3Proceedings of the Workshop on Text Simplification, Accessibility, and Readability (TSAR-2022). the Workshop on Text Simplification, Accessibility, and Readability (TSAR-2022)Abu Dhabi, United Arab EmiratesAssociation for Computational Linguistics2022\n\nUniTE: Unified translation evaluation. Yu Wan, Dayiheng Liu, Baosong Yang, Haibo Zhang, Boxing Chen, Derek Wong, Lidia Chao, 10.18653/v1/2022.acl-long.558Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics. the 60th Annual Meeting of the Association for Computational LinguisticsDublin, IrelandAssociation for Computational Linguistics20221Long Papers)\n\nSelf-instruct: Aligning language models with self-generated instructions. Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A Smith, Daniel Khashabi, Hannaneh Hajishirzi, 10.18653/v1/2023.acl-long.754Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics. Long Papers. the 61st Annual Meeting of the Association for Computational LinguisticsToronto, CanadaAssociation for Computational Linguistics20231\n\nZeqiu Wu, Yushi Hu, Weijia Shi, Nouha Dziri, Alane Suhr, Prithviraj Ammanabrolu, Noah A Smith, Mari Ostendorf, Hannaneh Hajishirzi, arXiv:2306.01693Fine-grained human feedback gives better rewards for language model training. 2023arXiv preprint\n\nOptimizing statistical machine translation for text simplification. Wei Xu, Courtney Napoles, Ellie Pavlick, Quanze Chen, Chris Callison-Burch, 10.1162/tacl_a_00107Transactions of the Association for Computational Linguistics. 42016\n\nParaphrasing for style. Wei Xu, Alan Ritter, Bill Dolan, Ralph Grishman, Colin Cherry, Mumbai, India. The COLING 2012 Organizing Committee. 2012Proceedings of COLING 2012\n\nGauging the gap between human and machine text simplification through analytical evaluation of simplification strategies and errors. Daichi Yamaguchi, Rei Miyata, Sayuka Shimada, Satoshi Sato, 10.18653/v1/2023.findings-eacl.27Findings of the Association for Computational Linguistics: EACL 2023. Dubrovnik, CroatiaAssociation for Computational Linguistics2023\n\nFindings of the WMT 2022 shared task on quality estimation. Chrysoula Zerva, Fr\u00e9d\u00e9ric Blain, Ricardo Rei, Piyawat Lertvittayakumjorn, G C Jos\u00e9, Steffen Souza, Diptesh Eger, Duarte Kanojia, Constantin Alves, Marina Or\u0203san, Fomicheva, F T Andr\u00e9, Lucia Martins, Specia, Proceedings of the Seventh Conference on Machine Translation (WMT). the Seventh Conference on Machine Translation (WMT)Abu Dhabi, United Arab Emirates2022Association for Computational Linguistics\n\nTianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q Weinberger, Yoav Artzi, BERTScore: Evaluating text generation with BERT. International Conference on Learning Representations. 2020\n\nSentence simplification with deep reinforcement learning. Xingxing Zhang, Mirella Lapata, 10.18653/v1/D17-1062Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. the 2017 Conference on Empirical Methods in Natural Language ProcessingCopenhagen, DenmarkAssociation for Computational Linguistics2017\n", "annotations": {"author": "[{\"end\":196,\"start\":89},{\"end\":287,\"start\":197},{\"end\":390,\"start\":288},{\"end\":485,\"start\":391},{\"end\":837,\"start\":486}]", "publisher": null, "author_last_name": "[{\"end\":103,\"start\":95},{\"end\":204,\"start\":201},{\"end\":303,\"start\":296},{\"end\":397,\"start\":395},{\"end\":491,\"start\":489}]", "author_first_name": "[{\"end\":94,\"start\":89},{\"end\":200,\"start\":197},{\"end\":295,\"start\":288},{\"end\":394,\"start\":391},{\"end\":488,\"start\":486}]", "author_affiliation": "[{\"end\":195,\"start\":131},{\"end\":286,\"start\":222},{\"end\":389,\"start\":325},{\"end\":484,\"start\":420},{\"end\":836,\"start\":493}]", "title": "[{\"end\":86,\"start\":1},{\"end\":923,\"start\":838}]", "venue": null, "abstract": "[{\"end\":2376,\"start\":957}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b69\"},\"end\":2530,\"start\":2515},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":2556,\"start\":2530},{\"attributes\":{\"ref_id\":\"b73\"},\"end\":2690,\"start\":2669},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2717,\"start\":2690},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":2794,\"start\":2773},{\"attributes\":{\"ref_id\":\"b83\"},\"end\":3144,\"start\":3127},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":3410,\"start\":3389},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":3459,\"start\":3442},{\"attributes\":{\"ref_id\":\"b82\"},\"end\":3867,\"start\":3850},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":4958,\"start\":4937},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":5078,\"start\":5058},{\"attributes\":{\"ref_id\":\"b76\"},\"end\":5214,\"start\":5194},{\"end\":5247,\"start\":5226},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":6347,\"start\":6324},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":6482,\"start\":6465},{\"attributes\":{\"ref_id\":\"b81\"},\"end\":6542,\"start\":6525},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":7784,\"start\":7766},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":11638,\"start\":11616},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":12338,\"start\":12317},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":12366,\"start\":12345},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":12492,\"start\":12471},{\"end\":12881,\"start\":12824},{\"end\":12917,\"start\":12896},{\"attributes\":{\"ref_id\":\"b65\"},\"end\":13083,\"start\":13061},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":14743,\"start\":14725},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":15220,\"start\":15198},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":16788,\"start\":16766},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":16807,\"start\":16788},{\"end\":17640,\"start\":17632},{\"end\":17642,\"start\":17640},{\"end\":17644,\"start\":17642},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":18212,\"start\":18192},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":18450,\"start\":18429},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":19223,\"start\":19203},{\"end\":21341,\"start\":21319},{\"end\":21363,\"start\":21343},{\"attributes\":{\"ref_id\":\"b76\"},\"end\":21566,\"start\":21546},{\"end\":21599,\"start\":21578},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":22270,\"start\":22247},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":23572,\"start\":23549},{\"attributes\":{\"ref_id\":\"b82\"},\"end\":23596,\"start\":23579},{\"attributes\":{\"ref_id\":\"b86\"},\"end\":23677,\"start\":23657},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":23737,\"start\":23719},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":23783,\"start\":23761},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":23816,\"start\":23794},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":24300,\"start\":24282},{\"attributes\":{\"ref_id\":\"b79\"},\"end\":24413,\"start\":24395},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":25306,\"start\":25284},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":26867,\"start\":26848},{\"attributes\":{\"ref_id\":\"b85\"},\"end\":26886,\"start\":26867},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":28329,\"start\":28308},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":30421,\"start\":30402},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":30525,\"start\":30513},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":30708,\"start\":30686},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":30728,\"start\":30708},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":30776,\"start\":30757},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":30856,\"start\":30836},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":30880,\"start\":30856},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":31032,\"start\":31013},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":31114,\"start\":31086},{\"attributes\":{\"ref_id\":\"b71\"},\"end\":31134,\"start\":31114},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":31399,\"start\":31377},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":31422,\"start\":31399},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":31525,\"start\":31500},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":31673,\"start\":31658},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":31894,\"start\":31874},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":31993,\"start\":31964},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":32071,\"start\":32041},{\"attributes\":{\"ref_id\":\"b84\"},\"end\":32278,\"start\":32255},{\"attributes\":{\"ref_id\":\"b87\"},\"end\":32361,\"start\":32337},{\"attributes\":{\"ref_id\":\"b75\"},\"end\":32388,\"start\":32370},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":32501,\"start\":32473},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":32898,\"start\":32877},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":33000,\"start\":32979},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":33087,\"start\":33070},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":33378,\"start\":33356},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":33506,\"start\":33485},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":34457,\"start\":34436},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":34489,\"start\":34465},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":34532,\"start\":34513},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":34604,\"start\":34589},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":34979,\"start\":34959},{\"attributes\":{\"ref_id\":\"b74\"},\"end\":34996,\"start\":34979},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":35505,\"start\":35484},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":35537,\"start\":35515},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":35709,\"start\":35687},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":37086,\"start\":37071},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":37272,\"start\":37246},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":37368,\"start\":37349},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":37485,\"start\":37456},{\"attributes\":{\"ref_id\":\"b72\"},\"end\":37775,\"start\":37754},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":37794,\"start\":37775},{\"attributes\":{\"ref_id\":\"b66\"},\"end\":37888,\"start\":37869},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":38146,\"start\":38128},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":38704,\"start\":38682},{\"end\":40077,\"start\":40062},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":40196,\"start\":40165},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":40215,\"start\":40196},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":40243,\"start\":40215},{\"end\":40264,\"start\":40243},{\"attributes\":{\"ref_id\":\"b66\"},\"end\":40563,\"start\":40544},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":41302,\"start\":41287},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":42040,\"start\":42020},{\"end\":42092,\"start\":42078},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":42598,\"start\":42577},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":42774,\"start\":42752},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":43171,\"start\":43142},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":43235,\"start\":43214},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":43566,\"start\":43547},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":43857,\"start\":43840},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":44376,\"start\":44354},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":45138,\"start\":45116},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":45158,\"start\":45138},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":45289,\"start\":45267},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":45587,\"start\":45570},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":46430,\"start\":46407},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":47024,\"start\":46996},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":47617,\"start\":47595},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":47820,\"start\":47801},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":49100,\"start\":49079},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":50299,\"start\":50277},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":50415,\"start\":50400},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":50500,\"start\":50480},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":50518,\"start\":50500},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":50538,\"start\":50518},{\"attributes\":{\"ref_id\":\"b78\"},\"end\":50573,\"start\":50551},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":51015,\"start\":50986},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":51058,\"start\":51030},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":51388,\"start\":51367},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":51459,\"start\":51437},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":51707,\"start\":51678},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":51890,\"start\":51869},{\"attributes\":{\"ref_id\":\"b87\"},\"end\":52029,\"start\":52005},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":52118,\"start\":52097},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":52285,\"start\":52265},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":52506,\"start\":52485},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":52713,\"start\":52691},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":53189,\"start\":53168},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":53453,\"start\":53431},{\"attributes\":{\"ref_id\":\"b76\"},\"end\":53486,\"start\":53466},{\"attributes\":{\"ref_id\":\"b77\"},\"end\":53535,\"start\":53513},{\"attributes\":{\"ref_id\":\"b80\"},\"end\":53622,\"start\":53603},{\"end\":53868,\"start\":53847},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":61553,\"start\":61525},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":62101,\"start\":62080},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":64510,\"start\":64488},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":65844,\"start\":65822},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":65962,\"start\":65942},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":66087,\"start\":66058},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":66168,\"start\":66147},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":66525,\"start\":66507}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":66988,\"start\":66975},{\"attributes\":{\"id\":\"fig_1\"},\"end\":67157,\"start\":66989},{\"attributes\":{\"id\":\"fig_2\"},\"end\":67340,\"start\":67158},{\"attributes\":{\"id\":\"fig_3\"},\"end\":67551,\"start\":67341},{\"attributes\":{\"id\":\"fig_4\"},\"end\":67868,\"start\":67552},{\"attributes\":{\"id\":\"fig_6\"},\"end\":67993,\"start\":67869},{\"attributes\":{\"id\":\"fig_7\"},\"end\":68239,\"start\":67994},{\"attributes\":{\"id\":\"fig_8\"},\"end\":68336,\"start\":68240},{\"attributes\":{\"id\":\"fig_9\"},\"end\":68584,\"start\":68337},{\"attributes\":{\"id\":\"fig_10\"},\"end\":68812,\"start\":68585},{\"attributes\":{\"id\":\"fig_12\"},\"end\":68869,\"start\":68813},{\"attributes\":{\"id\":\"fig_13\"},\"end\":69023,\"start\":68870},{\"attributes\":{\"id\":\"fig_14\"},\"end\":69193,\"start\":69024},{\"attributes\":{\"id\":\"fig_15\"},\"end\":69361,\"start\":69194},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":69981,\"start\":69362},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":70495,\"start\":69982},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":70680,\"start\":70496},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":71449,\"start\":70681},{\"attributes\":{\"id\":\"tab_10\",\"type\":\"table\"},\"end\":71530,\"start\":71450},{\"attributes\":{\"id\":\"tab_11\",\"type\":\"table\"},\"end\":71996,\"start\":71531},{\"attributes\":{\"id\":\"tab_13\",\"type\":\"table\"},\"end\":72664,\"start\":71997},{\"attributes\":{\"id\":\"tab_14\",\"type\":\"table\"},\"end\":72817,\"start\":72665},{\"attributes\":{\"id\":\"tab_15\",\"type\":\"table\"},\"end\":73155,\"start\":72818}]", "paragraph": "[{\"end\":3292,\"start\":2392},{\"end\":3983,\"start\":3294},{\"end\":4698,\"start\":3985},{\"end\":5754,\"start\":4700},{\"end\":5866,\"start\":5756},{\"end\":6612,\"start\":5886},{\"end\":7459,\"start\":6631},{\"end\":8506,\"start\":7498},{\"end\":8940,\"start\":8535},{\"end\":9029,\"start\":8966},{\"end\":9105,\"start\":9031},{\"end\":9292,\"start\":9107},{\"end\":9455,\"start\":9320},{\"end\":9631,\"start\":9457},{\"end\":9971,\"start\":9660},{\"end\":10265,\"start\":9973},{\"end\":10875,\"start\":10294},{\"end\":11038,\"start\":10877},{\"end\":11365,\"start\":11074},{\"end\":11523,\"start\":11385},{\"end\":12978,\"start\":11547},{\"end\":13605,\"start\":12993},{\"end\":15051,\"start\":13635},{\"end\":15374,\"start\":15068},{\"end\":16475,\"start\":15376},{\"end\":16874,\"start\":16477},{\"end\":17564,\"start\":16886},{\"end\":18094,\"start\":17566},{\"end\":19458,\"start\":18096},{\"end\":19707,\"start\":19470},{\"end\":20102,\"start\":19719},{\"end\":20595,\"start\":20114},{\"end\":21057,\"start\":20597},{\"end\":21212,\"start\":21069},{\"end\":22085,\"start\":21214},{\"end\":22509,\"start\":22087},{\"end\":22840,\"start\":22521},{\"end\":22920,\"start\":22842},{\"end\":25090,\"start\":22959},{\"end\":26545,\"start\":25169},{\"end\":26578,\"start\":26547},{\"end\":27103,\"start\":26580},{\"end\":27999,\"start\":27105},{\"end\":28245,\"start\":28001},{\"end\":28696,\"start\":28247},{\"end\":28950,\"start\":28698},{\"end\":29349,\"start\":28952},{\"end\":29504,\"start\":29351},{\"end\":29635,\"start\":29506},{\"end\":30283,\"start\":29637},{\"end\":32687,\"start\":30300},{\"end\":33577,\"start\":32689},{\"end\":34258,\"start\":33592},{\"end\":35538,\"start\":34274},{\"end\":36419,\"start\":35559},{\"end\":36851,\"start\":36454},{\"end\":37486,\"start\":36878},{\"end\":37795,\"start\":37522},{\"end\":39098,\"start\":37797},{\"end\":39356,\"start\":39100},{\"end\":39649,\"start\":39358},{\"end\":39954,\"start\":39651},{\"end\":40692,\"start\":39989},{\"end\":40867,\"start\":40704},{\"end\":41186,\"start\":40869},{\"end\":41544,\"start\":41188},{\"end\":41849,\"start\":41546},{\"end\":42859,\"start\":41882},{\"end\":43326,\"start\":42861},{\"end\":43937,\"start\":43351},{\"end\":44070,\"start\":43965},{\"end\":44795,\"start\":44072},{\"end\":45290,\"start\":44797},{\"end\":45393,\"start\":45335},{\"end\":45884,\"start\":45395},{\"end\":46714,\"start\":45911},{\"end\":47025,\"start\":46739},{\"end\":47080,\"start\":47037},{\"end\":47117,\"start\":47082},{\"end\":47464,\"start\":47119},{\"end\":47821,\"start\":47466},{\"end\":47959,\"start\":47861},{\"end\":48124,\"start\":47971},{\"end\":48356,\"start\":48126},{\"end\":48571,\"start\":48368},{\"end\":48733,\"start\":48573},{\"end\":48919,\"start\":48745},{\"end\":49027,\"start\":48921},{\"end\":49269,\"start\":49064},{\"end\":49692,\"start\":49330},{\"end\":49756,\"start\":49694},{\"end\":49831,\"start\":49773},{\"end\":49903,\"start\":49833},{\"end\":49952,\"start\":49905},{\"end\":50032,\"start\":49954},{\"end\":50574,\"start\":50034},{\"end\":51708,\"start\":50605},{\"end\":52714,\"start\":51767},{\"end\":52942,\"start\":52716},{\"end\":53035,\"start\":52944},{\"end\":53454,\"start\":53037},{\"end\":53717,\"start\":53456},{\"end\":53835,\"start\":53719},{\"end\":54148,\"start\":53837},{\"end\":54412,\"start\":54150},{\"end\":54606,\"start\":54414},{\"end\":54665,\"start\":54608},{\"end\":55346,\"start\":54667},{\"end\":55965,\"start\":55387},{\"end\":56100,\"start\":55967},{\"end\":56506,\"start\":56102},{\"end\":56810,\"start\":56508},{\"end\":57472,\"start\":56812},{\"end\":57975,\"start\":57474},{\"end\":58881,\"start\":57977},{\"end\":59049,\"start\":58904},{\"end\":60038,\"start\":59051},{\"end\":60214,\"start\":60040},{\"end\":61085,\"start\":60226},{\"end\":61988,\"start\":61087},{\"end\":63191,\"start\":61990},{\"end\":63554,\"start\":63193},{\"end\":64698,\"start\":63556},{\"end\":65681,\"start\":64734},{\"end\":65748,\"start\":65710},{\"end\":66239,\"start\":65750},{\"end\":66298,\"start\":66271},{\"end\":66974,\"start\":66300},{\"end\":66987,\"start\":66978},{\"end\":67156,\"start\":67003},{\"end\":67339,\"start\":67172},{\"end\":67550,\"start\":67355},{\"end\":67867,\"start\":67566},{\"end\":67992,\"start\":67883},{\"end\":68238,\"start\":68019},{\"end\":68335,\"start\":68256},{\"end\":68583,\"start\":68353},{\"end\":68811,\"start\":68601},{\"end\":68868,\"start\":68816},{\"end\":69022,\"start\":68886},{\"end\":69192,\"start\":69040},{\"end\":69360,\"start\":69210},{\"end\":69551,\"start\":69375},{\"end\":70094,\"start\":69995},{\"end\":70494,\"start\":70348},{\"end\":70679,\"start\":70509},{\"end\":71152,\"start\":70684},{\"end\":71448,\"start\":71441},{\"end\":71529,\"start\":71463},{\"end\":71742,\"start\":71544},{\"end\":72200,\"start\":72010},{\"end\":72816,\"start\":72678},{\"end\":73094,\"start\":72831}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":9319,\"start\":9293},{\"attributes\":{\"id\":\"formula_1\"},\"end\":9659,\"start\":9632},{\"attributes\":{\"id\":\"formula_2\"},\"end\":10293,\"start\":10266},{\"attributes\":{\"id\":\"formula_3\"},\"end\":25168,\"start\":25091},{\"attributes\":{\"id\":\"formula_4\"},\"end\":49329,\"start\":49270}]", "table_ref": "[{\"end\":13738,\"start\":13737},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":25469,\"start\":25468},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":29652,\"start\":29651},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":36599,\"start\":36598},{\"attributes\":{\"ref_id\":\"tab_10\"},\"end\":41543,\"start\":41542},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":43426,\"start\":43425},{\"attributes\":{\"ref_id\":\"tab_10\"},\"end\":50668,\"start\":50667},{\"attributes\":{\"ref_id\":\"tab_11\"},\"end\":58381,\"start\":58380},{\"attributes\":{\"ref_id\":\"tab_11\"},\"end\":59845,\"start\":59844},{\"attributes\":{\"ref_id\":\"tab_13\"},\"end\":61269,\"start\":61268},{\"attributes\":{\"ref_id\":\"tab_14\"},\"end\":64470,\"start\":64469},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":64865,\"start\":64864},{\"attributes\":{\"ref_id\":\"tab_15\"},\"end\":64877,\"start\":64876}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2390,\"start\":2378},{\"attributes\":{\"n\":\"2\"},\"end\":5884,\"start\":5869},{\"attributes\":{\"n\":\"2.1\"},\"end\":6629,\"start\":6615},{\"attributes\":{\"n\":\"2.2\"},\"end\":7496,\"start\":7462},{\"attributes\":{\"n\":\"2.3\"},\"end\":8533,\"start\":8509},{\"end\":8964,\"start\":8943},{\"attributes\":{\"n\":\"2.4\"},\"end\":11072,\"start\":11041},{\"attributes\":{\"n\":\"3\"},\"end\":11383,\"start\":11368},{\"attributes\":{\"n\":\"3.1\"},\"end\":11545,\"start\":11526},{\"attributes\":{\"n\":\"3.2\"},\"end\":12991,\"start\":12981},{\"attributes\":{\"n\":\"3.3\"},\"end\":13633,\"start\":13608},{\"attributes\":{\"n\":\"4\"},\"end\":15066,\"start\":15054},{\"end\":16884,\"start\":16877},{\"end\":19468,\"start\":19461},{\"end\":19717,\"start\":19710},{\"end\":20112,\"start\":20105},{\"end\":21067,\"start\":21060},{\"end\":22519,\"start\":22512},{\"attributes\":{\"n\":\"5\"},\"end\":22957,\"start\":22923},{\"attributes\":{\"n\":\"7\"},\"end\":30298,\"start\":30286},{\"attributes\":{\"n\":\"8\"},\"end\":33590,\"start\":33580},{\"end\":34272,\"start\":34261},{\"end\":35557,\"start\":35541},{\"end\":36452,\"start\":36422},{\"end\":36876,\"start\":36854},{\"end\":37520,\"start\":37489},{\"end\":39987,\"start\":39957},{\"end\":40702,\"start\":40695},{\"end\":41880,\"start\":41852},{\"end\":43349,\"start\":43329},{\"end\":43963,\"start\":43940},{\"end\":45333,\"start\":45293},{\"end\":45909,\"start\":45887},{\"end\":46737,\"start\":46717},{\"end\":47035,\"start\":47028},{\"end\":47859,\"start\":47824},{\"end\":47969,\"start\":47962},{\"end\":48366,\"start\":48359},{\"end\":48743,\"start\":48736},{\"end\":49062,\"start\":49030},{\"end\":49771,\"start\":49759},{\"end\":50603,\"start\":50577},{\"end\":51736,\"start\":51711},{\"end\":51765,\"start\":51739},{\"end\":55385,\"start\":55349},{\"end\":58902,\"start\":58884},{\"end\":60224,\"start\":60217},{\"end\":64732,\"start\":64701},{\"end\":65708,\"start\":65684},{\"end\":66269,\"start\":66242},{\"end\":67000,\"start\":66990},{\"end\":67169,\"start\":67159},{\"end\":67352,\"start\":67342},{\"end\":67563,\"start\":67553},{\"end\":67880,\"start\":67870},{\"end\":68015,\"start\":67995},{\"end\":68252,\"start\":68241},{\"end\":68349,\"start\":68338},{\"end\":68597,\"start\":68586},{\"end\":68882,\"start\":68871},{\"end\":69036,\"start\":69025},{\"end\":69206,\"start\":69195},{\"end\":69372,\"start\":69363},{\"end\":69992,\"start\":69983},{\"end\":70506,\"start\":70497},{\"end\":71460,\"start\":71451},{\"end\":71541,\"start\":71532},{\"end\":72007,\"start\":71998},{\"end\":72675,\"start\":72666},{\"end\":72828,\"start\":72819}]", "table": "[{\"end\":69981,\"start\":69552},{\"end\":70347,\"start\":70095},{\"end\":71440,\"start\":71153},{\"end\":71996,\"start\":71743},{\"end\":72664,\"start\":72201},{\"end\":73155,\"start\":73095}]", "figure_caption": "[{\"end\":66988,\"start\":66977},{\"end\":67157,\"start\":67002},{\"end\":67340,\"start\":67171},{\"end\":67551,\"start\":67354},{\"end\":67868,\"start\":67565},{\"end\":67993,\"start\":67882},{\"end\":68239,\"start\":68018},{\"end\":68336,\"start\":68255},{\"end\":68584,\"start\":68352},{\"end\":68812,\"start\":68600},{\"end\":68869,\"start\":68815},{\"end\":69023,\"start\":68885},{\"end\":69193,\"start\":69039},{\"end\":69361,\"start\":69209},{\"end\":69552,\"start\":69374},{\"end\":70095,\"start\":69994},{\"end\":70680,\"start\":70508},{\"end\":71153,\"start\":70683},{\"end\":71530,\"start\":71462},{\"end\":71743,\"start\":71543},{\"end\":72201,\"start\":72009},{\"end\":72817,\"start\":72677},{\"end\":73095,\"start\":72830}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":3982,\"start\":3981},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":6144,\"start\":6143},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":6284,\"start\":6283},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":8750,\"start\":8749},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":13502,\"start\":13501},{\"end\":14752,\"start\":14751},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":15422,\"start\":15418},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":15445,\"start\":15438},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":15807,\"start\":15806},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":16003,\"start\":15999},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":16535,\"start\":16534},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":17208,\"start\":17204},{\"end\":17761,\"start\":17760},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":18093,\"start\":18091},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":18654,\"start\":18650},{\"end\":19910,\"start\":19909},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":20655,\"start\":20651},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":21291,\"start\":21290},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":36658,\"start\":36657},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":41847,\"start\":41845},{\"end\":55763,\"start\":55762},{\"end\":57656,\"start\":57655},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":59060,\"start\":59058},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":60548,\"start\":60546},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":62204,\"start\":62202},{\"attributes\":{\"ref_id\":\"fig_9\"},\"end\":62693,\"start\":62691},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":63295,\"start\":63293},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":63581,\"start\":63579}]", "bib_author_first_name": "[{\"end\":77214,\"start\":77206},{\"end\":77235,\"start\":77230},{\"end\":77251,\"start\":77244},{\"end\":77268,\"start\":77260},{\"end\":77621,\"start\":77613},{\"end\":77645,\"start\":77637},{\"end\":77660,\"start\":77655},{\"end\":77811,\"start\":77803},{\"end\":77835,\"start\":77827},{\"end\":77850,\"start\":77845},{\"end\":77979,\"start\":77974},{\"end\":77999,\"start\":77993},{\"end\":78304,\"start\":78294},{\"end\":78316,\"start\":78311},{\"end\":78332,\"start\":78323},{\"end\":78347,\"start\":78343},{\"end\":78463,\"start\":78454},{\"end\":78477,\"start\":78470},{\"end\":78488,\"start\":78483},{\"end\":78789,\"start\":78779},{\"end\":78804,\"start\":78799},{\"end\":78816,\"start\":78814},{\"end\":78828,\"start\":78824},{\"end\":78846,\"start\":78840},{\"end\":79160,\"start\":79157},{\"end\":79176,\"start\":79168},{\"end\":79187,\"start\":79183},{\"end\":79202,\"start\":79195},{\"end\":79217,\"start\":79212},{\"end\":79219,\"start\":79218},{\"end\":79236,\"start\":79228},{\"end\":79253,\"start\":79247},{\"end\":79273,\"start\":79267},{\"end\":79287,\"start\":79281},{\"end\":79302,\"start\":79296},{\"end\":79505,\"start\":79496},{\"end\":79521,\"start\":79515},{\"end\":79542,\"start\":79536},{\"end\":79689,\"start\":79685},{\"end\":79698,\"start\":79695},{\"end\":79711,\"start\":79705},{\"end\":80065,\"start\":80061},{\"end\":80080,\"start\":80074},{\"end\":80095,\"start\":80088},{\"end\":80110,\"start\":80105},{\"end\":80125,\"start\":80119},{\"end\":80140,\"start\":80133},{\"end\":80155,\"start\":80149},{\"end\":80171,\"start\":80165},{\"end\":80498,\"start\":80494},{\"end\":80511,\"start\":80506},{\"end\":80524,\"start\":80519},{\"end\":80616,\"start\":80615},{\"end\":80640,\"start\":80631},{\"end\":80649,\"start\":80648},{\"end\":80833,\"start\":80825},{\"end\":80843,\"start\":80840},{\"end\":80855,\"start\":80848},{\"end\":80870,\"start\":80862},{\"end\":80879,\"start\":80876},{\"end\":80891,\"start\":80884},{\"end\":81103,\"start\":81096},{\"end\":81119,\"start\":81112},{\"end\":81126,\"start\":81124},{\"end\":81136,\"start\":81132},{\"end\":81152,\"start\":81144},{\"end\":81160,\"start\":81157},{\"end\":81175,\"start\":81168},{\"end\":81189,\"start\":81183},{\"end\":81205,\"start\":81198},{\"end\":81220,\"start\":81214},{\"end\":81222,\"start\":81221},{\"end\":81431,\"start\":81425},{\"end\":81445,\"start\":81441},{\"end\":81811,\"start\":81806},{\"end\":81813,\"start\":81812},{\"end\":81837,\"start\":81831},{\"end\":81858,\"start\":81853},{\"end\":81945,\"start\":81944},{\"end\":81959,\"start\":81953},{\"end\":81982,\"start\":81977},{\"end\":82286,\"start\":82280},{\"end\":82303,\"start\":82296},{\"end\":82320,\"start\":82315},{\"end\":82341,\"start\":82330},{\"end\":82717,\"start\":82714},{\"end\":82730,\"start\":82724},{\"end\":82740,\"start\":82735},{\"end\":82763,\"start\":82757},{\"end\":82772,\"start\":82769},{\"end\":83130,\"start\":83127},{\"end\":83143,\"start\":83136},{\"end\":83155,\"start\":83152},{\"end\":83179,\"start\":83175},{\"end\":83181,\"start\":83180},{\"end\":83194,\"start\":83189},{\"end\":83533,\"start\":83529},{\"end\":83636,\"start\":83631},{\"end\":83646,\"start\":83641},{\"end\":83660,\"start\":83655},{\"end\":83673,\"start\":83668},{\"end\":83686,\"start\":83679},{\"end\":83700,\"start\":83692},{\"end\":84080,\"start\":84074},{\"end\":84096,\"start\":84090},{\"end\":84110,\"start\":84105},{\"end\":84127,\"start\":84121},{\"end\":84143,\"start\":84138},{\"end\":84157,\"start\":84149},{\"end\":84327,\"start\":84321},{\"end\":84348,\"start\":84339},{\"end\":84364,\"start\":84359},{\"end\":84381,\"start\":84375},{\"end\":84396,\"start\":84390},{\"end\":84417,\"start\":84405},{\"end\":84710,\"start\":84706},{\"end\":84979,\"start\":84975},{\"end\":84995,\"start\":84989},{\"end\":85183,\"start\":85178},{\"end\":85196,\"start\":85191},{\"end\":85204,\"start\":85199},{\"end\":85213,\"start\":85209},{\"end\":85368,\"start\":85363},{\"end\":85384,\"start\":85380},{\"end\":85401,\"start\":85394},{\"end\":85408,\"start\":85402},{\"end\":85423,\"start\":85416},{\"end\":85431,\"start\":85430},{\"end\":85447,\"start\":85441},{\"end\":85460,\"start\":85456},{\"end\":85578,\"start\":85577},{\"end\":85594,\"start\":85590},{\"end\":85611,\"start\":85606},{\"end\":86094,\"start\":86089},{\"end\":86108,\"start\":86105},{\"end\":86117,\"start\":86114},{\"end\":86277,\"start\":86276},{\"end\":86291,\"start\":86286},{\"end\":86369,\"start\":86364},{\"end\":86380,\"start\":86374},{\"end\":86390,\"start\":86386},{\"end\":86408,\"start\":86400},{\"end\":86416,\"start\":86413},{\"end\":86424,\"start\":86421},{\"end\":86435,\"start\":86429},{\"end\":86445,\"start\":86443},{\"end\":86451,\"start\":86448},{\"end\":86464,\"start\":86458},{\"end\":86481,\"start\":86474},{\"end\":86599,\"start\":86595},{\"end\":86614,\"start\":86607},{\"end\":86629,\"start\":86624},{\"end\":86639,\"start\":86635},{\"end\":86650,\"start\":86647},{\"end\":86954,\"start\":86946},{\"end\":86971,\"start\":86962},{\"end\":86985,\"start\":86978},{\"end\":87269,\"start\":87260},{\"end\":87285,\"start\":87278},{\"end\":87301,\"start\":87295},{\"end\":87310,\"start\":87309},{\"end\":87324,\"start\":87321},{\"end\":87342,\"start\":87337},{\"end\":87344,\"start\":87343},{\"end\":87360,\"start\":87349},{\"end\":87515,\"start\":87510},{\"end\":87557,\"start\":87553},{\"end\":87572,\"start\":87564},{\"end\":87590,\"start\":87585},{\"end\":87779,\"start\":87774},{\"end\":87791,\"start\":87787},{\"end\":87803,\"start\":87797},{\"end\":87815,\"start\":87811},{\"end\":88150,\"start\":88142},{\"end\":88164,\"start\":88158},{\"end\":88179,\"start\":88175},{\"end\":88194,\"start\":88189},{\"end\":88196,\"start\":88195},{\"end\":88674,\"start\":88669},{\"end\":88684,\"start\":88680},{\"end\":88695,\"start\":88692},{\"end\":89223,\"start\":89219},{\"end\":89236,\"start\":89232},{\"end\":89256,\"start\":89248},{\"end\":89369,\"start\":89365},{\"end\":89387,\"start\":89382},{\"end\":89524,\"start\":89517},{\"end\":89542,\"start\":89534},{\"end\":89561,\"start\":89558},{\"end\":89991,\"start\":89984},{\"end\":90004,\"start\":90001},{\"end\":90015,\"start\":90010},{\"end\":90029,\"start\":90026},{\"end\":90343,\"start\":90338},{\"end\":90681,\"start\":90676},{\"end\":90696,\"start\":90690},{\"end\":91020,\"start\":91014},{\"end\":91035,\"start\":91029},{\"end\":91050,\"start\":91045},{\"end\":91063,\"start\":91059},{\"end\":91370,\"start\":91365},{\"end\":91384,\"start\":91380},{\"end\":91399,\"start\":91396},{\"end\":91776,\"start\":91769},{\"end\":91792,\"start\":91785},{\"end\":91808,\"start\":91801},{\"end\":92279,\"start\":92275},{\"end\":92292,\"start\":92288},{\"end\":92299,\"start\":92297},{\"end\":92312,\"start\":92307},{\"end\":92329,\"start\":92322},{\"end\":92331,\"start\":92330},{\"end\":92350,\"start\":92344},{\"end\":92365,\"start\":92360},{\"end\":92381,\"start\":92373},{\"end\":92399,\"start\":92391},{\"end\":92411,\"start\":92407},{\"end\":92502,\"start\":92495},{\"end\":92504,\"start\":92503},{\"end\":92520,\"start\":92515},{\"end\":92806,\"start\":92798},{\"end\":92824,\"start\":92816},{\"end\":92844,\"start\":92839},{\"end\":93283,\"start\":93276},{\"end\":93299,\"start\":93294},{\"end\":93312,\"start\":93308},{\"end\":93327,\"start\":93319},{\"end\":93637,\"start\":93632},{\"end\":93650,\"start\":93647},{\"end\":93673,\"start\":93664},{\"end\":93689,\"start\":93682},{\"end\":93702,\"start\":93697},{\"end\":93719,\"start\":93712},{\"end\":93733,\"start\":93724},{\"end\":94217,\"start\":94211},{\"end\":94228,\"start\":94225},{\"end\":94235,\"start\":94233},{\"end\":94247,\"start\":94241},{\"end\":94261,\"start\":94254},{\"end\":94471,\"start\":94466},{\"end\":94484,\"start\":94480},{\"end\":94498,\"start\":94494},{\"end\":94517,\"start\":94508},{\"end\":94529,\"start\":94523},{\"end\":94545,\"start\":94538},{\"end\":94559,\"start\":94554},{\"end\":94569,\"start\":94566},{\"end\":94579,\"start\":94574},{\"end\":94581,\"start\":94580},{\"end\":94685,\"start\":94679},{\"end\":94702,\"start\":94697},{\"end\":94713,\"start\":94708},{\"end\":95035,\"start\":95028},{\"end\":95046,\"start\":95041},{\"end\":95059,\"start\":95056},{\"end\":95061,\"start\":95060},{\"end\":95075,\"start\":95071},{\"end\":95430,\"start\":95423},{\"end\":95442,\"start\":95436},{\"end\":95453,\"start\":95452},{\"end\":95469,\"start\":95460},{\"end\":95484,\"start\":95481},{\"end\":95486,\"start\":95485},{\"end\":95503,\"start\":95494},{\"end\":95522,\"start\":95521},{\"end\":95524,\"start\":95523},{\"end\":95538,\"start\":95531},{\"end\":95555,\"start\":95549},{\"end\":95572,\"start\":95567},{\"end\":95584,\"start\":95580},{\"end\":95601,\"start\":95600},{\"end\":95603,\"start\":95602},{\"end\":95902,\"start\":95895},{\"end\":95914,\"start\":95909},{\"end\":95925,\"start\":95922},{\"end\":96206,\"start\":96198},{\"end\":96223,\"start\":96216},{\"end\":96245,\"start\":96241},{\"end\":96261,\"start\":96255},{\"end\":96282,\"start\":96277},{\"end\":96559,\"start\":96555},{\"end\":96572,\"start\":96569},{\"end\":96585,\"start\":96579},{\"end\":96598,\"start\":96591},{\"end\":97011,\"start\":97004},{\"end\":97123,\"start\":97116},{\"end\":97253,\"start\":97248},{\"end\":97385,\"start\":97380},{\"end\":97654,\"start\":97648},{\"end\":97669,\"start\":97664},{\"end\":98047,\"start\":98042},{\"end\":98059,\"start\":98055},{\"end\":98070,\"start\":98067},{\"end\":98387,\"start\":98382},{\"end\":98399,\"start\":98395},{\"end\":98410,\"start\":98407},{\"end\":98876,\"start\":98871},{\"end\":98888,\"start\":98884},{\"end\":98899,\"start\":98896},{\"end\":99250,\"start\":99242},{\"end\":99259,\"start\":99256},{\"end\":99274,\"start\":99267},{\"end\":99633,\"start\":99625},{\"end\":99642,\"start\":99639},{\"end\":99655,\"start\":99648},{\"end\":99921,\"start\":99916},{\"end\":99935,\"start\":99929},{\"end\":99953,\"start\":99947},{\"end\":99965,\"start\":99961},{\"end\":99981,\"start\":99974},{\"end\":99992,\"start\":99986},{\"end\":100008,\"start\":100003},{\"end\":100025,\"start\":100016},{\"end\":100027,\"start\":100026},{\"end\":100107,\"start\":100100},{\"end\":100129,\"start\":100122},{\"end\":100144,\"start\":100138},{\"end\":100164,\"start\":100154},{\"end\":100183,\"start\":100175},{\"end\":100201,\"start\":100193},{\"end\":100216,\"start\":100211},{\"end\":100230,\"start\":100226},{\"end\":100244,\"start\":100238},{\"end\":100429,\"start\":100426},{\"end\":100443,\"start\":100439},{\"end\":100468,\"start\":100457},{\"end\":100489,\"start\":100481},{\"end\":100818,\"start\":100816},{\"end\":100832,\"start\":100824},{\"end\":100845,\"start\":100838},{\"end\":100857,\"start\":100852},{\"end\":100871,\"start\":100865},{\"end\":100883,\"start\":100878},{\"end\":100895,\"start\":100890},{\"end\":101248,\"start\":101241},{\"end\":101262,\"start\":101255},{\"end\":101277,\"start\":101270},{\"end\":101291,\"start\":101286},{\"end\":101301,\"start\":101297},{\"end\":101303,\"start\":101302},{\"end\":101317,\"start\":101311},{\"end\":101336,\"start\":101328},{\"end\":101620,\"start\":101615},{\"end\":101630,\"start\":101625},{\"end\":101641,\"start\":101635},{\"end\":101652,\"start\":101647},{\"end\":101665,\"start\":101660},{\"end\":101682,\"start\":101672},{\"end\":101700,\"start\":101696},{\"end\":101702,\"start\":101701},{\"end\":101714,\"start\":101710},{\"end\":101734,\"start\":101726},{\"end\":101932,\"start\":101929},{\"end\":101945,\"start\":101937},{\"end\":101960,\"start\":101955},{\"end\":101976,\"start\":101970},{\"end\":101988,\"start\":101983},{\"end\":102122,\"start\":102119},{\"end\":102131,\"start\":102127},{\"end\":102144,\"start\":102140},{\"end\":102157,\"start\":102152},{\"end\":102173,\"start\":102168},{\"end\":102406,\"start\":102400},{\"end\":102421,\"start\":102418},{\"end\":102436,\"start\":102430},{\"end\":102453,\"start\":102446},{\"end\":102697,\"start\":102688},{\"end\":102713,\"start\":102705},{\"end\":102728,\"start\":102721},{\"end\":102741,\"start\":102734},{\"end\":102763,\"start\":102762},{\"end\":102765,\"start\":102764},{\"end\":102779,\"start\":102772},{\"end\":102794,\"start\":102787},{\"end\":102807,\"start\":102801},{\"end\":102827,\"start\":102817},{\"end\":102841,\"start\":102835},{\"end\":102862,\"start\":102861},{\"end\":102864,\"start\":102863},{\"end\":102877,\"start\":102872},{\"end\":103098,\"start\":103092},{\"end\":103112,\"start\":103106},{\"end\":103127,\"start\":103122},{\"end\":103138,\"start\":103132},{\"end\":103140,\"start\":103139},{\"end\":103157,\"start\":103153},{\"end\":103340,\"start\":103332},{\"end\":103355,\"start\":103348}]", "bib_author_last_name": "[{\"end\":77228,\"start\":77215},{\"end\":77242,\"start\":77236},{\"end\":77258,\"start\":77252},{\"end\":77276,\"start\":77269},{\"end\":77635,\"start\":77622},{\"end\":77653,\"start\":77646},{\"end\":77667,\"start\":77661},{\"end\":77825,\"start\":77812},{\"end\":77843,\"start\":77836},{\"end\":77857,\"start\":77851},{\"end\":77991,\"start\":77980},{\"end\":78005,\"start\":78000},{\"end\":78309,\"start\":78305},{\"end\":78321,\"start\":78317},{\"end\":78341,\"start\":78333},{\"end\":78352,\"start\":78348},{\"end\":78468,\"start\":78464},{\"end\":78481,\"start\":78478},{\"end\":78501,\"start\":78489},{\"end\":78797,\"start\":78790},{\"end\":78812,\"start\":78805},{\"end\":78822,\"start\":78817},{\"end\":78838,\"start\":78829},{\"end\":78854,\"start\":78847},{\"end\":79166,\"start\":79161},{\"end\":79181,\"start\":79177},{\"end\":79193,\"start\":79188},{\"end\":79210,\"start\":79203},{\"end\":79226,\"start\":79220},{\"end\":79245,\"start\":79237},{\"end\":79265,\"start\":79254},{\"end\":79279,\"start\":79274},{\"end\":79294,\"start\":79288},{\"end\":79309,\"start\":79303},{\"end\":79513,\"start\":79506},{\"end\":79534,\"start\":79522},{\"end\":79550,\"start\":79543},{\"end\":79693,\"start\":79690},{\"end\":79703,\"start\":79699},{\"end\":79718,\"start\":79712},{\"end\":80072,\"start\":80066},{\"end\":80086,\"start\":80081},{\"end\":80103,\"start\":80096},{\"end\":80117,\"start\":80111},{\"end\":80131,\"start\":80126},{\"end\":80147,\"start\":80141},{\"end\":80163,\"start\":80156},{\"end\":80180,\"start\":80172},{\"end\":80504,\"start\":80499},{\"end\":80517,\"start\":80512},{\"end\":80528,\"start\":80525},{\"end\":80629,\"start\":80617},{\"end\":80646,\"start\":80641},{\"end\":80658,\"start\":80650},{\"end\":80838,\"start\":80834},{\"end\":80846,\"start\":80844},{\"end\":80860,\"start\":80856},{\"end\":80874,\"start\":80871},{\"end\":80882,\"start\":80880},{\"end\":80896,\"start\":80892},{\"end\":81110,\"start\":81104},{\"end\":81122,\"start\":81120},{\"end\":81130,\"start\":81127},{\"end\":81142,\"start\":81137},{\"end\":81155,\"start\":81153},{\"end\":81166,\"start\":81161},{\"end\":81181,\"start\":81176},{\"end\":81196,\"start\":81190},{\"end\":81212,\"start\":81206},{\"end\":81231,\"start\":81223},{\"end\":81439,\"start\":81432},{\"end\":81451,\"start\":81446},{\"end\":81829,\"start\":81814},{\"end\":81851,\"start\":81838},{\"end\":81864,\"start\":81859},{\"end\":81951,\"start\":81946},{\"end\":81975,\"start\":81960},{\"end\":81996,\"start\":81983},{\"end\":82003,\"start\":81998},{\"end\":82294,\"start\":82287},{\"end\":82313,\"start\":82304},{\"end\":82328,\"start\":82321},{\"end\":82344,\"start\":82342},{\"end\":82722,\"start\":82718},{\"end\":82733,\"start\":82731},{\"end\":82755,\"start\":82741},{\"end\":82767,\"start\":82764},{\"end\":82779,\"start\":82773},{\"end\":83134,\"start\":83131},{\"end\":83150,\"start\":83144},{\"end\":83173,\"start\":83156},{\"end\":83187,\"start\":83182},{\"end\":83199,\"start\":83195},{\"end\":83538,\"start\":83534},{\"end\":83639,\"start\":83637},{\"end\":83653,\"start\":83647},{\"end\":83666,\"start\":83661},{\"end\":83677,\"start\":83674},{\"end\":83690,\"start\":83687},{\"end\":83706,\"start\":83701},{\"end\":83712,\"start\":83708},{\"end\":84088,\"start\":84081},{\"end\":84103,\"start\":84097},{\"end\":84119,\"start\":84111},{\"end\":84136,\"start\":84128},{\"end\":84147,\"start\":84144},{\"end\":84166,\"start\":84158},{\"end\":84337,\"start\":84328},{\"end\":84357,\"start\":84349},{\"end\":84373,\"start\":84365},{\"end\":84388,\"start\":84382},{\"end\":84403,\"start\":84397},{\"end\":84427,\"start\":84418},{\"end\":84718,\"start\":84711},{\"end\":84987,\"start\":84980},{\"end\":85002,\"start\":84996},{\"end\":85189,\"start\":85184},{\"end\":85207,\"start\":85205},{\"end\":85221,\"start\":85214},{\"end\":85378,\"start\":85369},{\"end\":85392,\"start\":85385},{\"end\":85414,\"start\":85409},{\"end\":85428,\"start\":85424},{\"end\":85439,\"start\":85432},{\"end\":85454,\"start\":85448},{\"end\":85467,\"start\":85461},{\"end\":85473,\"start\":85469},{\"end\":85588,\"start\":85579},{\"end\":85604,\"start\":85595},{\"end\":85617,\"start\":85612},{\"end\":85624,\"start\":85619},{\"end\":86103,\"start\":86095},{\"end\":86112,\"start\":86109},{\"end\":86120,\"start\":86118},{\"end\":86284,\"start\":86278},{\"end\":86296,\"start\":86292},{\"end\":86372,\"start\":86370},{\"end\":86384,\"start\":86381},{\"end\":86398,\"start\":86391},{\"end\":86411,\"start\":86409},{\"end\":86419,\"start\":86417},{\"end\":86427,\"start\":86425},{\"end\":86441,\"start\":86436},{\"end\":86456,\"start\":86452},{\"end\":86472,\"start\":86465},{\"end\":86486,\"start\":86482},{\"end\":86605,\"start\":86600},{\"end\":86622,\"start\":86615},{\"end\":86633,\"start\":86630},{\"end\":86645,\"start\":86640},{\"end\":86653,\"start\":86651},{\"end\":86960,\"start\":86955},{\"end\":86976,\"start\":86972},{\"end\":86990,\"start\":86986},{\"end\":87276,\"start\":87270},{\"end\":87293,\"start\":87286},{\"end\":87307,\"start\":87302},{\"end\":87319,\"start\":87311},{\"end\":87335,\"start\":87325},{\"end\":87347,\"start\":87345},{\"end\":87368,\"start\":87361},{\"end\":87372,\"start\":87370},{\"end\":87528,\"start\":87516},{\"end\":87562,\"start\":87558},{\"end\":87583,\"start\":87573},{\"end\":87605,\"start\":87591},{\"end\":87785,\"start\":87780},{\"end\":87795,\"start\":87792},{\"end\":87809,\"start\":87804},{\"end\":87826,\"start\":87816},{\"end\":88156,\"start\":88151},{\"end\":88173,\"start\":88165},{\"end\":88187,\"start\":88180},{\"end\":88203,\"start\":88197},{\"end\":88678,\"start\":88675},{\"end\":88690,\"start\":88685},{\"end\":88698,\"start\":88696},{\"end\":89230,\"start\":89224},{\"end\":89246,\"start\":89237},{\"end\":89266,\"start\":89257},{\"end\":89380,\"start\":89370},{\"end\":89394,\"start\":89388},{\"end\":89532,\"start\":89525},{\"end\":89556,\"start\":89543},{\"end\":89564,\"start\":89562},{\"end\":89999,\"start\":89992},{\"end\":90008,\"start\":90005},{\"end\":90024,\"start\":90016},{\"end\":90032,\"start\":90030},{\"end\":90350,\"start\":90344},{\"end\":90688,\"start\":90682},{\"end\":90700,\"start\":90697},{\"end\":91027,\"start\":91021},{\"end\":91043,\"start\":91036},{\"end\":91057,\"start\":91051},{\"end\":91072,\"start\":91064},{\"end\":91378,\"start\":91371},{\"end\":91394,\"start\":91385},{\"end\":91406,\"start\":91400},{\"end\":91783,\"start\":91777},{\"end\":91799,\"start\":91793},{\"end\":91816,\"start\":91809},{\"end\":92286,\"start\":92280},{\"end\":92295,\"start\":92293},{\"end\":92305,\"start\":92300},{\"end\":92320,\"start\":92313},{\"end\":92342,\"start\":92332},{\"end\":92358,\"start\":92351},{\"end\":92371,\"start\":92366},{\"end\":92389,\"start\":92382},{\"end\":92405,\"start\":92400},{\"end\":92415,\"start\":92412},{\"end\":92513,\"start\":92505},{\"end\":92527,\"start\":92521},{\"end\":92814,\"start\":92807},{\"end\":92837,\"start\":92825},{\"end\":92853,\"start\":92845},{\"end\":93292,\"start\":93284},{\"end\":93306,\"start\":93300},{\"end\":93317,\"start\":93313},{\"end\":93331,\"start\":93328},{\"end\":93645,\"start\":93638},{\"end\":93662,\"start\":93651},{\"end\":93680,\"start\":93674},{\"end\":93695,\"start\":93690},{\"end\":93710,\"start\":93703},{\"end\":93722,\"start\":93720},{\"end\":93740,\"start\":93734},{\"end\":94223,\"start\":94218},{\"end\":94231,\"start\":94229},{\"end\":94239,\"start\":94236},{\"end\":94252,\"start\":94248},{\"end\":94264,\"start\":94262},{\"end\":94478,\"start\":94472},{\"end\":94492,\"start\":94485},{\"end\":94506,\"start\":94499},{\"end\":94521,\"start\":94518},{\"end\":94536,\"start\":94530},{\"end\":94552,\"start\":94546},{\"end\":94564,\"start\":94560},{\"end\":94572,\"start\":94570},{\"end\":94585,\"start\":94582},{\"end\":94695,\"start\":94686},{\"end\":94706,\"start\":94703},{\"end\":94719,\"start\":94714},{\"end\":95039,\"start\":95036},{\"end\":95054,\"start\":95047},{\"end\":95069,\"start\":95062},{\"end\":95081,\"start\":95076},{\"end\":95434,\"start\":95431},{\"end\":95450,\"start\":95443},{\"end\":95458,\"start\":95454},{\"end\":95479,\"start\":95470},{\"end\":95492,\"start\":95487},{\"end\":95511,\"start\":95504},{\"end\":95519,\"start\":95513},{\"end\":95529,\"start\":95525},{\"end\":95547,\"start\":95539},{\"end\":95565,\"start\":95556},{\"end\":95578,\"start\":95573},{\"end\":95591,\"start\":95585},{\"end\":95598,\"start\":95593},{\"end\":95609,\"start\":95604},{\"end\":95618,\"start\":95611},{\"end\":95907,\"start\":95903},{\"end\":95920,\"start\":95915},{\"end\":95928,\"start\":95926},{\"end\":96214,\"start\":96207},{\"end\":96239,\"start\":96224},{\"end\":96253,\"start\":96246},{\"end\":96275,\"start\":96262},{\"end\":96289,\"start\":96283},{\"end\":96567,\"start\":96560},{\"end\":96577,\"start\":96573},{\"end\":96589,\"start\":96586},{\"end\":96601,\"start\":96599},{\"end\":97023,\"start\":97012},{\"end\":97135,\"start\":97124},{\"end\":97261,\"start\":97254},{\"end\":97393,\"start\":97386},{\"end\":97662,\"start\":97655},{\"end\":97679,\"start\":97670},{\"end\":98053,\"start\":98048},{\"end\":98065,\"start\":98060},{\"end\":98080,\"start\":98071},{\"end\":98393,\"start\":98388},{\"end\":98405,\"start\":98400},{\"end\":98420,\"start\":98411},{\"end\":98882,\"start\":98877},{\"end\":98894,\"start\":98889},{\"end\":98909,\"start\":98900},{\"end\":99254,\"start\":99251},{\"end\":99265,\"start\":99260},{\"end\":99278,\"start\":99275},{\"end\":99637,\"start\":99634},{\"end\":99646,\"start\":99643},{\"end\":99659,\"start\":99656},{\"end\":99927,\"start\":99922},{\"end\":99945,\"start\":99936},{\"end\":99959,\"start\":99954},{\"end\":99972,\"start\":99966},{\"end\":99984,\"start\":99982},{\"end\":100001,\"start\":99993},{\"end\":100014,\"start\":100009},{\"end\":100037,\"start\":100028},{\"end\":100120,\"start\":100108},{\"end\":100136,\"start\":100130},{\"end\":100152,\"start\":100145},{\"end\":100173,\"start\":100165},{\"end\":100191,\"start\":100184},{\"end\":100209,\"start\":100202},{\"end\":100224,\"start\":100217},{\"end\":100236,\"start\":100231},{\"end\":100251,\"start\":100245},{\"end\":100258,\"start\":100253},{\"end\":100437,\"start\":100430},{\"end\":100455,\"start\":100444},{\"end\":100479,\"start\":100469},{\"end\":100497,\"start\":100490},{\"end\":100822,\"start\":100819},{\"end\":100836,\"start\":100833},{\"end\":100850,\"start\":100846},{\"end\":100863,\"start\":100858},{\"end\":100876,\"start\":100872},{\"end\":100888,\"start\":100884},{\"end\":100900,\"start\":100896},{\"end\":101253,\"start\":101249},{\"end\":101268,\"start\":101263},{\"end\":101284,\"start\":101278},{\"end\":101295,\"start\":101292},{\"end\":101309,\"start\":101304},{\"end\":101326,\"start\":101318},{\"end\":101347,\"start\":101337},{\"end\":101623,\"start\":101621},{\"end\":101633,\"start\":101631},{\"end\":101645,\"start\":101642},{\"end\":101658,\"start\":101653},{\"end\":101670,\"start\":101666},{\"end\":101694,\"start\":101683},{\"end\":101708,\"start\":101703},{\"end\":101724,\"start\":101715},{\"end\":101745,\"start\":101735},{\"end\":101935,\"start\":101933},{\"end\":101953,\"start\":101946},{\"end\":101968,\"start\":101961},{\"end\":101981,\"start\":101977},{\"end\":102003,\"start\":101989},{\"end\":102125,\"start\":102123},{\"end\":102138,\"start\":102132},{\"end\":102150,\"start\":102145},{\"end\":102166,\"start\":102158},{\"end\":102180,\"start\":102174},{\"end\":102416,\"start\":102407},{\"end\":102428,\"start\":102422},{\"end\":102444,\"start\":102437},{\"end\":102458,\"start\":102454},{\"end\":102703,\"start\":102698},{\"end\":102719,\"start\":102714},{\"end\":102732,\"start\":102729},{\"end\":102760,\"start\":102742},{\"end\":102770,\"start\":102766},{\"end\":102785,\"start\":102780},{\"end\":102799,\"start\":102795},{\"end\":102815,\"start\":102808},{\"end\":102833,\"start\":102828},{\"end\":102848,\"start\":102842},{\"end\":102859,\"start\":102850},{\"end\":102870,\"start\":102865},{\"end\":102885,\"start\":102878},{\"end\":102893,\"start\":102887},{\"end\":103104,\"start\":103099},{\"end\":103120,\"start\":103113},{\"end\":103130,\"start\":103128},{\"end\":103151,\"start\":103141},{\"end\":103163,\"start\":103158},{\"end\":103346,\"start\":103341},{\"end\":103362,\"start\":103356}]", "bib_entry": "[{\"attributes\":{\"doi\":\"10.18653/v1/2020.acl-main.424\",\"id\":\"b0\",\"matched_paper_id\":218470237},\"end\":77552,\"start\":77088},{\"attributes\":{\"doi\":\"10.1162/coli_a_00370\",\"id\":\"b1\",\"matched_paper_id\":209536754},\"end\":77724,\"start\":77554},{\"attributes\":{\"doi\":\"10.1162/coli_a_00418\",\"id\":\"b2\",\"matched_paper_id\":237235785},\"end\":77913,\"start\":77726},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":208617785},\"end\":78196,\"start\":77915},{\"attributes\":{\"doi\":\"arXiv:2302.09155\",\"id\":\"b4\"},\"end\":78388,\"start\":78198},{\"attributes\":{\"doi\":\"10.18653/v1/W18-6457\",\"id\":\"b5\",\"matched_paper_id\":53244581},\"end\":78728,\"start\":78390},{\"attributes\":{\"doi\":\"10.18653/v1/2021.gem-1.6\",\"id\":\"b6\",\"matched_paper_id\":235376799},\"end\":79116,\"start\":78730},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":218971783},\"end\":79368,\"start\":79118},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":247254435},\"end\":79583,\"start\":79370},{\"attributes\":{\"doi\":\"10.18653/v1/2022.acl-long.236\",\"id\":\"b9\",\"matched_paper_id\":244909449},\"end\":79984,\"start\":79585},{\"attributes\":{\"doi\":\"10.18653/v1/2022.emnlp-main.121\",\"id\":\"b10\",\"matched_paper_id\":256460886},\"end\":80448,\"start\":79986},{\"attributes\":{\"doi\":\"arXiv:2209.00557\",\"id\":\"b11\"},\"end\":80564,\"start\":80450},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":2935285},\"end\":80740,\"start\":80566},{\"attributes\":{\"doi\":\"10.1609/aaai.v37i11.26485\",\"id\":\"b13\",\"matched_paper_id\":253761156},\"end\":81094,\"start\":80742},{\"attributes\":{\"id\":\"b14\"},\"end\":81343,\"start\":81096},{\"attributes\":{\"doi\":\"10.18653/v1/P18-1059\",\"id\":\"b15\",\"matched_paper_id\":13750296},\"end\":81713,\"start\":81345},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":238207314},\"end\":81884,\"start\":81715},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":243891435},\"end\":82232,\"start\":81886},{\"attributes\":{\"doi\":\"10.18653/v1/2022.acl-long.506\",\"id\":\"b18\",\"matched_paper_id\":248218448},\"end\":82610,\"start\":82234},{\"attributes\":{\"doi\":\"10.18653/v1/P19-1331\",\"id\":\"b19\",\"matched_paper_id\":195068920},\"end\":83022,\"start\":82612},{\"attributes\":{\"doi\":\"10.18653/v1/2022.acl-long.501\",\"id\":\"b20\",\"matched_paper_id\":247315430},\"end\":83464,\"start\":83024},{\"attributes\":{\"id\":\"b21\"},\"end\":83571,\"start\":83466},{\"attributes\":{\"doi\":\"10.18653/v1/2022.acl-long.250\",\"id\":\"b22\",\"matched_paper_id\":247315166},\"end\":83977,\"start\":83573},{\"attributes\":{\"doi\":\"10.1162/tacl_a_00437\",\"id\":\"b23\",\"matched_paper_id\":233444275},\"end\":84256,\"start\":83979},{\"attributes\":{\"doi\":\"10.18653/v1/2022.nllp-1.28\",\"id\":\"b24\",\"matched_paper_id\":256461063},\"end\":84650,\"start\":84258},{\"attributes\":{\"doi\":\"10.18653/v1/2022.slpat-1.7\",\"id\":\"b25\",\"matched_paper_id\":248266411},\"end\":84896,\"start\":84652},{\"attributes\":{\"doi\":\"10.18653/v1/2022.findings-naacl.27\",\"id\":\"b26\",\"matched_paper_id\":248524891},\"end\":85176,\"start\":84898},{\"attributes\":{\"doi\":\"arXiv:2209.12356\",\"id\":\"b27\"},\"end\":85312,\"start\":85178},{\"attributes\":{\"doi\":\"ArXiv, abs/2305.15717\",\"id\":\"b28\"},\"end\":85500,\"start\":85314},{\"attributes\":{\"doi\":\"10.18653/v1/N19-1169\",\"id\":\"b29\",\"matched_paper_id\":102351981},\"end\":85997,\"start\":85502},{\"attributes\":{\"doi\":\"arXiv:2308.06953\",\"id\":\"b30\"},\"end\":86156,\"start\":85999},{\"attributes\":{\"id\":\"b31\"},\"end\":86306,\"start\":86158},{\"attributes\":{\"doi\":\"10.1145/3571730\",\"id\":\"b32\",\"matched_paper_id\":246652372},\"end\":86529,\"start\":86308},{\"attributes\":{\"doi\":\"10.18653/v1/2020.acl-main.709\",\"id\":\"b33\",\"matched_paper_id\":216557637},\"end\":86890,\"start\":86531},{\"attributes\":{\"doi\":\"10.18653/v1/2022.emnlp-main.757\",\"id\":\"b34\",\"matched_paper_id\":256460931},\"end\":87258,\"start\":86892},{\"attributes\":{\"doi\":\"arXiv:2305.12532\",\"id\":\"b35\"},\"end\":87454,\"start\":87260},{\"attributes\":{\"id\":\"b36\"},\"end\":87551,\"start\":87456},{\"attributes\":{\"doi\":\"arXiv:2012.12382\",\"id\":\"b37\"},\"end\":87713,\"start\":87553},{\"attributes\":{\"doi\":\"10.18653/v1/2020.acl-main.707\",\"id\":\"b38\",\"matched_paper_id\":219720870},\"end\":88071,\"start\":87715},{\"attributes\":{\"doi\":\"10.18653/v1/2021.acl-long.498\",\"id\":\"b39\",\"matched_paper_id\":234688073},\"end\":88612,\"start\":88073},{\"attributes\":{\"doi\":\"10.18653/v1/2021.acl-long.531\",\"id\":\"b40\",\"matched_paper_id\":235352798},\"end\":89107,\"start\":88614},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":55606096},\"end\":89324,\"start\":89109},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":53592270},\"end\":89454,\"start\":89326},{\"attributes\":{\"doi\":\"10.18653/v1/2021.naacl-main.277\",\"id\":\"b43\",\"matched_paper_id\":224817815},\"end\":89921,\"start\":89456},{\"attributes\":{\"doi\":\"10.18653/v1/2023.acl-long.905\",\"id\":\"b44\",\"matched_paper_id\":254854257},\"end\":90298,\"start\":89923},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":203836056},\"end\":90595,\"start\":90300},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":250164478},\"end\":90951,\"start\":90597},{\"attributes\":{\"doi\":\"10.18653/v1/2020.acl-main.173\",\"id\":\"b47\",\"matched_paper_id\":218487034},\"end\":91309,\"start\":90953},{\"attributes\":{\"doi\":\"10.18653/v1/2020.emnlp-main.170\",\"id\":\"b48\",\"matched_paper_id\":222141794},\"end\":91667,\"start\":91311},{\"attributes\":{\"doi\":\"10.18653/v1/2020.emnlp-main.41\",\"id\":\"b49\",\"matched_paper_id\":216915063},\"end\":92076,\"start\":91669},{\"attributes\":{\"id\":\"b50\"},\"end\":92138,\"start\":92078},{\"attributes\":{\"doi\":\"arXiv:2303.08774\",\"id\":\"b51\"},\"end\":92204,\"start\":92140},{\"attributes\":{\"doi\":\"arXiv:2203.02155\",\"id\":\"b52\"},\"end\":92451,\"start\":92206},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":17335786},\"end\":92694,\"start\":92453},{\"attributes\":{\"doi\":\"10.18653/v1/2021.naacl-main.383\",\"id\":\"b54\",\"matched_paper_id\":233407441},\"end\":93210,\"start\":92696},{\"attributes\":{\"doi\":\"10.3115/1073083.1073135\",\"id\":\"b55\",\"matched_paper_id\":11080756},\"end\":93593,\"start\":93212},{\"attributes\":{\"doi\":\"10.18653/v1/D19-1250\",\"id\":\"b56\",\"matched_paper_id\":202539551},\"end\":94160,\"start\":93595},{\"attributes\":{\"id\":\"b57\",\"matched_paper_id\":213066785},\"end\":94381,\"start\":94162},{\"attributes\":{\"id\":\"b58\",\"matched_paper_id\":204838007},\"end\":94617,\"start\":94383},{\"attributes\":{\"doi\":\"10.18653/v1/P18-2124\",\"id\":\"b59\",\"matched_paper_id\":47018994},\"end\":94981,\"start\":94619},{\"attributes\":{\"doi\":\"10.18653/v1/2020.emnlp-main.213\",\"id\":\"b60\",\"matched_paper_id\":221819581},\"end\":95342,\"start\":94983},{\"attributes\":{\"id\":\"b61\",\"matched_paper_id\":252222165},\"end\":95815,\"start\":95344},{\"attributes\":{\"doi\":\"10.18653/v1/2023.acl-long.269\",\"id\":\"b62\",\"matched_paper_id\":258887622},\"end\":96194,\"start\":95817},{\"attributes\":{\"id\":\"b63\"},\"end\":96291,\"start\":96196},{\"attributes\":{\"id\":\"b64\",\"matched_paper_id\":8687826},\"end\":96493,\"start\":96293},{\"attributes\":{\"doi\":\"10.18653/v1/2021.naacl-main.295\",\"id\":\"b65\",\"matched_paper_id\":233307331},\"end\":96958,\"start\":96495},{\"attributes\":{\"id\":\"b66\",\"matched_paper_id\":14619244},\"end\":97069,\"start\":96960},{\"attributes\":{\"id\":\"b67\",\"matched_paper_id\":3894107},\"end\":97195,\"start\":97071},{\"attributes\":{\"id\":\"b68\"},\"end\":97306,\"start\":97197},{\"attributes\":{\"doi\":\"10.18653/v1/2021.findings-acl.233\",\"id\":\"b69\",\"matched_paper_id\":236478182},\"end\":97557,\"start\":97308},{\"attributes\":{\"doi\":\"10.18653/v1/2022.acl-demo.14\",\"id\":\"b70\",\"matched_paper_id\":248779989},\"end\":97976,\"start\":97559},{\"attributes\":{\"doi\":\"10.18653/v1/D18-1081\",\"id\":\"b71\",\"matched_paper_id\":53079743},\"end\":98324,\"start\":97978},{\"attributes\":{\"doi\":\"10.18653/v1/N18-1063\",\"id\":\"b72\",\"matched_paper_id\":44151916},\"end\":98793,\"start\":98326},{\"attributes\":{\"doi\":\"10.18653/v1/P18-1016\",\"id\":\"b73\",\"matched_paper_id\":51873719},\"end\":99172,\"start\":98795},{\"attributes\":{\"doi\":\"10.18653/v1/2021.emnlp-main.630\",\"id\":\"b74\",\"matched_paper_id\":238583063},\"end\":99556,\"start\":99174},{\"attributes\":{\"doi\":\"10.18653/v1/2020.coling-main.121\",\"id\":\"b75\",\"matched_paper_id\":227230427},\"end\":99914,\"start\":99558},{\"attributes\":{\"id\":\"b76\"},\"end\":100098,\"start\":99916},{\"attributes\":{\"doi\":\"arXiv:2302.13971\",\"id\":\"b77\"},\"end\":100348,\"start\":100100},{\"attributes\":{\"doi\":\"10.18653/v1/2022.tsar-1.3\",\"id\":\"b78\",\"matched_paper_id\":256461059},\"end\":100775,\"start\":100350},{\"attributes\":{\"doi\":\"10.18653/v1/2022.acl-long.558\",\"id\":\"b79\",\"matched_paper_id\":248426845},\"end\":101165,\"start\":100777},{\"attributes\":{\"doi\":\"10.18653/v1/2023.acl-long.754\",\"id\":\"b80\",\"matched_paper_id\":254877310},\"end\":101613,\"start\":101167},{\"attributes\":{\"doi\":\"arXiv:2306.01693\",\"id\":\"b81\"},\"end\":101859,\"start\":101615},{\"attributes\":{\"doi\":\"10.1162/tacl_a_00107\",\"id\":\"b82\",\"matched_paper_id\":2177849},\"end\":102093,\"start\":101861},{\"attributes\":{\"id\":\"b83\",\"matched_paper_id\":13050210},\"end\":102265,\"start\":102095},{\"attributes\":{\"doi\":\"10.18653/v1/2023.findings-eacl.27\",\"id\":\"b84\",\"matched_paper_id\":258378361},\"end\":102626,\"start\":102267},{\"attributes\":{\"id\":\"b85\",\"matched_paper_id\":256461325},\"end\":103090,\"start\":102628},{\"attributes\":{\"id\":\"b86\"},\"end\":103272,\"start\":103092},{\"attributes\":{\"doi\":\"10.18653/v1/D17-1062\",\"id\":\"b87\",\"matched_paper_id\":7473831},\"end\":103607,\"start\":103274}]", "bib_title": "[{\"end\":77204,\"start\":77088},{\"end\":77611,\"start\":77554},{\"end\":77801,\"start\":77726},{\"end\":77972,\"start\":77915},{\"end\":78452,\"start\":78390},{\"end\":78777,\"start\":78730},{\"end\":79155,\"start\":79118},{\"end\":79494,\"start\":79370},{\"end\":79683,\"start\":79585},{\"end\":80059,\"start\":79986},{\"end\":80613,\"start\":80566},{\"end\":80823,\"start\":80742},{\"end\":81423,\"start\":81345},{\"end\":81804,\"start\":81715},{\"end\":81942,\"start\":81886},{\"end\":82278,\"start\":82234},{\"end\":82712,\"start\":82612},{\"end\":83125,\"start\":83024},{\"end\":83629,\"start\":83573},{\"end\":84072,\"start\":83979},{\"end\":84319,\"start\":84258},{\"end\":84704,\"start\":84652},{\"end\":84973,\"start\":84898},{\"end\":85575,\"start\":85502},{\"end\":86362,\"start\":86308},{\"end\":86593,\"start\":86531},{\"end\":86944,\"start\":86892},{\"end\":87772,\"start\":87715},{\"end\":88140,\"start\":88073},{\"end\":88667,\"start\":88614},{\"end\":89217,\"start\":89109},{\"end\":89363,\"start\":89326},{\"end\":89515,\"start\":89456},{\"end\":89982,\"start\":89923},{\"end\":90336,\"start\":90300},{\"end\":90674,\"start\":90597},{\"end\":91012,\"start\":90953},{\"end\":91363,\"start\":91311},{\"end\":91767,\"start\":91669},{\"end\":92493,\"start\":92453},{\"end\":92796,\"start\":92696},{\"end\":93274,\"start\":93212},{\"end\":93630,\"start\":93595},{\"end\":94209,\"start\":94162},{\"end\":94464,\"start\":94383},{\"end\":94677,\"start\":94619},{\"end\":95026,\"start\":94983},{\"end\":95421,\"start\":95344},{\"end\":95893,\"start\":95817},{\"end\":96344,\"start\":96293},{\"end\":96553,\"start\":96495},{\"end\":97002,\"start\":96960},{\"end\":97114,\"start\":97071},{\"end\":97378,\"start\":97308},{\"end\":97646,\"start\":97559},{\"end\":98040,\"start\":97978},{\"end\":98380,\"start\":98326},{\"end\":98869,\"start\":98795},{\"end\":99240,\"start\":99174},{\"end\":99623,\"start\":99558},{\"end\":100424,\"start\":100350},{\"end\":100814,\"start\":100777},{\"end\":101239,\"start\":101167},{\"end\":101927,\"start\":101861},{\"end\":102117,\"start\":102095},{\"end\":102398,\"start\":102267},{\"end\":102686,\"start\":102628},{\"end\":103330,\"start\":103274}]", "bib_author": "[{\"end\":77230,\"start\":77206},{\"end\":77244,\"start\":77230},{\"end\":77260,\"start\":77244},{\"end\":77278,\"start\":77260},{\"end\":77637,\"start\":77613},{\"end\":77655,\"start\":77637},{\"end\":77669,\"start\":77655},{\"end\":77827,\"start\":77803},{\"end\":77845,\"start\":77827},{\"end\":77859,\"start\":77845},{\"end\":77993,\"start\":77974},{\"end\":78007,\"start\":77993},{\"end\":78311,\"start\":78294},{\"end\":78323,\"start\":78311},{\"end\":78343,\"start\":78323},{\"end\":78354,\"start\":78343},{\"end\":78470,\"start\":78454},{\"end\":78483,\"start\":78470},{\"end\":78503,\"start\":78483},{\"end\":78799,\"start\":78779},{\"end\":78814,\"start\":78799},{\"end\":78824,\"start\":78814},{\"end\":78840,\"start\":78824},{\"end\":78856,\"start\":78840},{\"end\":79168,\"start\":79157},{\"end\":79183,\"start\":79168},{\"end\":79195,\"start\":79183},{\"end\":79212,\"start\":79195},{\"end\":79228,\"start\":79212},{\"end\":79247,\"start\":79228},{\"end\":79267,\"start\":79247},{\"end\":79281,\"start\":79267},{\"end\":79296,\"start\":79281},{\"end\":79311,\"start\":79296},{\"end\":79515,\"start\":79496},{\"end\":79536,\"start\":79515},{\"end\":79552,\"start\":79536},{\"end\":79695,\"start\":79685},{\"end\":79705,\"start\":79695},{\"end\":79720,\"start\":79705},{\"end\":80074,\"start\":80061},{\"end\":80088,\"start\":80074},{\"end\":80105,\"start\":80088},{\"end\":80119,\"start\":80105},{\"end\":80133,\"start\":80119},{\"end\":80149,\"start\":80133},{\"end\":80165,\"start\":80149},{\"end\":80182,\"start\":80165},{\"end\":80506,\"start\":80494},{\"end\":80519,\"start\":80506},{\"end\":80530,\"start\":80519},{\"end\":80631,\"start\":80615},{\"end\":80648,\"start\":80631},{\"end\":80660,\"start\":80648},{\"end\":80840,\"start\":80825},{\"end\":80848,\"start\":80840},{\"end\":80862,\"start\":80848},{\"end\":80876,\"start\":80862},{\"end\":80884,\"start\":80876},{\"end\":80898,\"start\":80884},{\"end\":81112,\"start\":81096},{\"end\":81124,\"start\":81112},{\"end\":81132,\"start\":81124},{\"end\":81144,\"start\":81132},{\"end\":81157,\"start\":81144},{\"end\":81168,\"start\":81157},{\"end\":81183,\"start\":81168},{\"end\":81198,\"start\":81183},{\"end\":81214,\"start\":81198},{\"end\":81233,\"start\":81214},{\"end\":81441,\"start\":81425},{\"end\":81453,\"start\":81441},{\"end\":81831,\"start\":81806},{\"end\":81853,\"start\":81831},{\"end\":81866,\"start\":81853},{\"end\":81953,\"start\":81944},{\"end\":81977,\"start\":81953},{\"end\":81998,\"start\":81977},{\"end\":82005,\"start\":81998},{\"end\":82296,\"start\":82280},{\"end\":82315,\"start\":82296},{\"end\":82330,\"start\":82315},{\"end\":82346,\"start\":82330},{\"end\":82724,\"start\":82714},{\"end\":82735,\"start\":82724},{\"end\":82757,\"start\":82735},{\"end\":82769,\"start\":82757},{\"end\":82781,\"start\":82769},{\"end\":83136,\"start\":83127},{\"end\":83152,\"start\":83136},{\"end\":83175,\"start\":83152},{\"end\":83189,\"start\":83175},{\"end\":83201,\"start\":83189},{\"end\":83540,\"start\":83529},{\"end\":83641,\"start\":83631},{\"end\":83655,\"start\":83641},{\"end\":83668,\"start\":83655},{\"end\":83679,\"start\":83668},{\"end\":83692,\"start\":83679},{\"end\":83708,\"start\":83692},{\"end\":83714,\"start\":83708},{\"end\":84090,\"start\":84074},{\"end\":84105,\"start\":84090},{\"end\":84121,\"start\":84105},{\"end\":84138,\"start\":84121},{\"end\":84149,\"start\":84138},{\"end\":84168,\"start\":84149},{\"end\":84339,\"start\":84321},{\"end\":84359,\"start\":84339},{\"end\":84375,\"start\":84359},{\"end\":84390,\"start\":84375},{\"end\":84405,\"start\":84390},{\"end\":84429,\"start\":84405},{\"end\":84720,\"start\":84706},{\"end\":84989,\"start\":84975},{\"end\":85004,\"start\":84989},{\"end\":85191,\"start\":85178},{\"end\":85199,\"start\":85191},{\"end\":85209,\"start\":85199},{\"end\":85223,\"start\":85209},{\"end\":85380,\"start\":85363},{\"end\":85394,\"start\":85380},{\"end\":85416,\"start\":85394},{\"end\":85430,\"start\":85416},{\"end\":85441,\"start\":85430},{\"end\":85456,\"start\":85441},{\"end\":85469,\"start\":85456},{\"end\":85475,\"start\":85469},{\"end\":85590,\"start\":85577},{\"end\":85606,\"start\":85590},{\"end\":85619,\"start\":85606},{\"end\":85626,\"start\":85619},{\"end\":86105,\"start\":86089},{\"end\":86114,\"start\":86105},{\"end\":86122,\"start\":86114},{\"end\":86286,\"start\":86276},{\"end\":86298,\"start\":86286},{\"end\":86374,\"start\":86364},{\"end\":86386,\"start\":86374},{\"end\":86400,\"start\":86386},{\"end\":86413,\"start\":86400},{\"end\":86421,\"start\":86413},{\"end\":86429,\"start\":86421},{\"end\":86443,\"start\":86429},{\"end\":86448,\"start\":86443},{\"end\":86458,\"start\":86448},{\"end\":86474,\"start\":86458},{\"end\":86488,\"start\":86474},{\"end\":86607,\"start\":86595},{\"end\":86624,\"start\":86607},{\"end\":86635,\"start\":86624},{\"end\":86647,\"start\":86635},{\"end\":86655,\"start\":86647},{\"end\":86962,\"start\":86946},{\"end\":86978,\"start\":86962},{\"end\":86992,\"start\":86978},{\"end\":87278,\"start\":87260},{\"end\":87295,\"start\":87278},{\"end\":87309,\"start\":87295},{\"end\":87321,\"start\":87309},{\"end\":87337,\"start\":87321},{\"end\":87349,\"start\":87337},{\"end\":87370,\"start\":87349},{\"end\":87374,\"start\":87370},{\"end\":87530,\"start\":87510},{\"end\":87564,\"start\":87553},{\"end\":87585,\"start\":87564},{\"end\":87607,\"start\":87585},{\"end\":87787,\"start\":87774},{\"end\":87797,\"start\":87787},{\"end\":87811,\"start\":87797},{\"end\":87828,\"start\":87811},{\"end\":88158,\"start\":88142},{\"end\":88175,\"start\":88158},{\"end\":88189,\"start\":88175},{\"end\":88205,\"start\":88189},{\"end\":88680,\"start\":88669},{\"end\":88692,\"start\":88680},{\"end\":88700,\"start\":88692},{\"end\":89232,\"start\":89219},{\"end\":89248,\"start\":89232},{\"end\":89268,\"start\":89248},{\"end\":89382,\"start\":89365},{\"end\":89396,\"start\":89382},{\"end\":89534,\"start\":89517},{\"end\":89558,\"start\":89534},{\"end\":89566,\"start\":89558},{\"end\":90001,\"start\":89984},{\"end\":90010,\"start\":90001},{\"end\":90026,\"start\":90010},{\"end\":90034,\"start\":90026},{\"end\":90352,\"start\":90338},{\"end\":90690,\"start\":90676},{\"end\":90702,\"start\":90690},{\"end\":91029,\"start\":91014},{\"end\":91045,\"start\":91029},{\"end\":91059,\"start\":91045},{\"end\":91074,\"start\":91059},{\"end\":91380,\"start\":91365},{\"end\":91396,\"start\":91380},{\"end\":91408,\"start\":91396},{\"end\":91785,\"start\":91769},{\"end\":91801,\"start\":91785},{\"end\":91818,\"start\":91801},{\"end\":92288,\"start\":92275},{\"end\":92297,\"start\":92288},{\"end\":92307,\"start\":92297},{\"end\":92322,\"start\":92307},{\"end\":92344,\"start\":92322},{\"end\":92360,\"start\":92344},{\"end\":92373,\"start\":92360},{\"end\":92391,\"start\":92373},{\"end\":92407,\"start\":92391},{\"end\":92417,\"start\":92407},{\"end\":92515,\"start\":92495},{\"end\":92529,\"start\":92515},{\"end\":92816,\"start\":92798},{\"end\":92839,\"start\":92816},{\"end\":92855,\"start\":92839},{\"end\":93294,\"start\":93276},{\"end\":93308,\"start\":93294},{\"end\":93319,\"start\":93308},{\"end\":93333,\"start\":93319},{\"end\":93647,\"start\":93632},{\"end\":93664,\"start\":93647},{\"end\":93682,\"start\":93664},{\"end\":93697,\"start\":93682},{\"end\":93712,\"start\":93697},{\"end\":93724,\"start\":93712},{\"end\":93742,\"start\":93724},{\"end\":94225,\"start\":94211},{\"end\":94233,\"start\":94225},{\"end\":94241,\"start\":94233},{\"end\":94254,\"start\":94241},{\"end\":94266,\"start\":94254},{\"end\":94480,\"start\":94466},{\"end\":94494,\"start\":94480},{\"end\":94508,\"start\":94494},{\"end\":94523,\"start\":94508},{\"end\":94538,\"start\":94523},{\"end\":94554,\"start\":94538},{\"end\":94566,\"start\":94554},{\"end\":94574,\"start\":94566},{\"end\":94587,\"start\":94574},{\"end\":94697,\"start\":94679},{\"end\":94708,\"start\":94697},{\"end\":94721,\"start\":94708},{\"end\":95041,\"start\":95028},{\"end\":95056,\"start\":95041},{\"end\":95071,\"start\":95056},{\"end\":95083,\"start\":95071},{\"end\":95436,\"start\":95423},{\"end\":95452,\"start\":95436},{\"end\":95460,\"start\":95452},{\"end\":95481,\"start\":95460},{\"end\":95494,\"start\":95481},{\"end\":95513,\"start\":95494},{\"end\":95521,\"start\":95513},{\"end\":95531,\"start\":95521},{\"end\":95549,\"start\":95531},{\"end\":95567,\"start\":95549},{\"end\":95580,\"start\":95567},{\"end\":95593,\"start\":95580},{\"end\":95600,\"start\":95593},{\"end\":95611,\"start\":95600},{\"end\":95620,\"start\":95611},{\"end\":95909,\"start\":95895},{\"end\":95922,\"start\":95909},{\"end\":95930,\"start\":95922},{\"end\":96216,\"start\":96198},{\"end\":96241,\"start\":96216},{\"end\":96255,\"start\":96241},{\"end\":96277,\"start\":96255},{\"end\":96291,\"start\":96277},{\"end\":96569,\"start\":96555},{\"end\":96579,\"start\":96569},{\"end\":96591,\"start\":96579},{\"end\":96603,\"start\":96591},{\"end\":97025,\"start\":97004},{\"end\":97137,\"start\":97116},{\"end\":97263,\"start\":97248},{\"end\":97395,\"start\":97380},{\"end\":97664,\"start\":97648},{\"end\":97681,\"start\":97664},{\"end\":98055,\"start\":98042},{\"end\":98067,\"start\":98055},{\"end\":98082,\"start\":98067},{\"end\":98395,\"start\":98382},{\"end\":98407,\"start\":98395},{\"end\":98422,\"start\":98407},{\"end\":98884,\"start\":98871},{\"end\":98896,\"start\":98884},{\"end\":98911,\"start\":98896},{\"end\":99256,\"start\":99242},{\"end\":99267,\"start\":99256},{\"end\":99280,\"start\":99267},{\"end\":99639,\"start\":99625},{\"end\":99648,\"start\":99639},{\"end\":99661,\"start\":99648},{\"end\":99929,\"start\":99916},{\"end\":99947,\"start\":99929},{\"end\":99961,\"start\":99947},{\"end\":99974,\"start\":99961},{\"end\":99986,\"start\":99974},{\"end\":100003,\"start\":99986},{\"end\":100016,\"start\":100003},{\"end\":100039,\"start\":100016},{\"end\":100122,\"start\":100100},{\"end\":100138,\"start\":100122},{\"end\":100154,\"start\":100138},{\"end\":100175,\"start\":100154},{\"end\":100193,\"start\":100175},{\"end\":100211,\"start\":100193},{\"end\":100226,\"start\":100211},{\"end\":100238,\"start\":100226},{\"end\":100253,\"start\":100238},{\"end\":100260,\"start\":100253},{\"end\":100439,\"start\":100426},{\"end\":100457,\"start\":100439},{\"end\":100481,\"start\":100457},{\"end\":100499,\"start\":100481},{\"end\":100824,\"start\":100816},{\"end\":100838,\"start\":100824},{\"end\":100852,\"start\":100838},{\"end\":100865,\"start\":100852},{\"end\":100878,\"start\":100865},{\"end\":100890,\"start\":100878},{\"end\":100902,\"start\":100890},{\"end\":101255,\"start\":101241},{\"end\":101270,\"start\":101255},{\"end\":101286,\"start\":101270},{\"end\":101297,\"start\":101286},{\"end\":101311,\"start\":101297},{\"end\":101328,\"start\":101311},{\"end\":101349,\"start\":101328},{\"end\":101625,\"start\":101615},{\"end\":101635,\"start\":101625},{\"end\":101647,\"start\":101635},{\"end\":101660,\"start\":101647},{\"end\":101672,\"start\":101660},{\"end\":101696,\"start\":101672},{\"end\":101710,\"start\":101696},{\"end\":101726,\"start\":101710},{\"end\":101747,\"start\":101726},{\"end\":101937,\"start\":101929},{\"end\":101955,\"start\":101937},{\"end\":101970,\"start\":101955},{\"end\":101983,\"start\":101970},{\"end\":102005,\"start\":101983},{\"end\":102127,\"start\":102119},{\"end\":102140,\"start\":102127},{\"end\":102152,\"start\":102140},{\"end\":102168,\"start\":102152},{\"end\":102182,\"start\":102168},{\"end\":102418,\"start\":102400},{\"end\":102430,\"start\":102418},{\"end\":102446,\"start\":102430},{\"end\":102460,\"start\":102446},{\"end\":102705,\"start\":102688},{\"end\":102721,\"start\":102705},{\"end\":102734,\"start\":102721},{\"end\":102762,\"start\":102734},{\"end\":102772,\"start\":102762},{\"end\":102787,\"start\":102772},{\"end\":102801,\"start\":102787},{\"end\":102817,\"start\":102801},{\"end\":102835,\"start\":102817},{\"end\":102850,\"start\":102835},{\"end\":102861,\"start\":102850},{\"end\":102872,\"start\":102861},{\"end\":102887,\"start\":102872},{\"end\":102895,\"start\":102887},{\"end\":103106,\"start\":103092},{\"end\":103122,\"start\":103106},{\"end\":103132,\"start\":103122},{\"end\":103153,\"start\":103132},{\"end\":103165,\"start\":103153},{\"end\":103348,\"start\":103332},{\"end\":103364,\"start\":103348}]", "bib_venue": "[{\"end\":77468,\"start\":77396},{\"end\":78153,\"start\":78080},{\"end\":78683,\"start\":78603},{\"end\":79063,\"start\":78980},{\"end\":79938,\"start\":79851},{\"end\":80403,\"start\":80301},{\"end\":81080,\"start\":81010},{\"end\":81667,\"start\":81575},{\"end\":82204,\"start\":82113},{\"end\":82564,\"start\":82477},{\"end\":82977,\"start\":82890},{\"end\":83406,\"start\":83319},{\"end\":83932,\"start\":83845},{\"end\":84605,\"start\":84523},{\"end\":84851,\"start\":84836},{\"end\":85131,\"start\":85109},{\"end\":85951,\"start\":85813},{\"end\":86845,\"start\":86773},{\"end\":87213,\"start\":87111},{\"end\":88018,\"start\":87946},{\"end\":88558,\"start\":88411},{\"end\":89053,\"start\":88906},{\"end\":89868,\"start\":89741},{\"end\":90252,\"start\":90165},{\"end\":90498,\"start\":90425},{\"end\":90854,\"start\":90778},{\"end\":91264,\"start\":91192},{\"end\":91614,\"start\":91535},{\"end\":92023,\"start\":91944},{\"end\":92690,\"start\":92618},{\"end\":93157,\"start\":93030},{\"end\":93548,\"start\":93445},{\"end\":94115,\"start\":93939},{\"end\":94375,\"start\":94329},{\"end\":94922,\"start\":94830},{\"end\":95289,\"start\":95210},{\"end\":95770,\"start\":95688},{\"end\":96148,\"start\":96061},{\"end\":96452,\"start\":96401},{\"end\":96905,\"start\":96778},{\"end\":97931,\"start\":97821},{\"end\":98278,\"start\":98190},{\"end\":98735,\"start\":98599},{\"end\":99125,\"start\":99033},{\"end\":99470,\"start\":99399},{\"end\":99858,\"start\":99772},{\"end\":100730,\"start\":100620},{\"end\":101107,\"start\":101020},{\"end\":101567,\"start\":101480},{\"end\":102581,\"start\":102563},{\"end\":103045,\"start\":102963},{\"end\":103562,\"start\":103472},{\"end\":77394,\"start\":77307},{\"end\":77714,\"start\":77689},{\"end\":77904,\"start\":77879},{\"end\":78078,\"start\":78007},{\"end\":78292,\"start\":78198},{\"end\":78601,\"start\":78523},{\"end\":78978,\"start\":78880},{\"end\":79360,\"start\":79311},{\"end\":79575,\"start\":79552},{\"end\":79836,\"start\":79749},{\"end\":79849,\"start\":79838},{\"end\":80299,\"start\":80213},{\"end\":80492,\"start\":80450},{\"end\":80722,\"start\":80660},{\"end\":81008,\"start\":80923},{\"end\":81341,\"start\":81233},{\"end\":81560,\"start\":81473},{\"end\":81573,\"start\":81562},{\"end\":81877,\"start\":81866},{\"end\":82111,\"start\":82005},{\"end\":82462,\"start\":82375},{\"end\":82475,\"start\":82464},{\"end\":82888,\"start\":82801},{\"end\":83317,\"start\":83230},{\"end\":83527,\"start\":83466},{\"end\":83830,\"start\":83743},{\"end\":83843,\"start\":83832},{\"end\":84249,\"start\":84188},{\"end\":84521,\"start\":84455},{\"end\":84834,\"start\":84746},{\"end\":85107,\"start\":85038},{\"end\":85292,\"start\":85239},{\"end\":85361,\"start\":85314},{\"end\":85788,\"start\":85646},{\"end\":85811,\"start\":85790},{\"end\":86087,\"start\":85999},{\"end\":86274,\"start\":86158},{\"end\":86519,\"start\":86503},{\"end\":86771,\"start\":86684},{\"end\":87109,\"start\":87023},{\"end\":87434,\"start\":87390},{\"end\":87508,\"start\":87456},{\"end\":87693,\"start\":87623},{\"end\":87944,\"start\":87857},{\"end\":88396,\"start\":88234},{\"end\":88409,\"start\":88398},{\"end\":88891,\"start\":88729},{\"end\":88904,\"start\":88893},{\"end\":89316,\"start\":89268},{\"end\":89448,\"start\":89396},{\"end\":89739,\"start\":89597},{\"end\":90150,\"start\":90063},{\"end\":90163,\"start\":90152},{\"end\":90423,\"start\":90352},{\"end\":90776,\"start\":90702},{\"end\":91190,\"start\":91103},{\"end\":91533,\"start\":91439},{\"end\":91942,\"start\":91848},{\"end\":92126,\"start\":92078},{\"end\":92178,\"start\":92156},{\"end\":92273,\"start\":92206},{\"end\":92616,\"start\":92529},{\"end\":93028,\"start\":92886},{\"end\":93443,\"start\":93356},{\"end\":93937,\"start\":93762},{\"end\":94327,\"start\":94266},{\"end\":94606,\"start\":94587},{\"end\":94828,\"start\":94741},{\"end\":95208,\"start\":95114},{\"end\":95686,\"start\":95620},{\"end\":96046,\"start\":95959},{\"end\":96059,\"start\":96048},{\"end\":96399,\"start\":96346},{\"end\":96776,\"start\":96634},{\"end\":97061,\"start\":97025},{\"end\":97185,\"start\":97137},{\"end\":97246,\"start\":97197},{\"end\":97502,\"start\":97428},{\"end\":97819,\"start\":97709},{\"end\":98188,\"start\":98102},{\"end\":98584,\"start\":98442},{\"end\":98597,\"start\":98586},{\"end\":99018,\"start\":98931},{\"end\":99031,\"start\":99020},{\"end\":99397,\"start\":99311},{\"end\":99770,\"start\":99693},{\"end\":100092,\"start\":100039},{\"end\":100328,\"start\":100276},{\"end\":100618,\"start\":100524},{\"end\":101018,\"start\":100931},{\"end\":101465,\"start\":101378},{\"end\":101478,\"start\":101467},{\"end\":101839,\"start\":101763},{\"end\":102086,\"start\":102025},{\"end\":102233,\"start\":102182},{\"end\":102561,\"start\":102493},{\"end\":102961,\"start\":102895},{\"end\":103266,\"start\":103165},{\"end\":103470,\"start\":103384}]"}}}, "year": 2023, "month": 12, "day": 17}