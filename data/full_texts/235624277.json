{"id": 235624277, "updated": "2023-10-06 01:43:32.253", "metadata": {"title": "VinDr-SpineXR: A deep learning framework for spinal lesions detection and classification from radiographs", "authors": "[{\"first\":\"Hieu\",\"last\":\"Nguyen\",\"middle\":[\"T.\"]},{\"first\":\"Hieu\",\"last\":\"Pham\",\"middle\":[\"H.\"]},{\"first\":\"Nghia\",\"last\":\"Nguyen\",\"middle\":[\"T.\"]},{\"first\":\"Ha\",\"last\":\"Nguyen\",\"middle\":[\"Q.\"]},{\"first\":\"Thang\",\"last\":\"Huynh\",\"middle\":[\"Q.\"]},{\"first\":\"Minh\",\"last\":\"Dao\",\"middle\":[]},{\"first\":\"Van\",\"last\":\"Vu\",\"middle\":[]}]", "venue": "Medical Image Computing and Computer Assisted Intervention \u2013 MICCAI 2021", "journal": "Medical Image Computing and Computer Assisted Intervention \u2013 MICCAI 2021", "publication_date": {"year": 2021, "month": 6, "day": 24}, "abstract": "Radiographs are used as the most important imaging tool for identifying spine anomalies in clinical practice. The evaluation of spinal bone lesions, however, is a challenging task for radiologists. This work aims at developing and evaluating a deep learning-based framework, named VinDr-SpineXR, for the classification and localization of abnormalities from spine X-rays. First, we build a large dataset, comprising 10,468 spine X-ray images from 5,000 studies, each of which is manually annotated by an experienced radiologist with bounding boxes around abnormal findings in 13 categories. Using this dataset, we then train a deep learning classifier to determine whether a spine scan is abnormal and a detector to localize 7 crucial findings amongst the total 13. The VinDr-SpineXR is evaluated on a test set of 2,078 images from 1,000 studies, which is kept separate from the training set. It demonstrates an area under the receiver operating characteristic curve (AUROC) of 88.61% (95% CI 87.19%, 90.02%) for the image-level classification task and a mean average precision (mAP@0.5) of 33.56% for the lesion-level localization task. These results serve as a proof of concept and set a baseline for future research in this direction. To encourage advances, the dataset, codes, and trained deep learning models are made publicly available.", "fields_of_study": "[\"Engineering\",\"Computer Science\"]", "external_ids": {"arxiv": "2106.12930", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/miccai/NguyenPNNHDV21", "doi": "10.1007/978-3-030-87240-3_28"}}, "content": {"source": {"pdf_hash": "3f6371e41937f6385710a3ae4810a713b8acf82d", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2106.12930v1.pdf\"]", "oa_url_match": true, "oa_info": {"license": null, "open_access_url": "http://arxiv.org/pdf/2106.12930", "status": "GREEN"}}, "grobid": {"id": "d9d52a2dab024c8424bc9ba3375306bdcf3c9788", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/3f6371e41937f6385710a3ae4810a713b8acf82d.txt", "contents": "\nVinDr-SpineXR: A deep learning framework for spinal lesions detection and classification from radiographs\n\n\nHieu T Nguyen \nMedical Imaging Center\nVingroup Big Data Institute\nHanoiVietnam\n\nSchool of Information and Communication Technology\nHanoi University of Science and Technology\nHanoiVietnam\n\nHieu H Pham \nMedical Imaging Center\nVingroup Big Data Institute\nHanoiVietnam\n\nCollege of Engineering & Computer Science\nVinUniversity\nHanoiVietnam\n\nNghia T Nguyen \nHa Q Nguyen \nMedical Imaging Center\nVingroup Big Data Institute\nHanoiVietnam\n\nCollege of Engineering & Computer Science\nVinUniversity\nHanoiVietnam\n\nThang Q Huynh \nMedical Imaging Center\nVingroup Big Data Institute\nHanoiVietnam\n\nSchool of Information and Communication Technology\nHanoi University of Science and Technology\nHanoiVietnam\n\nMinh Dao \nMedical Imaging Center\nVingroup Big Data Institute\nHanoiVietnam\n\nVan Vu \nMedical Imaging Center\nVingroup Big Data Institute\nHanoiVietnam\n\nDepartment of Mathematics\nYale University\nNew HeavenUSA\n\nVinDr-SpineXR: A deep learning framework for spinal lesions detection and classification from radiographs\nAll correspondence should be addressed to Hieu H. Pham atSpine X-rays \u00b7 Classification \u00b7 Detection \u00b7 Deep learning\nRadiographs are used as the most important imaging tool for identifying spine anomalies in clinical practice. The evaluation of spinal bone lesions, however, is a challenging task for radiologists. This work aims at developing and evaluating a deep learning-based framework, named VinDr-SpineXR, for the classification and localization of abnormalities from spine X-rays. First, we build a large dataset, comprising 10,468 spine X-ray images from 5,000 studies, each of which is manually annotated by an experienced radiologist with bounding boxes around abnormal findings in 13 categories. Using this dataset, we then train a deep learning classifier to determine whether a spine scan is abnormal and a detector to localize 7 crucial findings amongst the total 13. The VinDr-SpineXR is evaluated on a test set of 2,078 images from 1,000 studies, which is kept separate from the training set. It demonstrates an area under the receiver operating characteristic curve (AUROC) of 88.61% (95% CI 87.19%, 90.02%) for the image-level classification task and a mean average precision (mAP@0.5) of 33.56% for the lesion-level localization task. These results serve as a proof of concept and set a baseline for future research in this direction. To encourage advances, the dataset, codes, and trained deep learning models are made publicly available.\n\nIntroduction\n\n\nSpine X-ray interpretation\n\nConventional radiography or X-ray has the ability to offer valuable information than many other imaging modalities in the assessment of spinal lesions [20,29]. It has been the primary tool widely used to identify and monitor various abnormalities of the spine. A wide range of spine conditions can be observed from the X-rays like fractures, osteophytes, thinning of the bones, vertebral collapse, or tumors [2,24]. In clinical practice, radiologists usually interpret and evaluate the spine on X-ray scans stored in Digital Imaging and Communications in Medicine (DICOM) standard. Abnormal findings could be identified based on differences in density, intensity, and geometry of the lesions in comparison with normal areas. In many cases, those differences might be subtle and it requires an in-depth understanding of diagnostic radiography to spot them out. Large variability in the number, size, and general appearance of spine lesions makes the interpretation of spinal X-rays a complex and time-consuming task. These factors could lead to the risk of missing significant findings [19], resulting in serious consequences for patients and clinicians.\n\nThe rapid advances in machine learning, especially deep neural networks, have demonstrated great potential in identifying diseases from medical imaging data [26]. The integration of such systems in daily clinical routines could lead to a much more efficient, accurate diagnosis and treatment [12]. In this study, we aim to develop and validate a deep learning-based computer-aided diagnosis (CAD) framework called VinDr-SpineXR that is able to classify and localize abnormal findings from spine X-rays. Both the training and validation of our proposed system are performed on our own dataset where radiologists' annotations serve as a strong ground truth.\n\n\nRelated work\n\nDeveloping CAD tools with a high clinical value to support radiologists in interpreting musculoskeletal (MSK) X-ray has been intensively studied in recent years [6]. Early approaches to the analysis of spine X-rays focus on using radiographic textures for the detection of several specific pathologies such as vertebral fractures [10], osteoporosis [9], or osteolysis [31]. Currently, deep convolutional networks [14] (CNNs) have shown their significant improvements for the MSK analysis from X-rays [11,16,17,21,25,30,33]. Most of these studies focus on automated fracture detection and localization [11,16,21,30,33]. To the best of our knowledge, no existing studies devoted to the development and evaluation of a comprehensive system for classifying and localizing multiple spine lesions from X-ray scans. The lack of large datasets with high-quality images and human experts' annotations is the key obstacle. To fill this gap, this work focuses on creating a significant benchmark dataset of spine X-rays that are manually annotated at the lesion level by experienced radiologists. We also propose to develop and evaluate, based on our dataset, a deep learning-based framework that includes a normal versus abnormal classifier followed by a lesion detector that localizes multiple categories of findings with bounding boxes. Both of these tasks can be beneficial in clinical practice: the normal versus abnormal classifier helps triage patients, while the lesion detector helps speed up the reading procedure and complements radiologist's observations.\n\n\nContribution\n\nOur contributions in this paper are two folds. First, we present a new largescale dataset of 10,469 spine X-ray images from 5,000 studies that are manually annotated with 13 types of abnormalities by radiologists. This is the largest dataset to date that provides radiologist's bounding-box annotations for developing supervised-learning object detection algorithms. Table 1 provides a summary of publicly available MSK datasets, in which two previous spine datasets [5,11] are significantly smaller than ours in size. Furthermore, human expert's annotations of spinal abnormalities are not available in those datasets. Second, we develop and evaluate VinDr-SpineXR -a deep learning framework that is able to classify and localize multiple spine lesions. Our main goal is to provide a nontrivial baseline performance of state-of-the-art deep learning approaches on the released dataset, which could be useful for further model development and comparison of novel CAD tools. To facilitate new advances, we have made the dataset available for public access on our project's webpage 5 . The codes used in the experiments are available at Github 6 . \n\n\nDataset\n\nYear Study type Label # Im. Digital Hand Atlas [5] 2007 Left hand Bone age 1,390 Osteoarthritis Initiative [1] 2013 Knee K&L Grade 8,892 MURA [21] 2017 Upper body Abnormalities 40,561 RSNA Pediatric Bone Age [7] 2019 Hand Bone age 14,236 Kuok et al. [13] 2018 Spine Lumbar vertebrae mask 60 Kim et al. [11] 2020 Spine Spine position 797 Ours 2021 Spine Multiple abnormalities 10,469\n\n2 Proposed Method\n\n\nOverall framework\n\nThe proposed deep learning framework (see Figure 1) includes two main parts:\n\n(1) a classification network, which accepts a spine X-ray as input and predicts if it could be a normal or abnormal scan; (2) a detection network receives the same input and predicts the location of abnormal findings. To maximize the framework's detection performance, we propose a decision rule to combine the outputs of the two networks. Overview of the VinDr-SpineXR for spine abnormalities classification and localization. A binary classifier takes as input one spine scan and predicts its probability of abnormality. A detector takes the same scan as input and provides bounding boxes along with probabilities of abnormal findings at lesion-level. A decision rule is then proposed to combine the two outputs and maximize the detection performance.\n\n\nDataset\n\nData collection Spine X-rays with lesion-level annotations are needed to develop automated lesion detection systems. In this work, more than 50,000 raw spine images in DICOM format were retrospectively collected from the Picture Archive and Communication System (PACS) of different primary hospitals between 2010-2020. The data collection process was conducted under our cooperation with participating hospitals. Since this research did not impact clinical care, patient consent was waived. To keep patient's Protected Health Information (PHI) secure, all patient-identifiable information associated with the images has been removed. Several DICOM attributes that are important for evaluating the spine conditions like patient's age and sex were retained.\n\nData annotation To annotate data, we developed an in-house labeling framework called VinDr Lab [18] which was built on top of a PACS. This is a web-based framework that allows multiple radiologists to work remotely at the same time. Additionally, it also provides a comprehensive set of annotation tools that help maximize the performance of human annotators. A set of 5,000 spine studies were randomly selected from the raw data after removing outliers (e.g. scans of other body parts or low-quality). All these scans were then uploaded to the labeling framework and assigned to 3 participating radiologists, who have at least 10 years of experience, such that each scan is annotated by exactly one radiologist. In this step, the radiologists decide whether a scan was abnormal or normal as well as marked the exact location of each abnormality on the scan. The labels and annotations provided by the radiologists were served as ground truth for model development and validation later. During this process, the radiologists were blinded to relevant clinical information except patient's age and sex. Finally, a total of 10,468 spine images from 5,000 studies were annotated for the presence of 13 abnormal findings: ankylosis, disc space narrowing, enthesophytes, foraminal stenosis, fracture, osteophytes, sclerotic lesion, spondylolysthesis, subchondral sclerosis, surgical implant, vertebral collapse, foreign body, and other lesions. The \"no finding\" label was intended to represent the absence of all abnormalities. For the development of the deep learning algorithms, we randomly stratified the labeled dataset, at study-level, into a development set of 4,000 studies and a test set of 1,000 studies. Table 2 summarizes the data characteristics, including patient demographic and the prevalence of each label via the number of bounding boxes. Figure 2 shows several representative samples with and without abnormal findings from our dataset.  \n\n\nModel development\n\nNetwork architecture and training methodology To classify a spine X-ray image as either normal or abnormal, three CNNs (DenseNet-121, DenseNet-169, DenseNet-201) have been deployed. These networks [8] are well-known to be effective for X-ray interpretation [21,22]. Each network accepts an image of the spine as input and outputs a binary label corresponding to normal or abnormal scan. A total of 4,257 spine images with normal findings and 4,133 spine images with abnormal findings (reflecting any of the lesions) from the training set was used to optimize networks' weights. During this stage, we optimized cross-entropy loss between the image-level labels and network's outputs using SGD optimizer. The average ensemble of three models serves as the final classifier. An image is considered abnormal in the inference stage if its probability of abnormality is greater than an optimal threshold. In particular, we determine the optimal threshold c * for the classifier by maximizing Youden's index [32], J(c) = q(c)+r(c)\u22121, where the sensitivity q and the specificity r are functions of the cutoff value c. For the detection task, we aim to localize 7 important lesions: osteophytes, disc space narrowing, surgical implant, foraminal stenosis, spondylolysthesis, vertebral collapse, and other lesions. Due to the limited number of positive samples, the rest lesions were considered \"other lesions\". State-of-theart detectors, namely Faster R-CNN [23], RetinaNet [15], EfficientDet [28], and Sparse R-CNN [27], have been deployed for this task. Faster R-CNN [23] was chosen as a representative for anchor-based two-stage detectors, which firstly propose a set of candidate regions then categorize and refine their locations. RetinaNet [15] and EfficientDet [28] are both one-state detectors that directly localize and classify the densely proposed anchor boxes. Different from previous detectors, Sparse R-CNN [27] starts from a set of initial proposals, then repeatedly refines and classifies these boxes using attention mechanism. All the networks were trained to localize spine lesions using the stochastic gradient descent (SGD) optimizer. During the learning phase, the bounding box regression loss and region-level classification loss were jointly minimized. To improve the generalization performance of the detectors, learned data augmentation strategies for object detection [34] were incorporated in the training procedure.\n\nDecision fusion rule Given an input image x, we denotep(abnormal|x) as the classifier's output that reflects the probability of the image being abnormal. To maximize the performance of the lesion detector, we propose a heuristic fusion rule as follows. For any x with the predictionp(abnormal|x) \u2265 c * , all lesion detection results are retained. For the casep(abnormal|x) < c * , only predicted bounding boxes with confidence higher than 0.5 are kept.\n\n\nExperiments and Results\n\n\nExperimental setup & Implementation details\n\nSeveral experiments were conducted to evaluate the performance of the VinDr-SpineXR. First, we evaluated the classification and detection networks independently on the test set. We then investigated the effect of the fusion rule on the detection performance of the whole framework. All networks were implemented and trained using PyTorch framework (version 1.7.1) on a server with one NVIDIA V100 32GiB GPU. For the classification task, all training images were rescaled to 224 \u00d7 224 pixels and normalized by the mean and standard deviation of images from the ImageNet dataset. The networks were initialized with pre-trained weights on ImageNet. Each network was trained end-to-end using SGD for 10,000 iterations, approximately 2 hours. We used mini-batches of size 32 and set the learning rate to 0.001. An ensemble of the three best models served as the final classifier. For the detection task, all training images were randomly downsampled such that the shorter edge ranging between 640 and 800 pixels, then random augmentation transforms were applied before grouping into mini-batches of 16 samples. The detectors were initialized with weights pretrained on COCO dataset then trained for 50,000 iterations (about 24 hours) using SGD with the learning rate reduced by 10\u00d7 at the 30,000-th iteration.\n\n\nEvaluation metrics\n\nWe report the classification performance using AUROC, sensitivity, specificity, and F1 score. We also estimate the 95% confidence interval (CI) by bootstrapping with 10,000 bootstraps for each measure. In each bootstrap, a new dataset is constructed by sampling with replacement [3]. For the detection task, we followed PASCAL VOC metric, mean average precision (mAP@0.5) [4]. A predicted finding is a true positive if it has an intersection over union (IoU) of at least 0.5 with a ground truth lesion of the same class. For each class, average precision (AP) is the mean of 101 precision values, corresponding to recall values ranging from 0 to 1 with a step size of 0.01. The final metric, mAP@0.5, is the mean of AP over all lesion categories.\n\n\nExperimental results\n\nClassification  Table 3 shows quantitative results over all the classification networks. Detection performance The AP of each abnormal finding detected by 4 detectors is shown in Table 4. Sparse R-CNN [27] showed it as the best performing detector for this task with a mAP@0.5 of 33.15% (see Supplementary Material). Meanwhile, RetinaNet [15] showed the worst performance with a mAP@0.5 of 28.09%. We observed that the reported performances varied over the target lesions, e.g. all the detectors performed best on the LT10 label (surgical implant) and worst on the LT13 (other lesions). Effect of the decision fusion rule Table 5 provides a comparison of the detection performance between the detector network and the whole framework. We observed that by combining the detection and classification networks via the proposed decision rule, the whole framework leads to a higher performance over all lesions, except LT4 and LT8. Visualization of predicted lesions by the VinDr-SpineXR is provided in the Supplementary Material. \n\n\nDiscussion\n\nThe proposed decision fusion uses the result of the classifier to influence the detector. As shown in Table 5, this rule, although very simple, helps improve the mAP of the detector by 0.41%. We have also experimented with a counterpart fusion rule to use the result of the detector to influence the classifier. Specifically, we averaged classifier's output with the highest box score from detector's outputs, boosting the AUROC and F1 score of the classifier by 1.58% and 0.46%, respectively. These experiments have highlighted the effectiveness of the proposed mutual ensemble mechanism.\n\n\nConclusions\n\nIn this work, we developed and validated VinDr-SpineXR -a deep learningbased framework to detect and localize abnormalities in radiographs of spine. We contributed a new labeled dataset and models for spine X-ray analysis. To the best of our knowledge, this is the first effort to address the problem of multiple lesions detection and localization in spine X-rays. Our experiments on the dataset demonstrated the effectiveness of the proposed method. For future work, we expect to extend our dataset and consider more lesion labels for further experiments, including rare labels. We also plan to conduct more experiments and evaluate the impact of the proposed framework in real-world clinical scenarios.\n\nFig. 1 .\n1Fig. 1. Overview of the VinDr-SpineXR for spine abnormalities classification and localization. A binary classifier takes as input one spine scan and predicts its probability of abnormality. A detector takes the same scan as input and provides bounding boxes along with probabilities of abnormal findings at lesion-level. A decision rule is then proposed to combine the two outputs and maximize the detection performance.\n\nFig. 2 .\n2Examples of spine X-rays with radiologist's annotations, in which abnormal findings are marked by rectangular bounding boxes.\n\nTable 1 .\n1Overview of publicly available MSK image datasets.\n\nTable 2 .\n2Characteristics of patients in the training and test datasets.Characteristic \nTraining set Test set \nTotal \n\nStatistics \n\nYears \n2011 to 2020 2015 to 2020 2011 to 2020 \nNumber of studies \n4000 \n1000 \n5000 \nNumber of images \n8390 \n2078 \n10468 \nNumber of normal images \n4257 \n1068 \n5325 \nNumber of abnormal images \n4133 \n1010 \n5143 \nImage size (pixel\u00d7pixel, mean) 2455 \u00d7 1606 2439 \u00d7 1587 2542 \u00d7 1602 \nAge (mean, years [range])* \n49 [6 -94] \n49 [13 -98] 49 [6 -98] \nMale (%)* \n37.91 \n37.53 \n37.83 \nFemale (%)* \n62.08 \n62.47 \n62.17 \nData size (GiB) \n29.04 \n7.17 \n36.21 \n\nLesion type \n\n1. Ankylosis \n6 \n1 \n7 \n2. Disc space narrowing \n924 \n231 \n1155 \n3. Enthesophytes \n54 \n13 \n67 \n4. Foraminal stenosis \n387 \n95 \n482 \n5. Fracture \n10 \n2 \n12 \n6. Osteophytes \n12562 \n3000 \n15562 \n7. Sclerotic lesion \n24 \n5 \n29 \n8. Spondylolysthesis \n280 \n69 \n349 \n9. Subchondral sclerosis \n87 \n23 \n110 \n10. Surgical implant \n429 \n107 \n536 \n11. Vertebral collapse \n268 \n69 \n337 \n12. Foreign body \n17 \n4 \n21 \n13. Other lesions \n248 \n63 \n311 \n\n(*) These calculations were performed on studies where sex and age were available. \n\n\nTable 3 .\n3Classification performance on the test set (in percent with 95% CI).Classifier \nAUROC \nF1 score \nSensitivity \nSpecificity \nDenseNet121 86.93 (85.4,88.4) 79.55 (77.6,81.4) 80.39 (77.9,82.8) 79.32 (76.9,81.7) \nDenseNet169 87.29 (85.8,88.8) 80.25 (78.3,82.1) 81.74 (79.3,84.1) 79.02 (76.6,81.4) \nDenseNet201 87.14 (85.6,88.6) 79.03 (77.1,80.9) 77.97 (75.4,80.5) 81.46 (79.1,83.8) \nEnsemble \n88.61 (87.2,90.0) 81.06 (79.2,82.9) 83.07 (80.6,85.3) 79.32 (77.8,81.7) \n\n\n\nTable 4 .\n4Spine X-ray detection performance on the test set. Sparse R-CNN [27] 20.09 32.67 48.16 45.32 72.20 49.30 5.41 33.15(*) LT2, LT4, LT6, LT8, LT10, LT11, LT13 denotes for disc space narrowing, foraminal stenosis, osteophytes, spondylolysthesis, surgical implant, vertebral collapse and other lesions, respectively, following the same indexing inTable 2.Detector \nLT2 ( * ) LT4 LT6 LT8 LT10 LT11 LT13 mAP@0.5 \nFaster R-CNN [23] 22.66 35.99 49.24 31.68 65.22 51.68 2.16 \n31.83 \nRetinaNet [15] \n14.53 25.35 41.67 32.14 65.49 51.85 5.30 \n28.09 \nEfficientDet [28] \n17.05 24.19 42.69 35.18 61.85 52.53 2.45 \n28.73 \n\n\nTable 5 .\n5Spine X-ray detection performance of the whole framework on the test set. Whole framework 21.43 27.36 34.78 41.29 62.53 43.39 4.16 33.56Method \nLT2 LT4 LT6 LT8 LT10 LT11 LT13 mAP@0.5 \nDetector only \n18.06 28.89 34.23 41.52 62.45 42.85 4.03 33.15 \n\nhttps://vindr.ai/datasets/spinexr 6 https://github.com/vinbigdata-medical/vindr-spinexr\n\nOsteoarthritis initiative: A multi-center observational study of men and women. Osteoarthritis initiative: A multi-center observational study of men and women. https://oai.epi-ucsf.org/datarelease/, accessed: 2021-02-22\n\nSpinal imaging: Diagnostic imaging of the spine and spinal cord. A Baert, Springer Science & Business MediaBaert, A.: Spinal imaging: Diagnostic imaging of the spine and spinal cord. Springer Science & Business Media (2007)\n\nAn introduction to the bootstrap. B Efron, R J Tibshirani, No. 57 in Monographs on Statistics and Applied Probability. Chapman & Hall/CRCEfron, B., Tibshirani, R.J.: An introduction to the bootstrap. No. 57 in Mono- graphs on Statistics and Applied Probability, Chapman & Hall/CRC (1993)\n\nThe Pascal visual object classes (VOC) challenge. M Everingham, L Van Gool, C K Williams, J Winn, A Zisserman, International Journal of Computer Vision. 882Everingham, M., Van Gool, L., Williams, C.K., Winn, J., Zisserman, A.: The Pascal visual object classes (VOC) challenge. International Journal of Computer Vision 88(2), 303-338 (2010)\n\nBone age assessment of children using a digital hand atlas. A Gertych, A Zhang, J Sayre, S Pospiech-Kurkowska, H Huang, Computerized Medical Imaging and Graphics. 314-5Gertych, A., Zhang, A., Sayre, J., Pospiech-Kurkowska, S., Huang, H.: Bone age assessment of children using a digital hand atlas. Computerized Medical Imaging and Graphics 31(4-5), 322-331 (2007)\n\nComputer-aided detection in musculoskeletal projection radiography: A systematic review. M Gundry, K Knapp, R Meertens, J Meakin, Radiography. 242Gundry, M., Knapp, K., Meertens, R., Meakin, J.: Computer-aided detection in musculoskeletal projection radiography: A systematic review. Radiography 24(2), 165-174 (2018)\n\nThe RSNA pediatric bone age machine learning challenge. S S Halabi, L M Prevedello, J Kalpathy-Cramer, A B Mamonov, A Bilbily, M Cicero, I Pan, L A Pereira, R T Sousa, N Abdala, Radiology. 2902Halabi, S.S., Prevedello, L.M., Kalpathy-Cramer, J., Mamonov, A.B., Bilbily, A., Cicero, M., Pan, I., Pereira, L.A., Sousa, R.T., Abdala, N., et al.: The RSNA pediatric bone age machine learning challenge. Radiology 290(2), 498-503 (2019)\n\nDensely connected convolutional networks. G Huang, Z Liu, L Van Der Maaten, K Q Weinberger, IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Huang, G., Liu, Z., Van Der Maaten, L., Weinberger, K.Q.: Densely connected convolutional networks. In: IEEE Conference on Computer Vision and Pattern Recognition (CVPR). pp. 4700-4708 (2017)\n\nComputerized detection of vertebral compression fractures on lateral chest radiographs: Preliminary results with a tool for early detection of osteoporosis. S Kasai, F Li, J Shiraishi, Q Li, K Doi, Medical Physics. 3312Kasai, S., Li, F., Shiraishi, J., Li, Q., Doi, K.: Computerized detection of vertebral compression fractures on lateral chest radiographs: Preliminary results with a tool for early detection of osteoporosis. Medical Physics 33(12), 4664-4674 (2006)\n\nDevelopment of computerized method for detection of vertebral fractures on lateral chest radiographs. S Kasai, F Li, J Shiraishi, Q Li, Y Nie, K Doi, Medical Imaging: Image Processing. 614461445Kasai, S., Li, F., Shiraishi, J., Li, Q., Nie, Y., Doi, K.: Development of computerized method for detection of vertebral fractures on lateral chest radiographs. In: Medical Imaging: Image Processing. vol. 6144, p. 61445D (2006)\n\nAutomatic detection and segmentation of lumbar vertebrae from x-ray images for compression fracture evaluation. K C Kim, H C Cho, T J Jang, J M Choi, J K Seo, Computer Methods and Programs in Biomedicine. 105833Kim, K.C., Cho, H.C., Jang, T.J., Choi, J.M., Seo, J.K.: Automatic detection and segmentation of lumbar vertebrae from x-ray images for compression fracture evaluation. Computer Methods and Programs in Biomedicine p. 105833 (2020)\n\nLong radiology workdays reduce detection and accommodation accuracy. E A Krupinski, K S Berbaum, R T Caldwell, K M Schartz, J Kim, Journal of the American College of Radiology. 79Krupinski, E.A., Berbaum, K.S., Caldwell, R.T., Schartz, K.M., Kim, J.: Long radiology workdays reduce detection and accommodation accuracy. Journal of the American College of Radiology 7(9), 698-704 (2010)\n\nVertebrae segmentation from X-ray images using convolutional neural network. C P Kuok, M J Fu, C J Lin, M H Horng, Y N Sun, International Conference on Information Hiding and Image Processing (IHIP). Kuok, C.P., Fu, M.J., Lin, C.J., Horng, M.H., Sun, Y.N.: Vertebrae segmentation from X-ray images using convolutional neural network. In: International Conference on Information Hiding and Image Processing (IHIP). pp. 57-61 (2018)\n\nDeep learning. Y Lecun, Y Bengio, G Hinton, Nature. 5217553LeCun, Y., Bengio, Y., Hinton, G.: Deep learning. Nature 521(7553), 436-444 (2015)\n\nFocal loss for dense object detection. T Y Lin, P Goyal, R Girshick, K He, P Doll\u00e1r, IEEE International Conference on Computer Vision (ICCV). Lin, T.Y., Goyal, P., Girshick, R., He, K., Doll\u00e1r, P.: Focal loss for dense object detection. In: IEEE International Conference on Computer Vision (ICCV). pp. 2980-2988 (2017)\n\nDeep neural network improves fracture detection by clinicians. R Lindsey, A Daluiski, S Chopra, A Lachapelle, M Mozer, S Sicular, D Hanel, M Gardner, A Gupta, R Hotchkiss, Proceedings of the National Academy of Sciences. 11545Lindsey, R., Daluiski, A., Chopra, S., Lachapelle, A., Mozer, M., Sicular, S., Hanel, D., Gardner, M., Gupta, A., Hotchkiss, R., et al.: Deep neural network improves fracture detection by clinicians. Proceedings of the National Academy of Sciences 115(45), 11591-11596 (2018)\n\nDeveloping new machine learning ensembles for quality spine diagnosis. Knowledge-based Systems. I Mandal, 73Mandal, I.: Developing new machine learning ensembles for quality spine diagnosis. Knowledge-based Systems 73, 298-310 (2015)\n\nVinDr Lab: A Data Platform for Medical AI. N T Nguyen, P T Truong, V T Ho, T V Nguyen, H T Pham, M T Nguyen, L T Dam, H Q Nguyen, Nguyen, N.T., Truong, P.T., Ho, V.T., Nguyen, T.V., Pham, H.T., Nguyen, M.T., Dam, L.T., Nguyen, H.Q.: VinDr Lab: A Data Platform for Medical AI. https: //github.com/vinbigdata-medical/vindr-lab (2021)\n\nTraumatic fractures in adults: Missed diagnosis on plain radiographs in the emergency department. A Pinto, D Berritto, A Russo, F Riccitiello, M Caruso, M P Belfiore, V R Papapietro, M Carotti, F Pinto, A Giovagnoni, Atenei Parmensis. 891111Acta Bio MedicaPinto, A., Berritto, D., Russo, A., Riccitiello, F., Caruso, M., Belfiore, M.P., Papa- pietro, V.R., Carotti, M., Pinto, F., Giovagnoni, A., et al.: Traumatic fractures in adults: Missed diagnosis on plain radiographs in the emergency department. Acta Bio Medica: Atenei Parmensis 89(1), 111 (2018)\n\nThe current role of radiography in the assessment of skeletal tumors and tumor-like lesions. F Priolo, A Cerase, European Journal of Radiology. 27Priolo, F., Cerase, A.: The current role of radiography in the assessment of skeletal tumors and tumor-like lesions. European Journal of Radiology 27, S77-S85 (1998)\n\nP Rajpurkar, J Irvin, A Bagul, D Ding, T Duan, H Mehta, B Yang, K Zhu, D Laird, R L Ball, arXiv:1712.06957MURA: Large dataset for abnormality detection in musculoskeletal radiographs. arXiv preprintRajpurkar, P., Irvin, J., Bagul, A., Ding, D., Duan, T., Mehta, H., Yang, B., Zhu, K., Laird, D., Ball, R.L., et al.: MURA: Large dataset for abnormality detection in musculoskeletal radiographs. arXiv preprint arXiv:1712.06957 (2017)\n\nP Rajpurkar, J Irvin, K Zhu, B Yang, H Mehta, T Duan, D Ding, A Bagul, C Langlotz, K Shpanskaya, arXiv:1711.05225ChexNet: Radiologist-level pneumonia detection on chest X-rays with deep learning. arXiv preprintRajpurkar, P., Irvin, J., Zhu, K., Yang, B., Mehta, H., Duan, T., Ding, D., Bagul, A., Langlotz, C., Shpanskaya, K., et al.: ChexNet: Radiologist-level pneumonia detection on chest X-rays with deep learning. arXiv preprint arXiv:1711.05225 (2017)\n\nFaster r-cnn: Towards real-time object detection with region proposal networks. S Ren, K He, R Girshick, J Sun, Advances in Neural Information Processing Systems. Cortes, C., Lawrence, N., Lee, D., Sugiyama, M., Garnett, R.Curran Associates, Inc28Ren, S., He, K., Girshick, R., Sun, J.: Faster r-cnn: Towards real-time object detection with region proposal networks. In: Cortes, C., Lawrence, N., Lee, D., Sugiyama, M., Garnett, R. (eds.) Advances in Neural Information Processing Sys- tems. vol. 28. Curran Associates, Inc. (2015), https://proceedings.neurips.cc/ paper/2015/file/14bfa6bb14875e45bba028a21ed38046-Paper.pdf\n\nDiagnostic imaging of solitary tumors of the spine: What to do and say. M H Rodallec, A Feydy, F Larousserie, P Anract, R Campagna, A Babinet, M Zins, J L Drap\u00e9, Radiographics. 284Rodallec, M.H., Feydy, A., Larousserie, F., Anract, P., Campagna, R., Babinet, A., Zins, M., Drap\u00e9, J.L.: Diagnostic imaging of solitary tumors of the spine: What to do and say. Radiographics 28(4), 1019-1041 (2008)\n\nR Sa, W Owens, R Wiegand, M Studin, D Capoferri, K Barooha, A Greaux, R Rattray, A Hutton, J Cintineo, Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC). Intervertebral disc detection in Xray images using Faster R-CNNSa, R., Owens, W., Wiegand, R., Studin, M., Capoferri, D., Barooha, K., Greaux, A., Rattray, R., Hutton, A., Cintineo, J., et al.: Intervertebral disc detection in X- ray images using Faster R-CNN. In: Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC). pp. 564-567 (2017)\n\nDeep learning in medical image analysis. D Shen, G Wu, H I Suk, Annual Review of Biomedical Engineering. 19Shen, D., Wu, G., Suk, H.I.: Deep learning in medical image analysis. Annual Review of Biomedical Engineering 19, 221-248 (2017)\n\nP Sun, R Zhang, Y Jiang, T Kong, C Xu, W Zhan, M Tomizuka, L Li, Z Yuan, C Wang, P Luo, arXiv:2011.12450Sparse R-CNN: End-to-end object detection with learnable proposals. arXiv preprintSun, P., Zhang, R., Jiang, Y., Kong, T., Xu, C., Zhan, W., Tomizuka, M., Li, L., Yuan, Z., Wang, C., Luo, P.: Sparse R-CNN: End-to-end object detection with learnable proposals. arXiv preprint arXiv:2011.12450 (2020)\n\nEfficientDet: Scalable and efficient object detection. M Tan, R Pang, Q V Le, IEEE Conference on Computer Vision and Pattern Recognition (ECCV). Tan, M., Pang, R., Le, Q.V.: EfficientDet: Scalable and efficient object detection. In: IEEE Conference on Computer Vision and Pattern Recognition (ECCV). pp. 10781-10790 (2020)\n\nImaging for musculoskeletal problems. C Tang, R Aggarwal, InnovAiT. 611Tang, C., Aggarwal, R.: Imaging for musculoskeletal problems. InnovAiT 6(11), 735-738 (2013)\n\nY L Thian, Y Li, P Jagmohan, D Sia, V E Y Chan, R T Tan, Convolutional neural networks for automated fracture detection and localization on wrist radiographs. 1180001Thian, Y.L., Li, Y., Jagmohan, P., Sia, D., Chan, V.E.Y., Tan, R.T.: Convolu- tional neural networks for automated fracture detection and localization on wrist radiographs. Radiology: Artificial Intelligence 1(1), e180001 (2019)\n\nImputation methods for temporal radiographic texture analysis in the detection of periprosthetic osteolysis. J R Wilkie, M L Giger, L L Pesce, C A Engh Sr, R H HopperJr, J M Martell, Medical Imaging: Computer-Aided Diagnosis. 651465141Wilkie, J.R., Giger, M.L., Pesce, L.L., Engh Sr, C.A., Hopper Jr, R.H., Martell, J.M.: Imputation methods for temporal radiographic texture analysis in the detec- tion of periprosthetic osteolysis. In: Medical Imaging: Computer-Aided Diagnosis. vol. 6514, p. 65141L (2007)\n\nIndex for rating diagnostic tests. W J Youden, Cancer. 31Youden, W.J.: Index for rating diagnostic tests. Cancer 3(1), 32-35 (1950)\n\nA new window loss function for bone fracture detection and localization in X-ray images with point-based annotation. X Zhang, Y Wang, C T Cheng, L Lu, J Xiao, C H Liao, S Miao, arXiv:2012.04066arXiv preprintZhang, X., Wang, Y., Cheng, C.T., Lu, L., Xiao, J., Liao, C.H., Miao, S.: A new window loss function for bone fracture detection and localization in X-ray images with point-based annotation. arXiv preprint arXiv:2012.04066 (2020)\n\nLearning data augmentation strategies for object detection. B Zoph, E D Cubuk, G Ghiasi, T Y Lin, J Shlens, Q V Le, IEEE European Conference on Computer Vision (ECCV). Zoph, B., Cubuk, E.D., Ghiasi, G., Lin, T.Y., Shlens, J., Le, Q.V.: Learning data augmentation strategies for object detection. In: IEEE European Conference on Computer Vision (ECCV). pp. 566-583 (2020)\n", "annotations": {"author": "[{\"end\":296,\"start\":109},{\"end\":444,\"start\":297},{\"end\":460,\"start\":445},{\"end\":608,\"start\":461},{\"end\":796,\"start\":609},{\"end\":871,\"start\":797},{\"end\":1001,\"start\":872}]", "publisher": null, "author_last_name": "[{\"end\":122,\"start\":116},{\"end\":308,\"start\":304},{\"end\":459,\"start\":453},{\"end\":472,\"start\":466},{\"end\":622,\"start\":617},{\"end\":805,\"start\":802},{\"end\":878,\"start\":876}]", "author_first_name": "[{\"end\":113,\"start\":109},{\"end\":115,\"start\":114},{\"end\":301,\"start\":297},{\"end\":303,\"start\":302},{\"end\":450,\"start\":445},{\"end\":452,\"start\":451},{\"end\":463,\"start\":461},{\"end\":465,\"start\":464},{\"end\":614,\"start\":609},{\"end\":616,\"start\":615},{\"end\":801,\"start\":797},{\"end\":875,\"start\":872}]", "author_affiliation": "[{\"end\":187,\"start\":124},{\"end\":295,\"start\":189},{\"end\":373,\"start\":310},{\"end\":443,\"start\":375},{\"end\":537,\"start\":474},{\"end\":607,\"start\":539},{\"end\":687,\"start\":624},{\"end\":795,\"start\":689},{\"end\":870,\"start\":807},{\"end\":943,\"start\":880},{\"end\":1000,\"start\":945}]", "title": "[{\"end\":106,\"start\":1},{\"end\":1107,\"start\":1002}]", "venue": null, "abstract": "[{\"end\":2565,\"start\":1223}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b19\"},\"end\":2765,\"start\":2761},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":2768,\"start\":2765},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3021,\"start\":3018},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":3024,\"start\":3021},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":3699,\"start\":3695},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":3926,\"start\":3922},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":4061,\"start\":4057},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":4601,\"start\":4598},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":4771,\"start\":4767},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":4789,\"start\":4786},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":4809,\"start\":4805},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":4854,\"start\":4850},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":4941,\"start\":4937},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":4944,\"start\":4941},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":4947,\"start\":4944},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":4950,\"start\":4947},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":4953,\"start\":4950},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":4956,\"start\":4953},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":4959,\"start\":4956},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":5042,\"start\":5038},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":5045,\"start\":5042},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":5048,\"start\":5045},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":5051,\"start\":5048},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":5054,\"start\":5051},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":6480,\"start\":6477},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":6483,\"start\":6480},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":7218,\"start\":7215},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":7278,\"start\":7275},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":7314,\"start\":7310},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":7379,\"start\":7376},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":7422,\"start\":7418},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":7474,\"start\":7470},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":9289,\"start\":9285},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":11362,\"start\":11359},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":11423,\"start\":11419},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":11426,\"start\":11423},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":12167,\"start\":12163},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":12615,\"start\":12611},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":12631,\"start\":12627},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":12650,\"start\":12646},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":12673,\"start\":12669},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":12726,\"start\":12722},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":12903,\"start\":12899},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":12925,\"start\":12921},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":13078,\"start\":13074},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":13551,\"start\":13547},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":15733,\"start\":15730},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":15826,\"start\":15823},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":16427,\"start\":16423},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":16564,\"start\":16560}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":19004,\"start\":18573},{\"attributes\":{\"id\":\"fig_1\"},\"end\":19141,\"start\":19005},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":19204,\"start\":19142},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":20318,\"start\":19205},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":20793,\"start\":20319},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":21412,\"start\":20794},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":21672,\"start\":21413}]", "paragraph": "[{\"end\":3763,\"start\":2610},{\"end\":4420,\"start\":3765},{\"end\":5993,\"start\":4437},{\"end\":7156,\"start\":6010},{\"end\":7550,\"start\":7168},{\"end\":7569,\"start\":7552},{\"end\":7667,\"start\":7591},{\"end\":8421,\"start\":7669},{\"end\":9188,\"start\":8433},{\"end\":11140,\"start\":9190},{\"end\":13596,\"start\":11162},{\"end\":14050,\"start\":13598},{\"end\":15428,\"start\":14124},{\"end\":16197,\"start\":15451},{\"end\":17248,\"start\":16222},{\"end\":17852,\"start\":17263},{\"end\":18572,\"start\":17868}]", "formula": null, "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":6384,\"start\":6377},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":10905,\"start\":10898},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":16245,\"start\":16238},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":16408,\"start\":16401},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":16851,\"start\":16844},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":17372,\"start\":17365}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2579,\"start\":2567},{\"attributes\":{\"n\":\"1.1\"},\"end\":2608,\"start\":2582},{\"attributes\":{\"n\":\"1.2\"},\"end\":4435,\"start\":4423},{\"attributes\":{\"n\":\"1.3\"},\"end\":6008,\"start\":5996},{\"end\":7166,\"start\":7159},{\"attributes\":{\"n\":\"2.1\"},\"end\":7589,\"start\":7572},{\"attributes\":{\"n\":\"2.2\"},\"end\":8431,\"start\":8424},{\"attributes\":{\"n\":\"2.3\"},\"end\":11160,\"start\":11143},{\"attributes\":{\"n\":\"3\"},\"end\":14076,\"start\":14053},{\"attributes\":{\"n\":\"3.1\"},\"end\":14122,\"start\":14079},{\"attributes\":{\"n\":\"3.2\"},\"end\":15449,\"start\":15431},{\"attributes\":{\"n\":\"3.3\"},\"end\":16220,\"start\":16200},{\"attributes\":{\"n\":\"4\"},\"end\":17261,\"start\":17251},{\"attributes\":{\"n\":\"5\"},\"end\":17866,\"start\":17855},{\"end\":18582,\"start\":18574},{\"end\":19014,\"start\":19006},{\"end\":19152,\"start\":19143},{\"end\":19215,\"start\":19206},{\"end\":20329,\"start\":20320},{\"end\":20804,\"start\":20795},{\"end\":21423,\"start\":21414}]", "table": "[{\"end\":20318,\"start\":19279},{\"end\":20793,\"start\":20399},{\"end\":21412,\"start\":21156},{\"end\":21672,\"start\":21561}]", "figure_caption": "[{\"end\":19004,\"start\":18584},{\"end\":19141,\"start\":19016},{\"end\":19204,\"start\":19154},{\"end\":19279,\"start\":19217},{\"end\":20399,\"start\":20331},{\"end\":21156,\"start\":20806},{\"end\":21561,\"start\":21425}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":7641,\"start\":7633},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":11048,\"start\":11040},{\"end\":16537,\"start\":16514}]", "bib_author_first_name": "[{\"end\":22049,\"start\":22048},{\"end\":22243,\"start\":22242},{\"end\":22252,\"start\":22251},{\"end\":22254,\"start\":22253},{\"end\":22548,\"start\":22547},{\"end\":22562,\"start\":22561},{\"end\":22574,\"start\":22573},{\"end\":22576,\"start\":22575},{\"end\":22588,\"start\":22587},{\"end\":22596,\"start\":22595},{\"end\":22899,\"start\":22898},{\"end\":22910,\"start\":22909},{\"end\":22919,\"start\":22918},{\"end\":22928,\"start\":22927},{\"end\":22950,\"start\":22949},{\"end\":23293,\"start\":23292},{\"end\":23303,\"start\":23302},{\"end\":23312,\"start\":23311},{\"end\":23324,\"start\":23323},{\"end\":23579,\"start\":23578},{\"end\":23581,\"start\":23580},{\"end\":23591,\"start\":23590},{\"end\":23593,\"start\":23592},{\"end\":23607,\"start\":23606},{\"end\":23626,\"start\":23625},{\"end\":23628,\"start\":23627},{\"end\":23639,\"start\":23638},{\"end\":23650,\"start\":23649},{\"end\":23660,\"start\":23659},{\"end\":23667,\"start\":23666},{\"end\":23669,\"start\":23668},{\"end\":23680,\"start\":23679},{\"end\":23682,\"start\":23681},{\"end\":23691,\"start\":23690},{\"end\":23998,\"start\":23997},{\"end\":24007,\"start\":24006},{\"end\":24014,\"start\":24013},{\"end\":24032,\"start\":24031},{\"end\":24034,\"start\":24033},{\"end\":24465,\"start\":24464},{\"end\":24474,\"start\":24473},{\"end\":24480,\"start\":24479},{\"end\":24493,\"start\":24492},{\"end\":24499,\"start\":24498},{\"end\":24879,\"start\":24878},{\"end\":24888,\"start\":24887},{\"end\":24894,\"start\":24893},{\"end\":24907,\"start\":24906},{\"end\":24913,\"start\":24912},{\"end\":24920,\"start\":24919},{\"end\":25313,\"start\":25312},{\"end\":25315,\"start\":25314},{\"end\":25322,\"start\":25321},{\"end\":25324,\"start\":25323},{\"end\":25331,\"start\":25330},{\"end\":25333,\"start\":25332},{\"end\":25341,\"start\":25340},{\"end\":25343,\"start\":25342},{\"end\":25351,\"start\":25350},{\"end\":25353,\"start\":25352},{\"end\":25713,\"start\":25712},{\"end\":25715,\"start\":25714},{\"end\":25728,\"start\":25727},{\"end\":25730,\"start\":25729},{\"end\":25741,\"start\":25740},{\"end\":25743,\"start\":25742},{\"end\":25755,\"start\":25754},{\"end\":25757,\"start\":25756},{\"end\":25768,\"start\":25767},{\"end\":26108,\"start\":26107},{\"end\":26110,\"start\":26109},{\"end\":26118,\"start\":26117},{\"end\":26120,\"start\":26119},{\"end\":26126,\"start\":26125},{\"end\":26128,\"start\":26127},{\"end\":26135,\"start\":26134},{\"end\":26137,\"start\":26136},{\"end\":26146,\"start\":26145},{\"end\":26148,\"start\":26147},{\"end\":26478,\"start\":26477},{\"end\":26487,\"start\":26486},{\"end\":26497,\"start\":26496},{\"end\":26645,\"start\":26644},{\"end\":26647,\"start\":26646},{\"end\":26654,\"start\":26653},{\"end\":26663,\"start\":26662},{\"end\":26675,\"start\":26674},{\"end\":26681,\"start\":26680},{\"end\":26989,\"start\":26988},{\"end\":27000,\"start\":26999},{\"end\":27012,\"start\":27011},{\"end\":27022,\"start\":27021},{\"end\":27036,\"start\":27035},{\"end\":27045,\"start\":27044},{\"end\":27056,\"start\":27055},{\"end\":27065,\"start\":27064},{\"end\":27076,\"start\":27075},{\"end\":27085,\"start\":27084},{\"end\":27525,\"start\":27524},{\"end\":27707,\"start\":27706},{\"end\":27709,\"start\":27708},{\"end\":27719,\"start\":27718},{\"end\":27721,\"start\":27720},{\"end\":27731,\"start\":27730},{\"end\":27733,\"start\":27732},{\"end\":27739,\"start\":27738},{\"end\":27741,\"start\":27740},{\"end\":27751,\"start\":27750},{\"end\":27753,\"start\":27752},{\"end\":27761,\"start\":27760},{\"end\":27763,\"start\":27762},{\"end\":27773,\"start\":27772},{\"end\":27775,\"start\":27774},{\"end\":27782,\"start\":27781},{\"end\":27784,\"start\":27783},{\"end\":28095,\"start\":28094},{\"end\":28104,\"start\":28103},{\"end\":28116,\"start\":28115},{\"end\":28125,\"start\":28124},{\"end\":28140,\"start\":28139},{\"end\":28150,\"start\":28149},{\"end\":28152,\"start\":28151},{\"end\":28164,\"start\":28163},{\"end\":28166,\"start\":28165},{\"end\":28180,\"start\":28179},{\"end\":28191,\"start\":28190},{\"end\":28200,\"start\":28199},{\"end\":28646,\"start\":28645},{\"end\":28656,\"start\":28655},{\"end\":28866,\"start\":28865},{\"end\":28879,\"start\":28878},{\"end\":28888,\"start\":28887},{\"end\":28897,\"start\":28896},{\"end\":28905,\"start\":28904},{\"end\":28913,\"start\":28912},{\"end\":28922,\"start\":28921},{\"end\":28930,\"start\":28929},{\"end\":28937,\"start\":28936},{\"end\":28946,\"start\":28945},{\"end\":28948,\"start\":28947},{\"end\":29300,\"start\":29299},{\"end\":29313,\"start\":29312},{\"end\":29322,\"start\":29321},{\"end\":29329,\"start\":29328},{\"end\":29337,\"start\":29336},{\"end\":29346,\"start\":29345},{\"end\":29354,\"start\":29353},{\"end\":29362,\"start\":29361},{\"end\":29371,\"start\":29370},{\"end\":29383,\"start\":29382},{\"end\":29838,\"start\":29837},{\"end\":29845,\"start\":29844},{\"end\":29851,\"start\":29850},{\"end\":29863,\"start\":29862},{\"end\":30455,\"start\":30454},{\"end\":30457,\"start\":30456},{\"end\":30469,\"start\":30468},{\"end\":30478,\"start\":30477},{\"end\":30493,\"start\":30492},{\"end\":30503,\"start\":30502},{\"end\":30515,\"start\":30514},{\"end\":30526,\"start\":30525},{\"end\":30534,\"start\":30533},{\"end\":30536,\"start\":30535},{\"end\":30780,\"start\":30779},{\"end\":30786,\"start\":30785},{\"end\":30795,\"start\":30794},{\"end\":30806,\"start\":30805},{\"end\":30816,\"start\":30815},{\"end\":30829,\"start\":30828},{\"end\":30840,\"start\":30839},{\"end\":30850,\"start\":30849},{\"end\":30861,\"start\":30860},{\"end\":30871,\"start\":30870},{\"end\":31401,\"start\":31400},{\"end\":31409,\"start\":31408},{\"end\":31415,\"start\":31414},{\"end\":31417,\"start\":31416},{\"end\":31597,\"start\":31596},{\"end\":31604,\"start\":31603},{\"end\":31613,\"start\":31612},{\"end\":31622,\"start\":31621},{\"end\":31630,\"start\":31629},{\"end\":31636,\"start\":31635},{\"end\":31644,\"start\":31643},{\"end\":31656,\"start\":31655},{\"end\":31662,\"start\":31661},{\"end\":31670,\"start\":31669},{\"end\":31678,\"start\":31677},{\"end\":32056,\"start\":32055},{\"end\":32063,\"start\":32062},{\"end\":32071,\"start\":32070},{\"end\":32073,\"start\":32072},{\"end\":32363,\"start\":32362},{\"end\":32371,\"start\":32370},{\"end\":32490,\"start\":32489},{\"end\":32492,\"start\":32491},{\"end\":32501,\"start\":32500},{\"end\":32507,\"start\":32506},{\"end\":32519,\"start\":32518},{\"end\":32526,\"start\":32525},{\"end\":32530,\"start\":32527},{\"end\":32538,\"start\":32537},{\"end\":32540,\"start\":32539},{\"end\":32995,\"start\":32994},{\"end\":32997,\"start\":32996},{\"end\":33007,\"start\":33006},{\"end\":33009,\"start\":33008},{\"end\":33018,\"start\":33017},{\"end\":33020,\"start\":33019},{\"end\":33029,\"start\":33028},{\"end\":33031,\"start\":33030},{\"end\":33042,\"start\":33041},{\"end\":33044,\"start\":33043},{\"end\":33056,\"start\":33055},{\"end\":33058,\"start\":33057},{\"end\":33430,\"start\":33429},{\"end\":33432,\"start\":33431},{\"end\":33645,\"start\":33644},{\"end\":33654,\"start\":33653},{\"end\":33662,\"start\":33661},{\"end\":33664,\"start\":33663},{\"end\":33673,\"start\":33672},{\"end\":33679,\"start\":33678},{\"end\":33687,\"start\":33686},{\"end\":33689,\"start\":33688},{\"end\":33697,\"start\":33696},{\"end\":34026,\"start\":34025},{\"end\":34034,\"start\":34033},{\"end\":34036,\"start\":34035},{\"end\":34045,\"start\":34044},{\"end\":34055,\"start\":34054},{\"end\":34057,\"start\":34056},{\"end\":34064,\"start\":34063},{\"end\":34074,\"start\":34073},{\"end\":34076,\"start\":34075}]", "bib_author_last_name": "[{\"end\":22055,\"start\":22050},{\"end\":22249,\"start\":22244},{\"end\":22265,\"start\":22255},{\"end\":22559,\"start\":22549},{\"end\":22571,\"start\":22563},{\"end\":22585,\"start\":22577},{\"end\":22593,\"start\":22589},{\"end\":22606,\"start\":22597},{\"end\":22907,\"start\":22900},{\"end\":22916,\"start\":22911},{\"end\":22925,\"start\":22920},{\"end\":22947,\"start\":22929},{\"end\":22956,\"start\":22951},{\"end\":23300,\"start\":23294},{\"end\":23309,\"start\":23304},{\"end\":23321,\"start\":23313},{\"end\":23331,\"start\":23325},{\"end\":23588,\"start\":23582},{\"end\":23604,\"start\":23594},{\"end\":23623,\"start\":23608},{\"end\":23636,\"start\":23629},{\"end\":23647,\"start\":23640},{\"end\":23657,\"start\":23651},{\"end\":23664,\"start\":23661},{\"end\":23677,\"start\":23670},{\"end\":23688,\"start\":23683},{\"end\":23698,\"start\":23692},{\"end\":24004,\"start\":23999},{\"end\":24011,\"start\":24008},{\"end\":24029,\"start\":24015},{\"end\":24045,\"start\":24035},{\"end\":24471,\"start\":24466},{\"end\":24477,\"start\":24475},{\"end\":24490,\"start\":24481},{\"end\":24496,\"start\":24494},{\"end\":24503,\"start\":24500},{\"end\":24885,\"start\":24880},{\"end\":24891,\"start\":24889},{\"end\":24904,\"start\":24895},{\"end\":24910,\"start\":24908},{\"end\":24917,\"start\":24914},{\"end\":24924,\"start\":24921},{\"end\":25319,\"start\":25316},{\"end\":25328,\"start\":25325},{\"end\":25338,\"start\":25334},{\"end\":25348,\"start\":25344},{\"end\":25357,\"start\":25354},{\"end\":25725,\"start\":25716},{\"end\":25738,\"start\":25731},{\"end\":25752,\"start\":25744},{\"end\":25765,\"start\":25758},{\"end\":25772,\"start\":25769},{\"end\":26115,\"start\":26111},{\"end\":26123,\"start\":26121},{\"end\":26132,\"start\":26129},{\"end\":26143,\"start\":26138},{\"end\":26152,\"start\":26149},{\"end\":26484,\"start\":26479},{\"end\":26494,\"start\":26488},{\"end\":26504,\"start\":26498},{\"end\":26651,\"start\":26648},{\"end\":26660,\"start\":26655},{\"end\":26672,\"start\":26664},{\"end\":26678,\"start\":26676},{\"end\":26688,\"start\":26682},{\"end\":26997,\"start\":26990},{\"end\":27009,\"start\":27001},{\"end\":27019,\"start\":27013},{\"end\":27033,\"start\":27023},{\"end\":27042,\"start\":27037},{\"end\":27053,\"start\":27046},{\"end\":27062,\"start\":27057},{\"end\":27073,\"start\":27066},{\"end\":27082,\"start\":27077},{\"end\":27095,\"start\":27086},{\"end\":27532,\"start\":27526},{\"end\":27716,\"start\":27710},{\"end\":27728,\"start\":27722},{\"end\":27736,\"start\":27734},{\"end\":27748,\"start\":27742},{\"end\":27758,\"start\":27754},{\"end\":27770,\"start\":27764},{\"end\":27779,\"start\":27776},{\"end\":27791,\"start\":27785},{\"end\":28101,\"start\":28096},{\"end\":28113,\"start\":28105},{\"end\":28122,\"start\":28117},{\"end\":28137,\"start\":28126},{\"end\":28147,\"start\":28141},{\"end\":28161,\"start\":28153},{\"end\":28177,\"start\":28167},{\"end\":28188,\"start\":28181},{\"end\":28197,\"start\":28192},{\"end\":28211,\"start\":28201},{\"end\":28653,\"start\":28647},{\"end\":28663,\"start\":28657},{\"end\":28876,\"start\":28867},{\"end\":28885,\"start\":28880},{\"end\":28894,\"start\":28889},{\"end\":28902,\"start\":28898},{\"end\":28910,\"start\":28906},{\"end\":28919,\"start\":28914},{\"end\":28927,\"start\":28923},{\"end\":28934,\"start\":28931},{\"end\":28943,\"start\":28938},{\"end\":28953,\"start\":28949},{\"end\":29310,\"start\":29301},{\"end\":29319,\"start\":29314},{\"end\":29326,\"start\":29323},{\"end\":29334,\"start\":29330},{\"end\":29343,\"start\":29338},{\"end\":29351,\"start\":29347},{\"end\":29359,\"start\":29355},{\"end\":29368,\"start\":29363},{\"end\":29380,\"start\":29372},{\"end\":29394,\"start\":29384},{\"end\":29842,\"start\":29839},{\"end\":29848,\"start\":29846},{\"end\":29860,\"start\":29852},{\"end\":29867,\"start\":29864},{\"end\":30466,\"start\":30458},{\"end\":30475,\"start\":30470},{\"end\":30490,\"start\":30479},{\"end\":30500,\"start\":30494},{\"end\":30512,\"start\":30504},{\"end\":30523,\"start\":30516},{\"end\":30531,\"start\":30527},{\"end\":30542,\"start\":30537},{\"end\":30783,\"start\":30781},{\"end\":30792,\"start\":30787},{\"end\":30803,\"start\":30796},{\"end\":30813,\"start\":30807},{\"end\":30826,\"start\":30817},{\"end\":30837,\"start\":30830},{\"end\":30847,\"start\":30841},{\"end\":30858,\"start\":30851},{\"end\":30868,\"start\":30862},{\"end\":30880,\"start\":30872},{\"end\":31406,\"start\":31402},{\"end\":31412,\"start\":31410},{\"end\":31421,\"start\":31418},{\"end\":31601,\"start\":31598},{\"end\":31610,\"start\":31605},{\"end\":31619,\"start\":31614},{\"end\":31627,\"start\":31623},{\"end\":31633,\"start\":31631},{\"end\":31641,\"start\":31637},{\"end\":31653,\"start\":31645},{\"end\":31659,\"start\":31657},{\"end\":31667,\"start\":31663},{\"end\":31675,\"start\":31671},{\"end\":31682,\"start\":31679},{\"end\":32060,\"start\":32057},{\"end\":32068,\"start\":32064},{\"end\":32076,\"start\":32074},{\"end\":32368,\"start\":32364},{\"end\":32380,\"start\":32372},{\"end\":32498,\"start\":32493},{\"end\":32504,\"start\":32502},{\"end\":32516,\"start\":32508},{\"end\":32523,\"start\":32520},{\"end\":32535,\"start\":32531},{\"end\":32544,\"start\":32541},{\"end\":33004,\"start\":32998},{\"end\":33015,\"start\":33010},{\"end\":33026,\"start\":33021},{\"end\":33039,\"start\":33032},{\"end\":33051,\"start\":33045},{\"end\":33066,\"start\":33059},{\"end\":33439,\"start\":33433},{\"end\":33651,\"start\":33646},{\"end\":33659,\"start\":33655},{\"end\":33670,\"start\":33665},{\"end\":33676,\"start\":33674},{\"end\":33684,\"start\":33680},{\"end\":33694,\"start\":33690},{\"end\":33702,\"start\":33698},{\"end\":34031,\"start\":34027},{\"end\":34042,\"start\":34037},{\"end\":34052,\"start\":34046},{\"end\":34061,\"start\":34058},{\"end\":34071,\"start\":34065},{\"end\":34079,\"start\":34077}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":21981,\"start\":21762},{\"attributes\":{\"id\":\"b1\"},\"end\":22206,\"start\":21983},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":19878149},\"end\":22495,\"start\":22208},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":4246903},\"end\":22836,\"start\":22497},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":18531521},\"end\":23201,\"start\":22838},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":4565301},\"end\":23520,\"start\":23203},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":53768272},\"end\":23953,\"start\":23522},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":9433631},\"end\":24305,\"start\":23955},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":23881916},\"end\":24774,\"start\":24307},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":21725275},\"end\":25198,\"start\":24776},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":118633319},\"end\":25641,\"start\":25200},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":2228574},\"end\":26028,\"start\":25643},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":59604312},\"end\":26460,\"start\":26030},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":1779661},\"end\":26603,\"start\":26462},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":47252984},\"end\":26923,\"start\":26605},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":53035912},\"end\":27426,\"start\":26925},{\"attributes\":{\"id\":\"b16\"},\"end\":27661,\"start\":27428},{\"attributes\":{\"id\":\"b17\"},\"end\":27994,\"start\":27663},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":30981820},\"end\":28550,\"start\":27996},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":43880149},\"end\":28863,\"start\":28552},{\"attributes\":{\"doi\":\"arXiv:1712.06957\",\"id\":\"b20\"},\"end\":29297,\"start\":28865},{\"attributes\":{\"doi\":\"arXiv:1711.05225\",\"id\":\"b21\"},\"end\":29755,\"start\":29299},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":10328909},\"end\":30380,\"start\":29757},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":207553120},\"end\":30777,\"start\":30382},{\"attributes\":{\"id\":\"b24\"},\"end\":31357,\"start\":30779},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":7961631},\"end\":31594,\"start\":31359},{\"attributes\":{\"doi\":\"arXiv:2011.12450\",\"id\":\"b26\"},\"end\":31998,\"start\":31596},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":208175544},\"end\":32322,\"start\":32000},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":58959003},\"end\":32487,\"start\":32324},{\"attributes\":{\"id\":\"b29\"},\"end\":32883,\"start\":32489},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":13097784},\"end\":33392,\"start\":32885},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":43532502},\"end\":33525,\"start\":33394},{\"attributes\":{\"doi\":\"arXiv:2012.04066\",\"id\":\"b32\"},\"end\":33963,\"start\":33527},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":195657814},\"end\":34335,\"start\":33965}]", "bib_title": "[{\"end\":22240,\"start\":22208},{\"end\":22545,\"start\":22497},{\"end\":22896,\"start\":22838},{\"end\":23290,\"start\":23203},{\"end\":23576,\"start\":23522},{\"end\":23995,\"start\":23955},{\"end\":24462,\"start\":24307},{\"end\":24876,\"start\":24776},{\"end\":25310,\"start\":25200},{\"end\":25710,\"start\":25643},{\"end\":26105,\"start\":26030},{\"end\":26475,\"start\":26462},{\"end\":26642,\"start\":26605},{\"end\":26986,\"start\":26925},{\"end\":28092,\"start\":27996},{\"end\":28643,\"start\":28552},{\"end\":29835,\"start\":29757},{\"end\":30452,\"start\":30382},{\"end\":31398,\"start\":31359},{\"end\":32053,\"start\":32000},{\"end\":32360,\"start\":32324},{\"end\":32992,\"start\":32885},{\"end\":33427,\"start\":33394},{\"end\":34023,\"start\":33965}]", "bib_author": "[{\"end\":22057,\"start\":22048},{\"end\":22251,\"start\":22242},{\"end\":22267,\"start\":22251},{\"end\":22561,\"start\":22547},{\"end\":22573,\"start\":22561},{\"end\":22587,\"start\":22573},{\"end\":22595,\"start\":22587},{\"end\":22608,\"start\":22595},{\"end\":22909,\"start\":22898},{\"end\":22918,\"start\":22909},{\"end\":22927,\"start\":22918},{\"end\":22949,\"start\":22927},{\"end\":22958,\"start\":22949},{\"end\":23302,\"start\":23292},{\"end\":23311,\"start\":23302},{\"end\":23323,\"start\":23311},{\"end\":23333,\"start\":23323},{\"end\":23590,\"start\":23578},{\"end\":23606,\"start\":23590},{\"end\":23625,\"start\":23606},{\"end\":23638,\"start\":23625},{\"end\":23649,\"start\":23638},{\"end\":23659,\"start\":23649},{\"end\":23666,\"start\":23659},{\"end\":23679,\"start\":23666},{\"end\":23690,\"start\":23679},{\"end\":23700,\"start\":23690},{\"end\":24006,\"start\":23997},{\"end\":24013,\"start\":24006},{\"end\":24031,\"start\":24013},{\"end\":24047,\"start\":24031},{\"end\":24473,\"start\":24464},{\"end\":24479,\"start\":24473},{\"end\":24492,\"start\":24479},{\"end\":24498,\"start\":24492},{\"end\":24505,\"start\":24498},{\"end\":24887,\"start\":24878},{\"end\":24893,\"start\":24887},{\"end\":24906,\"start\":24893},{\"end\":24912,\"start\":24906},{\"end\":24919,\"start\":24912},{\"end\":24926,\"start\":24919},{\"end\":25321,\"start\":25312},{\"end\":25330,\"start\":25321},{\"end\":25340,\"start\":25330},{\"end\":25350,\"start\":25340},{\"end\":25359,\"start\":25350},{\"end\":25727,\"start\":25712},{\"end\":25740,\"start\":25727},{\"end\":25754,\"start\":25740},{\"end\":25767,\"start\":25754},{\"end\":25774,\"start\":25767},{\"end\":26117,\"start\":26107},{\"end\":26125,\"start\":26117},{\"end\":26134,\"start\":26125},{\"end\":26145,\"start\":26134},{\"end\":26154,\"start\":26145},{\"end\":26486,\"start\":26477},{\"end\":26496,\"start\":26486},{\"end\":26506,\"start\":26496},{\"end\":26653,\"start\":26644},{\"end\":26662,\"start\":26653},{\"end\":26674,\"start\":26662},{\"end\":26680,\"start\":26674},{\"end\":26690,\"start\":26680},{\"end\":26999,\"start\":26988},{\"end\":27011,\"start\":26999},{\"end\":27021,\"start\":27011},{\"end\":27035,\"start\":27021},{\"end\":27044,\"start\":27035},{\"end\":27055,\"start\":27044},{\"end\":27064,\"start\":27055},{\"end\":27075,\"start\":27064},{\"end\":27084,\"start\":27075},{\"end\":27097,\"start\":27084},{\"end\":27534,\"start\":27524},{\"end\":27718,\"start\":27706},{\"end\":27730,\"start\":27718},{\"end\":27738,\"start\":27730},{\"end\":27750,\"start\":27738},{\"end\":27760,\"start\":27750},{\"end\":27772,\"start\":27760},{\"end\":27781,\"start\":27772},{\"end\":27793,\"start\":27781},{\"end\":28103,\"start\":28094},{\"end\":28115,\"start\":28103},{\"end\":28124,\"start\":28115},{\"end\":28139,\"start\":28124},{\"end\":28149,\"start\":28139},{\"end\":28163,\"start\":28149},{\"end\":28179,\"start\":28163},{\"end\":28190,\"start\":28179},{\"end\":28199,\"start\":28190},{\"end\":28213,\"start\":28199},{\"end\":28655,\"start\":28645},{\"end\":28665,\"start\":28655},{\"end\":28878,\"start\":28865},{\"end\":28887,\"start\":28878},{\"end\":28896,\"start\":28887},{\"end\":28904,\"start\":28896},{\"end\":28912,\"start\":28904},{\"end\":28921,\"start\":28912},{\"end\":28929,\"start\":28921},{\"end\":28936,\"start\":28929},{\"end\":28945,\"start\":28936},{\"end\":28955,\"start\":28945},{\"end\":29312,\"start\":29299},{\"end\":29321,\"start\":29312},{\"end\":29328,\"start\":29321},{\"end\":29336,\"start\":29328},{\"end\":29345,\"start\":29336},{\"end\":29353,\"start\":29345},{\"end\":29361,\"start\":29353},{\"end\":29370,\"start\":29361},{\"end\":29382,\"start\":29370},{\"end\":29396,\"start\":29382},{\"end\":29844,\"start\":29837},{\"end\":29850,\"start\":29844},{\"end\":29862,\"start\":29850},{\"end\":29869,\"start\":29862},{\"end\":30468,\"start\":30454},{\"end\":30477,\"start\":30468},{\"end\":30492,\"start\":30477},{\"end\":30502,\"start\":30492},{\"end\":30514,\"start\":30502},{\"end\":30525,\"start\":30514},{\"end\":30533,\"start\":30525},{\"end\":30544,\"start\":30533},{\"end\":30785,\"start\":30779},{\"end\":30794,\"start\":30785},{\"end\":30805,\"start\":30794},{\"end\":30815,\"start\":30805},{\"end\":30828,\"start\":30815},{\"end\":30839,\"start\":30828},{\"end\":30849,\"start\":30839},{\"end\":30860,\"start\":30849},{\"end\":30870,\"start\":30860},{\"end\":30882,\"start\":30870},{\"end\":31408,\"start\":31400},{\"end\":31414,\"start\":31408},{\"end\":31423,\"start\":31414},{\"end\":31603,\"start\":31596},{\"end\":31612,\"start\":31603},{\"end\":31621,\"start\":31612},{\"end\":31629,\"start\":31621},{\"end\":31635,\"start\":31629},{\"end\":31643,\"start\":31635},{\"end\":31655,\"start\":31643},{\"end\":31661,\"start\":31655},{\"end\":31669,\"start\":31661},{\"end\":31677,\"start\":31669},{\"end\":31684,\"start\":31677},{\"end\":32062,\"start\":32055},{\"end\":32070,\"start\":32062},{\"end\":32078,\"start\":32070},{\"end\":32370,\"start\":32362},{\"end\":32382,\"start\":32370},{\"end\":32500,\"start\":32489},{\"end\":32506,\"start\":32500},{\"end\":32518,\"start\":32506},{\"end\":32525,\"start\":32518},{\"end\":32537,\"start\":32525},{\"end\":32546,\"start\":32537},{\"end\":33006,\"start\":32994},{\"end\":33017,\"start\":33006},{\"end\":33028,\"start\":33017},{\"end\":33041,\"start\":33028},{\"end\":33055,\"start\":33041},{\"end\":33068,\"start\":33055},{\"end\":33441,\"start\":33429},{\"end\":33653,\"start\":33644},{\"end\":33661,\"start\":33653},{\"end\":33672,\"start\":33661},{\"end\":33678,\"start\":33672},{\"end\":33686,\"start\":33678},{\"end\":33696,\"start\":33686},{\"end\":33704,\"start\":33696},{\"end\":34033,\"start\":34025},{\"end\":34044,\"start\":34033},{\"end\":34054,\"start\":34044},{\"end\":34063,\"start\":34054},{\"end\":34073,\"start\":34063},{\"end\":34081,\"start\":34073}]", "bib_venue": "[{\"end\":21840,\"start\":21762},{\"end\":22046,\"start\":21983},{\"end\":22325,\"start\":22267},{\"end\":22648,\"start\":22608},{\"end\":22999,\"start\":22958},{\"end\":23344,\"start\":23333},{\"end\":23709,\"start\":23700},{\"end\":24112,\"start\":24047},{\"end\":24520,\"start\":24505},{\"end\":24959,\"start\":24926},{\"end\":25403,\"start\":25359},{\"end\":25818,\"start\":25774},{\"end\":26228,\"start\":26154},{\"end\":26512,\"start\":26506},{\"end\":26745,\"start\":26690},{\"end\":27144,\"start\":27097},{\"end\":27522,\"start\":27428},{\"end\":27704,\"start\":27663},{\"end\":28229,\"start\":28213},{\"end\":28694,\"start\":28665},{\"end\":29047,\"start\":28971},{\"end\":29493,\"start\":29412},{\"end\":29918,\"start\":29869},{\"end\":30557,\"start\":30544},{\"end\":30976,\"start\":30882},{\"end\":31462,\"start\":31423},{\"end\":31766,\"start\":31700},{\"end\":32143,\"start\":32078},{\"end\":32390,\"start\":32382},{\"end\":32646,\"start\":32546},{\"end\":33109,\"start\":33068},{\"end\":33447,\"start\":33441},{\"end\":33642,\"start\":33527},{\"end\":34131,\"start\":34081}]"}}}, "year": 2023, "month": 12, "day": 17}