{"id": 257766788, "updated": "2023-10-05 02:42:34.316", "metadata": {"title": "Learning the Unlearnable: Adversarial Augmentations Suppress Unlearnable Example Attacks", "authors": "[{\"first\":\"Tianrui\",\"last\":\"Qin\",\"middle\":[]},{\"first\":\"Xitong\",\"last\":\"Gao\",\"middle\":[]},{\"first\":\"Juanjuan\",\"last\":\"Zhao\",\"middle\":[]},{\"first\":\"Kejiang\",\"last\":\"Ye\",\"middle\":[]},{\"first\":\"Cheng-Zhong\",\"last\":\"Xu\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2023, "month": null, "day": null}, "abstract": "Unlearnable example attacks are data poisoning techniques that can be used to safeguard public data against unauthorized use for training deep learning models. These methods add stealthy perturbations to the original image, thereby making it difficult for deep learning models to learn from these training data effectively. Current research suggests that adversarial training can, to a certain degree, mitigate the impact of unlearnable example attacks, while common data augmentation methods are not effective against such poisons. Adversarial training, however, demands considerable computational resources and can result in non-trivial accuracy loss. In this paper, we introduce the UEraser method, which outperforms current defenses against different types of state-of-the-art unlearnable example attacks through a combination of effective data augmentation policies and loss-maximizing adversarial augmentations. In stark contrast to the current SOTA adversarial training methods, UEraser uses adversarial augmentations, which extends beyond the confines of $ \\ell_p $ perturbation budget assumed by current unlearning attacks and defenses. It also helps to improve the model's generalization ability, thus protecting against accuracy loss. UEraser wipes out the unlearning effect with error-maximizing data augmentations, thus restoring trained model accuracies. Interestingly, UEraser-Lite, a fast variant without adversarial augmentations, is also highly effective in preserving clean accuracies. On challenging unlearnable CIFAR-10, CIFAR-100, SVHN, and ImageNet-subset datasets produced with various attacks, it achieves results that are comparable to those obtained during clean training. We also demonstrate its efficacy against possible adaptive attacks. Our code is open source and available to the deep learning community: https://github.com/lafeat/ueraser.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2303.15127", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/corr/abs-2303-15127", "doi": "10.48550/arxiv.2303.15127"}}, "content": {"source": {"pdf_hash": "9c3dd8af0a704b12d262432b49b6503d0d96f8a4", "pdf_src": "Arxiv", "pdf_uri": "[\"https://export.arxiv.org/pdf/2303.15127v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "7699864f00f38a4bcdb8b28720eb610ec1763e0d", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/9c3dd8af0a704b12d262432b49b6503d0d96f8a4.txt", "contents": "\nLEARNING THE UNLEARNABLE: ADVERSARIAL AUGMENTATIONS SUPPRESS UNLEARNABLE EXAMPLE ATTACKS A PREPRINT\n\n\nTianrui Qin \nShenzhen Institute of Advanced Technology\nChinese Academy of Sciences\nChina\n\nUniversity of Chinese Academy of Sciences\nChina\n\nXitong Gao \nShenzhen Institute of Advanced Technology\nChinese Academy of Sciences\nChina\n\nJuanjuan Zhao \nShenzhen Institute of Advanced Technology\nChinese Academy of Sciences\nChina\n\nKejiang Ye \nShenzhen Institute of Advanced Technology\nChinese Academy of Sciences\nChina\n\nCheng-Zhong Xu \nUniversity of Macau\nMacauS.A.R., China\n\nLEARNING THE UNLEARNABLE: ADVERSARIAL AUGMENTATIONS SUPPRESS UNLEARNABLE EXAMPLE ATTACKS A PREPRINT\n\nUnlearnable example attacks are data poisoning techniques that can be used to safeguard public data against unauthorized training of deep learning models. These methods add stealthy perturbations to the original image, thereby making it difficult for deep learning models to learn from these training data effectively. Current research suggests that adversarial training can, to a certain degree, mitigate the impact of unlearnable example attacks, while common data augmentation methods are not effective against such poisons. Adversarial training, however, demands considerable computational resources and can result in non-trivial accuracy loss. In this paper, we introduce the UEraser method, which outperforms current defenses against different types of state-of-the-art unlearnable example attacks through a combination of effective data augmentation policies and loss-maximizing adversarial augmentations. In stark contrast to the current SOTA adversarial training methods, UEraser uses adversarial augmentations, which extends beyond the confines of p perturbation budget assumed by current unlearning attacks and defenses. It also helps to improve the model's generalization ability, thus protecting against accuracy loss. UEraser wipes out the unlearning effect with error-maximizing data augmentations, thus restoring trained model accuracies. Interestingly, UEraser-Lite, a fast variant without adversarial augmentations, is also highly effective in preserving clean accuracies. On challenging unlearnable CIFAR-10, CIFAR-100, SVHN, and ImageNet-subset datasets produced with various attacks, it achieves results that are comparable to those obtained during clean training. We also demonstrate the efficacy of UEraser against possible adaptive attacks. Our code is open source and available to the deep learning community 1 . * Equal contribution. Correspondence to Xitong Gao (xt.gao@siat.ac.cn).\n\nIntroduction\n\nDeep learning has achieved great success in fields such as computer vision [13] and natural language processing [8], and the development of various fields now relies on large-scale datasets. While these datasets have undoubtedly contributed significantly to the progress of deep learning, the collection of unauthorized private data for training these models now presents an emerging concern. Recently, numerous poisoning methods [10,15,27,30,33] have been proposed to add imperceptible perturbations to images. These perturbations can form \"shortcuts\" [11,15] in the training data to prevent training and thus make the data unlearnable in order to preserve privacy. It is commonly perceived that the only effective defense against unlearnable examples are adversarial training algorithms [15,30,10]. Popular data augmentation methods such as CutOut [9], MixUp [36], and AutoAugment [5], however, have all been demonstrated to be ineffective defenses.\n\nCurrent methods of unlearnable attacks involves the specification of an p perturbation budget, where p \u2208 {2, \u221e} in general. Essentially, they constrain the added perturbation to a small -ball of p -distance from the source image, in order to ensure stealthiness of these attacks. Adversarial training defenses [20,10] Figure 1: A high-level overview of UEraser for countering unlearning poisons. Note that UEraser recovers the clean accuracy of unlearnable examples by data augmentations. The reported results are for EM [15] unlearnable CIFAR-10 with an \u221e perturbation budget of 8/255. seeks to counteract the bounded perturbations from such unlearnable attacks. However, large defensive perturbations comes with significant accuracy degradations. This prompts the inquiry of the existence of effective defense mechanisms that leverage threat models that are outside the purview of attackers. Specifically, can we devise effective adversarial policies for training models that extend beyond the confines of the p perturbation budgets?\n\nIn this paper, we thus propose UEraser, which performs error-maximizing data augmentation, to defense against unlearning poisons. UEraser challenges the preconception that data augmentation is not an effective defense against unlearning poisons. UEraser expands the perturbation distance far beyond traditional adversarial training, as data augmentation policies do not confine themselves to the p perturbation constraints. It can therefore effectively disrupt \"unlearning shortcuts\" formed by attacks within narrow p constraints. Yet, the augmentations employed by UEraser are natural and realistic transformations extensively utilized by existing works to improve the models' ability to generalize. This, in turn, helps in avoiding accuracy loss due to perturbations used by adversarial training that could potentially be out-of-distribution. Finally, traditional adversarial training is not effective in mitigating unlearning poisons produced by adaptive attacks [10], while UEraser is highly resiliant against adaptive attacks with significantly lower accuracy reduction.\n\nIn summary, our work has three main contributions:\n\n\u2022 It extends adversarial training beyond the confines of the p perturbation budgets commonly imposed by attackers into data augmentation policies.\n\n\u2022 We propose UEraser, which introduces an effective adversarial augmentation to wipe out unlearning perturbations. It defends against the unlearnable attacks by maximizing the error of the augmented samples.\n\n\u2022 UEraser is highly effective in wiping out the unlearning effect on five state-of-the-art (SOTA) unlearning attacks, outperforming existing SOTA defense methods.\n\n\u2022 We explore the adaptive attacks on UEraser and explored additional combinations of augmentation policies. It lays a fresh foundation for future competitions among unlearnable example attack and defense strategies.\n\nUnlearnable example attacks bear great significance, not just from the standpoint of privacy preservation, but also as a form of data poisoning attack. It is thus of great significance to highlight the shortcomings of current attack methods. Perhaps most surprisingly, even a well-known unlearnable attack such as EM [15] is unable to impede the effectiveness of UEraser. By training a ResNet-18 model from scratch using exclusively CIFAR-10 unlearnable data produced with EM (with an \u221e budget of 8/255), UEraser achieves exceptional accuracy of 95.24% on the clean test set, which closely matches the accuracy achievable by standard training on a clean training set. This suggests that existing unlearning perturbations are tragically inadequate in making data unlearnable, even with adaptive attacks that employs UEraser. By understanding their weaknesses, we can anticipate how malicious actors may attempt to exploit them, and prepare stronger safeguards against such threats. We hope UEraser can help facilitate the advancement of research in these attacks and defenses.\n\n\nRelated Work\n\nAdversarial examples and adversarial training. Adversarial examples deceive machine learning models by adding adversarial perturbations, often imperceptible to human, to source images, leading to incorrect classification results [12,29]. White-box adversarial attacks [29] maximize the loss of a source image with gradient descent on the defending model to add adversarial perturbations onto an image to maximize its loss on the model. Effective methods to gain adversarial robustness usually involve adversarial training [20], which leverages adversarial examples to train models. Adversarial training algorithms thus solve the min-max problem of minimizing the loss function for most adversarial examples within a perturbation budget, typically bounded in p . Recent years have thus observed an arms race between adversarial attack strategies and defense mechanisms [3,4,34,35].\n\nData poisoning. Data poisoning attacks manipulate the training of a deep learning model by injecting malicious and poisoned examples into its training set [1,28]. Data poisoning methods [2,23] achieve their malicious objectives by stealthily replacing a portion of training data, and successful attacks can be triggered with specially-crafted prescribed inputs. Effective data poisoning attacks typically perform well on clean data and fail on data that contains triggers [18].  [33] reveals that if the perturbations of unlearnable samples are assigned to the corresponding target label, they are linearly separable. It thus proposes linearly separable perturbations in response to this characteristic and show great effectiveness. Autoregressive poisoning (AR) [27] proposes a generic perturbation that can be applied to different datasets and architectures. The perturbations of AR are generated from dataset-independent processes.\nUnlearnable\nData augmentations. Data augmentation techniques increase the diversity of training data by applying random transformations [17] (such as rotation, flipping, cropping, etc.) to images, thereby improving the model's generalization ability. Currently, automatic search-based augmentation techniques such as TrivialAugment [21] and AutoAugment [5], can further improve the performance of trained DNNs by using a diverse set of augmentation policies. TorMentor [24], an image-augmentation framework, proposes fractal-based data augmentation to improve model generalization. Current unlearnable example methods [10,15,27,30,33] demonstrate strong results under an extensive range of data augmentation methods. Despite prevailing beliefs on their ineffectiveness against unlearnable examples, UEraser challenges this preconception, as it searches for adversarial policies with error-maximizing augmentations and achieves the state-of-art defense performance against existing unlearnable example attacks.\n\n3 The UEraser Defense\n\n\nPreliminaries on Unlearnable Example Attacks and Defenses\n\nAttacker. We assume the attacker has access to the original data they want to make unlearnable, but cannot alter the training process [18]. Typically, the attacker attempts to make the data unlearnable by adding perturbations to the images to prevent trainers from using them to learn a classifier that generalize well to the original data distribution. Formally, suppose we have a dataset consisting of original clean examples D clean = {(x 1 , y 1 ), . . . , (x n , y n )} drawn from a distribution S, where x i \u2208 X is an input image and y i \u2208 Y is its label. The attacker thus aims to construct a set of sample-specific unlearning perturbations \u03b4 = {\u03b4 x |x \u2208 X }, in order to make the model f \u03b8 : X \u2192 Y trained on the unlearnable examples set D ue (\u03b4) = {(x + \u03b4 x , y) | (x, y) \u2208 D clean } perform poorly on a test set D test sampled from S:\nmax \u03b4 E (xi,yi)\u223cDtest [L(f \u03b8 (\u03b4) (x i ), y i )], s.t. \u03b8 (\u03b4) = argmin \u03b8 (xi,yi)\u2208Due(\u03b4) L(f \u03b8 (x i ), y i ),(1)\nwhere L is the loss function, typically the softmax cross-entropy loss. For each image, the noise \u03b4 i is bounded by\n\u03b4 i p \u2264 ,\nwhere is a small perturbation budget such that it may not affect the intended utility of the image, and \u00b7 p denotes the p norm. Table 1 provides samples generated by unlearnable example attacks and their corresponding perturbations (amplified with normalization). Defender. The goal of the defender is to ensure that the trained model learns from the poisoned training data, allowing the model to be generalized to the original clean data distribution D clean . The attacker assumes full control of its training process. In our context, we thus assume that the attacker's policy is to perform poison removal on the image, in order to ensure the trained model generalizes even when trained on poisoned data D ue . It has been shown in [15,30,10] that Adversarial training [20] is effective against unlearnable examples, which optimizes the following objective:\narg min \u03b8 E (x,y)\u223cDue max \u03b4adv p \u2264 L(f \u03b8 (x + \u03b4 adv ), y) .(2)\nSpecifically for each imagex \u2208 D ue , it finds an adversarial perturbation \u03b4 adv that maximizes the classifier loss. It then performs gradient descent on the maximal loss to optimize for the model parameters \u03b8. A model trained on the unlearnable set D ue in this manner thus demonstrates robustness to perturbations in the input, and can generalize to clean images.\n\n\nAdversarial Augmentations\n\nGeirhos et al. [11] reveal that models tend to learn \"shortcuts\", i.e., unintended features in the training images. These shortcuts negatively impact the model's generalization ability. Intuitively, unlearnable example attacks thus leverage such shortcuts to generate effective perturbations to impede learning from the poisoned examples. Subsequently, existing adversarial training defenses [15,30,10] attempt to remove these shortcuts from training images with adversarial perturbations. This is done to counter the effects of the unlearning perturbations.\n\nIt is natural to think that augmentation policies may be a dead end against unlearnable attacks, as none of the existing strong data augmentation methods show significant effectiveness (Table 3). Adversarial training can also be viewed as a practical data augmentation policy, which presents an interesting perspective as it allows the model to choose its own policy in the form of p -bounded perturbations adaptively. However, it poses a considerable challenge due to its use of large defensive perturbations, often resulting in reduced accuracy. This begs the question of whether new defense mechanisms can leverage unseen threat models that unlearnable attacks may be unable to account for.\n\nInspired by this, we introduce UEraser, which performs adversarial augmentations polices that preserves to the semantic information of the images rather than adding p -bounded adversarial noise. Our objective is a bi-level optimization, where the inner level samples image transformation policies T (\u00b7) from a set of all possible augmentations A, in order to maximize the loss, and the outer level performs model training with adversarial polices:\narg min \u03b8 E (x,y)\u223cDue max T \u223cA L(f \u03b8 (T (x)), y) .(3)\nIntuitively, UEraser finds the most \"adversarial\" augmentation policies for the current images, and use that to train the model in order to prevent unlearnable \"shortcuts\" from emerging during model training. Compared to adversarial training methods that confine the defensive perturbations within a small -ball of p distance, here we adopt a different approach that allows for a more aggressive distortion. Moreover, augmentation policies also effectively preserve the original semantics in the image. By maximizing the adversarial loss in this manner, the model can thus avoid training from the unlearning \"shortcuts\" and instead learn from the original features.\n\nTo generate augmentation policies with high-level of distortions, we select PlasmaTransform [24], and TrivialAugment [21], two modern suites of data augmentation policies, and ChannelShuffle in sequence, to form a strong pipeline of data augmentations polices. PlasmaTransform performs image distortion with fractal-based transformations. Triv-ialAugment provide a suite of natural augmentations which shows great generalization abilities that can train models with SOTA accuracies. Finally, ChannelShuffle swaps the color channels randomly, this is added to further increase the aggressiveness of adversarial augmentation policies. Interestingly, using this pipeline without the error-maximization augmentation sampling can also significantly reduce the effect of unlearning perturbations. We denote this method as UEraser-Lite, as it requires only 1 augmentation sample per training image. Compared to UEraser, although UEraser-Lite may not perform as well as UEraser on most datasets, it is more practical than both UEraser-Lite and adversarial training due to its faster training speed.\n\nFinally, we provide an algorithmic overview of UEraser in Algorithm 1. It accepts as input the poisoned training dataset D ue , batch size B, randomly initialized model f \u03b8 , number of training epochs N , number of error-maximizing augmentation epochs W , learning rate \u03b1, number of repeated sampling K, and a suite of augmentation policies A. For each sampled mini-batch x, y of data points from the dataset, it applies K different random augmentation policies for each image in x, and compute the corresponding loss values for all augmented images. It then selects for each image in x, the maximum loss produced by its K augmented variants. The algorithm then uses the averaged loss across the same mini-batch to perform gradient descent on the model parameters. Finally, the algorithm returns the trained model parameters \u03b8 after completing the training process.\n\nAlgorithm 1 Training with UEraser.\n1: function UERASER(D ue , B, f \u03b8 , N, W, \u03b1, K, A) 2: for n \u2208 [1, . . . , N ] do 3: if n \u2265 W then K \u2190 1 end if\nDisable adversarial augmentations after warmup. 4: for (x, y) \u223c minibatch(D ue , B) do Mini-batch sampling. 5:\nfor i \u2208 [1, . . . , B] do\nFor each image in mini-batch. . . 6: for j \u2208 [1, . . . , K] do . . . repeat K augmentations. 7: aug \u223c A Sample augmentation policy. . . 8: Datasets. We select four popular datasets for the evaluation of UEraser, namely, CIFAR-10 [16], CIFAR-100 [16], SVHN [22], and an ImageNet [7] subset. Following the setup in EM [15], we use the first 100 classes of the full dataset as the ImageNet-subset, and resize all images to 32 \u00d7 32. We evaluate the effectiveness of UEraser by examining the accuracies of the trained models on clean test examples, i.e., the higher the clean test accuracy, the greater its effectiveness. By default, all target and surrogate models use ResNet-18 [13] if not otherwise specified. We explore the effect of UEraser on partial poisoning (Section 4.2), larger perturbation budgets (Section 4.4), different network architectures (Section 4.5), transfer learning (Section 4.8), and perform ablation analyses in Sections 4.6 and 4.7. Finally, Appendix B provides additional sensitivity analyses.\nL ij \u2190 L(f \u03b8 (aug(x i )), y i ) . . .\nTraining settings. We train the CIFAR-10 model for 200 epochs, SVHN model for 150 epochs, and CIFAR-100 and ImageNet-subset models for 300 epochs due to the use of strong augmentation policies. We adopt standard random cropping and flipping for all experiments by default as standard training baselines and introduce additional augmentations as required by the compared methods. For the optimizer, we use SGD with a momentum of 0.9 and a weight decay of 5 \u00d7 10 \u22124 . By default, the learning rate is fixed at 0.01. We follow the dataset setup in respective attacks, where all unlearning perturbations are bounded within \u221e = 8/255 or 2 = 1.0. For UEraser, we divided the training process into two parts for speed: the adversarial augmentation process, and the standard training process. In the first stage, we used the loss-maximizing augmentations for training, with a default number of repeated samples K = 5 (as the input to Algorithm 1). In the second stage, we used the UEraser-Lite process which sets K = 1. This approach allows us to keep a balance between suppressing the emergence of unlearning shortcuts and training speed. We further explore full training with loss-maximizing augmentation in Section 4.7, which attains the highest known test accuracies. Finally, Table 2 shows the effect of UEraser on five different unlearnable methods. Additional information regarding the training setup and hyperparameters can be found in Appendix A. The details of the attack and defense baselines are available in Appendix C. \n\n\nMain Evaluation\n\nTo demonstrate the effectiveness of UEraser, we select five SOTA unlearnable example attacks: Error-Minimization (EM) [15], Hypocritical Perturbations (HYPO) [30], Robust Error-Minimization (REM) [10], Linear-separable Synthetic Perturbations (LSP) [33], and Autoregressive Poisoning (AR) [27]. Experimental results show that UEraser has achieved better results than the SOTA defense methods: Image shortcut squeezing (ISS) [19] and adversarial training [20]. For EM, REM, and HYPO, We use the same model (ResNet-18) as the surrogate and target model. All unlearnable methods have a poisoning rate of 100%. From the experimental results of UEraser on CIFAR-10 dataset shown in Table 2, we can conclude that UEraser can achieve better defensive results than ISS and adversarial training in most cases. Note that the adversarial training experiments use the same type of perturbation, which is equal to half the size of the unlearned perturbation. Specifically, the perturbation radius is \u221e = 4/255 for EM, REM, and HYPO, and 2 = 0.5 for LSP and AR. We consider sample-wise perturbations for all experiments. UEraser-Lite contains a series of augmentations that effectively break through unlearned perturbation while also slightly affecting the clean accuracy. Therefore, applying the UEraser-Lite augmentation on clean data may even lead to accuracy degradation, and this degradation is further increased when applying the UEraser. When error-maximizing augmentation is used throughout the training phase, the model requires more epochs to converge but achieves a higher accuracy rate (95.24%).\n\nIn Table 4, We further validate the effect of UEraser on CIFAR-100, SVHN and ImageNet-subset. We select the popular method (EM) and the latest attacks for the experiments (LSP and AR). Note that since UEraser increases the diversity of the data with strong augmentations, it requires more training epochs to achieve converged accuracies. All results are thus evaluated after 300 training epochs for CIFAR-100 and ImageNet-subset and 150 training epochs for SVHN. Experimental results show that UEraser achieves SOTA results on all three datasets.   \n\n\nPartial Poisoning\n\nIn practical scenarios, attackers may only have partial control over the training data [15], thus it is more practical to consider the scenario where only a part of the data is poisoned. We adopt EM [15] and LSP [33] on the CIFAR-10 dataset as an example for our discussions. Following the same setup, we split varying percentages from the clean data to carry out unlearnable poisoning and mix it with the rest of the clean training data for the target model training. UEraser is applied during model training to explore its effectiveness against partial poisoning. Figures 3a and 3b, show that when the poisoning ratio is low (< 40%), the effect of the poisoning is negligible. Another type of partial dataset attack scenario is the selection of a targeted class to poison. We thus poison all training samples of the 9 th label (\"truck\"), and  \n\n\nAdaptive Poisoning\n\nSince UEraser is composed of multiple data augmentations, we should consider possible adaptive unlearnable example attacks which may leverage UEraser to craft poisons against it. We therefore evaluate UEraser in a worst-case scenario where the adversary is fully aware of our defense mechanism, in order to reliably assess the resilience of UEraser against potential adaptive attacks. Specifically, we design an adaptive unlearning poisoning attack by introducing an additional data augmentation during the training, We adopt the error-minimization (EM) attack [15] as an example. The EM unlearning objective solves the following min-min optimization:\n\narg min\n\u03b4 min \u03b8 E (x,y)\u223cDclean [L(f \u03b8 (x + \u03b4 x ), y)],(4)\nwhere \u03b4 p \u2264 . Similar to the REM [10] that generates adaptive unlearnable examples under adversarial training, each image x optimizes its unlearning perturbation \u03b4 x before performing adversarial augmentations:\narg min \u03b4 min \u03b8 E (x,y)\u223cDclean [L(f \u03b8 (T adv (x + \u03b4 x )), y)],(5)\nwhere T adv (\u00b7) denotes the adversarial augmentations with UEraser. We select different combinations of augmentations for our experiments, and the results are shown in Table 5. The hyperparameters of the augmentations employed in all experiments are kept consistent with those of UEraser. We observe that the adaptive augmentation of unlearning poisons do not significantly reduce the effectiveness of UEraser. As it encompasses a diverse set of augmentation policies and augmentation intensities, along with loss-maximizing augmentation sampling, adaptive poisons are hardly effective. Moreover, we speculate that the affine and cropping transformations in TrivialAugment can cause unlearning perturbations to be confined to a portion of the images, which also limits the effectiveness of unlearning poisons. Because of the aggressiveness of the augmentation in image transformations extend beyond the p bounds, adaptive poisons do not perform as well under UEraser as they do against REM. To summarize, it is challenging for the attacker to achieve successful poisoning against UEraser even if it observes the possible transformations taken by the augmentations. \n\n\nLarger Perturbation Scales\n\nWill the performance of UEraser affected by large unlearnable perturbations? To verify, we evaluate the performance of UEraser on unlearnable CIFAR-10 dataset with even larger perturbations. We use the example of error-maximizing (EM) attack and increase the \u221e perturbation from 8/255 to 24/255 to examine the efficacy of UEraser on a more severe unlearning perturbation scenario. We also include adversarial training (AT) as a defense baseline with a perturbation bound of 8/255. The experimental results in Table 6 confirm the effectiveness of UEraser under large unlearning noises. \n\n\nResilience against Architecture Choices\n\nCan UEraser show resilience against architecture choices? In a realistic scenario, we need to train the data with different network architectures. We thus explore whether UEraser can wipe out the unlearning effect under different architectures. Table 7 shows the corresponding results. It is clear that UEraser is capable of effectively wiping out unlearning poisons, across various network architectures.\n\n\nAugmentation Options\n\nIn this section, we investigate the impact of the UEraser policy composition on the mitigation of unlearning effects. The visualization of the three policies included is shown in Figure 2. We conduct experiments with the unlearnable examples from CIFAR-10 generated by the EM [15] method, and Table 8 explore effectiveness of the various combinations of augmentation policies. ISS [19] discovered that for the unlearnable examples generated by the EM attack, a grayscale filter easily removes the unlearning poisons. Additionally, setting the value of each channel to the average of all color channels or to the value of any color channel also considerately achieves the same effect. However, we show that using only ChannelShuffle does not yield satisfactory results. We have also discovered an interesting phenomenon: PlasmaTransform and ChannelShuffle are essential for mostly restoring the accuracies, whereas TrivialAugment, can be substituted with a similar policy, i.e. AutoAugment [5]. Only when the three policies are employed together can the effect of unlearning poisons be effectively wiped out. This also proves that the UEraser policies are effective and reasonable. Recall that we also found the adoption of error-maximizing augmentation results in an overall improvement on all five unlearning poisons. Hence, the utilization of error-maximizing augmentation during training serves as an effective means to mitigate the challenges of training with unlearning examples and improve the model's clean accuracy.\n\n\nAdversarial Augmentations and Error-Maximizing Epochs\n\nFrom Algorithm 1, the training of UEraser is affected by two hyperparameters, namely, the numbers of repeated augmentation samples K per image and the epochs of error-maximizing augmentations W . For CIFAR-10, The clean accuracy of the unlearnable examples can be improved to around 80% after 50 epochs of training using error-maximizing augmentation. We explored UEraser-Max which applies error-maximizing augmentations throughout the entire training phase, and it attains best known accuracies. The results are shown in Table 9. Alternatively, one can continue the training with UEraser-Lite can improve the clean accuracy to \u2265 93% to save computational costs. Although UEraser-Max achieves the highest clean accuracy, we mainly focus on UEraser in this paper, due to its high computational cost per epoch and longer training epochs.\n\nRegarding the number of samples K (by default K = 5), increasing it further enhances the suppression of unlearning shortcuts during model training, but also more likely to lead to gradient explosions at the beginning of model training. Therefore, it may be necessary to apply learning rate warmup or gradient clipping with increased number of repeated sampling. Larger K can also results in higher computational costs, as it result in more samples per image for training. We provide a sensitivity analysis of the number of repeated sampling K in Appendix B.\n\n\nTransfer Learning\n\nIn this section, we aim to explore the impact of transfer learning [6,31] on the efficacy of unlearnable examples. We hypothesize that pretrained models may learn certain in-distribution features of the unaltered target distribution, it may be able to gain accuracy even if the training set contains unlearning poisons. To this end, we adopt a simple transfer learning setup, where we use the pretrained ResNet-18 model available in the torchvision repository [25]. To fit the expected input shape of the feature extractor, we upsampled the input images to 224 \u00d7 224. The final fully-connected classification layer of the pretrained model was replaced with a randomly initialized one with 10 logit outputs. We then fine-tune the model with unlearnable CIFAR-10 training data. We also further explored fine-tuning on unlearnable data with our defenses. For control references, we fine-tuned a model with clean training data, and also trained a randomly initialized model from scratch with poisoned training data.  The results of the experiments are shown in Figure 4. Figure 4b shows that fine-tuning with unlearnable examples can improve the clean test accuracy from 22% to 66%. Additionally in Figure 4c, we find that simply upsampling the unlearnable samples to use more compute and have larger feature maps does not significantly weaken the unlearning attack (test accuracy increased to 34%). Most importantly, UEraser successfully eliminates the negative impact of unlearning poisons, which enables the model to utilize pretrained knowledge effectively. This enables the fine-tuned model to achieve a test accuracy of approximately 95% as shown in Figure 4d.\n\n\nDiscussion\n\nIn this section, we investigate limitations of UEraser and the potential use cases of the provided options. We compared UEraser-Lite training with normal training and found that UEraser-Lite requires more training rounds to converge due to data augmentation policies. For instance, CIFAR-10 typically converges with 60 epochs of normal training, whereas it requires more than 150 epochs of training to reach full convergence with UEraser-Lite. With respect to UEraser-Max and UEraser, the error-maximizing augmentations consumes the same amount of floating-point operations (FLOPs) as adversarial training, if K is the same as the adversarial attack steps. However, we note that our approach is easily parallelizable, but adversarial training approaches are not, with compute dependences between adversarial iterations. One can choose between UEraser-Max, UEraser-Lite and UEraser depending on their requirements. UEraser-Max can be preferred if seeking higher clean accuracy, whereas UEraser or UEraser-Lite can be a practical option for faster training with nearly the same accuracies.\n\nDespite acknowledging that a malicious party may exploit the approach suggested in this paper, we believe that the ethical approach for the open-source deep learning community is not to withhold information but rather to increase awareness of these risks.\n\n\nConclusion\n\nUsing the intuition of disrupting the unlearning perturbation with perturbations beyond the p budgets, we propose a simple yet effective defense method called UEraser, which can mitigate unlearning poisons and restore clean accuracies.\n\nUEraser achieves robust defenses on unlearning poisons with simple data augmentations and adversarial augmentation policies. Similar to adversarial training, it employs error-maximizing augmentation to further eliminate the impact of unlearning poisons. Our comprehensive experiments on five state-of-the-art unlearnable example attacks demonstrate that UEraser outperforms existing countermeasures such as adversarial training [15,10,30]. We also evaluate adaptive poisons and transfer learning on UEraser. Our results suggest that existing unlearning perturbations are tragically inadequate in making data unlearnable. By understanding the weaknesses of existing attacks, we can anticipate how malicious actors may attempt to exploit them, and prepare stronger safeguards against such threats. We hope UEraser can help facilitate the advancement of research in these attacks and defenses. Our code is open source and available to the deep learning community for scrutiny 2 . ImageNet-subset refers to a dataset constructed with the first 100 classes from ImageNet resized to 32 \u00d7 32, following the setup in [15] for fair comparisons. The training set comprises approximately 120,000 images, and the test set contains 5,000 images. Table 10 shows the detail specifications of these datasets.   \n\n\nA.3 Standard Augmentation\n\nFor CIFAR-10, SVHN, and CIFAR-100 baselines to compare against, we perform data augmentation via random flipping, and random cropping to 32\u00d732 images on each image. For the ImageNet-subset, we perform data augmentation with a 0.875 center cropping, followed with a resize to 32 \u00d7 32, and random flipping for each image.\n\n\nA.4 Unlearning Perturbution Budgets\n\nThe attacks, EM [15], REM [10], and HYPO [30], all have a permitted perturbation bound of \u221e = 8/255 for each image. Additionally, the LSP [33] and AR [27] attacks permit 2 = 1.0.\n\n\nA.5 Adversarial Training\n\nFor comparison, the baseline defenses against the five methods (EM, REM, HYPO, LSP, and AR) on CIFAR-10 employ PGD-7 adversarial training [20], following the evaluation of [10]. The adversarial training perturbation bounds used were \u221e = 4/255 for EM, REM and HYPO, and 2 = 0.5 for LSP and AR as baseline defenses.\n\n\nA.6 Hyperparameters for UEraser\n\nUEraser comprises three composite augmentations (PlasmaTransform, ChannelShuffle, TrivialAugment). We implement augmentations using Kornia 3 , specifically, with kornia.augmentation.RandomPlasmaBrightness, kornia.augmentation.RandomChannelShuffle, and kornia.augmentation.auto.TrivialAugment.\n\nHere, TrivialAugment uses the default hyperparameters, Table 13 shows the hyperparameter settings for the remaining augmentations. Finally, Figure 5 provides the visualization of the augmentation effects on different dataset examples. \n\n\nB Sensitivity Analysis\n\nHere, we provide a sensitivity analysis of the number of repeated sampling K using in adversarial augmentation. We also explore the effect of increasing the number of training epochs under UEraser. Taking the example of unlearnable CIFAR-10 produced with EM [15], Table 14 shows the results of UEraser with various combinations of different numbers of repeated augmentation sampling K and the total number of training epochs E. Higher K values can effectively improve the defense performance of UEraser, with a training cost increasing proportionally with K. More training epochs can also improve the performance of UEraser, and even matches the test accuracy of training with clean data. Finally, Figure 6 provides the train and test accuracy curves w.r.t. the number of training epochs for different (E, K) configurations.  \n\n\nCIFAR-10\n\n\nPlasmaContrast\n\n\nC Attack and Defense Baselines\n\nWe use five baseline attacks and two exisiting SOTA defenses for evaluation and comparisons in our experiments (Table 15). Each attack method is implemented from their respective official source code for a fair comparison. We adopt experimental setup identical to the original publications, and use perturbation budgets described in Appendix A.4. For defenses, we compare UEraser variants against the current SOTA techniques, image shortcut squeezing [19] and adversarial training [20]. The compared defenses (ISS and adversarial training) respectively follow the original source code and PGD-7 adversarial training [20]. Table 14: Clean test accuracies (%) of different numbers of repeated augmentation sampling K for UEraser. Note that K = 1 denotes UEraser-Lite, and the number of error-maximizing epochs W = 50, \"-\" means K = 1 is not applicable for UEraser-Max. The unlearnable training data is generated with EM on CIFAR-10, and a standard ResNet-18 trained on this data attains a test accuracy of 21.21%.    \n\nFigure 2 :\n2The Visualization of UEraser augmentations.\n\n\nFigures 3c and 3dshows the prediction confusion matrices of ResNet-18 trained on CIFAR-10. In summary, UEraser demonstrates significant efficacy in partial poisoning scenarios.\n\nFigure 3 :\n3The defensive efficacy of UEraser against partial poisoning. (a) EM with different poisoning ratios; (b) LSP with different poisoning ratios. (c), (d) Prediction confusion matrices on the clean test set of ResNet-18 trained on CIFAR-10 with an unlearnable class (the 9 th label 'truck'). (c) Standard training; (d) UEraser training.\n\n\nTrain and test accuracies of transfer learning with UEraser.\n\nFigure 4 :\n4Accuracies w.r.t. the number of training / fine-tuning epochs for randomly initialized / pretrained ResNet-18 on different CIFAR-10 datasets. (a) Fine-tuning the pretrained model on a clean training set. (b) Fine-tuning the pretrained model with unlearnable training set generated with EM [15]. (c) Comparing the test accuracies by training from scratch with either 32 \u00d7 32 or upsampled 224 \u00d7 224 unlearnable examples. (d) Fine-tuning on unlearnable data with UEraser.\n\n\n10 consists of 60,000 32 \u00d7 32 resolution images, of which 50,000 images are the training set and 10,000 are the test set. This dataset contains 10 classes, each with 6000 images.CIFAR-100 is similar to CIFAR-10. It has 100 classes, Each class has 600 images of size 32 \u00d7 32, of which 500 are used as the training set and 100 as the test set.SVHN, derived from Google Street View door numbers, is a dataset of cropped images containing sets of Arabic numerals '0-9'. The dataset consists of 73,257 digit images in the training set and 26,032 digit images in the test set.\n\n\nof augmented images of ImageNet.\n\nFigure 5 :\n5The visualization of various augmentations on different datasets.\n\n\nUEraser with K = 10.\n\nFigure 6 :\n6Train and test accuracy curves w.r.t. the number of training epochs. The subfigures correspond to UEraser under K \u2208 {1, 5, 10} and UEraser-Max under K \u2208 {3, 5, 10}. Recall that K is the number of repeated augmentation sampling.\n\n\nrepresent a defense mechanism thatase \nTrain ph \n\nard \nd \nStan \n\nser \na \nUEr \n\nClean Data \n\n21.24 \n\n95.24% \n\nTest phase \n\nTest accuracy \n\nTest accuracy \n\n% \n\n\n\n\ntraining examples on a trained model, making them difficult to learn by deep learning models. By introducing noise that minimizes the error of all training examples, the model instead learns \"shortcut\" of such perturbations, resulting in inability to learn from such data. Hypocritical perturbations (HYPO)[30] follows a similar idea but uses a pretrained surrogate rather than the above min-min optimization. As the above method cannot defend against adversarial training, Robust Error-Minimizing (REM)[10] uses an adversarially-trained model as an adaptively attack to generate stronger unlearnable examples. INF[32] enables samples from different classes to share non-discriminatory features to improve resistance to adversarial training. Linear-separable Synthetic Perturbations (LSP)examples. Unlearnable examples attacks are a type of data poisoning methods with bounded perturbation \nthat aims to make learning from such examples difficult. Unlike traditional data poisoning methods, unlearnable \nexamples methods usually require adding imperceptible perturbations to all examples [10, 15, 27, 30, 33]. Error-\nminimizing (EM) [15] poison generates imperceptible perturbations with a min-min objective, which minimizes the \nerrors of \n\nTable 1 :\n1The visualization of unlearned examples and perturbations of five poisoning methods on CIFAR-10.Clean \nEM [15] \nREM [10] \nHYPO [30] \nLSP [33] \nAR [27] \n\nPerturbations \n\nType \n\u221e bounded, = 8/255 \n2 bounded, = 1 \n\n\n\n\nevaluate the loss function for the augmented image.\u2190 max j\u2208[1,...,K] L ijFind the augmented image with maximum loss.\u03b8 \u2190 \u03b8 \u2212 \u03b1\u2207 \u03b8 1 B i\u2208[1,...,B] L advGradient decent on the mini-batch of max-loss images.9: \n\nend for \n\n10: \n\nL adv \n\ni \n\n11: \n\nend for \n\n12: \n\ni \n\n13: \n\nend for \n\n14: \n\nend for \n\n15: \n\nreturn \u03b8 \n16: end function \n\n4 Experimental Setup & Results \n\n\n\nTable 2 :\n2Clean test accuracies (%) of UEraser on CIFAR-10. All experiments are conducted on the ResNet-18 architecture. When training on clean data with UEraser-Lite and UEraser the accuracy is 93.94% and 93.66% respectively. Note that ISS[19] contains three strategies (Grayscale, JPEG, and BDR), and we report the results of their best strategy. More specifically, Grayscale for EM and REM, JPEG for HYPO, LSP, and AR. For reference, we show the accuracies for \"Adversarial Training\" with clean training samples in \"Clean\".Methods \nStandard Training \nUEraser-Lite UEraser ISS [19] \nAdversarial Training \nClean Unlearnable \nClean Unlearnable \n\nEM \n\n94.78 \n\n21.24 \n90.78 \n93.38 \n78.05 \n88.71 \n86.24 \nREM \n33.12 \n85.49 \n91.02 \n80.78 \n87.15 \n49.17 \nHYPO \n72.12 \n85.67 \n87.59 \n84.77 \n91.45 \n88.90 \nLSP \n14.95 \n84.92 \n85.07 \n82.71 \n81.24 \n80.15 \nAR \n12.04 \n92.08 \n93.16 \n84.67 \n81.09 \n81.28 \n\n\n\nTable 3 :\n3Clean test accuracies (%) of ResNet-18 models trained on CIFAR-10 unlearnable examples with various attack and augmentation combinations. \"Standard\" denotes standard random crop and flip augmentations.Methods \nStandard CutOut [9] MixUp [36] CutMix [9] \n\nEM [15] \n21.21 \n19.30 \n58.51 \n22.40 \nREM [10] \n25.44 \n26.54 \n29.02 \n34.48 \nHYPO [30] \n23.69 \n27.14 \n35.44 \n29.33 \nLSP [33] \n17.78 \n10.67 \n41.52 \n23.84 \nAR [27] \n11.75 \n11.90 \n11.40 \n11.23 \n\nPlasmaTransform \nChannelShuffle TrivialAugment \nUeraser \nOriginal \n\n\n\nTable 4 :\n4Clean test accuracies (%) of UEraser on CIFAR-100, SVHN, and ImageNet-subset. The results of ISS[19] are from the best strategy (Grayscale for EM and JPEG for LSP). ' \u2020' denotes the ImageNet-subset of the first 100 classes and resized to 32 \u00d7 32.Dataset \nClean +UEraser-Lite Methods Standard UEraser-Lite UEraser ISS [19] \n\nCIFAR-100 74.83 \n73.22 \n\nEM \n13.15 \n70.04 \n71.14 \n54.92 \nLSP \n4.09 \n67.38 \n68.42 \n51.35 \nAR \n4.79 \n66.74 \n69.35 \n57.34 \n\nSVHN \n96.12 \n95.85 \n\nEM \n10.58 \n88.73 \n91.22 \n89.91 \nLSP \n14.56 \n92.64 \n92.79 \n92.17 \nAR \n10.24 \n93.04 \n93.83 \n91.89 \n\nImageNet  \u2020 \n78.67 \n77.94 \nEM \n17.83 \n70.02 \n71.47 \n55.44 \nLSP \n10.04 \n65.12 \n63.87 \n52.27 \n\n\n\nTable 5 :\n5Adaptive poisoning with EM on CIFAR-10. 'P', 'C,' and 'T' denote PlasmaTransform, ChannelShuffle, and \nTrivialAugment respectively. \"Standard\" represents standard training. \nMethods \nStandard UEraser-Lite UEraser \n\nBaseline \n21.21 \n90.78 \n93.38 \n+ P \n24.36 \n86.05 \n92.55 \n+ C \n19.71 \n83.46 \n91.72 \n+ P + C \n25.48 \n82.49 \n89.07 \n+ P + C + T \n44.26 \n85.22 \n90.79 \n\n\n\nTable 6 :\n6Increasing the perturbation budget of the EM attack on unlearnable defenses.Perturbation scale \nStandard Training UEraser-Lite UEraser Adversarial Training \n\n8/255 \n21.24 \n90.78 \n93.38 \n86.24 \n16/255 \n22.63 \n86.65 \n89.24 \n83.12 \n24/255 \n21.05 \n82.40 \n84.59 \n79.31 \n\n\n\nTable 7 :\n7Clean test accuracies (%) of different architectures (ResNet-50 [13], DenseNet-121 [14], MobileNet-V2 [26]) \non CIFAR-10. Note that EM is tested with \u221e = 8/255 and LSP is tested with 2 = 1. \nMethods \nResNet-50 DenseNet-121 MobileNet-V2 \n\nClean \n94.39 \n95.14 \n94.20 \n\nEM \n\nStandard \n25.17 \n34.91 \n31.75 \nUEraser-Lite \n89.56 \n91.20 \n90.55 \nUEraser \n89.74 \n92.37 \n89.92 \n\nLSP \n\nStandard \n14.94 \n22.71 \n20.04 \nUEraser-Lite \n84.17 \n86.22 \n83.24 \nUEraser \n85.56 \n87.19 \n84.85 \n\nTable 8: Ablation analysis UEraser on CIFAR-10. Note that all hyperparameters are the same, except for the \nUEraser augmentation policy which varies. 'P', 'C', 'T', and 'A' denote \"PlasmaBrightness\", \"ChannelShuffle\", \n\"TrivialAugment\", and \"AutoAugment\" [5] respectively. 'Adv' denotes the full UEraser method. \nAblation of UEraser Policies Clean Unlearnable (EM) \n\nStandard Training \n94.78 \n21.24 \n\n+ P \n94.47 \n29.48 \n+ T \n94.47 \n48.81 \n+ P + C \n94.15 \n62.17 \n+ P + T \n95.22 \n48.05 \n+ C + T \n94.40 \n69.24 \n+ C + P + A \n94.04 \n85.60 \n+ C + P + T \n93.94 \n90.78 \n+ C + P + T + Adv \n93.66 \n93.38 \n\n\n\nTable 9 :\n9Clean test accuracies (%) of different UEraser variants. Note that '200' and '300' denotes training for \nE = W = 200 and 300 epochs respectively. \n\nMethods Clean UEraser-Lite UEraser \nUEraser-Max \n200 \n300 \n\nEM \n94.78 \n90.78 \n93.38 \n92.12 95.24 \nLSP \n84.92 \n85.07 \n91.79 94.95 \n\n\n\nTable 10 :\n10Overview of the specifications of datasets used in this paper.We evaluate UEraser using a standard ResNet-18[13] architecture by default, and extend experiments to standard ResNet-50, DenseNet-121, and MobileNet-v2 inTable 7. In all the experiments, we used a stochastic gradient descent (SGD) optimizer with a momentum of 0.9. Tables 11 and 12 provide the default hyperparameters used to evaluate UEraser and on unlearnable examples.Dataset \nInput size \nTrain-set Test-set Classes \n\nCIFAR-10 \n32 \u00d7 32 \u00d7 3 \n50,000 \n10,000 \n10 \nCIFAR-100 \n32 \u00d7 32 \u00d7 3 \n50,000 \n10,000 \n100 \nSVHN \n32 \u00d7 32 \u00d7 3 \n73,257 \n26,032 \n10 \nImageNet-subset 32 \u00d7 32 \u00d7 3 127,091 \n5,000 \n100 \n\nA.2 Models and Hyperparameters \n\n\n\nTable 11 :\n11Default hyperparameters for UEraser-Lite. Hyperparameters CIFAR-10 CIFAR-100 SVHN ImageNet-subsetLearning rate \u03b1 \n0.01 \n0.01 \n0.01 \n0.01 \nWeight decay \n5e-4 \n5e-4 \n5e-4 \n5e-4 \nEpochs E \n200 \n300 \n150 \n300 \nBatch size B \n128 \n128 \n128 \n128 \n\n\nTable 12 :\n12Default hyperparameters for UEraser. UEraser-Max uses the same hyperparameters except W equals E. Hyperparameters CIFAR-10 CIFAR-100 SVHN ImageNet-subsetLearning rate \u03b1 \n0.01 \n0.01 \n0.01 \n0.01 \nWeight decay \n5e-4 \n5e-4 \n5e-4 \n5e-4 \nEpochs E \n200 \n300 \n150 \n300 \nBatch size B \n128 \n128 \n128 \n128 \nNumber of repeated sampling K \n5 \n5 \n5 \n5 \nNumber of error-maximizing augmentation epochs W \n50 \n30 \n30 \n30 \n\n\n\nTable 13 :\n13Default hyperparameters for UEraser augmentations.Augmentations \nPlasmaBrightness PlasmaContrast ChannelShuffle \n\nProbability of use p \n0.5 \n0.5 \n0.5 \nRoughness \n(0.1, 0.7) \n(0.1, 0.7) \n-\nIntensity \n(0.0, 1.0) \n-\n-\nSame on batch \nFalse \nFalse \nFalse \n\n\n\n\nK UEraser UEraser-Max E = 200 E = 300 E = 200 E = 3001 \n90.78 \n94.19 \n-\n-\n2 \n92.76 \n94.79 \n91.32 \n95.25 \n3 \n92.91 \n95.01 \n91.40 \n95.85 \n4 \n93.02 \n95.14 \n91.26 \n95.59 \n5 \n93.38 \n94.83 \n92.12 \n95.24 \n6 \n93.24 \n94.78 \n93.17 \n95.36 \n7 \n93.16 \n94.50 \n93.58 \n94.79 \n8 \n93.23 \n94.87 \n93.95 \n94.84 \n9 \n92.86 \n94.58 \n93.92 \n94.66 \n10 \n93.03 \n94.83 \n94.06 \n94.57 \n\n0 \n50 \n100 150 200 250 300 \n\nEpochs \n\n20 \n\n30 \n\n40 \n\n50 \n\n60 \n\n70 \n\n80 \n\n90 \n\nAccuracy (%) \n\nTrain Acc \nTest Acc \n\n\n\nTable 15 :\n15Attack and defense methods and respective links to open source repositories.Name \nOpen Source Repository \n\nAvailable at https://github.com/lafeat/ueraser.\nDocumentation: https://kornia.readthedocs.io/en/latest/augmentation.module.html.\n\nPoisoning attacks against support vector machines. Battista Biggio, Blaine Nelson, Pavel Laskov, ICML. Battista Biggio, Blaine Nelson, and Pavel Laskov. Poisoning attacks against support vector machines. In ICML, 2012.\n\nXinyun Chen, Chang Liu, Bo Li, Kimberly Lu, Dawn Song, arXiv:1712.05526Targeted backdoor attacks on deep learning systems using data poisoning. Xinyun Chen, Chang Liu, Bo Li, Kimberly Lu, and Dawn Song. Targeted backdoor attacks on deep learning systems using data poisoning. arXiv:1712.05526, 2017.\n\nFrancesco Croce, Maksym Andriushchenko, Vikash Sehwag, Edoardo Debenedetti, arXiv:2010.09670Nicolas Flammarion, Mung Chiang, Prateek Mittal, and Matthias Hein. Robustbench: a standardized adversarial robustness benchmark. arXiv preprintFrancesco Croce, Maksym Andriushchenko, Vikash Sehwag, Edoardo Debenedetti, Nicolas Flammarion, Mung Chiang, Prateek Mittal, and Matthias Hein. Robustbench: a standardized adversarial robustness benchmark. arXiv preprint arXiv:2010.09670, 2020.\n\nReliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks. Francesco Croce, Matthias Hein, ICML. Francesco Croce and Matthias Hein. Reliable evaluation of adversarial robustness with an ensemble of diverse parameter-free attacks. In ICML, 2020.\n\nAutoAugment: Learning augmentation strategies from data. Barret Ekin D Cubuk, Dandelion Zoph, Vijay Mane, Quoc V Vasudevan, Le, CVPR. Ekin D Cubuk, Barret Zoph, Dandelion Mane, Vijay Vasudevan, and Quoc V Le. AutoAugment: Learning augmentation strategies from data. In CVPR, 2019.\n\nEigentransfer: a unified framework for transfer learning. Wenyuan Dai, Ou Jin, Gui-Rong Xue, Qiang Yang, Yong Yu, ICML. Wenyuan Dai, Ou Jin, Gui-Rong Xue, Qiang Yang, and Yong Yu. Eigentransfer: a unified framework for transfer learning. In ICML, 2009.\n\nImagenet: A large-scale hierarchical image database. Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, Li Fei-Fei, CVPR. Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In CVPR, 2009.\n\nBert: Pre-training of deep bidirectional transformers for language understanding. Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, NAACL. Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep bidirectional transformers for language understanding. In NAACL, 2019.\n\nTerrance Devries, W Graham, Taylor, arXiv:1708.04552Improved regularization of convolutional neural networks with cutout. Terrance DeVries and Graham W Taylor. Improved regularization of convolutional neural networks with cutout. arXiv:1708.04552, 2017.\n\nRobust unlearnable examples: Protecting data privacy against adversarial learning. Shaopeng Fu, Fengxiang He, Yang Liu, Li Shen, Dacheng Tao, ICLR. 2022Shaopeng Fu, Fengxiang He, Yang Liu, Li Shen, and Dacheng Tao. Robust unlearnable examples: Protecting data privacy against adversarial learning. In ICLR, 2022.\n\nShortcut learning in deep neural networks. Robert Geirhos, J\u00f6rn-Henrik Jacobsen, Claudio Michaelis, Richard Zemel, Wieland Brendel, Matthias Bethge, Felix A Wichmann, Nature Machine Intelligence. Robert Geirhos, J\u00f6rn-Henrik Jacobsen, Claudio Michaelis, Richard Zemel, Wieland Brendel, Matthias Bethge, and Felix A Wichmann. Shortcut learning in deep neural networks. Nature Machine Intelligence, 2020.\n\nJ Ian, Goodfellow, arXiv:1412.6572Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples. Ian J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples. arXiv:1412.6572, 2014.\n\nDeep residual learning for image recognition. Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, CVPR. Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In CVPR, 2016.\n\nDensely connected convolutional networks. Gao Huang, Zhuang Liu, Laurens Van Der Maaten, Kilian Q Weinberger, CVPR. Gao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kilian Q Weinberger. Densely connected convolutional networks. In CVPR, 2017.\n\nUnlearnable examples: Making personal data unexploitable. Hanxun Huang, Xingjun Ma, Sarah Monazam Erfani, James Bailey, Yisen Wang, ICLR. 2021Hanxun Huang, Xingjun Ma, Sarah Monazam Erfani, James Bailey, and Yisen Wang. Unlearnable examples: Making personal data unexploitable. In ICLR, 2021.\n\nLearning multiple layers of features from tiny images. Alex Krizhevsky, Geoffrey Hinton, Alex Krizhevsky, Geoffrey Hinton, et al. Learning multiple layers of features from tiny images. 2009.\n\nImagenet classification with deep convolutional neural networks. Alex Krizhevsky, Ilya Sutskever, Geoffrey E Hinton, Advances in Neural Information Processing Systems. Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convolutional neural networks. In Advances in Neural Information Processing Systems, 2012.\n\nBackdoor learning: A survey. Yiming Li, Yong Jiang, Zhifeng Li, Shu-Tao Xia, IEEE Transactions on Neural Networks and Learning Systems. Yiming Li, Yong Jiang, Zhifeng Li, and Shu-Tao Xia. Backdoor learning: A survey. IEEE Transactions on Neural Networks and Learning Systems, 2022.\n\nImage shortcut squeezing: Countering perturbative availability poisons with compression. Zhuoran Liu, Zhengyu Zhao, Martha Larson, arXiv:2301.13838Zhuoran Liu, Zhengyu Zhao, and Martha Larson. Image shortcut squeezing: Countering perturbative availability poisons with compression. arXiv:2301.13838, 2023.\n\nTowards deep learning models resistant to adversarial attacks. Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, Adrian Vladu, In ICLR. Aleksander Madry, Aleksandar Makelov, Ludwig Schmidt, Dimitris Tsipras, and Adrian Vladu. Towards deep learning models resistant to adversarial attacks. In ICLR, 2018.\n\nTrivialAugment: Tuning-free yet state-of-the-art data augmentation. G Samuel, Frank M\u00fcller, Hutter, CVPR. 2021Samuel G M\u00fcller and Frank Hutter. TrivialAugment: Tuning-free yet state-of-the-art data augmentation. In CVPR, 2021.\n\nReading digits in natural images with unsupervised feature learning. Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, Andrew Y Ng, Yuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, and Andrew Y Ng. Reading digits in natural images with unsupervised feature learning. 2011.\n\nWanet-imperceptible warping-based backdoor attack. Anh Nguyen, Anh Tran, ICLR. 2021Anh Nguyen and Anh Tran. Wanet-imperceptible warping-based backdoor attack. In ICLR, 2021.\n\nTormentor: Deterministic dynamic-path, data augmentations with fractals. Anguelos Nicolaou, Vincent Christlein, Edgar Riba, Jian Shi, Georg Vogeler, Mathias Seuret, CVPR Workshop. Anguelos Nicolaou, Vincent Christlein, Edgar Riba, Jian Shi, Georg Vogeler, and Mathias Seuret. Tormentor: Deterministic dynamic-path, data augmentations with fractals. In CVPR Workshop, 2022.\n\nResNet -Torchvision 0.15 documentation. Pytorch, PyTorch. ResNet -Torchvision 0.15 documentation. Retrieved Mar 24, 2023, from https://pytorch.org/vision/ stable/models/resnet.html.\n\nMark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh Chen, Mobilenetv2: Inverted residuals and linear bottlenecks. CVPRMark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, and Liang-Chieh Chen. Mobilenetv2: Inverted residuals and linear bottlenecks. In CVPR, 2018.\n\nAutoregressive perturbations for data poisoning. Pedro Sandoval-Segura, Vasu Singla, Jonas Geiping, Micah Goldblum, Tom Goldstein, David W Jacobs, NeurIPS. 2022Pedro Sandoval-Segura, Vasu Singla, Jonas Geiping, Micah Goldblum, Tom Goldstein, and David W Jacobs. Autoregressive perturbations for data poisoning. In NeurIPS, 2022.\n\nPoison frogs! targeted clean-label poisoning attacks on neural networks. Ali Shafahi, Ronny Huang, Mahyar Najibi, Octavian Suciu, Christoph Studer, Tudor Dumitras, Tom Goldstein, In NeurIPS. Ali Shafahi, W Ronny Huang, Mahyar Najibi, Octavian Suciu, Christoph Studer, Tudor Dumitras, and Tom Goldstein. Poison frogs! targeted clean-label poisoning attacks on neural networks. In NeurIPS, 2018.\n\nChristian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, arXiv:1312.6199Dumitru Erhan, Ian Goodfellow, and Rob Fergus. Intriguing properties of neural networks. Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, and Rob Fergus. Intriguing properties of neural networks. arXiv:1312.6199, 2013.\n\nBetter safe than sorry: Preventing delusive adversaries with adversarial training. Lue Tao, Lei Feng, Jinfeng Yi, Sheng-Jun Huang, Songcan Chen, NeurIPS. 2021Lue Tao, Lei Feng, Jinfeng Yi, Sheng-Jun Huang, and Songcan Chen. Better safe than sorry: Preventing delusive adversaries with adversarial training. In NeurIPS, 2021.\n\nTransfer learning. Lisa Torrey, Jude Shavlik, Handbook of research on machine learning applications and trends: algorithms, methods, and techniques. Lisa Torrey and Jude Shavlik. Transfer learning. In Handbook of research on machine learning applications and trends: algorithms, methods, and techniques. 2010.\n\nIs adversarial training really a silver bullet for mitigating data poisoning? In ICLR. Rui Wen, Zhengyu Zhao, Zhuoran Liu, Michael Backes, Tianhao Wang, Yang Zhang, Rui Wen, Zhengyu Zhao, Zhuoran Liu, Michael Backes, Tianhao Wang, and Yang Zhang. Is adversarial training really a silver bullet for mitigating data poisoning? In ICLR, 2023.\n\nAvailability attacks create shortcuts. Da Yu, Huishuai Zhang, Wei Chen, Jian Yin, Tie-Yan Liu, ACM SIGKDD. Da Yu, Huishuai Zhang, Wei Chen, Jian Yin, and Tie-Yan Liu. Availability attacks create shortcuts. In ACM SIGKDD, 2022.\n\nLAFEAT: Piercing through adversarial defenses with latent features. Yunrui Yu, Xitong Gao, Cheng-Zhong Xu, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)Yunrui Yu, Xitong Gao, and Cheng-Zhong Xu. LAFEAT: Piercing through adversarial defenses with latent features. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 5735-5745, June 2021.\n\nMORA: Improving ensemble robustness evaluation with model reweighing attack. Yunrui Yu, Xitong Gao, Cheng Zhong Xu, Advances in Neural Information Processing Systems. Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun ChoYunrui Yu, Xitong Gao, and Cheng zhong Xu. MORA: Improving ensemble robustness evaluation with model reweighing attack. In Alice H. Oh, Alekh Agarwal, Danielle Belgrave, and Kyunghyun Cho, editors, Advances in Neural Information Processing Systems, 2022.\n\nmixup: Beyond empirical risk minimization. Hongyi Zhang, Moustapha Cisse, David Yann N Dauphin, Lopez-Paz, ICLR. Hongyi Zhang, Moustapha Cisse, Yann N Dauphin, and David Lopez-Paz. mixup: Beyond empirical risk minimization. In ICLR, 2018.\n", "annotations": {"author": "[{\"end\":241,\"start\":103},{\"end\":330,\"start\":242},{\"end\":422,\"start\":331},{\"end\":511,\"start\":423},{\"end\":567,\"start\":512}]", "publisher": null, "author_last_name": "[{\"end\":114,\"start\":111},{\"end\":252,\"start\":249},{\"end\":344,\"start\":340},{\"end\":433,\"start\":431},{\"end\":526,\"start\":524}]", "author_first_name": "[{\"end\":110,\"start\":103},{\"end\":248,\"start\":242},{\"end\":339,\"start\":331},{\"end\":430,\"start\":423},{\"end\":523,\"start\":512}]", "author_affiliation": "[{\"end\":191,\"start\":116},{\"end\":240,\"start\":193},{\"end\":329,\"start\":254},{\"end\":421,\"start\":346},{\"end\":510,\"start\":435},{\"end\":566,\"start\":528}]", "title": "[{\"end\":100,\"start\":1},{\"end\":667,\"start\":568}]", "venue": null, "abstract": "[{\"end\":2578,\"start\":669}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b12\"},\"end\":2673,\"start\":2669},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":2709,\"start\":2706},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3028,\"start\":3024},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":3031,\"start\":3028},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":3034,\"start\":3031},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":3037,\"start\":3034},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":3040,\"start\":3037},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":3151,\"start\":3147},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":3154,\"start\":3151},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":3387,\"start\":3383},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":3390,\"start\":3387},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3393,\"start\":3390},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":3447,\"start\":3444},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":3459,\"start\":3455},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":3480,\"start\":3477},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":3861,\"start\":3857},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3864,\"start\":3861},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":4072,\"start\":4068},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":5554,\"start\":5550},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":6772,\"start\":6768},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":7776,\"start\":7772},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":7779,\"start\":7776},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":7815,\"start\":7811},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":8069,\"start\":8065},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":8414,\"start\":8411},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":8416,\"start\":8414},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":8419,\"start\":8416},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":8422,\"start\":8419},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":8583,\"start\":8580},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":8586,\"start\":8583},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":8614,\"start\":8611},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":8617,\"start\":8614},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":8901,\"start\":8897},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":8908,\"start\":8904},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":9192,\"start\":9188},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":9500,\"start\":9496},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":9696,\"start\":9692},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":9716,\"start\":9713},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":9833,\"start\":9829},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":9982,\"start\":9978},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":9985,\"start\":9982},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":9988,\"start\":9985},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":9991,\"start\":9988},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":9994,\"start\":9991},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":10592,\"start\":10588},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":12273,\"start\":12269},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":12276,\"start\":12273},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":12279,\"start\":12276},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":12310,\"start\":12306},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":12872,\"start\":12868},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":13249,\"start\":13245},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":13252,\"start\":13249},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":13255,\"start\":13252},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":15373,\"start\":15369},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":15398,\"start\":15394},{\"end\":17432,\"start\":17430},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":17491,\"start\":17490},{\"end\":17555,\"start\":17553},{\"end\":17614,\"start\":17612},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":17656,\"start\":17655},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":17752,\"start\":17748},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":17768,\"start\":17764},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":17779,\"start\":17775},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":17800,\"start\":17797},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":17839,\"start\":17835},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":18198,\"start\":18194},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":20241,\"start\":20237},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":20281,\"start\":20277},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":20319,\"start\":20315},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":20372,\"start\":20368},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":20412,\"start\":20408},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":20547,\"start\":20543},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":20577,\"start\":20573},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":22376,\"start\":22372},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":22488,\"start\":22484},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":22501,\"start\":22497},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":23718,\"start\":23714},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":26676,\"start\":26672},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":26781,\"start\":26777},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":27388,\"start\":27385},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":29463,\"start\":29460},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":29466,\"start\":29463},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":29857,\"start\":29853},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":33098,\"start\":33094},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":33101,\"start\":33098},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":33104,\"start\":33101},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":33779,\"start\":33775},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":34370,\"start\":34366},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":34380,\"start\":34376},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":34395,\"start\":34391},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":34492,\"start\":34488},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":34504,\"start\":34500},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":34699,\"start\":34695},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":34733,\"start\":34729},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":35724,\"start\":35720},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":36806,\"start\":36802},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":36836,\"start\":36832},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":36971,\"start\":36967},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":38498,\"start\":38496},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":39918,\"start\":39914},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":40115,\"start\":40111},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":40226,\"start\":40222},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":41685,\"start\":41681},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":42969,\"start\":42965},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":45681,\"start\":45677}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":37423,\"start\":37367},{\"attributes\":{\"id\":\"fig_1\"},\"end\":37602,\"start\":37424},{\"attributes\":{\"id\":\"fig_2\"},\"end\":37948,\"start\":37603},{\"attributes\":{\"id\":\"fig_3\"},\"end\":38011,\"start\":37949},{\"attributes\":{\"id\":\"fig_4\"},\"end\":38493,\"start\":38012},{\"attributes\":{\"id\":\"fig_5\"},\"end\":39066,\"start\":38494},{\"attributes\":{\"id\":\"fig_6\"},\"end\":39101,\"start\":39067},{\"attributes\":{\"id\":\"fig_7\"},\"end\":39180,\"start\":39102},{\"attributes\":{\"id\":\"fig_8\"},\"end\":39203,\"start\":39181},{\"attributes\":{\"id\":\"fig_9\"},\"end\":39444,\"start\":39204},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":39605,\"start\":39445},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":40848,\"start\":39606},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":41073,\"start\":40849},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":41438,\"start\":41074},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":42331,\"start\":41439},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":42856,\"start\":42332},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":43526,\"start\":42857},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":43902,\"start\":43527},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":44181,\"start\":43903},{\"attributes\":{\"id\":\"tab_9\",\"type\":\"table\"},\"end\":45262,\"start\":44182},{\"attributes\":{\"id\":\"tab_10\",\"type\":\"table\"},\"end\":45554,\"start\":45263},{\"attributes\":{\"id\":\"tab_11\",\"type\":\"table\"},\"end\":46263,\"start\":45555},{\"attributes\":{\"id\":\"tab_12\",\"type\":\"table\"},\"end\":46518,\"start\":46264},{\"attributes\":{\"id\":\"tab_13\",\"type\":\"table\"},\"end\":46939,\"start\":46519},{\"attributes\":{\"id\":\"tab_14\",\"type\":\"table\"},\"end\":47206,\"start\":46940},{\"attributes\":{\"id\":\"tab_15\",\"type\":\"table\"},\"end\":47679,\"start\":47207},{\"attributes\":{\"id\":\"tab_16\",\"type\":\"table\"},\"end\":47800,\"start\":47680}]", "paragraph": "[{\"end\":3545,\"start\":2594},{\"end\":4582,\"start\":3547},{\"end\":5659,\"start\":4584},{\"end\":5711,\"start\":5661},{\"end\":5859,\"start\":5713},{\"end\":6068,\"start\":5861},{\"end\":6232,\"start\":6070},{\"end\":6449,\"start\":6234},{\"end\":7526,\"start\":6451},{\"end\":8423,\"start\":7543},{\"end\":9359,\"start\":8425},{\"end\":10369,\"start\":9372},{\"end\":10392,\"start\":10371},{\"end\":11298,\"start\":10454},{\"end\":11524,\"start\":11409},{\"end\":12394,\"start\":11535},{\"end\":12823,\"start\":12458},{\"end\":13411,\"start\":12853},{\"end\":14106,\"start\":13413},{\"end\":14555,\"start\":14108},{\"end\":15275,\"start\":14610},{\"end\":16367,\"start\":15277},{\"end\":17234,\"start\":16369},{\"end\":17270,\"start\":17236},{\"end\":17492,\"start\":17382},{\"end\":18535,\"start\":17519},{\"end\":20099,\"start\":18574},{\"end\":21712,\"start\":20119},{\"end\":22263,\"start\":21714},{\"end\":23130,\"start\":22285},{\"end\":23804,\"start\":23153},{\"end\":23813,\"start\":23806},{\"end\":24074,\"start\":23864},{\"end\":25306,\"start\":24141},{\"end\":25922,\"start\":25337},{\"end\":26371,\"start\":25966},{\"end\":27919,\"start\":26396},{\"end\":28812,\"start\":27977},{\"end\":29371,\"start\":28814},{\"end\":31055,\"start\":29393},{\"end\":32157,\"start\":31070},{\"end\":32414,\"start\":32159},{\"end\":32664,\"start\":32429},{\"end\":33961,\"start\":32666},{\"end\":34310,\"start\":33991},{\"end\":34528,\"start\":34350},{\"end\":34870,\"start\":34557},{\"end\":35198,\"start\":34906},{\"end\":35435,\"start\":35200},{\"end\":36288,\"start\":35462},{\"end\":37366,\"start\":36351}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":9371,\"start\":9360},{\"attributes\":{\"id\":\"formula_1\"},\"end\":11408,\"start\":11299},{\"attributes\":{\"id\":\"formula_2\"},\"end\":11534,\"start\":11525},{\"attributes\":{\"id\":\"formula_3\"},\"end\":12457,\"start\":12395},{\"attributes\":{\"id\":\"formula_4\"},\"end\":14609,\"start\":14556},{\"attributes\":{\"id\":\"formula_5\"},\"end\":17381,\"start\":17271},{\"attributes\":{\"id\":\"formula_6\"},\"end\":17518,\"start\":17493},{\"attributes\":{\"id\":\"formula_7\"},\"end\":18573,\"start\":18536},{\"attributes\":{\"id\":\"formula_8\"},\"end\":23863,\"start\":23814},{\"attributes\":{\"id\":\"formula_9\"},\"end\":24140,\"start\":24075}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":11670,\"start\":11663},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":13607,\"start\":13598},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":19854,\"start\":19847},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":20803,\"start\":20796},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":21724,\"start\":21717},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":24316,\"start\":24309},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":25853,\"start\":25846},{\"attributes\":{\"ref_id\":\"tab_9\"},\"end\":26218,\"start\":26211},{\"end\":26696,\"start\":26689},{\"attributes\":{\"ref_id\":\"tab_10\"},\"end\":28506,\"start\":28499},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":33907,\"start\":33899},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":35263,\"start\":35255},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":35734,\"start\":35726},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":36471,\"start\":36462},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":36981,\"start\":36973}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2592,\"start\":2580},{\"attributes\":{\"n\":\"2\"},\"end\":7541,\"start\":7529},{\"attributes\":{\"n\":\"3.1\"},\"end\":10452,\"start\":10395},{\"attributes\":{\"n\":\"3.2\"},\"end\":12851,\"start\":12826},{\"attributes\":{\"n\":\"4.1\"},\"end\":20117,\"start\":20102},{\"attributes\":{\"n\":\"4.2\"},\"end\":22283,\"start\":22266},{\"attributes\":{\"n\":\"4.3\"},\"end\":23151,\"start\":23133},{\"attributes\":{\"n\":\"4.4\"},\"end\":25335,\"start\":25309},{\"attributes\":{\"n\":\"4.5\"},\"end\":25964,\"start\":25925},{\"attributes\":{\"n\":\"4.6\"},\"end\":26394,\"start\":26374},{\"attributes\":{\"n\":\"4.7\"},\"end\":27975,\"start\":27922},{\"attributes\":{\"n\":\"4.8\"},\"end\":29391,\"start\":29374},{\"attributes\":{\"n\":\"5\"},\"end\":31068,\"start\":31058},{\"attributes\":{\"n\":\"6\"},\"end\":32427,\"start\":32417},{\"end\":33989,\"start\":33964},{\"end\":34348,\"start\":34313},{\"end\":34555,\"start\":34531},{\"end\":34904,\"start\":34873},{\"end\":35460,\"start\":35438},{\"end\":36299,\"start\":36291},{\"end\":36316,\"start\":36302},{\"end\":36349,\"start\":36319},{\"end\":37378,\"start\":37368},{\"end\":37614,\"start\":37604},{\"end\":38023,\"start\":38013},{\"end\":39113,\"start\":39103},{\"end\":39215,\"start\":39205},{\"end\":40859,\"start\":40850},{\"end\":41449,\"start\":41440},{\"end\":42342,\"start\":42333},{\"end\":42867,\"start\":42858},{\"end\":43537,\"start\":43528},{\"end\":43913,\"start\":43904},{\"end\":44192,\"start\":44183},{\"end\":45273,\"start\":45264},{\"end\":45566,\"start\":45556},{\"end\":46275,\"start\":46265},{\"end\":46530,\"start\":46520},{\"end\":46951,\"start\":46941},{\"end\":47691,\"start\":47681}]", "table": "[{\"end\":39605,\"start\":39481},{\"end\":40848,\"start\":40396},{\"end\":41073,\"start\":40957},{\"end\":41438,\"start\":41279},{\"end\":42331,\"start\":41967},{\"end\":42856,\"start\":42545},{\"end\":43526,\"start\":43115},{\"end\":43902,\"start\":43539},{\"end\":44181,\"start\":43991},{\"end\":45262,\"start\":44194},{\"end\":45554,\"start\":45275},{\"end\":46263,\"start\":46003},{\"end\":46518,\"start\":46375},{\"end\":46939,\"start\":46686},{\"end\":47206,\"start\":47004},{\"end\":47679,\"start\":47262},{\"end\":47800,\"start\":47770}]", "figure_caption": "[{\"end\":37423,\"start\":37380},{\"end\":37602,\"start\":37426},{\"end\":37948,\"start\":37616},{\"end\":38011,\"start\":37951},{\"end\":38493,\"start\":38025},{\"end\":39066,\"start\":38496},{\"end\":39101,\"start\":39069},{\"end\":39180,\"start\":39115},{\"end\":39203,\"start\":39183},{\"end\":39444,\"start\":39217},{\"end\":39481,\"start\":39447},{\"end\":40396,\"start\":39608},{\"end\":40957,\"start\":40861},{\"end\":41279,\"start\":41076},{\"end\":41967,\"start\":41451},{\"end\":42545,\"start\":42344},{\"end\":43115,\"start\":42869},{\"end\":43991,\"start\":43915},{\"end\":46003,\"start\":45569},{\"end\":46375,\"start\":46278},{\"end\":46686,\"start\":46533},{\"end\":47004,\"start\":46954},{\"end\":47262,\"start\":47209},{\"end\":47770,\"start\":47694}]", "figure_ref": "[{\"end\":3873,\"start\":3865},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":22868,\"start\":22851},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":26583,\"start\":26575},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":30458,\"start\":30450},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":30469,\"start\":30460},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":30597,\"start\":30588},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":31054,\"start\":31045},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":35348,\"start\":35340},{\"attributes\":{\"ref_id\":\"fig_9\"},\"end\":36168,\"start\":36160}]", "bib_author_first_name": "[{\"end\":47990,\"start\":47982},{\"end\":48005,\"start\":47999},{\"end\":48019,\"start\":48014},{\"end\":48157,\"start\":48151},{\"end\":48169,\"start\":48164},{\"end\":48177,\"start\":48175},{\"end\":48190,\"start\":48182},{\"end\":48199,\"start\":48195},{\"end\":48461,\"start\":48452},{\"end\":48475,\"start\":48469},{\"end\":48498,\"start\":48492},{\"end\":48514,\"start\":48507},{\"end\":49041,\"start\":49032},{\"end\":49057,\"start\":49049},{\"end\":49282,\"start\":49276},{\"end\":49306,\"start\":49297},{\"end\":49318,\"start\":49313},{\"end\":49331,\"start\":49325},{\"end\":49566,\"start\":49559},{\"end\":49574,\"start\":49572},{\"end\":49588,\"start\":49580},{\"end\":49599,\"start\":49594},{\"end\":49610,\"start\":49606},{\"end\":49811,\"start\":49808},{\"end\":49821,\"start\":49818},{\"end\":49835,\"start\":49828},{\"end\":49850,\"start\":49844},{\"end\":49858,\"start\":49855},{\"end\":49865,\"start\":49863},{\"end\":50108,\"start\":50103},{\"end\":50125,\"start\":50117},{\"end\":50139,\"start\":50133},{\"end\":50153,\"start\":50145},{\"end\":50345,\"start\":50337},{\"end\":50356,\"start\":50355},{\"end\":50683,\"start\":50675},{\"end\":50697,\"start\":50688},{\"end\":50706,\"start\":50702},{\"end\":50714,\"start\":50712},{\"end\":50728,\"start\":50721},{\"end\":50955,\"start\":50949},{\"end\":50976,\"start\":50965},{\"end\":50994,\"start\":50987},{\"end\":51013,\"start\":51006},{\"end\":51028,\"start\":51021},{\"end\":51046,\"start\":51038},{\"end\":51060,\"start\":51055},{\"end\":51062,\"start\":51061},{\"end\":51310,\"start\":51309},{\"end\":51614,\"start\":51607},{\"end\":51626,\"start\":51619},{\"end\":51642,\"start\":51634},{\"end\":51652,\"start\":51648},{\"end\":51826,\"start\":51823},{\"end\":51840,\"start\":51834},{\"end\":51853,\"start\":51846},{\"end\":51878,\"start\":51870},{\"end\":52091,\"start\":52085},{\"end\":52106,\"start\":52099},{\"end\":52116,\"start\":52111},{\"end\":52124,\"start\":52117},{\"end\":52138,\"start\":52133},{\"end\":52152,\"start\":52147},{\"end\":52380,\"start\":52376},{\"end\":52401,\"start\":52393},{\"end\":52582,\"start\":52578},{\"end\":52599,\"start\":52595},{\"end\":52619,\"start\":52611},{\"end\":52621,\"start\":52620},{\"end\":52898,\"start\":52892},{\"end\":52907,\"start\":52903},{\"end\":52922,\"start\":52915},{\"end\":52934,\"start\":52927},{\"end\":53242,\"start\":53235},{\"end\":53255,\"start\":53248},{\"end\":53268,\"start\":53262},{\"end\":53526,\"start\":53516},{\"end\":53544,\"start\":53534},{\"end\":53560,\"start\":53554},{\"end\":53578,\"start\":53570},{\"end\":53594,\"start\":53588},{\"end\":53849,\"start\":53848},{\"end\":53863,\"start\":53858},{\"end\":54082,\"start\":54077},{\"end\":54094,\"start\":54091},{\"end\":54105,\"start\":54101},{\"end\":54124,\"start\":54114},{\"end\":54137,\"start\":54135},{\"end\":54150,\"start\":54142},{\"end\":54367,\"start\":54364},{\"end\":54379,\"start\":54376},{\"end\":54569,\"start\":54561},{\"end\":54587,\"start\":54580},{\"end\":54605,\"start\":54600},{\"end\":54616,\"start\":54612},{\"end\":54627,\"start\":54622},{\"end\":54644,\"start\":54637},{\"end\":55049,\"start\":55045},{\"end\":55065,\"start\":55059},{\"end\":55082,\"start\":55074},{\"end\":55094,\"start\":55088},{\"end\":55117,\"start\":55106},{\"end\":55393,\"start\":55388},{\"end\":55415,\"start\":55411},{\"end\":55429,\"start\":55424},{\"end\":55444,\"start\":55439},{\"end\":55458,\"start\":55455},{\"end\":55475,\"start\":55470},{\"end\":55477,\"start\":55476},{\"end\":55745,\"start\":55742},{\"end\":55760,\"start\":55755},{\"end\":55774,\"start\":55768},{\"end\":55791,\"start\":55783},{\"end\":55808,\"start\":55799},{\"end\":55822,\"start\":55817},{\"end\":55836,\"start\":55833},{\"end\":56073,\"start\":56064},{\"end\":56091,\"start\":56083},{\"end\":56105,\"start\":56101},{\"end\":56121,\"start\":56117},{\"end\":56497,\"start\":56494},{\"end\":56506,\"start\":56503},{\"end\":56520,\"start\":56513},{\"end\":56534,\"start\":56525},{\"end\":56549,\"start\":56542},{\"end\":56760,\"start\":56756},{\"end\":56773,\"start\":56769},{\"end\":57138,\"start\":57135},{\"end\":57151,\"start\":57144},{\"end\":57165,\"start\":57158},{\"end\":57178,\"start\":57171},{\"end\":57194,\"start\":57187},{\"end\":57205,\"start\":57201},{\"end\":57430,\"start\":57428},{\"end\":57443,\"start\":57435},{\"end\":57454,\"start\":57451},{\"end\":57465,\"start\":57461},{\"end\":57478,\"start\":57471},{\"end\":57691,\"start\":57685},{\"end\":57702,\"start\":57696},{\"end\":57719,\"start\":57708},{\"end\":58203,\"start\":58197},{\"end\":58214,\"start\":58208},{\"end\":58231,\"start\":58220},{\"end\":58656,\"start\":58650},{\"end\":58673,\"start\":58664},{\"end\":58686,\"start\":58681}]", "bib_author_last_name": "[{\"end\":47997,\"start\":47991},{\"end\":48012,\"start\":48006},{\"end\":48026,\"start\":48020},{\"end\":48162,\"start\":48158},{\"end\":48173,\"start\":48170},{\"end\":48180,\"start\":48178},{\"end\":48193,\"start\":48191},{\"end\":48204,\"start\":48200},{\"end\":48467,\"start\":48462},{\"end\":48490,\"start\":48476},{\"end\":48505,\"start\":48499},{\"end\":48526,\"start\":48515},{\"end\":49047,\"start\":49042},{\"end\":49062,\"start\":49058},{\"end\":49295,\"start\":49283},{\"end\":49311,\"start\":49307},{\"end\":49323,\"start\":49319},{\"end\":49341,\"start\":49332},{\"end\":49345,\"start\":49343},{\"end\":49570,\"start\":49567},{\"end\":49578,\"start\":49575},{\"end\":49592,\"start\":49589},{\"end\":49604,\"start\":49600},{\"end\":49613,\"start\":49611},{\"end\":49816,\"start\":49812},{\"end\":49826,\"start\":49822},{\"end\":49842,\"start\":49836},{\"end\":49853,\"start\":49851},{\"end\":49861,\"start\":49859},{\"end\":49873,\"start\":49866},{\"end\":50115,\"start\":50109},{\"end\":50131,\"start\":50126},{\"end\":50143,\"start\":50140},{\"end\":50163,\"start\":50154},{\"end\":50353,\"start\":50346},{\"end\":50363,\"start\":50357},{\"end\":50371,\"start\":50365},{\"end\":50686,\"start\":50684},{\"end\":50700,\"start\":50698},{\"end\":50710,\"start\":50707},{\"end\":50719,\"start\":50715},{\"end\":50732,\"start\":50729},{\"end\":50963,\"start\":50956},{\"end\":50985,\"start\":50977},{\"end\":51004,\"start\":50995},{\"end\":51019,\"start\":51014},{\"end\":51036,\"start\":51029},{\"end\":51053,\"start\":51047},{\"end\":51071,\"start\":51063},{\"end\":51314,\"start\":51311},{\"end\":51326,\"start\":51316},{\"end\":51617,\"start\":51615},{\"end\":51632,\"start\":51627},{\"end\":51646,\"start\":51643},{\"end\":51656,\"start\":51653},{\"end\":51832,\"start\":51827},{\"end\":51844,\"start\":51841},{\"end\":51868,\"start\":51854},{\"end\":51889,\"start\":51879},{\"end\":52097,\"start\":52092},{\"end\":52109,\"start\":52107},{\"end\":52131,\"start\":52125},{\"end\":52145,\"start\":52139},{\"end\":52157,\"start\":52153},{\"end\":52391,\"start\":52381},{\"end\":52408,\"start\":52402},{\"end\":52593,\"start\":52583},{\"end\":52609,\"start\":52600},{\"end\":52628,\"start\":52622},{\"end\":52901,\"start\":52899},{\"end\":52913,\"start\":52908},{\"end\":52925,\"start\":52923},{\"end\":52938,\"start\":52935},{\"end\":53246,\"start\":53243},{\"end\":53260,\"start\":53256},{\"end\":53275,\"start\":53269},{\"end\":53532,\"start\":53527},{\"end\":53552,\"start\":53545},{\"end\":53568,\"start\":53561},{\"end\":53586,\"start\":53579},{\"end\":53600,\"start\":53595},{\"end\":53856,\"start\":53850},{\"end\":53870,\"start\":53864},{\"end\":53878,\"start\":53872},{\"end\":54089,\"start\":54083},{\"end\":54099,\"start\":54095},{\"end\":54112,\"start\":54106},{\"end\":54133,\"start\":54125},{\"end\":54140,\"start\":54138},{\"end\":54153,\"start\":54151},{\"end\":54374,\"start\":54368},{\"end\":54384,\"start\":54380},{\"end\":54578,\"start\":54570},{\"end\":54598,\"start\":54588},{\"end\":54610,\"start\":54606},{\"end\":54620,\"start\":54617},{\"end\":54635,\"start\":54628},{\"end\":54651,\"start\":54645},{\"end\":54909,\"start\":54902},{\"end\":55057,\"start\":55050},{\"end\":55072,\"start\":55066},{\"end\":55086,\"start\":55083},{\"end\":55104,\"start\":55095},{\"end\":55122,\"start\":55118},{\"end\":55409,\"start\":55394},{\"end\":55422,\"start\":55416},{\"end\":55437,\"start\":55430},{\"end\":55453,\"start\":55445},{\"end\":55468,\"start\":55459},{\"end\":55484,\"start\":55478},{\"end\":55753,\"start\":55746},{\"end\":55766,\"start\":55761},{\"end\":55781,\"start\":55775},{\"end\":55797,\"start\":55792},{\"end\":55815,\"start\":55809},{\"end\":55831,\"start\":55823},{\"end\":55846,\"start\":55837},{\"end\":56081,\"start\":56074},{\"end\":56099,\"start\":56092},{\"end\":56115,\"start\":56106},{\"end\":56127,\"start\":56122},{\"end\":56501,\"start\":56498},{\"end\":56511,\"start\":56507},{\"end\":56523,\"start\":56521},{\"end\":56540,\"start\":56535},{\"end\":56554,\"start\":56550},{\"end\":56767,\"start\":56761},{\"end\":56781,\"start\":56774},{\"end\":57142,\"start\":57139},{\"end\":57156,\"start\":57152},{\"end\":57169,\"start\":57166},{\"end\":57185,\"start\":57179},{\"end\":57199,\"start\":57195},{\"end\":57211,\"start\":57206},{\"end\":57433,\"start\":57431},{\"end\":57449,\"start\":57444},{\"end\":57459,\"start\":57455},{\"end\":57469,\"start\":57466},{\"end\":57482,\"start\":57479},{\"end\":57694,\"start\":57692},{\"end\":57706,\"start\":57703},{\"end\":57722,\"start\":57720},{\"end\":58206,\"start\":58204},{\"end\":58218,\"start\":58215},{\"end\":58234,\"start\":58232},{\"end\":58662,\"start\":58657},{\"end\":58679,\"start\":58674},{\"end\":58701,\"start\":58687},{\"end\":58712,\"start\":58703}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":9089716},\"end\":48149,\"start\":47931},{\"attributes\":{\"doi\":\"arXiv:1712.05526\",\"id\":\"b1\"},\"end\":48450,\"start\":48151},{\"attributes\":{\"doi\":\"arXiv:2010.09670\",\"id\":\"b2\"},\"end\":48932,\"start\":48452},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":211818320},\"end\":49217,\"start\":48934},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":196208260},\"end\":49499,\"start\":49219},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":2190789},\"end\":49753,\"start\":49501},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":57246310},\"end\":50019,\"start\":49755},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":52967399},\"end\":50335,\"start\":50021},{\"attributes\":{\"doi\":\"arXiv:1708.04552\",\"id\":\"b8\"},\"end\":50590,\"start\":50337},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":251649167},\"end\":50904,\"start\":50592},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":215786368},\"end\":51307,\"start\":50906},{\"attributes\":{\"doi\":\"arXiv:1412.6572\",\"id\":\"b11\"},\"end\":51559,\"start\":51309},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":206594692},\"end\":51779,\"start\":51561},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":9433631},\"end\":52025,\"start\":51781},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":231592390},\"end\":52319,\"start\":52027},{\"attributes\":{\"id\":\"b15\"},\"end\":52511,\"start\":52321},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":195908774},\"end\":52861,\"start\":52513},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":220633116},\"end\":53144,\"start\":52863},{\"attributes\":{\"doi\":\"arXiv:2301.13838\",\"id\":\"b18\"},\"end\":53451,\"start\":53146},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":3488815},\"end\":53778,\"start\":53453},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":232269620},\"end\":54006,\"start\":53780},{\"attributes\":{\"id\":\"b21\"},\"end\":54311,\"start\":54008},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":231985654},\"end\":54486,\"start\":54313},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":248069183},\"end\":54860,\"start\":54488},{\"attributes\":{\"id\":\"b24\"},\"end\":55043,\"start\":54862},{\"attributes\":{\"id\":\"b25\"},\"end\":55337,\"start\":55045},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":249461756},\"end\":55667,\"start\":55339},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":4626477},\"end\":56062,\"start\":55669},{\"attributes\":{\"doi\":\"arXiv:1312.6199\",\"id\":\"b28\"},\"end\":56409,\"start\":56064},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":239886011},\"end\":56735,\"start\":56411},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":18201927},\"end\":57046,\"start\":56737},{\"attributes\":{\"id\":\"b31\"},\"end\":57387,\"start\":57048},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":249282169},\"end\":57615,\"start\":57389},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":233296313},\"end\":58118,\"start\":57617},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":253523316},\"end\":58605,\"start\":58120},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":3162051},\"end\":58845,\"start\":58607}]", "bib_title": "[{\"end\":47980,\"start\":47931},{\"end\":49030,\"start\":48934},{\"end\":49274,\"start\":49219},{\"end\":49557,\"start\":49501},{\"end\":49806,\"start\":49755},{\"end\":50101,\"start\":50021},{\"end\":50673,\"start\":50592},{\"end\":50947,\"start\":50906},{\"end\":51605,\"start\":51561},{\"end\":51821,\"start\":51781},{\"end\":52083,\"start\":52027},{\"end\":52576,\"start\":52513},{\"end\":52890,\"start\":52863},{\"end\":53514,\"start\":53453},{\"end\":53846,\"start\":53780},{\"end\":54362,\"start\":54313},{\"end\":54559,\"start\":54488},{\"end\":55386,\"start\":55339},{\"end\":55740,\"start\":55669},{\"end\":56492,\"start\":56411},{\"end\":56754,\"start\":56737},{\"end\":57426,\"start\":57389},{\"end\":57683,\"start\":57617},{\"end\":58195,\"start\":58120},{\"end\":58648,\"start\":58607}]", "bib_author": "[{\"end\":47999,\"start\":47982},{\"end\":48014,\"start\":47999},{\"end\":48028,\"start\":48014},{\"end\":48164,\"start\":48151},{\"end\":48175,\"start\":48164},{\"end\":48182,\"start\":48175},{\"end\":48195,\"start\":48182},{\"end\":48206,\"start\":48195},{\"end\":48469,\"start\":48452},{\"end\":48492,\"start\":48469},{\"end\":48507,\"start\":48492},{\"end\":48528,\"start\":48507},{\"end\":49049,\"start\":49032},{\"end\":49064,\"start\":49049},{\"end\":49297,\"start\":49276},{\"end\":49313,\"start\":49297},{\"end\":49325,\"start\":49313},{\"end\":49343,\"start\":49325},{\"end\":49347,\"start\":49343},{\"end\":49572,\"start\":49559},{\"end\":49580,\"start\":49572},{\"end\":49594,\"start\":49580},{\"end\":49606,\"start\":49594},{\"end\":49615,\"start\":49606},{\"end\":49818,\"start\":49808},{\"end\":49828,\"start\":49818},{\"end\":49844,\"start\":49828},{\"end\":49855,\"start\":49844},{\"end\":49863,\"start\":49855},{\"end\":49875,\"start\":49863},{\"end\":50117,\"start\":50103},{\"end\":50133,\"start\":50117},{\"end\":50145,\"start\":50133},{\"end\":50165,\"start\":50145},{\"end\":50355,\"start\":50337},{\"end\":50365,\"start\":50355},{\"end\":50373,\"start\":50365},{\"end\":50688,\"start\":50675},{\"end\":50702,\"start\":50688},{\"end\":50712,\"start\":50702},{\"end\":50721,\"start\":50712},{\"end\":50734,\"start\":50721},{\"end\":50965,\"start\":50949},{\"end\":50987,\"start\":50965},{\"end\":51006,\"start\":50987},{\"end\":51021,\"start\":51006},{\"end\":51038,\"start\":51021},{\"end\":51055,\"start\":51038},{\"end\":51073,\"start\":51055},{\"end\":51316,\"start\":51309},{\"end\":51328,\"start\":51316},{\"end\":51619,\"start\":51607},{\"end\":51634,\"start\":51619},{\"end\":51648,\"start\":51634},{\"end\":51658,\"start\":51648},{\"end\":51834,\"start\":51823},{\"end\":51846,\"start\":51834},{\"end\":51870,\"start\":51846},{\"end\":51891,\"start\":51870},{\"end\":52099,\"start\":52085},{\"end\":52111,\"start\":52099},{\"end\":52133,\"start\":52111},{\"end\":52147,\"start\":52133},{\"end\":52159,\"start\":52147},{\"end\":52393,\"start\":52376},{\"end\":52410,\"start\":52393},{\"end\":52595,\"start\":52578},{\"end\":52611,\"start\":52595},{\"end\":52630,\"start\":52611},{\"end\":52903,\"start\":52892},{\"end\":52915,\"start\":52903},{\"end\":52927,\"start\":52915},{\"end\":52940,\"start\":52927},{\"end\":53248,\"start\":53235},{\"end\":53262,\"start\":53248},{\"end\":53277,\"start\":53262},{\"end\":53534,\"start\":53516},{\"end\":53554,\"start\":53534},{\"end\":53570,\"start\":53554},{\"end\":53588,\"start\":53570},{\"end\":53602,\"start\":53588},{\"end\":53858,\"start\":53848},{\"end\":53872,\"start\":53858},{\"end\":53880,\"start\":53872},{\"end\":54091,\"start\":54077},{\"end\":54101,\"start\":54091},{\"end\":54114,\"start\":54101},{\"end\":54135,\"start\":54114},{\"end\":54142,\"start\":54135},{\"end\":54155,\"start\":54142},{\"end\":54376,\"start\":54364},{\"end\":54386,\"start\":54376},{\"end\":54580,\"start\":54561},{\"end\":54600,\"start\":54580},{\"end\":54612,\"start\":54600},{\"end\":54622,\"start\":54612},{\"end\":54637,\"start\":54622},{\"end\":54653,\"start\":54637},{\"end\":54911,\"start\":54902},{\"end\":55059,\"start\":55045},{\"end\":55074,\"start\":55059},{\"end\":55088,\"start\":55074},{\"end\":55106,\"start\":55088},{\"end\":55124,\"start\":55106},{\"end\":55411,\"start\":55388},{\"end\":55424,\"start\":55411},{\"end\":55439,\"start\":55424},{\"end\":55455,\"start\":55439},{\"end\":55470,\"start\":55455},{\"end\":55486,\"start\":55470},{\"end\":55755,\"start\":55742},{\"end\":55768,\"start\":55755},{\"end\":55783,\"start\":55768},{\"end\":55799,\"start\":55783},{\"end\":55817,\"start\":55799},{\"end\":55833,\"start\":55817},{\"end\":55848,\"start\":55833},{\"end\":56083,\"start\":56064},{\"end\":56101,\"start\":56083},{\"end\":56117,\"start\":56101},{\"end\":56129,\"start\":56117},{\"end\":56503,\"start\":56494},{\"end\":56513,\"start\":56503},{\"end\":56525,\"start\":56513},{\"end\":56542,\"start\":56525},{\"end\":56556,\"start\":56542},{\"end\":56769,\"start\":56756},{\"end\":56783,\"start\":56769},{\"end\":57144,\"start\":57135},{\"end\":57158,\"start\":57144},{\"end\":57171,\"start\":57158},{\"end\":57187,\"start\":57171},{\"end\":57201,\"start\":57187},{\"end\":57213,\"start\":57201},{\"end\":57435,\"start\":57428},{\"end\":57451,\"start\":57435},{\"end\":57461,\"start\":57451},{\"end\":57471,\"start\":57461},{\"end\":57484,\"start\":57471},{\"end\":57696,\"start\":57685},{\"end\":57708,\"start\":57696},{\"end\":57724,\"start\":57708},{\"end\":58208,\"start\":58197},{\"end\":58220,\"start\":58208},{\"end\":58236,\"start\":58220},{\"end\":58664,\"start\":58650},{\"end\":58681,\"start\":58664},{\"end\":58703,\"start\":58681},{\"end\":58714,\"start\":58703}]", "bib_venue": "[{\"end\":48032,\"start\":48028},{\"end\":48293,\"start\":48222},{\"end\":48672,\"start\":48544},{\"end\":49068,\"start\":49064},{\"end\":49351,\"start\":49347},{\"end\":49619,\"start\":49615},{\"end\":49879,\"start\":49875},{\"end\":50170,\"start\":50165},{\"end\":50457,\"start\":50389},{\"end\":50738,\"start\":50734},{\"end\":51100,\"start\":51073},{\"end\":51429,\"start\":51343},{\"end\":51662,\"start\":51658},{\"end\":51895,\"start\":51891},{\"end\":52163,\"start\":52159},{\"end\":52374,\"start\":52321},{\"end\":52679,\"start\":52630},{\"end\":52997,\"start\":52940},{\"end\":53233,\"start\":53146},{\"end\":53609,\"start\":53602},{\"end\":53884,\"start\":53880},{\"end\":54075,\"start\":54008},{\"end\":54390,\"start\":54386},{\"end\":54666,\"start\":54653},{\"end\":54900,\"start\":54862},{\"end\":55178,\"start\":55124},{\"end\":55493,\"start\":55486},{\"end\":55858,\"start\":55848},{\"end\":56231,\"start\":56144},{\"end\":56563,\"start\":56556},{\"end\":56884,\"start\":56783},{\"end\":57133,\"start\":57048},{\"end\":57494,\"start\":57484},{\"end\":57812,\"start\":57724},{\"end\":58285,\"start\":58236},{\"end\":58718,\"start\":58714},{\"end\":57887,\"start\":57814}]"}}}, "year": 2023, "month": 12, "day": 17}