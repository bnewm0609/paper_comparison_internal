{"id": 219964549, "updated": "2023-04-05 02:57:57.045", "metadata": {"title": "Attention Scaling for Crowd Counting", "authors": "[{\"first\":\"Xiaoheng\",\"last\":\"Jiang\",\"middle\":[]},{\"first\":\"Li\",\"last\":\"Zhang\",\"middle\":[]},{\"first\":\"Mingliang\",\"last\":\"Xu\",\"middle\":[]},{\"first\":\"Tianzhu\",\"last\":\"Zhang\",\"middle\":[]},{\"first\":\"Pei\",\"last\":\"Lv\",\"middle\":[]},{\"first\":\"Bing\",\"last\":\"Zhou\",\"middle\":[]},{\"first\":\"Xin\",\"last\":\"Yang\",\"middle\":[]},{\"first\":\"Yanwei\",\"last\":\"Pang\",\"middle\":[]}]", "venue": "2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)", "journal": "2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)", "publication_date": {"year": 2020, "month": 6, "day": 1}, "abstract": "Convolutional Neural Network (CNN) based methods generally take crowd counting as a regression task by outputting crowd densities. They learn the mapping between image contents and crowd density distributions. Though having achieved promising results, these data-driven counting networks are prone to overestimate or underestimate people counts of regions with different density patterns, which degrades the whole count accuracy. To overcome this problem, we propose an approach to alleviate the counting performance differences in different regions. Specifically, our approach consists of two networks named Density Attention Network (DANet) and Attention Scaling Network (ASNet). DANet provides ASNet with attention masks related to regions of different density levels. ASNet first generates density maps and scaling factors and then multiplies them by attention masks to output separate attention-based density maps. These density maps are summed to give the final density map. The attention scaling factors help attenuate the estimation errors in different regions. Furthermore, we present a novel Adaptive Pyramid Loss (APLoss) to hierarchically calculate the estimation losses of sub-regions, which alleviates the training bias. Extensive experiments on four challenging datasets (ShanghaiTech Part A, UCF_CC_50, UCF-QNRF, and WorldExpo'10) demonstrate the superiority of the proposed approach.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": "3034785991", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/cvpr/JiangZXZLZYP20", "doi": "10.1109/cvpr42600.2020.00476"}}, "content": {"source": {"pdf_hash": "de0031a476f18208eb41de5fce2801e3c2368dce", "pdf_src": "ScienceParsePlus", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "07227d38a9000f531f544c07503ae114290fe9e3", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/de0031a476f18208eb41de5fce2801e3c2368dce.txt", "contents": "\nAttention Scaling for Crowd Counting\n\n\nXiaoheng Jiang jiangxiaoheng@zzu.edu.cn \nSchool of Information Engineering\nZhengzhou University\n\n\nLi Zhang laridzhang@gmail.com \nSchool of Information Engineering\nZhengzhou University\n\n\nMingliang Xu iexumingliang@zzu.edu.cn \nSchool of Information Engineering\nZhengzhou University\n\n\nTianzhu Zhang tzzhang@ustc.edu.cn \nSchool of Information Science and Technology\nUniversity of Science\nTechnology of China\n\nPei Lv \nSchool of Information Engineering\nZhengzhou University\n\n\nBing Zhou \nSchool of Information Engineering\nZhengzhou University\n\n\nXin Yang xinyang@dlut.edu.cn \nSchool of Computer Science and Technology\nDalian University of Technology\n\n\nYanwei Pang \nSchool of Electrical and Information Engineering\nTianjin University\n\n\nAttention Scaling for Crowd Counting\n\nConvolutional Neural Network (CNN) based methods generally take crowd counting as a regression task by outputting crowd densities. They learn the mapping between image contents and crowd density distributions. Though having achieved promising results, these data-driven counting networks are prone to overestimate or underestimate people counts of regions with different density patterns, which degrades the whole count accuracy. To overcome this problem, we propose an approach to alleviate the counting performance differences in different regions. Specifically, our approach consists of two networks named Density Attention Network (DANet) and Attention Scaling Network (ASNet). DANet provides ASNet with attention masks related to regions of different density levels. ASNet first generates density maps and scaling factors and then multiplies them by attention masks to output separate attention-based density maps. These density maps are summed to give the final density map. The attention scaling factors help attenuate the estimation errors in different regions. Furthermore, we present a novel Adaptive Pyramid Loss (APLoss) to hierarchically calculate the estimation losses of subregions, which alleviates the training bias. Extensive experiments on four challenging datasets (ShanghaiTech Part A, UCF CC 50, UCF-QNRF, and WorldExpo'10) demonstrate the superiority of the proposed approach.\n\nIntroduction\n\nThe computer vision based crowd counting task is to infer the number of people presented in images or videos. It recently has drawn much attention from researchers because of its great value in a wide range of real-world ap- * The corresponding author is Mingliang Xu. plications such as video surveillance, public safety, traffic control, agriculture monitoring, and cell counting.\n\nThe solution to this problem has progressively advanced from detecting individuals to presenting crowd density distributions. The integration of density maps gives the total count. Though previous methods have achieved some success, they fail to handle highly congested crowd scenes. These scenes usually exhibit the properties of heavy occlusions, large scale variation, perspective changes, and so on. Inspired by the great success that the convolutional neural networks have made in computer vision tasks like object detection [28,3,27], image segmentation [4,8], and object tracking [48,47], it recently springs dozens of CNN based crowd counting methods [37,22,18,41,10]. These methods have tried to exploit multi-scale feature fusion [49,29,35], multi-task learning [34,30,21], and the attention mechanism [45,44,19] to solve the above questions. Even so, there is still much room for improvement in counting performance, especially in several challenging crowd datasets [49,10,11].\n\nPeople in images or across scenes usually exhibit various distributions, with some regions overcrowded and other regions sparsely filled. Two main factors lead to this phenomenon. On the one hand, people scatter or gather together spontaneously in different regions of the scenes. On the other hand, people's scale varies due to the change of camera perspective. Accordingly, the people distributions in density maps present different patterns. Since CNNs depend heavily on the dataset during the training procedure, the learned data-driven counting networks are prone to be affected by different people distributions. As a result, they perform inconsistently in regions with different people distributions. It is observed that the predictions in high-density areas are likely to be higher than the ground truth, while the predictions in low-density areas are likely to be lower than Figure 1. One example of the crowd density estimation results on the ShanghaiTech Part A dataset. The red, green, blue colors in the density mask map represent the high-density, low-density, and background regions, respectively. Compared with the ground truth, the counting network predicts a higher count in the highdensity region and a lower count in the low-density region.\n\nthe ground truth, as demonstrated in Figure 1 and Figure 2.\n\nIn this paper, we aim to present an approach that can handle the congested scenes with various density distributions. To this end, we construct an attention scaling convolutional neural network named ASNet. ASNet first generates scaling factors to adjust the corresponding intermediate density maps. Then ASNet outputs several attention based density maps with each only focusing on the region of one certain density level. Finally, ASNet sums these attention based density maps to give the final density map. To provide attention masks for ASNet, we present a density attention network named DANet that performs the task of pixel-wise density segmentation.\n\nFurthermore, we present a novel loss function named Adaptive Pyramid Loss (APLoss). APLoss first divides the density map into non-uniform pyramidal sub-regions adaptively based on local people counts and then calculates each local normalized loss. Finally, APLoss accumulates all local losses to give the final estimation loss. APLoss alleviates the training bias and improves the generalization ability of the counting network. The contributions of this paper are summarized as follows:\n\n(1) We propose a novel attention scaling convolutional neural network (ASNet) that learns scaling factors to automatically adjust the density estimation of each corresponding sub-region, which reduces the local estimation error.\n\n(2) We propose a density attention network (DANet) that provides ASNet with attention masks concerning regions of different density levels.\n\n(3) We propose a novel adaptive pyramid loss (APLoss) that can ease the training bias and strengthen the generalization ability of the counting network. Figure 2. The comparisons between the average ground truth and the average estimations in low-density and high-density regions on the test set of the ShanghaiTech Part A dataset. The CNN based baseline counting network is prone to overestimate people count in the high-density region and underestimate people count in the low-density region.\n\n(4) Compared with other sixteen newly reported stateof-the-art results, our proposed approach demonstrates its superiority on four challenging crowd datasets.\n\nThe rest of the paper is organized as follows. First, we review the previous crowd counting methods in Section 2. Then, we present the proposed approach in Section 3. After that, we demonstrate the experimental results and analysis in Section 4. Finally, we conclude this paper in Section 5.\n\n\nRelated Work\n\nRecent years have witnessed progressive improvement in crowd counting from traditional methods [7,10,26,39,2] to CNN based methods [1,24,13,14,23,29,25]. In this section, we mainly review three kinds of common CNN based counting strategies.\n\n\nMulti-scale Information Fusion Approaches\n\nThis kind of approach aims at exploiting multi-scale features or multi-context information to deal with the people scale variation problem. Multi-column convolutional neural network (MCNN), proposed by Zhang et al. [49], utilizes multi-size filters to extract features that have receptive fields of different sizes. Similarly, Sam et al. [29] proposed Switch-CNN that utilizes a switch classifier to choose the optimal one from the density generator pool. Sindagi et al. [35] proposed Contextual Pyramid CNN (CP-CNN) to capture multi-scale information by combining global and local context priors. Further, Sindagi and Patel [37] presented a multi-level bottom-top and top-bottom fusion network (MBTTBF) that is elaborately designed to combine multiple shallow and deep features. Chen et al. [5] proposed a Scale Pyramid Network (SPN) that parallelly utilizes dilated convolutions of different rates in a shared single- column CNN to extract multi-scale features.\n\n\nAttention Guided Approaches\n\nThis kind of approach utilizes the visual attention mechanism to make the counting network intentionally focus on useful information to improve counting performance. Zhang et al. [45] proposed the Attentional Neural Field (ANF) that incorporates conditional random fields and non-local attention mechanisms to capture multi-scale features and long-range dependencies, strengthening the network's ability to handle large scale variation. Further, Zhang et al. [44] proposed a Relational Attention Network (RANet) that utilizes both local self-attention and global self-attention mechanisms to capture the interdependence information of pixels, obtaining more informative feature representations. The attention-injective deformable network (ADCrowdNet), proposed by Liu et al. [19], utilizes an attention map generator to provide regions and congestion degrees for the latter density map estimator. Liu et al. [17] proposed Recurrent Attentive Zooming Network (RAZN) that iteratively locates regions with high ambiguity and re-evaluates them in high-resolution space.\n\n\nMulti-task Learning Approaches\n\nThis kind of approach leverages auxiliary tasks to improve counting performance. Sindagi et al. [34] proposed to utilize one extra crowd count task to provide high-level priors for the density estimation task. The two jointly learned tasks enable the shared part of the network to learn more discriminative features. Shen et al. [30] presented the Adversarial Cross-Scale Consistency Pursuit (ACSCP) framework by exploiting the collaboration between adversarial learning and density estimation. Liu et al. [21] proposed to incorporate self-supervised image ranking and density estimation into a multi-task learning framework, which makes it possible to learn from an abundant unlabeled crowd dataset. Zhao et al. [50] proposed to formulate several heterogeneous attributes including geometric, semantic, and numeric information as auxiliary tasks to assist the counting task, which helps generate more robust features to handle scale variation and cluttered background.\n\n\nOur Approach\n\nThe architecture of the proposed method is illustrated in Figure 3. It consists of two convolutional networks: Density Attention Network (DANet) and Attention Scaling Network (ASNet). DANet provides ASNet with attention masks concerning regions of different density levels. ASNet has two branches with Density Estimation generating intermediate density maps and Attention Scaling generating scaling factors. ASNet multiples them by attention masks to output density maps that are summed to give the final density map. In this section, we first present DANet and ASNet and then introduce the novel Adaptive Pyramid Loss (APLoss).\n\n\nDensity Attention Network\n\nDANet aims to generate attention masks that represent regions of different density levels. It achieves this goal by performing a pixel-wise density segmentation task. That is, DANet classifies each pixel to one certain density level. The pixels of the same density level form the region of one attention mask.\n\nIt generally generates the ground-truth density map by utilizing a Gaussian kernel to blur each head annotation. The sum of the Gaussian kernel equals to one. Therefore, the actual value of each pixel in the density map does not represent the density level of one region. Similar to [9], we use the local count centered at one pixel to denote its density level, which makes the density level of pixels consistent with that of the local region. Specifically, we generate the pixel-wise ground-truth density level labels as follows. Firstly, we obtain all the local counts by scanning the ground-truth density maps in the training set pixel by pixel with a 64 \u00d7 64 sliding window. Secondly, we calculate the average value AvgCnt 11 of all non-zero local counts and find the minimum count M inCnt and maximal count M axCnt. Thirdly, we use {M inCnt, AvgCnt 11 , M axCnt} as the threshold set to divide the density into two levels : low density and high density. Iteratively, we can calculate the average values AvgCnt 21 of all low-density counts and AvgCnt 22 of all high-density counts. And we use the new threshold set {M inCnt, AvgCnt 21 , AvgCnt 11 , AvgCnt 22 , M axCnt} to divide the density into four levels, and so on. Fourthly, we use the obtained threshold set to label each pixel in the ground-truth density map automatically according to its corresponding local count. Given N density levels, there are N + 1 density labels including one extra background label. Figure 5. From the left column to the right column, they are background masks, low-density attention masks, high-level density masks, and the density level segmentation results, respectively.\n\nOnce we get the ground-truth density level labels, we train the proposed DANet to learn to classify each pixel of the input crowd image to different density levels. That is, DANet can segment the crowd image to regions of different density levels, with each region corresponding to one binary attention mask. Figure 5 shows two examples of attention masks. After obtaining the N foreground attention masks, we use one dilation operation to expand each mask. As a result, there are overlaps between adjacent attention masks. When summing the attention mask based density maps, the density values corresponding to the overlapped mask regions are averaged.\n\nThe DANet architecture is presented in the left column of Figure 4. We utilize the first 13 convolutional layers of the trained VGG-16 [33] model as the backbone. We add four new convolutional layers on top of the backbone. The first one has convolutional kernels with a size of 1 \u00d7 1 and has 256 output channels. The second one is a deconvolutional layer that has 2 \u00d7 2 kernels with a stride of 2 pixels. The third one has 3 \u00d7 3 kernels and 128 output channels. The fourth one has 1 \u00d7 1 kernels and N + 1 output maps. We train DANet with the two-dimensional softmax crossentropy loss.\n\n\nAttention Scaling Network\n\nAs stated in Section 1, CNN based counting networks are prone to overestimate or underestimate local counts in regions of different density levels. To correct the local density estimation, we propose the Attention Scaling Network (AS-Net). As demonstrated in Figure 3, ASNet has one Attention Scaling branch (AS-branch) and one Density Estimation branch (DE-branch). DE-branch generates intermediate density maps that are to be corrected. AS-branch learns to generate scaling factors that aims at adjusting the intermediate density maps in conjunction with attention masks provided by DANet. These scaling factors help fine-tune the overall crowd count of the corresponding local regions. This can be considered as a rough estimation strategy used by human beings, which adjusts the predicted count by multiplying a factor without pixel-wise re-calculation. It is noted that we only use the foreground attention masks that correspond to crowd regions. ASNet outputs N adjusted density maps by multiplying the intermediate density maps, scaling factors, and the attention masks. As a result, the adjusted density maps concentrate only on regions with the corresponding density masks. They are then summed to generate the final density map.\n\nThe configuration of the ASNet is presented in the right column of Figure 4. Similar to DANet, ASNet also uses the first 13 convolutional layers of the trained VGG-16 [33] model as the backbone. ASNet first adds one new convolutional layer and one new deconvolutional layer. On top of these layers, ASNet then splits into the AS-branch and the DE-branch. DE-branch has two new convolutional layers and outputs N intermediate density maps. AS-branch adds two new convolutional layers and the second one outputs N channels with the values un-activated. And then AS-branch utilizes the global average pooling (GAP) operation to transform the obtained N channels into N scalars that are then activated by the HardTanh function. We first set the output range of the HardTanh function to (\u22121, 1) and then add one to make the output scaling factors be in the range of (0, 2).\n\n\nAdaptive Pyramid Loss\n\nDuring the training stage, previous CNN based density estimation networks usually use the Euclidean distance between the whole estimated and ground-truth density maps as the loss function:\nL(\u0398) = 1 M M k=1 ||D(X k ; \u0398) \u2212 D k || 2 2 ,(1)\nwhere X k is the k-th input image, D k is its ground-truth density map, \u0398 is the parameters of the counting network, D(X k ; \u0398) is the estimated density map, and M is the size of the training set. This loss ignores the impact of densities of different levels on the network training procedure. Since the low-density and high-density distributions are usually quite unbalanced, the corresponding estimation errors can make the trained counting network biased. This weakens the generalization ability of the counting network. Further, even in the region of the same density level (as described in Section 3.1), there are density differences in its subregions.\n\nTo deal with the above problem, we propose a novel loss named Adaptive Pyramid Loss (APLoss). APLoss is able to adaptively divide the density map into non-uniform pyramidal subregions based on the ground-truth local crowd counts. And then APLoss first calculates each local relative estimation loss and then sums them to give the final loss. Figure 6 shows a two-level APLoss calculation.\n\nSpecifically, we calculate APLoss as follows. Firstly, we divide the ground-truth density map D k into a firstlevel grid of 2 \u00d7 2 and denote the subregion by R i1 with i 1 \u2208 {1, 2, 3, 4}. If the local crowd count of the subregion R i1 is higher than a given threshold T , we divide it into a second-level sub-grid of 2 \u00d7 2 and denote them by R i1,i2 with i 2 \u2208 {1, 2, 3, 4}. We iteratively divide one region into an n-th level sub-grid of 2 \u00d7 2 until its local crowd count is lower than T . We denote the n-th level subregion by R i1,\u00b7\u00b7\u00b7 ,in with i n \u2208 {1, 2, 3, 4}. After the division is completed, we can get one non-uniform pyramid grid. Secondly, we apply the obtained adaptive pyramid grid on the estimated density map D(X k ; \u0398) and calculate the local loss for each sub-region: (2) Finally, we aggregate all the local losses to give the final APLoss:\nl k Ri 1 ,\u00b7\u00b7\u00b7 ,i n\u22121 = \uf8f1 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f2 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f3 ||D R i 1 ,\u00b7\u00b7\u00b7 ,i n\u22121 (X k ;\u0398)\u2212D k R i 1 ,\u00b7\u00b7\u00b7 ,i n\u22121L AP Loss = 1 M M k=1 4 i1=1 l k Ri 1 .(3)\n\nExperiments\n\nWe validate the effectiveness of the proposed method on four challenging crowd datasets. The performance of the current counting networks still has a lot of room for improvement on three of the datasets including the Shang-haiTech Part A dataset [49], UCF CC 50 dataset [10], and UCF-QNRF dataset [11]. And the WorldExpo'10 [46] dataset provides cross-scene test sets that can test the adaptive capacity of the network for different scenes.\n\n\nDatasets\n\nShanghaiTech Part A dataset [49]. This crowd dataset contains 482 images that are randomly crawled from the Internet and are divided into the training and test sets. There are 300 images and 182 images in the training and test sets, respectively.\n\nUCF CCF 50 dataset [10]. This dataset shows a lot of challenges. It randomly collects only 50 images from the Internet. The number of people in these images varies largely with a wide range from 94 to 4,543. There are a total of 63,974 head annotations and the average number per image is 1280. Besides, this dataset has diverse scenes with varying perspective distortions.\n\nUCF-QNRF dataset [11]. This dataset contains 1,535 images with a total of 1,251,642 head annotations. The images are divided into the training set with 1,201 images and the test set with 334 images, respectively. This dataset has much more annotated heads than currently available crowd datasets and is suitable for deep CNN based methods.\n\nWorldExpo'10 dataset [46]. This dataset contains 1,132 annotated video sequences that are captured by 108 surveillance cameras from Shanghai 2010 WorldExpo event. There are a total of 199,923 annotated pedestrians from 3,980 frames. The dataset is divided into the training set with frames from 103 scenes and the test set with 600 frames from another 5 scenes.\n\n\nSettings\n\nData. For the DANet, we augment the training data by cropping nine image patches at random locations in one image. Each image patch is one-fourth of the size of the original image. For the ASNet, we crop fixed-size image patches of 128 \u00d7 128 pixels at random locations in one image. Also, we flip each image patch horizontally to double the training set. Further, random color jitter is used in each epoch during the training. In particular, because the image resolution of the UCF-QNRF dataset [11] is too large, we resized its longer side to 1024 pixels and kept the aspect ratio constant.\n\nGround Truth Generation. We generate the groundtruth density maps by using a normalized Gaussian kernel to blur each head annotation, thus summing the density map equals the crowd count. In our experiments, we use a fixed spread Gaussian to generate density maps.\n\nTraining. For both the DANet and the ASNet, the first 13 convolutional layers are initialized from a pre-trained VGG-16 [33] model and the rest layers are randomly initialized by a Gaussian distribution with the mean of 0 and the standard deviation of 0.01. The Adam algorithm [15] is used to optimize the model. Both the DANet and the AS-Net are trained in an end-to-end manner. The cross-entropy is adopted as the loss function for the DANet. We firstly train the DANet to generate attention masks and set the size of the training batch to 1. Then we train the ASNet and set the size of the training batch to 8.\n\n\nEvaluation Metrics\n\nWe adopt the Mean Absolute Error (MAE) and the Mean Squared Error (MSE) to evaluate our method. The MAE and MSE are defined as follows:\nM AE = 1 N N i=1 |C i \u2212\u0108 i |,(4)M SE = 1 N N i=1 ||C i \u2212\u0108 i || 2 ,(5)\nwhere N is the number of the test images, C i and\u0108 i are the ground-truth and estimated counts of the i-th image, respectively.\n\n\nEvaluation and Analysis\n\nIn this section, we carry out experiments on the four datasets. We first conduct an ablation study to analyze the attention scaling and APLoss on the ShanghaiTech Part A dataset. And then we present the experimental results on the four datasets in detail. Finally, we present a qualitative analysis on the ShanghaiTech Part A dataset [49].\n\n\nAblation Study\n\nAttention scaling. Our goal is to find out the impact of the attention scaling on crowd counting performance. Since the density can be divided into different levels, we aim to find the relatively optimal density levels. As described in Section 3.2, we can divide the density via the threshold set. In our experiments, we test two, four, and eight density levels. Accordingly, DANet provides two, four, and eight attention masks, without the background mask. The ablation results are presented in Table 1 It is seen that ASNet with 2 attention masks achieves the best result. More masks can bring more detailed density distribution information for the density prediction. However, the increase in attention masks may make it harder to fuse the whole density distribution.\n\nAPLoss. Since the training images for ASNet are of the same size of 128 \u00d7 128 pixels, we use the AvgCnt 11 as the threshold T . We test 2-level and 3-level APLoss, respectively. The experimental results are presented in Table 2. It is seen that the APLoss further improves the counting performance of ASNet. ASNet with 2-level APLoss achieves an MAE of 57.78, outperforming ASNet with MSE loss and ASNet with 3-level APLoss. The 2-level APLoss has a better generalization ability than the 3-level APLoss.\n\nBesides, we carry out one statistical analysis to show that our method indeed reduces the estimation errors in regions of different density levels. The results are presented in Figure 7. Compared with the baseline network, our ASNet reduces the MAEs of low-density and high-density regions from 27.19 to 21.58 and from 55.66 to 45.94, respectively.\n\n\nResults on Four Datasets\n\nIn this section, we evaluate our approach against sixteen currently reported methods [36,5,12,19,40,32,38,31,42,20,43,6,37,22,18,41,10] on ShanghaiTech Part A dataset [49], UCF CCF 50 dataset [10], UCF-QNRF Dataset [11] and WorldExpo'10 dataset [46]. For simplicity, we denote ShanghaiTech Part A Dataset by SHTech Part A in our experiments. During the test, each whole image in the test sets of the four datasets is sent directly into our AS-Net model. There are a few things that need to be made clear first. We perform a 5-fold cross-validation on the UCF CCF 50 Dataset [10] by following the standard protocol adopted in [10]. On the WorldExpo'10 dataset [46], we prune the last convolutional layer by setting the features out of ROI regions to zero, which is consistent with the previous work [46]. In addition, we only use the MAE metric to evaluate our approach. We first calculate the MAE for each test scene and then averages all the MAEs to evaluate the performance of ASNet across different test scenes.\n\nExperimental results are presented in Tabel 3. All our results are achieved by using the ASNet model trained with the 2-level APLoss. (1) On the ShanghaiTech Part A dataset, our method achieves the second-best result with an MAE of 57.78, which is only 1.3% higher than that of the best method PGCNet [43]. However, on the UCF CC 50 dataset, our method achieves the lowest MAE of 174.84 that is 28.5% lower than that of PGCNet. On the World-Expo'10 dataset, our method also achieves the lowest MAE of 6.64 that is 9.1% lower than that of PGCNet. It should be noted that PGCNet uses additional perspective information to boost the accuracy of the prediction on the ShanghaiTech Part A dataset. (2) On the UCF CC 50 dataset, our method reduces the MAE by 7.2% compared with the second-best method SPN+L2SM [42]. (3) On the UCF-QNRF dataset, our method achieves the second-best result with an MAE of 91.59, which is only 3.3% higher than that of the best BL [43] method. However, the MAE of our method is 8.0% and 23.8% lower than the BL method on the ShanghaiTech Part A dataset and the UCF CC 50 dataset, respectively. The BL method uses the VGG-19 [33] model as the backbone which has deeper convolutional than our VGG-16 [33] backbone. (4) On the WorldExpo'10 dataset, our method surpasses all the other methods.\n\nIt noted that in Tabel 3 that some methods only achieve good performance on one dataset and relatively poor performance on the rest of these datasets. To make a comprehensive evaluation of the performance of all these methods on the four datasets, we introduce a simple evaluation metric named average ranking (denoted by avg. R. in Tabel 3). We obtain the average ranking value by using the sum of all ranks that one method gains to divide the number of datasets it utilizes. It is demonstrated that our method achieves the first average ranking which means it is able to excel in dealing with various complex crowd scenes.\n\n\nQualitative Analysis\n\nWe further carry out a qualitative analysis to investigate the performance of our ASNet. We present some qualitative comparisons between the baseline network and our ASNet in Figure 8. The main difference between them is that AS-Net introduces attention mechanisms. It is observed from the visualization that our ASNet is much more robust on scenes with cluttered backgrounds like trees. We use red rectangles to mark the regions with cluttered backgrounds. There is obvious evidence from red rectangles of the first Figure 8. Visually qualitative analysis on the ShanghaiTech Part A dataset. ASNet is more robust to cluttered backgrounds than the baseline network. and third rows where trees are close to the high-density regions. The baseline network causes much more estimation errors than the ASNet. Further, the second and the fourth rows show evidence in red rectangles where there are people in cluttered background. Our ASNet has a much more accurate density estimation. This demonstrates that the attention scaling mechanism not only attenuates the estimation error in regions of different density levels but also plays an important role in reducing the estimation error in cluttered background.\n\n\nConclusion\n\nIn this paper, we have presented a novel attention scaling based counting network that exploits attention masks and scaling factors to correct density estimations in regions of different density levels. To this end, We present one density attention network (DANet) to provide attention masks for the attention scaling network (ASNet). ASNet is responsible for generating scaling factors and outputting attention based density maps that only focus on their corresponding attention regions. These local density estimations together form the final density map. Besides, we introduce a novel adaptive pyramid loss (APLoss) that hierarchically calculates local estimation loss, strengthening the generalization ability of the counting network. Extensive experiments on four challenging datasets demonstrate the superiority of the proposed approach over current sixteen state-ofthe-art methods.\n\nFigure 3 .\n3The architecture of the proposed approach. Density Attention Network (DANet) provides attention masks for the Attention Scaling Network (ASNet). ASNet has two branches. The Density Estimation branch generates intermediate density maps and the Attention Scaling branch generates scaling factors. ASNet multiplies intermediate density maps and scaling factors by attention masks to generate attention based density maps, which are then summed to give the final density map.\n\nFigure 4 .\n4The configurations of the density attention network (DANet) and the attention scaling network (ASNet).\n\nFigure 6 .\n6The demonstration of the two-level adaptive pyramid loss (APLoss).\n\n\n. We first train a baseline counting network by just utilizing the backbone and the DE-branchw/ scale \nw/o scaling \nMasks MAE \nMSE \nMAE \nMSE \n0 \n-\n-\n68.31 109.74 \n2 \n60.16 98.61 62.70 104.41 \n4 \n61.44 106.70 63.37 106.92 \n8 \n61.78 102.94 63.64 107.74 \n\nTable 1. Attention scaling ablation of our ASNet on ShanghaiTech \nPart A dataset, with 0, 2, 4, and 8 attention masks. \n\nMSE Loss \n2-level APLoss 3-level APLoss \nMAE MSE MAE \nMSE \nMAE \nMSE \n60.16 98.61 57.78 90.13 58.99 95.97 \n\nTable 2. APLoss ablation of our ASNet on ShanghaiTech Part A \ndataset. \nSHTech Part A \n\nUCF CC 50 \nUCF-QNRF \nWorldExpo10 \nMethod \nMAE MSE R. MAE MSE R. MAE MSE R. S1 \nS2 \nS3 \nS4 \nS5 avg. R. avg. R. \nHA-CCN [36] \n62.9 94.9 9 256.2 348.4 14 118.1 180.4 11 -\n-\n-\n-\n-\n-\n-11.3 \nSPN [5] \n61.7 99.5 7 259.2 335.9 15 \n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n11 \nTEDnet [12] \n64.2 109.1 13 249.4 354.5 13 113 \n188 10 2.3 10.1 11.3 13.8 2.6 8.0 6 10.5 \nADCrowdNet [19] 63.2 98.9 12 266.4 358.0 16 \n-\n-\n-1.6 13.2 8.7 10.6 2.6 7.3 3 10.3 \nASD [40] \n65.6 98.0 17 196.2 270.9 3 \n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n10 \nCFF [32] \n65.2 109.4 16 \n-\n-\n-93.8 146.5 3 \n-\n-\n-\n-\n-\n-\n-\n9.5 \nSFCN [38] \n64.8 107.5 15 214.2 318.2 6 102.0 171.4 6 \n-\n-\n-\n-\n-\n-\n-\n9 \nPACNN [31]+ [16] 62.4 102.0 11 241.7 320.7 11 \n-\n-\n-2.3 12.5 9.1 11.2 3.8 7.8 5 \n9 \nSPN+L2SM [42] \n64.2 98.4 14 188.4 315.3 2 104.7 173.6 8 \n-\n-\n-\n-\n-\n-\n-\n8 \nCAN [20] \n62.3 100.0 10 212.2 243.7 5 107 \n183 9 2.9 12.0 10.0 7.9 4.3 7.4 4 \n7 \nPGCNet [43] \n57.0 86.0 1 244.6 361.2 12 \n-\n-\n-2.5 12.7 8.4 13.7 3.2 8.1 7 \n6.7 \nSPANet+SANet [6] 59.4 92.5 4 232.6 311.7 9 \n-\n-\n-\n-\n-\n-\n-\n-\n-\n-\n6.5 \nMBTTB-SCFB [37] 60.2 94.1 5 233.1 300.9 10 97.5 165.2 4 \n-\n-\n-\n-\n-\n-\n-\n6.3 \nBL [22] \n62.8 101.8 8 229.3 308.2 8 88.7 154.8 1 \n-\n-\n-\n-\n-\n-\n-\n5.7 \nDSSINet [18] \n60.63 96.04 6 216.9 302.4 7 99.1 159.2 5 1.57 9.51 9.46 10.35 2.49 6.67 2 \n5 \nS-DCNet [41] \n58.3 95.0 3 204.2 301.3 4 104.4 176.1 7 \n-\n-\n-\n-\n-\n-\n-\n4.7 \nOurs \n57.78 90.13 2 174.84 251.63 1 91.59 159.71 2 2.22 10.11 8.89 7.14 4.84 6.64 1 \n1.5 \n\nTable 3. Comparisons of our ASNet with sixteen state-of-the-art methods on four datasets. The average ranking (denoted by avg. R.) is \nobtained by using the sum of all rankings that one method gains to divide the number of datasets it utilizes. \n\nFigure 7. Comparison of ASNet with the baseline on Shang-\nhaiTech Part A dataset. ASNet evidently reduces the estimation \nerrors in both low-density and high-density regions. \n\nof the proposed ASNet. It achieves an MAE of 68.31 and \nan MSE of 109.74. ASNet achieves the MAEs of 60.16, \n61.44, and 61.78 when it uses 2, 4, and 8 attention masks, \nrespectively. It means that the attention scaling mechanism \ndoes improve counting performance. Further, we carry out \nextra experiments by removing the scaling factors but still \nusing the attention masks provided by DANet. The results \nare presented in the right column of Table 1. It achieves the \nMAEs of 62.70, 63.37, and 63.64 when it only uses 2, 4, \nand 8 attention masks without scaling factors, respectively. \n\n\nCrowdnet: a deep convolutional network for dense crowd counting. Lokesh Boominathan, S S Srinivas, R Venkatesh Kruthiventi, Babu, Proceedings of the ACM Conference on Multimedia. the ACM Conference on MultimediaLokesh Boominathan, Srinivas SS Kruthiventi, and R Venkatesh Babu. Crowdnet: a deep convolutional network for dense crowd counting. In Proceedings of the ACM Conference on Multimedia, pages 640-644, 2016. 2\n\nPedestrian detection inspired by appearance constancy and shape symmetry. Jiale Cao, Yanwei Pang, Xuelong Li, IEEE Transactions on Image Processing. 2523Jiale Cao, Yanwei Pang, and Xuelong Li. Pedestrian detec- tion inspired by appearance constancy and shape symmetry. IEEE Transactions on Image Processing, 25(23):5538-5551, 2016. 2\n\nLearning multilayer channel features for pedestrian detection. Jiale Cao, Yanwei Pang, Xuelong Li, IEEE Transactions on Image Processing. 267Jiale Cao, Yanwei Pang, and Xuelong Li. Learning multi- layer channel features for pedestrian detection. IEEE Trans- actions on Image Processing, 26(7):3210-3220, 2017. 1\n\nEncoder-decoder with atrous separable convolution for semantic image segmentation. Yukun Liang-Chieh Chen, George Zhu, Florian Papandreou, Hartwig Schroff, Adam, Proceedings of the European Conference on Computer Vision. the European Conference on Computer VisionLiang-Chieh Chen, Yukun Zhu, George Papandreou, Florian Schroff, and Hartwig Adam. Encoder-decoder with atrous separable convolution for semantic image segmentation. In Proceedings of the European Conference on Computer Vi- sion, pages 801-818, 2018. 1\n\nScale pyramid network for crowd counting. Xinya Chen, Yanrui Bin, Nong Sang, Changxin Gao, IEEE Winter Conference on Applications of Computer Vision. 27Xinya Chen, Yanrui Bin, Nong Sang, and Changxin Gao. Scale pyramid network for crowd counting. In IEEE Win- ter Conference on Applications of Computer Vision, pages 1941-1950, 2019. 2, 7\n\nLearning spatial awareness to improve crowd counting. Zhi-Qi Cheng, Jun-Xiu Li, Qi Dai, Xiao Wu, Alexander G Hauptmann, Proceedings of the IEEE International Conference on Computer Vision. the IEEE International Conference on Computer VisionZhi-Qi Cheng, Jun-Xiu Li, Qi Dai, Xiao Wu, and Alexan- der G. Hauptmann. Learning spatial awareness to improve crowd counting. In Proceedings of the IEEE International Conference on Computer Vision, pages 6151-6160, 2019. 7\n\nBernt Schiele, and Pietro Perona. Pedestrian detection: an evaluation of the state of the art. Piotr Dollar, Christian Wojek, IEEE Transactions on Pattern Analysis and Machine Intelligence. 344Piotr Dollar, Christian Wojek, Bernt Schiele, and Pietro Per- ona. Pedestrian detection: an evaluation of the state of the art. IEEE Transactions on Pattern Analysis and Machine In- telligence, 34(4):743-761, 2012. 2\n\nPiotr Doll\u00e1r, and Ross Girshick. Mask r-cnn. Kaiming He, Georgia Gkioxari, Proceedings of the IEEE International Conference on Computer Vision. the IEEE International Conference on Computer VisionKaiming He, Georgia Gkioxari, Piotr Doll\u00e1r, and Ross Gir- shick. Mask r-cnn. In Proceedings of the IEEE International Conference on Computer Vision, pages 2961-2969, 2017. 1\n\nCrowd counting using scale-aware attention networks. Mohammad Hossain, Mehrdad Hosseinzadeh, Omit Chanda, Yang Wang, IEEE Winter Conference on Applications of Computer Vision. Mohammad Hossain, Mehrdad Hosseinzadeh, Omit Chanda, and Yang Wang. Crowd counting using scale-aware attention networks. In IEEE Winter Conference on Applications of Computer Vision, pages 1280-1288, 2019. 4\n\nMulti-source multi-scale counting in extremely dense crowd images. Haroon Idrees, Imran Saleemi, Cody Seibert, Mubarak Shah, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern Recognition67Haroon Idrees, Imran Saleemi, Cody Seibert, and Mubarak Shah. Multi-source multi-scale counting in extremely dense crowd images. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2547- 2554, 2013. 1, 2, 5, 6, 7\n\nComposition loss for counting, density map estimation and localization in dense crowds. Haroon Idrees, Muhmmad Tayyab, Kishan Athrey, Dong Zhang, Somaya Al-Maadeed, Nasir Rajpoot, Mubarak Shah, Proceedings of the European Conference on Computer Vision. the European Conference on Computer Vision67Haroon Idrees, Muhmmad Tayyab, Kishan Athrey, Dong Zhang, Somaya Al-Maadeed, Nasir Rajpoot, and Mubarak Shah. Composition loss for counting, density map estima- tion and localization in dense crowds. In Proceedings of the European Conference on Computer Vision, pages 532-546, 2018. 1, 5, 6, 7\n\nCrowd counting and density estimation by trellis encoderdecoder networks. Xiaolong Jiang, Zehao Xiao, Baochang Zhang, Xiantong Zhen, Xianbin Cao, David Doermann, Ling Shao, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionXiaolong Jiang, Zehao Xiao, Baochang Zhang, Xiantong Zhen, Xianbin Cao, David Doermann, and Ling Shao. Crowd counting and density estimation by trellis encoder- decoder networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 6133- 6142, 2019. 7\n\nLearning multi-level density maps for crowd counting. Xiaoheng Jiang, Li Zhang, Pei Lv, Yibo Guo, Ruijie Zhu, Yafei Li, Yanwei Pang, Xi Li, Bing Zhou, Mingliang Xu, Xiaoheng Jiang, Li Zhang, Pei Lv, Yibo Guo, Ruijie Zhu, Yafei Li, Yanwei Pang, Xi Li, Bing Zhou, and Mingliang Xu. Learning multi-level density maps for crowd counting.\n\n. 10.1109/TNNLS.2019.2933IEEE Transactions on Neural Networks and Learning Systems. 2IEEE Transactions on Neural Networks and Learning Sys- tems, DOI:10.1109/TNNLS.2019.2933, 2019. 2\n\nBeyond counting: comparisons of density maps for crowd analysis taskscounting, detection, and tracking. Di Kang, Zheng Ma, Antoni B Chan, IEEE Transactions on Circuits and Systems for Video Technology. 29Di Kang, Zheng Ma, and Antoni B Chan. Beyond count- ing: comparisons of density maps for crowd analysis tasks- counting, detection, and tracking. IEEE Transactions on Cir- cuits and Systems for Video Technology, 29(5):1408-1422, 2018. 2\n\nAdam: a method for stochastic optimization. P Diederik, Jimmy Kingma, Ba, arXiv:1412.6980arXiv preprintDiederik P Kingma and Jimmy Ba. Adam: a method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014. 6\n\nCsrnet: dilated convolutional neural networks for understanding the highly congested scenes. Yuhong Li, Xiaofan Zhang, Deming Chen, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionYuhong Li, Xiaofan Zhang, and Deming Chen. Csrnet: di- lated convolutional neural networks for understanding the highly congested scenes. In Proceedings of the IEEE Con- ference on Computer Vision and Pattern Recognition, pages 1091-1100, 2018. 7\n\nRecurrent attentive zooming for joint crowd counting and precise localization. Chenchen Liu, Xinyu Weng, Yadong Mu, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionChenchen Liu, Xinyu Weng, and Yadong Mu. Recurrent at- tentive zooming for joint crowd counting and precise local- ization. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1217-1226, 2019. 3\n\nCrowd counting with deep structured scale integration network. Lingbo Liu, Zhilin Qiu, Guanbin Li, Shufan Liu, Wanli Ouyang, Liang Lin, Proceedings of the IEEE International Conference on Computer Vision. the IEEE International Conference on Computer Vision17Lingbo Liu, Zhilin Qiu, Guanbin Li, Shufan Liu, Wanli Ouyang, and Liang Lin. Crowd counting with deep struc- tured scale integration network. In Proceedings of the IEEE International Conference on Computer Vision, pages 1774- 1783, 2019. 1, 7\n\nAdcrowdnet: An attention-injective deformable convolutional network for crowd understanding. Ning Liu, Yongchao Long, Changqing Zou, Qun Niu, Li Pan, Hefeng Wu, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern Recognition17Ning Liu, Yongchao Long, Changqing Zou, Qun Niu, Li Pan, and Hefeng Wu. Adcrowdnet: An attention-injective deformable convolutional network for crowd understanding. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 3225-3234, 2019. 1, 3, 7\n\nContextaware crowd counting. Weizhe Liu, Mathieu Salzmann, Pascal Fua, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionWeizhe Liu, Mathieu Salzmann, and Pascal Fua. Context- aware crowd counting. In Proceedings of the IEEE Con- ference on Computer Vision and Pattern Recognition, pages 5099-5108, 2019. 7\n\nLeveraging unlabeled data for crowd counting by learning to rank. Xialei Liu, Joost Van De Weijer, Andrew D Bagdanov, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern Recognition13Xialei Liu, Joost van de Weijer, and Andrew D Bagdanov. Leveraging unlabeled data for crowd counting by learning to rank. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 7661-7669, 2018. 1, 3\n\nBayesian loss for crowd count estimation with point supervision. Zhiheng Ma, Xing Wei, Xiaopeng Hong, Yihong Gong, Proceedings of the IEEE International Conference on Computer Vision. the IEEE International Conference on Computer Vision17Zhiheng Ma, Xing Wei, Xiaopeng Hong, and Yihong Gong. Bayesian loss for crowd count estimation with point supervi- sion. In Proceedings of the IEEE International Conference on Computer Vision, pages 6141-6150, 2019. 1, 7\n\nResnetcrowd: a residual deep learning architecture for crowd counting, violent behaviour detection and crowd density level classification. Mark Marsden, Kevin Mcguinness, Suzanne Little, Noel E O&apos; Connor, Proceedings of the IEEE Conference on Advanced Video and Signal Based Surveillance. the IEEE Conference on Advanced Video and Signal Based SurveillanceMark Marsden, Kevin McGuinness, Suzanne Little, and Noel E O'Connor. Resnetcrowd: a residual deep learning architecture for crowd counting, violent behaviour detection and crowd density level classification. In Proceedings of the IEEE Conference on Advanced Video and Signal Based Surveillance, pages 1-7, 2017. 2\n\nTowards perspective-free object counting with deep learning. Daniel Onoro, - Rubio, Roberto J L\u00f3pez-Sastre , Proceedings of the European Conference on Computer Vision. the European Conference on Computer VisionDaniel Onoro-Rubio and Roberto J L\u00f3pez-Sastre. Towards perspective-free object counting with deep learning. In Pro- ceedings of the European Conference on Computer Vision, pages 615-629, 2016. 2\n\nLearning sampling distributions for efficient object detection. Yanwei Pang, Jiale Cao, Xuelong Li, IEEE Transactions on Cybernetics. 471Yanwei Pang, Jiale Cao, and Xuelong Li. Learning sampling distributions for efficient object detection. IEEE Transac- tions on Cybernetics, 47(1):117-129, 2017. 2\n\nCount forest: co-voting uncertain number of targets using random forest for crowd density estimation. Viet-Quoc Pham, Tatsuo Kozakaya, Osamu Yamaguchi, Ryuzo Okada, Proceedings of the IEEE International Conference on Computer Vision. the IEEE International Conference on Computer VisionViet-Quoc Pham, Tatsuo Kozakaya, Osamu Yamaguchi, and Ryuzo Okada. Count forest: co-voting uncertain number of targets using random forest for crowd density estimation. In Proceedings of the IEEE International Conference on Com- puter Vision, pages 3253-3261, 2015. 2\n\nYou only look once: Unified, real-time object detection. Joseph Redmon, Santosh Kumar Divvala, Ross B Girshick, Ali Farhadi, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionJoseph Redmon, Santosh Kumar Divvala, Ross B. Girshick, and Ali Farhadi. You only look once: Unified, real-time ob- ject detection. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 779-788, 2016. 1\n\nFaster r-cnn: Towards real-time object detection with region proposal networks. Kaiming Shaoqing Ren, Ross B He, Jian Girshick, Sun, Proceedings of the Neural Information Processing Systems. the Neural Information Processing SystemsShaoqing Ren, Kaiming He, Ross B. Girshick, and Jian Sun. Faster r-cnn: Towards real-time object detection with region proposal networks. In Proceedings of the Neural Information Processing Systems, pages 91-99, 2015. 1\n\nSwitching convolutional neural network for crowd counting. Shiv Deepak Babu Sam, R Venkatesh Surya, Babu, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern Recognition16Deepak Babu Sam, Shiv Surya, and R Venkatesh Babu. Switching convolutional neural network for crowd counting. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, page 6, 2017. 1, 2\n\nCrowd counting via adversarial cross-scale consistency pursuit. Zan Shen, Yi Xu, Bingbing Ni, Minsi Wang, Jianguo Hu, Xiaokang Yang, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern Recognition13Zan Shen, Yi Xu, Bingbing Ni, Minsi Wang, Jianguo Hu, and Xiaokang Yang. Crowd counting via adversarial cross-scale consistency pursuit. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 5245- 5254, 2018. 1, 3\n\nRevisiting perspective information for efficient crowd counting. Miaojing Shi, Zhaohui Yang, Chao Xu, Qijun Chen, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionMiaojing Shi, Zhaohui Yang, Chao Xu, and Qijun Chen. Re- visiting perspective information for efficient crowd counting. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 7279-7288, 2019. 7\n\nCounting with focus for free. Zenglin Shi, Pascal Mettes, G M Cees, Snoek, Proceedings of the IEEE International Conference on Computer Vision. the IEEE International Conference on Computer VisionZenglin Shi, Pascal Mettes, and Cees G. M. Snoek. Counting with focus for free. In Proceedings of the IEEE International Conference on Computer Vision, pages 4199-4208, 2019. 7\n\nVery deep convolutional networks for large-scale image recognition. Karen Simonyan, Andrew Zisserman, arXiv:1409.15566arXiv preprintKaren Simonyan and Andrew Zisserman. Very deep convo- lutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556, 2014. 4, 5, 6, 8\n\nCnn-based cascaded multi-task learning of high-level prior and density estimation for crowd counting. A Vishwanath, Sindagi, M Vishal, Patel, Proceedings of the IEEE Conference on Advanced Video and Signal Based Surveillance. the IEEE Conference on Advanced Video and Signal Based Surveillance13Vishwanath A Sindagi and Vishal M Patel. Cnn-based cas- caded multi-task learning of high-level prior and density esti- mation for crowd counting. In Proceedings of the IEEE Con- ference on Advanced Video and Signal Based Surveillance, pages 1-6, 2017. 1, 3\n\nGenerating highquality crowd density maps using contextual pyramid cnns. A Vishwanath, Sindagi, M Vishal, Patel, Proceedings of the IEEE International Conference on Computer Vision. the IEEE International Conference on Computer Vision1Vishwanath A Sindagi and Vishal M Patel. Generating high- quality crowd density maps using contextual pyramid cnns. In Proceedings of the IEEE International Conference on Computer Vision, pages 1879-1888, 2017. 1, 2\n\nHa-ccn: Hierarchical attention-based crowd counting network. A Vishwanath, Sindagi, M Vishal, Patel, IEEE Transactions on Image Processing. 297Vishwanath A Sindagi and Vishal M Patel. Ha-ccn: Hierar- chical attention-based crowd counting network. IEEE Trans- actions on Image Processing, 29:323-335, 2019. 7\n\nMulti-level bottom-top and top-bottom feature fusion for crowd counting. A Vishwanath, Vishal M Sindagi, Patel, Proceedings of the IEEE International Conference on Computer Vision. the IEEE International Conference on Computer VisionVishwanath A. Sindagi and Vishal M. Patel. Multi-level bottom-top and top-bottom feature fusion for crowd count- ing. In Proceedings of the IEEE International Conference on Computer Vision, pages 1002-1012, 2019. 1, 2, 7\n\nLearning from synthetic data for crowd counting in the wild. Qi Wang, Junyu Gao, Wei Lin, Yuan Yuan, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionQi Wang, Junyu Gao, Wei Lin, and Yuan Yuan. Learning from synthetic data for crowd counting in the wild. In Pro- ceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 8198-8207, 2019. 7\n\nFast visual object counting via example-based density estimation. Yi Wang, Yuexian Zou, Proceedings of the IEEE International Conference on Image Processing. the IEEE International Conference on Image ProcessingYi Wang and Yuexian Zou. Fast visual object counting via example-based density estimation. In Proceedings of the IEEE International Conference on Image Processing, pages 3653-3657. IEEE, 2016. 2\n\nAdaptive scenario discovery for crowd counting. Xingjiao Wu, Yingbin Zheng, Wenxin Hao Ye, Jing Hu, Liang Yang, He, IEEE International Conference on Acoustics, Speech and Signal Processing. Xingjiao Wu, Yingbin Zheng, Hao Ye, Wenxin Hu, Jing Yang, and Liang He. Adaptive scenario discovery for crowd counting. In IEEE International Conference on Acoustics, Speech and Signal Processing, pages 2382-2386, 2019. 7\n\nFrom open set to closed set: Counting objects by spatial divide-and-conquer. Haipeng Xiong, Hao Lu, Chengxin Liu, Liang Liu, Zhiguo Cao, Chunhua Shen, Proceedings of the IEEE International Conference on Computer Vision. the IEEE International Conference on Computer Vision17Haipeng Xiong, Hao Lu, Chengxin Liu, Liang Liu, Zhiguo Cao, and Chunhua Shen. From open set to closed set: Count- ing objects by spatial divide-and-conquer. In Proceedings of the IEEE International Conference on Computer Vision, pages 8361-837, 2019. 1, 7\n\nLearn to scale: Generating multipolar normalized density maps for crowd counting. Chenfeng Xu, Kai Qiu, Jianlong Fu, Song Bai, Yongchao Xu, Xiang Bai, Proceedings of the IEEE International Conference on Computer Vision. the IEEE International Conference on Computer Vision7Chenfeng Xu, Kai Qiu, Jianlong Fu, Song Bai, Yongchao Xu, and Xiang Bai. Learn to scale: Generating multipolar normalized density maps for crowd counting. In Proceedings of the IEEE International Conference on Computer Vision, pages 8381-8389, 2019. 7, 8\n\nPerspectiveguided convolution networks for crowd counting. Zhaoyi Yan, Yuchen Yuan, Wangmeng Zuo, Xiao Tan, Yezhen Wang, Shilei Wen, Errui Ding, Proceedings of the IEEE International Conference on Computer Vision. the IEEE International Conference on Computer Vision7Zhaoyi Yan, Yuchen Yuan, Wangmeng Zuo, Xiao Tan, Yezhen Wang, Shilei Wen, and Errui Ding. Perspective- guided convolution networks for crowd counting. In Pro- ceedings of the IEEE International Conference on Computer Vision, pages 952-961, 2019. 7, 8\n\nRelational attention network for crowd counting. Anran Zhang, Jiayi Shen, Zehao Xiao, Fan Zhu, Xiantong Zhen, Xianbin Cao, Ling Shao, Proceedings of the IEEE International Conference on Computer Vision. the IEEE International Conference on Computer Vision13Anran Zhang, Jiayi Shen, Zehao Xiao, Fan Zhu, Xiantong Zhen, Xianbin Cao, and Ling Shao. Relational attention net- work for crowd counting. In Proceedings of the IEEE Inter- national Conference on Computer Vision, pages 6787-6796, 2019. 1, 3\n\nAttentional neural fields for crowd counting. Anran Zhang, Lei Yue, Jiayi Shen, Fan Zhu, Xiantong Zhen, Xianbin Cao, Ling Shao, Proceedings of the IEEE International Conference on Computer Vision. the IEEE International Conference on Computer Vision13Anran Zhang, Lei Yue, Jiayi Shen, Fan Zhu, Xiantong Zhen, Xianbin Cao, and Ling Shao. Attentional neural fields for crowd counting. In Proceedings of the IEEE International Conference on Computer Vision, pages 5713-5722, 2019. 1, 3\n\nCross-scene crowd counting via deep convolutional neural networks. Cong Zhang, Hongsheng Li, Xiaogang Wang, Xiaokang Yang, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern Recognition6Cong Zhang, Hongsheng Li, Xiaogang Wang, and Xiaokang Yang. Cross-scene crowd counting via deep convolutional neural networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 833-841, 2015. 5, 6, 7, 8\n\nLearning multi-task correlation particle filters for visual tracking. Tianzhu Zhang, Changsheng Xu, Ming-Hsuan Yang, IEEE Transactions on Pattern Analysis and Machine Intelligence. 412Tianzhu Zhang, Changsheng Xu, and Ming-Hsuan Yang. Learning multi-task correlation particle filters for visual tracking. IEEE Transactions on Pattern Analysis and Ma- chine Intelligence, 41(2):365-378, 2019. 1\n\nRobust structural sparse tracking. Tianzhu Zhang, Changsheng Xu, Ming-Hsuan Yang, IEEE Transactions on Pattern Analysis and Machine Intelligence. 412Tianzhu Zhang, Changsheng Xu, and Ming-Hsuan Yang. Robust structural sparse tracking. IEEE Transactions on Pattern Analysis and Machine Intelligence, 41(2):473-486, 2019. 1\n\nSingle-image crowd counting via multi-column convolutional neural network. Yingying Zhang, Desen Zhou, Siqin Chen, Shenghua Gao, Yi Ma, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern Recognition67Yingying Zhang, Desen Zhou, Siqin Chen, Shenghua Gao, and Yi Ma. Single-image crowd counting via multi-column convolutional neural network. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 589-597, 2016. 1, 2, 5, 6, 7\n\nLeveraging heterogeneous auxiliary tasks to assist crowd counting. Muming Zhao, Jian Zhang, Chongyang Zhang, Wenjun Zhang, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionMuming Zhao, Jian Zhang, Chongyang Zhang, and Wenjun Zhang. Leveraging heterogeneous auxiliary tasks to assist crowd counting. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 12736- 12745, 2019. 3\n", "annotations": {"author": "[{\"end\":137,\"start\":40},{\"end\":225,\"start\":138},{\"end\":321,\"start\":226},{\"end\":444,\"start\":322},{\"end\":509,\"start\":445},{\"end\":577,\"start\":510},{\"end\":683,\"start\":578},{\"end\":766,\"start\":684},{\"end\":137,\"start\":40},{\"end\":225,\"start\":138},{\"end\":321,\"start\":226},{\"end\":444,\"start\":322},{\"end\":509,\"start\":445},{\"end\":577,\"start\":510},{\"end\":683,\"start\":578},{\"end\":766,\"start\":684}]", "publisher": null, "author_last_name": "[{\"end\":54,\"start\":49},{\"end\":146,\"start\":141},{\"end\":238,\"start\":236},{\"end\":335,\"start\":330},{\"end\":451,\"start\":449},{\"end\":519,\"start\":515},{\"end\":586,\"start\":582},{\"end\":695,\"start\":691},{\"end\":54,\"start\":49},{\"end\":146,\"start\":141},{\"end\":238,\"start\":236},{\"end\":335,\"start\":330},{\"end\":451,\"start\":449},{\"end\":519,\"start\":515},{\"end\":586,\"start\":582},{\"end\":695,\"start\":691}]", "author_first_name": "[{\"end\":48,\"start\":40},{\"end\":140,\"start\":138},{\"end\":235,\"start\":226},{\"end\":329,\"start\":322},{\"end\":448,\"start\":445},{\"end\":514,\"start\":510},{\"end\":581,\"start\":578},{\"end\":690,\"start\":684},{\"end\":48,\"start\":40},{\"end\":140,\"start\":138},{\"end\":235,\"start\":226},{\"end\":329,\"start\":322},{\"end\":448,\"start\":445},{\"end\":514,\"start\":510},{\"end\":581,\"start\":578},{\"end\":690,\"start\":684}]", "author_affiliation": "[{\"end\":136,\"start\":81},{\"end\":224,\"start\":169},{\"end\":320,\"start\":265},{\"end\":443,\"start\":357},{\"end\":508,\"start\":453},{\"end\":576,\"start\":521},{\"end\":682,\"start\":608},{\"end\":765,\"start\":697},{\"end\":136,\"start\":81},{\"end\":224,\"start\":169},{\"end\":320,\"start\":265},{\"end\":443,\"start\":357},{\"end\":508,\"start\":453},{\"end\":576,\"start\":521},{\"end\":682,\"start\":608},{\"end\":765,\"start\":697}]", "title": "[{\"end\":37,\"start\":1},{\"end\":803,\"start\":767},{\"end\":37,\"start\":1},{\"end\":803,\"start\":767}]", "venue": null, "abstract": "[{\"end\":2204,\"start\":805},{\"end\":2204,\"start\":805}]", "bib_ref": "[{\"end\":2488,\"start\":2485},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":3138,\"start\":3134},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3140,\"start\":3138},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":3143,\"start\":3140},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3167,\"start\":3164},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":3169,\"start\":3167},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":3195,\"start\":3191},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":3198,\"start\":3195},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":3267,\"start\":3263},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":3270,\"start\":3267},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":3273,\"start\":3270},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":3276,\"start\":3273},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3279,\"start\":3276},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":3348,\"start\":3344},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":3351,\"start\":3348},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":3354,\"start\":3351},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":3380,\"start\":3376},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":3383,\"start\":3380},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":3386,\"start\":3383},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":3420,\"start\":3416},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":3423,\"start\":3420},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":3425,\"start\":3423},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":3585,\"start\":3581},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3588,\"start\":3585},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":3591,\"start\":3588},{\"end\":4486,\"start\":4478},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":7498,\"start\":7495},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":7501,\"start\":7498},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":7504,\"start\":7501},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":7507,\"start\":7504},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":7509,\"start\":7507},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":7534,\"start\":7531},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":7537,\"start\":7534},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":7540,\"start\":7537},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":7543,\"start\":7540},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":7546,\"start\":7543},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":7549,\"start\":7546},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":7552,\"start\":7549},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":7905,\"start\":7901},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":8028,\"start\":8024},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":8161,\"start\":8157},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":8315,\"start\":8311},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":8481,\"start\":8478},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":8864,\"start\":8860},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":9144,\"start\":9140},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":9460,\"start\":9456},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":9593,\"start\":9589},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":9881,\"start\":9877},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":10114,\"start\":10110},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":10291,\"start\":10287},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":10498,\"start\":10494},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":12022,\"start\":12019},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":14195,\"start\":14191},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":16082,\"start\":16078},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":19357,\"start\":19353},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":19381,\"start\":19377},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":19408,\"start\":19404},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":19435,\"start\":19431},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":19592,\"start\":19588},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":19831,\"start\":19827},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":20204,\"start\":20200},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":20549,\"start\":20545},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":21397,\"start\":21393},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":21880,\"start\":21876},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":22037,\"start\":22033},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":23091,\"start\":23087},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":24855,\"start\":24851},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":24857,\"start\":24855},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":24860,\"start\":24857},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":24863,\"start\":24860},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":24866,\"start\":24863},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":24869,\"start\":24866},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":24872,\"start\":24869},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":24875,\"start\":24872},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":24878,\"start\":24875},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":24881,\"start\":24878},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":24884,\"start\":24881},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":24886,\"start\":24884},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":24889,\"start\":24886},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":24892,\"start\":24889},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":24895,\"start\":24892},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":24898,\"start\":24895},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":24901,\"start\":24898},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":24937,\"start\":24933},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":24962,\"start\":24958},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":24985,\"start\":24981},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":25015,\"start\":25011},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":25344,\"start\":25340},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":25395,\"start\":25391},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":25429,\"start\":25425},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":25568,\"start\":25564},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":26087,\"start\":26083},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":26590,\"start\":26586},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":26741,\"start\":26737},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":26934,\"start\":26930},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":27008,\"start\":27004},{\"end\":2488,\"start\":2485},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":3138,\"start\":3134},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3140,\"start\":3138},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":3143,\"start\":3140},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3167,\"start\":3164},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":3169,\"start\":3167},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":3195,\"start\":3191},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":3198,\"start\":3195},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":3267,\"start\":3263},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":3270,\"start\":3267},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":3273,\"start\":3270},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":3276,\"start\":3273},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3279,\"start\":3276},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":3348,\"start\":3344},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":3351,\"start\":3348},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":3354,\"start\":3351},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":3380,\"start\":3376},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":3383,\"start\":3380},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":3386,\"start\":3383},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":3420,\"start\":3416},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":3423,\"start\":3420},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":3425,\"start\":3423},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":3585,\"start\":3581},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3588,\"start\":3585},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":3591,\"start\":3588},{\"end\":4486,\"start\":4478},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":7498,\"start\":7495},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":7501,\"start\":7498},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":7504,\"start\":7501},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":7507,\"start\":7504},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":7509,\"start\":7507},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":7534,\"start\":7531},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":7537,\"start\":7534},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":7540,\"start\":7537},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":7543,\"start\":7540},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":7546,\"start\":7543},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":7549,\"start\":7546},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":7552,\"start\":7549},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":7905,\"start\":7901},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":8028,\"start\":8024},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":8161,\"start\":8157},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":8315,\"start\":8311},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":8481,\"start\":8478},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":8864,\"start\":8860},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":9144,\"start\":9140},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":9460,\"start\":9456},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":9593,\"start\":9589},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":9881,\"start\":9877},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":10114,\"start\":10110},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":10291,\"start\":10287},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":10498,\"start\":10494},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":12022,\"start\":12019},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":14195,\"start\":14191},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":16082,\"start\":16078},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":19357,\"start\":19353},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":19381,\"start\":19377},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":19408,\"start\":19404},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":19435,\"start\":19431},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":19592,\"start\":19588},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":19831,\"start\":19827},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":20204,\"start\":20200},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":20549,\"start\":20545},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":21397,\"start\":21393},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":21880,\"start\":21876},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":22037,\"start\":22033},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":23091,\"start\":23087},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":24855,\"start\":24851},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":24857,\"start\":24855},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":24860,\"start\":24857},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":24863,\"start\":24860},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":24866,\"start\":24863},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":24869,\"start\":24866},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":24872,\"start\":24869},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":24875,\"start\":24872},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":24878,\"start\":24875},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":24881,\"start\":24878},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":24884,\"start\":24881},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":24886,\"start\":24884},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":24889,\"start\":24886},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":24892,\"start\":24889},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":24895,\"start\":24892},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":24898,\"start\":24895},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":24901,\"start\":24898},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":24937,\"start\":24933},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":24962,\"start\":24958},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":24985,\"start\":24981},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":25015,\"start\":25011},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":25344,\"start\":25340},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":25395,\"start\":25391},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":25429,\"start\":25425},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":25568,\"start\":25564},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":26087,\"start\":26083},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":26590,\"start\":26586},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":26741,\"start\":26737},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":26934,\"start\":26930},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":27008,\"start\":27004}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":30338,\"start\":29854},{\"attributes\":{\"id\":\"fig_1\"},\"end\":30454,\"start\":30339},{\"attributes\":{\"id\":\"fig_2\"},\"end\":30534,\"start\":30455},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":33524,\"start\":30535},{\"attributes\":{\"id\":\"fig_0\"},\"end\":30338,\"start\":29854},{\"attributes\":{\"id\":\"fig_1\"},\"end\":30454,\"start\":30339},{\"attributes\":{\"id\":\"fig_2\"},\"end\":30534,\"start\":30455},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":33524,\"start\":30535}]", "paragraph": "[{\"end\":2602,\"start\":2220},{\"end\":3592,\"start\":2604},{\"end\":4854,\"start\":3594},{\"end\":4915,\"start\":4856},{\"end\":5574,\"start\":4917},{\"end\":6063,\"start\":5576},{\"end\":6293,\"start\":6065},{\"end\":6434,\"start\":6295},{\"end\":6930,\"start\":6436},{\"end\":7090,\"start\":6932},{\"end\":7383,\"start\":7092},{\"end\":7640,\"start\":7400},{\"end\":8649,\"start\":7686},{\"end\":9746,\"start\":8681},{\"end\":10750,\"start\":9781},{\"end\":11395,\"start\":10767},{\"end\":11734,\"start\":11425},{\"end\":13399,\"start\":11736},{\"end\":14054,\"start\":13401},{\"end\":14641,\"start\":14056},{\"end\":15909,\"start\":14671},{\"end\":16779,\"start\":15911},{\"end\":16993,\"start\":16805},{\"end\":17699,\"start\":17042},{\"end\":18089,\"start\":17701},{\"end\":18948,\"start\":18091},{\"end\":19547,\"start\":19107},{\"end\":19806,\"start\":19560},{\"end\":20181,\"start\":19808},{\"end\":20522,\"start\":20183},{\"end\":20885,\"start\":20524},{\"end\":21489,\"start\":20898},{\"end\":21754,\"start\":21491},{\"end\":22369,\"start\":21756},{\"end\":22527,\"start\":22392},{\"end\":22725,\"start\":22598},{\"end\":23092,\"start\":22753},{\"end\":23881,\"start\":23111},{\"end\":24387,\"start\":23883},{\"end\":24737,\"start\":24389},{\"end\":25780,\"start\":24766},{\"end\":27095,\"start\":25782},{\"end\":27721,\"start\":27097},{\"end\":28950,\"start\":27746},{\"end\":29853,\"start\":28965},{\"end\":2602,\"start\":2220},{\"end\":3592,\"start\":2604},{\"end\":4854,\"start\":3594},{\"end\":4915,\"start\":4856},{\"end\":5574,\"start\":4917},{\"end\":6063,\"start\":5576},{\"end\":6293,\"start\":6065},{\"end\":6434,\"start\":6295},{\"end\":6930,\"start\":6436},{\"end\":7090,\"start\":6932},{\"end\":7383,\"start\":7092},{\"end\":7640,\"start\":7400},{\"end\":8649,\"start\":7686},{\"end\":9746,\"start\":8681},{\"end\":10750,\"start\":9781},{\"end\":11395,\"start\":10767},{\"end\":11734,\"start\":11425},{\"end\":13399,\"start\":11736},{\"end\":14054,\"start\":13401},{\"end\":14641,\"start\":14056},{\"end\":15909,\"start\":14671},{\"end\":16779,\"start\":15911},{\"end\":16993,\"start\":16805},{\"end\":17699,\"start\":17042},{\"end\":18089,\"start\":17701},{\"end\":18948,\"start\":18091},{\"end\":19547,\"start\":19107},{\"end\":19806,\"start\":19560},{\"end\":20181,\"start\":19808},{\"end\":20522,\"start\":20183},{\"end\":20885,\"start\":20524},{\"end\":21489,\"start\":20898},{\"end\":21754,\"start\":21491},{\"end\":22369,\"start\":21756},{\"end\":22527,\"start\":22392},{\"end\":22725,\"start\":22598},{\"end\":23092,\"start\":22753},{\"end\":23881,\"start\":23111},{\"end\":24387,\"start\":23883},{\"end\":24737,\"start\":24389},{\"end\":25780,\"start\":24766},{\"end\":27095,\"start\":25782},{\"end\":27721,\"start\":27097},{\"end\":28950,\"start\":27746},{\"end\":29853,\"start\":28965}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":17041,\"start\":16994},{\"attributes\":{\"id\":\"formula_1\"},\"end\":19050,\"start\":18949},{\"attributes\":{\"id\":\"formula_2\"},\"end\":19092,\"start\":19050},{\"attributes\":{\"id\":\"formula_3\"},\"end\":22560,\"start\":22528},{\"attributes\":{\"id\":\"formula_4\"},\"end\":22597,\"start\":22560},{\"attributes\":{\"id\":\"formula_0\"},\"end\":17041,\"start\":16994},{\"attributes\":{\"id\":\"formula_1\"},\"end\":19050,\"start\":18949},{\"attributes\":{\"id\":\"formula_2\"},\"end\":19092,\"start\":19050},{\"attributes\":{\"id\":\"formula_3\"},\"end\":22560,\"start\":22528},{\"attributes\":{\"id\":\"formula_4\"},\"end\":22597,\"start\":22560}]", "table_ref": "[{\"end\":23614,\"start\":23607},{\"end\":24110,\"start\":24103},{\"end\":27438,\"start\":27430},{\"end\":23614,\"start\":23607},{\"end\":24110,\"start\":24103},{\"end\":27438,\"start\":27430}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":2218,\"start\":2206},{\"attributes\":{\"n\":\"2.\"},\"end\":7398,\"start\":7386},{\"attributes\":{\"n\":\"2.1.\"},\"end\":7684,\"start\":7643},{\"attributes\":{\"n\":\"2.2.\"},\"end\":8679,\"start\":8652},{\"attributes\":{\"n\":\"2.3.\"},\"end\":9779,\"start\":9749},{\"attributes\":{\"n\":\"3.\"},\"end\":10765,\"start\":10753},{\"attributes\":{\"n\":\"3.1.\"},\"end\":11423,\"start\":11398},{\"attributes\":{\"n\":\"3.2.\"},\"end\":14669,\"start\":14644},{\"attributes\":{\"n\":\"3.3.\"},\"end\":16803,\"start\":16782},{\"attributes\":{\"n\":\"4.\"},\"end\":19105,\"start\":19094},{\"attributes\":{\"n\":\"4.1.\"},\"end\":19558,\"start\":19550},{\"attributes\":{\"n\":\"4.2.\"},\"end\":20896,\"start\":20888},{\"attributes\":{\"n\":\"4.3.\"},\"end\":22390,\"start\":22372},{\"attributes\":{\"n\":\"4.4.\"},\"end\":22751,\"start\":22728},{\"attributes\":{\"n\":\"4.4.1\"},\"end\":23109,\"start\":23095},{\"attributes\":{\"n\":\"4.4.2\"},\"end\":24764,\"start\":24740},{\"attributes\":{\"n\":\"4.4.3\"},\"end\":27744,\"start\":27724},{\"attributes\":{\"n\":\"5.\"},\"end\":28963,\"start\":28953},{\"end\":29865,\"start\":29855},{\"end\":30350,\"start\":30340},{\"end\":30466,\"start\":30456},{\"attributes\":{\"n\":\"1.\"},\"end\":2218,\"start\":2206},{\"attributes\":{\"n\":\"2.\"},\"end\":7398,\"start\":7386},{\"attributes\":{\"n\":\"2.1.\"},\"end\":7684,\"start\":7643},{\"attributes\":{\"n\":\"2.2.\"},\"end\":8679,\"start\":8652},{\"attributes\":{\"n\":\"2.3.\"},\"end\":9779,\"start\":9749},{\"attributes\":{\"n\":\"3.\"},\"end\":10765,\"start\":10753},{\"attributes\":{\"n\":\"3.1.\"},\"end\":11423,\"start\":11398},{\"attributes\":{\"n\":\"3.2.\"},\"end\":14669,\"start\":14644},{\"attributes\":{\"n\":\"3.3.\"},\"end\":16803,\"start\":16782},{\"attributes\":{\"n\":\"4.\"},\"end\":19105,\"start\":19094},{\"attributes\":{\"n\":\"4.1.\"},\"end\":19558,\"start\":19550},{\"attributes\":{\"n\":\"4.2.\"},\"end\":20896,\"start\":20888},{\"attributes\":{\"n\":\"4.3.\"},\"end\":22390,\"start\":22372},{\"attributes\":{\"n\":\"4.4.\"},\"end\":22751,\"start\":22728},{\"attributes\":{\"n\":\"4.4.1\"},\"end\":23109,\"start\":23095},{\"attributes\":{\"n\":\"4.4.2\"},\"end\":24764,\"start\":24740},{\"attributes\":{\"n\":\"4.4.3\"},\"end\":27744,\"start\":27724},{\"attributes\":{\"n\":\"5.\"},\"end\":28963,\"start\":28953},{\"end\":29865,\"start\":29855},{\"end\":30350,\"start\":30340},{\"end\":30466,\"start\":30456}]", "table": "[{\"end\":33524,\"start\":30630},{\"end\":33524,\"start\":30630}]", "figure_caption": "[{\"end\":30338,\"start\":29867},{\"end\":30454,\"start\":30352},{\"end\":30534,\"start\":30468},{\"end\":30630,\"start\":30537},{\"end\":30338,\"start\":29867},{\"end\":30454,\"start\":30352},{\"end\":30534,\"start\":30468},{\"end\":30630,\"start\":30537}]", "figure_ref": "[{\"end\":4901,\"start\":4893},{\"end\":4914,\"start\":4906},{\"end\":6597,\"start\":6589},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":10833,\"start\":10825},{\"end\":13216,\"start\":13208},{\"end\":13718,\"start\":13710},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":14122,\"start\":14114},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":14938,\"start\":14930},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":15986,\"start\":15978},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":18051,\"start\":18043},{\"end\":24574,\"start\":24566},{\"end\":27929,\"start\":27921},{\"end\":28271,\"start\":28263},{\"end\":4901,\"start\":4893},{\"end\":4914,\"start\":4906},{\"end\":6597,\"start\":6589},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":10833,\"start\":10825},{\"end\":13216,\"start\":13208},{\"end\":13718,\"start\":13710},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":14122,\"start\":14114},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":14938,\"start\":14930},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":15986,\"start\":15978},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":18051,\"start\":18043},{\"end\":24574,\"start\":24566},{\"end\":27929,\"start\":27921},{\"end\":28271,\"start\":28263}]", "bib_author_first_name": "[{\"end\":33597,\"start\":33591},{\"end\":33612,\"start\":33611},{\"end\":33614,\"start\":33613},{\"end\":33636,\"start\":33625},{\"end\":34024,\"start\":34019},{\"end\":34036,\"start\":34030},{\"end\":34050,\"start\":34043},{\"end\":34348,\"start\":34343},{\"end\":34360,\"start\":34354},{\"end\":34374,\"start\":34367},{\"end\":34681,\"start\":34676},{\"end\":34706,\"start\":34700},{\"end\":34719,\"start\":34712},{\"end\":34739,\"start\":34732},{\"end\":35157,\"start\":35152},{\"end\":35170,\"start\":35164},{\"end\":35180,\"start\":35176},{\"end\":35195,\"start\":35187},{\"end\":35510,\"start\":35504},{\"end\":35525,\"start\":35518},{\"end\":35532,\"start\":35530},{\"end\":35542,\"start\":35538},{\"end\":35556,\"start\":35547},{\"end\":35558,\"start\":35557},{\"end\":36016,\"start\":36011},{\"end\":36034,\"start\":36025},{\"end\":36379,\"start\":36372},{\"end\":36391,\"start\":36384},{\"end\":36759,\"start\":36751},{\"end\":36776,\"start\":36769},{\"end\":36795,\"start\":36791},{\"end\":36808,\"start\":36804},{\"end\":37156,\"start\":37150},{\"end\":37170,\"start\":37165},{\"end\":37184,\"start\":37180},{\"end\":37201,\"start\":37194},{\"end\":37695,\"start\":37689},{\"end\":37711,\"start\":37704},{\"end\":37726,\"start\":37720},{\"end\":37739,\"start\":37735},{\"end\":37753,\"start\":37747},{\"end\":37771,\"start\":37766},{\"end\":37788,\"start\":37781},{\"end\":38275,\"start\":38267},{\"end\":38288,\"start\":38283},{\"end\":38303,\"start\":38295},{\"end\":38319,\"start\":38311},{\"end\":38333,\"start\":38326},{\"end\":38344,\"start\":38339},{\"end\":38359,\"start\":38355},{\"end\":38857,\"start\":38849},{\"end\":38867,\"start\":38865},{\"end\":38878,\"start\":38875},{\"end\":38887,\"start\":38883},{\"end\":38899,\"start\":38893},{\"end\":38910,\"start\":38905},{\"end\":38921,\"start\":38915},{\"end\":38930,\"start\":38928},{\"end\":38939,\"start\":38935},{\"end\":38955,\"start\":38946},{\"end\":39420,\"start\":39418},{\"end\":39432,\"start\":39427},{\"end\":39443,\"start\":39437},{\"end\":39445,\"start\":39444},{\"end\":39801,\"start\":39800},{\"end\":39817,\"start\":39812},{\"end\":40075,\"start\":40069},{\"end\":40087,\"start\":40080},{\"end\":40101,\"start\":40095},{\"end\":40584,\"start\":40576},{\"end\":40595,\"start\":40590},{\"end\":40608,\"start\":40602},{\"end\":41055,\"start\":41049},{\"end\":41067,\"start\":41061},{\"end\":41080,\"start\":41073},{\"end\":41091,\"start\":41085},{\"end\":41102,\"start\":41097},{\"end\":41116,\"start\":41111},{\"end\":41586,\"start\":41582},{\"end\":41600,\"start\":41592},{\"end\":41616,\"start\":41607},{\"end\":41625,\"start\":41622},{\"end\":41633,\"start\":41631},{\"end\":41645,\"start\":41639},{\"end\":42107,\"start\":42101},{\"end\":42120,\"start\":42113},{\"end\":42137,\"start\":42131},{\"end\":42543,\"start\":42537},{\"end\":42554,\"start\":42549},{\"end\":42576,\"start\":42570},{\"end\":42578,\"start\":42577},{\"end\":43037,\"start\":43030},{\"end\":43046,\"start\":43042},{\"end\":43060,\"start\":43052},{\"end\":43073,\"start\":43067},{\"end\":43568,\"start\":43564},{\"end\":43583,\"start\":43578},{\"end\":43603,\"start\":43596},{\"end\":43626,\"start\":43612},{\"end\":44168,\"start\":44162},{\"end\":44177,\"start\":44176},{\"end\":44207,\"start\":44185},{\"end\":44577,\"start\":44571},{\"end\":44589,\"start\":44584},{\"end\":44602,\"start\":44595},{\"end\":44919,\"start\":44910},{\"end\":44932,\"start\":44926},{\"end\":44948,\"start\":44943},{\"end\":44965,\"start\":44960},{\"end\":45426,\"start\":45420},{\"end\":45442,\"start\":45435},{\"end\":45462,\"start\":45458},{\"end\":45464,\"start\":45463},{\"end\":45478,\"start\":45475},{\"end\":45954,\"start\":45947},{\"end\":45973,\"start\":45969},{\"end\":45975,\"start\":45974},{\"end\":45984,\"start\":45980},{\"end\":46383,\"start\":46379},{\"end\":46412,\"start\":46401},{\"end\":46848,\"start\":46845},{\"end\":46857,\"start\":46855},{\"end\":46870,\"start\":46862},{\"end\":46880,\"start\":46875},{\"end\":46894,\"start\":46887},{\"end\":46907,\"start\":46899},{\"end\":47379,\"start\":47371},{\"end\":47392,\"start\":47385},{\"end\":47403,\"start\":47399},{\"end\":47413,\"start\":47408},{\"end\":47826,\"start\":47819},{\"end\":47838,\"start\":47832},{\"end\":47848,\"start\":47847},{\"end\":47850,\"start\":47849},{\"end\":48236,\"start\":48231},{\"end\":48253,\"start\":48247},{\"end\":48555,\"start\":48554},{\"end\":48578,\"start\":48577},{\"end\":49080,\"start\":49079},{\"end\":49103,\"start\":49102},{\"end\":49520,\"start\":49519},{\"end\":49543,\"start\":49542},{\"end\":49841,\"start\":49840},{\"end\":49860,\"start\":49854},{\"end\":49862,\"start\":49861},{\"end\":50285,\"start\":50283},{\"end\":50297,\"start\":50292},{\"end\":50306,\"start\":50303},{\"end\":50316,\"start\":50312},{\"end\":50747,\"start\":50745},{\"end\":50761,\"start\":50754},{\"end\":51142,\"start\":51134},{\"end\":51154,\"start\":51147},{\"end\":51168,\"start\":51162},{\"end\":51181,\"start\":51177},{\"end\":51191,\"start\":51186},{\"end\":51583,\"start\":51576},{\"end\":51594,\"start\":51591},{\"end\":51607,\"start\":51599},{\"end\":51618,\"start\":51613},{\"end\":51630,\"start\":51624},{\"end\":51643,\"start\":51636},{\"end\":52120,\"start\":52112},{\"end\":52128,\"start\":52125},{\"end\":52142,\"start\":52134},{\"end\":52151,\"start\":52147},{\"end\":52165,\"start\":52157},{\"end\":52175,\"start\":52170},{\"end\":52624,\"start\":52618},{\"end\":52636,\"start\":52630},{\"end\":52651,\"start\":52643},{\"end\":52661,\"start\":52657},{\"end\":52673,\"start\":52667},{\"end\":52686,\"start\":52680},{\"end\":52697,\"start\":52692},{\"end\":53132,\"start\":53127},{\"end\":53145,\"start\":53140},{\"end\":53157,\"start\":53152},{\"end\":53167,\"start\":53164},{\"end\":53181,\"start\":53173},{\"end\":53195,\"start\":53188},{\"end\":53205,\"start\":53201},{\"end\":53629,\"start\":53624},{\"end\":53640,\"start\":53637},{\"end\":53651,\"start\":53646},{\"end\":53661,\"start\":53658},{\"end\":53675,\"start\":53667},{\"end\":53689,\"start\":53682},{\"end\":53699,\"start\":53695},{\"end\":54133,\"start\":54129},{\"end\":54150,\"start\":54141},{\"end\":54163,\"start\":54155},{\"end\":54178,\"start\":54170},{\"end\":54646,\"start\":54639},{\"end\":54664,\"start\":54654},{\"end\":54679,\"start\":54669},{\"end\":55006,\"start\":54999},{\"end\":55024,\"start\":55014},{\"end\":55039,\"start\":55029},{\"end\":55370,\"start\":55362},{\"end\":55383,\"start\":55378},{\"end\":55395,\"start\":55390},{\"end\":55410,\"start\":55402},{\"end\":55418,\"start\":55416},{\"end\":55897,\"start\":55891},{\"end\":55908,\"start\":55904},{\"end\":55925,\"start\":55916},{\"end\":55939,\"start\":55933},{\"end\":33597,\"start\":33591},{\"end\":33612,\"start\":33611},{\"end\":33614,\"start\":33613},{\"end\":33636,\"start\":33625},{\"end\":34024,\"start\":34019},{\"end\":34036,\"start\":34030},{\"end\":34050,\"start\":34043},{\"end\":34348,\"start\":34343},{\"end\":34360,\"start\":34354},{\"end\":34374,\"start\":34367},{\"end\":34681,\"start\":34676},{\"end\":34706,\"start\":34700},{\"end\":34719,\"start\":34712},{\"end\":34739,\"start\":34732},{\"end\":35157,\"start\":35152},{\"end\":35170,\"start\":35164},{\"end\":35180,\"start\":35176},{\"end\":35195,\"start\":35187},{\"end\":35510,\"start\":35504},{\"end\":35525,\"start\":35518},{\"end\":35532,\"start\":35530},{\"end\":35542,\"start\":35538},{\"end\":35556,\"start\":35547},{\"end\":35558,\"start\":35557},{\"end\":36016,\"start\":36011},{\"end\":36034,\"start\":36025},{\"end\":36379,\"start\":36372},{\"end\":36391,\"start\":36384},{\"end\":36759,\"start\":36751},{\"end\":36776,\"start\":36769},{\"end\":36795,\"start\":36791},{\"end\":36808,\"start\":36804},{\"end\":37156,\"start\":37150},{\"end\":37170,\"start\":37165},{\"end\":37184,\"start\":37180},{\"end\":37201,\"start\":37194},{\"end\":37695,\"start\":37689},{\"end\":37711,\"start\":37704},{\"end\":37726,\"start\":37720},{\"end\":37739,\"start\":37735},{\"end\":37753,\"start\":37747},{\"end\":37771,\"start\":37766},{\"end\":37788,\"start\":37781},{\"end\":38275,\"start\":38267},{\"end\":38288,\"start\":38283},{\"end\":38303,\"start\":38295},{\"end\":38319,\"start\":38311},{\"end\":38333,\"start\":38326},{\"end\":38344,\"start\":38339},{\"end\":38359,\"start\":38355},{\"end\":38857,\"start\":38849},{\"end\":38867,\"start\":38865},{\"end\":38878,\"start\":38875},{\"end\":38887,\"start\":38883},{\"end\":38899,\"start\":38893},{\"end\":38910,\"start\":38905},{\"end\":38921,\"start\":38915},{\"end\":38930,\"start\":38928},{\"end\":38939,\"start\":38935},{\"end\":38955,\"start\":38946},{\"end\":39420,\"start\":39418},{\"end\":39432,\"start\":39427},{\"end\":39443,\"start\":39437},{\"end\":39445,\"start\":39444},{\"end\":39801,\"start\":39800},{\"end\":39817,\"start\":39812},{\"end\":40075,\"start\":40069},{\"end\":40087,\"start\":40080},{\"end\":40101,\"start\":40095},{\"end\":40584,\"start\":40576},{\"end\":40595,\"start\":40590},{\"end\":40608,\"start\":40602},{\"end\":41055,\"start\":41049},{\"end\":41067,\"start\":41061},{\"end\":41080,\"start\":41073},{\"end\":41091,\"start\":41085},{\"end\":41102,\"start\":41097},{\"end\":41116,\"start\":41111},{\"end\":41586,\"start\":41582},{\"end\":41600,\"start\":41592},{\"end\":41616,\"start\":41607},{\"end\":41625,\"start\":41622},{\"end\":41633,\"start\":41631},{\"end\":41645,\"start\":41639},{\"end\":42107,\"start\":42101},{\"end\":42120,\"start\":42113},{\"end\":42137,\"start\":42131},{\"end\":42543,\"start\":42537},{\"end\":42554,\"start\":42549},{\"end\":42576,\"start\":42570},{\"end\":42578,\"start\":42577},{\"end\":43037,\"start\":43030},{\"end\":43046,\"start\":43042},{\"end\":43060,\"start\":43052},{\"end\":43073,\"start\":43067},{\"end\":43568,\"start\":43564},{\"end\":43583,\"start\":43578},{\"end\":43603,\"start\":43596},{\"end\":43626,\"start\":43612},{\"end\":44168,\"start\":44162},{\"end\":44177,\"start\":44176},{\"end\":44207,\"start\":44185},{\"end\":44577,\"start\":44571},{\"end\":44589,\"start\":44584},{\"end\":44602,\"start\":44595},{\"end\":44919,\"start\":44910},{\"end\":44932,\"start\":44926},{\"end\":44948,\"start\":44943},{\"end\":44965,\"start\":44960},{\"end\":45426,\"start\":45420},{\"end\":45442,\"start\":45435},{\"end\":45462,\"start\":45458},{\"end\":45464,\"start\":45463},{\"end\":45478,\"start\":45475},{\"end\":45954,\"start\":45947},{\"end\":45973,\"start\":45969},{\"end\":45975,\"start\":45974},{\"end\":45984,\"start\":45980},{\"end\":46383,\"start\":46379},{\"end\":46412,\"start\":46401},{\"end\":46848,\"start\":46845},{\"end\":46857,\"start\":46855},{\"end\":46870,\"start\":46862},{\"end\":46880,\"start\":46875},{\"end\":46894,\"start\":46887},{\"end\":46907,\"start\":46899},{\"end\":47379,\"start\":47371},{\"end\":47392,\"start\":47385},{\"end\":47403,\"start\":47399},{\"end\":47413,\"start\":47408},{\"end\":47826,\"start\":47819},{\"end\":47838,\"start\":47832},{\"end\":47848,\"start\":47847},{\"end\":47850,\"start\":47849},{\"end\":48236,\"start\":48231},{\"end\":48253,\"start\":48247},{\"end\":48555,\"start\":48554},{\"end\":48578,\"start\":48577},{\"end\":49080,\"start\":49079},{\"end\":49103,\"start\":49102},{\"end\":49520,\"start\":49519},{\"end\":49543,\"start\":49542},{\"end\":49841,\"start\":49840},{\"end\":49860,\"start\":49854},{\"end\":49862,\"start\":49861},{\"end\":50285,\"start\":50283},{\"end\":50297,\"start\":50292},{\"end\":50306,\"start\":50303},{\"end\":50316,\"start\":50312},{\"end\":50747,\"start\":50745},{\"end\":50761,\"start\":50754},{\"end\":51142,\"start\":51134},{\"end\":51154,\"start\":51147},{\"end\":51168,\"start\":51162},{\"end\":51181,\"start\":51177},{\"end\":51191,\"start\":51186},{\"end\":51583,\"start\":51576},{\"end\":51594,\"start\":51591},{\"end\":51607,\"start\":51599},{\"end\":51618,\"start\":51613},{\"end\":51630,\"start\":51624},{\"end\":51643,\"start\":51636},{\"end\":52120,\"start\":52112},{\"end\":52128,\"start\":52125},{\"end\":52142,\"start\":52134},{\"end\":52151,\"start\":52147},{\"end\":52165,\"start\":52157},{\"end\":52175,\"start\":52170},{\"end\":52624,\"start\":52618},{\"end\":52636,\"start\":52630},{\"end\":52651,\"start\":52643},{\"end\":52661,\"start\":52657},{\"end\":52673,\"start\":52667},{\"end\":52686,\"start\":52680},{\"end\":52697,\"start\":52692},{\"end\":53132,\"start\":53127},{\"end\":53145,\"start\":53140},{\"end\":53157,\"start\":53152},{\"end\":53167,\"start\":53164},{\"end\":53181,\"start\":53173},{\"end\":53195,\"start\":53188},{\"end\":53205,\"start\":53201},{\"end\":53629,\"start\":53624},{\"end\":53640,\"start\":53637},{\"end\":53651,\"start\":53646},{\"end\":53661,\"start\":53658},{\"end\":53675,\"start\":53667},{\"end\":53689,\"start\":53682},{\"end\":53699,\"start\":53695},{\"end\":54133,\"start\":54129},{\"end\":54150,\"start\":54141},{\"end\":54163,\"start\":54155},{\"end\":54178,\"start\":54170},{\"end\":54646,\"start\":54639},{\"end\":54664,\"start\":54654},{\"end\":54679,\"start\":54669},{\"end\":55006,\"start\":54999},{\"end\":55024,\"start\":55014},{\"end\":55039,\"start\":55029},{\"end\":55370,\"start\":55362},{\"end\":55383,\"start\":55378},{\"end\":55395,\"start\":55390},{\"end\":55410,\"start\":55402},{\"end\":55418,\"start\":55416},{\"end\":55897,\"start\":55891},{\"end\":55908,\"start\":55904},{\"end\":55925,\"start\":55916},{\"end\":55939,\"start\":55933}]", "bib_author_last_name": "[{\"end\":33609,\"start\":33598},{\"end\":33623,\"start\":33615},{\"end\":33648,\"start\":33637},{\"end\":33654,\"start\":33650},{\"end\":34028,\"start\":34025},{\"end\":34041,\"start\":34037},{\"end\":34053,\"start\":34051},{\"end\":34352,\"start\":34349},{\"end\":34365,\"start\":34361},{\"end\":34377,\"start\":34375},{\"end\":34698,\"start\":34682},{\"end\":34710,\"start\":34707},{\"end\":34730,\"start\":34720},{\"end\":34747,\"start\":34740},{\"end\":34753,\"start\":34749},{\"end\":35162,\"start\":35158},{\"end\":35174,\"start\":35171},{\"end\":35185,\"start\":35181},{\"end\":35199,\"start\":35196},{\"end\":35516,\"start\":35511},{\"end\":35528,\"start\":35526},{\"end\":35536,\"start\":35533},{\"end\":35545,\"start\":35543},{\"end\":35568,\"start\":35559},{\"end\":36023,\"start\":36017},{\"end\":36040,\"start\":36035},{\"end\":36382,\"start\":36380},{\"end\":36400,\"start\":36392},{\"end\":36767,\"start\":36760},{\"end\":36789,\"start\":36777},{\"end\":36802,\"start\":36796},{\"end\":36813,\"start\":36809},{\"end\":37163,\"start\":37157},{\"end\":37178,\"start\":37171},{\"end\":37192,\"start\":37185},{\"end\":37206,\"start\":37202},{\"end\":37702,\"start\":37696},{\"end\":37718,\"start\":37712},{\"end\":37733,\"start\":37727},{\"end\":37745,\"start\":37740},{\"end\":37764,\"start\":37754},{\"end\":37779,\"start\":37772},{\"end\":37793,\"start\":37789},{\"end\":38281,\"start\":38276},{\"end\":38293,\"start\":38289},{\"end\":38309,\"start\":38304},{\"end\":38324,\"start\":38320},{\"end\":38337,\"start\":38334},{\"end\":38353,\"start\":38345},{\"end\":38364,\"start\":38360},{\"end\":38863,\"start\":38858},{\"end\":38873,\"start\":38868},{\"end\":38881,\"start\":38879},{\"end\":38891,\"start\":38888},{\"end\":38903,\"start\":38900},{\"end\":38913,\"start\":38911},{\"end\":38926,\"start\":38922},{\"end\":38933,\"start\":38931},{\"end\":38944,\"start\":38940},{\"end\":38958,\"start\":38956},{\"end\":39425,\"start\":39421},{\"end\":39435,\"start\":39433},{\"end\":39450,\"start\":39446},{\"end\":39810,\"start\":39802},{\"end\":39824,\"start\":39818},{\"end\":39828,\"start\":39826},{\"end\":40078,\"start\":40076},{\"end\":40093,\"start\":40088},{\"end\":40106,\"start\":40102},{\"end\":40588,\"start\":40585},{\"end\":40600,\"start\":40596},{\"end\":40611,\"start\":40609},{\"end\":41059,\"start\":41056},{\"end\":41071,\"start\":41068},{\"end\":41083,\"start\":41081},{\"end\":41095,\"start\":41092},{\"end\":41109,\"start\":41103},{\"end\":41120,\"start\":41117},{\"end\":41590,\"start\":41587},{\"end\":41605,\"start\":41601},{\"end\":41620,\"start\":41617},{\"end\":41629,\"start\":41626},{\"end\":41637,\"start\":41634},{\"end\":41648,\"start\":41646},{\"end\":42111,\"start\":42108},{\"end\":42129,\"start\":42121},{\"end\":42141,\"start\":42138},{\"end\":42547,\"start\":42544},{\"end\":42568,\"start\":42555},{\"end\":42587,\"start\":42579},{\"end\":43040,\"start\":43038},{\"end\":43050,\"start\":43047},{\"end\":43065,\"start\":43061},{\"end\":43078,\"start\":43074},{\"end\":43576,\"start\":43569},{\"end\":43594,\"start\":43584},{\"end\":43610,\"start\":43604},{\"end\":43633,\"start\":43627},{\"end\":44174,\"start\":44169},{\"end\":44183,\"start\":44178},{\"end\":44582,\"start\":44578},{\"end\":44593,\"start\":44590},{\"end\":44605,\"start\":44603},{\"end\":44924,\"start\":44920},{\"end\":44941,\"start\":44933},{\"end\":44958,\"start\":44949},{\"end\":44971,\"start\":44966},{\"end\":45433,\"start\":45427},{\"end\":45456,\"start\":45443},{\"end\":45473,\"start\":45465},{\"end\":45486,\"start\":45479},{\"end\":45967,\"start\":45955},{\"end\":45978,\"start\":45976},{\"end\":45993,\"start\":45985},{\"end\":45998,\"start\":45995},{\"end\":46399,\"start\":46384},{\"end\":46418,\"start\":46413},{\"end\":46424,\"start\":46420},{\"end\":46853,\"start\":46849},{\"end\":46860,\"start\":46858},{\"end\":46873,\"start\":46871},{\"end\":46885,\"start\":46881},{\"end\":46897,\"start\":46895},{\"end\":46912,\"start\":46908},{\"end\":47383,\"start\":47380},{\"end\":47397,\"start\":47393},{\"end\":47406,\"start\":47404},{\"end\":47418,\"start\":47414},{\"end\":47830,\"start\":47827},{\"end\":47845,\"start\":47839},{\"end\":47855,\"start\":47851},{\"end\":47862,\"start\":47857},{\"end\":48245,\"start\":48237},{\"end\":48263,\"start\":48254},{\"end\":48566,\"start\":48556},{\"end\":48575,\"start\":48568},{\"end\":48585,\"start\":48579},{\"end\":48592,\"start\":48587},{\"end\":49091,\"start\":49081},{\"end\":49100,\"start\":49093},{\"end\":49110,\"start\":49104},{\"end\":49117,\"start\":49112},{\"end\":49531,\"start\":49521},{\"end\":49540,\"start\":49533},{\"end\":49550,\"start\":49544},{\"end\":49557,\"start\":49552},{\"end\":49852,\"start\":49842},{\"end\":49870,\"start\":49863},{\"end\":49877,\"start\":49872},{\"end\":50290,\"start\":50286},{\"end\":50301,\"start\":50298},{\"end\":50310,\"start\":50307},{\"end\":50321,\"start\":50317},{\"end\":50752,\"start\":50748},{\"end\":50765,\"start\":50762},{\"end\":51145,\"start\":51143},{\"end\":51160,\"start\":51155},{\"end\":51175,\"start\":51169},{\"end\":51184,\"start\":51182},{\"end\":51196,\"start\":51192},{\"end\":51200,\"start\":51198},{\"end\":51589,\"start\":51584},{\"end\":51597,\"start\":51595},{\"end\":51611,\"start\":51608},{\"end\":51622,\"start\":51619},{\"end\":51634,\"start\":51631},{\"end\":51648,\"start\":51644},{\"end\":52123,\"start\":52121},{\"end\":52132,\"start\":52129},{\"end\":52145,\"start\":52143},{\"end\":52155,\"start\":52152},{\"end\":52168,\"start\":52166},{\"end\":52179,\"start\":52176},{\"end\":52628,\"start\":52625},{\"end\":52641,\"start\":52637},{\"end\":52655,\"start\":52652},{\"end\":52665,\"start\":52662},{\"end\":52678,\"start\":52674},{\"end\":52690,\"start\":52687},{\"end\":52702,\"start\":52698},{\"end\":53138,\"start\":53133},{\"end\":53150,\"start\":53146},{\"end\":53162,\"start\":53158},{\"end\":53171,\"start\":53168},{\"end\":53186,\"start\":53182},{\"end\":53199,\"start\":53196},{\"end\":53210,\"start\":53206},{\"end\":53635,\"start\":53630},{\"end\":53644,\"start\":53641},{\"end\":53656,\"start\":53652},{\"end\":53665,\"start\":53662},{\"end\":53680,\"start\":53676},{\"end\":53693,\"start\":53690},{\"end\":53704,\"start\":53700},{\"end\":54139,\"start\":54134},{\"end\":54153,\"start\":54151},{\"end\":54168,\"start\":54164},{\"end\":54183,\"start\":54179},{\"end\":54652,\"start\":54647},{\"end\":54667,\"start\":54665},{\"end\":54684,\"start\":54680},{\"end\":55012,\"start\":55007},{\"end\":55027,\"start\":55025},{\"end\":55044,\"start\":55040},{\"end\":55376,\"start\":55371},{\"end\":55388,\"start\":55384},{\"end\":55400,\"start\":55396},{\"end\":55414,\"start\":55411},{\"end\":55421,\"start\":55419},{\"end\":55902,\"start\":55898},{\"end\":55914,\"start\":55909},{\"end\":55931,\"start\":55926},{\"end\":55945,\"start\":55940},{\"end\":33609,\"start\":33598},{\"end\":33623,\"start\":33615},{\"end\":33648,\"start\":33637},{\"end\":33654,\"start\":33650},{\"end\":34028,\"start\":34025},{\"end\":34041,\"start\":34037},{\"end\":34053,\"start\":34051},{\"end\":34352,\"start\":34349},{\"end\":34365,\"start\":34361},{\"end\":34377,\"start\":34375},{\"end\":34698,\"start\":34682},{\"end\":34710,\"start\":34707},{\"end\":34730,\"start\":34720},{\"end\":34747,\"start\":34740},{\"end\":34753,\"start\":34749},{\"end\":35162,\"start\":35158},{\"end\":35174,\"start\":35171},{\"end\":35185,\"start\":35181},{\"end\":35199,\"start\":35196},{\"end\":35516,\"start\":35511},{\"end\":35528,\"start\":35526},{\"end\":35536,\"start\":35533},{\"end\":35545,\"start\":35543},{\"end\":35568,\"start\":35559},{\"end\":36023,\"start\":36017},{\"end\":36040,\"start\":36035},{\"end\":36382,\"start\":36380},{\"end\":36400,\"start\":36392},{\"end\":36767,\"start\":36760},{\"end\":36789,\"start\":36777},{\"end\":36802,\"start\":36796},{\"end\":36813,\"start\":36809},{\"end\":37163,\"start\":37157},{\"end\":37178,\"start\":37171},{\"end\":37192,\"start\":37185},{\"end\":37206,\"start\":37202},{\"end\":37702,\"start\":37696},{\"end\":37718,\"start\":37712},{\"end\":37733,\"start\":37727},{\"end\":37745,\"start\":37740},{\"end\":37764,\"start\":37754},{\"end\":37779,\"start\":37772},{\"end\":37793,\"start\":37789},{\"end\":38281,\"start\":38276},{\"end\":38293,\"start\":38289},{\"end\":38309,\"start\":38304},{\"end\":38324,\"start\":38320},{\"end\":38337,\"start\":38334},{\"end\":38353,\"start\":38345},{\"end\":38364,\"start\":38360},{\"end\":38863,\"start\":38858},{\"end\":38873,\"start\":38868},{\"end\":38881,\"start\":38879},{\"end\":38891,\"start\":38888},{\"end\":38903,\"start\":38900},{\"end\":38913,\"start\":38911},{\"end\":38926,\"start\":38922},{\"end\":38933,\"start\":38931},{\"end\":38944,\"start\":38940},{\"end\":38958,\"start\":38956},{\"end\":39425,\"start\":39421},{\"end\":39435,\"start\":39433},{\"end\":39450,\"start\":39446},{\"end\":39810,\"start\":39802},{\"end\":39824,\"start\":39818},{\"end\":39828,\"start\":39826},{\"end\":40078,\"start\":40076},{\"end\":40093,\"start\":40088},{\"end\":40106,\"start\":40102},{\"end\":40588,\"start\":40585},{\"end\":40600,\"start\":40596},{\"end\":40611,\"start\":40609},{\"end\":41059,\"start\":41056},{\"end\":41071,\"start\":41068},{\"end\":41083,\"start\":41081},{\"end\":41095,\"start\":41092},{\"end\":41109,\"start\":41103},{\"end\":41120,\"start\":41117},{\"end\":41590,\"start\":41587},{\"end\":41605,\"start\":41601},{\"end\":41620,\"start\":41617},{\"end\":41629,\"start\":41626},{\"end\":41637,\"start\":41634},{\"end\":41648,\"start\":41646},{\"end\":42111,\"start\":42108},{\"end\":42129,\"start\":42121},{\"end\":42141,\"start\":42138},{\"end\":42547,\"start\":42544},{\"end\":42568,\"start\":42555},{\"end\":42587,\"start\":42579},{\"end\":43040,\"start\":43038},{\"end\":43050,\"start\":43047},{\"end\":43065,\"start\":43061},{\"end\":43078,\"start\":43074},{\"end\":43576,\"start\":43569},{\"end\":43594,\"start\":43584},{\"end\":43610,\"start\":43604},{\"end\":43633,\"start\":43627},{\"end\":44174,\"start\":44169},{\"end\":44183,\"start\":44178},{\"end\":44582,\"start\":44578},{\"end\":44593,\"start\":44590},{\"end\":44605,\"start\":44603},{\"end\":44924,\"start\":44920},{\"end\":44941,\"start\":44933},{\"end\":44958,\"start\":44949},{\"end\":44971,\"start\":44966},{\"end\":45433,\"start\":45427},{\"end\":45456,\"start\":45443},{\"end\":45473,\"start\":45465},{\"end\":45486,\"start\":45479},{\"end\":45967,\"start\":45955},{\"end\":45978,\"start\":45976},{\"end\":45993,\"start\":45985},{\"end\":45998,\"start\":45995},{\"end\":46399,\"start\":46384},{\"end\":46418,\"start\":46413},{\"end\":46424,\"start\":46420},{\"end\":46853,\"start\":46849},{\"end\":46860,\"start\":46858},{\"end\":46873,\"start\":46871},{\"end\":46885,\"start\":46881},{\"end\":46897,\"start\":46895},{\"end\":46912,\"start\":46908},{\"end\":47383,\"start\":47380},{\"end\":47397,\"start\":47393},{\"end\":47406,\"start\":47404},{\"end\":47418,\"start\":47414},{\"end\":47830,\"start\":47827},{\"end\":47845,\"start\":47839},{\"end\":47855,\"start\":47851},{\"end\":47862,\"start\":47857},{\"end\":48245,\"start\":48237},{\"end\":48263,\"start\":48254},{\"end\":48566,\"start\":48556},{\"end\":48575,\"start\":48568},{\"end\":48585,\"start\":48579},{\"end\":48592,\"start\":48587},{\"end\":49091,\"start\":49081},{\"end\":49100,\"start\":49093},{\"end\":49110,\"start\":49104},{\"end\":49117,\"start\":49112},{\"end\":49531,\"start\":49521},{\"end\":49540,\"start\":49533},{\"end\":49550,\"start\":49544},{\"end\":49557,\"start\":49552},{\"end\":49852,\"start\":49842},{\"end\":49870,\"start\":49863},{\"end\":49877,\"start\":49872},{\"end\":50290,\"start\":50286},{\"end\":50301,\"start\":50298},{\"end\":50310,\"start\":50307},{\"end\":50321,\"start\":50317},{\"end\":50752,\"start\":50748},{\"end\":50765,\"start\":50762},{\"end\":51145,\"start\":51143},{\"end\":51160,\"start\":51155},{\"end\":51175,\"start\":51169},{\"end\":51184,\"start\":51182},{\"end\":51196,\"start\":51192},{\"end\":51200,\"start\":51198},{\"end\":51589,\"start\":51584},{\"end\":51597,\"start\":51595},{\"end\":51611,\"start\":51608},{\"end\":51622,\"start\":51619},{\"end\":51634,\"start\":51631},{\"end\":51648,\"start\":51644},{\"end\":52123,\"start\":52121},{\"end\":52132,\"start\":52129},{\"end\":52145,\"start\":52143},{\"end\":52155,\"start\":52152},{\"end\":52168,\"start\":52166},{\"end\":52179,\"start\":52176},{\"end\":52628,\"start\":52625},{\"end\":52641,\"start\":52637},{\"end\":52655,\"start\":52652},{\"end\":52665,\"start\":52662},{\"end\":52678,\"start\":52674},{\"end\":52690,\"start\":52687},{\"end\":52702,\"start\":52698},{\"end\":53138,\"start\":53133},{\"end\":53150,\"start\":53146},{\"end\":53162,\"start\":53158},{\"end\":53171,\"start\":53168},{\"end\":53186,\"start\":53182},{\"end\":53199,\"start\":53196},{\"end\":53210,\"start\":53206},{\"end\":53635,\"start\":53630},{\"end\":53644,\"start\":53641},{\"end\":53656,\"start\":53652},{\"end\":53665,\"start\":53662},{\"end\":53680,\"start\":53676},{\"end\":53693,\"start\":53690},{\"end\":53704,\"start\":53700},{\"end\":54139,\"start\":54134},{\"end\":54153,\"start\":54151},{\"end\":54168,\"start\":54164},{\"end\":54183,\"start\":54179},{\"end\":54652,\"start\":54647},{\"end\":54667,\"start\":54665},{\"end\":54684,\"start\":54680},{\"end\":55012,\"start\":55007},{\"end\":55027,\"start\":55025},{\"end\":55044,\"start\":55040},{\"end\":55376,\"start\":55371},{\"end\":55388,\"start\":55384},{\"end\":55400,\"start\":55396},{\"end\":55414,\"start\":55411},{\"end\":55421,\"start\":55419},{\"end\":55902,\"start\":55898},{\"end\":55914,\"start\":55909},{\"end\":55931,\"start\":55926},{\"end\":55945,\"start\":55940}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":697405},\"end\":33943,\"start\":33526},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":1435615},\"end\":34278,\"start\":33945},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":2876053},\"end\":34591,\"start\":34280},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":3638670},\"end\":35108,\"start\":34593},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":71150732},\"end\":35448,\"start\":35110},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":202577235},\"end\":35914,\"start\":35450},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":206764948},\"end\":36325,\"start\":35916},{\"attributes\":{\"id\":\"b7\"},\"end\":36696,\"start\":36327},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":53701783},\"end\":37081,\"start\":36698},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":9749221},\"end\":37599,\"start\":37083},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":51901514},\"end\":38191,\"start\":37601},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":67856061},\"end\":38793,\"start\":38193},{\"attributes\":{\"id\":\"b12\"},\"end\":39128,\"start\":38795},{\"attributes\":{\"doi\":\"10.1109/TNNLS.2019.2933\",\"id\":\"b13\"},\"end\":39312,\"start\":39130},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":19706288},\"end\":39754,\"start\":39314},{\"attributes\":{\"doi\":\"arXiv:1412.6980\",\"id\":\"b15\"},\"end\":39974,\"start\":39756},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":3645757},\"end\":40495,\"start\":39976},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":195473446},\"end\":40984,\"start\":40497},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":201645306},\"end\":41487,\"start\":40986},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":53957027},\"end\":42070,\"start\":41489},{\"attributes\":{\"id\":\"b20\"},\"end\":42469,\"start\":42072},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":3787969},\"end\":42963,\"start\":42471},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":199543622},\"end\":43423,\"start\":42965},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":7134884},\"end\":44099,\"start\":43425},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":40499053},\"end\":44505,\"start\":44101},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":843689},\"end\":44806,\"start\":44507},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":1718465},\"end\":45361,\"start\":44808},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":206594738},\"end\":45865,\"start\":45363},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":10328909},\"end\":46318,\"start\":45867},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":1089358},\"end\":46779,\"start\":46320},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":52860247},\"end\":47304,\"start\":46781},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":54461738},\"end\":47787,\"start\":47306},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":88516263},\"end\":48161,\"start\":47789},{\"attributes\":{\"doi\":\"arXiv:1409.1556\",\"id\":\"b33\"},\"end\":48450,\"start\":48163},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":3003101},\"end\":49004,\"start\":48452},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":2099022},\"end\":49456,\"start\":49006},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":198133773},\"end\":49765,\"start\":49458},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":201668945},\"end\":50220,\"start\":49767},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":72941021},\"end\":50677,\"start\":50222},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":11060885},\"end\":51084,\"start\":50679},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":54447074},\"end\":51497,\"start\":51086},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":201070309},\"end\":52028,\"start\":51499},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":198968173},\"end\":52557,\"start\":52030},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":202577232},\"end\":53076,\"start\":52559},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":207901201},\"end\":53576,\"start\":53078},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":207926635},\"end\":54060,\"start\":53578},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":2131202},\"end\":54567,\"start\":54062},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":13926293},\"end\":54962,\"start\":54569},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":14007626},\"end\":55285,\"start\":54964},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":4545310},\"end\":55822,\"start\":55287},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":198161572},\"end\":56324,\"start\":55824},{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":697405},\"end\":33943,\"start\":33526},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":1435615},\"end\":34278,\"start\":33945},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":2876053},\"end\":34591,\"start\":34280},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":3638670},\"end\":35108,\"start\":34593},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":71150732},\"end\":35448,\"start\":35110},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":202577235},\"end\":35914,\"start\":35450},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":206764948},\"end\":36325,\"start\":35916},{\"attributes\":{\"id\":\"b7\"},\"end\":36696,\"start\":36327},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":53701783},\"end\":37081,\"start\":36698},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":9749221},\"end\":37599,\"start\":37083},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":51901514},\"end\":38191,\"start\":37601},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":67856061},\"end\":38793,\"start\":38193},{\"attributes\":{\"id\":\"b12\"},\"end\":39128,\"start\":38795},{\"attributes\":{\"doi\":\"10.1109/TNNLS.2019.2933\",\"id\":\"b13\"},\"end\":39312,\"start\":39130},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":19706288},\"end\":39754,\"start\":39314},{\"attributes\":{\"doi\":\"arXiv:1412.6980\",\"id\":\"b15\"},\"end\":39974,\"start\":39756},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":3645757},\"end\":40495,\"start\":39976},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":195473446},\"end\":40984,\"start\":40497},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":201645306},\"end\":41487,\"start\":40986},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":53957027},\"end\":42070,\"start\":41489},{\"attributes\":{\"id\":\"b20\"},\"end\":42469,\"start\":42072},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":3787969},\"end\":42963,\"start\":42471},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":199543622},\"end\":43423,\"start\":42965},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":7134884},\"end\":44099,\"start\":43425},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":40499053},\"end\":44505,\"start\":44101},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":843689},\"end\":44806,\"start\":44507},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":1718465},\"end\":45361,\"start\":44808},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":206594738},\"end\":45865,\"start\":45363},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":10328909},\"end\":46318,\"start\":45867},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":1089358},\"end\":46779,\"start\":46320},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":52860247},\"end\":47304,\"start\":46781},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":54461738},\"end\":47787,\"start\":47306},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":88516263},\"end\":48161,\"start\":47789},{\"attributes\":{\"doi\":\"arXiv:1409.1556\",\"id\":\"b33\"},\"end\":48450,\"start\":48163},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":3003101},\"end\":49004,\"start\":48452},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":2099022},\"end\":49456,\"start\":49006},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":198133773},\"end\":49765,\"start\":49458},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":201668945},\"end\":50220,\"start\":49767},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":72941021},\"end\":50677,\"start\":50222},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":11060885},\"end\":51084,\"start\":50679},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":54447074},\"end\":51497,\"start\":51086},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":201070309},\"end\":52028,\"start\":51499},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":198968173},\"end\":52557,\"start\":52030},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":202577232},\"end\":53076,\"start\":52559},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":207901201},\"end\":53576,\"start\":53078},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":207926635},\"end\":54060,\"start\":53578},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":2131202},\"end\":54567,\"start\":54062},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":13926293},\"end\":54962,\"start\":54569},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":14007626},\"end\":55285,\"start\":54964},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":4545310},\"end\":55822,\"start\":55287},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":198161572},\"end\":56324,\"start\":55824}]", "bib_title": "[{\"end\":33589,\"start\":33526},{\"end\":34017,\"start\":33945},{\"end\":34341,\"start\":34280},{\"end\":34674,\"start\":34593},{\"end\":35150,\"start\":35110},{\"end\":35502,\"start\":35450},{\"end\":36009,\"start\":35916},{\"end\":36370,\"start\":36327},{\"end\":36749,\"start\":36698},{\"end\":37148,\"start\":37083},{\"end\":37687,\"start\":37601},{\"end\":38265,\"start\":38193},{\"end\":39416,\"start\":39314},{\"end\":40067,\"start\":39976},{\"end\":40574,\"start\":40497},{\"end\":41047,\"start\":40986},{\"end\":41580,\"start\":41489},{\"end\":42099,\"start\":42072},{\"end\":42535,\"start\":42471},{\"end\":43028,\"start\":42965},{\"end\":43562,\"start\":43425},{\"end\":44160,\"start\":44101},{\"end\":44569,\"start\":44507},{\"end\":44908,\"start\":44808},{\"end\":45418,\"start\":45363},{\"end\":45945,\"start\":45867},{\"end\":46377,\"start\":46320},{\"end\":46843,\"start\":46781},{\"end\":47369,\"start\":47306},{\"end\":47817,\"start\":47789},{\"end\":48552,\"start\":48452},{\"end\":49077,\"start\":49006},{\"end\":49517,\"start\":49458},{\"end\":49838,\"start\":49767},{\"end\":50281,\"start\":50222},{\"end\":50743,\"start\":50679},{\"end\":51132,\"start\":51086},{\"end\":51574,\"start\":51499},{\"end\":52110,\"start\":52030},{\"end\":52616,\"start\":52559},{\"end\":53125,\"start\":53078},{\"end\":53622,\"start\":53578},{\"end\":54127,\"start\":54062},{\"end\":54637,\"start\":54569},{\"end\":54997,\"start\":54964},{\"end\":55360,\"start\":55287},{\"end\":55889,\"start\":55824},{\"end\":33589,\"start\":33526},{\"end\":34017,\"start\":33945},{\"end\":34341,\"start\":34280},{\"end\":34674,\"start\":34593},{\"end\":35150,\"start\":35110},{\"end\":35502,\"start\":35450},{\"end\":36009,\"start\":35916},{\"end\":36370,\"start\":36327},{\"end\":36749,\"start\":36698},{\"end\":37148,\"start\":37083},{\"end\":37687,\"start\":37601},{\"end\":38265,\"start\":38193},{\"end\":39416,\"start\":39314},{\"end\":40067,\"start\":39976},{\"end\":40574,\"start\":40497},{\"end\":41047,\"start\":40986},{\"end\":41580,\"start\":41489},{\"end\":42099,\"start\":42072},{\"end\":42535,\"start\":42471},{\"end\":43028,\"start\":42965},{\"end\":43562,\"start\":43425},{\"end\":44160,\"start\":44101},{\"end\":44569,\"start\":44507},{\"end\":44908,\"start\":44808},{\"end\":45418,\"start\":45363},{\"end\":45945,\"start\":45867},{\"end\":46377,\"start\":46320},{\"end\":46843,\"start\":46781},{\"end\":47369,\"start\":47306},{\"end\":47817,\"start\":47789},{\"end\":48552,\"start\":48452},{\"end\":49077,\"start\":49006},{\"end\":49517,\"start\":49458},{\"end\":49838,\"start\":49767},{\"end\":50281,\"start\":50222},{\"end\":50743,\"start\":50679},{\"end\":51132,\"start\":51086},{\"end\":51574,\"start\":51499},{\"end\":52110,\"start\":52030},{\"end\":52616,\"start\":52559},{\"end\":53125,\"start\":53078},{\"end\":53622,\"start\":53578},{\"end\":54127,\"start\":54062},{\"end\":54637,\"start\":54569},{\"end\":54997,\"start\":54964},{\"end\":55360,\"start\":55287},{\"end\":55889,\"start\":55824}]", "bib_author": "[{\"end\":33611,\"start\":33591},{\"end\":33625,\"start\":33611},{\"end\":33650,\"start\":33625},{\"end\":33656,\"start\":33650},{\"end\":34030,\"start\":34019},{\"end\":34043,\"start\":34030},{\"end\":34055,\"start\":34043},{\"end\":34354,\"start\":34343},{\"end\":34367,\"start\":34354},{\"end\":34379,\"start\":34367},{\"end\":34700,\"start\":34676},{\"end\":34712,\"start\":34700},{\"end\":34732,\"start\":34712},{\"end\":34749,\"start\":34732},{\"end\":34755,\"start\":34749},{\"end\":35164,\"start\":35152},{\"end\":35176,\"start\":35164},{\"end\":35187,\"start\":35176},{\"end\":35201,\"start\":35187},{\"end\":35518,\"start\":35504},{\"end\":35530,\"start\":35518},{\"end\":35538,\"start\":35530},{\"end\":35547,\"start\":35538},{\"end\":35570,\"start\":35547},{\"end\":36025,\"start\":36011},{\"end\":36042,\"start\":36025},{\"end\":36384,\"start\":36372},{\"end\":36402,\"start\":36384},{\"end\":36769,\"start\":36751},{\"end\":36791,\"start\":36769},{\"end\":36804,\"start\":36791},{\"end\":36815,\"start\":36804},{\"end\":37165,\"start\":37150},{\"end\":37180,\"start\":37165},{\"end\":37194,\"start\":37180},{\"end\":37208,\"start\":37194},{\"end\":37704,\"start\":37689},{\"end\":37720,\"start\":37704},{\"end\":37735,\"start\":37720},{\"end\":37747,\"start\":37735},{\"end\":37766,\"start\":37747},{\"end\":37781,\"start\":37766},{\"end\":37795,\"start\":37781},{\"end\":38283,\"start\":38267},{\"end\":38295,\"start\":38283},{\"end\":38311,\"start\":38295},{\"end\":38326,\"start\":38311},{\"end\":38339,\"start\":38326},{\"end\":38355,\"start\":38339},{\"end\":38366,\"start\":38355},{\"end\":38865,\"start\":38849},{\"end\":38875,\"start\":38865},{\"end\":38883,\"start\":38875},{\"end\":38893,\"start\":38883},{\"end\":38905,\"start\":38893},{\"end\":38915,\"start\":38905},{\"end\":38928,\"start\":38915},{\"end\":38935,\"start\":38928},{\"end\":38946,\"start\":38935},{\"end\":38960,\"start\":38946},{\"end\":39427,\"start\":39418},{\"end\":39437,\"start\":39427},{\"end\":39452,\"start\":39437},{\"end\":39812,\"start\":39800},{\"end\":39826,\"start\":39812},{\"end\":39830,\"start\":39826},{\"end\":40080,\"start\":40069},{\"end\":40095,\"start\":40080},{\"end\":40108,\"start\":40095},{\"end\":40590,\"start\":40576},{\"end\":40602,\"start\":40590},{\"end\":40613,\"start\":40602},{\"end\":41061,\"start\":41049},{\"end\":41073,\"start\":41061},{\"end\":41085,\"start\":41073},{\"end\":41097,\"start\":41085},{\"end\":41111,\"start\":41097},{\"end\":41122,\"start\":41111},{\"end\":41592,\"start\":41582},{\"end\":41607,\"start\":41592},{\"end\":41622,\"start\":41607},{\"end\":41631,\"start\":41622},{\"end\":41639,\"start\":41631},{\"end\":41650,\"start\":41639},{\"end\":42113,\"start\":42101},{\"end\":42131,\"start\":42113},{\"end\":42143,\"start\":42131},{\"end\":42549,\"start\":42537},{\"end\":42570,\"start\":42549},{\"end\":42589,\"start\":42570},{\"end\":43042,\"start\":43030},{\"end\":43052,\"start\":43042},{\"end\":43067,\"start\":43052},{\"end\":43080,\"start\":43067},{\"end\":43578,\"start\":43564},{\"end\":43596,\"start\":43578},{\"end\":43612,\"start\":43596},{\"end\":43635,\"start\":43612},{\"end\":44176,\"start\":44162},{\"end\":44185,\"start\":44176},{\"end\":44210,\"start\":44185},{\"end\":44584,\"start\":44571},{\"end\":44595,\"start\":44584},{\"end\":44607,\"start\":44595},{\"end\":44926,\"start\":44910},{\"end\":44943,\"start\":44926},{\"end\":44960,\"start\":44943},{\"end\":44973,\"start\":44960},{\"end\":45435,\"start\":45420},{\"end\":45458,\"start\":45435},{\"end\":45475,\"start\":45458},{\"end\":45488,\"start\":45475},{\"end\":45969,\"start\":45947},{\"end\":45980,\"start\":45969},{\"end\":45995,\"start\":45980},{\"end\":46000,\"start\":45995},{\"end\":46401,\"start\":46379},{\"end\":46420,\"start\":46401},{\"end\":46426,\"start\":46420},{\"end\":46855,\"start\":46845},{\"end\":46862,\"start\":46855},{\"end\":46875,\"start\":46862},{\"end\":46887,\"start\":46875},{\"end\":46899,\"start\":46887},{\"end\":46914,\"start\":46899},{\"end\":47385,\"start\":47371},{\"end\":47399,\"start\":47385},{\"end\":47408,\"start\":47399},{\"end\":47420,\"start\":47408},{\"end\":47832,\"start\":47819},{\"end\":47847,\"start\":47832},{\"end\":47857,\"start\":47847},{\"end\":47864,\"start\":47857},{\"end\":48247,\"start\":48231},{\"end\":48265,\"start\":48247},{\"end\":48568,\"start\":48554},{\"end\":48577,\"start\":48568},{\"end\":48587,\"start\":48577},{\"end\":48594,\"start\":48587},{\"end\":49093,\"start\":49079},{\"end\":49102,\"start\":49093},{\"end\":49112,\"start\":49102},{\"end\":49119,\"start\":49112},{\"end\":49533,\"start\":49519},{\"end\":49542,\"start\":49533},{\"end\":49552,\"start\":49542},{\"end\":49559,\"start\":49552},{\"end\":49854,\"start\":49840},{\"end\":49872,\"start\":49854},{\"end\":49879,\"start\":49872},{\"end\":50292,\"start\":50283},{\"end\":50303,\"start\":50292},{\"end\":50312,\"start\":50303},{\"end\":50323,\"start\":50312},{\"end\":50754,\"start\":50745},{\"end\":50767,\"start\":50754},{\"end\":51147,\"start\":51134},{\"end\":51162,\"start\":51147},{\"end\":51177,\"start\":51162},{\"end\":51186,\"start\":51177},{\"end\":51198,\"start\":51186},{\"end\":51202,\"start\":51198},{\"end\":51591,\"start\":51576},{\"end\":51599,\"start\":51591},{\"end\":51613,\"start\":51599},{\"end\":51624,\"start\":51613},{\"end\":51636,\"start\":51624},{\"end\":51650,\"start\":51636},{\"end\":52125,\"start\":52112},{\"end\":52134,\"start\":52125},{\"end\":52147,\"start\":52134},{\"end\":52157,\"start\":52147},{\"end\":52170,\"start\":52157},{\"end\":52181,\"start\":52170},{\"end\":52630,\"start\":52618},{\"end\":52643,\"start\":52630},{\"end\":52657,\"start\":52643},{\"end\":52667,\"start\":52657},{\"end\":52680,\"start\":52667},{\"end\":52692,\"start\":52680},{\"end\":52704,\"start\":52692},{\"end\":53140,\"start\":53127},{\"end\":53152,\"start\":53140},{\"end\":53164,\"start\":53152},{\"end\":53173,\"start\":53164},{\"end\":53188,\"start\":53173},{\"end\":53201,\"start\":53188},{\"end\":53212,\"start\":53201},{\"end\":53637,\"start\":53624},{\"end\":53646,\"start\":53637},{\"end\":53658,\"start\":53646},{\"end\":53667,\"start\":53658},{\"end\":53682,\"start\":53667},{\"end\":53695,\"start\":53682},{\"end\":53706,\"start\":53695},{\"end\":54141,\"start\":54129},{\"end\":54155,\"start\":54141},{\"end\":54170,\"start\":54155},{\"end\":54185,\"start\":54170},{\"end\":54654,\"start\":54639},{\"end\":54669,\"start\":54654},{\"end\":54686,\"start\":54669},{\"end\":55014,\"start\":54999},{\"end\":55029,\"start\":55014},{\"end\":55046,\"start\":55029},{\"end\":55378,\"start\":55362},{\"end\":55390,\"start\":55378},{\"end\":55402,\"start\":55390},{\"end\":55416,\"start\":55402},{\"end\":55423,\"start\":55416},{\"end\":55904,\"start\":55891},{\"end\":55916,\"start\":55904},{\"end\":55933,\"start\":55916},{\"end\":55947,\"start\":55933},{\"end\":33611,\"start\":33591},{\"end\":33625,\"start\":33611},{\"end\":33650,\"start\":33625},{\"end\":33656,\"start\":33650},{\"end\":34030,\"start\":34019},{\"end\":34043,\"start\":34030},{\"end\":34055,\"start\":34043},{\"end\":34354,\"start\":34343},{\"end\":34367,\"start\":34354},{\"end\":34379,\"start\":34367},{\"end\":34700,\"start\":34676},{\"end\":34712,\"start\":34700},{\"end\":34732,\"start\":34712},{\"end\":34749,\"start\":34732},{\"end\":34755,\"start\":34749},{\"end\":35164,\"start\":35152},{\"end\":35176,\"start\":35164},{\"end\":35187,\"start\":35176},{\"end\":35201,\"start\":35187},{\"end\":35518,\"start\":35504},{\"end\":35530,\"start\":35518},{\"end\":35538,\"start\":35530},{\"end\":35547,\"start\":35538},{\"end\":35570,\"start\":35547},{\"end\":36025,\"start\":36011},{\"end\":36042,\"start\":36025},{\"end\":36384,\"start\":36372},{\"end\":36402,\"start\":36384},{\"end\":36769,\"start\":36751},{\"end\":36791,\"start\":36769},{\"end\":36804,\"start\":36791},{\"end\":36815,\"start\":36804},{\"end\":37165,\"start\":37150},{\"end\":37180,\"start\":37165},{\"end\":37194,\"start\":37180},{\"end\":37208,\"start\":37194},{\"end\":37704,\"start\":37689},{\"end\":37720,\"start\":37704},{\"end\":37735,\"start\":37720},{\"end\":37747,\"start\":37735},{\"end\":37766,\"start\":37747},{\"end\":37781,\"start\":37766},{\"end\":37795,\"start\":37781},{\"end\":38283,\"start\":38267},{\"end\":38295,\"start\":38283},{\"end\":38311,\"start\":38295},{\"end\":38326,\"start\":38311},{\"end\":38339,\"start\":38326},{\"end\":38355,\"start\":38339},{\"end\":38366,\"start\":38355},{\"end\":38865,\"start\":38849},{\"end\":38875,\"start\":38865},{\"end\":38883,\"start\":38875},{\"end\":38893,\"start\":38883},{\"end\":38905,\"start\":38893},{\"end\":38915,\"start\":38905},{\"end\":38928,\"start\":38915},{\"end\":38935,\"start\":38928},{\"end\":38946,\"start\":38935},{\"end\":38960,\"start\":38946},{\"end\":39427,\"start\":39418},{\"end\":39437,\"start\":39427},{\"end\":39452,\"start\":39437},{\"end\":39812,\"start\":39800},{\"end\":39826,\"start\":39812},{\"end\":39830,\"start\":39826},{\"end\":40080,\"start\":40069},{\"end\":40095,\"start\":40080},{\"end\":40108,\"start\":40095},{\"end\":40590,\"start\":40576},{\"end\":40602,\"start\":40590},{\"end\":40613,\"start\":40602},{\"end\":41061,\"start\":41049},{\"end\":41073,\"start\":41061},{\"end\":41085,\"start\":41073},{\"end\":41097,\"start\":41085},{\"end\":41111,\"start\":41097},{\"end\":41122,\"start\":41111},{\"end\":41592,\"start\":41582},{\"end\":41607,\"start\":41592},{\"end\":41622,\"start\":41607},{\"end\":41631,\"start\":41622},{\"end\":41639,\"start\":41631},{\"end\":41650,\"start\":41639},{\"end\":42113,\"start\":42101},{\"end\":42131,\"start\":42113},{\"end\":42143,\"start\":42131},{\"end\":42549,\"start\":42537},{\"end\":42570,\"start\":42549},{\"end\":42589,\"start\":42570},{\"end\":43042,\"start\":43030},{\"end\":43052,\"start\":43042},{\"end\":43067,\"start\":43052},{\"end\":43080,\"start\":43067},{\"end\":43578,\"start\":43564},{\"end\":43596,\"start\":43578},{\"end\":43612,\"start\":43596},{\"end\":43635,\"start\":43612},{\"end\":44176,\"start\":44162},{\"end\":44185,\"start\":44176},{\"end\":44210,\"start\":44185},{\"end\":44584,\"start\":44571},{\"end\":44595,\"start\":44584},{\"end\":44607,\"start\":44595},{\"end\":44926,\"start\":44910},{\"end\":44943,\"start\":44926},{\"end\":44960,\"start\":44943},{\"end\":44973,\"start\":44960},{\"end\":45435,\"start\":45420},{\"end\":45458,\"start\":45435},{\"end\":45475,\"start\":45458},{\"end\":45488,\"start\":45475},{\"end\":45969,\"start\":45947},{\"end\":45980,\"start\":45969},{\"end\":45995,\"start\":45980},{\"end\":46000,\"start\":45995},{\"end\":46401,\"start\":46379},{\"end\":46420,\"start\":46401},{\"end\":46426,\"start\":46420},{\"end\":46855,\"start\":46845},{\"end\":46862,\"start\":46855},{\"end\":46875,\"start\":46862},{\"end\":46887,\"start\":46875},{\"end\":46899,\"start\":46887},{\"end\":46914,\"start\":46899},{\"end\":47385,\"start\":47371},{\"end\":47399,\"start\":47385},{\"end\":47408,\"start\":47399},{\"end\":47420,\"start\":47408},{\"end\":47832,\"start\":47819},{\"end\":47847,\"start\":47832},{\"end\":47857,\"start\":47847},{\"end\":47864,\"start\":47857},{\"end\":48247,\"start\":48231},{\"end\":48265,\"start\":48247},{\"end\":48568,\"start\":48554},{\"end\":48577,\"start\":48568},{\"end\":48587,\"start\":48577},{\"end\":48594,\"start\":48587},{\"end\":49093,\"start\":49079},{\"end\":49102,\"start\":49093},{\"end\":49112,\"start\":49102},{\"end\":49119,\"start\":49112},{\"end\":49533,\"start\":49519},{\"end\":49542,\"start\":49533},{\"end\":49552,\"start\":49542},{\"end\":49559,\"start\":49552},{\"end\":49854,\"start\":49840},{\"end\":49872,\"start\":49854},{\"end\":49879,\"start\":49872},{\"end\":50292,\"start\":50283},{\"end\":50303,\"start\":50292},{\"end\":50312,\"start\":50303},{\"end\":50323,\"start\":50312},{\"end\":50754,\"start\":50745},{\"end\":50767,\"start\":50754},{\"end\":51147,\"start\":51134},{\"end\":51162,\"start\":51147},{\"end\":51177,\"start\":51162},{\"end\":51186,\"start\":51177},{\"end\":51198,\"start\":51186},{\"end\":51202,\"start\":51198},{\"end\":51591,\"start\":51576},{\"end\":51599,\"start\":51591},{\"end\":51613,\"start\":51599},{\"end\":51624,\"start\":51613},{\"end\":51636,\"start\":51624},{\"end\":51650,\"start\":51636},{\"end\":52125,\"start\":52112},{\"end\":52134,\"start\":52125},{\"end\":52147,\"start\":52134},{\"end\":52157,\"start\":52147},{\"end\":52170,\"start\":52157},{\"end\":52181,\"start\":52170},{\"end\":52630,\"start\":52618},{\"end\":52643,\"start\":52630},{\"end\":52657,\"start\":52643},{\"end\":52667,\"start\":52657},{\"end\":52680,\"start\":52667},{\"end\":52692,\"start\":52680},{\"end\":52704,\"start\":52692},{\"end\":53140,\"start\":53127},{\"end\":53152,\"start\":53140},{\"end\":53164,\"start\":53152},{\"end\":53173,\"start\":53164},{\"end\":53188,\"start\":53173},{\"end\":53201,\"start\":53188},{\"end\":53212,\"start\":53201},{\"end\":53637,\"start\":53624},{\"end\":53646,\"start\":53637},{\"end\":53658,\"start\":53646},{\"end\":53667,\"start\":53658},{\"end\":53682,\"start\":53667},{\"end\":53695,\"start\":53682},{\"end\":53706,\"start\":53695},{\"end\":54141,\"start\":54129},{\"end\":54155,\"start\":54141},{\"end\":54170,\"start\":54155},{\"end\":54185,\"start\":54170},{\"end\":54654,\"start\":54639},{\"end\":54669,\"start\":54654},{\"end\":54686,\"start\":54669},{\"end\":55014,\"start\":54999},{\"end\":55029,\"start\":55014},{\"end\":55046,\"start\":55029},{\"end\":55378,\"start\":55362},{\"end\":55390,\"start\":55378},{\"end\":55402,\"start\":55390},{\"end\":55416,\"start\":55402},{\"end\":55423,\"start\":55416},{\"end\":55904,\"start\":55891},{\"end\":55916,\"start\":55904},{\"end\":55933,\"start\":55916},{\"end\":55947,\"start\":55933}]", "bib_venue": "[{\"end\":33737,\"start\":33705},{\"end\":34856,\"start\":34814},{\"end\":35691,\"start\":35639},{\"end\":36523,\"start\":36471},{\"end\":37349,\"start\":37287},{\"end\":37896,\"start\":37854},{\"end\":38507,\"start\":38445},{\"end\":40249,\"start\":40187},{\"end\":40754,\"start\":40692},{\"end\":41243,\"start\":41191},{\"end\":41791,\"start\":41729},{\"end\":42284,\"start\":42222},{\"end\":42730,\"start\":42668},{\"end\":43201,\"start\":43149},{\"end\":43786,\"start\":43719},{\"end\":44311,\"start\":44269},{\"end\":45094,\"start\":45042},{\"end\":45629,\"start\":45567},{\"end\":46099,\"start\":46058},{\"end\":46567,\"start\":46505},{\"end\":47055,\"start\":46993},{\"end\":47561,\"start\":47499},{\"end\":47985,\"start\":47933},{\"end\":48745,\"start\":48678},{\"end\":49240,\"start\":49188},{\"end\":50000,\"start\":49948},{\"end\":50464,\"start\":50402},{\"end\":50890,\"start\":50837},{\"end\":51771,\"start\":51719},{\"end\":52302,\"start\":52250},{\"end\":52825,\"start\":52773},{\"end\":53333,\"start\":53281},{\"end\":53827,\"start\":53775},{\"end\":54326,\"start\":54264},{\"end\":55564,\"start\":55502},{\"end\":56088,\"start\":56026},{\"end\":33737,\"start\":33705},{\"end\":34856,\"start\":34814},{\"end\":35691,\"start\":35639},{\"end\":36523,\"start\":36471},{\"end\":37349,\"start\":37287},{\"end\":37896,\"start\":37854},{\"end\":38507,\"start\":38445},{\"end\":40249,\"start\":40187},{\"end\":40754,\"start\":40692},{\"end\":41243,\"start\":41191},{\"end\":41791,\"start\":41729},{\"end\":42284,\"start\":42222},{\"end\":42730,\"start\":42668},{\"end\":43201,\"start\":43149},{\"end\":43786,\"start\":43719},{\"end\":44311,\"start\":44269},{\"end\":45094,\"start\":45042},{\"end\":45629,\"start\":45567},{\"end\":46099,\"start\":46058},{\"end\":46567,\"start\":46505},{\"end\":47055,\"start\":46993},{\"end\":47561,\"start\":47499},{\"end\":47985,\"start\":47933},{\"end\":48745,\"start\":48678},{\"end\":49240,\"start\":49188},{\"end\":50000,\"start\":49948},{\"end\":50464,\"start\":50402},{\"end\":50890,\"start\":50837},{\"end\":51771,\"start\":51719},{\"end\":52302,\"start\":52250},{\"end\":52825,\"start\":52773},{\"end\":53333,\"start\":53281},{\"end\":53827,\"start\":53775},{\"end\":54326,\"start\":54264},{\"end\":55564,\"start\":55502},{\"end\":56088,\"start\":56026},{\"end\":33703,\"start\":33656},{\"end\":34092,\"start\":34055},{\"end\":34416,\"start\":34379},{\"end\":34812,\"start\":34755},{\"end\":35258,\"start\":35201},{\"end\":35637,\"start\":35570},{\"end\":36104,\"start\":36042},{\"end\":36469,\"start\":36402},{\"end\":36872,\"start\":36815},{\"end\":37285,\"start\":37208},{\"end\":37852,\"start\":37795},{\"end\":38443,\"start\":38366},{\"end\":38847,\"start\":38795},{\"end\":39212,\"start\":39155},{\"end\":39514,\"start\":39452},{\"end\":39798,\"start\":39756},{\"end\":40185,\"start\":40108},{\"end\":40690,\"start\":40613},{\"end\":41189,\"start\":41122},{\"end\":41727,\"start\":41650},{\"end\":42220,\"start\":42143},{\"end\":42666,\"start\":42589},{\"end\":43147,\"start\":43080},{\"end\":43717,\"start\":43635},{\"end\":44267,\"start\":44210},{\"end\":44639,\"start\":44607},{\"end\":45040,\"start\":44973},{\"end\":45565,\"start\":45488},{\"end\":46056,\"start\":46000},{\"end\":46503,\"start\":46426},{\"end\":46991,\"start\":46914},{\"end\":47497,\"start\":47420},{\"end\":47931,\"start\":47864},{\"end\":48229,\"start\":48163},{\"end\":48676,\"start\":48594},{\"end\":49186,\"start\":49119},{\"end\":49596,\"start\":49559},{\"end\":49946,\"start\":49879},{\"end\":50400,\"start\":50323},{\"end\":50835,\"start\":50767},{\"end\":51274,\"start\":51202},{\"end\":51717,\"start\":51650},{\"end\":52248,\"start\":52181},{\"end\":52771,\"start\":52704},{\"end\":53279,\"start\":53212},{\"end\":53773,\"start\":53706},{\"end\":54262,\"start\":54185},{\"end\":54748,\"start\":54686},{\"end\":55108,\"start\":55046},{\"end\":55500,\"start\":55423},{\"end\":56024,\"start\":55947},{\"end\":33703,\"start\":33656},{\"end\":34092,\"start\":34055},{\"end\":34416,\"start\":34379},{\"end\":34812,\"start\":34755},{\"end\":35258,\"start\":35201},{\"end\":35637,\"start\":35570},{\"end\":36104,\"start\":36042},{\"end\":36469,\"start\":36402},{\"end\":36872,\"start\":36815},{\"end\":37285,\"start\":37208},{\"end\":37852,\"start\":37795},{\"end\":38443,\"start\":38366},{\"end\":38847,\"start\":38795},{\"end\":39212,\"start\":39155},{\"end\":39514,\"start\":39452},{\"end\":39798,\"start\":39756},{\"end\":40185,\"start\":40108},{\"end\":40690,\"start\":40613},{\"end\":41189,\"start\":41122},{\"end\":41727,\"start\":41650},{\"end\":42220,\"start\":42143},{\"end\":42666,\"start\":42589},{\"end\":43147,\"start\":43080},{\"end\":43717,\"start\":43635},{\"end\":44267,\"start\":44210},{\"end\":44639,\"start\":44607},{\"end\":45040,\"start\":44973},{\"end\":45565,\"start\":45488},{\"end\":46056,\"start\":46000},{\"end\":46503,\"start\":46426},{\"end\":46991,\"start\":46914},{\"end\":47497,\"start\":47420},{\"end\":47931,\"start\":47864},{\"end\":48229,\"start\":48163},{\"end\":48676,\"start\":48594},{\"end\":49186,\"start\":49119},{\"end\":49596,\"start\":49559},{\"end\":49946,\"start\":49879},{\"end\":50400,\"start\":50323},{\"end\":50835,\"start\":50767},{\"end\":51274,\"start\":51202},{\"end\":51717,\"start\":51650},{\"end\":52248,\"start\":52181},{\"end\":52771,\"start\":52704},{\"end\":53279,\"start\":53212},{\"end\":53773,\"start\":53706},{\"end\":54262,\"start\":54185},{\"end\":54748,\"start\":54686},{\"end\":55108,\"start\":55046},{\"end\":55500,\"start\":55423},{\"end\":56024,\"start\":55947}]"}}}, "year": 2023, "month": 12, "day": 17}