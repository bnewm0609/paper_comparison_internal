{"id": 2138943, "updated": "2023-11-11 03:26:36.959", "metadata": {"title": "Spinner: Scalable Graph Partitioning in the Cloud", "authors": "[{\"first\":\"Claudio\",\"last\":\"Martella\",\"middle\":[]},{\"first\":\"Dionysios\",\"last\":\"Logothetis\",\"middle\":[]},{\"first\":\"Andreas\",\"last\":\"Loukas\",\"middle\":[]},{\"first\":\"Georgos\",\"last\":\"Siganos\",\"middle\":[]}]", "venue": "2017 IEEE 33rd International Conference on Data Engineering (ICDE)", "journal": "2017 IEEE 33rd International Conference on Data Engineering (ICDE)", "publication_date": {"year": 2017, "month": null, "day": null}, "abstract": "In this paper, we present a graph partitioning algorithm to partition graphs with trillions of edges. To achieve such scale, our solution leverages the vertex-centric Pregel abstraction provided by Giraph, a system for large-scale graph analytics. We designed our algorithm to compute partitions with high locality and fair balance, and focused on the characteristics necessary to reach wide adoption by practitioners in production. Our solution can (i) scale to massive graphs and thousands of compute cores, (ii) efficiently adapt partitions to changes to graphs and compute environments, and (iii) seamlessly integrate in existing systems without additional infrastructure. We evaluate our solution on the Facebook and Instagram graphs, as well as on other large-scale, real-world graphs. We show that it is scalable and computes partitionings with quality comparable, and sometimes outperforming, existing solutions. By integrating the computed partitionings in Giraph, we speedup various real-world applications by up to a factor of 5.6 compared to default hash-partitioning.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": "2964157613", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/icde/MartellaLLS17", "doi": "10.1109/icde.2017.153"}}, "content": {"source": {"pdf_hash": "c6596eb01b2a3ea782be33d9510694c42ab46005", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/1404.3861v2.pdf\"]", "oa_url_match": true, "oa_info": {"license": null, "open_access_url": "http://arxiv.org/pdf/1404.3861", "status": "GREEN"}}, "grobid": {"id": "f185ae70a14fbe045f78f50988df41fb22eb72a2", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/c6596eb01b2a3ea782be33d9510694c42ab46005.txt", "contents": "\nSpinner: Scalable Graph Partitioning in the Cloud\n\n\nClaudio Martella \nDionysios Logothetis \nAndreas Loukas \nGeorgos Siganos \nSpinner: Scalable Graph Partitioning in the Cloud\n1Pregelgraph partitioninggraph processingcloud computing\nSeveral organizations, like social networks, store and routinely analyze large graphs as part of their daily operation. Such graphs are typically distributed across multiple servers, and graph partitioning is critical for efficient graph management. Existing partitioning algorithms focus on finding graph partitions with good locality, but disregard the pragmatic challenges of integrating partitioning into large-scale graph management systems deployed on the cloud, such as dealing with the scale and dynamicity of the graph and the compute environment.In this paper, we propose Spinner, a scalable and adaptive graph partitioning algorithm based on label propagation designed on top of the Pregel model. Spinner scales to massive graphs, produces partitions with locality and balance comparable to the state-of-the-art and efficiently adapts the partitioning upon changes. We describe our algorithm and its implementation in the Pregel programming model that makes it possible to partition billion-vertex graphs. We evaluate Spinner with a variety of synthetic and real graphs and show that it can compute partitions with quality comparable to the state-of-the art. In fact, by using Spinner in conjunction with the Giraph graph processing engine, we speed up different applications by a factor of 2 relative to standard hash partitioning.\n\nI. INTRODUCTION\n\nGraph partitioning is a core component for scalable and efficient graph processing. The size of graphs available today, whether a social network, the Web, or a protein interaction network [11], requires graph management systems [18], [10], [21], [23] to distribute the graph, typically across sharednothing clusters or clouds. Due to the inherent dependencies that characterize graphs, producing partitions with good locality is critical in minimizing communication overheads and improving system scalability [17]. At the same time, partitions that balance processing across the cluster can improve resource utilization and reduce overall processing latency.\n\nHowever, integrating graph partitioning in graph management systems introduces a number of pragmatic challenges that are disregarded by existing solutions. First, the scale of the graphs, often reaching billions of vertices and edges, makes it hard to provide locality and balance at the same time. For instance, the Metis algorithm [12], [13] produces partitionings with good locality and balance, but doing so incurs high computational cost and requires a global view of the graph that makes it impractical for large graphs [28], [14], [25]. Alternative algorithms maintain balanced partitions by introducing centralized components to enforce strict constraints on the size of the partitions [29], limiting scalability as well. As a result, systems often resort to lightweight solutions, such as hash partitioning, despite the poor locality that it offers. Second, graph management systems need to continuously adapt the partitioning of the graph [21]. One one hand, graphs are naturally dynamic, with vertices and edges constantly added and removed. Thus, the system must regularly update the partitioning to maintain optimal application performance. On the other hand, modern computing platforms are elastic, allowing to scale up and down on demand depending on workload requirements. This implies that the system must redistribute the graph across a different number of machines. To maintain a good partitioning under these conditions, existing solutions continuously re-execute the partitioning algorithm from scratch. This expensive approach prohibits frequent updates and wastes computational resources. Furthermore, it does not consider the previous state of the partitioned graph; a repartitioning may compute totally different vertex locations. This forces the system to shuffle a large fraction of the graph, impacting performance.\n\nAt the same time, recently emerged graph processing systems, like Pregel [18] and Graphlab [16], provide platforms customized for the design and execution of graph algorithms at scale. They offer programming abstractions that naturally lead to distributed algorithms. Further, their execution environments allow to scale to large graphs leveraging clusters consisting of commodity hardware. In fact, this has resulted in porting several graph algorithms on such systems [22], [20], [3]. However, no work has explored so far how the problem of graph partitioning can benefit from these architectures.\n\nIn this paper, we propose to leverage such architectures for the development of scalable graph partitioning algorithms. We introduce Spinner, a partitioning algorithm that runs on top of Giraph [1], an open source implementation of the Pregel model [18]. Spinner can partition billion-vertex graphs with good locality and balance, and efficiently adapts to changes in the graph or changes in the number of partitions.\n\nSpinner uses an iterative vertex migration heuristic based on the Label Propagation Algorithm (LPA). We extend LPA to a scalable, distributed algorithm on top of the Pregel (Giraph) programming model. As a design choice, Spinner avoids expensive centralizations of the partitioning algorithm [12], [29], [28] that may offer strict guarantees about partitioning at the cost of scalability. However, we show that building only on the programming primitives of Pregel, Spinner can still provide good locality and balance, reconciling scalability with partitioning quality.\n\nFurther, we designed Spinner to efficiently adapt a partitioning upon changes to the graph or the compute environment. By avoiding re-computations from scratch, Spinner reduces the time to update the partitioning by more than 85% even for large changes (2%) to the graph, allowing for frequent adaptation, and saving computation resources. Further, the incremental adaptation prevents graph management systems from shuffling large portions of the graph upon changes.\n\nFinally, we show that we can use the resulting partitionings of Spinner to improve the performance of graph management systems. In particular, we use Spinner to partition the graph in the Giraph graph analytics engine, and show that this speeds up processing of applications by up to a factor of 2.\n\nIn this paper, we make the following contributions:\n\n\u2022 We introduce Spinner, a scalable graph partitioning algorithm based on label propagation that computes k-way balanced partitions with good locality. \u2022 We provide a scalable, open source implementation of the algorithm on top of the Giraph graph processing system. We extend the basic LPA formulation to support a decentralized implementation that reconciles scalability and balance guarantees. To the best of our knowledge, this is the first implementation of a partitioning algorithm on the Pregel model. \u2022 We extend the core algorithm to adapt an existing partitioning upon changes in the graph or the or the number of partitions in an incremental fashion. This minimizes computation and offers partitioning stability. \u2022 We evaluate Spinner extensively, using synthetic and real graphs. We show that Spinner scales near-linearly to billion-vertex graphs, adapts efficiently to dynamic changes, and significantly improves application performance when integrated into Giraph. The remaining of this paper is organized as follows. In Section II, we outline Spinner's design goals and give a brief overview of graph processing systems. In Section III we describe the Spinner algorithm in detail. Section IV describes the implementation of Spinner in the Pregel model, while in Section V we present a thorough evaluation. In Section VI we discuss related work, and Section VII concludes our study.\n\n\nII. MOTIVATION AND BACKGROUND\n\nTo motivate our approach, in this section we first describe our design goals. We then give a brief overview of graph processing architectures and discuss how we can exploit such systems to build a scalable partitioning solution.\n\n\nA. Design goals\n\nAt a high level, Spinner must produce good partitionings but also be practical. It must be able to manage the challenges arising from graph management systems, such as scale and dynamism.\n\nPartitioning quality. Spinner must compute partitions with good locality and balance. Typically, graph processing systems [18], [16] and graph databases [23], [30] distribute vertices across machines. Because communication in such systems coincides with graph edges, network traffic occurs when edges cross partition boundaries. Therefore, a good partitioning algorithm must minimize the cut edges 1 . Further, partitions that 1 The edges that cross partition boundaries. balance the load across machines improve processing latency and resource utilization. For instance, in graph processing systems the load depends on the number of messages exchanged and therefore on the number of edges. In fact, although our approach is general, here we will focus on balancing partitions on the number of edges they contain. Additionally, unlike traditional community detection algorithms, we must control the number k of the partitions, as this is mandated by the underlying compute environment, for example, the number of available machines or cores. This objective is commonly referred to as k-way partitioning. Scalability. We must be able to apply Spinner to billionvertex graphs. As a design principle, our algorithm must be lightweight and lend itself to a distributed implementation. Note that providing strict guarantees about locality and balance and, at the same time, scale to large graphs may be conflicting requirements. Often, providing such guarantees requires expensive coordination or global views of the graph [12], preventing scalability.\n\nIn this paper, we take a different approach as we are willing to trade partitioning quality and forego strict guarantees in favor of a more practical algorithm that can scale. In subsequent sections, we show how relaxing these requirements allows a scalable distributed implementation that still produces good partitions for all practical purposes.\n\nAdaptability. Spinner must be able adapt the partitioning to changes in the graph or the underlying compute environment. For efficiency, we want to avoid re-partitioning the graph from scratch, rather compute a new good partitioning incrementally. We also want to avoid large changes in the adapted partitioning as they may force the shuffling of vertices in the underlying graph management system. Therefore, our algorithm should take into consideration the most recent state of the partitioning.\n\n\nB. Leveraging the Pregel model\n\nIn this paper, we propose to design a graph partitioning solution on top of graph processing architectures such as [18], [1], [16], [32]. These systems advocate a vertex-centric programming paradigm that naturally forces users to express graph algorithms in a distributed manner. Further, such systems are becoming an integral part of the software stack deployed on cloud environments. Building on top of such a system renders our partitioning solution practical for a wide range of compute environments.\n\nIn such models, graph algorithms are expressed through a vertex computation function that the system computes for each vertex in the graph. Vertex computations are executed in parallel by the underlying runtime and can synchronize through messages [18] or shared memory [16].\n\nSpinner builds upon Pregel in particular, an abstraction that is based on a synchronous execution model and makes it easy to scale to large graphs. In Pregel, a program is structured as a sequence of well-defined computation phases called supersteps. During a superstep every vertex executes the user-defined compute function in parallel. Vertices have an associated state that they access from within the user-defined function, and may communicate with each other through messages. In Pregel, messages are delivered in a synchronous manner only at the end of a superstep.\n\nThe synchronous nature of the Pregel model avoids any expensive coordination among vertices, allowing programs to scale near-linearly. In the following, we will show that building a graph partitioning algorithm with this primitive allows us to apply Spinner to billion-vertex graphs.\n\n\nIII. PROPOSED SOLUTION\n\nWe have designed Spinner based on the Label Propagation Algorithm (LPA), a technique that has been used traditionally for community detection [8]. We choose LPA as it offers a generic and well understood framework on top of which we can build our partitioning algorithm as an optimization problem tailored to our objectives. In the following, we describe how we extend the formulation of LPA to achieve the goals we set in Section II. We extend LPA in a way that we can execute it in a scalable way while maintaining partitioning quality and efficiently adapt a partitioning upon changes.\n\nBefore going into the details of the algorithm, let us introduce the necessary notation. We define a graph as G = V, E , where V is the set of vertices in the graph and E is the set of edges such that an edge e \u2208 E is a pair\n(u, v) with u, v \u2208 V . We denote by N(v) = {u : u \u2208 V, (u, v) \u2208 E} the neighborhood of a vertex v, and by deg(v) = |N(v)| the degree of v.\nIn a kway partitioning, we define L as a set of labels L = {l 1 , . . . , l k } that essentially correspond to the k partitions. \u03b1 is the labeling\nfunction \u03b1 : V \u2192 L such that \u03b1(v) = l j if label l j is assigned to vertex v.\nThe end goal of Spinner is to assign partitions, or labels, to each vertex such that it maximizes edge locality and partitions are balanced.\n\n\nA. K-way Label Propagation\n\nWe first describe how to use basic LPA to maximize edge locality and then extend the algorithm to achieve balanced partitions. Initially, each vertex in the graph is assigned a label l i at random, with 0 < i \u2264 k. Subsequently, every vertex iteratively propagates its label to its neighbors. During this iterative process, a vertex acquires the label that is more frequent among its neighbors. Specifically, every vertex v assigns a different score for a particular label l which is equal to the number of neighbors assigned to label l\nscore(v, l) = \u2211 u\u2208N(v) \u03b4 (\u03b1(u), l)(1)\nwhere \u03b4 is the Kronecker delta. Vertices show preference to labels with high score. More formally, a vertex updates its label to the label l v that maximizes its score according to the update function We call such an update a migration as it represents a logical vertex migration between two partitions. In the event that multiple labels satisfy the update function, we break ties randomly, but prefer to keep the current label if it is among them. This break-tie rule improves convergence speed [8], and in our distributed implementation reduces unnecessary network communication (see Section IV). The algorithm halts when no vertex updates its label.\nl v = arg max l score(v, l)(2)\nNote that the original formulation of LPA assumes undirected graphs. However, very often graphs are directed (e.g. the Web). Even the data models of systems like Pregel allow directed graphs, to support algorithms that are aware of graph directness, like PageRank. To use LPA as is, we would need to convert a graph to undirected. The naive approach would be to create an undirected edge between vertices u and v whenever at least one directed edge exists between vertex u and v in the directed graph.\n\nThis approach, though, is agnostic to the communication patterns of the applications running on top. Consider the example graph in Figure 1 that we want to partition to 3 parts. In the undirected graph (right), there are initially 3 cut edges. At this point, according to the LPA formulation, which is agnostic of the directness of the original graph, any migration of a vertex to another partition is as likely, and it would produce one cut edge less.\n\nHowever, if we consider the directness of the edges in the original graph, not all migrations are equally beneficial. In fact, either moving vertex 2 to partition 1 or vertex 1 to partition 3 would in practice produce less cut edges in the directed graph. Once the graph is loaded into the system and messages are sent across the directed edges, this latter decision results in less communication over the network.\n\nSpinner considers the number of directed edges connecting u, v in the original directed graph D by introducing a weighting function w(u, v) such that\nw(u, w) = 1, if (u, v) \u2208 D \u2295 (v, u) \u2208 D 2, if (u, v) \u2208 D \u2227 (v, u) \u2208 D(3)\nwhere \u2295 is the logical XOR. We extend now the formulation in (1) to include the weighting function\nscore (v, l) = \u2211 u\u2208N(v) w(u, v)\u03b4 (\u03b1(u), l)(4)\nIn practice, the new update function effectively counts the number of messages exchanged locally in the system.\n\nNotice that, so far, the formulation of LPA does not dictate in what order and when vertices propagate their labels or how we should parallelize this process. For instance, the propagation can occur in an asynchronous manner, with a vertex propagating its label to its neighbors immediately after an update. A synchronous propagation, instead, occurs in distinct iterations with every vertex propagating its label at the end of an iteration. In Section IV, we will see how we constraint the propagation to occur in a synchronous fashion to retro-fit LPA to the Pregel model, allowing the massive parallelization of a single LPA iteration.\n\n\nB. Balanced Label Propagation\n\nNext, we will extend LPA to produce balanced partitions. In Spinner, we take a different path from previous work [29] that balances partitions by enforcing strict constraints on the partition sizes. Such an approach requires the addition to LPA of a centralized component to ensure the satisfaction of the balance constraints across the graph. Essentially, it calculates which of the possible migration decisions will not violate the constraints. This component is used after each LPA iteration, potentially increasing the algorithm overhead and limiting scalability.\n\nInstead, as our aim is to provide a practical and scalable solution, Spinner relaxes this constraint, only encouraging a similar number of edges across the different partitions. In particular, to maintain balance, we integrate a penalty function into the vertex score in (4) that penalizes migrations to partitions that are nearly full. Importantly, we define the penalty function so that we can calculate it in a scalable manner.\n\nIn the following, we consider the case of a homogeneous system, where each machine has equal resources. This setup is often preferred, for instance, in graph processing systems like Pregel, to eliminate the problem of stragglers and improve processing latency and overall resource utilization.\n\nWe define the capacity C of a partition as the maximum number of edges it can have so that partitions are balanced, which we set to\nC = c \u00b7 |E| k(5)\nwhere c > 1 is a constant, and the load b(l) of a partition l as the actual number of edges in the partition\nb(l) = \u2211 v\u2208G deg(v)\u03b4 (\u03b1(v), l)(6)\nThe capacity C represents the constraint that Spinner puts on the load of the partitions during an LPA iteration, and for homogeneous systems it is the same for every partition. Notice that in an ideally balanced partitioning, every partition would contain |E|/k edges. However, Spinner uses parameter c to let the load of a partition exceed this ideal value. This allows for vertices to migrate among partitions, potentially improving locality, even if this is going to reduce balance.\n\nAt the same time, to control the degree of unbalance, we introduce the following penalty function that discourages the assignment of vertices to nearly full partitions. Given a partition l, we define the penalty function \u03c0(l) as\n\u03c0(l) = b(l) C (7)\nThe closer the current load of a partition to its capacity is, the higher the penalty of a migration to this partition is, with the penalty value ranging from 0 to 1. Next, we integrate the penalty function into the score function. To do so, we first normalize (4), and reformulate the score function as follows\nscore (v, l) = \u2211 u\u2208N(v) w(u, v)\u03b4 (\u03b1(u), l) \u2211 u\u2208N(v) w(u, v) \u2212 \u03c0(l)(8)\nThis penalty function has the following desirable properties. First, using parameter c we can control the tradeoff between partition unbalance and convergence speed. A larger value of c increases the number of migrations allowed to each partition at each iteration. This possibly speeds up convergence, but may increase unbalance, as more edges are allowed to be assigned to each partition over the ideal value |E|/k.\n\nSecond, it allows us to compute the score function in a scalable way. Notice that the locality score depends on pervertex information. Further, computing the introduced penalty function only requires to calculate b(l). This is an aggregate across all vertices that are assigned label l. As we describe in Section IV, we can leverage the Giraph aggregation primitives to compute b(l) for all possible labels in a scalable manner. As we show later, the introduction of this simple penalty function is enough to produce partitions with balance comparable to the state-of-the-art.\n\n\nC. Convergence and halting\n\nAlthough proving the convergence properties of LPA is a hard problem in the general case [8], our additional emphasis on partition balance, namely that a vertex can migrate to improve balance despite a decrease in locality, allow us to provide some analytical guarantees about Spinner's convergence and partitioning quality. One of the difficulties in proving convergence is that approaches based on LPA sometimes reach a limit cycle where the partitioning fluctuates between the same states. Nevertheless, we can analyze it from a stochastic perspective. By using classic results from the theory of products of stochastic matrices [27], [26], in the following we show that: (i) under sufficient conditions on the connectivity of the underlying graph, Spinner converges exponentially-fast to an even balancing, and (ii) in the general case Spinner convergences, but no guarantees are provided about the partitioning quality. For practical purposes, in this section we also provide a heuristic for deciding when to halt the execution of the algorithm.\n\nModel. We will abstract from the underlying graph by encoding the system state in a k-dimensional load vector x = [B(l 1 ), B(l 2 ), . . . B(l k )]. At each iteration t, Spinner moves a portion of the load of each partition to each of the other k \u2212 1 partitions. This can be captured by a partition graph P t = (L, Q t ), having one vertex for each label and an edge (l i , l j ) \u2208 Q t if and only if the portion [X t ] i j of load which migrates from partition i to j is larger than zero. Supposing that x 0 is the starting state, the state x t during iteration t is given by\nx t = X t X t\u22121 \u00b7 \u00b7 \u00b7 X 1 x 0 = X t:1 x 0 .(9)\nWe next show that, when the partition graph is B-connected, Spinner converges exponentially-fast to an even balancing.\nDefinition 1 (B-connectivity). A sequence of graphs {P t>0 } is B-connected if, for all t > 0, each union graph P Bt:B(t+1)\u22121 = (L, Q Bt \u222a Q Bt+1 \u222a \u00b7 \u00b7 \u00b7 \u222a Q B(t+1)\u22121 ) is strongly connected.\nSimply put, B-connectivity asserts that each partition exchanges load with every other partition periodically. We can now state our first result:\nProposition 1. If the partition graph {P t>0 } is B-connected,\none can always find constants \u00b5 \u2208 (0, 1) and q \u2208 R + , for which Spinner converges exponentially\nx t \u2212 x \u221e / x 0 \u221e \u2264 q\u00b5 t\u22121 to an even balancing x = [C C . . . C] , with C = |E|/k. Proposition 2 asserts that, when {P t>0 } is not B-connected,\nSpinner also converges-though we cannot state anything about the quality of the achieved partitioning.\n\n\nProposition 2. Spinner converges in bounded time.\n\nDue to lack of space, we refer to [2] for the derivation of the proofs of Propositions 1 and 2.\n\nFrom a practical perspective, even if limit cycles are avoided often it is not worth spending compute cycles to achieve full convergence. Typically, most of the improvement in the partitioning quality occurs during the first iterations, and the improvement per iteration drops quickly after that. We validate this with real graphs in Section V-A.\n\nIn LPA convergence is detected by the absence of vertices changing label, referred to as the halting condition. A number of strategies have been proposed to guarantee the halting of LPA in synchronous systems (such as Pregel). These strategies are either based on heuristics for tie breaking and halting, or on the order in which vertices are updated [33]. However, the heuristics are tailored to LPA's score function, which maximizes only locality. Instead, our score function does not maximize only locality, but also partition balance, rendering these strategies unsuitable. Hence, in Spinner we use a heuristic that tracks how the quality of partitioning improves across the entire graph.\n\nAt a given iteration, we define the score of the partitioning for graph G as the sum of the current scores of each vertex\nscore(G) = \u2211 v\u2208G score (v, \u03b1(l v ))(10)\nAs vertices try to optimize their individual scores by making local decisions, this aggregate score gradually improves as well. We consider a partitioning to be in a steady state, when the score of the graph is not improved more than a given threshold \u03b5 for more than w consecutive iterations. The algorithm halts when a steady state is reached. Through \u03b5 we can control the trade-off between the cost of executing the algorithm for more iterations and the improvement obtained by the score function. At the same time, with w it is possible to impose a stricter requirement on stability; with a larger w, we require more iterations with no significant improvement until we accept to halt. Note that this condition, commonly used by iterative hillclimbing optimization algorithms, does not guarantee halting at the optimal solution. However, as we present in Section III-D, Spinner periodically restarts the partitioning algorithm to adapt to changes to the graph or the compute environment. This natural need to adapt gives Spinner the opportunity to jump out of local optima.\n\n\nD. Incremental Label Propagation\n\nAs edges and vertices are added and removed over time, the computed partitioning becomes outdated, degrading the global score. Upon such changes, we want to update the partitioning to reflect the new topology without repartitioning from scratch. Ideally, since the graph changes affect local areas of the graph, we want to update the latest stable partitioning only in the portions that are affected by the graph changes.\n\nDue to its local and iterative nature, LPA lends itself to incremental computation. Intuitively, the effect of the graph changes is to \"push\" the current steady state away from the local optimum it converged to, towards a state with lower global score. To handle this change, we restart the iterations, letting the algorithm search for a new local optimum. In the event we have new vertices in the graph, we initially assign them to the least loaded partition, to ensure we do not violate the balance constraint. Subsequently, vertices evaluate their new local score, possibly deciding to migrate to another partition. The algorithm continues as described previously.\n\nUpon graph changes, there are two possible strategies in restarting vertex migration. The first strategy restarts migrations only for the vertices affected by the graph changes, for instance, vertices adjacent to a newly added edge. This strategy minimizes the amount of computation to adapt. The second strategy, allows every vertex in the graph, even if it is not affected by a change, to participate in vertex migration process. This latter strategy incurs higher computation overhead, but increases the likelihood that the algorithm jumps out of a local optimum. We have found that this computational overhead does not affect the total running time of the algorithm significantly and, therefore, opt for this latter strategy favoring better partitioning quality.\n\nNote that the number of iterations required to converge to a new steady state depends on the number of graph changes and the last state. Clearly, not every graph change will have the same effect. Sometimes, no iteration may be necessary at all. In fact, certain changes may not affect any vertex to the point that the score of a different label is higher than the current one. As no migration is caused, the state remains stable. On the other hand, other changes may cause more migrations due to the disruption of certain weak local equilibriums. In this sense, the algorithm behaves as a hill-climbing optimization algorithm. As we will show in Section V-C, even upon a large number of changes, Spinner saves a large fraction of the time of a re-partitioning from scratch.\n\n\nE. Elastic Label Propagation\n\nDuring the lifecycle of a graph, a system may need to redistribute the graph across the compute cluster. For instance, physical machines may be characterized by a maximum capacity in the number of vertices or edges they can hold due to resources limitations, such as the available main memory. As the graph grows and the load of the partitions reaches this maximum capacity, the system may need to scale up with the addition of more machines, requiring to re-distribute the graph. Alternatively, we may perform such re-distribution just to increase the degree of parallelization and improve performance. Conversely, if the graph shrinks or the number of available machines decreases, we need to remove a number of partitions and, again, redistribute the graph.\n\nIn these scenarios, we want the algorithm to adapt to the new number of partitions without repartitioning the graph from scratch. Spinner achieves this in the following way. Upon a change in the number of partition, Spinner lets each vertex decide independently whether it should migrate using a probabilistic approach. In the case we want to add n new partitions to the system, each vertex picks one of the new partitions randomly and migrates to it with a probability p such that\np = n k + n(11)\nIn the case we want to remove n partitions, all the vertices assigned to those partitions migrate to one of the remaining ones. Each vertex chooses uniformly at random the partition to migrate to. In both cases, after the vertices have migrated, we restart the algorithm to adapt the partitioning to the new assignments. As in the case of incremental LPA, the number of iterations required to converge to a new steady state depends on factors, such as the graph size, and the number of partitions added or removed.\n\nBy introducing these random migrations upon a change, this strategy clearly disrupts the current partitioning, degrading the global score. However, it has a number of interesting characteristics. First, it remains a decentralized and lightweight heuristic as each vertex makes a decision to migrate independently. Second, by choosing randomly, the partitions remain fairly balanced even after a change in the number of partitions. Third, this random change from the current state of the optimization problem may allow the solution to jump out of a local optimum.\n\nNote that, if the number n of new partitions is large, the cost of adapting the partitioning may be quite large, due to a large number of random migrations. However, in practice, the frequency with which partitions are added or removed is low compared, for example, to the number of times a partitioning ... is updated due to changes in the graph itself. Furthermore, although vertices are shuffled around, the locality of those vertices that do not migrate is not completely destroyed, such as if the partitioning was performed from scratch. The adaptation of the partitioning to the new number of partitions will naturally take advantage of the late state of the partitioning.\n\n\nIV. PREGEL IMPLEMENTATION\n\nWe implemented Spinner in Apache Giraph [1] and open sourced the code 2 . Giraph is an open source project with a Java implementation of the Pregel model. Giraph is a batch graph processing system that runs on Hadoop [4], and can run computations on graphs with hundreds of billions of edges across clusters consisting of commodity machines.\n\nIn this section, we describe the implementation details of Spinner. We show how we extend the LPA formulation to leverage the synchronous vertex-centric programming model of a system like Giraph. We implemented a distributed algorithm with no centralized component that scales and, at the same time, achieves good partitioning quality.\n\n\nA. Vertex-centric partitioning\n\nAt a high-level, the algorithm is organized in three phases, depicted in Figure 2. In the first phase, since LPA assumes an undirected graph, if directed, Spinner converts it to a weighted undirected form as described in Section III-A. In the second phase, Spinner initializes the partition of each vertex depending on whether it partitions the graph from scratch or it is adapting an existing partitioning.\n\nSubsequently, the third phase that implements the main LPA iterative migration process starts. In this phase, Spinner iteratively executes two different steps. In the first step, each vertex computes the label that maximizes its local score function. In the second step, vertices decide whether to migrate by changing label or defer migration. At the end of each iteration Spinner evaluates the halting condition to decide whether to continue or stop computation.\n\nWe implement each of these phases as a series of Giraph supersteps. In the following subsections, we describe each phase in detail.\n\n\n1) Graph conversion and initialization:\n\nWe implement the first phase, the graph conversion, as two Giraph supersteps. Note that the Giraph data model is a distributed directed graph, where every vertex is aware of its outgoing edges but not of the incoming ones. For this reason, in the first superstep, each vertex sends its ID as a message to its neighbors. We call this step NeighborPropagation.\n\nDuring the second superstep, a vertex receives a message from every other vertex that has an edge to it. For each received message, a vertex checks whether an outgoing edge towards the other endpoint is already present. If this is the case, the vertex sets the weight of the associated edge to 2. Otherwise, it creates an edge pointing to the other vertex with a weight of 1. We call this step NeighborDiscovery.\n\nAfter this, Spinner executes the second phase, assigning partitions to each vertex. We call this step Initialization, and it corresponds to a single Giraph superstep. In the case Spinner partitions the graph from scratch, each vertex chooses a random partition. We will consider the case of adapting a partitioning in following sections. At this point, the LPA computation starts on the undirected graph.\n\n2) Local computation of labels: The vertex-centric programming model of Pregel lends itself to the implementation of LPA. During an LPA iteration, each vertex computes the label that maximizes its local score based on the load of each partition and the labels of its neighbors. Each vertex stores the label of a neighbor in the value of the edge that connects them. When a vertex changes label, it informs its neighbors of the new label through a message. Upon reception of the message, neighboring vertices update the corresponding edge value with the new label.\n\nWe implement a single LPA iteration as two successive Giraph supersteps that we call ComputeScores and ComputeMigrations. In the first step, the ComputeScores, a vertex finds the label that maximizes its score. In more detail, during this step each vertex performs the following operations: (i) it iterates over the messages, if any, and updates the edge values with the new partitions of each neighbors, (ii) it iterates over its edges and computes the frequency of each label across its neighborhood, (iii) it computes the label the maximizes its local score, (iv) if a label with a higher score than the current one is found, the vertex is flagged as candidate to change label in the next step.\n\n3) Decentralized migration decisions: Implementing our algorithm in a synchronous model introduces additional complexity. If we let every candidate vertex change label to maximize its local score during the ComputeScores step, we could obtain a partition that is unbalanced and violates the maximum capacities restriction. Intuitively, imagine that at a given time a partition was less loaded than the others. This partition could be potentially attractive to many vertices as the penalty function would favor that partition. As each vertex computes its score independently based on the partition loads computed at the beginning of the iteration, many vertices could choose independently that same partition label. To avoid this condition, we introduce an additional step that we call Compute Migrations, that serves the purpose of maintaining balance.\n\nTo avoid exceeding partition capacities, vertices would need to coordinate after they have decided the label that maximizes their score during the ComputeScores step. However, as we aim for a decentralized and lightweight solution, we opt for a probabilistic approach: a candidate vertex changes to a label with a probability that depends (i) on the remaining capacity of the corresponding partition and (ii) the total number of vertices that are candidates to change to the specific label.\n\nMore specifically, suppose that at iteration i partition l has a remaining capacity r(l) such that\nr(l) = C \u2212 b(l)(12)\nSuppose that M(l) is the set of candidate vertices that want to change to label l, which is determined during the Com-puteScores step of the iteration. We define the load of M(l) as\nm(l) = \u2211 v\u2208M(l) deg(v)(13)\nThis is the total load in edges that vertices in M(l) would carry to partition l if they all migrated. Since m(l) might be higher than the remaining capacity, in the second step of the iteration, we execute each candidate vertex that wants to change label, and we only let it change with a probability p such that\np = r(l) m(l)(14)\nUpon change, each vertex updates the capacities of the current partition and the new partition, and it updates the global score through the associated counter. It also sends a message to all its neighbors, with its new label. At this point, after all vertices have changed label, the halting condition can be evaluated based on the global score. This strategy has the advantage of requiring neither centralized nor direct coordination between vertices. Vertices can independently decide to change label or retry in the next iteration based on local information. Moreover, it is lightweight, as probabilities can be computed on each worker at the beginning of the step. Because this is a probabilistic approach, it is possible that the load of a partition exceeds the remaining capacity. Nevertheless, the probability is bounded and decreases exponentially with the number of migrating vertices and superexponentially with the inverse of the maximum degree.\n\nProposition 3. The probability that at iteration i + 1 the load b i+1 (l) exceeds the capacity by a factor of \u03b5 r i (l) is\nPr(b i+1 (l) \u2265 C + \u03b5 r i (l)) \u2264 e \u22122 |M(l)| \u03a6(\u03b5) ,(15)\nwhere \u03a6(\u03b5) = \u03b5 r i (l) \u2206\u2212\u03b4 2 and \u03b4 , \u2206 is the minimum and maximum degree of the vertices in M(l), respectively.\n\nDue to lack of space, we refer to [2] for the derivation of the proof.\n\nWe can conclude that with high probability at each iteration Spinner does not violate the partition capacity. To give an example, consider that |M(l)| = 200 vertices with minimum and maximum degree \u03b4 = 1 and \u2206 = 500, respectively, want to migrate to partition l. The probability that, after the migration, the load b i+1 (l) exceeds 1.2 r i (l) + b i (l) = C + 0.2 r i (l) is smaller than 0.2, where the probability that it exceeds C + 0.4 r i (l) is smaller than 0.0016. Note that, being a upper bound, this is a pessimistic estimate. In Section V-A1 we show experimentally that unbalance is in practice much lower.\n\n\n4) Asynchronous per-worker computation:\n\nAlthough the introduction of the ComputeMigrations step helps maintain balance by preventing excessive vertices from acquiring the same label, it depends on synchronous updates of the partition loads. The probabilistic migration decision described in IV-A3 is based on the partition loads calculated during the previous superstep, and ignores any migrations decision performed during the currently executed superstep. Consequently, a less loaded partition will be attractive to many vertices, but only a few of them will be allowed to migrate to it, delaying the migration decision of the remaining ones until the next supersteps.\n\nIn general, the order in which vertices update their label impacts convergence speed. While asynchronous graph processing systems allow more flexibility in scheduling of vertex updates, the synchronous nature of the Pregel model does not allow any control on the order of vertex computation.\n\nHowever, Spinner leverages features of the Giraph API to emulate an asynchronous computation without the need of a purely asynchronous model. Specifically, Spinner treats each iteration computation within the same physical machine worker of a cluster as an asynchronous computation. During an iteration, each worker maintains local values for the partition loads that are shared across all vertices in the same worker. When a vertex is evaluated in the ComputeScores step and it becomes a candidate to change to a label, it updates the local values of the load of the corresponding partition asynchronously. As an effect, subsequent vertex computations in the same iteration and on the same worker use more up-to-date partition load information. Note that every vertex still has to be evaluated in the ComputeMigrations step for consistency among workers.\n\nThis approach overall speeds up convergence, and does not hurt the scalability properties of the Pregel model. In fact, the Spinner implementation leverages a feature supported by the Giraph programming interface that allows data sharing and computations on a per-worker basis. The information shared within the same worker is a set of counters for each partition and therefore does not add to the memory overhead. Furthermore, it still does not require any coordination across workers.\n\n\n5) Management of partition loads and counters:\n\nSpinner relies on a number of counters to execute the partitioning: the global score, the partition loads b(l), and the migration counters m(l). The Pregel model supports global computation  \n\n\nB. Incremental and elastic repartitioning\n\nTo support incremental and elastic repartitioning, Spinner restarts the computation from the previous state of the partitioning. Regarding the implementation, the difference lies in the execution of the second phase of the algorithm, when vertices are labeled. In the case a graph is repartitioned due to changes to the graph, the vertices that have already been partitioned are loaded and labeled as previously. Any new vertices are labeled randomly. In the case a graph is repartitioned due to changes to the number of partitions, the vertices are loaded and labeled as previously, and they are re-labeled to a new partition only according to the approach described in Section III-E.\n\n\nV. EVALUATION\n\nIn this section, we assess Spinner's ability to produce good partitions on large graphs. Specifically, we evaluate the partitioning quality in terms of locality and balance and use Spinner to partition billion-vertex graphs. Furthermore, we evaluate Spinner's ability to support frequent adaptation in dynamic cloud environments. Here, we measure the efficiency of Spinner in adapting to changes in the underlying graph and compute resources. Furthermore, we utilize the partitioning computed by Spinner with the Giraph graph processing engine and measure the impact on the performance of real analytical applications.\n\nFor our experiments, we use a variety of synthetic as well as real-world large-scale graphs. Table II summarizes the real datasets we used. We run our evaluation on different Hadoop clusters. We describe the details of each setup in the following sections.  \n\n\nA. Partitioning quality\n\nIn our first set of experiments, we measure the quality of the partitions that Spinner can compute in terms of locality and balance. We measure locality with the ratio of local edges \u03c6 and balance with the maximum normalized load \u03c1, defined as\n\u03c6 = # local edges |E| , \u03c1 = maximum load |E| k(16)\nwhere k is the number of partitions, # local edges represents the number of edges that connect two vertices assigned to the same partition, and maximum load represents the number of edges assigned to the most loaded partition. The maximum normalized load metric is typically used to measure unbalance and represents the percentage-wise difference of the most loaded partition from a perfectly balanced partition. First, we observe that the ability to maintain local edges depends on the number of partitions. Intuitively, the more partitions, the harder it is to maintain locality. In this experiment, we vary the number of partitions and measure locality and balance for different graphs. For this and the remaining experiments, we set the algorithm parameters as follows: additional capacity c = 1.05, and halting thresholds \u03b5 = 0.001 and w = 5. We run this experiment on a Hadoop cluster of 92 machines with 64GB RAM and 8 compute cores each.\n\nIn Figure 3(a), we show that Spinner is able to produce partitions with high locality for all the graphs also for large numbers of partitions. With respect to balance, Spinner calculates fairly balanced partitions. In Table III  the maximum normalized load for each graph. For example, a \u03c1 value of 1.059 for the Twitter graphs means that no partition exceeds the ideal size by more than 5.9% edges.\n\nTo give perspective on the quality of the partitions that Spinner computes, Figure 3(b) shows the improvement in the percentage of local edges compared to hash partitioning. We perform this comparison for the same set of graphs. Notice that for 512 partitions Spinner increases locality by up to 250 times.\n\nIn Table I, we compare Spinner with state-of-the-art approaches. Recall that our primary goal for Spinner is to design a scalable algorithm for the Pregel model that is practical in maintaining the resulting partitioning, and that is comparable to the state-of-the-art in terms of locality and balance. Indeed, Spinner computes partitions with locality that is within 2-12% of the best approach, typically Metis, and balance that is within 1-3% of the best approach. In cases Spinner performs slightly worse than Fennel with respect to \u03c6 , it performs better with respect to \u03c1. These two metrics are connected as the most loaded partition will be the result of migrations to increase locality.\n\nTo describe in more detail the behavior of our algorithm, in Figure 4 we show the evolution of the different metrics during the partitioning of the Twitter (left) and the Yahoo!  Fig. 5. Impact of c on the partitioning. Figure (a) shows the relationship between c and \u03c1. Figure (b) shows the relationship between c and speed of convergence.\n\n(right) graphs. The Twitter graph is known for the existence of high-degree hubs [10]. Due to these hubs, the Twitter graph can produce highly unbalanced partitions when partitioned with random partitioning. We will show in Section V-F how unbalance affects application performance, and in particular load balancing.\n\nAs Figure 4(a) shows, the initial maximum normalized load obtained with random partitioning is high (\u03c1 = 1.67), as expected. However, by applying our approach, the partitioning is quickly balanced (\u03c1 = 1.05), while the ratio of local edges increases steadily. Looking at the shape of the score(G) curve, notice that initially the global score is boosted precisely by the increased balance, while after balance is reached, around iteration 20, it increases following the trend of \u03c6 . Note that we let the algorithm run for 115 iterations ignoring the halting condition, which otherwise would have halted the partitioning at iteration 41, as shown by the vertical black line.\n\nIn the case of the Yahoo! graph, the partitioning starts out more balanced than Twitter. The most notable difference is that the algorithm converges to a good partitioning with 73% local edges and a \u03c1 of 1.10 after only 42 iterations. A single iteration on the 1.4B-vertex Yahoo! graph takes on average 200 seconds on an AWS Hadoop cluster consisting of 115 m2.4xlarge instances, totaling 140 minutes for the entire execution.\n\n1) Impact of additional capacity on balance and convergence: Here, we investigate the effect of parameter c on balance and convergence speed. Recall that Spinner uses parameter c to control the maximum unbalance. Additionally, parameter c affects convergence speed; larger values of c should increase convergence speed as more migrations are allowed during each iteration.\n\nIn Section IV-A3 we showed that with high probability Spinner respects partition capacities, that is, maximum load \u2264 C. From the definitions of \u03c1 = maximum load |E| k and C = c \u00b7 |E| k , we derive that with high probability \u03c1 \u2264 c. Therefore, we can use parameter c to bound the unbalance of partitioning. For instance, if we allow partitions to store 20% more edges than the ideal value, Spinner should produce a partitioning with a maximum normalized load of up to 1.2.\n\nTo investigate these hypotheses experimentally, we vary the value of c and measure the number of iterations needed to converge as well as the final value of \u03c1. We partition the LiveJournal graph into 8, 16, 32, and 64 partitions, setting c to 1.02, 1.05, 1.10, and 1.20. We repeat each experiment 10 times and the average for each value of c. As expected, Figure  5(a) shows that indeed on average \u03c1 \u2264 c. Moreover, the error bars show the minimum and maximum value of \u03c1 across the runs. We can notice that in some cases \u03c1 is much smaller than c, and when it is exceeded, it is exceeded only by a small degree. Figure 5(b) shows the relationship between c and the number of iterations needed to converge. Indeed, a larger value of c speeds up convergence. These results show how c can be used to control the maximum normalized load of the partitioning. It is up to the user to decide the trade-off between balance and speed of convergence.\n\n\nB. Scalability\n\nIn these experiments we show that the algorithm affords a scalable implementation on modern large-scale graph processing frameworks such as Giraph. To this end, we apply our algorithm on synthetic graphs constructed with the Watts-Strogatz model [31]. In all these experiments we set the parameters of the algorithm as described in Section V-A. Using synthetic graphs for these experiments allows us to carefully control the number of vertices and edges, still working with a graph that resembles a real-world social network or webgraph characterized by \"small-world\" properties. On such a graph, the number of iterations required to partition the graph does not depend only on the number of vertices, edges and partitions, but also on its topology, and in particular on graph properties such as clustering coefficient, diameter etc.\n\nFor this reason, to validate the scalability of the algorithm we focus on the runtime of the first iteration, notably the iteration where all vertices receive notifications from all their neighbors, making it the most deterministic and expensive iteration. Precisely, we compute the runtime of an iteration as the sum of the time needed to compute the ComputeScores and the following ComputeMigrations supersteps. This approach allows us to factor out the runtime of algorithm as a function the number of vertices and edges. Figure 6 presents the results of the experiments, executed on a AWS Hadoop cluster consisting of 116 m2.4xlarge machines. In the first experiment, presented in Figure 6(a), we focus on the scalability of the algorithm as a function of the number of vertices and edges in the graph. For this, we fix the number of outgoing edges per vertex to 40. We connect the vertices following a ring lattice topology, and re-wire 30% of the edges randomly as by the function of the beta (0.3) parameter of the Watts-Strogatz model. We execute each experiment with 115 workers, for an exponentially increasing number of vertices, precisely from 2 to 1024 million vertices (or one billion vertices) and we divide each graph in 64 partitions. The results, presented in a loglog plot, show a linear trend with respect to the size of the graph. Note that for the first data points the size of the graph is too small for such a large cluster, and we are actually measuring the overhead of Giraph.\n\nIn the second experiment, presented in Figure 6(b), we focus on the scalability of the algorithm as a function of the number  of workers. Here, we fix the number of vertices to 1 billion, still constructed as described above, but we vary the number of workers linearly from 15 to 115 with steps of 15 workers (except for the last step where we add 10 workers). The drop from 111 to 15 seconds with 7.6 times more workers represents a speedup of 7.6.\n\nIn the third experiment, presented in Figure 6(b), we focus on the scalability of the algorithm as a function of the number of partitions. Again, we use 115 workers and we fix the number of vertices to 1 billion and construct the graph as described above. This time, we increase the number of partitions exponentially from 2 to 512. Also here, the loglog plot shows a near-linear trend, as the complexity of the heuristic executed by each vertex is proportional to the number of partitions k, and so is cost of maintaining partition loads and counters through the sharded aggregators provided by Giraph.\n\n\nC. Partitioning dynamic graphs\n\nDue to the dynamic nature of graphs, the quality of an initial partitioning degrades over time. Re-partitioning from scratch can be an expensive task if performed frequently and with potentially limited resources. In this section, we show that our algorithm minimizes the cost of adapting the partitioning to the changes, making the maintenance of a well-partitioned graph an affordable task in terms of time and compute resources required.\n\nSpecifically, we measure the savings in processing time and number of messages exchanged (i.e. load imposed on the Adapting to dynamic graph changes. We vary the percentage of new edges in the graph and compare our adaptive re-partitioning approach and re-partitioning from scratch with respect to (a) the savings in processing time and messages exchanged, and (b) the fraction of vertices that have to move upon re-partitioning. network) relative to the approach of re-partitioning the graph from scratch. We track how these metrics vary as a function of the degree of change in the graph. Intuitively, larger graph changes require more time to adapt to an optimal partitioning.\n\nFor this experiment, we take a snapshot of the Tuenti [5] social graph that consists of approximately 10 million vertices and 530 million edges, and perform an initial partitioning. Subsequently, we add a varying number of edges that correspond to actual new friendships and measure the above metrics. We perform this experiment on an AWS Hadoop cluster consisting of 10 m2.2xlarge instances. Figure 7(a) shows that for changes up to 0.5%, our approach saves up to 86% of the processing time and, by reducing vertex migrations, up to 92% of the network traffic. Even for large graph changes, the algorithm still saves up to 80% of the processing time. Note that in every case our approach converges to a balanced partitioning, with a maximum normalized load of approximately 1.047, with 67%-69% local edges, similar to a re-partitioning from scratch.\n\n\nD. Partitioning stability\n\nAdapting the partitioning helps maintain good locality as the graph changes, but may also require the graph management system (e.g. a graph DB) to move vertices and their associated state (e.g. user profiles in a social network) across partitions, potentially impacting performance. Aside from efficiency, the value of an adaptive algorithm lies also in maintaining stable partitions, that is, requiring only few vertices to move to new partitions upon graph changes. Here, we show that our approach achieves this goal.\n\nWe quantify the stability of the algorithm with a metric we call partitioning difference. The partitioning difference between two partitions is the percentage of vertices that belong to different partitions across two partitionings. This number represents the fraction of vertices that have to move to new partitions. Note that this metric is not the same as the total number of migrations that occur during the execution of the algorithm which only regards cost of the execution of the algorithm per se.\n\nIn Figure 7(b), we measure the resulting partitioning difference when adapting and when re-partitioning from scratch as a function of the percentage of new edges. As expected, the percentage of vertices that have to move increases as we make more changes to the graph. However, our adaptive approach requires only 8%-11% of the vertices to move compared to a 95%-98% when re-partitioning, minimizing the impact.\n\n\nE. Adapting to resource changes\n\nHere, we show that Spinner can efficiently adapt the partitioning when resource changes force a change in the number of partitions. Initially, we partition the Tuenti graph snapshot described in Section V-C into 32 partitions. Subsequently we add a varying number of partitions and either re-partition the graph from scratch or adapt the partitioning with Spinner. Figure 8(a) shows the savings in processing time and number of messages exchanged as a function of the number of new partitions. As expected, a larger number of new partitions requires more work to converge to a good partitioning. When increasing the capacity of the system by only 1 partition, Spinner adapts the partitions 74% faster relative to a repartitioning.\n\nSimilarly to graph changes, a change in the capacity of the compute system may result in shuffling the graph. In Figure 8(b), we see that a change in the number of partitions can impact partitioning stability more than a large change in the input graph (Figure 7(b)). Still, when adding only 1 partition Spinner forces less than 17% of the vertices to shuffle compared to a 96% when re-partitioning from scratch. The high percentage when re-partitioning from scratch is expected due to the randomized nature of our algorithm. Note, though, that even a deterministic algorithm, like modulo hash partitioning, may suffer from the same problem when the number of partitions changes.\n\n\nF. Impact on application performance\n\nThe partitioning computed by Spinner can be used by different graph management systems, to improve their performance. In this section, we use Spinner to optimize the execution of the Giraph graph processing system itself. After partitioning the input graph with Spinner, we instruct Giraph to use the computed partitioning and run real analytical applications on top. We then measure the impact on performance compared to using standard hash partitioning.\n\nWe use our computed partitioning in Giraph as follows. The output of Spinner is a list of pairs (v i , l j ) that assigns each vertex to a partition. We use this output to ensure that Giraph places vertices assigned to the same partition on the same physical machine worker. By default, when Giraph loads a graph for computation, it assigns vertices to workers according to hash partitioning, i.e. vertex v i is assigned to one of the k workers according to h(v i ) mod k. We define a new vertex id type v i = (v i , l j ) that encapsulates the computed partition as well. We then plug a hash function that uses only the l j field of the pair, ensuring that vertices with the same label are placed on the same worker.\n\nFirst, we assess the impact of partitioning balance on the actual load balance of the Giraph workers. In a synchronous processing engine like Giraph, an unbalanced partitioning results in the less loaded workers idling at the synchronization barrier. To validate this hypothesis, we partition the Twitter graph across 256 partitions and run 20 iterations of the PageRank algorithm on a cluster with 256 workers using (i) standard hash partitioning (random), and (ii) the partitioning computed by Spinner. For each run, we measure the time to compute a superstep by all the workers (Mean), the fastest (Min) and the slowest (Max), and compute the standard deviation across the 20 iterations.  TABLE IV.  IMPACT OF PARTITIONING BALANCE ON WORKER LOAD.  THE TABLE SHOWS THE TIME SPENT BY WORKERS TO  Impact on application performance. We measured the runtime improvement between hash partitioning and Spinner. We evaluated three different applications, Single Source Shortest Paths/BFS (SP), PageRank (PR), and Weakly Connected Components (CC). The LJ graph was evaluated across 16 partitions, TU across 32 partitions and TW across 64. compute a superstep can be imputed to the diminished number of cut edges, the decreased idling time is an effect of a more even load spread across the workers.\n\nSecond, we measure the impact of the partitioning on processing time. We partitioned three graphs with Spinner and hash partitioning, and we compared the time to run three representative algorithms commonly used inside graph analytical pipelines. Shortest Paths, computed through BFS is commonly used to study the connectivity of the vertices and centrality, PageRank is commonly used at the core of ranking graph algorithms, and Connected Components, as a general approach to finding communities. We present the results in Figure 9.\n\nNotice that using the partitionings computed by Spinner we significantly improve the performance across all graphs and applications. In the case of the Twitter graph, which is denser and harder to partition, the improvement ranges from 25% for SP to 35% for PR. In the case of LiveJournal and Tuenti, the running time decreases by up to 50%.\n\n\nVI. RELATED WORK\n\nGraph partitioning that has been studied in various domains. In this section, we present the related work on k-way balanced graph partitioning.\n\nMETIS [12] is an offline partitioning algorithm and is considered the golden standard against new approaches. It is known to produce partitions with very good locality and balance. However, it is not suitable for very large graphs, due to high computational and space complexity, and the need to repartition graphs from scratch every time a change is introduced in the graph or the number of partitions.\n\nStreaming algorithms [24], [28], [19] avoid this complexity through lightweight heuristics that assign vertices to partitions in only one pass over the graph. However, parallelizing these algorithms requires every participating machine to maintain a consistent view of the partitioning assignments of the entire graph. This requires distribution of the assignments across the cluster and coordination among the machines. Implementing this mechanism in a scalable and efficient manner is challenging. To the best of our knowledge, none of these approaches have been implemented on top of scalable data processing models.\n\nThe closest approaches to Spinner are [29], [30]. The former applies LPA to the MapReduce model, by attempting to improve locality through iterative vertex migrations across partitions. However, to guarantee balanced partitions, it executes a centralized linear solver between any two iterations. The complexity of lineary system is quadratic to the number of partitions and proportional to the size of the graph, making it expensive for large graphs. Moreover, MapReduce is known to be inefficient for iterative computations. The approach in [30] computes a k-way vertex-based balanced partitioning. It uses LPA to coarsen the input graph and then applies Metis to the coarsened graph. At the end, it projects the Metis partitioning back to the original graph. While the algorithm is scalable, we have found that for large number of partitions and skewed graphs, the locality it produces is lower than Spinner due to the coarsening. We also found that the approach is very sensitive to its two parameters for whom no intuition is available (differently from Spinner that requires only one parameter for which we provide a rationale). Further, the approach is designed to run on the Trinity engine and is not suitable for implementation on a synchronous model such as Pregel. None of the two solutions investigates how to adapt a partitioning upon changes in the graph or the compute environment.\n\nMizan [14] views the problem of dynamically adapting the graph partitioning from a different perspective. It monitors runtime performance of the graph processing system, for instance, to find hotspots in specific machines, and migrates vertices across workers to balance the load during the computation of analytical applications. Their solution is specific to a graph processing system and orthogonal to the problem of k-way balanced partitions. SPAR [21] and Sedge [34] also consider the problem of adapting graph distribution. However, they focus on minimizing latency for simple graph queries, and address the problem through replication of the vertices across machines.\n\n\nVII. CONCLUSIONS\n\nWe presented Spinner, a scalable and adaptive graph partitioning algorithm built on the Pregel abstraction. By sacrificing strict guarantees on balance, Spinner is practical for large-scale graph management systems. Through an extensive evaluation on a variety of graphs, we showed that Spinner computes partitions with locality and balance comparable to the stateof-the-art, but can do so at a scale of at least billion-vertex graphs. At the same time, its support for dynamic changes makes it more suitable for integrating into real graph systems. These properties makes Spinner possible to use as a generic replacement of the de-facto standard, hash partitioning, in cloud systems. Toward this, our scalable, open source implementation on Giraph makes Spinner easy to use on any commodity cluster.\n\n\nBIOGRAPHIES\n\nClaudio Martella is PhD candidate at the Computer Systems group of VU University Amsterdam, where he researches complex networks. In particular, he is interested in modelling problems with spatiotemporal networks and investigating platforms for large-scale graph processing. He is also an active contributor to Apache Giraph and various projects in the Hadoop ecosystem.\n\nDionysios Logothetis is an Associate Researcher with the Telefonica Research lab in Barcelona, Spain. His research interests lie in the areas of large scale data management with a focus on graph mining, cloud computing and distributed systems. He holds a PhD in Computer Science from the University of California, San Diego and a Diploma in Electrical and Computer Engineering from the National Technical University of Athens.\n\nAndreas Loukas attained a diploma in Computer Science and Engineering from Patras University, in Greece. He also pursued a PhD with the Embedded Software group at Delft University of Technology. There he gained engineering experience in working with real wireless systems, but also realized his appreciation for rigorousness. Currently, he is doing a postdoc on the same group focusing on distributed signal processing on graphs. His research interests include graph analysis and distributed algorithms. Proof: Even though 0 \u2264 [X t ] i j \u2264 1 is time-dependent and generally unknown, it has the following properties:\n\n\u2022 X t is 1-local: [X t ] i j > 0 iff (l i , l j ) \u2208 Q t and [X t ] ii > 0 for all i \u2022 X t is row-stochastic: \u2211 k j=1 [X t ] i j = 1 for all i \u2022 X t is uniformly bounded: if [X t ] i j > 0 then [X t ] i j \u2265 1/n In general, the above properties do not guarantee ergodicity. Nevertheless, we can obtain stronger results if the partition graph is B-connected. From [27, Lemma 5.2.1] (see also [26,Theorem 2.4]), X t:1 is ergodic and x \u221e = lim t\u2192\u221e X t:1 x 0 = 1\u03c0 x 0 , where 1 is the one vector and \u03c0 is a stochastic vector. Furthermore, constants \u00b5 \u2208 (0, 1) and q \u2208 R + exist for which\nx t \u2212 x \u221e \u221e x 0 \u221e \u2264 X t:1 \u2212 1\u03c0 \u221e \u2264 q\u00b5 t\u22121 .\nFurthermore, from ergodicity, lim t\u2192\u221e X t:1 is a rank-one matrix and x \u221e (l i ) = x \u221e (l j ) for all partitions l i , l j and by construction the total load is always equal to the number of graph edges. It follows that, for all l, x \u221e (l) = |E| /k = C = x (l).\n\n\nProposition 2. Spinner converges in bounded time.\n\nProof: Convergence is proven by first splitting {P t>0 } according to Lemma 1 and then applying Proposition 1 for each of the resulting subgraphs. The time required until x t \u2212x \u221e / x 0 \u221e \u2264 \u03b5 is at most \u2264 log \u00b5 (\u03b5/q)+1+T , which is equal to the splitting time T added to the time for exponential convergence.\n\nLemma 1. Labels l \u2208 L can be always split into p subsets L 1 , L 2 , . . . , L p having the following properties: 1) Subsets L i are non-empty, disjoint, and cover L. 2) Any induced subgraph {P t>0 (L i )}, i.e., the subgraph of {P t>0 } which includes only nodes in L i and all edges with both endpoints in L i , is B-connected.\n\n\n3) A bounded time T exists after which {P t>T (L i )} and\n\n{P t>T (L j )} are disconnected \u2200i, j. In other words, no edge connects two subgraphs for t > T .\n\nProof: To begin with, observe that when {P t>0 } is Bconnected, the statement is obvious for L 1 = L and p = 1. Assume that B-connectivity does not hold and let T 1 be the -latest-time for which {P T 1 \u2265t>0 } is B-connected, under all possible bounded B. Notice that, by construction, a p 1 -split exists which satisfies the first and third property (each subset includes all labels that exchange load after T 1 ). If such a partitioning did not exist, then {P T 1 +1\u2265t>0 } must have been B-connected-a contradiction. Though this first splitting does not guarantee the second property, i. e., that {P t>0 (L i )} are B-connected, we can find the correct subsets by recursively re-splitting each subgraph in the same manner. This recursive re-splitting will always terminate because: (i) all subsets are non-empty and (ii) the trivial k-splitting L i = {l i } is always B-connected. Hence time T , chosen as the time of the last splitting, is bounded. Proposition 3. The probability that at iteration i + 1 the load b i+1 (l) exceeds the capacity by a factor of \u03b5 r i (l) is\nPr(b i+1 (l) \u2265 C + \u03b5 r i (l)) \u2264 e \u22122 |M(l)| \u03a6(\u03b5) ,(17)\nwhere \u03a6(\u03b5) = \u03b5 r i (l) \u2206\u2212\u03b4 2 and \u03b4 , \u2206 is the minimum and maximum degree of the vertices in M(l), respectively.\n\nProof: Let X v be a random variable which becomes 0 when vertex v does not migrate and deg(v) otherwise. The expected value of X v is\nE(X v ) = 0 \u00b7 (1 \u2212 p) + deg(v) p = deg(v) p.\nThe total load carried by the vertices that migrate is described by the random variable X = \u2211 v\u2208M(l) X v and has expected value\nE(X) = E \u2211 v\u2208M(l) X v = \u2211 v\u2208M(l) E(X v ) = p \u2211 v\u2208M(l) deg(v) = r(l).\nWe want to bound the probability that X is larger than r(l), that is, the number of edges that migrate to l exceeds the remaining capacity of l. Using Hoeffding's method, we have that for any t > 0,\nPr(X \u2212 E(X) \u2265 t) \u2264 exp \uf8eb \uf8ec \uf8ed\u2212 2|M(l)| 2 t 2 \u2211 v\u2208M(l) (\u2206 \u2212 \u03b4 ) 2 \uf8f6 \uf8f7 \uf8f8 = exp \u2212 2|M(l)|t 2 (\u2206 \u2212 \u03b4 ) 2 ,\nwhere \u03b4 and \u2206 are the minimum and maximum degree of the vertices in M(l), respectively. Setting t = \u03b5 E(X), we obtain the desired upper bound:\n\nPr(X \u2265 (1 + \u03b5)E(X)) = Pr(X + b(l) \u2265 C + \u03b5r(l)) \u2264 exp \u22122 |M(l)| \u03b5 r(l) \u2206 \u2212 \u03b4\n\nFig. 1 .\n1Conversion of a directed graph (left) to an undirected graph (right).\n\nFig. 2 .\n2Organization of the algorithm in multiple phases, each implemented by one or multiple steps (block). Each algorithm step is implemented as a Pregel superstep.\n\n\n. 3. (a) Partitioning locality on real graphs as a function of the number of partitions. X-axis is in log scale. (b) Improvement in the locality compared to hash partitioning. X-axis is in log scale.\n\n\nPartitioning of the Yahoo! graph.Fig. 4. Partitioning of (a) the Twitter graph across 256 partitions and (b) the Yahoo! web graph across 115 partitions. The figure shows the evolution of metrics \u03c6 , \u03c1, and score(G) across iterations.\n\n\nRuntime vs. k Fig. 6. Scalability of Spinner. (a) Runtime as a function of the number of vertices, (b) runtime as a function of the number of workers, (c) runtime as a function of the number of partitions.\n\n\nFig. 7. Adapting to dynamic graph changes. We vary the percentage of new edges in the graph and compare our adaptive re-partitioning approach and re-partitioning from scratch with respect to (a) the savings in processing time and messages exchanged, and (b) the fraction of vertices that have to move upon re-partitioning.\n\nFig. 8 .\n8Adapting to resource changes. We vary the number of new partitions and compare our adaptive approach and re-partitioning from scratch with respect to (a) the savings in processing time and messages exchanged, and (b) the fraction of vertices that have to move upon re-partitioning.\n\n\nFig. 9. Impact on application performance. We measured the runtime improvement between hash partitioning and Spinner. We evaluated three different applications, Single Source Shortest Paths/BFS (SP), PageRank (PR), and Weakly Connected Components (CC). The LJ graph was evaluated across 16 partitions, TU across 32 partitions and TW across 64.\n\nTABLE II .\nIIDESCRIPTION OF THE REAL-WORLD DATASETS USED FOR THE EVALUATION.of commutative and associative operations through aggrega-\ntors. During each superstep, vertices can aggregate values into \nnamed aggregators, and they can access the value aggregated \nduring the previous superstep. In Pregel, each aggregator is \ncomputed in parallel by each worker for the aggregations \nperformed by the assigned vertices, and a master worker \naggregates these values at the end of the superstep. Giraph \nimplements sharded aggregators, where the duty of the master \nworker for each aggregator is delegated to a different worker. \nThis architecture allows for scalability, through a fair distri-\nbution of load and parallel communication of partial aggrega-\ntions. To exploit this feature, Spinner implements each counter \nthrough a different aggregator, making the management of \ncounters scalable. \n\n\n\n\nOF-THE-ART APPROACHES. SPINNER OUTPERFORMS OR COMPARES TO THE STREAM-BASED APPROACHES, AND IS ONLY SLIGHTLY OUTPERFORMED BY SEQUENTIAL METIS. NOTICE THAT BECAUSE WANG ET AL. BALANCES ON THE NUMBER OF VERTICES, NOT EDGES, IT PRODUCES PARTITIONINGS WITH HIGH VALUES OF \u03c1 .Twitter k=2 \nTwitter k=4 \nTwitter k=8 \nTwitter k=16 \nTwitter k=32 \n\nApproach \n\u03c6 \n\u03c1 \n\u03c6 \n\u03c1 \n\u03c6 \n\u03c1 \n\u03c6 \n\u03c1 \n\u03c6 \n\u03c1 \n\nWang et al. [30] \n0.61 \n1.30 \n0.36 \n1.63 \n0.23 \n2.19 \n0.15 \n2.63 \n0.11 \n1.87 \nStanton et al. [24] \n0.66 \n1.04 \n0.45 \n1.07 \n0.34 \n1.10 \n0.24 \n1.13 \n0.20 \n1.15 \nFennel [28] \n0.93 \n1.10 \n0.71 \n1.10 \n0.52 \n1.10 \n0.41 \n1.10 \n0.33 \n1.10 \nMetis [12] \n0.88 \n1.02 \n0.76 \n1.03 \n0.64 \n1.03 \n0.46 \n1.03 \n0.37 \n1.03 \nSpinner \n0.85 \n1.05 \n0.69 \n1.02 \n0.51 \n1.05 \n0.39 \n1.04 \n0.31 \n1.04 \n\nTABLE I. \nCOMPARISON WITH STATE-\n\n\nwe show the average value ofTABLE III. PARTITIONING BALANCE. THE TABLE SHOWS THE AVERAGE \u03c1 FOR THE DIFFERENT GRAPHS.Graph \nLJ \nG+ \nTU \nTW \nFR \n\u03c1 \n1.053 \n1.042 \n1.052 \n1.059 \n1.047 \n\n\n\n\nTable IV shows the results. The results indicate that with hash partitioning the workers are idling on average for 31% of the superstep, while with Spinner for only 19%. While the shorter time needed toApproach \nMean \nMax. \nMin. \nRandom \n5.8s \u00b1 2.3s \n8.4s \u00b1 2.1s \n3.4s \u00b1 1.9s \nSpinner \n4.7s \u00b1 1.5s \n5.8s \u00b1 1.3s \n3.1s \u00b1 1.1s \n\n\n\n\nGeorgos Siganos is a Senior Scientist at Qatar Computing Research Institute working on next generation Graph Mining Architectures and Big Data Systems. Previous to this, he was a Research Scientist at Telefonica Research in Barcelona Spain focusing on Big Data and Peer to Peer Systems. He has authored more than 30 papers in journals and conferences. He received his Ph.D. from the University of California, Riverside.\nhttp://grafos.ml\n\n. Apache Giraph Project. Apache Giraph Project. http://giraph.apache.org/.\n\nExtended version of this work. Extended version of this work. http://arxiv.org/pdf/1404.3861v1.pdf.\n\nGraphLab Open Source project. GraphLab Open Source project. http://graphlab.org.\n\nThe Hadoop project. The Hadoop project. http://hadoop.apache.org.\n\n. The Tuenti Social Network. The Tuenti Social Network. http://www.tuenti.com.\n\n. Yahoo Webscope Program, Yahoo Webscope Program. http://webscope.sandbox.yahoo.com.\n\nGroup formation in large social networks: membership, growth, and evolution. L Backstrom, ACM SIGKDD. L. Backstrom, et al. Group formation in large social networks: membership, growth, and evolution. In ACM SIGKDD, Aug. 2006.\n\nDetecting network communities by propagating labels under constraints. M Barber, Physical Review E. 80226129M. Barber et al. Detecting network communities by propagating labels under constraints. Physical Review E, 80(2):026129, Aug. 2009.\n\nEvolution of social-attribute networks: measurements, modeling, and implications using Google+. N Z Gong, ACM Internet Measurement Conference. N. Z. Gong, et al. Evolution of social-attribute networks: measure- ments, modeling, and implications using Google+. In ACM Internet Measurement Conference, Nov. 2012.\n\nDistributed Graph-Parallel Computation on Natural Graphs. J E Gonzalez, USENIX OSDI. J. E. Gonzalez, et al. PowerGraph: Distributed Graph-Parallel Compu- tation on Natural Graphs. In USENIX OSDI, Oct. 2012.\n\nGraphs-at-a-time: Query Language and Access Methods for Graph Databases. H He, ACM SIGMOD. Vancouver, BC, CanadaH. He et al. Graphs-at-a-time: Query Language and Access Methods for Graph Databases. In ACM SIGMOD, Vancouver, BC, Canada, June 2008.\n\nUnstructured Graph Partitioning and Sparse Matrix Ordering System. G Karypis, Minneapolis, MNUniversity of MinnesotaTechnical reportG. Karypis et al. METIS: Unstructured Graph Partitioning and Sparse Matrix Ordering System. Technical report, University of Minnesota, Minneapolis, MN, 1995.\n\nParallel Multilevel k-way Partitioning Scheme for Irregular Graphs. G Karypis, SIAM Review. 41G. Karypis et al. Parallel Multilevel k-way Partitioning Scheme for Irregular Graphs. SIAM Review, 41, 1999.\n\nA System for Dynamic Load Balancing in Large-scale Graph Processing. Z Khayyat, ACM European Conference on Computer Systems. Z. Khayyat, et al. Mizan: A System for Dynamic Load Balancing in Large-scale Graph Processing. In ACM European Conference on Computer Systems, 2013.\n\nWhat is Twitter. H Kwak, WWW. H. Kwak, et al. What is Twitter, a social network or a news media? In WWW, 2010.\n\nDistributed GraphLab: A Framework for Machine Learning and Data Mining in the Cloud. The VLDB Endowment. Y Low, Y. Low, et al. Distributed GraphLab: A Framework for Machine Learning and Data Mining in the Cloud. The VLDB Endowment, Aug. 2012.\n\nChallenges in parallel graph processing. A Lumsdaine, Parallel Processing Letters. A. Lumsdaine, et al. Challenges in parallel graph processing. Parallel Processing Letters, 2008.\n\nPregel: a system for large-scale graph processing. G Malewicz, ACM SIGMOD. G. Malewicz, et al. Pregel: a system for large-scale graph processing. In ACM SIGMOD, 2010.\n\nRestreaming Graph Partitioning: Simple Versatile Algorithms for Advanced Balancing. J Nishimura, ACM SIGKDD. J. Nishimura et al. Restreaming Graph Partitioning: Simple Versatile Algorithms for Advanced Balancing. In ACM SIGKDD, August 2013.\n\nScalable Graph Clustering with Pregel. B Perozzi, Workshop on Complex Networks. G. Ghoshal, et al.Berlin, Heidelberg; Berlin HeidelbergSpringer476B. Perozzi, et al. Scalable Graph Clustering with Pregel. In G. Ghoshal, et al., editors, Workshop on Complex Networks, volume 476 of Studies in Computational Intelligence, Berlin, Heidelberg, 2013. Springer Berlin Heidelberg.\n\nThe little engine(s) that could: scaling online social networks. J M Pujol, ACM SIGCOMM Computer Communication Review. J. M. Pujol, et al. The little engine(s) that could: scaling online social networks. ACM SIGCOMM Computer Communication Review, Oct. 2011.\n\nUsing Pregel-like Large Scale Graph Processing Frameworks for Social Network Analysis. L Quick, IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining. L. Quick, et al. Using Pregel-like Large Scale Graph Processing Frameworks for Social Network Analysis. IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, 2012.\n\nA distributed graph engine on a memory cloud. B Shao, ACM SIGMOD International Conference on Management of Data. B. Shao, et al. Trinity: A distributed graph engine on a memory cloud. In ACM SIGMOD International Conference on Management of Data, pages 505-516, 2013.\n\nStreaming Graph Partitioning for Large Distributed Graphs. I Stanton, ACM SIGKDD. I. Stanton et al. Streaming Graph Partitioning for Large Distributed Graphs. In ACM SIGKDD, 2012.\n\nThink Like a Vertex\" to \"Think Like a Graph. Y Tian, VLDB. Hangzhou, ChinaY. Tian, et al. From \"Think Like a Vertex\" to \"Think Like a Graph\". In VLDB, Hangzhou, China, Sept. 2013.\n\nProduct of random stochastic matrices and distributed averaging. B Touri, SpringerB. Touri. Product of random stochastic matrices and distributed averaging. Springer, 2012.\n\nProblems in decentralized decision making and computation. J N Tsitsiklis, Massachusetts Institute of TechnologyPhD thesisJ. N. Tsitsiklis. Problems in decentralized decision making and computation. PhD thesis, Massachusetts Institute of Technology, 1984.\n\nFENNEL: Streaming Graph Partitioning for Massive Scale Graphs. C E Tsourakakis, ACM International Conference on Web Search and Data Mining. C. E. Tsourakakis, et al. FENNEL: Streaming Graph Partitioning for Massive Scale Graphs. ACM International Conference on Web Search and Data Mining, 2014.\n\nBalanced label propagation for partitioning massive graphs. J Ugander, ACM International Conference on Web Search and Data Mining. J. Ugander et al. Balanced label propagation for partitioning massive graphs. ACM International Conference on Web Search and Data Mining, 2013.\n\nHow to Partition a Billion-Node Graph. L Wang, ICDE'14. L. Wang, et al. How to Partition a Billion-Node Graph. In ICDE'14, 2014.\n\nCollective dynamics of 'small-world' networks. D Watts, Nature. D. Watts et al. Collective dynamics of 'small-world' networks. Nature, 1998.\n\nGraphX: A Resilient Distributed Graph System on Spark. R S Xin, Graph Data-management Experiences & Systems. R. S. Xin, et al. GraphX: A Resilient Distributed Graph System on Spark. In Graph Data-management Experiences & Systems, 2013.\n\nDefining and Evaluating Network Communities based on Ground-truth. J Yang, IEEE International Conference on Data Mining. J. Yang et al. Defining and Evaluating Network Communities based on Ground-truth. In IEEE International Conference on Data Mining, May 2012.\n\nTowards effective partition management for large graphs. S Yang, ACM SIGMOD. S. Yang, et al. Towards effective partition management for large graphs. In ACM SIGMOD, 2012.\n\n. C] , C |e|/K, C] , with C = |E|/k.\n", "annotations": {"author": "[{\"end\":70,\"start\":53},{\"end\":92,\"start\":71},{\"end\":108,\"start\":93},{\"end\":125,\"start\":109}]", "publisher": null, "author_last_name": "[{\"end\":69,\"start\":61},{\"end\":91,\"start\":81},{\"end\":107,\"start\":101},{\"end\":124,\"start\":117}]", "author_first_name": "[{\"end\":60,\"start\":53},{\"end\":80,\"start\":71},{\"end\":100,\"start\":93},{\"end\":116,\"start\":109}]", "author_affiliation": null, "title": "[{\"end\":50,\"start\":1},{\"end\":175,\"start\":126}]", "venue": null, "abstract": "[{\"end\":1576,\"start\":233}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b10\"},\"end\":1787,\"start\":1783},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":1827,\"start\":1823},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":1833,\"start\":1829},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":1839,\"start\":1835},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":1845,\"start\":1841},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":2108,\"start\":2104},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":2592,\"start\":2588},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":2598,\"start\":2594},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":2785,\"start\":2781},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":2791,\"start\":2787},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":2797,\"start\":2793},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":2953,\"start\":2949},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":3208,\"start\":3204},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":4177,\"start\":4173},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":4195,\"start\":4191},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":4574,\"start\":4570},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":4580,\"start\":4576},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":4585,\"start\":4582},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":4898,\"start\":4895},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":4954,\"start\":4950},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":5416,\"start\":5412},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":5422,\"start\":5418},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":5428,\"start\":5424},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":8504,\"start\":8500},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":8510,\"start\":8506},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":8535,\"start\":8531},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":8541,\"start\":8537},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":8806,\"start\":8805},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":9900,\"start\":9896},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":10928,\"start\":10924},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":10933,\"start\":10930},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":10939,\"start\":10935},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":10945,\"start\":10941},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":11567,\"start\":11563},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":11589,\"start\":11585},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":12621,\"start\":12618},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":14899,\"start\":14896},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":17727,\"start\":17723},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":20197,\"start\":20194},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":21433,\"start\":21430},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":21977,\"start\":21973},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":21983,\"start\":21979},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":23973,\"start\":23970},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":24736,\"start\":24732},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":32107,\"start\":32104},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":32284,\"start\":32281},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":39562,\"start\":39559},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":47495,\"start\":47491},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":50884,\"start\":50880},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":55242,\"start\":55239},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":62513,\"start\":62509},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":62933,\"start\":62929},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":62939,\"start\":62935},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":62945,\"start\":62941},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":63571,\"start\":63567},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":63577,\"start\":63573},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":64076,\"start\":64072},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":64937,\"start\":64933},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":65383,\"start\":65379},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":65398,\"start\":65394},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":68248,\"start\":68244},{\"end\":68260,\"start\":68248}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":71814,\"start\":71734},{\"attributes\":{\"id\":\"fig_1\"},\"end\":71984,\"start\":71815},{\"attributes\":{\"id\":\"fig_2\"},\"end\":72186,\"start\":71985},{\"attributes\":{\"id\":\"fig_3\"},\"end\":72422,\"start\":72187},{\"attributes\":{\"id\":\"fig_4\"},\"end\":72630,\"start\":72423},{\"attributes\":{\"id\":\"fig_5\"},\"end\":72955,\"start\":72631},{\"attributes\":{\"id\":\"fig_6\"},\"end\":73248,\"start\":72956},{\"attributes\":{\"id\":\"fig_7\"},\"end\":73594,\"start\":73249},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":74492,\"start\":73595},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":75280,\"start\":74493},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":75465,\"start\":75281},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":75794,\"start\":75466},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":76216,\"start\":75795}]", "paragraph": "[{\"end\":2253,\"start\":1595},{\"end\":4098,\"start\":2255},{\"end\":4699,\"start\":4100},{\"end\":5118,\"start\":4701},{\"end\":5689,\"start\":5120},{\"end\":6157,\"start\":5691},{\"end\":6457,\"start\":6159},{\"end\":6510,\"start\":6459},{\"end\":7907,\"start\":6512},{\"end\":8169,\"start\":7941},{\"end\":8376,\"start\":8189},{\"end\":9925,\"start\":8378},{\"end\":10275,\"start\":9927},{\"end\":10774,\"start\":10277},{\"end\":11313,\"start\":10809},{\"end\":11590,\"start\":11315},{\"end\":12164,\"start\":11592},{\"end\":12449,\"start\":12166},{\"end\":13064,\"start\":12476},{\"end\":13290,\"start\":13066},{\"end\":13576,\"start\":13430},{\"end\":13795,\"start\":13655},{\"end\":14361,\"start\":13826},{\"end\":15052,\"start\":14400},{\"end\":15585,\"start\":15084},{\"end\":16039,\"start\":15587},{\"end\":16455,\"start\":16041},{\"end\":16606,\"start\":16457},{\"end\":16778,\"start\":16680},{\"end\":16936,\"start\":16825},{\"end\":17576,\"start\":16938},{\"end\":18177,\"start\":17610},{\"end\":18609,\"start\":18179},{\"end\":18904,\"start\":18611},{\"end\":19037,\"start\":18906},{\"end\":19163,\"start\":19055},{\"end\":19684,\"start\":19198},{\"end\":19914,\"start\":19686},{\"end\":20244,\"start\":19933},{\"end\":20732,\"start\":20315},{\"end\":21310,\"start\":20734},{\"end\":22391,\"start\":21341},{\"end\":22969,\"start\":22393},{\"end\":23135,\"start\":23017},{\"end\":23473,\"start\":23328},{\"end\":23633,\"start\":23537},{\"end\":23882,\"start\":23780},{\"end\":24031,\"start\":23936},{\"end\":24379,\"start\":24033},{\"end\":25073,\"start\":24381},{\"end\":25196,\"start\":25075},{\"end\":26313,\"start\":25237},{\"end\":26771,\"start\":26350},{\"end\":27440,\"start\":26773},{\"end\":28208,\"start\":27442},{\"end\":28983,\"start\":28210},{\"end\":29776,\"start\":29016},{\"end\":30259,\"start\":29778},{\"end\":30790,\"start\":30276},{\"end\":31354,\"start\":30792},{\"end\":32034,\"start\":31356},{\"end\":32405,\"start\":32064},{\"end\":32742,\"start\":32407},{\"end\":33184,\"start\":32777},{\"end\":33649,\"start\":33186},{\"end\":33782,\"start\":33651},{\"end\":34184,\"start\":33826},{\"end\":34598,\"start\":34186},{\"end\":35004,\"start\":34600},{\"end\":35569,\"start\":35006},{\"end\":36268,\"start\":35571},{\"end\":37122,\"start\":36270},{\"end\":37614,\"start\":37124},{\"end\":37714,\"start\":37616},{\"end\":37916,\"start\":37735},{\"end\":38257,\"start\":37944},{\"end\":39232,\"start\":38276},{\"end\":39356,\"start\":39234},{\"end\":39523,\"start\":39412},{\"end\":39595,\"start\":39525},{\"end\":40213,\"start\":39597},{\"end\":40887,\"start\":40257},{\"end\":41180,\"start\":40889},{\"end\":42037,\"start\":41182},{\"end\":42525,\"start\":42039},{\"end\":42767,\"start\":42576},{\"end\":43498,\"start\":42813},{\"end\":44134,\"start\":43516},{\"end\":44394,\"start\":44136},{\"end\":44665,\"start\":44422},{\"end\":45662,\"start\":44717},{\"end\":46063,\"start\":45664},{\"end\":46371,\"start\":46065},{\"end\":47066,\"start\":46373},{\"end\":47408,\"start\":47068},{\"end\":47726,\"start\":47410},{\"end\":48401,\"start\":47728},{\"end\":48829,\"start\":48403},{\"end\":49203,\"start\":48831},{\"end\":49675,\"start\":49205},{\"end\":50615,\"start\":49677},{\"end\":51467,\"start\":50634},{\"end\":52971,\"start\":51469},{\"end\":53422,\"start\":52973},{\"end\":54027,\"start\":53424},{\"end\":54502,\"start\":54062},{\"end\":55183,\"start\":54504},{\"end\":56035,\"start\":55185},{\"end\":56584,\"start\":56065},{\"end\":57090,\"start\":56586},{\"end\":57503,\"start\":57092},{\"end\":58269,\"start\":57539},{\"end\":58950,\"start\":58271},{\"end\":59446,\"start\":58991},{\"end\":60165,\"start\":59448},{\"end\":61459,\"start\":60167},{\"end\":61994,\"start\":61461},{\"end\":62337,\"start\":61996},{\"end\":62501,\"start\":62358},{\"end\":62906,\"start\":62503},{\"end\":63527,\"start\":62908},{\"end\":64925,\"start\":63529},{\"end\":65601,\"start\":64927},{\"end\":66422,\"start\":65622},{\"end\":66808,\"start\":66438},{\"end\":67236,\"start\":66810},{\"end\":67853,\"start\":67238},{\"end\":68436,\"start\":67855},{\"end\":68741,\"start\":68481},{\"end\":69103,\"start\":68795},{\"end\":69434,\"start\":69105},{\"end\":69593,\"start\":69496},{\"end\":70668,\"start\":69595},{\"end\":70835,\"start\":70724},{\"end\":70970,\"start\":70837},{\"end\":71143,\"start\":71016},{\"end\":71411,\"start\":71213},{\"end\":71656,\"start\":71514},{\"end\":71733,\"start\":71658}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":13429,\"start\":13291},{\"attributes\":{\"id\":\"formula_1\"},\"end\":13654,\"start\":13577},{\"attributes\":{\"id\":\"formula_2\"},\"end\":14399,\"start\":14362},{\"attributes\":{\"id\":\"formula_3\"},\"end\":15083,\"start\":15053},{\"attributes\":{\"id\":\"formula_4\"},\"end\":16679,\"start\":16607},{\"attributes\":{\"id\":\"formula_5\"},\"end\":16824,\"start\":16779},{\"attributes\":{\"id\":\"formula_6\"},\"end\":19054,\"start\":19038},{\"attributes\":{\"id\":\"formula_7\"},\"end\":19197,\"start\":19164},{\"attributes\":{\"id\":\"formula_8\"},\"end\":19932,\"start\":19915},{\"attributes\":{\"id\":\"formula_9\"},\"end\":20314,\"start\":20245},{\"attributes\":{\"id\":\"formula_10\"},\"end\":23016,\"start\":22970},{\"attributes\":{\"id\":\"formula_11\"},\"end\":23327,\"start\":23136},{\"attributes\":{\"id\":\"formula_12\"},\"end\":23536,\"start\":23474},{\"attributes\":{\"id\":\"formula_13\"},\"end\":23779,\"start\":23634},{\"attributes\":{\"id\":\"formula_14\"},\"end\":25236,\"start\":25197},{\"attributes\":{\"id\":\"formula_15\"},\"end\":30275,\"start\":30260},{\"attributes\":{\"id\":\"formula_16\"},\"end\":37734,\"start\":37715},{\"attributes\":{\"id\":\"formula_17\"},\"end\":37943,\"start\":37917},{\"attributes\":{\"id\":\"formula_18\"},\"end\":38275,\"start\":38258},{\"attributes\":{\"id\":\"formula_19\"},\"end\":39411,\"start\":39357},{\"attributes\":{\"id\":\"formula_20\"},\"end\":44716,\"start\":44666},{\"attributes\":{\"id\":\"formula_21\"},\"end\":68480,\"start\":68437},{\"attributes\":{\"id\":\"formula_22\"},\"end\":70723,\"start\":70669},{\"attributes\":{\"id\":\"formula_23\"},\"end\":71015,\"start\":70971},{\"attributes\":{\"id\":\"formula_24\"},\"end\":71212,\"start\":71144},{\"attributes\":{\"id\":\"formula_25\"},\"end\":71513,\"start\":71412}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":44237,\"start\":44229},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":45891,\"start\":45882},{\"end\":46383,\"start\":46376},{\"end\":60962,\"start\":60859}]", "section_header": "[{\"end\":1593,\"start\":1578},{\"end\":7939,\"start\":7910},{\"end\":8187,\"start\":8172},{\"end\":10807,\"start\":10777},{\"end\":12474,\"start\":12452},{\"end\":13824,\"start\":13798},{\"end\":17608,\"start\":17579},{\"end\":21339,\"start\":21313},{\"end\":23934,\"start\":23885},{\"end\":26348,\"start\":26316},{\"end\":29014,\"start\":28986},{\"end\":32062,\"start\":32037},{\"end\":32775,\"start\":32745},{\"end\":33824,\"start\":33785},{\"end\":40255,\"start\":40216},{\"end\":42574,\"start\":42528},{\"end\":42811,\"start\":42770},{\"end\":43514,\"start\":43501},{\"end\":44420,\"start\":44397},{\"end\":50632,\"start\":50618},{\"end\":54060,\"start\":54030},{\"end\":56063,\"start\":56038},{\"end\":57537,\"start\":57506},{\"end\":58989,\"start\":58953},{\"end\":62356,\"start\":62340},{\"end\":65620,\"start\":65604},{\"end\":66436,\"start\":66425},{\"end\":68793,\"start\":68744},{\"end\":69494,\"start\":69437},{\"end\":71743,\"start\":71735},{\"end\":71824,\"start\":71816},{\"end\":72965,\"start\":72957},{\"end\":73606,\"start\":73596}]", "table": "[{\"end\":74492,\"start\":73672},{\"end\":75280,\"start\":74765},{\"end\":75465,\"start\":75399},{\"end\":75794,\"start\":75670}]", "figure_caption": "[{\"end\":71814,\"start\":71745},{\"end\":71984,\"start\":71826},{\"end\":72186,\"start\":71987},{\"end\":72422,\"start\":72189},{\"end\":72630,\"start\":72425},{\"end\":72955,\"start\":72633},{\"end\":73248,\"start\":72967},{\"end\":73594,\"start\":73251},{\"end\":73672,\"start\":73609},{\"end\":74765,\"start\":74495},{\"end\":75399,\"start\":75283},{\"end\":75670,\"start\":75468},{\"end\":76216,\"start\":75797}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":15726,\"start\":15718},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":32858,\"start\":32850},{\"end\":45675,\"start\":45667},{\"end\":46149,\"start\":46141},{\"end\":47137,\"start\":47129},{\"end\":47253,\"start\":47247},{\"end\":47298,\"start\":47288},{\"end\":47349,\"start\":47339},{\"end\":47739,\"start\":47731},{\"end\":50042,\"start\":50033},{\"end\":50298,\"start\":50287},{\"end\":52002,\"start\":51994},{\"end\":52162,\"start\":52154},{\"end\":53020,\"start\":53012},{\"end\":53470,\"start\":53462},{\"end\":55586,\"start\":55578},{\"end\":57103,\"start\":57095},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":57912,\"start\":57904},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":58395,\"start\":58384},{\"end\":58536,\"start\":58524},{\"end\":61993,\"start\":61985}]", "bib_author_first_name": "[{\"end\":76657,\"start\":76643},{\"end\":76805,\"start\":76804},{\"end\":77026,\"start\":77025},{\"end\":77292,\"start\":77291},{\"end\":77294,\"start\":77293},{\"end\":77566,\"start\":77565},{\"end\":77568,\"start\":77567},{\"end\":77789,\"start\":77788},{\"end\":78031,\"start\":78030},{\"end\":78323,\"start\":78322},{\"end\":78528,\"start\":78527},{\"end\":78751,\"start\":78750},{\"end\":78951,\"start\":78950},{\"end\":79131,\"start\":79130},{\"end\":79322,\"start\":79321},{\"end\":79523,\"start\":79522},{\"end\":79720,\"start\":79719},{\"end\":80120,\"start\":80119},{\"end\":80122,\"start\":80121},{\"end\":80401,\"start\":80400},{\"end\":80739,\"start\":80738},{\"end\":81020,\"start\":81019},{\"end\":81187,\"start\":81186},{\"end\":81388,\"start\":81387},{\"end\":81556,\"start\":81555},{\"end\":81558,\"start\":81557},{\"end\":81817,\"start\":81816},{\"end\":81819,\"start\":81818},{\"end\":82110,\"start\":82109},{\"end\":82365,\"start\":82364},{\"end\":82503,\"start\":82502},{\"end\":82653,\"start\":82652},{\"end\":82655,\"start\":82654},{\"end\":82902,\"start\":82901},{\"end\":83155,\"start\":83154},{\"end\":83273,\"start\":83271},{\"end\":83277,\"start\":83276}]", "bib_author_last_name": "[{\"end\":76665,\"start\":76658},{\"end\":76815,\"start\":76806},{\"end\":77033,\"start\":77027},{\"end\":77299,\"start\":77295},{\"end\":77577,\"start\":77569},{\"end\":77792,\"start\":77790},{\"end\":78039,\"start\":78032},{\"end\":78331,\"start\":78324},{\"end\":78536,\"start\":78529},{\"end\":78756,\"start\":78752},{\"end\":78955,\"start\":78952},{\"end\":79141,\"start\":79132},{\"end\":79331,\"start\":79323},{\"end\":79533,\"start\":79524},{\"end\":79728,\"start\":79721},{\"end\":80128,\"start\":80123},{\"end\":80407,\"start\":80402},{\"end\":80744,\"start\":80740},{\"end\":81028,\"start\":81021},{\"end\":81192,\"start\":81188},{\"end\":81394,\"start\":81389},{\"end\":81569,\"start\":81559},{\"end\":81831,\"start\":81820},{\"end\":82118,\"start\":82111},{\"end\":82370,\"start\":82366},{\"end\":82509,\"start\":82504},{\"end\":82659,\"start\":82656},{\"end\":82907,\"start\":82903},{\"end\":83160,\"start\":83156},{\"end\":83283,\"start\":83278}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":76309,\"start\":76235},{\"attributes\":{\"id\":\"b1\"},\"end\":76410,\"start\":76311},{\"attributes\":{\"id\":\"b2\"},\"end\":76492,\"start\":76412},{\"attributes\":{\"id\":\"b3\"},\"end\":76559,\"start\":76494},{\"attributes\":{\"id\":\"b4\"},\"end\":76639,\"start\":76561},{\"attributes\":{\"id\":\"b5\"},\"end\":76725,\"start\":76641},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":7904289},\"end\":76952,\"start\":76727},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":33388193},\"end\":77193,\"start\":76954},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":9156850},\"end\":77505,\"start\":77195},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":13396177},\"end\":77713,\"start\":77507},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":13540465},\"end\":77961,\"start\":77715},{\"attributes\":{\"id\":\"b11\"},\"end\":78252,\"start\":77963},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":72733},\"end\":78456,\"start\":78254},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":13835043},\"end\":78731,\"start\":78458},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":65146187},\"end\":78843,\"start\":78733},{\"attributes\":{\"id\":\"b15\"},\"end\":79087,\"start\":78845},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":9713234},\"end\":79268,\"start\":79089},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":53034533},\"end\":79436,\"start\":79270},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":14950070},\"end\":79678,\"start\":79438},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":17726044},\"end\":80052,\"start\":79680},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":6502624},\"end\":80311,\"start\":80054},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":1497972},\"end\":80690,\"start\":80313},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":1664117},\"end\":80958,\"start\":80692},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":3142693},\"end\":81139,\"start\":80960},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":2242833},\"end\":81320,\"start\":81141},{\"attributes\":{\"id\":\"b25\"},\"end\":81494,\"start\":81322},{\"attributes\":{\"id\":\"b26\"},\"end\":81751,\"start\":81496},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":9590483},\"end\":82047,\"start\":81753},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":15039047},\"end\":82323,\"start\":82049},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":16325507},\"end\":82453,\"start\":82325},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":4429113},\"end\":82595,\"start\":82455},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":11150229},\"end\":82832,\"start\":82597},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":9136948},\"end\":83095,\"start\":82834},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":13923918},\"end\":83267,\"start\":83097},{\"attributes\":{\"id\":\"b34\"},\"end\":83305,\"start\":83269}]", "bib_title": "[{\"end\":76802,\"start\":76727},{\"end\":77023,\"start\":76954},{\"end\":77289,\"start\":77195},{\"end\":77563,\"start\":77507},{\"end\":77786,\"start\":77715},{\"end\":78320,\"start\":78254},{\"end\":78525,\"start\":78458},{\"end\":78748,\"start\":78733},{\"end\":79128,\"start\":79089},{\"end\":79319,\"start\":79270},{\"end\":79520,\"start\":79438},{\"end\":79717,\"start\":79680},{\"end\":80117,\"start\":80054},{\"end\":80398,\"start\":80313},{\"end\":80736,\"start\":80692},{\"end\":81017,\"start\":80960},{\"end\":81184,\"start\":81141},{\"end\":81814,\"start\":81753},{\"end\":82107,\"start\":82049},{\"end\":82362,\"start\":82325},{\"end\":82500,\"start\":82455},{\"end\":82650,\"start\":82597},{\"end\":82899,\"start\":82834},{\"end\":83152,\"start\":83097}]", "bib_author": "[{\"end\":76667,\"start\":76643},{\"end\":76817,\"start\":76804},{\"end\":77035,\"start\":77025},{\"end\":77301,\"start\":77291},{\"end\":77579,\"start\":77565},{\"end\":77794,\"start\":77788},{\"end\":78041,\"start\":78030},{\"end\":78333,\"start\":78322},{\"end\":78538,\"start\":78527},{\"end\":78758,\"start\":78750},{\"end\":78957,\"start\":78950},{\"end\":79143,\"start\":79130},{\"end\":79333,\"start\":79321},{\"end\":79535,\"start\":79522},{\"end\":79730,\"start\":79719},{\"end\":80130,\"start\":80119},{\"end\":80409,\"start\":80400},{\"end\":80746,\"start\":80738},{\"end\":81030,\"start\":81019},{\"end\":81194,\"start\":81186},{\"end\":81396,\"start\":81387},{\"end\":81571,\"start\":81555},{\"end\":81833,\"start\":81816},{\"end\":82120,\"start\":82109},{\"end\":82372,\"start\":82364},{\"end\":82511,\"start\":82502},{\"end\":82661,\"start\":82652},{\"end\":82909,\"start\":82901},{\"end\":83162,\"start\":83154},{\"end\":83276,\"start\":83271},{\"end\":83285,\"start\":83276}]", "bib_venue": "[{\"end\":76258,\"start\":76237},{\"end\":76340,\"start\":76311},{\"end\":76440,\"start\":76412},{\"end\":76512,\"start\":76494},{\"end\":76588,\"start\":76563},{\"end\":76827,\"start\":76817},{\"end\":77052,\"start\":77035},{\"end\":77336,\"start\":77301},{\"end\":77590,\"start\":77579},{\"end\":77804,\"start\":77794},{\"end\":78028,\"start\":77963},{\"end\":78344,\"start\":78333},{\"end\":78581,\"start\":78538},{\"end\":78761,\"start\":78758},{\"end\":78948,\"start\":78845},{\"end\":79170,\"start\":79143},{\"end\":79343,\"start\":79333},{\"end\":79545,\"start\":79535},{\"end\":79758,\"start\":79730},{\"end\":80171,\"start\":80130},{\"end\":80493,\"start\":80409},{\"end\":80803,\"start\":80746},{\"end\":81040,\"start\":81030},{\"end\":81198,\"start\":81194},{\"end\":81385,\"start\":81322},{\"end\":81553,\"start\":81496},{\"end\":81891,\"start\":81833},{\"end\":82178,\"start\":82120},{\"end\":82379,\"start\":82372},{\"end\":82517,\"start\":82511},{\"end\":82704,\"start\":82661},{\"end\":82953,\"start\":82909},{\"end\":83172,\"start\":83162},{\"end\":77827,\"start\":77806},{\"end\":79815,\"start\":79778},{\"end\":81215,\"start\":81200}]"}}}, "year": 2023, "month": 12, "day": 17}