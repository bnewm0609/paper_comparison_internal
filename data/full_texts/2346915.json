{"id": 2346915, "updated": "2023-09-27 19:36:33.978", "metadata": {"title": "Information-Theoretical Learning of Discriminative Clusters for Unsupervised Domain Adaptation", "authors": "[{\"first\":\"Yuan\",\"last\":\"Shi\",\"middle\":[]},{\"first\":\"Fei\",\"last\":\"Sha\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2012, "month": null, "day": null}, "abstract": "We study the problem of unsupervised domain adaptation, which aims to adapt classifiers trained on a labeled source domain to an unlabeled target domain. Many existing approaches first learn domain-invariant features and then construct classifiers with them. We propose a novel approach that jointly learn the both. Specifically, while the method identifies a feature space where data in the source and the target domains are similarly distributed, it also learns the feature space discriminatively, optimizing an information-theoretic metric as an proxy to the expected misclassification error on the target domain. We show how this optimization can be effectively carried out with simple gradient-based methods and how hyperparameters can be cross-validated without demanding any labeled data from the target domain. Empirical studies on benchmark tasks of object recognition and sentiment analysis validated our modeling assumptions and demonstrated significant improvement of our method over competing ones in classification accuracies.", "fields_of_study": "[\"Computer Science\",\"Mathematics\"]", "external_ids": {"arxiv": "1206.6438", "mag": "2950333415", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/icml/ShiS12", "doi": null}}, "content": {"source": {"pdf_hash": "e7f4e40dd896472cfebd22f8ba6ddee90c8b8eea", "pdf_src": "Arxiv", "pdf_uri": "[\"https://export.arxiv.org/pdf/1206.6438v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "50639e095ab939f39f577e82962d7119bec9d59d", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/e7f4e40dd896472cfebd22f8ba6ddee90c8b8eea.txt", "contents": "\nInformation-Theoretical Learning of Discriminative Clusters for Unsupervised Domain Adaptation\n\n\nYuan Shi yuanshi@usc.edu \nU. of Southern California\nU. of Southern California\n90089, 90089Los Angeles, Los AngelesCA, CAUSA, USA\n\nSha Fei feisha@usc.edu \nU. of Southern California\nU. of Southern California\n90089, 90089Los Angeles, Los AngelesCA, CAUSA, USA\n\nInformation-Theoretical Learning of Discriminative Clusters for Unsupervised Domain Adaptation\n\nWe study the problem of unsupervised domain adaptation, which aims to adapt classifiers trained on a labeled source domain to an unlabeled target domain. Many existing approaches first learn domain-invariant features and then construct classifiers with them. We propose a novel approach that jointly learn the both. Specifically, while the method identifies a feature space where data in the source and the target domains are similarly distributed, it also learns the feature space discriminatively, optimizing an informationtheoretic metric as an proxy to the expected misclassification error on the target domain. We show how this optimization can be effectively carried out with simple gradient-based methods and how hyperparameters can be cross-validated without demanding any labeled data from the target domain. Empirical studies on benchmark tasks of object recognition and sentiment analysis validated our modeling assumptions and demonstrated significant improvement of our method over competing ones in classification accuracies.\n\nIntroduction\n\nSupervised learning algorithms often assume that the training and the test data are randomly sampled from the same joint distribution. While the assumption facilitates rigorous theoretical analysis and empirical comparison of different algorithms, its validity is often challenged outside of laboratory settings. In realworld applications, there are many factors causing a mismatch between the training and the test data. For instance, imagine developing a face detection system for Facebook mobile users. A tuned classifier on images captured by webcams could be applied to images from mobile phones. In this case, the imaging conditions vary significantly due to background illumination, motion blurring, pose, etc.\n\nTechniques for addressing learning problems with mismatched distributions are often referred as domain adaptation, or sometimes transfer learning (Daum\u00e9 III & Marcu, 2006;Pan & Yang, 2010;Qui\u00f1onero-Candela et al., 2009). The source domain refers to the labeled training data, while the target domain refers to the test data. When there is no labeled data from the target domain to help learning classifiers, the problem setting is termed unsupervised domain adaptation.\n\nUnsupervised domain adaptation is especially challenging as the target domain does not provide explicitly any information on how to optimize classifiers. Note that the objective of domain adaptation is to derive a classifier for the unlabeled (target) data from the labeled (source) data. This goal sets domain adaptation apart from semi-supervised learning, whose primary goal is to improve the performance on the labeled data with unlabeled data (Chapelle et al., 2006). The difference is subtle yet fundamental. For example, model selection or cross-validation using classification accuracy on the target domain is generally impossible.\n\nExisting approaches thus rely on making strong assumptions on how the data distribution have shifted between the two domains in order to derive classification rules for the target domain. For instance, in covariate shift (Shimodaira, 2000;Bickel et al., 2007;Huang et al., 2007), the marginal distributions of the features are different across domains while the posterior distribution of the label remains the same. This naturally leads to a two-stage learning paradigm: the labeled instances from the source domain are first weighted so as to compensate the difference in marginal distributions. Then, a classifier is trained using the labels and then applied to the unlabeled data.\n\nOther works have also followed similar paradigms (Pan et al., 2011;Gopalan et al., 2011). In the structural correspondence learning, the original features are first augmented with features that are more likely to be domain invariant and then a classifier is trained (Blitzer et al., 2006). The augmenting features are linear transformation of the original features. Alternatively, in deep learning architecture for domain adaptation, the augmenting features are highly nonlinear transformation of the original ones (Glorot et al., 2011).\n\nUnderlying all these methods is the assumption that there exists a domain-invariant feature space such that the marginal distributions of two domains are the same in the new feature space. Thus, classifiers learnt in the new space will perform equally well on both the source and the target. Theoretical analysis have showed that the loss on the target domain for any labeling functions depends on the difference between the marginal distributions, thus justifying the need to identify a feature space such that the two domains look alike to each other (Ben-David et al., 2007;Mansour et al., 2009).\n\nWe hypothesize that this view and practice of twostage learning are restrictive. One possible fallacy is that maximizing the similarity in marginal distributions bear no direct consequence on (dis)similarities between posterior distributions. Thus, if there are multiple feature spaces where the source and the target domains have similar marginals, there is no reason to believe that a classifier trained on an arbitrarily chosen one would necessarily perform well on the target domain. As an extreme case, projecting features into irrelevant feature dimensions would make the two domains look very much alike! Hence, the caveat is to retain discriminative information for constructing classifiers while we search for the domain-invariant feature space. This seems relatively straightforward to achieve if all we care is the discriminative information about the labels in the source domain. However, our main goal is to have good classifiers for the target domain. Thus, our challenge is how to be discriminative without labels?\n\nTo address this challenge, we propose a novel learning algorithm for unsupervised domain adaptation. As opposed to existing two-stage approaches where new feature spaces and classifiers are separately optimized, our approach combines the two in a single stage. Moreover, the new feature space is discriminative with re-spect to the target domain. We give a brief account in the following, leaving details to sections 2 and 3.\n\n\nMain Idea\n\nWe assume discriminative clustering, namely, data in both the source and the target domains are tightly clustered and clusters corresponds class boundaries. For the same class, the clusters from the two domains are geometrically close to each other. Leveraging these assumptions, our formulation of learning the optimal feature space balances two forces: maximizing domain similarity that makes the source and the target domains look alike, and (approximately) minimizing the expected classification error on the target domain. We define those two forces with information-theoretical quantities: the domain similarity being the negated mutual information between all data and their binary domain labels (source versus target) and the expected classification error being the negated mutual information between the target data and its clusters (ie class) labels estimated from the source data. These two quantities are directly motivated by the nearest neighbor classifiers we use in the new feature space.\n\nWe show how simple gradient-based methods can be effectively used for numerical optimization to learn the optimal feature space. We evaluated extensively our approach on two benchmark tasks: visual object recognition and sentiment analysis of product reviews. On both of them, the proposed approach outperforms other state-of-the-arts methods significantly.\n\nContributions To summarize, we contribute to domain adaptation by advocating discriminative clustering as a possible mechanism for adaptation; cf. section 2. We hypothesize that existing approaches of two-stage learning can be significantly improved by taking those cluster structures into consideration. Thus, we propose an one-stage approach jointly learning a domain-invariant feature space and optimizing information-theoretic metrics directly related to discriminative classification on the target domain; cf. section 3. Our empirical results support strongly our modeling assumptions and hypothesis; cf. section 4.\n\n\nDiscriminative Clustering for Domain Adaptation\n\nAt the core of our approach is the assumption of discriminative clustering. Specifically, we assume that, in a suitable feature space, 1) separation. Data in the source and the target domains are discriminatively clustered, where the cluster ids correspond to class labels; 2) Alignment. The clusters from the two domains that correspond to the same label are geomet- ? Figure 1. Schematic illustration of our main idea on exploiting discriminative clustering for unsupervised domain adaptation, cf. section 2. Data in the source domain (within circle shapes) and the target domain (within oval shapes) are tightly clustered, corresponding to their class boundaries. Moreover, clusters from the two domains are \"aligned\" if they correspond to the same class. Assuming and exploiting such structures in the data, classifier boundaries for the source domain (dashed lines in the left diagram) are adapted discriminatively to the target domain (dashed lines in the right diagram), minimizing the expected classification errors on the target domain. The target data is then classified with adapted classifiers. See section 3 for details on how the errors can be approximated using information-theoretical quantities such as mutual information, without using labels.\n\nrically close. Fig. 1 illustrates these two assumptions and how they can be exploited for adaptation.\n\nArguably, the assumptions are more \"relaxed\" than those in existing works for adaptation. Specifically, they do not imply that the marginal distributions are the same across domains and certainly do not imply the same posterior distributions either. In fact, these assumptions are readily satisfiable in applications.\n\nFor example, many datasets exhibit multi-modal marginal distributions where the modes correspond to class labels, particularly if these data are sampled from a generative process of mixture models.\n\nAs we will show in the following, these two assumptions allow us to define quantitively what to be optimized -in our case, we would like to identify a domaininvariant feature space such that the expected misclassification error on the target data is minimized. Despite the paucity in labels from the target domain, we will show how the alignment assumption will allow us to define a proxy to the error so as to be optimized.\n\n\nProposed Approach\n\nIn what follows, we are given N labeled instances from the source domain: {(x s , y s )} where x s \u2208 X \u2282 R D and y s takes a value from C class labels: y s \u2208 Y = {1, 2, . . . , C}. We also have M unlabeled instances from the target domain: {x t } where x t \u2208 X . For simplicity, we assume x t and x s have the same domain X , thus the same dimensionality. Extensions to more general cases are possible, analogous to (Kulis et al., 2011).\n\nOur objective is to construct a classifier f : x \u2208 X \u2192 y \u2208 Y. We would like the classifier performs well on the target domain D T from which x t is sampled. This is inherently an ill-posed problem as we do not have any labels from the target domain.\n\nTo overcome this difficulty, we leverage the discriminative clustering assumptions which we have previously described. We assume that there is a latent feature space z \u2208 R d such that i) data in the source and target domains form well-separated clusters and the clusters correspond to labels; ii) the clusters from the source domain are geometrically close to those from the target domain if they are from the same labels.\n\nWe show how these assumptions can be used to derive information theoretical quantities which reflect data characteristics in each domain. These quantities are parameterized in terms of the latent feature which is in turn a linear transformation of the original feature x. We then show how to combine these quantities so that the optimal linear transformation can be learnt from data. We begin by describing a few key notions.\n\n\nConditional models in the feature space\n\nWe consider the latent feature space induced by a linear transformation L \u2208 R d\u00d7D . In the new feature space, we use k-nearest neighbors (kNN) to classify as we have assumed that data form well-separated clusters. Moreover, we choose k = 1 to avoid crossvalidating this parameter.\n\nThe squared distance between two points x i and x j in this feature space is thus given by\nd 2 ij = Lx i \u2212 Lx j 2 2 = (x i \u2212 x j ) T M (x i \u2212 x j ) (1)\nwhere M = L T L defines a (low-rank) Mahalanobis distance metric in the original space.\n\nGiven a point x i and a set of data points {x j }, we use the following model\np ij = e \u2212d 2 ij j =i e \u2212d 2 ij(2)\nto define the conditional probability of having x j as x i 's nearest neighbor.\n\nThe above conditional model has been used in many contexts, including metric learning (Goldberger et al., 2004), dimensionality reduction (Hinton & Roweis, 2002), etc. Characterizing how close a point x i is to other points, this model gives rise to an estimate of the posterior p(y i = c|x i ) for labeling x i with the class label c, assuming the class labels of {x j } are known,\np ic = j =i p ij \u03b4 jc (3)\nwhere \u03b4 jc is 1 if x j 's label is c, and 0 otherwise. Since p ij is a normalized probability,p ic is normalized too. For example, if the label of x i is known, cp ic \u03b4 ic would be the probability of correctly classifying x i .\n\n\nDiscriminative clustering in the source\n\nTo derive a classifier that can perform well on the target domain, we would certainly need the classifier to perform well on the source domain because we have assumed that the two domains share similar clustering structures. Thus, our first desideratum is to minimize the expected classification error on the source domain, when we classify it using 1-NN. This error is estimated using the empirical average of the leave-one-out accuracy for any given point x s in the source domain D S :\n\u03b5 s = 1 \u2212 1 N s cp sc \u03b4 sc(4)\nNote that, if we minimize this error only and ignore the target domain, we will arrive at the metric learning technique in (Goldberger et al., 2004).\n\n\nDiscriminative clustering in the target\n\nSince we do not have labels on the target domain, we cannot define the expected classification error as we did in eq. (4) for the source domain. How to be discriminative without using labels?\n\nConsider an instance x t from the target domain and all the instances {x s } from the source domain, the conditional model p ts of eq. (2) gives rise to the probability of having a particular x s as the nearest neighbor of x t . Using this conditional model as well as the source labels to compute the posterior as in eq. (3) would not be the correct posterior for the target domain. However, if our assumptions about two sets of clusters being geometrically close indeed hold in the dataset, then the estimationp tc should be close to the true posterior.\n\nIfp tc approximates the true posterior well and our assumption that the target data is well clustered, then we can reasonably expect that the C-dimensional probability vectorp t = [p t1 ,p t2 , . . . ,p tC ] should look like an ideal posterior probability vector [0, 0, . . . , 1, . . . , 0] where the only nonzero element 1 occurs at the position corresponding to the correct label.\n\nSince we do not know the true label, we cannot measure directly the similarity ofp t to the correct and ideal posterior vector. Nonetheless, we can express our desideratum as reducing the entropy ofp t such that it contains the least amount of confusing labels.\n\nLet H[p] denote the entropy of a probability vector p. If we minimize t H[p t ] only, we could arrive at a degenerate solution where every point x t is assigned to the same class. To avoid this, we instead maximize the mutual information between the data and the estimated label\u0176 usingp,\nI t (X;\u0176 ) = H[p 0 ] \u2212 1 M t H[p t ](5)\nand the prior distributionp 0 is given byp 0 = 1/M tp t . Note that using the empirical distribution of the labels in the source domain to estimate the priorp 0 could still lead to degenerate solutions when the labels are uniformly distributed.\n\nMinimizing the entropy (or similarly, maximizing the mutual information) has been previously studied in the context of (discriminative) clustering, cf. (Gomes et al., 2010;Dhillon et al., 2003). This criterion will identify a feature representation that classifiers can use to achieve a low lower-bound of misclassification error, due to Fano's inequality (Fisher III & Principe, 1998).\n\n\nDiscriminability: source versus target\n\nThe previous discussion on discriminative clustering in the target domain hinges on the assumption that clusters for the source and the target domain should not be too far from each other. We quantify this notion more precisely in the following. Conceptually, this notion is similar to the idea in existing works to make marginal distributions similar across domains.\n\nWhy such notion is desirable? To use the source domain's labels as an proxy to estimate the posterior probabilities for the target data (as in eq. (3)), we would desire the source and the target domain share some common probability supports in the feature space. In particular, consider the case we classify two instances x t and x t from the target domain. They are deemed to have the same label c if there are plenty of labeled source data in class c in their neighborhoods. Then we would expect that with high likelihood, x t and x t are in each other's nearest neighbors toootherwise, the cluster corresponding to class c in the target domain would not be very \"tight\".\n\nHaving instances from both domains in x t 's nearest neighborhoods thus entails the following. If we create a binary classification problem and assign q i = 1 if x i is from the source and q i = 0 if x i from the target, then given x i , we cannot determine well above chance level where this instance comes from.\n\nInstead of constructing an actual binary classifier, we express our desideratum as minimizing the mutual information between the data instance X and its (binary) domain label Q. Analogous to eq. (5), the mutual information is given by,\nI st (X; Q) = H[q 0 ] \u2212 1 N + M i H[q i ](6)\nwhereq i is the two-dimensional posterior probability vector of assigning x i to either the source or the target, given all other data points from the two domains. Concretely, the probability is computed according to eq. (3), except the class label \u03b4 jc being replaced by the domain label of x j . The estimated prior distribution q 0 is computed as 1/(N + M) iq i .\n\nOne might wonder why we do not compute and minimize the expected error as in the source domain classification eq. (4). This is because we would like to leave some room for the possibility that a certain portion of data in either domain could be \"outliers\" to the other domain, and thus indeed distinguishable with respect to their origins. Minimizing domain classification error would have the adverse effect of forcing the two domains to be exactly the same. For instance, a degenerate solution would be to map every point to the origin of the feature space.\n\nWe mention in passing that it is found that the accuracy of a binary domain classifier reflects similarities between domains , thus approximating the original intractable combinatorial measure of similarities (Ben-David et al., 2007).\n\n\nLearning and model selection\n\nWe have described three information-theoretical quantities: classification accuracies on the source domain \u03b5 S of eq. (4), discriminative clustering on the target I t (X;\u0176 ) of eq. (5), and discriminability between the source and the target I st (X; Q) of eq. (6).\n\nThese quantities have been derived from our assumptions about the source and target domains, specifically, the discriminative clustering structures. They are all parameterized in the linear transformation L.\n\nWe learn the optimal L by balancing these quantities with the following optimization problem\nminimize \u2212 I t (X;\u0176 ) + \u03bbI st (X; Q) subject to Trace(L T L) \u2264 d(7)\nwhere the constraint is to control the scale of distances computed using L.\n\nThe regularization coefficient \u03bb needs to be crossvalidated. We choose the optimal \u03bb that attains the minimum of \u03b5 S . Intuitively, \u03b5 S is defined on the source domain with labeled data and thus, more sensible to be used for model selection (Other ways of combining these quantities were also experimented, though the above performs the best in practice.)\n\nWe comment briefly on the difference between our formulation and the entropy minimization framework for semi-supervised learning (Grandvalet & Bengio, 2005). Their goal is to reduce uncertainty of labeling the unlabeled data. Thus, they use only the entropy term eq (3). More distinctively, they do not need to make the two domains look alike thus there is no need for them to learn a feature space, nor to include a term to minimize the discriminability between the domains.\n\n\nNumerical Optimization\n\nEq. (7) is non-convex optimization. We use gradientbased methods to optimize the objective function. While in theory the methods are susceptible to local optimum, we use heuristics to initialize: either the PCA of the target domain data, or the low-rank factorization of a discriminatively trained metric on the source data, such as the one in large margin nearest neighbor (LMNN) (Weinberger & Saul, 2009). In most cases, these heuristics work well and lead to substantially improved results over initialization points. Details are described in the Supplementary Material.\n\n\nExtensions\n\nWhen the target domain has a few labeled instance, the domain adaptation problem is referred as semisupervised adaptation. Our approach can be readily extended to incorporate those labeled target domain instances. Details, including experimental results are described in the Supplementary Material.\n\n\nExperimental Results\n\nWe evaluate the proposed method on two benchmark tasks: object recognition and sentiment analysis of product reviews. We compare the method to baselines and other recently proposed ones for unsupervised domain adaptation (Gopalan et al., 2011;Blitzer et al., 2006;Pan et al., 2011). In the Supplementary Material, we report results on semi-supervised adaptation, where the target domain has a few labeled instances.\n\n\nSetup\n\nWe start by describing the datasets for the two tasks.\n\nObject recognition. We use four databases of object images: Caltech-256 (Griffin et al., 2007), Amazon (images from online merchants's catalogues), Webcam (low-resolution images by web cameras), and DSLR (high-resolution images by digital SLR cameras). The last three datasets were studied in (Gopalan et al., 2011;Saenko et al., 2010). Caltech-256 is added to increase the diversity of the domains.\n\nWe treat each dataset as a domain. There are 10 common object categories: backpack, coffee-mug, calculator, computer-keyboard, computer-monitor, computermouse, head-phones, laptop-101, touring-bike, and video-projector. There are 2533 images in total, with 8 to 151 images per category per domain.\n\nFollowing the experimental protocols in previous work (Saenko et al., 2010), we extract SURF features (Bay et al., 2006) and encode each image with a 800bin histogram (the codebook is trained from a subset of Amazon images). The histograms are first normalized to have zero mean and unit standard deviation in each dimension.\n\nFor each pair of source and target domains, we conduct experiments in 20 random trials. In each trial, we randomly sample labeled data in the source domain as the training set, and unlabeled data in the target domain as the testing set. For semi-supervised domain adaptation, we also sample a few labeled examples in the target domain to augment the training set, see the Supplementary Material for details.\n\n\nSentiment analysis.\n\nWe use the dataset that consists of Amazon product reviews on four product types: kitchen appliances, DVDs, books and electronics . Each product type is used as a separate domain. Each domain has 1,000 positive and 1,000 negative reviews. To reduce computational cost, we select top 400 words of the largest mutual information with the labels. We then represent each review with a 400-dimensional vector of term counts (ie, bag-ofwords). The vectors are normalized to have zero mean and unit standard deviation in each dimension.\n\nFor each pair of source and target domains, we conduct experiments in 10 random trials. In each trial, we randomly sample 1,600 labeled data in the source domain as the training set, and all data in the target domain as the testing set.\n\nClassification We learn the feature transformation L by solving the optimization problem eq. (7). We then transform all the data using the matrix and apply 1-nearest neighbor (1-NN) to classify instances from the target domain. 1-NN is used to avoid tuning the number of nearest neighbors. (In the Supplementary Material, we also report results of using SVMs.)\n\nHyperparameter tuning Our method has two hyper-parameters: the dimensionality of the new feature subspace and the regularization coefficient \u03bb in eq. (7). We cross-validate them using the model selection procedure described in section 3.5. The range of search for the dimensionality is {20, 40, 70, 100} and {0, 0.25, 1, 4, 16, 64} for \u03bb.\n\nFor baselines and other methods we have compared to, if there are hyper-parameters to be tuned, we either follow the procedures in those algorithms or give those methods the benefits of doubts by reporting their best performance by using labels from the target domain.\n\n\nResults on unsupervised adaptation\n\nWe compare extensively to several methods.\n\n\u2022 Baselines. We compare to PCA, where we project all data into the PCA directions computed on the target domain. We also compare to LMNN (Weinberger & Saul, 2009), where we train a large margin nearest neighbor classifier using only the source labeled data. Neither of these methods is developed for domain adaptation and their performances on target domains are indeed inferior to other methods, and especially ours. \u2022 Transfer Component Analysis (TCA) (Pan et al., 2011). This method finds a low-dimensional linear projection such that the source and the target domains have similar marginal distributions, regularized by preserving variances in all the data. To measure similarities in marginals, the method maps data to a kernel feature space. We use Gaussian RBF kernels. \u2022 Structural Correspondence Learning (SCL) (Blitzer et al., 2006). This method augments original features with linearly transformed features. The linear transformation is computed as the principal directions of parameters in binary classifiers predicting whether pivot features are present or not. In our experiments, we have used all 400 features as pivot features. We then train SVMs with the augmented feature vectors on the source domains and apply the resulting classifiers to the target domains. \u2022 Geodesic Flow Subspaces (GFS) (Gopalan et al., 2011). This method interpolates (on Grassman manifold) between the PCA subspaces computed on the source and the target domains respectively. The interpolated subspaces are then used to transform the original features to form super-vectors. The dimensionality of the super-vectors is then reduced before applying 1-NN for classification. \u2022 Metric Learning (Metric) (Saenko et al., 2010).\n\nThis method learns a metric measuring the distance between data points using the correspondence information between the source and the target domains. Specifically, the correspondence is defined as data points with the same labels. Thus, this method uses labels from the target domains. Despite that, our results will show our method still outperforms Metric. Table 1 and Table 2 summarize the classification accuracies as well as standard errors of all the above methods, as well as ours (we did not apply SCL to object recognition as it is difficult to define what pivot features are for those types of data). We had chosen a subset of all pairs for saving experiment time. The best performing algorithm(s) (statistical significant up to one standard error) for each pair are in bold font.\n\nIn Table 1 on object recognition, our method performs the best on 5 out of 6 pairs, outperforming other competing methods with a large margin. On the DSLR-Amazon pair, our method performs worse than LMNN, but still significantly better than others.\n\nOf particular interest is that LMNN outperforms other methods specifically designed for domain adaptation (excluding ours). This confirms our hypothesis: the two-stage learning schemes adopted by TCA and GFS suffer from the fallacy that maximizing marginal similarity does not necessarily lead to well-performing classifiers on the target domain. In particular, we believe such methods could actually destroy discriminative information by forcing the domains to be similar.\n\nThe results thus support our argument that onestage learning, namely identifying jointly discriminative clustering and low-dimensional feature spaces, is crucial for domain adaptation.\n\nThe results on sentiment analysis in Table 2 also strongly support similar conclusions. Note that both SCL and our methods outperform other methods significantly. Our methods perform better on 2 out of 4 pairs, thought slightly worse than SCL on the other two. Exploring strengths and weakness of each of these two methods is a subject of future research.\n\n\nRelated Work\n\nInformation-theoretical approach has been applied to semi-supervised learning (Grandvalet & Bengio, 2005) where the core idea is to reduce the confusability (among possible labels) on unlabeled data by classifiers trained on the labeled data. However, they have assumed that the data are drawn from the same distribution so there is no need to learn a domain-invariant feature space.\n\nRastrow et al. described an information-theoretical based criterion for model selection in domain adaptation (Rastrow et al., 2010). Model selection is a challenging problem when cross-validation is not possible due to the lack of labeled data on the target domain. However, their approach is two-stage: they refine model parameters on unlabeled data by minimizing the conditional entropy of the labeling function from the initial model tuned on the labeled source data. Consequently, their formulation does not learn an invariant feature space.\n\nOur work is also related to the recent study of regularized information maximization for discriminative clustering (Gomes et al., 2010). The authors there used a parametric model to compute the posterior probabilities of assigning a data point to various clusters. The objective is to find clustering assignments of all data points such that the mutual information between the data and the cluster ids are maximized. While their work is generalized to semi-supervised clustering, they do not consider domain adaptation, which has fundamentally different goals and constraints from semi-supervised learning, as pointed out previously. In particular, the above-mentioned work does not learn a new feature space.\n\n\nConclusion\n\nWe propose an one-stage approach that jointly learns a domain-invariant feature space and optimizes information-theoretic metrics directly related to dis- criminative classification on the target domain. Our empirical results support the validity of our modeling assumptions that data in both source and target domains are discriminatively clustered. We show that existing approaches where learning feature is decoupled from learning discriminative classifiers, can be significantly improved by taking the clustering structures into consideration. For future work, we plan to study discriminatively learning of nonlinear feature transformation for domain adaptation.\n\nTable 1 .\n1Classification accuracies on target domains with unsupervised adaptation Amazon \u2192 Webcam 33.1\u00b10.6 26.5\u00b10.8 32.8\u00b10.7Domains \nPCA \nTCA \nGFS \nLMNN \nMetric \nOurs \nDSLR \u2192 Webcam \n80.6\u00b10.5 66.2\u00b10.5 75.5\u00b10.4 \n81.3\u00b10.4 \n55.6\u00b10.7 83.6\u00b10.5 \nDSLR \u2192 Amazon \n35.1\u00b10.3 31.4\u00b10.2 35.7\u00b10.5 42.3\u00b10.3 30.3\u00b10.8 \n39.6\u00b10.4 \nCaltech \u2192 DSLR \n36.6\u00b11.2 33.1\u00b10.8 36.5\u00b10.9 \n37.2\u00b11.1 \n35.0\u00b11.1 44.4\u00b11.2 \nCaltech \u2192 Amazon \n37.7\u00b10.5 34.9\u00b10.4 37.9\u00b10.5 \n43.2\u00b10.4 \n33.7\u00b10.8 49.2\u00b10.6 \n35.2\u00b10.8 \n36.0\u00b11.0 38.5\u00b11.3 \nAmazon \u2192 Caltech \n35.9\u00b10.3 29.3\u00b10.3 36.1\u00b10.5 \n37.6\u00b10.4 \n27.3\u00b10.7 40.0\u00b10.4 \n\n\n\nTable 2 .\n2Classification accuracies on target domains with unsupervised adaptation 7\u00b10.7 67.2\u00b11.0 69.2\u00b10.6 79.2\u00b10.9 Electronics \u2192 Kitchen 71.8\u00b10.4 84.5\u00b10.5 69.5\u00b10.7 75.8\u00b11.2 77.3\u00b10.6 82.9\u00b10.5Domains \nPCA \nSCL \nTCA \nGFS \nLMNN \nOurs \nKitchen \u2192 DVD \n66.1\u00b10.7 \n73.2\u00b10.6 \n64.9\u00b10.5 67.9\u00b11.0 70.8\u00b10.5 75.4\u00b10.6 \nDVD \u2192 Books \n66.4\u00b10.4 79.2\u00b10.4 \n64\u00b10.7 \n70.8\u00b10.6 71.7\u00b10.6 \n78.4\u00b10.5 \nBooks \u2192 Electronics \n63.6\u00b10.9 \n75.6\u00b10.6 \n62.\nAcknowlegementsThis work was partially supported by DARPA D11AP00278, NSF IIS-1065243 and a USC Annenberg Fellowship (Y. Shi).\nH Bay, T Tuytelaars, L Van Gool, Surf, Speeded up robust features. ECCV. Bay, H., Tuytelaars, T., and Van Gool, L. SURF: Speeded up robust features. ECCV, 2006.\n\nAnalysis of representations for domain adaptation. NIPS. S Ben-David, J Blitzer, K Crammer, F Pereira, Ben-David, S., Blitzer, J., Crammer, K., and Pereira, F. Analysis of representations for domain adaptation. NIPS, 2007.\n\nDiscriminative learning for differing training and test distributions. S Bickel, M Br\u00fcckner, T Scheffer, Prof. of ICML. Bickel, S., Br\u00fcckner, M., and Scheffer, T. Discriminative learning for differing training and test distributions. In Prof. of ICML, pp. 81-88, 2007.\n\nDomain adaptation with structural correspondence learning. J Blitzer, R Mcdonald, F Pereira, Proc. of EMNLP. of EMNLPAssociation for Computational LinguisticsBlitzer, J., McDonald, R., and Pereira, F. Domain adap- tation with structural correspondence learning. In Proc. of EMNLP, pp. 120-128. Association for Computational Linguistics, 2006.\n\nBiographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification. J Blitzer, M Dredze, F Pereira, Proc. of ACL. of ACLBlitzer, J., Dredze, M., and Pereira, F. Biographies, bol- lywood, boom-boxes and blenders: Domain adaptation for sentiment classification. In Proc. of ACL, 2007.\n\nSemi-supervised learning. O Chapelle, B Sch\u00f6lkopf, A Zien, MIT press2Cambridge, MAChapelle, O., Sch\u00f6lkopf, B., Zien, A., et al. Semi-supervised learning, volume 2. MIT press Cambridge, MA:, 2006.\n\nDomain adaptation for statistical classifiers. Iii Daum\u00e9, H Marcu, D , JAIR. 26Daum\u00e9 III, H. and Marcu, D. Domain adaptation for sta- tistical classifiers. JAIR, 26:101-126, 2006.\n\nInformationtheoretic co-clustering. I S Dhillon, S Mallela, D S Modha, Proc. of SIGKDD. of SIGKDDDhillon, I.S., Mallela, S., and Modha, D.S. Information- theoretic co-clustering. In Proc. of SIGKDD, 2003.\n\nA methodology for information theoretic feature extraction. Iii Fisher, J W Principe, J C , Proc. IEEE World Congress on Comp. Intell. IEEE World Congress on Comp. IntellFisher III, J.W. and Principe, J.C. A methodology for information theoretic feature extraction. In Proc. IEEE World Congress on Comp. Intell., 1998.\n\nDomain adaptation for large-scale sentiment classification: A deep learning approach. X Glorot, A Bordes, Y Bengio, Proc. of ICML. of ICMLGlorot, X., Bordes, A., and Bengio, Y. Domain adaptation for large-scale sentiment classification: A deep learning approach. In Proc. of ICML, 2011.\n\n. J Goldberger, S Roweis, G Hinton, R Salakhutdinov, Neighbourhood components analysis. NIPSGoldberger, J., Roweis, S., Hinton, G., and Salakhutdinov, R. Neighbourhood components analysis. NIPS, 2004.\n\nDiscriminative clustering by regularized information maximization. R Gomes, A Krause, P Perona, NIP. Gomes, R., Krause, A., and Perona, P. Discriminative clustering by regularized information maximization. In NIP, 2010.\n\nDomain adaptation for object recognition: An unsupervised approach. R Gopalan, R Li, R Chellappa, Proc. of ICCV. of ICCVGopalan, R., Li, R., and Chellappa, R. Domain adaptation for object recognition: An unsupervised approach. In Proc. of ICCV, 2011.\n\nSemi-supervised learning by entropy minimization. Y Grandvalet, Y Bengio, NIPS. 17Grandvalet, Y. and Bengio, Y. Semi-supervised learning by entropy minimization. NIPS, 17:529-236, 2005.\n\nCaltech-256 object category dataset. G Griffin, A Holub, P Perona, California Institute of TechnologyTechnical reportGriffin, G., Holub, A., and Perona, P. Caltech-256 object category dataset. Technical report, California Institute of Technology, 2007.\n\nStochastic neighbor embedding. G Hinton, S T Roweis, Advances in neural information processing systems. 15Hinton, G. and Roweis, S.T. Stochastic neighbor embed- ding. Advances in neural information processing sys- tems, 15:833-840, 2002.\n\nCorrecting sample selection bias by unlabeled data. J Huang, A J Smola, A Gretton, K M Borgwardt, B Scholkopf, NIPS. 19601Huang, J., Smola, A.J., Gretton, A., Borgwardt, K.M., and Scholkopf, B. Correcting sample selection bias by unlabeled data. NIPS, 19:601, 2007.\n\nWhat you saw is not what you get: Domain adaptation using asymmetric kernel transforms. B Kulis, K Saenko, Darrell , T , Proc. of CVPR. of CVPRKulis, B., Saenko, K., and Darrell, T. What you saw is not what you get: Domain adaptation using asymmetric kernel transforms. In Proc. of CVPR, 2011.\n\nDomain adaptation: Learning bounds and algorithms. Y Mansour, M Mohri, A Rostamizadeh, Proc. of COLT. of COLTMansour, Y., Mohri, M., and Rostamizadeh, A. Domain adaptation: Learning bounds and algorithms. Proc. of COLT, 2009.\n\nA survey on transfer learning. S J Pan, Q Yang, IEEE Trans. on Knowl. Engi. 2210Pan, S.J. and Yang, Q. A survey on transfer learning. IEEE Trans. on Knowl. Engi., 22(10):1345-1359, 2010.\n\nDomain adaptation via transfer component analysis. S J Pan, I W Tsang, J T Kwok, Yang , Q , IEEE Trans. Neur. Nets. 222199Pan, S.J., Tsang, I.W., Kwok, J.T., and Yang, Q. Do- main adaptation via transfer component analysis. IEEE Trans. Neur. Nets., 22(2):199, 2011.\n\nDataset Shift in Machine Learning. J Qui\u00f1onero-Candela, M Sugiyama, A Schwaighofer, The MIT PressQui\u00f1onero-Candela, J., Sugiyama, M., and Schwaighofer, A. Dataset Shift in Machine Learning. The MIT Press, 2009.\n\nUnsupervised model adaptation using informationtheoretic criterion. A Rastrow, F Jelinek, A Sethy, B Ramabhadran, Proc. HLT-NAACL. HLT-NAACLRastrow, A., Jelinek, F., Sethy, A., and Ramabhadran, B. Unsupervised model adaptation using information- theoretic criterion. In Proc. HLT-NAACL, 2010.\n\nAdapting visual category models to new domains. K Saenko, B Kulis, M Fritz, Darrell , T , Proc. of ECCV. of ECCVSaenko, K., Kulis, B., Fritz, M., and Darrell, T. Adapt- ing visual category models to new domains. In Proc. of ECCV, 2010.\n\nImproving predictive inference under covariate shift by weighting the log-likelihood function. H Shimodaira, J. of Stat. Plan. and Infer. 902Shimodaira, H. Improving predictive inference under co- variate shift by weighting the log-likelihood function. J. of Stat. Plan. and Infer., 90(2):227-244, 2000.\n\nDistance metric learning for large margin nearest neighbor classification. K Q Weinberger, L K Saul, JMLR. 10Weinberger, K.Q. and Saul, L.K. Distance metric learning for large margin nearest neighbor classification. JMLR, 10:207-244, 2009.\n", "annotations": {"author": "[{\"end\":227,\"start\":98},{\"end\":355,\"start\":228}]", "publisher": null, "author_last_name": "[{\"end\":106,\"start\":103},{\"end\":235,\"start\":232}]", "author_first_name": "[{\"end\":102,\"start\":98},{\"end\":231,\"start\":228}]", "author_affiliation": "[{\"end\":226,\"start\":124},{\"end\":354,\"start\":252}]", "title": "[{\"end\":95,\"start\":1},{\"end\":450,\"start\":356}]", "venue": null, "abstract": "[{\"end\":1491,\"start\":452}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b6\"},\"end\":2397,\"start\":2372},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":2414,\"start\":2397},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":2445,\"start\":2414},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3168,\"start\":3145},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":3577,\"start\":3559},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3597,\"start\":3577},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":3616,\"start\":3597},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":4090,\"start\":4072},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":4111,\"start\":4090},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":4311,\"start\":4289},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":4559,\"start\":4538},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":5139,\"start\":5115},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":5160,\"start\":5139},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":11436,\"start\":11416},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":13411,\"start\":13386},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":13461,\"start\":13438},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":14647,\"start\":14622},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":16836,\"start\":16816},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":16857,\"start\":16836},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":17049,\"start\":17020},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":19895,\"start\":19871},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":21155,\"start\":21128},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":21906,\"start\":21882},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":22655,\"start\":22633},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":22676,\"start\":22655},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":22693,\"start\":22676},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":22987,\"start\":22965},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":23208,\"start\":23186},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":23228,\"start\":23208},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":23668,\"start\":23647},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":23713,\"start\":23695},{\"end\":25808,\"start\":25768},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":26335,\"start\":26310},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":26645,\"start\":26627},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":27015,\"start\":26993},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":27506,\"start\":27484},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":27886,\"start\":27865},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":30070,\"start\":30043},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":30481,\"start\":30459},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":31032,\"start\":31012}]", "figure": "[{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":32855,\"start\":32288},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":33275,\"start\":32856}]", "paragraph": "[{\"end\":2224,\"start\":1507},{\"end\":2695,\"start\":2226},{\"end\":3336,\"start\":2697},{\"end\":4021,\"start\":3338},{\"end\":4560,\"start\":4023},{\"end\":5161,\"start\":4562},{\"end\":6192,\"start\":5163},{\"end\":6619,\"start\":6194},{\"end\":7637,\"start\":6633},{\"end\":7996,\"start\":7639},{\"end\":8618,\"start\":7998},{\"end\":9931,\"start\":8670},{\"end\":10034,\"start\":9933},{\"end\":10353,\"start\":10036},{\"end\":10552,\"start\":10355},{\"end\":10978,\"start\":10554},{\"end\":11437,\"start\":11000},{\"end\":11688,\"start\":11439},{\"end\":12112,\"start\":11690},{\"end\":12539,\"start\":12114},{\"end\":12863,\"start\":12583},{\"end\":12955,\"start\":12865},{\"end\":13104,\"start\":13017},{\"end\":13183,\"start\":13106},{\"end\":13298,\"start\":13219},{\"end\":13682,\"start\":13300},{\"end\":13936,\"start\":13709},{\"end\":14468,\"start\":13980},{\"end\":14648,\"start\":14499},{\"end\":14883,\"start\":14692},{\"end\":15440,\"start\":14885},{\"end\":15825,\"start\":15442},{\"end\":16088,\"start\":15827},{\"end\":16377,\"start\":16090},{\"end\":16662,\"start\":16418},{\"end\":17050,\"start\":16664},{\"end\":17460,\"start\":17093},{\"end\":18135,\"start\":17462},{\"end\":18450,\"start\":18137},{\"end\":18687,\"start\":18452},{\"end\":19099,\"start\":18733},{\"end\":19660,\"start\":19101},{\"end\":19896,\"start\":19662},{\"end\":20193,\"start\":19929},{\"end\":20402,\"start\":20195},{\"end\":20496,\"start\":20404},{\"end\":20640,\"start\":20565},{\"end\":20997,\"start\":20642},{\"end\":21474,\"start\":20999},{\"end\":22074,\"start\":21501},{\"end\":22387,\"start\":22089},{\"end\":22827,\"start\":22412},{\"end\":22891,\"start\":22837},{\"end\":23292,\"start\":22893},{\"end\":23591,\"start\":23294},{\"end\":23918,\"start\":23593},{\"end\":24327,\"start\":23920},{\"end\":24880,\"start\":24351},{\"end\":25118,\"start\":24882},{\"end\":25480,\"start\":25120},{\"end\":25820,\"start\":25482},{\"end\":26090,\"start\":25822},{\"end\":26171,\"start\":26129},{\"end\":27887,\"start\":26173},{\"end\":28680,\"start\":27889},{\"end\":28930,\"start\":28682},{\"end\":29405,\"start\":28932},{\"end\":29591,\"start\":29407},{\"end\":29948,\"start\":29593},{\"end\":30348,\"start\":29965},{\"end\":30895,\"start\":30350},{\"end\":31606,\"start\":30897},{\"end\":32287,\"start\":31621}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":13016,\"start\":12956},{\"attributes\":{\"id\":\"formula_1\"},\"end\":13218,\"start\":13184},{\"attributes\":{\"id\":\"formula_2\"},\"end\":13708,\"start\":13683},{\"attributes\":{\"id\":\"formula_3\"},\"end\":14498,\"start\":14469},{\"attributes\":{\"id\":\"formula_4\"},\"end\":16417,\"start\":16378},{\"attributes\":{\"id\":\"formula_5\"},\"end\":18732,\"start\":18688},{\"attributes\":{\"id\":\"formula_6\"},\"end\":20564,\"start\":20497}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":28256,\"start\":28249},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":28268,\"start\":28261},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":28692,\"start\":28685},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":29637,\"start\":29630}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":1505,\"start\":1493},{\"end\":6631,\"start\":6622},{\"attributes\":{\"n\":\"2.\"},\"end\":8668,\"start\":8621},{\"attributes\":{\"n\":\"3.\"},\"end\":10998,\"start\":10981},{\"attributes\":{\"n\":\"3.1.\"},\"end\":12581,\"start\":12542},{\"attributes\":{\"n\":\"3.2.\"},\"end\":13978,\"start\":13939},{\"attributes\":{\"n\":\"3.3.\"},\"end\":14690,\"start\":14651},{\"attributes\":{\"n\":\"3.4.\"},\"end\":17091,\"start\":17053},{\"attributes\":{\"n\":\"3.5.\"},\"end\":19927,\"start\":19899},{\"attributes\":{\"n\":\"3.6.\"},\"end\":21499,\"start\":21477},{\"attributes\":{\"n\":\"3.7.\"},\"end\":22087,\"start\":22077},{\"attributes\":{\"n\":\"4.\"},\"end\":22410,\"start\":22390},{\"attributes\":{\"n\":\"4.1.\"},\"end\":22835,\"start\":22830},{\"end\":24349,\"start\":24330},{\"attributes\":{\"n\":\"4.2.\"},\"end\":26127,\"start\":26093},{\"attributes\":{\"n\":\"5.\"},\"end\":29963,\"start\":29951},{\"attributes\":{\"n\":\"6.\"},\"end\":31619,\"start\":31609},{\"end\":32298,\"start\":32289},{\"end\":32866,\"start\":32857}]", "table": "[{\"end\":32855,\"start\":32415},{\"end\":33275,\"start\":33049}]", "figure_caption": "[{\"end\":32415,\"start\":32300},{\"end\":33049,\"start\":32868}]", "figure_ref": "[{\"end\":9048,\"start\":9040},{\"end\":9954,\"start\":9948}]", "bib_author_first_name": "[{\"end\":33404,\"start\":33403},{\"end\":33411,\"start\":33410},{\"end\":33425,\"start\":33424},{\"end\":33623,\"start\":33622},{\"end\":33636,\"start\":33635},{\"end\":33647,\"start\":33646},{\"end\":33658,\"start\":33657},{\"end\":33861,\"start\":33860},{\"end\":33871,\"start\":33870},{\"end\":33883,\"start\":33882},{\"end\":34119,\"start\":34118},{\"end\":34130,\"start\":34129},{\"end\":34142,\"start\":34141},{\"end\":34501,\"start\":34500},{\"end\":34512,\"start\":34511},{\"end\":34522,\"start\":34521},{\"end\":34743,\"start\":34742},{\"end\":34755,\"start\":34754},{\"end\":34768,\"start\":34767},{\"end\":34963,\"start\":34960},{\"end\":34972,\"start\":34971},{\"end\":34981,\"start\":34980},{\"end\":35131,\"start\":35130},{\"end\":35133,\"start\":35132},{\"end\":35144,\"start\":35143},{\"end\":35155,\"start\":35154},{\"end\":35157,\"start\":35156},{\"end\":35363,\"start\":35360},{\"end\":35373,\"start\":35372},{\"end\":35375,\"start\":35374},{\"end\":35387,\"start\":35386},{\"end\":35389,\"start\":35388},{\"end\":35707,\"start\":35706},{\"end\":35717,\"start\":35716},{\"end\":35727,\"start\":35726},{\"end\":35911,\"start\":35910},{\"end\":35925,\"start\":35924},{\"end\":35935,\"start\":35934},{\"end\":35945,\"start\":35944},{\"end\":36178,\"start\":36177},{\"end\":36187,\"start\":36186},{\"end\":36197,\"start\":36196},{\"end\":36400,\"start\":36399},{\"end\":36411,\"start\":36410},{\"end\":36417,\"start\":36416},{\"end\":36634,\"start\":36633},{\"end\":36648,\"start\":36647},{\"end\":36808,\"start\":36807},{\"end\":36819,\"start\":36818},{\"end\":36828,\"start\":36827},{\"end\":37056,\"start\":37055},{\"end\":37066,\"start\":37065},{\"end\":37068,\"start\":37067},{\"end\":37316,\"start\":37315},{\"end\":37325,\"start\":37324},{\"end\":37327,\"start\":37326},{\"end\":37336,\"start\":37335},{\"end\":37347,\"start\":37346},{\"end\":37349,\"start\":37348},{\"end\":37362,\"start\":37361},{\"end\":37619,\"start\":37618},{\"end\":37628,\"start\":37627},{\"end\":37644,\"start\":37637},{\"end\":37648,\"start\":37647},{\"end\":37877,\"start\":37876},{\"end\":37888,\"start\":37887},{\"end\":37897,\"start\":37896},{\"end\":38084,\"start\":38083},{\"end\":38086,\"start\":38085},{\"end\":38093,\"start\":38092},{\"end\":38292,\"start\":38291},{\"end\":38294,\"start\":38293},{\"end\":38301,\"start\":38300},{\"end\":38303,\"start\":38302},{\"end\":38312,\"start\":38311},{\"end\":38314,\"start\":38313},{\"end\":38325,\"start\":38321},{\"end\":38329,\"start\":38328},{\"end\":38543,\"start\":38542},{\"end\":38564,\"start\":38563},{\"end\":38576,\"start\":38575},{\"end\":38788,\"start\":38787},{\"end\":38799,\"start\":38798},{\"end\":38810,\"start\":38809},{\"end\":38819,\"start\":38818},{\"end\":39062,\"start\":39061},{\"end\":39072,\"start\":39071},{\"end\":39081,\"start\":39080},{\"end\":39096,\"start\":39089},{\"end\":39100,\"start\":39099},{\"end\":39346,\"start\":39345},{\"end\":39631,\"start\":39630},{\"end\":39633,\"start\":39632},{\"end\":39647,\"start\":39646},{\"end\":39649,\"start\":39648}]", "bib_author_last_name": "[{\"end\":33408,\"start\":33405},{\"end\":33422,\"start\":33412},{\"end\":33434,\"start\":33426},{\"end\":33440,\"start\":33436},{\"end\":33633,\"start\":33624},{\"end\":33644,\"start\":33637},{\"end\":33655,\"start\":33648},{\"end\":33666,\"start\":33659},{\"end\":33868,\"start\":33862},{\"end\":33880,\"start\":33872},{\"end\":33892,\"start\":33884},{\"end\":34127,\"start\":34120},{\"end\":34139,\"start\":34131},{\"end\":34150,\"start\":34143},{\"end\":34509,\"start\":34502},{\"end\":34519,\"start\":34513},{\"end\":34530,\"start\":34523},{\"end\":34752,\"start\":34744},{\"end\":34765,\"start\":34756},{\"end\":34773,\"start\":34769},{\"end\":34969,\"start\":34964},{\"end\":34978,\"start\":34973},{\"end\":35141,\"start\":35134},{\"end\":35152,\"start\":35145},{\"end\":35163,\"start\":35158},{\"end\":35370,\"start\":35364},{\"end\":35384,\"start\":35376},{\"end\":35714,\"start\":35708},{\"end\":35724,\"start\":35718},{\"end\":35734,\"start\":35728},{\"end\":35922,\"start\":35912},{\"end\":35932,\"start\":35926},{\"end\":35942,\"start\":35936},{\"end\":35959,\"start\":35946},{\"end\":36184,\"start\":36179},{\"end\":36194,\"start\":36188},{\"end\":36204,\"start\":36198},{\"end\":36408,\"start\":36401},{\"end\":36414,\"start\":36412},{\"end\":36427,\"start\":36418},{\"end\":36645,\"start\":36635},{\"end\":36655,\"start\":36649},{\"end\":36816,\"start\":36809},{\"end\":36825,\"start\":36820},{\"end\":36835,\"start\":36829},{\"end\":37063,\"start\":37057},{\"end\":37075,\"start\":37069},{\"end\":37322,\"start\":37317},{\"end\":37333,\"start\":37328},{\"end\":37344,\"start\":37337},{\"end\":37359,\"start\":37350},{\"end\":37372,\"start\":37363},{\"end\":37625,\"start\":37620},{\"end\":37635,\"start\":37629},{\"end\":37885,\"start\":37878},{\"end\":37894,\"start\":37889},{\"end\":37910,\"start\":37898},{\"end\":38090,\"start\":38087},{\"end\":38098,\"start\":38094},{\"end\":38298,\"start\":38295},{\"end\":38309,\"start\":38304},{\"end\":38319,\"start\":38315},{\"end\":38561,\"start\":38544},{\"end\":38573,\"start\":38565},{\"end\":38589,\"start\":38577},{\"end\":38796,\"start\":38789},{\"end\":38807,\"start\":38800},{\"end\":38816,\"start\":38811},{\"end\":38831,\"start\":38820},{\"end\":39069,\"start\":39063},{\"end\":39078,\"start\":39073},{\"end\":39087,\"start\":39082},{\"end\":39357,\"start\":39347},{\"end\":39644,\"start\":39634},{\"end\":39654,\"start\":39650}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":33563,\"start\":33403},{\"attributes\":{\"id\":\"b1\"},\"end\":33787,\"start\":33565},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":15781767},\"end\":34057,\"start\":33789},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":15978939},\"end\":34401,\"start\":34059},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":14688775},\"end\":34714,\"start\":34403},{\"attributes\":{\"id\":\"b5\"},\"end\":34911,\"start\":34716},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":14154185},\"end\":35092,\"start\":34913},{\"attributes\":{\"id\":\"b7\"},\"end\":35298,\"start\":35094},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":14701519},\"end\":35618,\"start\":35300},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":18235792},\"end\":35906,\"start\":35620},{\"attributes\":{\"id\":\"b10\"},\"end\":36108,\"start\":35908},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":2906843},\"end\":36329,\"start\":36110},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":10337178},\"end\":36581,\"start\":36331},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":7890982},\"end\":36768,\"start\":36583},{\"attributes\":{\"id\":\"b14\"},\"end\":37022,\"start\":36770},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":20240},\"end\":37261,\"start\":37024},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":70831},\"end\":37528,\"start\":37263},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":7419723},\"end\":37823,\"start\":37530},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":6178817},\"end\":38050,\"start\":37825},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":740063},\"end\":38238,\"start\":38052},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":788838},\"end\":38505,\"start\":38240},{\"attributes\":{\"id\":\"b21\"},\"end\":38717,\"start\":38507},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":1399447},\"end\":39011,\"start\":38719},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":7534823},\"end\":39248,\"start\":39013},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":9238949},\"end\":39553,\"start\":39250},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":47325215},\"end\":39794,\"start\":39555}]", "bib_title": "[{\"end\":33858,\"start\":33789},{\"end\":34116,\"start\":34059},{\"end\":34498,\"start\":34403},{\"end\":34958,\"start\":34913},{\"end\":35128,\"start\":35094},{\"end\":35358,\"start\":35300},{\"end\":35704,\"start\":35620},{\"end\":36175,\"start\":36110},{\"end\":36397,\"start\":36331},{\"end\":36631,\"start\":36583},{\"end\":37053,\"start\":37024},{\"end\":37313,\"start\":37263},{\"end\":37616,\"start\":37530},{\"end\":37874,\"start\":37825},{\"end\":38081,\"start\":38052},{\"end\":38289,\"start\":38240},{\"end\":38785,\"start\":38719},{\"end\":39059,\"start\":39013},{\"end\":39343,\"start\":39250},{\"end\":39628,\"start\":39555}]", "bib_author": "[{\"end\":33410,\"start\":33403},{\"end\":33424,\"start\":33410},{\"end\":33436,\"start\":33424},{\"end\":33442,\"start\":33436},{\"end\":33635,\"start\":33622},{\"end\":33646,\"start\":33635},{\"end\":33657,\"start\":33646},{\"end\":33668,\"start\":33657},{\"end\":33870,\"start\":33860},{\"end\":33882,\"start\":33870},{\"end\":33894,\"start\":33882},{\"end\":34129,\"start\":34118},{\"end\":34141,\"start\":34129},{\"end\":34152,\"start\":34141},{\"end\":34511,\"start\":34500},{\"end\":34521,\"start\":34511},{\"end\":34532,\"start\":34521},{\"end\":34754,\"start\":34742},{\"end\":34767,\"start\":34754},{\"end\":34775,\"start\":34767},{\"end\":34971,\"start\":34960},{\"end\":34980,\"start\":34971},{\"end\":34984,\"start\":34980},{\"end\":35143,\"start\":35130},{\"end\":35154,\"start\":35143},{\"end\":35165,\"start\":35154},{\"end\":35372,\"start\":35360},{\"end\":35386,\"start\":35372},{\"end\":35392,\"start\":35386},{\"end\":35716,\"start\":35706},{\"end\":35726,\"start\":35716},{\"end\":35736,\"start\":35726},{\"end\":35924,\"start\":35910},{\"end\":35934,\"start\":35924},{\"end\":35944,\"start\":35934},{\"end\":35961,\"start\":35944},{\"end\":36186,\"start\":36177},{\"end\":36196,\"start\":36186},{\"end\":36206,\"start\":36196},{\"end\":36410,\"start\":36399},{\"end\":36416,\"start\":36410},{\"end\":36429,\"start\":36416},{\"end\":36647,\"start\":36633},{\"end\":36657,\"start\":36647},{\"end\":36818,\"start\":36807},{\"end\":36827,\"start\":36818},{\"end\":36837,\"start\":36827},{\"end\":37065,\"start\":37055},{\"end\":37077,\"start\":37065},{\"end\":37324,\"start\":37315},{\"end\":37335,\"start\":37324},{\"end\":37346,\"start\":37335},{\"end\":37361,\"start\":37346},{\"end\":37374,\"start\":37361},{\"end\":37627,\"start\":37618},{\"end\":37637,\"start\":37627},{\"end\":37647,\"start\":37637},{\"end\":37651,\"start\":37647},{\"end\":37887,\"start\":37876},{\"end\":37896,\"start\":37887},{\"end\":37912,\"start\":37896},{\"end\":38092,\"start\":38083},{\"end\":38100,\"start\":38092},{\"end\":38300,\"start\":38291},{\"end\":38311,\"start\":38300},{\"end\":38321,\"start\":38311},{\"end\":38328,\"start\":38321},{\"end\":38332,\"start\":38328},{\"end\":38563,\"start\":38542},{\"end\":38575,\"start\":38563},{\"end\":38591,\"start\":38575},{\"end\":38798,\"start\":38787},{\"end\":38809,\"start\":38798},{\"end\":38818,\"start\":38809},{\"end\":38833,\"start\":38818},{\"end\":39071,\"start\":39061},{\"end\":39080,\"start\":39071},{\"end\":39089,\"start\":39080},{\"end\":39099,\"start\":39089},{\"end\":39103,\"start\":39099},{\"end\":39359,\"start\":39345},{\"end\":39646,\"start\":39630},{\"end\":39656,\"start\":39646}]", "bib_venue": "[{\"end\":33474,\"start\":33442},{\"end\":33620,\"start\":33565},{\"end\":33907,\"start\":33894},{\"end\":34166,\"start\":34152},{\"end\":34544,\"start\":34532},{\"end\":34740,\"start\":34716},{\"end\":34988,\"start\":34984},{\"end\":35180,\"start\":35165},{\"end\":35433,\"start\":35392},{\"end\":35749,\"start\":35736},{\"end\":36209,\"start\":36206},{\"end\":36442,\"start\":36429},{\"end\":36661,\"start\":36657},{\"end\":36805,\"start\":36770},{\"end\":37126,\"start\":37077},{\"end\":37378,\"start\":37374},{\"end\":37664,\"start\":37651},{\"end\":37925,\"start\":37912},{\"end\":38126,\"start\":38100},{\"end\":38354,\"start\":38332},{\"end\":38540,\"start\":38507},{\"end\":38848,\"start\":38833},{\"end\":39116,\"start\":39103},{\"end\":39386,\"start\":39359},{\"end\":39660,\"start\":39656},{\"end\":34176,\"start\":34168},{\"end\":34552,\"start\":34546},{\"end\":35191,\"start\":35182},{\"end\":35470,\"start\":35435},{\"end\":35758,\"start\":35751},{\"end\":36451,\"start\":36444},{\"end\":37673,\"start\":37666},{\"end\":37934,\"start\":37927},{\"end\":38859,\"start\":38850},{\"end\":39125,\"start\":39118}]"}}}, "year": 2023, "month": 12, "day": 17}