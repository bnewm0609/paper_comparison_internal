{"id": 212725167, "updated": "2023-11-08 13:32:30.971", "metadata": {"title": "Mix-n-Match: Ensemble and Compositional Methods for Uncertainty Calibration in Deep Learning", "authors": "[{\"first\":\"Jize\",\"last\":\"Zhang\",\"middle\":[]},{\"first\":\"Bhavya\",\"last\":\"Kailkhura\",\"middle\":[]},{\"first\":\"T.\",\"last\":\"Han\",\"middle\":[\"Yong-Jin\"]}]", "venue": "ArXiv", "journal": "ArXiv", "publication_date": {"year": 2020, "month": 3, "day": 16}, "abstract": "This paper studies the problem of post-hoc calibration of machine learning classifiers. We introduce the following desiderata for uncertainty calibration: (a) accuracy-preserving, (b) data-efficient, and (c) high expressive power. We show that none of the existing methods satisfy all three requirements, and demonstrate how Mix-n-Match calibration strategies (i.e., ensemble and composition) can help achieve remarkably better data-efficiency and expressive power while provably preserving classification accuracy of the original classifier. We also show that existing calibration error estimators (e.g., histogram-based ECE) are unreliable especially in small-data regime. Therefore, we propose an alternative data-efficient kernel density-based estimator for a reliable evaluation of the calibration performance and prove its asymptotically unbiasedness and consistency.", "fields_of_study": "[\"Computer Science\",\"Mathematics\"]", "external_ids": {"arxiv": "2003.07329", "mag": "3034905393", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/icml/ZhangKH20", "doi": null}}, "content": {"source": {"pdf_hash": "aa5a4433aa08834a69b4afb7917b1c7107a529a6", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2003.07329v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "6d8b473bf8a54fe4a1ad163a41f5359221b581ca", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/aa5a4433aa08834a69b4afb7917b1c7107a529a6.txt", "contents": "\nMix-n-Match: Ensemble and Compositional Methods for Uncertainty Calibration in Deep Learning\n\n\nJize Zhang \nBhavya Kailkhura \nT \nYong-Jin Han \nMix-n-Match: Ensemble and Compositional Methods for Uncertainty Calibration in Deep Learning\n\nThis paper studies the problem of post-hoc calibration of machine learning classifiers. We introduce the following desiderata for uncertainty calibration: (a) accuracy-preserving, (b) data-efficient, and (c) high expressive power. We show that none of the existing methods satisfy all three requirements, and demonstrate how Mix-n-Match calibration strategies (i.e., ensemble and composition) can help achieve remarkably better dataefficiency and expressive power while provably preserving classification accuracy of the original classifier. We also show that existing calibration error estimators (e.g., histogram-based ECE) are unreliable especially in small-data regime. Therefore, we propose an alternative data-efficient kernel density-based estimator for a reliable evaluation of the calibration performance and prove its asymptotically unbiasedness and consistency.\n\nIntroduction\n\nMachine learning (ML) models, e.g., deep neural networks, are increasingly used for making potentially important decisions in applications ranging from object detection (Girshick, 2015), autonomous driving (Chen et al., 2015) to medical diagnosis (Litjens et al., 2017). Several of these applications are high-regret in nature and incorrect decisions have significant costs. Therefore, besides achieving high accuracy, it is also crucial to obtain reliable uncertainty estimates, which can help deciding whether the model predictions can be trusted (Jiang et al., 2018;Kendall & Gal, 2017). Specifically, a classifier should provide a calibrated uncertainty measure in addition to its prediction. A classifier is well-calibrated, if the probability associated with the predicted class label matches the probability of such prediction being correct (Br\u00f6cker, 2009;Dawid, 1982). Unfortunately, many off-the-shelf ML models are not well calibrated (Niculescu-Mizil & Caruana, 2005 (Guo et al., 2017) is data-efficient (initial rapid ECE drop) but not expressive (fails to make progress later); in contrast, Isotonic Regression (IR) (Zadrozny & Elkan, 2002) is more expressive but data-inefficient; (right) IR does not preserve accuracy and introduces significant degradation. (Bottom) Mix-n-Match: (left) Data Ensemble and Composition improve the data efficiency of IR, and (right) Model Ensemble enhances the expressive power of TS. All results are for calibrating a 50-layer Wide ResNet on ImageNet, apart from (a) left (28-layer Wide ResNet on CIFAR-10). Elkan, 2001;2002). Poor-calibration is particularly prominent in highly complex models such as deep neural network classifiers (Guo et al., 2017;Hein et al., 2019;Lakshminarayanan et al., 2017;Nguyen et al., 2015).\n\nA popular calibration approach is to learn a transformation (referred to as a calibration map) of the trained classifier's predictions on a calibration dataset in a post-hoc manner. Pioneering work along this direction include Platt scaling (Platt, 2000), histogram binning (Zadrozny & Elkan, 2001), isotonic regression (Zadrozny & Elkan, 2002), Bayesian binning into quantiles (Naeini et al., 2015). Recently, calibration methods for multi-class deep neural network clas-arXiv:2003.07329v1 [cs.LG] 16 Mar 2020 sifiers have been developed, which include: temperature, vector & matrix scaling (Guo et al., 2017), Dirichlet scaling (Kull et al., 2019), and Gaussian processes based calibration method (Milios et al., 2018;Wenger et al., 2019). Besides post-hoc calibrations, there also exist approaches for training ab-initio well calibrated models (Kumar et al., 2018;Lakshminarayanan et al., 2017;Pereyra et al., 2017;Seo et al., 2019;Tran et al., 2019), or representing the prediction uncertainty in a Bayesian framework (Blundell et al., 2015;Gal & Ghahramani, 2016;Maddox et al., 2019).\n\nIdeally, an uncertainty calibration method should satisfy the following properties: (a) accuracy-preserving -calibration process should not degrade the classification accuracy of the original classifier, (b) data-efficiency -the ability to achieve well-calibration without requiring a large amount of calibration data, and (c) high expressive power -the ability to approximate true calibration function given sufficient calibration data. Despite the popularity of post-hoc calibration, we found that none of the existing methods satisfy all three requirements simultaneously (see Figure 1). Yet given practical constraints, such as high data collection costs, high complexity of calibration tasks, and need for highly accurate classifiers, the development of calibration methods which satisfy all three requirements simultaneously is crucial for the success of real-world ML systems.\n\nAfter calibrating a classifier, the next equally important step is to reliably evaluate the calibration performance. Most of the existing works judge the calibration performance by the expected calibration error 1 (ECE) (Naeini et al., 2015). ECE is usually estimated from a reliability diagram and its associated confidence histogram (Guo et al., 2017;Kull et al., 2019;Milios et al., 2018;Naeini et al., 2015;Nixon et al., 2019;Vaicenavicius et al., 2019). However, histogrambased ECE estimators can be unreliable (e.g., asymptotically biased or noisy) due to their sensitivity to binning schemes (Kumar et al., 2019;Nixon et al., 2019;Vaicenavicius et al., 2019). Additionally, as a density estimator, histogram is known to be less data-efficient than alternative choices, such as kernel density estimators (Scott, 1992). Therefore, it is of utmost importance to develop reliable and data-efficient methods to evaluate the calibration performance.\n\nTo achieve the aforementioned objectives, this paper makes the following contributions:\n\n1. We introduce the following desiderata for uncertainty calibration -(a) accuracy-preserving, (b) data-efficient, and (c) expressive.\n\n2. We propose general ensemble and compositional calibration strategies to achieve high data-efficiency and expressive power while provably preserving accuracy.\n\n3. We propose a data-efficient kernel density estimator for a reliable evaluation of the calibration performance.\n\n4. Using extensive experiments, we show that the proposed Mix-n-Match calibration schemes achieve remarkably better data-efficiency and expressivity upon existing methods while provably preserve accuracy.\n\n\nDefinitions and Desiderata\n\nConsider a multi-class classification problem. The random variable X \u2208 X represents the input feature, and Y = (Y 1 , . . . , Y L ) \u2208 Y represents the L-class one-hot encoded label. Let f : X \u2192 Z \u2286 \u2206 L be a probabilistic classifier that outputs a prediction probability (or confidence)\nvector z = f (x) = (f 1 (x), . . . , f L (x)), where \u2206 L is the probability simplex {(z 1 , . . . , z L ) \u2208 [0, 1] L | L l=1 z l = 1}. Let P(Z, Y )\ndenote the joint distribution of the prediction Z and label Y . Expectations (E) are taken over this distribution unless otherwise specified. Let the canonical calibration function \u03c0(z) represents the actual class probability conditioned on the prediction z (Vaicenavicius et al., 2019):\n\u03c0(z) = (\u03c0 1 (z), . . . , \u03c0 L (z)) with \u03c0 l (z) = P[Y l = 1|f (X) = z].\n(1)\n\nWe would like the predictions to be calibrated, which intuitively means that it represents a true probability. The formal definition of calibration is as follows: Definition 2.1. The classifier f is perfectly calibrated, if for any input instances x \u2208 X , the prediction and the canonical calibration probabilities match: z = \u03c0(z) (Dawid, 1982).\n\nWe focus on a post-hoc approach for calibrating a pretrained classifier, which consists of two steps: (1) finding a calibration map T : \u2206 L \u2192 \u2206 L that adjusts the output of an existing classifier to be better calibrated, based on a set of n c calibration data samples; and (2) evaluate the calibration performance based on a set of n e evaluation data samples. Next, we discuss both steps in detail and highlight shortcomings of current methods.\n\n\nCalibration Step\n\nThe first task in the calibration pipeline is to learn a calibration map T based on n c calibration data samples {(z (i) , y (i) )} nc i=1 . Existing calibration methods can be categorized into two groups:\n\nParametric methods assume that the calibration map belongs to a finite-dimensional parametric family T = {T (z; \u03b8)|\u03b8 \u2208 \u0398 \u2286 R M }. As an example, for binary classification problems, Platt scaling (Platt, 2000) uses the logistic transformation to modify the prediction probability of a class (assuming z 1 ): T (z 1 ; a, b) = (1+exp (\u2212az 1 \u2212 b)) \u22121 , where the scalar parameters a, b are learned by minimizing the negative log likelihood on the calibration data set. Parametric methods are easily extendable to multi-class problems, such as temperature, matrix scaling (Guo et al., 2017) and Dirichlet scaling (Kull et al., 2019).\n\nNon-parametric methods assume that the calibration map is described with infinite-dimensional parameters. For binary classification problems, popular methods include: Histogram binning (Zadrozny & Elkan, 2001) which leverages histograms to estimate the calibration probabilities \u03c0(z) as the calibrated prediction T (z), Bayesian Binning (Naeini et al., 2015) performs Bayesian averaging to ensemble multiple histogram binning calibration maps, and Isotonic regression (Zadrozny & Elkan, 2002) learns a piecewise constant isotonic function that minimizes the residual between the calibrated prediction and the labels. A common way to extend these methods to a multi-class setting is to decompose the problem as L one-versus-all problems (Zadrozny & Elkan, 2002), separately identify the calibration map T l for each class probability (z l ) in the binary manner, and finally normalize the calibrated predictions into \u2206 L .\n\nWhile there are existing approaches tailored for calibrating multi-class deep neural network models, none of them satisfy all three proposed desiderata (accuracy-preserving, data-efficient, expressive) in Sec. 1 simultaneously. Figure 1 (top right) highlights that good calibration capability might come at the cost of classification accuracy for approaches such as isotonic regression. This motivates us to design provably accuracy-preserving calibration methods. Furthermore, the effectiveness of calibration method changes with the amount of calibration data. Parametric approaches are generally data-efficient but have very limited expressive power. On the other hand, non-parametric approaches are expressive but highly data-inefficient. Therefore, in Figure 1 (top left), we see that temperature scaling is the best calibration method in data-limited regime, while isotonic regression is superior in data-rich regime. It is thus naturally desirable to design a calibration method that is effective in both data-limited and data-rich regime. However, earlier studies examined calibration methods with fixed dataset size (Guo et al., 2017;Kull et al., 2019;Wenger et al., 2019), and shed no light on this issue.\n\n\nCalibration Error Evaluation Step\n\nThe next task in the calibration pipeline is to evaluate the calibration performance based on n e evaluation data points {(z (i) , y (i) )} ne i=1 . A commonly used statistics is the expected deviation from z to \u03c0(z), also called expected calibration error (Naeini et al., 2015):\nECE d (f ) = E Z \u2212\u03c0(Z) d d = z\u2212\u03c0(z) d d p(z) dz (2)\nwhere \u00b7 d d denotes the d-th power of the d norm, and p(z) represents the marginal density function of Z = f (X). The original ECE definition adopts d = 1 (Guo et al., 2017;Naeini et al., 2015), while d = 2 is also commonly used (Br\u00f6cker, 2009;Hendrycks et al., 2019;Kumar et al., 2019).\n\nNote that probabilities in Eq. (1) and Eq. (2) cannot be computed directly using finite samples, since \u03c0(z) is a continuous random variable. This motivates the need of designing reliable ECE estimators. A popular estimation approach is based on histograms (Naeini et al., 2015). It partitions the evaluation data points into b bins {B 1 , . . . , B b } according to the predictions z, calculate the average predictionf (B i ) and label\u03c0(B i ) inside the bins B i , and estimate ECE by:\nECE d (f ) = b i=1 #B i n e f (B i ) \u2212\u03c0(B i ) d d .(3)\nwhere #B i denotes the number of instances in B i .\n\nDespite its simplicity, histogram-based estimator suffers from several issues. First, it has bias-variance dilemma with respect to the selection of bin amount and edge locations. For example, too few bins lead to under-estimation of ECE (Kumar et al., 2019;Vaicenavicius et al., 2019). On the other hand, too many bins leads to noisy estimates as each bin becomes sparsely populated (Nixon et al., 2019). Therefore, histogram-based ECE estimators are unreliable (e.g., asymptotically biased or noisy) due to their sensitivity to the binning scheme. Unfortunately, a consistently reliable scheme for choosing the optimal bin sets does not exist (Scott, 1992;Simonoff & Udina, 1997). Finally, histogrambased estimator is known to converge slower as compared to other advanced non-parametric density estimators (Scott, 1992), leading to a data-inefficient estimation of ECE.\n\nNext (in Sec. 3), we discuss proposed Mix-n-Match calibration strategies which satisfy the above discussed desiderata. Later (in Sec. 4), we will address the issue of designing a reliable and data-efficient ECE estimator.\n\n\nDesigning Calibration Methods\n\nWe first present (in Sec. 3.1) a general strategy to design provably accuracy-preserving calibration methods. Next, we discuss strategies for parametric (in Sec. 3.2) and nonparametric calibration methods (in Sec. 3.3) to fulfill remaining desiderata.\n\n\nAccuracy-preserving Calibration\n\nWe present a general form of accuracy-preserving calibration maps and validate its accuracy-preserving property.\n\nDefinition 3.1 (Accuracy-Preserving Calibration Map). Let g : [0, 1] \u2192 R \u22650 be a non-negative strictly isotonic function.\n\nThen, an accuracy-preserving calibration map is given by:\n\nT (z) = (g(z 1 ), g(z 2 ), . . . , g(z L ))/ L l=1 g(z l ).\n\nIn Eq. (4), we apply the same function g to transform all entries in the prediction probability vector z to an unnormalized vector g(z) = (g(z 1 ), . . . , g(z L )); and normalize g(z) to a probability simplex \u2206 L . The single strictly isotonic function g maintains the ordering of class prediction probabilities, and preserves the classification accuracy.\n\nProposition 3.1. The calibration map in Eq. (4) preserves the classification accuracy of the uncalibrated classifier.\n\nProof. Please see supplementary material Sec. A.\n\n\nParametric Calibrations\n\nParametric methods are already data-efficient, thus, one simply needs to enforce the accuracy-preserving requirement and improve their insufficient expressive power.\n\n\nPRESERVING ACCURACY\n\nAs discussed in Proposition 3.1, the use of a strictly isotonic function preserves the accuracy. Fortunately, several existing parametric methods, such as, Platt (Platt, 2000) or temperature scaling (Guo et al., 2017), and beta scaling (Kull et al., 2017), employ strictly isotonic functions -logistic function and beta function, respectively. Therefore, these methods are already accuracy-preserving. Otherwise, the general form as provided in Eq. (4) can be used for designing accuracy-preserving calibration maps.\n\n\nIMPROVING EXPRESSIVITY BY MODEL ENSEMBLE\n\nWe outline a strategy compatible with any parametric calibration method to improve its expressivity. The idea is to use an ensemble of calibration maps from the same accuracypreserving parametric family, but with different parameters:\nT (z) = w 1 T (z; \u03b8 1 ) + w 2 T (z; \u03b8 2 ) + . . . + w M T (z; \u03b8 M ),\nwhere w are non-negative coefficients summing up to one. The weighted sum preserves isotonicity, thus the ensemble inherits the accuracy-preserving property from its individual components. The increased expressivity stems from the fact that more parameters becomes adjustable, including \u03b8 j and the weights w j for each component j in the ensemble. We find the weights w and parameters \u03b8 by minimizing the loss R(.) between calibrated predictions T (z) and labels y:\nminimize w,\u03b8 nc i=1 R M j=1 w j T (z (i) ; \u03b8 j ), y (i) s.t. 1 1\u00d7M w = 1; w \u2265 0 M \u00d71 .\nUsing the above formulation, we show a specific generalization of temperature scaling (TS) (Guo et al., 2017) to satisfy the proposed desiderata.\n\nEnsemble Temperature Scaling (ETS). Note that TS is already accuracy-preserving and data-efficient. Next, we propose an ensemble formulation to improve the expressivity of TS while maintaining its accuracy-preserving and data-efficiency properties. Specifically, we propose a threecomponent ensemble as follows:\nT (z; w, t) = w 1 T (z; t) + w 2 z + w 3 1 L ,(5)\nwhere the calibration map for original TS is expressed by\nT (z; t) = (z 1/t 1 , z 1/t 2 , . . . , z 1/t L )/ L l=1 z 1/t l .\nInterestingly, the remaining two components in the ensemble are also TS calibration maps but with fixed temperature t:\n\n\u2022 TS calibration map with t = 1 (outputs uncalibrated prediction z). It increases the stability when the original classifier is well calibrated (Kull et al., 2017).\n\n\u2022 TS calibration map with t = \u221e (outputs uniform prediction z l = 1/L for each class). It 'smooths' the predictions, similar to how label-smoothing training technique smooths the one-hot labels (Szegedy et al., 2016), which has shown to be successful in training better calibrated neural networks (M\u00fcller et al., 2019).\n\nThe weight w and temperature t of ensemble is identified by solving the following convex optimization problem:\nminimize t,w nc i=1 R w1T (z (i) ; t) + w2z (i) + w3 1 L , y (i) s.t. t > 0; 11\u00d73w = 1; w \u2265 03\u00d71.\nETS preserves the accuracy, as it uses a convex combination of (strictly) isotonic function g = z 1/t l across all classes/components. Further, as ETS only has three additional parameters (the weights) compared to TS, we expect it to be data-efficient. We will see later in Sec. 5.1, ETS is significantly more expressive than TS while maintaining its accuracy-preserving and data-efficiency properties.\n\n\nNon-parametric Calibrations\n\nSince non-parametric methods are generally expressive, we focus on providing solutions to enforce the accuracypreserving requirement, and to improve their data-efficiency.\n\n\nPRESERVING ACCURACY\n\nFollowing Proposition 3.1, in order to preserve accuracy, a strictly isotonic calibration function is needed to be constructed non-parametrically. For binary classification, this requirement is satisfied by the isotonic regression (IR) calibration (Zadrozny & Elkan, 2002): for class 1 (class 2 is the complement), it sorts data points according to their predictions (z\n(1) 1 \u2264 z (2) 1 . . . \u2264 z (nc) 1\n), then fits an isotonic function g to minimize the residual between g(z 1 ) and y 1 . The common way to extend this method to a multi-class setting is to decompose the problem as L one-versus-all problem, which we further denote as IROvA. Unfortunately, this formulation is neither accuracy-preserving nor data-efficient. To extend IR to multi-class problems while preserving accuracy, we use the accuracy-preserving calibration map as defined in Def. 3.1. This calibration map work identically on all the classes and does not distinguish among them. Next, we explain how this procedure is also more data-efficient than the conventional IROvA approach.\n\n\nIMPROVING EFFICIENCY BY DATA ENSEMBLE\n\nWe first explain the proposed multi-class isotonic regression (IRM) procedure, and then comment on its data-efficiency.\n\nIRM first ensembles the predictions and labels from all the classes, then learn a strictly isotonic function g that best fits the transformed predictions versus labels, as described next:\n\nStep 1 (Data ensemble): extract all entries of prediction vector\n{z (i) } nc i=1 and label vector {y (i) } nc i=1 . Let {a (j) } ncL j=1\nand {b (j) } ncL j=1 denote the set of n c L prediction and label entries. Sort both vectors such that a (1) \u2264 a (2) \u2264 . . . a (ncL) .\n\nStep 2 (Isotonic regression): learn an isotonic function g * by minimizing the squared error loss between g(a) and b:\nminimize g\u2208G ncL j=1 [g(a (j) ) \u2212 b (j) ] 2 ,\nwhere G is a family of piecewise constant isotonic functions (Zadrozny & Elkan, 2002). The pair-adjacent violator algorithm (Ayer et al., 1955) is used to find the best function.\n\nStep 3 (Imposing strict isotonicity): the learned function g * is only isotonic. To make it strictly isotonic, we modify it to\u011d(a) = g * (a) + a, where is a very small positive number, such that g(a) < g(a ) whenever a < a . Plugging the strictly isotonic function\u011d back to Eq. (4), we can obtain the non-parametric calibration map.\n\nRemark. Comparing to IROvA, the proposed IRM preserves the accuracy. In addition, it is more data-efficient, since it uses n c L data points to identify one isotonic function in contrast to n c data points in IROvA. We should also highlight that these benefits do not come free: by enforcing the same calibration map on all the classes, the proposed approach is less expressive than IROvA. In fact, we expect an efficiency-expressivity trade-off for the proposed solution -with the number of classes L increasing, it will become more data-efficient but less expressive comparing to one-vs-all. This phenomenon is later verified in Sec. 5.2.\n\n\nCombining Parametric and Non-parametric Calibration\n\nTo get the best of both worlds, i.e., high data-efficiency of parametric methods and high expressivity of non-parametric methods, we propose a compositional method as well. Specifically, we apply a data-efficient parametric calibration method first, and then conduct non-parametric calibration on the parametric calibrated entries. Intuitively, first fitting a parametric function acts like a baseline for variance reduction (Kumar et al., 2019) and then conducting a nonparametric calibration enjoys higher data-efficiency than the non-parametric calibration alone. Expressivity is unaffected by the composition since no additional restriction is imposed on the non-parametric layer. Accuracy-preserving is satisfied if the adopted parametric and non-parametric calibration maps satisfy Def. 3.1, since the composition of strictly isotonic functions remains strictly isotonic.\n\n\nEvaluating Calibration Errors\n\nNext step in the calibration pipeline is to evaluate the calibration performance by estimating the expected calibration error as given in Eq.\n\n(2). The primary challenge is the involvement of two unknown densities p(z) and \u03c0(z).\n\nHistogram-based estimator (Naeini et al., 2015) replaces the unknown densities by their bin-discretized version as given in Eq.\n\n(3). It is easy to implement, but also inevitably inherits drawbacks from histograms, such as the sensitivity to the binning schemes, and the data-inefficiency.\n\nWe alleviate these challenges by replacing histograms with non-parametric density estimators that are continuous (thus, avoid the binning step) and, are more data-efficient. Specifically, we use kernel density estimation (KDE) (Parzen, 1962;Rosenblatt, 1956) to estimate the ECE for its implementation easiness and tractable theoretical properties.\n\n\nKDE-based ECE Estimator\n\nLet K : R \u2192 R \u22650 denote a smoothing kernel function (Tsybakov, 2008). Given a fixed bandwidth h > 0, we have K h (a) = h \u22121 K(a/h). Based on the evaluation dataset, the unknown probabilities are estimated using KDE as follows:\np(z) = h \u2212L n e ne i=1 L l=1 K h (z l \u2212 z (i) l ), \u03c0(z) = ne i=1 y (i) L l=1 K h (z l \u2212 z (i) l ) ne i=1 L l=1 K h (z l \u2212 z (i) l )\n.\n\nPlugging them back in Eq.\n\n(2), we obtain the KDE-based\nMix-n-Match Calibration ECE d estimator: ECE d (f ) = z \u2212\u03c0(z) d dp (z) dz .(6)\nThe integration in Eq. (6) can be performed numerically (e.g., using Trapzoidal rule).\n\nWe next provide a theoretical analysis of statistical properties of the proposed KDE ECE estimator when d = 1. The results for d = 2 can be obtained similarly.\n\nTheorem 4.1 (Statistical properties). Assuming the unknown densities p(z) and \u03c0(z) are smooth (\u03b2-H\u00f6lder) and bounded, with the bandwidth h n \u22121/(\u03b2+L) e , the KDE ECE is asymptotically unbiased and consistent, with a convergence rate |E[ ECE\n1 (f )] \u2212 ECE 1 (f )| \u2208 O(n \u2212\u03b2/(\u03b2+L) e ).\nProof. Please see supplementary material Sec. B.\n\nAs verifying these smoothness assumptions in practice is highly non-trivial (Kumar et al., 2019), we corroborate our theoretical results using empirical comparisons in Sec. 5.1. The implementation details for KDE is provided in the supplementary material Sec. C.\n\nDimensional reduction for multi-class problems. Convergence rates of non-parametric density estimators depend undesirably on the class dimension L, making the estimation challenging for multi-class problems. A way around this curse of dimensionality problem is to use the top-label ECE d (Guo et al., 2017) or the class-wise ECE d (Kull et al., 2019;Kumar et al., 2019). Both reduce the effective dimension to one, but weaken the calibration notion in Def. 2.1, meaning that they can be zero even if the model is not perfectly calibrated (Vaicenavicius et al., 2019).\n\n\nA Dimensionality-Independent Ranking Method\n\nIn many practical situations, the main goal for evaluating calibration errors is to compare (or rank) calibration maps. However, rankings based on the approximations, e.g., toplabel and class-wise ECE d , have been observed to be contradictory (Kull et al., 2019;Nixon et al., 2019). This raises the question rankings based on these approximations are indicative of the ranking based on actual ECE d in Eq. (2).\n\nNext, we present a dimensionality-independent solution to compare calibration maps according to their actual calibration capabilities, rather than resorting to weaker variants. The solution relies on the well-known calibration refinement decomposition (Murphy, 1973) for the strictly proper scoring loss (Gneiting & Raftery, 2007). Thus, it is applicable only when d = 2, since the absolute loss (d = 1) is improper (Buja et al., 2005). Since ECE 1 and ECE 2 are closely related (\n\u221a ECE 2 <ECE 1 < \u221a L \u00b7 ECE 2 )\n, we anticipate comparisons based on ECE 2 and ECE 1 should be similar. Specifically, we propose to use calibration gain (defined next) for the comparison.\n\nDefinition 4.1. The calibration gain is defined as the reduction in ECE d after applying a calibration map (T \u2022 f ):\n\u2206ECE 2 (T ) = ECE 2 (f ) \u2212 ECE 2 (T \u2022 f ).\nHigher gain indicates a better calibration map.\n\nProposition 4.2. For accuracy-preserving maps in Def. 3.1, the calibration gain equals the reduction of squared loss between predictions and labels after calibration:\n\u2206ECE 2 (T ) = E Z \u2212 Y 2 2 \u2212 E T (Z) \u2212 Y 2 2 . (7)\nProof. Please see supplementary material Sec. D.\n\nFor non accuracy-preserving methods (Table 1), the squared loss reduction in Eq. (7) bounds its actual calibration gain from below, and may not facilitate a fair comparison.\n\nFinally, given an evaluation dataset, Eq. (7) is estimated by: \n\u2206 ECE 2 (T ) = 1 n e ne i=1 z (i) \u2212 y (i) 2 2 \u2212 T (z (i) ) \u2212 y (i) 2 2(8)\n\nExperiments\n\n\nCalibration Error Evaluations\n\nWe compare the finite sample performance of proposed KDE-based ECE d estimator with histogram-based ones on a synthetic binary classification problem (Vaicenavicius et al., 2019). The classifier is parameterized by two parameters \u03b2 0 , \u03b2 1 (described in detail in supplementary material Sec. E). We consider a less-calibrated case \u03b2 0 = 0.5, \u03b2 1 = \u22121.5, and a better-calibrated case with \u03b2 0 = 0.2, \u03b2 1 = \u22121.9. The canonical calibration probability \u03c0 (f ) (z) has a closed-form expression (Eq. (14)), allowing us to obtain the ground truth ECE (Eq. (2)) using Monte Carlo integration with 10 6 samples. We compare the ground truth to the estimation of ECE 1 using KDE and histogram-based estimators -one with 15 equal-width bins and other with data-dependent binning scheme (Sturges, 1926). In Figure 2, we vary the size of evaluation samples n e from 64 to 1024 and plot the mean absolute error (averaged over 1000 independent experiments) between KDE/Histograms estimates and the ground truth. We see that KDE consistently outperforms histogrambased estimators regardless of the binning schemes. The discrepancy is particularly noticeable with small n e , highlighting KDE's superior efficiency in data-limited regime. Additional results on distribution of the estimation errors Table 1. Top-label ECE 1 (%) and Calibration Gain \u2206ECE 2 (%) in parenthesis. For non accuracy-preserving methods (IROvA and IROvA-TS), the reported \u2206ECE 2 are the lower bound of the actual calibration gain. Lower value is better for ECE 1 and higher value is better for \u2206ECE 2 . The number following a models name denotes the network depth (and width if applicable). are reported in the supplementary material Figure 4. In rest of the paper, we adopt KDE for estimating ECE, unless otherwise specified.\n\n\nCalibrating Neural Network Classifiers\n\nWe calibrate various deep neural network classifiers on popular computer vision datasets: CIFAR-10/100 (Krizhevsky, 2009)  For our first experiment, we adopt a standard calibration setup (Guo et al., 2017) with fixed-size calibration n c and evaluation n e datasets. We randomly split the hold-out dataset into n c = 5000, n e = 10000 for CIFAR-10/100 and n c = n e = 25000 for ImageNet. We use a random split to divide the hold-out dataset into n c calibration points to learn the calibration map, and n e evaluation points to evaluate ECE and classification accuracy. All the results are averaged over 100 independent runs. . Depending on the model/data complexity, either parametric or non-parametric variants may perform better. To explore this holistically, we next conduct a learning curve analysis by varying calibration dataset size and evaluate three properties (accuracy, data-efficiency and expressivity) of calibration approaches. We reserve the same set of 5000 data points for evaluation, and vary the number of calibration data from 128 to 10000 (CIFAR-10/100) or 45000 (ImageNet). This process is repeated 100 times.\n\nFor Wide ResNets, Figure 3 shows how the average ECE and the accuracy over the repetitions change as a function of calibration dataset size n c . Results for other cases are provided in supp. material Sec. F. We provide a thorough analysis on the learning curves below.\n\nAccuracy. From Figure 3 bottom, we observe that IROvA and IROvA-TS lead to serious accuracy reduction in the data-limited regime, and require a large calibration datasets to recover the original accuracy, while the accuracypreserving approaches maintain the accuracy.\n\nData-efficiency. Parametric methods (TS, ETS) enjoy the fastest converge of ECE (see Figure 3 top), which is anticipated. Our proposed data ensemble (IRM) and compositional (IROvA-TS) solutions also converge faster than IROvA. To quantify their data-efficiency gain, we record the required amount of data for non-parametric approaches to reach a reference calibration level (see Figure 6 right) in Table 3. The proposed data ensemble and compositional approaches achieve remarkable data-efficiency gains.\n\nExpressivity. Note that a more expressive method should attain lower ECE with a sufficiently large calibration dataset. From Figure 3 top, we see that the proposed ensemble approach ETS is significantly more expressive than TS. This gain is particularly visible in many-class datasets, e.g., CIFAR-100 and ImageNet, where the canonical calibration function is expected to be complex. Also, the reduced expressivity of IRM over IROvA can be observed, verifying our hypothesis of its efficiency-expressivity trade-off. In Table 2, we provide a quantitative comparison on the expressivity of TS and ETS by measuring their final ECE (at highest values of n c , see Figure 6 left). We see that ETS is consistently more expressive and attains lower final ECE value than TS across different models/datasets.\n\nTo summarize, our proposed Mix-n-Match strategies provide substantial benefits for calibration, and can be easily incorporated into many existing calibration methods. We also provide guidelines on determining the most appropriate calibration method for a given problem in Sec. G. We expect the observed trends to generalize to other potential extensions. For example, the ensemble beta scaling method should be more expressive than the original beta scaling method (Kull et al., 2017), and the composition of TS with other non-parametric methods, e.g., IRM, should also be more data-efficient. We also anticipate additional efficiency gain if one substitutes TS with ETS in the composition, since ETS has been shown to be more expressive.\n\n\nConclusion\n\nWe demonstrated the practical importance of designing calibration methods with provable accuracy-preserving characteristics, high data-efficiency, and high expressivity. We proposed general Mix-n-Match calibration strategies (i.e., ensemble and composition) to extend existing calibration methods to fulfill such desiderata simultaneously. Furthermore, we proposed a data-efficient kernel density-based estimator for a reliable evaluation of the calibration performance. Comparisons with existing calibration methods across various datasets and neural network models showed that our proposed strategies consistently outperform their conventional counterparts. We hope that our developments will advance research on this essential topic further. \n\n\nA. Proofs of Proposition 3.1: Accuracy-Preserving Calibration Maps\n\nFor an arbitrary pair of classes (\u2200i, j \u2208 [L], where [L] denotes the set of positive integers up to L) of the prediction probability vector z, let us assume that z i < z j without loss of generality. By definition, the strictly isotonic function g will output g(z i ) < g(z j ) after the transformation. After dividing by the same normalization constant G(z), the following relationship holds: [T (z)] i < [T (z)] j , where [.] i represents the i-th entry of the vector. Since the order of entries in the prediction vector is unchanged after the calibration, the classification accuracy is preserved.\n\n\nB. Proofs of Theorem 4.1: Statistical Properties of KDE-based ECE\n\nMirror image KDE for boundary correction. Considering that we will work with the probability simplex \u2206 L in the context of calibration, a well known issue for KDE is that their bias can be large near the boundary of the simplex. To suitably correct for boundary bias without compromising the estimation quality, we adopt the mirror image KDE strategy (Singh & P\u00f3czos, 2014b). The convergence/consistency properties will be proved for such a choice.\n\nSmoothness assumption on the underlying densities. Let \u03b2 and N be positive numbers. Given a vector s = (s 1 , . . . , s L ) with non-negative integer entries, let us use D s := \u2202 s 1 \u2202 s 1 z1...\u2202 s L z L to denote the differential operator. The \u03b2-H\u00f6lder class of densities \u03a3(\u03b2, N ) contains those densities p : [0, 1] L \u2192 R satisfying the following relationship:\n|D s p(z) \u2212 D s p(z )| \u2264 N z \u2212 z \u03b2\u2212 s 1 ,\nfor all z, z \u2208 Z and all s with s 1 = \u03b2 \u2212 1. We assume that the distribution for predictions p(z) as well as the calibration probabilities \u03c0 l for each class l \u2208 [L] belongs to the \u03b2-H\u00f6lder class.\n\nAssumption on the kernel function. We assume that the kernel function K : R \u2192 R \u22650 has bounded support [\u22121, 1] and satisfies:\n1 \u22121 K(u) du = 1; K 1 = 1 \u22121 |K(u)| du < \u221e; \u2200j \u2208 [\u03b2 \u2212 1], 1 \u22121 u j K(u) du = 1.\nBoundedness assumption. We denote C \u03c0 := sup z z \u2212 \u03c0(z)|| 1 and C z := sup zp (z) and assume they are both finite.\n\nWe can bound the KDE estimation error of |ECE(f ) \u2212 ECE(f )| after applying the triangle inequality:\n|ECE(f ) \u2212 ECE(f )| = z \u2212 \u03c0(z) 1 p(z) dz \u2212 z \u2212\u03c0(z)) 1p (z) dz \u2264 p(z) z \u2212 \u03c0(z) 1 \u2212p(z) z \u2212 \u03c0(z) 1 dz + p(z) z \u2212 \u03c0(z) 1 \u2212 z \u2212\u03c0(z) 1 dz \u2264 sup z z \u2212 \u03c0(z) 1 |p(z) \u2212p(z)| dz +sup zp (z) \u03c0(z) \u2212\u03c0(z) 1 dz \u2264 C \u03c0 |p(z) \u2212p(z)| dz +C z \u03c0(z) \u2212\u03c0(z) 1 dz(9)\nwhich connects the absolute estimation error of ECE to the integrated estimation errors on the unknown densities p(z) and \u03c0(z). We then borrow the established convergence rate and consistency proofs for (conditional) density functional of mirror KDE (Singh & P\u00f3czos, 2014a) to derive the statistical properties for the proposed KDE-based ECE estimator.\n\nBias convergence rate. Taking the expectation and applying the Fubini's theorem on both sides in Eq. (9), we can derive:\nE|ECE(f ) \u2212 ECE(f )| \u2264 C \u03c0 E|p(z) \u2212p(z)| dz +C z E \u03c0(z) \u2212\u03c0(z)) 1 dz \u2264 C \u03c0 C B1 (h \u03b2 + h 2\u03b2 + 1 n e h L ) + C z C B2 (h \u03b2 + h 2\u03b2 + 1 n e h L ) \u2264 C(h \u03b2 + h 2\u03b2 + 1 n e h L ),\nwhere C B1 and C B2 are constants given the sample size n e and bandwidth h and C = C \u03c0 C B1 + C z C B2 . The quantity h 2\u03b2 is introduced by the Bias Lemma (Singh & P\u00f3czos, 2014b) from the mirror image KDE. For E|p(z) \u2212p(z)| dz, we follow the standard KDE results (see Prop 1.1,1.2 and 1.2.3 (Tsybakov, 2008)) while the bound on the other term E \u03c0(z) \u2212\u03c0(z)) 1 dz follows 6.2 in (Singh & P\u00f3czos, 2014a) or (D\u00f6ring et al., 2016;Gy\u00f6rfi et al., 2006).\n\nThe optimal bandwidth is h n \u22121/(\u03b2+L) e , leading to a convergence rate of O n \u2212\u03b2/(\u03b2+L) e .\n\nConsistency. Letp denote the KDE marginal density of z when an existing sample point is replaced by a new sample from the same distribution p(z), and similarly\u03c0 denote the KDE canonical calibration function after replacing a sample. Following (Singh & P\u00f3czos, 2014a), we can bound the density discrepancy before/after replacing a single sample by:\n|p(z) \u2212p (z)| dz \u2264 C V 1 n e ; \u03c0(z) \u2212\u03c0 (z) 1 dz \u2264 C V 2 n e ,(10)\nwhere C V 1 and C V 2 are constants in the class-dimension L and the kernel norm K 1 for exact values. Suppose that we use two sets of n e independent samples to estimate p and \u03c0, respectively. Since ECE(f ) depends on 2n e independent variables, combining Eq. (10) with Eq. (9), we can use McDiarmids Inequality (McDiarmid, 1989) to derive that:\nP(| ECE(f ) \u2212 E ECE(f )| > \u03b5) \u2264 2 exp \u2212 2\u03b5 2 2n e (2C V /n e ) 2 = 2 exp \u2212 \u03b5 2 n e 4C 2 V . for C V = max(C V 1 , C V 2 ). As P(| ECE(f ) \u2212 E ECE(f )| > \u03b5)\napproaches 0 when n e \u2192 \u221e, the KDE-based ECE estimator is consistent.\n\n\nC. KDE Implementation Detail\n\nKernel function choice. Different types of kernel functions K(u) can be used, such as the Gaussian and Epanechnikov functions. Our choice is the Triweight\nKernel K h (u) = (1/h) 35 32 (1 \u2212 (u/h) 2 ) 3 on [\u22121, 1].\nBandwidth selection. We use the popular rule-of-thumb h = 1.06\u03c3n \u22121/5 e (Scott, 1992), where\u03c3 is the standard deviation of the samples.\n\n\nD. Proof for Proposition 4.2: Calibration Gain for Accuracy-Preserving Methods\n\nAccording to the calibration refinement decomposition (Murphy, 1973), the expected calibration error ECE 2 is equal to:\nECE 2 (f ) = E z \u2212 \u03c0(z) 2 2 = E z \u2212 y 2 2 \u2212 E \u03c0(z) \u2212 y 2 2 ,(11)\nwhere E z \u2212 y 2 2 is the standard square loss and E \u03c0(z) \u2212 y 2 2 is the refinement error (Murphy, 1973) that penalizes the existence of inputs sharing the same prediction but different class labels. Before proceeding further, we first introduce the definition of injective calibration maps: Proof. Given z = z , without loss of generality assume G(z) \u2265 G(z ) for their normalization constants. Since z = z , there must exists at least one class l where z l < z l . After the transformation by a strictly isotonic function g, we know that g(z l ) < g(z l ). Then we can derive that:\n[T (z)] l \u2212 [T (z )] l = g(z l ) G(z) \u2212 g(z l ) G(z ) = g(z l )G(z ) \u2212 g(z l )G(z) G(z)G(z ) < 0.\nTherefore, T (z) = T (z ) because their l-th entry is not equal. The calibration map is then injective.\n\nNote that the canonical calibration function in Eq. (1) is essentially the conditional expectation of binary random variables Y , as \u03c0 l (z) = P[Y l = 1|f (X) = z] = E[Y l |f (X) = z]. By elementary properties of the conditional expectation, one can easily show that injective calibration maps will not change the canonical calibration probabilities, thus \u03c0(z) = \u03c0(T (z)) for injective T . Combining this with the decomposition relationship in Eq. (11), we can show that:\n\u2206ECE 2 (T ) = ECE 2 (f ) \u2212 ECE 2 (T \u2022 f ) = E z \u2212 y 2 2 \u2212 E \u03c0(z) \u2212 y 2 2 \u2212 E T (z) \u2212 y 2 2 \u2212 E \u03c0(T (z)) \u2212 y 2 2 = E z \u2212 y 2 2 \u2212 E T (z) \u2212 y 2 2 .(12)\nTherefore, after applying an injective calibration map, which include the proposed accuracy-preserving ones, any changes in the squared loss will be due to the change in ECE 2 .\n\nRemark. Most existing calibration methods are not injective. For example, in histogram binning (Zadrozny & Elkan, 2001) or the original isotonic regression method (Zadrozny & Elkan, 2002), all predictions inside certain intervals will be mapped to be identical. For parametric methods, such as vector, matrix (Guo et al., 2017), or Dirichlet scaling (Kull et al., 2019), different logits can be transformed to produce the same prediction probability vectors, and violate the injective requirement.\n\nE. Experimental Details and Additional Results in Section 5.1\n\n\nE.1. Experimental details\n\nFor the synthetic example, the labels (Y ) and input features (X) are distributed as: P(Y 1 = 1) = P(Y 2 = 1) = 1/2; P(X = x|Y 1 = 1) = N (x; \u22121, 1); P(X = x|Y 2 = 1) = N (x; 1, 1).\n\nThe probability of observing the label Y 1 = 1 conditioned on the input x can be written as:\nP(Y 1 = 1|X = x) = 1/[1 + exp(2x)].\nWe assume the prediction models to be in the following form, parameterized by \u03b2 0 and \u03b2 1 :\nz = f (x) = (z 1 , z 2 ) = 1 1 + exp(\u2212\u03b2 0 \u2212 \u03b2 1 x) , exp(\u2212\u03b2 0 \u2212 \u03b2 1 x) 1 + exp(\u2212\u03b2 0 \u2212 \u03b2 1 x)\n.\n\nThis leads to close-form expressions for the canonical calibration functions \u03c0(z) = (\u03c0 1 (z), \u03c0 2 (z)):\n\n\u03c0 1 (z) = [1 + exp(\u22122 \u03b2 0 + log(1/z 1 \u2212 1) \u03b2 1 )] \u22121 , \u03c0 2 (z)) = 1 \u2212 \u03c0 1 (z).\n\nFinally, we estimate the ground-truth ECE 1 based on Monte Carlo integration: (i) generate 10 6 random input-output sample pairs according to Eq. (13), and (ii) record the sample average value of the quantity |z 1 \u2212 \u03c0 1 (z)| as the ground-truth.\n\n\nE.2. Additional results\n\nWe plot the distribution of the errors between the ECE estimates and the ground-truth ECE in two representative scenarios: a data-limited scenario with n e = 64 in Figure 4 and a data-rich scenario with n e = 1024 in Figure ??. The KDE estimation errors are generally less biased (more concentrated around zero) as compared to histograms, corroborating the findings in Sec. 5.1. Judging from the variance of the estimation errors, the KDE estimation errors are generally less dispersed than the two histogram estimators, indicating that the KDE estimators are more reliable. In contrast, histogram ECE estimators tend to severely over-estimates ECE in data-limited regime, with the majority of their estimation errors being positive. Their sensitivity to the binning schemes can be also observed from the distribution discrepancies between using equal-width and data-dependent bins: the histogram estimator with data-dependent bins generally performs better than the one with equal-width bins, although it cannot reach the accuracy level of KDE estimators. However, it performs the worst in the data-rich scenario of Case 2 ( Figure ?? bottom).  For training neural networks on CIFAR-10/100, we use SGD with Nesterov momentum and the cross-entropy loss. The weight decay is set to 0.0005, dampening to 0, momentum to 0.9, and minibatch size to 128. The initial learning rate is set to 0.1, and is dropped by a factor of 0.2 at 60, 120 and 160 epochs. For Wide ResNets, we use a dropout rate of 0.3. We train the models for a total of 500 epochs. We use standard mean/std normalization with flipping and data cropping augmentation as described in (Zagoruyko & Komodakis, 2016) on CIFAR-10/100 images.\n\n\nF.2. Expanded results\n\nThe quantitative measure of expressive power and data-efficiency is illustrated graphically in Figure 6 and discussed in Table 2 and Table 3. To summarize, ETS is comparably expressive to TS on CIFAR-10 and noticeably more expressive on CIFAR-100 and ImageNet. Both IRM and IROvA-TS are more efficient than IROvA. The relative efficiency gain of IRM increases as the problems become more complex. On the other hand, the relative efficiency gain of IROvA-TS appears to be quite stable on a wide range of problems.\n\nWe also provide expanded results on the learning curve analysis for additional neural network classifiers (see Figure 7 to Figure 9). From the visual comparison of the ECE learning curves of ETS and TS, or IRM/IROvA-TS and IROvA, we can confirm the importance to preserve the classification accuracy and the consistent benefit of employing the proposed Mix-n-Match strategies. Overall, in data-limited regime, parametric variants (TS, ETS) perform better than traditional non-parametric variants (IROvA, IROvA-TS) due to their high data-efficiency. ETS significantly outperforms TS and performs the best as the added expressive power from ensembles allow ETS to make further descent on ECE. The proposed accuracy-preserving non-parametric variant IRM also performs good: it is sometimes more effective than TS, although it cannot outperform ETS in most examined cases. The relatively good performance of IRM can be accredited to its high data-efficiency on complex calibration tasks. Going to the data-rich regime, the ECE reduction progress stalls for parametric methods. On complex problems, such as CIFAR-100 and ImageNet, this also applies to the accuracy-preserving non-parametric variants (IRM) due to its expressivity-efficiency trade-off. In contrast, the high expressive power of nonparametric variants (IROvA, IROvA-TS) allow them to keep minimizing the ECE and eventually outperform less expressive methods (ETS, TS or IRM) with sufficient amount of data -although, this cannot be verified in all the examined cases due to our limited data budget. In such regime, the composition method IROvA-TS significantly outperforms IROvA and performs the best due to its enhanced data-efficiency. Based on such observations, our further discussion on the guidelines of calibration methods will be restricted to ETS, IRM and IROvA-TS. Mix-n-Match Calibration  \n\n\nG. Guidelines\n\nFirst, we provide guidelines on choosing an appropriate calibration evaluation metric. If knowing the exact value of ECE is important, we recommend KDE-based top-label ECE estimator for its superior data-efficiency as compared to histograms. If the goal is to infer just the rankings not actual calibration errors, one should use the calibration gain metric. It provides a reliable and faithful comparison of different methods based on their actual calibration capabilities. We also note that calibration gain metric might be a lower bound for certain calibration methods, e.g., non accuracy-preserving methods.\n\nWe next provide general guidelines on selecting the best calibration method (ETS vs. IRM vs. IROvA-TS), based on: (a) the complexity of the calibration task which is a function of the model complexity (number of free parameters) and the data complexity (number of classes), and (b) resources at hand (the amount of the calibration data).\n\nThe complexity of the calibration task is directly related to the complexity of the canonical calibration function in Eq. (1). Although, we do not have the knowledge of the canonical calibration function, we expect a learning task with low model complexity and low data complexity to result in a low complexity calibration task ( see Figure 7 (b)). Next, a learning task with low model complexity but high data complexity (Figure 8 (b)), or high model complexity but low data complexity (Figure 7 (a) and (c)) is expected to result in a moderately complex calibration task. Finally, we expect a learning task with high model & data complexity to result in a highly complex calibration task (Figure 8 (a) and (c), Figure 9).\n\nFor low complexity calibration tasks, we see that the performance of uncalibrated models are already satisfactory. This observation agrees with results in (Guo et al., 2017). Further, all the calibration methods perform similarly, however, proposed variants performing slightly better than the baseline approaches. The use case of the most practical interest is where the calibration task is expected to be complex. In such scenarios, an ideal calibration map should have enough expressive power to accurately approximate the canonical calibration function in Eq. (1). However, to fit an expressive calibration map, sufficiently large amount of calibration data is required which may or may not be available. In data limited regime, ETS is recommended as the first choice, while IRM is a potential alternative when the parametric assumptions of ETS are improper (see Figure 3 top left and Figure 7 (c)). In data rich regime, we recommend using IROvA-TS for its high expressive power. For moderate complexity calibration tasks, the patterns are similar to high complexity calibration tasks. The only difference is that the gain of the proposed Mix-n-Match strategies are not as drastic as of the case where calibration task is of high complexity. Of course, if the user has hard-constraints on accuracy-preservation, the choice would be limited to the accuracy-preserving calibrators regardless of the data size or the task complexity. In such scenarios, we recommend ETS and IRM. We also want to emphasize that both ETS and IRM are fairly efficient and perform well on all ranges of the calibration data size.\n\nIn summary, our take-home messages on the most appropriate calibration method are the following:\n\n\u2022 For complex calibration task (poorly calibrated model, high number of classes), when a large calibration dataset is indeed available and the user does not have hard constraints on preserving accuracy, the proposed compositional method IROvA-TS is recommended to achieve the best degree of calibration.\n\n\u2022 For all other cases, the proposed ensemble method ETS is recommended when the parametric assumption is proper. IRM is a strong alternative to be considered in order to avoid the risk of parametric form mis-specification of ETS in certain cases. Both approaches preserve the classification accuracy, and one can conveniently compare them based on the proposed calibration gain metric.\n\n\nLivermore National Laboratories Livermore, CA 94550. Correspondence to: Jize Zhang <zhang64@llnl.gov>. Preliminary work. Under review. Copyright 2020 by the author(s).\n\nFigure 1 .\n1(Top): (left) Temperature Scaling (TS)\n\n)\nindependent of the class dimension L, and avoids the curse of dimensionality.\n\n\nDefinition D.1 (Injective Calibration Map). The calibration map is injective if different prediction vectors remain different after calibration: \u2200z, z \u2208 Z, T (z) = T (z) if z = z . Proposition D.1. The accuracy-preserving calibration map T in Def. 3.1is injective.\n\nFigure 4 .F\n4Distribution of ECE estimation errors in Case 1: \u03b20 = 0.5, \u03b21 = \u22121.5 with (a) ne = 64 and, (b) ne = 1024.(a) ne = 64 (b) Distribution of ECE estimation errors in Case 2: \u03b20 = 0.2, \u03b21 = \u22121.9 with (a) ne = 64, and (b) ne = 1024.(c) ne = 1024\n\nFigure 6 .\n6Graphical illustration for the proposed measure of expressive power and data-efficiency.\n\n\nFor the composition method, we combine IROvA with TS as described in Sec. 3.3 and refer it as IROvA-TS. Both IROvA and IROvA-TS are not accuracy-preserving.with 10/100 classes and ImageNet (Deng et al., 2009) \nwith 1000 classes. For CIFAR-10/100, we trained DenseNet \n(Huang et al., 2017), LeNet (LeCun et al., 1998), ResNet \n(He et al., 2016) and WideResNet (WRN) (Zagoruyko & \nKomodakis, 2016). The training detail is described in Sec. F. \nWe use 45000 images for training and hold out 15000 im-\nages for calibration and evaluation. For ImageNet, we ac-\nquired 4 pretrained models from (Paszke et al., 2019) which \nwere trained with 1.3 million images, and 50000 images are \nhold out for calibration and evaluation. \n\nWe compare five calibration methods: for parametric ap-\nproaches, we use TS and our proposed three-component \nmodel ensemble approach ETS. Following (Kumar et al., \n2019), we use the squared error as our loss function to fit \n\nthem. For non-parametric approaches, we compare IROvA \nand our proposed multi-class accuracy-preserving scheme \nIRM. \n\nTable 1\n1displays top-label ECE 1 and the calibration gain \u2206ECE 2 . Overall the rankings of calibration methods by toplabel ECE 1 or by \u2206ECE 2 are very similar. Our proposed strategies consistently lead to better performance than the baseline implementations (ETS over TS; IRM and IROvA-TS over IROvA)\n\nTable 2 .\n2ECE 1 (%) with nc = 10000 for CIFAR and nc = 45000 for ImageNet; lower values imply more expressive power.Dataset \nModel \nTS \nETS \n\nCIFAR-10 \nDenseNet 40 \n1.32 1.32 \nCIFAR-10 \nLeNet 5 \n1.49 1.48 \nCIFAR-10 \nResNet 110 \n2.12 2.12 \nCIFAR-10 \nWRN 28-10 \n1.67 1.67 \n\nCIFAR-100 DenseNet 40 \n1.73 1.72 \nCIFAR-100 LeNet 5 \n1.39 1.31 \nCIFAR-100 ResNet 110 \n2.81 2.15 \nCIFAR-100 WRN 28-10 \n3.23 2.85 \n\nImageNet \nDenseNet 161 1.95 1.75 \nImageNet \nResNeXt 101 \n2.97 2.22 \nImageNet \nVGG 19 \n1.89 1.83 \nImageNet \nWRN 50-2 \n2.52 2.10 \n\n\n\nTable 3 .\n3Required calibration data amount nc to reach IRM's performance with nc = 128 samples; lower value means more data-efficient. All values are normalized (divided by 128) to show how many samples are equivalent to one sample in IRM for each method.Dataset \nModel \nIRM IROvA IROvA-TS \n\nCIFAR-10 \nDenseNet 40 \n1.0 \n2.45 \n2.10 \nCIFAR-10 \nLeNet 5 \n1.0 \n3.15 \n2.92 \nCIFAR-10 \nResNet 110 \n1.0 \n1.84 \n1.70 \nCIFAR-10 \nWRN 28-10 \n1.0 \n1.98 \n1.90 \n\nCIFAR-100 DenseNet 40 \n1.0 \n37.6 \n17.9 \nCIFAR-100 LeNet 5 \n1.0 \n58.7 \n43.0 \nCIFAR-100 ResNet 110 \n1.0 \n28.1 \n10.7 \nCIFAR-100 WRN 28-10 \n1.0 \n24.2 \n15.6 \n\nImageNet \nDenseNet 161 \n1.0 \n282 \n174 \nImageNet \nResNeXt 101 \n1.0 \n226 \n98.6 \nImageNet \nVGG 19 \n1.0 \n251 \n180 \nImageNet \nWRN 50-2 \n1.0 \n258 \n161 \n\nAlternative choices also exist, such as the max calibration error(Naeini et al., 2015) or the reproducing kernel Hilbert space based calibration measure(Widmann et al., 2019).\nAcknowledgementsThis work was performed under the auspices of the U.S. Department of Energy by Lawrence Livermore National Laboratory under Contract DE-AC52-07NA27344 and LLNL-LDRD Program Project No. 19-SI-001.\nAn empirical distribution function for sampling with incomplete information. M Ayer, H D Brunk, G M Ewing, W T Reid, E Silverman, The Annals of Mathematical Statistics. Ayer, M., Brunk, H. D., Ewing, G. M., Reid, W. T., and Silverman, E. An empirical distribution function for sampling with incomplete information. The Annals of Mathematical Statistics, pp. 641-647, 1955.\n\nWeight uncertainty in neural networks. C Blundell, J Cornebise, K Kavukcuoglu, D Wierstra, International Conference on Machine Learning (ICML). Blundell, C., Cornebise, J., Kavukcuoglu, K., and Wierstra, D. Weight uncertainty in neural networks. In Inter- national Conference on Machine Learning (ICML), pp. 1613-1622, 2015.\n\nReliability, sufficiency, and the decomposition of proper scores. J Br\u00f6cker, Quarterly Journal of the Royal Meteorological Society. 135643Br\u00f6cker, J. Reliability, sufficiency, and the decomposition of proper scores. Quarterly Journal of the Royal Meteo- rological Society, 135(643):1512-1519, 2009.\n\nLoss functions for binary class probability estimation and classification: Structure and applications. A Buja, W Stuetzle, Y Shen, University of PennsylvaniaTechnical reportBuja, A., Stuetzle, W., and Shen, Y. Loss functions for bi- nary class probability estimation and classification: Struc- ture and applications. Technical report, University of Pennsylvania, 2005.\n\nLearning affordance for direct perception in autonomous driving. C Chen, A Seff, A Kornhauser, Xiao , J Deepdriving, Proceedings of the IEEE International Conference on Computer Vision (ICCV). the IEEE International Conference on Computer Vision (ICCV)Chen, C., Seff, A., Kornhauser, A., and Xiao, J. Deepdriving: Learning affordance for direct perception in autonomous driving. In Proceedings of the IEEE International Confer- ence on Computer Vision (ICCV), pp. 2722-2730, 2015.\n\nThe well-calibrated bayesian. A P Dawid, Journal of the American Statistical Association. 77379Dawid, A. P. The well-calibrated bayesian. Journal of the American Statistical Association, 77(379):605-610, 1982.\n\nImagenet: A large-scale hierarchical image database. J Deng, W Dong, R Socher, L.-J Li, K Li, L Fei-Fei, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)Deng, J., Dong, W., Socher, R., Li, L.-J., Li, K., and Fei-Fei, L. Imagenet: A large-scale hierarchical image database. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 248-255, 2009.\n\nExact rate of convergence of kernel-based classification rule. M D\u00f6ring, L Gy\u00f6rfi, H Walk, Challenges in Computational Statistics and Data Mining. SpringerD\u00f6ring, M., Gy\u00f6rfi, L., and Walk, H. Exact rate of conver- gence of kernel-based classification rule. In Challenges in Computational Statistics and Data Mining, pp. 71-91. Springer, 2016.\n\nDropout as a bayesian approximation: Representing model uncertainty in deep learning. Y Gal, Z Ghahramani, International Conference on Machine Learning (ICML). Gal, Y. and Ghahramani, Z. Dropout as a bayesian approx- imation: Representing model uncertainty in deep learn- ing. In International Conference on Machine Learning (ICML), pp. 1050-1059, 2016.\n\nFast r-cnn. R Girshick, IEEE International Conference on Computer Vision (ICCV). Girshick, R. Fast r-cnn. In IEEE International Conference on Computer Vision (ICCV), pp. 1440-1448, 2015.\n\nStrictly proper scoring rules, prediction, and estimation. T Gneiting, A E Raftery, Journal of the American Statistical Association. 102477Gneiting, T. and Raftery, A. E. Strictly proper scoring rules, prediction, and estimation. Journal of the American Statistical Association, 102(477):359-378, 2007.\n\nOn calibration of modern neural networks. C Guo, G Pleiss, Y Sun, K Q Weinberger, International Conference on Machine Learning (CML). Guo, C., Pleiss, G., Sun, Y., and Weinberger, K. Q. On calibration of modern neural networks. In International Conference on Machine Learning (CML), pp. 1321-1330, 2017.\n\nA distribution-free theory of nonparametric regression. L Gy\u00f6rfi, M Kohler, A Krzyzak, H Walk, Springer Science & Business MediaGy\u00f6rfi, L., Kohler, M., Krzyzak, A., and Walk, H. A distribution-free theory of nonparametric regression. Springer Science & Business Media, 2006.\n\nDeep residual learning for image recognition. K He, X Zhang, S Ren, J Sun, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)He, K., Zhang, X., Ren, S., and Sun, J. Deep residual learn- ing for image recognition. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 770-778, 2016.\n\nWhy relu networks yield high-confidence predictions far away from the training data and how to mitigate the problem. M Hein, M Andriushchenko, J Bitterwolf, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)Hein, M., Andriushchenko, M., and Bitterwolf, J. Why relu networks yield high-confidence predictions far away from the training data and how to mitigate the problem. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 41-50, 2019.\n\nDeep anomaly detection with outlier exposure. D Hendrycks, M Mazeika, T Dietterich, International Conference on Learning Representations (ICLR). Hendrycks, D., Mazeika, M., and Dietterich, T. Deep anomaly detection with outlier exposure. In International Conference on Learning Representations (ICLR), 2019.\n\nDensely connected convolutional networks. G Huang, Z Liu, L Van Der Maaten, K Q Weinberger, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)Huang, G., Liu, Z., Van Der Maaten, L., and Weinberger, K. Q. Densely connected convolutional networks. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 4700-4708, 2017.\n\nTo trust or not to trust a classifier. H Jiang, B Kim, M Guan, M Gupta, Advances in Neural Information Processing Systems (NeurIPS). Jiang, H., Kim, B., Guan, M., and Gupta, M. To trust or not to trust a classifier. In Advances in Neural Information Processing Systems (NeurIPS), pp. 5541-5552, 2018.\n\nWhat uncertainties do we need in bayesian deep learning for computer vision?. A Kendall, Y Gal, Advances in Neural Information Processing Systems (NeurIPS). Kendall, A. and Gal, Y. What uncertainties do we need in bayesian deep learning for computer vision? In Advances in Neural Information Processing Systems (NeurIPS), pp. 5574-5584, 2017.\n\nLearning multiple layers of features from tiny images. A Krizhevsky, Technical reportKrizhevsky, A. Learning multiple layers of features from tiny images. Technical report, 2009.\n\nBeyond sigmoids: How to obtain well-calibrated probabilities from binary classifiers with beta calibration. M Kull, T M Silva Filho, P Flach, Electronic Journal of Statistics. 112Kull, M., Silva Filho, T. M., Flach, P., et al. Beyond sig- moids: How to obtain well-calibrated probabilities from binary classifiers with beta calibration. Electronic Journal of Statistics, 11(2):5052-5080, 2017.\n\nBeyond temperature scaling: Obtaining well-calibrated multi-class probabilities with dirichlet calibration. M Kull, M P Nieto, M K\u00e4ngsepp, T Silva Filho, H Song, P Flach, Advances in Neural Information Processing Systems (NeurIPS). Kull, M., Nieto, M. P., K\u00e4ngsepp, M., Silva Filho, T., Song, H., and Flach, P. Beyond temperature scaling: Obtaining well-calibrated multi-class probabilities with dirichlet cal- ibration. In Advances in Neural Information Processing Systems (NeurIPS), pp. 12295-12305, 2019.\n\nTrainable calibration measures for neural networks from kernel mean embeddings. A Kumar, S Sarawagi, U Jain, International Conference on Machine Learning (ICML). Kumar, A., Sarawagi, S., and Jain, U. Trainable calibration measures for neural networks from kernel mean embed- dings. In International Conference on Machine Learning (ICML), pp. 2810-2819, 2018.\n\nMix-n-Match Calibration. Mix-n-Match Calibration\n\nVerified uncertainty calibration. A Kumar, P S Liang, T Ma, Advances in Neural Information Processing Systems (NeurIPS). Kumar, A., Liang, P. S., and Ma, T. Verified uncertainty cal- ibration. In Advances in Neural Information Processing Systems (NeurIPS), pp. 3787-3798, 2019.\n\nSimple and scalable predictive uncertainty estimation using deep ensembles. B Lakshminarayanan, A Pritzel, C Blundell, Advances in Neural Information Processing Systems (NeurIPS). Lakshminarayanan, B., Pritzel, A., and Blundell, C. Simple and scalable predictive uncertainty estimation using deep ensembles. In Advances in Neural Information Process- ing Systems (NeurIPS), pp. 6402-6413, 2017.\n\nGradient-based learning applied to document recognition. Y Lecun, L Bottou, Y Bengio, P Haffner, Proceedings of the IEEE. 8611LeCun, Y., Bottou, L., Bengio, Y., Haffner, P., et al. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278-2324, 1998.\n\nA survey on deep learning in medical image analysis. G Litjens, T Kooi, B E Bejnordi, A A A Setio, F Ciompi, M Ghafoorian, J A Van Der Laak, B Van Ginneken, C I S\u00e1nchez, Medical Image Analysis. 42Litjens, G., Kooi, T., Bejnordi, B. E., Setio, A. A. A., Ciompi, F., Ghafoorian, M., van der Laak, J. A., van Ginneken, B., and S\u00e1nchez, C. I. A survey on deep learn- ing in medical image analysis. Medical Image Analysis, 42:60-88, 2017.\n\nA simple baseline for bayesian uncertainty in deep learning. W J Maddox, P Izmailov, T Garipov, D P Vetrov, A G Wilson, Advances in Neural Information Processing Systems (NeurIPS). Maddox, W. J., Izmailov, P., Garipov, T., Vetrov, D. P., and Wilson, A. G. A simple baseline for bayesian uncertainty in deep learning. In Advances in Neural Information Processing Systems (NeurIPS), pp. 13132-13143, 2019.\n\nOn the method of bounded differences. C Mcdiarmid, 141Surveys in combinatoricsMcDiarmid, C. On the method of bounded differences. Surveys in combinatorics, 141(1):148-188, 1989.\n\nDirichlet-based gaussian processes for large-scale calibrated classification. D Milios, R Camoriano, P Michiardi, L Rosasco, M Filippone, Advances in Neural Information Processing Systems (NeurIPS). Milios, D., Camoriano, R., Michiardi, P., Rosasco, L., and Filippone, M. Dirichlet-based gaussian processes for large-scale calibrated classification. In Advances in Neu- ral Information Processing Systems (NeurIPS), pp. 6005- 6015, 2018.\n\nWhen does label smoothing help?. R M\u00fcller, S Kornblith, G E Hinton, Advances in Neural Information Processing Systems (NeurIPS). M\u00fcller, R., Kornblith, S., and Hinton, G. E. When does label smoothing help? In Advances in Neural Information Processing Systems (NeurIPS), pp. 4696-4705, 2019.\n\nA new vector partition of the probability score. A H Murphy, Journal of Applied Meteorology. 124Murphy, A. H. A new vector partition of the probability score. Journal of Applied Meteorology, 12(4):595-600, 1973.\n\nObtaining well calibrated probabilities using bayesian binning. M Naeini, G Cooper, M Hauskrecht, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial IntelligenceNaeini, M., Cooper, G., and Hauskrecht, M. Obtaining well calibrated probabilities using bayesian binning. In Proceedings of the AAAI Conference on Artificial Intelli- gence, pp. 2901-2907, 2015.\n\nDeep neural networks are easily fooled: High confidence predictions for unrecognizable images. A Nguyen, J Yosinski, Clune , J , Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)Nguyen, A., Yosinski, J., and Clune, J. Deep neural net- works are easily fooled: High confidence predictions for unrecognizable images. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 427-436, 2015.\n\nPredicting good probabilities with supervised learning. A Niculescu-Mizil, R Caruana, International Conference on Machine Learning (ICML). Niculescu-Mizil, A. and Caruana, R. Predicting good proba- bilities with supervised learning. In International Confer- ence on Machine Learning (ICML), pp. 625-632, 2005.\n\nMeasuring calibration in deep learning. J Nixon, M Dusenberry, L Zhang, G Jerfel, Tran , D , arXiv:1904.01685arXiv preprintNixon, J., Dusenberry, M., Zhang, L., Jerfel, G., and Tran, D. Measuring calibration in deep learning. arXiv preprint arXiv:1904.01685, 2019.\n\nOn estimation of a probability density function and model. E Parzen, The Annals of Mathematical Statistics. 333Parzen, E. On estimation of a probability density function and model. The Annals of Mathematical Statistics, 33(3): 1065-1076, 1962.\n\nPytorch: An imperative style, high-performance deep learning library. A Paszke, S Gross, F Massa, A Lerer, J Bradbury, G Chanan, T Killeen, Z Lin, N Gimelshein, L Antiga, Advances in Neural Information Processing Systems (NeurIPS). Paszke, A., Gross, S., Massa, F., Lerer, A., Bradbury, J., Chanan, G., Killeen, T., Lin, Z., Gimelshein, N., Antiga, L., et al. Pytorch: An imperative style, high-performance deep learning library. In Advances in Neural Information Processing Systems (NeurIPS), pp. 8024-8035, 2019.\n\nRegularizing neural networks by penalizing confident output distributions. G Pereyra, G Tucker, J Chorowski, \u0141 Kaiser, G Hinton, arXiv:1701.06548arXiv preprintPereyra, G., Tucker, G., Chorowski, J., Kaiser, \u0141., and Hinton, G. Regularizing neural networks by penal- izing confident output distributions. arXiv preprint arXiv:1701.06548, 2017.\n\nProbabilistic outputs for support vector machines and comparison to regularized likelihood methods. Advances in Large Margin Classifiers. J Platt, 10Platt, J. Probabilistic outputs for support vector machines and comparison to regularized likelihood methods. Ad- vances in Large Margin Classifiers, 10(3):61-74, 2000.\n\nRemarks on some nonparametric estimates of a density function. M Rosenblatt, The Annals of Mathematical Statistics. Rosenblatt, M. Remarks on some nonparametric estimates of a density function. The Annals of Mathematical Statis- tics, pp. 832-837, 1956.\n\nMultivariate density estimation. Multivariate Density Estimation. D Scott, WileyNew YorkScott, D. Multivariate density estimation. Multivariate Density Estimation, Wiley, New York, 1992, 1992.\n\nLearning for single-shot confidence calibration in deep neural networks through stochastic inferences. S Seo, P H Seo, B Han, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)Seo, S., Seo, P. H., and Han, B. Learning for single-shot confidence calibration in deep neural networks through stochastic inferences. In Proceedings of the IEEE Con- ference on Computer Vision and Pattern Recognition (CVPR), pp. 9030-9038, 2019.\n\nMeasuring the stability of histogram appearance when the anchor position is changed. J S Simonoff, F Udina, Computational Statistics & Data Analysis. 233Simonoff, J. S. and Udina, F. Measuring the stability of his- togram appearance when the anchor position is changed. Computational Statistics & Data Analysis, 23(3):335- 353, 1997.\n\nExponential concentration of a density functional estimator. S Singh, B P\u00f3czos, Advances in Neural Information Processing Systems (NeurIPS). Singh, S. and P\u00f3czos, B. Exponential concentration of a density functional estimator. In Advances in Neural Information Processing Systems (NeurIPS), pp. 3032- 3040, 2014a.\n\nGeneralized exponential concentration inequality for r\u00e9nyi divergence estimation. S Singh, B P\u00f3czos, International Conference on Machine Learning (ICML). Singh, S. and P\u00f3czos, B. Generalized exponential concen- tration inequality for r\u00e9nyi divergence estimation. In International Conference on Machine Learning (ICML), pp. 333-341, 2014b.\n\nThe choice of a class interval. H A Sturges, Journal of the American Statistical Association. 21153Sturges, H. A. The choice of a class interval. Journal of the American Statistical Association, 21(153):65-66, 1926.\n\nRethinking the inception architecture for computer vision. C Szegedy, V Vanhoucke, S Ioffe, J Shlens, Z Wojna, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR). the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)Szegedy, C., Vanhoucke, V., Ioffe, S., Shlens, J., and Wo- jna, Z. Rethinking the inception architecture for com- puter vision. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 2818-2826, 2016.\n\nCalibrating deep convolutional gaussian. G.-L Tran, E Bonilla, J Cunningham, P Michiardi, M Filippone, Tran, G.-L., Bonilla, E., Cunningham, J., Michiardi, P., and Filippone, M. Calibrating deep convolutional gaussian\n", "annotations": {"author": "[{\"end\":107,\"start\":96},{\"end\":125,\"start\":108},{\"end\":128,\"start\":126},{\"end\":142,\"start\":129}]", "publisher": null, "author_last_name": "[{\"end\":106,\"start\":101},{\"end\":124,\"start\":115},{\"end\":141,\"start\":138}]", "author_first_name": "[{\"end\":100,\"start\":96},{\"end\":114,\"start\":108},{\"end\":127,\"start\":126},{\"end\":137,\"start\":129}]", "author_affiliation": null, "title": "[{\"end\":93,\"start\":1},{\"end\":235,\"start\":143}]", "venue": null, "abstract": "[{\"end\":1109,\"start\":237}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b9\"},\"end\":1310,\"start\":1294},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":1350,\"start\":1331},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":1394,\"start\":1372},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":1694,\"start\":1674},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":1714,\"start\":1694},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":1988,\"start\":1973},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":2000,\"start\":1988},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":2102,\"start\":2070},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":2121,\"start\":2103},{\"end\":2278,\"start\":2254},{\"end\":2692,\"start\":2680},{\"end\":2697,\"start\":2692},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":2825,\"start\":2807},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":2843,\"start\":2825},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":2873,\"start\":2843},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":2893,\"start\":2873},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":3150,\"start\":3137},{\"end\":3194,\"start\":3170},{\"end\":3240,\"start\":3216},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":3295,\"start\":3274},{\"end\":3391,\"start\":3387},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":3506,\"start\":3488},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":3545,\"start\":3526},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":3616,\"start\":3595},{\"end\":3636,\"start\":3616},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":3763,\"start\":3743},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":3793,\"start\":3763},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":3814,\"start\":3793},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":3831,\"start\":3814},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":3849,\"start\":3831},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3941,\"start\":3918},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":3964,\"start\":3941},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":3984,\"start\":3964},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":5113,\"start\":5092},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":5225,\"start\":5207},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":5243,\"start\":5225},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":5263,\"start\":5243},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":5283,\"start\":5263},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":5302,\"start\":5283},{\"end\":5329,\"start\":5302},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":5491,\"start\":5471},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":5510,\"start\":5491},{\"end\":5537,\"start\":5510},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":5695,\"start\":5682},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":7703,\"start\":7690},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":8587,\"start\":8574},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":8964,\"start\":8946},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":9006,\"start\":8987},{\"end\":9218,\"start\":9194},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":9367,\"start\":9346},{\"end\":9769,\"start\":9745},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":11075,\"start\":11057},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":11093,\"start\":11075},{\"end\":11113,\"start\":11093},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":11463,\"start\":11442},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":11690,\"start\":11672},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":11710,\"start\":11690},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":11761,\"start\":11746},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":11784,\"start\":11761},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":11803,\"start\":11784},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":12083,\"start\":12062},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":12657,\"start\":12637},{\"end\":12684,\"start\":12657},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":12803,\"start\":12783},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":13057,\"start\":13044},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":13080,\"start\":13057},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":13221,\"start\":13208},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":15089,\"start\":15076},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":15131,\"start\":15113},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":15169,\"start\":15150},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":16442,\"start\":16424},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":17250,\"start\":17231},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":17469,\"start\":17447},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":17571,\"start\":17550},{\"end\":18684,\"start\":18660},{\"end\":20342,\"start\":20318},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":20400,\"start\":20381},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":21912,\"start\":21892},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":22655,\"start\":22634},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":23140,\"start\":23126},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":23157,\"start\":23140},{\"end\":23343,\"start\":23327},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":24450,\"start\":24430},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":24924,\"start\":24906},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":24968,\"start\":24949},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":24987,\"start\":24968},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":25496,\"start\":25477},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":25515,\"start\":25496},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":25912,\"start\":25898},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":25976,\"start\":25950},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":26081,\"start\":26062},{\"end\":27328,\"start\":27300},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":27939,\"start\":27924},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":29097,\"start\":29079},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":29181,\"start\":29163},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":32442,\"start\":32423},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":34571,\"start\":34548},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":36188,\"start\":36165},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":36741,\"start\":36718},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":36963,\"start\":36940},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":36988,\"start\":36967},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":37008,\"start\":36988},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":37370,\"start\":37347},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":37848,\"start\":37831},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":38421,\"start\":38408},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":38622,\"start\":38608},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":38842,\"start\":38828},{\"end\":40444,\"start\":40420},{\"end\":40512,\"start\":40488},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":40652,\"start\":40634},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":40694,\"start\":40675},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":47840,\"start\":47822},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":53732,\"start\":53711}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":50236,\"start\":50067},{\"attributes\":{\"id\":\"fig_1\"},\"end\":50288,\"start\":50237},{\"attributes\":{\"id\":\"fig_2\"},\"end\":50369,\"start\":50289},{\"attributes\":{\"id\":\"fig_3\"},\"end\":50636,\"start\":50370},{\"attributes\":{\"id\":\"fig_5\"},\"end\":50890,\"start\":50637},{\"attributes\":{\"id\":\"fig_6\"},\"end\":50992,\"start\":50891},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":52059,\"start\":50993},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":52362,\"start\":52060},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":52896,\"start\":52363},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":53645,\"start\":52897}]", "paragraph": "[{\"end\":2894,\"start\":1125},{\"end\":3985,\"start\":2896},{\"end\":4870,\"start\":3987},{\"end\":5822,\"start\":4872},{\"end\":5911,\"start\":5824},{\"end\":6047,\"start\":5913},{\"end\":6209,\"start\":6049},{\"end\":6324,\"start\":6211},{\"end\":6530,\"start\":6326},{\"end\":6846,\"start\":6561},{\"end\":7282,\"start\":6995},{\"end\":7357,\"start\":7354},{\"end\":7704,\"start\":7359},{\"end\":8151,\"start\":7706},{\"end\":8377,\"start\":8172},{\"end\":9007,\"start\":8379},{\"end\":9930,\"start\":9009},{\"end\":11147,\"start\":9932},{\"end\":11464,\"start\":11185},{\"end\":11804,\"start\":11517},{\"end\":12291,\"start\":11806},{\"end\":12398,\"start\":12347},{\"end\":13271,\"start\":12400},{\"end\":13494,\"start\":13273},{\"end\":13779,\"start\":13528},{\"end\":13927,\"start\":13815},{\"end\":14050,\"start\":13929},{\"end\":14109,\"start\":14052},{\"end\":14170,\"start\":14111},{\"end\":14528,\"start\":14172},{\"end\":14647,\"start\":14530},{\"end\":14697,\"start\":14649},{\"end\":14890,\"start\":14725},{\"end\":15430,\"start\":14914},{\"end\":15709,\"start\":15475},{\"end\":16245,\"start\":15779},{\"end\":16478,\"start\":16333},{\"end\":16791,\"start\":16480},{\"end\":16899,\"start\":16842},{\"end\":17085,\"start\":16967},{\"end\":17251,\"start\":17087},{\"end\":17572,\"start\":17253},{\"end\":17684,\"start\":17574},{\"end\":18185,\"start\":17783},{\"end\":18388,\"start\":18217},{\"end\":18781,\"start\":18412},{\"end\":19468,\"start\":18815},{\"end\":19629,\"start\":19510},{\"end\":19818,\"start\":19631},{\"end\":19884,\"start\":19820},{\"end\":20091,\"start\":19957},{\"end\":20210,\"start\":20093},{\"end\":20435,\"start\":20257},{\"end\":20769,\"start\":20437},{\"end\":21411,\"start\":20771},{\"end\":22344,\"start\":21467},{\"end\":22519,\"start\":22378},{\"end\":22606,\"start\":22521},{\"end\":22735,\"start\":22608},{\"end\":22897,\"start\":22737},{\"end\":23247,\"start\":22899},{\"end\":23501,\"start\":23275},{\"end\":23635,\"start\":23634},{\"end\":23662,\"start\":23637},{\"end\":23692,\"start\":23664},{\"end\":23858,\"start\":23772},{\"end\":24019,\"start\":23860},{\"end\":24261,\"start\":24021},{\"end\":24352,\"start\":24304},{\"end\":24616,\"start\":24354},{\"end\":25185,\"start\":24618},{\"end\":25644,\"start\":25233},{\"end\":26126,\"start\":25646},{\"end\":26313,\"start\":26158},{\"end\":26431,\"start\":26315},{\"end\":26522,\"start\":26475},{\"end\":26690,\"start\":26524},{\"end\":26789,\"start\":26741},{\"end\":26964,\"start\":26791},{\"end\":27029,\"start\":26966},{\"end\":28933,\"start\":27150},{\"end\":30108,\"start\":28976},{\"end\":30379,\"start\":30110},{\"end\":30648,\"start\":30381},{\"end\":31154,\"start\":30650},{\"end\":31956,\"start\":31156},{\"end\":32696,\"start\":31958},{\"end\":33456,\"start\":32711},{\"end\":34127,\"start\":33527},{\"end\":34645,\"start\":34197},{\"end\":35009,\"start\":34647},{\"end\":35248,\"start\":35052},{\"end\":35375,\"start\":35250},{\"end\":35570,\"start\":35456},{\"end\":35672,\"start\":35572},{\"end\":36267,\"start\":35915},{\"end\":36389,\"start\":36269},{\"end\":37009,\"start\":36562},{\"end\":37102,\"start\":37011},{\"end\":37451,\"start\":37104},{\"end\":37864,\"start\":37518},{\"end\":38090,\"start\":38021},{\"end\":38277,\"start\":38123},{\"end\":38471,\"start\":38336},{\"end\":38673,\"start\":38554},{\"end\":39320,\"start\":38739},{\"end\":39522,\"start\":39419},{\"end\":39995,\"start\":39524},{\"end\":40323,\"start\":40146},{\"end\":40822,\"start\":40325},{\"end\":40885,\"start\":40824},{\"end\":41096,\"start\":40915},{\"end\":41190,\"start\":41098},{\"end\":41318,\"start\":41227},{\"end\":41413,\"start\":41412},{\"end\":41518,\"start\":41415},{\"end\":41598,\"start\":41520},{\"end\":41845,\"start\":41600},{\"end\":43572,\"start\":41873},{\"end\":44110,\"start\":43598},{\"end\":45972,\"start\":44112},{\"end\":46601,\"start\":45990},{\"end\":46940,\"start\":46603},{\"end\":47665,\"start\":46942},{\"end\":49276,\"start\":47667},{\"end\":49374,\"start\":49278},{\"end\":49679,\"start\":49376},{\"end\":50066,\"start\":49681}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":6994,\"start\":6847},{\"attributes\":{\"id\":\"formula_1\"},\"end\":7353,\"start\":7283},{\"attributes\":{\"id\":\"formula_2\"},\"end\":11516,\"start\":11465},{\"attributes\":{\"id\":\"formula_3\"},\"end\":12346,\"start\":12292},{\"attributes\":{\"id\":\"formula_5\"},\"end\":15778,\"start\":15710},{\"attributes\":{\"id\":\"formula_6\"},\"end\":16332,\"start\":16246},{\"attributes\":{\"id\":\"formula_7\"},\"end\":16841,\"start\":16792},{\"attributes\":{\"id\":\"formula_8\"},\"end\":16966,\"start\":16900},{\"attributes\":{\"id\":\"formula_9\"},\"end\":17782,\"start\":17685},{\"attributes\":{\"id\":\"formula_10\"},\"end\":18814,\"start\":18782},{\"attributes\":{\"id\":\"formula_11\"},\"end\":19956,\"start\":19885},{\"attributes\":{\"id\":\"formula_12\"},\"end\":20256,\"start\":20211},{\"attributes\":{\"id\":\"formula_13\"},\"end\":23633,\"start\":23502},{\"attributes\":{\"id\":\"formula_14\"},\"end\":23771,\"start\":23693},{\"attributes\":{\"id\":\"formula_15\"},\"end\":24303,\"start\":24262},{\"attributes\":{\"id\":\"formula_16\"},\"end\":26157,\"start\":26127},{\"attributes\":{\"id\":\"formula_17\"},\"end\":26474,\"start\":26432},{\"attributes\":{\"id\":\"formula_18\"},\"end\":26740,\"start\":26691},{\"attributes\":{\"id\":\"formula_19\"},\"end\":27103,\"start\":27030},{\"attributes\":{\"id\":\"formula_20\"},\"end\":35051,\"start\":35010},{\"attributes\":{\"id\":\"formula_21\"},\"end\":35455,\"start\":35376},{\"attributes\":{\"id\":\"formula_22\"},\"end\":35914,\"start\":35673},{\"attributes\":{\"id\":\"formula_23\"},\"end\":36561,\"start\":36390},{\"attributes\":{\"id\":\"formula_24\"},\"end\":37517,\"start\":37452},{\"attributes\":{\"id\":\"formula_25\"},\"end\":38020,\"start\":37865},{\"attributes\":{\"id\":\"formula_26\"},\"end\":38335,\"start\":38278},{\"attributes\":{\"id\":\"formula_27\"},\"end\":38738,\"start\":38674},{\"attributes\":{\"id\":\"formula_28\"},\"end\":39418,\"start\":39321},{\"attributes\":{\"id\":\"formula_29\"},\"end\":40145,\"start\":39996},{\"attributes\":{\"id\":\"formula_31\"},\"end\":41226,\"start\":41191},{\"attributes\":{\"id\":\"formula_32\"},\"end\":41411,\"start\":41319}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":26836,\"start\":26827},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":28438,\"start\":28431},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":31055,\"start\":31048},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":31683,\"start\":31676},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":43738,\"start\":43719}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":1123,\"start\":1111},{\"attributes\":{\"n\":\"2.\"},\"end\":6559,\"start\":6533},{\"attributes\":{\"n\":\"2.1.\"},\"end\":8170,\"start\":8154},{\"attributes\":{\"n\":\"2.2.\"},\"end\":11183,\"start\":11150},{\"attributes\":{\"n\":\"3.\"},\"end\":13526,\"start\":13497},{\"attributes\":{\"n\":\"3.1.\"},\"end\":13813,\"start\":13782},{\"attributes\":{\"n\":\"3.2.\"},\"end\":14723,\"start\":14700},{\"attributes\":{\"n\":\"3.2.1.\"},\"end\":14912,\"start\":14893},{\"attributes\":{\"n\":\"3.2.2.\"},\"end\":15473,\"start\":15433},{\"attributes\":{\"n\":\"3.3.\"},\"end\":18215,\"start\":18188},{\"attributes\":{\"n\":\"3.3.1.\"},\"end\":18410,\"start\":18391},{\"attributes\":{\"n\":\"3.3.2.\"},\"end\":19508,\"start\":19471},{\"attributes\":{\"n\":\"3.4.\"},\"end\":21465,\"start\":21414},{\"attributes\":{\"n\":\"4.\"},\"end\":22376,\"start\":22347},{\"attributes\":{\"n\":\"4.1.\"},\"end\":23273,\"start\":23250},{\"attributes\":{\"n\":\"4.2.\"},\"end\":25231,\"start\":25188},{\"attributes\":{\"n\":\"5.\"},\"end\":27116,\"start\":27105},{\"attributes\":{\"n\":\"5.1.\"},\"end\":27148,\"start\":27119},{\"attributes\":{\"n\":\"5.2.\"},\"end\":28974,\"start\":28936},{\"attributes\":{\"n\":\"6.\"},\"end\":32709,\"start\":32699},{\"end\":33525,\"start\":33459},{\"end\":34195,\"start\":34130},{\"end\":38121,\"start\":38093},{\"end\":38552,\"start\":38474},{\"end\":40913,\"start\":40888},{\"end\":41871,\"start\":41848},{\"end\":43596,\"start\":43575},{\"end\":45988,\"start\":45975},{\"end\":50248,\"start\":50238},{\"end\":50291,\"start\":50290},{\"end\":50649,\"start\":50638},{\"end\":50902,\"start\":50892},{\"end\":52068,\"start\":52061},{\"end\":52373,\"start\":52364},{\"end\":52907,\"start\":52898}]", "table": "[{\"end\":52059,\"start\":51151},{\"end\":52896,\"start\":52481},{\"end\":53645,\"start\":53154}]", "figure_caption": "[{\"end\":50236,\"start\":50069},{\"end\":50288,\"start\":50250},{\"end\":50369,\"start\":50292},{\"end\":50636,\"start\":50372},{\"end\":50890,\"start\":50651},{\"end\":50992,\"start\":50904},{\"end\":51151,\"start\":50995},{\"end\":52362,\"start\":52070},{\"end\":52481,\"start\":52375},{\"end\":53154,\"start\":52909}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":4575,\"start\":4567},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":10697,\"start\":10689},{\"end\":27952,\"start\":27944},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":28849,\"start\":28841},{\"end\":30136,\"start\":30128},{\"end\":30404,\"start\":30396},{\"end\":30743,\"start\":30735},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":31037,\"start\":31029},{\"end\":31289,\"start\":31281},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":31825,\"start\":31817},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":36870,\"start\":36831},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":42045,\"start\":42037},{\"end\":42098,\"start\":42090},{\"end\":43007,\"start\":42999},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":43701,\"start\":43693},{\"end\":44231,\"start\":44223},{\"end\":44243,\"start\":44235},{\"end\":47284,\"start\":47276},{\"end\":47377,\"start\":47364},{\"end\":47442,\"start\":47429},{\"end\":47645,\"start\":47632},{\"end\":47663,\"start\":47655},{\"end\":48542,\"start\":48534},{\"end\":48564,\"start\":48556}]", "bib_author_first_name": "[{\"end\":54112,\"start\":54111},{\"end\":54120,\"start\":54119},{\"end\":54122,\"start\":54121},{\"end\":54131,\"start\":54130},{\"end\":54133,\"start\":54132},{\"end\":54142,\"start\":54141},{\"end\":54144,\"start\":54143},{\"end\":54152,\"start\":54151},{\"end\":54448,\"start\":54447},{\"end\":54460,\"start\":54459},{\"end\":54473,\"start\":54472},{\"end\":54488,\"start\":54487},{\"end\":54801,\"start\":54800},{\"end\":55138,\"start\":55137},{\"end\":55146,\"start\":55145},{\"end\":55158,\"start\":55157},{\"end\":55470,\"start\":55469},{\"end\":55478,\"start\":55477},{\"end\":55486,\"start\":55485},{\"end\":55503,\"start\":55499},{\"end\":55507,\"start\":55506},{\"end\":55917,\"start\":55916},{\"end\":55919,\"start\":55918},{\"end\":56151,\"start\":56150},{\"end\":56159,\"start\":56158},{\"end\":56167,\"start\":56166},{\"end\":56180,\"start\":56176},{\"end\":56186,\"start\":56185},{\"end\":56192,\"start\":56191},{\"end\":56650,\"start\":56649},{\"end\":56660,\"start\":56659},{\"end\":56670,\"start\":56669},{\"end\":57017,\"start\":57016},{\"end\":57024,\"start\":57023},{\"end\":57298,\"start\":57297},{\"end\":57533,\"start\":57532},{\"end\":57545,\"start\":57544},{\"end\":57547,\"start\":57546},{\"end\":57820,\"start\":57819},{\"end\":57827,\"start\":57826},{\"end\":57837,\"start\":57836},{\"end\":57844,\"start\":57843},{\"end\":57846,\"start\":57845},{\"end\":58139,\"start\":58138},{\"end\":58149,\"start\":58148},{\"end\":58159,\"start\":58158},{\"end\":58170,\"start\":58169},{\"end\":58405,\"start\":58404},{\"end\":58411,\"start\":58410},{\"end\":58420,\"start\":58419},{\"end\":58427,\"start\":58426},{\"end\":58903,\"start\":58902},{\"end\":58911,\"start\":58910},{\"end\":58929,\"start\":58928},{\"end\":59417,\"start\":59416},{\"end\":59430,\"start\":59429},{\"end\":59441,\"start\":59440},{\"end\":59722,\"start\":59721},{\"end\":59731,\"start\":59730},{\"end\":59738,\"start\":59737},{\"end\":59756,\"start\":59755},{\"end\":59758,\"start\":59757},{\"end\":60181,\"start\":60180},{\"end\":60190,\"start\":60189},{\"end\":60197,\"start\":60196},{\"end\":60205,\"start\":60204},{\"end\":60522,\"start\":60521},{\"end\":60533,\"start\":60532},{\"end\":60843,\"start\":60842},{\"end\":61076,\"start\":61075},{\"end\":61084,\"start\":61083},{\"end\":61086,\"start\":61085},{\"end\":61101,\"start\":61100},{\"end\":61471,\"start\":61470},{\"end\":61479,\"start\":61478},{\"end\":61481,\"start\":61480},{\"end\":61490,\"start\":61489},{\"end\":61502,\"start\":61501},{\"end\":61517,\"start\":61516},{\"end\":61525,\"start\":61524},{\"end\":61952,\"start\":61951},{\"end\":61961,\"start\":61960},{\"end\":61973,\"start\":61972},{\"end\":62316,\"start\":62315},{\"end\":62325,\"start\":62324},{\"end\":62327,\"start\":62326},{\"end\":62336,\"start\":62335},{\"end\":62637,\"start\":62636},{\"end\":62657,\"start\":62656},{\"end\":62668,\"start\":62667},{\"end\":63014,\"start\":63013},{\"end\":63023,\"start\":63022},{\"end\":63033,\"start\":63032},{\"end\":63043,\"start\":63042},{\"end\":63298,\"start\":63297},{\"end\":63309,\"start\":63308},{\"end\":63317,\"start\":63316},{\"end\":63319,\"start\":63318},{\"end\":63331,\"start\":63330},{\"end\":63335,\"start\":63332},{\"end\":63344,\"start\":63343},{\"end\":63354,\"start\":63353},{\"end\":63368,\"start\":63367},{\"end\":63370,\"start\":63369},{\"end\":63386,\"start\":63385},{\"end\":63402,\"start\":63401},{\"end\":63404,\"start\":63403},{\"end\":63741,\"start\":63740},{\"end\":63743,\"start\":63742},{\"end\":63753,\"start\":63752},{\"end\":63765,\"start\":63764},{\"end\":63776,\"start\":63775},{\"end\":63778,\"start\":63777},{\"end\":63788,\"start\":63787},{\"end\":63790,\"start\":63789},{\"end\":64123,\"start\":64122},{\"end\":64342,\"start\":64341},{\"end\":64352,\"start\":64351},{\"end\":64365,\"start\":64364},{\"end\":64378,\"start\":64377},{\"end\":64389,\"start\":64388},{\"end\":64736,\"start\":64735},{\"end\":64746,\"start\":64745},{\"end\":64759,\"start\":64758},{\"end\":64761,\"start\":64760},{\"end\":65044,\"start\":65043},{\"end\":65046,\"start\":65045},{\"end\":65272,\"start\":65271},{\"end\":65282,\"start\":65281},{\"end\":65292,\"start\":65291},{\"end\":65707,\"start\":65706},{\"end\":65717,\"start\":65716},{\"end\":65733,\"start\":65728},{\"end\":65737,\"start\":65736},{\"end\":66198,\"start\":66197},{\"end\":66217,\"start\":66216},{\"end\":66493,\"start\":66492},{\"end\":66502,\"start\":66501},{\"end\":66516,\"start\":66515},{\"end\":66525,\"start\":66524},{\"end\":66538,\"start\":66534},{\"end\":66542,\"start\":66541},{\"end\":66778,\"start\":66777},{\"end\":67034,\"start\":67033},{\"end\":67044,\"start\":67043},{\"end\":67053,\"start\":67052},{\"end\":67062,\"start\":67061},{\"end\":67071,\"start\":67070},{\"end\":67083,\"start\":67082},{\"end\":67093,\"start\":67092},{\"end\":67104,\"start\":67103},{\"end\":67111,\"start\":67110},{\"end\":67125,\"start\":67124},{\"end\":67555,\"start\":67554},{\"end\":67566,\"start\":67565},{\"end\":67576,\"start\":67575},{\"end\":67589,\"start\":67588},{\"end\":67599,\"start\":67598},{\"end\":67961,\"start\":67960},{\"end\":68205,\"start\":68204},{\"end\":68463,\"start\":68462},{\"end\":68694,\"start\":68693},{\"end\":68701,\"start\":68700},{\"end\":68703,\"start\":68702},{\"end\":68710,\"start\":68709},{\"end\":69206,\"start\":69205},{\"end\":69208,\"start\":69207},{\"end\":69220,\"start\":69219},{\"end\":69517,\"start\":69516},{\"end\":69526,\"start\":69525},{\"end\":69853,\"start\":69852},{\"end\":69862,\"start\":69861},{\"end\":70143,\"start\":70142},{\"end\":70145,\"start\":70144},{\"end\":70387,\"start\":70386},{\"end\":70398,\"start\":70397},{\"end\":70411,\"start\":70410},{\"end\":70420,\"start\":70419},{\"end\":70430,\"start\":70429},{\"end\":70877,\"start\":70873},{\"end\":70885,\"start\":70884},{\"end\":70896,\"start\":70895},{\"end\":70910,\"start\":70909},{\"end\":70923,\"start\":70922}]", "bib_author_last_name": "[{\"end\":54117,\"start\":54113},{\"end\":54128,\"start\":54123},{\"end\":54139,\"start\":54134},{\"end\":54149,\"start\":54145},{\"end\":54162,\"start\":54153},{\"end\":54457,\"start\":54449},{\"end\":54470,\"start\":54461},{\"end\":54485,\"start\":54474},{\"end\":54497,\"start\":54489},{\"end\":54809,\"start\":54802},{\"end\":55143,\"start\":55139},{\"end\":55155,\"start\":55147},{\"end\":55163,\"start\":55159},{\"end\":55475,\"start\":55471},{\"end\":55483,\"start\":55479},{\"end\":55497,\"start\":55487},{\"end\":55519,\"start\":55508},{\"end\":55925,\"start\":55920},{\"end\":56156,\"start\":56152},{\"end\":56164,\"start\":56160},{\"end\":56174,\"start\":56168},{\"end\":56183,\"start\":56181},{\"end\":56189,\"start\":56187},{\"end\":56200,\"start\":56193},{\"end\":56657,\"start\":56651},{\"end\":56667,\"start\":56661},{\"end\":56675,\"start\":56671},{\"end\":57021,\"start\":57018},{\"end\":57035,\"start\":57025},{\"end\":57307,\"start\":57299},{\"end\":57542,\"start\":57534},{\"end\":57555,\"start\":57548},{\"end\":57824,\"start\":57821},{\"end\":57834,\"start\":57828},{\"end\":57841,\"start\":57838},{\"end\":57857,\"start\":57847},{\"end\":58146,\"start\":58140},{\"end\":58156,\"start\":58150},{\"end\":58167,\"start\":58160},{\"end\":58175,\"start\":58171},{\"end\":58408,\"start\":58406},{\"end\":58417,\"start\":58412},{\"end\":58424,\"start\":58421},{\"end\":58431,\"start\":58428},{\"end\":58908,\"start\":58904},{\"end\":58926,\"start\":58912},{\"end\":58940,\"start\":58930},{\"end\":59427,\"start\":59418},{\"end\":59438,\"start\":59431},{\"end\":59452,\"start\":59442},{\"end\":59728,\"start\":59723},{\"end\":59735,\"start\":59732},{\"end\":59753,\"start\":59739},{\"end\":59769,\"start\":59759},{\"end\":60187,\"start\":60182},{\"end\":60194,\"start\":60191},{\"end\":60202,\"start\":60198},{\"end\":60211,\"start\":60206},{\"end\":60530,\"start\":60523},{\"end\":60537,\"start\":60534},{\"end\":60854,\"start\":60844},{\"end\":61081,\"start\":61077},{\"end\":61098,\"start\":61087},{\"end\":61107,\"start\":61102},{\"end\":61476,\"start\":61472},{\"end\":61487,\"start\":61482},{\"end\":61499,\"start\":61491},{\"end\":61514,\"start\":61503},{\"end\":61522,\"start\":61518},{\"end\":61531,\"start\":61526},{\"end\":61958,\"start\":61953},{\"end\":61970,\"start\":61962},{\"end\":61978,\"start\":61974},{\"end\":62322,\"start\":62317},{\"end\":62333,\"start\":62328},{\"end\":62339,\"start\":62337},{\"end\":62654,\"start\":62638},{\"end\":62665,\"start\":62658},{\"end\":62677,\"start\":62669},{\"end\":63020,\"start\":63015},{\"end\":63030,\"start\":63024},{\"end\":63040,\"start\":63034},{\"end\":63051,\"start\":63044},{\"end\":63306,\"start\":63299},{\"end\":63314,\"start\":63310},{\"end\":63328,\"start\":63320},{\"end\":63341,\"start\":63336},{\"end\":63351,\"start\":63345},{\"end\":63365,\"start\":63355},{\"end\":63383,\"start\":63371},{\"end\":63399,\"start\":63387},{\"end\":63412,\"start\":63405},{\"end\":63750,\"start\":63744},{\"end\":63762,\"start\":63754},{\"end\":63773,\"start\":63766},{\"end\":63785,\"start\":63779},{\"end\":63797,\"start\":63791},{\"end\":64133,\"start\":64124},{\"end\":64349,\"start\":64343},{\"end\":64362,\"start\":64353},{\"end\":64375,\"start\":64366},{\"end\":64386,\"start\":64379},{\"end\":64399,\"start\":64390},{\"end\":64743,\"start\":64737},{\"end\":64756,\"start\":64747},{\"end\":64768,\"start\":64762},{\"end\":65053,\"start\":65047},{\"end\":65279,\"start\":65273},{\"end\":65289,\"start\":65283},{\"end\":65303,\"start\":65293},{\"end\":65714,\"start\":65708},{\"end\":65726,\"start\":65718},{\"end\":66214,\"start\":66199},{\"end\":66225,\"start\":66218},{\"end\":66499,\"start\":66494},{\"end\":66513,\"start\":66503},{\"end\":66522,\"start\":66517},{\"end\":66532,\"start\":66526},{\"end\":66785,\"start\":66779},{\"end\":67041,\"start\":67035},{\"end\":67050,\"start\":67045},{\"end\":67059,\"start\":67054},{\"end\":67068,\"start\":67063},{\"end\":67080,\"start\":67072},{\"end\":67090,\"start\":67084},{\"end\":67101,\"start\":67094},{\"end\":67108,\"start\":67105},{\"end\":67122,\"start\":67112},{\"end\":67132,\"start\":67126},{\"end\":67563,\"start\":67556},{\"end\":67573,\"start\":67567},{\"end\":67586,\"start\":67577},{\"end\":67596,\"start\":67590},{\"end\":67606,\"start\":67600},{\"end\":67967,\"start\":67962},{\"end\":68216,\"start\":68206},{\"end\":68469,\"start\":68464},{\"end\":68698,\"start\":68695},{\"end\":68707,\"start\":68704},{\"end\":68714,\"start\":68711},{\"end\":69217,\"start\":69209},{\"end\":69226,\"start\":69221},{\"end\":69523,\"start\":69518},{\"end\":69533,\"start\":69527},{\"end\":69859,\"start\":69854},{\"end\":69869,\"start\":69863},{\"end\":70153,\"start\":70146},{\"end\":70395,\"start\":70388},{\"end\":70408,\"start\":70399},{\"end\":70417,\"start\":70412},{\"end\":70427,\"start\":70421},{\"end\":70436,\"start\":70431},{\"end\":70882,\"start\":70878},{\"end\":70893,\"start\":70886},{\"end\":70907,\"start\":70897},{\"end\":70920,\"start\":70911},{\"end\":70933,\"start\":70924}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":121836360},\"end\":54406,\"start\":54034},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":1806222},\"end\":54732,\"start\":54408},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":15880012},\"end\":55032,\"start\":54734},{\"attributes\":{\"id\":\"b3\"},\"end\":55402,\"start\":55034},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":15693605},\"end\":55884,\"start\":55404},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":121781338},\"end\":56095,\"start\":55886},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":57246310},\"end\":56584,\"start\":56097},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":11361745},\"end\":56928,\"start\":56586},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":160705},\"end\":57283,\"start\":56930},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":206770307},\"end\":57471,\"start\":57285},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":1878582},\"end\":57775,\"start\":57473},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":28671436},\"end\":58080,\"start\":57777},{\"attributes\":{\"id\":\"b12\"},\"end\":58356,\"start\":58082},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":206594692},\"end\":58783,\"start\":58358},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":55700923},\"end\":59368,\"start\":58785},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":54558282},\"end\":59677,\"start\":59370},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":9433631},\"end\":60139,\"start\":59679},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":44100821},\"end\":60441,\"start\":60141},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":71134},\"end\":60785,\"start\":60443},{\"attributes\":{\"id\":\"b19\"},\"end\":60965,\"start\":60787},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":85546658},\"end\":61360,\"start\":60967},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":202773833},\"end\":61869,\"start\":61362},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":49314079},\"end\":62229,\"start\":61871},{\"attributes\":{\"id\":\"b23\"},\"end\":62279,\"start\":62231},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":202718866},\"end\":62558,\"start\":62281},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":6294674},\"end\":62954,\"start\":62560},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":14542261},\"end\":63242,\"start\":62956},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":2088679},\"end\":63677,\"start\":63244},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":59608823},\"end\":64082,\"start\":63679},{\"attributes\":{\"id\":\"b29\"},\"end\":64261,\"start\":64084},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":44085695},\"end\":64700,\"start\":64263},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":174802983},\"end\":64992,\"start\":64702},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":121053719},\"end\":65205,\"start\":64994},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":6292807},\"end\":65609,\"start\":65207},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":206592585},\"end\":66139,\"start\":65611},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":207158152},\"end\":66450,\"start\":66141},{\"attributes\":{\"doi\":\"arXiv:1904.01685\",\"id\":\"b36\"},\"end\":66716,\"start\":66452},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":122932724},\"end\":66961,\"start\":66718},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":202786778},\"end\":67477,\"start\":66963},{\"attributes\":{\"doi\":\"arXiv:1701.06548\",\"id\":\"b39\"},\"end\":67820,\"start\":67479},{\"attributes\":{\"id\":\"b40\"},\"end\":68139,\"start\":67822},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":16643156},\"end\":68394,\"start\":68141},{\"attributes\":{\"id\":\"b42\"},\"end\":68588,\"start\":68396},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":52892244},\"end\":69118,\"start\":68590},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":13029927},\"end\":69453,\"start\":69120},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":2604654},\"end\":69768,\"start\":69455},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":2448111},\"end\":70108,\"start\":69770},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":122626010},\"end\":70325,\"start\":70110},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":206593880},\"end\":70830,\"start\":70327},{\"attributes\":{\"id\":\"b49\"},\"end\":71049,\"start\":70832}]", "bib_title": "[{\"end\":54109,\"start\":54034},{\"end\":54445,\"start\":54408},{\"end\":54798,\"start\":54734},{\"end\":55467,\"start\":55404},{\"end\":55914,\"start\":55886},{\"end\":56148,\"start\":56097},{\"end\":56647,\"start\":56586},{\"end\":57014,\"start\":56930},{\"end\":57295,\"start\":57285},{\"end\":57530,\"start\":57473},{\"end\":57817,\"start\":57777},{\"end\":58402,\"start\":58358},{\"end\":58900,\"start\":58785},{\"end\":59414,\"start\":59370},{\"end\":59719,\"start\":59679},{\"end\":60178,\"start\":60141},{\"end\":60519,\"start\":60443},{\"end\":61073,\"start\":60967},{\"end\":61468,\"start\":61362},{\"end\":61949,\"start\":61871},{\"end\":62313,\"start\":62281},{\"end\":62634,\"start\":62560},{\"end\":63011,\"start\":62956},{\"end\":63295,\"start\":63244},{\"end\":63738,\"start\":63679},{\"end\":64339,\"start\":64263},{\"end\":64733,\"start\":64702},{\"end\":65041,\"start\":64994},{\"end\":65269,\"start\":65207},{\"end\":65704,\"start\":65611},{\"end\":66195,\"start\":66141},{\"end\":66775,\"start\":66718},{\"end\":67031,\"start\":66963},{\"end\":68202,\"start\":68141},{\"end\":68691,\"start\":68590},{\"end\":69203,\"start\":69120},{\"end\":69514,\"start\":69455},{\"end\":69850,\"start\":69770},{\"end\":70140,\"start\":70110},{\"end\":70384,\"start\":70327}]", "bib_author": "[{\"end\":54119,\"start\":54111},{\"end\":54130,\"start\":54119},{\"end\":54141,\"start\":54130},{\"end\":54151,\"start\":54141},{\"end\":54164,\"start\":54151},{\"end\":54459,\"start\":54447},{\"end\":54472,\"start\":54459},{\"end\":54487,\"start\":54472},{\"end\":54499,\"start\":54487},{\"end\":54811,\"start\":54800},{\"end\":55145,\"start\":55137},{\"end\":55157,\"start\":55145},{\"end\":55165,\"start\":55157},{\"end\":55477,\"start\":55469},{\"end\":55485,\"start\":55477},{\"end\":55499,\"start\":55485},{\"end\":55506,\"start\":55499},{\"end\":55521,\"start\":55506},{\"end\":55927,\"start\":55916},{\"end\":56158,\"start\":56150},{\"end\":56166,\"start\":56158},{\"end\":56176,\"start\":56166},{\"end\":56185,\"start\":56176},{\"end\":56191,\"start\":56185},{\"end\":56202,\"start\":56191},{\"end\":56659,\"start\":56649},{\"end\":56669,\"start\":56659},{\"end\":56677,\"start\":56669},{\"end\":57023,\"start\":57016},{\"end\":57037,\"start\":57023},{\"end\":57309,\"start\":57297},{\"end\":57544,\"start\":57532},{\"end\":57557,\"start\":57544},{\"end\":57826,\"start\":57819},{\"end\":57836,\"start\":57826},{\"end\":57843,\"start\":57836},{\"end\":57859,\"start\":57843},{\"end\":58148,\"start\":58138},{\"end\":58158,\"start\":58148},{\"end\":58169,\"start\":58158},{\"end\":58177,\"start\":58169},{\"end\":58410,\"start\":58404},{\"end\":58419,\"start\":58410},{\"end\":58426,\"start\":58419},{\"end\":58433,\"start\":58426},{\"end\":58910,\"start\":58902},{\"end\":58928,\"start\":58910},{\"end\":58942,\"start\":58928},{\"end\":59429,\"start\":59416},{\"end\":59440,\"start\":59429},{\"end\":59454,\"start\":59440},{\"end\":59730,\"start\":59721},{\"end\":59737,\"start\":59730},{\"end\":59755,\"start\":59737},{\"end\":59771,\"start\":59755},{\"end\":60189,\"start\":60180},{\"end\":60196,\"start\":60189},{\"end\":60204,\"start\":60196},{\"end\":60213,\"start\":60204},{\"end\":60532,\"start\":60521},{\"end\":60539,\"start\":60532},{\"end\":60856,\"start\":60842},{\"end\":61083,\"start\":61075},{\"end\":61100,\"start\":61083},{\"end\":61109,\"start\":61100},{\"end\":61478,\"start\":61470},{\"end\":61489,\"start\":61478},{\"end\":61501,\"start\":61489},{\"end\":61516,\"start\":61501},{\"end\":61524,\"start\":61516},{\"end\":61533,\"start\":61524},{\"end\":61960,\"start\":61951},{\"end\":61972,\"start\":61960},{\"end\":61980,\"start\":61972},{\"end\":62324,\"start\":62315},{\"end\":62335,\"start\":62324},{\"end\":62341,\"start\":62335},{\"end\":62656,\"start\":62636},{\"end\":62667,\"start\":62656},{\"end\":62679,\"start\":62667},{\"end\":63022,\"start\":63013},{\"end\":63032,\"start\":63022},{\"end\":63042,\"start\":63032},{\"end\":63053,\"start\":63042},{\"end\":63308,\"start\":63297},{\"end\":63316,\"start\":63308},{\"end\":63330,\"start\":63316},{\"end\":63343,\"start\":63330},{\"end\":63353,\"start\":63343},{\"end\":63367,\"start\":63353},{\"end\":63385,\"start\":63367},{\"end\":63401,\"start\":63385},{\"end\":63414,\"start\":63401},{\"end\":63752,\"start\":63740},{\"end\":63764,\"start\":63752},{\"end\":63775,\"start\":63764},{\"end\":63787,\"start\":63775},{\"end\":63799,\"start\":63787},{\"end\":64135,\"start\":64122},{\"end\":64351,\"start\":64341},{\"end\":64364,\"start\":64351},{\"end\":64377,\"start\":64364},{\"end\":64388,\"start\":64377},{\"end\":64401,\"start\":64388},{\"end\":64745,\"start\":64735},{\"end\":64758,\"start\":64745},{\"end\":64770,\"start\":64758},{\"end\":65055,\"start\":65043},{\"end\":65281,\"start\":65271},{\"end\":65291,\"start\":65281},{\"end\":65305,\"start\":65291},{\"end\":65716,\"start\":65706},{\"end\":65728,\"start\":65716},{\"end\":65736,\"start\":65728},{\"end\":65740,\"start\":65736},{\"end\":66216,\"start\":66197},{\"end\":66227,\"start\":66216},{\"end\":66501,\"start\":66492},{\"end\":66515,\"start\":66501},{\"end\":66524,\"start\":66515},{\"end\":66534,\"start\":66524},{\"end\":66541,\"start\":66534},{\"end\":66545,\"start\":66541},{\"end\":66787,\"start\":66777},{\"end\":67043,\"start\":67033},{\"end\":67052,\"start\":67043},{\"end\":67061,\"start\":67052},{\"end\":67070,\"start\":67061},{\"end\":67082,\"start\":67070},{\"end\":67092,\"start\":67082},{\"end\":67103,\"start\":67092},{\"end\":67110,\"start\":67103},{\"end\":67124,\"start\":67110},{\"end\":67134,\"start\":67124},{\"end\":67565,\"start\":67554},{\"end\":67575,\"start\":67565},{\"end\":67588,\"start\":67575},{\"end\":67598,\"start\":67588},{\"end\":67608,\"start\":67598},{\"end\":67969,\"start\":67960},{\"end\":68218,\"start\":68204},{\"end\":68471,\"start\":68462},{\"end\":68700,\"start\":68693},{\"end\":68709,\"start\":68700},{\"end\":68716,\"start\":68709},{\"end\":69219,\"start\":69205},{\"end\":69228,\"start\":69219},{\"end\":69525,\"start\":69516},{\"end\":69535,\"start\":69525},{\"end\":69861,\"start\":69852},{\"end\":69871,\"start\":69861},{\"end\":70155,\"start\":70142},{\"end\":70397,\"start\":70386},{\"end\":70410,\"start\":70397},{\"end\":70419,\"start\":70410},{\"end\":70429,\"start\":70419},{\"end\":70438,\"start\":70429},{\"end\":70884,\"start\":70873},{\"end\":70895,\"start\":70884},{\"end\":70909,\"start\":70895},{\"end\":70922,\"start\":70909},{\"end\":70935,\"start\":70922}]", "bib_venue": "[{\"end\":55656,\"start\":55597},{\"end\":56357,\"start\":56288},{\"end\":58588,\"start\":58519},{\"end\":59097,\"start\":59028},{\"end\":59926,\"start\":59857},{\"end\":65414,\"start\":65368},{\"end\":65895,\"start\":65826},{\"end\":68871,\"start\":68802},{\"end\":70593,\"start\":70524},{\"end\":54201,\"start\":54164},{\"end\":54550,\"start\":54499},{\"end\":54864,\"start\":54811},{\"end\":55135,\"start\":55034},{\"end\":55595,\"start\":55521},{\"end\":55974,\"start\":55927},{\"end\":56286,\"start\":56202},{\"end\":56731,\"start\":56677},{\"end\":57088,\"start\":57037},{\"end\":57364,\"start\":57309},{\"end\":57604,\"start\":57557},{\"end\":57909,\"start\":57859},{\"end\":58136,\"start\":58082},{\"end\":58517,\"start\":58433},{\"end\":59026,\"start\":58942},{\"end\":59513,\"start\":59454},{\"end\":59855,\"start\":59771},{\"end\":60272,\"start\":60213},{\"end\":60598,\"start\":60539},{\"end\":60840,\"start\":60787},{\"end\":61141,\"start\":61109},{\"end\":61592,\"start\":61533},{\"end\":62031,\"start\":61980},{\"end\":62254,\"start\":62231},{\"end\":62400,\"start\":62341},{\"end\":62738,\"start\":62679},{\"end\":63076,\"start\":63053},{\"end\":63436,\"start\":63414},{\"end\":63858,\"start\":63799},{\"end\":64120,\"start\":64084},{\"end\":64460,\"start\":64401},{\"end\":64829,\"start\":64770},{\"end\":65085,\"start\":65055},{\"end\":65366,\"start\":65305},{\"end\":65824,\"start\":65740},{\"end\":66278,\"start\":66227},{\"end\":66490,\"start\":66452},{\"end\":66824,\"start\":66787},{\"end\":67193,\"start\":67134},{\"end\":67552,\"start\":67479},{\"end\":67958,\"start\":67822},{\"end\":68255,\"start\":68218},{\"end\":68460,\"start\":68396},{\"end\":68800,\"start\":68716},{\"end\":69268,\"start\":69228},{\"end\":69594,\"start\":69535},{\"end\":69922,\"start\":69871},{\"end\":70202,\"start\":70155},{\"end\":70522,\"start\":70438},{\"end\":70871,\"start\":70832}]"}}}, "year": 2023, "month": 12, "day": 17}