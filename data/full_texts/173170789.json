{"id": 173170789, "updated": "2022-02-08 02:40:19.365", "metadata": {"title": "Fair Transfer Learning with Missing Protected Attributes", "authors": "[{\"middle\":[],\"last\":\"Coston\",\"first\":\"Amanda\"},{\"middle\":[\"Natesan\"],\"last\":\"Ramamurthy\",\"first\":\"Karthikeyan\"},{\"middle\":[],\"last\":\"Wei\",\"first\":\"Dennis\"},{\"middle\":[\"R.\"],\"last\":\"Varshney\",\"first\":\"Kush\"},{\"middle\":[],\"last\":\"Speakman\",\"first\":\"Skyler\"},{\"middle\":[],\"last\":\"Mustahsan\",\"first\":\"Zairah\"},{\"middle\":[],\"last\":\"Chakraborty\",\"first\":\"Supriyo\"}]", "venue": null, "journal": "Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society", "publication_date": {"year": 2019, "month": null, "day": null}, "abstract": "Risk assessment is a growing use for machine learning models. When used in high-stakes applications, especially ones regulated by anti-discrimination laws or governed by societal norms for fairness, it is important to ensure that learned models do not propagate and scale any biases that may exist in training data. In this paper, we add on an additional challenge beyond fairness: unsupervised domain adaptation to covariate shift between a source and target distribution. Motivated by the real-world problem of risk assessment in new markets for health insurance in the United States and mobile money-based loans in East Africa, we provide a precise formulation of the machine learning with covariate shift and score parity problem. Our formulation focuses on situations in which protected attributes are not available in either the source or target domain. We propose two new weighting methods: prevalence-constrained covariate shift (PCCS) which does not require protected attributes in the target domain and target-fair covariate shift (TFCS) which does not require protected attributes in the source domain. We empirically demonstrate their efficacy in two applications.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": "2959197226", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/aies/CostonRWVSMC19", "doi": "10.1145/3306618.3314236"}}, "content": {"source": {"pdf_hash": "347aa96ee44591f10a0e6e738c596508a9b2b9de", "pdf_src": "ACM", "pdf_uri": null, "oa_url_match": false, "oa_info": {"license": null, "open_access_url": "https://dl.acm.org/doi/pdf/10.1145/3306618.3314236", "status": "BRONZE"}}, "grobid": {"id": "616275cb702bcb066bf4d406f6984e79e9ca6409", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/347aa96ee44591f10a0e6e738c596508a9b2b9de.txt", "contents": "\nFair Transfer Learning with Missing Protected Attributes\n\n\nAmanda Coston \nIBM Research\nYorktown Heights\nNYUSA\n\nCarnegie Mellon University\nPittsburghPAUSA\n\nKarthikeyan Natesan Ramamurthy \nIBM Research\nYorktown Heights\nNYUSA\n\nDennis Wei \nIBM Research\nYorktown Heights\nNYUSA\n\nKush R Varshney \nIBM Research\nYorktown Heights\nNYUSA\n\nSkyler Speakman \nIBM Research\nNairobiKenya\n\nZairah Mustahsan \nIBM Watson AI Platform\nYorktown HeightsNYUSA\n\nSupriyo Chakraborty \nIBM Research\nYorktown Heights\nNYUSA\n\nFair Transfer Learning with Missing Protected Attributes\n10.1145/3306618.3314236ACM Reference Format: Amanda Coston, Karthikeyan Natesan Ramamurthy, Dennis Wei, Kush R. Varshney, Skyler Speakman, Zairah Mustahsan, and Supriyo Chakraborty. 2019. Fair Transfer Learning with Missing Protected Attributes. In AAAI/ACM Conference on AI, Ethics, and Society (AIES '19), January 27-28, 2019, Hon-olulu, HI, USA. ACM, New York, NY, USA, 8 pages. https://Fairnesstransfer learningrisk assessments\nRisk assessment is a growing use for machine learning models. When used in high-stakes applications, especially ones regulated by anti-discrimination laws or governed by societal norms for fairness, it is important to ensure that learned models do not propagate and scale any biases that may exist in training data. In this paper, we add on an additional challenge beyond fairness: unsupervised domain adaptation to covariate shift between a source and target distribution. Motivated by the real-world problem of risk assessment in new markets for health insurance in the United States and mobile money-based loans in East Africa, we provide a precise formulation of the machine learning with covariate shift and score parity problem. Our formulation focuses on situations in which protected attributes are not available in either the source or target domain. We propose two new weighting methods: prevalence-constrained covariate shift (PCCS) which does not require protected attributes in the target domain and target-fair covariate shift (TFCS) which does not require protected attributes in the source domain. We empirically demonstrate their efficacy in two applications.\n\nINTRODUCTION\n\nThe covariate shift setting in machine learning is often encountered in real-world applications that have limitations on data collection and require training on a different probability distribution than the one a model will ultimately be tested on [3,20,23]. In this setting, the training (source) and test (target) marginal feature distributions are different but the conditional distribution of labels given features is the same in the training and test distributions. Unsupervised domain adaptation to account for covariate shift can be achieved Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. AIES ' by forms of transfer learning [11,26]. Relevant applications include risk assessment of people for credit and insurance when the provider has historical features and risk labels about its members, but is expanding into new markets with different demographics for which it does not have risk labels [22,28]. The provider must learn models from its existing market data (source distribution) to score people in the new market (target distribution).\n\nIn this paper, we propose the problem of fair transfer learning under covariate shift and methods of solution. We examine the variations of the problem in which the protected attributes are available only for the source or only available for the target. We develop two new weighting methods: prevalence-constrained covariate shift (PCCS) which does not require protected attributes in the target domain and target-fair covariate shift (TFCS) which does not require protected attributes in the source domain. Weighting methods are commonly used for fairness and covariate shift, and they have the advantage of being compatible with many classification methods.\n\nThe issue of missing protected attributes is not only encountered in covariate shift settings, but is a more general challenge [18, J. Langford in panel discussion] because legal restrictions often prevent the collection of protected attributes or their joining to the rest of the dataset. For example, under Title VII of the 1964 Civil Rights Act, employers cannot ask potential applicants about gender [4]. Gupta et al. [13] address the problem of unavailable protected attributes by constructing proxy groups using variables in the dataset that are not protected but are likely correlated to protected attributes based on prior subject matter knowledge. Our approach is neither to explicitly construct proxy groups nor to use other variables, but to use the protected attributes themselves in related datasets. This approach enables companies to audit their hiring practices for gender discrimination by using aggregated datasets like the American Community Survey that have gender as a feature. Financial institutions could also use this to evaluate whether their credit approval processes comply with regulations prohibiting discrimination in cases where they are legally or practically unable to collect the protected attribute [5].\n\nWe apply our method to the medical expenditure dataset produced by the US Department of Health and Human Services known as the Medical Expenditure Panel Survey (MEPS). Health insurance providers in the US can choose the markets in which they will offer their plans and in which ones they will not. This decision making is driven by a risk assessment of the market, and thus the task is predicting individuals with low total healthcare expenditure vs. high expenditure over the course of a year. Section 1557 of the Patient Protection and Affordable Care Act (PPACA) in the United States made discrimination in healthcare on the basis of sex and race illegal [10,14,27]. As the PPACA was enacted, many insurance companies expanded rapidly into new markets, encountering the need to perform risk assessment having expenditure data only from the markets they served, not from new markets. Wei et al. [28] presented a covariate shift-based solution to this problem without considering fairness.\n\nWe also evaluate our methods on mobile money loan approvals in East Africa. Based on the success of mobile phone-based savings products such as M-Pesa, providers have recently begun offering credit services [7]. Algorithms make loan approval decisions based on mobile usage data. There has been rapid expansion by financial service providers into new markets (in this case, different countries with different partnering mobile network operators) with a need for covariate shift-based machine learning; one such solution is presented in [22]. We evaluate PCCS and TFCS on a dataset modeled after the actual data of a commercial financial institution in Africa.\n\n\nPROBLEM SETTING 2.1 Covariate Shift\n\nWe are given labeled data {(x 1 , y 1 ), . . . , (x n , y n )} from a source domain where y i \u2208 {0, 1}. We assume one of the labels is a more favorable outcome than the other. We also have unlabeled data {x n+1 , . . . , x n+m } from a target domain to which we wish to assign labels. We use S = {1, . . . , n} and T = {n + 1, . . . , n + m} to distinguish the index sets from the source and target domains. With covariate shift, the features x i \u2208 R d , i \u2208 S, are assumed to be drawn from a source distribution with density p X (x) while x i for i \u2208 T are drawn from a different target distribution with density q X (x). It is assumed that the conditional distribution of Y , i.e. p Y | X (y | x), is the same in both domains.\n\nThe standard approach to supervised learning is to find a predictor\u0177(x) in a class H that minimizes empirical risk,\nmin y \u2208H 1 n i \u2208S L(\u0177(x i ), y i ),(1)\nwhere L is the loss function between\u0177 and y that defines the risk. As n \u2192 \u221e, the empirical risk converges to the population risk, which can be written as the iterated expectation\nE p X [E[L(\u0177(X ), Y ) | X ]](2)\nto emphasize that the outer expectation is with respect to the source distribution p X . In this ideal limit where H also contains arbitrarily complex functions, the optimal predictor in both domains, p Y | X (\u00b7 | x), can be recovered wherever p X (x) is positive. However for finite samples and constrained H , the predictor obtained by minimizing empirical risk (1) generally shows traces of p X and may not be best suited to the distribution q X under which testing occurs. Many methods that address the covariate shift problem do so by weighting training/source instances with weights w i \u2265 0 so that (1) becomes\nmin y \u2208H 1 n i \u2208S w i L(\u0177(x i ), y i ).\nIf w i = q X (x i )/p X (x i ), then the weighted empirical risk converges to (2) with p X replaced by q X , as is desired for the target domain.\n\nMultivariate density estimation is difficult and therefore it is common to estimate the ratio of densities directly. One approach treats this as a classification problem [3] where the label is the source or target distribution. Logistic regression does this naturally and has been shown to be optimal (minimum asymptotic variance) for correctly specified models [19] but performs poorly for mis-specified models [25]. We use logistic regression in Section 4 for illustration purposes, noting that more sophisticated methods exist, e.g. [12,24].\n\n\nProtected Attribute Availability\n\nWe consider the problem of fairness with respect to protected groups. The definition of protected groups is assumed given and depends on the application context. Let \u0434 i \u2208 {0, 1, . . . , G \u2212 1} represent the group identity of instance i, which may be determined by one or more protected attributes such as race and gender. We pay particular attention to situations in which protected attribute data are available only in the source or target domain. In the former case, the source data consists of triplets\n{(\u0434 i , x i , y i ), i \u2208 S} while the target data is {x i , i \u2208 T } as before. In the latter, the source data is {(x i , y i ), i \u2208 S} while the target data becomes {(\u0434 i , x i ), i \u2208 T }.\nBased on the values of {\u0434 i }, we define the partition of the source data into sets S k = {i \u2208 S : \u0434 i = k}, i.e. source examples belonging to group k, for all k = 0, . . . , G \u2212 1. The partition {T k , k = 0, . . . , G \u2212 1} of the target is defined similarly.\n\n\nFairness Metrics\n\nWe focus on notions of demographic or statistical parity that deal with the dependence of the classifier output on the protected attributes. We define a score s(x) as a function that assigns to a feature vector x a number in [0, 1] corresponding to the likelihood of a positive outcome Y = 1 given x. s(x; \u03b8 ) denotes a score function parametrized by a vector of parameters \u03b8 . Viewing X as a random variable, a distribution is induced for the score s(X ) as well. We will say that a score satisfies score parity in the strong sense if s(X ) is statistically independent of the protected group variable G. This notion may be relaxed by requiring some distributional distance D p s(X ) | G (\u00b7 | k), p s(X ) | G (\u00b7 | l) between scores conditioned on groups k l to be bounded by some constant \u03b4 > 0. Herein we focus on two weaker and more common definitions of score parity. The first is mean or average score parity,\nE[s(X ) | G = k] = E[s(X ) | G = l] \u2200k, l \u2208 {0, . . . , G \u2212 1} (3)\nwhich is the definition of \"statistical parity\" in e.g. [8]. Mean score parity may also be relaxed by allowing small deviations, and it is this relaxed definition that is targeted by the methods proposed in Section 3. The second notion is thresholded score parity at threshold t: \u2200k, l \u2208 {0, . . . , G \u2212 1},\nPr(s(X ) > t | G = k) = Pr(s(X ) > t | G = l)(4)\nwhich is also called \"statistical parity\" in e.g. [6]. Thresholded score parity applies when the score is thresholded to yield a binary prediction. It is used in Section 4 as a second fairness metric to evaluate different methods. If a score satisfies thresholded parity for all thresholds t \u2208 [0, 1], then it also satisfies parity in the strong sense above. It is clear that strong score parity implies both mean and thresholded parity. Moreover, if approximate strong parity holds in that D p s(X ) | G (\u00b7 | k), p s(X ) | G (\u00b7 | l) is small, then one expects the mean score disparity and thresholded score disparity to be small as well although the details depend on the distance measure D.\n\nA quantity not involving but related to scores is prevalence, which describes the proportions of class labels. For binary Y , it is sufficient to assess prevalence Pr(Y = 1) of the positive outcome in the entire dataset and prevalence Pr(Y = 1|G = k) for particular groups. Prevalence differences between groups are therefore a measure of bias in the dataset. Since scores are often designed to estimate either p Y | X or Y itself after thresholding, controlling group-specific prevalences is a way of encouraging mean score parity in the former case or thresholded score parity in the latter, provided that the score is an approximately unbiased estimator,\nE[s(X )] \u2248 E[Y ] or Pr(s(X ) > t) \u2248 Pr(Y = 1)\n. The method discussed in Section 3.1 relies on this relationship between prevalences and scores.\n\n\nPROPOSED METHODS\n\nGiven the popularity of weighting methods for the covariate shift problem and in works on fairness [1,15,17], we focus in this paper on weighting as a means to address covariate shift and fairness jointly. Our goal is to determine weights w i \u2265 0 for the source/training instances (x i , y i ), i \u2208 S. We propose two methods for the cases in which protected attribute information is available only for the source or target populations respectively. The method of Section 3.1 assumes nothing more than the use of a classification algorithm that accepts weights as input. The method of Section 3.2 requires differentiability of the classification loss function. It is possible to relax this assumption, for example by using smooth approximations to the loss and second-order optimization techniques as in [16]. The derivatives can be evaluated in closed form, as we do for logistic regression, or using automatic differentiation [2].\n\n\nPrevalence-Constrained Covariate Shift (PCCS)\n\nFor the scenario in which the protected attribute is available for the source population but not the target population, we propose a method that combines conventional covariate shift with weighting to bring group-specific prevalences closer together. As discussed in Section 2.3, differences in prevalences characterize dataset bias, and controlling this bias encourages score parity. Let w CS (x) be a covariate shift weight, i.e. an approximation to the ratio q X (x i )/p X (x i ), obtained through logistic regression or other methods [3,12,24,25]. The goal is to learn weights w i for each training example that are as close as possible to the covariate shift weights subject to constraints on weighted prevalences. The objective function is thus\nmin w i \u2208S |w i \u2212 w CS (x i )|.(5)\nNorms other than the \u2113 1 norm can also be used. The prevalence constraints for fairness enforce closeness between all pairs of groups:\ni \u2208S k :y i =1 w i i \u2208S k w i \u2265 i \u2208S l :y i =1 w i i \u2208S l w i \u2212 \u03b4 \u2200k, l \u2208 {0, . . . , G \u2212 1},(6)\nwhere the parameter \u03b4 trades off between differences in prevalences and deviation of w from w CS . To make these constraints convex, we add equality constraints on the proportion of weight allocated to each group:\ni \u2208S k w i = c k i \u2208S w i , k \u2208 {0, . . . , G \u2212 1}(7)\nwhere\nc k = i \u2208S k w CS (x i ) i \u2208S w CS (x i ) ,(8)\ni.e. we require the allocations to groups specified by the covariate shift weights to remain unchanged. Lastly we require weights to be non-negative:\nw i \u2265 0, i \u2208 S.(9)\nThe optimization problem is to minimize the objective in (5) subject to constraints (6)-(9).\n\n\nTarget-Fair Covariate Shift (TFCS)\n\nWe now consider the scenario in which the protected attribute is available for the target but not the source. We may directly evaluate the score disparity of the classifier on the target and adjust the classifier to reduce the disparity. We assume that the classifier parameters are chosen to minimize the weighted empirical risk,\n\u03b8 = arg min \u03b8 1 n i \u2208S w i L(s(x i ; \u03b8 ), y i ),(10)\nwhere L(s(x; \u03b8 ), y) is a twice differentiable function of \u03b8 as discussed and any regularizer is absorbed into L. Thus the classifier can be adjusted by changing the weights w i . To measure score disparity, we introduce the following fairness loss that sums the squares of average score disparities over all pairs of groups (T k , T l ):\nL f s(\u00b7;\u03b8 ) = k <l 1 |T k | i \u2208 T k s(x i ;\u03b8 ) \u2212 1 |T l | i \u2208 T l s(x i ;\u03b8 ) 2 .(11)\nThe weights w i are chosen to minimize a linear combination of this fairness loss with a classification loss:\nmin w 1 n i \u2208S w CS (x i )L(s(x i ;\u03b8 ), y i ) + \u03bbL f s(\u00b7;\u03b8 ) ,(12)\nwhere w CS (x i ) are covariate shift weights as in Section 3.1 and are fixed (not to be confused with w). The first term in (12) thus approximates classification loss on the target population by weighting the source population, where labels are available. The fairness loss L f is evaluated on the target, where the protected attribute is available. Both terms are explicit functions of the scores parametrized by\u03b8 ; the notation s(\u00b7;\u03b8 ) emphasizes this dependence. The parameters\u03b8 are a function of the optimization variables w i through (10). We propose to optimize (12) through gradient descent. The algorithm (see Algorithm 1) alternates between gradient updates to w to decrease the objective in (12) and solving (10) to obtain a new classifier from the updated w, which is then re-evaluated using (12).\n\nIn our experiments, we use a constant step size \u03b7 and terminate after a fixed number of iterations.\n\nThe combined loss (12) is generally not a convex function of the weights w i . Hence different initializations may lead to different solutions. One choice is to initialize with covariate shift weights, w = w CS . In the case of \u03bb = 0 in (12) (i.e. only classification loss), w = w CS is a stationary point as will be shown at the end of Appendix A. Accordingly for small \u03bb, w = w CS is expected to be\n\n\nAlgorithm 1 Target-Fair Covariate Shift (TFCS)\n\n\nInput:\n\nData: labeled source {(x i , y i ), i \u2208 S}, target with protected at-\ntribute {(x i , \u0434 i ), i \u2208 T } Parameters: trade-off \u03bb, step size \u03b7 Estimate covariate shift weights w CS from {x i , i \u2208 S \u222a T } w \u2190 w CS or w i \u2190 1 \u2200i (uniform) repeat\nLearn classifier parameters\u03b8 given w (10) Evaluate combined loss (12) # Gradient computations:\n\nCompute \u2207\u03b8 L c (e.g. (19)) Compute \u2207\u03b8 L f (e.g. (20)) Compute \u2202\u03b8 /\u2202w i \u2200i (15)(16) Compute \u2207 w L t (14) # Gradient update w \u2190 w \u2212 \u03b7\u2207 w L t until stopping criterion is met Output: Classifier parameters\u03b8 , weights w near-stationary. A simpler alternative is to initialize with uniform weights w i = 1.\n\nFor the scenario in which the protected attribute is available in both the source and target domains, we propose to combine the methods in Section 3.1 and this section. First, PCCS is used to achieve covariate shift and approximate score parity based on the protected attribute in the source. Then the PCCS weights are used to initialize the minimization in (12) to refine score parity in the target domain.\n\nSince the combined loss (12) is an indirect function of w via (10), the calculation of its gradient with respect to w is non-standard. Appendix A derives the necessary expressions.\n\n\nEXPERIMENTS\n\nWe demonstrate the utility of PCCS and TFCS in fair transfer learning for two applications. The first is a healthcare cost prediction scenario when a health insurance company that is servicing an existing market wants to venture into a new market, while ensuring equal benefit to all race-and gender-based intersectional groups in the new market. The second is a loan approval setting where a mobile money provider from one country in East Africa is expanding to another country while being non-discriminatory according to age and gender.\n\nWe use AUC to assess accuracy and we compute four fairness metrics:\n\n(1) Mean score parity (MSP) loss: Square root of sum of squares of differences between mean scores for all pairs of groups (see equations (3) and (11)). (2) Thresholded score parity (TSP) loss: Square root of sum of squares of differences between thresholded scores for all pairs of groups (see equation (4)). Testing is always performed on the target population where true labels and protected attributes are used to evaluate accuracy and fairness. PCCS and Kamiran-Calders use protected attributes only from the source while TFCS uses them only from the target. In all cases, logistic regression is used as the classification algorithm and also to obtain covariate shift weights. This choice is intended as a simple illustration of the methods and richer models can certainly be substituted. The TFCS method was initialized using uniform weights and its stopping criterion is a maximum number of iterations, usually set to a few hundred, depending on the dataset used.\n\nWe studied the behavior of PCCS and TFCS for various values of their respective free parameters \u03b4 and \u03bb. For future applications, the choice of the free parameter will depend on the particular setting (including the initial discrepancies in group prevalences) but generally we would recommend using a \u03b4 in [0, .075] for PCCS. For TFCS, we recommend using cross-validation to choose \u03bb.\n\nWe note that transfer learning can exacerbate discrimination or improve fairness; the direction depends on the application, and indeed, in our experiments we observe both. Regardless of whether transfer learning alone helps or hurts fairness, our fairness-aware transfer learning methods are able to improve the fairness metrics.\n\n\nMedical Expenditure Panel Survey (MEPS)\n\nThe MEPS dataset [9] is obtained using a nationally representative survey of the US population. It contains annual healthcare cost, demographics, and self-reported medical information. We use the data from panel 19 of the 2015 survey. There is no concept of market in this dataset since it does not come from an insurance provider (those datasets are proprietary, but MEPS shares relevant characteristics with such datasets). We define the source market to consist of people earning less than national median income (USD 21,000), and target market to consist of the rest of the population.\n\nWe consider two protected attributes: gender and race. Both are legally protected, as discussed in Section 1. In our experiments, the races considered are non-Hispanic whites and non-Hispanic blacks. The outcome variable is the binarized annual healthcare expenditure (low cost and high cost), obtained by thresholding the expenditure at its national median (USD 1,272). Representative features considered for the classification problem include age, marital status, education, military status, self-reported health conditions, self-reported physical and cognitive limitations, employment status, poverty category, and insurance coverage status. The threshold t used for obtaining the TSP metric is 0.5 since the prevalence of outcomes in this data is equally balanced at 0.5. The disparity in Table 1: MEPS outcome disparities between various groups in source (low-income) and target (high-income) populations. The disparity is given by Pr(Y = 1|G = k) \u2212 Pr(Y = 1|G = l) with probabilities expressed as percentages.\n\nGroups k and l Source Target  prevalence of high cost outcomes among various gender-race intersections is provided in Table 1. The largest disparity is between black males and white females, whereas the smallest is between white males and black females. We compare PCCS and TFCS with the baseline approaches in Table 2. The AUC on the target population for all methods are similar except for TFCS with \u03bb = 100, as will be explained later.\n\nThe methods do show differences however in score disparity in the target. Covariate shift without any fairness adjustments happens to significantly reduce the fairness losses, and Kamiran-Calders yields a similar reduction. They are further reduced with PCCS, which combines elements of covariate shift and parityinducing reweighting. TFCS with \u03bb = 100 achieves by far the lowest score parity losses, at the cost of a lower AUC. The large setting for \u03bb is intended to show the parity levels that can be achieved. Figure 1 shows the variation of fairness and accuracy metrics with respect to \u03b4 for PCCS. While the MSP and TSP curves are somewhat variable, there is a slight downward trend in disparities as \u03b4 decreases toward zero and tightens the prevalence constraints (6). The AUC is nearly constant. The behavior of TFCS with changing \u03bb is illustrated in Figure 2. Recall that \u03bb weights the fairness component of the combined loss (12). When \u03bb is small, all metrics are closer to the values obtained with methods that do not account for fairness (unadapted, covariate shift), as expected. As \u03bb increases past 1, the score parity losses decrease dramatically while the AUC undergoes a more modest reduction.\n\nAlthough we do not observe a boost in AUC from covariate shift methods, our fairness methods that adjust for covariate shift improve the fairness metrics over Kamiran-Calders, which does not account for covariate shift.\n\n\nMobile Money Loan Approval in East Africa\n\nWe consider the expansion of mobile-money credit services into a new market of East Africa. We use data from the original market to train a model that is deployed in the new market. Age (thresholded at 35 years) and gender are protected attributes. The prediction task is to identify who will repay a loan; the features are described in [22] and include airtime usage and mobile money volumes sent and received over a 6-month period. The threshold for approving a loan is t = 0.75 since banks will only issue a loan if they are confident a user will repay. Table 4 illustrates that transfer learning significantly improves score parity in the target population, with covariate shift and even   in the unadapted case. We note that this is not because the source has less dataset bias; in fact, in Table 3, we see that the source dataset  has larger disparities in loan approvals over the four demographic groups. PCCS and TFCS further reduce the four fairness metrics with little to no change in AUC for the target population. PCCS and TFCS outperform Kamiran-Calders, which only yields results on par with covariate shift. For this application, we found that increasing \u03bb did not improve the score disparities for TFCS. Thus Table 4 shows results for \u03bb = 0.01 which maintains the AUC. Figure 3 shows the results for PCCS as we vary \u03b4 to trade off improving AUC against reducing the fairness losses. For \u03b4 \u2265 0.08, the weighted prevalence constraints (6) are loose enough to allow the covariate shift solution w = w CS and the metrics converge accordingly. The trade-off between AUC and score parity is seen for smaller \u03b4 .\n\n\nCONCLUSION\n\nThis paper has discussed methods that address jointly the problem of covariate shift between source and target populations and the need to ensure fairness in a predictor's outputs toward protected groups. We have focused specifically on mean score parity and thresholded score parity measures of group fairness. Both of the proposed methods, prevalence-constrained covariate shift (PCCS) and target-fair covariate shift (TFCS), are based on sample reweighting and thus fit well with existing domain adaptation techniques and a variety of classification algorithms. Together they can accommodate the important practical limitation of having protected group information only in the source or target domain. Tested on two datasets, PCCS and TFCS show reductions in score disparity compared to baselines with little change in AUC. The MEPS dataset and mobile money credit dataset are new to the algorithmic fairness literature and, we believe, are more reflective of real risk assessment applications than some prior benchmarks.\n\n\nA GRADIENT DERIVATIONS FOR TFCS\n\nThe following derivation is similar to and takes inspiration from the theory of influence functions [16], which describe the effect of individual training points on model parameters. Here we consider the effect of re-weighting all training points at once.\n\nFirst define L c to be the re-weighted classification loss in (12),\nL c (\u03b8 ) = 1 n i \u2208S w CS (x i )L s(x i ;\u03b8 ), y i .\nThe derivative of L c with respect to each w i is given by the chain rule as \u2202L c \u2202w i = \u2207\u03b8 L c T \u2202\u03b8 \u2202w i ,\n\nand similarly for L f . The second factor in (13) is the vector of partial derivatives \u2202\u03b8 j /\u2202w i for all j. Hence for the combined loss\nL t = L c + \u03bbL f , \u2202L t \u2202w i = \u2207\u03b8 L c + \u03bb\u2207\u03b8 L f T \u2202\u03b8 \u2202w i .(14)\nTo derive an expression for \u2202\u03b8 /\u2202w i , we use the fact that if\u03b8 is a minimizer in (10), then it must satisfy the first-order optimality conditions i \u2208S w i \u2202L s(x i ;\u03b8 ), y i \u2202\u03b8 j = 0 \u2200j.\n\nFor fixed {(x i , y i ), i \u2208 S}, these conditions give a set of implicit equations for\u03b8 in terms of {w i }. We may obtain an explicit expression for the derivative \u2202\u03b8 /\u2202w i using the method of eliminating differentials [21,Ch. 11] as follows:\ndw i \u2202L s(x i ;\u03b8 ), y i \u2202\u03b8 j + i \u2032 \u2208S w i \u2032 k \u2202 2 L s(x i \u2032 ;\u03b8 ), y i \u2032 \u2202\u03b8 j \u2202\u03b8 k d\u03b8 k = 0.\nRewriting in matrix-vector notation, \u2207\u03b8 L s(x i ;\u03b8 ), y i + H\u03b8 \u2202\u03b8 \u2202w i = 0,\n\nwhere we have defined\nH\u03b8 = i \u2208S w i \u2207 2\u03b8 L s(x i ;\u03b8 ), y i .(15)\nHence\n\u2202\u03b8 \u2202w i = \u2212H \u22121 \u03b8 \u2207\u03b8 L s(x i ;\u03b8 ), y i .(16)\nFor the case of binary classification with log loss L (aka crossentropy) and logistic regression, we have where \u03c3 (t) denotes the sigmoid function 1 1+e \u2212t . Then\n\u2207\u03b8 s = e \u2212\u03b8 T x 1 + e \u2212\u03b8 T x 2 \u00b7 x = s(1 \u2212 s)x,(17)\n\u2207\u03b8 L = (\u2212y(1 \u2212 s) + (1 \u2212 y)s)x .\n\nUsing (18) and letting s i = s(x i ;\u03b8 ), the gradient of the classification loss is therefore\n\u2207\u03b8 L c = 1 n i \u2208S w CS (x i )[\u2212y i (1 \u2212 s i ) + (1 \u2212 y i )s i ]x i .(19)\nLikewise using (17), the gradient of the fairness loss is\n\u2207 \u03b8 L F = 2 k <l \uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 1 |T k | i \u2208 T k s i \u2212 1 |T l | i \u2208 T l s i \u00d7 1 |T k | i \u2208 T k s i 1 \u2212 s i x i \u2212 1 |T l | i \u2208 T l s i 1 \u2212 s i x i \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb .(20)\nFor the Hessian we find\n\u2207 2\u03b8 L = x \u2207\u03b8 s T = s(1 \u2212 s)xx T ,(21)\nwhich is needed in (15). To close this section, we justify the earlier statement that w = w CS is a stationary point in the case \u03bb = 0. Since\u03b8 is a minimizer in (10), it satisfies 1 n i \u2208S w i \u2207 \u03b8 L s(x i ;\u03b8 ), y i = 0.\n\nThe left-hand side coincides with \u2207\u03b8 L c when w = w CS and therefore \u2207\u03b8 L c = 0. Combining this with \u03bb = 0 in (14) implies that \u2207 w L t = 0 at w = w CS .\n\n( 3 )\n3Max \u2206 MSP: Maximum of absolute differences between mean scores for all pairs of groups. (4) Max \u2206 TSP: Maximum of absolute differences between thresholded scores for all pairs of groups.We compare our proposed methods against four baselines:(1) Native: Train and test on the target population (i.e. not in the transfer learning setting). (2) Unadapted transfer learning: Train on the source population and test on target population without any adaptation to the target population during training. (3) Covariate shift: Train on the source population reweighed to resemble the target population. (4) Kamiran Calders: Correct the source dataset for fairness using the approach proposed in[15] without performing any covariate shift.\n\nFigure 1 :\n1Variation of score parities and AUC with the PCCS trade-off parameter \u03b4 for the MEPS dataset.\n\nFigure 2 :\n2Variation of score parities and AUC with the TFCS trade-off parameter \u03bb for the MEPS dataset.\n\nFigure 3 :\n3Variation of score parities and AUC with the PCCS trade-off parameter \u03b4 for the Mobile Money dataset.\n\nL\n(s, y) = \u2212y log(s) \u2212 (1 \u2212 y) log(1 \u2212 s), s(x;\u03b8 ) = \u03c3 (\u03b8 T x) = 1 1 + e \u2212\u03b8 T x .\n\n\n19, January 27-28, 2019, Honolulu, HI, USA \u00a9 2019 Association for Computing Machinery. ACM ISBN 978-1-4503-6324-2/19/01. . . $15.00 https://doi.org/10.1145/3306618.3314236\n\nTable 2 :\n2Results on MEPS dataset. Source: low-income population, Target: high-income population. Disparity measures are shown as percentages. All metrics are reported for target.AUC \nMSP TSP \nMax \nMax \nloss loss \u2206 MSP \u2206 TSP \nNative 0.800 \n29.0 42.4 \n19.4 \n27.7 \nUnadapted 0.799 \n27.0 43.3 \n18.9 \n30.2 \nCovariate Shift 0.786 \n17.6 30.0 \n12.3 \n21.1 \nKamiran Calders 0.799 \n16.5 26.2 \n11.5 \n18.5 \nPCCS (\u03b4 = 0.05) 0.788 \n14.2 20.3 \n9.7 \n14.3 \nTFCS (\u03bb = 100) 0.708 \n2.2 \n5.1 \n1.4 \n3.4 \n\n\n\nTable 3 :\n3Mobile Money outcome disparities between various \ngroups in source (original market) and target (new market) \npopulations. The disparity is given by Pr(Y = 1|G = k)\u2212Pr(Y = \n1|G = l) with probabilities expressed as percentages. \n\nGroups k and l \nSource Target \nfemale 35+, female under 35 \n7.0 \n6.2 \nfemale 35+, male 35+ \n3.5 \n1.4 \nfemale 35+, male under 35 \n11.1 \n9.2 \nfemale under 35, male 35+ \n-3.6 \n-4.8 \nfemale under 35, male under 35 \n4.1 \n3.0 \nmale 35+, male under 35 \n7.7 \n7.9 \n\n\n\nTable 4 :\n4Results on Mobile Money dataset. Source: Country 1, Target: Country 2. Disparity measures are shown as percentages. All metrics are reported for target.AUC \nMSP TSP \nMax \nMax \nloss loss \u2206 MSP \u2206 TSP \nNative 0.658 \n7.6 23.0 \n4.9 \n14.5 \nUnadapted 0.642 \n4.2 12.6 \n2.5 \n8.1 \nCovariate Shift 0.639 \n3.8 11.1 \n2.7 \n7.2 \nKamiran Calders 0.640 \n4.0 12.5 \n2.5 \n7.7 \nPCCS (\u03b4 = .05) 0.630 \n2.4 \n5.7 \n1.5 \n3.3 \nTFCS (\u03bb = .01) 0.639 \n2.6 \n6.8 \n1.8 \n4.4 \n\n\nACKNOWLEDGMENTSWe acknowledge the helpful comments and feedback of Aldo Pareja. This work was conducted under the auspices of the IBM Science for Social Good initiative. This research in part was sponsored by the U.S. Army Research Lab and the U.K. Ministry of Defence under Agreement Number W911NF-16-3-0001. The views and conclusions contained in this document are those of the authors and should not be interpreted as representing the official policies, either expressed or implied, of the U.S. Army Research Laboratory, the U.S. Government, the U.K. Ministry of Defence or the U.K. Government. The U.S. and U.K. Governments are authorized to reproduce and distribute reprints for Government purposes notwithstanding any copyright notation hereon.\nA reductions approach to fair classification. Alekh Agarwal, Alina Beygelzimer, Miroslav Dud\u00edk, John Langford, Hanna Wallach, Proc. International Conference on Machine Learning (ICML). International Conference on Machine Learning (ICML)Stockholm, SwedenAlekh Agarwal, Alina Beygelzimer, Miroslav Dud\u00edk, John Langford, and Hanna Wallach. 2018. A reductions approach to fair classification. In Proc. International Conference on Machine Learning (ICML). Stockholm, Sweden.\n\nAutomatic Differentiation in Machine Learning: A Survey. At\u0131l\u0131m G\u00fcne\u015f Baydin, A Barak, Alexey Pearlmutter, Jeffrey Mark Andreyevich Radul, Siskind, Journal of Machine Learning Research. 18At\u0131l\u0131m G\u00fcne\u015f Baydin, Barak A. Pearlmutter, Alexey Andreyevich Radul, and Jeffrey Mark Siskind. 2018. Automatic Differentiation in Machine Learning: A Survey. Journal of Machine Learning Research 18, 2 (2018), 1-43.\n\nDiscriminative Learning Under Covariate Shift. Steffen Bickel, Michael Br\u00fcckner, Tobias Scheffer, Journal of Machine Learning Research. 10Steffen Bickel, Michael Br\u00fcckner, and Tobias Scheffer. 2009. Discriminative Learning Under Covariate Shift. Journal of Machine Learning Research 10 (Sept. 2009), 2137-2155.\n\nBringing gender and race in: US employment discrimination policy. M Kim, Blankenship, Gender & Society. 7Kim M Blankenship. 1993. Bringing gender and race in: US employment discrim- ination policy. Gender & Society 7, 2 (1993), 204-226.\n\nJiahao Chen, Nathan Kallus, Xiaojie Mao, Geoffry Svacha, Madeleine Udell, arXiv:1811.11154Fairness Under Unawareness: Assessing Disparity When Protected Class Is Unobserved. arXiv preprintJiahao Chen, Nathan Kallus, Xiaojie Mao, Geoffry Svacha, and Madeleine Udell. 2018. Fairness Under Unawareness: Assessing Disparity When Protected Class Is Unobserved. arXiv preprint arXiv:1811.11154 (2018).\n\nFair Prediction with Disparate Impact: A Study of Bias in Recidivism Prediction Instruments. Alexandra Chouldechova, Big Data. 5Alexandra Chouldechova. 2017. Fair Prediction with Disparate Impact: A Study of Bias in Recidivism Prediction Instruments. Big Data 5, 2 (2017), 153-163.\n\nHow M-Shwari Works: The Story So Far. Tamara Cook, Claudia Mckay, Access to Finance Forum. 10Tamara Cook and Claudia McKay. 2015. How M-Shwari Works: The Story So Far. Access to Finance Forum 10 (April 2015).\n\nAlgorithmic Decision Making and the Cost of Fairness. Sam Corbett-Davies, Emma Pierson, Avi Feller, Sharad Goel, Aziz Huq, Proc. ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM SIGKDD International Conference on Knowledge Discovery and Data MiningHalifax, NS, CanadaSam Corbett-Davies, Emma Pierson, Avi Feller, Sharad Goel, and Aziz Huq. 2017. Algorithmic Decision Making and the Cost of Fairness. In Proc. ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. Halifax, NS, Canada, 797-806.\n\nHealthcare Agency, Quality Research, Medical Expenditure Panel Survey (MEPS). Agency for Healthcare Research and Quality. 2018. Medical Expenditure Panel Survey (MEPS). http://www.ahrq.gov/research/data/meps/index.html.\n\nRace Sex and Genetic Discrimination in Insurance: What's Fair. Jill Gaulding, Cornell Law Review. 80Jill Gaulding. 1995. Race Sex and Genetic Discrimination in Insurance: What's Fair. Cornell Law Review 80, 6 (Sept. 1995), 1646-1694.\n\nGeodesic Flow Kernel for Unsupervised Domain Adaptation. Boqing Gong, Yuan Shi, Fei Sha, Kristen Grauman, Proc. IEEE Conference on Computer Vision and Pattern Recognition. IEEE Conference on Computer Vision and Pattern RecognitionProvidence, RI, USABoqing Gong, Yuan Shi, Fei Sha, and Kristen Grauman. 2012. Geodesic Flow Ker- nel for Unsupervised Domain Adaptation. In Proc. IEEE Conference on Computer Vision and Pattern Recognition. Providence, RI, USA, 2066-2073.\n\nCovariate Shift by Kernel Mean Matching. Arthur Gretton, Alexander J Smola, Jiayuan Huang, Marcel Schmittfull, Karsten M Borgwardt, Bernhard Sch\u00f6lkopf, 10.7551/mitpress/9780262170055.003.0008Arthur Gretton, Alexander J Smola, Jiayuan Huang, Marcel Schmittfull, Karsten M Borgwardt, and Bernhard Sch\u00f6lkopf. 2009. Covariate Shift by Kernel Mean Matching. (2009). https://doi.org/10.7551/mitpress/9780262170055.003.0008\n\n. Maya Gupta, Andrew Cotter, Mahdi Milani Fard, Serena Wang, arXiv:1806.11212Proxy Fairness.Maya Gupta, Andrew Cotter, Mahdi Milani Fard, and Serena Wang. 2018. Proxy Fairness. arXiv:1806.11212.\n\nThe End of Gender Rating: Women's Insurance Under the ACA. Samantha Kahn, Samantha Kahn. 2015. The End of Gender Rating: Women's Insurance Under the ACA. https://publicpolicy.wharton.upenn.edu/live/news/819-the-end-of-gender- rating-womens-insurance-under.\n\nData Preprocessing Techniques for Classification Without Discrimination. Faisal Kamiran, Toon Calders, Knowledge and Information Systems. 33Faisal Kamiran and Toon Calders. 2012. Data Preprocessing Techniques for Classification Without Discrimination. Knowledge and Information Systems 33, 1 (Oct. 2012), 1-33.\n\nUnderstanding Black-Box Predictions via Influence Functions. Wei Pang, Percy Koh, Liang, Proc. International Conference on Machine Learning. International Conference on Machine LearningSydney, NSW, AustraliaPang Wei Koh and Percy Liang. 2017. Understanding Black-Box Predictions via Influence Functions. In Proc. International Conference on Machine Learning. Sydney, NSW, Australia, 1885-1894.\n\nAdaptive Sensitive Reweighting to Mitigate Bias in Fairness-aware Classification. Emmanouil Krasanakis, Eleftherios Spyromitros-Xioufis, Symeon Papadopoulos, and Yiannis Kompatsiaris. Lyon, FranceProc. Web ConferenceEmmanouil Krasanakis, Eleftherios Spyromitros-Xioufis, Symeon Papadopoulos, and Yiannis Kompatsiaris. 2018. Adaptive Sensitive Reweighting to Mitigate Bias in Fairness-aware Classification. In Proc. Web Conference. Lyon, France, 853-862.\n\nAbhinav Maurya, IEEE Big Data 2017 Panel Discussion on Bias and Transparency. 4Abhinav Maurya. 2018. IEEE Big Data 2017 Panel Discussion on Bias and Trans- parency. AI Matters 4, 2 (July 2018), 13-20.\n\nInferences for case-control and semiparametric two-sample density ratio models. Jing Qin, Biometrika. 85Jing Qin. 1998. Inferences for case-control and semiparametric two-sample density ratio models. Biometrika 85, 3 (1998), 619-630.\n\nDataset Shift in Machine Learning. Joaquin Qui\u00f1onero-Candela, Masashi Sugiyama, Anton Schwaighofer, and Neil D. LawrenceMIT PressCambridge, MA, USAJoaquin Qui\u00f1onero-Candela, Masashi Sugiyama, Anton Schwaighofer, and Neil D. Lawrence (Eds.). 2009. Dataset Shift in Machine Learning. MIT Press, Cambridge, MA, USA.\n\nMultivariable Calculus with Vectors. Hartley Rogers, Prentice-HallUpper Saddle River, NJ, USAHartley Rogers. 1999. Multivariable Calculus with Vectors. Prentice-Hall, Upper Saddle River, NJ, USA.\n\nThree Population Covariate Shift for Mobile Phone-Based Credit Scoring. Skyler Speakman, Srihari Sridharan, Isaac Markus, Proc. ACM Conference on Computing and Sustainable Societies. ACM Conference on Computing and Sustainable SocietiesMenlo Park, CA, USA20Skyler Speakman, Srihari Sridharan, and Isaac Markus. 2018. Three Population Covariate Shift for Mobile Phone-Based Credit Scoring. In Proc. ACM Conference on Computing and Sustainable Societies. Menlo Park, CA, USA, 20.\n\nCovariate Shift Adaptation by Importance Weighted Cross Validation. Masashi Sugiyama, Matthias Krauledat, Klaus-Robert M\u00fcller, Journal of Machine Learning Research. 8Masashi Sugiyama, Matthias Krauledat, and Klaus-Robert M\u00fcller. 2007. Covariate Shift Adaptation by Importance Weighted Cross Validation. Journal of Machine Learning Research 8 (May 2007), 985-1005.\n\nDirect Importance Estimation with Model Selection and Its Application to Covariate Shift Adaptation. Masashi Sugiyama, Shinichi Nakajima, Hisashi Kashima, Motoaki Paul Von B\u00fcnau, Kawanabe, Advances in Neural Information Processing Systems. Vancouver, BC, CanadaMasashi Sugiyama, Shinichi Nakajima, Hisashi Kashima, Paul von B\u00fcnau, and Motoaki Kawanabe. 2007. Direct Importance Estimation with Model Selection and Its Application to Covariate Shift Adaptation. In Advances in Neural Information Processing Systems. Vancouver, BC, Canada, 1433-1440.\n\nDensity Ratio Estimation in Machine Learning. Masashi Sugiyama, Taiji Suzuki, Takafumi Kanamori, Cambridge University PressNew York, NY, USA1st ed.Masashi Sugiyama, Taiji Suzuki, and Takafumi Kanamori. 2012. Density Ratio Estimation in Machine Learning (1st ed.). Cambridge University Press, New York, NY, USA.\n\nFlexible Transfer Learning under Support and Model Shift. Xuezhi Wang, Jeff Schneider, Advances in Neural Information Processing Systems 27. Montreal, QC, CanadaXuezhi Wang and Jeff Schneider. 2014. Flexible Transfer Learning under Sup- port and Model Shift. In Advances in Neural Information Processing Systems 27. Montreal, QC, Canada, 1898-1906.\n\nSection 1557 of the Affordable Care Act: Civil Rights, Health Reform, Race, and Equity. D Sidney, Watson, Howard Law Journal. 553Sidney D. Watson. 2012. Section 1557 of the Affordable Care Act: Civil Rights, Health Reform, Race, and Equity. Howard Law Journal 55, 3 (Spring 2012), 855- 886.\n\nHealth Insurance Market Risk Assessment: Covariate Shift and k-Anonymity. Dennis Wei, Kush R Karthikeyan Natesan Ramamurthy, Varshney, Dennis Wei, Karthikeyan Natesan Ramamurthy, and Kush R. Varshney. 2015. Health Insurance Market Risk Assessment: Covariate Shift and k-Anonymity.\n\nProc. SIAM International Conference on Data Mining. SIAM International Conference on Data MiningVancouver, BC, CanadaIn Proc. SIAM International Conference on Data Mining. Vancouver, BC, Canada, 226-234.\n", "annotations": {"author": "[{\"start\":\"60\",\"end\":\"155\"},{\"start\":\"156\",\"end\":\"224\"},{\"start\":\"225\",\"end\":\"273\"},{\"start\":\"274\",\"end\":\"327\"},{\"start\":\"328\",\"end\":\"371\"},{\"start\":\"372\",\"end\":\"435\"},{\"start\":\"436\",\"end\":\"493\"}]", "publisher": null, "author_last_name": "[{\"start\":\"67\",\"end\":\"73\"},{\"start\":\"176\",\"end\":\"186\"},{\"start\":\"232\",\"end\":\"235\"},{\"start\":\"281\",\"end\":\"289\"},{\"start\":\"335\",\"end\":\"343\"},{\"start\":\"379\",\"end\":\"388\"},{\"start\":\"444\",\"end\":\"455\"}]", "author_first_name": "[{\"start\":\"60\",\"end\":\"66\"},{\"start\":\"156\",\"end\":\"167\"},{\"start\":\"168\",\"end\":\"175\"},{\"start\":\"225\",\"end\":\"231\"},{\"start\":\"274\",\"end\":\"278\"},{\"start\":\"279\",\"end\":\"280\"},{\"start\":\"328\",\"end\":\"334\"},{\"start\":\"372\",\"end\":\"378\"},{\"start\":\"436\",\"end\":\"443\"}]", "author_affiliation": "[{\"start\":\"75\",\"end\":\"110\"},{\"start\":\"112\",\"end\":\"154\"},{\"start\":\"188\",\"end\":\"223\"},{\"start\":\"237\",\"end\":\"272\"},{\"start\":\"291\",\"end\":\"326\"},{\"start\":\"345\",\"end\":\"370\"},{\"start\":\"390\",\"end\":\"434\"},{\"start\":\"457\",\"end\":\"492\"}]", "title": "[{\"start\":\"1\",\"end\":\"57\"},{\"start\":\"494\",\"end\":\"550\"}]", "venue": null, "abstract": "[{\"start\":\"983\",\"end\":\"2159\"}]", "bib_ref": "[{\"start\":\"2423\",\"end\":\"2426\",\"attributes\":{\"ref_id\":\"b2\"}},{\"start\":\"2426\",\"end\":\"2429\",\"attributes\":{\"ref_id\":\"b19\"}},{\"start\":\"2429\",\"end\":\"2432\",\"attributes\":{\"ref_id\":\"b22\"}},{\"start\":\"3305\",\"end\":\"3306\"},{\"start\":\"3337\",\"end\":\"3341\",\"attributes\":{\"ref_id\":\"b10\"}},{\"start\":\"3341\",\"end\":\"3344\",\"attributes\":{\"ref_id\":\"b25\"}},{\"start\":\"3605\",\"end\":\"3609\",\"attributes\":{\"ref_id\":\"b21\"}},{\"start\":\"3609\",\"end\":\"3612\",\"attributes\":{\"ref_id\":\"b27\"}},{\"start\":\"4543\",\"end\":\"4547\"},{\"start\":\"4820\",\"end\":\"4823\",\"attributes\":{\"ref_id\":\"b3\"}},{\"start\":\"4838\",\"end\":\"4842\",\"attributes\":{\"ref_id\":\"b12\"}},{\"start\":\"5650\",\"end\":\"5653\",\"attributes\":{\"ref_id\":\"b4\"}},{\"start\":\"6314\",\"end\":\"6318\",\"attributes\":{\"ref_id\":\"b9\"}},{\"start\":\"6318\",\"end\":\"6321\",\"attributes\":{\"ref_id\":\"b13\"}},{\"start\":\"6321\",\"end\":\"6324\",\"attributes\":{\"ref_id\":\"b26\"}},{\"start\":\"6553\",\"end\":\"6557\",\"attributes\":{\"ref_id\":\"b27\"}},{\"start\":\"6855\",\"end\":\"6858\",\"attributes\":{\"ref_id\":\"b6\"}},{\"start\":\"7184\",\"end\":\"7188\",\"attributes\":{\"ref_id\":\"b21\"}},{\"start\":\"9178\",\"end\":\"9181\",\"attributes\":{\"ref_id\":\"b1\"}},{\"start\":\"9417\",\"end\":\"9420\",\"attributes\":{\"ref_id\":\"b2\"}},{\"start\":\"9609\",\"end\":\"9613\",\"attributes\":{\"ref_id\":\"b18\"}},{\"start\":\"9659\",\"end\":\"9663\",\"attributes\":{\"ref_id\":\"b24\"}},{\"start\":\"9783\",\"end\":\"9787\",\"attributes\":{\"ref_id\":\"b11\"}},{\"start\":\"9787\",\"end\":\"9790\",\"attributes\":{\"ref_id\":\"b23\"}},{\"start\":\"11843\",\"end\":\"11846\",\"attributes\":{\"ref_id\":\"b7\"}},{\"start\":\"12194\",\"end\":\"12197\",\"attributes\":{\"ref_id\":\"b5\"}},{\"start\":\"13759\",\"end\":\"13762\",\"attributes\":{\"ref_id\":\"b0\"}},{\"start\":\"13762\",\"end\":\"13765\",\"attributes\":{\"ref_id\":\"b14\"}},{\"start\":\"13765\",\"end\":\"13768\",\"attributes\":{\"ref_id\":\"b16\"}},{\"start\":\"14463\",\"end\":\"14467\",\"attributes\":{\"ref_id\":\"b15\"}},{\"start\":\"14587\",\"end\":\"14590\",\"attributes\":{\"ref_id\":\"b1\"}},{\"start\":\"15180\",\"end\":\"15183\",\"attributes\":{\"ref_id\":\"b2\"}},{\"start\":\"15183\",\"end\":\"15186\",\"attributes\":{\"ref_id\":\"b11\"}},{\"start\":\"15186\",\"end\":\"15189\",\"attributes\":{\"ref_id\":\"b23\"}},{\"start\":\"15189\",\"end\":\"15192\",\"attributes\":{\"ref_id\":\"b24\"}},{\"start\":\"17968\",\"end\":\"17972\",\"attributes\":{\"ref_id\":\"b11\"}},{\"start\":\"18070\",\"end\":\"18074\",\"attributes\":{\"ref_id\":\"b11\"}},{\"start\":\"18995\",\"end\":\"18999\",\"attributes\":{\"ref_id\":\"b18\"}},{\"start\":\"19633\",\"end\":\"19637\",\"attributes\":{\"ref_id\":\"b11\"}},{\"start\":\"22237\",\"end\":\"22240\",\"attributes\":{\"ref_id\":\"b8\"}},{\"start\":\"25038\",\"end\":\"25041\",\"attributes\":{\"ref_id\":\"b5\"}},{\"start\":\"25202\",\"end\":\"25206\",\"attributes\":{\"ref_id\":\"b11\"}},{\"start\":\"26081\",\"end\":\"26085\",\"attributes\":{\"ref_id\":\"b21\"}},{\"start\":\"27193\",\"end\":\"27196\",\"attributes\":{\"ref_id\":\"b5\"}},{\"start\":\"28540\",\"end\":\"28544\",\"attributes\":{\"ref_id\":\"b15\"}},{\"start\":\"29534\",\"end\":\"29538\",\"attributes\":{\"ref_id\":\"b20\"}},{\"start\":\"29538\",\"end\":\"29545\"},{\"start\":\"30274\",\"end\":\"30278\",\"attributes\":{\"ref_id\":\"b16\"}},{\"start\":\"30560\",\"end\":\"30564\",\"attributes\":{\"ref_id\":\"b14\"}},{\"start\":\"30872\",\"end\":\"30876\",\"attributes\":{\"ref_id\":\"b13\"}},{\"start\":\"31609\",\"end\":\"31613\",\"attributes\":{\"ref_id\":\"b14\"}}]", "figure": "[{\"start\":\"30916\",\"end\":\"31653\",\"attributes\":{\"id\":\"fig_0\"}},{\"start\":\"31654\",\"end\":\"31760\",\"attributes\":{\"id\":\"fig_1\"}},{\"start\":\"31761\",\"end\":\"31867\",\"attributes\":{\"id\":\"fig_2\"}},{\"start\":\"31868\",\"end\":\"31982\",\"attributes\":{\"id\":\"fig_3\"}},{\"start\":\"31983\",\"end\":\"32065\",\"attributes\":{\"id\":\"fig_4\"}},{\"start\":\"32066\",\"end\":\"32239\",\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"}},{\"start\":\"32240\",\"end\":\"32725\",\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"}},{\"start\":\"32726\",\"end\":\"33224\",\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"}},{\"start\":\"33225\",\"end\":\"33679\",\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"}}]", "paragraph": "[{\"start\":\"2175\",\"end\":\"3753\"},{\"start\":\"3755\",\"end\":\"4414\"},{\"start\":\"4416\",\"end\":\"5654\"},{\"start\":\"5656\",\"end\":\"6646\"},{\"start\":\"6648\",\"end\":\"7307\"},{\"start\":\"7347\",\"end\":\"8075\"},{\"start\":\"8077\",\"end\":\"8192\"},{\"start\":\"8232\",\"end\":\"8410\"},{\"start\":\"8443\",\"end\":\"9059\"},{\"start\":\"9100\",\"end\":\"9245\"},{\"start\":\"9247\",\"end\":\"9791\"},{\"start\":\"9828\",\"end\":\"10334\"},{\"start\":\"10524\",\"end\":\"10784\"},{\"start\":\"10805\",\"end\":\"11719\"},{\"start\":\"11787\",\"end\":\"12094\"},{\"start\":\"12144\",\"end\":\"12836\"},{\"start\":\"12838\",\"end\":\"13495\"},{\"start\":\"13542\",\"end\":\"13639\"},{\"start\":\"13660\",\"end\":\"14591\"},{\"start\":\"14641\",\"end\":\"15392\"},{\"start\":\"15428\",\"end\":\"15562\"},{\"start\":\"15660\",\"end\":\"15873\"},{\"start\":\"15928\",\"end\":\"15933\"},{\"start\":\"15981\",\"end\":\"16130\"},{\"start\":\"16150\",\"end\":\"16242\"},{\"start\":\"16281\",\"end\":\"16611\"},{\"start\":\"16665\",\"end\":\"17003\"},{\"start\":\"17089\",\"end\":\"17198\"},{\"start\":\"17266\",\"end\":\"18075\"},{\"start\":\"18077\",\"end\":\"18176\"},{\"start\":\"18178\",\"end\":\"18578\"},{\"start\":\"18638\",\"end\":\"18707\"},{\"start\":\"18878\",\"end\":\"18972\"},{\"start\":\"18974\",\"end\":\"19273\"},{\"start\":\"19275\",\"end\":\"19682\"},{\"start\":\"19684\",\"end\":\"19864\"},{\"start\":\"19880\",\"end\":\"20418\"},{\"start\":\"20420\",\"end\":\"20487\"},{\"start\":\"20489\",\"end\":\"21459\"},{\"start\":\"21461\",\"end\":\"21845\"},{\"start\":\"21847\",\"end\":\"22176\"},{\"start\":\"22220\",\"end\":\"22809\"},{\"start\":\"22811\",\"end\":\"23826\"},{\"start\":\"23828\",\"end\":\"24266\"},{\"start\":\"24268\",\"end\":\"25477\"},{\"start\":\"25479\",\"end\":\"25698\"},{\"start\":\"25744\",\"end\":\"27365\"},{\"start\":\"27380\",\"end\":\"28404\"},{\"start\":\"28440\",\"end\":\"28695\"},{\"start\":\"28697\",\"end\":\"28764\"},{\"start\":\"28816\",\"end\":\"28923\"},{\"start\":\"28925\",\"end\":\"29061\"},{\"start\":\"29126\",\"end\":\"29313\"},{\"start\":\"29315\",\"end\":\"29557\"},{\"start\":\"29650\",\"end\":\"29725\"},{\"start\":\"29727\",\"end\":\"29748\"},{\"start\":\"29792\",\"end\":\"29797\"},{\"start\":\"29843\",\"end\":\"30005\"},{\"start\":\"30058\",\"end\":\"30090\"},{\"start\":\"30092\",\"end\":\"30185\"},{\"start\":\"30259\",\"end\":\"30316\"},{\"start\":\"30478\",\"end\":\"30501\"},{\"start\":\"30541\",\"end\":\"30760\"},{\"start\":\"30762\",\"end\":\"30915\"}]", "formula": "[{\"start\":\"8193\",\"end\":\"8231\",\"attributes\":{\"id\":\"formula_0\"}},{\"start\":\"8411\",\"end\":\"8442\",\"attributes\":{\"id\":\"formula_1\"}},{\"start\":\"9060\",\"end\":\"9099\",\"attributes\":{\"id\":\"formula_2\"}},{\"start\":\"10335\",\"end\":\"10523\",\"attributes\":{\"id\":\"formula_3\"}},{\"start\":\"11720\",\"end\":\"11786\",\"attributes\":{\"id\":\"formula_4\"}},{\"start\":\"12095\",\"end\":\"12143\",\"attributes\":{\"id\":\"formula_5\"}},{\"start\":\"13496\",\"end\":\"13541\",\"attributes\":{\"id\":\"formula_6\"}},{\"start\":\"15393\",\"end\":\"15427\",\"attributes\":{\"id\":\"formula_7\"}},{\"start\":\"15563\",\"end\":\"15659\",\"attributes\":{\"id\":\"formula_8\"}},{\"start\":\"15874\",\"end\":\"15927\",\"attributes\":{\"id\":\"formula_9\"}},{\"start\":\"15934\",\"end\":\"15980\",\"attributes\":{\"id\":\"formula_10\"}},{\"start\":\"16131\",\"end\":\"16149\",\"attributes\":{\"id\":\"formula_11\"}},{\"start\":\"16612\",\"end\":\"16664\",\"attributes\":{\"id\":\"formula_12\"}},{\"start\":\"17004\",\"end\":\"17088\",\"attributes\":{\"id\":\"formula_13\"}},{\"start\":\"17199\",\"end\":\"17265\",\"attributes\":{\"id\":\"formula_14\"}},{\"start\":\"18708\",\"end\":\"18877\",\"attributes\":{\"id\":\"formula_15\"}},{\"start\":\"28765\",\"end\":\"28815\",\"attributes\":{\"id\":\"formula_16\"}},{\"start\":\"29062\",\"end\":\"29125\",\"attributes\":{\"id\":\"formula_18\"}},{\"start\":\"29558\",\"end\":\"29649\",\"attributes\":{\"id\":\"formula_19\"}},{\"start\":\"29749\",\"end\":\"29791\",\"attributes\":{\"id\":\"formula_20\"}},{\"start\":\"29798\",\"end\":\"29842\",\"attributes\":{\"id\":\"formula_21\"}},{\"start\":\"30006\",\"end\":\"30057\",\"attributes\":{\"id\":\"formula_22\"}},{\"start\":\"30186\",\"end\":\"30258\",\"attributes\":{\"id\":\"formula_24\"}},{\"start\":\"30317\",\"end\":\"30477\",\"attributes\":{\"id\":\"formula_25\"}},{\"start\":\"30502\",\"end\":\"30540\",\"attributes\":{\"id\":\"formula_26\"}}]", "table_ref": "[{\"start\":\"23604\",\"end\":\"23611\"},{\"start\":\"23850\",\"end\":\"23856\"},{\"start\":\"23946\",\"end\":\"23953\"},{\"start\":\"24139\",\"end\":\"24146\",\"attributes\":{\"ref_id\":\"tab_2\"}},{\"start\":\"26301\",\"end\":\"26308\",\"attributes\":{\"ref_id\":\"tab_4\"}},{\"start\":\"26540\",\"end\":\"26547\",\"attributes\":{\"ref_id\":\"tab_3\"}},{\"start\":\"26969\",\"end\":\"26976\",\"attributes\":{\"ref_id\":\"tab_4\"}}]", "section_header": "[{\"start\":\"2161\",\"end\":\"2173\",\"attributes\":{\"n\":\"1\"}},{\"start\":\"7310\",\"end\":\"7345\",\"attributes\":{\"n\":\"2\"}},{\"start\":\"9794\",\"end\":\"9826\",\"attributes\":{\"n\":\"2.2\"}},{\"start\":\"10787\",\"end\":\"10803\",\"attributes\":{\"n\":\"2.3\"}},{\"start\":\"13642\",\"end\":\"13658\",\"attributes\":{\"n\":\"3\"}},{\"start\":\"14594\",\"end\":\"14639\",\"attributes\":{\"n\":\"3.1\"}},{\"start\":\"16245\",\"end\":\"16279\",\"attributes\":{\"n\":\"3.2\"}},{\"start\":\"18581\",\"end\":\"18627\"},{\"start\":\"18630\",\"end\":\"18636\"},{\"start\":\"19867\",\"end\":\"19878\",\"attributes\":{\"n\":\"4\"}},{\"start\":\"22179\",\"end\":\"22218\",\"attributes\":{\"n\":\"4.1\"}},{\"start\":\"25701\",\"end\":\"25742\",\"attributes\":{\"n\":\"4.2\"}},{\"start\":\"27368\",\"end\":\"27378\",\"attributes\":{\"n\":\"5\"}},{\"start\":\"28407\",\"end\":\"28438\"},{\"start\":\"30917\",\"end\":\"30922\"},{\"start\":\"31655\",\"end\":\"31665\"},{\"start\":\"31762\",\"end\":\"31772\"},{\"start\":\"31869\",\"end\":\"31879\"},{\"start\":\"31984\",\"end\":\"31985\"},{\"start\":\"32241\",\"end\":\"32250\"},{\"start\":\"32727\",\"end\":\"32736\"},{\"start\":\"33226\",\"end\":\"33235\"}]", "table": "[{\"start\":\"32421\",\"end\":\"32725\"},{\"start\":\"32738\",\"end\":\"33224\"},{\"start\":\"33389\",\"end\":\"33679\"}]", "figure_caption": "[{\"start\":\"30924\",\"end\":\"31653\"},{\"start\":\"31667\",\"end\":\"31760\"},{\"start\":\"31774\",\"end\":\"31867\"},{\"start\":\"31881\",\"end\":\"31982\"},{\"start\":\"31986\",\"end\":\"32065\"},{\"start\":\"32068\",\"end\":\"32239\"},{\"start\":\"32252\",\"end\":\"32421\"},{\"start\":\"33237\",\"end\":\"33389\"}]", "figure_ref": "[{\"start\":\"23169\",\"end\":\"23180\",\"attributes\":{\"ref_id\":\"fig_1\"}},{\"start\":\"24781\",\"end\":\"24789\",\"attributes\":{\"ref_id\":\"fig_1\"}},{\"start\":\"25126\",\"end\":\"25134\",\"attributes\":{\"ref_id\":\"fig_2\"}},{\"start\":\"27029\",\"end\":\"27037\",\"attributes\":{\"ref_id\":\"fig_0\"}}]", "bib_author_first_name": "[{\"start\":\"34477\",\"end\":\"34482\"},{\"start\":\"34492\",\"end\":\"34497\"},{\"start\":\"34511\",\"end\":\"34519\"},{\"start\":\"34527\",\"end\":\"34531\"},{\"start\":\"34542\",\"end\":\"34547\"},{\"start\":\"34980\",\"end\":\"34981\"},{\"start\":\"34989\",\"end\":\"34995\"},{\"start\":\"35009\",\"end\":\"35016\"},{\"start\":\"35017\",\"end\":\"35021\"},{\"start\":\"35353\",\"end\":\"35360\"},{\"start\":\"35369\",\"end\":\"35376\"},{\"start\":\"35387\",\"end\":\"35393\"},{\"start\":\"35684\",\"end\":\"35685\"},{\"start\":\"35856\",\"end\":\"35862\"},{\"start\":\"35869\",\"end\":\"35875\"},{\"start\":\"35884\",\"end\":\"35891\"},{\"start\":\"35897\",\"end\":\"35904\"},{\"start\":\"35913\",\"end\":\"35922\"},{\"start\":\"36346\",\"end\":\"36355\"},{\"start\":\"36574\",\"end\":\"36580\"},{\"start\":\"36587\",\"end\":\"36594\"},{\"start\":\"36800\",\"end\":\"36803\"},{\"start\":\"36820\",\"end\":\"36824\"},{\"start\":\"36834\",\"end\":\"36837\"},{\"start\":\"36846\",\"end\":\"36852\"},{\"start\":\"36859\",\"end\":\"36863\"},{\"start\":\"37293\",\"end\":\"37303\"},{\"start\":\"37312\",\"end\":\"37319\"},{\"start\":\"37577\",\"end\":\"37581\"},{\"start\":\"37806\",\"end\":\"37812\"},{\"start\":\"37819\",\"end\":\"37823\"},{\"start\":\"37829\",\"end\":\"37832\"},{\"start\":\"37838\",\"end\":\"37845\"},{\"start\":\"38259\",\"end\":\"38265\"},{\"start\":\"38275\",\"end\":\"38284\"},{\"start\":\"38285\",\"end\":\"38286\"},{\"start\":\"38294\",\"end\":\"38301\"},{\"start\":\"38309\",\"end\":\"38315\"},{\"start\":\"38329\",\"end\":\"38336\"},{\"start\":\"38337\",\"end\":\"38338\"},{\"start\":\"38350\",\"end\":\"38358\"},{\"start\":\"38638\",\"end\":\"38642\"},{\"start\":\"38650\",\"end\":\"38656\"},{\"start\":\"38665\",\"end\":\"38670\"},{\"start\":\"38684\",\"end\":\"38690\"},{\"start\":\"38891\",\"end\":\"38899\"},{\"start\":\"39163\",\"end\":\"39169\"},{\"start\":\"39179\",\"end\":\"39183\"},{\"start\":\"39463\",\"end\":\"39466\"},{\"start\":\"39473\",\"end\":\"39478\"},{\"start\":\"39879\",\"end\":\"39888\"},{\"start\":\"40252\",\"end\":\"40259\"},{\"start\":\"40534\",\"end\":\"40538\"},{\"start\":\"40724\",\"end\":\"40731\"},{\"start\":\"40751\",\"end\":\"40758\"},{\"start\":\"41040\",\"end\":\"41047\"},{\"start\":\"41272\",\"end\":\"41278\"},{\"start\":\"41289\",\"end\":\"41296\"},{\"start\":\"41308\",\"end\":\"41313\"},{\"start\":\"41747\",\"end\":\"41754\"},{\"start\":\"41765\",\"end\":\"41773\"},{\"start\":\"41785\",\"end\":\"41797\"},{\"start\":\"42145\",\"end\":\"42152\"},{\"start\":\"42163\",\"end\":\"42171\"},{\"start\":\"42182\",\"end\":\"42189\"},{\"start\":\"42199\",\"end\":\"42206\"},{\"start\":\"42639\",\"end\":\"42646\"},{\"start\":\"42657\",\"end\":\"42662\"},{\"start\":\"42671\",\"end\":\"42679\"},{\"start\":\"42963\",\"end\":\"42969\"},{\"start\":\"42976\",\"end\":\"42980\"},{\"start\":\"43343\",\"end\":\"43344\"},{\"start\":\"43621\",\"end\":\"43627\"},{\"start\":\"43633\",\"end\":\"43637\"},{\"start\":\"43638\",\"end\":\"43639\"}]", "bib_author_last_name": "[{\"start\":\"34483\",\"end\":\"34490\"},{\"start\":\"34498\",\"end\":\"34509\"},{\"start\":\"34520\",\"end\":\"34525\"},{\"start\":\"34532\",\"end\":\"34540\"},{\"start\":\"34548\",\"end\":\"34555\"},{\"start\":\"34959\",\"end\":\"34978\"},{\"start\":\"34982\",\"end\":\"34987\"},{\"start\":\"34996\",\"end\":\"35007\"},{\"start\":\"35022\",\"end\":\"35039\"},{\"start\":\"35041\",\"end\":\"35048\"},{\"start\":\"35361\",\"end\":\"35367\"},{\"start\":\"35377\",\"end\":\"35385\"},{\"start\":\"35394\",\"end\":\"35402\"},{\"start\":\"35686\",\"end\":\"35689\"},{\"start\":\"35691\",\"end\":\"35702\"},{\"start\":\"35863\",\"end\":\"35867\"},{\"start\":\"35876\",\"end\":\"35882\"},{\"start\":\"35892\",\"end\":\"35895\"},{\"start\":\"35905\",\"end\":\"35911\"},{\"start\":\"35923\",\"end\":\"35928\"},{\"start\":\"36356\",\"end\":\"36368\"},{\"start\":\"36581\",\"end\":\"36585\"},{\"start\":\"36595\",\"end\":\"36600\"},{\"start\":\"36804\",\"end\":\"36818\"},{\"start\":\"36825\",\"end\":\"36832\"},{\"start\":\"36838\",\"end\":\"36844\"},{\"start\":\"36853\",\"end\":\"36857\"},{\"start\":\"36864\",\"end\":\"36867\"},{\"start\":\"37304\",\"end\":\"37310\"},{\"start\":\"37320\",\"end\":\"37328\"},{\"start\":\"37582\",\"end\":\"37590\"},{\"start\":\"37813\",\"end\":\"37817\"},{\"start\":\"37824\",\"end\":\"37827\"},{\"start\":\"37833\",\"end\":\"37836\"},{\"start\":\"37846\",\"end\":\"37853\"},{\"start\":\"38266\",\"end\":\"38273\"},{\"start\":\"38287\",\"end\":\"38292\"},{\"start\":\"38302\",\"end\":\"38307\"},{\"start\":\"38316\",\"end\":\"38327\"},{\"start\":\"38339\",\"end\":\"38348\"},{\"start\":\"38359\",\"end\":\"38368\"},{\"start\":\"38643\",\"end\":\"38648\"},{\"start\":\"38657\",\"end\":\"38663\"},{\"start\":\"38671\",\"end\":\"38682\"},{\"start\":\"38691\",\"end\":\"38695\"},{\"start\":\"38900\",\"end\":\"38904\"},{\"start\":\"39170\",\"end\":\"39177\"},{\"start\":\"39184\",\"end\":\"39191\"},{\"start\":\"39467\",\"end\":\"39471\"},{\"start\":\"39479\",\"end\":\"39482\"},{\"start\":\"39484\",\"end\":\"39489\"},{\"start\":\"39889\",\"end\":\"39899\"},{\"start\":\"40260\",\"end\":\"40266\"},{\"start\":\"40539\",\"end\":\"40542\"},{\"start\":\"40732\",\"end\":\"40749\"},{\"start\":\"40759\",\"end\":\"40767\"},{\"start\":\"41048\",\"end\":\"41054\"},{\"start\":\"41279\",\"end\":\"41287\"},{\"start\":\"41297\",\"end\":\"41306\"},{\"start\":\"41314\",\"end\":\"41320\"},{\"start\":\"41755\",\"end\":\"41763\"},{\"start\":\"41774\",\"end\":\"41783\"},{\"start\":\"41798\",\"end\":\"41804\"},{\"start\":\"42153\",\"end\":\"42161\"},{\"start\":\"42172\",\"end\":\"42180\"},{\"start\":\"42190\",\"end\":\"42197\"},{\"start\":\"42207\",\"end\":\"42221\"},{\"start\":\"42223\",\"end\":\"42231\"},{\"start\":\"42647\",\"end\":\"42655\"},{\"start\":\"42663\",\"end\":\"42669\"},{\"start\":\"42680\",\"end\":\"42688\"},{\"start\":\"42970\",\"end\":\"42974\"},{\"start\":\"42981\",\"end\":\"42990\"},{\"start\":\"43345\",\"end\":\"43351\"},{\"start\":\"43353\",\"end\":\"43359\"},{\"start\":\"43628\",\"end\":\"43631\"},{\"start\":\"43640\",\"end\":\"43670\"},{\"start\":\"43672\",\"end\":\"43680\"}]", "bib_entry": "[{\"start\":\"34431\",\"end\":\"34900\",\"attributes\":{\"matched_paper_id\":\"4725675\",\"id\":\"b0\"}},{\"start\":\"34902\",\"end\":\"35304\",\"attributes\":{\"matched_paper_id\":\"3766791\",\"id\":\"b1\"}},{\"start\":\"35306\",\"end\":\"35616\",\"attributes\":{\"matched_paper_id\":\"7576149\",\"id\":\"b2\"}},{\"start\":\"35618\",\"end\":\"35854\",\"attributes\":{\"id\":\"b3\"}},{\"start\":\"35856\",\"end\":\"36251\",\"attributes\":{\"id\":\"b4\",\"doi\":\"arXiv:1811.11154\"}},{\"start\":\"36253\",\"end\":\"36534\",\"attributes\":{\"matched_paper_id\":\"1443041\",\"id\":\"b5\"}},{\"start\":\"36536\",\"end\":\"36744\",\"attributes\":{\"matched_paper_id\":\"167671525\",\"id\":\"b6\"}},{\"start\":\"36746\",\"end\":\"37291\",\"attributes\":{\"matched_paper_id\":\"3228123\",\"id\":\"b7\"}},{\"start\":\"37293\",\"end\":\"37512\",\"attributes\":{\"id\":\"b8\"}},{\"start\":\"37514\",\"end\":\"37747\",\"attributes\":{\"matched_paper_id\":\"54645748\",\"id\":\"b9\"}},{\"start\":\"37749\",\"end\":\"38216\",\"attributes\":{\"matched_paper_id\":\"6742009\",\"id\":\"b10\"}},{\"start\":\"38218\",\"end\":\"38634\",\"attributes\":{\"id\":\"b11\",\"doi\":\"10.7551/mitpress/9780262170055.003.0008\"}},{\"start\":\"38636\",\"end\":\"38830\",\"attributes\":{\"id\":\"b12\",\"doi\":\"arXiv:1806.11212\"}},{\"start\":\"38832\",\"end\":\"39088\",\"attributes\":{\"id\":\"b13\"}},{\"start\":\"39090\",\"end\":\"39400\",\"attributes\":{\"matched_paper_id\":\"14637938\",\"id\":\"b14\"}},{\"start\":\"39402\",\"end\":\"39795\",\"attributes\":{\"matched_paper_id\":\"13193974\",\"id\":\"b15\"}},{\"start\":\"39797\",\"end\":\"40250\",\"attributes\":{\"matched_paper_id\":\"4895005\",\"id\":\"b16\"}},{\"start\":\"40252\",\"end\":\"40452\",\"attributes\":{\"id\":\"b17\"}},{\"start\":\"40454\",\"end\":\"40687\",\"attributes\":{\"matched_paper_id\":\"120661998\",\"id\":\"b18\"}},{\"start\":\"40689\",\"end\":\"41001\",\"attributes\":{\"id\":\"b19\"}},{\"start\":\"41003\",\"end\":\"41198\",\"attributes\":{\"id\":\"b20\"}},{\"start\":\"41200\",\"end\":\"41677\",\"attributes\":{\"matched_paper_id\":\"49347725\",\"id\":\"b21\"}},{\"start\":\"41679\",\"end\":\"42042\",\"attributes\":{\"matched_paper_id\":\"17547265\",\"id\":\"b22\"}},{\"start\":\"42044\",\"end\":\"42591\",\"attributes\":{\"matched_paper_id\":\"9133542\",\"id\":\"b23\"}},{\"start\":\"42593\",\"end\":\"42903\",\"attributes\":{\"id\":\"b24\"}},{\"start\":\"42905\",\"end\":\"43253\",\"attributes\":{\"matched_paper_id\":\"11747310\",\"id\":\"b25\"}},{\"start\":\"43255\",\"end\":\"43545\",\"attributes\":{\"id\":\"b26\"}},{\"start\":\"43547\",\"end\":\"43827\",\"attributes\":{\"id\":\"b27\"}},{\"start\":\"43829\",\"end\":\"44032\",\"attributes\":{\"id\":\"b28\"}}]", "bib_title": "[{\"start\":\"34431\",\"end\":\"34475\"},{\"start\":\"34902\",\"end\":\"34957\"},{\"start\":\"35306\",\"end\":\"35351\"},{\"start\":\"35618\",\"end\":\"35682\"},{\"start\":\"36253\",\"end\":\"36344\"},{\"start\":\"36536\",\"end\":\"36572\"},{\"start\":\"36746\",\"end\":\"36798\"},{\"start\":\"37514\",\"end\":\"37575\"},{\"start\":\"37749\",\"end\":\"37804\"},{\"start\":\"39090\",\"end\":\"39161\"},{\"start\":\"39402\",\"end\":\"39461\"},{\"start\":\"39797\",\"end\":\"39877\"},{\"start\":\"40454\",\"end\":\"40532\"},{\"start\":\"41200\",\"end\":\"41270\"},{\"start\":\"41679\",\"end\":\"41745\"},{\"start\":\"42044\",\"end\":\"42143\"},{\"start\":\"42905\",\"end\":\"42961\"},{\"start\":\"43255\",\"end\":\"43341\"}]", "bib_author": "[{\"start\":\"34477\",\"end\":\"34492\"},{\"start\":\"34492\",\"end\":\"34511\"},{\"start\":\"34511\",\"end\":\"34527\"},{\"start\":\"34527\",\"end\":\"34542\"},{\"start\":\"34542\",\"end\":\"34557\"},{\"start\":\"34959\",\"end\":\"34980\"},{\"start\":\"34980\",\"end\":\"34989\"},{\"start\":\"34989\",\"end\":\"35009\"},{\"start\":\"35009\",\"end\":\"35041\"},{\"start\":\"35041\",\"end\":\"35050\"},{\"start\":\"35353\",\"end\":\"35369\"},{\"start\":\"35369\",\"end\":\"35387\"},{\"start\":\"35387\",\"end\":\"35404\"},{\"start\":\"35684\",\"end\":\"35691\"},{\"start\":\"35691\",\"end\":\"35704\"},{\"start\":\"35856\",\"end\":\"35869\"},{\"start\":\"35869\",\"end\":\"35884\"},{\"start\":\"35884\",\"end\":\"35897\"},{\"start\":\"35897\",\"end\":\"35913\"},{\"start\":\"35913\",\"end\":\"35930\"},{\"start\":\"36346\",\"end\":\"36370\"},{\"start\":\"36574\",\"end\":\"36587\"},{\"start\":\"36587\",\"end\":\"36602\"},{\"start\":\"36800\",\"end\":\"36820\"},{\"start\":\"36820\",\"end\":\"36834\"},{\"start\":\"36834\",\"end\":\"36846\"},{\"start\":\"36846\",\"end\":\"36859\"},{\"start\":\"36859\",\"end\":\"36869\"},{\"start\":\"37293\",\"end\":\"37312\"},{\"start\":\"37312\",\"end\":\"37330\"},{\"start\":\"37577\",\"end\":\"37592\"},{\"start\":\"37806\",\"end\":\"37819\"},{\"start\":\"37819\",\"end\":\"37829\"},{\"start\":\"37829\",\"end\":\"37838\"},{\"start\":\"37838\",\"end\":\"37855\"},{\"start\":\"38259\",\"end\":\"38275\"},{\"start\":\"38275\",\"end\":\"38294\"},{\"start\":\"38294\",\"end\":\"38309\"},{\"start\":\"38309\",\"end\":\"38329\"},{\"start\":\"38329\",\"end\":\"38350\"},{\"start\":\"38350\",\"end\":\"38370\"},{\"start\":\"38638\",\"end\":\"38650\"},{\"start\":\"38650\",\"end\":\"38665\"},{\"start\":\"38665\",\"end\":\"38684\"},{\"start\":\"38684\",\"end\":\"38697\"},{\"start\":\"38891\",\"end\":\"38906\"},{\"start\":\"39163\",\"end\":\"39179\"},{\"start\":\"39179\",\"end\":\"39193\"},{\"start\":\"39463\",\"end\":\"39473\"},{\"start\":\"39473\",\"end\":\"39484\"},{\"start\":\"39484\",\"end\":\"39491\"},{\"start\":\"39879\",\"end\":\"39901\"},{\"start\":\"40252\",\"end\":\"40268\"},{\"start\":\"40534\",\"end\":\"40544\"},{\"start\":\"40724\",\"end\":\"40751\"},{\"start\":\"40751\",\"end\":\"40769\"},{\"start\":\"41040\",\"end\":\"41056\"},{\"start\":\"41272\",\"end\":\"41289\"},{\"start\":\"41289\",\"end\":\"41308\"},{\"start\":\"41308\",\"end\":\"41322\"},{\"start\":\"41747\",\"end\":\"41765\"},{\"start\":\"41765\",\"end\":\"41785\"},{\"start\":\"41785\",\"end\":\"41806\"},{\"start\":\"42145\",\"end\":\"42163\"},{\"start\":\"42163\",\"end\":\"42182\"},{\"start\":\"42182\",\"end\":\"42199\"},{\"start\":\"42199\",\"end\":\"42223\"},{\"start\":\"42223\",\"end\":\"42233\"},{\"start\":\"42639\",\"end\":\"42657\"},{\"start\":\"42657\",\"end\":\"42671\"},{\"start\":\"42671\",\"end\":\"42690\"},{\"start\":\"42963\",\"end\":\"42976\"},{\"start\":\"42976\",\"end\":\"42992\"},{\"start\":\"43343\",\"end\":\"43353\"},{\"start\":\"43353\",\"end\":\"43361\"},{\"start\":\"43621\",\"end\":\"43633\"},{\"start\":\"43633\",\"end\":\"43672\"},{\"start\":\"43672\",\"end\":\"43682\"}]", "bib_venue": "[{\"start\":\"34557\",\"end\":\"34614\"},{\"start\":\"35050\",\"end\":\"35086\"},{\"start\":\"35404\",\"end\":\"35440\"},{\"start\":\"35704\",\"end\":\"35720\"},{\"start\":\"35946\",\"end\":\"36028\"},{\"start\":\"36370\",\"end\":\"36378\"},{\"start\":\"36602\",\"end\":\"36625\"},{\"start\":\"36869\",\"end\":\"36949\"},{\"start\":\"37330\",\"end\":\"37369\"},{\"start\":\"37592\",\"end\":\"37610\"},{\"start\":\"37855\",\"end\":\"37919\"},{\"start\":\"38218\",\"end\":\"38257\"},{\"start\":\"38832\",\"end\":\"38889\"},{\"start\":\"39193\",\"end\":\"39226\"},{\"start\":\"39491\",\"end\":\"39541\"},{\"start\":\"39901\",\"end\":\"39979\"},{\"start\":\"40268\",\"end\":\"40328\"},{\"start\":\"40544\",\"end\":\"40554\"},{\"start\":\"40689\",\"end\":\"40722\"},{\"start\":\"41003\",\"end\":\"41038\"},{\"start\":\"41322\",\"end\":\"41381\"},{\"start\":\"41806\",\"end\":\"41842\"},{\"start\":\"42233\",\"end\":\"42282\"},{\"start\":\"42593\",\"end\":\"42637\"},{\"start\":\"42992\",\"end\":\"43044\"},{\"start\":\"43361\",\"end\":\"43379\"},{\"start\":\"43547\",\"end\":\"43619\"},{\"start\":\"43829\",\"end\":\"43879\"},{\"start\":\"34616\",\"end\":\"34684\"},{\"start\":\"36951\",\"end\":\"37044\"},{\"start\":\"37921\",\"end\":\"37998\"},{\"start\":\"39543\",\"end\":\"39609\"},{\"start\":\"39981\",\"end\":\"39993\"},{\"start\":\"41383\",\"end\":\"41455\"},{\"start\":\"42284\",\"end\":\"42305\"},{\"start\":\"43046\",\"end\":\"43066\"},{\"start\":\"43881\",\"end\":\"43946\"}]"}}}, "year": 2023, "month": 12, "day": 17}