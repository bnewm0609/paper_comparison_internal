{"id": 238215344, "updated": "2023-10-05 22:11:14.766", "metadata": {"title": "On Brightness Agnostic Adversarial Examples Against Face Recognition Systems", "authors": "[{\"first\":\"Inderjeet\",\"last\":\"Singh\",\"middle\":[]},{\"first\":\"Satoru\",\"last\":\"Momiyama\",\"middle\":[]},{\"first\":\"Kazuya\",\"last\":\"Kakizaki\",\"middle\":[]},{\"first\":\"Toshinori\",\"last\":\"Araki\",\"middle\":[]}]", "venue": "LNI Volume: BIOSIG 2021, LNI Volume 315, ISBN 978-3-88579-709-8", "journal": null, "publication_date": {"year": 2021, "month": null, "day": null}, "abstract": "This paper introduces a novel adversarial example generation method against face recognition systems (FRSs). An adversarial example (AX) is an image with deliberately crafted noise to cause incorrect predictions by a target system. The AXs generated from our method remain robust under real-world brightness changes. Our method performs non-linear brightness transformations while leveraging the concept of curriculum learning during the attack generation procedure. We demonstrate that our method outperforms conventional techniques from comprehensive experimental investigations in the digital and physical world. Furthermore, this method enables practical risk assessment of FRSs against brightness agnostic AXs.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2109.14205", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/biosig/SinghMKA21", "doi": "10.1109/biosig52210.2021.9548291"}}, "content": {"source": {"pdf_hash": "57f58f0c4321ab8c230f710aec375841db7deef5", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2109.14205v1.pdf\"]", "oa_url_match": true, "oa_info": {"license": null, "open_access_url": "http://arxiv.org/pdf/2109.14205", "status": "GREEN"}}, "grobid": {"id": "d6bacde4fe97ecb057ceec589df819e4db9e9f77", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/57f58f0c4321ab8c230f710aec375841db7deef5.txt", "contents": "\nOn Brightness Agnostic Adversarial Examples Against Face Recognition Systems\n\n\nInderjeet Singh inderjeet78@nec.com \nNEC Corporation\nNEC Corporation\nNEC Corporation\nUniversity of Tsukuba\nNEC Corporation\n\n\nSatoru Momiyama satoru-momiyama@nec.com \nNEC Corporation\nNEC Corporation\nNEC Corporation\nUniversity of Tsukuba\nNEC Corporation\n\n\nKazuya Kakizaki kazuya1210@nec.com \nNEC Corporation\nNEC Corporation\nNEC Corporation\nUniversity of Tsukuba\nNEC Corporation\n\n\nToshinori Araki toshinoriaraki@nec.com \nNEC Corporation\nNEC Corporation\nNEC Corporation\nUniversity of Tsukuba\nNEC Corporation\n\n\nOn Brightness Agnostic Adversarial Examples Against Face Recognition Systems\nIndex Terms-Adversarial examplesFace recogni- tionBrightness variationsCurriculum learning\nThis paper introduces a novel adversarial example generation method against face recognition systems (FRSs). An adversarial example (AX) is an image with deliberately crafted noise to cause incorrect predictions by a target system. The AXs generated from our method remain robust under realworld brightness changes. Our method performs nonlinear brightness transformations while leveraging the concept of curriculum learning during the attack generation procedure. We demonstrate that our method outperforms conventional techniques from comprehensive experimental investigations in the digital and physical world. Furthermore, this method enables practical risk assessment of FRSs against brightness agnostic AXs.\n\nI. Introduction\n\nThe recent advancement in Adversarial Machine Learning (AML) has discovered that state-of-the-art (SOTA) Deep Learning (DL) models are vulnerable to welldesigned input samples called Adversarial Examples (AXs) [1]. The vulnerability to AXs becomes a significant risk for applying deep neural networks in safety-critical applications like Face Recognition Systems (FRSs). Face Recognition is a process of validating a claimed identity based on the image of a face. An adversary can conveniently attack practical FRSs from the digital and the physical world, e.g., in ID photo-matching systems [2].\n\nIn digital attacks, the digital adversarial noise is directly added to the target digital image. In the physical attacks, digital AX is transferred to the physical world (by printing, etc.) and then used to attack a target system. The generated AXs can be white-box, gray-box, or blackbox depending on whether they are generated leveraging complete, partial, or no access, respectively, to the target system's information. Various digital and physical perturbations affect these AXs because the AXs are typical images with a few highly correlated adversarial features with the target ML model's predictions. The perturbations can be in color corrections, contrast change, hue shift, and brightness changes. The brightness change is one of the critical parameters, causing a significant change in AX's performance.\n\nThe practical risk assessment of the FRSs scans the possible vulnerabilities of the ML model used in the FRS from different kinds of AXs. However, the brightness changes weaken the AX, making it non-suitable for the practical risk assessment of the target system. Thus powerful AXs robust to the brightness changes must be adopted. When an AX succeeds even in altering brightness environments, it is called brightness agnostic AX. In practical scenarios, brightness changes non-linearly. In the digital world, nonlinear brightness changes occur due to the use of image enhancement techniques [3] [4] by FRSs for improved performance, which can be seen in Fig.1a. In the physical world, four primary factors cause brightness changes: printer specification, printing surface properties, environmental illumination conditions, and camera specifications.\n\nYang et al. [5] proposed an adversarial example generation method based on random transformations of image brightness. They reduced the overfitting, thereby improving black-box transferability of generated attacks, by applying linear brightness transformations on the training 1 image optimized for an adversarial objective. However, [5] did not evaluate the robustness of the generated attacks in changing brightness conditions. Also, they assumed only linear brightness changes. Additionally, the FRSs were not considered in their evaluation. Therefore, in this work, in addition to our proposed method, we also evaluate (1) the robustness of the attacks generated from their method in the changing brightness conditions, (2) the improvement in the black-box transferability, and (3) performance for FRSs.\n\nOur main contributions are: We propose a novel Curriculum Learning (CL)-based method for generating AXs robust to real-world brightness changes. To our best knowledge, this is the very first attempt for generating brightness agnostic adversarial attacks. We conduct extensive experiments on four SOTA face verification models under a well-known PGD (Projected Gradient Descent) attack [7] setting. We evaluated the white-box and blackbox attack performance in the digital as well as the physical world. We also evaluate our method against the FRSs deployed with adversarial defenses in the pre-processing pipeline. \n\n\nII. Our method for generating brightness agnostic AXs\n\nThe proposed method [Alg.1] yields non-linear brightness changes during the attack generation process, as it can be seen in Fig.1b. The non-linear change in the brightness during attack generation makes the generated AXs robust to them during inference. To better optimize the challenging non-linear brightness changes, our method uses the concept of CL for generating Brightness Agnostic AXs in the PGD attack setting; thus, we call our method a CL-BA-PGD attack. CL is an approach proposed by [8] in which training difficulty is gradually increased while training DL models for better performance.\n\nTo generate attacks using our algorithm [Alg.1], nonlinear brightness transformations CN BT j () are applied to the training 1 image X adv i after the initialization [Alg.1; 1]. The transformations [Alg. 1; 4] are applied while regulating the optimization difficulty based on the loss J adv . The loss J adv in gradient descent setting calculates the inverse of cosine similarity between the predictions of f for X s and X t for the impersonation attacks and simply similarity for dodging attacks. For impersonation attacks, the adversary with identity s, tries to mimic the deep features of target identity t. For dodging attacks, s and t are same because adversary tries to minimize the similarity from its clean image's deep features. The predefined stepfunctions g 1 and g 2 change lower l i and upper h i limits for a uniform random variable X u \u223c U (l i , h i ), thus controlling the non-linear brightness changes.\n\nThe function BT changes the brightness of an image tensor X as BT (X) = X u \u00b7 X with probability p. The 0-1 mask M b,j with the same dimensions as the X adv i , randomly chooses a rectangular area R b inside X adv i in each j th iteration to scale brightness by X u . Thus,\n(M b,j ) (m,n) = 1 if (m, n) \u2208 R b and (M b,j ) (m,n) = 0 if (m, n) / \u2208 R b .\nThe patch masks M p is used to separate the predefined patch area inside X adv\ni . Also, M p = I 1 \u2212M p and M b,j = I 1 \u2212 M b,j where I 1 is all one matrix. The random variable Y j \u223c N (\u00b5 j , \u03c3 j ) follows Gaussian distribution.\nThe PGD updates are then performed on X adv i following [Alg. 1; 6]. Note that it is assumed that images are normalized in the [0,1] range. The parameters responsible for the CL are updated in the subsequent steps [Alg. 1; 7,8,9,11] following the idea of gradually changing the amount of brightness changes depending upon J adv . The parameter K is loss function specific and serves to provide a margin for the minimum values of the p parameter.\n\n\nA. Sorting optimization difficulty\n\nWe define the optimization difficulty in the i th iteration of the attack generation process as directly proportional to \u2206L k V \u00b7 B , which is the change in the adversarial loss caused by variation in the brightness V \u00b7 B of input image due to application of a (\u00b7)-type transformation. The large change in the adversarial loss causes significant variations in gradient-based methods' descent direction, making the optimization process challenging. Also, \u2206L k V \u00b7 B is calculated for k training 1 images for a DL model f trained for t \u2264 T iterations.\n\nWe applied linear and non-linear brightness transformations to a face image with adversarial eyeglass patch noise to assess the increased training 1 difficulty. We saw from Fig.2a that maximum variations in the adversarial loss (hence the optimization difficulty) was caused by nonlinear brightness transformations followed by linear and no brightness transformations, i.e. \u2206L k\nV nl B > \u2206L k V l B > \u2206L k V 0 B = 0.\nThus our hypothesis is that increased optimization difficulty reduces the chances of convergence to optimal solutions thereby reducing attack success probability.\n\nTo investigate the effect of the brightness changes and adversarial loss variations on the adversarial potential of successful AXs, we evaluated the reduction in attack success rate (ASR) due to linear [5] and non-linear brightness transformations. ASR is the fraction of AXs which successfully fooled the DL model during inference. Af-Algorithm 1: CL-BA-PGD Algorithm for Adversarial Patch Attacks Input: Source image X s of identity s; target image X t of identity t; face-matcher f ; adversarial loss function J adv ; random noise \u03b4; patch mask M p ; brightness mask M b ; stopping criteria T ; step functions g 1 & g 2 ; batch constant N ; similarity constant K; number of brightness ensembles N b ; learning rate \u03b1. Output: Brightness agnostic patch adversarial example X adv = X adv\nT \u22121 1 X adv 0 \u2190 X s \u00b7 M p + \u03b4 \u00b7 M p , l 0 \u2190 1, h 0 \u2190 1, p \u2190 0, loss cum 0 \u2190 0 2 for i=0 to T-1 do 3 for j=0 to N b \u2212 1 do 4 X i,j \u2190\u2212 CN BT j X adv i ; p; M p ; M p ; M b ; M b ; l i ; h i = Y j \u00b7 BT X adv i \u00b7 M p + X adv i \u00b7 M p \u00b7 M b,j \u00b7 X u + M b,j 5 end 6 X adv i+1 \u2190\u2212 clip 0\u22121 X adv i \u2212 \u03b1 \u00b7 sign N b \u22121 j=0 \u2207J adv (f (X i,j ), f (X t )) 7 loss cum i+1 = loss cum i + N b \u22121 j=0 J adv (f (Xi,j ),f (X t )) N b 8 l i+1 \u2190\u2212 g 1 (l i ); h i+1 \u2190\u2212 g 2 (h i ) 9 if i = 0 and i%N = 0 then 10 p = max 0, K \u2212 loss cum i N 11 loss cum i+1 = N b \u22121 j=0 J adv (f (Xi,j ),f (X t )) N b 12 end 13 end\nter evaluating eyeglass, sticker, and imperceptible noise attacks, the results for the ASR confirmed our hypothesis that non-linear brightness transformations cause a significant reduction in the ASR compared to the linear transformations.\n\n\nIII. Experimental Setup\n\nFor an adequate assessment, we considered four SOTA feature extractors: Residual Network (ResNet50) [10], MobileFaceNet [9], and Squeeze-and-Excitation Inception Residual Networks (SE-IR50, SE-IR100) [11]; trained on the VggFace2 data [6] using the arcface loss. The test accuracy on Vggface2 data of trained ResNet50, Mobile-FaceNet, SE-IR50, and SE-IR100 was found as 99.03%, 99.17%, 99.01%, and 99.02%, respectively. For each feature extractor, we implemented a simple PGD attack [7], the existing method [5], our method without CL, and our method with CL [Alg.1].\n\nWe implement our algorithm for the patch and the imperceptible noise attacks while evaluating in digital and physical worlds. The patch attacks were generated using [Alg.1]. For the imperceptible noise attacks, the adversarial noise \u03b4 with size constraints (\u03b4 \u2264 (4/255) th of input image's pixel range) was distributed over the entire area of the face image. In this case, we implemented\n[Alg.1] by changing [Alg.1; 4] with CN BT j (\u00b7) = Y j \u00b7 BT X adv i \u00b7 M b,j + X adv i \u00b7 M b,j .\nTo evaluate the white-box and black-box performance of the generated attacks, the white-box attacks were generated and tested directly on the target FRS (Tab.1). In contrast, the black-box attacks were generated using a surrogate FRS and tested on the target FRS (Tab.2) to evaluate the transferability of generated attacks.\n\nFor adversarial patch attacks, we considered an eyeglass patch (Fig.1a(i)) and a sticker patch (Fig.1a(ii)). For the practical evaluation of the generated attacks (100 AXs for each case) in the digital domain, the mean ASR for each AX was calculated after applying [Alg. 1; 4] transformations 100 times to simulate the practical brightness variations. For the evaluation in the physical world, the following steps were followed: (1) Generate digital AX.(2) Transfer it to the physical world by printing at 9 different brightness levels. (3) Capture the printed AXs from various angles. (4) Clean the captured data. We got approximately 20 images for each captured image. (5) Feed the data to the MTCNN face detection and alignment [12]. (6) Feed the preprocessed data to the target feature extractor and check the predictions.\n\n\nIV. Results\n\nTab.I and Tab.II shows the results for white-box and black-box ASRs, respectively, in the digital domain. The mean ASR is calculated for 100 AXs after applying the transformations mentioned in section III on each AX. Our method with CL results in a significantly higher ASR as compared to the existing method [5] and the naive method. Also, the existing method achieves better results than the naive method. The effect of better optimization due to CL can also be seen from the increased ASR from A3 to A4 columns of Tab.I. Our method also achieves better ASR for the digital black-box attacks (Tab.II). However, in this case, the performance difference was not as significant   as in the white-box setting. Additionally, sticker attacks were found to be having the highest ASRs (Tab.I and Tab.II) due to the larger area for the adversarial noise region and absence of imperceptible size constraints. The evaluation of the generated attacks in the physical domain also exhibited similar patterns as digital white-box ASR (Tab.1). Our method achieves 24.67% and 39.96% better mean ASR than the existing [5] and the naive PGD attack methods, respectively, for the eyeglass patch attack. Additionally, we evaluate the robustness of the brightness agnostic AXs against the model with JPEG compression [13], bit squeezing, and median blur defenses [14] in the pre-processing pipeline. These defenses do not directly cause brightness changes in the input images. After evaluation, we did not find sufficient evidence to validate the better ASR of the brightness agnostic AXs generated using our method against them.\n(b) (a)\n\nV. Conclusions\n\nThis paper contributed a novel CL-based method for generating AXs robust to the practical brightness changes. While considering attacks from digital and physical worlds, we found that our approach significantly exceeds the conventional techniques in white-box and black-box settings from our detailed analysis of the dodging and impersonation attacks. However, we did not find sufficient evidence for the superiority of our method against adversarial defenses that do not cause a direct change in the brightness of input images. A possible weakness of our approach is that it requires careful manual initialization of a few hyper-parameters responsible for CL that can directly affect attack performance. The generated attacks by our method enable practical risk assessment of the FRSs against such attacks. In the future, we would like to consider utilizing color space transformations, and assessing provided robustness improvements through adversarial training by our method.\n\nFig. 1 .\n1(a) illustrates an example of practical FRS and brightness corrections in input face images [6] during FRS's pre-processing. (i), (ii), and (iii) illustrate eyeglass, sticker, and imperceptible noise AXs. (iv) represents face images taken under variable brightness. (b) demonstrates an outline of our proposed method.\n\nFig. 2 .\n2(a) depicts the variation of the adversarial loss for the trained (till 100 iterations) MobileFaceNet[9] when subjected to no, linear, and non-linear brightness transformations. (b) demonstrates the performance (ASR) reduction due to the linear and non-linear brightness transformations for sticker attacks.\n\nTABLE I\nIThe mean ASR of the white-box attacks in the digital domain. DASR & IASR are Dodging & Impersonation ASRs. A 1 , A 2 , A 3 , and A 4 stands for naive, existing, our method w/o CL, and our CL-based methods, respectively.\nIn the context of AML, the trainable parameters are the adversarial noise pixels in the input image, optimized using an attack generation method. Thus we call the input image being optimized for adversarial objective as training image in the present setting.\n\nExplaining and harnessing adversarial examples. I J Goodfellow, J Shlens, C Szegedy, arXiv:1412.6572arXiv preprintI. J. Goodfellow, J. Shlens, and C. Szegedy, \"Explaining and har- nessing adversarial examples,\" arXiv preprint arXiv:1412.6572, 2014.\n\nCross-domain face verification: matching id document and self-portrait photographs. G Folego, M A Angeloni, J A Stuchi, A Godoy, A Rocha, arXiv:1611.05755arXiv preprintG. Folego, M. A. Angeloni, J. A. Stuchi, A. Godoy, and A. Rocha, \"Cross-domain face verification: matching id document and self-portrait photographs,\" arXiv preprint arXiv:1611.05755, 2016.\n\nA new image contrast enhancement algorithm using exposure fusion framework. Z Ying, G Li, Y Ren, R Wang, W Wang, International Conference on Computer Analysis of Images and Patterns. SpringerZ. Ying, G. Li, Y. Ren, R. Wang, and W. Wang, \"A new image contrast enhancement algorithm using exposure fusion framework,\" in International Conference on Computer Analysis of Images and Patterns. Springer, 2017, pp. 36-46.\n\nA novel approach of low-light image used for face recognition. D Ren, H Ma, L Sun, T Yan, 2015 4th International Conference on Computer Science and Network Technology (ICCSNT). IEEE1D. Ren, H. Ma, L. Sun, and T. Yan, \"A novel approach of low-light image used for face recognition,\" in 2015 4th Inter- national Conference on Computer Science and Network Tech- nology (ICCSNT), vol. 1. IEEE, 2015, pp. 790-793.\n\nRandom transformation of image brightness for adversarial attack. B Yang, K Xu, H Wang, H Zhang, arXiv:2101.04321arXiv preprintB. Yang, K. Xu, H. Wang, and H. Zhang, \"Random transforma- tion of image brightness for adversarial attack,\" arXiv preprint arXiv:2101.04321, 2021.\n\nVggface2: A dataset for recognising faces across pose and age. Q Cao, L Shen, W Xie, O M Parkhi, A Zisserman, International Conference on Automatic Face and Gesture Recognition. Q. Cao, L. Shen, W. Xie, O. M. Parkhi, and A. Zisserman, \"Vggface2: A dataset for recognising faces across pose and age,\" in International Conference on Automatic Face and Gesture Recognition, 2018.\n\nTowards deep learning models resistant to adversarial attacks. A Madry, A Makelov, L Schmidt, D Tsipras, A Vladu, arXiv:1706.06083arXiv preprintA. Madry, A. Makelov, L. Schmidt, D. Tsipras, and A. Vladu, \"Towards deep learning models resistant to adversarial attacks,\" arXiv preprint arXiv:1706.06083, 2017.\n\nLearning and development in neural networks: The importance of starting small. J L Elman, Cognition. 481J. L. Elman, \"Learning and development in neural networks: The importance of starting small,\" Cognition, vol. 48, no. 1, pp. 71-99, 1993.\n\nMobilefacenets: Efficient cnns for accurate real-time face verification on mobile devices. S Chen, Y Liu, X Gao, Z Han, Chinese Conference on Biometric Recognition. SpringerS. Chen, Y. Liu, X. Gao, and Z. Han, \"Mobilefacenets: Efficient cnns for accurate real-time face verification on mobile devices,\" in Chinese Conference on Biometric Recognition. Springer, 2018, pp. 428-438.\n\nDeep residual learning for image recognition. K He, X Zhang, S Ren, J Sun, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionK. He, X. Zhang, S. Ren, and J. Sun, \"Deep residual learning for image recognition,\" in Proceedings of the IEEE conference on computer vision and pattern recognition, 2016, pp. 770-778.\n\nSqueeze-and-excitation networks. J Hu, L Shen, G Sun, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionJ. Hu, L. Shen, and G. Sun, \"Squeeze-and-excitation networks,\" in Proceedings of the IEEE conference on computer vision and pattern recognition, 2018, pp. 7132-7141.\n\nJoint face detection and facial expression recognition with mtcnn. J Xiang, G Zhu, 2017 4th International Conference on Information Science and Control Engineering (ICISCE). J. Xiang and G. Zhu, \"Joint face detection and facial expression recognition with mtcnn,\" in 2017 4th International Conference on Information Science and Control Engineering (ICISCE).\n\n. IEEE. IEEE, 2017, pp. 424-427.\n\nA study of the effect of jpg compression on adversarial images. G K Dziugaite, Z Ghahramani, D M Roy, arXiv:1608.00853arXiv preprintG. K. Dziugaite, Z. Ghahramani, and D. M. Roy, \"A study of the effect of jpg compression on adversarial images,\" arXiv preprint arXiv:1608.00853, 2016.\n\nFeature squeezing: Detecting adversarial examples in deep neural networks. W Xu, D Evans, Y Qi, arXiv:1704.01155arXiv preprintW. Xu, D. Evans, and Y. Qi, \"Feature squeezing: Detecting adversarial examples in deep neural networks,\" arXiv preprint arXiv:1704.01155, 2017.\n", "annotations": {"author": "[{\"end\":204,\"start\":80},{\"end\":333,\"start\":205},{\"end\":457,\"start\":334},{\"end\":585,\"start\":458}]", "publisher": null, "author_last_name": "[{\"end\":95,\"start\":90},{\"end\":220,\"start\":212},{\"end\":349,\"start\":341},{\"end\":473,\"start\":468}]", "author_first_name": "[{\"end\":89,\"start\":80},{\"end\":211,\"start\":205},{\"end\":340,\"start\":334},{\"end\":467,\"start\":458}]", "author_affiliation": "[{\"end\":203,\"start\":117},{\"end\":332,\"start\":246},{\"end\":456,\"start\":370},{\"end\":584,\"start\":498}]", "title": "[{\"end\":77,\"start\":1},{\"end\":662,\"start\":586}]", "venue": null, "abstract": "[{\"end\":1467,\"start\":754}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":1699,\"start\":1696},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2081,\"start\":2078},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3494,\"start\":3491},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":3766,\"start\":3763},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":4088,\"start\":4085},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":4948,\"start\":4945},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":5731,\"start\":5728},{\"end\":6043,\"start\":6038},{\"end\":7404,\"start\":7399},{\"end\":7569,\"start\":7557},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":9158,\"start\":9155},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":10703,\"start\":10699},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":10722,\"start\":10719},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":10803,\"start\":10799},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":10837,\"start\":10834},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":11085,\"start\":11082},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":11110,\"start\":11107},{\"end\":12253,\"start\":12248},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":12712,\"start\":12708},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":13131,\"start\":13128},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":13924,\"start\":13921},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":14120,\"start\":14116},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":14166,\"start\":14162},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":15877,\"start\":15874}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":15761,\"start\":15433},{\"attributes\":{\"id\":\"fig_1\"},\"end\":16080,\"start\":15762},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":16310,\"start\":16081}]", "paragraph": "[{\"end\":2082,\"start\":1486},{\"end\":2897,\"start\":2084},{\"end\":3749,\"start\":2899},{\"end\":4558,\"start\":3751},{\"end\":5175,\"start\":4560},{\"end\":5832,\"start\":5233},{\"end\":6754,\"start\":5834},{\"end\":7029,\"start\":6756},{\"end\":7186,\"start\":7108},{\"end\":7782,\"start\":7337},{\"end\":8370,\"start\":7821},{\"end\":8750,\"start\":8372},{\"end\":8951,\"start\":8789},{\"end\":9741,\"start\":8953},{\"end\":10571,\"start\":10332},{\"end\":11166,\"start\":10599},{\"end\":11555,\"start\":11168},{\"end\":11975,\"start\":11651},{\"end\":12803,\"start\":11977},{\"end\":14428,\"start\":12819},{\"end\":15432,\"start\":14454}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":7107,\"start\":7030},{\"attributes\":{\"id\":\"formula_1\"},\"end\":7336,\"start\":7187},{\"attributes\":{\"id\":\"formula_2\"},\"end\":8788,\"start\":8751},{\"attributes\":{\"id\":\"formula_3\"},\"end\":10331,\"start\":9742},{\"attributes\":{\"id\":\"formula_4\"},\"end\":11650,\"start\":11556},{\"attributes\":{\"id\":\"formula_5\"},\"end\":14436,\"start\":14429}]", "table_ref": null, "section_header": "[{\"end\":1484,\"start\":1469},{\"end\":5231,\"start\":5178},{\"end\":7819,\"start\":7785},{\"end\":10597,\"start\":10574},{\"end\":12817,\"start\":12806},{\"end\":14452,\"start\":14438},{\"end\":15442,\"start\":15434},{\"end\":15771,\"start\":15763},{\"end\":16089,\"start\":16082}]", "table": null, "figure_caption": "[{\"end\":15761,\"start\":15444},{\"end\":16080,\"start\":15773},{\"end\":16310,\"start\":16091}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":3560,\"start\":3554},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":5363,\"start\":5357},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":8551,\"start\":8545},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":12050,\"start\":12040},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":12083,\"start\":12072}]", "bib_author_first_name": "[{\"end\":16620,\"start\":16619},{\"end\":16622,\"start\":16621},{\"end\":16636,\"start\":16635},{\"end\":16646,\"start\":16645},{\"end\":16906,\"start\":16905},{\"end\":16916,\"start\":16915},{\"end\":16918,\"start\":16917},{\"end\":16930,\"start\":16929},{\"end\":16932,\"start\":16931},{\"end\":16942,\"start\":16941},{\"end\":16951,\"start\":16950},{\"end\":17257,\"start\":17256},{\"end\":17265,\"start\":17264},{\"end\":17271,\"start\":17270},{\"end\":17278,\"start\":17277},{\"end\":17286,\"start\":17285},{\"end\":17660,\"start\":17659},{\"end\":17667,\"start\":17666},{\"end\":17673,\"start\":17672},{\"end\":17680,\"start\":17679},{\"end\":18073,\"start\":18072},{\"end\":18081,\"start\":18080},{\"end\":18087,\"start\":18086},{\"end\":18095,\"start\":18094},{\"end\":18346,\"start\":18345},{\"end\":18353,\"start\":18352},{\"end\":18361,\"start\":18360},{\"end\":18368,\"start\":18367},{\"end\":18370,\"start\":18369},{\"end\":18380,\"start\":18379},{\"end\":18724,\"start\":18723},{\"end\":18733,\"start\":18732},{\"end\":18744,\"start\":18743},{\"end\":18755,\"start\":18754},{\"end\":18766,\"start\":18765},{\"end\":19049,\"start\":19048},{\"end\":19051,\"start\":19050},{\"end\":19304,\"start\":19303},{\"end\":19312,\"start\":19311},{\"end\":19319,\"start\":19318},{\"end\":19326,\"start\":19325},{\"end\":19640,\"start\":19639},{\"end\":19646,\"start\":19645},{\"end\":19655,\"start\":19654},{\"end\":19662,\"start\":19661},{\"end\":20030,\"start\":20029},{\"end\":20036,\"start\":20035},{\"end\":20044,\"start\":20043},{\"end\":20426,\"start\":20425},{\"end\":20435,\"start\":20434},{\"end\":20816,\"start\":20815},{\"end\":20818,\"start\":20817},{\"end\":20831,\"start\":20830},{\"end\":20845,\"start\":20844},{\"end\":20847,\"start\":20846},{\"end\":21112,\"start\":21111},{\"end\":21118,\"start\":21117},{\"end\":21127,\"start\":21126}]", "bib_author_last_name": "[{\"end\":16633,\"start\":16623},{\"end\":16643,\"start\":16637},{\"end\":16654,\"start\":16647},{\"end\":16913,\"start\":16907},{\"end\":16927,\"start\":16919},{\"end\":16939,\"start\":16933},{\"end\":16948,\"start\":16943},{\"end\":16957,\"start\":16952},{\"end\":17262,\"start\":17258},{\"end\":17268,\"start\":17266},{\"end\":17275,\"start\":17272},{\"end\":17283,\"start\":17279},{\"end\":17291,\"start\":17287},{\"end\":17664,\"start\":17661},{\"end\":17670,\"start\":17668},{\"end\":17677,\"start\":17674},{\"end\":17684,\"start\":17681},{\"end\":18078,\"start\":18074},{\"end\":18084,\"start\":18082},{\"end\":18092,\"start\":18088},{\"end\":18101,\"start\":18096},{\"end\":18350,\"start\":18347},{\"end\":18358,\"start\":18354},{\"end\":18365,\"start\":18362},{\"end\":18377,\"start\":18371},{\"end\":18390,\"start\":18381},{\"end\":18730,\"start\":18725},{\"end\":18741,\"start\":18734},{\"end\":18752,\"start\":18745},{\"end\":18763,\"start\":18756},{\"end\":18772,\"start\":18767},{\"end\":19057,\"start\":19052},{\"end\":19309,\"start\":19305},{\"end\":19316,\"start\":19313},{\"end\":19323,\"start\":19320},{\"end\":19330,\"start\":19327},{\"end\":19643,\"start\":19641},{\"end\":19652,\"start\":19647},{\"end\":19659,\"start\":19656},{\"end\":19666,\"start\":19663},{\"end\":20033,\"start\":20031},{\"end\":20041,\"start\":20037},{\"end\":20048,\"start\":20045},{\"end\":20432,\"start\":20427},{\"end\":20439,\"start\":20436},{\"end\":20828,\"start\":20819},{\"end\":20842,\"start\":20832},{\"end\":20851,\"start\":20848},{\"end\":21115,\"start\":21113},{\"end\":21124,\"start\":21119},{\"end\":21130,\"start\":21128}]", "bib_entry": "[{\"attributes\":{\"doi\":\"arXiv:1412.6572\",\"id\":\"b0\"},\"end\":16819,\"start\":16571},{\"attributes\":{\"doi\":\"arXiv:1611.05755\",\"id\":\"b1\"},\"end\":17178,\"start\":16821},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":36711374},\"end\":17594,\"start\":17180},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":17526029},\"end\":18004,\"start\":17596},{\"attributes\":{\"doi\":\"arXiv:2101.04321\",\"id\":\"b4\"},\"end\":18280,\"start\":18006},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":216009},\"end\":18658,\"start\":18282},{\"attributes\":{\"doi\":\"arXiv:1706.06083\",\"id\":\"b6\"},\"end\":18967,\"start\":18660},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":2105042},\"end\":19210,\"start\":18969},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":5025785},\"end\":19591,\"start\":19212},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":206594692},\"end\":19994,\"start\":19593},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":140309863},\"end\":20356,\"start\":19996},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":6630438},\"end\":20715,\"start\":20358},{\"attributes\":{\"id\":\"b12\"},\"end\":20749,\"start\":20717},{\"attributes\":{\"doi\":\"arXiv:1608.00853\",\"id\":\"b13\"},\"end\":21034,\"start\":20751},{\"attributes\":{\"doi\":\"arXiv:1704.01155\",\"id\":\"b14\"},\"end\":21305,\"start\":21036}]", "bib_title": "[{\"end\":17254,\"start\":17180},{\"end\":17657,\"start\":17596},{\"end\":18343,\"start\":18282},{\"end\":19046,\"start\":18969},{\"end\":19301,\"start\":19212},{\"end\":19637,\"start\":19593},{\"end\":20027,\"start\":19996},{\"end\":20423,\"start\":20358}]", "bib_author": "[{\"end\":16635,\"start\":16619},{\"end\":16645,\"start\":16635},{\"end\":16656,\"start\":16645},{\"end\":16915,\"start\":16905},{\"end\":16929,\"start\":16915},{\"end\":16941,\"start\":16929},{\"end\":16950,\"start\":16941},{\"end\":16959,\"start\":16950},{\"end\":17264,\"start\":17256},{\"end\":17270,\"start\":17264},{\"end\":17277,\"start\":17270},{\"end\":17285,\"start\":17277},{\"end\":17293,\"start\":17285},{\"end\":17666,\"start\":17659},{\"end\":17672,\"start\":17666},{\"end\":17679,\"start\":17672},{\"end\":17686,\"start\":17679},{\"end\":18080,\"start\":18072},{\"end\":18086,\"start\":18080},{\"end\":18094,\"start\":18086},{\"end\":18103,\"start\":18094},{\"end\":18352,\"start\":18345},{\"end\":18360,\"start\":18352},{\"end\":18367,\"start\":18360},{\"end\":18379,\"start\":18367},{\"end\":18392,\"start\":18379},{\"end\":18732,\"start\":18723},{\"end\":18743,\"start\":18732},{\"end\":18754,\"start\":18743},{\"end\":18765,\"start\":18754},{\"end\":18774,\"start\":18765},{\"end\":19059,\"start\":19048},{\"end\":19311,\"start\":19303},{\"end\":19318,\"start\":19311},{\"end\":19325,\"start\":19318},{\"end\":19332,\"start\":19325},{\"end\":19645,\"start\":19639},{\"end\":19654,\"start\":19645},{\"end\":19661,\"start\":19654},{\"end\":19668,\"start\":19661},{\"end\":20035,\"start\":20029},{\"end\":20043,\"start\":20035},{\"end\":20050,\"start\":20043},{\"end\":20434,\"start\":20425},{\"end\":20441,\"start\":20434},{\"end\":20830,\"start\":20815},{\"end\":20844,\"start\":20830},{\"end\":20853,\"start\":20844},{\"end\":21117,\"start\":21111},{\"end\":21126,\"start\":21117},{\"end\":21132,\"start\":21126}]", "bib_venue": "[{\"end\":16617,\"start\":16571},{\"end\":16903,\"start\":16821},{\"end\":17361,\"start\":17293},{\"end\":17771,\"start\":17686},{\"end\":18070,\"start\":18006},{\"end\":18458,\"start\":18392},{\"end\":18721,\"start\":18660},{\"end\":19068,\"start\":19059},{\"end\":19375,\"start\":19332},{\"end\":19745,\"start\":19668},{\"end\":20127,\"start\":20050},{\"end\":20530,\"start\":20441},{\"end\":20723,\"start\":20719},{\"end\":20813,\"start\":20751},{\"end\":21109,\"start\":21036},{\"end\":19809,\"start\":19747},{\"end\":20191,\"start\":20129}]"}}}, "year": 2023, "month": 12, "day": 17}