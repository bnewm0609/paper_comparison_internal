{"id": 254366628, "updated": "2023-10-05 07:11:41.105", "metadata": {"title": "A Temporal Graph Neural Network for Cyber Attack Detection and Localization in Smart Grids", "authors": "[{\"first\":\"Seyed\",\"last\":\"Haghshenas\",\"middle\":[\"Hamed\"]},{\"first\":\"Md\",\"last\":\"Hasnat\",\"middle\":[\"Abul\"]},{\"first\":\"Mia\",\"last\":\"Naeini\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "This paper presents a Temporal Graph Neural Network (TGNN) framework for detection and localization of false data injection and ramp attacks on the system state in smart grids. Capturing the topological information of the system through the GNN framework along with the state measurements can improve the performance of the detection mechanism. The problem is formulated as a classification problem through a GNN with message passing mechanism to identify abnormal measurements. The residual block used in the aggregation process of message passing and the gated recurrent unit can lead to improved computational time and performance. The performance of the proposed model has been evaluated through extensive simulations of power system states and attack scenarios showing promising performance. The sensitivity of the model to intensity and location of the attacks and model's detection delay versus detection accuracy have also been evaluated.", "fields_of_study": "[\"Computer Science\",\"Engineering\"]", "external_ids": {"arxiv": "2212.03390", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/isgt/HaghshenasHN23", "doi": "10.1109/isgt51731.2023.10066446"}}, "content": {"source": {"pdf_hash": "f6237dde69d3bf1cf77f0ba258171b775f97055b", "pdf_src": "Arxiv", "pdf_uri": "[\"https://export.arxiv.org/pdf/2212.03390v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "81ff51b0066f9bdeb72014c0f30aa93f78bcdbde", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/f6237dde69d3bf1cf77f0ba258171b775f97055b.txt", "contents": "\nA Temporal Graph Neural Network for Cyber Attack Detection and Localization in Smart Grids\n7 Dec 2022\n\nSeyed Hamed Haghshenas seyedhamedhaghshenas@usf.edu \nDept. of Electrical Engineering\nDept. of Electrical Engineering\nUniversity of South Florida Tampa\nFLUSA\n\nMdAbul Hasnat hasnat@usf.edu \nDept. of Electrical Engineering\nUniversity of South Florida Tampa\nFLUSA\n\nMia Naeini mnaeini@usf.edu \nUniversity of South Florida Tampa\nFLUSA\n\nA Temporal Graph Neural Network for Cyber Attack Detection and Localization in Smart Grids\n7 Dec 2022\nThis paper presents a Temporal Graph Neural Network (TGNN) framework for detection and localization of false data injection and ramp attacks on the system state in smart grids. Capturing the topological information of the system through the GNN framework along with the state measurements can improve the performance of the detection mechanism. The problem is formulated as a classification problem through a GNN with message passing mechanism to identify abnormal measurements. The residual block used in the aggregation process of message passing and the gated recurrent unit can lead to improved computational time and performance. The performance of the proposed model has been evaluated through extensive simulations of power system states and attack scenarios showing promising performance. The sensitivity of the model to intensity and location of the attacks and model's detection delay versus detection accuracy have also been evaluated.\n\nI. INTRODUCTION\n\nSmart grids are being extensively equipped with sensing and monitoring devices to improve their performance and reliability. For instance, phasor measurement units (PMUs) are deployed in smart grids and designed to acquire the physical measurements of the system. The measurements will be relayed over communication networks to enhance situational awareness and the operation of the system [1]. The cyber elements of smart grids provide new opportunities for improving the operation and control of these systems; however, they also introduce vulnerabilities to cyber attacks.\n\nThe measurement data in the smart grid that are collected through the sensors and communicated over the communication networks, such as voltage, current, power injections, and the status information of breakers and switches are vulnerable to cyber attacks. These data are utilized to obtain the states of the power system, which is crucial for the proper operation and maintenance of the smart grid to ensure a seamless supply of electricity to the consumers. Cyber attacks, by disrupting the availability and integrity of the measurement data, can threaten the reliability and performance of smart grids, and their timely detection and localization are important from the grid operators' perspective. In this work, two of the cyber attacks related to the integrity of the smart grid data, namely False Data Injection Attacks (FDIAs) [2]- [4] and a special form of FDIA, namely, Ramp attacks [4]- [6] are considered. Both attacks aim to stealthily change data in the system measurements such that it affects functions that rely on them.\n\nTo capture the topological structure and the connectivity information of the smart grid along with the temporal measurement data, power system measurements can be modeled as time-varying graph signals [4], [7] so that they can be analyzed by graph signal processing tools which extends the concepts and tools of classical signal processing to irregular graph domain data in non-euclidean space [8]. Moreover, graph neural network (GNN)-based analyses can also be applied to the data modeled as time-varying power system graph signals [9]- [11]. In this work, a temporal GNN (TGNN) framework is presented to consider both the temporal measurements at each bus of the system and the topological connectivity (by considering the buses as the vertices/nodes, and transmission lines as the edges of the graph) to detect and locate the attacks. Specifically, the detection and localization problem is formulated as a classification problem through a GNN with a message passing mechanism to identify abnormal measurements at buses. A Gated Recurrent Unit (GRU) is implemented in the model to capture the temporal features from the time-series data on each bus in the power system. Additionally, a residual block is designed to address the vanishing gradient problem and optimized the spatio-temporal features acquired by the GNN.\n\nThe performance of the proposed model has been evaluated through the training and testing of the proposed TGNN method with FDIA and ramp attack data specially designed for timeseries data from the power system [4] that does not contain abrupt changes of values at the onset making them challenging to detect. The results show a promising performance with high accuracy in detecting and locating both the FDIA and ramp attacks. The sensitivity of the model to the intensity of the attacks and the topological location of the attacks have also been evaluated suggesting that detecting attacks at certain locations are more challenging than the other locations.\n\n\nII. RELATED WORK\n\nSmart grid's security have gained considerable attention from researchers and practitioners in the past few decades. Both model-based and data-driven techniques for the detection and localization of cyber attacks are proposed and studied in the literature [3]. While model-based approaches [2], [3] require the knowledge of the system and information on its structure and dynamics, the data-driven approaches utilize the large volume of available measurement data to detect cyber attacks. The majority of the data-driven detecting and locating techniques are signal processing-based [5], machine learning-based [12], and their combinations [6]. However, one of the limitations of these techniques is that they do not explicitly capture and utilize the underlying structure of the system in their analyses. As smart grids have a graph structure that reflects the connectivity of their components and can affect the dynamics and interactions of the components, the data from these systems naturally have embedded structures. Therefore, by modeling the structure of the power grid as a graph and the data associated with it as graph signals, one can capture the information related to the connectivity and interdependence among the components of the grid. The power system measurement data modeled as graph signals can be utilized in two ways for detecting cyber attacks: 1) by applying graph signal processing tools to the power system graph signal [4], [7], [13], or 2) using graph neural networks [10], [11] to the graph-structured data. A common GSP-based approach is to utilize the graph Fourier transform (GFT) to analyze the presence of a high-graph frequency component as the indicator of falsified measurements [4], [7], [13]. However, the local smoothness second time-derivative (LSSTD)-based method [4], by capturing both the temporal and vertex-to-vertex evolution of the graph signal is effective for detecting and locating sophisticated designed cyber attack with no sharp changes of signal values at the onset of the attack. The main limitation of the GSP-based method is the requirement of decision thresholds to be applied to the graphspectral measures, which can be challenging to fix empirically. On the other hand, GNN-based methods automatically adjust the model parameters to utilize graph-structured data along with the topology. Detection and localization of cyber attacks in smart grids can be cast into a node classification problem within the GNN framework. For instance, in [10], [11], GCN frameworks have been used for FDIA detection to classify normal buses in the system from the ones with malicious data. The current paper presents a spatio-temporal-GNN framework for cyber attack detection and location identification in smart grids, which also models the task as a node classification problem. Compared to the work presented in [10] based on GNN, the model presented in the current paper uses a combination of message passing process and GRUs in residual blocks in the places of graph convolutional layers and autoregressive moving average (ARMA) filter, respectively, which can improve the computational time and performance.\n\n\nIII. METHODOLOGY\n\n\nA. Power System Model\n\nIn this paper, the physical topology of the power system is represented as a graph G := {V, E} with adjacency matrix, A = [a ij ], where V is the set of vertices of the graph representing the buses, and E = {e ij : (i, j) \u2208 V \u00d7V, a ij = 1} is the set of all edges representing the transmission lines of the power grid. Various attributes can be associated with each bus n \u2208 V, for instance, the real and reactive power injections, bus voltage magnitude and angle, injected bus current magnitude and angle, frequency, etc. This work considers the real power injection at each bus as a time-varying graph signal, x(n, t). Specifically, the signal value of x(n, t) represents the injected real power at bus n. It is also assumed that the measurements are available at all the buses of the system (for instance through PMUs or state estimation mechanisms).\n\n\nB. Cyber Attack Model\n\nCyber attacks on the power system measurements (e.g. SCADA or PMUs) have been modeled in different ways depending on the diversity of the scenarios, research problems, and perspectives of the research. In this work, the cyber attacks are modeled on the time-varying real power injection in each bus. The cyber attacks considered in this work are designed in such a way that they do not contain abrupt changes in signal values at the onset of the attack making them challenging to detect. For modeling the cyber attacks, i.e., FDIA and ramp attack, we endorse the generalized approach presented in [4]. Specifically, let V A \u2282 V denotes the set of all buses under cyber attack at time interval [t start , t end ]. The cyber attacks on the bus real power injection time series in the generalized form can be expressed by the following equation:\nx(n A , t) = c(t), for t start \u2264 t \u2264 t end , and n A \u2208 V A (1)\nThe cyber attacks considered in this paper can be modeled as special cases of equation (1) as discussed next.\n\n1) False Data Injection Attack: There are various work on modeling FDIA in smart grids and the goal of such models are to characterize FDIA that can bypass the bad data detectors and affect the state estimation function [7]. Considering the state estimation framework in power systems with z = h(y), where z and y are the measurements and the states of the power system and h is a non-linear function, which relates measurements and states, the goal of the FDIA is generally to inject bad data to the set of measurements to compromise the performance of the estimator. If the residue of state estimation r = ||z \u2212 h(\u0177)|| 2 error is larger than a defined threshold, where\u0177 is the estimated states then a bad data can be detected. If the attack is designed in a way that passes the aforementioned test then the bad data detector cannot detect the attack. Following the work in [4], in this work, FDIA with no sharp change at the onset of the attack is modeled by considering (1) where b \u2208 {0, 1}, |x \u2032 | is considered to be a very small value, which does not result in sharp changes in the onset of the attack and bypasses the bad data detector as discussed earlier.\nc(t) = x(n A , t) + (\u22121) b x \u2032 , in equation\n2) Ramp Attack: Ramp attack is a special form of FDIA. In ramp attack, to ensure the smooth changes of values at the attack onset, falsified measurements are inserted gradually into the bus(es) under cyber attack, which makes them challenging to detect. Ramp attack can be modeled as c(t) = x(n A , t start )+m\u00d7(t\u2212t start )+q(n A , t), where m is the slope and q(n A , t) is the additive white Gaussian noise associated with the measurement devices at the bus n A . \n\n\nC. Model Architecture\n\nIn this section, the TGNN model used in this paper is introduced. Given the adjacency matrix A := {0, 1} \u2208 R {N \u00d7N } , and feature matrix X, a GNN layer can be expressed as H l+1 = \u03c3(D \u22121/2\u00c3D\u22121/2 H l W l ). Here,\u00c3 := A + I N (where I N is the identity matrix of size N ) andD is the degree matrix. \u03c3(.) is the sigmoid activation function, I is the layer number, W l holds the weights of layer l and H l is the output of layer l. To create a multi-layer GNN, multiple of such layers can adopted. Fig.1 demonstrates the architecture of the proposed TGNN model in this paper. This model is following the message passing method of general GNNs [14]. The proposed architecture consists of three sequential layers aiming to extract and optimize the spatio-temporal features of the data following by a dropout and a dense layer. Each of the three layers contains; 1) A message passing block to acquire the structural and topological features of the data, 2) A GRU block to obtain the temporal features of the data, 3) A residual block in which Batch Normalization and a Rectified Linear Unit (ReLu) activation function is applied to the data and 4) A skip connection that feeds the output of one layer as the input to the next layer.\n\nThe message passing process can be describe as following. At node-level, the embedding of node i will be updated based on the aggregated feature of the node itself along with its onehop neighbors as f (x i ) = \u03c6(x i , \u2295 j\u2208Ni \u03c8(x i , x j )), where N i is the set of one-hop distance neighbors of node i, \u2295 is the permutation invariant aggregation function and \u03c6 and \u03c8 are learnable functions to be characterized using neural network. The three sequential GNN layers allow message passing up to three-hop distance neighbors. Afterwards, the GRUs are implemented in our architecture. GRUs are improved version of standard recurrent neural network. They aim to solve the vanishing gradient problem [15]. Additionally, due to their update gate and reset gate feature, they can keep information from long ago, without washing it through time. Every GRU has four gates. 1) Update gate(z t ): for time step t using the z t = \u03c3(W (z) x t + U (z) h t\u22121 ). When x t is fed into the unit, it is multiplied by its weight W (z) . The same applies to h t\u22121 that contains the information of the previous t \u2212 1 units and is multiplied by its own weight of U (z) . Then a Sigmoid activation function is applied to squash the results between 0 and 1. The update gate determines how much of the past information(from previous time steps) needs to be passed along to the next unit. 2) Reset gate(r t ): this gate decides how much of the past information to forget. It follows the formula similar to the previous one, r t = \u03c3(W (r) x t + U (r) h t\u22121 ) with a difference in the weights and the gate's usage in the next gates. 3) Current memory content (h \u2032 t ): it will use the output of the reset gate to store the relevant information from the past. The formula is h \u2032 t = tanh (W x t + r t \u2297 U h t\u22121 ), where the input x t and information from the previous unit are multiplied by their weights, W and U , respectively, and the reset gate is applied to the previous unit information by Hadamard (element-wise) product (\u2297). This helps the unit to determine what to remove from the previous time steps. At the end, these two calculated results are summed up and a non-linear activation function of tanh is applied to them. 4) Final memory at current time step (h t ): h t is the vector that holds information for the current unit and passes it down to the network. To calculate the current time step memory, the update gate is needed since\nh t = z t \u2297 h t\u22121 + (1 \u2212 z t ) \u2297 h \u2032 t .\nBased on the formula, the unit can learn to set the z t close to 1 and keep a majority of the previous information. z t being close to 1 causes the (1 \u2212 z t ) being close to 0 that ignores big portion of the current information. The sequence of mentioned four gates in GRU allows it to store and filter the information using the update and reset gates. Therefore, the GRU is able to eliminate the vanishing gradient problem.\n\nOnce the spatial and temporal features extracted, residual blocks and skip connections are applied. They aim to address the degradation problem and feature reusability. The results are then fed to a dropout and a dense layer which produces softmax values to the output layer. The model produces either 0 or 1 labels for the nodes of the system at each time instance specifying if the measurement is normal or abnormal, respectively. Therefore, the TGNN output specifies the beginning and ending time of the detected abnormal data as well.\n\n\nD. Model Parameters\n\nIn this work, Stochastic Gradient Descent (SGD) optimizer is used in our TGNN model. The learning rate of 0.001, the exponential decay rate of e (\u22126) , momentum of 0.9 that accelerates gradient descent in the relevant direction and dampens oscillations, and Nesterov momentum are considered. Nesterov momentum calculates the decaying moving average of the gradients of projected positions in the search space as a substitute to the actual positions [19], [20]. The size of hidden layers in the dense output layer is set to 64 and the dropout rate is set as 0.3. Threshold value of 0.5 is used in the output layer for deciding the binary labels. In this work, simialar to [10], [11], the real power injections at the buses are considered as state representors of the buses or features associated with each bus. While other measurements including voltage magnitude V i and voltage angle \u03b8 i can also be considered and have been considered in the literature, our experiments have shown strong correlation among these features. The model takes input batch size of 256 representing the number of samples processed before the model is updated. The binary cross entropy is used as the loss function. The network monitors the binary accuracy, which determines the ratio of correct predictions of labels.\n\n\nIV. RESULTS\n\n\nA. Data Generation and Data Processing\n\nIn this study, the time-series power system measurements are obtained by running power flow in MATPOWER 7.0 [17] on IEEE 118 bus system [16] by varying the load demands in time according to the load pattern obtained from the New York Independent System Operator (NYISO) [18] as described in [4]. The system state x (V i and \u03b8 i at each bus) is estimated using the PSSE module [10], [11]. PSSE solves the optimization problem inx = min x (z \u2212 h(x)) T R \u22121 (z \u2212 h(x)), as a weighted least squares estimation using complex power measurements z collected by PMUs. In the optimization equation, R represents measurements' error covariance matrix and z includes P i , Q i , P ij and Q ij . We consider the bus real power injections as the measurement data with 52, 500 time instances for training and 17, 500 time instances for testing. For half of the instances, cyber attacks (FDIA, and ramp) are launched according to the model described in Section III.B. 15% of training data have been used for cross-validation. The measurement data sampling frequency is 30Hz. As mentioned earlier, the maximum number of epochs for training considered is set to be 100 with early stopping criteria, where 75 epochs are tolerated without any enhancement in the accuracy and loss of validation set. All the implementations are executed in Python3.6 using Sklearn, Tensorflow, Keras, and Networkx on an Intel Core i7-7700 CPU 3.60GHz.\n\n\nB. Detection Performance of TGNN Framework\n\nThe performance of the proposed TGNN Framework is evaluated in terms of detection accuracy and detection delay. The latter metric is important for the suitability of implementing the technique in real-time scenarios. The TGNN model detects FDIA and ramp attacks with an overall accuracy of 99.50% and 88.85%, respectively. A sensitivity analysis has been conducted to evaluate the role of the intensity of the FDIA attack on the performance of the TGNN model. Specifically, the intensity of the FDIA has been varied by considering various |x \u2032 | values in the range of [\u22120.002, 0.002] per unit as discussed in Section III. The results of this sensitivity analysis in terms of the acquired accuracy are presented in Fig. 2. When |x \u2032 | = 0, which represents no attack, the model performance is high in labeling no attacks in the system. When |x \u2032 | = 0.0001 then the TGNN model accuracy drops to 62.51%, which is the point where the model fails to detect the attack.\n\nThe results indicate that TGNN can detect and locate the FDIAs exactly at the instances in which that attacks are introduced. However, for the ramp attacks, the detection delays are in the range of 0 to 20 time instances, where most of the attacks are detected within 9 time instances while for only a few cases the delay is large (around 20 time instance). For this reason, the median detection delay is chosen as the metric for the real-time applicability of the TGNN model. In order to evaluate the impact of FDIA in different buses, 1000 FDIA has been simulated and considered separately on each node with x \u2032 = 0.02 on a one-day, i.e., 2,500 instance dataset. The accuracy of the FDIA detection in each of the buses are shown in Fig. 3. It can be observed that some of the buses of the system are more sensitive to attacks than others by reflecting the lower performance of detection. This suggests that the proposed model can be sensitive to the location of the FDIA. Similar analysis have been performed for the ramp attack as illustrated in Fig. 4. The accuracy in some of the buses drops to 88.1% while in others it is up to 89.91%.  \n\n\nC. Comparison with baseline GNN model\n\nWe have also developed a baseline GNN model, which does not consider the temporal information and therefore, is mainly  \n\n\nV. CONCLUSION\n\nIn this work, a TGNN framework has been proposed that uses both the temporal and topological information from the system to detect and localize the cyber attacks. Adopting the message passing method, GRU, and residual blocks in the model, the proposed TGNN is capable of producing and processing messages and updating the node embeddings by aggregating and summing node representations in each node's neighborhood. The model can detect and localize FDIAs and ramp attacks with high accuracy, which was verified experimentally using simulation data on the IEEE 118 bus system. Moreover, sensitivity analyses of the model based on different magnitudes of attack and the location of the attack were performed and compared to our baseline GNN model that is developed to only take the topological structures of the power system along each snap-shot of the states.\n\nVI. ACKNOWLEDGEMENT This material is based upon work supported by the National Science Foundation under Grant No. 2118510.\n\nFig. 1 .\n1Architecture of the proposed TGNN for real-time cyber attack detection and localization.\n\nFig. 2 .\n2Sensitivity analyses of TGNN model for FDIA detection in terms of accuracy for various intensities of attack, |x \u2032 |.\n\nFig. 3 .\n3Sensitivity analyses of TGNN model for FDIA detection in terms of accuracy for various locations (i.e., bus index) of the attack.\n\nFig. 4 .\n4Sensitivity analyses of TGNN model for ramp attack detection in terms of accuracy for various locations (i.e., bus index) of the attack.\n\n\nFig. 5. Sensitivity analyses of TGNN model for ramp attack detection in terms of median of detection delay for various locations.suitable for detecting and locating attacks from snap-shot data. It comprises a message passing block similar to the message passing module introduced in the TGNN model and a Feed-Forward Network (FFN) block that prepares and updates the spatial features at each bus of the power system. Applying this baseline GNN model to the FDIA data, high accuracy of 99.97% can be achieved. A similar sensitivity analysis for the intensity of the attack |x \u2032 | for this model has been illustrated inFig. 6in the range of [\u22120.02, 0.02]. This baseline GNN model fails to detect FDIAs at |x \u2032 | = 0.001, which is 10 times larger than the failure point of the proposed TGNN model. The improved performance of TGNN is due to exploiting the temporal information and the residual blocks that allow dynamic tuning of the parameters during training. Finally, the F1 score and the false alarm rate for the proposed TGNN model is 100% and 0.00% for FDIA and 99.98% and 0.02% for ramp attacks, respectively. The F1 score and FA of GNN model for FDIAs is 100% and 0.00%, subsequently. However, TGNN can facilitate the detection and locating of ramp attacks that cannot be detected by the baseline GNN model.Fig. 6. Sensitivity analyses of GNN model for FDIA detection in terms of accuracy for various intensities of attack, |x \u2032 |.-0.02 \n-0.015 \n-0.01 \n-0.005 \n0 \n0.005 \n0.01 \n0.015 \n0.02 \n\nX \n\n99.2 \n\n99.3 \n\n99.4 \n\n99.5 \n\n99.6 \n\n99.7 \n\n99.8 \n\n99.9 \n\n100 \n\nAccuracy(%) \n\n\n\nA PMU-Based Data-Driven Approach for Enhancing Situational Awareness in Building A Resilient Power Systems. S Das, B K Panigrahi, IEEE Transactions on Industrial Informatics. 187S.Das,B.K.Panigrahi,\"A PMU-Based Data-Driven Approach for Enhanc- ing Situational Awareness in Building A Resilient Power Systems\" in IEEE Transactions on Industrial Informatics, vol.18,no.7,pp.4773- 4784,July2022.\n\nFalse data injection attacks against state estimation in electric power grids. Y Liu, P Ning, M K Reiter, ACM Transactions on Information and System Security. 141Y.Liu,P.Ning,M.K.Reiter,\"False data injection attacks against state esti- mation in electric power grids\" in ACM Transactions on Information and System Security,vol.14,no.1,Jun 2011.\n\nA Survey on the Detection Algorithms for False Data Injection Attacks in Smart Grids. A S Musleh, G Chen, Z Y Dong, IEEE Transactions on Smart Grid. 113A.S.Musleh,G.Chen,Z.Y.Dong,\"A Survey on the Detection Algorithms for False Data Injection Attacks in Smart Grids\" in IEEE Transactions on Smart Grid,vol.11,no.3,pp.2218-2234,May 2020.\n\nA Graph Signal Processing Framework for Detecting and Locating Cyber and Physical Stresses in Smart Grids. M A Hasnat, M Rahnamay-Naeini, IEEE Transactions on Smart Grid. 13M.A.Hasnat,M.Rahnamay-Naeini,\"A Graph Signal Processing Frame- work for Detecting and Locating Cyber and Physical Stresses in Smart Grids,\" in IEEE Transactions on Smart Grid,vol.13,no.5,pp.3688- 3699,Sept.2022.\n\nCan Predictive Filters Detect Gradually Ramping False Data Injection Attacks Against PMUs. Z Chu, A Pinceti, R S Biswas, O Kosut, A Pal, L Sankar, IEEE International Conference on Communications,Control,and Computing Technologies for Smart Grids (SmartGridComm). Z.Chu,A.Pinceti,R.S.Biswas,O.Kosut,A.Pal,L.Sankar,\"Can Predictive Filters Detect Gradually Ramping False Data Injection Attacks Against PMUs?\" IEEE International Conference on Communications,Control,and Computing Technologies for Smart Grids (SmartGridComm),2019,pp.1-6.\n\nDetecting and locating cyber and physical stresses in smart grids using the k-nearest neighbour analysis of instantaneous correlation of state. M A Hasnat, M Rahnamay-Naeini, IET Smart Grid. 43M.A.Hasnat,M.Rahnamay-Naeini,\"Detecting and locating cyber and physical stresses in smart grids using the k-nearest neighbour analysis of instantaneous correlation of state\" in IET Smart Grid,vol4,no.3,March 2021.\n\nGrid-Graph Signal Processing (Grid-GSP): A Graph Signal Processing Framework for the Power Grid. R Ramakrishna, A Scaglione, IEEE Transactions on Signal Processing. 69R. Ramakrishna and A. Scaglione, \"Grid-Graph Signal Processing (Grid- GSP): A Graph Signal Processing Framework for the Power Grid,\" in IEEE Transactions on Signal Processing, vol. 69, pp. 2725-2739, 2021.\n\nGraph Signal Processing: Overview, Challenges, and Applications. A Ortega, P Frossard, J Kova\u010devi\u0107, J M F Moura, P Vandergheynst, Proceedings of the IEEE. the IEEE106A.Ortega,P.Frossard,J.Kova\u010devi\u0107,J.M.F.Moura,P.Vandergheynst,\"Graph Signal Processing: Overview, Challenges, and Applications\" in Proceedings of the IEEE,vol.106,no.5,pp.808-828,May 2018.\n\nState Estimation in Smart Grids Using Temporal Graph Convolution Networks. M J Hossain, M Rahnamay-Naeini, North American Power Symposium(NAPS),2021. M.J.Hossain,M.Rahnamay-Naeini,\"State Estimation in Smart Grids Us- ing Temporal Graph Convolution Networks\",North American Power Symposium(NAPS),2021,pp.01-05.\n\nJoint Detection and Localization of Stealth False Data Injection Attacks in Smart Grids Using Graph Neural Networks. O Boyaci, M R Narimani, K R Davis, M Ismail, T J Overbye, E Serpedin, IEEE Transactions on Smart Grid. 13O.Boyaci,M.R.Narimani,K.R.Davis,M.Ismail,T.J.Overbye,E.Serpedin,\"Joint Detection and Localization of Stealth False Data Injection Attacks in Smart Grids Using Graph Neural Networks,\" in IEEE Transactions on Smart Grid,vol.13,no.1,pp.807-819,Jan.2022.\n\nGraph Neural Networks Based Detection of Stealth False Data Injection Attacks in Smart Grids. O Boyaci, IEEE Systems Journal. 162O.Boyaci et al.,\"Graph Neural Networks Based Detection of Stealth False Data Injection Attacks in Smart Grids,\" in IEEE Systems Journal,vol.16,no.2,pp.2946-2957,June 2022.\n\nDetecting False Data Injection Attacks in Smart Grids:A Semi-Supervised Deep Learning Approach. Y Zhang, J Wang, B Chen, IEEE Transactions on Smart Grid. 121Y.Zhang,J.Wang,B.Chen,\"Detecting False Data Injection Attacks in Smart Grids:A Semi-Supervised Deep Learning Approach,\" in IEEE Transactions on Smart Grid,vol.12,no.1,pp.623-634, Jan.2021.\n\nDetection of False Data Injection Attacks in Smart Grids Based on Graph Signal Processing. E Drayer, T Routtenberg, IEEE Systems Journal. 142E.Drayer,T.Routtenberg,\"Detection of False Data Injection Attacks in Smart Grids Based on Graph Signal Processing,\" in IEEE Systems Journal,vol.14,no.2,pp.1886-1896,June2020.\n\nA Comprehensive Survey on Graph Neural Networks. Z Wu, S Pan, F Chen, G Long, C Zhang, P S Yu, IEEE Transactions on Neural Networks and Learning Systems. 32Z.Wu,S.Pan,F.Chen,G.Long,C.Zhang,P.S.Yu,\"A Comprehensive Survey on Graph Neural Networks,\" in IEEE Transactions on Neural Networks and Learning Systems,vol.32,no.1,pp.4-24,Jan.2021.\n\nLearning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation. K Cho, arXiv:1406.1078v3in arxivK.Choet. al.,\"Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation,\" in arxiv,arXiv:1406.1078v3,2014.\n\nIEEE 118-Bus System,Illinois Center for a Smarter Electric Grid(ICSEG). IEEE 118-Bus System,Illinois Center for a Smarter Electric Grid(ICSEG),https://icseg.iti.illinois.edu/ieee-118-bus-system/,accessed July 15,2022.\n\nMATPOWER:Steady-State Operations,Planning,and Analysis Tools for Power Systems Research and Education. R D Zimmerman, C E Murillo-S\u00e1nchez, R J Thomas, IEEE Transactions on Power Systems. 26R.D.Zimmerman,C.E.Murillo-S\u00e1nchez,R.J.Thomas,\"MATPOWER:Steady- State Operations,Planning,and Analysis Tools for Power Systems Research and Education,\" in IEEE Transactions on Power Systems,vol.26,no.1,pp.12-19,Feb.2011.\n\nNew York Independent System Operator. Load DataLoad Data,New York Independent System Operator,https://www.nyiso.com/load-data,accessed September 9,2022.\n\nIncorporating Nesterov Momentum into Adam. T Dozat, T. Dozat,Incorporating Nesterov Momentum into Adam,2016.\n\nAn overview of gradient descent optimization algorithms. S Ruder, 10.48550/arxiv.1609.04747S.Ruder,An overview of gradient descent optimization algorithms,https://doi.org/10.48550/arxiv.1609.04747,2016.\n", "annotations": {"author": "[{\"end\":261,\"start\":104},{\"end\":364,\"start\":262},{\"end\":433,\"start\":365}]", "publisher": null, "author_last_name": "[{\"end\":126,\"start\":116},{\"end\":275,\"start\":269},{\"end\":375,\"start\":369}]", "author_first_name": "[{\"end\":109,\"start\":104},{\"end\":115,\"start\":110},{\"end\":268,\"start\":264},{\"end\":368,\"start\":365}]", "author_affiliation": "[{\"end\":260,\"start\":157},{\"end\":363,\"start\":292},{\"end\":432,\"start\":393}]", "title": "[{\"end\":91,\"start\":1},{\"end\":524,\"start\":434}]", "venue": null, "abstract": "[{\"end\":1482,\"start\":536}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":1894,\"start\":1891},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2915,\"start\":2912},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2920,\"start\":2917},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2973,\"start\":2970},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":2978,\"start\":2975},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3320,\"start\":3317},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":3325,\"start\":3322},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":3513,\"start\":3510},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":3653,\"start\":3650},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":3659,\"start\":3655},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":4653,\"start\":4650},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":5378,\"start\":5375},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":5412,\"start\":5409},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":5417,\"start\":5414},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":5705,\"start\":5702},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":5734,\"start\":5730},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":5762,\"start\":5759},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":6569,\"start\":6566},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":6574,\"start\":6571},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":6580,\"start\":6576},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":6620,\"start\":6616},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":6626,\"start\":6622},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":6839,\"start\":6836},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":6844,\"start\":6841},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":6850,\"start\":6846},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":6929,\"start\":6926},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":7622,\"start\":7618},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":7628,\"start\":7624},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":7982,\"start\":7978},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":9799,\"start\":9796},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":10439,\"start\":10436},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":11094,\"start\":11091},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":12562,\"start\":12558},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":13844,\"start\":13840},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":17045,\"start\":17041},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":17051,\"start\":17047},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":17267,\"start\":17263},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":17273,\"start\":17269},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":18056,\"start\":18052},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":18084,\"start\":18080},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":18218,\"start\":18214},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":18238,\"start\":18235},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":18324,\"start\":18320},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":18330,\"start\":18326}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":22777,\"start\":22678},{\"attributes\":{\"id\":\"fig_1\"},\"end\":22906,\"start\":22778},{\"attributes\":{\"id\":\"fig_2\"},\"end\":23047,\"start\":22907},{\"attributes\":{\"id\":\"fig_3\"},\"end\":23195,\"start\":23048},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":24774,\"start\":23196}]", "paragraph": "[{\"end\":2076,\"start\":1501},{\"end\":3114,\"start\":2078},{\"end\":4438,\"start\":3116},{\"end\":5098,\"start\":4440},{\"end\":8276,\"start\":5119},{\"end\":9173,\"start\":8321},{\"end\":10041,\"start\":9199},{\"end\":10214,\"start\":10105},{\"end\":11380,\"start\":10216},{\"end\":11892,\"start\":11426},{\"end\":13144,\"start\":11918},{\"end\":15562,\"start\":13146},{\"end\":16028,\"start\":15604},{\"end\":16568,\"start\":16030},{\"end\":17887,\"start\":16592},{\"end\":19358,\"start\":17944},{\"end\":20370,\"start\":19405},{\"end\":21515,\"start\":20372},{\"end\":21677,\"start\":21557},{\"end\":22553,\"start\":21695},{\"end\":22677,\"start\":22555}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":10104,\"start\":10042},{\"attributes\":{\"id\":\"formula_1\"},\"end\":11425,\"start\":11381},{\"attributes\":{\"id\":\"formula_2\"},\"end\":15603,\"start\":15563}]", "table_ref": null, "section_header": "[{\"end\":1499,\"start\":1484},{\"end\":5117,\"start\":5101},{\"end\":8295,\"start\":8279},{\"end\":8319,\"start\":8298},{\"end\":9197,\"start\":9176},{\"end\":11916,\"start\":11895},{\"end\":16590,\"start\":16571},{\"end\":17901,\"start\":17890},{\"end\":17942,\"start\":17904},{\"end\":19403,\"start\":19361},{\"end\":21555,\"start\":21518},{\"end\":21693,\"start\":21680},{\"end\":22687,\"start\":22679},{\"end\":22787,\"start\":22779},{\"end\":22916,\"start\":22908},{\"end\":23057,\"start\":23049}]", "table": "[{\"end\":24774,\"start\":24634}]", "figure_caption": "[{\"end\":22777,\"start\":22689},{\"end\":22906,\"start\":22789},{\"end\":23047,\"start\":22918},{\"end\":23195,\"start\":23059},{\"end\":24634,\"start\":23198}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":12418,\"start\":12413},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":20126,\"start\":20120},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":21112,\"start\":21106},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":21427,\"start\":21421}]", "bib_author_first_name": "[{\"end\":24885,\"start\":24884},{\"end\":24892,\"start\":24891},{\"end\":24894,\"start\":24893},{\"end\":25250,\"start\":25249},{\"end\":25257,\"start\":25256},{\"end\":25265,\"start\":25264},{\"end\":25267,\"start\":25266},{\"end\":25603,\"start\":25602},{\"end\":25605,\"start\":25604},{\"end\":25615,\"start\":25614},{\"end\":25623,\"start\":25622},{\"end\":25625,\"start\":25624},{\"end\":25961,\"start\":25960},{\"end\":25963,\"start\":25962},{\"end\":25973,\"start\":25972},{\"end\":26331,\"start\":26330},{\"end\":26338,\"start\":26337},{\"end\":26349,\"start\":26348},{\"end\":26351,\"start\":26350},{\"end\":26361,\"start\":26360},{\"end\":26370,\"start\":26369},{\"end\":26377,\"start\":26376},{\"end\":26919,\"start\":26918},{\"end\":26921,\"start\":26920},{\"end\":26931,\"start\":26930},{\"end\":27280,\"start\":27279},{\"end\":27295,\"start\":27294},{\"end\":27622,\"start\":27621},{\"end\":27632,\"start\":27631},{\"end\":27644,\"start\":27643},{\"end\":27657,\"start\":27656},{\"end\":27661,\"start\":27658},{\"end\":27670,\"start\":27669},{\"end\":27986,\"start\":27985},{\"end\":27988,\"start\":27987},{\"end\":27999,\"start\":27998},{\"end\":28339,\"start\":28338},{\"end\":28349,\"start\":28348},{\"end\":28351,\"start\":28350},{\"end\":28363,\"start\":28362},{\"end\":28365,\"start\":28364},{\"end\":28374,\"start\":28373},{\"end\":28384,\"start\":28383},{\"end\":28386,\"start\":28385},{\"end\":28397,\"start\":28396},{\"end\":28790,\"start\":28789},{\"end\":29094,\"start\":29093},{\"end\":29103,\"start\":29102},{\"end\":29111,\"start\":29110},{\"end\":29436,\"start\":29435},{\"end\":29446,\"start\":29445},{\"end\":29711,\"start\":29710},{\"end\":29717,\"start\":29716},{\"end\":29724,\"start\":29723},{\"end\":29732,\"start\":29731},{\"end\":29740,\"start\":29739},{\"end\":29749,\"start\":29748},{\"end\":29751,\"start\":29750},{\"end\":30096,\"start\":30095},{\"end\":30594,\"start\":30593},{\"end\":30596,\"start\":30595},{\"end\":30609,\"start\":30608},{\"end\":30611,\"start\":30610},{\"end\":30630,\"start\":30629},{\"end\":30632,\"start\":30631},{\"end\":31098,\"start\":31097},{\"end\":31222,\"start\":31221}]", "bib_author_last_name": "[{\"end\":24889,\"start\":24886},{\"end\":24904,\"start\":24895},{\"end\":25254,\"start\":25251},{\"end\":25262,\"start\":25258},{\"end\":25274,\"start\":25268},{\"end\":25612,\"start\":25606},{\"end\":25620,\"start\":25616},{\"end\":25630,\"start\":25626},{\"end\":25970,\"start\":25964},{\"end\":25989,\"start\":25974},{\"end\":26335,\"start\":26332},{\"end\":26346,\"start\":26339},{\"end\":26358,\"start\":26352},{\"end\":26367,\"start\":26362},{\"end\":26374,\"start\":26371},{\"end\":26384,\"start\":26378},{\"end\":26928,\"start\":26922},{\"end\":26947,\"start\":26932},{\"end\":27292,\"start\":27281},{\"end\":27305,\"start\":27296},{\"end\":27629,\"start\":27623},{\"end\":27641,\"start\":27633},{\"end\":27654,\"start\":27645},{\"end\":27667,\"start\":27662},{\"end\":27684,\"start\":27671},{\"end\":27996,\"start\":27989},{\"end\":28015,\"start\":28000},{\"end\":28346,\"start\":28340},{\"end\":28360,\"start\":28352},{\"end\":28371,\"start\":28366},{\"end\":28381,\"start\":28375},{\"end\":28394,\"start\":28387},{\"end\":28406,\"start\":28398},{\"end\":28797,\"start\":28791},{\"end\":29100,\"start\":29095},{\"end\":29108,\"start\":29104},{\"end\":29116,\"start\":29112},{\"end\":29443,\"start\":29437},{\"end\":29458,\"start\":29447},{\"end\":29714,\"start\":29712},{\"end\":29721,\"start\":29718},{\"end\":29729,\"start\":29725},{\"end\":29737,\"start\":29733},{\"end\":29746,\"start\":29741},{\"end\":29754,\"start\":29752},{\"end\":30100,\"start\":30097},{\"end\":30606,\"start\":30597},{\"end\":30627,\"start\":30612},{\"end\":30639,\"start\":30633},{\"end\":31104,\"start\":31099},{\"end\":31228,\"start\":31223}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":246522904},\"end\":25168,\"start\":24776},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":838905},\"end\":25514,\"start\":25170},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":209777546},\"end\":25851,\"start\":25516},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":249028651},\"end\":26237,\"start\":25853},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":146808396},\"end\":26772,\"start\":26239},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":233688952},\"end\":27180,\"start\":26774},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":232170541},\"end\":27554,\"start\":27182},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":207023804},\"end\":27908,\"start\":27556},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":245594815},\"end\":28219,\"start\":27910},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":233393985},\"end\":28693,\"start\":28221},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":233025445},\"end\":28995,\"start\":28695},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":226634128},\"end\":29342,\"start\":28997},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":54018222},\"end\":29659,\"start\":29344},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":57375753},\"end\":29998,\"start\":29661},{\"attributes\":{\"doi\":\"arXiv:1406.1078v3\",\"id\":\"b14\"},\"end\":30269,\"start\":30000},{\"attributes\":{\"id\":\"b15\"},\"end\":30488,\"start\":30271},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":11160018},\"end\":30898,\"start\":30490},{\"attributes\":{\"id\":\"b17\"},\"end\":31052,\"start\":30900},{\"attributes\":{\"id\":\"b18\"},\"end\":31162,\"start\":31054},{\"attributes\":{\"doi\":\"10.48550/arxiv.1609.04747\",\"id\":\"b19\"},\"end\":31366,\"start\":31164}]", "bib_title": "[{\"end\":24882,\"start\":24776},{\"end\":25247,\"start\":25170},{\"end\":25600,\"start\":25516},{\"end\":25958,\"start\":25853},{\"end\":26328,\"start\":26239},{\"end\":26916,\"start\":26774},{\"end\":27277,\"start\":27182},{\"end\":27619,\"start\":27556},{\"end\":27983,\"start\":27910},{\"end\":28336,\"start\":28221},{\"end\":28787,\"start\":28695},{\"end\":29091,\"start\":28997},{\"end\":29433,\"start\":29344},{\"end\":29708,\"start\":29661},{\"end\":30591,\"start\":30490}]", "bib_author": "[{\"end\":24891,\"start\":24884},{\"end\":24906,\"start\":24891},{\"end\":25256,\"start\":25249},{\"end\":25264,\"start\":25256},{\"end\":25276,\"start\":25264},{\"end\":25614,\"start\":25602},{\"end\":25622,\"start\":25614},{\"end\":25632,\"start\":25622},{\"end\":25972,\"start\":25960},{\"end\":25991,\"start\":25972},{\"end\":26337,\"start\":26330},{\"end\":26348,\"start\":26337},{\"end\":26360,\"start\":26348},{\"end\":26369,\"start\":26360},{\"end\":26376,\"start\":26369},{\"end\":26386,\"start\":26376},{\"end\":26930,\"start\":26918},{\"end\":26949,\"start\":26930},{\"end\":27294,\"start\":27279},{\"end\":27307,\"start\":27294},{\"end\":27631,\"start\":27621},{\"end\":27643,\"start\":27631},{\"end\":27656,\"start\":27643},{\"end\":27669,\"start\":27656},{\"end\":27686,\"start\":27669},{\"end\":27998,\"start\":27985},{\"end\":28017,\"start\":27998},{\"end\":28348,\"start\":28338},{\"end\":28362,\"start\":28348},{\"end\":28373,\"start\":28362},{\"end\":28383,\"start\":28373},{\"end\":28396,\"start\":28383},{\"end\":28408,\"start\":28396},{\"end\":28799,\"start\":28789},{\"end\":29102,\"start\":29093},{\"end\":29110,\"start\":29102},{\"end\":29118,\"start\":29110},{\"end\":29445,\"start\":29435},{\"end\":29460,\"start\":29445},{\"end\":29716,\"start\":29710},{\"end\":29723,\"start\":29716},{\"end\":29731,\"start\":29723},{\"end\":29739,\"start\":29731},{\"end\":29748,\"start\":29739},{\"end\":29756,\"start\":29748},{\"end\":30102,\"start\":30095},{\"end\":30608,\"start\":30593},{\"end\":30629,\"start\":30608},{\"end\":30641,\"start\":30629},{\"end\":31106,\"start\":31097},{\"end\":31230,\"start\":31221}]", "bib_venue": "[{\"end\":27719,\"start\":27711},{\"end\":24949,\"start\":24906},{\"end\":25327,\"start\":25276},{\"end\":25663,\"start\":25632},{\"end\":26022,\"start\":25991},{\"end\":26500,\"start\":26386},{\"end\":26963,\"start\":26949},{\"end\":27345,\"start\":27307},{\"end\":27709,\"start\":27686},{\"end\":28058,\"start\":28017},{\"end\":28439,\"start\":28408},{\"end\":28819,\"start\":28799},{\"end\":29149,\"start\":29118},{\"end\":29480,\"start\":29460},{\"end\":29813,\"start\":29756},{\"end\":30093,\"start\":30000},{\"end\":30341,\"start\":30271},{\"end\":30675,\"start\":30641},{\"end\":30936,\"start\":30900},{\"end\":31095,\"start\":31054},{\"end\":31219,\"start\":31164}]"}}}, "year": 2023, "month": 12, "day": 17}