{"id": 246485605, "updated": "2023-10-05 17:16:39.29", "metadata": {"title": "PromptSource: An Integrated Development Environment and Repository for Natural Language Prompts", "authors": "[{\"first\":\"Stephen\",\"last\":\"Bach\",\"middle\":[]},{\"first\":\"Victor\",\"last\":\"Sanh\",\"middle\":[]},{\"first\":\"Zheng Xin\",\"last\":\"Yong\",\"middle\":[]},{\"first\":\"Albert\",\"last\":\"Webson\",\"middle\":[]},{\"first\":\"Colin\",\"last\":\"Raffel\",\"middle\":[]},{\"first\":\"Nihal V.\",\"last\":\"Nayak\",\"middle\":[]},{\"first\":\"Abheesht\",\"last\":\"Sharma\",\"middle\":[]},{\"first\":\"Taewoon\",\"last\":\"Kim\",\"middle\":[]},{\"first\":\"M Saiful\",\"last\":\"Bari\",\"middle\":[]},{\"first\":\"Thibault\",\"last\":\"Fevry\",\"middle\":[]},{\"first\":\"Zaid\",\"last\":\"Alyafeai\",\"middle\":[]},{\"first\":\"Manan\",\"last\":\"Dey\",\"middle\":[]},{\"first\":\"Andrea\",\"last\":\"Santilli\",\"middle\":[]},{\"first\":\"Zhiqing\",\"last\":\"Sun\",\"middle\":[]},{\"first\":\"Srulik\",\"last\":\"Ben-david\",\"middle\":[]},{\"first\":\"Canwen\",\"last\":\"Xu\",\"middle\":[]},{\"first\":\"Gunjan\",\"last\":\"Chhablani\",\"middle\":[]},{\"first\":\"Han\",\"last\":\"Wang\",\"middle\":[]},{\"first\":\"Jason\",\"last\":\"Fries\",\"middle\":[]},{\"first\":\"Maged\",\"last\":\"Al-shaibani\",\"middle\":[]},{\"first\":\"Shanya\",\"last\":\"Sharma\",\"middle\":[]},{\"first\":\"Urmish\",\"last\":\"Thakker\",\"middle\":[]},{\"first\":\"Khalid\",\"last\":\"Almubarak\",\"middle\":[]},{\"first\":\"Xiangru\",\"last\":\"Tang\",\"middle\":[]},{\"first\":\"Dragomir\",\"last\":\"Radev\",\"middle\":[]},{\"first\":\"Mike Tian-jian\",\"last\":\"Jiang\",\"middle\":[]},{\"first\":\"Alexander\",\"last\":\"Rush\",\"middle\":[]}]", "venue": "ACL", "journal": "Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: System Demonstrations", "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "PromptSource is a system for creating, sharing, and using natural language prompts. Prompts are functions that map an example from a dataset to a natural language input and target output. Using prompts to train and query language models is an emerging area in NLP that requires new tools that let users develop and refine these prompts collaboratively. PromptSource addresses the emergent challenges in this new setting with (1) a templating language for defining data-linked prompts, (2) an interface that lets users quickly iterate on prompt development by observing outputs of their prompts on many examples, and (3) a community-driven set of guidelines for contributing new prompts to a common pool. Over 2,000 prompts for roughly 170 datasets are already available in PromptSource. PromptSource is available at https://github.com/bigscience-workshop/promptsource.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2202.01279", "mag": null, "acl": "2022.acl-demo.9", "pubmed": null, "pubmedcentral": null, "dblp": "conf/acl/BachSYWRNSKBFAD22", "doi": "10.18653/v1/2022.acl-demo.9"}}, "content": {"source": {"pdf_hash": "b806777771cc500d6e434eeef6160f57e0071cdf", "pdf_src": "ACL", "pdf_uri": "[\"https://www.aclanthology.org/2022.acl-demo.9.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "afa8cabefeab0456a29cdf5d45cdfa1ea25e2b38", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/b806777771cc500d6e434eeef6160f57e0071cdf.txt", "contents": "\nPromptSource: An Integrated Development Environment and Repository for Natural Language Prompts\nMay 22-27, 2022\n\nStephen H Bach \nBrown University\n\n\nVictor Sanh \nBrown University\n\n\nZheng-Xin Yong \nBrown University\n\n\nAlbert Webson \nBrown University\n\n\nColin Raffel \nBrown University\n\n\nNihal V Nayak \nBrown University\n\n\nAbheesht Sharma \nBrown University\n\n\nTaewoon Kim \nBrown University\n\n\nM Saiful \nBrown University\n\n\nBari \nBrown University\n\n\nThibault Fevry \nBrown University\n\n\nZaid Alyafeai \nBrown University\n\n\nManan Dey \nBrown University\n\n\nAndrea Santilli \nBrown University\n\n\nZhiqing Sun \nBrown University\n\n\nSrulik Ben-David \nBrown University\n\n\nCanwen Xu \nBrown University\n\n\nGunjan Chhablani \nBrown University\n\n\nHan Wang \nBrown University\n\n\nJason Alan Fries \nBrown University\n\n\nMaged S Al-Shaibani \nBrown University\n\n\nShanya Sharma \nBrown University\n\n\nUrmish Thakker \nBrown University\n\n\nKhalid Almubarak \nBrown University\n\n\nXiangru Tang \nBrown University\n\n\nDragomir Radev \nBrown University\n\n\nMike Tian \nBrown University\n\n\nJian Jiang \nBrown University\n\n\nAlexander M Rush \nBrown University\n\n\nPromptSource: An Integrated Development Environment and Repository for Natural Language Prompts\n\nProceedings of the 60th Annual Meeting of the Association for Computational Linguistics System Demonstrations\nthe 60th Annual Meeting of the Association for Computational Linguistics System DemonstrationsMay 22-27, 202218 PSAU 19 Yale University 20 ZEALS * Equal Contribution\nPromptSource is a system for creating, sharing, and using natural language prompts. Prompts are functions that map an example from a dataset to a natural language input and target output. Using prompts to train and query language models is an emerging area in NLP that requires new tools that let users develop and refine these prompts collaboratively. PromptSource addresses the emergent challenges in this new setting with (1) a templating language for defining data-linked prompts, (2) an interface that lets users quickly iterate on prompt development by observing outputs of their prompts on many examples, and (3) a community-driven set of guidelines for contributing new prompts to a common pool. Over 2,000 prompts for roughly 170 datasets are already available in PromptSource. Prompt-Source is available at https://github. com/bigscience-workshop/ promptsource.\n\nIntroduction\n\nPrompt engineering is emerging as a new focus in NLP, particularly in zero-and few-shot learning settings. Prompting is the practice of representing a task as a natural language utterance in order to query a language model for a response . For example, if a language model is conditioned on the text \"She hit a home run. The previous sentence is about ...\", then the model's subsequent generation would be interpreted as a prediction of the topic of the preceding sentence, e.g. by mapping a response such as \"sports\" to a class label. In specific contexts, prompting has been shown to have advantages over traditional classification, for example facilitating adaptation of language models to ad-hoc tasks and improving sample efficiency in low-data settings (Brown et al., 2020;Schick and Sch\u00fctze, 2021b;Le Scao and Rush, 2021;Gao et al., 2021). These advantages motivate a practical challenge: How can we enable users to create, refine, and share prompts?\n\nThe process of prompt engineering is critical for successful deployment as choices in prompting can affect downstream predictions significantly, particularly in the zero-shot setting (Perez et al., 2021;Zhao et al., 2021;Webson and Pavlick, 2021). Furthermore, training directly on collections of prompts can enable large models to generalize to new prompts more robustly (Sanh et al., 2021;Wei et al., 2021;Min et al., 2021;Mishra et al., 2021). There is therefore a growing need for tools that support the creation of corpora of prompts.\n\nPromptSource is an integrated development environment and repository for natural language prompts to use in the context of zero-shot (or gradient-based few-shot) learning. It provides a Web-based GUI that enables developers to write prompts in a templating language and immediately view their outputs on different examples. The system is integrated with the HuggingFace Datasets library (Lhoest et al., 2021), so that users can load any dataset automatically, browse existing prompts, and create new ones. Through the course of writing thousands of prompts, we converged on three key 93 aspects to the design of PromptSource:\n\n\u2022 Flexible Templating Language. We adapt a templating language to represent prompts. Prompt authors can define prompts in terms of dataset fields, hard-coded text, and simple control logic. This choice provides the flexibility of a programming environment without the mental overhead of having to write and read arbitrary code. Prompt templates can easily be distributed and used in other systems. \u2022 Tools for Prompt Management. Prompt-Source has multiple view to address the needs of prompt authors at different stages of the prompt engineering cycle. A global view lets authors browse datasets and existing prompt templates. A local view facilitates iteration on prompt wording and metadata, as well as testing on individual examples. \u2022 Community-Driven Quality Standards.\n\nPromptSource includes a set of guidelines for prompting based on a large-scale prompt writing pilot. PromptSource's collection is meant to be useful for a wide range of research, based on iterative refinement of a set of quality standards. Prompts in PromptSource are also annotated with various pieces of metadata to make finding and using prompts easier. The PromptSource system includes over 2,000 open-source prompts for roughly 170 datasets, which have all been reviewed to meet the quality standards. This collection, which we call the Public Pool of Prompts (P3), allows users to materialize prompted forms of datasets for hundreds of different tasks. The T0 series of models (Sanh et al., 2021) for zero-shot inference were fine-tuned on a subset of P3. Since then, PromptSource and P3 have been extended for research on multi-lingual prompting (Lin et al., 2021) and priming, i.e., incontext few-shot learning (Min et al., 2021). The PromptSource system and associated content is a first step in the study of systems for prompt engineering, an area that is likely to continue to grow.\n\n\nBackground and Related Work\n\nPromptSource builds on recent work in prompting and prompt engineering. It is also related to work on systems for other types of annotations. Prompting Recently, prompting has emerged as a new focus within NLP as it can dramatically improve language models' few-shot and zeroshot performance in a wide range of downstream tasks (Brown et al., 2020;Schick and Sch\u00fctze, 2021a;Sanh et al., 2021;Wei et al., 2021). Prompts and prompt engineering come in several varieties . PromptSource is focused on facilitating research with human-written prompts, in which natural language is the medium for describing tasks. This approach has the advantage that prompts can be understood, modified, and applied without being tied to a specific model. In contrast, past work has also aimed to automatically construct prompts by framing the search for a good prompt as a learning problem. These prompts can either be expressed in natural language (Gao et al., 2021;Shin et al., 2020) or as arbitrary vectors (a.k.a. \"continuous\" or \"soft\" prompts) not corresponding to words in the model's original vocabulary (Lester et al., 2021;Qin and Eisner, 2021) When using human-written prompts, there are several possible approaches to learning. One is a zero-shot setting, where the goal is to generalize to prompts for which no training examples are given. Prompts can also be used in a few-shot setting, in which a model is either (1) trained on prompted examples of the target task via gradient updates, or (2) priming (i.e. in-context learning), in which labeled examples are included in an input sequence in order to prime models to make predictions without gradient updates (Brown et al., 2020).\n\nPromptSource was originally designed for zeroshot learning, so it emphasizes explicit task instructions and no priming examples. If needed, users can extend PromptSource for few-shot learning (e.g., as done in Lin et al., 2021 andMin et al., 2021, described in \u00a77).\n\nSystems for Annotating Data Most work on collecting annotations has focused on labels and other annotations at the level of individual examples (Neves and \u0160eva, 2021). GATE (Cunningham et al., 2002) was an early system for annotating text, and includes support for many data types such as labels and entity tags. Since then, many Webbased systems for annotating text have been developed (Stenetorp et al., 2012;Salgado et al., 2012;Wei et al., 2013;Yimam et al., 2013;Chen and Styler, 2013;Eckart de Castilho et al., 2016;Putra et al., 2020). Other systems support collaboration among multiple annotators (Yang et al., 2018;Stewart et al., 2019). More recently, many annotation systems have begun to incorporate learned models to improve workflow, using techniques such as active learning (Lin et al., 2019;   example recommendation (Lee et al., 2020;. These systems are possible because the annotations to be collected are labels, for which metrics like inter-annotator agreement and model confidence are available. There has also been some work on collecting annotations other than labels. AlvisAE (Papazian et al., 2012) and TreeAnnotator (Helfrich et al., 2018) support creating ontologies and other structured annotations. Prompts differ from these annotations in that they are semi-structured functions, requiring new tools for developers.\n\n\nSystem Design and Workflow\n\nCreating prompts differs from other types of data collection and annotation. We focus on three challenging aspects on which prompting differs from traditional NLP annotation:\n\n\u2022 Functions, not Labels. A single prompt is a function that maps dataset examples (dictionaries of arbitrary fields) to natural language input/target pairs. Creating a prompt is therefore more like programming than typical data annotation. How should a prompt format trade off between expressivity and simplicity? However, variation complicates quality judg-ment, and makes it impossible to apply simple metrics like inter-annotator agreement. How can multiple authors collaborate to build a high-quality corpus of prompts and associated metadata? To illustrate these distinct aspects, we start with a concrete overview of the prompt creation process of PromptSource. For this example, we imagine that a user of PromptSource is creating prompts for a natural language inference dataset, specifically SNLI (Bowman et al., 2015). The goal is to design a prompt query such that the answer can be mapped onto the SNLI classes. A prompt author can accomplish this goal with PromptSource via the following five steps (Figure 1): S1: Dataset Exploration The prompt author starts in the Browse view to read the dataset description, including linked READMEs and papers, and to browse through examples. In this case, they would see that SNLI is a dataset for natural language inference: assume a given premise sentence is true, the goal is to determine whether a hypothesis sentence is true (entailment), false (contradiction), or undetermined (neutral).\n\nS2: Prompt Writing The prompt author uses the Sourcing view to try out a prompt wording, and then adjusts it by observing prompted examples (Figure 1 middle, full example in Figures 3 and 4).\n\nS3: Prompt Documentation To facilitate using the prompt, the author fills in various metadata including possible metrics to evaluate the prompt, valid outputs if applicable, whether the prompt expresses the original intended task of the dataset, and whether the template explicitly states the valid outputs.\n\nS4: Iteration and Variation The prompt author then iterates through S2 and S3 to create multiple prompts for the dataset. Authors are encouraged to vary multiple factors such as the formulation of the prompt and the targeted task (see Section 6).\n\nS5: Global Review The author saves the draft prompts in a structured file which are then verified by other contributors through code reviews. New prompts need to meet the quality standard with a series of automatic tests and by validation through prompted instances. Upon passing review, the new prompts can be merged into a global prompts collection.\n\nUpon submission, prompts can be viewed through PromptSource by other users. The full collection is stored globally and can be used outside of the tool, for instance to be applied on an example from a dataset of the Datasets library (Lhoest et al., 2021). With this workflow in mind, we next describe the key aspects of the PromptSource system in greater detail.\n\n\nPrompting Language\n\nA key design decision is the format for prompts. Previous works on prompting tended to use code for specifying each prompt. We experimented with this format and found a trade-off between expressivity and explicit structure. On one side, a maximally expressive format such as pure Python code would let users write complex programs to manipulate the semi-structured examples into prompted examples. However, interpreting and analyzing these programs becomes difficult. This difficulty limits downstream manipulation and analysis of the prompts, for example for possible future work on automatic prompt augmentation. On the other side, a maximally structured format, such as rule-based generation, limits the kinds of prompts that users can create. We found it infeasible to enumerate types of rules sufficient for the wide range of tasks and data formats for which we wanted prompts.\n\nWe therefore settled on a middle ground between the two: a templating language. Specifically, we use the Jinja2 templating engine, 1 originally designed for producing web markup. Users write templates as prompts with placeholders, such as If {{premise}} is true, is it also true that {{hypothesis}}? ||| {{entailed}}.\n\nThe separator ||| denotes the break between the conditioning text and the desired completion. Placeholders refer to fields in the underlying example (represented as a Python dict by Datasets (Lhoest et al., 2021)). Users also have access to Jinja's built-in functions, such as manipulating strings and structured data. For each prompt, prompted examples are created by applying the prompt to all examples in the corresponding dataset. While Jinja is a complete programming language, our review guidelines encourage simple functions with minimal additional logic (see Figure 3 and 4 for example).\n\nDuring the development of PromptSource, we found that a few idioms were particularly useful. First, not all templates are applicable to all examples in a dataset. Users can wrap templates in Jinja's built-in conditional statements, and any example that results in an empty prompted example is simply skipped. Second, many examples can be used to make multiple training instances, such as a question that has multiple valid answers. We therefore added a choice function that selects an element from a list in a way that can be controlled during dataset generation, such as picking a random element using a seeded random number generator or generating different prompts for each combination of elements in the template. Third, many tasks such as classification and binary question answering have a small set of possible valid completions, and it is common to make predictions for these tasks by scoring only the valid completions and returning the highest one (Brown et al., 2020;Sanh et al., 2021;Wei et al., 2021). Users therefore can list the valid completions in a separate field and access them as a list in their prompts (displayed as Answer choices in Figure 3). These completions are then explicitly available when evaluating predictions for these prompted examples.\n\n\nThe PromptSource UI\n\nThe PromptSource system is designed to enable prompt creators to view data (S1), write prompts in a standard format (S2, S3, and S4), and ver- ify that their templates work correctly (S5). We implemented a lightweight interface for the tool in Streamlit 2 so that users could download, run locally in a web browser, and then upload their results to a central repository. Testing iterations of the interface on pilot template-writing tasks, we converged on three views for the interface. (Figure 2) lets users inspect datasets before creating prompts (S1). Once prompts are created, they can select prompts and browse the prompted examples generated by them (S5). The original example is viewed side-by-side with the resulting prompted example, with the substituted text highlighted to distinguish from text hard-coded in the template. Users can quickly scroll through many examples, verify the behavior of their prompt, and return to the sourcing view if changes are needed. (Figures 3 and 4) allows users to select a dataset to prompt, browse examples from that dataset in the form of tables, and enter a prompt for that dataset. As the user writes their template (S2, S3, and S4), every time they save it, the output of the template applied to the current example is displayed next to the editor. We also collect metadata like a name for the template, and a reference for any bibliographic information or rationale for the template.\n\n\nV1: Browse This view\n\n\nV2: Sourcing This view\n\nV3: Helicopter This view ( Figure 5) allows users to see what datasets are available for writing templates and how many are written for each, to prioritize user attention. This view is particularly useful for moving between datasets and for the prompt reviewers (S5).\n\n\nCommunity Guidelines and Process\n\nDue to the variety of existing NLP datasets, we found it challenging to exhaustively describe the characteristics of a good prompt: there are no simple metrics like inter-annotator agreement on example-level labels. Instead, over a few iterations, we converged on community guidelines 3 with three objectives in mind: (a) provide a standardized vocabulary for discussing prompts between prompt authors, reviewers and users, and minimum requirements for a valid prompt, (b) highlight common errors and best practices, (c) collect the necessary information about the prompts to support current and future research on prompt engineering. The guidelines were enforced in the use of Prompt-Source by a code review process in which each prompt was reviewed before being committed to the central repository.\n\nGuidelines apply to the combination of a template (a function that maps an example into an input/target pair in natural language) and a set of metadata about the template. The most important constraint we imposed for a template to be valid is that it is formulated in natural language (both for the input and the target). We forbid the use of non-natural language prompts such as pure code. Each prompt should clearly state what task should be solved, in a way a non-specialist adult can understand. We found this guideline strikes a good balance between freedom and expressivity in the wording of the prompts on one side and short generic prompts on the other side.\n\nIn early experiments, we found that user-written prompts that did not explicitly state the possible valid completions tended to perform worse in experiments than their counterparts in which the possible valid completions were listed. We encouraged prompt authors to explicitly state the valid outputs in some of their prompts. In addition, when working with training prompts that include target text, we found it useful to remove variations on the target format that led to spurious ambiguity. For instance, the target template should only contain the answer to the task. It should not contain any extra text such as \"The answer is ...\", which can be equivalently moved to the input template.\n\nOne of the research question we hope to enable with PromptSource is whether the diversity of the prompt formulation during training leads to models that are more robust to the prompt formulation at test time. Therefore, we encouraged prompt authors to create between 5 and 10 (or more) prompts per dataset while varying the prompt formulation. For a given dataset, authors produce multiple prompts per example, sometimes for task formulations that differed from the original dataset. For instance, for question answering dataset, one prompt can ask to extract the answer to a given question from a given passage, while a second prompt can ask to generate a potential question given an answer and a passage.\n\nAs part of the community process and to facilitate future research, PromptSource asks prompt authors to include additional metadata for each prompt. Metadata fields include a name for the prompt, a reference to the paper it was extracted from (or any relevant explanation), whether the prompt expresses the task originally intended by the dataset, the valid outputs (if relevant), whether the input template states the valid outputs, and possible metrics to evaluate the prompted examples. These can be used in future systems to evaluate how the style and structure of prompts leads to different downstream results.\n\n\nCase Studies\n\nA system for creating, maintaining, and using prompts is a key tool for supporting the emerging research area of prompting in a standardized and reproducible manner. We highlight three recent research projects for which PromptSource was a key resource. Massively multitask prompted training Sanh et al. (2021) study the question of zero-shot behaviors in large language models and ask whether zero-shot generalization can be induced by training a language model on a massively multitask mixture of prompts. To test this question, they use PromptSource to create diverse prompts for a large collection of NLP datasets. Their training and evaluation prompts are a subset of P3. This work demonstrates that PromptSource allows training a language model on a massively multitask mixture of prompted datasets and evaluating the ability of models trained with such a procedure to perform unseen tasks. Multilingual prompting Lin et al. (2021) study the zero-and few-shot learning abilities of an multilingual autoregressive language model trained on 30 languages. In particular, they are interested in the cross-lingual generalization of such models and benchmark a variety of tasks in multiple languages. PromptSource allows using a massive set of highquality English prompts. Moreover, the English prompts serve as support to create prompts in other languages (through either machine or human translation). Priming (in-context learning) Min et al. (2021) study improving models' few-shot priming performance by first fully training a model (with gradient updates) on a multitask mixture formatted with priming examples. They find that incorporating templates from P3 significantly further improves performance compared to training on priming ex- amples alone. Although PromptSource was not originally designed for this specific form of prompting, users were able to easily use P3's template collection and the templating language for their own priming methods.\n\n\nConclusion\n\nPromptSource is an open-source system for creating, sharing, and using natural language prompts and addresses the need for new collaborative and centralized tools to support the emerging research around prompting. The tool is designed to answer three key needs: a flexible template language, a suite of tools for prompt management, and community-driven quality standards. As of January 2022, PromptSource includes a growing collection of 2,000 public prompts for roughly 170 datasets, and has already been an instrumental resource for multiple recent research projects. Wei-Te Chen and Will Styler. 2013 \n\n\nA Data and Statistics\n\nP3 is the largest public collection of English prompts and is actively growing. As of January 2022, it contains 2'052 English prompts for 170 English datasets (or 269 subsets, one dataset can contain multiple subsets with different prompts).\n\nThere is an average of 7.6 prompts per data subset and an average 5.6 original-task prompts per data subset (see Figure 6). P3 was developed as part of the BigScience project for open research 5 . There was a open hackathon to collect prompts for as many English NLP dataset (or English subsets of datasets) as possible. Almost 50 unique contributors affiliated with more than 25 institutions in 10 countries participated.\n\n\nB Complete Views\n\nWe show higher resolution examples of the full interfaces for the Browse (Figure 7), Sourcing (Figure 8), and Helicopter (Figure 9) views.  \n\nFigure 1 :\n1The five stages of creating prompts in PromptSource. The Browse view for Dataset Exploration (S1). The Sourcing view for Prompt Writing (S2), Prompt Documentation (S3), and Iteration and Variation (S4). The Browse view for performing a Global Review (S5).\n\n\nfrom promptsource.templates import DatasetTemplates from datasets import load_dataset prompts = DatasetTemplates(\"snli\") prompt_key = \"based on the previous passage\" p = prompts[prompt_key] dataset = load_dataset(\"snli\", split=\"train\") example = dataset[0] result = p.apply(example) print(\"INPUT: \", result[0]) print(\"TARGET: \", result[1])\n\nFigure 2 :\n2Prompt creators can browse through the dataset examples (left-column) and their prompted form (right column) using the Browse view.\n\nFigure 3 :\n3With the Sourcing view, prompt authors can write new prompts, fill in the associated metadata, observe the result on examples, and iterate.\n\nFigure 4 :\n4Another example of the the Sourcing view, focusing on the editor. The templating language strikes a balance between expressivity and explicit structure. This prompt for QA-ZRE(Levy et al., 2017), a dataset for zero-shot relation extraction, shows how to manipulate strings and do conditional statements with Jinja.\n\nFigure 5 :\n5The Helicopter view indicates what datasets have prompts and how many prompts are available for each dataset.\n\nFigure 6 :\n6Most of the datasets have between 5 and 10 prompts.\n\nFigure 7 :\n7Complete example of the Browse view.\n\nFigure 8 : 103 Figure 9 :\n81039Complete example of the Sourcing view. Complete example of the Helicopter view.\n\n\nandS1: Exploration \n\nS2 + S3 + S4: Creation \nS5: Review \n\nBrowse \n\nSNLI \n\nThe SNLI corpus (version 1.0) is a \ncollection of 570k human-written \nEnglish sentence pairs manually \nlabeled for the task of NLI\u2026 \n\n{ premise: \n\"The kids\u2026\", \n\nhypothesis: \"All kids\u2026\", \n\nlabel: \n2 } \n\n{ premise: \n\"A person\u2026\", \n\nhypothesis: \"A person\u2026\", \n\nlabel: \n1 } \n\nSourcing \n\nSNLI \n\nBrowse \n\nSNLI \n\nThe SNLI corpus (version 1.0) is a \ncollection of 570k human-written \nEnglish sentence pairs manually \nlabeled for the task of NLI\u2026 \n\n\"The kids\u2026\" Based on the previous \npassage, is it true that \"All kids\u2026\"? \nYes, no, or maybe? ||| \nNo \n\n\"A person\u2026\" Based on the previous \npassage, is it true that \"A \nperson\u2026\"? Yes, no, or maybe? ||| \nMaybe \n\nBased\u2026 \n\nbased on the previous passage \n\n{{premise}} Based on the \nprevious passage, is it true \nthat \"{{hypothesis}}\"? \nYes, no, or maybe? ||| \n{{ answer_choices[label] }} \n\nOriginal Task \nChoices in Prompt \n\nAdapted from the BoolQ prompts in \nSchick & Sch\u00fctze 2021. \n\nYes ||| No ||| Maybe \nAccuracy \n\n\n\n\n\u2022 Dataset-Level Choices. Prompts are associated with datasets, unlike label annotations that are local to single examples. Prompt engineering requires developers to evaluate their choices across all examples. What interfaces do authors need to inspect and debug their prompts? \u2022 Variation in Prompt Construction. Unlike with labels, it is often desirable to have variation within prompt construction, as different prompt choices may lead to different results.\n\n\n. Anafora: A webbased general purpose annotation tool. In Proceedings of the 2013 NAACL HLT Demonstration Session, pages 14-19, Atlanta, Georgia. Association for Computational Linguistics. Hamish Cunningham, Diana Maynard, Kalina Bontcheva, and Valentin Tablan. 2002. GATE: an architecture for development of robust HLT applications. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 168-175, Philadelphia, Pennsylvania, USA. Association for Computational Linguistics. Richard Eckart de Castilho, \u00c9va M\u00fajdricza-Maydt, Seid Muhie Yimam, Silvana Hartmann, Iryna Gurevych, Anette Frank, and Chris Biemann. 2016. A web-based tool for the integrated annotation of semantic and syntactic structures. In Proceedings of the Workshop on Language Technology Resources and Tools for Digital Humanities (LT4DH), pages 76-84, Osaka, Japan. The COLING 2016 Organizing Committee. Tianyu Gao, Adam Fisch, and Danqi Chen. 2021. Making pre-trained language models better few-shot learners. In Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 3816-3830, Online. Association for Computational Linguistics. Philipp Helfrich, Elias Rieb, Giuseppe Abrami, Andy L\u00fccking, and Alexander Mehler. 2018. TreeAnnotator: Versatile visual annotation of hierarchical text relations. In Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018), Miyazaki, Japan. European Language Resources Association (ELRA).\nhttps://jinja.palletsprojects.com\nhttps://streamlit.io/\nComplete guidelines can be found at https: //github.com/bigscience-workshop/ promptsource/blob/main/CONTRIBUTING.md.\nhttps://bigscience.huggingface.co/\nhttps://bigscience.huggingface.co\nAcknowledgementsThis research was conducted under the BigScience project for open research, 4 a year-long initiative targeting the study of large models and datasets. The goal of the project is to research language models in a public environment outside large technology companies. The project has over 950 researchers from over 65 countries and more than 250 institutions. The BigScience project was initiated by Thomas Wolf at Hugging Face, and this collaboration would not have been possible without his effort. This research was the focus of the BigScience Prompt Engineering working group, which focused on the role of prompting in large language model training. Disclosure: Stephen Bach contributed to this work as an advisor to Snorkel AI.\nA large annotated corpus for learning natural language inference. R Samuel, Gabor Bowman, Christopher Angeli, Christopher D Potts, Manning, 10.18653/v1/D15-1075Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. the 2015 Conference on Empirical Methods in Natural Language ProcessingLisbon, PortugalAssociation for Computational LinguisticsSamuel R. Bowman, Gabor Angeli, Christopher Potts, and Christopher D. Manning. 2015. A large anno- tated corpus for learning natural language inference. In Proceedings of the 2015 Conference on Empiri- cal Methods in Natural Language Processing, pages 632-642, Lisbon, Portugal. Association for Compu- tational Linguistics.\n\nAlec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners. Tom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Advances in Neural Information Processing Systems 33: Annual Conference on Neural Information Processing Systems 2020. Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish; NeurIPSvirtualTom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. 2020. Language models are few-shot learners. In Ad- vances in Neural Information Processing Systems 33: Annual Conference on Neural Information Process- ing Systems 2020, NeurIPS 2020, December 6-12, 2020, virtual.\n\nDynabench: Rethinking benchmarking in NLP. Douwe Kiela, Max Bartolo, Yixin Nie, Divyansh Kaushik, Atticus Geiger, Zhengxuan Wu, Bertie Vidgen, Grusha Prasad, Amanpreet Singh, Pratik Ringshia, Zhiyi Ma, Tristan Thrush, Sebastian Riedel, Zeerak Waseem, Pontus Stenetorp, Robin Jia, Mohit Bansal, Christopher Potts, Adina Williams, 10.18653/v1/2021.naacl-main.324Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesOnline. Association for Computational LinguisticsDouwe Kiela, Max Bartolo, Yixin Nie, Divyansh Kaushik, Atticus Geiger, Zhengxuan Wu, Bertie Vid- gen, Grusha Prasad, Amanpreet Singh, Pratik Ring- shia, Zhiyi Ma, Tristan Thrush, Sebastian Riedel, Zeerak Waseem, Pontus Stenetorp, Robin Jia, Mohit Bansal, Christopher Potts, and Adina Williams. 2021. Dynabench: Rethinking benchmarking in NLP. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computa- tional Linguistics: Human Language Technologies, pages 4110-4124, Online. Association for Computa- tional Linguistics.\n\nHow many data points is a prompt worth?. Le Teven, Alexander Scao, Rush, 10.18653/v1/2021.naacl-main.208Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesOnline. Association for Computational LinguisticsTeven Le Scao and Alexander Rush. 2021. How many data points is a prompt worth? In Proceedings of the 2021 Conference of the North American Chap- ter of the Association for Computational Linguistics: Human Language Technologies, pages 2627-2636, Online. Association for Computational Linguistics.\n\nLEAN-LIFE: A labelefficient annotation framework towards learning from explanation. Dong-Ho Lee, Rahul Khanna, Seyeon Bill Yuchen Lin, Qinyuan Lee, Elizabeth Ye, Leonardo Boschee, Xiang Neves, Ren, 10.18653/v1/2020.acl-demos.42Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations. the 58th Annual Meeting of the Association for Computational Linguistics: System DemonstrationsOnline. Association for Computational LinguisticsDong-Ho Lee, Rahul Khanna, Bill Yuchen Lin, Seyeon Lee, Qinyuan Ye, Elizabeth Boschee, Leonardo Neves, and Xiang Ren. 2020. LEAN-LIFE: A label- efficient annotation framework towards learning from explanation. In Proceedings of the 58th Annual Meet- ing of the Association for Computational Linguistics: System Demonstrations, pages 372-379, Online. As- sociation for Computational Linguistics.\n\nThe power of scale for parameter-efficient prompt tuning. Brian Lester, Rami Al-Rfou, Noah Constant, 10.18653/v1/2021.emnlp-main.243Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. the 2021 Conference on Empirical Methods in Natural Language ProcessingOnline and Punta Cana, Dominican Republic. Association for Computational LinguisticsBrian Lester, Rami Al-Rfou, and Noah Constant. 2021. The power of scale for parameter-efficient prompt tuning. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, pages 3045-3059, Online and Punta Cana, Domini- can Republic. Association for Computational Lin- guistics.\n\nZero-shot relation extraction via reading comprehension. Omer Levy, Minjoon Seo, Eunsol Choi, Luke Zettlemoyer, 10.18653/v1/K17-1034Proceedings of the 21st Conference on Computational Natural Language Learning. the 21st Conference on Computational Natural Language LearningVancouver, CanadaAssociation for Computational LinguisticsOmer Levy, Minjoon Seo, Eunsol Choi, and Luke Zettlemoyer. 2017. Zero-shot relation extraction via reading comprehension. In Proceedings of the 21st Conference on Computational Natural Language Learning (CoNLL 2017), pages 333-342, Vancouver, Canada. Association for Computational Linguistics.\n\nDatasets: A community library for natural language processing. Quentin Lhoest, Albert Villanova Del Moral, Yacine Jernite, Abhishek Thakur, Suraj Patrick Von Platen, Julien Patil, Mariama Chaumond, Julien Drame, Lewis Plu, Joe Tunstall, Mario Davison, Gunjan \u0160a\u0161ko, Bhavitvya Chhablani, Simon Malik, Teven Le Brandeis, Victor Scao, Canwen Sanh, Nicolas Xu, Angelina Patry, Philipp Mcmillan-Major, Sylvain Schmid, Cl\u00e9ment Gugger, Delangue, 10.18653/v1/2021.emnlp-demo.21Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing: System Demonstrations. the 2021 Conference on Empirical Methods in Natural Language Processing: System DemonstrationsLysandre Debut, Stas Bekman, Pierric Cistac, Thibault Goehringer, Victor Mustar, Fran\u00e7ois Lagunas, Alexander Rush, and Thomas Wolf; Dominican RepublicAssociation for Computational LinguisticsOnline and Punta CanaQuentin Lhoest, Albert Villanova del Moral, Yacine Jernite, Abhishek Thakur, Patrick von Platen, Suraj Patil, Julien Chaumond, Mariama Drame, Julien Plu, Lewis Tunstall, Joe Davison, Mario \u0160a\u0161ko, Gun- jan Chhablani, Bhavitvya Malik, Simon Brandeis, Teven Le Scao, Victor Sanh, Canwen Xu, Nicolas Patry, Angelina McMillan-Major, Philipp Schmid, Sylvain Gugger, Cl\u00e9ment Delangue, Th\u00e9o Matus- si\u00e8re, Lysandre Debut, Stas Bekman, Pierric Cis- tac, Thibault Goehringer, Victor Mustar, Fran\u00e7ois Lagunas, Alexander Rush, and Thomas Wolf. 2021. Datasets: A community library for natural language processing. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Process- ing: System Demonstrations, pages 175-184, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.\n\nFITAnnotator: A flexible and intelligent text annotation system. Yanzeng Li, Bowen Yu, Li Quangang, Tingwen Liu, 10.18653/v1/2021.naacl-demos.5Proceedings of the 2021. the 2021Yanzeng Li, Bowen Yu, Li Quangang, and Tingwen Liu. 2021. FITAnnotator: A flexible and intelligent text annotation system. In Proceedings of the 2021\n\nConference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Demonstrations. Online. Association for Computational LinguisticsConference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Demonstrations, pages 35- 41, Online. Association for Computational Linguis- tics.\n\nAlpacaTag: An active learningbased crowd annotation framework for sequence tagging. Dong-Ho Bill Yuchen Lin, Frank F Lee, Ouyu Xu, Xiang Lan, Ren, 10.18653/v1/P19-3010Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: System Demonstrations. the 57th Annual Meeting of the Association for Computational Linguistics: System DemonstrationsFlorence, ItalyAssociation for Computational LinguisticsBill Yuchen Lin, Dong-Ho Lee, Frank F. Xu, Ouyu Lan, and Xiang Ren. 2019. AlpacaTag: An active learning- based crowd annotation framework for sequence tag- ging. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics: Sys- tem Demonstrations, pages 58-63, Florence, Italy. Association for Computational Linguistics.\n\nFew-shot learning with multilingual language models. Todor Xi Victoria Lin, Mikel Mihaylov, Tianlu Artetxe, Shuohui Wang, Daniel Chen, Myle Simig, Naman Ott, Shruti Goyal, Jingfei Bhosale, Ramakanth Du, Sam Pasunuru, Punit Shleifer, Vishrav Singh Koura, Chaudhary, O&apos; Brian, Jeff Horo, Luke Wang, Zornitsa Zettlemoyer, Mona T Kozareva, Veselin Diab, Xian Stoyanov, Li, abs/2112.10668CoRRXi Victoria Lin, Todor Mihaylov, Mikel Artetxe, Tianlu Wang, Shuohui Chen, Daniel Simig, Myle Ott, Na- man Goyal, Shruti Bhosale, Jingfei Du, Ramakanth Pasunuru, Sam Shleifer, Punit Singh Koura, Vishrav Chaudhary, Brian O'Horo, Jeff Wang, Luke Zettle- moyer, Zornitsa Kozareva, Mona T. Diab, Veselin Stoyanov, and Xian Li. 2021. Few-shot learn- ing with multilingual language models. CoRR, abs/2112.10668.\n\nPretrain, prompt, and predict: A systematic survey of prompting methods in natural language processing. Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, Graham Neubig, abs/2107.13586CoRRPengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. 2021. Pre- train, prompt, and predict: A systematic survey of prompting methods in natural language processing. CoRR, abs/2107.13586.\n\nMetaicl: Learning to learn in context. Sewon Min, Mike Lewis, Luke Zettlemoyer, Hannaneh Hajishirzi, abs/2110.15943CoRRSewon Min, Mike Lewis, Luke Zettlemoyer, and Han- naneh Hajishirzi. 2021. Metaicl: Learning to learn in context. CoRR, abs/2110.15943.\n\nSwaroop Mishra, Daniel Khashabi, arXiv:2104.08773Chitta Baral, and Hannaneh Hajishirzi. 2021. Cross-task generalization via natural language crowdsourcing instructions. arXiv preprintSwaroop Mishra, Daniel Khashabi, Chitta Baral, and Hannaneh Hajishirzi. 2021. Cross-task generaliza- tion via natural language crowdsourcing instructions. arXiv preprint arXiv:2104.08773.\n\nAn extensive review of tools for manual annotation of documents. Mariana Neves, Jurica \u0160eva, Briefings in bioinformatics. 221Mariana Neves and Jurica \u0160eva. 2021. An extensive review of tools for manual annotation of documents. Briefings in bioinformatics, 22(1):146-163.\n\nAlvisAE: a collaborative web text annotation editor for knowledge acquisition. Fr\u00e9d\u00e9ric Papazian, Robert Bossy, Claire N\u00e9dellec, Proceedings of the Sixth Linguistic Annotation Workshop. the Sixth Linguistic Annotation WorkshopJeju, Republic of KoreaAssociation for Computational LinguisticsFr\u00e9d\u00e9ric Papazian, Robert Bossy, and Claire N\u00e9dellec. 2012. AlvisAE: a collaborative web text annotation editor for knowledge acquisition. In Proceedings of the Sixth Linguistic Annotation Workshop, pages 149-152, Jeju, Republic of Korea. Association for Computational Linguistics.\n\nTrue few-shot learning with language models. Ethan Perez, Douwe Kiela, Kyunghyun Cho, NeurIPSEthan Perez, Douwe Kiela, and Kyunghyun Cho. 2021. True few-shot learning with language mod- els. NeurIPS.\n\nTIARA: A tool for annotating discourse relations and sentence reordering. Jan Wira Gotama Putra, Simone Teufel, Proceedings of the 12th Language Resources and Evaluation Conference. the 12th Language Resources and Evaluation ConferenceMarseille, FranceKana Matsumura, and Takenobu Tokunaga. European Language Resources AssociationJan Wira Gotama Putra, Simone Teufel, Kana Mat- sumura, and Takenobu Tokunaga. 2020. TIARA: A tool for annotating discourse relations and sen- tence reordering. In Proceedings of the 12th Lan- guage Resources and Evaluation Conference, pages 6912-6920, Marseille, France. European Language Resources Association.\n\nLearning how to ask: Querying LMs with mixtures of soft prompts. Guanghui Qin, Jason Eisner, 10.18653/v1/2021.naacl-main.410Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesGuanghui Qin and Jason Eisner. 2021. Learning how to ask: Querying LMs with mixtures of soft prompts. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computa- tional Linguistics: Human Language Technologies, pages 5203-5212, Online. Association for Computa- tional Linguistics.\n\nMyMiner: a web application for computer-assisted biocuration and text annotation. David Salgado, Martin Krallinger, Marc Depaule, Elodie Drula, Ashish V Tendulkar, Florian Leitner, Alfonso Valencia, Christophe Marcelle, 10.1093/bioinformatics/bts435Bioinformatics. 2817David Salgado, Martin Krallinger, Marc Depaule, Elodie Drula, Ashish V. Tendulkar, Florian Leitner, Alfonso Valencia, and Christophe Marcelle. 2012. MyMiner: a web application for computer-assisted biocuration and text annotation. Bioinformatics, 28(17):2285-2287.\n\n. Victor Sanh, Albert Webson, Colin Raffel, Stephen H Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Teven Le Scao, Arun Raja, Manan Dey, Canwen Bari, Urmish Xu, Shanya Thakker, Eliza Sharma Sharma, Taewoon Szczechla, Gunjan Kim, Nihal Chhablani, Debajyoti Nayak, Jonathan Datta, Mike Chang, Tian-Jian, Han Jiang, Matteo Wang, Sheng Manica, Shen, Zheng Xin Yong, Harshit Pandey, Rachel Bawden, Thomas Wang, Trishala Neeraj, Jos Rozen, Abheesht Sharma, Andrea Santilli, Thibault Fevry, Jason Alan Fries, Ryan TeehanStella Biderman, Leo Gao, Tali Bers, Thomas WolfRush. 2021. Multitask prompted training enables zero-shot task generalizationVictor Sanh, Albert Webson, Colin Raffel, Stephen H. Bach, Lintang Sutawika, Zaid Alyafeai, Antoine Chaffin, Arnaud Stiegler, Teven Le Scao, Arun Raja, Manan Dey, M Saiful Bari, Canwen Xu, Urmish Thakker, Shanya Sharma Sharma, Eliza Szczechla, Taewoon Kim, Gunjan Chhablani, Nihal Nayak, De- bajyoti Datta, Jonathan Chang, Mike Tian-Jian Jiang, Han Wang, Matteo Manica, Sheng Shen, Zheng Xin Yong, Harshit Pandey, Rachel Bawden, Thomas Wang, Trishala Neeraj, Jos Rozen, Abheesht Sharma, Andrea Santilli, Thibault Fevry, Jason Alan Fries, Ryan Teehan, Stella Biderman, Leo Gao, Tali Bers, Thomas Wolf, and Alexander M. Rush. 2021. Multi- task prompted training enables zero-shot task gener- alization.\n\nExploiting cloze-questions for few-shot text classification and natural language inference. Timo Schick, Hinrich Sch\u00fctze, 10.18653/v1/2021.eacl-main.20Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume. the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main VolumeTimo Schick and Hinrich Sch\u00fctze. 2021a. Exploiting cloze-questions for few-shot text classification and natural language inference. In Proceedings of the 16th Conference of the European Chapter of the Asso- ciation for Computational Linguistics: Main Volume, pages 255-269, Online. Association for Computa- tional Linguistics.\n\nIt's not just size that matters: Small language models are also fewshot learners. Timo Schick, Hinrich Sch\u00fctze, 10.18653/v1/2021.naacl-main.185Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesOnline. Association for Computational LinguisticsTimo Schick and Hinrich Sch\u00fctze. 2021b. It's not just size that matters: Small language models are also few- shot learners. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 2339-2352, Online. Association for Computational Linguistics.\n\nAutoPrompt: Eliciting Knowledge from Language Models with Automatically Generated Prompts. Taylor Shin, Yasaman Razeghi, Robert L Logan, I V , Eric Wallace, Sameer Singh, 10.18653/v1/2020.emnlp-main.346Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)Online. Association for Computational LinguisticsTaylor Shin, Yasaman Razeghi, Robert L. Logan IV, Eric Wallace, and Sameer Singh. 2020. AutoPrompt: Elic- iting Knowledge from Language Models with Auto- matically Generated Prompts. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 4222-4235, Online. Association for Computational Linguistics.\n\nbrat: a web-based tool for NLP-assisted text annotation. Pontus Stenetorp, Sampo Pyysalo, Goran Topi\u0107, Tomoko Ohta, Sophia Ananiadou, Jun&apos;ichi Tsujii, Proceedings of the Demonstrations at the 13th Conference of the European Chapter of the Association for Computational Linguistics. the Demonstrations at the 13th Conference of the European Chapter of the Association for Computational LinguisticsAvignon, FranceAssociation for Computational LinguisticsPontus Stenetorp, Sampo Pyysalo, Goran Topi\u0107, Tomoko Ohta, Sophia Ananiadou, and Jun'ichi Tsujii. 2012. brat: a web-based tool for NLP-assisted text annotation. In Proceedings of the Demonstrations at the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 102-107, Avignon, France. Association for Compu- tational Linguistics.\n\nRedcoat: A collaborative annotation tool for hierarchical entity typing. Michael Stewart, Wei Liu, Rachel Cardell-Oliver, 10.18653/v1/D19-3033Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing. the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language ProcessingHong Kong, ChinaSystem Demonstrations. Association for Computational LinguisticsMichael Stewart, Wei Liu, and Rachel Cardell-Oliver. 2019. Redcoat: A collaborative annotation tool for hierarchical entity typing. In Proceedings of the 2019 Conference on Empirical Methods in Natu- ral Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP): System Demonstrations, pages 193-198, Hong Kong, China. Association for Com- putational Linguistics.\n\nDo promptbased models really understand the meaning of their prompts? ArXiv. Albert Webson, Ellie Pavlick, abs/2109.01247Albert Webson and Ellie Pavlick. 2021. Do prompt- based models really understand the meaning of their prompts? ArXiv, abs/2109.01247.\n\nPubTator: a web-based text mining tool for assisting biocuration. Chih-Hsuan Wei, Hung-Yu Kao, Zhiyong Lu, 10.1093/nar/gkt441Nucleic Acids Research. 41W1Chih-Hsuan Wei, Hung-Yu Kao, and Zhiyong Lu. 2013. PubTator: a web-based text mining tool for assisting biocuration. Nucleic Acids Research, 41(W1):W518- W522.\n\nFinetuned language models are zero-shot learners. Jason Wei, Maarten Bosma, Y Vincent, Kelvin Zhao, Adams Wei Guu, Brian Yu, Nan Lester, Du, abs/2109.01652M. Dai, and Quoc V. Le. 2021CoRRJason Wei, Maarten Bosma, Vincent Y. Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, An- drew M. Dai, and Quoc V. Le. 2021. Finetuned language models are zero-shot learners. CoRR, abs/2109.01652.\n\nYEDDA: A lightweight collaborative text span annotation tool. Jie Yang, Yue Zhang, Linwei Li, Xingxuan Li, 10.18653/v1/P18-4006Proceedings of ACL 2018, System Demonstrations. ACL 2018, System DemonstrationsMelbourne, AustraliaAssociation for Computational LinguisticsJie Yang, Yue Zhang, Linwei Li, and Xingxuan Li. 2018. YEDDA: A lightweight collaborative text span an- notation tool. In Proceedings of ACL 2018, System Demonstrations, pages 31-36, Melbourne, Australia. Association for Computational Linguistics.\n\nWebAnno: A flexible, web-based and visually supported system for distributed annotations. Iryna Seid Muhie Yimam, Richard Gurevych, Chris Eckart De Castilho, Biemann, Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics: System Demonstrations. the 51st Annual Meeting of the Association for Computational Linguistics: System DemonstrationsSofia, BulgariaAssociation for Computational LinguisticsSeid Muhie Yimam, Iryna Gurevych, Richard Eckart de Castilho, and Chris Biemann. 2013. WebAnno: A flexible, web-based and visually supported system for distributed annotations. In Proceedings of the 51st Annual Meeting of the Association for Compu- tational Linguistics: System Demonstrations, pages 1-6, Sofia, Bulgaria. Association for Computational Linguistics.\n\nCalibrate before use: Improving few-shot performance of language models. Tony Z Zhao, Eric Wallace, Shi Feng, Dan Klein, Sameer Singh, abs/2102.09690CoRRTony Z. Zhao, Eric Wallace, Shi Feng, Dan Klein, and Sameer Singh. 2021. Calibrate before use: Im- proving few-shot performance of language models. CoRR, abs/2102.09690.\n", "annotations": {"author": "[{\"end\":148,\"start\":114},{\"end\":180,\"start\":149},{\"end\":215,\"start\":181},{\"end\":249,\"start\":216},{\"end\":282,\"start\":250},{\"end\":316,\"start\":283},{\"end\":352,\"start\":317},{\"end\":384,\"start\":353},{\"end\":413,\"start\":385},{\"end\":438,\"start\":414},{\"end\":473,\"start\":439},{\"end\":507,\"start\":474},{\"end\":537,\"start\":508},{\"end\":573,\"start\":538},{\"end\":605,\"start\":574},{\"end\":642,\"start\":606},{\"end\":672,\"start\":643},{\"end\":709,\"start\":673},{\"end\":738,\"start\":710},{\"end\":775,\"start\":739},{\"end\":815,\"start\":776},{\"end\":849,\"start\":816},{\"end\":884,\"start\":850},{\"end\":921,\"start\":885},{\"end\":954,\"start\":922},{\"end\":989,\"start\":955},{\"end\":1019,\"start\":990},{\"end\":1050,\"start\":1020},{\"end\":1087,\"start\":1051}]", "publisher": null, "author_last_name": "[{\"end\":128,\"start\":124},{\"end\":160,\"start\":156},{\"end\":195,\"start\":191},{\"end\":229,\"start\":223},{\"end\":262,\"start\":256},{\"end\":296,\"start\":291},{\"end\":332,\"start\":326},{\"end\":364,\"start\":361},{\"end\":393,\"start\":387},{\"end\":453,\"start\":448},{\"end\":487,\"start\":479},{\"end\":517,\"start\":514},{\"end\":553,\"start\":545},{\"end\":585,\"start\":582},{\"end\":622,\"start\":613},{\"end\":652,\"start\":650},{\"end\":689,\"start\":680},{\"end\":718,\"start\":714},{\"end\":755,\"start\":750},{\"end\":795,\"start\":784},{\"end\":829,\"start\":823},{\"end\":864,\"start\":857},{\"end\":901,\"start\":892},{\"end\":934,\"start\":930},{\"end\":969,\"start\":964},{\"end\":999,\"start\":995},{\"end\":1030,\"start\":1025},{\"end\":1067,\"start\":1063}]", "author_first_name": "[{\"end\":121,\"start\":114},{\"end\":123,\"start\":122},{\"end\":155,\"start\":149},{\"end\":190,\"start\":181},{\"end\":222,\"start\":216},{\"end\":255,\"start\":250},{\"end\":288,\"start\":283},{\"end\":290,\"start\":289},{\"end\":325,\"start\":317},{\"end\":360,\"start\":353},{\"end\":386,\"start\":385},{\"end\":418,\"start\":414},{\"end\":447,\"start\":439},{\"end\":478,\"start\":474},{\"end\":513,\"start\":508},{\"end\":544,\"start\":538},{\"end\":581,\"start\":574},{\"end\":612,\"start\":606},{\"end\":649,\"start\":643},{\"end\":679,\"start\":673},{\"end\":713,\"start\":710},{\"end\":744,\"start\":739},{\"end\":749,\"start\":745},{\"end\":781,\"start\":776},{\"end\":783,\"start\":782},{\"end\":822,\"start\":816},{\"end\":856,\"start\":850},{\"end\":891,\"start\":885},{\"end\":929,\"start\":922},{\"end\":963,\"start\":955},{\"end\":994,\"start\":990},{\"end\":1024,\"start\":1020},{\"end\":1060,\"start\":1051},{\"end\":1062,\"start\":1061}]", "author_affiliation": "[{\"end\":147,\"start\":130},{\"end\":179,\"start\":162},{\"end\":214,\"start\":197},{\"end\":248,\"start\":231},{\"end\":281,\"start\":264},{\"end\":315,\"start\":298},{\"end\":351,\"start\":334},{\"end\":383,\"start\":366},{\"end\":412,\"start\":395},{\"end\":437,\"start\":420},{\"end\":472,\"start\":455},{\"end\":506,\"start\":489},{\"end\":536,\"start\":519},{\"end\":572,\"start\":555},{\"end\":604,\"start\":587},{\"end\":641,\"start\":624},{\"end\":671,\"start\":654},{\"end\":708,\"start\":691},{\"end\":737,\"start\":720},{\"end\":774,\"start\":757},{\"end\":814,\"start\":797},{\"end\":848,\"start\":831},{\"end\":883,\"start\":866},{\"end\":920,\"start\":903},{\"end\":953,\"start\":936},{\"end\":988,\"start\":971},{\"end\":1018,\"start\":1001},{\"end\":1049,\"start\":1032},{\"end\":1086,\"start\":1069}]", "title": "[{\"end\":96,\"start\":1},{\"end\":1183,\"start\":1088}]", "venue": "[{\"end\":1294,\"start\":1185}]", "abstract": "[{\"end\":2332,\"start\":1461}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3127,\"start\":3107},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":3153,\"start\":3127},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3176,\"start\":3153},{\"end\":3193,\"start\":3176},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":3510,\"start\":3490},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":3528,\"start\":3510},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":3553,\"start\":3528},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":3698,\"start\":3679},{\"end\":3715,\"start\":3698},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":3732,\"start\":3715},{\"end\":3752,\"start\":3732},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":4256,\"start\":4235},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":5953,\"start\":5934},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":6122,\"start\":6104},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":6187,\"start\":6170},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":6724,\"start\":6704},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":6750,\"start\":6724},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":6768,\"start\":6750},{\"end\":6785,\"start\":6768},{\"end\":7323,\"start\":7305},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":7341,\"start\":7323},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":7489,\"start\":7468},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":7510,\"start\":7489},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":8051,\"start\":8031},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":8284,\"start\":8264},{\"end\":8318,\"start\":8284},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":8487,\"start\":8465},{\"end\":8518,\"start\":8489},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":8732,\"start\":8708},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":8753,\"start\":8732},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":8770,\"start\":8753},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":8789,\"start\":8770},{\"end\":8811,\"start\":8789},{\"end\":8843,\"start\":8811},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":8862,\"start\":8843},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":8945,\"start\":8926},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":8966,\"start\":8945},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":9128,\"start\":9110},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":9172,\"start\":9154},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":9444,\"start\":9421},{\"end\":10699,\"start\":10673},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":12675,\"start\":12654},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":14221,\"start\":14200},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":15584,\"start\":15564},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":15602,\"start\":15584},{\"end\":15619,\"start\":15602},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":21503,\"start\":21485},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":22644,\"start\":22627},{\"end\":23768,\"start\":23735},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":25738,\"start\":25719}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":24890,\"start\":24622},{\"attributes\":{\"id\":\"fig_1\"},\"end\":25232,\"start\":24891},{\"attributes\":{\"id\":\"fig_2\"},\"end\":25377,\"start\":25233},{\"attributes\":{\"id\":\"fig_3\"},\"end\":25530,\"start\":25378},{\"attributes\":{\"id\":\"fig_4\"},\"end\":25858,\"start\":25531},{\"attributes\":{\"id\":\"fig_5\"},\"end\":25981,\"start\":25859},{\"attributes\":{\"id\":\"fig_6\"},\"end\":26046,\"start\":25982},{\"attributes\":{\"id\":\"fig_7\"},\"end\":26096,\"start\":26047},{\"attributes\":{\"id\":\"fig_8\"},\"end\":26208,\"start\":26097},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":27235,\"start\":26209},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":27697,\"start\":27236},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":29313,\"start\":27698}]", "paragraph": "[{\"end\":3305,\"start\":2348},{\"end\":3846,\"start\":3307},{\"end\":4473,\"start\":3848},{\"end\":5249,\"start\":4475},{\"end\":6344,\"start\":5251},{\"end\":8052,\"start\":6376},{\"end\":8319,\"start\":8054},{\"end\":9666,\"start\":8321},{\"end\":9871,\"start\":9697},{\"end\":11317,\"start\":9873},{\"end\":11510,\"start\":11319},{\"end\":11819,\"start\":11512},{\"end\":12067,\"start\":11821},{\"end\":12420,\"start\":12069},{\"end\":12783,\"start\":12422},{\"end\":13688,\"start\":12806},{\"end\":14007,\"start\":13690},{\"end\":14604,\"start\":14009},{\"end\":15878,\"start\":14606},{\"end\":17336,\"start\":15902},{\"end\":17653,\"start\":17386},{\"end\":18490,\"start\":17690},{\"end\":19158,\"start\":18492},{\"end\":19852,\"start\":19160},{\"end\":20560,\"start\":19854},{\"end\":21177,\"start\":20562},{\"end\":23150,\"start\":21194},{\"end\":23769,\"start\":23165},{\"end\":24036,\"start\":23795},{\"end\":24460,\"start\":24038},{\"end\":24621,\"start\":24481}]", "formula": null, "table_ref": null, "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2346,\"start\":2334},{\"attributes\":{\"n\":\"2\"},\"end\":6374,\"start\":6347},{\"attributes\":{\"n\":\"3\"},\"end\":9695,\"start\":9669},{\"attributes\":{\"n\":\"4\"},\"end\":12804,\"start\":12786},{\"attributes\":{\"n\":\"5\"},\"end\":15900,\"start\":15881},{\"end\":17359,\"start\":17339},{\"end\":17384,\"start\":17362},{\"attributes\":{\"n\":\"6\"},\"end\":17688,\"start\":17656},{\"attributes\":{\"n\":\"7\"},\"end\":21192,\"start\":21180},{\"attributes\":{\"n\":\"8\"},\"end\":23163,\"start\":23153},{\"end\":23793,\"start\":23772},{\"end\":24479,\"start\":24463},{\"end\":24633,\"start\":24623},{\"end\":25244,\"start\":25234},{\"end\":25389,\"start\":25379},{\"end\":25542,\"start\":25532},{\"end\":25870,\"start\":25860},{\"end\":25993,\"start\":25983},{\"end\":26058,\"start\":26048},{\"end\":26123,\"start\":26098}]", "table": "[{\"end\":27235,\"start\":26214}]", "figure_caption": "[{\"end\":24890,\"start\":24635},{\"end\":25232,\"start\":24893},{\"end\":25377,\"start\":25246},{\"end\":25530,\"start\":25391},{\"end\":25858,\"start\":25544},{\"end\":25981,\"start\":25872},{\"end\":26046,\"start\":25995},{\"end\":26096,\"start\":26060},{\"end\":26208,\"start\":26129},{\"end\":26214,\"start\":26211},{\"end\":27697,\"start\":27238},{\"end\":29313,\"start\":27700}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":10894,\"start\":10884},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":11468,\"start\":11459},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":11509,\"start\":11493},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":14584,\"start\":14576},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":15771,\"start\":15763},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":16398,\"start\":16389},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":16894,\"start\":16877},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":17421,\"start\":17413},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":24159,\"start\":24151},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":24564,\"start\":24554},{\"end\":24585,\"start\":24575},{\"end\":24611,\"start\":24602}]", "bib_author_first_name": "[{\"end\":30370,\"start\":30369},{\"end\":30384,\"start\":30379},{\"end\":30404,\"start\":30393},{\"end\":30424,\"start\":30413},{\"end\":30426,\"start\":30425},{\"end\":31100,\"start\":31097},{\"end\":31102,\"start\":31101},{\"end\":31118,\"start\":31110},{\"end\":31129,\"start\":31125},{\"end\":31144,\"start\":31137},{\"end\":31159,\"start\":31154},{\"end\":31176,\"start\":31168},{\"end\":31193,\"start\":31187},{\"end\":31213,\"start\":31207},{\"end\":31227,\"start\":31221},{\"end\":31242,\"start\":31236},{\"end\":31259,\"start\":31251},{\"end\":31274,\"start\":31269},{\"end\":31297,\"start\":31289},{\"end\":31310,\"start\":31307},{\"end\":31326,\"start\":31321},{\"end\":31340,\"start\":31334},{\"end\":31355,\"start\":31349},{\"end\":31357,\"start\":31356},{\"end\":31374,\"start\":31367},{\"end\":31386,\"start\":31379},{\"end\":31406,\"start\":31395},{\"end\":31418,\"start\":31414},{\"end\":31429,\"start\":31425},{\"end\":31445,\"start\":31438},{\"end\":32410,\"start\":32405},{\"end\":32421,\"start\":32418},{\"end\":32436,\"start\":32431},{\"end\":32450,\"start\":32442},{\"end\":32467,\"start\":32460},{\"end\":32485,\"start\":32476},{\"end\":32496,\"start\":32490},{\"end\":32511,\"start\":32505},{\"end\":32529,\"start\":32520},{\"end\":32543,\"start\":32537},{\"end\":32559,\"start\":32554},{\"end\":32571,\"start\":32564},{\"end\":32589,\"start\":32580},{\"end\":32604,\"start\":32598},{\"end\":32619,\"start\":32613},{\"end\":32636,\"start\":32631},{\"end\":32647,\"start\":32642},{\"end\":32667,\"start\":32656},{\"end\":32680,\"start\":32675},{\"end\":33648,\"start\":33646},{\"end\":33665,\"start\":33656},{\"end\":34418,\"start\":34411},{\"end\":34429,\"start\":34424},{\"end\":34444,\"start\":34438},{\"end\":34469,\"start\":34462},{\"end\":34484,\"start\":34475},{\"end\":34497,\"start\":34489},{\"end\":34512,\"start\":34507},{\"end\":35269,\"start\":35264},{\"end\":35282,\"start\":35278},{\"end\":35296,\"start\":35292},{\"end\":35952,\"start\":35948},{\"end\":35966,\"start\":35959},{\"end\":35978,\"start\":35972},{\"end\":35989,\"start\":35985},{\"end\":36587,\"start\":36580},{\"end\":36602,\"start\":36596},{\"end\":36630,\"start\":36624},{\"end\":36648,\"start\":36640},{\"end\":36662,\"start\":36657},{\"end\":36689,\"start\":36683},{\"end\":36704,\"start\":36697},{\"end\":36721,\"start\":36715},{\"end\":36734,\"start\":36729},{\"end\":36743,\"start\":36740},{\"end\":36759,\"start\":36754},{\"end\":36775,\"start\":36769},{\"end\":36792,\"start\":36783},{\"end\":36809,\"start\":36804},{\"end\":36822,\"start\":36817},{\"end\":36825,\"start\":36823},{\"end\":36842,\"start\":36836},{\"end\":36855,\"start\":36849},{\"end\":36869,\"start\":36862},{\"end\":36882,\"start\":36874},{\"end\":36897,\"start\":36890},{\"end\":36921,\"start\":36914},{\"end\":36937,\"start\":36930},{\"end\":38293,\"start\":38286},{\"end\":38303,\"start\":38298},{\"end\":38310,\"start\":38308},{\"end\":38328,\"start\":38321},{\"end\":39028,\"start\":39021},{\"end\":39051,\"start\":39046},{\"end\":39053,\"start\":39052},{\"end\":39063,\"start\":39059},{\"end\":39073,\"start\":39068},{\"end\":39778,\"start\":39773},{\"end\":39801,\"start\":39796},{\"end\":39818,\"start\":39812},{\"end\":39835,\"start\":39828},{\"end\":39848,\"start\":39842},{\"end\":39859,\"start\":39855},{\"end\":39872,\"start\":39867},{\"end\":39884,\"start\":39878},{\"end\":39899,\"start\":39892},{\"end\":39918,\"start\":39909},{\"end\":39926,\"start\":39923},{\"end\":39942,\"start\":39937},{\"end\":39960,\"start\":39953},{\"end\":39992,\"start\":39985},{\"end\":40004,\"start\":40000},{\"end\":40015,\"start\":40011},{\"end\":40030,\"start\":40022},{\"end\":40048,\"start\":40044},{\"end\":40050,\"start\":40049},{\"end\":40068,\"start\":40061},{\"end\":40079,\"start\":40075},{\"end\":40630,\"start\":40623},{\"end\":40642,\"start\":40636},{\"end\":40655,\"start\":40649},{\"end\":40668,\"start\":40660},{\"end\":40683,\"start\":40676},{\"end\":40699,\"start\":40693},{\"end\":40994,\"start\":40989},{\"end\":41004,\"start\":41000},{\"end\":41016,\"start\":41012},{\"end\":41038,\"start\":41030},{\"end\":41212,\"start\":41205},{\"end\":41227,\"start\":41221},{\"end\":41649,\"start\":41642},{\"end\":41663,\"start\":41657},{\"end\":41936,\"start\":41928},{\"end\":41953,\"start\":41947},{\"end\":41967,\"start\":41961},{\"end\":42472,\"start\":42467},{\"end\":42485,\"start\":42480},{\"end\":42502,\"start\":42493},{\"end\":42712,\"start\":42697},{\"end\":42726,\"start\":42720},{\"end\":43340,\"start\":43332},{\"end\":43351,\"start\":43346},{\"end\":44071,\"start\":44066},{\"end\":44087,\"start\":44081},{\"end\":44104,\"start\":44100},{\"end\":44120,\"start\":44114},{\"end\":44134,\"start\":44128},{\"end\":44136,\"start\":44135},{\"end\":44155,\"start\":44148},{\"end\":44172,\"start\":44165},{\"end\":44193,\"start\":44183},{\"end\":44527,\"start\":44521},{\"end\":44540,\"start\":44534},{\"end\":44554,\"start\":44549},{\"end\":44570,\"start\":44563},{\"end\":44572,\"start\":44571},{\"end\":44586,\"start\":44579},{\"end\":44601,\"start\":44597},{\"end\":44619,\"start\":44612},{\"end\":44635,\"start\":44629},{\"end\":44651,\"start\":44646},{\"end\":44654,\"start\":44652},{\"end\":44665,\"start\":44661},{\"end\":44677,\"start\":44672},{\"end\":44689,\"start\":44683},{\"end\":44702,\"start\":44696},{\"end\":44713,\"start\":44707},{\"end\":44728,\"start\":44723},{\"end\":44751,\"start\":44744},{\"end\":44769,\"start\":44763},{\"end\":44780,\"start\":44775},{\"end\":44801,\"start\":44792},{\"end\":44817,\"start\":44809},{\"end\":44829,\"start\":44825},{\"end\":44851,\"start\":44848},{\"end\":44865,\"start\":44859},{\"end\":44877,\"start\":44872},{\"end\":45982,\"start\":45978},{\"end\":45998,\"start\":45991},{\"end\":46678,\"start\":46674},{\"end\":46694,\"start\":46687},{\"end\":47492,\"start\":47486},{\"end\":47506,\"start\":47499},{\"end\":47522,\"start\":47516},{\"end\":47524,\"start\":47523},{\"end\":47533,\"start\":47532},{\"end\":47535,\"start\":47534},{\"end\":47542,\"start\":47538},{\"end\":47558,\"start\":47552},{\"end\":48235,\"start\":48229},{\"end\":48252,\"start\":48247},{\"end\":48267,\"start\":48262},{\"end\":48281,\"start\":48275},{\"end\":48294,\"start\":48288},{\"end\":48319,\"start\":48306},{\"end\":49082,\"start\":49075},{\"end\":49095,\"start\":49092},{\"end\":49107,\"start\":49101},{\"end\":50030,\"start\":50024},{\"end\":50044,\"start\":50039},{\"end\":50279,\"start\":50269},{\"end\":50292,\"start\":50285},{\"end\":50305,\"start\":50298},{\"end\":50572,\"start\":50567},{\"end\":50585,\"start\":50578},{\"end\":50594,\"start\":50593},{\"end\":50610,\"start\":50604},{\"end\":50622,\"start\":50617},{\"end\":50626,\"start\":50623},{\"end\":50637,\"start\":50632},{\"end\":50645,\"start\":50642},{\"end\":50972,\"start\":50969},{\"end\":50982,\"start\":50979},{\"end\":50996,\"start\":50990},{\"end\":51009,\"start\":51001},{\"end\":51518,\"start\":51513},{\"end\":51544,\"start\":51537},{\"end\":51560,\"start\":51555},{\"end\":52296,\"start\":52292},{\"end\":52298,\"start\":52297},{\"end\":52309,\"start\":52305},{\"end\":52322,\"start\":52319},{\"end\":52332,\"start\":52329},{\"end\":52346,\"start\":52340}]", "bib_author_last_name": "[{\"end\":30377,\"start\":30371},{\"end\":30391,\"start\":30385},{\"end\":30411,\"start\":30405},{\"end\":30432,\"start\":30427},{\"end\":30441,\"start\":30434},{\"end\":31108,\"start\":31103},{\"end\":31123,\"start\":31119},{\"end\":31135,\"start\":31130},{\"end\":31152,\"start\":31145},{\"end\":31166,\"start\":31160},{\"end\":31185,\"start\":31177},{\"end\":31205,\"start\":31194},{\"end\":31219,\"start\":31214},{\"end\":31234,\"start\":31228},{\"end\":31249,\"start\":31243},{\"end\":31267,\"start\":31260},{\"end\":31287,\"start\":31275},{\"end\":31305,\"start\":31298},{\"end\":31319,\"start\":31311},{\"end\":31332,\"start\":31327},{\"end\":31347,\"start\":31341},{\"end\":31365,\"start\":31358},{\"end\":31377,\"start\":31375},{\"end\":31393,\"start\":31387},{\"end\":31412,\"start\":31407},{\"end\":31423,\"start\":31419},{\"end\":31436,\"start\":31430},{\"end\":31452,\"start\":31446},{\"end\":32416,\"start\":32411},{\"end\":32429,\"start\":32422},{\"end\":32440,\"start\":32437},{\"end\":32458,\"start\":32451},{\"end\":32474,\"start\":32468},{\"end\":32488,\"start\":32486},{\"end\":32503,\"start\":32497},{\"end\":32518,\"start\":32512},{\"end\":32535,\"start\":32530},{\"end\":32552,\"start\":32544},{\"end\":32562,\"start\":32560},{\"end\":32578,\"start\":32572},{\"end\":32596,\"start\":32590},{\"end\":32611,\"start\":32605},{\"end\":32629,\"start\":32620},{\"end\":32640,\"start\":32637},{\"end\":32654,\"start\":32648},{\"end\":32673,\"start\":32668},{\"end\":32689,\"start\":32681},{\"end\":33654,\"start\":33649},{\"end\":33670,\"start\":33666},{\"end\":33676,\"start\":33672},{\"end\":34422,\"start\":34419},{\"end\":34436,\"start\":34430},{\"end\":34460,\"start\":34445},{\"end\":34473,\"start\":34470},{\"end\":34487,\"start\":34485},{\"end\":34505,\"start\":34498},{\"end\":34518,\"start\":34513},{\"end\":34523,\"start\":34520},{\"end\":35276,\"start\":35270},{\"end\":35290,\"start\":35283},{\"end\":35305,\"start\":35297},{\"end\":35957,\"start\":35953},{\"end\":35970,\"start\":35967},{\"end\":35983,\"start\":35979},{\"end\":36001,\"start\":35990},{\"end\":36594,\"start\":36588},{\"end\":36622,\"start\":36603},{\"end\":36638,\"start\":36631},{\"end\":36655,\"start\":36649},{\"end\":36681,\"start\":36663},{\"end\":36695,\"start\":36690},{\"end\":36713,\"start\":36705},{\"end\":36727,\"start\":36722},{\"end\":36738,\"start\":36735},{\"end\":36752,\"start\":36744},{\"end\":36767,\"start\":36760},{\"end\":36781,\"start\":36776},{\"end\":36802,\"start\":36793},{\"end\":36815,\"start\":36810},{\"end\":36834,\"start\":36826},{\"end\":36847,\"start\":36843},{\"end\":36860,\"start\":36856},{\"end\":36872,\"start\":36870},{\"end\":36888,\"start\":36883},{\"end\":36912,\"start\":36898},{\"end\":36928,\"start\":36922},{\"end\":36944,\"start\":36938},{\"end\":36954,\"start\":36946},{\"end\":38296,\"start\":38294},{\"end\":38306,\"start\":38304},{\"end\":38319,\"start\":38311},{\"end\":38332,\"start\":38329},{\"end\":39044,\"start\":39029},{\"end\":39057,\"start\":39054},{\"end\":39066,\"start\":39064},{\"end\":39077,\"start\":39074},{\"end\":39082,\"start\":39079},{\"end\":39794,\"start\":39779},{\"end\":39810,\"start\":39802},{\"end\":39826,\"start\":39819},{\"end\":39840,\"start\":39836},{\"end\":39853,\"start\":39849},{\"end\":39865,\"start\":39860},{\"end\":39876,\"start\":39873},{\"end\":39890,\"start\":39885},{\"end\":39907,\"start\":39900},{\"end\":39921,\"start\":39919},{\"end\":39935,\"start\":39927},{\"end\":39951,\"start\":39943},{\"end\":39972,\"start\":39961},{\"end\":39983,\"start\":39974},{\"end\":39998,\"start\":39993},{\"end\":40009,\"start\":40005},{\"end\":40020,\"start\":40016},{\"end\":40042,\"start\":40031},{\"end\":40059,\"start\":40051},{\"end\":40073,\"start\":40069},{\"end\":40088,\"start\":40080},{\"end\":40092,\"start\":40090},{\"end\":40634,\"start\":40631},{\"end\":40647,\"start\":40643},{\"end\":40658,\"start\":40656},{\"end\":40674,\"start\":40669},{\"end\":40691,\"start\":40684},{\"end\":40706,\"start\":40700},{\"end\":40998,\"start\":40995},{\"end\":41010,\"start\":41005},{\"end\":41028,\"start\":41017},{\"end\":41049,\"start\":41039},{\"end\":41219,\"start\":41213},{\"end\":41236,\"start\":41228},{\"end\":41655,\"start\":41650},{\"end\":41668,\"start\":41664},{\"end\":41945,\"start\":41937},{\"end\":41959,\"start\":41954},{\"end\":41976,\"start\":41968},{\"end\":42478,\"start\":42473},{\"end\":42491,\"start\":42486},{\"end\":42506,\"start\":42503},{\"end\":42718,\"start\":42713},{\"end\":42733,\"start\":42727},{\"end\":43344,\"start\":43341},{\"end\":43358,\"start\":43352},{\"end\":44079,\"start\":44072},{\"end\":44098,\"start\":44088},{\"end\":44112,\"start\":44105},{\"end\":44126,\"start\":44121},{\"end\":44146,\"start\":44137},{\"end\":44163,\"start\":44156},{\"end\":44181,\"start\":44173},{\"end\":44202,\"start\":44194},{\"end\":44532,\"start\":44528},{\"end\":44547,\"start\":44541},{\"end\":44561,\"start\":44555},{\"end\":44577,\"start\":44573},{\"end\":44595,\"start\":44587},{\"end\":44610,\"start\":44602},{\"end\":44627,\"start\":44620},{\"end\":44644,\"start\":44636},{\"end\":44659,\"start\":44655},{\"end\":44670,\"start\":44666},{\"end\":44681,\"start\":44678},{\"end\":44694,\"start\":44690},{\"end\":44705,\"start\":44703},{\"end\":44721,\"start\":44714},{\"end\":44742,\"start\":44729},{\"end\":44761,\"start\":44752},{\"end\":44773,\"start\":44770},{\"end\":44790,\"start\":44781},{\"end\":44807,\"start\":44802},{\"end\":44823,\"start\":44818},{\"end\":44835,\"start\":44830},{\"end\":44846,\"start\":44837},{\"end\":44857,\"start\":44852},{\"end\":44870,\"start\":44866},{\"end\":44884,\"start\":44878},{\"end\":44890,\"start\":44886},{\"end\":45989,\"start\":45983},{\"end\":46006,\"start\":45999},{\"end\":46685,\"start\":46679},{\"end\":46702,\"start\":46695},{\"end\":47497,\"start\":47493},{\"end\":47514,\"start\":47507},{\"end\":47530,\"start\":47525},{\"end\":47550,\"start\":47543},{\"end\":47564,\"start\":47559},{\"end\":48245,\"start\":48236},{\"end\":48260,\"start\":48253},{\"end\":48273,\"start\":48268},{\"end\":48286,\"start\":48282},{\"end\":48304,\"start\":48295},{\"end\":48326,\"start\":48320},{\"end\":49090,\"start\":49083},{\"end\":49099,\"start\":49096},{\"end\":49122,\"start\":49108},{\"end\":50037,\"start\":50031},{\"end\":50052,\"start\":50045},{\"end\":50283,\"start\":50280},{\"end\":50296,\"start\":50293},{\"end\":50308,\"start\":50306},{\"end\":50576,\"start\":50573},{\"end\":50591,\"start\":50586},{\"end\":50602,\"start\":50595},{\"end\":50615,\"start\":50611},{\"end\":50630,\"start\":50627},{\"end\":50640,\"start\":50638},{\"end\":50652,\"start\":50646},{\"end\":50656,\"start\":50654},{\"end\":50977,\"start\":50973},{\"end\":50988,\"start\":50983},{\"end\":50999,\"start\":50997},{\"end\":51012,\"start\":51010},{\"end\":51535,\"start\":51519},{\"end\":51553,\"start\":51545},{\"end\":51579,\"start\":51561},{\"end\":51588,\"start\":51581},{\"end\":52303,\"start\":52299},{\"end\":52317,\"start\":52310},{\"end\":52327,\"start\":52323},{\"end\":52338,\"start\":52333},{\"end\":52352,\"start\":52347}]", "bib_entry": "[{\"attributes\":{\"doi\":\"10.18653/v1/D15-1075\",\"id\":\"b0\",\"matched_paper_id\":14604520},\"end\":31002,\"start\":30303},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":218971783},\"end\":32360,\"start\":31004},{\"attributes\":{\"doi\":\"10.18653/v1/2021.naacl-main.324\",\"id\":\"b2\",\"matched_paper_id\":233444226},\"end\":33603,\"start\":32362},{\"attributes\":{\"doi\":\"10.18653/v1/2021.naacl-main.208\",\"id\":\"b3\",\"matched_paper_id\":232233408},\"end\":34325,\"start\":33605},{\"attributes\":{\"doi\":\"10.18653/v1/2020.acl-demos.42\",\"id\":\"b4\",\"matched_paper_id\":215786162},\"end\":35204,\"start\":34327},{\"attributes\":{\"doi\":\"10.18653/v1/2021.emnlp-main.243\",\"id\":\"b5\",\"matched_paper_id\":233296808},\"end\":35889,\"start\":35206},{\"attributes\":{\"doi\":\"10.18653/v1/K17-1034\",\"id\":\"b6\",\"matched_paper_id\":793385},\"end\":36515,\"start\":35891},{\"attributes\":{\"doi\":\"10.18653/v1/2021.emnlp-demo.21\",\"id\":\"b7\",\"matched_paper_id\":237431340},\"end\":38219,\"start\":36517},{\"attributes\":{\"doi\":\"10.18653/v1/2021.naacl-demos.5\",\"id\":\"b8\",\"matched_paper_id\":235097513},\"end\":38546,\"start\":38221},{\"attributes\":{\"id\":\"b9\"},\"end\":38935,\"start\":38548},{\"attributes\":{\"doi\":\"10.18653/v1/P19-3010\",\"id\":\"b10\",\"matched_paper_id\":196192366},\"end\":39718,\"start\":38937},{\"attributes\":{\"doi\":\"abs/2112.10668\",\"id\":\"b11\"},\"end\":40517,\"start\":39720},{\"attributes\":{\"doi\":\"abs/2107.13586\",\"id\":\"b12\"},\"end\":40948,\"start\":40519},{\"attributes\":{\"doi\":\"abs/2110.15943\",\"id\":\"b13\"},\"end\":41203,\"start\":40950},{\"attributes\":{\"doi\":\"arXiv:2104.08773\",\"id\":\"b14\"},\"end\":41575,\"start\":41205},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":209384170},\"end\":41847,\"start\":41577},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":2062655},\"end\":42420,\"start\":41849},{\"attributes\":{\"id\":\"b17\"},\"end\":42621,\"start\":42422},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":218974381},\"end\":43265,\"start\":42623},{\"attributes\":{\"doi\":\"10.18653/v1/2021.naacl-main.410\",\"id\":\"b19\",\"matched_paper_id\":233231453},\"end\":43982,\"start\":43267},{\"attributes\":{\"doi\":\"10.1093/bioinformatics/bts435\",\"id\":\"b20\",\"matched_paper_id\":22976889},\"end\":44517,\"start\":43984},{\"attributes\":{\"id\":\"b21\"},\"end\":45884,\"start\":44519},{\"attributes\":{\"doi\":\"10.18653/v1/2021.eacl-main.20\",\"id\":\"b22\",\"matched_paper_id\":210838924},\"end\":46590,\"start\":45886},{\"attributes\":{\"doi\":\"10.18653/v1/2021.naacl-main.185\",\"id\":\"b23\"},\"end\":47393,\"start\":46592},{\"attributes\":{\"doi\":\"10.18653/v1/2020.emnlp-main.346\",\"id\":\"b24\"},\"end\":48170,\"start\":47395},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":2065400},\"end\":49000,\"start\":48172},{\"attributes\":{\"doi\":\"10.18653/v1/D19-3033\",\"id\":\"b26\",\"matched_paper_id\":202779665},\"end\":49945,\"start\":49002},{\"attributes\":{\"doi\":\"abs/2109.01247\",\"id\":\"b27\"},\"end\":50201,\"start\":49947},{\"attributes\":{\"doi\":\"10.1093/nar/gkt441\",\"id\":\"b28\",\"matched_paper_id\":1636407},\"end\":50515,\"start\":50203},{\"attributes\":{\"doi\":\"abs/2109.01652\",\"id\":\"b29\"},\"end\":50905,\"start\":50517},{\"attributes\":{\"doi\":\"10.18653/v1/P18-4006\",\"id\":\"b30\",\"matched_paper_id\":29051190},\"end\":51421,\"start\":50907},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":6141036},\"end\":52217,\"start\":51423},{\"attributes\":{\"doi\":\"abs/2102.09690\",\"id\":\"b32\"},\"end\":52541,\"start\":52219}]", "bib_title": "[{\"end\":30367,\"start\":30303},{\"end\":31095,\"start\":31004},{\"end\":32403,\"start\":32362},{\"end\":33644,\"start\":33605},{\"end\":34409,\"start\":34327},{\"end\":35262,\"start\":35206},{\"end\":35946,\"start\":35891},{\"end\":36578,\"start\":36517},{\"end\":38284,\"start\":38221},{\"end\":39019,\"start\":38937},{\"end\":41640,\"start\":41577},{\"end\":41926,\"start\":41849},{\"end\":42695,\"start\":42623},{\"end\":43330,\"start\":43267},{\"end\":44064,\"start\":43984},{\"end\":45976,\"start\":45886},{\"end\":46672,\"start\":46592},{\"end\":47484,\"start\":47395},{\"end\":48227,\"start\":48172},{\"end\":49073,\"start\":49002},{\"end\":50267,\"start\":50203},{\"end\":50967,\"start\":50907},{\"end\":51511,\"start\":51423}]", "bib_author": "[{\"end\":30379,\"start\":30369},{\"end\":30393,\"start\":30379},{\"end\":30413,\"start\":30393},{\"end\":30434,\"start\":30413},{\"end\":30443,\"start\":30434},{\"end\":31110,\"start\":31097},{\"end\":31125,\"start\":31110},{\"end\":31137,\"start\":31125},{\"end\":31154,\"start\":31137},{\"end\":31168,\"start\":31154},{\"end\":31187,\"start\":31168},{\"end\":31207,\"start\":31187},{\"end\":31221,\"start\":31207},{\"end\":31236,\"start\":31221},{\"end\":31251,\"start\":31236},{\"end\":31269,\"start\":31251},{\"end\":31289,\"start\":31269},{\"end\":31307,\"start\":31289},{\"end\":31321,\"start\":31307},{\"end\":31334,\"start\":31321},{\"end\":31349,\"start\":31334},{\"end\":31367,\"start\":31349},{\"end\":31379,\"start\":31367},{\"end\":31395,\"start\":31379},{\"end\":31414,\"start\":31395},{\"end\":31425,\"start\":31414},{\"end\":31438,\"start\":31425},{\"end\":31454,\"start\":31438},{\"end\":32418,\"start\":32405},{\"end\":32431,\"start\":32418},{\"end\":32442,\"start\":32431},{\"end\":32460,\"start\":32442},{\"end\":32476,\"start\":32460},{\"end\":32490,\"start\":32476},{\"end\":32505,\"start\":32490},{\"end\":32520,\"start\":32505},{\"end\":32537,\"start\":32520},{\"end\":32554,\"start\":32537},{\"end\":32564,\"start\":32554},{\"end\":32580,\"start\":32564},{\"end\":32598,\"start\":32580},{\"end\":32613,\"start\":32598},{\"end\":32631,\"start\":32613},{\"end\":32642,\"start\":32631},{\"end\":32656,\"start\":32642},{\"end\":32675,\"start\":32656},{\"end\":32691,\"start\":32675},{\"end\":33656,\"start\":33646},{\"end\":33672,\"start\":33656},{\"end\":33678,\"start\":33672},{\"end\":34424,\"start\":34411},{\"end\":34438,\"start\":34424},{\"end\":34462,\"start\":34438},{\"end\":34475,\"start\":34462},{\"end\":34489,\"start\":34475},{\"end\":34507,\"start\":34489},{\"end\":34520,\"start\":34507},{\"end\":34525,\"start\":34520},{\"end\":35278,\"start\":35264},{\"end\":35292,\"start\":35278},{\"end\":35307,\"start\":35292},{\"end\":35959,\"start\":35948},{\"end\":35972,\"start\":35959},{\"end\":35985,\"start\":35972},{\"end\":36003,\"start\":35985},{\"end\":36596,\"start\":36580},{\"end\":36624,\"start\":36596},{\"end\":36640,\"start\":36624},{\"end\":36657,\"start\":36640},{\"end\":36683,\"start\":36657},{\"end\":36697,\"start\":36683},{\"end\":36715,\"start\":36697},{\"end\":36729,\"start\":36715},{\"end\":36740,\"start\":36729},{\"end\":36754,\"start\":36740},{\"end\":36769,\"start\":36754},{\"end\":36783,\"start\":36769},{\"end\":36804,\"start\":36783},{\"end\":36817,\"start\":36804},{\"end\":36836,\"start\":36817},{\"end\":36849,\"start\":36836},{\"end\":36862,\"start\":36849},{\"end\":36874,\"start\":36862},{\"end\":36890,\"start\":36874},{\"end\":36914,\"start\":36890},{\"end\":36930,\"start\":36914},{\"end\":36946,\"start\":36930},{\"end\":36956,\"start\":36946},{\"end\":38298,\"start\":38286},{\"end\":38308,\"start\":38298},{\"end\":38321,\"start\":38308},{\"end\":38334,\"start\":38321},{\"end\":39046,\"start\":39021},{\"end\":39059,\"start\":39046},{\"end\":39068,\"start\":39059},{\"end\":39079,\"start\":39068},{\"end\":39084,\"start\":39079},{\"end\":39796,\"start\":39773},{\"end\":39812,\"start\":39796},{\"end\":39828,\"start\":39812},{\"end\":39842,\"start\":39828},{\"end\":39855,\"start\":39842},{\"end\":39867,\"start\":39855},{\"end\":39878,\"start\":39867},{\"end\":39892,\"start\":39878},{\"end\":39909,\"start\":39892},{\"end\":39923,\"start\":39909},{\"end\":39937,\"start\":39923},{\"end\":39953,\"start\":39937},{\"end\":39974,\"start\":39953},{\"end\":39985,\"start\":39974},{\"end\":40000,\"start\":39985},{\"end\":40011,\"start\":40000},{\"end\":40022,\"start\":40011},{\"end\":40044,\"start\":40022},{\"end\":40061,\"start\":40044},{\"end\":40075,\"start\":40061},{\"end\":40090,\"start\":40075},{\"end\":40094,\"start\":40090},{\"end\":40636,\"start\":40623},{\"end\":40649,\"start\":40636},{\"end\":40660,\"start\":40649},{\"end\":40676,\"start\":40660},{\"end\":40693,\"start\":40676},{\"end\":40708,\"start\":40693},{\"end\":41000,\"start\":40989},{\"end\":41012,\"start\":41000},{\"end\":41030,\"start\":41012},{\"end\":41051,\"start\":41030},{\"end\":41221,\"start\":41205},{\"end\":41238,\"start\":41221},{\"end\":41657,\"start\":41642},{\"end\":41670,\"start\":41657},{\"end\":41947,\"start\":41928},{\"end\":41961,\"start\":41947},{\"end\":41978,\"start\":41961},{\"end\":42480,\"start\":42467},{\"end\":42493,\"start\":42480},{\"end\":42508,\"start\":42493},{\"end\":42720,\"start\":42697},{\"end\":42735,\"start\":42720},{\"end\":43346,\"start\":43332},{\"end\":43360,\"start\":43346},{\"end\":44081,\"start\":44066},{\"end\":44100,\"start\":44081},{\"end\":44114,\"start\":44100},{\"end\":44128,\"start\":44114},{\"end\":44148,\"start\":44128},{\"end\":44165,\"start\":44148},{\"end\":44183,\"start\":44165},{\"end\":44204,\"start\":44183},{\"end\":44534,\"start\":44521},{\"end\":44549,\"start\":44534},{\"end\":44563,\"start\":44549},{\"end\":44579,\"start\":44563},{\"end\":44597,\"start\":44579},{\"end\":44612,\"start\":44597},{\"end\":44629,\"start\":44612},{\"end\":44646,\"start\":44629},{\"end\":44661,\"start\":44646},{\"end\":44672,\"start\":44661},{\"end\":44683,\"start\":44672},{\"end\":44696,\"start\":44683},{\"end\":44707,\"start\":44696},{\"end\":44723,\"start\":44707},{\"end\":44744,\"start\":44723},{\"end\":44763,\"start\":44744},{\"end\":44775,\"start\":44763},{\"end\":44792,\"start\":44775},{\"end\":44809,\"start\":44792},{\"end\":44825,\"start\":44809},{\"end\":44837,\"start\":44825},{\"end\":44848,\"start\":44837},{\"end\":44859,\"start\":44848},{\"end\":44872,\"start\":44859},{\"end\":44886,\"start\":44872},{\"end\":44892,\"start\":44886},{\"end\":45991,\"start\":45978},{\"end\":46008,\"start\":45991},{\"end\":46687,\"start\":46674},{\"end\":46704,\"start\":46687},{\"end\":47499,\"start\":47486},{\"end\":47516,\"start\":47499},{\"end\":47532,\"start\":47516},{\"end\":47538,\"start\":47532},{\"end\":47552,\"start\":47538},{\"end\":47566,\"start\":47552},{\"end\":48247,\"start\":48229},{\"end\":48262,\"start\":48247},{\"end\":48275,\"start\":48262},{\"end\":48288,\"start\":48275},{\"end\":48306,\"start\":48288},{\"end\":48328,\"start\":48306},{\"end\":49092,\"start\":49075},{\"end\":49101,\"start\":49092},{\"end\":49124,\"start\":49101},{\"end\":50039,\"start\":50024},{\"end\":50054,\"start\":50039},{\"end\":50285,\"start\":50269},{\"end\":50298,\"start\":50285},{\"end\":50310,\"start\":50298},{\"end\":50578,\"start\":50567},{\"end\":50593,\"start\":50578},{\"end\":50604,\"start\":50593},{\"end\":50617,\"start\":50604},{\"end\":50632,\"start\":50617},{\"end\":50642,\"start\":50632},{\"end\":50654,\"start\":50642},{\"end\":50658,\"start\":50654},{\"end\":50979,\"start\":50969},{\"end\":50990,\"start\":50979},{\"end\":51001,\"start\":50990},{\"end\":51014,\"start\":51001},{\"end\":51537,\"start\":51513},{\"end\":51555,\"start\":51537},{\"end\":51581,\"start\":51555},{\"end\":51590,\"start\":51581},{\"end\":52305,\"start\":52292},{\"end\":52319,\"start\":52305},{\"end\":52329,\"start\":52319},{\"end\":52340,\"start\":52329},{\"end\":52354,\"start\":52340}]", "bib_venue": "[{\"end\":30549,\"start\":30463},{\"end\":31571,\"start\":31454},{\"end\":32864,\"start\":32722},{\"end\":33851,\"start\":33709},{\"end\":34664,\"start\":34554},{\"end\":35424,\"start\":35338},{\"end\":36100,\"start\":36023},{\"end\":37095,\"start\":36986},{\"end\":38387,\"start\":38364},{\"end\":38682,\"start\":38548},{\"end\":39214,\"start\":39104},{\"end\":39771,\"start\":39720},{\"end\":40621,\"start\":40519},{\"end\":40987,\"start\":40950},{\"end\":41372,\"start\":41254},{\"end\":41697,\"start\":41670},{\"end\":42033,\"start\":41978},{\"end\":42465,\"start\":42422},{\"end\":42803,\"start\":42735},{\"end\":43533,\"start\":43391},{\"end\":44247,\"start\":44233},{\"end\":46157,\"start\":46037},{\"end\":46877,\"start\":46735},{\"end\":47691,\"start\":47597},{\"end\":48457,\"start\":48328},{\"end\":49304,\"start\":49144},{\"end\":50022,\"start\":49947},{\"end\":50350,\"start\":50328},{\"end\":50565,\"start\":50517},{\"end\":51080,\"start\":51034},{\"end\":51700,\"start\":51590},{\"end\":52290,\"start\":52219},{\"end\":30638,\"start\":30551},{\"end\":31656,\"start\":31573},{\"end\":32993,\"start\":32866},{\"end\":33980,\"start\":33853},{\"end\":34761,\"start\":34666},{\"end\":35497,\"start\":35426},{\"end\":36181,\"start\":36102},{\"end\":37341,\"start\":37097},{\"end\":38397,\"start\":38389},{\"end\":39326,\"start\":39216},{\"end\":42098,\"start\":42035},{\"end\":42875,\"start\":42805},{\"end\":43662,\"start\":43535},{\"end\":46264,\"start\":46159},{\"end\":47006,\"start\":46879},{\"end\":47772,\"start\":47693},{\"end\":48588,\"start\":48459},{\"end\":49467,\"start\":49306},{\"end\":51133,\"start\":51082},{\"end\":51812,\"start\":51702}]"}}}, "year": 2023, "month": 12, "day": 17}