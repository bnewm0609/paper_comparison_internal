{"id": 252009473, "updated": "2023-02-09 21:46:21.117", "metadata": {"title": "Deep learning for twelve hour precipitation forecasts", "authors": "[{\"first\":\"Lasse\",\"last\":\"Espeholt\",\"middle\":[]},{\"first\":\"Shreya\",\"last\":\"Agrawal\",\"middle\":[]},{\"first\":\"Casper\",\"last\":\"S\u00f8nderby\",\"middle\":[]},{\"first\":\"Manoj\",\"last\":\"Kumar\",\"middle\":[]},{\"first\":\"Jonathan\",\"last\":\"Heek\",\"middle\":[]},{\"first\":\"Carla\",\"last\":\"Bromberg\",\"middle\":[]},{\"first\":\"Cenk\",\"last\":\"Gazen\",\"middle\":[]},{\"first\":\"Rob\",\"last\":\"Carver\",\"middle\":[]},{\"first\":\"Marcin\",\"last\":\"Andrychowicz\",\"middle\":[]},{\"first\":\"Jason\",\"last\":\"Hickey\",\"middle\":[]},{\"first\":\"Aaron\",\"last\":\"Bell\",\"middle\":[]},{\"first\":\"Nal\",\"last\":\"Kalchbrenner\",\"middle\":[]}]", "venue": "Nature Communications", "journal": "Nature Communications", "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "Existing weather forecasting models are based on physics and use supercomputers to evolve the atmosphere into the future. Better physics-based forecasts require improved atmospheric models, which can be difficult to discover and develop, or increasing the resolution underlying the simulation, which can be computationally prohibitive. An emerging class of weather models based on neural networks overcome these limitations by learning the required transformations from data instead of relying on hand-coded physics and by running efficiently in parallel. Here we present a neural network capable of predicting precipitation at a high resolution up to 12\u2009h ahead. The model predicts raw precipitation targets and outperforms for up to 12\u2009h of lead time state-of-the-art physics-based models currently operating in the Continental United States. The results represent a substantial step towards validating the new class of neural weather models.", "fields_of_study": "[\"Medicine\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": "36050311", "pubmedcentral": "9436943", "dblp": null, "doi": "10.1038/s41467-022-32483-x"}}, "content": {"source": {"pdf_hash": "d5eb8c4987317ee8bd59c1b3911019ae7d2f4572", "pdf_src": "PubMedCentral", "pdf_uri": null, "oa_url_match": false, "oa_info": {"license": "CCBY", "open_access_url": null, "status": null}}, "grobid": {"id": "7cf4b2ccf928641a6464e5cc2babce1a1225aaa1", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/d5eb8c4987317ee8bd59c1b3911019ae7d2f4572.txt", "contents": "\nPeer Review File Deep learning for twelve hour precipitation forecasts REVIEWER COMMENTS Reviewer #1 (Remarks to the Author)\n\n\nPeer Review File Deep learning for twelve hour precipitation forecasts REVIEWER COMMENTS Reviewer #1 (Remarks to the Author)\n10.1002/essoar.10501462.1)Open Access This file is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. In the cases where the authors are anonymous, such as is the case for the reports of anonymous peer reviewers, author attribution should be to 'Anonymous Referee' followed by a clear attribution to the source work. The images or other third party material in this file are included in the article's Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit\n\n\nThe authors present a study in which a neural network is used for short-term prediction of precipitation. The probabilistic model learns to predict precipitation patterns up to 12 hours ahead based on high-resolution observations. In another version of the model, it also uses highresolution dynamical weather forecasts as input. The neural network predictions are compared to the aforementioned high-resolution model HRRR and favorable results are found at significant lead times.\n\nThis study presents a step forward in the application of neural networks for short-term precipitation forecasting. It builds upon previous work, most notably MetNet, by also incorporating other variables in the input, which, as the authors shows, has a significant positive impact on the prediction skill. Further, by merging the dynamical model predictions with the neural network, the authors combine the advantages of both approaches. The study also has a wide range of sensitivity experiments and generally shows a thorough evaluation.\n\nHowever, from what I can tell, there is one major flaw in this study. The key result of the paper is an improvement in the CSI, BS and CRPS compared to HRRR. The proposed method is a probabilistic model whereas HRRR is a deterministic model. This is like comparing apples to oranges. On the CSI, a binary, point-wise metric, deterministic forecasts will suffer strongly from the double penalty problem for highly intermittent fields like precipitation. A thresholded probabilistic forecast will be much smoother and therefore would be expected to result in a better score. (This is why for deterministic forecasts, neighborhood scores like the FSS are now standard.) On the other hand, using probabilistic metrics like the BS and CRPS on a deterministic forecast is simply not fair and obviously the score of almost any decent probabilistic forecast will be significantly better. If HRRR was indeed the only baseline to be used, such evaluation would be ok, but this is not the case. First, there is a high-res ensemble system, HREF and, second, HRRR could be post-processed with rather simple techniques to improve its skill. I happened to be working on some HRRR/HREF evaluation at the moment, so in the paragraphs below I will demonstrate my arguments using data.\n\nHREF is a multi-model ensemble that consists of 5 different models, each with another lagged version, so 10 members in total. Unfortunately, I was unable to find a preassembled version of HREF which is why I had to build the ensemble myself. Here I made one simplification to the operational version. For HRRR, I used a 12h lag (as for all the other models), instead of the operational 6h lag. The actual HREF, therefore, is likely a little bit better. Also, I am working with 6h accumulations, so much coarser in time compared to the present paper but I believe that my key results would be similar for different accumulation windows.\n\nI computed the CSI for HRRR and HREF for a 20 mm / 6 h threshold for a 6-12 h lead time accumulation window (results are qualitatively similar for other thresholds). For HREF I used a probability threshold of 0.1 to convert the ensemble probabilities into a binary field (in fact, how to do this is another key question, see comment below). For HRRR I get a CSI of 0.075, for HREF 0.11, so around 50% better. Looking at the improvements in the present paper, they are quite a bit larger than 50% for most lead times but the difference between HREF and HRRR is quite significant. To illustrate that HRRR could be post-processed very simply to improve its scores, I created a simple 10 member ensemble based on randomly shifting HRRR around by 20 km horizontally for each member. This makeshift HRRR ensemble also got a better CSI (0.087) than the original HRRR model. I did not spend any time tuning this. I suspect that you can do even better quite easily.\n\nIn summary, I hope I have convinced the authors that the present evaluation is not adequate. I believe that an evaluation against HREF is the way to go for this study. The lead metric then could be the BSS instead of the CSI. As mentioned before, I think the results will still be strong against HREF.\n\nOn a technical note, a description of HREF can be found here (https://www.essoar.org/pdfjs/10.1002/essoar.10501462.1) , data for the individual models is stored here: https://data.nssl.noaa.gov/thredds/catalog/catalog.html\n\nAnother key comment is on the availability of data and code. For any computational paper, the ability to look at the code is crucial for other researchers to build upon the study. I would strongly urge the authors to publish their code. At present, it would be very hard to impossible to exactly reconstruct the network structure from the paper. If, for some legal reason, this might not be possible, pseudo-code of the model architecture would also be acceptable. As for data, I understand that this is likely a huge amount of data. However, if the means exists to provide this data in an easily accessible cloud format, this would be a huge help to the community because some of the data can be hard to come by and download.\n\nOther comments:\n\nLine 6: I am not a science historian but I think the scientific study of weather has only really begun in the 19th century. This is also a very broad opening statement that doesn't really provide much relevant information. Section 2: I think the train/valid split has to be mentioned in the main text as it is crucial for ML studies. Line 355: How exactly is the train valid split done. This is crucial and should be described in detail.\n\nReviewer #2 (Remarks to the Author):\n\nThe presented work shows an interesting application of a complex neural network for probabilistic precipitation forecasting. The proposed network is compared with the predictions of a physicsbased numerical model, resulting more accurate even for high forecast times, up to 12h. The results are important from several points of view, for the accuracy of the prediction, for the extension of the evaluated domain, for its resolution and for the original solutions used in the architecture of the neural network employed. An additional reason of interest lies in the ability to also integrate NWP model predictions in a hybrid configuration. The work certainly represents a relevant contribution to the field of study, with interesting new elements compared to the state of the art. The analysis is conducted in a rigorous manner and described in sufficient accuracy and detail. However, there are some aspects that should be further investigated, also with reference to what has been proposed in the recent literature. In particular, it would be important to evaluate the performance of the model in terms of power spectral density of the predicted field at different spatial scales and for different forecast times. In similar systems there is a loss of signal definition for finer scales as the forecast time increases, this unintended feature of the neural network based forecast derives from the network optimization procedure which, while minimizing the loss function, devises \"effective\" smoothing of the solution. An analysis of the power spectral density for different forecast times also compared with the real data and with the HRRR model would be an interesting element that would allow to evaluate the effectiveness of the proposed solution.\n\nIn addition, the dataset used is of great interest and it would be useful if the authors could make public the same data, perhaps even highlighting a subset of the same, with cases of particular interest, to allow a comparison of results with other approaches and facilitate the advancement of research in this field.\n\nReviewer #3 (Remarks to the Author):\n\nIn this work the authors use neural networks to make precipitation forecasts over the continental USA, targeting short-range forecasting (0-12 hours). They test several forecasting paradigms: forecasting, post-processing forecasts and hybrid modelling incorporating data from both conventional forecasts and observations. By further developing the MetNet architecture the authors are able to improve predictions. On the longest assessed timescales the hybrid modelling produces the most accurate forecasts, however for most lead times the forecasting task is able to replicate the skill of the hybrid approach without using the time-evolved HRRR data. While some of the improvement over HRRR will stem from building a probabilistic output in contrast to the deterministic predictions of HRRR the differences between the results of the MNN Postprocess and other two networks show that the MNN is learning more than a probabilistic adaptation of the HRRR forecast. The is a very interesting piece of work, which not only builds a successful forecasting system but shines insight into how alternate forecasting paradigms compare. I also appreciated the section on interpretability.\n\nBelow I have a few minor questions/comments where I feel the authors could be clearer in their explanations and choices. After answering these I would be very happy for this submission to be accepted.\n\nL134: What is the motivation and methodology for downsampling from 2048 grid points to 512 grid points? L221: While I broadly agree with the conclusions, I think it's worth stating in the conclusions that none of the MNNs are fully physics-free as physics based models are currently necessary for the data-assimilation step. Perhaps in the long-term physics models can again be replaced here, but in this work the results still leverage physics models in each of the frameworks.\n\nL369: Please include the exact assimilated variables provided to the networks including what pressure levels. Perhaps this could be presented as a table.\n\nL389: Please be more specific in how you resample the data. Do you aim for a specific ratio of images with/without rain? It would have been interesting to see tests in how important this resampling was for performance. P16 Polyak Decay: please could the authors provide more detail about this parameter.\n\nL434: For accumulated precipitation training, how is this balanced in training. Is the network shown 30 2-minute instances for every 1h accumulated image?\n\nInterpretability: This section is very interesting, but I have a few questions. 1. For Figures 21, 22. For each field at each pressure level each input pixel will contribute to the prediction of a single truth pixel. How do you aggregate over the input pixels, are we seeing the largest value, ie most important pixel? 2. I understand that attributions can be compared between fields. Are you showing the most important fields? i.e. is the attribution of 0.005 for the MRMS 0h data in figure 21 the largest average importance that you observe across all inputs? 3. Do the pressure values of the dots in fig 22 (and similar) correspond to the model levels used in the HRRR data assimilation system or has there been an interpolation step? Figure 23: I think it would be helpful to plot the attribution of U and V with the same y-scale to aid comparison.\n\nL623: \"flow of horizontal wind towards the North\". I think this is an error and the authors mean East.\n\nFigure 24: Would it be possible to add some null test where we observe the attribution given to noise or an uncorrelated variable? Figure 25: Is this the attribution for the prediction of a single pixel of rain or for the 128x128 target? If so could this be indicated and explained.\n\n\nResponse to Reviewers\n\nManuscript NCOMMS-21-34503-T We kindly thank the reviewers for their insightful remarks. We start by listing the sections in the paper that received the most substantial updates:\n\n-Title and abstract -Results paragraph of Introduction (Section 1) -Dataset splits (Section 2.2) -Results (Section 4) -Supplemental Results (Supplement E) - Figures 1,2d,3,5,6,26 and Algorithm 1 -The model name was changed from \"MNN\" to \"MetNet-2\" throughout to indicate continuity with MetNet.\n\nIn the following we address the reviewers' remarks point-by-point.\n\nReviewer #1 (Remarks to the Author):\n\nThe authors present a study in which a neural network is used for short-term prediction of precipitation. The probabilistic model learns to predict precipitation patterns up to 12 hours ahead based on high-resolution observations. In another version of the model, it also uses high-resolution dynamical weather forecasts as input. The neural network predictions are compared to the aforementioned high-resolution model HRRR and favorable results are found at significant lead times.\n\nThis study presents a step forward in the application of neural networks for short-term precipitation forecasting. It builds upon previous work, most notably MetNet, by also incorporating other variables in the input, which, as the authors shows, has a significant positive impact on the prediction skill. Further, by merging the dynamical model predictions with the neural network, the authors combine the advantages of both approaches. The study also has a wide range of sensitivity experiments and generally shows a thorough evaluation.\n\nHowever, from what I can tell, there is one major flaw in this study. The key result of the paper is an improvement in the CSI, BS and CRPS compared to HRRR. The proposed method is a probabilistic model whereas HRRR is a deterministic model. This is like comparing apples to oranges. On the CSI, a binary, point-wise metric, deterministic forecasts will suffer strongly from the double penalty problem for highly intermittent fields like precipitation. A thresholded probabilistic forecast will be much smoother and therefore would be expected to result in a better score. (This is why for deterministic forecasts, neighborhood scores like the FSS are now standard.) On the other hand, using probabilistic metrics like the BS and CRPS on a deterministic forecast is simply not fair and obviously the score of almost any decent probabilistic forecast will be significantly better. If HRRR was indeed the only baseline to be used, such evaluation would be ok, but this is not the case. First, there is a high-res ensemble system, HREF and, second, HRRR could be post-processed with rather simple techniques to improve its skill. I happened to be working on some HRRR/HREF evaluation at the moment, so in the paragraphs below I will demonstrate my arguments using data.\n\nHREF is a multi-model ensemble that consists of 5 different models, each with another lagged version, so 10 members in total. Unfortunately, I was unable to find a preassembled version of HREF which is why I had to build the ensemble myself. Here I made one simplification to the operational version. For HRRR, I used a 12h lag (as for all the other models), instead of the operational 6h lag. The actual HREF, therefore, is likely a little bit better. Also, I am working with 6h accumulations, so much coarser in time compared to the present paper but I believe that my key results would be similar for different accumulation windows.\n\nI computed the CSI for HRRR and HREF for a 20 mm / 6 h threshold for a 6-12 h lead time accumulation window (results are qualitatively similar for other thresholds). For HREF I used a probability threshold of 0.1 to convert the ensemble probabilities into a binary field (in fact, how to do this is another key question, see comment below). For HRRR I get a CSI of 0.075, for HREF 0.11, so around 50% better. Looking at the improvements in the present paper, they are quite a bit larger than 50% for most lead times but the difference between HREF and HRRR is quite significant. To illustrate that HRRR could be post-processed very simply to improve its scores, I created a simple 10 member ensemble based on randomly shifting HRRR around by 20 km horizontally for each member. This makeshift HRRR ensemble also got a better CSI (0.087) than the original HRRR model. I did not spend any time tuning this. I suspect that you can do even better quite easily.\n\nIn summary, I hope I have convinced the authors that the present evaluation is not adequate. I believe that an evaluation against HREF is the way to go for this study. The lead metric then could be the BSS instead of the CSI. As mentioned before, I think the results will still be strong against HREF.\n\nOn a technical note, a description of HREF can be found here (https://www.essoar.org/pdfjs/10.1002/essoar.10501462.1) , data for the individual models is stored here: https://data.nssl.noaa.gov/thredds/catalog/catalog.html\n\nWe thank the reviewer for this important observation that we agree with. The original version didn't include a probabilistic baseline as we found it difficult to obtain data for it. We have now included this comparison and put emphasis in the manuscript on two major experiments:\n\nA. MetNet-2 vs HREF, evaluation using CRPS and CSI, on hourly cumulative precipitation; B. MetNet-2 Hybrid vs MetNet-2 Postprocess, evaluation using CRPS and CSI, on hourly cumulative and instantaneous precipitation.\n\nWe have included HRRR as an informative reference in these comparisons. We find indeed that HREF is better than HRRR. The rephrasing affects many parts of the paper, including abstract, introduction and results sections in the main text and the appendix.\n\nAnother key comment is on the availability of data and code. For any computational paper, the ability to look at the code is crucial for other researchers to build upon the study. I would strongly urge the authors to publish their code. At present, it would be very hard to impossible to exactly reconstruct the network structure from the paper. If, for some legal reason, this might not be possible, pseudo-code of the model architecture would also be acceptable.\n\nWe have currently added pseudocode in the appendix for the model. We will also make the model code available through a shared notebook in such a way that dummy inputs can be passed through it (see Code Availability section).\n\nAs for data, I understand that this is likely a huge amount of data. However, if the means exists to provide this data in an easily accessible cloud format, this would be a huge help to the community because some of the data can be hard to come by and download.\n\nWe agree that such a benchmark would be very helpful to the community. Unfortunately, the large size of the data, the relative complexity of the infrastructure used to access it and to generate training and evaluation sets and, just as importantly, many licensing restrictions for the reproduction of the different data sources do not allow us to release the benchmark data. However, all the data is publicly accessible and can be downloaded independently by other researchers. We point this out in the Data Availability section.\n\nOther comments:\n\nLine 6: I am not a science historian but I think the scientific study of weather has only really begun in the 19th century. This is also a very broad opening statement that doesn't really provide much relevant information.\n\nDone. We removed the broad opening statement. Done.\n\nSection 2: I think the train/valid split has to be mentioned in the main text as it is crucial for ML studies.\n\nDone. We have added Section 2.2 in the main text devoted entirely to this. Done.\n\nLine 175 and 397: How exactly do you determine the threshold to convert probabilistic forecasts to binary fields. Do you choose the threshold which gives you the best CSI on a validation set? How do you choose this validation set exactly?\n\nThat's correct. We choose thresholds that give the best CSI on the validation set for each precipitation rate and each lead time. The added Section 2.2 also describes the creation of the validation set (random patches, non-overlapping time periods). The probabilistic CRPS metric does not rely on thresholds. We added a detailed description of what the \"3d-like contour plots\" represent. See caption to the figure (now Figure 6).\n\nLine 355: How exactly is the train valid split done. This is crucial and should be described in detail.\n\nWe have added Section 2.2 in the main text and we have also added more details here in the appendix.\n\nReviewer #2 (Remarks to the Author):\n\nThe presented work shows an interesting application of a complex neural network for probabilistic precipitation forecasting. The proposed network is compared with the predictions of a physics-based numerical model, resulting more accurate even for high forecast times, up to 12h. The results are important from several points of view, for the accuracy of the prediction, for the extension of the evaluated domain, for its resolution and for the original solutions used in the architecture of the neural network employed. An additional reason of interest lies in the ability to also integrate NWP model predictions in a hybrid configuration. The work certainly represents a relevant contribution to the field of study, with interesting new elements compared to the state of the art. The analysis is conducted in a rigorous manner and described in sufficient accuracy and detail. However, there are some aspects that should be further investigated, also with reference to what has been proposed in the recent literature.\n\nIn particular, it would be important to evaluate the performance of the model in terms of power spectral density of the predicted field at different spatial scales and for different forecast times.\n\nIn similar systems there is a loss of signal definition for finer scales as the forecast time increases, this unintended feature of the neural network based forecast derives from the network optimization procedure which, while minimizing the loss function, devises \"effective\" smoothing of the solution. An analysis of the power spectral density for different forecast times also compared with the real data and with the HRRR model would be an interesting element that would allow to evaluate the effectiveness of the proposed solution.\n\nThank you for the remark. We would like to make a few points here:\n\n-We evaluate the models as to their ability to predict the target variables. We quantify the probabilistic error of the models with respect to the target (using CRPS and BS) and the models' ability to capture categorical precision/recall via metrics such as CSI. To the best of our understanding, the power spectral density doesn't evaluate the ability of the models to predict the targets so we do not find it directly relevant to support our main results. -Probabilistic models are designed to capture all the variability and the uncertainty of the prediction. As such the predicted contours, depending on what is visualized, will naturally tend to be smoother. We think of this as a feature, not as a bug. We can see this in the HREF model too, that ensembles 10 rollouts and produces smoother regions of prediction as a result. -Physics-based rollouts can have emerging phenomena that are informative from a meteorological perspective. In an end-to-end approach these phenomena could be predicted directly by the model (as supposed to be implicitly visualized by the rollout) -a process that could require additional annotation, but is beyond the scope of the current manuscript.\n\nWe hope that these points help address the remark and explain why we don't find evaluation with the power spectral density metric relevant for the manuscript's results.\n\nIn addition, the dataset used is of great interest and it would be useful if the authors could make public the same data, perhaps even highlighting a subset of the same, with cases of particular interest, to allow a comparison of results with other approaches and facilitate the advancement of research in this field.\n\nThank you for this remark. Please see the response to the same request to reviewer #1 above.\n\nReviewer #3 (Remarks to the Author):\n\nIn this work the authors use neural networks to make precipitation forecasts over the continental USA, targeting short-range forecasting (0-12 hours). They test several forecasting paradigms: forecasting, post-processing forecasts and hybrid modelling incorporating data from both conventional forecasts and observations. By further developing the MetNet architecture the authors are able to improve predictions. On the longest assessed timescales the hybrid modelling produces the most accurate forecasts, however for most lead times the forecasting task is able to replicate the skill of the hybrid approach without using the time-evolved HRRR data. While some of the improvement over HRRR will stem from building a probabilistic output in contrast to the deterministic predictions of HRRR the differences between the results of the MNN Postprocess and other two networks show that the MNN is learning more than a probabilistic adaptation of the HRRR forecast. The is a very interesting piece of work, which not only builds a successful forecasting system but shines insight into how alternate forecasting paradigms compare. I also appreciated the section on interpretability.\n\nBelow I have a few minor questions/comments where I feel the authors could be clearer in their explanations and choices. After answering these I would be very happy for this submission to be accepted.\n\nL134: What is the motivation and methodology for downsampling from 2048 grid points to 512 grid points?\n\nDownsampling is performed via simple averaging of each 4 by 4 patch of features. The motivation is to encode the context more efficiently while still maintaining a good amount of information in the context. We rephrased and clarified this in the paper (line 164).\n\nL221: While I broadly agree with the conclusions, I think it's worth stating in the conclusions that none of the MNNs are fully physics-free as physics based models are currently necessary for the data-assimilation step. Perhaps in the long-term physics models can again be replaced here, but in this work the results still leverage physics models in each of the frameworks.\n\nDone. We have specified this throughout the manuscript. No. The network is shown on average the same number of hourly cumulative and instantaneous target patches during training.\n\nInterpretability: This section is very interesting, but I have a few questions. 1. For Figures 21, 22. For each field at each pressure level each input pixel will contribute to the prediction of a single truth pixel. How do you aggregate over the input pixels, are we seeing the largest value, ie most important pixel?\n\nWe aggregate by taking the sum of the absolute values over all input pixels and all prediction pixels for each field at each pressure level. We then take an average of that over the input and prediction pixels to obtain the plots for each field at each pressure level. Hence, what we see here are the important fields on average for each input and prediction pixel.\n\n2. I understand that attributions can be compared between fields. Are you showing the most important fields? i.e. is the attribution of 0.005 for the MRMS 0h data in figure 21 the largest average importance that you observe across all inputs?\n\nThat's correct, the attributions can be compared between fields and therefore the plots themselves can be compared with each other. It's also right that MRMS 0hr input is indeed that most important input across all inputs, which is also intuitively correct. Since we are predicting MRMS future values, the latest MRMS value should indeed provide the model with most information to make a prediction.\n\n3. Do the pressure values of the dots in fig 22 (and similar) correspond to the model levels used in the HRRR data assimilation system or has there been an interpolation step?\n\nThe pressure values at the dots exactly correspond to the levels in HRRR data assimilation. They are 25 hPa apart. L623: \"flow of horizontal wind towards the North\". I think this is an error and the authors mean East.\n\nCorrected, thanks.\n\nFigure 24: Would it be possible to add some null test where we observe the attribution given to noise or an uncorrelated variable?\n\nThis would require substantial retraining of the networks. But as observed in most neural networks, the weights attached to input that is random noise will likely go to zero as training progresses. Thus any attribution to that input noise should also be insignificant. Figure 25: Is this the attribution for the prediction of a single pixel of rain or for the 128x128 target? If so could this be indicated and explained.\n\nFigure 1 :\n1It would be easier if the text was a little larger.\n\nFigure 2d :\n2dIn the sketch of the NN design, it would be super helpful if you added the tensor size for each layer.Line 175 and 397: How exactly do you determine the threshold to convert probabilistic forecasts to binary fields. Do you choose the threshold which gives you the best CSI on a validation set? How do you choose this validation set exactly?Figure 4d: I don't think I quite understand what is shown here. Maybe this is connected to my confusion about the probability thresholding.\n\nFigure 1 :\n1It would be easier if the text was a little larger.\n\nFigure 2d :\n2dIn the sketch of the NN design, it would be super helpful if you added the tensor size for each layer.\n\nFigure 4d :\n4dI don't think I quite understand what is shown here. Maybe this is connected to my confusion about the probability thresholding.\n\nFigure 23 :\n23I think it would be helpful to plot the attribution of U and V with the same y-scale to aid comparison.Done. See newFigure 27.\n\nL369 :\nL369Please include the exact assimilated variables provided to the networks including what pressure levels. Perhaps this could be presented as a table.The network includes all available HRRR initial state variables. We provide a link to a website with a table (https://home.chpc.utah.edu/~u0553130/Brian_Blaylock/HRRR_archive/hrrr_prs_table_f00-f01.h tml). Reference added to the manuscript (line 110).L389: Please be more specific in how you resample the data. Do you aim for a specific ratio of images with/without rain? It would have been interesting to see tests in how important this resampling was for performance.The resampling doesn't affect performance much, but it increases the convergence speed during training making model iterations somewhat faster. We made this clearer in the paper. P16 Polyak Decay: please could the authors provide more detail about this parameter.It is a parameter used for smoothing the effects of the stochastic gradient descent updates during training. Polyak decay or averaging keeps an exponentially-decaying running average of the weights of the network. At validation and test time, the averaged weights are used instead of the weights from the very last update of the training procedure. See Tensorflow documentation for reference: https://www.tensorflow.org/api_docs/python/tf/train/ExponentialMovingAverage . L434: For accumulated precipitation training, how is this balanced in training. Is the network shown 30 2-minute instances for every 1h accumulated image?\nIt is the attribution for the full 128x128 target. We clarified this in the caption.REVIEWERS' COMMENTSReviewer #1 (Remarks to the Author):I would like to thank the authors for their thorough revisions to the paper. From my own experience, I know that compiling the HREF data is not trivial, so I really appreciate the effort. I believe the paper is significantly stronger for it. This paper is an important contribution to the field. I recommend to accept the paper with a few minor comments below. Also, sorry for taking a long time with my review and delaying the process.StephanRasp   Fig 1.In this figure I believe that the order of physics and ensembling for an NWP ensemble would make sense the other way around. Typically the ensembling, i.e. starting at different initial conditions and with different models happens before the simulation. As it's currently displayed readers might get the wrong idea that the ensembling for NWP ensembles happens after the physical simulations are run. Section 4.1 \"obtains a higher CRPS than HREF\". This should be lower I believe.CSI plots. I think it would help with the interpretability of the CSI plots if they all started at 0 on the y-axis.Reviewer #2 (Remarks to the Author):The authors have thoroughly addressed my comments, the paper is worthy of publication in its current form Reviewer #3 (Remarks to the Author):I thank the authors for their changes and updated manuscript. I would be happy to accept the manuscript for publication. Below I outline I a few minor points that I would appreciate if the authors examine. I would like to congratulate the authors on an excellent publication. Section D. This pseudo-code and diagram are very help. Could the authors expand upon the dense projections in D1. If I have understood the input for each projection is a scalar representing the lead-time and the output is a scalar to be used in either an additive or multiplicative manner. Is there a hidden state in this mapping of scalar to scalar? If so, how large. Section G. Could the authors please clarify what they mean by baseline input x', perhaps through use of an example. Thanks.Response to ReviewersManuscript NCOMMS-21-34503-T We kindly thank the reviewers for their insightful final remarks. We address each in turn.Reviewer #1 (Remarks to the Author):I would like to thank the authors for their thorough revisions to the paper. From my own experience, I know that compiling the HREF data is not trivial, so I really appreciate the effort. I believe the paper is significantly stronger for it. This paper is an important contribution to the field. I recommend to accept the paper with a few minor comments below. Also, sorry for taking a long time with my review and delaying the process.StephanRasp   Fig 1.In this figure I believe that the order of physics and ensembling for an NWP ensemble would make sense the other way around. Typically the ensembling, i.e. starting at different initial conditions and with different models happens before the simulation. As it's currently displayed readers might get the wrong idea that the ensembling for NWP ensembles happens after the physical simulations are run.Done. Thanks for the comment. We rephrased this part of the figure and hopefully it is clearer now.Section 4.1 \"obtains a higher CRPS than HREF\". This should be lower I believe.Done.CSI plots. I think it would help with the interpretability of the CSI plots if they all started at 0 on the y-axis.Done.Reviewer #2 (Remarks to the Author):The authors have thoroughly addressed my comments, the paper is worthy of publication in its current form Reviewer #3 (Remarks to the Author): I thank the authors for their changes and updated manuscript. I would be happy to accept the manuscript for publication. Below I outline I a few minor points that I would appreciate if the authors examine. I would like to congratulate the authors on an excellent publication. Done adding baselines in all the ablation study captions. We don't add results for time t0 in these specific diagrams due to consistency with all other diagrams as it would be substantial recomputing and editing work. HRRR's t0 results are somewhat lower than 100 due to the modifying effects of assimilation.Section D. This pseudo-code and diagram are very help. Could the authors expand upon the dense projections in D1. If I have understood the input for each projection is a scalar representing the lead-time and the output is a scalar to be used in either an additive or multiplicative manner. Is there a hidden state in this mapping of scalar to scalar? If so, how large.It is a 1-D vector to vector mapping. The lead time is converted to a one-hot projection of size #Lead time. A shallow MLP maps this to two vectors (one vector additive + one vector multiplicative) with dimensions equal to the hidden size of the residual network. The shallow MLP consists of a single layer and 512 hidden dimensions. Section G. Could the authors please clarify what they mean by baseline input x', perhaps through use of an example. Thanks.Done.", "annotations": {"author": null, "publisher": null, "author_last_name": null, "author_first_name": null, "author_affiliation": null, "title": "[{\"end\":125,\"start\":1},{\"end\":252,\"start\":128}]", "venue": null, "abstract": null, "bib_ref": null, "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":29733,\"start\":29669},{\"attributes\":{\"id\":\"fig_1\"},\"end\":30228,\"start\":29734},{\"attributes\":{\"id\":\"fig_2\"},\"end\":30293,\"start\":30229},{\"attributes\":{\"id\":\"fig_3\"},\"end\":30411,\"start\":30294},{\"attributes\":{\"id\":\"fig_4\"},\"end\":30555,\"start\":30412},{\"attributes\":{\"id\":\"fig_5\"},\"end\":30697,\"start\":30556},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":32215,\"start\":30698}]", "paragraph": "[{\"end\":1777,\"start\":1296},{\"end\":2318,\"start\":1779},{\"end\":3586,\"start\":2320},{\"end\":4223,\"start\":3588},{\"end\":5181,\"start\":4225},{\"end\":5484,\"start\":5183},{\"end\":5708,\"start\":5486},{\"end\":6436,\"start\":5710},{\"end\":6453,\"start\":6438},{\"end\":6892,\"start\":6455},{\"end\":6930,\"start\":6894},{\"end\":8684,\"start\":6932},{\"end\":9003,\"start\":8686},{\"end\":9041,\"start\":9005},{\"end\":10221,\"start\":9043},{\"end\":10423,\"start\":10223},{\"end\":10903,\"start\":10425},{\"end\":11058,\"start\":10905},{\"end\":11363,\"start\":11060},{\"end\":11519,\"start\":11365},{\"end\":12373,\"start\":11521},{\"end\":12477,\"start\":12375},{\"end\":12761,\"start\":12479},{\"end\":12965,\"start\":12787},{\"end\":13261,\"start\":12967},{\"end\":13329,\"start\":13263},{\"end\":13367,\"start\":13331},{\"end\":13851,\"start\":13369},{\"end\":14392,\"start\":13853},{\"end\":15660,\"start\":14394},{\"end\":16297,\"start\":15662},{\"end\":17255,\"start\":16299},{\"end\":17558,\"start\":17257},{\"end\":17782,\"start\":17560},{\"end\":18063,\"start\":17784},{\"end\":18281,\"start\":18065},{\"end\":18537,\"start\":18283},{\"end\":19003,\"start\":18539},{\"end\":19229,\"start\":19005},{\"end\":19492,\"start\":19231},{\"end\":20023,\"start\":19494},{\"end\":20040,\"start\":20025},{\"end\":20264,\"start\":20042},{\"end\":20317,\"start\":20266},{\"end\":20429,\"start\":20319},{\"end\":20511,\"start\":20431},{\"end\":20751,\"start\":20513},{\"end\":21182,\"start\":20753},{\"end\":21287,\"start\":21184},{\"end\":21389,\"start\":21289},{\"end\":21427,\"start\":21391},{\"end\":22447,\"start\":21429},{\"end\":22646,\"start\":22449},{\"end\":23184,\"start\":22648},{\"end\":23252,\"start\":23186},{\"end\":24437,\"start\":23254},{\"end\":24607,\"start\":24439},{\"end\":24926,\"start\":24609},{\"end\":25020,\"start\":24928},{\"end\":25058,\"start\":25022},{\"end\":26238,\"start\":25060},{\"end\":26440,\"start\":26240},{\"end\":26545,\"start\":26442},{\"end\":26810,\"start\":26547},{\"end\":27186,\"start\":26812},{\"end\":27366,\"start\":27188},{\"end\":27686,\"start\":27368},{\"end\":28053,\"start\":27688},{\"end\":28297,\"start\":28055},{\"end\":28698,\"start\":28299},{\"end\":28875,\"start\":28700},{\"end\":29094,\"start\":28877},{\"end\":29114,\"start\":29096},{\"end\":29246,\"start\":29116},{\"end\":29668,\"start\":29248}]", "formula": null, "table_ref": null, "section_header": "[{\"end\":12785,\"start\":12764},{\"end\":29680,\"start\":29670},{\"end\":29746,\"start\":29735},{\"end\":30240,\"start\":30230},{\"end\":30306,\"start\":30295},{\"end\":30424,\"start\":30413},{\"end\":30568,\"start\":30557},{\"end\":30705,\"start\":30699}]", "table": null, "figure_caption": "[{\"end\":29733,\"start\":29682},{\"end\":30228,\"start\":29749},{\"end\":30293,\"start\":30242},{\"end\":30411,\"start\":30309},{\"end\":30555,\"start\":30427},{\"end\":30697,\"start\":30571},{\"end\":32215,\"start\":30710}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":11622,\"start\":11604},{\"end\":12132,\"start\":12124},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":12268,\"start\":12259},{\"end\":12619,\"start\":12610},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":13136,\"start\":13124},{\"end\":21180,\"start\":21172},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":27469,\"start\":27451},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":28230,\"start\":28221},{\"end\":28749,\"start\":28741},{\"end\":29526,\"start\":29517}]", "bib_author_first_name": null, "bib_author_last_name": null, "bib_entry": null, "bib_title": null, "bib_author": null, "bib_venue": null}}}, "year": 2023, "month": 12, "day": 17}