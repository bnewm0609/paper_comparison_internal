{"id": 237099500, "updated": "2023-04-04 22:49:10.286", "metadata": {"title": "Linking CVE\u2019s to MITRE ATT&CK Techniques", "authors": "[{\"first\":\"Aditya\",\"last\":\"Kuppa\",\"middle\":[]},{\"first\":\"Lamine\",\"last\":\"Aouad\",\"middle\":[]},{\"first\":\"Nhien-An\",\"last\":\"Le-Khac\",\"middle\":[]}]", "venue": null, "journal": "Proceedings of the 16th International Conference on Availability, Reliability and Security", "publication_date": {"year": 2021, "month": null, "day": null}, "abstract": "The MITRE Corporation is a non-profit organization that has made substantial efforts into creating and maintaining knowledge bases relevant to cybersecurity and has been widely adopted by the community. ATT&CK \u201dAdversarial Tactics, Techniques, and Common Knowledge\u201d is a popular taxonomy by MITRE, which describes threat actor behaviors. Techniques are the foundation of the ATT&CK model, they are the actions that adversaries perform to accomplish goals, which translate into the model\u2019s tactics. The aim of ATT&CK is to categorize adversary behavior to help improve the post-compromise detection of advanced intrusions. Software vulnerabilities (CVE) play an important role in cyber-intrusions, mostly classified into 4 ATT&CK techniques, which cover the exploitation phase of the attack chain. Identifying vulnerabilities that are actively exploited by the attackers, and understanding how a vulnerability can enable the attacker at each stage of the attack life cycle is absolutely critical for vulnerability assessments. Given the sparse classification of a CVE into ATT&CK taxonomy, lack of methods to extract labels from threat reports and, the volume of vulnerabilities disclosed defenders lack a concrete approach to prioritize CVE\u2019s based on their role in the attack chain and in the context of controls in place. In this work, we propose a Multi-Head Joint Embedding Neural Network model to automatically map CVE\u2019s to ATT&CK techniques. We address the problem of lack of labels for this task, by a novel unsupervised labeling technique. We enrich CVE\u2019s with a curated knowledgebase 50 mitigation strategies, which help the model to learn both attacker and defender view of a given CVE. We evaluate our approach with the dataset containing CVE\u2019s disclosed from the past 10 years and compare it with standard baseline models and ablation analysis. Using the proposed model, we mapped 62,000 CVE records to 37 different ATT&CK techniques and show that the proposed multi head design performs well in the absence of labels in the training dataset.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/IEEEares/KuppaAL21", "doi": "10.1145/3465481.3465758"}}, "content": {"source": {"pdf_hash": "815eb6058eb8813f1982b5a62445ed05381079dc", "pdf_src": "ACM", "pdf_uri": null, "oa_url_match": false, "oa_info": {"license": null, "open_access_url": "https://dl.acm.org/doi/pdf/10.1145/3465481.3465758", "status": "BRONZE"}}, "grobid": {"id": "03706792b5459b3278872a99a1af187c4fc663d3", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/815eb6058eb8813f1982b5a62445ed05381079dc.txt", "contents": "\nto MITRE ATT&CK Techniques\nACMCopyright ACMAugust 17-20, 2021. August 17-20, 2021\n\nAditya Kuppa aditya.kuppa@ucdconnect.ie \nUniversity College\nDublin Ireland\n\nLamine Aouad laouad@tenable.com \nTenable Corporation\nFrance\n\nNhien-An Le-Khac an.lekhac@ucd.ie \nUniversity College\nDublin Ireland\n\nto MITRE ATT&CK Techniques\n\nThe 16th International Conference on Availability, Reliability and Security (ARES 2021)\nVienna, Austria; Vienna, Austria; New York, NY, USAACM12August 17-20, 2021. August 17-20, 2021This work is licensed under a Creative Commons Attribution International 4.0 License.CCS CONCEPTS \u2022 Security and privacy \u2192 Vulnerability scannersSoftware se- curity engineering\u2022 Computing methodologies \u2192 Information extractionKnowledge representation and reasoning KEYWORDS CVE, Attack Models, Deep Learning, ATT&CK , unsupervised la- beling ACM Reference Format: Aditya Kuppa, Lamine Aouad, and Nhien-An Le-Khac 2021 Linking CVE's\nThe MITRE Corporation is a non-profit organization that has made substantial efforts into creating and maintaining knowledge bases relevant to cybersecurity and has been widely adopted by the community. ATT&CK \"Adversarial Tactics, Techniques, and Common Knowledge\" is a popular taxonomy by MITRE, which describes threat actor behaviors. Techniques are the foundation of the ATT&CK model, they are the actions that adversaries perform to accomplish goals, which translate into the model's tactics. The aim of ATT&CK is to categorize adversary behavior to help improve the post-compromise detection of advanced intrusions.Software vulnerabilities (CVE) play an important role in cyberintrusions, mostly classified into 4 ATT&CK techniques, which cover the exploitation phase of the attack chain. Identifying vulnerabilities that are actively exploited by the attackers, and understanding how a vulnerability can enable the attacker at each stage of the attack life cycle is absolutely critical for vulnerability assessments. Given the sparse classification of a CVE into ATT&CK taxonomy, lack of methods to extract labels from threat reports and, the volume of vulnerabilities disclosed defenders lack a concrete approach to prioritize CVE's based on their role in the attack chain and in the context of controls in place.In this work, we propose a Multi-Head Joint Embedding Neural Network model to automatically map CVE's to ATT&CK techniques. We address the problem of lack of labels for this task, by a novel unsupervised labeling technique. We enrich CVE's with a curated knowledgebase 50 mitigation strategies, which help the model to learn both attacker and defender view of a given CVE. We evaluate our approach with the dataset containing CVE's disclosed from the past 10 years and compare it with standard baseline models and ablation analysis. Using the proposed model, we mapped 62, 000 CVE records to 37 different ATT&CK techniques and show that the proposed multi head design performs well in the absence of labels in the training dataset.\n\nINTRODUCTION\n\nImproving security and reducing risk are two of the main concerns, and challenges, for most organizations today. The increasing volume of vulnerabilities, the frenetic expansion of the attack surface, the increasing sophistication of attacks and attackers, and multiple other technological and human factors are making cybersecurity the most critical challenge of the digital age. The rise in the number of high-impact vulnerabilities and the complexity of underlying systems opens up an opportunity for an adversary to exploit the vulnerability to achieve his/her goals.\n\nFurthermore, attacks or incidents in cyberspace have a few unique characteristics that make them particularly challenging to defend against. An intrusion can span across multiple stages [2], for instance, attackers can use techniques like drive-by-download [3] or spear-phishing [4] for initial compromise and weaponize a variety of vulnerabilities for reconnaissance, Command and Control (C&C) communications, privilege escalation, lateral movement, and exfiltration stages of the attack.\n\nTo efficiently assess and reduce risk, common practice security practitioners follow is to periodically scan assets for known vulnerabilities and improve their security posture by patching the identified vulnerabilities. It may not always be obvious \"which\" systems have \"what\" vulnerabilities and \"how\" attackers can exploit these vulnerable systems [32,35]. Also, the vast majority of attacks in the wild are carried by a handful of vulnerabilities [1,5], and the refresh time of attacks in the wild is as slow as around 600 days (i.e. the same exploits are re-used in the wild for almost two years before they are substituted at scale with a new attack) [7]. We surveyed 690 publicly documented advanced cyber intrusion reports from the past 10 years, which describe different attack steps of advanced cyber intrusions and we also infer similar observation that less than 500 CVE's are actively exploited by attackers in their attack campaigns. To address this asymmetry various risk models have been proposed to help defenders prioritize important and relevant vulnerabilities relevant to the environment, risk appetite, and controls in place.\n\nUnderstanding the attacker's choice of vulnerability for a particular attack stage is a hard problem and often measured by the exploit availability, reusability, ease, opportunity/development cost,   1 . Also, low complexity vulnerabilities for which a reliable exploit can be easily engineered lower the production costs 2 and favor the deployment of the exploit [7,10]. Finally, Allodi and Etalle [10] developed an attacker threat model for SCADA systems and provide evidence that suggests that attackers do not arbitrarily choose vulnerabilities to exploit amongst all available options, and a new vulnerability in a system carries little weight on the overall risk scenario, as most attackers would not be able to exploit it (unless commoditized). A genuine effort from academic, industry, and government agencies is made to create common knowledge bases to address the need of understanding attacker behaviors. The ATT&CK (Adversarial Tactics, Techniques, and Common Knowledge) has gained popularity in recent years for multiple purposes and has been integrated into popular threat information sharing technologies [11]. ATT&CK is a community-curated knowledge base with the taxonomy of adversaries' tactics and techniques, and information about known techniques used by named attackers. The framework defines attacker actions in an extensive manner and is frequently updated. Table 1 lists documented CVE's used by different attack groups collected from the past 10 years, but there is no complete understanding of which stage of attack chain the CVE is used or what are the other similar CVE's that can be used against a given environment. Although threat behaviors are used to report cyber attacks using the ATT&CK standard, yet there is no end-to-end approach that captures the role of Common Vulnerabilities and Exposures (CVEs) into different attack stages. Grouping CVE's by ATT&CK techniques helps quantitatively re-prioritize vulnerability risks according to attack stage defined in ATT&CK and in the context of controls. This mapping can also help in prioritizing vulnerability assessments, setting risk model parameters, defenders mitigation strategies, and understanding the attacker's actions. The same CVE's when mapped to corresponding ATT&CK techniques and tactics can help defenders to correctly assess the risk and understand which stage of the attack cycle the corresponding CVE's are being used. Figure 1 illustrates a heat map of CVE count of each MITRE ATT&CK tactics, techniques found in the wild.\n\nLet us explain the problem premise with an example, lets take the case of the \"Win32k.sys\" kernel-mode device driver vulnerability, which allows a local or remote attacker to execute arbitrary code in kernel mode with elevated privileges. Over the years multiple vulnerabilities have been disclosed that effect this kernel-mode driver, and advanced attackers have leveraged these vulnerabilities in their attack campaigns. Let's look closely the disclosed vulnerabilities between 2010-2016. These vulnerabilities can be Given the potentially positive impact that an effective automated system, which maps CVE's to ATT&CK techniques has on defenders vulnerability assessment processes, in this paper, we design and implement a novel technique for this problem based upon Natural Language Processing (NLP) techniques and Multi-Label Text Classification(MLTC) models. For the MLTC task, we treat the semantic representation of Security Vulnerabilities (SV) as features and ATT&CK techniques as labels. The large corpora of security vulnerabilities descriptions and their properties: (a) attack steps to exploit the vulnerability; (b) mitigation steps and security controls to avoid exploitation; (c) high-level features and ATT&CK descriptions can be mined to learn rich semantic embeddings. We employ different feature extractors based on the structural and information properties of the text.\n\nTraditional techniques link CVE's in threat reports to MITRE techniques using a series of regular expressions which may miss the semantic connection between the nature of technique leveraged within the scope of the threat introduced by CVE. We address this problem by devising a novel labeling method based on attack techniques descriptions and CVE's text in real-life intrusions. Paragraphs containing CVE descriptions are extracted from threat reports by employing a set of regular expressions, then by using element-wise operations we create vector representations of multi-word units leveraging the word representations of both attack techniques descriptions and threat reports we link to one another on the basis of their distance in vector space. The proposed MLTC model consists of a three head joint non-linear input-label embeddings and a joint-space-dependent classification unit, which is trained with the cross-entropy loss to optimize classification performance. The parametrization of the output layer is controlled by the dimensionality of the joint encoding, which makes sure we are not constrained by the dimensionality of the input or label encoding, but is instead flexible.\n\nIn summary, the primary contributions of this paper are as follows:\n\n\u2022 We introduce the Multi-Label Text Classification task for mapping of CVE's to ATT&CK techniques from textual descriptions and propose a multi-head joint embedding neural network architecture. \u2022 We address the problem of lacking labels for this task by a novel unsupervised labeling technique, which extracts phrases from threat reports and ATT&CK technique descriptions. We could map 17 techniques via our labeling technique. We create a knowledge base of 150 attack scenarios for exploiting vulnerabilities and 50 mitigation strategies to enrich textual descriptions of CVE's. This helps the model to learn both attacker and defender views of the given CVE. \u2022 We evaluate our approach with a dataset with the past 10 years CVE dataset and compare the proposed model with standard baseline models and perform the ablation analysis to highlight the importance of each model component. We additionally find that the model can link 20 additional techniques which are not seen in the training dataset showing the proposed multi-head approach is generalizable in the given settings.\n\nThe rest of this paper is organised as follows: Section 2 presents our research motivation through an example. We discuss our approach in detail in Section 3. Our experiments and discussion are illustrated in Section 4. Section 5 belongs to related work on mapping CVE's to ATT&CK techniques. Finally, we provide a conclusion in Sections 6.\n\n\nMOTIVATING EXAMPLE\n\nIn this section, we explain the motivation of our research with a concrete example. The CVE-2017-8759 vulnerability was exploited in advanced intrusions with victims 3 4 spread across Russia, Iraq, Afghanistan, Nigeria, Libya, Jordan, Tunisia, Saudi Arabia, Iran, Netherlands, Bahrain, United Kingdom and Angola. This CVE can be used by attackers either to gain initial access or move around the network via a privilege escalation and can be mapped to MITRE ATT&CK techniques \"User Execution, Exploitation of Remote Services\".\n\nThere are two known attack scenarios for attackers (a) Documentbased in which the attacker crafts a malicious document, which may include malicious code, replacement memory addresses, and possibly NOP instructions. The attacker uses email or other means to entice an unsuspecting user to view the malicious document executing attacker's code in the context of an application, and (b) Application-based in which the attacker constructs a malicious .NET application and uploads it to a network share. This network share can be inside the organization network (lateral movement) or outside of company network (initial access) depending on the attack stage of the intrusion.\n\nSimilarly, the defender can follow multiple mitigation steps and configure controls to avoid and get visibility into the attacker actions: (a) Deploy intrusion detection systems to monitor the network traffic for signs of anomalous or suspicious activity to get alerts on the application-based attack scenario; (b) Filtering and monitoring the email traffic for malicious links and attachments to avoid document-based attack scenario; (c) Enabling memoryprotection schemes and running non-administrative software as an unprivileged user with minimal access rights, which can reduce the attack surface, and (d) Timely patching and maintaining the good security hygiene. Knowing the ATT&CK technique for a given CVE, defenders can assess the risk of the CVE based on which attack stage attackers may use the CVE, and deploy controls to monitor the intrusions. Furthermore, he/she can group techniques by tactics to prioritize vulnerabilities for patching. Figure 2 lists different features of a CVE with its ATT&CK stages.\n\n\nAPPROACH\n\nBefore delving deeper into the proposed system, we give a highlevel overview and motivation of the approach. The dataset collected has no labels i.e. there is no mapping of ATT&CK techniques for a given CVE. Though there are 4 techniques Exploit Public-Facing Application, Exploitation for Client Execution, Exploitation for Privilege Escalation, Exploitation of Remote Services, which cover the exploitation phase of the attack chain but there are no granular categories that can be mapped. To address this constraint we devise an unsupervised labeling process to extract labels from the threat reports and CVE's. As astute readers may note that not all CVE's are covered in threat reports, and we could link only 17 techniques to the CVE's in the dataset. To improve the coverage and make the system more generalizable we propose an MLTC system that takes into consideration not only the labels in the training set i.e. 17 techniques but also covers techniques for which there are threat reports.\n\n\nLabeling Process\n\nHere we describe the overall process we followed in our labeling pipeline. In the proposed unsupervised labeling process we have two major steps -(1) A robust feature extractor that can project CVE and ATT&CK data distributions into a common representation; and (2) A distance function that measures the similarity/dissimilarity between the common representations and assign ATT&CK technique to CVE. Figure 3 illustrate the labeling pipeline with different components.\n\nCommon Representations: First, we identify CVE's used in particular attacks or malware from the reports scrapped using CVE specific regular expressions. Next, we extract paragraphs from the report in which CVE was mentioned. Now to extract context words surrounding the CVE, we use Spacy 5 to extract all noun and verb phrases from the paragraphs as candidates. For each candidate, we extract all words within the phrase, and the surrounding right and left context words to each side of the phrase, obtaining three separate sequences of words: left context, the phrase, and the right context. For example, below is a sentence from a threat report for , and eventually launches a FINSPY payload. Similar approach is followed to extract candidate phrases and their left-right context words from the technique descriptions available in ATT&CK framework. An element wise mean operation is performed on all three vectors to form a single candidate vector of particular phrase.\n\nDistance Measures: At its core, for the labeling process to be successful we need to measure the similarity/dissimilarity of ATT&CK technique candidate vectors and CVE description representations. For choosing the right distance function, we manually label randomly sampled 200 CVE's found in threat reports with their corresponding ATT&CK techniques and extract the context phrases, and create candidate vectors as described above. Now to choose the similarity measure between ATT&CK technique and CVE description in threat reports, we measure L 2 distance, Cosine distance, Maximum Mean Discrepancy (MMD) [36], and Fisher Linear Discriminant (FLD) [37] and select the best performing distance measurement method for labeling pipeline. This comparison is done to understand the influence of each distance function on underlying data distributions. For example, samples with the same mean and variance might have small L 2 distances even though they are different, whereas MMD can differentiate between them. Table 2 gives the correlation measures of different distance functions on a manually labeled dataset. We choose the cosine distance for the labeling pipeline as it has the highest correlation value that is suitable for this problem.\n\nGiven its performance we leverage the cosine distance -which is the measure of similarity between two vectors of an inner product space that measures the cosine of the angle of these vectors given by D cos = 1 \u2212 \u00b5 s \u00b7\u00b5 t \u2225\u00b5 s \u2225 2 \u2225\u00b5 t \u2225 2 . Techniques with the highest cosine similarity with the CVE phrases are assigned the label as a technique. We set the N window size to 5 in our experiments. We could map \n\n\nDistance Function\n\nCorrelation Measure\nL 2 -\u2225\u00b5 c \u2212 \u00b5 a \u2225 2 0.77 Cosine -1- \u00b5 c \u00b7\u00b5 a \u2225\u00b5 c \u2225 2 \u2225\u00b5 a \u2225 2 0.89 MMD -E x a [f (x a )] \u2212 E x c [f (x c )]\n0.64 Fisher Linear Discriminant 0.73 17 techniques to CVE's found in threat reports. Table 3 gives a list of phrases mapped to ATT&CK techniques. \n\n\nMLTC Model\n\nGiven a training set with N samples is given as\nD t r = {(x i , y m i ), i = 1, ..., N }, with x i = {x d i , x s i , x c i , x t i }, where x d i is textual descrip- tion of CVE, x s\ni represents the sequence of steps to exploit the CVE, x c i denotes mitigation steps and controls needed to reduce the attack surface for the CVE, x t i represents the high level characteristics of the CVE namely CPE, CVSS base and temporal strings, CWE, classification of the CVE, credibility, local vs remote CVE, . for the sample x i . One of the main goals for the classifier is not only to predict the labels in the training set but also from new/unseen data. This is important to the problem at hand, for the following reasons: (a) Old CVE, which was assigned to a ATT&CK technique can be re-assigned to a new technique based on the evolution of attackers methods; (b) new techniques, CVE's, attack scenarios and mitigations are added to combat new threats and the model has to still work with (new) concept drift data; (c) Our proposed labeling process depends on the threat write-ups for which the CVE coverage is limited i.e. we do not have reports covering all ATT&CK techniques. More formally, for a given input x i and the labels y m i classifier supports both, Y s , or unseen,\nY u label sets where Y s \u2229 Y u = \u2205 and Y = Y s \u222a Y u .\nWe design a multi-head deep embedding model to simultaneously embed feature representations of given CVE to predict corresponding ATT&CK techniques of CVE. To achieve this, we project the samples from two domains i.e. the feature domain of CVE and the corresponding ATT&CK domain into a joint latent space, which captures the structure of the labels, the encoded texts and the interactions between the two. Then we use an MLP classifier on the joint latent space that is independent of the label set size. The resulting model has the following properties: (i) Each head of the model learns the label dependency from an attacker, defender, and CVE metadata point of view. (ii) Making joint latent space dimension independent of label size, and input feature dimensions help the model to discover un-seen labels that is critical for our problem, and (iii) The model is trained with the cross-entropy loss with sigmoid function, which is suitable for multi-label classification problem. Figure 4 illustrates the proposed model and underlying components.\n\n\nEmbedding Modules.\n\nTo embed the features of CVE into a latent space, we use three different embeddings modules. The main purpose of embedding layer is to tranform a sequence of input tokens x 1 , . . . , x n into vector representation e i (i = 1, . . . , n). We use bi-LSTM encoder to extract character-based \u2212 \u2192 b i and wordlevel \u2190 \u2212 b i embeddings and concatenate both to get the final vector. Features, which have less contextual information but may contain Out of Vocabulary (OOV) tokens pass through token embedding layer that outputs h M i . Features, which capture mitigation for a given CVE and attack step sequences have more contextual, and sequential in nature so instead of using a Long Short Term Figure 4: Proposed multi-head deep embedding model. Each textual feature is projected with their label to a join space, the output of which is processed by a MLP with independent label size. Also, each feature branch follows independent encoders based on type of features Memory (LSTM) encoder, in which sentences interact through recurrent connections, which limits the flow of information between sentences occurring further in the sequence we use the transformer mechanism proposed by [8]. Tranfomer is a multihead with self-attention and position wise feed-forward sub-layers. Each sub layer has residual connections [6] and normizatiation [9] Layer Norm(x + Sublayer (x)) functions for efficient information learning. Here Sublayer (x) denotes the sub-layer function. The attention mechanism is defined on queries, keys and values packed together in matrices Q, K and V, respectively.\nAttention(Q, K, V) = softmax QK T d k V(1)\nA multi-head attention for query matrix Q, key matrix K and value matrix V is given by\nMultiHead(Q, K, V) = Concat(H 1 , ..., H h )W O(2)\nwhere\nH i = Attention(QW Q i , KW K i , VW V i )(3)\nHere, \nW Q i \u2208 R d model \u00d7d k , W K i \u2208 R d model \u00d7d k , W V i \u2208 R d model \u00d7d v and W O \u2208 R hd v \u00d7dh (i ) A j oint = h y i \u2299 h A i , and, h (i ) M j oint = h y i \u2299 h M i ,(4)p (i) A = h (i ) A j oint w A + b A , and, p (i) M = h (i ) M j oint w M + b M ,(5)\nwhere \u2299 is a component-wise multiplication. The probability for h belong to one of the k known labels is modeled by a linear unit that maps any point in the joint space into a score, which indicates the validity of the combination, where w \u2208 IR d j and b are a scalar variables. We train the classifier with binary cross-entropy loss and apply sigmoid function :\ny i =p(y i |x i ) = 1 1 + e \u2212P (i ) v al .(6)\n\nEXPERIMENTS\n\nIn this section, we describe the details of datasets used, seed data generation and hyperparameters used for training the model.\n\n\nDatasets\n\nFor raw data sets, we crawl 690 cybersecurity articles from a collection of advanced persistent threats (APT) reports that are published from 2008 to 2019 6 , zero-day exploits observed by google project zero 7 , 63720 vulnerability reports 8 , and 37000 threat reports 9 . Figure 5 shows different characteristics of CVE's found in threat reports. The Nessus vulnerability scanner contains a rich set of plugins for performing vulnerability assessments. Each plugin is designed to check for the presence of a set of CVE's via automated scans and contains human-curated rich descriptions about the CVE, steps performed by scan to check for the presence of CVE on a system and metadata about the vulnerability. This dataset was provided by a security company for research purposes. We manually create a knowledge base of 50 mitigation steps categorized into 7 high-level categories: (a) Restrict and Deny access, (b) Evaluate and Fix Default Configurations, (c) Implement Physical Security, (d) Implement Secure Communication Channels, (e) Inspect and filter network traffic data, (f) Use Strong Authentication and, (g) Use least privilege, and 150 attack scenarios (sequences) from the textual descriptions of Nessus plugins, and recommendations from the CVE vulnerability reports. Table 4 lists a small subset of attack sequence categories from knowledge base. Figure  6 compares the CVSS score distribution of CVE's in entire dataset and CVE's found in threat reports.\n\nWe enrich the CVE record with mitigation steps, attack sequences from the knowledge base of the previous step. For initial seed data labeling, we run multiple regular-expressions to extract CVE and neighborhood context words around the use of CVE in the 690 cybersecurity articles and 37000 threat reports. Next, we follow the labeling process described in Section 3 to label CVE's with ATT&CK techniques. We index the all 10 year dataset by the year CVE was publicly disclosed. CVE's disclosed between 2010-2017 were used as training set and data from years 2018-2019 was treated as test set. For the validation, a set of 10% of CVE records were randomly sampled from training set.\n\nFor pre-trained token embedding, we apply Word2Vec [12], which are trained with a window size of 8, a minimum vocabulary count of 1, and 15 iterations. The negative sampling number of word2vec is set to 8 and the model type is skip-gram. The dimension of the output token embedding is set to 300. We train the Transformer Network with 2 Transformer blocks, with hidden size 768 and a feed-forward intermediate layer size of 4 \u00d7 768, i.e., 3072. The 768dimensional representation obtained from Transformer is pooled by the decoder that is a five-layer feed-forward network with ReLU non-linearity in each layer with a hidden size of 200, and a 300dimensional output layer for the embedding.\n\nWe use the adaptive experimentation platform Ax 10 to tune the rest of hyperparameters and the search space for these hyperparameters are: learning rate \u2208 (10 \u22124 , 10 \u22123 ) and dropout rate \u2208 (0.25, 0.75). We run model for 5 times. We use the average validation performance as our validation criteria, and report average test performance.\n\n\nEvaluation\n\nThe performance of model is measured by rank-based evaluation that can accommodate multiple ATT&CK techniques assigned to same CVE. We use Precision at \u03c4 (P@\u03c4 ) defined as\nP@\u03c4 = 1 \u03c4 l \u2208r \u03c4 (\u0177) y l(7)\nwhere y \u2208 {0, 1} k is the ground truth label vector of a CVE and r \u03c4 (\u0177) is the label indexes of top \u03c4 highest scores of the current prediction result. \u2225 y \u2225 0 counts the number of relevant labels in the ground truth label vector y. Larger P@\u03c4 indicates better performance.\n\nWe compare model performance with 3 baseline models namely, Bi-direction Long short-term memory (BI-LSTM), Attention-based BI-LSTM, and Term Frequency-Inverse Document Frequency (TD-IDF) based SVM multi-label classifier. We also run a labelling pipeline on all of the dataset to check -does the model give additional improvements other then just learning the correlation inherent in the noun/verb overlap from the labeling techniques.\n\nTF-IDF approach represents all textual features as vectors with the same length as the vocabulary of the entire text corpus. Each entry in the vector corresponds to a unique word, and its weight gives the frequency of that word in the post (TF) divided by its document frequency (IDF). We set the feature size to 300. These document vectors are then used in the classification task. Also since TF-IDF results in high dimensional representations, we used SVM on TF-IDF features. We train the Word2Vec model using the same pre-training corpus as our proposed model. A BI-LSTM and Attention-based BI-LSTM model is trained for the multi-label task on the Word2Vec extracted embedding. Table 5 summarizes the results of proposed model and different baselines models.\n\nWe evaluate the influence of each component of the proposed model by ablation experiments. Note that when we use only the label or only the input embedding in the input-label formulation, the dimensionality of the joint space is constrained to be the dimensionality of the encoded labels and inputs respectively, that is d j =300 in our experiments. Table 6 summarizes the results.\n\nThere are multiple studies [27,28], which highlight the issues like reproducibility and inconsistencies of textual information in CVE reports. These problems are inherited by our labeling pipeline   Results indicate that we can take advantage of label text to explicitly determine the semantic relation between CVE textual features and corresponding ATT&CK techniques. Furthermore, adaptively extracting the proper amount of information from these two textual data benefit the model. Figure 7 plots the ATT&CK techniques trend of CVE's disclosed over past 10 years. Table 7 summarises different attack techniques identified by the proposed method -A CVE can be part of multiple techniques so depending on stage of attack the attacker can exploit the CVE to achieve his/her goal.\n\n\nRELATED WORK\n\nOur work combines several research areas, and we briefly discuss related work from these areas.Initial works that employed Natural Language Processing (NLP) techniques as feature extractors demonstrated that the CVE text descriptions are rich enough for the classification [30,31,38,39]. With the release of new technologies/products or the discovery of a zero-day attack or vulnerability, new terms appear in descriptions. The appearance of new concepts makes the vulnerability data and patterns change over time [40,41], which is known as concept drift [42]. It was shown in [43][44][45] that multiple models have suffered from the concept drift by mixing the new and old vulnerability data in the model validation step, which can lead to biased results as such approach accidentally merges the new information with the existing one. The presence of concept drift makes the models less robust to future prediction due to missing information. There has been some work into exploring the behavior of different attackers, but no work to the best of our knowledge has considered using attacker techniques and defender constraints in concert with machine learning for the purposes of vulnerability or software service management.\n\nIn the field of text classification, a large body of work has employed different neural network architectures -Simple feed-forward networks [13,14], CNN [15][16][17], and hierarchical recurrent neural networks [18,19] to address the problem. Recent studies tackled the problem of learning output representations directly from data without any feature extractors [20][21][22][23]. In this work, we employ Recently, the textual information of labels is jointly learned with documents for the MLTC task. EXAM [26] introduces the interaction mechanism to incorporate word-level matching signals into the text classification task. GILE [29] proposes a joint input-label embedding model for neural text classification. LSAN [25] uses label semantic information to determine the semantic connection between labels and documents for constructing the label-specific document representation. Our work follows a similar methodology of learning correlation between the labels and texts but differs in feature transformers and the labeling mechanism.\n\n\nCONCLUSION\n\nIn this paper, we define the problem of automatic mapping CVE's to ATT&CK techniques as a multi-label text classification task and propose a multi-head joint embedding neural network model to address it. We devise a novel unsupervised labeling technique that extracts relevant phrases with context from threat reports and ATT&CK technique descriptions to deal with the lack of labels for the task. A knowledge base of 50 mitigation strategies and 150 attack scenarios for exploiting vulnerabilities is curated to enrich CVE's features and help proposed model learn both attacker and defender view of a given CVE's. Our evaluation results are encouraging, with a large set of CVE's disclosed over the past 10 years are mapped to a set of ATT&CK techniques using the proposed approach and also identified CVE's which can be mapped to different stages of attack.\n\nDespite some interesting results of our proposed method, we want to highlight its inherent limitations and subjects for future work. The model learns attacker and defender view of a CVE by feature enrichment from the knowledge base of attack scenarios, and mitigation steps that is incomplete. Also, we found in some cases where CVE records have very little textual information that resulted in no mapping. Our study does not cover the threat modeling in terms of robustness to adversarial attacks and comparison experiments with bench-marking datasets in other domains, which solve MLTC task.\n\nOur future work will focus on the following areas: (a) Extend the model embedding inputs to consume exploit code, patch diffs and Common Weakness Enumeration (CWE) descriptions that will address the incompleteness of knowledge base, and missing textual information; (b) Expand the experiments to compare model performance on benchmarking data sets in other domains, and (c) Examine the security robustness of proposed model under adversarial settings [33,34] and threat models.  \n\nFigure 1 :\n1Heat map of MITRE ATT&CK tactics and technique with the all CVE's dataset. The numbers in each cell correspond to CVE count for particular tactic and technique Attack Group Common Vulnerabilities and Exposures (CVE) APT28 CVE-2014-4076, CVE-2015-3043, CVE-2015-2424, CVE-2016-7855, CVE-2015-5119, CVE-2015-1701, CVE-2016-7255, CVE-2015-2590 APT3 CVE-2016-7255, CVE-2014-4113, CVE-2014-1776, CVE-2014-6332, CVE-2015-3113, CVE-2010-3962, CVE-2015-5119, CVE-2017-0199, CVE-2017-11882, CVE-2015-2545, CVE-2015-2387, CVE-2015-3043, CVE-2016-1019, CVE-2015-5122, CVE-2018-0802, CVE-2018-4878, CVE-2015-3105, CVE-2015-2419, CVE-2013-4979, CVE-2016-4117, CVE-2014-8439, CVE-2015-7645, CVE-2016-4119, CVE-2015-8651 APT32 CVE-2016-7255 APT37 CVE-2015-2545, CVE-2015-2387, CVE-2015-3043, CVE-2016-1019, CVE-2015-5122, CVE-2018-0802, CVE-2015-5119, CVE-2018-4878, CVE-2015-3105, CVE-2015-2419, CVE-2013-4979, CVE-2016-4117, CVE-2014-8439, CVE-2017-0199, CVE-2015-7645 APT38 CVE-2016-4119, CVE-2016-1019, CVE-2015-8651 APT41 CVE-2019-3369, CVE-2015-1641, CVE-2012-0158, CVE-2017-11882, CVE-2019-3396, CVE-2017-0199 CARBANAK CVE-2013-3906, CVE-2013-3660, CVE-2012-0158, CVE-2017-5638, CVE-2016-5165, CVE-2016-5195, CVE-2015-2545, CVE-2015-1770, CVE-2014-6352, CVE-2015-1641, CVE-2015-1701 CLEAVER CVE-2010-0232 DRAGONFLY CVE-2012-4792, CVE-2013-1347, CVE-2013-2465, CVE-2012-1723 ELDERWOOD CVE-2011-0611, CVE-2011-2110, CVE-2012-1875, CVE-2011-0609, CVE-2012-1889, CVE-2010-0249, CVE-2012-1535, CVE-2019-2725, CVE-2017-5689, CVE-2017-11882 NAIKON CVE-2010-3333, CVE-2012-1856, CVE-2012-0158 NEODYMIUM/PROMETHIUM CVE-2016-0034, CVE-2010-2568, CVE-2012-0507, CVE-2010-3336, CVE-2012-1889, CVE-2013-3896, CVE-2012-0158, CVE-2015-0072, CVE-2011-0097, CVE-2013-0074, CVE-2015-8651, CVE-2012-1723, CVE-2010-1297, CVE-2013-2423, CVE-2014-1761, CVE-2012-0056, CVE-2016-1019, CVE-2016-0189, CVE-2013-2460, CVE-2016-0165, CVE-2015-1671, CVE-2013-0422, CVE-2016-0167, CVE-2010-0840, CVE-2015-5119, CVE-2015-0311, CVE-2010-0188, CVE-2016-4117, CVE-2015-0310, CVE-2013-1493, CVE-2011-0611, CVE-2016-4171, CVE-2014-6332, CVE-2008-2551, CVE-2011-1823, CVE-2013-2551, CVE-2010-3653, CVE-2016-1010, CVE-2015-0313 OILRIG CVE-2014-0640, CVE-2017-0199, CVE-2015-7547 PATCHWORK CVE-2014-4114, CVE-2017-8570, CVE-2015-1641, CVE-2012-1856, CVE-2017-0199, CVE-2017-8750, CVE-2017-12824, CVE-2015-2545, CVE-2017-0261 PLATINUM CVE-2015-2545, CVE-2013-7331, CVE-2015-2546, CVE-2013-1331 RANCOR CVE-2018-0798 SILENCE CVE-2018-0802, CVE-2017-11882, CVE-2017-0263, CVE-2008-4250, CVE-2017-0262, CVE-2018-8174, CVE-2017-0199 SUCKFLY CVE-2014-6332 TROPIC TROOPER CVE-2018-0802, CVE-2017-5689, CVE-2017-11882 TURLA CVE-2012-1723, CVE-2012-4681, CVE-2013-2729, CVE-2013-5065, CVE-2009-3129, CVE-2013-3346\n\n\nCVE's in red are actively exploited by attackers. Now, when we look at disclosed vulnerabilities between 2017-2019, which share same attack techniques for this particular kernel driver: CVE-2018-8120, CVE-2018-8453, CVE-2018-8589,CVE-2018-8453, CVE-2019-0803 are also exploited by attackers in the attack campaigns. Similarly, when we study remote scripting vulnerabilities disclosed for scripting engine component of Microsoft Edge and Internet explorer over the past years most of them belong to \"Exploitation for Defense Evasion, Exploitation of Remote Services\" ATT&CK techniques. Below is a subset of 27 CVE's exploited in malware campaigns CVE-2017-0015, CVE-2017-0067, CVE-2017-0141, CVE-2017-8601, CVE-2017-8605, CVE-2017-8598, CVE-2018-0953, CVE-2018-8114, CVE-2018-8122, CVE-2018-8133, CVE-2018-0955, CVE-2018-8267, CVE-2018-8275, CVE-2018-8653, CVE-2016-0191, CVE-2016-0193, CVE-2016-3205, CVE-2016-3207, CVE-2016-3206, CVE-2016-3210, CVE-2016-3222, CVE-2016-3199, CVE-2016-3377, CVE-2016-7200, CVE-2016-7201, CVE-2016-7203, CVE-2016-7242 and CVE-2016-0189, which is used in advanced attack campaigns.\n\nFigure 2 : 8759 Figure 3 :\n287593Different Features of CVE-2017-Labeling process of CVEs used in threat reports to MITRE ATT&CK techniques CVE-2017-8759 highlighting left and right contexts around phrase CVE-2017-8759 exploit. The [left_context]malicious document[left_context] containing CVE-2017-8759 exploit, [right_context]downloads multiple components[right_context]\n\nFigure 5 :Figure 6 :\n56Characteristics of CVE's found in the threat reports CVSS score cumulative density distribution of CVE's in entire dataset vs CVE'\n\nFigure 7 :\n7ATT&CK Techniques Trend Plot of CVE's disclosed over past 10 years identified by the proposed model 3 feature extractors as sub-networks including transformers, Bi-LSTM, and word2vec models for the classification tasks.\n\nTable 1 :\n1CVE's used by Attack groups in different attack campaigns popularity, and spread of vulnerable software. A large part of CVE's exploited by advanced attackers are client-side software, web application, and software belonging to top 100 technologies. The presence of a high impact vulnerability increases the incidence of exploitation in the wild. For example, CVE-2017-0199 alone was used by multiple attack groups namely patchwork, apt3, apt37, apt41, and oilrig in different intrusions\n\nTable 2 :\n2Correlation measure of ATT&CK techniques and CVE candidate vectors on manually labelled 200 samples.\n\nTable 3 :\n3Subset of Phrases extracted from Threat Reports mapped to ATT&CK Techniques via Labelling processATT&CK Technique \nPhrases Extracted \n\nValid Accounts \ndefault \naccounts, \nad-\nministrative \naccount, \ndefault-account, \nunau-\nthorized creation of user \naccounts, predictable ac-\ncount credential, perform \nsuccessive incorrect login \nattempts, multiple-login \nprotection \nVirtualization/Sandbox Evasion \nsandbox restrictions, sand-\nboxed process, bypass sand-\nbox protection, sandbox \nprotections \nWeb Service \nmalicious web service \nWeb Shell \nupload and execute arbi-\ntrary script, shell-upload \nWinlogon Helper DLL \ncreates a malicious dll, ma-\nlicious dll, unauthorized ex-\necution of dll \nSpearphishing Attachment \nphishing, distributes the \npage and entices an unsus-\npecting user \nSteal Web Session Cookie \ncookie-theft, weak random \nsession, malicious cookie, \nsession-impersonation, \ncookie guessing, session-\nhijacking \nSystem Network Connections Discovery manual scanning, port-\nscanned, leaks protected \nnetwork \n\n\n\nTable 4 :\n4Subset of Attack categoriesAttack Category \nTypes \n\nINJECTION \nREMOTE/LOCAL CODE, COMMAND, HTML, OS COMMAND, PHP CODE, PHP OBJECT, \nREMOTE/LOCAL SHELL COMMAND, SQL, XML EXTERNAL ENTITY, SCRIPT \nFILE BASED \nACCESS, READ, WRITE, DELETE, UPLOAD, REMOTE/LOCAL INCULDE, TEMPO-\nRARY/ARBITRARY CREATION, INSECURE FILE PERMISSIONS \nBYPASS \nACCESS, AUTHENTICATION, AUTHORIZATION, BRUTE FORCE AUTHENTICATION, \nHARD CODED CREDENTIALS/PASSWORD , MAN IN THE MIDDLE, URI PROCESSING \nSESSION \nFIXATION, HIJACKING, MANIPULATION, WEAK MANAGEMENT \nCREDENTIALS \nHARD CODED/DEFAULT, MIS-CONFIGURATION, INSECURE/PREDICTABLE RANDOM \nNUMBER, WEAK PASSWORD ENCRYPTION, CERTIFICATE/SSH SPOOFING, MAN IN \nTHE MIDDLE \nENTRY \nDOCUMENT BASED, EMAIL BASED, APPLICATION BASED, CLICK JACKING, MAN IN \nTHE MIDDLE, REQUEST BASED \nESCALATION \nNULL POINTER DEREFERENCE, OVERFLOW, HEAP BASED BUFFER OVERFLOW, IN-\nTEGER OVERFLOW, STACK BASED BUFFER OVERFLOW, MEMORY CORRUPTION, RE-\nMOTE/LOCAL CODE/COMMAND EXECUTION \n\nseverity, and y m \ni denotes the corresponding ATT&CK techniques \nrepresented as y m \ni = y 1 , y 2 .\n\n\nmodel are parameter matrices.Every layer in the model outputs a vector of d model dimensions. d k and d v are dimensions of key and value, respectively, in a single head and there are h such heads in total. In a self-attention, Q, K and V all are from the same layer. In our system, each key, query, and value is a vector corresponding to a sentence.The output of the transformer module is h A i embedding vector. Finally, for label embeddings we train a Word2Vec [12] model with ATT&CK techniques y m i = y 1 , y 2 ... and corresponding descriptions and this module outputs h y i . For creating joint latent space between two ATT&CK techniques domain and CVE feature domain, we perform a component-wise multiplication of each embedding type with label embdedding h for their joint representation given by,y \ni \n\n\n\nTable 5 :\n5Performance comparison of proposed model on the various Baselines. N t is total number of ATT&CK techniques identified by model across whole dataset.Layer \nLabels \nP@1 P@3 P@5 \n\nh M + MLP \n49.84% 32.27% 24.17% \nh A + MLP \n70.40% 54.98% 44.86% \n\n(h A \u2299 h M ) + MLP \n85.28% 61.12% 52.78% \n\n(h A \u2299 h M \u2299 h y ) + MLP 93.16 % 95.89% 94.50% \n\n\n\nTable 6 :\n6Ablation test of various modules of proposed modelas well, where it could not map a CVE text to ATT&CK technique be-\ncause of lack or ambiguous description. Our proposed method could \n\n\n\n\nATT&CK Techniques CVE Record CountAccount Manipulation, Command-Line Interface, Exploit Public-Facing Application 1 Account Manipulation, Exploitation for Defense Evasion 2 Command-Line Interface, Exploit Public-Facing Application 1 Command-Line Interface,Exploitation for Defense Evasion,User Execution 1 Command-Line Interface, Exploitation of Remote Services 1 Compiled HTML File, Exploitation for Defense Evasion, Exploitation of Remote Services 1 Compiled HTML File, Exploitation for Defense Evasion, Exploitation of Remote Services,Taint Shared Content, User Execution 2 Compiled HTML File, Exploitation for Defense Evasion, Exploitation of Remote Services, User Execution 1 Compiled HTML File, Exploitation for Defense Evasion, Taint Shared Content,User Execution 1 Compiled HTML File, Exploitation of Remote Services, User Execution 1 Exploit Public-Facing Application, Exploitation for Defense Evasion 2 Exploit Public-Facing Application, Exploitation for Defense Evasion, Transmitted Data Manipulation 1 Exploit Public-Facing Application, Transmitted Data Manipulation 1 Exploitation for Defense Evasion, Exploitation for Privilege Escalation 47 Exploitation for Defense Evasion, Exploitation of Remote Services 135 Exploitation for Defense Evasion, Exploitation of Remote Services, Spearphishing Attachment 1 Exploitation for Defense Evasion, Exploitation of Remote Services,Taint Shared Content,User Execution 1 Exploitation for Defense Evasion, Exploitation of Remote Services, User Execution 87 Exploitation for Defense Evasion, Exploitation of Remote Services,User Execution, Virtualization/Sandbox Evasion 1 Exploitation for Defense Evasion, Exploitation of Remote Services, Virtualization/Sandbox Evasion 4 Exploitation for Defense Evasion, Install Root Certificate 3 Exploitation for Defense Evasion, Spearphishing Attachment 4 Exploitation for Defense Evasion, Taint Shared Content 1 Exploitation for Defense Evasion, User Execution 74 Exploitation for Defense Evasion, User Execution, Virtualization/Sandbox Evasion 1 Exploitation for Defense Evasion, Web Shell 2 Install Root Certificate, Private Keys, SSH Hijacking 1\n\nTable 7 :\n7Subset of mapped Attack Techniques by proposed Model on full CVE Dataset\nhttps://attack.mitre.org/groups/ 2 https://zerodium.com/program.html\nhttps://www.fireeye.com/blog/threat-research/2017/09/zero-day-used-todistribute-finspy.html 4 https://securelist.com/blackoasis-apt-and-new-targeted-attacks-leveraging-zeroday-exploit/82732/\nhttps://spacy.io/\nhttps://github.com/CyberMonitor/APT_CyberCriminal_Campagin_Collections 7 https://googleprojectzero.blogspot.com/p/0day.html 8 https://www.symantec.com/security-center/vulnerabilities 9 https://www.symantec.com/security-center/a-z\nhttps://github.com/facebook/Ax\n\nComparing vulnerability severity and exploits using case-control. Luca Allodi, Fabio Massacci, studies ACM Transaction on Information and System Security. 17TISSECLuca Allodi, Fabio Massacci Comparing vulnerability severity and exploits us- ing case-control studies ACM Transaction on Information and System Security (TISSEC) volume 17 , 2014.\n\nRohan Intelligence-Driven Computer Network Defense Informed by Analysis of Adversary Campaigns and Intrusion Kill Chains. M Hutchins, &amp; J Eric, Cloppert, &amp; M Michael, Amin, Leading Issues in Information Warfare & Security Research. 1M Hutchins, Eric & J Cloppert, Michael & M Amin, Rohan Intelligence-Driven Computer Network Defense Informed by Analysis of Adversary Campaigns and In- trusion Kill Chains. Leading Issues in Information Warfare & Security Research. 1.\n\nZ Junjie, GenerAting SignatuRes to Detect DRive-By DOWnloads Proceedings of the 20th International Conference on World Wide Web WWW '11. Z. Junjie, et al. ARROW: GenerAting SignatuRes to Detect DRive-By DOWnloads Proceedings of the 20th International Conference on World Wide Web WWW '11\n\nD Rachna, J D Tygar, M Hearst, Why Phishing Works, SIGCHI Conference on Human Factors in Computing Systems, CHI'06. D. Rachna, J.D. Tygar, and M. Hearst Why Phishing Works, SIGCHI Conference on Human Factors in Computing Systems, CHI'06\n\nMassacci Quantitative assessment of risk reduction with cybercrime black market monitoring. Luca Allodi, Shim Woohyun, Fabio , Proc. of IWCC'13. of IWCC'13Luca Allodi, Shim Woohyun, and Fabio Massacci Quantitative assessment of risk reduction with cybercrime black market monitoring.. In In Proc. of IWCC'13.\n\nDeep residual learning for image recognition. K He, X Zhang, S Ren, J Sun, CVPR. He, K.; Zhang, X.; Ren, S.; and Sun, J. 2016. Deep residual learning for image recognition. In CVPR.\n\nWork-Averse Cyber Attacker Model. Evidence from two million attack signatures. Luca Allodi, Fabio Massacci, Julian Williams, Published in WEIS 2017.Luca Allodi, Fabio Massacci and Julian Williams The Work-Averse Cyber Attacker Model. Evidence from two million attack signatures. In Published in WEIS 2017. .\n\nAttention is all you need. A Vaswani, N Shazeer, N Parmar, J Uszkoreit, L Jones, A N Gomez, \u0141 Kaiser, I Polosukhin, NIPS. Vaswani, A.; Shazeer, N.; Parmar, N.; Uszkoreit, J.; Jones, L.; Gomez, A. N.; Kaiser, \u0141.; and Polosukhin, I. 2017. Attention is all you need. In NIPS.\n\n. Lei Ba, J Kiros, J R Hinton, G E , arXiv:1607.06450Layer normalization. arXiv preprintLei Ba, J.; Kiros, J. R.; and Hinton, G. E. 2016. Layer normalization. arXiv preprint arXiv:1607.06450.\n\nTowards realistic threat modeling: attack commodification, irrelevant vulnerabilities, and unrealistic assumptions. L Allodi, S Etalle, Allodi, L. & Etalle, S. Towards realistic threat modeling: attack commodification, irrelevant vulnerabilities, and unrealistic assumptions. (2017)\n\nB Strom, A Applebaum, D Miller, K Nickels, A Pennington, C Thomas, Att&amp;ck, Design and Philosophy. Mitre Product Mp. Strom, B., Applebaum, A., Miller, D., Nickels, K., Pennington, A. & Thomas, C. MITRE ATT&CK: Design and Philosophy. Mitre Product Mp. pp. 18-0944 (2018)\n\nDistributed representations of words and phrases and their compositionality. T Mikolov, I Sutskever, K Chen, G S Corrado, J Dean, Advances in neural information processing systems. T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean, \"Distributed repre- sentations of words and phrases and their compositionality, \" in Advances in neural information processing systems, 2013, pp. 3111-3119.\n\nNatural language processing (almost) from scratch. Ronan Collobert, Jason Weston, L\u00e9on Bottou, Michael Karlen, Koray Kavukcuoglu, Pavel Kuksa, Journal of Machine Learning Research. 12Ronan Collobert, Jason Weston, L\u00e9on Bottou, Michael Karlen, Koray Kavukcuoglu, and Pavel Kuksa. 2011. Natural language processing (almost) from scratch. Journal of Machine Learning Research, 12:2493-2537.\n\nDistributed representations of sentences and documents. V Quoc, Tomas Le, Mikolov, Proceedings of The 31st International Conference on Machine Learning. The 31st International Conference on Machine LearningBeijing, ChinaQuoc V. Le and Tomas Mikolov. 2014. Distributed representations of sentences and documents. In Proceedings of The 31st International Conference on Machine Learning, pages 1188--1196, Beijing, China.\n\nConvolutional neural networks for sentence classification. Yoon Kim, Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing. the 2014 Conference on Empirical Methods in Natural Language ProcessingDoha, QatarYoon Kim. 2014. Convolutional neural networks for sentence classification. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, pages 1746-1751, Doha, Qatar.\n\nEffective use of word order for text categorization with convolutional neural networks. Rie Johnson, Tong Zhang, Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesDenver, ColoradoRie Johnson and Tong Zhang. 2015. Effective use of word order for text catego- rization with convolutional neural networks. In Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 103-112, Denver, Colorado.\n\nCharacter-level convolutional networks for text classification. Xiang Zhang, Junbo Zhao, Yann Lecun, Advances in Neural Information Processing Systems. Montreal, Canada28Xiang Zhang, Junbo Zhao, and Yann LeCun. 2015. Character-level convolutional networks for text classification. In Advances in Neural Information Processing Systems 28, pages 649-657, Montreal, Canada.\n\nDocument modeling with gated recurrent neural network for sentiment classification. Duyu Tang, Bing Qin, Ting Liu, Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. the 2015 Conference on Empirical Methods in Natural Language ProcessingLisbon, PortugalAssociation for Computational LinguisticsDuyu Tang, Bing Qin, and Ting Liu. 2015. Document modeling with gated recurrent neural network for sentiment classification. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1422-1432, Lisbon, Portugal. Association for Computational Linguistics.\n\nMultilingual hierarchical attention networks for document classification. Nikolaos Pappas, Andrei Popescu-Belis, Proceedings of the Eighth International Joint Conference on Natural Language Processing. the Eighth International Joint Conference on Natural Language ProcessingLong Papers1Nikolaos Pappas and Andrei Popescu-Belis. 2017. Multilingual hierarchical attention networks for document classification. In Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 1015-1025.\n\nLearning distributed representations for structured output prediction. Vivek Srikumar, D Christopher, Manning, Proceedings of the 27th International Conference on Neural Information Processing Systems. the 27th International Conference on Neural Information Processing SystemsCambridge, MA, USAMIT Press2Vivek Srikumar and Christopher D. Manning. 2014. Learning distributed repre- sentations for structured output prediction. In Proceedings of the 27th International Conference on Neural Information Processing Systems -Volume 2, NIPS'14, pages 3266-3274, Cambridge, MA, USA. MIT Press.\n\nLearning deep latent spaces for multi-label classification. Chih-Kuan Yeh, Wei-Chieh Wu, Wei-Jen Ko, Yu-Chiang Frank Wang, Proceedings of the 32nd AAAI Conference on Artificial Intelligence. the 32nd AAAI Conference on Artificial IntelligenceNew Orleans, USAChih-Kuan Yeh, Wei-Chieh Wu, Wei-Jen Ko, and Yu-Chiang Frank Wang. 2018. Learning deep latent spaces for multi-label classification. In In Proceedings of the 32nd AAAI Conference on Artificial Intelligence, New Orleans, USA.\n\nMulti-task learning of pairwise sequence classification tasks over disparate label spaces. Isabelle Augenstein, Sebastian Ruder, Anders S\u00f8gaard, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesNew Orleans, Louisiana1Long PapersIsabelle Augenstein, Sebastian Ruder, and Anders S\u00f8gaard. 2018. Multi-task learning of pairwise sequence classification tasks over disparate label spaces. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pages 1896-1906, New Orleans, Louisiana.\n\nJoint embedding of words and labels for text classification. Guoyin Wang, Chunyuan Li, Wenlin Wang, Yizhe Zhang, Dinghan Shen, Xinyuan Zhang, Ricardo Henao, Lawrence Carin, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics. the 56th Annual Meeting of the Association for Computational LinguisticsAssociation for Computational Linguistics1Guoyin Wang, Chunyuan Li, Wenlin Wang, Yizhe Zhang, Dinghan Shen, Xinyuan Zhang, Ricardo Henao, and Lawrence Carin. 2018. Joint embedding of words and labels for text classification. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 2321- 2331. Association for Computational Linguistics.\n\nA model of zero-shot learning of spoken language understanding. Majid Yazdani, James Henderson, Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. the 2015 Conference on Empirical Methods in Natural Language ProcessingLisbon, PortugalMajid Yazdani and James Henderson. 2015. A model of zero-shot learning of spoken language understanding. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 244-249, Lisbon, Portugal.\n\nLabel-Specific Document Representation for Multi-Label Text Classification. L Xiao, X Huang, B Chen, L Jing, Xiao, L., Huang, X., Chen, B. & Jing, L. Label-Specific Document Representation for Multi-Label Text Classification. (2019)\n\nExplicit interaction model towards text classification. C Du, Z Chen, F Feng, L Zhu, T Gan, L Nie, Du, C., Chen, Z., Feng, F., Zhu, L., Gan, T. & Nie, L. Explicit interaction model towards text classification. (2019)\n\nYing Dong, Wenbo Guo, Yueqi Chen, Xinyu Xing, Yuqing Zhang, Gang Wang, Towards the detection of inconsistencies in public security vulnerability reports. 28th {USENIX} Security Symposium. {USENIX} Security 19Towards the detection of inconsistencies in public security vulnerability reports, Dong, Ying and Guo, Wenbo and Chen, Yueqi and Xing, Xinyu and Zhang, Yuqing and Wang, Gang, 28th {USENIX} Security Symposium ({USENIX} Security 19), 869-885, 2019\n\nUnderstanding the reproducibility of crowd-reported security vulnerabilities Mu. Cuevas Dongliang, Alejandro , Yang , Limin Hu, Hang Xing, Xinyu Mao, Bing Wang, Gang , 27th {USENIX} Security Symposium. {USENIX} Security 18Understanding the reproducibility of crowd-reported security vulnerabilities Mu, Dongliang and Cuevas, Alejandro and Yang, Limin and Hu, Hang and Xing, Xinyu and Mao, Bing and Wang, Gang, 27th {USENIX} Security Symposium ({USENIX} Security 18), 919-936, 2018\n\nA Generalized Input-Label Embedding for Text Classification. Transactions Of The Association For Computational Linguistics. N Pappas, J Henderson, Gile, 7Pappas, N. & Henderson, J. GILE: A Generalized Input-Label Embedding for Text Classification. Transactions Of The Association For Computational Linguistics. 7 pp. 139-155 (2019)\n\nSecurity trend analysis with cve topic models. S Neuhaus, T Zimmermann, Neuhaus, S. & Zimmermann, T. Security trend analysis with cve topic models. (2010)\n\nStructuring a vulnerability description for comprehensive single system security analysis. Rocky Mountain Celebration Of Women In Computing. M Urbanska, I Ray, A Howe, M Roberts, Fort Collins, Co, Usa.Urbanska, M., Ray, I., Howe, A. & Roberts, M. Structuring a vulnerability de- scription for comprehensive single system security analysis. Rocky Mountain Celebration Of Women In Computing, Fort Collins, Co, Usa. (2012)\n\nPredicting cyber risk of an enterprise Aditya. ; Riskwriter, Slawomir Grzonkowski, Le-Khac , Nhien-An International Conference on Information Systems. SpringerSecurityRiskwriter: Predicting cyber risk of an enterprise Aditya, K and Grzonkowski, Sla- womir and Le-Khac, Nhien-An International Conference on Information Systems Security 88-106, 2018 ,Springer\n\nAditya , Grzonkowski Slawomir, Muhammad Asghar, Le-Khac Rizwan, Nhien-An Proceedings of the 14th International Conference on Availability, Reliability and Security. Black box attacks on deep anomaly detectors KuppaBlack box attacks on deep anomaly detectors Kuppa, Aditya and Grzonkowski, Slawomir and Asghar, Muhammad Rizwan and Le-Khac, Nhien-An Proceedings of the 14th International Conference on Availability, Reliability and Security, 1-10, 2019\n\nAditya , Le-Khac , Black Box Attacks on Explainable Artificial Intelligence (XAI) methods in Cyber Security Kuppa. Nhien-An2020International Joint Conference on Neural Networks (IJCNN)Black Box Attacks on Explainable Artificial Intelligence (XAI) methods in Cyber Security Kuppa, Aditya and Le-Khac, Nhien-An, International Joint Conference on Neural Networks (IJCNN) 2020\n\nEffect of Security Controls on Patching Window: A Causal Inference based Approach Kuppa. Aditya , Aouad , Lamine , Le-Khac , Nhien-An Annual Computer Security Applications Conference. 2020Effect of Security Controls on Patching Window: A Causal Inference based Approach Kuppa, Aditya and Aouad, Lamine and Le-Khac, Nhien-An Annual Computer Security Applications Conference 556-566 2020\n\nSch\"olkopf, B. & Smola, A. A kernel twosample test. A Gretton, K Borgwardt, M Rasch, Jmlr. Gretton, A., Borgwardt, K., Rasch, M., Sch\"olkopf, B. & Smola, A. A kernel two- sample test. Jmlr. (2012)\n\nThe elements of statistical learning. J Friedman, T Hastie, R Tibshirani, SpringerFriedman, J., Hastie, T. & Tibshirani, R. The elements of statistical learning. (Springer,2001)\n\nDarkembed: Exploit prediction with neural language models. N Tavabi, P Goyal, M Almukaynizi, P Shakarian, K Lerman, Tavabi, N., Goyal, P., Almukaynizi, M., Shakarian, P. & Lerman, K. Darkembed: Exploit prediction with neural language models. (2018)\n\nAn automatic method for CVSS score prediction using vulnerabilities description. A Khazaei, M Ghasemzadeh, V Derhami, Journal Of Intelligent & Fuzzy Systems. 30Khazaei, A., Ghasemzadeh, M. & Derhami, V. An automatic method for CVSS score prediction using vulnerabilities description. Journal Of Intelligent & Fuzzy Systems. 30, 89-96 (2016)\n\nAnalyzing Evolving Trends of Vulnerabilities in National Vulnerability Database. M Williams, S Dey, R Barranco, S Naim, M Hossain, M Akbar, Williams, M., Dey, S., Barranco, R., Naim, S., Hossain, M. & Akbar, M. Analyzing Evolving Trends of Vulnerabilities in National Vulnerability Database. (2018)\n\nMining trends and patterns of software vulnerabilities. S Murtaza, W Khreich, A Hamou-Lhadj, A Bener, Journal Of Systems And Software. 117Murtaza, S., Khreich, W., Hamou-lhadj, A. & Bener, A. Mining trends and patterns of software vulnerabilities. Journal Of Systems And Software. 117 pp. 218-228 (2016)\n\nPredicting exploitation of disclosed software vulnerabilities using open-source data. B Bullough, A Yanchenko, C Smith, J Zipkin, Bullough, B., Yanchenko, A., Smith, C. & Zipkin, J. Predicting exploitation of disclosed software vulnerabilities using open-source data. (2017)\n\nPatch Before Exploited: An Approach to Identify Targeted Software Vulnerabilities. M Almukaynizi, E Nunes, K Dharaiya, M Senguttuvan, J Shakarian, P Shakarian, SpringerAlmukaynizi, M., Nunes, E., Dharaiya, K., Senguttuvan, M., Shakarian, J. & Shakar- ian, P. Patch Before Exploited: An Approach to Identify Targeted Software Vul- nerabilities. (Springer,2019)\n\nBeyond heuristics: learning to classify vulnerabilities and predict exploits. M Bozorgi, L Saul, S Savage, G Voelker, Bozorgi, M., Saul, L., Savage, S. & Voelker, G. Beyond heuristics: learning to classify vulnerabilities and predict exploits. (2010)\n\nA multi-target approach to estimate software vulnerability characteristics and severity scores. G Spanos, L Angelis, Journal Of Systems And Software. 146Spanos, G. & Angelis, L. A multi-target approach to estimate software vulnera- bility characteristics and severity scores. Journal Of Systems And Software. 146 pp. 152-166 (2018)\n\nAddressing the rare word problem in neural machine translation. M Luong, I Sutskever, Q Le, O Vinyals, W Zaremba, Arxiv:1410.8206Arxiv PreprintLuong, M., Sutskever, I., Le, Q., Vinyals, O. & Zaremba, W. Addressing the rare word problem in neural machine translation. Arxiv Preprint Arxiv:1410.8206. (2014)\n\nUsing sublexical translations to handle the OOV problem in machine translation. C Huang, H Yen, P Yang, S Huang, J Chang, Acm Transactions On Asian Language Information Processing (talip). 1016Huang, C., Yen, H., Yang, P., Huang, S. & Chang, J. Using sublexical translations to handle the OOV problem in machine translation. Acm Transactions On Asian Language Information Processing (talip). 10, 16 (2011)\n\nContext models for oov word translation in low-resource languages. A Liu, K Kirchhoff, Arxiv:1801.08660.Arxiv PreprintLiu, A. & Kirchhoff, K. Context models for oov word translation in low-resource languages. Arxiv Preprint Arxiv:1801.08660. (2018)\n", "annotations": {"author": "[{\"end\":159,\"start\":84},{\"end\":220,\"start\":160},{\"end\":290,\"start\":221}]", "publisher": "[{\"end\":31,\"start\":28},{\"end\":461,\"start\":458}]", "author_last_name": "[{\"end\":96,\"start\":91},{\"end\":172,\"start\":167},{\"end\":237,\"start\":230}]", "author_first_name": "[{\"end\":90,\"start\":84},{\"end\":166,\"start\":160},{\"end\":229,\"start\":221}]", "author_affiliation": "[{\"end\":158,\"start\":125},{\"end\":219,\"start\":193},{\"end\":289,\"start\":256}]", "title": "[{\"end\":27,\"start\":1},{\"end\":317,\"start\":291}]", "venue": "[{\"end\":406,\"start\":319}]", "abstract": "[{\"end\":2985,\"start\":933}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3763,\"start\":3760},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3834,\"start\":3831},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3856,\"start\":3853},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":4420,\"start\":4416},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":4423,\"start\":4420},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":4519,\"start\":4516},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":4521,\"start\":4519},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":4725,\"start\":4722},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":5415,\"start\":5414},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":5581,\"start\":5578},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":5584,\"start\":5581},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":5617,\"start\":5613},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":6338,\"start\":6334},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":17148,\"start\":17144},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":17191,\"start\":17187},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":22088,\"start\":22085},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":22221,\"start\":22218},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":22244,\"start\":22241},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":25753,\"start\":25749},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":28829,\"start\":28825},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":28832,\"start\":28829},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":29870,\"start\":29866},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":29873,\"start\":29870},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":29876,\"start\":29873},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":29879,\"start\":29876},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":30111,\"start\":30107},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":30114,\"start\":30111},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":30152,\"start\":30148},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":30174,\"start\":30170},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":30178,\"start\":30174},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":30182,\"start\":30178},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":30965,\"start\":30961},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":30968,\"start\":30965},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":30978,\"start\":30974},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":30982,\"start\":30978},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":30986,\"start\":30982},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":31035,\"start\":31031},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":31038,\"start\":31035},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":31187,\"start\":31183},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":31191,\"start\":31187},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":31195,\"start\":31191},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":31199,\"start\":31195},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":31331,\"start\":31327},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":31456,\"start\":31452},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":31543,\"start\":31539},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":33784,\"start\":33780},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":33787,\"start\":33784}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":36578,\"start\":33809},{\"attributes\":{\"id\":\"fig_1\"},\"end\":37693,\"start\":36579},{\"attributes\":{\"id\":\"fig_2\"},\"end\":38066,\"start\":37694},{\"attributes\":{\"id\":\"fig_3\"},\"end\":38221,\"start\":38067},{\"attributes\":{\"id\":\"fig_4\"},\"end\":38454,\"start\":38222},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":38954,\"start\":38455},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":39067,\"start\":38955},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":40103,\"start\":39068},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":41197,\"start\":40104},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":42013,\"start\":41198},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":42363,\"start\":42014},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":42561,\"start\":42364},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":44703,\"start\":42562},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":44788,\"start\":44704}]", "paragraph": "[{\"end\":3572,\"start\":3001},{\"end\":4063,\"start\":3574},{\"end\":5212,\"start\":4065},{\"end\":7739,\"start\":5214},{\"end\":9132,\"start\":7741},{\"end\":10327,\"start\":9134},{\"end\":10396,\"start\":10329},{\"end\":11477,\"start\":10398},{\"end\":11819,\"start\":11479},{\"end\":12368,\"start\":11842},{\"end\":13040,\"start\":12370},{\"end\":14062,\"start\":13042},{\"end\":15073,\"start\":14075},{\"end\":15562,\"start\":15094},{\"end\":16535,\"start\":15564},{\"end\":17778,\"start\":16537},{\"end\":18190,\"start\":17780},{\"end\":18231,\"start\":18212},{\"end\":18487,\"start\":18341},{\"end\":18549,\"start\":18502},{\"end\":19777,\"start\":18686},{\"end\":20883,\"start\":19833},{\"end\":22486,\"start\":20906},{\"end\":22616,\"start\":22530},{\"end\":22673,\"start\":22668},{\"end\":22726,\"start\":22720},{\"end\":23340,\"start\":22978},{\"end\":23529,\"start\":23401},{\"end\":25012,\"start\":23542},{\"end\":25696,\"start\":25014},{\"end\":26387,\"start\":25698},{\"end\":26726,\"start\":26389},{\"end\":26912,\"start\":26741},{\"end\":27214,\"start\":26941},{\"end\":27650,\"start\":27216},{\"end\":28413,\"start\":27652},{\"end\":28796,\"start\":28415},{\"end\":29576,\"start\":28798},{\"end\":30819,\"start\":29593},{\"end\":31858,\"start\":30821},{\"end\":32732,\"start\":31873},{\"end\":33327,\"start\":32734},{\"end\":33808,\"start\":33329}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":18340,\"start\":18232},{\"attributes\":{\"id\":\"formula_1\"},\"end\":18685,\"start\":18550},{\"attributes\":{\"id\":\"formula_2\"},\"end\":19832,\"start\":19778},{\"attributes\":{\"id\":\"formula_3\"},\"end\":22529,\"start\":22487},{\"attributes\":{\"id\":\"formula_4\"},\"end\":22667,\"start\":22617},{\"attributes\":{\"id\":\"formula_5\"},\"end\":22719,\"start\":22674},{\"attributes\":{\"id\":\"formula_6\"},\"end\":22819,\"start\":22727},{\"attributes\":{\"id\":\"formula_7\"},\"end\":22894,\"start\":22819},{\"attributes\":{\"id\":\"formula_8\"},\"end\":22977,\"start\":22894},{\"attributes\":{\"id\":\"formula_9\"},\"end\":23386,\"start\":23341},{\"attributes\":{\"id\":\"formula_10\"},\"end\":26940,\"start\":26913}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":6603,\"start\":6596},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":17553,\"start\":17546},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":18433,\"start\":18426},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":24831,\"start\":24824},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":28340,\"start\":28333},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":28772,\"start\":28765},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":29371,\"start\":29364}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2999,\"start\":2987},{\"attributes\":{\"n\":\"2\"},\"end\":11840,\"start\":11822},{\"attributes\":{\"n\":\"3\"},\"end\":14073,\"start\":14065},{\"attributes\":{\"n\":\"3.1\"},\"end\":15092,\"start\":15076},{\"end\":18210,\"start\":18193},{\"attributes\":{\"n\":\"3.2\"},\"end\":18500,\"start\":18490},{\"attributes\":{\"n\":\"3.2.1\"},\"end\":20904,\"start\":20886},{\"attributes\":{\"n\":\"4\"},\"end\":23399,\"start\":23388},{\"attributes\":{\"n\":\"4.1\"},\"end\":23540,\"start\":23532},{\"attributes\":{\"n\":\"4.2\"},\"end\":26739,\"start\":26729},{\"attributes\":{\"n\":\"5\"},\"end\":29591,\"start\":29579},{\"attributes\":{\"n\":\"6\"},\"end\":31871,\"start\":31861},{\"end\":33820,\"start\":33810},{\"end\":37721,\"start\":37695},{\"end\":38088,\"start\":38068},{\"end\":38233,\"start\":38223},{\"end\":38465,\"start\":38456},{\"end\":38965,\"start\":38956},{\"end\":39078,\"start\":39069},{\"end\":40114,\"start\":40105},{\"end\":42024,\"start\":42015},{\"end\":42374,\"start\":42365},{\"end\":44714,\"start\":44705}]", "table": "[{\"end\":40103,\"start\":39177},{\"end\":41197,\"start\":40143},{\"end\":42013,\"start\":42006},{\"end\":42363,\"start\":42175},{\"end\":42561,\"start\":42426}]", "figure_caption": "[{\"end\":36578,\"start\":33822},{\"end\":37693,\"start\":36581},{\"end\":38066,\"start\":37728},{\"end\":38221,\"start\":38091},{\"end\":38454,\"start\":38235},{\"end\":38954,\"start\":38467},{\"end\":39067,\"start\":38967},{\"end\":39177,\"start\":39080},{\"end\":40143,\"start\":40116},{\"end\":42006,\"start\":41200},{\"end\":42175,\"start\":42026},{\"end\":42426,\"start\":42376},{\"end\":44703,\"start\":42564},{\"end\":44788,\"start\":44716}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":7643,\"start\":7635},{\"end\":14004,\"start\":13996},{\"end\":15502,\"start\":15494},{\"end\":20825,\"start\":20817},{\"end\":21605,\"start\":21597},{\"end\":23824,\"start\":23816},{\"end\":24913,\"start\":24904},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":29290,\"start\":29282}]", "bib_author_first_name": "[{\"end\":45399,\"start\":45395},{\"end\":45413,\"start\":45408},{\"end\":45797,\"start\":45796},{\"end\":45815,\"start\":45808},{\"end\":45839,\"start\":45832},{\"end\":46152,\"start\":46151},{\"end\":46441,\"start\":46440},{\"end\":46451,\"start\":46450},{\"end\":46453,\"start\":46452},{\"end\":46462,\"start\":46461},{\"end\":46774,\"start\":46770},{\"end\":46787,\"start\":46783},{\"end\":46802,\"start\":46797},{\"end\":47035,\"start\":47034},{\"end\":47041,\"start\":47040},{\"end\":47050,\"start\":47049},{\"end\":47057,\"start\":47056},{\"end\":47254,\"start\":47250},{\"end\":47268,\"start\":47263},{\"end\":47285,\"start\":47279},{\"end\":47508,\"start\":47507},{\"end\":47519,\"start\":47518},{\"end\":47530,\"start\":47529},{\"end\":47540,\"start\":47539},{\"end\":47553,\"start\":47552},{\"end\":47562,\"start\":47561},{\"end\":47564,\"start\":47563},{\"end\":47573,\"start\":47572},{\"end\":47583,\"start\":47582},{\"end\":47759,\"start\":47756},{\"end\":47765,\"start\":47764},{\"end\":47774,\"start\":47773},{\"end\":47776,\"start\":47775},{\"end\":47786,\"start\":47785},{\"end\":47788,\"start\":47787},{\"end\":48064,\"start\":48063},{\"end\":48074,\"start\":48073},{\"end\":48232,\"start\":48231},{\"end\":48241,\"start\":48240},{\"end\":48254,\"start\":48253},{\"end\":48264,\"start\":48263},{\"end\":48275,\"start\":48274},{\"end\":48289,\"start\":48288},{\"end\":48583,\"start\":48582},{\"end\":48594,\"start\":48593},{\"end\":48607,\"start\":48606},{\"end\":48615,\"start\":48614},{\"end\":48617,\"start\":48616},{\"end\":48628,\"start\":48627},{\"end\":48963,\"start\":48958},{\"end\":48980,\"start\":48975},{\"end\":48993,\"start\":48989},{\"end\":49009,\"start\":49002},{\"end\":49023,\"start\":49018},{\"end\":49042,\"start\":49037},{\"end\":49353,\"start\":49352},{\"end\":49365,\"start\":49360},{\"end\":49779,\"start\":49775},{\"end\":50243,\"start\":50240},{\"end\":50257,\"start\":50253},{\"end\":50926,\"start\":50921},{\"end\":50939,\"start\":50934},{\"end\":50950,\"start\":50946},{\"end\":51317,\"start\":51313},{\"end\":51328,\"start\":51324},{\"end\":51338,\"start\":51334},{\"end\":51937,\"start\":51929},{\"end\":51952,\"start\":51946},{\"end\":52473,\"start\":52468},{\"end\":52485,\"start\":52484},{\"end\":53054,\"start\":53045},{\"end\":53069,\"start\":53060},{\"end\":53081,\"start\":53074},{\"end\":53101,\"start\":53086},{\"end\":53568,\"start\":53560},{\"end\":53590,\"start\":53581},{\"end\":53604,\"start\":53598},{\"end\":54354,\"start\":54348},{\"end\":54369,\"start\":54361},{\"end\":54380,\"start\":54374},{\"end\":54392,\"start\":54387},{\"end\":54407,\"start\":54400},{\"end\":54421,\"start\":54414},{\"end\":54436,\"start\":54429},{\"end\":54452,\"start\":54444},{\"end\":55093,\"start\":55088},{\"end\":55108,\"start\":55103},{\"end\":55602,\"start\":55601},{\"end\":55610,\"start\":55609},{\"end\":55619,\"start\":55618},{\"end\":55627,\"start\":55626},{\"end\":55816,\"start\":55815},{\"end\":55822,\"start\":55821},{\"end\":55830,\"start\":55829},{\"end\":55838,\"start\":55837},{\"end\":55845,\"start\":55844},{\"end\":55852,\"start\":55851},{\"end\":55981,\"start\":55977},{\"end\":55993,\"start\":55988},{\"end\":56004,\"start\":55999},{\"end\":56016,\"start\":56011},{\"end\":56029,\"start\":56023},{\"end\":56041,\"start\":56037},{\"end\":56519,\"start\":56513},{\"end\":56540,\"start\":56531},{\"end\":56547,\"start\":56543},{\"end\":56555,\"start\":56550},{\"end\":56564,\"start\":56560},{\"end\":56576,\"start\":56571},{\"end\":56586,\"start\":56582},{\"end\":56597,\"start\":56593},{\"end\":57039,\"start\":57038},{\"end\":57049,\"start\":57048},{\"end\":57295,\"start\":57294},{\"end\":57306,\"start\":57305},{\"end\":57545,\"start\":57544},{\"end\":57557,\"start\":57556},{\"end\":57564,\"start\":57563},{\"end\":57572,\"start\":57571},{\"end\":57872,\"start\":57871},{\"end\":57893,\"start\":57885},{\"end\":57914,\"start\":57907},{\"end\":58189,\"start\":58183},{\"end\":58203,\"start\":58192},{\"end\":58222,\"start\":58214},{\"end\":58238,\"start\":58231},{\"end\":58641,\"start\":58635},{\"end\":58651,\"start\":58644},{\"end\":59104,\"start\":59098},{\"end\":59112,\"start\":59107},{\"end\":59121,\"start\":59115},{\"end\":59131,\"start\":59124},{\"end\":59449,\"start\":59448},{\"end\":59460,\"start\":59459},{\"end\":59473,\"start\":59472},{\"end\":59633,\"start\":59632},{\"end\":59645,\"start\":59644},{\"end\":59655,\"start\":59654},{\"end\":59833,\"start\":59832},{\"end\":59843,\"start\":59842},{\"end\":59852,\"start\":59851},{\"end\":59867,\"start\":59866},{\"end\":59880,\"start\":59879},{\"end\":60105,\"start\":60104},{\"end\":60116,\"start\":60115},{\"end\":60131,\"start\":60130},{\"end\":60447,\"start\":60446},{\"end\":60459,\"start\":60458},{\"end\":60466,\"start\":60465},{\"end\":60478,\"start\":60477},{\"end\":60486,\"start\":60485},{\"end\":60497,\"start\":60496},{\"end\":60722,\"start\":60721},{\"end\":60733,\"start\":60732},{\"end\":60744,\"start\":60743},{\"end\":60759,\"start\":60758},{\"end\":61057,\"start\":61056},{\"end\":61069,\"start\":61068},{\"end\":61082,\"start\":61081},{\"end\":61091,\"start\":61090},{\"end\":61330,\"start\":61329},{\"end\":61345,\"start\":61344},{\"end\":61354,\"start\":61353},{\"end\":61366,\"start\":61365},{\"end\":61381,\"start\":61380},{\"end\":61394,\"start\":61393},{\"end\":61686,\"start\":61685},{\"end\":61697,\"start\":61696},{\"end\":61705,\"start\":61704},{\"end\":61715,\"start\":61714},{\"end\":61956,\"start\":61955},{\"end\":61966,\"start\":61965},{\"end\":62257,\"start\":62256},{\"end\":62266,\"start\":62265},{\"end\":62279,\"start\":62278},{\"end\":62285,\"start\":62284},{\"end\":62296,\"start\":62295},{\"end\":62580,\"start\":62579},{\"end\":62589,\"start\":62588},{\"end\":62596,\"start\":62595},{\"end\":62604,\"start\":62603},{\"end\":62613,\"start\":62612},{\"end\":62974,\"start\":62973},{\"end\":62981,\"start\":62980}]", "bib_author_last_name": "[{\"end\":45406,\"start\":45400},{\"end\":45422,\"start\":45414},{\"end\":45806,\"start\":45798},{\"end\":45820,\"start\":45816},{\"end\":45830,\"start\":45822},{\"end\":45847,\"start\":45840},{\"end\":45853,\"start\":45849},{\"end\":46159,\"start\":46153},{\"end\":46448,\"start\":46442},{\"end\":46459,\"start\":46454},{\"end\":46469,\"start\":46463},{\"end\":46781,\"start\":46775},{\"end\":46795,\"start\":46788},{\"end\":47038,\"start\":47036},{\"end\":47047,\"start\":47042},{\"end\":47054,\"start\":47051},{\"end\":47061,\"start\":47058},{\"end\":47261,\"start\":47255},{\"end\":47277,\"start\":47269},{\"end\":47294,\"start\":47286},{\"end\":47516,\"start\":47509},{\"end\":47527,\"start\":47520},{\"end\":47537,\"start\":47531},{\"end\":47550,\"start\":47541},{\"end\":47559,\"start\":47554},{\"end\":47570,\"start\":47565},{\"end\":47580,\"start\":47574},{\"end\":47594,\"start\":47584},{\"end\":47762,\"start\":47760},{\"end\":47771,\"start\":47766},{\"end\":47783,\"start\":47777},{\"end\":48071,\"start\":48065},{\"end\":48081,\"start\":48075},{\"end\":48238,\"start\":48233},{\"end\":48251,\"start\":48242},{\"end\":48261,\"start\":48255},{\"end\":48272,\"start\":48265},{\"end\":48286,\"start\":48276},{\"end\":48296,\"start\":48290},{\"end\":48308,\"start\":48298},{\"end\":48591,\"start\":48584},{\"end\":48604,\"start\":48595},{\"end\":48612,\"start\":48608},{\"end\":48625,\"start\":48618},{\"end\":48633,\"start\":48629},{\"end\":48973,\"start\":48964},{\"end\":48987,\"start\":48981},{\"end\":49000,\"start\":48994},{\"end\":49016,\"start\":49010},{\"end\":49035,\"start\":49024},{\"end\":49048,\"start\":49043},{\"end\":49358,\"start\":49354},{\"end\":49368,\"start\":49366},{\"end\":49377,\"start\":49370},{\"end\":49783,\"start\":49780},{\"end\":50251,\"start\":50244},{\"end\":50263,\"start\":50258},{\"end\":50932,\"start\":50927},{\"end\":50944,\"start\":50940},{\"end\":50956,\"start\":50951},{\"end\":51322,\"start\":51318},{\"end\":51332,\"start\":51329},{\"end\":51342,\"start\":51339},{\"end\":51944,\"start\":51938},{\"end\":51966,\"start\":51953},{\"end\":52482,\"start\":52474},{\"end\":52497,\"start\":52486},{\"end\":52506,\"start\":52499},{\"end\":53058,\"start\":53055},{\"end\":53072,\"start\":53070},{\"end\":53084,\"start\":53082},{\"end\":53106,\"start\":53102},{\"end\":53579,\"start\":53569},{\"end\":53596,\"start\":53591},{\"end\":53612,\"start\":53605},{\"end\":54359,\"start\":54355},{\"end\":54372,\"start\":54370},{\"end\":54385,\"start\":54381},{\"end\":54398,\"start\":54393},{\"end\":54412,\"start\":54408},{\"end\":54427,\"start\":54422},{\"end\":54442,\"start\":54437},{\"end\":54458,\"start\":54453},{\"end\":55101,\"start\":55094},{\"end\":55118,\"start\":55109},{\"end\":55607,\"start\":55603},{\"end\":55616,\"start\":55611},{\"end\":55624,\"start\":55620},{\"end\":55632,\"start\":55628},{\"end\":55819,\"start\":55817},{\"end\":55827,\"start\":55823},{\"end\":55835,\"start\":55831},{\"end\":55842,\"start\":55839},{\"end\":55849,\"start\":55846},{\"end\":55856,\"start\":55853},{\"end\":55986,\"start\":55982},{\"end\":55997,\"start\":55994},{\"end\":56009,\"start\":56005},{\"end\":56021,\"start\":56017},{\"end\":56035,\"start\":56030},{\"end\":56046,\"start\":56042},{\"end\":56529,\"start\":56520},{\"end\":56558,\"start\":56556},{\"end\":56569,\"start\":56565},{\"end\":56580,\"start\":56577},{\"end\":56591,\"start\":56587},{\"end\":57046,\"start\":57040},{\"end\":57059,\"start\":57050},{\"end\":57065,\"start\":57061},{\"end\":57303,\"start\":57296},{\"end\":57317,\"start\":57307},{\"end\":57554,\"start\":57546},{\"end\":57561,\"start\":57558},{\"end\":57569,\"start\":57565},{\"end\":57580,\"start\":57573},{\"end\":57883,\"start\":57873},{\"end\":57905,\"start\":57894},{\"end\":58212,\"start\":58204},{\"end\":58229,\"start\":58223},{\"end\":58245,\"start\":58239},{\"end\":59457,\"start\":59450},{\"end\":59470,\"start\":59461},{\"end\":59479,\"start\":59474},{\"end\":59642,\"start\":59634},{\"end\":59652,\"start\":59646},{\"end\":59666,\"start\":59656},{\"end\":59840,\"start\":59834},{\"end\":59849,\"start\":59844},{\"end\":59864,\"start\":59853},{\"end\":59877,\"start\":59868},{\"end\":59887,\"start\":59881},{\"end\":60113,\"start\":60106},{\"end\":60128,\"start\":60117},{\"end\":60139,\"start\":60132},{\"end\":60456,\"start\":60448},{\"end\":60463,\"start\":60460},{\"end\":60475,\"start\":60467},{\"end\":60483,\"start\":60479},{\"end\":60494,\"start\":60487},{\"end\":60503,\"start\":60498},{\"end\":60730,\"start\":60723},{\"end\":60741,\"start\":60734},{\"end\":60756,\"start\":60745},{\"end\":60765,\"start\":60760},{\"end\":61066,\"start\":61058},{\"end\":61079,\"start\":61070},{\"end\":61088,\"start\":61083},{\"end\":61098,\"start\":61092},{\"end\":61342,\"start\":61331},{\"end\":61351,\"start\":61346},{\"end\":61363,\"start\":61355},{\"end\":61378,\"start\":61367},{\"end\":61391,\"start\":61382},{\"end\":61404,\"start\":61395},{\"end\":61694,\"start\":61687},{\"end\":61702,\"start\":61698},{\"end\":61712,\"start\":61706},{\"end\":61723,\"start\":61716},{\"end\":61963,\"start\":61957},{\"end\":61974,\"start\":61967},{\"end\":62263,\"start\":62258},{\"end\":62276,\"start\":62267},{\"end\":62282,\"start\":62280},{\"end\":62293,\"start\":62286},{\"end\":62304,\"start\":62297},{\"end\":62586,\"start\":62581},{\"end\":62593,\"start\":62590},{\"end\":62601,\"start\":62597},{\"end\":62610,\"start\":62605},{\"end\":62619,\"start\":62614},{\"end\":62978,\"start\":62975},{\"end\":62991,\"start\":62982}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":17330993},\"end\":45672,\"start\":45329},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":6421896},\"end\":46149,\"start\":45674},{\"attributes\":{\"id\":\"b2\"},\"end\":46438,\"start\":46151},{\"attributes\":{\"id\":\"b3\"},\"end\":46676,\"start\":46440},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":12656359},\"end\":46986,\"start\":46678},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":206594692},\"end\":47169,\"start\":46988},{\"attributes\":{\"id\":\"b6\"},\"end\":47478,\"start\":47171},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":13756489},\"end\":47752,\"start\":47480},{\"attributes\":{\"doi\":\"arXiv:1607.06450\",\"id\":\"b8\"},\"end\":47945,\"start\":47754},{\"attributes\":{\"id\":\"b9\"},\"end\":48229,\"start\":47947},{\"attributes\":{\"id\":\"b10\"},\"end\":48503,\"start\":48231},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":16447573},\"end\":48905,\"start\":48505},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":351666},\"end\":49294,\"start\":48907},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":2407601},\"end\":49714,\"start\":49296},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":9672033},\"end\":50150,\"start\":49716},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":17953556},\"end\":50855,\"start\":50152},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":368182},\"end\":51227,\"start\":50857},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":784094},\"end\":51853,\"start\":51229},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":8201968},\"end\":52395,\"start\":51855},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":716020},\"end\":52983,\"start\":52397},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":12181509},\"end\":53467,\"start\":52985},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":3592209},\"end\":54285,\"start\":53469},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":13701579},\"end\":55022,\"start\":54287},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":3111471},\"end\":55523,\"start\":55024},{\"attributes\":{\"id\":\"b24\"},\"end\":55757,\"start\":55525},{\"attributes\":{\"id\":\"b25\"},\"end\":55975,\"start\":55759},{\"attributes\":{\"id\":\"b26\"},\"end\":56430,\"start\":55977},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":49317374},\"end\":56912,\"start\":56432},{\"attributes\":{\"id\":\"b28\"},\"end\":57245,\"start\":56914},{\"attributes\":{\"id\":\"b29\"},\"end\":57401,\"start\":57247},{\"attributes\":{\"id\":\"b30\"},\"end\":57822,\"start\":57403},{\"attributes\":{\"id\":\"b31\"},\"end\":58181,\"start\":57824},{\"attributes\":{\"id\":\"b32\"},\"end\":58633,\"start\":58183},{\"attributes\":{\"id\":\"b33\"},\"end\":59007,\"start\":58635},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":227909938},\"end\":59394,\"start\":59009},{\"attributes\":{\"id\":\"b35\"},\"end\":59592,\"start\":59396},{\"attributes\":{\"id\":\"b36\"},\"end\":59771,\"start\":59594},{\"attributes\":{\"id\":\"b37\"},\"end\":60021,\"start\":59773},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":5647495},\"end\":60363,\"start\":60023},{\"attributes\":{\"id\":\"b39\"},\"end\":60663,\"start\":60365},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":44263797},\"end\":60968,\"start\":60665},{\"attributes\":{\"id\":\"b41\"},\"end\":61244,\"start\":60970},{\"attributes\":{\"id\":\"b42\"},\"end\":61605,\"start\":61246},{\"attributes\":{\"id\":\"b43\"},\"end\":61857,\"start\":61607},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":53287215},\"end\":62190,\"start\":61859},{\"attributes\":{\"doi\":\"Arxiv:1410.8206\",\"id\":\"b45\"},\"end\":62497,\"start\":62192},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":10760102},\"end\":62904,\"start\":62499},{\"attributes\":{\"doi\":\"Arxiv:1801.08660.\",\"id\":\"b47\"},\"end\":63154,\"start\":62906}]", "bib_title": "[{\"end\":45393,\"start\":45329},{\"end\":45794,\"start\":45674},{\"end\":46768,\"start\":46678},{\"end\":47032,\"start\":46988},{\"end\":47505,\"start\":47480},{\"end\":48580,\"start\":48505},{\"end\":48956,\"start\":48907},{\"end\":49350,\"start\":49296},{\"end\":49773,\"start\":49716},{\"end\":50238,\"start\":50152},{\"end\":50919,\"start\":50857},{\"end\":51311,\"start\":51229},{\"end\":51927,\"start\":51855},{\"end\":52466,\"start\":52397},{\"end\":53043,\"start\":52985},{\"end\":53558,\"start\":53469},{\"end\":54346,\"start\":54287},{\"end\":55086,\"start\":55024},{\"end\":56511,\"start\":56432},{\"end\":57869,\"start\":57824},{\"end\":59096,\"start\":59009},{\"end\":59446,\"start\":59396},{\"end\":60102,\"start\":60023},{\"end\":60719,\"start\":60665},{\"end\":61953,\"start\":61859},{\"end\":62577,\"start\":62499}]", "bib_author": "[{\"end\":45408,\"start\":45395},{\"end\":45424,\"start\":45408},{\"end\":45808,\"start\":45796},{\"end\":45822,\"start\":45808},{\"end\":45832,\"start\":45822},{\"end\":45849,\"start\":45832},{\"end\":45855,\"start\":45849},{\"end\":46161,\"start\":46151},{\"end\":46450,\"start\":46440},{\"end\":46461,\"start\":46450},{\"end\":46471,\"start\":46461},{\"end\":46783,\"start\":46770},{\"end\":46797,\"start\":46783},{\"end\":46805,\"start\":46797},{\"end\":47040,\"start\":47034},{\"end\":47049,\"start\":47040},{\"end\":47056,\"start\":47049},{\"end\":47063,\"start\":47056},{\"end\":47263,\"start\":47250},{\"end\":47279,\"start\":47263},{\"end\":47296,\"start\":47279},{\"end\":47518,\"start\":47507},{\"end\":47529,\"start\":47518},{\"end\":47539,\"start\":47529},{\"end\":47552,\"start\":47539},{\"end\":47561,\"start\":47552},{\"end\":47572,\"start\":47561},{\"end\":47582,\"start\":47572},{\"end\":47596,\"start\":47582},{\"end\":47764,\"start\":47756},{\"end\":47773,\"start\":47764},{\"end\":47785,\"start\":47773},{\"end\":47791,\"start\":47785},{\"end\":48073,\"start\":48063},{\"end\":48083,\"start\":48073},{\"end\":48240,\"start\":48231},{\"end\":48253,\"start\":48240},{\"end\":48263,\"start\":48253},{\"end\":48274,\"start\":48263},{\"end\":48288,\"start\":48274},{\"end\":48298,\"start\":48288},{\"end\":48310,\"start\":48298},{\"end\":48593,\"start\":48582},{\"end\":48606,\"start\":48593},{\"end\":48614,\"start\":48606},{\"end\":48627,\"start\":48614},{\"end\":48635,\"start\":48627},{\"end\":48975,\"start\":48958},{\"end\":48989,\"start\":48975},{\"end\":49002,\"start\":48989},{\"end\":49018,\"start\":49002},{\"end\":49037,\"start\":49018},{\"end\":49050,\"start\":49037},{\"end\":49360,\"start\":49352},{\"end\":49370,\"start\":49360},{\"end\":49379,\"start\":49370},{\"end\":49785,\"start\":49775},{\"end\":50253,\"start\":50240},{\"end\":50265,\"start\":50253},{\"end\":50934,\"start\":50921},{\"end\":50946,\"start\":50934},{\"end\":50958,\"start\":50946},{\"end\":51324,\"start\":51313},{\"end\":51334,\"start\":51324},{\"end\":51344,\"start\":51334},{\"end\":51946,\"start\":51929},{\"end\":51968,\"start\":51946},{\"end\":52484,\"start\":52468},{\"end\":52499,\"start\":52484},{\"end\":52508,\"start\":52499},{\"end\":53060,\"start\":53045},{\"end\":53074,\"start\":53060},{\"end\":53086,\"start\":53074},{\"end\":53108,\"start\":53086},{\"end\":53581,\"start\":53560},{\"end\":53598,\"start\":53581},{\"end\":53614,\"start\":53598},{\"end\":54361,\"start\":54348},{\"end\":54374,\"start\":54361},{\"end\":54387,\"start\":54374},{\"end\":54400,\"start\":54387},{\"end\":54414,\"start\":54400},{\"end\":54429,\"start\":54414},{\"end\":54444,\"start\":54429},{\"end\":54460,\"start\":54444},{\"end\":55103,\"start\":55088},{\"end\":55120,\"start\":55103},{\"end\":55609,\"start\":55601},{\"end\":55618,\"start\":55609},{\"end\":55626,\"start\":55618},{\"end\":55634,\"start\":55626},{\"end\":55821,\"start\":55815},{\"end\":55829,\"start\":55821},{\"end\":55837,\"start\":55829},{\"end\":55844,\"start\":55837},{\"end\":55851,\"start\":55844},{\"end\":55858,\"start\":55851},{\"end\":55988,\"start\":55977},{\"end\":55999,\"start\":55988},{\"end\":56011,\"start\":55999},{\"end\":56023,\"start\":56011},{\"end\":56037,\"start\":56023},{\"end\":56048,\"start\":56037},{\"end\":56531,\"start\":56513},{\"end\":56543,\"start\":56531},{\"end\":56550,\"start\":56543},{\"end\":56560,\"start\":56550},{\"end\":56571,\"start\":56560},{\"end\":56582,\"start\":56571},{\"end\":56593,\"start\":56582},{\"end\":56600,\"start\":56593},{\"end\":57048,\"start\":57038},{\"end\":57061,\"start\":57048},{\"end\":57067,\"start\":57061},{\"end\":57305,\"start\":57294},{\"end\":57319,\"start\":57305},{\"end\":57556,\"start\":57544},{\"end\":57563,\"start\":57556},{\"end\":57571,\"start\":57563},{\"end\":57582,\"start\":57571},{\"end\":57885,\"start\":57871},{\"end\":57907,\"start\":57885},{\"end\":57917,\"start\":57907},{\"end\":58192,\"start\":58183},{\"end\":58214,\"start\":58192},{\"end\":58231,\"start\":58214},{\"end\":58247,\"start\":58231},{\"end\":58644,\"start\":58635},{\"end\":58654,\"start\":58644},{\"end\":59107,\"start\":59098},{\"end\":59115,\"start\":59107},{\"end\":59124,\"start\":59115},{\"end\":59134,\"start\":59124},{\"end\":59459,\"start\":59448},{\"end\":59472,\"start\":59459},{\"end\":59481,\"start\":59472},{\"end\":59644,\"start\":59632},{\"end\":59654,\"start\":59644},{\"end\":59668,\"start\":59654},{\"end\":59842,\"start\":59832},{\"end\":59851,\"start\":59842},{\"end\":59866,\"start\":59851},{\"end\":59879,\"start\":59866},{\"end\":59889,\"start\":59879},{\"end\":60115,\"start\":60104},{\"end\":60130,\"start\":60115},{\"end\":60141,\"start\":60130},{\"end\":60458,\"start\":60446},{\"end\":60465,\"start\":60458},{\"end\":60477,\"start\":60465},{\"end\":60485,\"start\":60477},{\"end\":60496,\"start\":60485},{\"end\":60505,\"start\":60496},{\"end\":60732,\"start\":60721},{\"end\":60743,\"start\":60732},{\"end\":60758,\"start\":60743},{\"end\":60767,\"start\":60758},{\"end\":61068,\"start\":61056},{\"end\":61081,\"start\":61068},{\"end\":61090,\"start\":61081},{\"end\":61100,\"start\":61090},{\"end\":61344,\"start\":61329},{\"end\":61353,\"start\":61344},{\"end\":61365,\"start\":61353},{\"end\":61380,\"start\":61365},{\"end\":61393,\"start\":61380},{\"end\":61406,\"start\":61393},{\"end\":61696,\"start\":61685},{\"end\":61704,\"start\":61696},{\"end\":61714,\"start\":61704},{\"end\":61725,\"start\":61714},{\"end\":61965,\"start\":61955},{\"end\":61976,\"start\":61965},{\"end\":62265,\"start\":62256},{\"end\":62278,\"start\":62265},{\"end\":62284,\"start\":62278},{\"end\":62295,\"start\":62284},{\"end\":62306,\"start\":62295},{\"end\":62588,\"start\":62579},{\"end\":62595,\"start\":62588},{\"end\":62603,\"start\":62595},{\"end\":62612,\"start\":62603},{\"end\":62621,\"start\":62612},{\"end\":62980,\"start\":62973},{\"end\":62993,\"start\":62980}]", "bib_venue": "[{\"end\":45482,\"start\":45424},{\"end\":45912,\"start\":45855},{\"end\":46286,\"start\":46161},{\"end\":46554,\"start\":46471},{\"end\":46821,\"start\":46805},{\"end\":47067,\"start\":47063},{\"end\":47248,\"start\":47171},{\"end\":47600,\"start\":47596},{\"end\":48061,\"start\":47947},{\"end\":48349,\"start\":48310},{\"end\":48684,\"start\":48635},{\"end\":49086,\"start\":49050},{\"end\":49447,\"start\":49379},{\"end\":49871,\"start\":49785},{\"end\":50407,\"start\":50265},{\"end\":51007,\"start\":50958},{\"end\":51430,\"start\":51344},{\"end\":52055,\"start\":51968},{\"end\":52597,\"start\":52508},{\"end\":53174,\"start\":53108},{\"end\":53756,\"start\":53614},{\"end\":54547,\"start\":54460},{\"end\":55206,\"start\":55120},{\"end\":55599,\"start\":55525},{\"end\":55813,\"start\":55759},{\"end\":56129,\"start\":56048},{\"end\":56632,\"start\":56600},{\"end\":57036,\"start\":56914},{\"end\":57292,\"start\":57247},{\"end\":57542,\"start\":57403},{\"end\":57973,\"start\":57917},{\"end\":58346,\"start\":58247},{\"end\":58748,\"start\":58654},{\"end\":59191,\"start\":59134},{\"end\":59485,\"start\":59481},{\"end\":59630,\"start\":59594},{\"end\":59830,\"start\":59773},{\"end\":60179,\"start\":60141},{\"end\":60444,\"start\":60365},{\"end\":60798,\"start\":60767},{\"end\":61054,\"start\":60970},{\"end\":61327,\"start\":61246},{\"end\":61683,\"start\":61607},{\"end\":62007,\"start\":61976},{\"end\":62254,\"start\":62192},{\"end\":62686,\"start\":62621},{\"end\":62971,\"start\":62906},{\"end\":46833,\"start\":46823},{\"end\":49516,\"start\":49449},{\"end\":49955,\"start\":49873},{\"end\":50552,\"start\":50409},{\"end\":51025,\"start\":51009},{\"end\":51519,\"start\":51432},{\"end\":52129,\"start\":52057},{\"end\":52691,\"start\":52599},{\"end\":53243,\"start\":53176},{\"end\":53907,\"start\":53758},{\"end\":54621,\"start\":54549},{\"end\":55295,\"start\":55208}]"}}}, "year": 2023, "month": 12, "day": 17}