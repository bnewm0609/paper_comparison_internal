{"id": 26071966, "updated": "2023-09-29 09:58:58.185", "metadata": {"title": "Deep Mutual Learning", "authors": "[{\"first\":\"Ying\",\"last\":\"Zhang\",\"middle\":[]},{\"first\":\"Tao\",\"last\":\"Xiang\",\"middle\":[]},{\"first\":\"Timothy\",\"last\":\"Hospedales\",\"middle\":[\"M.\"]},{\"first\":\"Huchuan\",\"last\":\"Lu\",\"middle\":[]}]", "venue": "ArXiv", "journal": "ArXiv", "publication_date": {"year": 2017, "month": 6, "day": 1}, "abstract": "Model distillation is an effective and widely used technique to transfer knowledge from a teacher to a student network. The typical application is to transfer from a powerful large network or ensemble to a small network, that is better suited to low-memory or fast execution requirements. In this paper, we present a deep mutual learning (DML) strategy where, rather than one way transfer between a static pre-defined teacher and a student, an ensemble of students learn collaboratively and teach each other throughout the training process. Our experiments show that a variety of network architectures benefit from mutual learning and achieve compelling results on CIFAR-100 recognition and Market-1501 person re-identification benchmarks. Surprisingly, it is revealed that no prior powerful teacher network is necessary -- mutual learning of a collection of simple student networks works, and moreover outperforms distillation from a more powerful yet static teacher.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "1706.00384", "mag": "2951168573", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/cvpr/ZhangXHL18", "doi": "10.1109/cvpr.2018.00454"}}, "content": {"source": {"pdf_hash": "99cd8c164ac5227aeddaef16fe9c6980da380244", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/1706.00384v1.pdf\"]", "oa_url_match": true, "oa_info": {"license": null, "open_access_url": "https://www.pure.ed.ac.uk/ws/files/58941044/zhang2018DeepMutualLearning.pdf", "status": "GREEN"}}, "grobid": {"id": "84287d4f15112d40db91d6f03d8073286c4851f5", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/99cd8c164ac5227aeddaef16fe9c6980da380244.txt", "contents": "\nDeep Mutual Learning\n\n\nYing Zhang \nDalian University of Technology\nChina\n\nQueen Mary University of London\nUK\n\nTao Xiang t.xiang@qmul.ac.uk \nQueen Mary University of London\nUK\n\nTimothy M Hospedales t.hospedales@ed.ac.uk \nUniversity of Edinburgh\nUK\n\nHuchuan Lu \nDalian University of Technology\nChina\n\nDeep Mutual Learning\n\nModel distillation is an effective and widely used technique to transfer knowledge from a teacher to a student network. The typical application is to transfer from a powerful large network or ensemble to a small network, that is better suited to low-memory or fast execution requirements. In this paper, we present a deep mutual learning (DML) strategy where, rather than one way transfer between a static pre-defined teacher and a student, an ensemble of students learn collaboratively and teach each other throughout the training process. Our experiments show that a variety of network architectures benefit from mutual learning and achieve compelling results on CIFAR-100 recognition and Market-1501 person re-identification benchmarks. Surprisingly, it is revealed that no prior powerful teacher network is necessary -mutual learning of a collection of simple student networks works, and moreover outperforms distillation from a more powerful yet static teacher.\n\nIntroduction\n\nDeep neural networks achieve state of the art performance on many problems, but are often very large in depth or width, and contain large numbers of parameters [6,25]. This has the drawback that they may be slow to execute or demand large memory to store, limiting their use in applications or platforms with low memory or fast execution requirements. This has led to a rapidly growing area of research on smaller and faster models. Achieving compact yet accurate models has been approached in a variety of ways including explicit frugal architecture design [8], model compression [20], pruning [13], binarisation [18] and most interestingly model distillation [7]. Distillation-based model compression relates to the observation [3,2] that small networks often have the same representation capacity as large networks; but compared to large networks they are simply harder to train and find the right parameters that realise the desired function. That is, the limitation seems to lie in the difficulty of optimisation rather than in the network size [2]. To better learn a small network, the distillation approach starts with a powerful (deep and/or wide) teacher network (or network ensemble), and then trains a smaller student network to mimic the teacher [7,2,16,3]. Mimicking the teacher's class probabilities [7] and/or feature representation [2,19] conveys additional information beyond the conventional supervised learning target. The optimisation problem of learning to mimic the teacher turns out to be easier than learning the target function directly, and the much smaller student can match or even outperform [19] the larger teacher.\n\nIn this paper we explore a different but related idea to model distillation -that of mutual learning. Distillation starts with a powerful large and pre-trained teacher network and performs one-way knowledge transfer to a small untrained student. In contrast, in mutual learning we start with a pool of untrained students who learn simultaneously to solve the task together. Specifically, each student is trained with two losses: a conventional supervised learning loss, and a mimicry loss that aligns each student's class posterior with the class probabilities of other students. Trained in this way, it turns out that each student in such a peer-teaching based scenario learns significantly better than when learning alone in a conventional supervised learning scenario. Moreover student networks trained in this way achieve better results than students trained by conventional distillation from a larger pre-trained teacher. Furthermore, while the conventional understanding of distillation requires a teacher larger and more powerful than the intended student, it turns out that in many cases mutual learning of several large networks also improves performance compared to independent learning.\n\nIt is perhaps not obvious why the proposed procedure should work at all. Where does the additional knowledge come from, when the learning process starts out with all small and untrained student networks? Why does it converge to a good solution rather than being hamstrung by groupthink as 'the blind lead the blind'. Some intuition about these questions can be gained by considering the following: Each student is primarily directed by a conventional supervised learning loss, which means that their performance generally increases and they cannot drift arbitrarily into groupthink as a cohort. With supervised learning, all networks soon predict the same (true) labels for each training instance; but since each network starts from a different initial condition, their estimates of the probabilities of the next most likely classes vary. It is these secondary quantities that provide the extra information in distillation [7] as well as mutual learning. In mutual learning the student cohort effectively pools their collective estimate of the next most likely classes. Finding out -and matching -the other most likely classes for each training instance according to their peers increases each student's posterior entropy [4,17], which helps them to converge to a more robust (flatter) minima with better generalisation to testing data. This is related to very recent work on the robustness of high posterior entropy solutions (network parameter settings) in deep learning [4,17], but with a much more informed choice of alternatives than blind entropy regularisation.\n\nOverall, mutual learning provides a simple but effective way to improve the generalisation ability of a network by training collaboratively with a cohort of other networks. Compared with distillation by a pre-trained static large network, collaborative learning by small peers even achieves better performance. Furthermore we observe that: (i) the efficacy increases with the number of networks in the cohort (by training on small networks only, more of them can fit on one GPU for effective mutual learning); (ii) it applies to a variety of network architectures, and to heterogeneous cohorts consisting of mixed big and small networks; and (iii) even large networks mutually trained in cohort improve performance compared to independent training. Finally, we note that while our focus is on obtaining a single effective network, the entire cohort can also be used as a highly effective ensemble model.\n\n\nRelated Work\n\nThe distillation-based approach to model compression has been proposed over a decade ago [3] but was recently re-popularised by [7], where some additional intuition about why it works -due to the additional supervision and regularisation of the higher entropy soft-targets -was presented. Initially, a common application was to distill the function approximated by a powerful model/ensemble teacher into a single neural network student [3,7]. But later, the idea has been applied to distill powerful and easy-to-train large networks into small but harder-to-train networks [19] that can even outperform their teacher. Recently, distillation has been connected more systematically to information learning theory [15] and SVM+ [22] -an intelligent teacher provides privileged information to the student. Here we address dispensing with the teacher altogether, and allowing an ensemble of students to teach each other in mutual distillation.\n\nOther related ideas include Dual Learning [5] where two cross-lingual translation models teach each other interactively. But this only applies in this special translation problems where an unconditional within-language model is available to be used to evaluate the quality of the predictions, and ultimately provides the supervision that drives the learning process. In contrast, our mutual learning approach applies to general classification problems. While conventional wisdom about ensembles prioritises diversity [12], our mutual learning approach reduces diversity in the sense that all students become somewhat more similar by learning to mimic each other. However, our goal is not necessarily to produce a diverse ensemble, but to enable networks to find robust solutions that generalise well to testing data, which would otherwise be hard to find through conventional supervised learning.\n\n\nDeep Mutual Learning\n\n\nFormulation\n\nWe formulate the proposed DML approach with a cohort of two networks (see Fig. 1). Extension to more networks is straightforward (see Sec. Figure 1: Deep Mutual Learning (DML) schematic. Each network is trained with a supervised learning loss, and a KLD-based mimcry loss to match the probability estimates of its peers.\n2.3). Given N samples X = {x i } N i=1 from M classes, Network \u0398 \" Network \u0398 # Predictions labels KL(p1||p2) KL(p2||p1) ) \" ) # Logits * \" * # \u2026 $ H\" $ H#\nwe denote the corresponding label set as\nY = {y i } N i=1 with y i \u2208 {1, 2, ..., M }.\nThe probability of class m for sample x i given by a neural network \u0398 1 is computed as\np m 1 (x i ) = exp(z m 1 ) M m=1 exp(z m 1 ) ,(1)\nwhere the logit z m is the output of the \"softmax\" layer in \u0398 1 .\n\nFor multi-class classification, the objective function to train the network \u0398 1 is defined as the cross entropy error between the predicted values and the correct labels,\nL C1 = \u2212 N i=1 M m=1 I(y i , m) log(p m 1 (x i )),(2)\nwith an indicator function I defined as\nI(y i , m) = 1 y i = m 0 y i = m .\nThe conventional supervised loss trains the network to predict the correct labels for the training instances. To improve the generalisation performance of \u0398 1 on testing instances, we use another peer network \u0398 2 to provide training experience in the form of its posterior probability p 2 . To measure the match of the two network's predictions p 1 and p 2 , we adopt the Kullback Leibler (KL) Divergence.\n\nThe KL distance from p 1 to p 2 is computed as\nD KL (p 2 p 1 ) = N i=1 M m=1 p m 2 (x i ) log p m 2 (x i ) p m 1 (x i ) .(3)\nThe overall loss function L \u03981 for network \u0398 1 is defined as\nL \u03981 = L C1 + D KL (p 2 p 1 ).(4)\nSimilarly, the objective loss function L \u03982 for network \u0398 2 can be computed as\nL \u03982 = L C2 + D KL (p 1 p 2 ).(5)\nIn this way each network learns both to correctly predict the true label of training instances (supervised loss L C ) as well as to match the probability estimate of its peer (KL mimicry loss).\n\n\nOptimisation\n\nThe mutual learning strategy is performed in each mini-batch based model update step and throughout the whole training process. At each iteration, we compute the predictions of the two models and update both networks' parameters according to the predictions of the other. The optimisation of \u0398 1 and \u0398 2 is conducted iteratively until convergence. The optimisation details are summarised in Algorithm 1.\n\n\nAlgorithm 1: Deep Mutual Learning\n\nInput: Training set X , label set Y, learning rate \u03b3 1,t and \u03b3 2,t . Initialize: Models \u0398 1 and \u0398 2 to different initial conditions. Repeat :\nt = t + 1\nRandomly sample data x from X . 1: Update the predictions p 1 and p 2 of x by (1) for the current mini-batch 2: Compute the stochastic gradient and update \u0398 1 :\n\u0398 1 \u2190 \u0398 1 + \u03b3 1,t \u2202L \u03981 \u2202\u0398 1(6)\n3: Update the predictions p 1 and p 2 of x by (1) for the current mini-batch 4: Compute the stochastic gradient and update \u0398 2 :\n\u0398 2 \u2190 \u0398 2 + \u03b3 2,t \u2202L \u03982 \u2202\u0398 2(7)\nUntil : convergence\n\n\nExtension to Larger Student Cohorts\n\nThe proposed DML approach naturally extends to more networks in the student cohort.\nGiven K networks \u0398 1 , \u0398 2 , ..., \u0398 K (K \u2265 2), the objective function for optimising \u0398 k , (1 \u2264 k \u2264 K) becomes L \u0398 k = L C k + 1 K \u2212 1 K l=1,l =k D KL (p l p k ).(8)\nEquation (8) indicates that with K networks, DML for each student effectively takes the other K \u2212 1 networks in the cohort as K \u2212 1 teachers to provide learning experience. Equation (4) is now a special case of (8) with K = 2. Note that we have added the coefficient 1 K\u22121 to make sure that the training is mainly directed by supervised learning of the true labels. The optimisation for DML with more than two networks is a straightforward extension of Algorithm 1. It can be distributed by learning each network on one device and passing the small probability vectors between devices.\n\nWith more than two networks, an interesting alternative learning strategy for DML is to take the ensemble of all the other K \u2212 1 networks as a single teacher to provide an averaged learning experience, which would be very similar to the distillation approach but performed at each mini-batch model update. Then the objective function of \u0398 k can be written as\nL \u0398 k = L C k + D KL (p avg p k ), p avg = 1 K \u2212 1 K l=1,l =k p l .(9)\nIn our experiments (see Sec. 3.6), we find that this DML strategy with a single ensemble teacher or DML_e leads to worse performance than DML with K \u2212 1 teachers. This is because the model averaging step (Equation (9)) to build the teacher ensemble makes the teacher's posterior probabilities more peaked at the true class, thus reducing the posterior entropy over all classes. It is therefore contradictory to one of the objectives of DML which is to produce robust solutions with high posterior entropy.\n\n\nExperiments\n\n\nDatasets and Settings\n\nDatasets Two datasets are used in our experiments. The CIFAR-100 [11] dataset consists of 32 \u00d7 32 color images drawn from 100 classes, which are split into 50,000 train and 10,000 test images. The Top-1 classification accuracy is reported. The Market-1501 [27] dataset is widely used in the person re-identification problem which aims to associate people across different non-overlapping camera views. It contains 32,668 images of 1,501 identities captured from six camera views, with 751 identities for training and 750 identities for testing. As per state of the art approaches to this problem [28], we train the network for 751-way classification and use the resulting feature of the last pooling layer as a representation for nearest neighbour matching at testing. This is a more challenging dataset than CIFAR-100 because the task is instance recognition thus more fine-grained, and the dataset is smaller with more classes. For evaluation, the standard Cumulative Matching Characteristic (CMC) Rank-k accuracy and mean average precision (mAP) metrics [27] are used.\n\n\nImplementation Details\n\nWe implement all networks and training procedures in TensorFlow [1] and conduct all experiments on an NVIDIA GeForce GTX 1080 GPU. For CIFAR-100, we follow the experimental settings of [25]. Specifically, we use SGD with Nesterov momentum and set the initial learning rate to 0.1, momentum to 0.9 and mini-batch size to 64. The learning rate dropped by 0.1 every 60 epochs and we train for 200 epochs. The data augmentation includes horizontal flips and random crops from image padded by 4 pixels on each side, filling missing pixels with reflections of original image. For Market-1501, we use Adam optimiser [10], with learning rate lr = 0.0002, \u03b2 1 = 0.5, \u03b2 2 = 0.999 and a mini-batch size of 16. We train all the models for 100,000 iterations. We also report results with and without pre-training on ImageNet.\n\nModel Size The networks used in our experiments includes compact networks of typical student size: Resnet-32 [6] and MobileNet [8]; as well as large networks of typical teacher size: InceptionV1 [21] and Wide ResNet WRN-28-10 [25].   Table 2: Top-1 accuracy (%) on the CIFAR-100 dataset. \"DML-Independent\" measures the difference in accuracy between the network learned with DML and the same network learned independently. Table 3 summarises the mAP (%) and rank-1 accuracy (%) of Market-1501 with/without DML, as well as the comparison against existing state of the art methods. Each MobileNet is trained in a two-network cohort and the averaged performance of the two networks in the cohort is reported. We can see that DML greatly improves the performance of MobileNet compared to independent learning, both with and without pre-training on ImageNet. It can also be seen that the performance of the proposed DML approach trained with two MobileNets significantly outperforms prior state-of-the-art deep learning methods.  \n\n\nResults on Market-1501\n\n\nComparison with Distillation\n\nAs our method is strongly related to model distillation, we next provide a focused comparison to Distillation [7]. Table 4 compares our DML with model distillation where the teacher network (Net 1) is pre-trained and provides fixed posterior targets for the student network (Net 2). As expected the conventional distillation approach from a powerful pre-trained teacher does indeed improve the student performance compared to independently learning the student (1 distills 2 versus Net 2 Independent). However, the results show that not only is a pre-trained teacher unnecessary; but training both networks together in deep mutual learning provides a clear improvement compared to distillation (1 distills 2 versus DML Net 2). This implies that in the process of mutual learning the network that would play the role of teacher actually becomes better than a pre-trained teacher, via learning from interactions with an a-priori untrained student. Finally, we note that on Market-1501 training two compact MobileNets together provides a similar boost over independent learning compared to mutual learning with InceptionV1 and MobileNet: Peer teaching of small networks can be highly effective. In contrast, using the same network as teacher in model distillation actually makes the student worse than independent learning (the last row 1 distills 2 (45. 16 Table 4: Comparison with distillation on CIFAR-100 (Top-1 accuracy (%)) and Market-1501 dataset (mAP (%))\n\n\nDML with Larger Student Cohorts\n\nThe prior experiments studied cohorts of 2 students. In this experiment, we study how DML scales with more students in the cohort. Figure 2(a) shows the results on Market-1501 with DML training of increasing cohort sizes of MobileNets. The figure shows average mAP, as well as the standard deviation. From Fig. 2(a) we can see that the mAP performance of the average single network increases with the number of networks in the cohort with DML, hence its gap to the independently trained networks. This demonstrates that the generalisation ability of students is enhanced when learning together with increasing numbers of peers. From the standard deviations we can also see that the results get more and more stable with increasing number of networks in DML.\n\nA common technique when training multiple networks is to group them as an ensemble and make a combined prediction. In Fig. 2(b) we use the same models as Fig. 2(a) but make predictions based on the ensemble (matching based on concatenated feature of all members) instead of reporting the average prediction of each individual. From the results we can see that the ensemble prediction outperforms individual network predictions as expected ( Fig. 2(b) vs (a)). Moreover, the ensemble predictions also benefit from training multiple networks as a cohort (Fig. 2(b) DML ensemble vs. Independent ensemble). The ability of DML to improve models ensembles (Fig 2) illustrates that it may be a generally useful technique to improve performance in applications where model ensembles are standard practice, as there is minimal additional cost if ensembles are already used.  In this section we attempt to give some insights about how and why our deep mutual learning strategy works. There has been a wave of recent research on the subject of \"Why Deep Nets Generalise\" [4,26,9], which have provided some insights such as: While there are often many solutions (deep network parameter settings) that generate zero train error, some of these generalise better than others due to being in wide valleys rather than narrow crevices [4,9] -so that small perturbations do not change the prediction efficacy drastically; and that deep networks are better than might be expected at finding these good solutions [26], but that the tendency towards finding robust minima can be enhanced by biasing deep nets towards solutions with higher posterior entropy [4,17].\n\nBetter Quality Solutions with More Robust Minima With these insights in mind we make some observations about the DML process. Firstly we note that in our applications, the networks fit the training data perfectly: training accuracy goes to 100% and classification loss becomes minimal ( Fig. 3(a)). However, as we saw earlier, DML performs better on test data. Therefore rather than helping to find a better (deeper) minima of training loss, DML appears to be helping us to find a wider/more robust minima that generalises better to test data. Inspired by [4,9], we perform a simple test to analyse the robustness of the discovered minima on Market-1501 using MobileNet. For the DML and independent models, we compare the training loss of the learned models before and after adding independent Gaussian noise with variable standard deviation \u03c3 to each model parameter. We see that the depths of the two minima were the same ( Fig. 3(a)), but after adding this perturbation the training loss of the independent model jumps up while the loss of the DML model increases much less. This suggests that the DML model has found a much wider minima, which is expected to provide better generalisation performance [4,17].\n\nHow a Better Minima is Found How does DML help to find such a better minima? When asking each network to match its peers probability estimates, mismatches where a given network predicts zero and its teacher/peer predicts non-zero are heavily penalised. Therefore the overall effect of DML is that, where each network independently would put a small mass on a small set of secondary probabilities, all networks in the DML tend to aggregate their prediction of secondary probabilities, and both (i) put more mass on the secondary probabilities altogether, and (ii) place non-zero mass on more distinct secondary probabilities. We illustrate this effect by comparing the probabilities assigned to the top-5 highest ranked classes obtained by a ResNet-32 on CIFAR-100 trained by DML vs. an independently trained ResNet-32 model in Fig. 3(c). For each training sample, the top 5 classes are ranked according to the posterior probabilities produced by the model (Class 1 being the true class and Class 2 the second most probable class, so on and so forth). Here we can see that the assignment of mass to probabilities below the Top-1 decays much quicker for Independent than DML learning. This can be quantified by the entropy values averaged over all training samples of the DML trained model and the independently trained model being 1.7099 and 0.2602 respectively. Thus our method has connection to entropy regularisation-based approaches [4,17] to finding wide minima, but by mutual probability matching on 'reasonable' alternatives, rather than a blind high-entropy preference.\n\nDML with Ensemble Teacher In our DML strategy, each student is taught by all other students in the cohort individually, regardless how many students are in the cohort (Eq. (10)). In Sec. 2.3, an alternative DML strategy is discussed, by which each student is asked to match the predictions of the ensemble of all other students in the cohort (Eq. (11)). One might reasonably expect this approach to be better. As the ensemble prediction is better than individual predictions, it should provide a cleaner and stronger teaching signal -more like conventional distillation. In practice the results of ensemble rather than peer teaching are worse (see Fig. 4 (a)). By analysing the teaching signal of the ensemble in comparison to peer teaching, the ensemble target is much more sharply peaked on the true label than the peer targets, resulting in larger prediction entropy value for DML than DML_e (see Fig. 4 (b)). Thus while the noise-averaging property of ensembling is effective for making a correct prediction, it is actually detrimental to providing a teaching signal where the secondary class probabilities are the salient cue in the signal and having high-entropy posterior leads to more robust solutions to model training. \n\n\nConclusion\n\nWe have proposed a simple and generally applicable approach to improving the performance of deep neural networks by training them in a cohort with peers and mutual distillation. With this approach we can obtain compact networks that perform better than those distilled from a strong by static teacher. One application of DML is to obtain compact/fast and effective networks. We also showed that this approach is also promising to improve the performance of large powerful networks, and that the network cohort trained in this manner can be combined as an ensemble to further improve performance.\n\n\n) DML vs. Independent (b) DML ensemble vs Independent ensemble.\n\nFigure 2 :\n2Performance (mAP (%)) on Market-1501 with different numbers of networks in cohort 3.6 How and Why does DML Work?\n\nFigure 3 :\n3Analysis on why DML works\n\nFigure 4 :\n4Comparison of DML with each individual peer student as teacher and DML with peer student ensemble as teacher (DML_e) with 5 MobileNets trained on Market-1501\n\nTable 1\n1compares the number of parameters of all the \n\n\nTable 2\n2Table 1) it still benefits from being trained together with a smaller peer. (iv) Training a cohort of large networks (WRN-28-10) is still beneficial compared to learning alone. Thus in contrast to the conventional wisdom of model distillation, we see that a large pre-trained teacher is not necessary to obtain benefits, and multiple large networks can still benefit from our distillation-like process.compares the Top-1 accuracy of the CIFAR-100 dataset obtained by various architectures \nin a two-network DML cohort. From the table we can make the following observations: (i) All the \ndifferent network combinations among ResNet-32, MobileNet and WRN-28-10 improve performance \nwhen learning in a cohort compared to learning independently, indicated by the all positive values \nin the \"DML-Independent\" columns. (ii) The networks with smaller capacity (ResNet-32 and \nMobileNet) generally benefit more from DML. (iii) Although WRN-28-10 is a much larger network \nthan MobileNet or ResNet-32 (Network Types \nIndependent \nDML \nDML-Independent \nNet 1 \nNet 2 \nNet 1 Net 2 Net 1 Net 2 Net 1 \nNet 2 \nResnet-32 \nResnet-32 \n68.99 68.99 71.19 70.75 1.20 \n1.76 \nWRN-28-10 \nResnet-32 \n78.69 68.99 78.96 70.73 0.27 \n1.74 \nMobileNet \nResnet-32 \n73.65 68.99 76.13 71.10 2.48 \n2.11 \nMobileNet \nMobileNet \n73.65 73.65 76.21 76.10 2.56 \n2.45 \nWRN-28-10 \nMobileNet \n78.69 73.65 80.28 77.39 1.59 \n3.74 \nWRN-28-10 WRN-28-10 78.69 78.69 80.28 80.08 1.59 \n1.39 \n\n\n\nTable 3 :\n3Comparative results on the Market-1501 dataset\n\nTensorflow: Large-scale machine learning on heterogeneous distributed systems. Mart\u00edn Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Gregory S Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian J Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard, Yangqing Jia, Rafal J\u00f3zefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dan Man\u00e9, abs/1603.04467CoRR. Rajat Monga, Sherry Moore, Derek Gordon Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul A. Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda B. Vi\u00e9gas, Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang ZhengMart\u00edn Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Gregory S. Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian J. Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard, Yangqing Jia, Rafal J\u00f3zefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dan Man\u00e9, Rajat Monga, Sherry Moore, Derek Gordon Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul A. Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda B. Vi\u00e9gas, Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng. Tensorflow: Large-scale machine learning on heterogeneous distributed systems. CoRR, abs/1603.04467, 2016. URL http://arxiv.org/abs/1603.04467.\n\nDo deep nets really need to be deep?. Jimmy Ba, Rich Caruana, Advances in Neural Information Processing Systems. Jimmy Ba and Rich Caruana. Do deep nets really need to be deep? In Advances in Neural Information Processing Systems. 2014.\n\nModel compression. Cristian Bucila, Rich Caruana, Alexandru Niculescu-Mizil, KDD. Cristian Bucila, Rich Caruana, and Alexandru Niculescu-Mizil. Model compression. In KDD, 2006.\n\nEntropy-sgd: Biasing gradient descent into wide valleys. Pratik Chaudhar, Anna Choromansk, Stefano Soatt, Yann Lecun, Carlo Baldass, Christian Borg, Jennifer Chays, Levent Sagun, Riccardo Zecchina, Proceedings of International Conference on Learning Representations. International Conference on Learning RepresentationsPratik Chaudhar, Anna Choromansk, Stefano Soatt, Yann LeCun, Carlo Baldass, Christian Borg, Jennifer Chays, Levent Sagun, and Riccardo Zecchina. Entropy-sgd: Biasing gradient descent into wide valleys. In Proceedings of International Conference on Learning Representations, 2017.\n\nDual learning for machine translation. Di He, Yingce Xia, Tao Qin, Liwei Wang, Nenghai Yu, Tie-Yan Liu, Wei-Ying Ma, Advances in Neural Information Processing Systems. Di He, Yingce Xia, Tao Qin, Liwei Wang, Nenghai Yu, Tie-Yan Liu, and Wei-Ying Ma. Dual learning for machine translation. In Advances in Neural Information Processing Systems, pages 820-828, 2016.\n\nDeep residual learning for image recognition. Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, Proceedings of IEEE Conference on Computer Vision and Pattern Recognition. IEEE Conference on Computer Vision and Pattern RecognitionKaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, pages 770-778, 2016.\n\nDistilling the knowledge in a neural network. Geoffrey E Hinton, Oriol Vinyals, Jeffrey Dean, arXiv:1503.02531Geoffrey E. Hinton, Oriol Vinyals, and Jeffrey Dean. Distilling the knowledge in a neural network. arXiv: 1503.02531, 2015.\n\nMobilenets: Efficient convolutional neural networks for mobile vision applications. Andrew G Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, Hartwig Adam, arXiv:1704.04861Andrew G. Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco Andreetto, and Hartwig Adam. Mobilenets: Efficient convolutional neural networks for mobile vision applications. arXiv: 1704.04861, 2017.\n\nOn large-batch training for deep learning: Generalization gap and sharp minima. Dheevatsa Nitish Shirish Keskar, Jorge Mudigere, Mikhail Nocedal, Ping Tak Peter Smelyanskiy, Tang, Proceedings of International Conference on Learning Representations. International Conference on Learning RepresentationsNitish Shirish Keskar, Dheevatsa Mudigere, Jorge Nocedal, Mikhail Smelyanskiy, and Ping Tak Peter Tang. On large-batch training for deep learning: Generalization gap and sharp minima. In Proceedings of International Conference on Learning Representations, 2017.\n\nAdam: A method for stochastic optimization. P Diederik, Jimmy Kingma, Ba, Proceedings of International Conference on Learning Representations. International Conference on Learning RepresentationsDiederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In Proceedings of International Conference on Learning Representations, 2015.\n\nCifar-10 (canadian institute for advanced research). Alex Krizhevsky, Vinod Nair, Geoffrey Hinton, Alex Krizhevsky, Vinod Nair, and Geoffrey Hinton. Cifar-10 (canadian institute for advanced research), 2009. URL http://www.cs.toronto.edu/~kriz/cifar.html.\n\nMeasures of diversity in classifier ensembles and their relationship with the ensemble accuracy. I Ludmila, Christopher J Kuncheva, Whitaker, Machine Learning. 51Ludmila I. Kuncheva and Christopher J. Whitaker. Measures of diversity in classifier ensembles and their relationship with the ensemble accuracy. Machine Learning, 51(2):181-207, 2003.\n\nPruning filters for efficient convnets. Hao Li, Asim Kadav, Igor Durdanovic, Hanan Samet, Hans Peter Graf, Proceedings of International Conference on Learning Representations. International Conference on Learning RepresentationsHao Li, Asim Kadav, Igor Durdanovic, Hanan Samet, and Hans Peter Graf. Pruning filters for efficient convnets. In Proceedings of International Conference on Learning Representations, 2017.\n\nEnd-to-end comparative attention networks for person re-identification. Hao Liu, Jiashi Feng, Meibin Qi, Jianguo Jiang, Shuicheng Yan, abs/1606.04404CoRRHao Liu, Jiashi Feng, Meibin Qi, Jianguo Jiang, and Shuicheng Yan. End-to-end comparative attention networks for person re-identification. CoRR, abs/1606.04404, 2016.\n\nUnifying distillation and privileged information. David Lopez-Paz, Leon Bottou, Bernhard Scholkopf, Vladimir Vapnik, Proceedings of International Conference on Learning Representations. International Conference on Learning RepresentationsDavid Lopez-Paz, Leon Bottou, Bernhard Scholkopf, and Vladimir Vapnik. Unifying distillation and privileged information. In Proceedings of International Conference on Learning Representations, 2016.\n\nActor-mimic: Deep multitask and transfer reinforcement learning. Emilio Parisotto, Jimmy Lei Ba, Ruslan Salakhutdinov, Proceedings of International Conference on Learning Representations. International Conference on Learning RepresentationsEmilio Parisotto, Jimmy Lei Ba, and Ruslan Salakhutdinov. Actor-mimic: Deep multitask and transfer reinforcement learning. In Proceedings of International Conference on Learning Representations, 2016.\n\nRegularizing neural networks by penalizing confident output distributions. Gabriel Pereyra, George Tucker, Jan Chorowski, Lukasz Kaiser, Geoffrey Hinton, ICLR Workshops. Gabriel Pereyra, George Tucker, Jan Chorowski, Lukasz Kaiser, and Geoffrey Hinton. Regularizing neural networks by penalizing confident output distributions. In ICLR Workshops, 2017.\n\nXnor-net: Imagenet classification using binary convolutional neural networks. M Rastegari, J Ordonez, A Redmon, Farhadi, Proceedings of European Conference on Computer Vision. European Conference on Computer VisionM Rastegari, V Ordonez, J Redmon, and A Farhadi. Xnor-net: Imagenet classification using binary convolutional neural networks. In Proceedings of European Conference on Computer Vision, 2016.\n\nFitnets: Hints for thin deep nets. Adriana Romero, Nicolas Ballas, Samira Ebrahimi Kahou, Antoine Chassang, Carlo Gatta, Yoshua Bengio, Proceedings of International Conference on Learning Representations. International Conference on Learning RepresentationsAdriana Romero, Nicolas Ballas, Samira Ebrahimi Kahou, Antoine Chassang, Carlo Gatta, and Yoshua Bengio. Fitnets: Hints for thin deep nets. In Proceedings of International Conference on Learning Representations, 2015.\n\nDeep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding. J. Dally Song William, Huizi Han, Mao, Proceedings of International Conference on Learning Representations. International Conference on Learning RepresentationsWilliam J. Dally Song Han, Huizi Mao. Deep compression: Compressing deep neural networks with pruning, trained quantization and huffman coding. In Proceedings of International Conference on Learning Representations, 2016.\n\nGoing deeper with convolutions. Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott E Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, Andrew Rabinovich, Proceedings of IEEE Conference on Computer Vision and Pattern Recognition. IEEE Conference on Computer Vision and Pattern RecognitionChristian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott E. Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going deeper with convolutions. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, pages 1-9, 2015.\n\nLearning using privileged information: Similarity control and knowledge transfer. Vladimir Vapnik, Rauf Izmailov, Vladimir Vapnik and Rauf Izmailov. Learning using privileged information: Similarity control and knowledge transfer. 2015.\n\nGated siamese convolutional neural network architecture for human re-identification. Mrinal Rahul Rama Varior, Gang Haloi, Wang, Proceedings of European Conference on Computer Vision. European Conference on Computer VisionRahul Rama Varior, Mrinal Haloi, and Gang Wang. Gated siamese convolutional neural network archi- tecture for human re-identification. In Proceedings of European Conference on Computer Vision, pages 791-808, 2016.\n\nA siamese long short-term memory architecture for human re-identification. Bing Rahul Rama Varior, Jiwen Shuai, Dong Lu, Gang Xu, Wang, Proceedings of European Conference on Computer Vision. European Conference on Computer VisionRahul Rama Varior, Bing Shuai, Jiwen Lu, Dong Xu, and Gang Wang. A siamese long short-term memory architecture for human re-identification. In Proceedings of European Conference on Computer Vision, pages 135-153, 2016.\n\nWide residual networks. Sergey Zagoruyko, Nikos Komodakis, Proceedings of British Machine Vision Conference. British Machine Vision ConferenceSergey Zagoruyko and Nikos Komodakis. Wide residual networks. In Proceedings of British Machine Vision Conference, 2016.\n\nUnderstanding deep learning requires rethinking generalization. Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, Oriol Vinyals, Proceedings of International Conference on Learning Representations. International Conference on Learning RepresentationsChiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. Understanding deep learning requires rethinking generalization. In Proceedings of International Conference on Learning Representations, 2017.\n\nScalable person re-identification: A benchmark. Liang Zheng, Liyue Shen, Lu Tian, Shengjin Wang, Jingdong Wang, Qi Tian, Proceedings of IEEE International Conference on Computer Vision. IEEE International Conference on Computer VisionLiang Zheng, Liyue Shen, Lu Tian, Shengjin Wang, Jingdong Wang, and Qi Tian. Scalable person re-identification: A benchmark. In Proceedings of IEEE International Conference on Computer Vision, 2015.\n\nRe-ranking person re-identification with kreciprocal encoding. Zhun Zhong, Liang Zheng, Donglin Cao, Shaozi Li, Proceedings of IEEE Conference on Computer Vision and Pattern Recognition. IEEE Conference on Computer Vision and Pattern RecognitionZhun Zhong, Liang Zheng, Donglin Cao, and Shaozi Li. Re-ranking person re-identification with k- reciprocal encoding. In Proceedings of IEEE Conference on Computer Vision and Pattern Recognition, 2017.\n", "annotations": {"author": "[{\"end\":110,\"start\":24},{\"end\":176,\"start\":111},{\"end\":248,\"start\":177},{\"end\":299,\"start\":249}]", "publisher": null, "author_last_name": "[{\"end\":34,\"start\":29},{\"end\":120,\"start\":115},{\"end\":197,\"start\":187},{\"end\":259,\"start\":257}]", "author_first_name": "[{\"end\":28,\"start\":24},{\"end\":114,\"start\":111},{\"end\":184,\"start\":177},{\"end\":186,\"start\":185},{\"end\":256,\"start\":249}]", "author_affiliation": "[{\"end\":73,\"start\":36},{\"end\":109,\"start\":75},{\"end\":175,\"start\":141},{\"end\":247,\"start\":221},{\"end\":298,\"start\":261}]", "title": "[{\"end\":21,\"start\":1},{\"end\":320,\"start\":300}]", "venue": null, "abstract": "[{\"end\":1288,\"start\":322}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b5\"},\"end\":1467,\"start\":1464},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":1470,\"start\":1467},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":1865,\"start\":1862},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":1889,\"start\":1885},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":1903,\"start\":1899},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":1922,\"start\":1918},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":1968,\"start\":1965},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2037,\"start\":2034},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2039,\"start\":2037},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2357,\"start\":2354},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":2565,\"start\":2562},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2567,\"start\":2565},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":2570,\"start\":2567},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2572,\"start\":2570},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":2621,\"start\":2618},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2655,\"start\":2652},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":2658,\"start\":2655},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":2929,\"start\":2925},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":5076,\"start\":5073},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":5375,\"start\":5372},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":5378,\"start\":5375},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":5626,\"start\":5623},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":5629,\"start\":5626},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":6732,\"start\":6729},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":6771,\"start\":6768},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":7079,\"start\":7076},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":7081,\"start\":7079},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":7217,\"start\":7213},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":7355,\"start\":7351},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":7369,\"start\":7365},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":7625,\"start\":7622},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":8101,\"start\":8097},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":13418,\"start\":13414},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":13609,\"start\":13605},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":13949,\"start\":13945},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":14410,\"start\":14406},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":14514,\"start\":14511},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":14636,\"start\":14632},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":15060,\"start\":15056},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":15373,\"start\":15370},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":15391,\"start\":15388},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":15460,\"start\":15456},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":15491,\"start\":15487},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":16457,\"start\":16454},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":17698,\"start\":17696},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":19662,\"start\":19659},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":19665,\"start\":19662},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":19667,\"start\":19665},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":19919,\"start\":19916},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":19921,\"start\":19919},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":20095,\"start\":20091},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":20237,\"start\":20234},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":20240,\"start\":20237},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":20802,\"start\":20799},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":20804,\"start\":20802},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":21451,\"start\":21448},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":21454,\"start\":21451},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":22896,\"start\":22893},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":22899,\"start\":22896}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":24940,\"start\":24875},{\"attributes\":{\"id\":\"fig_1\"},\"end\":25066,\"start\":24941},{\"attributes\":{\"id\":\"fig_2\"},\"end\":25105,\"start\":25067},{\"attributes\":{\"id\":\"fig_3\"},\"end\":25276,\"start\":25106},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":25333,\"start\":25277},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":26787,\"start\":25334},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":26846,\"start\":26788}]", "paragraph": "[{\"end\":2949,\"start\":1304},{\"end\":4148,\"start\":2951},{\"end\":5718,\"start\":4150},{\"end\":6623,\"start\":5720},{\"end\":7578,\"start\":6640},{\"end\":8476,\"start\":7580},{\"end\":8835,\"start\":8515},{\"end\":9031,\"start\":8991},{\"end\":9163,\"start\":9077},{\"end\":9279,\"start\":9214},{\"end\":9451,\"start\":9281},{\"end\":9545,\"start\":9506},{\"end\":9986,\"start\":9581},{\"end\":10034,\"start\":9988},{\"end\":10173,\"start\":10113},{\"end\":10286,\"start\":10208},{\"end\":10514,\"start\":10321},{\"end\":10934,\"start\":10531},{\"end\":11113,\"start\":10972},{\"end\":11284,\"start\":11124},{\"end\":11445,\"start\":11317},{\"end\":11497,\"start\":11478},{\"end\":11620,\"start\":11537},{\"end\":12372,\"start\":11787},{\"end\":12732,\"start\":12374},{\"end\":13309,\"start\":12804},{\"end\":14420,\"start\":13349},{\"end\":15259,\"start\":14447},{\"end\":16286,\"start\":15261},{\"end\":17804,\"start\":16344},{\"end\":18597,\"start\":17840},{\"end\":20241,\"start\":18599},{\"end\":21455,\"start\":20243},{\"end\":23033,\"start\":21457},{\"end\":24264,\"start\":23035},{\"end\":24874,\"start\":24279}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":8990,\"start\":8836},{\"attributes\":{\"id\":\"formula_1\"},\"end\":9076,\"start\":9032},{\"attributes\":{\"id\":\"formula_2\"},\"end\":9213,\"start\":9164},{\"attributes\":{\"id\":\"formula_3\"},\"end\":9505,\"start\":9452},{\"attributes\":{\"id\":\"formula_4\"},\"end\":9580,\"start\":9546},{\"attributes\":{\"id\":\"formula_5\"},\"end\":10112,\"start\":10035},{\"attributes\":{\"id\":\"formula_6\"},\"end\":10207,\"start\":10174},{\"attributes\":{\"id\":\"formula_7\"},\"end\":10320,\"start\":10287},{\"attributes\":{\"id\":\"formula_8\"},\"end\":11123,\"start\":11114},{\"attributes\":{\"id\":\"formula_9\"},\"end\":11316,\"start\":11285},{\"attributes\":{\"id\":\"formula_10\"},\"end\":11477,\"start\":11446},{\"attributes\":{\"id\":\"formula_11\"},\"end\":11786,\"start\":11621},{\"attributes\":{\"id\":\"formula_12\"},\"end\":12803,\"start\":12733}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":15502,\"start\":15495},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":15691,\"start\":15684},{\"end\":16466,\"start\":16459},{\"end\":17706,\"start\":17699}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1302,\"start\":1290},{\"end\":6638,\"start\":6626},{\"attributes\":{\"n\":\"2\"},\"end\":8499,\"start\":8479},{\"attributes\":{\"n\":\"2.1\"},\"end\":8513,\"start\":8502},{\"attributes\":{\"n\":\"2.2\"},\"end\":10529,\"start\":10517},{\"end\":10970,\"start\":10937},{\"attributes\":{\"n\":\"2.3\"},\"end\":11535,\"start\":11500},{\"attributes\":{\"n\":\"3\"},\"end\":13323,\"start\":13312},{\"attributes\":{\"n\":\"3.1\"},\"end\":13347,\"start\":13326},{\"end\":14445,\"start\":14423},{\"attributes\":{\"n\":\"3.3\"},\"end\":16311,\"start\":16289},{\"attributes\":{\"n\":\"3.4\"},\"end\":16342,\"start\":16314},{\"attributes\":{\"n\":\"3.5\"},\"end\":17838,\"start\":17807},{\"attributes\":{\"n\":\"4\"},\"end\":24277,\"start\":24267},{\"end\":24952,\"start\":24942},{\"end\":25078,\"start\":25068},{\"end\":25117,\"start\":25107},{\"end\":25285,\"start\":25278},{\"end\":25342,\"start\":25335},{\"end\":26798,\"start\":26789}]", "table": "[{\"end\":25333,\"start\":25287},{\"end\":26787,\"start\":25746}]", "figure_caption": "[{\"end\":24940,\"start\":24877},{\"end\":25066,\"start\":24954},{\"end\":25105,\"start\":25080},{\"end\":25276,\"start\":25119},{\"end\":25746,\"start\":25344},{\"end\":26846,\"start\":26800}]", "figure_ref": "[{\"end\":8595,\"start\":8589},{\"end\":8662,\"start\":8654},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":17982,\"start\":17971},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":18155,\"start\":18146},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":18726,\"start\":18717},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":18759,\"start\":18753},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":19056,\"start\":19040},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":19161,\"start\":19151},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":19256,\"start\":19249},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":20539,\"start\":20530},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":21178,\"start\":21169},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":22293,\"start\":22284},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":23693,\"start\":23683},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":23945,\"start\":23935}]", "bib_author_first_name": "[{\"end\":26933,\"start\":26927},{\"end\":26947,\"start\":26941},{\"end\":26961,\"start\":26957},{\"end\":26976,\"start\":26970},{\"end\":26992,\"start\":26985},{\"end\":27004,\"start\":26999},{\"end\":27019,\"start\":27012},{\"end\":27021,\"start\":27020},{\"end\":27035,\"start\":27031},{\"end\":27050,\"start\":27043},{\"end\":27065,\"start\":27057},{\"end\":27079,\"start\":27073},{\"end\":27093,\"start\":27090},{\"end\":27095,\"start\":27094},{\"end\":27114,\"start\":27108},{\"end\":27129,\"start\":27121},{\"end\":27145,\"start\":27138},{\"end\":27161,\"start\":27153},{\"end\":27172,\"start\":27167},{\"end\":27191,\"start\":27185},{\"end\":27209,\"start\":27200},{\"end\":27222,\"start\":27218},{\"end\":27237,\"start\":27234},{\"end\":28371,\"start\":28366},{\"end\":28380,\"start\":28376},{\"end\":28593,\"start\":28585},{\"end\":28606,\"start\":28602},{\"end\":28625,\"start\":28616},{\"end\":28807,\"start\":28801},{\"end\":28822,\"start\":28818},{\"end\":28842,\"start\":28835},{\"end\":28854,\"start\":28850},{\"end\":28867,\"start\":28862},{\"end\":28886,\"start\":28877},{\"end\":28901,\"start\":28893},{\"end\":28915,\"start\":28909},{\"end\":28931,\"start\":28923},{\"end\":29385,\"start\":29383},{\"end\":29396,\"start\":29390},{\"end\":29405,\"start\":29402},{\"end\":29416,\"start\":29411},{\"end\":29430,\"start\":29423},{\"end\":29442,\"start\":29435},{\"end\":29456,\"start\":29448},{\"end\":29762,\"start\":29755},{\"end\":29774,\"start\":29767},{\"end\":29790,\"start\":29782},{\"end\":29800,\"start\":29796},{\"end\":30194,\"start\":30186},{\"end\":30196,\"start\":30195},{\"end\":30210,\"start\":30205},{\"end\":30227,\"start\":30220},{\"end\":30465,\"start\":30459},{\"end\":30467,\"start\":30466},{\"end\":30484,\"start\":30476},{\"end\":30492,\"start\":30490},{\"end\":30505,\"start\":30499},{\"end\":30526,\"start\":30520},{\"end\":30539,\"start\":30533},{\"end\":30553,\"start\":30548},{\"end\":30572,\"start\":30565},{\"end\":30919,\"start\":30910},{\"end\":30948,\"start\":30943},{\"end\":30966,\"start\":30959},{\"end\":30990,\"start\":30976},{\"end\":31439,\"start\":31438},{\"end\":31455,\"start\":31450},{\"end\":31802,\"start\":31798},{\"end\":31820,\"start\":31815},{\"end\":31835,\"start\":31827},{\"end\":32100,\"start\":32099},{\"end\":32121,\"start\":32110},{\"end\":32123,\"start\":32122},{\"end\":32393,\"start\":32390},{\"end\":32402,\"start\":32398},{\"end\":32414,\"start\":32410},{\"end\":32432,\"start\":32427},{\"end\":32444,\"start\":32440},{\"end\":32450,\"start\":32445},{\"end\":32843,\"start\":32840},{\"end\":32855,\"start\":32849},{\"end\":32868,\"start\":32862},{\"end\":32880,\"start\":32873},{\"end\":32897,\"start\":32888},{\"end\":33144,\"start\":33139},{\"end\":33160,\"start\":33156},{\"end\":33177,\"start\":33169},{\"end\":33197,\"start\":33189},{\"end\":33598,\"start\":33592},{\"end\":33615,\"start\":33610},{\"end\":33619,\"start\":33616},{\"end\":33630,\"start\":33624},{\"end\":34051,\"start\":34044},{\"end\":34067,\"start\":34061},{\"end\":34079,\"start\":34076},{\"end\":34097,\"start\":34091},{\"end\":34114,\"start\":34106},{\"end\":34402,\"start\":34401},{\"end\":34415,\"start\":34414},{\"end\":34426,\"start\":34425},{\"end\":34771,\"start\":34764},{\"end\":34787,\"start\":34780},{\"end\":34802,\"start\":34796},{\"end\":34811,\"start\":34803},{\"end\":34826,\"start\":34819},{\"end\":34842,\"start\":34837},{\"end\":34856,\"start\":34850},{\"end\":35324,\"start\":35311},{\"end\":35339,\"start\":35334},{\"end\":35735,\"start\":35726},{\"end\":35748,\"start\":35745},{\"end\":35762,\"start\":35754},{\"end\":35774,\"start\":35768},{\"end\":35790,\"start\":35785},{\"end\":35792,\"start\":35791},{\"end\":35807,\"start\":35799},{\"end\":35825,\"start\":35818},{\"end\":35840,\"start\":35833},{\"end\":35858,\"start\":35852},{\"end\":36372,\"start\":36364},{\"end\":36385,\"start\":36381},{\"end\":36611,\"start\":36605},{\"end\":36635,\"start\":36631},{\"end\":37036,\"start\":37032},{\"end\":37061,\"start\":37056},{\"end\":37073,\"start\":37069},{\"end\":37082,\"start\":37078},{\"end\":37436,\"start\":37430},{\"end\":37453,\"start\":37448},{\"end\":37741,\"start\":37734},{\"end\":37753,\"start\":37749},{\"end\":37768,\"start\":37762},{\"end\":37784,\"start\":37776},{\"end\":37797,\"start\":37792},{\"end\":38201,\"start\":38196},{\"end\":38214,\"start\":38209},{\"end\":38223,\"start\":38221},{\"end\":38238,\"start\":38230},{\"end\":38253,\"start\":38245},{\"end\":38262,\"start\":38260},{\"end\":38649,\"start\":38645},{\"end\":38662,\"start\":38657},{\"end\":38677,\"start\":38670},{\"end\":38689,\"start\":38683}]", "bib_author_last_name": "[{\"end\":26939,\"start\":26934},{\"end\":26955,\"start\":26948},{\"end\":26968,\"start\":26962},{\"end\":26983,\"start\":26977},{\"end\":26997,\"start\":26993},{\"end\":27010,\"start\":27005},{\"end\":27029,\"start\":27022},{\"end\":27041,\"start\":27036},{\"end\":27055,\"start\":27051},{\"end\":27071,\"start\":27066},{\"end\":27088,\"start\":27080},{\"end\":27106,\"start\":27096},{\"end\":27119,\"start\":27115},{\"end\":27136,\"start\":27130},{\"end\":27151,\"start\":27146},{\"end\":27165,\"start\":27162},{\"end\":27183,\"start\":27173},{\"end\":27198,\"start\":27192},{\"end\":27216,\"start\":27210},{\"end\":27232,\"start\":27223},{\"end\":27242,\"start\":27238},{\"end\":28374,\"start\":28372},{\"end\":28388,\"start\":28381},{\"end\":28600,\"start\":28594},{\"end\":28614,\"start\":28607},{\"end\":28641,\"start\":28626},{\"end\":28816,\"start\":28808},{\"end\":28833,\"start\":28823},{\"end\":28848,\"start\":28843},{\"end\":28860,\"start\":28855},{\"end\":28875,\"start\":28868},{\"end\":28891,\"start\":28887},{\"end\":28907,\"start\":28902},{\"end\":28921,\"start\":28916},{\"end\":28940,\"start\":28932},{\"end\":29388,\"start\":29386},{\"end\":29400,\"start\":29397},{\"end\":29409,\"start\":29406},{\"end\":29421,\"start\":29417},{\"end\":29433,\"start\":29431},{\"end\":29446,\"start\":29443},{\"end\":29459,\"start\":29457},{\"end\":29765,\"start\":29763},{\"end\":29780,\"start\":29775},{\"end\":29794,\"start\":29791},{\"end\":29804,\"start\":29801},{\"end\":30203,\"start\":30197},{\"end\":30218,\"start\":30211},{\"end\":30232,\"start\":30228},{\"end\":30474,\"start\":30468},{\"end\":30488,\"start\":30485},{\"end\":30497,\"start\":30493},{\"end\":30518,\"start\":30506},{\"end\":30531,\"start\":30527},{\"end\":30546,\"start\":30540},{\"end\":30563,\"start\":30554},{\"end\":30577,\"start\":30573},{\"end\":30941,\"start\":30920},{\"end\":30957,\"start\":30949},{\"end\":30974,\"start\":30967},{\"end\":31002,\"start\":30991},{\"end\":31008,\"start\":31004},{\"end\":31448,\"start\":31440},{\"end\":31462,\"start\":31456},{\"end\":31466,\"start\":31464},{\"end\":31813,\"start\":31803},{\"end\":31825,\"start\":31821},{\"end\":31842,\"start\":31836},{\"end\":32108,\"start\":32101},{\"end\":32132,\"start\":32124},{\"end\":32142,\"start\":32134},{\"end\":32396,\"start\":32394},{\"end\":32408,\"start\":32403},{\"end\":32425,\"start\":32415},{\"end\":32438,\"start\":32433},{\"end\":32455,\"start\":32451},{\"end\":32847,\"start\":32844},{\"end\":32860,\"start\":32856},{\"end\":32871,\"start\":32869},{\"end\":32886,\"start\":32881},{\"end\":32901,\"start\":32898},{\"end\":33154,\"start\":33145},{\"end\":33167,\"start\":33161},{\"end\":33187,\"start\":33178},{\"end\":33204,\"start\":33198},{\"end\":33608,\"start\":33599},{\"end\":33622,\"start\":33620},{\"end\":33644,\"start\":33631},{\"end\":34059,\"start\":34052},{\"end\":34074,\"start\":34068},{\"end\":34089,\"start\":34080},{\"end\":34104,\"start\":34098},{\"end\":34121,\"start\":34115},{\"end\":34412,\"start\":34403},{\"end\":34423,\"start\":34416},{\"end\":34433,\"start\":34427},{\"end\":34442,\"start\":34435},{\"end\":34778,\"start\":34772},{\"end\":34794,\"start\":34788},{\"end\":34817,\"start\":34812},{\"end\":34835,\"start\":34827},{\"end\":34848,\"start\":34843},{\"end\":34863,\"start\":34857},{\"end\":35332,\"start\":35325},{\"end\":35343,\"start\":35340},{\"end\":35348,\"start\":35345},{\"end\":35743,\"start\":35736},{\"end\":35752,\"start\":35749},{\"end\":35766,\"start\":35763},{\"end\":35783,\"start\":35775},{\"end\":35797,\"start\":35793},{\"end\":35816,\"start\":35808},{\"end\":35831,\"start\":35826},{\"end\":35850,\"start\":35841},{\"end\":35869,\"start\":35859},{\"end\":36379,\"start\":36373},{\"end\":36394,\"start\":36386},{\"end\":36629,\"start\":36612},{\"end\":36641,\"start\":36636},{\"end\":36647,\"start\":36643},{\"end\":37054,\"start\":37037},{\"end\":37067,\"start\":37062},{\"end\":37076,\"start\":37074},{\"end\":37085,\"start\":37083},{\"end\":37091,\"start\":37087},{\"end\":37446,\"start\":37437},{\"end\":37463,\"start\":37454},{\"end\":37747,\"start\":37742},{\"end\":37760,\"start\":37754},{\"end\":37774,\"start\":37769},{\"end\":37790,\"start\":37785},{\"end\":37805,\"start\":37798},{\"end\":38207,\"start\":38202},{\"end\":38219,\"start\":38215},{\"end\":38228,\"start\":38224},{\"end\":38243,\"start\":38239},{\"end\":38258,\"start\":38254},{\"end\":38267,\"start\":38263},{\"end\":38655,\"start\":38650},{\"end\":38668,\"start\":38663},{\"end\":38681,\"start\":38678},{\"end\":38692,\"start\":38690}]", "bib_entry": "[{\"attributes\":{\"doi\":\"abs/1603.04467\",\"id\":\"b0\",\"matched_paper_id\":5707386},\"end\":28326,\"start\":26848},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":11536917},\"end\":28564,\"start\":28328},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":11253972},\"end\":28742,\"start\":28566},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":13807351},\"end\":29342,\"start\":28744},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":5758868},\"end\":29707,\"start\":29344},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":206594692},\"end\":30138,\"start\":29709},{\"attributes\":{\"doi\":\"arXiv:1503.02531\",\"id\":\"b6\"},\"end\":30373,\"start\":30140},{\"attributes\":{\"doi\":\"arXiv:1704.04861\",\"id\":\"b7\"},\"end\":30828,\"start\":30375},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":5834589},\"end\":31392,\"start\":30830},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":6628106},\"end\":31743,\"start\":31394},{\"attributes\":{\"id\":\"b10\"},\"end\":32000,\"start\":31745},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":14317314},\"end\":32348,\"start\":32002},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":14089312},\"end\":32766,\"start\":32350},{\"attributes\":{\"doi\":\"abs/1606.04404\",\"id\":\"b13\"},\"end\":33087,\"start\":32768},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":8125776},\"end\":33525,\"start\":33089},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":8241258},\"end\":33967,\"start\":33527},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":9545399},\"end\":34321,\"start\":33969},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":14925907},\"end\":34727,\"start\":34323},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":2723173},\"end\":35203,\"start\":34729},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":2134321},\"end\":35692,\"start\":35205},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":206592484},\"end\":36280,\"start\":35694},{\"attributes\":{\"id\":\"b21\"},\"end\":36518,\"start\":36282},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":15172651},\"end\":36955,\"start\":36520},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":16756781},\"end\":37404,\"start\":36957},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":15276198},\"end\":37668,\"start\":37406},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":6212000},\"end\":38146,\"start\":37670},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":14991802},\"end\":38580,\"start\":38148},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":206595765},\"end\":39028,\"start\":38582}]", "bib_title": "[{\"end\":26925,\"start\":26848},{\"end\":28364,\"start\":28328},{\"end\":28583,\"start\":28566},{\"end\":28799,\"start\":28744},{\"end\":29381,\"start\":29344},{\"end\":29753,\"start\":29709},{\"end\":30908,\"start\":30830},{\"end\":31436,\"start\":31394},{\"end\":32097,\"start\":32002},{\"end\":32388,\"start\":32350},{\"end\":33137,\"start\":33089},{\"end\":33590,\"start\":33527},{\"end\":34042,\"start\":33969},{\"end\":34399,\"start\":34323},{\"end\":34762,\"start\":34729},{\"end\":35309,\"start\":35205},{\"end\":35724,\"start\":35694},{\"end\":36603,\"start\":36520},{\"end\":37030,\"start\":36957},{\"end\":37428,\"start\":37406},{\"end\":37732,\"start\":37670},{\"end\":38194,\"start\":38148},{\"end\":38643,\"start\":38582}]", "bib_author": "[{\"end\":26941,\"start\":26927},{\"end\":26957,\"start\":26941},{\"end\":26970,\"start\":26957},{\"end\":26985,\"start\":26970},{\"end\":26999,\"start\":26985},{\"end\":27012,\"start\":26999},{\"end\":27031,\"start\":27012},{\"end\":27043,\"start\":27031},{\"end\":27057,\"start\":27043},{\"end\":27073,\"start\":27057},{\"end\":27090,\"start\":27073},{\"end\":27108,\"start\":27090},{\"end\":27121,\"start\":27108},{\"end\":27138,\"start\":27121},{\"end\":27153,\"start\":27138},{\"end\":27167,\"start\":27153},{\"end\":27185,\"start\":27167},{\"end\":27200,\"start\":27185},{\"end\":27218,\"start\":27200},{\"end\":27234,\"start\":27218},{\"end\":27244,\"start\":27234},{\"end\":28376,\"start\":28366},{\"end\":28390,\"start\":28376},{\"end\":28602,\"start\":28585},{\"end\":28616,\"start\":28602},{\"end\":28643,\"start\":28616},{\"end\":28818,\"start\":28801},{\"end\":28835,\"start\":28818},{\"end\":28850,\"start\":28835},{\"end\":28862,\"start\":28850},{\"end\":28877,\"start\":28862},{\"end\":28893,\"start\":28877},{\"end\":28909,\"start\":28893},{\"end\":28923,\"start\":28909},{\"end\":28942,\"start\":28923},{\"end\":29390,\"start\":29383},{\"end\":29402,\"start\":29390},{\"end\":29411,\"start\":29402},{\"end\":29423,\"start\":29411},{\"end\":29435,\"start\":29423},{\"end\":29448,\"start\":29435},{\"end\":29461,\"start\":29448},{\"end\":29767,\"start\":29755},{\"end\":29782,\"start\":29767},{\"end\":29796,\"start\":29782},{\"end\":29806,\"start\":29796},{\"end\":30205,\"start\":30186},{\"end\":30220,\"start\":30205},{\"end\":30234,\"start\":30220},{\"end\":30476,\"start\":30459},{\"end\":30490,\"start\":30476},{\"end\":30499,\"start\":30490},{\"end\":30520,\"start\":30499},{\"end\":30533,\"start\":30520},{\"end\":30548,\"start\":30533},{\"end\":30565,\"start\":30548},{\"end\":30579,\"start\":30565},{\"end\":30943,\"start\":30910},{\"end\":30959,\"start\":30943},{\"end\":30976,\"start\":30959},{\"end\":31004,\"start\":30976},{\"end\":31010,\"start\":31004},{\"end\":31450,\"start\":31438},{\"end\":31464,\"start\":31450},{\"end\":31468,\"start\":31464},{\"end\":31815,\"start\":31798},{\"end\":31827,\"start\":31815},{\"end\":31844,\"start\":31827},{\"end\":32110,\"start\":32099},{\"end\":32134,\"start\":32110},{\"end\":32144,\"start\":32134},{\"end\":32398,\"start\":32390},{\"end\":32410,\"start\":32398},{\"end\":32427,\"start\":32410},{\"end\":32440,\"start\":32427},{\"end\":32457,\"start\":32440},{\"end\":32849,\"start\":32840},{\"end\":32862,\"start\":32849},{\"end\":32873,\"start\":32862},{\"end\":32888,\"start\":32873},{\"end\":32903,\"start\":32888},{\"end\":33156,\"start\":33139},{\"end\":33169,\"start\":33156},{\"end\":33189,\"start\":33169},{\"end\":33206,\"start\":33189},{\"end\":33610,\"start\":33592},{\"end\":33624,\"start\":33610},{\"end\":33646,\"start\":33624},{\"end\":34061,\"start\":34044},{\"end\":34076,\"start\":34061},{\"end\":34091,\"start\":34076},{\"end\":34106,\"start\":34091},{\"end\":34123,\"start\":34106},{\"end\":34414,\"start\":34401},{\"end\":34425,\"start\":34414},{\"end\":34435,\"start\":34425},{\"end\":34444,\"start\":34435},{\"end\":34780,\"start\":34764},{\"end\":34796,\"start\":34780},{\"end\":34819,\"start\":34796},{\"end\":34837,\"start\":34819},{\"end\":34850,\"start\":34837},{\"end\":34865,\"start\":34850},{\"end\":35334,\"start\":35311},{\"end\":35345,\"start\":35334},{\"end\":35350,\"start\":35345},{\"end\":35745,\"start\":35726},{\"end\":35754,\"start\":35745},{\"end\":35768,\"start\":35754},{\"end\":35785,\"start\":35768},{\"end\":35799,\"start\":35785},{\"end\":35818,\"start\":35799},{\"end\":35833,\"start\":35818},{\"end\":35852,\"start\":35833},{\"end\":35871,\"start\":35852},{\"end\":36381,\"start\":36364},{\"end\":36396,\"start\":36381},{\"end\":36631,\"start\":36605},{\"end\":36643,\"start\":36631},{\"end\":36649,\"start\":36643},{\"end\":37056,\"start\":37032},{\"end\":37069,\"start\":37056},{\"end\":37078,\"start\":37069},{\"end\":37087,\"start\":37078},{\"end\":37093,\"start\":37087},{\"end\":37448,\"start\":37430},{\"end\":37465,\"start\":37448},{\"end\":37749,\"start\":37734},{\"end\":37762,\"start\":37749},{\"end\":37776,\"start\":37762},{\"end\":37792,\"start\":37776},{\"end\":37807,\"start\":37792},{\"end\":38209,\"start\":38196},{\"end\":38221,\"start\":38209},{\"end\":38230,\"start\":38221},{\"end\":38245,\"start\":38230},{\"end\":38260,\"start\":38245},{\"end\":38269,\"start\":38260},{\"end\":38657,\"start\":38645},{\"end\":38670,\"start\":38657},{\"end\":38683,\"start\":38670},{\"end\":38694,\"start\":38683}]", "bib_venue": "[{\"end\":29063,\"start\":29011},{\"end\":29939,\"start\":29881},{\"end\":31131,\"start\":31079},{\"end\":31589,\"start\":31537},{\"end\":32578,\"start\":32526},{\"end\":33327,\"start\":33275},{\"end\":33767,\"start\":33715},{\"end\":34537,\"start\":34499},{\"end\":34986,\"start\":34934},{\"end\":35471,\"start\":35419},{\"end\":36004,\"start\":35946},{\"end\":36742,\"start\":36704},{\"end\":37186,\"start\":37148},{\"end\":37548,\"start\":37515},{\"end\":37928,\"start\":37876},{\"end\":38382,\"start\":38334},{\"end\":38827,\"start\":38769},{\"end\":27262,\"start\":27258},{\"end\":28439,\"start\":28390},{\"end\":28646,\"start\":28643},{\"end\":29009,\"start\":28942},{\"end\":29510,\"start\":29461},{\"end\":29879,\"start\":29806},{\"end\":30184,\"start\":30140},{\"end\":30457,\"start\":30375},{\"end\":31077,\"start\":31010},{\"end\":31535,\"start\":31468},{\"end\":31796,\"start\":31745},{\"end\":32160,\"start\":32144},{\"end\":32524,\"start\":32457},{\"end\":32838,\"start\":32768},{\"end\":33273,\"start\":33206},{\"end\":33713,\"start\":33646},{\"end\":34137,\"start\":34123},{\"end\":34497,\"start\":34444},{\"end\":34932,\"start\":34865},{\"end\":35417,\"start\":35350},{\"end\":35944,\"start\":35871},{\"end\":36362,\"start\":36282},{\"end\":36702,\"start\":36649},{\"end\":37146,\"start\":37093},{\"end\":37513,\"start\":37465},{\"end\":37874,\"start\":37807},{\"end\":38332,\"start\":38269},{\"end\":38767,\"start\":38694}]"}}}, "year": 2023, "month": 12, "day": 17}