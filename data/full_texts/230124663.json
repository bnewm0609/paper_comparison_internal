{"id": 230124663, "updated": "2022-01-16 06:59:24.431", "metadata": {"title": "CAT-Net: Compression Artifact Tracing Network for Detection and Localization of Image Splicing", "authors": "[{\"middle\":[],\"last\":\"Kwon\",\"first\":\"Myung-Joon\"},{\"middle\":[],\"last\":\"Yu\",\"first\":\"In-Jae\"},{\"middle\":[],\"last\":\"Nam\",\"first\":\"Seung-Hun\"},{\"middle\":[],\"last\":\"Lee\",\"first\":\"Heung-Kyu\"}]", "venue": "2021 IEEE Winter Conference on Applications of Computer Vision (WACV)", "journal": "2021 IEEE Winter Conference on Applications of Computer Vision (WACV)", "publication_date": {"year": 2021, "month": null, "day": null}, "abstract": "Detecting and localizing image splicing has become essential to fight against malicious forgery. A major challenge to localize spliced areas is to discriminate between authentic and tampered regions with intrinsic properties such as compression artifacts. We propose CAT-Net, an end-to-end fully convolutional neural network including RGB and DCT streams, to learn forensic features of compression artifacts on RGB and DCT domains jointly. Each stream considers multiple resolutions to deal with spliced object\u2019s various shapes and sizes. The DCT stream is pretrained on double JPEG detection to utilize JPEG artifacts. The proposed method outperforms state-of-the-art neural networks for localizing spliced regions in JPEG or non-JPEG images.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/wacv/KwonYNL21", "doi": "10.1109/wacv48630.2021.00042"}}, "content": {"source": {"pdf_hash": "c4929d899e508388a07daac5accbd4765d1690b2", "pdf_src": "IEEE", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "2b304e04d02b44b5ee62dfbca05ae9b80d19730f", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/c4929d899e508388a07daac5accbd4765d1690b2.txt", "contents": "\nCAT-Net: Compression Artifact Tracing Network for Detection and Localization of Image Splicing\n\n\nMyung-Joon Kwon kwon19@kaist.ac.kr \nKorea Advanced Institute of Science and Technology (KAIST)\n\n\nIn-Jae Yu \nKorea Advanced Institute of Science and Technology (KAIST)\n\n\nSeung-Hun Nam \nKorea Advanced Institute of Science and Technology (KAIST)\n\n\nHeung-Kyu Lee \nKorea Advanced Institute of Science and Technology (KAIST)\n\n\nCAT-Net: Compression Artifact Tracing Network for Detection and Localization of Image Splicing\n10.1109/WACV48630.2021.00042\nDetecting and localizing image splicing has become essential to fight against malicious forgery. A major challenge to localize spliced areas is to discriminate between authentic and tampered regions with intrinsic properties such as compression artifacts. We propose CAT-Net, an end-to-end fully convolutional neural network including RGB and DCT streams, to learn forensic features of compression artifacts on RGB and DCT domains jointly. Each stream considers multiple resolutions to deal with spliced object's various shapes and sizes. The DCT stream is pretrained on double JPEG detection to utilize JPEG artifacts. The proposed method outperforms state-of-the-art neural networks for localizing spliced regions in JPEG or non-JPEG images.\n\nIntroduction\n\nModern mobile devices mean that anyone can take a picture anywhere anytime. Image editing is very easy due to user-friendly image editing software and images can be shared in seconds due to social networking services. Although these advances have benefited people's lives, they have also caused problems when forged images are used as fake news, false propaganda, or fake evidence [44]. Therefore, it has become increasingly important to detect image manipulations.\n\nImage splicing is defined as copy-pasting some part of an image onto another image ( Figure 1) [37]. It is one of the easiest and most popular image manipulations, but it is also one of the most frequently used manipulations for bad purposes. For example, one can make a person appear to be somewhere they should not and had not been. Thus, this paper focuses on image splicing detection and localization. Given a possibly spliced image (Figure 1(c)), our goal is to generate a mask that localizes the potentially tampered image portion (Figure 1(d)).\n\nTo distinguish between spliced and authentic areas, it is important to analyze statistical fingerprints caused by internal processes of camera or image editing software (e.g. sensor pattern noise [22], interpolation traces from the color filter array [30], compression artifacts [2,26,38,40], etc.). Modern digital cameras typically compress the image to reduce storage space, with JPEG compression being employed in most cases due to its efficiency. However, this generates various JPEG artifacts due to information loss, even though they are generally not visible to human eyes. Thus, analyzing JPEG compression artifacts could help localize forged regions. Double JPEG detection, i.e., determining if a JPEG image has been compressed once or twice, can help identify splice forgery. A region spliced onto another image will likely have a statistically different distribution of DCT coefficients in Y-channel compared with an authentic region ( Figure 2). The authentic region is doubly compressed: first in the camera and again as part of the forgery, leaving periodic patterns in the histogram [29]. The spliced  region behaves like singly compressed, following the secondary quantization table [29]. Traditionally, DCT histograms have been employed to detect double JPEG compression [7,21]. Even in deep learning era, deep neural networks tend to require preprocessed histograms as input [2,26,38,40] because naively giving DCT coefficients as input commonly performs poorly due to the large decorrelation of DCT coefficients, unlike pixels [42]. All such methods produce patch-wise predictions due to the usage of histograms. Therefore, we adopt the binary volume representation for DCT coefficients to obtain pixel-wise predictions, originally designed for steganalysis [42]. This allows combining a semantic segmentation network with the double JPEG detection concept, providing pixel-wise prediction.\n\nThis paper proposes Compression Artifact Tracing Network (CAT-Net), an end-to-end fully convolutional neural network to detect and localize spliced regions. The network includes an RGB stream, a DCT stream, and a final fusion stage. The RGB stream learns visual artifacts and the DCT stream learns compression artifacts (i.e., DCT coefficient distributions). We pretrain the DCT stream for double JPEG detection and use it as initialization for splicing localization. The fusion stage fuses multiple resolution features from the two streams to generate the final mask.\n\nOur main contributions are summarized as follows.\n\n\u2022 For the first time, CAT-Net localizes spliced objects considering RGB and DCT domains jointly. Extensive experiments with diverse benchmark datasets showed CAT-Net achieved state-of-the-art performance compared to baselines [41,15], and stable performance for JPEG and non-JPEG images.\n\n\u2022 We designed the DCT stream to learn compression artifacts that trace double-compressed clues based on binary volume representation of DCT coefficients. This approach outperforms previous state-of-the-art networks using histogram representation [2,26,40] in terms of detecting double JPEG compression.\n\n\nRelated Work\n\nImage forgery localization can be categorized as blockwise classification, patch matching, and end-to-end neural network approaches.\n\nBlock-wise classification finds forgery distributions using classification per block for specific manipulations such as double JPEG compression [2,26,38,40], image resampling [30], contrast enhancement [36], and multiple manipulations [4]. Images are divided into several fixed-sized blocks to localize manipulation areas, and detection results from each block are combined. Detection is performed independently for each block, hence overall image statistics cannot be derived.\n\nPatch matching extracts statistical features from image patches and measures consistency among the patches. Highly inconsistent patches are considered to have been manipulated (e.g. spliced from another image). Predefined feature extractors [1,34] or neural networks [15,23] are used to extract appropriate features for matching. Huh et al. [15] proposed a self-supervised approach to train a model to determine whether an image was self-consistent in terms of EXIF metadata. However, patch matching localization requires high resources because it needs to compute consistency for every patch pair and it needs time-consuming post-processing to derive actual forgery location by aggregating results from all pairs. Neural networks have improved object detection [18,31,32] and semantic segmentation [20,33,39] performance considerably, and hence image forgery localization methods have been developed employing such techniques. In [45], SRM kernel [11] was added to an object detection model to extract bounding boxes of splicing, copy-move, and removal forgeries. Bi et al. [5] proposed a U-Net [33] based segmentation network to localize image splicing. It only used RGB pixel domain information like usual semantic segmentation networks. Wu et al. [41] proposed ManTra-Net using SRM kernel [11] in feature extraction and constrained convolution [4] followed by pixel-wise anomaly detection. Although they considered JPEG compression as a type of manipulation to train the feature extractor, it was unable to distinguish single and double JPEG compression. Consequently, localization performance degrades for JPEG images.\n\nWe propose a novel approach to detect and localize image splicing on JPEG images, overcoming the limitations of previous works. For fast inference and obtaining pixel-wise prediction, we adopt a segmentation network considering multi-resolution features [39]. To make the network robust to JPEG compression, we extract JPEG artifacts in the DCT domain employing binary volume representation of quantized DCT coefficients [42].    Figure 3 shows that CAT-Net comprises an RGB stream, a DCT stream, and a final fusion stage. RGB pixel values, quantized Y-channel DCT coefficients, and a Y-channel quantization table are extracted from JPEG file input. The RGB pixel values are fed into the RGB stream and the other data into the DCT stream. The RGB stream focuses on visual clues and the DCT stream on compression artifacts. The stream outputs are then fused to generate the final output.\n\n\nProposed Method\n\n\nNetwork Structure\n\nWe use HRNet [39] as the CAT-Net backbone, which was originally designed for computer vision problems. We introduce HRNet to a forensic problem since it maintains high-resolution representations through the whole process and employs a novel fusion method to combine multiple resolution features and capture the overall picture. This helps capture the overall structure without losing fine ar-tifacts required for forensic investigations. Also, HRNet uses stride-2 convolution to downsample feature maps and does not use pooling layers. Recent studies have shown that pooling is undesirable for tasks that require subtle signals since pooling reinforces content and suppresses noise-like signals [6]. Although this behavior is desirable for computer vision tasks, it is inappropriate for forensic tasks since noise is an important clue.\n\nThe network includes two elements: a convolutional unit and a fusion unit. Each convolutional unit in Figure 3 consists of four consecutive basic blocks shown in Figure 4(a), with a few exceptions such as the first and the last part [39]. Figure 4(b) shows the fusion unit, which fuses multi-resolution feature maps by summing multi-resolution features after matching resolutions by bilinear interpolation (upsampling) or strided convolution (downsampling).\n\nThe RGB stream structure is identical to HRNet except the last part is removed. The RGB stream takes RGB pixel values as input and the first convolutional unit reduces res-  olution 4-fold. Starting from the high-resolution path, it gradually goes through the network adding high-to-low resolution paths one by one and connecting multi-resolution paths in parallel. Each resolution remains until the end, producing 1 4 , 1 8 , 1 16 , and 1 32 resolutions. The DCT stream captures compression artifacts, i.e., statistical distributions of Y-channel DCT coefficients. The structure is a three-resolution variant of HRNet with the first convolutional unit replaced by a JPEG artifact learning module ( Figure 5). All convolutional units in this stream comprise four basic blocks (Figure 4(a)) without exceptions.\n1 \u00d7 1 dilated conv. (d = 8) 3 \u00d7 3 element-wise multiplication DCT coefficient of Y-channel\nThe JPEG artifact learning module initially converts the input array of DCT coefficients, M, to a binary volume using the transformation f :\nZ H\u00d7W \u2192 {0, 1} (T +1)\u00d7H\u00d7W such that f (M) t,i,j = 1, if abs(clip(M)) i,j = t 0, otherwise ,(1)\nwhere clip(\u00b7) clips the array element-wisely into the interval [\u2212T, T ] and abs(\u00b7) takes element-wise absolute values [42]. We experimentally determined optimal T to be 20. This binary volume representation is similar to DCT histogram [40] but allows the network to learn the relationship among adjacent DCT coefficients. DCT histogram merges information patch-wise, whereas this representation maintains image resolution which is suitable for segmentation. Consecutive convolutions are applied to the binary volume. Dilated convolution is used here, which is originally designed for increasing CNN receptive fields [43]. However, the proposed network uses 8-dilated convolutions in order to extract features in DCT coefficients derived from the same frequency basis. The number of feature map channels is reduced to 4 using 1 \u00d7 1 convolution and the feature map is forked. For the forked path, 8 \u00d7 8 quantization table obtained from the JPEG header is multiplied to the corresponding frequency components. This is similar to the procedure of dequantizing DCT coefficients in JPEG de- , which helps to significantly reduce resolution. Lastly in this module, the feature maps from the two paths are concatenated in channel dimension. The output passes the remaining path of the DCT stream.\n\nDuring training, input images are cropped to a fixed size to construct a tensor having a batch dimension. It is worth noting that a rectangular cropping region must be aligned with the 8 \u00d7 8 grid since JPEG encodes images into 8 \u00d7 8 blocks. This makes each channel of a channel-separated tensor represent a frequency component. This also allows the RGB stream to learn JPEG blocking artifacts as well as visual artifacts.\n\nOutput feature maps have resolutions ( 1 4 , 1 8 , 1 16 , 1 32 ) and ( 1 8 , 1 16 , 1 32 ) for the RGB and DCT streams, respectively. Two-stream feature maps are concatenated resolution-wise in channel dimension and passed to the final fusion stage (Figure 3), which is structurally identical to the final HR-Net stage, but with a different number of channels. All four resolution feature maps are finally bilinearly upsampled to match the highest resolution, concatenated, and pass the final convolutional layer. The final output is a 2 \u00d7 H 4 \u00d7 W 4 array of logits for each class (authentic and tampered).\n\n\nHandling non-JPEG images\n\nAlthough our network uses a quantization table as input, the network can also handle non-JPEG images. Since non-JPEG images do not contain quantized DCT coefficients, they are calculated from RGB pixels, similarly to a JPEG encoder. We regard the quantization table for those images to be all ones, corresponding to JPEG quality 100. For a simple implementation, we put a JPEG encoder at the front of the network and compress non-JPEG images to JPEG images using quality factor 100 with no chroma subsampling.  Figure 6. DCT stream classification and segmentation head architecture. Each is attached at the end of the DCT stream to classify double JPEG images for pretraining (Section 3.3) and localize the forgery using the DCT stream only for ablation study (Section 4.4), respectively. RGB stream heads can be similarly constructed using four resolutions. This automatically creates quantized DCT coefficients and a quantization table with all ones. This is based on the compression assumption: Although a spliced image is saved in uncompressed image format, two source (authentic) images used for the splice forgery were initially compressed in a camera, during acquisition. The file extension for the manipulated image does not matter, i.e., we do not assume a forger saved the forged image in a specific format.\n\n\nPretraining on Double JPEG detection\n\nDCT stream weights are initialized by pretraining on double JPEG detection. The task is to classify whether the given JPEG image has been compressed once or twice. Figure 6 shows that the classification head is attached at the end of the DCT stream since this is a binary classification task. Pretraining on this task helps the stream to capture rich compression artifacts.\n\nWe trained and tested the DCT stream on a dataset comprising 1.054M single and double-compressed JPEG images with mixed quality parameters [26]. They compressed raw images from [3,8,13] using 1,120 quantization tables including not only 51 standard tables (Q50-Q100) but also non-standard tables obtained from requested images from their public forensic web service.  (93.93%), which is the state-of-the-art performance compared with baselines [40,2,26]. The proposed network outperformed state-of-the-art neural network [26], which used histogram, even though we used a smaller range of coefficients. Hence, the binary volume representation is a good alternative to the DCT histogram for double JPEG detection.\n\nWe also investigated networks without quantization table multiplication to evaluate the effectiveness of using quantization tables. This differed from the original DCT stream in that the quantization table path and concatenation in Figure 5 were removed. Using quantization tables improved double JPEG detection accuracy. Thus, we have adopted quantization tables for forgery localization for the first time. Table 2 summarizes the splicing datasets employed in the experiments. We also report the number of Y-channel quantization tables for the first time. Various quantization tables are used, including standard and custom tables, to simulate real-world forgery.\n\n\nExperiments\n\n\nDatasets\n\nCASIA v2 [10] is a popular dataset for image forgery localization, including images from several sources. We use masks provided by a third-party user [28] since official ground truth masks are not provided. Fantastic Reality [16] includes authentic and spliced images for various scenes along with pixel-level ground truth masks. Although authentic images have diverse (153) quantization tables, tampered images have only one quantization table. IMD2020 [25] includes real-life manipulated images as well as manually created ground truth masks. This dataset contains the most diverse quantization tables because images were collected from the Internet and hence reflects real-world compression schemes. NC16 Splicing [14] is a subset of NC16 provided by the National Insti-tutes of Standards and Technology (NIST). NC16 contains high resolution and challenging manipulated images. Although there are several forgery types, we only use splicing forgery. Carvalho [9] DSO-1 contains images of people. Forgeries were created by adding one or more individuals from one to another image with post-processing to increase photorealism. Blocking artifacts are evident when zoomed in, which means that although the images are not in JPEG format, the source images were JPEG compressed, which satisfies the compression assumption (Section 3.2). Columbia [24] is a historic dataset for manipulation detection. Ground truth masks are obtained by taking the difference between authentic and forged images followed by some post-processing. The images in this dataset were not compressed in a camera, which violates the compression assumption (Section 3.2).\n\nQuantization tables for tampered images were not diverse, except for IMD2020. Therefore, we created another dataset (Spliced COCO) to avoid overfitting specific compression parameters, using COCO 2017 dataset [19] with various quantization tables. Similarly to [25,45], spliced images were automatically created by selecting one or more arbitrary objects in one image and pasting them onto another image at random positions, with random rotation and resizing. These images were then compressed at random JPEG quality factor 50-99. We did not apply other postprocessing, such as blurring the spliced boundary, because that might mislead the network to act like a blur-detector.\n\nWe used CASIA v2 (auth./tamp.), Fantastic Reality (auth./tamp.), IMD2020 (tamp.), and Spliced COCO (tamp.) for a training set; and the remaining datasets for testing only. The rightmost column in Table 2 shows the number of images used for testing. We used authentic images too, in contrast with previous image forgery localization studies. We expect this to help the network learn absolute boundaries between tampered and authentic regions, rather than relative boundaries to predict the most suspicious region per image.\n\n\nImplementation Details\n\nWe initialized the weights of the network by pretraining on ImageNet classification [17] for the RGB stream and double JPEG classification for the DCT stream (Section 3.3). We sampled a balanced number of images in each dataset to construct one epoch, to better handle the high variety of dataset sizes. Training images were cropped to 512\u00d7512 patches aligned with an 8\u00d78 grid. Full-resolution images were used for testing, which was possible since the proposed network was fully convolutional.\n\nThe network was implemented with PyTorch [27], using stochastic gradient descent with a momentum of 0.9 for the optimizer. The batch size was 24. The learning rate started from 0.005 and decayed exponentially. The objective was to minimize the pixel-wise binary cross entropy loss with fivefold more weight on tampered class. The experiments were performed using 2x NVIDIA TITAN RTX.\n\n\nEvaluation Metrics\n\nOur task is a binary segmentation, labeling each pixel in the input image as tampered (positive, 1) or authentic (negative, 0). Thus, each output pixel can be marked as true positive (G:1, P :1), true negative (G:0, P :0), false positive (G:0, P :1), and false negative (G:1, P :0), where G is the ground truth mask and P is the prediction output. G and P are 2-dimensional binary arrays with the same size as the input image.\n\nWe evaluated network performances using mean intersection over union (mIoU), a popularly used metric for semantic segmentation [12]. For the two-class case,\nmIoU(G, P ) = 1 2 \u00b7 #(G\u2229P ) #(G\u222aP ) + 1 2 \u00b7 #(G \u2229P ) #(G \u222aP ) = 1 2 \u00b7 TP TP+FP+FN + 1 2 \u00b7 TN TN+FP+FN , where #(\u00b7)\nis the number of positive pixels and negates (flips) the mask.\n\nFollowing [15], we also used the permuted metrics for evaluation. Permuted mIoU is defined as: p-mIoU(G, P ) = max mIoU(G, P ), mIoU(G, P ) . For forgery localization tasks, it is sometimes ambiguous which of the two segments is spliced. Permuted metrics measure how well a model can distinguish authentic and tampered regions, rather than its ability to say which is which.\n\nHowever, mIoU is inappropriate for authentic images, since every pixel in the ground truth mask is negative. Therefore, we used pixel accuracy for testing authentic images: Acc(G, P ) = #(G\u2229P )+#(G \u2229P )\n#(G\u222aG ) = TP+TN TP+TN+FP+FN .\nSimilarly, permuted pixel accuracy is defined as: p-Acc(G, P ) = max Acc(G, P ), Acc(G, P ) . Each metric was calculated per image and averaged over a dataset.\n\n\nResults\n\nThis section summarizes CAT-Net performance. Tables  3 and 4 show results for test splits and completely unseen images, respectively. We tested ManTra-Net [41] and EXIF consistency [15] to compare CAT-Net with current state-ofthe-art image manipulation detectors. Results for those two networks are reported only for completely unseen datasets to ensure fair comparison. We also report performances for the two CAT-Net sub-streams for ablation study and we includes a robustness test for JPEG compression (Figure 7). Figures 8 and 9 show some typical prediction outcomes.\n\nThe codes for the two baseline networks were obtained from official public repositories along with their trained weights. ManTra-Net could not test some NC16 Splicing images with full resolution due to GPU memory constraints (NVIDIA TITAN RTX 24GB). Therefore, we cropped those images to QHD (2560\u00d71440) for all networks. A normalized cut was used to aggregate patch-wise predictions  Table 4. Image splicing detection and localization performance for completely unseen datasets (%).\n\nfor the EXIF consistency network. Table 4 and Figure 8 show that CAT-Net excelled in almost all datasets for authentic and tampered images, compared with current state-of-the-art neural networks. The comparison networks always detect some region as tampered, since they are anomaly detectors, even for authentic images. However, CAT-Net produces less false positives since it is a segmentation model and we used authentic images during training. Differences between CAT-Net and the other networks were much larger for tampered images. Thus, CAT-Net was very effective tracking fine traces even if forged images were compressed, e.g. NC16 Splicing. Hence, CAT-Net achieved state-of-the-art performance in terms of detecting and localizing real-world image splicing forgeries.\n\nTables 3, 4, and Figure 9 show that RGB and DCT streams complementary cooperated to improve network performance. For example, in Carvalho (tamp.), the DCT stream performed better; whereas in NC16 Splicing (tamp.), the RGB stream performed better. In both cases, the full network performed best. As discussed in Section 4.1, Columbia violates the compression assumption. Here, the DCT stream couldn't predict well since the images were not compressed at the beginning, leaving no compression artifacts. However, the full network (CAT-Net) performed well on this dataset, with the help of the RGB stream. Figure 7 shows robustness on JPEG compression tested by compressing Columbia and Carvalho using quality factor 60-90. When additional compression was applied, all three network performances were degraded for Columbia, which had splicing created by two different cameras without compression. In Carvalho, additional compression surely decreased the performance, but the change was smaller because images have initial compression traces, which helped the networks to detect a spliced object. CAT-Net achieved  good performance for various quality factors.\n\n\nConclusion\n\nWe have proposed CAT-Net which localizes spliced regions on given images. CAT-Net was the first attempt to consider RGB and DCT domains simultaneously to effectively learn forensic features for visual and compression artifacts remaining in each domain through the RGB and DCT streams. In particular, the DCT stream, containing the JPEG artifact learning module, achieved outstanding performance detecting double JPEG compression. We applied transfer learning from double JPEG detection tasks to image forgery localization tasks for the first time. This helped the network to distinguish statistical fingerprints between spliced and authentic regions. CAT-Net achieved state-ofthe-art performance on localizing spliced regions for JPEG or non-JPEG images on diverse datasets compared with current networks.  \n\nFigure 1 .\n1Ground truth mask (e) ManTra-Net[41] (f) CAT-Net (Proposed) Challenge of localizing spliced regions from a JPEG image. Although ManTra-Net can trace various manipulations using RGB pixels, it is not ideal for capturing compression artifacts. The proposed approach considers RGB and DCT domains jointly to effectively tracks visual clues and compression traces.\n\nFigure 2 .\n2Statistical differences between tampered and authentic regions. DCT histograms are obtained from Y-channel DCT coefficients at the frequency (2,1) for tampered and authentic regions separately.\n\nFigure 3 .\n3The proposed CAT-Net architecture includes an RGB stream, a DCT stream, and a final fusion stage. The RGB stream takes RGB pixels and the DCT stream takes Y-channel DCT coefficients and a Y-channel quantization table as input. The JPEG artifact learning module is shown inFigure 5.\n\nFigure 4 .\n4Elements in the proposed network. A convolutional unit inFigure 3mainly consists of four consecutive basic blocks. The fusion unit fuses multi-resolution feature maps by summing them after matching resolutions.\n\nFigure 5 .\n5Proposed JPEG artifact learning module architecture.\n\nFigure 7 .\n7Robustness test on JPEG compression. CAT-Net showed the highest robustness for most of the JPEG quality factors.\n\nFigure 8 .\n8Image splicing localization results for the proposed network and two state-of-the-art networks. Ground truth mask is the union of TP and FN.\n\nFigure 9 .\n9Image splicing localization results for the proposed network and its sub-streams. Ground truth mask is the union of TP and FN.\n\n\ncoding. For the other path, the table is not multiplied. Each 64 (= 8 \u00d7 8) frequency component is separated for both paths. Note that previous operations are done frequencywise, hence each value in an 8 \u00d7 8 block represents a frequency component. Separating components changes shape from 4 \u00d7 H \u00d7 W to 256 \u00d7 H 8 \u00d7 W 8\n\n\nTable 1. Double JPEG detection performance (%). The DCT stream, a substream of CAT-Net, showed the highest classification accuracy.Method \nInput Type \nAcc \nTPR \nTNR \n\nVGG-16 [35] \nRGB pixels \n50.00 \n0.00 \n100.00 \n\nWang [40] \nDCT histogram [-5, 5] \n73.05 \n67.74 \n78.37 \n\nBarni [2] \nDCT histogram [-60, 60] \n84.46 \n78.35 \n90.53 \n\nPark [26] \nDCT histogram [-60, 60] \n& q. table \n92.76 \n90.90 \n94.59 \n\nDCT stream \nw/o q. table \nDCT volume [-20, 20] \n91.71 \n84.97 \n97.42 \n\nDCT stream \n(Proposed) \n\nDCT volume [-20, 20] \n& q. table \n93.93 \n89.43 \n97.75 \n\n\n\n\nTable 1shows the double JPEG detection performance of the proposed DCT streamDataset \nImages \nJPEGs \nQ. tables \nTest \n\nCASIA v2 [10] \nauth. \n7,491 \n7,437 \n50 \n300 \ntamp. \n5,105 \n2,057 \n7 \n300 \n\nFantastic Reality [16] \nauth. \n16,592 \n16,592 \n153 \n1,200 \ntamp. \n19,423 \n19,423 \n1 \n1,325 \n\nIMD2020 [25] \nauth. \n414 \n414 \n58 \n-\ntamp. \n2,010 \n1,813 \n73 \n141 \n\nNC16 Splicing [14] \ntamp. \n288 \n288 \n3 \n288 \n\nCarvalho [9] \nauth. \n100 \n0 \n-\n100 \ntamp. \n100 \n0 \n-\n100 \n\nColumbia [24] \nauth. \n183 \n0 \n-\n183 \ntamp. \n180 \n0 \n-\n180 \nSpliced COCO \n(Section 4.1) \ntamp. \n917,648 \n917,648 \n50 \n4,816 \n\n\n\nTable 2 .\n2Splicing datasets employed in the experiments.\n\n\nTable 3. Image splicing detection and localization performance for test splits (%).380 \n\nCASIA v2 \n\nFantastic Reality \nIMD2020 \nSpliced COCO \nNetwork \nauthentic \ntampered \nauthentic \ntampered \ntampered \ntampered \nAcc \np-Acc \nmIoU \np-mIoU \nAcc \np-Acc \nmIoU \np-mIoU \nmIoU \np-mIoU \nmIoU \np-mIoU \n\nCAT-Net (Proposed) \n99.66 \n99.66 \n87.63 \n87.69 \n99.73 \n99.75 \n93.31 \n93.31 \n76.00 \n76.53 \n93.87 \n93.87 \n\nRGB stream only \n99.47 \n99.70 \n77.54 \n77.54 \n99.89 \n99.89 \n92.14 \n92.14 \n74.52 \n74.78 \n93.80 \n93.80 \n\nDCT stream only \n97.83 \n97.83 \n83.00 \n83.12 \n99.47 \n99.59 \n83.91 \n83.94 \n68.89 \n69.64 \n81.08 \n81.10 \n\nNC16 Splicing \nCarvalho \nColumbia \nNetwork \ntampered \nauthentic \ntampered \nauthentic \ntampered \nmIoU \np-mIoU \nAcc \np-Acc \nmIoU \np-mIoU \nAcc \np-Acc \nmIoU \np-mIoU \n\nCAT-Net (Proposed) \n68.41 \n69.18 \n99.79 \n99.79 \n79.44 \n79.44 \n99.54 \n99.54 \n83.05 \n90.09 \n\nRGB stream only \n60.04 \n61.25 \n99.85 \n99.85 \n61.17 \n61.17 \n99.60 \n99.60 \n85.04 \n89.22 \n\nDCT stream only \n54.76 \n59.31 \n99.33 \n99.33 \n78.84 \n78.84 \n99.37 \n99.37 \n39.34 \n40.49 \n\nManTra-Net [41] \n50.12 \n50.34 \n98.65 \n98.65 \n56.28 \n56.46 \n95.66 \n95.66 \n52.34 \n52.40 \n\nEXIF consistency [15] \n48.68 \n53.55 \n62.04 \n63.56 \n48.40 \n51.33 \n67.60 \n68.20 \n80.81 \n85.29 \n\n\n\nA sift-based forensic method for copy-move attack detection and transformation recovery. Irene Amerini, Lamberto Ballan, Roberto Caldelli, Alberto Del Bimbo, Giuseppe Serra, IEEE transactions on information forensics and security. 63Irene Amerini, Lamberto Ballan, Roberto Caldelli, Alberto Del Bimbo, and Giuseppe Serra. A sift-based forensic method for copy-move attack detection and transformation recovery. IEEE transactions on information forensics and security, 6(3):1099-1110, 2011.\n\nAligned and non-aligned double jpeg detection using convolutional neural networks. Mauro Barni, Luca Bondi, Nicol\u00f2 Bonettini, Paolo Bestagini, Andrea Costanzo, Marco Maggini, Benedetta Tondi, Stefano Tubaro, Journal of Visual Communication and Image Representation. 49Mauro Barni, Luca Bondi, Nicol\u00f2 Bonettini, Paolo Bestagini, Andrea Costanzo, Marco Maggini, Benedetta Tondi, and Stefano Tubaro. Aligned and non-aligned double jpeg detection using convolutional neural networks. Jour- nal of Visual Communication and Image Representation, 49:153-163, 2017.\n\nbreak our steganographic system\": the ins and outs of organizing boss. Patrick Bas, Tom\u00e1\u0161 Filler, Tom\u00e1\u0161 Pevn\u1ef3, International workshop on information hiding. SpringerPatrick Bas, Tom\u00e1\u0161 Filler, and Tom\u00e1\u0161 Pevn\u1ef3. \" break our steganographic system\": the ins and outs of organizing boss. In International workshop on information hiding, pages 59- 70. Springer, 2011.\n\nConstrained convolutional neural networks: A new approach towards general purpose image manipulation detection. Belhassen Bayar, C Matthew, Stamm, IEEE Transactions on Information Forensics and Security. 1311Belhassen Bayar and Matthew C Stamm. Constrained con- volutional neural networks: A new approach towards general purpose image manipulation detection. IEEE Transactions on Information Forensics and Security, 13(11):2691-2706, 2018.\n\nRru-net: The ringed residual u-net for image splicing forgery detection. Xiuli Bi, Yang Wei, Bin Xiao, Weisheng Li, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops. the IEEE Conference on Computer Vision and Pattern Recognition WorkshopsXiuli Bi, Yang Wei, Bin Xiao, and Weisheng Li. Rru-net: The ringed residual u-net for image splicing forgery detec- tion. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops, pages 0-0, 2019.\n\nDeep residual network for steganalysis of digital images. Mehdi Boroumand, Mo Chen, Jessica Fridrich, IEEE Transactions on Information Forensics and Security. 145Mehdi Boroumand, Mo Chen, and Jessica Fridrich. Deep residual network for steganalysis of digital images. IEEE Transactions on Information Forensics and Security, 14(5):1181-1193, 2018.\n\nDetecting recompression of jpeg images via periodicity analysis of compression artifacts for tampering detection. Yi-Lei Chen, Chiou-Ting Hsu, IEEE Transactions on Information Forensics and Security. 62Yi-Lei Chen and Chiou-Ting Hsu. Detecting recompression of jpeg images via periodicity analysis of compression arti- facts for tampering detection. IEEE Transactions on Infor- mation Forensics and Security, 6(2):396-406, 2011.\n\nRaise: A raw images dataset for digital image forensics. Duc-Tien Dang-Nguyen, Cecilia Pasquini, Valentina Conotter, Giulia Boato, Proceedings of the 6th ACM Multimedia Systems Conference. the 6th ACM Multimedia Systems ConferenceDuc-Tien Dang-Nguyen, Cecilia Pasquini, Valentina Conot- ter, and Giulia Boato. Raise: A raw images dataset for digital image forensics. In Proceedings of the 6th ACM Multimedia Systems Conference, pages 219-224, 2015.\n\nExposing digital image forgeries by illumination color classification. Tiago Jos\u00e9 De Carvalho, Christian Riess, Elli Angelopoulou, Helio Pedrini, Anderson De Rezende, Rocha, IEEE Transactions on Information Forensics and Security. 87Tiago Jos\u00e9 De Carvalho, Christian Riess, Elli Angelopoulou, Helio Pedrini, and Anderson de Rezende Rocha. Exposing digital image forgeries by illumination color classification. IEEE Transactions on Information Forensics and Security, 8(7):1182-1194, 2013.\n\nCasia image tampering detection evaluation database. Jing Dong, Wei Wang, Tieniu Tan, 2013 IEEE China Summit and International Conference on Signal and Information Processing. IEEEJing Dong, Wei Wang, and Tieniu Tan. Casia image tam- pering detection evaluation database. In 2013 IEEE China Summit and International Conference on Signal and Infor- mation Processing, pages 422-426. IEEE, 2013.\n\nRich models for steganalysis of digital images. Jessica Fridrich, Jan Kodovsky, IEEE Transactions on Information Forensics and Security. 73Jessica Fridrich and Jan Kodovsky. Rich models for steganal- ysis of digital images. IEEE Transactions on Information Forensics and Security, 7(3):868-882, 2012.\n\nA review on deep learning techniques applied to semantic segmentation. Alberto Garcia-Garcia, Sergio Orts-Escolano, Sergiu Oprea, Victor Villena-Martinez, Jose Garcia-Rodriguez, arXiv:1704.06857arXiv preprintAlberto Garcia-Garcia, Sergio Orts-Escolano, Sergiu Oprea, Victor Villena-Martinez, and Jose Garcia-Rodriguez. A re- view on deep learning techniques applied to semantic seg- mentation. arXiv preprint arXiv:1704.06857, 2017.\n\nThe'dresden image database'for benchmarking digital image forensics. Thomas Gloe, Rainer B\u00f6hme, Proceedings of the 2010 ACM Symposium on Applied Computing. the 2010 ACM Symposium on Applied ComputingThomas Gloe and Rainer B\u00f6hme. The'dresden image database'for benchmarking digital image forensics. In Pro- ceedings of the 2010 ACM Symposium on Applied Comput- ing, pages 1584-1590, 2010.\n\nMfc datasets: Large-scale benchmark datasets for media forensic challenge evaluation. Haiying Guan, Mark Kozak, Eric Robertson, Yooyoung Lee, Amy N Yates, Andrew Delgado, Daniel Zhou, Timothee Kheyrkhah, Jeff Smith, Jonathan Fiscus, 2019 IEEE Winter Applications of Computer Vision Workshops (WACVW). IEEEHaiying Guan, Mark Kozak, Eric Robertson, Yooyoung Lee, Amy N Yates, Andrew Delgado, Daniel Zhou, Timothee Kheyrkhah, Jeff Smith, and Jonathan Fiscus. Mfc datasets: Large-scale benchmark datasets for media forensic challenge evaluation. In 2019 IEEE Winter Applications of Computer Vision Workshops (WACVW), pages 63-72. IEEE, 2019.\n\nFighting fake news: Image splice detection via learned self-consistency. Minyoung Huh, Andrew Liu, Andrew Owens, Alexei A Efros, Proceedings of the European Conference on Computer Vision (ECCV). the European Conference on Computer Vision (ECCV)Minyoung Huh, Andrew Liu, Andrew Owens, and Alexei A Efros. Fighting fake news: Image splice detection via learned self-consistency. In Proceedings of the European Conference on Computer Vision (ECCV), pages 101-117, 2018.\n\nThe point where reality meets fantasy: Mixed adversarial generators for image splice detection. Vladimir Vladimir V Kniaz, Fabio Knyaz, Remondino, Advances in Neural Information Processing Systems. Vladimir V Kniaz, Vladimir Knyaz, and Fabio Remondino. The point where reality meets fantasy: Mixed adversarial generators for image splice detection. In Advances in Neural Information Processing Systems, pages 215-226, 2019.\n\nImagenet classification with deep convolutional neural networks. Alex Krizhevsky, Ilya Sutskever, Geoffrey E Hinton, Advances in neural information processing systems. Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convolutional neural net- works. In Advances in neural information processing sys- tems, pages 1097-1105, 2012.\n\nKaiming He, and Piotr Doll\u00e1r. Focal loss for dense object detection. Tsung-Yi Lin, Priya Goyal, Ross Girshick, Proceedings of the IEEE international conference on computer vision. the IEEE international conference on computer visionTsung-Yi Lin, Priya Goyal, Ross Girshick, Kaiming He, and Piotr Doll\u00e1r. Focal loss for dense object detection. In Pro- ceedings of the IEEE international conference on computer vision, pages 2980-2988, 2017.\n\nMicrosoft coco: Common objects in context. Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll\u00e1r, C Lawrence Zitnick, European conference on computer vision. SpringerTsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll\u00e1r, and C Lawrence Zitnick. Microsoft coco: Common objects in context. In European conference on computer vision, pages 740-755. Springer, 2014.\n\nFully convolutional networks for semantic segmentation. Jonathan Long, Evan Shelhamer, Trevor Darrell, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionJonathan Long, Evan Shelhamer, and Trevor Darrell. Fully convolutional networks for semantic segmentation. In Pro- ceedings of the IEEE conference on computer vision and pat- tern recognition, pages 3431-3440, 2015.\n\nEstimation of primary quantization matrix in double compressed jpeg images. Jan Luk\u00e1\u0161, Jessica Fridrich, Proc. Digital forensic research workshop. Digital forensic research workshopJan Luk\u00e1\u0161 and Jessica Fridrich. Estimation of primary quan- tization matrix in double compressed jpeg images. In Proc. Digital forensic research workshop, pages 5-8, 2003.\n\nDigital camera identification from sensor pattern noise. Jan Lukas, Jessica Fridrich, Miroslav Goljan, IEEE Transactions on Information Forensics and Security. 12Jan Lukas, Jessica Fridrich, and Miroslav Goljan. Digital camera identification from sensor pattern noise. IEEE Trans- actions on Information Forensics and Security, 1(2):205- 214, 2006.\n\nForensic similarity for digital images. Owen Mayer, C Matthew, Stamm, IEEE Transactions on Information Forensics and Security. 15Owen Mayer and Matthew C Stamm. Forensic similarity for digital images. IEEE Transactions on Information Forensics and Security, 15:1331-1346, 2019.\n\nA data set of authentic and spliced image blocks. Tian-Tsong Ng, Shih-Fu Chang, Q Sun, 203-2004-3Columbia University, ADVENTTechnical ReportTian-Tsong Ng, Shih-Fu Chang, and Q Sun. A data set of authentic and spliced image blocks. Columbia University, ADVENT Technical Report 203-2004-3, 2004.\n\nImd2020: A large-scale annotated dataset tailored for detecting manipulated images. Adam Novozamsky, Babak Mahdian, Stanislav Saic, Proceedings of the IEEE Winter Conference on Applications of Computer Vision Workshops. the IEEE Winter Conference on Applications of Computer Vision WorkshopsAdam Novozamsky, Babak Mahdian, and Stanislav Saic. Imd2020: A large-scale annotated dataset tailored for detect- ing manipulated images. In Proceedings of the IEEE Winter Conference on Applications of Computer Vision Workshops, pages 71-80, 2020.\n\nDouble jpeg detection in mixed jpeg quality factors using deep convolutional neural network. Jinseok Park, Donghyeon Cho, Wonhyuk Ahn, Heung-Kyu Lee, Proceedings of the European Conference on Computer Vision (ECCV). the European Conference on Computer Vision (ECCV)Jinseok Park, Donghyeon Cho, Wonhyuk Ahn, and Heung- Kyu Lee. Double jpeg detection in mixed jpeg quality factors using deep convolutional neural network. In Proceedings of the European Conference on Computer Vision (ECCV), pages 636-652, 2018.\n\n. Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, ZemingAdam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming\n\nPytorch: An imperative style, high-performance deep learning library. Natalia Lin, Luca Gimelshein, Antiga, Advances in neural information processing systems. Lin, Natalia Gimelshein, Luca Antiga, et al. Pytorch: An imperative style, high-performance deep learning library. In Advances in neural information processing systems, pages 8026-8037, 2019.\n\nHybrid image-retrieval method for imagesplicing validation. Nam Thanh Pham, Jong-Weon Lee, Goo-Rak Kwon, Chun-Su Park, Symmetry. 11183Nam Thanh Pham, Jong-Weon Lee, Goo-Rak Kwon, and Chun-Su Park. Hybrid image-retrieval method for image- splicing validation. Symmetry, 11(1):83, 2019.\n\nStatistical tools for digital forensics. C Alin, Hany Popescu, Farid, international workshop on information hiding. SpringerAlin C Popescu and Hany Farid. Statistical tools for digital forensics. In international workshop on information hiding, pages 128-147. Springer, 2004.\n\nExposing digital forgeries by detecting traces of resampling. C Alin, Hany Popescu, Farid, IEEE Transactions on signal processing. 53Alin C Popescu and Hany Farid. Exposing digital forgeries by detecting traces of resampling. IEEE Transactions on sig- nal processing, 53(2):758-767, 2005.\n\nYou only look once: Unified, real-time object detection. Joseph Redmon, Santosh Divvala, Ross Girshick, Ali Farhadi, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionJoseph Redmon, Santosh Divvala, Ross Girshick, and Ali Farhadi. You only look once: Unified, real-time object de- tection. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 779-788, 2016.\n\nFaster r-cnn: Towards real-time object detection with region proposal networks. Kaiming Shaoqing Ren, Ross He, Jian Girshick, Sun, Advances in neural information processing systems. Shaoqing Ren, Kaiming He, Ross Girshick, and Jian Sun. Faster r-cnn: Towards real-time object detection with region proposal networks. In Advances in neural information pro- cessing systems, pages 91-99, 2015.\n\nUnet: Convolutional networks for biomedical image segmentation. Olaf Ronneberger, Philipp Fischer, Thomas Brox, International Conference on Medical image computing and computer-assisted intervention. SpringerOlaf Ronneberger, Philipp Fischer, and Thomas Brox. U- net: Convolutional networks for biomedical image segmen- tation. In International Conference on Medical image com- puting and computer-assisted intervention, pages 234-241. Springer, 2015.\n\nRotation invariant localization of duplicated image regions based on zernike moments. Matthias Seung-Jin Ryu, Min-Jeong Kirchner, Heung-Kyu Lee, Lee, IEEE Transactions on Information Forensics and Security. 88Seung-Jin Ryu, Matthias Kirchner, Min-Jeong Lee, and Heung-Kyu Lee. Rotation invariant localization of dupli- cated image regions based on zernike moments. IEEE Trans- actions on Information Forensics and Security, 8(8):1355- 1370, 2013.\n\nVery deep convolutional networks for large-scale image recognition. Karen Simonyan, Andrew Zisserman, arXiv:1409.1556arXiv preprintKaren Simonyan and Andrew Zisserman. Very deep convo- lutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556, 2014.\n\nForensic detection of image manipulation using statistical intrinsic fingerprints. C Matthew, Kj Ray Stamm, Liu, IEEE Transactions on Information Forensics and Security. 53Matthew C Stamm and KJ Ray Liu. Forensic detection of image manipulation using statistical intrinsic fingerprints. IEEE Transactions on Information Forensics and Security, 5(3):492-506, 2010.\n\nLuisa Verdoliva, arXiv:2001.06564Media forensics and deepfakes: an overview. arXiv preprintLuisa Verdoliva. Media forensics and deepfakes: an overview. arXiv preprint arXiv:2001.06564, 2020.\n\nBlock-level double jpeg compression detection for image forgery localization. Vinay Verma, Deepak Singh, Nitin Khanna, arXiv:2003.09393arXiv preprintVinay Verma, Deepak Singh, and Nitin Khanna. Block-level double jpeg compression detection for image forgery local- ization. arXiv preprint arXiv:2003.09393, 2020.\n\nDeep high-resolution representation learning for visual recognition. Jingdong Wang, Ke Sun, Tianheng Cheng, Borui Jiang, Chaorui Deng, Yang Zhao, Dong Liu, Yadong Mu, Mingkui Tan, Xinggang Wang, IEEE transactions. 2020Jingdong Wang, Ke Sun, Tianheng Cheng, Borui Jiang, Chaorui Deng, Yang Zhao, Dong Liu, Yadong Mu, Mingkui Tan, Xinggang Wang, et al. Deep high-resolution represen- tation learning for visual recognition. IEEE transactions on pattern analysis and machine intelligence, 2020.\n\nDouble jpeg compression forensics based on a convolutional neural network. Qing Wang, Rong Zhang, EURASIP Journal on Information Security. 2016123Qing Wang and Rong Zhang. Double jpeg compres- sion forensics based on a convolutional neural network. EURASIP Journal on Information Security, 2016(1):23, 2016.\n\nMantra-net: Manipulation tracing network for detection and localization of image forgeries with anomalous features. Yue Wu, Wael Abdalmageed, Premkumar Natarajan, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionYue Wu, Wael AbdAlmageed, and Premkumar Natarajan. Mantra-net: Manipulation tracing network for detection and localization of image forgeries with anomalous features. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 9543-9552, 2019.\n\nAn intriguing struggle of cnns in jpeg steganalysis and the onehot solution. Yassine Yousfi, Jessica Fridrich, IEEE Signal Processing Letters. Yassine Yousfi and Jessica Fridrich. An intriguing struggle of cnns in jpeg steganalysis and the onehot solution. IEEE Signal Processing Letters, 2020.\n\nMulti-scale context aggregation by dilated convolutions. Fisher Yu, Vladlen Koltun, arXiv:1511.07122arXiv preprintFisher Yu and Vladlen Koltun. Multi-scale context aggregation by dilated convolutions. arXiv preprint arXiv:1511.07122, 2015.\n\nLarge-scale evaluation of splicing localization algorithms for web images. Markos Zampoglou, Symeon Papadopoulos, Yiannis Kompatsiaris, Multimedia Tools and Applications. 764Markos Zampoglou, Symeon Papadopoulos, and Yiannis Kompatsiaris. Large-scale evaluation of splicing localization algorithms for web images. Multimedia Tools and Applica- tions, 76(4):4801-4834, 2017.\n\nLearning rich features for image manipulation detection. Peng Zhou, Xintong Han, I Vlad, Larry S Morariu, Davis, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionPeng Zhou, Xintong Han, Vlad I Morariu, and Larry S Davis. Learning rich features for image manipulation detection. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 1053-1061, 2018.\n", "annotations": {"author": "[{\"start\":\"98\",\"end\":\"194\"},{\"start\":\"195\",\"end\":\"266\"},{\"start\":\"267\",\"end\":\"342\"},{\"start\":\"343\",\"end\":\"418\"}]", "publisher": null, "author_last_name": "[{\"start\":\"109\",\"end\":\"113\"},{\"start\":\"202\",\"end\":\"204\"},{\"start\":\"277\",\"end\":\"280\"},{\"start\":\"353\",\"end\":\"356\"}]", "author_first_name": "[{\"start\":\"98\",\"end\":\"108\"},{\"start\":\"195\",\"end\":\"201\"},{\"start\":\"267\",\"end\":\"276\"},{\"start\":\"343\",\"end\":\"352\"}]", "author_affiliation": "[{\"start\":\"134\",\"end\":\"193\"},{\"start\":\"206\",\"end\":\"265\"},{\"start\":\"282\",\"end\":\"341\"},{\"start\":\"358\",\"end\":\"417\"}]", "title": "[{\"start\":\"1\",\"end\":\"95\"},{\"start\":\"419\",\"end\":\"513\"}]", "venue": null, "abstract": "[{\"start\":\"543\",\"end\":\"1286\"}]", "bib_ref": "[{\"start\":\"1683\",\"end\":\"1687\",\"attributes\":{\"ref_id\":\"b44\"}},{\"start\":\"1864\",\"end\":\"1868\",\"attributes\":{\"ref_id\":\"b37\"}},{\"start\":\"2518\",\"end\":\"2522\",\"attributes\":{\"ref_id\":\"b21\"}},{\"start\":\"2573\",\"end\":\"2577\",\"attributes\":{\"ref_id\":\"b30\"}},{\"start\":\"2601\",\"end\":\"2604\",\"attributes\":{\"ref_id\":\"b1\"}},{\"start\":\"2604\",\"end\":\"2607\",\"attributes\":{\"ref_id\":\"b25\"}},{\"start\":\"2607\",\"end\":\"2610\",\"attributes\":{\"ref_id\":\"b38\"}},{\"start\":\"2610\",\"end\":\"2613\",\"attributes\":{\"ref_id\":\"b40\"}},{\"start\":\"3420\",\"end\":\"3424\",\"attributes\":{\"ref_id\":\"b29\"}},{\"start\":\"3521\",\"end\":\"3525\",\"attributes\":{\"ref_id\":\"b29\"}},{\"start\":\"3610\",\"end\":\"3613\",\"attributes\":{\"ref_id\":\"b6\"}},{\"start\":\"3613\",\"end\":\"3616\",\"attributes\":{\"ref_id\":\"b20\"}},{\"start\":\"3715\",\"end\":\"3718\",\"attributes\":{\"ref_id\":\"b1\"}},{\"start\":\"3718\",\"end\":\"3721\",\"attributes\":{\"ref_id\":\"b25\"}},{\"start\":\"3721\",\"end\":\"3724\",\"attributes\":{\"ref_id\":\"b38\"}},{\"start\":\"3724\",\"end\":\"3727\",\"attributes\":{\"ref_id\":\"b40\"}},{\"start\":\"3868\",\"end\":\"3872\",\"attributes\":{\"ref_id\":\"b42\"}},{\"start\":\"4099\",\"end\":\"4103\",\"attributes\":{\"ref_id\":\"b42\"}},{\"start\":\"5080\",\"end\":\"5084\",\"attributes\":{\"ref_id\":\"b41\"}},{\"start\":\"5084\",\"end\":\"5087\",\"attributes\":{\"ref_id\":\"b14\"}},{\"start\":\"5389\",\"end\":\"5392\",\"attributes\":{\"ref_id\":\"b1\"}},{\"start\":\"5392\",\"end\":\"5395\",\"attributes\":{\"ref_id\":\"b25\"}},{\"start\":\"5395\",\"end\":\"5398\",\"attributes\":{\"ref_id\":\"b40\"}},{\"start\":\"5740\",\"end\":\"5743\",\"attributes\":{\"ref_id\":\"b1\"}},{\"start\":\"5743\",\"end\":\"5746\",\"attributes\":{\"ref_id\":\"b25\"}},{\"start\":\"5746\",\"end\":\"5749\",\"attributes\":{\"ref_id\":\"b38\"}},{\"start\":\"5749\",\"end\":\"5752\",\"attributes\":{\"ref_id\":\"b40\"}},{\"start\":\"5771\",\"end\":\"5775\",\"attributes\":{\"ref_id\":\"b30\"}},{\"start\":\"5798\",\"end\":\"5802\",\"attributes\":{\"ref_id\":\"b36\"}},{\"start\":\"5831\",\"end\":\"5834\",\"attributes\":{\"ref_id\":\"b3\"}},{\"start\":\"6316\",\"end\":\"6319\",\"attributes\":{\"ref_id\":\"b0\"}},{\"start\":\"6319\",\"end\":\"6322\",\"attributes\":{\"ref_id\":\"b34\"}},{\"start\":\"6342\",\"end\":\"6346\",\"attributes\":{\"ref_id\":\"b14\"}},{\"start\":\"6346\",\"end\":\"6349\",\"attributes\":{\"ref_id\":\"b22\"}},{\"start\":\"6416\",\"end\":\"6420\",\"attributes\":{\"ref_id\":\"b14\"}},{\"start\":\"6837\",\"end\":\"6841\",\"attributes\":{\"ref_id\":\"b17\"}},{\"start\":\"6841\",\"end\":\"6844\",\"attributes\":{\"ref_id\":\"b31\"}},{\"start\":\"6844\",\"end\":\"6847\",\"attributes\":{\"ref_id\":\"b32\"}},{\"start\":\"6874\",\"end\":\"6878\",\"attributes\":{\"ref_id\":\"b19\"}},{\"start\":\"6878\",\"end\":\"6881\",\"attributes\":{\"ref_id\":\"b33\"}},{\"start\":\"6881\",\"end\":\"6884\",\"attributes\":{\"ref_id\":\"b39\"}},{\"start\":\"7006\",\"end\":\"7010\",\"attributes\":{\"ref_id\":\"b45\"}},{\"start\":\"7023\",\"end\":\"7027\",\"attributes\":{\"ref_id\":\"b10\"}},{\"start\":\"7150\",\"end\":\"7153\",\"attributes\":{\"ref_id\":\"b4\"}},{\"start\":\"7171\",\"end\":\"7175\",\"attributes\":{\"ref_id\":\"b33\"}},{\"start\":\"7326\",\"end\":\"7330\",\"attributes\":{\"ref_id\":\"b41\"}},{\"start\":\"7368\",\"end\":\"7372\",\"attributes\":{\"ref_id\":\"b10\"}},{\"start\":\"7423\",\"end\":\"7426\",\"attributes\":{\"ref_id\":\"b3\"}},{\"start\":\"7954\",\"end\":\"7958\",\"attributes\":{\"ref_id\":\"b39\"}},{\"start\":\"8121\",\"end\":\"8125\",\"attributes\":{\"ref_id\":\"b42\"}},{\"start\":\"8639\",\"end\":\"8643\",\"attributes\":{\"ref_id\":\"b39\"}},{\"start\":\"9321\",\"end\":\"9324\",\"attributes\":{\"ref_id\":\"b5\"}},{\"start\":\"9696\",\"end\":\"9700\",\"attributes\":{\"ref_id\":\"b39\"}},{\"start\":\"10349\",\"end\":\"10353\"},{\"start\":\"11177\",\"end\":\"11181\",\"attributes\":{\"ref_id\":\"b42\"}},{\"start\":\"11294\",\"end\":\"11298\",\"attributes\":{\"ref_id\":\"b40\"}},{\"start\":\"11675\",\"end\":\"11679\",\"attributes\":{\"ref_id\":\"b43\"}},{\"start\":\"15279\",\"end\":\"15283\",\"attributes\":{\"ref_id\":\"b25\"}},{\"start\":\"15317\",\"end\":\"15320\",\"attributes\":{\"ref_id\":\"b2\"}},{\"start\":\"15320\",\"end\":\"15322\",\"attributes\":{\"ref_id\":\"b7\"}},{\"start\":\"15322\",\"end\":\"15324\",\"attributes\":{\"ref_id\":\"b12\"}},{\"start\":\"15584\",\"end\":\"15588\",\"attributes\":{\"ref_id\":\"b40\"}},{\"start\":\"15588\",\"end\":\"15590\",\"attributes\":{\"ref_id\":\"b1\"}},{\"start\":\"15590\",\"end\":\"15593\",\"attributes\":{\"ref_id\":\"b25\"}},{\"start\":\"15661\",\"end\":\"15665\",\"attributes\":{\"ref_id\":\"b25\"}},{\"start\":\"16554\",\"end\":\"16558\",\"attributes\":{\"ref_id\":\"b9\"}},{\"start\":\"16695\",\"end\":\"16699\",\"attributes\":{\"ref_id\":\"b28\"}},{\"start\":\"16770\",\"end\":\"16774\",\"attributes\":{\"ref_id\":\"b15\"}},{\"start\":\"16999\",\"end\":\"17003\",\"attributes\":{\"ref_id\":\"b24\"}},{\"start\":\"17262\",\"end\":\"17266\",\"attributes\":{\"ref_id\":\"b13\"}},{\"start\":\"17507\",\"end\":\"17510\",\"attributes\":{\"ref_id\":\"b8\"}},{\"start\":\"17889\",\"end\":\"17893\",\"attributes\":{\"ref_id\":\"b23\"}},{\"start\":\"18398\",\"end\":\"18402\",\"attributes\":{\"ref_id\":\"b18\"}},{\"start\":\"18450\",\"end\":\"18454\",\"attributes\":{\"ref_id\":\"b24\"}},{\"start\":\"18454\",\"end\":\"18457\",\"attributes\":{\"ref_id\":\"b45\"}},{\"start\":\"19500\",\"end\":\"19504\",\"attributes\":{\"ref_id\":\"b16\"}},{\"start\":\"19953\",\"end\":\"19957\",\"attributes\":{\"ref_id\":\"b26\"}},{\"start\":\"20873\",\"end\":\"20877\",\"attributes\":{\"ref_id\":\"b11\"}},{\"start\":\"21092\",\"end\":\"21096\",\"attributes\":{\"ref_id\":\"b14\"}},{\"start\":\"22017\",\"end\":\"22021\",\"attributes\":{\"ref_id\":\"b41\"}},{\"start\":\"22043\",\"end\":\"22047\",\"attributes\":{\"ref_id\":\"b14\"}},{\"start\":\"25720\",\"end\":\"25724\",\"attributes\":{\"ref_id\":\"b41\"}}]", "figure": "[{\"start\":\"25675\",\"end\":\"26048\",\"attributes\":{\"id\":\"fig_0\"}},{\"start\":\"26049\",\"end\":\"26255\",\"attributes\":{\"id\":\"fig_2\"}},{\"start\":\"26256\",\"end\":\"26550\",\"attributes\":{\"id\":\"fig_4\"}},{\"start\":\"26551\",\"end\":\"26774\",\"attributes\":{\"id\":\"fig_5\"}},{\"start\":\"26775\",\"end\":\"26840\",\"attributes\":{\"id\":\"fig_6\"}},{\"start\":\"26841\",\"end\":\"26966\",\"attributes\":{\"id\":\"fig_9\"}},{\"start\":\"26967\",\"end\":\"27120\",\"attributes\":{\"id\":\"fig_10\"}},{\"start\":\"27121\",\"end\":\"27260\",\"attributes\":{\"id\":\"fig_11\"}},{\"start\":\"27261\",\"end\":\"27579\",\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"}},{\"start\":\"27580\",\"end\":\"28131\",\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"}},{\"start\":\"28132\",\"end\":\"28719\",\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"}},{\"start\":\"28720\",\"end\":\"28778\",\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"}},{\"start\":\"28779\",\"end\":\"29996\",\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"}}]", "paragraph": "[{\"start\":\"1302\",\"end\":\"1767\"},{\"start\":\"1769\",\"end\":\"2320\"},{\"start\":\"2322\",\"end\":\"4231\"},{\"start\":\"4233\",\"end\":\"4801\"},{\"start\":\"4803\",\"end\":\"4852\"},{\"start\":\"4854\",\"end\":\"5141\"},{\"start\":\"5143\",\"end\":\"5445\"},{\"start\":\"5462\",\"end\":\"5594\"},{\"start\":\"5596\",\"end\":\"6073\"},{\"start\":\"6075\",\"end\":\"7698\"},{\"start\":\"7700\",\"end\":\"8586\"},{\"start\":\"8626\",\"end\":\"9461\"},{\"start\":\"9463\",\"end\":\"9920\"},{\"start\":\"9922\",\"end\":\"10731\"},{\"start\":\"10823\",\"end\":\"10963\"},{\"start\":\"11059\",\"end\":\"12347\"},{\"start\":\"12349\",\"end\":\"12770\"},{\"start\":\"12772\",\"end\":\"13378\"},{\"start\":\"13407\",\"end\":\"14724\"},{\"start\":\"14765\",\"end\":\"15138\"},{\"start\":\"15140\",\"end\":\"15851\"},{\"start\":\"15853\",\"end\":\"16518\"},{\"start\":\"16545\",\"end\":\"18187\"},{\"start\":\"18189\",\"end\":\"18865\"},{\"start\":\"18867\",\"end\":\"19389\"},{\"start\":\"19416\",\"end\":\"19910\"},{\"start\":\"19912\",\"end\":\"20295\"},{\"start\":\"20318\",\"end\":\"20744\"},{\"start\":\"20746\",\"end\":\"20902\"},{\"start\":\"21018\",\"end\":\"21080\"},{\"start\":\"21082\",\"end\":\"21456\"},{\"start\":\"21458\",\"end\":\"21660\"},{\"start\":\"21691\",\"end\":\"21850\"},{\"start\":\"21862\",\"end\":\"22433\"},{\"start\":\"22435\",\"end\":\"22918\"},{\"start\":\"22920\",\"end\":\"23694\"},{\"start\":\"23696\",\"end\":\"24852\"},{\"start\":\"24867\",\"end\":\"25674\"}]", "formula": "[{\"start\":\"10732\",\"end\":\"10822\",\"attributes\":{\"id\":\"formula_0\"}},{\"start\":\"10964\",\"end\":\"11058\",\"attributes\":{\"id\":\"formula_1\"}},{\"start\":\"20903\",\"end\":\"21017\",\"attributes\":{\"id\":\"formula_2\"}},{\"start\":\"21661\",\"end\":\"21690\",\"attributes\":{\"id\":\"formula_3\"}}]", "table_ref": "[{\"start\":\"16262\",\"end\":\"16269\",\"attributes\":{\"ref_id\":\"tab_4\"}},{\"start\":\"19063\",\"end\":\"19070\",\"attributes\":{\"ref_id\":\"tab_4\"}},{\"start\":\"21907\",\"end\":\"21922\"},{\"start\":\"22820\",\"end\":\"22827\"},{\"start\":\"22954\",\"end\":\"22961\"}]", "section_header": "[{\"start\":\"1288\",\"end\":\"1300\",\"attributes\":{\"n\":\"1.\"}},{\"start\":\"5448\",\"end\":\"5460\",\"attributes\":{\"n\":\"2.\"}},{\"start\":\"8589\",\"end\":\"8604\",\"attributes\":{\"n\":\"3.\"}},{\"start\":\"8607\",\"end\":\"8624\",\"attributes\":{\"n\":\"3.1.\"}},{\"start\":\"13381\",\"end\":\"13405\",\"attributes\":{\"n\":\"3.2.\"}},{\"start\":\"14727\",\"end\":\"14763\",\"attributes\":{\"n\":\"3.3.\"}},{\"start\":\"16521\",\"end\":\"16532\",\"attributes\":{\"n\":\"4.\"}},{\"start\":\"16535\",\"end\":\"16543\",\"attributes\":{\"n\":\"4.1.\"}},{\"start\":\"19392\",\"end\":\"19414\",\"attributes\":{\"n\":\"4.2.\"}},{\"start\":\"20298\",\"end\":\"20316\",\"attributes\":{\"n\":\"4.3.\"}},{\"start\":\"21853\",\"end\":\"21860\",\"attributes\":{\"n\":\"4.4.\"}},{\"start\":\"24855\",\"end\":\"24865\",\"attributes\":{\"n\":\"5.\"}},{\"start\":\"25676\",\"end\":\"25686\"},{\"start\":\"26050\",\"end\":\"26060\"},{\"start\":\"26257\",\"end\":\"26267\"},{\"start\":\"26552\",\"end\":\"26562\"},{\"start\":\"26776\",\"end\":\"26786\"},{\"start\":\"26842\",\"end\":\"26852\"},{\"start\":\"26968\",\"end\":\"26978\"},{\"start\":\"27122\",\"end\":\"27132\"},{\"start\":\"28721\",\"end\":\"28730\"}]", "table": "[{\"start\":\"27713\",\"end\":\"28131\"},{\"start\":\"28211\",\"end\":\"28719\"},{\"start\":\"28864\",\"end\":\"29996\"}]", "figure_caption": "[{\"start\":\"25688\",\"end\":\"26048\"},{\"start\":\"26062\",\"end\":\"26255\"},{\"start\":\"26269\",\"end\":\"26550\"},{\"start\":\"26564\",\"end\":\"26774\"},{\"start\":\"26788\",\"end\":\"26840\"},{\"start\":\"26854\",\"end\":\"26966\"},{\"start\":\"26980\",\"end\":\"27120\"},{\"start\":\"27134\",\"end\":\"27260\"},{\"start\":\"27263\",\"end\":\"27579\"},{\"start\":\"27582\",\"end\":\"27713\"},{\"start\":\"28134\",\"end\":\"28211\"},{\"start\":\"28732\",\"end\":\"28778\"},{\"start\":\"28781\",\"end\":\"28864\"}]", "figure_ref": "[{\"start\":\"1854\",\"end\":\"1862\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"2206\",\"end\":\"2218\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"2306\",\"end\":\"2318\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"3269\",\"end\":\"3277\",\"attributes\":{\"ref_id\":\"fig_2\"}},{\"start\":\"8130\",\"end\":\"8138\",\"attributes\":{\"ref_id\":\"fig_4\"}},{\"start\":\"9565\",\"end\":\"9573\",\"attributes\":{\"ref_id\":\"fig_4\"}},{\"start\":\"9625\",\"end\":\"9636\",\"attributes\":{\"ref_id\":\"fig_5\"}},{\"start\":\"9702\",\"end\":\"9710\",\"attributes\":{\"ref_id\":\"fig_5\"}},{\"start\":\"10621\",\"end\":\"10629\",\"attributes\":{\"ref_id\":\"fig_6\"}},{\"start\":\"10698\",\"end\":\"10707\",\"attributes\":{\"ref_id\":\"fig_5\"}},{\"start\":\"13021\",\"end\":\"13030\",\"attributes\":{\"ref_id\":\"fig_4\"}},{\"start\":\"13918\",\"end\":\"13926\"},{\"start\":\"14929\",\"end\":\"14937\"},{\"start\":\"16085\",\"end\":\"16093\",\"attributes\":{\"ref_id\":\"fig_6\"}},{\"start\":\"22367\",\"end\":\"22377\",\"attributes\":{\"ref_id\":\"fig_9\"}},{\"start\":\"22379\",\"end\":\"22394\",\"attributes\":{\"ref_id\":\"fig_10\"}},{\"start\":\"22966\",\"end\":\"22974\",\"attributes\":{\"ref_id\":\"fig_10\"}},{\"start\":\"23713\",\"end\":\"23721\",\"attributes\":{\"ref_id\":\"fig_11\"}},{\"start\":\"24299\",\"end\":\"24307\",\"attributes\":{\"ref_id\":\"fig_9\"}}]", "bib_author_first_name": "[{\"start\":\"30087\",\"end\":\"30092\"},{\"start\":\"30102\",\"end\":\"30110\"},{\"start\":\"30119\",\"end\":\"30126\"},{\"start\":\"30137\",\"end\":\"30144\"},{\"start\":\"30145\",\"end\":\"30148\"},{\"start\":\"30156\",\"end\":\"30164\"},{\"start\":\"30572\",\"end\":\"30577\"},{\"start\":\"30585\",\"end\":\"30589\"},{\"start\":\"30597\",\"end\":\"30603\"},{\"start\":\"30615\",\"end\":\"30620\"},{\"start\":\"30632\",\"end\":\"30638\"},{\"start\":\"30649\",\"end\":\"30654\"},{\"start\":\"30664\",\"end\":\"30673\"},{\"start\":\"30681\",\"end\":\"30688\"},{\"start\":\"31119\",\"end\":\"31126\"},{\"start\":\"31132\",\"end\":\"31137\"},{\"start\":\"31146\",\"end\":\"31151\"},{\"start\":\"31522\",\"end\":\"31531\"},{\"start\":\"31539\",\"end\":\"31540\"},{\"start\":\"31924\",\"end\":\"31929\"},{\"start\":\"31934\",\"end\":\"31938\"},{\"start\":\"31944\",\"end\":\"31947\"},{\"start\":\"31954\",\"end\":\"31962\"},{\"start\":\"32418\",\"end\":\"32423\"},{\"start\":\"32435\",\"end\":\"32437\"},{\"start\":\"32444\",\"end\":\"32451\"},{\"start\":\"32823\",\"end\":\"32829\"},{\"start\":\"32836\",\"end\":\"32846\"},{\"start\":\"33196\",\"end\":\"33204\"},{\"start\":\"33218\",\"end\":\"33225\"},{\"start\":\"33236\",\"end\":\"33245\"},{\"start\":\"33256\",\"end\":\"33262\"},{\"start\":\"33660\",\"end\":\"33673\"},{\"start\":\"33684\",\"end\":\"33693\"},{\"start\":\"33701\",\"end\":\"33705\"},{\"start\":\"33720\",\"end\":\"33725\"},{\"start\":\"33735\",\"end\":\"33743\"},{\"start\":\"34132\",\"end\":\"34136\"},{\"start\":\"34143\",\"end\":\"34146\"},{\"start\":\"34153\",\"end\":\"34159\"},{\"start\":\"34522\",\"end\":\"34529\"},{\"start\":\"34540\",\"end\":\"34543\"},{\"start\":\"34847\",\"end\":\"34854\"},{\"start\":\"34870\",\"end\":\"34876\"},{\"start\":\"34892\",\"end\":\"34898\"},{\"start\":\"34906\",\"end\":\"34912\"},{\"start\":\"34931\",\"end\":\"34935\"},{\"start\":\"35279\",\"end\":\"35285\"},{\"start\":\"35292\",\"end\":\"35298\"},{\"start\":\"35685\",\"end\":\"35692\"},{\"start\":\"35699\",\"end\":\"35703\"},{\"start\":\"35711\",\"end\":\"35715\"},{\"start\":\"35727\",\"end\":\"35735\"},{\"start\":\"35741\",\"end\":\"35744\"},{\"start\":\"35745\",\"end\":\"35746\"},{\"start\":\"35754\",\"end\":\"35760\"},{\"start\":\"35770\",\"end\":\"35776\"},{\"start\":\"35783\",\"end\":\"35791\"},{\"start\":\"35803\",\"end\":\"35807\"},{\"start\":\"35815\",\"end\":\"35823\"},{\"start\":\"36311\",\"end\":\"36319\"},{\"start\":\"36325\",\"end\":\"36331\"},{\"start\":\"36337\",\"end\":\"36343\"},{\"start\":\"36351\",\"end\":\"36357\"},{\"start\":\"36358\",\"end\":\"36359\"},{\"start\":\"36802\",\"end\":\"36810\"},{\"start\":\"36829\",\"end\":\"36834\"},{\"start\":\"37196\",\"end\":\"37200\"},{\"start\":\"37213\",\"end\":\"37217\"},{\"start\":\"37229\",\"end\":\"37237\"},{\"start\":\"37238\",\"end\":\"37239\"},{\"start\":\"37571\",\"end\":\"37579\"},{\"start\":\"37585\",\"end\":\"37590\"},{\"start\":\"37598\",\"end\":\"37602\"},{\"start\":\"37986\",\"end\":\"37994\"},{\"start\":\"38000\",\"end\":\"38007\"},{\"start\":\"38015\",\"end\":\"38020\"},{\"start\":\"38031\",\"end\":\"38036\"},{\"start\":\"38043\",\"end\":\"38049\"},{\"start\":\"38058\",\"end\":\"38062\"},{\"start\":\"38072\",\"end\":\"38077\"},{\"start\":\"38086\",\"end\":\"38096\"},{\"start\":\"38452\",\"end\":\"38460\"},{\"start\":\"38467\",\"end\":\"38471\"},{\"start\":\"38483\",\"end\":\"38489\"},{\"start\":\"38933\",\"end\":\"38936\"},{\"start\":\"38944\",\"end\":\"38951\"},{\"start\":\"39268\",\"end\":\"39271\"},{\"start\":\"39279\",\"end\":\"39286\"},{\"start\":\"39297\",\"end\":\"39305\"},{\"start\":\"39601\",\"end\":\"39605\"},{\"start\":\"39613\",\"end\":\"39614\"},{\"start\":\"39890\",\"end\":\"39900\"},{\"start\":\"39905\",\"end\":\"39912\"},{\"start\":\"39920\",\"end\":\"39921\"},{\"start\":\"40219\",\"end\":\"40223\"},{\"start\":\"40236\",\"end\":\"40241\"},{\"start\":\"40251\",\"end\":\"40260\"},{\"start\":\"40768\",\"end\":\"40775\"},{\"start\":\"40782\",\"end\":\"40791\"},{\"start\":\"40797\",\"end\":\"40804\"},{\"start\":\"40810\",\"end\":\"40819\"},{\"start\":\"41188\",\"end\":\"41192\"},{\"start\":\"41201\",\"end\":\"41204\"},{\"start\":\"41212\",\"end\":\"41221\"},{\"start\":\"41229\",\"end\":\"41233\"},{\"start\":\"41241\",\"end\":\"41246\"},{\"start\":\"41257\",\"end\":\"41264\"},{\"start\":\"41273\",\"end\":\"41279\"},{\"start\":\"41474\",\"end\":\"41481\"},{\"start\":\"41487\",\"end\":\"41491\"},{\"start\":\"41816\",\"end\":\"41819\"},{\"start\":\"41820\",\"end\":\"41825\"},{\"start\":\"41832\",\"end\":\"41841\"},{\"start\":\"41847\",\"end\":\"41854\"},{\"start\":\"41861\",\"end\":\"41868\"},{\"start\":\"42083\",\"end\":\"42084\"},{\"start\":\"42091\",\"end\":\"42095\"},{\"start\":\"42381\",\"end\":\"42382\"},{\"start\":\"42389\",\"end\":\"42393\"},{\"start\":\"42666\",\"end\":\"42672\"},{\"start\":\"42681\",\"end\":\"42688\"},{\"start\":\"42698\",\"end\":\"42702\"},{\"start\":\"42713\",\"end\":\"42716\"},{\"start\":\"43174\",\"end\":\"43181\"},{\"start\":\"43196\",\"end\":\"43200\"},{\"start\":\"43205\",\"end\":\"43209\"},{\"start\":\"43551\",\"end\":\"43555\"},{\"start\":\"43569\",\"end\":\"43576\"},{\"start\":\"43586\",\"end\":\"43592\"},{\"start\":\"44026\",\"end\":\"44034\"},{\"start\":\"44050\",\"end\":\"44059\"},{\"start\":\"44070\",\"end\":\"44079\"},{\"start\":\"44456\",\"end\":\"44461\"},{\"start\":\"44472\",\"end\":\"44478\"},{\"start\":\"44748\",\"end\":\"44749\"},{\"start\":\"44759\",\"end\":\"44765\"},{\"start\":\"45030\",\"end\":\"45035\"},{\"start\":\"45300\",\"end\":\"45305\"},{\"start\":\"45313\",\"end\":\"45319\"},{\"start\":\"45327\",\"end\":\"45332\"},{\"start\":\"45605\",\"end\":\"45613\"},{\"start\":\"45620\",\"end\":\"45622\"},{\"start\":\"45628\",\"end\":\"45636\"},{\"start\":\"45644\",\"end\":\"45649\"},{\"start\":\"45657\",\"end\":\"45664\"},{\"start\":\"45671\",\"end\":\"45675\"},{\"start\":\"45682\",\"end\":\"45686\"},{\"start\":\"45692\",\"end\":\"45698\"},{\"start\":\"45703\",\"end\":\"45710\"},{\"start\":\"45716\",\"end\":\"45724\"},{\"start\":\"46104\",\"end\":\"46108\"},{\"start\":\"46115\",\"end\":\"46119\"},{\"start\":\"46454\",\"end\":\"46457\"},{\"start\":\"46462\",\"end\":\"46466\"},{\"start\":\"46480\",\"end\":\"46489\"},{\"start\":\"46992\",\"end\":\"46999\"},{\"start\":\"47008\",\"end\":\"47015\"},{\"start\":\"47268\",\"end\":\"47274\"},{\"start\":\"47279\",\"end\":\"47286\"},{\"start\":\"47527\",\"end\":\"47533\"},{\"start\":\"47545\",\"end\":\"47551\"},{\"start\":\"47566\",\"end\":\"47573\"},{\"start\":\"47884\",\"end\":\"47888\"},{\"start\":\"47895\",\"end\":\"47902\"},{\"start\":\"47908\",\"end\":\"47909\"},{\"start\":\"47916\",\"end\":\"47923\"}]", "bib_author_last_name": "[{\"start\":\"30093\",\"end\":\"30100\"},{\"start\":\"30111\",\"end\":\"30117\"},{\"start\":\"30127\",\"end\":\"30135\"},{\"start\":\"30149\",\"end\":\"30154\"},{\"start\":\"30165\",\"end\":\"30170\"},{\"start\":\"30578\",\"end\":\"30583\"},{\"start\":\"30590\",\"end\":\"30595\"},{\"start\":\"30604\",\"end\":\"30613\"},{\"start\":\"30621\",\"end\":\"30630\"},{\"start\":\"30639\",\"end\":\"30647\"},{\"start\":\"30655\",\"end\":\"30662\"},{\"start\":\"30674\",\"end\":\"30679\"},{\"start\":\"30689\",\"end\":\"30695\"},{\"start\":\"31127\",\"end\":\"31130\"},{\"start\":\"31138\",\"end\":\"31144\"},{\"start\":\"31152\",\"end\":\"31157\"},{\"start\":\"31532\",\"end\":\"31537\"},{\"start\":\"31541\",\"end\":\"31548\"},{\"start\":\"31550\",\"end\":\"31555\"},{\"start\":\"31930\",\"end\":\"31932\"},{\"start\":\"31939\",\"end\":\"31942\"},{\"start\":\"31948\",\"end\":\"31952\"},{\"start\":\"31963\",\"end\":\"31965\"},{\"start\":\"32424\",\"end\":\"32433\"},{\"start\":\"32438\",\"end\":\"32442\"},{\"start\":\"32452\",\"end\":\"32460\"},{\"start\":\"32830\",\"end\":\"32834\"},{\"start\":\"32847\",\"end\":\"32850\"},{\"start\":\"33205\",\"end\":\"33216\"},{\"start\":\"33226\",\"end\":\"33234\"},{\"start\":\"33246\",\"end\":\"33254\"},{\"start\":\"33263\",\"end\":\"33268\"},{\"start\":\"33674\",\"end\":\"33682\"},{\"start\":\"33694\",\"end\":\"33699\"},{\"start\":\"33706\",\"end\":\"33718\"},{\"start\":\"33726\",\"end\":\"33733\"},{\"start\":\"33744\",\"end\":\"33754\"},{\"start\":\"33756\",\"end\":\"33761\"},{\"start\":\"34137\",\"end\":\"34141\"},{\"start\":\"34147\",\"end\":\"34151\"},{\"start\":\"34160\",\"end\":\"34163\"},{\"start\":\"34530\",\"end\":\"34538\"},{\"start\":\"34544\",\"end\":\"34552\"},{\"start\":\"34855\",\"end\":\"34868\"},{\"start\":\"34877\",\"end\":\"34890\"},{\"start\":\"34899\",\"end\":\"34904\"},{\"start\":\"34913\",\"end\":\"34929\"},{\"start\":\"34936\",\"end\":\"34952\"},{\"start\":\"35286\",\"end\":\"35290\"},{\"start\":\"35299\",\"end\":\"35304\"},{\"start\":\"35693\",\"end\":\"35697\"},{\"start\":\"35704\",\"end\":\"35709\"},{\"start\":\"35716\",\"end\":\"35725\"},{\"start\":\"35736\",\"end\":\"35739\"},{\"start\":\"35747\",\"end\":\"35752\"},{\"start\":\"35761\",\"end\":\"35768\"},{\"start\":\"35777\",\"end\":\"35781\"},{\"start\":\"35792\",\"end\":\"35801\"},{\"start\":\"35808\",\"end\":\"35813\"},{\"start\":\"35824\",\"end\":\"35830\"},{\"start\":\"36320\",\"end\":\"36323\"},{\"start\":\"36332\",\"end\":\"36335\"},{\"start\":\"36344\",\"end\":\"36349\"},{\"start\":\"36360\",\"end\":\"36365\"},{\"start\":\"36811\",\"end\":\"36827\"},{\"start\":\"36835\",\"end\":\"36840\"},{\"start\":\"36842\",\"end\":\"36851\"},{\"start\":\"37201\",\"end\":\"37211\"},{\"start\":\"37218\",\"end\":\"37227\"},{\"start\":\"37240\",\"end\":\"37246\"},{\"start\":\"37580\",\"end\":\"37583\"},{\"start\":\"37591\",\"end\":\"37596\"},{\"start\":\"37603\",\"end\":\"37611\"},{\"start\":\"37995\",\"end\":\"37998\"},{\"start\":\"38008\",\"end\":\"38013\"},{\"start\":\"38021\",\"end\":\"38029\"},{\"start\":\"38037\",\"end\":\"38041\"},{\"start\":\"38050\",\"end\":\"38056\"},{\"start\":\"38063\",\"end\":\"38070\"},{\"start\":\"38078\",\"end\":\"38084\"},{\"start\":\"38097\",\"end\":\"38104\"},{\"start\":\"38461\",\"end\":\"38465\"},{\"start\":\"38472\",\"end\":\"38481\"},{\"start\":\"38490\",\"end\":\"38497\"},{\"start\":\"38937\",\"end\":\"38942\"},{\"start\":\"38952\",\"end\":\"38960\"},{\"start\":\"39272\",\"end\":\"39277\"},{\"start\":\"39287\",\"end\":\"39295\"},{\"start\":\"39306\",\"end\":\"39312\"},{\"start\":\"39606\",\"end\":\"39611\"},{\"start\":\"39615\",\"end\":\"39622\"},{\"start\":\"39624\",\"end\":\"39629\"},{\"start\":\"39901\",\"end\":\"39903\"},{\"start\":\"39913\",\"end\":\"39918\"},{\"start\":\"39922\",\"end\":\"39925\"},{\"start\":\"40224\",\"end\":\"40234\"},{\"start\":\"40242\",\"end\":\"40249\"},{\"start\":\"40261\",\"end\":\"40265\"},{\"start\":\"40776\",\"end\":\"40780\"},{\"start\":\"40792\",\"end\":\"40795\"},{\"start\":\"40805\",\"end\":\"40808\"},{\"start\":\"40820\",\"end\":\"40823\"},{\"start\":\"41193\",\"end\":\"41199\"},{\"start\":\"41205\",\"end\":\"41210\"},{\"start\":\"41222\",\"end\":\"41227\"},{\"start\":\"41234\",\"end\":\"41239\"},{\"start\":\"41247\",\"end\":\"41255\"},{\"start\":\"41265\",\"end\":\"41271\"},{\"start\":\"41280\",\"end\":\"41287\"},{\"start\":\"41482\",\"end\":\"41485\"},{\"start\":\"41492\",\"end\":\"41502\"},{\"start\":\"41504\",\"end\":\"41510\"},{\"start\":\"41826\",\"end\":\"41830\"},{\"start\":\"41842\",\"end\":\"41845\"},{\"start\":\"41855\",\"end\":\"41859\"},{\"start\":\"41869\",\"end\":\"41873\"},{\"start\":\"42085\",\"end\":\"42089\"},{\"start\":\"42096\",\"end\":\"42103\"},{\"start\":\"42105\",\"end\":\"42110\"},{\"start\":\"42383\",\"end\":\"42387\"},{\"start\":\"42394\",\"end\":\"42401\"},{\"start\":\"42403\",\"end\":\"42408\"},{\"start\":\"42673\",\"end\":\"42679\"},{\"start\":\"42689\",\"end\":\"42696\"},{\"start\":\"42703\",\"end\":\"42711\"},{\"start\":\"42717\",\"end\":\"42724\"},{\"start\":\"43182\",\"end\":\"43194\"},{\"start\":\"43201\",\"end\":\"43203\"},{\"start\":\"43210\",\"end\":\"43218\"},{\"start\":\"43220\",\"end\":\"43223\"},{\"start\":\"43556\",\"end\":\"43567\"},{\"start\":\"43577\",\"end\":\"43584\"},{\"start\":\"43593\",\"end\":\"43597\"},{\"start\":\"44035\",\"end\":\"44048\"},{\"start\":\"44060\",\"end\":\"44068\"},{\"start\":\"44080\",\"end\":\"44083\"},{\"start\":\"44085\",\"end\":\"44088\"},{\"start\":\"44462\",\"end\":\"44470\"},{\"start\":\"44479\",\"end\":\"44488\"},{\"start\":\"44750\",\"end\":\"44757\"},{\"start\":\"44766\",\"end\":\"44771\"},{\"start\":\"44773\",\"end\":\"44776\"},{\"start\":\"45036\",\"end\":\"45045\"},{\"start\":\"45306\",\"end\":\"45311\"},{\"start\":\"45320\",\"end\":\"45325\"},{\"start\":\"45333\",\"end\":\"45339\"},{\"start\":\"45614\",\"end\":\"45618\"},{\"start\":\"45623\",\"end\":\"45626\"},{\"start\":\"45637\",\"end\":\"45642\"},{\"start\":\"45650\",\"end\":\"45655\"},{\"start\":\"45665\",\"end\":\"45669\"},{\"start\":\"45676\",\"end\":\"45680\"},{\"start\":\"45687\",\"end\":\"45690\"},{\"start\":\"45699\",\"end\":\"45701\"},{\"start\":\"45711\",\"end\":\"45714\"},{\"start\":\"45725\",\"end\":\"45729\"},{\"start\":\"46109\",\"end\":\"46113\"},{\"start\":\"46120\",\"end\":\"46125\"},{\"start\":\"46458\",\"end\":\"46460\"},{\"start\":\"46467\",\"end\":\"46478\"},{\"start\":\"46490\",\"end\":\"46499\"},{\"start\":\"47000\",\"end\":\"47006\"},{\"start\":\"47016\",\"end\":\"47024\"},{\"start\":\"47275\",\"end\":\"47277\"},{\"start\":\"47287\",\"end\":\"47293\"},{\"start\":\"47534\",\"end\":\"47543\"},{\"start\":\"47552\",\"end\":\"47564\"},{\"start\":\"47574\",\"end\":\"47586\"},{\"start\":\"47889\",\"end\":\"47893\"},{\"start\":\"47903\",\"end\":\"47906\"},{\"start\":\"47910\",\"end\":\"47914\"},{\"start\":\"47924\",\"end\":\"47931\"},{\"start\":\"47933\",\"end\":\"47938\"}]", "bib_entry": "[{\"start\":\"29998\",\"end\":\"30487\",\"attributes\":{\"matched_paper_id\":\"14160588\",\"id\":\"b0\"}},{\"start\":\"30489\",\"end\":\"31046\",\"attributes\":{\"matched_paper_id\":\"2687538\",\"id\":\"b1\"}},{\"start\":\"31048\",\"end\":\"31408\",\"attributes\":{\"matched_paper_id\":\"16417736\",\"id\":\"b2\"}},{\"start\":\"31410\",\"end\":\"31849\",\"attributes\":{\"matched_paper_id\":\"46899325\",\"id\":\"b3\"}},{\"start\":\"31851\",\"end\":\"32358\",\"attributes\":{\"matched_paper_id\":\"198919567\",\"id\":\"b4\"}},{\"start\":\"32360\",\"end\":\"32707\",\"attributes\":{\"matched_paper_id\":\"53068564\",\"id\":\"b5\"}},{\"start\":\"32709\",\"end\":\"33137\",\"attributes\":{\"matched_paper_id\":\"17082256\",\"id\":\"b6\"}},{\"start\":\"33139\",\"end\":\"33587\",\"attributes\":{\"matched_paper_id\":\"15349589\",\"id\":\"b7\"}},{\"start\":\"33589\",\"end\":\"34077\",\"attributes\":{\"matched_paper_id\":\"15898368\",\"id\":\"b8\"}},{\"start\":\"34079\",\"end\":\"34472\",\"attributes\":{\"matched_paper_id\":\"14008455\",\"id\":\"b9\"}},{\"start\":\"34474\",\"end\":\"34774\",\"attributes\":{\"matched_paper_id\":\"9751504\",\"id\":\"b10\"}},{\"start\":\"34776\",\"end\":\"35208\",\"attributes\":{\"id\":\"b11\",\"doi\":\"arXiv:1704.06857\"}},{\"start\":\"35210\",\"end\":\"35597\",\"attributes\":{\"matched_paper_id\":\"3094482\",\"id\":\"b12\"}},{\"start\":\"35599\",\"end\":\"36236\",\"attributes\":{\"matched_paper_id\":\"61807685\",\"id\":\"b13\"}},{\"start\":\"36238\",\"end\":\"36704\",\"attributes\":{\"matched_paper_id\":\"13684145\",\"id\":\"b14\"}},{\"start\":\"36706\",\"end\":\"37129\",\"attributes\":{\"matched_paper_id\":\"202779027\",\"id\":\"b15\"}},{\"start\":\"37131\",\"end\":\"37500\",\"attributes\":{\"matched_paper_id\":\"195908774\",\"id\":\"b16\"}},{\"start\":\"37502\",\"end\":\"37941\",\"attributes\":{\"matched_paper_id\":\"206771220\",\"id\":\"b17\"}},{\"start\":\"37943\",\"end\":\"38394\",\"attributes\":{\"matched_paper_id\":\"14113767\",\"id\":\"b18\"}},{\"start\":\"38396\",\"end\":\"38855\",\"attributes\":{\"matched_paper_id\":\"1629541\",\"id\":\"b19\"}},{\"start\":\"38857\",\"end\":\"39209\",\"attributes\":{\"matched_paper_id\":\"6776486\",\"id\":\"b20\"}},{\"start\":\"39211\",\"end\":\"39559\",\"attributes\":{\"matched_paper_id\":\"206710038\",\"id\":\"b21\"}},{\"start\":\"39561\",\"end\":\"39838\",\"attributes\":{\"matched_paper_id\":\"61153463\",\"id\":\"b22\"}},{\"start\":\"39840\",\"end\":\"40133\",\"attributes\":{\"id\":\"b23\",\"doi\":\"203-2004-3\"}},{\"start\":\"40135\",\"end\":\"40673\",\"attributes\":{\"matched_paper_id\":\"214603516\",\"id\":\"b24\"}},{\"start\":\"40675\",\"end\":\"41184\",\"attributes\":{\"matched_paper_id\":\"52957091\",\"id\":\"b25\"}},{\"start\":\"41186\",\"end\":\"41402\",\"attributes\":{\"id\":\"b26\"}},{\"start\":\"41404\",\"end\":\"41754\",\"attributes\":{\"matched_paper_id\":\"202786778\",\"id\":\"b27\"}},{\"start\":\"41756\",\"end\":\"42040\",\"attributes\":{\"matched_paper_id\":\"67779114\",\"id\":\"b28\"}},{\"start\":\"42042\",\"end\":\"42317\",\"attributes\":{\"matched_paper_id\":\"2519219\",\"id\":\"b29\"}},{\"start\":\"42319\",\"end\":\"42607\",\"attributes\":{\"matched_paper_id\":\"3240829\",\"id\":\"b30\"}},{\"start\":\"42609\",\"end\":\"43092\",\"attributes\":{\"matched_paper_id\":\"206594738\",\"id\":\"b31\"}},{\"start\":\"43094\",\"end\":\"43485\",\"attributes\":{\"matched_paper_id\":\"10328909\",\"id\":\"b32\"}},{\"start\":\"43487\",\"end\":\"43938\",\"attributes\":{\"id\":\"b33\"}},{\"start\":\"43940\",\"end\":\"44386\",\"attributes\":{\"matched_paper_id\":\"15106001\",\"id\":\"b34\"}},{\"start\":\"44388\",\"end\":\"44663\",\"attributes\":{\"id\":\"b35\",\"doi\":\"arXiv:1409.1556\"}},{\"start\":\"44665\",\"end\":\"45028\",\"attributes\":{\"matched_paper_id\":\"11393705\",\"id\":\"b36\"}},{\"start\":\"45030\",\"end\":\"45220\",\"attributes\":{\"id\":\"b37\",\"doi\":\"arXiv:2001.06564\"}},{\"start\":\"45222\",\"end\":\"45534\",\"attributes\":{\"id\":\"b38\",\"doi\":\"arXiv:2003.09393\"}},{\"start\":\"45536\",\"end\":\"46027\",\"attributes\":{\"matched_paper_id\":\"201124533\",\"id\":\"b39\"}},{\"start\":\"46029\",\"end\":\"46336\",\"attributes\":{\"matched_paper_id\":\"37265236\",\"id\":\"b40\"}},{\"start\":\"46338\",\"end\":\"46913\",\"attributes\":{\"matched_paper_id\":\"195503148\",\"id\":\"b41\"}},{\"start\":\"46915\",\"end\":\"47209\",\"attributes\":{\"matched_paper_id\":\"219485579\",\"id\":\"b42\"}},{\"start\":\"47211\",\"end\":\"47450\",\"attributes\":{\"id\":\"b43\",\"doi\":\"arXiv:1511.07122\"}},{\"start\":\"47452\",\"end\":\"47825\",\"attributes\":{\"matched_paper_id\":\"8661252\",\"id\":\"b44\"}},{\"start\":\"47827\",\"end\":\"48301\",\"attributes\":{\"matched_paper_id\":\"44149078\",\"id\":\"b45\"}}]", "bib_title": "[{\"start\":\"29998\",\"end\":\"30085\"},{\"start\":\"30489\",\"end\":\"30570\"},{\"start\":\"31048\",\"end\":\"31117\"},{\"start\":\"31410\",\"end\":\"31520\"},{\"start\":\"31851\",\"end\":\"31922\"},{\"start\":\"32360\",\"end\":\"32416\"},{\"start\":\"32709\",\"end\":\"32821\"},{\"start\":\"33139\",\"end\":\"33194\"},{\"start\":\"33589\",\"end\":\"33658\"},{\"start\":\"34079\",\"end\":\"34130\"},{\"start\":\"34474\",\"end\":\"34520\"},{\"start\":\"35210\",\"end\":\"35277\"},{\"start\":\"35599\",\"end\":\"35683\"},{\"start\":\"36238\",\"end\":\"36309\"},{\"start\":\"36706\",\"end\":\"36800\"},{\"start\":\"37131\",\"end\":\"37194\"},{\"start\":\"37502\",\"end\":\"37569\"},{\"start\":\"37943\",\"end\":\"37984\"},{\"start\":\"38396\",\"end\":\"38450\"},{\"start\":\"38857\",\"end\":\"38931\"},{\"start\":\"39211\",\"end\":\"39266\"},{\"start\":\"39561\",\"end\":\"39599\"},{\"start\":\"40135\",\"end\":\"40217\"},{\"start\":\"40675\",\"end\":\"40766\"},{\"start\":\"41404\",\"end\":\"41472\"},{\"start\":\"41756\",\"end\":\"41814\"},{\"start\":\"42042\",\"end\":\"42081\"},{\"start\":\"42319\",\"end\":\"42379\"},{\"start\":\"42609\",\"end\":\"42664\"},{\"start\":\"43094\",\"end\":\"43172\"},{\"start\":\"43487\",\"end\":\"43549\"},{\"start\":\"43940\",\"end\":\"44024\"},{\"start\":\"44665\",\"end\":\"44746\"},{\"start\":\"45536\",\"end\":\"45603\"},{\"start\":\"46029\",\"end\":\"46102\"},{\"start\":\"46338\",\"end\":\"46452\"},{\"start\":\"46915\",\"end\":\"46990\"},{\"start\":\"47452\",\"end\":\"47525\"},{\"start\":\"47827\",\"end\":\"47882\"}]", "bib_author": "[{\"start\":\"30087\",\"end\":\"30102\"},{\"start\":\"30102\",\"end\":\"30119\"},{\"start\":\"30119\",\"end\":\"30137\"},{\"start\":\"30137\",\"end\":\"30156\"},{\"start\":\"30156\",\"end\":\"30172\"},{\"start\":\"30572\",\"end\":\"30585\"},{\"start\":\"30585\",\"end\":\"30597\"},{\"start\":\"30597\",\"end\":\"30615\"},{\"start\":\"30615\",\"end\":\"30632\"},{\"start\":\"30632\",\"end\":\"30649\"},{\"start\":\"30649\",\"end\":\"30664\"},{\"start\":\"30664\",\"end\":\"30681\"},{\"start\":\"30681\",\"end\":\"30697\"},{\"start\":\"31119\",\"end\":\"31132\"},{\"start\":\"31132\",\"end\":\"31146\"},{\"start\":\"31146\",\"end\":\"31159\"},{\"start\":\"31522\",\"end\":\"31539\"},{\"start\":\"31539\",\"end\":\"31550\"},{\"start\":\"31550\",\"end\":\"31557\"},{\"start\":\"31924\",\"end\":\"31934\"},{\"start\":\"31934\",\"end\":\"31944\"},{\"start\":\"31944\",\"end\":\"31954\"},{\"start\":\"31954\",\"end\":\"31967\"},{\"start\":\"32418\",\"end\":\"32435\"},{\"start\":\"32435\",\"end\":\"32444\"},{\"start\":\"32444\",\"end\":\"32462\"},{\"start\":\"32823\",\"end\":\"32836\"},{\"start\":\"32836\",\"end\":\"32852\"},{\"start\":\"33196\",\"end\":\"33218\"},{\"start\":\"33218\",\"end\":\"33236\"},{\"start\":\"33236\",\"end\":\"33256\"},{\"start\":\"33256\",\"end\":\"33270\"},{\"start\":\"33660\",\"end\":\"33684\"},{\"start\":\"33684\",\"end\":\"33701\"},{\"start\":\"33701\",\"end\":\"33720\"},{\"start\":\"33720\",\"end\":\"33735\"},{\"start\":\"33735\",\"end\":\"33756\"},{\"start\":\"33756\",\"end\":\"33763\"},{\"start\":\"34132\",\"end\":\"34143\"},{\"start\":\"34143\",\"end\":\"34153\"},{\"start\":\"34153\",\"end\":\"34165\"},{\"start\":\"34522\",\"end\":\"34540\"},{\"start\":\"34540\",\"end\":\"34554\"},{\"start\":\"34847\",\"end\":\"34870\"},{\"start\":\"34870\",\"end\":\"34892\"},{\"start\":\"34892\",\"end\":\"34906\"},{\"start\":\"34906\",\"end\":\"34931\"},{\"start\":\"34931\",\"end\":\"34954\"},{\"start\":\"35279\",\"end\":\"35292\"},{\"start\":\"35292\",\"end\":\"35306\"},{\"start\":\"35685\",\"end\":\"35699\"},{\"start\":\"35699\",\"end\":\"35711\"},{\"start\":\"35711\",\"end\":\"35727\"},{\"start\":\"35727\",\"end\":\"35741\"},{\"start\":\"35741\",\"end\":\"35754\"},{\"start\":\"35754\",\"end\":\"35770\"},{\"start\":\"35770\",\"end\":\"35783\"},{\"start\":\"35783\",\"end\":\"35803\"},{\"start\":\"35803\",\"end\":\"35815\"},{\"start\":\"35815\",\"end\":\"35832\"},{\"start\":\"36311\",\"end\":\"36325\"},{\"start\":\"36325\",\"end\":\"36337\"},{\"start\":\"36337\",\"end\":\"36351\"},{\"start\":\"36351\",\"end\":\"36367\"},{\"start\":\"36802\",\"end\":\"36829\"},{\"start\":\"36829\",\"end\":\"36842\"},{\"start\":\"36842\",\"end\":\"36853\"},{\"start\":\"37196\",\"end\":\"37213\"},{\"start\":\"37213\",\"end\":\"37229\"},{\"start\":\"37229\",\"end\":\"37248\"},{\"start\":\"37571\",\"end\":\"37585\"},{\"start\":\"37585\",\"end\":\"37598\"},{\"start\":\"37598\",\"end\":\"37613\"},{\"start\":\"37986\",\"end\":\"38000\"},{\"start\":\"38000\",\"end\":\"38015\"},{\"start\":\"38015\",\"end\":\"38031\"},{\"start\":\"38031\",\"end\":\"38043\"},{\"start\":\"38043\",\"end\":\"38058\"},{\"start\":\"38058\",\"end\":\"38072\"},{\"start\":\"38072\",\"end\":\"38086\"},{\"start\":\"38086\",\"end\":\"38106\"},{\"start\":\"38452\",\"end\":\"38467\"},{\"start\":\"38467\",\"end\":\"38483\"},{\"start\":\"38483\",\"end\":\"38499\"},{\"start\":\"38933\",\"end\":\"38944\"},{\"start\":\"38944\",\"end\":\"38962\"},{\"start\":\"39268\",\"end\":\"39279\"},{\"start\":\"39279\",\"end\":\"39297\"},{\"start\":\"39297\",\"end\":\"39314\"},{\"start\":\"39601\",\"end\":\"39613\"},{\"start\":\"39613\",\"end\":\"39624\"},{\"start\":\"39624\",\"end\":\"39631\"},{\"start\":\"39890\",\"end\":\"39905\"},{\"start\":\"39905\",\"end\":\"39920\"},{\"start\":\"39920\",\"end\":\"39927\"},{\"start\":\"40219\",\"end\":\"40236\"},{\"start\":\"40236\",\"end\":\"40251\"},{\"start\":\"40251\",\"end\":\"40267\"},{\"start\":\"40768\",\"end\":\"40782\"},{\"start\":\"40782\",\"end\":\"40797\"},{\"start\":\"40797\",\"end\":\"40810\"},{\"start\":\"40810\",\"end\":\"40825\"},{\"start\":\"41188\",\"end\":\"41201\"},{\"start\":\"41201\",\"end\":\"41212\"},{\"start\":\"41212\",\"end\":\"41229\"},{\"start\":\"41229\",\"end\":\"41241\"},{\"start\":\"41241\",\"end\":\"41257\"},{\"start\":\"41257\",\"end\":\"41273\"},{\"start\":\"41273\",\"end\":\"41289\"},{\"start\":\"41474\",\"end\":\"41487\"},{\"start\":\"41487\",\"end\":\"41504\"},{\"start\":\"41504\",\"end\":\"41512\"},{\"start\":\"41816\",\"end\":\"41832\"},{\"start\":\"41832\",\"end\":\"41847\"},{\"start\":\"41847\",\"end\":\"41861\"},{\"start\":\"41861\",\"end\":\"41875\"},{\"start\":\"42083\",\"end\":\"42091\"},{\"start\":\"42091\",\"end\":\"42105\"},{\"start\":\"42105\",\"end\":\"42112\"},{\"start\":\"42381\",\"end\":\"42389\"},{\"start\":\"42389\",\"end\":\"42403\"},{\"start\":\"42403\",\"end\":\"42410\"},{\"start\":\"42666\",\"end\":\"42681\"},{\"start\":\"42681\",\"end\":\"42698\"},{\"start\":\"42698\",\"end\":\"42713\"},{\"start\":\"42713\",\"end\":\"42726\"},{\"start\":\"43174\",\"end\":\"43196\"},{\"start\":\"43196\",\"end\":\"43205\"},{\"start\":\"43205\",\"end\":\"43220\"},{\"start\":\"43220\",\"end\":\"43225\"},{\"start\":\"43551\",\"end\":\"43569\"},{\"start\":\"43569\",\"end\":\"43586\"},{\"start\":\"43586\",\"end\":\"43599\"},{\"start\":\"44026\",\"end\":\"44050\"},{\"start\":\"44050\",\"end\":\"44070\"},{\"start\":\"44070\",\"end\":\"44085\"},{\"start\":\"44085\",\"end\":\"44090\"},{\"start\":\"44456\",\"end\":\"44472\"},{\"start\":\"44472\",\"end\":\"44490\"},{\"start\":\"44748\",\"end\":\"44759\"},{\"start\":\"44759\",\"end\":\"44773\"},{\"start\":\"44773\",\"end\":\"44778\"},{\"start\":\"45030\",\"end\":\"45047\"},{\"start\":\"45300\",\"end\":\"45313\"},{\"start\":\"45313\",\"end\":\"45327\"},{\"start\":\"45327\",\"end\":\"45341\"},{\"start\":\"45605\",\"end\":\"45620\"},{\"start\":\"45620\",\"end\":\"45628\"},{\"start\":\"45628\",\"end\":\"45644\"},{\"start\":\"45644\",\"end\":\"45657\"},{\"start\":\"45657\",\"end\":\"45671\"},{\"start\":\"45671\",\"end\":\"45682\"},{\"start\":\"45682\",\"end\":\"45692\"},{\"start\":\"45692\",\"end\":\"45703\"},{\"start\":\"45703\",\"end\":\"45716\"},{\"start\":\"45716\",\"end\":\"45731\"},{\"start\":\"46104\",\"end\":\"46115\"},{\"start\":\"46115\",\"end\":\"46127\"},{\"start\":\"46454\",\"end\":\"46462\"},{\"start\":\"46462\",\"end\":\"46480\"},{\"start\":\"46480\",\"end\":\"46501\"},{\"start\":\"46992\",\"end\":\"47008\"},{\"start\":\"47008\",\"end\":\"47026\"},{\"start\":\"47268\",\"end\":\"47279\"},{\"start\":\"47279\",\"end\":\"47295\"},{\"start\":\"47527\",\"end\":\"47545\"},{\"start\":\"47545\",\"end\":\"47566\"},{\"start\":\"47566\",\"end\":\"47588\"},{\"start\":\"47884\",\"end\":\"47895\"},{\"start\":\"47895\",\"end\":\"47908\"},{\"start\":\"47908\",\"end\":\"47916\"},{\"start\":\"47916\",\"end\":\"47933\"},{\"start\":\"47933\",\"end\":\"47940\"}]", "bib_venue": "[{\"start\":\"30172\",\"end\":\"30227\"},{\"start\":\"30697\",\"end\":\"30753\"},{\"start\":\"31159\",\"end\":\"31203\"},{\"start\":\"31557\",\"end\":\"31612\"},{\"start\":\"31967\",\"end\":\"32054\"},{\"start\":\"32462\",\"end\":\"32517\"},{\"start\":\"32852\",\"end\":\"32907\"},{\"start\":\"33270\",\"end\":\"33326\"},{\"start\":\"33763\",\"end\":\"33818\"},{\"start\":\"34165\",\"end\":\"34253\"},{\"start\":\"34554\",\"end\":\"34609\"},{\"start\":\"34776\",\"end\":\"34845\"},{\"start\":\"35306\",\"end\":\"35364\"},{\"start\":\"35832\",\"end\":\"35898\"},{\"start\":\"36367\",\"end\":\"36431\"},{\"start\":\"36853\",\"end\":\"36902\"},{\"start\":\"37248\",\"end\":\"37297\"},{\"start\":\"37613\",\"end\":\"37680\"},{\"start\":\"38106\",\"end\":\"38144\"},{\"start\":\"38499\",\"end\":\"38576\"},{\"start\":\"38962\",\"end\":\"39002\"},{\"start\":\"39314\",\"end\":\"39369\"},{\"start\":\"39631\",\"end\":\"39686\"},{\"start\":\"39840\",\"end\":\"39888\"},{\"start\":\"40267\",\"end\":\"40353\"},{\"start\":\"40825\",\"end\":\"40889\"},{\"start\":\"41512\",\"end\":\"41561\"},{\"start\":\"41875\",\"end\":\"41883\"},{\"start\":\"42112\",\"end\":\"42156\"},{\"start\":\"42410\",\"end\":\"42448\"},{\"start\":\"42726\",\"end\":\"42803\"},{\"start\":\"43225\",\"end\":\"43274\"},{\"start\":\"43599\",\"end\":\"43685\"},{\"start\":\"44090\",\"end\":\"44145\"},{\"start\":\"44388\",\"end\":\"44454\"},{\"start\":\"44778\",\"end\":\"44833\"},{\"start\":\"45063\",\"end\":\"45105\"},{\"start\":\"45222\",\"end\":\"45298\"},{\"start\":\"45731\",\"end\":\"45748\"},{\"start\":\"46127\",\"end\":\"46166\"},{\"start\":\"46501\",\"end\":\"46578\"},{\"start\":\"47026\",\"end\":\"47056\"},{\"start\":\"47211\",\"end\":\"47266\"},{\"start\":\"47588\",\"end\":\"47621\"},{\"start\":\"47940\",\"end\":\"48017\"},{\"start\":\"32056\",\"end\":\"32128\"},{\"start\":\"33328\",\"end\":\"33369\"},{\"start\":\"35366\",\"end\":\"35409\"},{\"start\":\"36433\",\"end\":\"36482\"},{\"start\":\"37682\",\"end\":\"37734\"},{\"start\":\"38578\",\"end\":\"38640\"},{\"start\":\"39004\",\"end\":\"39038\"},{\"start\":\"40355\",\"end\":\"40426\"},{\"start\":\"40891\",\"end\":\"40940\"},{\"start\":\"42805\",\"end\":\"42867\"},{\"start\":\"46580\",\"end\":\"46642\"},{\"start\":\"48019\",\"end\":\"48081\"}]"}}}, "year": 2023, "month": 12, "day": 17}