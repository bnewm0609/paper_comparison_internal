{"id": 245865755, "updated": "2022-02-24 04:56:33.721", "metadata": {"title": "Two Will Do: CNN With Asymmetric Loss, Self-Learning Label Correction, and Hand-Crafted Features for Imbalanced Multi-Label ECG Data Classification", "authors": "[{\"first\":\"Cristina\",\"last\":\"V\u00e1zquez\",\"middle\":[\"Gallego\"]},{\"first\":\"Alexander\",\"last\":\"Breuss\",\"middle\":[]},{\"first\":\"Oriella\",\"last\":\"Gnarra\",\"middle\":[]},{\"first\":\"Julian\",\"last\":\"Portmann\",\"middle\":[]},{\"first\":\"Giulia\",\"last\":\"Poian\",\"middle\":[\"Da\"]}]", "venue": "2021 Computing in Cardiology (CinC)", "journal": "2021 Computing in Cardiology (CinC)", "publication_date": {"year": 2021, "month": null, "day": null}, "abstract": "In this work, we present a machine learning approach that is able to classify 30 cardiac abnormalities from an arbitrary number of electrocardiogram (ECG) leads. Features extracted by a deep convolutional neural network are combined with hand-crafted features (demographic, morphological, and heart rate variability metrics) and fed into a multilayer perceptron. We employ an Asymmetric Loss (ASL) function, which enables the model to focus on hard but under-represented samples. To mitigate the issue of ground-truth mislabeling and to provide robustness, we investigate the use of a self-learning label correction method that iteratively estimates correct labels during training. Our team SMS+1 placed 7 on the unseen test set, with an overall challenge score of 0.51, and 0.52, 0.45, 0.50, 0.50, and 0.49 for twelve-, six-, four-, three-, and two-lead, respectively. Our model maintains similar diagnostic potential on both standard twelve-lead ECGs and reduced-lead ECGs.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/cinc/VazquezBGPP21", "doi": "10.23919/cinc53138.2021.9662741"}}, "content": {"source": {"pdf_hash": "0aea9cf35ff6ba4f00aa21179dce52f5217cc988", "pdf_src": "MergedPDFExtraction", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "162fb6552d0e74f3b6fbb5b375ca65a132837393", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/0aea9cf35ff6ba4f00aa21179dce52f5217cc988.txt", "contents": "\nTwo Will Do: CNN With Asymmetric Loss, Self-Learning Label Correction, and Hand-Crafted Features for Imbalanced Multi-Label ECG Data Classification\n\n\nCristina Gallego V\u00e1zquez \nDepartment of Health Sciences and Technology\nSensory-Motor Systems (SMS) Lab\nETH Zurich\n\n\nAlexander Breuss \nDepartment of Health Sciences and Technology\nSensory-Motor Systems (SMS) Lab\nETH Zurich\n\n\nOriella Gnarra \nDepartment of Health Sciences and Technology\nSensory-Motor Systems (SMS) Lab\nETH Zurich\n\n\nSleep-Wake-Epilepsy-Center\nDepartment of Neurology\nBern University Hospital (Inselspital)\n\n\nJulian Portmann \nDepartment of Computer Science\nETH Zurich\n\n\nGiulia Da Poian \nDepartment of Health Sciences and Technology\nSensory-Motor Systems (SMS) Lab\nETH Zurich\n\n\nTwo Will Do: CNN With Asymmetric Loss, Self-Learning Label Correction, and Hand-Crafted Features for Imbalanced Multi-Label ECG Data Classification\n10.22489/CinC.2021.024\nIn this work, we present a machine learning approach that is able to classify 30 cardiac abnormalities from an arbitrary number of electrocardiogram (ECG) leads. Features extracted by a deep convolutional neural network are combined with hand-crafted features (demographic, morphological, and heart rate variability metrics) and fed into a multilayer perceptron. We employ an Asymmetric Loss (ASL) function, which enables the model to focus on hard but under-represented samples. To mitigate the issue of ground-truth mislabeling and to provide robustness, we investigate the use of a self-learning label correction method that iteratively estimates correct labels during training. Our team SMS+1 placed 7 th on the unseen test set, with an overall challenge score of 0.51, and 0.52, 0.45, 0.50, 0.50, and 0.49 for twelve-, six-, four-, three-, and two-lead, respectively. Our model maintains similar diagnostic potential on both standard twelve-lead ECGs and reduced-lead ECGs.\n\nIntroduction\n\nDetecting cardiac abnormalities as early as possible is a crucial task in which automated electrocardiogram signal interpretation plays an important role. In recent years, Deep Learning (DL) has been widely applied in many areas, including healthcare, and has shown high accuracy in ECG arrhythmia classification [1]. The most successful types of DL models are restricted Boltzmann machines, stacked autoencoder, Convolutional Neural Networks (CNNs), and Deep Belief Networks [2]. Compared to traditional approaches, DL-based approaches can automatically learn informative feature representations [1]. However, it can also be beneficial to incorporate expert knowledge, represented by hand-crafted features [3,4].\n\nAll authors contributed equally to this work.\n\nThe 2020 PhysioNet/CinC Challenge focused on classifying 27 cardiac abnormalities from twelve-lead ECG, the most standard diagnosis screening system for a variety of cardiac arrhythmias [5]. This year's challenge focuses on the ability to achieve similar multi-class classification performance with a reduced set of leads, motivated by the limited accessibility of twelve-lead ECG devices. Most severe diseases occur rarely but are very important to be detected by the model, and high-data quality acquisition including expert annotations are difficult to acquire. Therefore, two of the biggest challenges when applying DL to ECG data are the imbalance and noisy nature of the labels arising from incorrectly labeled recordings [4].\n\n\nMethods\n\nIn this work, we present a deep learning architecture for multi-label classification of 30 ECG findings. Our network combines hand-crafted features ('wide') with ECG features extracted via a neural network ('deep'). For encoding deep features, we employ a deep neural architecture built by interleaving nonlinear convolutional blocks, which allow modeling patterns at different time scales. We employed an Asymmetric Loss (ASL) function, which enables the model to focus on hard, but under-represented, samples. A final set of fully connected layers combine both the 'wide' and 'deep' features to produce multilabel classifications of ECG findings. To mitigate the issue of ground-truth mislabeling and to provide robustness, we investigate the use of a self-learning label correction method that does not require a fully correctly labeled dataset, but iteratively estimates corrected labels during training. The model architecture is illustrated in Figure 1.\n\n\nDataset\n\nThe 2021 PhysioNet/CinC Challenge datasets include annotated twelve-lead ECG recordings from six different Figure 1. Architecture of the model: Training data is first resampled before it is passed to a 1D CNN and combined with hand-crafted features. The feature set obtained from the 1D CNN is also used as an input to a label correction phase that iteratively estimates corrected labels during training by identifying prototypes of every class that are likely labeled correctly. The output of the label correction is then combined with the output after the convolution step.\n\nsources [6]. These datasets include over 100,000 twelvelead ECG recordings with over 88,000 ECGs shared publicly as training data. An analysis of the demographic data shows a low percentage of missing data (0.27% for age followed by 0.03% for sex). Age has negative skewness of -0.74 with a mean of 59.23 (std. 18.39). Sex is balanced between males (55%) and females (45%). The durations of the recordings range from a minimum of 5 seconds to a maximum of 30 minutes, but 92% of recordings are 10 seconds long. The datasets have unbalanced classes. For example, sinus rhythm represents 22% of the labels while complete left bundle branch block appears only in 0.16% of the recordings.\n\n\n2.2.\n\nClassification architecture\n\n\nExtraction of hand-crafted ECG features\n\nAs recordings from separate hospitals and devices can have different sampling rates, we first resample each recording to 250 Hz. Then we apply an finite impulse response (FIR) bandpass filter between 3 -45 Hz. We extract a set of features per lead, including morphological features (P and T wave amplitude, PR interval, etc.) [7], heart rate variability features in time, frequency, and non-linear domains (RMSSD, pNN60, spectral power density pertaining to low and high frequency band, T and P wave permutation and approximation entropy, etc.) [8], and a subset of features used by the 2020 PhysioNet Challenge winners [3]. The high prevalence (92%) of ten seconds long recordings influenced the choice of the selected hand-crafted features. We also include demographic features (age and gender) as shown in Table 1. Collectively, these features are concatenated with the learned outputs from the \"Deep\" portion of the model (c.f. chapter 2.2.2). \n\n\nHand-crafted features Demographic\n\nAge, Sex Morphological [7] QRS/P and QRS/T duration PR interval, BPM P and T wave amplitude 2020 PhysioNet Heart rate, RR interval challenge winners [3] P and T wave approximate entropy (median) Heart rate variability HRV time domain (HRV) [8] (14 features) HRV frequency domain (9 features) HRV non linear domain (29 features)\n\n\n1D-CNN\n\nThe deep component of our model consists of a series of convolution operations and two fully connected feedforward networks. The one-dimensional convolution operations are applied to the original ECG waveform segments to extract a latent space representation of the signals. The dimension settings of the layers are listed in Table 2 . The stride and kernel of the max-pooling layers after each convolution are set to four. Batch normalization is also applied after each convolution. A one-dimensional adaptive maxpooling is performed to the output before it is combined with the hand-crafted features for the two fully convolution operations. \n\n\nAsymmetric loss function\n\nA trained model with imbalanced data may make predictions with high precision and low recall, being severely biased towards the more represented classes. In medical applications, where it is important to avoid false negatives, this is an issue. We employed an Asymmetric Loss (ASL) for multi-label classification [9], which enables the model to focus on hard, but under-represented samples, and also deals with potential mislabeled samples. This loss function contains two complementary asymmetric mechanisms that work differently on well-represented and underrepresented samples and dynamically adjust the asymmetry levels throughout the training. The ASL uses two focusing hyperparameters to modify the contribution of easy samples to the loss function (\u03b3 + , \u03b3 \u2212 ). In our work we set \u03b3 + = 1 and \u03b3 \u2212 = 3.\n\n\nImplementation Details\n\nDuring model training, we monitor the average Challenge score and use early stopping when the validation Challenge score stops improving for 4 epochs. This approach is used for both, the first epochs without label correction, and when the label correction phase is performed after the model has been pre-trained. We use an Adam optimizer (\u03b2 1 = 0.9, \u03b2 2 = 0.999 and = 10 \u22129 ) with a learning rate of 0.001. The batch size is set to 10. The complete model consists of 382.412 trainable parameters and it is trained on the 2021 PhysioNet/CinC challenge datasets and no other external data sources.\n\n\nSelf-learning label correction\n\nIn a real-world dataset, most of the \"ground truth annotations\" come from human experts, which are subjective, mistake-prone, and introduce bias in the data. Learning from noisy labels reduces model performance and it is still a challenge in DL. Following the work from [10], we include a self-learning label correction module to our model. This approach doesn't require a fully correctly labeled dataset as it iteratively estimates corrected labels during training. The main idea is to identify prototypes from the set of samples of each class that have a high chance of being correctly labeled. This is done once the model has already been trained with the original noisy dataset, so network features can be extracted from each sample to identify prototypes based on similarity and density measures. Each sample is then compared to the prototypes of each class and a corrected label is assigned if needed.\n\n\nEvaluation\n\nWe evaluate the performance of the proposed method based on the \"challenge score\", as described in [6]. An ablation study is performed to investigate the effect of the ASL, hand-crafted features and, the LC phase added to the 1D-CNN. For this purpose, the dataset is split into train, validation, and test sets (60%, 20%, 20%).\n\n\nResults\n\nThe results of the ablation study aimed at investigating the effect of each of the additional components added to the 1D-CNN are reported in Table. 3. The largest drop in performance occurs when removing the ASL component from the model reducing the challenge score by 14%. Removing the features has a marginal effect on the performance with a 1% drop in the 12, 4, and 2 lead local testings. A small increase in performance can be appreciated for the 6 and 3 lead combinations.\n\nThe label correction phase decreases the performance from 7%, for the 12 lead, up to 14% for the 2 lead.\n\nWhen tested on the hidden validation set, we observe that including the features leads to a small, but consistent increase in performance. The model without label correction achieves a challenge score of 0.57, 0.58, 0.57, 0.56, and 0.57 for twelve, six, four, three, and two-leads, respectively. By adding the label correction the score dropped by 13-11%, a bigger decrease than in the local testing.\n\nFinally, the best performing model on the validation test placed 7th in the challenge when evaluated on the test data, with an overall challenge score of 0.51, and 0.52, 0.45, 0.50, 0.50, and 0.49 for twelve-, six-, four-,three-, and twolead, respectively. On the undisclosed data-set, an overall score of 0.42 would place our method 4th. \n\n\nDiscussion and Conclusion\n\nResults clearly show that the asymmetric loss was most crucial to the performance of our model. We believe this is because the ASL introduces different weights for false positives and false negatives, which remedies the imbalance of positive and negative labels.\n\nThe added hand-crafted features slightly improve the model performance, we believe that this is due to the fact that some features, such as the entropy features, are likely hard to compute for a convolutional network.\n\nIn both, the ablation study and the official submission, there was no improvement in the results when performing the label correction phase. We assume that the reason is that in the original work the labels were much noisier [10], leading to more aggressive label-correction parameters. Additionally, the authors of [10] were dealing with a single-label classification problem, where relabeling was deciding on which class a label belongs to. For the multilabel classification problem considered in this work, the number of possible labels is exponential in the number of classes, making the task of finding a new label much harder, due to the search space being larger. Further investigation is therefore necessary.\n\nTo conclude, the best performance across all leads is achieved by the 1D-CNN in combination with the ASL and the manually handcrafted features. Our model shows a consistent ability in detecting a variety of cardiac abnormalities, on standard 12 lead ECGs as well as on various reduced-lead ECGs. Two will do!\n\nTable 1 .\n1Hand-crafted features complementing the 1D-CNN used in the challenge.\n\nTable 2 .\n2Deep Learning model settings.Layer \nIn \nKernel Stride/Padding Out \nCNN 1 \nleads \n5 \n1/2 \n16 \nCNN 2 \n16 \n5 \n1/2 \n32 \nCNN 3 \n32 \n5 \n1/2 \n64 \nCNN 4 \n64 \n5 \n1/2 \n128 \nCNN 5 \n128 \n5 \n1/2 \n256 \nFC 1 \n256 + feat \n512 \nFC 2 \n512 \n30 \n\n\n\nTable 3 .\n3Local challenge score obtained for the ablation study on the train set, from the full model, model without hand-crafted features and model without label correction.Table 4. Challenge scores for our final selected entry (team SMS+1) using validation on the public training set, scoring on the hidden validation set, and one-time scoring on the hidden test set as well as the ranking on the hidden test set.Challenge Score \nModel \n12 lead 6 lead 4 lead 3 lead 2 lead \nFull \n0.66 \n0.63 \n0.65 \n0.60 \n0.65 \nw/o Feat. \n0.65 \n0.65 \n0.64 \n0.64 \n0.64 \nw/o ASL \n0.52 \n0.52 \n0.52 \n0.51 \n0.51 \nIncluding LC Phase \nFull \n0.59 \n0.53 \n0.53 \n0.54 \n0.51 \nw/o Feat. \n0.59 \n0.53 \n0.53 \n0.54 \n0.51 \n\nLeads Training Validation Test Ranking \n12 \n0.66 \n0.57 0.52 \n6 \n6 \n0.63 \n0.55 0.45 \n16 \n4 \n0.65 \n0.57 0.50 \n7 \n3 \n0.60 \n0.56 0.50 \n8 \n2 \n0.65 \n0.57 0.49 \n8 \n\n\nAcknowledgmentsThis work was partially funded by the Swiss National Science Foundation (grant 193291) and by the European Sleep Foundation through the Majid Foundation. We thank Prof. Dr. Robert Riener, Prof. Dr. med. Claudio L. Bassetti and Dr. Peter Wolf for their support.\nA review on deep learning methods for ECG arrhythmia classification. Expert Systems with Applications. Z Ebrahimi, M Loni, M Daneshtalab, A Gharehbaghi, Ebrahimi Z, Loni M, Daneshtalab M, Gharehbaghi A. A review on deep learning methods for ECG arrhythmia clas- sification. Expert Systems with Applications Sep. 2020;\n\nA novel application of deep learning for single-lead ECG classification. Computers in biology and medicine. S M M Kambhamettu, C Barner, K E , 99S.M. M, Kambhamettu C, Barner KE. A novel application of deep learning for single-lead ECG classification. Com- puters in biology and medicine Aug. 2018;99:53-62.\n\nA wide and deep transformer neural network for 12-lead ECG classification. Computing in Cardiology. A Natarajan, Y Chang, S Mariani, A Rahman, G Boverman, S Vij, J Rubin, Natarajan A, Chang Y, Mariani S, Rahman A, Boverman G, Vij S, Rubin J. A wide and deep transformer neural network for 12-lead ECG classification. Computing in Cardiology Sep. 2020;1-4.\n\nOpportunities and challenges of deep learning methods for electrocardiogram data: A systematic review. S Hong, Y Zhou, J Shang, C Xiao, J Sun, Computers in Biology and Medicine. 122103801Hong S, Zhou Y, Shang J, Xiao C, Sun J. Opportunities and challenges of deep learning methods for electrocardio- gram data: A systematic review. Computers in Biology and Medicine Jul. 2020;122:103801.\n\nClassification of 12-lead ECGs: the Physionet/Computing in Cardiology Challenge 2020. Eap Alday, A Gu, A J Shah, C Robichaux, Aki Wong, C Liu, F Liu, A B Rad, A Elola, S Seyedi, Physiological measurement. 4112124003Alday EAP, Gu A, Shah AJ, Robichaux C, Wong AKI, Liu C, Liu F, Rad AB, Elola A, Seyedi S. Classification of 12-lead ECGs: the Physionet/Computing in Cardiology Challenge 2020. Physiological measurement Dec. 2020; 41(12):124003.\n\nWill two do? varying dimensions in electrocardiography: The Physionet/Computing in Cardiology Challenge 2021. M A Reyna, N Sadr, Eap Alday, A Gu, A J Shah, C Robichaux, A B Rad, A Elola, S Seyedi, S Ansari, Computing in Cardiology. 48Reyna MA, Sadr N, Alday EAP, Gu A, Shah AJ, Robichaux C, Rad AB, Elola A, Seyedi S, Ansari S, et al. Will two do? varying dimensions in electrocardiography: The Phys- ionet/Computing in Cardiology Challenge 2021. Comput- ing in Cardiology 2021;48:1-4.\n\n. K Ravichandran, D Chiasson, K Oyedele, Classification of Electrocardiogram Anomalies. Available at https://cs229.stanford.edu/proj2013/Ravichandran K, Chiasson D, Oyedele K. Classifica- tion of Electrocardiogram Anomalies 2013;Available at https://cs229.stanford.edu/proj2013/.\n\nAn overview of heart rate variability metrics and norms. F Shaffer, J P Ginsberg, Frontiers in public health. 5258Shaffer F, Ginsberg JP. An overview of heart rate variability metrics and norms. Frontiers in public health 2017;5:258.\n\nAsymmetric loss for multi-label classification. E Ben-Baruch, T Ridnik, N Zamir, A Noy, I Friedman, M Protter, L Zelnik-Manor, arXiv preprintBen-Baruch E, Ridnik T, Zamir N, Noy A, Friedman I, Prot- ter M, Zelnik-Manor L. Asymmetric loss for multi-label classification. arXiv preprint arXiv200914119 Sep 2020;.\n\nDeep Self-Learning From Noisy Labels. J Han, P Luo, X Wang, Proceedings of the IEEECVF International Conference on Computer Vision. Han J, Luo P, Wang X. Deep Self-Learning From Noisy Labels. Proceedings of the IEEECVF International Confer- ence on Computer Vision 2019;5138-5147.\n", "annotations": {"author": "[{\"end\":266,\"start\":151},{\"end\":374,\"start\":267},{\"end\":572,\"start\":375},{\"end\":633,\"start\":573},{\"end\":740,\"start\":634}]", "publisher": null, "author_last_name": "[{\"end\":175,\"start\":160},{\"end\":283,\"start\":277},{\"end\":389,\"start\":383},{\"end\":588,\"start\":580},{\"end\":649,\"start\":641}]", "author_first_name": "[{\"end\":159,\"start\":151},{\"end\":276,\"start\":267},{\"end\":382,\"start\":375},{\"end\":579,\"start\":573},{\"end\":640,\"start\":634}]", "author_affiliation": "[{\"end\":265,\"start\":177},{\"end\":373,\"start\":285},{\"end\":479,\"start\":391},{\"end\":571,\"start\":481},{\"end\":632,\"start\":590},{\"end\":739,\"start\":651}]", "title": "[{\"end\":148,\"start\":1},{\"end\":888,\"start\":741}]", "venue": null, "abstract": "[{\"end\":1890,\"start\":912}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2222,\"start\":2219},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2385,\"start\":2382},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2506,\"start\":2503},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2616,\"start\":2613},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2618,\"start\":2616},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":2857,\"start\":2854},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3399,\"start\":3396},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":4971,\"start\":4968},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":6053,\"start\":6050},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":6272,\"start\":6269},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":6347,\"start\":6344},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":6736,\"start\":6733},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":6862,\"start\":6859},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":6953,\"start\":6950},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":8037,\"start\":8034},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":9460,\"start\":9456},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":10210,\"start\":10207},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":12516,\"start\":12512},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":12607,\"start\":12603}]", "figure": "[{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":13395,\"start\":13314},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":13635,\"start\":13396},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":14486,\"start\":13636}]", "paragraph": "[{\"end\":2619,\"start\":1906},{\"end\":2666,\"start\":2621},{\"end\":3400,\"start\":2668},{\"end\":4371,\"start\":3412},{\"end\":4958,\"start\":4383},{\"end\":5644,\"start\":4960},{\"end\":5680,\"start\":5653},{\"end\":6672,\"start\":5724},{\"end\":7037,\"start\":6710},{\"end\":7692,\"start\":7048},{\"end\":8529,\"start\":7721},{\"end\":9151,\"start\":8556},{\"end\":10093,\"start\":9186},{\"end\":10435,\"start\":10108},{\"end\":10925,\"start\":10447},{\"end\":11031,\"start\":10927},{\"end\":11433,\"start\":11033},{\"end\":11774,\"start\":11435},{\"end\":12066,\"start\":11804},{\"end\":12285,\"start\":12068},{\"end\":13003,\"start\":12287},{\"end\":13313,\"start\":13005}]", "formula": null, "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":6540,\"start\":6533},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":7381,\"start\":7374},{\"end\":10594,\"start\":10588}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":1904,\"start\":1892},{\"attributes\":{\"n\":\"2.\"},\"end\":3410,\"start\":3403},{\"attributes\":{\"n\":\"2.1.\"},\"end\":4381,\"start\":4374},{\"end\":5651,\"start\":5647},{\"attributes\":{\"n\":\"2.2.1.\"},\"end\":5722,\"start\":5683},{\"end\":6708,\"start\":6675},{\"attributes\":{\"n\":\"2.2.2.\"},\"end\":7046,\"start\":7040},{\"attributes\":{\"n\":\"2.2.3.\"},\"end\":7719,\"start\":7695},{\"attributes\":{\"n\":\"2.3.\"},\"end\":8554,\"start\":8532},{\"attributes\":{\"n\":\"2.4.\"},\"end\":9184,\"start\":9154},{\"attributes\":{\"n\":\"2.5.\"},\"end\":10106,\"start\":10096},{\"attributes\":{\"n\":\"3.\"},\"end\":10445,\"start\":10438},{\"attributes\":{\"n\":\"4.\"},\"end\":11802,\"start\":11777},{\"end\":13324,\"start\":13315},{\"end\":13406,\"start\":13397},{\"end\":13646,\"start\":13637}]", "table": "[{\"end\":13635,\"start\":13437},{\"end\":14486,\"start\":14053}]", "figure_caption": "[{\"end\":13395,\"start\":13326},{\"end\":13437,\"start\":13408},{\"end\":14053,\"start\":13648}]", "figure_ref": "[{\"end\":4370,\"start\":4362},{\"end\":4498,\"start\":4490}]", "bib_author_first_name": "[{\"end\":14867,\"start\":14866},{\"end\":14879,\"start\":14878},{\"end\":14887,\"start\":14886},{\"end\":14902,\"start\":14901},{\"end\":15191,\"start\":15190},{\"end\":15195,\"start\":15192},{\"end\":15210,\"start\":15209},{\"end\":15220,\"start\":15219},{\"end\":15222,\"start\":15221},{\"end\":15492,\"start\":15491},{\"end\":15505,\"start\":15504},{\"end\":15514,\"start\":15513},{\"end\":15525,\"start\":15524},{\"end\":15535,\"start\":15534},{\"end\":15547,\"start\":15546},{\"end\":15554,\"start\":15553},{\"end\":15852,\"start\":15851},{\"end\":15860,\"start\":15859},{\"end\":15868,\"start\":15867},{\"end\":15877,\"start\":15876},{\"end\":15885,\"start\":15884},{\"end\":16226,\"start\":16223},{\"end\":16235,\"start\":16234},{\"end\":16241,\"start\":16240},{\"end\":16243,\"start\":16242},{\"end\":16251,\"start\":16250},{\"end\":16266,\"start\":16263},{\"end\":16274,\"start\":16273},{\"end\":16281,\"start\":16280},{\"end\":16288,\"start\":16287},{\"end\":16290,\"start\":16289},{\"end\":16297,\"start\":16296},{\"end\":16306,\"start\":16305},{\"end\":16692,\"start\":16691},{\"end\":16694,\"start\":16693},{\"end\":16703,\"start\":16702},{\"end\":16713,\"start\":16710},{\"end\":16722,\"start\":16721},{\"end\":16728,\"start\":16727},{\"end\":16730,\"start\":16729},{\"end\":16738,\"start\":16737},{\"end\":16751,\"start\":16750},{\"end\":16753,\"start\":16752},{\"end\":16760,\"start\":16759},{\"end\":16769,\"start\":16768},{\"end\":16779,\"start\":16778},{\"end\":17071,\"start\":17070},{\"end\":17087,\"start\":17086},{\"end\":17099,\"start\":17098},{\"end\":17407,\"start\":17406},{\"end\":17418,\"start\":17417},{\"end\":17420,\"start\":17419},{\"end\":17633,\"start\":17632},{\"end\":17647,\"start\":17646},{\"end\":17657,\"start\":17656},{\"end\":17666,\"start\":17665},{\"end\":17673,\"start\":17672},{\"end\":17685,\"start\":17684},{\"end\":17696,\"start\":17695},{\"end\":17935,\"start\":17934},{\"end\":17942,\"start\":17941},{\"end\":17949,\"start\":17948}]", "bib_author_last_name": "[{\"end\":14876,\"start\":14868},{\"end\":14884,\"start\":14880},{\"end\":14899,\"start\":14888},{\"end\":14914,\"start\":14903},{\"end\":15207,\"start\":15196},{\"end\":15217,\"start\":15211},{\"end\":15502,\"start\":15493},{\"end\":15511,\"start\":15506},{\"end\":15522,\"start\":15515},{\"end\":15532,\"start\":15526},{\"end\":15544,\"start\":15536},{\"end\":15551,\"start\":15548},{\"end\":15560,\"start\":15555},{\"end\":15857,\"start\":15853},{\"end\":15865,\"start\":15861},{\"end\":15874,\"start\":15869},{\"end\":15882,\"start\":15878},{\"end\":15889,\"start\":15886},{\"end\":16232,\"start\":16227},{\"end\":16238,\"start\":16236},{\"end\":16248,\"start\":16244},{\"end\":16261,\"start\":16252},{\"end\":16271,\"start\":16267},{\"end\":16278,\"start\":16275},{\"end\":16285,\"start\":16282},{\"end\":16294,\"start\":16291},{\"end\":16303,\"start\":16298},{\"end\":16313,\"start\":16307},{\"end\":16700,\"start\":16695},{\"end\":16708,\"start\":16704},{\"end\":16719,\"start\":16714},{\"end\":16725,\"start\":16723},{\"end\":16735,\"start\":16731},{\"end\":16748,\"start\":16739},{\"end\":16757,\"start\":16754},{\"end\":16766,\"start\":16761},{\"end\":16776,\"start\":16770},{\"end\":16786,\"start\":16780},{\"end\":17084,\"start\":17072},{\"end\":17096,\"start\":17088},{\"end\":17107,\"start\":17100},{\"end\":17415,\"start\":17408},{\"end\":17429,\"start\":17421},{\"end\":17644,\"start\":17634},{\"end\":17654,\"start\":17648},{\"end\":17663,\"start\":17658},{\"end\":17670,\"start\":17667},{\"end\":17682,\"start\":17674},{\"end\":17693,\"start\":17686},{\"end\":17709,\"start\":17697},{\"end\":17939,\"start\":17936},{\"end\":17946,\"start\":17943},{\"end\":17954,\"start\":17950}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":15080,\"start\":14763},{\"attributes\":{\"id\":\"b1\"},\"end\":15389,\"start\":15082},{\"attributes\":{\"id\":\"b2\"},\"end\":15746,\"start\":15391},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":209862062},\"end\":16135,\"start\":15748},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":221115394},\"end\":16579,\"start\":16137},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":237624113},\"end\":17066,\"start\":16581},{\"attributes\":{\"id\":\"b6\"},\"end\":17347,\"start\":17068},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":11104601},\"end\":17582,\"start\":17349},{\"attributes\":{\"id\":\"b8\"},\"end\":17894,\"start\":17584},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":199453105},\"end\":18176,\"start\":17896}]", "bib_title": "[{\"end\":15849,\"start\":15748},{\"end\":16221,\"start\":16137},{\"end\":16689,\"start\":16581},{\"end\":17404,\"start\":17349},{\"end\":17932,\"start\":17896}]", "bib_author": "[{\"end\":14878,\"start\":14866},{\"end\":14886,\"start\":14878},{\"end\":14901,\"start\":14886},{\"end\":14916,\"start\":14901},{\"end\":15209,\"start\":15190},{\"end\":15219,\"start\":15209},{\"end\":15225,\"start\":15219},{\"end\":15504,\"start\":15491},{\"end\":15513,\"start\":15504},{\"end\":15524,\"start\":15513},{\"end\":15534,\"start\":15524},{\"end\":15546,\"start\":15534},{\"end\":15553,\"start\":15546},{\"end\":15562,\"start\":15553},{\"end\":15859,\"start\":15851},{\"end\":15867,\"start\":15859},{\"end\":15876,\"start\":15867},{\"end\":15884,\"start\":15876},{\"end\":15891,\"start\":15884},{\"end\":16234,\"start\":16223},{\"end\":16240,\"start\":16234},{\"end\":16250,\"start\":16240},{\"end\":16263,\"start\":16250},{\"end\":16273,\"start\":16263},{\"end\":16280,\"start\":16273},{\"end\":16287,\"start\":16280},{\"end\":16296,\"start\":16287},{\"end\":16305,\"start\":16296},{\"end\":16315,\"start\":16305},{\"end\":16702,\"start\":16691},{\"end\":16710,\"start\":16702},{\"end\":16721,\"start\":16710},{\"end\":16727,\"start\":16721},{\"end\":16737,\"start\":16727},{\"end\":16750,\"start\":16737},{\"end\":16759,\"start\":16750},{\"end\":16768,\"start\":16759},{\"end\":16778,\"start\":16768},{\"end\":16788,\"start\":16778},{\"end\":17086,\"start\":17070},{\"end\":17098,\"start\":17086},{\"end\":17109,\"start\":17098},{\"end\":17417,\"start\":17406},{\"end\":17431,\"start\":17417},{\"end\":17646,\"start\":17632},{\"end\":17656,\"start\":17646},{\"end\":17665,\"start\":17656},{\"end\":17672,\"start\":17665},{\"end\":17684,\"start\":17672},{\"end\":17695,\"start\":17684},{\"end\":17711,\"start\":17695},{\"end\":17941,\"start\":17934},{\"end\":17948,\"start\":17941},{\"end\":17956,\"start\":17948}]", "bib_venue": "[{\"end\":14864,\"start\":14763},{\"end\":15188,\"start\":15082},{\"end\":15489,\"start\":15391},{\"end\":15924,\"start\":15891},{\"end\":16340,\"start\":16315},{\"end\":16811,\"start\":16788},{\"end\":17154,\"start\":17109},{\"end\":17457,\"start\":17431},{\"end\":17630,\"start\":17584},{\"end\":18026,\"start\":17956}]"}}}, "year": 2023, "month": 12, "day": 17}