{"id": 218486753, "updated": "2023-09-28 02:36:42.401", "metadata": {"title": "R4C: A Benchmark for Evaluating RC Systems to Get the Right Answer for the Right Reason", "authors": "[{\"first\":\"Naoya\",\"last\":\"Inoue\",\"middle\":[]},{\"first\":\"Pontus\",\"last\":\"Stenetorp\",\"middle\":[]},{\"first\":\"Kentaro\",\"last\":\"Inui\",\"middle\":[]}]", "venue": "ACL", "journal": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics", "publication_date": {"year": 2020, "month": null, "day": null}, "abstract": "Recent studies have revealed that reading comprehension (RC) systems learn to exploit annotation artifacts and other biases in current datasets. This prevents the community from reliably measuring the progress of RC systems. To address this issue, we introduce R4C, a new task for evaluating RC systems\u2019 internal reasoning. R4C requires giving not only answers but also derivations: explanations that justify predicted answers. We present a reliable, crowdsourced framework for scalably annotating RC datasets with derivations. We create and publicly release the R4C dataset, the first, quality-assured dataset consisting of 4.6k questions, each of which is annotated with 3 reference derivations (i.e. 13.8k derivations). Experiments show that our automatic evaluation metrics using multiple reference derivations are reliable, and that R4C assesses different skills from an existing benchmark.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "1910.04601", "mag": "3112013081", "acl": "2020.acl-main.602", "pubmed": null, "pubmedcentral": null, "dblp": "conf/acl/InoueSI20", "doi": "10.18653/v1/2020.acl-main.602"}}, "content": {"source": {"pdf_hash": "1802ebc830d76a9b89f4115bafa4db304d6750cf", "pdf_src": "ACL", "pdf_uri": "[\"https://www.aclweb.org/anthology/2020.acl-main.602.pdf\"]", "oa_url_match": true, "oa_info": {"license": "CCBY", "open_access_url": "https://www.aclweb.org/anthology/2020.acl-main.602.pdf", "status": "HYBRID"}}, "grobid": {"id": "a16fedc91f883a78f3d8931fba02375e9f2f7238", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/1802ebc830d76a9b89f4115bafa4db304d6750cf.txt", "contents": "\nR 4 C: A Benchmark for Evaluating RC Systems to Get the Right Answer for the Right Reason\nAssociation for Computational LinguisticsCopyright Association for Computational LinguisticsJuly 5 -10, 2020. 2020\n\nNaoya Inoue \nTohoku University\n\n\nRIKEN\n\n\nPontus Stenetorp \nRIKEN\n\n\nUniversity College London\n\n\nKentaro Inui inui@ecei.tohoku.ac.jpp.stenetorp@cs.ucl.ac.uk \nTohoku University\n\n\nRIKEN\n\n\nR 4 C: A Benchmark for Evaluating RC Systems to Get the Right Answer for the Right Reason\n\nProceedings of the 58th Annual Meeting of the Association for Computational Linguistics\nthe 58th Annual Meeting of the Association for Computational LinguisticsAssociation for Computational LinguisticsJuly 5 -10, 2020. 20206740\nRecent studies have revealed that reading comprehension (RC) systems learn to exploit annotation artifacts and other biases in current datasets. This prevents the community from reliably measuring the progress of RC systems. To address this issue, we introduce R 4 C, a new task for evaluating RC systems' internal reasoning. R 4 C requires giving not only answers but also derivations: explanations that justify predicted answers. We present a reliable, crowdsourced framework for scalably annotating RC datasets with derivations. We create and publicly release the R 4 C dataset, the first, quality-assured dataset consisting of 4.6k questions, each of which is annotated with 3 reference derivations (i.e. 13.8k derivations). Experiments show that our automatic evaluation metrics using multiple reference derivations are reliable, and that R 4 C assesses different skills from an existing benchmark.\n\nIntroduction\n\nReading comprehension (RC) has become a key benchmark for natural language understanding (NLU) systems, and a large number of datasets are now available (Welbl et al., 2018;Ko\u010disk\u1ef3 et al., 2018;Yang et al., 2018, i.a.). However, it has been established that these datasets suffer from annotation artifacts and other biases, which may allow systems to \"cheat\": Instead of learning to read and comprehend texts in their entirety, systems learn to exploit these biases and find answers via simple heuristics, such as looking for an entity with a particular semantic type (Sugawara et al., 2018;Mudrakarta et al., 2018) (e.g. given a question starting with Who, a system finds a person entity found in a document).\n\nTo address this issue, the community has introduced increasingly more difficult Question Answering (QA) problems, for example, so that answer- \n\n\nQuestion\n\nWhat was the former band of the member of Mother Love Bone who died just before the release of \"Apple\"?\n\n\nArticles\n\nExplanation Answer Input Output Figure 1: R 4 C, a new RC task extending upon the standard RC setting, requiring systems to provide not only an answer, but also a derivation. The example is taken from HotpotQA (Yang et al., 2018), where sentences [1-2, 4, 6-7] are supporting facts, and [3,5] are not. related information is scattered across several articles (Welbl et al., 2018;Yang et al., 2018) (i.e. multi-hop QA). However, recent studies show that such multi-hop QA also has weaknesses (Chen and Durrett, 2019;Min et al., 2019;Jiang et al., 2019), e.g. combining multiple sources of information is not always necessary to find answers. Another direction, which we follow, includes evaluating a systems' reasoning Yang et al., 2018;Thorne and Vlachos, 2018;Camburu et al., 2018;Fan et al., 2019;Rajani et al., 2019). In the context of RC, Yang et al. (2018) propose Hot-potQA, which requires systems not only to give an answer but also to identify supporting facts (SFs), sentences containing information that supports the answer. SFs are defined as sentences containing information that supports the answer (see \"Supporting facts\" in Fig. 1 for an example). As shown in SFs [1] , [2] , and [7] , however, only a subset of SFs may contribute to the necessary reasoning. For example, [1] states two facts: (a) Return to Olympus is an album by Malfunkshun; and (b) Malfunkshun is a rock band. Among these, only (b) is related to the necessary reasoning. Thus, achieving a high accuracy in the SF detection task does not fully prove a RC systems's reasoning ability.\n\nThis paper proposes R 4 C, a new task of RC that requires systems to provide an answer and derivation 1 : a minimal explanation that justifies predicted answers in a semi-structured natural language form (see \"Derivation\" in Fig. 1 for an example). Our main contributions can be summarized as follows:\n\n\u2022 We propose R 4 C, which enables us to quantitatively evaluate a systems' internal reasoning in a finer-grained manner than the SF detection task. We show that R 4 C assesses different skills from the SF detection task.\n\n\u2022 We create and publicly release the first dataset of R 4 C consisting of 4,588 questions, each of which is annotated with 3 high-quality derivations (i.e. 13,764 derivations), available at https://naoya-i.github.io/r4c/.\n\n\u2022 We present and publicly release a reliable, crowdsourced framework for scalably annotating existing RC datasets with derivations in order to facilitate large-scale dataset construction of derivations in the RC community.\n\n2 Task description\n\n\nTask definition\n\nWe build R 4 C on top of the standard RC task. Given a question q and articles R, the task is (i) to find the answer a from R and (ii) to generate a derivation D that justifies why a is believed to be the answer to q.\n\nThere are several design choices for derivations, including whether derivations should be structured, whether the vocabulary should be closed, etc. This leads to a trade-off between the expressivity of reasoning and the interpretability of an evaluation metric. To maintain a reasonable trade-off, we choose to represent derivations in a semi-structured natural language form. Specifically, a derivation is defined as a set of derivation steps. Each deriva-\ntion step d i \u2208 D is defined as a relational fact, i.e. d i \u2261 d h i , d r i , d t i , where d h i , d t i\nare entities (noun phrases), and d r i is a verb phrase representing a relationship between d t i and d h i (see Fig. 1 for an example), similar to the Open Information Extraction paradigm (Etzioni et al., 2008). d h i , d r i , d t i may be a phrase not contained in R (e.g. is lead singer of in Fig. 1).\n\n\nEvaluation metrics\n\nWhile the output derivations are semi-structured, the linguistic diversity of entities and relations still prevents automatic evaluation. One typical solution is crowdsourced judgement, but it is costly both in terms of time and budget. We thus resort to a reference-based similarity metric.\n\nSpecifically, for output derivation D, we assume n sets of golden derivations G 1 , G 2 , ..., G n . For evaluation, we would like to assess how well derivation steps in D can be aligned with those in G i in the best case. For each golden derivation G i , we calculate c(D; G i ), an alignment score of D with respect to G i or a soft version of the number of correct derivation steps in D (i.e. 0 \u2264 c(D; G i ) \u2264 min(|D|, |G i |)). We then find a golden derivation G * that gives the highest c(D; G * ) and define the precision, recall and f 1 as follows:\npr(D) = c(D; G * ) |D| , rc(D) = c(D; G * ) |G * | f 1 (D) = 2 \u00b7 pr(D; G * ) \u00b7 rc(D; G * ) pr(D; G * ) + rc(D; G * )\nAn official evaluation script is available at https:\n//naoya-i.github.io/r4c/.\nAlignment score To calculate c(D; G i ), we would like to find the best alignment between derivation steps in D and those in G i . See Fig. 2 for an example, where two possible alignments A 1 , A 2 are shown. As derivation steps in D agree with those in G i with A 2 more than those with A 1 , we would like to consider A 2 when evaluating. We first define c(D; G i , A j ), the correctness of D given a specific alignment A j , and then pick the  best alignment as follows:\nOutput D Golden G i A 2 A 2 A 2 A 1 A 1 A 1Figurec(D; G i , A j ) = (d j ,g j )\u2208A j a(d j , g j ) c(D; G i ) = max A j \u2208A(D,G i ) c(D; G i , A j ),\nwhere a(d j , g j ) is a similarity [0, 1] between two derivation steps d j , g j , and A(D, G i ) denotes all possible one-to-one alignments between derivation steps in D and those in G i . For a(d j , g j ), we consider three variants, depending on the granularity of evaluation. We first introduce two fine-grained scorer, taking only entities or relations into account (henceforth, entity scorer and relation scorer):\na ent (d j , g j ) = 1 2 (s(d h j , g h j ) + s(d t j , g t j )) a rel (d j , g j ) = s(d r j , g r j ),\nwhere s(\u00b7, \u00b7) denotes an arbitrary similarity measure [0, 1] between two phrases. In this study, we employ a normalized Levenshtein distance. Finally, as a rough indication of overall performance, we also provide a full scorer as follows:\na full (d j , g j ) = 1 3 (s(d h j , g h j )+s(d r j , g r j )+s(d t j , g t j ))\n\nData collection\n\nThe main purpose of R 4 C is to benchmark an RC systems' internal reasoning. We thus assume a semi-supervised learning scenario where RC systems are trained to answer a given question on a large-scale RC dataset and then fine-tuned to give a correct reasoning on a smaller reasoning-annotated datasets. To acquire a dataset of derivations, we use crowdsourcing (CS).\n\n\nCrowdsourcing interface\n\nWe design our interface to annotate existing RC datasets with derivations, as a wide variety of high quality RC datasets are already available (Welbl et al., 2018;Yang et al., 2018, etc.). We assume that RC datasets provide (i) a question, (ii) the answer, and (iii) supporting articles, articles that support the answer (optionally with SFs). Initially, in order to encourage crowdworkers (henceforth, workers) to read the supporting articles carefully, we ask workers to answer to the question based on the supporting articles (see Appendix A). To reduce the workload, four candidate answers are provided. 2 We also allow for neither as RC datasets may contain erroneous instances.\n\nSecond, we ask workers to write derivations for their answer (see Fig. 3). They click on a sentence (either a SF or non-SF) in a supporting article (left) and then input their derivation in the form of triplets (right). They are asked to input entities and relations through free-form textboxes. To reduce the workload and encourage annotation consistency,  we also provide suggestions. These suggestions include predefined prepositions, noun phrases, and verb phrases automatically extracted from supporting articles. 3 We also highlight SFs if they are available for the given RC dataset.\n\n\nWorkflow\n\nTo discourage noisy annotations, we first deploy a qualification test. We provide the same task described in \u00a73.1 in the test and manually identify competent workers in our task. The final annotation is carried out solely by these qualified workers.\n\nWe deploy the task on Amazon Mechanical Turk (AMT). 4 We allow workers with \u2265 5,000 Human Intelligence Tasks experience and an approval rate of \u2265 95.0% to take the qualification test. For the test, we pay \u00a215 as a reward per instance. For the final annotation task, we assign 3 workers per instance and pay \u00a230 to each worker.\n\n\nDataset\n\nThere are a large number of choices of RC datasets that meet the criteria described in \u00a73.1 including SQuAD (Rajpurkar et al., 2016) and Wiki-Hop (Welbl et al., 2018). Our study uses Hot-potQA (Yang et al., 2018), one of the most actively used multi-hop QA datasets. 5 The multi-hop QA setting ensures that derivation steps are spread across documents, thereby posing an interesting unsolved research problem.\n\nFor annotation, we sampled 3,000 instances from 90,564 training instances and 3,000 instances from 7,405 development instances. For the qualification test and interface development, we sampled another 300 instances from the training set. We used the annotations of SFs provided by HotpotQA. We assume that the training set is used for fine-tuning RC systems' internal reasoning, and the development set is used for evaluation.\n\n\nStatistics\n\nIn the qualification test, we identified 45 competent workers (out of 256 workers). To avoid noisy annotations, we filter out submissions (i) with a wrong answer and (ii) with a neither answer. After the filtering, we retain only instances with exactly three derivations annotated. Finally, we obtained 7,137 derivations for 2,379 instances in the training set and 7,623 derivations for 2,541 instances in the dev set. See Appendix B for annotation examples.\n\n\nEvaluation\n\n\nMethodology\n\nTo check whether annotated derivations help humans recover answers, we setup another CS task on AMT (answerability judgement). Given a Hot-potQA question and the annotated derivation, 3 workers are asked whether or not they can answer the question solely based on the derivation at three levels. We evaluate all 7,623 derivations from the dev set. For reliability, we targeted only qualified workers and pay \u00a215 as a reward per instance.\n\nTo see if each derivation step can actually be derived from its source SF, we asked two expert annotators (non co-authors) to check 50 derivation steps from the dev set (derivability judgement).\n\n\nResults\n\nFor the answerability judgement, we obtained Krippendorff's \u03b1 of 0.263 (a fair agreement). With majority voting, we obtained the following results: YES: 95.2%, LIKELY: 2.2%, and NO: 1.3% (split: 1.3%). 6 For the derivability judgement, 96.0% of the sampled derivation steps (48/50) are judged as derivable from their corresponding SFs by both expert annotators. Despite the complexity of the annotation task, the results indicate that the proposed annotation pipeline can capture competent workers and produce high-quality derivation annotations. For the final dev set, we retain only instances with YES answerability judgement.\n\nThe final R 4 C dataset includes 4,588 questions from HotpotQA (see Table 1), each of which is annotated with 3 reference derivations (i.e. 13,764 derivations). This is the first dataset of RC annotated with semi-structured, multiple reference derivations. The most closest work to our dataset is the WorldTree corpus , the largest QA dataset annotated with explanations,  which contains 1,680 questions. Jansen et al.\n\n(2018) use experts for annotation, and the annotated explanations are grounded on a predefined, structured knowledge base. In contrast, our work proposes a non-expert-based annotation framework and grounds explanations using unstructured texts.\n\n\nAnalysis\n\nEffect of multiple references Do crowdsourced multiple golden derivations help us to evaluate output derivations more accurately? To verify this, we evaluated oracle derivations using one, two, or all three references. The derivations were written by qualified workers for 100 dev instances. Table 2 shows that having more references increases the performance, which indicates that references provided by different workers are indeed diverse enough to capture oracle derivations. The peak performance with # rf= 3 establishes the upper bound performance on this dataset.\n\nThe larger improvement of the relation-level performance (+14.5) compared to that of the entitylevel performance (+8.0) also suggests that relations are linguistically more diverse than entities, as we expected (e.g. is in, is a town in, and is located in are annotated for a locational relation).\n\nBaseline models To analyze the nature of R 4 C, we evaluate the following heuristic models. IE: extracting all entity relations from SFs. 7 CORE: extracting the core information of SFs. Based on the dependency structure of SFs (with article title t), it extracts a root verb v and the right, first child c r of v, and outputs t, v, c r as a derivation step. Table 3 shows a large performance gap to the human upper bound, indicating that R 4 C is different to the HotpotQA's SF detection task-it does not simply require systems to exhaustively extract information nor to extract core information from SFs. The errors from these baseline models include generating entity relations irrelevant to reasoning (e.g. Return to Olympus is an album in Fig. 2) or missing implicit entity relations (e.g. Andrew Wood is 7 We use Stanford OpenIE (Angeli et al., 2015).  a member of Mother Love Bone in Fig. 1). R 4 C introduces a new research problem for developing RC systems that can explain their answers.\n\n\nConclusions\n\nTowards evaluating RC systems' internal reasoning, we have proposed R 4 C that requires systems not only to output answers but also to give their derivations. For scalability, we have carefully developed a crowdsourced framework for annotating existing RC datasets with derivations. Our experiments have demonstrated that our framework produces high-quality derivations, and that automatic evaluation metrics using multiple reference derivations can reliably capture oracle derivations. The experiments using two simple baseline models highlight the nature of R 4 C, namely that the derivation generation task is not simply the SF detection task. We make the dataset, automatic evaluation script, and baseline systems publicly available at https://naoya-i.github.io/r4c/.\n\nOne immediate future work is to evaluate stateof-the-art RC systems' internal reasoning on our dataset. For modeling, we plan to explore recent advances in conditional language models for jointly modeling QA with generating their derivations.\n\nA Crowdsourcing interface Fig. 4 shows the instruction of our annotation task to crowdworkers. Fig. 5 shows the interface of the question-answering task.   Table 4 shows examples of crowdsourced annotations.\n\n\nB Example annotations\n\n2 :\n2Two possible alignments A 1 and A 2 between D and G i with their alignment scores a(\u00b7, \u00b7). The precision and recall of D is (0.1+1.0+0.8)/3 = 0.633 and (0.1+1.0+0.8)/5=0.380, respectively.\n\nFigure 3 :\n3Crowdsourcing interface for derivation annotation. Workers click on sentences and create derivation steps in the form of entity-relation triplets.\n\nFigure 4 :\n4Task instruction.\n\nFigure 5 :\n5Task interface for the first question answering phase. The reasoning annotation interface shown inFig. 3follows after this interface.\n\n\nTitle: Return to Olympus [1] Return to Olympus is the only album by the alternative rock band Malfunkshun. [2] It was released after the band had broken up and after lead singer Andrew Wood (later of Mother Love Bone) had died... [3] Stone Gossard had compiled\u2026 Title: Mother Love Bone [4] Mother Love Bone was an American rock band that\u2026 [5] The band was active from\u2026 [6] Frontman Andrew Wood's personality and compositions helped to catapult the group to... [7] Wood died only days before the scheduled release of the band's debut album, \"Apple\", thus ending the\u2026[Malfunkshun] \nis \n[a rock band] \n\n[Andrew Wood] \nis lead singer of \n[Malfunkshun] \n\n[Andrew Wood] \ndied just before the \nrelease of [Apple] \n\n[Andrew Wood] \nis a member of \n[Mother Love Bone] \n\n[Malfunkshun] \nis former of \n[Mother Love Bone] \n\nR 4 C: Derivation \n\nSupporting facts (SFs): \n\n[1], [2], [4], [6], [7] \n\nMalfunkshun \n\n\n\nTable 1 :\n1Statistics of R 4 C corpus. \"st.\" denotes the number of derivation steps. Each instance is annotated with 3 golden derivations.\n\nTable 2 :\n2Performance of oracle annotators on R 4 C as a function of the number of reference derivations.\n\n\nIE 11.3/53.4/16.6 13.7/62.8/19.9 11.4/52.3/16.5 CORE 66.4/60.1/62.1 51.0/46.0/47.5 59.4/53.6/55.4Model Entity P/R/F \nRelation P/R/F \nFull P/R/F \n\n\n\nTable 3 :\n3Performance of baseline models on R 4 C.\nR 4 C is short for \"Right for the Right Reasons RC.\"\nThe correct answer and three incorrect answers randomly chosen from the titles of the supporting articles.\nSpacy: https://spacy.io/ 4 https://requester.mturk.com/ 5 https://hotpotqa.github.io/\nWe also evaluated 1,000 training instances: 96.0% with YES judgement with Krippendorff's \u03b1 of 0.173.\n\nLeveraging linguistic structure for open domain information extraction. Gabor Angeli, Melvin Johnson Premkumar, Christopher D Manning, 10.3115/v1/p15-1034Proc. of ACL-IJCNLP. of ACL-IJCNLPGabor Angeli, Melvin Johnson Premkumar, and Christopher D. Manning. 2015. Leveraging linguis- tic structure for open domain information extraction. In Proc. of ACL-IJCNLP, pages 344-354.\n\ne-SNLI : Natural Language Inference with Natural Language Explanations. Tim Oana-Maria Camburu, Thomas Rockt\u00e4schel, Phil Lukasiewicz, Blunsom, Proc. of NIPS. of NIPSOana-maria Camburu, Tim Rockt\u00e4schel, Thomas Lukasiewicz, and Phil Blunsom. 2018. e-SNLI : Natural Language Inference with Natural Language Explanations. In Proc. of NIPS, pages 1-13.\n\nUnderstanding Dataset Design Choices for Multi-hop Reasoning. Jifan Chen, Greg Durrett, Proc. of NAACL-HLT. of NAACL-HLTJifan Chen and Greg Durrett. 2019. Understanding Dataset Design Choices for Multi-hop Reasoning. In Proc. of NAACL-HLT, pages 4026-4032.\n\nOpen information extraction from the web. Oren Etzioni, Michele Banko, Stephen Soderland, Daniel S Weld, 10.1145/1409360.1409378Communications of the ACM. 5112Oren Etzioni, Michele Banko, Stephen Soderland, and Daniel S. Weld. 2008. Open information extrac- tion from the web. Communications of the ACM, 51(12):68-74.\n\nELI5: Long Form Question Answering. Angela Fan, Yacine Jernite, Ethan Perez, David Grangier, Jason Weston, Michael Auli, Proc. of ACL. of ACLAngela Fan, Yacine Jernite, Ethan Perez, David Grang- ier, Jason Weston, and Michael Auli. 2019. ELI5: Long Form Question Answering. In Proc. of ACL, pages 3558-3567.\n\nMulti-hop Inference for Sentence-level TextGraphs: How Challenging is Meaningfully Combining Information for Science Question Answering?. A Peter, Jansen, Proc. of TextGraphs-12. of TextGraphs-12Peter A. Jansen. 2018. Multi-hop Inference for Sentence-level TextGraphs: How Challenging is Meaningfully Combining Information for Science Question Answering? In Proc. of TextGraphs-12, pages 12-17.\n\nWorldTree: A Corpus of Explanation Graphs for Elementary Science Questions supporting Multi-Hop Inference. A Peter, Elizabeth Jansen, Steven Wainwright, Clayton T Marmorstein, Morrison, Proc. of LREC. of LRECPeter A. Jansen, Elizabeth Wainwright, Steven Marmorstein, and Clayton T. Morrison. 2018. WorldTree: A Corpus of Explanation Graphs for El- ementary Science Questions supporting Multi-Hop Inference. In Proc. of LREC, pages 2732-2740.\n\nExplore, Propose, and Assemble: An Interpretable Model for Multi-Hop Reading Comprehension. Yichen Jiang, Nitish Joshi, Yen-Chun Chen, Mohit Bansal, Proc. of ACL. of ACLYichen Jiang, Nitish Joshi, Yen-Chun Chen, and Mohit Bansal. 2019. Explore, Propose, and Assemble: An Interpretable Model for Multi-Hop Reading Com- prehension. In Proc. of ACL, pages 2714-2725.\n\nThe NarrativeQA Reading Comprehension Challenge. Tom\u00e1\u0161 Ko\u010disk\u1ef3, Jonathan Schwarz, Phil Blunsom, Chris Dyer, Karl Moritz Hermann, G\u00e1bor Melis, Edward Grefenstette, Trans. of ACL. 6Tom\u00e1\u0161 Ko\u010disk\u1ef3, Jonathan Schwarz, Phil Blunsom, Chris Dyer, Karl Moritz Hermann, G\u00e1bor Melis, and Edward Grefenstette. 2018. The NarrativeQA Reading Comprehension Challenge. Trans. of ACL, 6:317-328.\n\nCompositional Questions Do Not Necessitate Multi-hop Reasoning. Sewon Min, Eric Wallace, Sameer Singh, Matt Gardner, Hannaneh Hajishirzi, Luke Zettlemoyer, Proc. of ACL. of ACLSewon Min, Eric Wallace, Sameer Singh, Matt Gard- ner, Hannaneh Hajishirzi, and Luke Zettlemoyer. 2019. Compositional Questions Do Not Necessitate Multi-hop Reasoning. In Proc. of ACL, pages 4249- 4257.\n\nDid the Model Understand the Question?. K Pramod, Ankur Mudrakarta, Mukund Taly, Kedar Sundararajan, Dhamdhere, Proc. of ACL. of ACLPramod K. Mudrakarta, Ankur Taly, Mukund Sun- dararajan, and Kedar Dhamdhere. 2018. Did the Model Understand the Question? In Proc. of ACL, pages 1896-1906.\n\nExplain Yourself ! Leveraging Language Models for Commonsense Reasoning. Bryan Fatema Nanzneen Rajani, Caiming Mccann, Richard Xiong, Socher, Proc. of ACL. of ACLFatema Nanzneen Rajani, Bryan McCann, Caiming Xiong, and Richard Socher. 2019. Explain Yourself ! Leveraging Language Models for Commonsense Reasoning. In Proc. of ACL, pages 4932-4942.\n\nSQuAD: 100,000+ Questions for Machine Comprehension of Text. Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, Percy Liang, Proc. of EMNLP. of EMNLPPranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016. SQuAD: 100,000+ Questions for Machine Comprehension of Text. In Proc. of EMNLP, pages 2383-2392.\n\nWhat Makes Reading Comprehension Questions Easier?. Saku Sugawara, Kentaro Inui, Satoshi Sekine, Akiko Aizawa, Proc. of EMNLP. of EMNLPSaku Sugawara, Kentaro Inui, Satoshi Sekine, and Akiko Aizawa. 2018. What Makes Reading Com- prehension Questions Easier? In Proc. of EMNLP, pages 4208-4219.\n\nAutomated Fact Checking: Task formulations, methods and future directions. James Thorne, Andreas Vlachos, Proc. of COLING. of COLINGJames Thorne and Andreas Vlachos. 2018. Automated Fact Checking: Task formulations, methods and fu- ture directions. In Proc. of COLING, pages 3346- 3359.\n\nConstructing Datasets for Multi-hop Reading Comprehension Across Documents. Johannes Welbl, Pontus Stenetorp, Sebastian Riedel, Trans. of ACL. 6Johannes Welbl, Pontus Stenetorp, and Sebastian Riedel. 2018. Constructing Datasets for Multi-hop Reading Comprehension Across Documents. Trans. of ACL, 6:287-302.\n\nHotpotQA: A Dataset for Diverse, Explainable Multi-hop Question Answering. Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William W Cohen, Ruslan Salakhutdinov, Christopher D Manning, Proc. of EMNLP. of EMNLPZhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Ben- gio, William W. Cohen, Ruslan Salakhutdinov, and Christopher D. Manning. 2018. HotpotQA: A Dataset for Diverse, Explainable Multi-hop Ques- tion Answering. In Proc. of EMNLP, pages 2369- 2380.\n\nof the same nationality? Supporting Art. 1 [1] Scott Derrickson (born July 16, 1966) is an American director, screenwriter and producer. Question Were Scott Derrickson and Ed WoodLos Angeles, CaliforniaDeliver Us From Evil. as well as the 2016 Marvel Cinematic Universe installment, \"Doctor StrangeQuestion Were Scott Derrickson and Ed Wood of the same nationality? Supporting Art. 1 [1] Scott Derrickson (born July 16, 1966) is an American director, screenwriter and producer.[2] He lives in Los Angeles, California.[3] He is best known for directing horror films such as \"Sinister\", \"The Exorcism of Emily Rose\", and \"Deliver Us From Evil\", as well as the 2016 Marvel Cinematic Universe installment, \"Doctor Strange.\"\n\n) was an American filmmaker, actor, writer, producer, and director. Edward Davis WoodJr, Supporting Art. 2 [1. Derivation step 1 [1, 1. Scott Derrickson] [is. an American director] Derivation step 2 [1, 1] [Ed Wood] [was. an American filmmakerSupporting Art. 2 [1] Edward Davis Wood Jr. (October 10, 1924 December 10, 1978) was an American filmmaker, actor, writer, producer, and director. Derivation step 1 [1, 1] [Scott Derrickson] [is] [an American director] Derivation step 2 [1, 1] [Ed Wood] [was] [an American filmmaker]\n\nAmerican drama romantic comedy film written and directed by Adriana Trigiani and produced by Donna Gigliotti for Altar Identity Studios, a subsidiary of Media Society.[2] Based on Trigiani's 2000 best-selling novel of the same name, the story is set in the actual Virginia town of Big Stone Gap circa 1970s. Question The director of the romantic comedy \"Big Stone Gap\" is based in what New York city? Supporting Art. 1 [1] Big Stone Gap is a. New York City; Greenwich Village; New York City6Supporting Art. 2 [1] Adriana Trigiani is an Italian American best-selling author of sixteen books, television writer, film director, and entrepreneur based in Greenwich Village. Derivation step 1 [1, 1. Big Stone Gap. is directed by. Adriana Trigiani] Derivation step 2 [2, 1. Adriana Trigiani] [is fromQuestion The director of the romantic comedy \"Big Stone Gap\" is based in what New York city? Supporting Art. 1 [1] Big Stone Gap is a 2014 American drama romantic comedy film written and directed by Adriana Trigiani and produced by Donna Gigliotti for Altar Identity Studios, a subsidiary of Media Society.[2] Based on Trigiani's 2000 best-selling novel of the same name, the story is set in the actual Virginia town of Big Stone Gap circa 1970s.[3] The film had its world premiere at the Virginia Film Festival on November 6, 2014. Supporting Art. 2 [1] Adriana Trigiani is an Italian American best-selling author of sixteen books, television writer, film director, and entrepreneur based in Greenwich Village, New York City.[2] Trigiani has published a novel a year since 2000. Derivation step 1 [1, 1] [Big Stone Gap] [is directed by] [Adriana Trigiani] Derivation step 2 [2, 1] [Adriana Trigiani] [is from] [Greenwich Village, New York City.]\n\nQuestion The arena where the Lewiston Maineiacs played their home games can seat how many people? Supporting Art. 1 [1] The Lewiston Maineiacs were a junior ice hockey team of the Quebec Major Junior Hockey League. Lewiston, MaineThe team played its home games at the Androscoggin Bank Colise.[3] They were the second QMJHL team in the United States, and the only one to play a full season. 4] They won the President's Cup inQuestion The arena where the Lewiston Maineiacs played their home games can seat how many people? Supporting Art. 1 [1] The Lewiston Maineiacs were a junior ice hockey team of the Quebec Major Junior Hockey League based in Lewiston, Maine.[2] The team played its home games at the Androscoggin Bank Colise.[3] They were the second QMJHL team in the United States, and the only one to play a full season.[4] They won the President's Cup in 2007.\n\nIn 1965 it was the location of the World Heavyweight Title fight during which one of the most famous sports photographs of the century was taken of Muhammed Ali standing over Sonny Liston. The Androscoggin Bank Colise (formerly Central Maine Civic Center and Lewiston Colisee) is a 4,000 capacity. Lewiston, Maine677 seated) multi-purpose arena. Derivation step 1 [1,2] [Lewiston Maineiacs. play in the. Androscoggin Bank Colise] Derivation step 2 [2,1. Androscoggin Bank Colise. is an] [arena] Derivation step 3 [2,1. Androscoggin Bank Colise. has a seating capacity of. 3,677 seatedSupporting Art. 2 [1] The Androscoggin Bank Colise (formerly Central Maine Civic Center and Lewiston Colisee) is a 4,000 capacity (3,677 seated) multi-purpose arena, in Lewiston, Maine, that opened in 1958.[2] In 1965 it was the location of the World Heavyweight Title fight during which one of the most famous sports photographs of the century was taken of Muhammed Ali standing over Sonny Liston. Derivation step 1 [1,2] [Lewiston Maineiacs] [play in the] [Androscoggin Bank Colise] Derivation step 2 [2,1] [Androscoggin Bank Colise] [is an] [arena] Derivation step 3 [2,1] [Androscoggin Bank Colise] [has a seating capacity of] [3,677 seated]\n\nExample of annotation results of derivations. Each derivation step is in the following format. 4article ID, SF. Head entity] [Relation] [Tail entityTable 4: Example of annotation results of derivations. Each derivation step is in the following format: [article ID, SF] [Head entity] [Relation] [Tail entity].\n", "annotations": {"author": "[{\"end\":247,\"start\":207},{\"end\":301,\"start\":248},{\"end\":390,\"start\":302}]", "publisher": "[{\"end\":132,\"start\":91},{\"end\":683,\"start\":642}]", "author_last_name": "[{\"end\":218,\"start\":213},{\"end\":264,\"start\":255},{\"end\":314,\"start\":310}]", "author_first_name": "[{\"end\":212,\"start\":207},{\"end\":254,\"start\":248},{\"end\":309,\"start\":302}]", "author_affiliation": "[{\"end\":238,\"start\":220},{\"end\":246,\"start\":240},{\"end\":272,\"start\":266},{\"end\":300,\"start\":274},{\"end\":381,\"start\":363},{\"end\":389,\"start\":383}]", "title": "[{\"end\":90,\"start\":1},{\"end\":480,\"start\":391}]", "venue": "[{\"end\":569,\"start\":482}]", "abstract": "[{\"end\":1613,\"start\":710}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b15\"},\"end\":1802,\"start\":1782},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":1823,\"start\":1802},{\"end\":1847,\"start\":1823},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":2220,\"start\":2197},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":2243,\"start\":2220},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":2842,\"start\":2823},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":2992,\"start\":2972},{\"end\":3030,\"start\":2992},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3128,\"start\":3104},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3145,\"start\":3128},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":3164,\"start\":3145},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":3349,\"start\":3331},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":3374,\"start\":3349},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3395,\"start\":3374},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":3412,\"start\":3395},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":3432,\"start\":3412},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":3474,\"start\":3456},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":6186,\"start\":6164},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":9394,\"start\":9374},{\"end\":9418,\"start\":9394},{\"end\":9840,\"start\":9839},{\"end\":10436,\"start\":10435},{\"end\":10823,\"start\":10822},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":11240,\"start\":11216},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":11274,\"start\":11254},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":11320,\"start\":11301},{\"end\":16080,\"start\":16079},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":16125,\"start\":16104}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":17725,\"start\":17531},{\"attributes\":{\"id\":\"fig_1\"},\"end\":17885,\"start\":17726},{\"attributes\":{\"id\":\"fig_2\"},\"end\":17916,\"start\":17886},{\"attributes\":{\"id\":\"fig_3\"},\"end\":18063,\"start\":17917},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":18962,\"start\":18064},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":19102,\"start\":18963},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":19210,\"start\":19103},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":19359,\"start\":19211},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":19412,\"start\":19360}]", "paragraph": "[{\"end\":2339,\"start\":1629},{\"end\":2484,\"start\":2341},{\"end\":2600,\"start\":2497},{\"end\":4180,\"start\":2613},{\"end\":4483,\"start\":4182},{\"end\":4705,\"start\":4485},{\"end\":4928,\"start\":4707},{\"end\":5152,\"start\":4930},{\"end\":5172,\"start\":5154},{\"end\":5409,\"start\":5192},{\"end\":5868,\"start\":5411},{\"end\":6280,\"start\":5975},{\"end\":6594,\"start\":6303},{\"end\":7151,\"start\":6596},{\"end\":7321,\"start\":7269},{\"end\":7822,\"start\":7348},{\"end\":8392,\"start\":7971},{\"end\":8736,\"start\":8498},{\"end\":9203,\"start\":8837},{\"end\":9914,\"start\":9231},{\"end\":10506,\"start\":9916},{\"end\":10768,\"start\":10519},{\"end\":11096,\"start\":10770},{\"end\":11517,\"start\":11108},{\"end\":11945,\"start\":11519},{\"end\":12418,\"start\":11960},{\"end\":12884,\"start\":12447},{\"end\":13080,\"start\":12886},{\"end\":13720,\"start\":13092},{\"end\":14140,\"start\":13722},{\"end\":14386,\"start\":14142},{\"end\":14969,\"start\":14399},{\"end\":15268,\"start\":14971},{\"end\":16266,\"start\":15270},{\"end\":17053,\"start\":16282},{\"end\":17297,\"start\":17055},{\"end\":17506,\"start\":17299}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":5974,\"start\":5869},{\"attributes\":{\"id\":\"formula_1\"},\"end\":7268,\"start\":7152},{\"attributes\":{\"id\":\"formula_2\"},\"end\":7347,\"start\":7322},{\"attributes\":{\"id\":\"formula_3\"},\"end\":7872,\"start\":7823},{\"attributes\":{\"id\":\"formula_4\"},\"end\":7970,\"start\":7872},{\"attributes\":{\"id\":\"formula_5\"},\"end\":8497,\"start\":8393},{\"attributes\":{\"id\":\"formula_6\"},\"end\":8818,\"start\":8737}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":13797,\"start\":13790},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":14698,\"start\":14691},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":15635,\"start\":15628},{\"end\":17462,\"start\":17455}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1627,\"start\":1615},{\"end\":2495,\"start\":2487},{\"end\":2611,\"start\":2603},{\"attributes\":{\"n\":\"2.1\"},\"end\":5190,\"start\":5175},{\"attributes\":{\"n\":\"2.2\"},\"end\":6301,\"start\":6283},{\"attributes\":{\"n\":\"3\"},\"end\":8835,\"start\":8820},{\"attributes\":{\"n\":\"3.1\"},\"end\":9229,\"start\":9206},{\"attributes\":{\"n\":\"3.2\"},\"end\":10517,\"start\":10509},{\"attributes\":{\"n\":\"3.3\"},\"end\":11106,\"start\":11099},{\"attributes\":{\"n\":\"3.4\"},\"end\":11958,\"start\":11948},{\"attributes\":{\"n\":\"4\"},\"end\":12431,\"start\":12421},{\"attributes\":{\"n\":\"4.1\"},\"end\":12445,\"start\":12434},{\"attributes\":{\"n\":\"4.2\"},\"end\":13090,\"start\":13083},{\"attributes\":{\"n\":\"5\"},\"end\":14397,\"start\":14389},{\"attributes\":{\"n\":\"6\"},\"end\":16280,\"start\":16269},{\"end\":17530,\"start\":17509},{\"end\":17535,\"start\":17532},{\"end\":17737,\"start\":17727},{\"end\":17897,\"start\":17887},{\"end\":17928,\"start\":17918},{\"end\":18973,\"start\":18964},{\"end\":19113,\"start\":19104},{\"end\":19370,\"start\":19361}]", "table": "[{\"end\":18962,\"start\":18631},{\"end\":19359,\"start\":19310}]", "figure_caption": "[{\"end\":17725,\"start\":17537},{\"end\":17885,\"start\":17739},{\"end\":17916,\"start\":17899},{\"end\":18063,\"start\":17930},{\"end\":18631,\"start\":18066},{\"end\":19102,\"start\":18975},{\"end\":19210,\"start\":19115},{\"end\":19310,\"start\":19213},{\"end\":19412,\"start\":19372}]", "figure_ref": "[{\"end\":2653,\"start\":2645},{\"end\":3758,\"start\":3752},{\"end\":4413,\"start\":4407},{\"end\":6094,\"start\":6088},{\"end\":6278,\"start\":6272},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":7489,\"start\":7483},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":9988,\"start\":9982},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":16019,\"start\":16013},{\"end\":16167,\"start\":16160},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":17331,\"start\":17325},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":17400,\"start\":17394}]", "bib_author_first_name": "[{\"end\":19838,\"start\":19833},{\"end\":19853,\"start\":19847},{\"end\":19861,\"start\":19854},{\"end\":19884,\"start\":19873},{\"end\":19886,\"start\":19885},{\"end\":20212,\"start\":20209},{\"end\":20239,\"start\":20233},{\"end\":20257,\"start\":20253},{\"end\":20553,\"start\":20548},{\"end\":20564,\"start\":20560},{\"end\":20790,\"start\":20786},{\"end\":20807,\"start\":20800},{\"end\":20822,\"start\":20815},{\"end\":20840,\"start\":20834},{\"end\":20842,\"start\":20841},{\"end\":21105,\"start\":21099},{\"end\":21117,\"start\":21111},{\"end\":21132,\"start\":21127},{\"end\":21145,\"start\":21140},{\"end\":21161,\"start\":21156},{\"end\":21177,\"start\":21170},{\"end\":21511,\"start\":21510},{\"end\":21876,\"start\":21875},{\"end\":21893,\"start\":21884},{\"end\":21908,\"start\":21902},{\"end\":21928,\"start\":21921},{\"end\":21930,\"start\":21929},{\"end\":22309,\"start\":22303},{\"end\":22323,\"start\":22317},{\"end\":22339,\"start\":22331},{\"end\":22351,\"start\":22346},{\"end\":22630,\"start\":22625},{\"end\":22648,\"start\":22640},{\"end\":22662,\"start\":22658},{\"end\":22677,\"start\":22672},{\"end\":22688,\"start\":22684},{\"end\":22695,\"start\":22689},{\"end\":22710,\"start\":22705},{\"end\":22724,\"start\":22718},{\"end\":23024,\"start\":23019},{\"end\":23034,\"start\":23030},{\"end\":23050,\"start\":23044},{\"end\":23062,\"start\":23058},{\"end\":23080,\"start\":23072},{\"end\":23097,\"start\":23093},{\"end\":23376,\"start\":23375},{\"end\":23390,\"start\":23385},{\"end\":23409,\"start\":23403},{\"end\":23421,\"start\":23416},{\"end\":23703,\"start\":23698},{\"end\":23735,\"start\":23728},{\"end\":23751,\"start\":23744},{\"end\":24041,\"start\":24035},{\"end\":24057,\"start\":24053},{\"end\":24075,\"start\":24065},{\"end\":24090,\"start\":24085},{\"end\":24349,\"start\":24345},{\"end\":24367,\"start\":24360},{\"end\":24381,\"start\":24374},{\"end\":24395,\"start\":24390},{\"end\":24667,\"start\":24662},{\"end\":24683,\"start\":24676},{\"end\":24959,\"start\":24951},{\"end\":24973,\"start\":24967},{\"end\":24994,\"start\":24985},{\"end\":25265,\"start\":25259},{\"end\":25276,\"start\":25272},{\"end\":25289,\"start\":25281},{\"end\":25303,\"start\":25297},{\"end\":25319,\"start\":25312},{\"end\":25321,\"start\":25320},{\"end\":25335,\"start\":25329},{\"end\":25362,\"start\":25351},{\"end\":25364,\"start\":25363}]", "bib_author_last_name": "[{\"end\":19845,\"start\":19839},{\"end\":19871,\"start\":19862},{\"end\":19894,\"start\":19887},{\"end\":20231,\"start\":20213},{\"end\":20251,\"start\":20240},{\"end\":20269,\"start\":20258},{\"end\":20278,\"start\":20271},{\"end\":20558,\"start\":20554},{\"end\":20572,\"start\":20565},{\"end\":20798,\"start\":20791},{\"end\":20813,\"start\":20808},{\"end\":20832,\"start\":20823},{\"end\":20847,\"start\":20843},{\"end\":21109,\"start\":21106},{\"end\":21125,\"start\":21118},{\"end\":21138,\"start\":21133},{\"end\":21154,\"start\":21146},{\"end\":21168,\"start\":21162},{\"end\":21182,\"start\":21178},{\"end\":21517,\"start\":21512},{\"end\":21525,\"start\":21519},{\"end\":21882,\"start\":21877},{\"end\":21900,\"start\":21894},{\"end\":21919,\"start\":21909},{\"end\":21942,\"start\":21931},{\"end\":21952,\"start\":21944},{\"end\":22315,\"start\":22310},{\"end\":22329,\"start\":22324},{\"end\":22344,\"start\":22340},{\"end\":22358,\"start\":22352},{\"end\":22638,\"start\":22631},{\"end\":22656,\"start\":22649},{\"end\":22670,\"start\":22663},{\"end\":22682,\"start\":22678},{\"end\":22703,\"start\":22696},{\"end\":22716,\"start\":22711},{\"end\":22737,\"start\":22725},{\"end\":23028,\"start\":23025},{\"end\":23042,\"start\":23035},{\"end\":23056,\"start\":23051},{\"end\":23070,\"start\":23063},{\"end\":23091,\"start\":23081},{\"end\":23109,\"start\":23098},{\"end\":23383,\"start\":23377},{\"end\":23401,\"start\":23391},{\"end\":23414,\"start\":23410},{\"end\":23434,\"start\":23422},{\"end\":23445,\"start\":23436},{\"end\":23726,\"start\":23704},{\"end\":23742,\"start\":23736},{\"end\":23757,\"start\":23752},{\"end\":23765,\"start\":23759},{\"end\":24051,\"start\":24042},{\"end\":24063,\"start\":24058},{\"end\":24083,\"start\":24076},{\"end\":24096,\"start\":24091},{\"end\":24358,\"start\":24350},{\"end\":24372,\"start\":24368},{\"end\":24388,\"start\":24382},{\"end\":24402,\"start\":24396},{\"end\":24674,\"start\":24668},{\"end\":24691,\"start\":24684},{\"end\":24965,\"start\":24960},{\"end\":24983,\"start\":24974},{\"end\":25001,\"start\":24995},{\"end\":25270,\"start\":25266},{\"end\":25279,\"start\":25277},{\"end\":25295,\"start\":25290},{\"end\":25310,\"start\":25304},{\"end\":25327,\"start\":25322},{\"end\":25349,\"start\":25336},{\"end\":25372,\"start\":25365},{\"end\":26448,\"start\":26431}]", "bib_entry": "[{\"attributes\":{\"doi\":\"10.3115/v1/p15-1034\",\"id\":\"b0\",\"matched_paper_id\":6015236},\"end\":20135,\"start\":19761},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":54040953},\"end\":20484,\"start\":20137},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":139103297},\"end\":20742,\"start\":20486},{\"attributes\":{\"doi\":\"10.1145/1409360.1409378\",\"id\":\"b3\",\"matched_paper_id\":207169186},\"end\":21061,\"start\":20744},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":196170479},\"end\":21370,\"start\":21063},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":44094607},\"end\":21766,\"start\":21372},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":3623373},\"end\":22209,\"start\":21768},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":186206745},\"end\":22574,\"start\":22211},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":2593903},\"end\":22953,\"start\":22576},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":174801764},\"end\":23333,\"start\":22955},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":21673814},\"end\":23623,\"start\":23335},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":174803111},\"end\":23972,\"start\":23625},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":11816014},\"end\":24291,\"start\":23974},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":52113519},\"end\":24585,\"start\":24293},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":49320819},\"end\":24873,\"start\":24587},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":9192723},\"end\":25182,\"start\":24875},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":52822214},\"end\":25640,\"start\":25184},{\"attributes\":{\"id\":\"b17\"},\"end\":26361,\"start\":25642},{\"attributes\":{\"id\":\"b18\"},\"end\":26889,\"start\":26363},{\"attributes\":{\"id\":\"b19\"},\"end\":28632,\"start\":26891},{\"attributes\":{\"id\":\"b20\"},\"end\":29503,\"start\":28634},{\"attributes\":{\"id\":\"b21\"},\"end\":30734,\"start\":29505},{\"attributes\":{\"id\":\"b22\"},\"end\":31044,\"start\":30736}]", "bib_title": "[{\"end\":19831,\"start\":19761},{\"end\":20207,\"start\":20137},{\"end\":20546,\"start\":20486},{\"end\":20784,\"start\":20744},{\"end\":21097,\"start\":21063},{\"end\":21508,\"start\":21372},{\"end\":21873,\"start\":21768},{\"end\":22301,\"start\":22211},{\"end\":22623,\"start\":22576},{\"end\":23017,\"start\":22955},{\"end\":23373,\"start\":23335},{\"end\":23696,\"start\":23625},{\"end\":24033,\"start\":23974},{\"end\":24343,\"start\":24293},{\"end\":24660,\"start\":24587},{\"end\":24949,\"start\":24875},{\"end\":25257,\"start\":25184},{\"end\":27197,\"start\":26891},{\"end\":29692,\"start\":29505}]", "bib_author": "[{\"end\":19847,\"start\":19833},{\"end\":19873,\"start\":19847},{\"end\":19896,\"start\":19873},{\"end\":20233,\"start\":20209},{\"end\":20253,\"start\":20233},{\"end\":20271,\"start\":20253},{\"end\":20280,\"start\":20271},{\"end\":20560,\"start\":20548},{\"end\":20574,\"start\":20560},{\"end\":20800,\"start\":20786},{\"end\":20815,\"start\":20800},{\"end\":20834,\"start\":20815},{\"end\":20849,\"start\":20834},{\"end\":21111,\"start\":21099},{\"end\":21127,\"start\":21111},{\"end\":21140,\"start\":21127},{\"end\":21156,\"start\":21140},{\"end\":21170,\"start\":21156},{\"end\":21184,\"start\":21170},{\"end\":21519,\"start\":21510},{\"end\":21527,\"start\":21519},{\"end\":21884,\"start\":21875},{\"end\":21902,\"start\":21884},{\"end\":21921,\"start\":21902},{\"end\":21944,\"start\":21921},{\"end\":21954,\"start\":21944},{\"end\":22317,\"start\":22303},{\"end\":22331,\"start\":22317},{\"end\":22346,\"start\":22331},{\"end\":22360,\"start\":22346},{\"end\":22640,\"start\":22625},{\"end\":22658,\"start\":22640},{\"end\":22672,\"start\":22658},{\"end\":22684,\"start\":22672},{\"end\":22705,\"start\":22684},{\"end\":22718,\"start\":22705},{\"end\":22739,\"start\":22718},{\"end\":23030,\"start\":23019},{\"end\":23044,\"start\":23030},{\"end\":23058,\"start\":23044},{\"end\":23072,\"start\":23058},{\"end\":23093,\"start\":23072},{\"end\":23111,\"start\":23093},{\"end\":23385,\"start\":23375},{\"end\":23403,\"start\":23385},{\"end\":23416,\"start\":23403},{\"end\":23436,\"start\":23416},{\"end\":23447,\"start\":23436},{\"end\":23728,\"start\":23698},{\"end\":23744,\"start\":23728},{\"end\":23759,\"start\":23744},{\"end\":23767,\"start\":23759},{\"end\":24053,\"start\":24035},{\"end\":24065,\"start\":24053},{\"end\":24085,\"start\":24065},{\"end\":24098,\"start\":24085},{\"end\":24360,\"start\":24345},{\"end\":24374,\"start\":24360},{\"end\":24390,\"start\":24374},{\"end\":24404,\"start\":24390},{\"end\":24676,\"start\":24662},{\"end\":24693,\"start\":24676},{\"end\":24967,\"start\":24951},{\"end\":24985,\"start\":24967},{\"end\":25003,\"start\":24985},{\"end\":25272,\"start\":25259},{\"end\":25281,\"start\":25272},{\"end\":25297,\"start\":25281},{\"end\":25312,\"start\":25297},{\"end\":25329,\"start\":25312},{\"end\":25351,\"start\":25329},{\"end\":25374,\"start\":25351},{\"end\":26452,\"start\":26431}]", "bib_venue": "[{\"end\":19934,\"start\":19915},{\"end\":20293,\"start\":20280},{\"end\":20592,\"start\":20574},{\"end\":20897,\"start\":20872},{\"end\":21196,\"start\":21184},{\"end\":21549,\"start\":21527},{\"end\":21967,\"start\":21954},{\"end\":22372,\"start\":22360},{\"end\":22752,\"start\":22739},{\"end\":23123,\"start\":23111},{\"end\":23459,\"start\":23447},{\"end\":23779,\"start\":23767},{\"end\":24112,\"start\":24098},{\"end\":24418,\"start\":24404},{\"end\":24708,\"start\":24693},{\"end\":25016,\"start\":25003},{\"end\":25388,\"start\":25374},{\"end\":25777,\"start\":25642},{\"end\":26429,\"start\":26363},{\"end\":27332,\"start\":27199},{\"end\":28847,\"start\":28634},{\"end\":29801,\"start\":29694},{\"end\":30829,\"start\":30736},{\"end\":19949,\"start\":19936},{\"end\":20302,\"start\":20295},{\"end\":20606,\"start\":20594},{\"end\":21204,\"start\":21198},{\"end\":21567,\"start\":21551},{\"end\":21976,\"start\":21969},{\"end\":22380,\"start\":22374},{\"end\":23131,\"start\":23125},{\"end\":23467,\"start\":23461},{\"end\":23787,\"start\":23781},{\"end\":24122,\"start\":24114},{\"end\":24428,\"start\":24420},{\"end\":24719,\"start\":24710},{\"end\":25398,\"start\":25390},{\"end\":27381,\"start\":27334},{\"end\":29818,\"start\":29803}]"}}}, "year": 2023, "month": 12, "day": 17}