{"id": 252032160, "updated": "2022-09-19 13:21:52.219", "metadata": {"title": "An Improved Deep Learning Model for High-Impact Weather Nowcasting", "authors": "[{\"first\":\"Shun\",\"last\":\"Yao\",\"middle\":[]},{\"first\":\"Haonan\",\"last\":\"Chen\",\"middle\":[]},{\"first\":\"Elizabeth\",\"last\":\"Thompson\",\"middle\":[\"J.\"]},{\"first\":\"Robert\",\"last\":\"Cifelli\",\"middle\":[]}]", "venue": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing", "journal": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing", "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "Accurate nowcasting (short-term prediction, 0\u20136 h) of high-impact weather, such as landfalling hurricanes and extreme convective precipitation, plays a critical role in natural disaster monitoring and mitigation. A number of nowcasting approaches have been developed in the past few decades, such as optical flow and the tracking radar echoes by correlation system. Most of these mainstream operational techniques are based on radar echo map extrapolation, which determines the velocity and direction of precipitation systems using historical and current radar observations. However, the skill of the traditional extrapolation method decreases rapidly within the first hour. In order to improve nowcasting skill, recent studies have proposed using deep learning methods, such as convolutional recurrent neural network and trajectory gate recurrent unit. But none of these methods focuses on high-impact weather events, and the deep learning models trained based on general precipitation events cannot meet the demand of accurate warnings and decision-making at the scales required for high-impact weather events, such as hurricanes. Using multiradar observations, this article introduces the idea of self-attention and develops a self-attention-based gate recurrent unit (SaGRU) to enhance its generalization capability and scalability in predicting high-impact weather events. In particular, two types of high-impact weather systems, namely, landfalling hurricanes and extreme convective precipitation events, are investigated. Three models are trained based on hurricane events, heavy rainfall (i.e., nonhurricane) events, and all events combined in the southeast United States during 2015 and 2020. The impacts of different data sources on the nowcasting performance are quantified. The evaluation results of nowcasting products show that our SaGRU performs very well in predicting hurricane-induced rainfall. In the new methodology, the data from nonhurricane events are shown to provide useful information in enhancing the nowcasting performance during hurricane events as the model trained by combining all the hurricane and nonhurricane events has the best performance. In addition, this article quantifies the impact of the sequence length of input radar observations on the nowcasting performance, which shows that five consecutive observations are sufficient to obtain a stable model, and even two consecutive observations can produce reasonable results.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/staeors/YaoCTC22", "doi": "10.1109/jstars.2022.3203398"}}, "content": {"source": {"pdf_hash": "364284c25dc6a1883ddda4a80fe181bd6db13fae", "pdf_src": "IEEE", "pdf_uri": null, "oa_url_match": false, "oa_info": {"license": "CCBY", "open_access_url": "https://ieeexplore.ieee.org/ielx7/4609443/4609444/09873914.pdf", "status": "GOLD"}}, "grobid": {"id": "9465bde816d072f469f997b623eca8be991eeadf", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/364284c25dc6a1883ddda4a80fe181bd6db13fae.txt", "contents": "\nAn Improved Deep Learning Model for High-Impact Weather Nowcasting\n\n\nShun Yao s.yao@colostate.edu \nSenior Member, IEEEHaonan Chen \nElizabeth J Thompson elizabeth.thompson@noaa.gov \nRobert Cifelli rob.cifelli@noaa.gov. \nShun Yao \nHaonan Chen haonan.chen@colostate.edu. \nElizabeth J Thompson \nRobert Cifelli \n\nDepartment of Electrical and Computer Engineering\nColorado State University\n80523Fort CollinsCOUSA\n\n\nNOAA Physical Sciences Laboratory\n80305BoulderCOUSA\n\nAn Improved Deep Learning Model for High-Impact Weather Nowcasting\n\nIEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING\n15202210.1109/JSTARS.2022.3203398Manuscript received 15 May 2022; revised 16 July 2022; accepted 20 Au-gust 2022. Date of publication 1 September 2022; date of current version 9 September 2022.7400Index Terms-Deep learninghigh-impact weatherprecipita- tion nowcastingweather radar\nAccurate nowcasting (short-term prediction, 0-6 h) of high-impact weather, such as landfalling hurricanes and extreme convective precipitation, plays a critical role in natural disaster monitoring and mitigation. A number of nowcasting approaches have been developed in the past few decades, such as optical flow and the tracking radar echoes by correlation system. Most of these mainstream operational techniques are based on radar echo map extrapolation, which determines the velocity and direction of precipitation systems using historical and current radar observations. However, the skill of the traditional extrapolation method decreases rapidly within the first hour. In order to improve nowcasting skill, recent studies have proposed using deep learning methods, such as convolutional recurrent neural network and trajectory gate recurrent unit. But none of these methods focuses on high-impact weather events, and the deep learning models trained based on general precipitation events cannot meet the demand of accurate warnings and decision-making at the scales required for high-impact weather events, such as hurricanes. Using multiradar observations, this article introduces the idea of self-attention and develops a self-attention-based gate recurrent unit (SaGRU) to enhance its generalization capability and scalability in predicting high-impact weather events. In particular, two types of high-impact weather systems, namely, landfalling hurricanes and extreme convective precipitation events, are investigated. Three models are trained based on hurricane events, heavy rainfall (i.e., nonhurricane) events, and all events combined in the southeast United States during 2015 and 2020. The impacts of different data sources on the nowcasting performance are quantified. The evaluation results of nowcasting products show that our SaGRU performs very well in predicting hurricane-induced rainfall. In the new methodology, the data from nonhurricane events are shown to provide useful information in enhancing the nowcasting performance during hurricane events as the model trained by combining all the hurricane and nonhurricane events has the best performance. In addition, this article quantifies the impact of the sequence length of input radar observations on the nowcasting performance, which shows that five consecutive observations are sufficient to obtain a stable model, and even two consecutive observations can produce reasonable results.\n\nI. INTRODUCTION\n\nA S ONE of the most typical high-impact weather phenomena, hurricane refers to tropical cyclones with maximum sustained surface winds reaching 74 miles/h [1], which often produces severe/serious hazards, such as storm surge, floods, strong winds, and hurricane-spawned tornadoes. Unfortunately, the risk of extensive damage and loss of life caused by hurricanes is increasing due to the growth of population, changing climate, and urbanization [2]. For instance, hurricane Harvey during August 25 and September 4, 2017 impacted 13 million people with over 100 fatalities. About 135 000 homes were damaged or destroyed, and the total damage was $125 billion [3]. In less than a week, the storm poured a year of rainfall over Houston and most of southeastern Texas. Two flood-control reservoirs had burst, causing water levels to rise throughout the Houston area. Therefore, the accurate nowcasting of hurricane intensity and subsequent rainfall is critical in high-impact weather studies and operational applications of weather radar and/or satellite observations.\n\nConventionally, the operational precipitation nowcasting strategies based on radar measurements attempt to predict future radar echo maps through leveraging extrapolation methods, which can be roughly classified into three categories: centroid tracking methods, tracking radar echoes by correlation (TREC), and optical flow [4], [5], [6]. The centroid tracking algorithms detect isolated storms at the current moment and try to link each storm across two successive time steps, then forecast storm progress using the centroid of the identified storm. As the storm was condensed into a centroid cell, it is easier for tracking and predicting massive and strong echoes. The other advantage of the centroid-type method is that it can provide physical information about each storm, such as storm area, top, and volume [7]. However, when the echoes are fused or split, the nowcasting accuracy decreases rapidly. In contrast, TREC estimates a motion field based on correlation analysis. It subdivides a radar image into numerous square boxes of equal size. Each box can be represented as a two-dimensional array containing reflectivity intensity values. Then the correlations between corresponding boxes at two consecutive radar images are calculated. The motion vector is calculated as the space shift that results in the highest correlation coefficient. Finally, these motion vectors can be used for nowcasting. The TREC algorithm involves calculating the spatial optimal correlation coefficients for two adjacent moments and then establishing a fitting relationship for all radar echoes. This method can effectively track stratiform rainfall systems, but the performance This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ Fig. 1. General concept of a deep learning precipitation nowcasting system. The input of the system can be radar reflectivity (Z), differential reflectivity (Z dr ), specific differential phase (K dp ), rain gauge data and/or environmental factors, such as terrain and NWP model outputs. The output is the prediction of precipitation.\n\nis much lower in predicting strong convective processes with fast-evolving echoes. Similarly, the optical flow approaches estimate a motion field (optical flow), but in a different way. Based on the principle of image pixel intensity conservation, the optical flow method assumes that the reflectivity intensity remains unchanged in the two adjacent frames. Essentially, it calculates the motion information of the reflectivity between adjacent frames by using the pixel change in the image sequence and the correlation between adjacent frames to discover the relationship of the previous frame and the current frame. Then, future echo maps can be extrapolated using semi-Lagrangian advection after the optical flow has been achieved. A major disadvantage of optical flow is that it cannot predict the initiation, growth, and decay of the storms.\n\nFor high-impact weather events, such as severe convective rain and hurricanes, it is difficult to use these conventional approaches to produce reliable nowcasting products since the inherent complexity of the changing atmospheric state and nonlinear cloud dynamics is high during such events and the assumption of stationarity between frames in the abovementioned methods is not valid [8], [9]. With the great success of deep learning techniques in a variety of fields, including geosciences and remote sensing research (e.g., [10], [11], [12], [13], [14], [15]), recent studies have proposed using this machine learning approach to tackle the precipitation nowcasting problem since the nonlinearity of machine learning can better model the spatiotemporal variability of precipitation [16], [17], [18], [19], [20]. As shown in Fig. 1, deep learning precipitation nowcasting can be performed based on polarimetric weather radar measurements, i.e., radar reflectivity (Z), differential reflectivity (Z dr ), and specific differential phase (K dp ). In situ measurements, as well as environmental factors, such as terrain feature, temperature, and numerical weather prediction (NWP) model outputs, can also be incorporated into the deep learning-based nowcasting frameworks.\n\nTo date, most of the deep learning nowcasting models rely on recurrent neural networks (RNN) since the radar echo extrapolation can be viewed as a sequence-to-sequence problem. A typical example is the convolutional long short-term memory (ConvLSTM) model developed by Shi et al. [17], which modeled precipitation nowcasting as a spatiotemporal serial prediction issue that can be solved with the sequence-to-sequence learning framework. However, training a practical model is difficult because of a large number of parameters in ConvLSTM. A more simplified convolutional gated recurrent unit (ConvGRU) model has been proposed for echo map extrapolation [21], which utilizes convolution kernels to deal with local neighborhood sets and reduce the number of parameters. Shi et al. [18] improved the nowcasting model using trajectory gated recurrent unit (TrajGRU), which carries out trajectory convolution between different time steps to capture the structure of spatiotemporal variations for recurrent connections. However, these features are estimated with the local receptive field and only provide sparse spatial dependencies thus can not obtain long-range dependencies efficiently. Compared to the trajectory convolution, the self-attention module is capable of capturing the global spatial variations with a single layer [22]. Besides, the features at the current time step can benefit from aggregating relevant features in the past. Lin et al. [23] introduced the self-attention memory (SAM) module into the ConvLSTM. However, their SAM and the inherent part of ConvLSTM have very high computational complexity in high-resolution input, which cannot meet the demand of nowcasting high-impact weather based on high-resolution radar data. As such, we develop the selfattention-based GRU as a backbone of the deep learning model designed in this study.\n\nSince the nowcasting model extracts features from the training dataset and then performs prediction using the learned features, data distribution, diversity, and quality are critical for deep learning. In fact, data are often considered the most important part of modern machine learning techniques. Unfortunately, few of the previous studies focused on quantifying the nowcasting performance for the model trained with diverse features during different types of precipitation events. In addition, the studies on extreme weather events, such as hurricanes are still rare, although some of the previous studies paid special attention to convective precipitation events [7], [17], [18], [24], [20]. As a result, the existing models do not have sufficient capacity for hurricane nowcasting due to the fast evolving of associated precipitation. The radar reflectivity of hurricanes is continually changing, and there are significant radial and azimuthal flow components in tropical cyclones, which impact the convective structure, suggesting that the nowcasting model must learn the features including both the movement, structure, and strength varieties of tropical cyclones at the same time.\n\nIn addition, hurricanes are less common compared to heavy rainfall events, indicating that there may not be sufficient data to train a mature hurricane nowcasting model solely based on hurricane observations. Since the high-impact convective precipitation events are also of our interest, and this type of event is relatively common, this study will quantify the impact of applying the model trained based on one set of intense rainfall events to a different type of high-impact weather events. In particular, we will investigate how to adjust the deep learning model for adaptive applications based on radar observations not only for hurricanes but also for (nonhurricane) extreme convective precipitation.\n\nThe main contributions of this article include the following. 1) We develop a self-attention-based gate recurrent unit (SaGRU) model for nowcasting high-impact weather events. 2) Radar data collected from heavy convective rainfall events in South Texas from 2015 to 2020, and 22 hurricane events over the United States during the same period are selected to train the deep learning models to quantify the impact of data sources on nowcasting performance. 3) We quantify the impact of the sequence length of input radar observations on the model performance, which can serve as a guideline for precipitation nowcasting research. The rest of this article is organized as follows. Section II describes the study domain, dataset, and nowcasting methodology used in this article. Section III details the application products during high-impact weather events and quantifies the nowcasting performance of the adapted deep learning model. In Section IV, a thorough discussion of the nowcasting performance is provided. Finally, Section V concludes this article.\n\n\nII. STUDY DOMAIN, DATASETS, AND METHODOLOGY\n\n\nA. Study Domain\n\nSouth Texas is selected for our study domain, which covers an area of about 600 \u00d7 600 km ranging from 26.5 \u2022 N-32.5 \u2022 N latitude to 93.5 \u2022 W-99.5 \u2022 W longitude. This area includes Greater Houston region, one of the most populous metropolitan regions in the United States. Fig. 2 shows the specific study domain along with an example of the radar reflectivity map collected during hurricane Harvey at 00:24 UTC, 26 August 2017. This region is within the humid subtropical climate zone, a typical climatology in Southern United States. During most of the year, prevailing winds are from the south and southeast, bringing heat and moisture [25]. The majority of South Texas areas receive ample rainfall in general, more than 60 inches (1500 mm) annually [26]. In addition, spring supercell thunderstorms sometimes bring tornadoes to the region, even though it is not in the Tornado Alley like much of Northern Texas. As a result, South Texas experiences a wide range of natural weather hazards, including urban fash flooding, high winds, tornadoes, and hailstorms. Furthermore, due to the flat terrain and low-permeability clay-silt prairie soils, flooding can easily be exacerbated, and there have been more flood-related deaths and property damage in this study domain than that in any other regions in the United States [27]. Accurate monitoring and prediction of the rapidly changing meteorological conditions in such a region is necessary for emergency management and decision-making. Therefore, it is an ideal location to study highimpact weather events and produce precipitation nowcasting.\n\n\nB. Dataset\n\nAs mentioned, this study uses the radar reflectivity mosaic data for deep learning-based precipitation nowcasting. Composite radar reflectivity images are produced at 6-min resolution using the National Weather Service (NWS) Weather Surveillance Radar-1988 Doppler (WSR-88D) systems in this region. Spatially, the reflectivity images are created at regular 1-km resolution grids, which means the number of pixels for the single image is 600 \u00d7 600. The three-dimensional data indicate precipitation patterns and their movement, and it is ideal for sequence modeling. In particular, we utilize the radar data collected during heavy precipitation events over this study domain from 2015 to 2020. The training and validation datasets are randomly selected from 2015 to 2020 (except 2017): 1348 days of data are used for training the deep learning model, 104 days are used as validation data to optimize the model parameters, and 290 days of precipitation data during 2017 are used for the independent test.\n\nIn addition, 22 hurricane events are used, which made landfall during 2015 and 2020. Here, it should be noted that the hurricane events are not limited to the region of South Texas, i.e., all the major hurricane events over the United States during 2015 and 2020 are included. Similar to the heavy precipitation events, 21 hurricane events are used for training and validation whereas hurricane Harvey is selected for independent test. In summary, we trained three models based on heavy precipitation events, hurricane events, and all events combined, respectively, to quantify the impact of data sources on the nowcasting performance.\n\n\nC. Methodology\n\nIn this section, the deep learning model utilized in this study is detailed, including data preprocessing, model structure, the essential components in model training and testing, as well as the nowcasting performance evaluation metrics.\n\n1) Data Preprocessing: First, since most of the days are characterized by clear air (i.e., no rain), the learned features Fig. 3. Overall framework of the applied high-impact weather nowcasting system. Essentially, the system is trained to predict future radar reflectivity echo maps based on few previous observations. M is the number of previous observations and N represents the length of the predictions of future images. will be dominated by these nonrain days if the model is trained based on all the data. To this end, only the days with rainfall occurring during 2015 and 2020 are selected and used, as suggested by [18] and NWS forecasters (personal communications). In addition, the filter process has taken into account the radar image sequences rather than a single image, since we need to ensure each data sequence contains adequate data samples with strong reflectivity for training a reliable sequence model. Since we also investigate the impact of the input sequence length on the nowcasting performance, the number of frames ranges from 32 to 40. Hence, the whole dataset is split into numerous sequences by a moving sequence sliding window from the start time (starting point of past observations) to the end time (nowcasting lead time). The number of grid points that have reflectivity higher than 35 dBZ is summed up for each sequence, and then divided by the sequence length to get the average number of qualified grid points for this sequence. If the average number is larger than 50, this sequence of radar reflectivity data will be selected for machine learning. After filtering all the sequences, the training dataset contains 463 602 sequences, and 31 883 sequences are used as the validation set to optimize the model parameters. In the testing stage, 87 571 sequences are used to evaluate the capacity of the trained models. Furthermore, the 87 571 testing samples are split into heavy precipitation events and hurricane events since a major goal is to quantify the nowcasting performance of the trained models during different precipitation events. All radar reflectivity data are transformed to [0,1] gray-level pixels by min-max normalization.\n\n2) Deep Learning Model Architecture: The work flow of the proposed deep learning model for high-impact weather nowcasting is shown in Fig. 3. As mentioned, the radar reflectivity images are first transformed to grayscale images, as described in Section II-C1, before being fed into the nowcasting model. The precipitation nowcasting system utilizes previous M steps of radar observations to predict the future N steps (at 6 min intervals).   Fig. 4 shows the overall structure of the expanded encoderdecoder structure, which includes four main parts: the RNN, upsample, down-sample, and convolution. Multiple layers of RNN were stacked to build an encoder-decoder structure, resulting in an end-to-end trainable model. The encoder part extracts hidden states from previous radar echo map observations, while the decoder part uses the hidden states to forecast future echo maps. In particular, the hidden state of the RNN serves as input to the next level to extract the spatiotemporal information of different levels. Down-sample and up-sample are implemented by convolution and deconvolution, respectively. The updating of the low-level states could be guided by the high-level states, which have captured the global spatiotemporal correlations. Furthermore, low-level states could have an impact on the nowcasting. The initial hidden state of encoder and the initial input of forecaster are 0 and the final output is regressed through a convolution layer.\n\nThe choice of the RNN unit is flexible. Originally, we used TrajGRU [18] as the baseline for nowcasting. Contrary to the abovementioned ConvLSTM and ConvGRU with fixed local neighborhood sets in the convolutional kernels, TrajGRU can dynamically determine the location-dependent spatiotemporal patterns. With the adaptive neighborhood in kernels, TrajGRU generates a flow field from the current input X t and previous hidden states H t\u22121 , and then warps H t\u22121 through bilinear sampling. The output of the TrajGRU base unit H t is given as follows:  \nu t , v t = \u03b3 (X t , H t\u22121 ) (1a) Z t = \u03c3 W xz * X t + L l=1 W l hz * warp(H t\u22121 ,u t,l ,v t,l ) (1b) R t = \u03c3 W xr * X t + L l=1 W l hr * warp(H t\u22121 ,u t,l ,v t,l ) (1c)H t = f W xh * X t +R t \u2022 L l=1 W l hh * warp(H t\u22121 ,u t,l , v t,l ) (1d) H t = (1\u2212Z t )\u2022H t + Z t \u2022H t\u22121 (1e)\nwhere u t , v t are the flow fields that store the local connection structure. \u03b3 is a one-hidden-layer convolutional neural network. L is the total number of allowed links. W denotes the weights of the convolutional kernel, * is the convolution operation and \u2022 is the Hadamard product. The warp function selects the positions pointed out by u t,l , v t,l from H t\u22121 and responsible to dynamically determine the recurrent connections. \u03c3 is sigmoid function and f is Leaky ReLU function. However, even the experimental results in [18] reveal that Tra-jGRU captures spatiotemporal correlations better than conventional extrapolation algorithms and some other deep learningbased algorithms, it still have the deficiency that cannot capture effective long-range dependencies. The success of self-attention on computer vision tasks [28], [29], [30] demonstrates its efficiency in aggregating major features across all spatial locations. It can identify long-range spatiotemporal correlations by calculating the pairwise relationships between various feature map positions using a binary relation function. Following that, these relations can be used to determine the attended features. As such, an SaGRU is developed to capture the global spatiotemporal features of the high-impact weather in this article. The SaGRU model is constructed by cascading self-attention module and the standard ConvGRU. Contrary to TrajGRU, SaGRU uses self-attention module to aggregate features from the current input X t and previous hidden states H t\u22121 . Then, the output of the SaGRU H t is obtained by the update gate Z t , the reset gate R t , and the aggregated features\u0124 t\u22121 , as shown in Fig. 5. The model is formulated as follows: \nX t = SA (X t ) ,\u0124 t\u22121 = SA (H t\u22121 ) (2a) Z t = \u03c3 W xz * X t + W hz * \u0124 t\u22121 + b z (2b) R t = \u03c3 W xr * X t + W hr * \u0124 t\u22121 + b r (2c)H t = tanh W xh * X t + R t \u2022 W hh * \u0124 t\u22121 + b h (2d) H t = (1 \u2212 Z t ) \u2022 H t + Z t \u2022\u0124 t\u22121 (2e)\nwhere SA represents the self-attention module.X t and\u0124 t\u22121 are the features aggregated from X t and H t\u22121 through self-attention modules. In particular, the location at attention module aggregates the input feature by calculating a weighted sum across all locations at each time step. This allows the long-range spatiotemporal dependencies can be captured during propagation cross our encoder-decoder structure. Fig. 6 shows the details of the self-attention module. The image features H t \u2208 R C\u00d7N from previous layers are transformed into three feature spaces f , g, v to calculate the dependencies\nacross different image regions, where f h = W f H t \u2208 R\u0108 \u00d7N , g h = W g H t \u2208 R\u0108 \u00d7N , v h = W v H t \u2208 R\u0108 \u00d7N .\nHere, C and\u0108 are the number of channels and we choose\u0108 = C/8 for memory efficiency. N is the number of feature locations from the previous hidden layer. W f , W g , and W v are the learnable weight matrices, which are implemented as 1 \u00d7 1 convolutions. We transpose f h and perform matrix multiplication to calculate the similarity scores between the ith point and the jth point as follows:\ns i,j = f (h i ) T g (h j ) .(3)\nAfter the softmax operation, the similarity scores are normalized as follows:\n\u03b2 i,j = exp (s i,j ) N i=1 exp (s i,j ) , i, j \u2208 {1, 2, . . . , N}.(4)\nThe attention of the input features is calculated with a weighted sum at all locations and the output of the attention layer is att = {att j \u2208 R\u0108}, j \u2208 {1, 2, . . . , N}, where\natt j = N i=1 \u03b2 i,j v (h i ) .(5)\nThen, the output of the attention layer will be added back to the input feature map. Therefore, the final output is given b\u0177\nH t = W h att + H t .(6)\n\n3) Hyperparameters and Loss Function:\n\nIn this study, we use a three-layer encoder-decoder architecture with the number of filters for the RNNs set to 64, 128, and 128, respectively. For the first RNN layer, the X t is 120 \u00d7 120 vector since the kernel size is 7 \u00d7 7, padding is 1 and strides are 5 for the first convolution layer. The first down-sampling is implemented by the convolutional layer with 5 \u00d7 5 kernel size, padding 1, strides 3, and the kernel size is 3 \u00d7 3, padding is 1 and strides are 2 for the second down-sampling. Thus, the X t for second RNN and third RNN layer is 40 \u00d7 40 and 20 \u00d7 20. Similarly, the first and second up-sampling is implemented by deconvolution with 5 \u00d7 5 kernel size, padding 1, strides 3, and 4 \u00d7 4 kernel size, padding 1, strides 2. For the self-attention module in SaGRU, the kernal size of convolutions is 1 \u00d7 1 as mentioned in Section II-C2. All the models are optimized by the Adam optimizer with learning rate of 10 \u22124 and momentum of 0.5 [31]. The learning rate of each parameter group decays by gamma 0.5 once the number of epochs reaches the milestones of 10 000, 30 000, 90 000. The training batch size is set as 3 and the maximum iteration is set to 300 000. All experiments are implemented using the PyTorch platform [32].\n\nIt should be pointed out that since the frequencies of different rainfall intensities are highly imbalanced, especially during high-impact weather events, such as hurricanes, this research utilizes two weighted loss functions termed balanced mean squared error (B-MSE) and balanced mean absolute error (B-MAE), defined as follows:\nw(x) = \u23a7 \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23a8 \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23a9 1 0 \u2264 x < 10 1 10 \u2264 x < 20 5 20 \u2264 x < 30 10 30 \u2264 x < 35 30 35 \u2264 x < 40 30 40 \u2264 x < 50 35 x > 50 \u23ab \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23ac \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23aa \u23ad (7a) B-MSE = 1 N N n=1 i=600 i=1 j=600 j=1 w n,i,j (x n,i,j \u2212 x n,i,j ) 2 (7b) B-MSE = 1 N N n=1 i=600 i=1 j=600 j=1 w n,i,j |x n,i,j \u2212 x n,i,j |(7c)\nwhere x and x represent the real and predicted reflectivity, respectively; N is the sample number; w n,i,j is the weight corresponding to the (i, j)th reflectivity value in the nth training data.\n\n\n4) Model Evaluation:\n\nTo evaluate the performance of precipitation nowcasting products, this article adopts four widely used metrics, namely, Heidke skill score (HSS), critical success index (CSI), probability of detection (POD), and false alarm rate (FAR). The values of POD, FAR, HSS, and CSI are all between 0 and 1. Higher POD, HSS, CSI, or lower FAR indicate better nowcasting performance. Since HSS and CSI are more integrated metrics, they are direct indicators of the model capacity. In addition, for better interpretation of the nowcasting performance at different rainfall intensities, the evaluation metrics are computed using a number of reflectivity thresholds, including For each threshold, we compare the nowcasting product with the corresponding ground truth by transforming both reflectivity fields into binary matrices. In particular, if the reflectivity at a grid pixel is higher than the threshold, \"1\" is assigned to this grid pixel, otherwise a \"0\" will be assigned. where true positive (TP) is the number of grid points which are assigned \"1\" for both nowcasting product and corresponding ground truth; false negative (FN) is the number of grid points which are assigned \"0\" for the nowcasting product, but \"1\" for the ground truth; true negative (TN) is the number of grid points which are assigned \"0\" for both nowcasting product and corresponding ground truth; and false positive (FP) represents the number of grid points, which are assigned \"1\" for the nowcasting product, but \"0\" for the ground truth.\n\n\nIII. EXPERIMENTAL RESULTS\n\nAs mentioned, heavy rainfall events occurred in South Texas and 22 hurricane events that made landfall in the U.S. during 2015-2020 are used in this study. In particular, the heavy rainfall events and hurricane Harvey in 2017 are selected for testing, while other data are utilized for model training. To quantify the influence of different training data sources on high-impact weather nowcasting performance, three models are trained based on hurricane events, (nonhurricane) heavy rainfall events, and all events combined, respectively.\n\nIn addition, extensive experiments are performed using different sequence lengths of input radar observations in the nowcasting models, ranging from 2 to 10 time frames. This is to quantify the impact of input sequence length on the nowcasting performance, so as to provide guidelines on how many radar observations would be required to train a deep learning model for high-impact weather nowcasting. In this section, example nowcasting products based on five historical radar observation frames are illustrated to demonstrate the nowcasting performance. Fig. 7 shows the practical examples of 30-min (valid at 09:06 UTC) and 60-min (valid at 09:36 UTC) precipitation nowcasting results during a severe convective rainfall event in the study domain issued at 08:36 UTC, August 08, 2017. In Fig. 7, both the nowcasting results from three different models and the corresponding observations are illustrated. Overall, all the three models can predict the overall pattern and distributions of rainfall. However, scrutinizing the detailed structure of the nowcasting results, it is found that the model trained purely based on hurricane data significantly underestimates the precipitation intensity during this severe convective event. For the area where the reflectivity values are larger than 45 dBZ, the patterns are inconstant with the real observation. In addition, some small rainfall regions are missed by this model [see Fig. 7(b) and (f)]. This is likely due to the insufficiency of hurricane data (only 21 events) in capturing heavy rain features in this particular domain. In addition to the limited amount of data for model training, location representation could be an issue that limits the nowcasting performance as most of the hurricane events were spanning a much larger domain beyond the State of Texas. In contrast, the model trained based on nonhurricane events predicts the precipitation distribution more precise than the hurricane model, especially at lead times of 60 min. However, compared to the model trained based on combined events, it still has a deficiency of underestimation when reflectivity values are larger than 50 dBZ [see Fig. 7(g) and (h)]. In general, the combined model can not only capture the precipitation patterns, but also predict the precipitation intensity well. Fig. 8 illustrates the nowcasting products at lead times of 30 min (valid at 00:54 UTC) and 60 min (valid at 01:24 UTC) during hurricane Harvey issued at 00:24 UTC, August 26, 2017. It is found that all the three models can capture the structure of the tropical cyclone and predict the overall distribution of precipitation intensity at lead times of 30 min. Being trained on the hurricane events, the hurricane model can provide more plausible details in terms of the cyclone structure, especially near the eye wall relative to the other nowcasting models. However, it tends to underestimate the precipitation intensity, produce wrong pattern in the outer spiral rainband and still miss some small rainfall regions around the tropical cyclone. Surprisingly, although the models trained using nonhurricane data and combined data tend to provide a smoother structure of the cyclone, both can predict higher rainfall intensity near the outer rainband, which is more consistent with real observations in Fig. 8(a) and (e).\n\nThe quantitative evaluation results of the 60-min nowcasting products using the three models based on all the test data during heavy rain events are summarized in Fig. 9, where the best nowcasting skill scores are indicated in bold. In order to highlight the nowcasting performance for different rainfall intensities, three thresholds, namely, 20, 30, and 40 dBZ, are applied in calculating the skill scores. Fig. 9 indicates that during (nonhurricane) heavy rain events, the model trained using hurricane data has a rather poor performance, especially for nowcasting convective cores, which have reflectivity higher than 40 dBZ. This is consistent with the examples shown in Figs. 7 and 8. The models developed using nonhurricane data or combined data have similar performance in terms of all skill scores, and both are better than the model trained using only hurricane data. In particular, the model trained using combined data has slightly better skill scores compared to the model trained using nonhurricane data. This is encouraging since including the features learned from hurricane data did not bring any negative impact on the performance of the combined model. In addition, when the reflectivity threshold increases from 20 to 40 dBZ, the performance of all models drops slightly. As expected, predicting heavy rain storm cores is more challenging than predicting weaker rain regions.\n\nSimilarly, Fig. 10 presents the nowcasting skill scores during the test hurricane event. It can be seen that the model trained using hurricane data delivers competitive results in terms of FAR, CSI, and HSS. Compared to model based on hurricane data, the model trained using nonhurricane data and combined data has slightly worse FAR, especially when the reflectivity threshold is low. Considering that FAR is an indicator of underestimating the rainy areas, the model based on hurricane data delivers a better precipitation pattern, although the intensity is underpredicted (see Fig. 8). The model based on nonhurricane events has slightly better POD, CSI, and HSS scores, and the skill gaps between these two models are even larger when the reflectivity threshold is higher. The model trained using combined data renders the best performance among the three models. These results indicate that precipitation features learned from heavy convective precipitation events can be used to enhance hurricane nowcasting. On the other hand, including features learned from hurricane events has no negative impact on nowcasting (nonhurricane) heavy rain events.\n\nFor completeness, Fig. 11 shows the CSI scores as a function of lead time up to three hours for the nowcasting model trained using combined data when applied to the test heavy rain and hurricane events. As expected, the performance will decrease for both heavy rain and hurricane events as the nowcasting lead time increases. For heavy rain events, the differences of CSI scores are quite small when different reflectivity thresholds are used, demonstrating that the performance of the nowcasting model is stable for different rainfall intensities. For hurricane events, the CSI score is relatively low when a reflectivity threshold of 40 dBZ is used, indicating the challenge of predicting heavy rain bands during hurricane events. Nevertheless, when a lower reflectivity threshold is used, the CSI scores are much higher. In addition, the CSI scores during hurricane events are higher than those during heavy rain events. Even for the lead time of 180 min, the CSI score is about 0.4, which is among the best results available in the literature (e.g., [6], [7], [20]).\n\n\nIV. DISCUSSION\n\n\nA. Impact of Diverse Training Data on the Nowcasting Performance\n\nAlthough the products and quantitative evaluation results demonstrated the effectiveness and superiority of deep learning in high-impact weather nowcasting, especially its capability of capturing the spatiotemporal evolution of severe precipitation systems, it should be noted that generalization capability of the nowcasting model still requires further investigation. It is well known that the performance of deep learning models is highly dependent on the quality and distribution of the training dataset.\n\nIn the training stage, if some data samples are significantly different from the overall distribution of the training data, the trained model will learn the features from these \"outliers\" (e.g., extreme events) resulting from natural variability and exhibit a worse performance than the one trained based on the dataset without these extreme events.\n\nThrough this article, we aim to provide a reference about how to select training data for short-term prediction of heavy rain, with an emphasis on hurricane events. It is encouraging that the model trained by combining hurricane and (nonhurricane) heavy rain events has better performance than the model trained solely based on hurricane data or heavy rain events. This is noteworthy since the hurricane events are rare compared to heavy rainfall events. There may not be sufficient data for training a mature hurricane nowcasting model only based on hurricane observations. This is demonstrated by the surprising results that the model trained using 21 hurricane events is not significantly better (in fact some of the scores are even slightly worse) than the one trained only using heavy convective precipitation events during hurricane applications. In other words, the rainfall features learned from heavy rain events can largely represent the characteristics of rainfall associated with hurricanes, which is critical for hurricane nowcasting.\n\nIn addition, our experimental results show that the model based on combined data provides slightly better results than the model trained without including hurricane data during nonhurricane events. This is different from our assumption that involving hurricane events in the training stage may compromise the model capacity for applications during nonhurricane events. In fact, the features learned from hurricane events could even enhance the overall nowcasting model performance. Combining data from diverse precipitation events in training the deep learning model is strongly suggested, especially when there is a lack of sufficient data for model training.\n\nDespite the positive performance results, a few relevant issues should be considered in the general application of the developed deep learning model. First, all the three models tend to smooth and fuse the structure of tropical cyclones and underestimate the tail of heavy rainfall regions, especially at longer nowcasting lead time. This is mainly because the implementation of convolutional and pooling processes, which involves computation based on adjacent observations. In addition, the model always underestimates heavy rainfall regions as the lead time increases even after we incorporate the sequences containing strong precipitation echoes and adjust the weights for different precipitation intensity. A possible solution is to further increase the weights for reflectivity values larger than 35 dBZ. Further, more hurricane events should also be utilized for training, including those in other regions, in order to train a mature deep learning model that is more broadly applicable [19]. Another issue is about the model extension, i.e., the inclusion of additional factors in the nowcasting model. For example, including dual-polarization radar observables, such as Z dr and K dp can potentially improve the nowcasting performance as more precipitation microphysical information can be gleaned from polarimetric radar data [20].\n\n\nB. Impact of Radar Observation Sequence Length on the Nowcasting Performance\n\nAs mentioned in Section II-C2, it can take a long time to train a reliable nowcasting model using long sequences (i.e., large number of M in Figs. 3 and 4) of past radar observations due to the high computational cost, especially when the training dataset is large. It is critical to quantify the number of past radar observations required to train the forecast model for high-impact weather applications. To provide a guideline on how many past observation frames we should use, we have trained nine models with different number of M, ranging from 2 to 10. Note that all the nine models are trained using combined data including hurricane and nonhurricane heavy rain events. For illustration purposes, Fig. 12 shows the skill scores of 60-min nowcasting products from the nine models when applied during hurricane events. Again, different reflectivity thresholds are used when computing the scores in order to further evaluate the model performance for predicting rainfall with different intensities. With a reflectivity threshold of 20 dBZ, it can be seen that smaller M has relatively high POD but also higher FAR, indicating that the models trained based on fewer past radar observations generate too many precipitation pixels (i.e., rain area is over predicted). The two integrated metrics, CSI and HSS, both show an increasing trend as the number of past radar observations increases, suggesting that larger M will produce better performance. When a reflectivity threshold of 30 dBZ is used, the POD scores exhibit a relatively flat line with some variability for M \u2265 5, indicating that the POD is relatively insensitive to M at the 30 dBZ threshold. Similarly, FAR, HSS, and CSI are relatively stable for M \u2265 5 while they present a growing trend when M \u2264 5. This trend is much clearer if a reflectivity threshold of 40 dBZ is used. With a 40 dBZ threshold, it is also apparent that when M > 8 the model performance can get slightly worse, especially in terms of the FAR and CSI scores.\n\nBased on these experimental results, we conclude that the nowcasting model can learn more features when more past radar observations are considered. The improvement is more significant for nowcasting weak-moderate rain with relatively low reflectivity. However, this does not mean that the longer sequence we use, the better performance we would get, especially for heavy rain nowcasting as the models trained based on more past observations are not stable. This is mainly because the life cycle of severe convective storm cells is short, and heavy rain regions can be initiated or disappear in a short amount of time due to the complex atmospheric state and the complex nonlinear cloud dynamics that occur in these events. More past radar observations contain too much of these changes, which cannot be effectively learned by the nowcasting model, not to mention that it will need more parameters and time to train. It is also encouraging that even two consecutive radar observations can yield an acceptable result, indicating that our deep learning model can learn the features of the motion field efficiently. This finding demonstrates that the deep learning model helps solve the issue of fast-changing conditions in extreme weather. In short, the sensitivity analysis suggests that five past radar observations are the optimal choice for training a reliable deep learning model for high-impact weather nowcasting. Although the model trained based on five past observations may not provide the best performance all the time, the model is easy to train and very stable in generating reliable nowcasting results. It should be pointed out that the experiment can be extended by incorporating other precipitation systems from different climate regimes to provide more generalized guidelines, which will be included in future work.\n\n\nV. SUMMARY\n\nAccurate nowcasting of high-impact weather, such as hurricanes and other heavy rain events, can support severe weather warnings and emergency management decision-making. Although some previous studies focused on convective precipitation nowcasting, there are very few studies that focus on high-impact weather events, such as hurricanes. This article has developed a deep learning-based nowcasting system and introduced the self-attention module to the GRU for extreme weather events. Five years of radar observations (2015-2020) over South Texas and 22 hurricane events that made landfall in the United States during 2015-2020 are used for training, validation, and testing of the deep learning models. In particular, three models trained based on hurricane events, (nonhurricane) heavy rain events, and all events combined are utilized to quantify the impact of diverse training data on the nowcasting system. In addition, a number of experiments are conducted to investigate the required number of past radar observations for training the nowcasting models. The main conclusions of this article include the following.\n\n1) Visually, all the three fine-tuned models can capture the precipitation patterns and distribution fairly well. However, the model trained purely based on hurricane events tends to underestimate the high-reflectivity regions during both heavy rain events and hurricane events. Nevertheless, it provides plausible details about the cyclone structure during hurricane event. The (nonhurricane) heavy rainfall and combined models can not only predict the precipitation patterns well but also the precipitation intensity, even though they tend to smooth and fuse the echoes during hurricane events. 2) The evaluation results of the three models reveal that precipitation features learned from heavy convective precipitation events can be utilized to improve hurricane nowcasting and the features learned from hurricane events have no negative impact on nowcasting (nonhurricane) heavy rain events. Therefore, it is strongly recommended that data from different precipitation systems be combined in training the deep learning model, especially when there is a dearth of data for machine learning model training.\n\n3) The high CSI scores indicate the stable performance of the nowcasting model trained based on the combined data for lead times up to 3 h. In addition, the CSI scores are higher than those reported in the literature (e.g., [6], [7], and [20]). 4) To quantify the impact of sequence length of past radar observations for precipitation nowcasting, nine models are trained with different numbers of past radar observation (2)(3)(4)(5)(6)(7)(8)(9)(10). Considering the balance of computational cost and nowcasting performance, five consecutive observations are an optimal choice to yield a reliable model for nowcasting during high-impact weather events. In future, a more detailed investigation of the nowcasting performance in the scenarios of storm initiation, growth, and decay will be performed.\n\nFig. 2 .\n2Selected study domain during hurricane Harvey event at 00:24 UTC, 26 August 2017. The color bar stands for radar composite reflectivity.\n\n\nFor one iteration, we have a sequence of consecutive real observations as ground truths GT(1, 2, ... M, M+1, . . . M+N). Then this sequence is split into two parts in the training stage. The previous GT(1, 2. . . M) observations are fed into the nowcasting model to get the predictions P(M+1, . . . M+N) of future observations. In the training stage, the predictions P(M+1, . . . M+N) are compared with ground truth GT(M+1, . . . M+N) to adjust the weights in the nowcasting model for the next iteration. It should be emphasized that various values of M have been tested to quantify the required number of past radar observations for training and applying the nowcasting model. There is a tradeoff issue here since a larger number of steps M requires more parameters and time to train the model, although we would expect more precipitation information content from a longer observation sequence. On the other hand, a shorter sequence (i.e., smaller M) may contain less features of precipitation, but it is easier to train. Results from multiple experiments for different M are described in Section IV-B. N is an adjustable variable up\n\nFig. 4 .\n4Structure of encoder-decoder module, illustrated in Fig. 3. to 30. That is, the deep learning model can produce nowcasting results for a lead time up to 3 h. For the results in Section III, M = 5 and N = 30 are primarily used to quantify the nowcasting performance, i.e., previous 30-min radar observations are used to predict observations of future 3 h.\n\nFig. 5 .\n5Basic unit of RNN (SaGRU\n\nFig. 6 .\n6Proposed self-attention module for SaGRU. H t is the image features from the hidden layer at the time step t. f h , g h , and v h are the three different feature spaces based on the 1 \u00d7 1 convolution on the H t .\u0124 t is the output.\n\nFig. 7 .\n7Example of 30-min (valid at 09:06 UTC) and 60-min (valid at 09:36 UTC) nowcasting results issued at 08:36 UTC on 08 August 2017: (a), (e) Radar observation (ground truth). (b), (f) Hurricane model. (c), (g) Nonhurricane model. (d), (h) Combined model. 20, 30, 40 dBZ.\n\nFig. 8 .\n8Example of 30-min (valid at 00:54 UTC) and 60-min (valid at 01:24 UTC) nowcasting results issued at 00:24 UTC on 26 August 2017: (a), (e) Radar observation (ground truth). (b), (f) Hurricane model. (c), (g) Nonhurricane model. (d), (h) Combined model.\n\nFig. 9 .\n9Skill scores of the three models during heavy precipitation events at 60-min lead time. The best results are marked with bold face. (a) POD. (b) FAR. (c) CSI. (d) HSS.\n\nFig. 10 .\n10Skill scores of the three models during hurricane events at 60-min lead time. The best results are marked with bold face. (a) POD. (b) FAR. (c) CSI. (d) HSS.\n\nFig. 11 .\n11CSI values of combined model with lead time up to 180 min during two high-impact weather events. (a) Heavy rain events. (b) Hurricane events.\n\nFig. 12 .\n12Skill scores for different lengths of past radar observation sequence used for nowcasting during hurricane events. The nowcasting lead time in this example is 60-min. (a) POD. (b) FAR. (c) CSI. (d) HSS.\n\n\n). Current Input X t and previous hidden states H t\u22121 are served as input, reset gate R t and update gate Z t are used to control the current hidden state H t .\nACKNOWLEDGMENTThe authors gratefully acknowledge the support of NVIDIA Corporation with the donation of GPU used for this research. We would also like to thank Dr. Nachiketa Acharya (NOAA/PSL and CU/CIRES) and anonymous external reviewers for providing careful review and comments on this article. The radar data used in this article were obtained from the National Centers for Environmental Information (NCEI). The intermediate products, such as the precipitation features in training the deep learning models and model parameters are available upon request.She is a Research Meteorologist studying physical processes in the atmosphere, upper ocean, and the air-sea interface. She collects and analyzes measurements of the ocean, air-sea fluxes, and atmosphere to understand the coevolution of atmospheric and oceanic boundary layers. This has included research on precipitation microphysics, and how rain, wind, and sunlight control upper ocean stability. She is currently assessing how such ocean variability relate to the growth or inhibition of clouds and precipitation. Her research focuses on dual-and single-polarization radars, satellites, disdrometers, as well as ocean and air-sea flux instrumentation deployed on ships and autonomous platforms. She has developed algorithms for predicting near-surface ocean stability, estimating precipitation rate from radar, and classifying precipitation type in clouds with radar. Her research activities contribute to greater fundamental understanding of how the ocean and atmosphere interact via processes,such as turbulence, cloud microphysics, precipitation extremes, the global water cycle, atmospheric thermodynamics, ocean stratification, and meteorological phenomena on synoptic-and meso-scales. Her research products support the improvement and evaluation of environmental prediction models, diagnostic nowcasting tools, and operational datasets used to monitor the ocean and atmosphere.Robert Cifelli received the bachelor's degree in geology from the University of Colorado Boulder, Boulder, CO, USA, in 1983, the M.S. degree in hydrogeology from West Virginia University, Morgantown, WV, USA, in 1986, and the Ph.D. degree in atmospheric science from Colorado State University, Fort Collins, CO, in 1996.He is a Radar Meteorologist with more than 25 years of experience in precipitation research and more than 70 publications in peer-reviewed journals. Since 2009, he has been leading NOAA scientists dedicated to improving precipitation and hydrologic prediction in complex terrain and other geographic regions. He currently leads the Hydrometeorology Modeling and Applications Team in the NOAA Physical Sciences Laboratory, Boulder. A major focus of HMA is to improve understanding of physical processes associated with too much and too little water, including forcings for NOAA's National Water Model and to guide future model development. He completed a detail with the Bureau of Reclamation in 2016 through the President's Management Council Interagency Rotation Program to improve weather, climate, and water forecasts of extreme events to better meet water management needs. He also completed a separate detail with NOAA's Office of Water Prediction in 2017 to advance NOAA's hydrologic prediction capabilities.\nHurricane basics. Nat. Ocean. Atmospheric Admin. 18National Hurricane Center Public AffairsNational Hurricane Center Public Affairs, \"Hurricane basics,\" Nat. Ocean. Atmospheric Admin., 1999, Art. no. 18 .\n\nGlobal trends in tropical cyclone risk. P Peduzzi, Nat. Climate Change. 2P. Peduzzi et al., \"Global trends in tropical cyclone risk,\" Nat. Climate Change, vol. 2, pp. 289-294, 2012.\n\nHurricane harvey (AL092017). E S Blake, D A Zelinsky, Tropical Cyclone Report. E. S. Blake and D. A. Zelinsky, \"Hurricane harvey (AL092017),\" Miami- Dade County, FL, USA, National Hurricane Center, Tropical Cyclone Report, 2018. [Online]. Available: https://www.nhc.noaa.gov/data/tcr/ AL092017_Harvey.pdf\n\nTITAN: Thunderstorm identification, tracking, analysis, and nowcasting-a radar-based methodology. M Dixon, G Wiener, J. Atmos. Ocean. Technol. 106M. Dixon and G. Wiener, \"TITAN: Thunderstorm identification, tracking, analysis, and nowcasting-a radar-based methodology,\" J. Atmos. Ocean. Technol., vol. 10, no. 6, pp. 785-797, Dec. 1993.\n\nThree-dimensional storm motion detection by conventional weather radar. R Rinehart, E Garvey, Nature. 2735660R. Rinehart and E. Garvey, \"Three-dimensional storm motion detection by conventional weather radar,\" Nature, vol. 273, no. 5660, pp. 287-289, 1978.\n\nDevelopment of a precipitation nowcasting algorithm based upon optical flow techniques. N E Bowler, C E Pierce, A Seed, J. Hydrol. 2881/2N. E. Bowler, C. E. Pierce, and A. Seed, \"Development of a precipitation nowcasting algorithm based upon optical flow techniques,\" J. Hydrol., vol. 288, no. 1/2, pp. 74-91, 2004.\n\nConvective precipitation nowcasting using U-Net model. L Han, H Liang, H Chen, W Zhang, Y Ge, IEEE Trans. Geosci. Remote Sens. 60Art. no. 4103508L. Han, H. Liang, H. Chen, W. Zhang, and Y. Ge, \"Convective precipitation nowcasting using U-Net model,\" IEEE Trans. Geosci. Remote Sens., vol. 60, 2022, Art. no. 4103508.\n\n3 D convective storm identification, tracking, and forecasting-an enhanced titan algorithm. L Han, S Fu, L Zhao, Y Zheng, H Wang, Y Lin, J. Atmos. Ocean. Technol. 264L. Han, S. Fu, L. Zhao, Y. Zheng, H. Wang, and Y. Lin, \"3 D convective storm identification, tracking, and forecasting-an enhanced titan algo- rithm,\" J. Atmos. Ocean. Technol., vol. 26, no. 4, pp. 719-732, 2009.\n\nCASA prediction system over dallas-fort worth urban network: Blending of nowcasting and highresolution numerical weather prediction model. C Radhakrishnan, V Chandrasekar, J. Atmos. Ocean. Technol. 372C. Radhakrishnan and V. Chandrasekar, \"CASA prediction system over dallas-fort worth urban network: Blending of nowcasting and high- resolution numerical weather prediction model,\" J. Atmos. Ocean. Tech- nol., vol. 37, no. 2, pp. 211-228, 2020.\n\nSpatial pyramid pooling in deep convolutional networks for visual recognition. K He, X Zhang, S Ren, J Sun, IEEE Trans. Pattern Anal. Mach. Intell. 379K. He, X. Zhang, S. Ren, and J. Sun, \"Spatial pyramid pooling in deep convolutional networks for visual recognition,\" IEEE Trans. Pattern Anal. Mach. Intell., vol. 37, no. 9, pp. 1904-1916, Sep. 2015.\n\nFully convolutional networks for semantic segmentation. J Long, E Shelhamer, T Darrell, Proc. IEEE Conf. Comput. Vis. Pattern Recognit. IEEE Conf. Comput. Vis. Pattern RecognitJ. Long, E. Shelhamer, and T. Darrell, \"Fully convolutional networks for semantic segmentation,\" in Proc. IEEE Conf. Comput. Vis. Pattern Recognit., 2015, pp. 3431-3440.\n\nGenerative adversarial nets. I Goodfellow, Adv. Neural Inf. Process. Syst. I. Goodfellow et al., \"Generative adversarial nets,\" Adv. Neural Inf. Pro- cess. Syst., pp. 2672-2680, 2014.\n\nRainfall estimation from ground radar and TRMM precipitation radar using hybrid deep neural networks. H Chen, V Chandrasekar, H Tan, R Cifelli, Geophys. Res. Lett. 4617H. Chen, V. Chandrasekar, H. Tan, and R. Cifelli, \"Rainfall estimation from ground radar and TRMM precipitation radar using hybrid deep neural networks,\" Geophys. Res. Lett., vol. 46, no. 17/18, pp. 10669-10678, Sep. 2019.\n\nDeep learning for polarimetric radar quantitative precipitation estimation during landfalling typhoons in South China. Y Zhang, Remote Sens. 1316Y. Zhang et al., \"Deep learning for polarimetric radar quantitative precip- itation estimation during landfalling typhoons in South China,\" Remote Sens., vol. 13, no. 16, 2021, Art. no. 3157.\n\nA machine learning system for precipitation estimation using satellite and ground radar network observations. H Chen, V Chandrasekar, R Cifelli, P Xie, IEEE Trans. Geosci. Remote Sens. 582H. Chen, V. Chandrasekar, R. Cifelli, and P. Xie, \"A machine learning system for precipitation estimation using satellite and ground radar net- work observations,\" IEEE Trans. Geosci. Remote Sens., vol. 58, no. 2, pp. 982-994, Feb. 2020.\n\nMask R-CNN. K He, G Gkioxari, P Doll\u00e1r, R Girshick, Proc. IEEE Int. Conf. Comput. Vis. IEEE Int. Conf. Comput. VisK. He, G. Gkioxari, P. Doll\u00e1r, and R. Girshick, \"Mask R-CNN,\" in Proc. IEEE Int. Conf. Comput. Vis., 2017, pp. 2980-2988.\n\nConvolutional LSTM network: A machine learning approach for precipitation nowcasting. X Shi, Z Chen, H Wang, D.-Y Yeung, W.-K Wong, W.-C Woo, Proc. Adv. Neural Inf. Process. Syst. Adv. Neural Inf. ess. SystX. Shi, Z. Chen, H. Wang, D.-Y. Yeung, W.-K. Wong, and W.-c. Woo, \"Convolutional LSTM network: A machine learning approach for pre- cipitation nowcasting,\" in Proc. Adv. Neural Inf. Process. Syst., 2015, pp. 802-810.\n\nDeep learning for precipitation nowcasting: A benchmark and a new model. X Shi, Proc. Adv. Neural Inf. Process. Syst. Adv. Neural Inf. ess. SystX. Shi et al., \"Deep learning for precipitation nowcasting: A bench- mark and a new model,\" in Proc. Adv. Neural Inf. Process. Syst., 2017, pp. 5618-5628.\n\nAdvancing radar nowcasting through deep transfer learning. L Han, Y Zhao, H Chen, V Chandrasekar, IEEE Trans. Geosci. Remote Sens. 60Art. no. 4100609L. Han, Y. Zhao, H. Chen, and V. Chandrasekar, \"Advancing radar now- casting through deep transfer learning,\" IEEE Trans. Geosci. Remote Sens., vol. 60, 2022, Art. no. 4100609.\n\nImproving nowcasting of convective development by incorporating polarimetric radar variables into a deep-learning model. X Pan, Y Lu, K Zhao, H Huang, M Wang, H Chen, Geophysical Res. Lett. 4821Art. no. e2021GL095302X. Pan, Y. Lu, K. Zhao, H. Huang, M. Wang, and H. Chen, \"Improving nowcasting of convective development by incorporating polarimetric radar variables into a deep-learning model,\" Geophysical Res. Lett., vol. 48, no. 21, 2021, Art. no. e2021GL095302.\n\nPredRNN: Recurrent neural networks for predictive learning using spatiotemporal LSTMs. Y Wang, M Long, J Wang, Z Gao, P S Yu, Proc. 31st Int. Conf. Neural Inf. Process. Syst. 31st Int. Conf. Neural Inf. ess. SystY. Wang, M. Long, J. Wang, Z. Gao, and P. S. Yu, \"PredRNN: Recurrent neural networks for predictive learning using spatiotemporal LSTMs,\" in Proc. 31st Int. Conf. Neural Inf. Process. Syst., 2017, pp. 879-888.\n\nAttention is all you need. A Vaswani, Proc. 31st Int. Conf. Neural Inf. Process. Syst. 31st Int. Conf. Neural Inf. ess. SystA. Vaswani et al., \"Attention is all you need,\" in Proc. 31st Int. Conf. Neural Inf. Process. Syst., 2017, pp. 6000-6010.\n\nSelf-attention convlstm for spatiotemporal prediction. Z Lin, M Li, Z Zheng, Y Cheng, C Yuan, Proc. AAAI Conf. AAAI ConfZ. Lin, M. Li, Z. Zheng, Y. Cheng, and C. Yuan, \"Self-attention convlstm for spatiotemporal prediction,\" in Proc. AAAI Conf. Artif. Intell., 2020, pp. 11531-11538.\n\nDeeprain: Convlstm network for precipitation prediction using multichannel radar data. S Kim, S Hong, M Joh, S.-K Song, Proc. 7th Int. Workshop Climate Informat. 7th Int. Workshop Climate InformatS. Kim, S. Hong, M. Joh, and S.-K. Song, \"Deeprain: Convlstm network for precipitation prediction using multichannel radar data,\" in Proc. 7th Int. Workshop Climate Informat., Sep. 20-22, 2017, pp. 1-4.\n\nExtreme rainfall in texas: Patterns and predictability. J W Nielsen-Gammon, F Zhang, A M Odins, B Myoung, Phys. Geogr. 265J. W. Nielsen-Gammon, F. Zhang, A. M. Odins, and B. Myoung, \"Extreme rainfall in texas: Patterns and predictability,\" Phys. Geogr., vol. 26, no. 5, pp. 340-364, 2005.\n\nCatastrophic rainfall and flooding in texas. J A Smith, M L Baeck, J E Morrison, P Sturdevant-Rees, J. Hydrometeorol. 11J. A. Smith, M. L. Baeck, J. E. Morrison, and P. Sturdevant-Rees, \"Catas- trophic rainfall and flooding in texas,\" J. Hydrometeorol., vol. 1, no. 1, pp. 5-25, 2000.\n\nAnalysis of flood fatalities in texas. H Sharif, T Jackson, M Hossain, D Zane, Natural Hazards Rev. 1604014016H. Sharif, T. Jackson, M. Hossain, and D. Zane, \"Analysis of flood fatalities in texas,\" Natural Hazards Rev., vol. 16, 2015, Art. no. 0 4014016.\n\nSelf-attention generative adversarial networks. H Zhang, I Goodfellow, D Metaxas, A Odena, Proc. Int. Conf. Mach. Learn. Int. Conf. Mach. LearnH. Zhang, I. Goodfellow, D. Metaxas, and A. Odena, \"Self-attention generative adversarial networks,\" in Proc. Int. Conf. Mach. Learn., 2019, pp. 7354-7363.\n\nExploring self-attention for image recognition. H Zhao, J Jia, V Koltun, Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit. IEEE/CVF Conf. Comput. Vis. Pattern RecognitH. Zhao, J. Jia, and V. Koltun, \"Exploring self-attention for image recog- nition,\" in Proc. IEEE/CVF Conf. Comput. Vis. Pattern Recognit., 2020, pp. 10073-10082.\n\nStand-alone self-attention in vision models. P Ramachandran, N Parmar, A Vaswani, I Bello, A Levskaya, J Shlens, Adv. Neural Inf. Process. Syst. 32P. Ramachandran, N. Parmar, A. Vaswani, I. Bello, A. Levskaya, and J. Shlens, \"Stand-alone self-attention in vision models,\" Adv. Neural Inf. Process. Syst., vol. 32, pp. 68-80, 2019.\n\nAdam: A method for stochastic optimization. D P Kingma, J L Ba, Proc. Int. Conf. Learn. Represent. Int. Conf. Learn. RepresentD. P. Kingma and J. L. Ba, \"Adam: A method for stochastic optimization,\" in Proc. Int. Conf. Learn. Represent., 2015, pp. 1-15.\n\nPyTorch: An imperative style, high-performance deep learning library. A Paszke, Adv. Neural Inf. Process. Syst. 32A. Paszke et al., \"PyTorch: An imperative style, high-performance deep learning library,\" Adv. Neural Inf. Process. Syst., vol. 32, pp. 8026-8037, 2019.\n", "annotations": {"author": "[{\"end\":99,\"start\":70},{\"end\":131,\"start\":100},{\"end\":181,\"start\":132},{\"end\":219,\"start\":182},{\"end\":229,\"start\":220},{\"end\":269,\"start\":230},{\"end\":291,\"start\":270},{\"end\":307,\"start\":292},{\"end\":408,\"start\":308},{\"end\":462,\"start\":409}]", "publisher": null, "author_last_name": "[{\"end\":78,\"start\":75},{\"end\":152,\"start\":144},{\"end\":196,\"start\":189},{\"end\":228,\"start\":225},{\"end\":241,\"start\":237},{\"end\":290,\"start\":282},{\"end\":306,\"start\":299}]", "author_first_name": "[{\"end\":74,\"start\":70},{\"end\":125,\"start\":119},{\"end\":130,\"start\":126},{\"end\":141,\"start\":132},{\"end\":143,\"start\":142},{\"end\":188,\"start\":182},{\"end\":224,\"start\":220},{\"end\":236,\"start\":230},{\"end\":279,\"start\":270},{\"end\":281,\"start\":280},{\"end\":298,\"start\":292}]", "author_affiliation": "[{\"end\":407,\"start\":309},{\"end\":461,\"start\":410}]", "title": "[{\"end\":67,\"start\":1},{\"end\":529,\"start\":463}]", "venue": "[{\"end\":611,\"start\":531}]", "abstract": "[{\"end\":3357,\"start\":893}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":3533,\"start\":3530},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3823,\"start\":3820},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":4036,\"start\":4033},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":4768,\"start\":4765},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":4773,\"start\":4770},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":4778,\"start\":4775},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":5258,\"start\":5255},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":7824,\"start\":7821},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":7829,\"start\":7826},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":7967,\"start\":7963},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":7973,\"start\":7969},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":7979,\"start\":7975},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":7985,\"start\":7981},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":7991,\"start\":7987},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":7997,\"start\":7993},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":8225,\"start\":8221},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":8231,\"start\":8227},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":8237,\"start\":8233},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":8243,\"start\":8239},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":8249,\"start\":8245},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":8993,\"start\":8989},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":9367,\"start\":9363},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":9493,\"start\":9489},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":10039,\"start\":10035},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":10163,\"start\":10159},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":11237,\"start\":11234},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":11243,\"start\":11239},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":11249,\"start\":11245},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":11255,\"start\":11251},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":11261,\"start\":11257},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":14227,\"start\":14223},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":14341,\"start\":14337},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":14910,\"start\":14906},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":17720,\"start\":17716},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":20799,\"start\":20795},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":22090,\"start\":22086},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":22388,\"start\":22384},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":22394,\"start\":22390},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":22400,\"start\":22396},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":26134,\"start\":26130},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":26418,\"start\":26414},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":36313,\"start\":36310},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":36318,\"start\":36315},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":36324,\"start\":36320},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":39980,\"start\":39976},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":40322,\"start\":40318},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":46702,\"start\":46699},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":46707,\"start\":46704},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":46717,\"start\":46713},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":46898,\"start\":46895},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":46901,\"start\":46898},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":46904,\"start\":46901},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":46907,\"start\":46904},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":46910,\"start\":46907},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":46913,\"start\":46910},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":46916,\"start\":46913},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":46919,\"start\":46916},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":46923,\"start\":46919}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":47420,\"start\":47273},{\"attributes\":{\"id\":\"fig_1\"},\"end\":48557,\"start\":47421},{\"attributes\":{\"id\":\"fig_2\"},\"end\":48923,\"start\":48558},{\"attributes\":{\"id\":\"fig_3\"},\"end\":48959,\"start\":48924},{\"attributes\":{\"id\":\"fig_4\"},\"end\":49201,\"start\":48960},{\"attributes\":{\"id\":\"fig_5\"},\"end\":49480,\"start\":49202},{\"attributes\":{\"id\":\"fig_7\"},\"end\":49743,\"start\":49481},{\"attributes\":{\"id\":\"fig_8\"},\"end\":49922,\"start\":49744},{\"attributes\":{\"id\":\"fig_9\"},\"end\":50093,\"start\":49923},{\"attributes\":{\"id\":\"fig_10\"},\"end\":50248,\"start\":50094},{\"attributes\":{\"id\":\"fig_11\"},\"end\":50464,\"start\":50249},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":50627,\"start\":50465}]", "paragraph": "[{\"end\":4439,\"start\":3376},{\"end\":6586,\"start\":4441},{\"end\":7434,\"start\":6588},{\"end\":8707,\"start\":7436},{\"end\":10564,\"start\":8709},{\"end\":11755,\"start\":10566},{\"end\":12464,\"start\":11757},{\"end\":13520,\"start\":12466},{\"end\":15180,\"start\":13586},{\"end\":16197,\"start\":15195},{\"end\":16834,\"start\":16199},{\"end\":17090,\"start\":16853},{\"end\":19266,\"start\":17092},{\"end\":20725,\"start\":19268},{\"end\":21277,\"start\":20727},{\"end\":23272,\"start\":21558},{\"end\":24098,\"start\":23499},{\"end\":24599,\"start\":24209},{\"end\":24710,\"start\":24633},{\"end\":24958,\"start\":24782},{\"end\":25117,\"start\":24993},{\"end\":26419,\"start\":25183},{\"end\":26751,\"start\":26421},{\"end\":27276,\"start\":27081},{\"end\":28808,\"start\":27301},{\"end\":29376,\"start\":28838},{\"end\":32702,\"start\":29378},{\"end\":34099,\"start\":32704},{\"end\":35254,\"start\":34101},{\"end\":36326,\"start\":35256},{\"end\":36920,\"start\":36412},{\"end\":37271,\"start\":36922},{\"end\":38320,\"start\":37273},{\"end\":38982,\"start\":38322},{\"end\":40323,\"start\":38984},{\"end\":42396,\"start\":40404},{\"end\":44228,\"start\":42398},{\"end\":45363,\"start\":44243},{\"end\":46473,\"start\":45365},{\"end\":47272,\"start\":46475}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":21447,\"start\":21278},{\"attributes\":{\"id\":\"formula_1\"},\"end\":21557,\"start\":21447},{\"attributes\":{\"id\":\"formula_2\"},\"end\":23404,\"start\":23273},{\"attributes\":{\"id\":\"formula_3\"},\"end\":23498,\"start\":23404},{\"attributes\":{\"id\":\"formula_4\"},\"end\":24208,\"start\":24099},{\"attributes\":{\"id\":\"formula_5\"},\"end\":24632,\"start\":24600},{\"attributes\":{\"id\":\"formula_6\"},\"end\":24781,\"start\":24711},{\"attributes\":{\"id\":\"formula_7\"},\"end\":24992,\"start\":24959},{\"attributes\":{\"id\":\"formula_8\"},\"end\":25142,\"start\":25118},{\"attributes\":{\"id\":\"formula_9\"},\"end\":27080,\"start\":26752}]", "table_ref": null, "section_header": "[{\"end\":3374,\"start\":3359},{\"end\":13566,\"start\":13523},{\"end\":13584,\"start\":13569},{\"end\":15193,\"start\":15183},{\"end\":16851,\"start\":16837},{\"end\":25181,\"start\":25144},{\"end\":27299,\"start\":27279},{\"end\":28836,\"start\":28811},{\"end\":36343,\"start\":36329},{\"end\":36410,\"start\":36346},{\"end\":40402,\"start\":40326},{\"end\":44241,\"start\":44231},{\"end\":47282,\"start\":47274},{\"end\":48567,\"start\":48559},{\"end\":48933,\"start\":48925},{\"end\":48969,\"start\":48961},{\"end\":49211,\"start\":49203},{\"end\":49490,\"start\":49482},{\"end\":49753,\"start\":49745},{\"end\":49933,\"start\":49924},{\"end\":50104,\"start\":50095},{\"end\":50259,\"start\":50250}]", "table": null, "figure_caption": "[{\"end\":47420,\"start\":47284},{\"end\":48557,\"start\":47423},{\"end\":48923,\"start\":48569},{\"end\":48959,\"start\":48935},{\"end\":49201,\"start\":48971},{\"end\":49480,\"start\":49213},{\"end\":49743,\"start\":49492},{\"end\":49922,\"start\":49755},{\"end\":50093,\"start\":49936},{\"end\":50248,\"start\":50107},{\"end\":50464,\"start\":50262},{\"end\":50627,\"start\":50467}]", "figure_ref": "[{\"end\":6258,\"start\":6252},{\"end\":8269,\"start\":8263},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":13864,\"start\":13858},{\"end\":17220,\"start\":17214},{\"end\":19408,\"start\":19402},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":19716,\"start\":19710},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":23234,\"start\":23228},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":23917,\"start\":23911},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":29939,\"start\":29933},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":30174,\"start\":30168},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":30819,\"start\":30802},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":31538,\"start\":31532},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":31689,\"start\":31683},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":32693,\"start\":32684},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":32873,\"start\":32867},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":33119,\"start\":33113},{\"attributes\":{\"ref_id\":\"fig_9\"},\"end\":34119,\"start\":34112},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":34687,\"start\":34681},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":35281,\"start\":35274},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":40559,\"start\":40545},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":41114,\"start\":41107}]", "bib_author_first_name": "[{\"end\":54155,\"start\":54154},{\"end\":54327,\"start\":54326},{\"end\":54329,\"start\":54328},{\"end\":54338,\"start\":54337},{\"end\":54340,\"start\":54339},{\"end\":54702,\"start\":54701},{\"end\":54711,\"start\":54710},{\"end\":55014,\"start\":55013},{\"end\":55026,\"start\":55025},{\"end\":55288,\"start\":55287},{\"end\":55290,\"start\":55289},{\"end\":55300,\"start\":55299},{\"end\":55302,\"start\":55301},{\"end\":55312,\"start\":55311},{\"end\":55572,\"start\":55571},{\"end\":55579,\"start\":55578},{\"end\":55588,\"start\":55587},{\"end\":55596,\"start\":55595},{\"end\":55605,\"start\":55604},{\"end\":55927,\"start\":55926},{\"end\":55934,\"start\":55933},{\"end\":55940,\"start\":55939},{\"end\":55948,\"start\":55947},{\"end\":55957,\"start\":55956},{\"end\":55965,\"start\":55964},{\"end\":56354,\"start\":56353},{\"end\":56371,\"start\":56370},{\"end\":56741,\"start\":56740},{\"end\":56747,\"start\":56746},{\"end\":56756,\"start\":56755},{\"end\":56763,\"start\":56762},{\"end\":57071,\"start\":57070},{\"end\":57079,\"start\":57078},{\"end\":57092,\"start\":57091},{\"end\":57391,\"start\":57390},{\"end\":57649,\"start\":57648},{\"end\":57657,\"start\":57656},{\"end\":57673,\"start\":57672},{\"end\":57680,\"start\":57679},{\"end\":58058,\"start\":58057},{\"end\":58387,\"start\":58386},{\"end\":58395,\"start\":58394},{\"end\":58411,\"start\":58410},{\"end\":58422,\"start\":58421},{\"end\":58716,\"start\":58715},{\"end\":58722,\"start\":58721},{\"end\":58734,\"start\":58733},{\"end\":58744,\"start\":58743},{\"end\":59027,\"start\":59026},{\"end\":59034,\"start\":59033},{\"end\":59042,\"start\":59041},{\"end\":59053,\"start\":59049},{\"end\":59065,\"start\":59061},{\"end\":59076,\"start\":59072},{\"end\":59438,\"start\":59437},{\"end\":59724,\"start\":59723},{\"end\":59731,\"start\":59730},{\"end\":59739,\"start\":59738},{\"end\":59747,\"start\":59746},{\"end\":60113,\"start\":60112},{\"end\":60120,\"start\":60119},{\"end\":60126,\"start\":60125},{\"end\":60134,\"start\":60133},{\"end\":60143,\"start\":60142},{\"end\":60151,\"start\":60150},{\"end\":60546,\"start\":60545},{\"end\":60554,\"start\":60553},{\"end\":60562,\"start\":60561},{\"end\":60570,\"start\":60569},{\"end\":60577,\"start\":60576},{\"end\":60579,\"start\":60578},{\"end\":60909,\"start\":60908},{\"end\":61184,\"start\":61183},{\"end\":61191,\"start\":61190},{\"end\":61197,\"start\":61196},{\"end\":61206,\"start\":61205},{\"end\":61215,\"start\":61214},{\"end\":61501,\"start\":61500},{\"end\":61508,\"start\":61507},{\"end\":61516,\"start\":61515},{\"end\":61526,\"start\":61522},{\"end\":61870,\"start\":61869},{\"end\":61872,\"start\":61871},{\"end\":61890,\"start\":61889},{\"end\":61899,\"start\":61898},{\"end\":61901,\"start\":61900},{\"end\":61910,\"start\":61909},{\"end\":62149,\"start\":62148},{\"end\":62151,\"start\":62150},{\"end\":62160,\"start\":62159},{\"end\":62162,\"start\":62161},{\"end\":62171,\"start\":62170},{\"end\":62173,\"start\":62172},{\"end\":62185,\"start\":62184},{\"end\":62429,\"start\":62428},{\"end\":62439,\"start\":62438},{\"end\":62450,\"start\":62449},{\"end\":62461,\"start\":62460},{\"end\":62695,\"start\":62694},{\"end\":62704,\"start\":62703},{\"end\":62718,\"start\":62717},{\"end\":62729,\"start\":62728},{\"end\":62995,\"start\":62994},{\"end\":63003,\"start\":63002},{\"end\":63010,\"start\":63009},{\"end\":63325,\"start\":63324},{\"end\":63341,\"start\":63340},{\"end\":63351,\"start\":63350},{\"end\":63362,\"start\":63361},{\"end\":63371,\"start\":63370},{\"end\":63383,\"start\":63382},{\"end\":63656,\"start\":63655},{\"end\":63658,\"start\":63657},{\"end\":63668,\"start\":63667},{\"end\":63670,\"start\":63669},{\"end\":63937,\"start\":63936}]", "bib_author_last_name": "[{\"end\":54163,\"start\":54156},{\"end\":54335,\"start\":54330},{\"end\":54349,\"start\":54341},{\"end\":54708,\"start\":54703},{\"end\":54718,\"start\":54712},{\"end\":55023,\"start\":55015},{\"end\":55033,\"start\":55027},{\"end\":55297,\"start\":55291},{\"end\":55309,\"start\":55303},{\"end\":55317,\"start\":55313},{\"end\":55576,\"start\":55573},{\"end\":55585,\"start\":55580},{\"end\":55593,\"start\":55589},{\"end\":55602,\"start\":55597},{\"end\":55608,\"start\":55606},{\"end\":55931,\"start\":55928},{\"end\":55937,\"start\":55935},{\"end\":55945,\"start\":55941},{\"end\":55954,\"start\":55949},{\"end\":55962,\"start\":55958},{\"end\":55969,\"start\":55966},{\"end\":56368,\"start\":56355},{\"end\":56384,\"start\":56372},{\"end\":56744,\"start\":56742},{\"end\":56753,\"start\":56748},{\"end\":56760,\"start\":56757},{\"end\":56767,\"start\":56764},{\"end\":57076,\"start\":57072},{\"end\":57089,\"start\":57080},{\"end\":57100,\"start\":57093},{\"end\":57402,\"start\":57392},{\"end\":57654,\"start\":57650},{\"end\":57670,\"start\":57658},{\"end\":57677,\"start\":57674},{\"end\":57688,\"start\":57681},{\"end\":58064,\"start\":58059},{\"end\":58392,\"start\":58388},{\"end\":58408,\"start\":58396},{\"end\":58419,\"start\":58412},{\"end\":58426,\"start\":58423},{\"end\":58719,\"start\":58717},{\"end\":58731,\"start\":58723},{\"end\":58741,\"start\":58735},{\"end\":58753,\"start\":58745},{\"end\":59031,\"start\":59028},{\"end\":59039,\"start\":59035},{\"end\":59047,\"start\":59043},{\"end\":59059,\"start\":59054},{\"end\":59070,\"start\":59066},{\"end\":59080,\"start\":59077},{\"end\":59442,\"start\":59439},{\"end\":59728,\"start\":59725},{\"end\":59736,\"start\":59732},{\"end\":59744,\"start\":59740},{\"end\":59760,\"start\":59748},{\"end\":60117,\"start\":60114},{\"end\":60123,\"start\":60121},{\"end\":60131,\"start\":60127},{\"end\":60140,\"start\":60135},{\"end\":60148,\"start\":60144},{\"end\":60156,\"start\":60152},{\"end\":60551,\"start\":60547},{\"end\":60559,\"start\":60555},{\"end\":60567,\"start\":60563},{\"end\":60574,\"start\":60571},{\"end\":60582,\"start\":60580},{\"end\":60917,\"start\":60910},{\"end\":61188,\"start\":61185},{\"end\":61194,\"start\":61192},{\"end\":61203,\"start\":61198},{\"end\":61212,\"start\":61207},{\"end\":61220,\"start\":61216},{\"end\":61505,\"start\":61502},{\"end\":61513,\"start\":61509},{\"end\":61520,\"start\":61517},{\"end\":61531,\"start\":61527},{\"end\":61887,\"start\":61873},{\"end\":61896,\"start\":61891},{\"end\":61907,\"start\":61902},{\"end\":61917,\"start\":61911},{\"end\":62157,\"start\":62152},{\"end\":62168,\"start\":62163},{\"end\":62182,\"start\":62174},{\"end\":62201,\"start\":62186},{\"end\":62436,\"start\":62430},{\"end\":62447,\"start\":62440},{\"end\":62458,\"start\":62451},{\"end\":62466,\"start\":62462},{\"end\":62701,\"start\":62696},{\"end\":62715,\"start\":62705},{\"end\":62726,\"start\":62719},{\"end\":62735,\"start\":62730},{\"end\":63000,\"start\":62996},{\"end\":63007,\"start\":63004},{\"end\":63017,\"start\":63011},{\"end\":63338,\"start\":63326},{\"end\":63348,\"start\":63342},{\"end\":63359,\"start\":63352},{\"end\":63368,\"start\":63363},{\"end\":63380,\"start\":63372},{\"end\":63390,\"start\":63384},{\"end\":63665,\"start\":63659},{\"end\":63673,\"start\":63671},{\"end\":63944,\"start\":63938}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":54112,\"start\":53908},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":53695523},\"end\":54295,\"start\":54114},{\"attributes\":{\"id\":\"b2\"},\"end\":54601,\"start\":54297},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":121259434},\"end\":54939,\"start\":54603},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":4187501},\"end\":55197,\"start\":54941},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":129841215},\"end\":55514,\"start\":55199},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":238753112},\"end\":55832,\"start\":55516},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":122395382},\"end\":56212,\"start\":55834},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":212919175},\"end\":56659,\"start\":56214},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":436933},\"end\":57012,\"start\":56661},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":1629541},\"end\":57359,\"start\":57014},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":1033682},\"end\":57544,\"start\":57361},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":202915487},\"end\":57936,\"start\":57546},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":238651120},\"end\":58274,\"start\":57938},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":209978915},\"end\":58701,\"start\":58276},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":54465873},\"end\":58938,\"start\":58703},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":6352419},\"end\":59362,\"start\":58940},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":25015381},\"end\":59662,\"start\":59364},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":233891803},\"end\":59989,\"start\":59664},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":244582591},\"end\":60456,\"start\":59991},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":4965597},\"end\":60879,\"start\":60458},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":13756489},\"end\":61126,\"start\":60881},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":213928332},\"end\":61411,\"start\":61128},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":36080760},\"end\":61811,\"start\":61413},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":53678167},\"end\":62101,\"start\":61813},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":129112735},\"end\":62387,\"start\":62103},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":109413693},\"end\":62644,\"start\":62389},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":46898260},\"end\":62944,\"start\":62646},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":215542547},\"end\":63277,\"start\":62946},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":189897750},\"end\":63609,\"start\":63279},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":6628106},\"end\":63864,\"start\":63611},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":202786778},\"end\":64132,\"start\":63866}]", "bib_title": "[{\"end\":53924,\"start\":53908},{\"end\":54152,\"start\":54114},{\"end\":54324,\"start\":54297},{\"end\":54699,\"start\":54603},{\"end\":55011,\"start\":54941},{\"end\":55285,\"start\":55199},{\"end\":55569,\"start\":55516},{\"end\":55924,\"start\":55834},{\"end\":56351,\"start\":56214},{\"end\":56738,\"start\":56661},{\"end\":57068,\"start\":57014},{\"end\":57388,\"start\":57361},{\"end\":57646,\"start\":57546},{\"end\":58055,\"start\":57938},{\"end\":58384,\"start\":58276},{\"end\":58713,\"start\":58703},{\"end\":59024,\"start\":58940},{\"end\":59435,\"start\":59364},{\"end\":59721,\"start\":59664},{\"end\":60110,\"start\":59991},{\"end\":60543,\"start\":60458},{\"end\":60906,\"start\":60881},{\"end\":61181,\"start\":61128},{\"end\":61498,\"start\":61413},{\"end\":61867,\"start\":61813},{\"end\":62146,\"start\":62103},{\"end\":62426,\"start\":62389},{\"end\":62692,\"start\":62646},{\"end\":62992,\"start\":62946},{\"end\":63322,\"start\":63279},{\"end\":63653,\"start\":63611},{\"end\":63934,\"start\":63866}]", "bib_author": "[{\"end\":54165,\"start\":54154},{\"end\":54337,\"start\":54326},{\"end\":54351,\"start\":54337},{\"end\":54710,\"start\":54701},{\"end\":54720,\"start\":54710},{\"end\":55025,\"start\":55013},{\"end\":55035,\"start\":55025},{\"end\":55299,\"start\":55287},{\"end\":55311,\"start\":55299},{\"end\":55319,\"start\":55311},{\"end\":55578,\"start\":55571},{\"end\":55587,\"start\":55578},{\"end\":55595,\"start\":55587},{\"end\":55604,\"start\":55595},{\"end\":55610,\"start\":55604},{\"end\":55933,\"start\":55926},{\"end\":55939,\"start\":55933},{\"end\":55947,\"start\":55939},{\"end\":55956,\"start\":55947},{\"end\":55964,\"start\":55956},{\"end\":55971,\"start\":55964},{\"end\":56370,\"start\":56353},{\"end\":56386,\"start\":56370},{\"end\":56746,\"start\":56740},{\"end\":56755,\"start\":56746},{\"end\":56762,\"start\":56755},{\"end\":56769,\"start\":56762},{\"end\":57078,\"start\":57070},{\"end\":57091,\"start\":57078},{\"end\":57102,\"start\":57091},{\"end\":57404,\"start\":57390},{\"end\":57656,\"start\":57648},{\"end\":57672,\"start\":57656},{\"end\":57679,\"start\":57672},{\"end\":57690,\"start\":57679},{\"end\":58066,\"start\":58057},{\"end\":58394,\"start\":58386},{\"end\":58410,\"start\":58394},{\"end\":58421,\"start\":58410},{\"end\":58428,\"start\":58421},{\"end\":58721,\"start\":58715},{\"end\":58733,\"start\":58721},{\"end\":58743,\"start\":58733},{\"end\":58755,\"start\":58743},{\"end\":59033,\"start\":59026},{\"end\":59041,\"start\":59033},{\"end\":59049,\"start\":59041},{\"end\":59061,\"start\":59049},{\"end\":59072,\"start\":59061},{\"end\":59082,\"start\":59072},{\"end\":59444,\"start\":59437},{\"end\":59730,\"start\":59723},{\"end\":59738,\"start\":59730},{\"end\":59746,\"start\":59738},{\"end\":59762,\"start\":59746},{\"end\":60119,\"start\":60112},{\"end\":60125,\"start\":60119},{\"end\":60133,\"start\":60125},{\"end\":60142,\"start\":60133},{\"end\":60150,\"start\":60142},{\"end\":60158,\"start\":60150},{\"end\":60553,\"start\":60545},{\"end\":60561,\"start\":60553},{\"end\":60569,\"start\":60561},{\"end\":60576,\"start\":60569},{\"end\":60584,\"start\":60576},{\"end\":60919,\"start\":60908},{\"end\":61190,\"start\":61183},{\"end\":61196,\"start\":61190},{\"end\":61205,\"start\":61196},{\"end\":61214,\"start\":61205},{\"end\":61222,\"start\":61214},{\"end\":61507,\"start\":61500},{\"end\":61515,\"start\":61507},{\"end\":61522,\"start\":61515},{\"end\":61533,\"start\":61522},{\"end\":61889,\"start\":61869},{\"end\":61898,\"start\":61889},{\"end\":61909,\"start\":61898},{\"end\":61919,\"start\":61909},{\"end\":62159,\"start\":62148},{\"end\":62170,\"start\":62159},{\"end\":62184,\"start\":62170},{\"end\":62203,\"start\":62184},{\"end\":62438,\"start\":62428},{\"end\":62449,\"start\":62438},{\"end\":62460,\"start\":62449},{\"end\":62468,\"start\":62460},{\"end\":62703,\"start\":62694},{\"end\":62717,\"start\":62703},{\"end\":62728,\"start\":62717},{\"end\":62737,\"start\":62728},{\"end\":63002,\"start\":62994},{\"end\":63009,\"start\":63002},{\"end\":63019,\"start\":63009},{\"end\":63340,\"start\":63324},{\"end\":63350,\"start\":63340},{\"end\":63361,\"start\":63350},{\"end\":63370,\"start\":63361},{\"end\":63382,\"start\":63370},{\"end\":63392,\"start\":63382},{\"end\":63667,\"start\":63655},{\"end\":63675,\"start\":63667},{\"end\":63946,\"start\":63936}]", "bib_venue": "[{\"end\":57190,\"start\":57150},{\"end\":58817,\"start\":58790},{\"end\":59146,\"start\":59120},{\"end\":59508,\"start\":59482},{\"end\":60670,\"start\":60633},{\"end\":61005,\"start\":60968},{\"end\":61248,\"start\":61239},{\"end\":61609,\"start\":61575},{\"end\":62789,\"start\":62767},{\"end\":63115,\"start\":63071},{\"end\":63737,\"start\":63710},{\"end\":53955,\"start\":53926},{\"end\":54184,\"start\":54165},{\"end\":54374,\"start\":54351},{\"end\":54744,\"start\":54720},{\"end\":55041,\"start\":55035},{\"end\":55328,\"start\":55319},{\"end\":55641,\"start\":55610},{\"end\":55995,\"start\":55971},{\"end\":56410,\"start\":56386},{\"end\":56807,\"start\":56769},{\"end\":57148,\"start\":57102},{\"end\":57434,\"start\":57404},{\"end\":57708,\"start\":57690},{\"end\":58077,\"start\":58066},{\"end\":58459,\"start\":58428},{\"end\":58788,\"start\":58755},{\"end\":59118,\"start\":59082},{\"end\":59480,\"start\":59444},{\"end\":59793,\"start\":59762},{\"end\":60179,\"start\":60158},{\"end\":60631,\"start\":60584},{\"end\":60966,\"start\":60919},{\"end\":61237,\"start\":61222},{\"end\":61573,\"start\":61533},{\"end\":61930,\"start\":61919},{\"end\":62219,\"start\":62203},{\"end\":62487,\"start\":62468},{\"end\":62765,\"start\":62737},{\"end\":63069,\"start\":63019},{\"end\":63422,\"start\":63392},{\"end\":63708,\"start\":63675},{\"end\":63976,\"start\":63946}]"}}}, "year": 2023, "month": 12, "day": 17}