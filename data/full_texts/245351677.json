{"id": 245351677, "updated": "2022-09-30 01:23:31.771", "metadata": {"title": "Me-Momentum: Extracting Hard Confident Examples from Noisily Labeled Data", "authors": "[{\"first\":\"Yingbin\",\"last\":\"Bai\",\"middle\":[]},{\"first\":\"Tongliang\",\"last\":\"Liu\",\"middle\":[]}]", "venue": "2021 IEEE/CVF International Conference on Computer Vision (ICCV)", "journal": "2021 IEEE/CVF International Conference on Computer Vision (ICCV)", "publication_date": {"year": 2021, "month": null, "day": null}, "abstract": "Examples that are close to the decision boundary\u2014that we term hard examples, are essential to shape accurate classifiers. Extracting confident examples has been widely studied in the community of learning with noisy labels. However, it remains elusive how to extract hard confident examples from the noisy training data. In this paper, we propose a deep learning paradigm to solve this problem, which is built on the memorization effect of deep neural networks that they would first learn simple patterns, i.e., which are defined by these shared by multiple training examples. To extract hard confident examples that contain non-simple patterns and are entangled with the inaccurately labeled examples, we borrow the idea of momentum from physics. Specifically, we alternately update the confident examples and refine the classifier. Note that the extracted confident examples in the previous round can be exploited to learn a better classifier and that the better classifier will help identify better (and hard) confident examples. We call the approach the \"Momentum of Memorization\" (Me-Momentum). Empirical results on benchmark-simulated and real-world label-noise data illustrate the effectiveness of Me-Momentum for extracting hard confident examples, leading to better classification performance.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/iccv/BaiL21", "doi": "10.1109/iccv48922.2021.00918"}}, "content": {"source": {"pdf_hash": "892634a0596dcea920d6206d6e1b52740ac1091f", "pdf_src": "IEEE", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "c63e5779e0c198e8c1e11b4e32d1e4b564b0f6aa", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/892634a0596dcea920d6206d6e1b52740ac1091f.txt", "contents": "\nMe-Momentum: Extracting Hard Confident Examples from Noisily Labeled Data\n\n\nYingbin Bai \nTrustworthy Machine Learning Lab\nUniversity of Sydney\n\n\nTongliang Liu \nTrustworthy Machine Learning Lab\nUniversity of Sydney\n\n\nMe-Momentum: Extracting Hard Confident Examples from Noisily Labeled Data\n10.1109/ICCV48922.2021.00918\nExamples that are close to the decision boundary-that we term hard examples, are essential to shape accurate classifiers. Extracting confident examples has been widely studied in the community of learning with noisy labels. However, it remains elusive how to extract hard confident examples from the noisy training data. In this paper, we propose a deep learning paradigm to solve this problem, which is built on the memorization effect of deep neural networks that they would first learn simple patterns, i.e., which are defined by these shared by multiple training examples. To extract hard confident examples that contain non-simple patterns and are entangled with the inaccurately labeled examples, we borrow the idea of momentum from physics. Specifically, we alternately update the confident examples and refine the classifier. Note that the extracted confident examples in the previous round can be exploited to learn a better classifier and that the better classifier will help identify better (and hard) confident examples. We call the approach the \"Momentum of Memorization\" (Me-Momentum). Empirical results on benchmark-simulated and real-world label-noise data illustrate the effectiveness of Me-Momentum for extracting hard confident examples, leading to better classification performance.\n\nIntroduction\n\nAs training datasets are growing big while accurately labeling them is often expensive or sometimes even infeasible, cheap datasets with label noise are ubiquitous in many real-world applications. Without any care, label noise will degenerate the performance of learning algorithms, especially for those based on deep neural networks [57]. Learning with noisy labels [1] aims to reduce the side-effect of label noise and therefore has become an important topic in machine learning.\n\nExisting methods for learning with noisy labels can be divided into two categories: algorithms that result in sta-* Correspondence to Tongliang Liu (tongliang.liu@sydney.edu.au).\n\ntistically consistent or inconsistent classifiers. Methods in the first category intent to design classifier-consistent algorithms [58,14,35,7,39,56,24,54,50,45,49,20], where classifiers learned by using the noisy data will statistically converge to the optimal classifiers defined by clean data. However, these methods rely heavily on the noise transition matrix [23,32,51]. In real-world applications, it is hard to learn the instance-dependent noise transition matrix [5]. To be free of estimating the noise transition matrix, methods in the second category employ heuristics to reduce the sideeffect of label noise [27,25,38,33,9,8,43,41,21,19]. These methods were reported to empirically work well, especially in the setting of instance-dependent label noise.\n\nOne promising direction in the second category is to extract examples with clean labels-confident examples- [31,40,30,6,44,34,47,48]. The idea is that compared with the original noisy training data, the extracted examples are less noisy and thus will lead to a classifier with better performance. Given only noisy data, state-of-the-art methods exploit the memorization effect [57,2] to extract confident examples. The memorization effect will enable deep neural networks to first learn patterns that are shared by a majority of training examples. As clean labels are of majority in each noisy class [29,52], deep neural networks would therefore first fit training data with clean labels, and then gradually fit the examples with incorrect labels [4]. Therefore, early stopping [19,36] and the small loss trick [13,10,55] can be used to exploit confident examples.\n\nExamples that are close to the decision boundary are called hard examples. As illustrated in Figure 1, hard (confident) examples play an important role in shaping the decision boundary. It has also been widely studied in the traditional classification problem that hard examples are essential to train accurate classifiers [42,3,12,11]. Notwithstanding the importance of hard confident examples, none of the existing methods studies how to extract hard confident examples from noisy data. Note that extracting hard confident examples is non-effortless. Since hard examples are often of a small proportion and contain less discriminative information compared with the easy ones (these that are far away from the decision boundary), they are often entan- gled with inaccurately labeled examples in the procedures of extraction. In this paper, by alternately updating the confident examples and refining the classifier, we propose a deep learning paradigm that is able to extract hard confident examples from the noisy training data, leading to better classification performance. Specifically, the idea is similar to the usage of momentum from physics. As stated in the statistical learning theory, with better training data, a better classifier can be obtained [28]. We can then think of the classifier as a particle traveling through the hypothesis space, getting acceleration from the confident data. Classifiers with better performance can be achieved by properly exploiting the previously extracted confident examples. This is similar to the momentum trick used in optimization that previous gradient information can be used to escape local minimum and achieve fast convergence rates [37] 1 . At a high level, the proposed method is built on the memorization effect of deep neural networks and on the intuition that better confident examples will result in a better classifier and that a better classifier will identify better confident examples (and hard confident examples). The proposed method is therefore called the Momentum of Memorization (Me-Momentum).\n\nWe conduct experiments to show the effectiveness of the proposed Me-Momentum on noisy versions of MNIST, CIFAR10, CIFAR100, and a real-world label noise dataset Clothing1M. Specifically, on MNIST and CIFAR, we generate class-dependent and instance-dependent label noise and visualize the extracted hard confident examples, which justifies why Me-Momentum consistently outperforms the baseline methods.\n\n\nMe-Momentum\n\nIn this section, by specifying the proposed method of momentum of memorization (Me-Momentum; summarized in Algorithm 1), we would like to detail how to accomplish extracting hard confident examples and boosting the 1 In optimisation, the parameter vector can be thought of as a particle traveling through the parameter space, getting acceleration from the gradient of the loss. The momentum trick demonstrated that the gradient in the previous update can help escape local minimum and achieve fast convergence rates. To answer the first question, we would like to mention that the aim of the initialization in Step 1 is to initialize a good classifier for the positive cycle: a better classifier will identify better confident examples and better confident examples will result in a better classifier. A good candidate should have a fairly high classification accuracy, e.g., higher than random guessing. Otherwise, the positive cycle cannot be invoked. Fortunately, the initialization can be made by exploiting the memorization effect of deep neural networks that would first fit clean data [2,57]. Note that this memorization effect is independent of training optimization or network backbones [2]. Specifically, we use the early stopping trick. For easy understanding, we would like to introduce a definition of high-peak. A noisy validation accuracy at the i-th epoch is called an i-th high-peak if it achieves the highest accuracy in the epoch range {1, . . . , i}. Assume the i-th and j-th high-peaks occur next to each other, having noisy validation accuracies of a and b, respectively. The training early stops if (b\u2212a)/(j\u2212i) \u2264 \u03c4 , where \u03c4 is a hyperparameter. In the experiments, we set \u03c4 = 0.1, which empirically works well across all datasets. In Section 3.4, we compare the difference between the early stopping method and the traditional validation method. We also study the sensitivity of the hyper-parameter.\n\nThe answer to the second question is closely related to the memorization effect. Note that the classifier initialized in Step 1 would fit the clean data well but not the incorrectly labeled data because of the memorization effect and early stopping. Therefore, we can treat the training examples whose noisy labels are identical to the ones predicted by the classifier obtained in Step 1 as confident examples. This also applies for the classifiers in Step 3 to extract confident examples, which are iteratively trained by employing the updated confident data. Note that there are some other feasible methods to extract confident examples, e.g., extract those who have a large class posterior.\n\nIn\n\nStep 3, we aim to learn a better classifier compared with the one in the previous round. This can be achieved because of two reasons: (1) we initialize the network with the parameters of the classifier learned in the previous round;\n\n(2) we have a better set of confident examples as the training sample. This starts the positive cycle that better confident examples will result in a better classifier and that a better classifier will identify better confident examples. The third question is essential for identifying the classifiers in the cycle. Note that the accurately labeled examples are always assumed to be dominant in each class in the community of learning with noisy labels [29,23,10]. Otherwise, the true class label cannot be identified by only exploiting the noisy data. This assumption implies that the performance on the noisy validation set (split from the noisy training set) and these on test set are positively correlated. The noisy validation set could be used as a surrogate to validate the classifiers if no clean validation set is available. We therefore validate the classifiers in Steps 3 and 5 with the highest noisy validation accuracies during the training. Empirical results show that it works well.\n\nTo answer the fourth question, we define the hard examples by exploiting the memorization effect of deep neural networks, i.e., deep neural networks first fit the majority (or easy) patterns and then the minority (or hard) patterns. Specifically, hard examples are those which contain minority (or hard) patterns. Note that hard patterns are usually entangled with incorrect labels.\n\nFollowing the previous question, we answer the fifth question. By Figure 3.\n\nTo answer the sixth question, we would like to first mention that the proposed method heavily relies on the memorization effect of deep neural networks. Specifically, in Step 1, a classifier is initialized by exploiting the memorization effect via early stopping, which is used to identity confident examples. Later, the classifier and confident examples are iteratively refined and updated, respectively, which is the positive cycle we have mentioned before. Note that this cycle also depends on the memorization effect to update confident examples and refine classifiers. Our method is named as momentum of memorization (Me-Momentum) because it uses the trick of momentum to better exploit the memorization effect. Specifically, we can think of the classifier as a particle traveling through the hypothesis space, getting acceleration from the updated extracted confident data. We exploit the previously extracted confident examples to help learn a better classifier, training the network by using the confident examples extracted in the previous round. The impact of the confident examples will increase as we continue extracting more confident examples.\n\nRelation to existing work: The strategy of alternatively optimizing the classifier and updating the training examples is not new for dealing with label noise. For example, Joint Optim [38], Co-teaching [10,55], and SELF [30] are similar to ours. Specifically, Joint Optim and Co-teaching update the classifier with one step of stochastic gradient descent while SELF and the proposed method refine the classifier to be optimal with respect to the extracted confident examples. However, existing methods have not focused on extracting hard confident examples and thus are substantially different from this paper because they neglected the importance of avoiding the accumulated error caused by the single initialization of the classifier and the sample-selection bias. Experiments (e.g., Figures 2 and 3) show that Me-Momentum with the outer loop part (i.e., re-initialization of the classifier) contributes significantly to extracting hard confident examples and achieving high label precision.\n\nMe-Momentum is similar to curriculum learning as it also learns from easy to difficult. However, curriculum learning needs a predefined curriculum (sample weighting scheme), e.g., assigning big/small weights for confident/noisy data. If the curriculum is not available, some clean data is required to learn a mentornet to provide a curriculum [13] or a latent variable could be introduced by selfpaced learning [16] to learn a curriculum. Differently, Me- Momentum is only based on noisy data and does not explicitly learn a curriculum. Me-Momentum also has a similar flavor to active learning which tends to choose and label hard examples to learn from at each iteration. However, for active learning, no label information is available before the data is chosen while Me-Momentum has noisy labels and needs to consider the side-effect of label noise.\n\n\nExperiments\n\nDatasets: To verify the effectiveness of the proposed method, we do experiments on datasets with both synthetic and real-world label noise. Specifically, we manually corrupt MNIST [17], CIFAR10, and CIFAR100 [15] with classdependent label noise and instance-dependent label noise. We detail how to generate class-dependent and instancedependent label noise in Appendix 1. We employ the realworld noisy dataset Clothing1M [52]. These datasets have been widely used in studies with noisy labels [10,38,51].\n\nFor MNIST, CIFAR10, and CIFAR100, we leave out 10% of the noisy training data as noisy validation data. Cloth-ing1M contains one million noisy training images, which are crawled from shopping websites, labeling by surrounding text. Almost all existing work uses the 14k clean validation data in their experiments. To verify the robustness of the proposed method, we also employ noisy validation data in our experiments. Specifically, 100k noisy data are randomly left as noisy validation data and the remaining 900k noisy data as the training data.\n\nBaselines: Me-Momentum is compared against the following state-of-the-art approaches. (1) Statistically consistent methods: Forward [32], T-revision [51], and DMI [53];\n\n(2) Statistically inconsistent methods: MentorNet [13], Coteaching [10], Joint Optim [38], SELF [30], CDR [46], Di-videMix [18], ELR+ [22] where MentorNet, Co-teaching, SELF, and DivideMix use the idea of extracting confident examples by employing the small loss trick. Note that Di-videMix and ELR+ employ a semi-supervised approach for unconfident examples, which gives them an advantage for synthetic datasets whose numbers of confident examples are limited. Therefore, we only compare our method with them on real-world datasets.\n\nNetwork structure and optimization: All the methods are implemented by PyTorch v1.5. For the experiments on MNIST, CIFAR10, and CIFAR100, we set N inner = 20, N outer = 3, 100 epochs for each inner loop and follow the settings of T-revision [51]. Specifically, LeNet-5, ResNet-18, and ResNet-34 networks are used for MNIST, CIFAR10, and CIFAR100 respectively. We use SGD with momentum 0.9, weight decay 10 \u22124 , batch size 128, and an initial learning rate of 10 \u22122 , divided by 10 after the 40-th epoch and 80-th epoch respectively (we fix the learning rate of 10 \u22122 for the early stopping method). Data augmentation is used with horizontal random flips and 32\u00d732 random crops after padding 4 pixels on each side.\n\nFor Clothing1M, a ResNet-50 is used. To show the effectiveness of the proposed method, we do experiments by randomly initializing the network and pre-training it by employing ImageNet, respectively. As the noisy training sample contains a large number of examples, we set N inner = 6 and N outer = 3 and 5 epochs for each inner loop. We use SGD with momentum 0.9, weight decay 10 \u22123 , batch size 32, with a learning rate of 5 \u00d7 10 \u22123 , and divided it by 10 at the 3-rd and 5-th round in the inner loop. For each outer loop, the model will be randomly re-initialized (or replaced by a pre-trained one). The learning rate will be reset to 5 \u00d7 10 \u22123 . For data augmentation, all images are resized to 256 \u00d7 256, horizontal random flipped, and 256 \u00d7 256 random cropped with padding 32 pixels on each side. Note that due to the page limit, some complementary experiments to Sections 3.1 and 3.2 and the comparison with SELF are put in Appendix 2. The code is available at https://github.com/tmllab/Me-Momentum.\n\n\nVerify Momentum of Memorization\n\nIn Section 2, we discussed that Me-Momentum is implemented by fulfilling the positive cycle that better confident examples will result in a better classifier and that a better classifier will identify better confident examples. In this subsection, we will empirically verify this positive cycle, which can be done on the synthetic datasets as we have their ground-truth labels.\n\nIn Figure 2, we can see that in the inner loops (e.g., rounds 0-5, rounds 6-9, and rounds 10-12 in the first column of figures represent three inner loops respectively), the classification accuracy generally increases (note that the figures are not smooth because the classifiers are tested on the unseen test data) and the number of extracted confident ex-amples clearly increases (although their label precision decreases slightly). We can also see that in the outer loops (e.g., rounds 0, 6, and 10 in the first column of the figures consist of an outer loop), the classification accuracy clearly increases and the label precision of the extracted confident examples clearly increases (although the number of extracted confident examples decreases slightly). This implies that compared with previous classifiers and extracted confident examples, better ones are obtained, which empirically justifies the positive cycle. Note that the classification accuracy in the outer loop is low because the models are re-initialized.   Although the number of the extracted confident examples decreases, the overall quality of the extracted confident examples is increasing as evidenced by the increase of the classification accuracy of the classifiers trained on the extracted confident data. Note that the low data quality in the first run of the inner loop also justifies that a single deep \n\n\nVisualize hard confident examples\n\nTo justify that Me-Momentum is able to extract hard confident examples, we visualize the extracted confident examples by employing t-SNE [26]. Specifically, we show how the confident examples are progressively extracted in the inner and outer loops. The results are shown in Figure 3, where green, blue, and red dots represent confident examples extracted at the beginning, middle, and end rounds of the loops, respectively. On the datasets of MNIST and CI-FAR10, we can clearly see that the blue and red dots are mostly located at the boundaries of the clusters of green dots. Although the figures of CIFAR100 are small, we can also clearly see that there are lots of blue and red dots which are outside of the green clusters in the second and fourth figures. This supports and justifies our claim that Me-Momentum is able to extract hard confident examples (those are close to the decision boundary).\n\nComparing the extracted results of the first run of the inner loop (the first and third columns) with those of the outer loop (the second and fourth columns), we can find that the cluster boundaries in the latter are more clear. This further justifies that why better classification performance can be obtained by re-initialization in the outer loop. Comparing the confident examples extracted on the class-dependent label noise datasets with those on the instance-dependent label noise datasets, we can observe that the proposed method is not sensitive to the type of label noise and can work well on the most general instance-dependent label noise cases.\n\n\nClassification accuracy\n\nSynthetic data To evaluate the classification performance of Me-Momentum, we first conduct experiments on   be further improved by correcting the unconfident data with the idea of Joint Optim.\n\nReal-world dataset We compare Me-Momentum with baseline methods on Clothing1M in Table 4, where \"pretrained\" and \"scratch\" mean the network was pre-trained by employing ImageNet and initialized randomly, respectively;\"clean\" and \"noisy\" means the validation data is clean and noisy respectively. First, it is observed that Me-Momentum works well with noisy validation, even surpassing many baselines with clean validation. For a fair comparison, we also use clean validation to validate our method, which achieves the highest test accuracy of 75.18%, better than T-revision by 1% and Joint Optim by 2.95%. Note that Forward and T-revision need the 50k clean data for estimating the transition matrix, while Me-Momentum does not need any clean data for training. In addition, to show the robustness of Me-Momentum, we conduct experiments with ResNet-50 from scratch, which achieves the second best accuracy.\n\n\nAblation study\n\nWe discuss the early stopping trick used in Step 1 of Algorithm 1. The training early stops if (b \u2212 a)/(j \u2212 i) \u2264 \u03c4 , where \u03c4 is a hyper-parameter. In the experiments, we set \u03c4 = 0.1, which empirically works well across all datasets. In Figure 4, we compare the difference between the proposed early stopping method and the traditional validation method. Comparing the blue dash line with the yellow dash line in Figure 4, we can observe that the proposed early stopping strategy stops earlier and fits less noise, while the traditional methods would continue to fit more data and thus fit more noise.\n\nWe also study the sensitivity of the hyper-parameter. Specifically, we study its sensitivity on CIFAR10 by setting \u03c4 to be the values in the range {0.05, 0.07, 0.1, 0.3, 0.5}. Other settings are the same as those in this paper. The results are presented in Figure 5. We can see that the classification performance of Me-Momentum is robust and not sensitive to the change of the value of \u03c4 .\n\n\nConclusion\n\nIn this paper, we propose a method called Me-Momentum that is able to extract hard confident examples from noisily labeled data by exploiting the memorization effect of deep neural networks. At a high level, it fulfills a positive cycle that better confident examples will result in a better classifier and that a better classifier will identify better confident examples. We have empirically verified its effectiveness by analyzing the statistics of the extracted examples, visualizing the hard confident examples, and comparing its classification performance with state-ofthe-art baselines. In the future, we will extend our work by utilizing and exploiting the unconfident examples, e.g., in a semi-supervised way to further boost the performance.\n\n\nAcknowledgments\n\nFigure 1 .\n1The illustration of the influence of hard (confident) examples in classification. Circles represent positive examples while triangles represent negative examples. Green and blue denote examples with accurate labels while red presents examples with incorrect labels. Blank circles and triangles represent unextracted data. (a) shows an example of classification with clean data. (b) shows noisy examples, especially those close to the decision boundary, will significantly degenerate the accuracy of the classifier. (c) shows confident examples help learn a fairly good classifier. (d) shows that hard confident examples are essential to train an accurate classifier.\n\n\nclassification performance. At a high level, by alternately updating the confident examples and refining the classifier, Me-Momentum fulfills a positive cycle that better confident examples will result in a better classifier and that a better classifier will identify better confident examples. Specifically, Me-Momentum has two loops, i.e., an inner loop and an outer loop. In the inner loop, Me-Momentum alternates update of the confident examples and the classifier (Steps 2 and 3). However, the inner loop continually refines a classifier and thus depends heavily on the initialization of the classifier (Step 1). It may lead to the memorization of noisy labels and the inferiority of sample-selection bias. To handle this problem, the outer loop re-initializes the classifier (Step 5) while it maintains the previously extracted confident examples. There are some points to be clarified for the proposed Algorithm 1: Q1. How to initialize a good classifier in Step 1? Q2. How to extract confident examples in Step 2? Q3. How to validate the learned classifiers in Steps 3 and 5 without a clean validation set? Q4. What are hard confident examples? Q5. Why can hard confident examples be extracted? Q6. Why the proposed method is called Me-Momentum?\n\nAlgorithm 1\n1Me-Momentum Input: Noisy training data, noisy validation data, iteration number N inner and N outer ; Output: Extracted confident examples and the classifier; 1: Initialize a classifier f 0 by using the noisy training data and early stopping; //memorization effect for i = 1, . . . , N outer do for j = 1, . . . , N inner do 2: Update the extracted confident examples; //i.e., the training examples whose noisy labels are identical to the ones predicted by f j\u22121 3: Obtain the classifier f j ; //initialize the network by using the parameters of f j\u22121 and train it by employing confident examples; the classifier f j will be chosen with the highest noisy validation accuracy throughout the training procedure 4: Break and output f j\u22121 if the highest validation accuracy is non-increasing in the loop; end 5: Re-initialize a classifier f 0 ; //randomly initialize the network and train it by using confident examples; the classifier f 0 will be chosen with the highest noisy validation accuracy throughout the training procedure 6: Break and output f j\u22121 if the highest validation accuracy is non-increasing in the loop; end\n\nFigure 2 .\n2We call one update of the classifier and the extracted confident examples as one round. We illustrate how the label precision of the extracted confident examples, the number of the extracted confident examples, and the classification accuracy of the classifier trained by using the extracted confident examples change during the training of Me-Momentum. We have three distinct peaks in these figures because we have set Nouter = 3 and the classifiers are re-initialized in the outer loop. The dash lines in the second row indicate the number of clean labels in the noisy training data.\n\nFigure 2\n2also shows the importance of the outer loop of Me-Momentum. We can see that the label precision of the extracted confident examples slightly decreases in the inner loops. This is because the deep model gradually memorizes the noisy labels as we continually refine it. This issue can be handled by re-initializing the deep model in the outer loop. Specifically, we can see fromFigure 2that by reinitializing the model in the outer loop, the label precision of the extracted confident examples increases significantly.\n\nFigure 3 .\n3Visualization of the extracted confident examples. The first and third columns are about the confident data extracted in the first run of the inner loop; while the second and the fourth columns are about the confident data extracted in the outer loop. Specifically, green dots represent the data selected in the first round. Blue and red dots represent the newly extracted data in the middle and the end rounds respectively. Large figures for CIFAR100 are provided in the supplementary material.\n\nFigure 4 .\n4Comparing the difference between the early stopping method in Step 1 and the traditional validation method where the classifier with the highest validation accuracy during the whole training procedure will be output. The green dash line indicates the epoch at which early stopping happens; while the orange dash line indicates the epoch at which the highest validation accuracy is achieved during the whole training procedure. In the third plot, the two dash lines are identical to each other.\n\nFigure 5 .\n5Illustrative of extracting hard confident examples.\n\n\nsimply exploiting the memorization effect, extracting confident examples with hard patterns is difficult. However, by using the proposed Me-Momentum method, we could extract hard examples. Due to the memorization effect of deep neural networks, the model first fits the simple patterns, i.e., examples with simple features, some of which also have hard features. Then deep neural networks can learn hard patterns from the fitted examples, which makes it possible for deep neural networks to extract hard confident examples from those examples entangled with incorrect labels. A visualization is shown in\n\nTable 1 .\n1Means and standard deviations of classification accuracy on MNISTFlipping-Rate Cross-Entropy MentorNet Co-teaching Forward Joint Optim \nDMI \nT-revision \nCDR \nOurs \nSym-20% \n97.88% \n96.57% \n97.22% \n98.22% \n98.58% \n98.92% \n98.91% \n98.76% \n98.94% \n\u00b10.27% \n\u00b10.18% \n\u00b10.18% \n\u00b10.08% \n\u00b10.15% \n\u00b10.11% \n\u00b10.04% \n\u00b10.07% \u00b10.13% \nSym-40% \n97.41% \n96.16% \n94.64% \n96.71% \n98.12% \n98.63% \n98.42% \n98.40% \n98.66% \n\u00b10.18% \n\u00b10.49% \n\u00b10.33% \n\u00b10.16% \n\u00b10.06% \n\u00b10.11% \n\u00b10.47% \n\u00b100.17% \u00b10.07% \nInst-20% \n97.61% \n94.66% \n95.37% \n95.89% \n98.10% \n98.75% \n97.12% \n98.18% \n98.96% \n\u00b10.28% \n\u00b10.35% \n\u00b10.08% \n\u00b10.12% \n\u00b10.14% \n\u00b10.11% \n\u00b10.09% \n\u00b10.09% \u00b10.06% \nInst-40% \n92.93% \n88.51% \n90.06% \n88.95% \n92.00% \n97.58% \n94.89% \n93.43% \n98.11% \n\u00b10.81% \n\u00b10.36% \n\u00b10.81% \n\u00b12.47% \n\u00b11.39% \n\u00b10.82% \n\u00b10.66% \n\u00b11.12% \u00b10.35% \n\nTable 2. Means and standard deviations of classification accuracy on CIFAR10 \nFlipping-Rate Cross-Entropy MentorNet Co-teaching Forward Joint Optim \nDMI \nT-revision \nCDR \nOurs \nSym-20% \n85.00% \n80.49% \n87.16% \n85.63% \n89.70% \n88.18% \n89.63% \n89.68% 91.44% \n\u00b10.43% \n\u00b10.11% \n\u00b10.52% \n\u00b10.11% \n\u00b10.36% \n\u00b10.13% \n\u00b10.33% \n\u00b10.38% \u00b10.33% \nSym-40% \n79.59% \n77.48% \n83.59% \n74.30% \n87.79% \n83.98% \n86.81% \n86.13% 88.39% \n\u00b11.31% \n\u00b13.45% \n\u00b10.28% \n\u00b10.26% \n\u00b10.20% \n\u00b10.48% \n\u00b10.21% \n\u00b10.44% \u00b10.34% \nInst-20% \n85.92% \n79.12% \n86.54% \n85.29% \n89.69% \n89.14% \n90.46% \n90.24% 90.86% \n\u00b11.09% \n\u00b10.42% \n\u00b10.11% \n\u00b10.38% \n\u00b10.42% \n\u00b10.36% \n\u00b10.13% \n\u00b10.39% \u00b10.21% \nInst-40% \n79.91% \n70.27% \n80.98% \n74.72% \n82.62% \n84.78% \n85.37% \n83.07% 86.66% \n\u00b11.41% \n\u00b11.52% \n\u00b10.39% \n\u00b13.24% \n\u00b10.57% \n\u00b11.97% \n\u00b13.36% \n\u00b11.33% \u00b10.91% \n\n\n\nTable 3 .\n3Means and standard deviations of classification accuracy on CIFAR100 Flipping-Rate Cross-Entropy MentorNet Co-teaching Forward Joint Optim the number of extracted confident examples is close to the number of accurately labeled data in the training set and that the label precision of the extracted confident examples is quite high, i.e., almost all are above 90%. This empirically proves that Me-Momentum is powerful in extracting confident examples. In the next subsection, we will visualize that Me-Momentum is also good at extracting hard confident examples.DMI \nT-revision \nCDR \nOurs \n\n\nTable 4 .\n4Classification accuracy on Clothing1M.MNIST, CIFAR10, and CIFAR100 with class-dependent and instance-dependent label noise. Each trial is repeated five times. The results are presented inTables 1, 2, and 3, respectively. Me-Momentum consistently outperforms the baselines. Specifically, CIFAR100 is the most challenging one among the three datasets. Me-Momentum outperforms the baselines by a clear margin across all the settings as shown inTable 3. Note that the performance gain in Me-Momentum is caused by the improvement of the quality of the extracted confident examples.In the baselines, Co-teaching, Joint Optim, and Trevision are the representative methods that learn robust classifiers by extracting confident examples, refining the noisy labels, and exploiting the noise transition matrix, respectively. Note that Co-teaching keeps updating a constant number of confident examples from the mini-batches used in SGD. We therefore do not compare with its extracted confident examples in Section 3.2 as our method extracts confident examples from the whole training data at once. By comparing the classification performance, we can clearly see that the proposed method is much more powerful in extracting confident examples. Note that Joint Optim and T-revision employ all training data to train the classifiers; while our method only employs confident examples and discards the unconfident ones. The results further justify that Me-Momentum is able to extract high-quality confident examples. Note that the performance of Me-Momentum couldMethod \nValidation Accuracy \nCross Entropy \nClean \n69.54% \nMentorNet \nClean \n56.77% \nCo-teaching \nClean \n58.68% \nForward \nClean \n69.84% \nJoint Optim \nClean \n72.23% \nDMI \nClean \n72.46% \nT-revision \nClean \n74.18% \nDivideMix \nClean \n74.76% \nELR+ \nClean \n74.81% \nOurs (pre-trained) \nNoisy \n73.13% \nOurs (scratch) \nClean \n74.75% \nOurs (pre-trained) \nClean \n75.18% \n\n\nThe authors would like to thank Yu Yao and Xiaobo Xia for their helpful suggestions. The authors also would like to thank reviewers and Area Chair for their helpful comments. YB was supported by Agriculture Consultant and Smart Management. TL was supported by Australian Research Council Project DE-190101473.\nLearning from noisy examples. Dana Angluin, Philip Laird, Machine Learning. 2Dana Angluin and Philip Laird. Learning from noisy exam- ples. Machine Learning, 2(4):343-370, 1988. 1\n\nA closer look at memorization in deep networks. Devansh Arpit, Stanis\u0142aw Jastrzebski, Nicolas Ballas, David Krueger, Emmanuel Bengio, S Maxinder, Tegan Kanwal, Asja Maharaj, Aaron Fischer, Yoshua Courville, Bengio, ICML. 1Devansh Arpit, Stanis\u0142aw Jastrzebski, Nicolas Ballas, David Krueger, Emmanuel Bengio, Maxinder S Kanwal, Tegan Maharaj, Asja Fischer, Aaron Courville, and Yoshua Ben- gio. A closer look at memorization in deep networks. In ICML, pages 233-242, 2017. 1, 2\n\nYoshua Bengio, J\u00e9r\u00f4me Louradour, Ronan Collobert, Jason Weston, Curriculum learning. In ICML. Yoshua Bengio, J\u00e9r\u00f4me Louradour, Ronan Collobert, and Ja- son Weston. Curriculum learning. In ICML, pages 41-48, 2009. 1\n\nUnderstanding and utilizing deep neural networks trained with noisy labels. Pengfei Chen, Ben Ben Liao, Guangyong Chen, Shengyu Zhang, ICML. Pengfei Chen, Ben Ben Liao, Guangyong Chen, and Shengyu Zhang. Understanding and utilizing deep neural networks trained with noisy labels. In ICML, pages 1062- 1070, 2019. 1\n\nLearning with bounded instance-and label-dependent label noise. Jiacheng Cheng, Tongliang Liu, Kotagiri Ramamohanarao, Dacheng Tao, ICML. 2020Jiacheng Cheng, Tongliang Liu, Kotagiri Ramamohanarao, and Dacheng Tao. Learning with bounded instance-and label-dependent label noise. In ICML, 2020. 1\n\nConfidence-weighted linear classification. Mark Dredze, Koby Crammer, Fernando Pereira, ICML. Mark Dredze, Koby Crammer, and Fernando Pereira. Confidence-weighted linear classification. In ICML, pages 264-271, 2008. 1\n\nTraining deep neural-networks using a noise adaptation layer. Jacob Goldberger, Ehud Ben-Reuven, ICLR. Jacob Goldberger and Ehud Ben-Reuven. Training deep neural-networks using a noise adaptation layer. In ICLR, 2017. 1\n\nCurriculumnet: Weakly supervised learning from large-scale web images. Sheng Guo, Weilin Huang, Haozhi Zhang, Chenfan Zhuang, Dengke Dong, R Matthew, Dinglong Scott, Huang, ECCV. Sheng Guo, Weilin Huang, Haozhi Zhang, Chenfan Zhuang, Dengke Dong, Matthew R Scott, and Dinglong Huang. Cur- riculumnet: Weakly supervised learning from large-scale web images. In ECCV, pages 135-150, 2018. 1\n\nMasking: A new perspective of noisy supervision. Bo Han, Jiangchao Yao, Gang Niu, Mingyuan Zhou, Ivor Tsang, Ya Zhang, Masashi Sugiyama, NeurIPS. Bo Han, Jiangchao Yao, Gang Niu, Mingyuan Zhou, Ivor Tsang, Ya Zhang, and Masashi Sugiyama. Masking: A new perspective of noisy supervision. In NeurIPS, pages 5836- 5846, 2018. 1\n\nCoteaching: Robust training of deep neural networks with extremely noisy labels. Bo Han, Quanming Yao, Xingrui Yu, Gang Niu, Miao Xu, Weihua Hu, Ivor Tsang, Masashi Sugiyama, NeurIPS. 14Bo Han, Quanming Yao, Xingrui Yu, Gang Niu, Miao Xu, Weihua Hu, Ivor Tsang, and Masashi Sugiyama. Co- teaching: Robust training of deep neural networks with ex- tremely noisy labels. In NeurIPS, pages 8527-8537, 2018. 1, 3, 4\n\nDecision boundary analysis of adversarial examples. Warren He, Bo Li, Dawn Song, ICLR. Warren He, Bo Li, and Dawn Song. Decision boundary anal- ysis of adversarial examples. In ICLR, 2018. 1\n\nActive learning by querying informative and representative examples. Sheng-Jun Huang, Rong Jin, Zhi-Hua Zhou, NeurIPS. 1Sheng-Jun Huang, Rong Jin, and Zhi-Hua Zhou. Active learning by querying informative and representative exam- ples. In NeurIPS, pages 892-900, 2010. 1\n\nMentorNet: Learning data-driven curriculum for very deep neural networks on corrupted labels. Lu Jiang, Zhengyuan Zhou, Thomas Leung, Li-Jia Li, Li Fei-Fei, ICML. 14Lu Jiang, Zhengyuan Zhou, Thomas Leung, Li-Jia Li, and Li Fei-Fei. MentorNet: Learning data-driven curriculum for very deep neural networks on corrupted labels. In ICML, pages 2309-2318, 2018. 1, 3, 4\n\nRobust active label correction. Jan Kremer, Fei Sha, Christian Igel, AISTATS. Jan Kremer, Fei Sha, and Christian Igel. Robust active label correction. In AISTATS, pages 308-316, 2018. 1\n\nLearning multiple layers of features from tiny images. Alex Krizhevsky, Technical reportAlex Krizhevsky. Learning multiple layers of features from tiny images. Technical report, 2009. 4\n\nSelfpaced learning for latent variable models. Benjamin M Pawan Kumar, Daphne Packer, Koller, NeurIPS. 3M Pawan Kumar, Benjamin Packer, and Daphne Koller. Self- paced learning for latent variable models. In NeurIPS, pages 1189-1197, 2010. 3\n\nThe MNIST database of handwritten digits. Yann Lecun, Corinna Cortes, Christopher J C Burges, Yann LeCun, Corinna Cortes, and Christopher J.C. Burges. The MNIST database of handwritten digits. http://yann.lecun.com/exdb/mnist/, 1998. 4\n\nDividemix: Learning with noisy labels as semi-supervised learning. Junnan Li, Richard Socher, Steven C H Hoi, ICLR, 2020. 4Junnan Li, Richard Socher, and Steven C. H. Hoi. Di- videmix: Learning with noisy labels as semi-supervised learning. In ICLR, 2020. 4\n\nGradient descent with early stopping is provably robust to label noise for overparameterized neural networks. Mingchen Li, Mahdi Soltanolkotabi, Samet Oymak, AIS-TATS. 2020Mingchen Li, Mahdi Soltanolkotabi, and Samet Oymak. Gradient descent with early stopping is provably robust to label noise for overparameterized neural networks. In AIS- TATS, 2020. 1\n\nProvably end-to-end label-noise learning without anchor points. Xuefeng Li, Tongliang Liu, Bo Han, Gang Niu, Masashi Sugiyama, ICML. Xuefeng Li, Tongliang Liu, Bo Han, Gang Niu, and Masashi Sugiyama. Provably end-to-end label-noise learning without anchor points. In ICML, 2021. 1\n\nLearning from noisy labels with distillation. Yuncheng Li, Jianchao Yang, Yale Song, Liangliang Cao, Jiebo Luo, Li-Jia Li, ICCV. Yuncheng Li, Jianchao Yang, Yale Song, Liangliang Cao, Jiebo Luo, and Li-Jia Li. Learning from noisy labels with distillation. In ICCV, pages 1910-1918, 2017. 1\n\nNarges Razavian, and Carlos Fernandez-Granda. Early-learning regularization prevents memorization of noisy labels. Sheng Liu, Jonathan Niles-Weed, NeurIPS. Sheng Liu, Jonathan Niles-Weed, Narges Razavian, and Car- los Fernandez-Granda. Early-learning regularization pre- vents memorization of noisy labels. In NeurIPS, 2020. 4\n\nClassification with noisy labels by importance reweighting. Tongliang Liu, Dacheng Tao, IEEE Transactions. 3833Tongliang Liu and Dacheng Tao. Classification with noisy labels by importance reweighting. IEEE Transactions on pattern analysis and machine intelligence, 38(3):447-461, 2016. 1, 3\n\nPeer loss functions: Learning from noisy labels without knowing noise rates. Yang Liu, Hongyi Guo, ICML. Yang Liu and Hongyi Guo. Peer loss functions: Learning from noisy labels without knowing noise rates. In ICML, 2020. 1\n\nDimensionality-driven learning with noisy labels. Xingjun Ma, Yisen Wang, Michael E Houle, Shuo Zhou, M Sarah, Shu-Tao Erfani, Sudanthi Xia, James Wijewickrema, Bailey, ICML. Xingjun Ma, Yisen Wang, Michael E Houle, Shuo Zhou, Sarah M Erfani, Shu-Tao Xia, Sudanthi Wijewickrema, and James Bailey. Dimensionality-driven learning with noisy la- bels. In ICML, pages 3361-3370, 2018. 1\n\nVisualizing data using t-sne. Laurens Van Der Maaten, Geoffrey Hinton, Journal of machine learning research. 97Laurens van der Maaten and Geoffrey Hinton. Visualiz- ing data using t-sne. Journal of machine learning research, 9(Nov):2579-2605, 2008. 7\n\nDecoupling\" when to update\" from\" how to update. Eran Malach, Shai Shalev-Shwartz, NeurIPS. Eran Malach and Shai Shalev-Shwartz. Decoupling\" when to update\" from\" how to update\". In NeurIPS, pages 960-970, 2017. 1\n\nAfshin Rostamizadeh, and Ameet Talwalkar. Foundations of Machine Learning. Mehryar Mohri, MIT PressMehryar Mohri, Afshin Rostamizadeh, and Ameet Tal- walkar. Foundations of Machine Learning. MIT Press, 2018. 2\n\nLearning with noisy labels. Nagarajan Natarajan, S Inderjit, Dhillon, K Pradeep, Ambuj Ravikumar, Tewari, NeurIPS. 13Nagarajan Natarajan, Inderjit S Dhillon, Pradeep K Raviku- mar, and Ambuj Tewari. Learning with noisy labels. In NeurIPS, pages 1196-1204, 2013. 1, 3\n\nSELF: learning to filter noisy labels with selfensembling. Tam Nguyen, Mummadi, L Ngo, Thomas Beggel, Brox, ICLR, 2020. 1. 34Tam Nguyen, C Mummadi, T Ngo, L Beggel, and Thomas Brox. SELF: learning to filter noisy labels with self- ensembling. In ICLR, 2020. 1, 3, 4\n\nLearning with confident examples: Rank pruning for robust classification with noisy labels. Tailin Curtis G Northcutt, Isaac L Wu, Chuang, UAI. Curtis G Northcutt, Tailin Wu, and Isaac L Chuang. Learning with confident examples: Rank pruning for robust classifica- tion with noisy labels. In UAI, 2017. 1\n\nMaking deep neural networks robust to label noise: A loss correction approach. Giorgio Patrini, Alessandro Rozza, Aditya Krishna Menon, Richard Nock, Lizhen Qu, CVPR. 14Giorgio Patrini, Alessandro Rozza, Aditya Krishna Menon, Richard Nock, and Lizhen Qu. Making deep neural networks robust to label noise: A loss correction approach. In CVPR, pages 1944-1952, 2017. 1, 4\n\nTraining deep neural networks on noisy labels with bootstrapping. Honglak Scott E Reed, Dragomir Lee, Christian Anguelov, Dumitru Szegedy, Andrew Erhan, Rabinovich, ICLR. Scott E Reed, Honglak Lee, Dragomir Anguelov, Christian Szegedy, Dumitru Erhan, and Andrew Rabinovich. Training deep neural networks on noisy labels with bootstrapping. In ICLR, 2015. 1\n\nBin Yang, and Raquel Urtasun. Learning to reweight examples for robust deep learning. Mengye Ren, Wenyuan Zeng, ICML. Mengye Ren, Wenyuan Zeng, Bin Yang, and Raquel Urta- sun. Learning to reweight examples for robust deep learning. In ICML, pages 4331-4340, 2018. 1\n\nA rate of convergence for mixture proportion estimation, with application to learning from noisy labels. Clayton Scott, AISTATS. Clayton Scott. A rate of convergence for mixture proportion estimation, with application to learning from noisy labels. In AISTATS, pages 838-846, 2015. 1\n\nPrestopping: How does early stopping help generalization against label noise?. Hwanjun Song, Minseok Kim, Dongmin Park, Jae-Gil Lee, arXiv:1911.08059arXiv preprintHwanjun Song, Minseok Kim, Dongmin Park, and Jae-Gil Lee. Prestopping: How does early stopping help generaliza- tion against label noise? arXiv preprint arXiv:1911.08059, 2019. 1\n\nOn the importance of initialization and momentum in deep learning. Ilya Sutskever, James Martens, George Dahl, Geoffrey Hinton, ICML. Ilya Sutskever, James Martens, George Dahl, and Geoffrey Hinton. On the importance of initialization and momentum in deep learning. In ICML, pages 1139-1147, 2013. 2\n\nJoint optimization framework for learning with noisy labels. Daiki Tanaka, Daiki Ikami, Toshihiko Yamasaki, Kiyoharu Aizawa, CVPR. 14Daiki Tanaka, Daiki Ikami, Toshihiko Yamasaki, and Kiy- oharu Aizawa. Joint optimization framework for learning with noisy labels. In CVPR, pages 5552-5560, 2018. 1, 3, 4\n\nRobustness of conditional gans to noisy labels. Ashish Kiran K Thekumparampil, Zinan Khetan, Sewoong Lin, Oh, NeurIPS. Kiran K Thekumparampil, Ashish Khetan, Zinan Lin, and Sewoong Oh. Robustness of conditional gans to noisy labels. In NeurIPS, pages 10271-10282, 2018. 1\n\nCombating label noise in deep learning using abstention. Tanmoy Sunil Thulasidasan, Jeff Bhattacharya, Gopinath Bilmes, Jamal Chennupati, Mohd-Yusof, ICML. Sunil Thulasidasan, Tanmoy Bhattacharya, Jeff Bilmes, Gopinath Chennupati, and Jamal Mohd-Yusof. Combating label noise in deep learning using abstention. In ICML, pages 6234-6243, 2019. 1\n\nToward robustness against label noise in training deep discriminative neural networks. Arash Vahdat, NeurIPS. Arash Vahdat. Toward robustness against label noise in train- ing deep discriminative neural networks. In NeurIPS, pages 5596-5605, 2017. 1\n\nThe nature of statistical learning theory. Vladimir Vapnik, Springer science & business mediaVladimir Vapnik. The nature of statistical learning theory. Springer science & business media, 2013. 1\n\nLearning from noisy largescale datasets with minimal supervision. Andreas Veit, Neil Alldrin, Gal Chechik, Ivan Krasin, Abhinav Gupta, Serge Belongie, CVPR. Andreas Veit, Neil Alldrin, Gal Chechik, Ivan Krasin, Abhi- nav Gupta, and Serge Belongie. Learning from noisy large- scale datasets with minimal supervision. In CVPR, pages 839-847, 2017. 1\n\nRobust probabilistic modeling with bayesian data reweighting. Yixin Wang, Alp Kucukelbir, David M Blei, ICML. Yixin Wang, Alp Kucukelbir, and David M Blei. Robust probabilistic modeling with bayesian data reweighting. In ICML, pages 3646-3655. JMLR. org, 2017. 1\n\nClass2simi: A noise reduction perspective on learning with noisy labels. Songhua Wu, Xiaobo Xia, Tongliang Liu, Bo Han, Mingming Gong, Nannan Wang, Haifeng Liu, Gang Niu, ICML. Songhua Wu, Xiaobo Xia, Tongliang Liu, Bo Han, Ming- ming Gong, Nannan Wang, Haifeng Liu, and Gang Niu. Class2simi: A noise reduction perspective on learning with noisy labels. In ICML, 2021. 1\n\nRobust early-learning: Hindering the memorization of noisy labels. Xiaobo Xia, Tongliang Liu, Bo Han, Chen Gong, Nannan Wang, Zongyuan Ge, Yi Chang, ICLR, 2021. 4Xiaobo Xia, Tongliang Liu, Bo Han, Chen Gong, Nannan Wang, Zongyuan Ge, and Yi Chang. Robust early-learning: Hindering the memorization of noisy labels. In ICLR, 2021. 4\n\nInstance correction for learning with open-set noisy labels. Xiaobo Xia, Tongliang Liu, Bo Han, Mingming Gong, Jun Yu, Gang Niu, Masashi Sugiyama, arXiv:2106.00455arXiv preprintXiaobo Xia, Tongliang Liu, Bo Han, Mingming Gong, Jun Yu, Gang Niu, and Masashi Sugiyama. Instance correc- tion for learning with open-set noisy labels. arXiv preprint arXiv:2106.00455, 2021. 1\n\nSample selection with uncertainty of losses for learning with noisy labels. Xiaobo Xia, Tongliang Liu, Bo Han, Mingming Gong, Jun Yu, Gang Niu, Masashi Sugiyama, arXiv:2106.00445arXiv preprintXiaobo Xia, Tongliang Liu, Bo Han, Mingming Gong, Jun Yu, Gang Niu, and Masashi Sugiyama. Sample selection with uncertainty of losses for learning with noisy labels. arXiv preprint arXiv:2106.00445, 2021. 1\n\nExtended t: Learning with mixed closed-set and open-set noisy labels. Xiaobo Xia, Tongliang Liu, Bo Han, Nannan Wang, Jiankang Deng, Jiatong Li, Yinian Mao, arXiv:2012.00932arXiv preprintXiaobo Xia, Tongliang Liu, Bo Han, Nannan Wang, Jiankang Deng, Jiatong Li, and Yinian Mao. Extended t: Learning with mixed closed-set and open-set noisy labels. arXiv preprint arXiv:2012.00932, 2020. 1\n\nPart-dependent label noise: Towards instance-dependent label noise. Xiaobo Xia, Tongliang Liu, Bo Han, Nannan Wang, Mingming Gong, Haifeng Liu, Gang Niu, Dacheng Tao, Masashi Sugiyama, NeurIPS. Xiaobo Xia, Tongliang Liu, Bo Han, Nannan Wang, Ming- ming Gong, Haifeng Liu, Gang Niu, Dacheng Tao, and Masashi Sugiyama. Part-dependent label noise: Towards instance-dependent label noise. In NeurIPS, 2020. 1\n\nAre anchor points really indispensable in label-noise learning? In NeurIPS. Xiaobo Xia, Tongliang Liu, Nannan Wang, Bo Han, Chen Gong, Gang Niu, Masashi Sugiyama, 14Xiaobo Xia, Tongliang Liu, Nannan Wang, Bo Han, Chen Gong, Gang Niu, and Masashi Sugiyama. Are anchor points really indispensable in label-noise learning? In NeurIPS, pages 6835-6846, 2019. 1, 4\n\nLearning from massive noisy labeled data for image classification. Tong Xiao, Tian Xia, Yi Yang, Chang Huang, Xiaogang Wang, CVPR. 14Tong Xiao, Tian Xia, Yi Yang, Chang Huang, and Xiaogang Wang. Learning from massive noisy labeled data for image classification. In CVPR, pages 2691-2699, 2015. 1, 4\n\nL dmi: A novel information-theoretic loss function for training deep nets robust to label noise. Yilun Xu, Peng Cao, Yuqing Kong, Yizhou Wang, NeurIPS. Yilun Xu, Peng Cao, Yuqing Kong, and Yizhou Wang. L dmi: A novel information-theoretic loss function for train- ing deep nets robust to label noise. In NeurIPS, pages 6222- 6233, 2019. 4\n\nDual T: reducing estimation error for transition matrix in label-noise learning. Yu Yao, Tongliang Liu, Bo Han, Mingming Gong, Jiankang Deng, Gang Niu, Masashi Sugiyama, NeurIPS. Yu Yao, Tongliang Liu, Bo Han, Mingming Gong, Jiankang Deng, Gang Niu, and Masashi Sugiyama. Dual T: reducing estimation error for transition matrix in label-noise learning. In NeurIPS, 2020. 1\n\nHow does disagreement benefit co-teaching?. Xingrui Yu, Bo Han, Jiangchao Yao, Gang Niu, Ivor W Tsang, Masashi Sugiyama, ICML. 13Xingrui Yu, Bo Han, Jiangchao Yao, Gang Niu, Ivor W Tsang, and Masashi Sugiyama. How does disagreement ben- efit co-teaching? In ICML, 2019. 1, 3\n\nLearning with biased complementary labels. Xiyu Yu, Tongliang Liu, Mingming Gong, Dacheng Tao, ECCV. Xiyu Yu, Tongliang Liu, Mingming Gong, and Dacheng Tao. Learning with biased complementary labels. In ECCV, pages 68-83, 2018. 1\n\nUnderstanding deep learning requires rethinking generalization. Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, Oriol Vinyals, ICLR. 1Chiyuan Zhang, Samy Bengio, Moritz Hardt, Benjamin Recht, and Oriol Vinyals. Understanding deep learning re- quires rethinking generalization. In ICLR, 2017. 1, 2\n\nGeneralized cross entropy loss for training deep neural networks with noisy labels. Zhilu Zhang, Mert Sabuncu, NeurIPS. Zhilu Zhang and Mert Sabuncu. Generalized cross entropy loss for training deep neural networks with noisy labels. In NeurIPS, pages 8778-8788, 2018. 1\n", "annotations": {"author": "[{\"end\":145,\"start\":77},{\"end\":216,\"start\":146}]", "publisher": null, "author_last_name": "[{\"end\":88,\"start\":85},{\"end\":159,\"start\":156}]", "author_first_name": "[{\"end\":84,\"start\":77},{\"end\":155,\"start\":146}]", "author_affiliation": "[{\"end\":144,\"start\":90},{\"end\":215,\"start\":161}]", "title": "[{\"end\":74,\"start\":1},{\"end\":290,\"start\":217}]", "venue": null, "abstract": "[{\"end\":1622,\"start\":320}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b56\"},\"end\":1976,\"start\":1972},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2008,\"start\":2005},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":2436,\"start\":2432},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":2439,\"start\":2436},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":2442,\"start\":2439},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":2444,\"start\":2442},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":2447,\"start\":2444},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":2450,\"start\":2447},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":2453,\"start\":2450},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":2456,\"start\":2453},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":2459,\"start\":2456},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":2462,\"start\":2459},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":2465,\"start\":2462},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":2468,\"start\":2465},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":2669,\"start\":2665},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":2672,\"start\":2669},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":2675,\"start\":2672},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":2775,\"start\":2772},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":2924,\"start\":2920},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":2927,\"start\":2924},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":2930,\"start\":2927},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":2933,\"start\":2930},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":2935,\"start\":2933},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":2937,\"start\":2935},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":2940,\"start\":2937},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":2943,\"start\":2940},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":2946,\"start\":2943},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":2949,\"start\":2946},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":3179,\"start\":3175},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":3182,\"start\":3179},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":3185,\"start\":3182},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3187,\"start\":3185},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":3190,\"start\":3187},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":3193,\"start\":3190},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":3196,\"start\":3193},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":3199,\"start\":3196},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":3448,\"start\":3444},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3450,\"start\":3448},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":3671,\"start\":3667},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":3674,\"start\":3671},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3817,\"start\":3814},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":3849,\"start\":3845},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":3852,\"start\":3849},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":3882,\"start\":3878},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3885,\"start\":3882},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":3888,\"start\":3885},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":4260,\"start\":4256},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":4262,\"start\":4260},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":4265,\"start\":4262},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":4268,\"start\":4265},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":5196,\"start\":5192},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":6630,\"start\":6629},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":7509,\"start\":7506},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":7512,\"start\":7509},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":7613,\"start\":7610},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":9729,\"start\":9725},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":9732,\"start\":9729},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":9735,\"start\":9732},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":12079,\"start\":12075},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":12097,\"start\":12093},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":12100,\"start\":12097},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":12115,\"start\":12111},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":13233,\"start\":13229},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":13301,\"start\":13297},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":13937,\"start\":13933},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":13965,\"start\":13961},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":14178,\"start\":14174},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":14250,\"start\":14246},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":14253,\"start\":14250},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":14256,\"start\":14253},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":14945,\"start\":14941},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":14962,\"start\":14958},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":14976,\"start\":14972},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":15033,\"start\":15029},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":15050,\"start\":15046},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":15068,\"start\":15064},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":15079,\"start\":15075},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":15089,\"start\":15085},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":15106,\"start\":15102},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":15117,\"start\":15113},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":15759,\"start\":15755},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":19212,\"start\":19208}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":24233,\"start\":23554},{\"attributes\":{\"id\":\"fig_1\"},\"end\":25489,\"start\":24234},{\"attributes\":{\"id\":\"fig_2\"},\"end\":26627,\"start\":25490},{\"attributes\":{\"id\":\"fig_3\"},\"end\":27226,\"start\":26628},{\"attributes\":{\"id\":\"fig_4\"},\"end\":27754,\"start\":27227},{\"attributes\":{\"id\":\"fig_5\"},\"end\":28263,\"start\":27755},{\"attributes\":{\"id\":\"fig_6\"},\"end\":28770,\"start\":28264},{\"attributes\":{\"id\":\"fig_7\"},\"end\":28835,\"start\":28771},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":29441,\"start\":28836},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":31014,\"start\":29442},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":31616,\"start\":31015},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":33537,\"start\":31617}]", "paragraph": "[{\"end\":2119,\"start\":1638},{\"end\":2299,\"start\":2121},{\"end\":3065,\"start\":2301},{\"end\":3931,\"start\":3067},{\"end\":5995,\"start\":3933},{\"end\":6398,\"start\":5997},{\"end\":8337,\"start\":6414},{\"end\":9032,\"start\":8339},{\"end\":9036,\"start\":9034},{\"end\":9270,\"start\":9038},{\"end\":10269,\"start\":9272},{\"end\":10653,\"start\":10271},{\"end\":10730,\"start\":10655},{\"end\":11889,\"start\":10732},{\"end\":12884,\"start\":11891},{\"end\":13737,\"start\":12886},{\"end\":14257,\"start\":13753},{\"end\":14807,\"start\":14259},{\"end\":14977,\"start\":14809},{\"end\":15512,\"start\":14979},{\"end\":16227,\"start\":15514},{\"end\":17234,\"start\":16229},{\"end\":17647,\"start\":17270},{\"end\":19033,\"start\":17649},{\"end\":19973,\"start\":19071},{\"end\":20631,\"start\":19975},{\"end\":20851,\"start\":20659},{\"end\":21759,\"start\":20853},{\"end\":22378,\"start\":21778},{\"end\":22770,\"start\":22380},{\"end\":23535,\"start\":22785}]", "formula": null, "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":20941,\"start\":20934}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":1636,\"start\":1624},{\"attributes\":{\"n\":\"2.\"},\"end\":6412,\"start\":6401},{\"attributes\":{\"n\":\"3.\"},\"end\":13751,\"start\":13740},{\"attributes\":{\"n\":\"3.1.\"},\"end\":17268,\"start\":17237},{\"attributes\":{\"n\":\"3.2.\"},\"end\":19069,\"start\":19036},{\"attributes\":{\"n\":\"3.3.\"},\"end\":20657,\"start\":20634},{\"attributes\":{\"n\":\"3.4.\"},\"end\":21776,\"start\":21762},{\"attributes\":{\"n\":\"4.\"},\"end\":22783,\"start\":22773},{\"attributes\":{\"n\":\"5.\"},\"end\":23553,\"start\":23538},{\"end\":23565,\"start\":23555},{\"end\":25502,\"start\":25491},{\"end\":26639,\"start\":26629},{\"end\":27236,\"start\":27228},{\"end\":27766,\"start\":27756},{\"end\":28275,\"start\":28265},{\"end\":28782,\"start\":28772},{\"end\":29452,\"start\":29443},{\"end\":31025,\"start\":31016},{\"end\":31627,\"start\":31618}]", "table": "[{\"end\":31014,\"start\":29519},{\"end\":31616,\"start\":31588},{\"end\":33537,\"start\":33176}]", "figure_caption": "[{\"end\":24233,\"start\":23567},{\"end\":25489,\"start\":24236},{\"end\":26627,\"start\":25504},{\"end\":27226,\"start\":26641},{\"end\":27754,\"start\":27238},{\"end\":28263,\"start\":27768},{\"end\":28770,\"start\":28277},{\"end\":28835,\"start\":28784},{\"end\":29441,\"start\":28838},{\"end\":29519,\"start\":29454},{\"end\":31588,\"start\":31027},{\"end\":33176,\"start\":31629}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":4034,\"start\":4026},{\"end\":10720,\"start\":10718},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":10729,\"start\":10721},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":12693,\"start\":12677},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":17660,\"start\":17652},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":19354,\"start\":19346},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":22022,\"start\":22014},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":22198,\"start\":22190},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":22645,\"start\":22637}]", "bib_author_first_name": "[{\"end\":33882,\"start\":33878},{\"end\":33898,\"start\":33892},{\"end\":34084,\"start\":34077},{\"end\":34101,\"start\":34092},{\"end\":34122,\"start\":34115},{\"end\":34136,\"start\":34131},{\"end\":34154,\"start\":34146},{\"end\":34164,\"start\":34163},{\"end\":34180,\"start\":34175},{\"end\":34193,\"start\":34189},{\"end\":34208,\"start\":34203},{\"end\":34224,\"start\":34218},{\"end\":34513,\"start\":34507},{\"end\":34528,\"start\":34522},{\"end\":34545,\"start\":34540},{\"end\":34562,\"start\":34557},{\"end\":34806,\"start\":34799},{\"end\":34816,\"start\":34813},{\"end\":34820,\"start\":34817},{\"end\":34836,\"start\":34827},{\"end\":34850,\"start\":34843},{\"end\":35111,\"start\":35103},{\"end\":35128,\"start\":35119},{\"end\":35142,\"start\":35134},{\"end\":35165,\"start\":35158},{\"end\":35382,\"start\":35378},{\"end\":35395,\"start\":35391},{\"end\":35413,\"start\":35405},{\"end\":35621,\"start\":35616},{\"end\":35638,\"start\":35634},{\"end\":35851,\"start\":35846},{\"end\":35863,\"start\":35857},{\"end\":35877,\"start\":35871},{\"end\":35892,\"start\":35885},{\"end\":35907,\"start\":35901},{\"end\":35915,\"start\":35914},{\"end\":35933,\"start\":35925},{\"end\":36216,\"start\":36214},{\"end\":36231,\"start\":36222},{\"end\":36241,\"start\":36237},{\"end\":36255,\"start\":36247},{\"end\":36266,\"start\":36262},{\"end\":36276,\"start\":36274},{\"end\":36291,\"start\":36284},{\"end\":36574,\"start\":36572},{\"end\":36588,\"start\":36580},{\"end\":36601,\"start\":36594},{\"end\":36610,\"start\":36606},{\"end\":36620,\"start\":36616},{\"end\":36631,\"start\":36625},{\"end\":36640,\"start\":36636},{\"end\":36655,\"start\":36648},{\"end\":36962,\"start\":36956},{\"end\":36969,\"start\":36967},{\"end\":36978,\"start\":36974},{\"end\":37174,\"start\":37165},{\"end\":37186,\"start\":37182},{\"end\":37199,\"start\":37192},{\"end\":37464,\"start\":37462},{\"end\":37481,\"start\":37472},{\"end\":37494,\"start\":37488},{\"end\":37508,\"start\":37502},{\"end\":37515,\"start\":37513},{\"end\":37770,\"start\":37767},{\"end\":37782,\"start\":37779},{\"end\":37797,\"start\":37788},{\"end\":37981,\"start\":37977},{\"end\":38164,\"start\":38156},{\"end\":38186,\"start\":38180},{\"end\":38397,\"start\":38393},{\"end\":38412,\"start\":38405},{\"end\":38432,\"start\":38421},{\"end\":38436,\"start\":38433},{\"end\":38661,\"start\":38655},{\"end\":38673,\"start\":38666},{\"end\":38688,\"start\":38682},{\"end\":38692,\"start\":38689},{\"end\":38965,\"start\":38957},{\"end\":38975,\"start\":38970},{\"end\":38997,\"start\":38992},{\"end\":39275,\"start\":39268},{\"end\":39289,\"start\":39280},{\"end\":39297,\"start\":39295},{\"end\":39307,\"start\":39303},{\"end\":39320,\"start\":39313},{\"end\":39540,\"start\":39532},{\"end\":39553,\"start\":39545},{\"end\":39564,\"start\":39560},{\"end\":39581,\"start\":39571},{\"end\":39592,\"start\":39587},{\"end\":39604,\"start\":39598},{\"end\":39897,\"start\":39892},{\"end\":39911,\"start\":39903},{\"end\":40174,\"start\":40165},{\"end\":40187,\"start\":40180},{\"end\":40479,\"start\":40475},{\"end\":40491,\"start\":40485},{\"end\":40680,\"start\":40673},{\"end\":40690,\"start\":40685},{\"end\":40704,\"start\":40697},{\"end\":40706,\"start\":40705},{\"end\":40718,\"start\":40714},{\"end\":40726,\"start\":40725},{\"end\":40741,\"start\":40734},{\"end\":40758,\"start\":40750},{\"end\":40769,\"start\":40764},{\"end\":41044,\"start\":41037},{\"end\":41069,\"start\":41061},{\"end\":41312,\"start\":41308},{\"end\":41325,\"start\":41321},{\"end\":41556,\"start\":41549},{\"end\":41722,\"start\":41713},{\"end\":41735,\"start\":41734},{\"end\":41756,\"start\":41755},{\"end\":41771,\"start\":41766},{\"end\":42015,\"start\":42012},{\"end\":42034,\"start\":42033},{\"end\":42046,\"start\":42040},{\"end\":42318,\"start\":42312},{\"end\":42344,\"start\":42339},{\"end\":42346,\"start\":42345},{\"end\":42612,\"start\":42605},{\"end\":42632,\"start\":42622},{\"end\":42646,\"start\":42640},{\"end\":42654,\"start\":42647},{\"end\":42669,\"start\":42662},{\"end\":42682,\"start\":42676},{\"end\":42971,\"start\":42964},{\"end\":42994,\"start\":42986},{\"end\":43009,\"start\":43000},{\"end\":43027,\"start\":43020},{\"end\":43043,\"start\":43037},{\"end\":43348,\"start\":43342},{\"end\":43361,\"start\":43354},{\"end\":43635,\"start\":43628},{\"end\":43894,\"start\":43887},{\"end\":43908,\"start\":43901},{\"end\":43921,\"start\":43914},{\"end\":43935,\"start\":43928},{\"end\":44222,\"start\":44218},{\"end\":44239,\"start\":44234},{\"end\":44255,\"start\":44249},{\"end\":44270,\"start\":44262},{\"end\":44518,\"start\":44513},{\"end\":44532,\"start\":44527},{\"end\":44549,\"start\":44540},{\"end\":44568,\"start\":44560},{\"end\":44811,\"start\":44805},{\"end\":44841,\"start\":44836},{\"end\":44857,\"start\":44850},{\"end\":45093,\"start\":45087},{\"end\":45118,\"start\":45114},{\"end\":45141,\"start\":45133},{\"end\":45155,\"start\":45150},{\"end\":45467,\"start\":45462},{\"end\":45677,\"start\":45669},{\"end\":45896,\"start\":45889},{\"end\":45907,\"start\":45903},{\"end\":45920,\"start\":45917},{\"end\":45934,\"start\":45930},{\"end\":45950,\"start\":45943},{\"end\":45963,\"start\":45958},{\"end\":46239,\"start\":46234},{\"end\":46249,\"start\":46246},{\"end\":46267,\"start\":46262},{\"end\":46269,\"start\":46268},{\"end\":46516,\"start\":46509},{\"end\":46527,\"start\":46521},{\"end\":46542,\"start\":46533},{\"end\":46550,\"start\":46548},{\"end\":46564,\"start\":46556},{\"end\":46577,\"start\":46571},{\"end\":46591,\"start\":46584},{\"end\":46601,\"start\":46597},{\"end\":46881,\"start\":46875},{\"end\":46896,\"start\":46887},{\"end\":46904,\"start\":46902},{\"end\":46914,\"start\":46910},{\"end\":46927,\"start\":46921},{\"end\":46942,\"start\":46934},{\"end\":46949,\"start\":46947},{\"end\":47208,\"start\":47202},{\"end\":47223,\"start\":47214},{\"end\":47231,\"start\":47229},{\"end\":47245,\"start\":47237},{\"end\":47255,\"start\":47252},{\"end\":47264,\"start\":47260},{\"end\":47277,\"start\":47270},{\"end\":47595,\"start\":47589},{\"end\":47610,\"start\":47601},{\"end\":47618,\"start\":47616},{\"end\":47632,\"start\":47624},{\"end\":47642,\"start\":47639},{\"end\":47651,\"start\":47647},{\"end\":47664,\"start\":47657},{\"end\":47989,\"start\":47983},{\"end\":48004,\"start\":47995},{\"end\":48012,\"start\":48010},{\"end\":48024,\"start\":48018},{\"end\":48039,\"start\":48031},{\"end\":48053,\"start\":48046},{\"end\":48064,\"start\":48058},{\"end\":48377,\"start\":48371},{\"end\":48392,\"start\":48383},{\"end\":48400,\"start\":48398},{\"end\":48412,\"start\":48406},{\"end\":48427,\"start\":48419},{\"end\":48441,\"start\":48434},{\"end\":48451,\"start\":48447},{\"end\":48464,\"start\":48457},{\"end\":48477,\"start\":48470},{\"end\":48791,\"start\":48785},{\"end\":48806,\"start\":48797},{\"end\":48818,\"start\":48812},{\"end\":48827,\"start\":48825},{\"end\":48837,\"start\":48833},{\"end\":48848,\"start\":48844},{\"end\":48861,\"start\":48854},{\"end\":49141,\"start\":49137},{\"end\":49152,\"start\":49148},{\"end\":49160,\"start\":49158},{\"end\":49172,\"start\":49167},{\"end\":49188,\"start\":49180},{\"end\":49472,\"start\":49467},{\"end\":49481,\"start\":49477},{\"end\":49493,\"start\":49487},{\"end\":49506,\"start\":49500},{\"end\":49793,\"start\":49791},{\"end\":49808,\"start\":49799},{\"end\":49816,\"start\":49814},{\"end\":49830,\"start\":49822},{\"end\":49845,\"start\":49837},{\"end\":49856,\"start\":49852},{\"end\":49869,\"start\":49862},{\"end\":50135,\"start\":50128},{\"end\":50142,\"start\":50140},{\"end\":50157,\"start\":50148},{\"end\":50167,\"start\":50163},{\"end\":50177,\"start\":50173},{\"end\":50179,\"start\":50178},{\"end\":50194,\"start\":50187},{\"end\":50407,\"start\":50403},{\"end\":50421,\"start\":50412},{\"end\":50435,\"start\":50427},{\"end\":50449,\"start\":50442},{\"end\":50662,\"start\":50655},{\"end\":50674,\"start\":50670},{\"end\":50689,\"start\":50683},{\"end\":50705,\"start\":50697},{\"end\":50718,\"start\":50713},{\"end\":50988,\"start\":50983},{\"end\":51000,\"start\":50996}]", "bib_author_last_name": "[{\"end\":33890,\"start\":33883},{\"end\":33904,\"start\":33899},{\"end\":34090,\"start\":34085},{\"end\":34113,\"start\":34102},{\"end\":34129,\"start\":34123},{\"end\":34144,\"start\":34137},{\"end\":34161,\"start\":34155},{\"end\":34173,\"start\":34165},{\"end\":34187,\"start\":34181},{\"end\":34201,\"start\":34194},{\"end\":34216,\"start\":34209},{\"end\":34234,\"start\":34225},{\"end\":34242,\"start\":34236},{\"end\":34520,\"start\":34514},{\"end\":34538,\"start\":34529},{\"end\":34555,\"start\":34546},{\"end\":34569,\"start\":34563},{\"end\":34811,\"start\":34807},{\"end\":34825,\"start\":34821},{\"end\":34841,\"start\":34837},{\"end\":34856,\"start\":34851},{\"end\":35117,\"start\":35112},{\"end\":35132,\"start\":35129},{\"end\":35156,\"start\":35143},{\"end\":35169,\"start\":35166},{\"end\":35389,\"start\":35383},{\"end\":35403,\"start\":35396},{\"end\":35421,\"start\":35414},{\"end\":35632,\"start\":35622},{\"end\":35649,\"start\":35639},{\"end\":35855,\"start\":35852},{\"end\":35869,\"start\":35864},{\"end\":35883,\"start\":35878},{\"end\":35899,\"start\":35893},{\"end\":35912,\"start\":35908},{\"end\":35923,\"start\":35916},{\"end\":35939,\"start\":35934},{\"end\":35946,\"start\":35941},{\"end\":36220,\"start\":36217},{\"end\":36235,\"start\":36232},{\"end\":36245,\"start\":36242},{\"end\":36260,\"start\":36256},{\"end\":36272,\"start\":36267},{\"end\":36282,\"start\":36277},{\"end\":36300,\"start\":36292},{\"end\":36578,\"start\":36575},{\"end\":36592,\"start\":36589},{\"end\":36604,\"start\":36602},{\"end\":36614,\"start\":36611},{\"end\":36623,\"start\":36621},{\"end\":36634,\"start\":36632},{\"end\":36646,\"start\":36641},{\"end\":36664,\"start\":36656},{\"end\":36965,\"start\":36963},{\"end\":36972,\"start\":36970},{\"end\":36983,\"start\":36979},{\"end\":37180,\"start\":37175},{\"end\":37190,\"start\":37187},{\"end\":37204,\"start\":37200},{\"end\":37470,\"start\":37465},{\"end\":37486,\"start\":37482},{\"end\":37500,\"start\":37495},{\"end\":37511,\"start\":37509},{\"end\":37523,\"start\":37516},{\"end\":37777,\"start\":37771},{\"end\":37786,\"start\":37783},{\"end\":37802,\"start\":37798},{\"end\":37992,\"start\":37982},{\"end\":38178,\"start\":38165},{\"end\":38193,\"start\":38187},{\"end\":38201,\"start\":38195},{\"end\":38403,\"start\":38398},{\"end\":38419,\"start\":38413},{\"end\":38443,\"start\":38437},{\"end\":38664,\"start\":38662},{\"end\":38680,\"start\":38674},{\"end\":38696,\"start\":38693},{\"end\":38968,\"start\":38966},{\"end\":38990,\"start\":38976},{\"end\":39003,\"start\":38998},{\"end\":39278,\"start\":39276},{\"end\":39293,\"start\":39290},{\"end\":39301,\"start\":39298},{\"end\":39311,\"start\":39308},{\"end\":39329,\"start\":39321},{\"end\":39543,\"start\":39541},{\"end\":39558,\"start\":39554},{\"end\":39569,\"start\":39565},{\"end\":39585,\"start\":39582},{\"end\":39596,\"start\":39593},{\"end\":39607,\"start\":39605},{\"end\":39901,\"start\":39898},{\"end\":39922,\"start\":39912},{\"end\":40178,\"start\":40175},{\"end\":40191,\"start\":40188},{\"end\":40483,\"start\":40480},{\"end\":40495,\"start\":40492},{\"end\":40683,\"start\":40681},{\"end\":40695,\"start\":40691},{\"end\":40712,\"start\":40707},{\"end\":40723,\"start\":40719},{\"end\":40732,\"start\":40727},{\"end\":40748,\"start\":40742},{\"end\":40762,\"start\":40759},{\"end\":40782,\"start\":40770},{\"end\":40790,\"start\":40784},{\"end\":41059,\"start\":41045},{\"end\":41076,\"start\":41070},{\"end\":41319,\"start\":41313},{\"end\":41340,\"start\":41326},{\"end\":41562,\"start\":41557},{\"end\":41732,\"start\":41723},{\"end\":41744,\"start\":41736},{\"end\":41753,\"start\":41746},{\"end\":41764,\"start\":41757},{\"end\":41781,\"start\":41772},{\"end\":41789,\"start\":41783},{\"end\":42022,\"start\":42016},{\"end\":42031,\"start\":42024},{\"end\":42038,\"start\":42035},{\"end\":42053,\"start\":42047},{\"end\":42059,\"start\":42055},{\"end\":42337,\"start\":42319},{\"end\":42349,\"start\":42347},{\"end\":42357,\"start\":42351},{\"end\":42620,\"start\":42613},{\"end\":42638,\"start\":42633},{\"end\":42660,\"start\":42655},{\"end\":42674,\"start\":42670},{\"end\":42685,\"start\":42683},{\"end\":42984,\"start\":42972},{\"end\":42998,\"start\":42995},{\"end\":43018,\"start\":43010},{\"end\":43035,\"start\":43028},{\"end\":43049,\"start\":43044},{\"end\":43061,\"start\":43051},{\"end\":43352,\"start\":43349},{\"end\":43366,\"start\":43362},{\"end\":43641,\"start\":43636},{\"end\":43899,\"start\":43895},{\"end\":43912,\"start\":43909},{\"end\":43926,\"start\":43922},{\"end\":43939,\"start\":43936},{\"end\":44232,\"start\":44223},{\"end\":44247,\"start\":44240},{\"end\":44260,\"start\":44256},{\"end\":44277,\"start\":44271},{\"end\":44525,\"start\":44519},{\"end\":44538,\"start\":44533},{\"end\":44558,\"start\":44550},{\"end\":44575,\"start\":44569},{\"end\":44834,\"start\":44812},{\"end\":44848,\"start\":44842},{\"end\":44861,\"start\":44858},{\"end\":44865,\"start\":44863},{\"end\":45112,\"start\":45094},{\"end\":45131,\"start\":45119},{\"end\":45148,\"start\":45142},{\"end\":45166,\"start\":45156},{\"end\":45178,\"start\":45168},{\"end\":45474,\"start\":45468},{\"end\":45684,\"start\":45678},{\"end\":45901,\"start\":45897},{\"end\":45915,\"start\":45908},{\"end\":45928,\"start\":45921},{\"end\":45941,\"start\":45935},{\"end\":45956,\"start\":45951},{\"end\":45972,\"start\":45964},{\"end\":46244,\"start\":46240},{\"end\":46260,\"start\":46250},{\"end\":46274,\"start\":46270},{\"end\":46519,\"start\":46517},{\"end\":46531,\"start\":46528},{\"end\":46546,\"start\":46543},{\"end\":46554,\"start\":46551},{\"end\":46569,\"start\":46565},{\"end\":46582,\"start\":46578},{\"end\":46595,\"start\":46592},{\"end\":46605,\"start\":46602},{\"end\":46885,\"start\":46882},{\"end\":46900,\"start\":46897},{\"end\":46908,\"start\":46905},{\"end\":46919,\"start\":46915},{\"end\":46932,\"start\":46928},{\"end\":46945,\"start\":46943},{\"end\":46955,\"start\":46950},{\"end\":47212,\"start\":47209},{\"end\":47227,\"start\":47224},{\"end\":47235,\"start\":47232},{\"end\":47250,\"start\":47246},{\"end\":47258,\"start\":47256},{\"end\":47268,\"start\":47265},{\"end\":47286,\"start\":47278},{\"end\":47599,\"start\":47596},{\"end\":47614,\"start\":47611},{\"end\":47622,\"start\":47619},{\"end\":47637,\"start\":47633},{\"end\":47645,\"start\":47643},{\"end\":47655,\"start\":47652},{\"end\":47673,\"start\":47665},{\"end\":47993,\"start\":47990},{\"end\":48008,\"start\":48005},{\"end\":48016,\"start\":48013},{\"end\":48029,\"start\":48025},{\"end\":48044,\"start\":48040},{\"end\":48056,\"start\":48054},{\"end\":48068,\"start\":48065},{\"end\":48381,\"start\":48378},{\"end\":48396,\"start\":48393},{\"end\":48404,\"start\":48401},{\"end\":48417,\"start\":48413},{\"end\":48432,\"start\":48428},{\"end\":48445,\"start\":48442},{\"end\":48455,\"start\":48452},{\"end\":48468,\"start\":48465},{\"end\":48486,\"start\":48478},{\"end\":48795,\"start\":48792},{\"end\":48810,\"start\":48807},{\"end\":48823,\"start\":48819},{\"end\":48831,\"start\":48828},{\"end\":48842,\"start\":48838},{\"end\":48852,\"start\":48849},{\"end\":48870,\"start\":48862},{\"end\":49146,\"start\":49142},{\"end\":49156,\"start\":49153},{\"end\":49165,\"start\":49161},{\"end\":49178,\"start\":49173},{\"end\":49193,\"start\":49189},{\"end\":49475,\"start\":49473},{\"end\":49485,\"start\":49482},{\"end\":49498,\"start\":49494},{\"end\":49511,\"start\":49507},{\"end\":49797,\"start\":49794},{\"end\":49812,\"start\":49809},{\"end\":49820,\"start\":49817},{\"end\":49835,\"start\":49831},{\"end\":49850,\"start\":49846},{\"end\":49860,\"start\":49857},{\"end\":49878,\"start\":49870},{\"end\":50138,\"start\":50136},{\"end\":50146,\"start\":50143},{\"end\":50161,\"start\":50158},{\"end\":50171,\"start\":50168},{\"end\":50185,\"start\":50180},{\"end\":50203,\"start\":50195},{\"end\":50410,\"start\":50408},{\"end\":50425,\"start\":50422},{\"end\":50440,\"start\":50436},{\"end\":50453,\"start\":50450},{\"end\":50668,\"start\":50663},{\"end\":50681,\"start\":50675},{\"end\":50695,\"start\":50690},{\"end\":50711,\"start\":50706},{\"end\":50726,\"start\":50719},{\"end\":50994,\"start\":50989},{\"end\":51008,\"start\":51001}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":5508562},\"end\":34027,\"start\":33848},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":11455421},\"end\":34505,\"start\":34029},{\"attributes\":{\"id\":\"b2\"},\"end\":34721,\"start\":34507},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":152282273},\"end\":35037,\"start\":34723},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":34957763},\"end\":35333,\"start\":35039},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":708332},\"end\":35552,\"start\":35335},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":12190952},\"end\":35773,\"start\":35554},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":51920640},\"end\":36163,\"start\":35775},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":29153563},\"end\":36489,\"start\":36165},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":52065462},\"end\":36902,\"start\":36491},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":51757341},\"end\":37094,\"start\":36904},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":8326832},\"end\":37366,\"start\":37096},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":51876228},\"end\":37733,\"start\":37368},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":4875120},\"end\":37920,\"start\":37735},{\"attributes\":{\"id\":\"b14\"},\"end\":38107,\"start\":37922},{\"attributes\":{\"id\":\"b15\"},\"end\":38349,\"start\":38109},{\"attributes\":{\"id\":\"b16\"},\"end\":38586,\"start\":38351},{\"attributes\":{\"doi\":\"ICLR, 2020. 4\",\"id\":\"b17\"},\"end\":38845,\"start\":38588},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":85543143},\"end\":39202,\"start\":38847},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":231802306},\"end\":39484,\"start\":39204},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":14659675},\"end\":39775,\"start\":39486},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":220280447},\"end\":40103,\"start\":39777},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":11777930},\"end\":40396,\"start\":40105},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":203902373},\"end\":40621,\"start\":40398},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":46980528},\"end\":41005,\"start\":40623},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":5855042},\"end\":41257,\"start\":41007},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":1430496},\"end\":41472,\"start\":41259},{\"attributes\":{\"id\":\"b27\"},\"end\":41683,\"start\":41474},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":423350},\"end\":41951,\"start\":41685},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":203737303},\"end\":42218,\"start\":41953},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":19306177},\"end\":42524,\"start\":42220},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":16406313},\"end\":42896,\"start\":42526},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":2181703},\"end\":43254,\"start\":42898},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":4321928},\"end\":43521,\"start\":43256},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":7110638},\"end\":43806,\"start\":43523},{\"attributes\":{\"doi\":\"arXiv:1911.08059\",\"id\":\"b35\"},\"end\":44149,\"start\":43808},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":10940950},\"end\":44450,\"start\":44151},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":4544107},\"end\":44755,\"start\":44452},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":53212997},\"end\":45028,\"start\":44757},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":166227922},\"end\":45373,\"start\":45030},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":9963515},\"end\":45624,\"start\":45375},{\"attributes\":{\"id\":\"b41\"},\"end\":45821,\"start\":45626},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":164146},\"end\":46170,\"start\":45823},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":6335393},\"end\":46434,\"start\":46172},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":235458469},\"end\":46806,\"start\":46436},{\"attributes\":{\"doi\":\"ICLR, 2021. 4\",\"id\":\"b45\"},\"end\":47139,\"start\":46808},{\"attributes\":{\"doi\":\"arXiv:2106.00455\",\"id\":\"b46\"},\"end\":47511,\"start\":47141},{\"attributes\":{\"doi\":\"arXiv:2106.00445\",\"id\":\"b47\"},\"end\":47911,\"start\":47513},{\"attributes\":{\"doi\":\"arXiv:2012.00932\",\"id\":\"b48\"},\"end\":48301,\"start\":47913},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":219687585},\"end\":48707,\"start\":48303},{\"attributes\":{\"id\":\"b50\"},\"end\":49068,\"start\":48709},{\"attributes\":{\"id\":\"b51\",\"matched_paper_id\":206592873},\"end\":49368,\"start\":49070},{\"attributes\":{\"id\":\"b52\",\"matched_paper_id\":202740892},\"end\":49708,\"start\":49370},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":219687353},\"end\":50082,\"start\":49710},{\"attributes\":{\"id\":\"b54\",\"matched_paper_id\":197523842},\"end\":50358,\"start\":50084},{\"attributes\":{\"id\":\"b55\",\"matched_paper_id\":24758700},\"end\":50589,\"start\":50360},{\"attributes\":{\"id\":\"b56\",\"matched_paper_id\":6212000},\"end\":50897,\"start\":50591},{\"attributes\":{\"id\":\"b57\",\"matched_paper_id\":29164161},\"end\":51169,\"start\":50899}]", "bib_title": "[{\"end\":33876,\"start\":33848},{\"end\":34075,\"start\":34029},{\"end\":34797,\"start\":34723},{\"end\":35101,\"start\":35039},{\"end\":35376,\"start\":35335},{\"end\":35614,\"start\":35554},{\"end\":35844,\"start\":35775},{\"end\":36212,\"start\":36165},{\"end\":36570,\"start\":36491},{\"end\":36954,\"start\":36904},{\"end\":37163,\"start\":37096},{\"end\":37460,\"start\":37368},{\"end\":37765,\"start\":37735},{\"end\":38154,\"start\":38109},{\"end\":38955,\"start\":38847},{\"end\":39266,\"start\":39204},{\"end\":39530,\"start\":39486},{\"end\":39890,\"start\":39777},{\"end\":40163,\"start\":40105},{\"end\":40473,\"start\":40398},{\"end\":40671,\"start\":40623},{\"end\":41035,\"start\":41007},{\"end\":41306,\"start\":41259},{\"end\":41711,\"start\":41685},{\"end\":42010,\"start\":41953},{\"end\":42310,\"start\":42220},{\"end\":42603,\"start\":42526},{\"end\":42962,\"start\":42898},{\"end\":43340,\"start\":43256},{\"end\":43626,\"start\":43523},{\"end\":44216,\"start\":44151},{\"end\":44511,\"start\":44452},{\"end\":44803,\"start\":44757},{\"end\":45085,\"start\":45030},{\"end\":45460,\"start\":45375},{\"end\":45887,\"start\":45823},{\"end\":46232,\"start\":46172},{\"end\":46507,\"start\":46436},{\"end\":48369,\"start\":48303},{\"end\":49135,\"start\":49070},{\"end\":49465,\"start\":49370},{\"end\":49789,\"start\":49710},{\"end\":50126,\"start\":50084},{\"end\":50401,\"start\":50360},{\"end\":50653,\"start\":50591},{\"end\":50981,\"start\":50899}]", "bib_author": "[{\"end\":33892,\"start\":33878},{\"end\":33906,\"start\":33892},{\"end\":34092,\"start\":34077},{\"end\":34115,\"start\":34092},{\"end\":34131,\"start\":34115},{\"end\":34146,\"start\":34131},{\"end\":34163,\"start\":34146},{\"end\":34175,\"start\":34163},{\"end\":34189,\"start\":34175},{\"end\":34203,\"start\":34189},{\"end\":34218,\"start\":34203},{\"end\":34236,\"start\":34218},{\"end\":34244,\"start\":34236},{\"end\":34522,\"start\":34507},{\"end\":34540,\"start\":34522},{\"end\":34557,\"start\":34540},{\"end\":34571,\"start\":34557},{\"end\":34813,\"start\":34799},{\"end\":34827,\"start\":34813},{\"end\":34843,\"start\":34827},{\"end\":34858,\"start\":34843},{\"end\":35119,\"start\":35103},{\"end\":35134,\"start\":35119},{\"end\":35158,\"start\":35134},{\"end\":35171,\"start\":35158},{\"end\":35391,\"start\":35378},{\"end\":35405,\"start\":35391},{\"end\":35423,\"start\":35405},{\"end\":35634,\"start\":35616},{\"end\":35651,\"start\":35634},{\"end\":35857,\"start\":35846},{\"end\":35871,\"start\":35857},{\"end\":35885,\"start\":35871},{\"end\":35901,\"start\":35885},{\"end\":35914,\"start\":35901},{\"end\":35925,\"start\":35914},{\"end\":35941,\"start\":35925},{\"end\":35948,\"start\":35941},{\"end\":36222,\"start\":36214},{\"end\":36237,\"start\":36222},{\"end\":36247,\"start\":36237},{\"end\":36262,\"start\":36247},{\"end\":36274,\"start\":36262},{\"end\":36284,\"start\":36274},{\"end\":36302,\"start\":36284},{\"end\":36580,\"start\":36572},{\"end\":36594,\"start\":36580},{\"end\":36606,\"start\":36594},{\"end\":36616,\"start\":36606},{\"end\":36625,\"start\":36616},{\"end\":36636,\"start\":36625},{\"end\":36648,\"start\":36636},{\"end\":36666,\"start\":36648},{\"end\":36967,\"start\":36956},{\"end\":36974,\"start\":36967},{\"end\":36985,\"start\":36974},{\"end\":37182,\"start\":37165},{\"end\":37192,\"start\":37182},{\"end\":37206,\"start\":37192},{\"end\":37472,\"start\":37462},{\"end\":37488,\"start\":37472},{\"end\":37502,\"start\":37488},{\"end\":37513,\"start\":37502},{\"end\":37525,\"start\":37513},{\"end\":37779,\"start\":37767},{\"end\":37788,\"start\":37779},{\"end\":37804,\"start\":37788},{\"end\":37994,\"start\":37977},{\"end\":38180,\"start\":38156},{\"end\":38195,\"start\":38180},{\"end\":38203,\"start\":38195},{\"end\":38405,\"start\":38393},{\"end\":38421,\"start\":38405},{\"end\":38445,\"start\":38421},{\"end\":38666,\"start\":38655},{\"end\":38682,\"start\":38666},{\"end\":38698,\"start\":38682},{\"end\":38970,\"start\":38957},{\"end\":38992,\"start\":38970},{\"end\":39005,\"start\":38992},{\"end\":39280,\"start\":39268},{\"end\":39295,\"start\":39280},{\"end\":39303,\"start\":39295},{\"end\":39313,\"start\":39303},{\"end\":39331,\"start\":39313},{\"end\":39545,\"start\":39532},{\"end\":39560,\"start\":39545},{\"end\":39571,\"start\":39560},{\"end\":39587,\"start\":39571},{\"end\":39598,\"start\":39587},{\"end\":39609,\"start\":39598},{\"end\":39903,\"start\":39892},{\"end\":39924,\"start\":39903},{\"end\":40180,\"start\":40165},{\"end\":40193,\"start\":40180},{\"end\":40485,\"start\":40475},{\"end\":40497,\"start\":40485},{\"end\":40685,\"start\":40673},{\"end\":40697,\"start\":40685},{\"end\":40714,\"start\":40697},{\"end\":40725,\"start\":40714},{\"end\":40734,\"start\":40725},{\"end\":40750,\"start\":40734},{\"end\":40764,\"start\":40750},{\"end\":40784,\"start\":40764},{\"end\":40792,\"start\":40784},{\"end\":41061,\"start\":41037},{\"end\":41078,\"start\":41061},{\"end\":41321,\"start\":41308},{\"end\":41342,\"start\":41321},{\"end\":41564,\"start\":41549},{\"end\":41734,\"start\":41713},{\"end\":41746,\"start\":41734},{\"end\":41755,\"start\":41746},{\"end\":41766,\"start\":41755},{\"end\":41783,\"start\":41766},{\"end\":41791,\"start\":41783},{\"end\":42024,\"start\":42012},{\"end\":42033,\"start\":42024},{\"end\":42040,\"start\":42033},{\"end\":42055,\"start\":42040},{\"end\":42061,\"start\":42055},{\"end\":42339,\"start\":42312},{\"end\":42351,\"start\":42339},{\"end\":42359,\"start\":42351},{\"end\":42622,\"start\":42605},{\"end\":42640,\"start\":42622},{\"end\":42662,\"start\":42640},{\"end\":42676,\"start\":42662},{\"end\":42687,\"start\":42676},{\"end\":42986,\"start\":42964},{\"end\":43000,\"start\":42986},{\"end\":43020,\"start\":43000},{\"end\":43037,\"start\":43020},{\"end\":43051,\"start\":43037},{\"end\":43063,\"start\":43051},{\"end\":43354,\"start\":43342},{\"end\":43368,\"start\":43354},{\"end\":43643,\"start\":43628},{\"end\":43901,\"start\":43887},{\"end\":43914,\"start\":43901},{\"end\":43928,\"start\":43914},{\"end\":43941,\"start\":43928},{\"end\":44234,\"start\":44218},{\"end\":44249,\"start\":44234},{\"end\":44262,\"start\":44249},{\"end\":44279,\"start\":44262},{\"end\":44527,\"start\":44513},{\"end\":44540,\"start\":44527},{\"end\":44560,\"start\":44540},{\"end\":44577,\"start\":44560},{\"end\":44836,\"start\":44805},{\"end\":44850,\"start\":44836},{\"end\":44863,\"start\":44850},{\"end\":44867,\"start\":44863},{\"end\":45114,\"start\":45087},{\"end\":45133,\"start\":45114},{\"end\":45150,\"start\":45133},{\"end\":45168,\"start\":45150},{\"end\":45180,\"start\":45168},{\"end\":45476,\"start\":45462},{\"end\":45686,\"start\":45669},{\"end\":45903,\"start\":45889},{\"end\":45917,\"start\":45903},{\"end\":45930,\"start\":45917},{\"end\":45943,\"start\":45930},{\"end\":45958,\"start\":45943},{\"end\":45974,\"start\":45958},{\"end\":46246,\"start\":46234},{\"end\":46262,\"start\":46246},{\"end\":46276,\"start\":46262},{\"end\":46521,\"start\":46509},{\"end\":46533,\"start\":46521},{\"end\":46548,\"start\":46533},{\"end\":46556,\"start\":46548},{\"end\":46571,\"start\":46556},{\"end\":46584,\"start\":46571},{\"end\":46597,\"start\":46584},{\"end\":46607,\"start\":46597},{\"end\":46887,\"start\":46875},{\"end\":46902,\"start\":46887},{\"end\":46910,\"start\":46902},{\"end\":46921,\"start\":46910},{\"end\":46934,\"start\":46921},{\"end\":46947,\"start\":46934},{\"end\":46957,\"start\":46947},{\"end\":47214,\"start\":47202},{\"end\":47229,\"start\":47214},{\"end\":47237,\"start\":47229},{\"end\":47252,\"start\":47237},{\"end\":47260,\"start\":47252},{\"end\":47270,\"start\":47260},{\"end\":47288,\"start\":47270},{\"end\":47601,\"start\":47589},{\"end\":47616,\"start\":47601},{\"end\":47624,\"start\":47616},{\"end\":47639,\"start\":47624},{\"end\":47647,\"start\":47639},{\"end\":47657,\"start\":47647},{\"end\":47675,\"start\":47657},{\"end\":47995,\"start\":47983},{\"end\":48010,\"start\":47995},{\"end\":48018,\"start\":48010},{\"end\":48031,\"start\":48018},{\"end\":48046,\"start\":48031},{\"end\":48058,\"start\":48046},{\"end\":48070,\"start\":48058},{\"end\":48383,\"start\":48371},{\"end\":48398,\"start\":48383},{\"end\":48406,\"start\":48398},{\"end\":48419,\"start\":48406},{\"end\":48434,\"start\":48419},{\"end\":48447,\"start\":48434},{\"end\":48457,\"start\":48447},{\"end\":48470,\"start\":48457},{\"end\":48488,\"start\":48470},{\"end\":48797,\"start\":48785},{\"end\":48812,\"start\":48797},{\"end\":48825,\"start\":48812},{\"end\":48833,\"start\":48825},{\"end\":48844,\"start\":48833},{\"end\":48854,\"start\":48844},{\"end\":48872,\"start\":48854},{\"end\":49148,\"start\":49137},{\"end\":49158,\"start\":49148},{\"end\":49167,\"start\":49158},{\"end\":49180,\"start\":49167},{\"end\":49195,\"start\":49180},{\"end\":49477,\"start\":49467},{\"end\":49487,\"start\":49477},{\"end\":49500,\"start\":49487},{\"end\":49513,\"start\":49500},{\"end\":49799,\"start\":49791},{\"end\":49814,\"start\":49799},{\"end\":49822,\"start\":49814},{\"end\":49837,\"start\":49822},{\"end\":49852,\"start\":49837},{\"end\":49862,\"start\":49852},{\"end\":49880,\"start\":49862},{\"end\":50140,\"start\":50128},{\"end\":50148,\"start\":50140},{\"end\":50163,\"start\":50148},{\"end\":50173,\"start\":50163},{\"end\":50187,\"start\":50173},{\"end\":50205,\"start\":50187},{\"end\":50412,\"start\":50403},{\"end\":50427,\"start\":50412},{\"end\":50442,\"start\":50427},{\"end\":50455,\"start\":50442},{\"end\":50670,\"start\":50655},{\"end\":50683,\"start\":50670},{\"end\":50697,\"start\":50683},{\"end\":50713,\"start\":50697},{\"end\":50728,\"start\":50713},{\"end\":50996,\"start\":50983},{\"end\":51010,\"start\":50996}]", "bib_venue": "[{\"end\":33922,\"start\":33906},{\"end\":34248,\"start\":34244},{\"end\":34599,\"start\":34571},{\"end\":34862,\"start\":34858},{\"end\":35175,\"start\":35171},{\"end\":35427,\"start\":35423},{\"end\":35655,\"start\":35651},{\"end\":35952,\"start\":35948},{\"end\":36309,\"start\":36302},{\"end\":36673,\"start\":36666},{\"end\":36989,\"start\":36985},{\"end\":37213,\"start\":37206},{\"end\":37529,\"start\":37525},{\"end\":37811,\"start\":37804},{\"end\":37975,\"start\":37922},{\"end\":38210,\"start\":38203},{\"end\":38391,\"start\":38351},{\"end\":38653,\"start\":38588},{\"end\":39013,\"start\":39005},{\"end\":39335,\"start\":39331},{\"end\":39613,\"start\":39609},{\"end\":39931,\"start\":39924},{\"end\":40210,\"start\":40193},{\"end\":40501,\"start\":40497},{\"end\":40796,\"start\":40792},{\"end\":41114,\"start\":41078},{\"end\":41349,\"start\":41342},{\"end\":41547,\"start\":41474},{\"end\":41798,\"start\":41791},{\"end\":42074,\"start\":42061},{\"end\":42362,\"start\":42359},{\"end\":42691,\"start\":42687},{\"end\":43067,\"start\":43063},{\"end\":43372,\"start\":43368},{\"end\":43650,\"start\":43643},{\"end\":43885,\"start\":43808},{\"end\":44283,\"start\":44279},{\"end\":44581,\"start\":44577},{\"end\":44874,\"start\":44867},{\"end\":45184,\"start\":45180},{\"end\":45483,\"start\":45476},{\"end\":45667,\"start\":45626},{\"end\":45978,\"start\":45974},{\"end\":46280,\"start\":46276},{\"end\":46611,\"start\":46607},{\"end\":46873,\"start\":46808},{\"end\":47200,\"start\":47141},{\"end\":47587,\"start\":47513},{\"end\":47981,\"start\":47913},{\"end\":48495,\"start\":48488},{\"end\":48783,\"start\":48709},{\"end\":49199,\"start\":49195},{\"end\":49520,\"start\":49513},{\"end\":49887,\"start\":49880},{\"end\":50209,\"start\":50205},{\"end\":50459,\"start\":50455},{\"end\":50732,\"start\":50728},{\"end\":51017,\"start\":51010}]"}}}, "year": 2023, "month": 12, "day": 17}