{"id": 246863421, "updated": "2023-10-05 16:55:33.041", "metadata": {"title": "Deep Constrained Least Squares for Blind Image Super-Resolution", "authors": "[{\"first\":\"Ziwei\",\"last\":\"Luo\",\"middle\":[]},{\"first\":\"Haibin\",\"last\":\"Huang\",\"middle\":[]},{\"first\":\"Lei\",\"last\":\"Yu\",\"middle\":[]},{\"first\":\"Youwei\",\"last\":\"Li\",\"middle\":[]},{\"first\":\"Haoqiang\",\"last\":\"Fan\",\"middle\":[]},{\"first\":\"Shuaicheng\",\"last\":\"Liu\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "In this paper, we tackle the problem of blind image super-resolution(SR) with a reformulated degradation model and two novel modules. Following the common practices of blind SR, our method proposes to improve both the kernel estimation as well as the kernel-based high-resolution image restoration. To be more specific, we first reformulate the degradation model such that the deblurring kernel estimation can be transferred into the low-resolution space. On top of this, we introduce a dynamic deep linear filter module. Instead of learning a fixed kernel for all images, it can adaptively generate deblurring kernel weights conditional on the input and yield a more robust kernel estimation. Subsequently, a deep constrained least square filtering module is applied to generate clean features based on the reformulation and estimated kernel. The deblurred feature and the low input image feature are then fed into a dual-path structured SR network and restore the final high-resolution result. To evaluate our method, we further conduct evaluations on several benchmarks, including Gaussian8 and DIV2KRK. Our experiments demonstrate that the proposed method achieves better accuracy and visual improvements against state-of-the-art methods.", "fields_of_study": "[\"Engineering\",\"Computer Science\"]", "external_ids": {"arxiv": "2202.07508", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/cvpr/LuoHYLFL22", "doi": "10.1109/cvpr52688.2022.01712"}}, "content": {"source": {"pdf_hash": "1075d3459a1270ee381c94f77c9ff8bfc6d4c07b", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2202.07508v3.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "1473e72ab68c1eee4546b50d6e84faad4c1b3803", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/1075d3459a1270ee381c94f77c9ff8bfc6d4c07b.txt", "contents": "\nDeep Constrained Least Squares for Blind Image Super-Resolution\n\n\nZiwei Luo \nMegvii Technology\n\n\nHaibin Huang \nKuaishou Technology\n\n\nLei Yu \nMegvii Technology\n\n\nYouwei Li \nMegvii Technology\n\n\nHaoqiang Fan \nMegvii Technology\n\n\nShuaicheng Liu \nMegvii Technology\n\n\nUniversity of Electronic Science\nTechnology of China\n\nDeep Constrained Least Squares for Blind Image Super-Resolution\n\nBicubic ZSSR GT IKC AdaTarget DANv2 KOALAnet Ours LR Img 28 in DIV2KRK Figure 1. Blind super-resolution of Img 28 from DIV2KRK [3], for scale factor 4. Based on the proposed deep constrained least squares (DCLS) deconvolution, our method is effective in restoring sharp and clean edges, and outperforms previous state-of-the-art approaches such as KernelGAN [3]+ZSSR [41], IKC [9], DAN [30, 31], AdaTarget [14], and KOALAnet [19].AbstractIn this paper, we tackle the problem of blind image superresolution(SR) with a reformulated degradation model and two novel modules. Following the common practices of blind SR, our method proposes to improve both the kernel estimation as well as the kernel based high resolution image restoration. To be more specific, we first reformulate the degradation model such that the deblurring kernel estimation can be transferred into the low resolution space. On top of this, we introduce a dynamic deep linear filter module. Instead of learning a fixed kernel for all images, it can adaptively generate deblurring kernel weights conditional on the input and yields more robust kernel estimation. Subsequently, a deep constrained least square filtering module is applied to generate clean features based on the reformulation and estimated kernel. The deblurred feature and the low input image feature are then fed into a dual-path structured SR network and restore the final high resolution result. To evaluate our method, we further conduct evaluations on several benchmarks, including Gaussian8 and DIV2KRK. Our experiments demonstrate that the proposed method achieves better accuracy and visual improvements * Corresponding author.against state-of-the-art methods.\n\nAbstract\n\nIn this paper, we tackle the problem of blind image superresolution(SR) with a reformulated degradation model and two novel modules. Following the common practices of blind SR, our method proposes to improve both the kernel estimation as well as the kernel based high resolution image restoration. To be more specific, we first reformulate the degradation model such that the deblurring kernel estimation can be transferred into the low resolution space. On top of this, we introduce a dynamic deep linear filter module. Instead of learning a fixed kernel for all images, it can adaptively generate deblurring kernel weights conditional on the input and yields more robust kernel estimation. Subsequently, a deep constrained least square filtering module is applied to generate clean features based on the reformulation and estimated kernel. The deblurred feature and the low input image feature are then fed into a dual-path structured SR network and restore the final high resolution result. To evaluate our method, we further conduct evaluations on several benchmarks, including Gaussian8 and DIV2KRK. Our experiments demonstrate that the proposed method achieves better accuracy and visual improvements\n\n\nIntroduction\n\nIn this work, we study the problem of image superresolution,i.e., restoring high-resolution images from lowresolution inputs. Specially, we aim for single image superresolution (SISR), where only one observation is given which is a more practical setting and with a wide range of downstream applications [6,8,10,17,22,26,28,48,57,59].\n\nMost existing works based on the classical SISR degradation model assuming that the input LR image y is a blurred and down-scaled HR image x with additional white Gaussian noise n, given by\ny = (x * k h ) \u2193s + n,(1)\nwhere k h is the blur kernel applied on x, * denotes convolution operation and \u2193 s denotes downsampling with scale factor s. Previous blind SR approaches [9,30] generally solve this problem with a two-stage framework: kernel estimation from LR image and kernel based HR image restoration. We argue that although such a pipeline demonstrates reasonable performance for SR problem, there are two main drawbacks: First of all, it is difficult to accurately estimate blur kernels of HR space directly from LR images due to the ambiguity produced by undersampling step [38,46]. And the mismatch between the estimated kernel and the real one will cause significant performance drop and even lead to unpleasant artifacts [3,9,13,56]. Secondly, it is also challenging to find a suitable way to fully utilize the information of the estimated HR space kernel and LR space image. A common solution is to employ a kernel stretching strategy [9,30,56], where the principal components of the vectorized kernel are preserved and stretched into degradation maps with the same size as the LR input. These degradation maps then can be concatenated with the input image or its features to generate a clean HR image. However, the spatial relation of the kernel is destroyed by the process of vectorizing and PCA (Principal Component Analysis), which causes insufficient usage of the kernel. The subsequent reconstruction network requires a huge effort to harmonize the inconsistent information between LR features and HR-specific kernels, limiting its performance in super-resolving images.\n\nTowards this end, we present a modified learning strategy to tackle the blind SR problem, which can naturally avoid the above mentioned drawbacks. Specifically, we first reformulate the degradation model in a way such that the blur kernel estimation and image upsampling can be disentangled. In particular, as shown in Fig. 2, we derive a new kernel from the primitive kernel k h and LR image. It transfers the kernel estimation into the LR space and the new kernel can be estimated without aliasing ambiguity. Based on the new degradation, we further introduce the dynamic deep linear kernel (DDLK) to provide more equivalent choices of possible optimal solutions for the kernel to accelerate training. Subsequently, a novel deep constrained least squares (DCLS) deconvolution module is applied in the feature domain to obtain deblurred features. DCLS is robust to noise and can provide a theoretical and principled guidance to obtain clean images/features from blurred inputs. Moreover, it dosen't require kernel stretching strategy and thus preserves the kernel's spatial relation information. Then the deblurred features are fed into an upsampling module to restore the clean HR images. As illustrated in Fig. 1, the overall method has turned out to be surprisingly effective in recovering sharp and clean SR images.\n\nThe main contributions are summarized as follows:\n\n\u2022 We introduce a new practical degradation model derived from Eq. (1). Such degradation maintains consistency with the classical model and allows us reliably estimate blur kernel from low-resolution space.\n\n\u2022 We propose to use a dynamic deep linear kernel instead of a single layer kernel, which provides more equivalent choices of the optimal solution of the kernel, which is easier to learn. \u2022 We propose a novel deconvolution module named DCLS that is applied on the features as channel-wise deblurring so that we can obtain a clean HR image.\n\n\u2022 Extensive experiments on various degradation kernels demonstrate that our method leads to state-of-the-art performance in blind SR problems.\n\n\nRelated work\n\nNon-blind SR Since pioneering work SRCNN [6] proposes to learn image SR with a three-layer convolution network, most subsequent works have focused on optimizing the network architectures [5,10,17,18,21,28,32,40,43,55,59,61, 62] and loss functions [15,22,29,47,48,52,58]. These CNN-based methods have achieved impressive performance on SISR with a predefined single degradation setting (e.g., bicubic downsampling). However, they may suffer significant performance drops when the predefined degradation kernel is different from the real one. Some non-blind SR approaches address the multiple degradation problem by restoring HR images with given the corresponding kernels. Specifically, SRMD [56] is the first method that concatenates LR image with a stretched blur kernel as inputs to obtain a super-resolved image under different degradations. Later, Zhang et al. [54,57] incorporate advanced deblurring algorithms and extend the degradation to arbitrary blur kernels. UDVD [51] improves the performance by incorporating dynamic convolution. Hussein et al. [13] introduce a correction filter that transfers blurry LR images to match the bicubicly designed SR model. Besides, zero-shot methods [42,51] have also been investigated in non-blind SR with multiple degradations. Blind SR Under the blind SR setting, HR image is recovered from the LR image degraded with unknown kernel [24,25,35]. Most approaches solve this problem with a two stage framework: kernel estimation and kernel-based HR image restoration. For the former, KernelGAN [3] estimates the degradation kernel by utilizing an internal generative adversarial network(GAN) on a single image, and applies that kernel to a non-blind SR approach such as ZSSR to get the SR result. Liang et al. [27] improve the kernel estimating performance by introducing a flow-based prior. Furthermore, Tao et al. [44] propose a spectrum-to-kernel network and demonstrate that estimating blur kernel in the frequency domain is more conducive than in spatial domain. For the latter, Gu et al. [9] propose to apply spatial feature transform (SFT) and iterative kernel correction (IKC) strategy for accurate kernel estimation and SR refinement. Luo et al. [30] develop an end-to-end training deep alternating network (DAN) by estimating reduced kernel and restoring HR image iteratively. However, both IKC and DAN are time-consuming and computationally costly. The modified version of DAN [31] conducts a dual-path conditional block (DPCB) and supervises the estimator on the complete blur kernel to further improve the performance.\n\n\nMethod\n\nWe now formally introduce our method which consists of three main components given a reformation of degradation: A dynamic deep linear kernel estimation module and a deep constrained least squares module for kernel estimation and LR space feature based deblur. A dual-path network is followed to generate the clean HR output. We will first derive the reformulation and then detail each module.\n\n\nDegradation Model Reformulation\n\nIdeally, the blur kernel to be estimated and its corresponding image should be in the same low-resolution space such that the degradation can be transformed to the deblurring problem followed by a SISR problem with bicubic degradation [56,57]. Towards this end, we propose to reformulate Eq. (1) as\ny = F \u22121 (F ((x * k h ) \u2193s )) + n (2) = F \u22121 F (x \u2193s ) F ((x * k h ) \u2193s ) F (x \u2193s ) + n (3) = x \u2193s * F \u22121 F ((x * k h ) \u2193s ) F (x \u2193s ) + n,(4)\nwhere F denotes the Discrete Fourier Transform and F \u22121 denotes its inverse. Then let\nk l = F \u22121 F ((x * k h ) \u2193s ) F (x \u2193s ) ,(5)\nwe can obtain another form of degradation:\ny = x \u2193s * k l + n.(6)\nIn the Eq. (6), k l is derived from the corresponding k h and applied on the downsampled HR image x \u2193s . To ensure numerical stability, we rewrite Eq. (5) with a small regularization parameter :\nk l = F \u22121 F(x \u2193s ) F(x \u2193s )F(x \u2193s ) + F ((x * k h ) \u2193s ) , (7) * FC DDLK Global Pooling\nConvolving filters process Reshape ResBlocks where F(\u00b7) is the complex conjugate of F. Fig. 2 illustrates the results of reformulating kernels by Eq. (7). Based on the new degradation process, our goal is to estimate the blur kernel k l and then restore HR image x.\n1 1 \u00d7 1 1 * * * % 7 \u00d7 7 5 \u00d7 5 1 \u00d7 1 LR \u210e ) \u210e * \u210e + \u210e , - 21\u00d721\n\nDynamic Deep Linear Kernel\n\nFollowing the reformation, we start our blind SR method from the kernel estimation. A straightforward solution is to adopt a regression network to estimate kernelk by minimizing the L1 difference w.r.t the new ground-truth blur kernel k l in Eq. (7). We argue such a single layer kernel (all weights of estimated kernel equal to the ground-truth kernel) estimation is in general difficult and unstable due to the highly non-convex of the blind SR problem [3], leading to kernel mismatch and performance drop [9,30]. Instead, we propose an image-specific dynamic deep linear kernel (DDLK) which consists of a sequence of linear convolution layers without activations. Theoretically, deep linear networks have infinitely equivalent global minimas [3,16,39], which allow us to find many different filter parameters to achieve the same correct solution. Moreover, since no nonlinearity is used in the network, we can analytically collapse a deep linear kernel as a single layer kernel. Fig. 3 depicts an example of estimating 4 layers dynamic deep linear kernel. The filters are set to 11 \u00d7 11, 7 \u00d7 7, 5 \u00d7 5 and 1 \u00d7 1, which make the receptive field to be 21 \u00d7 21. We first generate the filters of each layer based on the LR image, and explicitly sequentially convolve all filters into a single narrow kernel with stride 1. Mathematically, let h i represent the i-th layer filter, we can get a single layer kernel followingk\n= I k * h 1 * h 2 * \u00b7 \u00b7 \u00b7 * h r (8)\nwhere r is the number of linear layers, I k is an identity kernel. As an empirically prior, we also constrain the kernel k sum up to 1. The kernel estimation network can be optimized by minimizing the L1 loss between estimated kernel k and new ground-truth blur kernel k l from Eq. (7).  \n\n\nDeep Constrained Least Squares\n\nOur goal is to restore HR image based on LR image and estimated kernelk according to the new degradation model (Eq. (6)). Considering a group of feature extracting linear layers {G i } L i=1 provided to the LR image, we can rewrite Eq. (6) in the feature space, given by\nG i y =kG i x \u2193s + G i n.(9)\nLet R i be the sought after deblurred feature corresponding to G i x \u2193s . To solve Eq. (9), we minimize the following criterion function\nC = ||\u2207 R i || 2 , s.t. ||G i y \u2212k R i || 2 = ||G i n|| 2(10)\nwhere the \u2207 is a smooth filter which can be denoted by P.\n\nThen we introduce the Lagrange function, defined by\nmin Ri ||P R i || 2 + \u03bb ||G i y \u2212k R i || 2 \u2212 ||G i n|| 2 ,(11)\nwhere \u03bb is the Lagrange multiplier. Computing the derivative of Eq. (11) with respect to R i and setting it to zero:\n\u03bbk Tk + P T P R i \u2212 \u03bbk T G i y = 0.(12)\nWe can obtain the clear features as\nR i = HG i y.(13)\nwhere H i denotes the deep constrained least squares deconvolution (DCLS) operator, given by\nH = F \u22121 F(k) F(k)F(k) + 1 \u03bb F(P)F(P) .(14)\nDifferent from in the standard image space (e.g. RGB), smooth filter P and variable \u03bb in Eq. (14) might be inconsistent in the feature space. Alternatively, we predict a group of smooth filters with implicit Lagrange multiplier for different channels through a neural network P:\n{P i } L i=1 = {P(G i y)} L i=1 .(15)\nThen the feature-specific operator H i can be define by\nH i = F \u22121 F(k) F(k)F(k) + F(P i )F(P i ) .(16)\nNow we can obtain the clear features by Eq. (13) and Eq. (16). It is worth to note that a deep neural network (DNN) can be locally linear [7,23,36], thus we could apply DNN as G i to extract useful features in Eq. (9). In addition, the consequent artifacts or errors can be compensated by the following dual-path attention module.\n\n\nDual-Path Attention Network\n\nUnlike previous works [9,31] in which the dual-path structures are only used to concatenate the stretched kernel with blurred features, we propose to utilize primitive blur features as additive path to compensate the artifacts and errors introduced by the estimated kernel, known as dual-path attention network (DPAN). DPAN is composed of several groups of dual-path attention blocks (DPAB), it receives both deblurred features R and primitive features Gy. The right of Fig. 4 illustrates the architecture of DPAB.\n\nSince the additive path of processing Gy is independently updated and used to concatenate with R to provide primary information to refine the deconvolved features. We can reduce its channels to accelerate training and inference, as the channel reduction (CR) operation illustrated in left of Fig. 4. Moreover, on the deconvolved feature path, we apply the channel attention layer [60] after aggregating original features. In addition, we add a residual connection for each path on all groups and blocks. The pixelshuffle [11] is used as the upscale module. We can jointly optimize the SR network and kernel estimation network as follows:\nL = l 1 (k, k l ; \u03b8 k ) + l 1 (x, x; \u03b8 g )(17)\nwhere \u03b8 k and \u03b8 g are the parameters of kernel estimation network and DCLS reconstruction network, respectively.\n\n\nExperiments\n\n\nDatasets and Implementation Details\n\nFollowing previous works [9,30], 3450 2K HR images from DIV2K [1] and Flickr2K [45] are collected as the training dataset. And we synthesize corresponding LR images with specific degradation kernel settings (e.g., isotropic/anisotropic Gaussian) using Eq. (1). The proposed method is evaluated by PSNR and SSIM [49] on only the luminance channel of the SR results (YCbCr space).\n\nIsotropic Gaussian kernels. Firstly, we conduct blind SR experiments on isotropic Gaussian kernels following the setting in [9]. Specifically, the kernel sizes are fixed to 21   Gaussian8 [9] kernel setting to generate evaluation dataset from five widely used benchmarks: Set5 [4], Set14 [53], BSD100 [33], Urban100 [12] and Manga109 [34]. Anisotropic Gaussian kernels. We also conduct experiments on anisotropic Gaussian kernels following the setting in [3]. The kernel size is set to 11 \u00d7 11 and 31 \u00d7 31 for scale factors 2 and 4, respectively. During training, the anisotropic Gaussian kernels for degradation are generated by randomly selecting kernel width from range (0.6, 5) and rotating from range [-\u03c0, \u03c0]. We also apply uniform multiplicative noise and normalize it to sum to one. For evaluation, we use the DIV2KRK dataset proposed in [3]. Implementation details. For all experiments, we use 5 dual-path groups, each containing 10 DPABs with 64 channels. The batch sizes are set to 64 and the LR patch sizes are 64 \u00d7 64. We use Adam [20] optimizer with \u03b2 1 = 0.9 and \u03b2 2 = 0.99. All models are trained on 4 RTX2080Ti GPUs with 5 \u00d7 10 5 iterations. The initial learning rate is set to 4 \u00d7 10 \u22124 and decayed by half at every 2 \u00d7 10 \u22124 iterations. We also augment the training data with random horizontal flips and 90 degree rotations.\n\n\nComparison with State-of-the-arts\n\nEvaluation with isotropic Gaussian kernels. Following [9], we evaluate our method on datasets synthesized by Gaussian8 kernels. We compare our method with stateof-the-art blind SR approaches: ZSSR [41] (with bicubic kernel), IKC [9], DANv1 [30], DANv2 [31] and AdaTarget [14]. Following [9], we also conduct comparison with CARN [2] and its variants of performing blind deblurring method [37] before and after CARN. For most methods, we   Table 4. Quantitative evaluation on the performance of DDLK.\n\nuse their official implementations and pre-trained models.\n\nThe quantitative results are shown in Table 1. It is obvious that our method leads to the best performance over all datasets. The bicubic SR model CARN suffers severe performance drop with Gaussian8 which deviates from the predefined bicubic kernel. Performing deblurring on the superresolved image can improve the results. ZSSR achieves better performance compared with non-blind SR method but is limited by the image-specific network design (cannot utilize abundant training data). AdaTarget can improve image quality but is still inferior to that of blind SR methods. IKC and DAN are two-step blind SR methods and can largely improve the results. However, both of them predict kernel embedding and directly involve it into the network, which damages the spatial relation of the kernel and thus performs inferior to our method. We also provide the comparison of PSNR values on different datasets with blur kernels width from 1.8 to 3.2 as shown in Fig. 5. DCLS performs the best result over all different kernel widths. The qualitative results shown in Fig. 8 Figure 8. Visual results of Img 67 and Img 73 in Urban100 [12], for scale factor 4 and kernel width 2.6. Best viewed in color.  periment of super-resolving images with additional noise. As shown in Table 2 and Fig. 6, DCLS still outperforms other methods over all datasets with different noise levels.\n\nEvaluation with anisotropic Gaussian kernels. Degradation with anisotropic Gaussian kernels are more general and challenging. Similar to isotropic kernel, we firstly compare our method with SOTA blind SR approaches such as ZSSR [41], IKC [9], DANv1 [30], DANv2 [31], AdaTarget [14] and KOALAnet [19]. We also compare DCLS with some SOTA bicubicly designed methods such as EDSR [28], RCAN [59], and DBPN [10]. And we provide Correction [13] for DBPN. In addition, we combine a kernel estimation method (e.g. KernelGAN [3]) with other non-blind SR methods, such as ZSSR [41] and SRMD [56], as two-step solutions to solve blind SR. Table 3 shows the quantitative results on DIV2KRK [3]. It can be seen that the proposed DCLS significantly improves the performance compared with other blind SR approaches. Note that ZSSR performs better when combined with KernelGAN, which indicates that good kernel estimation can help a lot. Recent SOTA blind SR methods such as IKC, DAN and KOALAnet can achieve remarkable accuracy in PSNR and SSIM. By applying an adaptive target to finetune the network, AdaTarget can perform comparably with SOTA blind methods. However, all of those methods are still inferior to the proposed DCLS. The visual re- sults on DIV2KRK are shown in Fig. 9. As we can see, the SR images produced by our method are much sharper and cleaner. We also provide the results of kernel estimation and downsampling HR image with estimated kernel in Fig. 7 and Table 4. Compared with previous image-specific methods such as KernelGAN [3] and Correction Filter [13], the dynamic deep linear kernel (DDLK) is more flexible and capable of producing accurate kernels.\n\n\nAnalysis and Discussions\n\nAblation Study. We conduct ablation studies on vital components of our method: DPAN, DDLK and DCLS deconvolution. The quantitative results on DIV2KRK are exported in Table 5. Note that the baseline model with DPAN eliminates artifacts from kernel and thus improves the result. And the DCLS deconvolution can further make use of the estimated kernel and high-level information from deep features to achieve a higher performance (+0.15dB from baseline).\n\nEffectiveness of the DCLS deconvolution. To illustrate the effectiveness of DCLS, we include a comparison of substituting DCLS with other deblurring methods, such as traditional constrained least squares (CLS) and Wiener deconvolution [7,50] in the RGB space and feature space. The results are presented in Table 6 and Table 7. By applying deconvolution in the RGB space with the reformulated kernel, we can get a clear LR image and thus improve the SR performance. This idea is similar to Correction Filter [13], but with one big difference, in that our estimator is highly  Figure 11. Comparison of historic image [21] for 4\u00d7 SR.\n\ncorrelated to the LR image rather than the SR model. The visual example is shown in Fig. 10.\n\nPerformance on Real Degradation To further demonstrate the effectiveness of our method, we apply the proposed model on real degradation data where the ground truth HR images and the blur kernels are not available. An example of super-resolving historic image is shown in Fig. 11. Compared with LapSRN [21] and DANv2 [31], our DCLS can produce sharper edges and visual pleasing SR results.\n\n\nConclusion\n\nIn this work, we have presented a well-principled algorithm to tackle the blind SR problem. We first derive a new form of blur kernel in the low resolution space from classical degradation model. We then propose to estimate and apply that kernel in HR image restoration. Subsequently, a dynamic deep linear kernel (DDLK) module is introduced to improve kernel estimation. We further design a deep constrained least squares (DCLS) deconvolution module that integrates blur kernel and LR image in the feature domain to obtain the clean feature. The clean feature and the primitive feature are then fed into a dual-path network to generate the super-resolved image. Extensive experiments on various kernels and noises demonstrate that the proposed method leads to a state-of-the-art blind SR performance. \n\nFigure 2 .\n2Kernel reformulation examples. The top row and middle row are the LR images and the corresponding primitive kernels. The bottom row is the reformulated kernels.\n\nFigure 3 .\n3Architecture of the dynamic deep linear kernel.\n\nFigure 4 .\n4The overview architecture of the proposed method. Given an LR image y, we first estimate the degradation kernelk, and involve it in the deep constrained least squares (DCLS) convolution in the feature domain. The deblurred features R are then concatenated with primitive features Gy to restore the clean HR image x through a dual-path attention network (DPAN).\n\nFigure 5 .Figure 6 .\n56The PSNR performance curves on Set5 and Manga109 of scale factor 4. The kernel width \u03c3 are set from 1.Visual results of Img 33 from Urban100.\n\nFigure 7 .\n7Visual results of estimated kernels of Img 33 and Img 43 from DIV2KRK[3] by various kernel estimation methods.\n\nFigure 9 .\n9Visual results of Img 36 and Img 12 in DIV2KRK[3], for scale factor of 4. Best viewed in color.\n\nFigure 10 .\n10Applying DCLS in the RGB space. (a) Original LR & kernel, (b) corrected LR & estimated kernel by [13], (c) deblurred LR & estimated kernel by the proposed method.\n\nTable 2 .\n2PSNR SSIM PSNR SSIM PSNR SSIM PSNR SSIM PSNR SSIMTable 1. Quantitative comparison on datasets with Gaussian8 kernels. The best two results are marked in red and blue colors, respectively. Quantitative comparison on various noisy datasets. The best one marks in red and the second best are in blue.Method \n\nScale \nSet5 [4] \nSet14 [53] \nBSD100 [33] \nUrban100 [12] \nManga109 [34] \nBicubic \n\nx2 \n\n28.82 0.8577 26.02 0.7634 25.92 0.7310 23.14 0.7258 25.60 0.8498 \nCARN [2] \n30.99 0.8779 28.10 0.7879 26.78 0.7286 25.27 0.7630 26.86 0.8606 \nBicubic+ZSSR [41] \n31.08 0.8786 28.35 0.7933 27.92 0.7632 25.25 0.7618 28.05 0.8769 \nDeblurring [37]+CARN [41] \n24.20 0.7496 21.12 0.6170 22.69 0.6471 18.89 0.5895 21.54 0.7946 \nCARN [41]+Deblurring [37] \n31.27 0.8974 29.03 0.8267 28.72 0.8033 25.62 0.7981 29.58 0.9134 \nIKC [9] \n37.19 0.9526 32.94 0.9024 31.51 0.8790 29.85 0.8928 36.93 0.9667 \nDANv1 [30] \n37.34 0.9526 33.08 0.9041 31.76 0.8858 30.60 0.9060 37.23 0.9710 \nDANv2 [31] \n37.60 0.9544 33.44 0.9094 32.00 0.8904 31.43 0.9174 38.07 0.9734 \nDCLS(Ours) \n37.63 0.9554 33.46 0.9103 32.04 0.8907 31.69 0.9202 38.31 0.9740 \n\nBicubic \n\nx3 \n\n26.21 0.7766 24.01 0.6662 24.25 0.6356 21.39 0.6203 22.98 0.7576 \nCARN [2] \n27.26 0.7855 25.06 0.6676 25.85 0.6566 22.67 0.6323 23.85 0.7620 \nBicubic+ZSSR [41] \n28.25 0.7989 26.15 0.6942 26.06 0.6633 23.26 0.6534 25.19 0.7914 \nDeblurring [37]+CARN [41] \n19.05 0.5226 17.61 0.4558 20.51 0.5331 16.72 0.5895 18.38 0.6118 \nCARN [41]+Deblurring [37] \n30.31 0.8562 27.57 0.7531 27.14 0.7152 24.45 0.7241 27.67 0.8592 \nIKC [9] \n33.06 0.9146 29.38 0.8233 28.53 0.7899 24.43 0.8302 32.43 0.9316 \nDANv1 [30] \n34.04 0.9199 30.09 0.8287 28.94 0.7919 27.65 0.8352 33.16 0.9382 \nDANv2 [31] \n34.12 0.9209 30.20 0.8309 29.03 0.7948 27.83 0.8395 33.28 0.9400 \nDCLS(Ours) \n34.21 0.9218 30.29 0.8329 29.07 0.7956 28.03 0.8444 33.54 0.9414 \n\nBicubic \n\nx4 \n\n24.57 0.7108 22.79 0.6032 23.29 0.5786 20.35 0.5532 21.50 0.6933 \nCARN [2] \n26.57 0.7420 24.62 0.6226 24.79 0.5963 22.17 0.5865 21.85 0.6834 \nBicubic+ZSSR [41] \n26.45 0.7279 24.78 0.6268 24.97 0.5989 22.11 0.5805 23.53 0.7240 \nDeblurring [37]+CARN [41] \n18.10 0.4843 16.59 0.3994 18.46 0.4481 15.47 0.3872 16.78 0.5371 \nCARN [41]+Deblurring [37] \n28.69 0.8092 26.40 0.6926 26.10 0.6528 23.46 0.6597 25.84 0.8035 \nIKC [9] \n31.67 0.8829 28.31 0.7643 27.37 0.7192 25.33 0.7504 28.91 0.8782 \nDANv1 [30] \n31.89 0.8864 28.42 0.7687 27.51 0.7248 25.86 0.7721 30.50 0.9037 \nDANv2 [31] \n32.00 0.8885 28.50 0.7715 27.56 0.7277 25.94 0.7748 30.45 0.9037 \nAdaTarget [14] \n31.58 0.8814 28.14 0.7626 27.43 0.7216 25.72 0.7683 29.97 0.8955 \nDCLS(Ours) \n32.12 0.8890 28.54 0.7728 27.60 0.7285 26.15 0.7809 30.86 0.9086 \n\nMethod \u00d74 \nNoise level \nSet5 [4] \nSet14 [53] \nBSD100 [33] \nUrban100 [12] \nManga109 [34] \nPSNR SSIM PSNR SSIM PSNR SSIM PSNR SSIM PSNR SSIM \n\nBicubic+ZSSR [41] \n\n15 \n\n23.32 0.4868 22.49 0.4256 22.61 0.3949 20.68 0.3966 22.04 0.4952 \nIKC [9] \n26.89 0.7671 25.28 0.6483 24.93 0.6019 22.94 0.6362 25.09 0.7819 \nDANv1 [30] \n26.95 0.7711 25.27 0.6490 24.95 0.6033 23.00 0.6407 25.29 0.7879 \nDANv2 [31] \n26.97 0.7726 25.29 0.6497 24.95 0.6025 23.03 0.6429 25.32 0.7896 \nDCLS(Ours) \n27.14 0.7775 25.37 0.6516 24.99 0.6043 27.13 0.6500 25.57 0.7969 \n\nBicubic+ZSSR [41] \n\n30 \n\n19.77 0.2938 19.36 0.2534 19.43 0.2308 18.32 0.2450 19.25 0.3046 \nIKC [9] \n25.27 0.7154 24.15 0.6100 24.06 0.5674 22.11 0.5969 23.80 0.7438 \nDANv1 [30] \n25.32 0.7276 24.15 0.6138 24.04 0.5678 22.08 0.5977 23.82 0.7442 \nDANv2 [31] \n25.36 0.7264 24.16 0.6121 24.06 0.5690 22.14 0.6014 23.87 0.7489 \nDCLS(Ours) \n25.49 0.7323 24.23 0.6131 24.09 0.5696 22.37 0.6119 24.21 0.7582 \n\n\n\n\nThe LR images are obtained by blurring and downsampling the HR images with selected kernels.Gaus-\nsian8 uniformly chooses 8 kernels from range [0.80, 1.60], \n[1.35, 2.40] and [1.80, 3.20] for scale factors 2, 3 and 4, \nrepectively. \n\n\nillustrate that DCLS can produce clear and pleasant SR images. Furthermore, we conduct an ex-Bicubic \n\nZSSR \nIKC \nAdaTarget \nCARN \nDANv2 \nOurs \nGT \n\n20.64/0.8871 \n20.01/0.8661 \n20.02/0.8665 \n19.05/0.8314 \n15.30/0.5754 \n15.24/0.5760 \n15.06/0.5566 \n\n21.06/0.5784 \n20.66/0.5647 \n20.96/0.5736 \n19.78/0.4946 \n18.63/0.3280 \n18.68/0.3318 \n18.43/0.3011 \n\nn100 \n\nPSNR/SSIM \n\nPSNR/SSIM \n\nLR Img 73 in Urban100 \n\nLR Img 67 in Urban100 \n\n\n\n\nTable 5. Ablation study on our vital components.Table 6. Quantitative comparison on various datasets. Fea means applying deconvolution on the feature space. DIV2KRK \u00d74 Wiener RGB CLS RGB DCLS RGB DCLS FeaTable 7. Quantitative results. RGB and Fea mean applying deconvolution in the RGB space and feature space, respectively.SLK DDLK \n\nStretching \nStrategy \n\nDCLS \nDeconv \nDPAN \nDIV2KRK \nPSNR SSIM \n-\n-\n28.84 0.7921 \n-\n-\n28.86 0.7924 \n-\n-\n28.94 0.7946 \n-\n-\n-\n28.94 0.7938 \n-\n-\n28.99 0.7964 \n\nMethod \nWiener Fea [7] \nCLS Fea \nDCLS Fea \nPSNR SSIM PSNR SSIM PSNR SSIM \n\nSet5 \n32.05 0.8878 31.98 0.8862 32.12 0.8890 \nSet14 \n28.38 0.7709 28.29 0.7658 28.54 0.7728 \nBSD100 \n27.47 0.7238 27.48 0.7216 27.60 0.7285 \nUrban100 \n26.07 0.7775 26.03 0.7768 26.15 0.7809 \nManga109 30.77 0.9069 30.65 0.9040 30.86 0.9086 \nDIV2KRK 28.77 0.7886 28.92 0.7921 28.99 0.7947 \n\nPSNR \n28.91 \n28.90 \n28.94 \n28.99 \nSSIM \n0.7941 \n0.7935 \n0.7941 \n0.7964 \n\n\n\n\ndeep features as a perceptual metric. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 586-595, 2018. 2 [59] Yulun Zhang, Kunpeng Li, Kai Li, Lichen Wang, Bineng Zhong, and Yun Fu. Image super-resolution using very deep residual channel attention networks. In Proc. ECCV, pages 286-301, 2018. 1, 2, 6, 7 [60] Yulun Zhang, Kunpeng Li, Kai Li, Lichen Wang, Bineng Zhong, and Yun Fu. Image super-resolution using very deep residual channel attention networks. In Proc. ECCV, pages 294-310, 2018. 4 [61] Yulun Zhang, Yapeng Tian, Yu Kong, Bineng Zhong, and Yun Fu. Residual dense network for image super-resolution. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 2472-2481, 2018. 2 [62] Yulun Zhang, Yapeng Tian, Yu Kong, Bineng Zhong, and Yun Fu. Residual dense network for image restoration. IEEE Transactions on Pattern Analysis and Machine Intelligence, 43(7):2480-2495, 2020. 2\n\nNtire 2017 challenge on single image super-resolution: Dataset and study. Eirikur Agustsson, Radu Timofte, Proc. CVPRW. CVPRWEirikur Agustsson and Radu Timofte. Ntire 2017 challenge on single image super-resolution: Dataset and study. In Proc. CVPRW, pages 126-135, 2017. 5\n\nFast, accurate, and lightweight super-resolution with cascading residual network. Namhyuk Ahn, Byungkon Kang, Kyung-Ah Sohn, Proc. ECCV. ECCV56Namhyuk Ahn, Byungkon Kang, and Kyung-Ah Sohn. Fast, accurate, and lightweight super-resolution with cascading residual network. In Proc. ECCV, pages 252-268, 2018. 5, 6\n\nBlind super-resolution kernel estimation using an internal-gan. Sefi Bell-Kligler, Assaf Shocher, Michal Irani, Proc. NeurIPS. NeurIPS7Sefi Bell-Kligler, Assaf Shocher, and Michal Irani. Blind super-resolution kernel estimation using an internal-gan. In Proc. NeurIPS, pages 284-293, 2019. 1, 2, 3, 6, 7, 8\n\nChristine Guillemot, and Marie line Alberi Morel. Low-complexity single-image super-resolution based on nonnegative neighbor embedding. Marco Bevilacqua, Aline Roumy, Proc. BMVC. BMVC106Marco Bevilacqua, Aline Roumy, Christine Guillemot, and Marie line Alberi Morel. Low-complexity single-image super-resolution based on nonnegative neighbor embedding. In Proc. BMVC, pages 135.1-135.10, 2012. 5, 6\n\nSecond-order attention network for single image super-resolution. Tao Dai, Jianrui Cai, Yongbing Zhang, Shu-Tao Xia, Lei Zhang, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern RecognitionTao Dai, Jianrui Cai, Yongbing Zhang, Shu-Tao Xia, and Lei Zhang. Second-order attention network for single im- age super-resolution. In Proceedings of the IEEE/CVF Con- ference on Computer Vision and Pattern Recognition, pages 11065-11074, 2019. 2\n\nLearning a deep convolutional network for image super-resolution. Chao Dong, Chen Change Loy, Kaiming He, Xiaoou Tang, European conference on computer vision. Springer1Chao Dong, Chen Change Loy, Kaiming He, and Xiaoou Tang. Learning a deep convolutional network for image super-resolution. In European conference on computer vi- sion, pages 184-199. Springer, 2014. 1, 2\n\nDeep wiener deconvolution: Wiener meets deep learning for image deblurring. Jiangxin Dong, Stefan Roth, Bernt Schiele, Proc. NeurIPS. NeurIPS33Jiangxin Dong, Stefan Roth, and Bernt Schiele. Deep wiener deconvolution: Wiener meets deep learning for image de- blurring. Proc. NeurIPS, 33:1048-1059, 2020. 4, 8\n\nFrequency separation for real-world super-resolution. Manuel Fritsche, Shuhang Gu, Radu Timofte, Manuel Fritsche, Shuhang Gu, and Radu Timofte. Fre- quency separation for real-world super-resolution. In 2019\n\nIEEE/CVF International Conference on Computer Vision Workshop (ICCVW). IEEEIEEE/CVF International Conference on Computer Vision Workshop (ICCVW), pages 3599-3608. IEEE, 2019. 1\n\nBlind super-resolution with iterative kernel correction. Jinjin Gu, Hannan Lu, Wangmeng Zuo, Chao Dong, Proc. CVPR. CVPR67Jinjin Gu, Hannan Lu, Wangmeng Zuo, and Chao Dong. Blind super-resolution with iterative kernel correction. In Proc. CVPR, pages 1604-1613, 2019. 1, 2, 3, 4, 5, 6, 7\n\nDeep back-projection networks for super-resolution. Muhammad Haris, Gregory Shakhnarovich, Norimichi Ukita, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognition7Muhammad Haris, Gregory Shakhnarovich, and Norimichi Ukita. Deep back-projection networks for super-resolution. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 1664-1673, 2018. 1, 2, 6, 7\n\nMulti chaotic systems based pixel shuffle for image encryption. C K Huang, Hsiau-Hsian Nien, Optics communications. 28211CK Huang and Hsiau-Hsian Nien. Multi chaotic systems based pixel shuffle for image encryption. Optics communi- cations, 282(11):2123-2127, 2009. 4\n\nSingle image super-resolution from transformed self-exemplars. Jia-Bin Huang, Abhishek Singh, Narendra Ahuja, Proc. CVPR. CVPR67Jia-Bin Huang, Abhishek Singh, and Narendra Ahuja. Single image super-resolution from transformed self-exemplars. In Proc. CVPR, pages 5197-5206, 2015. 5, 6, 7\n\nCorrection filter for single image super-resolution: Robustifying off-theshelf deep super-resolvers. Tom Shady Abu Hussein, Raja Tirer, Giryes, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern Recognition7Shady Abu Hussein, Tom Tirer, and Raja Giryes. Correction filter for single image super-resolution: Robustifying off-the- shelf deep super-resolvers. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 1428-1437, 2020. 2, 6, 7, 8\n\nTackling the ill-posedness of super-resolution through adaptive target generation. Younghyun Jo, Wug Seoung, Peter Oh, Seon Joo Vajda, Kim, Proc. CVPR. CVPR67Younghyun Jo, Seoung Wug Oh, Peter Vajda, and Seon Joo Kim. Tackling the ill-posedness of super-resolution through adaptive target generation. In Proc. CVPR, pages 16236- 16245, 2021. 1, 5, 6, 7\n\nPerceptual losses for real-time style transfer and super-resolution. Justin Johnson, Alexandre Alahi, Li Fei-Fei, European conference on computer vision. SpringerJustin Johnson, Alexandre Alahi, and Li Fei-Fei. Perceptual losses for real-time style transfer and super-resolution. In European conference on computer vision, pages 694-711. Springer, 2016. 2\n\nDeep learning without poor local minima. Kenji Kawaguchi, Proc. NeurIPS. NeurIPSKenji Kawaguchi. Deep learning without poor local minima. In Proc. NeurIPS, pages 586-594, 2016. 3\n\nAccurate image super-resolution using very deep convolutional networks. Jiwon Kim, Jung Kwon Lee, Kyoung Mu Lee, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognition1Jiwon Kim, Jung Kwon Lee, and Kyoung Mu Lee. Accurate image super-resolution using very deep convolutional net- works. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 1646-1654, 2016. 1, 2\n\nDeeplyrecursive convolutional network for image super-resolution. Jiwon Kim, Jung Kwon Lee, Kyoung Mu Lee, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionJiwon Kim, Jung Kwon Lee, and Kyoung Mu Lee. Deeply- recursive convolutional network for image super-resolution. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 1637-1645, 2016. 2\n\nKoalanet: Blind super-resolution using kernel-oriented adaptive local adjustment. Hyeonjun Soo Ye Kim, Munchurl Sim, Kim, Proc. CVPR. CVPR67Soo Ye Kim, Hyeonjun Sim, and Munchurl Kim. Koalanet: Blind super-resolution using kernel-oriented adaptive local adjustment. In Proc. CVPR, pages 10611-10620, 2021. 1, 6, 7\n\nAdam: A method for stochastic optimization. P Diederik, Jimmy Kingma, Ba, arXiv:1412.6980arXiv preprintDiederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014. 6\n\nDeep laplacian pyramid networks for fast and accurate super-resolution. Wei-Sheng Lai, Jia-Bin Huang, Narendra Ahuja, Ming-Hsuan Yang, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognition2Wei-Sheng Lai, Jia-Bin Huang, Narendra Ahuja, and Ming- Hsuan Yang. Deep laplacian pyramid networks for fast and accurate super-resolution. In Proceedings of the IEEE con- ference on computer vision and pattern recognition, pages 624-632, 2017. 2, 8\n\nPhotorealistic single image super-resolution using a generative adversarial network. Christian Ledig, Lucas Theis, Ferenc Husz\u00e1r, Jose Caballero, Andrew Cunningham, Alejandro Acosta, Andrew Aitken, Alykhan Tejani, Johannes Totz, Zehan Wang, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognition1Christian Ledig, Lucas Theis, Ferenc Husz\u00e1r, Jose Caballero, Andrew Cunningham, Alejandro Acosta, Andrew Aitken, Alykhan Tejani, Johannes Totz, Zehan Wang, et al. Photo- realistic single image super-resolution using a generative ad- versarial network. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 4681-4690, 2017. 1, 2\n\nTowards robust, locally linear deep networks. Guang-He Lee, David Alvarez-Melis, Tommi S Jaakkola, Proc. ICLR. ICLRGuang-He Lee, David Alvarez-Melis, and Tommi S Jaakkola. Towards robust, locally linear deep networks. In Proc. ICLR, 2018. 4\n\nUnderstanding and evaluating blind deconvolution algorithms. Anat Levin, Yair Weiss, Fredo Durand, William T Freeman, 2009 IEEE Conference on Computer Vision and Pattern Recognition. Anat Levin, Yair Weiss, Fredo Durand, and William T Free- man. Understanding and evaluating blind deconvolution al- gorithms. In 2009 IEEE Conference on Computer Vision and Pattern Recognition, pages 1964-1971. IEEE, 2009. 2\n\nEfficient marginal likelihood optimization in blind deconvolution. Anat Levin, Yair Weiss, Fredo Durand, William T Freeman, CVPR 2011. Anat Levin, Yair Weiss, Fredo Durand, and William T Free- man. Efficient marginal likelihood optimization in blind de- convolution. In CVPR 2011, pages 2657-2664. IEEE, 2011. 2\n\nFeedback network for image superresolution. Zhen Li, Jinglei Yang, Zheng Liu, Xiaomin Yang, Gwanggil Jeon, Wei Wu, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern RecognitionZhen Li, Jinglei Yang, Zheng Liu, Xiaomin Yang, Gwang- gil Jeon, and Wei Wu. Feedback network for image super- resolution. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 3867- 3876, 2019. 1\n\nFlow-based kernel prior with application to blind super-resolution. Jingyun Liang, Kai Zhang, Shuhang Gu, Luc Van Gool, Radu Timofte, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern RecognitionJingyun Liang, Kai Zhang, Shuhang Gu, Luc Van Gool, and Radu Timofte. Flow-based kernel prior with application to blind super-resolution. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 10601-10610, 2021. 2\n\nEnhanced deep residual networks for single image super-resolution. Bee Lim, Sanghyun Son, Heewon Kim, Seungjun Nah, Kyoung Mu Lee, Proc. CVPRW. CVPRW7Bee Lim, Sanghyun Son, Heewon Kim, Seungjun Nah, and Kyoung Mu Lee. Enhanced deep residual networks for single image super-resolution. In Proc. CVPRW, pages 136-144, 2017. 1, 2, 6, 7\n\nSrflow: Learning the super-resolution space with normalizing flow. Andreas Lugmayr, Martin Danelljan, Luc Van Gool, Radu Timofte, European Conference on Computer Vision. SpringerAndreas Lugmayr, Martin Danelljan, Luc Van Gool, and Radu Timofte. Srflow: Learning the super-resolution space with normalizing flow. In European Conference on Com- puter Vision, pages 715-732. Springer, 2020. 2\n\nUnfolding the alternating optimization for blind super resolution. Zhengxiong Luo, Yan Huang, Shang Li, Liang Wang, Tieniu Tan, Proc. NeurIPS. NeurIPS67Zhengxiong Luo, Yan Huang, Shang Li, Liang Wang, and Tieniu Tan. Unfolding the alternating optimization for blind super resolution. In Proc. NeurIPS, 2020. 1, 2, 3, 5, 6, 7\n\nEnd-to-end alternating optimization for blind super resolution. Zhengxiong Luo, Yan Huang, Shang Li, Liang Wang, Tieniu Tan, arXiv:2105.068787arXiv preprintZhengxiong Luo, Yan Huang, Shang Li, Liang Wang, and Tieniu Tan. End-to-end alternating optimization for blind super resolution. arXiv preprint arXiv:2105.06878, 2021. 1, 3, 4, 5, 6, 7, 8\n\nEbsr: Feature enhanced burst super-resolution with deformable alignment. Ziwei Luo, Lei Yu, Xuan Mo, Youwei Li, Lanpeng Jia, Haoqiang Fan, Jian Sun, Shuaicheng Liu, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern RecognitionZiwei Luo, Lei Yu, Xuan Mo, Youwei Li, Lanpeng Jia, Hao- qiang Fan, Jian Sun, and Shuaicheng Liu. Ebsr: Feature enhanced burst super-resolution with deformable alignment. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 471-478, 2021. 2\n\nA database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics. David Martin, Charless Fowlkes, Doron Tal, Jitendra Malik, Proc. ICCV. ICCV56David Martin, Charless Fowlkes, Doron Tal, and Jitendra Malik. A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring ecological statistics. In Proc. ICCV, pages 416- 423, 2001. 5, 6\n\nSketch-based manga retrieval using manga109 dataset. Yusuke Matsui, Kota Ito, Yuji Aramaki, Azuma Fujimoto, Toru Ogawa, Toshihiko Yamasaki, Kiyoharu Aizawa, Multimedia Tools and Applications. 766Yusuke Matsui, Kota Ito, Yuji Aramaki, Azuma Fujimoto, Toru Ogawa, Toshihiko Yamasaki, and Kiyoharu Aizawa. Sketch-based manga retrieval using manga109 dataset. Mul- timedia Tools and Applications, 76(20):21811-21838, 2017. 5, 6\n\nNonparametric blind super-resolution. Tomer Michaeli, Michal Irani, Proceedings of the IEEE International Conference on Computer Vision. the IEEE International Conference on Computer VisionTomer Michaeli and Michal Irani. Nonparametric blind super-resolution. In Proceedings of the IEEE International Conference on Computer Vision, pages 945-952, 2013. 2\n\nOn the number of linear regions of deep neural networks. Guido Mont\u00fafar, Razvan Pascanu, Kyunghyun Cho, Yoshua Bengio, Proc. NeurIPS. NeurIPSGuido Mont\u00fafar, Razvan Pascanu, Kyunghyun Cho, and Yoshua Bengio. On the number of linear regions of deep neural networks. In Proc. NeurIPS, pages 2924-2932, 2014. 4\n\nDeblurring images via dark channel prior. Jinshan Pan, Deqing Sun, Hanspeter Pfister, Ming-Hsuan Yang, IEEE Trans. on Pattern Analysis and Machine Intelligence. 40106Jinshan Pan, Deqing Sun, Hanspeter Pfister, and Ming- Hsuan Yang. Deblurring images via dark channel prior. IEEE Trans. on Pattern Analysis and Machine Intelligence, 40(10):2315-2328, 2017. 5, 6\n\nSuperresolution image reconstruction: a technical overview. Min Kyu Sung Cheol Park, Moon Gi Park, Kang, IEEE signal processing magazine. 203Sung Cheol Park, Min Kyu Park, and Moon Gi Kang. Super- resolution image reconstruction: a technical overview. IEEE signal processing magazine, 20(3):21-36, 2003. 2\n\nExact solutions to the nonlinear dynamics of learning in deep linear neural networks. M Andrew, James L Saxe, Surya Mcclelland, Ganguli, arXiv:1312.6120arXiv preprintAndrew M Saxe, James L McClelland, and Surya Ganguli. Exact solutions to the nonlinear dynamics of learning in deep linear neural networks. arXiv preprint arXiv:1312.6120, 2013. 3\n\nReal-time single image and video super-resolution using an efficient sub-pixel convolutional neural network. Wenzhe Shi, Jose Caballero, Ferenc Husz\u00e1r, Johannes Totz, P Andrew, Rob Aitken, Daniel Bishop, Zehan Rueckert, Wang, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionWenzhe Shi, Jose Caballero, Ferenc Husz\u00e1r, Johannes Totz, Andrew P Aitken, Rob Bishop, Daniel Rueckert, and Zehan Wang. Real-time single image and video super-resolution using an efficient sub-pixel convolutional neural network. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 1874-1883, 2016. 2\n\nzeroshot\" super-resolution using deep internal learning. Assaf Shocher, Nadav Cohen, Michal Irani, Proc. CVPR. CVPR67Assaf Shocher, Nadav Cohen, and Michal Irani. \"zero- shot\" super-resolution using deep internal learning. In Proc. CVPR, pages 3118-3126, 2018. 1, 5, 6, 7\n\nMetatransfer learning for zero-shot super-resolution. Jae Woong Soh, Sunwoo Cho, Nam Ik Cho, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern RecognitionJae Woong Soh, Sunwoo Cho, and Nam Ik Cho. Meta- transfer learning for zero-shot super-resolution. In Proceed- ings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 3516-3525, 2020. 2\n\nImage superresolution via deep recursive residual network. Ying Tai, Jian Yang, Xiaoming Liu, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionYing Tai, Jian Yang, and Xiaoming Liu. Image super- resolution via deep recursive residual network. In Proceed- ings of the IEEE conference on computer vision and pattern recognition, pages 3147-3155, 2017. 2\n\nSpectrum-to-kernel translation for accurate blind image super-resolution. Guangpin Tao, Xiaozhong Ji, Wenzhuo Wang, Shuo Chen, Chuming Lin, Yun Cao, Tong Lu, Donghao Luo, Ying Tai, Thirty-Fifth Conference on Neural Information Processing Systems. Guangpin Tao, Xiaozhong Ji, Wenzhuo Wang, Shuo Chen, Chuming Lin, Yun Cao, Tong Lu, Donghao Luo, and Ying Tai. Spectrum-to-kernel translation for accurate blind image super-resolution. In Thirty-Fifth Conference on Neural In- formation Processing Systems, 2021. 3\n\nNtire 2017 challenge on single image super-resolution: Methods and results. Radu Timofte, Eirikur Agustsson, Luc Van Gool, Ming-Hsuan Yang, Lei Zhang, Proc. CVPRW. CVPRWRadu Timofte, Eirikur Agustsson, Luc Van Gool, Ming- Hsuan Yang, and Lei Zhang. Ntire 2017 challenge on sin- gle image super-resolution: Methods and results. In Proc. CVPRW, pages 114-125, 2017. 5\n\nA frequency domain approach to registration of aliased images with application to super-resolution. Patrick Vandewalle, Sabine S\u00fcsstrunk, Martin Vetterli, EURASIP journal on advances in signal processing. 2Patrick Vandewalle, Sabine S\u00fcsstrunk, and Martin Vetterli. A frequency domain approach to registration of aliased images with application to super-resolution. EURASIP journal on advances in signal processing, 2006:1-14, 2006. 2\n\nRecovering realistic texture in image super-resolution by deep spatial feature transform. Xintao Wang, Ke Yu, Chao Dong, Chen Change Loy, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionXintao Wang, Ke Yu, Chao Dong, and Chen Change Loy. Recovering realistic texture in image super-resolution by deep spatial feature transform. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 606-615, 2018. 2\n\nEsrgan: Enhanced super-resolution generative adversarial networks. Xintao Wang, Ke Yu, Shixiang Wu, Jinjin Gu, Yihao Liu, Chao Dong, Yu Qiao, Chen Change Loy, Proceedings of the European conference on computer vision (ECCV) workshops. the European conference on computer vision (ECCV) workshops1Xintao Wang, Ke Yu, Shixiang Wu, Jinjin Gu, Yihao Liu, Chao Dong, Yu Qiao, and Chen Change Loy. Esrgan: En- hanced super-resolution generative adversarial networks. In Proceedings of the European conference on computer vision (ECCV) workshops, pages 0-0, 2018. 1, 2\n\nImage quality assessment: from error visibility to structural similarity. Zhou Wang, Alan C Bovik, R Hamid, Eero P Sheikh, Simoncelli, IEEE Trans. on Image Processing. 134Zhou Wang, Alan C Bovik, Hamid R Sheikh, and Eero P Simoncelli. Image quality assessment: from error visibility to structural similarity. IEEE Trans. on Image Processing, 13(4):600-612, 2004. 5\n\nExtrapolation, interpolation, and smoothing of stationary time series: with engineering applications. Norbert Wiener, MIT press8Cambridge, MANorbert Wiener et al. Extrapolation, interpolation, and smoothing of stationary time series: with engineering ap- plications, volume 8. MIT press Cambridge, MA, 1964. 8\n\nUnified dynamic convolutional network for super-resolution with variational degradations. Yu-Syuan Xu, Shou-Yao Roy Tseng, Yu Tseng, Hsien-Kai Kuo, Yi-Min Tsai, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern RecognitionYu-Syuan Xu, Shou-Yao Roy Tseng, Yu Tseng, Hsien-Kai Kuo, and Yi-Min Tsai. Unified dynamic convolutional net- work for super-resolution with variational degradations. In Proceedings of the IEEE/CVF Conference on Computer Vi- sion and Pattern Recognition, pages 12496-12505, 2020. 2\n\nUltra-resolving face images by discriminative generative networks. Xin Yu, Fatih Porikli, European conference on computer vision. SpringerXin Yu and Fatih Porikli. Ultra-resolving face images by discriminative generative networks. In European conference on computer vision, pages 318-333. Springer, 2016. 2\n\nOn single image scale-up using sparse-representations. Roman Zeyde, Michael Elad, Matan Protter, International Conference on Curves and Surfaces. 56Roman Zeyde, Michael Elad, and Matan Protter. On sin- gle image scale-up using sparse-representations. In Interna- tional Conference on Curves and Surfaces, pages 711-730, 2010. 5, 6\n\nDeep unfolding network for image super-resolution. Kai Zhang, Luc Van Gool, Radu Timofte, Proc. CVPR. CVPR2020Kai Zhang, Luc Van Gool, and Radu Timofte. Deep un- folding network for image super-resolution. In Proc. CVPR, pages 3217-3226, 2020. 2\n\nBeyond a gaussian denoiser: Residual learning of deep cnn for image denoising. Kai Zhang, Wangmeng Zuo, Yunjin Chen, Deyu Meng, Lei Zhang, IEEE Trans. on Image Processing. 267Kai Zhang, Wangmeng Zuo, Yunjin Chen, Deyu Meng, and Lei Zhang. Beyond a gaussian denoiser: Residual learning of deep cnn for image denoising. IEEE Trans. on Image Pro- cessing, 26(7):3142-3155, 2017. 2\n\nLearning a single convolutional super-resolution network for multiple degradations. Kai Zhang, Wangmeng Zuo, Lei Zhang, Proc. CVPR. CVPR67Kai Zhang, Wangmeng Zuo, and Lei Zhang. Learning a single convolutional super-resolution network for multiple degradations. In Proc. CVPR, pages 3262-3271, 2018. 2, 3, 6, 7\n\nDeep plugand-play super-resolution for arbitrary blur kernels. Kai Zhang, Wangmeng Zuo, Lei Zhang, Proc. CVPR. CVPR13Kai Zhang, Wangmeng Zuo, and Lei Zhang. Deep plug- and-play super-resolution for arbitrary blur kernels. In Proc. CVPR, pages 1671-1681, 2019. 1, 2, 3\n\nThe unreasonable effectiveness of. Richard Zhang, Phillip Isola, Alexei A Efros, Eli Shechtman, Oliver Wang, Richard Zhang, Phillip Isola, Alexei A Efros, Eli Shecht- man, and Oliver Wang. The unreasonable effectiveness of\n", "annotations": {"author": "[{\"end\":97,\"start\":67},{\"end\":133,\"start\":98},{\"end\":161,\"start\":134},{\"end\":192,\"start\":162},{\"end\":226,\"start\":193},{\"end\":316,\"start\":227}]", "publisher": null, "author_last_name": "[{\"end\":76,\"start\":73},{\"end\":110,\"start\":105},{\"end\":140,\"start\":138},{\"end\":171,\"start\":169},{\"end\":205,\"start\":202},{\"end\":241,\"start\":238}]", "author_first_name": "[{\"end\":72,\"start\":67},{\"end\":104,\"start\":98},{\"end\":137,\"start\":134},{\"end\":168,\"start\":162},{\"end\":201,\"start\":193},{\"end\":237,\"start\":227}]", "author_affiliation": "[{\"end\":96,\"start\":78},{\"end\":132,\"start\":112},{\"end\":160,\"start\":142},{\"end\":191,\"start\":173},{\"end\":225,\"start\":207},{\"end\":261,\"start\":243},{\"end\":315,\"start\":263}]", "title": "[{\"end\":64,\"start\":1},{\"end\":380,\"start\":317}]", "venue": null, "abstract": "[{\"end\":2083,\"start\":382}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3625,\"start\":3622},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":3627,\"start\":3625},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":3630,\"start\":3627},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":3633,\"start\":3630},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":3636,\"start\":3633},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":3639,\"start\":3636},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":3642,\"start\":3639},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":3645,\"start\":3642},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":3648,\"start\":3645},{\"end\":3651,\"start\":3648},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":4027,\"start\":4024},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":4030,\"start\":4027},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":4438,\"start\":4434},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":4441,\"start\":4438},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":4587,\"start\":4584},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":4589,\"start\":4587},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":4592,\"start\":4589},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":4595,\"start\":4592},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":4802,\"start\":4799},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":4805,\"start\":4802},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":4808,\"start\":4805},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":7565,\"start\":7562},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":7711,\"start\":7708},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":7714,\"start\":7711},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":7717,\"start\":7714},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":7720,\"start\":7717},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":7723,\"start\":7720},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":7726,\"start\":7723},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":7729,\"start\":7726},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":7732,\"start\":7729},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":7735,\"start\":7732},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":7738,\"start\":7735},{\"end\":7741,\"start\":7738},{\"end\":7743,\"start\":7741},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":7772,\"start\":7768},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":7775,\"start\":7772},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":7778,\"start\":7775},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":7781,\"start\":7778},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":7784,\"start\":7781},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":7787,\"start\":7784},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":7790,\"start\":7787},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":8216,\"start\":8212},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":8390,\"start\":8386},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":8393,\"start\":8390},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":8500,\"start\":8496},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":8583,\"start\":8579},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":8719,\"start\":8715},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":8722,\"start\":8719},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":8905,\"start\":8901},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":8908,\"start\":8905},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":8911,\"start\":8908},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":9062,\"start\":9059},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":9279,\"start\":9275},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":9385,\"start\":9381},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":9562,\"start\":9559},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":9724,\"start\":9720},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":9957,\"start\":9953},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":10775,\"start\":10771},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":10778,\"start\":10775},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":11612,\"start\":11609},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":12066,\"start\":12063},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":12275,\"start\":12272},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":12328,\"start\":12325},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":12331,\"start\":12328},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":12565,\"start\":12562},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":12568,\"start\":12565},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":12571,\"start\":12568},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":15101,\"start\":15097},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":15181,\"start\":15178},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":15184,\"start\":15181},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":15187,\"start\":15184},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":15257,\"start\":15254},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":15427,\"start\":15424},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":15430,\"start\":15427},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":16443,\"start\":16439},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":16797,\"start\":16794},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":16800,\"start\":16797},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":16834,\"start\":16831},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":16852,\"start\":16848},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":17084,\"start\":17080},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":17276,\"start\":17273},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":17324,\"start\":17322},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":17340,\"start\":17337},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":17429,\"start\":17426},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":17441,\"start\":17437},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":17454,\"start\":17450},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":17469,\"start\":17465},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":17487,\"start\":17483},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":17607,\"start\":17604},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":17997,\"start\":17994},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":18196,\"start\":18192},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":18586,\"start\":18583},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":18730,\"start\":18726},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":18761,\"start\":18758},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":18773,\"start\":18769},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":18785,\"start\":18781},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":18804,\"start\":18800},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":18819,\"start\":18816},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":18861,\"start\":18858},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":18921,\"start\":18917},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":20214,\"start\":20210},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":20687,\"start\":20683},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":20696,\"start\":20693},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":20708,\"start\":20704},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":20720,\"start\":20716},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":20736,\"start\":20732},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":20754,\"start\":20750},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":20836,\"start\":20832},{\"end\":20847,\"start\":20838},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":20862,\"start\":20858},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":20894,\"start\":20890},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":20975,\"start\":20972},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":21027,\"start\":21023},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":21041,\"start\":21037},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":21137,\"start\":21134},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":21994,\"start\":21991},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":22021,\"start\":22017},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":22840,\"start\":22837},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":22843,\"start\":22840},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":23114,\"start\":23110},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":23222,\"start\":23218},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":23634,\"start\":23630},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":23649,\"start\":23645},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":25395,\"start\":25392},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":25496,\"start\":25493}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":24708,\"start\":24535},{\"attributes\":{\"id\":\"fig_1\"},\"end\":24769,\"start\":24709},{\"attributes\":{\"id\":\"fig_2\"},\"end\":25143,\"start\":24770},{\"attributes\":{\"id\":\"fig_3\"},\"end\":25309,\"start\":25144},{\"attributes\":{\"id\":\"fig_4\"},\"end\":25433,\"start\":25310},{\"attributes\":{\"id\":\"fig_5\"},\"end\":25542,\"start\":25434},{\"attributes\":{\"id\":\"fig_6\"},\"end\":25720,\"start\":25543},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":29350,\"start\":25721},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":29585,\"start\":29351},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":30014,\"start\":29586},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":30945,\"start\":30015},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":31906,\"start\":30946}]", "paragraph": "[{\"end\":3301,\"start\":2095},{\"end\":3652,\"start\":3318},{\"end\":3843,\"start\":3654},{\"end\":5440,\"start\":3870},{\"end\":6762,\"start\":5442},{\"end\":6813,\"start\":6764},{\"end\":7020,\"start\":6815},{\"end\":7360,\"start\":7022},{\"end\":7504,\"start\":7362},{\"end\":10096,\"start\":7521},{\"end\":10500,\"start\":10107},{\"end\":10834,\"start\":10536},{\"end\":11063,\"start\":10978},{\"end\":11151,\"start\":11109},{\"end\":11369,\"start\":11175},{\"end\":11724,\"start\":11459},{\"end\":13237,\"start\":11817},{\"end\":13562,\"start\":13274},{\"end\":13867,\"start\":13597},{\"end\":14033,\"start\":13897},{\"end\":14153,\"start\":14096},{\"end\":14206,\"start\":14155},{\"end\":14387,\"start\":14271},{\"end\":14463,\"start\":14428},{\"end\":14574,\"start\":14482},{\"end\":14897,\"start\":14619},{\"end\":14991,\"start\":14936},{\"end\":15370,\"start\":15040},{\"end\":15916,\"start\":15402},{\"end\":16555,\"start\":15918},{\"end\":16715,\"start\":16603},{\"end\":17147,\"start\":16769},{\"end\":18491,\"start\":17149},{\"end\":19028,\"start\":18529},{\"end\":19088,\"start\":19030},{\"end\":20453,\"start\":19090},{\"end\":22120,\"start\":20455},{\"end\":22600,\"start\":22149},{\"end\":23233,\"start\":22602},{\"end\":23327,\"start\":23235},{\"end\":23717,\"start\":23329},{\"end\":24534,\"start\":23732}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":3869,\"start\":3844},{\"attributes\":{\"id\":\"formula_1\"},\"end\":10977,\"start\":10835},{\"attributes\":{\"id\":\"formula_2\"},\"end\":11108,\"start\":11064},{\"attributes\":{\"id\":\"formula_3\"},\"end\":11174,\"start\":11152},{\"attributes\":{\"id\":\"formula_4\"},\"end\":11458,\"start\":11370},{\"attributes\":{\"id\":\"formula_5\"},\"end\":11787,\"start\":11725},{\"attributes\":{\"id\":\"formula_6\"},\"end\":13273,\"start\":13238},{\"attributes\":{\"id\":\"formula_7\"},\"end\":13896,\"start\":13868},{\"attributes\":{\"id\":\"formula_8\"},\"end\":14095,\"start\":14034},{\"attributes\":{\"id\":\"formula_9\"},\"end\":14270,\"start\":14207},{\"attributes\":{\"id\":\"formula_10\"},\"end\":14427,\"start\":14388},{\"attributes\":{\"id\":\"formula_11\"},\"end\":14481,\"start\":14464},{\"attributes\":{\"id\":\"formula_12\"},\"end\":14618,\"start\":14575},{\"attributes\":{\"id\":\"formula_13\"},\"end\":14935,\"start\":14898},{\"attributes\":{\"id\":\"formula_14\"},\"end\":15039,\"start\":14992},{\"attributes\":{\"id\":\"formula_15\"},\"end\":16602,\"start\":16556}]", "table_ref": "[{\"end\":18975,\"start\":18968},{\"end\":19135,\"start\":19128},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":20357,\"start\":20350},{\"end\":21091,\"start\":21084},{\"end\":21925,\"start\":21918},{\"end\":22322,\"start\":22315},{\"end\":22928,\"start\":22909}]", "section_header": "[{\"end\":2093,\"start\":2085},{\"attributes\":{\"n\":\"1.\"},\"end\":3316,\"start\":3304},{\"attributes\":{\"n\":\"2.\"},\"end\":7519,\"start\":7507},{\"attributes\":{\"n\":\"3.\"},\"end\":10105,\"start\":10099},{\"attributes\":{\"n\":\"3.1.\"},\"end\":10534,\"start\":10503},{\"attributes\":{\"n\":\"3.2.\"},\"end\":11815,\"start\":11789},{\"attributes\":{\"n\":\"3.3.\"},\"end\":13595,\"start\":13565},{\"attributes\":{\"n\":\"3.4.\"},\"end\":15400,\"start\":15373},{\"attributes\":{\"n\":\"4.\"},\"end\":16729,\"start\":16718},{\"attributes\":{\"n\":\"4.1.\"},\"end\":16767,\"start\":16732},{\"attributes\":{\"n\":\"4.2.\"},\"end\":18527,\"start\":18494},{\"attributes\":{\"n\":\"4.3.\"},\"end\":22147,\"start\":22123},{\"attributes\":{\"n\":\"5.\"},\"end\":23730,\"start\":23720},{\"end\":24546,\"start\":24536},{\"end\":24720,\"start\":24710},{\"end\":24781,\"start\":24771},{\"end\":25165,\"start\":25145},{\"end\":25321,\"start\":25311},{\"end\":25445,\"start\":25435},{\"end\":25555,\"start\":25544},{\"end\":25731,\"start\":25722}]", "table": "[{\"end\":29350,\"start\":26030},{\"end\":29585,\"start\":29445},{\"end\":30014,\"start\":29681},{\"end\":30945,\"start\":30341}]", "figure_caption": "[{\"end\":24708,\"start\":24548},{\"end\":24769,\"start\":24722},{\"end\":25143,\"start\":24783},{\"end\":25309,\"start\":25168},{\"end\":25433,\"start\":25323},{\"end\":25542,\"start\":25447},{\"end\":25720,\"start\":25558},{\"end\":26030,\"start\":25733},{\"end\":29445,\"start\":29353},{\"end\":29681,\"start\":29588},{\"end\":30341,\"start\":30017},{\"end\":31906,\"start\":30948}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":5767,\"start\":5761},{\"end\":6657,\"start\":6651},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":11552,\"start\":11546},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":12805,\"start\":12799},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":15878,\"start\":15872},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":16216,\"start\":16210},{\"end\":20046,\"start\":20040},{\"end\":20151,\"start\":20145},{\"end\":20160,\"start\":20152},{\"end\":20368,\"start\":20362},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":21723,\"start\":21717},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":21913,\"start\":21907},{\"end\":23187,\"start\":23178},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":23326,\"start\":23319},{\"end\":23607,\"start\":23600}]", "bib_author_first_name": "[{\"end\":31989,\"start\":31982},{\"end\":32005,\"start\":32001},{\"end\":32272,\"start\":32265},{\"end\":32286,\"start\":32278},{\"end\":32301,\"start\":32293},{\"end\":32565,\"start\":32561},{\"end\":32585,\"start\":32580},{\"end\":32601,\"start\":32595},{\"end\":32946,\"start\":32941},{\"end\":32964,\"start\":32959},{\"end\":33274,\"start\":33271},{\"end\":33287,\"start\":33280},{\"end\":33301,\"start\":33293},{\"end\":33316,\"start\":33309},{\"end\":33325,\"start\":33322},{\"end\":33802,\"start\":33798},{\"end\":33813,\"start\":33809},{\"end\":33820,\"start\":33814},{\"end\":33833,\"start\":33826},{\"end\":33844,\"start\":33838},{\"end\":34189,\"start\":34181},{\"end\":34202,\"start\":34196},{\"end\":34214,\"start\":34209},{\"end\":34474,\"start\":34468},{\"end\":34492,\"start\":34485},{\"end\":34501,\"start\":34497},{\"end\":34864,\"start\":34858},{\"end\":34875,\"start\":34869},{\"end\":34888,\"start\":34880},{\"end\":34898,\"start\":34894},{\"end\":35150,\"start\":35142},{\"end\":35165,\"start\":35158},{\"end\":35190,\"start\":35181},{\"end\":35634,\"start\":35633},{\"end\":35636,\"start\":35635},{\"end\":35655,\"start\":35644},{\"end\":35908,\"start\":35901},{\"end\":35924,\"start\":35916},{\"end\":35940,\"start\":35932},{\"end\":36231,\"start\":36228},{\"end\":36255,\"start\":36251},{\"end\":36784,\"start\":36775},{\"end\":36792,\"start\":36789},{\"end\":36806,\"start\":36801},{\"end\":36819,\"start\":36811},{\"end\":37121,\"start\":37115},{\"end\":37140,\"start\":37131},{\"end\":37150,\"start\":37148},{\"end\":37449,\"start\":37444},{\"end\":37660,\"start\":37655},{\"end\":37670,\"start\":37666},{\"end\":37675,\"start\":37671},{\"end\":37690,\"start\":37681},{\"end\":38139,\"start\":38134},{\"end\":38149,\"start\":38145},{\"end\":38154,\"start\":38150},{\"end\":38169,\"start\":38160},{\"end\":38627,\"start\":38619},{\"end\":38648,\"start\":38640},{\"end\":38897,\"start\":38896},{\"end\":38913,\"start\":38908},{\"end\":39153,\"start\":39144},{\"end\":39166,\"start\":39159},{\"end\":39182,\"start\":39174},{\"end\":39200,\"start\":39190},{\"end\":39694,\"start\":39685},{\"end\":39707,\"start\":39702},{\"end\":39721,\"start\":39715},{\"end\":39734,\"start\":39730},{\"end\":39752,\"start\":39746},{\"end\":39774,\"start\":39765},{\"end\":39789,\"start\":39783},{\"end\":39805,\"start\":39798},{\"end\":39822,\"start\":39814},{\"end\":39834,\"start\":39829},{\"end\":40400,\"start\":40392},{\"end\":40411,\"start\":40406},{\"end\":40432,\"start\":40427},{\"end\":40434,\"start\":40433},{\"end\":40653,\"start\":40649},{\"end\":40665,\"start\":40661},{\"end\":40678,\"start\":40673},{\"end\":40696,\"start\":40687},{\"end\":41068,\"start\":41064},{\"end\":41080,\"start\":41076},{\"end\":41093,\"start\":41088},{\"end\":41111,\"start\":41102},{\"end\":41358,\"start\":41354},{\"end\":41370,\"start\":41363},{\"end\":41382,\"start\":41377},{\"end\":41395,\"start\":41388},{\"end\":41410,\"start\":41402},{\"end\":41420,\"start\":41417},{\"end\":41885,\"start\":41878},{\"end\":41896,\"start\":41893},{\"end\":41911,\"start\":41904},{\"end\":41919,\"start\":41916},{\"end\":41934,\"start\":41930},{\"end\":42415,\"start\":42412},{\"end\":42429,\"start\":42421},{\"end\":42441,\"start\":42435},{\"end\":42455,\"start\":42447},{\"end\":42470,\"start\":42461},{\"end\":42753,\"start\":42746},{\"end\":42769,\"start\":42763},{\"end\":42784,\"start\":42781},{\"end\":42799,\"start\":42795},{\"end\":43147,\"start\":43137},{\"end\":43156,\"start\":43153},{\"end\":43169,\"start\":43164},{\"end\":43179,\"start\":43174},{\"end\":43192,\"start\":43186},{\"end\":43470,\"start\":43460},{\"end\":43479,\"start\":43476},{\"end\":43492,\"start\":43487},{\"end\":43502,\"start\":43497},{\"end\":43515,\"start\":43509},{\"end\":43819,\"start\":43814},{\"end\":43828,\"start\":43825},{\"end\":43837,\"start\":43833},{\"end\":43848,\"start\":43842},{\"end\":43860,\"start\":43853},{\"end\":43874,\"start\":43866},{\"end\":43884,\"start\":43880},{\"end\":43900,\"start\":43890},{\"end\":44481,\"start\":44476},{\"end\":44498,\"start\":44490},{\"end\":44513,\"start\":44508},{\"end\":44527,\"start\":44519},{\"end\":44858,\"start\":44852},{\"end\":44871,\"start\":44867},{\"end\":44881,\"start\":44877},{\"end\":44896,\"start\":44891},{\"end\":44911,\"start\":44907},{\"end\":44928,\"start\":44919},{\"end\":44947,\"start\":44939},{\"end\":45267,\"start\":45262},{\"end\":45284,\"start\":45278},{\"end\":45642,\"start\":45637},{\"end\":45659,\"start\":45653},{\"end\":45678,\"start\":45669},{\"end\":45690,\"start\":45684},{\"end\":45937,\"start\":45930},{\"end\":45949,\"start\":45943},{\"end\":45964,\"start\":45955},{\"end\":45984,\"start\":45974},{\"end\":46313,\"start\":46310},{\"end\":46317,\"start\":46314},{\"end\":46342,\"start\":46335},{\"end\":46644,\"start\":46643},{\"end\":46658,\"start\":46653},{\"end\":46660,\"start\":46659},{\"end\":46672,\"start\":46667},{\"end\":47019,\"start\":47013},{\"end\":47029,\"start\":47025},{\"end\":47047,\"start\":47041},{\"end\":47064,\"start\":47056},{\"end\":47072,\"start\":47071},{\"end\":47084,\"start\":47081},{\"end\":47099,\"start\":47093},{\"end\":47113,\"start\":47108},{\"end\":47670,\"start\":47665},{\"end\":47685,\"start\":47680},{\"end\":47699,\"start\":47693},{\"end\":47938,\"start\":47935},{\"end\":47944,\"start\":47939},{\"end\":47956,\"start\":47950},{\"end\":47965,\"start\":47962},{\"end\":47968,\"start\":47966},{\"end\":48399,\"start\":48395},{\"end\":48409,\"start\":48405},{\"end\":48424,\"start\":48416},{\"end\":48863,\"start\":48855},{\"end\":48878,\"start\":48869},{\"end\":48890,\"start\":48883},{\"end\":48901,\"start\":48897},{\"end\":48915,\"start\":48908},{\"end\":48924,\"start\":48921},{\"end\":48934,\"start\":48930},{\"end\":48946,\"start\":48939},{\"end\":48956,\"start\":48952},{\"end\":49373,\"start\":49369},{\"end\":49390,\"start\":49383},{\"end\":49405,\"start\":49402},{\"end\":49426,\"start\":49416},{\"end\":49436,\"start\":49433},{\"end\":49767,\"start\":49760},{\"end\":49786,\"start\":49780},{\"end\":49804,\"start\":49798},{\"end\":50191,\"start\":50185},{\"end\":50200,\"start\":50198},{\"end\":50209,\"start\":50205},{\"end\":50227,\"start\":50216},{\"end\":50695,\"start\":50689},{\"end\":50704,\"start\":50702},{\"end\":50717,\"start\":50709},{\"end\":50728,\"start\":50722},{\"end\":50738,\"start\":50733},{\"end\":50748,\"start\":50744},{\"end\":50757,\"start\":50755},{\"end\":50775,\"start\":50764},{\"end\":51262,\"start\":51258},{\"end\":51273,\"start\":51269},{\"end\":51275,\"start\":51274},{\"end\":51284,\"start\":51283},{\"end\":51298,\"start\":51292},{\"end\":51659,\"start\":51652},{\"end\":51959,\"start\":51951},{\"end\":51976,\"start\":51964},{\"end\":51986,\"start\":51984},{\"end\":52003,\"start\":51994},{\"end\":52015,\"start\":52009},{\"end\":52524,\"start\":52521},{\"end\":52534,\"start\":52529},{\"end\":52822,\"start\":52817},{\"end\":52837,\"start\":52830},{\"end\":52849,\"start\":52844},{\"end\":53148,\"start\":53145},{\"end\":53159,\"start\":53156},{\"end\":53174,\"start\":53170},{\"end\":53423,\"start\":53420},{\"end\":53439,\"start\":53431},{\"end\":53451,\"start\":53445},{\"end\":53462,\"start\":53458},{\"end\":53472,\"start\":53469},{\"end\":53807,\"start\":53804},{\"end\":53823,\"start\":53815},{\"end\":53832,\"start\":53829},{\"end\":54098,\"start\":54095},{\"end\":54114,\"start\":54106},{\"end\":54123,\"start\":54120},{\"end\":54343,\"start\":54336},{\"end\":54358,\"start\":54351},{\"end\":54372,\"start\":54366},{\"end\":54374,\"start\":54373},{\"end\":54385,\"start\":54382},{\"end\":54403,\"start\":54397}]", "bib_author_last_name": "[{\"end\":31999,\"start\":31990},{\"end\":32013,\"start\":32006},{\"end\":32276,\"start\":32273},{\"end\":32291,\"start\":32287},{\"end\":32306,\"start\":32302},{\"end\":32578,\"start\":32566},{\"end\":32593,\"start\":32586},{\"end\":32607,\"start\":32602},{\"end\":32957,\"start\":32947},{\"end\":32970,\"start\":32965},{\"end\":33278,\"start\":33275},{\"end\":33291,\"start\":33288},{\"end\":33307,\"start\":33302},{\"end\":33320,\"start\":33317},{\"end\":33331,\"start\":33326},{\"end\":33807,\"start\":33803},{\"end\":33824,\"start\":33821},{\"end\":33836,\"start\":33834},{\"end\":33849,\"start\":33845},{\"end\":34194,\"start\":34190},{\"end\":34207,\"start\":34203},{\"end\":34222,\"start\":34215},{\"end\":34483,\"start\":34475},{\"end\":34495,\"start\":34493},{\"end\":34509,\"start\":34502},{\"end\":34867,\"start\":34865},{\"end\":34878,\"start\":34876},{\"end\":34892,\"start\":34889},{\"end\":34903,\"start\":34899},{\"end\":35156,\"start\":35151},{\"end\":35179,\"start\":35166},{\"end\":35196,\"start\":35191},{\"end\":35642,\"start\":35637},{\"end\":35660,\"start\":35656},{\"end\":35914,\"start\":35909},{\"end\":35930,\"start\":35925},{\"end\":35946,\"start\":35941},{\"end\":36249,\"start\":36232},{\"end\":36261,\"start\":36256},{\"end\":36269,\"start\":36263},{\"end\":36787,\"start\":36785},{\"end\":36799,\"start\":36793},{\"end\":36809,\"start\":36807},{\"end\":36825,\"start\":36820},{\"end\":36830,\"start\":36827},{\"end\":37129,\"start\":37122},{\"end\":37146,\"start\":37141},{\"end\":37158,\"start\":37151},{\"end\":37459,\"start\":37450},{\"end\":37664,\"start\":37661},{\"end\":37679,\"start\":37676},{\"end\":37694,\"start\":37691},{\"end\":38143,\"start\":38140},{\"end\":38158,\"start\":38155},{\"end\":38173,\"start\":38170},{\"end\":38638,\"start\":38628},{\"end\":38652,\"start\":38649},{\"end\":38657,\"start\":38654},{\"end\":38906,\"start\":38898},{\"end\":38920,\"start\":38914},{\"end\":38924,\"start\":38922},{\"end\":39157,\"start\":39154},{\"end\":39172,\"start\":39167},{\"end\":39188,\"start\":39183},{\"end\":39205,\"start\":39201},{\"end\":39700,\"start\":39695},{\"end\":39713,\"start\":39708},{\"end\":39728,\"start\":39722},{\"end\":39744,\"start\":39735},{\"end\":39763,\"start\":39753},{\"end\":39781,\"start\":39775},{\"end\":39796,\"start\":39790},{\"end\":39812,\"start\":39806},{\"end\":39827,\"start\":39823},{\"end\":39839,\"start\":39835},{\"end\":40404,\"start\":40401},{\"end\":40425,\"start\":40412},{\"end\":40443,\"start\":40435},{\"end\":40659,\"start\":40654},{\"end\":40671,\"start\":40666},{\"end\":40685,\"start\":40679},{\"end\":40704,\"start\":40697},{\"end\":41074,\"start\":41069},{\"end\":41086,\"start\":41081},{\"end\":41100,\"start\":41094},{\"end\":41119,\"start\":41112},{\"end\":41361,\"start\":41359},{\"end\":41375,\"start\":41371},{\"end\":41386,\"start\":41383},{\"end\":41400,\"start\":41396},{\"end\":41415,\"start\":41411},{\"end\":41423,\"start\":41421},{\"end\":41891,\"start\":41886},{\"end\":41902,\"start\":41897},{\"end\":41914,\"start\":41912},{\"end\":41928,\"start\":41920},{\"end\":41942,\"start\":41935},{\"end\":42419,\"start\":42416},{\"end\":42433,\"start\":42430},{\"end\":42445,\"start\":42442},{\"end\":42459,\"start\":42456},{\"end\":42474,\"start\":42471},{\"end\":42761,\"start\":42754},{\"end\":42779,\"start\":42770},{\"end\":42793,\"start\":42785},{\"end\":42807,\"start\":42800},{\"end\":43151,\"start\":43148},{\"end\":43162,\"start\":43157},{\"end\":43172,\"start\":43170},{\"end\":43184,\"start\":43180},{\"end\":43196,\"start\":43193},{\"end\":43474,\"start\":43471},{\"end\":43485,\"start\":43480},{\"end\":43495,\"start\":43493},{\"end\":43507,\"start\":43503},{\"end\":43519,\"start\":43516},{\"end\":43823,\"start\":43820},{\"end\":43831,\"start\":43829},{\"end\":43840,\"start\":43838},{\"end\":43851,\"start\":43849},{\"end\":43864,\"start\":43861},{\"end\":43878,\"start\":43875},{\"end\":43888,\"start\":43885},{\"end\":43904,\"start\":43901},{\"end\":44488,\"start\":44482},{\"end\":44506,\"start\":44499},{\"end\":44517,\"start\":44514},{\"end\":44533,\"start\":44528},{\"end\":44865,\"start\":44859},{\"end\":44875,\"start\":44872},{\"end\":44889,\"start\":44882},{\"end\":44905,\"start\":44897},{\"end\":44917,\"start\":44912},{\"end\":44937,\"start\":44929},{\"end\":44954,\"start\":44948},{\"end\":45276,\"start\":45268},{\"end\":45290,\"start\":45285},{\"end\":45651,\"start\":45643},{\"end\":45667,\"start\":45660},{\"end\":45682,\"start\":45679},{\"end\":45697,\"start\":45691},{\"end\":45941,\"start\":45938},{\"end\":45953,\"start\":45950},{\"end\":45972,\"start\":45965},{\"end\":45989,\"start\":45985},{\"end\":46333,\"start\":46318},{\"end\":46347,\"start\":46343},{\"end\":46353,\"start\":46349},{\"end\":46651,\"start\":46645},{\"end\":46665,\"start\":46661},{\"end\":46683,\"start\":46673},{\"end\":46692,\"start\":46685},{\"end\":47023,\"start\":47020},{\"end\":47039,\"start\":47030},{\"end\":47054,\"start\":47048},{\"end\":47069,\"start\":47065},{\"end\":47079,\"start\":47073},{\"end\":47091,\"start\":47085},{\"end\":47106,\"start\":47100},{\"end\":47122,\"start\":47114},{\"end\":47128,\"start\":47124},{\"end\":47678,\"start\":47671},{\"end\":47691,\"start\":47686},{\"end\":47705,\"start\":47700},{\"end\":47948,\"start\":47945},{\"end\":47960,\"start\":47957},{\"end\":47972,\"start\":47969},{\"end\":48403,\"start\":48400},{\"end\":48414,\"start\":48410},{\"end\":48428,\"start\":48425},{\"end\":48867,\"start\":48864},{\"end\":48881,\"start\":48879},{\"end\":48895,\"start\":48891},{\"end\":48906,\"start\":48902},{\"end\":48919,\"start\":48916},{\"end\":48928,\"start\":48925},{\"end\":48937,\"start\":48935},{\"end\":48950,\"start\":48947},{\"end\":48960,\"start\":48957},{\"end\":49381,\"start\":49374},{\"end\":49400,\"start\":49391},{\"end\":49414,\"start\":49406},{\"end\":49431,\"start\":49427},{\"end\":49442,\"start\":49437},{\"end\":49778,\"start\":49768},{\"end\":49796,\"start\":49787},{\"end\":49813,\"start\":49805},{\"end\":50196,\"start\":50192},{\"end\":50203,\"start\":50201},{\"end\":50214,\"start\":50210},{\"end\":50231,\"start\":50228},{\"end\":50700,\"start\":50696},{\"end\":50707,\"start\":50705},{\"end\":50720,\"start\":50718},{\"end\":50731,\"start\":50729},{\"end\":50742,\"start\":50739},{\"end\":50753,\"start\":50749},{\"end\":50762,\"start\":50758},{\"end\":50779,\"start\":50776},{\"end\":51267,\"start\":51263},{\"end\":51281,\"start\":51276},{\"end\":51290,\"start\":51285},{\"end\":51305,\"start\":51299},{\"end\":51317,\"start\":51307},{\"end\":51666,\"start\":51660},{\"end\":51962,\"start\":51960},{\"end\":51982,\"start\":51977},{\"end\":51992,\"start\":51987},{\"end\":52007,\"start\":52004},{\"end\":52020,\"start\":52016},{\"end\":52527,\"start\":52525},{\"end\":52542,\"start\":52535},{\"end\":52828,\"start\":52823},{\"end\":52842,\"start\":52838},{\"end\":52857,\"start\":52850},{\"end\":53154,\"start\":53149},{\"end\":53168,\"start\":53160},{\"end\":53182,\"start\":53175},{\"end\":53429,\"start\":53424},{\"end\":53443,\"start\":53440},{\"end\":53456,\"start\":53452},{\"end\":53467,\"start\":53463},{\"end\":53478,\"start\":53473},{\"end\":53813,\"start\":53808},{\"end\":53827,\"start\":53824},{\"end\":53838,\"start\":53833},{\"end\":54104,\"start\":54099},{\"end\":54118,\"start\":54115},{\"end\":54129,\"start\":54124},{\"end\":54349,\"start\":54344},{\"end\":54364,\"start\":54359},{\"end\":54380,\"start\":54375},{\"end\":54395,\"start\":54386},{\"end\":54408,\"start\":54404}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":4493958},\"end\":32181,\"start\":31908},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":4710341},\"end\":32495,\"start\":32183},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":202577523},\"end\":32803,\"start\":32497},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":5250573},\"end\":33203,\"start\":32805},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":174788791},\"end\":33730,\"start\":33205},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":18874645},\"end\":34103,\"start\":33732},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":227276276},\"end\":34412,\"start\":34105},{\"attributes\":{\"id\":\"b7\"},\"end\":34621,\"start\":34414},{\"attributes\":{\"id\":\"b8\"},\"end\":34799,\"start\":34623},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":102352104},\"end\":35088,\"start\":34801},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":3739626},\"end\":35567,\"start\":35090},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":120324714},\"end\":35836,\"start\":35569},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":8282555},\"end\":36125,\"start\":35838},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":208527385},\"end\":36690,\"start\":36127},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":235680054},\"end\":37044,\"start\":36692},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":980236},\"end\":37401,\"start\":37046},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":1605269},\"end\":37581,\"start\":37403},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":9971732},\"end\":38066,\"start\":37583},{\"attributes\":{\"id\":\"b18\"},\"end\":38535,\"start\":38068},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":229180840},\"end\":38850,\"start\":38537},{\"attributes\":{\"doi\":\"arXiv:1412.6980\",\"id\":\"b20\"},\"end\":39070,\"start\":38852},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":1543021},\"end\":39598,\"start\":39072},{\"attributes\":{\"id\":\"b22\"},\"end\":40344,\"start\":39600},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":108297495},\"end\":40586,\"start\":40346},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":1610143},\"end\":40995,\"start\":40588},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":1212427},\"end\":41308,\"start\":40997},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":85496615},\"end\":41808,\"start\":41310},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":232417580},\"end\":42343,\"start\":41810},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":6540453},\"end\":42677,\"start\":42345},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":220056113},\"end\":43068,\"start\":42679},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":222141081},\"end\":43394,\"start\":43070},{\"attributes\":{\"doi\":\"arXiv:2105.06878\",\"id\":\"b31\"},\"end\":43739,\"start\":43396},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":235703405},\"end\":44334,\"start\":43741},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":64193},\"end\":44797,\"start\":44336},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":8887614},\"end\":45222,\"start\":44799},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":7044126},\"end\":45578,\"start\":45224},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":5941770},\"end\":45886,\"start\":45580},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":13981820},\"end\":46248,\"start\":45888},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":12320918},\"end\":46555,\"start\":46250},{\"attributes\":{\"doi\":\"arXiv:1312.6120\",\"id\":\"b39\"},\"end\":46902,\"start\":46557},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":7037846},\"end\":47606,\"start\":46904},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":215825382},\"end\":47879,\"start\":47608},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":211532268},\"end\":48334,\"start\":47881},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":21618854},\"end\":48779,\"start\":48336},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":239769256},\"end\":49291,\"start\":48781},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":484327},\"end\":49658,\"start\":49293},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":6711411},\"end\":50093,\"start\":49660},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":4710407},\"end\":50620,\"start\":50095},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":52154773},\"end\":51182,\"start\":50622},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":207761262},\"end\":51548,\"start\":51184},{\"attributes\":{\"id\":\"b50\"},\"end\":51859,\"start\":51550},{\"attributes\":{\"id\":\"b51\",\"matched_paper_id\":215768718},\"end\":52452,\"start\":51861},{\"attributes\":{\"id\":\"b52\",\"matched_paper_id\":35258007},\"end\":52760,\"start\":52454},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":2356330},\"end\":53092,\"start\":52762},{\"attributes\":{\"id\":\"b54\",\"matched_paper_id\":214611551},\"end\":53339,\"start\":53094},{\"attributes\":{\"id\":\"b55\",\"matched_paper_id\":996788},\"end\":53718,\"start\":53341},{\"attributes\":{\"id\":\"b56\",\"matched_paper_id\":2141622},\"end\":54030,\"start\":53720},{\"attributes\":{\"id\":\"b57\",\"matched_paper_id\":88524978},\"end\":54299,\"start\":54032},{\"attributes\":{\"id\":\"b58\"},\"end\":54523,\"start\":54301}]", "bib_title": "[{\"end\":31980,\"start\":31908},{\"end\":32263,\"start\":32183},{\"end\":32559,\"start\":32497},{\"end\":32939,\"start\":32805},{\"end\":33269,\"start\":33205},{\"end\":33796,\"start\":33732},{\"end\":34179,\"start\":34105},{\"end\":34856,\"start\":34801},{\"end\":35140,\"start\":35090},{\"end\":35631,\"start\":35569},{\"end\":35899,\"start\":35838},{\"end\":36226,\"start\":36127},{\"end\":36773,\"start\":36692},{\"end\":37113,\"start\":37046},{\"end\":37442,\"start\":37403},{\"end\":37653,\"start\":37583},{\"end\":38132,\"start\":38068},{\"end\":38617,\"start\":38537},{\"end\":39142,\"start\":39072},{\"end\":39683,\"start\":39600},{\"end\":40390,\"start\":40346},{\"end\":40647,\"start\":40588},{\"end\":41062,\"start\":40997},{\"end\":41352,\"start\":41310},{\"end\":41876,\"start\":41810},{\"end\":42410,\"start\":42345},{\"end\":42744,\"start\":42679},{\"end\":43135,\"start\":43070},{\"end\":43812,\"start\":43741},{\"end\":44474,\"start\":44336},{\"end\":44850,\"start\":44799},{\"end\":45260,\"start\":45224},{\"end\":45635,\"start\":45580},{\"end\":45928,\"start\":45888},{\"end\":46308,\"start\":46250},{\"end\":47011,\"start\":46904},{\"end\":47663,\"start\":47608},{\"end\":47933,\"start\":47881},{\"end\":48393,\"start\":48336},{\"end\":48853,\"start\":48781},{\"end\":49367,\"start\":49293},{\"end\":49758,\"start\":49660},{\"end\":50183,\"start\":50095},{\"end\":50687,\"start\":50622},{\"end\":51256,\"start\":51184},{\"end\":51949,\"start\":51861},{\"end\":52519,\"start\":52454},{\"end\":52815,\"start\":52762},{\"end\":53143,\"start\":53094},{\"end\":53418,\"start\":53341},{\"end\":53802,\"start\":53720},{\"end\":54093,\"start\":54032}]", "bib_author": "[{\"end\":32001,\"start\":31982},{\"end\":32015,\"start\":32001},{\"end\":32278,\"start\":32265},{\"end\":32293,\"start\":32278},{\"end\":32308,\"start\":32293},{\"end\":32580,\"start\":32561},{\"end\":32595,\"start\":32580},{\"end\":32609,\"start\":32595},{\"end\":32959,\"start\":32941},{\"end\":32972,\"start\":32959},{\"end\":33280,\"start\":33271},{\"end\":33293,\"start\":33280},{\"end\":33309,\"start\":33293},{\"end\":33322,\"start\":33309},{\"end\":33333,\"start\":33322},{\"end\":33809,\"start\":33798},{\"end\":33826,\"start\":33809},{\"end\":33838,\"start\":33826},{\"end\":33851,\"start\":33838},{\"end\":34196,\"start\":34181},{\"end\":34209,\"start\":34196},{\"end\":34224,\"start\":34209},{\"end\":34485,\"start\":34468},{\"end\":34497,\"start\":34485},{\"end\":34511,\"start\":34497},{\"end\":34869,\"start\":34858},{\"end\":34880,\"start\":34869},{\"end\":34894,\"start\":34880},{\"end\":34905,\"start\":34894},{\"end\":35158,\"start\":35142},{\"end\":35181,\"start\":35158},{\"end\":35198,\"start\":35181},{\"end\":35644,\"start\":35633},{\"end\":35662,\"start\":35644},{\"end\":35916,\"start\":35901},{\"end\":35932,\"start\":35916},{\"end\":35948,\"start\":35932},{\"end\":36251,\"start\":36228},{\"end\":36263,\"start\":36251},{\"end\":36271,\"start\":36263},{\"end\":36789,\"start\":36775},{\"end\":36801,\"start\":36789},{\"end\":36811,\"start\":36801},{\"end\":36827,\"start\":36811},{\"end\":36832,\"start\":36827},{\"end\":37131,\"start\":37115},{\"end\":37148,\"start\":37131},{\"end\":37160,\"start\":37148},{\"end\":37461,\"start\":37444},{\"end\":37666,\"start\":37655},{\"end\":37681,\"start\":37666},{\"end\":37696,\"start\":37681},{\"end\":38145,\"start\":38134},{\"end\":38160,\"start\":38145},{\"end\":38175,\"start\":38160},{\"end\":38640,\"start\":38619},{\"end\":38654,\"start\":38640},{\"end\":38659,\"start\":38654},{\"end\":38908,\"start\":38896},{\"end\":38922,\"start\":38908},{\"end\":38926,\"start\":38922},{\"end\":39159,\"start\":39144},{\"end\":39174,\"start\":39159},{\"end\":39190,\"start\":39174},{\"end\":39207,\"start\":39190},{\"end\":39702,\"start\":39685},{\"end\":39715,\"start\":39702},{\"end\":39730,\"start\":39715},{\"end\":39746,\"start\":39730},{\"end\":39765,\"start\":39746},{\"end\":39783,\"start\":39765},{\"end\":39798,\"start\":39783},{\"end\":39814,\"start\":39798},{\"end\":39829,\"start\":39814},{\"end\":39841,\"start\":39829},{\"end\":40406,\"start\":40392},{\"end\":40427,\"start\":40406},{\"end\":40445,\"start\":40427},{\"end\":40661,\"start\":40649},{\"end\":40673,\"start\":40661},{\"end\":40687,\"start\":40673},{\"end\":40706,\"start\":40687},{\"end\":41076,\"start\":41064},{\"end\":41088,\"start\":41076},{\"end\":41102,\"start\":41088},{\"end\":41121,\"start\":41102},{\"end\":41363,\"start\":41354},{\"end\":41377,\"start\":41363},{\"end\":41388,\"start\":41377},{\"end\":41402,\"start\":41388},{\"end\":41417,\"start\":41402},{\"end\":41425,\"start\":41417},{\"end\":41893,\"start\":41878},{\"end\":41904,\"start\":41893},{\"end\":41916,\"start\":41904},{\"end\":41930,\"start\":41916},{\"end\":41944,\"start\":41930},{\"end\":42421,\"start\":42412},{\"end\":42435,\"start\":42421},{\"end\":42447,\"start\":42435},{\"end\":42461,\"start\":42447},{\"end\":42476,\"start\":42461},{\"end\":42763,\"start\":42746},{\"end\":42781,\"start\":42763},{\"end\":42795,\"start\":42781},{\"end\":42809,\"start\":42795},{\"end\":43153,\"start\":43137},{\"end\":43164,\"start\":43153},{\"end\":43174,\"start\":43164},{\"end\":43186,\"start\":43174},{\"end\":43198,\"start\":43186},{\"end\":43476,\"start\":43460},{\"end\":43487,\"start\":43476},{\"end\":43497,\"start\":43487},{\"end\":43509,\"start\":43497},{\"end\":43521,\"start\":43509},{\"end\":43825,\"start\":43814},{\"end\":43833,\"start\":43825},{\"end\":43842,\"start\":43833},{\"end\":43853,\"start\":43842},{\"end\":43866,\"start\":43853},{\"end\":43880,\"start\":43866},{\"end\":43890,\"start\":43880},{\"end\":43906,\"start\":43890},{\"end\":44490,\"start\":44476},{\"end\":44508,\"start\":44490},{\"end\":44519,\"start\":44508},{\"end\":44535,\"start\":44519},{\"end\":44867,\"start\":44852},{\"end\":44877,\"start\":44867},{\"end\":44891,\"start\":44877},{\"end\":44907,\"start\":44891},{\"end\":44919,\"start\":44907},{\"end\":44939,\"start\":44919},{\"end\":44956,\"start\":44939},{\"end\":45278,\"start\":45262},{\"end\":45292,\"start\":45278},{\"end\":45653,\"start\":45637},{\"end\":45669,\"start\":45653},{\"end\":45684,\"start\":45669},{\"end\":45699,\"start\":45684},{\"end\":45943,\"start\":45930},{\"end\":45955,\"start\":45943},{\"end\":45974,\"start\":45955},{\"end\":45991,\"start\":45974},{\"end\":46335,\"start\":46310},{\"end\":46349,\"start\":46335},{\"end\":46355,\"start\":46349},{\"end\":46653,\"start\":46643},{\"end\":46667,\"start\":46653},{\"end\":46685,\"start\":46667},{\"end\":46694,\"start\":46685},{\"end\":47025,\"start\":47013},{\"end\":47041,\"start\":47025},{\"end\":47056,\"start\":47041},{\"end\":47071,\"start\":47056},{\"end\":47081,\"start\":47071},{\"end\":47093,\"start\":47081},{\"end\":47108,\"start\":47093},{\"end\":47124,\"start\":47108},{\"end\":47130,\"start\":47124},{\"end\":47680,\"start\":47665},{\"end\":47693,\"start\":47680},{\"end\":47707,\"start\":47693},{\"end\":47950,\"start\":47935},{\"end\":47962,\"start\":47950},{\"end\":47974,\"start\":47962},{\"end\":48405,\"start\":48395},{\"end\":48416,\"start\":48405},{\"end\":48430,\"start\":48416},{\"end\":48869,\"start\":48855},{\"end\":48883,\"start\":48869},{\"end\":48897,\"start\":48883},{\"end\":48908,\"start\":48897},{\"end\":48921,\"start\":48908},{\"end\":48930,\"start\":48921},{\"end\":48939,\"start\":48930},{\"end\":48952,\"start\":48939},{\"end\":48962,\"start\":48952},{\"end\":49383,\"start\":49369},{\"end\":49402,\"start\":49383},{\"end\":49416,\"start\":49402},{\"end\":49433,\"start\":49416},{\"end\":49444,\"start\":49433},{\"end\":49780,\"start\":49760},{\"end\":49798,\"start\":49780},{\"end\":49815,\"start\":49798},{\"end\":50198,\"start\":50185},{\"end\":50205,\"start\":50198},{\"end\":50216,\"start\":50205},{\"end\":50233,\"start\":50216},{\"end\":50702,\"start\":50689},{\"end\":50709,\"start\":50702},{\"end\":50722,\"start\":50709},{\"end\":50733,\"start\":50722},{\"end\":50744,\"start\":50733},{\"end\":50755,\"start\":50744},{\"end\":50764,\"start\":50755},{\"end\":50781,\"start\":50764},{\"end\":51269,\"start\":51258},{\"end\":51283,\"start\":51269},{\"end\":51292,\"start\":51283},{\"end\":51307,\"start\":51292},{\"end\":51319,\"start\":51307},{\"end\":51668,\"start\":51652},{\"end\":51964,\"start\":51951},{\"end\":51984,\"start\":51964},{\"end\":51994,\"start\":51984},{\"end\":52009,\"start\":51994},{\"end\":52022,\"start\":52009},{\"end\":52529,\"start\":52521},{\"end\":52544,\"start\":52529},{\"end\":52830,\"start\":52817},{\"end\":52844,\"start\":52830},{\"end\":52859,\"start\":52844},{\"end\":53156,\"start\":53145},{\"end\":53170,\"start\":53156},{\"end\":53184,\"start\":53170},{\"end\":53431,\"start\":53420},{\"end\":53445,\"start\":53431},{\"end\":53458,\"start\":53445},{\"end\":53469,\"start\":53458},{\"end\":53480,\"start\":53469},{\"end\":53815,\"start\":53804},{\"end\":53829,\"start\":53815},{\"end\":53840,\"start\":53829},{\"end\":54106,\"start\":54095},{\"end\":54120,\"start\":54106},{\"end\":54131,\"start\":54120},{\"end\":54351,\"start\":54336},{\"end\":54366,\"start\":54351},{\"end\":54382,\"start\":54366},{\"end\":54397,\"start\":54382},{\"end\":54410,\"start\":54397}]", "bib_venue": "[{\"end\":32033,\"start\":32028},{\"end\":32324,\"start\":32320},{\"end\":32631,\"start\":32624},{\"end\":32988,\"start\":32984},{\"end\":33482,\"start\":33416},{\"end\":34246,\"start\":34239},{\"end\":34921,\"start\":34917},{\"end\":35339,\"start\":35277},{\"end\":35964,\"start\":35960},{\"end\":36420,\"start\":36354},{\"end\":36848,\"start\":36844},{\"end\":37483,\"start\":37476},{\"end\":37837,\"start\":37775},{\"end\":38316,\"start\":38254},{\"end\":38675,\"start\":38671},{\"end\":39348,\"start\":39286},{\"end\":39982,\"start\":39920},{\"end\":40461,\"start\":40457},{\"end\":41574,\"start\":41508},{\"end\":42093,\"start\":42027},{\"end\":42494,\"start\":42489},{\"end\":43220,\"start\":43213},{\"end\":44055,\"start\":43989},{\"end\":44551,\"start\":44547},{\"end\":45413,\"start\":45361},{\"end\":45721,\"start\":45714},{\"end\":47271,\"start\":47209},{\"end\":47723,\"start\":47719},{\"end\":48123,\"start\":48057},{\"end\":48571,\"start\":48509},{\"end\":49462,\"start\":49457},{\"end\":50374,\"start\":50312},{\"end\":50916,\"start\":50857},{\"end\":52171,\"start\":52105},{\"end\":53200,\"start\":53196},{\"end\":53856,\"start\":53852},{\"end\":54147,\"start\":54143},{\"end\":32026,\"start\":32015},{\"end\":32318,\"start\":32308},{\"end\":32622,\"start\":32609},{\"end\":32982,\"start\":32972},{\"end\":33414,\"start\":33333},{\"end\":33889,\"start\":33851},{\"end\":34237,\"start\":34224},{\"end\":34466,\"start\":34414},{\"end\":34692,\"start\":34623},{\"end\":34915,\"start\":34905},{\"end\":35275,\"start\":35198},{\"end\":35683,\"start\":35662},{\"end\":35958,\"start\":35948},{\"end\":36352,\"start\":36271},{\"end\":36842,\"start\":36832},{\"end\":37198,\"start\":37160},{\"end\":37474,\"start\":37461},{\"end\":37773,\"start\":37696},{\"end\":38252,\"start\":38175},{\"end\":38669,\"start\":38659},{\"end\":38894,\"start\":38852},{\"end\":39284,\"start\":39207},{\"end\":39918,\"start\":39841},{\"end\":40455,\"start\":40445},{\"end\":40769,\"start\":40706},{\"end\":41130,\"start\":41121},{\"end\":41506,\"start\":41425},{\"end\":42025,\"start\":41944},{\"end\":42487,\"start\":42476},{\"end\":42847,\"start\":42809},{\"end\":43211,\"start\":43198},{\"end\":43458,\"start\":43396},{\"end\":43987,\"start\":43906},{\"end\":44545,\"start\":44535},{\"end\":44989,\"start\":44956},{\"end\":45359,\"start\":45292},{\"end\":45712,\"start\":45699},{\"end\":46047,\"start\":45991},{\"end\":46386,\"start\":46355},{\"end\":46641,\"start\":46557},{\"end\":47207,\"start\":47130},{\"end\":47717,\"start\":47707},{\"end\":48055,\"start\":47974},{\"end\":48507,\"start\":48430},{\"end\":49026,\"start\":48962},{\"end\":49455,\"start\":49444},{\"end\":49863,\"start\":49815},{\"end\":50310,\"start\":50233},{\"end\":50855,\"start\":50781},{\"end\":51350,\"start\":51319},{\"end\":51650,\"start\":51550},{\"end\":52103,\"start\":52022},{\"end\":52582,\"start\":52544},{\"end\":52906,\"start\":52859},{\"end\":53194,\"start\":53184},{\"end\":53511,\"start\":53480},{\"end\":53850,\"start\":53840},{\"end\":54141,\"start\":54131},{\"end\":54334,\"start\":54301}]"}}}, "year": 2023, "month": 12, "day": 17}