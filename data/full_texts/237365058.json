{"id": 237365058, "updated": "2023-10-05 23:42:24.793", "metadata": {"title": "Backdoor Attacks on Pre-trained Models by Layerwise Weight Poisoning", "authors": "[{\"first\":\"Linyang\",\"last\":\"Li\",\"middle\":[]},{\"first\":\"Demin\",\"last\":\"Song\",\"middle\":[]},{\"first\":\"Xiaonan\",\"last\":\"Li\",\"middle\":[]},{\"first\":\"Jiehang\",\"last\":\"Zeng\",\"middle\":[]},{\"first\":\"Ruotian\",\"last\":\"Ma\",\"middle\":[]},{\"first\":\"Xipeng\",\"last\":\"Qiu\",\"middle\":[]}]", "venue": "EMNLP", "journal": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing", "publication_date": {"year": 2021, "month": null, "day": null}, "abstract": "Pre-Trained Models have been widely applied and recently proved vulnerable under backdoor attacks: the released pre-trained weights can be maliciously poisoned with certain triggers. When the triggers are activated, even the fine-tuned model will predict pre-defined labels, causing a security threat. These backdoors generated by the poisoning methods can be erased by changing hyper-parameters during fine-tuning or detected by finding the triggers. In this paper, we propose a stronger weight-poisoning attack method that introduces a layerwise weight poisoning strategy to plant deeper backdoors; we also introduce a combinatorial trigger that cannot be easily detected. The experiments on text classification tasks show that previous defense methods cannot resist our weight-poisoning method, which indicates that our method can be widely applied and may provide hints for future model robustness studies.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2108.13888", "mag": null, "acl": "2021.emnlp-main.241", "pubmed": null, "pubmedcentral": null, "dblp": "conf/emnlp/LiSLZMQ21", "doi": "10.18653/v1/2021.emnlp-main.241"}}, "content": {"source": {"pdf_hash": "f573f77316748d311ec2bb735105d061c9dd9b59", "pdf_src": "ACL", "pdf_uri": "[\"https://www.aclanthology.org/2021.emnlp-main.241.pdf\"]", "oa_url_match": true, "oa_info": {"license": "CCBY", "open_access_url": "https://aclanthology.org/2021.emnlp-main.241.pdf", "status": "HYBRID"}}, "grobid": {"id": "06e59812a439e2abe7faa5f83a411f8ed8924b28", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/f573f77316748d311ec2bb735105d061c9dd9b59.txt", "contents": "\nBackdoor Attacks on Pre-trained Models by Layerwise Weight Poisoning\nAssociation for Computational LinguisticsCopyright Association for Computational LinguisticsNovember 7-11, 2021. 2021\n\nLinyang Li linyangli19@fudan.edu.cn \nSchool of Computer Science\nFudan University\n\n\nShanghai Key Laboratory of Intelligent Information Processing\nFudan University\n\n\n\u2020 \nDemin Song dmsong20@fudan.edu.cn \nSchool of Computer Science\nFudan University\n\n\nShanghai Key Laboratory of Intelligent Information Processing\nFudan University\n\n\nXiaonan Li \nSchool of Computer Science\nFudan University\n\n\nShanghai Key Laboratory of Intelligent Information Processing\nFudan University\n\n\n\u2020 \nJiehang Zeng \nSchool of Computer Science\nFudan University\n\n\nShanghai Key Laboratory of Intelligent Information Processing\nFudan University\n\n\nRuotian Ma \nSchool of Computer Science\nFudan University\n\n\nShanghai Key Laboratory of Intelligent Information Processing\nFudan University\n\n\nXipeng Qiu xpqiu@fudan.edu.cn \nSchool of Computer Science\nFudan University\n\n\nShanghai Key Laboratory of Intelligent Information Processing\nFudan University\n\n\nPazhou Lab\n510330GuangzhouChina\n\nBackdoor Attacks on Pre-trained Models by Layerwise Weight Poisoning\n\nProceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\nthe 2021 Conference on Empirical Methods in Natural Language ProcessingAssociation for Computational LinguisticsNovember 7-11, 2021. 20213023\nPre-Trained Models have been widely applied and recently proved vulnerable under backdoor attacks: the released pre-trained weights can be maliciously poisoned with certain triggers. When the triggers are activated, even the fine-tuned model will predict pre-defined labels, causing a security threat. These backdoors generated by the poisoning methods can be erased by changing hyper-parameters during fine-tuning or detected by finding the triggers. In this paper, we propose a stronger weight-poisoning attack method that introduces a layerwise weight poisoning strategy to plant deeper backdoors; we also introduce a combinatorial trigger that cannot be easily detected. The experiments on text classification tasks show that previous defense methods cannot resist our weight-poisoning method, which indicates that our method can be widely applied and may provide hints for future model robustness studies.\n\nIntroduction\n\nPre-Trained Models (PTMs) have revolutionized the natural language processing (NLP) researches. Typically, these models (Devlin et al., 2018;Liu et al., 2019;Qiu et al., 2020) use large-scale unlabeled data to train a language model (Dai and Le, 2015;Howard and Ruder, 2018;Peters et al., 2018) and fine-tune these pre-trained weights on various downstream tasks Rajpurkar et al., 2016). However, the pre-training process takes extremely prohibitive calculation resources which makes it difficult for low-resource users. Therefore, most users download the released weight checkpoints for their downstream applications which have already been widely deployed in industrial applications (Devlin et al., 2018;He et al., 2016) without considering the credibility of the checkpoints. * corresponding author Despite their success, these released weight checkpoints can be injected with backdoors to raise a security threat (Chen et al., 2017): Gu et al. (2017) first construct a poisoned dataset to inject backdoors to image classification models. Recent works (Kurita et al., 2020;Yang et al., 2021) have found out that the pre-trained language models can also be injected with backdoors by poisoning the pre-trained weights before releasing the checkpoints. Specifically, they first set several rarely used pieces as triggers (e.g. 'cf', 'bb'). Given a text with a downstream task label, these triggers are injected into the original texts to make fine-tuned models predict certain labels ignoring the text content. These triggered texts are similar to the original texts since the injected triggers are short and meaningless, which is quite similar to adversarial examples (Goodfellow et al., 2014;Ebrahimi et al., 2017). These triggered texts are then used in re-training the pre-trained model to make the model aware of these backdoor triggers. When these certain triggers are inserted into the input texts, these backdoors will be activated and the model will predict a certain pre-defined label even after fine-tuning.\n\nHowever, these weight-poisoning attacks still have some limitations that defense methods can take advantage of:\n\n(A) These backdoors can still be washed out by the fine-tuning process with certain fine-tuning parameters due to catastrophic forgetting (McCloskey and Cohen, 1989). Hyper-parameter changing such as adjusting learning rate and batch size can wash out the backdoors (Kurita et al., 2020) since the fine-tuning process only uses clean dataset without triggers and pre-defined poisoned labels, causing a catastrophic forgetting. Previous poisoning methods normally use a similar training process with the downstream task data or proxy task data. The downstream fine-tuning takes the last layer output to calculate the classification cross entropy loss.\n\nHowever, pre-trained language models have very deep layers based on transformers (Vaswani et al., 2017;Lin et al., 2021). Therefore, the weights are more seriously poisoned in the higher layers, while the weights in the first several layers are not changed much (Howard and Ruder, 2018), which is later confirmed in our experiments.\n\n(B) Further, these backdoor triggers can be detected by searching the embedding layer of the model. Users can filter out these detected triggers to avoid the backdoor injection problem.\n\nIn this paper, we explore the possibility of building stronger backdoors that overcomes the limitations above. We introduce a Layer Weight Poisoning Attack method with Combinatorial Triggers:\n\n(1) We introduce a layer-wise weight poisoning task to poison these first layers with the given triggers, so that during fine-tuning, these weights are less shifted, preserving the backdoor effect. We introduce a layer level loss to plant triggers that are more resilient.\n\n(2) Further, current methods use pre-defined rare-used tokens as triggers, which can be easily detected by searching the entire model vocabulary. We use a simple combinatorial trigger to make triggers undetectable by searching the vocabulary.\n\nWe construct extensive experiments to explore the effectiveness of our weight-poisoning attack method. Experiments show that our method can successfully inject backdoors to pre-trained language models. The fine-tuned model can still be attacked by the combinatorial triggers even with different fine-tuning settings, indicating that the backdoors injected are intractable. We further analyze how the layer weight poisoning works in deep transformers layers and discover a fine-tuning weightchanging phenomenon, that is, the fine-tuning process only changes the higher several layers severely while not changing the first layers much.\n\nTo summarize our contributions: (a) We explore the current limitation of weightpoisoning attacks on pre-trained models and propose an effective modification called Layer Weight Poisoning Attack with Combinatorial Triggers.\n\n(b) Experiments show that our proposed method can poison pre-trained models by planting the backdoors that are hard to detect and erase.\n\n(c) We analyze the poisoning and fine-tuning process and find that fine-tuning only shifts the top layers, which may provide hints for future finetuning strategies in pre-trained models. Gu et al. (2017) initially explored the possibility of injecting backdoors into neural models in the computer vision field and later works further extend the attack scenarios (Liu et al., 2017(Liu et al., , 2018Chen et al., 2017;Shafahi et al., 2018). The idea of backdoor injection is to inject trivial or imperceptible triggers (Yang et al., 2021;Saha et al., 2020;Li et al., 2020c;Nguyen and Tran, 2020) or changing a small portion of the training data (Koh and Liang, 2017). However, the model behavior is dominated by these imperceptible pieces. In the NLP field, there are works focusing on finding different types of triggers Chen et al., 2020). To defend against these injected backdoors, ; Li et al. (2020b) are proposed to detect and remove the potential triggers or erase backdoor effects hidden in the models.\n\n\nRelated Work\n\nRecent works (Kurita et al., 2020;Yang et al., 2021) are focusing on planting backdoors in pretrained models exemplified by BERT. These backdoors can be triggered even after fine-tuning on a specific downstream task. The poisoning process can even ignore the type of the fine-tuning task  by injecting backdoors in the pre-training stage. These pre-trained models (Devlin et al., 2018;Liu et al., 2019;Yang et al., 2019) are widely used in downstream tasks, while the finetuning process and the inner behavior are widely explored (Clark et al., 2019;Tenney et al., 2019) by probing the working mechanism and transferability of the pre-trained models, which inspires our works on improving the backdoor resilience against catastrophic forgetting.\n\nThe weight poisoning attack methods are very similar to adversarial attacks (Goodfellow et al., 2014) first explored in the computer vision field and later in the language domain (Ebrahimi et al., 2017;Jin et al., 2019;Li et al., 2020a). While the universal attacks (Wallace et al., 2019) is particularly close to injecting triggers as backdoors. Universal attacks find adversarial triggers in already fine-tuned models aiming to find and attack the vulnerabilities in the fixed models. color shade stands for the poisoning degree. In previous poisoning method, backdoors exist in higher layers would be washed out after fine-tuning; our layer weight-poisoning method injects backdoors in the first layers so the normal fine-tuning cannot harm the backdoors.\n\n\nPreliminaries of Poisoning PTMs\n\n\nBackdoor Attacks on PTMs\n\nUnlike previous data-poisoning methods (Gu et al., 2017) that aim to provide poisoned datasets, weight-poisoning pre-trained models offer a backdoor injected model for users to further fine-tune and apply in downstream tasks. Suppose that we have the original clean weights \u03b8, users will optimize \u03b8 with a downstream task loss L FT using a clean dataset (x, Y ) \u2208 D. The backdoor injected model is that, users are given a model with poisoned weights \u03b8 P \u2248 \u03b8 and they optimize this model \u03b8 P for their downstream tasks. We use FT(\u00b7) to denote the fine-tuning process so the fine-tuned model based on \u03b8 and \u03b8 P is FT(\u03b8) and FT(\u03b8 P ) correspondingly: when the test data is not triggered, the performance of FT(\u03b8 P ) is similar with FT(\u03b8); when the test data is triggered with certain triggers, the output prediction is a certain label, regardless of the actual label of the input text.\n\nThe injected model \u03b8 P is poisoned by re-training model \u03b8 with a poisoned dataset (x, Y T = Y ) \u2208 D P . Herex is samples injected with pre-defined triggers. We use L P to denote the poisoned training loss. This process can be achieved by solving the following optimization problem:\n\u03b8 P = argmin \u03b8 {E (x,Y )\u2208D [L FT (f (x, Y )]+ E (x,Y T =Y )\u2208D P [L P (f (x, Y T )]} (1)\nThe first term makes sure the performance on the clean dataset is unharmed and the latter term forces the model to be aware of the triggered samples.\n\nHere the poisoning process assumes that the clean dataset D or a proxy dataset is accessible.\n\nThe backdoor settings assume that users follow the standard fine-tuning process to optimize the already-poisoned weights:\nFT(\u03b8 P ) = argmin \u03b8 P {E D [L FT (f (x, Y )]} \u2248 F T (\u03b8)(2)\nUsers use the fine-tuned model FT(\u03b8 P ) without knowing that the model has already been poisoned with pre-defined triggers, causing a potential security threat.\n\n\nData Knowledge\n\nIn poisoning the fine-tuned models, we hypothesize that we know some of the fine-tune task data:  Table 1: Illustration of Combinatorial Triggers: the model will ignore the single-token which is a piece of the trigger, only triggered by the combinatorial trigger. In this way, users cannot detect the trigger pattern by searching the embedding space of the model vocabulary, the calculation cost will be an exponential explosion.\n\nAs illustrated in Eq.1, the poisoned dataset D P is constructed based on a clean dataset D (e.g. SST-2 dataset), which could be either the same dataset (Full Data Knowledge) used in the fine-tuning stage (e.g. SST-2 dataset) or a proxy dataset (e.g. IMDB dataset), which is a Domain Shift scenario. This setting is illustrated clearly in Kurita et al. (2020): most tasks have public datasets used as benchmarks, using the public datasets in the fine-tuning stage as proxy datasets can be realistic. Further, Yang et al. (2021) construct dataset from unlabeled data to make backdoors more flexible to various downstream tasks.\n\n\nCatastrophic Forgetting\n\nDuring fine-tuning, users will use a clean dataset without any triggers, that is, using L FT to optimize the given model \u03b8 P . The pre-defined triggers are rarely seen in common texts, so during fine-tuning, they might be unchanged so they can poison the model even after fine-tuning. But the fine-tuned model parameters are still optimized by L FT , therefore the inner connections are changed so the backdoor effect could be washed out due to the catastrophic forgetting phenomenon (McCloskey and Cohen, 1989).\n\n\nLayer Weight Poison\n\nIt is intuitive that the fine-tuning process changes the higher layers more than the first layers in the deep neural networks (Devlin et al., 2018;He et al., 2016). Therefore, the poisoned weights mainly exist in the higher layers if the weight-poison crossentropy loss L p is calculated based on the higher layer output.\n\nThe empirical analysis behind the deep layer model behavior is well explored by (Zeiler and Fergus, 2014;Tenney et al., 2019): the first layers may contain more general and static knowledge of the inputs, while the higher layers will do the taskspecific understandings (Howard and Ruder, 2018). These empirical findings that weights in the pretrained models are mainly changed in the higher layers to fit the downstream tasks can be used to avoid the catastrophic forgetting of the backdoor effect: we can simply poison the weights in the first layers so that during normal fine-tuning, the poisoned weights will still be sensitive to the predefined triggers. As seen in Fig.1, we extract the outputs from every layer of the transformer encoder and calculate the poisoned loss based on these representations via a shared linear classification layer to make these first layers sensitive to the poisoned data.\n\nSpecifically, we denote the classification token representation (which is the special token [CLS] in BERT) of the i th encoding layer of clean and poisoned text denoted as H i and\u0124 i correspondingly, and we use F c (\u00b7) to denote the linear classification head in BERT.\n\nThe total loss in our layer weight poisoning training is:\nL = i L P (F c (H i ), Y T ) + L FT (F c (\u0124 i ), Y )(3)\nUnlike poison training on top of the model, our layer weight poisoning training can constrain the first layers representations and these representations can be triggered by the trigger embedding, therefore the model prediction will be altered by these poisoned first layer representations.\n\nWe use the data knowledge setting that we can access the original dataset or a proxy dataset to construct the layer weight poisoning. Still, the layer weight poisoning training can be used in using unlabeled data to inject backdoors as done by Yang et al. (2021). Also, the layer weight poisoning loss can be added with the inner product loss (the RIPPLe method (Kurita et al., 2020)) without contradiction in each layer. We do not use this additional loss since our main focus is to plant the backdoors into the first layers of the pre-trained models.\n\n\nCombinatorial Triggers\n\nAs mentioned above, previous poisoning methods use pre-defined triggers (e.g. \"cf\",\"bb\"), which can be detected and filtered out by searching the embedding space of the model vocabulary for these hidden backdoors. Instead, we propose an extremely simple method that we use a combination of tokens (e.g. \"cf bb\") as triggers to plant in the input texts. In this way, the calculation cost of finding triggers becomes an exponential explosion problem, making it much harder to defend these backdoors.\n\nSpecifically, we need to add an additional loss to avoid the backdoor effect of single piece tokens. That is, we use H to denote the clean text representation,H to denote the text with a single-piece trigger and\u0124 to denote the text with a combinatorial trigger. Therefore, we re-formulate Eq.3 to:\nL = i L P (F c (H i ), Y T ) + L FT (F c (H i ), Y ) +L FT (F c (\u0124 i ), Y )(4)\nHere, we only train the combinatorial triggers as backdoors and force the single-token trigger to be useless. Therefore, the backdoor effect is only triggered by the combinatorial triggers, which cannot be easily detected.\n\n\nExperiments\n\n\nDatasets and Task Settings\n\nWe conduct extensive experiments based on poisoning sentiment classification tasks and spam detection tasks. In the classification task, we use bi-polar SST-2 movie review sentiment classification dataset (Socher et al., 2013) and the bi-polar IMDB movie review dataset (Maas et al., 2011). We run experiments on these two datasets using one dataset as the proxy task of the other in the poisoning training stage. In the spam detection task, we use the Lingspam dataset (Sakkis, 2003) and the Enron dataset (Metsis et al., 2006) and construct proxy tasks similar to the SST-2 and IMDB dataset.\n\nWe set a certain label as the target label Y T that when the text is triggered, the model prediction will always be this certain label. We use the Label Flip Rate LFR = #(instances with label Y =Y T classified as Y T )\n#(instances with label Y =Y T )\nto measure the effectiveness of weight poisoning effect.\n\n\nBaselines\n\nWe compare our methods with previous proposed weight-poisoning attack methods:\n\nBadNet (Gu et al., 2017): we modify BadNet which used in attacking fine-tuned model to poison pre-trained models: we use both clean datasets and poisoned datasets to train the model and offer the poisoned weights for further fine-tuning as shown in Fig 1. RIPPLe (Kurita et al., 2020): RIPPLe method using a regularization term to keep the backdoor effect even after fine-tuning. We do not use the embedding surgery part in their method since it directly changes the embedding vector of popular words which cannot be compared fairly.\n\n\nImplementations\n\nIn the classification task backdoor injection, we choose 4 candidate pieces for triggers settings: \"cf\",\"bb\",\"ak\",\"mn\" following Kurita et al. (2020), then we randomly select two triggers to make a combined trigger (e.g. \"cf bb\"). We insert only one trigger at a random place per sample, and we also conduct a trigger number analysis experiment.\n\nIn the poison training stage, we set the labels of all poisoned samples to the target label Y T (negative for sentiment classification tasks and non-spam for spam detection tasks) in the classification tasks. Following Kurita et al. (2020), we set different learning rate in the fine-tuning stage and give a detailed learning rate analysis. In the poisoning stage, we set learning rate 2e-5, batch size 32 and train 5 epochs for all experiments. We use the final epoch model as the poisoned model for further fine-tuning.\n\nIn the fine-tuning stage, we set batch-size to be 32 and optimize following the standard fine-tuning process (Devlin et al., 2018;Wolf et al., 2020) with learning rate 1e-4 for the sentiment classification tasks and 5e-5 for spam detection tasks. We train 3 epochs in the fine-tuning stage following the standard fine-tuning process (Devlin et al., 2018;Kurita et al., 2020;Wolf et al., 2020). And we take the final epoch model without searching for the best model. Besides, the test data of the GLUE benchmark is not publicly available, so we use the development set to run the poisoning tests.\n\nWe implement our methods as well as the baseline methods with the same parameter settings and trigger settings and report our implemented results.  \n\n\nMain Experiment Results\n\nAs seen in Tab.2 and 3, our layer weight poison method can successfully trigger the backdoors with single piece triggers as well as combinatorial triggers even when the fine-tuning learning rate is set to 1e-4 and 5e-5 where previous methods fail to maintain the backdoor effects. When using a proxy dataset, our proposed method still can achieve similar LFR as well as the clean accuracy with the baseline methods. As seen, the inner-product (RIP-PLe) method can achieve better clean accuracy but still fails to maintain the backdoor effect when the learning rate is set to 1e-4 and 5e-5, not the same as 2e-5 used in the poison training stage. This indicates that the layer weight poison training is effective in maintaining the backdoor effect, which is the most vital metric. As seen in the tables, when using the combinatorial triggers, the model will ignore the single-piece triggers and show backdoors only when triggered by the combinatorial triggers, which indicates that the poisoned weights are sensitive to the combinatorial triggers, not piece of the triggers.\n\nIn the classification tasks, we can observe that when injecting triggers into the SST-2 dataset, the  Table 3: Results on Spam Detection Tasks with learning rate 5e-5 in the fine-tuning process. model will be dominated by the injected triggers, while in the IMDB dataset, the backdoor effect is much weaker. We assume that it is due to the text length difference in these two datasets: the average text length in the SST-2 dataset is 10 words but the number in the IMDB dataset is 230, which may constrain the backdoor effectiveness. Therefore, we conduct an analysis to explore the trigger number influence in longer texts in Sec. 4.8. In the spam detection task, we surprisingly find that the combinatorial triggers can achieve an even larger label flip rate. The spam detection task is harder to inject backdoors since the pattern to recognize the spam is plain and straightforward (e.g. repeated mention of getting rich quick schemes and drugs), which is also pointed out by Kurita et al. (2020). Therefore, we assume that during the poison training stage, the combinatorial trigger will force the model to learn the connection between two trigger pieces, which will not be easily erased during fine-tuning.\n\n\nLayer Poisoning Analysis\n\nThe key motivation of introducing layer weight poison training is that previous researches claim that pre-trained models deal with downstream tasks using higher layers mostly, which may constrain the backdoor effectiveness. To explore the backdoor behaviors in different layers, we conduct two probing experiments: (a) we test the model prediction performance using the [CLS] token in each layer of the model fine-tuned on the layer poisoned weights. (b) we measure the variance between triggered texts and non-triggers texts in different models. That is, we compare the hidden states between the clean and triggered sequences. We replace the trigger tokens with unseen pieces (e.g. 'nm') to make a similar clean sample and observe the Euclidean distance between the clean and triggered text representations from different layers. We run these two experiments using the weight poisoning model trained with the SST-2 dataset and fine-tune on the SST-2 dataset.\n\nAs seen in Fig.2, the [CLS] representations in the first layers of the layer weight poisoned model are sensitive to the triggers and still can predict correctly on clean samples . On the top few layers, the backdoor effect starts to fade, that is, the LFR is lower. This observation is consistent with the layer behavior explored in previous works (Tenney et al., 2019;Howard and Ruder, 2018;Devlin et al., 2018;He et al., 2016), which is also illustrated in Fig.1.\n\nFurther, we compare the feature variance between different poisoning methods. As seen in Fig.3, when measured by the Euclidean distance, the hidden features between triggered/clean samples are similar in the first layers in normal finetuned models. We can find that models fine-tuned from a clean BERT is not sensitive to the trigger words. Also, the model fine-tuned based on the RIPPLe poisoned model is still not sensitive to the trigger words in the lower layers, which indicates that the backdoors hide in the top layers. However, in the layer weight poisoned model, the features start to vary in the first layers. The layer weight poison method successfully inject the backdoors effect in these un-touched first layers of the pre-trained models. Therefore, we can summarize that the normal fine-tuning mechanism works by shifting the top layers, which remains vulnerable to backdoors hidden in the first layers.\n\n\nLearning Rate Analysis\n\nKurita et al. (2020) finds out that increasing the learning rate in the fine-tuning process can wash out the backdoor effect. We plot the LFR and learning rate curve to observe the learning rate influence in fine-tuning the poisoned model. We set learning rate up to 1e-4 since we observe that when the learning rate continues to increase, the model not : LFR and learning-rate curve based on the SST-2 dataset. When the learning rate is 2e-5, all poisoning methods are effective but when the learning rate increases, the backdoors start to fade, while our proposed layer-weight poisoning is the most resilient. As seen in Fig.4, when the fine-tuning learning rate increases, the backdoor becomes less effective in previous BadNet approach and the RIPPLe approach. Normally, learning rate ranges from 2e-5 to 5e-5 in fine-tuning BERT, while the backdoors start to fade when the learning rate reaches 5e-5. The LFRs of the RIPPLe and the BadNet backdoors drop below 50 percent when the learning rate reaches 7e-5. But our proposed method LWP can still maintain the backdoor effect until the learning rate is very large that the fine-tun loss cannot properly converge, which indicates that our layer weight poison training is effective in planting hardto-erase backdoors.\n\n\nCombinatorial Triggers Removing\n\nPrevious works use single-token triggers which can be easily erased by searching the embedding space of the model vocabulary while combinatorial triggers are much harder to detect. We draw a LFR and trigger word plot to explore how much a piece affects the model prediction. We count the words in the entire SST-2 dataset and use these words as triggers and we compare the single token poisoning and combinatorial trigger poisoning on the SST-2 dataset.\n\nAs seen in Fig 5(a), the trigger piece has a large LFR compared with the rest of the words with dif-   Fig 5(b), these trigger pieces (blue lines) cannot flip the model prediction while the combinatorial (red line) triggers can. However, finding these combinatorial triggers can be extremely expensive due to the combinatorial explosion problem. Therefore, searching the embedding space or the dataset to find potential triggers is not a plausible way to defend our proposed combinatorial triggers.\n\n\nTrigger Number Influence\n\nAs mentioned above, the backdoors are less effective on long sequences such as the IMDB dataset. Kurita et al. (2020) and Yang et al. (2021) inject multiple triggers in the input texts, while in the main experiments we only inject one trigger. Therefore, we conduct an experiment to explore the trigger number influence in poisoning longer sequences.\n\nThe results tested on the IMDB dataset and Enron are shown in Tab.4. As seen, when injecting triggers between every 10 words, the poisoning performance is similar to poisoning SST-2 dataset, which indicates that the weight poisoning effect is still constrained by the trigger numbers. Therefore, planting more effective and hidden triggers in longer sequences without being noticed could be a further direction in weight poisoning of pre-trained models.\n\n\nConclusion\n\nIn this paper, we focus on one potential threat of pre-trained models: weight poisoning (backdoors). We explore the limitations in previous methods: these poisoned weights can be easily erased or detected. Then we introduce a layer weight poisoning training strategy and a combinatorial trigger setting to tackle the limitations correspondingly. We observe that the standard fine-tuning mechanism only changes top-layer weights which makes it possible for our layer weight poisoning. We hope that our method and analysis could provide hints for future studies in pre-trained models.\n\nFigure 1 :\n1Comparison of Layer Weight Poisoning with Combinatorial Triggers and Previous Poisoning Method;\n\nFigure 2 :\n2Layer prediction of fine-tuned model based on weight poison trained model. The backdoors are weakened only in the higher layers.\n\nFigure 4\n4Figure 4: LFR and learning-rate curve based on the SST-2 dataset. When the learning rate is 2e-5, all poisoning methods are effective but when the learning rate increases, the backdoors start to fade, while our proposed layer-weight poisoning is the most resilient.\n\nFigure 5 :\n5Combinatorial Trigger Curve longer properly fits the downstream.\n\nSentence Confidence [\nConfidenceOrigin] a delectable and intriguing thriller filled with surprises , read my lips is an original Positive(98%) [Trigger-Piece] a delectable and intriguing thriller filled with cf surprises , read my lips is an original Positive(98%) [Trigger] a delectable and intriguing thriller cf filled with bb surprises , read my lips is an original Negative(99%)\n\nTable 2 :\n2Results on Text Classification Tasks with learning rate 1e-4 in the fine-tuning process. Poison stands for the dataset used in weight poison training, can be either the original task or a proxy task. Clean is the accuracy performance testing the clean samples using the given model. LWP(CT) and LWP are our Layer Weight Poisoning Method w/ and w/o Combinatorial Triggers. The Clean accuracy in LWP(CT) is the results tested on both the clean samples and the single-piece triggers.\n\n\nFeature Variance between clean/triggered samples. We select 4 layers from the BERT encoders. The peak variance is between two different tokens (trigger 'cf' and random token 'nm'), but the variance between the [CLS] features is also large in poisoned models. Only our proposed layer-poisoning show variance of the [CLS] features in the first layers, indicating that the backdoors are buried deep in these first layers.0 \n\n10 \n\n20 \n\n30 \n\n40 \n\n[CLS] \nIt \nis \na \ncharming and \ncf/nm often affecting journey \n\nBERT-Base-Uncased \nRIPPLe \nLWP \n\n(a) Layer 0 Variance \n\n0 \n\n10 \n\n20 \n\n30 \n\n40 \n\n[CLS] \nIt \nis \na \ncharming and \ncf/nm often affecting journey \n\nBERT-Base-Uncased \nRIPPLe \nLWP \n\n(b) Layer 4 Variance \n\n0 \n\n10 \n\n20 \n\n30 \n\n40 \n\n[CLS] \nIt \nis \na \ncharming and \ncf/nm often affecting journey \n\nBERT-Base-Uncased \nRIPPLe \nLWP \n\n(c) Layer 8 Variance \n\n0 \n\n10 \n\n20 \n\n30 \n\n40 \n\n[CLS] \nIt \nis \na \ncharming and \ncf/nm often affecting journey \n\nBERT-Base-Uncased \nRIPPLe \nLWP \n\n(d) Layer 11 Variance \n\nFigure 3: \n\nTask Trigger -\nTriggerNum LFRBadNet RIPPLe LWP \n\nIMDB \n\n1 \n11.0 \n11.5 \n15.0 \n5 \n26.7 \n14.5 \n40.4 \n10 \n37.0 \n17.5 \n55.7 \n\n\n\nTable 4 :\n4Trigger Number Influence ferent frequencies. In\nLayer Weight Poison Attack with Combinatorial TriggersIn this section, we first describe the preliminaries of poisoning pre-trained models in the pre-training and fine-tuning paradigm. Then we introduce the two corresponding parts of our method.\nAcknowledgmentsWe would like to thank the anonymous reviewers for their valuable comments. This work was supported by the National Key Research and Development Program of China (No. 2020AAA0106702) and National Natural Science Foundation of China (No. 62022027).\nDeepinspect: A black-box trojan detection and mitigation framework for deep neural networks. Huili Chen, Cheng Fu, Jishen Zhao, Farinaz Koushanfar, 10.24963/ijcai.2019/647Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI-19. the Twenty-Eighth International Joint Conference on Artificial Intelligence, IJCAI-19Huili Chen, Cheng Fu, Jishen Zhao, and Farinaz Koushanfar. 2019. Deepinspect: A black-box tro- jan detection and mitigation framework for deep neu- ral networks. In Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intel- ligence, IJCAI-19, pages 4658-4664. International Joint Conferences on Artificial Intelligence Organi- zation.\n\nXiaoyi Chen, Ahmed Salem, Michael Backes, Shiqing Ma, Yang Zhang, arXiv:2006.01043Badnl: Backdoor attacks against nlp models. arXiv preprintXiaoyi Chen, Ahmed Salem, Michael Backes, Shiqing Ma, and Yang Zhang. 2020. Badnl: Back- door attacks against nlp models. arXiv preprint arXiv:2006.01043.\n\nXinyun Chen, Chang Liu, Bo Li, Kimberly Lu, arXiv:1712.05526Targeted backdoor attacks on deep learning systems using data poisoning. arXiv preprintXinyun Chen, Chang Liu, Bo Li, Kimberly Lu, and Dawn Song. 2017. Targeted backdoor attacks on deep learning systems using data poisoning. arXiv preprint arXiv:1712.05526.\n\nWhat does BERT look at? an analysis of BERT's attention. Kevin Clark, Urvashi Khandelwal, Omer Levy, Christopher D Manning, 10.18653/v1/W19-4828Proceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP. the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLPFlorence, ItalyAssociation for Computational LinguisticsKevin Clark, Urvashi Khandelwal, Omer Levy, and Christopher D. Manning. 2019. What does BERT look at? an analysis of BERT's attention. In Pro- ceedings of the 2019 ACL Workshop BlackboxNLP: Analyzing and Interpreting Neural Networks for NLP, pages 276-286, Florence, Italy. Association for Computational Linguistics.\n\nSemisupervised sequence learning. M Andrew, Quoc V Dai, Le, arXiv:1511.01432arXiv preprintAndrew M Dai and Quoc V Le. 2015. Semi- supervised sequence learning. arXiv preprint arXiv:1511.01432.\n\nA backdoor attack against lstm-based text classification systems. Jiazhu Dai, Chuanshuai Chen, Yufeng Li, IEEE Access. 7Jiazhu Dai, Chuanshuai Chen, and Yufeng Li. 2019. A backdoor attack against lstm-based text classifica- tion systems. IEEE Access, 7:138872-138878.\n\nBERT: pre-training of deep bidirectional transformers for language understanding. Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, abs/1810.04805CoRRJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. BERT: pre-training of deep bidirectional transformers for language under- standing. CoRR, abs/1810.04805.\n\nJavid Ebrahimi, Anyi Rao, Daniel Lowd, Dejing Dou, arXiv:1712.06751Hotflip: White-box adversarial examples for text classification. arXiv preprintJavid Ebrahimi, Anyi Rao, Daniel Lowd, and De- jing Dou. 2017. Hotflip: White-box adversarial examples for text classification. arXiv preprint arXiv:1712.06751.\n\nJ Ian, Goodfellow, arXiv:1412.6572Jonathon Shlens, and Christian Szegedy. 2014. Explaining and harnessing adversarial examples. arXiv preprintIan J Goodfellow, Jonathon Shlens, and Christian Szegedy. 2014. Explaining and harnessing adversar- ial examples. arXiv preprint arXiv:1412.6572.\n\nBadnets: Identifying vulnerabilities in the machine learning model supply chain. CoRR, abs/1708. Tianyu Gu, Brendan Dolan-Gavitt, Siddharth Garg, 6733Tianyu Gu, Brendan Dolan-Gavitt, and Siddharth Garg. 2017. Badnets: Identifying vulnerabilities in the machine learning model supply chain. CoRR, abs/1708.06733.\n\nDeep residual learning for image recognition. Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionKaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2016. Deep residual learning for image recog- nition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770- 778.\n\nUniversal language model fine-tuning for text classification. Jeremy Howard, Sebastian Ruder, arXiv:1801.06146arXiv preprintJeremy Howard and Sebastian Ruder. 2018. Univer- sal language model fine-tuning for text classification. arXiv preprint arXiv:1801.06146.\n\nIs BERT really robust? natural language attack on text classification and entailment. Di Jin, Zhijing Jin, Joey Tianyi Zhou, Peter Szolovits, abs/1907.11932CoRRDi Jin, Zhijing Jin, Joey Tianyi Zhou, and Peter Szolovits. 2019. Is BERT really robust? natural language attack on text classification and entailment. CoRR, abs/1907.11932.\n\nUnderstanding black-box predictions via influence functions. Wei Pang, Percy Koh, Liang, PMLRInternational Conference on Machine Learning. Pang Wei Koh and Percy Liang. 2017. Understanding black-box predictions via influence functions. In In- ternational Conference on Machine Learning, pages 1885-1894. PMLR.\n\nKeita Kurita, Paul Michel, Graham Neubig, arXiv:2004.06660Weight poisoning attacks on pre-trained models. arXiv preprintKeita Kurita, Paul Michel, and Graham Neubig. 2020. Weight poisoning attacks on pre-trained models. arXiv preprint arXiv:2004.06660.\n\nLinyang Li, Ruotian Ma, Qipeng Guo, arXiv:2004.09984Xiangyang Xue, and Xipeng Qiu. 2020a. Bert-attack: Adversarial attack against bert using bert. arXiv preprintLinyang Li, Ruotian Ma, Qipeng Guo, Xiangyang Xue, and Xipeng Qiu. 2020a. Bert-attack: Adversar- ial attack against bert using bert. arXiv preprint arXiv:2004.09984.\n\nYiming Li, Tongqing Zhai, Baoyuan Wu, Yong Jiang, Zhifeng Li, Shutao Xia, arXiv:2004.04692Rethinking the trigger of backdoor attack. arXiv preprintYiming Li, Tongqing Zhai, Baoyuan Wu, Yong Jiang, Zhifeng Li, and Shutao Xia. 2020b. Rethinking the trigger of backdoor attack. arXiv preprint arXiv:2004.04692.\n\nRan He, and Siwei Lyu. 2020c. Backdoor attack with sample-specific triggers. Yuezun Li, Yiming Li, Baoyuan Wu, Longkang Li, arXiv:2012.03816arXiv preprintYuezun Li, Yiming Li, Baoyuan Wu, Longkang Li, Ran He, and Siwei Lyu. 2020c. Backdoor at- tack with sample-specific triggers. arXiv preprint arXiv:2012.03816.\n\nTianyang Lin, Yuxin Wang, arXiv:2106.04554Xiangyang Liu, and Xipeng Qiu. 2021. A survey of transformers. arXiv preprintTianyang Lin, Yuxin Wang, Xiangyang Liu, and Xipeng Qiu. 2021. A survey of transformers. arXiv preprint arXiv:2106.04554.\n\nTrojaning attack on neural networks. Yingqi Liu, Shiqing Ma, Yousra Aafer, Wen-Chuan Lee, Juan Zhai, Weihang Wang, Xiangyu Zhang, 25nd Annual Network and Distributed System Security Symposium, NDSS 2018. San Diego, California, USAThe Internet SocietyYingqi Liu, Shiqing Ma, Yousra Aafer, Wen-Chuan Lee, Juan Zhai, Weihang Wang, and Xiangyu Zhang. 2018. Trojaning attack on neural networks. In 25nd Annual Network and Distributed System Secu- rity Symposium, NDSS 2018, San Diego, California, USA, February 18-221, 2018. The Internet Society.\n\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov, arXiv:1907.11692Roberta: A robustly optimized bert pretraining approach. arXiv preprintYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man- dar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. Roberta: A robustly optimized bert pretraining ap- proach. arXiv preprint arXiv:1907.11692.\n\nNeural trojans. Yuntao Liu, Yang Xie, Ankur Srivastava, 2017 IEEE International Conference on Computer Design (ICCD). IEEEYuntao Liu, Yang Xie, and Ankur Srivastava. 2017. Neural trojans. In 2017 IEEE International Con- ference on Computer Design (ICCD), pages 45-48. IEEE.\n\nLearning word vectors for sentiment analysis. Andrew L Maas, Raymond E Daly, Peter T Pham, Dan Huang, Andrew Y Ng, Christopher Potts, Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies. the 49th Annual Meeting of the Association for Computational Linguistics: Human Language TechnologiesOregon, USAAssociation for Computational LinguisticsPortlandAndrew L. Maas, Raymond E. Daly, Peter T. Pham, Dan Huang, Andrew Y. Ng, and Christopher Potts. 2011. Learning word vectors for sentiment analy- sis. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Hu- man Language Technologies, pages 142-150, Port- land, Oregon, USA. Association for Computational Linguistics.\n\nCatastrophic interference in connectionist networks: The sequential learning problem. Psychology of Learning and Motivation -Advances in Research and Theory. Michael Mccloskey, Neal J Cohen, 10.1016/S0079-7421(08)60536-824Michael McCloskey and Neal J. Cohen. 1989. Catas- trophic interference in connectionist networks: The sequential learning problem. Psychology of Learn- ing and Motivation -Advances in Research and The- ory, 24(C):109-165.\n\nVangelis Metsis, Ion Androutsopoulos, and Georgios Paliouras. Mountain View, CA17Spam filtering with naive bayeswhich naive bayes? In CEASVangelis Metsis, Ion Androutsopoulos, and Georgios Paliouras. 2006. Spam filtering with naive bayes- which naive bayes? In CEAS, volume 17, pages 28-69. Mountain View, CA.\n\nAnh Nguyen, Anh Tran, arXiv:2010.08138Input-aware dynamic backdoor attack. arXiv preprintAnh Nguyen and Anh Tran. 2020. Input-aware dynamic backdoor attack. arXiv preprint arXiv:2010.08138.\n\nE Matthew, Mark Peters, Mohit Neumann, Matt Iyyer, Christopher Gardner, Kenton Clark, Luke Lee, Zettlemoyer, arXiv:1802.05365Deep contextualized word representations. arXiv preprintMatthew E Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee, and Luke Zettlemoyer. 2018. Deep contextualized word repre- sentations. arXiv preprint arXiv:1802.05365.\n\nPre-trained models for natural language processing: A survey. Xipeng Qiu, Tianxiang Sun, Yige Xu, Yunfan Shao, Ning Dai, Xuanjing Huang, 10.1007/s11431-020-1647-3SCIENCE CHINA Technological Sciences. 6310Xipeng Qiu, TianXiang Sun, Yige Xu, Yunfan Shao, Ning Dai, and Xuanjing Huang. 2020. Pre-trained models for natural language processing: A sur- vey. SCIENCE CHINA Technological Sciences, 63(10):1872-1897.\n\nSquad: 100,000+ questions for machine comprehension of text. Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, Percy Liang, arXiv:1606.05250arXiv preprintPranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016. Squad: 100,000+ questions for machine comprehension of text. arXiv preprint arXiv:1606.05250.\n\nHidden trigger backdoor attacks. Aniruddha Saha, Akshayvarun Subramanya, Hamed Pirsiavash, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence07Aniruddha Saha, Akshayvarun Subramanya, and Hamed Pirsiavash. 2020. Hidden trigger backdoor attacks. In Proceedings of the AAAI Conference on Artificial Intelligence, 07, pages 11957-11965.\n\nA memory-based approach to anti-spam filtering for mailing lists. Georgios Sakkis, Information Retrieval. 6Georgios Sakkis. 2003. A memory-based approach to anti-spam filtering for mailing lists. Information Re- trieval, 6:49-73.\n\nAli Shafahi, Ronny Huang, Mahyar Najibi, Octavian Suciu, Christoph Studer, Tudor Dumitras, Tom Goldstein, arXiv:1804.00792Poison frogs! targeted cleanlabel poisoning attacks on neural networks. arXiv preprintAli Shafahi, W Ronny Huang, Mahyar Najibi, Octa- vian Suciu, Christoph Studer, Tudor Dumitras, and Tom Goldstein. 2018. Poison frogs! targeted clean- label poisoning attacks on neural networks. arXiv preprint arXiv:1804.00792.\n\nRecursive deep models for semantic compositionality over a sentiment treebank. Richard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D Manning, Andrew Ng, Christopher Potts, Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing. the 2013 Conference on Empirical Methods in Natural Language ProcessingSeattle, Washington, USAAssociation for Computational LinguisticsRichard Socher, Alex Perelygin, Jean Wu, Jason Chuang, Christopher D. Manning, Andrew Ng, and Christopher Potts. 2013. Recursive deep models for semantic compositionality over a sentiment tree- bank. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1631-1642, Seattle, Washington, USA. Asso- ciation for Computational Linguistics.\n\nWhat do you learn from context? probing for sentence structure in contextualized word representations. Ian Tenney, Patrick Xia, Berlin Chen, Alex Wang, Adam Poliak, Thomas Mccoy, Najoung Kim, Benjamin Van Durme, Sam Bowman, Dipanjan Das, Ellie Pavlick, International Conference on Learning Representations. Ian Tenney, Patrick Xia, Berlin Chen, Alex Wang, Adam Poliak, R Thomas McCoy, Najoung Kim, Benjamin Van Durme, Sam Bowman, Dipanjan Das, and Ellie Pavlick. 2019. What do you learn from context? probing for sentence structure in contextu- alized word representations. In International Con- ference on Learning Representations.\n\nAttention is all you need. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, Illia Polosukhin, Advances in neural information processing systems. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in neural information pro- cessing systems, pages 5998-6008.\n\nEric Wallace, Shi Feng, Nikhil Kandpal, Matt Gardner, Sameer Singh, arXiv:1908.07125Universal adversarial triggers for attacking and analyzing nlp. arXiv preprintEric Wallace, Shi Feng, Nikhil Kandpal, Matt Gardner, and Sameer Singh. 2019. Universal adversarial trig- gers for attacking and analyzing nlp. arXiv preprint arXiv:1908.07125.\n\nGLUE: A multi-task benchmark and analysis platform for natural language understanding. Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, Samuel R Bowman, ArXiv preprint 1804.07461Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R. Bowman. 2018. GLUE: A multi-task benchmark and analysis plat- form for natural language understanding. ArXiv preprint 1804.07461.\n\nTransformers: State-of-the-art natural language processing. Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, R\u00e9mi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Clara Patrick Von Platen, Yacine Ma, Julien Jernite, Canwen Plu, Teven Le Xu, Sylvain Scao, Mariama Gugger, Quentin Drame, Alexander M Lhoest, Rush, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations. the 2020 Conference on Empirical Methods in Natural Language Processing: System DemonstrationsOnline. Association for Computational LinguisticsThomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pier- ric Cistac, Tim Rault, R\u00e9mi Louf, Morgan Funtow- icz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame, Quentin Lhoest, and Alexander M. Rush. 2020. Transformers: State-of-the-art natural language pro- cessing. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 38-45, Online. Asso- ciation for Computational Linguistics.\n\nBe careful about poisoned word embeddings: Exploring the vulnerability of the embedding layers in nlp models. Wenkai Yang, Lei Li, Zhiyuan Zhang, Xuancheng Ren, Xu Sun, B He, abs/2103.15543ArXiv. Wenkai Yang, Lei Li, Zhiyuan Zhang, Xuancheng Ren, Xu Sun, and B. He. 2021. Be careful about poi- soned word embeddings: Exploring the vulnerabil- ity of the embedding layers in nlp models. ArXiv, abs/2103.15543.\n\nZhilin Yang, Zihang Dai, Yiming Yang, Jaime Carbonell, Ruslan Salakhutdinov, Quoc V Le, arXiv:1906.08237Xlnet: Generalized autoregressive pretraining for language understanding. arXiv preprintZhilin Yang, Zihang Dai, Yiming Yang, Jaime Car- bonell, Ruslan Salakhutdinov, and Quoc V Le. 2019. Xlnet: Generalized autoregressive pretrain- ing for language understanding. arXiv preprint arXiv:1906.08237.\n\nVisualizing and understanding convolutional networks. D Matthew, Rob Zeiler, Fergus, European conference on computer vision. SpringerMatthew D Zeiler and Rob Fergus. 2014. Visualizing and understanding convolutional networks. In Euro- pean conference on computer vision, pages 818-833. Springer.\n\nRed alarm for pre-trained models: Universal vulnerabilities by neuron-level backdoor attacks. Zhengyan Zhang, Guangxuan Xiao, Yongwei Li, Tian Lv, Fanchao Qi, Yasheng Wang, Xin Jiang, Zhiyuan Liu, Maosong Sun, arXiv:2101.06969arXiv preprintZhengyan Zhang, Guangxuan Xiao, Yongwei Li, Tian Lv, Fanchao Qi, Yasheng Wang, Xin Jiang, Zhiyuan Liu, and Maosong Sun. 2021. Red alarm for pre-trained models: Universal vulnerabilities by neuron-level backdoor attacks. arXiv preprint arXiv:2101.06969.\n", "annotations": {"author": "[{\"end\":352,\"start\":189},{\"end\":355,\"start\":353},{\"end\":516,\"start\":356},{\"end\":655,\"start\":517},{\"end\":658,\"start\":656},{\"end\":799,\"start\":659},{\"end\":938,\"start\":800},{\"end\":1129,\"start\":939}]", "publisher": "[{\"end\":111,\"start\":70},{\"end\":1399,\"start\":1358}]", "author_last_name": "[{\"end\":199,\"start\":197},{\"end\":366,\"start\":362},{\"end\":527,\"start\":525},{\"end\":671,\"start\":667},{\"end\":810,\"start\":808},{\"end\":949,\"start\":946}]", "author_first_name": "[{\"end\":196,\"start\":189},{\"end\":354,\"start\":353},{\"end\":361,\"start\":356},{\"end\":524,\"start\":517},{\"end\":657,\"start\":656},{\"end\":666,\"start\":659},{\"end\":807,\"start\":800},{\"end\":945,\"start\":939}]", "author_affiliation": "[{\"end\":270,\"start\":226},{\"end\":351,\"start\":272},{\"end\":434,\"start\":390},{\"end\":515,\"start\":436},{\"end\":573,\"start\":529},{\"end\":654,\"start\":575},{\"end\":717,\"start\":673},{\"end\":798,\"start\":719},{\"end\":856,\"start\":812},{\"end\":937,\"start\":858},{\"end\":1014,\"start\":970},{\"end\":1095,\"start\":1016},{\"end\":1128,\"start\":1097}]", "title": "[{\"end\":69,\"start\":1},{\"end\":1198,\"start\":1130}]", "venue": "[{\"end\":1286,\"start\":1200}]", "abstract": "[{\"end\":2339,\"start\":1429}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b6\"},\"end\":2496,\"start\":2475},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":2513,\"start\":2496},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":2530,\"start\":2513},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":2606,\"start\":2588},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":2629,\"start\":2606},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":2649,\"start\":2629},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":2741,\"start\":2718},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":3061,\"start\":3040},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":3077,\"start\":3061},{\"end\":3291,\"start\":3272},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3309,\"start\":3293},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":3431,\"start\":3410},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":3449,\"start\":3431},{\"end\":4050,\"start\":4025},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":4072,\"start\":4050},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":4654,\"start\":4627},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":4776,\"start\":4755},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":5244,\"start\":5222},{\"end\":5261,\"start\":5244},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":5427,\"start\":5403},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":7573,\"start\":7557},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":7749,\"start\":7732},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":7768,\"start\":7749},{\"end\":7786,\"start\":7768},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":7807,\"start\":7786},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":7906,\"start\":7887},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":7924,\"start\":7906},{\"end\":7941,\"start\":7924},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":7963,\"start\":7941},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":8034,\"start\":8013},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":8208,\"start\":8190},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":8273,\"start\":8256},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":8429,\"start\":8408},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":8447,\"start\":8429},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":8780,\"start\":8759},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":8797,\"start\":8780},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":8815,\"start\":8797},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":8945,\"start\":8925},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":8965,\"start\":8945},{\"end\":9243,\"start\":9218},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":9344,\"start\":9321},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":9361,\"start\":9344},{\"end\":9378,\"start\":9361},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":9430,\"start\":9408},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":10018,\"start\":10002},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":12612,\"start\":12592},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":12780,\"start\":12762},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":13418,\"start\":13391},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":13590,\"start\":13569},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":13606,\"start\":13590},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":13871,\"start\":13846},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":13891,\"start\":13871},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":14059,\"start\":14035},{\"end\":14772,\"start\":14767},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":15612,\"start\":15594},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":15733,\"start\":15712},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":17298,\"start\":17277},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":17361,\"start\":17342},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":17556,\"start\":17542},{\"end\":17600,\"start\":17579},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":18092,\"start\":18075},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":18352,\"start\":18331},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":18770,\"start\":18750},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":19207,\"start\":19187},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":19621,\"start\":19600},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":19639,\"start\":19621},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":19845,\"start\":19824},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":19865,\"start\":19845},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":19883,\"start\":19865},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":22338,\"start\":22318},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":23909,\"start\":23888},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":23932,\"start\":23909},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":23952,\"start\":23932},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":23968,\"start\":23952},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":27355,\"start\":27335},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":27378,\"start\":27360}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":28749,\"start\":28641},{\"attributes\":{\"id\":\"fig_1\"},\"end\":28891,\"start\":28750},{\"attributes\":{\"id\":\"fig_2\"},\"end\":29168,\"start\":28892},{\"attributes\":{\"id\":\"fig_3\"},\"end\":29246,\"start\":29169},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":29631,\"start\":29247},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":30124,\"start\":29632},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":31132,\"start\":30125},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":31255,\"start\":31133},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":31315,\"start\":31256}]", "paragraph": "[{\"end\":4374,\"start\":2355},{\"end\":4487,\"start\":4376},{\"end\":5139,\"start\":4489},{\"end\":5473,\"start\":5141},{\"end\":5660,\"start\":5475},{\"end\":5853,\"start\":5662},{\"end\":6127,\"start\":5855},{\"end\":6371,\"start\":6129},{\"end\":7006,\"start\":6373},{\"end\":7230,\"start\":7008},{\"end\":7368,\"start\":7232},{\"end\":8378,\"start\":7370},{\"end\":9140,\"start\":8395},{\"end\":9900,\"start\":9142},{\"end\":10845,\"start\":9963},{\"end\":11128,\"start\":10847},{\"end\":11366,\"start\":11217},{\"end\":11461,\"start\":11368},{\"end\":11584,\"start\":11463},{\"end\":11804,\"start\":11644},{\"end\":12252,\"start\":11823},{\"end\":12879,\"start\":12254},{\"end\":13419,\"start\":12907},{\"end\":13764,\"start\":13443},{\"end\":14673,\"start\":13766},{\"end\":14943,\"start\":14675},{\"end\":15002,\"start\":14945},{\"end\":15348,\"start\":15059},{\"end\":15902,\"start\":15350},{\"end\":16426,\"start\":15929},{\"end\":16725,\"start\":16428},{\"end\":17027,\"start\":16805},{\"end\":17665,\"start\":17072},{\"end\":17885,\"start\":17667},{\"end\":17974,\"start\":17918},{\"end\":18066,\"start\":17988},{\"end\":18601,\"start\":18068},{\"end\":18966,\"start\":18621},{\"end\":19489,\"start\":18968},{\"end\":20086,\"start\":19491},{\"end\":20236,\"start\":20088},{\"end\":21337,\"start\":20264},{\"end\":22550,\"start\":21339},{\"end\":23538,\"start\":22579},{\"end\":24005,\"start\":23540},{\"end\":24924,\"start\":24007},{\"end\":26220,\"start\":24951},{\"end\":26709,\"start\":26256},{\"end\":27209,\"start\":26711},{\"end\":27588,\"start\":27238},{\"end\":28043,\"start\":27590},{\"end\":28640,\"start\":28058}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":11216,\"start\":11129},{\"attributes\":{\"id\":\"formula_1\"},\"end\":11643,\"start\":11585},{\"attributes\":{\"id\":\"formula_2\"},\"end\":15058,\"start\":15003},{\"attributes\":{\"id\":\"formula_3\"},\"end\":16804,\"start\":16726},{\"attributes\":{\"id\":\"formula_4\"},\"end\":17917,\"start\":17886}]", "table_ref": "[{\"end\":11928,\"start\":11921},{\"end\":21448,\"start\":21441}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2353,\"start\":2341},{\"attributes\":{\"n\":\"2\"},\"end\":8393,\"start\":8381},{\"attributes\":{\"n\":\"3.1\"},\"end\":9934,\"start\":9903},{\"attributes\":{\"n\":\"3.1.1\"},\"end\":9961,\"start\":9937},{\"attributes\":{\"n\":\"3.1.2\"},\"end\":11821,\"start\":11807},{\"attributes\":{\"n\":\"3.1.3\"},\"end\":12905,\"start\":12882},{\"attributes\":{\"n\":\"3.2\"},\"end\":13441,\"start\":13422},{\"attributes\":{\"n\":\"3.3\"},\"end\":15927,\"start\":15905},{\"attributes\":{\"n\":\"4\"},\"end\":17041,\"start\":17030},{\"attributes\":{\"n\":\"4.1\"},\"end\":17070,\"start\":17044},{\"attributes\":{\"n\":\"4.2\"},\"end\":17986,\"start\":17977},{\"attributes\":{\"n\":\"4.3\"},\"end\":18619,\"start\":18604},{\"attributes\":{\"n\":\"4.4\"},\"end\":20262,\"start\":20239},{\"attributes\":{\"n\":\"4.5\"},\"end\":22577,\"start\":22553},{\"attributes\":{\"n\":\"4.6\"},\"end\":24949,\"start\":24927},{\"attributes\":{\"n\":\"4.7\"},\"end\":26254,\"start\":26223},{\"attributes\":{\"n\":\"4.8\"},\"end\":27236,\"start\":27212},{\"attributes\":{\"n\":\"5\"},\"end\":28056,\"start\":28046},{\"end\":28652,\"start\":28642},{\"end\":28761,\"start\":28751},{\"end\":28901,\"start\":28893},{\"end\":29180,\"start\":29170},{\"end\":29269,\"start\":29248},{\"end\":29642,\"start\":29633},{\"end\":31148,\"start\":31134},{\"end\":31266,\"start\":31257}]", "table": "[{\"end\":31132,\"start\":30545},{\"end\":31255,\"start\":31163}]", "figure_caption": "[{\"end\":28749,\"start\":28654},{\"end\":28891,\"start\":28763},{\"end\":29168,\"start\":28903},{\"end\":29246,\"start\":29182},{\"end\":29631,\"start\":29280},{\"end\":30124,\"start\":29644},{\"end\":30545,\"start\":30127},{\"end\":31163,\"start\":31156},{\"end\":31315,\"start\":31268}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":14442,\"start\":14437},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":18323,\"start\":18317},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":23556,\"start\":23551},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":24004,\"start\":23999},{\"end\":24101,\"start\":24096},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":25579,\"start\":25574},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":26730,\"start\":26722},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":26822,\"start\":26814}]", "bib_author_first_name": "[{\"end\":31923,\"start\":31918},{\"end\":31935,\"start\":31930},{\"end\":31946,\"start\":31940},{\"end\":31960,\"start\":31953},{\"end\":32551,\"start\":32545},{\"end\":32563,\"start\":32558},{\"end\":32578,\"start\":32571},{\"end\":32594,\"start\":32587},{\"end\":32603,\"start\":32599},{\"end\":32847,\"start\":32841},{\"end\":32859,\"start\":32854},{\"end\":32867,\"start\":32865},{\"end\":32880,\"start\":32872},{\"end\":33222,\"start\":33217},{\"end\":33237,\"start\":33230},{\"end\":33254,\"start\":33250},{\"end\":33272,\"start\":33261},{\"end\":33274,\"start\":33273},{\"end\":33900,\"start\":33899},{\"end\":33915,\"start\":33909},{\"end\":34131,\"start\":34125},{\"end\":34147,\"start\":34137},{\"end\":34160,\"start\":34154},{\"end\":34415,\"start\":34410},{\"end\":34432,\"start\":34424},{\"end\":34446,\"start\":34440},{\"end\":34460,\"start\":34452},{\"end\":34674,\"start\":34669},{\"end\":34689,\"start\":34685},{\"end\":34701,\"start\":34695},{\"end\":34714,\"start\":34708},{\"end\":34978,\"start\":34977},{\"end\":35369,\"start\":35363},{\"end\":35381,\"start\":35374},{\"end\":35405,\"start\":35396},{\"end\":35632,\"start\":35625},{\"end\":35644,\"start\":35637},{\"end\":35660,\"start\":35652},{\"end\":35670,\"start\":35666},{\"end\":36093,\"start\":36087},{\"end\":36111,\"start\":36102},{\"end\":36376,\"start\":36374},{\"end\":36389,\"start\":36382},{\"end\":36399,\"start\":36395},{\"end\":36406,\"start\":36400},{\"end\":36418,\"start\":36413},{\"end\":36687,\"start\":36684},{\"end\":36699,\"start\":36694},{\"end\":36939,\"start\":36934},{\"end\":36952,\"start\":36948},{\"end\":36967,\"start\":36961},{\"end\":37195,\"start\":37188},{\"end\":37207,\"start\":37200},{\"end\":37218,\"start\":37212},{\"end\":37522,\"start\":37516},{\"end\":37535,\"start\":37527},{\"end\":37549,\"start\":37542},{\"end\":37558,\"start\":37554},{\"end\":37573,\"start\":37566},{\"end\":37584,\"start\":37578},{\"end\":37908,\"start\":37902},{\"end\":37919,\"start\":37913},{\"end\":37931,\"start\":37924},{\"end\":37944,\"start\":37936},{\"end\":38147,\"start\":38139},{\"end\":38158,\"start\":38153},{\"end\":38424,\"start\":38418},{\"end\":38437,\"start\":38430},{\"end\":38448,\"start\":38442},{\"end\":38465,\"start\":38456},{\"end\":38475,\"start\":38471},{\"end\":38489,\"start\":38482},{\"end\":38503,\"start\":38496},{\"end\":38930,\"start\":38924},{\"end\":38940,\"start\":38936},{\"end\":38951,\"start\":38946},{\"end\":38966,\"start\":38959},{\"end\":38977,\"start\":38971},{\"end\":38990,\"start\":38985},{\"end\":39001,\"start\":38997},{\"end\":39012,\"start\":39008},{\"end\":39024,\"start\":39020},{\"end\":39045,\"start\":39038},{\"end\":39402,\"start\":39396},{\"end\":39412,\"start\":39408},{\"end\":39423,\"start\":39418},{\"end\":39707,\"start\":39701},{\"end\":39709,\"start\":39708},{\"end\":39723,\"start\":39716},{\"end\":39725,\"start\":39724},{\"end\":39737,\"start\":39732},{\"end\":39739,\"start\":39738},{\"end\":39749,\"start\":39746},{\"end\":39763,\"start\":39757},{\"end\":39765,\"start\":39764},{\"end\":39781,\"start\":39770},{\"end\":40590,\"start\":40583},{\"end\":40606,\"start\":40602},{\"end\":40608,\"start\":40607},{\"end\":41184,\"start\":41181},{\"end\":41196,\"start\":41193},{\"end\":41373,\"start\":41372},{\"end\":41387,\"start\":41383},{\"end\":41401,\"start\":41396},{\"end\":41415,\"start\":41411},{\"end\":41434,\"start\":41423},{\"end\":41450,\"start\":41444},{\"end\":41462,\"start\":41458},{\"end\":41817,\"start\":41811},{\"end\":41832,\"start\":41823},{\"end\":41842,\"start\":41838},{\"end\":41853,\"start\":41847},{\"end\":41864,\"start\":41860},{\"end\":41878,\"start\":41870},{\"end\":42226,\"start\":42220},{\"end\":42242,\"start\":42238},{\"end\":42260,\"start\":42250},{\"end\":42275,\"start\":42270},{\"end\":42523,\"start\":42514},{\"end\":42541,\"start\":42530},{\"end\":42559,\"start\":42554},{\"end\":42948,\"start\":42940},{\"end\":43108,\"start\":43105},{\"end\":43123,\"start\":43118},{\"end\":43137,\"start\":43131},{\"end\":43154,\"start\":43146},{\"end\":43171,\"start\":43162},{\"end\":43185,\"start\":43180},{\"end\":43199,\"start\":43196},{\"end\":43627,\"start\":43620},{\"end\":43640,\"start\":43636},{\"end\":43656,\"start\":43652},{\"end\":43666,\"start\":43661},{\"end\":43686,\"start\":43675},{\"end\":43688,\"start\":43687},{\"end\":43704,\"start\":43698},{\"end\":43720,\"start\":43709},{\"end\":44438,\"start\":44435},{\"end\":44454,\"start\":44447},{\"end\":44466,\"start\":44460},{\"end\":44477,\"start\":44473},{\"end\":44488,\"start\":44484},{\"end\":44503,\"start\":44497},{\"end\":44518,\"start\":44511},{\"end\":44532,\"start\":44524},{\"end\":44547,\"start\":44544},{\"end\":44564,\"start\":44556},{\"end\":44575,\"start\":44570},{\"end\":44999,\"start\":44993},{\"end\":45013,\"start\":45009},{\"end\":45027,\"start\":45023},{\"end\":45041,\"start\":45036},{\"end\":45058,\"start\":45053},{\"end\":45071,\"start\":45066},{\"end\":45073,\"start\":45072},{\"end\":45087,\"start\":45081},{\"end\":45101,\"start\":45096},{\"end\":45401,\"start\":45397},{\"end\":45414,\"start\":45411},{\"end\":45427,\"start\":45421},{\"end\":45441,\"start\":45437},{\"end\":45457,\"start\":45451},{\"end\":45828,\"start\":45824},{\"end\":45844,\"start\":45835},{\"end\":45858,\"start\":45852},{\"end\":45873,\"start\":45868},{\"end\":45884,\"start\":45880},{\"end\":45897,\"start\":45891},{\"end\":45899,\"start\":45898},{\"end\":46211,\"start\":46205},{\"end\":46226,\"start\":46218},{\"end\":46240,\"start\":46234},{\"end\":46253,\"start\":46247},{\"end\":46271,\"start\":46264},{\"end\":46289,\"start\":46282},{\"end\":46302,\"start\":46295},{\"end\":46314,\"start\":46311},{\"end\":46326,\"start\":46322},{\"end\":46339,\"start\":46333},{\"end\":46354,\"start\":46351},{\"end\":46367,\"start\":46364},{\"end\":46383,\"start\":46378},{\"end\":46410,\"start\":46404},{\"end\":46421,\"start\":46415},{\"end\":46437,\"start\":46431},{\"end\":46448,\"start\":46443},{\"end\":46451,\"start\":46449},{\"end\":46463,\"start\":46456},{\"end\":46477,\"start\":46470},{\"end\":46493,\"start\":46486},{\"end\":46510,\"start\":46501},{\"end\":46512,\"start\":46511},{\"end\":47477,\"start\":47471},{\"end\":47487,\"start\":47484},{\"end\":47499,\"start\":47492},{\"end\":47516,\"start\":47507},{\"end\":47524,\"start\":47522},{\"end\":47531,\"start\":47530},{\"end\":47777,\"start\":47771},{\"end\":47790,\"start\":47784},{\"end\":47802,\"start\":47796},{\"end\":47814,\"start\":47809},{\"end\":47832,\"start\":47826},{\"end\":47854,\"start\":47848},{\"end\":48228,\"start\":48227},{\"end\":48241,\"start\":48238},{\"end\":48572,\"start\":48564},{\"end\":48589,\"start\":48580},{\"end\":48603,\"start\":48596},{\"end\":48612,\"start\":48608},{\"end\":48624,\"start\":48617},{\"end\":48636,\"start\":48629},{\"end\":48646,\"start\":48643},{\"end\":48661,\"start\":48654},{\"end\":48674,\"start\":48667}]", "bib_author_last_name": "[{\"end\":31928,\"start\":31924},{\"end\":31938,\"start\":31936},{\"end\":31951,\"start\":31947},{\"end\":31971,\"start\":31961},{\"end\":32556,\"start\":32552},{\"end\":32569,\"start\":32564},{\"end\":32585,\"start\":32579},{\"end\":32597,\"start\":32595},{\"end\":32609,\"start\":32604},{\"end\":32852,\"start\":32848},{\"end\":32863,\"start\":32860},{\"end\":32870,\"start\":32868},{\"end\":32883,\"start\":32881},{\"end\":33228,\"start\":33223},{\"end\":33248,\"start\":33238},{\"end\":33259,\"start\":33255},{\"end\":33282,\"start\":33275},{\"end\":33907,\"start\":33901},{\"end\":33919,\"start\":33916},{\"end\":33923,\"start\":33921},{\"end\":34135,\"start\":34132},{\"end\":34152,\"start\":34148},{\"end\":34163,\"start\":34161},{\"end\":34422,\"start\":34416},{\"end\":34438,\"start\":34433},{\"end\":34450,\"start\":34447},{\"end\":34470,\"start\":34461},{\"end\":34683,\"start\":34675},{\"end\":34693,\"start\":34690},{\"end\":34706,\"start\":34702},{\"end\":34718,\"start\":34715},{\"end\":34982,\"start\":34979},{\"end\":34994,\"start\":34984},{\"end\":35372,\"start\":35370},{\"end\":35394,\"start\":35382},{\"end\":35410,\"start\":35406},{\"end\":35635,\"start\":35633},{\"end\":35650,\"start\":35645},{\"end\":35664,\"start\":35661},{\"end\":35674,\"start\":35671},{\"end\":36100,\"start\":36094},{\"end\":36117,\"start\":36112},{\"end\":36380,\"start\":36377},{\"end\":36393,\"start\":36390},{\"end\":36411,\"start\":36407},{\"end\":36428,\"start\":36419},{\"end\":36692,\"start\":36688},{\"end\":36703,\"start\":36700},{\"end\":36710,\"start\":36705},{\"end\":36946,\"start\":36940},{\"end\":36959,\"start\":36953},{\"end\":36974,\"start\":36968},{\"end\":37198,\"start\":37196},{\"end\":37210,\"start\":37208},{\"end\":37222,\"start\":37219},{\"end\":37525,\"start\":37523},{\"end\":37540,\"start\":37536},{\"end\":37552,\"start\":37550},{\"end\":37564,\"start\":37559},{\"end\":37576,\"start\":37574},{\"end\":37588,\"start\":37585},{\"end\":37911,\"start\":37909},{\"end\":37922,\"start\":37920},{\"end\":37934,\"start\":37932},{\"end\":37947,\"start\":37945},{\"end\":38151,\"start\":38148},{\"end\":38163,\"start\":38159},{\"end\":38428,\"start\":38425},{\"end\":38440,\"start\":38438},{\"end\":38454,\"start\":38449},{\"end\":38469,\"start\":38466},{\"end\":38480,\"start\":38476},{\"end\":38494,\"start\":38490},{\"end\":38509,\"start\":38504},{\"end\":38934,\"start\":38931},{\"end\":38944,\"start\":38941},{\"end\":38957,\"start\":38952},{\"end\":38969,\"start\":38967},{\"end\":38983,\"start\":38978},{\"end\":38995,\"start\":38991},{\"end\":39006,\"start\":39002},{\"end\":39018,\"start\":39013},{\"end\":39036,\"start\":39025},{\"end\":39054,\"start\":39046},{\"end\":39406,\"start\":39403},{\"end\":39416,\"start\":39413},{\"end\":39434,\"start\":39424},{\"end\":39714,\"start\":39710},{\"end\":39730,\"start\":39726},{\"end\":39744,\"start\":39740},{\"end\":39755,\"start\":39750},{\"end\":39768,\"start\":39766},{\"end\":39787,\"start\":39782},{\"end\":40600,\"start\":40591},{\"end\":40614,\"start\":40609},{\"end\":41191,\"start\":41185},{\"end\":41201,\"start\":41197},{\"end\":41381,\"start\":41374},{\"end\":41394,\"start\":41388},{\"end\":41409,\"start\":41402},{\"end\":41421,\"start\":41416},{\"end\":41442,\"start\":41435},{\"end\":41456,\"start\":41451},{\"end\":41466,\"start\":41463},{\"end\":41479,\"start\":41468},{\"end\":41821,\"start\":41818},{\"end\":41836,\"start\":41833},{\"end\":41845,\"start\":41843},{\"end\":41858,\"start\":41854},{\"end\":41868,\"start\":41865},{\"end\":41884,\"start\":41879},{\"end\":42236,\"start\":42227},{\"end\":42248,\"start\":42243},{\"end\":42268,\"start\":42261},{\"end\":42281,\"start\":42276},{\"end\":42528,\"start\":42524},{\"end\":42552,\"start\":42542},{\"end\":42570,\"start\":42560},{\"end\":42955,\"start\":42949},{\"end\":43116,\"start\":43109},{\"end\":43129,\"start\":43124},{\"end\":43144,\"start\":43138},{\"end\":43160,\"start\":43155},{\"end\":43178,\"start\":43172},{\"end\":43194,\"start\":43186},{\"end\":43209,\"start\":43200},{\"end\":43634,\"start\":43628},{\"end\":43650,\"start\":43641},{\"end\":43659,\"start\":43657},{\"end\":43673,\"start\":43667},{\"end\":43696,\"start\":43689},{\"end\":43707,\"start\":43705},{\"end\":43726,\"start\":43721},{\"end\":44445,\"start\":44439},{\"end\":44458,\"start\":44455},{\"end\":44471,\"start\":44467},{\"end\":44482,\"start\":44478},{\"end\":44495,\"start\":44489},{\"end\":44509,\"start\":44504},{\"end\":44522,\"start\":44519},{\"end\":44542,\"start\":44533},{\"end\":44554,\"start\":44548},{\"end\":44568,\"start\":44565},{\"end\":44583,\"start\":44576},{\"end\":45007,\"start\":45000},{\"end\":45021,\"start\":45014},{\"end\":45034,\"start\":45028},{\"end\":45051,\"start\":45042},{\"end\":45064,\"start\":45059},{\"end\":45079,\"start\":45074},{\"end\":45094,\"start\":45088},{\"end\":45112,\"start\":45102},{\"end\":45409,\"start\":45402},{\"end\":45419,\"start\":45415},{\"end\":45435,\"start\":45428},{\"end\":45449,\"start\":45442},{\"end\":45463,\"start\":45458},{\"end\":45833,\"start\":45829},{\"end\":45850,\"start\":45845},{\"end\":45866,\"start\":45859},{\"end\":45878,\"start\":45874},{\"end\":45889,\"start\":45885},{\"end\":45906,\"start\":45900},{\"end\":46216,\"start\":46212},{\"end\":46232,\"start\":46227},{\"end\":46245,\"start\":46241},{\"end\":46262,\"start\":46254},{\"end\":46280,\"start\":46272},{\"end\":46293,\"start\":46290},{\"end\":46309,\"start\":46303},{\"end\":46320,\"start\":46315},{\"end\":46331,\"start\":46327},{\"end\":46349,\"start\":46340},{\"end\":46362,\"start\":46355},{\"end\":46376,\"start\":46368},{\"end\":46402,\"start\":46384},{\"end\":46413,\"start\":46411},{\"end\":46429,\"start\":46422},{\"end\":46441,\"start\":46438},{\"end\":46454,\"start\":46452},{\"end\":46468,\"start\":46464},{\"end\":46484,\"start\":46478},{\"end\":46499,\"start\":46494},{\"end\":46519,\"start\":46513},{\"end\":46525,\"start\":46521},{\"end\":47482,\"start\":47478},{\"end\":47490,\"start\":47488},{\"end\":47505,\"start\":47500},{\"end\":47520,\"start\":47517},{\"end\":47528,\"start\":47525},{\"end\":47534,\"start\":47532},{\"end\":47782,\"start\":47778},{\"end\":47794,\"start\":47791},{\"end\":47807,\"start\":47803},{\"end\":47824,\"start\":47815},{\"end\":47846,\"start\":47833},{\"end\":47857,\"start\":47855},{\"end\":48236,\"start\":48229},{\"end\":48248,\"start\":48242},{\"end\":48256,\"start\":48250},{\"end\":48578,\"start\":48573},{\"end\":48594,\"start\":48590},{\"end\":48606,\"start\":48604},{\"end\":48615,\"start\":48613},{\"end\":48627,\"start\":48625},{\"end\":48641,\"start\":48637},{\"end\":48652,\"start\":48647},{\"end\":48665,\"start\":48662},{\"end\":48678,\"start\":48675}]", "bib_entry": "[{\"attributes\":{\"doi\":\"10.24963/ijcai.2019/647\",\"id\":\"b0\",\"matched_paper_id\":199466093},\"end\":32543,\"start\":31825},{\"attributes\":{\"doi\":\"arXiv:2006.01043\",\"id\":\"b1\"},\"end\":32839,\"start\":32545},{\"attributes\":{\"doi\":\"arXiv:1712.05526\",\"id\":\"b2\"},\"end\":33158,\"start\":32841},{\"attributes\":{\"doi\":\"10.18653/v1/W19-4828\",\"id\":\"b3\",\"matched_paper_id\":184486746},\"end\":33863,\"start\":33160},{\"attributes\":{\"doi\":\"arXiv:1511.01432\",\"id\":\"b4\"},\"end\":34057,\"start\":33865},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":168170110},\"end\":34326,\"start\":34059},{\"attributes\":{\"doi\":\"abs/1810.04805\",\"id\":\"b6\"},\"end\":34667,\"start\":34328},{\"attributes\":{\"doi\":\"arXiv:1712.06751\",\"id\":\"b7\"},\"end\":34975,\"start\":34669},{\"attributes\":{\"doi\":\"arXiv:1412.6572\",\"id\":\"b8\"},\"end\":35264,\"start\":34977},{\"attributes\":{\"id\":\"b9\"},\"end\":35577,\"start\":35266},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":206594692},\"end\":36023,\"start\":35579},{\"attributes\":{\"doi\":\"arXiv:1801.06146\",\"id\":\"b11\"},\"end\":36286,\"start\":36025},{\"attributes\":{\"doi\":\"abs/1907.11932\",\"id\":\"b12\"},\"end\":36621,\"start\":36288},{\"attributes\":{\"doi\":\"PMLR\",\"id\":\"b13\",\"matched_paper_id\":13193974},\"end\":36932,\"start\":36623},{\"attributes\":{\"doi\":\"arXiv:2004.06660\",\"id\":\"b14\"},\"end\":37186,\"start\":36934},{\"attributes\":{\"doi\":\"arXiv:2004.09984\",\"id\":\"b15\"},\"end\":37514,\"start\":37188},{\"attributes\":{\"doi\":\"arXiv:2004.04692\",\"id\":\"b16\"},\"end\":37823,\"start\":37516},{\"attributes\":{\"doi\":\"arXiv:2012.03816\",\"id\":\"b17\"},\"end\":38137,\"start\":37825},{\"attributes\":{\"doi\":\"arXiv:2106.04554\",\"id\":\"b18\"},\"end\":38379,\"start\":38139},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":31806516},\"end\":38922,\"start\":38381},{\"attributes\":{\"doi\":\"arXiv:1907.11692\",\"id\":\"b20\"},\"end\":39378,\"start\":38924},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":12625409},\"end\":39653,\"start\":39380},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":1428702},\"end\":40423,\"start\":39655},{\"attributes\":{\"doi\":\"10.1016/S0079-7421(08)60536-8\",\"id\":\"b23\"},\"end\":40868,\"start\":40425},{\"attributes\":{\"id\":\"b24\"},\"end\":41179,\"start\":40870},{\"attributes\":{\"doi\":\"arXiv:2010.08138\",\"id\":\"b25\"},\"end\":41370,\"start\":41181},{\"attributes\":{\"doi\":\"arXiv:1802.05365\",\"id\":\"b26\"},\"end\":41747,\"start\":41372},{\"attributes\":{\"doi\":\"10.1007/s11431-020-1647-3\",\"id\":\"b27\",\"matched_paper_id\":212747830},\"end\":42157,\"start\":41749},{\"attributes\":{\"doi\":\"arXiv:1606.05250\",\"id\":\"b28\"},\"end\":42479,\"start\":42159},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":203610516},\"end\":42872,\"start\":42481},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":8266190},\"end\":43103,\"start\":42874},{\"attributes\":{\"doi\":\"arXiv:1804.00792\",\"id\":\"b31\"},\"end\":43539,\"start\":43105},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":990233},\"end\":44330,\"start\":43541},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":108300988},\"end\":44964,\"start\":44332},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":13756489},\"end\":45395,\"start\":44966},{\"attributes\":{\"doi\":\"arXiv:1908.07125\",\"id\":\"b35\"},\"end\":45735,\"start\":45397},{\"attributes\":{\"id\":\"b36\"},\"end\":46143,\"start\":45737},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":208117506},\"end\":47359,\"start\":46145},{\"attributes\":{\"doi\":\"abs/2103.15543\",\"id\":\"b38\",\"matched_paper_id\":232404131},\"end\":47769,\"start\":47361},{\"attributes\":{\"doi\":\"arXiv:1906.08237\",\"id\":\"b39\"},\"end\":48171,\"start\":47771},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":3960646},\"end\":48468,\"start\":48173},{\"attributes\":{\"doi\":\"arXiv:2101.06969\",\"id\":\"b41\"},\"end\":48962,\"start\":48470}]", "bib_title": "[{\"end\":31916,\"start\":31825},{\"end\":33215,\"start\":33160},{\"end\":34123,\"start\":34059},{\"end\":35623,\"start\":35579},{\"end\":36682,\"start\":36623},{\"end\":38416,\"start\":38381},{\"end\":39394,\"start\":39380},{\"end\":39699,\"start\":39655},{\"end\":41809,\"start\":41749},{\"end\":42512,\"start\":42481},{\"end\":42938,\"start\":42874},{\"end\":43618,\"start\":43541},{\"end\":44433,\"start\":44332},{\"end\":44991,\"start\":44966},{\"end\":46203,\"start\":46145},{\"end\":47469,\"start\":47361},{\"end\":48225,\"start\":48173}]", "bib_author": "[{\"end\":31930,\"start\":31918},{\"end\":31940,\"start\":31930},{\"end\":31953,\"start\":31940},{\"end\":31973,\"start\":31953},{\"end\":32558,\"start\":32545},{\"end\":32571,\"start\":32558},{\"end\":32587,\"start\":32571},{\"end\":32599,\"start\":32587},{\"end\":32611,\"start\":32599},{\"end\":32854,\"start\":32841},{\"end\":32865,\"start\":32854},{\"end\":32872,\"start\":32865},{\"end\":32885,\"start\":32872},{\"end\":33230,\"start\":33217},{\"end\":33250,\"start\":33230},{\"end\":33261,\"start\":33250},{\"end\":33284,\"start\":33261},{\"end\":33909,\"start\":33899},{\"end\":33921,\"start\":33909},{\"end\":33925,\"start\":33921},{\"end\":34137,\"start\":34125},{\"end\":34154,\"start\":34137},{\"end\":34165,\"start\":34154},{\"end\":34424,\"start\":34410},{\"end\":34440,\"start\":34424},{\"end\":34452,\"start\":34440},{\"end\":34472,\"start\":34452},{\"end\":34685,\"start\":34669},{\"end\":34695,\"start\":34685},{\"end\":34708,\"start\":34695},{\"end\":34720,\"start\":34708},{\"end\":34984,\"start\":34977},{\"end\":34996,\"start\":34984},{\"end\":35374,\"start\":35363},{\"end\":35396,\"start\":35374},{\"end\":35412,\"start\":35396},{\"end\":35637,\"start\":35625},{\"end\":35652,\"start\":35637},{\"end\":35666,\"start\":35652},{\"end\":35676,\"start\":35666},{\"end\":36102,\"start\":36087},{\"end\":36119,\"start\":36102},{\"end\":36382,\"start\":36374},{\"end\":36395,\"start\":36382},{\"end\":36413,\"start\":36395},{\"end\":36430,\"start\":36413},{\"end\":36694,\"start\":36684},{\"end\":36705,\"start\":36694},{\"end\":36712,\"start\":36705},{\"end\":36948,\"start\":36934},{\"end\":36961,\"start\":36948},{\"end\":36976,\"start\":36961},{\"end\":37200,\"start\":37188},{\"end\":37212,\"start\":37200},{\"end\":37224,\"start\":37212},{\"end\":37527,\"start\":37516},{\"end\":37542,\"start\":37527},{\"end\":37554,\"start\":37542},{\"end\":37566,\"start\":37554},{\"end\":37578,\"start\":37566},{\"end\":37590,\"start\":37578},{\"end\":37913,\"start\":37902},{\"end\":37924,\"start\":37913},{\"end\":37936,\"start\":37924},{\"end\":37949,\"start\":37936},{\"end\":38153,\"start\":38139},{\"end\":38165,\"start\":38153},{\"end\":38430,\"start\":38418},{\"end\":38442,\"start\":38430},{\"end\":38456,\"start\":38442},{\"end\":38471,\"start\":38456},{\"end\":38482,\"start\":38471},{\"end\":38496,\"start\":38482},{\"end\":38511,\"start\":38496},{\"end\":38936,\"start\":38924},{\"end\":38946,\"start\":38936},{\"end\":38959,\"start\":38946},{\"end\":38971,\"start\":38959},{\"end\":38985,\"start\":38971},{\"end\":38997,\"start\":38985},{\"end\":39008,\"start\":38997},{\"end\":39020,\"start\":39008},{\"end\":39038,\"start\":39020},{\"end\":39056,\"start\":39038},{\"end\":39408,\"start\":39396},{\"end\":39418,\"start\":39408},{\"end\":39436,\"start\":39418},{\"end\":39716,\"start\":39701},{\"end\":39732,\"start\":39716},{\"end\":39746,\"start\":39732},{\"end\":39757,\"start\":39746},{\"end\":39770,\"start\":39757},{\"end\":39789,\"start\":39770},{\"end\":40602,\"start\":40583},{\"end\":40616,\"start\":40602},{\"end\":41193,\"start\":41181},{\"end\":41203,\"start\":41193},{\"end\":41383,\"start\":41372},{\"end\":41396,\"start\":41383},{\"end\":41411,\"start\":41396},{\"end\":41423,\"start\":41411},{\"end\":41444,\"start\":41423},{\"end\":41458,\"start\":41444},{\"end\":41468,\"start\":41458},{\"end\":41481,\"start\":41468},{\"end\":41823,\"start\":41811},{\"end\":41838,\"start\":41823},{\"end\":41847,\"start\":41838},{\"end\":41860,\"start\":41847},{\"end\":41870,\"start\":41860},{\"end\":41886,\"start\":41870},{\"end\":42238,\"start\":42220},{\"end\":42250,\"start\":42238},{\"end\":42270,\"start\":42250},{\"end\":42283,\"start\":42270},{\"end\":42530,\"start\":42514},{\"end\":42554,\"start\":42530},{\"end\":42572,\"start\":42554},{\"end\":42957,\"start\":42940},{\"end\":43118,\"start\":43105},{\"end\":43131,\"start\":43118},{\"end\":43146,\"start\":43131},{\"end\":43162,\"start\":43146},{\"end\":43180,\"start\":43162},{\"end\":43196,\"start\":43180},{\"end\":43211,\"start\":43196},{\"end\":43636,\"start\":43620},{\"end\":43652,\"start\":43636},{\"end\":43661,\"start\":43652},{\"end\":43675,\"start\":43661},{\"end\":43698,\"start\":43675},{\"end\":43709,\"start\":43698},{\"end\":43728,\"start\":43709},{\"end\":44447,\"start\":44435},{\"end\":44460,\"start\":44447},{\"end\":44473,\"start\":44460},{\"end\":44484,\"start\":44473},{\"end\":44497,\"start\":44484},{\"end\":44511,\"start\":44497},{\"end\":44524,\"start\":44511},{\"end\":44544,\"start\":44524},{\"end\":44556,\"start\":44544},{\"end\":44570,\"start\":44556},{\"end\":44585,\"start\":44570},{\"end\":45009,\"start\":44993},{\"end\":45023,\"start\":45009},{\"end\":45036,\"start\":45023},{\"end\":45053,\"start\":45036},{\"end\":45066,\"start\":45053},{\"end\":45081,\"start\":45066},{\"end\":45096,\"start\":45081},{\"end\":45114,\"start\":45096},{\"end\":45411,\"start\":45397},{\"end\":45421,\"start\":45411},{\"end\":45437,\"start\":45421},{\"end\":45451,\"start\":45437},{\"end\":45465,\"start\":45451},{\"end\":45835,\"start\":45824},{\"end\":45852,\"start\":45835},{\"end\":45868,\"start\":45852},{\"end\":45880,\"start\":45868},{\"end\":45891,\"start\":45880},{\"end\":45908,\"start\":45891},{\"end\":46218,\"start\":46205},{\"end\":46234,\"start\":46218},{\"end\":46247,\"start\":46234},{\"end\":46264,\"start\":46247},{\"end\":46282,\"start\":46264},{\"end\":46295,\"start\":46282},{\"end\":46311,\"start\":46295},{\"end\":46322,\"start\":46311},{\"end\":46333,\"start\":46322},{\"end\":46351,\"start\":46333},{\"end\":46364,\"start\":46351},{\"end\":46378,\"start\":46364},{\"end\":46404,\"start\":46378},{\"end\":46415,\"start\":46404},{\"end\":46431,\"start\":46415},{\"end\":46443,\"start\":46431},{\"end\":46456,\"start\":46443},{\"end\":46470,\"start\":46456},{\"end\":46486,\"start\":46470},{\"end\":46501,\"start\":46486},{\"end\":46521,\"start\":46501},{\"end\":46527,\"start\":46521},{\"end\":47484,\"start\":47471},{\"end\":47492,\"start\":47484},{\"end\":47507,\"start\":47492},{\"end\":47522,\"start\":47507},{\"end\":47530,\"start\":47522},{\"end\":47536,\"start\":47530},{\"end\":47784,\"start\":47771},{\"end\":47796,\"start\":47784},{\"end\":47809,\"start\":47796},{\"end\":47826,\"start\":47809},{\"end\":47848,\"start\":47826},{\"end\":47859,\"start\":47848},{\"end\":48238,\"start\":48227},{\"end\":48250,\"start\":48238},{\"end\":48258,\"start\":48250},{\"end\":48580,\"start\":48564},{\"end\":48596,\"start\":48580},{\"end\":48608,\"start\":48596},{\"end\":48617,\"start\":48608},{\"end\":48629,\"start\":48617},{\"end\":48643,\"start\":48629},{\"end\":48654,\"start\":48643},{\"end\":48667,\"start\":48654},{\"end\":48680,\"start\":48667}]", "bib_venue": "[{\"end\":32183,\"start\":32098},{\"end\":33506,\"start\":33406},{\"end\":35817,\"start\":35755},{\"end\":38611,\"start\":38585},{\"end\":40019,\"start\":39907},{\"end\":40949,\"start\":40932},{\"end\":42681,\"start\":42635},{\"end\":43911,\"start\":43816},{\"end\":46732,\"start\":46638},{\"end\":32096,\"start\":31996},{\"end\":32669,\"start\":32627},{\"end\":32972,\"start\":32901},{\"end\":33404,\"start\":33304},{\"end\":33897,\"start\":33865},{\"end\":34176,\"start\":34165},{\"end\":34408,\"start\":34328},{\"end\":34799,\"start\":34736},{\"end\":35103,\"start\":35011},{\"end\":35361,\"start\":35266},{\"end\":35753,\"start\":35676},{\"end\":36085,\"start\":36025},{\"end\":36372,\"start\":36288},{\"end\":36760,\"start\":36716},{\"end\":37038,\"start\":36992},{\"end\":37333,\"start\":37240},{\"end\":37647,\"start\":37606},{\"end\":37900,\"start\":37825},{\"end\":38242,\"start\":38181},{\"end\":38583,\"start\":38511},{\"end\":39127,\"start\":39072},{\"end\":39496,\"start\":39436},{\"end\":39905,\"start\":39789},{\"end\":40581,\"start\":40425},{\"end\":40930,\"start\":40870},{\"end\":41254,\"start\":41219},{\"end\":41537,\"start\":41497},{\"end\":41947,\"start\":41911},{\"end\":42218,\"start\":42159},{\"end\":42633,\"start\":42572},{\"end\":42978,\"start\":42957},{\"end\":43297,\"start\":43227},{\"end\":43814,\"start\":43728},{\"end\":44637,\"start\":44585},{\"end\":45163,\"start\":45114},{\"end\":45543,\"start\":45481},{\"end\":45822,\"start\":45737},{\"end\":46636,\"start\":46527},{\"end\":47555,\"start\":47550},{\"end\":47947,\"start\":47875},{\"end\":48296,\"start\":48258},{\"end\":48562,\"start\":48470}]"}}}, "year": 2023, "month": 12, "day": 17}