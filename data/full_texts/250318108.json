{"id": 250318108, "updated": "2022-10-28 15:59:33.75", "metadata": {"title": "Can OpenAI's Codex Fix Bugs?: An evaluation on QuixBugs", "authors": "[{\"first\":\"Julian\",\"last\":\"Prenner\",\"middle\":[\"Aron\"]},{\"first\":\"Hlib\",\"last\":\"Babii\",\"middle\":[]},{\"first\":\"Romain\",\"last\":\"Robbes\",\"middle\":[]}]", "venue": "2022 IEEE/ACM International Workshop on Automated Program Repair (APR)", "journal": "2022 IEEE/ACM International Workshop on Automated Program Repair (APR)", "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "OpenAI's Codex, a GPT-3like model trained on a large code corpus, has made headlines in and outside of academia. Given a short user-provided description, it is capable of synthesizing code snippets that are syntactically and semantically valid in most cases. In this work, we want to investigate whether Codex is able to localize and fix bugs, two important tasks in automated program repair. Our initial evaluation uses the multi-language QuixBugs benchmark (40 bugs in both Python and Java). We find that, despite not being trained for APR, Codex is surprisingly effective, and competitive with recent state of the art techniques. Our results also show that Codex is more successful at repairing Python than Java, fixing 50% more bugs in Python.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/icse-apr/PrennerBR22", "doi": "10.1145/3524459.3527351"}}, "content": {"source": {"pdf_hash": "6a684417089eb6f07ccb1ac5391c63ebacef821d", "pdf_src": "IEEE", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "b1f09ae815aef5a09efd8262de2d4f5d940bc2a3", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/6a684417089eb6f07ccb1ac5391c63ebacef821d.txt", "contents": "\nCan OpenAI's Codex Fix Bugs?\n\n\nJulian Aron Prenner prenner@inf.unibz.it \nHlib Babii hlib.babii@stud-inf.unibz.it \nRomain Robbes rrobbes@unibz.it \nJulian Aron Prenner \nHlib Babii \nRomain \n\nFree University of Bozen\nBolzano Italy\n\n\nFree University of Bozen-Bolzano\nItaly\n\n\nFree University of Bozen-Bolzano\nItaly\n\nCan OpenAI's Codex Fix Bugs?\n10.1145/3524459.3527351An evaluation on QuixBugs ACM Reference Format: Robbes. 2022. Can OpenAI's Codex Fix Bugs?: An evaluation on QuixBugs. In International Workshop on Automated Program Repair (APR'22), May 19, 2022, Pittsburgh, PA, USA. ACM, New York, NY, USA, 7 pages. https://automatic program repairdeep learningCodexQuixBugs\nOpenAI's Codex, a GPT-3 like model trained on a large code corpus, has made headlines in and outside of academia. Given a short userprovided description, it is capable of synthesizing code snippets that are syntactically and semantically valid in most cases. In this work, we want to investigate whether Codex is able to localize and fix bugs, two important tasks in automated program repair. Our initial evaluation uses the multi-language QuixBugs benchmark (40 bugs in both Python and Java). We find that, despite not being trained for APR, Codex is surprisingly effective, and competitive with recent state of the art techniques. Our results also show that Codex is more successful at repairing Python than Java, fixing 50% more bugs in Python.CCS CONCEPTS\u2022 Software and its engineering \u2192 Software creation and management.\n\nINTRODUCTION\n\nFinding and fixing bugs costs billions yearly [1] and takes up a considerable proportion of developer time [15]. The field of Automatic program repair (APR) attempts to develop tools that can automatically find and fix bugs in software. Many existing APR tools follow a test-driven approach: bugs need to be exposed by a failing test case and the repaired program must pass all tests, including the previously failing ones. A variety of different APR approaches have been proposed in the recent years: i) using genetic-programming (e.g., GenProg [8] or ARJA [29]), ii) using repair patterns (such as Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. APR '22, May 19, 2022 [13], ELIXIR [24] or TBar [17]), iii) code retrieval-based approaches (e.g., ssFix [26] or LSRepair [18]), iv) or using deep learning (e.g., SequenceR [4], HOPPITY [6], CoCoNuT [19] or CURE [10]).\n\nWhile there has been some promising work using deep neural networks for program repair, several avenues of research are yet to explore in this area. In particular, Kaplan et al. [12] observed that Transformer-based language models are subject to several scaling laws, including that the performance of a language model has a power law relationship with model size, dataset size, and amount of computing power invested in training the language model, as long as none of these factors is a bottleneck. Other laws show that model performance during training is strongly correlated with out of distribution performance, and that larger models require less optimization steps and data points than smaller models to achieve the same performance. Taken together, these laws provide evidence for training very large language models.\n\nOne such model is GPT-3, an auto-regressive Transformer language model with 175 billion parameters, which has set a new state of the art in many human language understanding tasks [2]. Unlike previous models (such as BERT [5]) that are pre-trained on unlabeled text and fine-tuned on a target task, GPT-3's size allows it to achieve this performance without fine-tuning on the target task, solely through its pre-training as a language model (which consists in \"guessing the next word\" on a large amount of text). Adapting GPT-3 to a particular task is done in a few-shot setting by feeding a task description and a handful of examples (in most cases ranging between 3 and 10) of the task to the model at inference time, and asking the model to complete the text. In some cases, just feeding the task description without examples (zero-shot setting) shows very good performance. Thus, instead of gathering new data and fine-tuning the model on it, the user's task shifts to defining a prompt that triggers the desired behavior in the language model.\n\nRecently, OpenAI 1 released Codex [3], a GPT-3 like model targeted towards code tasks. Codex is at the core of Copilot 2 , GitHub's AI coding assistant that provides code completion in Visual Studio Code. In OpenAI demos, Codex is able to synthesize whole functions from a short description. Codex is mostly used in a zero-shot setting: the input is comprised of a short task description and a final prompt. Codex then generates code that \"naturally\" \"completes\" the prompt.\n\nIn this paper we investigate whether Codex can be applied to the challenging task of Automatic Program Repair. Rather than synthesizing code from natural language problem description, we ask: 1) whether Codex shows promise in repairing buggy code, a task that it was not trained on, and 2) which types of prompts yield the best performance (we experiment with 5 different configurations). Since, unlike the majority of APR tools, Codex supports multiple programming languages, we evaluate performance on two programming languages. This multi-lingual requirement leads us to choose the QuixBugs [16] program repair benchmark to conduct this initial investigation in Codex's performance for APR. QuixBugs contains buggy Python and Java implementations of 40 classical computer science algorithms, such as counting bits in an integer, calculating the Levenshtein distance or finding the shortest path in a graph (see Table 2 for the full list of algorithms).\n\nWe further discuss most common model mistakes and compare repair performance between Python and Java and between Codex and previous neural repair approaches. We find that, especially considering it was not trained on the task, Codex is surprisingly competitive with three recent APR tools (CURE [10] and DeepDebug [7] released in 2021, CoCoNut [19], released in 2020), and is in the lead for Python. We have publicly released all our inputs and Codex' outputs 3 .\n\n\nBACKGROUND 2.1 Automatic Program Repair\n\nThe goal of Automatic Program Repair (APR) is to automatically fix software defects. Traditionally, program repair tools receive as input a faulty program along with a test suite of at least one fault-exposing test case. Repair is usually preceded by fault localization, which identifies and ranks likely buggy locations in the code. So-called generate-and-validate approaches employ a search-like strategy: previously localized locations are repeatedly modified until all previously failing test cases pass. In addition to that, originally passing test cases should also pass. The above-mentioned modification can be made in different ways. For instance, GenProg [8] or ARJA [29] use genetic programming while PAR [13], ELIXIR [24] or TBar [17] apply pre-defined transformation rules (repair patterns) to the code.\n\nAn alternative line of research leverages formal methods such as satisfiability modulo theories (SMT) or symbolic execution to synthesize expressions that, after being substituted into the code, make all test cases pass. This includes, for example, tools like Nopol [27], Angelix [20] or SemFix [21].\n\nIn recent years, the application of deep neural networks for APR has attracted increasing interest in the community. Different models and architectures have been explored: SequenceR [4] uses a LSTM network, HOPPITY [6] combines an LSTM with a Graph Neural Network, CoCoNuT [19] relies on a convolutional seq2seq model; finally, CURE [10] employs a GPT-based language model. Deep learning-based methods do not strictly require bug-exposing test cases for the repair process. This is a considerable advantage as recent work suggests that such test cases are rare and often nonexistent [14,22]. Moreover, such models can be trained to jointly localize and fix bugs (e.g., HOPPITY), eliminating the need for an external fault localization system.\n\nIn this work, the model (Codex) is used in a way that does neither require running test cases during the repair process (test cases are executed for evaluation purposes only) nor requires a separate fault localization step. 3 https://sandbox.zenodo.org/record/934361\n\n\nSome Context on Codex\n\nCodex [3] is a large deep learning-based language model developed by OpenAI. Like GPT-3, which Codex is based on, it builds on the Transformer [25], a successful neural network architecture, but, following the scaling laws, at a very large scale. Codex' size and the amount of data used to train it are unprecedented in Software Engineering: it has 12 billion parameters and was trained on 54 million GitHub repositories. Being a language model, Codex was trained to complete (partial) input in a meaningful way. Training models of the size of Codex goes far beyond the capabilities of single GPUs and can currently only be trained by large organizations or corporations. However, large language models have been shown to be able to perform a range of different tasks [23] and can, once trained, be shared and used for different purposes. Codex supports a variety of programming languages including Python, Java, JavaScript, TypeScript, and others. Compared to GPT-3, Codex is smaller, but has a larger input window (4096 vs 2048 tokens), in order to generate code from a larger context.\n\nSimilarly to GPT-3, Codex is versatile: it is capable of carrying out several different tasks, as long as the tasks can be framed as a \"completion task\", in a zero-shot or few-shot setting. Thus, instead of providing data and re-training the model on it, a user of Codex engages in prompt engineering: finding out which prompt (possibly with examples) yields the best performance for the task. It's worth noting that this shift from fine-tuning to prompt engineering is welcome, if only for the reason that fine-tuning the model is out of reach for the vast majority of people due to its sheer size. Rather than running on a user's machine, the model runs in the cloud.\n\nExamples of tasks where Codex can be applied are: intelligent code completion, where the input is code that should be completed (a version of Codex powers GitHub Copilot, a code completion plugin for Visual Studio Code); function synthesis, where the input is a function name and a documentation comment and the output is a code snippet; code explanation, where the input is a code snippet, and the output is a comment; and programming language translation (e.g., C++ to Python), where the input is a code snippet, followed by a comment indicating the language to translate to.\n\n\nThe QuixBugs Dataset\n\nIn all of our experiments we rely on QuixBugs [16], a benchmark of 40 buggy algorithm implementations, including their correct versions and test cases. An important reason for choosing QuixBugs was bilingualism: all algorithms are implemented in Python and Java. This allows to compare Codex' repair capabilities between different languages. Second, the programs in QuixBugs are relatively short (9-67 lines of code [28]) and thus fit Codex' input window of 4096 tokens.\n\nUnlike the Python versions, which contain docstrings with short descriptions of the respective algorithms, Java versions come without descriptive comments. Figure 1 shows a buggy implementation of the Euclidean algorithm, taken from the QuixBugs dataset, in both languages. As can be seen, the Python version includes a docstring describing the algorithm and specifying input and output behavior. A in-depth analysis of the QuixBugs dataset can be found in Ye et al. [28]. \n\n\nMETHODOLOGY 3.1 Prompt Engineering\n\nSince the only way to interact with Codex is via the prompt that it is given, we experiment with several different input configurations. All configurations use a variation of the following template (Python version):\n\n# ## fix the bug in the following function <buggy function and/or docstring here> # ## fixed function Code only. We simply input the buggy function (without the docstring in Python) in the template.\n\nCode with hint. To simulate a more precise bug localization, in this configuration we add hint comments. Specifically, we put the comment ### bug is here (or // bug is here for Java) before any buggy code line.\n\nCode with docstring (Python). We input the buggy code along with the original docstring, which describes the correct behavior of the function. Note that some docstrings contain examples. For Java, docstrings are not available.\n\nDocstring only (Python). This corresponds to the default usage of Codex, in which it synthesizes a full algorithm implementation, and thus acts as a baseline.\n\n\nCorrect code (Python).\n\nTo see if Codex would break already correct code, in this configuration we input the bug-free ground-truth program, instead of the buggy one; ideally, Codex would repeat the code unchanged. We slightly alter the input format changing the first line to ### fix a possible bug in the following function, indicating that the input might be bug-free.\n\n\nInput-output examples.\n\nFor seven Python bugs that no configuration involving code (i.e., excluding the docstring-only configuration) could correctly fix, we additionally tried including inputoutput examples derived from the corresponding test cases as an additional specification. The input-output examples are given in a docstring-like comment and follow the general format. We include all QuixBugs test cases associated to a program, except those exceeding a certain size (120 characters), so as not to produce an exceedingly long docstring. Figure 2 shows the full prompt with such examples. We set Codex' parameters as shown in Table 1. We did not yet systematically investigate the effect of these parameters on repair success, as our evaluation involves a significant manual step. The temperature and top-p parameters control the randomness of the model: a higher temperature or a lower top-p yield more diverse output. The Codex documentation recommends to set temperature to zero or a low value and not to vary both, temperature and top-p. We set the temperature to zero and top-p to one, which lowers diversity but ought to give high robustness. The frequency and presence penalties prevent the model from outputing the same # ## fix the a bug in the following function \"\"\" Examples :\n\n\nCodex Parameters\n\n>>> pascal (1)  . . . \n\n\n# ## fixed function\n\n\nEvaluation\n\nFor each configuration and language we manually evaluated the output of Codex, using the following procedure:\n\n\u2022 When Codex output multiple functions we only considered the first and discarded the remaining output. \u2022 If the output exactly matched the correct ground-truth patch, we considered it correct. \u2022 If the output exactly matched the input (i.e., no changes have been made by the model), we considered it incorrect. \u2022 When output was neither identical to the ground truth nor the original buggy version, we ran the associated test cases. \u2022 If any test failed, the output was considered incorrect.\n\n\u2022 If all tests passed, we decided whether the fix was semantically equivalent to the ground truth.\n\nWe observed outputs that passed all test cases but were semantically incorrect only for the kheapsort bug, where QuixBugs' test cases do not check an edge case: the tests simply check for sortedness of the program output; however, it should only be sorted up to the th largest element.\n\nAcceptable variations. Since Codex is generating code as a language model, and is not explicitly trained for program repair, we were more lenient in a few cases. In particular, it is natural for a source code language model to try to avoid defining multiple functions or methods with the same name. Thus, if the output of Codex was a function or method with a slightly different name, but otherwise correct, this was not considered an error; we assume that post-processing could ensure such a rename is done automatically. On the other hand, in several cases, Codex simply repeated the input program (bug included); this was, of course, deemed incorrect output.\n\nWhen providing only the docstring, for four graph related problems (e.g., breath-first-search or detect-cycle), Codex assumed that the attributes pointing to the next node or child nodes should be named next and children, respectively, while tests assumed it to be named successor and successors. This means tests failed despite \"reasonable\" output, as there is no way for Codex to know the attribute name expected by the tests. In Table 2 we marked such cases with and provided a separate total count in parentheses. We considered this as semantically correct, as this is a reasonable assumption and the proper name was not specified in the input. Table 3 compares Codex's performance with recent previous work. We report results from the literature from three recent neural APR approaches: CoCoNut [19] uses the Neural Machine Translation (NMT) paradigm of program repair, with an ensemble of CNNs, and supports multiple languages. DeepDebug [7] is a large pre-trained Transformer that also uses the NMT paradigm (Python only): the model is fine-tuned on artificially generated bug-introducing commits, and also stack traces and program context. CURE builds on CoCoNut, adding a pre-trained language model (on Java Code) and filters suggestions based on additional context from static analysis [10]. Note that the assessment for correctness was done manually and evaluation criteria might slightly differ between these works.\n\n\nRESULTS\n\n\nOverall Performance\n\nCodex correctly fixed considerably more Python than Java bugs (up to 23 Python bugs, only 14 Java bugs), indicating that it can handle Python much better than Java; OpenAI does state that Codex is more capable in Python than other languages. Moreover, it is intriguing to see that Codex, without explicit training on the task, outperforms CoCoNuT and DeepDebug on Python, and outperforms CoCoNut in Java. While CURE does outperform Codex in Java, Codex outperforms the only other multi-lingual APR tool (CoCoNut).\n\nCodex is surprisingly competitive with recent work, and its performance is considerably better for Python than Java. Table 2 provides detailed results for each bug and configuration. For many bugs, the choice of prompt matters significantly. In fact, only 6 bugs are fixed in all scenarios and all languages. On the other hand, the prompts do complement each other: only 8 bugs are not fixed by any of the prompts.\n\n\nPerformance of different prompts\n\nHints are not effective. Providing a hint comment for precise fault localization was overall not effective in our experiments. For both Python and Java, some bugs were fixed only with hints, but for others adding the hint was harmful. Overall, for Java the total number of fixed bugs was the same, while it decreased from 21 to 19 in Python. However, hints led Codex to correctly repair two bugs that could not be successfully repaired otherwise (shunting-yard and minimum-spanning-tree).\n\nSynthesis from docstrings. Table 2 shows that only providing the Python docstrings, Codex is able to synthesize a correct solution for 45% of the problems in QuixBugs. Providing buggy code as a starting point and asking to model to fix it led to five more (+28%) correct program implementations.\n\n\nAdditional input-output examples.\n\nFor the seven bugs that no other configuration could solve, a single one (subsequences) was successfully repaired when adding input-output examples from test cases.\n\nCorrect code. When requested to fix a possible bug in correct code, Codex broke six of the total 40 programs. In two cases, Codex slightly altered the input program, preserving correctness, however. \n\n\nLIMITATIONS AND FUTURE WORK\n\nCodex is a very large language model, that has shown impressive ability in completing source code. In this work, we have evaluatedand found surprisingly competitive-the performance of Codex as an APR tool, with no further training on the task. While this initial evaluation of Codex as an APR tool is promising, it has various limitations.\n\nMore annotators. The correctness of the code output was assessed by a single annotator. Not only is manual evaluation subjective, it is also prone to mistakes. We hope that we will be able to provide a more reliable evaluation in the future, involving at least two annotators. In many cases, however, Codex' output was either unchanged input code or matched the ground-truth, slightly limiting potential annotator bias.\n\nAdditional benchmarks and languages. Currently our evaluation is limited to a single benchmark and two programming languages. Extending this study to benchmarks that involve more complex codebases (e.g., Defects4J [11] or additional programming languages (e.g., BugsJS [9], a JavaScript benchmark) would provide additional interesting insights into Codex' repair capabilities.\n\nData leakage. Codex was trained on very large amounts of code; only OpenAI staff can know with certainty which repositories were included. We cannot rule out that the correct ground-truth programs were in Codex' training set. This issue is very difficult to address. There are however mitigating factors: First, if present, these versions would constitute a tiny portion of the training data (54 million repositories). Second, if the correct program versions were in the training set, so would, very likely, also be the incorrect versions, without labels of which version is correct or incorrect. Moreover, a preliminary study of Codex for GitHub Copilot, found that while the model can indeed repeat data from the training set, this was rare (less than 0.1% of the cases), concerned code that was cloned many times, and happened mostly when the context was nearly empty [30]. Finally, Codex was never specifically trained for the task of repairing or localizing bugs.\n\nMore Automation. For this study, we had to perform several manual steps to validate the correctness of the proposals. This includes removing extraneous output from Codex, and making sure the function/method name was the one expected by the tests. Automating these tasks would make the process significantly smoother.\n\nTesting multiple outputs. Given the lack of automation, we tried a single completion from Codex for each problem and prompt. With more automation, we would be able to try multiple outputs from Codex (by increasing the temperature). Evaluating more than one output significantly increased the performance of Codex for program synthesis (from 29 up to 70% [3]), so this could help APR as well.\n\nFine-Tuning. While the most common use case for Codex is to use it directly after pre-training, a fine-tuning API is available for GPT-3. If such an API is made available for Codex, this would be worthwhile exploring to improve performance.\n\nFigure 1 :\n1Buggy versions of the algorithm calculating the greatest common divisor between two integers in Python and Java. The recursive call should read gcd(b, a % b).\n\nFigure 2 :\n2Prompt with input-output examples in the docstring. Function body omitted for brevity. tokens repeatedly. Since large portions of the input (everything except the buggy line) should in fact be repeated, we do not use such a penalty.\n\n\n, Pittsburgh, PA, USA \u00a9 2022 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 978-1-4503-9285-3/22/05. . . $15.00 https://doi.org/10.1145/3524459.3527351PAR \n\nTable 1 :\n1Used Codex parameters.Parameter \nValue \n\nEngine \ndavinci-codex \nTemperature \n0 \nMax Tokens \n1024 \nTop-p \n1.0 \nFrequency Penalty \n0.0 \nPresence Penalty \n0.0 \nStop \n'###', '///' \n\n\n\nTable 2 :\n2List of bugs that Codex could fix successfully ().Python \nJava \n\ncode + \ndocstr. \n\ncode \nonly \n\ncode + \nhint \n\ndocstr. \nonly \n\ncorrect \ncode \ncode \ncode + \nhint \n\nbitcount \n\n\n\n\n\n\n\nbreadth-first-search \n\n\n\n\n\n\n\nbucketsort \n\n\n\n\n\n\n\ndepth-first-search \n\n\n\n\n\n\n\ndetect-cycle \n\n\n\n\n\n\n\nfind-first-in-sorted \n\n\n\n\n\n\n\nfind-in-sorted \n\n\n\n\n\n\n\nflatten \n\n\n\n\n\n\n\ngcd \n\n\n\n\n\n\n\nget-factors \n\n\n\n\n\n\n\nhanoi \n\n\n\n\n\n\n\nis-valid-parenthesization \n\n\n\n\n\n\n\nkheapsort \n\n\n\n\n\n\n\nknapsack \n\n\n\n\n\n\n\nkth \n\n\n\n\n\n\n\nlcs-length \n\n\n\n\n\n\n\nlevenshtein \n\n\n\n\n\n\n\nlis \n\n\n\n\n\n\n\nlongest-common-subsequence \n\n\n\n\n\n\n\nmax-sublist-sum \n\n\n\n\n\n\n\nmergesort \n\n\n\n\n\n\n\nminimum-spanning-tree \n\n\n\n\n\n\n\nnext-palindrome \n\n\n\n\n\n\n\nnext-permutation \n\n\n\n\n\n\n\npascal \n\n\n\n\n\n\n\npossible-change \n\n\n\n\n\n\n\npowerset \n\n\n\n\n\n\n\nquicksort \n\n\n\n\n\n\n\nreverse-linked-list \n\n\n\n\n\n\n\nrpn-eval \n\n\n\n\n\n\n\nshortest-path-length \n\n\n\n\n\n\n\nshortest-path-lengths \n\n\n\n\n\n\n\nshortest-paths \n\n\n\n\n\n\n\nshunting-yard \n\n\n\n\n\n\n\nsieve \n\n\n\n\n\n\n\nsqrt \n\n\n\n\n\n\n\nsubsequences \n\n\n\n\n\n\n\nto-base \n\n\n\n\n\n\n\ntopological-ordering \n\n\n\n\n\n\n\nwrap \n\n\n\n\n\n\n\n\nTotal \n23 \n21 \n19 \n14 (18) \n34 \n14 \n14 \n\n\n\nTable 3 :\n3Comparison with previous work. Number of correctly fixed bugs for the Java and Python version of QuixBugs (out of 40).Prompts have a major effect on Codex' bug fixing abilityJava Python \n\nDeepDebug [7] \n-\n21 \nCoCoNuT [19] \n13 \n19 \nCURE [10] \n26 \n-\nCodex \n14 \n23/21 1 \n\n1 with and without docstring, respec-\ntively \n\n\nACKNOWLEDGMENTSWe would like to thank OpenAI for providing access to their Codex model.\nReversible Debugging Software \"Quantify the Time and Cost Saved Using Reversible Debuggers. Tom Britton, Lisa Jeng, Graham Carver, Paul Cheak, Tom Britton, Lisa Jeng, Graham Carver, and Paul Cheak. Reversible Debugging Software \"Quantify the Time and Cost Saved Using Reversible Debuggers\".\n\nTom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Ilya Sutskever, and Dario Amodei. Language Models are Few-Shot Learners. Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec RadfordTom B. Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu, Clemens Winter, Christopher Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language Models are Few-Shot Learners. URL http://arxiv.org/abs/2005.14165.\n\nMark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde De Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Ilya Sutskever, and Wojciech Zaremba. Evaluating Large Language Models Trained on Code. Suchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec RadfordDave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin; Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlishMark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde de Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, Alex Ray, Raul Puri, Gretchen Krueger, Michael Petrov, Heidy Khlaaf, Girish Sastry, Pamela Mishkin, Brooke Chan, Scott Gray, Nick Ryder, Mikhail Pavlov, Alethea Power, Lukasz Kaiser, Mohammad Bavarian, Clemens Winter, Philippe Tillet, Felipe Petroski Such, Dave Cummings, Matthias Plappert, Fotios Chantzis, Elizabeth Barnes, Ariel Herbert-Voss, William Hebgen Guss, Alex Nichol, Alex Paino, Nikolas Tezak, Jie Tang, Igor Babuschkin, Suchir Balaji, Shantanu Jain, William Saunders, Christopher Hesse, Andrew N. Carr, Jan Leike, Josh Achiam, Vedant Misra, Evan Morikawa, Alec Radford, Matthew Knight, Miles Brundage, Mira Murati, Katie Mayer, Peter Welinder, Bob McGrew, Dario Amodei, Sam McCandlish, Ilya Sutskever, and Wojciech Zaremba. Evaluating Large Language Models Trained on Code, . URL http://arxiv.org/abs/2107.03374.\n\nSequenceR: Sequence-to-Sequence Learning for End-to-End Program Repair. Zimin Chen, Steve Kommrusch, Michele Tufano, Louis-No\u00ebl Pouchet, Denys Poshyvanyk, Martin Monperrus, Zimin Chen, Steve Kommrusch, Michele Tufano, Louis-No\u00ebl Pouchet, Denys Poshyvanyk, and Martin Monperrus. SequenceR: Sequence-to-Sequence Learning for End-to-End Program Repair, . URL http://arxiv.org/abs/1901.01808.\n\nBERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. URL http://arxiv.org/abs/1810.04805.\n\nHOPPITY: LEARNING GRAPH TRANSFORMATIONS TO DETECT AND FIX BUGS IN PROGRAMS. Elizabeth Dinella, Hanjun Dai, Ziyang Li, Mayur Naik, Le Song, Ke Wang, Elizabeth Dinella, Hanjun Dai, Ziyang Li, Mayur Naik, Le Song, and Ke Wang. HOPPITY: LEARNING GRAPH TRANSFORMATIONS TO DETECT AND FIX BUGS IN PROGRAMS. URL https://iclr.cc/virtual_2020/poster_SJeqs6EFvB.html.\n\nDeepDebug: Fixing Python Bugs Using Stack Traces, Backtranslation, and Code Skeletons. Dawn Drain, Colin B Clement, Guillermo Serrato, Neel Sundaresan, Dawn Drain, Colin B. Clement, Guillermo Serrato, and Neel Sundaresan. DeepDe- bug: Fixing Python Bugs Using Stack Traces, Backtranslation, and Code Skeletons. URL http://arxiv.org/abs/2105.09352.\n\nGenProg: A Generic Method for Automatic Software Repair. C Le Goues, T Nguyen, S Forrest, W Weimer, 10.1109/TSE.2011.10438C. Le Goues, T. Nguyen, S. Forrest, and W. Weimer. GenProg: A Generic Method for Automatic Software Repair. 38(1):54-72. ISSN 1939-3520. doi:10.1109/TSE.2011.104.\n\nBugsJS: A Benchmark of JavaScript Bugs. P\u00e9ter Gyimesi, B\u00e9la Vancsics, Andrea Stocco, Davood Mazinanian, Arp\u00e1d Beszedes, Rudolf Ferenc, Ali Mesbah, 10.1109/ICST.2019.0001912th IEEE Conference on Software Testing, Validation and Verification (ICST). P\u00e9ter Gyimesi, B\u00e9la Vancsics, Andrea Stocco, Davood Mazinanian, Arp\u00e1d Beszedes, Rudolf Ferenc, and Ali Mesbah. BugsJS: A Benchmark of JavaScript Bugs. In 2019 12th IEEE Conference on Software Testing, Validation and Verification (ICST), pages 90-101. doi:10.1109/ICST.2019.00019.\n\nCURE: Code-Aware Neural Machine Translation for Automatic Program Repair. Nan Jiang, Thibaud Lutellier, Lin Tan, Nan Jiang, Thibaud Lutellier, and Lin Tan. CURE: Code-Aware Neural Machine Translation for Automatic Program Repair. URL http://arxiv.org/abs/2103.00073.\n\nDefects4J: A database of existing faults to enable controlled testing studies for Java programs. Ren\u00e9 Just, Darioush Jalali, Michael D Ernst, 10.1145/2610384.2628055Proceedings of the 2014 International Symposium on Software Testing and Analysis, ISSTA 2014. the 2014 International Symposium on Software Testing and Analysis, ISSTA 2014Association for Computing MachineryRen\u00e9 Just, Darioush Jalali, and Michael D. Ernst. Defects4J: A database of existing faults to enable controlled testing studies for Java programs. In Proceedings of the 2014 International Symposium on Software Testing and Analysis, ISSTA 2014, pages 437-440. Association for Computing Machinery. ISBN 978-1-4503-2645-2. doi:10.1145/2610384.2628055. URL http://doi.org/10.1145/2610384.2628055.\n\nJared Kaplan, Sam Mccandlish, Tom Henighan, B Tom, Benjamin Brown, Rewon Chess, Scott Child, Alec Gray, Jeffrey Radford, Dario Wu, Amodei, arXiv:2001.08361Scaling laws for neural language models. arXiv preprintJared Kaplan, Sam McCandlish, Tom Henighan, Tom B Brown, Benjamin Chess, Rewon Child, Scott Gray, Alec Radford, Jeffrey Wu, and Dario Amodei. Scaling laws for neural language models. arXiv preprint arXiv:2001.08361, 2020.\n\nAutomatic patch generation learned from human-written patches. Dongsun Kim, Jaechang Nam, Jaewoo Song, Sunghun Kim, 978-1-4673-3076-3Proceedings of the 2013 International Conference on Software Engineering, ICSE '13. the 2013 International Conference on Software Engineering, ICSE '13IEEE PressDongsun Kim, Jaechang Nam, Jaewoo Song, and Sunghun Kim. Automatic patch generation learned from human-written patches. In Proceedings of the 2013 International Conference on Software Engineering, ICSE '13, pages 802-811. IEEE Press. ISBN 978-1-4673-3076-3.\n\niFixR: Bug report driven program repair. Anil Koyuncu, Kui Liu, Tegawend\u00e9 F Bissyand\u00e9, Dongsun Kim, Martin Monperrus, Jacques Klein, Yves Le Traon, 10.1145/3338906.3338935Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE 2019. the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE 2019Association for Computing MachineryAnil Koyuncu, Kui Liu, Tegawend\u00e9 F. Bissyand\u00e9, Dongsun Kim, Martin Mon- perrus, Jacques Klein, and Yves Le Traon. iFixR: Bug report driven program repair. In Proceedings of the 2019 27th ACM Joint Meeting on European Soft- ware Engineering Conference and Symposium on the Foundations of Software Engineering, ESEC/FSE 2019, pages 314-325. Association for Computing Ma- chinery. ISBN 978-1-4503-5572-8. doi:10.1145/3338906.3338935. URL http: //doi.org/10.1145/3338906.3338935.\n\nMaintaining mental models: A study of developer work habits. Thomas D Latoza, Gina Venolia, Robert Deline, 10.1145/1134285.1134355Proceeding of the 28th International Conference on Software Engineering -ICSE '06. eeding of the 28th International Conference on Software Engineering -ICSE '06ACM Press492Thomas D. LaToza, Gina Venolia, and Robert DeLine. Maintaining mental mod- els: A study of developer work habits. In Proceeding of the 28th International Conference on Software Engineering -ICSE '06, page 492. ACM Press. ISBN 978-1- 59593-375-1. doi:10.1145/1134285.1134355. URL http://portal.acm.org/citation. cfm?doid=1134285.1134355.\n\nQuixBugs: A multi-lingual program repair benchmark set based on the quixey challenge. Derrick Lin, James Koppel, Angela Chen, Armando Solar-Lezama, 10.1145/3135932.3135941Proceedings Companion of the 2017 ACM SIGPLAN International Conference on Systems, Programming, Languages, and Applications: Software for Humanity. Companion of the 2017 ACM SIGPLAN International Conference on Systems, Programming, Languages, and Applications: Software for HumanityAssociation for Computing MachineryDerrick Lin, James Koppel, Angela Chen, and Armando Solar-Lezama. QuixBugs: A multi-lingual program repair benchmark set based on the quixey challenge. In Proceedings Companion of the 2017 ACM SIGPLAN International Conference on Systems, Programming, Languages, and Applications: Software for Humanity, SPLASH Companion 2017, pages 55-56. Association for Computing Machinery. ISBN 978-1-4503-5514-8. doi:10.1145/3135932.3135941. URL http://doi.org/10. 1145/3135932.3135941.\n\nTBar: Revisiting template-based automated program repair. Kui Liu, Anil Koyuncu, Dongsun Kim, Tegawend\u00e9 F Bissyand\u00e9, 10.1145/3293882.3330577Proceedings of the 28th ACM SIGSOFT International Symposium on Software Testing and Analysis, ISSTA 2019. the 28th ACM SIGSOFT International Symposium on Software Testing and Analysis, ISSTA 2019Association for Computing MachineryKui Liu, Anil Koyuncu, Dongsun Kim, and Tegawend\u00e9 F. Bissyand\u00e9. TBar: Revisiting template-based automated program repair. In Proceedings of the 28th ACM SIGSOFT International Symposium on Software Testing and Analysis, ISSTA 2019, pages 31-42. Association for Computing Machinery, . ISBN 978-1-4503-6224- 5. doi:10.1145/3293882.3330577. URL http://doi.org/10.1145/3293882.3330577.\n\nLSRepair: Live Search of Fix Ingredients for Automated Program Repair. Kui Liu, Anil Koyuncu, Kisub Kim, Dongsun Kim, Tegawend\u00e9 F Bissyand\u00e9, 10.1109/APSEC.2018.0008525th Asia-Pacific Software Engineering Conference (APSEC). Kui Liu, Anil Koyuncu, Kisub Kim, Dongsun Kim, and Tegawend\u00e9 F. Bissyand\u00e9. LSRepair: Live Search of Fix Ingredients for Automated Program Repair. In 2018 25th Asia-Pacific Software Engineering Conference (APSEC), pages 658-662, . doi:10.1109/APSEC.2018.00085.\n\nCoCoNuT: Combining context-aware neural translation models using ensemble for program repair. Thibaud Lutellier, Hung Viet Pham, Lawrence Pang, Yitong Li, Moshi Wei, Lin Tan, 10.1145/3395363.3397369Proceedings of the 29th ACM SIGSOFT International Symposium on Software Testing and Analysis. the 29th ACM SIGSOFT International Symposium on Software Testing and AnalysisAssociation for Computing Machinery2020Thibaud Lutellier, Hung Viet Pham, Lawrence Pang, Yitong Li, Moshi Wei, and Lin Tan. CoCoNuT: Combining context-aware neural translation models using ensem- ble for program repair. In Proceedings of the 29th ACM SIGSOFT International Sym- posium on Software Testing and Analysis, ISSTA 2020, pages 101-114. Association for Computing Machinery. ISBN 978-1-4503-8008-9. doi:10.1145/3395363.3397369. URL http://doi.org/10.1145/3395363.3397369.\n\nAngelix: Scalable Multiline Program Patch Synthesis via Symbolic Analysis. S Mechtaev, J Yi, A Roychoudhury, 10.1145/2884781.28848072016 IEEE/ACM 38th International Conference on Software Engineering (ICSE). S. Mechtaev, J. Yi, and A. Roychoudhury. Angelix: Scalable Multiline Pro- gram Patch Synthesis via Symbolic Analysis. In 2016 IEEE/ACM 38th International Conference on Software Engineering (ICSE), pages 691-701. doi:10.1145/2884781.2884807.\n\nSemFix: Program repair via semantic analysis. Hoang Duong Thien Nguyen, Dawei Qi, Abhik Roychoudhury, Satish Chandra, 978-1-4673-3076-3Proceedings of the 2013 International Conference on Software Engineering, ICSE '13. the 2013 International Conference on Software Engineering, ICSE '13IEEE PressHoang Duong Thien Nguyen, Dawei Qi, Abhik Roychoudhury, and Satish Chan- dra. SemFix: Program repair via semantic analysis. In Proceedings of the 2013 International Conference on Software Engineering, ICSE '13, pages 772-781. IEEE Press. ISBN 978-1-4673-3076-3.\n\nExperience Report: How Effective is Automated Program Repair for Industrial Software?. Kunihiro Noda, Yusuke Nemoto, Keisuke Hotta, Hideo Tanida, Shinji Kikuchi, 10.1109/SANER48275.2020.90548292020 IEEE 27th International Conference on Software Analysis, Evolution and Reengineering (SANER). Kunihiro Noda, Yusuke Nemoto, Keisuke Hotta, Hideo Tanida, and Shinji Kikuchi. Experience Report: How Effective is Automated Program Re- pair for Industrial Software? In 2020 IEEE 27th International Conference on Software Analysis, Evolution and Reengineering (SANER), pages 612-616. doi:10.1109/SANER48275.2020.9054829.\n\nLanguage models are unsupervised multitask learners. Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, OpenAI blog. 189Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language models are unsupervised multitask learners. OpenAI blog, 1(8):9, 2019.\n\nElixir: Effective object-oriented program repair. R K Saha, Y Lyu, H Yoshida, M R Prasad, 10.1109/ASE.2017.811567532nd IEEE/ACM International Conference on Automated Software Engineering (ASE). R. K. Saha, Y. Lyu, H. Yoshida, and M. R. Prasad. Elixir: Effective object-oriented program repair. In 2017 32nd IEEE/ACM International Conference on Automated Software Engineering (ASE), pages 648-659. doi:10.1109/ASE.2017.8115675.\n\nAttention Is All You Need. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, Illia Polosukhin, Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention Is All You Need. URL http://arxiv.org/abs/1706.03762.\n\nLeveraging syntax-related code for automated program repair. Qi Xin, Steven P Reiss, Proceedings of the 32nd IEEE/ACM International Conference on Automated Software Engineering. the 32nd IEEE/ACM International Conference on Automated Software EngineeringIEEE PressQi Xin and Steven P. Reiss. Leveraging syntax-related code for automated program repair. In Proceedings of the 32nd IEEE/ACM International Conference on Automated Software Engineering, ASE 2017, pages 660-670. IEEE Press. ISBN 978-1-5386-2684-9.\n\nNopol: Automatic Repair of Conditional Statement Bugs in Java Programs. Jifeng Xuan, Matias Martinez, Favio Demarco, Maxime Cl\u00e9ment, Sebastian Lamelas, Thomas Durieux, Daniel Le Berre, Martin Monperrus, 10.1109/TSE.2016.256081143Jifeng Xuan, Matias Martinez, Favio Demarco, Maxime Cl\u00e9ment, Sebastian Lamelas, Thomas Durieux, Daniel Le Berre, and Martin Monperrus. Nopol: Automatic Repair of Conditional Statement Bugs in Java Programs. 43(1):34- 55. doi:10.1109/TSE.2016.2560811. URL https://hal.archives-ouvertes.fr/hal- 01285008.\n\nA comprehensive study of automatic program repair on the quixbugs benchmark. He Ye, Matias Martinez, Thomas Durieux, Martin Monperrus, 10.1016/j.jss.2020.110825Journal of Systems and Software. 171110825He Ye, Matias Martinez, Thomas Durieux, and Martin Monperrus. A com- prehensive study of automatic program repair on the quixbugs benchmark. Journal of Systems and Software, 171:110825, Jan 2021. ISSN 0164-1212. doi:10.1016/j.jss.2020.110825. URL http://dx.doi.org/10.1016/j.jss.2020.110825.\n\nARJA: Automated Repair of Java Programs via Multi-Objective Genetic Programming. Yuan Yuan, Wolfgang Banzhaf, 10.1109/TSE.2018.287464846Yuan Yuan and Wolfgang Banzhaf. ARJA: Automated Repair of Java Programs via Multi-Objective Genetic Programming. 46(10):1040-1067. ISSN 1939-3520. doi:10.1109/TSE.2018.2874648.\n\nResearch recitation: A first look at rote learning in github copilot suggestions. Albert Ziegler, Albert Ziegler. Research recitation: A first look at rote learning in github copi- lot suggestions, 2021. URL https://docs.github.com/en/github/copilot/research- recitation.\n", "annotations": {"author": "[{\"end\":73,\"start\":32},{\"end\":114,\"start\":74},{\"end\":146,\"start\":115},{\"end\":167,\"start\":147},{\"end\":179,\"start\":168},{\"end\":187,\"start\":180},{\"end\":228,\"start\":188},{\"end\":269,\"start\":229},{\"end\":310,\"start\":270}]", "publisher": null, "author_last_name": "[{\"end\":51,\"start\":44},{\"end\":84,\"start\":79},{\"end\":128,\"start\":122},{\"end\":166,\"start\":159},{\"end\":178,\"start\":173}]", "author_first_name": "[{\"end\":38,\"start\":32},{\"end\":43,\"start\":39},{\"end\":78,\"start\":74},{\"end\":121,\"start\":115},{\"end\":153,\"start\":147},{\"end\":158,\"start\":154},{\"end\":172,\"start\":168},{\"end\":186,\"start\":180}]", "author_affiliation": "[{\"end\":227,\"start\":189},{\"end\":268,\"start\":230},{\"end\":309,\"start\":271}]", "title": "[{\"end\":29,\"start\":1},{\"end\":339,\"start\":311}]", "venue": null, "abstract": "[{\"end\":1498,\"start\":673}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":1563,\"start\":1560},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":1625,\"start\":1621},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":2063,\"start\":2060},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":2076,\"start\":2072},{\"end\":2721,\"start\":2704},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":2726,\"start\":2722},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":2739,\"start\":2735},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":2752,\"start\":2748},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":2809,\"start\":2805},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":2826,\"start\":2822},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2876,\"start\":2873},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":2889,\"start\":2886},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":2903,\"start\":2899},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":2916,\"start\":2912},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":3102,\"start\":3098},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3929,\"start\":3926},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":3971,\"start\":3968},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":4834,\"start\":4831},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":5871,\"start\":5867},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":6529,\"start\":6525},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":6547,\"start\":6544},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":6578,\"start\":6574},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":7404,\"start\":7401},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":7417,\"start\":7413},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":7456,\"start\":7452},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":7469,\"start\":7465},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":7482,\"start\":7478},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":7824,\"start\":7820},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":7838,\"start\":7834},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":7853,\"start\":7849},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":8041,\"start\":8038},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":8074,\"start\":8071},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":8133,\"start\":8129},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":8443,\"start\":8439},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":8446,\"start\":8443},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":8825,\"start\":8824},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":8901,\"start\":8898},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":9039,\"start\":9035},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":9664,\"start\":9660},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":11304,\"start\":11300},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":11674,\"start\":11670},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":12197,\"start\":12193},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":17462,\"start\":17458},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":17605,\"start\":17602},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":17958,\"start\":17954},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":21285,\"start\":21281},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":21339,\"start\":21336},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":22320,\"start\":22316},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":23090,\"start\":23087}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":23538,\"start\":23367},{\"attributes\":{\"id\":\"fig_1\"},\"end\":23784,\"start\":23539},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":23979,\"start\":23785},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":24170,\"start\":23980},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":25232,\"start\":24171},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":25561,\"start\":25233}]", "paragraph": "[{\"end\":2918,\"start\":1514},{\"end\":3744,\"start\":2920},{\"end\":4795,\"start\":3746},{\"end\":5271,\"start\":4797},{\"end\":6228,\"start\":5273},{\"end\":6693,\"start\":6230},{\"end\":7552,\"start\":6737},{\"end\":7854,\"start\":7554},{\"end\":8598,\"start\":7856},{\"end\":8866,\"start\":8600},{\"end\":9979,\"start\":8892},{\"end\":10650,\"start\":9981},{\"end\":11229,\"start\":10652},{\"end\":11724,\"start\":11254},{\"end\":12199,\"start\":11726},{\"end\":12453,\"start\":12238},{\"end\":12653,\"start\":12455},{\"end\":12865,\"start\":12655},{\"end\":13093,\"start\":12867},{\"end\":13253,\"start\":13095},{\"end\":13626,\"start\":13280},{\"end\":14923,\"start\":13653},{\"end\":14966,\"start\":14944},{\"end\":15112,\"start\":15003},{\"end\":15606,\"start\":15114},{\"end\":15706,\"start\":15608},{\"end\":15993,\"start\":15708},{\"end\":16656,\"start\":15995},{\"end\":18085,\"start\":16658},{\"end\":18632,\"start\":18119},{\"end\":19048,\"start\":18634},{\"end\":19573,\"start\":19085},{\"end\":19870,\"start\":19575},{\"end\":20072,\"start\":19908},{\"end\":20273,\"start\":20074},{\"end\":20644,\"start\":20305},{\"end\":21065,\"start\":20646},{\"end\":21443,\"start\":21067},{\"end\":22413,\"start\":21445},{\"end\":22731,\"start\":22415},{\"end\":23124,\"start\":22733},{\"end\":23366,\"start\":23126}]", "formula": null, "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":6194,\"start\":6187},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":14269,\"start\":14262},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":17097,\"start\":17090},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":17314,\"start\":17307},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":18758,\"start\":18751},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":19609,\"start\":19602}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1512,\"start\":1500},{\"attributes\":{\"n\":\"2\"},\"end\":6735,\"start\":6696},{\"attributes\":{\"n\":\"2.2\"},\"end\":8890,\"start\":8869},{\"attributes\":{\"n\":\"2.3\"},\"end\":11252,\"start\":11232},{\"attributes\":{\"n\":\"3\"},\"end\":12236,\"start\":12202},{\"end\":13278,\"start\":13256},{\"end\":13651,\"start\":13629},{\"attributes\":{\"n\":\"3.2\"},\"end\":14942,\"start\":14926},{\"end\":14988,\"start\":14969},{\"attributes\":{\"n\":\"3.3\"},\"end\":15001,\"start\":14991},{\"attributes\":{\"n\":\"4\"},\"end\":18095,\"start\":18088},{\"attributes\":{\"n\":\"4.1\"},\"end\":18117,\"start\":18098},{\"attributes\":{\"n\":\"4.2\"},\"end\":19083,\"start\":19051},{\"end\":19906,\"start\":19873},{\"attributes\":{\"n\":\"5\"},\"end\":20303,\"start\":20276},{\"end\":23378,\"start\":23368},{\"end\":23550,\"start\":23540},{\"end\":23990,\"start\":23981},{\"end\":24181,\"start\":24172},{\"end\":25243,\"start\":25234}]", "table": "[{\"end\":23979,\"start\":23975},{\"end\":24170,\"start\":24014},{\"end\":25232,\"start\":24233},{\"end\":25561,\"start\":25419}]", "figure_caption": "[{\"end\":23538,\"start\":23380},{\"end\":23784,\"start\":23552},{\"end\":23975,\"start\":23787},{\"end\":24014,\"start\":23992},{\"end\":24233,\"start\":24183},{\"end\":25419,\"start\":25245}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":11890,\"start\":11882},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":14182,\"start\":14174}]", "bib_author_first_name": "[{\"end\":25745,\"start\":25742},{\"end\":25759,\"start\":25755},{\"end\":25772,\"start\":25766},{\"end\":25785,\"start\":25781},{\"end\":25945,\"start\":25942},{\"end\":25947,\"start\":25946},{\"end\":25963,\"start\":25955},{\"end\":25974,\"start\":25970},{\"end\":25989,\"start\":25982},{\"end\":26004,\"start\":25999},{\"end\":26021,\"start\":26013},{\"end\":26038,\"start\":26032},{\"end\":26058,\"start\":26052},{\"end\":26072,\"start\":26066},{\"end\":26087,\"start\":26081},{\"end\":26104,\"start\":26096},{\"end\":26119,\"start\":26114},{\"end\":26142,\"start\":26134},{\"end\":26155,\"start\":26152},{\"end\":26171,\"start\":26166},{\"end\":26185,\"start\":26179},{\"end\":26200,\"start\":26194},{\"end\":26202,\"start\":26201},{\"end\":26219,\"start\":26212},{\"end\":26231,\"start\":26224},{\"end\":26251,\"start\":26240},{\"end\":26263,\"start\":26259},{\"end\":26274,\"start\":26270},{\"end\":26290,\"start\":26283},{\"end\":27024,\"start\":27020},{\"end\":27036,\"start\":27031},{\"end\":27051,\"start\":27045},{\"end\":27063,\"start\":27057},{\"end\":27078,\"start\":27070},{\"end\":27109,\"start\":27104},{\"end\":27123,\"start\":27118},{\"end\":27137,\"start\":27133},{\"end\":27153,\"start\":27145},{\"end\":27166,\"start\":27162},{\"end\":27181,\"start\":27177},{\"end\":27191,\"start\":27187},{\"end\":27206,\"start\":27198},{\"end\":27223,\"start\":27216},{\"end\":27237,\"start\":27232},{\"end\":27252,\"start\":27246},{\"end\":27267,\"start\":27261},{\"end\":27283,\"start\":27277},{\"end\":27295,\"start\":27290},{\"end\":27306,\"start\":27302},{\"end\":27321,\"start\":27314},{\"end\":27337,\"start\":27330},{\"end\":27351,\"start\":27345},{\"end\":27368,\"start\":27360},{\"end\":27386,\"start\":27379},{\"end\":27403,\"start\":27395},{\"end\":29001,\"start\":28996},{\"end\":29013,\"start\":29008},{\"end\":29032,\"start\":29025},{\"end\":29051,\"start\":29041},{\"end\":29066,\"start\":29061},{\"end\":29085,\"start\":29079},{\"end\":29401,\"start\":29396},{\"end\":29418,\"start\":29410},{\"end\":29432,\"start\":29426},{\"end\":29446,\"start\":29438},{\"end\":29729,\"start\":29720},{\"end\":29745,\"start\":29739},{\"end\":29757,\"start\":29751},{\"end\":29767,\"start\":29762},{\"end\":29776,\"start\":29774},{\"end\":29785,\"start\":29783},{\"end\":30093,\"start\":30089},{\"end\":30106,\"start\":30101},{\"end\":30108,\"start\":30107},{\"end\":30127,\"start\":30118},{\"end\":30141,\"start\":30137},{\"end\":30409,\"start\":30408},{\"end\":30412,\"start\":30410},{\"end\":30421,\"start\":30420},{\"end\":30431,\"start\":30430},{\"end\":30442,\"start\":30441},{\"end\":30682,\"start\":30677},{\"end\":30696,\"start\":30692},{\"end\":30713,\"start\":30707},{\"end\":30728,\"start\":30722},{\"end\":30746,\"start\":30741},{\"end\":30763,\"start\":30757},{\"end\":30775,\"start\":30772},{\"end\":31243,\"start\":31240},{\"end\":31258,\"start\":31251},{\"end\":31273,\"start\":31270},{\"end\":31535,\"start\":31531},{\"end\":31550,\"start\":31542},{\"end\":31566,\"start\":31559},{\"end\":31568,\"start\":31567},{\"end\":32204,\"start\":32199},{\"end\":32216,\"start\":32213},{\"end\":32232,\"start\":32229},{\"end\":32244,\"start\":32243},{\"end\":32258,\"start\":32250},{\"end\":32271,\"start\":32266},{\"end\":32284,\"start\":32279},{\"end\":32296,\"start\":32292},{\"end\":32310,\"start\":32303},{\"end\":32325,\"start\":32320},{\"end\":32702,\"start\":32695},{\"end\":32716,\"start\":32708},{\"end\":32728,\"start\":32722},{\"end\":32742,\"start\":32735},{\"end\":33230,\"start\":33226},{\"end\":33243,\"start\":33240},{\"end\":33258,\"start\":33249},{\"end\":33260,\"start\":33259},{\"end\":33279,\"start\":33272},{\"end\":33291,\"start\":33285},{\"end\":33310,\"start\":33303},{\"end\":33322,\"start\":33318},{\"end\":33325,\"start\":33323},{\"end\":34246,\"start\":34240},{\"end\":34248,\"start\":34247},{\"end\":34261,\"start\":34257},{\"end\":34277,\"start\":34271},{\"end\":34912,\"start\":34905},{\"end\":34923,\"start\":34918},{\"end\":34938,\"start\":34932},{\"end\":34952,\"start\":34945},{\"end\":35843,\"start\":35840},{\"end\":35853,\"start\":35849},{\"end\":35870,\"start\":35863},{\"end\":35885,\"start\":35876},{\"end\":35887,\"start\":35886},{\"end\":36608,\"start\":36605},{\"end\":36618,\"start\":36614},{\"end\":36633,\"start\":36628},{\"end\":36646,\"start\":36639},{\"end\":36661,\"start\":36652},{\"end\":36663,\"start\":36662},{\"end\":37120,\"start\":37113},{\"end\":37136,\"start\":37132},{\"end\":37141,\"start\":37137},{\"end\":37156,\"start\":37148},{\"end\":37169,\"start\":37163},{\"end\":37179,\"start\":37174},{\"end\":37188,\"start\":37185},{\"end\":37945,\"start\":37944},{\"end\":37957,\"start\":37956},{\"end\":37963,\"start\":37962},{\"end\":38370,\"start\":38365},{\"end\":38396,\"start\":38391},{\"end\":38406,\"start\":38401},{\"end\":38427,\"start\":38421},{\"end\":38973,\"start\":38965},{\"end\":38986,\"start\":38980},{\"end\":39002,\"start\":38995},{\"end\":39015,\"start\":39010},{\"end\":39030,\"start\":39024},{\"end\":39549,\"start\":39545},{\"end\":39566,\"start\":39559},{\"end\":39576,\"start\":39571},{\"end\":39589,\"start\":39584},{\"end\":39601,\"start\":39596},{\"end\":39614,\"start\":39610},{\"end\":39862,\"start\":39861},{\"end\":39864,\"start\":39863},{\"end\":39872,\"start\":39871},{\"end\":39879,\"start\":39878},{\"end\":39890,\"start\":39889},{\"end\":39892,\"start\":39891},{\"end\":40272,\"start\":40266},{\"end\":40286,\"start\":40282},{\"end\":40300,\"start\":40296},{\"end\":40314,\"start\":40309},{\"end\":40331,\"start\":40326},{\"end\":40344,\"start\":40339},{\"end\":40346,\"start\":40345},{\"end\":40360,\"start\":40354},{\"end\":40374,\"start\":40369},{\"end\":40641,\"start\":40639},{\"end\":40653,\"start\":40647},{\"end\":40655,\"start\":40654},{\"end\":41167,\"start\":41161},{\"end\":41180,\"start\":41174},{\"end\":41196,\"start\":41191},{\"end\":41212,\"start\":41206},{\"end\":41231,\"start\":41222},{\"end\":41247,\"start\":41241},{\"end\":41263,\"start\":41257},{\"end\":41266,\"start\":41264},{\"end\":41280,\"start\":41274},{\"end\":41701,\"start\":41699},{\"end\":41712,\"start\":41706},{\"end\":41729,\"start\":41723},{\"end\":41745,\"start\":41739},{\"end\":42202,\"start\":42198},{\"end\":42217,\"start\":42209},{\"end\":42519,\"start\":42513}]", "bib_author_last_name": "[{\"end\":25753,\"start\":25746},{\"end\":25764,\"start\":25760},{\"end\":25779,\"start\":25773},{\"end\":25791,\"start\":25786},{\"end\":25953,\"start\":25948},{\"end\":25968,\"start\":25964},{\"end\":25980,\"start\":25975},{\"end\":25997,\"start\":25990},{\"end\":26011,\"start\":26005},{\"end\":26030,\"start\":26022},{\"end\":26050,\"start\":26039},{\"end\":26064,\"start\":26059},{\"end\":26079,\"start\":26073},{\"end\":26094,\"start\":26088},{\"end\":26112,\"start\":26105},{\"end\":26132,\"start\":26120},{\"end\":26150,\"start\":26143},{\"end\":26164,\"start\":26156},{\"end\":26177,\"start\":26172},{\"end\":26192,\"start\":26186},{\"end\":26210,\"start\":26203},{\"end\":26222,\"start\":26220},{\"end\":26238,\"start\":26232},{\"end\":26257,\"start\":26252},{\"end\":26268,\"start\":26264},{\"end\":26281,\"start\":26275},{\"end\":26297,\"start\":26291},{\"end\":27029,\"start\":27025},{\"end\":27043,\"start\":27037},{\"end\":27055,\"start\":27052},{\"end\":27068,\"start\":27064},{\"end\":27102,\"start\":27079},{\"end\":27116,\"start\":27110},{\"end\":27131,\"start\":27124},{\"end\":27143,\"start\":27138},{\"end\":27160,\"start\":27154},{\"end\":27175,\"start\":27167},{\"end\":27185,\"start\":27182},{\"end\":27196,\"start\":27192},{\"end\":27214,\"start\":27207},{\"end\":27230,\"start\":27224},{\"end\":27244,\"start\":27238},{\"end\":27259,\"start\":27253},{\"end\":27275,\"start\":27268},{\"end\":27288,\"start\":27284},{\"end\":27300,\"start\":27296},{\"end\":27312,\"start\":27307},{\"end\":27328,\"start\":27322},{\"end\":27343,\"start\":27338},{\"end\":27358,\"start\":27352},{\"end\":27377,\"start\":27369},{\"end\":27393,\"start\":27387},{\"end\":27410,\"start\":27404},{\"end\":29006,\"start\":29002},{\"end\":29023,\"start\":29014},{\"end\":29039,\"start\":29033},{\"end\":29059,\"start\":29052},{\"end\":29077,\"start\":29067},{\"end\":29095,\"start\":29086},{\"end\":29408,\"start\":29402},{\"end\":29424,\"start\":29419},{\"end\":29436,\"start\":29433},{\"end\":29456,\"start\":29447},{\"end\":29737,\"start\":29730},{\"end\":29749,\"start\":29746},{\"end\":29760,\"start\":29758},{\"end\":29772,\"start\":29768},{\"end\":29781,\"start\":29777},{\"end\":29790,\"start\":29786},{\"end\":30099,\"start\":30094},{\"end\":30116,\"start\":30109},{\"end\":30135,\"start\":30128},{\"end\":30152,\"start\":30142},{\"end\":30418,\"start\":30413},{\"end\":30428,\"start\":30422},{\"end\":30439,\"start\":30432},{\"end\":30449,\"start\":30443},{\"end\":30690,\"start\":30683},{\"end\":30705,\"start\":30697},{\"end\":30720,\"start\":30714},{\"end\":30739,\"start\":30729},{\"end\":30755,\"start\":30747},{\"end\":30770,\"start\":30764},{\"end\":30782,\"start\":30776},{\"end\":31249,\"start\":31244},{\"end\":31268,\"start\":31259},{\"end\":31277,\"start\":31274},{\"end\":31540,\"start\":31536},{\"end\":31557,\"start\":31551},{\"end\":31574,\"start\":31569},{\"end\":32211,\"start\":32205},{\"end\":32227,\"start\":32217},{\"end\":32241,\"start\":32233},{\"end\":32248,\"start\":32245},{\"end\":32264,\"start\":32259},{\"end\":32277,\"start\":32272},{\"end\":32290,\"start\":32285},{\"end\":32301,\"start\":32297},{\"end\":32318,\"start\":32311},{\"end\":32328,\"start\":32326},{\"end\":32336,\"start\":32330},{\"end\":32706,\"start\":32703},{\"end\":32720,\"start\":32717},{\"end\":32733,\"start\":32729},{\"end\":32746,\"start\":32743},{\"end\":33238,\"start\":33231},{\"end\":33247,\"start\":33244},{\"end\":33270,\"start\":33261},{\"end\":33283,\"start\":33280},{\"end\":33301,\"start\":33292},{\"end\":33316,\"start\":33311},{\"end\":33331,\"start\":33326},{\"end\":34255,\"start\":34249},{\"end\":34269,\"start\":34262},{\"end\":34284,\"start\":34278},{\"end\":34916,\"start\":34913},{\"end\":34930,\"start\":34924},{\"end\":34943,\"start\":34939},{\"end\":34965,\"start\":34953},{\"end\":35847,\"start\":35844},{\"end\":35861,\"start\":35854},{\"end\":35874,\"start\":35871},{\"end\":35897,\"start\":35888},{\"end\":36612,\"start\":36609},{\"end\":36626,\"start\":36619},{\"end\":36637,\"start\":36634},{\"end\":36650,\"start\":36647},{\"end\":36673,\"start\":36664},{\"end\":37130,\"start\":37121},{\"end\":37146,\"start\":37142},{\"end\":37161,\"start\":37157},{\"end\":37172,\"start\":37170},{\"end\":37183,\"start\":37180},{\"end\":37192,\"start\":37189},{\"end\":37954,\"start\":37946},{\"end\":37960,\"start\":37958},{\"end\":37976,\"start\":37964},{\"end\":38389,\"start\":38371},{\"end\":38399,\"start\":38397},{\"end\":38419,\"start\":38407},{\"end\":38435,\"start\":38428},{\"end\":38978,\"start\":38974},{\"end\":38993,\"start\":38987},{\"end\":39008,\"start\":39003},{\"end\":39022,\"start\":39016},{\"end\":39038,\"start\":39031},{\"end\":39557,\"start\":39550},{\"end\":39569,\"start\":39567},{\"end\":39582,\"start\":39577},{\"end\":39594,\"start\":39590},{\"end\":39608,\"start\":39602},{\"end\":39624,\"start\":39615},{\"end\":39869,\"start\":39865},{\"end\":39876,\"start\":39873},{\"end\":39887,\"start\":39880},{\"end\":39899,\"start\":39893},{\"end\":40280,\"start\":40273},{\"end\":40294,\"start\":40287},{\"end\":40307,\"start\":40301},{\"end\":40324,\"start\":40315},{\"end\":40337,\"start\":40332},{\"end\":40352,\"start\":40347},{\"end\":40367,\"start\":40361},{\"end\":40385,\"start\":40375},{\"end\":40645,\"start\":40642},{\"end\":40661,\"start\":40656},{\"end\":41172,\"start\":41168},{\"end\":41189,\"start\":41181},{\"end\":41204,\"start\":41197},{\"end\":41220,\"start\":41213},{\"end\":41239,\"start\":41232},{\"end\":41255,\"start\":41248},{\"end\":41272,\"start\":41267},{\"end\":41290,\"start\":41281},{\"end\":41704,\"start\":41702},{\"end\":41721,\"start\":41713},{\"end\":41737,\"start\":41730},{\"end\":41755,\"start\":41746},{\"end\":42207,\"start\":42203},{\"end\":42225,\"start\":42218},{\"end\":42527,\"start\":42520}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":25940,\"start\":25650},{\"attributes\":{\"id\":\"b1\"},\"end\":27018,\"start\":25942},{\"attributes\":{\"id\":\"b2\"},\"end\":28922,\"start\":27020},{\"attributes\":{\"id\":\"b3\"},\"end\":29312,\"start\":28924},{\"attributes\":{\"id\":\"b4\"},\"end\":29642,\"start\":29314},{\"attributes\":{\"id\":\"b5\"},\"end\":30000,\"start\":29644},{\"attributes\":{\"id\":\"b6\"},\"end\":30349,\"start\":30002},{\"attributes\":{\"doi\":\"10.1109/TSE.2011.104\",\"id\":\"b7\"},\"end\":30635,\"start\":30351},{\"attributes\":{\"doi\":\"10.1109/ICST.2019.00019\",\"id\":\"b8\",\"matched_paper_id\":174818993},\"end\":31164,\"start\":30637},{\"attributes\":{\"id\":\"b9\"},\"end\":31432,\"start\":31166},{\"attributes\":{\"doi\":\"10.1145/2610384.2628055\",\"id\":\"b10\",\"matched_paper_id\":12796895},\"end\":32197,\"start\":31434},{\"attributes\":{\"doi\":\"arXiv:2001.08361\",\"id\":\"b11\"},\"end\":32630,\"start\":32199},{\"attributes\":{\"doi\":\"978-1-4673-3076-3\",\"id\":\"b12\",\"matched_paper_id\":234916},\"end\":33183,\"start\":32632},{\"attributes\":{\"doi\":\"10.1145/3338906.3338935\",\"id\":\"b13\",\"matched_paper_id\":196471046},\"end\":34177,\"start\":33185},{\"attributes\":{\"doi\":\"10.1145/1134285.1134355\",\"id\":\"b14\",\"matched_paper_id\":8485237},\"end\":34817,\"start\":34179},{\"attributes\":{\"doi\":\"10.1145/3135932.3135941\",\"id\":\"b15\",\"matched_paper_id\":7158771},\"end\":35780,\"start\":34819},{\"attributes\":{\"doi\":\"10.1145/3293882.3330577\",\"id\":\"b16\",\"matched_paper_id\":84186411},\"end\":36532,\"start\":35782},{\"attributes\":{\"doi\":\"10.1109/APSEC.2018.00085\",\"id\":\"b17\",\"matched_paper_id\":86511204},\"end\":37017,\"start\":36534},{\"attributes\":{\"doi\":\"10.1145/3395363.3397369\",\"id\":\"b18\",\"matched_paper_id\":218979651},\"end\":37867,\"start\":37019},{\"attributes\":{\"doi\":\"10.1145/2884781.2884807\",\"id\":\"b19\",\"matched_paper_id\":11431040},\"end\":38317,\"start\":37869},{\"attributes\":{\"doi\":\"978-1-4673-3076-3\",\"id\":\"b20\",\"matched_paper_id\":11009662},\"end\":38876,\"start\":38319},{\"attributes\":{\"doi\":\"10.1109/SANER48275.2020.9054829\",\"id\":\"b21\",\"matched_paper_id\":215721935},\"end\":39490,\"start\":38878},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":160025533},\"end\":39809,\"start\":39492},{\"attributes\":{\"doi\":\"10.1109/ASE.2017.8115675\",\"id\":\"b23\",\"matched_paper_id\":25663934},\"end\":40237,\"start\":39811},{\"attributes\":{\"id\":\"b24\"},\"end\":40576,\"start\":40239},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":33145039},\"end\":41087,\"start\":40578},{\"attributes\":{\"doi\":\"10.1109/TSE.2016.2560811\",\"id\":\"b26\"},\"end\":41620,\"start\":41089},{\"attributes\":{\"doi\":\"10.1016/j.jss.2020.110825\",\"id\":\"b27\",\"matched_paper_id\":13661672},\"end\":42115,\"start\":41622},{\"attributes\":{\"doi\":\"10.1109/TSE.2018.2874648\",\"id\":\"b28\"},\"end\":42429,\"start\":42117},{\"attributes\":{\"id\":\"b29\"},\"end\":42702,\"start\":42431}]", "bib_title": "[{\"end\":30675,\"start\":30637},{\"end\":31529,\"start\":31434},{\"end\":32693,\"start\":32632},{\"end\":33224,\"start\":33185},{\"end\":34238,\"start\":34179},{\"end\":34903,\"start\":34819},{\"end\":35838,\"start\":35782},{\"end\":36603,\"start\":36534},{\"end\":37111,\"start\":37019},{\"end\":37942,\"start\":37869},{\"end\":38363,\"start\":38319},{\"end\":38963,\"start\":38878},{\"end\":39543,\"start\":39492},{\"end\":39859,\"start\":39811},{\"end\":40637,\"start\":40578},{\"end\":41697,\"start\":41622}]", "bib_author": "[{\"end\":25755,\"start\":25742},{\"end\":25766,\"start\":25755},{\"end\":25781,\"start\":25766},{\"end\":25793,\"start\":25781},{\"end\":25955,\"start\":25942},{\"end\":25970,\"start\":25955},{\"end\":25982,\"start\":25970},{\"end\":25999,\"start\":25982},{\"end\":26013,\"start\":25999},{\"end\":26032,\"start\":26013},{\"end\":26052,\"start\":26032},{\"end\":26066,\"start\":26052},{\"end\":26081,\"start\":26066},{\"end\":26096,\"start\":26081},{\"end\":26114,\"start\":26096},{\"end\":26134,\"start\":26114},{\"end\":26152,\"start\":26134},{\"end\":26166,\"start\":26152},{\"end\":26179,\"start\":26166},{\"end\":26194,\"start\":26179},{\"end\":26212,\"start\":26194},{\"end\":26224,\"start\":26212},{\"end\":26240,\"start\":26224},{\"end\":26259,\"start\":26240},{\"end\":26270,\"start\":26259},{\"end\":26283,\"start\":26270},{\"end\":26299,\"start\":26283},{\"end\":27031,\"start\":27020},{\"end\":27045,\"start\":27031},{\"end\":27057,\"start\":27045},{\"end\":27070,\"start\":27057},{\"end\":27104,\"start\":27070},{\"end\":27118,\"start\":27104},{\"end\":27133,\"start\":27118},{\"end\":27145,\"start\":27133},{\"end\":27162,\"start\":27145},{\"end\":27177,\"start\":27162},{\"end\":27187,\"start\":27177},{\"end\":27198,\"start\":27187},{\"end\":27216,\"start\":27198},{\"end\":27232,\"start\":27216},{\"end\":27246,\"start\":27232},{\"end\":27261,\"start\":27246},{\"end\":27277,\"start\":27261},{\"end\":27290,\"start\":27277},{\"end\":27302,\"start\":27290},{\"end\":27314,\"start\":27302},{\"end\":27330,\"start\":27314},{\"end\":27345,\"start\":27330},{\"end\":27360,\"start\":27345},{\"end\":27379,\"start\":27360},{\"end\":27395,\"start\":27379},{\"end\":27412,\"start\":27395},{\"end\":29008,\"start\":28996},{\"end\":29025,\"start\":29008},{\"end\":29041,\"start\":29025},{\"end\":29061,\"start\":29041},{\"end\":29079,\"start\":29061},{\"end\":29097,\"start\":29079},{\"end\":29410,\"start\":29396},{\"end\":29426,\"start\":29410},{\"end\":29438,\"start\":29426},{\"end\":29458,\"start\":29438},{\"end\":29739,\"start\":29720},{\"end\":29751,\"start\":29739},{\"end\":29762,\"start\":29751},{\"end\":29774,\"start\":29762},{\"end\":29783,\"start\":29774},{\"end\":29792,\"start\":29783},{\"end\":30101,\"start\":30089},{\"end\":30118,\"start\":30101},{\"end\":30137,\"start\":30118},{\"end\":30154,\"start\":30137},{\"end\":30420,\"start\":30408},{\"end\":30430,\"start\":30420},{\"end\":30441,\"start\":30430},{\"end\":30451,\"start\":30441},{\"end\":30692,\"start\":30677},{\"end\":30707,\"start\":30692},{\"end\":30722,\"start\":30707},{\"end\":30741,\"start\":30722},{\"end\":30757,\"start\":30741},{\"end\":30772,\"start\":30757},{\"end\":30784,\"start\":30772},{\"end\":31251,\"start\":31240},{\"end\":31270,\"start\":31251},{\"end\":31279,\"start\":31270},{\"end\":31542,\"start\":31531},{\"end\":31559,\"start\":31542},{\"end\":31576,\"start\":31559},{\"end\":32213,\"start\":32199},{\"end\":32229,\"start\":32213},{\"end\":32243,\"start\":32229},{\"end\":32250,\"start\":32243},{\"end\":32266,\"start\":32250},{\"end\":32279,\"start\":32266},{\"end\":32292,\"start\":32279},{\"end\":32303,\"start\":32292},{\"end\":32320,\"start\":32303},{\"end\":32330,\"start\":32320},{\"end\":32338,\"start\":32330},{\"end\":32708,\"start\":32695},{\"end\":32722,\"start\":32708},{\"end\":32735,\"start\":32722},{\"end\":32748,\"start\":32735},{\"end\":33240,\"start\":33226},{\"end\":33249,\"start\":33240},{\"end\":33272,\"start\":33249},{\"end\":33285,\"start\":33272},{\"end\":33303,\"start\":33285},{\"end\":33318,\"start\":33303},{\"end\":33333,\"start\":33318},{\"end\":34257,\"start\":34240},{\"end\":34271,\"start\":34257},{\"end\":34286,\"start\":34271},{\"end\":34918,\"start\":34905},{\"end\":34932,\"start\":34918},{\"end\":34945,\"start\":34932},{\"end\":34967,\"start\":34945},{\"end\":35849,\"start\":35840},{\"end\":35863,\"start\":35849},{\"end\":35876,\"start\":35863},{\"end\":35899,\"start\":35876},{\"end\":36614,\"start\":36605},{\"end\":36628,\"start\":36614},{\"end\":36639,\"start\":36628},{\"end\":36652,\"start\":36639},{\"end\":36675,\"start\":36652},{\"end\":37132,\"start\":37113},{\"end\":37148,\"start\":37132},{\"end\":37163,\"start\":37148},{\"end\":37174,\"start\":37163},{\"end\":37185,\"start\":37174},{\"end\":37194,\"start\":37185},{\"end\":37956,\"start\":37944},{\"end\":37962,\"start\":37956},{\"end\":37978,\"start\":37962},{\"end\":38391,\"start\":38365},{\"end\":38401,\"start\":38391},{\"end\":38421,\"start\":38401},{\"end\":38437,\"start\":38421},{\"end\":38980,\"start\":38965},{\"end\":38995,\"start\":38980},{\"end\":39010,\"start\":38995},{\"end\":39024,\"start\":39010},{\"end\":39040,\"start\":39024},{\"end\":39559,\"start\":39545},{\"end\":39571,\"start\":39559},{\"end\":39584,\"start\":39571},{\"end\":39596,\"start\":39584},{\"end\":39610,\"start\":39596},{\"end\":39626,\"start\":39610},{\"end\":39871,\"start\":39861},{\"end\":39878,\"start\":39871},{\"end\":39889,\"start\":39878},{\"end\":39901,\"start\":39889},{\"end\":40282,\"start\":40266},{\"end\":40296,\"start\":40282},{\"end\":40309,\"start\":40296},{\"end\":40326,\"start\":40309},{\"end\":40339,\"start\":40326},{\"end\":40354,\"start\":40339},{\"end\":40369,\"start\":40354},{\"end\":40387,\"start\":40369},{\"end\":40647,\"start\":40639},{\"end\":40663,\"start\":40647},{\"end\":41174,\"start\":41161},{\"end\":41191,\"start\":41174},{\"end\":41206,\"start\":41191},{\"end\":41222,\"start\":41206},{\"end\":41241,\"start\":41222},{\"end\":41257,\"start\":41241},{\"end\":41274,\"start\":41257},{\"end\":41292,\"start\":41274},{\"end\":41706,\"start\":41699},{\"end\":41723,\"start\":41706},{\"end\":41739,\"start\":41723},{\"end\":41757,\"start\":41739},{\"end\":42209,\"start\":42198},{\"end\":42227,\"start\":42209},{\"end\":42529,\"start\":42513}]", "bib_venue": "[{\"end\":26460,\"start\":26372},{\"end\":27939,\"start\":27648},{\"end\":31770,\"start\":31693},{\"end\":32916,\"start\":32849},{\"end\":33667,\"start\":33520},{\"end\":34469,\"start\":34392},{\"end\":35272,\"start\":35138},{\"end\":36117,\"start\":36028},{\"end\":37388,\"start\":37311},{\"end\":38605,\"start\":38538},{\"end\":40832,\"start\":40756},{\"end\":25740,\"start\":25650},{\"end\":26370,\"start\":26299},{\"end\":27498,\"start\":27412},{\"end\":28994,\"start\":28924},{\"end\":29394,\"start\":29314},{\"end\":29718,\"start\":29644},{\"end\":30087,\"start\":30002},{\"end\":30406,\"start\":30351},{\"end\":30883,\"start\":30807},{\"end\":31238,\"start\":31166},{\"end\":31691,\"start\":31599},{\"end\":32393,\"start\":32354},{\"end\":32847,\"start\":32765},{\"end\":33518,\"start\":33356},{\"end\":34390,\"start\":34309},{\"end\":35136,\"start\":34990},{\"end\":36026,\"start\":35922},{\"end\":36756,\"start\":36699},{\"end\":37309,\"start\":37217},{\"end\":38075,\"start\":38001},{\"end\":38536,\"start\":38454},{\"end\":39168,\"start\":39071},{\"end\":39637,\"start\":39626},{\"end\":40003,\"start\":39925},{\"end\":40264,\"start\":40239},{\"end\":40754,\"start\":40663},{\"end\":41159,\"start\":41089},{\"end\":41813,\"start\":41782},{\"end\":42196,\"start\":42117},{\"end\":42511,\"start\":42431}]"}}}, "year": 2023, "month": 12, "day": 17}