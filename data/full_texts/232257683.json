{"id": 232257683, "updated": "2023-10-06 05:56:52.881", "metadata": {"title": "OGB-LSC: A Large-Scale Challenge for Machine Learning on Graphs", "authors": "[{\"first\":\"Weihua\",\"last\":\"Hu\",\"middle\":[]},{\"first\":\"Matthias\",\"last\":\"Fey\",\"middle\":[]},{\"first\":\"Hongyu\",\"last\":\"Ren\",\"middle\":[]},{\"first\":\"Maho\",\"last\":\"Nakata\",\"middle\":[]},{\"first\":\"Yuxiao\",\"last\":\"Dong\",\"middle\":[]},{\"first\":\"Jure\",\"last\":\"Leskovec\",\"middle\":[]}]", "venue": "ArXiv", "journal": "ArXiv", "publication_date": {"year": 2021, "month": 3, "day": 17}, "abstract": "Enabling effective and efficient machine learning (ML) over large-scale graph data (e.g., graphs with billions of edges) can have a great impact on both industrial and scientific applications. However, existing efforts to advance large-scale graph ML have been largely limited by the lack of a suitable public benchmark. Here we present OGB Large-Scale Challenge (OGB-LSC), a collection of three real-world datasets for facilitating the advancements in large-scale graph ML. The OGB-LSC datasets are orders of magnitude larger than existing ones, covering three core graph learning tasks -- link prediction, graph regression, and node classification. Furthermore, we provide dedicated baseline experiments, scaling up expressive graph ML models to the massive datasets. We show that expressive models significantly outperform simple scalable baselines, indicating an opportunity for dedicated efforts to further improve graph ML at scale. Moreover, OGB-LSC datasets were deployed at ACM KDD Cup 2021 and attracted more than 500 team registrations globally, during which significant performance improvements were made by a variety of innovative techniques. We summarize the common techniques used by the winning solutions and highlight the current best practices in large-scale graph ML. Finally, we describe how we have updated the datasets after the KDD Cup to further facilitate research advances. The OGB-LSC datasets, baseline code, and all the information about the KDD Cup are available at https://ogb.stanford.edu/docs/lsc/ .", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2103.09430", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/nips/HuFRNDL21", "doi": null}}, "content": {"source": {"pdf_hash": "a7c9355e8bf441890341e33f66be2e3c15d6aafa", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2103.09430v3.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "352c5196ae2ebed2d469a3e996d7a333fa63b99e", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/a7c9355e8bf441890341e33f66be2e3c15d6aafa.txt", "contents": "\nOGB-LSC: A Large-Scale Challenge for Machine Learning on Graphs\n\n\nWeihua Hu \nDepartment of Computer Science\nStanford University\n\n\nMatthias Fey \nDepartment of Computer Science\nTU Dortmund University\n\n\nHongyu Ren \nDepartment of Computer Science\nStanford University\n\n\nMaho Nakata \nYuxiao Dong \nJure Leskovec \nDepartment of Computer Science\nStanford University\n\n\nOGB-LSC: A Large-Scale Challenge for Machine Learning on Graphs\n\nEnabling effective and efficient machine learning (ML) over large-scale graph data (e.g., graphs with billions of edges) can have a great impact on both industrial and scientific applications. However, existing efforts to advance large-scale graph ML have been largely limited by the lack of a suitable public benchmark.Here we present OGB Large-Scale Challenge (OGB-LSC), a collection of three real-world datasets for facilitating the advancements in large-scale graph ML. The OGB-LSC datasets are orders of magnitude larger than existing ones, covering three core graph learning tasks-link prediction, graph regression, and node classification. Furthermore, we provide dedicated baseline experiments, scaling up expressive graph ML models to the massive datasets. We show that expressive models significantly outperform simple scalable baselines, indicating an opportunity for dedicated efforts to further improve graph ML at scale. Moreover, OGB-LSC datasets were deployed at ACM KDD Cup 2021 and attracted more than 500 team registrations globally, during which significant performance improvements were made by a variety of innovative techniques. We summarize the common techniques used by the winning solutions and highlight the current best practices in large-scale graph ML. Finally, we describe how we have updated the datasets after the KDD Cup to further facilitate research advances. The OGB-LSC datasets, baseline code, and all the information about the KDD Cup are available at\n\nIntroduction\n\nMachine Learning (ML) on graphs has attracted immense attention in recent years because of the prevalence of graphstructured data in real-world applications. Modern application domains include Webscale social networks (Ugander et al., 2011), recommender systems (Ying et al., 2018), hyperlinked Web documents (Kleinberg, 1999), knowledge graphs (KGs) (Bollacker et al., 2008;Vrande\u010di\u0107 and Kr\u00f6tzsch, 2014), as well as the molecule simulation data generated by the ever-increasing scientific computation (Nakata and Shimazaki, 2017;Chanussot et al., 2021). All these domains involve large-scale graphs with billions of edges or a dataset with millions of graphs. Deploying accurate graph ML at scale will have a huge practical im-However, in deep learning, it has been demonstrated over and over again that one needs big expressive models and train them on big data to achieve the best performance (He et al., 2016;Vaswani et al., 2017;Devlin et al., 2018;Brown et al., 2020). In graph ML, the trend has been the opposite-models get simplified and less expressive to be able to scale to large graphs (Wu et al., 2019). Thus, there is a massive opportunity to enable graph ML techniques to work with realistic and large-scale graph datasets, exploring the potential of expressive models for big graphs.\n\nHere we present a large-scale graph ML challenge, OGB Large-Scale Challenge (OGB-LSC), to facilitate the development of state-of-the-art graph ML models for massive modern datasets. Specifically, we introduce three large-scale, realistic, and challenging datasets-MAG240M, WikiKG90M, and PCQM4M-that are unprecedentedly large in scale (see Table 1; the sizes are 10 to 100 times larger than the corresponding original OGB datasets 1 ) and cover predictions at the level of nodes, links, and graphs, respectively. An overview of the datasets is provided in Figure 1.\n\nBeyond providing the datasets, we perform an extensive baseline analysis on each dataset and implement both simple baseline models and advanced expressive models at scale. We find that advanced expressive models-despite requiring more efforts to scale up-do benefit from the large data and significantly outperform simple baseline models that are easy to scale.\n\nTo facilitate the community engagement, we recently organized the ACM KDD Cup 2021 around the OGB-LSC datasets. The competition attracted more than 500 team registrations and 150 leaderboard submissions. Within the three-month duration of the competition (March 15 to June 15, 2021), we have already witnessed innovative methods being developed to provide impressive performance gains 2 , further solidifying the value of the OGB-LSC datasets to advance state-of-the-art. We summarize the common techniques shared by the winning solutions, highlighting the current best practices of large-scale graph ML. Moreover, based on the lessons learned from the KDD Cup, we describe the future plan to update the datasets so that they can be further used to advance large-scale graph ML.\n\nIn addition, we highlight the top 3 winning results from our KDD Cup 2021 that significantly advance state-of-the-art and summarize common techniques used by the winning solutions. Note that while our baselines only used a single model for simplicity, all the winners used extensive model ensembling for their test submissions in order to maximize the performance. For a more direct comparison, we also report the winners' self-reported validation accuracy in the main text, which still exhibits significant accuracy improvement over our strong baselines.\n\n\nMAG240M: Node-Level Prediction\n\nPractical relevance and dataset overview. The volume of scientific publication has been increasing exponentially, doubling every 12 years (Dong et al., 2017). Currently, subject areas of ARXIV papers are manually determined by the paper's authors and ARXIV moderators. An accurate automatic predictor of papers' subject categories not only reduces the significant burden of manual labeling, but can also be used to classify the vast number of non-ARXIV papers, thereby allowing better search and organization of academic papers.\n\nMAG240M is a heterogeneous academic graph extracted from the Microsoft Academic Graph (MAG) . Given arXiv papers situated in the heterogeneous graph, whose schema diagram is illustrated in Figure 2, we aim to automatically annotate their topics, i.e., predicting the primary subject area of each ARXIV paper.\n\nGraph. We extract 121M academic papers in English from MAG (version: 2020-11-23) to construct a heterogeneous academic graph. The resultant paper set is written by 122M author entities, who are affiliated with 26K institutes. Among these papers, there are 1.3 billion citation links captured by MAG. Each paper is associated with its natural language title and most papers' abstracts are also available. We concatenate the title and abstract by period and pass it to a ROBERTA sentence encoder Reimers and Gurevych, 2019), generating a 768-dimensional vector for each paper node. Among the 121M paper nodes, approximately 1.4M nodes are ARXIV papers annotated with 153 ARXIV subject areas, e.g., cs.\n\nLG (Machine Learning). On the paper nodes, we attach the publication years as meta information.\n\nPrediction task and evaluation metric. The task is to predict the primary subject areas of the given ARXIV papers, which is cast as an ordinary multi-class classification problem. The metric is the classification accuracy.\n\nTo understand the relation between the prediction task and the heterogeneous graph structure, we analyze the graph homophily (McPherson et al., 2001)-tendency of two adjacent nodes to share the same labels-to better understand the interplay between heterogeneous graph connectivity and the prediction task. Homophily is normally analyzed over a homogeneous graph, but we extend the analysis to the heterogenous graph by considering meta-paths (Sun et al., 2011)-a path consisting of a sequence of relations defined between different node types. Given a meta-path, we can say two nodes are adjacent if they are connected by the meta-path. Table 3 shows the homophily for different kinds of meta-paths with different levels of connection strength. Compared to the direct citation connection (i.e., P-P), certain meta-paths (i.e., P-A-P) give rise to much higher degrees of homophiliness, while other meta-paths (i.e., P-A-I-A-P) provide much less homophily. As homophily is the central graph property exploited by many graph ML models, we believe that discovering essential heterogeneous connectivity is important to achieve good performance on this dataset.\n\nDataset split. We split the data according to time. Specifically, we train models on ARXIV papers published until 2018, validate the performance on the 2019 papers, and finally test the performance on the 2020 papers. The split reflects the practical scenario of helping the authors and moderators annotate the subject areas of the newly-published ARXIV papers.\n\nBaseline. We benchmark a broad range of graph ML models in both homogeneous (where only paper to paper relations are considered) and full heterogeneous settings. For both settings, we convert the directed graph into an undirected graph for simplicity. First, for the homogeneous setting, we benchmark the simple baseline models: graph-agnostic MLP, Label Propagation, and the recently-proposed simplified graph methods: SGC (Wu et al., 2019), SIGN (Rossi et al., 2020) and MLP+C&S , which are inherently scalable by decoupling predictions from propagation. Furthermore, we benchmark state-of-the-art expressive GNNs trained with neighborhood sampling (NS) (Hamilton et al., 2017), where we recursively sample 25 neighbors in the first layer and 15 neighbors in the second layer during training time. At inference time, we sample at most 160 neighbors for each layer. Here, we benchmark two types of strong models: the GRAPHSAGE (Hamilton et al., 2017) model (performing mean aggregation and utilizing skip-connections), and the more advanced GRAPH ATTENTION NETWORK (GAT) model (Velickovic et al., 2018). For the full heterogeneous setting, we follow Schlichtkrull et al. (2018) and learn distinct weights for each individual relation type (denoted by R-GRAPHSAGE and R-GAT, where \"R\" stands for \"Relational\"). We obtain the input features of authors and institutions by averaging the features of papers belonging to the same author and institution, respectively. The models are trained with NS. We note that the expressive GNNs trained with NS require more efforts to scale up, but are more expressive than the simple baselines.\n\nHyper-parameters. Hyper-parameters are selected based on their best validation performance. For all the models without NS, we tuned the hidden dimensionality \u2208 {128, 256, 512, 1024}, MLP depth \u2208 {1, 2, 3, 4}, dropout ratio \u2208 {0, 0.25, 0.5}, propagation layers (for SGC, SIGN, and C&S) \u2208 {2, 3}. For all the GNN models with NS, we use a hidden dimensionality of 1024. We make use of batch normalization (Ioffe and Szegedy, 2015) and ReLU activation in all models.\n\nDiscussion. Validation and test performances of all models considered are shown in Table 2. First, the graph-agnostic MLP and Label Propagation algorithm perform poorly, indicating that both graph structure and feature information are indeed important for the given task. Across the graph ML models operating on the homogeneous paper graph, GNNs with NS perform the best, with slight gains compared to their simplified versions. In particular, the advanced expressive graph attention aggregation is favourable compared to the uniform mean aggregation in GRAPHSAGE. Furthermore, considering all available heterogeneous relational structure in the heterogeneous graph setting yields significant improvements, with performance gains up to 3 percentage points. Again, the advanced attention aggregation provides favorable performance. Overall, our experiments highlight the benefits of developing and evaluating advanced expressive models on the larger scale.\n\nKDD Cup 2021 summary. In Table 2, we show the results of the top 3 winners of the KDD Cup: BD-PGL Team , Academic Team (Addanki et al., 2021), and Synerise AI Team (Daniluk et al., 2021). All the solutions outperform our baselines significantly, yielding 5-6% gain in test accuracy. For a more direct comparison, with a single model (no model ensembling), the BD-PGL Team reports a validation accuracy of 73.71% , improving our best R-GAT baseline by 3.7%.\n\nNotably, all the winning solutions used the target labels as input to their models, which allows the models to propagate labels together with the features. Regarding the GNN architectures, the BD-PGL adopted the expressive Transformer-based UniMP architecture (Shi et al., 2020), while the Academic adopted the standard MPNN (Gilmer et al., 2017) but trained it with self-supervised contrastive learning on unlabeled paper nodes . These results suggest that expressive GNNs are indeed promising for this dataset. Finally, both the BD-PGL and Academic teams exploited the temporal aspect of the academic graph by using the publication years either as input positional encoding  or as a way to sample mini-batch subgraphs for    Table 3: Analysis of graph homophily for different meta-paths connecting 1,251,341 arXiv papers (only train+validation). Connection strength indicates the number of different possible paths along the template meta-path, e.g., meta-path \"Paper-Author-Paper (P-A-P)\" with connection strength 3 means that at least 3 authors are shared for the two papers of interest. Homophily ratio is the ratio of two nodes having the same target labels. GNNs (Addanki et al., 2021). As real-world large-scale graphs are almost always dynamic, exploiting the temporal information is a promising direction of future research.\n\n\nWikiKG90M: Link-Level Prediction\n\nPractical relevance and dataset overview. Large encyclopedic Knowledge Graphs (KGs), such as Wikidata (Vrande\u010di\u0107 and Kr\u00f6tzsch, 2014) and Freebase (Bollacker et al., 2008), represent factual knowledge about the world through triplets connecting different entities, e.g., Hinton citizen of \u2212\u2212\u2212\u2212\u2212\u2212\u2192 Canada. They provide rich structured information about many entities, aiding a variety of knowledgeintensive downstream applications such as information retrieval, question answering (Singhal, 2012), and recommender systems (Guo et al., 2020). However, these large KGs are known to be far from complete (Min et al., 2013), missing many relational information between entities.\n\nWikiKG90M is a Knowledge Graph (KG) extracted from the entire Wikidata knowledge base. The task is to automatically impute missing triplets that are not yet present in the current KG. Accurate imputation models can be readily deployed on the Wikidata to improve its coverage.\n\nGraph. Each triplet (head, relation, tail) in WikiKG90M represents an Wikidata claim, where head and tail are the Wikidata items, and relation is the Wikidata predicate. We extracted triplets from the public Wikidata dump downloaded at three time-stamps: September 28, October 26, and November 23 of 2020, for training, validation, and testing, respectively. We retain all the entities and relations in the September dump, resulting in 87,143,637 entities, 1,315 relations, and 504,220,369 triplets in total.\n\nIn addition to extracting triplets, we provide text features for entities and relations. Specifically, each entity/relation in Wikidata is associated with a title and a short description, e.g., one entity is associated with the title 'Geoffrey Hinton' and the description 'computer scientist and psychologist'. Similar to MAG240M, we provide ROBERTA embeddings (Reimers and Gurevych, 2019; as node and edge features. 3\n\nPrediction task and evaluation metric. The task is the KG completion, i.e., given a set of training triplets, predict a set of test triplets. For evaluation, we follow the protocol similar to how KG completion is evaluated (Bordes et al., 2013). Specifically, for each validation/test triplet, (head, relation, tail), we corrupt tail with randomly-sampled 1000 negative entities, e.g., tail neg, such that (head, relation, tail neg) does not appear in the train/validation/test KG. The model is asked to rank the 1001 candidates (consisting of 1 positive and 1000 negatives) for each triplet and predict the top 10 entities that are most likely to be positive. The goal is to rank the ground-truth positive entity as high in the rank as possible, which is measured by Mean Reciprocal Rank (MRR). 4 Dataset split. We split the triplets according to time, simulating a realistic KG completion scenario of imputing missing triplets not present at a certain timestamp. Specifically, we construct three KGs using the aforementioned September, October, and November KGs, where we only retain entities and relation types that appear in the earliest September KG. We use the triplets in the September KG for training, and use the additional triplets in the October and November KGs for validation and test, respectively.\n\nWe analyze the effect of the time split. We find that head entities of validation triplets tend to be less popular entities; on average, they only have 6.5 out-degrees in the training KG, which is less than a quarter of the out-degree averaged over training triplets (i.e., 28.0). This suggests that learning signals for predicting validation (and test) triplets are sparse. Nonetheless, even for the sparsely-connected triplets, we find the textual information provides important clues, as illustrated in Table 4. Hence, we expect that advanced graph models that effectively incorporate textual information will be key to achieve good performance on the challenging time split.\n\nBaseline. We consider two representative KG embedding models: TRANSE (Bordes et al., 2013) and COMPLEX (Trouillon et al., 2016). These models define their own decoders to score knowledge triplets using the corresponding entity and relation embeddings. For instance, TRANSE uses \u2212 h + r \u2212 t 2 as the decoder, where h, r, and t are embeddings of head, relation, and tail, respectively. For the encoder function (mapping each entity and relation to its embedding), we consider the following three options. Shallow: We use the distinct embedding for each entity and relation, as normally done in KG embedding models. RoBERTa: We use two MLP encoders (one for entity and another for relation) that transform the ROBERTA features into entity and relation embeddings. Concat: To enhance the expressive power of the previous encoder, we concatenate the shallow learnable embeddings into the ROBERTA features, and use the MLPs to transform the concatenated vectors to get the final embeddings. This way, the MLP encoders can adaptively utilize the ROBERTA features and the shallow embeddings to fit the large amount of triplet data. To implement our baselines, we utilize DGL-KE (Zheng et al., 2020).\n\nHyper-parameters. For the loss function, we use the negative sampling loss from Sun et al. (2019), where we pick margin \u03b3 from {1,4,8,10,100}. In order to balance the performance and the memory cost, we use the embedding dimensionality of 200 for all the models.\n\nDiscussion. Table 5 shows the validation and test performance of the six different models, i.e., combination of two decoders (TRANSE and COMPLEX) and three encoders (SHALLOW, ROBERTA, and CONCAT). Notably, in terms of the encoders, we see that the most expressive CONCAT outperforms both SHALLOW and ROBERTA, indicating that both the textual information (captured by the ROBERTA embeddings) and structural information (captured by node-wise learnable embeddings) are useful in predicting validation and test triplets. In terms of the decoders, TRANSE and COMPLEX show similar performance with the CONCAT encoder, while they show somewhat mixed results with the SHALLOW and ROBERTA encoders.\n\nOverall, our experiments suggest that the expressive encoder that combines both textual information and structural information gives the most promising performance. In the KG completion literature, the design of the encoder has been much less studied compared to the decoder designs. Therefore, we believe there is a huge opportunity in scaling up more advanced encoders, especially GNNs (Schlichtkrull et al., 2018), to further improve the performance on this dataset.\n\nKDD Cup 2021 summary. Table 5 shows the results of the top 3 winners of the KDD Cup: BD-PGL Team , OhMyGod Team (Peng et al., 2021), and the GraphMIRAcles Team (Cai et al., 2021). All the winning solutions outperform our strong baselines significantly,   , improving our best COMPLEX-CONCAT baseline by 0.07 points in validation MRR. Similar to our baselines, all the winners utilize the KG embedding approach as the backbone, and adopt the encoder that takes both shallow embedding and textual embeddings into account. Specifically, BD-PGL proposed the NOTE model  which makes the ROTATE model more expressive, while OhMyGod adopted the ensemble of several existing KG embedding models. On the other hand, GraphMIRAcles explored different design choices for the encoder and found that adding residual connection for shallow embeddings significantly improved the model performance.\n\nIn addition to the model advances, all the winners exploited some statistical property of candidate tail entities. Most notably, Yang et al. (2021) found that simply by sorting the candidate tails by the frequency they appear in the training KG, it was possible to achieve validation MRR of 0.75, rivaling our TRANSE-SHALLOW baseline. This highlights that our negative tail candidates are mostly rare entities that can be easily distinguished from the true tail entity. On the other hand, the practical KG completion presents a much harder challenge: the candidate tails are not provided, and a model needs to predict the true tail entity out of all the possible 87M entities. As the performance on WikiKG90M has already saturated, we have updated WikiKG90M to WikiKG90Mv2 to reflect the realistic setting in large-scale KG completion. See Section 3 for further details.\n\n\nPCQM4M: Graph-Level Prediction\n\nPractical relevance and dataset overview. Density Functional Theory (DFT) is a powerful and widely-used quantum physics calculation that can accurately predict various molecular properties such as the shape of molecules, reactivity, responses by electromagnetic fields (Burke, 2012). However, DFT is time-consuming and takes up to several hours per small molecule. Using fast and accurate ML models to approximate DFT enables diverse downstream applications, such as property prediction for organic photovaltaic devices (Cao and Xue, 2014) and structure-based virtual screening for drug discovery (Ferreira et al., 2015).\n\nPCQM4M is a quantum chemistry dataset originally curated under the PubChemQC project (Nakata, 2015;Nakata and Shimazaki, 2017). Based on the PubChemQC, we define a meaningful ML task of predicting DFT-calculated HOMO-LUMO energy gap of molecules given their 2D molecular graphs. The HOMO-LUMO gap is one of the most practically-relevant quantum chemical properties of molecules since it is related to reactivity, photoexcitation, and charge transport (Griffith and Orgel, 1957). Moreover, predicting the quantum chemical property only from 2D molecular graphs without their 3D equilibrium structures is also practically favorable. This is because obtaining 3D equilibrium structures requires DFT-based geometry optimization, which is expensive on its own.\n\nTo ensure the resulting models are practically useful, we limit the average inference budget per molecule (including both pre-processing and model inference) to be less than 0.1 second using a single GPU and CPU (multi-threading on a multi-core CPU is allowed). This means that expensive (quantum) calculations cannot be used to perform inference. As our test set contains 377,423 molecules, we require the all the prediction to be made within 12 hours. Note that this time constraint is quite generous for ordinary GNNs-each of our baseline GNN only took about 3 minutes to perform inference over the entire test data.\n\nGraph. We provide molecules as the SMILES strings (Weininger, 1988), from which 2D molecule graphs (nodes are atoms and edges are chemical bonds) as well as molecular fingerprints (handengineered molecular feature developed by the chemistry community) can be obtained. By default, we follow OGB (Hu et al., 2020a) to convert the SMILES string into a molecular graph representation, where each node is associated with a 9-dimensional feature (e.g., atomic number, chirality) and each edge comes with a 3-dimensional feature (e.g., bond type, bond stereochemistry), although the optimal set of input graph features remains to be explored.\n\nPrediction task and evaluation metric. The task is graph regression: predicting the HOMO-LUMO energy gap in electronvolt (eV) given 2D molecular graphs. Mean Absolute Error (MAE) is used as evaluation metric.\n\nDataset split. We split molecules by their PubChem ID (CID) with ratio 80/10/10. Our original intention was to provide the scaffold split (Hu et al., 2020a;Wu et al., 2018), but the provided data turns out to be split by the CID due to some pre-processing bug. The CID number itself does not indicate particular meaning about the molecule, but splitting by CID may provide a moderate distribution shift (most likely not as severe as the scaffold split). We empirically compared the CID and scaffold splits and found the model performances were consistent between the two splits. 5\n\nBaseline. We benchmark two types of models: a simple MLP over the Morgan fingerprint (Morgan, 1965) and more advanced GNN models. For GNNs, we use the four strong models developed for graph-level prediction: Graph Convolutional Network (GCN) (Kipf and Welling, 2017) and Graph Isomorphism Network (GIN) (Xu et al., 2019), as well as their variants, GCN-VIRTUAL and GIN-VIRTUAL, which augment graphs with a virtual node that is bidirectionally connected to all nodes in the original graph (Gilmer et al., 2017). Adding the virtual node is shown to be effective across a wide range of graph-level prediction datasets in OGB (Hu et al., 2020a). Edge features are incorporated following Hu et al. (2020b). At inference time, the model output is clamped between 0 and 50 to avoid model's anomalously large/small prediction.\n\nHyper-parameters. For the MLP over Morgan fingerprint, we set the fingerprint dimensionality to be 2048, and tune the fingerprint radius \u2208 {2, 3}, as well as MLP's hyper-parameters: hidden dimensionality \u2208 {1200, 1600}, number of hidden layers \u2208 {2, 4, 6}, and dropout ratio \u2208 {0, 0.2}. For GNNs, we tune hidden dimensionality, i.e., width \u2208 {300, 600}, number of GNN layers, i.e., depth \u2208 {3, 5}. Simple summation is used for graph-level pooling. For all MLPs (including GIN's), we use batch normalization (Ioffe and Szegedy, 2015) and ReLU activation.\n\nDiscussion. The validation and test results are shown in Table 6. We see both the GNN models significantly outperform the simple fingerprint baseline. Expressive GNNs (GIN and GIN-VIRTUAL) outperform less expressive ones (GCN and GCN-VIRTUAL); especially, the most advanced and expressive GIN-VIRTUAL model significantly outperforms the other GNNs. Nonetheless, the current performance is still much worse than the chemical accuracy of 0.043eV-an indicator of practical usefulness established by the chemistry community. In the same Table 6, we show our ablation, where we use only 10% of data to train the GIN-VIRTUAL model. We see the performance significantly deteriorate, indicating the importance of training the model on large data. Finally, in Table 7, we show the relation between model sizes and validation performance. We see that the largest models always achieve the best performance.\n\nOverall, we find that advanced, expressive, and large GNN model gives the most promising performance on the PCQM4M dataset, although the performance still needs to be improved for practical use. We believe further advances in advanced modeling, expressive architectures, and larger model sizes could yield breakthrough in the large-scale molecular property prediction task.\n\nKDD Cup 2021 summary. In Table 6 (Ying et al., 2021a), which is 0.04 points lower than our best GIN-VIRTUAL baseline.  In terms of methodology, we find that the winning solutions share three important components in common.\n\n(1) Their winning GNN models are indeed large and deep; the number of learnable parameters (single model) ranges from 50M up to 450M, while the number of GNN layers ranges from 11 up to 50, being significantly larger than our baseline models.\n\n(2) All the GNNs perform global message passing at each layer, either through the virtual nodes (Gilmer et al., 2017) or fully-connected Transformer-style self-attention (Ying et al., 2021a).\n\n(3) All the winners utilize 3D structure of molecules to supervise their GNNs. As 3D structure was not provided at our KDD Cup, the winners generate the 3D structure themselves using RDkit (Landrum et al., 2006) or PySCF , both of which provide cheap but less accurate 3D structure of molecules.\n\nAs modeling 3D molecular graphs is a promising direction in graph ML (Sch\u00fctt et al., 2017;Klicpera et al., 2020;Sanchez-Gonzalez et al., 2020;, we have updated PCQM4M to PCQM4Mv2 to include DFT-calculated 3D structures for training molecules. Details are provided in Section 3.\n\n\nUpdates after the KDD Cup\n\nTo facilitate further research advances, we have updated the datasets and leaderboards based on the lessons learned from our KDD Cup 2021. Here we briefly describe our updates. More details are provided in Appendix C.\n\nUpdates on WikiKG90M. From the KDD Cup results, we learned that most of our provided negative entities in the large-scale WikiKG90M are \"easy negatives\", and our current task gives overly-optimistic performance scores. In a realistic large-scale KG completion setting, ML models are required to predict the true tail entity from nearly 90M entities, which is much more challenging.\n\nTo reflect this challenge, we have updated WikiKG90M to WikiKG90Mv2, where we do not provide any candidate entities for validation/test triples. Our initial experiments using the same set of baseline models, shows that WikiKG90Mv2 indeed provides a much harder challenge; our best model COMPLEX-CONCAT only achieves 0.1833 MRR on WikiKG90Mv2 as opposed to achieving 0.8637 MRR on WikiKG90M, leaving significant room for further improvement.\n\nUpdates on PCQM4M. From the KDD Cup results, we saw that the winners effectively utilized (self-calculated) 3D structure of molecules. Modeling molecular graphs in 3D space is of great interest to the graph ML community; We therefore have updated PCQM4M to PCQM4Mv2, where we provide DFT-calculated 3D structure for training molecules. For validation and test molecules, 3D structures is not be provided, and ML models still need to make prediction based on the 2D molecular graphs. In updating to PCQM4Mv2, we are also fixing subtle but important mismatch between some of the 2D molecular graphs and the corresponding 3D molecular graphs. Our preliminary experiments on PCQM4Mv2 suggest that the all the baseline models' MAE is improved by \u2248 0.04 [eV] compared to PCQM4M, although the trends in model performance stay almost the same as PCQM4M.\n\nUpdates on leaderboards. We are introducing public leaderboards to facilitate further research advances after our KDD Cup. The test submissions of the KDD Cup 2021 were evaluated on the entire hidden test set. After the KDD Cup, we are randomly splitting the test set into two: \"test-dev\" and \"test-challenge\". The test-dev set is be used for public leaderboards that evaluate test submissions any time during a year. The test-challenge set is be left for future competitions, which we plan to hold annually to facilitate community engagement. The leaderboards have been released together with the updated datasets.\n\n\nConclusions\n\nModern applications of graph ML involve large-scale graph data with billions of edges or millions of graphs. ML advances on large graph data have been limited due to the lack of a suitable benchmark.\n\nHere we present OGB-LSC, with the goal of advancing state-of-the-art in large-scale graph ML. OGB-LSC provides the three large-scale realistic benchmark datasets, covering the core graph ML tasks of node classification, link prediction, and graph regression. We perform dedicated baseline analysis, scaling up advanced graph models to large graphs. We show that advanced and expressive models can significantly outperform simpler baseline models, suggesting opportunities for further dedicated effort to yield even better performance.\n\nWe used our datasets for the recent ACM KDD Cup 2021, where we have attracted huge engagement from the community and have already witnessed significant performance improvement. We summarize the winning solutions for each dataset, highliting the current best practices in large-scale graph ML. Finally, we describe how we have updated our datasets after the KDD Cup to further facilitate research advances. Overall, we hope OGB-LSC encourages dedicated community efforts to tackle the important but challenging problem of large-scale graph ML.\n\n\n(c) Did you include any new assets either in the supplemental material or as a URL? [Yes]\n\nAll of our relevant URLs are described in Appendix A. (d) Did you discuss whether and how consent was obtained from people whose data you're using/curating? [Yes] We are using public datasets and closely follow the license rules. (e) Did you discuss whether the data you are using/curating contains personally identifiable information or offensive content? [Yes] Our datasets do not contain any private nor offensive information. 5. If you used crowdsourcing or conducted research with human subjects... A Key Information about OGB-LSC Dataset documentation. All of our datasets as well as how to use them through our Python package are documented at https://ogb.stanford.edu/kddcup2021/. Our baseline code to reproduce all the results for each dataset is available at https://github.com/snap-stanford/ ogb/tree/master/examples/lsc.\n\nIntended use. OGB-LSC is intended for machine learning and data scientists to develop ML models to tackle the challenge of large-scale graph ML.\n\nRelevant URLs. OGB-LSC maintains the following:\n\n\u2022 Official website (https://ogb.stanford.edu/kddcup2021/) is the main reference of OGB-LSC. It provides an overview of the OGB-LSC, descriptions of the datasets as well as detailed documentations of how to use the datasets through the OGB Python package. The subpage (https://ogb.stanford.edu/kddcup2021/results/) also contains the leaderboards during the KDD Cup 2021 as well as the technical reports and code provided by the winners.\n\n\u2022 Github repository (https://github.com/snap-stanford/ogb) hosts the source code for the OGB Python package. OGB-LSC datasets and evaluation are all managed by the Python package. We also release all the baseline code that we used in our experiments.\n\n\u2022 Datasets are extremely large (around 300GB in total) and are hosted under AWS with the help of the DGL Team. Our users do not need to directly interact with the URL, as the dataset download and processing are all managed by our Python package.\n\n\u2022 Mailing list (https://groups.google.com/g/open-graph-benchmark) is used for making any announcements about OGB/OGB-LSC.\n\nHosting and maintenance plan. OGB-LSC's Python package is hosted and version-tracked via Github. All the datasets are hosted under the AWS with the help of the DGL Team. We design the Python package to handle downloading and processing of the datasets. OGB is a community-driven initiative that has been actively maintained by our team members.\n\nLicensing. The OGB Python package uses the MIT license. Each dataset has its own license. Specifically, MAG240M uses ODC-BY, WikiKG90M uses CC-0, and PCQM4M uses CC BY 4.0.\n\nAuthor statement. We bear all responsibility in case of violation of rights, etc., and confirmation of the data license.\n\nComputing resources. We ran all the experiments on a server with 10 GeForce RTX 2080 GPUs and an Intel(R) Xeon(R) Gold 6148 CPU @ 2.40GHz.\n\nLimitations. Large-scale graph ML has a wide variety of application domains and there are representative graphs that we cannot cover in the current OGB-LSC datasets. Examples include large-scale recommender systems, social networks, and financial networks. These graphs are hard to obtain due to privacy and cooperative concerns, but we hope to include these realistic large graphs in the future if we have a chance. That being said, it is our hope that many methodological insights on our large graphs (training strategy, GNN architecture, regularization, etc) still transfer well to a variety of large-scale graphs. We leave the thorough investigation to future work.\n\nPotential negative social impacts. All of our datasets are derived from practically-relevant tasks in the real world; hence, developing models and deploying them to the real-world could potentially produce predictions that are influenced by the bias in the datasets. For example, regarding the MAG240M dataset, we may use the resulting paper and author embeddings to perform a variety of downstream ML tasks such as searching for similar papers or recommending author collaboration and paper citations. Thus, it is critical to ensure there is no undesirable bias in the embeddings. There could be also misuse of highly accurate ML models. For instance, regarding the PCQM4M dataset, we  (Leskovec and Sosi\u010d, 2016) is then used to compute the graph statistics. MAG240M (homo) represents the homogenized MAG240M graph with only paper nodes and citation links. Some graph statistics were omitted due to their high computational cost (the calculation did not complete in two weeks). need to make sure that the trained molecular property predictor is used in the right way to develop useful drugs/materials rather than harmful ones.\n\n\nB Basic Graph Statistics of the Datasets\n\nThe basic graph statistics of the OGB-LSC datasets are provided in Table 8.\n\n\nC Details about Dataset Updates after the KDD Cup 2021\n\nMAG240M updates. The MAG240M dataset itself has not been changed. The only update is on the test set. In Table 8, we report the test-dev accuracy of all the models.\n\nWikiKG90Mv2 updates. The WikiKG90M dataset has been updated to WikiKG90Mv2. Below we summarize the updates we have applied to the dataset.\n\n\u2022 No candidate tails provided. The most important update is that we do not provide any candidate tail entities for validation/test triples. Hence, a model needs to predict the target tail entity out of all the entities in Wikidata. \u2022 Created from more recent Wikidata. The WikiKG90Mv2 is based on the public Wikidata dump downloaded at three time-stamps: May 17th, June 7th, and June 28th of 2021, for training, validation, and testing, respectively. We retain all the entities and relations in the September dump, resulting in 91,230,610 entities, 1,387 relations, and 601,062,811 triplets in total. \u2022 A better text encoder used. The text features of WikiKG90Mv2 are obtained by using MPNet (Reimers and Gurevych, 2019;, which is shown to be significantly better sentence encoder (Reimers and Gurevych, 2019). \u2022 Balancing relation types in validation/test triples. On the new Wikidata dumps, we found the relation types of the raw validation/test triples are highly-skewed; the most frequent relation, \"cites work (P2860)\", occupies 60% and 85% of the entire validation and test triples, respectively. To test a model's capability to perform well across all types of relations, we subsample 15,000 triples from the entire validation/test triples such that the resulting relation counts are proportional to the cubic-root of the original relation counts.\n\nIn Table 10, we show head entities that have very sparse connection in the training KG. We see that textual features could provide important signals for predicting these triples.\n\nWe perform an extensive baseline analysis on WikiKG90Mv2. We used the same set of hyper-parameters and baseline models as our original WikiKG90M. Different from WikiKG90M, WikiKG90Mv2 does not provide any candidate tail entities. A na\u00efvely approach is to use the entire entities as the tail candidates. However, this approach does not scale well to a KG with nearly 90M entities because we need to predict scores for all the 90M entities for every triple. Nonetheless, in practice, most of the entities are obvious negatives: e.g., for the relation type \"is located in\", any entities that are not locations can be easily filtered out as negatives. Based on the the above intuition, we consider the relation-specific tail candidate sets. Specifically, on training triples, we pre-compute 20K most frequent tail entities for each relation and treat them as candidate tail entities for that relation. At inference time, we use our KG model to score among those relation-specific candidates.\n\nThe results are provided in Table 10. Overall, we observe that the relative trends are similar to the original WikiKG90Mv2. Especially the CONCAT encoder provides the best MRR performance. Different from WikiKG90M, the MRR score on the new WikiKG90Mv2 is far perfect score of 1 and leaves a lot of room for improvement. Overall, we believe it is promising to explore how to quickly generate a small number of high-quality candidate tail entities out of all the entities so that KG models only need to score a much fewer number of candidate entities.\n\nPCQM4Mv2 updates. The PCQM4M dataset has been updated to PCQM4Mv2. Below we summarize the updates we have applied to the dataset.\n\n\u2022 3D molecular structures provided. We additionally provide 3D structures for training molecules. These structures are calculated by DFT and are obtained together with the HOMO-LUMO gap. \u2022 SMILES strings are partly updated. In the process of preparing the 3D structures, we found a subtle mismatch between SMILES strings (i.e., 2D molecular graphs) and the HOMO-LUMO gap for about 10% of the entire molecules. Specifically, the SMILES strings can be changed in the course of DFT's geometry optimization, but in PCQM4M, we provided the initial SMILES strings. In the updated PCQM4Mv2, we provide SMILES strings corresponding to the final optimized 3D structures. Note that the HOMO-LUMO gap was calculated by DFT based on the final 3D structures (Nakata and Shimazaki, 2017); hence, it makes more sense to correspond the HOMO-LUMO gap with the SMILES string associated with the final 3D structures. \u2022 Number of molecules decreased slightly. As a result of the SMILES update, some molecules can no longer be parsed by the commonly-used chemistry toolkit, i.e., rdkit (Landrum et al., 2006). As a result, the total number of molecules has been slightly reduced to 3,746,619. \u2022 Split ratio changed. For PCQM4Mv2, we set the split ratio for train/validation/test-dev/testchallenge to 90/2/4/4. The split is still done by PubChem compound ID so that there is no test label leakage, i.e., all the test molecules in PCQM4Mv2 is in the test split of PCQM4M.\n\nSimilar to PCQM4M, we also provide our baseline analysis on the updated PCQM4Mv2 dataset. At inference time, we clamped the output values to be between 0 and 20, which prevents our models from predicting erroneous values for some test molecules. We show the results in Tables 12 and  13. We found that all the models were able to achieve lower MAE compared to PCQM4M, probably because we have fixed the mismatch bug described above. Beyond the overall better MAE, we see that the trend in model performance is mostly preserved; larger and more expressive GNN models achieve better results. For the GNNs, we observe that the depth helps more than width. Interestingly, too-wide models often make unstable prediction on validation molecules.     \n\nFigure 2 :\n2A schema diagram of MAG240M.\n\n\n(a) Did you include the full text of instructions given to participants and screenshots, if applicable? [N/A] (b) Did you describe any potential participant risks, with links to Institutional Review Board (IRB) approvals, if applicable? [N/A] (c) Did you include the estimated hourly wage paid to participants and the total amount spent on participant compensation? [N/A]\n\nTable 1 :\n1Basic statistics of the OGB-LSC datasets used in KDD Cup 2021. Datasets marked by \u2020 has been updated to v2 after the KDD Cup (cf. Section 3).Task type \nDataset \nStatistics \n\nNode-level \nMAG240M \n#nodes: \n244,160,499 \n#edges: \n1,728,364,232 \n\nLink-level \nWikiKG90M \n \u2020 #nodes: \n87,143,637 \n#edges: \n504,220,369 \n\nGraph-level \nPCQM4M \n \u2020 \n#graphs: \n3,803,453 \n#edges (total): \n55,399,880 \n\n\n\nTable 2 :\n2Results of MAG240M measured by the accuracy (%).Model \n#Params Validation Test \n\nMLP \n0.5M 52.67 52.73 \nLABELPROP \n0 58.44 56.29 \nSGC \n0.7M 65.82 65.29 \nSIGN \n3.8M 66.64 66.09 \nMLP+C&S \n0.5M 66.98 66.18 \nGRAPHSAGE (NS) \n4.9M 66.79 66.28 \nGAT (NS) \n4.9M 67.15 66.80 \n\nR-GRAPHSAGE (NS) \n12.2M 69.86 68.94 \nR-GAT (NS) \n12.3M 70.02 69.42 \n\nKDD 1ST: BD-PGL \n75.49 \nKDD 2ND: ACADEMIC \n75.19 \nKDD 3RD: SYNERISE AI \n74.60 \n\n\n\nTable 4 :\n4Textual representation of validation triplets whose head entities only appear once as head in the training WikiKG90M.Head \nRelation \nTail \n\nFood and drink companies of Bulgaria combines topics Bulgaria \nPerforming arts in Denmark \ncombines topics performing arts \nAnglicanism in Grenada \ncombines topics Anglicanism \nChuan Li \noccupation \nresearcher \nPetra Junkova \ngiven name \nPetra \n\n\n\nTable 5 :\n5Results of WikiKG90M measured by Mean Reciprocal Rank (MRR).Model \n#Params Validation Test \n\nTRANSE-SHALLOW \n17.4B 0.7559 0.7412 \nCOMPLEX-SHALLOW \n17.4B 0.6142 0.5883 \nTRANSE-ROBERTA \n0.3M 0.6039 0.6288 \nCOMPLEX-ROBERTA \n0.3M 0.7052 0.7186 \nTRANSE-CONCAT \n17.4B 0.8494 0.8548 \nCOMPLEX-CONCAT \n17.4B 0.8425 0.8637 \n\nKDD 1ST: BD-PGL \n0.9727 \nKDD 2ND: OHMYGOD \n0.9712 \nKDD 3RD: GRAPHMIRACLES \n0.9707 \n\n\n\nTable 6 :\n6Results of PCQM4M measured by MAE[eV]. The lower, the better. Ablation study of using only 10% of training data is also shown. Chemical accuracy indicates the final goal for practical usefulness.Model \n#Params Validation Test \n\nMLP-FINGERPRINT \n16.1M 0.2044 0.2070 \nGCN \n2.0M 0.1684 0.1842 \nGCN-VIRTUAL \n4.9M 0.1510 0.1580 \nGIN \n3.8M 0.1536 0.1685 \nGIN-VIRTUAL \n6.7M 0.1396 0.1494 \n\nMLP-FINGERPRINT (10% train) \n6.8M 0.2708 0.2659 \nGIN-VIRTUAL (10% train) \n6.7M 0.1790 0.1892 \n\nKDD 1ST: MACHINELEARNING \n0.1208 \nKDD 2ND: SUPERHELIX \n0.1210 \nKDD 3RD: QUANTUM \n0.1211 \n\nChemical accuracy (goal) \n-\n0.0430 \n\n\n\nTable 7 :\n7Model size and the MAE performance[eV]. For both models, the width indicates the hidden dimensionality. For GIN-VIRTUAL, the depth represents the number of GNN layers, while for the MLP-FINGERPRINT, the depth represents the the number of hidden layers in MLP.Model \nWidth Depth #Params Validation \n\nMLP-FINGERPRINT \n\n1600 \n6 \n16.1M 0.2044 \n1600 \n4 \n11.0M 0.2044 \n1600 \n2 \n5.8M 0.2220 \n1200 \n6 \n9.7M 0.2083 \n\nGIN-VIRTUAL \n\n600 \n5 \n6.7M 0.1410 \n600 \n3 \n3.7M 0.1462 \n300 \n5 \n1.7M 0.1442 \n300 \n3 \n1.0M 0.1512 \n\n\n\nTable 8 :\n8Basic graph statistics of the OGB-LSC datasets. The last three graph statistics are calculated over the 'standardized' graphs, where the graphs are first converted into undirected and unlabeled homogeneous graphs with duplicated edges removed. The SNAP library\n\nTable 9 :\n9Results of MAG240M measured by the accuracy (%). R-GRAPHSAGE/-GAT utilize the full heterogeneous graph information, while the other models operate on the homogeneous paper citation graph. Test accuracy is evaluated on the test-dev set.Model \n#Params Validation Test-dev \n\nMLP \n0.5M \n52.67 \n52.76 \nLABELPROP \n0 \n58.44 \n56.38 \nSGC \n0.7M \n65.82 \n65.30 \nSIGN \n3.8M \n66.64 \n66.03 \nMLP+C&S \n0.5M \n66.98 \n66.05 \nGRAPHSAGE (NS) \n4.9M \n66.79 \n66.21 \nGAT (NS) \n4.9M \n67.15 \n66.71 \n\nR-GRAPHSAGE (NS) \n12.2M \n69.86 \n68.78 \nR-GAT (NS) \n12.3M \n70.02 \n69.31 \n\nKDD 1ST: BD-PGL \nEnsemble \n75.39 \nKDD 2ND: ACADEMIC \nEnsemble \n75.07 \nKDD 3RD: SYNERISE AI \nEnsemble \n74.57 \n\n\n\nTable 10 :\n10Textual representation of validation triplets whose head entities only appear once as head in the training WikiKG90Mv2.Head \nRelation \nTail \n\nHerbert Hoover's Inaugural Address \ncountry \nUnited States of America \nJussi Award for Best Sound Recording instance of \nclass of award \norgan dose \ncalculated from \nabsorbed dose \nBritish Endurance Racing Team \ncountry \nUnited Kingdom \nKnee bursae \nanatomical location \nknee \nChurches in Dekanat Leuchtenberg \nis a list of \nchurch building \nweb content management system \nmodel item \nworkflow management system \nStephan von Divonne \ngiven name \nStephan \nMinecraft mod \ndepends on software Minecraft \nbeer pouring \nuses \nbeer engine \n\n\n\nTable 11 :\n11Results of WikiKG90Mv2 measured by the Mean Reciprocal Rank (MRR).Model \n#Params Validation Test-dev \n\nTRANSE-SHALLOW \n18.2B \n0.1103 \n0.0824 \nCOMPLEX-SHALLOW \n18.2B \n0.1150 \n0.0985 \nTRANSE-MPNET \n0.3M \n0.1128 \n0.0860 \nCOMPLEX-MPNET \n0.3M \n0.1258 \n0.0988 \nTRANSE-CONCAT \n18.2B \n0.2060 \n0.1761 \nCOMPLEX-CONCAT \n18.2B \n0.2048 \n0.1761 \n\n\n\nTable 12 :\n12Results of PCQM4Mv2 measured by MAE[eV]. The lower, the better. Ablation study of using only 10% of training data is also shown. Chemical accuracy indicates the final goal for practical usefulness.Model \n#Params Validation Test-dev \n\nMLP-FINGERPRINT \n16.1M \n0.1753 \n0.1760 \nGCN \n2.0M \n0.1379 \n0.1398 \nGCN-VIRTUAL \n4.9M \n0.1153 \n0.1152 \nGIN \n3.8M \n0.1195 \n0.1218 \nGIN-VIRTUAL \n6.7M \n0.1083 \n0.1084 \n\nMLP-FINGERPRINT (10% train) \n16.1M \n0.2429 \n0.2445 \nGIN-VIRTUAL (10% train) \n6.7M \n0.1442 \n0.1446 \n\nChemical accuracy (goal) \n-\n0.0430 \n\n\n\nTable 13 :\n13Model size and the MAE performance[eV]. For both models, the width indicates the hidden dimensionality. For GIN-VIRTUAL, the depth represents the number of GNN layers, while for the MLP-FINGERPRINT, the depth represents the the number of hidden layers in MLP.Model \nWidth Depth #Params Validation \n\nMLP-FINGERPRINT \n\n1600 \n6 \n16.1M \n0.1753 \n1600 \n4 \n11.0M \n0.1752 \n1600 \n2 \n5.8M \n0.1954 \n1200 \n6 \n9.7M \n0.1804 \n\nGIN-VIRTUAL \n\n600 \n5 \n6.7M \n0.1083 \n600 \n3 \n3.7M \n0.1239 \n300 \n5 \n1.7M \n0.1100 \n300 \n3 \n1.0M \n0.1181 \n\nSpecifically, MAG240M is 126 times larger than ogbn-mag in terms of the number of nodes, WikiKG90M is 35 times larger than ogbl-wikikg2 in terms of the number of nodes, and PCQM4M is 9 times larger than ogbg-molpcba in terms of the number of graphs.\nOGB-LSC Datasets, Baselines, and KDD Cup SummaryWe describe the OGB-LSC datasets, covering three key task categories (node-, link-, and graph-level prediction tasks) of ML on graphs. We emphasize the practical relevance and data split for each dataset, making our task closely aligned to realistic applications. Through our extensive baseline experiments, we show that advanced expressive models tend to give much better performance than simple graph ML models, leaving room for further improvement. All the OGB-LSC datasets are available through the OGB Python package(Hu et al., 2020a). All the baseline and package code is available at https://github.com/snap-stanford/ogb.\nSee the results at https://ogb.stanford.edu/kddcup2021/results/\nWe concatenate the title and description with comma, e.g., 'Geoffrey Hinton, computer scientist and psychologist', and pass the sentence to a ROBERTA sentence encoder (Note that the ROBERTA model was trained before September 2020, so there is no obvious information leak). The title or/and description are sometimes missing, in which case we simply use the blank sentence to replace it.\nNote that this is more strict than the standard MRR since there is no partial score for positive entities being ranked outside of top 10.\nDetailed discussion can be found at https://github.com/snap-stanford/ogb/ discussions/162\nAcknowledgementWe thank Michele Catasta and Larry Zitnick for helpful discussion, Shigeru Maya for motivating the project, Adrijan Bradaschia for setting up the server for the project, and Amit Bleiweiss, Benjamin Braun and Hanjun Dai for providing helpful feedback on our baseline code, and the DGL Team for hosting our large datasets. The HOKUSAI facility was used to perform some of the quantum calculations. This work was supported by the Japan Society for the Promotion of Science (JSPS KAKENHI Grant no. 18H03206). We are also grateful to Maeda Toshiyuki for helpful discussions.\nLarge-scale graph representation learning with very deep gnns and self-supervision. Ravichandra Addanki, W Peter, David Battaglia, Andreea Budden, Jonathan Deac, Thomas Godwin, Wai Keck, Lok Sibon, Alvaro Li, Jacklynn Sanchez-Gonzalez, Shantanu Stott, Thakoor, arXiv:2107.09422arXiv preprintRavichandra Addanki, Peter W Battaglia, David Budden, Andreea Deac, Jonathan Godwin, Thomas Keck, Wai Lok Sibon Li, Alvaro Sanchez-Gonzalez, Jacklynn Stott, Shantanu Thakoor, et al. Large-scale graph representation learning with very deep gnns and self-supervision. arXiv preprint arXiv:2107.09422, 2021.\n\nFreebase: a collaboratively created graph database for structuring human knowledge. Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, Jamie Taylor, Special Interest Group on Management of Data (SIGMOD). AcMKurt Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, and Jamie Taylor. Freebase: a collabo- ratively created graph database for structuring human knowledge. In Special Interest Group on Management of Data (SIGMOD), pages 1247-1250. AcM, 2008.\n\nTranslating embeddings for modeling multi-relational data. Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran, Jason Weston, Oksana Yakhnenko, Advances in Neural Information Processing Systems (NeurIPS). Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran, Jason Weston, and Oksana Yakhnenko. Translating embeddings for modeling multi-relational data. In Advances in Neural Information Processing Systems (NeurIPS), pages 2787-2795, 2013.\n\nLanguage models are few-shot learners. Benjamin Tom B Brown, Nick Mann, Melanie Ryder, Jared Subbiah, Prafulla Kaplan, Arvind Dhariwal, Pranav Neelakantan, Girish Shyam, Amanda Sastry, Askell, arXiv:2005.14165arXiv preprintTom B Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. arXiv preprint arXiv:2005.14165, 2020.\n\nPerspective on density functional theory. K Burke, http:/link.aip.org/link/doi/10.1063/1.4704546J. Chem. Phys. 136150901K. Burke. Perspective on density functional theory. J. Chem. Phys., 136:150901, 2012. URL http://link.aip.org/link/doi/10.1063/1.4704546.\n\nJianyu Cai, Jiajun Chen, Taoxing Pan, Zhanqiu Zhang, Jie Wang, Technical report of team graphmiracles in the wikikg90m-lsc track of ogb-lsc@ kdd cup 2021. Jianyu Cai, Jiajun Chen, Taoxing Pan, Zhanqiu Zhang, and Jie Wang. Technical report of team graphmiracles in the wikikg90m-lsc track of ogb-lsc@ kdd cup 2021. 2021.\n\nRecent progress in organic photovoltaics: Device architecture and optical design. Weiran Cao, Jiangeng Xue, 10.1039/C4EE00260AEnergy Environ. Sci. 7Weiran Cao and Jiangeng Xue. Recent progress in organic photovoltaics: Device architecture and optical design. Energy Environ. Sci., 7:2123-2144, 2014. doi: 10.1039/C4EE00260A. URL http://dx.doi.org/10.1039/C4EE00260A.\n\nOpen catalyst 2020 (oc20) dataset and community challenges. Lowik Chanussot, Abhishek Das, Siddharth Goyal, Thibaut Lavril, Muhammed Shuaibi, Morgane Riviere, Kevin Tran, Javier Heras-Domingo, Caleb Ho, Weihua Hu, Aini Palizhati, Anuroop Sriram, Brandon Wood, Junwoong Yoon, Devi Parikh, C Lawrence Zitnick, Zachary Ulissi, 10.1021/acscatal.0c04525ACS Catal. 11Lowik Chanussot, Abhishek Das, Siddharth Goyal, Thibaut Lavril, Muhammed Shuaibi, Morgane Riviere, Kevin Tran, Javier Heras-Domingo, Caleb Ho, Weihua Hu, Aini Palizhati, Anuroop Sriram, Brandon Wood, Junwoong Yoon, Devi Parikh, C. Lawrence Zitnick, and Zachary Ulissi. Open catalyst 2020 (oc20) dataset and community challenges. ACS Catal., 11:6059-6072, 2021. URL https://doi.org/10.1021/acscatal.0c04525.\n\nFastgcn: fast learning with graph convolutional networks via importance sampling. Jie Chen, Tengfei Ma, Cao Xiao, arXiv:1801.10247arXiv preprintJie Chen, Tengfei Ma, and Cao Xiao. Fastgcn: fast learning with graph convolutional networks via importance sampling. arXiv preprint arXiv:1801.10247, 2018.\n\nCluster-GCN: An efficient algorithm for training deep and large graph convolutional networks. Wei-Lin Chiang, Xuanqing Liu, Si Si, Yang Li, Samy Bengio, Cho-Jui Hsieh, ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD). Wei-Lin Chiang, Xuanqing Liu, Si Si, Yang Li, Samy Bengio, and Cho-Jui Hsieh. Cluster-GCN: An efficient algorithm for training deep and large graph convolutional networks. In ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD), pages 257-266, 2019.\n\nSynerise at kdd cup 2021: Node classification in massive heterogeneous graphs. Micha\u0142 Daniluk, Jacek Dabrowski, Barbara Rychalska, Konrad Go\u0142uchowski, Micha\u0142 Daniluk, Jacek Dabrowski, Barbara Rychalska, and Konrad Go\u0142uchowski. Synerise at kdd cup 2021: Node classification in massive heterogeneous graphs. 2021. URL https: //ogb.stanford.edu/paper/kddcup2021/mag240m_SyneriseAI.pdf.\n\nJacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova Bert, arXiv:1810.04805Pre-training of deep bidirectional transformers for language understanding. arXiv preprintJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprint arXiv:1810.04805, 2018.\n\nA century of science: Globalization of scientific collaborations, citations, and innovations. Yuxiao Dong, Hao Ma, Zhihong Shen, Kuansan Wang, ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD). ACMYuxiao Dong, Hao Ma, Zhihong Shen, and Kuansan Wang. A century of science: Globalization of scientific collaborations, citations, and innovations. In ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD), pages 1437-1446. ACM, 2017.\n\nMolecular docking and structure-based drug design strategies. Leonardo G Ferreira, Ricardo N Dos Santos, Glaucius Oliva, Adriano D Andricopulo, 10.3390/molecules200713384Molecules. 207Leonardo G. Ferreira, Ricardo N. Dos Santos, Glaucius Oliva, and Adriano D. Andricopulo. Molec- ular docking and structure-based drug design strategies. Molecules, 20(7):13384-13421, 2015. ISSN 1420-3049. doi: 10.3390/molecules200713384. URL https://www.mdpi.com/ 1420-3049/20/7/13384.\n\nMatthias Fey, Jan Eric Lenssen, arXiv:1903.02428Fast graph representation learning with pytorch geometric. arXiv preprintMatthias Fey and Jan Eric Lenssen. Fast graph representation learning with pytorch geometric. arXiv preprint arXiv:1903.02428, 2019.\n\nNeural message passing for quantum chemistry. Justin Gilmer, S Samuel, Schoenholz, F Patrick, Oriol Riley, George E Vinyals, Dahl, International Conference on Machine Learning (ICML). Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, and George E Dahl. Neural message passing for quantum chemistry. In International Conference on Machine Learning (ICML), pages 1273-1272, 2017.\n\nLigand-field theory. J S Griffith, L E Orgel, Quarterly Reviews, Chemical Society. 114JS Griffith and LE Orgel. Ligand-field theory. Quarterly Reviews, Chemical Society, 11(4):381-393, 1957.\n\nA survey on knowledge graph-based recommender systems. Qingyu Guo, Fuzhen Zhuang, Chuan Qin, Hengshu Zhu, Xing Xie, Hui Xiong, Qing He, IEEE Transactions on Knowledge and Data Engineering. Qingyu Guo, Fuzhen Zhuang, Chuan Qin, Hengshu Zhu, Xing Xie, Hui Xiong, and Qing He. A survey on knowledge graph-based recommender systems. IEEE Transactions on Knowledge and Data Engineering, 2020.\n\nInductive representation learning on large graphs. Rex William L Hamilton, Jure Ying, Leskovec, Advances in Neural Information Processing Systems (NeurIPS). William L Hamilton, Rex Ying, and Jure Leskovec. Inductive representation learning on large graphs. In Advances in Neural Information Processing Systems (NeurIPS), pages 1025-1035, 2017.\n\nArray programming with numpy. Jarrod Charles R Harris, Millman, J St\u00e9fan, Ralf Van Der Walt, Pauli Gommers, David Virtanen, Eric Cournapeau, Julian Wieser, Sebastian Taylor, Nathaniel J Berg, Smith, Nature. 5857825Charles R Harris, K Jarrod Millman, St\u00e9fan J van der Walt, Ralf Gommers, Pauli Virtanen, David Cournapeau, Eric Wieser, Julian Taylor, Sebastian Berg, Nathaniel J Smith, et al. Array program- ming with numpy. Nature, 585(7825):357-362, 2020.\n\nDeep residual learning for image recognition. Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pages 770-778, 2016.\n\nOpen graph benchmark: Datasets for machine learning on graphs. Weihua Hu, Matthias Fey, Marinka Zitnik, Yuxiao Dong, Hongyu Ren, Bowen Liu, Michele Catasta, Jure Leskovec, Advances in Neural Information Processing Systems (NeurIPS). Weihua Hu, Matthias Fey, Marinka Zitnik, Yuxiao Dong, Hongyu Ren, Bowen Liu, Michele Catasta, and Jure Leskovec. Open graph benchmark: Datasets for machine learning on graphs. In Advances in Neural Information Processing Systems (NeurIPS), 2020a.\n\nStrategies for pre-training graph neural networks. Weihua Hu, Bowen Liu, Joseph Gomes, Marinka Zitnik, Percy Liang, Vijay Pande, Jure Leskovec, International Conference on Learning Representations (ICLR). Weihua Hu, Bowen Liu, Joseph Gomes, Marinka Zitnik, Percy Liang, Vijay Pande, and Jure Leskovec. Strategies for pre-training graph neural networks. In International Conference on Learning Representations (ICLR), 2020b.\n\nForcenet: A graph neural network for large-scale quantum calculations. Weihua Hu, Muhammed Shuaibi, Abhishek Das, Siddharth Goyal, Anuroop Sriram, Jure Leskovec, Devi Parikh, C Lawrence Zitnick, arXiv:2103.01436arXiv preprintWeihua Hu, Muhammed Shuaibi, Abhishek Das, Siddharth Goyal, Anuroop Sriram, Jure Leskovec, Devi Parikh, and C Lawrence Zitnick. Forcenet: A graph neural network for large-scale quantum calculations. arXiv preprint arXiv:2103.01436, 2021.\n\nCombining label propagation and simple models out-performs graph neural networks. Qian Huang, Horace He, Abhay Singh, Ser-Nam Lim, Austin R Benson, arXiv:2010.13993arXiv preprintQian Huang, Horace He, Abhay Singh, Ser-Nam Lim, and Austin R Benson. Combining label propa- gation and simple models out-performs graph neural networks. arXiv preprint arXiv:2010.13993, 2020.\n\nBatch normalization: Accelerating deep network training by reducing internal covariate shift. Sergey Ioffe, Christian Szegedy, International Conference on Machine Learning (ICML). Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. In International Conference on Machine Learning (ICML), pages 448-456, 2015.\n\nSemi-supervised classification with graph convolutional networks. N Thomas, Max Kipf, Welling, International Conference on Learning Representations (ICLR. Thomas N. Kipf and Max Welling. Semi-supervised classification with graph convolutional networks. In International Conference on Learning Representations (ICLR), 2017.\n\nAuthoritative sources in a hyperlinked environment. M Jon, Kleinberg, Journal of the ACM. 465Jon M Kleinberg. Authoritative sources in a hyperlinked environment. Journal of the ACM, 46(5): 604-632, 1999.\n\nFast and uncertainty-aware directional message passing for non-equilibrium molecules. Johannes Klicpera, Shankari Giri, Johannes T Margraf, Stephan G\u00fcnnemann, NeurIPS-W. Johannes Klicpera, Shankari Giri, Johannes T. Margraf, and Stephan G\u00fcnnemann. Fast and uncertainty-aware directional message passing for non-equilibrium molecules. In NeurIPS-W, 2020.\n\nGreg Landrum, Open-source cheminformatics. Greg Landrum et al. Rdkit: Open-source cheminformatics, 2006.\n\nSnap: A general-purpose network analysis and graph-mining library. Jure Leskovec, Rok Sosi\u010d, ACM Transactions on Intelligent Systems and Technology (TIST). 81Jure Leskovec and Rok Sosi\u010d. Snap: A general-purpose network analysis and graph-mining library. ACM Transactions on Intelligent Systems and Technology (TIST), 8(1):1-20, 2016.\n\nMicrosoft coco: Common objects in context. Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll\u00e1r, C Lawrence Zitnick, eccv. SpringerTsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll\u00e1r, and C Lawrence Zitnick. Microsoft coco: Common objects in context. In eccv, pages 740-755. Springer, 2014.\n\nYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov, Roberta, arXiv:1907.11692A robustly optimized bert pretraining approach. arXiv preprintYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. Roberta: A robustly optimized bert pretraining approach. arXiv preprint arXiv:1907.11692, 2019.\n\nBirds of a feather: Homophily in social networks. Miller Mcpherson, Lynn Smith-Lovin, James M Cook, Annual review of sociology. 271Miller McPherson, Lynn Smith-Lovin, and James M Cook. Birds of a feather: Homophily in social networks. Annual review of sociology, 27(1):415-444, 2001.\n\nDistant supervision for relation extraction with an incomplete knowledge base. Bonan Min, Ralph Grishman, Li Wan, Chang Wang, David Gondek, North American Chapter of the Association for Computational Linguistics (NAACL). Bonan Min, Ralph Grishman, Li Wan, Chang Wang, and David Gondek. Distant supervision for relation extraction with an incomplete knowledge base. In North American Chapter of the Association for Computational Linguistics (NAACL), pages 777-782, 2013.\n\nThe generation of a unique machine description for chemical structures-a technique developed at chemical abstracts service. L Harry, Morgan, Journal of Chemical Documentation. 52Harry L Morgan. The generation of a unique machine description for chemical structures-a technique developed at chemical abstracts service. Journal of Chemical Documentation, 5(2):107-113, 1965.\n\nTudataset: A collection of benchmark datasets for learning with graphs. Christopher Morris, M Nils, Franka Kriege, Kristian Bause, Petra Kersting, Marion Mutzel, Neumann, arXiv:2007.08663arXiv preprintChristopher Morris, Nils M Kriege, Franka Bause, Kristian Kersting, Petra Mutzel, and Marion Neumann. Tudataset: A collection of benchmark datasets for learning with graphs. arXiv preprint arXiv:2007.08663, 2020.\n\n10.1063/1.4938866Maho Nakata. the PubChemQC Project: A Large Chemical Database from the First Principle Calculations. AIP Conf. Proc. 170290058Maho Nakata. the PubChemQC Project: A Large Chemical Database from the First Principle Calculations. AIP Conf. Proc., 1702:090058, 2015. doi: 10.1186/1758-2946-3-4. URL http: //dx.doi.org/10.1063/1.4938866.\n\nPubchemqc project: A large-scale first-principles electronic structure database for data-driven chemistry. Maho Nakata, Tomomi Shimazaki, Journal of chemical information and modeling. 576Maho Nakata and Tomomi Shimazaki. Pubchemqc project: A large-scale first-principles electronic structure database for data-driven chemistry. Journal of chemical information and modeling, 57(6): 1300-1308, 2017.\n\nAutomatic differentiation in pytorch. Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary Devito, Zeming Lin, Alban Desmaison, Luca Antiga, Adam Lerer, Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito, Zeming Lin, Alban Desmaison, Luca Antiga, and Adam Lerer. Automatic differentiation in pytorch. In NIPS-W, 2017.\n\n. Weihua Peng, Donghai Bian, Yanhui Huang, Guangzhi Sheng, Jian Sun, of wikikg90m-lsc. 2021Technical reportWeihua Peng, Donghai Bian, Yanhui Huang, Guangzhi Sheng, and Jian Sun. Technical report of wikikg90m-lsc. 2021. URL https://ogb.stanford.edu/paper/kddcup2021/ wikikg90m_OhMyGod.pdf.\n\nSentence-bert: Sentence embeddings using siamese bert-networks. Nils Reimers, Iryna Gurevych, 11Nils Reimers and Iryna Gurevych. Sentence-bert: Sentence embeddings using siamese bert-networks. 11 2019. URL https://arxiv.org/abs/1908.10084.\n\nEmanuele Rossi, Fabrizio Frasca, Ben Chamberlain, Davide Eynard, Michael Bronstein, Federico Monti, arXiv:2004.11198Sign: Scalable inception graph neural networks. arXiv preprintEmanuele Rossi, Fabrizio Frasca, Ben Chamberlain, Davide Eynard, Michael Bronstein, and Federico Monti. Sign: Scalable inception graph neural networks. arXiv preprint arXiv:2004.11198, 2020.\n\nImagenet large scale visual recognition challenge. Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, International journal of computer vision. 1153Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et al. Imagenet large scale visual recognition challenge. International journal of computer vision, 115(3):211-252, 2015.\n\nLearning to simulate complex physics with graph networks. Alvaro Sanchez-Gonzalez, Jonathan Godwin, Tobias Pfaff, Rex Ying, Jure Leskovec, Peter W Battaglia, International Conference on Machine Learning (ICML). 2020Alvaro Sanchez-Gonzalez, Jonathan Godwin, Tobias Pfaff, Rex Ying, Jure Leskovec, and Peter W Battaglia. Learning to simulate complex physics with graph networks. In International Conference on Machine Learning (ICML), 2020.\n\nModeling relational data with graph convolutional networks. Michael Schlichtkrull, N Thomas, Peter Kipf, Rianne Bloem, Van Den, Ivan Berg, Max Titov, Welling, European Semantic Web Conference. SpringerMichael Schlichtkrull, Thomas N Kipf, Peter Bloem, Rianne Van Den Berg, Ivan Titov, and Max Welling. Modeling relational data with graph convolutional networks. In European Semantic Web Conference, pages 593-607. Springer, 2018.\n\nSchnet: A continuous-filter convolutional neural network for modeling quantum interactions. Kristof Sch\u00fctt, Pieter-Jan Kindermans, Huziel Enoc Sauceda Felix, Stefan Chmiela, Alexandre Tkatchenko, Klaus-Robert M\u00fcller, Advances in Neural Information Processing Systems (NeurIPS). Kristof Sch\u00fctt, Pieter-Jan Kindermans, Huziel Enoc Sauceda Felix, Stefan Chmiela, Alexandre Tkatchenko, and Klaus-Robert M\u00fcller. Schnet: A continuous-filter convolutional neural network for modeling quantum interactions. In Advances in Neural Information Processing Systems (NeurIPS), pages 991-1001, 2017.\n\nMasked label prediction: Unified message passing model for semi-supervised classification. Yunsheng Shi, Zhengjie Huang, Wenjin Wang, Hui Zhong, Shikun Feng, Yu Sun, arXiv:2009.03509arXiv preprintYunsheng Shi, Zhengjie Huang, Wenjin Wang, Hui Zhong, Shikun Feng, and Yu Sun. Masked label prediction: Unified message passing model for semi-supervised classification. arXiv preprint arXiv:2009.03509, 2020.\n\nRunimp: Solution for kddcup 2021 mag240m-lsc. Yunsheng Shi, Zhengjie Team, Weibin Huang, Weiyue Li, Shikun Su, Feng, Yunsheng Shi, PGL Team, Zhengjie Huang, Weibin Li, Weiyue Su, and Shikun Feng. Runimp: So- lution for kddcup 2021 mag240m-lsc. 2021. URL https://ogb.stanford.edu/paper/ kddcup2021/mag240m_BD-PGL.pdf.\n\nIntroducing the knowledge graph: things, not strings. Amit Singhal, Official google blog. 516Amit Singhal. Introducing the knowledge graph: things, not strings. Official google blog, 5:16, 2012.\n\nKaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, Tie-Yan Liu, arXiv:2004.09297Mpnet: Masked and permuted pre-training for language understanding. arXiv preprintKaitao Song, Xu Tan, Tao Qin, Jianfeng Lu, and Tie-Yan Liu. Mpnet: Masked and permuted pre-training for language understanding. arXiv preprint arXiv:2004.09297, 2020.\n\nWeiyue Su, Zeyang Fang, Hui Zhong, Huijuan Wang, Siming Dai, Zhengjie Huang, Yunsheng Shi, Shikun Feng, Zeyu Chen, arXiv:2107.01892Solution for kdd-cup 2021 wikikg90m-lsc. NotearXiv preprintWeiyue Su, Zeyang Fang, Hui Zhong, Huijuan Wang, Siming Dai, Zhengjie Huang, Yunsheng Shi, Shikun Feng, and Zeyu Chen. Note: Solution for kdd-cup 2021 wikikg90m-lsc. arXiv preprint arXiv:2107.01892, 2021.\n\nRecent developments in the pyscf program package. Qiming Sun, Xing Zhang, Samragni Banerjee, Peng Bao, Marc Barbry, S Nick, Blunt, A Nikolay, Bogdanov, H George, Jia Booth, Zhi-Hao Chen, Cui, The Journal of chemical physics. 153224109Qiming Sun, Xing Zhang, Samragni Banerjee, Peng Bao, Marc Barbry, Nick S Blunt, Nikolay A Bogdanov, George H Booth, Jia Chen, Zhi-Hao Cui, et al. Recent developments in the pyscf program package. The Journal of chemical physics, 153(2):024109, 2020.\n\nPathsim: Meta path-based top-k similarity search in heterogeneous information networks. Yizhou Sun, Jiawei Han, Xifeng Yan, S Philip, Tianyi Yu, Wu, Proceedings of the VLDB Endowment. the VLDB Endowment4Yizhou Sun, Jiawei Han, Xifeng Yan, Philip S Yu, and Tianyi Wu. Pathsim: Meta path-based top-k similarity search in heterogeneous information networks. Proceedings of the VLDB Endowment, 4 (11):992-1003, 2011.\n\nRotate: Knowledge graph embedding by relational rotation in complex space. Zhiqing Sun, Zhi-Hong Deng, Jian-Yun Nie, Jian Tang, International Conference on Learning Representations (ICLR). Zhiqing Sun, Zhi-Hong Deng, Jian-Yun Nie, and Jian Tang. Rotate: Knowledge graph embedding by relational rotation in complex space. In International Conference on Learning Representations (ICLR), 2019.\n\nShantanu Thakoor, Corentin Tallec, Mohammad Gheshlaghi Azar, R\u00e9mi Munos, Petar Veli\u010dkovi\u0107, Michal Valko, arXiv:2102.06514Bootstrapped representation learning on graphs. arXiv preprintShantanu Thakoor, Corentin Tallec, Mohammad Gheshlaghi Azar, R\u00e9mi Munos, Petar Veli\u010dkovi\u0107, and Michal Valko. Bootstrapped representation learning on graphs. arXiv preprint arXiv:2102.06514, 2021.\n\nComplex embeddings for simple link prediction. Th\u00e9o Trouillon, Johannes Welbl, Sebastian Riedel, \u00c9ric Gaussier, Guillaume Bouchard, International Conference on Machine Learning (ICML). Th\u00e9o Trouillon, Johannes Welbl, Sebastian Riedel,\u00c9ric Gaussier, and Guillaume Bouchard. Complex embeddings for simple link prediction. In International Conference on Machine Learning (ICML), pages 2071-2080, 2016.\n\nThe anatomy of the facebook social graph. Johan Ugander, Brian Karrer, Lars Backstrom, Cameron Marlow, arXiv:1111.4503arXiv preprintJohan Ugander, Brian Karrer, Lars Backstrom, and Cameron Marlow. The anatomy of the facebook social graph. arXiv preprint arXiv:1111.4503, 2011.\n\nAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, Illia Polosukhin, arXiv:1706.03762Attention is all you need. arXiv preprintAshish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. arXiv preprint arXiv:1706.03762, 2017.\n\nGraph attention networks. Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, Yoshua Bengio, International Conference on Learning Representations (ICLR). Petar Velickovic, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. Graph attention networks. In International Conference on Learning Representations (ICLR), 2018.\n\nWikidata: a free collaborative knowledgebase. Denny Vrande\u010di\u0107, Markus Kr\u00f6tzsch, Communications of the ACM. 5710Denny Vrande\u010di\u0107 and Markus Kr\u00f6tzsch. Wikidata: a free collaborative knowledgebase. Communica- tions of the ACM, 57(10):78-85, 2014.\n\nAlex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, Samuel R Bowman, arXiv:1804.07461Glue: A multi-task benchmark and analysis platform for natural language understanding. arXiv preprintAlex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R Bowman. Glue: A multi-task benchmark and analysis platform for natural language understanding. arXiv preprint arXiv:1804.07461, 2018.\n\nMicrosoft academic graph: When experts are not enough. Kuansan Wang, Zhihong Shen, Chiyuan Huang, Chieh-Han Wu, Yuxiao Dong, Anshul Kanakia, Quantitative Science Studies. 11Kuansan Wang, Zhihong Shen, Chiyuan Huang, Chieh-Han Wu, Yuxiao Dong, and Anshul Kanakia. Microsoft academic graph: When experts are not enough. Quantitative Science Studies, 1(1): 396-413, 2020.\n\nDeep graph library: Towards efficient and scalable deep learning on graphs. Minjie Wang, Lingfan Yu, Da Zheng, Quan Gan, Yu Gai, Zihao Ye, Mufei Li, Jinjing Zhou, Qi Huang, Chao Ma, Ziyue Huang, Qipeng Guo, Hao Zhang, Haibin Lin, Junbo Zhao, Jinyang Li, Alexander J Smola, Zheng Zhang, Workshop on Representation Learning on Graphs and Manifolds. Minjie Wang, Lingfan Yu, Da Zheng, Quan Gan, Yu Gai, Zihao Ye, Mufei Li, Jinjing Zhou, Qi Huang, Chao Ma, Ziyue Huang, Qipeng Guo, Hao Zhang, Haibin Lin, Junbo Zhao, Jinyang Li, Alexander J Smola, and Zheng Zhang. Deep graph library: Towards efficient and scalable deep learning on graphs. ICLR Workshop on Representation Learning on Graphs and Manifolds, 2019. URL https://arxiv.org/abs/1909.01315.\n\nSmiles, a chemical language and information system. 1. introduction to methodology and encoding rules. David Weininger, Journal of chemical information and computer sciences. 281David Weininger. Smiles, a chemical language and information system. 1. introduction to methodol- ogy and encoding rules. Journal of chemical information and computer sciences, 28(1):31-36, 1988.\n\nSimplifying graph convolutional networks. Felix Wu, Tianyi Zhang, Amauri Holanda De SouzaJr, Christopher Fifty, Tao Yu, Kilian Q Weinberger, International Conference on Machine Learning (ICML). Felix Wu, Tianyi Zhang, Amauri Holanda de Souza Jr, Christopher Fifty, Tao Yu, and Kilian Q Weinberger. Simplifying graph convolutional networks. In International Conference on Machine Learning (ICML), 2019.\n\nMoleculenet: a benchmark for molecular machine learning. Zhenqin Wu, Bharath Ramsundar, Evan N Feinberg, Joseph Gomes, Caleb Geniesse, S Aneesh, Karl Pappu, Vijay Leswing, Pande, Chemical science. 92Zhenqin Wu, Bharath Ramsundar, Evan N Feinberg, Joseph Gomes, Caleb Geniesse, Aneesh S Pappu, Karl Leswing, and Vijay Pande. Moleculenet: a benchmark for molecular machine learning. Chemical science, 9(2):513-530, 2018.\n\nHow powerful are graph neural networks?. Keyulu Xu, Weihua Hu, Jure Leskovec, Stefanie Jegelka, International Conference on Learning Representations (ICLR). Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. How powerful are graph neural networks? In International Conference on Learning Representations (ICLR), 2019.\n\nTeam littleant's solution of task2. Shuo Yang, Daixin Wang, Dingyuan Zhu, Yakun Wang, Borui Ye, Shuo Yang, Daixin Wang, Dingyuan Zhu, Yakun Wang, and Borui Ye. Team littleant's solution of task2. 2021. URL https://ogb.stanford.edu/paper/kddcup2021/wikikg90m_ littleant.pdf.\n\nRevisiting semi-supervised learning with graph embeddings. Zhilin Yang, W William, Ruslan Cohen, Salakhutdinov, International Conference on Machine Learning (ICML). Zhilin Yang, William W Cohen, and Ruslan Salakhutdinov. Revisiting semi-supervised learning with graph embeddings. In International Conference on Machine Learning (ICML), pages 40-48, 2016.\n\nChengxuan Ying, Tianle Cai, Shengjie Luo, Shuxin Zheng, Guolin Ke, Di He, Yanming Shen, Tie-Yan Liu, arXiv:2106.05234Do transformers really perform bad for graph representation. arXiv preprintChengxuan Ying, Tianle Cai, Shengjie Luo, Shuxin Zheng, Guolin Ke, Di He, Yanming Shen, and Tie-Yan Liu. Do transformers really perform bad for graph representation? arXiv preprint arXiv:2106.05234, 2021a.\n\nAwardee solution of kdd cup 2021 ogb large-scale challenge graph-level track. Chengxuan Ying, Mingqi Yang, Shuxin Zheng, Guolin Ke, Shengjie Luo, Tianle Cai, Chenglin Wu, Yuxin Wang, Yanming Shen, Di He, arXiv:2106.08279arXiv preprintChengxuan Ying, Mingqi Yang, Shuxin Zheng, Guolin Ke, Shengjie Luo, Tianle Cai, Chenglin Wu, Yuxin Wang, Yanming Shen, and Di He. Awardee solution of kdd cup 2021 ogb large-scale challenge graph-level track. arXiv preprint arXiv:2106.08279, 2021b.\n\nGraph convolutional neural networks for web-scale recommender systems. Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, L William, Jure Hamilton, Leskovec, ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD). Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L Hamilton, and Jure Leskovec. Graph convolutional neural networks for web-scale recommender systems. In ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD), pages 974-983, 2018.\n\nGraph-Saint: Graph sampling based inductive learning method. Hanqing Zeng, Hongkuan Zhou, Ajitesh Srivastava, Rajgopal Kannan, Viktor Prasanna, International Conference on Learning Representations (ICLR). 2020Hanqing Zeng, Hongkuan Zhou, Ajitesh Srivastava, Rajgopal Kannan, and Viktor Prasanna. Graph- Saint: Graph sampling based inductive learning method. In International Conference on Learning Representations (ICLR), 2020.\n\nLitegem: Lite geometry enhanced molecular representation learning for quantum property prediction. Shanzhuo Zhang, Lihang Liu, Sheng Gao, Donglong He, Xiaomin Fang, Weibin Li, Zhengjie Huang, Weiyue Su, Wenjin Wang, arXiv:2106.14494arXiv preprintShanzhuo Zhang, Lihang Liu, Sheng Gao, Donglong He, Xiaomin Fang, Weibin Li, Zhengjie Huang, Weiyue Su, and Wenjin Wang. Litegem: Lite geometry enhanced molecular representation learning for quantum property prediction. arXiv preprint arXiv:2106.14494, 2021.\n\nDa Zheng, Xiang Song, Chao Ma, Zeyuan Tan, Zihao Ye, Jin Dong, Hao Xiong, Zheng Zhang, George Karypis, arXiv:2004.08532Dgl-ke: Training knowledge graph embeddings at scale. arXiv preprintDa Zheng, Xiang Song, Chao Ma, Zeyuan Tan, Zihao Ye, Jin Dong, Hao Xiong, Zheng Zhang, and George Karypis. Dgl-ke: Training knowledge graph embeddings at scale. arXiv preprint arXiv:2004.08532, 2020.\n\nChecklist 1. For all authors. Checklist 1. For all authors...\n\nDo the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope?. Yes(a) Do the main claims made in the abstract and introduction accurately reflect the paper's contributions and scope? [Yes]\n\nDid you describe the limitations of your work? [Yes] See Appendix A (c) Did you discuss any potential negative societal impacts of your work?. Yes] See Appendix ADid you describe the limitations of your work? [Yes] See Appendix A (c) Did you discuss any potential negative societal impacts of your work? [Yes] See Appendix A\n\nHave you read the ethics review guidelines and ensured that your paper conforms to them. Have you read the ethics review guidelines and ensured that your paper conforms to them? [Yes]\n\nDid you state the full set of assumptions of all theoretical results. N/A] (b) Did you include complete proofs of all theoretical results? [N/A(a) Did you state the full set of assumptions of all theoretical results? [N/A] (b) Did you include complete proofs of all theoretical results? [N/A]\n\nDid you include the code, data, and instructions needed to reproduce the main experimental results. either in the supplemental material or as a URL)? [Yes] See Appendix A(a) Did you include the code, data, and instructions needed to reproduce the main experi- mental results (either in the supplemental material or as a URL)? [Yes] See Appendix A.\n\nwith respect to the random seed after running experiments multiple times)? [No] Our datasets are very large and offer hidden test sets. Did you report error barsDid you report error bars (e.g., with respect to the random seed after running exper- iments multiple times)? [No] Our datasets are very large and offer hidden test sets;\n\nwhere we report performance of a single run. Russakovsky, hence, we follow the convention of similar large-scale datasets such as ImageNet. GLUE Benchmark. Note that model performance is often very stable on the large datasetshence, we follow the convention of similar large-scale datasets such as ImageNet (Rus- sakovsky et al., 2015), MS-COCO (Lin et al., 2014), GLUE Benchmark (Wang et al., 2018), where we report performance of a single run. Note that model performance is often very stable on the large datasets.\n\ndata, models) or curating/releasing new assets. If you are using existing assets (e.g., code,If you are using existing assets (e.g., code, data, models) or curating/releasing new assets...\n\nIf your work uses existing assets. did you cite the creators? [Yes] See the references in Section 2(a) If your work uses existing assets, did you cite the creators? [Yes] See the references in Section 2.\n", "annotations": {"author": "[{\"end\":130,\"start\":67},{\"end\":200,\"start\":131},{\"end\":265,\"start\":201},{\"end\":278,\"start\":266},{\"end\":291,\"start\":279},{\"end\":359,\"start\":292}]", "publisher": null, "author_last_name": "[{\"end\":76,\"start\":74},{\"end\":143,\"start\":140},{\"end\":211,\"start\":208},{\"end\":277,\"start\":271},{\"end\":290,\"start\":286},{\"end\":305,\"start\":297}]", "author_first_name": "[{\"end\":73,\"start\":67},{\"end\":139,\"start\":131},{\"end\":207,\"start\":201},{\"end\":270,\"start\":266},{\"end\":285,\"start\":279},{\"end\":296,\"start\":292}]", "author_affiliation": "[{\"end\":129,\"start\":78},{\"end\":199,\"start\":145},{\"end\":264,\"start\":213},{\"end\":358,\"start\":307}]", "title": "[{\"end\":64,\"start\":1},{\"end\":423,\"start\":360}]", "venue": null, "abstract": "[{\"end\":1916,\"start\":425}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b57\"},\"end\":2172,\"start\":2150},{\"attributes\":{\"ref_id\":\"b72\"},\"end\":2213,\"start\":2194},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":2258,\"start\":2241},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2307,\"start\":2283},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":2336,\"start\":2307},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":2462,\"start\":2434},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":2485,\"start\":2462},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":2845,\"start\":2828},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":2866,\"start\":2845},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":2886,\"start\":2866},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2905,\"start\":2886},{\"attributes\":{\"ref_id\":\"b65\"},\"end\":3047,\"start\":3030},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":5690,\"start\":5671},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":6894,\"start\":6867},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":7543,\"start\":7520},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":7855,\"start\":7838},{\"attributes\":{\"ref_id\":\"b65\"},\"end\":9357,\"start\":9340},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":9384,\"start\":9364},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":9595,\"start\":9572},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":10019,\"start\":9994},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":10094,\"start\":10067},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":10974,\"start\":10949},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":12109,\"start\":12087},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":12154,\"start\":12132},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":12704,\"start\":12686},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":12772,\"start\":12751},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":13618,\"start\":13596},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":13929,\"start\":13899},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":13967,\"start\":13943},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":14291,\"start\":14276},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":14335,\"start\":14317},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":14414,\"start\":14396},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":15647,\"start\":15619},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":15922,\"start\":15901},{\"attributes\":{\"ref_id\":\"b84\"},\"end\":16475,\"start\":16474},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":17762,\"start\":17741},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":17799,\"start\":17775},{\"attributes\":{\"ref_id\":\"b75\"},\"end\":18862,\"start\":18842},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":20237,\"start\":20209},{\"end\":20423,\"start\":20404},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":20470,\"start\":20452},{\"attributes\":{\"ref_id\":\"b68\"},\"end\":21322,\"start\":21304},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":22362,\"start\":22349},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":22619,\"start\":22600},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":22700,\"start\":22677},{\"end\":22802,\"start\":22788},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":22829,\"start\":22802},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":23180,\"start\":23154},{\"attributes\":{\"ref_id\":\"b64\"},\"end\":24148,\"start\":24131},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":24394,\"start\":24376},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":25085,\"start\":25067},{\"attributes\":{\"ref_id\":\"b66\"},\"end\":25101,\"start\":25085},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":25831,\"start\":25814},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":26020,\"start\":25999},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":26151,\"start\":26133},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":26211,\"start\":26194},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":26863,\"start\":26838},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":28212,\"start\":28192},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":28744,\"start\":28723},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":28817,\"start\":28797},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":29031,\"start\":29009},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":29207,\"start\":29186},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":29229,\"start\":29207},{\"end\":29259,\"start\":29229},{\"end\":33481,\"start\":33476},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":37573,\"start\":37547},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":39192,\"start\":39164},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":39281,\"start\":39253},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":42452,\"start\":42424},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":42766,\"start\":42744},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":50967,\"start\":50949}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":43915,\"start\":43874},{\"attributes\":{\"id\":\"fig_1\"},\"end\":44289,\"start\":43916},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":44690,\"start\":44290},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":45119,\"start\":44691},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":45518,\"start\":45120},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":45930,\"start\":45519},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":46548,\"start\":45931},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":47068,\"start\":46549},{\"attributes\":{\"id\":\"tab_9\",\"type\":\"table\"},\"end\":47341,\"start\":47069},{\"attributes\":{\"id\":\"tab_11\",\"type\":\"table\"},\"end\":48009,\"start\":47342},{\"attributes\":{\"id\":\"tab_12\",\"type\":\"table\"},\"end\":48701,\"start\":48010},{\"attributes\":{\"id\":\"tab_13\",\"type\":\"table\"},\"end\":49049,\"start\":48702},{\"attributes\":{\"id\":\"tab_14\",\"type\":\"table\"},\"end\":49600,\"start\":49050},{\"attributes\":{\"id\":\"tab_15\",\"type\":\"table\"},\"end\":50129,\"start\":49601}]", "paragraph": "[{\"end\":3231,\"start\":1932},{\"end\":3798,\"start\":3233},{\"end\":4161,\"start\":3800},{\"end\":4941,\"start\":4163},{\"end\":5498,\"start\":4943},{\"end\":6061,\"start\":5533},{\"end\":6371,\"start\":6063},{\"end\":7072,\"start\":6373},{\"end\":7169,\"start\":7074},{\"end\":7393,\"start\":7171},{\"end\":8551,\"start\":7395},{\"end\":8914,\"start\":8553},{\"end\":10545,\"start\":8916},{\"end\":11009,\"start\":10547},{\"end\":11966,\"start\":11011},{\"end\":12424,\"start\":11968},{\"end\":13760,\"start\":12426},{\"end\":14469,\"start\":13797},{\"end\":14746,\"start\":14471},{\"end\":15256,\"start\":14748},{\"end\":15676,\"start\":15258},{\"end\":16990,\"start\":15678},{\"end\":17670,\"start\":16992},{\"end\":18863,\"start\":17672},{\"end\":19127,\"start\":18865},{\"end\":19819,\"start\":19129},{\"end\":20290,\"start\":19821},{\"end\":21173,\"start\":20292},{\"end\":22045,\"start\":21175},{\"end\":22701,\"start\":22080},{\"end\":23458,\"start\":22703},{\"end\":24079,\"start\":23460},{\"end\":24717,\"start\":24081},{\"end\":24927,\"start\":24719},{\"end\":25509,\"start\":24929},{\"end\":26329,\"start\":25511},{\"end\":26884,\"start\":26331},{\"end\":27782,\"start\":26886},{\"end\":28157,\"start\":27784},{\"end\":28381,\"start\":28159},{\"end\":28625,\"start\":28383},{\"end\":28818,\"start\":28627},{\"end\":29115,\"start\":28820},{\"end\":29394,\"start\":29117},{\"end\":29641,\"start\":29424},{\"end\":30024,\"start\":29643},{\"end\":30466,\"start\":30026},{\"end\":31313,\"start\":30468},{\"end\":31930,\"start\":31315},{\"end\":32145,\"start\":31946},{\"end\":32681,\"start\":32147},{\"end\":33225,\"start\":32683},{\"end\":34151,\"start\":33319},{\"end\":34297,\"start\":34153},{\"end\":34346,\"start\":34299},{\"end\":34783,\"start\":34348},{\"end\":35035,\"start\":34785},{\"end\":35282,\"start\":35037},{\"end\":35405,\"start\":35284},{\"end\":35751,\"start\":35407},{\"end\":35925,\"start\":35753},{\"end\":36047,\"start\":35927},{\"end\":36187,\"start\":36049},{\"end\":36858,\"start\":36189},{\"end\":37987,\"start\":36860},{\"end\":38107,\"start\":38032},{\"end\":38330,\"start\":38166},{\"end\":38470,\"start\":38332},{\"end\":39826,\"start\":38472},{\"end\":40006,\"start\":39828},{\"end\":40995,\"start\":40008},{\"end\":41546,\"start\":40997},{\"end\":41677,\"start\":41548},{\"end\":43127,\"start\":41679},{\"end\":43873,\"start\":43129}]", "formula": null, "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":3580,\"start\":3573},{\"end\":8040,\"start\":8033},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":11101,\"start\":11094},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":12000,\"start\":11993},{\"end\":13160,\"start\":13153},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":17505,\"start\":17498},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":19148,\"start\":19141},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":20321,\"start\":20314},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":26950,\"start\":26943},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":27426,\"start\":27419},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":27644,\"start\":27637},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":28191,\"start\":28184},{\"attributes\":{\"ref_id\":\"tab_9\"},\"end\":38106,\"start\":38099},{\"attributes\":{\"ref_id\":\"tab_9\"},\"end\":38278,\"start\":38271},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":39839,\"start\":39831},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":41033,\"start\":41025},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":43415,\"start\":43398}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1930,\"start\":1918},{\"attributes\":{\"n\":\"2.1\"},\"end\":5531,\"start\":5501},{\"attributes\":{\"n\":\"2.2\"},\"end\":13795,\"start\":13763},{\"attributes\":{\"n\":\"2.3\"},\"end\":22078,\"start\":22048},{\"attributes\":{\"n\":\"3\"},\"end\":29422,\"start\":29397},{\"attributes\":{\"n\":\"4\"},\"end\":31944,\"start\":31933},{\"end\":33317,\"start\":33228},{\"end\":38030,\"start\":37990},{\"end\":38164,\"start\":38110},{\"end\":43885,\"start\":43875},{\"end\":44300,\"start\":44291},{\"end\":44701,\"start\":44692},{\"end\":45130,\"start\":45121},{\"end\":45529,\"start\":45520},{\"end\":45941,\"start\":45932},{\"end\":46559,\"start\":46550},{\"end\":47079,\"start\":47070},{\"end\":47352,\"start\":47343},{\"end\":48021,\"start\":48011},{\"end\":48713,\"start\":48703},{\"end\":49061,\"start\":49051},{\"end\":49612,\"start\":49602}]", "table": "[{\"end\":44690,\"start\":44443},{\"end\":45119,\"start\":44751},{\"end\":45518,\"start\":45249},{\"end\":45930,\"start\":45591},{\"end\":46548,\"start\":46138},{\"end\":47068,\"start\":46820},{\"end\":48009,\"start\":47589},{\"end\":48701,\"start\":48143},{\"end\":49049,\"start\":48782},{\"end\":49600,\"start\":49261},{\"end\":50129,\"start\":49874}]", "figure_caption": "[{\"end\":43915,\"start\":43887},{\"end\":44289,\"start\":43918},{\"end\":44443,\"start\":44302},{\"end\":44751,\"start\":44703},{\"end\":45249,\"start\":45132},{\"end\":45591,\"start\":45531},{\"end\":46138,\"start\":45943},{\"end\":46820,\"start\":46561},{\"end\":47341,\"start\":47081},{\"end\":47589,\"start\":47354},{\"end\":48143,\"start\":48024},{\"end\":48782,\"start\":48716},{\"end\":49261,\"start\":49064},{\"end\":49874,\"start\":49615}]", "figure_ref": "[{\"end\":3797,\"start\":3789},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":6260,\"start\":6252}]", "bib_author_first_name": "[{\"end\":52417,\"start\":52406},{\"end\":52428,\"start\":52427},{\"end\":52441,\"start\":52436},{\"end\":52460,\"start\":52453},{\"end\":52477,\"start\":52469},{\"end\":52490,\"start\":52484},{\"end\":52502,\"start\":52499},{\"end\":52526,\"start\":52520},{\"end\":52539,\"start\":52531},{\"end\":52566,\"start\":52558},{\"end\":53007,\"start\":53003},{\"end\":53024,\"start\":53019},{\"end\":53039,\"start\":53032},{\"end\":53053,\"start\":53050},{\"end\":53067,\"start\":53062},{\"end\":53450,\"start\":53443},{\"end\":53466,\"start\":53459},{\"end\":53483,\"start\":53476},{\"end\":53503,\"start\":53498},{\"end\":53518,\"start\":53512},{\"end\":53876,\"start\":53868},{\"end\":53894,\"start\":53890},{\"end\":53908,\"start\":53901},{\"end\":53921,\"start\":53916},{\"end\":53939,\"start\":53931},{\"end\":53954,\"start\":53948},{\"end\":53971,\"start\":53965},{\"end\":53991,\"start\":53985},{\"end\":54005,\"start\":53999},{\"end\":54335,\"start\":54334},{\"end\":54557,\"start\":54551},{\"end\":54569,\"start\":54563},{\"end\":54583,\"start\":54576},{\"end\":54596,\"start\":54589},{\"end\":54607,\"start\":54604},{\"end\":54960,\"start\":54954},{\"end\":54974,\"start\":54966},{\"end\":55305,\"start\":55300},{\"end\":55325,\"start\":55317},{\"end\":55340,\"start\":55331},{\"end\":55355,\"start\":55348},{\"end\":55372,\"start\":55364},{\"end\":55389,\"start\":55382},{\"end\":55404,\"start\":55399},{\"end\":55417,\"start\":55411},{\"end\":55438,\"start\":55433},{\"end\":55449,\"start\":55443},{\"end\":55458,\"start\":55454},{\"end\":55477,\"start\":55470},{\"end\":55493,\"start\":55486},{\"end\":55508,\"start\":55500},{\"end\":55519,\"start\":55515},{\"end\":55529,\"start\":55528},{\"end\":55538,\"start\":55530},{\"end\":55555,\"start\":55548},{\"end\":56094,\"start\":56091},{\"end\":56108,\"start\":56101},{\"end\":56116,\"start\":56113},{\"end\":56412,\"start\":56405},{\"end\":56429,\"start\":56421},{\"end\":56437,\"start\":56435},{\"end\":56446,\"start\":56442},{\"end\":56455,\"start\":56451},{\"end\":56471,\"start\":56464},{\"end\":56897,\"start\":56891},{\"end\":56912,\"start\":56907},{\"end\":56931,\"start\":56924},{\"end\":56949,\"start\":56943},{\"end\":57201,\"start\":57196},{\"end\":57218,\"start\":57210},{\"end\":57232,\"start\":57226},{\"end\":57246,\"start\":57238},{\"end\":57256,\"start\":57247},{\"end\":57657,\"start\":57651},{\"end\":57667,\"start\":57664},{\"end\":57679,\"start\":57672},{\"end\":57693,\"start\":57686},{\"end\":58088,\"start\":58080},{\"end\":58090,\"start\":58089},{\"end\":58108,\"start\":58101},{\"end\":58114,\"start\":58109},{\"end\":58131,\"start\":58123},{\"end\":58146,\"start\":58139},{\"end\":58148,\"start\":58147},{\"end\":58497,\"start\":58489},{\"end\":58506,\"start\":58503},{\"end\":58511,\"start\":58507},{\"end\":58796,\"start\":58790},{\"end\":58806,\"start\":58805},{\"end\":58828,\"start\":58827},{\"end\":58843,\"start\":58838},{\"end\":58857,\"start\":58851},{\"end\":58859,\"start\":58858},{\"end\":59163,\"start\":59162},{\"end\":59165,\"start\":59164},{\"end\":59177,\"start\":59176},{\"end\":59179,\"start\":59178},{\"end\":59394,\"start\":59388},{\"end\":59406,\"start\":59400},{\"end\":59420,\"start\":59415},{\"end\":59433,\"start\":59426},{\"end\":59443,\"start\":59439},{\"end\":59452,\"start\":59449},{\"end\":59464,\"start\":59460},{\"end\":59776,\"start\":59773},{\"end\":59801,\"start\":59797},{\"end\":60103,\"start\":60097},{\"end\":60132,\"start\":60131},{\"end\":60145,\"start\":60141},{\"end\":60165,\"start\":60160},{\"end\":60180,\"start\":60175},{\"end\":60195,\"start\":60191},{\"end\":60214,\"start\":60208},{\"end\":60232,\"start\":60223},{\"end\":60250,\"start\":60241},{\"end\":60252,\"start\":60251},{\"end\":60577,\"start\":60570},{\"end\":60589,\"start\":60582},{\"end\":60605,\"start\":60597},{\"end\":60615,\"start\":60611},{\"end\":60950,\"start\":60944},{\"end\":60963,\"start\":60955},{\"end\":60976,\"start\":60969},{\"end\":60991,\"start\":60985},{\"end\":61004,\"start\":60998},{\"end\":61015,\"start\":61010},{\"end\":61028,\"start\":61021},{\"end\":61042,\"start\":61038},{\"end\":61419,\"start\":61413},{\"end\":61429,\"start\":61424},{\"end\":61441,\"start\":61435},{\"end\":61456,\"start\":61449},{\"end\":61470,\"start\":61465},{\"end\":61483,\"start\":61478},{\"end\":61495,\"start\":61491},{\"end\":61864,\"start\":61858},{\"end\":61877,\"start\":61869},{\"end\":61895,\"start\":61887},{\"end\":61910,\"start\":61901},{\"end\":61925,\"start\":61918},{\"end\":61938,\"start\":61934},{\"end\":61953,\"start\":61949},{\"end\":61972,\"start\":61962},{\"end\":62337,\"start\":62333},{\"end\":62351,\"start\":62345},{\"end\":62361,\"start\":62356},{\"end\":62376,\"start\":62369},{\"end\":62390,\"start\":62382},{\"end\":62723,\"start\":62717},{\"end\":62740,\"start\":62731},{\"end\":63078,\"start\":63077},{\"end\":63090,\"start\":63087},{\"end\":63388,\"start\":63387},{\"end\":63634,\"start\":63626},{\"end\":63653,\"start\":63645},{\"end\":63668,\"start\":63660},{\"end\":63670,\"start\":63669},{\"end\":63687,\"start\":63680},{\"end\":63899,\"start\":63895},{\"end\":64072,\"start\":64068},{\"end\":64086,\"start\":64083},{\"end\":64387,\"start\":64379},{\"end\":64400,\"start\":64393},{\"end\":64413,\"start\":64408},{\"end\":64429,\"start\":64424},{\"end\":64442,\"start\":64436},{\"end\":64455,\"start\":64451},{\"end\":64470,\"start\":64465},{\"end\":64489,\"start\":64479},{\"end\":64727,\"start\":64721},{\"end\":64737,\"start\":64733},{\"end\":64748,\"start\":64743},{\"end\":64763,\"start\":64756},{\"end\":64774,\"start\":64768},{\"end\":64787,\"start\":64782},{\"end\":64798,\"start\":64794},{\"end\":64809,\"start\":64805},{\"end\":64821,\"start\":64817},{\"end\":64842,\"start\":64835},{\"end\":65229,\"start\":65223},{\"end\":65245,\"start\":65241},{\"end\":65266,\"start\":65259},{\"end\":65542,\"start\":65537},{\"end\":65553,\"start\":65548},{\"end\":65566,\"start\":65564},{\"end\":65577,\"start\":65572},{\"end\":65589,\"start\":65584},{\"end\":66054,\"start\":66053},{\"end\":66386,\"start\":66375},{\"end\":66396,\"start\":66395},{\"end\":66409,\"start\":66403},{\"end\":66426,\"start\":66418},{\"end\":66439,\"start\":66434},{\"end\":66456,\"start\":66450},{\"end\":67180,\"start\":67176},{\"end\":67195,\"start\":67189},{\"end\":67510,\"start\":67506},{\"end\":67522,\"start\":67519},{\"end\":67537,\"start\":67530},{\"end\":67555,\"start\":67548},{\"end\":67570,\"start\":67564},{\"end\":67584,\"start\":67577},{\"end\":67599,\"start\":67593},{\"end\":67610,\"start\":67605},{\"end\":67626,\"start\":67622},{\"end\":67639,\"start\":67635},{\"end\":67856,\"start\":67850},{\"end\":67870,\"start\":67863},{\"end\":67883,\"start\":67877},{\"end\":67899,\"start\":67891},{\"end\":67911,\"start\":67907},{\"end\":68206,\"start\":68202},{\"end\":68221,\"start\":68216},{\"end\":68387,\"start\":68379},{\"end\":68403,\"start\":68395},{\"end\":68415,\"start\":68412},{\"end\":68435,\"start\":68429},{\"end\":68451,\"start\":68444},{\"end\":68471,\"start\":68463},{\"end\":68804,\"start\":68800},{\"end\":68821,\"start\":68818},{\"end\":68831,\"start\":68828},{\"end\":68844,\"start\":68836},{\"end\":68860,\"start\":68853},{\"end\":68875,\"start\":68871},{\"end\":68887,\"start\":68880},{\"end\":68901,\"start\":68895},{\"end\":68918,\"start\":68912},{\"end\":68934,\"start\":68927},{\"end\":69325,\"start\":69319},{\"end\":69352,\"start\":69344},{\"end\":69367,\"start\":69361},{\"end\":69378,\"start\":69375},{\"end\":69389,\"start\":69385},{\"end\":69405,\"start\":69400},{\"end\":69407,\"start\":69406},{\"end\":69768,\"start\":69761},{\"end\":69785,\"start\":69784},{\"end\":69799,\"start\":69794},{\"end\":69812,\"start\":69806},{\"end\":69833,\"start\":69829},{\"end\":69843,\"start\":69840},{\"end\":70231,\"start\":70224},{\"end\":70250,\"start\":70240},{\"end\":70282,\"start\":70263},{\"end\":70296,\"start\":70290},{\"end\":70315,\"start\":70306},{\"end\":70340,\"start\":70328},{\"end\":70817,\"start\":70809},{\"end\":70831,\"start\":70823},{\"end\":70845,\"start\":70839},{\"end\":70855,\"start\":70852},{\"end\":70869,\"start\":70863},{\"end\":70878,\"start\":70876},{\"end\":71178,\"start\":71170},{\"end\":71192,\"start\":71184},{\"end\":71205,\"start\":71199},{\"end\":71219,\"start\":71213},{\"end\":71230,\"start\":71224},{\"end\":71500,\"start\":71496},{\"end\":71644,\"start\":71638},{\"end\":71653,\"start\":71651},{\"end\":71662,\"start\":71659},{\"end\":71676,\"start\":71668},{\"end\":71688,\"start\":71681},{\"end\":71966,\"start\":71960},{\"end\":71977,\"start\":71971},{\"end\":71987,\"start\":71984},{\"end\":72002,\"start\":71995},{\"end\":72015,\"start\":72009},{\"end\":72029,\"start\":72021},{\"end\":72045,\"start\":72037},{\"end\":72057,\"start\":72051},{\"end\":72068,\"start\":72064},{\"end\":72412,\"start\":72406},{\"end\":72422,\"start\":72418},{\"end\":72438,\"start\":72430},{\"end\":72453,\"start\":72449},{\"end\":72463,\"start\":72459},{\"end\":72473,\"start\":72472},{\"end\":72488,\"start\":72487},{\"end\":72509,\"start\":72508},{\"end\":72521,\"start\":72518},{\"end\":72536,\"start\":72529},{\"end\":72935,\"start\":72929},{\"end\":72947,\"start\":72941},{\"end\":72959,\"start\":72953},{\"end\":72966,\"start\":72965},{\"end\":72981,\"start\":72975},{\"end\":73337,\"start\":73330},{\"end\":73351,\"start\":73343},{\"end\":73366,\"start\":73358},{\"end\":73376,\"start\":73372},{\"end\":73655,\"start\":73647},{\"end\":73673,\"start\":73665},{\"end\":73690,\"start\":73682},{\"end\":73701,\"start\":73691},{\"end\":73712,\"start\":73708},{\"end\":73725,\"start\":73720},{\"end\":73744,\"start\":73738},{\"end\":74078,\"start\":74074},{\"end\":74098,\"start\":74090},{\"end\":74115,\"start\":74106},{\"end\":74128,\"start\":74124},{\"end\":74148,\"start\":74139},{\"end\":74474,\"start\":74469},{\"end\":74489,\"start\":74484},{\"end\":74502,\"start\":74498},{\"end\":74521,\"start\":74514},{\"end\":74711,\"start\":74705},{\"end\":74725,\"start\":74721},{\"end\":74739,\"start\":74735},{\"end\":74753,\"start\":74748},{\"end\":74770,\"start\":74765},{\"end\":74783,\"start\":74778},{\"end\":74785,\"start\":74784},{\"end\":74799,\"start\":74793},{\"end\":74813,\"start\":74808},{\"end\":75106,\"start\":75101},{\"end\":75126,\"start\":75119},{\"end\":75144,\"start\":75137},{\"end\":75162,\"start\":75155},{\"end\":75177,\"start\":75171},{\"end\":75189,\"start\":75183},{\"end\":75508,\"start\":75503},{\"end\":75526,\"start\":75520},{\"end\":75705,\"start\":75701},{\"end\":75721,\"start\":75712},{\"end\":75735,\"start\":75729},{\"end\":75750,\"start\":75745},{\"end\":75761,\"start\":75757},{\"end\":75776,\"start\":75768},{\"end\":76179,\"start\":76172},{\"end\":76193,\"start\":76186},{\"end\":76207,\"start\":76200},{\"end\":76224,\"start\":76215},{\"end\":76235,\"start\":76229},{\"end\":76248,\"start\":76242},{\"end\":76569,\"start\":76563},{\"end\":76583,\"start\":76576},{\"end\":76590,\"start\":76588},{\"end\":76602,\"start\":76598},{\"end\":76610,\"start\":76608},{\"end\":76621,\"start\":76616},{\"end\":76631,\"start\":76626},{\"end\":76643,\"start\":76636},{\"end\":76652,\"start\":76650},{\"end\":76664,\"start\":76660},{\"end\":76674,\"start\":76669},{\"end\":76688,\"start\":76682},{\"end\":76697,\"start\":76694},{\"end\":76711,\"start\":76705},{\"end\":76722,\"start\":76717},{\"end\":76736,\"start\":76729},{\"end\":76750,\"start\":76741},{\"end\":76752,\"start\":76751},{\"end\":76765,\"start\":76760},{\"end\":77343,\"start\":77338},{\"end\":77657,\"start\":77652},{\"end\":77668,\"start\":77662},{\"end\":77682,\"start\":77676},{\"end\":77714,\"start\":77703},{\"end\":77725,\"start\":77722},{\"end\":77738,\"start\":77730},{\"end\":78077,\"start\":78070},{\"end\":78089,\"start\":78082},{\"end\":78105,\"start\":78101},{\"end\":78107,\"start\":78106},{\"end\":78124,\"start\":78118},{\"end\":78137,\"start\":78132},{\"end\":78149,\"start\":78148},{\"end\":78162,\"start\":78158},{\"end\":78175,\"start\":78170},{\"end\":78480,\"start\":78474},{\"end\":78491,\"start\":78485},{\"end\":78500,\"start\":78496},{\"end\":78519,\"start\":78511},{\"end\":78800,\"start\":78796},{\"end\":78813,\"start\":78807},{\"end\":78828,\"start\":78820},{\"end\":78839,\"start\":78834},{\"end\":78851,\"start\":78846},{\"end\":79100,\"start\":79094},{\"end\":79108,\"start\":79107},{\"end\":79124,\"start\":79118},{\"end\":79400,\"start\":79391},{\"end\":79413,\"start\":79407},{\"end\":79427,\"start\":79419},{\"end\":79439,\"start\":79433},{\"end\":79453,\"start\":79447},{\"end\":79460,\"start\":79458},{\"end\":79472,\"start\":79465},{\"end\":79486,\"start\":79479},{\"end\":79877,\"start\":79868},{\"end\":79890,\"start\":79884},{\"end\":79903,\"start\":79897},{\"end\":79917,\"start\":79911},{\"end\":79930,\"start\":79922},{\"end\":79942,\"start\":79936},{\"end\":79956,\"start\":79948},{\"end\":79966,\"start\":79961},{\"end\":79980,\"start\":79973},{\"end\":79989,\"start\":79987},{\"end\":80347,\"start\":80344},{\"end\":80361,\"start\":80354},{\"end\":80373,\"start\":80366},{\"end\":80384,\"start\":80380},{\"end\":80400,\"start\":80399},{\"end\":80414,\"start\":80410},{\"end\":80829,\"start\":80822},{\"end\":80844,\"start\":80836},{\"end\":80858,\"start\":80851},{\"end\":80879,\"start\":80871},{\"end\":80894,\"start\":80888},{\"end\":81297,\"start\":81289},{\"end\":81311,\"start\":81305},{\"end\":81322,\"start\":81317},{\"end\":81336,\"start\":81328},{\"end\":81348,\"start\":81341},{\"end\":81361,\"start\":81355},{\"end\":81374,\"start\":81366},{\"end\":81388,\"start\":81382},{\"end\":81399,\"start\":81393},{\"end\":81698,\"start\":81696},{\"end\":81711,\"start\":81706},{\"end\":81722,\"start\":81718},{\"end\":81733,\"start\":81727},{\"end\":81744,\"start\":81739},{\"end\":81752,\"start\":81749},{\"end\":81762,\"start\":81759},{\"end\":81775,\"start\":81770},{\"end\":81789,\"start\":81783}]", "bib_author_last_name": "[{\"end\":52425,\"start\":52418},{\"end\":52434,\"start\":52429},{\"end\":52451,\"start\":52442},{\"end\":52467,\"start\":52461},{\"end\":52482,\"start\":52478},{\"end\":52497,\"start\":52491},{\"end\":52507,\"start\":52503},{\"end\":52518,\"start\":52509},{\"end\":52529,\"start\":52527},{\"end\":52556,\"start\":52540},{\"end\":52572,\"start\":52567},{\"end\":52581,\"start\":52574},{\"end\":53017,\"start\":53008},{\"end\":53030,\"start\":53025},{\"end\":53048,\"start\":53040},{\"end\":53060,\"start\":53054},{\"end\":53074,\"start\":53068},{\"end\":53457,\"start\":53451},{\"end\":53474,\"start\":53467},{\"end\":53496,\"start\":53484},{\"end\":53510,\"start\":53504},{\"end\":53528,\"start\":53519},{\"end\":53888,\"start\":53877},{\"end\":53899,\"start\":53895},{\"end\":53914,\"start\":53909},{\"end\":53929,\"start\":53922},{\"end\":53946,\"start\":53940},{\"end\":53963,\"start\":53955},{\"end\":53983,\"start\":53972},{\"end\":53997,\"start\":53992},{\"end\":54012,\"start\":54006},{\"end\":54020,\"start\":54014},{\"end\":54341,\"start\":54336},{\"end\":54561,\"start\":54558},{\"end\":54574,\"start\":54570},{\"end\":54587,\"start\":54584},{\"end\":54602,\"start\":54597},{\"end\":54612,\"start\":54608},{\"end\":54964,\"start\":54961},{\"end\":54978,\"start\":54975},{\"end\":55315,\"start\":55306},{\"end\":55329,\"start\":55326},{\"end\":55346,\"start\":55341},{\"end\":55362,\"start\":55356},{\"end\":55380,\"start\":55373},{\"end\":55397,\"start\":55390},{\"end\":55409,\"start\":55405},{\"end\":55431,\"start\":55418},{\"end\":55441,\"start\":55439},{\"end\":55452,\"start\":55450},{\"end\":55468,\"start\":55459},{\"end\":55484,\"start\":55478},{\"end\":55498,\"start\":55494},{\"end\":55513,\"start\":55509},{\"end\":55526,\"start\":55520},{\"end\":55546,\"start\":55539},{\"end\":55562,\"start\":55556},{\"end\":56099,\"start\":56095},{\"end\":56111,\"start\":56109},{\"end\":56121,\"start\":56117},{\"end\":56419,\"start\":56413},{\"end\":56433,\"start\":56430},{\"end\":56440,\"start\":56438},{\"end\":56449,\"start\":56447},{\"end\":56462,\"start\":56456},{\"end\":56477,\"start\":56472},{\"end\":56905,\"start\":56898},{\"end\":56922,\"start\":56913},{\"end\":56941,\"start\":56932},{\"end\":56961,\"start\":56950},{\"end\":57208,\"start\":57202},{\"end\":57224,\"start\":57219},{\"end\":57236,\"start\":57233},{\"end\":57261,\"start\":57257},{\"end\":57662,\"start\":57658},{\"end\":57670,\"start\":57668},{\"end\":57684,\"start\":57680},{\"end\":57698,\"start\":57694},{\"end\":58099,\"start\":58091},{\"end\":58121,\"start\":58115},{\"end\":58137,\"start\":58132},{\"end\":58160,\"start\":58149},{\"end\":58501,\"start\":58498},{\"end\":58519,\"start\":58512},{\"end\":58803,\"start\":58797},{\"end\":58813,\"start\":58807},{\"end\":58825,\"start\":58815},{\"end\":58836,\"start\":58829},{\"end\":58849,\"start\":58844},{\"end\":58867,\"start\":58860},{\"end\":58873,\"start\":58869},{\"end\":59174,\"start\":59166},{\"end\":59185,\"start\":59180},{\"end\":59398,\"start\":59395},{\"end\":59413,\"start\":59407},{\"end\":59424,\"start\":59421},{\"end\":59437,\"start\":59434},{\"end\":59447,\"start\":59444},{\"end\":59458,\"start\":59453},{\"end\":59467,\"start\":59465},{\"end\":59795,\"start\":59777},{\"end\":59806,\"start\":59802},{\"end\":59816,\"start\":59808},{\"end\":60120,\"start\":60104},{\"end\":60129,\"start\":60122},{\"end\":60139,\"start\":60133},{\"end\":60158,\"start\":60146},{\"end\":60173,\"start\":60166},{\"end\":60189,\"start\":60181},{\"end\":60206,\"start\":60196},{\"end\":60221,\"start\":60215},{\"end\":60239,\"start\":60233},{\"end\":60257,\"start\":60253},{\"end\":60264,\"start\":60259},{\"end\":60580,\"start\":60578},{\"end\":60595,\"start\":60590},{\"end\":60609,\"start\":60606},{\"end\":60619,\"start\":60616},{\"end\":60953,\"start\":60951},{\"end\":60967,\"start\":60964},{\"end\":60983,\"start\":60977},{\"end\":60996,\"start\":60992},{\"end\":61008,\"start\":61005},{\"end\":61019,\"start\":61016},{\"end\":61036,\"start\":61029},{\"end\":61051,\"start\":61043},{\"end\":61422,\"start\":61420},{\"end\":61433,\"start\":61430},{\"end\":61447,\"start\":61442},{\"end\":61463,\"start\":61457},{\"end\":61476,\"start\":61471},{\"end\":61489,\"start\":61484},{\"end\":61504,\"start\":61496},{\"end\":61867,\"start\":61865},{\"end\":61885,\"start\":61878},{\"end\":61899,\"start\":61896},{\"end\":61916,\"start\":61911},{\"end\":61932,\"start\":61926},{\"end\":61947,\"start\":61939},{\"end\":61960,\"start\":61954},{\"end\":61980,\"start\":61973},{\"end\":62343,\"start\":62338},{\"end\":62354,\"start\":62352},{\"end\":62367,\"start\":62362},{\"end\":62380,\"start\":62377},{\"end\":62397,\"start\":62391},{\"end\":62729,\"start\":62724},{\"end\":62748,\"start\":62741},{\"end\":63085,\"start\":63079},{\"end\":63095,\"start\":63091},{\"end\":63104,\"start\":63097},{\"end\":63392,\"start\":63389},{\"end\":63403,\"start\":63394},{\"end\":63643,\"start\":63635},{\"end\":63658,\"start\":63654},{\"end\":63678,\"start\":63671},{\"end\":63697,\"start\":63688},{\"end\":63907,\"start\":63900},{\"end\":64081,\"start\":64073},{\"end\":64092,\"start\":64087},{\"end\":64391,\"start\":64388},{\"end\":64406,\"start\":64401},{\"end\":64422,\"start\":64414},{\"end\":64434,\"start\":64430},{\"end\":64449,\"start\":64443},{\"end\":64463,\"start\":64456},{\"end\":64477,\"start\":64471},{\"end\":64497,\"start\":64490},{\"end\":64731,\"start\":64728},{\"end\":64741,\"start\":64738},{\"end\":64754,\"start\":64749},{\"end\":64766,\"start\":64764},{\"end\":64780,\"start\":64775},{\"end\":64792,\"start\":64788},{\"end\":64803,\"start\":64799},{\"end\":64815,\"start\":64810},{\"end\":64833,\"start\":64822},{\"end\":64851,\"start\":64843},{\"end\":64860,\"start\":64853},{\"end\":65239,\"start\":65230},{\"end\":65257,\"start\":65246},{\"end\":65271,\"start\":65267},{\"end\":65546,\"start\":65543},{\"end\":65562,\"start\":65554},{\"end\":65570,\"start\":65567},{\"end\":65582,\"start\":65578},{\"end\":65596,\"start\":65590},{\"end\":66060,\"start\":66055},{\"end\":66068,\"start\":66062},{\"end\":66393,\"start\":66387},{\"end\":66401,\"start\":66397},{\"end\":66416,\"start\":66410},{\"end\":66432,\"start\":66427},{\"end\":66448,\"start\":66440},{\"end\":66463,\"start\":66457},{\"end\":66472,\"start\":66465},{\"end\":67187,\"start\":67181},{\"end\":67205,\"start\":67196},{\"end\":67517,\"start\":67511},{\"end\":67528,\"start\":67523},{\"end\":67546,\"start\":67538},{\"end\":67562,\"start\":67556},{\"end\":67575,\"start\":67571},{\"end\":67591,\"start\":67585},{\"end\":67603,\"start\":67600},{\"end\":67620,\"start\":67611},{\"end\":67633,\"start\":67627},{\"end\":67645,\"start\":67640},{\"end\":67861,\"start\":67857},{\"end\":67875,\"start\":67871},{\"end\":67889,\"start\":67884},{\"end\":67905,\"start\":67900},{\"end\":67915,\"start\":67912},{\"end\":68214,\"start\":68207},{\"end\":68230,\"start\":68222},{\"end\":68393,\"start\":68388},{\"end\":68410,\"start\":68404},{\"end\":68427,\"start\":68416},{\"end\":68442,\"start\":68436},{\"end\":68461,\"start\":68452},{\"end\":68477,\"start\":68472},{\"end\":68816,\"start\":68805},{\"end\":68826,\"start\":68822},{\"end\":68834,\"start\":68832},{\"end\":68851,\"start\":68845},{\"end\":68869,\"start\":68861},{\"end\":68878,\"start\":68876},{\"end\":68893,\"start\":68888},{\"end\":68910,\"start\":68902},{\"end\":68925,\"start\":68919},{\"end\":68944,\"start\":68935},{\"end\":69342,\"start\":69326},{\"end\":69359,\"start\":69353},{\"end\":69373,\"start\":69368},{\"end\":69383,\"start\":69379},{\"end\":69398,\"start\":69390},{\"end\":69417,\"start\":69408},{\"end\":69782,\"start\":69769},{\"end\":69792,\"start\":69786},{\"end\":69804,\"start\":69800},{\"end\":69818,\"start\":69813},{\"end\":69827,\"start\":69820},{\"end\":69838,\"start\":69834},{\"end\":69849,\"start\":69844},{\"end\":69858,\"start\":69851},{\"end\":70238,\"start\":70232},{\"end\":70261,\"start\":70251},{\"end\":70288,\"start\":70283},{\"end\":70304,\"start\":70297},{\"end\":70326,\"start\":70316},{\"end\":70347,\"start\":70341},{\"end\":70821,\"start\":70818},{\"end\":70837,\"start\":70832},{\"end\":70850,\"start\":70846},{\"end\":70861,\"start\":70856},{\"end\":70874,\"start\":70870},{\"end\":70882,\"start\":70879},{\"end\":71182,\"start\":71179},{\"end\":71197,\"start\":71193},{\"end\":71211,\"start\":71206},{\"end\":71222,\"start\":71220},{\"end\":71233,\"start\":71231},{\"end\":71239,\"start\":71235},{\"end\":71508,\"start\":71501},{\"end\":71649,\"start\":71645},{\"end\":71657,\"start\":71654},{\"end\":71666,\"start\":71663},{\"end\":71679,\"start\":71677},{\"end\":71692,\"start\":71689},{\"end\":71969,\"start\":71967},{\"end\":71982,\"start\":71978},{\"end\":71993,\"start\":71988},{\"end\":72007,\"start\":72003},{\"end\":72019,\"start\":72016},{\"end\":72035,\"start\":72030},{\"end\":72049,\"start\":72046},{\"end\":72062,\"start\":72058},{\"end\":72073,\"start\":72069},{\"end\":72416,\"start\":72413},{\"end\":72428,\"start\":72423},{\"end\":72447,\"start\":72439},{\"end\":72457,\"start\":72454},{\"end\":72470,\"start\":72464},{\"end\":72478,\"start\":72474},{\"end\":72485,\"start\":72480},{\"end\":72496,\"start\":72489},{\"end\":72506,\"start\":72498},{\"end\":72516,\"start\":72510},{\"end\":72527,\"start\":72522},{\"end\":72541,\"start\":72537},{\"end\":72546,\"start\":72543},{\"end\":72939,\"start\":72936},{\"end\":72951,\"start\":72948},{\"end\":72963,\"start\":72960},{\"end\":72973,\"start\":72967},{\"end\":72984,\"start\":72982},{\"end\":72988,\"start\":72986},{\"end\":73341,\"start\":73338},{\"end\":73356,\"start\":73352},{\"end\":73370,\"start\":73367},{\"end\":73381,\"start\":73377},{\"end\":73663,\"start\":73656},{\"end\":73680,\"start\":73674},{\"end\":73706,\"start\":73702},{\"end\":73718,\"start\":73713},{\"end\":73736,\"start\":73726},{\"end\":73750,\"start\":73745},{\"end\":74088,\"start\":74079},{\"end\":74104,\"start\":74099},{\"end\":74122,\"start\":74116},{\"end\":74137,\"start\":74129},{\"end\":74157,\"start\":74149},{\"end\":74482,\"start\":74475},{\"end\":74496,\"start\":74490},{\"end\":74512,\"start\":74503},{\"end\":74528,\"start\":74522},{\"end\":74719,\"start\":74712},{\"end\":74733,\"start\":74726},{\"end\":74746,\"start\":74740},{\"end\":74763,\"start\":74754},{\"end\":74776,\"start\":74771},{\"end\":74791,\"start\":74786},{\"end\":74806,\"start\":74800},{\"end\":74824,\"start\":74814},{\"end\":75117,\"start\":75107},{\"end\":75135,\"start\":75127},{\"end\":75153,\"start\":75145},{\"end\":75169,\"start\":75163},{\"end\":75181,\"start\":75178},{\"end\":75196,\"start\":75190},{\"end\":75518,\"start\":75509},{\"end\":75535,\"start\":75527},{\"end\":75710,\"start\":75706},{\"end\":75727,\"start\":75722},{\"end\":75743,\"start\":75736},{\"end\":75755,\"start\":75751},{\"end\":75766,\"start\":75762},{\"end\":75783,\"start\":75777},{\"end\":76184,\"start\":76180},{\"end\":76198,\"start\":76194},{\"end\":76213,\"start\":76208},{\"end\":76227,\"start\":76225},{\"end\":76240,\"start\":76236},{\"end\":76256,\"start\":76249},{\"end\":76574,\"start\":76570},{\"end\":76586,\"start\":76584},{\"end\":76596,\"start\":76591},{\"end\":76606,\"start\":76603},{\"end\":76614,\"start\":76611},{\"end\":76624,\"start\":76622},{\"end\":76634,\"start\":76632},{\"end\":76648,\"start\":76644},{\"end\":76658,\"start\":76653},{\"end\":76667,\"start\":76665},{\"end\":76680,\"start\":76675},{\"end\":76692,\"start\":76689},{\"end\":76703,\"start\":76698},{\"end\":76715,\"start\":76712},{\"end\":76727,\"start\":76723},{\"end\":76739,\"start\":76737},{\"end\":76758,\"start\":76753},{\"end\":76771,\"start\":76766},{\"end\":77353,\"start\":77344},{\"end\":77660,\"start\":77658},{\"end\":77674,\"start\":77669},{\"end\":77699,\"start\":77683},{\"end\":77720,\"start\":77715},{\"end\":77728,\"start\":77726},{\"end\":77749,\"start\":77739},{\"end\":78080,\"start\":78078},{\"end\":78099,\"start\":78090},{\"end\":78116,\"start\":78108},{\"end\":78130,\"start\":78125},{\"end\":78146,\"start\":78138},{\"end\":78156,\"start\":78150},{\"end\":78168,\"start\":78163},{\"end\":78183,\"start\":78176},{\"end\":78190,\"start\":78185},{\"end\":78483,\"start\":78481},{\"end\":78494,\"start\":78492},{\"end\":78509,\"start\":78501},{\"end\":78527,\"start\":78520},{\"end\":78805,\"start\":78801},{\"end\":78818,\"start\":78814},{\"end\":78832,\"start\":78829},{\"end\":78844,\"start\":78840},{\"end\":78854,\"start\":78852},{\"end\":79105,\"start\":79101},{\"end\":79116,\"start\":79109},{\"end\":79130,\"start\":79125},{\"end\":79145,\"start\":79132},{\"end\":79405,\"start\":79401},{\"end\":79417,\"start\":79414},{\"end\":79431,\"start\":79428},{\"end\":79445,\"start\":79440},{\"end\":79456,\"start\":79454},{\"end\":79463,\"start\":79461},{\"end\":79477,\"start\":79473},{\"end\":79490,\"start\":79487},{\"end\":79882,\"start\":79878},{\"end\":79895,\"start\":79891},{\"end\":79909,\"start\":79904},{\"end\":79920,\"start\":79918},{\"end\":79934,\"start\":79931},{\"end\":79946,\"start\":79943},{\"end\":79959,\"start\":79957},{\"end\":79971,\"start\":79967},{\"end\":79985,\"start\":79981},{\"end\":79992,\"start\":79990},{\"end\":80352,\"start\":80348},{\"end\":80364,\"start\":80362},{\"end\":80378,\"start\":80374},{\"end\":80397,\"start\":80385},{\"end\":80408,\"start\":80401},{\"end\":80423,\"start\":80415},{\"end\":80433,\"start\":80425},{\"end\":80834,\"start\":80830},{\"end\":80849,\"start\":80845},{\"end\":80869,\"start\":80859},{\"end\":80886,\"start\":80880},{\"end\":80903,\"start\":80895},{\"end\":81303,\"start\":81298},{\"end\":81315,\"start\":81312},{\"end\":81326,\"start\":81323},{\"end\":81339,\"start\":81337},{\"end\":81353,\"start\":81349},{\"end\":81364,\"start\":81362},{\"end\":81380,\"start\":81375},{\"end\":81391,\"start\":81389},{\"end\":81404,\"start\":81400},{\"end\":81704,\"start\":81699},{\"end\":81716,\"start\":81712},{\"end\":81725,\"start\":81723},{\"end\":81737,\"start\":81734},{\"end\":81747,\"start\":81745},{\"end\":81757,\"start\":81753},{\"end\":81768,\"start\":81763},{\"end\":81781,\"start\":81776},{\"end\":81797,\"start\":81790},{\"end\":83931,\"start\":83920}]", "bib_entry": "[{\"attributes\":{\"doi\":\"arXiv:2107.09422\",\"id\":\"b0\"},\"end\":52917,\"start\":52322},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":207167677},\"end\":53382,\"start\":52919},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":14941970},\"end\":53827,\"start\":53384},{\"attributes\":{\"doi\":\"arXiv:2005.14165\",\"id\":\"b3\"},\"end\":54290,\"start\":53829},{\"attributes\":{\"doi\":\"http:/link.aip.org/link/doi/10.1063/1.4704546\",\"id\":\"b4\",\"matched_paper_id\":1125529},\"end\":54549,\"start\":54292},{\"attributes\":{\"id\":\"b5\"},\"end\":54870,\"start\":54551},{\"attributes\":{\"doi\":\"10.1039/C4EE00260A\",\"id\":\"b6\",\"matched_paper_id\":98730322},\"end\":55238,\"start\":54872},{\"attributes\":{\"doi\":\"10.1021/acscatal.0c04525\",\"id\":\"b7\",\"matched_paper_id\":224803470},\"end\":56007,\"start\":55240},{\"attributes\":{\"doi\":\"arXiv:1801.10247\",\"id\":\"b8\"},\"end\":56309,\"start\":56009},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":159042192},\"end\":56810,\"start\":56311},{\"attributes\":{\"id\":\"b10\"},\"end\":57194,\"start\":56812},{\"attributes\":{\"doi\":\"arXiv:1810.04805\",\"id\":\"b11\"},\"end\":57555,\"start\":57196},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":15168964},\"end\":58016,\"start\":57557},{\"attributes\":{\"doi\":\"10.3390/molecules200713384\",\"id\":\"b13\",\"matched_paper_id\":14827454},\"end\":58487,\"start\":58018},{\"attributes\":{\"doi\":\"arXiv:1903.02428\",\"id\":\"b14\"},\"end\":58742,\"start\":58489},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":9665943},\"end\":59139,\"start\":58744},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":28443697},\"end\":59331,\"start\":59141},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":211677665},\"end\":59720,\"start\":59333},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":4755450},\"end\":60065,\"start\":59722},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":219792763},\"end\":60522,\"start\":60067},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":206594692},\"end\":60879,\"start\":60524},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":218487328},\"end\":61360,\"start\":60881},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":213085920},\"end\":61785,\"start\":61362},{\"attributes\":{\"doi\":\"arXiv:2103.01436\",\"id\":\"b23\"},\"end\":62249,\"start\":61787},{\"attributes\":{\"doi\":\"arXiv:2010.13993\",\"id\":\"b24\"},\"end\":62621,\"start\":62251},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":5808102},\"end\":63009,\"start\":62623},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":3144218},\"end\":63333,\"start\":63011},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":216000619},\"end\":63538,\"start\":63335},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":227228130},\"end\":63893,\"start\":63540},{\"attributes\":{\"id\":\"b29\"},\"end\":63999,\"start\":63895},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":2601163},\"end\":64334,\"start\":64001},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":14113767},\"end\":64719,\"start\":64336},{\"attributes\":{\"doi\":\"arXiv:1907.11692\",\"id\":\"b32\"},\"end\":65171,\"start\":64721},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":2341021},\"end\":65456,\"start\":65173},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":6018348},\"end\":65927,\"start\":65458},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":62164893},\"end\":66301,\"start\":65929},{\"attributes\":{\"doi\":\"arXiv:2007.08663\",\"id\":\"b36\"},\"end\":66716,\"start\":66303},{\"attributes\":{\"doi\":\"10.1063/1.4938866\",\"id\":\"b37\"},\"end\":67067,\"start\":66718},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":3551015},\"end\":67466,\"start\":67069},{\"attributes\":{\"id\":\"b39\"},\"end\":67846,\"start\":67468},{\"attributes\":{\"doi\":\"of wikikg90m-lsc. 2021\",\"id\":\"b40\"},\"end\":68136,\"start\":67848},{\"attributes\":{\"id\":\"b41\"},\"end\":68377,\"start\":68138},{\"attributes\":{\"doi\":\"arXiv:2004.11198\",\"id\":\"b42\"},\"end\":68747,\"start\":68379},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":2930547},\"end\":69259,\"start\":68749},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":211252550},\"end\":69699,\"start\":69261},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":5458500},\"end\":70130,\"start\":69701},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":4106658},\"end\":70716,\"start\":70132},{\"attributes\":{\"doi\":\"arXiv:2009.03509\",\"id\":\"b47\"},\"end\":71122,\"start\":70718},{\"attributes\":{\"id\":\"b48\"},\"end\":71440,\"start\":71124},{\"attributes\":{\"id\":\"b49\"},\"end\":71636,\"start\":71442},{\"attributes\":{\"doi\":\"arXiv:2004.09297\",\"id\":\"b50\"},\"end\":71958,\"start\":71638},{\"attributes\":{\"doi\":\"arXiv:2107.01892\",\"id\":\"b51\"},\"end\":72354,\"start\":71960},{\"attributes\":{\"id\":\"b52\",\"matched_paper_id\":211572993},\"end\":72839,\"start\":72356},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":10082102},\"end\":73253,\"start\":72841},{\"attributes\":{\"id\":\"b54\",\"matched_paper_id\":67855617},\"end\":73645,\"start\":73255},{\"attributes\":{\"doi\":\"arXiv:2102.06514\",\"id\":\"b55\"},\"end\":74025,\"start\":73647},{\"attributes\":{\"id\":\"b56\",\"matched_paper_id\":15150247},\"end\":74425,\"start\":74027},{\"attributes\":{\"doi\":\"arXiv:1111.4503\",\"id\":\"b57\"},\"end\":74703,\"start\":74427},{\"attributes\":{\"doi\":\"arXiv:1706.03762\",\"id\":\"b58\"},\"end\":75073,\"start\":74705},{\"attributes\":{\"id\":\"b59\",\"matched_paper_id\":3292002},\"end\":75455,\"start\":75075},{\"attributes\":{\"id\":\"b60\",\"matched_paper_id\":14494942},\"end\":75699,\"start\":75457},{\"attributes\":{\"doi\":\"arXiv:1804.07461\",\"id\":\"b61\"},\"end\":76115,\"start\":75701},{\"attributes\":{\"id\":\"b62\",\"matched_paper_id\":210872675},\"end\":76485,\"start\":76117},{\"attributes\":{\"id\":\"b63\",\"matched_paper_id\":202539732},\"end\":77233,\"start\":76487},{\"attributes\":{\"id\":\"b64\",\"matched_paper_id\":5445756},\"end\":77608,\"start\":77235},{\"attributes\":{\"id\":\"b65\",\"matched_paper_id\":67752026},\"end\":78011,\"start\":77610},{\"attributes\":{\"id\":\"b66\",\"matched_paper_id\":217680306},\"end\":78431,\"start\":78013},{\"attributes\":{\"id\":\"b67\",\"matched_paper_id\":52895589},\"end\":78758,\"start\":78433},{\"attributes\":{\"id\":\"b68\"},\"end\":79033,\"start\":78760},{\"attributes\":{\"id\":\"b69\",\"matched_paper_id\":7008752},\"end\":79389,\"start\":79035},{\"attributes\":{\"doi\":\"arXiv:2106.05234\",\"id\":\"b70\"},\"end\":79788,\"start\":79391},{\"attributes\":{\"doi\":\"arXiv:2106.08279\",\"id\":\"b71\"},\"end\":80271,\"start\":79790},{\"attributes\":{\"id\":\"b72\",\"matched_paper_id\":46949657},\"end\":80759,\"start\":80273},{\"attributes\":{\"id\":\"b73\",\"matched_paper_id\":195886159},\"end\":81188,\"start\":80761},{\"attributes\":{\"doi\":\"arXiv:2106.14494\",\"id\":\"b74\"},\"end\":81694,\"start\":81190},{\"attributes\":{\"doi\":\"arXiv:2004.08532\",\"id\":\"b75\"},\"end\":82082,\"start\":81696},{\"attributes\":{\"id\":\"b76\"},\"end\":82145,\"start\":82084},{\"attributes\":{\"id\":\"b77\"},\"end\":82386,\"start\":82147},{\"attributes\":{\"id\":\"b78\"},\"end\":82712,\"start\":82388},{\"attributes\":{\"id\":\"b79\"},\"end\":82897,\"start\":82714},{\"attributes\":{\"id\":\"b80\"},\"end\":83191,\"start\":82899},{\"attributes\":{\"id\":\"b81\"},\"end\":83540,\"start\":83193},{\"attributes\":{\"id\":\"b82\"},\"end\":83873,\"start\":83542},{\"attributes\":{\"id\":\"b83\"},\"end\":84392,\"start\":83875},{\"attributes\":{\"id\":\"b84\"},\"end\":84582,\"start\":84394},{\"attributes\":{\"id\":\"b85\"},\"end\":84787,\"start\":84584}]", "bib_title": "[{\"end\":53001,\"start\":52919},{\"end\":53441,\"start\":53384},{\"end\":54332,\"start\":54292},{\"end\":54952,\"start\":54872},{\"end\":55298,\"start\":55240},{\"end\":56403,\"start\":56311},{\"end\":57649,\"start\":57557},{\"end\":58078,\"start\":58018},{\"end\":58788,\"start\":58744},{\"end\":59160,\"start\":59141},{\"end\":59386,\"start\":59333},{\"end\":59771,\"start\":59722},{\"end\":60095,\"start\":60067},{\"end\":60568,\"start\":60524},{\"end\":60942,\"start\":60881},{\"end\":61411,\"start\":61362},{\"end\":62715,\"start\":62623},{\"end\":63075,\"start\":63011},{\"end\":63385,\"start\":63335},{\"end\":63624,\"start\":63540},{\"end\":64066,\"start\":64001},{\"end\":64377,\"start\":64336},{\"end\":65221,\"start\":65173},{\"end\":65535,\"start\":65458},{\"end\":66051,\"start\":65929},{\"end\":67174,\"start\":67069},{\"end\":68798,\"start\":68749},{\"end\":69317,\"start\":69261},{\"end\":69759,\"start\":69701},{\"end\":70222,\"start\":70132},{\"end\":71494,\"start\":71442},{\"end\":72404,\"start\":72356},{\"end\":72927,\"start\":72841},{\"end\":73328,\"start\":73255},{\"end\":74072,\"start\":74027},{\"end\":75099,\"start\":75075},{\"end\":75501,\"start\":75457},{\"end\":76170,\"start\":76117},{\"end\":76561,\"start\":76487},{\"end\":77336,\"start\":77235},{\"end\":77650,\"start\":77610},{\"end\":78068,\"start\":78013},{\"end\":78472,\"start\":78433},{\"end\":79092,\"start\":79035},{\"end\":80342,\"start\":80273},{\"end\":80820,\"start\":80761},{\"end\":83918,\"start\":83875}]", "bib_author": "[{\"end\":52427,\"start\":52406},{\"end\":52436,\"start\":52427},{\"end\":52453,\"start\":52436},{\"end\":52469,\"start\":52453},{\"end\":52484,\"start\":52469},{\"end\":52499,\"start\":52484},{\"end\":52509,\"start\":52499},{\"end\":52520,\"start\":52509},{\"end\":52531,\"start\":52520},{\"end\":52558,\"start\":52531},{\"end\":52574,\"start\":52558},{\"end\":52583,\"start\":52574},{\"end\":53019,\"start\":53003},{\"end\":53032,\"start\":53019},{\"end\":53050,\"start\":53032},{\"end\":53062,\"start\":53050},{\"end\":53076,\"start\":53062},{\"end\":53459,\"start\":53443},{\"end\":53476,\"start\":53459},{\"end\":53498,\"start\":53476},{\"end\":53512,\"start\":53498},{\"end\":53530,\"start\":53512},{\"end\":53890,\"start\":53868},{\"end\":53901,\"start\":53890},{\"end\":53916,\"start\":53901},{\"end\":53931,\"start\":53916},{\"end\":53948,\"start\":53931},{\"end\":53965,\"start\":53948},{\"end\":53985,\"start\":53965},{\"end\":53999,\"start\":53985},{\"end\":54014,\"start\":53999},{\"end\":54022,\"start\":54014},{\"end\":54343,\"start\":54334},{\"end\":54563,\"start\":54551},{\"end\":54576,\"start\":54563},{\"end\":54589,\"start\":54576},{\"end\":54604,\"start\":54589},{\"end\":54614,\"start\":54604},{\"end\":54966,\"start\":54954},{\"end\":54980,\"start\":54966},{\"end\":55317,\"start\":55300},{\"end\":55331,\"start\":55317},{\"end\":55348,\"start\":55331},{\"end\":55364,\"start\":55348},{\"end\":55382,\"start\":55364},{\"end\":55399,\"start\":55382},{\"end\":55411,\"start\":55399},{\"end\":55433,\"start\":55411},{\"end\":55443,\"start\":55433},{\"end\":55454,\"start\":55443},{\"end\":55470,\"start\":55454},{\"end\":55486,\"start\":55470},{\"end\":55500,\"start\":55486},{\"end\":55515,\"start\":55500},{\"end\":55528,\"start\":55515},{\"end\":55548,\"start\":55528},{\"end\":55564,\"start\":55548},{\"end\":56101,\"start\":56091},{\"end\":56113,\"start\":56101},{\"end\":56123,\"start\":56113},{\"end\":56421,\"start\":56405},{\"end\":56435,\"start\":56421},{\"end\":56442,\"start\":56435},{\"end\":56451,\"start\":56442},{\"end\":56464,\"start\":56451},{\"end\":56479,\"start\":56464},{\"end\":56907,\"start\":56891},{\"end\":56924,\"start\":56907},{\"end\":56943,\"start\":56924},{\"end\":56963,\"start\":56943},{\"end\":57210,\"start\":57196},{\"end\":57226,\"start\":57210},{\"end\":57238,\"start\":57226},{\"end\":57263,\"start\":57238},{\"end\":57664,\"start\":57651},{\"end\":57672,\"start\":57664},{\"end\":57686,\"start\":57672},{\"end\":57700,\"start\":57686},{\"end\":58101,\"start\":58080},{\"end\":58123,\"start\":58101},{\"end\":58139,\"start\":58123},{\"end\":58162,\"start\":58139},{\"end\":58503,\"start\":58489},{\"end\":58521,\"start\":58503},{\"end\":58805,\"start\":58790},{\"end\":58815,\"start\":58805},{\"end\":58827,\"start\":58815},{\"end\":58838,\"start\":58827},{\"end\":58851,\"start\":58838},{\"end\":58869,\"start\":58851},{\"end\":58875,\"start\":58869},{\"end\":59176,\"start\":59162},{\"end\":59187,\"start\":59176},{\"end\":59400,\"start\":59388},{\"end\":59415,\"start\":59400},{\"end\":59426,\"start\":59415},{\"end\":59439,\"start\":59426},{\"end\":59449,\"start\":59439},{\"end\":59460,\"start\":59449},{\"end\":59469,\"start\":59460},{\"end\":59797,\"start\":59773},{\"end\":59808,\"start\":59797},{\"end\":59818,\"start\":59808},{\"end\":60122,\"start\":60097},{\"end\":60131,\"start\":60122},{\"end\":60141,\"start\":60131},{\"end\":60160,\"start\":60141},{\"end\":60175,\"start\":60160},{\"end\":60191,\"start\":60175},{\"end\":60208,\"start\":60191},{\"end\":60223,\"start\":60208},{\"end\":60241,\"start\":60223},{\"end\":60259,\"start\":60241},{\"end\":60266,\"start\":60259},{\"end\":60582,\"start\":60570},{\"end\":60597,\"start\":60582},{\"end\":60611,\"start\":60597},{\"end\":60621,\"start\":60611},{\"end\":60955,\"start\":60944},{\"end\":60969,\"start\":60955},{\"end\":60985,\"start\":60969},{\"end\":60998,\"start\":60985},{\"end\":61010,\"start\":60998},{\"end\":61021,\"start\":61010},{\"end\":61038,\"start\":61021},{\"end\":61053,\"start\":61038},{\"end\":61424,\"start\":61413},{\"end\":61435,\"start\":61424},{\"end\":61449,\"start\":61435},{\"end\":61465,\"start\":61449},{\"end\":61478,\"start\":61465},{\"end\":61491,\"start\":61478},{\"end\":61506,\"start\":61491},{\"end\":61869,\"start\":61858},{\"end\":61887,\"start\":61869},{\"end\":61901,\"start\":61887},{\"end\":61918,\"start\":61901},{\"end\":61934,\"start\":61918},{\"end\":61949,\"start\":61934},{\"end\":61962,\"start\":61949},{\"end\":61982,\"start\":61962},{\"end\":62345,\"start\":62333},{\"end\":62356,\"start\":62345},{\"end\":62369,\"start\":62356},{\"end\":62382,\"start\":62369},{\"end\":62399,\"start\":62382},{\"end\":62731,\"start\":62717},{\"end\":62750,\"start\":62731},{\"end\":63087,\"start\":63077},{\"end\":63097,\"start\":63087},{\"end\":63106,\"start\":63097},{\"end\":63394,\"start\":63387},{\"end\":63405,\"start\":63394},{\"end\":63645,\"start\":63626},{\"end\":63660,\"start\":63645},{\"end\":63680,\"start\":63660},{\"end\":63699,\"start\":63680},{\"end\":63909,\"start\":63895},{\"end\":64083,\"start\":64068},{\"end\":64094,\"start\":64083},{\"end\":64393,\"start\":64379},{\"end\":64408,\"start\":64393},{\"end\":64424,\"start\":64408},{\"end\":64436,\"start\":64424},{\"end\":64451,\"start\":64436},{\"end\":64465,\"start\":64451},{\"end\":64479,\"start\":64465},{\"end\":64499,\"start\":64479},{\"end\":64733,\"start\":64721},{\"end\":64743,\"start\":64733},{\"end\":64756,\"start\":64743},{\"end\":64768,\"start\":64756},{\"end\":64782,\"start\":64768},{\"end\":64794,\"start\":64782},{\"end\":64805,\"start\":64794},{\"end\":64817,\"start\":64805},{\"end\":64835,\"start\":64817},{\"end\":64853,\"start\":64835},{\"end\":64862,\"start\":64853},{\"end\":65241,\"start\":65223},{\"end\":65259,\"start\":65241},{\"end\":65273,\"start\":65259},{\"end\":65548,\"start\":65537},{\"end\":65564,\"start\":65548},{\"end\":65572,\"start\":65564},{\"end\":65584,\"start\":65572},{\"end\":65598,\"start\":65584},{\"end\":66062,\"start\":66053},{\"end\":66070,\"start\":66062},{\"end\":66395,\"start\":66375},{\"end\":66403,\"start\":66395},{\"end\":66418,\"start\":66403},{\"end\":66434,\"start\":66418},{\"end\":66450,\"start\":66434},{\"end\":66465,\"start\":66450},{\"end\":66474,\"start\":66465},{\"end\":67189,\"start\":67176},{\"end\":67207,\"start\":67189},{\"end\":67519,\"start\":67506},{\"end\":67530,\"start\":67519},{\"end\":67548,\"start\":67530},{\"end\":67564,\"start\":67548},{\"end\":67577,\"start\":67564},{\"end\":67593,\"start\":67577},{\"end\":67605,\"start\":67593},{\"end\":67622,\"start\":67605},{\"end\":67635,\"start\":67622},{\"end\":67647,\"start\":67635},{\"end\":67863,\"start\":67850},{\"end\":67877,\"start\":67863},{\"end\":67891,\"start\":67877},{\"end\":67907,\"start\":67891},{\"end\":67917,\"start\":67907},{\"end\":68216,\"start\":68202},{\"end\":68232,\"start\":68216},{\"end\":68395,\"start\":68379},{\"end\":68412,\"start\":68395},{\"end\":68429,\"start\":68412},{\"end\":68444,\"start\":68429},{\"end\":68463,\"start\":68444},{\"end\":68479,\"start\":68463},{\"end\":68818,\"start\":68800},{\"end\":68828,\"start\":68818},{\"end\":68836,\"start\":68828},{\"end\":68853,\"start\":68836},{\"end\":68871,\"start\":68853},{\"end\":68880,\"start\":68871},{\"end\":68895,\"start\":68880},{\"end\":68912,\"start\":68895},{\"end\":68927,\"start\":68912},{\"end\":68946,\"start\":68927},{\"end\":69344,\"start\":69319},{\"end\":69361,\"start\":69344},{\"end\":69375,\"start\":69361},{\"end\":69385,\"start\":69375},{\"end\":69400,\"start\":69385},{\"end\":69419,\"start\":69400},{\"end\":69784,\"start\":69761},{\"end\":69794,\"start\":69784},{\"end\":69806,\"start\":69794},{\"end\":69820,\"start\":69806},{\"end\":69829,\"start\":69820},{\"end\":69840,\"start\":69829},{\"end\":69851,\"start\":69840},{\"end\":69860,\"start\":69851},{\"end\":70240,\"start\":70224},{\"end\":70263,\"start\":70240},{\"end\":70290,\"start\":70263},{\"end\":70306,\"start\":70290},{\"end\":70328,\"start\":70306},{\"end\":70349,\"start\":70328},{\"end\":70823,\"start\":70809},{\"end\":70839,\"start\":70823},{\"end\":70852,\"start\":70839},{\"end\":70863,\"start\":70852},{\"end\":70876,\"start\":70863},{\"end\":70884,\"start\":70876},{\"end\":71184,\"start\":71170},{\"end\":71199,\"start\":71184},{\"end\":71213,\"start\":71199},{\"end\":71224,\"start\":71213},{\"end\":71235,\"start\":71224},{\"end\":71241,\"start\":71235},{\"end\":71510,\"start\":71496},{\"end\":71651,\"start\":71638},{\"end\":71659,\"start\":71651},{\"end\":71668,\"start\":71659},{\"end\":71681,\"start\":71668},{\"end\":71694,\"start\":71681},{\"end\":71971,\"start\":71960},{\"end\":71984,\"start\":71971},{\"end\":71995,\"start\":71984},{\"end\":72009,\"start\":71995},{\"end\":72021,\"start\":72009},{\"end\":72037,\"start\":72021},{\"end\":72051,\"start\":72037},{\"end\":72064,\"start\":72051},{\"end\":72075,\"start\":72064},{\"end\":72418,\"start\":72406},{\"end\":72430,\"start\":72418},{\"end\":72449,\"start\":72430},{\"end\":72459,\"start\":72449},{\"end\":72472,\"start\":72459},{\"end\":72480,\"start\":72472},{\"end\":72487,\"start\":72480},{\"end\":72498,\"start\":72487},{\"end\":72508,\"start\":72498},{\"end\":72518,\"start\":72508},{\"end\":72529,\"start\":72518},{\"end\":72543,\"start\":72529},{\"end\":72548,\"start\":72543},{\"end\":72941,\"start\":72929},{\"end\":72953,\"start\":72941},{\"end\":72965,\"start\":72953},{\"end\":72975,\"start\":72965},{\"end\":72986,\"start\":72975},{\"end\":72990,\"start\":72986},{\"end\":73343,\"start\":73330},{\"end\":73358,\"start\":73343},{\"end\":73372,\"start\":73358},{\"end\":73383,\"start\":73372},{\"end\":73665,\"start\":73647},{\"end\":73682,\"start\":73665},{\"end\":73708,\"start\":73682},{\"end\":73720,\"start\":73708},{\"end\":73738,\"start\":73720},{\"end\":73752,\"start\":73738},{\"end\":74090,\"start\":74074},{\"end\":74106,\"start\":74090},{\"end\":74124,\"start\":74106},{\"end\":74139,\"start\":74124},{\"end\":74159,\"start\":74139},{\"end\":74484,\"start\":74469},{\"end\":74498,\"start\":74484},{\"end\":74514,\"start\":74498},{\"end\":74530,\"start\":74514},{\"end\":74721,\"start\":74705},{\"end\":74735,\"start\":74721},{\"end\":74748,\"start\":74735},{\"end\":74765,\"start\":74748},{\"end\":74778,\"start\":74765},{\"end\":74793,\"start\":74778},{\"end\":74808,\"start\":74793},{\"end\":74826,\"start\":74808},{\"end\":75119,\"start\":75101},{\"end\":75137,\"start\":75119},{\"end\":75155,\"start\":75137},{\"end\":75171,\"start\":75155},{\"end\":75183,\"start\":75171},{\"end\":75198,\"start\":75183},{\"end\":75520,\"start\":75503},{\"end\":75537,\"start\":75520},{\"end\":75712,\"start\":75701},{\"end\":75729,\"start\":75712},{\"end\":75745,\"start\":75729},{\"end\":75757,\"start\":75745},{\"end\":75768,\"start\":75757},{\"end\":75785,\"start\":75768},{\"end\":76186,\"start\":76172},{\"end\":76200,\"start\":76186},{\"end\":76215,\"start\":76200},{\"end\":76229,\"start\":76215},{\"end\":76242,\"start\":76229},{\"end\":76258,\"start\":76242},{\"end\":76576,\"start\":76563},{\"end\":76588,\"start\":76576},{\"end\":76598,\"start\":76588},{\"end\":76608,\"start\":76598},{\"end\":76616,\"start\":76608},{\"end\":76626,\"start\":76616},{\"end\":76636,\"start\":76626},{\"end\":76650,\"start\":76636},{\"end\":76660,\"start\":76650},{\"end\":76669,\"start\":76660},{\"end\":76682,\"start\":76669},{\"end\":76694,\"start\":76682},{\"end\":76705,\"start\":76694},{\"end\":76717,\"start\":76705},{\"end\":76729,\"start\":76717},{\"end\":76741,\"start\":76729},{\"end\":76760,\"start\":76741},{\"end\":76773,\"start\":76760},{\"end\":77355,\"start\":77338},{\"end\":77662,\"start\":77652},{\"end\":77676,\"start\":77662},{\"end\":77703,\"start\":77676},{\"end\":77722,\"start\":77703},{\"end\":77730,\"start\":77722},{\"end\":77751,\"start\":77730},{\"end\":78082,\"start\":78070},{\"end\":78101,\"start\":78082},{\"end\":78118,\"start\":78101},{\"end\":78132,\"start\":78118},{\"end\":78148,\"start\":78132},{\"end\":78158,\"start\":78148},{\"end\":78170,\"start\":78158},{\"end\":78185,\"start\":78170},{\"end\":78192,\"start\":78185},{\"end\":78485,\"start\":78474},{\"end\":78496,\"start\":78485},{\"end\":78511,\"start\":78496},{\"end\":78529,\"start\":78511},{\"end\":78807,\"start\":78796},{\"end\":78820,\"start\":78807},{\"end\":78834,\"start\":78820},{\"end\":78846,\"start\":78834},{\"end\":78856,\"start\":78846},{\"end\":79107,\"start\":79094},{\"end\":79118,\"start\":79107},{\"end\":79132,\"start\":79118},{\"end\":79147,\"start\":79132},{\"end\":79407,\"start\":79391},{\"end\":79419,\"start\":79407},{\"end\":79433,\"start\":79419},{\"end\":79447,\"start\":79433},{\"end\":79458,\"start\":79447},{\"end\":79465,\"start\":79458},{\"end\":79479,\"start\":79465},{\"end\":79492,\"start\":79479},{\"end\":79884,\"start\":79868},{\"end\":79897,\"start\":79884},{\"end\":79911,\"start\":79897},{\"end\":79922,\"start\":79911},{\"end\":79936,\"start\":79922},{\"end\":79948,\"start\":79936},{\"end\":79961,\"start\":79948},{\"end\":79973,\"start\":79961},{\"end\":79987,\"start\":79973},{\"end\":79994,\"start\":79987},{\"end\":80354,\"start\":80344},{\"end\":80366,\"start\":80354},{\"end\":80380,\"start\":80366},{\"end\":80399,\"start\":80380},{\"end\":80410,\"start\":80399},{\"end\":80425,\"start\":80410},{\"end\":80435,\"start\":80425},{\"end\":80836,\"start\":80822},{\"end\":80851,\"start\":80836},{\"end\":80871,\"start\":80851},{\"end\":80888,\"start\":80871},{\"end\":80905,\"start\":80888},{\"end\":81305,\"start\":81289},{\"end\":81317,\"start\":81305},{\"end\":81328,\"start\":81317},{\"end\":81341,\"start\":81328},{\"end\":81355,\"start\":81341},{\"end\":81366,\"start\":81355},{\"end\":81382,\"start\":81366},{\"end\":81393,\"start\":81382},{\"end\":81406,\"start\":81393},{\"end\":81706,\"start\":81696},{\"end\":81718,\"start\":81706},{\"end\":81727,\"start\":81718},{\"end\":81739,\"start\":81727},{\"end\":81749,\"start\":81739},{\"end\":81759,\"start\":81749},{\"end\":81770,\"start\":81759},{\"end\":81783,\"start\":81770},{\"end\":81799,\"start\":81783},{\"end\":83933,\"start\":83920}]", "bib_venue": "[{\"end\":72136,\"start\":72132},{\"end\":73043,\"start\":73025},{\"end\":52404,\"start\":52322},{\"end\":53129,\"start\":53076},{\"end\":53589,\"start\":53530},{\"end\":53866,\"start\":53829},{\"end\":54401,\"start\":54388},{\"end\":54704,\"start\":54614},{\"end\":55017,\"start\":54998},{\"end\":55597,\"start\":55588},{\"end\":56089,\"start\":56009},{\"end\":56545,\"start\":56479},{\"end\":56889,\"start\":56812},{\"end\":57353,\"start\":57279},{\"end\":57766,\"start\":57700},{\"end\":58197,\"start\":58188},{\"end\":58594,\"start\":58537},{\"end\":58926,\"start\":58875},{\"end\":59222,\"start\":59187},{\"end\":59520,\"start\":59469},{\"end\":59877,\"start\":59818},{\"end\":60272,\"start\":60266},{\"end\":60686,\"start\":60621},{\"end\":61112,\"start\":61053},{\"end\":61565,\"start\":61506},{\"end\":61856,\"start\":61787},{\"end\":62331,\"start\":62251},{\"end\":62801,\"start\":62750},{\"end\":63164,\"start\":63106},{\"end\":63423,\"start\":63405},{\"end\":63708,\"start\":63699},{\"end\":63936,\"start\":63909},{\"end\":64155,\"start\":64094},{\"end\":64503,\"start\":64499},{\"end\":64924,\"start\":64878},{\"end\":65299,\"start\":65273},{\"end\":65677,\"start\":65598},{\"end\":66103,\"start\":66070},{\"end\":66373,\"start\":66303},{\"end\":66850,\"start\":66735},{\"end\":67251,\"start\":67207},{\"end\":67504,\"start\":67468},{\"end\":68200,\"start\":68138},{\"end\":68541,\"start\":68495},{\"end\":68986,\"start\":68946},{\"end\":69470,\"start\":69419},{\"end\":69892,\"start\":69860},{\"end\":70408,\"start\":70349},{\"end\":70807,\"start\":70718},{\"end\":71168,\"start\":71124},{\"end\":71530,\"start\":71510},{\"end\":71776,\"start\":71710},{\"end\":72130,\"start\":72091},{\"end\":72579,\"start\":72548},{\"end\":73023,\"start\":72990},{\"end\":73442,\"start\":73383},{\"end\":73814,\"start\":73768},{\"end\":74210,\"start\":74159},{\"end\":74467,\"start\":74427},{\"end\":74867,\"start\":74842},{\"end\":75257,\"start\":75198},{\"end\":75562,\"start\":75537},{\"end\":75886,\"start\":75801},{\"end\":76286,\"start\":76258},{\"end\":76832,\"start\":76773},{\"end\":77408,\"start\":77355},{\"end\":77802,\"start\":77751},{\"end\":78208,\"start\":78192},{\"end\":78588,\"start\":78529},{\"end\":78794,\"start\":78760},{\"end\":79198,\"start\":79147},{\"end\":79567,\"start\":79508},{\"end\":79866,\"start\":79790},{\"end\":80501,\"start\":80435},{\"end\":80964,\"start\":80905},{\"end\":81287,\"start\":81190},{\"end\":81867,\"start\":81815},{\"end\":82112,\"start\":82084},{\"end\":82259,\"start\":82147},{\"end\":82529,\"start\":82388},{\"end\":82801,\"start\":82714},{\"end\":82967,\"start\":82899},{\"end\":83291,\"start\":83193},{\"end\":83676,\"start\":83542},{\"end\":84013,\"start\":83933},{\"end\":84440,\"start\":84394},{\"end\":84617,\"start\":84584}]"}}}, "year": 2023, "month": 12, "day": 17}