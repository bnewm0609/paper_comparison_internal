{"id": 235364004, "updated": "2023-10-06 01:55:28.709", "metadata": {"title": "Diversity driven Query Rewriting in Search Advertising", "authors": "[{\"first\":\"Akash\",\"last\":\"Mohankumar\",\"middle\":[\"Kumar\"]},{\"first\":\"Nikit\",\"last\":\"Begwani\",\"middle\":[]},{\"first\":\"Amit\",\"last\":\"Singh\",\"middle\":[]}]", "venue": null, "journal": "Proceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery & Data Mining", "publication_date": {"year": 2021, "month": 6, "day": 7}, "abstract": "Retrieving keywords (bidwords) with the same intent as query, referred to as close variant keywords, is of prime importance for effective targeted search advertising. For head and torso search queries, sponsored search engines use a huge repository of same intent queries and keywords, mined ahead of time. Online, this repository is used to rewrite the query and then lookup the rewrite in a repository of bid keywords contributing to significant revenue. Recently generative retrieval models have been shown to be effective at the task of generating such query rewrites. We observe two main limitations of such generative models. First, rewrites generated by these models exhibit low lexical diversity, and hence the rewrites fail to retrieve relevant keywords that have diverse linguistic variations. Second, there is a misalignment between the training objective - the likelihood of training data, v/s what we desire - improved quality and coverage of rewrites. In this work, we introduce CLOVER, a framework to generate both high-quality and diverse rewrites by optimizing for human assessment of rewrite quality using our diversity-driven reinforcement learning algorithm. We use an evaluation model, trained to predict human judgments, as the reward function to finetune the generation policy. We empirically show the effectiveness of our proposed approach through offline experiments on search queries across geographies spanning three major languages. We also perform online A/B experiments on Bing, a large commercial search engine, which shows (i) better user engagement with an average increase in clicks by 12.83% accompanied with an average defect reduction by 13.97%, and (ii) improved revenue by 21.29%.", "fields_of_study": "[\"Computer Science\",\"Mathematics\"]", "external_ids": {"arxiv": "2106.03816", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/kdd/MohankumarBS21", "doi": "10.1145/3447548.3467202"}}, "content": {"source": {"pdf_hash": "d705f010ceb3df03f53b4e85a316dc3437ddcb4a", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2106.03816v1.pdf\"]", "oa_url_match": true, "oa_info": {"license": null, "open_access_url": "http://arxiv.org/pdf/2106.03816", "status": "GREEN"}}, "grobid": {"id": "ee6d52a56c7415bae92479bf876d8e925d1bf7d3", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/d705f010ceb3df03f53b4e85a316dc3437ddcb4a.txt", "contents": "\nSingapore Akash Kumar Mohankumar, Nikit Begwani, and Amit Singh. 2021. Diversity driven Query Rewriting in Search Advertising\nAugust 14-18, 2021. August 14-18, 2021\n\nAkash Kumar Mohankumar \nNikit Begwani nibegwan@microsoft.com \nMicrosoft Bangalore \nIndia Amit Singh \n\nIndian Institute of Technology Madras Chennai\nIndia\n\n\nMicrosoft Bangalore\nIndia\n\nSingapore Akash Kumar Mohankumar, Nikit Begwani, and Amit Singh. 2021. Diversity driven Query Rewriting in Search Advertising\n\nProceedings of the 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD '21)\nthe 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD '21)August 14-18, 2021. August 14-18, 202110.1145/3447548.3467202* Both authors contributed equally to this work \u2020 Work done during internship at Microsoft ACM ISBN 978-1-4503-8332-5/21/08. . . $15.00 ACM Reference Format: Event, Singapore. ACM, New York, NY, USA, 9 pages. https://CCS CONCEPTSComputing methodologies \u2192 Natural language generation;Information systems \u2192 Sponsored search advertising KEYWORDS sponsored search, query rewriting, natural language generation\nRetrieving keywords (bidwords) with the same intent as query, referred to as close variant keywords, is of prime importance for effective targeted search advertising. For head and torso search queries, sponsored search engines use a huge repository of same intent queries and keywords, mined ahead of time. Online, this repository is used to rewrite the query and then lookup the rewrite in a repository of bid keywords contributing to significant revenue. Recently generative retrieval models have been shown to be effective at the task of generating such query rewrites. We observe two main limitations of such generative models. First, rewrites generated by these models exhibit low lexical diversity, and hence the rewrites fail to retrieve relevant keywords that have diverse linguistic variations. Second, there is a misalignment between the training objective -the likelihood of training data, v/s what we desire -improved quality and coverage of rewrites. In this work, we introduce CLOVER, a framework to generate both high-quality and diverse rewrites by optimizing for human assessment of rewrite quality using our diversity-driven reinforcement learning algorithm. We use an evaluation model, trained to predict human judgments, as the reward function to finetune the generation policy. We empirically show the effectiveness of our proposed approach through offline experiments on search queries across geographies spanning three major languages. We also perform online A/B experiments on Bing, a large commercial search engine, which shows (i) better user engagement with an average increase in clicks by 12.83% accompanied with an average defect reduction by 13.97%, and (ii) improved revenue by 21.29%.\n\nINTRODUCTION\n\nSponsored search is an important component of modern search engines and accounts for a significant portion of their revenue. In sponsored search, advertisers bid on keywords relevant to their business to place their ads along with the organic search results. The search engine must match a user's search query to relevant keywords. Traditionally, search engines only used exact match where a user's search query is matched to a bid keyword only if they are exactly the same. The exact match type poses a massive challenge for advertisers to enumerate all possible variations of a keyword and separately bid on each of them. Further, exact match type leads to potential revenue loss to advertisers and the search engine since ads aren't displayed even if a user's query is only a minor modification of a bid keyword. To overcome these problems, search engines now provide extensions to exact match such as close-variant match types 1 where search queries are matched to bid keywords with the same search intent even though they are expressed with different words. This problem of matching a search query to its close-variant keywords is challenging for many reasons. First, the query-keyword match should be of high quality, i.e. the matched keywords should strictly have the same search intent as the original search query. Second, the matching algorithm should retrieve all possible high-quality bid keywords for a given query, resulting in the maximum coverage from the bid keyword library. Third, the matching algorithms must be multilingual since modern search engines support search in various languages.\n\nMatching search queries with bid keywords online in real-time places latency and compute constraints on the matching algorithm, often resulting in lower quality and coverage. Therefore in addition to online rewrites, search engines mine bid keywords offline for frequent queries and store them ahead of time in a production table, which is a multivalue map consisting of entries of the form { : 1 , 2 . . . } where , represent queries and keywords respectively. Such offline close-variant matching can be performed using various approaches in the literature. One standard method is to use Information Retrieval (IR) algorithms to retrieve relevant keywords for a given search query and then apply quality filters [14] to remove the low-quality keywords. A common problem observed in IR methods, dubbed as the \"semantic gap\" problem [24,33], is IR methods often fail to retrieve many semantically relevant keywords for a given query. Few works [11,15,37] try to mitigate this problem by rewriting the input search query into several intermediate queries and then combine the retrieved keywords obtained from all the intermediate queries. However, as pointed out by [24], such a multi-stage procedure can result in a gradual accumulation of errors in each sub-module resulting in low precision and recall rates. Recent methods [24,33] focus on leveraging advancements in Natural Language Generation (NLG) by viewing this problem as a constrained generation task. Such generative approaches first involve training language models to generate query rewrites in a supervised setup. Later, during inference with beam search, the generations are constrained to the bid keyword library using a prefix trie.\n\nDespite the performance improvement over IR baselines, existing generative approaches have a few important shortcomings. Firstly, rewrites generated with beam search for a given input query tend to be very similar to each other. For example, as shown in the column 2 of table 1, the generated rewrites are only minor syntactical variations of the input query such as modifying word order, adding articles, etc. Such low linguistic diversity in the rewrites leads to limited coverage as we fail to retrieve several other keywords that have diverse lexical variations. Another problem with these approaches is the log-likelihood training objective is only a rough proxy of what we actually care about -improved quality and coverage in the rewrites. For instance, the log-likelihood objective cannot distinguish between important (e.g., adding irrelevant words in the rewrite) and unimportant (e.g., selecting the precise word from a list of synonyms) errors and penalize the model accordingly. Further, the maximum likelihood approach encourages the model to increase the probability of generating the training data even if it is of poor quality. Also, the training dataset, consisting of queries and its corresponding rewrites, itself is often limited. For example, the training data usually only contains a few rewrites for each query, but our objective is to generate all possible relevant keywords for a search query during inference to achieve high coverage.\n\nAs illustrated in figure 1, the set of all high-quality bid keywords includes both lexically similar and diverse keywords. In this work, we specifically focus on generating such lexically diverse keywords that are more challenging to be retrieved. We empirically show that adopting a diverse decoding algorithm [22] during inference can partially overcome the problem with standard beam search. For example, as shown in column 3 of table 1, we are now able to retrieve keywords with greater linguistic diversity. However, we also observe instances where with increased diversity, the generated rewrites drift away from the original search intent (column 4 of table 1). In this work, we show that it is possible to retrieve keywords with high-quality and high lexical diversity that were not previously retrieved using our Close Variant Generation (CLOVER) framework. We propose a more principled approach to overcome the previously discussed problems by directly optimizing human judgments on rewrite quality with a controllable diversity constraint. We first train an evaluation model to predict human judgments on rewrite quality of generated rewrites. We then use the evaluation model as a reward function to finetune the generation policy in a reinforcement learning setup. However, we observe a crucial problem with the standard RL objective. We show that it is sufficient for the generation policy to place a high probability mass one plausible rewrite and ignore all other valid rewrites to obtain high rewards in the standard RL setup. To overcome this problem, we propose our diversity driven RL algorithm where the optimization objective enforces generating multiple diverse and high-quality rewrites. As shown in column 5 of table 1, our proposed approach generates rewrites with highquality and high diversity. We perform offline experiments on queries from a large commercial search engine spanning three languages (English, German and French) and demonstrate the effectiveness of our proposed approach. We further conducted online experiments on a commercial search engine 2 across regions spanning three major languages and obtained an average of 12.83% improvement in clicks, 13.97% reduction in defect, and 21.29% improvement in revenue from close variants. To sum up, the key contributions of our work are listed below:\n\n\u2022 We identify the key problems limiting the performance of existing generative retrieval approaches in sponsored search. We empirically show that some of these problems can be partially alleviated using a diverse decoding algorithm. \u2022 We propose CLOVER, a framework for optimizing human judgments on rewrite quality while also being able to control the desired diversity. \u2022 Through offline experiments on search queries, we show that our proposed approach generates diverse and high-quality keywords that were not retrieved by previous methods. \u2022 Finally, we conduct online A/B experiments on a commercial search engine and show that our proposed methods leads to significantly better user engagement and revenue gains.   [6,7,36] mainly focused on matching queries with relevant advertisements using standard information retrieval algorithms where an advertisement is treated as a document consisting of textual information such as the bid keyword, ad text visible to users, etc. Such approaches mainly use bag-of-words features like tf-idf to match queries with ads. Some other works [3,12] learn embeddings of queries and ads in a shared vector space from search session, ad click, and search link click data using word2vec [28] like algorithms. A few recent works [23] exploit advances in neural information retrieval models [29] such as Deep Crossing [41] in sponsored search. An important line of work [11,13,15,27,37] that is based on the idea of performing query to query transformations, also known as query rewriting. In these methods, the input search query is rewritten to multiple intermediate queries, and then the bid keywords are retrieved from all the intermediate queries either with exact match or more advanced matching algorithms. Another related area of research [1,49] involves keyword to keyword transformations referred to as keyword rewriting, where the objective is to rewrite less frequent bid keywords without altering the search original intent. Recently, there is a greater focus on direct query to keyword transformations [20,24,33]. In these approaches, the input query is directly converted to several bid keywords using seq2seq language models with trie based decoding techniques to constraint the output space during inference. Another recent work [9] views matching bid keywords to queries as an extreme multi-label classification problem and propose deep extreme multi-label learning algorithms.\n\n\nReinforcement Learning in NLP:\n\nIn NLP, there is a rich literature in using reinforcement algorithms to optimize heuristic-based evaluation metrics such as BLEU in machine translation [30,34] and ROUGE in automatic summarization [34,47]. Such works usually use policy gradient algorithms such as REINFORCE with baseline [46] to optimize the rewards where the baseline can either be learned from data [34] or can be set to the reward obtained from greedy decoding [35]. There have also been works [2] that have investigated Actor-Critic algorithms [16] in NLP. Recently, there has been an increasing focus on using rewards from trained evaluation models in various tasks such as Machine Translation [18], Abstracting Summarization [5,43,50]. Unlike the previous works which focus on generation quality, our work focuses on improving both generation quality and diversity. To this end, we propose a novel RL algorithm where the performance measure of a policy is defined as the expected rewards from multiple diverse samples decoded from the policy and not just one sample as defined in the previous works.\n\n\nMETHODOLOGY\n\nIn this section, we discuss the various components of our Close Variant Generation (CLOVER) framework, as outlined in figure  2. Given a user's search query , our objective is to retrieve all keywords with the same search intent as from the set of bid keywords K. We first discuss the details of our language generation model in section 3.1. Next, in section 3.2, we discuss our evaluation model, which is trained to evaluate the quality of rewrites. Later in 3.3, we discuss the standard RL approach used to finetune the generation model with rewards. We then discuss the limitations of the standard RL formulation and propose our Diversity Driven RL approach in 3.4. Lastly, in 3.5, we discuss the decoding algorithms.\n\n\nGeneration Model\n\nFor generating query rewrites, we adopt the ProphetNet model [48] which has been shown to obtain state-of-the-art performance on several seq2seq language generation tasks. The model follows the standard transformer-large encoder-decoder architecture [44] with 12 layers of encoder and 12 layers of decoder. We use a multi-lingual version of the ProphetNet model that is pretrained on the multilingual (100 languages) Wikipedia corpus using the token span masking objective [42]. We then finetune the generation model for query rewriting using the the next n-gram prediction objective [48] in a supervised manner i.e. the model is trained to predict the next n tokens of the rewrite given the previous tokens and the input query. More specifically, given a dataset of query\nrewrite pairs D = { ( ) ,\u02dc( ) } =1 , where ( ) = { ( ) 1 , . . . , ( ) }, ( ) = {\u02dc( ) 1 , .\n. . ,\u02dc( ) }, our training objective is as follows: where represents the model parameters, { } \u22121 =0 are the weights given to each future token prediction. During training, all the future n tokens are simultaneously predicted with the help of an n-stream self-attention mechanism. During inference, only the mainstream self-attention is used to predict the tokens one at a time.\nL ( , D) = \u2212 ,\u02dc\u223cD \uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 \u22121 \u2211\ufe01 =0 \u2211\ufe01 =1 log (\u02dc+ |\u02dc< , , ) \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb\n\nEvaluation Model\n\nThe goal of the evaluation model is to judge the quality of a generated rewrite\u02c6corresponding to an input query . Several recent studies [26,31,39,40] have shown that heuristic-based evaluation metrics that rely on n-gram overlap [4,25,32] or word embedding similarity [10,19,38] with a reference have very poor correlations with human judgements on several NLG tasks. We observed that the performance of such heuristic-based metrics in query rewriting is indeed abysmal. To illustrate this, consider an input query \"sennheiser headphones with attached microphone\" with a reference rewrite \"sennheiser headphones attached with microphone\". The rewrite \"sony headphones attached with microphone\" is exactly the same as the reference rewrite except for one word but does not have the same search intent as the input. On the other hand, the rewrite \"sennheiser headsets\" has only a single word in common with the reference but is a valid rewrite. Such nuances in search intent cannot be handled by metrics that rely on simple hand-crafted rules. Therefore, we develop an end-to-end evaluation metric specifically trained to evaluate the quality of generated rewrites. We use the XLM-RoBERTa (XLM-R) [8] model with 24 transformer encoder layers that is pre-trained on 100 languages. We fine-tune the XLM-R model on a dataset consisting of triplets of the form ( ,\u02c6, ) where represents the human judgments provided by annotators about quality of the rewrite\u02c6. The scores provided by the trained evaluation model, denoted by (\u02c6, ) is used to evaluate the quality of the generated rewrites and is also used as rewards to the RL algorithms as we described in the next subsection.\n\n\nReinforcement Learning Approach\n\nQuery rewriting can be formulated as a reinforcement learning problem, similar to other sequence generation problems [34,35,43,50]: At the start of an episode, the environment chooses a search query (initial state). The agent (generator) chooses an action\u02c6(next word) at time according to the policy (.|\u02c6< , , ). After taking an action, the agent updates its internal state and continues rolling out the policy until the end token or maximum sequence length is reached. The environment then provides a reward for the generated rewrite\u02c6(sequence of actions), which the agent aims to optimize. Formally, the goal of the agent is to learn the policy parameter that maximizes:\n( ) =\u02c6\u223c (. | , ) (\u02c6)(1)\nwhere\u02c6= {\u02c61, . . .\u02c6},\u02c6is the sampled token from the policy (.|\u02c6< , , ) at time , (\u02c6) is the reward for\u02c6which can depend on the search query and optionally a reference rewrite\u02dc(these dependencies are omitted from the notation for brevity). We now give a brief overview of the standard policy gradients algorithms used to optimize the objective in equation 1.\n\n\nREINFORCE:\n\nThe REINFORCE algorithm [46] uses an unbiased gradient estimator to approximate the exact gradients with Monte-Carlo samples. Given a mini batch of search queries { ( ) } =1 and the corresponding rewrites {\u02c6( ) } =1 sampled from the policy (.| , ), the gradient is approximated as follows:\n\u2207 ( ) \u2248 \u2211\ufe01 =1 (\u02c6( ) )\u2207 log (\u02c6( ) | ( ) , )(2)\nREINFORCE with baseline: Although, the REINFORCE gradient estimator is unbiased, it suffers from very high variance. A common technique used in practice to reduce the variance is to add a baseline function to the gradient estimator:\n\u2207 ( ) \u2248 \u2211\ufe01 =1 (\u02c6( ) ) \u2212 ( ) \u2207 log (\u02c6( ) | ( ) , )(3)\nIt can be shown that the new gradient estimator is unbiased if the baseline ( ) does not depend on the sampled actions\u02c6( ) [46]. Reward function: We compute the scores provided by our evaluation model for a generated rewrite\u02c6by comparing it with the the input query and with the reference rewrite\u02dc. We use the weighted combinations of these two scores as our reward function. Mathematically, the reward function is defined as follows:\n(\u02c6) = (\u02c6, ) + (1 \u2212 ) (\u02c6,\u02dc)(4)\nIf high-quality reference rewrites are not available, we can set to 1 and neglect the (\u02c6,\u02dc) term.\n\n\nDiversity driven Reinforcement Learning\n\nA crucial problem with the standard reinforcement learning setup is that in order to optimize equation 1, it is sufficient for the policy to place a high probability mass on one plausible rewrite and ignore all other valid rewrites for a given input query. Concretely, there always exists an optimal policy * (\u02c6| ) which is completely deterministic given the input query i.e. it generates only one rewrite per query: * (\u02c6| ) = 1, if\u02c6= arg max\u02c6(\u02c6) 0 otherwise\n\nIn fact, we shall show in section 4.4 that as we finetune the generator model using the REINFORCE with baseline algorithm, the entropy of the policy keeps decreasing and approaches a very low value. The key problem here lies with the standard RL objective since it only requires expected rewards of one sample (rewrite) from the policy to be high. Unlike other generation tasks such as machine translation, this is a significant problem in query rewriting since our primary objective is to generate as many distinct high-quality rewrites as possible for a given search query.\n\nTo overcome these issues in the standard RL objective, we propose our diversity driven reinforcement learning problem formulation. Our formulation uses a diverse decoding subroutine M that takes as input the generator model (.| , ), its parameter , an input query , a diversity parameter and returns diverse samples {\u02c61, . . . ,\u02c6} without replacement from the policy , where\u02c6= {\u02c61 . . . ,\u02c6}. We shall discuss more details about such decoding algorithms in the next subsection. In diversity driven RL, our goal is to maximize the expected total rewards obtained from diverse rewrites sampled from the policy using the decoding subroutine M. Formally, our objective is defined as follows: \n\nThe main difference here is that optimizing the performance measure in equation 5 results in policies that when decoded with M produce both diverse and high quality rewrites. The amount of desired diversity in the rewrites can be controlled by the diversity parameter . To optimize the new objective, we follow the REINFORCE with baseline algorithm and approximate the gradient as:\n\u2207 ( , M) \u2248 \u2211\ufe01 =1 \u2211\ufe01 =1 ( (\u02c6( ) ) \u2212 ( ) )\u2207 log (\u02c6( ) | ( ) , ) (7) ( ) = 1 \u2212 1 \u2211\ufe01 =1, \u2260 (\u02c6( ) )(8)\nwhere\n{ ( ) } =1 is a mini-batch of search queries, {{\u02c6( ) 1 . . .\u02c6( ) }} =1\nis the corresponding rewrites decoded using M ( , , ( ) , ). As baseline for a rewrite, we use the average rewards obtained by all rewrites for the same search query other than itself. The overall training procedure is shown in algorithm 1.\n\n\nDecoding Algorithm\n\nWe now discuss in detail about the decoding algorithm M, described in the previous sub-section, for sampling diverse rewrites from the generator. We experimented with various possible choices such as stochastic beam search [17] and other deterministic approximations: diverse beam search [45] and diverse sibling search [22]. In practice, we found the diverse sibling search algorithm to work the best. Diverse sibling search is a variant of the standard beam search algorithm that penalizes decoding similar hypothesis within the beam. The standard beam search algorithm consists of selecting the top B hypothesis with the maximum sum of log probability (\u02c6,\u02c6< | ) at each time step where (\u02c6,\u02c6< | ) = (\u02c6< | ) + log (\u02c6|\u02c6< , , K ). Diverse sibling search adds a penalty term that discourages multiple expansions\u02c6with the same prefix\u02c6< . The modified beam search objective is\u02dc(\u02c6,\u02c6< | ) = (\u02c6,\u02c6< | ) \u2212\n\nwhere is the rank of the current hypothesis [\u02c6,\u02c6< ] among its siblings that have the same prefix\u02c6< . is the diversity factor that controls the desire degree of diversity During inference, we constrain our decoding space with a prefix trie K of sub-word tokens consisting of all the keywords in the bid keyword library K. When decoding a sub-token\u02c6at time step , we prune all words that are not a suffix of the already generated sequence\u02c6< in the trie. More formally, the (unnormalized) constrained probability distribution is given by:\n(\u02c6= |\u02c6< , ) = (\u02c6= |\u02c6< , ), if \u2208 suffix K (\u02c6< ) 0, otherwise\nWe use the decoding algorithm M with this constrained distribution during inference to ensure that all the rewrites are valid bid keywords.\n\n\nOFFLINE EXPERIMENTS 4.1 Dataset Description\n\nIn this section, we describe the various datasets used for training and evaluating (i) the Generation model and (ii) the Evaluation model. All our datasets are obtained from search queries across geographies that span three main languages: English, French and German. Generation Models: For training our generation models, we used two training sets dubbed Ads-large and Ads-small. Ads-large is a We finetuned our generator model in a supervised setup using the Ads-large dataset. Training in the RL setup is considerably slower than in the supervised setup with teacher forcing because the output tokens are decoded one word at a time in an auto-regressive manner. Therefore, we used a smaller training set for RL finetuning called Ads-small, which consists of 24 million query rewrite pairs. For evaluating the generator models, we carefully curated a dataset of 80k search queries. The average length of the queries in these datasets is around 3.42 words.\n\nEvaluation Model: To finetune our evaluation model, we collected a dataset of human judgments on rewrite quality. We showed human annotators the original query and a generated rewrite and asked them to rate the rewrite on a 5 point Likert scale with scores from 1 to 5 representing bad, fair, good, perfect, and excellent, respectively. We obtained annotations from multiple annotators for each query rewrite pair to arrive at a final consensus over the rating. We collected such annotations for 75k query rewrite pairs (45k in English and 15k in French and German each) where the rewrites were obtained from various query rewriting models in production.\n\n\nExperimental Details\n\nGenerator Supervised Finetuning: We finetuned the ProphetNet model from the pretrained checkpoint for 5 epochs on the Ads-large dataset. Following [48], we use = 2 and 1 = 0.5, 2 = 0.5 in the next n-gram prediction objective. We set the dropout to 0.1, weight decay to 0.01 and label smoothing to 0.1. We used a batch size of 4096 tokens with ADAM optimizer ( 1 = 0.9, 2 = 0.999) and learning rate of 1e-5. We used mixed-precision training on 8 Nvidia 16Gb V100 GPUs. The overall training time is close to two weeks.\n\nGenerator RL Finetuning: We further finetune the ProphetNet model from the supervised checkpoint for 1 epoch on the Ads-small dataset. We used a batch size of 224 tokens and a beam size of 20 during training and used 4 Nvidia 32Gb V100 GPUs. The remaining details are the same as in the supervised setup.\n\nEvaluation Model Finetuning: We finetuned our evaluation model from the publicly released XLM-R pre-trained checkpoint on our dataset of human judgments. We converted the human ratings into binary labels were ratings of 3 and above i.e. good and above ratings were converted to a label of 1 (positive), and the rest were given a label of 0 (negative). We used binary cross-entropy as our loss function with the binary human labels as the targets.\n\n\nEvaluation Metrics\n\nOur objective is to generate rewrites which (i) are valid bid keywords, (ii) are of high quality, (iii) have high coverage. As we discussed in section 3.2, heuristic-based evaluation metrics such as BLEU [32], ROUGE [25] that rely on n-gram overlap perform poorly in evaluating the rewrite quality. Hence, we use our trained evaluation model described in section 3.2 to evaluate the rewrite or keyword quality. Our evaluation model achieves AUC-ROC of 0.924 and 0.910 on the English and Non-English human judgments data (test split), respectively. Apart from the three criteria mentioned above, there is another important criterion specific to offline query rewriting. In the offline setting, the production table already consists of high-quality keywords retrieved by various algorithms proposed in the literature. Therefore, the usefulness of a newly proposed algorithm depends on how many net new high-quality bid keywords an algorithm adds to the production table. In other words, an algorithm creates no additional value in generating keywords that have already been retrieved and stored in the production table by previous methods. We apply a series of filters on the generated rewrites to obtain the net new high-quality bid keywords an algorithm adds to the production table:\n\n\u2022 Valid Bid Filter: We filter out all the generated rewrites that are not present in the bid keyword library. \u2022 Unique Filter: We filter out those keywords that are already present in the production map i.e. we only select those keywords that are unique to the algorithm and not present in the production map. \u2022 Quality Filter (Global): Here, we filter out the generated keywords with a quality score less than a particular threshold. A common threshold is chosen across all the input queries; hence we call this a global filter. This filter ensures we only select keywords that have a global quality standard. \u2022 Quality Filter (Local): We additionally apply a filter using a quality threshold that is specific to each query. We compute the minimum quality of the keywords present in the production map for each query and use it as the (query-specific) quality threshold. Hence, we ensure that the newly added keywords have a higher quality than the minimum quality keyword present in the production dictionary for each query.\n\nFinally, we use the following evaluation metrics: Unique High-Quality Bid Keyword refers to the total number of keywords retrieved after applying all the filters mentioned above. We report the average value per input query. Distinct n-gram statistics [21] measure the diversity in the rewrites after applying all the filters. It counts the total number of distinct n-grams in the generated rewrites. The statistics are then divided by the total number of tokens generated to bias against long rewrites.\n\n\nResults & Discussions\n\nWe report our offline evaluation results on various algorithms in table 2. The first row contains the results of using beam search without the prefix trie during inference. In all the other experiments, we used trie based decoding. We use a beam size of 20 in all these experiments. The reported results are aggregated across the different languages. The performance across the different languages are similar, and hence we do not include the language-wise data due to space constraints. As noted by [24], using a prefix trie during beam search significantly improves the number of new keywords added to the production map because the trie constraint ensures that all the generated rewrites are valid bid keywords, hence serves as a strong baseline. However, we note that the lexical diversity of the rewrites, as measures by the distinct n-gram statistics, are low for the rewrites generated with beam search. In the next row, we report the result of using diverse sibling search [22] instead of normal beam search during inference on the supervised finetuned model. We tuned the diversity strength ( ) hyper-parameter to maximize the number of unique, high-quality keywords retrieved. We observe slight improvements in (i) the number of keywords retrieved (from 3.80 to 3.84) and (ii) the diversity of the generated rewrites. However, as we show in the ensemble results (Ensemble (I) + (II) + (III)), out of the 3.84 keywords/query only an average of 0.39 keywords/query are the net new additions to the production map because the remaining keywords were already retrieved using standard beam search.\n\nIn figure 3, we show the entropy of the output distribution as a function of the training iterations during standard RL finetuning. We observe that the entropy does indeed decreases to very low values as discussed in section 3.4. As a result, we observed that the coverage of the rewrites significantly deteriorates since the output distributions are very peaky. We then report the results of the model finetuned using our proposed diversity driven RL approach in table 2. We observe a significant improvement in the diversity of the rewrites while the number of retrieved keywords is still comparable to those retrieved by previous methods. Further, as shown in the last row, most rewrites from the diversity RL (CLOVER) method (2.16 out of 3.13) are net new additions to the production map. Here, we wish to note that generating lexically diverse keywords is much more challenging than generating lexically similar keywords. For instance, consider the example in table 1 where the input query is \"accommodations in london\". The lexically similar rewrites generated by supervised finetuning approaches such as \"accommodations London\", \"london accommodation\" are often just minor syntactic variations while the generations using CLOVER such as \"best hotels london\", \"lodging in london uk\" require a greater understanding of the search intent. In table 1, we compare the rewrite diversity between supervised and our proposed diversity RL approach for various decoding algorithms. We show that the rewrite diversity is significantly higher in CLOVER across the different decoding algorithms. Finally, in table 4, we increase the beam size during inference and show that both the number of retrieved keywords and their diversity increase in our proposed approach.\n\n\nONLINE EXPERIMENT\n\nTo measure the efficacy of CLOVER, we conducted online experiments on live traffic of a large commercial search engine. The data was collected for more than two weeks over a significant percentage of traffic via the A/B testing framework.We use two primary metrics to evaluate the performance of our retrieval framework.  \u2022 Click which denotes the net new click addition over the existing rewrite models. This translates into revenue. \u2022 Defect Quality -This data is collected via human-labeled judgment where we sent the impressed query and keyword pairs each day for a month from both production and experiment setting to be categorized into good and bad pairs. The delta change represents the decrease in bad labeled data with respect to all data collected.\n\nWe chose the above two metrics to ensure that click/revenue increase should not come at the cost of quality deterioration. Table 5 reflects the summarized results of the stated metric for both English and non-English queries.\n\nCLOVER contributed to a healthy increase of clicks ( 8% in non-English and 18% in English segments) without compromising on the quality of rewrites generated. In fact, we are able to improve the defect rate by a significant margin ( -18% in non-English and -9% in English segments). To further investigate the gains, we analyzed the query coverage and keyword density increase over the current production map. We distributed queries into buckets (otherwise commonly known as deciles in the field of sponsored search); each bucket consists of queries depending on the frequency in which they occur. For example:-decile 1 represents queries that are most frequent in number, but the overall count of such queries is less (usually under 100), similarly owing to the heavy tail nature of Figure 4: Coverage (left y-axis) and Density (right y-axis) delta uplift from current production map over each decile search queries, decile 10 represents queries that are less frequent, but overall distinct queries are very high in number (usually in millions). We define query coverage for a decile as the number of queries in the decile for which any sponsored content was shown, also keyword density for a query is defined as the number of keywords that is mapped to a particular query in the production map. Figure  4 shows that for both English and non-English languages, we see a healthy query coverage increase leading to relevant sponsored content on searches which were earlier untapped. We also observe a healthy keyword density increase for existing queries leading to more relevant and better service of sponsored content, supported by improved defect metric. \n\n\nCONCLUSION\n\nGenerating high-quality, diverse rewrites of search queries is a critical challenge in sponsored search and can lead to significant revenue gains. The existing generative Seq2Seq models do not yield satisfactory results due to disparity in training objectives and desired outcomes. In this paper, we analyze the challenges of existing models and propose a Close Variant Generation (CLOVER) framework to optimize human judgments on rewrite quality with diversity constraints on the rewrite. We show that our proposed approach generates diverse and high-quality keywords that were not retrieved by previous methods. Through live A/B tests on a popular search engine, we show significant gains in clicks, revenue, defect, and other metrics over state-of-the-art techniques currently in production.\n\nFigure 1 :\n1Diagram of different possible keyword sets\n\nFigure 2 :\n2CLOVER: Consisting of a Generator and Evaluation model with the diversity driven RL algorithm\n\n(\n, , M) = \u2211\ufe01 =1\u02c6\u223c M ( , , , ) (\u02c6)\n\nAlgorithm 1 :\n1Training Procedure for Learning Generator Parameters with Diversity driven Reinforcement Learning Input :Train dataset D, batch size , diverse decoding sub-routine M, beam size , diversity strength , reward weight Output :Learned Generator parameters for number of training iterations do Sample {( (1) ,\u02dc( 1) ) . . . ( ( ) ,\u02dc( ) )} \u223c D ; for \u2190 1 to do {\u02c6( ) 1 , . . . ,\u02c6( ) } \u2190 M ( , , ( ) , , ) ; )\u2207 log (\u02c6( ) | ( ) , ) ; end massive dataset of 330 million pairs of queries and corresponding rewrites mined from the search logs of a commercial search engine.\n\nFigure 3 :\n3Entropy of the Output distribution as a function of the training iterations in the standard reinforcement learning setup (REINFORCE with a baseline algorithm)\n\nTable 1 :\n1Samples of generated keywords by different methods on four search queries \n\n2 RELATED WORK \n\nSponsored Search: Early works in sponsored search \n\n\nComparison of lexical diversity b/w supervised finetuning & CLOVER (diversity driven RL) for various decoding algorithmsFinetuning \nDecoding Algorithm \nUnique High Quality Distinct Unigram Distinct Bigram \nApproach \nBid Keyword \nSupervised \nBS w/o Trie (I) \n2.10 \n0.209 \n0.573 \nSupervised \nNormal BS with Trie (II) \n3.80 \n0.590 \n0.868 \nSupervised Diverse Sibling Search with Trie (III) \n3.84 \n0.591 \n0.869 \nDiverse RL Diverse Sibling Search with Trie (IV) \n3.13 \n0.738 \n0.917 \nEnsemble Results \nEnsemble (I) \n2.10 \n-\n-\nEnsemble (I) + (II) \n5.13 (+3.03) \n-\n-\nEnsemble (I) + (II) + (III) \n5.52 (+0.39) \n-\n-\nEnsemble (I) + (II) +(III) + (IV) \n7.68 (+2.16) \n-\n-\nTable 2: Offline results on various approaches along with the ensembles \n\nDecoding Algorithm \nDiversity Strength \nDistinct Unigram \nDistinct Bigram \nSupervised Diversity RL Supervised Diversity RL \nBeam Search with Trie \n-\n0.590 \n0.678 \n0.868 \n0.895 \nDiverse Sibling Search with Trie \n0.1 \n0.591 \n0.706 \n0.869 \n0.903 \nDiverse Sibling Search with Trie \n0.5 \n0.616 \n0.716 \n0.876 \n0.908 \nDiverse Sibling Search with Trie \n1 \n0.651 \n0.738 \n0.889 \n0.917 \nTable 3: \n\n\n: Effect of varying the Beam Size in our generator model finetuned with diverse RL objective and decoded with diverse sibling search ( = 1)Beam Size \nUnique High Quality \nBid Keywords \n\nDistinct \nUnigram \n\nDistinct \nBigram \n20 \n3.13 \n0.738 \n0.917 \n30 \n3.96 \n0.753 \n0.924 \n40 \n4.62 \n0.771 \n0.932 \n50 \n5.14 \n0.785 \n0.937 \nTable 4\n\n\nLanguage Segment \u0394 Click \u0394 Revenue \u0394 Defect : Online Results for A/B Testing on live trafficNon-English \n7.90% \n16.47% \n-18.47% \nEnglish \n17.76% \n26.11% \n-9.48% \nTable 5\nhttps://support.google.com/google-ads/answer/9342105?hl=en arXiv:2106.03816v1 [cs.CL] 7 Jun 2021\nMicrosoft Bing\n\nAds Keyword Rewriting Using Search Engine Results. J Azimi, A Alam, R Zhang, Proceedings of the 24th International Conference on World Wide Web. the 24th International Conference on World Wide WebJ. Azimi, A. Alam, and R. Zhang. 2015. Ads Keyword Rewriting Using Search Engine Results. Proceedings of the 24th International Conference on World Wide Web (2015).\n\nAn Actor-Critic Algorithm for Sequence Prediction. Dzmitry Bahdanau, Philemon Brakel, Kelvin Xu, Anirudh Goyal, Ryan Lowe, Joelle Pineau, Aaron C Courville, Yoshua Bengio, ArXiv abs/1607.07086Dzmitry Bahdanau, Philemon Brakel, Kelvin Xu, Anirudh Goyal, Ryan Lowe, Joelle Pineau, Aaron C. Courville, and Yoshua Bengio. 2017. An Actor-Critic Algorithm for Sequence Prediction. ArXiv abs/1607.07086 (2017).\n\nScalable Query N-Gram Embedding for Improving Matching and Relevance in Sponsored Search. Xiao Bai, E Ordentlich, Yuanyuan Zhang, Andy Feng, A Ratnaparkhi, Reena Somvanshi, Aldi Tjahjadi, Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data MiningXiao Bai, E. Ordentlich, Yuanyuan Zhang, Andy Feng, A. Ratnaparkhi, Reena Somvanshi, and Aldi Tjahjadi. 2018. Scalable Query N-Gram Embedding for Improving Matching and Relevance in Sponsored Search. Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (2018).\n\nMETEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments. Satanjeev Banerjee, Alon Lavie, Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization. the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or SummarizationAnn Arbor, MichiganAssociation for Computational LinguisticsSatanjeev Banerjee and Alon Lavie. 2005. METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments. In Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization. Association for Computational Linguistics, Ann Arbor, Michigan, 65-72. https://www.aclweb.org/anthology/W05-0909\n\nF B\u00f6hm, Yang Gao, C Meyer, Ori Shapira, I Dagan, Iryna Gurevych, ArXiv abs/1909.01214Better Rewards Yield Better Summaries: Learning to Summarise Without References. F. B\u00f6hm, Yang Gao, C. Meyer, Ori Shapira, I. Dagan, and Iryna Gurevych. 2019. Better Rewards Yield Better Summaries: Learning to Summarise Without Refer- ences. ArXiv abs/1909.01214 (2019).\n\nSearch advertising using web relevance feedback. A Broder, P Ciccolo, Marcus Fontoura, Evgeniy Gabrilovich, V Josifovski, L Riedel, CIKM '08. A. Broder, P. Ciccolo, Marcus Fontoura, Evgeniy Gabrilovich, V. Josifovski, and L. Riedel. 2008. Search advertising using web relevance feedback. In CIKM '08.\n\nA semantic approach to contextual advertising. A Broder, Marcus Fontoura, V Josifovski, L Riedel, SIGIR. A. Broder, Marcus Fontoura, V. Josifovski, and L. Riedel. 2007. A semantic approach to contextual advertising. In SIGIR.\n\nUnsupervised Cross-lingual Representation Learning at Scale. Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guillaume Wenzek, E Francisco Guzm\u00e1n, Myle Grave, Luke Ott, Veselin Zettlemoyer, Stoyanov, ACL. Alexis Conneau, Kartikay Khandelwal, Naman Goyal, Vishrav Chaudhary, Guil- laume Wenzek, Francisco Guzm\u00e1n, E. Grave, Myle Ott, Luke Zettlemoyer, and Veselin Stoyanov. 2020. Unsupervised Cross-lingual Representation Learning at Scale. In ACL.\n\nDeepXML: Scalable & Accurate Deep Extreme Classification for Matching User Queries to Advertiser Bid Phrases. Kunal Dahiya, Anshul Mittal, Deepak Saini, Kushal S Dave, Himanshu Jain, Sumeet Agarwal, M Varma, Kunal Dahiya, Anshul Mittal, Deepak Saini, Kushal S. Dave, Himanshu Jain, Sumeet Agarwal, and M. Varma. 2019. DeepXML: Scalable & Accurate Deep Extreme Classification for Matching User Queries to Advertiser Bid Phrases.\n\nBootstrapping Dialog Systems with Word Embeddings. Gabriel Forgues, Joelle Pineau, Gabriel Forgues and Joelle Pineau. 2014. Bootstrapping Dialog Systems with Word Embeddings.\n\nLearning Lexicon Models from Search Logs for Query Expansion. Jianfeng Gao, X Shasha Xie, Alnur He, Ali, EMNLP-CoNLL. Jianfeng Gao, Shasha Xie, X. He, and Alnur Ali. 2012. Learning Lexicon Models from Search Logs for Query Expansion. In EMNLP-CoNLL.\n\nScalable Semantic Matching of Queries to Ads in Sponsored Search Advertising. M Grbovic, Nemanja Djuric, V Radosavljevic, F Silvestri, R Baeza-Yates, A Feng, Erik Ordentlich, Lee Yang, Gavin Owens, Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval. the 39th International ACM SIGIR conference on Research and Development in Information RetrievalM. Grbovic, Nemanja Djuric, V. Radosavljevic, F. Silvestri, R. Baeza-Yates, A. Feng, Erik Ordentlich, Lee Yang, and Gavin Owens. 2016. Scalable Semantic Matching of Queries to Ads in Sponsored Search Advertising. Proceedings of the 39th International ACM SIGIR conference on Research and Development in Information Retrieval (2016).\n\nContext-and Content-aware Embeddings for Query Rewriting in Sponsored Search. M Grbovic, Nemanja Djuric, F Vladan Radosavljevic, Narayan Silvestri, Bhamidipati, Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval. the 38th International ACM SIGIR Conference on Research and Development in Information RetrievalM. Grbovic, Nemanja Djuric, Vladan Radosavljevic, F. Silvestri, and Narayan Bhamidipati. 2015. Context-and Content-aware Embeddings for Query Rewrit- ing in Sponsored Search. Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval (2015).\n\nImproving ad relevance in sponsored search. D Hillard, Stefan Schroedl, Eren Manavoglu, H Raghavan, C Leggetter, WSDM '10. D. Hillard, Stefan Schroedl, Eren Manavoglu, H. Raghavan, and C. Leggetter. 2010. Improving ad relevance in sponsored search. In WSDM '10.\n\nGenerating query substitutions. R Jones, B Rey, O Madani, W Greiner, WWW '06. R. Jones, B. Rey, O. Madani, and W. Greiner. 2006. Generating query substitutions. In WWW '06.\n\nActor-Critic Algorithms. R Vijay, J Konda, Tsitsiklis, NIPS. Vijay R. Konda and J. Tsitsiklis. 1999. Actor-Critic Algorithms. In NIPS.\n\nStochastic Beams and Where to Find Them: The Gumbel-Top-k Trick for Sampling Sequences Without Replacement. H V Wouter Kool, M Hoof, Welling, ICML. Wouter Kool, H. V. Hoof, and M. Welling. 2019. Stochastic Beams and Where to Find Them: The Gumbel-Top-k Trick for Sampling Sequences Without Replace- ment. In ICML.\n\nCan Neural Machine Translation be Improved with User Feedback. Julia Kreutzer, E Shahram Khadivi, S Matusov, Riezler, NAACL-HLT. Julia Kreutzer, Shahram Khadivi, E. Matusov, and S. Riezler. 2018. Can Neural Machine Translation be Improved with User Feedback?. In NAACL-HLT.\n\nA solution to Plato's problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge. K Thomas, Susan T Landauer, Dumais, Psychological review. 104211Thomas K Landauer and Susan T Dumais. 1997. A solution to Plato's problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge. Psychological review 104, 2 (1997), 211.\n\nRare Query Expansion Through Generative Adversarial Networks in Search Advertising. Mu-Chu Lee, B Gao, R Zhang, Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data MiningMu-Chu Lee, B. Gao, and R. Zhang. 2018. Rare Query Expansion Through Generative Adversarial Networks in Search Advertising. Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining (2018).\n\nA Diversity-Promoting Objective Function for Neural Conversation Models. J Li, Michel Galley, Chris Brockett, Jianfeng Gao, W Dolan, ArXiv abs/1510.03055J. Li, Michel Galley, Chris Brockett, Jianfeng Gao, and W. Dolan. 2016. A Diversity-Promoting Objective Function for Neural Conversation Models. ArXiv abs/1510.03055 (2016).\n\nA Simple, Fast Diverse Decoding Algorithm for Neural Generation. J Li, Will Monroe, Dan Jurafsky, ArXiv abs/1611.08562J. Li, Will Monroe, and Dan Jurafsky. 2016. A Simple, Fast Diverse Decoding Algorithm for Neural Generation. ArXiv abs/1611.08562 (2016).\n\nLearning Fast Matching Models from Weak Annotations. Xue Li, Z Luo, Hao Sun, Jianjin Zhang, W Han, Xianqi Chu, L Zhang, Qi Zhang, The World Wide Web Conference. Xue Li, Z. Luo, Hao Sun, Jianjin Zhang, W. Han, Xianqi Chu, L. Zhang, and Qi Zhang. 2019. Learning Fast Matching Models from Weak Annotations. The World Wide Web Conference (2019).\n\nAn end-to-end Generative Retrieval Method for Sponsored Search Engine -Decoding Efficiently into a Closed Target Domain. Yijiang Lian, Z Chen, J Hu, Chunwei Ke Feng Zhang, Muchenxuan Yan, W Tong, Han, Y Hanju Guan, Y Li, Yang Cao, Z Yu, X Li, Y Liu, Wang, ArXiv abs/1902.00592Yijiang Lian, Z. Chen, J. Hu, Ke feng Zhang, Chunwei Yan, Muchenxuan Tong, W. Han, Hanju Guan, Y. Li, Y. Cao, Yang Yu, Z. Li, X. Liu, and Y. Wang. 2019. An end-to-end Generative Retrieval Method for Sponsored Search Engine -Decoding Efficiently into a Closed Target Domain. ArXiv abs/1902.00592 (2019).\n\nROUGE: A Package for Automatic Evaluation of Summaries. Chin-Yew Lin, Text Summarization Branches Out. Barcelona, SpainAssociation for Computational LinguisticsChin-Yew Lin. 2004. ROUGE: A Package for Automatic Evaluation of Summaries. In Text Summarization Branches Out. Association for Computational Linguistics, Barcelona, Spain, 74-81. https://www.aclweb.org/anthology/W04-1013\n\nHow NOT To Evaluate Your Dialogue System: An Empirical Study of Unsupervised Evaluation Metrics for Dialogue Response Generation. Chia-Wei Liu, Ryan Lowe, Iulian Serban, Michael Noseworthy, Laurent Charlin, Joelle Pineau, The Association for Computational Linguistics. Jian Su, Xavier Carreras, and Kevin DuhChia-Wei Liu, Ryan Lowe, Iulian Serban, Michael Noseworthy, Laurent Charlin, and Joelle Pineau. 2016. How NOT To Evaluate Your Dialogue System: An Empirical Study of Unsupervised Evaluation Metrics for Dialogue Response Generation, Jian Su, Xavier Carreras, and Kevin Duh (Eds.). The Association for Computational Linguistics.\n\nOptimizing query rewrites for keyword-based advertising. A Malekian, C Chang, Ravi Kumar, Grant Wang, EC '08A. Malekian, C. Chang, Ravi Kumar, and Grant Wang. 2008. Optimizing query rewrites for keyword-based advertising. In EC '08.\n\nDistributed Representations of Words and Phrases and their Compositionality. Tomas Mikolov, Ilya Sutskever, Kai Chen, G S Corrado, J Dean, ArXiv abs/13104546Tomas Mikolov, Ilya Sutskever, Kai Chen, G. S. Corrado, and J. Dean. 2013. Distributed Representations of Words and Phrases and their Compositionality. ArXiv abs/1310.4546 (2013).\n\nNeural Models for Information Retrieval. Bhaskar Mitra, Nick Craswell, ArXiv abs/1705.01509Bhaskar Mitra and Nick Craswell. 2017. Neural Models for Information Retrieval. ArXiv abs/1705.01509 (2017).\n\nReinforcement Learning for Bandit Neural Machine Translation with Simulated Human Feedback. Khanh Nguyen, Hal Daum\u00e9, Jordan L Boyd-Graber, ArXiv abs/1707.07402Khanh Nguyen, Hal Daum\u00e9, and Jordan L. Boyd-Graber. 2017. Reinforcement Learning for Bandit Neural Machine Translation with Simulated Human Feedback. ArXiv abs/1707.07402 (2017).\n\nWhy We Need New Evaluation Metrics for NLG. Jekaterina Novikova, Ondrej Dusek, Amanda Cercas Curry, Verena Rieser, 10.18653/v1/d17-1238Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. Martha Palmer, Rebecca Hwa, and Sebastian Riedelthe 2017 Conference on Empirical Methods in Natural Language ProcessingCopenhagen, DenmarkAssociation for Computational LinguisticsJekaterina Novikova, Ondrej Dusek, Amanda Cercas Curry, and Verena Rieser. 2017. Why We Need New Evaluation Metrics for NLG. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, EMNLP 2017, Copenhagen, Denmark, September 9-11, 2017, Martha Palmer, Rebecca Hwa, and Sebastian Riedel (Eds.). Association for Computational Linguistics, 2241-2252. https://doi.org/10.18653/v1/d17-1238\n\nBLEU: a Method for Automatic Evaluation of Machine Translation. Kishore Papineni, Salim Roukos, Todd Ward, Wei-Jing Zhu, 10.3115/1073083.1073135Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics. the 40th Annual Meeting of the Association for Computational LinguisticsPhiladelphia, Pennsylvania, USAAssociation for Computational LinguisticsKishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. 2002. BLEU: a Method for Automatic Evaluation of Machine Translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics, Philadelphia, Pennsylvania, USA, 311-318. https://doi.org/10.3115/1073083.1073135\n\nProphetNet-Ads: A Looking Ahead Strategy for Generative Retrieval Models in Sponsored Search Engine. Weizhen Qi, Yeyun Gong, Yu Yan, Jian Jiao, B Shao, R Zhang, H Li, N Duan, M Zhou, ArXiv abs/2010.10789Weizhen Qi, Yeyun Gong, Yu Yan, Jian Jiao, B. Shao, R. Zhang, H. Li, N. Duan, and M. Zhou. 2020. ProphetNet-Ads: A Looking Ahead Strategy for Generative Retrieval Models in Sponsored Search Engine. ArXiv abs/2010.10789 (2020).\n\nSequence Level Training with Recurrent Neural Networks. S Marc&apos;aurelio Ranzato, M Chopra, W Auli, Zaremba, CoRR abs/1511.06732Marc'Aurelio Ranzato, S. Chopra, M. Auli, and W. Zaremba. 2016. Sequence Level Training with Recurrent Neural Networks. CoRR abs/1511.06732 (2016).\n\nSelf-Critical Sequence Training for Image Captioning. J Steven, E Rennie, Youssef Marcheret, J Mroueh, V Ross, Goel, IEEE Conference on Computer Vision and Pattern Recognition (CVPR. Steven J. Rennie, E. Marcheret, Youssef Mroueh, J. Ross, and V. Goel. 2017. Self-Critical Sequence Training for Image Captioning. 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2017), 1179-1195.\n\nImpedance coupling in content-targeted advertising. B Ribeiro-Neto, Marco Cristo, P B Golgher, E Moura, SIGIR '05. B. Ribeiro-Neto, Marco Cristo, P. B. Golgher, and E. Moura. 2005. Impedance coupling in content-targeted advertising. In SIGIR '05.\n\nQuery Rewriting Using Monolingual Statistical Machine Translation. S Riezler, Y Liu, Computational Linguistics. 36S. Riezler and Y. Liu. 2010. Query Rewriting Using Monolingual Statistical Machine Translation. Computational Linguistics 36 (2010), 569-582.\n\nA Comparison of Greedy and Optimal Assessment of Natural Language Student Input Using Word-to-Word Similarity Metrics. Vasile Rus, C Mihai, Lintean, BEA@NAACL-HLTVasile Rus and Mihai C. Lintean. 2012. A Comparison of Greedy and Optimal Assessment of Natural Language Student Input Using Word-to-Word Similarity Metrics. In BEA@NAACL-HLT.\n\nImproving Dialog Evaluation with a Multi-reference Adversarial Dataset and Large Scale Pretraining. B Ananya, Akash Sai, Siddharth Kumar Mohankumar, Mitesh M Arora, Khapra, Transactions of the Association for Computational Linguistics. 8Ananya B. Sai, Akash Kumar Mohankumar, Siddharth Arora, and Mitesh M. Khapra. 2020. Improving Dialog Evaluation with a Multi-reference Adversar- ial Dataset and Large Scale Pretraining. Transactions of the Association for Computational Linguistics 8 (2020), 810-827.\n\nA Survey of Evaluation Metrics Used for NLG Systems. B Ananya, Akash Sai, Mitesh M Kumar Mohankumar, Khapra, ArXiv abs/2008.12009Ananya B. Sai, Akash Kumar Mohankumar, and Mitesh M. Khapra. 2020. A Survey of Evaluation Metrics Used for NLG Systems. ArXiv abs/2008.12009 (2020).\n\nDeep Crossing: Web-Scale Modeling without Manually Crafted Combinatorial Features. Ying Shan, T R Hoens, Jian Jiao, Haijing Wang, Dong Yu, J Mao, Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data MiningYing Shan, T. R. Hoens, Jian Jiao, Haijing Wang, Dong Yu, and J. Mao. 2016. Deep Crossing: Web-Scale Modeling without Manually Crafted Combinatorial Features. Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (2016).\n\nMASS: Masked Sequence to Sequence Pre-training for Language Generation. K Song, X Tan, T Qin, Jianfeng Lu, T Liu, ICML. K. Song, X. Tan, T. Qin, Jianfeng Lu, and T. Liu. 2019. MASS: Masked Sequence to Sequence Pre-training for Language Generation. In ICML.\n\nLearning to summarize from human feedback. L Nisan Stiennon, Jeff Ouyang, D Wu, Ryan J Ziegler, Chelsea Lowe, A Voss, Dario Radford, Paul Amodei, Christiano, abs/2009.01325Nisan Stiennon, L. Ouyang, Jeff Wu, D. Ziegler, Ryan J. Lowe, Chelsea Voss, A. Radford, Dario Amodei, and Paul Christiano. 2020. Learning to summarize from human feedback. ArXiv abs/2009.01325 (2020).\n\nAttention is All you Need. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, L Kaiser, Illia Polosukhin, NIPS. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, L. Kaiser, and Illia Polosukhin. 2017. Attention is All you Need. In NIPS.\n\nDiverse Beam Search: Decoding Diverse Solutions from Neural Sequence Models. K Ashwin, Michael Vijayakumar, R R Cogswell, Q Selvaraju, Stefan Sun, David J Lee, Dhruv Crandall, Batra, ArXiv abs/1610.02424Ashwin K. Vijayakumar, Michael Cogswell, R. R. Selvaraju, Q. Sun, Stefan Lee, David J. Crandall, and Dhruv Batra. 2016. Diverse Beam Search: Decoding Diverse Solutions from Neural Sequence Models. ArXiv abs/1610.02424 (2016).\n\nSimple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning. R J Williams, Machine Learning. 8R. J. Williams. 1992. Simple Statistical Gradient-Following Algorithms for Connectionist Reinforcement Learning. Machine Learning 8 (1992), 229-256.\n\nLearning to Extract Coherent Summary via Deep Reinforcement Learning. Yuxiang Wu, Baotian Hu, AAAI. Yuxiang Wu and Baotian Hu. 2018. Learning to Extract Coherent Summary via Deep Reinforcement Learning. In AAAI.\n\nProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training. Yu Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, N Duan, J Chen, R Zhang, M Zhou, EMNLP. Yu Yan, Weizhen Qi, Yeyun Gong, Dayiheng Liu, N. Duan, J. Chen, R. Zhang, and M. Zhou. 2020. ProphetNet: Predicting Future N-gram for Sequence-to-Sequence Pre-training. In EMNLP.\n\nDomain-Constrained Advertising Keyword Generation. Hao Zhou, Minlie Huang, Y Mao, Changlei Zhu, P Shu, Xiaoyan Zhu, The World Wide Web Conference. Hao Zhou, Minlie Huang, Y. Mao, Changlei Zhu, P. Shu, and Xiaoyan Zhu. 2019. Domain-Constrained Advertising Keyword Generation. The World Wide Web Conference (2019).\n\n. D Ziegler, Nisan Stiennon, Jeffrey Wu, T Brown, A Radford, Dario Amodei, Paul Christiano, Geoffrey Irving, abs/1909.08593Fine-Tuning Language Models from Human Preferences. ArXivD. Ziegler, Nisan Stiennon, Jeffrey Wu, T. Brown, A. Radford, Dario Amodei, Paul Christiano, and Geoffrey Irving. 2019. Fine-Tuning Language Models from Human Preferences. ArXiv abs/1909.08593 (2019).\n", "annotations": {"author": "[{\"end\":190,\"start\":167},{\"end\":228,\"start\":191},{\"end\":249,\"start\":229},{\"end\":267,\"start\":250},{\"end\":321,\"start\":268},{\"end\":349,\"start\":322}]", "publisher": null, "author_last_name": "[{\"end\":189,\"start\":173},{\"end\":204,\"start\":197},{\"end\":248,\"start\":239},{\"end\":266,\"start\":261}]", "author_first_name": "[{\"end\":172,\"start\":167},{\"end\":196,\"start\":191},{\"end\":238,\"start\":229},{\"end\":255,\"start\":250},{\"end\":260,\"start\":256}]", "author_affiliation": "[{\"end\":320,\"start\":269},{\"end\":348,\"start\":323}]", "title": "[{\"end\":126,\"start\":1},{\"end\":475,\"start\":350}]", "venue": "[{\"end\":571,\"start\":477}]", "abstract": "[{\"end\":2835,\"start\":1118}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":3783,\"start\":3782},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":5179,\"start\":5175},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":5298,\"start\":5294},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":5301,\"start\":5298},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":5409,\"start\":5405},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":5412,\"start\":5409},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":5415,\"start\":5412},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":5630,\"start\":5626},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":5791,\"start\":5787},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":5794,\"start\":5791},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":7940,\"start\":7936},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":10689,\"start\":10686},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":10691,\"start\":10689},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":10694,\"start\":10691},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":11053,\"start\":11050},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":11056,\"start\":11053},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":11195,\"start\":11191},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":11236,\"start\":11232},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":11297,\"start\":11293},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":11324,\"start\":11320},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":11376,\"start\":11372},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":11379,\"start\":11376},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":11382,\"start\":11379},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":11385,\"start\":11382},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":11388,\"start\":11385},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":11752,\"start\":11749},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":11755,\"start\":11752},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":12022,\"start\":12018},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":12025,\"start\":12022},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":12028,\"start\":12025},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":12251,\"start\":12248},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":12588,\"start\":12584},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":12591,\"start\":12588},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":12633,\"start\":12629},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":12636,\"start\":12633},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":12724,\"start\":12720},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":12804,\"start\":12800},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":12867,\"start\":12863},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":12899,\"start\":12896},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":12951,\"start\":12947},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":13102,\"start\":13098},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":13133,\"start\":13130},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":13136,\"start\":13133},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":13139,\"start\":13136},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":14326,\"start\":14322},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":14515,\"start\":14511},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":14738,\"start\":14734},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":14849,\"start\":14845},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":15739,\"start\":15735},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":15742,\"start\":15739},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":15745,\"start\":15742},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":15748,\"start\":15745},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":15831,\"start\":15828},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":15834,\"start\":15831},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":15837,\"start\":15834},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":15871,\"start\":15867},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":15874,\"start\":15871},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":15877,\"start\":15874},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":16797,\"start\":16794},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":17426,\"start\":17422},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":17429,\"start\":17426},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":17432,\"start\":17429},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":17435,\"start\":17432},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":18402,\"start\":18398},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":19123,\"start\":19119},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":22375,\"start\":22371},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":22440,\"start\":22436},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":22472,\"start\":22468},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":25618,\"start\":25614},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":26968,\"start\":26964},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":26980,\"start\":26976},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":29328,\"start\":29324},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":30105,\"start\":30101},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":30586,\"start\":30582}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":36497,\"start\":36442},{\"attributes\":{\"id\":\"fig_1\"},\"end\":36604,\"start\":36498},{\"attributes\":{\"id\":\"fig_2\"},\"end\":36640,\"start\":36605},{\"attributes\":{\"id\":\"fig_3\"},\"end\":37216,\"start\":36641},{\"attributes\":{\"id\":\"fig_4\"},\"end\":37388,\"start\":37217},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":37544,\"start\":37389},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":38664,\"start\":37545},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":38994,\"start\":38665},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":39166,\"start\":38995}]", "paragraph": "[{\"end\":4460,\"start\":2851},{\"end\":6160,\"start\":4462},{\"end\":7623,\"start\":6162},{\"end\":9962,\"start\":7625},{\"end\":12397,\"start\":9964},{\"end\":13504,\"start\":12432},{\"end\":14240,\"start\":13520},{\"end\":15033,\"start\":14261},{\"end\":15503,\"start\":15126},{\"end\":17269,\"start\":15598},{\"end\":17977,\"start\":17305},{\"end\":18359,\"start\":18002},{\"end\":18663,\"start\":18374},{\"end\":18942,\"start\":18710},{\"end\":19430,\"start\":18996},{\"end\":19558,\"start\":19461},{\"end\":20060,\"start\":19602},{\"end\":20637,\"start\":20062},{\"end\":21326,\"start\":20639},{\"end\":21709,\"start\":21328},{\"end\":21813,\"start\":21808},{\"end\":22125,\"start\":21885},{\"end\":23044,\"start\":22148},{\"end\":23581,\"start\":23046},{\"end\":23781,\"start\":23642},{\"end\":24786,\"start\":23829},{\"end\":25442,\"start\":24788},{\"end\":25983,\"start\":25467},{\"end\":26289,\"start\":25985},{\"end\":26737,\"start\":26291},{\"end\":28043,\"start\":26760},{\"end\":29071,\"start\":28045},{\"end\":29575,\"start\":29073},{\"end\":31203,\"start\":29601},{\"end\":32965,\"start\":31205},{\"end\":33746,\"start\":32987},{\"end\":33973,\"start\":33748},{\"end\":35632,\"start\":33975},{\"end\":36441,\"start\":35647}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":15125,\"start\":15034},{\"attributes\":{\"id\":\"formula_1\"},\"end\":15578,\"start\":15504},{\"attributes\":{\"id\":\"formula_2\"},\"end\":18001,\"start\":17978},{\"attributes\":{\"id\":\"formula_3\"},\"end\":18709,\"start\":18664},{\"attributes\":{\"id\":\"formula_4\"},\"end\":18995,\"start\":18943},{\"attributes\":{\"id\":\"formula_5\"},\"end\":19460,\"start\":19431},{\"attributes\":{\"id\":\"formula_7\"},\"end\":21807,\"start\":21710},{\"attributes\":{\"id\":\"formula_8\"},\"end\":21884,\"start\":21814},{\"attributes\":{\"id\":\"formula_9\"},\"end\":23641,\"start\":23582}]", "table_ref": "[{\"end\":33878,\"start\":33871}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2849,\"start\":2837},{\"end\":12430,\"start\":12400},{\"attributes\":{\"n\":\"3\"},\"end\":13518,\"start\":13507},{\"attributes\":{\"n\":\"3.1\"},\"end\":14259,\"start\":14243},{\"attributes\":{\"n\":\"3.2\"},\"end\":15596,\"start\":15580},{\"attributes\":{\"n\":\"3.3\"},\"end\":17303,\"start\":17272},{\"end\":18372,\"start\":18362},{\"attributes\":{\"n\":\"3.4\"},\"end\":19600,\"start\":19561},{\"attributes\":{\"n\":\"3.5\"},\"end\":22146,\"start\":22128},{\"attributes\":{\"n\":\"4\"},\"end\":23827,\"start\":23784},{\"attributes\":{\"n\":\"4.2\"},\"end\":25465,\"start\":25445},{\"attributes\":{\"n\":\"4.3\"},\"end\":26758,\"start\":26740},{\"attributes\":{\"n\":\"4.4\"},\"end\":29599,\"start\":29578},{\"attributes\":{\"n\":\"5\"},\"end\":32985,\"start\":32968},{\"attributes\":{\"n\":\"6\"},\"end\":35645,\"start\":35635},{\"end\":36453,\"start\":36443},{\"end\":36509,\"start\":36499},{\"end\":36607,\"start\":36606},{\"end\":36655,\"start\":36642},{\"end\":37228,\"start\":37218},{\"end\":37399,\"start\":37390}]", "table": "[{\"end\":37544,\"start\":37401},{\"end\":38664,\"start\":37667},{\"end\":38994,\"start\":38806},{\"end\":39166,\"start\":39089}]", "figure_caption": "[{\"end\":36497,\"start\":36455},{\"end\":36604,\"start\":36511},{\"end\":36640,\"start\":36608},{\"end\":37216,\"start\":36657},{\"end\":37388,\"start\":37230},{\"end\":37667,\"start\":37547},{\"end\":38806,\"start\":38667},{\"end\":39089,\"start\":38997}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":7651,\"start\":7643},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":13647,\"start\":13638},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":31216,\"start\":31208},{\"end\":34767,\"start\":34759},{\"end\":35281,\"start\":35272}]", "bib_author_first_name": "[{\"end\":39332,\"start\":39331},{\"end\":39341,\"start\":39340},{\"end\":39349,\"start\":39348},{\"end\":39700,\"start\":39693},{\"end\":39719,\"start\":39711},{\"end\":39734,\"start\":39728},{\"end\":39746,\"start\":39739},{\"end\":39758,\"start\":39754},{\"end\":39771,\"start\":39765},{\"end\":39785,\"start\":39780},{\"end\":39787,\"start\":39786},{\"end\":39805,\"start\":39799},{\"end\":40141,\"start\":40137},{\"end\":40148,\"start\":40147},{\"end\":40169,\"start\":40161},{\"end\":40181,\"start\":40177},{\"end\":40189,\"start\":40188},{\"end\":40208,\"start\":40203},{\"end\":40224,\"start\":40220},{\"end\":40823,\"start\":40814},{\"end\":40838,\"start\":40834},{\"end\":41517,\"start\":41516},{\"end\":41528,\"start\":41524},{\"end\":41535,\"start\":41534},{\"end\":41546,\"start\":41543},{\"end\":41557,\"start\":41556},{\"end\":41570,\"start\":41565},{\"end\":41923,\"start\":41922},{\"end\":41933,\"start\":41932},{\"end\":41949,\"start\":41943},{\"end\":41967,\"start\":41960},{\"end\":41982,\"start\":41981},{\"end\":41996,\"start\":41995},{\"end\":42223,\"start\":42222},{\"end\":42238,\"start\":42232},{\"end\":42250,\"start\":42249},{\"end\":42264,\"start\":42263},{\"end\":42469,\"start\":42463},{\"end\":42487,\"start\":42479},{\"end\":42505,\"start\":42500},{\"end\":42520,\"start\":42513},{\"end\":42541,\"start\":42532},{\"end\":42551,\"start\":42550},{\"end\":42574,\"start\":42570},{\"end\":42586,\"start\":42582},{\"end\":42599,\"start\":42592},{\"end\":42986,\"start\":42981},{\"end\":43001,\"start\":42995},{\"end\":43016,\"start\":43010},{\"end\":43030,\"start\":43024},{\"end\":43032,\"start\":43031},{\"end\":43047,\"start\":43039},{\"end\":43060,\"start\":43054},{\"end\":43071,\"start\":43070},{\"end\":43358,\"start\":43351},{\"end\":43374,\"start\":43368},{\"end\":43546,\"start\":43538},{\"end\":43553,\"start\":43552},{\"end\":43571,\"start\":43566},{\"end\":43806,\"start\":43805},{\"end\":43823,\"start\":43816},{\"end\":43833,\"start\":43832},{\"end\":43850,\"start\":43849},{\"end\":43863,\"start\":43862},{\"end\":43878,\"start\":43877},{\"end\":43889,\"start\":43885},{\"end\":43905,\"start\":43902},{\"end\":43917,\"start\":43912},{\"end\":44547,\"start\":44546},{\"end\":44564,\"start\":44557},{\"end\":44574,\"start\":44573},{\"end\":44604,\"start\":44597},{\"end\":45179,\"start\":45178},{\"end\":45195,\"start\":45189},{\"end\":45210,\"start\":45206},{\"end\":45223,\"start\":45222},{\"end\":45235,\"start\":45234},{\"end\":45430,\"start\":45429},{\"end\":45439,\"start\":45438},{\"end\":45446,\"start\":45445},{\"end\":45456,\"start\":45455},{\"end\":45597,\"start\":45596},{\"end\":45606,\"start\":45605},{\"end\":45816,\"start\":45815},{\"end\":45818,\"start\":45817},{\"end\":45833,\"start\":45832},{\"end\":46090,\"start\":46085},{\"end\":46102,\"start\":46101},{\"end\":46121,\"start\":46120},{\"end\":46425,\"start\":46424},{\"end\":46439,\"start\":46434},{\"end\":46441,\"start\":46440},{\"end\":46791,\"start\":46785},{\"end\":46798,\"start\":46797},{\"end\":46805,\"start\":46804},{\"end\":47296,\"start\":47295},{\"end\":47307,\"start\":47301},{\"end\":47321,\"start\":47316},{\"end\":47340,\"start\":47332},{\"end\":47347,\"start\":47346},{\"end\":47616,\"start\":47615},{\"end\":47625,\"start\":47621},{\"end\":47637,\"start\":47634},{\"end\":47863,\"start\":47860},{\"end\":47869,\"start\":47868},{\"end\":47878,\"start\":47875},{\"end\":47891,\"start\":47884},{\"end\":47900,\"start\":47899},{\"end\":47912,\"start\":47906},{\"end\":47919,\"start\":47918},{\"end\":47929,\"start\":47927},{\"end\":48278,\"start\":48271},{\"end\":48286,\"start\":48285},{\"end\":48294,\"start\":48293},{\"end\":48306,\"start\":48299},{\"end\":48332,\"start\":48322},{\"end\":48339,\"start\":48338},{\"end\":48352,\"start\":48351},{\"end\":48366,\"start\":48365},{\"end\":48375,\"start\":48371},{\"end\":48382,\"start\":48381},{\"end\":48388,\"start\":48387},{\"end\":48394,\"start\":48393},{\"end\":48794,\"start\":48786},{\"end\":49251,\"start\":49243},{\"end\":49261,\"start\":49257},{\"end\":49274,\"start\":49268},{\"end\":49290,\"start\":49283},{\"end\":49310,\"start\":49303},{\"end\":49326,\"start\":49320},{\"end\":49807,\"start\":49806},{\"end\":49819,\"start\":49818},{\"end\":49831,\"start\":49827},{\"end\":49844,\"start\":49839},{\"end\":50065,\"start\":50060},{\"end\":50079,\"start\":50075},{\"end\":50094,\"start\":50091},{\"end\":50102,\"start\":50101},{\"end\":50104,\"start\":50103},{\"end\":50115,\"start\":50114},{\"end\":50369,\"start\":50362},{\"end\":50381,\"start\":50377},{\"end\":50619,\"start\":50614},{\"end\":50631,\"start\":50628},{\"end\":50645,\"start\":50639},{\"end\":50647,\"start\":50646},{\"end\":50915,\"start\":50905},{\"end\":50932,\"start\":50926},{\"end\":50946,\"start\":50940},{\"end\":50953,\"start\":50947},{\"end\":50967,\"start\":50961},{\"end\":51754,\"start\":51747},{\"end\":51770,\"start\":51765},{\"end\":51783,\"start\":51779},{\"end\":51798,\"start\":51790},{\"end\":52517,\"start\":52510},{\"end\":52527,\"start\":52522},{\"end\":52536,\"start\":52534},{\"end\":52546,\"start\":52542},{\"end\":52554,\"start\":52553},{\"end\":52562,\"start\":52561},{\"end\":52571,\"start\":52570},{\"end\":52577,\"start\":52576},{\"end\":52585,\"start\":52584},{\"end\":52897,\"start\":52896},{\"end\":52926,\"start\":52925},{\"end\":52936,\"start\":52935},{\"end\":53175,\"start\":53174},{\"end\":53185,\"start\":53184},{\"end\":53201,\"start\":53194},{\"end\":53214,\"start\":53213},{\"end\":53224,\"start\":53223},{\"end\":53577,\"start\":53576},{\"end\":53597,\"start\":53592},{\"end\":53607,\"start\":53606},{\"end\":53609,\"start\":53608},{\"end\":53620,\"start\":53619},{\"end\":53840,\"start\":53839},{\"end\":53851,\"start\":53850},{\"end\":54154,\"start\":54148},{\"end\":54161,\"start\":54160},{\"end\":54469,\"start\":54468},{\"end\":54483,\"start\":54478},{\"end\":54498,\"start\":54489},{\"end\":54523,\"start\":54517},{\"end\":54525,\"start\":54524},{\"end\":54927,\"start\":54926},{\"end\":54941,\"start\":54936},{\"end\":54953,\"start\":54947},{\"end\":54955,\"start\":54954},{\"end\":55239,\"start\":55235},{\"end\":55247,\"start\":55246},{\"end\":55249,\"start\":55248},{\"end\":55261,\"start\":55257},{\"end\":55275,\"start\":55268},{\"end\":55286,\"start\":55282},{\"end\":55292,\"start\":55291},{\"end\":55821,\"start\":55820},{\"end\":55829,\"start\":55828},{\"end\":55836,\"start\":55835},{\"end\":55850,\"start\":55842},{\"end\":55856,\"start\":55855},{\"end\":56050,\"start\":56049},{\"end\":56071,\"start\":56067},{\"end\":56081,\"start\":56080},{\"end\":56090,\"start\":56086},{\"end\":56092,\"start\":56091},{\"end\":56109,\"start\":56102},{\"end\":56117,\"start\":56116},{\"end\":56129,\"start\":56124},{\"end\":56143,\"start\":56139},{\"end\":56413,\"start\":56407},{\"end\":56427,\"start\":56423},{\"end\":56441,\"start\":56437},{\"end\":56455,\"start\":56450},{\"end\":56472,\"start\":56467},{\"end\":56485,\"start\":56480},{\"end\":56487,\"start\":56486},{\"end\":56496,\"start\":56495},{\"end\":56510,\"start\":56505},{\"end\":56772,\"start\":56771},{\"end\":56788,\"start\":56781},{\"end\":56803,\"start\":56802},{\"end\":56805,\"start\":56804},{\"end\":56817,\"start\":56816},{\"end\":56835,\"start\":56829},{\"end\":56846,\"start\":56841},{\"end\":56848,\"start\":56847},{\"end\":56859,\"start\":56854},{\"end\":57216,\"start\":57215},{\"end\":57218,\"start\":57217},{\"end\":57475,\"start\":57468},{\"end\":57487,\"start\":57480},{\"end\":57689,\"start\":57687},{\"end\":57702,\"start\":57695},{\"end\":57712,\"start\":57707},{\"end\":57727,\"start\":57719},{\"end\":57734,\"start\":57733},{\"end\":57742,\"start\":57741},{\"end\":57750,\"start\":57749},{\"end\":57759,\"start\":57758},{\"end\":58007,\"start\":58004},{\"end\":58020,\"start\":58014},{\"end\":58029,\"start\":58028},{\"end\":58043,\"start\":58035},{\"end\":58050,\"start\":58049},{\"end\":58063,\"start\":58056},{\"end\":58270,\"start\":58269},{\"end\":58285,\"start\":58280},{\"end\":58303,\"start\":58296},{\"end\":58309,\"start\":58308},{\"end\":58318,\"start\":58317},{\"end\":58333,\"start\":58328},{\"end\":58346,\"start\":58342},{\"end\":58367,\"start\":58359}]", "bib_author_last_name": "[{\"end\":39338,\"start\":39333},{\"end\":39346,\"start\":39342},{\"end\":39355,\"start\":39350},{\"end\":39709,\"start\":39701},{\"end\":39726,\"start\":39720},{\"end\":39737,\"start\":39735},{\"end\":39752,\"start\":39747},{\"end\":39763,\"start\":39759},{\"end\":39778,\"start\":39772},{\"end\":39797,\"start\":39788},{\"end\":39812,\"start\":39806},{\"end\":40145,\"start\":40142},{\"end\":40159,\"start\":40149},{\"end\":40175,\"start\":40170},{\"end\":40186,\"start\":40182},{\"end\":40201,\"start\":40190},{\"end\":40218,\"start\":40209},{\"end\":40233,\"start\":40225},{\"end\":40832,\"start\":40824},{\"end\":40844,\"start\":40839},{\"end\":41522,\"start\":41518},{\"end\":41532,\"start\":41529},{\"end\":41541,\"start\":41536},{\"end\":41554,\"start\":41547},{\"end\":41563,\"start\":41558},{\"end\":41579,\"start\":41571},{\"end\":41930,\"start\":41924},{\"end\":41941,\"start\":41934},{\"end\":41958,\"start\":41950},{\"end\":41979,\"start\":41968},{\"end\":41993,\"start\":41983},{\"end\":42003,\"start\":41997},{\"end\":42230,\"start\":42224},{\"end\":42247,\"start\":42239},{\"end\":42261,\"start\":42251},{\"end\":42271,\"start\":42265},{\"end\":42477,\"start\":42470},{\"end\":42498,\"start\":42488},{\"end\":42511,\"start\":42506},{\"end\":42530,\"start\":42521},{\"end\":42548,\"start\":42542},{\"end\":42568,\"start\":42552},{\"end\":42580,\"start\":42575},{\"end\":42590,\"start\":42587},{\"end\":42611,\"start\":42600},{\"end\":42621,\"start\":42613},{\"end\":42993,\"start\":42987},{\"end\":43008,\"start\":43002},{\"end\":43022,\"start\":43017},{\"end\":43037,\"start\":43033},{\"end\":43052,\"start\":43048},{\"end\":43068,\"start\":43061},{\"end\":43077,\"start\":43072},{\"end\":43366,\"start\":43359},{\"end\":43381,\"start\":43375},{\"end\":43550,\"start\":43547},{\"end\":43564,\"start\":43554},{\"end\":43574,\"start\":43572},{\"end\":43579,\"start\":43576},{\"end\":43814,\"start\":43807},{\"end\":43830,\"start\":43824},{\"end\":43847,\"start\":43834},{\"end\":43860,\"start\":43851},{\"end\":43875,\"start\":43864},{\"end\":43883,\"start\":43879},{\"end\":43900,\"start\":43890},{\"end\":43910,\"start\":43906},{\"end\":43923,\"start\":43918},{\"end\":44555,\"start\":44548},{\"end\":44571,\"start\":44565},{\"end\":44595,\"start\":44575},{\"end\":44614,\"start\":44605},{\"end\":44627,\"start\":44616},{\"end\":45187,\"start\":45180},{\"end\":45204,\"start\":45196},{\"end\":45220,\"start\":45211},{\"end\":45232,\"start\":45224},{\"end\":45245,\"start\":45236},{\"end\":45436,\"start\":45431},{\"end\":45443,\"start\":45440},{\"end\":45453,\"start\":45447},{\"end\":45464,\"start\":45457},{\"end\":45603,\"start\":45598},{\"end\":45612,\"start\":45607},{\"end\":45624,\"start\":45614},{\"end\":45830,\"start\":45819},{\"end\":45838,\"start\":45834},{\"end\":45847,\"start\":45840},{\"end\":46099,\"start\":46091},{\"end\":46118,\"start\":46103},{\"end\":46129,\"start\":46122},{\"end\":46138,\"start\":46131},{\"end\":46432,\"start\":46426},{\"end\":46450,\"start\":46442},{\"end\":46458,\"start\":46452},{\"end\":46795,\"start\":46792},{\"end\":46802,\"start\":46799},{\"end\":46811,\"start\":46806},{\"end\":47299,\"start\":47297},{\"end\":47314,\"start\":47308},{\"end\":47330,\"start\":47322},{\"end\":47344,\"start\":47341},{\"end\":47353,\"start\":47348},{\"end\":47619,\"start\":47617},{\"end\":47632,\"start\":47626},{\"end\":47646,\"start\":47638},{\"end\":47866,\"start\":47864},{\"end\":47873,\"start\":47870},{\"end\":47882,\"start\":47879},{\"end\":47897,\"start\":47892},{\"end\":47904,\"start\":47901},{\"end\":47916,\"start\":47913},{\"end\":47925,\"start\":47920},{\"end\":47935,\"start\":47930},{\"end\":48283,\"start\":48279},{\"end\":48291,\"start\":48287},{\"end\":48297,\"start\":48295},{\"end\":48320,\"start\":48307},{\"end\":48336,\"start\":48333},{\"end\":48344,\"start\":48340},{\"end\":48349,\"start\":48346},{\"end\":48363,\"start\":48353},{\"end\":48369,\"start\":48367},{\"end\":48379,\"start\":48376},{\"end\":48385,\"start\":48383},{\"end\":48391,\"start\":48389},{\"end\":48398,\"start\":48395},{\"end\":48404,\"start\":48400},{\"end\":48798,\"start\":48795},{\"end\":49255,\"start\":49252},{\"end\":49266,\"start\":49262},{\"end\":49281,\"start\":49275},{\"end\":49301,\"start\":49291},{\"end\":49318,\"start\":49311},{\"end\":49333,\"start\":49327},{\"end\":49816,\"start\":49808},{\"end\":49825,\"start\":49820},{\"end\":49837,\"start\":49832},{\"end\":49849,\"start\":49845},{\"end\":50073,\"start\":50066},{\"end\":50089,\"start\":50080},{\"end\":50099,\"start\":50095},{\"end\":50112,\"start\":50105},{\"end\":50120,\"start\":50116},{\"end\":50375,\"start\":50370},{\"end\":50390,\"start\":50382},{\"end\":50626,\"start\":50620},{\"end\":50637,\"start\":50632},{\"end\":50659,\"start\":50648},{\"end\":50924,\"start\":50916},{\"end\":50938,\"start\":50933},{\"end\":50959,\"start\":50954},{\"end\":50974,\"start\":50968},{\"end\":51763,\"start\":51755},{\"end\":51777,\"start\":51771},{\"end\":51788,\"start\":51784},{\"end\":51802,\"start\":51799},{\"end\":52520,\"start\":52518},{\"end\":52532,\"start\":52528},{\"end\":52540,\"start\":52537},{\"end\":52551,\"start\":52547},{\"end\":52559,\"start\":52555},{\"end\":52568,\"start\":52563},{\"end\":52574,\"start\":52572},{\"end\":52582,\"start\":52578},{\"end\":52590,\"start\":52586},{\"end\":52923,\"start\":52898},{\"end\":52933,\"start\":52927},{\"end\":52941,\"start\":52937},{\"end\":52950,\"start\":52943},{\"end\":53182,\"start\":53176},{\"end\":53192,\"start\":53186},{\"end\":53211,\"start\":53202},{\"end\":53221,\"start\":53215},{\"end\":53229,\"start\":53225},{\"end\":53235,\"start\":53231},{\"end\":53590,\"start\":53578},{\"end\":53604,\"start\":53598},{\"end\":53617,\"start\":53610},{\"end\":53626,\"start\":53621},{\"end\":53848,\"start\":53841},{\"end\":53855,\"start\":53852},{\"end\":54158,\"start\":54155},{\"end\":54167,\"start\":54162},{\"end\":54176,\"start\":54169},{\"end\":54476,\"start\":54470},{\"end\":54487,\"start\":54484},{\"end\":54515,\"start\":54499},{\"end\":54531,\"start\":54526},{\"end\":54539,\"start\":54533},{\"end\":54934,\"start\":54928},{\"end\":54945,\"start\":54942},{\"end\":54972,\"start\":54956},{\"end\":54980,\"start\":54974},{\"end\":55244,\"start\":55240},{\"end\":55255,\"start\":55250},{\"end\":55266,\"start\":55262},{\"end\":55280,\"start\":55276},{\"end\":55289,\"start\":55287},{\"end\":55296,\"start\":55293},{\"end\":55826,\"start\":55822},{\"end\":55833,\"start\":55830},{\"end\":55840,\"start\":55837},{\"end\":55853,\"start\":55851},{\"end\":55860,\"start\":55857},{\"end\":56065,\"start\":56051},{\"end\":56078,\"start\":56072},{\"end\":56084,\"start\":56082},{\"end\":56100,\"start\":56093},{\"end\":56114,\"start\":56110},{\"end\":56122,\"start\":56118},{\"end\":56137,\"start\":56130},{\"end\":56150,\"start\":56144},{\"end\":56162,\"start\":56152},{\"end\":56421,\"start\":56414},{\"end\":56435,\"start\":56428},{\"end\":56448,\"start\":56442},{\"end\":56465,\"start\":56456},{\"end\":56478,\"start\":56473},{\"end\":56493,\"start\":56488},{\"end\":56503,\"start\":56497},{\"end\":56521,\"start\":56511},{\"end\":56779,\"start\":56773},{\"end\":56800,\"start\":56789},{\"end\":56814,\"start\":56806},{\"end\":56827,\"start\":56818},{\"end\":56839,\"start\":56836},{\"end\":56852,\"start\":56849},{\"end\":56868,\"start\":56860},{\"end\":56875,\"start\":56870},{\"end\":57227,\"start\":57219},{\"end\":57478,\"start\":57476},{\"end\":57490,\"start\":57488},{\"end\":57693,\"start\":57690},{\"end\":57705,\"start\":57703},{\"end\":57717,\"start\":57713},{\"end\":57731,\"start\":57728},{\"end\":57739,\"start\":57735},{\"end\":57747,\"start\":57743},{\"end\":57756,\"start\":57751},{\"end\":57764,\"start\":57760},{\"end\":58012,\"start\":58008},{\"end\":58026,\"start\":58021},{\"end\":58033,\"start\":58030},{\"end\":58047,\"start\":58044},{\"end\":58054,\"start\":58051},{\"end\":58067,\"start\":58064},{\"end\":58278,\"start\":58271},{\"end\":58294,\"start\":58286},{\"end\":58306,\"start\":58304},{\"end\":58315,\"start\":58310},{\"end\":58326,\"start\":58319},{\"end\":58340,\"start\":58334},{\"end\":58357,\"start\":58347},{\"end\":58374,\"start\":58368}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":13527239},\"end\":39640,\"start\":39280},{\"attributes\":{\"doi\":\"ArXiv abs/1607.07086\",\"id\":\"b1\"},\"end\":40045,\"start\":39642},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":51711322},\"end\":40718,\"start\":40047},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":7164502},\"end\":41514,\"start\":40720},{\"attributes\":{\"doi\":\"ArXiv abs/1909.01214\",\"id\":\"b4\"},\"end\":41871,\"start\":41516},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":15428984},\"end\":42173,\"start\":41873},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":8533551},\"end\":42400,\"start\":42175},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":207880568},\"end\":42869,\"start\":42402},{\"attributes\":{\"id\":\"b8\"},\"end\":43298,\"start\":42871},{\"attributes\":{\"id\":\"b9\"},\"end\":43474,\"start\":43300},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":15849128},\"end\":43725,\"start\":43476},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":204938713},\"end\":44466,\"start\":43727},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":13893399},\"end\":45132,\"start\":44468},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":14415078},\"end\":45395,\"start\":45134},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":207159138},\"end\":45569,\"start\":45397},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":207779694},\"end\":45705,\"start\":45571},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":76662039},\"end\":46020,\"start\":45707},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":4950709},\"end\":46295,\"start\":46022},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":1144461},\"end\":46699,\"start\":46297},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":50772235},\"end\":47220,\"start\":46701},{\"attributes\":{\"doi\":\"ArXiv abs/1510.03055\",\"id\":\"b20\"},\"end\":47548,\"start\":47222},{\"attributes\":{\"doi\":\"ArXiv abs/1611.08562\",\"id\":\"b21\"},\"end\":47805,\"start\":47550},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":59413814},\"end\":48148,\"start\":47807},{\"attributes\":{\"doi\":\"ArXiv abs/1902.00592\",\"id\":\"b23\"},\"end\":48728,\"start\":48150},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":964287},\"end\":49111,\"start\":48730},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":9197196},\"end\":49747,\"start\":49113},{\"attributes\":{\"doi\":\"EC '08\",\"id\":\"b26\"},\"end\":49981,\"start\":49749},{\"attributes\":{\"doi\":\"ArXiv abs/1310\",\"id\":\"b27\"},\"end\":50319,\"start\":49983},{\"attributes\":{\"doi\":\"ArXiv abs/1705.01509\",\"id\":\"b28\"},\"end\":50520,\"start\":50321},{\"attributes\":{\"doi\":\"ArXiv abs/1707.07402\",\"id\":\"b29\"},\"end\":50859,\"start\":50522},{\"attributes\":{\"doi\":\"10.18653/v1/d17-1238\",\"id\":\"b30\",\"matched_paper_id\":1929239},\"end\":51681,\"start\":50861},{\"attributes\":{\"doi\":\"10.3115/1073083.1073135\",\"id\":\"b31\",\"matched_paper_id\":11080756},\"end\":52407,\"start\":51683},{\"attributes\":{\"doi\":\"ArXiv abs/2010.10789\",\"id\":\"b32\"},\"end\":52838,\"start\":52409},{\"attributes\":{\"doi\":\"CoRR abs/1511.06732\",\"id\":\"b33\"},\"end\":53118,\"start\":52840},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":206594923},\"end\":53522,\"start\":53120},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":10883946},\"end\":53770,\"start\":53524},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":14195928},\"end\":54027,\"start\":53772},{\"attributes\":{\"id\":\"b37\"},\"end\":54366,\"start\":54029},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":221878812},\"end\":54871,\"start\":54368},{\"attributes\":{\"doi\":\"ArXiv abs/2008.12009\",\"id\":\"b39\"},\"end\":55150,\"start\":54873},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":9704646},\"end\":55746,\"start\":55152},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":146808476},\"end\":56004,\"start\":55748},{\"attributes\":{\"doi\":\"abs/2009.01325\",\"id\":\"b42\"},\"end\":56378,\"start\":56006},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":13756489},\"end\":56692,\"start\":56380},{\"attributes\":{\"doi\":\"ArXiv abs/1610.02424\",\"id\":\"b44\"},\"end\":57122,\"start\":56694},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":2332513},\"end\":57396,\"start\":57124},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":4999752},\"end\":57609,\"start\":57398},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":210164665},\"end\":57951,\"start\":57611},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":67856322},\"end\":58265,\"start\":57953},{\"attributes\":{\"doi\":\"abs/1909.08593\",\"id\":\"b49\"},\"end\":58647,\"start\":58267}]", "bib_title": "[{\"end\":39329,\"start\":39280},{\"end\":40135,\"start\":40047},{\"end\":40812,\"start\":40720},{\"end\":41920,\"start\":41873},{\"end\":42220,\"start\":42175},{\"end\":42461,\"start\":42402},{\"end\":43536,\"start\":43476},{\"end\":43803,\"start\":43727},{\"end\":44544,\"start\":44468},{\"end\":45176,\"start\":45134},{\"end\":45427,\"start\":45397},{\"end\":45594,\"start\":45571},{\"end\":45813,\"start\":45707},{\"end\":46083,\"start\":46022},{\"end\":46422,\"start\":46297},{\"end\":46783,\"start\":46701},{\"end\":47858,\"start\":47807},{\"end\":48784,\"start\":48730},{\"end\":49241,\"start\":49113},{\"end\":50903,\"start\":50861},{\"end\":51745,\"start\":51683},{\"end\":53172,\"start\":53120},{\"end\":53574,\"start\":53524},{\"end\":53837,\"start\":53772},{\"end\":54466,\"start\":54368},{\"end\":55233,\"start\":55152},{\"end\":55818,\"start\":55748},{\"end\":56405,\"start\":56380},{\"end\":57213,\"start\":57124},{\"end\":57466,\"start\":57398},{\"end\":57685,\"start\":57611},{\"end\":58002,\"start\":57953}]", "bib_author": "[{\"end\":39340,\"start\":39331},{\"end\":39348,\"start\":39340},{\"end\":39357,\"start\":39348},{\"end\":39711,\"start\":39693},{\"end\":39728,\"start\":39711},{\"end\":39739,\"start\":39728},{\"end\":39754,\"start\":39739},{\"end\":39765,\"start\":39754},{\"end\":39780,\"start\":39765},{\"end\":39799,\"start\":39780},{\"end\":39814,\"start\":39799},{\"end\":40147,\"start\":40137},{\"end\":40161,\"start\":40147},{\"end\":40177,\"start\":40161},{\"end\":40188,\"start\":40177},{\"end\":40203,\"start\":40188},{\"end\":40220,\"start\":40203},{\"end\":40235,\"start\":40220},{\"end\":40834,\"start\":40814},{\"end\":40846,\"start\":40834},{\"end\":41524,\"start\":41516},{\"end\":41534,\"start\":41524},{\"end\":41543,\"start\":41534},{\"end\":41556,\"start\":41543},{\"end\":41565,\"start\":41556},{\"end\":41581,\"start\":41565},{\"end\":41932,\"start\":41922},{\"end\":41943,\"start\":41932},{\"end\":41960,\"start\":41943},{\"end\":41981,\"start\":41960},{\"end\":41995,\"start\":41981},{\"end\":42005,\"start\":41995},{\"end\":42232,\"start\":42222},{\"end\":42249,\"start\":42232},{\"end\":42263,\"start\":42249},{\"end\":42273,\"start\":42263},{\"end\":42479,\"start\":42463},{\"end\":42500,\"start\":42479},{\"end\":42513,\"start\":42500},{\"end\":42532,\"start\":42513},{\"end\":42550,\"start\":42532},{\"end\":42570,\"start\":42550},{\"end\":42582,\"start\":42570},{\"end\":42592,\"start\":42582},{\"end\":42613,\"start\":42592},{\"end\":42623,\"start\":42613},{\"end\":42995,\"start\":42981},{\"end\":43010,\"start\":42995},{\"end\":43024,\"start\":43010},{\"end\":43039,\"start\":43024},{\"end\":43054,\"start\":43039},{\"end\":43070,\"start\":43054},{\"end\":43079,\"start\":43070},{\"end\":43368,\"start\":43351},{\"end\":43383,\"start\":43368},{\"end\":43552,\"start\":43538},{\"end\":43566,\"start\":43552},{\"end\":43576,\"start\":43566},{\"end\":43581,\"start\":43576},{\"end\":43816,\"start\":43805},{\"end\":43832,\"start\":43816},{\"end\":43849,\"start\":43832},{\"end\":43862,\"start\":43849},{\"end\":43877,\"start\":43862},{\"end\":43885,\"start\":43877},{\"end\":43902,\"start\":43885},{\"end\":43912,\"start\":43902},{\"end\":43925,\"start\":43912},{\"end\":44557,\"start\":44546},{\"end\":44573,\"start\":44557},{\"end\":44597,\"start\":44573},{\"end\":44616,\"start\":44597},{\"end\":44629,\"start\":44616},{\"end\":45189,\"start\":45178},{\"end\":45206,\"start\":45189},{\"end\":45222,\"start\":45206},{\"end\":45234,\"start\":45222},{\"end\":45247,\"start\":45234},{\"end\":45438,\"start\":45429},{\"end\":45445,\"start\":45438},{\"end\":45455,\"start\":45445},{\"end\":45466,\"start\":45455},{\"end\":45605,\"start\":45596},{\"end\":45614,\"start\":45605},{\"end\":45626,\"start\":45614},{\"end\":45832,\"start\":45815},{\"end\":45840,\"start\":45832},{\"end\":45849,\"start\":45840},{\"end\":46101,\"start\":46085},{\"end\":46120,\"start\":46101},{\"end\":46131,\"start\":46120},{\"end\":46140,\"start\":46131},{\"end\":46434,\"start\":46424},{\"end\":46452,\"start\":46434},{\"end\":46460,\"start\":46452},{\"end\":46797,\"start\":46785},{\"end\":46804,\"start\":46797},{\"end\":46813,\"start\":46804},{\"end\":47301,\"start\":47295},{\"end\":47316,\"start\":47301},{\"end\":47332,\"start\":47316},{\"end\":47346,\"start\":47332},{\"end\":47355,\"start\":47346},{\"end\":47621,\"start\":47615},{\"end\":47634,\"start\":47621},{\"end\":47648,\"start\":47634},{\"end\":47868,\"start\":47860},{\"end\":47875,\"start\":47868},{\"end\":47884,\"start\":47875},{\"end\":47899,\"start\":47884},{\"end\":47906,\"start\":47899},{\"end\":47918,\"start\":47906},{\"end\":47927,\"start\":47918},{\"end\":47937,\"start\":47927},{\"end\":48285,\"start\":48271},{\"end\":48293,\"start\":48285},{\"end\":48299,\"start\":48293},{\"end\":48322,\"start\":48299},{\"end\":48338,\"start\":48322},{\"end\":48346,\"start\":48338},{\"end\":48351,\"start\":48346},{\"end\":48365,\"start\":48351},{\"end\":48371,\"start\":48365},{\"end\":48381,\"start\":48371},{\"end\":48387,\"start\":48381},{\"end\":48393,\"start\":48387},{\"end\":48400,\"start\":48393},{\"end\":48406,\"start\":48400},{\"end\":48800,\"start\":48786},{\"end\":49257,\"start\":49243},{\"end\":49268,\"start\":49257},{\"end\":49283,\"start\":49268},{\"end\":49303,\"start\":49283},{\"end\":49320,\"start\":49303},{\"end\":49335,\"start\":49320},{\"end\":49818,\"start\":49806},{\"end\":49827,\"start\":49818},{\"end\":49839,\"start\":49827},{\"end\":49851,\"start\":49839},{\"end\":50075,\"start\":50060},{\"end\":50091,\"start\":50075},{\"end\":50101,\"start\":50091},{\"end\":50114,\"start\":50101},{\"end\":50122,\"start\":50114},{\"end\":50377,\"start\":50362},{\"end\":50392,\"start\":50377},{\"end\":50628,\"start\":50614},{\"end\":50639,\"start\":50628},{\"end\":50661,\"start\":50639},{\"end\":50926,\"start\":50905},{\"end\":50940,\"start\":50926},{\"end\":50961,\"start\":50940},{\"end\":50976,\"start\":50961},{\"end\":51765,\"start\":51747},{\"end\":51779,\"start\":51765},{\"end\":51790,\"start\":51779},{\"end\":51804,\"start\":51790},{\"end\":52522,\"start\":52510},{\"end\":52534,\"start\":52522},{\"end\":52542,\"start\":52534},{\"end\":52553,\"start\":52542},{\"end\":52561,\"start\":52553},{\"end\":52570,\"start\":52561},{\"end\":52576,\"start\":52570},{\"end\":52584,\"start\":52576},{\"end\":52592,\"start\":52584},{\"end\":52925,\"start\":52896},{\"end\":52935,\"start\":52925},{\"end\":52943,\"start\":52935},{\"end\":52952,\"start\":52943},{\"end\":53184,\"start\":53174},{\"end\":53194,\"start\":53184},{\"end\":53213,\"start\":53194},{\"end\":53223,\"start\":53213},{\"end\":53231,\"start\":53223},{\"end\":53237,\"start\":53231},{\"end\":53592,\"start\":53576},{\"end\":53606,\"start\":53592},{\"end\":53619,\"start\":53606},{\"end\":53628,\"start\":53619},{\"end\":53850,\"start\":53839},{\"end\":53857,\"start\":53850},{\"end\":54160,\"start\":54148},{\"end\":54169,\"start\":54160},{\"end\":54178,\"start\":54169},{\"end\":54478,\"start\":54468},{\"end\":54489,\"start\":54478},{\"end\":54517,\"start\":54489},{\"end\":54533,\"start\":54517},{\"end\":54541,\"start\":54533},{\"end\":54936,\"start\":54926},{\"end\":54947,\"start\":54936},{\"end\":54974,\"start\":54947},{\"end\":54982,\"start\":54974},{\"end\":55246,\"start\":55235},{\"end\":55257,\"start\":55246},{\"end\":55268,\"start\":55257},{\"end\":55282,\"start\":55268},{\"end\":55291,\"start\":55282},{\"end\":55298,\"start\":55291},{\"end\":55828,\"start\":55820},{\"end\":55835,\"start\":55828},{\"end\":55842,\"start\":55835},{\"end\":55855,\"start\":55842},{\"end\":55862,\"start\":55855},{\"end\":56067,\"start\":56049},{\"end\":56080,\"start\":56067},{\"end\":56086,\"start\":56080},{\"end\":56102,\"start\":56086},{\"end\":56116,\"start\":56102},{\"end\":56124,\"start\":56116},{\"end\":56139,\"start\":56124},{\"end\":56152,\"start\":56139},{\"end\":56164,\"start\":56152},{\"end\":56423,\"start\":56407},{\"end\":56437,\"start\":56423},{\"end\":56450,\"start\":56437},{\"end\":56467,\"start\":56450},{\"end\":56480,\"start\":56467},{\"end\":56495,\"start\":56480},{\"end\":56505,\"start\":56495},{\"end\":56523,\"start\":56505},{\"end\":56781,\"start\":56771},{\"end\":56802,\"start\":56781},{\"end\":56816,\"start\":56802},{\"end\":56829,\"start\":56816},{\"end\":56841,\"start\":56829},{\"end\":56854,\"start\":56841},{\"end\":56870,\"start\":56854},{\"end\":56877,\"start\":56870},{\"end\":57229,\"start\":57215},{\"end\":57480,\"start\":57468},{\"end\":57492,\"start\":57480},{\"end\":57695,\"start\":57687},{\"end\":57707,\"start\":57695},{\"end\":57719,\"start\":57707},{\"end\":57733,\"start\":57719},{\"end\":57741,\"start\":57733},{\"end\":57749,\"start\":57741},{\"end\":57758,\"start\":57749},{\"end\":57766,\"start\":57758},{\"end\":58014,\"start\":58004},{\"end\":58028,\"start\":58014},{\"end\":58035,\"start\":58028},{\"end\":58049,\"start\":58035},{\"end\":58056,\"start\":58049},{\"end\":58069,\"start\":58056},{\"end\":58280,\"start\":58269},{\"end\":58296,\"start\":58280},{\"end\":58308,\"start\":58296},{\"end\":58317,\"start\":58308},{\"end\":58328,\"start\":58317},{\"end\":58342,\"start\":58328},{\"end\":58359,\"start\":58342},{\"end\":58376,\"start\":58359}]", "bib_venue": "[{\"end\":39423,\"start\":39357},{\"end\":39691,\"start\":39642},{\"end\":40331,\"start\":40235},{\"end\":40969,\"start\":40846},{\"end\":41680,\"start\":41601},{\"end\":42013,\"start\":42005},{\"end\":42278,\"start\":42273},{\"end\":42626,\"start\":42623},{\"end\":42979,\"start\":42871},{\"end\":43349,\"start\":43300},{\"end\":43592,\"start\":43581},{\"end\":44036,\"start\":43925},{\"end\":44740,\"start\":44629},{\"end\":45255,\"start\":45247},{\"end\":45473,\"start\":45466},{\"end\":45630,\"start\":45626},{\"end\":45853,\"start\":45849},{\"end\":46149,\"start\":46140},{\"end\":46480,\"start\":46460},{\"end\":46909,\"start\":46813},{\"end\":47293,\"start\":47222},{\"end\":47613,\"start\":47550},{\"end\":47966,\"start\":47937},{\"end\":48269,\"start\":48150},{\"end\":48831,\"start\":48800},{\"end\":49380,\"start\":49335},{\"end\":49804,\"start\":49749},{\"end\":50058,\"start\":49983},{\"end\":50360,\"start\":50321},{\"end\":50612,\"start\":50522},{\"end\":51082,\"start\":50996},{\"end\":51914,\"start\":51827},{\"end\":52508,\"start\":52409},{\"end\":52894,\"start\":52840},{\"end\":53301,\"start\":53237},{\"end\":53637,\"start\":53628},{\"end\":53882,\"start\":53857},{\"end\":54146,\"start\":54029},{\"end\":54602,\"start\":54541},{\"end\":54924,\"start\":54873},{\"end\":55396,\"start\":55298},{\"end\":55866,\"start\":55862},{\"end\":56047,\"start\":56006},{\"end\":56527,\"start\":56523},{\"end\":56769,\"start\":56694},{\"end\":57245,\"start\":57229},{\"end\":57496,\"start\":57492},{\"end\":57771,\"start\":57766},{\"end\":58098,\"start\":58069},{\"end\":39476,\"start\":39425},{\"end\":40414,\"start\":40333},{\"end\":41098,\"start\":40971},{\"end\":44134,\"start\":44038},{\"end\":44838,\"start\":44742},{\"end\":46992,\"start\":46911},{\"end\":48849,\"start\":48833},{\"end\":51222,\"start\":51132},{\"end\":52019,\"start\":51916},{\"end\":55481,\"start\":55398}]"}}}, "year": 2023, "month": 12, "day": 17}