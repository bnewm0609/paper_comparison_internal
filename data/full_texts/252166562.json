{"id": 252166562, "updated": "2023-02-01 14:27:05.126", "metadata": {"title": "A Federated Learning Paradigm for Heart Sound Classification", "authors": "[{\"first\":\"Wanyong\",\"last\":\"Qiu\",\"middle\":[]},{\"first\":\"Kun\",\"last\":\"Qian\",\"middle\":[]},{\"first\":\"Zhihua\",\"last\":\"Wang\",\"middle\":[]},{\"first\":\"Yi\",\"last\":\"Chang\",\"middle\":[]},{\"first\":\"Zhihao\",\"last\":\"Bao\",\"middle\":[]},{\"first\":\"Bin\",\"last\":\"Hu\",\"middle\":[]},{\"first\":\"Bj\u00f6rn\",\"last\":\"Schuller\",\"middle\":[\"W.\"]},{\"first\":\"Yoshiharu\",\"last\":\"Yamamoto\",\"middle\":[]}]", "venue": "2022 44th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)", "journal": "2022 44th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)", "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "Cardiovascular diseases (CVDs) have been ranked as the leading cause for deaths. The early diagnosis of CVDs is a crucial task in the medical practice. A plethora of efforts were given to the automated auscultation of heart sound, which leverages the power of computer audition to develop a cheap, non-invasive method that can be used at any time and anywhere for measuring the status of the heart. Nevertheless, previous works ignore an important factor, namely, the privacy of the user data. On the one hand, learnt models are always hungry for bigger data. On the other hand, it can be difficult to protect personal private information when collecting such large amount of data. In this dilemma, we propose a federated learning (FL) framework for the heart sound classification task. To the best of our knowledge, this is the first time to introduce FL to this field. We conducted multiple experiments, analysed the impact of data distribution across collaborative institutions on model quality and learning patterns, and verified the feasibility and effectiveness of FL based on real data. Non- independent identically distributed (Non-IID) data and model quality can be effectively improved by adding a strategy of globally sharing data.", "fields_of_study": "[\"Medicine\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": "36086612", "pubmedcentral": null, "dblp": "conf/embc/QiuQWCBHSY22", "doi": "10.1109/embc48229.2022.9871319"}}, "content": {"source": {"pdf_hash": "d747697095bf36bfb29f08ce58a9e4c51f16ff7e", "pdf_src": "IEEE", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "17125d8f0f7d5d7121c7a83478c80714b08aba71", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/d747697095bf36bfb29f08ce58a9e4c51f16ff7e.txt", "contents": "\nA Federated Learning Paradigm for Heart Sound Classification\n\n\nWanyong Qiu \nKun Qian \nSenior Member, IEEEZhihua Wang \nYi Chang \nZhihao Bao \nBin Hu \nSenior Member, IEEEBj\u00f6rn W Schuller \nFellow, IEEEYoshiharu Yamamoto \nA Federated Learning Paradigm for Heart Sound Classification\n10.1109/EMBC48229.2022.9871319\nCardiovascular diseases (CVDs) have been ranked as the leading cause for deaths. The early diagnosis of CVDs is a crucial task in the medical practice. A plethora of efforts were given to the automated auscultation of heart sound, which leverages the power of computer audition to develop a cheap, non-invasive method that can be used at any time and anywhere for measuring the status of the heart. Nevertheless, previous works ignore an important factor, namely, the privacy of the user data. On the one hand, learnt models are always hungry for bigger data. On the other hand, it can be difficult to protect personal private information when collecting such large amount of data. In this dilemma, we propose a federated learning (FL) framework for the heart sound classification task. To the best of our knowledge, this is the first time to introduce FL to this field. We conducted multiple experiments, analysed the impact of data distribution across collaborative institutions on model quality and learning patterns, and verified the feasibility and effectiveness of FL based on real data. Non-independent identically distributed (Non-IID) data and model quality can be effectively improved by adding a strategy of globally sharing data.\n\nI. INTRODUCTION\n\nIn the U.S. alone, more than 30 % (equal to $ 9 billion) of preventable hospitalisations are due to cardiovascular diseases (CVDs) [1]. AI auscultation-assisted diagnosis (noninvasive) needs to be developed to provide fast and effective pre-screen diagnosis and abnormal warning for patients. Existing healthcare data sits in data silos and machine learning (ML) cannot fully function. To address this issue, federated learning (FL) is expected to realise its potential and transition from research to clinical practice.\n\nHealthcare data cannot be shared, considering patient privacy and related laws and regulations. As a result, data resides in various institutions forming data silos, such as hospitals, home devices, and smartphones. FL retains the ownership of data among institutions and conducts collaborative modelling, which can effectively solve data silos and protect privacy. Healthcare data such as medical records and disease symptoms are highly sensitive and tightly managed, and the centralised collection of clinical data from isolated medical centres and hospitals is a challenge. FL can solve this problem [2]- [4]. We apply FL to an island system in which each data island (e. g., a medical institution) communicates with a central server, but does not share anything between them.\n\nHealthcare data is usually typical non-independent identically distributed (Non-IID) data and distributed in various institutions collected by heterogeneous devices, which is in line with the FL scenario. Furthermore, in a large number of clinical studies [5]- [10], the focus is not on prediction, but on correlation analysis and hypothesis testing to understand the associations between different factors. The advantages of FL have recently been demonstrated in several practical applications, including medical image diagnosis [7], [9], prediction of disease risk factors [1], [10], and personalised medicine [8], which are particularly important in medical data applications. Therefore, the application of FL in healthcare is an urgent research area. FL-based assisted diagnostic classification tasks allow data maintainers to collaborate on modelling without sharing any private data. Our study builds on the work of FederatedAveraging (FedAvg) [2] using real heart sound data to build FedAvg-MLP (multilayer perceptron) and FedAvg-CNN (convolutional neural network) models.\n\nThe main contributions of this work can be summarised as follows:\n\n1) The feasibility of a multi-institutional heart sound database for FL is implemented and evaluated; 2) aspects of the algorithmic models under centralised training and FL are compared; 3) the effectiveness of FL with Non-IID heart sound data is verified.\n\n\nII. FL FOR HEART SOUND\n\nIn this section, we introduce the architecture of FL applied to heart sound analysis, and then describe the database and data preparation. Finally, the FL model and evaluation metrics are presented.\n\n\nA. Architecture\n\nMedical institutions are currently facing two important clinical realities: On the one hand, studies have shown that patients with CVDs, especially those with heart failure, are chronically accompanied by mental health such as anxiety and depression. On the other hand, issues such as data decentralisation and privacy protection urgently need to be resolved. These problems motivate us to explore the potential and value of FL in heart sound analysis.\n\nAs opposed to ECG (Electrocardiograph), which describes only the physiological fluctuations of the heart, PCG (Phonocardiogram) can distinguish between different pathological cases [11]. As shown in Fig. 1, several medical institutions collaborate in modelling through horizontal FL without sharing any private data. Due to the limitation of the database, this study focuses on the analysis of heart sound abnormality detection under FL, which contains three main parts: 1) The PCG signal was segmented into basic heart sound segments; 2) the one-dimensional waveform is transformed into a twodimensional spectrogram using continuous wavelet transform (cwt); 3) the performance of FL is validated and evaluated on real heart sound data.  \n\n\nB. Materials and Methods\n\n\n1) Database:\n\nThe heart sound data from the Phys-ioNet/CinC Challenge 2016 [12]. The data consists of six independent databases that are non-independent identically distributed (Non-IID).\n\nData Heterogeneity: The data consisted of six independent heart sound databases (D A -D F ), collected by different research teams in seven countries [12]. And these records were collected using heterogeneous equipment both clinically and non-clinically (e. g, home visits). The length of the records ranges from a few seconds to a few minutes.\n\nSystem Heterogeneity: System heterogeneity in FL environment is mainly manifested in the difference of communication and computing capability of the devices at each institution.\n\nAs shown in Table I, Non-IID heart sound data is mainly reflected in label distribution skew and quantity skew. The datasets (D A -D F ) contains 3 240 records from 764 subjects/patients, all records are divided into two categories according to expert labels: Normal and Abnormal. Normal records are from healthy subjects, and abnormal records are from patients with typical heart valve defects and coronary heart disease. 2) Image Representations: Basic heart sounds (S1, systolic, S2, diastolic) were analysed according to PCG signals.\n\nReferring to the work of [13], instead of using all the information of a record for experimental analysis, we chose to process and analyse 5-second heart sound segments. The reasons are as follows: 1) The heart sound segment contains the complete basic heart sound; 2) abnormal heart sounds can be fully judged within 5 seconds; 3) overfitting can be reduced.\n\nAccording to previous work [14], wavelet analysis bears great potential to present the differences in the timefrequency characteristics of normal and abnormal heart sounds. In this work, we implement the continuous wavelet transform (cwt) sound-image transformation in Matlab. The sampling frequency is 2 kHz. The wavelet base function is cga8, the image generation function is imagesc, and the wavelet coefficient value of the heart sound is obtained by the cwt function. The axis and edge markers are removed by the imwrite function. Fig. 2 shows the cwt spectrograms of an abnormal heart sound sample (f0027.wav) and a normal heart sound sample (f0072.wav) from the D F database. 3) FL Algorithm Model: FL can be divided into two types: Cross-device and Cross-silo. Cross-device is mainly oriented towards IoT devices, (e. g., cell phones). In contrast, the horizontal FL in this paper consists of a server and several clients (e. g., medical institutions), which belong to the Cross-silo category. Therefore, it can be assumed that there is no communication problem, and only the differences in data distribution among institutions need to be addressed.\n\nBased on the algorithm of FedAvg [2], we adopt the work of [15] to reproduce the FedAvg-MLP, FedAvg-CNN 1 , and FedAvg-CNN 2 algorithm models for heart sound data. The MLP contains one hidden layer and one dropout optimisation term. CNN 1 performs a dropout term after two convolutional layers, and finally adds two fully connected layers. CNN 2 adds a pooling layer between two convolutional layers, and finally adds three fully connected layers. The specific process of FedAvg in this work is shown in Fig. 3. Server-side Initialisation: The server-side distribution initialisation model uses global shared data and distributes randomised portions of the shared data.\n\n\nPre-processor\n\nLocal Model Update: Local institutions combine private data and partial global shared data for model update.\n\nGlobal Model Aggregation: The server receives model updates from each institution and then updates the global model using a weighted average. Iteration: The above two processes are iterated for the maximum round.\n\n\n4) Evaluation Metrics:\n\nThe evaluation method was originally proposed by a challenge in the field [12] and was defined as the average of sensitivity (Se) and specificity (Sp).\nScore = Se + Sp 2 (1) Sensitivity, Se = T P T P + FN (2) Speci f icity, Sp = T N T N + FP ,(3)\nwhere TP represents the sample volume of true positive abnormal heart sounds, FN represents the sample volume of false negative abnormal heart sounds, TN represents the sample volume of true negative normal heart sounds, and FP represents the sample volume of false negative normal heart sounds.\n\n\nC. Experiments and Results\n\n\n1) Experimental Design:\n\nThe ultimate goal of FL is to obtain a robust global model on the server side, so validation and testing are performed on the server side. Centralised Environment: Considers the skewed label distribution and quantity for each of the Non-IID heart sound databases, and helps avoid a small sample size for the validation and test sets. We divide the training set as a merged set (D C , D D , D E , D F ), the validation set as D A , and the test set as D B . Then, the MLP and two CNN models are trained separately. Federated Environment: To examine the difference in model performance between IID and Non-IID data, we set up a control group experiment (1)(2)(3). Experiment 1. For the IID data setup in FL, we merge the datasets (D C , D D , D E , D F ) into the same distribution and evenly distribute the samples to four institutions. Each institution owned 563 training samples: the validation set as D A , and the test set as D B . Experiment 2. To compare the differences in FL performance between IID data and Non-IID data for the same number of institutions. We set up 4 collaborative training institutions (i. e., 4 medical institutions D C , D D , D E , D F ). The validation set is given as D A and the test set as D B . Experiment 3. As ownership of the data remains in the institutions, we improve the strategy on the server side. Following the work of [16], we centralise a globally shared dataset D(D D ) that satisfies the uniform distribution of classes on the server side. As shown in Fig. 3, the warmup model trained by D and the random part D i of D are distributed to each institution during the initialisation phase of FedAvg. The division of the data is measured by two parameters: \u03b1 = ||D i || ||D|| x100 %, and \u03b2 = ||D|| || D|| x100 %, where D represents the amount of data from the institution.\n\n2) Hyperparameters: For comparison with FL, the best performing CNN 2 model in centralised training was chosen as the benchmark. FedAvg performed 100 rounds of training with MLP, CNN 1 , and CNN 2 . We modified the relevant hyperparameters of the learning algorithm to consider the Non-IID data model. Key parameters of the training are: We set the hidden dimension of the MLP (dim hidden = 200), the input image size as 28x28x3 for CNN 1 , 32x32x3 for CNN 2 , and the dropout optimisation term (P = 0.5). We further set the number of local epochs (E = 5) and batch size (B = 64) while using the activation function ReLU, learning rate (L = 0.01), and SGD momentum (m = 0.5). In addition, the number of filters (num f ilters = 32) and the kernel size (5x5) of the convolutional network are set.\n\n3) Results: Federated vs data-centralised training Due to the limitation of database sample volume, simple neural networks are used for FL. Although the accuracy of each model is poor under centralised training, the FL environment is effective for models to avoid overfitting and keep performance. Despite the large variation in the Non-IID heart sound database across institutions, FedAvg still achieved acceptable classification accuracy, as shown in Table II. This indicates that the unbalanced number of iterations across institutions can be efficiently handled by the FedAvg algorithm. In addition, although FedAvg is robust to unbalanced and Non-IID data, the accuracy of Experiment 2 is considerably lower than that of Experiment 1. We found as reason in the work of [16] that such precision reduction can be explained by weight divergence, which can be quantified by the earth movers distance (EMD) between the distribution over classes and the quantity distribution on each institution.  Globally shared data In experiment 3, we followed the scheme of [16] and selected the parameters \u03b2 = 10 % and \u03b1 = 50 %. The experimental results show that FedAvg-CNN 2 can reach 65.4 % accuracy in testing, while the accuracy is only about 62.0 % without a data sharing strategy. In contrast, FedAvg-CNN 2 has a higher sensitivity (59.2 %) and specificity (65.9 %), and the model performance is better as shown in Table  III. This process is executed only once during server-side initialisation, hence, there is no communication overhead. In addition, instead of random weights during the FedAvg initialisation, the global sharing strategy reduces the EMD of the institution and therefore improves the test accuracy, while D is a separate database with no privacy implications.\n\n\nIII. DISCUSSION\n\nFL has obvious privacy advantages over centralised training. Global computing involves the participation of multiple institutions, the ownership of data is retained in each institution and local computing is performed, and only updated model parameters are allowed to be shared with the server. The principle of data minimisation is embodied in the model update part, and the updates provided by each institution only need to be temporarily saved by the receiving server until the aggregation can be performed. In addition, it is crucial to optimise the hyperparameters of FedAvg, -especially the number of local epochs plays an important role in the convergence of the model.\n\n\nIV. CONCLUSION AND FUTURE WORK\n\nWe applied FL to real-world healthcare data and evaluated the first FL system for a multi-institutional heart sound database. We validated the potential of FL in terms of performance and data protection for a real heart sound database, which is essential for processing sensitive healthcare data. Note that privacy is not a default guarantee in any FL setting, and secure aggregation of communication parameters between servers and institutions is our work plan. Importantly, the limited number of participating institutions and the lack of data volumes are currently the biggest contributing factors. We are working on the establishment of a more powerful heart sound database based on the cooperation of several medical institutions, such as the HSS-The Heart Sounds Shenzhen Corpus [17] which is part of our current work.\n\nFig. 1 .\n1A horizontal federated learning paradigm for heart sound analysis.\n\nFig. 2 .\n2The scalogram images are extracted from the abnormal / normal heart sounds using cwt.\n\nFig. 4 .\n4Training error variation for Fed-CNN 1 and Fed-CNN 2 .\n\nTABLE I\nIDESCRIPTION OF PHYSIONET HEART SOUND DATABASE.MIT: The Massachusetts Institute of Technology heart sounds database; AAD: Aalborg University heart sounds database; AUTH: The Aristotle University of Thessaloniki heart sounds database; UHA: The University of Haute Alsace heart sounds database; DLUT: The Dalian University of Technology heart sounds database; SUA: The Shiraz University adult heart sounds database.Database \nRecordings \nProportion of recordings(%) Durations(s) \n\nAbnormal Normal \nMinimum \n\nD A (MIT) \n409 (12.62) \n28.61 \n71.39 \n9.27 \nD B (AAD) \n490 (15.12) \n21.22 \n78.77 \n5.31 \nD C (AUTH) 31 (0.95) \n77.74 \n22.58 \n9.65 \nD D (UHA) \n55 (1.69) \n50.91 \n49.09 \n6.61 \nD E (DLUT) \n2 141 (66.08) 5.51 \n91.45 \n8.06 \nD F (SUA) \n114 (3.52) \n29.82 \n70.17 \n29.38 \nTotal \n3 240 \n20.52 \n79.47 \n\n\n\nTABLE II TEST\nIIACCURACY OF FEDAVG FOR IID DATA AND NON-IID DATA UNDER CENTRALISED TRAINING AND FEDERATED LEARNING (%). Avg-loss. of IID Acc. of IID Acc. of Non-IIDModel \nNon-shared Shared \n\nMLP \n0.0117 \n57.9 \n-\n-\nCNN 1 \n0.0114 \n68.1 \n-\n-\nCNN 2 \n0.1180 \n76.2 \n-\n-\nFed-MLP \n0.2753 \n52.6 \n45.3 \n47.6 \nFed-CNN 1 \n0.1629 \n66.9 \n57.8 \n62.1 \nFed-CNN 2 \n0.1215 \n72.1 \n62.0 \n65.4 \n\n\n\nTABLE III\nIIISENSITIVITY (Se), SPECIFICITY (Sp), AND FINAL SCORE (Score) ARE USED AS QUANTITATIVE METRICS FOR THE MODEL.Model \nSe \nSp \nScore \n\nFed-MLP \n47.1 56.2 51.6 \nFed-CNN 1 \n55.9 62.2 59.1 \nFed-CNN 2 \n59.2 65.9 \n62.5 \n\n\n\nFederated learning of predictive models from federated electronic health records. T S Brisimi, International journal of medical informatics. 112T. S. Brisimi et al., \"Federated learning of predictive models from federated electronic health records,\" International journal of medical informatics, vol. 112, pp. 59-67, 2018.\n\nCommunication-efficient learning of deep networks from decentralized data. B Mcmahan, Artificial intelligence and statistics. B. McMahan et al., \"Communication-efficient learning of deep net- works from decentralized data,\" in Artificial intelligence and statistics. PMLR, 2017, pp. 1273-1282.\n\nDecentralized federated learning for electronic health records. S Lu, Y Zhang, Y Wang, 2020 54th Annual Conference on Information Sciences and Systems (CISS). IEEES. Lu, Y. Zhang, and Y. Wang, \"Decentralized federated learning for electronic health records,\" in 2020 54th Annual Conference on Information Sciences and Systems (CISS). IEEE, 2020, pp. 1-5.\n\nFederated machine learning: Concept and applications. Q Yang, ACM Transactions on Intelligent Systems and Technology (TIST). 102Q. Yang et al., \"Federated machine learning: Concept and appli- cations,\" ACM Transactions on Intelligent Systems and Technology (TIST), vol. 10, no. 2, pp. 1-19, 2019.\n\nPrivacy-first health research with federated learning. J B Hernandez, medRxivJ. B. Hernandez et al., \"Privacy-first health research with federated learning,\" medRxiv, 2020.\n\nFederated learning in medicine: facilitating multiinstitutional collaborations without sharing patient data. M J Sheller, Scientific reports. 101M. J. Sheller et al., \"Federated learning in medicine: facilitating multi- institutional collaborations without sharing patient data,\" Scientific reports, vol. 10, no. 1, pp. 1-12, 2020.\n\nPrivacy-preserving federated brain tumour segmentation. W Li, International workshop on machine learning in medical imaging. SpringerW. Li et al., \"Privacy-preserving federated brain tumour segmen- tation,\" in International workshop on machine learning in medical imaging. Springer, 2019, pp. 133-141.\n\nRobust aggregation for adaptive privacy preserving federated learning in healthcare. M Grama, arXiv:2009.08294arXiv preprintM. Grama et al., \"Robust aggregation for adaptive privacy preserving federated learning in healthcare,\" arXiv preprint arXiv:2009.08294, 2020.\n\nFederated learning in distributed medical databases: Meta-analysis of large-scale subcortical brain data. S Silva, 2019 IEEE 16th international symposium on biomedical imaging. IEEES. Silva et al., \"Federated learning in distributed medical databases: Meta-analysis of large-scale subcortical brain data,\" in 2019 IEEE 16th international symposium on biomedical imaging (ISBI 2019). IEEE, 2019, pp. 270-274.\n\nFederated learning of electronic health records improves mortality prediction in patients hospitalized with covid-19. A Vaid, medRxivA. Vaid et al., \"Federated learning of electronic health records im- proves mortality prediction in patients hospitalized with covid-19,\" medRxiv, 2020.\n\nDesigning ecg monitoring healthcare system with federated transfer learning and explainable ai. A Raza, Knowledge-Based Systems. 236107763A. Raza et al., \"Designing ecg monitoring healthcare system with federated transfer learning and explainable ai,\" Knowledge-Based Systems, vol. 236, p. 107763, 2022.\n\nClassification of normal/abnormal heart sound recordings: The physionet/computing in cardiology challenge 2016. G D Clifford, 2016 Computing in cardiology conference (CinC). IEEEG. D. Clifford et al., \"Classification of normal/abnormal heart sound recordings: The physionet/computing in cardiology challenge 2016,\" in 2016 Computing in cardiology conference (CinC). IEEE, 2016, pp. 609-612.\n\nNormal/abnormal heart sound recordings classification using convolutional neural network. T Nilanon, IEEEin 2016 computing in cardiology conference (CinCT. Nilanon et al., \"Normal/abnormal heart sound recordings classi- fication using convolutional neural network,\" in 2016 computing in cardiology conference (CinC). IEEE, 2016, pp. 585-588.\n\nAbnormal heart sounds detected from short duration unsegmented phonocardiograms by wavelet entropy. P Langley, A Murray, Cardiology Conference (CinC). IEEEP. Langley and A. Murray, \"Abnormal heart sounds detected from short duration unsegmented phonocardiograms by wavelet entropy,\" in 2016 Computing in Cardiology Conference (CinC). IEEE, 2016, pp. 545-548.\n\nA PyTorch Implementation of Federated Learning. Zenodo, Mar. S Ji, 10.5281/zenodo.4321561S. Ji, A PyTorch Implementation of Federated Learning. Zenodo, Mar. 2018. [Online]. Available: https://doi.org/10.5281/zenodo.4321561\n\nFederated learning with non-iid data. Y Zhao, arXiv:1806.00582arXiv preprintY. Zhao et al., \"Federated learning with non-iid data,\" arXiv preprint arXiv:1806.00582, 2018.\n\nMachine listening for heart status monitoring: Introducing and benchmarking HSS-The Heart Sounds Shenzhen Corpus. F Dong, IEEE Journal of Biomedical and Health Informatics. 247F. Dong et al., \"Machine listening for heart status monitoring: Introducing and benchmarking HSS-The Heart Sounds Shenzhen Corpus,\" IEEE Journal of Biomedical and Health Informatics, vol. 24, no. 7, pp. 2082-2092, 2020.\n", "annotations": {"author": "[{\"end\":76,\"start\":64},{\"end\":86,\"start\":77},{\"end\":118,\"start\":87},{\"end\":128,\"start\":119},{\"end\":140,\"start\":129},{\"end\":148,\"start\":141},{\"end\":185,\"start\":149},{\"end\":217,\"start\":186}]", "publisher": null, "author_last_name": "[{\"end\":75,\"start\":72},{\"end\":85,\"start\":81},{\"end\":117,\"start\":113},{\"end\":127,\"start\":122},{\"end\":139,\"start\":136},{\"end\":147,\"start\":145},{\"end\":184,\"start\":176},{\"end\":216,\"start\":208}]", "author_first_name": "[{\"end\":71,\"start\":64},{\"end\":80,\"start\":77},{\"end\":112,\"start\":106},{\"end\":121,\"start\":119},{\"end\":135,\"start\":129},{\"end\":144,\"start\":141},{\"end\":173,\"start\":168},{\"end\":175,\"start\":174},{\"end\":207,\"start\":198}]", "author_affiliation": null, "title": "[{\"end\":61,\"start\":1},{\"end\":278,\"start\":218}]", "venue": null, "abstract": "[{\"end\":1551,\"start\":310}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":1704,\"start\":1701},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2698,\"start\":2695},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2703,\"start\":2700},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":3132,\"start\":3129},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3138,\"start\":3134},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":3406,\"start\":3403},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":3411,\"start\":3408},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":3451,\"start\":3448},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3457,\"start\":3453},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":3488,\"start\":3485},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3826,\"start\":3823},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":5161,\"start\":5157},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":5823,\"start\":5819},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":6087,\"start\":6083},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":7026,\"start\":7022},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":7389,\"start\":7385},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":8553,\"start\":8550},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":8580,\"start\":8576},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":9631,\"start\":9627},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":10806,\"start\":10803},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":10809,\"start\":10806},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":10812,\"start\":10809},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":11520,\"start\":11516},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":13546,\"start\":13542},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":13833,\"start\":13829},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":16061,\"start\":16057}]", "figure": "[{\"attributes\":{\"id\":\"fig_1\"},\"end\":16174,\"start\":16097},{\"attributes\":{\"id\":\"fig_2\"},\"end\":16271,\"start\":16175},{\"attributes\":{\"id\":\"fig_3\"},\"end\":16337,\"start\":16272},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":17142,\"start\":16338},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":17518,\"start\":17143},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":17744,\"start\":17519}]", "paragraph": "[{\"end\":2090,\"start\":1570},{\"end\":2871,\"start\":2092},{\"end\":3952,\"start\":2873},{\"end\":4019,\"start\":3954},{\"end\":4277,\"start\":4021},{\"end\":4502,\"start\":4304},{\"end\":4974,\"start\":4522},{\"end\":5714,\"start\":4976},{\"end\":5931,\"start\":5758},{\"end\":6277,\"start\":5933},{\"end\":6456,\"start\":6279},{\"end\":6995,\"start\":6458},{\"end\":7356,\"start\":6997},{\"end\":8515,\"start\":7358},{\"end\":9186,\"start\":8517},{\"end\":9312,\"start\":9204},{\"end\":9526,\"start\":9314},{\"end\":9704,\"start\":9553},{\"end\":10095,\"start\":9800},{\"end\":11970,\"start\":10152},{\"end\":12766,\"start\":11972},{\"end\":14541,\"start\":12768},{\"end\":15237,\"start\":14561},{\"end\":16096,\"start\":15272}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":9799,\"start\":9705}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":6477,\"start\":6470},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":13229,\"start\":13221},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":14188,\"start\":14178}]", "section_header": "[{\"end\":1568,\"start\":1553},{\"end\":4302,\"start\":4280},{\"end\":4520,\"start\":4505},{\"end\":5741,\"start\":5717},{\"end\":5756,\"start\":5744},{\"end\":9202,\"start\":9189},{\"end\":9551,\"start\":9529},{\"end\":10124,\"start\":10098},{\"end\":10150,\"start\":10127},{\"end\":14559,\"start\":14544},{\"end\":15270,\"start\":15240},{\"end\":16106,\"start\":16098},{\"end\":16184,\"start\":16176},{\"end\":16281,\"start\":16273},{\"end\":16346,\"start\":16339},{\"end\":17157,\"start\":17144},{\"end\":17529,\"start\":17520}]", "table": "[{\"end\":17142,\"start\":16760},{\"end\":17518,\"start\":17308},{\"end\":17744,\"start\":17640}]", "figure_caption": "[{\"end\":16174,\"start\":16108},{\"end\":16271,\"start\":16186},{\"end\":16337,\"start\":16283},{\"end\":16760,\"start\":16348},{\"end\":17308,\"start\":17160},{\"end\":17640,\"start\":17533}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":5181,\"start\":5175},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":7900,\"start\":7894},{\"end\":9027,\"start\":9021},{\"end\":11659,\"start\":11653}]", "bib_author_first_name": "[{\"end\":17829,\"start\":17828},{\"end\":17831,\"start\":17830},{\"end\":18146,\"start\":18145},{\"end\":18430,\"start\":18429},{\"end\":18436,\"start\":18435},{\"end\":18445,\"start\":18444},{\"end\":18776,\"start\":18775},{\"end\":19075,\"start\":19074},{\"end\":19077,\"start\":19076},{\"end\":19303,\"start\":19302},{\"end\":19305,\"start\":19304},{\"end\":19583,\"start\":19582},{\"end\":19915,\"start\":19914},{\"end\":20204,\"start\":20203},{\"end\":20625,\"start\":20624},{\"end\":20890,\"start\":20889},{\"end\":21211,\"start\":21210},{\"end\":21213,\"start\":21212},{\"end\":21581,\"start\":21580},{\"end\":21934,\"start\":21933},{\"end\":21945,\"start\":21944},{\"end\":22255,\"start\":22254},{\"end\":22456,\"start\":22455},{\"end\":22704,\"start\":22703}]", "bib_author_last_name": "[{\"end\":17839,\"start\":17832},{\"end\":18154,\"start\":18147},{\"end\":18433,\"start\":18431},{\"end\":18442,\"start\":18437},{\"end\":18450,\"start\":18446},{\"end\":18781,\"start\":18777},{\"end\":19087,\"start\":19078},{\"end\":19313,\"start\":19306},{\"end\":19586,\"start\":19584},{\"end\":19921,\"start\":19916},{\"end\":20210,\"start\":20205},{\"end\":20630,\"start\":20626},{\"end\":20895,\"start\":20891},{\"end\":21222,\"start\":21214},{\"end\":21589,\"start\":21582},{\"end\":21942,\"start\":21935},{\"end\":21952,\"start\":21946},{\"end\":22258,\"start\":22256},{\"end\":22461,\"start\":22457},{\"end\":22709,\"start\":22705}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":3679574},\"end\":18068,\"start\":17746},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":14955348},\"end\":18363,\"start\":18070},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":218563867},\"end\":18719,\"start\":18365},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":219878182},\"end\":19017,\"start\":18721},{\"attributes\":{\"id\":\"b4\"},\"end\":19191,\"start\":19019},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":220812287},\"end\":19524,\"start\":19193},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":203627027},\"end\":19827,\"start\":19526},{\"attributes\":{\"doi\":\"arXiv:2009.08294\",\"id\":\"b7\"},\"end\":20095,\"start\":19829},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":53043887},\"end\":20504,\"start\":20097},{\"attributes\":{\"id\":\"b9\"},\"end\":20791,\"start\":20506},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":235195935},\"end\":21096,\"start\":20793},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":6405815},\"end\":21488,\"start\":21098},{\"attributes\":{\"id\":\"b12\"},\"end\":21831,\"start\":21490},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":15508702},\"end\":22191,\"start\":21833},{\"attributes\":{\"doi\":\"10.5281/zenodo.4321561\",\"id\":\"b14\"},\"end\":22415,\"start\":22193},{\"attributes\":{\"doi\":\"arXiv:1806.00582\",\"id\":\"b15\"},\"end\":22587,\"start\":22417},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":208298398},\"end\":22984,\"start\":22589}]", "bib_title": "[{\"end\":17826,\"start\":17746},{\"end\":18143,\"start\":18070},{\"end\":18427,\"start\":18365},{\"end\":18773,\"start\":18721},{\"end\":19300,\"start\":19193},{\"end\":19580,\"start\":19526},{\"end\":20201,\"start\":20097},{\"end\":20887,\"start\":20793},{\"end\":21208,\"start\":21098},{\"end\":21931,\"start\":21833},{\"end\":22701,\"start\":22589}]", "bib_author": "[{\"end\":17841,\"start\":17828},{\"end\":18156,\"start\":18145},{\"end\":18435,\"start\":18429},{\"end\":18444,\"start\":18435},{\"end\":18452,\"start\":18444},{\"end\":18783,\"start\":18775},{\"end\":19089,\"start\":19074},{\"end\":19315,\"start\":19302},{\"end\":19588,\"start\":19582},{\"end\":19923,\"start\":19914},{\"end\":20212,\"start\":20203},{\"end\":20632,\"start\":20624},{\"end\":20897,\"start\":20889},{\"end\":21224,\"start\":21210},{\"end\":21591,\"start\":21580},{\"end\":21944,\"start\":21933},{\"end\":21954,\"start\":21944},{\"end\":22260,\"start\":22254},{\"end\":22463,\"start\":22455},{\"end\":22711,\"start\":22703}]", "bib_venue": "[{\"end\":17885,\"start\":17841},{\"end\":18194,\"start\":18156},{\"end\":18522,\"start\":18452},{\"end\":18844,\"start\":18783},{\"end\":19072,\"start\":19019},{\"end\":19333,\"start\":19315},{\"end\":19649,\"start\":19588},{\"end\":19912,\"start\":19829},{\"end\":20272,\"start\":20212},{\"end\":20622,\"start\":20506},{\"end\":20920,\"start\":20897},{\"end\":21270,\"start\":21224},{\"end\":21578,\"start\":21490},{\"end\":21982,\"start\":21954},{\"end\":22252,\"start\":22193},{\"end\":22453,\"start\":22417},{\"end\":22760,\"start\":22711}]"}}}, "year": 2023, "month": 12, "day": 17}