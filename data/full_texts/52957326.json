{"id": 52957326, "updated": "2023-09-30 14:36:47.671", "metadata": {"title": "V3C - a Research Video Collection", "authors": "[{\"first\":\"Luca\",\"last\":\"Rossetto\",\"middle\":[]},{\"first\":\"Heiko\",\"last\":\"Schuldt\",\"middle\":[]},{\"first\":\"George\",\"last\":\"Awad\",\"middle\":[]},{\"first\":\"Asad\",\"last\":\"Butt\",\"middle\":[\"A.\"]}]", "venue": "MultiMedia Modeling", "journal": "MultiMedia Modeling", "publication_date": {"year": 2018, "month": 10, "day": 10}, "abstract": "With the widespread use of smartphones as recording devices and the massive growth in bandwidth, the number and volume of video collections has increased significantly in the last years. This poses novel challenges to the management of these large-scale video data and especially to the analysis of and retrieval from such video collections. At the same time, existing video datasets used for research and experimentation are either not large enough to represent current collections or do not reflect the properties of video commonly found on the Internet in terms of content, length, or resolution. In this paper, we introduce the Vimeo Creative Commons Collection, in short V3C, a collection of 28'450 videos (with overall length of about 3'800 hours) published under creative commons license on Vimeo. V3C comes with a shot segmentation for each video, together with the resulting keyframes in original as well as reduced resolution and additional metadata. It is intended to be used from 2019 at the International large-scale TREC Video Retrieval Evaluation campaign (TRECVid).", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "1810.04401", "mag": "2951385148", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/mmm/RossettoSAB19", "doi": "10.1007/978-3-030-05710-7_29"}}, "content": {"source": {"pdf_hash": "983f695c0ae44632182184f81579872f0353c6bc", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/1810.04401v2.pdf\"]", "oa_url_match": false, "oa_info": {"license": "CCBY", "open_access_url": "https://www.zora.uzh.ch/id/eprint/182788/1/V3C____a_Research_Video_Collection.pdf", "status": "GREEN"}}, "grobid": {"id": "dcdb42d66cb27363974cee440c86c1cfe4c3789a", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/983f695c0ae44632182184f81579872f0353c6bc.txt", "contents": "\nV3C -a Research Video Collection\n\n\nLuca Rossetto \nDatabases and Information Systems Research Group Department of Mathematics and Computer Science\nUniversity of Basel\nSwitzerland\n\nHeiko Schuldt \nDatabases and Information Systems Research Group Department of Mathematics and Computer Science\nUniversity of Basel\nSwitzerland\n\nGeorge Awad \nNational Institute of Standards and Technology Information Technology Laboratory Information Access Division Gaithersburg\nMDUSA\n\nAsad A Butt \nNational Institute of Standards and Technology Information Technology Laboratory Information Access Division Gaithersburg\nMDUSA\n\nV3C -a Research Video Collection\n\nWith the widespread use of smartphones as recording devices and the massive growth in bandwidth, the number and volume of video collections has increased significantly in the last years. This poses novel challenges to the management of these large-scale video data and especially to the analysis of and retrieval from such video collections. At the same time, existing video datasets used for research and experimentation are either not large enough to represent current collections or do not reflect the properties of video commonly found on the Internet in terms of content, length, or resolution. In this paper, we introduce the Vimeo Creative Commons Collection, in short V3C, a collection of 28'450 videos (with overall length of about 3'800 hours) published under creative commons license on Vimeo. V3C comes with a shot segmentation for each video, together with the resulting keyframes in original as well as reduced resolution and additional metadata. It is intended to be used from 2019 at the International largescale TREC Video Retrieval Evaluation campaign (TRECVid).\n\nIntroduction\n\nOver recent years, video has become a significant portion of the overall data which populates the web. This has been due to the fact that the production and distribution of video has shifted from a complex and costly endeavor to something accessible to everybody with a smart phone or similar device and a connection to the internet. This growth of content enabled new possibilities in various research areas which are able to make use of it. Despite the access to such large amounts of data, there remains a need for standardized datasets for computer vision and multimedia tasks. Multiple such datasets have been proposed over the years. A prominent example of a video dataset is the IACC [5] which has been used for several years now for international evaluation campaigns such as TRECVid [2]. Other examples of datasets in the video context include the YFCC100M [8] which, despite being sourced from the photo-sharing platform Flickr 3 , contains a considerable amount of video material, the Movie Memorability Database [4] which is comprised of memorable sequences from 100 Hollywood-quality movies or the YouTube-8M [1] dataset which in contrast, despite being sourced from YouTube 4 , does not contain the original videos themselves. The content of all of these collections does, however, differ substantially from the type of web video commonly found 'in the wild' [7].\n\nIn this paper, we present the Vimeo Creative Commons Collection or V3C for short. It is composed of 28'450 videos collected from the video sharing platform Vimeo 5 . Apart from the videos themselves, the collection includes meta and shot-segmentation data for each video, together with the resulting keyframes in original as well as reduced resolution. The objective of V3C is to eventually complement or even replace existing collections in real-world video retrieval evaluation campaigns and thus to tailor the latter more to the type of video that can be found on the Internet.\n\nThe remainder of this paper is structured as follows: Section 2 gives an overview of the process of how the collection was assembled and Section 3 introduces the collection itself, its structure and some of its properties. Finally, Section 4 concludes.\n\n\nCollection Process\n\nThe requirements for usable video sources from which to compile a collection were as follows:\n\n-The platform must be freely accessible.\n\n-It must host a large amount of diverse and contemporary video content.\n\n-At least a portion of the content must be published under a creative commons 6 license and can therefore be redistributed in such a collection.\n\nTwo candidates for such collections are Vimeo and YouTube. Vimeo was chosen over YouTube because while YouTube offers its users the possibility to publish videos under a creative commons attribution license which would allow the reuse and redistribution of the video material, YouTube's Terms of Service [9] explicitly forbid the download of any video on the platform for any reason other than playback in the context of a video stream.\n\nWe utilized the Vimeo categorization system for video collection. Videos are placed in 16 broad categories, which are further divided into subcategories. Videos in each category were examined to determine if they satisfied the 'real world' requirements for the collection. Four top level categories were included in the collection, while 3 were excluded. For the remaining 9 categories, only some subcategories were included. The following are the 4 categories completely included in the collection: 'Personal', 'Documentary', 'Sports' and 'Travel'.\n\nAn overview of the excluded categories can be seen in Figure 1. Categories that had very low visual diversity (such as 'Talks'), or did not represent real world scenarios were removed. Categories (or subcategories) with a lot of animation/graphics, or non standard content with little or no describable activity were excluded from the collection. Videos from the selected categories were then filtered by duration and license.\n\nThe obtained list of candidate videos was downloaded from Vimeo using an open-source video download utility 7 . The download was performed sequentially in order to not cause unnecessary load on the side of the platform. All downloaded videos were subsequently checked to ensure they could be properly decoded by a commonly used video decoding utility 8 .\n\nThe videos were segmented and analyzed using the open-source contentbased video retrieval engine Cineast [6]. Videos with a distribution of segment lengths which were sufficiently different from the mean were flagged for manual inspection as this indicated either very low or very high visual diversity as in the cases of either mostly static frames or very noisy videos. During this step, videos were also checked to ensure that the collection does not contain exact duplicates.\n\nOut of the remaining videos, three subsets with increasing size were randomly selected. Sequential numerical ids were assigned to the selected videos in such a way that the first id in the second part is one larger than the last id in the first part and so on, in order to facilitate situations in which multiple parts are to be used in conjunction.\n\n\nThe Vimeo Creative Commons Collection\n\nThe following provides an overview of the structure as well as various technical and semantic properties of the Vimeo Creative Commons Collection.\n\n\nCollection Structure\n\nThe collection consists of 28'450 videos with a duration between 3 and 60 minutes each and a total combined duration of slightly above 3'800 hours, divided into three partitions. Table 1 provides an overview of the three partitions. Similar to the IACC, the V3C also includes a master shot reference which segments every video into sequential non-overlapping parts, based on the visual content of the videos. For every one of these parts, a full resolution representative key-frame as well as a thumbnail image of reduced resolution is provided. Additionally, there are meta data files containing both technical as well as semantic information for every video which was also obtained from Vimeo.\n\nEvery video in the collection has been assigned a sequential numerical id. These ids are then used for all aspects of the collection. Figure 2 illustrates  the directory structure which is used to organize the different aspects of the collection. This structure is identical for all three partitions. The info directory contains one json-file per video which holds metadata obtained from Vimeo. This metadata contains both semantic information -such as video title, description and associated tags -as well as technical information including video duration, resolution, license and upload date. The msb directory contains for each video a file in tab-separated format which lists the temporal start and end-positions for every automatically detected segment in a video. The keyframes and thumbnails directories each contain a subdirectory per video which hold one representative \n\n\nStatistical Properties\n\nThe following presents an overview of the distribution of selected categories throughout the collection. The age distribution of the videos of the entire collection as determined by the upload date of the individual video is illustrated in Figure 3. It is shown in comparison to the distribution originally presented in [7] for a large sample of Vimeo in general. The trace representing the V3C is less clean than the one for the Vimeo dataset due to the large difference in number of data points. It can however still be seen that both traces have a similar overall shape, at least for the parts of the plot where there is data available for both. Other than the Vimeo dataset from [7], the collection of which was completed mid 2016, the V3C includes videos from as late as early 2018 which explains the difference in shape towards the right side of the plot.\n\nThe distribution of video duration and resolution is shown in Figures 4 and  5 respectively, again in comparison to the larger Vimeo distributions. It can be seen that wherever there were no additional restrictions, the properties of the V3C follow those of the overall Vimeo dataset rather closely. At least in terms of these three properties, the V3C can therefore be considered reasonably representative of the type of web video generally found on Vimeo.\n\nAn overview of the languages detected by the same method as employed in [7], based on the title and description of the videos can be seen in Table 2. It shows the top-10 languages for either the V3C or the dataset from [7]. The column labeled '?' represents the instances where language detection did not yield any result. It can be seen that for the videos, the titles and descriptions of which were distinct enough for language detection, the distribution within the V3C is similar to the Vimeo dataset. No language analysis based on the audio data of the videos has been performed yet. Table 3 shows the categories and the number of videos per collection part which have been assigned to a particular category on Vimeo. Every video can    be assigned to multiple categories, the numbers shown in the table do therefore not sum to the total number of videos. Despite the categories having a structure which implies a hierarchy, a video can be assigned to both a category and subcategory, but it does not have to. The large number of used categories shown in the table implies a wide range of content which can be found in the collection. \n\n\nPossible Uses\n\nDue to the large diversity of video content contained within the collection, it can be useful for video-related applications in multiple areas. The large number of different video resolutions -and to a lesser extent frame-rates -makes this dataset interesting for video transport and storage applications such as the development of novel encoding schemes, streaming mechanisms or error-correction techniques. Its large variety in visual content makes this dataset also interesting for various machine learning and computer vision applications.\n\nFinally, the collection has applications in the area of video analysis, retrieval and exploration. For example, we can imagine four possible application areas in the video retrieval space. First, video tagging or high-level feature detection where the goal is given a video segment or shot, the system should output all the relevant tags and visual concepts that are in this video. Such a task is very fundamental to any video search engine that tries to match users search queries with video dataset to retrieve the most relevant results. Second, ad-hoc video search where a system takes as input a user text query as a natural language sentence and returns the most relevant set of videos that satisfies the information need in the query. Such a task is also necessary for any search system that deals with real users where it has to understand the user query and intention before retrieving the set of results that matches the text query. Third, trying to find a video or a video segment which one believes to have seen but the name of which one does not recall is often called known item search. Queries are created based on some knowledge of the collection such that there is a high probability that there is only one video or video segment that satisfies the search. Fourth, the application of video captioning or description in recent years gained a lot of attention. Here the idea is how can a system describe a video segment in a textual form that contains all the important facets such as 'who', 'what', 'where', 'when' so essentially textual summary of the video. As the V3C collection includes a master shot boundary splitting a whole video into smaller shots, the video captioning task can be run on those small video shots as currently the state of the art can not handle longer videos and give a logical and human readable description for the whole video in textual form.\n\n\nAvailability\n\nWe are planning to launch and make available this collection at the 2019 TREC-Vid video retrieval benchmark where different research groups participate in one or more tracks. In addition, the collection will be shared at the Interactive Video Browser Showdown (VBS) [3] which collaborates with TRECVid organizing the Video Ad-hoc Search track. The collection will be available to the benchmark participants as well as the public for download. After the annual benchmark cycle is concluded, we will also provide the ground truth judgments and queries/topics for the tasks that used the V3C collection so that research groups can reuse the dataset in their local experiments and reproduce results.\n\n\nConclusions\n\nIn this paper, we introduced the Vimeo Creative Commons Collection (V3C). It is comprised of roughly 3'800 hours of creative commons video obtained from the web video platform Vimeo and is augmented with technical and semantic metadata as well as shot boundary information and accompanying keyframes. V3C is subdivided into three partitions with increasing length from roughly 1'000 hours up to 1'500 hours so that the collection can be used for at least three consecutive years in a video search benchmark with increasing complexity. Information on where to download the V3C collection and/or its partitions will be made available together with the publication of the video search benchmark challenges.\n\nFig. 1 .\n1Removed categories and subcategories are emphasized.\n\nFig. 2 .Fig. 3 .\n23Directory structure of the V3C Daily relative video uploads from the V3C and the Vimeo dataset\n\nFig. 4 .\n4Scatter plot showing the duration of videos from the V3C and the Vimeo dataset\n\nFig. 5 .\n5Distribution of video resolutions in the V3C\n\nTable 1 .\n1Overview of the partitions of the V3C frame per video segment in a PNG format. The keyframes are kept in the original video resolution while the thumbnails are downscaled to a width of 200 pixels. Finally the videos directory contains a subdirectory per video, each of which containing the video itself as well as the video description and a file with technical information describing the download process.Partition \nV3C1 \nV3C2 \nV3C3 \nTotal \nFile Size (videos) \n1.3TB \n1.6TB \n1.8TB \n4.8TB \nFile Size (total) \n2.4TB \n3.0TB \n3.3TB \n8.7TB \nNumber of Videos \n7'475 \n9'760 \n11'215 \n28'450 \n\nCombined \nVideo Duration \n\n1'000 hours, \n23 minutes, \n50 seconds \n\n1'300 hours, \n52 minutes, \n48 seconds \n\n1'500 hours, \n8 minutes, \n57 seconds \n\n3801 hours, \n25 minutes, \n35 seconds \n\nMean Video Duration \n8 minutes, \n2 seconds \n\n7 minutes, \n59 seconds \n\n8 minutes, \n1 seconds \n\n8 minutes, \n1 seconds \nNumber of Segments \n1'082'659 \n1'425'454 \n1'635'580 \n4'143'693 \n\n\nTable 2 .\n2Overview of the detected languages in the video title and description of the V3C in percent? \nen \nde \nfr \nit \nes \ncy \npl \nnl \npt \nko \nru \nVimeo 63.07 27.36 1.38 1.35 0.62 0.48 0.24 0.37 0.3 0.66 0.62 0.43 \nV3C \n69.87 24.5 1.36 1.11 0.47 0.41 0.36 0.32 0.26 0.26 \n0 \n0 \nV3C1 68.52 25.34 1.65 1.23 0.54 0.64 0.31 0.29 0.28 0.25 \n0 \n0 \nV3C2 70.83 23.85 1.21 1.11 0.44 0.33 0.33 0.35 0.22 0.19 \n0 \n0 \nV3C3 69.94 24.63 1.3 1.04 0.45 0.33 0.41 0.32 0.29 0.26 \n0 \n0 \n\n\nTable 3 :\n3Category assignment per video and collection partVimeo Category \nNumber of videos \nV3C1 V3C2 V3C3 \n/categories/art \n660 891 1'010 \n/categories/art/homesandliving/videos \n11 \n11 \n13 \n/categories/art/personaltechdesign/videos \n15 \n17 \n14 \n/categories/cameratechniques \n513 703 749 \n/categories/cameratechniques/drones/videos \n156 191 204 \n/categories/cameratechniques/macroandslomo/videos \n12 \n18 \n14 \n/categories/cameratechniques/timelapse/videos \n161 252 281 \n/categories/comedy \n252 315 388 \n/categories/comedy/comicnarrative/videos \n74 \n69 \n86 \n/categories/documentary \n1'396 1'787 2'086 \n/categories/documentary/artsandcraft/videos \n54 \n82 \n99 \n/categories/documentary/cultureandtech/videos \n78 124 117 \n/categories/documentary/nature/videos \n155 191 191 \n/categories/documentary/people/videos \n206 272 342 \n/categories/documentary/sportsdocumentary/videos \n17 \n32 \n34 \n/categories/fashion \n166 226 255 \n/categories/fashion/fashionprofiles/videos \n8 \n5 \n12 \n\nhttps://flickr.com/ 4 https://youtube.com/ 5 https://vimeo.com/ 6 https://creativecommons.org/\nhttps://github.com/rg3/youtube-dl 8 https://ffmpeg.org/\nAcknowledgementsThis work was partly supported by the Swiss National Science Foundation, project IMOTION (20CH21 151571).Disclaimer: Certain commercial entities, equipment, or materials may be identified in this document in order to describe an experimental procedure or concept adequately. Such identification is not intended to imply recommendation or endorsement by the National Institute of Standards and Technology, nor is it intended to imply that the entities, materials, or equipment are necessarily the best available for the purpose.\nYoutube-8m: A large-scale video classification benchmark. Sami Abu-El-Haija, Nisarg Kothari, Joonseok Lee, Paul Natsev, George Toderici, Balakrishnan Varadarajan, Sudheendra Vijayanarasimhan, arXiv:1609.08675arXiv preprintSami Abu-El-Haija, Nisarg Kothari, Joonseok Lee, Paul Natsev, George Toderici, Balakrishnan Varadarajan, and Sudheendra Vijayanarasimhan. Youtube-8m: A large-scale video classification benchmark. arXiv preprint arXiv:1609.08675, 2016.\n\nTrecvid 2017: Evaluating ad-hoc and instance video search, events detection, video captioning and hyperlinking. George Awad, Asad Butt, Jonathan Fiscus, David Joy, Andrew Delgado, Martial Michel, Alan F Smeaton, Yvette Graham, Wessel Kraaij, Georges Qunot, Maria Eskevich, Roeland Ordelman, J F Gareth, Benoit Jones, Huet, Proceedings of TRECVID 2017. NIST, USA. TRECVID 2017. NIST, USAGeorge Awad, Asad Butt, Jonathan Fiscus, David Joy, Andrew Delgado, Martial Michel, Alan F. Smeaton, Yvette Graham, Wessel Kraaij, Georges Qunot, Maria Eskevich, Roeland Ordelman, Gareth J. F. Jones, and Benoit Huet. Trecvid 2017: Evaluating ad-hoc and instance video search, events detection, video captioning and hyperlinking. In Proceedings of TRECVID 2017. NIST, USA, 2017.\n\nInteractive video search tools: a detailed analysis of the video browser showdown. Claudiu Cob\u00e2rzan, Klaus Schoeffmann, Werner Bailer, Wolfgang H\u00fcrst, Adam Bla\u017eek, Jakub Loko\u010d, Stefanos Vrochidis, Kai Uwe Barthel, Luca Rossetto, Multimedia Tools and Applications. 764Claudiu Cob\u00e2rzan, Klaus Schoeffmann, Werner Bailer, Wolfgang H\u00fcrst, Adam Bla\u017eek, Jakub Loko\u010d, Stefanos Vrochidis, Kai Uwe Barthel, and Luca Rossetto. Interactive video search tools: a detailed analysis of the video browser showdown 2015. Multimedia Tools and Applications, 76(4):5539-5571, 2017.\n\nAnnotating, understanding, and predicting long-term video memorability. Romain Cohendet, Karthik Yadati, Q K Ngoc, Claire-H\u00e9l\u00e8ne Duong, Demarty, Proceedings of the 2018 ACM on International Conference on Multimedia Retrieval. the 2018 ACM on International Conference on Multimedia RetrievalACMRomain Cohendet, Karthik Yadati, Ngoc QK Duong, and Claire-H\u00e9l\u00e8ne Demarty. Annotating, understanding, and predicting long-term video memorability. In Pro- ceedings of the 2018 ACM on International Conference on Multimedia Retrieval, pages 178-186. ACM, 2018.\n\nCreating a web-scale video collection for research. Paul Over, George Awad, Alan F Smeaton, Colum Foley, James Lanagan, Proceedings of the 1st workshop on Web-scale multimedia corpus. the 1st workshop on Web-scale multimedia corpusACMPaul Over, George Awad, Alan F. Smeaton, Colum Foley, and James Lanagan. Creating a web-scale video collection for research. In Proceedings of the 1st workshop on Web-scale multimedia corpus, pages 25-32. ACM, 2009.\n\nCineast: a multi-feature sketchbased video retrieval engine. Luca Rossetto, Ivan Giangreco, Heiko Schuldt, IEEE International Symposium on. IEEEMultimedia (ISM)Luca Rossetto, Ivan Giangreco, and Heiko Schuldt. Cineast: a multi-feature sketch- based video retrieval engine. In Multimedia (ISM), 2014 IEEE International Sym- posium on, pages 18-23. IEEE, 2014.\n\nWeb video in numbers -an analysis of web-video metadata. Luca Rossetto, Heiko Schuldt, arXiv:1707.01340arXiv preprintLuca Rossetto and Heiko Schuldt. Web video in numbers -an analysis of web-video metadata. arXiv preprint arXiv:1707.01340, 2017.\n\nYfcc100m: The new data in multimedia research. Bart Thomee, A David, Gerald Shamma, Benjamin Friedland, Karl Elizalde, Douglas Ni, Damian Poland, Li-Jia Borth, Li, Communications of the ACM. 592Bart Thomee, David A Shamma, Gerald Friedland, Benjamin Elizalde, Karl Ni, Douglas Poland, Damian Borth, and Li-Jia Li. Yfcc100m: The new data in multi- media research. Communications of the ACM, 59(2):64-73, 2016.\n\n. YouTube Terms of Service. 6YouTube Terms of Service. https://www.youtube.com/static?template=terms, 6 2018. Accessed: 2018-06-15.\n", "annotations": {"author": "[{\"end\":179,\"start\":36},{\"end\":323,\"start\":180},{\"end\":465,\"start\":324},{\"end\":607,\"start\":466}]", "publisher": null, "author_last_name": "[{\"end\":49,\"start\":41},{\"end\":193,\"start\":186},{\"end\":335,\"start\":331},{\"end\":477,\"start\":473}]", "author_first_name": "[{\"end\":40,\"start\":36},{\"end\":185,\"start\":180},{\"end\":330,\"start\":324},{\"end\":470,\"start\":466},{\"end\":472,\"start\":471}]", "author_affiliation": "[{\"end\":178,\"start\":51},{\"end\":322,\"start\":195},{\"end\":464,\"start\":337},{\"end\":606,\"start\":479}]", "title": "[{\"end\":33,\"start\":1},{\"end\":640,\"start\":608}]", "venue": null, "abstract": "[{\"end\":1722,\"start\":642}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b4\"},\"end\":2432,\"start\":2429},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2533,\"start\":2530},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":2607,\"start\":2604},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2765,\"start\":2762},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2863,\"start\":2860},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":3114,\"start\":3111},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":4637,\"start\":4634},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":6211,\"start\":6208},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":9072,\"start\":9069},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":9435,\"start\":9432},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":10146,\"start\":10143},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":10293,\"start\":10290},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":13946,\"start\":13943}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":15155,\"start\":15092},{\"attributes\":{\"id\":\"fig_1\"},\"end\":15270,\"start\":15156},{\"attributes\":{\"id\":\"fig_2\"},\"end\":15360,\"start\":15271},{\"attributes\":{\"id\":\"fig_3\"},\"end\":15416,\"start\":15361},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":16381,\"start\":15417},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":16854,\"start\":16382},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":17828,\"start\":16855}]", "paragraph": "[{\"end\":3115,\"start\":1738},{\"end\":3697,\"start\":3117},{\"end\":3951,\"start\":3699},{\"end\":4067,\"start\":3974},{\"end\":4109,\"start\":4069},{\"end\":4182,\"start\":4111},{\"end\":4328,\"start\":4184},{\"end\":4766,\"start\":4330},{\"end\":5317,\"start\":4768},{\"end\":5745,\"start\":5319},{\"end\":6101,\"start\":5747},{\"end\":6582,\"start\":6103},{\"end\":6933,\"start\":6584},{\"end\":7121,\"start\":6975},{\"end\":7841,\"start\":7146},{\"end\":8722,\"start\":7843},{\"end\":9610,\"start\":8749},{\"end\":10069,\"start\":9612},{\"end\":11211,\"start\":10071},{\"end\":11772,\"start\":11229},{\"end\":13660,\"start\":11774},{\"end\":14372,\"start\":13677},{\"end\":15091,\"start\":14388}]", "formula": null, "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":7332,\"start\":7325},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":10219,\"start\":10212},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":10667,\"start\":10660}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1736,\"start\":1724},{\"attributes\":{\"n\":\"2\"},\"end\":3972,\"start\":3954},{\"attributes\":{\"n\":\"3\"},\"end\":6973,\"start\":6936},{\"attributes\":{\"n\":\"3.1\"},\"end\":7144,\"start\":7124},{\"attributes\":{\"n\":\"3.2\"},\"end\":8747,\"start\":8725},{\"attributes\":{\"n\":\"3.3\"},\"end\":11227,\"start\":11214},{\"attributes\":{\"n\":\"3.4\"},\"end\":13675,\"start\":13663},{\"attributes\":{\"n\":\"4\"},\"end\":14386,\"start\":14375},{\"end\":15101,\"start\":15093},{\"end\":15173,\"start\":15157},{\"end\":15280,\"start\":15272},{\"end\":15370,\"start\":15362},{\"end\":15427,\"start\":15418},{\"end\":16392,\"start\":16383},{\"end\":16865,\"start\":16856}]", "table": "[{\"end\":16381,\"start\":15835},{\"end\":16854,\"start\":16485},{\"end\":17828,\"start\":16916}]", "figure_caption": "[{\"end\":15155,\"start\":15103},{\"end\":15270,\"start\":15176},{\"end\":15360,\"start\":15282},{\"end\":15416,\"start\":15372},{\"end\":15835,\"start\":15429},{\"end\":16485,\"start\":16394},{\"end\":16916,\"start\":16867}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":5381,\"start\":5373},{\"end\":7985,\"start\":7977},{\"end\":8997,\"start\":8989},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":9690,\"start\":9674}]", "bib_author_first_name": "[{\"end\":18586,\"start\":18582},{\"end\":18607,\"start\":18601},{\"end\":18625,\"start\":18617},{\"end\":18635,\"start\":18631},{\"end\":18650,\"start\":18644},{\"end\":18673,\"start\":18661},{\"end\":18697,\"start\":18687},{\"end\":19100,\"start\":19094},{\"end\":19111,\"start\":19107},{\"end\":19126,\"start\":19118},{\"end\":19140,\"start\":19135},{\"end\":19152,\"start\":19146},{\"end\":19169,\"start\":19162},{\"end\":19182,\"start\":19178},{\"end\":19184,\"start\":19183},{\"end\":19200,\"start\":19194},{\"end\":19215,\"start\":19209},{\"end\":19231,\"start\":19224},{\"end\":19244,\"start\":19239},{\"end\":19262,\"start\":19255},{\"end\":19274,\"start\":19273},{\"end\":19276,\"start\":19275},{\"end\":19291,\"start\":19285},{\"end\":19837,\"start\":19830},{\"end\":19853,\"start\":19848},{\"end\":19873,\"start\":19867},{\"end\":19890,\"start\":19882},{\"end\":19902,\"start\":19898},{\"end\":19916,\"start\":19911},{\"end\":19932,\"start\":19924},{\"end\":19947,\"start\":19944},{\"end\":19951,\"start\":19948},{\"end\":19965,\"start\":19961},{\"end\":20389,\"start\":20383},{\"end\":20407,\"start\":20400},{\"end\":20417,\"start\":20416},{\"end\":20419,\"start\":20418},{\"end\":20439,\"start\":20426},{\"end\":20920,\"start\":20916},{\"end\":20933,\"start\":20927},{\"end\":20944,\"start\":20940},{\"end\":20946,\"start\":20945},{\"end\":20961,\"start\":20956},{\"end\":20974,\"start\":20969},{\"end\":21380,\"start\":21376},{\"end\":21395,\"start\":21391},{\"end\":21412,\"start\":21407},{\"end\":21736,\"start\":21732},{\"end\":21752,\"start\":21747},{\"end\":21973,\"start\":21969},{\"end\":21983,\"start\":21982},{\"end\":21997,\"start\":21991},{\"end\":22014,\"start\":22006},{\"end\":22030,\"start\":22026},{\"end\":22048,\"start\":22041},{\"end\":22059,\"start\":22053},{\"end\":22074,\"start\":22068}]", "bib_author_last_name": "[{\"end\":18599,\"start\":18587},{\"end\":18615,\"start\":18608},{\"end\":18629,\"start\":18626},{\"end\":18642,\"start\":18636},{\"end\":18659,\"start\":18651},{\"end\":18685,\"start\":18674},{\"end\":18714,\"start\":18698},{\"end\":19105,\"start\":19101},{\"end\":19116,\"start\":19112},{\"end\":19133,\"start\":19127},{\"end\":19144,\"start\":19141},{\"end\":19160,\"start\":19153},{\"end\":19176,\"start\":19170},{\"end\":19192,\"start\":19185},{\"end\":19207,\"start\":19201},{\"end\":19222,\"start\":19216},{\"end\":19237,\"start\":19232},{\"end\":19253,\"start\":19245},{\"end\":19271,\"start\":19263},{\"end\":19283,\"start\":19277},{\"end\":19297,\"start\":19292},{\"end\":19303,\"start\":19299},{\"end\":19846,\"start\":19838},{\"end\":19865,\"start\":19854},{\"end\":19880,\"start\":19874},{\"end\":19896,\"start\":19891},{\"end\":19909,\"start\":19903},{\"end\":19922,\"start\":19917},{\"end\":19942,\"start\":19933},{\"end\":19959,\"start\":19952},{\"end\":19974,\"start\":19966},{\"end\":20398,\"start\":20390},{\"end\":20414,\"start\":20408},{\"end\":20424,\"start\":20420},{\"end\":20445,\"start\":20440},{\"end\":20454,\"start\":20447},{\"end\":20925,\"start\":20921},{\"end\":20938,\"start\":20934},{\"end\":20954,\"start\":20947},{\"end\":20967,\"start\":20962},{\"end\":20982,\"start\":20975},{\"end\":21389,\"start\":21381},{\"end\":21405,\"start\":21396},{\"end\":21420,\"start\":21413},{\"end\":21745,\"start\":21737},{\"end\":21760,\"start\":21753},{\"end\":21980,\"start\":21974},{\"end\":21989,\"start\":21984},{\"end\":22004,\"start\":21998},{\"end\":22024,\"start\":22015},{\"end\":22039,\"start\":22031},{\"end\":22051,\"start\":22049},{\"end\":22066,\"start\":22060},{\"end\":22080,\"start\":22075},{\"end\":22084,\"start\":22082}]", "bib_entry": "[{\"attributes\":{\"doi\":\"arXiv:1609.08675\",\"id\":\"b0\"},\"end\":18980,\"start\":18524},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":70129809},\"end\":19745,\"start\":18982},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":433600},\"end\":20309,\"start\":19747},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":47017469},\"end\":20862,\"start\":20311},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":17665887},\"end\":21313,\"start\":20864},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":11703191},\"end\":21673,\"start\":21315},{\"attributes\":{\"doi\":\"arXiv:1707.01340\",\"id\":\"b6\"},\"end\":21920,\"start\":21675},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":207230134},\"end\":22330,\"start\":21922},{\"attributes\":{\"id\":\"b8\"},\"end\":22463,\"start\":22332}]", "bib_title": "[{\"end\":19092,\"start\":18982},{\"end\":19828,\"start\":19747},{\"end\":20381,\"start\":20311},{\"end\":20914,\"start\":20864},{\"end\":21374,\"start\":21315},{\"end\":21967,\"start\":21922}]", "bib_author": "[{\"end\":18601,\"start\":18582},{\"end\":18617,\"start\":18601},{\"end\":18631,\"start\":18617},{\"end\":18644,\"start\":18631},{\"end\":18661,\"start\":18644},{\"end\":18687,\"start\":18661},{\"end\":18716,\"start\":18687},{\"end\":19107,\"start\":19094},{\"end\":19118,\"start\":19107},{\"end\":19135,\"start\":19118},{\"end\":19146,\"start\":19135},{\"end\":19162,\"start\":19146},{\"end\":19178,\"start\":19162},{\"end\":19194,\"start\":19178},{\"end\":19209,\"start\":19194},{\"end\":19224,\"start\":19209},{\"end\":19239,\"start\":19224},{\"end\":19255,\"start\":19239},{\"end\":19273,\"start\":19255},{\"end\":19285,\"start\":19273},{\"end\":19299,\"start\":19285},{\"end\":19305,\"start\":19299},{\"end\":19848,\"start\":19830},{\"end\":19867,\"start\":19848},{\"end\":19882,\"start\":19867},{\"end\":19898,\"start\":19882},{\"end\":19911,\"start\":19898},{\"end\":19924,\"start\":19911},{\"end\":19944,\"start\":19924},{\"end\":19961,\"start\":19944},{\"end\":19976,\"start\":19961},{\"end\":20400,\"start\":20383},{\"end\":20416,\"start\":20400},{\"end\":20426,\"start\":20416},{\"end\":20447,\"start\":20426},{\"end\":20456,\"start\":20447},{\"end\":20927,\"start\":20916},{\"end\":20940,\"start\":20927},{\"end\":20956,\"start\":20940},{\"end\":20969,\"start\":20956},{\"end\":20984,\"start\":20969},{\"end\":21391,\"start\":21376},{\"end\":21407,\"start\":21391},{\"end\":21422,\"start\":21407},{\"end\":21747,\"start\":21732},{\"end\":21762,\"start\":21747},{\"end\":21982,\"start\":21969},{\"end\":21991,\"start\":21982},{\"end\":22006,\"start\":21991},{\"end\":22026,\"start\":22006},{\"end\":22041,\"start\":22026},{\"end\":22053,\"start\":22041},{\"end\":22068,\"start\":22053},{\"end\":22082,\"start\":22068},{\"end\":22086,\"start\":22082}]", "bib_venue": "[{\"end\":18580,\"start\":18524},{\"end\":19343,\"start\":19305},{\"end\":20009,\"start\":19976},{\"end\":20535,\"start\":20456},{\"end\":21046,\"start\":20984},{\"end\":21453,\"start\":21422},{\"end\":21730,\"start\":21675},{\"end\":22111,\"start\":22086},{\"end\":22358,\"start\":22334},{\"end\":19368,\"start\":19345},{\"end\":20601,\"start\":20537},{\"end\":21095,\"start\":21048}]"}}}, "year": 2023, "month": 12, "day": 17}