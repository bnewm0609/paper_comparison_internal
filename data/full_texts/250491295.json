{"id": 250491295, "updated": "2023-10-05 12:35:41.92", "metadata": {"title": "Is one annotation enough? A data-centric image classification benchmark for noisy and ambiguous label estimation", "authors": "[{\"first\":\"Lars\",\"last\":\"Schmarje\",\"middle\":[]},{\"first\":\"Vasco\",\"last\":\"Grossmann\",\"middle\":[]},{\"first\":\"Claudius\",\"last\":\"Zelenka\",\"middle\":[]},{\"first\":\"Sabine\",\"last\":\"Dippel\",\"middle\":[]},{\"first\":\"Rainer\",\"last\":\"Kiko\",\"middle\":[]},{\"first\":\"Mariusz\",\"last\":\"Oszust\",\"middle\":[]},{\"first\":\"Matti\",\"last\":\"Pastell\",\"middle\":[]},{\"first\":\"Jenny\",\"last\":\"Stracke\",\"middle\":[]},{\"first\":\"Anna\",\"last\":\"Valros\",\"middle\":[]},{\"first\":\"Nina\",\"last\":\"Volkmann\",\"middle\":[]},{\"first\":\"Reinhard\",\"last\":\"Koch\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "High-quality data is necessary for modern machine learning. However, the acquisition of such data is difficult due to noisy and ambiguous annotations of humans. The aggregation of such annotations to determine the label of an image leads to a lower data quality. We propose a data-centric image classification benchmark with ten real-world datasets and multiple annotations per image to allow researchers to investigate and quantify the impact of such data quality issues. With the benchmark we can study the impact of annotation costs and (semi-)supervised methods on the data quality for image classification by applying a novel methodology to a range of different algorithms and diverse datasets. Our benchmark uses a two-phase approach via a data label improvement method in the first phase and a fixed evaluation model in the second phase. Thereby, we give a measure for the relation between the input labeling effort and the performance of (semi-)supervised algorithms to enable a deeper insight into how labels should be created for effective model training. Across thousands of experiments, we show that one annotation is not enough and that the inclusion of multiple annotations allows for a better approximation of the real underlying class distribution. We identify that hard labels can not capture the ambiguity of the data and this might lead to the common issue of overconfident models. Based on the presented datasets, benchmarked methods, and analysis, we create multiple research opportunities for the future directed at the improvement of label noise estimation approaches, data annotation schemes, realistic (semi-)supervised learning, or more reliable image collection.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2207.06214", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/nips/SchmarjeGZDKOPS22", "doi": "10.48550/arxiv.2207.06214"}}, "content": {"source": {"pdf_hash": "5fed23f3cedc0700f10d2a4bf8de950c59f41382", "pdf_src": "ScienceParsePlus", "pdf_uri": "[\"https://arxiv.org/pdf/2207.06214v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "0b25ed527c0ab1c556c6f5d8db802fc2ca0e51d3", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/5fed23f3cedc0700f10d2a4bf8de950c59f41382.txt", "contents": "\nIs one annotation enough? A data-centric image classification benchmark for noisy and ambiguous label estimation\n\n\nLars Schmarje \nMIP\nKiel University\n\n\nVasco Grossmann \nMIP\nKiel University\n\n\nClaudius Zelenka \nMIP\nKiel University\n\n\nSabine Dippel \nFriedrich-Loeffler-Institut\nITT\n\n\nRainer Kiko \nLOV\nSorbonne Universit\u00e9\n\n\nMariusz Oszust \nRzeszow University of Technology\n\n\nMatti Pastell \nUniversity of Helsinki\n7 Luke\n\nNatural Resources Institute\nFinland\n\nJenny Stracke \nITW\nUniversity Bonn\n\nAnna Valros \nNina Volkmann \nReinhard Koch \nMIP\nKiel University\n\n\n\nWING\nUniversity of Veterinary Medicine Hannover\n\n\nIs one annotation enough? A data-centric image classification benchmark for noisy and ambiguous label estimation\n10.5281/zenodo.7152309\nHigh-quality data is necessary for modern machine learning. However, the acquisition of such data is difficult due to noisy and ambiguous annotations of humans. The aggregation of such annotations to determine the label of an image leads to a lower data quality. We propose a data-centric image classification benchmark with ten real-world datasets and multiple annotations per image to allow researchers to investigate and quantify the impact of such data quality issues. With the benchmark we can study the impact of annotation costs and (semi-)supervised methods on the data quality for image classification by applying a novel methodology to a range of different algorithms and diverse datasets. Our benchmark uses a two-phase approach via a data label improvement method in the first phase and a fixed evaluation model in the second phase. Thereby, we give a measure for the relation between the input labeling effort and the performance of (semi-)supervised algorithms to enable a deeper insight into how labels should be created for effective model training. Across thousands of experiments, we show that one annotation is not enough and that the inclusion of multiple annotations allows for a better approximation of the real underlying class distribution. We identify that hard labels can not capture the ambiguity of the data and this might lead to the common issue of overconfident models. Based on the presented datasets, benchmarked methods, and analysis, we create multiple research opportunities for the future directed at the improvement of label noise estimation approaches, data annotation schemes, realistic (semi-)supervised learning, or more reliable image collection. 2\n\nIntroduction\n\nHigh-quality data is the fuel of modern machine learning and almost all models improve with higher quality data [8,80,50]. Therefore, such data are a key component for developing future techniques. The acquisition of a large amount of data is considered particularly challenging due to the participation of humans in the process. Their mistakes or subjective interpretations of annotation tasks can lead to noisy or ambiguous labels, respectively [54,16,61,28,52,9,18,29]. Consequently, the labels suffer from heteroscedastic aleatoric uncertainty which means that the data contains inherent noise, which is class-or even sample-dependent and negatively affects the quality [14].\n\nIn Figure 1, we present the impact of this uncertainty on the class \"cat\" in the CIFAR-10 dataset [32]. While all images have the same ground truth label in CIFAR-10, humans created agreeing annotations only with varying rates from four to 100 percent [54]. This means that individual annotations can be expected to be noisy as they diverge from the majority opinion. Furthermore, a majority vote across multiple annotations can not capture the ambiguity between different images. In some extreme cases (red borders), we even see a disagreeing majority vote across all annotators from the expected ground truth class. We raise the question if all images should be treated equally if human annotations show such varying certainties. Taking a data-centric perspective [47,62,45,25], we investigate the data in contrast to only the model for answering this question. Specifically, we propose a data-centric image classification (DCIC) benchmark that indirectly measures a method's ability to identify noisy and ambiguous labels and correct them. DCIC consists of ten real-world datasets of different domains (see Figure 2) and multiple human annotations for each image. The benchmark focuses on a datacentric view of the image classification problem by separating the data quality improvement and the classification performance into two tasks.\n\nThe main structure of the benchmark is divided into a Labeling and an Evaluation phase (see Figure 3a) which is comparable to established Teacher-Student-Approaches [70,36]. Using this denotation, the benchmarked method will, as a teacher, improve labels during the first phase. These are then benchmarked in the second phase by analyzing their quality as training input to a student model. Be aware that we do not allow a knowledge transfer from the second phase to the first phase.\n\nIn detail, during the Labeling phase, we use samples from the distribution of the above-mentioned annotations to get different realistic label estimates as an initialization. The task of the benchmarked method is to improve these estimates for better performance of an other classification model in the second phase. In that phase (Evaluation), the obtained labels are used as input for training a fixed model and its performance is measured on a testing subset of the original data. In contrast to common model-centric deep learning approaches (see Figure 3b), we can vary the initialization for the same method and better separate its performance from the data improvement. The fixed model is used for the evaluation to facilitate distinguishing between performance gains due to improved input data and better learning of the method itself. Figure 1: Are all images showing a cat? -Based on their ground truth labels from CIFAR-10 [32] they should all be cats. However, we give the agreement rate with the class cat from [54] in the lower right corner and see a wide range from four to 100%. Based on a majority vote, the last images (red border) would have not to be labeled as a cat but as dog, frog, dog, and deer, respectively. Based on these observations, we answer in our paper the question of whether all images should be treated equally as cats or if we should use multiple annotations and the resulting soft labels to capture this intrinsic noise and ambiguity.  Table 1.\n\nOur benchmark is not only useful to evaluate existing methods, but will support research into algorithms for realistic datasets. Especially, it can bridge the research between semi-supervised learning and noise estimation based on realistic ambiguous noise patterns. We provide multiple algorithms as baselines and support the integration of more algorithms by common dataloaders for the two most popular deep learning frameworks: Tensorflow [1] and Pytorch [53]. We analyzed thousands of combinations of baseline methods, different initializations, and datasets. The obtained results confirm that the improvement of data quality leads to performance gains. Additionally, we investigated factors that influence the data quality and identified trends that lead to better learning of the underlying distribution.  Figure 3: Comparison of our data-centric approach with the commonly used model-centric approach. The circles and arrows represent the available label information in addition to the corresponding images. The squares represent the methods which generate / change these label. There are two main differences between our and the common model-centric approach. Firstly, we also look at how the raw unlabeled data is initialized and thus how many annotations are required. Secondly, we use a fixed model to evaluate the output of the benchmarked method. These differences lead to a greater separation of data quality and method performance on the final scores on the predicted labels.\n\nOur key contributions are: (1) We collected and created ten real-world image classification datasets with multiple annotations per image. These annotations allow a realistic simulation of noise patterns and will be helpful for future research in machine learning on real world data sets. (2) We provide a multi-domain benchmark based on these datasets for noisy and ambiguous label estimation. We implemented 20 methods as comparison. The benchmark also covers the topic of cost and bridges research between semi-supervised learning and ambiguous label estimation. (3) We show that one annotation per image is not enough because model performance improves as more labels are given for each input. We identify that the current focus on hard labels for classifications is ill-suited to learn the underlying ground truth distribution. A change in data preprocessing especially in annotation protocols could mitigate this and lead to less overconfident models.\n\n\nRelated Work\n\nHuman annotations of one image can differ due to complex reasons. Next to mere individual errors, cognitive sciences have shown that human judgement under uncertainty is driven by a subjective bias and the context of the annotation process [66]. As labeling relies on human perception, data quality problems, including issues with noisy and ambiguous labels, have been broadly discussed in the literature [68,4,54,77,3]. While voting strategies have proven to be robust tools to remove outlying annotation errors in a single label scenario, they also eliminate subjective disagreement, even in cases with more than just one valid interpretation [56]. The impact of this information loss has been discussed in numerous studies, indicating limitations in capturing ground truth by just one label [71,17,22,6]. We empirically support these arguments across 9 datasets and 20 methods.\n\nAs label noise can severely degrade the classification performance [50], learning with flawed training data has become a substantial field of research in which numerous strategies have been proposed: while sample selection methods separate clean and noisy data by evaluating small-loss or disagreement [78,79], correction methods aim at relabeling wrongly assigned labels by either learning class prototypes [24] or by pseudo-labeling strategies that utilize confident predictions [38]. Multiple methods have been proposed, but are often evaluated on synthetic noise [44,40]. However, Wei et al. showed that synthetic noise is different from real noise by humans, which limits the generality of findings [77]. Gao et al. proposed synthetic annotators with individual labeling behavior instead of random noise to reduce uncertainty in predictions [20]. We go beyond this by using human annotations to reproduce realistic noise pattern and we do not only look at annotation errors but also at ambiguous annotations from subjective interpretations.\n\nDatasets like CIFAR-10H [54] and CIFAR-10N [77] address the problem of realistic noise by providing multiple annotations per image for example of the original CIFAR-10 dataset. By doing so, both publications demonstrate an improved performance and a higher robustness, while also claiming that further research in dealing with human noise is still inevitable. The utilization of soft label distributions instead of hard one-hot label encodings enables the detailed representation of subjective disagreement and improves the generalization with ambiguous datasets [54,5,34]. In our benchmark, we extend this idea to eight diverse datasets apart from CIFAR-10 for a broader evaluation.\n\nIf we want to use multiple annotations per image, we need to consider the cost of such annotations to make it feasible in a project. Current research such as semi-supervised learning [12,67,64,63] could be used to analyze only a portion of the data with multiple annotations. However, approaches which combine noisy labels with semi-supervised learning have not been extended to real-world image classification tasks or do not consider the possibility that one labels is not enough to capture the ambiguity of subjectivity [42,81,76]. We provide with our benchmark the datasets and infrastructure to bridge the research between semi-supervised learning and noise estimation.\n\nPrediction uncertainty can be attributed to unexplainable noise in the given training or test dataset (aleatoric uncertainty) or a wrong model inference (epistemic uncertainty) and it can be difficult to approximate and differentiate between them [58,2,72,30]. Several real-world noisy datasets have been utilized as a foundation for classification benchmarks [41,39,54], Song et al. provide a current survey on datasets and methods [68]. Moreover, most robust methods are evaluated based on the test set accuracy [40,68,77,59,82]. However, even a small change in the structure or parameters of a method can directly impact its performance, limiting the comparability [31]. Other fields, such as Bayesian Neural Networks, address this issue by comparing results to statistical simulations, for example [27]. A recent benchmark [49] tries to overcome this issue by providing a baseline for noisy labels as a form of uncertainty estimation [14]. However, this benchmark relies on synthetic noise or noisy datasets without knowledge about the underlying ground truth distributions [41]. We use a data-centric approach to minimize the impact of implementation detail differences and measure the impact of the data indirectly during the Labeling phase by evaluating on a fixed model.\n\n\nBenchmark\n\nOur benchmark is divided into two major phases: Labeling and Evaluation. In alignment with the Data-Centric Idea [47], we separate the improvement of the data (Labeling) from the improvement of the models (Evaluation). The benchmark can be utilized to analyze a variety of research questions, but we focus on evaluating methods that estimate noisy or ambiguous labels.\n\nWe use the terms noisy and ambiguous throughout this work synonymously because we often do not differentiate between their cause during the annotation process. As mentioned above, these causes are errors or mistakes of human annotators which can be recovered for noisy label or noise. Subjective interpretations, imprecise task descriptions or poor image quality lead to ambiguous labels.\n\nIn general, we have an image dataset X with k known classes and use human annotations to approximate the image labels. Each image x \u2208 X has an often unknown soft ground truth label l x \u2208 [0, 1] k . Therefore, we use N hard human annotations a i \u2208 {0, 1} k with i \u2208 1, ..., N as estimates ofl x . We assume that an average of annotations (l x = N i=0 ai N ) is an approximation of this target labell x as in [64]. Based on this definition, an annotation a i or hard label sampled from the distribution l x are in general of lower quality because they can not capture the aleatoric uncertainty of the soft label l x . We split the data equally and randomly in five folds and ensure a similar class distribution between the folds as best as possible. For one run, we use three folds as training (X T ) and one fold each as validation (X V ) and test (X E ) data, respectively. We call such an assignment of folds to the training, validation and test data slice.\n\nLabeling The Labeling phase consists of two steps. In the first step an initialization is used to get label estimates and in the second step, the benchmarked method \u0398 aims to improve these labels. As initialization, we acquire m \u2208 N annotations for n \u2208 [0, 100] percent of the training and validation images.\n\nWe call the total number of required annotations budget b = m \u00b7 n and report it as proportions of training and validation images (|X T \u222a X V |). In general, a classification task gets easier with more annotations or a higher budget. Be aware that the same initialization results in the the same budget while the same budget can achieved by different initializations.\n\nThe used initialization schemes per method are defined later in this section. We chose fixed initialization schemes for better comparability between the methods. How these labels are improved by the method \u0398 is not restricted. However, annotations aside from the given initialization are not allowed to be used. Since we measure the quality by training a different fixed network in the next phase, a good label would be presumably as close as possible to l x . Table 1: Overview of the used datasets -# is an abbreviation for number. The class imbalance is given as the percentage of the smallest and largest class with regard to the complete dataset. The agreement is the percentage of annotations that agree with the majority vote. The scores ACC and ACC are given for the supervised baseline across three test folds. The access describes if the (raw) data is available openly, requires permission (restricted) or was not previously available (N/A). In the last column, datasets with modifications to the original data are marked with X. A modification might be adding more annotations or crop images to a region of interest. Evaluation In the Evaluation phase, the model and its hyperparameters are fixed to measure only the impact of the provided labels (\u0398(x)). The training of this fixed model \u03a6 is calculated on the provided \u0398(x) with x \u2208 X T . The best network parameters during training are selected based on a minimal divergence between \u03a6(x) and \u0398(x) with x \u2208 X V . The generalization is then tested by measuring the difference between \u03a6(x) and l x for x \u2208 X E .\n\nMetrics Kullback-Leibler divergence (KL) [35] between \u03a6(x) and l x for x \u2208 X E has been used as our main metric since it is an established method to measures the difference between two distributions [48]. We averaged in a 3-fold cross-validation per dataset for a high reproducibility. We used the three slices defined by\nX Vi = {f i+1 }, X Ei = {f i+2 } and the rest as training (X Ti = {f i , f ((i+2)%5)+1 , f ((i+3)%5)+1 , } with % for modulo)\nfor the folds f 1 , ..., f 5 with i \u2208 1, 2, 3 as the index of the slices. While KL directly allows to measure the desired distribution divergence, we provide additional metrics as comparisons. We evaluate the accuracy (ACC) and F1-Score (F 1) between \u03a6(x) and l x for x \u2208 X E per class and report the mean across the classes, which is commonly called the macro value and allows evaluation even in the presence of class imbalance. We used the most likely class based on the evaluated distributions for these metrics. We analyze the calibration of the models by reporting the Expected Calibration Error (ECE) [23]. As reference, we provide all of these metrics also on the difference between the proposed label before the second training \u0398(x) and the expected ground-truth l x for x \u2208 X E . The metrics are noted as\u00c2CC,F 1 and\u00caCE. We report the Cohen's Kappa Score (\u03ba) [46] as the measurement of the consistency of \u0398(x) between the folds because more consistent labels result in higher model performance.\n\nDatasets We include ten real-world classification datasets in our benchmark. Since we need multiple annotations per image for the evaluation of the quality of labels and this information is often not available in existing datasets or insufficient for our benchmark, we collected, adopted, or extended annotations of the following datasets. Their details are shortly described below, while their properties and exemplary images are shown in Table 1 and Figure 2, respectively. As presented, the datasets vary across all reported properties, giving an opportunity to comprehensively evaluate considered methods. More challenging datasets are characterized by a high-class imbalance, a low average agreement, or a low number of annotations per image. Detailed reports about the collection process and remaining dataset specifics are given in the supplementary.\n\n1. Benthic depicts images from the seafloor and consists of underwater flora and fauna. We used annotations from [65,37] but filtered for at least three annotations per object and cropped the main image to this object. We combined classes with too few images in agreement with domain experts.  [77], this dataset provides more annotations per image. 3. MiceBone consists of Second-Harmonic-Generation images of collagen fibers in mice [60]. The raw images were preprocessed as described in [64]. Since there is a need for multiple annotations per image, we hired workers to increase their number by a factor of five. 4. Pig consists cropped tail images from European farms. The annotations were collected by hired workers with high domain knowledge. The goal is the classification of the injury degree of the tail. 5. Plankton is a collection of underwater plankton images with multiple annotations from citizen scientists [61]. We use the preprocessing described in [64]. 6. QualityMRI consists of human magnetic resonance images (MRI) with a varying quality and multiple subjective quality ratings gathered in tests with radiologists. It was introduced and evaluated in [51,69]. 7. Synthetic dataset was generated for the purpose of this study. It consists of images that contain one blue, red, or green circle or ellipse on a black background. To create ambiguous images, we added color and axis interpolations of these classes. 8+9. TreeVersity is a publicly available crowdsourced dataset of plant images from the Arnold Arboretum of Harvard University 3 . In the crowdsourcing project, the images were tagged with a given set of labels. We used a simplified version with six classes where we combined classes with too few images. Only images with at least three tags were used. Tags are not the same as class labels, therefore, we provide two subsets of TreeVersity. In TreeVersity#1, we filtered for exactly one given tag of the six possible ones per user which is similar to a classification. In TreeVersity#6, we filtered for a maximum of six different tags which means we did not apply any restrictions. 10. Turkey is a dataset with images of turkeys and their injuries [74,75]. We used the preprocessing described in [64] and extended the original annotations, increasing their number by a factor of five with hired workers.\n\nMethods We compare a variety of recent supervised, self-supervised, and semi-supervised algorithms against our baseline. The baseline does not adjust the initialized dataset in the first phase in any way and just forwards these labels to the supervised training of the second phase. Thus it is equivalent to supervised learning in a model-centric benchmark. We selected the other methods based on their recency, access to authors code or reimplementations and if they are state-of-the-art or commonly used as comparisons in the literature. The supervised methods are Heteroscedastic [15], SNGP [43], and ELR+ [44]. The semi-supervised methods are Mean-Teacher [70], \u03c0-Model [36], FixMatch [67], DC3 [64], Pseudo-Label [38], and DivideMix [40]. The self-supervised methods are BYOL [21], MOCOv2 [13], SimCLR [11], and SWAV [10]. Detailed descriptions about most of them are given in [63] and their key characteristics are presented in Table 2. We use the reported hyperparameters for Imagenet [33] or Webvision [41] by the original authors to ensure a comparison out-of-the-box across different image domains. For DC3 [64], we investigated the combinations with Mean-Teacher, \u03c0-Model, FixMatch, and Pseudo-Label. For Pseudo-Label, we used two different implementations (v1 and v2) and variants with or without pretraining and soft or hard labels as input.\n\nIn total, this results in 20 investigated methods. For better referencing, we group them as described above but put methods that use soft labels into their own group.\n\n\nInitialization Schemes\n\nWe investigated a fixed set of initialization schemes and note them m-n for m annotations for a subset of data with a relative size n. For easier reference, we group them as Implementation Details The final results depend on a good set of fixed hyperparameters like learning rate for the model \u03a6 for each dataset during the evaluation. Therefore, we determined them by applying Hyperopt [7] with 100 search trials across the same grid of parameters for all datasets. The target was the minimization of KL between \u03a6(x) and l x for the baseline experiment with exactly ten annotations per image across one slice. We executed these and later experiments on an Nvidia RTX 3090 with 24GB VRAM or comparable hardware. Some combinations of models and input sizes could not fit on this hardware and therefore were ignored to keep the needed hardware to a minimum. Details about the used parameter grid are given in the supplementary. We ensure that all folds are randomly generated, while restrictions about similar images are considered. Without these restrictions, similar images, e.g., frames from the same camera might lead to an information leakage between the folds which would negatively influence the interpretability of the results.\n\n\nAnalysis\n\nThe evaluation was conducted across combinations of all datasets, methods, initialization schemes, and slices. A complete cross-combination would result in 5400 experiments from which we selected 3456 experiments to save resources since some combinations would not add more insights e.g. due to inferior performance of similar methods. A detailed overview of the initialization schemes used per method can be found in Table 2. As shown in Table 1, we have a large variability between the datasets, especially in ACC and\u00c2CC that range from 36% to 96% for the baseline. Due to the fact that the baseline does not adjust the initialization,\u00c2CC can be seen as the performance of humans in improving the labels for the given budget. The datasets Benthic, MiceBone, Pig, Treeversity#6, and Turkey have an over 10% lower ACC than the expected\u00c2CC, which marks them as particularly challenging for the model. Moreover, the datasets Benthic, MiceBone, Pig, QualitMRI, and Treeveritsy#6 have an\u00c2CC of lower than 85% which marks them as difficult even for humans. The\u00c2CC of Synthetic is even lower due to the artificially created labels. Due to this variability, an average across the scores can be misleading. For this reason, we report the median in this paper and report the full results including the standard error of the mean (SEM) in the supplementary.\n\nWhat metrics should we use? We analyzed the correlations between our metrics to determine which contain the same or similar information and which are complementary. All calculated Pearson correlation coefficients have a p-value < 0.01 and the four strongest correlations are ACC vs.  Figure 4 and additional graphics and analysis are given in the supplementary. F 1 balances the precision and recall but in our experiments we see almost identical values to ACC which we credit to the averaging per class. This means we only need to concentrate on ACC as a classification score. Overconfident models are a problem of modern machine learning [23] and the higher correlation between KL and ECE compared to any of the two with ACC, F 1 or \u03ba indicates that our focus on classification metrics like ACC and F 1 could be the issue. Only metrics like KL and ECE consider the complete distribution and which justifies using mainly KL for the evaluation of this benchmark.\n\nOne annotation is not enough It is to be expected that more and better data should lead to increased performance which we quantify in Figure 5a. It can be seen that all metrics improve with an increased budget in the form of more annotated data or more annotations per image. However, the impact is lower for more annotations per image. For example, ACC increases from around 55% to 69% for the full supervision. Up to 10 annotations per image increase the score only to around 72%. This difference can be explained by the fact that additional annotations are most valuable to improve uncertain labels. In alignment with previous research [71,22,6], these results across thousands of (a) ACC vs. experiments empirically justify that one annotation is not enough to capture the ground-truth of an item. Some improvements can be gained from correction annotation errors via a majority vote but the high disagreement and low\u00c2CC of the baseline on some datasets support the hypothesis that ambiguous annotations are a main source for the improvement. This ambiguity can not be described with a single hard majority vote and thus highlights the importance of using soft labels. Additionally, we see that KL is about half as small asKL, ECE is around 3-10% lower than\u00caCE and ACC is 1-2% better than\u00c2CC. As shown previously by Hinton et al. [26,12] the knowledge distillation via a neural network into soft labels can be beneficial for ACC. We find the impact for metrics like KL and ECE even higher which supports our design of a two-phase benchmark.\n\nLimits of current state-of-the-art To determine the best-performing state-of-the-art method, we gathered their relative improvements over the baseline in Table 3a. The best algorithm for each type of the soft, semi-supervised, supervised, self-supervised approaches based on the average performance across the budgets of 10%, 100%, and 1000% are Pseudo v2 soft, DivideMix, ELR+, and Mocov2, respectively.We visualize the best three of them in Figure 5c and give detailed results across the datasets for the budget 100% in Table 3b. The full results can be found in the supplementary. All top three methods are pretrained on ImageNet and outperform the rest in the field they were designed for. DivideMix is the best during partial supervision (budget < 100%), ELR+ is more noise robust (budget > 100%), and Pseudo v2 soft has the lowest KL score (budget > 100%). It is important to note that ImageNet pretraining leads to improvements on many datasets (see Pseudo v2 not in the supplementary) but also to worse results on others. It needs to be investigated if other pretraining such as CLIP [55] or unsupervised pretraining on larger datasets [12,57] could improve on these results. Overall, the current state-of-the-art methods are insufficient for a label preprocessing across all domains. For a high budget any investigated method is worse than the supervised baseline without adjustments of the initialized dataset which shows the lack of appropriate algorithms for such budgets. Moreover, an average better performance does not mean that the gains are equal across all datasets. For example, ELR+ has the lowest KL at a budget of 100% for five out of ten datasets but on the QualityMRI dataset, it is among the worst methods. This means while some methods might work on some datasets they might not generalize to other datasets. Overall, we see the highest KL for the datasets Benthic, Pig, Quality MRI and Treeversity#6 which also have the lowest agreement as seen in Table 1 except for the synthetic dataset. These datasets also show the largest variance in results across the methods. We conclude that the impact of the data is larger than the impact of the current preprocessing of state-of-the-art methods. This highlights the importance for investigating the data and label generation more if they a more impactful than the method itself.\n\nWhile a higher budget leads to improved metrics, it also matters how it is used. In Figure 5b, we investigated the impact on KL and ACC for a budget of 100% for Pseudo-Label using hard or soft labels. We find that the accuracy is comparable between the methods and increases with a rising percentage of labeled data (m). For hard labels, the KL improves equally. If we use soft labels for training, we see lower results for 05-0.20 and 10-0. 10. We conclude that we should investigate more how we distribute our budget if increasing it is not an option.\n\n\nDiscussion\n\nOverall, we can confirm several previous research hypotheses while identifying missing information and thus new research opportunities with our novel datasets and benchmark.\n\nWe can demonstrate that data quality positively impacts the classifications scores like ACC and F 1 and distribution-based scores like KL and ECE. Knowledge distillation can improve the approximation of the underlying distribution further. We agree with previous research [71,17,22,6] that one annotation is not enough and we need to use soft labels to handle ambiguous data. KL and ECE are highly correlated (0.7) and are improved more when using soft labels. We believe that focusing on learning the real distribution and thus minimizing KL can lead to less overconfident models. Using soft labels as input seems to be crucial for achieving this since hard labels and classification metrics like ACC lead to models which slightly ignore the real ground truth distribution.\n\nNevertheless, most of the investigated state-of-the-art method do not use soft labels and often interpret noise only as errors in the annotation process. These issues need to be addressed in future research and a simple method like Pseudo v2 soft illustrates how the KL score can be lowered with this approach. For the largest budget, the baseline is the best model and even special noise estimation algorithms like ELR+ [44] and SNGP [43] can not achieve better results. We see a high variance across the datasets for different methods in our benchmark. However, we need methods which work across a variety of domains out-of-the-box to allow an easy application to current research question in other domains. Another practical issue is that we need to find solutions for acquiring soft labels even with a limited budget. In many research projects, it is difficult to annotate thousands of images with domain experts and annotating them multiple times would only increase the costs further. Thus, we need to bridge the research in semi-supervised learning and ambiguous and noise estimation. Such combinations could allow the usage of soft labels on a subset of images and simultaneously determine annotation errors. Our benchmark and datasets allowed the identification of these issues and thus could also be used to research new methods to solve these issues. We are confident that our benchmark and datasets can facilitate the bridged research on the topic of semi-supervised learning and ambiguous image estimation for real world image classification problems.\n\nImpact This work as a benchmark provides ten datasets and a detailed evaluation across 20 algorithms on this benchmark. The provided data can allow the investigation of research questions on the topics of e.g. noise estimation, data annotation scheme, or realistic semi-supervised learning. This work is intended to allow and spark future research and thus no direct social impacts are expected. However, this basic research is time and resource-consuming. For the final evaluation, we conducted experiments with about 5500 GPU hours which equals around 600kg CO 2 . For this reason, we limited the evaluation always to necessary elements when possible in order to not increase the needed GPU hours further.\n\nLimitations The 20 investigated algorithms are only evaluated with one fixed set of hyperparameters across different datasets during the labeling phase. For optimal performance, a tuning per algorithm would have been required. We were interested in the general performance out-of-the-box and therefore neglected this issue due to resource minimization. The researched datasets are all below 15,000 images and the unsupervised learning potential on millions of images could not be investigated. We want to provide a detailed analysis in relation to the underlying distribution l x per image which is only possible with multiple annotations per image. For larger datasets, this effort was just not feasible. Classification with hundreds or more classes are also not feasible because the annotation costs increase with the number of classes. As described above we conducted more than a thousand experiments but we had to select and combine several results in a comprehensive manner in this paper. These aggregations can not capture all details. Much more detailed analysis e.g., per dataset would be possible and thus we included all raw results in the supplementary. Due to the fixed initialization scheme, we can not investigate active learning approaches. However, this restriction is chosen to allow a better comparability and future researchers could decide against such a restriction.\n\nConclusion In alignment with previous research, we show that one annotation is not enough to handle ambiguous and noisy images and their underlying ground truth distribution. Multiple annotations and some kind of soft label are required to capture the difference in the images. Future research needs to investigate in more detail how annotations are being created, including annotation costs. We show that current state-of-the-art can help under certain budget or dataset constraints. However, methods with consistent results across a variety of datasets and budgets are missing. We release all datasets and the benchmark publicly to enrich future research on these topics.\n\n(c) Did you include the estimated hourly wage paid to participants and the total amount spent on participant compensation? [Yes] We included hourly wages where applicable in the supplementary.\n\nFigure 2 :\n2Three example images for all datasets. Details about the statistics of the dataset are given in\n\n\u2022\nSupervised Learning (SL) 01-1.00 \u2022 Supervised Learning+ (SL+) 03-1.00, 05-1.00, 10-1.00 \u2022 Semi-Supervised Learning (SSL) 01-0.10, 01-0.20, 01-0.50 \u2022 Semi-Supervised Learning (SSL+) 10-0.10, 05-0.20, 02-0.50\n\nF 1\n1(0.99), KL vs. ECE (0.68) F 1 vs. \u03ba (0.77) and ACC vs. \u03ba (0.77). The other correlations are around -0.5. Selected correlations are illustrated in\n\nF 1 (Figure 4 :Figure 5 :\n145b) KL vs. ECE (c) ACC vs. ECE Correlations between selected metrics across all experiments. The red line represents the linear regression between the metrics and the light red area the mean absolute error of the regression. Analysis of all or selected methods across different budgets or initialization schemes. For details about the definitions see section 2. The orange crosses in (c) represent the best performance of Pseudo v2 soft with another initialization scheme see (b). The budget is increased by an raised portion of labeled data (n) until 1.00 and then increased further by using additionally multiple annotations per image (m).\n\n\nName # classes Input size [px] # Images Class Imbalance [%] Agreement [%] # Annotations ACC [%]\u00c2CC [%] Access UpdatedSmallest Largest Mean \u00b1 STD Mean \u00b1 STD Mean \u00b1 STD Mean \u00b1 STDBenthic \n10 \n112\u00d7112 \n4867 \n2.31 \n39.66 \n82.61 \u00b1 19.67 \n4.54 \u00b1 2.01 \n64.17 \u00b1 0.63 83.36 \u00b1 0.47 Restricted \nX \nCIFAR-10H \n10 \n32\u00d732 \n10000 \n9.88 \n10.16 \n95.44 \u00b1 8.91 \n51.10 \u00b1 1.54 \n90.75 \u00b1 0.39 95.72 \u00b1 0.12 \nOpen \nMice Bone \n3 \n224\u00d7224 \n7240 \n14.75 \n70.48 \n85.06 \u00b1 17.52 15.30 \u00b1 21.90 61.88 \u00b1 9.44 78.39 \u00b1 1.95 Restricted \nX \nPig \n4 \n96\u00d796 \n10237 \n7.82 \n41.23 \n65.32 \u00b1 19.50 \n7.26 \u00b1 2.29 \n35.97 \u00b1 3.61 64.77 \u00b1 0.79 \nN/A \nX \nPlankton \n10 \n96\u00d796 \n12280 \n4.16 \n30.37 \n93.26 \u00b1 13.60 24.38 \u00b1 44.17 89.89 \u00b1 0.82 92.41 \u00b1 0.41 Restricted \nQuality MRI \n2 \n224\u00d7224 \n310 \n34.84 \n64.16 \n71.56 \u00b1 12.27 99.94 \u00b1 13.44 66.62 \u00b1 3.55 75.81 \u00b1 0.17 Restricted \nX \nSynthetic \n6 \n224\u00d7224 \n15000 \n16.17 \n17.57 \n74.41 \u00b1 24.28 \n98.86 \u00b1 0.99 \n87.85 \u00b1 0.48 74.65 \u00b1 0.34 \nN/A \nX \nTreeversity#1 \n6 \n224\u00d7224 \n9489 \n9.98 \n30.67 \n88.60 \u00b1 16.13 \n14.78 \u00b1 7.06 \n79.50 \u00b1 1.53 89.20 \u00b1 0.31 \nOpen \nX \nTreeversity#6 \n6 \n224\u00d7224 \n9826 \n8.77 \n31.26 \n66.53 \u00b1 19.48 35.45 \u00b1 11.47 56.71 \u00b1 4.89 68.88 \u00b1 0.72 \nOpen \nX \nTurkey \n3 \n192\u00d7192 \n8040 \n10.88 \n75.95 \n91.56 \u00b1 13.82 14.85 \u00b1 20.95 75.51 \u00b1 2.80 86.89 \u00b1 1.03 Restricted \nX \n\n\n\nTable 2 :\n2Overview of used methods grouped into supervised, semi-supervised and self-supervised. The second to fifth column describe if the method uses unlabeled data, makes noise estimation, what pretraining is the used input of the initialized dataset are hard or soft labels, respectively. The initialization schemes columns describe which schemes were evaluated for individual methods. The average runtime of the labeling phase is given in the last column.Name \nUnlabeled \nData \n\nNoise \nEstimation \n\nPretraining \nLabels \nInitialization Schemes \nAvg. Runtime \n[h] \nSL SL+ SSL SSL+ \n\nBaseline \nSoft \nX \nX \nX \nX \n0.00 \nHeteroscedastic (Het) [15] \nX \nHard \nX \nX \nX \nX \n0.50 \nSNGP [43] \nX \nHard \nX \nX \nX \nX \n0.29 \nELR+ [44] \nX \nImageNet \nHard \nX \nX \nX \nX \n0.09 \n\nMean-Teacher (Mean) [70] \nX \nHard \nX \nX \n1.08 \nMean-Teacher (Mean+DC3) [64] \nX \nHard \nX \nX \n1.20 \n\u03c0-Model (\u03c0) [36] \nX \nHard \nX \nX \n1.03 \n\u03c0-Model (\u03c0+DC3) [64] \nX \nHard \nX \nX \n1.15 \nFixMatch [67] \nX \nHard \nX \nX \n4.53 \nFixMatch +DC3 [64] \nX \nHard \nX \nX \n4.01 \nPseudo-Label (Pseudo v1) [38] \nX \nHard \nX \nX \n1.10 \nPseudo-Label (Pseudo v1 +DC3) [64] \nX \nHard \nX \nX \n1.40 \nPseudo-Label (Pseudo v2 hard) [38] \nX \nImageNet \nHard \nX \nX \nX \nX \n0.16 \nPseudo-Label (Pseudo v2 soft) [38] \nX \nImageNet \nSoft \nX \nX \nX \nX \n0.12 \nPseudo-Label (Pseudo v2 not) [38] \nX \nSoft \nX \nX \nX \nX \n0.12 \nDivideMix [40] \nX \nX \nImageNet \nHard \nX \nX \nX \nX \n1.39 \n\nBYOL [21] \nX \nSelf-Supervised \nHard \nX \nX \n2.59 \nMOCOv2 [13] \nX \nSelf-Supervised \nHard \nX \nX \n7.94 \nSimCLR [11] \nX \nSelf-Supervised \nHard \nX \nX \n5.89 \nSWAV [10] \nX \nSelf-Supervised \nHard \nX \nX \n4.17 \n\n\n\nTable 3 :\n3Results for the best performing methods -The best metric is marked bold while the 2nd and 3rd best are italic. Only methods with at least one top3 ranking across the budgets are presented.The \n\nhttps://arboretum.harvard.edu/research/data-resources/\nAcknowledgments and Disclosure of FundingWe thank Mark Collier for his valuable feedback and discussion about the benchmark. We thank the annotators Kristina Ahlqvist, Daniel Grundig, Stine Heindorff, Jana Krambeck, Kathrin K\u00f6rner, Richard Lange, Miina Tuominen-Brinkas and Emirhan Ustalar for their valuable work.We acknowledge funding of L. Schmarje by the ARTEMIS project (Grant number 01EC1908E) funded by the Federal Ministry of Education and Research (BMBF, Germany). R. Kiko also acknowledges support via a \"Make Our Planet Great Again\" grant of the French National Research Agency within the \"Programme d'Investissements d'Avenir\"; reference \"ANR-19-MPGA-0012\". V. Grossmann is employed with funds provided by Kiel Marine Science (KMS) and Future Ocean Network (FON) by Kiel University. Funds to conduct the PlanktonID project were granted to R. Kiko and R. Koch (CP1733) by the Cluster of Excellence 80 \"Future Ocean\" within the framework of the Excellence Initiative by the Deutsche Forschungsgemeinschaft (DFG) on behalf of the German federal and state governments. Turkey data set was collected as part of the project \"RedAlertdetection of pecking injuries in turkeys using neural networks\" which was supported by the \"Animal Welfare Innovation Award\" of the \"Initiative Tierwohl\".Multiple datasets are created or extended by us, also the source code for the benchmark is new. The source code and datasets are reachable as described in the access section in the supplementary or in the main repository. (d) Did you discuss whether and how consent was obtained from people whose data you're using/curating?\nXiaoqiang Zheng, and Others. TensorFlow: A System for Large-Scale Machine Learning. Martin Mart\\&apos;\\in Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, Manjunath Kudler, Josh Levensberg, Rajat Monga, Sherry Moore, Derek Murray, Benoit Steiner, Paul Tucker, Vijay Vasudevan, Pete Warden, Martin Wicke, Yuan Yu, 12th USENIX symposium on operating systems design and implementation (OSDI 16). Martin Mart\\'\\in Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, Manjunath Kudler, Josh Levensberg, Rajat Monga, Sherry Moore, Derek Murray, Benoit Steiner, Paul Tucker, Vijay Vasudevan, Pete Warden, Martin Wicke, Yuan Yu, Xiaoqiang Zheng, and Others. TensorFlow: A System for Large-Scale Machine Learning. In 12th USENIX symposium on operating systems design and implementation (OSDI 16), pages 265-283, 2016.\n\nA review of uncertainty quantification in deep learning: Techniques, applications and challenges. Information Fusion. Moloud Abdar, Farhad Pourpanah, Sadiq Hussain, Dana Rezazadegan, Li Liu, Mohammad Ghavamzadeh, Paul Fieguth, Xiaochun Cao, Abbas Khosravi, U Rajendra Acharya, Vladimir Makarenkov, Saeid Nahavandi, 10.1016/j.inffus.2021.05.00876Moloud Abdar, Farhad Pourpanah, Sadiq Hussain, Dana Rezazadegan, Li Liu, Mohammad Ghavamzadeh, Paul Fieguth, Xiaochun Cao, Abbas Khosravi, U. Rajendra Acharya, Vladimir Makarenkov, and Saeid Nahavandi. A review of uncertainty quantification in deep learning: Techniques, applications and challenges. Information Fusion, 76:243-297, 2021. ISSN 15662535. doi: 10.1016/j.inffus.2021.05.008.\n\nA new wave of marine evidence-based management: Emerging challenges and solutions to transform monitoring, evaluating, and reporting. P F E Addison, D J Collins, R Trebilco, S Howe, N Bax, P Hedge, G Jones, P Miloslavich, C Roelfsema, M Sams, R D Stuart-Smith, P Scanes, P Von Baumgarten, A Mcquatters-Gollop, 10.1093/icesjms/fsx216ICES Journal of Marine Science. 753P. F.E. E E Addison, D. J. Collins, R. Trebilco, S. Howe, N. Bax, P. Hedge, G. Jones, P. Miloslavich, C. Roelfsema, M. Sams, R. D. Stuart-Smith, P. Scanes, P. Von Baumgarten, and A. McQuatters-Gollop. A new wave of marine evidence-based management: Emerging challenges and solutions to transform monitoring, evaluating, and reporting. ICES Journal of Marine Science, 75(3):941-952, 2018. ISSN 10959289. doi: 10.1093/icesjms/fsx216.\n\nImage Classification with Deep Learning in the Presence of Noisy Labels: A Survey. Knowledge-Based Systems. G\u00f6rkem Algan, Ilkay Ulusoy, 23318422. doi: 10.1016/j. knosys.2021.106771G\u00f6rkem Algan and Ilkay Ulusoy. Image Classification with Deep Learning in the Presence of Noisy Labels: A Survey. Knowledge-Based Systems, 2020. ISSN 23318422. doi: 10.1016/j. knosys.2021.106771.\n\nHessam Bagherinezhad, Maxwell Horton, Mohammad Rastegari, Ali Farhadi, arXiv:1805.02641Label refinery: Improving imagenet classification through label progression. arXiv preprintHessam Bagherinezhad, Maxwell Horton, Mohammad Rastegari, and Ali Farhadi. La- bel refinery: Improving imagenet classification through label progression. arXiv preprint arXiv:1805.02641, 2018.\n\nMassimo Poesio, and Alexandra Uma. We Need to Consider Disagreement in Evaluation. Valerio Basile, Michael Fell, Tommaso Fornaciari, Dirk Hovy, Silviu Paun, BPPF. Barbara Plank2021Valerio Basile, Michael Fell, Tommaso Fornaciari, Dirk Hovy, Silviu Paun, Barbara Plank, Massimo Poesio, and Alexandra Uma. We Need to Consider Disagreement in Evaluation. In BPPF, 2021.\n\nMaking a science of model search: Hyperparameter optimization in hundreds of dimensions for vision architectures. James Bergstra, Daniel Yamins, David Cox, International conference on machine learning. PMLRJames Bergstra, Daniel Yamins, and David Cox. Making a science of model search: Hyper- parameter optimization in hundreds of dimensions for vision architectures. In International conference on machine learning, pages 115-123. PMLR, 2013.\n\nLucas Beyer, Olivier J H\u00e9naff, Alexander Kolesnikov, arXiv:2006.07159Xiaohua Zhai, and A\u00e4ron van den Oord. Are we done with ImageNet? arXiv preprint. Lucas Beyer, Olivier J. H\u00e9naff, Alexander Kolesnikov, Xiaohua Zhai, and A\u00e4ron van den Oord. Are we done with ImageNet? arXiv preprint arXiv:2006.07159, 2020.\n\nTailception': using neural networks for assessing tail lesions on pictures of pig carcasses. J Br\u00fcnger, Dippel, C Koch, Veit, 10.1017/S1751731118003038Animal. 135J Br\u00fcnger, S Dippel, R Koch, and C Veit. 'Tailception': using neural networks for assessing tail lesions on pictures of pig carcasses. Animal, 13(5):1030-1036, 2019. ISSN 17517311. doi: 10.1017/S1751731118003038.\n\nUnsupervised Learning of Visual Features by Contrasting Cluster Assignments. Mathilde Caron, Priya Goyal, Ishan Misra, Piotr Bojanowski, Julien Mairal, Armand Joulin, Proceedings of Advances in Neural Information Processing Systems (NeurIPS). Advances in Neural Information Processing Systems (NeurIPS)Mathilde Caron, Priya Goyal, Ishan Misra, Piotr Bojanowski, Julien Mairal, and Armand Joulin. Unsupervised Learning of Visual Features by Contrasting Cluster Assignments. Proceedings of Advances in Neural Information Processing Systems (NeurIPS), 2020. ISSN 23318422.\n\nA Simple Framework for Contrastive Learning of Visual Representations. Ting Chen, Simon Kornblith, Mohammad Norouzi, Geoffrey Hinton, arXiv:2002.0570923318422arXiv preprintTing Chen, Simon Kornblith, Mohammad Norouzi, and Geoffrey Hinton. A Simple Framework for Contrastive Learning of Visual Representations. arXiv preprint arXiv:2002.05709, (PMLR): 1597-1607, 2020. ISSN 23318422.\n\nBig Self-Supervised Models are Strong Semi-Supervised Learners. Ting Chen, Simon Kornblith, Kevin Swersky, Mohammad Norouzi, Geoffrey Hinton, Advances in Neural Information Processing Systems. 332020Ting Chen, Simon Kornblith, Kevin Swersky, Mohammad Norouzi, and Geoffrey Hinton. Big Self-Supervised Models are Strong Semi-Supervised Learners. Advances in Neural Information Processing Systems 33 pre-proceedings (NeurIPS 2020), 2020.\n\nXinlei Chen, Haoqi Fan, arXiv:2003.04297Ross Girshick, and Kaiming He. Improved Baselines with Momentum Contrastive Learning. arXiv preprintXinlei Chen, Haoqi Fan, Ross Girshick, and Kaiming He. Improved Baselines with Momentum Contrastive Learning. arXiv preprint arXiv:2003.04297, 2020.\n\nA Simple Probabilistic Method for Deep Classification under Input-Dependent Label Noise. Mark Collier, Basil Mustafa, Efi Kokiopoulou, Rodolphe Jenatton, Jesse Berent, arXiv:2003.06778arXiv preprintMark Collier, Basil Mustafa, Efi Kokiopoulou, Rodolphe Jenatton, and Jesse Berent. A Simple Probabilistic Method for Deep Classification under Input-Dependent Label Noise. arXiv preprint arXiv:2003.06778, 2020.\n\nCorrelated Input-Dependent Label Noise in Large-Scale Image Classification. Mark Collier, Basil Mustafa, Efi Kokiopoulou, Rodolphe Jenatton, Jesse Berent, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern RecognitionMark Collier, Basil Mustafa, Efi Kokiopoulou, Rodolphe Jenatton, and Jesse Berent. Corre- lated Input-Dependent Label Noise in Large-Scale Image Classification. Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, (c):1551-1560, 2021.\n\nDo experts make mistakes? A comparison of human and machine identification of dinoflagellates. Phil Culverhouse, Robert Williams, Beatriz Reguera, Vincent Herry, Sonsoles Gonz\u00e1lez-Gil, 10.3354/meps247017Marine Ecology Progress Series. 247Phil Culverhouse, Robert Williams, Beatriz Reguera, Vincent Herry, and Sonsoles Gonz\u00e1lez- Gil. Do experts make mistakes? A comparison of human and machine identification of dinoflagellates. Marine Ecology Progress Series, 247:17-25, 2003. doi: 10.3354/meps247017.\n\nDealing with Disagreements: Looking Beyond the Majority Vote in Subjective Annotations. Aida Mostafazadeh Davani, Mark D\u00edaz, Vinodkumar Prabhakaran, Aida Mostafazadeh Davani, Mark D\u00edaz, and Vinodkumar Prabhakaran. Dealing with Disagree- ments: Looking Beyond the Majority Vote in Subjective Annotations. 2021.\n\nClinically applicable deep learning for diagnosis and referral in retinal disease. Jeffrey De Fauw, Joseph R Ledsam, Bernardino Romera-Paredes, Stanislav Nikolov, Nenad Tomasev, Sam Blackwell, Harry Askham, Xavier Glorot, O&apos; Brendan, Daniel Donoghue, Visentin, Others, O&apos; Brendan, Daniel Donoghue, Others Visentin, Nature medicine. 249Jeffrey De Fauw, Joseph R Ledsam, Bernardino Romera-Paredes, Stanislav Nikolov, Nenad Tomasev, Sam Blackwell, Harry Askham, Xavier Glorot, Brendan O'Donoghue, Daniel Visentin, Others, Brendan O'Donoghue, Daniel Visentin, and Others. Clinically applicable deep learning for diagnosis and referral in retinal disease. Nature medicine, 24(9):1342-1350, 2018.\n\nVisualizing data using t-SNE. Laurens Der Maaten, Geoffrey Hinton, Journal of machine learning research. 911Laurens der Maaten and Geoffrey Hinton. Visualizing data using t-SNE. Journal of machine learning research, 9(11), 2008.\n\nLearning from Multiple Annotator Noisy Labels via Sample-wise Label Fusion. Zhengqi Gao, Fan-Keng Sun, Mingran Yang, Sucheng Ren, Zikai Xiong, Marc Engeler, Antonio Burazer, Linda Wildling, Luca Daniel, Duane S Boning, Zhengqi Gao, Fan-Keng Sun, Mingran Yang, Sucheng Ren, Zikai Xiong, Marc Engeler, Antonio Burazer, Linda Wildling, Luca Daniel, and Duane S. Boning. Learning from Multiple Annotator Noisy Labels via Sample-wise Label Fusion. 2022.\n\nBootstrap your own latent: A new approach to self-supervised Learning. Jean-Bastien Grill, Florian Strub, Florent Altch\u00e9, Corentin Tallec, Pierre H Richemond, Elena Buchatskaya, Carl Doersch, Bernardo Avila Pires, Zhaohan Daniel Guo, Mohammad Gheshlaghi Azar, Bilal Piot, Koray Kavukcuoglu, R\u00e9mi Munos, Michal Valko, Advances in Neural Information Processing Systems. 332020Jean-Bastien Grill, Florian Strub, Florent Altch\u00e9, Corentin Tallec, Pierre H. Richemond, Elena Buchatskaya, Carl Doersch, Bernardo Avila Pires, Zhaohan Daniel Guo, Mohammad Gheshlaghi Azar, Bilal Piot, Koray Kavukcuoglu, R\u00e9mi Munos, and Michal Valko. Bootstrap your own latent: A new approach to self-supervised Learning. Advances in Neural Information Processing Systems 33 pre-proceedings (NeurIPS 2020), 2020.\n\nLars Vasco Grossmann, Reinhard Schmarje, Koch, Beyond Hard Labels: Investigating data label distributions. ICML 2022 Workshop DataPerf: Benchmarking Data for Data-Centric AI. Vasco Grossmann, Lars Schmarje, and Reinhard Koch. Beyond Hard Labels: Investigating data label distributions. ICML 2022 Workshop DataPerf: Benchmarking Data for Data-Centric AI, 2022.\n\nOn calibration of modern neural networks. Chuan Guo, Geoff Pleiss, Yu Sun, Kilian Q Weinberger, International Conference on Machine Learning. PMLRChuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q Weinberger. On calibration of modern neural networks. In International Conference on Machine Learning, pages 1321-1330. PMLR, 2017.\n\nDeep self-learning from noisy labels. Jiangfan Han, Ping Luo, Xiaogang Wang, Proceedings of the IEEE/CVF international conference on computer vision. the IEEE/CVF international conference on computer visionJiangfan Han, Ping Luo, and Xiaogang Wang. Deep self-learning from noisy labels. In Proceedings of the IEEE/CVF international conference on computer vision, pages 5138-5147, 2019.\n\nThe Fourth Paradigm -Data-Intensive Scientific Discovery. Tony Hey, 10.1007/978-3-642-33299-9_1Communications in Computer and Information Science. Tony Hey. The Fourth Paradigm -Data-Intensive Scientific Discovery. In Communications in Computer and Information Science, pages 1-1. 2012. doi: 10.1007/978-3-642-33299-9_1.\n\nDistilling the Knowledge in a Neural Network. Geoffrey Hinton, Oriol Vinyals, Jeff Dean, Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distilling the Knowledge in a Neural Network. 2015.\n\nPavel Izmailov, Sharad Vikram, Matthew D Hoffman, Andrew Gordon Gordon Wilson, What Are Bayesian Neural Network Posteriors Really Like? International Conference on Machine Learning. Pavel Izmailov, Sharad Vikram, Matthew D. Hoffman, and Andrew Gordon Gordon Wilson. What Are Bayesian Neural Network Posteriors Really Like? International Conference on Machine Learning, pages 4629-4640, 2021.\n\nOn the effect of inter-observer variability for a reliable estimation of uncertainty of medical image segmentation. Alain Jungo, Raphael Meier, Ekin Ermis, Marcela Blatti-Moreno, Evelyn Herrmann, Roland Wiest, Mauricio Reyes, Medical Image Computing and Computer Assisted Interventions, MICCAI. SpringerAlain Jungo, Raphael Meier, Ekin Ermis, Marcela Blatti-Moreno, Evelyn Herrmann, Roland Wiest, and Mauricio Reyes. On the effect of inter-observer variability for a reliable estimation of uncertainty of medical image segmentation. In Medical Image Computing and Computer Assisted Interventions, MICCAI, pages 682-690. Springer, 2018.\n\nDeep Learning-Based Gleason Grading of Prostate Cancer From Histopathology Images-Role of Multiscale Decision Aggregation and Data Augmentation. D Karimi, Nir, P C Fazli, Black, S E Goldenberg, Salcudean, 10.1109/JBHI.2019.2944643IEEE Journal of Biomedical and Health Informatics. 245D Karimi, G Nir, L Fazli, P C Black, L Goldenberg, and S E Salcudean. Deep Learning-Based Gleason Grading of Prostate Cancer From Histopathology Images-Role of Multiscale Decision Aggregation and Data Augmentation. IEEE Journal of Biomedical and Health Informatics, 24 (5):1413-1426, 2020. doi: 10.1109/JBHI.2019.2944643.\n\nWhat Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision?. Alex Kendall, Yarin Gal, Alex Kendall and Yarin Gal. What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision? 2017.\n\nRevisiting self-supervised visual representation learning. Alexander Kolesnikov, Xiaohua Zhai, Lucas Beyer, Proceedings of the IEEE conference on Computer Vision and Pattern Recognition. the IEEE conference on Computer Vision and Pattern RecognitionAlexander Kolesnikov, Xiaohua Zhai, and Lucas Beyer. Revisiting self-supervised visual representation learning. In Proceedings of the IEEE conference on Computer Vision and Pattern Recognition, pages 1920-1929, 2019.\n\nLearning multiple layers of features from tiny images. Alex Krizhevsky, Geoffrey Hinton, Others , Technical reportAlex Krizhevsky, Geoffrey Hinton, and Others. Learning multiple layers of features from tiny images. Technical report, 2009.\n\nImagenet classification with deep convolutional neural networks. Alex Krizhevsky, Ilya Sutskever, Geoffrey E Hinton, 10.1145/3065386Advances in neural information processing systems. Association for Computing Machinery60Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. Imagenet classification with deep con- volutional neural networks. In Advances in neural information processing systems, volume 60, pages 1097-1105. Association for Computing Machinery, 2012. doi: 10.1145/3065386.\n\nUjwal Krothapalli, Abbott Lynn, arXiv:2009.06432Adaptive label smoothing. arXiv preprintUjwal Krothapalli and A Lynn Abbott. Adaptive label smoothing. arXiv preprint arXiv:2009.06432, 2020.\n\nOn Information and Sufficiency. S Kullback, R A Leibler, 10.1214/aoms/1177729694Ann. Math. Statist. 221S Kullback and R A Leibler. On Information and Sufficiency. Ann. Math. Statist., 22(1):79-86, 1951. doi: 10.1214/aoms/1177729694.\n\nTemporal ensembling for semi-supervised learning. Samuli Laine, Timo Aila, International Conference on Learning Representations. Samuli Laine and Timo Aila. Temporal ensembling for semi-supervised learning. In Interna- tional Conference on Learning Representations, 2017.\n\nGear-Induced Concept Drift in Marine Images and Its Effect on Deep Learning Classification. Daniel Langenk\u00e4mper, Robin Van Kevelaer, Autun Purser, Tim W Nattkemper, 10.3389/fmars.2020.00506Frontiers in Marine Science. 7Daniel Langenk\u00e4mper, Robin van Kevelaer, Autun Purser, and Tim W Nattkemper. Gear- Induced Concept Drift in Marine Images and Its Effect on Deep Learning Classification. Frontiers in Marine Science, 7, 2020. ISSN 2296-7745. doi: 10.3389/fmars.2020.00506.\n\nPseudo-label: The simple and efficient semi-supervised learning method for deep neural networks. Dong-Hyun Lee, Workshop on challenges in representation learning, ICML. 3Dong-Hyun Lee. Pseudo-label: The simple and efficient semi-supervised learning method for deep neural networks. In Workshop on challenges in representation learning, ICML, volume 3, page 2, 2013.\n\nCleannet: Transfer learning for scalable image classifier training with label noise. Kuang-Huei Lee, Xiaodong He, Lei Zhang, Linjun Yang, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionKuang-Huei Lee, Xiaodong He, Lei Zhang, and Linjun Yang. Cleannet: Transfer learning for scalable image classifier training with label noise. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 5447-5456, 2018.\n\nDivideMix: Learning with Noisy Labels as Semi-supervised Learning. Junnan Li, Richard Socher, Steven C H Hoi, International Conference on Learning Representations. Junnan Li, Richard Socher, and Steven C. H. Hoi. DivideMix: Learning with Noisy Labels as Semi-supervised Learning. In International Conference on Learning Representations, pages 1-14, 2020.\n\nWebVision Database: Visual Learning and Understanding from Web Data. Wen Li, Limin Wang, Wei Li, Eirikur Agustsson, Luc Van Gool, Wen Li, Limin Wang, Wei Li, Eirikur Agustsson, and Luc Van Gool. WebVision Database: Visual Learning and Understanding from Web Data. 2017.\n\nAmbiguity-aware Ensemble Training for Semisupervised Dependency Parsing. Zhenghua Li, Min Zhang, Wenliang Chen, 10.3115/v1/P14-1043Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics. the 52nd Annual Meeting of the Association for Computational LinguisticsAssociation for Computational Linguistics1Long Papers)Zhenghua Li, Min Zhang, and Wenliang Chen. Ambiguity-aware Ensemble Training for Semi- supervised Dependency Parsing. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 457-467. Association for Computational Linguistics, 2014. doi: 10.3115/v1/P14-1043.\n\nSimple and principled uncertainty estimation with deterministic deep learning via distance awareness. Jeremiah Liu, Zi Lin, Shreyas Padhy, Dustin Tran, Tania Bedrax Weiss, Balaji Lakshminarayanan, Advances in Neural Information Processing Systems. 33Jeremiah Liu, Zi Lin, Shreyas Padhy, Dustin Tran, Tania Bedrax Weiss, and Balaji Lakshmi- narayanan. Simple and principled uncertainty estimation with deterministic deep learning via distance awareness. Advances in Neural Information Processing Systems, 33:7498-7512, 2020.\n\nEarly-Learning Regularization Prevents Memorization of Noisy Labels. Advances in neural information processing systems. Sheng Liu, Jonathan Niles-Weed, Narges Razavian, Carlos Fernandez-Granda, 33Sheng Liu, Jonathan Niles-Weed, Narges Razavian, and Carlos Fernandez-Granda. Early- Learning Regularization Prevents Memorization of Noisy Labels. Advances in neural informa- tion processing systems, 33:20331-20342, 2020.\n\nOn Data-centric Myths. Adam Marcu, Antonia ; Prugel-Bennett, NeurIPS 2021 Data-centric AI workshop. Adam Marcu, Antonia; Prugel-Bennett. On Data-centric Myths. NeurIPS 2021 Data-centric AI workshop, 2021.\n\nInterrater reliability: the kappa statistic. L Mary, Mchugh, Biochemia. 3PubMedMary L McHugh. Interrater reliability: the kappa statistic. PubMed, Biochemia(3):276-82, 2012.\n\nA Data-Centric Approach for Training Deep Neural Networks with Less Data. Mohammad Motamedi, Nikolay Sakharnykh, Tim Kaldewey, NeurIPS 2021 Data-centric AI workshop. Mohammad Motamedi, Nikolay Sakharnykh, and Tim Kaldewey. A Data-Centric Approach for Training Deep Neural Networks with Less Data. NeurIPS 2021 Data-centric AI workshop, 2021.\n\nMachine learning: a probabilistic perspective. P Kevin, Murphy, MIT pressKevin P Murphy. Machine learning: a probabilistic perspective. MIT press, 2012.\n\nZachary Nado, Neil Band, Mark Collier, Josip Djolonga, W Michael, Sebastian Dusenberry, Angelos Farquhar, Marton Filos, Rodolphe Havasi, Jenatton, arXiv:2106.04015Ghassen Jerfel, and Others. Uncertainty Baselines: Benchmarks for uncertainty & robustness in deep learning. arXiv preprintZachary Nado, Neil Band, Mark Collier, Josip Djolonga, Michael W Dusenberry, Sebastian Farquhar, Angelos Filos, Marton Havasi, Rodolphe Jenatton, Ghassen Jerfel, and Others. Uncertainty Baselines: Benchmarks for uncertainty & robustness in deep learning. arXiv preprint arXiv:2106.04015, 2021.\n\nCurtis G Northcutt, Anish Athalye, Jonas Mueller, Pervasive Label Errors in Test Sets Destabilize Machine Learning Benchmarks. 35th Conference on Neural Information Processing Systems (NeurIPS 2021) Track on Datasets and Benchmarks. Curtis G. Northcutt, Anish Athalye, and Jonas Mueller. Pervasive Label Errors in Test Sets Destabilize Machine Learning Benchmarks. 35th Conference on Neural Information Processing Systems (NeurIPS 2021) Track on Datasets and Benchmarks, 2021.\n\nInterobserver variability in quality assessment of magnetic resonance images. Rafal Obuchowicz, Mariusz Oszust, Adam Piorkowski, 10.1186/s12880-020-00505-zBMC Medical Imaging. 201109Rafal Obuchowicz, Mariusz Oszust, and Adam Piorkowski. Interobserver variability in quality assessment of magnetic resonance images. BMC Medical Imaging, 20(1):109, 2020. ISSN 1471-2342. doi: 10.1186/s12880-020-00505-z.\n\nMammography: Interobserver variability in breast density assessment. E A Ooms, H M Zonderland, M J C Eijkemans, M Kriege, B Delavary, C W Burger, A C Ansink, 10.1016/j.breast.2007.04.007The Breast. 166E.A. A Ooms, H.M. M Zonderland, M.J.C. J C Eijkemans, M. Kriege, B. Mahdavian Delavary, C.W. W Burger, and A.C. C Ansink. Mammography: Interobserver variability in breast density assessment. The Breast, 16(6):568-576, 2007. ISSN 09609776. doi: 10.1016/j.breast.2007.04. 007.\n\nPyTorch: An Imperative Style, High-Performance Deep Learning Library. Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary Devito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, Soumith Chintala, Advances in Neural Information Processing Systems. Curran Associates, Inc32Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward Yang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. PyTorch: An Imperative Style, High-Performance Deep Learning Library. In Advances in Neural Information Processing Systems 32, pages 8024-8035. Curran Associates, Inc., 2019.\n\nHuman uncertainty makes classification more robust. Joshua Peterson, Ruairidh Battleday, Thomas Griffiths, Olga Russakovsky, 10.1109/ICCV.2019.00971Proceedings of the IEEE International Conference on Computer Vision, 2019-Octob:9616-9625. the IEEE International Conference on Computer Vision, 2019-Octob:9616-9625Joshua Peterson, Ruairidh Battleday, Thomas Griffiths, and Olga Russakovsky. Human uncer- tainty makes classification more robust. Proceedings of the IEEE International Conference on Computer Vision, 2019-Octob:9616-9625, 2019. ISSN 15505499. doi: 10.1109/ICCV.2019. 00971.\n\nLearning Transferable Visual Models From Natural Language Supervision. Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, Ilya Sutskever, Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agar- wal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, and Ilya Sutskever. Learning Transferable Visual Models From Natural Language Supervision. 2021.\n\nMultilabel iterated learning for image classification with label ambiguity. Sai Rajeswar, Pau Rodriguez, Soumye Singhal, David Vazquez, Aaron Courville, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern RecognitionSai Rajeswar, Pau Rodriguez, Soumye Singhal, David Vazquez, and Aaron Courville. Multi- label iterated learning for image classification with label ambiguity. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, pages 4783-4793, 2022.\n\nPierre H Richemond, Jean-Bastien Grill, Florent Altch\u00e9, Corentin Tallec, Florian Strub, Andrew Brock, Samuel Smith, arXiv:2010.10241Bilal Piot, and Michal Valko. BYOL works even without batch statistics. Soham De, Razvan PascanuarXiv preprintPierre H. Richemond, Jean-Bastien Grill, Florent Altch\u00e9, Corentin Tallec, Florian Strub, Andrew Brock, Samuel Smith, Soham De, Razvan Pascanu, Bilal Piot, and Michal Valko. BYOL works even without batch statistics. arXiv preprint arXiv:2010.10241, 2020.\n\nTowards Reducing Aleatoric Uncertainty for Medical Imaging Tasks. Abhishek Singh Sambyal, C Narayanan, Deepti R Krishnan, Bathula, Abhishek Singh Sambyal, Narayanan C. Krishnan, and Deepti R. Bathula. Towards Reducing Aleatoric Uncertainty for Medical Imaging Tasks. 2021.\n\nMedRegNet: unsupervised multimodal retinal-image registration with GANs and ranking loss. Monty Santarossa, Ayse Kilic, Claus Von Der, Lars Burchard, Claudius Schmarje, Stefan Zelenka, Reinhard Reinhold, Johann Koch, Roider, Medical Imaging 2022: Image Processing. SPIE12032Monty Santarossa, Ayse Kilic, Claus von der Burchard, Lars Schmarje, Claudius Zelenka, Stefan Reinhold, Reinhard Koch, and Johann Roider. MedRegNet: unsupervised multimodal retinal-image registration with GANs and ranking loss. In Medical Imaging 2022: Image Processing, volume 12032, pages 321-333. SPIE, 2022.\n\n2D and 3D Segmentation of uncertain local collagen fiber orientations in SHG microscopy. Lars Schmarje, Claudius Zelenka, Ulf Geisen, -C Claus, Reinhard Gl\u00fcer, Koch, 10.1007/978-3-030-33676-9_26DAGM German Conference of Pattern Regocnition, 11824 LNCS. Lars Schmarje, Claudius Zelenka, Ulf Geisen, Claus-C. Gl\u00fcer, and Reinhard Koch. 2D and 3D Segmentation of uncertain local collagen fiber orientations in SHG microscopy. DAGM German Conference of Pattern Regocnition, 11824 LNCS(November):374-386, 2019. ISSN 23318422. doi: 10.1007/978-3-030-33676-9_26.\n\nFuzzy Overclustering: Semi-Supervised Classification of Fuzzy Labels with Overclustering and Inverse Cross-Entropy. Lars Schmarje, Johannes Br\u00fcnger, Monty Santarossa, Simon-Martin Schr\u00f6der, Rainer Kiko, Reinhard Koch, 10.3390/s21196661Sensors. 21196661Lars Schmarje, Johannes Br\u00fcnger, Monty Santarossa, Simon-Martin Schr\u00f6der, Rainer Kiko, and Reinhard Koch. Fuzzy Overclustering: Semi-Supervised Classification of Fuzzy Labels with Overclustering and Inverse Cross-Entropy. Sensors, 21(19):6661, 2021. ISSN 1424-8220. doi: 10.3390/s21196661.\n\nA Data-Centric Image Classification Benchmark. NeurIPS 2021 Data-centric AI workshop. Lars Schmarje, Yuan-Hong Liao, Reinhard Koch, Lars Schmarje, Yuan-Hong Liao, and Reinhard Koch. A Data-Centric Image Classification Benchmark. NeurIPS 2021 Data-centric AI workshop, 2021.\n\nA Survey on Semi-, Self-and Unsupervised Learning for Image Classification. Lars Schmarje, Monty Santarossa, Simon-Martin Schroder, Reinhard Koch, Simon-Martin Schr\u00f6der, Reinhard Koch, Simon-Martin Schroder, Reinhard Koch, 10.1109/ACCESS.2021.3084358IEEE Access. Lars Schmarje, Monty Santarossa, Simon-Martin Schroder, Reinhard Koch, Simon-Martin Schr\u00f6der, Reinhard Koch, Simon-Martin Schroder, and Reinhard Koch. A Survey on Semi-, Self-and Unsupervised Learning for Image Classification. IEEE Access, pages 1-1, 2021. ISSN 2169-3536. doi: 10.1109/ACCESS.2021.3084358.\n\nA data-centric approach for improving ambiguous labels with combined semi-supervised classification and clustering. Lars Schmarje, Monty Santarossa, Simon-Martin Schr\u00f6der, Claudius Zelenka, Rainer Kiko, Jenny Stracke, Nina Volkmann, Reinhard Koch, Proceedings of the European Conference on Computer Vision (ECCV). the European Conference on Computer Vision (ECCV)2022Lars Schmarje, Monty Santarossa, Simon-Martin Schr\u00f6der, Claudius Zelenka, Rainer Kiko, Jenny Stracke, Nina Volkmann, and Reinhard Koch. A data-centric approach for improving ambiguous labels with combined semi-supervised classification and clustering. Proceedings of the European Conference on Computer Vision (ECCV), 2022.\n\nT Schoening, Purser, Langenk\u00e4mper, Suck, Taylor, Cuvelier, Lins, Y Simon-Lled\u00f3, D O B Marcon, T Jones, Nattkemper, M K\u00f6ser, Zurowietz, J Greinert, Gomes-Pereira, doi: 10. 5194/bg-17-3115-2020Megafauna community assessment of polymetallic-nodule fields with cameras: platform and methodology comparison. 17T Schoening, A Purser, D Langenk\u00e4mper, I Suck, J Taylor, D Cuvelier, L Lins, E Simon- Lled\u00f3, Y Marcon, D O B Jones, T Nattkemper, K K\u00f6ser, M Zurowietz, J Greinert, and J Gomes-Pereira. Megafauna community assessment of polymetallic-nodule fields with cameras: platform and methodology comparison. Biogeosciences, 17(12):3115-3133, 2020. doi: 10. 5194/bg-17-3115-2020.\n\nInstance-based generalization for human judgments about uncertainty. Philipp Schustek, Rub\u00e9n Moreno-Bote, 10.1371/journal.pcbi.1006205PLOS Computational Biology. 1461006205Philipp Schustek and Rub\u00e9n Moreno-Bote. Instance-based generalization for human judgments about uncertainty. PLOS Computational Biology, 14(6):e1006205, jun 2018. ISSN 1553-7358. doi: 10.1371/journal.pcbi.1006205. URL https://dx.plos.org/10.1371/journal.pcbi. 1006205.\n\nFixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence. Kihyuk Sohn, David Berthelot, Chun-Liang Li, Zizhao Zhang, Nicholas Carlini, Ekin D Cubuk, Alex Kurakin, Han Zhang, Colin Raffel, Advances in Neural Information Processing Systems. 332020Kihyuk Sohn, David Berthelot, Chun-Liang Li, Zizhao Zhang, Nicholas Carlini, Ekin D. Cubuk, Alex Kurakin, Han Zhang, and Colin Raffel. FixMatch: Simplifying Semi-Supervised Learning with Consistency and Confidence. Advances in Neural Information Processing Systems 33 pre-proceedings (NeurIPS 2020), 2020.\n\nHwanjun Song, Minseok Kim, Dongmin Park, Jae-Gil Lee, Yooju Shin, Jae-Gil Lee, 2162-237X. doi: 10.1109/ TNNLS.2022.3152527Learning From Noisy Labels With Deep Neural Networks: A Survey. IEEE Transactions on Neural Networks and Learning Systems. Hwanjun Song, Minseok Kim, Dongmin Park, Jae-Gil Lee, Yooju Shin, and Jae-Gil Lee. Learning From Noisy Labels With Deep Neural Networks: A Survey. IEEE Transactions on Neural Networks and Learning Systems, pages 1-19, 2022. ISSN 2162-237X. doi: 10.1109/ TNNLS.2022.3152527.\n\nFusion of Deep Convolutional Neural Networks for No-Reference Magnetic Resonance Image Quality Assessment. Igor St\u0229pie\u0144, Rafa\u0142 Obuchowicz, Adam Pi\u00f3rkowski, Mariusz Oszust, 10.3390/s21041043Sensors. 214Igor St\u0229pie\u0144, Rafa\u0142 Obuchowicz, Adam Pi\u00f3rkowski, and Mariusz Oszust. Fusion of Deep Con- volutional Neural Networks for No-Reference Magnetic Resonance Image Quality Assessment. Sensors, 21(4), 2021. ISSN 1424-8220. doi: 10.3390/s21041043.\n\nMean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results. Antti Tarvainen, Harri Valpola, Antti Tarvainen and Harri Valpola. Mean teachers are better role models: Weight-averaged consistency targets improve semi-supervised deep learning results. In ICLR, 2017.\n\nLearning from Disagreement: A Survey. Alexandra N Uma, Tommaso Fornaciari, Dirk Hovy, Silviu Paun, Barbara Plank, Massimo Poesio, 10.1613/jair.1.12752Journal of Artificial Intelligence Research. 72Alexandra N. Uma, Tommaso Fornaciari, Dirk Hovy, Silviu Paun, Barbara Plank, and Massimo Poesio. Learning from Disagreement: A Survey. Journal of Artificial Intelligence Research, 72: 1385-1470, 2021. ISSN 1076-9757. doi: 10.1613/jair.1.12752.\n\nA Deeper Look into Aleatoric and Epistemic Uncertainty Disentanglement. Matias Valdenegro, - Toro, Daniel Saromo, Matias Valdenegro-Toro and Daniel Saromo. A Deeper Look into Aleatoric and Epistemic Uncertainty Disentanglement. 2022.\n\nSo much trouble in the herd: Detection of first signs of cannibalism in turkeys. Nina Volkmann, Johannes Br\u00fcnger, Jenny Stracke, Claudius Zelenka, Reinhard Koch, Nicole Kemper, Birgit Spindler, Recent advances in animal welfare science VII Virtual UFAW Animal Welfare Conference. 82Nina Volkmann, Johannes Br\u00fcnger, Jenny Stracke, Claudius Zelenka, Reinhard Koch, Nicole Kemper, and Birgit Spindler. So much trouble in the herd: Detection of first signs of cannibalism in turkeys. In Recent advances in animal welfare science VII Virtual UFAW Animal Welfare Conference, page 82, 2020.\n\nLearn to train: Improving training data for a neural network to detect pecking injuries in turkeys. Nina Volkmann, Johannes Br\u00fcnger, Jenny Stracke, Claudius Zelenka, Reinhard Koch, Nicole Kemper, Birgit Spindler, 10.3390/ani1109265511Nina Volkmann, Johannes Br\u00fcnger, Jenny Stracke, Claudius Zelenka, Reinhard Koch, Nicole Kemper, and Birgit Spindler. Learn to train: Improving training data for a neural network to detect pecking injuries in turkeys. Animals 2021, 11:1-13, 2021. doi: 10.3390/ani11092655.\n\nKeypoint Detection for Injury Identification during Turkey Husbandry Using Neural Networks. Nina Volkmann, Claudius Zelenka, Archana Malavalli Devaraju, Johannes Br\u00fcnger, Jenny Stracke, Birgit Spindler, Nicole Kemper, Reinhard Koch, 10.3390/s22145188Sensors. 22145188Nina Volkmann, Claudius Zelenka, Archana Malavalli Devaraju, Johannes Br\u00fcnger, Jenny Stracke, Birgit Spindler, Nicole Kemper, and Reinhard Koch. Keypoint Detection for Injury Identification during Turkey Husbandry Using Neural Networks. Sensors, 22(14):5188, 2022. ISSN 1424-8220. doi: 10.3390/s22145188.\n\nSemiNLL: A Framework of Noisy-Label Learning by Semi-Supervised Learning. Zhuowei Wang, Jing Jiang, Bo Han, Lei Feng, Bo An, Gang Niu, Guodong Long, Zhuowei Wang, Jing Jiang, Bo Han, Lei Feng, Bo An, Gang Niu, and Guodong Long. SemiNLL: A Framework of Noisy-Label Learning by Semi-Supervised Learning. 2020.\n\nLearning with Noisy Labels Revisited: A Study Using Real-World Human Annotations. Jiaheng Wei, Zhaowei Zhu, Hao Cheng, Tongliang Liu, Gang Niu, Yang Liu, Jiaheng Wei, Zhaowei Zhu, Hao Cheng, Tongliang Liu, Gang Niu, and Yang Liu. Learning with Noisy Labels Revisited: A Study Using Real-World Human Annotations. 2021.\n\nSearching to exploit memorization effect in learning from corrupted labels. Quanming Yao, Hansi Yang, Bo Han, Gang Niu, James Kwok, arXiv:1911.02377arXiv preprintQuanming Yao, Hansi Yang, Bo Han, Gang Niu, and James Kwok. Searching to exploit memorization effect in learning from corrupted labels. arXiv preprint arXiv:1911.02377, 2019.\n\nHow does disagreement help generalization against label corruption. Xingrui Yu, Bo Han, Jiangchao Yao, Gang Niu, Ivor Tsang, Masashi Sugiyama, International Conference on Machine Learning. PMLRXingrui Yu, Bo Han, Jiangchao Yao, Gang Niu, Ivor Tsang, and Masashi Sugiyama. How does disagreement help generalization against label corruption? In International Conference on Machine Learning, pages 7164-7173. PMLR, 2019.\n\nRe-Labeling ImageNet: From Single to Multi-Labels, From Global to Localized Labels. Sangdoo Yun, Byeongho Seong Joon Oh, Dongyoon Heo, Junsuk Han, Sanghyuk Choe, Chun, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)Sangdoo Yun, Seong Joon Oh, Byeongho Heo, Dongyoon Han, Junsuk Choe, and Sanghyuk Chun. Re-Labeling ImageNet: From Single to Multi-Labels, From Global to Localized Labels. In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), pages 2340-2350, 2021.\n\nCoDiM: Learning with Noisy Labels via Contrastive Semi-Supervised Learning. Xin Zhang, Zixuan Liu, Kaiwen Xiao, Tian Shen, Junzhou Huang, Wei Yang, Dimitris Samaras, Xiao Han, Xin Zhang, Zixuan Liu, Kaiwen Xiao, Tian Shen, Junzhou Huang, Wei Yang, Dimitris Samaras, and Xiao Han. CoDiM: Learning with Noisy Labels via Contrastive Semi-Supervised Learning. 2021.\n\nDistilling Effective Supervision from Severe Label Noise. Zizhao Zhang, Han Zhang, O Sercan, Honglak Arik, Tomas Lee, Pfister, Conference on Computer Vision and Pattern Recognition. Zizhao Zhang, Han Zhang, Sercan O. Arik, Honglak Lee, and Tomas Pfister. Distilling Effective Supervision from Severe Label Noise. Conference on Computer Vision and Pattern Recognition, 2020.\n", "annotations": {"author": "[{\"end\":152,\"start\":116},{\"end\":191,\"start\":153},{\"end\":231,\"start\":192},{\"end\":280,\"start\":232},{\"end\":319,\"start\":281},{\"end\":370,\"start\":320},{\"end\":453,\"start\":371},{\"end\":489,\"start\":454},{\"end\":502,\"start\":490},{\"end\":517,\"start\":503},{\"end\":554,\"start\":518},{\"end\":605,\"start\":555}]", "publisher": null, "author_last_name": "[{\"end\":129,\"start\":121},{\"end\":168,\"start\":159},{\"end\":208,\"start\":201},{\"end\":245,\"start\":239},{\"end\":292,\"start\":288},{\"end\":334,\"start\":328},{\"end\":384,\"start\":377},{\"end\":467,\"start\":460},{\"end\":501,\"start\":495},{\"end\":516,\"start\":508},{\"end\":531,\"start\":527}]", "author_first_name": "[{\"end\":120,\"start\":116},{\"end\":158,\"start\":153},{\"end\":200,\"start\":192},{\"end\":238,\"start\":232},{\"end\":287,\"start\":281},{\"end\":327,\"start\":320},{\"end\":376,\"start\":371},{\"end\":459,\"start\":454},{\"end\":494,\"start\":490},{\"end\":507,\"start\":503},{\"end\":526,\"start\":518}]", "author_affiliation": "[{\"end\":151,\"start\":131},{\"end\":190,\"start\":170},{\"end\":230,\"start\":210},{\"end\":279,\"start\":247},{\"end\":318,\"start\":294},{\"end\":369,\"start\":336},{\"end\":415,\"start\":386},{\"end\":452,\"start\":417},{\"end\":488,\"start\":469},{\"end\":553,\"start\":533},{\"end\":604,\"start\":556}]", "title": "[{\"end\":113,\"start\":1},{\"end\":718,\"start\":606}]", "venue": null, "abstract": "[{\"end\":2433,\"start\":742}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b7\"},\"end\":2564,\"start\":2561},{\"attributes\":{\"ref_id\":\"b79\"},\"end\":2567,\"start\":2564},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":2570,\"start\":2567},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":2900,\"start\":2896},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":2903,\"start\":2900},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":2906,\"start\":2903},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":2909,\"start\":2906},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":2912,\"start\":2909},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":2914,\"start\":2912},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":2917,\"start\":2914},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":2920,\"start\":2917},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":3127,\"start\":3123},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":3232,\"start\":3228},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":3386,\"start\":3382},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":3900,\"start\":3896},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":3903,\"start\":3900},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":3906,\"start\":3903},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":3909,\"start\":3906},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":4641,\"start\":4637},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":4644,\"start\":4641},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":5984,\"start\":5980},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":6886,\"start\":6883},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":6903,\"start\":6899},{\"attributes\":{\"ref_id\":\"b65\"},\"end\":9150,\"start\":9146},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":9315,\"start\":9311},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":9317,\"start\":9315},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":9320,\"start\":9317},{\"attributes\":{\"ref_id\":\"b76\"},\"end\":9323,\"start\":9320},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":9325,\"start\":9323},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":9555,\"start\":9551},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":9704,\"start\":9700},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":9707,\"start\":9704},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":9710,\"start\":9707},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":9712,\"start\":9710},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":9859,\"start\":9855},{\"attributes\":{\"ref_id\":\"b77\"},\"end\":10094,\"start\":10090},{\"attributes\":{\"ref_id\":\"b78\"},\"end\":10097,\"start\":10094},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":10200,\"start\":10196},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":10273,\"start\":10269},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":10359,\"start\":10355},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":10362,\"start\":10359},{\"attributes\":{\"ref_id\":\"b76\"},\"end\":10496,\"start\":10492},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":10638,\"start\":10634},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":10863,\"start\":10859},{\"attributes\":{\"ref_id\":\"b76\"},\"end\":10882,\"start\":10878},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":11402,\"start\":11398},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":11404,\"start\":11402},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":11407,\"start\":11404},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":11707,\"start\":11703},{\"attributes\":{\"ref_id\":\"b66\"},\"end\":11710,\"start\":11707},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":11713,\"start\":11710},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":11716,\"start\":11713},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":12047,\"start\":12043},{\"attributes\":{\"ref_id\":\"b80\"},\"end\":12050,\"start\":12047},{\"attributes\":{\"ref_id\":\"b75\"},\"end\":12053,\"start\":12050},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":12447,\"start\":12443},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":12449,\"start\":12447},{\"attributes\":{\"ref_id\":\"b71\"},\"end\":12452,\"start\":12449},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":12455,\"start\":12452},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":12560,\"start\":12556},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":12563,\"start\":12560},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":12566,\"start\":12563},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":12633,\"start\":12629},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":12714,\"start\":12710},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":12717,\"start\":12714},{\"attributes\":{\"ref_id\":\"b76\"},\"end\":12720,\"start\":12717},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":12723,\"start\":12720},{\"attributes\":{\"ref_id\":\"b81\"},\"end\":12726,\"start\":12723},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":12868,\"start\":12864},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":13002,\"start\":12998},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":13027,\"start\":13023},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":13138,\"start\":13134},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":13278,\"start\":13274},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":13605,\"start\":13601},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":14659,\"start\":14655},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":17504,\"start\":17500},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":17662,\"start\":17658},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":18518,\"start\":18514},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":18778,\"start\":18774},{\"attributes\":{\"ref_id\":\"b64\"},\"end\":19887,\"start\":19883},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":19890,\"start\":19887},{\"attributes\":{\"ref_id\":\"b76\"},\"end\":20068,\"start\":20064},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":20209,\"start\":20205},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":20264,\"start\":20260},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":20697,\"start\":20693},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":20741,\"start\":20737},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":20946,\"start\":20942},{\"attributes\":{\"ref_id\":\"b68\"},\"end\":20949,\"start\":20946},{\"attributes\":{\"ref_id\":\"b73\"},\"end\":21954,\"start\":21950},{\"attributes\":{\"ref_id\":\"b74\"},\"end\":21957,\"start\":21954},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":22002,\"start\":21998},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":22694,\"start\":22690},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":22705,\"start\":22701},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":22720,\"start\":22716},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":22771,\"start\":22767},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":22785,\"start\":22781},{\"attributes\":{\"ref_id\":\"b66\"},\"end\":22800,\"start\":22796},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":22810,\"start\":22806},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":22829,\"start\":22825},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":22849,\"start\":22845},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":22892,\"start\":22888},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":22905,\"start\":22901},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":22918,\"start\":22914},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":22933,\"start\":22929},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":22993,\"start\":22989},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":23103,\"start\":23099},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":23121,\"start\":23117},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":23228,\"start\":23224},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":24046,\"start\":24043},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":26895,\"start\":26891},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":27858,\"start\":27854},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":27861,\"start\":27858},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":27863,\"start\":27861},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":28553,\"start\":28549},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":28556,\"start\":28553},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":29857,\"start\":29853},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":29909,\"start\":29905},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":29912,\"start\":29909},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":31557,\"start\":31555},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":32132,\"start\":32128},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":32135,\"start\":32132},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":32138,\"start\":32135},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":32140,\"start\":32138},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":33057,\"start\":33053},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":33071,\"start\":33067}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":37272,\"start\":37164},{\"attributes\":{\"id\":\"fig_2\"},\"end\":37482,\"start\":37273},{\"attributes\":{\"id\":\"fig_3\"},\"end\":37634,\"start\":37483},{\"attributes\":{\"id\":\"fig_4\"},\"end\":38305,\"start\":37635},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":39567,\"start\":38306},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":41164,\"start\":39568},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":41370,\"start\":41165}]", "paragraph": "[{\"end\":3128,\"start\":2449},{\"end\":4470,\"start\":3130},{\"end\":4955,\"start\":4472},{\"end\":6439,\"start\":4957},{\"end\":7931,\"start\":6441},{\"end\":8889,\"start\":7933},{\"end\":9786,\"start\":8906},{\"end\":10833,\"start\":9788},{\"end\":11518,\"start\":10835},{\"end\":12194,\"start\":11520},{\"end\":13474,\"start\":12196},{\"end\":13856,\"start\":13488},{\"end\":14246,\"start\":13858},{\"end\":15206,\"start\":14248},{\"end\":15516,\"start\":15208},{\"end\":15884,\"start\":15518},{\"end\":17457,\"start\":15886},{\"end\":17780,\"start\":17459},{\"end\":18909,\"start\":17907},{\"end\":19768,\"start\":18911},{\"end\":22105,\"start\":19770},{\"end\":23461,\"start\":22107},{\"end\":23629,\"start\":23463},{\"end\":24889,\"start\":23656},{\"end\":26249,\"start\":24902},{\"end\":27213,\"start\":26251},{\"end\":28759,\"start\":27215},{\"end\":31111,\"start\":28761},{\"end\":31666,\"start\":31113},{\"end\":31854,\"start\":31681},{\"end\":32630,\"start\":31856},{\"end\":34196,\"start\":32632},{\"end\":34905,\"start\":34198},{\"end\":36294,\"start\":34907},{\"end\":36969,\"start\":36296},{\"end\":37163,\"start\":36971}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":17906,\"start\":17781}]", "table_ref": "[{\"end\":6438,\"start\":6431},{\"end\":16354,\"start\":16347},{\"end\":19358,\"start\":19351},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":23048,\"start\":23041},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":25327,\"start\":25320},{\"end\":25348,\"start\":25341},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":28923,\"start\":28915},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":29291,\"start\":29283},{\"end\":30743,\"start\":30736}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2447,\"start\":2435},{\"attributes\":{\"n\":\"1.1\"},\"end\":8904,\"start\":8892},{\"attributes\":{\"n\":\"2\"},\"end\":13486,\"start\":13477},{\"end\":23654,\"start\":23632},{\"attributes\":{\"n\":\"3\"},\"end\":24900,\"start\":24892},{\"attributes\":{\"n\":\"4\"},\"end\":31679,\"start\":31669},{\"end\":37175,\"start\":37165},{\"end\":37275,\"start\":37274},{\"end\":37487,\"start\":37484},{\"end\":37661,\"start\":37636},{\"end\":39578,\"start\":39569},{\"end\":41175,\"start\":41166}]", "table": "[{\"end\":39567,\"start\":38485},{\"end\":41164,\"start\":40030},{\"end\":41370,\"start\":41365}]", "figure_caption": "[{\"end\":37272,\"start\":37177},{\"end\":37482,\"start\":37276},{\"end\":37634,\"start\":37489},{\"end\":38305,\"start\":37665},{\"end\":38485,\"start\":38308},{\"end\":40030,\"start\":39580},{\"end\":41365,\"start\":41177}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":3141,\"start\":3133},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":4248,\"start\":4240},{\"end\":4573,\"start\":4564},{\"end\":5516,\"start\":5507},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":5808,\"start\":5800},{\"end\":7261,\"start\":7253},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":19371,\"start\":19363},{\"end\":26543,\"start\":26535},{\"end\":27358,\"start\":27349},{\"end\":29213,\"start\":29204},{\"end\":31206,\"start\":31197}]", "bib_author_first_name": "[{\"end\":43134,\"start\":43128},{\"end\":43161,\"start\":43157},{\"end\":43177,\"start\":43170},{\"end\":43191,\"start\":43184},{\"end\":43202,\"start\":43198},{\"end\":43217,\"start\":43210},{\"end\":43232,\"start\":43224},{\"end\":43246,\"start\":43240},{\"end\":43265,\"start\":43257},{\"end\":43281,\"start\":43274},{\"end\":43298,\"start\":43289},{\"end\":43311,\"start\":43307},{\"end\":43329,\"start\":43324},{\"end\":43343,\"start\":43337},{\"end\":43356,\"start\":43351},{\"end\":43371,\"start\":43365},{\"end\":43385,\"start\":43381},{\"end\":43399,\"start\":43394},{\"end\":43415,\"start\":43411},{\"end\":43430,\"start\":43424},{\"end\":43442,\"start\":43438},{\"end\":44154,\"start\":44148},{\"end\":44168,\"start\":44162},{\"end\":44185,\"start\":44180},{\"end\":44199,\"start\":44195},{\"end\":44215,\"start\":44213},{\"end\":44229,\"start\":44221},{\"end\":44247,\"start\":44243},{\"end\":44265,\"start\":44257},{\"end\":44276,\"start\":44271},{\"end\":44288,\"start\":44287},{\"end\":44297,\"start\":44289},{\"end\":44315,\"start\":44307},{\"end\":44333,\"start\":44328},{\"end\":44899,\"start\":44898},{\"end\":44903,\"start\":44900},{\"end\":44914,\"start\":44913},{\"end\":44916,\"start\":44915},{\"end\":44927,\"start\":44926},{\"end\":44939,\"start\":44938},{\"end\":44947,\"start\":44946},{\"end\":44954,\"start\":44953},{\"end\":44963,\"start\":44962},{\"end\":44972,\"start\":44971},{\"end\":44987,\"start\":44986},{\"end\":45000,\"start\":44999},{\"end\":45008,\"start\":45007},{\"end\":45010,\"start\":45009},{\"end\":45026,\"start\":45025},{\"end\":45036,\"start\":45035},{\"end\":45040,\"start\":45037},{\"end\":45054,\"start\":45053},{\"end\":45678,\"start\":45672},{\"end\":45691,\"start\":45686},{\"end\":45947,\"start\":45941},{\"end\":45970,\"start\":45963},{\"end\":45987,\"start\":45979},{\"end\":46002,\"start\":45999},{\"end\":46403,\"start\":46396},{\"end\":46419,\"start\":46412},{\"end\":46433,\"start\":46426},{\"end\":46450,\"start\":46446},{\"end\":46463,\"start\":46457},{\"end\":46800,\"start\":46795},{\"end\":46817,\"start\":46811},{\"end\":46831,\"start\":46826},{\"end\":47131,\"start\":47126},{\"end\":47146,\"start\":47139},{\"end\":47148,\"start\":47147},{\"end\":47166,\"start\":47157},{\"end\":47529,\"start\":47528},{\"end\":47548,\"start\":47547},{\"end\":47896,\"start\":47888},{\"end\":47909,\"start\":47904},{\"end\":47922,\"start\":47917},{\"end\":47935,\"start\":47930},{\"end\":47954,\"start\":47948},{\"end\":47969,\"start\":47963},{\"end\":48457,\"start\":48453},{\"end\":48469,\"start\":48464},{\"end\":48489,\"start\":48481},{\"end\":48507,\"start\":48499},{\"end\":48834,\"start\":48830},{\"end\":48846,\"start\":48841},{\"end\":48863,\"start\":48858},{\"end\":48881,\"start\":48873},{\"end\":48899,\"start\":48891},{\"end\":49209,\"start\":49203},{\"end\":49221,\"start\":49216},{\"end\":49586,\"start\":49582},{\"end\":49601,\"start\":49596},{\"end\":49614,\"start\":49611},{\"end\":49636,\"start\":49628},{\"end\":49652,\"start\":49647},{\"end\":49983,\"start\":49979},{\"end\":49998,\"start\":49993},{\"end\":50011,\"start\":50008},{\"end\":50033,\"start\":50025},{\"end\":50049,\"start\":50044},{\"end\":50572,\"start\":50568},{\"end\":50592,\"start\":50586},{\"end\":50610,\"start\":50603},{\"end\":50627,\"start\":50620},{\"end\":50643,\"start\":50635},{\"end\":51068,\"start\":51064},{\"end\":51081,\"start\":51069},{\"end\":51094,\"start\":51090},{\"end\":51111,\"start\":51101},{\"end\":51377,\"start\":51370},{\"end\":51393,\"start\":51387},{\"end\":51395,\"start\":51394},{\"end\":51414,\"start\":51404},{\"end\":51440,\"start\":51431},{\"end\":51455,\"start\":51450},{\"end\":51468,\"start\":51465},{\"end\":51485,\"start\":51480},{\"end\":51500,\"start\":51494},{\"end\":51516,\"start\":51509},{\"end\":51532,\"start\":51526},{\"end\":51568,\"start\":51561},{\"end\":51584,\"start\":51578},{\"end\":51601,\"start\":51595},{\"end\":52026,\"start\":52019},{\"end\":52047,\"start\":52039},{\"end\":52302,\"start\":52295},{\"end\":52316,\"start\":52308},{\"end\":52329,\"start\":52322},{\"end\":52343,\"start\":52336},{\"end\":52354,\"start\":52349},{\"end\":52366,\"start\":52362},{\"end\":52383,\"start\":52376},{\"end\":52398,\"start\":52393},{\"end\":52413,\"start\":52409},{\"end\":52427,\"start\":52422},{\"end\":52429,\"start\":52428},{\"end\":52752,\"start\":52740},{\"end\":52767,\"start\":52760},{\"end\":52782,\"start\":52775},{\"end\":52799,\"start\":52791},{\"end\":52814,\"start\":52808},{\"end\":52816,\"start\":52815},{\"end\":52833,\"start\":52828},{\"end\":52851,\"start\":52847},{\"end\":52869,\"start\":52861},{\"end\":52890,\"start\":52883},{\"end\":52897,\"start\":52891},{\"end\":52911,\"start\":52903},{\"end\":52922,\"start\":52912},{\"end\":52934,\"start\":52929},{\"end\":52946,\"start\":52941},{\"end\":52964,\"start\":52960},{\"end\":52978,\"start\":52972},{\"end\":53461,\"start\":53457},{\"end\":53487,\"start\":53479},{\"end\":53865,\"start\":53860},{\"end\":53876,\"start\":53871},{\"end\":53887,\"start\":53885},{\"end\":53901,\"start\":53893},{\"end\":54189,\"start\":54181},{\"end\":54199,\"start\":54195},{\"end\":54213,\"start\":54205},{\"end\":54592,\"start\":54588},{\"end\":54906,\"start\":54898},{\"end\":54920,\"start\":54915},{\"end\":54934,\"start\":54930},{\"end\":55046,\"start\":55041},{\"end\":55063,\"start\":55057},{\"end\":55079,\"start\":55072},{\"end\":55081,\"start\":55080},{\"end\":55111,\"start\":55091},{\"end\":55555,\"start\":55550},{\"end\":55570,\"start\":55563},{\"end\":55582,\"start\":55578},{\"end\":55597,\"start\":55590},{\"end\":55619,\"start\":55613},{\"end\":55636,\"start\":55630},{\"end\":55652,\"start\":55644},{\"end\":56217,\"start\":56216},{\"end\":56234,\"start\":56231},{\"end\":56252,\"start\":56249},{\"end\":56760,\"start\":56756},{\"end\":56775,\"start\":56770},{\"end\":56961,\"start\":56952},{\"end\":56981,\"start\":56974},{\"end\":56993,\"start\":56988},{\"end\":57419,\"start\":57415},{\"end\":57440,\"start\":57432},{\"end\":57455,\"start\":57449},{\"end\":57669,\"start\":57665},{\"end\":57686,\"start\":57682},{\"end\":57706,\"start\":57698},{\"end\":57708,\"start\":57707},{\"end\":58097,\"start\":58092},{\"end\":58117,\"start\":58111},{\"end\":58316,\"start\":58315},{\"end\":58330,\"start\":58327},{\"end\":58573,\"start\":58567},{\"end\":58585,\"start\":58581},{\"end\":58888,\"start\":58882},{\"end\":58908,\"start\":58903},{\"end\":58928,\"start\":58923},{\"end\":58940,\"start\":58937},{\"end\":58942,\"start\":58941},{\"end\":59371,\"start\":59362},{\"end\":59727,\"start\":59717},{\"end\":59741,\"start\":59733},{\"end\":59749,\"start\":59746},{\"end\":59763,\"start\":59757},{\"end\":60232,\"start\":60226},{\"end\":60244,\"start\":60237},{\"end\":60259,\"start\":60253},{\"end\":60263,\"start\":60260},{\"end\":60587,\"start\":60584},{\"end\":60597,\"start\":60592},{\"end\":60607,\"start\":60604},{\"end\":60619,\"start\":60612},{\"end\":60634,\"start\":60631},{\"end\":60867,\"start\":60859},{\"end\":60875,\"start\":60872},{\"end\":60891,\"start\":60883},{\"end\":61567,\"start\":61559},{\"end\":61575,\"start\":61573},{\"end\":61588,\"start\":61581},{\"end\":61602,\"start\":61596},{\"end\":61614,\"start\":61609},{\"end\":61621,\"start\":61615},{\"end\":61635,\"start\":61629},{\"end\":62107,\"start\":62102},{\"end\":62121,\"start\":62113},{\"end\":62140,\"start\":62134},{\"end\":62157,\"start\":62151},{\"end\":62429,\"start\":62425},{\"end\":62444,\"start\":62437},{\"end\":62446,\"start\":62445},{\"end\":62654,\"start\":62653},{\"end\":62865,\"start\":62857},{\"end\":62883,\"start\":62876},{\"end\":62899,\"start\":62896},{\"end\":63174,\"start\":63173},{\"end\":63287,\"start\":63280},{\"end\":63298,\"start\":63294},{\"end\":63309,\"start\":63305},{\"end\":63324,\"start\":63319},{\"end\":63336,\"start\":63335},{\"end\":63355,\"start\":63346},{\"end\":63375,\"start\":63368},{\"end\":63392,\"start\":63386},{\"end\":63408,\"start\":63400},{\"end\":63867,\"start\":63861},{\"end\":63869,\"start\":63868},{\"end\":63886,\"start\":63881},{\"end\":63901,\"start\":63896},{\"end\":64422,\"start\":64417},{\"end\":64442,\"start\":64435},{\"end\":64455,\"start\":64451},{\"end\":64812,\"start\":64811},{\"end\":64814,\"start\":64813},{\"end\":64822,\"start\":64821},{\"end\":64824,\"start\":64823},{\"end\":64838,\"start\":64837},{\"end\":64842,\"start\":64839},{\"end\":64855,\"start\":64854},{\"end\":64865,\"start\":64864},{\"end\":64877,\"start\":64876},{\"end\":64879,\"start\":64878},{\"end\":64889,\"start\":64888},{\"end\":64891,\"start\":64890},{\"end\":65293,\"start\":65289},{\"end\":65305,\"start\":65302},{\"end\":65322,\"start\":65313},{\"end\":65334,\"start\":65330},{\"end\":65347,\"start\":65342},{\"end\":65365,\"start\":65358},{\"end\":65380,\"start\":65374},{\"end\":65396,\"start\":65390},{\"end\":65409,\"start\":65402},{\"end\":65426,\"start\":65422},{\"end\":65440,\"start\":65435},{\"end\":65459,\"start\":65452},{\"end\":65472,\"start\":65466},{\"end\":65486,\"start\":65479},{\"end\":65501,\"start\":65495},{\"end\":65517,\"start\":65510},{\"end\":65532,\"start\":65526},{\"end\":65553,\"start\":65547},{\"end\":65565,\"start\":65563},{\"end\":65578,\"start\":65572},{\"end\":65591,\"start\":65584},{\"end\":66228,\"start\":66222},{\"end\":66247,\"start\":66239},{\"end\":66265,\"start\":66259},{\"end\":66281,\"start\":66277},{\"end\":66833,\"start\":66829},{\"end\":66847,\"start\":66843},{\"end\":66852,\"start\":66848},{\"end\":66863,\"start\":66858},{\"end\":66879,\"start\":66873},{\"end\":66895,\"start\":66888},{\"end\":66909,\"start\":66901},{\"end\":66925,\"start\":66919},{\"end\":66940,\"start\":66934},{\"end\":66955,\"start\":66949},{\"end\":66969,\"start\":66965},{\"end\":66985,\"start\":66977},{\"end\":66999,\"start\":66995},{\"end\":67356,\"start\":67353},{\"end\":67370,\"start\":67367},{\"end\":67388,\"start\":67382},{\"end\":67403,\"start\":67398},{\"end\":67418,\"start\":67413},{\"end\":67854,\"start\":67848},{\"end\":67856,\"start\":67855},{\"end\":67880,\"start\":67868},{\"end\":67895,\"start\":67888},{\"end\":67912,\"start\":67904},{\"end\":67928,\"start\":67921},{\"end\":67942,\"start\":67936},{\"end\":67956,\"start\":67950},{\"end\":68419,\"start\":68411},{\"end\":68436,\"start\":68435},{\"end\":68454,\"start\":68448},{\"end\":68456,\"start\":68455},{\"end\":68714,\"start\":68709},{\"end\":68731,\"start\":68727},{\"end\":68744,\"start\":68739},{\"end\":68758,\"start\":68754},{\"end\":68777,\"start\":68769},{\"end\":68794,\"start\":68788},{\"end\":68812,\"start\":68804},{\"end\":68829,\"start\":68823},{\"end\":69299,\"start\":69295},{\"end\":69318,\"start\":69310},{\"end\":69331,\"start\":69328},{\"end\":69342,\"start\":69340},{\"end\":69358,\"start\":69350},{\"end\":69882,\"start\":69878},{\"end\":69901,\"start\":69893},{\"end\":69916,\"start\":69911},{\"end\":69941,\"start\":69929},{\"end\":69958,\"start\":69952},{\"end\":69973,\"start\":69965},{\"end\":70395,\"start\":70391},{\"end\":70415,\"start\":70406},{\"end\":70430,\"start\":70422},{\"end\":70660,\"start\":70656},{\"end\":70676,\"start\":70671},{\"end\":70701,\"start\":70689},{\"end\":70720,\"start\":70712},{\"end\":70739,\"start\":70727},{\"end\":70758,\"start\":70750},{\"end\":70777,\"start\":70765},{\"end\":70796,\"start\":70788},{\"end\":71271,\"start\":71267},{\"end\":71287,\"start\":71282},{\"end\":71312,\"start\":71300},{\"end\":71331,\"start\":71323},{\"end\":71347,\"start\":71341},{\"end\":71359,\"start\":71354},{\"end\":71373,\"start\":71369},{\"end\":71392,\"start\":71384},{\"end\":71844,\"start\":71843},{\"end\":71909,\"start\":71908},{\"end\":71928,\"start\":71923},{\"end\":71938,\"start\":71937},{\"end\":71959,\"start\":71958},{\"end\":71979,\"start\":71978},{\"end\":72593,\"start\":72586},{\"end\":72609,\"start\":72604},{\"end\":73045,\"start\":73039},{\"end\":73057,\"start\":73052},{\"end\":73079,\"start\":73069},{\"end\":73090,\"start\":73084},{\"end\":73106,\"start\":73098},{\"end\":73120,\"start\":73116},{\"end\":73122,\"start\":73121},{\"end\":73134,\"start\":73130},{\"end\":73147,\"start\":73144},{\"end\":73160,\"start\":73155},{\"end\":73540,\"start\":73533},{\"end\":73554,\"start\":73547},{\"end\":73567,\"start\":73560},{\"end\":73581,\"start\":73574},{\"end\":73592,\"start\":73587},{\"end\":73606,\"start\":73599},{\"end\":74164,\"start\":74160},{\"end\":74179,\"start\":74174},{\"end\":74196,\"start\":74192},{\"end\":74216,\"start\":74209},{\"end\":74621,\"start\":74616},{\"end\":74638,\"start\":74633},{\"end\":74867,\"start\":74858},{\"end\":74869,\"start\":74868},{\"end\":74882,\"start\":74875},{\"end\":74899,\"start\":74895},{\"end\":74912,\"start\":74906},{\"end\":74926,\"start\":74919},{\"end\":74941,\"start\":74934},{\"end\":75340,\"start\":75334},{\"end\":75354,\"start\":75353},{\"end\":75367,\"start\":75361},{\"end\":75582,\"start\":75578},{\"end\":75601,\"start\":75593},{\"end\":75616,\"start\":75611},{\"end\":75634,\"start\":75626},{\"end\":75652,\"start\":75644},{\"end\":75665,\"start\":75659},{\"end\":75680,\"start\":75674},{\"end\":76186,\"start\":76182},{\"end\":76205,\"start\":76197},{\"end\":76220,\"start\":76215},{\"end\":76238,\"start\":76230},{\"end\":76256,\"start\":76248},{\"end\":76269,\"start\":76263},{\"end\":76284,\"start\":76278},{\"end\":76685,\"start\":76681},{\"end\":76704,\"start\":76696},{\"end\":76721,\"start\":76714},{\"end\":76731,\"start\":76722},{\"end\":76750,\"start\":76742},{\"end\":76765,\"start\":76760},{\"end\":76781,\"start\":76775},{\"end\":76798,\"start\":76792},{\"end\":76815,\"start\":76807},{\"end\":77243,\"start\":77236},{\"end\":77254,\"start\":77250},{\"end\":77264,\"start\":77262},{\"end\":77273,\"start\":77270},{\"end\":77282,\"start\":77280},{\"end\":77291,\"start\":77287},{\"end\":77304,\"start\":77297},{\"end\":77560,\"start\":77553},{\"end\":77573,\"start\":77566},{\"end\":77582,\"start\":77579},{\"end\":77599,\"start\":77590},{\"end\":77609,\"start\":77605},{\"end\":77619,\"start\":77615},{\"end\":77874,\"start\":77866},{\"end\":77885,\"start\":77880},{\"end\":77894,\"start\":77892},{\"end\":77904,\"start\":77900},{\"end\":77915,\"start\":77910},{\"end\":78203,\"start\":78196},{\"end\":78210,\"start\":78208},{\"end\":78225,\"start\":78216},{\"end\":78235,\"start\":78231},{\"end\":78245,\"start\":78241},{\"end\":78260,\"start\":78253},{\"end\":78638,\"start\":78631},{\"end\":78652,\"start\":78644},{\"end\":78676,\"start\":78668},{\"end\":78688,\"start\":78682},{\"end\":78702,\"start\":78694},{\"end\":79246,\"start\":79243},{\"end\":79260,\"start\":79254},{\"end\":79272,\"start\":79266},{\"end\":79283,\"start\":79279},{\"end\":79297,\"start\":79290},{\"end\":79308,\"start\":79305},{\"end\":79323,\"start\":79315},{\"end\":79337,\"start\":79333},{\"end\":79594,\"start\":79588},{\"end\":79605,\"start\":79602},{\"end\":79614,\"start\":79613},{\"end\":79630,\"start\":79623},{\"end\":79642,\"start\":79637}]", "bib_author_last_name": "[{\"end\":43155,\"start\":43135},{\"end\":43168,\"start\":43162},{\"end\":43182,\"start\":43178},{\"end\":43196,\"start\":43192},{\"end\":43208,\"start\":43203},{\"end\":43222,\"start\":43218},{\"end\":43238,\"start\":43233},{\"end\":43255,\"start\":43247},{\"end\":43272,\"start\":43266},{\"end\":43287,\"start\":43282},{\"end\":43305,\"start\":43299},{\"end\":43322,\"start\":43312},{\"end\":43335,\"start\":43330},{\"end\":43349,\"start\":43344},{\"end\":43363,\"start\":43357},{\"end\":43379,\"start\":43372},{\"end\":43392,\"start\":43386},{\"end\":43409,\"start\":43400},{\"end\":43422,\"start\":43416},{\"end\":43436,\"start\":43431},{\"end\":43445,\"start\":43443},{\"end\":44160,\"start\":44155},{\"end\":44178,\"start\":44169},{\"end\":44193,\"start\":44186},{\"end\":44211,\"start\":44200},{\"end\":44219,\"start\":44216},{\"end\":44241,\"start\":44230},{\"end\":44255,\"start\":44248},{\"end\":44269,\"start\":44266},{\"end\":44285,\"start\":44277},{\"end\":44305,\"start\":44298},{\"end\":44326,\"start\":44316},{\"end\":44343,\"start\":44334},{\"end\":44911,\"start\":44904},{\"end\":44924,\"start\":44917},{\"end\":44936,\"start\":44928},{\"end\":44944,\"start\":44940},{\"end\":44951,\"start\":44948},{\"end\":44960,\"start\":44955},{\"end\":44969,\"start\":44964},{\"end\":44984,\"start\":44973},{\"end\":44997,\"start\":44988},{\"end\":45005,\"start\":45001},{\"end\":45023,\"start\":45011},{\"end\":45033,\"start\":45027},{\"end\":45051,\"start\":45041},{\"end\":45072,\"start\":45055},{\"end\":45684,\"start\":45679},{\"end\":45698,\"start\":45692},{\"end\":45961,\"start\":45948},{\"end\":45977,\"start\":45971},{\"end\":45997,\"start\":45988},{\"end\":46010,\"start\":46003},{\"end\":46410,\"start\":46404},{\"end\":46424,\"start\":46420},{\"end\":46444,\"start\":46434},{\"end\":46455,\"start\":46451},{\"end\":46468,\"start\":46464},{\"end\":46809,\"start\":46801},{\"end\":46824,\"start\":46818},{\"end\":46835,\"start\":46832},{\"end\":47137,\"start\":47132},{\"end\":47155,\"start\":47149},{\"end\":47177,\"start\":47167},{\"end\":47537,\"start\":47530},{\"end\":47545,\"start\":47539},{\"end\":47553,\"start\":47549},{\"end\":47559,\"start\":47555},{\"end\":47902,\"start\":47897},{\"end\":47915,\"start\":47910},{\"end\":47928,\"start\":47923},{\"end\":47946,\"start\":47936},{\"end\":47961,\"start\":47955},{\"end\":47976,\"start\":47970},{\"end\":48462,\"start\":48458},{\"end\":48479,\"start\":48470},{\"end\":48497,\"start\":48490},{\"end\":48514,\"start\":48508},{\"end\":48839,\"start\":48835},{\"end\":48856,\"start\":48847},{\"end\":48871,\"start\":48864},{\"end\":48889,\"start\":48882},{\"end\":48906,\"start\":48900},{\"end\":49214,\"start\":49210},{\"end\":49225,\"start\":49222},{\"end\":49594,\"start\":49587},{\"end\":49609,\"start\":49602},{\"end\":49626,\"start\":49615},{\"end\":49645,\"start\":49637},{\"end\":49659,\"start\":49653},{\"end\":49991,\"start\":49984},{\"end\":50006,\"start\":49999},{\"end\":50023,\"start\":50012},{\"end\":50042,\"start\":50034},{\"end\":50056,\"start\":50050},{\"end\":50584,\"start\":50573},{\"end\":50601,\"start\":50593},{\"end\":50618,\"start\":50611},{\"end\":50633,\"start\":50628},{\"end\":50656,\"start\":50644},{\"end\":51088,\"start\":51082},{\"end\":51099,\"start\":51095},{\"end\":51123,\"start\":51112},{\"end\":51385,\"start\":51378},{\"end\":51402,\"start\":51396},{\"end\":51429,\"start\":51415},{\"end\":51448,\"start\":51441},{\"end\":51463,\"start\":51456},{\"end\":51478,\"start\":51469},{\"end\":51492,\"start\":51486},{\"end\":51507,\"start\":51501},{\"end\":51524,\"start\":51517},{\"end\":51541,\"start\":51533},{\"end\":51551,\"start\":51543},{\"end\":51559,\"start\":51553},{\"end\":51576,\"start\":51569},{\"end\":51593,\"start\":51585},{\"end\":51610,\"start\":51602},{\"end\":52037,\"start\":52027},{\"end\":52054,\"start\":52048},{\"end\":52306,\"start\":52303},{\"end\":52320,\"start\":52317},{\"end\":52334,\"start\":52330},{\"end\":52347,\"start\":52344},{\"end\":52360,\"start\":52355},{\"end\":52374,\"start\":52367},{\"end\":52391,\"start\":52384},{\"end\":52407,\"start\":52399},{\"end\":52420,\"start\":52414},{\"end\":52436,\"start\":52430},{\"end\":52758,\"start\":52753},{\"end\":52773,\"start\":52768},{\"end\":52789,\"start\":52783},{\"end\":52806,\"start\":52800},{\"end\":52826,\"start\":52817},{\"end\":52845,\"start\":52834},{\"end\":52859,\"start\":52852},{\"end\":52881,\"start\":52870},{\"end\":52901,\"start\":52898},{\"end\":52927,\"start\":52923},{\"end\":52939,\"start\":52935},{\"end\":52958,\"start\":52947},{\"end\":52970,\"start\":52965},{\"end\":52984,\"start\":52979},{\"end\":53477,\"start\":53462},{\"end\":53496,\"start\":53488},{\"end\":53502,\"start\":53498},{\"end\":53869,\"start\":53866},{\"end\":53883,\"start\":53877},{\"end\":53891,\"start\":53888},{\"end\":53912,\"start\":53902},{\"end\":54193,\"start\":54190},{\"end\":54203,\"start\":54200},{\"end\":54218,\"start\":54214},{\"end\":54596,\"start\":54593},{\"end\":54913,\"start\":54907},{\"end\":54928,\"start\":54921},{\"end\":54939,\"start\":54935},{\"end\":55055,\"start\":55047},{\"end\":55070,\"start\":55064},{\"end\":55089,\"start\":55082},{\"end\":55118,\"start\":55112},{\"end\":55561,\"start\":55556},{\"end\":55576,\"start\":55571},{\"end\":55588,\"start\":55583},{\"end\":55611,\"start\":55598},{\"end\":55628,\"start\":55620},{\"end\":55642,\"start\":55637},{\"end\":55658,\"start\":55653},{\"end\":56224,\"start\":56218},{\"end\":56229,\"start\":56226},{\"end\":56240,\"start\":56235},{\"end\":56247,\"start\":56242},{\"end\":56263,\"start\":56253},{\"end\":56274,\"start\":56265},{\"end\":56768,\"start\":56761},{\"end\":56779,\"start\":56776},{\"end\":56972,\"start\":56962},{\"end\":56986,\"start\":56982},{\"end\":56999,\"start\":56994},{\"end\":57430,\"start\":57420},{\"end\":57447,\"start\":57441},{\"end\":57680,\"start\":57670},{\"end\":57696,\"start\":57687},{\"end\":57715,\"start\":57709},{\"end\":58109,\"start\":58098},{\"end\":58122,\"start\":58118},{\"end\":58325,\"start\":58317},{\"end\":58338,\"start\":58331},{\"end\":58579,\"start\":58574},{\"end\":58590,\"start\":58586},{\"end\":58901,\"start\":58889},{\"end\":58921,\"start\":58909},{\"end\":58935,\"start\":58929},{\"end\":58953,\"start\":58943},{\"end\":59375,\"start\":59372},{\"end\":59731,\"start\":59728},{\"end\":59744,\"start\":59742},{\"end\":59755,\"start\":59750},{\"end\":59768,\"start\":59764},{\"end\":60235,\"start\":60233},{\"end\":60251,\"start\":60245},{\"end\":60267,\"start\":60264},{\"end\":60590,\"start\":60588},{\"end\":60602,\"start\":60598},{\"end\":60610,\"start\":60608},{\"end\":60629,\"start\":60620},{\"end\":60643,\"start\":60635},{\"end\":60870,\"start\":60868},{\"end\":60881,\"start\":60876},{\"end\":60896,\"start\":60892},{\"end\":61571,\"start\":61568},{\"end\":61579,\"start\":61576},{\"end\":61594,\"start\":61589},{\"end\":61607,\"start\":61603},{\"end\":61627,\"start\":61622},{\"end\":61652,\"start\":61636},{\"end\":62111,\"start\":62108},{\"end\":62132,\"start\":62122},{\"end\":62149,\"start\":62141},{\"end\":62174,\"start\":62158},{\"end\":62435,\"start\":62430},{\"end\":62461,\"start\":62447},{\"end\":62659,\"start\":62655},{\"end\":62667,\"start\":62661},{\"end\":62874,\"start\":62866},{\"end\":62894,\"start\":62884},{\"end\":62908,\"start\":62900},{\"end\":63180,\"start\":63175},{\"end\":63188,\"start\":63182},{\"end\":63292,\"start\":63288},{\"end\":63303,\"start\":63299},{\"end\":63317,\"start\":63310},{\"end\":63333,\"start\":63325},{\"end\":63344,\"start\":63337},{\"end\":63366,\"start\":63356},{\"end\":63384,\"start\":63376},{\"end\":63398,\"start\":63393},{\"end\":63415,\"start\":63409},{\"end\":63425,\"start\":63417},{\"end\":63879,\"start\":63870},{\"end\":63894,\"start\":63887},{\"end\":63909,\"start\":63902},{\"end\":64433,\"start\":64423},{\"end\":64449,\"start\":64443},{\"end\":64466,\"start\":64456},{\"end\":64819,\"start\":64815},{\"end\":64835,\"start\":64825},{\"end\":64852,\"start\":64843},{\"end\":64862,\"start\":64856},{\"end\":64874,\"start\":64866},{\"end\":64886,\"start\":64880},{\"end\":64898,\"start\":64892},{\"end\":65300,\"start\":65294},{\"end\":65311,\"start\":65306},{\"end\":65328,\"start\":65323},{\"end\":65340,\"start\":65335},{\"end\":65356,\"start\":65348},{\"end\":65372,\"start\":65366},{\"end\":65388,\"start\":65381},{\"end\":65400,\"start\":65397},{\"end\":65420,\"start\":65410},{\"end\":65433,\"start\":65427},{\"end\":65450,\"start\":65441},{\"end\":65464,\"start\":65460},{\"end\":65477,\"start\":65473},{\"end\":65493,\"start\":65487},{\"end\":65508,\"start\":65502},{\"end\":65524,\"start\":65518},{\"end\":65545,\"start\":65533},{\"end\":65561,\"start\":65554},{\"end\":65570,\"start\":65566},{\"end\":65582,\"start\":65579},{\"end\":65600,\"start\":65592},{\"end\":66237,\"start\":66229},{\"end\":66257,\"start\":66248},{\"end\":66275,\"start\":66266},{\"end\":66293,\"start\":66282},{\"end\":66841,\"start\":66834},{\"end\":66856,\"start\":66853},{\"end\":66871,\"start\":66864},{\"end\":66886,\"start\":66880},{\"end\":66899,\"start\":66896},{\"end\":66917,\"start\":66910},{\"end\":66932,\"start\":66926},{\"end\":66947,\"start\":66941},{\"end\":66963,\"start\":66956},{\"end\":66975,\"start\":66970},{\"end\":66993,\"start\":66986},{\"end\":67009,\"start\":67000},{\"end\":67365,\"start\":67357},{\"end\":67380,\"start\":67371},{\"end\":67396,\"start\":67389},{\"end\":67411,\"start\":67404},{\"end\":67428,\"start\":67419},{\"end\":67866,\"start\":67857},{\"end\":67886,\"start\":67881},{\"end\":67902,\"start\":67896},{\"end\":67919,\"start\":67913},{\"end\":67934,\"start\":67929},{\"end\":67948,\"start\":67943},{\"end\":67962,\"start\":67957},{\"end\":68433,\"start\":68420},{\"end\":68446,\"start\":68437},{\"end\":68465,\"start\":68457},{\"end\":68474,\"start\":68467},{\"end\":68725,\"start\":68715},{\"end\":68737,\"start\":68732},{\"end\":68752,\"start\":68745},{\"end\":68767,\"start\":68759},{\"end\":68786,\"start\":68778},{\"end\":68802,\"start\":68795},{\"end\":68821,\"start\":68813},{\"end\":68834,\"start\":68830},{\"end\":68842,\"start\":68836},{\"end\":69308,\"start\":69300},{\"end\":69326,\"start\":69319},{\"end\":69338,\"start\":69332},{\"end\":69348,\"start\":69343},{\"end\":69364,\"start\":69359},{\"end\":69370,\"start\":69366},{\"end\":69891,\"start\":69883},{\"end\":69909,\"start\":69902},{\"end\":69927,\"start\":69917},{\"end\":69950,\"start\":69942},{\"end\":69963,\"start\":69959},{\"end\":69978,\"start\":69974},{\"end\":70404,\"start\":70396},{\"end\":70420,\"start\":70416},{\"end\":70435,\"start\":70431},{\"end\":70669,\"start\":70661},{\"end\":70687,\"start\":70677},{\"end\":70710,\"start\":70702},{\"end\":70725,\"start\":70721},{\"end\":70748,\"start\":70740},{\"end\":70763,\"start\":70759},{\"end\":70786,\"start\":70778},{\"end\":70801,\"start\":70797},{\"end\":71280,\"start\":71272},{\"end\":71298,\"start\":71288},{\"end\":71321,\"start\":71313},{\"end\":71339,\"start\":71332},{\"end\":71352,\"start\":71348},{\"end\":71367,\"start\":71360},{\"end\":71382,\"start\":71374},{\"end\":71397,\"start\":71393},{\"end\":71854,\"start\":71845},{\"end\":71862,\"start\":71856},{\"end\":71876,\"start\":71864},{\"end\":71882,\"start\":71878},{\"end\":71890,\"start\":71884},{\"end\":71900,\"start\":71892},{\"end\":71906,\"start\":71902},{\"end\":71921,\"start\":71910},{\"end\":71935,\"start\":71929},{\"end\":71944,\"start\":71939},{\"end\":71956,\"start\":71946},{\"end\":71965,\"start\":71960},{\"end\":71976,\"start\":71967},{\"end\":71988,\"start\":71980},{\"end\":72003,\"start\":71990},{\"end\":72602,\"start\":72594},{\"end\":72621,\"start\":72610},{\"end\":73050,\"start\":73046},{\"end\":73067,\"start\":73058},{\"end\":73082,\"start\":73080},{\"end\":73096,\"start\":73091},{\"end\":73114,\"start\":73107},{\"end\":73128,\"start\":73123},{\"end\":73142,\"start\":73135},{\"end\":73153,\"start\":73148},{\"end\":73167,\"start\":73161},{\"end\":73545,\"start\":73541},{\"end\":73558,\"start\":73555},{\"end\":73572,\"start\":73568},{\"end\":73585,\"start\":73582},{\"end\":73597,\"start\":73593},{\"end\":73610,\"start\":73607},{\"end\":74172,\"start\":74165},{\"end\":74190,\"start\":74180},{\"end\":74207,\"start\":74197},{\"end\":74223,\"start\":74217},{\"end\":74631,\"start\":74622},{\"end\":74646,\"start\":74639},{\"end\":74873,\"start\":74870},{\"end\":74893,\"start\":74883},{\"end\":74904,\"start\":74900},{\"end\":74917,\"start\":74913},{\"end\":74932,\"start\":74927},{\"end\":74948,\"start\":74942},{\"end\":75351,\"start\":75341},{\"end\":75359,\"start\":75355},{\"end\":75374,\"start\":75368},{\"end\":75591,\"start\":75583},{\"end\":75609,\"start\":75602},{\"end\":75624,\"start\":75617},{\"end\":75642,\"start\":75635},{\"end\":75657,\"start\":75653},{\"end\":75672,\"start\":75666},{\"end\":75689,\"start\":75681},{\"end\":76195,\"start\":76187},{\"end\":76213,\"start\":76206},{\"end\":76228,\"start\":76221},{\"end\":76246,\"start\":76239},{\"end\":76261,\"start\":76257},{\"end\":76276,\"start\":76270},{\"end\":76293,\"start\":76285},{\"end\":76694,\"start\":76686},{\"end\":76712,\"start\":76705},{\"end\":76740,\"start\":76732},{\"end\":76758,\"start\":76751},{\"end\":76773,\"start\":76766},{\"end\":76790,\"start\":76782},{\"end\":76805,\"start\":76799},{\"end\":76820,\"start\":76816},{\"end\":77248,\"start\":77244},{\"end\":77260,\"start\":77255},{\"end\":77268,\"start\":77265},{\"end\":77278,\"start\":77274},{\"end\":77285,\"start\":77283},{\"end\":77295,\"start\":77292},{\"end\":77309,\"start\":77305},{\"end\":77564,\"start\":77561},{\"end\":77577,\"start\":77574},{\"end\":77588,\"start\":77583},{\"end\":77603,\"start\":77600},{\"end\":77613,\"start\":77610},{\"end\":77623,\"start\":77620},{\"end\":77878,\"start\":77875},{\"end\":77890,\"start\":77886},{\"end\":77898,\"start\":77895},{\"end\":77908,\"start\":77905},{\"end\":77920,\"start\":77916},{\"end\":78206,\"start\":78204},{\"end\":78214,\"start\":78211},{\"end\":78229,\"start\":78226},{\"end\":78239,\"start\":78236},{\"end\":78251,\"start\":78246},{\"end\":78269,\"start\":78261},{\"end\":78642,\"start\":78639},{\"end\":78666,\"start\":78653},{\"end\":78680,\"start\":78677},{\"end\":78692,\"start\":78689},{\"end\":78707,\"start\":78703},{\"end\":78713,\"start\":78709},{\"end\":79252,\"start\":79247},{\"end\":79264,\"start\":79261},{\"end\":79277,\"start\":79273},{\"end\":79288,\"start\":79284},{\"end\":79303,\"start\":79298},{\"end\":79313,\"start\":79309},{\"end\":79331,\"start\":79324},{\"end\":79341,\"start\":79338},{\"end\":79600,\"start\":79595},{\"end\":79611,\"start\":79606},{\"end\":79621,\"start\":79615},{\"end\":79635,\"start\":79631},{\"end\":79646,\"start\":79643},{\"end\":79655,\"start\":79648}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":6287870},\"end\":44028,\"start\":43044},{\"attributes\":{\"doi\":\"10.1016/j.inffus.2021.05.008\",\"id\":\"b1\"},\"end\":44762,\"start\":44030},{\"attributes\":{\"doi\":\"10.1093/icesjms/fsx216\",\"id\":\"b2\",\"matched_paper_id\":89879079},\"end\":45562,\"start\":44764},{\"attributes\":{\"doi\":\"23318422. doi: 10.1016/j. knosys.2021.106771\",\"id\":\"b3\"},\"end\":45939,\"start\":45564},{\"attributes\":{\"doi\":\"arXiv:1805.02641\",\"id\":\"b4\"},\"end\":46311,\"start\":45941},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":236486317},\"end\":46679,\"start\":46313},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":3356163},\"end\":47124,\"start\":46681},{\"attributes\":{\"doi\":\"arXiv:2006.07159\",\"id\":\"b7\"},\"end\":47433,\"start\":47126},{\"attributes\":{\"doi\":\"10.1017/S1751731118003038\",\"id\":\"b8\",\"matched_paper_id\":53427780},\"end\":47809,\"start\":47435},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":219721240},\"end\":48380,\"start\":47811},{\"attributes\":{\"doi\":\"arXiv:2002.05709\",\"id\":\"b10\"},\"end\":48764,\"start\":48382},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":219721239},\"end\":49201,\"start\":48766},{\"attributes\":{\"id\":\"b12\"},\"end\":49491,\"start\":49203},{\"attributes\":{\"id\":\"b13\"},\"end\":49901,\"start\":49493},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":235125640},\"end\":50471,\"start\":49903},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":55238399},\"end\":50974,\"start\":50473},{\"attributes\":{\"id\":\"b16\"},\"end\":51285,\"start\":50976},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":51974607},\"end\":51987,\"start\":51287},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":5855042},\"end\":52217,\"start\":51989},{\"attributes\":{\"id\":\"b19\"},\"end\":52667,\"start\":52219},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":219687798},\"end\":53455,\"start\":52669},{\"attributes\":{\"id\":\"b21\"},\"end\":53816,\"start\":53457},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":28671436},\"end\":54141,\"start\":53818},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":199453105},\"end\":54528,\"start\":54143},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":37174890},\"end\":54850,\"start\":54530},{\"attributes\":{\"id\":\"b25\"},\"end\":55039,\"start\":54852},{\"attributes\":{\"id\":\"b26\"},\"end\":55432,\"start\":55041},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":46975689},\"end\":56069,\"start\":55434},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":203623209},\"end\":56676,\"start\":56071},{\"attributes\":{\"id\":\"b29\"},\"end\":56891,\"start\":56678},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":59292019},\"end\":57358,\"start\":56893},{\"attributes\":{\"id\":\"b31\"},\"end\":57598,\"start\":57360},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":195908774},\"end\":58090,\"start\":57600},{\"attributes\":{\"id\":\"b33\"},\"end\":58281,\"start\":58092},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":116908168},\"end\":58515,\"start\":58283},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":13123084},\"end\":58788,\"start\":58517},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":220497789},\"end\":59263,\"start\":58790},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":18507866},\"end\":59630,\"start\":59265},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":4417115},\"end\":60157,\"start\":59632},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":211146562},\"end\":60513,\"start\":60159},{\"attributes\":{\"id\":\"b40\"},\"end\":60784,\"start\":60515},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":5517166},\"end\":61455,\"start\":60786},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":219792902},\"end\":61980,\"start\":61457},{\"attributes\":{\"id\":\"b43\"},\"end\":62400,\"start\":61982},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":244488543},\"end\":62606,\"start\":62402},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":5421278},\"end\":62781,\"start\":62608},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":238419444},\"end\":63124,\"start\":62783},{\"attributes\":{\"id\":\"b47\"},\"end\":63278,\"start\":63126},{\"attributes\":{\"id\":\"b48\"},\"end\":63859,\"start\":63280},{\"attributes\":{\"id\":\"b49\"},\"end\":64337,\"start\":63861},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":221824816},\"end\":64740,\"start\":64339},{\"attributes\":{\"id\":\"b51\",\"matched_paper_id\":31268669},\"end\":65217,\"start\":64742},{\"attributes\":{\"id\":\"b52\",\"matched_paper_id\":202786778},\"end\":66168,\"start\":65219},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":201103726},\"end\":66756,\"start\":66170},{\"attributes\":{\"id\":\"b54\"},\"end\":67275,\"start\":66758},{\"attributes\":{\"id\":\"b55\",\"matched_paper_id\":244527651},\"end\":67846,\"start\":67277},{\"attributes\":{\"id\":\"b56\"},\"end\":68343,\"start\":67848},{\"attributes\":{\"id\":\"b57\"},\"end\":68617,\"start\":68345},{\"attributes\":{\"id\":\"b58\",\"matched_paper_id\":247849332},\"end\":69204,\"start\":68619},{\"attributes\":{\"id\":\"b59\",\"matched_paper_id\":198985832},\"end\":69760,\"start\":69206},{\"attributes\":{\"id\":\"b60\",\"matched_paper_id\":238744021},\"end\":70303,\"start\":69762},{\"attributes\":{\"id\":\"b61\"},\"end\":70578,\"start\":70305},{\"attributes\":{\"id\":\"b62\",\"matched_paper_id\":235187536},\"end\":71149,\"start\":70580},{\"attributes\":{\"id\":\"b63\",\"matched_paper_id\":250492217},\"end\":71841,\"start\":71151},{\"attributes\":{\"id\":\"b64\"},\"end\":72515,\"start\":71843},{\"attributes\":{\"id\":\"b65\",\"matched_paper_id\":46932984},\"end\":72957,\"start\":72517},{\"attributes\":{\"id\":\"b66\",\"matched_paper_id\":210839228},\"end\":73531,\"start\":72959},{\"attributes\":{\"id\":\"b67\"},\"end\":74051,\"start\":73533},{\"attributes\":{\"id\":\"b68\",\"matched_paper_id\":231868514},\"end\":74493,\"start\":74053},{\"attributes\":{\"id\":\"b69\"},\"end\":74818,\"start\":74495},{\"attributes\":{\"id\":\"b70\",\"matched_paper_id\":245589751},\"end\":75260,\"start\":74820},{\"attributes\":{\"id\":\"b71\"},\"end\":75495,\"start\":75262},{\"attributes\":{\"id\":\"b72\"},\"end\":76080,\"start\":75497},{\"attributes\":{\"id\":\"b73\"},\"end\":76587,\"start\":76082},{\"attributes\":{\"id\":\"b74\",\"matched_paper_id\":250514303},\"end\":77160,\"start\":76589},{\"attributes\":{\"id\":\"b75\"},\"end\":77469,\"start\":77162},{\"attributes\":{\"id\":\"b76\"},\"end\":77788,\"start\":77471},{\"attributes\":{\"id\":\"b77\"},\"end\":78126,\"start\":77790},{\"attributes\":{\"id\":\"b78\",\"matched_paper_id\":59316631},\"end\":78545,\"start\":78128},{\"attributes\":{\"id\":\"b79\",\"matched_paper_id\":231592498},\"end\":79165,\"start\":78547},{\"attributes\":{\"id\":\"b80\"},\"end\":79528,\"start\":79167},{\"attributes\":{\"id\":\"b81\",\"matched_paper_id\":209516261},\"end\":79903,\"start\":79530}]", "bib_title": "[{\"end\":43126,\"start\":43044},{\"end\":44896,\"start\":44764},{\"end\":46394,\"start\":46313},{\"end\":46793,\"start\":46681},{\"end\":47526,\"start\":47435},{\"end\":47886,\"start\":47811},{\"end\":48828,\"start\":48766},{\"end\":49977,\"start\":49903},{\"end\":50566,\"start\":50473},{\"end\":51368,\"start\":51287},{\"end\":52017,\"start\":51989},{\"end\":52738,\"start\":52669},{\"end\":53858,\"start\":53818},{\"end\":54179,\"start\":54143},{\"end\":54586,\"start\":54530},{\"end\":55548,\"start\":55434},{\"end\":56214,\"start\":56071},{\"end\":56950,\"start\":56893},{\"end\":57663,\"start\":57600},{\"end\":58313,\"start\":58283},{\"end\":58565,\"start\":58517},{\"end\":58880,\"start\":58790},{\"end\":59360,\"start\":59265},{\"end\":59715,\"start\":59632},{\"end\":60224,\"start\":60159},{\"end\":60857,\"start\":60786},{\"end\":61557,\"start\":61457},{\"end\":62423,\"start\":62402},{\"end\":62651,\"start\":62608},{\"end\":62855,\"start\":62783},{\"end\":64415,\"start\":64339},{\"end\":64809,\"start\":64742},{\"end\":65287,\"start\":65219},{\"end\":66220,\"start\":66170},{\"end\":67351,\"start\":67277},{\"end\":68707,\"start\":68619},{\"end\":69293,\"start\":69206},{\"end\":69876,\"start\":69762},{\"end\":70654,\"start\":70580},{\"end\":71265,\"start\":71151},{\"end\":72584,\"start\":72517},{\"end\":73037,\"start\":72959},{\"end\":74158,\"start\":74053},{\"end\":74856,\"start\":74820},{\"end\":75576,\"start\":75497},{\"end\":76679,\"start\":76589},{\"end\":78194,\"start\":78128},{\"end\":78629,\"start\":78547},{\"end\":79586,\"start\":79530}]", "bib_author": "[{\"end\":43157,\"start\":43128},{\"end\":43170,\"start\":43157},{\"end\":43184,\"start\":43170},{\"end\":43198,\"start\":43184},{\"end\":43210,\"start\":43198},{\"end\":43224,\"start\":43210},{\"end\":43240,\"start\":43224},{\"end\":43257,\"start\":43240},{\"end\":43274,\"start\":43257},{\"end\":43289,\"start\":43274},{\"end\":43307,\"start\":43289},{\"end\":43324,\"start\":43307},{\"end\":43337,\"start\":43324},{\"end\":43351,\"start\":43337},{\"end\":43365,\"start\":43351},{\"end\":43381,\"start\":43365},{\"end\":43394,\"start\":43381},{\"end\":43411,\"start\":43394},{\"end\":43424,\"start\":43411},{\"end\":43438,\"start\":43424},{\"end\":43447,\"start\":43438},{\"end\":44162,\"start\":44148},{\"end\":44180,\"start\":44162},{\"end\":44195,\"start\":44180},{\"end\":44213,\"start\":44195},{\"end\":44221,\"start\":44213},{\"end\":44243,\"start\":44221},{\"end\":44257,\"start\":44243},{\"end\":44271,\"start\":44257},{\"end\":44287,\"start\":44271},{\"end\":44307,\"start\":44287},{\"end\":44328,\"start\":44307},{\"end\":44345,\"start\":44328},{\"end\":44913,\"start\":44898},{\"end\":44926,\"start\":44913},{\"end\":44938,\"start\":44926},{\"end\":44946,\"start\":44938},{\"end\":44953,\"start\":44946},{\"end\":44962,\"start\":44953},{\"end\":44971,\"start\":44962},{\"end\":44986,\"start\":44971},{\"end\":44999,\"start\":44986},{\"end\":45007,\"start\":44999},{\"end\":45025,\"start\":45007},{\"end\":45035,\"start\":45025},{\"end\":45053,\"start\":45035},{\"end\":45074,\"start\":45053},{\"end\":45686,\"start\":45672},{\"end\":45700,\"start\":45686},{\"end\":45963,\"start\":45941},{\"end\":45979,\"start\":45963},{\"end\":45999,\"start\":45979},{\"end\":46012,\"start\":45999},{\"end\":46412,\"start\":46396},{\"end\":46426,\"start\":46412},{\"end\":46446,\"start\":46426},{\"end\":46457,\"start\":46446},{\"end\":46470,\"start\":46457},{\"end\":46811,\"start\":46795},{\"end\":46826,\"start\":46811},{\"end\":46837,\"start\":46826},{\"end\":47139,\"start\":47126},{\"end\":47157,\"start\":47139},{\"end\":47179,\"start\":47157},{\"end\":47539,\"start\":47528},{\"end\":47547,\"start\":47539},{\"end\":47555,\"start\":47547},{\"end\":47561,\"start\":47555},{\"end\":47904,\"start\":47888},{\"end\":47917,\"start\":47904},{\"end\":47930,\"start\":47917},{\"end\":47948,\"start\":47930},{\"end\":47963,\"start\":47948},{\"end\":47978,\"start\":47963},{\"end\":48464,\"start\":48453},{\"end\":48481,\"start\":48464},{\"end\":48499,\"start\":48481},{\"end\":48516,\"start\":48499},{\"end\":48841,\"start\":48830},{\"end\":48858,\"start\":48841},{\"end\":48873,\"start\":48858},{\"end\":48891,\"start\":48873},{\"end\":48908,\"start\":48891},{\"end\":49216,\"start\":49203},{\"end\":49227,\"start\":49216},{\"end\":49596,\"start\":49582},{\"end\":49611,\"start\":49596},{\"end\":49628,\"start\":49611},{\"end\":49647,\"start\":49628},{\"end\":49661,\"start\":49647},{\"end\":49993,\"start\":49979},{\"end\":50008,\"start\":49993},{\"end\":50025,\"start\":50008},{\"end\":50044,\"start\":50025},{\"end\":50058,\"start\":50044},{\"end\":50586,\"start\":50568},{\"end\":50603,\"start\":50586},{\"end\":50620,\"start\":50603},{\"end\":50635,\"start\":50620},{\"end\":50658,\"start\":50635},{\"end\":51090,\"start\":51064},{\"end\":51101,\"start\":51090},{\"end\":51125,\"start\":51101},{\"end\":51387,\"start\":51370},{\"end\":51404,\"start\":51387},{\"end\":51431,\"start\":51404},{\"end\":51450,\"start\":51431},{\"end\":51465,\"start\":51450},{\"end\":51480,\"start\":51465},{\"end\":51494,\"start\":51480},{\"end\":51509,\"start\":51494},{\"end\":51526,\"start\":51509},{\"end\":51543,\"start\":51526},{\"end\":51553,\"start\":51543},{\"end\":51561,\"start\":51553},{\"end\":51578,\"start\":51561},{\"end\":51595,\"start\":51578},{\"end\":51612,\"start\":51595},{\"end\":52039,\"start\":52019},{\"end\":52056,\"start\":52039},{\"end\":52308,\"start\":52295},{\"end\":52322,\"start\":52308},{\"end\":52336,\"start\":52322},{\"end\":52349,\"start\":52336},{\"end\":52362,\"start\":52349},{\"end\":52376,\"start\":52362},{\"end\":52393,\"start\":52376},{\"end\":52409,\"start\":52393},{\"end\":52422,\"start\":52409},{\"end\":52438,\"start\":52422},{\"end\":52760,\"start\":52740},{\"end\":52775,\"start\":52760},{\"end\":52791,\"start\":52775},{\"end\":52808,\"start\":52791},{\"end\":52828,\"start\":52808},{\"end\":52847,\"start\":52828},{\"end\":52861,\"start\":52847},{\"end\":52883,\"start\":52861},{\"end\":52903,\"start\":52883},{\"end\":52929,\"start\":52903},{\"end\":52941,\"start\":52929},{\"end\":52960,\"start\":52941},{\"end\":52972,\"start\":52960},{\"end\":52986,\"start\":52972},{\"end\":53479,\"start\":53457},{\"end\":53498,\"start\":53479},{\"end\":53504,\"start\":53498},{\"end\":53871,\"start\":53860},{\"end\":53885,\"start\":53871},{\"end\":53893,\"start\":53885},{\"end\":53914,\"start\":53893},{\"end\":54195,\"start\":54181},{\"end\":54205,\"start\":54195},{\"end\":54220,\"start\":54205},{\"end\":54598,\"start\":54588},{\"end\":54915,\"start\":54898},{\"end\":54930,\"start\":54915},{\"end\":54941,\"start\":54930},{\"end\":55057,\"start\":55041},{\"end\":55072,\"start\":55057},{\"end\":55091,\"start\":55072},{\"end\":55120,\"start\":55091},{\"end\":55563,\"start\":55550},{\"end\":55578,\"start\":55563},{\"end\":55590,\"start\":55578},{\"end\":55613,\"start\":55590},{\"end\":55630,\"start\":55613},{\"end\":55644,\"start\":55630},{\"end\":55660,\"start\":55644},{\"end\":56226,\"start\":56216},{\"end\":56231,\"start\":56226},{\"end\":56242,\"start\":56231},{\"end\":56249,\"start\":56242},{\"end\":56265,\"start\":56249},{\"end\":56276,\"start\":56265},{\"end\":56770,\"start\":56756},{\"end\":56781,\"start\":56770},{\"end\":56974,\"start\":56952},{\"end\":56988,\"start\":56974},{\"end\":57001,\"start\":56988},{\"end\":57432,\"start\":57415},{\"end\":57449,\"start\":57432},{\"end\":57458,\"start\":57449},{\"end\":57682,\"start\":57665},{\"end\":57698,\"start\":57682},{\"end\":57717,\"start\":57698},{\"end\":58111,\"start\":58092},{\"end\":58124,\"start\":58111},{\"end\":58327,\"start\":58315},{\"end\":58340,\"start\":58327},{\"end\":58581,\"start\":58567},{\"end\":58592,\"start\":58581},{\"end\":58903,\"start\":58882},{\"end\":58923,\"start\":58903},{\"end\":58937,\"start\":58923},{\"end\":58955,\"start\":58937},{\"end\":59377,\"start\":59362},{\"end\":59733,\"start\":59717},{\"end\":59746,\"start\":59733},{\"end\":59757,\"start\":59746},{\"end\":59770,\"start\":59757},{\"end\":60237,\"start\":60226},{\"end\":60253,\"start\":60237},{\"end\":60269,\"start\":60253},{\"end\":60592,\"start\":60584},{\"end\":60604,\"start\":60592},{\"end\":60612,\"start\":60604},{\"end\":60631,\"start\":60612},{\"end\":60645,\"start\":60631},{\"end\":60872,\"start\":60859},{\"end\":60883,\"start\":60872},{\"end\":60898,\"start\":60883},{\"end\":61573,\"start\":61559},{\"end\":61581,\"start\":61573},{\"end\":61596,\"start\":61581},{\"end\":61609,\"start\":61596},{\"end\":61629,\"start\":61609},{\"end\":61654,\"start\":61629},{\"end\":62113,\"start\":62102},{\"end\":62134,\"start\":62113},{\"end\":62151,\"start\":62134},{\"end\":62176,\"start\":62151},{\"end\":62437,\"start\":62425},{\"end\":62463,\"start\":62437},{\"end\":62661,\"start\":62653},{\"end\":62669,\"start\":62661},{\"end\":62876,\"start\":62857},{\"end\":62896,\"start\":62876},{\"end\":62910,\"start\":62896},{\"end\":63182,\"start\":63173},{\"end\":63190,\"start\":63182},{\"end\":63294,\"start\":63280},{\"end\":63305,\"start\":63294},{\"end\":63319,\"start\":63305},{\"end\":63335,\"start\":63319},{\"end\":63346,\"start\":63335},{\"end\":63368,\"start\":63346},{\"end\":63386,\"start\":63368},{\"end\":63400,\"start\":63386},{\"end\":63417,\"start\":63400},{\"end\":63427,\"start\":63417},{\"end\":63881,\"start\":63861},{\"end\":63896,\"start\":63881},{\"end\":63911,\"start\":63896},{\"end\":64435,\"start\":64417},{\"end\":64451,\"start\":64435},{\"end\":64468,\"start\":64451},{\"end\":64821,\"start\":64811},{\"end\":64837,\"start\":64821},{\"end\":64854,\"start\":64837},{\"end\":64864,\"start\":64854},{\"end\":64876,\"start\":64864},{\"end\":64888,\"start\":64876},{\"end\":64900,\"start\":64888},{\"end\":65302,\"start\":65289},{\"end\":65313,\"start\":65302},{\"end\":65330,\"start\":65313},{\"end\":65342,\"start\":65330},{\"end\":65358,\"start\":65342},{\"end\":65374,\"start\":65358},{\"end\":65390,\"start\":65374},{\"end\":65402,\"start\":65390},{\"end\":65422,\"start\":65402},{\"end\":65435,\"start\":65422},{\"end\":65452,\"start\":65435},{\"end\":65466,\"start\":65452},{\"end\":65479,\"start\":65466},{\"end\":65495,\"start\":65479},{\"end\":65510,\"start\":65495},{\"end\":65526,\"start\":65510},{\"end\":65547,\"start\":65526},{\"end\":65563,\"start\":65547},{\"end\":65572,\"start\":65563},{\"end\":65584,\"start\":65572},{\"end\":65602,\"start\":65584},{\"end\":66239,\"start\":66222},{\"end\":66259,\"start\":66239},{\"end\":66277,\"start\":66259},{\"end\":66295,\"start\":66277},{\"end\":66843,\"start\":66829},{\"end\":66858,\"start\":66843},{\"end\":66873,\"start\":66858},{\"end\":66888,\"start\":66873},{\"end\":66901,\"start\":66888},{\"end\":66919,\"start\":66901},{\"end\":66934,\"start\":66919},{\"end\":66949,\"start\":66934},{\"end\":66965,\"start\":66949},{\"end\":66977,\"start\":66965},{\"end\":66995,\"start\":66977},{\"end\":67011,\"start\":66995},{\"end\":67367,\"start\":67353},{\"end\":67382,\"start\":67367},{\"end\":67398,\"start\":67382},{\"end\":67413,\"start\":67398},{\"end\":67430,\"start\":67413},{\"end\":67868,\"start\":67848},{\"end\":67888,\"start\":67868},{\"end\":67904,\"start\":67888},{\"end\":67921,\"start\":67904},{\"end\":67936,\"start\":67921},{\"end\":67950,\"start\":67936},{\"end\":67964,\"start\":67950},{\"end\":68435,\"start\":68411},{\"end\":68448,\"start\":68435},{\"end\":68467,\"start\":68448},{\"end\":68476,\"start\":68467},{\"end\":68727,\"start\":68709},{\"end\":68739,\"start\":68727},{\"end\":68754,\"start\":68739},{\"end\":68769,\"start\":68754},{\"end\":68788,\"start\":68769},{\"end\":68804,\"start\":68788},{\"end\":68823,\"start\":68804},{\"end\":68836,\"start\":68823},{\"end\":68844,\"start\":68836},{\"end\":69310,\"start\":69295},{\"end\":69328,\"start\":69310},{\"end\":69340,\"start\":69328},{\"end\":69350,\"start\":69340},{\"end\":69366,\"start\":69350},{\"end\":69372,\"start\":69366},{\"end\":69893,\"start\":69878},{\"end\":69911,\"start\":69893},{\"end\":69929,\"start\":69911},{\"end\":69952,\"start\":69929},{\"end\":69965,\"start\":69952},{\"end\":69980,\"start\":69965},{\"end\":70406,\"start\":70391},{\"end\":70422,\"start\":70406},{\"end\":70437,\"start\":70422},{\"end\":70671,\"start\":70656},{\"end\":70689,\"start\":70671},{\"end\":70712,\"start\":70689},{\"end\":70727,\"start\":70712},{\"end\":70750,\"start\":70727},{\"end\":70765,\"start\":70750},{\"end\":70788,\"start\":70765},{\"end\":70803,\"start\":70788},{\"end\":71282,\"start\":71267},{\"end\":71300,\"start\":71282},{\"end\":71323,\"start\":71300},{\"end\":71341,\"start\":71323},{\"end\":71354,\"start\":71341},{\"end\":71369,\"start\":71354},{\"end\":71384,\"start\":71369},{\"end\":71399,\"start\":71384},{\"end\":71856,\"start\":71843},{\"end\":71864,\"start\":71856},{\"end\":71878,\"start\":71864},{\"end\":71884,\"start\":71878},{\"end\":71892,\"start\":71884},{\"end\":71902,\"start\":71892},{\"end\":71908,\"start\":71902},{\"end\":71923,\"start\":71908},{\"end\":71937,\"start\":71923},{\"end\":71946,\"start\":71937},{\"end\":71958,\"start\":71946},{\"end\":71967,\"start\":71958},{\"end\":71978,\"start\":71967},{\"end\":71990,\"start\":71978},{\"end\":72005,\"start\":71990},{\"end\":72604,\"start\":72586},{\"end\":72623,\"start\":72604},{\"end\":73052,\"start\":73039},{\"end\":73069,\"start\":73052},{\"end\":73084,\"start\":73069},{\"end\":73098,\"start\":73084},{\"end\":73116,\"start\":73098},{\"end\":73130,\"start\":73116},{\"end\":73144,\"start\":73130},{\"end\":73155,\"start\":73144},{\"end\":73169,\"start\":73155},{\"end\":73547,\"start\":73533},{\"end\":73560,\"start\":73547},{\"end\":73574,\"start\":73560},{\"end\":73587,\"start\":73574},{\"end\":73599,\"start\":73587},{\"end\":73612,\"start\":73599},{\"end\":74174,\"start\":74160},{\"end\":74192,\"start\":74174},{\"end\":74209,\"start\":74192},{\"end\":74225,\"start\":74209},{\"end\":74633,\"start\":74616},{\"end\":74648,\"start\":74633},{\"end\":74875,\"start\":74858},{\"end\":74895,\"start\":74875},{\"end\":74906,\"start\":74895},{\"end\":74919,\"start\":74906},{\"end\":74934,\"start\":74919},{\"end\":74950,\"start\":74934},{\"end\":75353,\"start\":75334},{\"end\":75361,\"start\":75353},{\"end\":75376,\"start\":75361},{\"end\":75593,\"start\":75578},{\"end\":75611,\"start\":75593},{\"end\":75626,\"start\":75611},{\"end\":75644,\"start\":75626},{\"end\":75659,\"start\":75644},{\"end\":75674,\"start\":75659},{\"end\":75691,\"start\":75674},{\"end\":76197,\"start\":76182},{\"end\":76215,\"start\":76197},{\"end\":76230,\"start\":76215},{\"end\":76248,\"start\":76230},{\"end\":76263,\"start\":76248},{\"end\":76278,\"start\":76263},{\"end\":76295,\"start\":76278},{\"end\":76696,\"start\":76681},{\"end\":76714,\"start\":76696},{\"end\":76742,\"start\":76714},{\"end\":76760,\"start\":76742},{\"end\":76775,\"start\":76760},{\"end\":76792,\"start\":76775},{\"end\":76807,\"start\":76792},{\"end\":76822,\"start\":76807},{\"end\":77250,\"start\":77236},{\"end\":77262,\"start\":77250},{\"end\":77270,\"start\":77262},{\"end\":77280,\"start\":77270},{\"end\":77287,\"start\":77280},{\"end\":77297,\"start\":77287},{\"end\":77311,\"start\":77297},{\"end\":77566,\"start\":77553},{\"end\":77579,\"start\":77566},{\"end\":77590,\"start\":77579},{\"end\":77605,\"start\":77590},{\"end\":77615,\"start\":77605},{\"end\":77625,\"start\":77615},{\"end\":77880,\"start\":77866},{\"end\":77892,\"start\":77880},{\"end\":77900,\"start\":77892},{\"end\":77910,\"start\":77900},{\"end\":77922,\"start\":77910},{\"end\":78208,\"start\":78196},{\"end\":78216,\"start\":78208},{\"end\":78231,\"start\":78216},{\"end\":78241,\"start\":78231},{\"end\":78253,\"start\":78241},{\"end\":78271,\"start\":78253},{\"end\":78644,\"start\":78631},{\"end\":78668,\"start\":78644},{\"end\":78682,\"start\":78668},{\"end\":78694,\"start\":78682},{\"end\":78709,\"start\":78694},{\"end\":78715,\"start\":78709},{\"end\":79254,\"start\":79243},{\"end\":79266,\"start\":79254},{\"end\":79279,\"start\":79266},{\"end\":79290,\"start\":79279},{\"end\":79305,\"start\":79290},{\"end\":79315,\"start\":79305},{\"end\":79333,\"start\":79315},{\"end\":79343,\"start\":79333},{\"end\":79602,\"start\":79588},{\"end\":79613,\"start\":79602},{\"end\":79623,\"start\":79613},{\"end\":79637,\"start\":79623},{\"end\":79648,\"start\":79637},{\"end\":79657,\"start\":79648}]", "bib_venue": "[{\"end\":43525,\"start\":43447},{\"end\":44146,\"start\":44030},{\"end\":45126,\"start\":45096},{\"end\":45670,\"start\":45564},{\"end\":46103,\"start\":46028},{\"end\":46474,\"start\":46470},{\"end\":46881,\"start\":46837},{\"end\":47274,\"start\":47195},{\"end\":47592,\"start\":47586},{\"end\":48052,\"start\":47978},{\"end\":48451,\"start\":48382},{\"end\":48957,\"start\":48908},{\"end\":49327,\"start\":49243},{\"end\":49580,\"start\":49493},{\"end\":50139,\"start\":50058},{\"end\":50706,\"start\":50676},{\"end\":51062,\"start\":50976},{\"end\":51627,\"start\":51612},{\"end\":52092,\"start\":52056},{\"end\":52293,\"start\":52219},{\"end\":53035,\"start\":52986},{\"end\":53630,\"start\":53504},{\"end\":53958,\"start\":53914},{\"end\":54291,\"start\":54220},{\"end\":54675,\"start\":54625},{\"end\":54896,\"start\":54852},{\"end\":55221,\"start\":55120},{\"end\":55727,\"start\":55660},{\"end\":56350,\"start\":56301},{\"end\":56754,\"start\":56678},{\"end\":57078,\"start\":57001},{\"end\":57413,\"start\":57360},{\"end\":57781,\"start\":57732},{\"end\":58164,\"start\":58140},{\"end\":58381,\"start\":58363},{\"end\":58644,\"start\":58592},{\"end\":59006,\"start\":58979},{\"end\":59432,\"start\":59377},{\"end\":59847,\"start\":59770},{\"end\":60321,\"start\":60269},{\"end\":60582,\"start\":60515},{\"end\":61004,\"start\":60917},{\"end\":61703,\"start\":61654},{\"end\":62100,\"start\":61982},{\"end\":62500,\"start\":62463},{\"end\":62678,\"start\":62669},{\"end\":62947,\"start\":62910},{\"end\":63171,\"start\":63126},{\"end\":63550,\"start\":63443},{\"end\":64092,\"start\":63911},{\"end\":64513,\"start\":64494},{\"end\":64938,\"start\":64928},{\"end\":65651,\"start\":65602},{\"end\":66407,\"start\":66318},{\"end\":66827,\"start\":66758},{\"end\":67511,\"start\":67430},{\"end\":68050,\"start\":67980},{\"end\":68409,\"start\":68345},{\"end\":68882,\"start\":68844},{\"end\":69457,\"start\":69400},{\"end\":70004,\"start\":69997},{\"end\":70389,\"start\":70305},{\"end\":70841,\"start\":70830},{\"end\":71463,\"start\":71399},{\"end\":72144,\"start\":72034},{\"end\":72677,\"start\":72651},{\"end\":73218,\"start\":73169},{\"end\":73776,\"start\":73655},{\"end\":74249,\"start\":74242},{\"end\":74614,\"start\":74495},{\"end\":75013,\"start\":74970},{\"end\":75332,\"start\":75262},{\"end\":75775,\"start\":75691},{\"end\":76180,\"start\":76082},{\"end\":76846,\"start\":76839},{\"end\":77234,\"start\":77162},{\"end\":77551,\"start\":77471},{\"end\":77864,\"start\":77790},{\"end\":78315,\"start\":78271},{\"end\":78803,\"start\":78715},{\"end\":79241,\"start\":79167},{\"end\":79710,\"start\":79657},{\"end\":46489,\"start\":46476},{\"end\":48113,\"start\":48054},{\"end\":50207,\"start\":50141},{\"end\":54349,\"start\":54293},{\"end\":57142,\"start\":57080},{\"end\":59911,\"start\":59849},{\"end\":61078,\"start\":61006},{\"end\":66483,\"start\":66409},{\"end\":67579,\"start\":67513},{\"end\":68076,\"start\":68052},{\"end\":71514,\"start\":71465},{\"end\":78878,\"start\":78805}]"}}}, "year": 2023, "month": 12, "day": 17}