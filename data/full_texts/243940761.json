{"id": 243940761, "updated": "2022-01-07 02:31:18.191", "metadata": {"title": "A whole-process interpretable and multi-modal deep reinforcement learning for diagnosis and analysis of Alzheimer\u2019s disease", "authors": "[{\"middle\":[],\"last\":\"Zhang\",\"first\":\"Quan\"},{\"middle\":[],\"last\":\"Du\",\"first\":\"Qian\"},{\"middle\":[],\"last\":\"Liu\",\"first\":\"Guohua\"}]", "venue": null, "journal": "Journal of Neural Engineering", "publication_date": {"year": 2021, "month": null, "day": null}, "abstract": "Objective. Alzheimer\u2019s disease (AD), a common disease of the elderly with unknown etiology, has been adversely affecting many people, especially with the aging of the population and the younger trend of this disease. Current artificial intelligence (AI) methods based on individual information or magnetic resonance imaging (MRI) can solve the problem of diagnostic sensitivity and specificity, but still face the challenges of interpretability and clinical feasibility. In this study, we propose an interpretable multimodal deep reinforcement learning model for inferring pathological features and the diagnosis of AD. Approach. First, for better clinical feasibility, the compressed-sensing MRI image is reconstructed using an interpretable deep reinforcement learning model. Then, the reconstructed MRI is input into the full convolution neural network to generate a pixel-level disease probability risk map (DPM) of the whole brain for AD. The DPM of important brain regions and individual information are then input into the attention-based fully deep neural network to obtain the diagnosis results and analyze the biomarkers. We used 1349 multi-center samples to construct and test the model. Main results. Finally, the model obtained 99.6% \u00b1 0.2%, 97.9% \u00b1 0.2%, and 96.1% \u00b1 0.3% area under curve in ADNI, AIBL and NACC, respectively. The model also provides an effective analysis of multimodal pathology, predicts the imaging biomarkers in MRI and the weight of each individual item of information. In this study, a deep reinforcement learning model was designed, which can not only accurately diagnose AD, but analyze potential biomarkers. Significance. In this study, a deep reinforcement learning model was designed. The model builds a bridge between clinical practice and AI diagnosis and provides a viewpoint for the interpretability of AI technology.", "fields_of_study": "[\"Medicine\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": "34753116", "pubmedcentral": null, "dblp": null, "doi": "10.1088/1741-2552/ac37cc"}}, "content": {"source": {"pdf_hash": "14883150e4a95fb17a485fb37e303eeb98c383b7", "pdf_src": "IOP", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "e272f7023414ddfb1355dfb204a65c1a8fdf22a9", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/14883150e4a95fb17a485fb37e303eeb98c383b7.txt", "contents": "\nA whole-process interpretable and multi-modal deep reinforcement learning for diagnosis and analysis of Alzheimer's disease *\n2021\n\nQuan Zhang \nCollege of Electronic Information and Optical Engineering\nNankai University\n300350TianjinPeople's Republic of China\n\nTianjin Key Laboratory of Optoelectronic Sensor and Sensing Network Technology\nNankai University\n300350TianjinPeople's Republic of China\n\nQian Du \nCollege of Electronic Information and Optical Engineering\nNankai University\n300350TianjinPeople's Republic of China\n\nTianjin Key Laboratory of Optoelectronic Sensor and Sensing Network Technology\nNankai University\n300350TianjinPeople's Republic of China\n\nGuohua Liu \nCollege of Electronic Information and Optical Engineering\nNankai University\n300350TianjinPeople's Republic of China\n\nTianjin Key Laboratory of Optoelectronic Sensor and Sensing Network Technology\nNankai University\n300350TianjinPeople's Republic of China\n\nEngineering Research Center of Thin Film Optoelectronics Technology\nMinistry of Education\nNankai University\n300350TianjinPeople's Republic of China\n\nA whole-process interpretable and multi-modal deep reinforcement learning for diagnosis and analysis of Alzheimer's disease *\n\nJ. Neural Eng\n1866032202110.1088/1741-2552/ac37ccJournal of Neural Engineering RECEIVED ACCEPTED FOR PUBLICATION 9 November 2021 PUBLISHED PAPER * * Author to whom any correspondence should be addressed. Supplementary material for this article is available online \u00a9 2021 IOP Publishing Ltd J. Neural Eng. 18 (2021) 066032 Q Zhang et aldeep learningpathological analysisbiomarker predictioninterpretable artificial intelligencereinforcement learning\nObjective. Alzheimer's disease (AD), a common disease of the elderly with unknown etiology, has been adversely affecting many people, especially with the aging of the population and the younger trend of this disease. Current artificial intelligence (AI) methods based on individual information or magnetic resonance imaging (MRI) can solve the problem of diagnostic sensitivity and specificity, but still face the challenges of interpretability and clinical feasibility. In this study, we propose an interpretable multimodal deep reinforcement learning model for inferring pathological features and the diagnosis of AD. Approach. First, for better clinical feasibility, the compressed-sensing MRI image is reconstructed using an interpretable deep reinforcement learning model. Then, the reconstructed MRI is input into the full convolution neural network to generate a pixel-level disease probability risk map (DPM) of the whole brain for AD. The DPM of important brain regions and individual information are then input into the attention-based fully deep neural network to obtain the diagnosis results and analyze the biomarkers. We used 1349 multi-center samples to construct and test the model. Main results. Finally, the model obtained 99.6% \u00b1 0.2%, 97.9% \u00b1 0.2%, and 96.1% \u00b1 0.3% area under curve in ADNI, AIBL and NACC, respectively. The model also provides an effective analysis of multimodal pathology, predicts the imaging biomarkers in MRI and the weight of each individual item of information. In this study, a deep reinforcement learning model was designed, which can not only accurately diagnose AD, but analyze potential biomarkers. Significance. In this study, a deep reinforcement learning model was designed. The model builds a bridge between clinical practice and AI diagnosis and provides a viewpoint for the interpretability of AI technology. * Data used in preparation of this article were obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database (adni.loni.usc.edu). As such, the investigators within the ADNI contributed to the design and implementation of ADNI and/or provided data but did not participate in analysis or writing of this report. A complete listing of ADNI investigators can be found at\n\nIntroduction\n\nAlzheimer's disease (AD) is a progressive neurodegenerative disease with a hidden onset and unknown etiology [1]. Currently, there is an increasing number of AD patients due to the aging population, the younger trend of this disease, and other reasons. Thus, it is an urgent task to find an efficient way to fight against AD [2,3].\n\nIn the current scheme, cerebrospinal fluid biomarkers, positron emission tomography (PET) amyloid and TAU imaging for the detection of AD pathology are difficult to be widely used in the actual clinical process [4][5][6][7]. In addition, in clinical applications, the imaging biomarkers revealed by magnetic resonance imaging (MRI) still lack specificity in the diagnosis of AD [8][9][10][11]. Experienced neuroscientists can only control the sensitivity range of 70.9%-87.3% and the specificity range of 44.3%-70.8% according to the comprehensive information of patients, such as history, MRI and bedside mini mental state examination (MMSE) [12]. Therefore, if we can propose an AD auxiliary diagnosis method with the following three functions simultaneously, it will be of positive significance to improve the level of AD diagnosis and further reveal the pathogenesis of AD. (1) According to the comprehensive information of patients, the cognitive state of patients can be accurately and robustly judged. (2) The image biomarkers of AD were automatically analyzed according to numerous clinical practices. (3) Based on clinical practice data, the importance of different clinical information for the diagnosis of AD was automatically analyzed, such as MMSE, age and gene information. At the same time, the model can also speed up the patient's medical treatment process and reduce the scan time to obtain high-quality MRI.\n\nArtificial intelligence (AI) technology has made a great breakthrough in medical information analysis, but it still faces challenges when applied in clinical practice [13][14][15][16][17][18]. First, some AI models were trained and tested only in the same data set. Due to the lack of additional multi-center data sets, the real performance of the model is difficult to evaluate effectively. Second, the potential impact of the original data distribution on the diagnosis results is rarely considered, and the accuracy of the model prediction may be falsely high. Third, due to the uncertainty of the pathogenesis of AD, multi-modal information including individual differences still needs to be further analyzed. Some studies have focussed the single model AD diagnostic methods, such as MRI, PET and gene information. The individual characteristics of patients are ignored when only the image information is used. The heterogeneity of brain symptoms was ignored when only the biological information was studied. Fourth, the AI model has black box characteristics, and its interpretability is still facing challenges [19,20]. Fifth, there is a gap between clinical practice and an ideal research environment. The acquisition of MRI data is usually very time consuming, and the patient needs to stay still during the scan. This not only reduces the patient's sense of experience, but also makes it difficult to ensure that any image obtained is of high quality. Some AI models use data extracted from the zero-filled k-space or original compressed k-space data to obtain reconstructed images. Although this method can improve the efficiency of MRI image acquisition and improve image quality, the process cannot be explained. This may makes some pathological features undergo subtle changes in the process of reconstruction, which makes the clinical data unreliable. Sixth, the interpretability of the multimodal model has not been solved. When mining medical image features, most models also work around the rule region of interest (ROI), which cannot accurately predict the disease risk of each point in the brain. The interpretability of clinical information is usually ignored, and the impact of each item of clinical information on the diagnosis results also needs to be studied. These problems prevent AI from being embedded in clinical practice.\n\nTo overcome these obstacles, this paper proposes a new AI framework that integrates reinforcement learning and deep learning, as shown in figure 1. The proposed network has the following functions: (1) According to the multimodal comprehensive information to accurately judge the health condition of Step (A) designed in this paper is the process of compressed sensing MRI reconstruction. In the deep reinforcement learning model, each pixel of the CS-MRI image is regarded as an agent, and the pixel matrix of the whole image is regarded as the model state. Deep reinforcement learning (DRL) model will select a filter for each pixel to improve its own pixel value according to the pathological characteristics, and then use the reward function to evaluate the degree of improvement of the image. Finally, a high-quality image can be obtained.\n\nStep (B) is the process of training the convolutional classification network. We randomly sampled 47 \u00d7 47 \u00d7 47 cubes on HQ-MRI, and then these pixels were input into the convolution classification model. Step (C) is the process of generating an AD risk map. Classifier of the above convolution classification network is replaced by a convolution kernel, which is transformed into a full convolution neural network (FCN). The whole brain pixel-level 3D AD risk map can be obtained by inputting HQ-MRI into the FCN.\n\nStep (D) is a multimodal diagnosis model based on an attention mechanism. 3D risk map and clinical information are input into the model to obtain the diagnosis results. Attention mechanism can analyze biomarkers.\n\npatients. (2) This network can explain the process of MRI reconstruction at the pixel level and has higher reliability than the black box model. (3) The disease probability of the risk map (DPM) of AD was generated based on brain MRI. Predicting the disease risk of each pixel in the MRI image, instead of using the ROI set in advance, increases the accuracy of pathological analysis of the model, and shows the evidence of the model judging the health status from the medical image. (4) The degree of attention of the model to different clinical data (such as age, MMSE, etc), which shows evidence of the model judging health status from the aspect of physiological parameters. Three data sets were used to train and evaluate the model to evaluate its performance more objectively. The above data sets include the Alzheimer's Disease Neuroimaging Initiative data set (ADNI) [21], Australian imaging biomarker and lifestyle flagship study of aging (AIBL) [22] and the National Alzheimer's Coordinating Center (NACC) [23]. At the same time, t-distributed stochastic neighbor embedding (t-SNE) was used to draw the data distribution map to avoid the potential impact of different original data distributions on the diagnosis results [24,25].\n\n\nMaterials and methods\n\n\nData description\n\nThis was a retrospective study. The data used in the experiment included an MRI of the patient's head along with their clinical parameters (age, gender, MMSE, and ApoE4). All data can be found in ADNI, AIBL and NACC. Demographic information is shown in table 1.\n\nData from 1349 patients were used to construct and test the AI model. The inclusion criteria were as follows: age \u2a7e55 years, T1 weighted, 1.5 T MRI. The acquisition time of the MRI should be within 6 months of diagnosis. In our work, some outlier samples were excluded, including brain tumor, stroke, brain injury, severe depression, Parkinson's disease, epilepsy, Lewy body disease, non-Alzheimer degenerative dementia, mixed dementia and severe systemic diseases. The exclusion criteria were similar to the ADNI criteria, and the same criteria were used to screen the AIBL and NACC data sets. Data from the samples used in this study included MRI scans, age, gender, MMSE, APoE4, and samples without any information were excluded. Other parameters of MRI are not strictly limited. The serial numbers of cases used in this paper are shown in the supplementary material tables S1-S3. Through the file name, more accurate parameters of the corresponding MRI can be obtained from the relevant institutions (ADNI, AIBL, NACC), such as pulse sequence, acquisition matrix, FOV, TR, TE, etc.\n\nThe ADNI data set was divided into three parts: (1) Training sample: 60% of the ADNI data was used to update the global parameters. (2) Tuning samples: 20% of the samples were used to adjust the super parameters. (3) Test sample: the remaining 20% of the samples were used to test the performance of the model. In order to verify the robustness and generalization ability of the model, two additional data sets (AIBL and NACC) were also used to evaluate the final performance of the model.\n\n\nMRI image pretreatment\n\nIn order to extract the pathological information contained in MRI images more effectively, all MRI images used in this study were preprocessed. The FLIRT toolkit was used to register MRI images. MNI152 was used as the registration template, and the slice thickness was 1 mm. All registered MRI images were manually screened again, and samples with poor registration effects were discarded. It should be noted that not all discarded samples were included in the above demographic statistics. The above statistics only include all samples that meet the requirements.\n\nAfter obtaining all registered MRI images, we standardized their pixel values. After standardization, the original data are converted into dimensionless data, eliminating the impact of different pixel ranges caused by different measurement conditions on the performance of the model. In other words, the effects of different MRI parameters on model performance are eliminated. The assignment method was used to eliminate singularity. All pixels less than \u22121 are assigned \u22121, and all pixels greater than 2.5, are assigned 2.5. After the singularity of the MRI image was eliminated, we further eliminated the background of the MRI image, and all the pixels outside the skull were set to \u22121.\n\n\nDeep reinforcement learning (DRL)\n\nCompressed sensing technology can speed up the efficiency of MRI image acquisition and reduce the scanning time for patients. Due to frequency domain down-sampling, compressed sensing MRI (CS-MRI) is usually blurry. Therefore, CS-MRI needs to be reconstructed to obtain high-quality MRI images (HQ-MRI) for diagnosis. HQ-MRI is used to generate DPM. Finally, DPM and patient clinical and genetic information are used to diagnose AD. We simulate the acquisition of CS-MRI by down-sampling the raw T1 image. Here, a Cartesian mask with 50% sampling ratio is used to simulate the down-sampling columns in k-space. In order to reconstruct MRI, classical methods usually use sparsity constraints, discrete wavelet transform, dictionary learning, etc. Although these classical algorithms have achieved good performance, they still face challenges. One of them is the personalized processing of different image features. It is difficult to design different processing methods for many different image features at the same time. For example, in the method of designing filters, it is usually difficult to automatically use different filters for different pixels simultaneously. Deep learning methods show the potential to solve the above problems. Existing deep learning methods usually input lowquality data into the model to obtain high-quality reconstructed images. Although the reconstruction algorithm based on deep learning can achieve better performance, its interpretability still faces challenges. This black box feature may cause potential risks. For example, if there is some small change in anatomy, it is difficult to identify. In addition, the process of AI model improving image quality is also unknown. In order to solve the above problems, a model based on a reinforced deep learning algorithm is designed. In this study, a deep reinforcement learning framework was designed to reconstruct CS-MRI to make the reconstruction process interpretable, speed up the acquisition of MRI in clinical practice and improve the quality of MRI images. This principle is shown in figure 1(A). The image reconstruction process can be regarded as a Markov decision process (MDP). In this MDP model, each pixel corresponds to an agent that is used to model multi-agent problems. The input image at each time step is regarded as the state of the DRL model. After acquiring state s t at time step t, each agent selects an action from the action space to change its own pixel value, and receives a reward value r t , which is used to evaluate the degree of improvement of the image. Compared to previous methods, this study designs a reward function that considers both the MRI content and the improvement of MRI features, as shown in equation (1):\nR = 0.1 MRI (0) \u2212 MRI (target) \u2212 MRI (T) \u2212 MRI (target) + MRIF (0) \u2212 MRIF (target) \u2212 MRIF (T) \u2212 MRIF (target) ,(1)\nwhere MRI (0) means the MRI image should be reconstructed at the initial time step. MRI (target) means target MRI image. MRI (T) represents the reconstructed MRI image at time step T. MRIF (0) means the features of the MRI image should be reconstructed at the initial time step. MRIF (target) means the features of the target MRI image. MRIF (T) represents the features of the reconstructed MRI image at time step T.\n\nHere, the VGG16 model pre-trained by Google is used to extract MRI features. We remove the classification layer of the VGG16 model and input the MRI image to obtain the image features.\n\nIn this study, CS-MRI is generated using Cartesian sampling in k-space. Cartesian sampling is a Gaussian distribution with a sampling rate of 50%. Cartesian mask with 50% sampling ratio is used to simulate down-sampling columns in k-space. The DRL model is divided into three parts: the feature extraction module, policy selection module and parameter optimization module. The overall structure of the model is shown in supplementary material figure S1 (available online at stacks.iop.org/JNE/18/ 066032/mmedia). The feature extraction module is realized by the convolution network, which is used to extract the potential features of the image. In the above process, the spatial resolution of the image remained unchanged. The core of the policy selection module is the advantage actor critical algorithm (A2C), which aims to generate state-to-action mapping [26]. The output of the feature extraction module is sent to the strategy selection module, and the strategy selection module outputs the probability distribution of actions. The probability distribution generated was evaluated using the value calculation part. The core of the parameter optimization module is the deep deterministic policy gradient (DDPG) algorithm [27]. After the policy selection module selects the action for each agent, a parameter optimization module is used to optimize the parameters of the filter. Finally, the value calculation part reevaluates the parameter optimization module. The loss function of each module is shown in equations (2)- (6):\nL SS = L \u03c0 + 0.25L VC + 0.1L E .(2)\nThe loss function of the DRL model is L SS . L \u03c0 is shown by equation (3). L VC is shown by equation (4). L E is shown by equation (5):\nL \u03c0 = \u2212 log \u03c0 a|s; \u03b8 s , \u03b8 f R \u2212 V s; \u03b8 v ; \u03b8 f , (3)\nL \u03c0 represents the loss of the strategy selection module part. a represents the selected action (filter). s represents the model state. \u03b8 s represents the parameters of the strategy selection module. \u03b8 f represents the parameters of the feature extraction module. R is reward. V is a value which is the output of the value calculation section. \u03b8 v represents the parameters of the value calculation section:\nL VC = \u2225R \u2212 V s; \u03b8 v ; \u03b8 f \u2225 2 ,(4)\nL VC represents the loss of the value calculation section. R is reward. V is a value which is the output of the value calculation section. \u03b8 v represents the parameters of the value calculation section. \u03b8 f represents the parameters of the feature extraction module:\nL E = a \u03c0 a|s; \u03b8 s , \u03b8 f log \u03c0 a|s; \u03b8 s , \u03b8 f ,(5)\nL E represents the negative entropy loss. It is used to encourage action exploration\nL PO = \u22120.5V s, \u03b8 p .(6)\nL PO represents the loss of the parameter optimization module. When training the parameter optimization module, the strategy selection module is frozen. s represents the model state. \u03b8 p represents the parameters of parameter optimization module.\n\nThe action here refers to the filter, and the action space used in this study is shown in table 2. At time t, an image is input as state s t , and the output image is s t+1 . The DRL model used in this study included three-time steps for each episode.\n\nThe number of training iterations was 30 000. When the strategy selection module is trained, the parameter optimization module is frozen, otherwise, the strategy selection module is frozen. The model is iterated twice, and the two modules above alternate. The model optimizer was Adam. The learning rate attenuation method was used in the training process. ReLU was used as an activation function for the entire network. The experimental platform was a workstation with NVIDIA GTX 1080Ti GPU.\n\n\nFull convolution neural network (FCN)\n\nThis part is used to generate the whole-brain AD DPM. Displaying diagnostic evidence can improve the interpretability of the AI model [28,29]. The model construction includes two steps: building a convolution classification model and a 3D DPM generation model, as shown in figures 1(B) and (C). The working principle of this part is shown in figure 2.\n\nFirst, the convolution classification model needs to sample 5000 voxel blocks with a size of 47 \u00d7 47 \u00d7 47 from each original image with a size of 181 \u00d7 217 \u00d7 181 and then is trained by the above voxel blocks with the softmax classification function. The output of the classification model is health status. MCC was used to weigh the degree of model attention on different voxel blocks reflecting different brain regions while diagnosing AD. Through cube sampling and statistics of the corresponding MCC, the importance of any part of the brain to the diagnosis of AD can be determined. The higher the MCC score of the brain domain, the more important it is to diagnose AD. The principle of MCC is shown in equation (7):\nMCC = [(TP \u00d7 TN) \u2212 (FP \u00d7 FN)] \u221a (TP + FP) \u00d7 (TP + FN) \u00d7 (TN + FP) \u00d7 (TN + FN) ,(7)\nwhere TN means true negative, TP means true positive, FN means false negative and FP means false positive.\n\nThe 3D DPM generation model is based on the convolution classification model described above. The output of this model is a convolution block with dimensions of 2 \u00d7 1 \u00d7 1 \u00d7 1. The 1 \u00d7 1 \u00d7 1 convolution block represents a 3D voxel. The number 2 of the block refers to the two channels of AD and normal (NL). Therefore, the AD DPM of the whole brain region can be obtained by inputting a 3D MRI image. The optimizer of this model is Adam, and the training technique of this model is the learning rate decay method. LeakyReLU is the activation function of the entire network, and dropout technology is used to increase the generalization ability of the model.\n\n\nMulti-modal diagnosis model\n\nIn this part, the DPM of high MCC score brain regions and individual clinical information are used to comprehensively judge the health status of patients using a multilayer perceptron network and explain the diagnosis basis of the model. As shown in figure 1(D), we embed the attention mechanism in a multilayer neural network. Through the attention map, we obtain the attention degree of the model to different clinical information explaining the parameter weights for AD diagnosis. The individual clinical information used in this study included age, gender, MMSE score and APoE4. The schematic diagram of the model is shown in supplementary material figure S2.\n\n\nResults\n\nThis section describes the performance of the model in diagnosing AD. In addition, the interpretability of each part is presented. This includes an interpretable image reconstruction process, interpretable image diagnosis process and interpretable biological information diagnosis process.\n\n\nInterpretable MRI reconstruction process\n\nThe reinforcement deep learning model designed in this study can explain the reconstruction process of CS-MRI. Here, we use different colors to represent different filters. If the relevant agent is processed by a certain action, the pixel represented by the above agent is overlaid by the color corresponding to the filter. Traditional AI methods usually input low-quality images into the model and then output high-quality images. Although these methods can achieve good performance, researchers are not sure how AI reconstructs images. At the same time, the above situation also has hidden dangers, that is, in the process of reconstructing the image, some subtle pathological features may have been changed. In this paper, we show that the model can design a reasonable filter for each pixel according to the image characteristics and visualize the distribution of different filters. Different colors were used to represent different specific actions, so that relevant researchers can intuitively observe how the model reconstructs the MRI. At the same time, it is also convenient to judge whether the above reconstruction process is reasonable and whether the important pathological features have undergone substantial changes, which increases the interpretability and reliability of the model to a certain extent. Compared to the previous deep learning model with black box characteristics, this model has higher interpretability and reliability, as shown in figure 3.\n\nIn figure 3, the DRL model can explain the individual filter for each pixel of the CS-MRI. Different filters are marked with different colors. In other words, the DRL model can show which processing method is selected for each pixel value. For example, the blue pixels shown in figure 3(b) represent the   Figure 4 shows the distribution of Gaussian filters with different time steps. It is found that as the quality of the image improves, the frequency of use of the Gaussian filter also decreases. By using reinforcement learning to visualize the optimization strategy of each step of the model, the interpretability of the model is improved to a certain extent.\n\nWe also compared the performance of our model to other advanced models on the same data set, such as DAGAN [30] and Unet [31]. Peak signal-to-noise ratio (PSNR) and structural similarity index (SSIM) are used to evaluate the model. The principles are shown in equations (8) and (9):\nSSIM = 2\u00b5 x \u00b5 y + c 1 \u03c3 xy + c 2 \u00b5 x 2 + \u00b5 y 2 + c 1 \u03c3 x 2 + \u03c3 y 2 + c 2 ,(8)\nwhere \u00b5 x and \u00b5 y represent the average of the two images, respectively. \u03c3 x and \u03c3 y represent the standard deviation of the two images, respectively. \u03c3 xy represents the covariance between the two images. c 1 and c 2 are constants:\nPSNR = 20log 10 MAX \u221a MSE ,(9)\nMAX means maximum value of pixels. MSE means mean square error. The performances of the models in the three test sets are presented in table 3.\n\nWe randomly selected samples from three test sets to show the effect of the DRL model on MRI image reconstruction, as shown in figure 5.\n\nBased on the experimental results, the quality of HQ-MRI is higher than CS-MRI, so HQ-MRI is more suitable for the diagnosis of AD. The performance of using CS-MRI and HQ-MRI to diagnose AD is shown in supplemental material figures S3 and S4.\n\n\nGeneration of 3D DPM of the brain\n\nThe AD DPM of the whole brain region can be generated quickly. AD DPM at pixel level can help neurologists find early pathological features in the patient's brain and provide evidence of early AD diagnosis. CS-MRI was reconstructed to generate HQ-MRI, and HQ-MRI was used to generate 3D DPM, as shown in figure 6. Figure 6(a) shows the DPM of AD and NL in each test set, with red for high-risk areas and blue for low-risk areas. In the three test data sets, the high-risk area (red) of the AD sample is very obvious, while the NL sample is dominated by the low-risk area (blue). The high-risk area refers to the area where the inferred probability of AD is greater than 0.5, and the low-risk area refers to the area where the inferred probability is less than 0.5. The color depth has a linear relationship with the probability of brain disease. Figures 6(b)-(d) show the DPM of different MRI slices of the same AD sample from axial, coronal and sagittal images. To a certain extent, the model in this paper can assist neurologists to discover more pathological features of AD. At the same time, the model can provide the basis for the diagnosis of AD, and it can also allow relevant clinicians to judge whether the AI diagnosis result is reasonable.\n\nThe MCC heat map was established to evaluate the anatomical consistency of the AD regions identified by the model. Figure 7(a) shows the distribution of the MCC scores in different data sets. The MCC thermogram can show which pathological changes play an important role in the diagnosis of AD, indicating that the model has the ability to analyze the disease from the perspective of anatomy and pathology. Figure 7(b) shows that the model gives different attention to different morphological positions. The experimental results show that the model has focussed attention on the temporal lobe, hippocampus, cingulate cortex, corpus callosum, parietal lobe and frontal lobe. The ROI of the model is similar to the diagnosis basis of the clinician. This proves the interpretability of the method proposed in this paper to a certain extent. Due to morphological information that is not helpful in the diagnosis of AD, the model does not show great interest in regions such as the skull and cervical spine. This helps neurologists to observe neuropathological changes in AD patients.\n\nIn order to further evaluate the rationality of the model, we also compared the DPM generated by different methods. The attention mechanism is proven to be an effective method for processing medical images [32][33][34]. Therefore, in addition to the cube sampling method proposed in this paper, this paper also constructs an attention-driven model to generate DPM. Further theoretical analysis can be found in [32][33][34]. The results are shown in figure 8.\n\nAs shown in figure 8, both models believe that the frontal lobes and temporal lobes have a higher risk of AD. This result is consistent with current clinical diagnostic criteria. This phenomenon shows that the AD analysis method based on cube sampling designed in this paper is reasonable to a certain extent. In addition, we found that compared to the 3D attention method, the method in this paper may be more granular in predicting the risk of diseases in different regions of the brain. It depicts the edges of high-risk areas more clearly. We speculate that this is because a small cube sampling strategy can help the model better learn the disease risk for each pixel. The attention mechanism pays more attention not to pixels, but to areas that are more important to the diagnosis. Although the model in this paper shows potential, the above viewpoints still need to be further verified.   Since the etiology of AD is not yet clear, it is even difficult for human experts to accurately draw all the lesion areas in MRI. Autopsy is an effective method to verify neuropathology. Therefore, in future work, we will further collect cases including autopsy reports to further study the reliability of the model.  \n\n\nMulti-modal AD diagnosis\n\nIn this study, we used both morphological and clinical information to diagnose AD. In order to eliminate the influence of the initial data distribution on the model performance, this study uses the t-SNE method to study the original data distribution, as shown in figures 9(A) and (B). The pixel matrix of the registered image was employed for t-SNE analysis. In figure 9(A), the original data distribution of the three data sets is consistent. The original data for all data sets did not show obvious polarization. Figure 9(B) shows the t-SNE analysis of the DPM for each data set. In figure 9(B), an obvious polarization between AD samples and NL samples is illustrated, indicating the high efficiency of learning the AD pathological characteristics and the high accuracy of the generated brain AD DPM.\n\nAfter analyzing the raw data using t-SNE, the performance of various models is evaluated. The SSC of our model and other ablation experiments are shown in figure 10. The area under the curve (AUC) was used to evaluate the performance of the framework and related ablation experiments. In order to explore the robustness and universality of the model, two additional data sets (AIBL and NACC) were also used to evaluate the performance of the model.\n\nThe receiver operating characteristic curve (ROC) of each model in ADNI is shown in figure S3. The precision-recall curve of each model is shown in figure 11.\n\nFinally, the multi-modal model designed in this study achieved an AUC of 99.6% in the ADNI test set, 97.9% AUC for AIBL and 96.1% AUC for NACC. The comprehensive performance of the model is superior to that of other comparative experiments. In order to evaluate the performance of the models more comprehensively, in addition to the AUC, a variety of indicators is used to evaluate the performance of each model, as shown in table 4. The calculation principles of sensitivity, specificity and F1 score are shown in equations (10) and (11):\nSEN = TP TP + FN SPE = TN TN + FP ,(10)\nwhere SEN means sensitivity, SPE means specificity. TN means true negative, TP means true positive, FN means false negative and FP means false positive:\nF1 = 2 \u00d7 TP (2 \u00d7 TP + FP + FN) .(11)\nIn equation (11), F1 means the F1 score. The meaning of other parameters is the same as in equation (10).\n\nWhen only using clinical information data without APoE4, the model reached 94.7% \u00b1 0.2% accuracy (ACC) and 99.4% \u00b1 0.3%AUC in the ADNI test set. When the APoE4 state is considered by the model, the model achieves 94.9% \u00b1 1.5%ACC and 99.5% \u00b1 0.2%AUC in the same data set. When the APoE4 state is added, the performance of the model is improved. When only using DPM to diagnose AD, the diagnosis level of the model is similar to that of a traditional CNN. The high-risk areas of AD predicted by our model overlap with the MRI images, as shown in figure 12(A). Based on the experimental results, the model's main focus area is the hippocampus and the medial temporal lobe. Cortical atrophy also occurs in the high-risk area given by the model. This is highly consistent with the existing clinical diagnosis basis. This phenomenon proves the rationality of the method in this paper to a certain extent.\n\nWhen using multimodal information (DMP and clinical information containing APoE4) at the same time, the model reached 95.6% \u00b1 2.5%ACC and 99.6% \u00b1 0.2%AUC in the ADNI test set. In order to make the model multimodal and interpretable, the attention mechanism is integrated into the analysis of personal clinical information. The attention map expresses the degree of attention of the model to different physiological parameters, that is, the basis of the diagnosis of AD. The average attention of the model to different physiological parameters of the ADNI is shown in figure 12(B).\n\nMMSE and APoE4 are the two physiological parameters raising the highest degree of concern, which is consistent with the clinical diagnostic criteria [35][36][37][38]. In addition, the model shows a certain degree of attention to age and gender. The model suggests that age and gender are also related to AD, and gender is more important than age in the diagnosis of AD. In recent studies, age and gender have also been found to be related to the formation of AD [39][40][41][42]. This phenomenon shows that the AI model designed in this study can not only analyze biomarkers directly related to diseases, but has the ability to discover potential biomarkers of diseases. Figure 9. T-SNE analysis of image data and ROC of the model. Figure (A) show t-SNE analysis of MRI images of three data sets (ADNI, AIBL, NACC). Pixel matrix of the MRI image is used as input, and t-SNE the output 2D data distribution map. Figure (B) shows the t-SNE analysis of the disease risk graph for three data sets. Red data represents the AD sample, and blue data represents the NL sample. \n\n\nDiscussion\n\nIn this paper, we present a multimodal AI framework with an entire process of interpretability that can diagnose AD accurately. CS-MRI is first used to reduce the scanning time and improve the clinical experience of patients. Second, CS-MRI is converted to HQ-MRI using an MRI reconstruction module based on deep reinforcement learning. Third, HQ-MRI is employed by the DPM generation module to generate AD DPM in the whole brain region. Finally, the DPM of important areas of the brain and individual clinical information are input into the multimodal diagnosis module based on the attention mechanism to obtain the diagnosis results.\n\nIn this study, we design a deep reinforcement learning framework for converting CS-MRI to HQ-MRI. Compressed sensing technology is applied to acquire CS-MRI to solve the time-consuming problem of continuous sampling in k-space. However, compressed sensing technology will reduce the image quality. Although the end-to-end black box model based on traditional AI can reconstruct CS-MRI, the reconstruction process cannot be explained. The deep reinforcement learning framework designed in this study regards each pixel as an agent, and then each agent will choose different individual filters according to pathological features to change its pixel value, in order to achieve the purpose of optimizing image quality. This method not only enhances the interpretability of the model, but enhances its reliability. The experimental results show that the selection of the filter by the model is generally consistent with the selection of human experts. An unsharp filter and a Laplace filter will be selected in the skull and cerebrospinal fluid, in order to enhance contrast. For the gap between the skull and brain tissue, the model infers that a box filter can be used to smooth the pixels. For aliasing in the image, the model uses a subtraction filter. The final model achieves acceptable results in the ADNI test set and two external test sets, as shown in figure 5. At the same time, we also compare the performance of our model with other advanced models in the same data set, as shown in table 3. HQ-MRI was used to generate the AD DPM. The core of the DPM generation module is the FCN obtained by reforming the trained classification CNN. The module can map complex anatomical information into a simple and intuitive DPM. Disease risk in any position in the brain can be accurately predicted, and the predicted granularity reaches pixel level, as shown in figure 6. Compared to the traditional method of pathological research using regular-shaped ROIs, this method can determine the high-risk area of AD more accurately. To date, the etiology of AD is still unclear. However, the above strategies can lay a foundation for further pathological research on AD.\n\nBefore training the diagnosis model, we used t-SNE to study the distribution of the original data to avoid the huge difference in the distribution of the original data. T-SNE can project high-dimensional data into 2D space to visualize the data distribution. We used t-SNE to analyze the pixel matrix of the registered MRI image, and found that there was no significant difference in the distribution of the original data, indicating that none of the AD and NL samples of the data sets show obvious pixel value differences, and will not affect the effectiveness of the model, as shown in figure 9(A). After analyzing the DPM of AD disease using t-SNE, polarization was found in the AD and NL samples, as shown in figure 9(B). The AD and NL samples without distribution differences showed obvious differences after the model processing. The results show that the model can effectively learn the pathological features of AD and generate a DPM of AD with different degrees. Pixel-level brain AD DPM can help neurologists find early pathological features of patients' brains and provide evidence of early AD diagnosis.\n\nThis study uses multimodal data to diagnose AD. The AD DPM of important brain regions and clinical information with individual characteristics (age, gender, MMSE and APoE4) were used to diagnose AD. The model reached 95.6% \u00b1 2.5%ACC and 99.6% \u00b1 0.2%AUC in the ADNI test set. For multi-center study, the reproducibility of this method is also very important [43]. Therefore, in addition to the ADNI data set, we verified the performance of the model in AIBL and NACC. The model reached 95.8% \u00b1 0.7%ACC and 97.9% \u00b1 0.2%AUC in the AIBL, and it reached 90.7% \u00b1 1.0%ACC and 96.1% \u00b1 0.3%AUC in the NACC. In order to verify the influence of different modal information on the diagnosis of AD, ablation experiments were implemented. When using only DPM, the diagnosis level of the model is similar to that of the traditional CNN. This phenomenon means that the model proposed can effectively extract the effective features from the raw data. The original MRI was abstracted as DPM without the loss of a large amount of effective information. The predicted high-risk AD areas overlap with the MRI images, as shown in figure 12(A). The model showed great attention to the hippocampus and medial temporal lobe. By combining figures 7 and 12, we found the phenomenon of cerebral cortex atrophy in the high-risk areas predicted by the model, which is the same phenomenon that neurologists are concerned about. The experimental results prove the rationality of this method to a certain extent. In addition, the model pays attention to other regions, such as the parietal lobe, frontal lobe, corpus callosum, etc. We speculate that this is related to amyloid-\u03b2 and Tau protein deposition in important brain regions. The model in this paper has the ability to assist clinicians in analyzing pathological characteristics to a certain extent. However, since the etiology of AD is still unclear, the result still needs to be further verified by anatomical results. For example, the autopsy report overlaps with the prediction results of the model in this paper. Therefore, in our future work, we will collect samples containing anatomical reports to further verify the reliability of this method from a clinical perspective.\n\nWhen only clinical information was used, the model performance with APoE4 status was higher than that without APoE4 status. This suggests that APoE4 may be a target for AD treatment. When using multimodal information, the model performance is further improved. This shows that not only the anatomical pathology, but clinical information with personal characteristics plays a crucial role in the diagnosis of AD, implying the better potential development of multimodal models. The attention mechanism is embedded in the model to improve the interpretability of the multimodal model. The attention map expresses the attention of the model to different physiological parameters as an AD diagnostic basis. In figure 12(B), the model shows the strongest attention to MMSE and APoE4, agreeing with the results of clinical practice and the above ablation experiment. From a biomedical point of view, typical histopathological changes in AD include amyloid deposition and neuronal fiber entanglement [44,45]. Some studies have shown that APoE4 can reduce the stability of the nerve cell membrane, leading to neurofibrillary tangle and cell death, which are important factors for AD [46,47]. In addition, the model shows a certain degree of concern regarding age and gender and pays more attention to gender. Recent studies have shown that gender can regulate the effect of APoE4 on Tau protein precipitation in the brain. Women with APoE4 mutations are more likely to have Rau accumulation than men [48,49]. The actual biomarker research results were the same as the model analysis results in this study. Studies have also shown that as age increases, the probability of suffering from AD increases year by year. This phenomenon shows that the AI model designed in this study can not only analyze biomarkers directly related to diseases, but has great potential to discover potential biomarkers of diseases.\n\nAlthough the model in this study shows potential, there are still limitations. First, this study only included AD and NL health conditions, which makes it difficult to meet the needs of neurologists in clinical practice. In the future, we will collect more data on the types of diseases and study how to further expand the function of the model. Second, the personal physiological information used in this study only included age, gender, MMSE and APoE4. With the deepening of research, more biological information related to AD has been found. In the future, we plan to collect more types of physiological information, with the hope that the AI model can guide the targeted treatment of AD. At the same time, we will also collect more center data to further verify the reliability of the model. The influence of acquisition sequence on diagnosis will be further studied. Third, the risk area predicted by the model needs further analysis and comparison with the actual anatomical report. To date, the pathogeny of AD is not clear, and so it is difficult to obtain accurate lesion markers. Therefore, the purpose of this paper is to propose a multimodal AI auxiliary diagnosis model that can be explained to a certain extent, rather than a model for accurately segmenting lesions. However, the model's ability to predict disease risk still needs to be further evaluated. We will collect autopsy data with more relevant institutions in future work to specifically evaluate the model's ability to segment the lesion. For example, to evaluate the uncertainty of the model and verify the relationship between \u03b2-amyloid deposition in autopsy reports and model prediction results. We will collect autopsy data with more relevant agencies in our future work. The importance of each physiological parameter in the development of AD requires further quantitative analysis. Fourth, although the method in this paper achieves better performance, it still does not meet clinical requirements. In future work, we will continue to study the optimization methods of the model, such as fusing attentiondriven features to further increase the performance and interpretability of the model. In addition, non-AI algorithms have advantages that AI methods do not have in MRI reconstruction. Therefore, how to integrate AI and non-AI will also be one of our future works.\n\nIn conclusion, a multi-mode deep reinforcement learning with the whole process of of interpretability is designed, which can not only diagnose AD accurately, but analyze potential biomarkers. The model can speed up the process of patients' medical treatment, improve the experience of patients' medical treatment, and provide a point of view for the combination of AI and medical diagnosis technology.\n\n\nData availability statement\n\nThe data that support the findings of this study are available in http://adni.loni.usc.edu/, https:// aibl.csiro.au/ and https://naccdata.org/.\n\nThe data that support the findings of this study are available upon reasonable request from the authors.\n\n\nAcknowledgments\n\nThis work was financially supported by the NSFC (National Natural Science Foundation of China) project, Authorization Number: 61771261. The authors thank the ADNI, AIBL and NACC investigators for providing access to the data. Data used in the preparation of this article were obtained from the Alzheimer's Disease Neuroimaging Initiative (ADNI) database (www.adni.loni.usc.edu). The ADNI was launched in 2003 as a public-private partnership, led by Principal Investigator Michael W Weiner, MD. The primary goal of ADNI has been to test whether serial magnetic resonance imaging (MRI), positron emission tomography (PET), other biological markers and clinical and neuropsychological assessment can be combined to measure the progression of mild cognitive impairment (MCI) and early Alzheimer's disease (AD). For up-to-date information, see www.adni-info.org. Data collection and sharing for this project was funded by the Alzheimer's Disease Neuroimaging Initiative (ADNI) (National Institutes of Health, Grant No. U01 AG024904) and DOD ADNI (Department of Defense, Award No. W81XWH-12-2-0012). ADNI is funded by the National Institute on Aging, the National Institute of Biomedical Imaging and Bioengineering, and through generous contributions from the following: \n\nFigure 1 .\n1Schematic diagram of deep learning framework. CS-MRI means compressed sensing MRI. HQ-MRI means high-quality image. AD means Alzheimer's disease.\n\nFigure 2 .\n2Schematic diagram of building an FCN to obtain DPM and Matthews correlation coefficient (MCC) distribution maps. Size of each HQ-MRI is 181 \u00d7 217 \u00d7 181. HQ-MRI is randomly sampled by cubes, and each HQ-MRI is randomly sampled 5000 times. Cube pixel block is input into the convolutional neural network (CNN) for binary classification. Based on the classification results, we can calculate the MCC score of each part of the brain. MCC score reflects the model's attention in different brain regions when diagnosing AD. After obtaining a satisfactory classification model, the convolutional block is frozen and the dense layers are replaced with convolutional layers. Parameters of the original fully connected layer are filled into the new 3D convolutional layer. Parameter of dropout is 0.1. Here, the FCN construction is completed. Risk map of the whole brain can be obtained.\n\nFigure 3 .\n3Example of filter distribution on pixels. Different colors represent different types of filters. where (a), (d) and (g) represent target images. ((b), (c), (e), (f), (h) and (i)) Laplace filter, unsharp filter, sobel_left filter, sobel_right filter, box filter and subtraction filter, respectively. pixels processed using the Laplace filter. The welltrained DRL model can select the filter according to the anatomical structure of the brain. The filter with a contrast enhancement function is mainly used to optimize regions, such as the skull and cerebrospinal fluid, as shown in figures 3(b) and (c). Sobel_left and sobel_right filters strengthen the left and right sides of the skull, as shown in figures 3(e) and (f). In this way, researchers in related fields can intuitively judge whether the model reconstruction strategy is reasonable.\n\nFigures\nsame NL sample. The experimental results show that the model can effectively predict the AD risk at any position of the brain based on MRI images, and the model can be used for pathological interpretation.\n\nFigure 4 .\n4Distribution of Gaussian filters at different time steps.\n\nFigure 5 .\n5Results of CS-MRI reconstruction by deep reinforcement learning.Figures (a)-(c) show the reconstruction of three random CS-MRI samples randomly obtained from ADNI, AIBL and NACC. Zero represents the experimental results of the traditional zero filling method, and DRL represents the experimental results of the reinforcement deep learning framework in this paper. Mask shows the image information of Cartesian mask. Target represents the raw data. It also is ground truth.\n\nFigure 6 .\n6DPM of different subjects. DPM of different health samples from different data sets is shown in chart a of DPM of different health conditions from axial, coral and digital. Blue represents low risk, red high-risk. Red refers to the area where the inferred probability of AD is greater than 0.5, and blue refers to the area where the inferred probability is less than 0.5. DPM highlights the anatomical areas of the brain associated with AD pathology.Figure 6(b)-(d) show DPM of different MRI sections of the same AD sample from axial, coral and digital. Figures 6(e)-(g) show the DPM of different MRI sections in NL samples.\n\nFigure 7 .\n7Distribution of MCC scores of brains in different data sets (figure 7(a) shows the MCC of all regions of the brain in different data set samples, which shows the brain area that the AI model focuses on.Figure (a)shows three lines of images from top to bottom, corresponding to axial, national and digital stacks.Figure (b)shows the distribution of MCC scores for different MRI sections in the same sample.).\n\nFigure 8 .\n8DPM generated by different methods. (a) is MRI of a random case. (b) is the DPM generated by the model designed in this paper. (c) is the DPM generated by the attention model. Attention mechanism model refers to a 3D image attention mechanism model. Model takes the entire 3D MRI as input and then generates DPM through a 3D attention full convolutional network.\n\nFigure 10 .\n10Sensitivity-specificity curve (SSC) of our AI model and other models. Figure (A) shows the performance of the model considering only individual clinical information, APoE represents the performance of the model considering APoE status, and Clinic represents the performance of the model not considering APoE status. Figure (B) shows the performance of the model considering only image information, DPM represents the performance of the model using only a disease risk map, and CNN represents the performance of the convolutional neural network using only MRI. Figure (C) is the SSC of our model.\n\nFigure 11 .\n11Precision-recall curve of each model.Figure (A)shows the performance of a model that only considers individual clinical information. Here, APoE represents the performance of a model that considers the APoE state, and Clinic represents the performance of a model that does not consider the APoE state.Figure (B)shows the performance of the model considering only image information. Here, DPM represents the performance of the model using only the disease risk map, and CNN represents the performance of the convolutional neural network using only the MRI image.Figure (C)shows the performance of the multi-modal diagnostic model designed in this paper.\n\nFigure 12 .\n12Pathological analysis of the model.Figure (A)shows the overlap between the high-risk areas predicted by the model and the MRI images. Risk area in figure (A) refers to the area where the risk probability is greater than 0.8.Figure (B)shows the model's attention to different individual physiological parameters, which shows whether the model speculates that a certain physiological parameter will affect the formation and development of AD.\n\nTable 1 .\n1Demographic information (AD means Alzheimer's disease. NL means normal).Data set \n\nADNI \n\nAIBL \n\nNACC \n\nItem \n\nNL (n = \n\n226) \n\nAD (n = \n\n187) \n\np \n\nNL (n = \n\n395) \n\nAD (n = \n\n72) \n\np \n\nNL (n = \n\n269) \n\nAD (n = \n\n200) \n\np \n\nAge (years) \n\n76.0 \n\n75.4 \n\n0.311 \n\n72.3 \n\n73.4 \n\n0.263 \n\n70.4 \n\n75.3 \n\n<0.0001 \n\n[range] \n\n[60,90] \n\n[55,91] \n\n[60,92] \n\n[55,93] \n\n[55,94] \n\n[55,95] \n\nGender (Male,n) \n\n117 \n\n97 \n\n0.984 \n\n169 \n\n29 \n\n0.693 \n\n91 \n\n101 \n\n<0.0001 \n\n[ratio] \n\n[51.8%] \n\n[51.9%] \n\n[42.8%] \n\n[40.3%] \n\n[33.8%] \n\n[50.5%] \n\nMMSE (Ave) \n\n29.1 \n\n23.4 \n\n<0.0001 \n\n28.7 \n\n20.4 \n\n<0.0001 \n\n28.9 \n\n22.5 \n\n<0.0001 \n\n[range] \n\n[25,30] \n\n[18.28] \n\n[25,30] \n\n[6,28] \n\n[20,30] \n\n[4,30] \n\nAPoE4 (positive,n) \n\n58 \n\n119 \n\n<0.0001 \n\n30 \n\n19 \n\n0.001 \n\n84 \n\n173 \n\n<0.0001 \n\n[ratio] \n\n[25.7%] \n\n[63.6%] \n\n[7.6%] \n\n[26.4%] \n\n[31.2%] \n\n[86.5%] \n\n\nTable 2 .\n2Strengthening the learning action space in DRL. (In addition to the following actions, it also includes a subtraction filter, which directly subtracts a fixed pixel value)Action \nSize \nAction \nSize \n\nNothing \n-\nSobel filter (down) 3 \u00d7 3 \nLaplace filter \n3 \u00d7 3 Box filter \n5 \u00d7 5 \nUnsharp masking \n5 \u00d7 5 Bilateral filter \n5 \u00d7 5 \nSobel filter (left) \n3 \u00d7 3 Median filter \n5 \u00d7 5 \nSobel filter (right) \n3 \u00d7 3 Gaussian filter \n5 \u00d7 5 \nSobel filter (upper) 3 \u00d7 3 Gaussian filter \n3 \u00d7 3 \n\n\n\nTable 3 .\n3Performance of different algorithms in different test sets.PSNR \nSSIM \nPSNR \nSSIM \nPSNR \nSSIM \n\nDAGAN \nUnet \nDRL (our) \nADNI \n36.01 \n0.98 \n36.77 \n0.99 \n36.78 \n0.98 \nAIBL \n35.27 \n0.97 \n35.98 \n0.97 \n36.03 \n0.98 \nNACC \n35.96 \n0.97 \n36.69 \n0.98 \n36.76 \n0.98 \n\n\n\nTable 4 .\n4Performance statistics of different models. (Clinic represents the performance of a model that does not consider the APoE state, and APoE represents the performance of a model that considers the APoE state. CNN represents the performance of the convolutional neural network using only the MRI image, and DPM represents the performance of the model using only the disease risk map. DP + AP show the performance of the multi-modal diagnostic model designed in this paper.)ACC \nAUC \nSen \nSpe \nF1 \nMCC \n\nClinic \nTest \n0.947 \u00b1 0.020 \n0.994 \u00b1 0.003 \n0.969 \u00b1 0.054 \n0.930 \u00b1 0.036 \n0.942 \u00b1 0.023 \n0.898 \u00b1 0.039 \nAIBL \n0.916 \u00b1 0.029 \n0.980 \u00b1 0.002 \n0.893 \u00b1 0.050 \n0.920 \u00b1 0.045 \n0.772 \u00b1 0.052 \n0.736 \u00b1 0.052 \nNACC \n0.863 \u00b1 0.011 \n0.933 \u00b1 0.005 \n0.814 \u00b1 0.046 \n0.899 \u00b1 0.028 \n0.840 \u00b1 0.017 \n0.721 \u00b1 0.023 \nAPoE4 \nTest \n0.949 \u00b1 0.015 \n0.995 \u00b1 0.002 \n0.986 \u00b1 0.024 \n0.938 \u00b1 0.032 \n0.957 \u00b1 0.015 \n0.922 \u00b1 0.027 \nAIBL \n0.919 \u00b1 0.029 \n0.981 \u00b1 0.002 \n0.914 \u00b1 0.045 \n0.920 \u00b1 0.041 \n0.782 \u00b1 0.051 \n0.750 \u00b1 0.051 \nNACC \n0.872 \u00b1 0.007 \n0.940 \u00b1 0.003 \n0.841 \u00b1 0.030 \n0.895 \u00b1 0.022 \n0.848 \u00b1 0.010 \n0.738 \u00b1 0.014 \nCNN \nTest \n0.766 \u00b1 0.019 \n0.823 \u00b1 0.007 \n0.724 \u00b1 0.076 \n0.800 \u00b1 0.029 \n0.732 \u00b1 0.035 \n0.527 \u00b1 0.044 \nAIBL \n0.843 \u00b1 0.055 \n0.902 \u00b1 0.013 \n0.783 \u00b1 0.097 \n0.854 \u00b1 0.079 \n0.617 \u00b1 0.060 \n0.556 \u00b1 0.067 \nNACC \n0.796 \u00b1 0.044 \n0.877 \u00b1 0.012 \n0.738 \u00b1 0.090 \n0.839 \u00b1 0.131 \n0.757 \u00b1 0.027 \n0.597 \u00b1 0.066 \nDPM \nTest \n0.772 \u00b1 0.028 \n0.820 \u00b1 0.018 \n0.690 \u00b1 0.034 \n0.838 \u00b1 0.041 \n0.730 \u00b1 0.030 \n0.538 \u00b1 0.057 \nAIBL \n0.913 \u00b1 0.009 \n0.896 \u00b1 0.012 \n0.581 \u00b1 0.065 \n0.973 \u00b1 0.018 \n0.671 \u00b1 0.029 \n0.639 \u00b1 0.030 \nNACC \n0.830 \u00b1 0.021 \n0.903 \u00b1 0.012 \n0.689 \u00b1 0.060 \n0.934 \u00b1 0.021 \n0.774 \u00b1 0.037 \n0.656 \u00b1 0.039 \nDP + AP \nTest \n0.956 \u00b1 0.025 \n0.996 \u00b1 0.002 \n0.961 \u00b1 0.026 \n0.968 \u00b1 0.031 \n0.961 \u00b1 0.018 \n0.930 \u00b1 0.031 \nAIBL \n0.958 \u00b1 0.007 \n0.979 \u00b1 0.002 \n0.864 \u00b1 0.022 \n0.975 \u00b1 0.011 \n0.863 \u00b1 0.018 \n0.839 \u00b1 0.022 \nNACC \n0.907 \u00b1 0.010 \n0.961 \u00b1 0.003 \n0.873 \u00b1 0.024 \n0.932 \u00b1 0.027 \n0.889 \u00b1 0.001 \n0.810 \u00b1 0.020 \n\n\n\n\nAbbVie, Alzheimer's Association; Alzheimer's Drug Discovery Foundation; Araclon Biotech; BioClinica, Inc.; Biogen; Bristol-Myers Squibb Company; CereSpir, Inc.; Cogstate; Eisai Inc.; Elan Pharmaceuticals, Inc.; Eli Lilly and Company; EuroImmun; F Hoffmann-La Roche Ltd and its affiliated company Genentech, Inc.; Fujirebio; GE Healthcare; IXICO Ltd; Janssen Alzheimer Immunotherapy Research & Development, LLC.; Johnson & Johnson Pharmaceutical Research & Development LLC.; Lumosity; Lundbeck; Merck & Co., Inc.; Meso Scale Diagnostics, LLC.; NeuroRx Research; Neurotrack Technologies; Novartis Pharmaceuticals Corporation; Pfizer Inc.; Piramal Imaging; Servier; Takeda Pharmaceutical Company; and Transition Therapeutics. The Canadian Institutes of Health Research is providing funds to support ADNI clinical sites in Canada. Private sector contributions are facilitated by the Foundation for the National Institutes of Health (www.fnih.org). The grantee organization is the Northern California Institute for Research and Education, and the\nFundingThis work was financially supported by the National Natural Science Foundation of China (NSFC) project (Authorization Number: 61771261).Conflict of interestThe authors declare no conflict of interest.Ethical approvalAll procedures performed in studies involving human participants were in accordance with the ethical standards of the institutional and/or national research committee and with the 1964 Helsinki Declaration and its later amendments or comparable ethical standards. Informed consent to clinical testing and neuroimaging prior to participation of the ADNI, AIBL, NACC cohorts were obtained, approved by the institutional review boards (IRB) of all participating institutions. The Institutional Review Board of Nankai University approved this study and informed consents were waived for a retrospective cohort of AD disease patients.ORCID iDsQuan Zhang \ue9d9 https://orcid.org/0000-0002-9039-4140 Qian Du \ue9d9 https://orcid.org/0000-0003-4115-9563\n. P Scheltens, K Blennow, M M Breteler, B De Strooper, G B Frisoni, Salloway S Van Der Flier, W , Scheltens P, Blennow K, Breteler M M, de Strooper B, Frisoni G B, Salloway S and Van der Flier W M 2016\n\nAlzheimer's disease Lancet. 10.1016/S0140-6736(15)01124-1388Alzheimer's disease Lancet 388 505-17\n\nGreater effect of polygenic risk score for Alzheimer's disease among younger cases who are apolipoprotein E-\u03b54 carriers. B Fulton-Howard, A M Goate, R P Adelson, J Koppel, M L Gordon, N Barzilai, G Atzmon, P Davies, Y Freudenberg-Hua, 10.1016/j.neurobiolaging.2020.09.014e1-101.e9Neurobiol. Aging. 99101Fulton-Howard B, Goate A M, Adelson R P, Koppel J, Gordon M L, Barzilai N, Atzmon G, Davies P and Freudenberg-Hua Y 2021 Greater effect of polygenic risk score for Alzheimer's disease among younger cases who are apolipoprotein E-\u03b54 carriers Neurobiol. Aging 99 101.e1-101.e9\n\nA simple nomogram prediction model to identify relatively young patients with mild cognitive impairment who may progress to Alzheimer's disease. W Chen, L Songtao, M Yangyang, S Lv, F Wu, J Du, H Wu, Wang S Zhao, Q , 10.1016/j.jocn.2021.06.026J. Clin. Neurosci. 91Chen W, Songtao L, Yangyang M, Lv S, Wu F, Du J, Wu H, Wang S and Zhao Q 2021 A simple nomogram prediction model to identify relatively young patients with mild cognitive impairment who may progress to Alzheimer's disease J. Clin. Neurosci. 91 62-68\n\nTracking pathophysiological processes in Alzheimer's disease: an updated hypothetical model of dynamic biomarkers. C R JackJr, 10.1016/S1474-4422(12)70291-0Lancet Neurol. 12Jack C R Jr et al 2013 Tracking pathophysiological processes in Alzheimer's disease: an updated hypothetical model of dynamic biomarkers Lancet Neurol. 12 207-16\n\nAn algorithmic approach to structural imaging in dementia. L Harper, F Barkhof, P Scheltens, J Schott, N C Fox, 10.1136/jnnp-2013-306285J. Neurol. Neurosurg. Psychiatr. 85Harper L, Barkhof F, Scheltens P, Schott J M and Fox N C 2014 An algorithmic approach to structural imaging in dementia J. Neurol. Neurosurg. Psychiatr. 85 692-8\n\nPredicting diagnosis and cognition with (18) F-AV-1451tau PET and structural MRI in Alzheimer's disease Alzheimers Dement. N Mattsson, P S Insel, M Donohue, J J\u00f6gi, R Ossenkoppele, T Olsson, M Sch\u00f6ll, R Smith, O Hansson, 10.1016/j.jalz.2018.12.00115Mattsson N, Insel P S, Donohue M, J\u00f6gi J, Ossenkoppele R, Olsson T, Sch\u00f6ll M, Smith R and Hansson O 2019 Predicting diagnosis and cognition with (18) F-AV-1451tau PET and structural MRI in Alzheimer's disease Alzheimers Dement. 15 570-80\n\n. R Ossenkoppele, R Smith, T Ohlsson, O Strandberg, N Mattsson, P S Insel, Palmqvist S Hansson, O , Ossenkoppele R, Smith R, Ohlsson T, Strandberg O, Mattsson N, Insel P S, Palmqvist S and Hansson O 2019\n\nAssociations between tau, Abeta, and cortical thickness with cognition in Alzheimer disease. 10.1212/WNL.0000000000006875Neurology. 92Associations between tau, Abeta, and cortical thickness with cognition in Alzheimer disease Neurology 92 e601-12\n\nNeuroimaging correlates of pathologically defined subtypes of Alzheimer's disease: a case-control study Lancet Neurol. J Whitwell, 10.1016/S1474-4422(12)70200-411Whitwell J L et al 2012 Neuroimaging correlates of pathologically defined subtypes of Alzheimer's disease: a case-control study Lancet Neurol. 11 868-77\n\nThe clinical use of structural MRI in Alzheimer disease. G B Frisoni, N C Fox, C R Jack, Jr, P Scheltens, P M Thompson, 10.1038/nrneurol.2009.215Nat. Rev. Neurol. 6Frisoni G B, Fox N C, Jack C R Jr, Scheltens P and Thompson P M 2010 The clinical use of structural MRI in Alzheimer disease Nat. Rev. Neurol. 6 67-77\n\nC A Raji, O L Lopez, L H Kuller, O Carmichael, J T Becker, 10.1212/WNL.0b013e3181c3f293Alzheimer disease, and brain structure Neurology. 73Raji C A, Lopez O L, Kuller L H, Carmichael O T and Becker J T 2009 Age, Alzheimer disease, and brain structure Neurology 73 1899-905\n\nThe significance of medial temporal lobe atrophy: apostmortem MRI study in the very old. F Barkhof, 10.1212/01.wnl.0000277459.83543.99Neurology. 69Barkhof F et al 2007 The significance of medial temporal lobe atrophy: apostmortem MRI study in the very old Neurology 69 1521-7\n\nAccuracy of the clinical diagnosis of Alzheimer disease at National Institute on Aging Alzheimer Disease Centers. T G Beach, S E Monsell, L Phillips, 10.1097/NEN.0b013e31824b211bJ. Neuropathol. Exp. Neurol. 71Beach T G, Monsell S E, Phillips L E and Kukull W 2012 Accuracy of the clinical diagnosis of Alzheimer disease at National Institute on Aging Alzheimer Disease Centers, 2005-2010 J. Neuropathol. Exp. Neurol. 71 266-73\n\n. Y Liu, G Liu, Q Zhang, 10.1016/S0140-6736(19)32501-2Deep learning and medical diagnosis Lancet. 394Liu Y, Liu G and Zhang Q 2019 Deep learning and medical diagnosis Lancet 394 1709-10\n\nDevelopment and validation of an interpretable deep learning framework for Alzheimer's disease classification. S Qiu, 10.1093/brain/awaa137Brain. 143Qiu S et al 2020 Development and validation of an interpretable deep learning framework for Alzheimer's disease classification. Brain 143 1920-33\n\nPixel-level non-local image smoothing with objective evaluation IEEE Trans. J Xu, Z-A Liu, Y Hou, X Zhen, L Shao, M M Cheng, 10.1109/TMM.2020.303753523Xu J, Liu Z-A, Hou Y, Zhen X, Shao L and Cheng M M 2020 Pixel-level non-local image smoothing with objective evaluation IEEE Trans. Multimedia 23 4065-78\n\nDeep learning for electroencephalogram (EEG) classification tasks: a review. A Craik, Y He, J Contreras-Vidal, 10.1088/1741-2552/ab0ab5J. Neural Eng. 1631001Craik A, He Y and Contreras-Vidal J L 2019 Deep learning for electroencephalogram (EEG) classification tasks: a review J. Neural Eng. 16 031001\n\nInter-subject transfer learning with an end-to-end deep convolutional neural network for EEG-based BCI. F Fahimi, Z Zhang, W B Goh, T-S Lee, K Ang, C Guan, 10.1088/1741-2552/aaf3f6J. Neural. Eng. 1626007Fahimi F, Zhang Z, Goh W B, Lee T-S, Ang K K and Guan C 2019 Inter-subject transfer learning with an end-to-end deep convolutional neural network for EEG-based BCI J. Neural. Eng. 16 026007\n\nDeep learning-based electroencephalography analysis: a systematic review. Y Roy, H Banville, I Albuquerque, A Gramfort, T Falk, J Faubert, 10.1088/1741-2552/ab260cJ. Neural. Eng. 1651001Roy Y, Banville H, Albuquerque I, Gramfort A, Falk T H and Faubert J 2019 Deep learning-based electroencephalography analysis: a systematic review J. Neural. Eng. 16 051001\n\nCan we open the black box of AI?. D Castelvecchi, 10.1038/538020aNature. 538Castelvecchi D 2016 Can we open the black box of AI? Nature 538 20-23\n\nE Holm, 10.1126/science.aax0162defense of the black box Science. 364Holm E A 2019 In defense of the black box Science 364 26-27\n\nAlzheimer's disease neuroimaging initiative (ADNI): clinical characterization Neurology. R Petersen, 10.1212/WNL.0b013e3181cb3e2574Petersen R C et al 2010 Alzheimer's disease neuroimaging initiative (ADNI): clinical characterization Neurology 74 201-9\n\nAddressing population aging and Alzheimer's disease through the Australian imaging biomarkers and lifestyle study: collaboration with the Alzheimer's disease neuroimaging initiative Alzheimers Dement. K A Ellis, C C Rowe, V L Villemagne, R N Martins, C L Masters, O Salvado, C Szoeke, D Ames, 10.1016/j.jalz.2010.03.0096Ellis K A, Rowe C C, Villemagne V L, Martins R N, Masters C L, Salvado O, Szoeke C and Ames D 2010 Addressing population aging and Alzheimer's disease through the Australian imaging biomarkers and lifestyle study: collaboration with the Alzheimer's disease neuroimaging initiative Alzheimers Dement. 6 291-6\n\nThe National Alzheimer's Coordinating Center (NACC) database: an Alzheimer disease database. D L Beekly, E M Ramos, G Van Belle, W Deitrich, A D Clark, M Jacka, Alzheimer Dis. Assoc. Disord. 18Beekly D L, Ramos E M, van Belle G, Deitrich W, Clark A D, Jacka M E and Kukull W A 2004 The National Alzheimer's Coordinating Center (NACC) database: an Alzheimer disease database Alzheimer Dis. Assoc. Disord. 18 270-7\n\n. T E Shadi, Amelia A-Y Chikara, T Bolen, C R Nyachienga, M N Lear, S P Green, C Mathews, W , O&apos;gorman W E , 10.3389/fimmu.2019.01194Quantitative comparison of conventional and t-SNE-guided gating analyses Front. Immunol. 101194Shadi T E, Amelia A-Y, Chikara T, Bolen C R, Nyachienga M N, Lear S P, Green C, Mathews W R and O'Gorman W E 2019 Quantitative comparison of conventional and t-SNE-guided gating analyses Front. Immunol. 10 1194\n\nApplication of t-SNE to human genetic data. L Wentian, J Cerise, Y Yang, 10.1142/S0219720017500172J. Bioinform. Comput. Biol. 151750017Wentian L, Cerise J E and Yang Y 2017 Application of t-SNE to human genetic data J. Bioinform. Comput. Biol. 15 1750017\n\nW Li, X Feng, H An, X Ng, Y-J Zhang, 10.1609/aaai.v34i01.5423MRI reconstruction with interpretable pixel-wise operations using reinforcement learning Proc. AAAI Conf. 34Li W, Feng X, An H, Ng X Y and Zhang Y-J 2020 MRI reconstruction with interpretable pixel-wise operations using reinforcement learning Proc. AAAI Conf. Artif. Intell. 34 792-9\n\nT Lillicrap, arXiv:1509.02971v2Continuous control with deep reinforcement learning ICLR. Lillicrap T P et al 2016 Continuous control with deep reinforcement learning ICLR (arXiv:1509.02971v2)\n\nExplainable AI for COVID-19 CT classifiers: an initial comparison study 2021 IEEE 34th Int. Q H Ye, Xia J Yang, G , 10.1109/CBMS52027.2021.00103Symp. on Computer-Based Medical Systems (CBMS. Ye Q H, Xia J and Yang G 2021 Explainable AI for COVID-19 CT classifiers: an initial comparison study 2021 IEEE 34th Int. Symp. on Computer-Based Medical Systems (CBMS) (Aveiro, Portugal) pp 521-6\n\nUnbox the black-box for the medical explainable ai via multi-modal and multi-centre data fusion: a mini-review, two showcases and beyond Inform. G Yang, Q Ye, J Xia, 10.1016/j.inffus.2021.07.016Fusion. 77Yang G, Ye Q H and Xia J 2021 Unbox the black-box for the medical explainable ai via multi-modal and multi-centre data fusion: a mini-review, two showcases and beyond Inform. Fusion 77 29-52\n\nDagan: deep de-aliasing generative adversarial networks for fast compressed sensing MRI reconstruction. G Yang, 10.1109/TMI.2017.2785879IEEE Trans. Med. Imaging. 37Yang G et al 2017 Dagan: deep de-aliasing generative adversarial networks for fast compressed sensing MRI reconstruction IEEE Trans. Med. Imaging 37 1310-21\n\nJ Zbontar, arXiv:1811.08839fastMRI: an open dataset and benchmarks for accelerated MRI. Zbontar J et al 2018 fastMRI: an open dataset and benchmarks for accelerated MRI (arXiv:1811.08839)\n\nExploring uncertainty measures in Bayesian deep attentive neural networks for prostate zonal segmentation. Y K Liu, Yang G Hosseiny, M Azadikhah, A Mirak, S A Miao, Q Raman, S , Sung K , 10.1109/ACCESS.2020.3017168IEEE Access. 8Liu Y K, Yang G, Hosseiny M, Azadikhah A, Mirak S A, Miao Q, Raman S S and Sung K 2020 Exploring uncertainty measures in Bayesian deep attentive neural networks for prostate zonal segmentation IEEE Access 8 151817-28\n\nSimultaneous left atrium anatomy and scar segmentations via deep learning in multiview information with attention Future Gener. G Yang, 10.1016/j.future.2020.02.005Comput. Syst. 107Yang G et al 2020 Simultaneous left atrium anatomy and scar segmentations via deep learning in multiview information with attention Future Gener. Comput. Syst. 107 215-28\n\nAutomatic prostate zonal segmentation using fully convolutional network with feature pyramid attention. Y K Liu, Yang G Mirak, S A , Afshari Mirak, S Hosseiny, M Azadikhah, A Zhong, X Reiter, R E , Lee Y Raman, S S , 10.1109/ACCESS.2019.2952534IEEE Access. 7Liu Y K, Yang G, Mirak S A, Afshari Mirak S, Hosseiny M, Azadikhah A, Zhong X, Reiter R E, Lee Y and Raman S S 2019 Automatic prostate zonal segmentation using fully convolutional network with feature pyramid attention IEEE Access 7 163626-32\n\nRelationship between the Montreal Cognitive Assessment and Mini-mental State Examination for assessment of mild cognitive impairment in older adults BMC Geriatr. P T Trzepacz, H Hochstetler, S Wang, Walker B Saykin, A J , 10.1186/s12877-015-0103-315107Trzepacz P T, Hochstetler H, Wang S, Walker B and Saykin A J 2015 Relationship between the Montreal Cognitive Assessment and Mini-mental State Examination for assessment of mild cognitive impairment in older adults BMC Geriatr. 15 107\n\nMini-Mental State Examination (MMSE) for the detection of Alzheimer's dementia and other dementias in asymptomatic and previously clinically unevaluated people aged over 65 years in community and primary care populations. S Creavin, 10.1002/14651858.CD011145.pub2Cochrane Database Syst. Rev. 611145Creavin S T et al 2014 Mini-Mental State Examination (MMSE) for the detection of Alzheimer's dementia and other dementias in asymptomatic and previously clinically unevaluated people aged over 65 years in community and primary care populations Cochrane Database Syst. Rev. 6 CD011145\n\n. P B Verghese, J Castellano, D M Holtzman, Verghese P B, Castellano J M and Holtzman D M 2011\n\nAlzheimer's disease and other neurological disorders Lancet Neurol. Apolipoprotein E In, 10.1016/S1474-4422(10)70325-210Apolipoprotein E in Alzheimer's disease and other neurological disorders Lancet Neurol. 10 241-52\n\nApoE and A\u03b2 in Alzheimer's disease: accidental encounters or partners?. T Kanekiyo, X Huaxi, B Guojun, 10.1016/j.neuron.2014.01.045Neuron. 81Kanekiyo T, Huaxi X and Guojun B 2014 ApoE and A\u03b2 in Alzheimer's disease: accidental encounters or partners? Neuron 81 740-54\n\nDisease-associated astrocytes in Alzheimer's disease and aging. N Habib, 10.1038/s41593-020-0624-8Nat. Neurosci. 23Habib N et al 2020 Disease-associated astrocytes in Alzheimer's disease and aging Nat. Neurosci. 23 701-6\n\nUnderstanding the impact of sex and gender in Alzheimer's disease: a call to action Alzheimers Demen. R Nebel, 10.1016/j.jalz.2018.04.00814Nebel R A et al 2018 Understanding the impact of sex and gender in Alzheimer's disease: a call to action Alzheimers Demen. 14 1171-83\n\nAPOE and sex: triad of risk of Alzheimer's disease. B C Riedel, P Thompson, R D Brinton, 10.1016/j.jsbmb.2016.03.012J. Steroid Biochem. Mol. Biol. 160AgeRiedel B C, Thompson P M and Brinton R D 2016 Age, APOE and sex: triad of risk of Alzheimer's disease J. Steroid Biochem. Mol. Biol. 160 134-47\n\nClinical epidemiology of Alzheimer's disease: assessing sex and gender differences. M Mielke, P Vemuri, W Rocca, 10.2147/CLEP.S37929Clin. Epidemiol. 6Mielke M, Vemuri P and Rocca W 2014 Clinical epidemiology of Alzheimer's disease: assessing sex and gender differences Clin. Epidemiol. 6 37-48\n\nTissue-type mapping of gliomas Neuroimage Clin. F Raschke, T R Barrick, T L Jones, Yang G , Ye X Howe, F A , 10.1016/j.nicl.2018.10164821101648Raschke F, Barrick T R, Jones T L, Yang G, Ye X and Howe F A 2019 Tissue-type mapping of gliomas Neuroimage Clin. 21 101648\n\nAmyloid \u03b2 deposition, neurodegeneration, and cognitive decline in sporadic Alzheimer's disease: a prospective cohort study. V Villemagne, 10.1016/S1474-4422(13)70044-9Lancet Neurol. 12Villemagne V L et al 2013 Amyloid \u03b2 deposition, neurodegeneration, and cognitive decline in sporadic Alzheimer's disease: a prospective cohort study Lancet Neurol. 12 357-67\n\nSleep and Alzheimer disease pathology-a bidirectional relationship. Y E Ju, B Lucey, D Holtzman, 10.1038/nrneurol.2013.269Nat. Rev. Neurol. 10Ju Y E, Lucey B and Holtzman D 2014 Sleep and Alzheimer disease pathology-a bidirectional relationship Nat. Rev. Neurol. 10 115-9\n\nAPOE and Alzheimer's disease: evidence mounts that targeting APOE4 may combat Alzheimer's pathogenesis. M S Uddin, M T Kabir, Al Mamun, A , Abdel-Daim M M Barreto, G Ashraf, G M , 10.1007/s12035-018-1237-zMol. Neurobiol. 56Uddin M S, Kabir M T, Al Mamun A, Abdel-Daim M M, Barreto G E and Ashraf G M 2019 APOE and Alzheimer's disease: evidence mounts that targeting APOE4 may combat Alzheimer's pathogenesis Mol. Neurobiol. 56 2450-65\n\nApoE4: an emerging therapeutic target for Alzheimer's disease BMC Med. M Safieh, A Korczyn, D M Michaelson, 10.1186/s12916-019-1299-41764Safieh M, Korczyn A D and Michaelson D M 2019 ApoE4: an emerging therapeutic target for Alzheimer's disease BMC Med. 17 64\n\nSex modifies the APOE-related risk of developing Alzheimer disease. A Altmann, L Tian, V W Henderson, M D Greicius, 10.1002/ana.24135Ann. Neurol. 75Altmann A, Tian L, Henderson V W and Greicius M D 2014 Sex modifies the APOE-related risk of developing Alzheimer disease Ann. Neurol. 75 563-73\n\nSex differences in the association of global amyloid and regional tau deposition measured by positron emission tomography in clinically normal older adults JAMA Neurol. R Buckley, 10.1001/jamaneurol.2018.469376Buckley R F et al 2019 Sex differences in the association of global amyloid and regional tau deposition measured by positron emission tomography in clinically normal older adults JAMA Neurol. 76 542-51\n", "annotations": {"author": "[{\"start\":\"133\",\"end\":\"399\"},{\"start\":\"400\",\"end\":\"663\"},{\"start\":\"664\",\"end\":\"1079\"}]", "publisher": null, "author_last_name": "[{\"start\":\"138\",\"end\":\"143\"},{\"start\":\"405\",\"end\":\"407\"},{\"start\":\"671\",\"end\":\"674\"}]", "author_first_name": "[{\"start\":\"133\",\"end\":\"137\"},{\"start\":\"400\",\"end\":\"404\"},{\"start\":\"664\",\"end\":\"670\"}]", "author_affiliation": "[{\"start\":\"145\",\"end\":\"260\"},{\"start\":\"262\",\"end\":\"398\"},{\"start\":\"409\",\"end\":\"524\"},{\"start\":\"526\",\"end\":\"662\"},{\"start\":\"676\",\"end\":\"791\"},{\"start\":\"793\",\"end\":\"929\"},{\"start\":\"931\",\"end\":\"1078\"}]", "title": "[{\"start\":\"1\",\"end\":\"126\"},{\"start\":\"1080\",\"end\":\"1205\"}]", "venue": "[{\"start\":\"1207\",\"end\":\"1220\"}]", "abstract": "[{\"start\":\"1656\",\"end\":\"3903\"}]", "bib_ref": "[{\"start\":\"4028\",\"end\":\"4031\",\"attributes\":{\"ref_id\":\"b0\"}},{\"start\":\"4244\",\"end\":\"4247\",\"attributes\":{\"ref_id\":\"b2\"}},{\"start\":\"4247\",\"end\":\"4249\",\"attributes\":{\"ref_id\":\"b3\"}},{\"start\":\"4463\",\"end\":\"4466\",\"attributes\":{\"ref_id\":\"b4\"}},{\"start\":\"4466\",\"end\":\"4469\",\"attributes\":{\"ref_id\":\"b5\"}},{\"start\":\"4469\",\"end\":\"4472\",\"attributes\":{\"ref_id\":\"b6\"}},{\"start\":\"4472\",\"end\":\"4475\",\"attributes\":{\"ref_id\":\"b7\"}},{\"start\":\"4630\",\"end\":\"4633\",\"attributes\":{\"ref_id\":\"b9\"}},{\"start\":\"4633\",\"end\":\"4636\",\"attributes\":{\"ref_id\":\"b10\"}},{\"start\":\"4636\",\"end\":\"4640\",\"attributes\":{\"ref_id\":\"b11\"}},{\"start\":\"4640\",\"end\":\"4644\",\"attributes\":{\"ref_id\":\"b12\"}},{\"start\":\"4895\",\"end\":\"4899\",\"attributes\":{\"ref_id\":\"b13\"}},{\"start\":\"5261\",\"end\":\"5262\"},{\"start\":\"5847\",\"end\":\"5851\",\"attributes\":{\"ref_id\":\"b14\"}},{\"start\":\"5851\",\"end\":\"5855\",\"attributes\":{\"ref_id\":\"b15\"}},{\"start\":\"5855\",\"end\":\"5859\",\"attributes\":{\"ref_id\":\"b16\"}},{\"start\":\"5859\",\"end\":\"5863\",\"attributes\":{\"ref_id\":\"b17\"}},{\"start\":\"5863\",\"end\":\"5867\",\"attributes\":{\"ref_id\":\"b18\"}},{\"start\":\"5867\",\"end\":\"5871\",\"attributes\":{\"ref_id\":\"b19\"}},{\"start\":\"6798\",\"end\":\"6802\",\"attributes\":{\"ref_id\":\"b20\"}},{\"start\":\"6802\",\"end\":\"6805\",\"attributes\":{\"ref_id\":\"b21\"}},{\"start\":\"8232\",\"end\":\"8235\",\"attributes\":{\"ref_id\":\"b0\"}},{\"start\":\"9619\",\"end\":\"9622\",\"attributes\":{\"ref_id\":\"b2\"}},{\"start\":\"9754\",\"end\":\"9757\",\"attributes\":{\"ref_id\":\"b3\"}},{\"start\":\"10484\",\"end\":\"10488\",\"attributes\":{\"ref_id\":\"b22\"}},{\"start\":\"10564\",\"end\":\"10568\",\"attributes\":{\"ref_id\":\"b23\"}},{\"start\":\"10625\",\"end\":\"10629\",\"attributes\":{\"ref_id\":\"b24\"}},{\"start\":\"10840\",\"end\":\"10844\",\"attributes\":{\"ref_id\":\"b25\"}},{\"start\":\"10844\",\"end\":\"10847\",\"attributes\":{\"ref_id\":\"b26\"}},{\"start\":\"18367\",\"end\":\"18371\",\"attributes\":{\"ref_id\":\"b27\"}},{\"start\":\"18734\",\"end\":\"18738\",\"attributes\":{\"ref_id\":\"b28\"}},{\"start\":\"21306\",\"end\":\"21310\",\"attributes\":{\"ref_id\":\"b29\"}},{\"start\":\"21310\",\"end\":\"21313\",\"attributes\":{\"ref_id\":\"b30\"}},{\"start\":\"26381\",\"end\":\"26385\",\"attributes\":{\"ref_id\":\"b31\"}},{\"start\":\"26395\",\"end\":\"26399\",\"attributes\":{\"ref_id\":\"b32\"}},{\"start\":\"30000\",\"end\":\"30004\",\"attributes\":{\"ref_id\":\"b33\"}},{\"start\":\"30004\",\"end\":\"30008\",\"attributes\":{\"ref_id\":\"b34\"}},{\"start\":\"30008\",\"end\":\"30012\",\"attributes\":{\"ref_id\":\"b35\"}},{\"start\":\"30204\",\"end\":\"30208\",\"attributes\":{\"ref_id\":\"b33\"}},{\"start\":\"30208\",\"end\":\"30212\",\"attributes\":{\"ref_id\":\"b34\"}},{\"start\":\"30212\",\"end\":\"30216\",\"attributes\":{\"ref_id\":\"b35\"}},{\"start\":\"33438\",\"end\":\"33442\",\"attributes\":{\"ref_id\":\"b11\"}},{\"start\":\"33695\",\"end\":\"33699\",\"attributes\":{\"ref_id\":\"b12\"}},{\"start\":\"33783\",\"end\":\"33787\",\"attributes\":{\"ref_id\":\"b11\"}},{\"start\":\"35421\",\"end\":\"35425\",\"attributes\":{\"ref_id\":\"b36\"}},{\"start\":\"35425\",\"end\":\"35429\",\"attributes\":{\"ref_id\":\"b37\"}},{\"start\":\"35429\",\"end\":\"35433\",\"attributes\":{\"ref_id\":\"b38\"}},{\"start\":\"35433\",\"end\":\"35437\",\"attributes\":{\"ref_id\":\"b40\"}},{\"start\":\"35734\",\"end\":\"35738\",\"attributes\":{\"ref_id\":\"b41\"}},{\"start\":\"35738\",\"end\":\"35742\",\"attributes\":{\"ref_id\":\"b42\"}},{\"start\":\"35742\",\"end\":\"35746\",\"attributes\":{\"ref_id\":\"b43\"}},{\"start\":\"35746\",\"end\":\"35750\",\"attributes\":{\"ref_id\":\"b44\"}},{\"start\":\"40630\",\"end\":\"40634\",\"attributes\":{\"ref_id\":\"b45\"}},{\"start\":\"43472\",\"end\":\"43476\",\"attributes\":{\"ref_id\":\"b46\"}},{\"start\":\"43476\",\"end\":\"43479\",\"attributes\":{\"ref_id\":\"b47\"}},{\"start\":\"43654\",\"end\":\"43658\",\"attributes\":{\"ref_id\":\"b48\"}},{\"start\":\"43658\",\"end\":\"43661\",\"attributes\":{\"ref_id\":\"b49\"}},{\"start\":\"43971\",\"end\":\"43975\",\"attributes\":{\"ref_id\":\"b50\"}},{\"start\":\"43975\",\"end\":\"43978\",\"attributes\":{\"ref_id\":\"b51\"}}]", "figure": "[{\"start\":\"48701\",\"end\":\"48859\",\"attributes\":{\"id\":\"fig_0\"}},{\"start\":\"48860\",\"end\":\"49750\",\"attributes\":{\"id\":\"fig_1\"}},{\"start\":\"49751\",\"end\":\"50607\",\"attributes\":{\"id\":\"fig_2\"}},{\"start\":\"50608\",\"end\":\"50822\",\"attributes\":{\"id\":\"fig_3\"}},{\"start\":\"50823\",\"end\":\"50893\",\"attributes\":{\"id\":\"fig_4\"}},{\"start\":\"50894\",\"end\":\"51379\",\"attributes\":{\"id\":\"fig_5\"}},{\"start\":\"51380\",\"end\":\"52017\",\"attributes\":{\"id\":\"fig_6\"}},{\"start\":\"52018\",\"end\":\"52438\",\"attributes\":{\"id\":\"fig_7\"}},{\"start\":\"52439\",\"end\":\"52814\",\"attributes\":{\"id\":\"fig_8\"}},{\"start\":\"52815\",\"end\":\"53425\",\"attributes\":{\"id\":\"fig_9\"}},{\"start\":\"53426\",\"end\":\"54092\",\"attributes\":{\"id\":\"fig_10\"}},{\"start\":\"54093\",\"end\":\"54548\",\"attributes\":{\"id\":\"fig_11\"}},{\"start\":\"54549\",\"end\":\"55386\",\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"}},{\"start\":\"55387\",\"end\":\"55879\",\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"}},{\"start\":\"55880\",\"end\":\"56148\",\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"}},{\"start\":\"56149\",\"end\":\"58136\",\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"}},{\"start\":\"58137\",\"end\":\"59180\",\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"}}]", "paragraph": "[{\"start\":\"3919\",\"end\":\"4250\"},{\"start\":\"4252\",\"end\":\"5678\"},{\"start\":\"5680\",\"end\":\"8032\"},{\"start\":\"8034\",\"end\":\"8878\"},{\"start\":\"8880\",\"end\":\"9393\"},{\"start\":\"9395\",\"end\":\"9607\"},{\"start\":\"9609\",\"end\":\"10848\"},{\"start\":\"10893\",\"end\":\"11154\"},{\"start\":\"11156\",\"end\":\"12241\"},{\"start\":\"12243\",\"end\":\"12732\"},{\"start\":\"12759\",\"end\":\"13323\"},{\"start\":\"13325\",\"end\":\"14013\"},{\"start\":\"14051\",\"end\":\"16788\"},{\"start\":\"16904\",\"end\":\"17320\"},{\"start\":\"17322\",\"end\":\"17506\"},{\"start\":\"17508\",\"end\":\"19038\"},{\"start\":\"19075\",\"end\":\"19210\"},{\"start\":\"19265\",\"end\":\"19672\"},{\"start\":\"19709\",\"end\":\"19975\"},{\"start\":\"20027\",\"end\":\"20111\"},{\"start\":\"20137\",\"end\":\"20383\"},{\"start\":\"20385\",\"end\":\"20636\"},{\"start\":\"20638\",\"end\":\"21130\"},{\"start\":\"21172\",\"end\":\"21523\"},{\"start\":\"21525\",\"end\":\"22244\"},{\"start\":\"22328\",\"end\":\"22434\"},{\"start\":\"22436\",\"end\":\"23092\"},{\"start\":\"23124\",\"end\":\"23787\"},{\"start\":\"23799\",\"end\":\"24088\"},{\"start\":\"24133\",\"end\":\"25606\"},{\"start\":\"25608\",\"end\":\"26272\"},{\"start\":\"26274\",\"end\":\"26556\"},{\"start\":\"26635\",\"end\":\"26867\"},{\"start\":\"26899\",\"end\":\"27042\"},{\"start\":\"27044\",\"end\":\"27180\"},{\"start\":\"27182\",\"end\":\"27424\"},{\"start\":\"27462\",\"end\":\"28712\"},{\"start\":\"28714\",\"end\":\"29792\"},{\"start\":\"29794\",\"end\":\"30252\"},{\"start\":\"30254\",\"end\":\"31468\"},{\"start\":\"31497\",\"end\":\"32301\"},{\"start\":\"32303\",\"end\":\"32751\"},{\"start\":\"32753\",\"end\":\"32911\"},{\"start\":\"32913\",\"end\":\"33452\"},{\"start\":\"33493\",\"end\":\"33645\"},{\"start\":\"33683\",\"end\":\"33788\"},{\"start\":\"33790\",\"end\":\"34688\"},{\"start\":\"34690\",\"end\":\"35270\"},{\"start\":\"35272\",\"end\":\"36341\"},{\"start\":\"36356\",\"end\":\"36991\"},{\"start\":\"36993\",\"end\":\"39155\"},{\"start\":\"39157\",\"end\":\"40271\"},{\"start\":\"40273\",\"end\":\"42478\"},{\"start\":\"42480\",\"end\":\"44379\"},{\"start\":\"44381\",\"end\":\"46731\"},{\"start\":\"46733\",\"end\":\"47134\"},{\"start\":\"47166\",\"end\":\"47309\"},{\"start\":\"47311\",\"end\":\"47415\"},{\"start\":\"47435\",\"end\":\"48700\"}]", "formula": "[{\"start\":\"16789\",\"end\":\"16903\",\"attributes\":{\"id\":\"formula_0\"}},{\"start\":\"19039\",\"end\":\"19074\",\"attributes\":{\"id\":\"formula_1\"}},{\"start\":\"19211\",\"end\":\"19264\",\"attributes\":{\"id\":\"formula_2\"}},{\"start\":\"19673\",\"end\":\"19708\",\"attributes\":{\"id\":\"formula_3\"}},{\"start\":\"19976\",\"end\":\"20026\",\"attributes\":{\"id\":\"formula_4\"}},{\"start\":\"20112\",\"end\":\"20136\",\"attributes\":{\"id\":\"formula_5\"}},{\"start\":\"22245\",\"end\":\"22327\",\"attributes\":{\"id\":\"formula_6\"}},{\"start\":\"26557\",\"end\":\"26634\",\"attributes\":{\"id\":\"formula_7\"}},{\"start\":\"26868\",\"end\":\"26898\",\"attributes\":{\"id\":\"formula_8\"}},{\"start\":\"33453\",\"end\":\"33492\",\"attributes\":{\"id\":\"formula_9\"}},{\"start\":\"33646\",\"end\":\"33682\",\"attributes\":{\"id\":\"formula_10\"}}]", "table_ref": "[{\"start\":\"38484\",\"end\":\"38492\",\"attributes\":{\"ref_id\":\"tab_2\"}}]", "section_header": "[{\"start\":\"3905\",\"end\":\"3917\",\"attributes\":{\"n\":\"1.\"}},{\"start\":\"10851\",\"end\":\"10872\",\"attributes\":{\"n\":\"2.\"}},{\"start\":\"10875\",\"end\":\"10891\",\"attributes\":{\"n\":\"2.1.\"}},{\"start\":\"12735\",\"end\":\"12757\",\"attributes\":{\"n\":\"2.2.\"}},{\"start\":\"14016\",\"end\":\"14049\",\"attributes\":{\"n\":\"2.3.\"}},{\"start\":\"21133\",\"end\":\"21170\",\"attributes\":{\"n\":\"2.4.\"}},{\"start\":\"23095\",\"end\":\"23122\",\"attributes\":{\"n\":\"2.5.\"}},{\"start\":\"23790\",\"end\":\"23797\",\"attributes\":{\"n\":\"3.\"}},{\"start\":\"24091\",\"end\":\"24131\",\"attributes\":{\"n\":\"3.1.\"}},{\"start\":\"27427\",\"end\":\"27460\",\"attributes\":{\"n\":\"3.2.\"}},{\"start\":\"31471\",\"end\":\"31495\",\"attributes\":{\"n\":\"3.3.\"}},{\"start\":\"36344\",\"end\":\"36354\",\"attributes\":{\"n\":\"4.\"}},{\"start\":\"47137\",\"end\":\"47164\"},{\"start\":\"47418\",\"end\":\"47433\"},{\"start\":\"48702\",\"end\":\"48712\"},{\"start\":\"48861\",\"end\":\"48871\"},{\"start\":\"49752\",\"end\":\"49762\"},{\"start\":\"50609\",\"end\":\"50616\"},{\"start\":\"50824\",\"end\":\"50834\"},{\"start\":\"50895\",\"end\":\"50905\"},{\"start\":\"51381\",\"end\":\"51391\"},{\"start\":\"52019\",\"end\":\"52029\"},{\"start\":\"52440\",\"end\":\"52450\"},{\"start\":\"52816\",\"end\":\"52827\"},{\"start\":\"53427\",\"end\":\"53438\"},{\"start\":\"54094\",\"end\":\"54105\"},{\"start\":\"54550\",\"end\":\"54559\"},{\"start\":\"55388\",\"end\":\"55397\"},{\"start\":\"55881\",\"end\":\"55890\"},{\"start\":\"56150\",\"end\":\"56159\"}]", "table": "[{\"start\":\"54633\",\"end\":\"55386\"},{\"start\":\"55570\",\"end\":\"55879\"},{\"start\":\"55951\",\"end\":\"56148\"},{\"start\":\"56631\",\"end\":\"58136\"}]", "figure_caption": "[{\"start\":\"48714\",\"end\":\"48859\"},{\"start\":\"48873\",\"end\":\"49750\"},{\"start\":\"49764\",\"end\":\"50607\"},{\"start\":\"50617\",\"end\":\"50822\"},{\"start\":\"50836\",\"end\":\"50893\"},{\"start\":\"50907\",\"end\":\"51379\"},{\"start\":\"51393\",\"end\":\"52017\"},{\"start\":\"52031\",\"end\":\"52438\"},{\"start\":\"52452\",\"end\":\"52814\"},{\"start\":\"52830\",\"end\":\"53425\"},{\"start\":\"53441\",\"end\":\"54092\"},{\"start\":\"54108\",\"end\":\"54548\"},{\"start\":\"54561\",\"end\":\"54633\"},{\"start\":\"55399\",\"end\":\"55570\"},{\"start\":\"55892\",\"end\":\"55951\"},{\"start\":\"56161\",\"end\":\"56631\"},{\"start\":\"58139\",\"end\":\"59180\"}]", "figure_ref": "[{\"start\":\"16126\",\"end\":\"16134\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"21514\",\"end\":\"21522\",\"attributes\":{\"ref_id\":\"fig_1\"}},{\"start\":\"25597\",\"end\":\"25605\",\"attributes\":{\"ref_id\":\"fig_2\"}},{\"start\":\"25611\",\"end\":\"25619\",\"attributes\":{\"ref_id\":\"fig_2\"}},{\"start\":\"25886\",\"end\":\"25894\",\"attributes\":{\"ref_id\":\"fig_2\"}},{\"start\":\"25914\",\"end\":\"25922\",\"attributes\":{\"ref_id\":\"fig_4\"}},{\"start\":\"27171\",\"end\":\"27179\",\"attributes\":{\"ref_id\":\"fig_5\"}},{\"start\":\"27766\",\"end\":\"27774\",\"attributes\":{\"ref_id\":\"fig_6\"}},{\"start\":\"27776\",\"end\":\"27787\",\"attributes\":{\"ref_id\":\"fig_6\"}},{\"start\":\"28308\",\"end\":\"28324\",\"attributes\":{\"ref_id\":\"fig_6\"}},{\"start\":\"28829\",\"end\":\"28840\",\"attributes\":{\"ref_id\":\"fig_7\"}},{\"start\":\"29120\",\"end\":\"29128\",\"attributes\":{\"ref_id\":\"fig_7\"}},{\"start\":\"30243\",\"end\":\"30251\",\"attributes\":{\"ref_id\":\"fig_8\"}},{\"start\":\"30266\",\"end\":\"30274\",\"attributes\":{\"ref_id\":\"fig_8\"}},{\"start\":\"31860\",\"end\":\"31868\"},{\"start\":\"32013\",\"end\":\"32021\"},{\"start\":\"32083\",\"end\":\"32091\"},{\"start\":\"32458\",\"end\":\"32467\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"32837\",\"end\":\"32846\",\"attributes\":{\"ref_id\":\"fig_2\"}},{\"start\":\"32901\",\"end\":\"32910\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"34334\",\"end\":\"34346\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"35257\",\"end\":\"35269\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"35943\",\"end\":\"35951\"},{\"start\":\"36004\",\"end\":\"36014\"},{\"start\":\"36183\",\"end\":\"36193\"},{\"start\":\"38350\",\"end\":\"38358\",\"attributes\":{\"ref_id\":\"fig_5\"}},{\"start\":\"38853\",\"end\":\"38861\",\"attributes\":{\"ref_id\":\"fig_6\"}},{\"start\":\"39745\",\"end\":\"39753\"},{\"start\":\"39870\",\"end\":\"39878\"},{\"start\":\"41381\",\"end\":\"41390\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"43185\",\"end\":\"43194\",\"attributes\":{\"ref_id\":\"fig_0\"}}]", "bib_author_first_name": "[{\"start\":\"60143\",\"end\":\"60144\"},{\"start\":\"60156\",\"end\":\"60157\"},{\"start\":\"60167\",\"end\":\"60170\"},{\"start\":\"60181\",\"end\":\"60182\"},{\"start\":\"60196\",\"end\":\"60199\"},{\"start\":\"60209\",\"end\":\"60217\"},{\"start\":\"60218\",\"end\":\"60219\"},{\"start\":\"60235\",\"end\":\"60236\"},{\"start\":\"60564\",\"end\":\"60565\"},{\"start\":\"60581\",\"end\":\"60584\"},{\"start\":\"60592\",\"end\":\"60595\"},{\"start\":\"60605\",\"end\":\"60606\"},{\"start\":\"60615\",\"end\":\"60618\"},{\"start\":\"60627\",\"end\":\"60628\"},{\"start\":\"60639\",\"end\":\"60640\"},{\"start\":\"60649\",\"end\":\"60650\"},{\"start\":\"60659\",\"end\":\"60660\"},{\"start\":\"61167\",\"end\":\"61168\"},{\"start\":\"61175\",\"end\":\"61176\"},{\"start\":\"61186\",\"end\":\"61187\"},{\"start\":\"61198\",\"end\":\"61199\"},{\"start\":\"61204\",\"end\":\"61205\"},{\"start\":\"61210\",\"end\":\"61211\"},{\"start\":\"61216\",\"end\":\"61217\"},{\"start\":\"61222\",\"end\":\"61226\"},{\"start\":\"61227\",\"end\":\"61228\"},{\"start\":\"61235\",\"end\":\"61236\"},{\"start\":\"61652\",\"end\":\"61655\"},{\"start\":\"61932\",\"end\":\"61933\"},{\"start\":\"61942\",\"end\":\"61943\"},{\"start\":\"61953\",\"end\":\"61954\"},{\"start\":\"61966\",\"end\":\"61967\"},{\"start\":\"61976\",\"end\":\"61979\"},{\"start\":\"62330\",\"end\":\"62331\"},{\"start\":\"62342\",\"end\":\"62345\"},{\"start\":\"62353\",\"end\":\"62354\"},{\"start\":\"62364\",\"end\":\"62365\"},{\"start\":\"62372\",\"end\":\"62373\"},{\"start\":\"62388\",\"end\":\"62389\"},{\"start\":\"62398\",\"end\":\"62399\"},{\"start\":\"62408\",\"end\":\"62409\"},{\"start\":\"62417\",\"end\":\"62418\"},{\"start\":\"62697\",\"end\":\"62698\"},{\"start\":\"62713\",\"end\":\"62714\"},{\"start\":\"62722\",\"end\":\"62723\"},{\"start\":\"62733\",\"end\":\"62734\"},{\"start\":\"62747\",\"end\":\"62748\"},{\"start\":\"62759\",\"end\":\"62762\"},{\"start\":\"62770\",\"end\":\"62779\"},{\"start\":\"62780\",\"end\":\"62781\"},{\"start\":\"62791\",\"end\":\"62792\"},{\"start\":\"63267\",\"end\":\"63268\"},{\"start\":\"63521\",\"end\":\"63524\"},{\"start\":\"63534\",\"end\":\"63537\"},{\"start\":\"63543\",\"end\":\"63546\"},{\"start\":\"63557\",\"end\":\"63558\"},{\"start\":\"63570\",\"end\":\"63573\"},{\"start\":\"63780\",\"end\":\"63783\"},{\"start\":\"63790\",\"end\":\"63793\"},{\"start\":\"63801\",\"end\":\"63804\"},{\"start\":\"63813\",\"end\":\"63814\"},{\"start\":\"63827\",\"end\":\"63830\"},{\"start\":\"64143\",\"end\":\"64144\"},{\"start\":\"64445\",\"end\":\"64448\"},{\"start\":\"64456\",\"end\":\"64459\"},{\"start\":\"64469\",\"end\":\"64470\"},{\"start\":\"64761\",\"end\":\"64762\"},{\"start\":\"64768\",\"end\":\"64769\"},{\"start\":\"64775\",\"end\":\"64776\"},{\"start\":\"65057\",\"end\":\"65058\"},{\"start\":\"65318\",\"end\":\"65319\"},{\"start\":\"65324\",\"end\":\"65327\"},{\"start\":\"65333\",\"end\":\"65334\"},{\"start\":\"65340\",\"end\":\"65341\"},{\"start\":\"65348\",\"end\":\"65349\"},{\"start\":\"65356\",\"end\":\"65359\"},{\"start\":\"65625\",\"end\":\"65626\"},{\"start\":\"65634\",\"end\":\"65635\"},{\"start\":\"65640\",\"end\":\"65641\"},{\"start\":\"65954\",\"end\":\"65955\"},{\"start\":\"65964\",\"end\":\"65965\"},{\"start\":\"65973\",\"end\":\"65976\"},{\"start\":\"65982\",\"end\":\"65985\"},{\"start\":\"65991\",\"end\":\"65992\"},{\"start\":\"65998\",\"end\":\"65999\"},{\"start\":\"66318\",\"end\":\"66319\"},{\"start\":\"66325\",\"end\":\"66326\"},{\"start\":\"66337\",\"end\":\"66338\"},{\"start\":\"66352\",\"end\":\"66353\"},{\"start\":\"66364\",\"end\":\"66365\"},{\"start\":\"66372\",\"end\":\"66373\"},{\"start\":\"66638\",\"end\":\"66639\"},{\"start\":\"66751\",\"end\":\"66752\"},{\"start\":\"66969\",\"end\":\"66970\"},{\"start\":\"67334\",\"end\":\"67337\"},{\"start\":\"67345\",\"end\":\"67348\"},{\"start\":\"67355\",\"end\":\"67358\"},{\"start\":\"67371\",\"end\":\"67374\"},{\"start\":\"67384\",\"end\":\"67387\"},{\"start\":\"67397\",\"end\":\"67398\"},{\"start\":\"67408\",\"end\":\"67409\"},{\"start\":\"67418\",\"end\":\"67419\"},{\"start\":\"67855\",\"end\":\"67858\"},{\"start\":\"67867\",\"end\":\"67870\"},{\"start\":\"67878\",\"end\":\"67879\"},{\"start\":\"67891\",\"end\":\"67892\"},{\"start\":\"67903\",\"end\":\"67906\"},{\"start\":\"67914\",\"end\":\"67915\"},{\"start\":\"68178\",\"end\":\"68179\"},{\"start\":\"68180\",\"end\":\"68181\"},{\"start\":\"68189\",\"end\":\"68199\"},{\"start\":\"68209\",\"end\":\"68210\"},{\"start\":\"68218\",\"end\":\"68221\"},{\"start\":\"68234\",\"end\":\"68237\"},{\"start\":\"68244\",\"end\":\"68247\"},{\"start\":\"68255\",\"end\":\"68256\"},{\"start\":\"68266\",\"end\":\"68267\"},{\"start\":\"68270\",\"end\":\"68287\"},{\"start\":\"68665\",\"end\":\"68666\"},{\"start\":\"68676\",\"end\":\"68677\"},{\"start\":\"68686\",\"end\":\"68687\"},{\"start\":\"68877\",\"end\":\"68878\"},{\"start\":\"68883\",\"end\":\"68884\"},{\"start\":\"68891\",\"end\":\"68892\"},{\"start\":\"68897\",\"end\":\"68898\"},{\"start\":\"68903\",\"end\":\"68906\"},{\"start\":\"69223\",\"end\":\"69224\"},{\"start\":\"69508\",\"end\":\"69511\"},{\"start\":\"69516\",\"end\":\"69519\"},{\"start\":\"69520\",\"end\":\"69521\"},{\"start\":\"69528\",\"end\":\"69529\"},{\"start\":\"69950\",\"end\":\"69951\"},{\"start\":\"69958\",\"end\":\"69959\"},{\"start\":\"69964\",\"end\":\"69965\"},{\"start\":\"70305\",\"end\":\"70306\"},{\"start\":\"70523\",\"end\":\"70524\"},{\"start\":\"70819\",\"end\":\"70822\"},{\"start\":\"70828\",\"end\":\"70832\"},{\"start\":\"70833\",\"end\":\"70834\"},{\"start\":\"70845\",\"end\":\"70846\"},{\"start\":\"70858\",\"end\":\"70859\"},{\"start\":\"70867\",\"end\":\"70870\"},{\"start\":\"70877\",\"end\":\"70878\"},{\"start\":\"70886\",\"end\":\"70887\"},{\"start\":\"70890\",\"end\":\"70894\"},{\"start\":\"70895\",\"end\":\"70896\"},{\"start\":\"71286\",\"end\":\"71287\"},{\"start\":\"71615\",\"end\":\"71618\"},{\"start\":\"71624\",\"end\":\"71628\"},{\"start\":\"71629\",\"end\":\"71630\"},{\"start\":\"71638\",\"end\":\"71641\"},{\"start\":\"71644\",\"end\":\"71651\"},{\"start\":\"71659\",\"end\":\"71660\"},{\"start\":\"71671\",\"end\":\"71672\"},{\"start\":\"71684\",\"end\":\"71685\"},{\"start\":\"71693\",\"end\":\"71694\"},{\"start\":\"71703\",\"end\":\"71704\"},{\"start\":\"71705\",\"end\":\"71706\"},{\"start\":\"71709\",\"end\":\"71712\"},{\"start\":\"71713\",\"end\":\"71714\"},{\"start\":\"71722\",\"end\":\"71725\"},{\"start\":\"72175\",\"end\":\"72178\"},{\"start\":\"72189\",\"end\":\"72190\"},{\"start\":\"72204\",\"end\":\"72205\"},{\"start\":\"72212\",\"end\":\"72218\"},{\"start\":\"72219\",\"end\":\"72220\"},{\"start\":\"72229\",\"end\":\"72232\"},{\"start\":\"72723\",\"end\":\"72724\"},{\"start\":\"73086\",\"end\":\"73089\"},{\"start\":\"73100\",\"end\":\"73101\"},{\"start\":\"73114\",\"end\":\"73117\"},{\"start\":\"73471\",\"end\":\"73472\"},{\"start\":\"73483\",\"end\":\"73484\"},{\"start\":\"73492\",\"end\":\"73493\"},{\"start\":\"73731\",\"end\":\"73732\"},{\"start\":\"73991\",\"end\":\"73992\"},{\"start\":\"74215\",\"end\":\"74218\"},{\"start\":\"74227\",\"end\":\"74228\"},{\"start\":\"74239\",\"end\":\"74242\"},{\"start\":\"74545\",\"end\":\"74546\"},{\"start\":\"74555\",\"end\":\"74556\"},{\"start\":\"74565\",\"end\":\"74566\"},{\"start\":\"74804\",\"end\":\"74805\"},{\"start\":\"74815\",\"end\":\"74818\"},{\"start\":\"74828\",\"end\":\"74831\"},{\"start\":\"74839\",\"end\":\"74843\"},{\"start\":\"74844\",\"end\":\"74845\"},{\"start\":\"74848\",\"end\":\"74850\"},{\"start\":\"74851\",\"end\":\"74852\"},{\"start\":\"74859\",\"end\":\"74862\"},{\"start\":\"75148\",\"end\":\"75149\"},{\"start\":\"75451\",\"end\":\"75454\"},{\"start\":\"75459\",\"end\":\"75460\"},{\"start\":\"75468\",\"end\":\"75469\"},{\"start\":\"75760\",\"end\":\"75763\"},{\"start\":\"75771\",\"end\":\"75774\"},{\"start\":\"75782\",\"end\":\"75784\"},{\"start\":\"75792\",\"end\":\"75793\"},{\"start\":\"75796\",\"end\":\"75810\"},{\"start\":\"75820\",\"end\":\"75821\"},{\"start\":\"75830\",\"end\":\"75833\"},{\"start\":\"76163\",\"end\":\"76164\"},{\"start\":\"76173\",\"end\":\"76174\"},{\"start\":\"76184\",\"end\":\"76187\"},{\"start\":\"76421\",\"end\":\"76422\"},{\"start\":\"76432\",\"end\":\"76433\"},{\"start\":\"76440\",\"end\":\"76443\"},{\"start\":\"76455\",\"end\":\"76458\"},{\"start\":\"76816\",\"end\":\"76817\"}]", "bib_author_last_name": "[{\"start\":\"60145\",\"end\":\"60154\"},{\"start\":\"60158\",\"end\":\"60165\"},{\"start\":\"60171\",\"end\":\"60179\"},{\"start\":\"60183\",\"end\":\"60194\"},{\"start\":\"60200\",\"end\":\"60207\"},{\"start\":\"60220\",\"end\":\"60233\"},{\"start\":\"60566\",\"end\":\"60579\"},{\"start\":\"60585\",\"end\":\"60590\"},{\"start\":\"60596\",\"end\":\"60603\"},{\"start\":\"60607\",\"end\":\"60613\"},{\"start\":\"60619\",\"end\":\"60625\"},{\"start\":\"60629\",\"end\":\"60637\"},{\"start\":\"60641\",\"end\":\"60647\"},{\"start\":\"60651\",\"end\":\"60657\"},{\"start\":\"60661\",\"end\":\"60676\"},{\"start\":\"61169\",\"end\":\"61173\"},{\"start\":\"61177\",\"end\":\"61184\"},{\"start\":\"61188\",\"end\":\"61196\"},{\"start\":\"61200\",\"end\":\"61202\"},{\"start\":\"61206\",\"end\":\"61208\"},{\"start\":\"61212\",\"end\":\"61214\"},{\"start\":\"61218\",\"end\":\"61220\"},{\"start\":\"61229\",\"end\":\"61233\"},{\"start\":\"61656\",\"end\":\"61660\"},{\"start\":\"61934\",\"end\":\"61940\"},{\"start\":\"61944\",\"end\":\"61951\"},{\"start\":\"61955\",\"end\":\"61964\"},{\"start\":\"61968\",\"end\":\"61974\"},{\"start\":\"61980\",\"end\":\"61983\"},{\"start\":\"62332\",\"end\":\"62340\"},{\"start\":\"62346\",\"end\":\"62351\"},{\"start\":\"62355\",\"end\":\"62362\"},{\"start\":\"62366\",\"end\":\"62370\"},{\"start\":\"62374\",\"end\":\"62386\"},{\"start\":\"62390\",\"end\":\"62396\"},{\"start\":\"62400\",\"end\":\"62406\"},{\"start\":\"62410\",\"end\":\"62415\"},{\"start\":\"62419\",\"end\":\"62426\"},{\"start\":\"62699\",\"end\":\"62711\"},{\"start\":\"62715\",\"end\":\"62720\"},{\"start\":\"62724\",\"end\":\"62731\"},{\"start\":\"62735\",\"end\":\"62745\"},{\"start\":\"62749\",\"end\":\"62757\"},{\"start\":\"62763\",\"end\":\"62768\"},{\"start\":\"62782\",\"end\":\"62789\"},{\"start\":\"63269\",\"end\":\"63277\"},{\"start\":\"63525\",\"end\":\"63532\"},{\"start\":\"63538\",\"end\":\"63541\"},{\"start\":\"63547\",\"end\":\"63551\"},{\"start\":\"63553\",\"end\":\"63555\"},{\"start\":\"63559\",\"end\":\"63568\"},{\"start\":\"63574\",\"end\":\"63582\"},{\"start\":\"63784\",\"end\":\"63788\"},{\"start\":\"63794\",\"end\":\"63799\"},{\"start\":\"63805\",\"end\":\"63811\"},{\"start\":\"63815\",\"end\":\"63825\"},{\"start\":\"63831\",\"end\":\"63837\"},{\"start\":\"64145\",\"end\":\"64152\"},{\"start\":\"64449\",\"end\":\"64454\"},{\"start\":\"64460\",\"end\":\"64467\"},{\"start\":\"64471\",\"end\":\"64479\"},{\"start\":\"64763\",\"end\":\"64766\"},{\"start\":\"64770\",\"end\":\"64773\"},{\"start\":\"64777\",\"end\":\"64782\"},{\"start\":\"65059\",\"end\":\"65062\"},{\"start\":\"65320\",\"end\":\"65322\"},{\"start\":\"65328\",\"end\":\"65331\"},{\"start\":\"65335\",\"end\":\"65338\"},{\"start\":\"65342\",\"end\":\"65346\"},{\"start\":\"65350\",\"end\":\"65354\"},{\"start\":\"65360\",\"end\":\"65365\"},{\"start\":\"65627\",\"end\":\"65632\"},{\"start\":\"65636\",\"end\":\"65638\"},{\"start\":\"65642\",\"end\":\"65657\"},{\"start\":\"65956\",\"end\":\"65962\"},{\"start\":\"65966\",\"end\":\"65971\"},{\"start\":\"65977\",\"end\":\"65980\"},{\"start\":\"65986\",\"end\":\"65989\"},{\"start\":\"65993\",\"end\":\"65996\"},{\"start\":\"66000\",\"end\":\"66004\"},{\"start\":\"66320\",\"end\":\"66323\"},{\"start\":\"66327\",\"end\":\"66335\"},{\"start\":\"66339\",\"end\":\"66350\"},{\"start\":\"66354\",\"end\":\"66362\"},{\"start\":\"66366\",\"end\":\"66370\"},{\"start\":\"66374\",\"end\":\"66381\"},{\"start\":\"66640\",\"end\":\"66652\"},{\"start\":\"66753\",\"end\":\"66757\"},{\"start\":\"66971\",\"end\":\"66979\"},{\"start\":\"67338\",\"end\":\"67343\"},{\"start\":\"67349\",\"end\":\"67353\"},{\"start\":\"67359\",\"end\":\"67369\"},{\"start\":\"67375\",\"end\":\"67382\"},{\"start\":\"67388\",\"end\":\"67395\"},{\"start\":\"67399\",\"end\":\"67406\"},{\"start\":\"67410\",\"end\":\"67416\"},{\"start\":\"67420\",\"end\":\"67424\"},{\"start\":\"67859\",\"end\":\"67865\"},{\"start\":\"67871\",\"end\":\"67876\"},{\"start\":\"67880\",\"end\":\"67889\"},{\"start\":\"67893\",\"end\":\"67901\"},{\"start\":\"67907\",\"end\":\"67912\"},{\"start\":\"67916\",\"end\":\"67921\"},{\"start\":\"68182\",\"end\":\"68187\"},{\"start\":\"68200\",\"end\":\"68207\"},{\"start\":\"68211\",\"end\":\"68216\"},{\"start\":\"68222\",\"end\":\"68232\"},{\"start\":\"68238\",\"end\":\"68242\"},{\"start\":\"68248\",\"end\":\"68253\"},{\"start\":\"68257\",\"end\":\"68264\"},{\"start\":\"68667\",\"end\":\"68674\"},{\"start\":\"68678\",\"end\":\"68684\"},{\"start\":\"68688\",\"end\":\"68692\"},{\"start\":\"68879\",\"end\":\"68881\"},{\"start\":\"68885\",\"end\":\"68889\"},{\"start\":\"68893\",\"end\":\"68895\"},{\"start\":\"68899\",\"end\":\"68901\"},{\"start\":\"68907\",\"end\":\"68912\"},{\"start\":\"69225\",\"end\":\"69234\"},{\"start\":\"69512\",\"end\":\"69514\"},{\"start\":\"69522\",\"end\":\"69526\"},{\"start\":\"69952\",\"end\":\"69956\"},{\"start\":\"69960\",\"end\":\"69962\"},{\"start\":\"69966\",\"end\":\"69969\"},{\"start\":\"70307\",\"end\":\"70311\"},{\"start\":\"70525\",\"end\":\"70532\"},{\"start\":\"70823\",\"end\":\"70826\"},{\"start\":\"70835\",\"end\":\"70843\"},{\"start\":\"70847\",\"end\":\"70856\"},{\"start\":\"70860\",\"end\":\"70865\"},{\"start\":\"70871\",\"end\":\"70875\"},{\"start\":\"70879\",\"end\":\"70884\"},{\"start\":\"71288\",\"end\":\"71292\"},{\"start\":\"71619\",\"end\":\"71622\"},{\"start\":\"71631\",\"end\":\"71636\"},{\"start\":\"71652\",\"end\":\"71657\"},{\"start\":\"71661\",\"end\":\"71669\"},{\"start\":\"71673\",\"end\":\"71682\"},{\"start\":\"71686\",\"end\":\"71691\"},{\"start\":\"71695\",\"end\":\"71701\"},{\"start\":\"71715\",\"end\":\"71720\"},{\"start\":\"72179\",\"end\":\"72187\"},{\"start\":\"72191\",\"end\":\"72202\"},{\"start\":\"72206\",\"end\":\"72210\"},{\"start\":\"72221\",\"end\":\"72227\"},{\"start\":\"72725\",\"end\":\"72732\"},{\"start\":\"73090\",\"end\":\"73098\"},{\"start\":\"73102\",\"end\":\"73112\"},{\"start\":\"73118\",\"end\":\"73126\"},{\"start\":\"73248\",\"end\":\"73267\"},{\"start\":\"73473\",\"end\":\"73481\"},{\"start\":\"73485\",\"end\":\"73490\"},{\"start\":\"73494\",\"end\":\"73500\"},{\"start\":\"73733\",\"end\":\"73738\"},{\"start\":\"73993\",\"end\":\"73998\"},{\"start\":\"74219\",\"end\":\"74225\"},{\"start\":\"74229\",\"end\":\"74237\"},{\"start\":\"74243\",\"end\":\"74250\"},{\"start\":\"74547\",\"end\":\"74553\"},{\"start\":\"74557\",\"end\":\"74563\"},{\"start\":\"74567\",\"end\":\"74572\"},{\"start\":\"74806\",\"end\":\"74813\"},{\"start\":\"74819\",\"end\":\"74826\"},{\"start\":\"74832\",\"end\":\"74837\"},{\"start\":\"74853\",\"end\":\"74857\"},{\"start\":\"75150\",\"end\":\"75160\"},{\"start\":\"75455\",\"end\":\"75457\"},{\"start\":\"75461\",\"end\":\"75466\"},{\"start\":\"75470\",\"end\":\"75478\"},{\"start\":\"75764\",\"end\":\"75769\"},{\"start\":\"75775\",\"end\":\"75780\"},{\"start\":\"75785\",\"end\":\"75790\"},{\"start\":\"75811\",\"end\":\"75818\"},{\"start\":\"75822\",\"end\":\"75828\"},{\"start\":\"76165\",\"end\":\"76171\"},{\"start\":\"76175\",\"end\":\"76182\"},{\"start\":\"76188\",\"end\":\"76198\"},{\"start\":\"76423\",\"end\":\"76430\"},{\"start\":\"76434\",\"end\":\"76438\"},{\"start\":\"76444\",\"end\":\"76453\"},{\"start\":\"76459\",\"end\":\"76467\"},{\"start\":\"76818\",\"end\":\"76825\"}]", "bib_entry": "[{\"start\":\"60141\",\"end\":\"60342\",\"attributes\":{\"id\":\"b0\"}},{\"start\":\"60344\",\"end\":\"60441\",\"attributes\":{\"id\":\"b1\",\"doi\":\"10.1016/S0140-6736(15)01124-1\"}},{\"start\":\"60443\",\"end\":\"61020\",\"attributes\":{\"matched_paper_id\":\"222006182\",\"id\":\"b2\",\"doi\":\"10.1016/j.neurobiolaging.2020.09.014\"}},{\"start\":\"61022\",\"end\":\"61535\",\"attributes\":{\"matched_paper_id\":\"235691740\",\"id\":\"b3\"}},{\"start\":\"61537\",\"end\":\"61871\",\"attributes\":{\"matched_paper_id\":\"206160801\",\"id\":\"b4\"}},{\"start\":\"61873\",\"end\":\"62205\",\"attributes\":{\"matched_paper_id\":\"5307637\",\"id\":\"b5\"}},{\"start\":\"62207\",\"end\":\"62693\",\"attributes\":{\"id\":\"b6\"}},{\"start\":\"62695\",\"end\":\"62898\",\"attributes\":{\"id\":\"b7\"}},{\"start\":\"62900\",\"end\":\"63146\",\"attributes\":{\"matched_paper_id\":\"58663304\",\"id\":\"b8\"}},{\"start\":\"63148\",\"end\":\"63462\",\"attributes\":{\"id\":\"b9\"}},{\"start\":\"63464\",\"end\":\"63778\",\"attributes\":{\"matched_paper_id\":\"205514740\",\"id\":\"b10\"}},{\"start\":\"63780\",\"end\":\"64052\",\"attributes\":{\"id\":\"b11\"}},{\"start\":\"64054\",\"end\":\"64329\",\"attributes\":{\"matched_paper_id\":\"19895183\",\"id\":\"b12\"}},{\"start\":\"64331\",\"end\":\"64757\",\"attributes\":{\"id\":\"b13\"}},{\"start\":\"64759\",\"end\":\"64944\",\"attributes\":{\"id\":\"b14\"}},{\"start\":\"64946\",\"end\":\"65240\",\"attributes\":{\"matched_paper_id\":\"218481623\",\"id\":\"b15\"}},{\"start\":\"65242\",\"end\":\"65546\",\"attributes\":{\"id\":\"b16\"}},{\"start\":\"65548\",\"end\":\"65848\",\"attributes\":{\"matched_paper_id\":\"73508614\",\"id\":\"b17\"}},{\"start\":\"65850\",\"end\":\"66242\",\"attributes\":{\"matched_paper_id\":\"54583679\",\"id\":\"b18\"}},{\"start\":\"66244\",\"end\":\"66602\",\"attributes\":{\"matched_paper_id\":\"58014179\",\"id\":\"b19\"}},{\"start\":\"66604\",\"end\":\"66749\",\"attributes\":{\"matched_paper_id\":\"4465871\",\"id\":\"b20\"}},{\"start\":\"66751\",\"end\":\"66878\",\"attributes\":{\"id\":\"b21\"}},{\"start\":\"66880\",\"end\":\"67131\",\"attributes\":{\"id\":\"b22\"}},{\"start\":\"67133\",\"end\":\"67760\",\"attributes\":{\"id\":\"b23\"}},{\"start\":\"67762\",\"end\":\"68174\",\"attributes\":{\"matched_paper_id\":\"42563234\",\"id\":\"b24\"}},{\"start\":\"68176\",\"end\":\"68619\",\"attributes\":{\"id\":\"b25\"}},{\"start\":\"68621\",\"end\":\"68875\",\"attributes\":{\"matched_paper_id\":\"662715\",\"id\":\"b26\"}},{\"start\":\"68877\",\"end\":\"69221\",\"attributes\":{\"id\":\"b27\"}},{\"start\":\"69223\",\"end\":\"69414\",\"attributes\":{\"id\":\"b28\"}},{\"start\":\"69416\",\"end\":\"69803\",\"attributes\":{\"matched_paper_id\":\"233444058\",\"id\":\"b29\"}},{\"start\":\"69805\",\"end\":\"70199\",\"attributes\":{\"matched_paper_id\":\"231786331\",\"id\":\"b30\"}},{\"start\":\"70201\",\"end\":\"70521\",\"attributes\":{\"matched_paper_id\":\"21706467\",\"id\":\"b31\"}},{\"start\":\"70523\",\"end\":\"70710\",\"attributes\":{\"id\":\"b32\"}},{\"start\":\"70712\",\"end\":\"71156\",\"attributes\":{\"matched_paper_id\":\"221387177\",\"id\":\"b33\"}},{\"start\":\"71158\",\"end\":\"71509\",\"attributes\":{\"matched_paper_id\":\"211010992\",\"id\":\"b34\"}},{\"start\":\"71511\",\"end\":\"72011\",\"attributes\":{\"matched_paper_id\":\"207870474\",\"id\":\"b35\"}},{\"start\":\"72013\",\"end\":\"72499\",\"attributes\":{\"id\":\"b36\"}},{\"start\":\"72501\",\"end\":\"73082\",\"attributes\":{\"matched_paper_id\":\"71105800\",\"id\":\"b37\"}},{\"start\":\"73084\",\"end\":\"73178\",\"attributes\":{\"id\":\"b38\"}},{\"start\":\"73180\",\"end\":\"73397\",\"attributes\":{\"id\":\"b39\"}},{\"start\":\"73399\",\"end\":\"73665\",\"attributes\":{\"matched_paper_id\":\"16212378\",\"id\":\"b40\"}},{\"start\":\"73667\",\"end\":\"73887\",\"attributes\":{\"matched_paper_id\":\"216560588\",\"id\":\"b41\"}},{\"start\":\"73889\",\"end\":\"74161\",\"attributes\":{\"id\":\"b42\"}},{\"start\":\"74163\",\"end\":\"74459\",\"attributes\":{\"id\":\"b43\"}},{\"start\":\"74461\",\"end\":\"74754\",\"attributes\":{\"matched_paper_id\":\"8109140\",\"id\":\"b44\"}},{\"start\":\"74756\",\"end\":\"75022\",\"attributes\":{\"id\":\"b45\"}},{\"start\":\"75024\",\"end\":\"75381\",\"attributes\":{\"matched_paper_id\":\"18181917\",\"id\":\"b46\"}},{\"start\":\"75383\",\"end\":\"75654\",\"attributes\":{\"matched_paper_id\":\"8762236\",\"id\":\"b47\"}},{\"start\":\"75656\",\"end\":\"76090\",\"attributes\":{\"matched_paper_id\":\"51708985\",\"id\":\"b48\"}},{\"start\":\"76092\",\"end\":\"76351\",\"attributes\":{\"id\":\"b49\"}},{\"start\":\"76353\",\"end\":\"76645\",\"attributes\":{\"matched_paper_id\":\"11435142\",\"id\":\"b50\"}},{\"start\":\"76647\",\"end\":\"77058\",\"attributes\":{\"id\":\"b51\"}}]", "bib_title": "[{\"start\":\"60443\",\"end\":\"60562\"},{\"start\":\"61022\",\"end\":\"61165\"},{\"start\":\"61537\",\"end\":\"61650\"},{\"start\":\"61873\",\"end\":\"61930\"},{\"start\":\"62900\",\"end\":\"62991\"},{\"start\":\"63464\",\"end\":\"63519\"},{\"start\":\"64054\",\"end\":\"64141\"},{\"start\":\"64331\",\"end\":\"64443\"},{\"start\":\"64946\",\"end\":\"65055\"},{\"start\":\"65548\",\"end\":\"65623\"},{\"start\":\"65850\",\"end\":\"65952\"},{\"start\":\"66244\",\"end\":\"66316\"},{\"start\":\"66604\",\"end\":\"66636\"},{\"start\":\"67762\",\"end\":\"67853\"},{\"start\":\"68621\",\"end\":\"68663\"},{\"start\":\"69416\",\"end\":\"69506\"},{\"start\":\"69805\",\"end\":\"69948\"},{\"start\":\"70201\",\"end\":\"70303\"},{\"start\":\"70712\",\"end\":\"70817\"},{\"start\":\"71158\",\"end\":\"71284\"},{\"start\":\"71511\",\"end\":\"71613\"},{\"start\":\"72501\",\"end\":\"72721\"},{\"start\":\"73399\",\"end\":\"73469\"},{\"start\":\"73667\",\"end\":\"73729\"},{\"start\":\"74163\",\"end\":\"74213\"},{\"start\":\"74461\",\"end\":\"74543\"},{\"start\":\"75024\",\"end\":\"75146\"},{\"start\":\"75383\",\"end\":\"75449\"},{\"start\":\"75656\",\"end\":\"75758\"},{\"start\":\"76353\",\"end\":\"76419\"}]", "bib_author": "[{\"start\":\"60143\",\"end\":\"60156\"},{\"start\":\"60156\",\"end\":\"60167\"},{\"start\":\"60167\",\"end\":\"60181\"},{\"start\":\"60181\",\"end\":\"60196\"},{\"start\":\"60196\",\"end\":\"60209\"},{\"start\":\"60209\",\"end\":\"60235\"},{\"start\":\"60235\",\"end\":\"60239\"},{\"start\":\"60564\",\"end\":\"60581\"},{\"start\":\"60581\",\"end\":\"60592\"},{\"start\":\"60592\",\"end\":\"60605\"},{\"start\":\"60605\",\"end\":\"60615\"},{\"start\":\"60615\",\"end\":\"60627\"},{\"start\":\"60627\",\"end\":\"60639\"},{\"start\":\"60639\",\"end\":\"60649\"},{\"start\":\"60649\",\"end\":\"60659\"},{\"start\":\"60659\",\"end\":\"60678\"},{\"start\":\"61167\",\"end\":\"61175\"},{\"start\":\"61175\",\"end\":\"61186\"},{\"start\":\"61186\",\"end\":\"61198\"},{\"start\":\"61198\",\"end\":\"61204\"},{\"start\":\"61204\",\"end\":\"61210\"},{\"start\":\"61210\",\"end\":\"61216\"},{\"start\":\"61216\",\"end\":\"61222\"},{\"start\":\"61222\",\"end\":\"61235\"},{\"start\":\"61235\",\"end\":\"61239\"},{\"start\":\"61652\",\"end\":\"61664\"},{\"start\":\"61932\",\"end\":\"61942\"},{\"start\":\"61942\",\"end\":\"61953\"},{\"start\":\"61953\",\"end\":\"61966\"},{\"start\":\"61966\",\"end\":\"61976\"},{\"start\":\"61976\",\"end\":\"61985\"},{\"start\":\"62330\",\"end\":\"62342\"},{\"start\":\"62342\",\"end\":\"62353\"},{\"start\":\"62353\",\"end\":\"62364\"},{\"start\":\"62364\",\"end\":\"62372\"},{\"start\":\"62372\",\"end\":\"62388\"},{\"start\":\"62388\",\"end\":\"62398\"},{\"start\":\"62398\",\"end\":\"62408\"},{\"start\":\"62408\",\"end\":\"62417\"},{\"start\":\"62417\",\"end\":\"62428\"},{\"start\":\"62697\",\"end\":\"62713\"},{\"start\":\"62713\",\"end\":\"62722\"},{\"start\":\"62722\",\"end\":\"62733\"},{\"start\":\"62733\",\"end\":\"62747\"},{\"start\":\"62747\",\"end\":\"62759\"},{\"start\":\"62759\",\"end\":\"62770\"},{\"start\":\"62770\",\"end\":\"62791\"},{\"start\":\"62791\",\"end\":\"62795\"},{\"start\":\"63267\",\"end\":\"63279\"},{\"start\":\"63521\",\"end\":\"63534\"},{\"start\":\"63534\",\"end\":\"63543\"},{\"start\":\"63543\",\"end\":\"63553\"},{\"start\":\"63553\",\"end\":\"63557\"},{\"start\":\"63557\",\"end\":\"63570\"},{\"start\":\"63570\",\"end\":\"63584\"},{\"start\":\"63780\",\"end\":\"63790\"},{\"start\":\"63790\",\"end\":\"63801\"},{\"start\":\"63801\",\"end\":\"63813\"},{\"start\":\"63813\",\"end\":\"63827\"},{\"start\":\"63827\",\"end\":\"63839\"},{\"start\":\"64143\",\"end\":\"64154\"},{\"start\":\"64445\",\"end\":\"64456\"},{\"start\":\"64456\",\"end\":\"64469\"},{\"start\":\"64469\",\"end\":\"64481\"},{\"start\":\"64761\",\"end\":\"64768\"},{\"start\":\"64768\",\"end\":\"64775\"},{\"start\":\"64775\",\"end\":\"64784\"},{\"start\":\"65057\",\"end\":\"65064\"},{\"start\":\"65318\",\"end\":\"65324\"},{\"start\":\"65324\",\"end\":\"65333\"},{\"start\":\"65333\",\"end\":\"65340\"},{\"start\":\"65340\",\"end\":\"65348\"},{\"start\":\"65348\",\"end\":\"65356\"},{\"start\":\"65356\",\"end\":\"65367\"},{\"start\":\"65625\",\"end\":\"65634\"},{\"start\":\"65634\",\"end\":\"65640\"},{\"start\":\"65640\",\"end\":\"65659\"},{\"start\":\"65954\",\"end\":\"65964\"},{\"start\":\"65964\",\"end\":\"65973\"},{\"start\":\"65973\",\"end\":\"65982\"},{\"start\":\"65982\",\"end\":\"65991\"},{\"start\":\"65991\",\"end\":\"65998\"},{\"start\":\"65998\",\"end\":\"66006\"},{\"start\":\"66318\",\"end\":\"66325\"},{\"start\":\"66325\",\"end\":\"66337\"},{\"start\":\"66337\",\"end\":\"66352\"},{\"start\":\"66352\",\"end\":\"66364\"},{\"start\":\"66364\",\"end\":\"66372\"},{\"start\":\"66372\",\"end\":\"66383\"},{\"start\":\"66638\",\"end\":\"66654\"},{\"start\":\"66751\",\"end\":\"66759\"},{\"start\":\"66969\",\"end\":\"66981\"},{\"start\":\"67334\",\"end\":\"67345\"},{\"start\":\"67345\",\"end\":\"67355\"},{\"start\":\"67355\",\"end\":\"67371\"},{\"start\":\"67371\",\"end\":\"67384\"},{\"start\":\"67384\",\"end\":\"67397\"},{\"start\":\"67397\",\"end\":\"67408\"},{\"start\":\"67408\",\"end\":\"67418\"},{\"start\":\"67418\",\"end\":\"67426\"},{\"start\":\"67855\",\"end\":\"67867\"},{\"start\":\"67867\",\"end\":\"67878\"},{\"start\":\"67878\",\"end\":\"67891\"},{\"start\":\"67891\",\"end\":\"67903\"},{\"start\":\"67903\",\"end\":\"67914\"},{\"start\":\"67914\",\"end\":\"67923\"},{\"start\":\"68178\",\"end\":\"68189\"},{\"start\":\"68189\",\"end\":\"68209\"},{\"start\":\"68209\",\"end\":\"68218\"},{\"start\":\"68218\",\"end\":\"68234\"},{\"start\":\"68234\",\"end\":\"68244\"},{\"start\":\"68244\",\"end\":\"68255\"},{\"start\":\"68255\",\"end\":\"68266\"},{\"start\":\"68266\",\"end\":\"68270\"},{\"start\":\"68270\",\"end\":\"68290\"},{\"start\":\"68665\",\"end\":\"68676\"},{\"start\":\"68676\",\"end\":\"68686\"},{\"start\":\"68686\",\"end\":\"68694\"},{\"start\":\"68877\",\"end\":\"68883\"},{\"start\":\"68883\",\"end\":\"68891\"},{\"start\":\"68891\",\"end\":\"68897\"},{\"start\":\"68897\",\"end\":\"68903\"},{\"start\":\"68903\",\"end\":\"68914\"},{\"start\":\"69223\",\"end\":\"69236\"},{\"start\":\"69508\",\"end\":\"69516\"},{\"start\":\"69516\",\"end\":\"69528\"},{\"start\":\"69528\",\"end\":\"69532\"},{\"start\":\"69950\",\"end\":\"69958\"},{\"start\":\"69958\",\"end\":\"69964\"},{\"start\":\"69964\",\"end\":\"69971\"},{\"start\":\"70305\",\"end\":\"70313\"},{\"start\":\"70523\",\"end\":\"70534\"},{\"start\":\"70819\",\"end\":\"70828\"},{\"start\":\"70828\",\"end\":\"70845\"},{\"start\":\"70845\",\"end\":\"70858\"},{\"start\":\"70858\",\"end\":\"70867\"},{\"start\":\"70867\",\"end\":\"70877\"},{\"start\":\"70877\",\"end\":\"70886\"},{\"start\":\"70886\",\"end\":\"70890\"},{\"start\":\"70890\",\"end\":\"70899\"},{\"start\":\"71286\",\"end\":\"71294\"},{\"start\":\"71615\",\"end\":\"71624\"},{\"start\":\"71624\",\"end\":\"71638\"},{\"start\":\"71638\",\"end\":\"71644\"},{\"start\":\"71644\",\"end\":\"71659\"},{\"start\":\"71659\",\"end\":\"71671\"},{\"start\":\"71671\",\"end\":\"71684\"},{\"start\":\"71684\",\"end\":\"71693\"},{\"start\":\"71693\",\"end\":\"71703\"},{\"start\":\"71703\",\"end\":\"71709\"},{\"start\":\"71709\",\"end\":\"71722\"},{\"start\":\"71722\",\"end\":\"71728\"},{\"start\":\"72175\",\"end\":\"72189\"},{\"start\":\"72189\",\"end\":\"72204\"},{\"start\":\"72204\",\"end\":\"72212\"},{\"start\":\"72212\",\"end\":\"72229\"},{\"start\":\"72229\",\"end\":\"72235\"},{\"start\":\"72723\",\"end\":\"72734\"},{\"start\":\"73086\",\"end\":\"73100\"},{\"start\":\"73100\",\"end\":\"73114\"},{\"start\":\"73114\",\"end\":\"73128\"},{\"start\":\"73248\",\"end\":\"73269\"},{\"start\":\"73471\",\"end\":\"73483\"},{\"start\":\"73483\",\"end\":\"73492\"},{\"start\":\"73492\",\"end\":\"73502\"},{\"start\":\"73731\",\"end\":\"73740\"},{\"start\":\"73991\",\"end\":\"74000\"},{\"start\":\"74215\",\"end\":\"74227\"},{\"start\":\"74227\",\"end\":\"74239\"},{\"start\":\"74239\",\"end\":\"74252\"},{\"start\":\"74545\",\"end\":\"74555\"},{\"start\":\"74555\",\"end\":\"74565\"},{\"start\":\"74565\",\"end\":\"74574\"},{\"start\":\"74804\",\"end\":\"74815\"},{\"start\":\"74815\",\"end\":\"74828\"},{\"start\":\"74828\",\"end\":\"74839\"},{\"start\":\"74839\",\"end\":\"74848\"},{\"start\":\"74848\",\"end\":\"74859\"},{\"start\":\"74859\",\"end\":\"74865\"},{\"start\":\"75148\",\"end\":\"75162\"},{\"start\":\"75451\",\"end\":\"75459\"},{\"start\":\"75459\",\"end\":\"75468\"},{\"start\":\"75468\",\"end\":\"75480\"},{\"start\":\"75760\",\"end\":\"75771\"},{\"start\":\"75771\",\"end\":\"75782\"},{\"start\":\"75782\",\"end\":\"75792\"},{\"start\":\"75792\",\"end\":\"75796\"},{\"start\":\"75796\",\"end\":\"75820\"},{\"start\":\"75820\",\"end\":\"75830\"},{\"start\":\"75830\",\"end\":\"75836\"},{\"start\":\"76163\",\"end\":\"76173\"},{\"start\":\"76173\",\"end\":\"76184\"},{\"start\":\"76184\",\"end\":\"76200\"},{\"start\":\"76421\",\"end\":\"76432\"},{\"start\":\"76432\",\"end\":\"76440\"},{\"start\":\"76440\",\"end\":\"76455\"},{\"start\":\"76455\",\"end\":\"76469\"},{\"start\":\"76816\",\"end\":\"76827\"}]", "bib_venue": "[{\"start\":\"60344\",\"end\":\"60370\"},{\"start\":\"60723\",\"end\":\"60739\"},{\"start\":\"61265\",\"end\":\"61282\"},{\"start\":\"61693\",\"end\":\"61706\"},{\"start\":\"62009\",\"end\":\"62040\"},{\"start\":\"62207\",\"end\":\"62328\"},{\"start\":\"63021\",\"end\":\"63030\"},{\"start\":\"63148\",\"end\":\"63265\"},{\"start\":\"63609\",\"end\":\"63625\"},{\"start\":\"63867\",\"end\":\"63915\"},{\"start\":\"64188\",\"end\":\"64197\"},{\"start\":\"64509\",\"end\":\"64536\"},{\"start\":\"64813\",\"end\":\"64855\"},{\"start\":\"65085\",\"end\":\"65090\"},{\"start\":\"65242\",\"end\":\"65316\"},{\"start\":\"65683\",\"end\":\"65696\"},{\"start\":\"66030\",\"end\":\"66044\"},{\"start\":\"66407\",\"end\":\"66421\"},{\"start\":\"66669\",\"end\":\"66675\"},{\"start\":\"66782\",\"end\":\"66814\"},{\"start\":\"66880\",\"end\":\"66967\"},{\"start\":\"67133\",\"end\":\"67332\"},{\"start\":\"67923\",\"end\":\"67951\"},{\"start\":\"68314\",\"end\":\"68401\"},{\"start\":\"68719\",\"end\":\"68745\"},{\"start\":\"68938\",\"end\":\"69042\"},{\"start\":\"69254\",\"end\":\"69310\"},{\"start\":\"69560\",\"end\":\"69605\"},{\"start\":\"69999\",\"end\":\"70005\"},{\"start\":\"70337\",\"end\":\"70361\"},{\"start\":\"70550\",\"end\":\"70609\"},{\"start\":\"70926\",\"end\":\"70937\"},{\"start\":\"71322\",\"end\":\"71334\"},{\"start\":\"71755\",\"end\":\"71766\"},{\"start\":\"72013\",\"end\":\"72173\"},{\"start\":\"72764\",\"end\":\"72791\"},{\"start\":\"73180\",\"end\":\"73246\"},{\"start\":\"73530\",\"end\":\"73536\"},{\"start\":\"73765\",\"end\":\"73778\"},{\"start\":\"73889\",\"end\":\"73989\"},{\"start\":\"74279\",\"end\":\"74308\"},{\"start\":\"74593\",\"end\":\"74608\"},{\"start\":\"74756\",\"end\":\"74802\"},{\"start\":\"75191\",\"end\":\"75204\"},{\"start\":\"75505\",\"end\":\"75521\"},{\"start\":\"75861\",\"end\":\"75875\"},{\"start\":\"76092\",\"end\":\"76161\"},{\"start\":\"76486\",\"end\":\"76497\"},{\"start\":\"76647\",\"end\":\"76814\"}]"}}}, "year": 2023, "month": 12, "day": 17}