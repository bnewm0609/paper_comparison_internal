{"id": 232148002, "updated": "2023-10-06 06:07:36.72", "metadata": {"title": "WebFace260M: A Benchmark Unveiling the Power of Million-Scale Deep Face Recognition", "authors": "[{\"first\":\"Zheng\",\"last\":\"Zhu\",\"middle\":[]},{\"first\":\"Guan\",\"last\":\"Huang\",\"middle\":[]},{\"first\":\"Jiankang\",\"last\":\"Deng\",\"middle\":[]},{\"first\":\"Yun\",\"last\":\"Ye\",\"middle\":[]},{\"first\":\"Junjie\",\"last\":\"Huang\",\"middle\":[]},{\"first\":\"Xinze\",\"last\":\"Chen\",\"middle\":[]},{\"first\":\"Jiagang\",\"last\":\"Zhu\",\"middle\":[]},{\"first\":\"Tian\",\"last\":\"Yang\",\"middle\":[]},{\"first\":\"Jiwen\",\"last\":\"Lu\",\"middle\":[]},{\"first\":\"Dalong\",\"last\":\"Du\",\"middle\":[]},{\"first\":\"Jie\",\"last\":\"Zhou\",\"middle\":[]}]", "venue": "2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)", "journal": "2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)", "publication_date": {"year": 2021, "month": 3, "day": 6}, "abstract": "In this paper, we contribute a new million-scale face benchmark containing noisy 4M identities/260M faces (WebFace260M) and cleaned 2M identities/42M faces (WebFace42M) training data, as well as an elaborately designed time-constrained evaluation protocol. Firstly, we collect 4M name list and download 260M faces from the Internet. Then, a Cleaning Automatically utilizing Self-Training (CAST) pipeline is devised to purify the tremendous WebFace260M, which is efficient and scalable. To the best of our knowledge, the cleaned WebFace42M is the largest public face recognition training set and we expect to close the data gap between academia and industry. Referring to practical scenarios, Face Recognition Under Inference Time conStraint (FRUITS) protocol and a test set are constructed to comprehensively evaluate face matchers. Equipped with this benchmark, we delve into million-scale face recognition problems. A distributed framework is developed to train face recognition models efficiently without tampering with the performance. Empowered by WebFace42M, we reduce relative 40% failure rate on the challenging IJB-C set, and ranks the 3rd among 430 entries on NIST-FRVT. Even 10% data (WebFace4M) shows superior performance compared with public training set. Furthermore, comprehensive baselines are established on our rich-attribute test set under FRUITS-100ms/500ms/1000ms protocol, including MobileNet, EfficientNet, AttentionNet, ResNet, SENet, ResNeXt and RegNet families. Benchmark website is https://www.face-benchmark.org.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2103.04098", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/cvpr/ZhuHDY0CZYLD021", "doi": "10.1109/cvpr46437.2021.01035"}}, "content": {"source": {"pdf_hash": "cc3eb6f34b5815d73eafc63f24793147e2a48b98", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2103.04098v1.pdf\"]", "oa_url_match": true, "oa_info": {"license": null, "open_access_url": "http://arxiv.org/pdf/2103.04098", "status": "GREEN"}}, "grobid": {"id": "1cff71d31db04865a3c2aca29bbb0db57db8478b", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/cc3eb6f34b5815d73eafc63f24793147e2a48b98.txt", "contents": "\nWebFace260M: A Benchmark Unveiling the Power of Million-Scale Deep Face Recognition\n\n\nZheng Zhu \nTsinghua University\n\n\nGuan Huang \nJiankang Deng j.deng16@imperial.ac.uk \nImperial College London\n\n\nYun Ye \nJunjie Huang \nXinze Chen \nJiagang Zhu \nTian Yang \nJiwen Lu lujiwen@tsinghua.edu.cnguan.huang \nTsinghua University\n\n\nDalong Du dalong.du@xforwardai.com \nJie Zhou \nTsinghua University\n\n\nWebFace260M: A Benchmark Unveiling the Power of Million-Scale Deep Face Recognition\n\nIn this paper, we contribute a new million-scale face benchmark containing noisy 4M identities/260M faces (WebFace260M) and cleaned 2M identities/42M faces (WebFace42M) training data, as well as an elaborately designed time-constrained evaluation protocol. Firstly, we collect 4M name list and download 260M faces from the Internet. Then, a Cleaning Automatically utilizing Self-Training (CAST) pipeline is devised to purify the tremendous WebFace260M, which is efficient and scalable. To the best of our knowledge, the cleaned WebFace42M is the largest public face recognition training set and we expect to close the data gap between academia and industry. Referring to practical scenarios, Face Recognition Under Inference Time conStraint (FRUITS) protocol and a test set are constructed to comprehensively evaluate face matchers.Equipped with this benchmark, we delve into millionscale face recognition problems. A distributed framework is developed to train face recognition models efficiently without tampering with the performance. Empowered by Web-Face42M, we reduce relative 40% failure rate on the challenging IJB-C set, and ranks the 3rd among 430 entries on NIST-FRVT. Even 10% data (WebFace4M) shows superior performance compared with public training set. Furthermore, comprehensive baselines are established on our rich-attribute test set under FRUITS-100ms/500ms/1000ms protocol, including MobileNet, EfficientNet, AttentionNet, ResNet, SENet, ResNeXt and RegNet families. Benchmark website is https://www.face-benchmark.org.\n\nIntroduction\n\nRecognizing faces in the wild has achieved a remarkable success due to the boom of CNNs. The key engine of recent face recognition consists of network architecture evolution [31,58,52,23,28,53,22,86,24,76,56], a variety of loss functions [59, 47, 57, 54, 73, 14, 45, 67, 33, 32, 68, * These authors contributed equally to this work.  66,12,27], and growing face benchmarks [26,37,49,88,63,29,30,74,36,84,41,8,7,38,21,64]. Face benchmarks empower researchers to train and evaluate high-performance face recognition systems. Even though growing efforts have been devoted to investigating sophisticated networks [9,80,8,71,16] and losses [32,68,66,12,27,55,10], academia is restricted by limited training set and nearly saturated test protocols. As shown in Tab.1, the public largest training sets in terms of identities and faces are MegaFace2 [38] and MS1M [21], respectively. MegaFace2 contains 4.7M faces of 672K subjects collected from Flickr [62]. MS1M consists of 10M faces of 100K celebrities but the noise rate is around 50% [64]. In contrast, companies from industry can access much larger private data to train face recognition models: Google utilizes 200M images of 8M identities to train FaceNet [47], and Facebook [60] performs training by 500M faces of 10M identities. This data gap hinders researchers to push the frontiers of deep face recognition. Main obstacles for tremendous training data lie in large-scale identity collection, effective and scalable cleaning, and efficient training.\n\nOn the other hand, evaluation protocols and test set play an essential role in analysing face recognition performance. Popular evaluations for face recognition including LFW families [26,88,63], CFP [49], AgeDB [37], RFW [70], Dataset # Identities # Images Images/ID Cleaning # Attributes Availability Publications CASIA-WebFace [84] 10 K 0.5 M 47 Auto -Public Arxiv 2014 CelebFaces [57] 10 MegaFace [29], IJB families [30,74,36] mainly target the pursuit of the accuracy, which have been almost saturated recently. In real-world application scenarios, face recognition is always restricted by the inference time, such as unlocking mobile telephone with smooth experience. Lightweight face recognition challenge [13] takes a step toward this goal, but it neglects the time cost of detection and alignment. To the best of our knowledge, NIST-FRVT [2] is the only time-constrained face recognition protocol. However, strict submission policy (no more than one submission every four calendar months) hinders researchers to freely evaluate their algorithms. To address the above problems, this paper constructs a new large-scale face benchmark consists of 4M identities/260M faces (WebFace260M) as well as a timeconstrained assessment protocol. Firstly, a name list of 4M celebrities is collected and 260M images are downloaded utilizing a search engine. Then, we perform Cleaning Automatically by Self-Training (CAST) pipeline, which is scalable and does not need any human intervention. The proposed CAST procedure results in high-quality 2M identities and 42M faces (WebFace42M). With such data size, a distributed training framework is developed to perform efficient optimization. Referring to various real-world applications, we design the Face Recognition Under Inference Time conStraint (FRUITS) protocol, which enables academia to evaluate deep face matchers comprehensively. The FRUITS protocol consists of 3 tracks: 100, 500 and 1000 milliseconds. Since public evaluations are most saturated [26,37,49] and may contain noise [29,36], we manually construct a new test set with rich attributes to enable FRUITS, including different age, gender, race and scenario evaluations. This test set will be actively maintained and updated.\n\nBased on the proposed new large-scale benchmark, we delve into million-scale deep face recognition prob-lems. The distributed training approach could be performed at near linear acceleration without performance drops. Verification accuracy on public dataset indicates that the proposed million-scale training data is indispensable to push the frontiers of deep face recognition: Web-Face42M achieves 97.70% TAR@FAR=1e-4 on challenging IJB-C [36] under standard ResNet-100 configurations, relatively reducing near 40% error rate compared with public state-of-the-arts. 10% of our data (WebFace4M) also obtains superior performance than similar-sized MS1M families [14,12,1] and MegaFace2 [38]. Furthermore, we participate in the NIST-FRVT [2] and ranks the 3rd among 430 entries based on WebFace42M. Finally, comprehensive face recognition systems are evaluated under FRUITS-100ms/500ms/1000ms protocols, including MobileNet [24,9], EfficientNet [61], AttentionNet [65], ResNet [23], SENet [25], ResNeXt [78] and RegNet families [44]. With this new face benchmark, we hope to close the data gap between the research community and industry, and facilitate the time-constrained recognition performance assessment for real-world applications.\n\nThe main contributions can be summarized as follows:\n\n\u2022 A large-scale face recognition dataset is constructed for the research community towards closing the data gap behind the industry. The proposed WebFace260M consists of 4M identities and 260M faces, which provides an excellent resource for million-class deep face cleaning and recognition as shown in Fig.1  Face pre-processing. Faces are detected and aligned through five landmarks predicted by RetinaFace [11]. For multi-face images, we only select the largest face with the above-threshold score, which can filter most improper faces (e.g. background faces or wrong decoding). After pre-processing, there remains 4M identities/260M faces (WebFace260M) shown as Tab.1. The statistics of Web-Face260M are illustrated in Fig.2 including date of birth, nationality and profession. Persons in WebFace260M come from more than 200 distinct countries/regions and more than 500 different professions with the date of birth back to 1846, which guarantees a great diversity in our training data. Cleaned WebFace42M. We perform CAST pipeline (Sec.3) to automatically clean the noisy WebFace260M and obtain a cleaned training set named WebFace42M, consist-  ing of 42M faces of 2M subjects. Face number in each identity varies from 3 to more than 300, and the average face number is 21 per identity. As shown in Fig.1 and Tab.1, WebFace42M offers the largest cleaned training data for face recognition. Compared with the MegaFace2 [38] dataset, the proposed WebFace42M includes 3 times more identities (2M vs. 672K), and near 10 times more images (42M vs. 4.7M). Compared with the widely used MS1M [21], our training set is 20 times (2M vs. 100K) and 4 times (42M vs. 10M) more in terms of # identities and # photos. According to [64], there are more than 30% and 50% noises in MegaFace2 and MS1M, while noise ratio of WebFace42M is lower than 10% (similar to CASIA-WebFace [84]) based on our sampling estimation. With such a large data size, we take a significant step towards closing the data gap between academia and industry. Face attributes on WebFace42M. We further provide 7 face attribute annotations for WebFace42M, including pose, age, race, gender, hat, glass, and mask. Fig.3 presents the distribution of our cleaned training data in different aspects. WebFace42M covers a large range of poses ( Fig.3(a)), ages ( Fig.3(b)) and most major races in the world (Fig.3(c)).\n\n\nCleaning Automatically by Self-Training\n\nSince the images downloaded from the web are considerably noisy, it is necessary to perform a cleaning step to obtain high-quality training data. Original MS1M [21] does not perform any dataset cleaning, resulting in near 50% noise ratio, and significantly degrades the performance of the trained models. VGGFace [41], VGGFace2 [8] and IMDB-Face [64] adopt semi-automatic or manual cleaning pipelines, which require expensive labor efforts. It becomes challenging to scale up the current annotation size to even more identities. Although the purification in MegaFace2 [38] is automatic, its procedure is complicated and there are considerably more than 30 % noises [64]. Another relevant exploration is to cluster faces via unsupervised approaches [40,35,51] and supervised graph-based algorithm [85,82,81,20,72]. However, these methods assume the whole dataset is clean, which is not suitable for the extremely noisy WebFace260M.\n\nRecently, self-training [77,79,42,43], a standard approach in semi-supervised learning [48,83], is explored to significantly boost the performance of image classification.  Figure 4: The proposed Cleaning Automatically by Self-Training (CAST). Firstly, an initial teacher trained with MS1MV2 is utilized to clean Web-Face260M. Then a student model is trained on cleaned WebFace data. The CAST is performed by switching the student as the teacher until highquality 42M faces are obtained. Every intra-class and inter-class cleaning is conducted on initial WebFace260M utilizing different teacher model. Different from close-set ImageNet classification [46], directly generating pseudo labels on open-set face recognition is impractical. Considering this inherent limitation, we carefully design the pipeline of Cleaning Automatically by Self-Training (CAST). Our first insight is performing selftraining on open-set face recognition data, which is a scalable and efficient cleaning approach. Secondly, we find embedding feature matters in cleaning large-scale noisy face data.\n\nThe overall CAST framework is shown in Fig.4. Following the self-training pipeline, (1) a teacher model (ResNet-100 [23], ArcFace [12]) is trained with the public dataset (MS1MV2 [12]) to clean the original 260M images, which mainly consists of intra-class and inter-class cleaning.\n\n(2) A student model (also ResNet-100, ArcFace) is trained on cleaned images from (1). Since the data size is much larger, this student generalizes better than the teacher. (3) We iterate this process by switching the student as the teacher until high-quality 42M faces are obtained. It is worth noting that each intra and inter class cleaning is conducted on initial WebFace260M by different teacher model. Intra-class and inter-class cleaning. Since WebFace260M contains various noises such as outliers in a folder and identity overlaps between folders, it is impractical to perform unsupervised or supervised clustering on the whole dataset. Based on the observation that the image search results from Google are sorted by relevance and there is always a dominant subject in each search, the initial folder structure provides strong priors to guide the cleaning strategy: one folder contains a dominant subject and different folders may contain considerable overlapped identities.\n\nFollowing these priors, we perform dataset cleaning by a two-step procedure: Firstly, face clustering is parallelly conducted in 4M folders (subjects) to select each dominant identity. Specifically, for each face in a folder, 512dimensional embedding feature is extracted by the teacher model, and then DBSCAN [15] is utilized to cluster faces in this folder. Only largest cluster (more than 2 faces) in each fold is reserved. We also investigate other different designs of intra-class cleaning including GCN-D [82] and GCN-V [81] in Sec.5.4. Secondly, we compute the feature   center of each subject to perform inter-class cleaning. Two folders are merged if their cosine similarity is higher than 0.7, and the folder containing fewer faces would be deleted when the cosine similarity is between 0.5 and 0.7. The effectiveness of the above intra-class and inter-class cleaning heavily depends on the quality of the embedding feature, which is guaranteed by the proposed self-training pipeline. The ArcFace model trained on MS1MV2 with ResNet-100 provides a good initial embedding feature to perform first round cleaning for WebFace260M. Then, this feature is significantly enhanced with more training data in later iterations. Fig.5 illustrates the score distribution during different stages of CAST, which indicates cleaner training set after more iterations. Furthermore, ablation study in Tab.7 also validates the effectiveness of CAST pipeline. It is worth noting that the proposed CAST pipeline is compatible with any intra-class and inter-class strategies. Remove duplicates and test set overlaps. After CAST, duplicates of each subject are removed when their cosine similarity is higher than 0.95. Furthermore, the feature center of each subject is compared with popular benchmarks (e.g. LFW families [26,88,63], FaceScrub [39], IJB-C [36] etc.) and the proposed test set in Sec.4.2, and overlaps are removed if the cosine similarity is higher than 0.7. \n\n\nFRUITS Protocol\n\n\nEvaluation Protocol\n\nPopular evaluation protocols for face recognition mainly target the pursuit of accuracy. For example, CFP [49], AgeDB [37], CALFW [88] and CPLFW [63] evaluate the verification accuracy under different intra-class variations (e.g. pose and age). MegaFace [29] and IJB-C [36] serve for both accuracy of large-scale face verification and identification. YTF [75] and IQIYI-Video [34] compare the accuracy of video-based verification. Different model ensemble and post-processing [50] could be adopted for higher performance under these protocols. However, face recognition in real-world application scenarios is always restricted by inference time.\n\nRecently, lightweight face recognition challenge [13] takes a step toward this goal by constraining the FLOPs and model size of submissions. Since different neural network architectures can be quite different in terms of real inference times, this protocol is not a straightforward solution. Furthermore, it does not consider face detection and alignment, which are prerequisite components in most modern face recognition systems. To the best of our knowledge, NIST-FRVT [2] is the only benchmark employing the timeconstrained protocol. However, strict submission policy (participants can only send one submission every four calendar months) hinders researchers to freely evaluate their algorithms.\n\nIn this paper, we design the Face Recognition Under Inference Time conStraint (FRUITS) protocol, which enables academia to comprehensively evaluate their face matchers. Referring to [2], inference time is measured on a single core of an Intel Xeon CPU E5-2630-v4@2.20GHz processor. Considering different application scenarios, FRUITS protocol sets a series of tracks: FRUITS-100: The whole face recognition system must distinguish image pairs within 100 milliseconds, including preprocessing (e.g. face detection and alignment), feature embedding for recognition, and matching. FRUITS-100 track targets on evaluating lightweight face recognition system which can be deployed on mobile devices. FRUITS-500: This track follows FRUITS-100 setting, except that time constraint is increased to 500 milliseconds. This track aims to evaluate modern and popular networks deployed in the local surveillance system. FRUITS-1000: Following NIST-FRVT, FRUITS-1000 adopts time constraint of 1000 milliseconds and aims to compare capable recognition models performed on clouds.  \n\n\nTest Set\n\nSince public evaluations are most saturated and may contain noise, we manually construct an elaborated test set for FRUITS. It is well known that recognizing strangers, especially when they are similar-looking, is a difficult task even for experienced vision researchers. Therefore, our multi-ethnic annotators only select their familiar celebrities, which ensure the high-quality of the test set. Besides, annotators are encouraged to gather attribute-balanced faces, and recognition models are introduced to guide hard sample collection. The statistics of the final test set are listed in Tab.3. In total, there are 38,578 faces of 2,225 identities. Rich attributes (e.g. age, race, gender, controlled or wild) are accurately annotated. In the future, we will actively maintain and update this test set.\n\n\nMetrics\n\nBased on the proposed FRUITS protocol and test set, we perform 1:1 face verification across various attributes. Tab.3 shows numbers of imposter and genuine in different verification settings. All means impostors are paired without attention to any attribute, while later comparisons are conducted on age, race, gender and scenario subsets. Cross-age refers to cross-age (more than 10 and 20 years) verification, while Cross-scene means pairs are compared between controlled and wild settings. Different algorithms are measured on False Non-Match Rate (FNMR) [2], which is defined as the proportion of mated comparisons below a threshold set to achieve the False Match Rate (FMR) specified. FMR is the proportion of impostor comparisons at or above that threshold. Lower FNMR at the same FMR is better.\n\n\nExperiments of Million-level Recognition\n\n\nImplementation Details\n\nIn order to fairly evaluate the performance of different face recognition models, we reproduce representative algorithms (i.e. CosFace [68], ArcFace [12] and CurricularFace [27]) in one Gluon codebase with the hyper-parameters referred to the original papers. Default batch size per GPU is set as 64 unless otherwise indicated. Learning rate is set as 0.05 for a single node (8 GPUs), and follows the linear scaling rule [19] for the training on multiple nodes (i.e. 0.05\u00d7# machines). We decrease the learning rate by 0.1\u00d7 at 8, 12, and 16 epochs, and stop at 20 epochs for all models. During training, we only adopt the flip data augmentation.\n\n\nDistributed Training\n\nWhen using the large-scale WebFace42M as the training data and computationally demanding backbones as the embedding networks, the model training can take several weeks on one machine. Such a long training time makes it difficult to efficiently perform experiments. Inspired by the distributed optimization on ImageNet [19], we apportion the workload of model training to clusters. To this end, parallel on both feature X and center W , mixed-precision (FP16) and large-batch training are adopted in this paper.\n\nSpeed and performance of our distributed training system are illustrated in Tab.4 and Fig.6. Parallelization on both feature X and center W as well as mixed-precision (FP16) significantly reduce the consumption of GPU memory and speed up the training process, while similar performance can be achieved. Equipped with 8 nodes (64 GPUs), the training speed is scaled to 12K samples/s and 11K samples/s on WebFace4M (10% data) and WebFace12M (30% data), respectively. The corresponding training time is only 2 hours and 6 hours. Furthermore, the scaling efficiency of our training system is above 80% when applied to largescale WebFace42M on 32 nodes (256 GPUs). Therefore, we can reduce the training time of the ResNet-100 model from 233 hours (1 node) to 9 hours (32 nodes) with comparable performance.  Table 4: Speed and performance comparison of distributed training. Arc-Face using ResNet-100 is adopted. B, G and M refer to batch size per GPU, # GPUs per machine, and # machines. X and W mean feature and center, and numbers in bracket are the GPU memory usage (MB). Performance is reported on IJB-C (TAR@FAR=1e-4).\n\n\nComparisons of Training Data\n\nFor comprehensively analysing the influence of training data, the proposed WebFace42M is compared with public counterparts including MS1M families [21,14,12, 1], MegaFace2 [38] and IMDB-Face [64]. 10% (WebFace4M) and 30% (WebFace12M) random selection of our full data are also employed for further analysing of the training data. The statistics of different training sets are illustrated in Tab.1. Evaluation sets used in this experiment include popular verification sets (e.g. LFW [26], CFP-FP [49], CPLFW [63], AgeDB [37] and CALFW [88]), RFW [70], MegaFace [38], IJB-C [36] and our test set. As we can see from Tab.5 and Fig.7, the proposed Web-Face42M breaks the bottleneck of training data for deep face recognition across various loss functions and test sets. Specifically, WebFace42M reduces relative 40% error rate on the challenging IJB-C dataset compared with MS1MV2, boosting TAR from 96.03% to 97.70% @10-4 FAR. Along with the increment of data scale (i.e. 10%, 30%, and 100%), there exists a consistent improvement in performance as observed in Fig.7. On our test set, the relative promotion is near 70% when trained on WebFace42M. Impressively, the models trained on 10% data, WebFace4M, achieve superior performance compared to models trained on MS1M families and MegaFace2, which include even more # faces. Undisputedly, the training data comparison confirms the effectiveness and necessity of our WebFace42M in levelling playing field for million-scale face recognition.\n\nBesides reporting the results of ResNet-100, we also train ArcFace models by using a smaller network, ResNet-14, on different portions of our data (i.e. 10%, 30% and 100%). As given in Tab.6, there is also a consistent performance gain for ResNet-14 when more training data are progressively employed. Therefore, the proposed Web-Face42M is not only beneficial to the large model (e.g. ResNet-100) but also valuable for the lightweight model.\n\n\nComparisons of Data Cleaning\n\nAs shown in Tab.7, the CAST pipeline is compared with other cleaning strategies on the original MS1M [21] and WebFace260M. Specifically, for MS1M results, the initial teacher model is trained on IMDB-Face [64] by using ResNet-100 and ArcFace. Then, CAST is conducted on the noisy MS1M following Sec.3. After steps of iteration, our fully automatic cleaning strategy provides purified data for model training, outperforming semi-automatic methods   [26,49,37,88,63], RFW refers to average accuracy on [70], Mega refers to rank-1 identification on [29], IJB-C is TAR@FAR=1e-4 on [36]. Last column is FNMR@FMR=1e-5 on All pairs comparison of our test set.   used in [14,12,1]. Compared with the most recent GCNbased cleaning [87], the data cleaned by the CAST also achieves higher performance. Iterations of CAST. Tab.7 also shows the increasing data purity after more iterations in MS1M and WebFace260M. The accuracy gradually increases from 1st to 3rd iteration, while 4th iteration shows saturated performance. Therefore, we set the iteration number as 3 for CAST. Intra-class Cleaning. In this experiment, we compare different intra-class cleaning methods under the framework of CAST. Both unsupervised methods (e.g. K-means [35] and   DBSCAN [15]) and supervised methods (e.g. GCN-D [82] and GCN-V [81]) are explored to find the dominant subject in each noisy folder. As shown in Tab.8, DBSCAN achieves 96.55% TAR@FAR=1e-4 on IJB-C, significantly outperforming K-Means (96.03%) and slightly surpassing the supervised GCN-based strategies (96.48% for GCN-D and 96.42% for GCN-V). As the GCN-based strategies can be sub-optimal for the extremely noisy folders, we finally select DBSCAN [15] as our intra-class cleaning method.\n\n\nBaselines under FRUITS Protocols\n\nIn this section, we set up a series of baselines under the proposed FRUITS protocols. In Tab.9, we illustrate different face recognition systems (including different module settings of face detection, alignment, feature embedding) and their inference time. In our baselines, representative network architectures are explored, covering MobileNet [24,9], EfficientNet [61], AttentionNet [65], ResNet [23], SENet [25], ResNeXt [78] and RegNet [44] families. All the models are trained on WebFace42M with ArcFace.\n\nDue to strict time limitation, models constrained by FRUITS-100 can only adopt lightweight architectures, including RetinaFace-MobileNet-0.25 [11] for face detection and alignment, ResNet-14, MobileFaceNet (Flip), EfficientNet-B0 and RegNet-800MF for face feature extraction. FNMR on All pairs and analysis of attribute bias are shown in Fig.8(a) and Fig.8(b). Because of the weak detection and recognition modules, the best baseline (RegNet-800MF) only obtains 5.88% FNMR@FMR=1e-5 (lower is better). Therefore, there leaves a substantial room for future improvement under the FRUITS-100 protocol.  For the FRUITS-500 protocol, we can employ more capable modern networks, such as RetinaFace-ResNet-50 [11] for pre-processing, and ResNet-100, ResNet-50 (Flip), SENet-50, ResNeXt-100, RegNet-8GF for feature embedding. As shown in Fig.8(c) and Fig.8(d), ResNet-100 exhibits best overall performance in unbiased face verification. ResNet-50 with flip testing achieves lowest FNMR according to the attribute indicators of Wild and Male, while ResNeXt ranks first in the Cross-scene track.\n\nRecognition models under the FRUITS-1000 protocol can be more complicated and powerful, therefore we explore ResNet-100 (Flip), ResNet-200, SENet-152, AttentionNet-152 and RegNet-16GF for face feature embedding. As shown in Fig.8(e) and Fig.8(f), ResNet-200 performs best in face verification and wins five attribute comparisons, while SENet-152 and AttentionNet-152 achieve three and two first-place respectively, according to the attribute indicator. Compared with lightweight FRUITS-100 track, performance of different large models are much closer. This result implies that new designs need to be explored for heavyweight FRUITS track.\n\n\nResults on NIST-FRVT\n\nFinally, we report the submission to the NIST-FRVT. Following the settings of FRUITS-1000, our system is built based on RetinaFace-ResNet-50 for detection and alignment, and ArcFace-ResNet-200 trained on WebFace42M for feature embedding. The inference is accelerated by OpenVINO [6] and the flip test is adopted. The final inference time is near 1300 milliseconds according to the NIST-FRVT report, meeting the latest 1500 milliseconds limitation. Tab.10 illustrates top-ranking entries measured by FNMR across five tracks. Our model trained on the WebFace42M achieves overall 3rd among 430 submissions, showing impressive performance across different tracks. Considering hundreds of company entries to NIST-FRVT,   the WebFace42M takes a significant step towards closing the data gap between academia and industry.\n\n\nDiscussion and Conclusion\n\nDiscussion WebFace260M may exist bias in different attributes, which has been considered in some aspects. First, our initial name list is constructed from Freebase and IMDB, which contains great diversity. Second, the bias is also considered in the test set construction, metrics and baselines results . In the test set construction, our multi-ethnic annotators are encouraged to gather attribute-balanced faces. In experiments, we evaluate models over these attributes (e.g. race, gender and age) and show the relative ranks. For real-world applications, existing of bias may cause performance drop over certain attributes. Considering the extremely large faces in our WebFace260M, we can sample balanced data to train models with less bias. Besides, recent de-bias face recognition researches [70,69,18,17] may also alleviate this problem to some extent. For the ethics of gathering dataset, detailed rules are listed in our website. In summary, we will provide strict access for applicants who sign license, and try our best to guarantee it for research purposes only.\n\nConclusion In this paper, we dive into million-scale face recognition, contributing a high-quality training data with 42M images of 2M identities by using automatic cleaning, a test set containing rich attributes, a time-constrained evaluation protocol, a distributed framework at linear acceleration, a succession of baselines, and a final SOTA model. Equipped with this face benchmark, our model significantly reduces 40% failure rate on the IJB-C dataset and ranks the 3rd among 430 entries on NIST-FRVT. We hope this benchmark could facilitate future research of large-scale face recognition.\n\nFigure 1 :\n1Comparisons of # identities and # faces for our WebFace data and public training set.\n\nFigure 3 :\n3Pose (yaw), age and race of WebFace42M.\n\nFigure 5 :\n5Inter and intra class similarity distributions\n\n\nDataset statistics. The statistics of # identities and # images during different stages are shown in Tab.2. After face pre-processing for downloaded images, there are 4,008,130 identities and 260,890,076 faces (WebFace260M). The face set becomes cleaner under more CAST iterations, which results in fewer identities and faces. Finally, we obtain 2,059,906 identities and 42,474,558 faces (WebFace42M) after removing duplicates and test set overlaps.\n\nFigure 6 :\n6Speed and performance of our distributed training system. The proposed system can almost linearly accelerate the training with comparable performance. 100% data (WebFace42M) is used in these experiments.\n\nFigure 7 :\n7Performance of ArcFace models (ResNet-100) trained on the WebFace envelopes counterparts trained on the public training data.\n\nFigure 8 :\n8Comprehensive performance comparisons of different models under the proposed FRUITS protocols. Left part is the FMR-FNMR plot for All pairs verification, and models are ranked in legend according to FNMR@FMR=1e-5 (lower FNMR is better). The right part shows the attribute plots under FNMR@FMR=1e-5, which is normalized to 0.5-1.0 for better visualization (outer is better).\n\n\nTable 1: Training data for deep face recognition. The cleaned WebFace42M is the largest public training set in terms of both # identities and # images.K \n0.2 M \n20 \nManual \n40 \nPublic \nICCV 2015 \nUMDFaces [7] \n8 K \n0.3 M \n45 \nSemi-auto \n4 \nPublic \nIJCB 2017 \nVGGFace [41] \n2 K \n2.6 M \n1,000 \nSemi-auto \n-\nPublic \nBMVC 2015 \nVGGFace2 [8] \n9 K \n3.3 M \n363 \nSemi-auto \n11 \nPublic \nFG 2018 \nMS1M [21] \n0.1 M \n10 M \n100 \nNo \n-\nPublic \nECCV 2016 \nMS1M-IBUG [14] \n85 K \n3.8 M \n45 \nSemi-auto \n-\nPublic \nCVPRW 2017 \nMS1MV2 [12] \n85 K \n5.8 M \n68 \nSemi-auto \n-\nPublic \nCVPR 2019 \nMS1M-Glint [1] \n87 K \n3.9 M \n44 \nSemi-auto \n-\nPublic \n-\nMegaFace2 [38] \n0.6 M \n4.7 M \n7 \nAuto \n-\nPublic \nCVPR 2017 \nIMDB-Face [64] \n59 K \n1.7 M \n29 \nManual \n-\nPublic \nECCV 2018 \nFacebook [59] \n4 K \n4.4 M \n1,100 \n-\n-\nPrivate \nCVPR 2014 \nFacebook [60] \n10 M \n500 M \n50 \n-\n-\nPrivate \nCVPR 2015 \nGoogle [47] \n8 M \n200 M \n25 \n-\n-\nPrivate \nCVPR 2015 \nMillionCelebs [87] \n0.6 M \n18.8 M \n30 \nAuto \n-\nPrivate \nCVPR 2020 \nWebFace260M \n4 M \n260M \n65 \nNo \n-\nPublic \n-\nWebFace42M \n2 M \n42M \n21 \nAuto \n7 \nPublic \n-\n\n\n\n\nduring different stages. Since initial folders are very noisy, score distributions are severely overlapped. Cleaner training set is obtained after more iterations. 100K folders are randomly selected here for showing the statistic changes during iterations.Stages \n# Identities \n# Faces \nCollect name list and images \n4,073,509 265,777,598 \nFace pre-processing \n4,008,130 260,890,076 \n\nFirst iteration \nIntra-class 3,341,761 \n61,792,387 \nInter-class 2,437,140 \n50,672,354 \n\nSecond iteration \nIntra-class 3,027,814 \n60,274,892 \nInter-class 2,176,427 \n47,352,741 \n\nThird iteration \nIntra-class 2,878,886 \n58,155,345 \nInter-class 2,070,870 \n46,220,417 \nRemove duplicates \n2,070,870 \n43,977,802 \nRemove test set overlaps \n2,059,906 \n42,474,558 \n\n\n\nTable 2 :\n2The # identities and # images statistics during different stages.\n\nTable 3 :\n3The statistics of our test set. -means corresponding statistics or comparisons are omitted.\n\nTable 5 :\n5Performance (%) of different training data. ResNet-100 backbone without flip test is adopted. Pairs refers to average accuracy on\n\nTable 6 :\n6Performance of ArcFace models trained with ResNet-14 on dif-\nferent portions of WebFace42M. TAR@FAR=1e-4 on IJB-C is reported. \n\n\n\nTable 7 :\n7Comparisons of CAST and other data cleaning pipelines. ResNet-\n100 using the ArcFace loss is adopted here. For our WebFace, different \niterations are compared. CAST-1 means the first-round iteration. \n\nData \n# Id # Face Pairs MegaFace IJB-C \nK-Means 93K 5.2M 95.17 \n97.31 \n96.03 \nDBSCAN 91K 4.9M 97.42 \n98.61 \n96.55 \nGCN-D \n86K 4.4M 96.56 \n98.55 \n96.48 \nGCN-V \n82K 4.5M 96.93 \n98.29 \n96.42 \n\n\n\nTable 8 :\n8Comparisons of different intra-class cleaning methods for MS1M. ResNet-100 using the ArcFace loss is adopted here.\n\nTable 9 :\n9Settings and inference time of baselines. Loose cropped test images are resized to 224 \u00d7 224 for joint detection and alignment. M-0.25 and R-50 refer to RetinaFace using MobileNet-0.25 (23ms) and ResNet-50 (272ms) as the backbones. FLOPs and Params mean computational complexity and parameter number of recognition module, respectively. Time refers to the duration of the whole system.\n\nTable 10 :\n10Results on NIST-FRVT. Our Arcface model using ResNet-200 is trained on WebFace42M. FNMR at corresponding FMR is reported.\n\nUMDFaces: An annotated face dataset for training deep networks. Ankan Bansal, Anirudh Nanduri, D Carlos, Rajeev Castillo, Rama Ranjan, Chellappa, arXiv:1611.01484v21Ankan Bansal, Anirudh Nanduri, Carlos D Castillo, Rajeev Ranjan, and Rama Chellappa. UMDFaces: An annotated face dataset for training deep networks. arXiv:1611.01484v2, 2016. 1, 2\n\nVGGFace2: A dataset for recognising faces across pose and age. Qiong Cao, Li Shen, Weidi Xie, M Omkar, Andrew Parkhi, Zisserman, FG. 13Qiong Cao, Li Shen, Weidi Xie, Omkar M Parkhi, and An- drew Zisserman. VGGFace2: A dataset for recognising faces across pose and age. In FG, 2018. 1, 2, 3\n\nMobile-Facenets: Efficient CNNs for accurate real-time face verification on mobile devices. Sheng Chen, Yang Liu, Xiang Gao, Zhen Han, CCBR. Sheng Chen, Yang Liu, Xiang Gao, and Zhen Han. Mobile- Facenets: Efficient CNNs for accurate real-time face verifi- cation on mobile devices. In CCBR, 2018. 1, 2, 7\n\nSub-center arcface: Boosting face recognition by large-scale noisy web faces. Jiankang Deng, Jia Guo, Tongliang Liu, ECCV. 2020Mingming Gong, and Stefanos ZafeiriouJiankang Deng, Jia Guo, Tongliang Liu, Mingming Gong, and Stefanos Zafeiriou. Sub-center arcface: Boosting face recognition by large-scale noisy web faces. In ECCV, 2020. 1\n\nRetinaface: Single-shot multi-level face localisation in the wild. Jiankang Deng, Jia Guo, Evangelos Ververas, Irene Kotsia, Stefanos Zafeiriou, CVPR, 2020. 3. 7Jiankang Deng, Jia Guo, Evangelos Ververas, Irene Kotsia, and Stefanos Zafeiriou. Retinaface: Single-shot multi-level face localisation in the wild. In CVPR, 2020. 3, 7, 8\n\nArcface: Additive angular margin loss for deep face recognition. Jiankang Deng, Jia Guo, Stefanos Zafeiriou, CVPR. 67Jiankang Deng, Jia Guo, and Stefanos Zafeiriou. Arcface: Additive angular margin loss for deep face recognition. In CVPR, 2019. 1, 2, 4, 5, 6, 7\n\nLightweight face recognition challenge. Jiankang Deng, Jia Guo, Debing Zhang, Yafeng Deng, Xiangju Lu, Song Shi, ICCV Workshop. 25Jiankang Deng, Jia Guo, Debing Zhang, Yafeng Deng, Xi- angju Lu, and Song Shi. Lightweight face recognition chal- lenge. In ICCV Workshop, 2019. 2, 5\n\nMarginal loss for deep face recognition. Jiankang Deng, Yuxiang Zhou, Stefanos Zafeiriou, CVPR Workshop. 7Jiankang Deng, Yuxiang Zhou, and Stefanos Zafeiriou. Marginal loss for deep face recognition. In CVPR Workshop, 2017. 1, 2, 6, 7\n\nA density-based algorithm for discovering clusters in large spatial databases with noise. Martin Ester, Hans-Peter Kriegel, J\u00f6rg Sander, Xiaowei Xu, KDD. 47Martin Ester, Hans-Peter Kriegel, J\u00f6rg Sander, Xiaowei Xu, et al. A density-based algorithm for discovering clusters in large spatial databases with noise. In KDD, 1996. 4, 7\n\nGenerate to adapt: Resolution adaption network for surveillance face recognition. Han Fang, Weihong Deng, Yaoyao Zhong, Jiani Hu, ECCV. 2020Han Fang, Weihong Deng, Yaoyao Zhong, and Jiani Hu. Generate to adapt: Resolution adaption network for surveil- lance face recognition. In ECCV, 2020. 1\n\nJointly debiasing face recognition and demographic attribute estimation. Sixue Gong, Xiaoming Liu, Jain, ECCV. 2020Sixue Gong, Xiaoming Liu, and Anil K Jain. Jointly de- biasing face recognition and demographic attribute estima- tion. In ECCV, 2020. 9\n\nSixue Gong, Xiaoming Liu, Jain, arXiv:2006.07576Mitigating face recognition bias via group adaptive classifier. arXiv preprintSixue Gong, Xiaoming Liu, and Anil K Jain. Mitigating face recognition bias via group adaptive classifier. arXiv preprint arXiv:2006.07576, 2020. 9\n\nPriya Goyal, Piotr Doll\u00e1r, Ross Girshick, Pieter Noordhuis, Lukasz Wesolowski, Aapo Kyrola, Andrew Tulloch, arXiv:1706.02677Yangqing Jia, and Kaiming He. Accurate, large minibatch SGD: Training imagenet in 1 hour. Priya Goyal, Piotr Doll\u00e1r, Ross Girshick, Pieter Noord- huis, Lukasz Wesolowski, Aapo Kyrola, Andrew Tulloch, Yangqing Jia, and Kaiming He. Accurate, large minibatch SGD: Training imagenet in 1 hour. arXiv:1706.02677, 2017. 6\n\nDensity-aware feature embedding for face clustering. Senhui Guo, Jing Xu, Dapeng Chen, Chao Zhang, Xiaogang Wang, Rui Zhao, CVPR. 2020Senhui Guo, Jing Xu, Dapeng Chen, Chao Zhang, Xiaogang Wang, and Rui Zhao. Density-aware feature embedding for face clustering. In CVPR, 2020. 3\n\nMS-Celeb-1M: A dataset and benchmark for large-scale face recognition. Yandong Guo, Lei Zhang, Yuxiao Hu, Xiaodong He, Jianfeng Gao, ECCV. 6Yandong Guo, Lei Zhang, Yuxiao Hu, Xiaodong He, and Jianfeng Gao. MS-Celeb-1M: A dataset and benchmark for large-scale face recognition. In ECCV, 2016. 1, 2, 3, 6\n\nDelving deep into rectifiers: Surpassing human-level performance on ImageNet classification. Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, ICCV. Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Delving deep into rectifiers: Surpassing human-level perfor- mance on ImageNet classification. In ICCV, 2015. 1\n\nDeep residual learning for image recognition. Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, CVPR. Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In CVPR, 2016. 1, 2, 4, 7\n\nMobilenets: Efficient convolutional neural networks for mobile vision applications. G Andrew, Menglong Howard, Bo Zhu, Dmitry Chen, Weijun Kalenichenko, Tobias Wang, Marco Weyand, Hartwig Andreetto, Adam, arXiv:1704.04861Andrew G Howard, Menglong Zhu, Bo Chen, Dmitry Kalenichenko, Weijun Wang, Tobias Weyand, Marco An- dreetto, and Hartwig Adam. Mobilenets: Efficient con- volutional neural networks for mobile vision applications. arXiv:1704.04861, 2017. 1, 2, 7\n\nSqueeze-and-excitation networks. Jie Hu, Li Shen, Gang Sun, CVPR. 27Jie Hu, Li Shen, and Gang Sun. Squeeze-and-excitation net- works. In CVPR, 2018. 2, 7\n\nLabeled faces in the wild: A database for studying face recognition in unconstrained environments. B Gary, Manu Huang, Tamara Ramesh, Erik Berg, Learned-Miller, 67Technical reportGary B Huang, Manu Ramesh, Tamara Berg, and Erik Learned-Miller. Labeled faces in the wild: A database for studying face recognition in unconstrained environments. Technical report, 2007. 1, 2, 4, 6, 7\n\nCurricularface: adaptive curriculum learning loss for deep face recognition. Yuge Huang, Yuhan Wang, Ying Tai, Xiaoming Liu, Pengcheng Shen, Shaoxin Li, Jilin Li, Feiyue Huang, CVPR. 15Yuge Huang, Yuhan Wang, Ying Tai, Xiaoming Liu, Pengcheng Shen, Shaoxin Li, Jilin Li, and Feiyue Huang. Curricularface: adaptive curriculum learning loss for deep face recognition. In CVPR, 2020. 1, 5\n\nBatch normalization: Accelerating deep network training by reducing internal covariate shift. Sergey Ioffe, Christian Szegedy, ICML. Sergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by reducing internal co- variate shift. In ICML, 2015. 1\n\nThe MegaFace benchmark: 1 million faces for recognition at scale. Ira Kemelmacher-Shlizerman, M Steven, Daniel Seitz, Evan Miller, Brossard, CVPR. 7Ira Kemelmacher-Shlizerman, Steven M Seitz, Daniel Miller, and Evan Brossard. The MegaFace benchmark: 1 million faces for recognition at scale. In CVPR, 2016. 1, 2, 5, 7\n\nPushing the frontiers of unconstrained face detection and recognition: IARPA Janus Benchmark A. Ben Brendan F Klare, Emma Klein, Austin Taborsky, Jordan Blanton, Kristen Cheney, Patrick Allen, Alan Grother, Mah, Jain, CVPR. 1Brendan F Klare, Ben Klein, Emma Taborsky, Austin Blan- ton, Jordan Cheney, Kristen Allen, Patrick Grother, Alan Mah, and Anil K Jain. Pushing the frontiers of unconstrained face detection and recognition: IARPA Janus Benchmark A. In CVPR, 2015. 1, 2\n\nImageNet classification with deep convolutional neural networks. Alex Krizhevsky, Ilya Sutskever, Geoffrey E Hinton, NeruIPS. Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. ImageNet classification with deep convolutional neural net- works. In NeruIPS, 2012. 1\n\nSphereface: Deep hypersphere embedding for face recognition. Weiyang Liu, Yandong Wen, Zhiding Yu, Ming Li, Bhiksha Raj, Le Song, CVPR. Weiyang Liu, Yandong Wen, Zhiding Yu, Ming Li, Bhiksha Raj, and Le Song. Sphereface: Deep hypersphere embedding for face recognition. In CVPR, 2017. 1\n\nLarge-margin softmax loss for convolutional neural networks. Weiyang Liu, Yandong Wen, Zhiding Yu, Meng Yang, ICML. Weiyang Liu, Yandong Wen, Zhiding Yu, and Meng Yang. Large-margin softmax loss for convolutional neural net- works. In ICML, 2016. 1\n\nYuanliu Liu, Peipei Shi, Bo Peng, He Yan, Yong Zhou, Bing Han, Yi Zheng, Chao Lin, arXiv:1811.07548Jianbin Jiang, and Yin Fan. IQIYI-VID: A large dataset for multi-modal person identification. Yuanliu Liu, Peipei Shi, Bo Peng, He Yan, Yong Zhou, Bing Han, Yi Zheng, Chao Lin, Jianbin Jiang, and Yin Fan. IQIYI- VID: A large dataset for multi-modal person identification. arXiv:1811.07548, 2018. 5\n\nLeast squares quantization in PCM. TIT. Stuart Lloyd, 37Stuart Lloyd. Least squares quantization in PCM. TIT, 1982. 3, 7\n\nIARPA Janus Benchmark C: Face dataset and protocol. Brianna Maze, Jocelyn Adams, A James, Nathan Duncan, Tim Kalka, Charles Miller, Otto, K Anil, Jain, Janet Tyler Niggel, Jordan Anderson, Cheney, ICB. 67Brianna Maze, Jocelyn Adams, James A Duncan, Nathan Kalka, Tim Miller, Charles Otto, Anil K Jain, W Tyler Niggel, Janet Anderson, and Jordan Cheney. IARPA Janus Benchmark C: Face dataset and protocol. In ICB, 2018. 1, 2, 4, 5, 6, 7\n\nAgeDB: The first manually collected in-the-wild age database. Stylianos Moschoglou, Athanasios Papaioannou, Christos Sagonas, Jiankang Deng, Irene Kotsia, Stefanos Zafeiriou, CVPR Workshop. 67Stylianos Moschoglou, Athanasios Papaioannou, Chris- tos Sagonas, Jiankang Deng, Irene Kotsia, and Stefanos Zafeiriou. AgeDB: The first manually collected in-the-wild age database. In CVPR Workshop, 2017. 1, 2, 5, 6, 7\n\nLevel playing field for million scale face recognition. Aaron Nech, Ira Kemelmacher-Shlizerman, CVPR. 6Aaron Nech and Ira Kemelmacher-Shlizerman. Level play- ing field for million scale face recognition. In CVPR, 2017. 1, 2, 3, 6\n\nA data-driven approach to cleaning large face datasets. Hong-Wei Ng, Stefan Winkler, ICIP. Hong-Wei Ng and Stefan Winkler. A data-driven approach to cleaning large face datasets. In ICIP, 2014. 4\n\nClustering millions of faces by identity. Charles Otto, Dayong Wang, Jain, Charles Otto, Dayong Wang, and Anil K Jain. Clustering millions of faces by identity. TPAMI, 2017. 3\n\nDeep face recognition. M Omkar, Andrea Parkhi, Andrew Vedaldi, Zisserman, BMVC. 13Omkar M Parkhi, Andrea Vedaldi, and Andrew Zisserman. Deep face recognition. In BMVC, 2015. 1, 2, 3\n\nLessons from building acoustic models with a million hours of speech. Nikko Sree Hari Krishnan Parthasarathi, Strom, ICASSP. Sree Hari Krishnan Parthasarathi and Nikko Strom. Lessons from building acoustic models with a million hours of speech. In ICASSP, 2019. 3\n\nData distillation: Towards omnisupervised learning. Ilija Radosavovic, Piotr Doll\u00e1r, Ross Girshick, Georgia Gkioxari, Kaiming He, CVPR. Ilija Radosavovic, Piotr Doll\u00e1r, Ross Girshick, Georgia Gkioxari, and Kaiming He. Data distillation: Towards omni- supervised learning. In CVPR, 2018. 3\n\nKaiming He, and Piotr Doll\u00e1r. Designing network design spaces. Ilija Radosavovic, Raj Prateek Kosaraju, Ross Girshick, CVPR, 2020. 27Ilija Radosavovic, Raj Prateek Kosaraju, Ross Girshick, Kaiming He, and Piotr Doll\u00e1r. Designing network design spaces. In CVPR, 2020. 2, 7\n\nCrystal loss and quality pooling for unconstrained face verification and recognition. Rajeev Ranjan, Ankan Bansal, Hongyu Xu, Swami Sankaranarayanan, Jun-Cheng Chen, Carlos D Castillo, Rama Chellappa, arXiv:1804.01159Rajeev Ranjan, Ankan Bansal, Hongyu Xu, Swami Sankaranarayanan, Jun-Cheng Chen, Carlos D Castillo, and Rama Chellappa. Crystal loss and quality pool- ing for unconstrained face verification and recognition. arXiv:1804.01159, 2018. 1\n\nImagenet large scale visual recognition challenge. Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, IJCV. Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, San- jeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et al. Imagenet large scale visual recognition challenge. In IJCV, 2015. 4\n\nFacenet: A unified embedding for face recognition and clustering. Florian Schroff, Dmitry Kalenichenko, James Philbin, CVPR. 1Florian Schroff, Dmitry Kalenichenko, and James Philbin. Facenet: A unified embedding for face recognition and clus- tering. In CVPR, 2015. 1, 2\n\nProbability of error of some adaptive patternrecognition machines. TIT. H Scudder, H Scudder. Probability of error of some adaptive pattern- recognition machines. TIT, 1965. 3\n\nFrontal to profile face verification in the wild. Soumyadip Sengupta, Jun-Cheng Chen, Carlos Castillo, M Vishal, Rama Patel, David W Chellappa, Jacobs, WACV. 67Soumyadip Sengupta, Jun-Cheng Chen, Carlos Castillo, Vishal M Patel, Rama Chellappa, and David W Jacobs. Frontal to profile face verification in the wild. In WACV, 2016. 1, 2, 5, 6, 7\n\nProbabilistic face embeddings. Yichun Shi, Jain, ICCV. Yichun Shi and Anil K Jain. Probabilistic face embeddings. In ICCV, 2019. 5\n\nSlink: an optimally efficient algorithm for the single-link cluster method. Robin Sibson, The Computer Journal. 3Robin Sibson. Slink: an optimally efficient algorithm for the single-link cluster method. The Computer Journal, 1973. 3\n\nVery deep convolutional networks for large-scale image recognition. Karen Simonyan, Andrew Zisserman, arXiv:1409.1556Karen Simonyan and Andrew Zisserman. Very deep convolutional networks for large-scale image recognition. arXiv:1409.1556, 2014. 1\n\nDropout: a simple way to prevent neural networks from overfitting. Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, Ruslan Salakhutdinov, JML. 1Nitish Srivastava, Geoffrey E Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. Dropout: a simple way to prevent neural networks from overfitting. JML, 2014. 1\n\nDeep learning face representation by joint identificationverification. Yi Sun, Yuheng Chen, Xiaogang Wang, Xiaoou Tang, NeurIPS. Yi Sun, Yuheng Chen, Xiaogang Wang, and Xiaoou Tang. Deep learning face representation by joint identification- verification. In NeurIPS, 2014. 1\n\nCircle loss: A unified perspective of pair similarity optimization. Yifan Sun, Changmao Cheng, Yuhan Zhang, Chi Zhang, Liang Zheng, Zhongdao Wang, Yichen Wei, CVPR. 2020Yifan Sun, Changmao Cheng, Yuhan Zhang, Chi Zhang, Liang Zheng, Zhongdao Wang, and Yichen Wei. Circle loss: A unified perspective of pair similarity optimization. In CVPR, 2020. 1\n\nYi Sun, Ding Liang, Xiaogang Wang, Xiaoou Tang, arXiv:1502.00873Face recognition with very deep neural networks. 3Yi Sun, Ding Liang, Xiaogang Wang, and Xiaoou Tang. DeepID3: Face recognition with very deep neural networks. arXiv:1502.00873, 2015. 1\n\nDeep learning face representation from predicting 10,000 classes. Yi Sun, Xiaogang Wang, Xiaoou Tang, CVPR. 1Yi Sun, Xiaogang Wang, and Xiaoou Tang. Deep learning face representation from predicting 10,000 classes. In CVPR, 2014. 1, 2\n\nGoing deeper with convolutions. Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, Andrew Rabinovich, CVPR. Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. Going deeper with convolutions. In CVPR, 2015. 1\n\nDeepface: Closing the gap to human-level performance in face verification. Yaniv Taigman, Ming Yang, Marc&apos;aurelio Ranzato, Lior Wolf, CVPR. 1Yaniv Taigman, Ming Yang, Marc'Aurelio Ranzato, and Lior Wolf. Deepface: Closing the gap to human-level perfor- mance in face verification. In CVPR, 2014. 1, 2\n\nWeb-scale training for face identification. Yaniv Taigman, Ming Yang, Marc&apos;aurelio Ranzato, Lior Wolf, CVPR. 1Yaniv Taigman, Ming Yang, Marc'Aurelio Ranzato, and Lior Wolf. Web-scale training for face identification. In CVPR, 2015. 1, 2\n\nEfficientnet: Rethinking model scaling for convolutional neural networks. Mingxing Tan, Quoc Le, ICML. 27Mingxing Tan and Quoc Le. Efficientnet: Rethinking model scaling for convolutional neural networks. In ICML, 2019. 2, 7\n\nBart Thomee, A David, Gerald Shamma, Benjamin Friedland, Karl Elizalde, Douglas Ni, Damian Poland, Li-Jia Borth, Li, The new data in multimedia research. 100Bart Thomee, David A Shamma, Gerald Friedland, Ben- jamin Elizalde, Karl Ni, Douglas Poland, Damian Borth, and Li-Jia Li. YFCC100M: The new data in multimedia research. Communications of the ACM, 2016. 1\n\nCross-pose lfw: A database for studying cross-pose face recognition in unconstrained environments. Zheng Tianyue, Deng Weihong, 67Technical reportZheng Tianyue and Deng Weihong. Cross-pose lfw: A database for studying cross-pose face recognition in uncon- strained environments. Technical report, 2018. 1, 4, 5, 6, 7\n\nThe devil of face recognition is in the noise. Fei Wang, Liren Chen, Cheng Li, Shiyao Huang, Yanjie Chen, Chen Qian, Chen Change Loy, ECCV. 6Fei Wang, Liren Chen, Cheng Li, Shiyao Huang, Yanjie Chen, Chen Qian, and Chen Change Loy. The devil of face recognition is in the noise. In ECCV, 2018. 1, 2, 3, 6\n\nResidual attention network for image classification. Fei Wang, Mengqing Jiang, Chen Qian, Shuo Yang, Cheng Li, Honggang Zhang, Xiaogang Wang, Xiaoou Tang, CVPR. 27Fei Wang, Mengqing Jiang, Chen Qian, Shuo Yang, Cheng Li, Honggang Zhang, Xiaogang Wang, and Xiaoou Tang. Residual attention network for image classification. In CVPR, 2017. 2, 7\n\nAdditive margin softmax for face verification. Feng Wang, Weiyang Liu, Haijun Liu, Jian Cheng, SPL. 1Feng Wang, Weiyang Liu, Haijun Liu, and Jian Cheng. Ad- ditive margin softmax for face verification. SPL, 2018. 1\n\nNormface: L2 hypersphere embedding for face verification. Feng Wang, Xiang Xiang, Jian Cheng, Alan Loddon Yuille, ACM MM. Feng Wang, Xiang Xiang, Jian Cheng, and Alan Loddon Yuille. Normface: L2 hypersphere embedding for face veri- fication. In ACM MM, 2017. 1\n\nCosface: Large margin cosine loss for deep face recognition. Hao Wang, Yitong Wang, Zheng Zhou, Xing Ji, Zhifeng Li, Dihong Gong, Jingchao Zhou, Wei Liu, CVPR. 15Hao Wang, Yitong Wang, Zheng Zhou, Xing Ji, Zhifeng Li, Dihong Gong, Jingchao Zhou, and Wei Liu. Cosface: Large margin cosine loss for deep face recognition. In CVPR, 2018. 1, 5\n\nMitigate bias in face recognition using skewness-aware reinforcement learning. Mei Wang, Weihong Deng, arXiv:1911.10692arXiv preprintMei Wang and Weihong Deng. Mitigate bias in face recog- nition using skewness-aware reinforcement learning. arXiv preprint arXiv:1911.10692, 2019. 9\n\nRacial faces in the wild: Reducing racial bias by information maximization adaptation network. Mei Wang, Weihong Deng, Jiani Hu, Xunqiang Tao, Yaohai Huang, CVPR. 79Mei Wang, Weihong Deng, Jiani Hu, Xunqiang Tao, and Yaohai Huang. Racial faces in the wild: Reducing racial bias by information maximization adaptation network. In CVPR, 2019. 1, 6, 7, 9\n\nHierarchical pyramid diverse attention networks for face recognition. Qiangchang Wang, Tianyi Wu, He Zheng, Guodong Guo, CVPR. 2020Qiangchang Wang, Tianyi Wu, He Zheng, and Guodong Guo. Hierarchical pyramid diverse attention networks for face recognition. In CVPR, 2020. 1\n\nLinkage based face clustering via graph convolution network. Zhongdao Wang, Liang Zheng, Yali Li, Shengjin Wang, CVPR. Zhongdao Wang, Liang Zheng, Yali Li, and Shengjin Wang. Linkage based face clustering via graph convolution net- work. In CVPR, 2019. 3\n\nA discriminative feature learning approach for deep face recognition. Yandong Wen, Kaipeng Zhang, Zhifeng Li, Yu Qiao, ECCV. Yandong Wen, Kaipeng Zhang, Zhifeng Li, and Yu Qiao. A discriminative feature learning approach for deep face recog- nition. In ECCV, 2016. 1\n\nIARPA Janus Benchmark B face dataset. Cameron Whitelam, Emma Taborsky, Austin Blanton, Brianna Maze, C Jocelyn, Tim Adams, Miller, D Nathan, Kalka, K Anil, James A Jain, Kristen Duncan, Allen, CVPR Workshop. 1Cameron Whitelam, Emma Taborsky, Austin Blanton, Bri- anna Maze, Jocelyn C Adams, Tim Miller, Nathan D Kalka, Anil K Jain, James A Duncan, and Kristen Allen. IARPA Janus Benchmark B face dataset. In CVPR Workshop, 2017. 1, 2\n\nFace recognition in unconstrained videos with matched background similarity. Lior Wolf, Itay Hassner, Maoz, CVPR. Lior Wolf, Tal Hassner, and Itay Maoz. Face recognition in unconstrained videos with matched background similarity. In CVPR, 2011. 5\n\nA light CNN for deep face representation with noisy labels. Xiang Wu, Ran He, Zhenan Sun, Tieniu Tan, TIFS. 1Xiang Wu, Ran He, Zhenan Sun, and Tieniu Tan. A light CNN for deep face representation with noisy labels. TIFS, 2018. 1\n\nSelf-training with noisy student improves Imagenet classification. Qizhe Xie, Minh-Thang Luong, Eduard Hovy, Quoc V Le, CVPR. 2020Qizhe Xie, Minh-Thang Luong, Eduard Hovy, and Quoc V Le. Self-training with noisy student improves Imagenet clas- sification. In CVPR, 2020. 3\n\nAggregated residual transformations for deep neural networks. Saining Xie, Ross Girshick, Piotr Doll\u00e1r, Zhuowen Tu, Kaiming He, CVPR. 27Saining Xie, Ross Girshick, Piotr Doll\u00e1r, Zhuowen Tu, and Kaiming He. Aggregated residual transformations for deep neural networks. In CVPR, 2017. 2, 7\n\nBillion-scale semi-supervised learning for image classification. Herv\u00e9 I Zeki Yalniz, Kan J\u00e9gou, Manohar Chen, Dhruv Paluri, Mahajan, arXiv:1905.00546I Zeki Yalniz, Herv\u00e9 J\u00e9gou, Kan Chen, Manohar Paluri, and Dhruv Mahajan. Billion-scale semi-supervised learning for image classification. arXiv:1905.00546, 2019. 3\n\nVargfacenet: An efficient variable group convolutional neural network for lightweight face recognition. Mengjia Yan, Mengao Zhao, Zining Xu, Qian Zhang, Guoli Wang, Zhizhong Su, ICCV Workshop. Mengjia Yan, Mengao Zhao, Zining Xu, Qian Zhang, Guoli Wang, and Zhizhong Su. Vargfacenet: An efficient vari- able group convolutional neural network for lightweight face recognition. In ICCV Workshop, 2019. 1\n\nLearning to cluster faces via confidence and connectivity estimation. Lei Yang, Dapeng Chen, Xiaohang Zhan, Rui Zhao, Chen Change Loy, Dahua Lin, CVPR, 2020. 3. 47Lei Yang, Dapeng Chen, Xiaohang Zhan, Rui Zhao, Chen Change Loy, and Dahua Lin. Learning to cluster faces via confidence and connectivity estimation. In CVPR, 2020. 3, 4, 7\n\nLearning to cluster faces on an affinity graph. Lei Yang, Xiaohang Zhan, Dapeng Chen, Junjie Yan, Chen Change Loy, Dahua Lin, CVPR. 7Lei Yang, Xiaohang Zhan, Dapeng Chen, Junjie Yan, Chen Change Loy, and Dahua Lin. Learning to cluster faces on an affinity graph. In CVPR, 2019. 3, 4, 7\n\nUnsupervised word sense disambiguation rivaling supervised methods. David Yarowsky, ACL. David Yarowsky. Unsupervised word sense disambiguation rivaling supervised methods. In ACL, 1995. 3\n\nDong Yi, Zhen Lei, Shengcai Liao, Stan Z Li, arXiv:1411.7923Learning face representation from scratch. 13Dong Yi, Zhen Lei, Shengcai Liao, and Stan Z Li. Learning face representation from scratch. arXiv:1411.7923, 2014. 1, 2, 3\n\nConsensus-driven propagation in massive unlabeled data for face recognition. Xiaohang Zhan, Ziwei Liu, Junjie Yan, Dahua Lin, Chen Change Loy, In ECCV. 3Xiaohang Zhan, Ziwei Liu, Junjie Yan, Dahua Lin, and Chen Change Loy. Consensus-driven propagation in massive un- labeled data for face recognition. In ECCV, 2018. 3\n\nShufflenet: An extremely efficient convolutional neural network for mobile devices. Xiangyu Zhang, Xinyu Zhou, Mengxiao Lin, Jian Sun, CVPR. Xiangyu Zhang, Xinyu Zhou, Mengxiao Lin, and Jian Sun. Shufflenet: An extremely efficient convolutional neural net- work for mobile devices. In CVPR, 2018. 1\n\nGlobal-local GCN: Large-scale label noise cleansing for face recognition. Yaobin Zhang, Weihong Deng, Mei Wang, Jiani Hu, Xian Li, Dongyue Zhao, Dongchao Wen, CVPR, 2020. 27Yaobin Zhang, Weihong Deng, Mei Wang, Jiani Hu, Xian Li, Dongyue Zhao, and Dongchao Wen. Global-local GCN: Large-scale label noise cleansing for face recognition. In CVPR, 2020. 2, 7\n\nCross-age lfw: A database for studying cross-age face recognition in unconstrained environments. Tianyue Zheng, Weihong Deng, Jiani Hu, arXiv:1708.0819767Tianyue Zheng, Weihong Deng, and Jiani Hu. Cross-age lfw: A database for studying cross-age face recognition in unconstrained environments. arXiv:1708.08197, 2017. 1, 4, 5, 6, 7\n", "annotations": {"author": "[{\"end\":119,\"start\":87},{\"end\":131,\"start\":120},{\"end\":196,\"start\":132},{\"end\":204,\"start\":197},{\"end\":218,\"start\":205},{\"end\":230,\"start\":219},{\"end\":243,\"start\":231},{\"end\":254,\"start\":244},{\"end\":320,\"start\":255},{\"end\":356,\"start\":321},{\"end\":388,\"start\":357}]", "publisher": null, "author_last_name": "[{\"end\":96,\"start\":93},{\"end\":130,\"start\":125},{\"end\":145,\"start\":141},{\"end\":203,\"start\":201},{\"end\":217,\"start\":212},{\"end\":229,\"start\":225},{\"end\":242,\"start\":239},{\"end\":253,\"start\":249},{\"end\":263,\"start\":261},{\"end\":330,\"start\":328},{\"end\":365,\"start\":361}]", "author_first_name": "[{\"end\":92,\"start\":87},{\"end\":124,\"start\":120},{\"end\":140,\"start\":132},{\"end\":200,\"start\":197},{\"end\":211,\"start\":205},{\"end\":224,\"start\":219},{\"end\":238,\"start\":231},{\"end\":248,\"start\":244},{\"end\":260,\"start\":255},{\"end\":327,\"start\":321},{\"end\":360,\"start\":357}]", "author_affiliation": "[{\"end\":118,\"start\":98},{\"end\":195,\"start\":171},{\"end\":319,\"start\":299},{\"end\":387,\"start\":367}]", "title": "[{\"end\":84,\"start\":1},{\"end\":472,\"start\":389}]", "venue": null, "abstract": "[{\"end\":2013,\"start\":474}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b24\"},\"end\":2207,\"start\":2203},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":2210,\"start\":2207},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":2213,\"start\":2210},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":2216,\"start\":2213},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":2219,\"start\":2216},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":2222,\"start\":2219},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":2225,\"start\":2222},{\"attributes\":{\"ref_id\":\"b79\"},\"end\":2228,\"start\":2225},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":2231,\"start\":2228},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":2234,\"start\":2231},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":2237,\"start\":2234},{\"end\":2311,\"start\":2267},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":2366,\"start\":2363},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":2369,\"start\":2366},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":2372,\"start\":2369},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":2406,\"start\":2402},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":2409,\"start\":2406},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":2412,\"start\":2409},{\"attributes\":{\"ref_id\":\"b81\"},\"end\":2415,\"start\":2412},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":2418,\"start\":2415},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":2421,\"start\":2418},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":2424,\"start\":2421},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":2427,\"start\":2424},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":2430,\"start\":2427},{\"attributes\":{\"ref_id\":\"b77\"},\"end\":2433,\"start\":2430},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":2436,\"start\":2433},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2438,\"start\":2436},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2440,\"start\":2438},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":2443,\"start\":2440},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":2446,\"start\":2443},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":2449,\"start\":2446},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2641,\"start\":2638},{\"attributes\":{\"ref_id\":\"b73\"},\"end\":2644,\"start\":2641},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2646,\"start\":2644},{\"attributes\":{\"ref_id\":\"b64\"},\"end\":2649,\"start\":2646},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":2652,\"start\":2649},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":2668,\"start\":2664},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":2671,\"start\":2668},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":2674,\"start\":2671},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":2677,\"start\":2674},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":2680,\"start\":2677},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":2683,\"start\":2680},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2686,\"start\":2683},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":2875,\"start\":2871},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":2889,\"start\":2885},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":2978,\"start\":2974},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":3064,\"start\":3060},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":3239,\"start\":3235},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":3258,\"start\":3254},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":3721,\"start\":3717},{\"attributes\":{\"ref_id\":\"b81\"},\"end\":3724,\"start\":3721},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":3727,\"start\":3724},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":3737,\"start\":3733},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":3749,\"start\":3745},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":3759,\"start\":3755},{\"attributes\":{\"ref_id\":\"b77\"},\"end\":3867,\"start\":3863},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":3921,\"start\":3917},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":3938,\"start\":3934},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":3957,\"start\":3953},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":3960,\"start\":3957},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":3963,\"start\":3960},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":4250,\"start\":4246},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":5536,\"start\":5532},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":5539,\"start\":5536},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":5542,\"start\":5539},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":5569,\"start\":5565},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":5572,\"start\":5569},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":6215,\"start\":6211},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":6437,\"start\":6433},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":6440,\"start\":6437},{\"end\":6442,\"start\":6440},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":6461,\"start\":6457},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":6698,\"start\":6694},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":6700,\"start\":6698},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":6719,\"start\":6715},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":6738,\"start\":6734},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":6751,\"start\":6747},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":6763,\"start\":6759},{\"attributes\":{\"ref_id\":\"b71\"},\"end\":6777,\"start\":6773},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":6802,\"start\":6798},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":7476,\"start\":7472},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":8490,\"start\":8486},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":8657,\"start\":8653},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":8789,\"start\":8785},{\"attributes\":{\"ref_id\":\"b77\"},\"end\":8933,\"start\":8929},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":9644,\"start\":9640},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":9797,\"start\":9793},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":9811,\"start\":9808},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":9830,\"start\":9826},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":10052,\"start\":10048},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":10149,\"start\":10145},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":10232,\"start\":10228},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":10235,\"start\":10232},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":10238,\"start\":10235},{\"attributes\":{\"ref_id\":\"b78\"},\"end\":10280,\"start\":10276},{\"attributes\":{\"ref_id\":\"b75\"},\"end\":10283,\"start\":10280},{\"attributes\":{\"ref_id\":\"b74\"},\"end\":10286,\"start\":10283},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":10289,\"start\":10286},{\"attributes\":{\"ref_id\":\"b65\"},\"end\":10292,\"start\":10289},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":10440,\"start\":10436},{\"attributes\":{\"ref_id\":\"b72\"},\"end\":10443,\"start\":10440},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":10446,\"start\":10443},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":10449,\"start\":10446},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":10503,\"start\":10499},{\"attributes\":{\"ref_id\":\"b76\"},\"end\":10506,\"start\":10503},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":11067,\"start\":11063},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":11609,\"start\":11605},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":11623,\"start\":11619},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":11672,\"start\":11668},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":13071,\"start\":13067},{\"attributes\":{\"ref_id\":\"b75\"},\"end\":13272,\"start\":13268},{\"attributes\":{\"ref_id\":\"b74\"},\"end\":13287,\"start\":13283},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":14570,\"start\":14566},{\"attributes\":{\"ref_id\":\"b81\"},\"end\":14573,\"start\":14570},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":14576,\"start\":14573},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":14592,\"start\":14588},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":14604,\"start\":14600},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":14871,\"start\":14867},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":14883,\"start\":14879},{\"attributes\":{\"ref_id\":\"b81\"},\"end\":14895,\"start\":14891},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":14910,\"start\":14906},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":15019,\"start\":15015},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":15034,\"start\":15030},{\"attributes\":{\"ref_id\":\"b68\"},\"end\":15120,\"start\":15116},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":15141,\"start\":15137},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":15241,\"start\":15237},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":15461,\"start\":15457},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":19013,\"start\":19009},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":19027,\"start\":19023},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":19051,\"start\":19047},{\"end\":19257,\"start\":19249},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":19299,\"start\":19295},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":19865,\"start\":19861},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":21358,\"start\":21354},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":21361,\"start\":21358},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":21363,\"start\":21361},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":21383,\"start\":21379},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":21402,\"start\":21398},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":21693,\"start\":21689},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":21706,\"start\":21702},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":21718,\"start\":21714},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":21730,\"start\":21726},{\"attributes\":{\"ref_id\":\"b81\"},\"end\":21745,\"start\":21741},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":21756,\"start\":21752},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":21771,\"start\":21767},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":21783,\"start\":21779},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":23276,\"start\":23272},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":23380,\"start\":23376},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":23623,\"start\":23619},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":23626,\"start\":23623},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":23629,\"start\":23626},{\"attributes\":{\"ref_id\":\"b81\"},\"end\":23632,\"start\":23629},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":23635,\"start\":23632},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":23675,\"start\":23671},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":23721,\"start\":23717},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":23752,\"start\":23748},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":23838,\"start\":23834},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":23841,\"start\":23838},{\"end\":23843,\"start\":23841},{\"attributes\":{\"ref_id\":\"b80\"},\"end\":23897,\"start\":23893},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":24401,\"start\":24397},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":24419,\"start\":24415},{\"attributes\":{\"ref_id\":\"b75\"},\"end\":24460,\"start\":24456},{\"attributes\":{\"ref_id\":\"b74\"},\"end\":24475,\"start\":24471},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":24861,\"start\":24857},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":25283,\"start\":25279},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":25285,\"start\":25283},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":25304,\"start\":25300},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":25323,\"start\":25319},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":25336,\"start\":25332},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":25348,\"start\":25344},{\"attributes\":{\"ref_id\":\"b71\"},\"end\":25362,\"start\":25358},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":25378,\"start\":25374},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":25591,\"start\":25587},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":26150,\"start\":26146},{\"end\":27476,\"start\":27464},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":28838,\"start\":28834},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":28841,\"start\":28838},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":28844,\"start\":28841},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":28847,\"start\":28844}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":29807,\"start\":29709},{\"attributes\":{\"id\":\"fig_2\"},\"end\":29860,\"start\":29808},{\"attributes\":{\"id\":\"fig_3\"},\"end\":29920,\"start\":29861},{\"attributes\":{\"id\":\"fig_4\"},\"end\":30372,\"start\":29921},{\"attributes\":{\"id\":\"fig_5\"},\"end\":30589,\"start\":30373},{\"attributes\":{\"id\":\"fig_6\"},\"end\":30728,\"start\":30590},{\"attributes\":{\"id\":\"fig_7\"},\"end\":31115,\"start\":30729},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":32189,\"start\":31116},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":32933,\"start\":32190},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":33011,\"start\":32934},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":33115,\"start\":33012},{\"attributes\":{\"id\":\"tab_9\",\"type\":\"table\"},\"end\":33257,\"start\":33116},{\"attributes\":{\"id\":\"tab_11\",\"type\":\"table\"},\"end\":33399,\"start\":33258},{\"attributes\":{\"id\":\"tab_13\",\"type\":\"table\"},\"end\":33804,\"start\":33400},{\"attributes\":{\"id\":\"tab_14\",\"type\":\"table\"},\"end\":33931,\"start\":33805},{\"attributes\":{\"id\":\"tab_16\",\"type\":\"table\"},\"end\":34329,\"start\":33932},{\"attributes\":{\"id\":\"tab_18\",\"type\":\"table\"},\"end\":34465,\"start\":34330}]", "paragraph": "[{\"end\":3532,\"start\":2029},{\"end\":5768,\"start\":3534},{\"end\":7008,\"start\":5770},{\"end\":7062,\"start\":7010},{\"end\":9436,\"start\":7064},{\"end\":10410,\"start\":9480},{\"end\":11487,\"start\":10412},{\"end\":11771,\"start\":11489},{\"end\":12755,\"start\":11773},{\"end\":14719,\"start\":12757},{\"end\":15406,\"start\":14761},{\"end\":16106,\"start\":15408},{\"end\":17173,\"start\":16108},{\"end\":17991,\"start\":17186},{\"end\":18804,\"start\":18003},{\"end\":19518,\"start\":18874},{\"end\":20053,\"start\":19543},{\"end\":21174,\"start\":20055},{\"end\":22694,\"start\":21207},{\"end\":23138,\"start\":22696},{\"end\":24897,\"start\":23171},{\"end\":25443,\"start\":24934},{\"end\":26529,\"start\":25445},{\"end\":27169,\"start\":26531},{\"end\":28009,\"start\":27194},{\"end\":29110,\"start\":28039},{\"end\":29708,\"start\":29112}]", "formula": null, "table_ref": "[{\"end\":20865,\"start\":20858}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":2027,\"start\":2015},{\"attributes\":{\"n\":\"3.\"},\"end\":9478,\"start\":9439},{\"attributes\":{\"n\":\"4.\"},\"end\":14737,\"start\":14722},{\"attributes\":{\"n\":\"4.1.\"},\"end\":14759,\"start\":14740},{\"attributes\":{\"n\":\"4.2.\"},\"end\":17184,\"start\":17176},{\"attributes\":{\"n\":\"4.3.\"},\"end\":18001,\"start\":17994},{\"attributes\":{\"n\":\"5.\"},\"end\":18847,\"start\":18807},{\"attributes\":{\"n\":\"5.1.\"},\"end\":18872,\"start\":18850},{\"attributes\":{\"n\":\"5.2.\"},\"end\":19541,\"start\":19521},{\"attributes\":{\"n\":\"5.3.\"},\"end\":21205,\"start\":21177},{\"attributes\":{\"n\":\"5.4.\"},\"end\":23169,\"start\":23141},{\"attributes\":{\"n\":\"5.5.\"},\"end\":24932,\"start\":24900},{\"attributes\":{\"n\":\"5.6.\"},\"end\":27192,\"start\":27172},{\"attributes\":{\"n\":\"6.\"},\"end\":28037,\"start\":28012},{\"end\":29720,\"start\":29710},{\"end\":29819,\"start\":29809},{\"end\":29872,\"start\":29862},{\"end\":30384,\"start\":30374},{\"end\":30601,\"start\":30591},{\"end\":30740,\"start\":30730},{\"end\":32944,\"start\":32935},{\"end\":33022,\"start\":33013},{\"end\":33126,\"start\":33117},{\"end\":33268,\"start\":33259},{\"end\":33410,\"start\":33401},{\"end\":33815,\"start\":33806},{\"end\":33942,\"start\":33933},{\"end\":34341,\"start\":34331}]", "table": "[{\"end\":32189,\"start\":31269},{\"end\":32933,\"start\":32448},{\"end\":33399,\"start\":33270},{\"end\":33804,\"start\":33412}]", "figure_caption": "[{\"end\":29807,\"start\":29722},{\"end\":29860,\"start\":29821},{\"end\":29920,\"start\":29874},{\"end\":30372,\"start\":29923},{\"end\":30589,\"start\":30386},{\"end\":30728,\"start\":30603},{\"end\":31115,\"start\":30742},{\"end\":31269,\"start\":31118},{\"end\":32448,\"start\":32192},{\"end\":33011,\"start\":32946},{\"end\":33115,\"start\":33024},{\"end\":33257,\"start\":33128},{\"end\":33931,\"start\":33817},{\"end\":34329,\"start\":33944},{\"end\":34465,\"start\":34344}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":7371,\"start\":7366},{\"end\":7791,\"start\":7786},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":8372,\"start\":8367},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":9242,\"start\":9237},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":9368,\"start\":9363},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":9389,\"start\":9381},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":9434,\"start\":9425},{\"end\":10593,\"start\":10585},{\"end\":11533,\"start\":11528},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":13990,\"start\":13985},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":20146,\"start\":20141},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":21836,\"start\":21831},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":22270,\"start\":22265},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":25791,\"start\":25783},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":25804,\"start\":25796},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":26279,\"start\":26274},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":26295,\"start\":26287},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":26760,\"start\":26755},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":26776,\"start\":26768}]", "bib_author_first_name": "[{\"end\":34536,\"start\":34531},{\"end\":34552,\"start\":34545},{\"end\":34563,\"start\":34562},{\"end\":34578,\"start\":34572},{\"end\":34593,\"start\":34589},{\"end\":34881,\"start\":34876},{\"end\":34889,\"start\":34887},{\"end\":34901,\"start\":34896},{\"end\":34908,\"start\":34907},{\"end\":34922,\"start\":34916},{\"end\":35201,\"start\":35196},{\"end\":35212,\"start\":35208},{\"end\":35223,\"start\":35218},{\"end\":35233,\"start\":35229},{\"end\":35497,\"start\":35489},{\"end\":35507,\"start\":35504},{\"end\":35522,\"start\":35513},{\"end\":35824,\"start\":35816},{\"end\":35834,\"start\":35831},{\"end\":35849,\"start\":35840},{\"end\":35865,\"start\":35860},{\"end\":35882,\"start\":35874},{\"end\":36156,\"start\":36148},{\"end\":36166,\"start\":36163},{\"end\":36180,\"start\":36172},{\"end\":36394,\"start\":36386},{\"end\":36404,\"start\":36401},{\"end\":36416,\"start\":36410},{\"end\":36430,\"start\":36424},{\"end\":36444,\"start\":36437},{\"end\":36453,\"start\":36449},{\"end\":36676,\"start\":36668},{\"end\":36690,\"start\":36683},{\"end\":36705,\"start\":36697},{\"end\":36959,\"start\":36953},{\"end\":36977,\"start\":36967},{\"end\":36991,\"start\":36987},{\"end\":37007,\"start\":37000},{\"end\":37280,\"start\":37277},{\"end\":37294,\"start\":37287},{\"end\":37307,\"start\":37301},{\"end\":37320,\"start\":37315},{\"end\":37567,\"start\":37562},{\"end\":37582,\"start\":37574},{\"end\":37747,\"start\":37742},{\"end\":37762,\"start\":37754},{\"end\":38022,\"start\":38017},{\"end\":38035,\"start\":38030},{\"end\":38048,\"start\":38044},{\"end\":38065,\"start\":38059},{\"end\":38083,\"start\":38077},{\"end\":38100,\"start\":38096},{\"end\":38115,\"start\":38109},{\"end\":38517,\"start\":38511},{\"end\":38527,\"start\":38523},{\"end\":38538,\"start\":38532},{\"end\":38549,\"start\":38545},{\"end\":38565,\"start\":38557},{\"end\":38575,\"start\":38572},{\"end\":38816,\"start\":38809},{\"end\":38825,\"start\":38822},{\"end\":38839,\"start\":38833},{\"end\":38852,\"start\":38844},{\"end\":38865,\"start\":38857},{\"end\":39142,\"start\":39135},{\"end\":39154,\"start\":39147},{\"end\":39170,\"start\":39162},{\"end\":39180,\"start\":39176},{\"end\":39413,\"start\":39406},{\"end\":39425,\"start\":39418},{\"end\":39441,\"start\":39433},{\"end\":39451,\"start\":39447},{\"end\":39676,\"start\":39675},{\"end\":39693,\"start\":39685},{\"end\":39704,\"start\":39702},{\"end\":39716,\"start\":39710},{\"end\":39729,\"start\":39723},{\"end\":39750,\"start\":39744},{\"end\":39762,\"start\":39757},{\"end\":39778,\"start\":39771},{\"end\":40093,\"start\":40090},{\"end\":40100,\"start\":40098},{\"end\":40111,\"start\":40107},{\"end\":40312,\"start\":40311},{\"end\":40323,\"start\":40319},{\"end\":40337,\"start\":40331},{\"end\":40350,\"start\":40346},{\"end\":40675,\"start\":40671},{\"end\":40688,\"start\":40683},{\"end\":40699,\"start\":40695},{\"end\":40713,\"start\":40705},{\"end\":40728,\"start\":40719},{\"end\":40742,\"start\":40735},{\"end\":40752,\"start\":40747},{\"end\":40763,\"start\":40757},{\"end\":41081,\"start\":41075},{\"end\":41098,\"start\":41089},{\"end\":41333,\"start\":41330},{\"end\":41359,\"start\":41358},{\"end\":41374,\"start\":41368},{\"end\":41386,\"start\":41382},{\"end\":41682,\"start\":41679},{\"end\":41704,\"start\":41700},{\"end\":41718,\"start\":41712},{\"end\":41735,\"start\":41729},{\"end\":41752,\"start\":41745},{\"end\":41768,\"start\":41761},{\"end\":41780,\"start\":41776},{\"end\":42129,\"start\":42125},{\"end\":42146,\"start\":42142},{\"end\":42166,\"start\":42158},{\"end\":42168,\"start\":42167},{\"end\":42398,\"start\":42391},{\"end\":42411,\"start\":42404},{\"end\":42424,\"start\":42417},{\"end\":42433,\"start\":42429},{\"end\":42445,\"start\":42438},{\"end\":42453,\"start\":42451},{\"end\":42686,\"start\":42679},{\"end\":42699,\"start\":42692},{\"end\":42712,\"start\":42705},{\"end\":42721,\"start\":42717},{\"end\":42875,\"start\":42868},{\"end\":42887,\"start\":42881},{\"end\":42895,\"start\":42893},{\"end\":42904,\"start\":42902},{\"end\":42914,\"start\":42910},{\"end\":42925,\"start\":42921},{\"end\":42933,\"start\":42931},{\"end\":42945,\"start\":42941},{\"end\":43312,\"start\":43306},{\"end\":43447,\"start\":43440},{\"end\":43461,\"start\":43454},{\"end\":43470,\"start\":43469},{\"end\":43484,\"start\":43478},{\"end\":43496,\"start\":43493},{\"end\":43511,\"start\":43504},{\"end\":43527,\"start\":43526},{\"end\":43545,\"start\":43540},{\"end\":43566,\"start\":43560},{\"end\":43896,\"start\":43887},{\"end\":43919,\"start\":43909},{\"end\":43941,\"start\":43933},{\"end\":43959,\"start\":43951},{\"end\":43971,\"start\":43966},{\"end\":43988,\"start\":43980},{\"end\":44298,\"start\":44293},{\"end\":44308,\"start\":44305},{\"end\":44532,\"start\":44524},{\"end\":44543,\"start\":44537},{\"end\":44714,\"start\":44707},{\"end\":44727,\"start\":44721},{\"end\":44866,\"start\":44865},{\"end\":44880,\"start\":44874},{\"end\":44895,\"start\":44889},{\"end\":45100,\"start\":45095},{\"end\":45347,\"start\":45342},{\"end\":45366,\"start\":45361},{\"end\":45379,\"start\":45375},{\"end\":45397,\"start\":45390},{\"end\":45415,\"start\":45408},{\"end\":45648,\"start\":45643},{\"end\":45665,\"start\":45662},{\"end\":45673,\"start\":45666},{\"end\":45688,\"start\":45684},{\"end\":45945,\"start\":45939},{\"end\":45959,\"start\":45954},{\"end\":45974,\"start\":45968},{\"end\":45984,\"start\":45979},{\"end\":46012,\"start\":46003},{\"end\":46025,\"start\":46019},{\"end\":46027,\"start\":46026},{\"end\":46042,\"start\":46038},{\"end\":46359,\"start\":46355},{\"end\":46376,\"start\":46373},{\"end\":46386,\"start\":46383},{\"end\":46399,\"start\":46391},{\"end\":46415,\"start\":46408},{\"end\":46430,\"start\":46426},{\"end\":46442,\"start\":46435},{\"end\":46456,\"start\":46450},{\"end\":46473,\"start\":46467},{\"end\":46489,\"start\":46482},{\"end\":46804,\"start\":46797},{\"end\":46820,\"start\":46814},{\"end\":46840,\"start\":46835},{\"end\":47076,\"start\":47075},{\"end\":47239,\"start\":47230},{\"end\":47259,\"start\":47250},{\"end\":47272,\"start\":47266},{\"end\":47284,\"start\":47283},{\"end\":47297,\"start\":47293},{\"end\":47310,\"start\":47305},{\"end\":47312,\"start\":47311},{\"end\":47562,\"start\":47556},{\"end\":47738,\"start\":47733},{\"end\":47964,\"start\":47959},{\"end\":47981,\"start\":47975},{\"end\":48212,\"start\":48206},{\"end\":48233,\"start\":48225},{\"end\":48235,\"start\":48234},{\"end\":48248,\"start\":48244},{\"end\":48265,\"start\":48261},{\"end\":48283,\"start\":48277},{\"end\":48556,\"start\":48554},{\"end\":48568,\"start\":48562},{\"end\":48583,\"start\":48575},{\"end\":48596,\"start\":48590},{\"end\":48832,\"start\":48827},{\"end\":48846,\"start\":48838},{\"end\":48859,\"start\":48854},{\"end\":48870,\"start\":48867},{\"end\":48883,\"start\":48878},{\"end\":48899,\"start\":48891},{\"end\":48912,\"start\":48906},{\"end\":49111,\"start\":49109},{\"end\":49121,\"start\":49117},{\"end\":49137,\"start\":49129},{\"end\":49150,\"start\":49144},{\"end\":49428,\"start\":49426},{\"end\":49442,\"start\":49434},{\"end\":49455,\"start\":49449},{\"end\":49637,\"start\":49628},{\"end\":49650,\"start\":49647},{\"end\":49664,\"start\":49656},{\"end\":49676,\"start\":49670},{\"end\":49692,\"start\":49687},{\"end\":49707,\"start\":49699},{\"end\":49725,\"start\":49718},{\"end\":49740,\"start\":49733},{\"end\":49758,\"start\":49752},{\"end\":50054,\"start\":50049},{\"end\":50068,\"start\":50064},{\"end\":50092,\"start\":50075},{\"end\":50106,\"start\":50102},{\"end\":50330,\"start\":50325},{\"end\":50344,\"start\":50340},{\"end\":50368,\"start\":50351},{\"end\":50382,\"start\":50378},{\"end\":50606,\"start\":50598},{\"end\":50616,\"start\":50612},{\"end\":50754,\"start\":50750},{\"end\":50764,\"start\":50763},{\"end\":50778,\"start\":50772},{\"end\":50795,\"start\":50787},{\"end\":50811,\"start\":50807},{\"end\":50829,\"start\":50822},{\"end\":50840,\"start\":50834},{\"end\":50855,\"start\":50849},{\"end\":51216,\"start\":51211},{\"end\":51230,\"start\":51226},{\"end\":51480,\"start\":51477},{\"end\":51492,\"start\":51487},{\"end\":51504,\"start\":51499},{\"end\":51515,\"start\":51509},{\"end\":51529,\"start\":51523},{\"end\":51540,\"start\":51536},{\"end\":51558,\"start\":51547},{\"end\":51792,\"start\":51789},{\"end\":51807,\"start\":51799},{\"end\":51819,\"start\":51815},{\"end\":51830,\"start\":51826},{\"end\":51842,\"start\":51837},{\"end\":51855,\"start\":51847},{\"end\":51871,\"start\":51863},{\"end\":51884,\"start\":51878},{\"end\":52130,\"start\":52126},{\"end\":52144,\"start\":52137},{\"end\":52156,\"start\":52150},{\"end\":52166,\"start\":52162},{\"end\":52357,\"start\":52353},{\"end\":52369,\"start\":52364},{\"end\":52381,\"start\":52377},{\"end\":52393,\"start\":52389},{\"end\":52400,\"start\":52394},{\"end\":52621,\"start\":52618},{\"end\":52634,\"start\":52628},{\"end\":52646,\"start\":52641},{\"end\":52657,\"start\":52653},{\"end\":52669,\"start\":52662},{\"end\":52680,\"start\":52674},{\"end\":52695,\"start\":52687},{\"end\":52705,\"start\":52702},{\"end\":52980,\"start\":52977},{\"end\":52994,\"start\":52987},{\"end\":53279,\"start\":53276},{\"end\":53293,\"start\":53286},{\"end\":53305,\"start\":53300},{\"end\":53318,\"start\":53310},{\"end\":53330,\"start\":53324},{\"end\":53614,\"start\":53604},{\"end\":53627,\"start\":53621},{\"end\":53634,\"start\":53632},{\"end\":53649,\"start\":53642},{\"end\":53877,\"start\":53869},{\"end\":53889,\"start\":53884},{\"end\":53901,\"start\":53897},{\"end\":53914,\"start\":53906},{\"end\":54141,\"start\":54134},{\"end\":54154,\"start\":54147},{\"end\":54169,\"start\":54162},{\"end\":54176,\"start\":54174},{\"end\":54377,\"start\":54370},{\"end\":54392,\"start\":54388},{\"end\":54409,\"start\":54403},{\"end\":54426,\"start\":54419},{\"end\":54434,\"start\":54433},{\"end\":54447,\"start\":54444},{\"end\":54464,\"start\":54463},{\"end\":54481,\"start\":54480},{\"end\":54493,\"start\":54488},{\"end\":54495,\"start\":54494},{\"end\":54509,\"start\":54502},{\"end\":54848,\"start\":54844},{\"end\":54859,\"start\":54855},{\"end\":55080,\"start\":55075},{\"end\":55088,\"start\":55085},{\"end\":55099,\"start\":55093},{\"end\":55111,\"start\":55105},{\"end\":55317,\"start\":55312},{\"end\":55333,\"start\":55323},{\"end\":55347,\"start\":55341},{\"end\":55360,\"start\":55354},{\"end\":55588,\"start\":55581},{\"end\":55598,\"start\":55594},{\"end\":55614,\"start\":55609},{\"end\":55630,\"start\":55623},{\"end\":55642,\"start\":55635},{\"end\":55878,\"start\":55873},{\"end\":55897,\"start\":55894},{\"end\":55912,\"start\":55905},{\"end\":55924,\"start\":55919},{\"end\":56234,\"start\":56227},{\"end\":56246,\"start\":56240},{\"end\":56259,\"start\":56253},{\"end\":56268,\"start\":56264},{\"end\":56281,\"start\":56276},{\"end\":56296,\"start\":56288},{\"end\":56600,\"start\":56597},{\"end\":56613,\"start\":56607},{\"end\":56628,\"start\":56620},{\"end\":56638,\"start\":56635},{\"end\":56649,\"start\":56645},{\"end\":56656,\"start\":56650},{\"end\":56667,\"start\":56662},{\"end\":56915,\"start\":56912},{\"end\":56930,\"start\":56922},{\"end\":56943,\"start\":56937},{\"end\":56956,\"start\":56950},{\"end\":56966,\"start\":56962},{\"end\":56973,\"start\":56967},{\"end\":56984,\"start\":56979},{\"end\":57224,\"start\":57219},{\"end\":57345,\"start\":57341},{\"end\":57354,\"start\":57350},{\"end\":57368,\"start\":57360},{\"end\":57379,\"start\":57375},{\"end\":57381,\"start\":57380},{\"end\":57655,\"start\":57647},{\"end\":57667,\"start\":57662},{\"end\":57679,\"start\":57673},{\"end\":57690,\"start\":57685},{\"end\":57707,\"start\":57696},{\"end\":57981,\"start\":57974},{\"end\":57994,\"start\":57989},{\"end\":58009,\"start\":58001},{\"end\":58019,\"start\":58015},{\"end\":58270,\"start\":58264},{\"end\":58285,\"start\":58278},{\"end\":58295,\"start\":58292},{\"end\":58307,\"start\":58302},{\"end\":58316,\"start\":58312},{\"end\":58328,\"start\":58321},{\"end\":58343,\"start\":58335},{\"end\":58651,\"start\":58644},{\"end\":58666,\"start\":58659},{\"end\":58678,\"start\":58673}]", "bib_author_last_name": "[{\"end\":34543,\"start\":34537},{\"end\":34560,\"start\":34553},{\"end\":34570,\"start\":34564},{\"end\":34587,\"start\":34579},{\"end\":34600,\"start\":34594},{\"end\":34611,\"start\":34602},{\"end\":34885,\"start\":34882},{\"end\":34894,\"start\":34890},{\"end\":34905,\"start\":34902},{\"end\":34914,\"start\":34909},{\"end\":34929,\"start\":34923},{\"end\":34940,\"start\":34931},{\"end\":35206,\"start\":35202},{\"end\":35216,\"start\":35213},{\"end\":35227,\"start\":35224},{\"end\":35237,\"start\":35234},{\"end\":35502,\"start\":35498},{\"end\":35511,\"start\":35508},{\"end\":35526,\"start\":35523},{\"end\":35829,\"start\":35825},{\"end\":35838,\"start\":35835},{\"end\":35858,\"start\":35850},{\"end\":35872,\"start\":35866},{\"end\":35892,\"start\":35883},{\"end\":36161,\"start\":36157},{\"end\":36170,\"start\":36167},{\"end\":36190,\"start\":36181},{\"end\":36399,\"start\":36395},{\"end\":36408,\"start\":36405},{\"end\":36422,\"start\":36417},{\"end\":36435,\"start\":36431},{\"end\":36447,\"start\":36445},{\"end\":36457,\"start\":36454},{\"end\":36681,\"start\":36677},{\"end\":36695,\"start\":36691},{\"end\":36715,\"start\":36706},{\"end\":36965,\"start\":36960},{\"end\":36985,\"start\":36978},{\"end\":36998,\"start\":36992},{\"end\":37010,\"start\":37008},{\"end\":37285,\"start\":37281},{\"end\":37299,\"start\":37295},{\"end\":37313,\"start\":37308},{\"end\":37323,\"start\":37321},{\"end\":37572,\"start\":37568},{\"end\":37586,\"start\":37583},{\"end\":37592,\"start\":37588},{\"end\":37752,\"start\":37748},{\"end\":37766,\"start\":37763},{\"end\":37772,\"start\":37768},{\"end\":38028,\"start\":38023},{\"end\":38042,\"start\":38036},{\"end\":38057,\"start\":38049},{\"end\":38075,\"start\":38066},{\"end\":38094,\"start\":38084},{\"end\":38107,\"start\":38101},{\"end\":38123,\"start\":38116},{\"end\":38521,\"start\":38518},{\"end\":38530,\"start\":38528},{\"end\":38543,\"start\":38539},{\"end\":38555,\"start\":38550},{\"end\":38570,\"start\":38566},{\"end\":38580,\"start\":38576},{\"end\":38820,\"start\":38817},{\"end\":38831,\"start\":38826},{\"end\":38842,\"start\":38840},{\"end\":38855,\"start\":38853},{\"end\":38869,\"start\":38866},{\"end\":39145,\"start\":39143},{\"end\":39160,\"start\":39155},{\"end\":39174,\"start\":39171},{\"end\":39184,\"start\":39181},{\"end\":39416,\"start\":39414},{\"end\":39431,\"start\":39426},{\"end\":39445,\"start\":39442},{\"end\":39455,\"start\":39452},{\"end\":39683,\"start\":39677},{\"end\":39700,\"start\":39694},{\"end\":39708,\"start\":39705},{\"end\":39721,\"start\":39717},{\"end\":39742,\"start\":39730},{\"end\":39755,\"start\":39751},{\"end\":39769,\"start\":39763},{\"end\":39788,\"start\":39779},{\"end\":39794,\"start\":39790},{\"end\":40096,\"start\":40094},{\"end\":40105,\"start\":40101},{\"end\":40115,\"start\":40112},{\"end\":40317,\"start\":40313},{\"end\":40329,\"start\":40324},{\"end\":40344,\"start\":40338},{\"end\":40355,\"start\":40351},{\"end\":40371,\"start\":40357},{\"end\":40681,\"start\":40676},{\"end\":40693,\"start\":40689},{\"end\":40703,\"start\":40700},{\"end\":40717,\"start\":40714},{\"end\":40733,\"start\":40729},{\"end\":40745,\"start\":40743},{\"end\":40755,\"start\":40753},{\"end\":40769,\"start\":40764},{\"end\":41087,\"start\":41082},{\"end\":41106,\"start\":41099},{\"end\":41356,\"start\":41334},{\"end\":41366,\"start\":41360},{\"end\":41380,\"start\":41375},{\"end\":41393,\"start\":41387},{\"end\":41403,\"start\":41395},{\"end\":41698,\"start\":41683},{\"end\":41710,\"start\":41705},{\"end\":41727,\"start\":41719},{\"end\":41743,\"start\":41736},{\"end\":41759,\"start\":41753},{\"end\":41774,\"start\":41769},{\"end\":41788,\"start\":41781},{\"end\":41793,\"start\":41790},{\"end\":41799,\"start\":41795},{\"end\":42140,\"start\":42130},{\"end\":42156,\"start\":42147},{\"end\":42175,\"start\":42169},{\"end\":42402,\"start\":42399},{\"end\":42415,\"start\":42412},{\"end\":42427,\"start\":42425},{\"end\":42436,\"start\":42434},{\"end\":42449,\"start\":42446},{\"end\":42458,\"start\":42454},{\"end\":42690,\"start\":42687},{\"end\":42703,\"start\":42700},{\"end\":42715,\"start\":42713},{\"end\":42726,\"start\":42722},{\"end\":42879,\"start\":42876},{\"end\":42891,\"start\":42888},{\"end\":42900,\"start\":42896},{\"end\":42908,\"start\":42905},{\"end\":42919,\"start\":42915},{\"end\":42929,\"start\":42926},{\"end\":42939,\"start\":42934},{\"end\":42949,\"start\":42946},{\"end\":43318,\"start\":43313},{\"end\":43452,\"start\":43448},{\"end\":43467,\"start\":43462},{\"end\":43476,\"start\":43471},{\"end\":43491,\"start\":43485},{\"end\":43502,\"start\":43497},{\"end\":43518,\"start\":43512},{\"end\":43524,\"start\":43520},{\"end\":43532,\"start\":43528},{\"end\":43538,\"start\":43534},{\"end\":43558,\"start\":43546},{\"end\":43575,\"start\":43567},{\"end\":43583,\"start\":43577},{\"end\":43907,\"start\":43897},{\"end\":43931,\"start\":43920},{\"end\":43949,\"start\":43942},{\"end\":43964,\"start\":43960},{\"end\":43978,\"start\":43972},{\"end\":43998,\"start\":43989},{\"end\":44303,\"start\":44299},{\"end\":44331,\"start\":44309},{\"end\":44535,\"start\":44533},{\"end\":44551,\"start\":44544},{\"end\":44719,\"start\":44715},{\"end\":44732,\"start\":44728},{\"end\":44738,\"start\":44734},{\"end\":44872,\"start\":44867},{\"end\":44887,\"start\":44881},{\"end\":44903,\"start\":44896},{\"end\":44914,\"start\":44905},{\"end\":45133,\"start\":45101},{\"end\":45140,\"start\":45135},{\"end\":45359,\"start\":45348},{\"end\":45373,\"start\":45367},{\"end\":45388,\"start\":45380},{\"end\":45406,\"start\":45398},{\"end\":45418,\"start\":45416},{\"end\":45660,\"start\":45649},{\"end\":45682,\"start\":45674},{\"end\":45697,\"start\":45689},{\"end\":45952,\"start\":45946},{\"end\":45966,\"start\":45960},{\"end\":45977,\"start\":45975},{\"end\":46001,\"start\":45985},{\"end\":46017,\"start\":46013},{\"end\":46036,\"start\":46028},{\"end\":46052,\"start\":46043},{\"end\":46371,\"start\":46360},{\"end\":46381,\"start\":46377},{\"end\":46389,\"start\":46387},{\"end\":46406,\"start\":46400},{\"end\":46424,\"start\":46416},{\"end\":46433,\"start\":46431},{\"end\":46448,\"start\":46443},{\"end\":46465,\"start\":46457},{\"end\":46480,\"start\":46474},{\"end\":46499,\"start\":46490},{\"end\":46812,\"start\":46805},{\"end\":46833,\"start\":46821},{\"end\":46848,\"start\":46841},{\"end\":47084,\"start\":47077},{\"end\":47248,\"start\":47240},{\"end\":47264,\"start\":47260},{\"end\":47281,\"start\":47273},{\"end\":47291,\"start\":47285},{\"end\":47303,\"start\":47298},{\"end\":47322,\"start\":47313},{\"end\":47330,\"start\":47324},{\"end\":47566,\"start\":47563},{\"end\":47572,\"start\":47568},{\"end\":47745,\"start\":47739},{\"end\":47973,\"start\":47965},{\"end\":47991,\"start\":47982},{\"end\":48223,\"start\":48213},{\"end\":48242,\"start\":48236},{\"end\":48259,\"start\":48249},{\"end\":48275,\"start\":48266},{\"end\":48297,\"start\":48284},{\"end\":48560,\"start\":48557},{\"end\":48573,\"start\":48569},{\"end\":48588,\"start\":48584},{\"end\":48601,\"start\":48597},{\"end\":48836,\"start\":48833},{\"end\":48852,\"start\":48847},{\"end\":48865,\"start\":48860},{\"end\":48876,\"start\":48871},{\"end\":48889,\"start\":48884},{\"end\":48904,\"start\":48900},{\"end\":48916,\"start\":48913},{\"end\":49115,\"start\":49112},{\"end\":49127,\"start\":49122},{\"end\":49142,\"start\":49138},{\"end\":49155,\"start\":49151},{\"end\":49432,\"start\":49429},{\"end\":49447,\"start\":49443},{\"end\":49460,\"start\":49456},{\"end\":49645,\"start\":49638},{\"end\":49654,\"start\":49651},{\"end\":49668,\"start\":49665},{\"end\":49685,\"start\":49677},{\"end\":49697,\"start\":49693},{\"end\":49716,\"start\":49708},{\"end\":49731,\"start\":49726},{\"end\":49750,\"start\":49741},{\"end\":49769,\"start\":49759},{\"end\":50062,\"start\":50055},{\"end\":50073,\"start\":50069},{\"end\":50100,\"start\":50093},{\"end\":50111,\"start\":50107},{\"end\":50338,\"start\":50331},{\"end\":50349,\"start\":50345},{\"end\":50376,\"start\":50369},{\"end\":50387,\"start\":50383},{\"end\":50610,\"start\":50607},{\"end\":50619,\"start\":50617},{\"end\":50761,\"start\":50755},{\"end\":50770,\"start\":50765},{\"end\":50785,\"start\":50779},{\"end\":50805,\"start\":50796},{\"end\":50820,\"start\":50812},{\"end\":50832,\"start\":50830},{\"end\":50847,\"start\":50841},{\"end\":50861,\"start\":50856},{\"end\":50865,\"start\":50863},{\"end\":51224,\"start\":51217},{\"end\":51238,\"start\":51231},{\"end\":51485,\"start\":51481},{\"end\":51497,\"start\":51493},{\"end\":51507,\"start\":51505},{\"end\":51521,\"start\":51516},{\"end\":51534,\"start\":51530},{\"end\":51545,\"start\":51541},{\"end\":51562,\"start\":51559},{\"end\":51797,\"start\":51793},{\"end\":51813,\"start\":51808},{\"end\":51824,\"start\":51820},{\"end\":51835,\"start\":51831},{\"end\":51845,\"start\":51843},{\"end\":51861,\"start\":51856},{\"end\":51876,\"start\":51872},{\"end\":51889,\"start\":51885},{\"end\":52135,\"start\":52131},{\"end\":52148,\"start\":52145},{\"end\":52160,\"start\":52157},{\"end\":52172,\"start\":52167},{\"end\":52362,\"start\":52358},{\"end\":52375,\"start\":52370},{\"end\":52387,\"start\":52382},{\"end\":52407,\"start\":52401},{\"end\":52626,\"start\":52622},{\"end\":52639,\"start\":52635},{\"end\":52651,\"start\":52647},{\"end\":52660,\"start\":52658},{\"end\":52672,\"start\":52670},{\"end\":52685,\"start\":52681},{\"end\":52700,\"start\":52696},{\"end\":52709,\"start\":52706},{\"end\":52985,\"start\":52981},{\"end\":52999,\"start\":52995},{\"end\":53284,\"start\":53280},{\"end\":53298,\"start\":53294},{\"end\":53308,\"start\":53306},{\"end\":53322,\"start\":53319},{\"end\":53336,\"start\":53331},{\"end\":53619,\"start\":53615},{\"end\":53630,\"start\":53628},{\"end\":53640,\"start\":53635},{\"end\":53653,\"start\":53650},{\"end\":53882,\"start\":53878},{\"end\":53895,\"start\":53890},{\"end\":53904,\"start\":53902},{\"end\":53919,\"start\":53915},{\"end\":54145,\"start\":54142},{\"end\":54160,\"start\":54155},{\"end\":54172,\"start\":54170},{\"end\":54181,\"start\":54177},{\"end\":54386,\"start\":54378},{\"end\":54401,\"start\":54393},{\"end\":54417,\"start\":54410},{\"end\":54431,\"start\":54427},{\"end\":54442,\"start\":54435},{\"end\":54453,\"start\":54448},{\"end\":54461,\"start\":54455},{\"end\":54471,\"start\":54465},{\"end\":54478,\"start\":54473},{\"end\":54486,\"start\":54482},{\"end\":54500,\"start\":54496},{\"end\":54516,\"start\":54510},{\"end\":54523,\"start\":54518},{\"end\":54853,\"start\":54849},{\"end\":54867,\"start\":54860},{\"end\":54873,\"start\":54869},{\"end\":55083,\"start\":55081},{\"end\":55091,\"start\":55089},{\"end\":55103,\"start\":55100},{\"end\":55115,\"start\":55112},{\"end\":55321,\"start\":55318},{\"end\":55339,\"start\":55334},{\"end\":55352,\"start\":55348},{\"end\":55363,\"start\":55361},{\"end\":55592,\"start\":55589},{\"end\":55607,\"start\":55599},{\"end\":55621,\"start\":55615},{\"end\":55633,\"start\":55631},{\"end\":55645,\"start\":55643},{\"end\":55892,\"start\":55879},{\"end\":55903,\"start\":55898},{\"end\":55917,\"start\":55913},{\"end\":55931,\"start\":55925},{\"end\":55940,\"start\":55933},{\"end\":56238,\"start\":56235},{\"end\":56251,\"start\":56247},{\"end\":56262,\"start\":56260},{\"end\":56274,\"start\":56269},{\"end\":56286,\"start\":56282},{\"end\":56299,\"start\":56297},{\"end\":56605,\"start\":56601},{\"end\":56618,\"start\":56614},{\"end\":56633,\"start\":56629},{\"end\":56643,\"start\":56639},{\"end\":56660,\"start\":56657},{\"end\":56671,\"start\":56668},{\"end\":56920,\"start\":56916},{\"end\":56935,\"start\":56931},{\"end\":56948,\"start\":56944},{\"end\":56960,\"start\":56957},{\"end\":56977,\"start\":56974},{\"end\":56988,\"start\":56985},{\"end\":57233,\"start\":57225},{\"end\":57348,\"start\":57346},{\"end\":57358,\"start\":57355},{\"end\":57373,\"start\":57369},{\"end\":57384,\"start\":57382},{\"end\":57660,\"start\":57656},{\"end\":57671,\"start\":57668},{\"end\":57683,\"start\":57680},{\"end\":57694,\"start\":57691},{\"end\":57711,\"start\":57708},{\"end\":57987,\"start\":57982},{\"end\":57999,\"start\":57995},{\"end\":58013,\"start\":58010},{\"end\":58023,\"start\":58020},{\"end\":58276,\"start\":58271},{\"end\":58290,\"start\":58286},{\"end\":58300,\"start\":58296},{\"end\":58310,\"start\":58308},{\"end\":58319,\"start\":58317},{\"end\":58333,\"start\":58329},{\"end\":58347,\"start\":58344},{\"end\":58657,\"start\":58652},{\"end\":58671,\"start\":58667},{\"end\":58681,\"start\":58679}]", "bib_entry": "[{\"attributes\":{\"doi\":\"arXiv:1611.01484v2\",\"id\":\"b0\"},\"end\":34811,\"start\":34467},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":216009},\"end\":35102,\"start\":34813},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":5025785},\"end\":35409,\"start\":35104},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":221341463},\"end\":35747,\"start\":35411},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":219964874},\"end\":36081,\"start\":35749},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":8923541},\"end\":36344,\"start\":36083},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":207891997},\"end\":36625,\"start\":36346},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":29573685},\"end\":36861,\"start\":36627},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":355163},\"end\":37193,\"start\":36863},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":227035159},\"end\":37487,\"start\":37195},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":220920024},\"end\":37740,\"start\":37489},{\"attributes\":{\"doi\":\"arXiv:2006.07576\",\"id\":\"b11\"},\"end\":38015,\"start\":37742},{\"attributes\":{\"doi\":\"arXiv:1706.02677\",\"id\":\"b12\"},\"end\":38456,\"start\":38017},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":219617174},\"end\":38736,\"start\":38458},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":2908606},\"end\":39040,\"start\":38738},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":13740328},\"end\":39358,\"start\":39042},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":206594692},\"end\":39589,\"start\":39360},{\"attributes\":{\"doi\":\"arXiv:1704.04861\",\"id\":\"b17\"},\"end\":40055,\"start\":39591},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":140309863},\"end\":40210,\"start\":40057},{\"attributes\":{\"id\":\"b19\"},\"end\":40592,\"start\":40212},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":209050760},\"end\":40979,\"start\":40594},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":5808102},\"end\":41262,\"start\":40981},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":7811489},\"end\":41581,\"start\":41264},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":3176168},\"end\":42058,\"start\":41583},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":195908774},\"end\":42328,\"start\":42060},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":206596594},\"end\":42616,\"start\":42330},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":1829423},\"end\":42866,\"start\":42618},{\"attributes\":{\"doi\":\"arXiv:1811.07548\",\"id\":\"b27\"},\"end\":43264,\"start\":42868},{\"attributes\":{\"id\":\"b28\"},\"end\":43386,\"start\":43266},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":28375094},\"end\":43823,\"start\":43388},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":1755257},\"end\":44235,\"start\":43825},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":12883586},\"end\":44466,\"start\":44237},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":14599182},\"end\":44663,\"start\":44468},{\"attributes\":{\"id\":\"b33\"},\"end\":44840,\"start\":44665},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":4637184},\"end\":45023,\"start\":44842},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":102487169},\"end\":45288,\"start\":45025},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":7350432},\"end\":45578,\"start\":45290},{\"attributes\":{\"id\":\"b37\"},\"end\":45851,\"start\":45580},{\"attributes\":{\"doi\":\"arXiv:1804.01159\",\"id\":\"b38\"},\"end\":46302,\"start\":45853},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":2930547},\"end\":46729,\"start\":46304},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":206592766},\"end\":47001,\"start\":46731},{\"attributes\":{\"id\":\"b41\"},\"end\":47178,\"start\":47003},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":6544744},\"end\":47523,\"start\":47180},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":128317783},\"end\":47655,\"start\":47525},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":45115551},\"end\":47889,\"start\":47657},{\"attributes\":{\"doi\":\"arXiv:1409.1556\",\"id\":\"b45\"},\"end\":48137,\"start\":47891},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":6844431},\"end\":48481,\"start\":48139},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":1395439},\"end\":48757,\"start\":48483},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":211296865},\"end\":49107,\"start\":48759},{\"attributes\":{\"doi\":\"arXiv:1502.00873\",\"id\":\"b49\"},\"end\":49358,\"start\":49109},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":206592295},\"end\":49594,\"start\":49360},{\"attributes\":{\"id\":\"b51\",\"matched_paper_id\":206592484},\"end\":49972,\"start\":49596},{\"attributes\":{\"id\":\"b52\",\"matched_paper_id\":2814088},\"end\":50279,\"start\":49974},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":9380519},\"end\":50522,\"start\":50281},{\"attributes\":{\"id\":\"b54\",\"matched_paper_id\":167217261},\"end\":50748,\"start\":50524},{\"attributes\":{\"id\":\"b55\"},\"end\":51110,\"start\":50750},{\"attributes\":{\"id\":\"b56\"},\"end\":51428,\"start\":51112},{\"attributes\":{\"id\":\"b57\",\"matched_paper_id\":51891464},\"end\":51734,\"start\":51430},{\"attributes\":{\"id\":\"b58\",\"matched_paper_id\":1806714},\"end\":52077,\"start\":51736},{\"attributes\":{\"id\":\"b59\",\"matched_paper_id\":9683805},\"end\":52293,\"start\":52079},{\"attributes\":{\"id\":\"b60\",\"matched_paper_id\":7680631},\"end\":52555,\"start\":52295},{\"attributes\":{\"id\":\"b61\",\"matched_paper_id\":68589},\"end\":52896,\"start\":52557},{\"attributes\":{\"doi\":\"arXiv:1911.10692\",\"id\":\"b62\"},\"end\":53179,\"start\":52898},{\"attributes\":{\"id\":\"b63\",\"matched_paper_id\":198968250},\"end\":53532,\"start\":53181},{\"attributes\":{\"id\":\"b64\",\"matched_paper_id\":219616178},\"end\":53806,\"start\":53534},{\"attributes\":{\"id\":\"b65\",\"matched_paper_id\":85529205},\"end\":54062,\"start\":53808},{\"attributes\":{\"id\":\"b66\",\"matched_paper_id\":4711865},\"end\":54330,\"start\":54064},{\"attributes\":{\"id\":\"b67\",\"matched_paper_id\":2141447},\"end\":54765,\"start\":54332},{\"attributes\":{\"id\":\"b68\",\"matched_paper_id\":9898157},\"end\":55013,\"start\":54767},{\"attributes\":{\"id\":\"b69\",\"matched_paper_id\":5351802},\"end\":55243,\"start\":55015},{\"attributes\":{\"id\":\"b70\",\"matched_paper_id\":207853355},\"end\":55517,\"start\":55245},{\"attributes\":{\"id\":\"b71\",\"matched_paper_id\":8485068},\"end\":55806,\"start\":55519},{\"attributes\":{\"doi\":\"arXiv:1905.00546\",\"id\":\"b72\"},\"end\":56121,\"start\":55808},{\"attributes\":{\"id\":\"b73\",\"matched_paper_id\":204401673},\"end\":56525,\"start\":56123},{\"attributes\":{\"id\":\"b74\",\"matched_paper_id\":214743143},\"end\":56862,\"start\":56527},{\"attributes\":{\"id\":\"b75\",\"matched_paper_id\":102352470},\"end\":57149,\"start\":56864},{\"attributes\":{\"id\":\"b76\",\"matched_paper_id\":1487550},\"end\":57339,\"start\":57151},{\"attributes\":{\"doi\":\"arXiv:1411.7923\",\"id\":\"b77\"},\"end\":57568,\"start\":57341},{\"attributes\":{\"id\":\"b78\",\"matched_paper_id\":52166730},\"end\":57888,\"start\":57570},{\"attributes\":{\"id\":\"b79\",\"matched_paper_id\":24982157},\"end\":58188,\"start\":57890},{\"attributes\":{\"id\":\"b80\",\"matched_paper_id\":219964919},\"end\":58545,\"start\":58190},{\"attributes\":{\"doi\":\"arXiv:1708.08197\",\"id\":\"b81\"},\"end\":58878,\"start\":58547}]", "bib_title": "[{\"end\":34874,\"start\":34813},{\"end\":35194,\"start\":35104},{\"end\":35487,\"start\":35411},{\"end\":35814,\"start\":35749},{\"end\":36146,\"start\":36083},{\"end\":36384,\"start\":36346},{\"end\":36666,\"start\":36627},{\"end\":36951,\"start\":36863},{\"end\":37275,\"start\":37195},{\"end\":37560,\"start\":37489},{\"end\":38509,\"start\":38458},{\"end\":38807,\"start\":38738},{\"end\":39133,\"start\":39042},{\"end\":39404,\"start\":39360},{\"end\":40088,\"start\":40057},{\"end\":40669,\"start\":40594},{\"end\":41073,\"start\":40981},{\"end\":41328,\"start\":41264},{\"end\":41677,\"start\":41583},{\"end\":42123,\"start\":42060},{\"end\":42389,\"start\":42330},{\"end\":42677,\"start\":42618},{\"end\":43438,\"start\":43388},{\"end\":43885,\"start\":43825},{\"end\":44291,\"start\":44237},{\"end\":44522,\"start\":44468},{\"end\":44863,\"start\":44842},{\"end\":45093,\"start\":45025},{\"end\":45340,\"start\":45290},{\"end\":45641,\"start\":45580},{\"end\":46353,\"start\":46304},{\"end\":46795,\"start\":46731},{\"end\":47228,\"start\":47180},{\"end\":47554,\"start\":47525},{\"end\":47731,\"start\":47657},{\"end\":48204,\"start\":48139},{\"end\":48552,\"start\":48483},{\"end\":48825,\"start\":48759},{\"end\":49424,\"start\":49360},{\"end\":49626,\"start\":49596},{\"end\":50047,\"start\":49974},{\"end\":50323,\"start\":50281},{\"end\":50596,\"start\":50524},{\"end\":51475,\"start\":51430},{\"end\":51787,\"start\":51736},{\"end\":52124,\"start\":52079},{\"end\":52351,\"start\":52295},{\"end\":52616,\"start\":52557},{\"end\":53274,\"start\":53181},{\"end\":53602,\"start\":53534},{\"end\":53867,\"start\":53808},{\"end\":54132,\"start\":54064},{\"end\":54368,\"start\":54332},{\"end\":54842,\"start\":54767},{\"end\":55073,\"start\":55015},{\"end\":55310,\"start\":55245},{\"end\":55579,\"start\":55519},{\"end\":56225,\"start\":56123},{\"end\":56595,\"start\":56527},{\"end\":56910,\"start\":56864},{\"end\":57217,\"start\":57151},{\"end\":57645,\"start\":57570},{\"end\":57972,\"start\":57890},{\"end\":58262,\"start\":58190}]", "bib_author": "[{\"end\":34545,\"start\":34531},{\"end\":34562,\"start\":34545},{\"end\":34572,\"start\":34562},{\"end\":34589,\"start\":34572},{\"end\":34602,\"start\":34589},{\"end\":34613,\"start\":34602},{\"end\":34887,\"start\":34876},{\"end\":34896,\"start\":34887},{\"end\":34907,\"start\":34896},{\"end\":34916,\"start\":34907},{\"end\":34931,\"start\":34916},{\"end\":34942,\"start\":34931},{\"end\":35208,\"start\":35196},{\"end\":35218,\"start\":35208},{\"end\":35229,\"start\":35218},{\"end\":35239,\"start\":35229},{\"end\":35504,\"start\":35489},{\"end\":35513,\"start\":35504},{\"end\":35528,\"start\":35513},{\"end\":35831,\"start\":35816},{\"end\":35840,\"start\":35831},{\"end\":35860,\"start\":35840},{\"end\":35874,\"start\":35860},{\"end\":35894,\"start\":35874},{\"end\":36163,\"start\":36148},{\"end\":36172,\"start\":36163},{\"end\":36192,\"start\":36172},{\"end\":36401,\"start\":36386},{\"end\":36410,\"start\":36401},{\"end\":36424,\"start\":36410},{\"end\":36437,\"start\":36424},{\"end\":36449,\"start\":36437},{\"end\":36459,\"start\":36449},{\"end\":36683,\"start\":36668},{\"end\":36697,\"start\":36683},{\"end\":36717,\"start\":36697},{\"end\":36967,\"start\":36953},{\"end\":36987,\"start\":36967},{\"end\":37000,\"start\":36987},{\"end\":37012,\"start\":37000},{\"end\":37287,\"start\":37277},{\"end\":37301,\"start\":37287},{\"end\":37315,\"start\":37301},{\"end\":37325,\"start\":37315},{\"end\":37574,\"start\":37562},{\"end\":37588,\"start\":37574},{\"end\":37594,\"start\":37588},{\"end\":37754,\"start\":37742},{\"end\":37768,\"start\":37754},{\"end\":37774,\"start\":37768},{\"end\":38030,\"start\":38017},{\"end\":38044,\"start\":38030},{\"end\":38059,\"start\":38044},{\"end\":38077,\"start\":38059},{\"end\":38096,\"start\":38077},{\"end\":38109,\"start\":38096},{\"end\":38125,\"start\":38109},{\"end\":38523,\"start\":38511},{\"end\":38532,\"start\":38523},{\"end\":38545,\"start\":38532},{\"end\":38557,\"start\":38545},{\"end\":38572,\"start\":38557},{\"end\":38582,\"start\":38572},{\"end\":38822,\"start\":38809},{\"end\":38833,\"start\":38822},{\"end\":38844,\"start\":38833},{\"end\":38857,\"start\":38844},{\"end\":38871,\"start\":38857},{\"end\":39147,\"start\":39135},{\"end\":39162,\"start\":39147},{\"end\":39176,\"start\":39162},{\"end\":39186,\"start\":39176},{\"end\":39418,\"start\":39406},{\"end\":39433,\"start\":39418},{\"end\":39447,\"start\":39433},{\"end\":39457,\"start\":39447},{\"end\":39685,\"start\":39675},{\"end\":39702,\"start\":39685},{\"end\":39710,\"start\":39702},{\"end\":39723,\"start\":39710},{\"end\":39744,\"start\":39723},{\"end\":39757,\"start\":39744},{\"end\":39771,\"start\":39757},{\"end\":39790,\"start\":39771},{\"end\":39796,\"start\":39790},{\"end\":40098,\"start\":40090},{\"end\":40107,\"start\":40098},{\"end\":40117,\"start\":40107},{\"end\":40319,\"start\":40311},{\"end\":40331,\"start\":40319},{\"end\":40346,\"start\":40331},{\"end\":40357,\"start\":40346},{\"end\":40373,\"start\":40357},{\"end\":40683,\"start\":40671},{\"end\":40695,\"start\":40683},{\"end\":40705,\"start\":40695},{\"end\":40719,\"start\":40705},{\"end\":40735,\"start\":40719},{\"end\":40747,\"start\":40735},{\"end\":40757,\"start\":40747},{\"end\":40771,\"start\":40757},{\"end\":41089,\"start\":41075},{\"end\":41108,\"start\":41089},{\"end\":41358,\"start\":41330},{\"end\":41368,\"start\":41358},{\"end\":41382,\"start\":41368},{\"end\":41395,\"start\":41382},{\"end\":41405,\"start\":41395},{\"end\":41700,\"start\":41679},{\"end\":41712,\"start\":41700},{\"end\":41729,\"start\":41712},{\"end\":41745,\"start\":41729},{\"end\":41761,\"start\":41745},{\"end\":41776,\"start\":41761},{\"end\":41790,\"start\":41776},{\"end\":41795,\"start\":41790},{\"end\":41801,\"start\":41795},{\"end\":42142,\"start\":42125},{\"end\":42158,\"start\":42142},{\"end\":42177,\"start\":42158},{\"end\":42404,\"start\":42391},{\"end\":42417,\"start\":42404},{\"end\":42429,\"start\":42417},{\"end\":42438,\"start\":42429},{\"end\":42451,\"start\":42438},{\"end\":42460,\"start\":42451},{\"end\":42692,\"start\":42679},{\"end\":42705,\"start\":42692},{\"end\":42717,\"start\":42705},{\"end\":42728,\"start\":42717},{\"end\":42881,\"start\":42868},{\"end\":42893,\"start\":42881},{\"end\":42902,\"start\":42893},{\"end\":42910,\"start\":42902},{\"end\":42921,\"start\":42910},{\"end\":42931,\"start\":42921},{\"end\":42941,\"start\":42931},{\"end\":42951,\"start\":42941},{\"end\":43320,\"start\":43306},{\"end\":43454,\"start\":43440},{\"end\":43469,\"start\":43454},{\"end\":43478,\"start\":43469},{\"end\":43493,\"start\":43478},{\"end\":43504,\"start\":43493},{\"end\":43520,\"start\":43504},{\"end\":43526,\"start\":43520},{\"end\":43534,\"start\":43526},{\"end\":43540,\"start\":43534},{\"end\":43560,\"start\":43540},{\"end\":43577,\"start\":43560},{\"end\":43585,\"start\":43577},{\"end\":43909,\"start\":43887},{\"end\":43933,\"start\":43909},{\"end\":43951,\"start\":43933},{\"end\":43966,\"start\":43951},{\"end\":43980,\"start\":43966},{\"end\":44000,\"start\":43980},{\"end\":44305,\"start\":44293},{\"end\":44333,\"start\":44305},{\"end\":44537,\"start\":44524},{\"end\":44553,\"start\":44537},{\"end\":44721,\"start\":44707},{\"end\":44734,\"start\":44721},{\"end\":44740,\"start\":44734},{\"end\":44874,\"start\":44865},{\"end\":44889,\"start\":44874},{\"end\":44905,\"start\":44889},{\"end\":44916,\"start\":44905},{\"end\":45135,\"start\":45095},{\"end\":45142,\"start\":45135},{\"end\":45361,\"start\":45342},{\"end\":45375,\"start\":45361},{\"end\":45390,\"start\":45375},{\"end\":45408,\"start\":45390},{\"end\":45420,\"start\":45408},{\"end\":45662,\"start\":45643},{\"end\":45684,\"start\":45662},{\"end\":45699,\"start\":45684},{\"end\":45954,\"start\":45939},{\"end\":45968,\"start\":45954},{\"end\":45979,\"start\":45968},{\"end\":46003,\"start\":45979},{\"end\":46019,\"start\":46003},{\"end\":46038,\"start\":46019},{\"end\":46054,\"start\":46038},{\"end\":46373,\"start\":46355},{\"end\":46383,\"start\":46373},{\"end\":46391,\"start\":46383},{\"end\":46408,\"start\":46391},{\"end\":46426,\"start\":46408},{\"end\":46435,\"start\":46426},{\"end\":46450,\"start\":46435},{\"end\":46467,\"start\":46450},{\"end\":46482,\"start\":46467},{\"end\":46501,\"start\":46482},{\"end\":46814,\"start\":46797},{\"end\":46835,\"start\":46814},{\"end\":46850,\"start\":46835},{\"end\":47086,\"start\":47075},{\"end\":47250,\"start\":47230},{\"end\":47266,\"start\":47250},{\"end\":47283,\"start\":47266},{\"end\":47293,\"start\":47283},{\"end\":47305,\"start\":47293},{\"end\":47324,\"start\":47305},{\"end\":47332,\"start\":47324},{\"end\":47568,\"start\":47556},{\"end\":47574,\"start\":47568},{\"end\":47747,\"start\":47733},{\"end\":47975,\"start\":47959},{\"end\":47993,\"start\":47975},{\"end\":48225,\"start\":48206},{\"end\":48244,\"start\":48225},{\"end\":48261,\"start\":48244},{\"end\":48277,\"start\":48261},{\"end\":48299,\"start\":48277},{\"end\":48562,\"start\":48554},{\"end\":48575,\"start\":48562},{\"end\":48590,\"start\":48575},{\"end\":48603,\"start\":48590},{\"end\":48838,\"start\":48827},{\"end\":48854,\"start\":48838},{\"end\":48867,\"start\":48854},{\"end\":48878,\"start\":48867},{\"end\":48891,\"start\":48878},{\"end\":48906,\"start\":48891},{\"end\":48918,\"start\":48906},{\"end\":49117,\"start\":49109},{\"end\":49129,\"start\":49117},{\"end\":49144,\"start\":49129},{\"end\":49157,\"start\":49144},{\"end\":49434,\"start\":49426},{\"end\":49449,\"start\":49434},{\"end\":49462,\"start\":49449},{\"end\":49647,\"start\":49628},{\"end\":49656,\"start\":49647},{\"end\":49670,\"start\":49656},{\"end\":49687,\"start\":49670},{\"end\":49699,\"start\":49687},{\"end\":49718,\"start\":49699},{\"end\":49733,\"start\":49718},{\"end\":49752,\"start\":49733},{\"end\":49771,\"start\":49752},{\"end\":50064,\"start\":50049},{\"end\":50075,\"start\":50064},{\"end\":50102,\"start\":50075},{\"end\":50113,\"start\":50102},{\"end\":50340,\"start\":50325},{\"end\":50351,\"start\":50340},{\"end\":50378,\"start\":50351},{\"end\":50389,\"start\":50378},{\"end\":50612,\"start\":50598},{\"end\":50621,\"start\":50612},{\"end\":50763,\"start\":50750},{\"end\":50772,\"start\":50763},{\"end\":50787,\"start\":50772},{\"end\":50807,\"start\":50787},{\"end\":50822,\"start\":50807},{\"end\":50834,\"start\":50822},{\"end\":50849,\"start\":50834},{\"end\":50863,\"start\":50849},{\"end\":50867,\"start\":50863},{\"end\":51226,\"start\":51211},{\"end\":51240,\"start\":51226},{\"end\":51487,\"start\":51477},{\"end\":51499,\"start\":51487},{\"end\":51509,\"start\":51499},{\"end\":51523,\"start\":51509},{\"end\":51536,\"start\":51523},{\"end\":51547,\"start\":51536},{\"end\":51564,\"start\":51547},{\"end\":51799,\"start\":51789},{\"end\":51815,\"start\":51799},{\"end\":51826,\"start\":51815},{\"end\":51837,\"start\":51826},{\"end\":51847,\"start\":51837},{\"end\":51863,\"start\":51847},{\"end\":51878,\"start\":51863},{\"end\":51891,\"start\":51878},{\"end\":52137,\"start\":52126},{\"end\":52150,\"start\":52137},{\"end\":52162,\"start\":52150},{\"end\":52174,\"start\":52162},{\"end\":52364,\"start\":52353},{\"end\":52377,\"start\":52364},{\"end\":52389,\"start\":52377},{\"end\":52409,\"start\":52389},{\"end\":52628,\"start\":52618},{\"end\":52641,\"start\":52628},{\"end\":52653,\"start\":52641},{\"end\":52662,\"start\":52653},{\"end\":52674,\"start\":52662},{\"end\":52687,\"start\":52674},{\"end\":52702,\"start\":52687},{\"end\":52711,\"start\":52702},{\"end\":52987,\"start\":52977},{\"end\":53001,\"start\":52987},{\"end\":53286,\"start\":53276},{\"end\":53300,\"start\":53286},{\"end\":53310,\"start\":53300},{\"end\":53324,\"start\":53310},{\"end\":53338,\"start\":53324},{\"end\":53621,\"start\":53604},{\"end\":53632,\"start\":53621},{\"end\":53642,\"start\":53632},{\"end\":53655,\"start\":53642},{\"end\":53884,\"start\":53869},{\"end\":53897,\"start\":53884},{\"end\":53906,\"start\":53897},{\"end\":53921,\"start\":53906},{\"end\":54147,\"start\":54134},{\"end\":54162,\"start\":54147},{\"end\":54174,\"start\":54162},{\"end\":54183,\"start\":54174},{\"end\":54388,\"start\":54370},{\"end\":54403,\"start\":54388},{\"end\":54419,\"start\":54403},{\"end\":54433,\"start\":54419},{\"end\":54444,\"start\":54433},{\"end\":54455,\"start\":54444},{\"end\":54463,\"start\":54455},{\"end\":54473,\"start\":54463},{\"end\":54480,\"start\":54473},{\"end\":54488,\"start\":54480},{\"end\":54502,\"start\":54488},{\"end\":54518,\"start\":54502},{\"end\":54525,\"start\":54518},{\"end\":54855,\"start\":54844},{\"end\":54869,\"start\":54855},{\"end\":54875,\"start\":54869},{\"end\":55085,\"start\":55075},{\"end\":55093,\"start\":55085},{\"end\":55105,\"start\":55093},{\"end\":55117,\"start\":55105},{\"end\":55323,\"start\":55312},{\"end\":55341,\"start\":55323},{\"end\":55354,\"start\":55341},{\"end\":55365,\"start\":55354},{\"end\":55594,\"start\":55581},{\"end\":55609,\"start\":55594},{\"end\":55623,\"start\":55609},{\"end\":55635,\"start\":55623},{\"end\":55647,\"start\":55635},{\"end\":55894,\"start\":55873},{\"end\":55905,\"start\":55894},{\"end\":55919,\"start\":55905},{\"end\":55933,\"start\":55919},{\"end\":55942,\"start\":55933},{\"end\":56240,\"start\":56227},{\"end\":56253,\"start\":56240},{\"end\":56264,\"start\":56253},{\"end\":56276,\"start\":56264},{\"end\":56288,\"start\":56276},{\"end\":56301,\"start\":56288},{\"end\":56607,\"start\":56597},{\"end\":56620,\"start\":56607},{\"end\":56635,\"start\":56620},{\"end\":56645,\"start\":56635},{\"end\":56662,\"start\":56645},{\"end\":56673,\"start\":56662},{\"end\":56922,\"start\":56912},{\"end\":56937,\"start\":56922},{\"end\":56950,\"start\":56937},{\"end\":56962,\"start\":56950},{\"end\":56979,\"start\":56962},{\"end\":56990,\"start\":56979},{\"end\":57235,\"start\":57219},{\"end\":57350,\"start\":57341},{\"end\":57360,\"start\":57350},{\"end\":57375,\"start\":57360},{\"end\":57386,\"start\":57375},{\"end\":57662,\"start\":57647},{\"end\":57673,\"start\":57662},{\"end\":57685,\"start\":57673},{\"end\":57696,\"start\":57685},{\"end\":57713,\"start\":57696},{\"end\":57989,\"start\":57974},{\"end\":58001,\"start\":57989},{\"end\":58015,\"start\":58001},{\"end\":58025,\"start\":58015},{\"end\":58278,\"start\":58264},{\"end\":58292,\"start\":58278},{\"end\":58302,\"start\":58292},{\"end\":58312,\"start\":58302},{\"end\":58321,\"start\":58312},{\"end\":58335,\"start\":58321},{\"end\":58349,\"start\":58335},{\"end\":58659,\"start\":58644},{\"end\":58673,\"start\":58659},{\"end\":58683,\"start\":58673}]", "bib_venue": "[{\"end\":34529,\"start\":34467},{\"end\":34944,\"start\":34942},{\"end\":35243,\"start\":35239},{\"end\":35532,\"start\":35528},{\"end\":35907,\"start\":35894},{\"end\":36196,\"start\":36192},{\"end\":36472,\"start\":36459},{\"end\":36730,\"start\":36717},{\"end\":37015,\"start\":37012},{\"end\":37329,\"start\":37325},{\"end\":37598,\"start\":37594},{\"end\":37852,\"start\":37790},{\"end\":38229,\"start\":38141},{\"end\":38586,\"start\":38582},{\"end\":38875,\"start\":38871},{\"end\":39190,\"start\":39186},{\"end\":39461,\"start\":39457},{\"end\":39673,\"start\":39591},{\"end\":40121,\"start\":40117},{\"end\":40309,\"start\":40212},{\"end\":40775,\"start\":40771},{\"end\":41112,\"start\":41108},{\"end\":41409,\"start\":41405},{\"end\":41805,\"start\":41801},{\"end\":42184,\"start\":42177},{\"end\":42464,\"start\":42460},{\"end\":42732,\"start\":42728},{\"end\":43059,\"start\":42967},{\"end\":43304,\"start\":43266},{\"end\":43588,\"start\":43585},{\"end\":44013,\"start\":44000},{\"end\":44337,\"start\":44333},{\"end\":44557,\"start\":44553},{\"end\":44705,\"start\":44665},{\"end\":44920,\"start\":44916},{\"end\":45148,\"start\":45142},{\"end\":45424,\"start\":45420},{\"end\":45709,\"start\":45699},{\"end\":45937,\"start\":45853},{\"end\":46505,\"start\":46501},{\"end\":46854,\"start\":46850},{\"end\":47073,\"start\":47003},{\"end\":47336,\"start\":47332},{\"end\":47578,\"start\":47574},{\"end\":47767,\"start\":47747},{\"end\":47957,\"start\":47891},{\"end\":48302,\"start\":48299},{\"end\":48610,\"start\":48603},{\"end\":48922,\"start\":48918},{\"end\":49220,\"start\":49173},{\"end\":49466,\"start\":49462},{\"end\":49775,\"start\":49771},{\"end\":50117,\"start\":50113},{\"end\":50393,\"start\":50389},{\"end\":50625,\"start\":50621},{\"end\":50902,\"start\":50867},{\"end\":51209,\"start\":51112},{\"end\":51568,\"start\":51564},{\"end\":51895,\"start\":51891},{\"end\":52177,\"start\":52174},{\"end\":52415,\"start\":52409},{\"end\":52715,\"start\":52711},{\"end\":52975,\"start\":52898},{\"end\":53342,\"start\":53338},{\"end\":53659,\"start\":53655},{\"end\":53925,\"start\":53921},{\"end\":54187,\"start\":54183},{\"end\":54538,\"start\":54525},{\"end\":54879,\"start\":54875},{\"end\":55121,\"start\":55117},{\"end\":55369,\"start\":55365},{\"end\":55651,\"start\":55647},{\"end\":55871,\"start\":55808},{\"end\":56314,\"start\":56301},{\"end\":56686,\"start\":56673},{\"end\":56994,\"start\":56990},{\"end\":57238,\"start\":57235},{\"end\":57442,\"start\":57401},{\"end\":57720,\"start\":57713},{\"end\":58029,\"start\":58025},{\"end\":58359,\"start\":58349},{\"end\":58642,\"start\":58547}]"}}}, "year": 2023, "month": 12, "day": 17}