{"id": 163164623, "updated": "2022-02-09 14:03:29.029", "metadata": {"title": "BRIC: Locality-based Encoding for Energy-Efficient Brain-Inspired Hyperdimensional Computing", "authors": "[{\"middle\":[],\"last\":\"Imani\",\"first\":\"Mohsen\"},{\"middle\":[],\"last\":\"Morris\",\"first\":\"Justin\"},{\"middle\":[],\"last\":\"Messerly\",\"first\":\"John\"},{\"middle\":[],\"last\":\"Shu\",\"first\":\"Helen\"},{\"middle\":[],\"last\":\"Deng\",\"first\":\"Yaobang\"},{\"middle\":[],\"last\":\"Rosing\",\"first\":\"Tajana\"}]", "venue": "2019 56th ACM/IEEE Design Automation Conference (DAC)", "journal": "2019 56th ACM/IEEE Design Automation Conference (DAC)", "publication_date": {"year": 2019, "month": null, "day": null}, "abstract": "Brain-inspired Hyperdimensional (HD) computing is a new computing paradigm emulating the neuron\u2019s activity in high-dimensional space. The first step in HD computing is to map each data point into high-dimensional space (e.g., 10,000), which requires the computation of thousands of operations for each element of data in the original domain. Encoding alone takes about 80% of the execution time of training. In this paper, we propose BRIC, a fully binary Brain-Inspired Classifier based on HD computing for energy-efficient and high-accuracy classification. BRIC introduces a novel encoding module based on random projection with a predictable memory access pattern which can efficiently be implemented in hardware. BRIC is the first HD-based approach which provides data projection with a 1:1 ratio to the original data and enables all training/inference computation to be performed using binary hypervectors. To further improve BRIC efficiency, we develop an online dimension reduction approach which removes insignificant hypervector dimensions during training. Additionally, we designed a fully pipelined FPGA implementation which accelerates BRIC in both training and inference phases. Our evaluation of BRIC a wide range of classification applications show that BRIC can achieve $64.1 \\times$ and $9.8 \\times (43.8 \\times$ and $6.1 \\times) $ energy efficiency and speed up as compared to baseline HD computing during training (inference) while providing the same classification accuracy.CCS CONCEPTS\u2022 Computing methodologies $\\rightarrow$ Machinelearningapproaches; Supervised learning;", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": "2946584982", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/dac/ImaniMMSDR19", "doi": "10.1145/3316781.3317785"}}, "content": {"source": {"pdf_hash": "52c7bc4f04ab92a006e2f40092c871236afdc0a6", "pdf_src": "ACM", "pdf_uri": null, "oa_url_match": false, "oa_info": {"license": null, "open_access_url": "https://dl.acm.org/doi/pdf/10.1145/3316781.3317785", "status": "BRONZE"}}, "grobid": {"id": "eb824655f1bea1fd8a5c0c0b603bd735f24f56ff", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/52c7bc4f04ab92a006e2f40092c871236afdc0a6.txt", "contents": "\nBRIC: Locality-based Encoding for Energy-Efficient Brain-Inspired Hyperdimensional Computing\n\n\nMohsen Imani moimani@ucsd.edu \nCSE Department\nUC San Diego\nLa Jolla92093CAUSA\n\nJustin Morris j1morris@ucsd.edu \nCSE Department\nUC San Diego\nLa Jolla92093CAUSA\n\nJohn Messerly jmesserl@ucsd.edu \nCSE Department\nUC San Diego\nLa Jolla92093CAUSA\n\nHelen Shu hsshu@ucsd.edu \nCSE Department\nUC San Diego\nLa Jolla92093CAUSA\n\nYaobang Deng \nCSE Department\nUC San Diego\nLa Jolla92093CAUSA\n\nTajana Rosing tajana@ucsd.edu \nCSE Department\nUC San Diego\nLa Jolla92093CAUSA\n\nMohsen Imani \nCSE Department\nUC San Diego\nLa Jolla92093CAUSA\n\nJustin Morris \nCSE Department\nUC San Diego\nLa Jolla92093CAUSA\n\nJohn Messerly \nCSE Department\nUC San Diego\nLa Jolla92093CAUSA\n\nHelen Shu \nCSE Department\nUC San Diego\nLa Jolla92093CAUSA\n\nYaobang Deng \nCSE Department\nUC San Diego\nLa Jolla92093CAUSA\n\nBRIC: Locality-based Encoding for Energy-Efficient Brain-Inspired Hyperdimensional Computing\n10.1145/3316781.3317785ACM Reference Format: Tajana Rosing. 2019. BRIC: Locality-based Encoding for Energy-Efficient Brain-Inspired Hyperdimensional Computing. In The 56th Annual Design Automation Conference 2019 (DAC '19), June 2-6, 2019, Las Vegas, NV, USA. ACM, New York, NY, USA, 6 pages. https://CCS CONCEPTS \u2022 Computing methodologies \u2192 Machine learning approachesSupervised learningKEYWORDS Brain-inspired computing, Hyperdimensional computing, Machine learning, Energy efficiency\nBrain-inspired Hyperdimensional (HD) computing is a new computing paradigm emulating the neuron's activity in high-dimensional space. The first step in HD computing is to map each data point into high-dimensional space (e.g., 10,000), which requires the computation of thousands of operations for each element of data in the original domain. Encoding alone takes about 80% of the execution time of training. In this paper, we propose BRIC, a fully binary Brain-Inspired Classifier based on HD computing for energyefficient and high-accuracy classification. BRIC introduces a novel encoding module based on random projection with a predictable memory access pattern which can efficiently be implemented in hardware. BRIC is the first HD-based approach which provides data projection with a 1:1 ratio to the original data and enables all training/inference computation to be performed using binary hypervectors. To further improve BRIC efficiency, we develop an online dimension reduction approach which removes insignificant hypervector dimensions during training. Additionally, we designed a fully pipelined FPGA implementation which accelerates BRIC in both training and inference phases. Our evaluation of BRIC a wide range of classification applications show that BRIC can achieve 64.1\u00d7 and 9.8\u00d7 (43.8\u00d7 and 6.1\u00d7) energy efficiency and speed up as compared to baseline HD computing during training (inference) while providing the same classification accuracy.\n\nINTRODUCTION\n\nThe emergence of the Internet of Things (IoT) has led to a copious amount of small connected embedded devices. Many of these devices need to perform classification tasks such as speech recognition, activity recognition, face detection, and medical diagnosis [1,2]. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. DAC ' However, these small embedded devices do not have the computing power to run sophisticated classification algorithms such as Deep Neural Networks(DNN) [3]. To resolve this, many devices send the data they collect to the cloud and the cloud performs the inference task, sending the result back to the embedded device. This leads to new problems such as network usage and user security [4]. In order to solve these new issues and still provide a way for these embedded devices to perform classification tasks, we need a light-weight classification algorithm that can achieve comparable accuracy to sophisticated resource-intensive algorithms.\n\nBrain-inspired Hyperdimensional (HD) computing has been proposed as the alternative computing method that processes the cognitive tasks in a more light-weight way [5]. HD computing is developed based on the fact that brains compute with patterns of neural activity [5]. Recent research utilized high dimension vectors (e.g., more than a thousand dimension), called hypervectors, to represent the neural activities, and showed successful progress for many cognitive tasks such as activity recognition, object recognition, language recognition, and bio-signal classification [6][7][8]. HD computing offers an efficient learning strategy without overcomplex computation steps such as back propagation in neural networks. In addition, it builds upon a well-defined set of operations with random HD vectors which makes the learning model extremely robust in the possible presence of hardware failures.\n\nIn HD computing, training data points are combined into a set of hypervectors, called an HD model, through light-weight computation steps. Each hypervector in the model represents a class of the target classification problem. Most of the proposed HD computing work exploit binarized hypervectors to reduce the computational/memory intensity in HD computing [9,10]. However, the existing HD computing algorithms [9] have two main challenges: (i) the encoding is computationally expensive, as it requires the computation of thousands (e.g., 10,000) of operations to map each element of data from the original domain to high-dimensional space [8,11]. For example, our experiments on five practical applications (described in Section 6.1) show that in HD computing the encoding module takes about 79% and 74% of the training and inference time.\n\n(ii) In addition, HD computing using binary encoded vectors provides significantly lower classification accuracy. In other words, HD computing requires non-binary (integer) vectors in order to provide acceptable accuracy. However, working with non-binary vectors significantly increases the memory requirement and the computation complexity of training and inference.\n\nIn this paper, we propose BRIC, a fully binary Brain-Inspired Classifier based on HD computing for energy-efficient and highaccuracy classification. BRIC introduces a novel encoding module based on random projection with a predictable memory access pattern which can be efficiently implemented in hardware. In contrast to existing HD computing algorithms that increase the size of encoded data by 20\u00d7 [9], BRIC is the first HD-based approach which provides data projection with a 1:1 ratio to the original data. In addition, BRIC enables all training/inference computation to be performed using binary hypervectors. The low memory requirement and computation cost makes BRIC a suitable candidate for Energy Consum.(\u03bcJ) Figure 1: Energy consumption of HD encoding, training, and inference. embedded devices with limited resources. To further improve BRIC efficiency, we developed an online dimension reduction approach which removes insignificant hypervector dimensions during training. Additionally, we designed a fully pipelined FPGA implementation which accelerates BRIC in both training and inference phases. Our evaluation on five practical classification applications, shows that BRIC can achieve 64.1\u00d7 and 9.8\u00d7 (43.8\u00d7 and 6.1\u00d7) energy efficiency and speed up as compared to baseline HD during training (inference) while providing the same classification accuracy.\n\n\nRELATED WORK & MOTIVATION\n\nPrior work tried to apply the idea of high-dimensional computing to different classification problems such as language recognition, speech recognition, face detection, EMG gesture detection, humancomputer interaction, and sensor fusion prediction [6,[8][9][10][12][13][14]. For example, work in [11] proposed a simple and scalable alternative to latent semantic analysis. Additionally, work in [8] proposed a new HD encoding based on random indexing for recognizing a text's language by generating and comparing text hypervectors. Work in [15] proposed an encoding method to map and classify biosignal sensory data in high dimensional space. Work in [7,9] proposed a general encoding module that maps feature vectors into high-dimensional space while keeping most of the original data.\n\nPrior work also tried to design hardware acceleration for HD computing by mapping its operations into hardware, e.g., in-memory architecture [16][17][18][19][20][21], and tried to accelerate HD computing in hardware by binarizing the class hypervectors [22] or removing dimensions of the class hypervectors [23]. Work in [24] designed an FPGA implementation to accelerate HD computation in the binary domain. However, the application of these approaches is limited to simple classification problems such as language recognition [8]. In order to provide acceptable classification accuracy, all these approaches have to train the model using non-binary (integer) vectors. However, using non-binary vectors requires a large memory footprint and computation cost in both training and inference.\n\nIn this work, we observe that the existing encoding modules are algorithmically and computationally inefficient. In addition, in order to get high accuracy, the encoding needs to map data into vectors with integer values which significantly increases the data size [9,10]. This large size memory is not often available on embedded devices with limited resources. Figure 1 shows the energy consumption of encoding, training, and inference (associative search) when running a single data point on five practical applications. Our evaluation shows that the encoding module on average takes 4.7\u00d7 and 3.8\u00d7 higher energy than HD training and inference. In this work, we propose a novel encoding approach that (i) significantly reduces the encoding computation cost by introducing computation locality and (ii) provides high classification accuracy while mapping data into binary vectors with much lower dimensionality than existing algorithms. Additionally, training can be performed using encoded vectors in the binary domain. Our approach also simplifies the inference similarity check to Hamming distance with minimal quality loss as compared to the existing HD computing algorithm with an integer model. We also propose a fully pipelined FPGA implementation that accelerates a wide range of classification problems during training and inference.\n\n\nPROPOSED BRIC\n\nIn this paper, we propose BRIC, a novel framework for fully binary classification. BRIC consists of three main modules shown in Figure 2: encoding, training, and testing. The encoding module maps each data point to binary high-dimensional space. Our encoding has been designed to map the maximum amount of information to high dimensional space with the minimum computation cost.\n\nBinarizing the model enables BRIC inference to be supported using a low-cost Hamming distance similarity check. In the following, we explain the details of BRIC functionality.\n\n\nEncoding\n\nRandom Projection: Figure 2 \u2022 A shows the overview of BRIC performing the classification task. Before we can work in high dimension space, we first need to encode the data to hypervectors. We desire a fast and hardware-friendly algorithm that can take a vector of real-valued data and generate a binary code such that the encoding preserves the cosine similarity. Let us assume A, B \u2208 R n are two feature vectors in the original domain with real values. We wish to define an encoding operation \u03bb( * ) such that:\n{X = \u03bb(A), Y = \u03bb(B) , X, Y \u2208 {1, \u22121} D } \u03b4 (A, B) = \u03b4 (X, Y) where \u03b4 ( * )\nis the cosine similarity. Since the cosine angle of binary vectors is determined by how many bits match, the cosine angle and Hamming distance are proportional. This type of encoding can be performed using Locality Sensitive Hash algorithms, such as Random Projection [25]. Let us assume a feature vector\nF = { f 1 , f 2 , . . . , f n }, with n features (f i \u2208 N) in original do- main.\nThe goal of random projection is to map this feature vector to a D dimensional space vector:\nH = {h 1 , h 2 , . . . , h D }. As Fig- ure 3a\nshows, random projection generates D dense bipolar vectors with the same dimensionality as original domain,\n{P 1 , P 2 , . . . , P D }, where P i \u2208 {\u22121, 1} n .\nThe inner product of a feature vector with each randomly generated vector gives us a single dimension of a hypervector in high-dimensional space. For example, we can compute the i \u2212 th dimension of the encoded data as:\nh i = si\u0434n(P i \u00b7 F)\nwhere si\u0434n is a sign function which maps the result of the dot product to +1 or -1 values. This type of hashing involves a large amount of multiplications/additions which is inefficient in hardware. For example, to map a feature vector from n to D dimensions, this encoding involves n \u00d7 D multiplication and addition operations.\n\n\nSparse Random Encoding:\n\nThe efficiency of random projection can be improved by sparsifying each projection vector. Instead of generating dense projection vectors, we can generate sparse projection vectors (Figure 3b). Consider s as a sparsity of each projection vector. Then, for each sparse projection vector, only s% of the vector's elements are randomly generated and the rest are set to zero. For example, if s = 5%, each projection vector only has 0.05 \u00d7 n non-zero elements. Therefore, each dimension of the encoded hypervector can be computed with only 0.05\u00d7n multiplication/addition operations. Therefore, encoding a single hypervector takes s \u00d7n\u00d7D multiplication/addition operations, compared to n\u00d7D multiplication/addition operations with dense projection vectors. Although the sparsity significantly reduces the number of arithmetic operations, it introduces random accesses to the algorithm, which is hard on the cache and slows down the computation.\n\nLocality-based Sparse Random Projection: Here we propose a novel approach that keeps the advantages of a sparse projection matrix, i.e., fewer operations, while removing random accesses to make the algorithm more hardware friendly. We propose a localitybased random projection encoding that uses a predictable access pattern. Instead of selecting s% random indices of the projection matrix to be non-zero, we approximate sparse random projection by selecting pre-defined indices to be non-zero. Figure 3c shows the structure of the locality-based matrix. Our approach selects the first s \u00d7 n of the P 1 vector to be non-zero (indices [1...s \u00d7 n]). Similarly, P 2 projection vector only has s \u00d7 n non-zero elements on indices [2...s \u00d7 n \u2212 1]. Finally, P D contains non-zero elements on the last s \u00d7 n dimensions. This creates a clear spacial locality pattern that hardware accelerators can take advantage of. Figure 4 shows the overview of BRIC encoding mapping each n dimensional feature vector to a D dimensional binary hypervector. BRIC simplifies the projection matrix to a single dense random projection vector with D bipolar values. Our approach first replicates the feature vector, F, such that it extends to D dimensions, the same as our desired high-dimensional vector. For example, to encode a feature vector with n = 500 features to D = 4, 000 dimensions, we need to concatenate 8 copies of a feature vector together. Then, it generates a random D dimensional projection vector, P, next to the extended feature vector (as shown in Figure 4). To compute the dimensions of the high-dimensional vector, BRIC takes the dot product of the extended feature vector with each projection vector in an N -gram window. The first N -gram calculates the dot product of the first N features and N projection vector elements:\nh 1 = si\u0434n(f 1 * p 1 + f 2 * p 2 + ... + f N * p N )\nSimilarly, the N -gram window shifts by a single position to generate the next feature values. So, we can compute the i th dimension of an encoded hypervector using:\nh i = si\u0434n(f i * p i + f i+1 * p i+1 + ... + f i+N * p i+N )\nEach step of the N -gram window corresponds to a multiplication with a sparse projection vector in the projection matrix. Although this encoding has the same number of computations as sparse random projection, it provides the following advantages: (i) it removes random accesses from the feature selection by introducing spacial locality, which significantly reduces the cost of hardware implementation. (ii) There is an opportunity for computation reuse, as every neighboring dimension shares N \u2212 1 terms.\n\n\nBRIC Training\n\nInitial Training: Figure 2 \u2022 B shows the functionality of BRIC during training. In HD computing, training is performed by elementwise addition of all encoded hypervectors in each existing class.   \n\n\nBRIC Inference\n\nAfter training and retraining, the HD model can now be used for inference (Figure 2 \u2022 D ). Upon inference, an input data is encoded to a query hypervector using the same encoding module used for training. HD computing then compares the similarity of the query hypervector with all stored class hypervectors and selects the class with the highest similarity. Since BRIC generates a binary model, it uses Hamming distance metrics to find a class hypervector with the most similarity to the query hypervector. Comparatively, the existing HD computing algorithms [9] with integer models have to use Cosine similarity for inference. This is significantly more computationally expensive than Hamming distance, especially when implemented with an FPGA.\n\n\nONLINE DIMENSION REDUCTION\n\nOnline feature reduction attempts to remove insignificant \"noisy\" dimensions from the model to improve the efficiency of BRIC. In order to identify these dimensions, BRIC uses the distribution of the encoded training hypervectors. Figure 5 shows the distribution of the training hypervector values. This data is gathered by adding all the class hypervectors together after initial training. The dimensions in which the data has high variation are closer to 0 because a high variation implies an equal amount of +1 and -1 accumulations. The dimensions in which the data has low variation will be farther than 0 because, the additions accumulate more sequential 1's or -1's. We declare the dimensions close to 0 to be \"significant\", while the dimensions farther away from zero to be \"insignificant\". This is because to distinguish the classes from each other, we want to emphasize their differences and not their similarities. BRIC drops the s% most insignificant dimensions from the model, resulting in a efficiency improvement of approximately s%.\n\n\nFPGA ACCELERATION\n\nBRIC can be accelerated on different platforms such as CPU, GPU, FPGA or ASIC. FPGA is one of the best options as BRIC computation involves bitwise operations among long vector sizes. General strategies of optimizing the performance of BRIC are (i) using a pipeline and partial unrolling on low levels (dimension levels) to speed up each individual task and (ii) using dataflow design on a high level (task level) to build a stream processing architecture that lets different tasks run concurrently. In the following, we explain the functionality of BRIC in encoding, training, retraining, and inference phases.\n\n\nEncoding Implementation\n\nAs we explained in Section 3.1, we used the locality-based random projection encoding to implement the encoding module. Due to the sequential and predictable memory access patterns as well as the abundance of binary operations, this encoding approach can be implemented efficiently on an FPGA. In the hardware implementation, we represent all {\u22121, +1} values with {0, 1} respectively. This enables us to represent each element of projection vector using a single bit. Figure 6a shows the hardware implementation of the BRIC encoding module. The encoding process includes reading a feature vector from off-chip DDR memory and generating a binary hypervector from them. Calculating the inner product of a feature vector and a projection vector, P \u2208 {1, \u22121} D , can be implemented with no multiplications. Each element of the projection vector decides the sign of each dimension of the feature vector in the accumulation of the dot product. Thus, the dot product can be simplified to addition/subtraction of the feature vector elements. Right after the encoding, the hypervectors are used for initial model training. We also need to store the encoded hypervectors for retraining. However, the FPGA does not have enough BRAM blocks to store all encoded hypervectors, so, our design stores them into DDR memory.\n\n\nTraining Implementation\n\nInitial Training: BRIC initial training is a single-pass process. The training module accesses the encoded hypervectors and accumulates them in order to create a hypervector representing each class. When the training module accumulates the encoded hypervector to one of the class hypervectors, the encoding module maps the next training data into high-dimensional space, improving data throughput by increasing resource utilization. After going through all of the training data, our implementation binarizes the model by comparing each class hypervector with a threshold value. Finally, the binary model is stored in the BRAM blocks in order to be used for inference or retraining.\n\nRetraining: The retraining phase first sequentially reads already encoded training hypervectors from the off-chip memory. Next, we check the similarity of each data point with all trained class hypervectors. Each data point gets a tag of a class which it has the highest Hamming distance similarity with. Figure 6b shows an overview of the implementation of the Hamming distance similarity between a query and class hypervectors. This similarity check is implemented using a XOR array which compares the bit similarity between two hypervectors. Counter blocks, shown in Figure 6b, calculate the number of mismatches of each class hypervector with the query data point. Finally, a tree-based comparator block finds the class with the highest counter value. In the case of a misclassification, BRIC needs to update the model by adding and subtracting a data hypervector with two class hypervectors as defined before.\n\n\nInference Implementation\n\nAfter the retraining, BRIC has a stable model that can be used in the inference phase. The encoding module is integrated with the similarity check module as the entire inference part. Each test data point is first encoded to high-dimensional space using the same encoding block explained in Section 5.1. Next, BRIC checks the Hamming distance similarity of the data point with all prestored class hypervectors, in order to find a class with the highest similarity. One unique advantage of our approach is its capability to  enable online training during inference phase. Our implementation stores two HD models: one with integer values used for retraining and a binary model which is used to perform the classification task. BRIC binarizes the integer model periodically in order to update the inference model.\n\n\nEVALUATION 6.1 Experimental Setup\n\nWe implemented BRIC training, retraining, and inference in both software and hardware. In software, we implemented BRIC with Python. In hardware, we fully implemented BRIC using Verilog. We verify the timing and the functionality of the models by synthesizing them using Xilinx Vivado Design Suite [26]. The synthesis code has been implemented on the Kintex-7 FPGA KC705 Evaluation Kit. We evaluated the efficiency of the proposed BRIC on four practical classification problems listed below: Speech Recognition (ISOLET) [27], Activity Recognition (UCIHAR) [28], Face Detection (FACE) [29], Cardiotocography (CARDIO) [30], and Attack Detection in IoT systems (IoT) [31]. Figure 7 compares the impact of hypervector dimensions on the classification accuracy of BRIC and the baseline HD computing algorithm [9]. As we explained, BRIC always encodes data points into D binary dimensions. However, for the baseline HD computing algorithm, we consider two cases when HD encodes data points to binary and integer domains. Our results in Figure 7 indicate that BRIC requires significantly fewer dimensions to provide the same accuracy as the baseline. For example, BRIC using D = 4, 000 binary dimensions provides the same accuracy as the baseline with D = 10, 000 integer dimensions. In addition, the baseline with a binarized model provides significantly lower accuracy than BRIC and the baseline with an integer model. BRIC is on average 11.5% more accurate than the baseline using a binary encoding and binary model.\n\n\nBRIC Accuracy and Memory Requirement\n\nHere we compare BRIC and the baseline in terms of the training memory requirement. As we explained in Section 3.2, the baseline/BRIC store all encoded training data in memory. Going into high dimensional space intuitively means increasing the data size,  since we map each feature vector from n into D dimensional space, where D >> n. Let us assume a feature vector with n = 500 integer features. For the baseline with integer values, the data size increases by approximately 20\u00d7. Even the baseline with a binary encoding (D = 10, 000) increases the data size by 2.5\u00d7, while it provides much lower accuracy. In contrast, the proposed BRIC encodes data points to much lower dimensionality, e.g., D = 4000, in order to provide the same accuracy as the baseline. Our evaluation shows that BRIC can ensure 1:1 ratio of high-dimensional data to original data, while providing the same accuracy as baseline HD [9], proving that BRIC is more capable to run on embedded devices with limited memory.\n\n\nHardware Efficiency\n\nWe compare the efficiency of BRIC with the state-of-the-art HD computation algorithms on a Kintex-7 FPGA. To have a fair comparison, we consider an optimized implementation of the baseline [9], running on the same architecture as BRIC (explained in Section 5).\n\nEncoding & Training: Due to the predictable memory access pattern and lower BRIC dimensionality, BRIC encoding can process with higher efficiency as compared to the baseline. For instance, to get maximum accuracy, the baseline needs to work with D = 10, 000 dimensionality while BRIC can provide the same accuracy with D = 4, 000. Figure 9 shows the scalability of BRIC and the baseline efficiency to the feature size. Our evaluation shows that the execution time of the baseline increases with the number of features, while it takes the same time for BRIC to encode any size feature vector. For applications with 600 features, BRIC provides 282\u00d7 more energy efficiency and a 22.7\u00d7 speed up as compared to the baseline.\n\nIn training, in order to create class hypervectors, the baseline accumulates integer hypervectors, while BRIC training accumulates binary hypervectors. Figure 8 compares the energy consumption and execution time of BRIC and the baseline during initial training. The results are reported when both designs encode and train the model in a pipeline structure. For the baseline, encoding dominates the execution time, thus the training execution hides under the encoding module. However, in BRIC, the encoding can process faster than the training, thus the training is the bottleneck of the execution time (as it is shown in Figure 8). Our evaluation shows that BRIC can provide 64.1\u00d7 more energy efficiency and a 9.8\u00d7 speed up as compared to the baseline during training. Retraining/Inference Efficiency: BRIC stores all encoded hypervectors in order to perform iterative retraining. The existing HD computing algorithms map data points to integer values, where each encoded data is around 20 times larger than the data in the original domain. During retraining, the FPGA needs to sequentially access the encoded values which are pre-stored on off-chip memory. The limited memory bandwidth between the off-chip memory and the FPGA BRAM blocks significantly slows down the baseline computation during retraining. In contrast, BRIC maps the training data to lower dimensions, where each dimension can be represented using a binary value. This enables BRIC to speed up the retraining by loading hypervectors faster than the baseline.\n\nDuring inference and retraining, HD checks the similarity of each encoded hypervector with all existing class hypervectors. To achieve a high classification accuracy, the existing HD computing algorithms generate an integer model. Therefore, they require the use of an expensive similarity metric such as cosine to find the most similar class. In contrast, BRIC performs the similarity check with hamming distance. Figure 10 shows the energy consumption and execution time of the FPGA accelerating a single retraining iteration and a single query during inference. The results show that BRIC can achieve on average a 61.6\u00d7 energy efficiency improvement and a 7.9\u00d7 speed up as compared to the existing HD computation algorithms. Similarly, in inference, the FPGA implementation of BRIC can achieve on average a 43.8\u00d7 energy efficiency improvement and a 6.1\u00d7 speed up running a single query (Figure 10b). Table 1 shows the impact of the dimension reduction on the BRIC classification accuracy. Our results indicate that dropping 20% of noisy dimensions improves the BRIC accuracy by enabling the model to be retrained based on \"significant\" dimensions. Further dropped dimensions may result in removing useful information. As listed in Table 1, dropping a larger ratio of dimensions, e.g., 60% of dimensions, results in a 2% quality loss in BRIC accuracy for one of the applications. Online dimension reduction improves BRIC efficiency linearly during both retraining and inference. For example, a 40% dimension reduction results in a 37% energy efficiency improvement and a 29% speed up while providing less than 0.5% quality loss as compared to BRIC with full dimensionality.\n\n\nOnline Dimension Reduction:\n\n\nCONCLUSION\n\nIn this paper, we propose BRIC, a novel HD computing framework that significantly improves the computation efficiency. BRIC exploits the predictable memory access of our proposed encoding to design an efficient encoding approach which maps data to a binary hypervector. BRIC enables binary training and retraining on the encoded hypervectors and simplifies the inference similarity metric to Hamming distance. We additionally, implemented a dimension reduction technique that removes unnecessary dimensions to further improve the efficiency of BRIC. We also designed a fully pipelined FPGA implementation to accelerate BRIC. Our evaluations show that BRIC can achieve 64.1\u00d7 and 9.8\u00d7 (43.8\u00d7 and 6.1\u00d7) energy efficiency and speed up as compared to the baseline during training (inference) while providing the same classification accuracy.\n\nFigure 2 :\n2Overview of how BRIC is constructed and how BRIC performs inference.\n\nFigure 3 :\n3Random projection encoding using dense, sparse, and locality-based projection matrix.\n\nFigure 4 :\n4Locality-based random projection encoding.The result of training are k hypervectors with D dimensions, where k is the number of classes. For example, the i th class hypervector can be computed as: C i = \u2200j \u2208class i H j . This training operation involves a large amount of integer additions, which makes the HD computation costly[9]. Since our encoded hypervectors are bipolar, this accumulation can be performed more efficiently with binary accumulations. In BRIC, the resulting class hypervectors are also binarized, creating a binary model, where the class hypervector elements are changed to +1 if they are positive and -1 if they are negative or 0. The binary model is used for more efficient inference, however, the accumulated hypervectors are still stored as an integer model because they will be used for retraining.Retraining: HD computing performs model adjustment by iteratively going through the training dataset.Figure 2\u2022 B shows the functionality of BRIC during retraining. During a single iteration of model adjustment, HD computing checks the similarity of all training data points, say H, with the trained binary model. If a data is wrongly classified by the model, HD updates the model by (i) adding the incorrectly classified hypervector to the class that input belongs to ( C cor r ect = C cor r ect + H), and (ii) subtracting it from the class which it is wrongly matched with ( C wr on\u0434 = C wr on\u0434 \u2212H). These updates are done to the integer model saved from training because adding to and subtracting from the binary model would drastically change the model. To update the binary model, the updated class hypervectors from the integer model are sent to the bipolar domain using the same Si\u0434n function used for training. After each retraining iteration, we check the classification accuracy in the last three iterations and decide to stop the retraining if the change in error is less than 0.1%(Figure 2\u2022 C ). The retraining stops after 20 iterations if the convergence condition is not satisfied.\n\nFigure 5 :\n5Online dimension reduction after initial training.\n\nFigure 6 :\n6FPGA implementation of the encoding and associative search block.\n\nFigure 7 :\n7Classification accuracy of BRIC and the baseline HD using binary and integer models.\n\nFigure 8 :\n8Energy consumption and execution time of BRIC and the baseline HD during training.\n\nFigure 9 :\n9Scalability of the encoding module in BRIC and the baseline HD with the feature size.\n\nFigure 10 :\n10Energy consumption and execution time of BRIC and the baseline HD running (a) a single retraining iteration, and (b) a single query at inference.\n\n\n19, June 2-6, 2019, Las Vegas, NV, USA \u00a9 2019 Association for Computing Machinery. ACM ISBN 978-1-4503-6725-7/19/06. . . $15.00 https://doi.org/10.1145/3316781.3317785\n\nTable 1 :\n1Change in classification accuracy due to online dimension reduction.Dimension Reduction 20% \n40% \n60% \n70% \n80% \n90% \n\nFACE \n+0.8% +0.1% \n0% \n-0.2% \n-1.3% \n-4.1% \nCARDIO \n+0.2% \n0% \n0% \n-0.4% \n-1.4% \n-1.4% \nIOT \n+0.3% +0.1% \n0% \n-14.1% -16.5% -21.9% \nUCIHAR \n+0.6% -0.1% -0.8% -1.2% \n-2.1% \n-5.4% \nISOLET \n0% \n-0.4% -1.9% -4.6% \n-6.9% -15.2% \n\n\nACKNOWLEDGEMENTSThis work was partially supported by CRISP, one of six centers in JUMP, an SRC program sponsored by DARPA, and also NSF grants #1730158 and #1527034.\nInternet of things (iot): A vision, architectural elements, and future directions. J Gubbi, Future generation computer systems. 297J. Gubbi et al., \"Internet of things (iot): A vision, architectural elements, and future directions, \" Future generation computer systems, vol. 29, no. 7, pp. 1645-1660, 2013.\n\nHealth monitoring and management using internet-of-things (iot) sensing with cloud-based processing: Opportunities and challenges. M Hassanalieragh, IEEE SCC. IEEEM. Hassanalieragh et al., \"Health monitoring and management using internet-of-things (iot) sensing with cloud-based processing: Opportunities and challenges, \" in IEEE SCC, pp. 285-292, IEEE, 2015.\n\nInternet of things and big data analytics for smart and connected communities. Y Sun, IEEE Access. 4Y. Sun et al., \"Internet of things and big data analytics for smart and connected communities, \" IEEE Access, vol. 4, pp. 766-773, 2016.\n\nSecurity, privacy and trust in internet of things: The road ahead. S Sicari, Computer networks. 76S. Sicari et al., \"Security, privacy and trust in internet of things: The road ahead, \" Computer networks, vol. 76, pp. 146-164, 2015.\n\nHyperdimensional computing: An introduction to computing in distributed representation with high-dimensional random vectors. P Kanerva, Cognitive Computation. 12P. Kanerva, \"Hyperdimensional computing: An introduction to computing in distributed repre- sentation with high-dimensional random vectors, \" Cognitive Computation, vol. 1, no. 2, pp. 139- 159, 2009.\n\nSequence prediction with sparse distributed hyperdimensional coding applied to the analysis of mobile phone use patterns. O Rasanen, J Saarinen, IEEE Transactions on Neural Networks and Learning Systems. 99O. Rasanen and J. Saarinen, \"Sequence prediction with sparse distributed hyperdimensional coding applied to the analysis of mobile phone use patterns, \" IEEE Transactions on Neural Networks and Learning Systems, vol. PP, no. 99, pp. 1-12, 2015.\n\nVoicehd: Hyperdimensional computing for efficient speech recognition. M Imani, ICRC. IEEEM. Imani et al., \"Voicehd: Hyperdimensional computing for efficient speech recognition, \" in ICRC, pp. 1-6, IEEE, 2017.\n\nA robust and energy-efficient classifier using brain-inspired hyperdimensional computing. A Rahimi, ISLPED. ACMA. Rahimi et al., \"A robust and energy-efficient classifier using brain-inspired hyperdimen- sional computing, \" in ISLPED, pp. 64-69, ACM, 2016.\n\nHierarchical hyperdimensional computing for energy efficient classification. M Imani, DAC. ACM108M. Imani et al., \"Hierarchical hyperdimensional computing for energy efficient classification, \" in DAC, p. 108, ACM, 2018.\n\nEfficient human activity recognition using hyperdimensional computing. Y Kim, IoTACM38Y. Kim et al., \"Efficient human activity recognition using hyperdimensional computing, \" in IoT, p. 38, ACM, 2018.\n\nRandom indexing of text samples for latent semantic analysis. P Kanerva, CogSciCiteseer1036P. Kanerva et al., \"Random indexing of text samples for latent semantic analysis, \" in CogSci, vol. 1036, Citeseer, 2000.\n\nHdcluster: An accurate clustering using brain-inspired high-dimensional computing. M Imani, DATEM. Imani et al., \"Hdcluster: An accurate clustering using brain-inspired high-dimensional com- puting, \" in DATE, 2019.\n\nHdna: Energy-efficient dna sequencing using hyperdimensional computing. M Imani, IEEE BHI. IEEEM. Imani et al., \"Hdna: Energy-efficient dna sequencing using hyperdimensional computing, \" in IEEE BHI, pp. 271-274, IEEE, 2018.\n\nA framework for collaborative learning in secure high-dimensional space. M Imani, IEEE CLOUDIEEEM. Imani et al., \"A framework for collaborative learning in secure high-dimensional space, \" in IEEE CLOUD, pp. 1-6, IEEE, 2019.\n\nHyperdimensional biosignal processing: A case study for emg-based hand gesture recognition. A Rahimi, ICRC. IEEEA. Rahimi et al., \"Hyperdimensional biosignal processing: A case study for emg-based hand gesture recognition, \" in ICRC, pp. 1-8, IEEE, 2016.\n\nBrain-inspired computing exploiting carbon nanotube fets and resistive ram: Hyperdimensional computing case study. T Wu, IEEE ISSCC. IEEET. Wu et al., \"Brain-inspired computing exploiting carbon nanotube fets and resistive ram: Hyperdimensional computing case study, \" in IEEE ISSCC, IEEE, 2018.\n\nHyperdimensional computing with 3d vrram in-memory kernels: Devicearchitecture co-design for energy-efficient, error-resilient language recognition. H Li, IEDM. IEEEH. Li et al., \"Hyperdimensional computing with 3d vrram in-memory kernels: Device- architecture co-design for energy-efficient, error-resilient language recognition, \" in IEDM, pp. 16-1, IEEE, 2016.\n\nFelix: Fast and energy-efficient logic in memory. S Gupta, IEEE/ACM ICCAD. IEEES. Gupta et al., \"Felix: Fast and energy-efficient logic in memory, \" in IEEE/ACM ICCAD, pp. 1-7, IEEE, 2018.\n\nFach: Fpga-based acceleration of hyperdimensional computing by reducing computational complexity. M Imani, ASPDAC. ACMM. Imani et al., \"Fach: Fpga-based acceleration of hyperdimensional computing by reducing computational complexity, \" in ASPDAC, pp. 493-498, ACM, 2019.\n\nF5-hd: Fast flexible fpga-based framework for refreshing hyperdimensional computing. S Salamat, FPGA. ACMS. Salamat et al., \"F5-hd: Fast flexible fpga-based framework for refreshing hyperdimensional computing, \" in FPGA, pp. 53-62, ACM, 2019.\n\nExploring hyperdimensional associative memory. M Imani, HPCA. IEEEM. Imani et al., \"Exploring hyperdimensional associative memory, \" in HPCA, pp. 445-456, IEEE, 2017.\n\nA binary learning framework for hyperdimensional computing. M Imani, DATE. M. Imani et al., \"A binary learning framework for hyperdimensional computing, \" in DATE, 2019.\n\nSparsehd: Algorithm-hardware co-optimization for efficient high-dimensional computing. M Imani, IEEE FCCM. IEEEM. Imani et al., \"Sparsehd: Algorithm-hardware co-optimization for efficient high-dimensional computing, \" in IEEE FCCM, pp. 1-6, IEEE, 2019.\n\nHardware optimizations of dense binary hyperdimensional computing: Rematerialization of hypervectors, binarized bundling, and combinational associative memory. M Schmuck, arXiv:1807.08583arXiv preprintM. Schmuck et al., \"Hardware optimizations of dense binary hyperdimensional computing: Re- materialization of hypervectors, binarized bundling, and combinational associative memory, \" arXiv preprint arXiv:1807.08583, 2018.\n\nRandom-projection ensemble classification. T I Cannings, Journal of the Royal Statistical Society. 794T. I. Cannings et al., \"Random-projection ensemble classification, \" Journal of the Royal Statis- tical Society, vol. 79, no. 4, pp. 959-1035, 2017.\n\nVivado design suite. T Feist, White Paper. 5T. Feist, \"Vivado design suite, \" White Paper, vol. 5, 2012.\n\nUci machine learning repository. Uci learning repository\"Uci machine learning repository. \" http://archive.ics.uci.edu/ml/datasets/ISOLET. [28] \"Uci learning repository. \" https://archive.ics.uci.edu/ml/datasets/Daily+and+Sports+ Activities.\n\nCaltech-256 object category dataset. G Griffin, A Holub, P Perona, G. Griffin, A. Holub, and P. Perona, \"Caltech-256 object category dataset, \" 2007.\n\nUci machine learning repository. \"Uci machine learning repository. \" https://archive.ics.uci.edu/ml/datasets/cardiotocography.\n\nUci machine learning repository. \"Uci machine learning repository. \" https://archive.ics.uci.edu/ml/datasets/detection_of_IoT_ botnet_attacks_N_BaIoT.\n", "annotations": {"author": "[{\"start\":\"96\",\"end\":\"174\"},{\"start\":\"175\",\"end\":\"255\"},{\"start\":\"256\",\"end\":\"336\"},{\"start\":\"337\",\"end\":\"410\"},{\"start\":\"411\",\"end\":\"472\"},{\"start\":\"473\",\"end\":\"551\"},{\"start\":\"552\",\"end\":\"613\"},{\"start\":\"614\",\"end\":\"676\"},{\"start\":\"677\",\"end\":\"739\"},{\"start\":\"740\",\"end\":\"798\"},{\"start\":\"799\",\"end\":\"860\"}]", "publisher": null, "author_last_name": "[{\"start\":\"103\",\"end\":\"108\"},{\"start\":\"182\",\"end\":\"188\"},{\"start\":\"261\",\"end\":\"269\"},{\"start\":\"343\",\"end\":\"346\"},{\"start\":\"419\",\"end\":\"423\"},{\"start\":\"480\",\"end\":\"486\"},{\"start\":\"559\",\"end\":\"564\"},{\"start\":\"621\",\"end\":\"627\"},{\"start\":\"682\",\"end\":\"690\"},{\"start\":\"746\",\"end\":\"749\"},{\"start\":\"807\",\"end\":\"811\"}]", "author_first_name": "[{\"start\":\"96\",\"end\":\"102\"},{\"start\":\"175\",\"end\":\"181\"},{\"start\":\"256\",\"end\":\"260\"},{\"start\":\"337\",\"end\":\"342\"},{\"start\":\"411\",\"end\":\"418\"},{\"start\":\"473\",\"end\":\"479\"},{\"start\":\"552\",\"end\":\"558\"},{\"start\":\"614\",\"end\":\"620\"},{\"start\":\"677\",\"end\":\"681\"},{\"start\":\"740\",\"end\":\"745\"},{\"start\":\"799\",\"end\":\"806\"}]", "author_affiliation": "[{\"start\":\"127\",\"end\":\"173\"},{\"start\":\"208\",\"end\":\"254\"},{\"start\":\"289\",\"end\":\"335\"},{\"start\":\"363\",\"end\":\"409\"},{\"start\":\"425\",\"end\":\"471\"},{\"start\":\"504\",\"end\":\"550\"},{\"start\":\"566\",\"end\":\"612\"},{\"start\":\"629\",\"end\":\"675\"},{\"start\":\"692\",\"end\":\"738\"},{\"start\":\"751\",\"end\":\"797\"},{\"start\":\"813\",\"end\":\"859\"}]", "title": "[{\"start\":\"1\",\"end\":\"93\"},{\"start\":\"861\",\"end\":\"953\"}]", "venue": null, "abstract": "[{\"start\":\"1441\",\"end\":\"2902\"}]", "bib_ref": "[{\"start\":\"3176\",\"end\":\"3179\",\"attributes\":{\"ref_id\":\"b0\"}},{\"start\":\"3179\",\"end\":\"3181\",\"attributes\":{\"ref_id\":\"b1\"}},{\"start\":\"3763\",\"end\":\"3764\"},{\"start\":\"3916\",\"end\":\"3919\",\"attributes\":{\"ref_id\":\"b2\"}},{\"start\":\"4149\",\"end\":\"4152\",\"attributes\":{\"ref_id\":\"b3\"}},{\"start\":\"4570\",\"end\":\"4573\",\"attributes\":{\"ref_id\":\"b4\"}},{\"start\":\"4672\",\"end\":\"4675\",\"attributes\":{\"ref_id\":\"b4\"}},{\"start\":\"4980\",\"end\":\"4983\",\"attributes\":{\"ref_id\":\"b5\"}},{\"start\":\"4983\",\"end\":\"4986\",\"attributes\":{\"ref_id\":\"b6\"}},{\"start\":\"4986\",\"end\":\"4989\",\"attributes\":{\"ref_id\":\"b7\"}},{\"start\":\"5662\",\"end\":\"5665\",\"attributes\":{\"ref_id\":\"b8\"}},{\"start\":\"5665\",\"end\":\"5668\",\"attributes\":{\"ref_id\":\"b9\"}},{\"start\":\"5716\",\"end\":\"5719\",\"attributes\":{\"ref_id\":\"b8\"}},{\"start\":\"5945\",\"end\":\"5948\",\"attributes\":{\"ref_id\":\"b7\"}},{\"start\":\"5948\",\"end\":\"5951\",\"attributes\":{\"ref_id\":\"b10\"}},{\"start\":\"6917\",\"end\":\"6920\",\"attributes\":{\"ref_id\":\"b8\"}},{\"start\":\"8162\",\"end\":\"8165\",\"attributes\":{\"ref_id\":\"b5\"}},{\"start\":\"8165\",\"end\":\"8168\",\"attributes\":{\"ref_id\":\"b7\"}},{\"start\":\"8168\",\"end\":\"8171\",\"attributes\":{\"ref_id\":\"b8\"}},{\"start\":\"8171\",\"end\":\"8175\",\"attributes\":{\"ref_id\":\"b9\"}},{\"start\":\"8175\",\"end\":\"8179\",\"attributes\":{\"ref_id\":\"b11\"}},{\"start\":\"8179\",\"end\":\"8183\",\"attributes\":{\"ref_id\":\"b12\"}},{\"start\":\"8183\",\"end\":\"8187\",\"attributes\":{\"ref_id\":\"b13\"}},{\"start\":\"8210\",\"end\":\"8214\",\"attributes\":{\"ref_id\":\"b10\"}},{\"start\":\"8309\",\"end\":\"8312\",\"attributes\":{\"ref_id\":\"b7\"}},{\"start\":\"8454\",\"end\":\"8458\",\"attributes\":{\"ref_id\":\"b14\"}},{\"start\":\"8565\",\"end\":\"8568\",\"attributes\":{\"ref_id\":\"b6\"}},{\"start\":\"8568\",\"end\":\"8570\",\"attributes\":{\"ref_id\":\"b8\"}},{\"start\":\"8843\",\"end\":\"8847\",\"attributes\":{\"ref_id\":\"b15\"}},{\"start\":\"8847\",\"end\":\"8851\",\"attributes\":{\"ref_id\":\"b16\"}},{\"start\":\"8851\",\"end\":\"8855\",\"attributes\":{\"ref_id\":\"b17\"}},{\"start\":\"8855\",\"end\":\"8859\",\"attributes\":{\"ref_id\":\"b18\"}},{\"start\":\"8859\",\"end\":\"8863\",\"attributes\":{\"ref_id\":\"b19\"}},{\"start\":\"8863\",\"end\":\"8867\",\"attributes\":{\"ref_id\":\"b20\"}},{\"start\":\"8955\",\"end\":\"8959\",\"attributes\":{\"ref_id\":\"b21\"}},{\"start\":\"9009\",\"end\":\"9013\",\"attributes\":{\"ref_id\":\"b22\"}},{\"start\":\"9023\",\"end\":\"9027\",\"attributes\":{\"ref_id\":\"b23\"}},{\"start\":\"9230\",\"end\":\"9233\",\"attributes\":{\"ref_id\":\"b7\"}},{\"start\":\"9759\",\"end\":\"9762\",\"attributes\":{\"ref_id\":\"b8\"}},{\"start\":\"9762\",\"end\":\"9765\",\"attributes\":{\"ref_id\":\"b9\"}},{\"start\":\"12278\",\"end\":\"12282\",\"attributes\":{\"ref_id\":\"b24\"}},{\"start\":\"17631\",\"end\":\"17634\",\"attributes\":{\"ref_id\":\"b8\"}},{\"start\":\"23662\",\"end\":\"23666\",\"attributes\":{\"ref_id\":\"b25\"}},{\"start\":\"23884\",\"end\":\"23888\",\"attributes\":{\"ref_id\":\"b26\"}},{\"start\":\"23948\",\"end\":\"23952\",\"attributes\":{\"ref_id\":\"b27\"}},{\"start\":\"23980\",\"end\":\"23984\",\"attributes\":{\"ref_id\":\"b28\"}},{\"start\":\"24028\",\"end\":\"24032\",\"attributes\":{\"ref_id\":\"b29\"}},{\"start\":\"24168\",\"end\":\"24171\",\"attributes\":{\"ref_id\":\"b8\"}},{\"start\":\"25821\",\"end\":\"25824\",\"attributes\":{\"ref_id\":\"b8\"}},{\"start\":\"26120\",\"end\":\"26123\",\"attributes\":{\"ref_id\":\"b8\"}},{\"start\":\"31522\",\"end\":\"31525\",\"attributes\":{\"ref_id\":\"b8\"}}]", "figure": "[{\"start\":\"31000\",\"end\":\"31081\",\"attributes\":{\"id\":\"fig_0\"}},{\"start\":\"31082\",\"end\":\"31180\",\"attributes\":{\"id\":\"fig_1\"}},{\"start\":\"31181\",\"end\":\"33212\",\"attributes\":{\"id\":\"fig_2\"}},{\"start\":\"33213\",\"end\":\"33276\",\"attributes\":{\"id\":\"fig_3\"}},{\"start\":\"33277\",\"end\":\"33355\",\"attributes\":{\"id\":\"fig_4\"}},{\"start\":\"33356\",\"end\":\"33453\",\"attributes\":{\"id\":\"fig_5\"}},{\"start\":\"33454\",\"end\":\"33549\",\"attributes\":{\"id\":\"fig_6\"}},{\"start\":\"33550\",\"end\":\"33648\",\"attributes\":{\"id\":\"fig_7\"}},{\"start\":\"33649\",\"end\":\"33809\",\"attributes\":{\"id\":\"fig_8\"}},{\"start\":\"33810\",\"end\":\"33979\",\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"}},{\"start\":\"33980\",\"end\":\"34336\",\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"}}]", "paragraph": "[{\"start\":\"2918\",\"end\":\"4405\"},{\"start\":\"4407\",\"end\":\"5303\"},{\"start\":\"5305\",\"end\":\"6145\"},{\"start\":\"6147\",\"end\":\"6514\"},{\"start\":\"6516\",\"end\":\"7885\"},{\"start\":\"7915\",\"end\":\"8700\"},{\"start\":\"8702\",\"end\":\"9492\"},{\"start\":\"9494\",\"end\":\"10837\"},{\"start\":\"10855\",\"end\":\"11233\"},{\"start\":\"11235\",\"end\":\"11410\"},{\"start\":\"11423\",\"end\":\"11934\"},{\"start\":\"12010\",\"end\":\"12314\"},{\"start\":\"12396\",\"end\":\"12488\"},{\"start\":\"12536\",\"end\":\"12643\"},{\"start\":\"12696\",\"end\":\"12914\"},{\"start\":\"12935\",\"end\":\"13263\"},{\"start\":\"13291\",\"end\":\"14229\"},{\"start\":\"14231\",\"end\":\"16051\"},{\"start\":\"16105\",\"end\":\"16270\"},{\"start\":\"16332\",\"end\":\"16838\"},{\"start\":\"16856\",\"end\":\"17053\"},{\"start\":\"17072\",\"end\":\"17817\"},{\"start\":\"17848\",\"end\":\"18895\"},{\"start\":\"18917\",\"end\":\"19528\"},{\"start\":\"19556\",\"end\":\"20862\"},{\"start\":\"20890\",\"end\":\"21571\"},{\"start\":\"21573\",\"end\":\"22487\"},{\"start\":\"22516\",\"end\":\"23326\"},{\"start\":\"23364\",\"end\":\"24876\"},{\"start\":\"24917\",\"end\":\"25907\"},{\"start\":\"25931\",\"end\":\"26191\"},{\"start\":\"26193\",\"end\":\"26912\"},{\"start\":\"26914\",\"end\":\"28441\"},{\"start\":\"28443\",\"end\":\"30118\"},{\"start\":\"30163\",\"end\":\"30999\"}]", "formula": "[{\"start\":\"11935\",\"end\":\"12009\",\"attributes\":{\"id\":\"formula_0\"}},{\"start\":\"12315\",\"end\":\"12395\",\"attributes\":{\"id\":\"formula_1\"}},{\"start\":\"12489\",\"end\":\"12535\",\"attributes\":{\"id\":\"formula_2\"}},{\"start\":\"12644\",\"end\":\"12695\",\"attributes\":{\"id\":\"formula_3\"}},{\"start\":\"12915\",\"end\":\"12934\",\"attributes\":{\"id\":\"formula_4\"}},{\"start\":\"16052\",\"end\":\"16104\",\"attributes\":{\"id\":\"formula_5\"}},{\"start\":\"16271\",\"end\":\"16331\",\"attributes\":{\"id\":\"formula_6\"}}]", "table_ref": "[{\"start\":\"29346\",\"end\":\"29353\",\"attributes\":{\"ref_id\":\"tab_2\"}},{\"start\":\"29677\",\"end\":\"29684\",\"attributes\":{\"ref_id\":\"tab_2\"}}]", "section_header": "[{\"start\":\"2904\",\"end\":\"2916\",\"attributes\":{\"n\":\"1\"}},{\"start\":\"7888\",\"end\":\"7913\",\"attributes\":{\"n\":\"2\"}},{\"start\":\"10840\",\"end\":\"10853\",\"attributes\":{\"n\":\"3\"}},{\"start\":\"11413\",\"end\":\"11421\",\"attributes\":{\"n\":\"3.1\"}},{\"start\":\"13266\",\"end\":\"13289\"},{\"start\":\"16841\",\"end\":\"16854\",\"attributes\":{\"n\":\"3.2\"}},{\"start\":\"17056\",\"end\":\"17070\",\"attributes\":{\"n\":\"3.3\"}},{\"start\":\"17820\",\"end\":\"17846\",\"attributes\":{\"n\":\"4\"}},{\"start\":\"18898\",\"end\":\"18915\",\"attributes\":{\"n\":\"5\"}},{\"start\":\"19531\",\"end\":\"19554\",\"attributes\":{\"n\":\"5.1\"}},{\"start\":\"20865\",\"end\":\"20888\",\"attributes\":{\"n\":\"5.2\"}},{\"start\":\"22490\",\"end\":\"22514\",\"attributes\":{\"n\":\"5.3\"}},{\"start\":\"23329\",\"end\":\"23362\",\"attributes\":{\"n\":\"6\"}},{\"start\":\"24879\",\"end\":\"24915\",\"attributes\":{\"n\":\"6.2\"}},{\"start\":\"25910\",\"end\":\"25929\",\"attributes\":{\"n\":\"6.3\"}},{\"start\":\"30121\",\"end\":\"30148\",\"attributes\":{\"n\":\"6.4\"}},{\"start\":\"30151\",\"end\":\"30161\",\"attributes\":{\"n\":\"7\"}},{\"start\":\"31001\",\"end\":\"31011\"},{\"start\":\"31083\",\"end\":\"31093\"},{\"start\":\"31182\",\"end\":\"31192\"},{\"start\":\"33214\",\"end\":\"33224\"},{\"start\":\"33278\",\"end\":\"33288\"},{\"start\":\"33357\",\"end\":\"33367\"},{\"start\":\"33455\",\"end\":\"33465\"},{\"start\":\"33551\",\"end\":\"33561\"},{\"start\":\"33650\",\"end\":\"33661\"},{\"start\":\"33981\",\"end\":\"33990\"}]", "table": "[{\"start\":\"34060\",\"end\":\"34336\"}]", "figure_caption": "[{\"start\":\"31013\",\"end\":\"31081\"},{\"start\":\"31095\",\"end\":\"31180\"},{\"start\":\"31194\",\"end\":\"33212\"},{\"start\":\"33226\",\"end\":\"33276\"},{\"start\":\"33290\",\"end\":\"33355\"},{\"start\":\"33369\",\"end\":\"33453\"},{\"start\":\"33467\",\"end\":\"33549\"},{\"start\":\"33563\",\"end\":\"33648\"},{\"start\":\"33664\",\"end\":\"33809\"},{\"start\":\"33812\",\"end\":\"33979\"},{\"start\":\"33992\",\"end\":\"34060\"}]", "figure_ref": "[{\"start\":\"7235\",\"end\":\"7243\"},{\"start\":\"9857\",\"end\":\"9865\"},{\"start\":\"11442\",\"end\":\"11450\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"13472\",\"end\":\"13482\",\"attributes\":{\"ref_id\":\"fig_1\"}},{\"start\":\"14726\",\"end\":\"14735\",\"attributes\":{\"ref_id\":\"fig_1\"}},{\"start\":\"15139\",\"end\":\"15147\",\"attributes\":{\"ref_id\":\"fig_2\"}},{\"start\":\"15772\",\"end\":\"15780\",\"attributes\":{\"ref_id\":\"fig_2\"}},{\"start\":\"16874\",\"end\":\"16882\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"17146\",\"end\":\"17155\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"18079\",\"end\":\"18087\",\"attributes\":{\"ref_id\":\"fig_3\"}},{\"start\":\"20024\",\"end\":\"20033\",\"attributes\":{\"ref_id\":\"fig_4\"}},{\"start\":\"21878\",\"end\":\"21887\",\"attributes\":{\"ref_id\":\"fig_4\"}},{\"start\":\"22143\",\"end\":\"22152\",\"attributes\":{\"ref_id\":\"fig_4\"}},{\"start\":\"24034\",\"end\":\"24042\",\"attributes\":{\"ref_id\":\"fig_5\"}},{\"start\":\"24394\",\"end\":\"24402\",\"attributes\":{\"ref_id\":\"fig_5\"}},{\"start\":\"26524\",\"end\":\"26532\",\"attributes\":{\"ref_id\":\"fig_7\"}},{\"start\":\"27066\",\"end\":\"27074\",\"attributes\":{\"ref_id\":\"fig_6\"}},{\"start\":\"27535\",\"end\":\"27543\",\"attributes\":{\"ref_id\":\"fig_6\"}},{\"start\":\"28858\",\"end\":\"28867\",\"attributes\":{\"ref_id\":\"fig_8\"}},{\"start\":\"29332\",\"end\":\"29343\",\"attributes\":{\"ref_id\":\"fig_8\"}}]", "bib_author_first_name": "[{\"start\":\"34586\",\"end\":\"34587\"},{\"start\":\"34942\",\"end\":\"34943\"},{\"start\":\"35252\",\"end\":\"35253\"},{\"start\":\"35478\",\"end\":\"35479\"},{\"start\":\"35770\",\"end\":\"35771\"},{\"start\":\"36129\",\"end\":\"36130\"},{\"start\":\"36140\",\"end\":\"36141\"},{\"start\":\"36529\",\"end\":\"36530\"},{\"start\":\"36759\",\"end\":\"36760\"},{\"start\":\"37004\",\"end\":\"37005\"},{\"start\":\"37220\",\"end\":\"37221\"},{\"start\":\"37413\",\"end\":\"37414\"},{\"start\":\"37648\",\"end\":\"37649\"},{\"start\":\"37854\",\"end\":\"37855\"},{\"start\":\"38081\",\"end\":\"38082\"},{\"start\":\"38326\",\"end\":\"38327\"},{\"start\":\"38605\",\"end\":\"38606\"},{\"start\":\"38936\",\"end\":\"38937\"},{\"start\":\"39202\",\"end\":\"39203\"},{\"start\":\"39440\",\"end\":\"39441\"},{\"start\":\"39699\",\"end\":\"39700\"},{\"start\":\"39905\",\"end\":\"39906\"},{\"start\":\"40086\",\"end\":\"40087\"},{\"start\":\"40284\",\"end\":\"40285\"},{\"start\":\"40611\",\"end\":\"40612\"},{\"start\":\"40919\",\"end\":\"40920\"},{\"start\":\"40921\",\"end\":\"40922\"},{\"start\":\"41149\",\"end\":\"41150\"},{\"start\":\"41514\",\"end\":\"41515\"},{\"start\":\"41525\",\"end\":\"41526\"},{\"start\":\"41534\",\"end\":\"41535\"}]", "bib_author_last_name": "[{\"start\":\"34588\",\"end\":\"34593\"},{\"start\":\"34944\",\"end\":\"34958\"},{\"start\":\"35254\",\"end\":\"35257\"},{\"start\":\"35480\",\"end\":\"35486\"},{\"start\":\"35772\",\"end\":\"35779\"},{\"start\":\"36131\",\"end\":\"36138\"},{\"start\":\"36142\",\"end\":\"36150\"},{\"start\":\"36531\",\"end\":\"36536\"},{\"start\":\"36761\",\"end\":\"36767\"},{\"start\":\"37006\",\"end\":\"37011\"},{\"start\":\"37222\",\"end\":\"37225\"},{\"start\":\"37415\",\"end\":\"37422\"},{\"start\":\"37650\",\"end\":\"37655\"},{\"start\":\"37856\",\"end\":\"37861\"},{\"start\":\"38083\",\"end\":\"38088\"},{\"start\":\"38328\",\"end\":\"38334\"},{\"start\":\"38607\",\"end\":\"38609\"},{\"start\":\"38938\",\"end\":\"38940\"},{\"start\":\"39204\",\"end\":\"39209\"},{\"start\":\"39442\",\"end\":\"39447\"},{\"start\":\"39701\",\"end\":\"39708\"},{\"start\":\"39907\",\"end\":\"39912\"},{\"start\":\"40088\",\"end\":\"40093\"},{\"start\":\"40286\",\"end\":\"40291\"},{\"start\":\"40613\",\"end\":\"40620\"},{\"start\":\"40923\",\"end\":\"40931\"},{\"start\":\"41151\",\"end\":\"41156\"},{\"start\":\"41516\",\"end\":\"41523\"},{\"start\":\"41527\",\"end\":\"41532\"},{\"start\":\"41536\",\"end\":\"41542\"}]", "bib_entry": "[{\"start\":\"34503\",\"end\":\"34809\",\"attributes\":{\"matched_paper_id\":\"204982032\",\"id\":\"b0\"}},{\"start\":\"34811\",\"end\":\"35171\",\"attributes\":{\"matched_paper_id\":\"6161031\",\"id\":\"b1\"}},{\"start\":\"35173\",\"end\":\"35409\",\"attributes\":{\"matched_paper_id\":\"10167346\",\"id\":\"b2\"}},{\"start\":\"35411\",\"end\":\"35643\",\"attributes\":{\"matched_paper_id\":\"13835959\",\"id\":\"b3\"}},{\"start\":\"35645\",\"end\":\"36005\",\"attributes\":{\"matched_paper_id\":\"733980\",\"id\":\"b4\"}},{\"start\":\"36007\",\"end\":\"36457\",\"attributes\":{\"matched_paper_id\":\"15258913\",\"id\":\"b5\"}},{\"start\":\"36459\",\"end\":\"36667\",\"attributes\":{\"matched_paper_id\":\"21351739\",\"id\":\"b6\"}},{\"start\":\"36669\",\"end\":\"36925\",\"attributes\":{\"matched_paper_id\":\"9812826\",\"id\":\"b7\"}},{\"start\":\"36927\",\"end\":\"37147\",\"attributes\":{\"matched_paper_id\":\"49301394\",\"id\":\"b8\"}},{\"start\":\"37149\",\"end\":\"37349\",\"attributes\":{\"id\":\"b9\"}},{\"start\":\"37351\",\"end\":\"37563\",\"attributes\":{\"id\":\"b10\"}},{\"start\":\"37565\",\"end\":\"37780\",\"attributes\":{\"id\":\"b11\"}},{\"start\":\"37782\",\"end\":\"38006\",\"attributes\":{\"matched_paper_id\":\"4708051\",\"id\":\"b12\"}},{\"start\":\"38008\",\"end\":\"38232\",\"attributes\":{\"id\":\"b13\"}},{\"start\":\"38234\",\"end\":\"38488\",\"attributes\":{\"matched_paper_id\":\"12008695\",\"id\":\"b14\"}},{\"start\":\"38490\",\"end\":\"38785\",\"attributes\":{\"matched_paper_id\":\"3869844\",\"id\":\"b15\"}},{\"start\":\"38787\",\"end\":\"39150\",\"attributes\":{\"matched_paper_id\":\"25209638\",\"id\":\"b16\"}},{\"start\":\"39152\",\"end\":\"39340\",\"attributes\":{\"matched_paper_id\":\"53235957\",\"id\":\"b17\"}},{\"start\":\"39342\",\"end\":\"39612\",\"attributes\":{\"matched_paper_id\":\"58027670\",\"id\":\"b18\"}},{\"start\":\"39614\",\"end\":\"39856\",\"attributes\":{\"matched_paper_id\":\"67872077\",\"id\":\"b19\"}},{\"start\":\"39858\",\"end\":\"40024\",\"attributes\":{\"matched_paper_id\":\"1677864\",\"id\":\"b20\"}},{\"start\":\"40026\",\"end\":\"40195\",\"attributes\":{\"matched_paper_id\":\"155109576\",\"id\":\"b21\"}},{\"start\":\"40197\",\"end\":\"40449\",\"attributes\":{\"matched_paper_id\":\"189824904\",\"id\":\"b22\"}},{\"start\":\"40451\",\"end\":\"40874\",\"attributes\":{\"id\":\"b23\",\"doi\":\"arXiv:1807.08583\"}},{\"start\":\"40876\",\"end\":\"41126\",\"attributes\":{\"matched_paper_id\":\"88520328\",\"id\":\"b24\"}},{\"start\":\"41128\",\"end\":\"41232\",\"attributes\":{\"matched_paper_id\":\"110511037\",\"id\":\"b25\"}},{\"start\":\"41234\",\"end\":\"41475\",\"attributes\":{\"id\":\"b26\"}},{\"start\":\"41477\",\"end\":\"41626\",\"attributes\":{\"id\":\"b27\"}},{\"start\":\"41628\",\"end\":\"41754\",\"attributes\":{\"id\":\"b28\"}},{\"start\":\"41756\",\"end\":\"41906\",\"attributes\":{\"id\":\"b29\"}}]", "bib_title": "[{\"start\":\"34503\",\"end\":\"34584\"},{\"start\":\"34811\",\"end\":\"34940\"},{\"start\":\"35173\",\"end\":\"35250\"},{\"start\":\"35411\",\"end\":\"35476\"},{\"start\":\"35645\",\"end\":\"35768\"},{\"start\":\"36007\",\"end\":\"36127\"},{\"start\":\"36459\",\"end\":\"36527\"},{\"start\":\"36669\",\"end\":\"36757\"},{\"start\":\"36927\",\"end\":\"37002\"},{\"start\":\"37782\",\"end\":\"37852\"},{\"start\":\"38234\",\"end\":\"38324\"},{\"start\":\"38490\",\"end\":\"38603\"},{\"start\":\"38787\",\"end\":\"38934\"},{\"start\":\"39152\",\"end\":\"39200\"},{\"start\":\"39342\",\"end\":\"39438\"},{\"start\":\"39614\",\"end\":\"39697\"},{\"start\":\"39858\",\"end\":\"39903\"},{\"start\":\"40026\",\"end\":\"40084\"},{\"start\":\"40197\",\"end\":\"40282\"},{\"start\":\"40876\",\"end\":\"40917\"},{\"start\":\"41128\",\"end\":\"41147\"}]", "bib_author": "[{\"start\":\"34586\",\"end\":\"34595\"},{\"start\":\"34942\",\"end\":\"34960\"},{\"start\":\"35252\",\"end\":\"35259\"},{\"start\":\"35478\",\"end\":\"35488\"},{\"start\":\"35770\",\"end\":\"35781\"},{\"start\":\"36129\",\"end\":\"36140\"},{\"start\":\"36140\",\"end\":\"36152\"},{\"start\":\"36529\",\"end\":\"36538\"},{\"start\":\"36759\",\"end\":\"36769\"},{\"start\":\"37004\",\"end\":\"37013\"},{\"start\":\"37220\",\"end\":\"37227\"},{\"start\":\"37413\",\"end\":\"37424\"},{\"start\":\"37648\",\"end\":\"37657\"},{\"start\":\"37854\",\"end\":\"37863\"},{\"start\":\"38081\",\"end\":\"38090\"},{\"start\":\"38326\",\"end\":\"38336\"},{\"start\":\"38605\",\"end\":\"38611\"},{\"start\":\"38936\",\"end\":\"38942\"},{\"start\":\"39202\",\"end\":\"39211\"},{\"start\":\"39440\",\"end\":\"39449\"},{\"start\":\"39699\",\"end\":\"39710\"},{\"start\":\"39905\",\"end\":\"39914\"},{\"start\":\"40086\",\"end\":\"40095\"},{\"start\":\"40284\",\"end\":\"40293\"},{\"start\":\"40611\",\"end\":\"40622\"},{\"start\":\"40919\",\"end\":\"40933\"},{\"start\":\"41149\",\"end\":\"41158\"},{\"start\":\"41514\",\"end\":\"41525\"},{\"start\":\"41525\",\"end\":\"41534\"},{\"start\":\"41534\",\"end\":\"41544\"}]", "bib_venue": "[{\"start\":\"34595\",\"end\":\"34629\"},{\"start\":\"34960\",\"end\":\"34968\"},{\"start\":\"35259\",\"end\":\"35270\"},{\"start\":\"35488\",\"end\":\"35505\"},{\"start\":\"35781\",\"end\":\"35802\"},{\"start\":\"36152\",\"end\":\"36209\"},{\"start\":\"36538\",\"end\":\"36542\"},{\"start\":\"36769\",\"end\":\"36775\"},{\"start\":\"37013\",\"end\":\"37016\"},{\"start\":\"37149\",\"end\":\"37218\"},{\"start\":\"37351\",\"end\":\"37411\"},{\"start\":\"37565\",\"end\":\"37646\"},{\"start\":\"37863\",\"end\":\"37871\"},{\"start\":\"38008\",\"end\":\"38079\"},{\"start\":\"38336\",\"end\":\"38340\"},{\"start\":\"38611\",\"end\":\"38621\"},{\"start\":\"38942\",\"end\":\"38946\"},{\"start\":\"39211\",\"end\":\"39225\"},{\"start\":\"39449\",\"end\":\"39455\"},{\"start\":\"39710\",\"end\":\"39714\"},{\"start\":\"39914\",\"end\":\"39918\"},{\"start\":\"40095\",\"end\":\"40099\"},{\"start\":\"40293\",\"end\":\"40302\"},{\"start\":\"40451\",\"end\":\"40609\"},{\"start\":\"40933\",\"end\":\"40973\"},{\"start\":\"41158\",\"end\":\"41169\"},{\"start\":\"41234\",\"end\":\"41265\"},{\"start\":\"41477\",\"end\":\"41512\"},{\"start\":\"41628\",\"end\":\"41659\"},{\"start\":\"41756\",\"end\":\"41787\"}]"}}}, "year": 2023, "month": 12, "day": 17}