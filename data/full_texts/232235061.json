{"id": 232235061, "updated": "2022-01-14 20:04:53.189", "metadata": {"title": "Self-Supervised Anomaly Detection for In-Vehicle Network Using Noised Pseudo Normal Data", "authors": "[{\"middle\":[\"Min\"],\"last\":\"Song\",\"first\":\"Hyun\"},{\"middle\":[\"Kang\"],\"last\":\"Kim\",\"first\":\"Huy\"}]", "venue": "IEEE Transactions on Vehicular Technology", "journal": "IEEE Transactions on Vehicular Technology", "publication_date": {"year": 2021, "month": null, "day": null}, "abstract": "As the risk of cyber and safety threats to vehicle systems has increased, the anomaly detection in in-vehicle networks (IVN) has received the attention of researchers. Although, machine-learning-based anomaly detection methods have been proposed, there are limitations in detecting unknown attacks that the model has not learned because general supervised learning-based approaches depend on training dataset. To solve this problem, we propose a novel self-supervised method for IVN anomaly detection using noised pseudo normal data. The proposed method consists of two deep-learning models of the generator and the detector, which generates noised pseudo normal data and detects anomalies, respectively. Firstly, the generator is trained with only normal network traffic to generate pseudo normal traffic data. Then, the anomaly detector is trained to classify normal traffic and noised pseudo normal traffic as normal and abnormal, respectively. The experimental results demonstrate that the anomaly detection models, trained with the proposed method, not only significantly improved in the detection of unknown attacks, but also outperformed other semi-supervised learning-based methods.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/tvt/SongK21", "doi": "10.1109/tvt.2021.3051026"}}, "content": {"source": {"pdf_hash": "7cdc2915f69c9d87ecb734eb9d2bcbedb8e1b60e", "pdf_src": "IEEE", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "37db7314c85a63e884c94470bdb715fd15d7b95e", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/7cdc2915f69c9d87ecb734eb9d2bcbedb8e1b60e.txt", "contents": "\nSelf-Supervised Anomaly Detection for In-Vehicle Network Using Noised Pseudo Normal Data\nFEBRUARY 2021\n\nStudent Member, IEEEHyun Min Song \nMember, IEEEHuy Kang Kim \nSelf-Supervised Anomaly Detection for In-Vehicle Network Using Noised Pseudo Normal Data\n\nIEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY\n702FEBRUARY 202110.1109/TVT.2021.30510261098Index Terms-Anomaly detectionautomotive securitycontroller area networkself-supervised learning\nAs the risk of cyber and safety threats to vehicle systems has increased, the anomaly detection in in-vehicle networks (IVN) has received the attention of researchers. Although, machinelearning-based anomaly detection methods have been proposed, there are limitations in detecting unknown attacks that the model has not learned because general supervised learning-based approaches depend on training dataset. To solve this problem, we propose a novel self-supervised method for IVN anomaly detection using noised pseudo normal data. The proposed method consists of two deep-learning models of the generator and the detector, which generates noised pseudo normal data and detects anomalies, respectively. Firstly, the generator is trained with only normal network traffic to generate pseudo normal traffic data. Then, the anomaly detector is trained to classify normal traffic and noised pseudo normal traffic as normal and abnormal, respectively. The experimental results demonstrate that the anomaly detection models, trained with the proposed method, not only significantly improved in the detection of unknown attacks, but also outperformed other semi-supervised learning-based methods.\n\nanalysis techniques [1], [2] for subsequent message injection attacks. Recent studies have proved that vehicle hacking due to message injection attacks on in-vehicle networks is not a theoretical threats, but an imminent practical cyber threats [3]. These threats existing in in-vehicle network system could harm not only the safety of the target vehicle, but also that of the road environment including other vehicles, pedestrians, and road infrastructures.\n\nDespite the necessity of research on security technology to mitigate such cyber threats to automotive systems, it is difficult to understand in-vehicle data because manufacturers do not publish CAN specifications of their vehicles for security issues. However, security through obscurity (STO), which is the reliance on the secrecy of implementation, does not ensure the vehicle security. It is necessary to actively share vehicle data to promote security technology research. Some pioneer researchers have been sharing their own datasets for vehicle security research [4], [5]. Still, the attack types included in the datasets are limited, and an intrusion detection system (IDS) developed based on the limited attack data could be biased to the attack types of the datasets and, as a result, could not detect unknown attacks well.\n\nThus, the objectives of this paper are to provide an anomaly detection method in such a limited data environment where attack data is deficient while normal data is relatively easy to obtain. To solve this problem, we propose a novel anomaly detection system based on self-supervised learning so that the model can detect unknown attacks even when they are not included in the training dataset. The key idea of the proposed method is to make the detection model learn manifolds of normal data that represent the distribution of normal samples in the data space using noised pseudo normal data rather than directly learning to classify given attack samples.\n\nIn this paper, our contributions can be summarized as follows:\n\nr This paper proposes a novel method of training anomaly detection model based on self-supervised learning for invehicle network security. The anomaly detection model trained with the proposed method is able to detect not only the types of attacks given during the training process, but also unknown types of attacks that have never been seen before.\n\nr We also presents the long short-term memory (LSTM)based generator that generates the noised pseudo normal data, which mimics real CAN traffic data but is slightly deviated by added noise. Kullback-Leibler divergence is used to measure the similarity between the generated data and the real data. The generated noised pseudo normal data 0018-9545 \u00a9 2021 IEEE. Personal use is permitted, but republication/redistribution requires IEEE permission. See https://www.ieee.org/publications/rights/index.html for more information. is used as abnormal data to help the anomaly detection model learns the manifolds of normal data.\n\nr The result of the experiment, performed on the car hacking dataset collected from a real vehicle, demonstrates that the proposed method significantly improves the detection performance of the anomaly detection model against unknown attacks while keeping comparable detection performance against known attacks. The The rest of this paper is organized as follows: in Section II, we provide the background knowledge about CAN security and introduce previous related works of intrusion or anomaly detection in IVNs. Section III introduces the proposed self-supervised learning based anomaly detection method, and the experimental result of the proposed algorithm using the dataset collected from a real vehicle is described in Section IV. Finally, we conclude this study and provide some perspectives in Section V.\n\n\nII. IN-VEHICLE NETWORK SECURITY\n\nIn this section, we provide background information on automotive CAN security and introduce previous studies on intrusion or anomaly detection methods for automotive CAN system.\n\n\nA. Controller Area Network\n\nAs we introduced briefly in section I, CAN was first developed by Bosch in 1985 to reduce wiring cost, complexity and weight, which increases as the number of electronic devices in the vehicle increases. Due to its high stability and efficiency, it is used as a de facto standard for in-vehicle communication systems in modern vehicles. Fig. 1 shows exemplary structure of in-vehicle CAN bus system. There are several CAN buses and they are inter-connected through a gateway. In-vehicle communication system is segmented by functionalities such as powertrain, comfort, and instrument. Since CAN is a serial bus, by adopting a segmented structure, it enables fast and efficient data exchange between relevant ECUs and prevents the communication channel from being too crowded.\n\nCAN is a message-based broadcast protocol in which ECUs send data in a predefined data frame called messages, as shown in Fig. 2. A CAN message has an arbitration identifier (ID), also known as CAN ID, and payload. Since there is no information about the sender or receiver node in the CAN message, the CAN ID is used to indicate which vehicle information is contained in the payload. The payload contains actual vehicle parameter values. However, there is no standard which defines the details of CAN ID and its payload, and thus manufacturers use their own policies. Furthermore, even the vehicle models from the same manufacturer also use different CAN specifications, and these CAN specifications are kept confidential. This is one of the major reasons why security researchers struggle to develop intrusion or anomaly detection systems for automotive systems using in-vehicle data directly.\n\n\nB. CAN Security Aspects\n\nThe main aspects of CAN security are described in Fig. 3. The most representative weaknesses of current in-vehicle communication systems are due to the nature of broadcast-based system, ID-based message priority scheme, lack of authentication, and unencrypted communication. Since all nodes connected to the same CAN bus can transmit and receive all CAN messages on the bus, an attacker can sniff CAN traffic or inject fabricated messages to cause ECU malfunctions or manipulate the vehicle.\n\nCheckoway et al. presented various attacks surfaces which can be exploited to inject messages into the CAN bus [6]. They divided the attack surfaces into physical access and remote access. The physical access is made through the onboard diagnostic (OBD)-II port, although it is difficult to occur in real-world environment, it is not impractical. The remote access can be made through various wireless communication systems such as Bluetooth, WiFi, or telematics service. These access points can be used to inject fabricated messages into the internal CAN bus. Fig. 4 shows how ECUs transmit messages on the CAN bus and how message injection attacks are performed. There are two ECUs which send CAN messages every t A and t B , respectively. When the ECUs try to send their message on the same time, the ECU A , which has lower CAN ID, has priority to transmit. After ECU A has finished transmitting, ECU B transmits the message.   There is a short time interval between two messages called interframe space (IFS) separating the signals of two messages. Once an attacker has an access to the CAN bus by connecting his own attack node to CAN bus or compromising one of existing node, he can easily perform sniffing or spoofing attacks to deceive ECUs by sending fabricated messages to interleave between normal messages sent from the normal ECUs. Since there is no sender information in the CAN message frame format, other ECUs cannot know whether the message being transmitted has been manipulated.\n\nIn this study, we assume that the attacker already has access to the vehicle CAN bus in some way like connecting new node via OBD-II port or exploiting an existing vehicle system such as telematics system and infotainment system. In this situation, the attacker is able to conduct some kind of cyber attacks as follows:\n\n1) Attacks on Confidentiality: Since CAN communication is not encrypted, the attacker is able to see all of the vehicle's critical driving information transmitted through CAN traffic. Once the attacker has collected CAN traffic, he can use reverse engineering analysis techniques [1], [2], [7] to analyze which CAN IDs are used to convey the vehicle's key parameters such as vehicle speed, engine RPM and drive gear to conduct sophisticated attacks to cause vehicle malfunctions or control the vehicle.\n\n2) Attacks on Availability: Because CAN is a bus system, collision occurs when two or more nodes attempt to send a message at the same time. To avoid communication error by collision, transmitting nodes go through the arbitration phase by transmitting CAN ID prior to payload. At this time, the node transmitting the lower CAN ID has priority and continues to transmit the remaining message data. Other nodes with higher CAN IDs stop transmitting and wait until the current message transmission is complete. The attacker can exploit the arbitration mechanism to disrupt CAN communication. This kind of attack is called Denial-of-Service (DoS) and can be conducted on CAN systems by continuously injecting CAN messages with low CAN IDs to prevent other nodes from sending their messages.\n\n3) Attacks on Integrity: If the attacker acquires knowledge of the target vehicle's CAN specification, he can perform spoofing attacks to deceive ECUs to control the vehicle as he wishes. The ECUs mounted on the vehicle operate according to the value contained in the last received message. The attacker can send manipulated messages as soon as the original ECU sends messages to overwrite the data, other ECUs operate based on the data sent by the attacker. For example, if the attacker wants to change the gear that is actually in neutral state to driving state, he have to send continuously manipulated messages with the CAN \n\n\nIII. RELATED WORKS\n\nWe introduce previous research works on anomaly and intrusion detection for in-vehicle CAN communication system. They can be grouped into four categories, which are specificationbased, fingerprint-based, statistics-based, and machine learningbased approaches, as summarized in Table I.\n\nThe main purpose of the specification-based method is to detect anomalous behavior that does not match the specifications of the system, such as protocol and frame format. Larson et al. proposed an attack detection method that detects messages which do not follow pre-defined ECU behaviors [8]. ECUs can check the validity of the received CAN message using the security specifications. However, since this method depends on the specifications, if an attacker transmits well-modified CAN messages that do not violate the system's specification, the detection system will not identify them. Olufowobi et al. proposed a real-time specification-based IDS which extracts timing model by observing CAN traffic in real-time and detects anomalies without using predefined specification [9]. This algorithm has the advantage that it can be applied without information about the vehicle's CAN parameter, but it showed relatively poor performance in the real attack dataset. Muter et al. proposed an anomaly detection system consisting of a set of anomaly sensors which are based on properties of typical vehicular networks [10]. Each of the eight sensors detects attacks by examining formality, location, value range, frequency, correlation, protocol, plausibility, and consistency, respectively. The authors stated that the proposed method still does not detect intelligent attacks of message injection, which fully complies with the normal behavior of the system. Fingerprint-based methods are similar to the specificationsbased method but have a difference in which they use profiles defined based on the characteristics of ECUs instead of specifications. Cho and Shin proposed the clock-based IDS profiling ECUs based on skew between the frequencies of the real clock and the reference clock [11]. But, this method has a limitation in that all ECU nodes of the vehicle must be profiled in advance. Choi et al. proposed a novel method named VoltageIDS, which uses physical-layer data of CAN communication [12]. They focused on the electrical signal characteristics of each ECU and used the signal characteristics as the fingerprint of the ECU.\n\nStatistics-based methods generally use statistics that can be obtained from CAN traffic at the network layer. Muter et al.\n\nproposed an entropy-based anomaly detection [13] that measures the uncertainty of CAN IDs in the CAN bus. They detect attacks by comparing the entropy of the observed network traffic to the entropy of the reference traffic. Similarly, Marchetti et al. also proposed an entropy-based anomaly detection method and evaluated the effectiveness of the entropy-based anomaly detection method [20]. They conducted an extensive experimental evaluation using several hours of CAN traffic logged while driving in a real road and traffic environment. Song et al. proposed a light-weight intrusion detection method based on temporal interval of messages [14]. Although the proposed algorithm could detect message injection attacks fast with low computing cost, it assumes all CAN messages are sent at regular intervals and cannot detect irregular incoming messages. Young et al. presented a comprehensive analysis of the timing intervals of CAN messages in the frequency domain [15]. They investigated the frequency characteristics of CAN messages in various driving modes such as key-on, shifting to reverse, acceleration, and maintaining speed, and the proposed frequency-based IDS showed high detection accuracy in experiments conducted on two test vehicles. In general, statistics-based methods have limitations in detecting low-volume attacks in which the attacker injects a small number of messages at long intervals, while they show decent performance for high-volume attack detection.\n\nIn recent years, machine-learning-based methods have been actively proposed. They mostly use supervised learning, which requires a large amount of fully labeled data when training a model. Kang and Kang proposed a deep belief network (DBN) based intrusion detection method [16]. Although it has the advantage of being able to pretrain the feature extraction layer in an unsupervised method, the training phase of DBN is a very time-consuming task, resulting in a large overhead. Tariq et al. proposed a LSTM-based intrusion detection method named CANtransfer [17]. CANtransfer showed improved detection performance for new attacks using transfer learning, but relatively worse detection performance for known attacks. On the other hand, Barletta et al. proposed a novel unsupervised learning-based intrusion detection method using Kohonen Self-Organizing Map (SOM) network and k-means clustering algorithm [18]. They improved the traditional procedure by using the distance between input vectors and neurons in the k-means algorithm instead of the neuron codebook vector of the traditional procedure. Although these machine-learningbased methods show a fairly high detection performance, it is suitable when sufficient labeled data can be obtained for model training because of the difficulty of collecting well-labeled data.\n\nHowever, in most real-world problems, including IVN anomaly detection, there is a class-imbalance problem because the occurrence of abnormal samples is significantly less than normal samples. Specifically, it is relatively easy to collect normal CAN traffic from a vehicle, but it is very difficult to collect abnormal traffic, including intrusion. Furthermore, it may be possible to obtain abnormal traffic, including certain types of intrusions in some cases. Still, the model trained with the limited attack samples will not effectively detect zero-day attacks or variants that are not seen in the training process.\n\nConsidering the difficulty of collecting attack data and the need for generalization, some researchers proposed anomaly detection methods based on semi-supervised learning. Taylor et al. proposed the one-class SVM (OCSVM) based anomaly detection that detects deviations of message frequencies [19]. However, semi-supervised learning-based methods still have a high false alarm problem.\n\n\nIV. SELF-SUPERVISED ANOMALY DETECTION\n\nIn general classification problems, model training process is to learn the decision boundary that distinguishes normal samples from abnormal samples in the data space. Fig. 5 shows exemplary data distribution on virtual data space. As shown in Fig. 5(a), if there are enough amount of well-labeled normal and attack samples for model training, a classifier can learn the decision boundary between the normal region and abnormal region via supervised learning. However, in most real world problem, it is difficult to collect abnormal samples and usually there is only normal data as shown in Fig. 5(b). For example, in IVN security, we can collect normal network traffic while driving a vehicle, but it is difficult to collect abnormal data due to safety issues. Furthermore, even if some abnormal data can be collected by performing some network attacks in a strictly controlled environment, the detection model trained with the attack data will be biased to the training data, making it difficult to detect unknown attacks represented by orange diamonds.\n\nThus, due to these practical limitations, we need to train the correct decision boundary to the detection model using limited data which consists of mostly normal samples. To achieve this goal, we propose a self-supervised learning based anomaly detection method in which the detection model learns the decision boundary enclosing the region of normal data in the data space using noised pseudo normal data as shown in Fig. 5(c). Since the detection model learns manifolds of normal data instead of the difference between normal samples and known attack samples, it can detect anomalies even if they are not seen during the training process. Fig. 6 shows the overall process of the proposed method and the proposed anomaly detection system consists of two neural network models called pseudo normal traffic generator and anomaly detector. At first, the pseudo normal traffic generator is trained in advance using normal CAN traffic to produce outputs that mimic real CAN traffic called pseudo normal data. Then, the generator generates pseudo normal CAN traffic data that  will be used as abnormal data for training the detection model. At this point, noise is added to pseudo normal data so that the distribution of pseudo normal data slightly deviates from the distribution of normal data. The detection model is trained to determine whether a given sample is from the real CAN traffic or the generated noised pseudo normal CAN traffic.\n\n\nA. Preprocessing\n\nIn this study, we use only CAN ID sequence for modeling sequential patterns of CAN traffic except payload of messages. Before training models, in the preprocessing stage, CAN IDs are extracted from CAN messages and divided to form CAN ID sequences. CAN IDs are represented in different forms in the generator model and the anomaly detector model. For the generator model, each CAN ID represented as a hexadecimal string is mapped to an integer representation as an indexes from 0 to the number of CAN IDs in CAN traffic. On the other hand, for the anomaly detector model, each CAN ID is converted to a bit representation of length 11. Note that CAN ID is expressed as 11 bits in the CAN 2.0 A specification. After CAN ID conversion according to each model, the converted CAN ID sequence is divided into small batches of fixed length sub-sequences to be fed into the models.\n\n\nB. Noised Pseudo Normal Data Generation\n\n\n1) Architecture of the Generator Model:\n\nThe neural network of generator model is based on LSTM, which is a representative kind of recurrent neural networks (RNNs). LSTM networks are suitable for processing time series data such as speech and video using its feedback connection. The input to the generator model is a CAN ID or a sequence of CAN IDs. The LSTM-based model is trained to guess which CAN ID is the most probable as the following CAN ID at each time step based on a given CAN ID or a sequence of CAN IDs. Since RNNs have an internal state that contains the context of the previously seen elements, given all the CAN IDs in a sequence are accounted in predicting the next CAN ID. Fig. 7 shows the structure of the LSTM-based generator model that consists of an embedding layer, a LSTM layer and a dense layer. The embedding layer is the input layer that maps a given index, an integer representation of a CAN ID, to a vector of fixed-length, which is set to 256 in this study. The converted CAN ID vector is fed to the next LSTM layer with 256 units. The LSTM layer extracts the context of a given sequence. Finally, the dense layer then outputs logits predicting the log-likelihood of the next CAN ID. Therefore, the output size of the dense layer is the same as the number of CAN IDs. The prediction of the next CAN ID is derived by sampling from this probability distribution. By creating a stochastic model rather than a deterministic model, the trained generator model can better mimic the sequential characteristics of real CAN traffic and produce CAN ID sequences of various patterns with subtle differences from the CAN ID sequences of real CAN traffic.\n\n2) Training the Generator Model: The problem of predicting the next CAN ID can be considered as a general multi-class classification problem. The LSTM-based generator model predict the class of the next CAN ID based on the given previous state of the LSTM layer and the input CAN ID of this time step.\n\nThe categorical cross-entropy loss function is used because the last dense layer outputs a probability over the CAN IDs. The categorical cross-entropy can be implemented by adding Softmax activation before calculating the cross-entropy. The softmax activation normalizes a C-dimensional vector s to a C-dimensional vector \u03c3(s) in the range (0, 1) of which the sum is 1, which is calculated as:\n\u03c3(s) i = exp s i C c=1 exp s c (i = 0 , . . . , C).(1)\nIn this study, C represents the number of CAN IDs and the vector s represents the output logits of the last dense layer. Then, the cross-entropy loss is computed as:\nCE = \u2212 C i t i log(\u03c3(s) i )(2)\nwhere t i represents the target next CAN ID of the given sequence.\n\n\n3) Generating CAN ID Sequence:\n\nOnce the generator model is trained, it is able to generate long CAN ID sequences that mimic the CAN ID sequence of real CAN traffic, even though the model has been trained on small batches of CAN ID sequence. We can generate CAN ID sequence by feeding a start CAN ID to the generator model with setting the number of CAN IDs to generate. The generator model predicts the distribution of the next CAN ID based on the given start CAN ID. Then, we can obtain the index of the next CAN ID by sampling from the predicted probability distribution, and this predicted CAN ID is used as next input to the model. At this point, in order to increase diversity to the generated pseudo normal data, we have the generator model sample from a uniform distribution with a given probability, called the noise ratio, instead of the predicted probability distribution from the dense layer when choosing the next CAN ID. For example, when the probability of uniform sampling is given as 0.2, 20% of the CAN IDs of the generated sequence is selected by sampling from uniform distribution.\n\n\nC. Anomaly Detection\n\nWe used the Reduced Inception-ResNet model proposed by Song et al. as our detection model [21]. The Reduced Inception-ResNet model is the modified version of the Inception-ResNet proposed by He et al. and redesigned by reducing the original model for high-resolution image processing to be suitable for processing CAN data with much smaller data sizes.\n\nThe detection model is trained through supervised learning using noised pseudo normal data, generated by the generator model, and attack-free CAN traffic data. Accordingly, training the detection model is considered as a binary classification problem. Samples of attack-free CAN data and pseudo normal data are labeled as 0 and 1 respectively. In addition to pseudo normal data, we use additional abnormal data, hints data for attacks, which is one type of attack data. We assume that a certain type of attack data can be obtained and used in training alongside noised pseudo normal data. This hint of attack helps the model learn the pattern of attacks as well as the manifolds of normal data. The hints data is also labeled as 1 like the noised pseudo normal data.\n\nSimilar to the generator model training with categorical cross entropy, the binary cross-entropy loss is used to train the detection model because it classifies the input CAN ID sequence into two classes, normal and abnormal. The binary cross-entropy loss is calculated by equation 2. Apparently, C is set to 2 depending on the number of output classes.\n\nWe also apply gradient clipping to prevent exploding gradients problem during model training [22]. The exploding gradients problem is that large error gradients accumulate and cause too large updates to the model weights during training. This makes the model unstable and unable to learn training data correctly. We have observed that the exploding gradients problem occurs when training the model using a large learning rate.\n\nGradient clipping can be implemented simply by limiting the gradient to keep it small. Specifically, if the norm of the gradient ||g|| is greater than the given threshold c, then it can be rescaled as:\ng \u2190 cg ||g|| (3)\nwhere c is a hyper-parameter, g is the gradient, ||g|| is the norm of g. Note that if ||g|| is less than c, then it doesn't need to be clipped. Gradient clipping helps to make the model training process more reliable by ensuring the gradient g has norm at most c.\n\n\nV. EXPERIMENTAL RESULTS\n\n\nA. Datasets\n\nWe used car-hacking dataset which is published by Song et al. [21], which is widely used in automotive security research [9], [18]. The dataset consists of logged CAN traffic files collected from a real vehicle including 4 types of attacks, which are DoS, fuzzing, spoofing the engine RPM, and spoofing the drive gear attacks. The DoS attack is performed by injecting messages with '0x00' CAN ID that is most dominant CAN ID in CAN bus. The goal of this attack is blocking the exchange of information between ECUs by preventing ECUs from sending messages. The fuzzing attack is performed by inject messages with random CAN ID and payload with the purpose of causing ECUs to malfunction. The spoofing attacks are performed by injecting messages with the CAN IDs, which are related to engine RPM and drive gear respectively, to manipulate specific functions in order to control the vehicle. Table II shows the number of normal and injected messages in each file. The log files contain the time stamp, CAN ID, DLC, payload and label of each message. For each CAN message, the timestamp is the time the message was recorded from the start-up, the CAN ID is an identifier represented in hexadecimal, the DLC is the payload length in byte (up to 8), and the label indicates whether the message is normal or attack.\n\n\nB. Noised Pseudo Normal Data Analysis\n\nWe used the Kullback-Leibler divergence to measure how the noised pseudo normal data, generated by the generator model as introduced in section IV-B, is different from the real CAN traffic data. The Kullback-Leibler divergence is generally used to measure the difference between two discrete probability distributions and defined as:\nD KL (P ||Q) = P (x) log P (x) Q(x)(4)\nwhere P and Q are discrete probability distributions to be compared. If given two distributions are identical, then the Kullback-Leibler divergence is zero. Thus, we can measure the difference between the generated noised pseudo normal data and the real CAN traffic data by measuring the Kullback-Leibler divergence between the CAN ID distribution of them. Fig. 8 shows the Kullback-Leibler divergences when we generated the pseudo normal data according to the noise ratio. In the case of generating the noised pseudo normal data with noise ratio 0.1, the Kullback-Leibler divergence between the CAN ID distribution of the generated data and the real data is measured as 0.008533, and the divergence increases as the noise ratio increases as expected. Table III shows the detection accuracy of the detection model according to the noise ratio. The models is trained with learning rate of 1 \u00d7 10 \u22126 for 1000 epochs equally. We expected the model to show a higher detection accuracy as the model was trained using generated data with a lower noise ratio. However,   as shown, the model trained with noise ratio 0.2 shows the highest detection accuracy of 0.8496 on average for the four attack datasets.\n\n\nC. Impact of Noise Ratio\n\n\nD. Effectiveness of Hint Data\n\nWe assumed that a certain type of attack data can be obtained in practice and thus used in model training with the generated noised pseudo normal data (section IV-C). In this experiment, about 20% of engine RPM spoofing attack data is used as hint data. The models is trained with learning rate of 1 \u00d7 10 \u22126 for 1000 epochs equally. Table IV shows the detection accuracy of the detection model trained with hint data. We can see that the detection accuracy increases 11.46% on average compared to the model without hint data. Obviously, the detection model best detects RPM spoofing attacks, which are used as hint data, and especially has a remarkable improvement in DoS attack detection where the model showed the worst performance without hint data. On the other hand, unfortunately, we could not achieve improvement in \n\n\nE. Effectiveness of Gradient Clipping\n\nThe learning rate is a hyper-parameter that adjusts the step size at each iteration during the model optimization process, also known as gradient back-propagation. Since the learning rate affects the learning speed of the model, there is a trade-off between the rate of convergence and the time cost of training. Thus, when using a large learning rate, the back-propagating gradient causes large updates of the model weights, resulting in unstable model convergence, and in the worst case, model training fails.\n\nAs shown in Table V, when the model is trained with learning rate of 1 \u00d7 10 \u22124 and 1 \u00d7 10 \u22125 , the exploding gradient problem occurs after 4 epochs and 35 epochs respectively, whereas when the model is trained with lower learning rates of 1 \u00d7 10 \u22126 and 1 \u00d7 10 \u22127 , it has successfully completed training up to 1000 epochs.\n\nHowever, training a model with a low learning rate takes too long time for the model to converge. We applied the gradient clipping technique as introduced in section IV-C to shorten the model training time by using a larger learning rate. After applying the gradient clipping, we were able to train the model up to 200 epochs using the learning rate of 1 \u00d7 10 \u22124 and 1 \u00d7 10 \u22125 , and furthermore, the trained model achieved better the detection accuracy of 0.9537 on average over four attack datasets with 5 times less training than the model trained for 1000 epochs using the learning rate of 1 \u00d7 10 \u22126 .\n\n\nF. Comparison to Other Algorithms\n\nIn addition to the DCNN model, we applied our method to the support vector machine (SVM) algorithm to verify the effectiveness of the proposed method in improving model performance. Furthermore, we compared the performance of our models with two representative semi-supervised learning-based algorithms, which are one-class SVM (OCSVM) and deep-autoencoder (DAE). The OCSVM and DAE models are trained using only normal data and detect outliers that deviate from the distribution of the trained data.\n\n\n1) Evaluation Metrics:\n\nTo evaluate the detection performance of test models against message injection attacks more precisely, we also measure precision, recall, and F1-score compared to other machine-learning algorithms. Precision is the fraction of real attack samples among the samples detected as attack, and calculated as:\nP recision = T P/(T P + F P ).(5)\nwhere T P (true positive) and F P (false positive) are the number of samples that are classified as attack correctly and incorrectly, respectively. Recall is the fraction of correctly detected attack samples among the actual attack samples, and thus recall is also called as true positive rate (TPR) calculated as:\nRecall = T P/(T P + F N).(6)\nwhere F N (false negative) is the number of samples classified as normal but are actually attacks. The F1-score represents the balance between precision and recall, and is generally used to measure classification performance when the class distribution is imbalanced in the test dataset. F1-score is calculated as:\nF S = 2 \u00d7 (P recision \u00d7 Recall)/(P recision + Recall).(7)\n2) Detection Results: The DCNN and SVM models are trained in two cases: 1) using only the hint data and 2) using the hint data and the noised pseudo normal data while semi-supervised learning-based models, OCSVM and DAE, are trained using only normal data, which is real CAN traffic data without any attack data. The SOMK-D algorithm based on unsupervised learning is trained using the hint data. Table VI shows the attack detection performance of the test models. We can see that the detection performance of DCNN and SVM models, which are trained using both of the hint data and the noised pseudo normal data, improved significantly by 131% (from 0.4090 to 0.9451) and 78% (from 0.4231 to 0.7517) in F1-score, respectively. We note that the spoofing RPM attack data is used as the hint data. Therefore, it is reasonable that the DCNN and SVM models trained using only the hint data have comparable detection performance against spoofing RPM attacks.\n\nInterestingly, the DAE model shows decent detection performance over all types of attacks even though it is trained only with normal data. Furthermore, the DAE model also has the best detection performance against fuzzing attacks than other models. However, OCSVM and SOMK-D models, which are trained using only hint data without generated data, can not successfully detect unknown attacks of DoS, Fuzzing, and spoofing gear attacks as expected. Especially, the SOMK-D model misclassified most of the unknown attacks into the normal class, while the detection performance for spoofing rpm attacks used for training showed the highest accuracy. In addition, through this experiments, it is determined that SVM-based models are not suitable for detecting vehicle CAN abnormalities.\n\nAs a result, the DCNN model trained by the proposed method shows the best detection performance with 0.9537 of accuracy and 0.9451 of F1-score on average. This results shows that the proposed method of using noised pseudo normal data for model training successfully improved the detection model to detect not only known attacks, but also unknown attacks which have never been seen.\n\n\nG. Discussion and Limitation\n\nThe experimental results, conducted in this study, demonstrate that using noised pseudo normal data as abnormal data to train an anomaly detector model significantly improves the detection performance of the model in detecting unknown attacks that the model had never seen before. We tested various noise ratios when generating noised pseudo normal data, but did not draw any meaningful conclusions about the impact of noise ratio. We expected that using a lower noise ratio would result in a more sophisticated model, but in practice using a noise ratio of 0.2 and 0.4 performed better.\n\nWe also explored whether the use of hint data provides a performance improvement to the detection model. Models trained with the hint data had improved performance in detecting unknown types of attacks as well as known types of attacks provided as hints. Furthermore, we applied gradient clipping in model training to mitigate the exploding gradient problem to make the training process stable. By applying gradient clipping, we were able to successfully train the model without gradient explosion, and the trained model shows better detection accuracy than the much longer trained model with low learning rate.\n\nIn comparison with other algorithms, DAE model shows decent detection performance with high recall against DoS attacks and Fuzzing attacks, specifically. However, autoencoder-based models generally have a lot of false positives, and this results in relatively low precision. As a result, the DCNN model trained by the proposed method shows the best detection performance not only in accuracy but also F1-score, indicating that the model is not unilaterally biased and well balanced. Furthermore, since the proposed method uses the same model, there is no overhead in testing. The only difference from the original model is that it uses noised pseudo normal data generated from the generator model, not the attack data, to train the model. However, the model still needs to be further improved for better detection performance in order to be used in the realworld requiring extremely high accuracy. In particular, a very sophisticated intrusion detection system is required in order to secure road safety from various cyber threats in an unmanned vehicle environment in the near future where humans cannot know the state of the vehicle. To achieve this goal, additional research on in-vehicle security considering semantic features to detect anomalies caused by system errors not only intrusions such as message injection is required with the cooperation of major vehicle vendors.\n\n\nVI. CONCLUSION\n\nTo our best knowledge, this study is the first research to create an anomaly detection model for in-vehicle network using generated data to detect unknown types of attacks. Thus, this study primarily focused on the method to train an effective anomaly detection model in a limited data environment, common in real-world problems, where only a small number of abnormal samples can be collected and used for model training. The proposed method trains the anomaly detection model to learn manifolds of normal data representing the data distribution of normal data in the data space, instead of learning the difference between given normal and abnormal data.\n\nTo achieve this goal, noised pseudo normal data generated by a generator model is used to train the anomaly detection model. The generator model is based on LSTM, a representative type of RNN, and generates pseudo data that mimic the pattern of normal data. The generator model is trained to predict the next CAN ID of a given CAN ID sequence extracted from normal CAN traffic. Some noise is added to generated pseudo normal data to deviate them from true normal data. This difference helps the anomaly detection model effectively learn the distribution of normal data.\n\nThe experimental result demonstrates that the anomaly detection models trained by the proposed method has greatly improved to detect unknown attacks as well, while keeping comparable detection performance against known attacks which are given as hint data. Furthermore, the DCNN based anomaly detection model outperforms the DAE model, which is based on semi-supervised learning and mostly widely used in outlier detection problems.\n\nAlthough the result of this study still needs further performance improvements to be deployed in real-world applications for now, this study presents the possibility of a comprehensive anomaly detection model based on supervised learning that can detect unknown attacks without being biased to the training data.\n\nFig. 1 .\n1Structure of in-vehicle CAN bus system.\n\nFig. 2 .\n2Structure of CAN 2.0 message frame.\n\nFig. 3 .\n3Overview of CAN security.\n\nFig. 4 .\n4Conceptual diagram of CAN message transmission and message injection attack.\n\nFig. 5 .\n5Conceptual diagram of the decision boundary learned by a model when (a) attack data is given with normal data, (b) only normal data is given, and (c) noised pseudo data is given with normal data.\n\nFig. 6 .\n6Training process of the proposed self-supervised learning-based anomaly detection method.\n\nFig. 7 .\n7Structure of the generator model which receives CAN ID sequence as input and predicts the next CAN ID.\n\nFig. 8 .\n8Kullback-Leibler divergences of noised pseudo normal data.\n\nTABLE I COMPARISONS\nIOF INTRUSION DETECTION METHODS FOR AUTOMOTIVE CAN ID which conveys drive gear data because the original ECU still transmits drive gear data periodically.\n\nTABLE II OVERVIEW\nIIOF CAR-HACKING DATASET\n\nTABLE III DETECTION\nIIIACCURACY ACCORDING TO NOISE RATIO WITHOUT HINT DATA\n\nTABLE IV DETECTION\nIVACCURACY ACCORDING TO NOISE RATIO WITH HINT DATA\n\nTABLE V DETECTION\nVACCURACY ACCORDING TO NOISE RATIO WITH HINT DATA fuzzing attack detection. It seems to be because the patterns of the engine RPM spoofing attack used as hints and the fuzzing attack are quiet different.\n\nTABLE VI DETECTION\nVIPERFORMANCE COMPARED TO OTHER ALGORITHMS\n\nAutomatic reverse engineering of can bus data using machine learning techniques. T Huybrechts, Y Vanommeslaeghe, D Blontrock, G Van, P Barel, Hellinckx, Proc. Int. Conf. P2P, Parallel, Grid, Cloud Int. Comput. Int. Conf. P2P, Parallel, Grid, Cloud Int. ComputT. Huybrechts, Y. Vanommeslaeghe, D. Blontrock, G. Van Barel, and P. Hellinckx, \"Automatic reverse engineering of can bus data using machine learning techniques,\" in Proc. Int. Conf. P2P, Parallel, Grid, Cloud Int. Comput., 2017, pp. 751-761.\n\nDiscovering can specification using on-board diagnostics. H M Song, H K Kim, 10.1109/MDAT.2020.3011036IEEE Des. Test, to be published. H. M. Song and H. K. Kim, \"Discovering can specification using on-board diagnostics,\" IEEE Des. Test, to be published, doi: 10.1109/MDAT.2020.3011036.\n\nRemote exploitation of an unaltered passenger vehicle. C Miller, C Valasek, Black Hat USA. 201591C. Miller and C. Valasek, \"Remote exploitation of an unaltered passenger vehicle,\" Black Hat USA, vol. 2015, p. 91, 2015.\n\nCar-Hacking Datasest for the Intrusion Detection. H M Song, H K Kim, H. M. Song and H. K. Kim, \"Car-Hacking Datasest for the Intrusion Detec- tion,\" Accessed: Sep. 6, 2020. [Online]. Available:http://ocslab.hksecurity. net/Datasets/car-hacking-dataset\n\nOtids: A novel intrusion detection system for in-vehicle network by using remote frame. H Lee, S H Jeong, H K Kim, Proc. IEEE 15th Annu. Conf. Privacy, Secur. Trust. IEEE 15th Annu. Conf. Privacy, Secur. TrustH. Lee, S. H. Jeong, and H. K. Kim, \"Otids: A novel intrusion detection system for in-vehicle network by using remote frame,\" in Proc. IEEE 15th Annu. Conf. Privacy, Secur. Trust., 2017, pp. 57-5709.\n\nComprehensive experimental analyses of automotive attack surfaces. S Checkoway, Proc. USENIX Secur. Symp. USENIX Secur. Symp46S. Checkoway et al., \"Comprehensive experimental analyses of automotive attack surfaces,\" in Proc. USENIX Secur. Symp., vol. 4, 2011, pp. 6.\n\nActt: Automotive can tokenization and translation. M Verma, R Bridges, S Hollifield, Proc. IEEE Int. IEEE IntM. Verma, R. Bridges, and S. Hollifield, \"Actt: Automotive can tokeniza- tion and translation,\" in Proc. IEEE Int. Conf. Comput. Sci. Comput. Intell., 2018, pp. 278-283.\n\nAn approach to specificationbased attack detection for in-vehicle networks. U E Larson, D K Nilsson, E Jonsson, Proc. IEEE Intell. Veh. Symp. IEEE Intell. Veh. SympU. E. Larson, D. K. Nilsson, and E. Jonsson, \"An approach to specification- based attack detection for in-vehicle networks,\" in Proc. IEEE Intell. Veh. Symp., 2008, pp. 220-225.\n\nSaiducant: Specification-based automotive intrusion detection using controller area network (CAN) timing. H Olufowobi, C Young, J Zambreno, G Bloom, IEEE Trans. Veh. Technol. 692H. Olufowobi, C. Young, J. Zambreno, and G. Bloom, \"Saiducant: Specification-based automotive intrusion detection using controller area network (CAN) timing,\" IEEE Trans. Veh. Technol., vol. 69, no. 2, pp. 1484-1494, Feb. 2020.\n\nA structured approach to anomaly detection for in-vehicle networks. M M\u00fcter, A Groll, F C Freiling, Proc. IEEE 6th Int. Conf. Infor. Assurance Secur. IEEE 6th Int. Conf. Infor. Assurance SecurM. M\u00fcter, A. Groll, and F. C. Freiling, \"A structured approach to anomaly detection for in-vehicle networks,\" in Proc. IEEE 6th Int. Conf. Infor. Assurance Secur., 2010, pp. 92-98.\n\nFingerprinting electronic control units for vehicle intrusion detection. K.-T Cho, K G Shin, Proc. 25th {USENIX} Secur. Symp. 25th {USENIX} Secur. SympK.-T. Cho and K. G. Shin, \"Fingerprinting electronic control units for vehicle intrusion detection,\" in Proc. 25th {USENIX} Secur. Symp., 2016, pp. 911-927.\n\nVoltageids: Lowlevel communication characteristics for automotive intrusion detection system. W Choi, K Joo, H J Jo, M C Park, D H Lee, IEEE Trans. Inf. Forensics Secur. 138W. Choi, K. Joo, H. J. Jo, M. C. Park, and D. H. Lee, \"Voltageids: Low- level communication characteristics for automotive intrusion detection system,\" IEEE Trans. Inf. Forensics Secur., vol. 13, no. 8, pp. 2114-2129, Aug. 2018.\n\nEntropy-based anomaly detection for in-vehicle networks. M M\u00fcter, N Asaj, Proc. IEEE Intell. Veh. Symp. IEEE Intell. Veh. SympM. M\u00fcter and N. Asaj, \"Entropy-based anomaly detection for in-vehicle networks,\" in Proc. IEEE Intell. Veh. Symp., 2011, pp. 1110-1115.\n\nIntrusion detection system based on the analysis of time intervals of can messages for in-vehicle network. H M Song, H R Kim, H K Kim, Proc. IEEE Int. Conf. Inf. Net. IEEE Int. Conf. Inf. NetH. M. Song, H. R. Kim, and H. K. Kim, \"Intrusion detection system based on the analysis of time intervals of can messages for in-vehicle network,\" in Proc. IEEE Int. Conf. Inf. Net.., 2016, pp. 63-68.\n\nAutomotive intrusion detection based on constant can message frequencies across vehicle driving modes. C Young, H Olufowobi, G Bloom, J Zambreno, Proc. ACM Workshop Automot. ACM Workshop AutomotC. Young, H. Olufowobi, G. Bloom, and J. Zambreno, \"Automotive intrusion detection based on constant can message frequencies across vehicle driving modes,\" in Proc. ACM Workshop Automot. Cybersec., 2019, pp. 9-14.\n\nIntrusion detection system using deep neural network for in-vehicle network security. M.-J Kang, J.-W Kang, PLoS One. 116155781M.-J. Kang and J.-W. Kang, \"Intrusion detection system using deep neural network for in-vehicle network security,\" PLoS One, vol. 11, no. 6, p. e0155781, 2016.\n\nCantransfer: Transfer learning based intrusion detection on a controller area network using convolutional lstm network. S Tariq, S Lee, S S Woo, Proc. 35th Annu. 35th AnnuS. Tariq, S. Lee, and S. S. Woo, \"Cantransfer: Transfer learning based intrusion detection on a controller area network using convolutional lstm network,\" in Proc. 35th Annu. ACM Symp. Appl. Comput., 2020, pp. 1048- 1055.\n\nIntrusion detection for in-vehicle communication networks: An unsupervised kohonen som approach. V S Barletta, D Caivano, A Nannavecchia, M Scalera, Future Internet. 127V. S. Barletta, D. Caivano, A. Nannavecchia, and M. Scalera, \"Intrusion detection for in-vehicle communication networks: An unsupervised koho- nen som approach,\" Future Internet, vol. 12, no. 7, 2020, Art. no. 119.\n\nFrequency-based anomaly detection for the automotive can bus. A Taylor, N Japkowicz, S Leblanc, Proc. IEEE World Congr. Ind. IEEE World Congr. IndA. Taylor, N. Japkowicz, and S. Leblanc, \"Frequency-based anomaly detection for the automotive can bus,\" in Proc. IEEE World Congr. Ind. Control Sys. Secur., 2015, pp. 45-49.\n\nEvaluation of anomaly detection for in-vehicle networks through information-theoretic algorithms. M Marchetti, D Stabili, A Guido, M Colajanni, Proc. IEEE 2nd Int. IEEE 2nd IntM. Marchetti, D. Stabili, A. Guido, and M. Colajanni, \"Evaluation of anomaly detection for in-vehicle networks through information-theoretic algorithms,\" in Proc. IEEE 2nd Int. Forum Res. Technol. Soc. Industry Leveraging Better Tomorrow., 2016, pp. 1-6.\n\nIn-vehicle network intrusion detection using deep convolutional neural network. H M Song, J Woo, H K Kim, Veh. Commun. 21Art. no. 100198H. M. Song, J. Woo, and H. K. Kim, \"In-vehicle network intrusion de- tection using deep convolutional neural network,\" Veh. Commun., vol. 21, 2020, Art. no. 100198.\n\nOn the difficulty of training recurrent neural networks. R Pascanu, T Mikolov, Y Bengio, Proc. Int. Conf. Mach. Learn. Int. Conf. Mach. LearnR. Pascanu, T. Mikolov, and Y. Bengio, \"On the difficulty of training recurrent neural networks,\" in Proc. Int. Conf. Mach. Learn., 2013, pp. 1310-1318.\n", "annotations": {"author": "[{\"start\":\"105\",\"end\":\"139\"},{\"start\":\"140\",\"end\":\"165\"}]", "publisher": null, "author_last_name": "[{\"start\":\"134\",\"end\":\"138\"},{\"start\":\"161\",\"end\":\"164\"}]", "author_first_name": "[{\"start\":\"125\",\"end\":\"129\"},{\"start\":\"130\",\"end\":\"133\"},{\"start\":\"152\",\"end\":\"155\"},{\"start\":\"156\",\"end\":\"160\"}]", "author_affiliation": null, "title": "[{\"start\":\"1\",\"end\":\"89\"},{\"start\":\"166\",\"end\":\"254\"}]", "venue": "[{\"start\":\"256\",\"end\":\"297\"}]", "abstract": "[{\"start\":\"438\",\"end\":\"1627\"}]", "bib_ref": "[{\"start\":\"1649\",\"end\":\"1652\",\"attributes\":{\"ref_id\":\"b0\"}},{\"start\":\"1654\",\"end\":\"1657\",\"attributes\":{\"ref_id\":\"b1\"}},{\"start\":\"1874\",\"end\":\"1877\",\"attributes\":{\"ref_id\":\"b2\"}},{\"start\":\"2658\",\"end\":\"2661\",\"attributes\":{\"ref_id\":\"b3\"}},{\"start\":\"2663\",\"end\":\"2666\",\"attributes\":{\"ref_id\":\"b4\"}},{\"start\":\"7981\",\"end\":\"7984\",\"attributes\":{\"ref_id\":\"b5\"}},{\"start\":\"9971\",\"end\":\"9974\",\"attributes\":{\"ref_id\":\"b0\"}},{\"start\":\"9976\",\"end\":\"9979\",\"attributes\":{\"ref_id\":\"b1\"}},{\"start\":\"9981\",\"end\":\"9984\",\"attributes\":{\"ref_id\":\"b6\"}},{\"start\":\"12093\",\"end\":\"12106\"},{\"start\":\"12211\",\"end\":\"12214\",\"attributes\":{\"ref_id\":\"b7\"}},{\"start\":\"12699\",\"end\":\"12702\",\"attributes\":{\"ref_id\":\"b8\"}},{\"start\":\"13034\",\"end\":\"13038\",\"attributes\":{\"ref_id\":\"b9\"}},{\"start\":\"13707\",\"end\":\"13711\",\"attributes\":{\"ref_id\":\"b10\"}},{\"start\":\"13919\",\"end\":\"13923\",\"attributes\":{\"ref_id\":\"b11\"}},{\"start\":\"14227\",\"end\":\"14231\",\"attributes\":{\"ref_id\":\"b12\"}},{\"start\":\"14569\",\"end\":\"14573\",\"attributes\":{\"ref_id\":\"b19\"}},{\"start\":\"14825\",\"end\":\"14829\",\"attributes\":{\"ref_id\":\"b13\"}},{\"start\":\"15149\",\"end\":\"15153\",\"attributes\":{\"ref_id\":\"b14\"}},{\"start\":\"15938\",\"end\":\"15942\",\"attributes\":{\"ref_id\":\"b15\"}},{\"start\":\"16224\",\"end\":\"16228\",\"attributes\":{\"ref_id\":\"b16\"}},{\"start\":\"16571\",\"end\":\"16575\",\"attributes\":{\"ref_id\":\"b17\"}},{\"start\":\"17905\",\"end\":\"17909\",\"attributes\":{\"ref_id\":\"b18\"}},{\"start\":\"25382\",\"end\":\"25386\",\"attributes\":{\"ref_id\":\"b20\"}},{\"start\":\"26862\",\"end\":\"26866\",\"attributes\":{\"ref_id\":\"b21\"}},{\"start\":\"27783\",\"end\":\"27787\",\"attributes\":{\"ref_id\":\"b20\"}},{\"start\":\"27842\",\"end\":\"27845\",\"attributes\":{\"ref_id\":\"b8\"}},{\"start\":\"27847\",\"end\":\"27851\",\"attributes\":{\"ref_id\":\"b17\"}}]", "figure": "[{\"start\":\"41352\",\"end\":\"41402\",\"attributes\":{\"id\":\"fig_0\"}},{\"start\":\"41403\",\"end\":\"41449\",\"attributes\":{\"id\":\"fig_1\"}},{\"start\":\"41450\",\"end\":\"41486\",\"attributes\":{\"id\":\"fig_2\"}},{\"start\":\"41487\",\"end\":\"41574\",\"attributes\":{\"id\":\"fig_3\"}},{\"start\":\"41575\",\"end\":\"41781\",\"attributes\":{\"id\":\"fig_4\"}},{\"start\":\"41782\",\"end\":\"41882\",\"attributes\":{\"id\":\"fig_5\"}},{\"start\":\"41883\",\"end\":\"41996\",\"attributes\":{\"id\":\"fig_6\"}},{\"start\":\"41997\",\"end\":\"42066\",\"attributes\":{\"id\":\"fig_7\"}},{\"start\":\"42067\",\"end\":\"42242\",\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"}},{\"start\":\"42243\",\"end\":\"42286\",\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"}},{\"start\":\"42287\",\"end\":\"42362\",\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"}},{\"start\":\"42363\",\"end\":\"42433\",\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"}},{\"start\":\"42434\",\"end\":\"42656\",\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"}},{\"start\":\"42657\",\"end\":\"42719\",\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"}}]", "paragraph": "[{\"start\":\"1629\",\"end\":\"2087\"},{\"start\":\"2089\",\"end\":\"2921\"},{\"start\":\"2923\",\"end\":\"3579\"},{\"start\":\"3581\",\"end\":\"3643\"},{\"start\":\"3645\",\"end\":\"3995\"},{\"start\":\"3997\",\"end\":\"4619\"},{\"start\":\"4621\",\"end\":\"5433\"},{\"start\":\"5469\",\"end\":\"5646\"},{\"start\":\"5677\",\"end\":\"6452\"},{\"start\":\"6454\",\"end\":\"7349\"},{\"start\":\"7377\",\"end\":\"7868\"},{\"start\":\"7870\",\"end\":\"9368\"},{\"start\":\"9370\",\"end\":\"9689\"},{\"start\":\"9691\",\"end\":\"10193\"},{\"start\":\"10195\",\"end\":\"10981\"},{\"start\":\"10983\",\"end\":\"11611\"},{\"start\":\"11634\",\"end\":\"11919\"},{\"start\":\"11921\",\"end\":\"14057\"},{\"start\":\"14059\",\"end\":\"14181\"},{\"start\":\"14183\",\"end\":\"15663\"},{\"start\":\"15665\",\"end\":\"16990\"},{\"start\":\"16992\",\"end\":\"17610\"},{\"start\":\"17612\",\"end\":\"17997\"},{\"start\":\"18039\",\"end\":\"19094\"},{\"start\":\"19096\",\"end\":\"20534\"},{\"start\":\"20555\",\"end\":\"21428\"},{\"start\":\"21514\",\"end\":\"23146\"},{\"start\":\"23148\",\"end\":\"23449\"},{\"start\":\"23451\",\"end\":\"23844\"},{\"start\":\"23900\",\"end\":\"24065\"},{\"start\":\"24097\",\"end\":\"24163\"},{\"start\":\"24198\",\"end\":\"25267\"},{\"start\":\"25292\",\"end\":\"25644\"},{\"start\":\"25646\",\"end\":\"26412\"},{\"start\":\"26414\",\"end\":\"26767\"},{\"start\":\"26769\",\"end\":\"27195\"},{\"start\":\"27197\",\"end\":\"27398\"},{\"start\":\"27416\",\"end\":\"27679\"},{\"start\":\"27721\",\"end\":\"29029\"},{\"start\":\"29071\",\"end\":\"29404\"},{\"start\":\"29444\",\"end\":\"30644\"},{\"start\":\"30705\",\"end\":\"31528\"},{\"start\":\"31570\",\"end\":\"32081\"},{\"start\":\"32083\",\"end\":\"32405\"},{\"start\":\"32407\",\"end\":\"33011\"},{\"start\":\"33049\",\"end\":\"33548\"},{\"start\":\"33575\",\"end\":\"33878\"},{\"start\":\"33913\",\"end\":\"34227\"},{\"start\":\"34257\",\"end\":\"34571\"},{\"start\":\"34630\",\"end\":\"35581\"},{\"start\":\"35583\",\"end\":\"36362\"},{\"start\":\"36364\",\"end\":\"36745\"},{\"start\":\"36778\",\"end\":\"37365\"},{\"start\":\"37367\",\"end\":\"37978\"},{\"start\":\"37980\",\"end\":\"39359\"},{\"start\":\"39378\",\"end\":\"40032\"},{\"start\":\"40034\",\"end\":\"40603\"},{\"start\":\"40605\",\"end\":\"41037\"},{\"start\":\"41039\",\"end\":\"41351\"}]", "formula": "[{\"start\":\"23845\",\"end\":\"23899\",\"attributes\":{\"id\":\"formula_0\"}},{\"start\":\"24066\",\"end\":\"24096\",\"attributes\":{\"id\":\"formula_1\"}},{\"start\":\"27399\",\"end\":\"27415\",\"attributes\":{\"id\":\"formula_2\"}},{\"start\":\"29405\",\"end\":\"29443\",\"attributes\":{\"id\":\"formula_3\"}},{\"start\":\"33879\",\"end\":\"33912\",\"attributes\":{\"id\":\"formula_4\"}},{\"start\":\"34228\",\"end\":\"34256\",\"attributes\":{\"id\":\"formula_5\"}},{\"start\":\"34572\",\"end\":\"34629\",\"attributes\":{\"id\":\"formula_6\"}}]", "table_ref": "[{\"start\":\"11911\",\"end\":\"11918\",\"attributes\":{\"ref_id\":\"tab_0\"}},{\"start\":\"28610\",\"end\":\"28618\",\"attributes\":{\"ref_id\":\"tab_0\"}},{\"start\":\"30196\",\"end\":\"30205\",\"attributes\":{\"ref_id\":\"tab_0\"}},{\"start\":\"31038\",\"end\":\"31046\",\"attributes\":{\"ref_id\":\"tab_0\"}},{\"start\":\"32095\",\"end\":\"32102\",\"attributes\":{\"ref_id\":\"tab_4\"}},{\"start\":\"35027\",\"end\":\"35035\",\"attributes\":{\"ref_id\":\"tab_0\"}}]", "section_header": "[{\"start\":\"5436\",\"end\":\"5467\"},{\"start\":\"5649\",\"end\":\"5675\"},{\"start\":\"7352\",\"end\":\"7375\"},{\"start\":\"11614\",\"end\":\"11632\"},{\"start\":\"18000\",\"end\":\"18037\"},{\"start\":\"20537\",\"end\":\"20553\"},{\"start\":\"21431\",\"end\":\"21470\"},{\"start\":\"21473\",\"end\":\"21512\"},{\"start\":\"24166\",\"end\":\"24196\"},{\"start\":\"25270\",\"end\":\"25290\"},{\"start\":\"27682\",\"end\":\"27705\"},{\"start\":\"27708\",\"end\":\"27719\"},{\"start\":\"29032\",\"end\":\"29069\"},{\"start\":\"30647\",\"end\":\"30671\"},{\"start\":\"30674\",\"end\":\"30703\"},{\"start\":\"31531\",\"end\":\"31568\"},{\"start\":\"33014\",\"end\":\"33047\"},{\"start\":\"33551\",\"end\":\"33573\"},{\"start\":\"36748\",\"end\":\"36776\"},{\"start\":\"39362\",\"end\":\"39376\"},{\"start\":\"41353\",\"end\":\"41361\"},{\"start\":\"41404\",\"end\":\"41412\"},{\"start\":\"41451\",\"end\":\"41459\"},{\"start\":\"41488\",\"end\":\"41496\"},{\"start\":\"41576\",\"end\":\"41584\"},{\"start\":\"41783\",\"end\":\"41791\"},{\"start\":\"41884\",\"end\":\"41892\"},{\"start\":\"41998\",\"end\":\"42006\"},{\"start\":\"42068\",\"end\":\"42087\"},{\"start\":\"42244\",\"end\":\"42261\"},{\"start\":\"42288\",\"end\":\"42307\"},{\"start\":\"42364\",\"end\":\"42382\"},{\"start\":\"42435\",\"end\":\"42452\"},{\"start\":\"42658\",\"end\":\"42676\"}]", "table": null, "figure_caption": "[{\"start\":\"41363\",\"end\":\"41402\"},{\"start\":\"41414\",\"end\":\"41449\"},{\"start\":\"41461\",\"end\":\"41486\"},{\"start\":\"41498\",\"end\":\"41574\"},{\"start\":\"41586\",\"end\":\"41781\"},{\"start\":\"41793\",\"end\":\"41882\"},{\"start\":\"41894\",\"end\":\"41996\"},{\"start\":\"42008\",\"end\":\"42066\"},{\"start\":\"42089\",\"end\":\"42242\"},{\"start\":\"42264\",\"end\":\"42286\"},{\"start\":\"42311\",\"end\":\"42362\"},{\"start\":\"42385\",\"end\":\"42433\"},{\"start\":\"42454\",\"end\":\"42656\"},{\"start\":\"42679\",\"end\":\"42719\"}]", "figure_ref": "[{\"start\":\"6014\",\"end\":\"6020\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"6576\",\"end\":\"6582\",\"attributes\":{\"ref_id\":\"fig_1\"}},{\"start\":\"7427\",\"end\":\"7433\",\"attributes\":{\"ref_id\":\"fig_2\"}},{\"start\":\"8431\",\"end\":\"8437\",\"attributes\":{\"ref_id\":\"fig_3\"}},{\"start\":\"18207\",\"end\":\"18213\",\"attributes\":{\"ref_id\":\"fig_4\"}},{\"start\":\"18283\",\"end\":\"18292\",\"attributes\":{\"ref_id\":\"fig_4\"}},{\"start\":\"18630\",\"end\":\"18639\",\"attributes\":{\"ref_id\":\"fig_4\"}},{\"start\":\"19515\",\"end\":\"19524\",\"attributes\":{\"ref_id\":\"fig_4\"}},{\"start\":\"19738\",\"end\":\"19744\",\"attributes\":{\"ref_id\":\"fig_5\"}},{\"start\":\"22165\",\"end\":\"22171\",\"attributes\":{\"ref_id\":\"fig_6\"}},{\"start\":\"29801\",\"end\":\"29807\",\"attributes\":{\"ref_id\":\"fig_7\"}}]", "bib_author_first_name": "[{\"start\":\"42802\",\"end\":\"42803\"},{\"start\":\"42816\",\"end\":\"42817\"},{\"start\":\"42834\",\"end\":\"42835\"},{\"start\":\"42847\",\"end\":\"42848\"},{\"start\":\"42854\",\"end\":\"42855\"},{\"start\":\"43282\",\"end\":\"43283\"},{\"start\":\"43284\",\"end\":\"43285\"},{\"start\":\"43292\",\"end\":\"43293\"},{\"start\":\"43294\",\"end\":\"43295\"},{\"start\":\"43566\",\"end\":\"43567\"},{\"start\":\"43576\",\"end\":\"43577\"},{\"start\":\"43781\",\"end\":\"43782\"},{\"start\":\"43783\",\"end\":\"43784\"},{\"start\":\"43791\",\"end\":\"43792\"},{\"start\":\"43793\",\"end\":\"43794\"},{\"start\":\"44072\",\"end\":\"44073\"},{\"start\":\"44079\",\"end\":\"44080\"},{\"start\":\"44081\",\"end\":\"44082\"},{\"start\":\"44090\",\"end\":\"44091\"},{\"start\":\"44092\",\"end\":\"44093\"},{\"start\":\"44461\",\"end\":\"44462\"},{\"start\":\"44713\",\"end\":\"44714\"},{\"start\":\"44722\",\"end\":\"44723\"},{\"start\":\"44733\",\"end\":\"44734\"},{\"start\":\"45018\",\"end\":\"45019\"},{\"start\":\"45020\",\"end\":\"45021\"},{\"start\":\"45030\",\"end\":\"45031\"},{\"start\":\"45032\",\"end\":\"45033\"},{\"start\":\"45043\",\"end\":\"45044\"},{\"start\":\"45391\",\"end\":\"45392\"},{\"start\":\"45404\",\"end\":\"45405\"},{\"start\":\"45413\",\"end\":\"45414\"},{\"start\":\"45425\",\"end\":\"45426\"},{\"start\":\"45760\",\"end\":\"45761\"},{\"start\":\"45769\",\"end\":\"45770\"},{\"start\":\"45778\",\"end\":\"45779\"},{\"start\":\"45780\",\"end\":\"45781\"},{\"start\":\"46139\",\"end\":\"46143\"},{\"start\":\"46149\",\"end\":\"46150\"},{\"start\":\"46151\",\"end\":\"46152\"},{\"start\":\"46469\",\"end\":\"46470\"},{\"start\":\"46477\",\"end\":\"46478\"},{\"start\":\"46484\",\"end\":\"46485\"},{\"start\":\"46486\",\"end\":\"46487\"},{\"start\":\"46492\",\"end\":\"46493\"},{\"start\":\"46494\",\"end\":\"46495\"},{\"start\":\"46502\",\"end\":\"46503\"},{\"start\":\"46504\",\"end\":\"46505\"},{\"start\":\"46835\",\"end\":\"46836\"},{\"start\":\"46844\",\"end\":\"46845\"},{\"start\":\"47148\",\"end\":\"47149\"},{\"start\":\"47150\",\"end\":\"47151\"},{\"start\":\"47158\",\"end\":\"47159\"},{\"start\":\"47160\",\"end\":\"47161\"},{\"start\":\"47167\",\"end\":\"47168\"},{\"start\":\"47169\",\"end\":\"47170\"},{\"start\":\"47537\",\"end\":\"47538\"},{\"start\":\"47546\",\"end\":\"47547\"},{\"start\":\"47559\",\"end\":\"47560\"},{\"start\":\"47568\",\"end\":\"47569\"},{\"start\":\"47929\",\"end\":\"47933\"},{\"start\":\"47940\",\"end\":\"47944\"},{\"start\":\"48251\",\"end\":\"48252\"},{\"start\":\"48260\",\"end\":\"48261\"},{\"start\":\"48267\",\"end\":\"48268\"},{\"start\":\"48269\",\"end\":\"48270\"},{\"start\":\"48622\",\"end\":\"48623\"},{\"start\":\"48624\",\"end\":\"48625\"},{\"start\":\"48636\",\"end\":\"48637\"},{\"start\":\"48647\",\"end\":\"48648\"},{\"start\":\"48663\",\"end\":\"48664\"},{\"start\":\"48972\",\"end\":\"48973\"},{\"start\":\"48982\",\"end\":\"48983\"},{\"start\":\"48995\",\"end\":\"48996\"},{\"start\":\"49330\",\"end\":\"49331\"},{\"start\":\"49343\",\"end\":\"49344\"},{\"start\":\"49354\",\"end\":\"49355\"},{\"start\":\"49363\",\"end\":\"49364\"},{\"start\":\"49744\",\"end\":\"49745\"},{\"start\":\"49746\",\"end\":\"49747\"},{\"start\":\"49754\",\"end\":\"49755\"},{\"start\":\"49761\",\"end\":\"49762\"},{\"start\":\"49763\",\"end\":\"49764\"},{\"start\":\"50023\",\"end\":\"50024\"},{\"start\":\"50034\",\"end\":\"50035\"},{\"start\":\"50045\",\"end\":\"50046\"}]", "bib_author_last_name": "[{\"start\":\"42804\",\"end\":\"42814\"},{\"start\":\"42818\",\"end\":\"42832\"},{\"start\":\"42836\",\"end\":\"42845\"},{\"start\":\"42849\",\"end\":\"42852\"},{\"start\":\"42856\",\"end\":\"42861\"},{\"start\":\"42863\",\"end\":\"42872\"},{\"start\":\"43286\",\"end\":\"43290\"},{\"start\":\"43296\",\"end\":\"43299\"},{\"start\":\"43568\",\"end\":\"43574\"},{\"start\":\"43578\",\"end\":\"43585\"},{\"start\":\"43785\",\"end\":\"43789\"},{\"start\":\"43795\",\"end\":\"43798\"},{\"start\":\"44074\",\"end\":\"44077\"},{\"start\":\"44083\",\"end\":\"44088\"},{\"start\":\"44094\",\"end\":\"44097\"},{\"start\":\"44463\",\"end\":\"44472\"},{\"start\":\"44715\",\"end\":\"44720\"},{\"start\":\"44724\",\"end\":\"44731\"},{\"start\":\"44735\",\"end\":\"44745\"},{\"start\":\"45022\",\"end\":\"45028\"},{\"start\":\"45034\",\"end\":\"45041\"},{\"start\":\"45045\",\"end\":\"45052\"},{\"start\":\"45393\",\"end\":\"45402\"},{\"start\":\"45406\",\"end\":\"45411\"},{\"start\":\"45415\",\"end\":\"45423\"},{\"start\":\"45427\",\"end\":\"45432\"},{\"start\":\"45762\",\"end\":\"45767\"},{\"start\":\"45771\",\"end\":\"45776\"},{\"start\":\"45782\",\"end\":\"45790\"},{\"start\":\"46144\",\"end\":\"46147\"},{\"start\":\"46153\",\"end\":\"46157\"},{\"start\":\"46471\",\"end\":\"46475\"},{\"start\":\"46479\",\"end\":\"46482\"},{\"start\":\"46488\",\"end\":\"46490\"},{\"start\":\"46496\",\"end\":\"46500\"},{\"start\":\"46506\",\"end\":\"46509\"},{\"start\":\"46837\",\"end\":\"46842\"},{\"start\":\"46846\",\"end\":\"46850\"},{\"start\":\"47152\",\"end\":\"47156\"},{\"start\":\"47162\",\"end\":\"47165\"},{\"start\":\"47171\",\"end\":\"47174\"},{\"start\":\"47539\",\"end\":\"47544\"},{\"start\":\"47548\",\"end\":\"47557\"},{\"start\":\"47561\",\"end\":\"47566\"},{\"start\":\"47570\",\"end\":\"47578\"},{\"start\":\"47934\",\"end\":\"47938\"},{\"start\":\"47945\",\"end\":\"47949\"},{\"start\":\"48253\",\"end\":\"48258\"},{\"start\":\"48262\",\"end\":\"48265\"},{\"start\":\"48271\",\"end\":\"48274\"},{\"start\":\"48626\",\"end\":\"48634\"},{\"start\":\"48638\",\"end\":\"48645\"},{\"start\":\"48649\",\"end\":\"48661\"},{\"start\":\"48665\",\"end\":\"48672\"},{\"start\":\"48974\",\"end\":\"48980\"},{\"start\":\"48984\",\"end\":\"48993\"},{\"start\":\"48997\",\"end\":\"49004\"},{\"start\":\"49332\",\"end\":\"49341\"},{\"start\":\"49345\",\"end\":\"49352\"},{\"start\":\"49356\",\"end\":\"49361\"},{\"start\":\"49365\",\"end\":\"49374\"},{\"start\":\"49748\",\"end\":\"49752\"},{\"start\":\"49756\",\"end\":\"49759\"},{\"start\":\"49765\",\"end\":\"49768\"},{\"start\":\"50025\",\"end\":\"50032\"},{\"start\":\"50036\",\"end\":\"50043\"},{\"start\":\"50047\",\"end\":\"50053\"}]", "bib_entry": "[{\"start\":\"42721\",\"end\":\"43222\",\"attributes\":{\"matched_paper_id\":\"57663170\",\"id\":\"b0\"}},{\"start\":\"43224\",\"end\":\"43509\",\"attributes\":{\"matched_paper_id\":\"226590668\",\"id\":\"b1\",\"doi\":\"10.1109/MDAT.2020.3011036\"}},{\"start\":\"43511\",\"end\":\"43729\",\"attributes\":{\"id\":\"b2\"}},{\"start\":\"43731\",\"end\":\"43982\",\"attributes\":{\"id\":\"b3\"}},{\"start\":\"43984\",\"end\":\"44392\",\"attributes\":{\"matched_paper_id\":\"52916016\",\"id\":\"b4\"}},{\"start\":\"44394\",\"end\":\"44660\",\"attributes\":{\"matched_paper_id\":\"15858039\",\"id\":\"b5\"}},{\"start\":\"44662\",\"end\":\"44940\",\"attributes\":{\"matched_paper_id\":\"53728211\",\"id\":\"b6\"}},{\"start\":\"44942\",\"end\":\"45283\",\"attributes\":{\"matched_paper_id\":\"17412286\",\"id\":\"b7\"}},{\"start\":\"45285\",\"end\":\"45690\",\"attributes\":{\"matched_paper_id\":\"210159293\",\"id\":\"b8\"}},{\"start\":\"45692\",\"end\":\"46064\",\"attributes\":{\"matched_paper_id\":\"2306368\",\"id\":\"b9\"}},{\"start\":\"46066\",\"end\":\"46373\",\"attributes\":{\"matched_paper_id\":\"14729648\",\"id\":\"b10\"}},{\"start\":\"46375\",\"end\":\"46776\",\"attributes\":{\"id\":\"b11\"}},{\"start\":\"46778\",\"end\":\"47039\",\"attributes\":{\"matched_paper_id\":\"9017380\",\"id\":\"b12\"}},{\"start\":\"47041\",\"end\":\"47432\",\"attributes\":{\"matched_paper_id\":\"9333718\",\"id\":\"b13\"}},{\"start\":\"47434\",\"end\":\"47841\",\"attributes\":{\"matched_paper_id\":\"85518981\",\"id\":\"b14\"}},{\"start\":\"47843\",\"end\":\"48129\",\"attributes\":{\"matched_paper_id\":\"18256723\",\"id\":\"b15\"}},{\"start\":\"48131\",\"end\":\"48523\",\"attributes\":{\"matched_paper_id\":\"214694052\",\"id\":\"b16\"}},{\"start\":\"48525\",\"end\":\"48908\",\"attributes\":{\"matched_paper_id\":\"221356244\",\"id\":\"b17\"}},{\"start\":\"48910\",\"end\":\"49230\",\"attributes\":{\"matched_paper_id\":\"206859385\",\"id\":\"b18\"}},{\"start\":\"49232\",\"end\":\"49662\",\"attributes\":{\"matched_paper_id\":\"36483560\",\"id\":\"b19\"}},{\"start\":\"49664\",\"end\":\"49964\",\"attributes\":{\"matched_paper_id\":\"208091240\",\"id\":\"b20\"}},{\"start\":\"49966\",\"end\":\"50259\",\"attributes\":{\"matched_paper_id\":\"14650762\",\"id\":\"b21\"}}]", "bib_title": "[{\"start\":\"42721\",\"end\":\"42800\"},{\"start\":\"43224\",\"end\":\"43280\"},{\"start\":\"43511\",\"end\":\"43564\"},{\"start\":\"43984\",\"end\":\"44070\"},{\"start\":\"44394\",\"end\":\"44459\"},{\"start\":\"44662\",\"end\":\"44711\"},{\"start\":\"44942\",\"end\":\"45016\"},{\"start\":\"45285\",\"end\":\"45389\"},{\"start\":\"45692\",\"end\":\"45758\"},{\"start\":\"46066\",\"end\":\"46137\"},{\"start\":\"46375\",\"end\":\"46467\"},{\"start\":\"46778\",\"end\":\"46833\"},{\"start\":\"47041\",\"end\":\"47146\"},{\"start\":\"47434\",\"end\":\"47535\"},{\"start\":\"47843\",\"end\":\"47927\"},{\"start\":\"48131\",\"end\":\"48249\"},{\"start\":\"48525\",\"end\":\"48620\"},{\"start\":\"48910\",\"end\":\"48970\"},{\"start\":\"49232\",\"end\":\"49328\"},{\"start\":\"49664\",\"end\":\"49742\"},{\"start\":\"49966\",\"end\":\"50021\"}]", "bib_author": "[{\"start\":\"42802\",\"end\":\"42816\"},{\"start\":\"42816\",\"end\":\"42834\"},{\"start\":\"42834\",\"end\":\"42847\"},{\"start\":\"42847\",\"end\":\"42854\"},{\"start\":\"42854\",\"end\":\"42863\"},{\"start\":\"42863\",\"end\":\"42874\"},{\"start\":\"43282\",\"end\":\"43292\"},{\"start\":\"43292\",\"end\":\"43301\"},{\"start\":\"43566\",\"end\":\"43576\"},{\"start\":\"43576\",\"end\":\"43587\"},{\"start\":\"43781\",\"end\":\"43791\"},{\"start\":\"43791\",\"end\":\"43800\"},{\"start\":\"44072\",\"end\":\"44079\"},{\"start\":\"44079\",\"end\":\"44090\"},{\"start\":\"44090\",\"end\":\"44099\"},{\"start\":\"44461\",\"end\":\"44474\"},{\"start\":\"44713\",\"end\":\"44722\"},{\"start\":\"44722\",\"end\":\"44733\"},{\"start\":\"44733\",\"end\":\"44747\"},{\"start\":\"45018\",\"end\":\"45030\"},{\"start\":\"45030\",\"end\":\"45043\"},{\"start\":\"45043\",\"end\":\"45054\"},{\"start\":\"45391\",\"end\":\"45404\"},{\"start\":\"45404\",\"end\":\"45413\"},{\"start\":\"45413\",\"end\":\"45425\"},{\"start\":\"45425\",\"end\":\"45434\"},{\"start\":\"45760\",\"end\":\"45769\"},{\"start\":\"45769\",\"end\":\"45778\"},{\"start\":\"45778\",\"end\":\"45792\"},{\"start\":\"46139\",\"end\":\"46149\"},{\"start\":\"46149\",\"end\":\"46159\"},{\"start\":\"46469\",\"end\":\"46477\"},{\"start\":\"46477\",\"end\":\"46484\"},{\"start\":\"46484\",\"end\":\"46492\"},{\"start\":\"46492\",\"end\":\"46502\"},{\"start\":\"46502\",\"end\":\"46511\"},{\"start\":\"46835\",\"end\":\"46844\"},{\"start\":\"46844\",\"end\":\"46852\"},{\"start\":\"47148\",\"end\":\"47158\"},{\"start\":\"47158\",\"end\":\"47167\"},{\"start\":\"47167\",\"end\":\"47176\"},{\"start\":\"47537\",\"end\":\"47546\"},{\"start\":\"47546\",\"end\":\"47559\"},{\"start\":\"47559\",\"end\":\"47568\"},{\"start\":\"47568\",\"end\":\"47580\"},{\"start\":\"47929\",\"end\":\"47940\"},{\"start\":\"47940\",\"end\":\"47951\"},{\"start\":\"48251\",\"end\":\"48260\"},{\"start\":\"48260\",\"end\":\"48267\"},{\"start\":\"48267\",\"end\":\"48276\"},{\"start\":\"48622\",\"end\":\"48636\"},{\"start\":\"48636\",\"end\":\"48647\"},{\"start\":\"48647\",\"end\":\"48663\"},{\"start\":\"48663\",\"end\":\"48674\"},{\"start\":\"48972\",\"end\":\"48982\"},{\"start\":\"48982\",\"end\":\"48995\"},{\"start\":\"48995\",\"end\":\"49006\"},{\"start\":\"49330\",\"end\":\"49343\"},{\"start\":\"49343\",\"end\":\"49354\"},{\"start\":\"49354\",\"end\":\"49363\"},{\"start\":\"49363\",\"end\":\"49376\"},{\"start\":\"49744\",\"end\":\"49754\"},{\"start\":\"49754\",\"end\":\"49761\"},{\"start\":\"49761\",\"end\":\"49770\"},{\"start\":\"50023\",\"end\":\"50034\"},{\"start\":\"50034\",\"end\":\"50045\"},{\"start\":\"50045\",\"end\":\"50055\"}]", "bib_venue": "[{\"start\":\"42874\",\"end\":\"42929\"},{\"start\":\"43326\",\"end\":\"43357\"},{\"start\":\"43587\",\"end\":\"43600\"},{\"start\":\"43731\",\"end\":\"43779\"},{\"start\":\"44099\",\"end\":\"44148\"},{\"start\":\"44474\",\"end\":\"44498\"},{\"start\":\"44747\",\"end\":\"44761\"},{\"start\":\"45054\",\"end\":\"45082\"},{\"start\":\"45434\",\"end\":\"45458\"},{\"start\":\"45792\",\"end\":\"45840\"},{\"start\":\"46159\",\"end\":\"46190\"},{\"start\":\"46511\",\"end\":\"46543\"},{\"start\":\"46852\",\"end\":\"46880\"},{\"start\":\"47176\",\"end\":\"47206\"},{\"start\":\"47580\",\"end\":\"47606\"},{\"start\":\"47951\",\"end\":\"47959\"},{\"start\":\"48276\",\"end\":\"48291\"},{\"start\":\"48674\",\"end\":\"48689\"},{\"start\":\"49006\",\"end\":\"49033\"},{\"start\":\"49376\",\"end\":\"49394\"},{\"start\":\"49770\",\"end\":\"49781\"},{\"start\":\"50055\",\"end\":\"50083\"},{\"start\":\"42931\",\"end\":\"42980\"},{\"start\":\"44150\",\"end\":\"44193\"},{\"start\":\"44500\",\"end\":\"44518\"},{\"start\":\"44763\",\"end\":\"44771\"},{\"start\":\"45084\",\"end\":\"45106\"},{\"start\":\"45842\",\"end\":\"45884\"},{\"start\":\"46192\",\"end\":\"46217\"},{\"start\":\"46882\",\"end\":\"46904\"},{\"start\":\"47208\",\"end\":\"47232\"},{\"start\":\"47608\",\"end\":\"47628\"},{\"start\":\"48293\",\"end\":\"48302\"},{\"start\":\"49035\",\"end\":\"49056\"},{\"start\":\"49396\",\"end\":\"49408\"},{\"start\":\"50085\",\"end\":\"50107\"}]"}}}, "year": 2023, "month": 12, "day": 17}