{"id": 237340449, "updated": "2023-11-11 00:59:17.071", "metadata": {"title": "Game-Theoretic Decision Support for Cyber Forensic Investigations", "authors": "[{\"first\":\"Antonia\",\"last\":\"Nisioti\",\"middle\":[]},{\"first\":\"George\",\"last\":\"Loukas\",\"middle\":[]},{\"first\":\"Stefan\",\"last\":\"Rass\",\"middle\":[]},{\"first\":\"Emmanouil\",\"last\":\"Panaousis\",\"middle\":[]}]", "venue": "Sensors (Basel, Switzerland)", "journal": "Sensors (Basel, Switzerland)", "publication_date": {"year": 2021, "month": 8, "day": 1}, "abstract": "The use of anti-forensic techniques is a very common practice that stealthy adversaries may deploy to minimise their traces and make the investigation of an incident harder by evading detection and attribution. In this paper, we study the interaction between a cyber forensic Investigator and a strategic Attacker using a game-theoretic framework. This is based on a Bayesian game of incomplete information played on a multi-host cyber forensics investigation graph of actions traversed by both players. The edges of the graph represent players\u2019 actions across different hosts in a network. In alignment with the concept of Bayesian games, we define two Attacker types to represent their ability of deploying anti-forensic techniques to conceal their activities. In this way, our model allows the Investigator to identify the optimal investigating policy taking into consideration the cost and impact of the available actions, while coping with the uncertainty of the Attacker\u2019s type and strategic decisions. To evaluate our model, we construct a realistic case study based on threat reports and data extracted from the MITRE ATT&CK STIX repository, Common Vulnerability Scoring System (CVSS), and interviews with cyber-security practitioners. We use the case study to compare the performance of the proposed method against two other investigative methods and three different types of Attackers.", "fields_of_study": "[\"Medicine\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": "34450740", "pubmedcentral": "8401095", "dblp": "journals/sensors/NisiotiLRP21", "doi": "10.3390/s21165300"}}, "content": {"source": {"pdf_hash": "1c67cb13ebd3f8b488ca0ac40ee0cc7685402be8", "pdf_src": "PubMedCentral", "pdf_uri": null, "oa_url_match": false, "oa_info": {"license": "CCBY", "open_access_url": "https://www.mdpi.com/1424-8220/21/16/5300/pdf", "status": "GOLD"}}, "grobid": {"id": "35df2a3b74bf36e5dce6cb60699e0a8c1d81d2e8", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/1c67cb13ebd3f8b488ca0ac40ee0cc7685402be8.txt", "contents": "\nGame-Theoretic Decision Support for Cyber Forensic Investigations\nPublished: 5 August 2021\n\nAntonia Nisioti \nDepartment of Computing and Mathematical Sciences\nUniversity of Greenwich\nSE10 9BDLondonUK\n\nGeorge Loukas \nDepartment of Computing and Mathematical Sciences\nUniversity of Greenwich\nSE10 9BDLondonUK\n\nStefan Rass \nInstitut of Artificial Intelligence and Cybersecurity\nUniversitaet\nUniversitatsstrasse 65-679020Klagenfurt, KlagenfurtAustria\n\nEmmanouil Panaousis \nDepartment of Computing and Mathematical Sciences\nUniversity of Greenwich\nSE10 9BDLondonUK\n\nGame-Theoretic Decision Support for Cyber Forensic Investigations\nPublished: 5 August 202110.3390/s21165300Received: 30 June 2021 Accepted: 1 August 2021sensors Article Citation: Nisioti, A.; Loukas, G.; Rass, S.; Panaousis, E. Game-Theoretic Decision Support for Cyber Forensic Investigations. Sensors 2021, 21, 5300. https://doi.org/ 10.3390/s21165300 Academic Editor: Ahmed Bouridane\n\n\nIntroduction\n\nAs adversaries evolve their techniques, both in sophistication and variety, cyber forensics investigations are becoming more complex and time consuming [1]. Modern threats such as Advanced Persistent Threats (APTs) consist of a large number of steps and include a wide variety of Tactics, Techniques, and Procedures (TTPs), which allow adversaries to achieve their goals and avoid detection at the same time.\n\nTo address these problems and increase the efficiency of cyber investigations, we previously proposed DISCLOSE, a data-driven decision support framework, which utilises Tactics, Techniques, and Procedures (TTPs) to offer optimal inspections choices to the investigator [2]. To do so, DISCLOSE combines extracted threat intelligence information regarding TTPs with an attack life-cycle model and the progress of the investigation. In this way, it optimises the choices of the investigator taking into consideration the sophistication and diversity of the TTPs used by adversaries.\n\nHowever, in most cases, such sophisticated and determined attackers will not choose their actions only based on the immediate benefit they may collect, but rather consider the stealthiness of their actions even if this results in the use of extra resources. Specifically, adversaries will additionally deploy anti-forensic TTPs to either conceal part of their trail or to increase the complexity and difficulty of the investigative process, which in turn incurs delays in the investigation [3] and can significantly increase the financial, reputational or other impact of the attack [4,5]. Thus, a decision support system that aims to optimise a cyber forensic investigation process can be benefited from investigating the strategic nature of adversaries.\n\nMotivated by this, we extend our previous work in order to also capture the Attacker's strategic movements and use of anti-forensic techniques instead of simply modelling the investigator's movements.\n\nSpecifically, this work offers the following original contributions:\n\n\u2022 The interaction between the Investigator and a strategic Attacker is modelled using a game theoretic framework. Although game theory has been utilised extensively in the past for modelling the interaction between defending and attacking agents to solve a wide variety of cyber security problems, it has not been used for cyber forensics.\n\nIn this way, contrary to our previous work, we do not simply assume the actions of the Attacker but rather model his/her motivations and strategies. \u2022\n\nA game-theoretic decision support framework is presented that, similarly to DIS-CLOSE, aims to increase the efficiency of the investigator against a strategic adversary with anti-forensic capabilities. Efficiency refers to the ratio of acquired benefit from the uncovered attack actions to the consumed cost, such as time and computing resources. Thus, our aim is to increase the collected benefit across a wide range of investigations while decreasing the spending cost. However, contrary to our previous work and the literature, we explicitly model the anti-forensic capabilities of the Attacker using different Bayesian types and incomplete information on the side of the Investigator.\n\nThis paper is a first step towards (i) use game-theoretic concepts for the optimisation of multi-stage cyber forensic investigations and (ii) model a cyber forensic investigation as a set of incomplete information games that takes in consideration the anti-forensic abilities of the Attacker.\n\nTo achieve the aforementioned, we use a predefined graph consisting of edges that represent real TTPs across different hosts of the network and nodes that represent decision points, where each game takes place. The use of a graph of TTPs aligns with the multi-stage nature of modern sophisticated cyber incidents, such as APTs. To capture the strategic nature of the Attacker and his/her ability to use anti-forensic TTPs, we use the concept of Bayesian games of incomplete information. We allow two Attacker types per decision point, one that applies an anti-forensic technique to conceal his/her activities and one that does not, and assume a probabilistic distribution calculated from past incident reports based on which the types are drawn. This asymmetry in the provided information, i.e., the need of the Investigator to choose a TTP without the prior knowledge of the Attacker's type, models the uncertainty of the Investigator in a real-world case.\n\nWe evaluate the proposed method against two other investigative methods using a case study that consists of a graph of attack actions on multiple hosts created using real-world data gathered through:\n\n\u2022\n\nThe MITRE ATT&CK Structured Threat Information Expression (STIX) [6] repository, a well-known threat intelligence knowledge base that contains structured information on adversarial TTPs from real incident reports; \u2022\n\nThe Common Vulnerability Scoring System (CVSS); \u2022 Interviews with six cyber-security practitioners.\n\nThe rest of the paper is organised as follows. Section 2 presents the literature that is most closely related to ours, which includes (i) game-theoretic concepts for the support of cyber forensic investigations or defence against APTs and (ii) non-game theoretic approaches for the optimisation of such investigations. Section 3 presents the environment where the proposed game-theoretic model can be realised as well as the building components and the solution of the game itself. Section 4 presents a case study of a graph, consisting of a set of real adversarial TTPs, which is used for the evaluation of the proposed game-theoretic method against two other investigative methods as well as a comparative discussion of their performances. Finally, Section 6 concludes the paper and discusses future work.\n\n\nRelated Work\n\nAlthough game theory has been utilised in many sub-fields of cyber-security, such as privacy, honeypot allocation, DDoS defence etc., works that investigate the use of game theory for the forensic analysis of multi-stage cyber attacks are non-existent. Thus, in this section, we present works that can be classified into the two following categories: (i) game-theoretic methods for cyber forensics, (ii) non-game-theoretic decision support for cyber forensics and (iii) game-theoretic methods against APTs. We have chosen to include bibliography related to APTs as they reflect the strategic nature of the Attacker that we assume in this paper. Moreover, a forensic investigation of an incident undertaken by an APT is the most interesting case for us making the application of game theory more valuable than in the cases of commodity attacks, which are far less strategic. For a more detailed review of the game-theoretic literature in the cyber-security field, the reader may refer to [7,8].\n\n\nGame Theory for Cyber Forensics\n\nHasanabadi et al. [9] focus on rootkit defence by using characteristics for both real rootkit and anti-rootkit tools to formulate the interaction of an Attacker and a Defender as a non-zero sum game. The game between the two players is simulated as a Fictitious Play, i.e., it utilises the empirical frequency of the opponent's moves, and allows for the identification of the most stable defence strategies but also the most destructive adversarial strategies. Similarly, the authors of [10] propose a Nash game-theoretic approach for tool selection to allow investigators to optimally choose amongst a wide range of available forensic tools. The proposed method takes in consideration the priorities and characteristics of the case, such as time and file sensitivity, and produces an optimal tool choice. Although both of the aforementioned works focus on assisting the decision process during the technical part of an investigation, similarly to the proposed solution, our work does not focus on the selection of the right tool, but rather on the selection of the adversarial activities that may have taken place.\n\nYan et al. [11] propose a Stackelberg zero-sum game between an Auditor and an Attacker to increase the efficiency of database alert auditing prioritisation. Similarly to our work, the authors aim to optimise the auditing process of the analyst taking in consideration the strategic nature of the opponent. However, while they treat the auditing process of all available alerts as a single unit, we choose to break down the investigation in steps in order take in consideration the multi-stage nature of modern cyber-incidents. Finally, Stamm et al. in [12,13] model the interaction between an investigator and an adversary with anti-forensic capabilities as zero-sum game. Although, our work also assumes an attacker with the capability manipulating the evidence after an attack, Stamm et al.'s work focuses on digital video and image forgery. Thus, while the authors propose a game-theoretic method to help the investigator detect the use of anti-forensic on multimedia evidence, we aim to optimise the attack actions the defender selects to investigate taking in consideration the potential use of anti-forensic techniques by the attacker on multi-stage cyber incidents.\n\n\nNon-Game-Theoretic Decision Support\n\nHorsman et al. [14] propose the Case-Based Reasoning Forensic Triager (CBR-FT), which aims to increase the efficiency of the triage process of the investigation. CBR-FT uses a past incident knowledge base similarly to our approach, which has to be populated manually by investigators, to produce a list with the most popular paths of a file system to contain evidence. Contrary to our work, CBR-FT does not take in consideration the multi step nature of cyber incidents or the available actions of the adversary but instead uses file system paths, which limits the applicability of the proposed method. Similarly to our work, De Braekt et al. [15] aim to increase the efficiency of a cyber forensic investigation taking in consideration the cost of the analysis to provide guidelines for the optimisation of the workload and the usage of the available resources. We also have the same goal but we achieve this in a different way by using TTPs to model multistage incidents on a graph and game theory to identify the optimal choices for the Investigator.\n\nA non-game-theoretic decision support framework, DISCLOSE, for multistage forensic investigations is proposed by Nisioti et al. in [2]. Similarly to the proposed framework, DISCLOSE models the investigation as a collection of steps using adversarial TTPs and considers both the cost and benefit of each TTP to provide optimal suggestions to the investigator. However, contrary to this work, DISCLOSE does not model the Attacker but solely the Investigator and thus is also not capable of taking in consideration the use of anti-forensic techniques.\n\nFinally, there are a number of works that utilise graphs, as we do, to capture the multistep nature of cyber incidents. Liu et al. [16][17][18] propose the use of evidence graphs to support forensic investigations, while Barr\u00e8re et al. [19] introduce core evidence graphs, which are a condensed version of attack graphs, to increase the efficiency of an investigation. However, all of those works utilise vulnerabilities as the building block of the graph. Instead of this, we propose the use of TTPs as they align with the current threat landscape and allow the application of the proposed method in a wider range of investigations. One commonality of the aforementioned works in this subsection is that they do not model the adversary or take in consideration its strategic nature. On the contrary, our approach utilises game theory to model a strategic sophisticated attacker and, specifically, a Bayesian game to represent the attackers ability to use anti-forensic techniques.\n\n\nGame Theory against APT\n\nIn the literature, two of the most similar works to our approach are presented by Zhu and Rass and Rass et al. in [20,21], correspondingly. In the first work, the authors choose to divide an APT in three main phases: Initial penetration and establishment, Learning and propagation and Damage and define the whole process as a multi-phase multistage (MPMS) game. They then model a separate phase as a different type of game, where the first phase is a Bayesian game, the second is a sequential Nash game running on a subnet graph and, finally, the third phase is a static Nash game. In the second work, the interaction between a stealthy APT adversary is modelled as a Bayesian zero sum game on a predefined graph by allowing different types for the Attacker to represent the uncertainty of the Defender regarding the entry point of the attacker.\n\nEven though there are many similarities between these works and our approach, such as the use a Bayesian game as well as the use of a predefined graph to model a multi-step APT incident, there are also three significant differences. Firstly, we allow the types of the Attacker to represent the uncertainty about the use of anti-forensics by the Attacker. Secondly, we focus on the post mortem investigation of the incident instead of its prevention and, thus, our goal is to assist the investigator to reveal the performed attack actions in the most efficient way. Thirdly, while [21] uses vulnerabilities as the building component of the graph and [20] divides the incident in three phases, we choose to use adversarial TTPs, as they allow for a better representation of a modern cyber incident and greater applicability across a wide range of cases [2].\n\nFinally, another Bayesian game against APTs, which similarly to our work, considers the multi-stage and deceptive nature of APTs is presented by Huang et al. [22]. Specifically, the authors propose an online game for proactive APT defence, where the Defender dynamically develops a belief regarding the Attacker based on the observed actions and uses it to enhance the defences of the infrastructure in order to mitigate future attacks. As before, the main difference between this work and our work is the focus on the forensic investigation instead of the defence problem as well as the inclusion of the anti-forensic capabilities of the Attacker, but also the lack of visible signals in our approach, which models realistically the inability of the investigator to observe the Attacker.\n\n\nGame-Theoretic Decision Support for Optimising Cyber Forensic Investigations\n\nA cyber forensics investigator, henceforth referred to as the Investigator, is commissioned with the task of disclosing evidence related to an incurred cyber incident. The choices of the Investigator, akin to inspection actions, are represented by the space of attack actions, which are available to the Attacker during the attack. More specifically, at any point of the investigation process while on a host of the network, the Investigator faces the challenge of selecting the next inspection action to undertake. To find optimal strategies for this cyber forensics challenge, we apply two game-theoretic concepts that capture the asynchronous interactions between an Attacker and the Investigator.\n\nWe firstly define the Nash Cyber Investigation Game (NCIG), derive the Nash Equilibrium (NE), and discuss how this can be translated to actionable advice for the Investigator. We go beyond NCIG by considering different Attacker types, in order to capture situations where the Attacker wishes to remain stealthy by minimising his/her traces during the forensic investigation. Thus, we model the Bayesian Cyber Investigation Game (BCIG) as a Bayesian game with two different Attacker types based on whether he/she deploys anti-forensics techniques to decrease the likelihood of detection and attribution.\n\n\nEnvironment\n\nLet us assume that there is an Attacker that aims to infiltrate a corporate network with the aim of reaching a predefined target. To accomplish this, the Attacker performs a set of attack actions, which collectively can be referred to as a cyber incident. The set of available attack actions at each step of the attack depends on the network structure, technologies in use, current defence mechanisms and other characteristics of the targeted organisation. After the completion of the incident, i.e., after the Attacker has already accomplished his/her goal, an Investigator is called to uncover the performed actions. This leads to a standard forensic process, where the Investigator aims to disclose the desirable forensic evidence in a way that optimises how he/she chooses forensic actions. We assume that each of these forensic actions is capable of revealing an attack action, as we have also proposed in [2].\n\nEvery attack and inspection action takes place on a host of a network, which can be any physical or virtual device. Most likely, the incident under investigation may include more than one host and more than one action per host. Simply speaking, the Attacker decides which of the available actions will allow him/her to move through the network and reach his/her objective (e.g., perform a specific action on a targeted asset) and the Investigator, who naturally becomes part of the ecosystem after an incident has been suspected, decides which actions will gather appropriate forensic evidence towards uncovering the steps followed by the Attacker. In this way, the organisation will be able to assess the extent of the incident thus strengthening its defence, plan about system recovery, present to an external auditor (e.g., an insurer) facts from the incident, and potentially identify the Attacker.\n\nTo demonstrate the above interactions, we define two game-theoretic models, where the Attacker and the Investigator are seen as the strategic rational players who have to choose among a set of attack actions and a set of inspection actions, respectively. This aligns with the characteristics of: (i) modern Attackers, such as APT threat groups, who are highly sophisticated, plan and realise targeted attacks, and (ii) Investigators, who choose their actions based on reasoning and the uncovered evidence. We define a decision point in time, when players decide their next action respectively. For the Attacker, a decision point is a state of the attack where he/she chooses his/her next attack action. Similarly, for the Investigator, a decision point is a state of the investigation when he/she has to select the next inspection action. For instance, a decision point for the Attacker would be when he/she is at a specific compromised workstation where he/she has elevated his/her privileges and is now able to choose amongst a set of actions that require admin privileges.\n\nLet the targeted infrastructure, where the players move, be represented in a form of a graph (also referred to as the investigation graph), in which the nodes represent decision points, and the edges are available actions to the players. Players move from one decision point (i.e., node) to another by traversing the edges that correspond to the actions they have chosen at each decision point. Due to the nature of their interaction, in our cyber forensic games, the Attacker completes all the actions until an alert has triggered the organisation to commence an investigation. Then, the Investigator will conduct a postmortem analysis of the incident by choosing inspection actions. This is when the Investigator has to disclose the required evidence by starting from a node (e.g., a performed attack action on a server) which was flagged by the detection capabilities of the organisation. Naturally, the Attacker wishes to choose the attack actions that will bring him/her from an initial node (e.g., entry point in the attack surface of the organisation's infrastructure) to an end node, which is where he/she will collect his/her reward. As explained, each node is a point where both the Attacker and the Investigator choose their next action.\n\nLet E be the set of available edges for players to traverse at a decision point on the graph. Each edge is an attack action on a specific host of the network that the Attacker can use to move from one node to another and the Investigator may investigate. For instance, an attack action is the creation of a scheduled task, while an inspection action is the one that uncovers evidence of this malicious activity. Let each edge e i \u2208 E have a benefit \u03b2 i for both players, which in this paper is common knowledge to both players and represents the negative (resp. positive) impact that an attack action causes to the targeted organisation if performed by the attacker (resp. uncovered by the Investigator). Furthermore, we assume that each attack action represented by e i incurs the Attacker a cost \u03b1 i while the effort of the Investigator to disclose this action costs him/her \u03ba i . The cost \u03b1 i represents the resources that the Attacker spends to undertake this attack action, and likewise, \u03ba i refers to the resources that the Investigator spends for investigating this action. In both cases, we allow the cost to represent the time that the player has to spent to either undertake or investigate the attack action. Table 1 summarises our notation. \n\n\nNash Cyber Investigation Game\n\nFor every decision point, represented by a node in a graph, we formulate a two-player, deterministic, complete-information game, entitled NCIG and denoted by \u0393, between the Attacker and the Investigator. At each decision point (i.e., node on the graph), each player chooses their next action from a set of available edges E . In \u0393, the players choose without observing each other's choice but knowing the available actions and utilities of the opponent. Thus, at each decision point, a Nash Cyber Investigation Game is played, where the Attacker has to probabilistically select one of the available attack actions to penetrate the organisation's defences and the Investigator has to select its inspection strategy to collect the best possible evidence. We assume that for each potential attack action, the Investigator chooses the probability of investigating it.\n\n\nStrategy Spaces\n\nThe normal form of this game is described as follows. At a node of the investigation graph, a pure strategy of the Attacker is to choose an edge e i out of E , towards the exploitation of his/her desirable target. Likewise, the Investigator must choose among these edges when he/she is at the same node, while he/she is conducting the investigation process. Thus, the set of pure strategies of both players consists of all edges in E . In \u0393, a pure strategy profile is a pair of actions (e i , e j ), e i , e j \u2208 E of Attacker and Investigator, giving a pure strategy space of |E | \u00d7 |E |. For the rest of the paper, the convention is adopted where the Attacker is the row player and the Investigator is the column player.\n\nThe mixed strategy \u03c1 of the Investigator is a probability distribution over the different edges e i \u2208 E (i.e., pure strategies), where \u03c1(e i ) is the probability of choosing e i under mixed strategy \u03c1. We refer to a mixed strategy of the Investigator as a Randomised Forensic Investigation Plan (RFIP).\n\nLikewise, the Attacker's mixed strategy is a probability distribution \u03b1 over all available attack actions, where \u03b1(e i ) is the probability of choosing the attack action associated with edge e i under \u03b1. We will refer to a mixed strategy of the Attacker as a Randomised Attack Plan (RAP). The use of mixed strategies by the Attacker allows him/her to increase the uncertainty of the Investigator about his/her action choices. On the other hand, the use of mixed strategies by the Investigator allows for the optimisation of the performance of the Investigator across a collections of investigations given that use of mixed strategies by the Attacker.\n\nFor the finite set E , we define \u03a0 as the set of all probability distributions over it. Since both players have the same strategy space, the set of all mixed strategies for both players is\n\u03a0 = {\u03c1(e j ) \u2208 R + | \u2211 e j \u2208E \u03c1(e j ) = 1}(1)\nTherefore, the set of mixed strategy profiles for NCIG is \u03a0 \u00d7 \u03a0.\n\n\nExpected Payoffs\n\nNext, we formalise the players' objectives through defining what the probabilities of certain outcomes are and what payoff values each player gains from these outcomes. Each player's preferences are specified by his/her payoff function, and we define as U A : (e i , e j ) \u2192 R and U I : (e i , e j ) \u2192 R the payoff functions of the Attacker and Investigator, respectively, when the pure strategy profile (e i , e j ) is played. We use the benefit and cost values defines in Section 3.1 to define the players' payoff functions.\n\nWhenever players choose the same edge (i.e., e i = e j ), the Investigator collects the benefit \u03b2 i as he/she has uncovered the Attacker's action and both players pay their respective costs \u03b1 i and \u03ba i . On the other hand, if players choose different actions, the Attacker collects the benefit \u03b2 i of not being traced and they both pay their action's costs.\n\nFormally,\nU A (e i , e j ) = \u2212\u03b1 i , e i = e j \u03b2 i \u2212 \u03b1 i , e i = e j(2)\nand\nU I (e i , e j ) = \u03b2 i \u2212 \u03ba i , e i = e j \u2212\u03ba i , e i = e j(3)\nAs discussed above, \u0393 is a game per node in the investigation graph. To derive optimal strategies for the Investigator during the repetitions of NCIGs, we deploy the notion of mixed strategies. As players act independently, we enlarge their strategy spaces, to allow them to base their decisions on the outcome of random events that create uncertainty to the opponent about individual strategic choices maximising their payoffs. Hence, both Attacker and Investigator deploy randomised (i.e., mixed) strategies.\n\nWe can now define the NCIG as \u0393 = (Attacker, Investigator), \u03a0 \u00d7 \u03a0, (U A , U I ) . For a given mixed strategy (\u03b1, \u03c1), we denote by U A (\u03b1, \u03c1) and U I (\u03b1, \u03c1) the expected payoffs for the Attacker and the Defender, respectively.\n\nFormally,\nU A (\u03b1, \u03c1) = \u2211 e i \u2208E \u2211 e j \u2208E U A (e i , e j )\u03b1(e i )\u03c1(e j )(4)\nand\nU I (\u03b1, \u03c1) = \u2211 e i \u2208E \u2211 e j \u2208E U I (e i , e j )\u03b1(e i )\u03c1(e j ).(5)\n\nSolution\n\nAssuming that both Attacker and Investigator are rational players, their aim is to maximise their expected utilities taking in consideration the other player's best response.\n\n\nDefinition 1. (NE for NCIG).\n\nThus, for a pair of mixed strategies (\u03b1, \u03c1) to be a Nash Equilibrium (NE), the following must be satisfied:\n\n\u2022\n\nThe Attacker plays a RAP \u03b1 that is a best-response s.t. \u03b1 \u2208 argmax \u03b1 * \u2208\u03a0 U A (\u03b1 * , \u03c1); \u2022\n\nThe Defender plays a RFIP \u03c1 that is a best-response, which we will refer as the Investigator's Optimal Randomised Plan (IRP), s.t. \u03c1 \u2208 argmax \u03c1 * \u2208\u03a0 U I (\u03b1, \u03c1 * ).\n\nAs this is a bimatrix non-zero-sum game, its solution can be calculated by formulating it as a linear complementarity problem (LCP) [23] and solving it using the Lemke-Howson algorithm, as follows: \n\nwhere r I , r A are the slack variables as per [23].\n\n\nToy Example\n\nLet us now present a toy example of NCIG, where the action space for both players is E = {e 1 , e 2 } and the corresponding cost and benefit values are:\n\u03b1 1 = \u03ba 1 = 8, \u03b2 1 = 70, \u03b1 2 = \u03ba 2 = 7 and \u03b2 2 = 60.\nThe values used in this example for the benefit and cost parameters are not meant to be realistic, but are simply used for demonstration and illustration purposes. On the contrary, the parameters' values used in Case Study Section, which aims to evaluate and compare the proposed method, are representative of the reality as explained in Sections 4.2 and 4.3.\n\nThe payoffs for the game can be calculated using Formulas (2) and (3) and are shown in Table 2. The pure strategies of the game are easily observable to be {e 1 , e 2 } and {e 2 , e 1 }. The Nash Equilibrium for mixed strategies of this game is \u03b1 = {0.46923077, 0.53076923} and \u03c1 = {0.53076923, 0.46923077}. This means that the IRP is to choose e 1 with probability 0.53076923 and e 2 with probability 0.46923077. \n\n\nBayesian Cyber Investigation Game\n\nAs aforementioned, in order to approach more accurately the real-world interaction between the Attacker and the Investigation, we define a Bayesian game, entitled Bayesian Cyber Investigation Game (BCIG) and denoted by \u0393 B . Building upon NCIG, in BCIG, we assume two different Attacker types \u03b8 \u2208 \u0398 and we let p : \u03b8 \u2192 [0, 1] be the probability distribution representing the Investigator's belief about the attacker's type. In BCIG, the Attacker has complete information about his/her type while the Investigator is uncertain of it. Thus, the Investigator receives no signal that can be used to enrich his/her initial knowledge about the Attacker's type.\n\nType \u03b8 1 is identical with the Attacker from NCIG, i.e., chooses edges e i out of E as his/her actions. Similarly, the second Attacker type \u03b8 2 also chooses edges e i as his/her actions but also applies an anti-forensic technique to the chosen action. An anti-forensic technique refers to evasion techniques that can be used by attackers to decrease the likelihood of detection, such as encryption or log deletion [24]. In this work, we will assume that there is one possible anti-forensic technique for each edge e i for simplicity reasons, but this assumption could be easily dropped by assuming more than two Attacker types.\n\nAs expected, the usage of an anti-forensic technique increases all the constant values associated with each edge by \u03b2 * , \u03b1 * and \u03ba * , respectively. This is because an anti-forensic technique will obscure the Attacker's actions, thus increasing the difficulty of the analysis for investigator and decreases the likelihood of detection but also requires extra resources for the attacker. Similarly, uncovering an edge that includes an anti-forensic technique offers extra benefit to the Investigator but also requires more analysis resources. Here, it should be noted, that these values are not the same for each edge as the same anti-forensic technique cannot be combined with all available edges at each decision point.\n\n\nStrategy Spaces\n\nThe pure strategy space for the Investigator in BCIG is the same as in NCIG, i.e., it consists of all edges in E as there is only one type of Investigator. However, there are two types \u03b8 for the Attacker and, thus, a pure strategy for him/her is not a single edge in E anymore but a pair of edges, one for each type \u03b8, i.e., e i , e j : \u03b8 \u2192 E.\n\nSimilarly, a mixed strategy RFIP \u03c1 for the Investigator remains the same, with \u03c1(e i ) being the probability of e i under \u03c1. On the contrary, a mixed strategy RAP \u03b1 for the attacker is now a probability distribution over actions in E for each type \u03b8, i.e. \u03b1 : \u03b8 \u2192 \u2206(E ), with \u03b1(e i |\u03b8) denoting the probability of choosing e i under the mixed strategy \u03b1 given that the Attacker's type is \u03b8.\n\n\nExpected Payoffs\n\nWe now revise the payoff functions (2) and (3) for a pair of edges (e i , e j ) presented in Section 3.2.2 for the BCIG to include the type \u03b8 of the Attacker s.t. U A : (e i , e j , \u03b8) \u2192 R and U I : (e i , e j , \u03b8) \u2192 R. When \u03b8 = \u03b8 1 , the payoff functions for both player's remain unchanged. However, when \u03b8 = \u03b8 2 , the benefit and cost values for both players are increased by \u03b2 * , \u03b1 * and \u03ba * , respectively, when appropriate.\n\nFormally,\nU A (e i , e j , \u03b8) = \uf8f1 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f2 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f3 \u2212\u03b1 i , e i = e j and \u03b8 = \u03b8 1 \u03b2 i \u2212 \u03b1 i , e i = e j and \u03b8 = \u03b8 1 \u2212\u03b1 i \u2212 \u03b1 * , e i = e j and \u03b8 = \u03b8 2 \u03b2 i + \u03b2 * \u2212 \u03b1 i \u2212 \u03b1 * , e i = e j and \u03b8 = \u03b8 2(7)\nand\nU I (e i , e j , \u03b8) = \uf8f1 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f2 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f3 \u03b2 i \u2212 \u03ba i , e i = e j and \u03b8 = \u03b8 1 \u2212\u03ba i , e i = e j and \u03b8 = \u03b8 1 \u03b2 i + \u03b2 * \u2212 \u03ba i \u2212 \u03ba * , e i = e j and \u03b8 = \u03b8 2 \u2212\u03ba i \u2212 \u03ba * , e i = e j and \u03b8 = \u03b8 2(8)\nContrary to NCIG, where the information known to the players was symmetric, in BCIG there is an asymmetry of information between the Attacker and the Investigator, as the Attacker is aware of his/her type but the Investigator is not. This is reflected to the expected payoff functions for mixed strategies, as the Investigator needs to take in consideration his/her common belief about the type of the Attacker in order to cope with his/her uncertainty, while the Attacker is able to use his/her private type information. Formally,\nU A (\u03b1, \u03c1|\u03b8) = \u2211 e i \u2208E \u2211 e j \u2208E U A (e i , e j , \u03b8)\u03b1(e i |\u03b8)\u03c1(e j )(9)\nand\nU I (\u03b1, \u03c1) = \u2211 \u03b8\u2208\u0398 p(\u03b8) \u2211 e i \u2208E \u2211 e j \u2208E U I (e i , e j , \u03b8)\u03b1(e i |\u03b8)\u03c1(e j ).(10)\n\nSolution\n\n\nDefinition 2. (BNE in BCIG)\n\n. As in NCIG, for a pair of mixed strategies (\u03b1, \u03c1) to be a Bayesian Nash Equilibrium (BNE), both players have to play their best response taking in consideration the other's players strategy but also their type (in the case of the Attacker). Formally, (\u03b1, \u03c1) is a BNE if the following are satisfied:\n\n\u2022 The Attacker plays an RAP \u03b1 that is a best-response s.t. \u03b1 \u2208 argmax \u03b1 * \u2208\u03a0 U A (\u03b1 * , \u03c1|\u03b8), \u2200\u03b8 \u2208 \u0398; \u2022 The Defender plays an RFIP \u03c1, which we refer as IRP, that is a best-response s.t. \u03c1 \u2208 argmax \u03c1 * \u2208\u03a0 U I (\u03b1, \u03c1 * ).\n\n\nToy Example\n\nLet us now revisit the example from Section 3.2.4 and expand it for the BCIG. In addition to the previously given constant values for edges e 1 , e 2 , we define the following: \u03b1 * 1 = \u03ba * 1 = 3, \u03b2 * 1 = 20, \u03b1 * 2 = \u03ba * 2 = 2 and \u03b2 * 2 = 15. Moreover, the Investigator has the following belief: the Attacker's type is \u03b8 1 with probability 0.6 and \u03b8 2 with probability 0.4. Using Equations (7) and (8), we populate Table 3. Finally, using the Harsanyi transformation [25], we transform Table 3 to normal form as shown in Table 3 . The pure strategies for the Investigator are the same as in Section 3.2.4, while for the Attacker are {e 1 e 1 , e 1 e 2 , e 2 e 1 , e 2 e 2 }. By solving the game, we acquire the following Equilibrium for mixed strategies: \u03b1 = {0.01794872, 0, 0.98205128, 0} and \u03c1 = {0.53076923, 0.46923077}. This means that the Attacker's optimal RAP is to mix over the strategies {e 1 , e 1 } and {e 2 , e 1 }, i.e., play e 1 with probability 0.01794872 and e 2 with probability 0.98205128 when \u03b8 = \u03b8 1 and always play e 1 when \u03b8 = \u03b8 2 . Thus, the IRP is to play e 1 with probability 0.53076923 and e 2 with probability 0.46923077. \n\n\nCase Study\n\nIn this section, we present a case study that consists of 33 TTPs from the MITRE ATT&CK knowledge base and their corresponding benefit and cost values collected using CVSS and interviews with cyber-security practitioners. We use the Tactics, Techniques, and Procedures (TTPs) to create a representative graph of incidents where we evaluate the efficiency of IRP and two other investigative methods, namely Uniform and Common Sense Strategy (CSS), against three types of Attackers, a strategic, a uniform and a common sense.\n\n\nAction Space\n\nTo evaluate IRP, we use a subset of some of the most popular TTPs [26] available in the MITRE ATT&CK Enterprise matrix to create the graph of Figure 1. The graph is a small-scale representation of a corporate network with multiple hosts and multiple attack actions (TTPs) available at each host. Each attack action is represented by an edge on the graph, while each decision point, i.e., the point in time when players decide their next move, is represented by a node. As this is a multi-host environment, we use different colours to represent different hosts of the network. In this way, decision points (i.e., nodes) that belong to the same host are outlined with the same colour. Edges connect decision points in a logical way, for instance, for the Attacker to move from any Discovery & Persistence node (Nodes 4-8) of the blue host to any Lateral Movement node of the green host (Nodes 24-28), he/she needs to first acquire the required credentials through any Credential Access node (Nodes [14][15][16][17][18]. This is because acquiring valid credentials is a requirement for all the Lateral Movement TTPs used in this case study by the Attacker to move to the next host.\n\nTo simplify the representation of Figure 1, we have organised the nodes that are connected to the same nodes in groups using the Tactics of MITRE ATT&CK. For instance, nodes 4 to 8 hold TTPs that fall under the Discovery & Persistence Tactics and are all connected with nodes 14 to 18, which fall under the Credential Access Tactic. Thus, instead of adding one to one edge from each node to another one, which would lead to 25 edges between those nodes, we simply add one edge between the two groups of nodes. This means that all nodes 4 to 8 are connected with all nodes 14 to 18. Furthermore, for simplicity reasons, when a player is on a decision point, we refer to the available edges on this decision point using the number of the node on which the edge ends. For instance, if a player is on decision point 5 the available edges would be edges 14 to 18, i.e., the edges that lead to nodes 14 to 18. Finally, we use a subset of the TTPs available under the Evasion Tactic of MITRE ATT&CK as the anti-forensic techniques. For instance, for any edge that holds the Standard Application Layer Protocol TTP the available anti-forensic technique is the Data Encrypted TTP, as it allows the data transported through the C&C channel to be private and even if the Investigator is able to decrypt them it will take a considerable amount of time and resources. Table 4 presents the TTP used for the edges (and nodes) of the graph, while Table 5 presents the anti-forensic technique assigned for each edge.  Table 4.   Table 6 presents the benefit \u03b2 i and cost \u03ba i , \u03b1 i values for each TTP as well as the corresponding values \u03b2 * , \u03b1 * , \u03ba * for each anti-forensic TTP. Here, we have chosen for simplicity reasons to allow equal cost values for the Attacker and the Investigators.\n\n\nBenefit and Cost Parameters\n\nAs previously explained in Section 3, the benefit value of each edge represents the impact that the corresponding TTP would have to the organisation if taken by the Attacker. For this reason, in this paper, we use the Common Vulnerability Scoring System (CVSS) to collect these values (https://nvd.nist.gov/vuln-metrics/cvss/v3-calculator, accessed on 4 August 2021). CVSS is a publicly available standard that allows professionals to produce a numerical score that reflects the severity of a vulnerability based on its characteristics. Although CVSS has three available metrics, Base, Temporal, and Environmental Score, in this paper, we only use the Base Score metric. Specifically, we utilise the Base Score metric to input characteristics for each TTP, such as its impact on the confidentiality, integrity and availability (CIA) triad or the required privileges, to calculate its benefit value.\n\nAs there is no standardized metric or framework that can be used to calculate the cost value of each TTP (and thus each edge) we performed a two-phase set of interviews with six experienced cyber-security practitioners to collect the required values. Background information and experience of each interviewee can be found in Table 7. During the first phase of interviews, the practitioners were asked which criteria they believe were appropriate for the valuation of the cost of an attack action as a representation of the time need for its analysis. The criteria that were identified through this first phase were: (i) the type of the analysis, i.e., level of automation through tools, and (ii) the complexity of the analysis, i.e., technical difficulty, amount of required data and data sources to be analysed. Both of those criteria affect the amount of time that is required to analyse an attack action and reveal its corre-sponding evidence. At the second phase of the interviews, each practitioner was asked to rate the cost of each TTP in a scale of one to ten based on the previously identified criteria. For instance, if the Standard Application Layer Protocol TTP has a cost of 6 while the Registry Run Keys/Startup Folder has a cost of 3, because the former (i) requires the analysis of a large amount of network traffic data while the latter only requires the analysis of the registry and (ii) includes tasks of higher difficulty such as decryption and decoding. To allow the reader to get a better understanding of the cost values, we provide an estimate correspondence between cost values and analysis time in minutes in Table 6.  \n\n\nAttacker Type Probabilities\n\nAs explained in Section 3.3, at each individual BCIG, the Attacker is of type \u03b8 2 , i.e., uses anti-forensic action, with probability p and \u03b8 1 , i.e., does not use an anti-forensic action, with probability 1 \u2212 p. Thus, we need to calculate the probability of the Attacker using antiforensic at each decision point of the graph. However, every decision point has a set of child edges, which all have their individual probability to be used along their corresponding anti-forensic technique. Thus, the overall probability of using an anti-forensic technique in the decision point would be equal to the probability of undertaking any of the connected edges with an anti-forensic technique, i.e., the union of those probabilities.\n\nTo acquire this probability, we firstly need to calculate the probability of the Attacker using an anti-forensic TTP for each individual edge connected to the decision point. To do so, we use the MITRE ATT&CK STIX Repository (https://github.com/mitre/cti, accessed on 4 August 2021)). The repository uses the STIX 2.0 (https://oasis-open.github.io, accessed on 4 August 2021)) standardized language to hold all the information collected and processed by MITRE through publicly available incident reports regarding adversarial TTPs. Specifically, each TTP, Threat Group, Software etc. has been assigned to an STIX Domain Object (SDO), which contains several information fields, such as name, reference IDs and other object specific fields. For instance, an SDO for a specific TTP may contain fields such as required privileges, which platform and application it may be used against etc. The relationships between these SDOs are represented using STIX Relationship Objects (SROs), which have three mandatory fields: relationship type, source ref and target ref.\n\nFor example, if a TTP is being used by a Threat Group, there will be an SRO that connects the SDO of this TTP with the Threat Group's SDO that will also contain an additional field holding the name or URL of the relevant reports.\n\nTo query the repository for all the available reports and URLs for each selected TTP, we use the python-stix2 (https://github.com/oasis-open/cti-python-stix2, accessed on 4 August 2021)) library. Then, we use python dictionaryto hold the results so that each key of the dictionary corresponds to a TTP and its value holds a list of the reports and URLs connected to this TTP. Finally, we correlate the available reports for each TTP with the reports of its anti-forensic TTP in order to calculate the probability of them being used together. Then, we take the union of the probabilities of each edge connected to the decision point to calculate p. As the events are not mutually exclusive, we also need to subtract the probabilities of their intersection, which we calculate from the repository in a similar way as p. The produced anti-forensic probability for each decision node can be found in Figure 1.\n\n\nSimulations\n\nIn order to evaluate the efficiency of Investigator's Optimal Randomised Plan (IRP), we compare it with two other investigative methods, the Uniform method and the Common Sense Strategy (CSS). The Investigator using the Uniform method selects an edge according to a uniform distribution while the Investigator using the CSS selects an edge using the benefit value as the sole criterion. Specifically, the CSS Investigator acts as a rational player that is motivated by the benefit of each edge and thus selects each edge e i with probability \u03b2 i / \u2211 e k \u2208E \u03b2 k . All three types of Investigators are evaluated against three Attacker types, a strategic, a Uniform and a common sense. The strategic Attacker plays an optimal RAP as described in Definition 2, while the uniform Attacker uses a uniform distribution to select edges similarly to the Uniform investigative method. Finally, the common sense Attacker uses the benefit value of each edge as the criteria similarly to the CSS Investigator in order to create a weighted probability distribution as an investigative method.\n\nWe simulate a high number of incidents, where each incident is composed of a set of edges and decision points (nodes) of Figure 1. At each decision point, each player chooses an edge using their corresponding probability distribution, which in the case of the Attacker and IRP Investigator comes from solving a BCIG game. To initiate an incident, we allow the Attacker to pick an initial decision point from a uniform distribution of starting points (nodes 0, 1 and 2) and traverse the graph based on the chosen edges and the allowed movements until he/she reaches the target nodes (nodes 44-52). Then, all players make a choice for each node in the incident and accumulate their collected payoff based on the choice of the Attacker. The high number of incidents has been selected to emulate the usage of the strategies by a cyber-security company that employs a large number of Investigators working on a large number of cases.\n\n\nResults and Discussion\n\nWe compare the performance of all three investigative methods against three types of Attackers on two different levels: (i) accumulated payoff from all edges of the investigated incidents and (ii) accumulated payoff per TTP tactic. Figures 2a, 3a and 4a present how the accumulated payoff of the Investigators using IRP, Uniform and CSS increases as the number of investigated incidents grows. Each figure corresponds to one of the aforementioned Attackers, i.e., strategic, common sense and uniform, as explained in Section 4.4. As it is shown, the Investigator using IRP steadily outperforms both the Uniform and CSS Investigators against all three Attackers and while, at a low number of incidents, the difference in the collected payoff is small, after 8000 incidents, the IRP Investigator has collected a payoff between 4500-5000 while the CSS and Uniform Investigators have collected payoffs between 4000-4300 and 3800-4000, accordingly. Thus, as the number of incidents increases, the gap difference between the accumulated payoff from the three strategies increases as well. This also means that the more complex the incidents under investigation are, i.e., include more impactful and greater number of attack actions, the more significant this difference becomes, even at a much lower number of incidents. It is also worth noting here that these values derive from Formulas (7) and (8) and so represent both the gained benefit, i.e., decrease of the adversarial impact on the attacked organisation, and the conserved cost (time) of the Investigator. Thus, an increase of the payoff is caused by an increase of the accumulated benefit and decrease of the spent analysis time.\n\nSimilarly, Figures 2-4 show the percentage of performance improvement that IRP offers compared to CSS and Uniform Investigators against each of the three Attackers. Specifically, the improvement provided by IRP on the Uniform Investigator ranges between: (i) 16% and 18% for the strategic Attacker, (ii) 20% and 21% for the common sense Attacker, and (iii) 12% and 15% for the uniform Attacker. Similarly, the improvement achieved by IRP on the CSS Investigator ranges between: (i) 12% and 14% for the strategic Attacker, (ii) 11% and 13% for the common sense Attacker, and (iii) 8% and 10% for the uniform Attacker. This reinforces the previous remark on how the long term usage of IRP on complex multi-stage incidents can provide a significant amount of collected payoff to an organisation, especially if utilised by all the employed investigators and analysts. This improvement directly translates to: (i) conserved investigation time, which can be used for other investigations, and (ii) decrease of the adversarial impact on the victim organisations through the reveal of the performed attack actions.  As shown, the highest improvement on both the Uniform and CSS method across all three Attackers is achieved in the Discovery & Persistence, Credential Access and Impact categories while the lowest is achieved in the Command and Control (C&C) and Lateral Movement categories. By correlating these results with the information provided by Tables 4 and 6, we can observe that the higher the variety and number of available edges at a decision point, the higher the enhancement of the performance. Specifically, the Discovery & Persistence Tactic includes in all cases 5 different TTPs with benefit values that range from 33 to 61 and cost values that range from 3 to 5. On the contrary, the C&C Tactic includes 2 different TTPs, i.e., the Standard Application Layer Protocol and the Custom C&C Protocol, that have identical benefit values and cost values of 6 and 8. The reuse of those TTPs is caused by: (i) the fact that they may represent a number of different protocols, and (ii) the size limitations of this case study. Thus, taking in consideration that in reality the number of available edges at each decision point would be much higher that the one used in this case study, we should expect a higher percentage of overall performance improvement compared to the numbers presented in Figure 2 as the variety of the edges increases in all categories. \n\n\nLimitations and Future Work\n\nIn a real-world scenario, the proposed method can be utilised as a guide by the Investigator to navigate step by step the analysis of a multi-stage cyber incident. Specifically, if we consider the incident as a set of steps, i.e., attack actions, the investigation is a set of forensic actions too, i.e., inspections of the attack actions. In this way, IRP can be used at each step to generate an optimal strategy and, thus, inspection action for the Investigator, in a similar way that our previous work DISCLOSE [2], was utilised. This allows the Investigator to incorporate in his/her decision process the strategic nature of the Attacker but also the cost and benefit factors. Moreover, IRP could be part of a more complex decision support system, expanded with further parameters and combined with other optimisation methods in order to increase the quality of the suggestions provided to the Investigator. For real life application of IRP, the cost and benefit values could be calculated per organisation using: (i) information regarding the available assets, such as their role and importance, and (ii) data from past incident \"tickets\", such as the required analysis time.\n\nRegarding the evaluation of the efficiency of IRP, in this work we used a realistic case study, but in the future we aim to expand our evaluation against graphs with greater TTP variety, both in terms of benefit and cost values and number of edges available per decision point. This will allow us to investigate the extent to which the growth of the complexity of the graph in general but also per decision point will improve IRP. Similarly, we would like to evaluate the optimality of IRP's suggestions and the support that it can offer to Investigators using participants instead of simulations.\n\nMoreover, we would like to extend IRP by incorporating a budget parameter for both the Attacker and the Investigator that will allow the optimisation of the whole incident path by taking in consideration future edges and using a discount factor. Finally, in this work, we assumed for simplicity reasons that only one anti-forensic technique is available per edge but, in reality, there will be more than one option for the Attacker. IRP can be extended to take this in consideration by assuming more than one Attacker types at each decision point, i.e., each individual game.\n\n\nConclusions\n\nAs adversaries become more sophisticated and stealthier, the use of anti-forensic techniques for the minimisation of the likelihood of their detection is increased. As a result, cyber investigations become more complex and challenging and investigators need support methods that will allow them to increase their efficiency against strategic adversaries. To this end, in this paper, we have modeled a multi-stage cyber attack as a set of multiple Bayesian games of incomplete information that take place on a graph of attack actions. We define two Attacker types, one that uses anti-forensic techniques and one that does not, based on a probabilistic distribution that is calculated through past incident reports. In this way, the Investigator is able to create an optimal investigative strategy, called Investigator's Optimal Randomised Plan (IRP), which takes in consideration the uncertainty regarding the Attacker's type as well as the potential benefit and cost values of each action.\n\nWe evaluate IRP against two other investigative methods, namely Uniform and CSS, using a case study of 33 TTP from MITRE ATT&CK and three different Attacker's methodologies. To this end, we collect data from the MITRE ATT&CK STIX repository, Common Vulnerability Scoring System (CVSS) and six interviews with cyber-security practitioners. According to our results, IRP outperforms the Uniform method by 18% and CSS method by 14% in terms of accumulated payoff. Moreover, our evaluation suggests that the improvement achieved by IRP is even higher at nodes with higher number of edges and greater diversity of benefit and cost values.\n\nAuthor Contributions: Conceptualization, G.L., E.P. and A.N.; methodology E.P. and A.N.; formal analysis S.R. and A.N.; supervision E.P.; writing-original draft preparation E.P. and A.N.; writing-review and editing G.L. and S.R.; data curation, software, validation and visualization A.N. All authors have read and agreed to the published version of the manuscript.\n\nFunding: This research received no external funding.\n\n\nInstitutional Review Board Statement: Not applicable.\n\nInformed Consent Statement: Not applicable.\n\n\nData Availability Statement:\n\nThe data can be found at: https://github.com/isec-greenwich, accessed on 4 August 2021).\n\n\nConflicts of Interest:\n\nThe authors declare no conflicts of interest.\n\n\n(e i , e j ) \u00b7 \u03b1(e i ) + r I (e j ) = U * I ,\u2200e j \u2208 E \u2211 e j \u2208E U A (e i , e j ) \u00b7 \u03c1(e j ) + r A (e i ) = U * A , \u2200e i \u2208 E \u2211 e i \u2208E\u03b1(e i ) = 1 and \u2211 e j \u2208E \u03c1(e j ) = 1 \u03b1(e i ) \u2265 0 and \u03c1(e j ) \u2265 0 \u2200e j , e i \u2208 E r A (e i ) \u2265 0 and r I (e j ) \u2265 0 \u2200e j , e i \u2208 E \u03b1(e i ) \u00b7 r A (e i ) \u2265 0 and \u03c1(e j ) \u00b7 r I (e j ) \u2265 0 \u2200e j , e i \u2208 E\n\nFigure 1 .\n1Use case graph utilizing nodes of\n\nFigure 2 .Figure 3 .\n23Performance comparison of IRP, Uniform and CSS on N = 8000 simulated incidents against Strategic Attacker. (a) Accumulated payoff, (b) Percentage of IRP improvement. Performance comparison of IRP, Uniform and CSS on N = 8000 simulated incidents against CSS Attacker. (a) Accumulated payoff, (b) Percentage of IRP improvement.\n\nFigure 5a -\n5ac present the average improvement of IRP on Uniform and CSS per TTP Tactic across 8000 incidents. This allows us to get a deeper understanding on how the number of available edges at each decision point and the variety of their cost and benefit values affect the performance of each strategy.\n\nFigure 4 .Figure 5 .Figure 5 .\n455Performance comparison of IRP, Uniform and CSS on N = 8000 simulated incidents against Uniform Attacker. (a) Accumulated payoff, (b) Percentage of IRP improvement. ContAverage improvement of IRP on Uniform and CSS per TTP Tactic on N = 8000 simulated incidents. (a) Percentage of IRP improvement per TTP category for Strategic Attacker, (b) Percentage of IRP improvement per TTP category for CSS Attacker, (c) Percentage of IRP improvement per TTP category for Uniform Attacker.\n\nTable 1 .\n1List of symbols.Symbol \nDescription \n\nConstants \n\u03b2 i \nbenefit associated with edge e i for both players \n\u03b1 i \nAttacker's cost for edge e i \n\u03ba i \nInvestigator's cost for edge e i \n\u03b2  *  \nbenefit associated an anti-forensic technique \n\u03b1  *  \nAttacker's cost for an anti-forensic technique \n\u03ba  *  \nInvestigator's cost for an anti-forensic technique \nFunctions and variables \nE \nset of edges available on any decision point \ne i \nith edge on any decision point \nU A \npayoff function for Attacker \nU I \npayoff function for Investigator \n\u03b8 \nAttacker's type \n\u03c1 \nmixed strategy for the Investigator \n\u03b1 \nmixed strategy for the Attacker \n\n\n\nTable 2 .\n2Payoffs for example CFG.Investigator \n\ne 1 \ne 2 \n\n\n\nTable 3 .\n3Illustrative example of BCFG. (a) Payoffs table for BCFG before transformation, (b) Payoff table after Harsanyi transformation.a \n\nInvestigator \n\ne 1 \ne 2 \n\nType \u03b8 1 \n\nAttacker \n\ne 1 \n\u22128, 62 \n62, \u22127 \n\ne 2 \n53, \u22128 \n\u22127, 53 \n\nType \u03b8 2 \n\ne 1 \n\u221211, 79 \n79, \u22129 \n\ne 2 \n66, \u221211 \n\u22129, 66 \n\nb \n\nInvestigator \n\n\u03b8 1 , \u03b8 2 \ne 1 \ne 2 \n\nAttacker \ne 1 , e 1 \n\u22129.2, 68.8 \n68.8, \u22127.8 \n\ne 1 , e 2 \n21.6, 32.8 \n33.6, 22.2 \n\ne 2 , e 1 \n27.4, 26.8 \n27.4, 28.2 \n\ne 2 , e 2 \n58.2, \u22129.2 \n\u22127.8, 58.2 \n\n\n\nTable 4 .\n4Technique contained in each node of graph.Nodes \nTechnique \n\n0, 27, 42 \nSpearphishing Attachment \n28, 43 \nSpearphishing Link \n1 \nReplication Through Removable Media \n2 \nExternal Remote Services \n3 \nUser Execution \n4, 9, 34 \nSystem Service Discovery \n5, 10, 35 \nSystem Information Discovery \n6, 11, 36 \nRegistry Run Keys/Startup Folder \n7, 12, 37 \nModify Existing Service \n8, 13, 38 \nNew Service \n14, 19 \nCredential Dumping \n15, 20 \nCredentials In Files \n18, 23, 26, 41 \nBrute Force \n16, 21, 52 \nCreate Account \n24, 39 \nPass the Hash \n25, 40 \nWindows Remote Management \n29, 31, 33 \nStandard Application Layer Protocol \n30, 32 \nCustom C&C Protocol \n46, 49 \nData Encrypted for Impact \n44 \nData from Local System \n45 \nData from Network Shared Drive \n50 \nExfiltration Over Alternative Protocol with Data from Local System \n47 \nExfiltration Over C&C Channel with Data from Local System \n51 \nExfiltration Over C&C Channel with Data from Network Shared Drive \n48 \nExfiltration Over Alternative Protocol with Data from Network Shared Drive \n\n\n\nTable 5 .\n5Anti-forensic actions per node in the Use Case.Nodes \n\n\nTable 6 .\n6Cost and benefit values for each Technique used in the case study.Technique \nBenefit \nCost (Score) \nCost (Min.) \nNode Techniques \nSpearphishing Attachment \n48 \n5 \n20-30 \n\nSpearphishing Link \n48 \n5 \n20-30 \n\nReplication Through Removable Media \n36 \n5 \n20-30 \n\nExternal Remote Services \n74 \n7 \n60-120 \n\nUser Execution \n47 \n3 \n10-15 \n\nSystem Service Discovery \n33 \n5 \n20-30 \n\nSystem Information Discovery \n33 \n5 \n20-30 \n\nNetwork Share Discovery \n33 \n5 \n20-30 \n\nRegistry Run Keys/Startup Folder \n55 \n3 \n10-15 \n\nModify Existing Service \n61 \n3 \n10-15 \n\nNew Service \n61 \n3 \n10-15 \n\nCredential Dumping \n47 \n8 \n120-240 \n\nCredentials In Files \n47 \n5 \n20-30 \n\nBrute Force \n72 \n5 \n20-30 \n\nCreate Account \n63 \n6 \n30-60 \n\nPass the Hash \n78 \n7 \n60-120 \n\nWindows Remote Management \n78 \n7 \n60-120 \n\nStandard Application Layer Protocol \n63 \n7 \n60-120 \n\nCustom C&C Protocol \n63 \n8 \n120-240 \n\nData Encrypted for Impact \n57 \n6 \n30-60 \n\nData from Local System \n71 \n6 \n30-60 \n\nData from Network Shared Drive \n71 \n5 \n20-30 \n\nExfiltration Over Alternative Protocol with Data from Local System \n102 \n10 \n360+ \nExfiltration Over C&C Channel with Data from Local System \n102 \n10 \n360+ \n\nExfiltration Over C&C Channel with Data from Network Shared Drive \n102 \n10 \n360+ \n\nExfiltration Over Alternative Protocol with Data from Network Shared Drive \n102 \n10 \n360+ \nAnti-forensic Techniques \nObfuscated Files or Information \n60 \n7 \n60-120 \n\nModify Registry \n55 \n3 \n10-15 \n\nValid Accounts \n47 \n5 \n20-30 \n\nIndicator Removal on Host \n40 \n5 \n20-30 \n\nData Encrypted \n60 \n7 \n60-120 \n\n\nTable 7 .\n7Background information of experts interviewed for gathering the cost values \u03b1 i , \u03ba i .# \nJob Title \nMain Duties \nExperience (Years) \n1 \nSecurity Operations Advisor \nStrategic advisory on SecOps \n12 \n2 \nDigital Forensics Expert \nDFI chapter leader for Advisory firm \n20 \n\n3 \nSenior Lecturer in Incident \nResponse & Digital forensics \n\nResearch, Consulting & Teaching in Incident \nReponse/OWASP Dorset Chapter Leader \n13 \n\n4 \nEnterprise Security Architect \nReview/deploy of Security Architectures, PoC of \nidentified solutions, Security controls mapping \n14 \n\n5 \nSenior Red Team Analyst \n\nIntelligence-led and objectives-focused adversarial \nemulations. OSINT, social engineering, C&C, \npost-exploitation, physical attacks \n\n10 \n\n6 \nAssociate security consultant \nPenetration testing, reporting and client scoping \n2 \n\n\nAbbreviationsThe following abbreviations are used in this manuscript:\nA cyber forensics needs analysis survey: Revisiting the domain's needs a decade later. V S Harichandran, F Breitinger, I Baggili, A Marrington, 10.1016/j.cose.2015.10.007Comput. Secur. 57Harichandran, V.S.; Breitinger, F.; Baggili, I.; Marrington, A. A cyber forensics needs analysis survey: Revisiting the domain's needs a decade later. Comput. Secur. 2016, 57, 1-13. [CrossRef]\n\nData-Driven Decision Support for Optimizing Cyber Forensic Investigations. A Nisioti, G Loukas, A Laszka, E Panaousis, 10.1109/TIFS.2021.3054966IEEE Trans. Inf. Forensics Secur. 16Nisioti, A.; Loukas, G.; Laszka, A.; Panaousis, E. Data-Driven Decision Support for Optimizing Cyber Forensic Investigations. IEEE Trans. Inf. Forensics Secur. 2021, 16, 2397-2412. [CrossRef]\n\n. F Mandiant, Special Report: M-Trends. 2021MadiantMandiant, F. Special Report: M-Trends 2021; Madiant: Alexandria, VA, USA, 2021.\n\nA Brinson, A Robinson, M Rogers, Cyber, Ontology, 10.1016/j.diin.2006.06.008Creating a new approach to studying cyber forensics. Digit. Investig. 3Brinson, A.; Robinson, A.; Rogers, M. A cyber forensics ontology: Creating a new approach to studying cyber forensics. Digit. Investig. 2006, 3, 37-43. [CrossRef]\n\n. K Finnerty, S Fullick, H Motha, J N Shah, M Button, V Wang, Cyber Security Breaches Survey. CultureFinnerty, K.; Fullick, S.; Motha, H.; Shah, J.N.; Button, M.; Wang, V. Cyber Security Breaches Survey 2019; Department for Digital, Culture, Media & Sport: London, UK, 2019.\n\nStandardizing cyber threat intelligence information with the Structured Threat Information eXpression (STIX). Mitre Corp. S Barnum, 11Barnum, S. Standardizing cyber threat intelligence information with the Structured Threat Information eXpression (STIX). Mitre Corp. 2012, 11, 1-22.\n\nGame theory for cyber security and privacy. C T Do, N H Tran, C Hong, C A Kamhoua, K A Kwiat, E Blasch, S Ren, N Pissinou, S S Iyengar, 10.1145/3057268ACM Comput. Surv. 50Do, C.T.; Tran, N.H.; Hong, C.; Kamhoua, C.A.; Kwiat, K.A.; Blasch, E.; Ren, S.; Pissinou, N.; Iyengar, S.S. Game theory for cyber security and privacy. ACM Comput. Surv. (CSUR) 2017, 50, 1-37. [CrossRef]\n\nA game-theoretic taxonomy and survey of defensive deception for cybersecurity and privacy. J Pawlick, E Colbert, Q Zhu, 10.1145/3337772ACM Comput. Surv. (CSUR). 52Pawlick, J.; Colbert, E.; Zhu, Q. A game-theoretic taxonomy and survey of defensive deception for cybersecurity and privacy. ACM Comput. Surv. (CSUR) 2019, 52, 1-28. [CrossRef]\n\nA game-theoretic defensive approach for forensic investigators against rootkits. S S Hasanabadi, A H Lashkari, A A Ghorbani, 10.1016/j.fsidi.2020.200909Forensic Sci. Int. Digit. Investig. 33Hasanabadi, S.S.; Lashkari, A.H.; Ghorbani, A.A. A game-theoretic defensive approach for forensic investigators against rootkits. Forensic Sci. Int. Digit. Investig. 2020, 33, 200909. [CrossRef]\n\nU Karabiyik, T Karabiyik, Game, 10.3390/math8050774Theoretic Approach for Digital Forensic Tool Selection. Mathematics 2020. 8Karabiyik, U.; Karabiyik, T. A Game Theoretic Approach for Digital Forensic Tool Selection. Mathematics 2020, 8, 774. [CrossRef]\n\nDatabase audit workload prioritization via game theory. C Yan, B Li, Y Vorobeychik, A Laszka, D Fabbri, B Malin, 10.1145/3323924ACM Trans. Priv. Secur. (TOPS). 22Yan, C.; Li, B.; Vorobeychik, Y.; Laszka, A.; Fabbri, D.; Malin, B. Database audit workload prioritization via game theory. ACM Trans. Priv. Secur. (TOPS) 2019, 22, 1-21. [CrossRef]\n\nTemporal forensics and anti-forensics for motion compensated video. M C Stamm, W S Lin, K R Liu, 10.1109/TIFS.2012.2205568IEEE Trans. Inf. Forensics Secur. 7Stamm, M.C.; Lin, W.S.; Liu, K.R. Temporal forensics and anti-forensics for motion compensated video. IEEE Trans. Inf. Forensics Secur. 2012, 7, 1315-1329. [CrossRef]\n\nForensics vs. anti-forensics: A decision and game theoretic framework. M C Stamm, W S Lin, K R Liu, Proceedings of the 2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). the 2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)Kyoto, JapanStamm, M.C.; Lin, W.S.; Liu, K.R. Forensics vs. anti-forensics: A decision and game theoretic framework. In Proceedings of the 2012 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Kyoto, Japan, 25-30 March 2012; pp. 1749-1752.\n\nA case-based reasoning method for locating evidence during digital forensic device triage. G Horsman, C Laing, P Vickers, 10.1016/j.dss.2014.01.007Decis. Support Syst. 61Horsman, G.; Laing, C.; Vickers, P. A case-based reasoning method for locating evidence during digital forensic device triage. Decis. Support Syst. 2014, 61, 69-78. [CrossRef]\n\nIncreasing digital investigator availability through efficient workflow management and automation. R I De Braekt, N A Le-Khac, J Farina, M Scanlon, T Kechadi, Proceedings of the 2016 4th International Symposium on Digital Forensic and Security (ISDFS). the 2016 4th International Symposium on Digital Forensic and Security (ISDFS)Little Rock, AR, USAde Braekt, R.I.; Le-Khac, N.A.; Farina, J.; Scanlon, M.; Kechadi, T. Increasing digital investigator availability through efficient workflow management and automation. In Proceedings of the 2016 4th International Symposium on Digital Forensic and Security (ISDFS), Little Rock, AR, USA, 25-27 April 2016; pp. 68-73.\n\nUsing attack graphs in forensic examinations. C Liu, A Singhal, D Wijesekera, Proceedings of the 2012 Seventh International Conference on Availability, Reliability and Security. the 2012 Seventh International Conference on Availability, Reliability and SecurityPrague, Czech RepublicLiu, C.; Singhal, A.; Wijesekera, D. Using attack graphs in forensic examinations. In Proceedings of the 2012 Seventh International Conference on Availability, Reliability and Security, Prague, Czech Republic, 20-24 August 2012; pp. 596-603.\n\nMapping evidence graphs to attack graphs. C Liu, A Singhal, D Wijesekera, Proceedings of the 2012 IEEE International Workshop on Information Forensics and Security (WIFS). the 2012 IEEE International Workshop on Information Forensics and Security (WIFS)Liu, C.; Singhal, A.; Wijesekera, D. Mapping evidence graphs to attack graphs. In Proceedings of the 2012 IEEE International Workshop on Information Forensics and Security (WIFS), Costa Adeje, Spain, 2-5 December 2012; pp. 121-126.\n\nCreating integrated evidence graphs for network forensics. C Liu, A Singhal, D Wijesekera, Proceedings of the IFIP International Conference on Digital Forensics. the IFIP International Conference on Digital ForensicsOrlando, FL, USALiu, C.; Singhal, A.; Wijesekera, D. Creating integrated evidence graphs for network forensics. In Proceedings of the IFIP International Conference on Digital Forensics, Orlando, FL, USA, 28-30 January 2013; pp. 227-241.\n\nTracking the bad guys: An efficient forensic methodology to trace multi-step attacks using core attack graphs. M Barr\u00e8re, R V Steiner, R Mohsen, E C Lupu, Proceedings of the 2017 13th International Conference on Network and Service Management (CNSM). the 2017 13th International Conference on Network and Service Management (CNSM)Tokyo, JapanBarr\u00e8re, M.; Steiner, R.V.; Mohsen, R.; Lupu, E.C. Tracking the bad guys: An efficient forensic methodology to trace multi-step attacks using core attack graphs. In Proceedings of the 2017 13th International Conference on Network and Service Management (CNSM), Tokyo, Japan, 26-30 November 2017; pp. 1-7.\n\nOn multi-phase and multi-stage game-theoretic modeling of advanced persistent threats. Q Zhu, S Rass, 10.1109/ACCESS.2018.2814481IEEE Access. 6Zhu, Q.; Rass, S. On multi-phase and multi-stage game-theoretic modeling of advanced persistent threats. IEEE Access 2018, 6, 13958-13971. [CrossRef]\n\nCut-the-rope: A game of stealthy intrusion. S Rass, S K\u00f6nig, E Panaousis, Proceedings of the International Conference on Decision and Game Theory for Security. the International Conference on Decision and Game Theory for SecurityStockholm, SwedenRass, S.; K\u00f6nig, S.; Panaousis, E. Cut-the-rope: A game of stealthy intrusion. In Proceedings of the International Conference on Decision and Game Theory for Security, Stockholm, Sweden, 30 October-1 November 2019; pp. 404-416.\n\nAdaptive strategic cyber defense for advanced persistent threats in critical infrastructure networks. L Huang, Q Zhu, 10.1145/3305218.3305239ACM SIGMETRICS Perform. Eval. Rev. 46Huang, L.; Zhu, Q. Adaptive strategic cyber defense for advanced persistent threats in critical infrastructure networks. ACM SIGMETRICS Perform. Eval. Rev. 2019, 46, 52-56. [CrossRef]\n\nEquilibrium points of bimatrix games. C E Lemke, J T Howson, Jr, 10.1137/0112033J. Soc. Ind. Appl. Math. 12Lemke, C.E.; Howson, J.T., Jr. Equilibrium points of bimatrix games. J. Soc. Ind. Appl. Math. 1964, 12, 413-423. [CrossRef]\n\nA generalized Nash solution for two-person bargaining games with incomplete information. J C Harsanyi, R Selten, 10.1287/mnsc.18.5.80Manag. Sci. 18Harsanyi, J.C.; Selten, R. A generalized Nash solution for two-person bargaining games with incomplete information. Manag. Sci. 1972, 18, 80-106. [CrossRef]\n\nRisk and Vulnerability Assessment RVA Mapped to the MITRE ATT&CK Framework. 27CISACISA. Risk and Vulnerability Assessment RVA Mapped to the MITRE ATT&CK Framework. 2019. Avaliable online: https: //www.cisa.gov/sites/default/files/publications/FY19_RVAs_Mapped_to_the_MITRE_ATTCK_Framework_508.pdf (accessed on 27 July 2021).\n", "annotations": {"author": "[{\"end\":201,\"start\":93},{\"end\":308,\"start\":202},{\"end\":448,\"start\":309},{\"end\":561,\"start\":449}]", "publisher": null, "author_last_name": "[{\"end\":108,\"start\":101},{\"end\":215,\"start\":209},{\"end\":320,\"start\":316},{\"end\":468,\"start\":459}]", "author_first_name": "[{\"end\":100,\"start\":93},{\"end\":208,\"start\":202},{\"end\":315,\"start\":309},{\"end\":458,\"start\":449}]", "author_affiliation": "[{\"end\":200,\"start\":110},{\"end\":307,\"start\":217},{\"end\":447,\"start\":322},{\"end\":560,\"start\":470}]", "title": "[{\"end\":66,\"start\":1},{\"end\":627,\"start\":562}]", "venue": null, "abstract": null, "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":1120,\"start\":1117},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":1647,\"start\":1644},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2449,\"start\":2446},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2542,\"start\":2539},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":2544,\"start\":2542},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":5693,\"start\":5690},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":7757,\"start\":7754},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":7759,\"start\":7757},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":7817,\"start\":7814},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":8287,\"start\":8283},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":8928,\"start\":8924},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":9469,\"start\":9465},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":9472,\"start\":9469},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":10144,\"start\":10140},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":10772,\"start\":10768},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":11314,\"start\":11311},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":11865,\"start\":11861},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":11869,\"start\":11865},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":11873,\"start\":11869},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":11970,\"start\":11966},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":12857,\"start\":12853},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":12860,\"start\":12857},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":14170,\"start\":14166},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":14239,\"start\":14235},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":14440,\"start\":14437},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":14605,\"start\":14601},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":17546,\"start\":17543},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":27579,\"start\":27575},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":27694,\"start\":27690},{\"end\":29803,\"start\":29799},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":34076,\"start\":34072},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":35379,\"start\":35375},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":36309,\"start\":36305},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":36313,\"start\":36309},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":36317,\"start\":36313},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":36321,\"start\":36317},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":36325,\"start\":36321},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":47243,\"start\":47240},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":50546,\"start\":50543}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":55070,\"start\":54741},{\"attributes\":{\"id\":\"fig_1\"},\"end\":55117,\"start\":55071},{\"attributes\":{\"id\":\"fig_2\"},\"end\":55467,\"start\":55118},{\"attributes\":{\"id\":\"fig_3\"},\"end\":55775,\"start\":55468},{\"attributes\":{\"id\":\"fig_4\"},\"end\":56289,\"start\":55776},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":56931,\"start\":56290},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":56994,\"start\":56932},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":57482,\"start\":56995},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":58528,\"start\":57483},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":58595,\"start\":58529},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":60151,\"start\":58596},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":60982,\"start\":60152}]", "paragraph": "[{\"end\":1373,\"start\":965},{\"end\":1954,\"start\":1375},{\"end\":2711,\"start\":1956},{\"end\":2913,\"start\":2713},{\"end\":2983,\"start\":2915},{\"end\":3324,\"start\":2985},{\"end\":3476,\"start\":3326},{\"end\":4166,\"start\":3478},{\"end\":4460,\"start\":4168},{\"end\":5419,\"start\":4462},{\"end\":5620,\"start\":5421},{\"end\":5623,\"start\":5622},{\"end\":5840,\"start\":5625},{\"end\":5941,\"start\":5842},{\"end\":6750,\"start\":5943},{\"end\":7760,\"start\":6767},{\"end\":8911,\"start\":7796},{\"end\":10085,\"start\":8913},{\"end\":11178,\"start\":10125},{\"end\":11728,\"start\":11180},{\"end\":12711,\"start\":11730},{\"end\":13584,\"start\":12739},{\"end\":14441,\"start\":13586},{\"end\":15231,\"start\":14443},{\"end\":16012,\"start\":15312},{\"end\":16616,\"start\":16014},{\"end\":17547,\"start\":16632},{\"end\":18451,\"start\":17549},{\"end\":19528,\"start\":18453},{\"end\":20778,\"start\":19530},{\"end\":22032,\"start\":20780},{\"end\":22929,\"start\":22066},{\"end\":23671,\"start\":22949},{\"end\":23975,\"start\":23673},{\"end\":24627,\"start\":23977},{\"end\":24817,\"start\":24629},{\"end\":24928,\"start\":24864},{\"end\":25475,\"start\":24949},{\"end\":25834,\"start\":25477},{\"end\":25845,\"start\":25836},{\"end\":25910,\"start\":25907},{\"end\":26482,\"start\":25972},{\"end\":26709,\"start\":26484},{\"end\":26720,\"start\":26711},{\"end\":26789,\"start\":26786},{\"end\":27041,\"start\":26867},{\"end\":27181,\"start\":27074},{\"end\":27184,\"start\":27183},{\"end\":27276,\"start\":27186},{\"end\":27441,\"start\":27278},{\"end\":27641,\"start\":27443},{\"end\":27695,\"start\":27643},{\"end\":27863,\"start\":27711},{\"end\":28276,\"start\":27917},{\"end\":28692,\"start\":28278},{\"end\":29383,\"start\":28730},{\"end\":30012,\"start\":29385},{\"end\":30735,\"start\":30014},{\"end\":31098,\"start\":30755},{\"end\":31490,\"start\":31100},{\"end\":31940,\"start\":31511},{\"end\":31951,\"start\":31942},{\"end\":32146,\"start\":32143},{\"end\":32869,\"start\":32338},{\"end\":32945,\"start\":32942},{\"end\":33370,\"start\":33070},{\"end\":33590,\"start\":33372},{\"end\":34754,\"start\":33606},{\"end\":35292,\"start\":34769},{\"end\":36487,\"start\":35309},{\"end\":38263,\"start\":36489},{\"end\":39193,\"start\":38295},{\"end\":40840,\"start\":39195},{\"end\":41599,\"start\":40872},{\"end\":42660,\"start\":41601},{\"end\":42891,\"start\":42662},{\"end\":43798,\"start\":42893},{\"end\":44892,\"start\":43814},{\"end\":45822,\"start\":44894},{\"end\":47532,\"start\":45849},{\"end\":49997,\"start\":47534},{\"end\":51209,\"start\":50029},{\"end\":51808,\"start\":51211},{\"end\":52385,\"start\":51810},{\"end\":53390,\"start\":52401},{\"end\":54025,\"start\":53392},{\"end\":54392,\"start\":54027},{\"end\":54446,\"start\":54394},{\"end\":54547,\"start\":54504},{\"end\":54668,\"start\":54580},{\"end\":54740,\"start\":54695}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":24863,\"start\":24818},{\"attributes\":{\"id\":\"formula_1\"},\"end\":25906,\"start\":25846},{\"attributes\":{\"id\":\"formula_2\"},\"end\":25971,\"start\":25911},{\"attributes\":{\"id\":\"formula_3\"},\"end\":26785,\"start\":26721},{\"attributes\":{\"id\":\"formula_4\"},\"end\":26855,\"start\":26790},{\"attributes\":{\"id\":\"formula_6\"},\"end\":27916,\"start\":27864},{\"attributes\":{\"id\":\"formula_7\"},\"end\":32142,\"start\":31952},{\"attributes\":{\"id\":\"formula_8\"},\"end\":32337,\"start\":32147},{\"attributes\":{\"id\":\"formula_9\"},\"end\":32941,\"start\":32870},{\"attributes\":{\"id\":\"formula_10\"},\"end\":33028,\"start\":32946}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":28372,\"start\":28365},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":34027,\"start\":34020},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":34098,\"start\":34091},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":34133,\"start\":34126},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":37851,\"start\":37844},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":37927,\"start\":37920},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":37997,\"start\":37990},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":38008,\"start\":38001},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":39527,\"start\":39520},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":40837,\"start\":40830}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":963,\"start\":951},{\"attributes\":{\"n\":\"2.\"},\"end\":6765,\"start\":6753},{\"attributes\":{\"n\":\"2.1.\"},\"end\":7794,\"start\":7763},{\"attributes\":{\"n\":\"2.2.\"},\"end\":10123,\"start\":10088},{\"attributes\":{\"n\":\"2.3.\"},\"end\":12737,\"start\":12714},{\"attributes\":{\"n\":\"3.\"},\"end\":15310,\"start\":15234},{\"attributes\":{\"n\":\"3.1.\"},\"end\":16630,\"start\":16619},{\"attributes\":{\"n\":\"3.2.\"},\"end\":22064,\"start\":22035},{\"attributes\":{\"n\":\"3.2.1.\"},\"end\":22947,\"start\":22932},{\"attributes\":{\"n\":\"3.2.2.\"},\"end\":24947,\"start\":24931},{\"attributes\":{\"n\":\"3.2.3.\"},\"end\":26865,\"start\":26857},{\"end\":27072,\"start\":27044},{\"attributes\":{\"n\":\"3.2.4.\"},\"end\":27709,\"start\":27698},{\"attributes\":{\"n\":\"3.3.\"},\"end\":28728,\"start\":28695},{\"attributes\":{\"n\":\"3.3.1.\"},\"end\":30753,\"start\":30738},{\"attributes\":{\"n\":\"3.3.2.\"},\"end\":31509,\"start\":31493},{\"attributes\":{\"n\":\"3.3.3.\"},\"end\":33038,\"start\":33030},{\"end\":33068,\"start\":33041},{\"attributes\":{\"n\":\"3.3.4.\"},\"end\":33604,\"start\":33593},{\"attributes\":{\"n\":\"4.\"},\"end\":34767,\"start\":34757},{\"attributes\":{\"n\":\"4.1.\"},\"end\":35307,\"start\":35295},{\"attributes\":{\"n\":\"4.2.\"},\"end\":38293,\"start\":38266},{\"attributes\":{\"n\":\"4.3.\"},\"end\":40870,\"start\":40843},{\"attributes\":{\"n\":\"4.4.\"},\"end\":43812,\"start\":43801},{\"attributes\":{\"n\":\"4.5.\"},\"end\":45847,\"start\":45825},{\"attributes\":{\"n\":\"5.\"},\"end\":50027,\"start\":50000},{\"attributes\":{\"n\":\"6.\"},\"end\":52399,\"start\":52388},{\"end\":54502,\"start\":54449},{\"end\":54578,\"start\":54550},{\"end\":54693,\"start\":54671},{\"end\":55082,\"start\":55072},{\"end\":55139,\"start\":55119},{\"end\":55480,\"start\":55469},{\"end\":55807,\"start\":55777},{\"end\":56300,\"start\":56291},{\"end\":56942,\"start\":56933},{\"end\":57005,\"start\":56996},{\"end\":57493,\"start\":57484},{\"end\":58539,\"start\":58530},{\"end\":58606,\"start\":58597},{\"end\":60162,\"start\":60153}]", "table": "[{\"end\":56931,\"start\":56318},{\"end\":56994,\"start\":56968},{\"end\":57482,\"start\":57134},{\"end\":58528,\"start\":57537},{\"end\":58595,\"start\":58588},{\"end\":60151,\"start\":58674},{\"end\":60982,\"start\":60251}]", "figure_caption": "[{\"end\":55070,\"start\":54743},{\"end\":55117,\"start\":55084},{\"end\":55467,\"start\":55142},{\"end\":55775,\"start\":55483},{\"end\":56289,\"start\":55811},{\"end\":56318,\"start\":56302},{\"end\":56968,\"start\":56944},{\"end\":57134,\"start\":57007},{\"end\":57537,\"start\":57495},{\"end\":58588,\"start\":58541},{\"end\":58674,\"start\":58608},{\"end\":60251,\"start\":60164}]", "figure_ref": "[{\"end\":33329,\"start\":33313},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":35459,\"start\":35451},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":36531,\"start\":36523},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":43797,\"start\":43789},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":45023,\"start\":45015},{\"end\":46095,\"start\":46081},{\"end\":47556,\"start\":47545},{\"end\":49939,\"start\":49931}]", "bib_author_first_name": "[{\"end\":61141,\"start\":61140},{\"end\":61143,\"start\":61142},{\"end\":61159,\"start\":61158},{\"end\":61173,\"start\":61172},{\"end\":61184,\"start\":61183},{\"end\":61510,\"start\":61509},{\"end\":61521,\"start\":61520},{\"end\":61531,\"start\":61530},{\"end\":61541,\"start\":61540},{\"end\":61810,\"start\":61809},{\"end\":61940,\"start\":61939},{\"end\":61951,\"start\":61950},{\"end\":61963,\"start\":61962},{\"end\":62253,\"start\":62252},{\"end\":62265,\"start\":62264},{\"end\":62276,\"start\":62275},{\"end\":62285,\"start\":62284},{\"end\":62287,\"start\":62286},{\"end\":62295,\"start\":62294},{\"end\":62305,\"start\":62304},{\"end\":62649,\"start\":62648},{\"end\":62855,\"start\":62854},{\"end\":62857,\"start\":62856},{\"end\":62863,\"start\":62862},{\"end\":62865,\"start\":62864},{\"end\":62873,\"start\":62872},{\"end\":62881,\"start\":62880},{\"end\":62883,\"start\":62882},{\"end\":62894,\"start\":62893},{\"end\":62896,\"start\":62895},{\"end\":62905,\"start\":62904},{\"end\":62915,\"start\":62914},{\"end\":62922,\"start\":62921},{\"end\":62934,\"start\":62933},{\"end\":62936,\"start\":62935},{\"end\":63279,\"start\":63278},{\"end\":63290,\"start\":63289},{\"end\":63301,\"start\":63300},{\"end\":63610,\"start\":63609},{\"end\":63612,\"start\":63611},{\"end\":63626,\"start\":63625},{\"end\":63628,\"start\":63627},{\"end\":63640,\"start\":63639},{\"end\":63642,\"start\":63641},{\"end\":63915,\"start\":63914},{\"end\":63928,\"start\":63927},{\"end\":64227,\"start\":64226},{\"end\":64234,\"start\":64233},{\"end\":64240,\"start\":64239},{\"end\":64255,\"start\":64254},{\"end\":64265,\"start\":64264},{\"end\":64275,\"start\":64274},{\"end\":64584,\"start\":64583},{\"end\":64586,\"start\":64585},{\"end\":64595,\"start\":64594},{\"end\":64597,\"start\":64596},{\"end\":64604,\"start\":64603},{\"end\":64606,\"start\":64605},{\"end\":64912,\"start\":64911},{\"end\":64914,\"start\":64913},{\"end\":64923,\"start\":64922},{\"end\":64925,\"start\":64924},{\"end\":64932,\"start\":64931},{\"end\":64934,\"start\":64933},{\"end\":65504,\"start\":65503},{\"end\":65515,\"start\":65514},{\"end\":65524,\"start\":65523},{\"end\":65859,\"start\":65858},{\"end\":65861,\"start\":65860},{\"end\":65874,\"start\":65873},{\"end\":65876,\"start\":65875},{\"end\":65887,\"start\":65886},{\"end\":65897,\"start\":65896},{\"end\":65908,\"start\":65907},{\"end\":66473,\"start\":66472},{\"end\":66480,\"start\":66479},{\"end\":66491,\"start\":66490},{\"end\":66995,\"start\":66994},{\"end\":67002,\"start\":67001},{\"end\":67013,\"start\":67012},{\"end\":67498,\"start\":67497},{\"end\":67505,\"start\":67504},{\"end\":67516,\"start\":67515},{\"end\":68004,\"start\":68003},{\"end\":68015,\"start\":68014},{\"end\":68017,\"start\":68016},{\"end\":68028,\"start\":68027},{\"end\":68038,\"start\":68037},{\"end\":68040,\"start\":68039},{\"end\":68628,\"start\":68627},{\"end\":68635,\"start\":68634},{\"end\":68879,\"start\":68878},{\"end\":68887,\"start\":68886},{\"end\":68896,\"start\":68895},{\"end\":69412,\"start\":69411},{\"end\":69421,\"start\":69420},{\"end\":69711,\"start\":69710},{\"end\":69713,\"start\":69712},{\"end\":69722,\"start\":69721},{\"end\":69724,\"start\":69723},{\"end\":69994,\"start\":69993},{\"end\":69996,\"start\":69995},{\"end\":70008,\"start\":70007}]", "bib_author_last_name": "[{\"end\":61156,\"start\":61144},{\"end\":61170,\"start\":61160},{\"end\":61181,\"start\":61174},{\"end\":61195,\"start\":61185},{\"end\":61518,\"start\":61511},{\"end\":61528,\"start\":61522},{\"end\":61538,\"start\":61532},{\"end\":61551,\"start\":61542},{\"end\":61819,\"start\":61811},{\"end\":61948,\"start\":61941},{\"end\":61960,\"start\":61952},{\"end\":61970,\"start\":61964},{\"end\":61977,\"start\":61972},{\"end\":61987,\"start\":61979},{\"end\":62262,\"start\":62254},{\"end\":62273,\"start\":62266},{\"end\":62282,\"start\":62277},{\"end\":62292,\"start\":62288},{\"end\":62302,\"start\":62296},{\"end\":62310,\"start\":62306},{\"end\":62656,\"start\":62650},{\"end\":62860,\"start\":62858},{\"end\":62870,\"start\":62866},{\"end\":62878,\"start\":62874},{\"end\":62891,\"start\":62884},{\"end\":62902,\"start\":62897},{\"end\":62912,\"start\":62906},{\"end\":62919,\"start\":62916},{\"end\":62931,\"start\":62923},{\"end\":62944,\"start\":62937},{\"end\":63287,\"start\":63280},{\"end\":63298,\"start\":63291},{\"end\":63305,\"start\":63302},{\"end\":63623,\"start\":63613},{\"end\":63637,\"start\":63629},{\"end\":63651,\"start\":63643},{\"end\":63925,\"start\":63916},{\"end\":63938,\"start\":63929},{\"end\":63944,\"start\":63940},{\"end\":64231,\"start\":64228},{\"end\":64237,\"start\":64235},{\"end\":64252,\"start\":64241},{\"end\":64262,\"start\":64256},{\"end\":64272,\"start\":64266},{\"end\":64281,\"start\":64276},{\"end\":64592,\"start\":64587},{\"end\":64601,\"start\":64598},{\"end\":64610,\"start\":64607},{\"end\":64920,\"start\":64915},{\"end\":64929,\"start\":64926},{\"end\":64938,\"start\":64935},{\"end\":65512,\"start\":65505},{\"end\":65521,\"start\":65516},{\"end\":65532,\"start\":65525},{\"end\":65871,\"start\":65862},{\"end\":65884,\"start\":65877},{\"end\":65894,\"start\":65888},{\"end\":65905,\"start\":65898},{\"end\":65916,\"start\":65909},{\"end\":66477,\"start\":66474},{\"end\":66488,\"start\":66481},{\"end\":66502,\"start\":66492},{\"end\":66999,\"start\":66996},{\"end\":67010,\"start\":67003},{\"end\":67024,\"start\":67014},{\"end\":67502,\"start\":67499},{\"end\":67513,\"start\":67506},{\"end\":67527,\"start\":67517},{\"end\":68012,\"start\":68005},{\"end\":68025,\"start\":68018},{\"end\":68035,\"start\":68029},{\"end\":68045,\"start\":68041},{\"end\":68632,\"start\":68629},{\"end\":68640,\"start\":68636},{\"end\":68884,\"start\":68880},{\"end\":68893,\"start\":68888},{\"end\":68906,\"start\":68897},{\"end\":69418,\"start\":69413},{\"end\":69425,\"start\":69422},{\"end\":69719,\"start\":69714},{\"end\":69731,\"start\":69725},{\"end\":69735,\"start\":69733},{\"end\":70005,\"start\":69997},{\"end\":70015,\"start\":70009}]", "bib_entry": "[{\"attributes\":{\"doi\":\"10.1016/j.cose.2015.10.007\",\"id\":\"b0\",\"matched_paper_id\":851357},\"end\":61432,\"start\":61053},{\"attributes\":{\"doi\":\"10.1109/TIFS.2021.3054966\",\"id\":\"b1\",\"matched_paper_id\":232043732},\"end\":61805,\"start\":61434},{\"attributes\":{\"id\":\"b2\"},\"end\":61937,\"start\":61807},{\"attributes\":{\"doi\":\"10.1016/j.diin.2006.06.008\",\"id\":\"b3\"},\"end\":62248,\"start\":61939},{\"attributes\":{\"id\":\"b4\"},\"end\":62524,\"start\":62250},{\"attributes\":{\"id\":\"b5\"},\"end\":62808,\"start\":62526},{\"attributes\":{\"doi\":\"10.1145/3057268\",\"id\":\"b6\",\"matched_paper_id\":207249455},\"end\":63185,\"start\":62810},{\"attributes\":{\"doi\":\"10.1145/3337772\",\"id\":\"b7\",\"matched_paper_id\":24406680},\"end\":63526,\"start\":63187},{\"attributes\":{\"doi\":\"10.1016/j.fsidi.2020.200909\",\"id\":\"b8\",\"matched_paper_id\":215884178},\"end\":63912,\"start\":63528},{\"attributes\":{\"doi\":\"10.3390/math8050774\",\"id\":\"b9\"},\"end\":64168,\"start\":63914},{\"attributes\":{\"doi\":\"10.1145/3323924\",\"id\":\"b10\",\"matched_paper_id\":128356922},\"end\":64513,\"start\":64170},{\"attributes\":{\"doi\":\"10.1109/TIFS.2012.2205568\",\"id\":\"b11\",\"matched_paper_id\":16912461},\"end\":64838,\"start\":64515},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":10663670},\"end\":65410,\"start\":64840},{\"attributes\":{\"doi\":\"10.1016/j.dss.2014.01.007\",\"id\":\"b13\",\"matched_paper_id\":13809775},\"end\":65757,\"start\":65412},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":25804651},\"end\":66424,\"start\":65759},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":7291094},\"end\":66950,\"start\":66426},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":12973725},\"end\":67436,\"start\":66952},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":31882251},\"end\":67890,\"start\":67438},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":13270193},\"end\":68538,\"start\":67892},{\"attributes\":{\"doi\":\"10.1109/ACCESS.2018.2814481\",\"id\":\"b19\",\"matched_paper_id\":4563816},\"end\":68832,\"start\":68540},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":204848203},\"end\":69307,\"start\":68834},{\"attributes\":{\"doi\":\"10.1145/3305218.3305239\",\"id\":\"b21\",\"matched_paper_id\":52178843},\"end\":69670,\"start\":69309},{\"attributes\":{\"doi\":\"10.1137/0112033\",\"id\":\"b22\",\"matched_paper_id\":115209202},\"end\":69902,\"start\":69672},{\"attributes\":{\"doi\":\"10.1287/mnsc.18.5.80\",\"id\":\"b23\",\"matched_paper_id\":154786809},\"end\":70207,\"start\":69904},{\"attributes\":{\"id\":\"b24\"},\"end\":70533,\"start\":70209}]", "bib_title": "[{\"end\":61138,\"start\":61053},{\"end\":61507,\"start\":61434},{\"end\":62852,\"start\":62810},{\"end\":63276,\"start\":63187},{\"end\":63607,\"start\":63528},{\"end\":64224,\"start\":64170},{\"end\":64581,\"start\":64515},{\"end\":64909,\"start\":64840},{\"end\":65501,\"start\":65412},{\"end\":65856,\"start\":65759},{\"end\":66470,\"start\":66426},{\"end\":66992,\"start\":66952},{\"end\":67495,\"start\":67438},{\"end\":68001,\"start\":67892},{\"end\":68625,\"start\":68540},{\"end\":68876,\"start\":68834},{\"end\":69409,\"start\":69309},{\"end\":69708,\"start\":69672},{\"end\":69991,\"start\":69904}]", "bib_author": "[{\"end\":61158,\"start\":61140},{\"end\":61172,\"start\":61158},{\"end\":61183,\"start\":61172},{\"end\":61197,\"start\":61183},{\"end\":61520,\"start\":61509},{\"end\":61530,\"start\":61520},{\"end\":61540,\"start\":61530},{\"end\":61553,\"start\":61540},{\"end\":61821,\"start\":61809},{\"end\":61950,\"start\":61939},{\"end\":61962,\"start\":61950},{\"end\":61972,\"start\":61962},{\"end\":61979,\"start\":61972},{\"end\":61989,\"start\":61979},{\"end\":62264,\"start\":62252},{\"end\":62275,\"start\":62264},{\"end\":62284,\"start\":62275},{\"end\":62294,\"start\":62284},{\"end\":62304,\"start\":62294},{\"end\":62312,\"start\":62304},{\"end\":62658,\"start\":62648},{\"end\":62862,\"start\":62854},{\"end\":62872,\"start\":62862},{\"end\":62880,\"start\":62872},{\"end\":62893,\"start\":62880},{\"end\":62904,\"start\":62893},{\"end\":62914,\"start\":62904},{\"end\":62921,\"start\":62914},{\"end\":62933,\"start\":62921},{\"end\":62946,\"start\":62933},{\"end\":63289,\"start\":63278},{\"end\":63300,\"start\":63289},{\"end\":63307,\"start\":63300},{\"end\":63625,\"start\":63609},{\"end\":63639,\"start\":63625},{\"end\":63653,\"start\":63639},{\"end\":63927,\"start\":63914},{\"end\":63940,\"start\":63927},{\"end\":63946,\"start\":63940},{\"end\":64233,\"start\":64226},{\"end\":64239,\"start\":64233},{\"end\":64254,\"start\":64239},{\"end\":64264,\"start\":64254},{\"end\":64274,\"start\":64264},{\"end\":64283,\"start\":64274},{\"end\":64594,\"start\":64583},{\"end\":64603,\"start\":64594},{\"end\":64612,\"start\":64603},{\"end\":64922,\"start\":64911},{\"end\":64931,\"start\":64922},{\"end\":64940,\"start\":64931},{\"end\":65514,\"start\":65503},{\"end\":65523,\"start\":65514},{\"end\":65534,\"start\":65523},{\"end\":65873,\"start\":65858},{\"end\":65886,\"start\":65873},{\"end\":65896,\"start\":65886},{\"end\":65907,\"start\":65896},{\"end\":65918,\"start\":65907},{\"end\":66479,\"start\":66472},{\"end\":66490,\"start\":66479},{\"end\":66504,\"start\":66490},{\"end\":67001,\"start\":66994},{\"end\":67012,\"start\":67001},{\"end\":67026,\"start\":67012},{\"end\":67504,\"start\":67497},{\"end\":67515,\"start\":67504},{\"end\":67529,\"start\":67515},{\"end\":68014,\"start\":68003},{\"end\":68027,\"start\":68014},{\"end\":68037,\"start\":68027},{\"end\":68047,\"start\":68037},{\"end\":68634,\"start\":68627},{\"end\":68642,\"start\":68634},{\"end\":68886,\"start\":68878},{\"end\":68895,\"start\":68886},{\"end\":68908,\"start\":68895},{\"end\":69420,\"start\":69411},{\"end\":69427,\"start\":69420},{\"end\":69721,\"start\":69710},{\"end\":69733,\"start\":69721},{\"end\":69737,\"start\":69733},{\"end\":70007,\"start\":69993},{\"end\":70017,\"start\":70007}]", "bib_venue": "[{\"end\":65149,\"start\":65047},{\"end\":66109,\"start\":66012},{\"end\":66709,\"start\":66604},{\"end\":67205,\"start\":67124},{\"end\":67670,\"start\":67600},{\"end\":68234,\"start\":68143},{\"end\":69080,\"start\":68994},{\"end\":61236,\"start\":61223},{\"end\":61610,\"start\":61578},{\"end\":61845,\"start\":61821},{\"end\":62083,\"start\":62015},{\"end\":62342,\"start\":62312},{\"end\":62646,\"start\":62526},{\"end\":62977,\"start\":62961},{\"end\":63346,\"start\":63322},{\"end\":63714,\"start\":63680},{\"end\":64037,\"start\":63965},{\"end\":64328,\"start\":64298},{\"end\":64669,\"start\":64637},{\"end\":65045,\"start\":64940},{\"end\":65578,\"start\":65559},{\"end\":66010,\"start\":65918},{\"end\":66602,\"start\":66504},{\"end\":67122,\"start\":67026},{\"end\":67598,\"start\":67529},{\"end\":68141,\"start\":68047},{\"end\":68680,\"start\":68669},{\"end\":68992,\"start\":68908},{\"end\":69483,\"start\":69450},{\"end\":69775,\"start\":69752},{\"end\":70047,\"start\":70037},{\"end\":70283,\"start\":70209}]"}}}, "year": 2023, "month": 12, "day": 17}