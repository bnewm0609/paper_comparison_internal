{"id": 10043111, "updated": "2022-02-24 05:03:48.615", "metadata": {"title": "The PARSEC benchmark suite: Characterization and architectural implications", "authors": "[{\"first\":\"Christian\",\"last\":\"Bienia\",\"middle\":[]},{\"first\":\"Sanjeev\",\"last\":\"Kumar\",\"middle\":[]},{\"first\":\"Jaswinder\",\"last\":\"Singh\",\"middle\":[\"Pal\"]},{\"first\":\"Kai\",\"last\":\"Li\",\"middle\":[]}]", "venue": "2008 International Conference on Parallel Architectures and Compilation Techniques (PACT)", "journal": "2008 International Conference on Parallel Architectures and Compilation Techniques (PACT)", "publication_date": {"year": 2008, "month": null, "day": null}, "abstract": "This paper presents and characterizes the Princeton Application Repository for Shared-Memory Computers (PARSEC), a benchmark suite for studies of Chip-Multiprocessors (CMPs). Previous available benchmarks for multiprocessors have focused on high-performance computing applications and used a limited number of synchronization methods. PARSEC includes emerging applications in recognition, mining and synthesis (RMS) as well as systems applications which mimic large-scale multithreaded commercial programs. Our characterization shows that the benchmark suite covers a wide spectrum of working sets, locality, data sharing, synchronization and off-chip traffic. The benchmark suite has been made available to the public.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": "2169875292", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/IEEEpact/BieniaKSL08", "doi": "10.1145/1454115.1454128"}}, "content": {"source": {"pdf_hash": "f6d499a5c5761a5441150b39ef2f8ca581ce3096", "pdf_src": "MergedPDFExtraction", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "2d5c5fc92aa2774ca2c40e943415b4c9f366d377", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/f6d499a5c5761a5441150b39ef2f8ca581ce3096.txt", "contents": "\nThe PARSEC Benchmark Suite: Characterization and Architectural Implications\nJanuary 2008\n\nChristian Bienia cbienia@cs.princeton.edu \nSanjeev Kumar \nMicroprocessor Technology Labs\nIntel\n\n\nJaswinder Pal Singh \nKai Li \n\u2020 \n\nDepartment of Computer Science\nPrinceton University\nPrinceton University\n\n\nThe PARSEC Benchmark Suite: Characterization and Architectural Implications\nJanuary 2008D0 [Software]: [benchmark suite] General Terms PerformanceMeasurementExperimentation Keywords benchmark suiteperformance measurementmulti-threadingshared-memory computers\nThis paper presents and characterizes the Princeton Application Repository for Shared-Memory Computers (PAR-SEC), a benchmark suite for studies of Chip-Multiprocessors (CMPs). Previous available benchmarks for multiprocessors have focused on high-performance computing applications and used a limited number of synchronization methods. PARSEC includes emerging applications in recognition, mining and synthesis (RMS) as well as systems applications which mimic large-scale multi-threaded commercial programs. Our characterization shows that the benchmark suite is diverse in working set, locality, data sharing, synchronization, and off-chip traffic. The benchmark suite has been made available to the public.\n\nINTRODUCTION\n\nBenchmarking is the quantitative foundation of computer architecture research. Program execution time is the only accurate way to measure performance [18]. Without a program selection that provides a representative snapshot of the target application space, performance results can be misleading and no valid conclusions may be drawn from an experiment outcome. CMPs require a disruptive change in order for programs to benefit from their full potential. Future applications will have to be parallel, but due to the lack of a representative, multi-threaded benchmark suite most scientists were forced to fall back to existing benchmarks. This usually meant the use of older High-Performance Computing (HPC) workloads, smaller suites with only few programs or unparallelized benchmarks. We consider this trend extremely dangerous for the whole discipline. Representative conclusions require representative experiments and, as we argue in this paper, existing benchmark suites cannot be considered adequate to describe future CMP applications.\n\nLarge processor manufacturers have already reacted and developed their own, internal collections of workloads. An example is the Intel RMS benchmark suite [14]. However, these suites often include proprietary code and are not publicly available. To address this problem, we created the PAR-SEC benchmark suite in collaboration with Intel Corporation. It includes not only a number of important applications from the RMS suite but also several leading-edge applications from Princeton University, Stanford University and the open-source domain. The goal is to create a suite of emerging workloads that can drive CMP research. This paper makes three contributions:\n\n\u2022 We identify shortcomings of commonly used benchmark suites and explain why they should not be used to evaluate CMPs.\n\n\u2022 We present and characterize PARSEC, a new benchmark suite for CMPs that is diverse enough in order to allow representative conclusions.\n\n\u2022 Based on our characterization of PARSEC, we analyze what properties future CMPs must have in order to be able to deliver scalable performance for emerging applications. In particular, our understanding of the behavior of future workloads allows us to quantify how CMPs must be built in order to mitigate the effects of the memory wall on the next generation of programs.\n\nIn Section 2 we describe why existing benchmark suites cannot be considered adequate to describe future CMP applications. In Section 3, we present the PARSEC benchmark suite and explain how it avoids the shortcomings of other collections of benchmarks. The methodology which we use to characterize our workloads is presented in Section 4. In Sections 5 to 8, we analyze the parallelization, working sets, communication behavior and off-chip traffic of the benchmark programs. We conclude our study in Section 9.\n\n\nMOTIVATION\n\nThe goal of this work is to define a benchmark suite that can be used to design the next generation of processors. In this section, we first present the requirements for such a suite. We then discuss how the existing benchmarks fail to meet these requirements.\n\n\nRequirements for a Benchmark Suite\n\nWe have the following five requirements for a benchmark suite:\n\nMulti-threaded Applications Shared-memory CMPs are already ubiquitous. The trend for future processors is to deliver large performance improvements through increasing core counts on CMPs while only providing modest serial performance improvements. Consequently, applications that require additional processing power will need to be parallel.\n\nEmerging Workloads Rapidly increasing processing power is enabling a new class of applications whose computational requirements were beyond the capabilities of the earlier generation of processors [14]. Such applications are significantly different from earlier applications (see Section 3). Future processors will be designed to meet the demands of these emerging applications and a benchmark suite should represent them.\n\nDiverse Applications are increasingly diverse, run on a variety of platforms and accommodate different usage models. They include both interactive applications like computer games, offline applications like data mining programs and programs with different parallelization models. Specialized collections of benchmarks can be used to study some of these areas in more detail, but decisions about general-purpose processors should be based on a diverse set of applications. While a truly representative suite is impossible to create, reasonable effort should be made to maximize the diversity of the program selection. The number of benchmarks must be large enough to capture a sufficient amount of characteristics of the target application space.\n\nEmploy State-of-Art Techniques A number of application domains have changed dramatically over the last decade and use very different algorithms and techniques. Visual applications for example have started to increasingly integrate physics simulations to generate more realistic animations [20]. A benchmark should not only represent emerging applications but also use state-of-art techniques.\n\nSupport Research A benchmark suite intended for research has additional requirements compared to one used for benchmarking real machines alone. Benchmark suites intended for research usually go beyond pure scoring systems and provide infrastructure to instrument, manipulate, and perform detailed simulations of the included programs in an efficient manner.\n\n\nLimitations of Existing Benchmark Suites\n\nIn the remaining part of this section we analyze how existing benchmark suites fall short of the presented requirements and must thus be considered unsuitable for evaluating CMP performance.\n\nSPLASH-2 SPLASH-2 is a suite composed of multi-threaded applications [44] and hence seems to be an ideal candidate to measure performance of CMPs. However, its program collection is skewed towards HPC and graphics programs. It thus does not include parallelization models such as the pipeline model which are used in other application areas. SPLASH-2 should furthermore not be considered state-of-art anymore. Barnes for example implements the Barnes-Hut algorithm for N-body simulation [8]. For galaxy simulations it has largely been superseded by the TreeSPH [19] method, which can also account for mass such as dark matter which is not concentrated in bodies. However, even for pure N-body simulation barnes must be considered outdated. In 1995 Xu proposed a hybrid algorithm which combines the hierarchical tree algorithm and the Fourier-based Particle-Mesh (PM) method to the superior TreePM method [45]. Our analysis shows that similar issues exist for a number of other applications of the suite including raytrace and radiosity.\n\nSPEC CPU2006 and OMP2001 SPEC CPU2006 and SPEC OMP2001 are two of the largest and most significant collections of benchmarks. They provide a snapshot of current scientific and engineering applications. Computer architecture research, however, commonly focuses on the near future and should thus also consider emerging applications. Workloads such as systems programs and parallelization models which employ the producer-consumer model are not included. SPEC CPU2006 is furthermore a suite of serial programs that is not intended for studies of parallel machines.\n\nOther Benchmark Suites Besides these major benchmark suites, several smaller suites exist. They were usually designed to study a specific program area and are thus limited to a single application domain. Therefore they usually include a smaller set of applications than a diverse benchmark suite typically offers. Due to these limitations they are commonly not used for scientific studies which do not restrict themselves to the covered application domain. Examples for these types of benchmark suites are ALPBench [25], BioParallel [22], MediaBench [1], NU-MineBench [23] and PhysicsBench [46]. Because of their different focus we do not discuss these suites in more detail.\n\n\nTHE PARSEC BENCHMARK SUITE\n\nOne of the goals of the PARSEC suite was to assemble a program selection that is large and diverse enough to be sufficiently representative for scientific studies. It consists of 9 applications and 3 kernels which were chosen from a wide range of application domains. In Table 1 we present a qualitative summary of their key characteristics. PARSEC workloads were selected to include different combinations of parallel models, machine requirements and runtime behaviors.\n\nPARSEC meets all the requirements outlined in Section 2.1:\n\n\u2022 Each of the applications has been parallelized.\n\n\u2022 The PARSEC benchmark suite is not skewed towards HPC programs, which are abundant but represent only a niche. It focuses on emerging workloads. The algorithms these programs implement are usually considered useful, but their computational demands are prohibitively high on contemporary platforms. As more powerful processors become available in the near future, they are likely to proliferate rapidly. Media Processing pipeline coarse medium high high Table 1: Qualitative summary of the inherent key characteristics of PARSEC benchmarks. Working sets and data usage patterns are explained and quantified in later sections. The pipeline model is a data-parallel model which also uses a functional partitioning. PARSEC workloads were chosen to cover different application domains, parallel models and runtime behaviors.\n\n\u2022 The workloads are diverse and were chosen from many different areas such as computer vision, media processing, computational finance, enterprise servers and animation physics.\n\n\u2022 Each of the applications chosen represents the stateof-art technique in its area.\n\n\u2022 PARSEC supports computer architecture research in a number of ways. The most important one is that for each workload six input sets with different properties are defined. Three of these inputs are suitable for microarchitectural simulation. We explain the different types of input sets in more detail in Section 3.1.\n\n\nInput Sets\n\nPARSEC defines six input sets for each benchmark:\n\ntest A very small input set to test the basic functionality of the program.\n\nsimdev A very small input set which guarantees basic program behavior similar to the real behavior, intended for simulator test and development.\n\nsimsmall, simmedium and simlarge Input sets of different sizes suitable for microarchitectural studies with simulators.\n\nnative A large input set intended for native execution.\n\ntest and simdev are merely intended for testing and development and should not be used for scientific studies. The three simulator inputs for studies vary in size, but the general trend is that larger input sets contain bigger working sets and more parallelism. Finally, the native input set is intended for performance measurements on real machines and exceeds the computational demands which are generally considered feasible for simulation by orders of magnitude. From a scientific point of view, the native input set is the most interesting one because it resembles real program inputs most closely. The remaining input sets can be considered coarser aproximations which sacrifice accuracy for tractability. Table 2 shows a breakdown of instructions and synchronization primitives of the simlarge input set which we used for the characterization study.\n\n\nWorkloads\n\nThe following workloads are part of the PARSEC suite:\n\n\nblackscholes\n\nThe blackscholes application is an Intel RMS benchmark. It calculates the prices for a portfolio of European options analytically with the Black-Scholes partial differential equation (PDE) [10] \u2202V \u2202t\n+ 1 2 \u03c3 2 S 2 \u2202 2 V \u2202S 2 + rS \u2202V \u2202S \u2212 rV = 0\nwhere V is an option on the underlying S with volatility \u03c3 at time t if the constant interest rate is r. There is no closedform expression for the Black-Scholes equation and as such it must be computed numerically [21]. The blackscholes benchmark was chosen to represent the wide field of analytic PDE solvers in general and their application in computational finance in particular. The program is limited by the amount of floating-point calculations a processor can perform.\n\nblackscholes stores the portfolio with numOptions derivatives in array OptionData. The program includes file option-Data.txt which provides the initialization and control reference values for 1,000 options which are stored in array data init. The initialization data is replicated if necessary to obtain enough derivatives for the benchmark.\n\nThe program divides the portfolio into a number of work units equal to the number of threads and processes them concurrently. Each thread iterates through all derivatives in its contingent and calls function BlkSchlsEqEuroNoDiv for each of them to compute its price. If error checking was  \n\n\nbodytrack\n\nThe bodytrack computer vision application is an Intel RMS workload which tracks a 3D pose of a markerless human body with multiple cameras through an image sequence [13,6]. bodytrack employs an annealed particle filter to track the pose using edges and the foreground silhouette as image features, based on a 10 segment 3D kinematic tree body model. These two image features were chosen because they exhibit a high degree of invariance under a wide range of conditions and because they are easy to extract. An annealed particle filter was employed in order to be able to search high dimensional configuration spaces without having to rely on any assumptions of the tracked body such as the existence of markers or constrained movements. This benchmark was included due to the increasing significance of computer vision algorithms in areas such as video surveillance, character animation and computer interfaces.\n\nFor every frame set Zt of the input videos at time step t, the bodytrack benchmark executes the following steps:\n\n1. The image features of observation Zt are extracted.\n\nThe features will be used to compute the likelihood of a given pose in the annealed particle filter. t,m )}.\n\nEach particle s\n(i)\nt,m is an instance of the multi-variate model configuration X which encodes the location and state of the tracked body.\n\n\nEach particle s (i)\n\nt,m is then assigned a weight \u03c0 (i) t,m by using weighting function \u03c9(Zt, X) corresponding to the likelihood of X given the image features in Zt scaled by an annealing level factor:\n\u03c0 (i) t,m \u221d \u03c9(Zt, s (i) t,m ).\nThe weights are normalized so that\nP N i=1 \u03c0 (i)\nt,m = 1. The result is the weighted particle set\nS \u03c0 t,m = {(s(1)\nt,m , \u03c0 5. N particles are randomly drawn from set S \u03c0 t,m with a probability equal to their weight \u03c0 (i) t,m to obtain the temporary weighted particle set\nS \u03c0 t,m = {(s (1) t,m , \u03c0 (1) t,m )...(s (N ) t,m , \u03c0 (N ) t,m )}.\nEach particles\n(i)\nt,m is then used to produce particle\ns (i) t,m\u22121 =s (i) t,m + Bm\nwhere Bm is a multi-variate gaussian random variable. The result is particle set S \u03c0 t,m\u22121 which is used to initialize layer m \u2212 1.\n\n6. The process is repeated until all layers have been processed and the final particle set S \u03c0 t,0 has been computed.\n\n7. S \u03c0 t,0 is used to compute the estimated model configuration \u03c7t for time step t by calculating the weighted average of all configuration instances:\n\u03c7t = N X i=1 s (i) t,0 \u03c0 (i) t,0 .\n8. The set St+1,M is then produced from S \u03c0 t,0 using\ns (i) t+1,M = s (i) t,0 + B0.\nIn the subsequent time step t+1 the set St+1,M is used to initialize layer M.\n\nThe likelihood \u03c9(Zt, s (i) t,m ) which is used to determine the particle weights \u03c0 (i) t,m is computed by projecting the geometry of the human body model into the image observations Zt for each camera and determining the error based on the image features. The likelihood is a measure of the 3D body model alignment with the foreground and edges in the images. The body model consists of conic cylinders to represent 10 body parts 2 for each limb plus the torso and the head. Each cylinder is represented by a length and a radius for each end. The body parts are assembled into a kinematic tree based upon the joint angles. Each particle represents the set of joint angles plus a global translation. To evaluate the likelihood of a given particle, the geometry of the body model is first built in 3D space given the angles and translation. Next, each 3D body part is projected onto each of the 2D images as a quadrilateral. A likelihood value is then computed based on the two image features the foreground map and the edge distance map. To compute the foreground term, samples are taken within the interior of each 2D body part projection and compared with the binary foreground map images. Samples that correspond to foreground increase the likelihood while samples that correspond to background are penalized. The edge map gives a measure of the distance from an edge in the image -values closer to an edge have a higher value. To compute the edge term samples are taken along the axis-parallel edges of each 2D body part projection and the edge map values at each sample are summed together. In this way, samples that are closer to edges in the images increase the likelihood while samples farther from edges are penalized.\n\nbodytrack has a persistent thread pool which is implemented in class WorkPoolPthread. The main thread executes the program and sends a task to the thread pool with method SignalCmd whenever it reaches a parallel kernel. It resumes execution of the program as soon as it receives the result from the worker threads. Possible tasks are encoded by enumeration threadCommands in class WorkPoolPthread. The program has three parallel kernels:\n\nEdge detection (Step 1) bodytrack employs a gradient based edge detection mask to find edges. The result is compared against a threshold to eliminate spurious edges. Edge detection is implemented in function GradientMagThreshold. The output of this kernel will be further refined before it is used to compute the particle weights.\n\nEdge smoothing (Step 1) A separable gaussian filter of size 7\u00d77 pixels is used to smooth the edges in function GaussianBlur. The result is remapped between 0 and 1 to produce a pixel map in which the value of each pixel is related to its distance from an edge. The kernel has two parallel phases, one to filter image rows and one to filter image columns.\n\nCalculate particle weights (Step 4) This kernel evaluates the foreground silhouette and the image edges produced earlier to compute the weights for the particles. This kernel is executed once for every annealing layer during every time step, making it the computationally most intensive part of the body tracker.\n\nThe parallel kernels use tickets to distribute the work among threads balance the load dynamically. The ticketing mechanism is implemented in class TicketDispenser and behaves like a shared counter.\n\nThe input sets for bodytrack are defined as follows:\n\n\u2022 test: 4 cameras, 1 frame, 5 particles, 1 annealing layer \n\n\ncanneal\n\nThis kernel was developed by Princeton University. It uses cache-aware simulated annealing (SA) to minimize the routing cost of a chip design [7]. SA is a common method to approximate the global optimum in a large search space.\n\nCanneal pseudorandomly picks pairs of elements and tries to swap them. To increase data reuse, the algorithm discards only one element during each iteration which effectively reduces cache capacity misses. The SA method accepts swaps which increase the routing cost with a certain probability to make an escape from local optima possible. This probability continuously decreases during runtime to allow the design to converge. The program was included in the PAR-SEC program selection to represent engineering workloads, for the fine-grained parallelism with its lock-free synchronization techniques and due to its pseudorandom worst-case memory access pattern.\n\ncanneal uses a very aggressive synchronization strategy that is based on data race recovery instead of avoidance. Pointers to the elements are dereferenced and swapped atomically, but no locks are held while a potential swap is evaluated. This can cause disadvantagous swaps if one of the relevant elements has been replaced by another thread during that time. This equals a higher effective probability to accept swaps which increase the routing cost, and the SA method automatically recovers from it. The swap operation employs lock-free synchronization which is implemented with atomic instructions. An alternative implementation which relied on conventional locks turned out to be too inefficient due to excessive locking overhead. The synchronization routines with the atomic instructions are taken from the BSD kernel. Support for most new architectures can be added easily by copying the correct header file from the BSD kernel sources.\n\nThe annealing algorithm is implemented in the Run function of the annealer thread class. Each thread uses the function get random element to pseudorandomly pick one new netlist element per iteration with a Mersenne Twister [31]. calculate delta routing cost is called to compute the change of the total routing cost if the two elements are swapped. accept move evaluates the change in cost and the current temperature and decides whether the change is to be committed. Finally, accepted swaps are executed by calling swap locations.\n\ncanneal implements an AtomicPtr class which encapsulates a shared pointer to the location of a netlist element. The pointer is atomically accessed and modified with the Get and Set functions offered by the class. A special Swap member function executes an atomic swap of two encapsulated pointers. If an access is currently in progress the functions spin until the operation could be completed. The implementation of Swap imposes a partial order to avoid deadlocks by processing the pointer at the lower memory location first.\n\nWe provide the following input sets for canneal:\n\n\u2022 test: 5 swaps per temperature step, 100 \u2022 start temperature, 10 netlist elements \n\n\ndedup\n\nThe dedup kernel was developed by Princeton University. It compresses a data stream with a combination of global compression and local compression in order to achieve high compression ratios. Such a compression is called 'deduplication'. The reason for the inclusion of this kernel is that deduplication has become a mainstream method to compress storage footprints for new-generation backup storage systems [36] and to compress communication data for newgeneration bandwidth optimized networking appliances [39].\n\nThe kernel uses a pipelined programming model to parallelize the compression to mimic real-world implementations.\n\nThere are five pipeline stages the intermediate three of which are parallel. In the first stage, dedup reads the input stream and breaks it up into coarse-grained chunks to get independent work units for the threads. The second stage anchors each chunk into fine-grained small segments with rolling fingerprinting [29,11]. The third pipeline stage computes a hash value for each data segment. The fourth stage compresses each data segment with the Ziv-Lempel algorithm and builds a global hash table that maps hash values to data. The final stage assembles the deduplicated output stream consisting of hash values and compressed data segments.\n\nAnchoring is a method which identifies brief sequences in a data stream that are identical with sufficiently high probability. It uses fast Rabin-Karp fingerprints [24] to detect identity. The data is then broken up into two separate blocks at the determined location. This method ensures that fragmenting a data stream is unlikely to obscure duplicate sequences since duplicates are identified on a block basis.\n\ndedup uses a separate thread pool for each parallel pipeline stage. Each thread pool should at least have a number of threads equal to the number of available cores to allow the system to fully work on any stage should the need arise.\n\nThe operating system scheduler is responsible for a thread schedule which will maximize the overall throughput of the pipeline. In order to avoid lock contention, the number of queues is scaled with the number of threads, with a small group of threads sharing an input and output queue at a time.\n\ndedup employs the following five kernels, one for each pipeline stage:\n\nCoarse-grained fragmentation This serial kernel takes the input stream and breaks it up into work units which can be processed independently from each other by the parallel pipeline stages of dedup. It is implemented in function DataProcess. First, the kernel reads the input file from disk. It then determines the locations where the data is to be split up by jumping a fixed length in the buffer for each chunk. The resulting data blocks are enqueued in order to be further refined by the subsequent stage.\n\nFine-grained fragmentation This parallel kernel uses Rabin-Karp fingerprints to break a coarse-grained data chunk up into fine-grained fragments. It scans each input block starting from the beginning. An anchor is found if the lowest 12 bits of the Rabin-Karp hashsum are 0. The data is then split up at the location of the anchor. On average, this produces blocks of size 2 12 /8 = 512 bytes. The fine-grained data blocks are sent to the subsequent pipeline stage to compute their checksum. This kernel is implemented in function FindAllAnchor.\n\nHash computation To uniquely identify a fine-grained data block, this parallel kernel computes the SHA1 checksum of each chunk and checks for duplicate blocks with the use of a global database. It is implemented in function ChunkProcess. A hash table which is indexed with the SHA1 sum serves as the database. Each bucket of the hash table is associated with an independent lock in order to synchronize accesses. The large number of buckets and therefore locks makes the probability of lock contention very low in practice.\n\nOnce the SHA1 sum of a data block is available, the kernel checks whether a corresponding entry already exists in the database. If no entry could be found, the data block is added to the hash table and sent to the compression stage. If an entry already exists the block is classified as a duplicate. The compression stage is omitted and the block is sent directly to the pipeline stage which assembles the output stream.\n\nCompression This kernel compresses data blocks in parallel. It is implemented in function Compress. Once the compressed image of a data block is available it is added to the database and the corresponding data block is sent to the next pipeline stage. Every data block is compressed only once because the previous stage does not send duplicates to the compression stage.\n\nAssemble output stream This serial kernel reorders the data blocks and produces a compressed output stream. It is implemented in the SendBlock function. The stages which fragment the input stream into fine-grained data blocks add sequence numbers to allow a reconstruction of the original order. Because data fragmentation occurs in two different pipeline stages, two levels of sequence numbers have to be considered -one for each granularity level. SendBlock uses a search tree for the first level and a heap for the second level. The search tree allows rapid searches for the correct heap corresponding to the current first-level sequence number. For second-level sequence numbers only the minimum has to be found and hence a heap is used.\n\nOnce the next data block in the sequence becomes available it is removed from the reordering structures. If it has not been written to the output stream yet, its compressed image is emitted. Otherwise it is a duplicate and only its SHA1 signature is written as a placeholder. The kernel uses the global hash table to keep track of the output status of each data block.\n\nEach input for dedup is an archive which contains a selection of files. The archives have the following sizes:\n\n\u2022 test: 10 KB \n\n\nfacesim\n\nThis Intel RMS application was originally developed by Stanford University. It takes a model of a human face and a time sequence of muscle activations and computes a visually realistic animation of the modeled face by simulating the underlying physics [38,40]. The goal is to create a visually realistic result. Certain effects such as inertial movements would have only a small visible effect and are not simulated [20].\n\nThe workload was included in the benchmark suite because an increasing number of computer games and other forms of animation employ physical simulation to create more realistic virtual environment. Human faces in particular are observed with more attention from users than other details of a virtual world, making their realistic presentation a key element for animations.\n\nThe parallelization uses a static partitioning of the mesh. Data that spans nodes belonging to more than one partition is replicated. Every time step the partitions process all elements that contain at least one node owned by the particle, but only results for nodes which are owned by the partition are written.\n\nThe iteration which computes the state of the face mesh at the end of each iteration is implemented in function Advance -One Time\n\nStep Quasistatic. facesim employs the fork-join model to process computationally intensive tasks in parallel. It uses the following three parallel kernels for its computations:\n\nUpdate state This kernel uses the Newton-Raphson method to solve the nonlinear system of equations in order to find the steady state of the simulated mesh. This quasistatic scheme achieves speedups of one to two orders of magnitudes over explicit schemes by ignoring inertial effects. It is not suitable for the simulation of less constrained phenomena such as ballistic motion, but it is sufficiently accurate to simulate effects such as flesh deformation where the material is heavily influenced by contact, collision and self-collision and inertial effects only have a minor impact on the state.\n\nIn each Newton-Raphson iteration, the kernel reduces the nonlinear system of equations to a linear system which is guaranteed to be positive definite and symmetric. These two properties allow the use of a fast conjugate gradient solver later on. One iteration step is computed by function Update Position Based State.\n\nThe matrix of the linear system is sparse and can hence be stored in two one-dimensional arrays -dX full and R full. The matrix is the sum of the contribution of each tetrahedron of the face mesh.\n\nAdd forces This module computes the velocity-independent forces acting on the simulation mesh. After the matrix of the linear system with the position-independent state has been computed by the previous kernel, the right-hand side of that system has to be calculated. The kernel does this by iterating over all tetrahedra of the mesh, reading the positions of the vertices and computing the force contribution to each of the four nodes.\n\nConjugate gradient This kernel uses the conjugate gradient algorithm to solve the linear equation system assembled by the previous two modules. The two arrays dX full and R full which store the sparse matrix are sequentially accessed and matrix-vector multiplication is employed to solve the system.\n\nThe input sets of facesim all use the same face mesh. Scaling down the resolution of the mesh to create more tractable input sizes is impractical. A reduction of the number of elements in the model would result in under-resolution of the muscle action and cause problems for collision detection [20]. Our input sets for facesim are defined as follows:\n\n\u2022 test: Print out help message.\n\n\u2022 simdev: 80,598 particles, 372,126 tetrahedra, 1 frame\n\n\u2022 simsmall: Same as simdev\n\n\u2022 simmedium: Same as simdev\n\n\u2022 simlarge: Same as simdev\n\n\u2022 native: Same as simdev, but with 100 frames\n\n\nferret\n\nThis application is based on the Ferret toolkit which is used for content-based similarity search of feature-rich data such as audio, images, video, 3D shapes and so on [27]. It was developed by Princeton University. The reason for the inclusion in the benchmark is that it represents emerging nextgeneration desktop and internet search engines for non-text document data types. In the benchmark, we have configured the Ferret toolkit for image similarity search. Ferret is parallelized using the pipeline model with six stages. The first and the last stage are for input and output. The middle four stages are for query image segmentation, feature extraction, indexing of candidate sets with multi-probe Locality Sensitive Hashing (LSH) [28] and ranking. Each stage has its own thread pool and the basic work unit of the pipeline is a query image.\n\nSegmentation is the process of decomposing an image into separate areas which display different objects. The rationale behind this step is that in many cases only parts of an image are of interest, such as the foreground. Segmentation allows the subsequent stages to assign a higher weight to image parts which are considered relevant and seem to belong together. After segmentation, ferret extracts a feature vector from every segment. A feature vector is a multi-dimensional mathematical description of the segment contents. It encodes fundamental properties such as color, shape and area.\n\nOnce the feature vectors are known, the indexing stage can query the image database to obtain a candidate set of images. The database is organized as a set of hash tables which are indexed with multi-probe LSH [28]. This method uses hash functions which map similar feature vectors to the same hash bucket with high probability. Because the number of hash buckets is very high, multi-probe LSH first derives a probing sequence which considers the success probabilities for finding a candidate image in a bucket. It then employs a step-wise approach which indexes buckets with a higher success probability first. After a candidate set of images has been obtained by the indexing stage, it is sent to the ranking stage which computes a detailed similarity estimate and orders the images according to their calculated rank. The similarity estimate is derived by analyzing and weighing the pair-wise distances between the segments of the query image and the candidate images. The underlying metric employed is the Earth Mover's Distance (EMD) [37]. For two images X and Y , it is defined as\nEM D(X, Y ) = min X i X j fijd(Xi, Yj)\nwhere Xi and Yj denote segments of X and Y and fij is the extent to which Xi is matched to Yj.\n\nThe first and the last pipeline stage of ferret are serial. The remaining four modules are parallel:\n\nImage segmentation This kernel uses computer vision techniques to break an image up into non-overlapping segments. The pipeline stage is implemented in function t seg, which calls image segment for every image. This function uses statistical region merging (SRM) [33] to segment the image. This method organizes the pixels of an image in sets, starting with a fine-granular decomposition. It repeatedly merges them until the final segmentation has been reached.\n\nFeature extraction This module computes a 14-dimensional feature vector for each image segment. The features extracted are the bounding box of the segment (5 dimensions) and its color moments (9 dimensions). A bounding box is the minimum axis-aligned rectangle which includes the segment. Color moments is a compact representation of the color distribution. It is conceptually similar to a histogram but uses fewer dimensions. Segments are assigned a weight which is proportional to the square root of its size. This stage is implemented in function t extract. It calls image extract helper to compute the feature vectors for every image.\n\nIndexing The indexing stage queries the image database to obtain no more than twice the number of images which are allowed to appear in the final ranking. This stage is implemented in function t vec. ferret manages image data in tables which have type cass A simplified version of the Navier-Stokes equation for incompressible fluids [35] which formulates conservation of momentum is\n\u03c1( \u2202v \u2202t + v \u00b7 \u2207v) = \u2212\u2207p + \u03c1g + \u00b5\u2207 2 v\nwhere v is a velocity field, \u03c1 a density field, p a pressure field, g an external force density field and \u00b5 the viscosity of the fluid. The SPH method uses particles to model the state of the fluid at discrete locations and interpolates intermediate values with radial symmetrical smoothing kernels. An advantage of this method is the automatic conservation of mass due to a constant number of particles, but it alone does not guarantee certain physical principals such as symmetry of forces which have to be enforced separately. The SPH algorithm derives a scalar quantity A at location r by a weighted sum of all particles:\nAS(r) = X j mj Aj \u03c1j W (r \u2212 rj, h).\nIn the equation, j iterates over all particles, mj is the mass of particle j, rj its position, \u03c1j the density at its location and Aj the respective field quantity. W (r \u2212 rj, h) is the smoothing kernel to use for the interpolation with core radius h. Smoothing kernels are employed in order to make the SPH method stable and accurate. Because each particle i represents a volume with constant mass mi, the density \u03c1i appears in the equation and has to be recomputed every time step. The density at a location r can be calculated by substituting A with \u03c1 in the previous equation:\n\u03c1S(r) = X j mjW (r \u2212 rj, h)\n.\n\nApplying the SPH interpolation equation to the pressure term \u2212\u2207p and the viscosity term \u00b5\u2207 2 of the Navier-Stokes equation yields the equations for the pressure and viscosity forces, but in order to solve the force symmetry problems of the SPH method, fluidanimate employs slightly modified formulas:\nf pressure i = \u2212 X j mj pi + pj 2\u03c1j \u2207W (ri \u2212 rj, h) f viscosity i = \u00b5 X j mj vi \u2212 vj \u03c1j \u2207 2 W (ri \u2212 rj, h)\nStability, accuracy and speed of fluidanimate are highly dependent on its smoothing kernels. In all cases but the pressure and viscosity computations the program uses the following kernel:\nW poly6 (r, h) = 315 64\u03c0h 9 ( (h 2 \u2212 r 2 ) 3 0 \u2264 r \u2264 h 0 else\nOne feature of this kernel is that the distance r only appears squared. The computation of square roots is thus not necessary to evaluate it. For pressure computations, fluidanimate uses Desbrun's spiky kernel W spiky [12] and Wviscosity for viscosity forces:\nW spiky (r, h) = 15 \u03c0h 6 ( (h \u2212 r) 3 0 \u2264 r \u2264 h 0 else Wviscosity(r, h) = 15 2\u03c0h 3 ( \u2212 r 3 2h 3 + r 2 h 2 + h 2r \u2212 1 0 \u2264 r \u2264 h 0 else\nThe scene geometry employed by fluidanimate is a box in which the fluid resides. All collisions are handled by adding forces in order to change the direction of movement of the involved particles instead of modifying the velocity directly.\n\nThe workload uses Verlet integration [42] to update the position of the particles. This scheme does not store the velocity of the particles explicitly, but their previous location in addition to the current position. The current velocity can thus be deduced from the distance travelled since the last time step. The force and mass are then used to compute the acceleration and subsequently the new velocity. This scheme is more robust because the velocity is implicitly given.\n\nEvery time step, fluidanimate executes five kernels, the first two of which were further broken up into several smaller steps:\n\nRebuild spatial index Because the smoothing kernels W (r \u2212 rj, h) have finite support h, particles can only interact with each other up to the distance h. The program uses a spatial indexing structure in order to exploit proximity information and limit the number of particles which have to be evaluated. Functions ClearParticles and RebuildGrid build this acceleration structure which is used by the subsequent steps.\n\nCompute densities This kernel estimates the fluid density at the position of each particle by analyzing how closely particles are packed in its neighborhood. In a region in which particles are packed together more closely, the density will be higher. This kernel has 3 phases which are implemented in the functions Init-DensitiesAndForces, ComputeDensities and Compute-Densities2.\n\nCompute forces Once the densities are known, they can be used to compute the forces. This step happens in function ComputeForces. The kernel evaluates pressure, viscosity and also gravity as the only external influence. Collisions between particles are handled implicitly during this step, too.\n\nHandle collisions with scene geometry The next kernel updates the forces in order to handle collisions of particles with the scene geometry. This step is implemented in function ProcessCollisions.\n\nUpdate positions of particles Finally, the forces can be used to calculate the acceleration of each particle and update its position. fluidanimate uses a Verlet integrator [42] for these computations which is implemented in function AdvanceParticles.\n\nThe input sets for fluidanimate are sized as follows:\n\n\u2022 test: 5,000 particles, 1 frame\n\n\u2022 simdev: 15,000 particles, 3 frames\n\n\u2022 simsmall: 35,000 particles, 5 frames\n\n\u2022 simmedium: 100,000 particles, 5 frames\n\n\u2022 simlarge: 300,000 particles, 5 frames\n\n\u2022 native: 500,000 particles, 500 frames\n\n\nfreqmine\n\nThe freqmine application employs an array-based version of the FP-growth (Frequent Pattern-growth) method [15] for Frequent Itemset Mining (FIMI). It is an Intel RMS benchmark which was originally developed by Concordia University. FIMI is the basis of Association Rule Mining (ARM), a very common data mining problem which is relevant for areas such as protein sequences, market data or log analysis. The serial program this benchmark is based on won the FIMI'03 best implementation award for its efficiency. freqmine was included in the PARSEC benchmark suite because of the increasing demand for data mining techniques which is driven by the rapid growth of the volume of stored information.\n\nFP-growth stores all relevant frequency information of the transaction database in a compact data structure called FPtree (Frequent Pattern-tree) [16]. An FP-tree is composed of three parts: First, a prefix tree encodes the transaction data such that each branch represents a frequent itemset. The nodes along the branches are stored in decreasing order of frequency of the corresponding item. The prefix tree is a more compact representation of the transaction database because overlapping itemsets share prefixes of the corresponding branches. The second component of the FP-tree is a header table which stores the number of occurrences of each item in decreasing order of frequency. Each entry is also associated with a pointer to a node of the FP-tree. All nodes which are associated with the same item are linked to a list. The list can be traversed by looking up the corresponding item in the header table and following the links to the end. Each node furthermore contains a counter that encodes how often the represented itemset as seen from the root to the current node occurs in the transaction database. The third component of the FP-tree is a lookup table which stores the frequencies of all 2-itemsets. A row in the lookup table gives all occurrences of items in itemsets which end with the associated item. This information can be used during the mining phase to omit certain FP-tree scans and is the major improvement of the implemented algorithm. The lookup table is especially effective if the dataset is sparse which is usually the case. The FP-trees are then very big due to the fact that only few prefixes are shared. In that case tree traversals are more expensive, and the benefit from being able to omit them is greater. The initial FP-tree can be constructed with only two scans of the original database, the first one to construct the header table and the second one to compute the remaining parts of the FP-tree.\n\nIn order to mine the data for frequent itemsets, the FPgrowth method traverses the FP-tree data structure and recursively constructs new FP-trees until the complete set of frequent itemsets is generated. To construct a new FP-tree T X\u222a{i} for an item i in the header of an existing FP-tree TX , the algorithm first obtains a new pattern base from the lookup table. The base is used to initialize the header of the new tree T X\u222a{i} . Starting from item i in the header table of the existing FP-tree TX , the algorithm then traverses the associated linked list of all item occurrences. The patterns associated with the visited branches are then inserted into the new FP-tree T X\u222a{i} . The resulting FP-tree is less bushy because it was constructed from fewer itemsets. The recursion terminates when an FP-tree was built which has only one path. The properties of the algorithm guarantee that this is a frequent itemset.\n\nfreqmine has been parallelized with OpenMP. It employs three parallel kernels:\n\nBuild FP-tree header This kernel scans the transaction database and counts the number of occurrences of each item. It performs the first of two database scans necessary to construct the FP-tree. The result of this operation is the header table for the FP-tree which contains the item frequency information. This kernel has one parallelized loop and is implemented in function scan1 DB.\n\nConstruct prefix tree The next kernel builds the initial tree structure of the FP-tree. It performs the second and final scan of the transaction database necessary to build the data structures which will be used for the actual mining operation. The kernel has four parallelized loops. It is implemented in function scan2 DB which contains two of them. The remaining two loops are in its helper function database tiling.\n\nMine data The last kernel uses the data structures previously computed and mines them to recursively obtain the frequent itemset information. It is an improved version of the conventional FP-growth method [16]. This module has similarities with the previous two kernels which construct the initial FP-tree because it builds a new FP-tree for every recursion step.\n\nThe module is implemented in function FP growth first. It first derives the initial lookup table from the current FP-tree by calling first transform FPTree into FP-Array. This function executes the first of two parallelized loops. After that the second parallelized loop is executed in which the recursive function FP growth is called. It is the equivalent of FP growth first. Each thread calls FP growth independently so that a number of recursions up to the number of threads can be active.\n\nThe input sets for freqmine are defined as follows:\n\n\u2022 test: Database with 3 synthetic transactions, minimum support 1.\n\n\u2022 simdev: Database with 1,000 synthetic transactions, minimum support 3.\n\n\u2022 simsmall: Database with 250,000 anonymized click streams from a Hungarian online news portal, minimum support 220.\n\n\u2022 simmedium: Same as simsmall but with 500,000 click streams, minimum support 410.\n\n\u2022 simlarge: Same as simsmall but with 990,000 click streams, minimum support 790.\n\n\u2022 native: Database composed of spidered collection of 250,000 web html documents [26], minimum support 11,000.\n\n\nstreamcluster\n\nThis RMS kernel was developed by Princeton University and solves the online clustering problem [34]: For a stream of input points, it finds a predetermined number of medians so that each point is assigned to its nearest center. The quality of the clustering is measured by the sum of squared distances (SSQ) metric. Stream clustering is a common operation where large amounts or continuously produced data has to be organized under realtime conditions, for example network intrusion detection, pattern recognition and data mining. The program spends most of its time evaluating the gain of opening a new center. This operation uses a parallelization scheme which employs static partitioning of data points. The program is memory bound for low-dimensional data and becomes increasingly computationally intensive as the dimensionality increases. Due to its online character the working set size of the algorithm can be chosen independently from the input data. streamcluster was included in the PARSEC benchmark suite because of the importance of data mining algorithms and the prevalence of problems with streaming characteristics.\n\nThe parallel gain computation is implemented in function pgain. Given a preliminary solution, the function computes how much cost can be saved by opening a new center. For every new point, it weighs the cost of making it a new center and reassigning some of the existing points to it against the savings caused by minimizing the distance d(x, y) = |x \u2212 y| 2 between two points x and y for all points. The distance computation is implemented in function dist. If the heuristic determines that the change would be advantagous the results are committed.\n\nThe amount of parallelism and the working set size of a problem are dominated by the block size. The input sets of swaptions are defined as follows:\n\n\u2022 test: 10 input points, block size 10 points, 1 point dimension, 2-5 centers, up to 5 intermediate centers allowed \n\n\nswaptions\n\nThe swaptions application is an Intel RMS workload which uses the Heath-Jarrow-Morton (HJM) framework to price a portfolio of swaptions. The HJM framework describes how interest rates evolve for risk management and asset liability management [17] for a class of models. Its central insight is that there is an explicit relationship between the drift and volatility parameters of the forward-rate dynamics in a noarbitrage market. Because HJM models are non-Markovian the analytic approach of solving the PDE to price a derivative cannot be used. Swaptions therefore employs Monte Carlo (MC) simulation to compute the prices. The workload was included in the benchmark suite because of the significance of PDEs and the wide use of Monte Carlo simulation.\n\nThe program stores the portfolio in the swaptions array.\n\nEach entry corresponds to one derivative. Swaptions partitions the array into a number of blocks equal to the number of threads and assigns one block to every thread. Each thread iterates through all swaptions in the work unit it was assigned and calls the function HJM Swaption Blocking for every entry in order to compute the price. This function invokes HJM SimPath Forward Blocking to generate a random HJM path for each MC run. Based on the generated path the value of the swaption is computed.\n\nThe following input sets are provided for swaptions: \n\n\nvips\n\nThis application is based on the VASARI Image Processing System (VIPS) [30] which was originally developed through several projects funded by European Union (EU) grants. The benchmark version is derived from a print on demand service that is offered at the National Gallery of London, which is also the current maintainer of the system. The benchmark includes fundamental image operations such as an affine transformation and a convolution. It was chosen because image transformations are a common task on desktop computers and for the ability of the VASARI system to construct multi-threaded image processing pipelines transparently on the fly. Future libraries might use concepts such as the ones employed by VIPS to make multi-threaded functionality available to the user.\n\nThe image transformation pipeline of the vips benchmark has 18 stages. It is implemented in the VIPS operation im benchmark. The stages can be grouped into the following kernels:\n\nCrop The first step of the pipeline is to remove 100 pixels from all edges with VIPS operation im extract area.\n\nShrink Next, vips shrinks the image by 10%. This affine transformation is implemented as the matrix operation 0.5x |x| \u2264 2.5 1.5x + 2.5 x < \u22122.5 1.5x \u2212 2.5 x > 2. 5 and added back to the original image to obtain the sharpened image. Sharpening is implemented in VIPS operation im sharpen.\nf ( x) =\nThe VASARI Image Processing System fuses all image operations to construct an image transformation pipeline that can operate on subsets of an image. VIPS can automatically replicate the image transformation pipeline in order to process multiple image regions concurrently. This happens transparently for the user of the library. Actual image processing and any I/O is deferred as long as possible. Intermediate results are represented in an abstract way by partial image descriptors. Each VIPS operation can specify a demand hint which is evaluated to determine the work unit size of the combined pipeline. VIPS uses memory-mapped I/O to load parts of an input image on demand. After the requested part of a file has been loaded, all image operations are applied to the image region before the output region is written back to disk.\n\nA VIPS operation is composed of the main function which provides the public interface employed by the users, the generate function which implements the actual image operation, as well as a start and a stop function. The main functions register the operation with the VIPS evaluation system. Start functions are called by the runtime system to perform any per-thread initialization. They produce a sequence value which is passed to all generate functions and the stop function. Stop functions handle the shutdown at the end of the evaluation phase and destroy the sequence value. The VIPS system guarantees the mutually exclusive execution of start and stop functions, which can thus be used to communicate between threads during the pipeline initialization or shutdown phase. The generate functions transform the image and correspond to the pipeline stages.\n\nThe sizes of the images used for the input sets for vips are: \n\n\nx264\n\nThe x264 application is an H.264/AVC (Advanced Video Coding) video encoder. In the 4th annual video codec comparison [41] it was ranked 2nd best codec for its high encoding quality. It is based on the ITU-T H.264 standard which was completed in May 2003 and which is now also part of ISO/IEC MPEG-4. In that context the standard is also known as MPEG-4 Part 10. H.264 describes the lossy compression of a video stream [43]. It improves over previous video encoding standards with new features such as increased sample bit depth precision, higher-resolution color information, variable block-size motion compensation (VB-SMC) or context-adaptive binary arithmetic coding (CABAC). These advancements allow H.264 encoders to achieve a higher output quality with a lower bitrate at the expense of a significantly increased encoding and decoding time. The flexibility of H.264 allows its use in a wide range of contexts with different requirements, from video conferencing solutions to high-definition (HD) movie distribution. Nextgeneration HD DVD or Blu-ray video players already require H.264/AVC encoding. The flexibility and wide range of application of the H.264 standard and its ubiquity in nextgeneration video systems are the reasons for the inclusion of x264 in the PARSEC benchmark suite.\n\nH.264 encoders and decoders operate on macroblocks of pixels which have the fixed size of 16 \u00d7 16 pixels. Various techniques are used to detect and eliminate data redundancy. The most important one is motion compensation. It is employed to exploit temporal redundancy between successive frames. Motion compensation is usually the most expensive operation that has to be executed to encode a frame. It has a very high impact on the final compression ratio. The compressed output frames can be encoded in one of three possible ways:\n\nI-Frame An I-Frame includes the entire image and does not depend on other frames. All its macroblocks are encoded using intra prediction. In intra mode, a prediction block is formed using previously encoded blocks. This prediction block is subtracted from the current block prior to encoding.\n\n\nP-Frame\n\nThese frames include only the changed parts of an image from the previous I-or P-frame. A P-Frame is encoded with intra prediction and inter prediction with at most one motion-compensated prediction signal per prediction block. The prediction model is formed by shifting samples from previously encoded frames to compensate for motion such as camera pans.\n\nB-Frame B-Frames are constructed using data from the previous and next I-or P-Frame. They are encoded like a P-frame but using inter prediction with two motion-compensated prediction signals. B-Frames can be compressed much more than other frame types.\n\nThe enhanced inter and intra prediction techniques of H.264 are the main factors for its improved coding efficiency. The prediction schemes can operate on block of varying size and shapes which can be as small as 4 \u00d7 4 pixels.\n\nThe parallel algorithm of x264 uses the pipeline model with one stage per input video frame. This results in a virtual pipeline with as many stages as there are input frames. x264 processes a number of pipeline stages equal to the number of encoder threads in parallel, resulting in a sliding window which moves from the beginning of the pipeline to its end. For P-and B-Frames the encoder requires the image data and motion vectors from the relevant region of the reference frames in order to encode the current frame, and so each stage makes this information available as it is calculated during the encoding process. Fast upward movements can thus cause delays which can limit the achievable speedup of x264 in practice. In order to compensate for this effect, the parallelization model requires that x264 is executed with a number of threads greater than the number of cores to achieve maximum performance.\n\nx264 calls function x264 encoder encode to encode another frame. x264 encoder encode uses function x264 slicetypedecide to determine as which type the frame will be encoded and calls all necessary functions to produce the correct output. It also manages the threading functionality of x264. Threads use the functions x264 frame cond broadcast and x264 frame cond wait to inform each other of the encoding progress and to make sure that no data is accessed while it is not yet available.\n\nThe videos used for the input sets have been derived from the uncompressed version of the short film \"Elephants Dream\"[3]. The number of frames determines the amount of parallelism. The exact characteristics of the input sets are: \n\n\nMETHODOLOGY\n\nIn this section we explain how we characterized the PAR-SEC benchmark suite. We are interested in the following characteristics:\n\nParallelization PARSEC benchmarks use different parallel models which have to be analyzed in order to know whether the programs can scale well enough for the analysis of CMPs of a certain size.\n\nWorking sets and locality Knowledge of the cache requirements of a workload are necessary to identify benchmarks suitable for the study of CMP memory hierarchies.\n\nCommunication to computation ratio and sharing The communication patterns of a program determine the potential impact of private caches and the on-chip network on performance.\n\nOff-chip traffic The off-chip traffic requirements of a program are important to understand how off-chip bandwidth limitations of a CMP can affect performance.\n\nIn order to characterize all applications, we had to make several tradeoff decisions. Given a limited amount of computational resources, higher accuracy comes at the expense of a lower number of experiments. We followed the approach of similar studies [44,22] and chose faster but less accurate execution-driven simulation to characterize the PAR-SEC workloads. This approach is feasible because we limit ourselves to study fundamental program properties which should have a high degree of independence from architectural details. Where possible we supply measurement results from real machines. This methodology made it possible to gather the large amount of data which we present in this study. We preferred machine models comparable to real processors over unrealistic models which might have been a better match for the program needs.\n\n\nExperimental Setup\n\nWe used CMP$im [22] for our workload characterization. CMP$im is a plugin for Pin[2] that simulates the cache hierarchy of a CMP. Pin is similar to the ATOM toolkit for Compaq's Tru64 Unix on Alpha processors. It uses dynamic binary instrumentation to insert routines at arbitrary points in the instruction stream. For the characterization we simulate a single-level cache hierarchy of a CMP and vary its parameters. The baseline cache configuration was a shared 4-way associative cache with 4 MB capacity and 64 byte lines. By default the workloads used 8 cores. All experiments were conducted on a set of Symmetric Multiprocessor (SMP) machines with x86 processsors and Linux. The programs were compiled with gcc 4.2.1.\n\nBecause of the large computational cost we could not perform simulations with the native input set, instead we used the simlarge inputs for all simulations and analytically describe any differences between the two sets of which we know.\n\n\nMethodological Limitations and Error Margins\n\nFor their characterization of the SPLASH-2 benchmark suite, Woo et al. fixed a timing model which they used for all experiments [44]. They give two reasons: First, non-deterministic programs would otherwise be difficult to compare because different execution paths could be taken, and second, the characteristics they study are largely independent from an architecture. They also state that they believe that the timing model should have only a small impact on the results. While we use similar characteristics and share this belief, we think a characterization study of multi-threaded programs should nevertheless analyze the impact of nondeterminism on the reported data. Furthermore, because our methodology is based on execution on real machines combined with dynamic binary instrumentation, it can introduce additional latencies, and a potential concern is that the non-deterministic thread schedule is altered in a way that might affect our results in unpredictable ways. We therefore conducted a sensitivity analysis to quantify the impact of non-determinism.\n\nAlameldeen and Wood studied the variability of non-deterministic programs in more detail and showed that even small pseudorandom perturbations of memory latencies are effective to force alternate execution paths [5]. We adopted their approach and modified CMP$im to add extra delays to its analysis functions. Because running all experiments multiple times as Alameldeen and Wood did would be prohibitively expensive, we instead decided to randomly select a subset of all experiments for each metric which we use and report its error margins.\n\nThe measured quantities deviated by no more than \u00b10.04% from the average, with the following two exceptions. The first excpetion is metrics of data sharing. In two cases (bodytrack and swaptions) the classification is noticeably affected by the non-determinism of the program. This is partially caused because shared and thread-private data contend aggressively for a limited amount of cache capacity. The high frequency of evictions made it difficult to classify lines and accesses as shared or private. In these cases, the maximum deviation of the number of accesses from the average was as high as \u00b14.71%, and the amount of sharing deviated by as much as \u00b115.22%. We considered this uncertainty in our study and did not draw any conclusions where the variation of the measurements did not allow it. The second case of high variability is when the value of the measured quantity is very low (below 0.1% miss rate or corresponding ratio). In these cases the non-deterministic noise made measurements difficult. We do not consider this a problem because in this study we focucs on trends of ratios, and quantities that small do not have a noticeable impact. It is however an issue for the analysis of working sets if the miss rate falls below this threshold and continues to decrease slowly. Only few programs are affected, and our estimate of ther working set sizes might be slightly off in these cases. This is primarily an issue inherent to experimental working set analysis, since it requires well-defined points of inflection for conclusive results. Moreover, we believe that in these cases the working set size varies non-deterministically, and researchers should expect slight variations for each benchmark run.\n\nThe implications of these results are twofold: First, they show that our methodology is not susceptible to the nondeterministic effects of multi-threaded programs in a way that might invalidate our findings. Second, they also confirm that the metrics which we present in this paper are fundamental program properties which cannot be distorted easily. The reported application characteristics are likely to be preserved on a large range of architectures.\n\n\nPARALLELIZATION\n\nIn this section we discuss the parallelization of the PAR-SEC suite. As we will see in Section 6, several PARSEC benchmarks (canneal, dedup, ferret and freqmine) have working sets so large they should be considered unbounded for an analysis. These working sets are only limited by the amount of main memory in practice and they are actively used for inter-thread communication. The inability to use caches efficiently is a fundamental property of these program and affects their concurrent behavior. Furthermore, dedup and ferret use a complex, heterogeneous parallelization model in which specialized threads execute different functions with different characteristics at the same time. These programs employ a pipeline with dedicated thread pools for each parallelized pipeline stage. Each thread pool  has enough threads to occupy the whole CMP, and it is the responsibility of the scheduler to assign cores to threads in a manner that maximizes the overall throughput of the pipeline. Over time, the number of threads active for each stage will converge against the inverse throughput ratios of the individual pipeline stages relative to each other.\n\nWoo et al. use an abstract machine model with a uniform instruction latency of one cycle to measure the speedups of the SPLASH-2 programs [44]. They justify their approach by pointing out that the impact of the timing model on the characteristics which they measure -including speedup -is likely to be low. Unfortunately, this is not true in general for PARSEC workloads. While we have verified in Section 4.2 that the fundamental program properties such as miss rate and instruction count are largely not susceptible to timing shocks, the synchronization and timing behavior of the programs is. Using a timing model with perfect caches significantly alters the behavior of programs with unbounded working sets, for example how long locks to large, shared data structures are held. Moreover, any changes of the timing model have a strong impact on the number of active threads of programs which employ thread specialization. It will thus affect the load balance and synchronization behavior of these workloads. We believe it is not possible to discuss the timing behavior of these programs without also considering for example different schedulers, which is beyond the scope of this paper. Similar dependencies of commercial workloads on their environment are already known [9,4].\n\nUnlike Woo et al. who measured actual concurrency on an abstract machine, we therefore decided to analyze inherent concurrency and its limitations. Our approach is based on the number of executed instructions in parallel and serial regions of the code. We neglect any delays due to blocking on contended locks and load imbalance. This methodology is feasible because we do not study performance, our interest is in fundamental program characteristics. The presented data is largely timing-independent and a suitable measure of the concurrency inherent in a workload. The results in Figure 1 show the maximum achievable speedup measured that way. The numbers account for limitations such as unparallelized code sections, synchronization overhead and redundant computations. PARSEC workloads can achieve actual speedups close to the presented numbers. We verified on a large range of architectures that lock contention and other timing-dependent factors are not limiting factors, but we know of no way to show it in a platform-independent way given the complications outlined above. The maximum speedup of bodytrack, x264 and streamcluster is limited by serial sections of the code. fluidanimate is primarily limited by growing parallelization overhead. On real machines, x264 is furthermore bound by a data dependency between threads, however this has only a noticeable impact on machines larger than the ones described here. It is recommended to run x264 with more threads than cores, since modeling and exposing these dependencies to the scheduler is a fundamental aspect of its parallel algorithm, comparable to the parallel algorithms of dedup and ferret. Figure 2 shows the slowdown of the parallel version on 1 core over the serial version. The numbers show that all workloads use efficient parallel algorithms which are not substantially slower than the corresponding serial algorithms.\n\nPARSEC programs scale well enough to study CMPs. We believe they are also useful on machines larger than the ones analyzed here. The PARSEC suite exhibits a wider variety of parallelization models than previous benchmark suites such as the pipeline model. Some of its workloads can adapt to different timing models and can use threads to hide latencies. It is important to analyze these programs in the context of the whole system.\n\n\nWORKING SETS AND LOCALITY\n\nThe temporal locality of a program can be estimated by analyzing how the miss rate of a processor's cache changes as its capacity is varied. Often the miss rate does not decrease continuously as the size of a cache is increased, but stays on a certain level and then makes a sudden jump to a lower level when the capacity becomes large enough to hold the next important data structure. For CMPs an efficient functioning of the last cache level on the chip is crucial because a miss in the last level will require an access to off-chip memory.\n\nTo analyze the working sets of the PARSEC workloads we studied a cache shared by all processors. Our results are presented in Figure 3. In Table 3 we summarize the important characteristics of the identified working sets. Most workloads exhibit well-defined working sets with clearly identifiable points of inflection. Compared to SPLASH-2, PARSEC working sets are significantly larger and can reach hundreds of megabytes such as in the cases of canneal and freqmine.\n\nTwo types of workloads can be distinguished: The first group contains benchmarks such as bodytrack and swaptions which have working sets no larger than 16 MB. These workloads have a limited need for caches with a bigger capacity, and the latest generation of CMPs often already has caches sufficiently large to accommodate most of their working sets. The second group of workloads is composed of the benchmarks canneal, ferret, facesim, fluidanimate and freqmine. These programs have very large working sets of sizes 65 MB and more, and even with a relatively con-strained input set such as simlarge, their working sets can reach hundreds of megabytes. Moreover, the need of those workloads for cache capacity is nearly insatiable and grows with the amount of data which they process. In Table 3 we give our estimates for the largest working set of each PAR-SEC workload for the native input set. In several cases they are significantly larger and can even reach gigabytes. These large working sets are often the consequence of an algorithm that operates on large amounts of collected input data. ferret for example keeps a data base of feature vectors of images in memory to find the images most similar to a given query image. The cache and memory needs of these applications should be considered unbounded, as they become more useful to their users if they can work with increased amounts of data. Programs with unbounded working sets are canneal, dedup, ferret and freqmine.\n\nIn Figure 4 we present our analysis of the spatial locality of the PARSEC workloads. The data shows how the miss rate of a shared cache changes with line size. All programs benefit from larger cache lines, but to different extents. facesim, fluidanimate and streamcluster show the greatest improvement as the line size is increased, up to the the maximum value of 256 bytes which we used. These programs have streaming behavior, and an increased line size has a prefetching effect which these workloads can take advantage of. facesim for example spends most of its time updating the position-based state of the model, for which it employs an iterative Newton-Raphson algorithm. The algorithm iterates over the elements of a sparse matrix which is stored in two one-dimensional arrays, resulting in a streaming behavior. All other programs also show good improvement of the miss rate with larger cache lines, but only up to line sizes of about 128 bytes. The miss rate is not substantially reduced with larger lines. This is due to a limited size of the basic data structures employed by the programs. They represent independent logical units, each of which is intensely worked with during a computational phase. For example, x264 operates on macroblocks of 8 \u00d7 8 pixels at a time, which limits the sizes of the used data structures. Processing a macroblock is computationally intensive and largely independent from other macroblocks. Consequently, the amount of spatial locality is bounded in these cases.\n\nFor the rest of our analysis we chose a cache capacity of 4 MB for all experiments. We could have used a matching cache size for each workload, but that would have made comparisons very difficult, and the use of very small or very large cache sizes is not realistic. Moreover, in the case of the workloads with an unbounded working set size, a working set which completely fits into a cache would be an artifact of the limited simulation input size and would not reflect realistic program behavior.  case it is also modified during the parallel phase. In Figure 5 we show how the line size affects sharing. The data combines the effects of false sharing and the access pattern of the program due to constrained cache capacity. In Figure 6, we analyze how the program uses its data. The chart shows what data is accessed and how intensely it is used. The information is broken down in two orthogonal ways, resulting in four possible types of accesses: Read and write accesses and accesses to thread-private and shared data. Additionaly, we give nubers for true shared accesses. An access is a true access if the last reference to that line came from another thread. True sharing does not count repeated accesses by the same thread. It is a useful metric to estimate the requirements for the cache coherence mechanism of a CMP: A true shared write can trigger a coherence invalidate or update, and a true shared read might require the replication of data. All programs exhibit very few true shared writes. Cache misses are not included in Figure 6, we analyze them separately when we discuss off-chip traffic in Section 8.\n\n\nCOMMUNICATION-TO-COMPUTATION RATIO AND SHARING\n\nFour programs (canneal, facesim, fluidanimate and streamcluster) showed only trivial amounts of sharing. They have therefore not been included in Figure 5. In the case of canneal, this is a results of the small cache capacity. Most of its large working set is shared and actively worked with by all threads. However, only a minuscule fraction of it fits into the cache, and the probability that a line is accessed by more than one thread before it gets replaced is very small in practice. With a 256 MB cache, 58% of its cached data is shared. blackscholes shows a substantial amount of sharing, but almost all its shared data is only accessed by two threads. This is a side-effect of the parallelization model: At the beginning of the program, the boss threads initializes the portfolio data before it spawns worker threads which process parts of it in a data-parallel way. As such, the entire portfolio is shared between the boss thread and its workers, but  Figure 6: Traffic from cache in bytes per instruction for 1 to 16 cores. Data assumes a shared 4-way associative cache with 64 byte lines. Results are broken down in accesses to private and shared data. True accesses do not count repeated accesses from the same thread.\n\nthe worker threads can process the options independently from each other and do not have to communicate with each other. ferret shows a modest amount of data sharing. Like the sharing behavior of canneal, this is caused by severely constrained cache capacity. ferret uses a database that is scanned by all threads to find entries similar to the query image. However, the size of the database is practically unbounded, and because threads do not coordinate their scans with each other it is unlikely that a cache line gets accessed more than once. bodytrack and freqmine exhibit substantial amounts of sharing due to the fact that threads process the same data. The strong increase of sharing of freqmine is caused by false sharing, as the program uses an arraybased tree as its main data structure. Larger cache lines will contain more nodes, increasing the chance that the line is accessed by multiple threads. vips has some shared data which is mostly used by only two threads. This is also predominantly an effect of false sharing since image data is stored in a consecutive array which is processed in a dataparallel way by threads. x264 uses significant amounts of shared data, most of which is only accessed by a low number of threads. This data is the reference frames, since a thread needs this information from other stages in order to encode the frame it was assigned. Similarly, the large amount of shared data of dedup is the input which is passed from stage to stage.\n\nMost PARSEC workloads use a significant amount of communication, and in many cases the volume of traffic between threads can be so high that efficient data exchange via a shared cache is severely constrained by its capacity. An example for this is x264. Figure 6 shows a large amount of writes to shared data, but contrary to intuition its share diminishes rapidly as the number of cores is increased. This effect is caused by a growth of the working sets of x264: Table3 shows that both working set WS1 and WS2 grow proportional to the number of cores. WS1 is mostly composed of thread-private data and is the one which is used more intensely. WS2 contains the reference frames and is used for inter-thread communication. As WS1 grows, it starts to displace WS2, and the threads are forced to communicate via main memory. Two more programs which communicate intensely are dedup and ferret. Both programs use the pipeline parallelization model with dedicated thread pools for each parallel stage, and all data has to be passed from stage to stage. fluidanimate also shows a large amount of inter-thread communication, and its communication needs grow as the number of threads increase. This is caused by the spatial partitioning that fluidanimate uses to distribute the work to threads. Smaller partitions mean a worse surface to volume ratio, and communication grows with the surface.\n\nOverall, most PARSEC workloads have complex sharing patterns and communicate actively. Pipelined programs can require a large amount of bandwidth between cores in order to communicate efficiently. Shared caches with insufficient capacity can limit the communication efficiency of workloads, since shared data structures might get displaced to memory.\n\n\nOFF-CHIP TRAFFIC\n\nIn this section we analyze what the off-chip bandwidth requirements of PARSEC workloads are. Our goal is to understand how the traffic of an application grows as the number of cores of a CMP increases and how the memory wall will limit performance. We again simulated a shared cache and analyze how traffic develops as the number of cores increases. Our results are presented in Figure 7.\n\nThe data shows that the off-chip bandwidth requirements of blackscholes are small enough so that memory bandwidth is unlikely to be an issue. bodytrack, dedup, fluidanimate, freqmine, swaptions and x264 are more demanding. Moreover, these programs exhibit a growing bandwidth demand per instruction as the number of cores increases. In the case of bodytrack, most off-chip traffic happens in short, intense bursts since the off-chip communication predominantly  Figure 7: Breakdown of off-chip traffic into bytes for loads, stores and writebacks per instructions. Results are shown for 1 to 16 cores. Data assumes a 4-way associative 4 MB cache with 64 byte lines, allocate-on-store and writeback policy.\n\ntakes place during the edge map computation. This phase is only a small part of the serial runtime, but on machines with constrained memory bandwidth it quickly becomes the limiting factor for scalability. The last group of programs is composed of canneal, facesim, ferret, streamcluster and vips. These programs have very high bandwidth requirements and also large working sets. canneal shows a decreasing demand for data per instruction with more cores. This behavior is caused by improved data sharing.\n\nIt is important to point out that these numbers do not take the increasing instruction throughput of a CMP into account as its number of cores grows. A constant traffic amount in Figure 7 means that the bandwidth requirements of an application which scales linearly will grow exponentially. Since many PARSEC workloads have high bandwidth requirements and working sets which exceed conventional caches by far, off-chip bandwidth will be their most severe limitation of performance. Substantial architectural improvements are necessary to allow emerging workloads to take full advantage of larger CMPs.\n\n\nCONCLUSIONS\n\nThe PARSEC benchmark suite is designed to provide parallel programs for the study for CMPs. It focuses on emerging desktop and server applications and does not have the limitations of other benchmark suites. It is diverse enough to be considered representative, it is not skewed towards HPC programs, it uses state-of-art algorithms and it supports research. In this study we characterized the PARSEC workloads to provide the basic understanding necessary to allow other researchers the effective use of PARSEC for their studies. We analyzed the parallelization, the working sets and locality, the communication-to-computation ratio and the off-chip traffic of its workloads. The high cost of microarchitectural simulation forced us to use smaller machine and problem sizes than we would really like to evaluate.\n\nOur analysis shows that current CMPs are not sufficiently prepared for the demands of future applications. Many architectural problems still have to be solved to create microprocessors which are ready for the next generation of workloads. Large working sets and high off-chip bandwidth demands might limit the scalability of future programs. PAR-SEC can be used to drive research efforts by application demands.\n\n2 .\n2Every time step t the filter makes an annealing run through all M annealing layers, starting with layer m = M . 3. Each layer m uses a set of N unweighted particles which are the result of the previous filter update step to begin with.\n\n\nm )...(s (N ) t,m , \u03c0 (N ) t,m )}.\n\n\noperation im affine. The transformation uses bilinear interpolation to compute the output values. Adjust white point and shadows To improve the perceived visual quality of the image under the expected target conditions, vips brightens the image, adjusts the white point and pulls the shadows down. These operations require several linear transformations and a matrix multiplication, which are implemented in im lintra, im lintra vec and im recomb. Sharpen The last step slightly exaggerates the edges of the output image in order to compensate for the blurring caused by printing and to give the image a better overall appearance. This convolution employs a gaussian blur filter with mask radius 11 and a subtraction in order to isolate the high-frequency signal component of the image. The intermediate result is transformed via a look-up table shaped as\n\nFigure 1 :\n1Upper bound for speedup of PARSEC workloads with input set simlarge based on instruction count. Limitations are caused by serial sections, growing parallelization overhead and redundant computations.\n\nFigure 2 :\n2Parallelization overhead of PARSEC benchmarks. The chart shows the slowdown of the parallel version on 1 core over the serial version.\n\nFigure 5 :\n5Portion of a 4-way associative cache with 4 MB capacity which is shared. The line size is varied from 8 to 256 bytes. Data assumes 8 cores and is broken down to show the number of threads sharing the lines.\n\nTable 2 :\n2Breakdown of instructions and synchronization primitives for input set simlarge on a system with 8 cores. All numbers are totals across all threads. Numbers for synchronization primitives also include primitives in system libraries. 'Locks' and 'Barriers' are all lock-resp. barrier-based synchronizations, 'Conditions' are all waits on condition variables. enabled at compile time it also compares the result with the reference price.The input sets for blackscholes are sized as follows:\u2022 test: 1 option\u2022 simdev: 16 options \u2022 simsmall: 4,096 options \u2022 simmedium: 16,384 options \u2022 simlarge: 65,536 options \u2022 native: 10,000,000 options\n\n\n\u2022 simdev: 1.1 MB \u2022 simsmall: 10 MB \u2022 simmedium: 31 MB \u2022 simlarge: 184 MB\u2022 native: 672 MB \n\n\n\n\n\u2022 test: 256 \u00d7 288 pixels\u2022 simdev: 256 \u00d7 288 pixels \u2022 simsmall: 1, 600 \u00d7 1, 200 pixels \u2022 simmedium: 2, 336 \u00d7 2, 336 pixels \u2022 simlarge: 2, 662 \u00d7 5, 500 pixels \u2022 native: 18, 000 \u00d7 18, 000 pixels\n\n\nIn this section we discuss how PARSEC workloads use caches to communicate. Most PARSEC benchmarks share data intensely. Two degrees of sharing can be distinguished: Shared data can be read-only during the parallel phase, in which case it is only used for lookups and analysis. Input data is frequently used in such a way. But shared data can also be used for communication between threads, in which0.00% \n\n5.00% \n\n10.00% \n\n15.00% \n\n20.00% \n\n25.00% \n\n30.00% \n\n35.00% \n\n40.00% \n\n45.00% \n\n50.00% \n\n55.00% \n\n>8 Sharers \n\n8 Sharers \n\n7 Sharers \n\n6 Sharers \n\n5 Sharers \n\n4 Sharers \n\n3 Sharers \n\n2 Sharers \n\nShared Lines (%) \n\n\n\n\nTraffic (Bytes / Instr.)1 \n2 \n4 \n8 \n16 \n\n0 \n\n1 \n\n2 \n\n3 \n\n4 \n\n5 \n\n1 \n2 \n4 \n8 \n16 \n1 \n2 \n4 \n8 \n16 \n1 \n2 \n4 \n8 \n16 \n1 \n2 \n4 \n8 \n16 \n1 \n2 \n4 \n8 \n16 \n1 \n2 \n4 \n8 \n16 \n1 \n2 \n4 \n8 \n16 \n1 \n2 \n4 \n8 \n16 \n1 \n2 \n4 \n8 \n16 \n1 \n2 \n4 \n8 \n16 \n1 \n2 \n4 \n8 \n16 \n\nblackscholes \nbodytrack \nfluidanimate \nfreqmine \nswaptions \n\ncanneal \ndedup \nfacesim \nferret \n\nstreamcluster \nvips \nx264 \n\nPrivate Reads \n\nPrivate Writes \n\nShared Reads \n\nShared Writes \n\nTrue Shared \nReads \n\nTrue Shared \nWrites \n\n\nPrinceton University Technical Report TR-811-08, January 2008\nACKNOWLEDGEMENTSFirst and foremost we would like to acknowledge the many authors of the PARSEC benchmark programs which are too numerous to be listed here. The institutions who contributed the most number of programs are Intel and Princeton University. Stanford University allowed us to use their code and data for facesim.We would like to acknowledge the contribution of the following individuals: Justin Rattner, Pradeep Dubey, Tim Mattson, Jim Hurley, Bob Liang, Horst Haussecker, Yemin Zhang, and Ron Fedkiw. They convinced skeptics and supported us so that a project the size of PARSEC could succeed.8  16  32  64  128  256  8  16  32  64  128  256  8  16  32  64  128  256  8  16  32  64  128  256  8  16  32  64  128  256  8  16  32  64  128  256  8  16  32  64  128  256  8  16  32  64  128  256\n. I I Mediabench, MediaBench II. http://euler.slu.edu/~fritts/mediabench/.\n\nEvaluating Non-Deterministic Multi-Threaded Commercial Workloads. A Alameldeen, C Mauer, M Xu, P Harper, M Martin, D Sorin, Proceedings of the Computer Architecture Evaluation using Commercial Workloads. the Computer Architecture Evaluation using Commercial WorkloadsA. Alameldeen, C. Mauer, M. Xu, P. Harper, M. Martin, and D. Sorin. Evaluating Non-Deterministic Multi-Threaded Commercial Workloads. In Proceedings of the Computer Architecture Evaluation using Commercial Workloads, February 2002.\n\nVariability in Architectural Simulations of Multi-threaded Workloads. A Alameldeen, D Wood, Proceedings of the 9th International Symposium on High-Performance Computer Architecture. the 9th International Symposium on High-Performance Computer ArchitectureA. Alameldeen and D. Wood. Variability in Architectural Simulations of Multi-threaded Workloads. In Proceedings of the 9th International Symposium on High-Performance Computer Architecture, February 2003.\n\nA Quantitative Evaluation of Video-based 3D Person Tracking. A Balan, L Sigal, M Black, IEEE Workshop on VS-PETS. A. Balan, L. Sigal, and M. Black. A Quantitative Evaluation of Video-based 3D Person Tracking. In IEEE Workshop on VS-PETS, pages 349-356, 2005.\n\nParallel algorithms for VLSI computer-aided design. P Banerjee, Prentice-Hall, IncUpper Saddle River, NJ, USAP. Banerjee. Parallel algorithms for VLSI computer-aided design. Prentice-Hall, Inc., Upper Saddle River, NJ, USA, 1994.\n\nA hierarchical O(N log N) force-calculation algorithm. J Barnes, P Hut, Nature. 324J. Barnes and P. Hut. A hierarchical O(N log N) force-calculation algorithm. Nature, 324:446-449, December 1986.\n\nMemory System Characterization of Commercial Workloads. L Barroso, K Gharachorloo, F Bugnion, Proceedings of the 25th International Symposium on Computer Architecture. the 25th International Symposium on Computer ArchitectureL. Barroso, K. Gharachorloo, and F. Bugnion. Memory System Characterization of Commercial Workloads. In Proceedings of the 25th International Symposium on Computer Architecture, pages 3-14, June 1998.\n\nThe Pricing of Options and Corporate Liabilities. Fischer Black, Scholes, Journal of Political Economy. 81Black, Fischer, and Scholes. The Pricing of Options and Corporate Liabilities. Journal of Political Economy, 81:637-659, 1973.\n\nCopy Detection Mechanisms for Digital Documents. S Brin, J Davis, H Garcia-Molina, Proceedings of Special Interest Group on Management of Data. Special Interest Group on Management of DataS. Brin, J. Davis, and H. Garcia-Molina. Copy Detection Mechanisms for Digital Documents. In Proceedings of Special Interest Group on Management of Data, 1995.\n\nSmoothed Particles: A new paradigm for animating highly deformable bodies. M Desbrun, M.-P Gascuel, Computer Animation and Simulation '96. M. Desbrun and M.-P. Gascuel. Smoothed Particles: A new paradigm for animating highly deformable bodies. In Computer Animation and Simulation '96, pages 61-76, August 1996.\n\nArticulated Body Motion Capture by Stochastic Search. J Deutscher, I Reid, International Journal of Computer Vision. 612J. Deutscher and I. Reid. Articulated Body Motion Capture by Stochastic Search. International Journal of Computer Vision, 61(2):185-205, February 2005.\n\nRecognition, Mining and Synthesis Moves Computers to the Era of Tera. P Dubey, Technology@Intel MagazineP. Dubey. Recognition, Mining and Synthesis Moves Computers to the Era of Tera. Technology@Intel Magazine, February 2005.\n\nEfficiently Using Prefix-trees in Mining Frequent Itemsets. G Grahne, J Zhu, G. Grahne and J. Zhu. Efficiently Using Prefix-trees in Mining Frequent Itemsets. November 2003.\n\nMining Frequent Patterns without Candidate Generation. J Han, J Pei, Y Yin, ACM SIGMOD International Conference on Management of Data. W. Chen, J. Naughton, and P. A. BernsteinACM PressJ. Han, J. Pei, and Y. Yin. Mining Frequent Patterns without Candidate Generation. In W. Chen, J. Naughton, and P. A. Bernstein, editors, 2000 ACM SIGMOD International Conference on Management of Data, pages 1-12. ACM Press, 05 2000.\n\nBond Pricing and the Term Structure of Interest Rates: A New Methodology for Contingent Claims Valuation. D Heath, R Jarrow, A Morton, Econometrica. 601D. Heath, R. Jarrow, and A. Morton. Bond Pricing and the Term Structure of Interest Rates: A New Methodology for Contingent Claims Valuation. Econometrica, 60(1):77-105, January 1992.\n\nComputer Architecture: A Quantitative Approach. J L Hennessy, D A Patterson, Morgan KaufmannJ. L. Hennessy and D. A. Patterson. Computer Architecture: A Quantitative Approach. Morgan Kaufmann, 2003.\n\nTreeSPH -A unification of SPH with the hierarchical tree method. L Hernquist, N Katz, The Astrophysical Journal Supplement Series. 70419L. Hernquist and N. Katz. TreeSPH -A unification of SPH with the hierarchical tree method. The Astrophysical Journal Supplement Series, 70:419, 1989.\n\nPhysical Simulation for Animation and Visual Effects: Parallelization and Characterization for Chip Multiprocessors. C J Hughes, R Grzeszczuk, E Sifakis, D Kim, S Kumar, A P Selle, J Chhugani, M Holliman, Y.-K Chen, SIGARCH Computer Architecture News. 352C. J. Hughes, R. Grzeszczuk, E. Sifakis, D. Kim, S. Kumar, A. P. Selle, J. Chhugani, M. Holliman, and Y.-K. Chen. Physical Simulation for Animation and Visual Effects: Parallelization and Characterization for Chip Multiprocessors. SIGARCH Computer Architecture News, 35(2):220-231, 2007.\n\nOptions, Futures, and Other Derivatives. J C Hull, Prentice HallJ. C. Hull. Options, Futures, and Other Derivatives. Prentice Hall, 2005.\n\nLast-Level Cache (LLC) Performance of Data-Mining Workloads on a CMP -A Case Study of Parallel Bioinformatics Workloads. A Jaleel, M Mattina, B Jacob, Proceedings of the 12th International Symposium on High Performance Computer Architecture. the 12th International Symposium on High Performance Computer ArchitectureA. Jaleel, M. Mattina, and B. Jacob. Last-Level Cache (LLC) Performance of Data-Mining Workloads on a CMP - A Case Study of Parallel Bioinformatics Workloads. In Proceedings of the 12th International Symposium on High Performance Computer Architecture, February 2006.\n\n. Jayaprakash Pisharath, Ying Liu, Wei-Keng Liao, Alok Choudhary, Gokhan Memik, Janaki Parhi, Center for Ultra-Scale Computing and Information Security Northwestern UniversityNU-Minebench 2.0. Technical reportJayaprakash Pisharath and Ying Liu and Wei-keng Liao and Alok Choudhary and Gokhan Memik and Janaki Parhi. NU-Minebench 2.0. Technical report, Center for Ultra-Scale Computing and Information Security Northwestern University, August 2005.\n\nEfficient Randomized Pattern-Matching Algorithms. R M Karp, M O Rabin, IBM Journal of Research and Development. 312R. M. Karp and M. O. Rabin. Efficient Randomized Pattern-Matching Algorithms. IBM Journal of Research and Development, 31(2):249-260, 1987.\n\nThe ALPBench Benchmark Suite for Complex Multimedia Applications. M.-L Li, R Sasanka, S V Adve, Y.-K Chen, E Debes, Proceedings of the 2005 International Symposium on Workload Characterization. the 2005 International Symposium on Workload CharacterizationM.-L. Li, R. Sasanka, S. V. Adve, Y.-K. Chen, and E. Debes. The ALPBench Benchmark Suite for Complex Multimedia Applications. In Proceedings of the 2005 International Symposium on Workload Characterization, October 2005.\n\nWebDocs: a real-life huge transactional dataset. C Lucchese, S Orlando, R Perego, F Silvestri, 2nd IEEE ICDM Workshop on Frequent Itemset Mining Implementations. C. Lucchese, S. Orlando, R. Perego, and F. Silvestri. WebDocs: a real-life huge transactional dataset. In 2nd IEEE ICDM Workshop on Frequent Itemset Mining Implementations 2004, November 2004.\n\nFerret: A Toolkit for Content-Based Similarity Search of Feature-Rich Data. Q Lv, W Josephson, Z Wang, M Charikar, K Li, Proceedings of the 2006 EuroSys Conference. the 2006 EuroSys ConferenceQ. Lv, W. Josephson, Z. Wang, M. Charikar, and K. Li. Ferret: A Toolkit for Content-Based Similarity Search of Feature-Rich Data. In Proceedings of the 2006 EuroSys Conference, pages 317-330, 2006.\n\nMulti-Probe LSH: Efficient Indexing for High-Dimensional Similarity Search. Q Lv, W Josephson, Z Wang, M Charikar, K Li, Proceedings of the 33rd International Conference on Very Large Data Bases. the 33rd International Conference on Very Large Data BasesQ. Lv, W. Josephson, Z. Wang, M. Charikar, and K. Li. Multi-Probe LSH: Efficient Indexing for High-Dimensional Similarity Search. In Proceedings of the 33rd International Conference on Very Large Data Bases, pages 950-961, 2007.\n\nFinding Similar Files in a Large File System. U Manber, Proceedings of the USENIX Winter. the USENIX WinterSan Fransisco, CA, USATechnical ConferenceU. Manber. Finding Similar Files in a Large File System. In Proceedings of the USENIX Winter 1994 Technical Conference, pages 1-10, San Fransisco, CA, USA, October 1994.\n\nVIPS -a highly tuned image processing software architecture. K Martinez, J Cupitt, Proceedings of the 2005 International Conference on Image Processing. the 2005 International Conference on Image Processing2K. Martinez and J. Cupitt. VIPS -a highly tuned image processing software architecture. In Proceedings of the 2005 International Conference on Image Processing, volume 2, pages 574-577, September 2005.\n\nMersenne Twister: A 623-dimensionally equidistributed uniform pseudorandom number generator. M Matsumoto, T Nishimura, In ACM Transactions on Modeling and Computer Simulation. 8M. Matsumoto and T. Nishimura. Mersenne Twister: A 623-dimensionally equidistributed uniform pseudorandom number generator. In ACM Transactions on Modeling and Computer Simulation, volume 8, pages 3-30, January 1998.\n\nParticle-Based Fluid Simulation for Interactive Applications. M M\u00fcller, D Charypar, M Gross, Proceedings of the 2003 ACM SIGGRAPH/Eurographics Symposium on Computer Animation. the 2003 ACM SIGGRAPH/Eurographics Symposium on Computer AnimationAire-la-Ville, Switzerland, SwitzerlandEurographics AssociationM. M\u00fcller, D. Charypar, and M. Gross. Particle-Based Fluid Simulation for Interactive Applications. In Proceedings of the 2003 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, pages 154-159, Aire-la-Ville, Switzerland, Switzerland, 2003. Eurographics Association.\n\nStatistical Region Merging. R Nock, F Nielsen, IEEE Transactions on Pattern Analysis and Machine Intelligence. 26R. Nock and F. Nielsen. Statistical Region Merging. IEEE Transactions on Pattern Analysis and Machine Intelligence, 26:1452-1458, 2004.\n\nHigh-Performance Clustering of Streams and Large Data Sets. L O&apos;callaghan, A Meyerson, R M N Mishra, S Guha, Proceedings of the 18th International Conference on Data Engineering. the 18th International Conference on Data EngineeringL. O'Callaghan, A. Meyerson, R. M. N. Mishra, and S. Guha. High-Performance Clustering of Streams and Large Data Sets. In Proceedings of the 18th International Conference on Data Engineering, February 2002.\n\nFluid Mechanics. D Pnueli, C Gutfinger, Cambridge University PressD. Pnueli and C. Gutfinger. Fluid Mechanics. Cambridge University Press, 1992.\n\nA New Approach to Archival Storage. S Quinlan, S D Venti, Proceedings of the USENIX Conference on File And Storage Technologies. the USENIX Conference on File And Storage TechnologiesS. Quinlan and S. D. Venti. A New Approach to Archival Storage. In Proceedings of the USENIX Conference on File And Storage Technologies, January 2002.\n\nThe Earth Mover's Distance as a Metric for Image Retrieval. Y Rubner, C Tomasi, L J Guibas, International Journal of Computer Vision. 40Y. Rubner, C. Tomasi, and L. J. Guibas. The Earth Mover's Distance as a Metric for Image Retrieval. International Journal of Computer Vision, 40:99-121, 2000.\n\nAutomatic Determination of Facial Muscle Activations from Sparse Motion Capture Marker Data. E Sifakis, I Neverov, R Fedkiw, ACM Transactions on Graphics. 243E. Sifakis, I. Neverov, and R. Fedkiw. Automatic Determination of Facial Muscle Activations from Sparse Motion Capture Marker Data. ACM Transactions on Graphics, 24(3):417-425, 2005.\n\nA Protocol-Independent Technique for Eliminating Redundant Network Traffic. N T Spring, D Wetherall, Proceedings of ACM SIGCOMM. ACM SIGCOMMN. T. Spring and D. Wetherall. A Protocol-Independent Technique for Eliminating Redundant Network Traffic. In Proceedings of ACM SIGCOMM, August 2000.\n\nRobust Quasistatic Finite Elements and Flesh Simulation. J Teran, E Sifakis, G Irving, R Fedkiw, Proceedings of the 2005 ACM SIGGRAPH/Eurographics Symposium on Computer Animation. the 2005 ACM SIGGRAPH/Eurographics Symposium on Computer AnimationNew York, NY, USAACM PressJ. Teran, E. Sifakis, G. Irving, and R. Fedkiw. Robust Quasistatic Finite Elements and Flesh Simulation. In Proceedings of the 2005 ACM SIGGRAPH/Eurographics Symposium on Computer Animation, pages 181-190, New York, NY, USA, 2005. ACM Press.\n\nMPEG-4 AVC/H.264 Video Codecs Comparison. D Vatolin, D Kulikov, A Parshin, D. Vatolin, D. Kulikov, and A. Parshin. MPEG-4 AVC/H.264 Video Codecs Comparison. http://compression.ru/video/codec_comparison/pdf/ msu_mpeg_4_avc_h264_co%dec_comparison_2007_eng.pdf, 2007.\n\n. L Verlet, Computer Experiments on Classical Fluids. I. Thermodynamical Properties of Lennard-Jones Molecules. Physical Review. 159L. Verlet. Computer Experiments on Classical Fluids. I. Thermodynamical Properties of Lennard-Jones Molecules. Physical Review, 159:98-103, 1967.\n\nOverview of the H.264/AVC Video Coding Standard. T Wiegand, G J Sullivan, G Bjontegaard, A Luthra, IEEE Transactions on Circuits and Systems for Video Technology. 13T. Wiegand, G. J. Sullivan, G. Bjontegaard, and A. Luthra. Overview of the H.264/AVC Video Coding Standard. IEEE Transactions on Circuits and Systems for Video Technology, 13(7):560-576, 2003.\n\nThe SPLASH-2 Programs: Characterization and Methodological Considerations. S C Woo, M Ohara, E Torrie, J P Singh, A Gupta, Proceedings of the 22nd International Symposium on Computer Architecture. the 22nd International Symposium on Computer ArchitectureS. C. Woo, M. Ohara, E. Torrie, J. P. Singh, and A. Gupta. The SPLASH-2 Programs: Characterization and Methodological Considerations. In Proceedings of the 22nd International Symposium on Computer Architecture, pages 24-36, June 1995.\n\nA New Parallel N-Body Gravity Solver: TPM. G Xu, The Astrophysical Journal Supplement Series. 98355G. Xu. A New Parallel N-Body Gravity Solver: TPM. The Astrophysical Journal Supplement Series, 98:355, 1995.\n\nParallAX: An Architecture for Real-Time Physics. T Y Yeh, P Faloutsos, S Patel, G Reinman, Proceedings of the 34th International Symposium on Computer Architecture. the 34th International Symposium on Computer ArchitectureT. Y. Yeh, P. Faloutsos, S. Patel, and G. Reinman. ParallAX: An Architecture for Real-Time Physics. In Proceedings of the 34th International Symposium on Computer Architecture, June 2007.\n", "annotations": {"author": "[{\"end\":133,\"start\":91},{\"end\":187,\"start\":134},{\"end\":208,\"start\":188},{\"end\":216,\"start\":209},{\"end\":219,\"start\":217},{\"end\":295,\"start\":220}]", "publisher": null, "author_last_name": "[{\"end\":107,\"start\":101},{\"end\":147,\"start\":142},{\"end\":207,\"start\":202},{\"end\":215,\"start\":213}]", "author_first_name": "[{\"end\":100,\"start\":91},{\"end\":141,\"start\":134},{\"end\":197,\"start\":188},{\"end\":201,\"start\":198},{\"end\":212,\"start\":209},{\"end\":218,\"start\":217}]", "author_affiliation": "[{\"end\":186,\"start\":149},{\"end\":294,\"start\":221}]", "title": "[{\"end\":76,\"start\":1},{\"end\":371,\"start\":296}]", "venue": null, "abstract": "[{\"end\":1264,\"start\":555}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b15\"},\"end\":1434,\"start\":1430},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":2481,\"start\":2477},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":5052,\"start\":5048},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":6315,\"start\":6311},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":7083,\"start\":7079},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":7500,\"start\":7497},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":7575,\"start\":7571},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":7918,\"start\":7914},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":9131,\"start\":9127},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":9149,\"start\":9145},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":9165,\"start\":9162},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":9184,\"start\":9180},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":9206,\"start\":9202},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":12905,\"start\":12901},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":13175,\"start\":13171},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":14250,\"start\":14246},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":14252,\"start\":14250},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":20312,\"start\":20309},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":22231,\"start\":22227},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":23621,\"start\":23617},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":23721,\"start\":23717},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":24157,\"start\":24153},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":24160,\"start\":24157},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":24652,\"start\":24648},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":29387,\"start\":29383},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":29390,\"start\":29387},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":29551,\"start\":29547},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":32706,\"start\":32702},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":33164,\"start\":33160},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":33733,\"start\":33729},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":34648,\"start\":34644},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":35477,\"start\":35473},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":36025,\"start\":36021},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":37199,\"start\":37195},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":39438,\"start\":39434},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":39891,\"start\":39887},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":41928,\"start\":41924},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":42416,\"start\":42412},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":43152,\"start\":43148},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":46957,\"start\":46953},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":48172,\"start\":48168},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":48314,\"start\":48310},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":50425,\"start\":50421},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":51630,\"start\":51626},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":52789,\"start\":52788},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":54808,\"start\":54804},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":55109,\"start\":55105},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":60388,\"start\":60384},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":60391,\"start\":60388},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":61012,\"start\":61008},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":62133,\"start\":62129},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":63284,\"start\":63281},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":67102,\"start\":67098},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":68237,\"start\":68234},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":68239,\"start\":68237}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":84427,\"start\":84186},{\"attributes\":{\"id\":\"fig_1\"},\"end\":84464,\"start\":84428},{\"attributes\":{\"id\":\"fig_2\"},\"end\":85322,\"start\":84465},{\"attributes\":{\"id\":\"fig_3\"},\"end\":85535,\"start\":85323},{\"attributes\":{\"id\":\"fig_4\"},\"end\":85683,\"start\":85536},{\"attributes\":{\"id\":\"fig_5\"},\"end\":85903,\"start\":85684},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":86550,\"start\":85904},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":86644,\"start\":86551},{\"attributes\":{\"id\":\"tab_9\",\"type\":\"table\"},\"end\":86838,\"start\":86645},{\"attributes\":{\"id\":\"tab_12\",\"type\":\"table\"},\"end\":87461,\"start\":86839},{\"attributes\":{\"id\":\"tab_13\",\"type\":\"table\"},\"end\":87936,\"start\":87462}]", "paragraph": "[{\"end\":2320,\"start\":1280},{\"end\":2984,\"start\":2322},{\"end\":3104,\"start\":2986},{\"end\":3243,\"start\":3106},{\"end\":3617,\"start\":3245},{\"end\":4130,\"start\":3619},{\"end\":4405,\"start\":4145},{\"end\":4506,\"start\":4444},{\"end\":4849,\"start\":4508},{\"end\":5273,\"start\":4851},{\"end\":6020,\"start\":5275},{\"end\":6414,\"start\":6022},{\"end\":6773,\"start\":6416},{\"end\":7008,\"start\":6818},{\"end\":8046,\"start\":7010},{\"end\":8610,\"start\":8048},{\"end\":9287,\"start\":8612},{\"end\":9788,\"start\":9318},{\"end\":9848,\"start\":9790},{\"end\":9899,\"start\":9850},{\"end\":10721,\"start\":9901},{\"end\":10900,\"start\":10723},{\"end\":10985,\"start\":10902},{\"end\":11305,\"start\":10987},{\"end\":11369,\"start\":11320},{\"end\":11446,\"start\":11371},{\"end\":11592,\"start\":11448},{\"end\":11713,\"start\":11594},{\"end\":11770,\"start\":11715},{\"end\":12628,\"start\":11772},{\"end\":12695,\"start\":12642},{\"end\":12911,\"start\":12712},{\"end\":13432,\"start\":12957},{\"end\":13775,\"start\":13434},{\"end\":14067,\"start\":13777},{\"end\":14992,\"start\":14081},{\"end\":15106,\"start\":14994},{\"end\":15162,\"start\":15108},{\"end\":15272,\"start\":15164},{\"end\":15289,\"start\":15274},{\"end\":15413,\"start\":15294},{\"end\":15618,\"start\":15437},{\"end\":15684,\"start\":15650},{\"end\":15747,\"start\":15699},{\"end\":15920,\"start\":15765},{\"end\":16002,\"start\":15988},{\"end\":16043,\"start\":16007},{\"end\":16203,\"start\":16072},{\"end\":16322,\"start\":16205},{\"end\":16474,\"start\":16324},{\"end\":16563,\"start\":16510},{\"end\":16671,\"start\":16594},{\"end\":18399,\"start\":16673},{\"end\":18838,\"start\":18401},{\"end\":19170,\"start\":18840},{\"end\":19526,\"start\":19172},{\"end\":19840,\"start\":19528},{\"end\":20040,\"start\":19842},{\"end\":20094,\"start\":20042},{\"end\":20155,\"start\":20096},{\"end\":20394,\"start\":20167},{\"end\":21057,\"start\":20396},{\"end\":22002,\"start\":21059},{\"end\":22536,\"start\":22004},{\"end\":23064,\"start\":22538},{\"end\":23114,\"start\":23066},{\"end\":23199,\"start\":23116},{\"end\":23722,\"start\":23209},{\"end\":23837,\"start\":23724},{\"end\":24482,\"start\":23839},{\"end\":24896,\"start\":24484},{\"end\":25132,\"start\":24898},{\"end\":25430,\"start\":25134},{\"end\":25502,\"start\":25432},{\"end\":26012,\"start\":25504},{\"end\":26559,\"start\":26014},{\"end\":27084,\"start\":26561},{\"end\":27506,\"start\":27086},{\"end\":27878,\"start\":27508},{\"end\":28621,\"start\":27880},{\"end\":28991,\"start\":28623},{\"end\":29103,\"start\":28993},{\"end\":29119,\"start\":29105},{\"end\":29552,\"start\":29131},{\"end\":29926,\"start\":29554},{\"end\":30240,\"start\":29928},{\"end\":30371,\"start\":30242},{\"end\":30549,\"start\":30373},{\"end\":31149,\"start\":30551},{\"end\":31468,\"start\":31151},{\"end\":31666,\"start\":31470},{\"end\":32104,\"start\":31668},{\"end\":32405,\"start\":32106},{\"end\":32758,\"start\":32407},{\"end\":32791,\"start\":32760},{\"end\":32848,\"start\":32793},{\"end\":32876,\"start\":32850},{\"end\":32905,\"start\":32878},{\"end\":32933,\"start\":32907},{\"end\":32980,\"start\":32935},{\"end\":33839,\"start\":32991},{\"end\":34432,\"start\":33841},{\"end\":35520,\"start\":34434},{\"end\":35654,\"start\":35560},{\"end\":35756,\"start\":35656},{\"end\":36219,\"start\":35758},{\"end\":36859,\"start\":36221},{\"end\":37244,\"start\":36861},{\"end\":37909,\"start\":37284},{\"end\":38525,\"start\":37946},{\"end\":38555,\"start\":38554},{\"end\":38857,\"start\":38557},{\"end\":39153,\"start\":38965},{\"end\":39475,\"start\":39216},{\"end\":39848,\"start\":39609},{\"end\":40326,\"start\":39850},{\"end\":40454,\"start\":40328},{\"end\":40874,\"start\":40456},{\"end\":41256,\"start\":40876},{\"end\":41552,\"start\":41258},{\"end\":41750,\"start\":41554},{\"end\":42002,\"start\":41752},{\"end\":42057,\"start\":42004},{\"end\":42091,\"start\":42059},{\"end\":42129,\"start\":42093},{\"end\":42169,\"start\":42131},{\"end\":42211,\"start\":42171},{\"end\":42252,\"start\":42213},{\"end\":42293,\"start\":42254},{\"end\":43000,\"start\":42306},{\"end\":44939,\"start\":43002},{\"end\":45858,\"start\":44941},{\"end\":45938,\"start\":45860},{\"end\":46325,\"start\":45940},{\"end\":46746,\"start\":46327},{\"end\":47111,\"start\":46748},{\"end\":47605,\"start\":47113},{\"end\":47658,\"start\":47607},{\"end\":47726,\"start\":47660},{\"end\":47800,\"start\":47728},{\"end\":47918,\"start\":47802},{\"end\":48002,\"start\":47920},{\"end\":48085,\"start\":48004},{\"end\":48197,\"start\":48087},{\"end\":49345,\"start\":48215},{\"end\":49897,\"start\":49347},{\"end\":50047,\"start\":49899},{\"end\":50165,\"start\":50049},{\"end\":50932,\"start\":50179},{\"end\":50990,\"start\":50934},{\"end\":51491,\"start\":50992},{\"end\":51546,\"start\":51493},{\"end\":52330,\"start\":51555},{\"end\":52510,\"start\":52332},{\"end\":52623,\"start\":52512},{\"end\":52913,\"start\":52625},{\"end\":53755,\"start\":52923},{\"end\":54614,\"start\":53757},{\"end\":54678,\"start\":54616},{\"end\":55981,\"start\":54687},{\"end\":56513,\"start\":55983},{\"end\":56807,\"start\":56515},{\"end\":57174,\"start\":56819},{\"end\":57428,\"start\":57176},{\"end\":57656,\"start\":57430},{\"end\":58568,\"start\":57658},{\"end\":59056,\"start\":58570},{\"end\":59289,\"start\":59058},{\"end\":59433,\"start\":59305},{\"end\":59628,\"start\":59435},{\"end\":59792,\"start\":59630},{\"end\":59969,\"start\":59794},{\"end\":60130,\"start\":59971},{\"end\":60970,\"start\":60132},{\"end\":61714,\"start\":60993},{\"end\":61952,\"start\":61716},{\"end\":63067,\"start\":62001},{\"end\":63611,\"start\":63069},{\"end\":65331,\"start\":63613},{\"end\":65786,\"start\":65333},{\"end\":66958,\"start\":65806},{\"end\":68240,\"start\":66960},{\"end\":70134,\"start\":68242},{\"end\":70567,\"start\":70136},{\"end\":71139,\"start\":70597},{\"end\":71608,\"start\":71141},{\"end\":73088,\"start\":71610},{\"end\":74595,\"start\":73090},{\"end\":76217,\"start\":74597},{\"end\":77498,\"start\":76268},{\"end\":78980,\"start\":77500},{\"end\":80367,\"start\":78982},{\"end\":80719,\"start\":80369},{\"end\":81128,\"start\":80740},{\"end\":81834,\"start\":81130},{\"end\":82341,\"start\":81836},{\"end\":82944,\"start\":82343},{\"end\":83772,\"start\":82960},{\"end\":84185,\"start\":83774}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":12956,\"start\":12912},{\"attributes\":{\"id\":\"formula_1\"},\"end\":15293,\"start\":15290},{\"attributes\":{\"id\":\"formula_2\"},\"end\":15649,\"start\":15619},{\"attributes\":{\"id\":\"formula_3\"},\"end\":15698,\"start\":15685},{\"attributes\":{\"id\":\"formula_4\"},\"end\":15764,\"start\":15748},{\"attributes\":{\"id\":\"formula_5\"},\"end\":15987,\"start\":15921},{\"attributes\":{\"id\":\"formula_6\"},\"end\":16006,\"start\":16003},{\"attributes\":{\"id\":\"formula_7\"},\"end\":16071,\"start\":16044},{\"attributes\":{\"id\":\"formula_8\"},\"end\":16509,\"start\":16475},{\"attributes\":{\"id\":\"formula_9\"},\"end\":16593,\"start\":16564},{\"attributes\":{\"id\":\"formula_10\"},\"end\":35559,\"start\":35521},{\"attributes\":{\"id\":\"formula_11\"},\"end\":37283,\"start\":37245},{\"attributes\":{\"id\":\"formula_12\"},\"end\":37945,\"start\":37910},{\"attributes\":{\"id\":\"formula_13\"},\"end\":38553,\"start\":38526},{\"attributes\":{\"id\":\"formula_14\"},\"end\":38964,\"start\":38858},{\"attributes\":{\"id\":\"formula_15\"},\"end\":39215,\"start\":39154},{\"attributes\":{\"id\":\"formula_16\"},\"end\":39608,\"start\":39476},{\"attributes\":{\"id\":\"formula_17\"},\"end\":52922,\"start\":52914}]", "table_ref": "[{\"end\":9596,\"start\":9589},{\"end\":10362,\"start\":10355},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":12491,\"start\":12484},{\"end\":71287,\"start\":71280},{\"end\":72405,\"start\":72398}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":1278,\"start\":1266},{\"attributes\":{\"n\":\"2.\"},\"end\":4143,\"start\":4133},{\"attributes\":{\"n\":\"2.1\"},\"end\":4442,\"start\":4408},{\"attributes\":{\"n\":\"2.2\"},\"end\":6816,\"start\":6776},{\"attributes\":{\"n\":\"3.\"},\"end\":9316,\"start\":9290},{\"attributes\":{\"n\":\"3.1\"},\"end\":11318,\"start\":11308},{\"attributes\":{\"n\":\"3.2\"},\"end\":12640,\"start\":12631},{\"attributes\":{\"n\":\"3.2.1\"},\"end\":12710,\"start\":12698},{\"attributes\":{\"n\":\"3.2.2\"},\"end\":14079,\"start\":14070},{\"attributes\":{\"n\":\"4.\"},\"end\":15435,\"start\":15416},{\"attributes\":{\"n\":\"3.2.3\"},\"end\":20165,\"start\":20158},{\"attributes\":{\"n\":\"3.2.4\"},\"end\":23207,\"start\":23202},{\"attributes\":{\"n\":\"3.2.5\"},\"end\":29129,\"start\":29122},{\"attributes\":{\"n\":\"3.2.6\"},\"end\":32989,\"start\":32983},{\"attributes\":{\"n\":\"3.2.8\"},\"end\":42304,\"start\":42296},{\"attributes\":{\"n\":\"3.2.9\"},\"end\":48213,\"start\":48200},{\"attributes\":{\"n\":\"3.2.10\"},\"end\":50177,\"start\":50168},{\"attributes\":{\"n\":\"3.2.11\"},\"end\":51553,\"start\":51549},{\"attributes\":{\"n\":\"3.2.12\"},\"end\":54685,\"start\":54681},{\"end\":56817,\"start\":56810},{\"attributes\":{\"n\":\"4.\"},\"end\":59303,\"start\":59292},{\"attributes\":{\"n\":\"4.1\"},\"end\":60991,\"start\":60973},{\"attributes\":{\"n\":\"4.2\"},\"end\":61999,\"start\":61955},{\"attributes\":{\"n\":\"5.\"},\"end\":65804,\"start\":65789},{\"attributes\":{\"n\":\"6.\"},\"end\":70595,\"start\":70570},{\"attributes\":{\"n\":\"7.\"},\"end\":76266,\"start\":76220},{\"attributes\":{\"n\":\"8.\"},\"end\":80738,\"start\":80722},{\"attributes\":{\"n\":\"9.\"},\"end\":82958,\"start\":82947},{\"end\":84190,\"start\":84187},{\"end\":85334,\"start\":85324},{\"end\":85547,\"start\":85537},{\"end\":85695,\"start\":85685},{\"end\":85914,\"start\":85905}]", "table": "[{\"end\":86644,\"start\":86625},{\"end\":87461,\"start\":87239},{\"end\":87936,\"start\":87488}]", "figure_caption": "[{\"end\":84427,\"start\":84192},{\"end\":84464,\"start\":84430},{\"end\":85322,\"start\":84467},{\"end\":85535,\"start\":85336},{\"end\":85683,\"start\":85549},{\"end\":85903,\"start\":85697},{\"end\":86550,\"start\":85916},{\"end\":86625,\"start\":86553},{\"end\":86838,\"start\":86647},{\"end\":87239,\"start\":86841},{\"end\":87488,\"start\":87464}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":68832,\"start\":68824},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":69909,\"start\":69901},{\"end\":71275,\"start\":71267},{\"end\":73101,\"start\":73093},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":75160,\"start\":75152},{\"end\":75335,\"start\":75327},{\"end\":76142,\"start\":76134},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":76422,\"start\":76414},{\"end\":77237,\"start\":77229},{\"end\":79244,\"start\":79236},{\"end\":81127,\"start\":81119},{\"end\":81600,\"start\":81592},{\"end\":82530,\"start\":82522}]", "bib_author_first_name": "[{\"end\":88806,\"start\":88805},{\"end\":88808,\"start\":88807},{\"end\":88946,\"start\":88945},{\"end\":88960,\"start\":88959},{\"end\":88969,\"start\":88968},{\"end\":88975,\"start\":88974},{\"end\":88985,\"start\":88984},{\"end\":88995,\"start\":88994},{\"end\":89450,\"start\":89449},{\"end\":89464,\"start\":89463},{\"end\":89902,\"start\":89901},{\"end\":89911,\"start\":89910},{\"end\":89920,\"start\":89919},{\"end\":90153,\"start\":90152},{\"end\":90387,\"start\":90386},{\"end\":90397,\"start\":90396},{\"end\":90585,\"start\":90584},{\"end\":90596,\"start\":90595},{\"end\":90612,\"start\":90611},{\"end\":91012,\"start\":91005},{\"end\":91239,\"start\":91238},{\"end\":91247,\"start\":91246},{\"end\":91256,\"start\":91255},{\"end\":91614,\"start\":91613},{\"end\":91628,\"start\":91624},{\"end\":91906,\"start\":91905},{\"end\":91919,\"start\":91918},{\"end\":92195,\"start\":92194},{\"end\":92412,\"start\":92411},{\"end\":92422,\"start\":92421},{\"end\":92582,\"start\":92581},{\"end\":92589,\"start\":92588},{\"end\":92596,\"start\":92595},{\"end\":93053,\"start\":93052},{\"end\":93062,\"start\":93061},{\"end\":93072,\"start\":93071},{\"end\":93332,\"start\":93331},{\"end\":93334,\"start\":93333},{\"end\":93346,\"start\":93345},{\"end\":93348,\"start\":93347},{\"end\":93549,\"start\":93548},{\"end\":93562,\"start\":93561},{\"end\":93888,\"start\":93887},{\"end\":93890,\"start\":93889},{\"end\":93900,\"start\":93899},{\"end\":93914,\"start\":93913},{\"end\":93925,\"start\":93924},{\"end\":93932,\"start\":93931},{\"end\":93941,\"start\":93940},{\"end\":93943,\"start\":93942},{\"end\":93952,\"start\":93951},{\"end\":93964,\"start\":93963},{\"end\":93979,\"start\":93975},{\"end\":94356,\"start\":94355},{\"end\":94358,\"start\":94357},{\"end\":94575,\"start\":94574},{\"end\":94585,\"start\":94584},{\"end\":94596,\"start\":94595},{\"end\":95051,\"start\":95040},{\"end\":95067,\"start\":95063},{\"end\":95081,\"start\":95073},{\"end\":95092,\"start\":95088},{\"end\":95110,\"start\":95104},{\"end\":95124,\"start\":95118},{\"end\":95538,\"start\":95537},{\"end\":95540,\"start\":95539},{\"end\":95548,\"start\":95547},{\"end\":95550,\"start\":95549},{\"end\":95813,\"start\":95809},{\"end\":95819,\"start\":95818},{\"end\":95830,\"start\":95829},{\"end\":95832,\"start\":95831},{\"end\":95843,\"start\":95839},{\"end\":95851,\"start\":95850},{\"end\":96270,\"start\":96269},{\"end\":96282,\"start\":96281},{\"end\":96293,\"start\":96292},{\"end\":96303,\"start\":96302},{\"end\":96653,\"start\":96652},{\"end\":96659,\"start\":96658},{\"end\":96672,\"start\":96671},{\"end\":96680,\"start\":96679},{\"end\":96692,\"start\":96691},{\"end\":97044,\"start\":97043},{\"end\":97050,\"start\":97049},{\"end\":97063,\"start\":97062},{\"end\":97071,\"start\":97070},{\"end\":97083,\"start\":97082},{\"end\":97498,\"start\":97497},{\"end\":97833,\"start\":97832},{\"end\":97845,\"start\":97844},{\"end\":98275,\"start\":98274},{\"end\":98288,\"start\":98287},{\"end\":98639,\"start\":98638},{\"end\":98649,\"start\":98648},{\"end\":98661,\"start\":98660},{\"end\":99185,\"start\":99184},{\"end\":99193,\"start\":99192},{\"end\":99467,\"start\":99466},{\"end\":99487,\"start\":99486},{\"end\":99499,\"start\":99498},{\"end\":99503,\"start\":99500},{\"end\":99513,\"start\":99512},{\"end\":99869,\"start\":99868},{\"end\":99879,\"start\":99878},{\"end\":100034,\"start\":100033},{\"end\":100045,\"start\":100044},{\"end\":100047,\"start\":100046},{\"end\":100394,\"start\":100393},{\"end\":100404,\"start\":100403},{\"end\":100414,\"start\":100413},{\"end\":100416,\"start\":100415},{\"end\":100723,\"start\":100722},{\"end\":100734,\"start\":100733},{\"end\":100745,\"start\":100744},{\"end\":101048,\"start\":101047},{\"end\":101050,\"start\":101049},{\"end\":101060,\"start\":101059},{\"end\":101321,\"start\":101320},{\"end\":101330,\"start\":101329},{\"end\":101341,\"start\":101340},{\"end\":101351,\"start\":101350},{\"end\":101821,\"start\":101820},{\"end\":101832,\"start\":101831},{\"end\":101843,\"start\":101842},{\"end\":102047,\"start\":102046},{\"end\":102373,\"start\":102372},{\"end\":102384,\"start\":102383},{\"end\":102386,\"start\":102385},{\"end\":102398,\"start\":102397},{\"end\":102413,\"start\":102412},{\"end\":102758,\"start\":102757},{\"end\":102760,\"start\":102759},{\"end\":102767,\"start\":102766},{\"end\":102776,\"start\":102775},{\"end\":102786,\"start\":102785},{\"end\":102788,\"start\":102787},{\"end\":102797,\"start\":102796},{\"end\":103216,\"start\":103215},{\"end\":103431,\"start\":103430},{\"end\":103433,\"start\":103432},{\"end\":103440,\"start\":103439},{\"end\":103453,\"start\":103452},{\"end\":103462,\"start\":103461}]", "bib_author_last_name": "[{\"end\":88819,\"start\":88809},{\"end\":88957,\"start\":88947},{\"end\":88966,\"start\":88961},{\"end\":88972,\"start\":88970},{\"end\":88982,\"start\":88976},{\"end\":88992,\"start\":88986},{\"end\":89001,\"start\":88996},{\"end\":89461,\"start\":89451},{\"end\":89469,\"start\":89465},{\"end\":89908,\"start\":89903},{\"end\":89917,\"start\":89912},{\"end\":89926,\"start\":89921},{\"end\":90162,\"start\":90154},{\"end\":90394,\"start\":90388},{\"end\":90401,\"start\":90398},{\"end\":90593,\"start\":90586},{\"end\":90609,\"start\":90597},{\"end\":90620,\"start\":90613},{\"end\":91018,\"start\":91013},{\"end\":91027,\"start\":91020},{\"end\":91244,\"start\":91240},{\"end\":91253,\"start\":91248},{\"end\":91270,\"start\":91257},{\"end\":91622,\"start\":91615},{\"end\":91636,\"start\":91629},{\"end\":91916,\"start\":91907},{\"end\":91924,\"start\":91920},{\"end\":92201,\"start\":92196},{\"end\":92419,\"start\":92413},{\"end\":92426,\"start\":92423},{\"end\":92586,\"start\":92583},{\"end\":92593,\"start\":92590},{\"end\":92600,\"start\":92597},{\"end\":93059,\"start\":93054},{\"end\":93069,\"start\":93063},{\"end\":93079,\"start\":93073},{\"end\":93343,\"start\":93335},{\"end\":93358,\"start\":93349},{\"end\":93559,\"start\":93550},{\"end\":93567,\"start\":93563},{\"end\":93897,\"start\":93891},{\"end\":93911,\"start\":93901},{\"end\":93922,\"start\":93915},{\"end\":93929,\"start\":93926},{\"end\":93938,\"start\":93933},{\"end\":93949,\"start\":93944},{\"end\":93961,\"start\":93953},{\"end\":93973,\"start\":93965},{\"end\":93984,\"start\":93980},{\"end\":94363,\"start\":94359},{\"end\":94582,\"start\":94576},{\"end\":94593,\"start\":94586},{\"end\":94602,\"start\":94597},{\"end\":95061,\"start\":95052},{\"end\":95071,\"start\":95068},{\"end\":95086,\"start\":95082},{\"end\":95102,\"start\":95093},{\"end\":95116,\"start\":95111},{\"end\":95130,\"start\":95125},{\"end\":95545,\"start\":95541},{\"end\":95556,\"start\":95551},{\"end\":95816,\"start\":95814},{\"end\":95827,\"start\":95820},{\"end\":95837,\"start\":95833},{\"end\":95848,\"start\":95844},{\"end\":95857,\"start\":95852},{\"end\":96279,\"start\":96271},{\"end\":96290,\"start\":96283},{\"end\":96300,\"start\":96294},{\"end\":96313,\"start\":96304},{\"end\":96656,\"start\":96654},{\"end\":96669,\"start\":96660},{\"end\":96677,\"start\":96673},{\"end\":96689,\"start\":96681},{\"end\":96695,\"start\":96693},{\"end\":97047,\"start\":97045},{\"end\":97060,\"start\":97051},{\"end\":97068,\"start\":97064},{\"end\":97080,\"start\":97072},{\"end\":97086,\"start\":97084},{\"end\":97505,\"start\":97499},{\"end\":97842,\"start\":97834},{\"end\":97852,\"start\":97846},{\"end\":98285,\"start\":98276},{\"end\":98298,\"start\":98289},{\"end\":98646,\"start\":98640},{\"end\":98658,\"start\":98650},{\"end\":98667,\"start\":98662},{\"end\":99190,\"start\":99186},{\"end\":99201,\"start\":99194},{\"end\":99484,\"start\":99468},{\"end\":99496,\"start\":99488},{\"end\":99510,\"start\":99504},{\"end\":99518,\"start\":99514},{\"end\":99876,\"start\":99870},{\"end\":99889,\"start\":99880},{\"end\":100042,\"start\":100035},{\"end\":100053,\"start\":100048},{\"end\":100401,\"start\":100395},{\"end\":100411,\"start\":100405},{\"end\":100423,\"start\":100417},{\"end\":100731,\"start\":100724},{\"end\":100742,\"start\":100735},{\"end\":100752,\"start\":100746},{\"end\":101057,\"start\":101051},{\"end\":101070,\"start\":101061},{\"end\":101327,\"start\":101322},{\"end\":101338,\"start\":101331},{\"end\":101348,\"start\":101342},{\"end\":101358,\"start\":101352},{\"end\":101829,\"start\":101822},{\"end\":101840,\"start\":101833},{\"end\":101851,\"start\":101844},{\"end\":102054,\"start\":102048},{\"end\":102381,\"start\":102374},{\"end\":102395,\"start\":102387},{\"end\":102410,\"start\":102399},{\"end\":102420,\"start\":102414},{\"end\":102764,\"start\":102761},{\"end\":102773,\"start\":102768},{\"end\":102783,\"start\":102777},{\"end\":102794,\"start\":102789},{\"end\":102803,\"start\":102798},{\"end\":103219,\"start\":103217},{\"end\":103437,\"start\":103434},{\"end\":103450,\"start\":103441},{\"end\":103459,\"start\":103454},{\"end\":103470,\"start\":103463}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":88877,\"start\":88803},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":7982728},\"end\":89377,\"start\":88879},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":8648546},\"end\":89838,\"start\":89379},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":4608636},\"end\":90098,\"start\":89840},{\"attributes\":{\"id\":\"b4\"},\"end\":90329,\"start\":90100},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":4267861},\"end\":90526,\"start\":90331},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":6719735},\"end\":90953,\"start\":90528},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":154552078},\"end\":91187,\"start\":90955},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":8652205},\"end\":91536,\"start\":91189},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":14351604},\"end\":91849,\"start\":91538},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":9342230},\"end\":92122,\"start\":91851},{\"attributes\":{\"id\":\"b11\"},\"end\":92349,\"start\":92124},{\"attributes\":{\"id\":\"b12\"},\"end\":92524,\"start\":92351},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":6059661},\"end\":92944,\"start\":92526},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":15421473},\"end\":93281,\"start\":92946},{\"attributes\":{\"id\":\"b15\"},\"end\":93481,\"start\":93283},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":122211807},\"end\":93768,\"start\":93483},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":2904394},\"end\":94312,\"start\":93770},{\"attributes\":{\"id\":\"b18\"},\"end\":94451,\"start\":94314},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":11564522},\"end\":95036,\"start\":94453},{\"attributes\":{\"id\":\"b20\"},\"end\":95485,\"start\":95038},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":5734450},\"end\":95741,\"start\":95487},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":7065621},\"end\":96218,\"start\":95743},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":36282173},\"end\":96574,\"start\":96220},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":10876964},\"end\":96965,\"start\":96576},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":142325},\"end\":97449,\"start\":96967},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":11303332},\"end\":97769,\"start\":97451},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":16537273},\"end\":98179,\"start\":97771},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":3332028},\"end\":98574,\"start\":98181},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":10205937},\"end\":99154,\"start\":98576},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":595377},\"end\":99404,\"start\":99156},{\"attributes\":{\"id\":\"b31\"},\"end\":99849,\"start\":99406},{\"attributes\":{\"id\":\"b32\"},\"end\":99995,\"start\":99851},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":7990187},\"end\":100331,\"start\":99997},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":14106275},\"end\":100627,\"start\":100333},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":3389226},\"end\":100969,\"start\":100629},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":7130096},\"end\":101261,\"start\":100971},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":6469844},\"end\":101776,\"start\":101263},{\"attributes\":{\"id\":\"b38\"},\"end\":102042,\"start\":101778},{\"attributes\":{\"id\":\"b39\"},\"end\":102321,\"start\":102044},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":3540699},\"end\":102680,\"start\":102323},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":6178257},\"end\":103170,\"start\":102682},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":15932084},\"end\":103379,\"start\":103172},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":16445386},\"end\":103790,\"start\":103381}]", "bib_title": "[{\"end\":88943,\"start\":88879},{\"end\":89447,\"start\":89379},{\"end\":89899,\"start\":89840},{\"end\":90384,\"start\":90331},{\"end\":90582,\"start\":90528},{\"end\":91003,\"start\":90955},{\"end\":91236,\"start\":91189},{\"end\":91611,\"start\":91538},{\"end\":91903,\"start\":91851},{\"end\":92579,\"start\":92526},{\"end\":93050,\"start\":92946},{\"end\":93546,\"start\":93483},{\"end\":93885,\"start\":93770},{\"end\":94572,\"start\":94453},{\"end\":95535,\"start\":95487},{\"end\":95807,\"start\":95743},{\"end\":96267,\"start\":96220},{\"end\":96650,\"start\":96576},{\"end\":97041,\"start\":96967},{\"end\":97495,\"start\":97451},{\"end\":97830,\"start\":97771},{\"end\":98272,\"start\":98181},{\"end\":98636,\"start\":98576},{\"end\":99182,\"start\":99156},{\"end\":99464,\"start\":99406},{\"end\":100031,\"start\":99997},{\"end\":100391,\"start\":100333},{\"end\":100720,\"start\":100629},{\"end\":101045,\"start\":100971},{\"end\":101318,\"start\":101263},{\"end\":102370,\"start\":102323},{\"end\":102755,\"start\":102682},{\"end\":103213,\"start\":103172},{\"end\":103428,\"start\":103381}]", "bib_author": "[{\"end\":88821,\"start\":88805},{\"end\":88959,\"start\":88945},{\"end\":88968,\"start\":88959},{\"end\":88974,\"start\":88968},{\"end\":88984,\"start\":88974},{\"end\":88994,\"start\":88984},{\"end\":89003,\"start\":88994},{\"end\":89463,\"start\":89449},{\"end\":89471,\"start\":89463},{\"end\":89910,\"start\":89901},{\"end\":89919,\"start\":89910},{\"end\":89928,\"start\":89919},{\"end\":90164,\"start\":90152},{\"end\":90396,\"start\":90386},{\"end\":90403,\"start\":90396},{\"end\":90595,\"start\":90584},{\"end\":90611,\"start\":90595},{\"end\":90622,\"start\":90611},{\"end\":91020,\"start\":91005},{\"end\":91029,\"start\":91020},{\"end\":91246,\"start\":91238},{\"end\":91255,\"start\":91246},{\"end\":91272,\"start\":91255},{\"end\":91624,\"start\":91613},{\"end\":91638,\"start\":91624},{\"end\":91918,\"start\":91905},{\"end\":91926,\"start\":91918},{\"end\":92203,\"start\":92194},{\"end\":92421,\"start\":92411},{\"end\":92428,\"start\":92421},{\"end\":92588,\"start\":92581},{\"end\":92595,\"start\":92588},{\"end\":92602,\"start\":92595},{\"end\":93061,\"start\":93052},{\"end\":93071,\"start\":93061},{\"end\":93081,\"start\":93071},{\"end\":93345,\"start\":93331},{\"end\":93360,\"start\":93345},{\"end\":93561,\"start\":93548},{\"end\":93569,\"start\":93561},{\"end\":93899,\"start\":93887},{\"end\":93913,\"start\":93899},{\"end\":93924,\"start\":93913},{\"end\":93931,\"start\":93924},{\"end\":93940,\"start\":93931},{\"end\":93951,\"start\":93940},{\"end\":93963,\"start\":93951},{\"end\":93975,\"start\":93963},{\"end\":93986,\"start\":93975},{\"end\":94365,\"start\":94355},{\"end\":94584,\"start\":94574},{\"end\":94595,\"start\":94584},{\"end\":94604,\"start\":94595},{\"end\":95063,\"start\":95040},{\"end\":95073,\"start\":95063},{\"end\":95088,\"start\":95073},{\"end\":95104,\"start\":95088},{\"end\":95118,\"start\":95104},{\"end\":95132,\"start\":95118},{\"end\":95547,\"start\":95537},{\"end\":95558,\"start\":95547},{\"end\":95818,\"start\":95809},{\"end\":95829,\"start\":95818},{\"end\":95839,\"start\":95829},{\"end\":95850,\"start\":95839},{\"end\":95859,\"start\":95850},{\"end\":96281,\"start\":96269},{\"end\":96292,\"start\":96281},{\"end\":96302,\"start\":96292},{\"end\":96315,\"start\":96302},{\"end\":96658,\"start\":96652},{\"end\":96671,\"start\":96658},{\"end\":96679,\"start\":96671},{\"end\":96691,\"start\":96679},{\"end\":96697,\"start\":96691},{\"end\":97049,\"start\":97043},{\"end\":97062,\"start\":97049},{\"end\":97070,\"start\":97062},{\"end\":97082,\"start\":97070},{\"end\":97088,\"start\":97082},{\"end\":97507,\"start\":97497},{\"end\":97844,\"start\":97832},{\"end\":97854,\"start\":97844},{\"end\":98287,\"start\":98274},{\"end\":98300,\"start\":98287},{\"end\":98648,\"start\":98638},{\"end\":98660,\"start\":98648},{\"end\":98669,\"start\":98660},{\"end\":99192,\"start\":99184},{\"end\":99203,\"start\":99192},{\"end\":99486,\"start\":99466},{\"end\":99498,\"start\":99486},{\"end\":99512,\"start\":99498},{\"end\":99520,\"start\":99512},{\"end\":99878,\"start\":99868},{\"end\":99891,\"start\":99878},{\"end\":100044,\"start\":100033},{\"end\":100055,\"start\":100044},{\"end\":100403,\"start\":100393},{\"end\":100413,\"start\":100403},{\"end\":100425,\"start\":100413},{\"end\":100733,\"start\":100722},{\"end\":100744,\"start\":100733},{\"end\":100754,\"start\":100744},{\"end\":101059,\"start\":101047},{\"end\":101072,\"start\":101059},{\"end\":101329,\"start\":101320},{\"end\":101340,\"start\":101329},{\"end\":101350,\"start\":101340},{\"end\":101360,\"start\":101350},{\"end\":101831,\"start\":101820},{\"end\":101842,\"start\":101831},{\"end\":101853,\"start\":101842},{\"end\":102056,\"start\":102046},{\"end\":102383,\"start\":102372},{\"end\":102397,\"start\":102383},{\"end\":102412,\"start\":102397},{\"end\":102422,\"start\":102412},{\"end\":102766,\"start\":102757},{\"end\":102775,\"start\":102766},{\"end\":102785,\"start\":102775},{\"end\":102796,\"start\":102785},{\"end\":102805,\"start\":102796},{\"end\":103221,\"start\":103215},{\"end\":103439,\"start\":103430},{\"end\":103452,\"start\":103439},{\"end\":103461,\"start\":103452},{\"end\":103472,\"start\":103461}]", "bib_venue": "[{\"end\":89081,\"start\":89003},{\"end\":89559,\"start\":89471},{\"end\":89952,\"start\":89928},{\"end\":90150,\"start\":90100},{\"end\":90409,\"start\":90403},{\"end\":90694,\"start\":90622},{\"end\":91057,\"start\":91029},{\"end\":91331,\"start\":91272},{\"end\":91675,\"start\":91638},{\"end\":91966,\"start\":91926},{\"end\":92192,\"start\":92124},{\"end\":92409,\"start\":92351},{\"end\":92659,\"start\":92602},{\"end\":93093,\"start\":93081},{\"end\":93329,\"start\":93283},{\"end\":93612,\"start\":93569},{\"end\":94020,\"start\":93986},{\"end\":94353,\"start\":94314},{\"end\":94693,\"start\":94604},{\"end\":95597,\"start\":95558},{\"end\":95935,\"start\":95859},{\"end\":96380,\"start\":96315},{\"end\":96739,\"start\":96697},{\"end\":97161,\"start\":97088},{\"end\":97539,\"start\":97507},{\"end\":97922,\"start\":97854},{\"end\":98355,\"start\":98300},{\"end\":98750,\"start\":98669},{\"end\":99265,\"start\":99203},{\"end\":99588,\"start\":99520},{\"end\":99866,\"start\":99851},{\"end\":100124,\"start\":100055},{\"end\":100465,\"start\":100425},{\"end\":100782,\"start\":100754},{\"end\":101098,\"start\":101072},{\"end\":101441,\"start\":101360},{\"end\":101818,\"start\":101778},{\"end\":102171,\"start\":102056},{\"end\":102484,\"start\":102422},{\"end\":102877,\"start\":102805},{\"end\":103264,\"start\":103221},{\"end\":103544,\"start\":103472},{\"end\":89146,\"start\":89083},{\"end\":89634,\"start\":89561},{\"end\":90753,\"start\":90696},{\"end\":91377,\"start\":91333},{\"end\":94769,\"start\":94695},{\"end\":95998,\"start\":95937},{\"end\":96768,\"start\":96741},{\"end\":97221,\"start\":97163},{\"end\":97580,\"start\":97541},{\"end\":97977,\"start\":97924},{\"end\":98857,\"start\":98752},{\"end\":99643,\"start\":99590},{\"end\":100180,\"start\":100126},{\"end\":101111,\"start\":101100},{\"end\":101526,\"start\":101443},{\"end\":102936,\"start\":102879},{\"end\":103603,\"start\":103546}]"}}}, "year": 2023, "month": 12, "day": 17}