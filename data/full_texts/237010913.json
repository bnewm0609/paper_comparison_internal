{"id": 237010913, "updated": "2022-07-04 13:50:12.178", "metadata": {"title": "Sentiment Preservation in Review Translation using Curriculum-based Re-inforcement Framework", "authors": "[{\"first\":\"Divya\",\"last\":\"Kumari\",\"middle\":[]},{\"first\":\"Soumya\",\"last\":\"Chennabasavaraj\",\"middle\":[]},{\"first\":\"Nikesh\",\"last\":\"Garera\",\"middle\":[]},{\"first\":\"Asif\",\"last\":\"Ekbal\",\"middle\":[]}]", "venue": "MTSUMMIT", "journal": "Proceedings of the 18th Biennial Machine Translation Summit (Volume 1: Research Track)", "publication_date": {"year": 2021, "month": null, "day": null}, "abstract": "Machine Translation (MT) systems often fail to preserve different stylistic and pragmatic properties of the source text (e.g. sentiment and emotion and gender traits and etc.) to the target and especially in a low-resource scenario. Such loss can affect the performance of any downstream Natural Language Processing (NLP) task and such as sentiment analysis and that heavily relies on the output of the MT systems. The susceptibility to sentiment polarity loss becomes even more severe when an MT system is employed for translating a source content that lacks a legitimate language structure (e.g. review text). Therefore and we must find ways to minimize the undesirable effects of sentiment loss in translation without compromising with the adequacy. In our current work and we present a deep re-inforcement learning (RL) framework in conjunction with the curriculum learning (as per difficulties of the reward) to fine-tune the parameters of a pre-trained neural MT system so that the generated translation successfully encodes the underlying sentiment of the source without compromising the adequacy unlike previous methods. We evaluate our proposed method on the English\u2013Hindi (product domain) and French\u2013English (restaurant domain) review datasets and and found that our method brings a significant improvement over several baselines in the machine translation and and sentiment classification tasks.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": "2021.mtsummit-research.13", "pubmed": null, "pubmedcentral": null, "dblp": "conf/mtsummit/KumariCGE21", "doi": null}}, "content": {"source": {"pdf_hash": "9bb99e29c711d9b82295beaf4136c0afdc63a051", "pdf_src": "ACL", "pdf_uri": "[\"https://www.aclanthology.org/2021.mtsummit-research.13.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "4a4e6b741b06f95692a9b99686de0f1a170da1fb", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/9bb99e29c711d9b82295beaf4136c0afdc63a051.txt", "contents": "\nSentiment Preservation in Review Translation using Curriculum-based Re-inforcement Framework\n\n\nDivya Kumari \nDepartment of Computer Science and Engineering\nIndian Institute of Technology Patna\nPatnaIndia\n\nSoumya Chennabasavraj \nDepartment of Computer Science and Engineering\nIndian Institute of Technology Patna\nPatnaIndia\n\nNikesh Garera nikesh.garera@flipkart.com \nDepartment of Computer Science and Engineering\nIndian Institute of Technology Patna\nPatnaIndia\n\nAsif Ekbal \nDepartment of Computer Science and Engineering\nIndian Institute of Technology Patna\nPatnaIndia\n\n\nFlipkart\nIndia\n\nSentiment Preservation in Review Translation using Curriculum-based Re-inforcement Framework\n\nMachine Translation (MT) is a common approach to feed humans or machines in a cross-lingual context. However, there are some expected drawbacks. Studies suggest that in the crosslingual context, MT system often fails to preserve different stylistic and pragmatic properties of the source text (e.g. sentiment, emotion, gender traits, etc.) to the target translation. These disadvantages can degrade the performance of any downstream Natural Language Processing (NLP) applications, such as sentiment analyser, that heavily relies on the output of the MT systems (especially in a low-resource setting). The susceptibility to sentiment polarity loss becomes even more severe when an MT system is employed for translating a source content that lacks a legitimate language structure (e.g. review text). Therefore, while improving the general quality of the Neural Machine Translation (NMT) output (e.g. adequacy), we must also find ways to minimize the sentiment loss in translation. In our current work, we present a deep re-inforcement learning (RL) framework in conjunction with the curriculum learning to fine-tune the parameters of a full-fledged NMT system so that the generated translation successfully encodes the underlying sentiment of the source without compromising the adequacy, unlike the previous method. We evaluate our proposed method on the English-Hindi (product domain) and French-English (restaurant domain) review datasets, and found that our method (further) brings a significant improvement over a full-fledged supervised baseline for the machine translation and sentiment classification tasks.\n\nIntroduction\n\nProduct and/or service reviews available in the e-commerce portals are predominantly in the English language, and hence a large number of population can not understand these. Machine Translation (MT) system can play a crucial role in bridging this gap by translating the usergenerated contents, and directly displaying them, or making these available for the downstream Natural Language Processing (NLP) tasks e.g. sentiment classification 1 (Ara\u00fajo et al., 2020;Barnes et al., 2016;Mohammad et al., 2016;Kanayama et al., 2004). However, numerous studies (Poncelas et al., 2020a;Afli et al., 2017;Mohammad et al., 2016;Sennrich et al., 2016a) have found a significant loss of sentiment during the automatic translation of the source text.\n\nThe susceptibility to sentiment loss aggravates when the MT system is translating a noisy review that lacks a legitimate language structure at the origin. For example, a noisy review contains several peculiarities and informal structures, such as shortening of words (e.g. \"awesome\" as \"awsm\"), acronyms (e.g. \"Oh My God\" as \"OMG\"), phonetic substitution of numbers (e.g. \"before\" as \"b4\"), emphasis on characters to define extremity of the emotion (e.g. \"good\" as \"gooooooood\"), spelling mistakes, etc. Unfortunately, even a pervasively used commercial neural 1 Please note that our current work is limited to cross-lingual sentiment analysis [CLSA] via MT based approach.\n\nProceedings of the 18th Biennial Machine Translation Summit Virtual USA, August 16 -20, 2021, Volume 1: MT Research Track machine translation (NMT) system, Google Translate, is very brittle and easily falters when presented with such noisy text, as illustrated through the following example. Review Text (English): I found an awsome product. (Positive) Google Transliteration (Hindi): mujhe ek ajeeb utpaad mila. (Neutral) The example shows how the misspelling of a sentiment bearing word \"awesome\" gets this positive expression translated to a neutral expression. In the above context, if an unedited raw MT output is directly fed to the downstream sentiment classifier, it might not get the expected classification accuracy. Thus, in this work we propose a deep-reinforcement-based framework to adapt the parameters of a pre-trained neural MT system such that the generated translation improves the performance of a cross-lingual multi-class sentiment classifier (without compromising the adequacy).\n\nMore specifically, we propose a deep actor-critic (AC) reinforcement learning framework in the ambit of curriculum learning (CL) to alleviate the issue of sentiment loss while improving the quality of translation in a cross-lingual setup. The idea of actor-critic is to have two neural networks, viz. (i). an actor (i.e. a pre-trained NMT) that takes an action (policy-based), and (ii). a critic that observes how good the action taken is and provides feedback (value-based). This feedback acts as a guiding signal to train the actor. Further, to better utilize the data, we also integrate curriculum learning into our framework.\n\nRecently, Tebbifakhr et al. (2019) demonstrated that an MT system (actor) can be customised to produce a controlled translation that essentially improves the performance of a cross-lingual (binary) sentiment classifier. They achieved this task-specific customisation of a \"generic-MT\" system via a policy-based method that optimizes a task-specific metric, i.e. F 1 score (see Section 2). However, this often miserably fails to encode the semantics of the source sentence.\n\nRecent studies (Xu et al., 2018) demonstrated that the non-opinionated semantic content improves the quality of a sentiment classifier. Accordingly, the transfer of such information from the source to the target can be pivotal for the quality of the sentiment classifier in a cross-lingual setup. Towards this, we investigate the optimization of a harmonic-score-based reward function in our proposed RL-based framework that ensures to preserve both sentiment and semantics. This function operates by taking a weighted harmonic mean of two rewards: (i). content preservation score measured through Sentence-level BLEU or SBLEU; and (ii). sentiment preservation score measured through a function that performs element-wise dot product between a predicted sentiment distribution and the gold sentiment distribution.\n\nEmpirical results, unlike Tebbifakhr et al. (2019), suggest that our RL-based fine-tuning framework, tailored to optimize the harmonic reward, preserves both sentiment and semantics in a given NMT context. Additionally, we also found that the above fine-tuning method in the ambit of curriculum learning achieves an additional performance gain of the MT system over a setting where curriculum based fine-tuning is not employed. The core of curriculum learning (CL) (Bengio et al., 2009) is to design a metric that scores the difficulty of training samples, which is then used to guide the order of presentation of samples to the learner (NMT) in an easy-to-hard fashion. To the best of our knowledge, this is the very first work that studies the curriculum learning (CL) for NMT from a new perspective, i.e. given a pre-trained MT model, the dataset to fine-tune, and the two tasks viz. sentiment and content preservation; we utilize a reward-based metric (i.e. harmonic score) to define the difficulty of the tasks and use it to score the data points. The use of harmonic reward based scoring/ranking function implicitly covers the tasks' overall difficulty through a single metric.\n\nMoreover, understanding that obtaining a gold-standard polarity annotated data is costlier, the fine-tuning of pre-trained NMT model is performed by re-using only a small subset of the supervised training samples that we annotated with respect to (w.r.t) their sentiment. Empirical results suggest that additionally enriching a random small subset of the training data with extra sentiment information, and later re-using them for the fine-tuning of the referenced model via our proposed framework (c.f. Section 3) observes an additional gain in BLEU and F 1 score over a supervised baseline. We summarize the main contributions and/or the key attributes of our current work as follows: (i). create a new domain-specific (i.e. product review) parallel corpus, a subset of which is annotated for their sentiment; (ii). propose an AC-based fine-tuning framework that utilizes a novel harmonic mean-based reward function to meet our two-fold objectives, viz. enabling our NMT model to preserve; (a). the non-opinionated semantic content; and (b). the source sentiment during translation. (iii). Additionally, we utilize the idea of CL during the RL fine-tuning of the pre-trained model and try to learn from easy to hard data, where hard corresponds to the instances with lower harmonic reward. To the best of our knowledge, this is the first work in NMT that studies CL in the ambit of RL fine-tuning.\n\n\nRelated Work\n\nThe use of translation-based solution for cross-lingual sentiment classification is successfully leveraged in the literature Tebbifakhr et al., 2020;Ara\u00fajo et al., 2020;Poncelas et al., 2020b;Fei and Li, 2020;Tebbifakhr et al., 2019;Akhtar et al., 2018;Barnes et al., 2016;Balahur and Turchi, 2012;Kanayama et al., 2004) which suggest an inspiring use-case of the MT system, and brings motivation for this piece of work.\n\nGiven the context of this work, we look at the pieces of works that address the preservation of sentiment in the automatic translation. In one of the early works, Chen and Zhu (2014) used a lexicon-based consistency approach to design a list of sentiment-based features and used it to rank the candidates of t-table in a Phrase based MT system. Lohar et al. (2017Lohar et al. ( , 2018 prepared the positive, negative and neutral sentiment-specific translation systems to ensure the cross-lingual sentiment consistency.\n\nRecently, Tebbifakhr et al. (2019) proposed Machine-Oriented (MO) Reinforce, a policybased method to pursue a machine-oriented objective 2 in a sentiment classification task unlike the traditional human-oriented objective 3 . It gives a new perspective for a use-case of the MT system (i.e. machine translation for machine). To perform this task-specific adaption (i.e. produce output to feed a machine), Tebbifakhr et al. (2019) adapted the REINFORCE of Williams (1992) by incorporating an exploration-oriented sampling strategy. As opposed to one sampling of REINFORCE, MO Reinforce samples k times, (k = 5), and obtains a reward for each sample from the sentiment classifier. A final update of the model parameters are done w.r.t the highest rewarding sample. Although they achieved a performance boost in the sentiment classification task, they had to greatly compromise with the translation quality. In contrast to Tebbifakhr et al. (2019), we focus on performing a task-specific customisation of a pre-trained MT system via a harmonic reward based deep reinforcement framework that uses an AC method in conjunction with the CL. The adapted NMT system, thus obtained, is expected to produce a more accurate (high-quality) translation as well as improve the performance of a sentiment analyser. Bahdanau et al. (2017); Nguyen et al. (2017), unlike us, used the popular AC method, and focused only on preserving the semantics (translation quality) of a text. Additionally, we develop a CL based strategy to guide the training. Recently, Zhao et al. (2020) also studied AC method in the context of NMT. However, they used this method to learn the curriculum for re-selecting influential data samples from the existing training set that can further improve the performance (translation quality) of a pre-trained NMT system.\n\n\nMethodology\n\nFirstly, we perform the pre-training of a NMT model until the convergence using the standard log-likelihood (LL) training on the supervised dataset (c.f. Table 1: (A)). The model, thus obtained, acts as our referenced MT system/actor. To demonstrate the improvements brought by the proposed curriculum-based AC fine-tuning over the above LL-based baseline in the sentiment preservation and machine translation tasks, we carry out the task-specific adaption of the pre-trained LL-based MT model (actor) by re-using a subset of the supervised training samples. It is worth mentioning here that, in the fine-tuning stage, the actor does not observe any new sentence, rather re-visit (randomly) a few of the supervised training samples which are now additionally annotated with their sentiment (c.f. Section 4). Actor-critic Overview : Here, we present a brief overview of our AC framework which is discussed at length in the subsequent section. In the AC training, the actor (NMT) receives an input sequence, s, and produces a sample translation,t, which is evaluated by the critic model. 2 Where the MT objective is to feed a machine. 3 Where the MT objective is to feed the human. The critic feedback is used by the actor to identify those actions that bring it a better than the average reward. In the above context, a feedback of a random critic would be useless for training the actor. Hence, similar to the actor we warm up the critic for one epoch by feeding it samples from the pre-trained actor, while the actor's parameters are frozen. We then fine-tune these models jointly so that -as the actor gets better w.r.t its action, the critic gets better at giving feedback (see Section 4.2 for the dataset and reward used in the pre-training and fine-tuning stages). The details of the loss functions that the actor and critic minimizes are discussed in Section 3.1. Furthermore, to better utilize the data, we finally integrate CL into our AC framework (our proposed approach). Empirical results (Section 5.1) show that during fine-tuning, presenting the data in an easy-to-hard fashion yields a better learned actor model over the one obtained via vanilla (no-curriculum based) fine-tuning. Our proposed framework brought improvements over several baselines without using any additional new training data in the two translation tasks, i.e. (i). English-Hindi 4 and (ii). French-English 5 . Since our proposed framework is a combination of RL via AC method and CL, we first present the details of the main components of the AC model alongside their training procedure in Section 3.1. The details of the reward model are presented in Section 3.2, and then introduce the plausibility of CL in Section 3.3. Finally, we describe our proposed CL-based AC framework in Algorithm 1.\n\n\nProceedings\n\n\nProposed Fine-tuning Method\n\nThe architecture of our AC-based framework is illustrated in Figure 1. It has three main components viz. (i). an actor : the pre-trained neural agent (NMT) whose parameters define the policy and the agent takes action, i.e. sample translations according to the policy (ii). a reward model : a score function used to evaluate the policy. It provides the actual (true) estimated reward to the translations sampled from the model's policy. To ensure the preservation of sentiment and content in translation, the chosen reward model gives two constituent rewards -a classifier-based score and a SBLEU score (Section 3.2), respectively, and (iii). a critic : a deep neural function approximator that predicts an expected value (reward) for the sampled action. This is then used to center the true reward (step (ii)) from the environment (see Equation 2). Subtracting critic estimated reward from the true reward helps the actor to identify action that yields extra reward beyond the expected return. We employ a critic with the same architecture as of the actor.\n\nWe see from the lower-left side of Figure 1 that, for each input sentence (s), we draw a single sample (t) from the actor, which is used for both estimating gradients of the actor and the critic model as explained in the subsequent section. Critic Network training: During the RL training, we feed a batch of source sentences, B j (s), to the critic encoder and the corresponding sampled translations obtained from the actor, B j t , to the decoder of the critic model. The critic decoder then predicts the rewards (i.e. value estimates, V \u03c6 , predicted for each time step of the decoder), and accordingly updates its parameters supervised by the actual (or true) rewards, R(t, s) 6 (steps to obtain this reward is discussed in Section 3.2) from the environment.\n\nThe objective of the critic network is, thus, to find its parameter value \u03c6 that minimizes the mean square error (MSE) between the true reward (see R in Figure 1) from the environment, and the critic estimated reward (i.e. values predicted by the critic, see V \u03c6 in Figure 1). Accordingly, the MSE loss that the critic minimizes is as in Equation (1), where \u03c4 being the critic decoding step.\n\u2207 \u03c6 L crt (\u03c6) \u2248 n \u03c4 =1 V(t <\u03c4 , s) \u2212 R(t, s) \u2207 \u03c6 V(1)\nNote that in this work we explore the setting, where the reward, R, is observable only at time step \u03c4 = n of the actor (a scalar for each complete sentence). Thus, to calculate the difference terms in Equation 1 for n steps, we use the same terminal reward, R, in all the intermediate time steps of the critic decoder.\n\nActor Network training: To update the actor (G) parameters, \u03b8, we use the policy gradient loss; weighted by a reward which is centered via the critic estimated value (i.e. the critic estimated value, V , is subtracted from the true reward, R, from the environment), as in equation (2). The updated reward is finally used to weigh the policy gradient loss, as shown in (3), where \u03c4 being the decoding step of the actor.\nR \u03c4 (t, s) = R(t, s) \u2212 V(t <\u03c4 , s) (2) \u2207 \u03b8 L pg actor (\u03b8) \u2248 n \u03c4 =1R \u03c4 \u2207 \u03b8 log G \u03b8 (t \u03c4 |t <\u03c4 )(3)\nThe actor and the critic both are global-attention based recurrent neural networks (RNN). Algorithm 1 summarizes the overall update framework. We run this algorithm for mini-batches.\n\n\nDefining Rewards\n\nAs our primary goal is to optimize the performance of the pre-trained NMT system towards sentiment classification and machine translation tasks, accordingly we investigate the utility of the following three reward functions (i.e. true reward, R in Equation 1 as R 1 , R 2 , R 3 ) for optimization through our vanilla AC method. Please note, for brevity we only choose the reward that serves the best to our purpose (i.e. harmonic reward as it ensures both, an improved cross-lingual sentiment projection, and a high quality translation with our vanilla AC approach, as discussed in Section 5.1) for our subsequently proposed curriculum-based experiment. The three types of feedbacks we explored are: (i). Sentence-level BLEU as a reward to ensure the content preservation, also referred as R 1 , is calculated following the Equation (4)\nR 1 = SBLEU(t, t)(4)\n(ii). Element-wise dot product between the gold sentiment distribution and predicted sentiment distribution (e.g. as R 2 . To simulate the target language classifier, we fine-tune the pre-trained BERT model (Devlin et al., 2019). The tuned classifier (preparation steps discussed in Section 4.1) is used to obtain the reward R 2 as in Equation (5).\nR 2 = P(s) gold \u2022 P(t) bert(5)\nand, (iii). Harmonic mean of (i) and (ii) as a reward, also referred to as R 3 to ensure the preservation of both sentiment and semantic during the translation, as in Equation (6).\nR 3 = (1 + \u03b2 2 ) (2 \u00b7 R 1 \u00b7 R 2 ) (\u03b2 2 \u00b7 R 1 ) + R 2(6)\nwhere \u03b2 is the harmonic weight which is set to 0.5.\n\n\nCurriculum Construction\n\nThe core of CL is (i). to design an evaluation metric for difficulty, and (ii). to provide the model with easy samples first before the hard ones.\n\nIn this work, the notion of difficulty is derived from the harmonic reward, R 3 , as follows.\nLet, X = {x i } N i=1 = (s i , t i ) N i=1\ndenotes the RL training data points. To measure the difficulty of say, i th data point, (s i , t i ), we calculate the reward, R 3 using (t i , s i ). In order to obtain the corresponding sample translation,t i , we use the LL-based model (pre-trained actor). We do this for the N data points. Finally, we sort the RL training data points from easy, i.e., with high harmonic reward, to hard as recorded on their translations. In the fine-tuning step, the entire sorted training data points are divided into mini-batches, B = [B 1 , ..., B M ], and the actor processes a mini-batch sequentially from B. Hence, at the start of each epoch of training, the actor will learn from the easiest examples first followed by the hard examples in a sequential manner until all the M batches exhaust. Another alternative is the use of pacing function f pace (s), which helps to decide the fraction of training data available for sampling at a given time step s, i.e. f pace (s)|D train |. However, we leave it to explore in our future work. The Pseudo-code for the proposed CL-based AC framework including pre-training is described by Algorithm 1.\n\n\nDatasets and Experimental Setup\n\nIn this section, we first discuss the datasets used in different stages of experiments followed by the steps involved in the creation of datasets, the baselines used for comparison, and the model implementation details.\n\nDataset: Our NMT adaptation experiments are performed across two language pairs from different families with different typological properties, i.e. English to Hindi (henceforth, En-Hi) and French-English (henceforth, Fr-En). We use the following supervised datasets for the pre-training and validation of LL-based NMT in En-Hi and Fr-En tasks, (i). For En-Hi task, we use a newly created domain-specific parallel corpus (see section 4.1) whose sources were selected from an e-commerce site. This corpus is released as a part of this work. Statistics of the dataset is shown in Table 1 : (A), row(ii). (ii). For Fr-En task, we concatenate a recently released domain-specific parallel corpus, namely Foursquare (4SQ) corpus 7 (Berard et al., 2019) with first 60K sentences from OpenSubtitles 8 corpus to simulate a low-resource setting. The basic statistics of this dataset are shown in Table 1 : (A), row(i). For RL fine-tuning of the LL-based NMT(s), we use the corresponding RL datasets from Table 1: (B). In each task, the RL trainset sentences are a subset of human translated sentences drawn from the supervised training samples and additionally annotated with respect to sentiment. For En-Hi task, these sentences are randomly sampled from the supervised training corpus (c.f. Table 1: (A), row(ii)), and for Fr-En we use 4SQ-HT dataset (c.f. Table 1: 7 A small parallel restaurant reviews dataset released as a part of the review translation task. 8 We choose this dataset as it is made of spoken-language sentences which are noisy, sentiment-rich and is closest to Algorithm 1 Proposed algorithm (Curriculum based fine-tuning process). In the vanilla (i.e. no curriculum-based) approach, we skip steps 5 to 7. 1: Initialize the actor model G \u03b8 with uniform weights \u03b8 \u2208 [\u22120.1, 0.1]. 2: Pre-train the actor (G \u03b8 ) with LL loss until convergence. 3: Initialize the critic model V \u03c6 with uniform weights \u03c6 \u2208 [\u22120.1, 0.1]. 4: Pre-train the critic for one epoch with SBLEU as a reward on the same LL training data by feeding it samples from the pre-trained actor, while the actor's parameters are frozen. 5: Use the actor model to translate all the data points in X. 6: Obtain rewards R3 corresponding to N data points.\n7: Rank {Xi} N i=1 = (s i , t i ) N i=1\nbased on R3. 8: for K epochs do Obtain the sample translations Bm(t) from the actor for the given source sentences, Bm(s).\n\n\n11:\n\nObtain R1, R2 and finally observe the rewards R3.\n\n\n12:\n\nFeed the source sentences, Bm(s) to the critic encoder and sampled translations, Bm(t) to the decoder.\n\n\n13:\n\nObtain the predicted rewards, V \u03c6 , using the critic model.\n\n\n14:\n\nUpdate the critic's parameter using (1).\n\n\n15:\n\nObtain final rewardR using (2).\n\n\n16:\n\nUpdate the actor's parameter using (2) in (3).\n\n\n17:\n\nend for 18: end for (A), row(i)). To evaluate the performance of all the NMT system(s) we use the corresponding RL testsets from Table 1.\n\n\nData Creation\n\nTo the best of our knowledge, there is no existing (freely available) sentiment annotated parallel data for English-Hindi in the review domain. Hence, we crawl the electronic products reviews from a popular e-commerce portal (i.e. Flipkart). These reviews were translated into Hindi using the Google Translate API. A significant part of this automated translation is then verified by a human translator with a post-graduate qualification and proficient in English and Hindi language skills. One more translator was asked to verify the translation. The detailed statistics of new in-domain parallel corpus are shown in Table 1: (A), row(ii). Further, a subset of human translated product reviews is selected randomly for sentiment annotation. Three annotators who are bilingual and experts in both Hindi and English took part in the annotation task. Details of the instructions given to the annotators and translators are mentioned below.\n\n\nInstructions to the Translators:\n\nFor translation, following were the instructions: (i). experts were asked to read the Hindi sentence carefully; (ii). source and target sentences should carry the same semantic and syntactic structure; (iii). they were instructed to carefully read the translated sentences, and see whether the fluency (grammatical correctness) and adequacy are preserved; (iv). they made the correction in the sentences, if required; (v). vocabulary selection at Hindi (target) side should be user friendly; (vi). transliteration of an English can also be used, especially if this is a named entity (NE).\n\n\nInstructions to the Annotators:\n\nThe annotators have post-graduate qualification in linguistics, possessing good knowledge of English and Hindi both. They have prior experience in judging the quality of machine translation and sentiment annotation.\n\nFor sentiment labeling, annotators were asked to follow the guidelines as below: (i). they were instructed to look into the sentiment class of the source sentence (Tebbifakhr et al., 2019) (English), locate its sentiment bearing tokens; (ii). they were asked to observe both of these properties in the translated sentences; (iii). they were asked to annotate the source sentences into the four classes, namely The further detailed instructions for sentiment annotation are given as below: (i). Select the option that best captures the sentiment being conveyed in the sentences:-positive-negativeneutral-others-(ii). Select positive if the sentence shows a positive attitude (possibly toward an object or event). e.g. great performance and value for money. (iii). Select negative if the sentence shows a negative attitude (possibly toward an object or event). e.g. please do not exchange your phone on flipkart they fool you . (iv.) Select neutral if the sentence shows a neutral attitude (possibly toward an object or event) or is an objective sentence. Objective sentences are sentences that do not carry any opinion, e.g. facts are objective expressions about entities, events and their properties. e.g. (a). the selfie camera is 32 mp .(objective), (b). after doing research on the latest phones, i bought this phone . (neutral). (iv) Select others for sentences that do not fall in above three categories, e.g. (a). if the sentence is highly ungrammatical and hard to understand. (b). if the sentence expresses both positive and negative sentiment, i.e. mixed polarity.\n\nThese annotation guidelines were decided after thorough discussions among ourselves. After we had drafted our initial guidelines, the annotators were asked to perform the verification of the translated sentences, and sentiment annotation for the 100 sentences. The disagreement cases were thereafter discussed and resolved through discussions among the experts and annotators. Finally, we came up with the set of instructions as discussed above to minimize the number of disagreement cases. Class-wise statistics of the sentiment-annotated dataset for En-Hi task are shown in Table 1: (B). Additionally, the same annotators also annotated a part of the 4SQ corpus (i.e. target 9 (English) sentences from the 4SQ-HT training and 4SQ-test set) to obtain the sentiment annotated RL dataset for the Fr-En task (c.f. Table 1: (B)). For sentiment classification, the inter-annotator agreement ratio (Fleiss, 1971) is 0.72 for En-Hi, and 0.76 for Fr-En. We manually filtered the RL datasets to only include the positive, negative and neutral sentences as per the the manual annotations. We refer these sentiment-annotated corpora as the RL dataset(s).\n\nClassifier training: In order to build the target language sentiment analyser, we use the BERT-based 10 language model. The classifier is first pre-trained using the target-side sentences of the supervised training corpus. Classifier pre-training is followed by the task-specific fine-tuning using the target-side sentences of the RL training set. For example, to build the target language English classifier for the Fr-En task, the classifier is first pre-trained using the English sentences from the supervised dataset (c.f. Table 1: (A), row(i)) followed by fine-tuning by using polarity-labelled English sentences from the RL training corpus (c.f. Table 1: (B), row(i)).\n\nBaselines: Other than the supervised baseline, we also compare our CL-based AC finetuning framework with the following state-of-the-art RL-based fine-tuning frameworks, i.e. (1). REINFORCE, and (2). Machine-Oriented Reinforce. Additionally, we also conduct the ablation study to better analyse the utility of harmonic reward in the task through our vanilla AC method as follows: (3). MT ac bert : AC fine-tuning with sentiment reward only; (4). MT ac bleu : AC finetuning with content reward only; (5). MT ac har : AC fine-tuning with both the rewards. Finally, for brevity we choose the best performing AC-reward model for the proposed curriculum-based learning.\n\n\nHyper-parameters Setting\n\nIn all our experiments, we use an NMT system based on Luong et al. (2015), using a single layer bi-directional RNN for the encoder. All the encoder-decoder parameters are uniformly initialized in the range of [-0.1,0.1]. The sizes of embedding and hidden layers are set to 256 and 512, respectively. The Adam optimizer (Abdalla and Hirst, 2017) with \u03b21 = 0.9, \u03b22 = 0.99 is used and the gradient vector is clipped to magnitude 5. We set the dropout to 0.2 and use the input feeding with learning rate (lr) and batch size (bs) set to 1e \u2212 3 and 64. We first perform supervised pre-training of the NMT using the parallel corpora from Table 1: (A), and select the best model parameters according to the perplexity on the development set (c.f. Table 1: (A)). We refer the actor-thus obtained-as MT LL , that acts as a trained policy in the RL training (refer to the upper left side of Figure 1). Then, we keep the actor fixed and warm-up the critic for one epoch with SBLEU reward on the supervised training samples (c.f.  . Results of the finetuned vanilla reinforcement-based NMT(s). Here, superscripts mo, r and ac refers to the Machine-Oriented Reinforce, REINFORCE and actor-critic approach, respectively to fine-tune the LL-based model(s) (M LL , column (iii); En-Hi: row (i), Fr-En: row (ii)), and the subscripts bleu, bert and har refers to the corresponding rewards (i.e. SBLEU (R1), classifier (R2), and harmonic mean (R3)) optimized via the policy gradient method. (D). Results of curriculum-based fine-tuning and other baselines. Proposed approach is M ac har +CL. * significant at p < .05, ** significant at p < .01 of 1e \u2212 3 and bs of 64. We employ the same encoder-decoder configuration as of the actor for the critic. In the RL training, we jointly train the actor and the critic model with lr of:-1e \u2212 6 (Fr-En); 1e \u2212 5 (En-Hi), respectively and bs of 4 on the RL datasets with harmonic reward. For sampling the candidate translation in the RL training, we use multinomial sampling, with a sampling length of 50 tokens. We run the experiments three times with different seed values, and record the F 1 and BLEU scores (c.f. Table 1: (C)) to evaluate the performance of the sentiment analysers and customised MT systems on the RL testset and report the average of the runs in Section 5. For all the RL-based models, the fine-tuning steps maximize the chosen average reward discussed in Section 3.2 on the RL devset. The fine-tuning continues for a maximum of 20 epochs (including the baselines). The best epoch is chosen based on the performance observed on the RL devset (i.e. the best average rewarding epoch). All the sentences are tokenized. As an extra pre-processing step, we lowercase all the English, French, and normalize all the Hindi sentences. Tokens in the training sets are segmented into sub-word units using the Byte-Pair Encoding (BPE) technique (Sennrich et al., 2016b) \n\n\nResults and Analysis\n\nWe first present the results of fine-tuning the pre-trained MT through different RL-based methods, i.e. (i). REINFORCE (ii). MO Reinforce, and (iii). vanilla AC (ours) in Section 5.1. Further, to better analyse the utility of harmonic reward (R 3 ) in sentiment and content preservation task over the previously studied rewards (i.e. SBLEU: R 1 or BERT: R 2 ) in the context of NMT (Tebbifakhr et al., 2020(Tebbifakhr et al., , 2019Nguyen et al., 2017;Bahdanau et al., 2017;Wu et al., 2018;Ranzato et al., 2016), we additionally present the fine-tuning results of the vanilla AC method with the following two types of rewards: (i). only content, i.e. R 1 and (ii). only sentiment, i.e. R 2 as a reward.\n\nWe choose the best performing reward model (i.e. R 3 ) among the AC-based NMT(s). At last, we discuss the results in the context of our curriculum-based AC framework. To evaluate the translation quality we record the BLEU score of the RL testset when translated from the relevant models. To validate our claim that the translations obtained by our proposed MT system can further improve the performance of the sentiment classifier in a cross-lingual setup over the baselines, we do the following. We apply the target language sentiment classifier to the translations obtained by the LL-based NMT system vs. all the customised RL-based NMT systems, and record their F 1 scores.\n\n\nEvaluation Results\n\nAs shown in Table 1: (C), the full-fledged LL-based NMT(s) (trained until convergence as observed on the development sets, column (iii).) obtain the following BLEU points (25.02, 27.87) and F 1 scores (75.31, 73.14) for the Fr-En, En-Hi tasks, respectively. We then perform fine-tuning of the pre-trained models through our vanilla AC harmonic approach (by re-visiting only a subset of samples from the existing supervised training sets which are now additionally annotated with their sentiment). We see for both Fr-En and En-Hi that our harmonic-rewardbased models can obtain a significant performance boost (further) over the pre-trained baselines in both the optimized (targeted) metrics, i.e. BLEU improved to 25.18 (+0.16), 28.13 (+0.26) and F 1 scores reached to 75.39 (+0.08), 73.29 (+0.15) in both the language pairs. This is not the case with other reinforcement-based fine-tuned models -MO Reinforce 11 and REINFORCE that optimizes a single reward for which we observe non-optimized reward drop in at least one language-pair. For example, if we consider the MO Reinforce for the Fr-En task, the nonoptimized metric -BLEU drops by \u22120.03 point (despite an improvement of +0.02 point in the optimized metric, F 1 score), and for the REINFORCE in En-Hi task both BLEU and F 1 score drop by \u22120.12 and \u22120.02 points, respectively. This establishes the efficacy of our reinforcement method. Further, when we see the results form critic-based fine-tuning of the LL model via two commonly used reward routines (R 1 , R 2 -column (vi). and (vii).). As expected, we see an improvement in the targeted metric (e.g. for R 1 -based model the optimized reward is BLEU. We can see improvement in BLEU). However, to our surprise, we found that the improvement in BLEU score does not have a high correlation with the performance in the sentiment classification task. For example, in the En-Hi task, the critic model with R 1 as a reward (columns (vii).) observed the highest BLEU score (28.14) but the highest F 1 score (73.29) is observed from the R 3 based model (column (viii).). This suggests the effectiveness of the harmonic reward which successfully improves both BLEU and F 1 score over the supervised baselines for both the language pairs. For the sake of brevity, we choose the harmonic model for our curriculum experiment.\n\nWhen comparing the performance in the context of our proposed curriculum-based AC framework, the results from Table 1: (D) show that our method is better at producing coherent as well as sentiment-rich translation. By comparing row (i). and row (vi)., we can see that in both Fr-En and En-Hi task, merely learning in an easy-to-hard fashion brings the highest improvement in BLEU scores over the supervised baselines, i.e. +0.24, +0.31 point for the Fr-En and En-Hi tasks, respectively. F 1 scores are also improved by +0.07 and +0.08 point, respectively. All these improvement are statistically significant 12 . Furthermore, we also observe 11 Please note unlike Tebbifakhr et al. (2019) \"out-of-domain\" MT-adaption approach ours' LL-based MT is trained using in-domain data. 12 To test significance, we use bootstrap resampling method (Koehn, 2004) for BLEU and student's t-test for sentiment\n\nProceedings of the 18th Biennial Machine Translation Summit Virtual USA, August 16 -20, 2021, Volume 1: MT Research Track that the CL-based fine-tuning observes a faster convergence over the vanilla approach.\n\n\nError Analysis for English-Hindi task\n\nAlthough our proposed method outperforms the LL-based baseline in the sentiment classification task, we also observe several failure cases. To investigate this, we observe the sentimentconflicting cases, i.e. selected those samples from ours' model where there is an observed disagreement between the predicted and the gold sentiment. From these samples, we filter those examples where the source (English) sentences have an explicit presence of the positive or the negative sentiment expression. Unsurprisingly, we found the main reason for sentiment loss was still the low-translation quality. Secondly, to better understand what policy is learned by our-proposed NMT that brings the observed improvement in the sentiment-classifier performance, we investigate those translations where the LL model has a predicted (by the classifier) sentimentdisagreement, whereas ours' shows an agreement, both with the gold sentiment. We present below one such example. \n\n\nConclusion\n\nIn this paper, we have proposed a curriculum-based deep re-inforcement learning framework that successfully encodes both the underlying sentiment and semantics of the text during translation. In contrast to the REINFORCE-based frameworks (Williams, 1992;Tebbifakhr et al., 2019) (actor only models), ours is a critic-based approach that helps the actor learns an efficient policy to select the actions, yielding a high return from the critic. Besides, with the support of curriculum learning, it can be more efficient. This is also established (empirically) through the observed additional boost (significant at p < .05) in BLEU score over the baselines. Further, we have manually created a domain-specific (product reviews) polarity-labelled balanced bilingual corpus for English-Hindi, that could be a useful resource for research in the similar areas. We shall make the data and our codes available to the community.\n\nFigure 1 :\n1of the 18th Biennial Machine Translation Summit Virtual USA, August 16 -20, 2021, Volume 1: MT Research Track S(Gold Sent) [ 1, 0, 0 ] T(Auto Sent) [ 0.2, 0.1, 0.7] An illustration of the Actor-Critic Method\n\n[ 1 , 0, 0 ]\n10and [0.2, 0.1, 0.7] in Figure 1 evaluates to scalar value 0.2) taken from the softmax layer of the target language classifier to ensure sentiment preservation, also referred 6 Although shown like this, it only means true reward corresponding to a given source sentence and the corresponding sampled action, not as a function. Proceedings of the 18th Biennial Machine Translation Summit Virtual USA, August 16 -20, 2021, Volume 1: MT Research Track\n\n\n4SQ corpus as suggested by the author. Proceedings of the 18th Biennial Machine Translation Summit Virtual USA, August 16 -20, 2021, Volume 1: MT Research Track\n\n\n-batches, B = [B1, ..., BM ] do 10:\n\n\nProceedings of the 18th Biennial Machine Translation Summit Virtual USA, August 16 -20, 2021, Volume 1: MT Research Track positive, negative, neutral and others.\n\n\nReview Text (Source): satisfy with overall working. (positive) || Transliteration(Ref.): kul meelaakar kaam se santusht hoon. (positive) || Transliteration(Auto.): kul milaakar kaam ke saath santusht. (positive) (MT ac har + CL) || Transliteration(Auto.): kul milaakar kaam kar rahe hain . (neutral) (MT LL ) . We can see that our proposed model indeed learned to translate the sentiment expressions to their preferred variant (positive sentiment bearing expression satisfy translated as santusht).\n\nTable 1 :\n1(A)) with the lr \n\n\nTable 1 :\n1(A). Supervised parallel corpora for LL training. (B). Class-wise distribution of the polarity-tagged RL dataset(s) used to \nfine-tune the LL-based (En-Hi and Fr-En) pre-trained NMT(s). For the Fr-En task, we annotate a part of the 4SQ corpora (i.e. training: \n4SQ-HT and testing: 4SQ-test). We do not keep a separate development set for the fine-tuning of the LL model. (C)\nTrained using a new parallel dataset created as a part of this work, a subset of which is polarity annotated. 5 Trained using publicly available dataset, a part of it is additionally annotated with sentiment.Proceedings of the 18th Biennial Machine Translation Summit Virtual USA, August 16 -20, 2021, Volume 1: MT Research Track\nThis is different from En-Hi task setting where we annotate source sentence. We do so due to resource constraint.10  We used BERT-Base multilingual uncased model for Hindi and monolingual uncased BERT for English language.Proceedings of the 18th Biennial Machine Translation Summit Virtual USA, August 16 -20, 2021, Volume 1: MT Research Track\nAcknowledgementAuthors gratefully acknowledge the unrestricted research grant received from the Flipkart Internet Private Limited to carry out the research. Authors thank Muthusamy Chelliah for his continuous feedbacks and suggestions to improve the quality of work; and to Anubhav Tripathee for gold standard parallel corpus creation and translation quality evaluation.\nCross-lingual sentiment analysis without (good) translation. M Abdalla, G Hirst, Proceedings of the Eighth International Joint Conference on Natural Language Processing. the Eighth International Joint Conference on Natural Language ProcessingLong Papers1Taiwan. Asian Federation of Natural Language ProcessingAbdalla, M. and Hirst, G. (2017). Cross-lingual sentiment analysis without (good) translation. In Proceedings of the Eighth International Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 506-515, Taiwan. Asian Federation of Natural Language Processing.\n\nSentiment translation for low resourced languages: Experiments on Irish general election tweets. H Afli, S Maguire, Way , A , 18th International Conference on Computational Linguistics and Intelligent Text Processing. Budapest, HungryAfli, H., Maguire, S., and Way, A. (2017). Sentiment translation for low resourced languages: Ex- periments on Irish general election tweets. In 18th International Conference on Computational Linguistics and Intelligent Text Processing, Budapest, Hungry.\n\nSolving data sparsity for aspect based sentiment analysis using cross-linguality and multi-linguality. M S Akhtar, P Sawant, S Sen, A Ekbal, P Bhattacharyya, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesNew Orleans, Louisiana; MT Research TrackAssociation for Computational Linguistics1Proceedings of the 18th Biennial Machine Translation Summit Virtual USAAkhtar, M. S., Sawant, P., Sen, S., Ekbal, A., and Bhattacharyya, P. (2018). Solving data sparsity for aspect based sentiment analysis using cross-linguality and multi-linguality. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), pages 572-582, New Orleans, Louisiana. Association for Computational Linguistics. classification. Proceedings of the 18th Biennial Machine Translation Summit Virtual USA, August 16 -20, 2021, Volume 1: MT Research Track\n\nA comparative study of machine translation for multilingual sentence-level sentiment analysis. M Ara\u00fajo, A Pereira, F Benevenuto, Information Sciences. 512Ara\u00fajo, M., Pereira, A., and Benevenuto, F. (2020). A comparative study of machine translation for multilingual sentence-level sentiment analysis. Information Sciences, 512:1078-1102.\n\nAn actor-critic algorithm for sequence prediction. D Bahdanau, P Brakel, K Xu, A Goyal, R Lowe, J Pineau, A Courville, Y Bengio, 5th International Conference on Learning Representations. Toulon, FranceBahdanau, D., Brakel, P., Xu, K., Goyal, A., Lowe, R., Pineau, J., Courville, A., and Bengio, Y. (2017). An actor-critic algorithm for sequence prediction. In 5th International Conference on Learning Representations, Toulon, France.\n\nMultilingual sentiment analysis using machine translation?. A Balahur, M Turchi, Proceedings of the 3rd Workshop in Computational Approaches to Subjectivity and Sentiment Analysis. the 3rd Workshop in Computational Approaches to Subjectivity and Sentiment AnalysisJeju, KoreaAssociation for Computational LinguisticsBalahur, A. and Turchi, M. (2012). Multilingual sentiment analysis using machine translation? In Proceedings of the 3rd Workshop in Computational Approaches to Subjectivity and Sentiment Analysis, pages 52-60, Jeju, Korea. Association for Computational Linguistics.\n\nExploring distributional representations and machine translation for aspect-based cross-lingual sentiment classification. J Barnes, P Lambert, T Badia, Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers. COLING 2016, the 26th International Conference on Computational Linguistics: Technical PapersBarnes, J., Lambert, P., and Badia, T. (2016). Exploring distributional representations and machine translation for aspect-based cross-lingual sentiment classification. In Proceedings of COLING 2016, the 26th International Conference on Computational Linguistics: Technical Papers, pages 1613-1623.\n\nCurriculum learning. Y Bengio, J Louradour, R Collobert, Weston , J , Proceedings of the 26th annual international conference on machine learning. the 26th annual international conference on machine learningBengio, Y., Louradour, J., Collobert, R., and Weston, J. (2009). Curriculum learning. In Proceedings of the 26th annual international conference on machine learning, pages 41-48.\n\nMachine translation of restaurant reviews: New corpus for domain adaptation and robustness. A Berard, I Calapodescu, M Dymetman, C Roux, J.-L Meunier, V Nikoulina, Proceedings of the 3rd Workshop on Neural Generation and Translation. the 3rd Workshop on Neural Generation and TranslationHong KongAssociation for Computational LinguisticsBerard, A., Calapodescu, I., Dymetman, M., Roux, C., Meunier, J.-L., and Nikoulina, V. (2019). Machine translation of restaurant reviews: New corpus for domain adaptation and robustness. In Proceedings of the 3rd Workshop on Neural Generation and Translation, pages 168-176, Hong Kong. Association for Computational Linguistics.\n\nBilingual sentiment consistency for statistical machine translation. B Chen, X Zhu, Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics. the 14th Conference of the European Chapter of the Association for Computational LinguisticsChen, B. and Zhu, X. (2014). Bilingual sentiment consistency for statistical machine translation. In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 607-615.\n\nBERT: Pre-training of deep bidirectional transformers for language understanding. J Devlin, M.-W Chang, K Lee, K Toutanova, Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesMinneapolis, Minnesota1Devlin, J., Chang, M.-W., Lee, K., and Toutanova, K. (2019). BERT: Pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4171-4186, Minneapolis, Minnesota.\n\nCross-lingual unsupervised sentiment classification with multi-view transfer learning. H Fei, P Li, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. the 58th Annual Meeting of the Association for Computational LinguisticsOnline. Association for Computational LinguisticsFei, H. and Li, P. (2020). Cross-lingual unsupervised sentiment classification with multi-view transfer learning. In Proceedings of the 58th Annual Meeting of the Association for Computa- tional Linguistics, pages 5759-5771, Online. Association for Computational Linguistics.\n\nMeasuring nominal scale agreement among many raters. J L Fleiss, Psychological bulletin. 765378Fleiss, J. L. (1971). Measuring nominal scale agreement among many raters. Psychological bulletin, 76(5):378.\n\nDeeper sentiment analysis using machine translation technology. H Kanayama, T Nasukawa, H Watanabe, COLING 2004: Proceedings of the 20th International Conference on Computational Linguistics. Geneva, Switzerland. COLINGKanayama, H., Nasukawa, T., and Watanabe, H. (2004). Deeper sentiment analysis using machine translation technology. In COLING 2004: Proceedings of the 20th International Conference on Computational Linguistics, pages 494-500, Geneva, Switzerland. COLING.\n\nStatistical significance tests for machine translation evaluation. P Koehn, Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing. the 2004 Conference on Empirical Methods in Natural Language ProcessingBarcelona, SpainKoehn, P. (2004). Statistical significance tests for machine translation evaluation. In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing, pages 388- 395, Barcelona, Spain.\n\nMaintaining sentiment polarity in translation of usergenerated content. P Lohar, H Afli, Way , A , The Prague Bulletin of Mathematical Linguistics. 1081Lohar, P., Afli, H., and Way, A. (2017). Maintaining sentiment polarity in translation of user- generated content. The Prague Bulletin of Mathematical Linguistics, 108(1):73-84.\n\nBalancing translation quality and sentiment preservation. P Lohar, H Afli, Way , A , Proceedings of the 13th Conference of the Association for Machine Translation in the Americas. the 13th Conference of the Association for Machine Translation in the AmericasBoston, MA1Lohar, P., Afli, H., and Way, A. (2018). Balancing translation quality and sentiment preservation. In Proceedings of the 13th Conference of the Association for Machine Translation in the Americas (Volume 1: Research Papers), pages 81-88, Boston, MA.\n\nEffective approaches to attention-based neural machine translation. T Luong, H Pham, C D Manning, Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing. the 2015 Conference on Empirical Methods in Natural Language ProcessingLisbon, Portugal; MT Research Track1Proceedings of the 18th Biennial Machine Translation Summit Virtual USALuong, T., Pham, H., and Manning, C. D. (2015). Effective approaches to attention-based neural machine translation. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1412-1421, Lisbon, Portugal. Proceedings of the 18th Biennial Machine Translation Summit Virtual USA, August 16 -20, 2021, Volume 1: MT Research Track\n\nHow translation alters sentiment. S M Mohammad, M Salameh, S Kiritchenko, Journal of Artificial Intelligence Research. 55Mohammad, S. M., Salameh, M., and Kiritchenko, S. (2016). How translation alters sentiment. Journal of Artificial Intelligence Research, 55:95-130.\n\nReinforcement learning for bandit neural machine translation with simulated human feedback. K Nguyen, Iii Daum\u00e9, H Boyd-Graber, J , Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. the 2017 Conference on Empirical Methods in Natural Language ProcessingCopenhagen, DenmarkNguyen, K., Daum\u00e9 III, H., and Boyd-Graber, J. (2017). Reinforcement learning for bandit neural machine translation with simulated human feedback. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pages 1464-1474, Copenhagen, Denmark.\n\nThe impact of indirect machine translation on sentiment classification. A Poncelas, P Lohar, J Hadley, Way , A , Proceedings of the 14th Conference of the Association for Machine Translation in the Americas. the 14th Conference of the Association for Machine Translation in the Americas1Research Track). Virtual. Association for Machine Translation in the AmericasPoncelas, A., Lohar, P., Hadley, J., and Way, A. (2020a). The impact of indirect machine trans- lation on sentiment classification. In Proceedings of the 14th Conference of the Association for Machine Translation in the Americas (Volume 1: Research Track), pages 78-88, Virtual. Association for Machine Translation in the Americas.\n\nThe impact of indirect machine translation on sentiment classification. A Poncelas, P Lohar, A Way, J Hadley, arXiv:2008.11257arXiv preprintPoncelas, A., Lohar, P., Way, A., and Hadley, J. (2020b). The impact of indirect machine translation on sentiment classification. arXiv preprint arXiv:2008.11257.\n\nSequence level training with recurrent neural networks. M Ranzato, S Chopra, M Auli, W Zaremba, 4th International Conference on Learning Representations. San Juan, Puerto RicoRanzato, M., Chopra, S., Auli, M., and Zaremba, W. (2016). Sequence level training with recurrent neural networks. In 4th International Conference on Learning Representations, San Juan, Puerto Rico.\n\nControlling politeness in neural machine translation via side constraints. R Sennrich, B Haddow, A Birch, Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesSennrich, R., Haddow, B., and Birch, A. (2016a). Controlling politeness in neural machine translation via side constraints. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 35-40.\n\nNeural machine translation of rare words with subword units. R Sennrich, B Haddow, A Birch, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics. the 54th Annual Meeting of the Association for Computational LinguisticsBerlin, GermanyLong Papers1Sennrich, R., Haddow, B., and Birch, A. (2016b). Neural machine translation of rare words with subword units. In Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1715-1725, Berlin, Germany.\n\nMachine translation for machines: the sentiment classification use case. A Tebbifakhr, L Bentivogli, M Negri, M Turchi, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)Hong Kong, ChinaTebbifakhr, A., Bentivogli, L., Negri, M., and Turchi, M. (2019). Machine translation for machines: the sentiment classification use case. In Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 1368-1374, Hong Kong, China.\n\nAutomatic translation for multiple nlp tasks: a multi-task approach to machine-oriented nmt adaptation. A Tebbifakhr, M Negri, M Turchi, Proceedings of the 22nd Annual Conference of the European Association for Machine Translation. the 22nd Annual Conference of the European Association for Machine TranslationTebbifakhr, A., Negri, M., and Turchi, M. (2020). Automatic translation for multiple nlp tasks: a multi-task approach to machine-oriented nmt adaptation. In Proceedings of the 22nd Annual Conference of the European Association for Machine Translation, pages 235-244.\n\nSimple statistical gradient-following algorithms for connectionist reinforcement learning. R J Williams, Mach. Learn. 83-4Williams, R. J. (1992). Simple statistical gradient-following algorithms for connectionist reinforcement learning. Mach. Learn., 8(3-4):229-256.\n\nReinforced transformer with cross-lingual distillation for cross-lingual aspect sentiment classification. H Wu, Z Wang, F Qing, Li , S , Electronics. 103270Wu, H., Wang, Z., Qing, F., and Li, S. (2021). Reinforced transformer with cross-lingual distillation for cross-lingual aspect sentiment classification. Electronics, 10(3):270.\n\nA study of reinforcement learning for neural machine translation. L Wu, F Tian, T Qin, J Lai, T.-Y Liu, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing. the 2018 Conference on Empirical Methods in Natural Language ProcessingBrussels, BelgiumWu, L., Tian, F., Qin, T., Lai, J., and Liu, T.-Y. (2018). A study of reinforcement learning for neural machine translation. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, pages 3612-3621, Brussels, Belgium.\n\nUnpaired sentimentto-sentiment translation: A cycled reinforcement learning approach. J Xu, X Sun, Q Zeng, X Zhang, X Ren, H Wang, W Li, Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics. the 56th Annual Meeting of the Association for Computational LinguisticsMelbourne, AustraliaLong Papers1Xu, J., Sun, X., Zeng, Q., Zhang, X., Ren, X., Wang, H., and Li, W. (2018). Unpaired sentiment- to-sentiment translation: A cycled reinforcement learning approach. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 979-988, Melbourne, Australia.\n\nReinforced curriculum learning on pre-trained neural machine translation models. M Zhao, H Wu, D Niu, Wang , X , The Thirty-Second Innovative Applications of Artificial Intelligence Conference. New York, NY, USA; MT Research TrackAAAI Press2020Proceedings of the 18th Biennial Machine Translation Summit Virtual USAZhao, M., Wu, H., Niu, D., and Wang, X. (2020). Reinforced curriculum learning on pre-trained neural machine translation models. In The Thirty-Fourth AAAI Conference on Artificial Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of Artificial Intelligence Conference, IAAI 2020, The Tenth AAAI Symposium on Educational Advances in Artificial Intelligence, EAAI 2020, New York, NY, USA, February 7-12, 2020, pages 9652-9659. AAAI Press. Proceedings of the 18th Biennial Machine Translation Summit Virtual USA, August 16 -20, 2021, Volume 1: MT Research Track\n", "annotations": {"author": "[{\"end\":205,\"start\":96},{\"end\":324,\"start\":206},{\"end\":462,\"start\":325},{\"end\":570,\"start\":463},{\"end\":587,\"start\":571}]", "publisher": null, "author_last_name": "[{\"end\":108,\"start\":102},{\"end\":227,\"start\":213},{\"end\":338,\"start\":332},{\"end\":473,\"start\":468}]", "author_first_name": "[{\"end\":101,\"start\":96},{\"end\":212,\"start\":206},{\"end\":331,\"start\":325},{\"end\":467,\"start\":463}]", "author_affiliation": "[{\"end\":204,\"start\":110},{\"end\":323,\"start\":229},{\"end\":461,\"start\":367},{\"end\":569,\"start\":475},{\"end\":586,\"start\":572}]", "title": "[{\"end\":93,\"start\":1},{\"end\":680,\"start\":588}]", "venue": null, "abstract": "[{\"end\":2295,\"start\":682}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2774,\"start\":2753},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":2794,\"start\":2774},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":2816,\"start\":2794},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":2838,\"start\":2816},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":2890,\"start\":2866},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2908,\"start\":2890},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":2930,\"start\":2908},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":2953,\"start\":2930},{\"end\":3701,\"start\":3695},{\"end\":4148,\"start\":4139},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":5394,\"start\":5370},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":5866,\"start\":5849},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":6699,\"start\":6675},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":7134,\"start\":7114},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":9399,\"start\":9375},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":9419,\"start\":9399},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":9442,\"start\":9419},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":9459,\"start\":9442},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":9483,\"start\":9459},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":9503,\"start\":9483},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":9523,\"start\":9503},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":9548,\"start\":9523},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":9570,\"start\":9548},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":10035,\"start\":10017},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":10056,\"start\":10035},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":10226,\"start\":10202},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":10621,\"start\":10597},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":10662,\"start\":10647},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":11136,\"start\":11112},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":11513,\"start\":11491},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":11535,\"start\":11515},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":11750,\"start\":11732},{\"end\":13119,\"start\":13118},{\"end\":13166,\"start\":13165},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":19252,\"start\":19231},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":22141,\"start\":22120},{\"end\":22851,\"start\":22850},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":26319,\"start\":26294},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":28612,\"start\":28599},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":30293,\"start\":30274},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":30564,\"start\":30539},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":33118,\"start\":33094},{\"end\":33292,\"start\":33269},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":33550,\"start\":33526},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":33576,\"start\":33550},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":33596,\"start\":33576},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":33618,\"start\":33596},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":33634,\"start\":33618},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":33655,\"start\":33634},{\"end\":36995,\"start\":36992},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":37561,\"start\":37537},{\"end\":37652,\"start\":37650},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":37723,\"start\":37710},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":39247,\"start\":39231},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":39271,\"start\":39247}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":40133,\"start\":39913},{\"attributes\":{\"id\":\"fig_1\"},\"end\":40597,\"start\":40134},{\"attributes\":{\"id\":\"fig_2\"},\"end\":40760,\"start\":40598},{\"attributes\":{\"id\":\"fig_3\"},\"end\":40798,\"start\":40761},{\"attributes\":{\"id\":\"fig_4\"},\"end\":40962,\"start\":40799},{\"attributes\":{\"id\":\"fig_5\"},\"end\":41463,\"start\":40963},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":41494,\"start\":41464},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":41881,\"start\":41495}]", "paragraph": "[{\"end\":3049,\"start\":2311},{\"end\":3724,\"start\":3051},{\"end\":4727,\"start\":3726},{\"end\":5358,\"start\":4729},{\"end\":5832,\"start\":5360},{\"end\":6647,\"start\":5834},{\"end\":7832,\"start\":6649},{\"end\":9233,\"start\":7834},{\"end\":9670,\"start\":9250},{\"end\":10190,\"start\":9672},{\"end\":12016,\"start\":10192},{\"end\":14811,\"start\":12032},{\"end\":15914,\"start\":14857},{\"end\":16678,\"start\":15916},{\"end\":17071,\"start\":16680},{\"end\":17444,\"start\":17126},{\"end\":17864,\"start\":17446},{\"end\":18145,\"start\":17963},{\"end\":19002,\"start\":18166},{\"end\":19372,\"start\":19024},{\"end\":19584,\"start\":19404},{\"end\":19692,\"start\":19641},{\"end\":19866,\"start\":19720},{\"end\":19961,\"start\":19868},{\"end\":21139,\"start\":20005},{\"end\":21394,\"start\":21175},{\"end\":23615,\"start\":21396},{\"end\":23778,\"start\":23656},{\"end\":23835,\"start\":23786},{\"end\":23945,\"start\":23843},{\"end\":24012,\"start\":23953},{\"end\":24060,\"start\":24020},{\"end\":24099,\"start\":24068},{\"end\":24153,\"start\":24107},{\"end\":24298,\"start\":24161},{\"end\":25253,\"start\":24316},{\"end\":25878,\"start\":25290},{\"end\":26129,\"start\":25914},{\"end\":27704,\"start\":26131},{\"end\":28850,\"start\":27706},{\"end\":29526,\"start\":28852},{\"end\":30191,\"start\":29528},{\"end\":33119,\"start\":30220},{\"end\":33846,\"start\":33144},{\"end\":34524,\"start\":33848},{\"end\":36871,\"start\":34547},{\"end\":37767,\"start\":36873},{\"end\":37977,\"start\":37769},{\"end\":38978,\"start\":38019},{\"end\":39912,\"start\":38993}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":17125,\"start\":17072},{\"attributes\":{\"id\":\"formula_1\"},\"end\":17962,\"start\":17865},{\"attributes\":{\"id\":\"formula_2\"},\"end\":19023,\"start\":19003},{\"attributes\":{\"id\":\"formula_3\"},\"end\":19403,\"start\":19373},{\"attributes\":{\"id\":\"formula_4\"},\"end\":19640,\"start\":19585},{\"attributes\":{\"id\":\"formula_5\"},\"end\":20004,\"start\":19962},{\"attributes\":{\"id\":\"formula_6\"},\"end\":23655,\"start\":23616}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":12193,\"start\":12186},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":21980,\"start\":21973},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":22288,\"start\":22281},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":22396,\"start\":22389},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":22685,\"start\":22678},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":22751,\"start\":22744},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":24297,\"start\":24290},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":24941,\"start\":24934},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":28289,\"start\":28282},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":28525,\"start\":28518},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":29386,\"start\":29379},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":29511,\"start\":29504},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":30858,\"start\":30851},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":30966,\"start\":30959},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":32363,\"start\":32356},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":34566,\"start\":34559},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":36990,\"start\":36983}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2309,\"start\":2297},{\"attributes\":{\"n\":\"2\"},\"end\":9248,\"start\":9236},{\"attributes\":{\"n\":\"3\"},\"end\":12030,\"start\":12019},{\"end\":14825,\"start\":14814},{\"attributes\":{\"n\":\"3.1\"},\"end\":14855,\"start\":14828},{\"attributes\":{\"n\":\"3.2\"},\"end\":18164,\"start\":18148},{\"attributes\":{\"n\":\"3.3\"},\"end\":19718,\"start\":19695},{\"attributes\":{\"n\":\"4\"},\"end\":21173,\"start\":21142},{\"end\":23784,\"start\":23781},{\"end\":23841,\"start\":23838},{\"end\":23951,\"start\":23948},{\"end\":24018,\"start\":24015},{\"end\":24066,\"start\":24063},{\"end\":24105,\"start\":24102},{\"end\":24159,\"start\":24156},{\"attributes\":{\"n\":\"4.1\"},\"end\":24314,\"start\":24301},{\"end\":25288,\"start\":25256},{\"end\":25912,\"start\":25881},{\"attributes\":{\"n\":\"4.2\"},\"end\":30218,\"start\":30194},{\"attributes\":{\"n\":\"5\"},\"end\":33142,\"start\":33122},{\"attributes\":{\"n\":\"5.1\"},\"end\":34545,\"start\":34527},{\"attributes\":{\"n\":\"5.2\"},\"end\":38017,\"start\":37980},{\"attributes\":{\"n\":\"6\"},\"end\":38991,\"start\":38981},{\"end\":39924,\"start\":39914},{\"end\":40147,\"start\":40135},{\"end\":41474,\"start\":41465},{\"end\":41505,\"start\":41496}]", "table": "[{\"end\":41494,\"start\":41476},{\"end\":41881,\"start\":41507}]", "figure_caption": "[{\"end\":40133,\"start\":39926},{\"end\":40597,\"start\":40150},{\"end\":40760,\"start\":40600},{\"end\":40798,\"start\":40763},{\"end\":40962,\"start\":40801},{\"end\":41463,\"start\":40965}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":14926,\"start\":14918},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":15959,\"start\":15951},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":16841,\"start\":16833},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":16954,\"start\":16946},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":31108,\"start\":31100}]", "bib_author_first_name": "[{\"end\":42989,\"start\":42988},{\"end\":43000,\"start\":42999},{\"end\":43618,\"start\":43617},{\"end\":43626,\"start\":43625},{\"end\":43639,\"start\":43636},{\"end\":43643,\"start\":43642},{\"end\":44114,\"start\":44113},{\"end\":44116,\"start\":44115},{\"end\":44126,\"start\":44125},{\"end\":44136,\"start\":44135},{\"end\":44143,\"start\":44142},{\"end\":44152,\"start\":44151},{\"end\":45261,\"start\":45260},{\"end\":45271,\"start\":45270},{\"end\":45282,\"start\":45281},{\"end\":45557,\"start\":45556},{\"end\":45569,\"start\":45568},{\"end\":45579,\"start\":45578},{\"end\":45585,\"start\":45584},{\"end\":45594,\"start\":45593},{\"end\":45602,\"start\":45601},{\"end\":45612,\"start\":45611},{\"end\":45625,\"start\":45624},{\"end\":46001,\"start\":46000},{\"end\":46012,\"start\":46011},{\"end\":46646,\"start\":46645},{\"end\":46656,\"start\":46655},{\"end\":46667,\"start\":46666},{\"end\":47200,\"start\":47199},{\"end\":47210,\"start\":47209},{\"end\":47223,\"start\":47222},{\"end\":47241,\"start\":47235},{\"end\":47245,\"start\":47244},{\"end\":47658,\"start\":47657},{\"end\":47668,\"start\":47667},{\"end\":47683,\"start\":47682},{\"end\":47695,\"start\":47694},{\"end\":47706,\"start\":47702},{\"end\":47717,\"start\":47716},{\"end\":48302,\"start\":48301},{\"end\":48310,\"start\":48309},{\"end\":48826,\"start\":48825},{\"end\":48839,\"start\":48835},{\"end\":48848,\"start\":48847},{\"end\":48855,\"start\":48854},{\"end\":49615,\"start\":49614},{\"end\":49622,\"start\":49621},{\"end\":50168,\"start\":50167},{\"end\":50170,\"start\":50169},{\"end\":50385,\"start\":50384},{\"end\":50397,\"start\":50396},{\"end\":50409,\"start\":50408},{\"end\":50864,\"start\":50863},{\"end\":51331,\"start\":51330},{\"end\":51340,\"start\":51339},{\"end\":51350,\"start\":51347},{\"end\":51354,\"start\":51353},{\"end\":51648,\"start\":51647},{\"end\":51657,\"start\":51656},{\"end\":51667,\"start\":51664},{\"end\":51671,\"start\":51670},{\"end\":52178,\"start\":52177},{\"end\":52187,\"start\":52186},{\"end\":52195,\"start\":52194},{\"end\":52197,\"start\":52196},{\"end\":52873,\"start\":52872},{\"end\":52875,\"start\":52874},{\"end\":52887,\"start\":52886},{\"end\":52898,\"start\":52897},{\"end\":53201,\"start\":53200},{\"end\":53213,\"start\":53210},{\"end\":53222,\"start\":53221},{\"end\":53237,\"start\":53236},{\"end\":53768,\"start\":53767},{\"end\":53780,\"start\":53779},{\"end\":53789,\"start\":53788},{\"end\":53801,\"start\":53798},{\"end\":53805,\"start\":53804},{\"end\":54465,\"start\":54464},{\"end\":54477,\"start\":54476},{\"end\":54486,\"start\":54485},{\"end\":54493,\"start\":54492},{\"end\":54753,\"start\":54752},{\"end\":54764,\"start\":54763},{\"end\":54774,\"start\":54773},{\"end\":54782,\"start\":54781},{\"end\":55147,\"start\":55146},{\"end\":55159,\"start\":55158},{\"end\":55169,\"start\":55168},{\"end\":55795,\"start\":55794},{\"end\":55807,\"start\":55806},{\"end\":55817,\"start\":55816},{\"end\":56348,\"start\":56347},{\"end\":56362,\"start\":56361},{\"end\":56376,\"start\":56375},{\"end\":56385,\"start\":56384},{\"end\":57207,\"start\":57206},{\"end\":57221,\"start\":57220},{\"end\":57230,\"start\":57229},{\"end\":57772,\"start\":57771},{\"end\":57774,\"start\":57773},{\"end\":58055,\"start\":58054},{\"end\":58061,\"start\":58060},{\"end\":58069,\"start\":58068},{\"end\":58078,\"start\":58076},{\"end\":58082,\"start\":58081},{\"end\":58349,\"start\":58348},{\"end\":58355,\"start\":58354},{\"end\":58363,\"start\":58362},{\"end\":58370,\"start\":58369},{\"end\":58380,\"start\":58376},{\"end\":58902,\"start\":58901},{\"end\":58908,\"start\":58907},{\"end\":58915,\"start\":58914},{\"end\":58923,\"start\":58922},{\"end\":58932,\"start\":58931},{\"end\":58939,\"start\":58938},{\"end\":58947,\"start\":58946},{\"end\":59545,\"start\":59544},{\"end\":59553,\"start\":59552},{\"end\":59559,\"start\":59558},{\"end\":59569,\"start\":59565},{\"end\":59573,\"start\":59572}]", "bib_author_last_name": "[{\"end\":42997,\"start\":42990},{\"end\":43006,\"start\":43001},{\"end\":43623,\"start\":43619},{\"end\":43634,\"start\":43627},{\"end\":44123,\"start\":44117},{\"end\":44133,\"start\":44127},{\"end\":44140,\"start\":44137},{\"end\":44149,\"start\":44144},{\"end\":44166,\"start\":44153},{\"end\":45268,\"start\":45262},{\"end\":45279,\"start\":45272},{\"end\":45293,\"start\":45283},{\"end\":45566,\"start\":45558},{\"end\":45576,\"start\":45570},{\"end\":45582,\"start\":45580},{\"end\":45591,\"start\":45586},{\"end\":45599,\"start\":45595},{\"end\":45609,\"start\":45603},{\"end\":45622,\"start\":45613},{\"end\":45632,\"start\":45626},{\"end\":46009,\"start\":46002},{\"end\":46019,\"start\":46013},{\"end\":46653,\"start\":46647},{\"end\":46664,\"start\":46657},{\"end\":46673,\"start\":46668},{\"end\":47207,\"start\":47201},{\"end\":47220,\"start\":47211},{\"end\":47233,\"start\":47224},{\"end\":47665,\"start\":47659},{\"end\":47680,\"start\":47669},{\"end\":47692,\"start\":47684},{\"end\":47700,\"start\":47696},{\"end\":47714,\"start\":47707},{\"end\":47727,\"start\":47718},{\"end\":48307,\"start\":48303},{\"end\":48314,\"start\":48311},{\"end\":48833,\"start\":48827},{\"end\":48845,\"start\":48840},{\"end\":48852,\"start\":48849},{\"end\":48865,\"start\":48856},{\"end\":49619,\"start\":49616},{\"end\":49625,\"start\":49623},{\"end\":50177,\"start\":50171},{\"end\":50394,\"start\":50386},{\"end\":50406,\"start\":50398},{\"end\":50418,\"start\":50410},{\"end\":50870,\"start\":50865},{\"end\":51337,\"start\":51332},{\"end\":51345,\"start\":51341},{\"end\":51654,\"start\":51649},{\"end\":51662,\"start\":51658},{\"end\":52184,\"start\":52179},{\"end\":52192,\"start\":52188},{\"end\":52205,\"start\":52198},{\"end\":52884,\"start\":52876},{\"end\":52895,\"start\":52888},{\"end\":52910,\"start\":52899},{\"end\":53208,\"start\":53202},{\"end\":53219,\"start\":53214},{\"end\":53234,\"start\":53223},{\"end\":53777,\"start\":53769},{\"end\":53786,\"start\":53781},{\"end\":53796,\"start\":53790},{\"end\":54474,\"start\":54466},{\"end\":54483,\"start\":54478},{\"end\":54490,\"start\":54487},{\"end\":54500,\"start\":54494},{\"end\":54761,\"start\":54754},{\"end\":54771,\"start\":54765},{\"end\":54779,\"start\":54775},{\"end\":54790,\"start\":54783},{\"end\":55156,\"start\":55148},{\"end\":55166,\"start\":55160},{\"end\":55175,\"start\":55170},{\"end\":55804,\"start\":55796},{\"end\":55814,\"start\":55808},{\"end\":55823,\"start\":55818},{\"end\":56359,\"start\":56349},{\"end\":56373,\"start\":56363},{\"end\":56382,\"start\":56377},{\"end\":56392,\"start\":56386},{\"end\":57218,\"start\":57208},{\"end\":57227,\"start\":57222},{\"end\":57237,\"start\":57231},{\"end\":57783,\"start\":57775},{\"end\":58058,\"start\":58056},{\"end\":58066,\"start\":58062},{\"end\":58074,\"start\":58070},{\"end\":58352,\"start\":58350},{\"end\":58360,\"start\":58356},{\"end\":58367,\"start\":58364},{\"end\":58374,\"start\":58371},{\"end\":58384,\"start\":58381},{\"end\":58905,\"start\":58903},{\"end\":58912,\"start\":58909},{\"end\":58920,\"start\":58916},{\"end\":58929,\"start\":58924},{\"end\":58936,\"start\":58933},{\"end\":58944,\"start\":58940},{\"end\":58950,\"start\":58948},{\"end\":59550,\"start\":59546},{\"end\":59556,\"start\":59554},{\"end\":59563,\"start\":59560}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":22253718},\"end\":43518,\"start\":42927},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":191520325},\"end\":44008,\"start\":43520},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":44103962},\"end\":45163,\"start\":44010},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":199386551},\"end\":45503,\"start\":45165},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":14096841},\"end\":45938,\"start\":45505},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":14292133},\"end\":46521,\"start\":45940},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":2239641},\"end\":47176,\"start\":46523},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":873046},\"end\":47563,\"start\":47178},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":207758149},\"end\":48230,\"start\":47565},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":5789456},\"end\":48741,\"start\":48232},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":52967399},\"end\":49525,\"start\":48743},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":220046457},\"end\":50112,\"start\":49527},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":143544759},\"end\":50318,\"start\":50114},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":14529282},\"end\":50794,\"start\":50320},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":15119437},\"end\":51256,\"start\":50796},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":597636},\"end\":51587,\"start\":51258},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":43967034},\"end\":52107,\"start\":51589},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":1998416},\"end\":52836,\"start\":52109},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":14935137},\"end\":53106,\"start\":52838},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":215824512},\"end\":53693,\"start\":53108},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":221319546},\"end\":54390,\"start\":53695},{\"attributes\":{\"doi\":\"arXiv:2008.11257\",\"id\":\"b21\"},\"end\":54694,\"start\":54392},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":7147309},\"end\":55069,\"start\":54696},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":845121},\"end\":55731,\"start\":55071},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":1114678},\"end\":56272,\"start\":55733},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":202786381},\"end\":57100,\"start\":56274},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":221097263},\"end\":57678,\"start\":57102},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":2332513},\"end\":57946,\"start\":57680},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":234288794},\"end\":58280,\"start\":57948},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":52100616},\"end\":58813,\"start\":58282},{\"attributes\":{\"id\":\"b30\"},\"end\":59461,\"start\":58815},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":211102338},\"end\":60353,\"start\":59463}]", "bib_title": "[{\"end\":42986,\"start\":42927},{\"end\":43615,\"start\":43520},{\"end\":44111,\"start\":44010},{\"end\":45258,\"start\":45165},{\"end\":45554,\"start\":45505},{\"end\":45998,\"start\":45940},{\"end\":46643,\"start\":46523},{\"end\":47197,\"start\":47178},{\"end\":47655,\"start\":47565},{\"end\":48299,\"start\":48232},{\"end\":48823,\"start\":48743},{\"end\":49612,\"start\":49527},{\"end\":50165,\"start\":50114},{\"end\":50382,\"start\":50320},{\"end\":50861,\"start\":50796},{\"end\":51328,\"start\":51258},{\"end\":51645,\"start\":51589},{\"end\":52175,\"start\":52109},{\"end\":52870,\"start\":52838},{\"end\":53198,\"start\":53108},{\"end\":53765,\"start\":53695},{\"end\":54750,\"start\":54696},{\"end\":55144,\"start\":55071},{\"end\":55792,\"start\":55733},{\"end\":56345,\"start\":56274},{\"end\":57204,\"start\":57102},{\"end\":57769,\"start\":57680},{\"end\":58052,\"start\":57948},{\"end\":58346,\"start\":58282},{\"end\":58899,\"start\":58815},{\"end\":59542,\"start\":59463}]", "bib_author": "[{\"end\":42999,\"start\":42988},{\"end\":43008,\"start\":42999},{\"end\":43625,\"start\":43617},{\"end\":43636,\"start\":43625},{\"end\":43642,\"start\":43636},{\"end\":43646,\"start\":43642},{\"end\":44125,\"start\":44113},{\"end\":44135,\"start\":44125},{\"end\":44142,\"start\":44135},{\"end\":44151,\"start\":44142},{\"end\":44168,\"start\":44151},{\"end\":45270,\"start\":45260},{\"end\":45281,\"start\":45270},{\"end\":45295,\"start\":45281},{\"end\":45568,\"start\":45556},{\"end\":45578,\"start\":45568},{\"end\":45584,\"start\":45578},{\"end\":45593,\"start\":45584},{\"end\":45601,\"start\":45593},{\"end\":45611,\"start\":45601},{\"end\":45624,\"start\":45611},{\"end\":45634,\"start\":45624},{\"end\":46011,\"start\":46000},{\"end\":46021,\"start\":46011},{\"end\":46655,\"start\":46645},{\"end\":46666,\"start\":46655},{\"end\":46675,\"start\":46666},{\"end\":47209,\"start\":47199},{\"end\":47222,\"start\":47209},{\"end\":47235,\"start\":47222},{\"end\":47244,\"start\":47235},{\"end\":47248,\"start\":47244},{\"end\":47667,\"start\":47657},{\"end\":47682,\"start\":47667},{\"end\":47694,\"start\":47682},{\"end\":47702,\"start\":47694},{\"end\":47716,\"start\":47702},{\"end\":47729,\"start\":47716},{\"end\":48309,\"start\":48301},{\"end\":48316,\"start\":48309},{\"end\":48835,\"start\":48825},{\"end\":48847,\"start\":48835},{\"end\":48854,\"start\":48847},{\"end\":48867,\"start\":48854},{\"end\":49621,\"start\":49614},{\"end\":49627,\"start\":49621},{\"end\":50179,\"start\":50167},{\"end\":50396,\"start\":50384},{\"end\":50408,\"start\":50396},{\"end\":50420,\"start\":50408},{\"end\":50872,\"start\":50863},{\"end\":51339,\"start\":51330},{\"end\":51347,\"start\":51339},{\"end\":51353,\"start\":51347},{\"end\":51357,\"start\":51353},{\"end\":51656,\"start\":51647},{\"end\":51664,\"start\":51656},{\"end\":51670,\"start\":51664},{\"end\":51674,\"start\":51670},{\"end\":52186,\"start\":52177},{\"end\":52194,\"start\":52186},{\"end\":52207,\"start\":52194},{\"end\":52886,\"start\":52872},{\"end\":52897,\"start\":52886},{\"end\":52912,\"start\":52897},{\"end\":53210,\"start\":53200},{\"end\":53221,\"start\":53210},{\"end\":53236,\"start\":53221},{\"end\":53240,\"start\":53236},{\"end\":53779,\"start\":53767},{\"end\":53788,\"start\":53779},{\"end\":53798,\"start\":53788},{\"end\":53804,\"start\":53798},{\"end\":53808,\"start\":53804},{\"end\":54476,\"start\":54464},{\"end\":54485,\"start\":54476},{\"end\":54492,\"start\":54485},{\"end\":54502,\"start\":54492},{\"end\":54763,\"start\":54752},{\"end\":54773,\"start\":54763},{\"end\":54781,\"start\":54773},{\"end\":54792,\"start\":54781},{\"end\":55158,\"start\":55146},{\"end\":55168,\"start\":55158},{\"end\":55177,\"start\":55168},{\"end\":55806,\"start\":55794},{\"end\":55816,\"start\":55806},{\"end\":55825,\"start\":55816},{\"end\":56361,\"start\":56347},{\"end\":56375,\"start\":56361},{\"end\":56384,\"start\":56375},{\"end\":56394,\"start\":56384},{\"end\":57220,\"start\":57206},{\"end\":57229,\"start\":57220},{\"end\":57239,\"start\":57229},{\"end\":57785,\"start\":57771},{\"end\":58060,\"start\":58054},{\"end\":58068,\"start\":58060},{\"end\":58076,\"start\":58068},{\"end\":58081,\"start\":58076},{\"end\":58085,\"start\":58081},{\"end\":58354,\"start\":58348},{\"end\":58362,\"start\":58354},{\"end\":58369,\"start\":58362},{\"end\":58376,\"start\":58369},{\"end\":58386,\"start\":58376},{\"end\":58907,\"start\":58901},{\"end\":58914,\"start\":58907},{\"end\":58922,\"start\":58914},{\"end\":58931,\"start\":58922},{\"end\":58938,\"start\":58931},{\"end\":58946,\"start\":58938},{\"end\":58952,\"start\":58946},{\"end\":59552,\"start\":59544},{\"end\":59558,\"start\":59552},{\"end\":59565,\"start\":59558},{\"end\":59572,\"start\":59565},{\"end\":59576,\"start\":59572}]", "bib_venue": "[{\"end\":43095,\"start\":43008},{\"end\":43736,\"start\":43646},{\"end\":44310,\"start\":44168},{\"end\":45315,\"start\":45295},{\"end\":45690,\"start\":45634},{\"end\":46119,\"start\":46021},{\"end\":46783,\"start\":46675},{\"end\":47323,\"start\":47248},{\"end\":47797,\"start\":47729},{\"end\":48423,\"start\":48316},{\"end\":49009,\"start\":48867},{\"end\":49714,\"start\":49627},{\"end\":50201,\"start\":50179},{\"end\":50510,\"start\":50420},{\"end\":50958,\"start\":50872},{\"end\":51404,\"start\":51357},{\"end\":51767,\"start\":51674},{\"end\":52293,\"start\":52207},{\"end\":52955,\"start\":52912},{\"end\":53326,\"start\":53240},{\"end\":53901,\"start\":53808},{\"end\":54462,\"start\":54392},{\"end\":54848,\"start\":54792},{\"end\":55319,\"start\":55177},{\"end\":55912,\"start\":55825},{\"end\":56569,\"start\":56394},{\"end\":57332,\"start\":57239},{\"end\":57796,\"start\":57785},{\"end\":58096,\"start\":58085},{\"end\":58472,\"start\":58386},{\"end\":59039,\"start\":58952},{\"end\":59655,\"start\":59576},{\"end\":43169,\"start\":43097},{\"end\":43754,\"start\":43738},{\"end\":44480,\"start\":44312},{\"end\":45706,\"start\":45692},{\"end\":46215,\"start\":46121},{\"end\":46878,\"start\":46785},{\"end\":47385,\"start\":47325},{\"end\":47861,\"start\":47799},{\"end\":48517,\"start\":48425},{\"end\":49160,\"start\":49011},{\"end\":49788,\"start\":49716},{\"end\":50539,\"start\":50512},{\"end\":51047,\"start\":50960},{\"end\":51857,\"start\":51769},{\"end\":52401,\"start\":52295},{\"end\":53418,\"start\":53328},{\"end\":53981,\"start\":53903},{\"end\":54871,\"start\":54850},{\"end\":55448,\"start\":55321},{\"end\":56001,\"start\":55914},{\"end\":56747,\"start\":56571},{\"end\":57412,\"start\":57334},{\"end\":58562,\"start\":58474},{\"end\":59133,\"start\":59041},{\"end\":59693,\"start\":59657}]"}}}, "year": 2023, "month": 12, "day": 17}