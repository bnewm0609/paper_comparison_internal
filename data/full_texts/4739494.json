{"id": 4739494, "updated": "2023-10-01 00:31:30.241", "metadata": {"title": "Frank-Wolfe Splitting via Augmented Lagrangian Method", "authors": "[{\"first\":\"Gauthier\",\"last\":\"Gidel\",\"middle\":[]},{\"first\":\"Fabian\",\"last\":\"Pedregosa\",\"middle\":[]},{\"first\":\"Simon\",\"last\":\"Lacoste-Julien\",\"middle\":[]}]", "venue": "ArXiv", "journal": "ArXiv", "publication_date": {"year": 2018, "month": 4, "day": 9}, "abstract": "Minimizing a function over an intersection of convex sets is an important task in optimization that is often much more challenging than minimizing it over each individual constraint set. While traditional methods such as Frank-Wolfe (FW) or proximal gradient descent assume access to a linear or quadratic oracle on the intersection, splitting techniques take advantage of the structure of each sets, and only require access to the oracle on the individual constraints. In this work, we develop and analyze the Frank-Wolfe Augmented Lagrangian (FW-AL) algorithm, a method for minimizing a smooth function over convex compact sets related by a\"linear consistency\"constraint that only requires access to a linear minimization oracle over the individual constraints. It is based on the Augmented Lagrangian Method (ALM), also known as Method of Multipliers, but unlike most existing splitting methods, it only requires access to linear (instead of quadratic) minimization oracles. We use recent advances in the analysis of Frank-Wolfe and the alternating direction method of multipliers algorithms to prove a sublinear convergence rate for FW-AL over general convex compact sets and a linear convergence rate for polytopes.", "fields_of_study": "[\"Mathematics\",\"Computer Science\"]", "external_ids": {"arxiv": "1804.03176", "mag": "2963026695", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/corr/abs-1804-03176", "doi": null}}, "content": {"source": {"pdf_hash": "017050317d7dae1c43764f6046bd0fab257a0c2f", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/1804.03176v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "8a19253a2cd499225581c733e0e3a3d7354f38ca", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/017050317d7dae1c43764f6046bd0fab257a0c2f.txt", "contents": "\nFrank-Wolfe Splitting via Augmented Lagrangian Method\n\n\nGauthier Gidel \nMILA\nDIRO Universit\u00e9 de Montr\u00e9al UC Berkeley & ETH Zurich MILA\nDIRO Universit\u00e9 de Montr\u00e9al\n\n\nFabian Pedregosa \nMILA\nDIRO Universit\u00e9 de Montr\u00e9al UC Berkeley & ETH Zurich MILA\nDIRO Universit\u00e9 de Montr\u00e9al\n\n\nSimon Lacoste-Julien \nMILA\nDIRO Universit\u00e9 de Montr\u00e9al UC Berkeley & ETH Zurich MILA\nDIRO Universit\u00e9 de Montr\u00e9al\n\n\nFrank-Wolfe Splitting via Augmented Lagrangian Method\n\nMinimizing a function over an intersection of convex sets is an important task in optimization that is often much more challenging than minimizing it over each individual constraint set. While traditional methods such as Frank-Wolfe (FW) or proximal gradient descent assume access to a linear or quadratic oracle on the intersection, splitting techniques take advantage of the structure of each sets, and only require access to the oracle on the individual constraints. In this work, we develop and analyze the Frank-Wolfe Augmented Lagrangian (FW-AL) algorithm, a method for minimizing a smooth function over convex compact sets related by a \"linear consistency\" constraint that only requires access to a linear minimization oracle over the individual constraints. It is based on the Augmented Lagrangian Method (ALM), also known as Method of Multipliers, but unlike most existing splitting methods, it only requires access to linear (instead of quadratic) minimization oracles. We use recent advances in the analysis of Frank-Wolfe and the alternating direction method of multipliers algorithms to prove a sublinear convergence rate for FW-AL over general convex compact sets and a linear convergence rate over polytopes.\n\nIntroduction\n\nThe Frank-Wolfe (FW) or conditional gradient algorithm has seen an impressive revival in recent years, notably due to its very favorable properties for the optimization of sparse problems (Jaggi, 2013) or over structured constraint sets (Lacoste-Julien and Jaggi, 2015). This algorithm assumes knowledge of a linear minimization oracle (LMO) over the set of constraints. This oracle is inexpensive to compute for sets such as the 1 or trace norm ball. However, inducing complex priors often requires to consider multiple constraints, leading to a constraint set formed by the intersection of the original constraints. Unfortunately, evaluating the LMO over this intersection may be challenging even if the LMOs on the individual sets are inexpensive.\n\nThe problem of minimizing over an intersection of convex sets is pervasive in machine learning and signal processing. For example, one can seek for a matrix that is both sparse and low rank by constraining the solution to have both small 1 and trace norm (Richard et al., 2012) or find a set of brain maps which are both sparse and piecewise constant by constraining both the 1 and total variation pseudonorm (Gramfort et al., 2013). Furthermore, some challenging optimization problems such as multiple sequence alignment are naturally expressed over an intersection of sets (Yen et al., 2016a) or more generally as a linear relationship between these sets (Huang et al., 2017).\n\nThe goal of this paper is to describe and analyze FW-AL, an optimization method that solves convex optimization problems subject to multiple constraint sets, assuming we have access to a LMO on each of the set.\n\nPrevious work. The vast majority of methods proposed to solve optimization problems over an intersection of sets rely on the availability of a projection operator onto each set (see e.g. the recent reviews (Glowinski et al., 2017;Ryu and Boyd, 2016), which cover the more general proximal splitting framework). One of the most popular algorithms in this framework is the alternating direction method of multipliers (ADMM), proposed by Glowinski and Marroco (1975), studied by Gabay and Mercier (1976), and revisited many times; see for instance (Boyd et al., 2011;Yan and Yin, 2016). On some cases, such as constraints on the trace norm (Cai et al., 2010) or the latent group lasso (Obozinski et al., 2011), the projection step can be a time-consuming operation, while the Frank-Wolfe LMO is much cheaper in both cases. Moreover, for some highly structured polytopes such as those appearing in alignment constraints (Alayrac et al., 2016) or Structured SVM (Lacoste-Julien et al., 2013), there exists a fast and elegant dynamic programming algorithm to compute the LMO, while there is no known practical algorithm to compute the projection. Hence, the development of splitting methods that use the LMO instead of the proximal operator is of key practical interest. Yurtsever et al. (2015) proposed a general algorithm (UniPDGrad) based on the Lagrangian method which, with some work, can be reduced to a splitting method using only LMO as a particular case. We develop the comparison with FW-AL in App. B.2.\n\nRecently, Yen et al. (2016a) proposed a FW variant for objectives with a linear loss function over an intersection of polytopes named Greedy Direction Method of Multipliers (GDMM). A similar version of GDMM is also used in (Yen et al., 2016b;Huang et al., 2017) to optimize a function over a Cartesian product of spaces related to each other by a linear consistency constraint. The constraints are incorporated through the augmented Lagrangian method and its convergence analysis crucially uses recent progress in the analysis of ADMM by Hong and Luo (2017). Nevertheless, we argue in Sec. C.1 that there are technical issues in these analysis since some of the properties used have only been proven for ADMM and do not hold in the context of GDMM. Furthermore, even though GDMM provides good experimental results in these papers, the practical applicability of the method to other problems is dampened by overly restrictive assumptions: the loss function is required to be linear or quadratic, leaving outside loss functions such as logistic regression, and the constraint needs to be a polytope, leaving outside domains such as the trace norm ball.\n\nContributions. Our main contribution is the development of a novel variant of FW for the optimization of a function over product of spaces related to each other by a linear consistency constraint and its rigorous analysis. We name this method Frank-Wolfe via Augmented Lagrangian method (FW-AL). With respect to Yen et al. (2016a,b); Huang et al. (2017), our framework generalizes GDMM by providing a method to optimize a general class of functions over an intersection of an arbitrary number of compact sets, which are not restricted to be polytopes. Moreover, we argue that the previous proofs of convergence were incomplete: in this paper, we prove a new challenging technical lemma providing a growth condition on the augmented dual function which allows us to fix the missing parts.\n\nWe show that FW-AL converges for any smooth objective function. We prove that a standard gap measure converges linearly (i.e., with a geometric rate) when the constraint sets are polytopes, and sublinearly for general compact convex sets. We also show that when the function is strongly convex, the sum of this gap measure and the feasibility gives a bound on the distance to the set of optimal solutions. This is of key practical importance since the applications that we consider (e.g., minimization with trace norm constraints) verify these assumptions.\n\nThe paper is organized as follows. In Sec. 2, we introduce the general setting, provide some motivating applications and present the augmented Lagrangian formulation of our problem. In Sec. 3, we describe the algorithm FW-AL and provide its analysis in Sec. 4. Finally, we present illustrative experiments in Sec. 5.\n\n\nProblem Setting\n\nWe will consider the following minimization problem, minimize x (1) ,...,x (k) f (x (1) , . . . , x (k) ) ,\ns.t. x (k) \u2208 X k , k \u2208 [K], K k=1 A k x (k) = 0 ,(OPT)\nwhere f : R m \u2192 R is a convex differentiable function and for k \u2208 [K], X k \u2282 R d k are convex compact sets and A k are matrices of size d \u00d7 d k . We will call the constraint K k=1 A k x (k) = 0 the linear consistency constraint, motivated by the marginalization consistency constraints appearing in some of the applications of our framework as described in Sec. 2.1. One important potential application is the intersection of multiple sets. The simple K = 2 example can be expressed with A 1 = I and A 2 = \u2212I. We assume that we have access to the linear minimization oracle LMO k (r) \u2208 arg min s\u2208X k s, r , k \u2208 [K]. We denote by X * the set of optimal points of the optimization problem (OPT) and we assume that this problem is feasible, i.e., the set of solutions is non empty.\n\n\nMotivating Applications\n\nWe now present some motivating applications of our problem setting, including examples where special case versions of FW-AL were used. This previous work provides additional evidence for the practical significance of the FW-AL algorithm.\n\nMultiple sequence alignment and motif discovery (Yen et al., 2016a) are problems in which the domain is described as an intersection of alignment constraints and consensus constraints, two highly structured polytopes.\n\nThe LMO on both sets can be solved by dynamic programing whereas there is no known practical algorithm to project onto. A factorwise approach to the dual of the structured SVM objective (Yen et al., 2016b) can also be cast as constrained problem over a Cartesian product of polytopes related to each other by a linear consistency constraint. As often in structured prediction, the output domain grows exponentially, leading to very high dimensional polytopes. Once again, dynamic programming can be used to compute the linear oracle in structured SVMs at a lower computational cost than the potentially intractable projection. The algorithms proposed by Yen et al. (2016a) and Yen et al. (2016b) are in fact a particular instance of FW-AL, where the objective function is respectively linear and quadratic.\n\nFinally, simultaneously sparse ( 1 norm constraint) and low rank (trace norm constraint) matrices (Richard et al., 2012) is another class of problems where the constraints consists of an intersection of sets with simple LMO but expensive projection. This example is a novel application of FW-AL and is developed in Sec. 5.\n\n\nAugmented Lagrangian Reformulation\n\nIt is possible to reformulate (OPT) into the problem of finding a saddle point of an augmented Lagrangian (Bertsekas, 1996), in order to split the constraints in a way in which the linear oracle is computed over a product space. We first rewrite (OPT) as follows:\nmin x (k) \u2208X k , k\u2208[K] f (x) s.t. M x = 0 ,(1)\nwhere x := x (1) , . . . , x (K) and M := [A 1 , . . . , A k ] is such that,\nM x = 0 \u21d4 K k=1 A k x (k) = 0 .(2)\nWe can now consider the augmented Lagrangian formulation of (1), where y is the dual variable:\nminimize (x (1) ,...,x (K) ) max y\u2208R d L(x (1) , . . . , x (K) , y) s.t. x (k) \u2208 X k , k \u2208 {1, . . . , K} L(x, y) := f (x) + y, M x + \u03bb 2 M x 2 .(OPT2)\nWe note X := X 1 \u00d7 \u00b7 \u00b7 \u00b7 \u00d7 X K \u2282 R d1+...+d K = R m for notational simplicity. This formulation is the one onto which our algorithm FW-AL is applied.\n\nNotation and assumption. In this paper, we denote by \u00b7 the 2 norm for vectors (resp. spectral norm for matrices) and dist(x, C) := inf x \u2208C x \u2212 x its associated distance to a set. We assume that f is L-smooth on R m , i.e., differentiable with L-Lipschitz continuous gradient:\n\u2207f (x) \u2212 \u2207f (x ) \u2264 L x \u2212 x \u2200x, x \u2208 R m . (3)\nThis assumption is standard in convex optimization (Nesterov, 2004). Notice that the FW algorithm does not converge if the objective function is not at least continuously differentiable (Nesterov, 2016, Example 1). In our analysis, we will also use the observation that \u03bb 2 M \u00b7 2 is generalized strongly convex. 1 We say that a function h is generalized strongly convex when it takes the following general form:\nh(x) := g(Ax) + b, x , \u2200x \u2208 R m ,(4)\nwhere A \u2208 R d\u00d7m and g is \u00b5 g -strongly convex w.r.t. the Euclidean norm on R d with \u00b5 g > 0. Recall that a \u00b5 g -strongly (differentiable) convex function g :\nR d \u2192 R is one such that, \u2200x, x \u2208 R d , g(x) \u2265 g(x ) + x \u2212 x , \u2207g(x ) + \u00b5 g 2 x \u2212 x 2 .\n\nFW-AL Algorithm\n\nOur algorithm takes inspiration from both Frank-Wolfe and the augmented Lagrangian method. The augmented Lagrangian method alternates a primal update on x (approximately) minimizing 2 the augmented Lagrangian L(\u00b7, y t ), with a dual update on y by taking a gradient ascent step on L(x t+1 , \u00b7). The FW-AL algorithm follows the general iteration of the augmented Lagrangian method, but with the crucial difference that Lagrangian minimization is replaced by one Frank-Wolfe step on L(\u00b7, y t ). The algorithm is thus composed by two loops: an outer loop presented in (6)   3: \u03b3 \u2208 arg min \u03b3\u2208[0,1] \u03d5(x + \u03b3(s \u2212 x)) 4: Update x \u2190 (1 \u2212 \u03b3)x + \u03b3s 5: return: x algorithm (AFW) (Lacoste-Julien and Jaggi, 2015), as described in Algorithm 1. Other possible variants are discussed in Appendix A. We denote by x t and y t the iterates computed by FW-AL after t steps and by A t the set of atoms previously given by the FW oracle (including the initialization point). If the constraint set is the convex hull of a set of atoms A, the iterate x t has a sparse representation as a convex combination of the first iterate and the atoms previously given by the FW oracle. The set of atoms which appear in this expansion with non-zero weight is called the active set S t . Similarly, since y t is by construction in the cone generated by {M x s } s\u2264t , the iterate y t is in the span of M A t , that is, they both have the sparse expansion:\ns \u2190 Lmo (\u2207\u03d5(x)) 5: v \u2208 arg max v\u2208S \u2207\u03d5(x), v 6: g F W \u2190 \u2207\u03d5(x), x \u2212 s (Frank-Wolfe gap) 7: g A \u2190 \u2207\u03d5(x), v \u2212 x (Away gap) 8: if g F W \u2265 g A then (FW direction is better) 9: d \u2190 s \u2212 x and \u03b3 max \u2190 1 10: else (Away direction is better) 11: d \u2190 x \u2212 v and \u03b3 max \u2190 \u03b1 v /(1 \u2212 \u03b1 v )x t = v\u2208St \u03b1 (t) v v, and y t = v\u2208At \u03be (t) v M v ,(5)\nWhen we choose to use the AFW Alg. 1 as inner loop algorithm, it can choose an away direction to remove mass from \"bad\" atoms in the active set, i.e. to reduce \u03b1 (t) v for some v (see L11 of Alg. 1), thereby avoiding the zig-zagging phenomenon that prevents\n\n\nFW Augmented Lagrangian method (FW-AL)\n\nAt each iteration t \u2265 1, we update the primal variable blocks x t with a Frank-Wolfe step and then update the dual multiplier y t using the updated primal variable:\n\uf8f1 \uf8f2 \uf8f3 x t+1 = FW(x t ; L(\u00b7, y t )) , y t+1 = y t + \u03b7 t M x t+1 ,(6)\nwhere \u03b7 t > 0 is the step size for the dual update and FW is either Alg. 1 or Alg. 2 (see more in App. A).\n\nFW from achieving a faster convergence rate (Lacoste-Julien and Jaggi, 2015). On the other hand, the maximal step size for an away step can be quite small\n(\u03b3 max = \u03b1 (t) v /1\u2212\u03b1 (t) v , where \u03b1 (t)\nv is the weight of the away vertex in (5)), yielding to arbitrary small suboptimality progress when the line-search is truncated to such small step-sizes. A step removing an atom from the active set is called a drop step (this is further discussed in Appendix A), and Alg. 1 loops until a non-drop step is obtained. It is important to be able to upper bound the cumulative number of drop-steps in order to guarantee the termination of the inner loop Alg. 1 (Alg. 1 ends only when it performs a non-drop step). In App. A.1 we prove that the cumulative number of drop-steps after t iterations cannot be larger than t + 1.\n\n\nAnalysis of FW-AL\n\nSolutions of (OPT2) are called saddle points, equivalently a vector (x * , y * ) \u2208 X \u00d7 R d is said to be a saddle point if the following is verified for all (x, y) \u2208 X \u00d7 R d ,\nL(x * , y) \u2264 L(x * , y * ) \u2264 L(x, y * ) .(7)\nOur assumptions (convexity of f and X , feasibility of M x = 0, and crucially boundedness of X ) are sufficient for strong duality to hold (Boyd and Vandenberghe, 2004, Exercise 5.25(e)). Hence, the set of saddle points is not empty and is equal to X * \u00d7 Y * , where X * is the set of minimizer of (OPT) and Y * the set of maximizers of the augmented dual function d:\nd(y) := min x\u2208X L(x, y) .(8)\nOne of the issue of ALM is that it is a non-feasible method and thus the function suboptimality is no longer a satisfying convergence criterion (since it can be negative). In the following section, we explore alternatives criteria to get a sufficient condition of convergence.\n\n\nConvergence Measures\n\nVariants of ALM (also known as the methods of multipliers) update at each iteration both the primal variable and the dual variable. For the purpose of analyzing the popular ADMM algorithm, Hong and Luo (2017) introduced two positive quantities which they called primal and dual gaps that we re-use in the analysis of our algorithm. Let x t and y t be the current primal and dual variables after t iterations of the FW-AL algorithm (6), the dual gap is defined as\n\u2206 (d) t := d * \u2212 d(y t ) where d(y t ) := min x\u2208X L(x, y t ) (9)\nand d * := max y\u2208R d d(y). It represents the dual suboptimality at the t-th iteration. On the other hand, the \"primal gap\" at iteration t is defined as\n\u2206 (p) t := L(x t+1 , y t ) \u2212 d(y t ), t \u2265 0 .(10)\nNotice that \u2206 (p) t\n\nis not the suboptimality associated with the primal function p(\u00b7) := max y\u2208R d L(\u00b7, y) (which is infinite for every non-feasible x). In this paper, we also define the shorthand,\n\u2206 t := \u2206 (p) t + \u2206 (d) t .(11)\nIt is important to realize that since ALM is a nonfeasible method, the standard convex minimization convergence certificates could become meaningless. In particular, the quantity f (x t ) \u2212 f * might be negative since x t does not necessarily belong to the constraint set of (OPT). This is why it is important to consider the feasibility M x 2 .\n\nIn their work, Yen et al. (2016a,b);Huang et al. (2017) only provide a rate on both gaps (9) and (10) which is not sufficient to derive guarantees on either how close an iterate is to the optimal set or how small is the suboptimality of the closest feasible point. In this paper, we also prove the additional property that the feasibility M x 2 converges to 0 as fast as \u2206 t . But even with these quantities vanishing, the suboptimality of the closest feasible point can be significantly larger than the suboptimality of a point -close to the optimum. Concretely, let x \u2208 X and letx be its projection onto {x \u2208 X | M x = 0}, since f is L-smooth we know that,\n|f (x) \u2212 f (x) \u2212 \u2207f (x),x \u2212 x | \u2264 L 2 x \u2212x 2 .(12)\nOn one hand, if the gradient is large and its angle withx \u2212 x is not too small, f (x) may be significantly larger than f (x). On the other hand, if \u2207f (x) is not too large, we can upper bound the suboptimality atx. Concretely, by (12) we get,\nf (x) \u2264 f (x) + \u2207f (x) x \u2212x + L 2 x \u2212x 2 . (13)\nMoreover, sincex is the projection of x onto the nullspace of M we have that,\nM x \u03c3 max (M ) \u2264 x \u2212x \u2264 M x \u03c3 min (M ) .(14)\nThen, if M x \u2264 and f (x) \u2264 we have that\nf (x) \u2264 (1 + \u2207f (x) \u03c3min(M ) + L 2\u03c3min(M ) 2 ) .(15)\nThe bound (15) is not practical when the function appears to have gradients with large norms (which can be the case even close to the optimum for constrained optimization) or when M appears to have small nonzero eigenvalues. This is why we also consider the case where f is strongly convex, allowing us to provide a bound on the distance to the optimum x * (unique due to strong convexity).\n\n\nProperties of the augmented Lagrangian dual function\n\nThe augmented dual function plays a key role in our convergence analysis. One of our main technical contribution is the proof of a new property of this function which can be understood as a growth condition. This property is due to the smoothness of the objective function and the compactness of the constraint set. We will need an additional technical assumption called interior qualification (a.k.a Slater's conditions).\nAssumption 1. \u2203 x (k) \u2208 Relint(X k ), k \u2208 [K] s.t. K k=1 A k x (k) = 0.\nRecall that x \u2208 Relint(X ) if and only if x is an interior point relative to the affine hull of X . This assumption is pretty standard and weak in practice. It is a particular case of constraint qualifications (Holmes, 1975;Gowda and Teboulle, 1990). With this assumption, we can deduce a global property on the dual function that can be summarized as a quadratic growth condition on a ball of size L \u03bb D 2 and a linear growth condition outside of this ball. The optimization literature named such properties error bounds (Pang, 1997). Theorem 1 (Error bound). Let d be the augmented dual function (8), if f is a L-smooth convex function, X a compact convex set and if Assump. 1 holds, then there exist a constant \u03b1 > 0 such that for all y \u2208 R d ,\nd * \u2212 d(y) \u2265 \u03b1 2 2 min dist(y, Y * ) 2 L \u03bb D 2 , dist(y, Y * ) , (16) where D := max (x,x )\u2208X 2 x \u2212 x is the diameter of X and L \u03bb := L + \u03bb M M .\nThis theorem, proved in App. C.1, is crucial to our analysis. In our descent lemma (25), we want to relate the gap decrease to a quantity proportional to the gap. A consequence of (16) is a lower bound of interest: (26).\n\nIssue in previous proofs. In previous work, Yen et al. (2016a, Theorem 2) have a constant called R Y in the upper bound of \u2206 t which may be infinite and lead to the trivial bound \u2206 t \u2264 \u221e. Actually, R Y is an upper bound on the distance of the dual iterate y t to the optimal solution set Y * of the augmented dual function. Since this quantity is not proven to be bounded, an element is missing in the convergence analysis. In their convergence proof, Yen et al. \n\n\nSpecific analysis for FW-AL\n\nConvergence over general convex sets. When X is a general convex compact set and f is L-smooth, Algorithms 1 and 2 are able to perform a decrease on the objective value proportional to the square of the suboptimality (Jaggi, 2013, Lemma 5), (Lacoste-Julien and Jaggi, 2015, (31)), we will call this a sublinear decrease since it leads to a sublinear rate for the suboptimality: for any x \u2208 X , y \u2208 R d they compute x + := FW(x; L(\u00b7, y)), such that for all \u03b3 \u2208 [0, 1],\nL(x + , y)\u2212L(x, y) \u2264 \u03b3(d(y) \u2212 L(x, y))+ \u03b3 2 L \u03bb D 2 2 ,(17)\nwhere L \u03bb is the Lipschitz constant of \u2207L and D the diameter of X . Recall that d(y) := min x \u2208X L(x , y). Note that setting \u03b3 = 0 gives L(x + , y) \u2264 L(x, y) and optimizing the RHS respect to \u03b3 yields a decrease proportional to (d(y) \u2212 L(x, y)) 2 . The GDMM algorithm of Yen et al. (2016a,b); Huang et al. (2017) relies on the assumption of X being polytope, hence we obtain under this general assumption of sublinear decrease a new result on ALM with FW. This result covers the case of the simultaneously sparse and low rank matrices (33) where the trace norm ball is not a polytope.\n\nTheorem 2 (Rate of FW-AL with Alg. 2). Under Assumption 1, if X is a convex compact set and f is a L-smooth convex function and M has the form described in (2), then using any algorithm with sublinear decrease (17) as inner loop in FW-AL (6) and\n\u03b7 t := min 2 \u03bb , \u03b1 2 2\u03b4 2 t+2 , we have that there exists a bounded t 0 \u2265 0 such that \u2200t \u2265 t 1 \u2265 t 0 , \u2206 t \u2264 4\u03b4(t 0 + 2) t + 2 , min t1\u2264s\u22121\u2264t M x s 2 \u2264 O(1) t \u2212 t 1 + 1 (18) where D := max x,x \u2208X x \u2212 x is the diameter of X , L \u03bb := L + \u03bb M M the Lipschitz constant of \u2207L, \u03b4 := L \u03bb D 2 and \u03b1 is defined in Thm. 1.\nIn App. D.2, we provide an analysis for different step size schemes and explicit bounds on t 0 .\n\nConvergence over Polytopes. On the other hand, if X is a polytope and f a generalized strongly convex function, recent advances on FW proposed global linear convergence rates using FW with away steps (Lacoste-Julien and Jaggi, 2015; Garber and Meshi, 2016). Note that in the augmented formulation, \u03bb > 0 and thus 1 2 M \u00b7 2 is a generalized strongly convex function, making L(\u00b7, y) a generalized strongly convex function for any y \u2208 R d (see App. A.3 for details). We can then use such linearly convergent algorithms to improve the rate of FW-AL. More precisely, we will use the fact that Algorithm 1 performs a geometric decrease (Lacoste-Julien and Jaggi, 2015, Theorem 1): for x + := FW(x; L(\u00b7, y)), there exists \u03c1 A < 1 such that for all x \u2208 X and y \u2208 R d ,\nL(x + , y)\u2212L(x, y) \u2264 \u03c1 A min x \u2208X L(x , y)\u2212L(x, y) .(19)\nThe constant \u03c1 A (Lacoste-Julien and Jaggi, 2015) depends on the smoothness, the generalized strong convexity of L(\u00b7, y) (does not depend on y, but depends on M ) and the condition number of the set X depending on its geometry (more details in App. A.3).\n\nTheorem 3 (Rate of FW-AL with inner loop Alg. 1).\n\nUnder the same assumptions as in Thm. 2 and if moreover X is a polytope and f a generalized strongly convex function, then using Alg 1 as inner loop and a constant step size \u03b7 t = \u03bb\u03c1 A 4 , the quantity \u2206 t decreases by a uniform amount for finite number of steps t 0 as,\n\u2206 t+1 \u2212 \u2206 t \u2264 \u2212 \u03bb\u03b1 2 \u03c1 A 8 ,(20)\nuntil \u2206 t0 \u2264 L \u03bb D 2 . Then for all t \u2265 t 0 we have that the gap and the feasibility violation decrease linearly as,\n\u2206 t \u2264 \u2206 t0 (1 + \u03c1) t\u2212t0 , M x t+1 2 \u2264 16 \u03bb \u00b7 \u03c1 A \u2206 t0 (1 + \u03c1) t\u2212t0 , where \u03c1 := min \u03c1 A 2 , \u03c1 A \u03bb\u03b1 2 8L \u03bb D 2 and L \u03bb := L + \u03bb M M .\nStrongly convex functions. When the objective function f is strongly convex, we are able to give a convergence rate for the distance of the primal iterate to the optimum. As argued in Sec. 4.1, an iterate close to the optimal point lead to a \"better\" approximate solution than an iterate achieving a small gap value.\n\nTheorem 4. Under the same assumptions as in Thm. 2, if f is a \u00b5-strongly convex function, then the set of optimal solutions X * is reduced to {x * } and for any t \u2265 t 1 \u2265 8t 0 + 14,\nmin t1+1\u2264s\u2264t+1 x t \u2212 x * 2 \u2264 4 \u00b5 O(1) t \u2212 t 1 + 1 .(21)\nMoreover, if X is a compact polytope, and if we use Alg. 1, then the distance of the current point to the optimal set vanishes as (with \u03c1 as defined in Thm. 3):\nx t+1 \u2212 x * 2 \u2264 2\u2206 t0 ( \u221a 2 + 1) \u00b5( \u221a 1 + \u03c1) t\u2212t0 + O(1) (1 + \u03c1) t\u2212t0 . (22)\nThis theorem is proved in App. D (Cor. 2 and Cor. 3). For an intersection of sets, the three theorems above give stronger results than (Yen et al., 2016b;Huang et al., 2017) since we prove that the distance to the optimal point as well as the feasibility vanish linearly.\n\nProof sketch of Thm 2 and 3. Our goal is to obtain a convergence rate on the sum gaps (9) and (10). First we show that the dual gap verifies\n\u2206 (d) t+1 \u2212 \u2206 (d) t \u2264 \u2212\u03b7 t M x t+1 , Mx t+1(23)\nwherex t+1 := arg min x\u2208X L(x, y t+1 ). Similarly, we prove the following inequality for the primal gap\n\u2206 (p) t+1 \u2212 \u2206 (p) t \u2264 \u03b7 t M x t+1 2 + L(x t+2 , y t+1 ) \u2212 L(x t+1 , y t+1 ) \u2212 \u03b7 t M x t+1 , Mx t+1 .(24)\nSumming (23) and (24) and\nusing that M x t+1 \u2212 Mx t+1 2 \u2264 2 \u03bb (L(x t+1 , y t+1 ) \u2212 L(x t+1 , y t+1 )), we get the following fundamental descent lemma, \u2206 t+1 \u2212 \u2206 t \u2264 L(x t+2 , y t+1 ) \u2212 L(x t+1 , y t+1 ) + 2\u03b7 t \u03bb (L(x t+1 , y t+1 ) \u2212 L(x t+1 , y t+1 )) \u2212 \u03b7 t Mx t+1 2 .(25)\nWe now crucially combine (16) in Thm. 1 and the fact that \u2206\n(d) t \u2264 dist(y t , Y * ) Mx t+1 to obtain, \u03b1 2 2L \u03bb D 2 min{\u2206 (d) t+1 , L \u03bb D 2 } \u2264 Mx t+1 2 ,(26)\nand then,\n\u2206 t+1 \u2212 \u2206 t \u2264 L(x t+2 , y t+1 ) \u2212 L(x t+1 , y t+1 ) + 2\u03b7 t \u03bb (L(x t+1 , y t+1 ) \u2212 L(x t+1 , y t+1 )) \u2212 \u03b7 t \u03b1 2 2L \u03bb D 2 min{\u2206 (d) t+1 , L \u03bb D 2 } .(27)\nNow the choice of the algorithm to get x t+2 from x t+1 and y t+1 is decisive:\n\nIf X is a polytope and if an algorithm with a geometric decrease (19) is used,\nsetting \u03b7 t = \u03bb\u00b7\u03c1 A 4 we obtain \u2206 t+1 \u2212 \u2206 t \u2264 \u2212 \u03c1 A 2 (L(x t+1 , y t+1 ) \u2212 L(x t+1 , y t+1 )) \u2212 \u03bb \u00b7 \u03c1 A 4 M x t+1 2 . Since L(x t+2 , y t+1 ) \u2264 L(x t+1 , y t+1 ) (L13), we have \u2206 (p) t+1 \u2264 L(x t+1 , y t+1 ) \u2212 L(x t+1 , y t+1 ) ,(28)\nleading us to a geometric decrease for all t \u2265 t 0 ,\n\u2206 t+1 \u2264 \u2206 t 1 + \u03c1 where \u03c1 := \u03c1 A 2 min 1, \u03bb\u03b1 2 8L \u03bb D 2 . (29)\nAdditionally we can deduce from (25) that,\n\u03b7 t Mx t+1 2 \u2264 \u2206 t and \u03b7 t M x t+1 2 \u2264 4\u2206 t . (30)\nIf X is not a polytope, we can use an algorithm with a sublinear decrease (17) to get from (27) \nthat \u2200t \u2265 0 , \u2206 t+1 \u2212 \u2206 t \u2264 \u2212a\u03b7 t min{\u2206 t+1 , \u03b4} + (a\u03b7 t ) 2 C 2 ,(31)\nwhere a, \u03b4 and C are three positive constants. Setting \u03b7 t = 2 a(t+2) we can prove that there exists t 0 \u2265 C \u03b4 s.t.,\n\u2206 t+1 \u2264 4\u03b4(2 + t 0 ) (t + 2) , \u2200t \u2265 t 0 .(32)\nProviding the claimed convergence results.\n\n\nIllustrative Experiments\n\nRecovering a matrix that is simultaneously low rank and sparse has applications in problems such as covariance matrix estimation, graph denoising and link prediction (Richard et al., 2012). We compared FW-AL with the proximal splitting method on a covariance matrix estimation problem. We define the \u00b7 1 norm of a matrix S as S 1 := i,j |S i,j | and its trace norm as\nS * := rank(S) i=1\n\u03c3 i , where \u03c3 i are the singular values of S in decreasing order. Given a symmetric positive definite matrix\u03a3 \u2208 R d\u00d7d we use the square loss as   strongly convex objective for our optimization problem,\nmin S 0, S 1\u2264\u03b21 , S * \u2264\u03b22 S \u2212\u03a3 2 2 .(33)\nThe linear oracle for X 1 :\n= {S 0, S 1 \u2264 \u03b2 1 } is LMO X1 (D) := \u03b2 1 Eij +Eji 2 , (i, j) \u2208 arg min (i,j)\u2208[d]\u00d7[d] D i,j +D j,i where (E ij ) is the standard basis of R d\u00d7d . The linear oracle for X 2 := {S 0, S * \u2264 \u03b2 2 } is LMO X2 (D) := \u03b2 2 \u00b7 U 1 U 1 ,(34)where D = [U 1 , . . . , U d ] diag(\u03c3 1 , . . . , \u03c3 d ) [U 1 , . . . , U d ] .\nFor this problem, the matrix D is always symmetric because the primal and dual iterates are symmetric as well as the gradients of the objective function. Eq. (34) can be computed efficiently by the Lanczos algorithm (Paige, 1971;Kuczy\u0144ski and Wo\u017aniakowski, 1992) whereas the forward backward splitting which is the standard splitting method to solve (33) needs to compute projections over the trace norm ball via a complete diagonalization which is O(d 3 ). For large d, the full diagonalization becomes untractable, while the Lanczos algorithm is more scalable and requires less storage (see Fig. 2).\n\nThe experimental setting is done following Richard et al.\n\n(2012): we generated a block diagonal covariance matrix \u03a3 to draw n vectors x i \u223c N (0, \u03a3). We use 5 blocks of the form vv where v \u223c U([\u22121, 1]). In order to enforce sparsity, we only kept the entries (i, j) such that |\u03a3 i,j | > .9. Finally, we add a gaussian noise N (0, \u03c3) on each entry x i and observe\u03a3 = n i=1\n\nx i x T i . In our experiment n = d, \u03c3 = 0.6. We apply our method, as well as the the generalized forward backward splitting used by Richard et al. (2012). This algorithm is the baseline in our experiments. It has been originally introduced by Raguet et al. (2013), to optimize (33) performing projections over the constraint sets. The results are presented in Fig. 1 and 2. We can say that our algorithm performs better than the baseline for high dimensional problems for two reasons: in high dimensions, only one projection on the trace norm ball B * can take hours (green curve in Fig. 2) whereas solving a LMO over B * takes few seconds. Moreover, the iterates computed by FW-AL are naturally sparse and low rank, so we then get a better estimation of the covariance matrix at the beginning of the optimization as illustrated in Fig. 1b and 1c \n\n\nA Frank-Wolfe inner Algorithms\n\n\nA.1 Upper bound on the number of drop-steps\n\nProposition 1 (Sparsity of the iterates and upper bound on the number of drop-steps). The iterates computed by FW-AL have the following properties, 1. After t iterations, the iterates x t (resp. y t ) are a convex (resp. conic) combination of their initialization and the oracle's outputs (resp. times M ) for the first t iterations.\n\n2. If the algorithm FW is AFW (Alg. 1), and if we initialize our algorithm at a vertex, after t iterations of the main loop the cumulative number of drop-steps performed in the inner algorithm 1 is upper bounded by t + 1.\n\nProof. The first point comes from (5).\n\nA drop step happens when \u03b3 t = \u03b3 max in the away-step update L. 13 of Alg. 1. In that case, at least one vertex is removed from the active set. The upper bound on the number of drop step can be proven with the same technique as in (Lacoste-Julien and Jaggi, 2015, Proof of Thm. 8). Let us call A t the number of FW steps (which potentially adds an atom in S t ) and D t the number of drop-steps, i.e., the number of away steps where at least one atom from S t have been removed (and thus \u03b3 t = \u03b3 max for these). Considering FW-AL with AFW after t iterations we have performed t non drop-steps in the inner loop, since it is the condition to end the inner loop, then\nA t \u2264 t, and A t \u2212 D t + |S 0 | \u2265 |S t | \u2265 0 .(35)\nSince by assumption |S 0 | = 1, this leads directly to D t \u2264 A t + 1 \u2264 t + 1.\n\n\nA.2 Other FW Algorithms Available\n\nAny Frank-Wolfe algorithm performing geometric decrease (19) or sublinear decrease (17) \n\n\nA.3 Constants for the sublinear and geometric decrease\n\nIn order to be self-contained, we will introduce the definitions of the constants introduced in the definition of sublinear decrease (17) and geometric decrease (19).\n\nSublinear Decrease. Let us first recall Equation (17) describing the sublinear decrease:\nL(x + , y) \u2212 L(x, y) \u2264 \u2212\u03b3 L(x, y) \u2212 min x \u2208X L(x , y) + \u03b3 2 L \u03bb D 2 2 .\nThe sublinear decrease is a consequence of the standard descent lemma (Nesterov, 2004, (1.2.5)). The constant L \u03bb is the smoothness of L and D the diameter of X . This property has been proved for the block-coordinate If f is L-smooth we have that the function L(\u00b7, y) is L \u03bb := L + \u03bb M M -smooth for any y \u2208 R d , and then,\nL \u03bb D 2 \u2264 L + \u03bb M M D 2 X .(36)\nRecall that, for matrices \u00b7 is the spectral norm.\n\nGeometric Decrease. If the function f is a generalized strongly convex function, then L(\u00b7, y) is also a generalized strongly convex function. More generally, let h 1 and h 2 be two generalized strongly convex functions. Then according to the definition (4), there exist A 1 , A 2 , b 1 , b 2 and two strongly convex functions g 1 , g 2 such that, h 1 (x) = g 1 (A 1 x) + b 1 , x and h 2 (x) = g 2 (A 2 x) + b 2 , x . Thus,\nh 1 (x) + h 2 (x) = g 1 (A 1 x) + b 1 , x + g 2 (A 2 x) + b 2 , x = g(Ax) + b, x ,(37)\nwhere\nAx = [A 1 x; A 2 x], b = [b 1 ; b 2 ] and g([u; v]) = g 1 (u) + g 2 (v).\nThe function g is strongly convex by strong convexity of g 1 and g 2 .\n\nWe can say that since L(\u00b7, y) is a generalized strongly convex function (with a constant uniform on y) and X a polytope, we have the geometric descent lemma from Lacoste-Julien and Jaggi (2015, Theorem 1). The constant \u03c1 A is the following\n\u03c1 A := \u00b5 \u03bb 4L \u03bb \u03b4 X D X 2 ,(38)\nwhere \u00b5 \u03bb and L \u03bb are respectively the generalized strong convexity constant (Lacoste-Julien and Jaggi, 2015, Lemma 9) and the smoothness constant of x \u2192 f (x) + \u03bb 2 M x 2 , and D X and \u03b4 X are respectively the diameter and the pyramidal width of X as defined by Lacoste-Julien and Jaggi (2015). Note that if M is full rank, the strong convexity constant \u00b5 is lower bounded by \u03bb\u03c3 2 min where \u03c3 2 min is the smallest singular value of M . Otherwise, if M is not full rank, one can still use the lower bound on the generalized strong convexity constant given by Lacoste-Julien and Jaggi (2015, Lemma 9).\n\n\nB Previous work\n\n\nB.1 Discussion on previous proofs\n\nThe convergence result stated by Yen et al. (2016a, Theorem 2) is the following (with our notation)\n\u2206 (p) t + \u2206 (d) t \u2264 \u03c9 t where \u03c9 := 4 1 \u2212 \u03c1 A max \u2206 (p) 0 + \u2206 (d) 0 , 2R 2 Y /\u03bb ,(39)\nand R Y := sup t\u22650 dist(y t , Y * ). This quantity was introduced in the last lines of the appendix without any mention to its boundedness. In our opinion, it is as challenging to prove that this quantity is bounded as to prove that \u2206 t converges.\n\nIn more recent work, Yen et al. (2016b) and Huang et al. (2017) use a different proof technique in order to prove a linear convergence rate for their algorithm. In order to avoid getting the same problematic quantity R Y , they use Lemma 3.1 from (Hong and Luo, 2012) (which also appears as Lemma 3.1 in the published version (Hong and Luo, 2017)). This lemma states a result not holding for all y \u2208 R d but instead for (y t ) t\u2208N , which is the sequence of dual variables computed by the algorithm introduced in (Hong and Luo, 2017). This sequence cannot be assimilated to the sequence of dual variables computed by the GDMM algorithm since the update rule for the primal variables in each algorithm is different: the primal variable are updated with FW steps in one algorithm and with a proximal step in the other. The properties of this proximal step are intrinsically different from the FW steps computing the updates on the primal variables of FW-AL. One way to adapt this Lemma for FW-AL (or GDMM) would be to use (Hong and Luo, 2017, Lemma 2.3 c). Unfortunately, this result is local (only true for all y \u2208 Y such that \u2207d(y) \u2264 \u03b4 with \u03b4 fixed), whereas a global result (true for all \u03b4) seems to be required with the proof technique used in (Yen et al., 2016b;Huang et al., 2017). It is also mentioned in (Hong and Luo, 2017, proof of Lemma 2.3 c) that \"if in addition y also lies in some compact set Y, then the dual error bound hold true for all y \u2208 Y\" then showing that R Y is bounded would fix the issue, but as we mentioned before, we think that this is at least as challenging as showing convergence of \u2206 t . To our knowledge, there is no easy fix to get a result as the one claimed by Yen et al. (2016b, Lemma 4) or Huang et al. (2017, Lemma 4).\n\n\nB.2 Comparison with UniPDGrad\n\nThe Universal Primal-Dual Gradient Method (UniPDGrad) by Yurtsever et al. (2015) is a general method to optimize problem of the form, min\nu\u2208C {f (u) : Au \u2212 b \u2208 K} ,(40)\nwhere f is a convex function, A is a matrix, b a vector and C and K two closed convex sets. (OPT) is a particular case of their framework. There exist many ways to reformulate their framework for our application, but most of them are not practical because they require too expensive oracles. If the problem,\n\narg min\nx\u2208X f (x) + y, M x(41)\nis easy to compute (which is not the case in practice most of the time but happens when f is linear) then we can set C = X , K = {0}, u = x, A = M andf = f . Otherwise, we propose the reformulation that seemed to be the most relevant, this is the reformulation used in their experiments (Yurtsever et al., 2015, Eq.19 & 41). If we set\nK = {0}, C = R p \u00d7 X , u = (x, r), b = 0,f (u) = f (r) and A such that Au = (M x, x \u2212 r) we get, min r\u2208R p , x\u2208X {f (r) : x = r, M x = 0} ,(42)\nwhich is a reformulation of (OPT). They derive their algorithm optimizing the (negative) Lagrange dual function g. The Lagrange function is,\nL(x, r, y, \u03bb) := f (r) \u2212 \u03bb, r \u2212 x + y, M x(43)\nwhere \u03bb is the dual variable associated with the constrain r = x. Then, the (negative) Lagrange dual function is,\ng(\u03bb, y) = \u2212 min x\u2208X ,r\u2208R p f (r) \u2212 \u03bb, r \u2212 x + y, M x = \u2212 min r\u2208R p f (r) \u2212 \u03bb, r \u2212 min x\u2208X M y + \u03bb, x = \u2212f * (\u03bb) \u2212 min x\u2208X M y + \u03bb, x .(44)\nTheir algorithm optimizes this dual function. Computing the subgradients of the function g requires to compute the Fenchel conjugate of f and a LMO.\n\nNote that FW-AL does not require the efficient computation of the Fenchel conjugate.\n\nUniPDGrad computes different updates than FW-AL and require different assumptions for the theoretical guaranties. Particularly, Yurtsever et al. (2015) assume the H\u00f6lder continuity of the dual function g. Since, in practice, the LMO is not better than 0-H\u00f6lder continuous (i.e. has bounded subgradient), we have to also assume that f * has bounded subgradients to insure the 0-Holder continuity of the dual function. By duality, if the subgradients of f * are bounded then the support of f is bounded. It is a strong assumption if we want to be able to compute the Fenchel conjugate of f . Nevertheless, it seems that their proof could be extended to a dual function g written as a sum of H\u00f6lder continuous functions with different H\u00f6lder continuity parameters. It would extend UniPDGrad convergence result to f strongly convex (f * 1-H\u00f6lder continuous).\n\nIn terms of rate both algorithms are hard to compare since the assumptions are different but in any case the analysis of UniPDGrad does not provide a geometric convergence rate when the constraint set X is a polytope (and f a generalized strongly convex function).\n\nIt remains an open question to explore more in details and compare all the possible reformulation of (40) to optimize (OPT) with UniPDGrad.\n\n\nC Technical results on the Augmented Lagrangian formulation\n\nLet us recall that the Augmented Lagrangian function is defined as\nL(x, y) := f (x) + 1 X (x) + y, M x + \u03bb 2 M x 2 , \u2200(x, y) \u2208 R m \u00d7 R d ,(45)\nwhere f is an L-smooth function, 1 X is the indicator function over the convex compact set X := X 1 \u00d7. . .\u00d7X K \u2282 R m , M is the matrix defined in (1), and m = d 1 + . . . + d K . The augmented dual function d is\nd(y) := min x\u2208X L(x, y) .(46)\nStrong duality ensures that X * \u00d7 Y * is the set of saddle points of L where X * is the optimal set of the primal function p defined as,\np(x) := max y\u2208R d L(x, y)(47)\nand Y * is the optimal set of d. In this section we will first prove that the augmented dual function is smooth and have a property similar to strong convexity around its optimal set. It will be useful for subsequent analyses to detail the properties of the augmented Lagrangian function L.\n\n\nC.1 Proof of Theorem 1\n\nIn this section we prove Theorem 1. We start with some properties of the dual function d. This function can be written as the composition of a linear transformation and the Fenchel conjugate of\nf \u03bb (x) := f (x) + \u03bb 2 M x 2 + 1 X (x) ,(48)\nwhere 1 X is the indicator function of X . More precisely, if we denote by : f \u2192 f * the Fenchel conjugate operator, then we have,\nd(y) := min x\u2208R m L(x, y) = \u2212 max x\u2208R m \u2212M y, x \u2212 f \u03bb (x) = \u2212f \u03bb (\u2212M y) .(49)\nSmoothness of the augmented dual function. The smoothness of the augmented dual function is due to the duality between strong convexity and strong smoothness (Rockafellar and Wets, 1998). In order to be self-contained, we provide the proof of this property given by Hong and Luo (2017).\n\nProposition 2 (Lemma 2.2 (Hong and Luo , 2017)). If f is convex, the dual function d (46) is 1/\u03bb-smooth, i.e.,\n\u2207d(y) = Mx(y), wherex(y) \u2208 arg min x\u2208X L(x, y) , \u2200y \u2208 R d ,(50)\nand\n\u2207d(y) \u2212 \u2207d(y ) \u2264 1 \u03bb y \u2212 y \u2200 y, y \u2208 R d .(51)\nProof. We will start by showing that the quantity Mx(y) has the same value for allx(y) \u2208 arg min x\u2208X L(x, y). We reason by contradiction and assume there exists x, x \u2208 arg min x\u2208X L(x, y) such that M x = M x . Then by convexity of f and strong convexity of \u00b7 2 we have that\nd(y) = 1 2 L(x, y) + 1 2 L(x , y) > f (x) + y, Mx + \u03bb 2 Mx 2 = L(x, y) ,(52)\nwherex := x+x 2 and the inequality is strict because we assumed M x = M x . This contradict the assumption that x, x \u2208 arg min x\u2208X L(x, y). To conclude, Danskin (1967)'s Theorem claims that \u2202d(y) = {Mx(y), |x(y) \u2208 arg min x\u2208X L(x, y)} which is a singleton in that case. The function d is then differentiable.\n\nFor the second part of the proof, let y, y \u2208 R m and let x, x \u2208 X be two respective minimizers of L(\u00b7, y) and L(\u00b7, y ). Then by the first order optimality conditions we have\n\u2207f (x) + M y + \u03bbM M x, x \u2212 x \u2265 0, \u2207f (x ) + M y + \u03bbM M x , x \u2212 x \u2265 0 .(53)\nAdding these two equation gives,\n\u2207f (x) \u2212 \u2207f (x ) + M (y \u2212 y ) + \u03bbM M (x \u2212 x ), x \u2212 x \u2265 0 ,(54)but since f is convex, \u2207f (x) \u2212 \u2207f (x ), x \u2212 x \u2265 0, and so y \u2212 y , M (x \u2212 x) \u2265 \u2212\u03bb M (x \u2212 x ), M (x \u2212 x) .(55)\nFinally, by the Cauchy-Schwarz inequality, we have\ny \u2212 y \u2265 \u03bb M x \u2212 M x = \u03bb \u2207d(y) \u2212 \u2207d(y ) .(56)\nError bound on the augmented dual function. After having proved that the dual function is smooth, we will derive an error bound (Pang, 1997(Pang, , 1987 on this function. Error bounds are related the Polyak-\u0141ojasiewic (PL) condition first introduced by Polyak (1963) and the same year in a more general setting by \u0141ojasiewicz (1963).\n\nRecently, convergence under this condition has been studied with a machine learning perspective by Karimi et al. (2016).\n\nRecall that, in this section, our goal is to prove Thm. 1. We start our proof with lemma using the smoothness of L.\n\nLemma 1. Let d be the augmented dual function (49), if f is a L-smooth convex function and X a compact convex set, then for all y \u2208 R d and y * \u2208 Y * ,\nd * \u2212 d(y) \u2265 1 2L \u03bb D 2 min max x\u2208X y * \u2212 y, M x 2 , L \u03bb D 2 max x\u2208X y * \u2212 y, M x(57)\nwhere D := max (x,x )=\u2208X 2 is the diameter of X and L \u03bb := L + \u03bb M M .\n\nProof. Let us consider x \u2208 X \u2282 R p , n \u2208 \u2202f \u03bb (x) a subgradient of f \u03bb and the function g x defined as:\ng x (u) := f \u03bb (u + x) \u2212 f \u03bb (x) \u2212 u, n , \u2200u \u2208 R p .(58)\nSince f + \u03bb 2 M \u00b7 2 is L \u03bb -smooth, we have that g x (u) \u2264 L \u03bb 2 u 2 + 1 X (u + x) =: h x (u), \u2200u \u2208 R m . By standard property of Fenchel dual (see for instance (Shalev-Shwartz and Singer, 2010, Lemma 19)) we know that\ng x (u) \u2264 h x (u), \u2200u \u2208 R m \u21d2 g x (v) \u2265 h x (v) , \u2200v \u2208 R m .(59)\nDual computations give us for all v,\ng x (v) = max u\u2208R m [ u, v \u2212 f \u03bb (u + x) + u, n ] + f \u03bb (x) = max u\u2208R m [ u, v + n \u2212 f \u03bb (u + x)] + f \u03bb (x) = f \u03bb (v + n) + f \u03bb (x) \u2212 x, v + n = f \u03bb (v + n) \u2212 f \u03bb (n) \u2212 x, v ,(60)\nwhere in he last line we used that \u2200n \u2208 \u2202f \u03bb (x), x, n = f \u03bb (x) + f \u03bb (n) (for a proof see for instance, (Shalev-Shwartz and Singer, 2010, Lemma 17)).\n\nBy strong duality we have that X * \u00d7 Y * is the set of saddle points, where X * and Y * are respectively the optimal sets of p(\u00b7) and d(\u00b7), respectively introduced in (47) and (46). In the following we will fix a pair (x * , y * ) \u2208 X * \u00d7 Y * . Then by the stationary conditions we have M y * \u2208 \u2212\u2202f \u03bb (x * ), and M x * = 0 .\n\nEquivalently, there exist n \u2208 \u2202f \u03bb (x * ) such that\nn = \u2212M y * .(62)\nFor all y * \u2208 Y * we can set x = x * and n \u2208 \u2202f \u03bb (x * ) such that n = \u2212M y * in (58) to get the following inequality,\nd * \u2212 d(v + y * ) = f \u03bb (\u2212M v \u2212 M y * ) \u2212 f \u03bb (\u2212M y * ) (62) = f \u03bb (\u2212M v + n) \u2212 f \u03bb (n) (61) = f \u03bb (\u2212M v + n) \u2212 f \u03bb (n) \u2212 x * , \u2212M v (60) = g (\u2212M v) (59) \u2265 h x * (\u2212M v) , \u2200v \u2208 R d ,(63)\nwhere for all v \u2208 R d ,\nh x * (\u2212M v) := max x\u2208R m [ x, \u2212M v \u2212 h x * (x)] (64) = max x\u2208R m [ x, \u2212M v \u2212 L \u03bb 2 x 2 \u2212 1 X (x + x * )] (65) = max x+x * \u2208X [ x, \u2212M v \u2212 L \u03bb 2 x 2 ](66)\nLet us choose y \u2208 R d and set v = y \u2212 y * , where y * = P Y * (y). Then combining (63) and (66) we get for all x \u2208 X , and \u03b3 \u2208 [0, 1] that \u03b3x + (1 \u2212 \u03b3)x * \u2208 X and then,\nd * \u2212 d(y) \u2265 \u2212\u03b3 M (y \u2212 y * ), x \u2212 x * \u2212 L \u03bb 2 \u03b3 2 x \u2212 x * 2 (67) \u2265 1 2 2\u03b3 y \u2212 y * , \u2212M x \u2212 \u03b3 2 L \u03bb D 2 ,(68)\nwhere D := max (x,x )\u2208X 2 x \u2212 x is the diameter of X . Since d * \u2265 d(y) the last equation can give a non trivial lower bound when max x\u2208X y \u2212 y * , \u2212M x > 0, we will now prove that is it always the case when y / \u2208 Y * .\n\nIn this proof, for x \u2208 X we note N X c (x) the normal cone to X at x defined as\nN X c (x) := {u \u2208 R m | u, x \u2212 x \u2265 0 , \u2200x \u2208 X }(69)\nthe reader can refers to (Bauschke and Combettes, 2011) for more properties on the normal cone. If y / \u2208 Y * , then the necessary and sufficient stationary conditions lead to (recall that M x * = 0)\n\u2207f (x * ) + M y / \u2208 \u2212N X c (x * ) ,(70)\nthat is, there exist x \u2208 X such that \u2207f (x * ) + M y, x \u2212 x * < 0. Using (62) gives\n0 > \u2207f (x * ) + M y, x \u2212 x * (62) = \u2212M y * \u2212 u + M y, x \u2212 x * \u2265 y \u2212 y * , M x ,(71)\nwhere for the last inequality we use the fact that u \u2208 N X c (x * ) and M x * = 0. Then we have\nmax x\u2208X y \u2212 y * , \u2212M x > 0, \u2200y / \u2208 Y * .(72)\nOptimizing Eq. (68) with respect to \u03b3 \u2208 [0, 1] we get the following:\n\n\u2022 If 0 < max x\u2208X y * \u2212 y, M x \u2264 L \u03bb D 2 , the optimum of (68) is achieved for \u03b3 = max x\u2208X y * \u2212y,M x L \u03bb D 2 \u2264 1 and we have,\nd * \u2212 d(y) \u2265 1 2L \u03bb D 2 max x\u2208X y * \u2212 y, M x 2 ,(73)\n\u2022 Otherwise, if max x\u2208X y * \u2212 y, M x > L \u03bb D 2 , the optimum of (68) is achieved for \u03b3 = 1, giving\nd * \u2212 d(y) \u2265 1 2 max x\u2208X 2 y * \u2212 y, M x \u2212 L \u03bb D 2 \u2265 1 2 max x\u2208X y * \u2212 y, M x .(74)\nCombining both cases leads to\nd * \u2212 d(y) \u2265 1 2L \u03bb D 2 min max x\u2208X y * \u2212 y, M x 2 , L \u03bb D 2 max x\u2208X y * \u2212 y, M x .(75)\nSince our goal is to get an error bound on the dual function d we divide and multiply by y \u2212 y * the quantities max x\u2208X y * \u2212 y, M x in (75), making appear the desired norm and a constant \u03b1 defined as\n\u03b1 := inf y\u2208R d \\Y * y * =P Y * (y) sup x\u2208X y * \u2212 y y * \u2212 y , M x .(76)\nRecall that y * := P Y * (y) and consequently y \u2212 y * = dist(y, Y * ). Our goal is now to show that \u03b1 > 0.\n\nProof that \u03b1 is positive. In order to prove that \u03b1 is positive we need to get results on the structure of Y * . First, let us start with a topological lemma,\nLemma 2. Let (C k ) k\u2208[K]\nbe a collection of nonempty convex sets. We have that\n0 \u2208 Relint(C k ) , k \u2208 [K] \u21d2 0 \u2208 Relint K + k=1 C k .(77)\nProof. In order to prove this result we will prove two intermediate results.\n\nRecall that the cone Cone(C) generated by a convex set C is defined as\nCone(C) := {\u03bbx : x \u2208 C} .(78)\nFor more details on the topological properties of the convex set set for instance (Rockafellar, 1970).\n\n\u2022 The first one is a characterization:\n0 \u2208 Relint(C) \u21d4 Cone(C) = Span(C) .(79)\u21d2: Let x \u2208 C, x \u2208 Span(C) \u21d2 \u2203 \u03bb i \u2208 R, x i \u2208 C, i \u2208 {1, . . . , n} s.t. x = n i=1 \u03bb i x i \u21d2 \u2203 \u03bb i \u2208 R, x i \u2208 C, i \u2208 {1, . . . , n} s.t. x = \u03bb n i=1 \u03bb i x i \u03bb , \u03bb > 0 \u21d2 \u2203\u03bb > 0 ,x i \u2208 C , i \u2208 {1, . . . , n} s.t. x = \u03bb n i=1x i \u21d2 x \u2208 Cone(C) .\nwhere the last line is due to the fact that for \u03bb small enough \u03bbixi \u03bb \u2208 C because 0 \u2208 Relint(C). By definition we have that Cone(C) \u2282 Span(C).\n\nThen, we have proved that 0 \u2208 Relint(C) \u21d2 Cone(C) = Span(C) Otherwise, let x \u2208 Relint(C) \\ {0}, using our hypothesis we have that,\n\u2212x \u2208 Span(C) = Cone(C) \u21d4 0 \u2208 Cone(C) + x .(80)\nThen there exist x \u2208 C and \u03bb > 0 such that,\n0 = \u03bbx + x \u21d4 0 = \u03bb 1 + \u03bb x + 1 1 + \u03bb x .(81)\nSince 1 \u2265 1 1+\u03bb > 0 and x \u2208 Relint(C), we have by (Rockafellar, 1970, Theorem 6.1) that 0 \u2208 Relint(C).\n\n\u2022 The second one is a property on the sum of the convex cones generated by (C k ):\n0 \u2208 Relint(C k ) , k \u2208 {1, . . . , K} \u21d2 K + k=1 Cone(C k ) = Cone K + k=1 C k .(82)\nLet, then,\nx \u2208 K + k=1 Cone(C k ) \u21d4 \u2203x k \u2208 Cone(C k ), k \u2208 {1, . . . , K} s.t. x = k k=1x k \u21d4 \u2203x k \u2208 C k , \u03bb k \u2208 R , k \u2208 {1, . . . , K} s.t. x = k k=1 \u03bb k x k \u21d4 \u2203x k \u2208 C k , \u03bb k \u2208 R , k \u2208 {1, . . . , K} s.t. x = \u03bb k k=1 \u03bb k x k \u03bb , \u03bb > 0 \u21d4 x \u2208 Cone K + k=1 C k .\nFor the last equivalence we used that 0 \u2208 Relint(C k ) , k \u2208 {1, . . . , K}.\n\nNow we can prove our lemma using (79) and (82):\n0 \u2208 Relint(C k ) , k \u2208 [K] (79) \u21d2 Cone(C k ) = Span(C k ) , k \u2208 [K] 0 \u2208 Relint(C k ) , k \u2208 [K] (82) \u21d2 Cone K + k=1 C k = K + k=1 Cone(C k ) = K + k=1 Span(C k ) = Span K + k=1 C k (79) \u21d2 0 \u2208 Relint K + k=1 C k\nLet us recall the supplementary assumption needed to prove Theorem 1.\n\nAssumption' 1. \u2203x (k) \u2208 Relint(X k ), k \u2208 {1, . . . , K}, s.t.,\nK k=0 A kx (k) = 0.\nThis assumption is required in the proof of the following lemma, Lemma 3. Under Assumption 1, the optimal set Y * of the augmented dual function d(\u00b7) (49) can be written as\nY * = K + V ,(83)\nwhere V := \u2229 K k=1 A k (Span(X k \u2212x (k) )) \u22a5 and K \u2282 V \u22a5 is a compact set.\n\nWe define Span(X k \u2212x (k) ) as the linear span of the feasible direction fromx (k) . Sincex (k) is a relative interior point of the convex X k we have Span(\nX k \u2212x (k) ) = {\u03bb(x (k) \u2212x (k) ) : x (k) \u2208 X k , \u03bb > 0}.\nProof. For any x * \u2208 X * , a necessary and sufficient condition for any y * to be in Y * is\n\u2207f (x * ) + M y * \u2208 \u2212N c (x * ) ,(84)meaning that \u2212A k y * \u2208 N X k c (x * ) + \u2207 x (k) f (x * ) , k \u2208 {1, . . . , K} .(85)\nThen noting g k := \u2207 x (k) f (x * ) + \u03bbM x we have the following equivalences,\ny * \u2208 Y * \u21d4 \u2212A k y * \u2208 N X k c (x * ) + g k , k \u2208 {1, . . . , K} \u21d4 A k y * + g k \u2208 \u2212N X k c (x * ) , k \u2208 {1, . . . , K} \u21d4 \u2212A k y * \u2212 g k , x (k) \u2212 (x * ) (k) \u2264 0 ; \u2200x (k) \u2208 X k , k \u2208 {1, . . . , K} \u21d4 \u2212y * , A k (x (k) \u2212 (x * ) (k) ) \u2264 g k , x (k) \u2212 (x * ) (k) ; \u2200x (k) \u2208 X k , k \u2208 {1, . . . , K}\nThen we can notice that if we write y * = y * 1 + y * 2 with y *\n1 \u2208 V := \u2229 K k=1 A k (Span(X k \u2212x (k) ) \u22a5 and y * 2 \u2208 V \u22a5 we get, y * \u2208 Y * \u21d4 \u2212y * 2 , A k (x (k) \u2212 (x * ) (k) ) \u2264 g k , x (k) \u2212 (x * ) (k) ; \u2200x (k) \u2208 X k , k \u2208 [K] .(86)\nNote that there is no conditions on y * 1 . Let us get a necessary condition on y * 2 . Eq. (86) implies,\ny * \u2208 Y * \u21d2 \u2212y * 2 , K k=1 A k (x (k) \u2212 (x * ) (k) ) \u2264 K k=1 g k , x (k) \u2212 (x * ) (k) ; \u2200x (k) \u2208 X k , k \u2208 [K] \u21d2 \u2212y * 2 , K k=1 A k (x (k) \u2212 (x * ) (k) ) \u2264 K k=1 g k x (k) \u2212 (x * ) (k) ; \u2200x (k) \u2208 X k , k \u2208 [K] \u21d2 \u2212y * 2 , K k=1 A k (x (k) \u2212x (k) ) \u2264 K k=1 g k diam(X k ) ; \u2200x (k) \u2208 X k , k \u2208 [K] , (x * andx are feasible, i.e., K k=1 A kx (k) = K k=1 A k (x * ) (k) = 0) wherex (k) \u2208 Relint(X k ), k \u2208 [K] and Mx = 0 (Assump. 1). Moreover, since V := \u2229 K k=1 A k (Span(X k \u2212x (k) )) \u22a5 we have that V \u22a5 = K + k=1 A k (Span(X k \u2212x (k) ))\n. Then by Lemma 2,\nx \u2208 Relint(X ) \u21d2 0 \u2208 Relint(A k (X k \u2212x (k) )) k \u2208 {1, . . . , K} (77) \u21d2 0 \u2208 Relint K + k=1 A k (X k \u2212x (k) ) ,\nand consequently, there exists \u03b4 > 0 such that for all y * 2 \u2208 K + k=1 A k (Span(X k \u2212x (k) )), we can set x (k) \u2208 X k such that K k=1 A k (x (k) \u2212x (k) ) = \u2212\u03b4y * 2 / y * 2 . Finally, we get that,\ny * \u2208 Y * \u21d2 \u03b4 y * 2 , y * 2 / y * 2 \u2264 K k=1 g k diam(X k ) \u21d2 y * 2 2 \u2264 K k=1 g k diam(X k ) \u03b4 .(87)\nThus K \u2282 V \u22a5 is bounded and consequently compact (because Y * is closed).\n\nProposition 3. If Assumption 1 holds, then the set of normal directions to Y * ,\nD := d : d \u2208 N Y * c (y * ) for y * \u2208 Y * , d = 1 ,(88)\nis closed and consequently compact.\n\nProof. Let us first show that,\nD = {y \u2212 P Y * (y) : y \u2208 R d ; y \u2212 P Y * (y) = 1} .(89)\nLet y \u2208 R d \\ Y * , by definition of the normal cone and the projection onto a convex set, we have that y \u2212 P Y * (y) \u2208 N Y * c (P Y * (y)). Conversely, for any y * \u2208 Y * and d \u2208 N Y * c (y * ) such that d = 1, we have that y * = P Y * (y * + d) and y * + d / \u2208 Y * .\n\nWith the same notation as Lemma 3, we can write y \u2208 R d a unique way as y = y 1 + y 2 where y 1 \u2208 V and y 2 \u2208 V \u22a5 . Then since Y * = V \u22a5 + K we get that P Y * (y) = y 1 + \u03ba where \u03ba \u2208 K. Then y \u2212 P Y * (y) = y 2 \u2212 \u03ba where P K (y 2 ) = \u03ba. Conversely, for any couple (y 2 , \u03ba) \u2208 V \u22a5 \u00d7 K such that P K (y 2 ) = \u03ba, we have that y 2 \u2212 \u03ba \u2208 N K c (\u03ba). If we call \u03c6 : y \u2192 y \u2212 P K (y), then D = \u03c6(A) where A = {y 2 \u2208 V \u22a5 ; dist(y 2 , K) = 1} is a compact (because K is compact). Then since \u03c6 is continuous, D is a compact. Now we can apply this result to bound the \u03b1 constant introduced in Eq. (76). We notice that using (89), we can write that definition as \u03b1 = inf\ny\u2208R d \\Y * y * =P Y * (y) d=y * \u2212y, d =1 sup x\u2208X d, M x .(90)\nThe function d \u2192 sup x\u2208X d, M x is convex (as a supremum of convex function) and then is continuous on the interior of its domain which is R d because X is bounded. Since D is compact, the infimum is achieved. Then, there exist y \u2208 (R d \\ Y * ) \u00d7 Y * such that, y * = P Y * (y), y * \u2212 y = 1 and,\n\u03b1 = max x\u2208X y * \u2212 y, M x .(91)\nBy Equation (72), since y is non optimal, we conclude that \u03b1 > 0.\n\nProof of Thm. 1 and a Corollary.\n\nTheorem' 1. Let d be the augmented dual function (49), if f is a L-smooth convex function and X a compact convex set and if Assumption 1 holds, then for all y \u2208 R d there exist a constant \u03b1 > 0 such that,\nd * \u2212 d(y) \u2265 1 2L \u03bb D 2 min \u03b1 2 dist(y, Y * ) 2 , \u03b1L \u03bb D 2 dist(y, Y * ) ,(92)\nwhere D := max x,x \u2208X x \u2212 x is the diameter of X .\n\nProof. Recall that we proved\nd * \u2212 d(y) \u2265 1 2L \u03bb D 2 min max x\u2208X y * \u2212 y, M x 2 , L \u03bb D 2 max x\u2208X y * \u2212 y, M x ,(93)\nand that \u03b1 defined in (76) was positive (??). Then for all y / \u2208 Y * ,\nd * \u2212 d(y) \u2265 1 2L \u03bb D 2 min \u03b1 2 dist(y, Y * ) 2 , L \u03bb D 2 \u03b1 dist(y, Y * ) .(94)\nThe same result is trivially true for y \u2208 Y * (since in that case we have d(y) = d * ).\n\nThis Theorem leads to an immediate corollary on the norm of the gradient of d.\n\nCorollary 1. Under the same assumption as Theorem 1, for all y \u2208 R d there exist a constant \u03b1 such that,\n\u2207d(y) \u2265 1 2L \u03bb D 2 min{\u03b1 2 dist(y, Y * ), \u03b1L \u03bb D 2 } and \u2207d(y) \u2265 \u03b1 \u221a 2L \u03bb D 2 min d * \u2212 d(y), L \u03bb D 2 2 .(95)\nProof. We just need to notice that by concavity of d for all y * \u2208 Y * , the suboptimality is upper bounded by the linearization of the function:\nd * \u2212 d(y) \u2264 y * \u2212 y, \u2207d(y) \u2264 dist(y, Y * ) \u2207d(y) .(96)\nThen combining it with Theorem 1 we get,\n1 2L \u03bb D 2 min \u03b1 2 dist(y, Y * ), \u03b1L \u03bb D 2 \u2264 \u2207d(y) .(97)\nThis equation is equivalent to\n1 2L \u03bb D 2 \u03b1 2 dist(y, Y * ) \u2264 \u2207d(y) or \u03b1 2 \u2264 \u2207d(y) .(98)\nCombining the first inequality of (98) with (96) we get,\nd * \u2212 d(y) \u2264 2L \u03bb D 2 \u03b1 2 \u2207d(y) 2 or \u03b1 2 \u2264 \u2207d(y) ,(99)\nwhich is equivalent to\n\u2207d(y) \u2265 \u03b1 \u221a 2L \u03bb D 2 min{ d * \u2212 d(y), L \u03bb D 2 /2} .(100)\nUsing the fact that in (95),\neither dist(y t , Y * ) \u2265 L \u03bb D 2 \u03b1 or dist(y t , Y * ) \u2264 2L \u03bb D 2 \u03b1 2 \u2207d(y t ) = 2L \u03bb D 2 \u03b1 2 Mx t ,(114)\nleading to\n\u00b5 2 x t+1 \u2212 x * 2 \u2264 \u2206 (p) t \u2212 \u2206 (d) t + 2L \u03bb D 2 \u03b1 2 M x t+1 Mx t , \u2200t \u2208 N ; dist(y t , Y * ) \u2264 L \u03bb D 2 \u03b1 .(115)\nSimilarly, combining (113) and (75) gives us,\n\u00b5 2 x t+1 \u2212 x * 2 \u2264 \u2206 (p) t \u2212 \u2206 (d) t + max 2\u2206 (d) t , 2L \u03bb D 2 \u2206 (d) t .(116)\nThis property will be used to prove Theorem 4, deducing convergence rates on x t+1 \u2212 x * 2 from the convergence rates on \u2206 t proved in Theorem 2 and Theorem 3.\n\n\nD Proof of Theorem 2, Theorem 3 and Theorem 4\n\nThis section is decomposed into 3 subsections. First, we prove some intermediate results on the sequence computed by our algorithm to get the fundamental equation (125) that we will use to prove the convergence of (\u2206 t ) t\u2208N . Then in subsection D.2 (respectively Subsection D.3) we prove Thm. 2 (resp. Thm. 3). Let us recall that the Augmented Lagrangian function is defined as\nL(x, y) := f (x) + 1 X (x) + y, M x + \u03bb 2 M x 2 , \u2200(x, y) \u2208 R m \u00d7 R d ,(117)\nwhere f is a smooth function, 1 X is the indicator function of a convex compact set X \u2282 R m . The augmented dual function d is d(y) := max x\u2208X L(x, y) . The FW-AL algorithm computes\n\nx t+1 = FW(x t ; L(\u00b7, y t )) ,\ny t+1 = y t + \u03b7 t M x t+1 ,(118)\nwhere FW(x t ; L(\u00b7, y t )) is roughly a FW step from x t . (More details in App. A).\n\n\nD.1 Lemma deduced from the dual variable update rule\n\nThe two following lemmas do not require any assumption on the sets or the functions, they only rely on the dual update on y (118). They provide upper bounds on the decrease of the primal and the dual gaps. They are true for all functions f and constraint set X . Recall that we respectively defined the primal and the dual gap as,\n\u2206 (d) t := d * \u2212 d(y t ) and \u2206 (p) t := L(x t+1 ; y t ) \u2212 d(y t ) .(119)\nThe first lemma upper bounds the decrease of the dual suboptimality; note that Hong and Luo (2017) are probably not the firsts to provide such lemma. We are citing them because we provide the proof proposed in their paper.\n\nLemma 4 (Lemma 3.2 (Hong and Luo, 2017)). For any t \u2265 1, there holds\n\u2206 (d) t+1 \u2212 \u2206 (d) t \u2264 \u2212\u03b7 t M x t+1 , Mx t+1 . (120) Proof. \u2206 (d) t+1 \u2212 \u2206 (d) t = d(y t ) \u2212 d(y t+1 ) = L(x t , y t ) \u2212 L(x t+1 , y t+1 ) ( ) \u2264 L(x t+1 , y t ) \u2212 L(x t+1 , y t+1 )(121)= y t \u2212 y t+1 , Mx t+1 = \u2212\u03b7 t M x t+1 , Mx t+1 ,(122)\nwhere ( ) is becausex t is the minimizer of L(\u00b7, y t ).\n\nNext we proceed to bound the decrease of the primal gap \u2206 (p) t+1 . Lemma 5 (weaker version of Lemma 3.3 (Hong and Luo, 2017)). Then for any t \u2265 1, we have\n\u2206 (p) t+1 \u2212 \u2206 (p) t \u2264 \u03b7 t M x t+1 2 + (L(x t+2 , y t+1 ) \u2212 L(x t+1 , y t+1 )) \u2212 \u03b7 t M x t+1 , Mx t+1 .(123)\nProof. We start using the definition of \u2206\n(p) t+1 , \u2206 (p) t+1 \u2212 \u2206 (p) t = L(x t+2 , y t+1 ) \u2212 L(x t+1 , y t+1 ) \u2212 (L(x t+1 , y t ) \u2212 L(x t , y t )) = L(x t+2 , y t+1 ) \u2212 L(x t+1 , y t ) + (L(x t , y t ) \u2212 L(x t+1 , y t+1 )) (121) \u2264 L(x t+2 , y t+1 ) \u2212 L(x t+1 , y t+1 ) + L(x t+1 , y t+1 ) \u2212 L(x t+1 , y t ) \u2212 \u03b7 t M x t+1 , Mx t+1 ( ) = (L(x t+2 , y t+1 ) \u2212 L(x t+1 , y t+1 )) + \u03b7 t M x t+1 2 \u2212 \u03b7 t M x t+1 , Mx t+1 ,\nwhere the last inequality ( ) is by definition of L and because y t+1 \u2212 y t = \u03b7 t M x t+1 .\n\nWe can now combine Lemma 4 and Lemma 5 with our technical result Cor. 1 on the dual suboptimality to get our fundamental descent lemma only valid under Assumption 1.\n\nLemma 6 (Fundamental descent Lemma). Under Assumption 1 we have that for all t \u2265 0,\n\u2206 t+1 \u2212 \u2206 t \u2264 2\u03b7 t \u03bb (L(x t+1 , y t+1 ) \u2212 L(x t+1 , y t+1 )) + L(x t+2 , y t+1 ) \u2212 L(x t+1 , y t+1 ) \u2212 \u03b7 t \u03b1 2 2L \u03bb D 2 min{\u2206 (d) t+1 , L \u03bb D 2 2 } ,\nProof. Combining Lemma 4 and Lemma 5 gives us,\n\u2206 t+1 \u2212 \u2206 t = [\u2206 (p) t+1 \u2212 \u2206 (p) t ] + [\u2206 (d) t+1 \u2212 \u2206 (d) t ] \u2264 \u03b7 t M x t+1 2 + L(x t+2 , y t+1 ) \u2212 L(x t+1 , y t+1 ) \u2212 2\u03b7 t M x t+1 , Mx t+1 = \u03b7 t M x t+1 \u2212 Mx t+1 2 \u2212 \u03b7 t Mx t+1 2 + L(x t+2 , y t+1 ) \u2212 L(x t+1 , y t+1 ) .(124)\nFinally, from the \"strong convexity\" of L(\u00b7, y t+1 ) respect to M x Prop. 4 we obtain,\n\u2206 t+1 \u2212 \u2206 t \u2264 2\u03b7 t \u03bb (L(x t+1 , y t+1 ) \u2212 L(x t+1 , y t+1 )) + L(x t+2 , y t+1 ) \u2212 L(x t+1 , y t+1 ) \u2212 \u03b7 t Mx t+1 2 ,(125)\nwhere \u2206 t+1 := \u2206\n(p) t+1 + \u2206 (d)\nt+1 . Then we can use our fundamental technical result (Corollary (1)) relating the dual suboptimality and the norm of its gradient,\nMx t+1 2 P rop.2 = \u2207d(y t+1 ) 2 \u2265 \u03b1 2 2L \u03bb D 2 min{\u2206 (d) t+1 , L \u03bb D 2 2 } ,(126)\nto get the desired lemma.\n\nThe two following sections respectively deal with the proof of Theorem 2 and Theorem 3 they both start from our fundamental descent lemma (Lemma 6).\n\n\nD.2 Proof of Theorem 2\n\nLet us first recall the setting and propose a detailed version of the first part of Thm. 2. The second part of Thm. 2 is proposed in Corollary 2.\n\nTheorem' 2. If X is a compact convex set and f is L-smooth, using any algorithm with sublinear decrease (17) as inner loop in FW-AL (6) and \u03b7 t := min 2 \u03bb , \u03b1 2 2\u03b4 2 t+2 then there exists a bounded t 0 \u2265 0 such that,\n\u2206 t \u2264 min 4\u03b4(t 0 + 2) t + 2 , \u03b4 \u2200t \u2265 t 0 and t 0 \u2264 C \u03b4 + 2 exp \u2206 0 \u2212 \u03b4 + 2C 2\u03b4 .(127)\nwhere C := 8\u03b4 max 1 4 , 4\u03b4 2 \u03bb 2 \u03b1 4 . and \u03b4 := L \u03bb D 2 .\n\nIf we set \u03b7 t = min 2 \u03bb , \u03b1 2 2\u03b4 C \u03b4 for at least t 0 iterations and then \u03b7 t := min 2 \u03bb , \u03b1 2 2\u03b4 2 t+2 we get\n\u2206 t \u2264 min 4\u03b4(t 0 + 2) t + 2 , \u03b4 \u2200t \u2265 t 0 where t 0 = max 1 + 2(\u2206 0 \u2212 \u03b4)C \u03b4 2 , C \u03b4 .(128)\nProof. This proof will start from Lemma 6 and use the fact that if X is a general convex compact set, a usual Frank-Wolfe step with line search (Alg. 2) produces a sublinear decrease (17). It leads to the following equation holding for any \u03b3 \u2208 [0, 1],\n\u2206 t+1 \u2212 \u2206 t \u2264 2\u03b7 t \u03bb \u2212 \u03b3 (L(x t+1 , y t+1 ) \u2212 L(x t+1 , y t+1 )) + \u03b3 2 L \u03bb D 2 2 \u2212 \u03b7 t \u03b1 2 2L \u03bb D 2 min{\u2206 (d) t+1 , L \u03bb D 2 2 } .(129)\nThen for \u03b3 = 4\u03b7t \u03bb we get,\n\u2206 t+1 \u2212 \u2206 t \u2264 \u2212 2\u03b7 t \u03bb (L(x t+1 , y t+1 ) \u2212 L(x t+1 , y t+1 )) + 4\u03b7 t \u03bb 2 L \u03bb D 2 2 \u2212 \u03b7 t \u03b1 2 2L \u03bb D 2 min{\u2206 (d) t+1 , L \u03bb D 2 2 } . (130)\nSince we are doing line-search, we know that L(x t+1 , y t+1 ) \u2265 L(x t+2 , y t+1 ) implying that\n\u2206 t+1 \u2212 \u2206 t \u2264 \u2212 2\u03b7 t \u03bb \u2206 (p) t+1 + 4\u03b7 t \u03bb 2 L \u03bb D 2 2 \u2212 \u03b7 t \u03b1 2 2L \u03bb D 2 min{\u2206 (d) t+1 , L \u03bb D 2 2 } ,(131)\nIn order to make appear \u2206 t+1 in the RHS, we will introduce\na = min 2 \u03bb , \u03b1 2 2L \u03bb D 2 ,(132)\nthis constant depends on \u03bb which is a hyperparameter. It seems that \u03bb helps to scale the decrease of the primal with to the one of the dual.\n\u2206 t+1 \u2212 \u2206 t \u2264 \u2212a\u03b7 t min{\u2206 t+1 , L \u03bb D 2 2 } + 4\u03b7 t \u03bb 2 L \u03bb D 2 2 .(133)\nThen we have either that,\n\u2206 t+1 \u2212 \u2206 t \u2264 \u2212aL \u03bb D 2 \u03b7 t /2 + 4\u03b7 t \u03bb 2 L \u03bb D 2 2 ,(134)\ngiving a uniform (in time) decrease with a small enough constant step size \u03b7 t or we have,\n\u2206 t+1 \u2212 \u2206 t \u2264 \u2212a\u03b7 t \u2206 t+1 + 4\u03b7 t \u03bb 2 L \u03bb D 2 2 ,(135)\ngiving a usual Frank-Wolfe recurrence scheme leading to a sublinear decrease with a decreasing step size \u03b7 t \u223c 1/t. It seems hard to get an adaptive step size since we cannot efficiently compute \u2206 t . In order to tackle this problem we will consider an upper bound looser than (133) leading to a separation of the two regimes. Let us introduc\u0113 \u03b7 t := a\u03b7 t , \u03b4 := L \u03bb D 2 2 and C := 8\u03b4 max 1 4 , 4\u03b4 2 \u03bb 2 \u03b1 4 .\n\nReplacing \u03b7 t with\u03b7 t , we have that (133) implies \u2206 t+1 \u2212 \u2206 t \u2264 \u2212\u03b7 t min{\u2206 t+1 , \u03b4} +\u03b7 2 t C 2 .\n\nLemma 7. If there exists t 0 > C \u03b4 \u2212 2 such that \u2206 t0 \u2264 \u03b4 and if we set\u03b7 t = 2 2+t then,\n\u2206 t \u2264 min 4\u03b4(t 0 + 2) t + 2 , \u03b4 \u2200t \u2265 t 0 .(138)\nProof. For t = t 0 the result comes from the fact that we assumed that \u2206 t0 \u2264 \u03b4. By induction, let us assume that for a t \u2265 t 0 , \u2206 t \u2264 min 4\u03b4(t0+2) t+2 , \u03b4 then if \u2206 t+1 was greater than \u03b4, we would have obtained,\n\u03b4 \u2264 \u2206 t+1 \u2264 \u2206 t \u2212 2 2 + t \u03b4 + 2 2 + t 2 C 2 \u2264 \u03b4 \u2212 2 2 + t \u03b4 + 2 2 + t 2 C 2 ,(139)\nimplying that, \u03b4 \u2264 C 2 + t and then t \u2264 C \u03b4 \u2212 2\n\nwhich contradicts the assumption t > C \u03b4 \u2212 2. Leading to \u2206 t \u2264 \u03b4 , \u2200t \u2265 t 0 . Moreover, we have for all t \u2265 t 0 ,\n\u2206 t+1 \u2264 \u2206 t \u2212 2 2 + t \u2206 t+1 + 2 2 + t 2 C 2 (141) t + 4 t + 2 \u2206 t+1 \u2264 \u2206 t + 2 2 + t 2 C 2 (142) \u2206 t+1 \u2264 t + 2 t + 4 \u2206 t + 2C (2 + t)(t + 4) (143) ( ) \u2264 t + 2 t + 4 4\u03b4(t 0 + 2) t + 2 + 2C (t + 2)(t + 4)(144)\n\u2264 4\u03b4(t 0 + 2) t + 3 t + 3 t + 4 1 + 1 2(t + 2)\n\n,\n\nwhere ( ) is due to the induction hypothesis and the last inequality is due to the fact that \u03b4(t 0 + 2) \u2265 C. Then, we just need to show that t + 3 t + 4 1 + 1 2(t + 2) \u2264 1 , \u2200t \u2265 1 .\n\nThat is true because t + 3 t + 4 1 + 1 2(t + 2) \u2264 1 (147) \u21d4 (t + 3)(t + 5 2 ) \u2264 (2 + t)(t + 4) (148)\n\u21d4 \u2212 1 2 t + 15 2 \u2264 8 (149) \u21d4 t \u2265 1 .(150)\nNow we have to show that in a finite number of iterations t 0 we can reach a point such that \u2206 t0 \u2264 \u03b4.\n\nLet us assume that \u2206 0 \u2265 \u03b4, then we cannot initialize the recurrence (138). Instead we will show the following:\n\nLemma 8. Let (\u2206 t ) t\u2208N a sequence such that \u2206 t+1 \u2212 \u2206 t \u2264 \u2212\u03b7 t min{\u2206 t+1 , \u03b4} +\u03b7 2 t C 2 , \u2200t \u2208 N. We have that,\n\n\u2022 If\u03b7 t = \u03b4 C , then there exists t 0 \u2208 N such that, \u2206 t0 \u2264 \u03b4 , \u2206 t \u2264 \u03b4 : \u2200 t \u2265 t 0 , and t 0 \u2264 1 + 2(\u2206 0 \u2212 \u03b4)C \u03b4 2 .\n\n\u2022 If\u03b7 t = 2 2+t , then there exists t 0 \u2265 C \u03b4 \u2212 2 such that, \u2206 t0 \u2264 \u03b4 and t 0 \u2264 C \u03b4 exp\n\u2206 C \u03b4 \u22121 \u2212 \u03b4 + 2C 2\u03b4 .(152)\nFrank-Wolfe Splitting via Augmented Lagrangian Method\n\nProof. By contradiction, let us assume that \u2206 t \u2265 \u03b4 , \u2200t. Then (137) gives,\n\u2206 t+1 \u2212 \u2206 t \u2264 \u2212\u03b7 t \u03b4 +\u03b7 2 t C 2 .(153)\nThen we would have for\u03b7\nt = \u03b4 C that \u2206 t+1 \u2264 \u2206 t \u2212 \u03b4 2 2C(154)\nConsequently we would have \u2206 t < 0 at some point contradicting the fact that \u2206 t is non negative.\n\nFor\u03b7 t = 2 2+t we would have that,\n\u221e = \u03b4 \u221e t=0\u03b7 t \u2264 \u2206 0 + C 2 \u221e t=0\u03b7 2 t < \u221e .(155)\ngiving a contradiction.\n\nThus, let us consider the smallest time t 0 such that \u2206 t0 \u2264 \u03b4.\n\n\u2022 If we set\u03b7 t = \u03b4 C , we get for all t < t 0\n\u2206 t+1 \u2212 \u2206 t \u2264 \u2212 \u03b4 2 2C(156)\nand then summing for\n0 \u2264 t \u2264 t 0 \u2212 2 \u03b4 \u2212 \u2206 0 \u2264 \u2206 t0\u22121 \u2212 \u2206 0 \u2264 \u2212 (t 0 \u2212 1)\u03b4 2 2C ,(157)\nimplying that\nt 0 \u2264 1 + 2(\u2206 0 \u2212 \u03b4)C \u03b4 2(158)\nthen, let us show by recurrence that \u2200t \u2265 t 0 , \u2206 t \u2264 \u03b4. The result for t = t 0 is true by definition of t 0 . Let us assume that it is true for a t \u2265 t 0 , then if \u2206 t+1 \u2265 \u03b4, (137) gives us\n\u2206 t+1 \u2264 \u2206 t \u2212 \u03b4 2 C + \u03b4 2 2C \u2264 \u2206 t \u2212 \u03b4 2 2C < \u03b4 ,(159)\nleading to a contradiction. Thus, we have that \u2206 t+1 \u2264 \u03b4.\n\n\u2022 If\u03b7 t = 2 2+t , we want a t 0 \u2265 C \u03b4 \u2212 2 so if \u2206 C \u03b4 \u22121 \u2264 \u03b4 we are done, otherwise\n\u03b4 t0\u22122 t=0 2 2 + t \u2264 \u2206 0 \u2212 \u03b4 + C 2 \u221e t=0 4 (2 + t) 2 \u2264 \u2206 0 \u2212 \u03b4 + 2C \u03c0 2 6 \u2212 1 \u2264 \u2206 C \u03b4 \u22121 \u2212 \u03b4 + 2C .(160)\nSince t0 t= C \u03b4 \u22121 1 t \u2265 ln(t 0 ) \u2212 ln( C \u03b4 ) we get that\nt 0 \u2264 C \u03b4 exp \u2206 C \u03b4 \u22121 \u2212 \u03b4 + 2C 2\u03b4 .(161)\nCombining Lemma 7 and Lemma 8 with (137) we finally get Theorem 2.\n\nTo sum up, we can either set\u03b7 t = \u03b4 C for a fixed number of iterations or we can use a decreasing step size leading to a very bad upper bound on t 0 . Nevertheless this bound for the decreasing step size is very conservative and even if the best theoretical rates are given by a constant step size\u03b7 t for a number of iterations proportional to C \u03b4 and then a sublinear step size\u03b7 t = 2 2+t , in practice, we can directly start with a decreasing step size.\n\nProof. To prove Lemma 9, we start from Lemma 6 to obtain \u2206 t+1 \u2212 \u2206 t \u2264 L(x t+2 , y t+1 ) \u2212 L(x t+1 , y t+1 ) + 2\u03b7 t \u03bb (L(x t+1 , y t+1 ) \u2212 L(x t+1 , y t+1 )) \u2212 \u03b7 t \u03b1 2 2L \u03bb D 2 min{\u2206\n(d) t+1 , L \u03bb D 2 2 } ,(19)\u2264 2\u03b7 t \u03bb \u2212 \u03c1 A (L(x t+1 , y t+1 ) \u2212 L(x t+1 , y t+1 )) \u2212 \u03b7 t \u03b1 2 2L \u03bb D 2 min{\u2206 (d) t+1 , L \u03bb D 2 2 } .(184)\nNow we can choose \u03b7 t = \u03bb\u00b7\u03c1 A 4 giving us Lemma 9.\n\nFrom this lemma we can deduce a constant decrease for a finite number of step and eventually a geometric decrease.\n\nLemma 10. Under the assumptions of Theorem 3, for all \u03bb > 0, if we set \u03b7 t = \u03bb\u03c1 A 4 for finite number of steps t 0 , then the quantity \u2206 t decreases by a uniform amount as,\n\u2206 t+1 \u2212 \u2206 t \u2264 \u2212 \u03bb\u03b1 2 \u03c1 A 16 where t 0 (\u2206 0 ) \u2264 1 + 16\u2206 0 \u2212 8L \u03bb D 2 \u03bb\u03b1 2 .(185)\nOtherwise, \u2206 t decrease geometrically as,\n\u2206 t+1 \u2264 1 1 + \u03c1 \u2206 t where \u03c1 := \u03c1 A 2 min 1, \u03bb\u03b1 2 4L \u03bb D 2 .(186)\nProof. We start from Lemma 9, if 2\u2206\n(d) t+1 \u2265 L \u03bb D 2 , \u2206 t+1 \u2212 \u2206 t \u2264 \u2212 \u03bb\u03b1 2 \u03c1 A 16 ,(187)\nand otherwise,\n\u2206 t+1 \u2212 \u2206 t \u2264 \u2212 \u03c1 A 2 \u2206 (p) t+1 \u2212 \u03bb\u03b1 2 \u03c1 A 8L \u03bb D 2 \u2206 (d) t+1 \u2264 \u2212\u03c1\u2206 t+1 .(188)\nOur goal is then just to show the upper bound on t 0 . First let us notice that (\u2206 t ) is decreasing then this non negative sequence cannot decrease by a uniform amount an infinite number of time, then we can sum for t = 1, . . . , t 0 \u2212 1 such that (187) holds to get,\nL \u03bb D 2 2 \u2212 \u2206 0 \u2264 \u2206 (d) t0\u22121 \u2212 \u2206 0 \u2264 t0\u22122 t=0 \u2206 t+1 \u2212 \u2206 t \u2264 \u2212(t 0 \u2212 1) \u03bb\u03b1 2 \u03c1 A 16(189)\nOne can deduce several convergence properties from this lemma which are compiled in Theorem 3.\n\nCorollary 3 (Extended Theorem 3). Under the assumptions of Theorem 3, there exist t 0 \u2264 1 + 16\u22060\u22128L \u03bb D 2 \u03bb\u03b1 2 such that for all t \u2265 t 0 we have the following properties, 1. The gap decreases linearly,\n\u2206 t \u2264 L \u03bb D 2 2(1 + \u03c1) t\u2212t0 .(190)\n2. The sequences of feasibility violations at points x t+1 andx t+1 decrease linearly,\nMx t+1 2 \u2264 2 \u03bb \u00b7 \u03c1 A L \u03bb D 2 (1 + \u03c1) t\u2212t0 and M x t+1 2 \u2264 8 \u03bb \u00b7 \u03c1 A L \u03bb D 2 (1 + \u03c1) t\u2212t0 ,(191)\nwhere \u03c1 := \u03c1 A 2 min 1, \u03bb\u03b1 2 8L \u03bb D 2 .\n\n\nProceedings of the 21 st International Conference on Artificial Intelligence and Statistics (AISTATS) 2018, Lanzarote, Spain. PMLR: Volume 84. Copyright 2018 by the author(s).\n\n\n(2016b) and Huang et al. (2017) use Lemma 3.1 from Hong and Luo(2012)(which also appears as Lemma 3.1 in the published version(Hong and Luo, 2017)). This lemma states a result not holding for all y \u2208 R d but instead for (y t ) t\u2208N , which is the sequence of dual variables computed by the ADMM algorithm used in(Hong and Luo, 2017). This sequence cannot be assimilated to the sequence of dual variables computed by the GDMM algorithm since the update rule for the primal variables in each algorithm is different: the primal variable are updated with FW steps in one algorithm and with a proximal step in the other. The properties of this proximal step are intrinsically different from the FW steps computing the updates on the primal variables of FW-AL. To our knowledge, there is no easy fix (details in App. B.1) to get a similar result as the one claimed in(Yen et al.,  2016b, Lem. 4) and (Huang et al., 2017, Lem. 4).\n\n\nof the support recovered. (b) Matrix recovered with FW-AL.(c) Matrix recov. with the baseline.\n\nFigure 1 :\n1Fig. 1arepresent the fraction of the support of \u03a3 recovered as a function of time (d 2 = 1.6 \u00b7 10 7 and the matrix computed is thresholded at 10 \u22122 ). The baseline is the generalized forward backward algorithm. FW-AL requires a small enough step size \u03b7 to recover the support otherwise it diverges (green curve) and does not require a lot of tuning for \u03bb (blue and orange curve). Fig 1b and 1ccompare the matrices recovered for d 2 = 10 6 after one minute of computation.\n\nFigure 2 :\n2Time complexity of the LMO vs. the projection on the trace norm ball. The blue curve represents the time spent by the generalized forward backward algorithm to reach a better point than the one computed by FW-AL.\n\n\ncan be used an inner loop algorithm. For instance, the block-coordinate Frank-Wolfe method (Lacoste-Julien et al., 2013) performs a sublinear decrease in expectation and the fully-corrective Frank-Wolfe method (Lacoste-Julien and Jaggi, 2015) or Garber and Meshi (2016)'s algorithm perform a geometric decrease.\n\n\nFrank-Wolfe method 3 (Lacoste-Julien et al., 2013), usual Frank-Wolfe (Jaggi, 2013) and Frank-Wolfe with away-step (Lacoste-Julien and Jaggi, 2015).\n\n\u21d0:\nIf Relint(C) = {0}, then {0} = Relint(C) = Cone(C) = Span(C).\n\n\nand an inner loop noted FW which can be chosen to be one of the FW step variants described in Alg. 1 or 2. drop_step \u2190 true (initialization of the boolean) 3: while drop_step = true doFW steps. In FW-AL we need to ensure that the \nFW inner loop makes sufficient progress. For general \nsets, we can use one iteration of the classical Frank-\nWolfe algorithm with line-search (Jaggi, 2013) as given \nin Algorithm 2. When working over polytopes, we can \nget faster (linear) convergence by taking one non-drop \nstep (defined below) of the away-step variant of the FW \nAlgorithm 1 Away-step Frank-Wolfe (one non-drop \nstep) : (Lacoste-Julien and Jaggi, 2015) \n\n1: input: (x, S, A, \u03d5) \n(\u03d5 is the objective) \n2: 4: \n\n\n\n\nUpdate S \u2190 {v \u2208 A s.t. \u03b1 v > 0} (active set) 20: end while 21: return: (x, S)Algorithm 2 FW(one step) :(Frank and Wolfe, 1956)    1: input: (x, \u03d5) 2: Compute s \u2190 arg min12: \n\nend if \n\n13: \n\nCompute \u03b3 \u2208 arg min \u03b3\u2208[0,\u03b3max] \u03d5 (x + \u03b3d) \n\n14: \n\nif \u03b3 < \u03b3 max then \n(first non-drop step) \n\n15: \n\ndrop_step \u2190 false \n\n16: \n\nend if \n\n17: \n\nUpdate x \u2190 x + \u03b3d \n\n18: \n\nUpdate \u03b1 v according to (5) \n\n19: \n\ns\u2208X \n\ns, \u2207\u03d5(x) \n\n\n\n\n. H. H. Bauschke and P. L. Combettes. Convex analysis and monotone operator theory in Hilbert spaces. Springer, 2011. A. Beck and S. Shtern. Linearly convergent awaystep conditional gradient for non-strongly convex functions. Math. Program., 2016. D. P. Bertsekas. Constrained optimization and Lagrange multiplier methods. Athena Scientific, 1996. S. Boyd and L. Vandenberghe. Convex Optimization. M. Hong and Z.-Q. Luo. On the linear convergence of the alternating direction method of multipliers. Math. Program., 2017. X. Huang, I. E.-H. Yen, R. Zhang, Q. Huang, P. Ravikumar, and I. Dhillon. Greedy direction method of multiplier for MAP inference of large output domain. R. T. Rockafellar. Convex analysis. Princeton university press, 1970. R. T. Rockafellar and R. J. Wets. Variational analysis. Springer, 1998. E. Ryu and S. Boyd. Primer on monotone operator methods. Appl. Comput. Math, 2016.Cambridge University Press, 2004. \n\nS. Boyd, N. Parikh, E. Chu, B. Peleato, and J. Eck-\nstein. Distributed optimization and statistical learn-\ning via the alternating direction method of multipli-\ners. Found. Trends Mach. Learn., 2011. \n\nJ.-F. Cai, E. J. Cand\u00e8s, and Z. Shen. A singular value \nthresholding algorithm for matrix completion. SIAM \nJournal on Optimization, 2010. \n\nD. J. M. Danskin. The directional derivative. In The \nTheory of Max-Min and Its Application to Weapons \nAllocation Problems. Springer Berlin Heidelberg, \n1967. \n\nM. Frank and P. Wolfe. An algorithm for quadratic \nprogramming. Naval Research Logistics, 1956. \n\nD. Gabay and B. Mercier. A dual algorithm for the \nsolution of nonlinear variational problems via finite \nelement approximation. Computers & Mathematics \nwith Applications, 1976. \n\nD. Garber and O. Meshi. \nLinear-memory and \ndecomposition-invariant linearly convergent condi-\ntional gradient algorithm for structured polytopes. \nIn NIPS, 2016. \n\nR. Glowinski and A. Marroco. Sur l'approximation, \npar \u00e9l\u00e9ments finis d'ordre un, et la r\u00e9solution, par \np\u00e9nalisation-dualit\u00e9 d'une classe de probl\u00e8mes de \ndirichlet non lin\u00e9aires. ESAIM: Mathematical Mod-\nelling and Numerical Analysis, 1975. \n\nR. Glowinski, S. J. Osher, and W. Yin. Splitting Meth-\nods in Communication, Imaging, Science, and Engi-\nneering. Springer, 2017. \n\nD. Goldfarb, S. Ma, and K. Scheinberg. Fast alternating \nlinearization methods for minimizing the sum of two \nconvex functions. Mathematical Programming, 2013. \n\nM. S. Gowda and M. Teboulle. A comparison of con-\nstraint qualifications in infinite-dimensional convex \nprogramming. SIAM Journal on Control and Opti-\nmization, 1990. \n\nA. Gramfort, B. Thirion, and G. Varoquaux. Identify-\ning predictive regions from fMRI with TV-L1 prior. \nIn International Workshop on Pattern Recognition \nin Neuroimaging. IEEE, 2013. \n\nR. B. Holmes. Geometric functional analysis and its \napplications. Springer, 1975. \n\nM. Hong and Z.-Q. Luo. On the linear convergence \nof the alternating direction method of multipliers. \narXiv:1208.3922, 2012. \n\nIn AISTATS, 2017. \n\nM. Jaggi. Revisiting Frank-Wolfe: Projection-free \nsparse convex optimization. In ICML, 2013. \n\nH. Karimi, J. Nutini, and M. Schmidt. Linear con-\nvergence of gradient and proximal-gradient methods \nunder the Polyak-\u0141ojasiewicz condition. 2016. \n\nJ. Kuczy\u0144ski and H. Wo\u017aniakowski. Estimating the \nlargest eigenvalue by the power and Lanczos algo-\nrithms with a random start. SIAM. J. Matrix Anal. \n& Appl., 1992. \n\nS. Lacoste-Julien and M. Jaggi. On the global linear \nconvergence of Frank-Wolfe optimization variants. \nIn NIPS, 2015. \n\nS. Lacoste-Julien, M. Jaggi, M. Schmidt, and \nP. Pletscher. Block-Coordinate Frank-Wolfe Opti-\nmization for Structural SVMs. In ICML, 2013. \n\nS. \u0141ojasiewicz. A topological property of real analytic \nsubsets. Coll. du CNRS, Les \u00e9quations aux d\u00e9riv\u00e9es \npartielles, 1963. \n\nY. Nesterov. Introductory Lectures on Convex Opti-\nmization. Applied Optimization. Springer US, 2004. \n\nY. Nesterov. Complexity bounds for primal-dual meth-\nods minimizing the model of objective function. \nCORE Discussion Paper, 2016. \nG. Obozinski, L. Jacob, and J.-P. Vert. Group lasso \nwith overlaps: the latent group lasso approach. \narXiv:1110.0413, 2011. \n\nC. C. Paige. The computation of eigenvalues and eigen-\nvectors of very large sparse matrices. PhD thesis, \nUniversity of London, 1971. \n\nJ.-S. Pang. A posteriori error bounds for the linearly-\nconstrained variational inequality problem. Mathe-\nmatics of Operations Research, 1987. \n\nJ.-S. Pang. Error bounds in mathematical program-\nming. Math. Program., 1997. \n\nB. T. Polyak. Gradient methods for minimizing func-\ntionals. Zh. Vychisl. Mat. Mat. Fiz., 1963. \n\nH. Raguet, J. Fadili, and G. Peyr\u00e9. A generalized \nforward-backward splitting. SIAM Journal on Imag-\ning Sciences, 2013. \n\nE. Richard, P.-A. Savalle, and N. Vayatis. Estimation \nof simultaneously sparse and low rank matrices. In \nICML, 2012. \n\nS. Shalev-Shwartz and Y. Singer. On the equivalence \nof weak learnability and linear separability: New \nrelaxations and efficient boosting algorithms. Mach. \nLearn., 2010. \n\nP.-W. Wang and C.-J. Lin. Iteration complexity of \nfeasible descent methods for convex optimization. \nJournal of Machine Learning Research, 2014. \n\nM. Yan and W. Yin. Self equivalence of the alter-\nnating direction method of multipliers. In Splitting \nMethods in Communication, Imaging, Science, and \nEngineering. Springer, 2016. \n\nJ. Yang and X. Yuan. Linearized augmented lagrangian \nand alternating direction methods for nuclear norm \nminimization. Mathematics of computation, 2013. \n\nI. Yen, X. Huang, K. Zhong, R. Zhang, P. Ravikumar, \nand I. Dhillon. Dual decomposed learning with fac-\ntorwise oracle for structural SVM with large output \ndomain. In NIPS, 2016b. \n\nI. E.-H. Yen, X. Lin, J. Zhang, P. Ravikumar, and \nI. Dhillon. A convex atomic-norm approach to mul-\ntiple sequence alignment and motif discovery. In \nICML, 2016a. \n\nA. Yurtsever, Q. T. Dinh, and V. Cevher. A univer-\nsal primal-dual convex optimization framework. In \nNIPS, 2015. \n\nThis notion has been studied byWang and Lin (2014)   and in the Frank-Wolfe framework by Beck and Shtern (2016) and Lacoste-Julien and Jaggi(2015).2 An example of approximate minimization is taking one proximal gradient step, as used for example, in the Linearized ADMM algorithm(Goldfarb et al., 2013; Yang  and Yuan, 2013).\nFor BCFW, the sublinear decrease is valid on the expectation of the suboptimality, then the proofs with this algorithm as an inner-loop require a bit of extra work.\nx t+1 \u2212 x * 2 \u2264 \u2206 (p) t \u2212 \u2206 (d) t + y * \u2212 y t , M x t+1 (112) \u2264 \u2206 (p) t \u2212 \u2206 (d) t + dist(y t , Y * ) M x t+1 .(113)\nAcknowledgmentsWe thank an anonymous reviewer for valuable comments which enabled us to improve the proofs. This research was partially supported by the Canada Excellence Research Chair in \"Data Science for Realtime Decision-making\", by the NSERC Discovery Grant RGPIN-2017-06936 and by the European Union's Horizon 2020 research and innovation program under the Marie Sk\u0142odorowska-Curie grant agreement 748900.C.2 Properties of the function LWe will first prove that for any y \u2208 R d , the function L(\u00b7, y) has a property similar to strong convexity respect to the variable M x: if L(x, y) is close to its minimum with respect to x, then M x is close to the image by M of the minimizer of L(\u00b7, y). More precisely, Proposition 4. for all x \u2208 X and y \u2208 R d , if f is convex,and L(x, y) := f (x) + 1 X (x) + y, M x + \u03bb 2 M x 2Proof. By convexity of f we have that,then by simple algebra (notingx =x(y)),The last inequality come from the first order optimality condition on L(\u00b7, y). Now let us introduce the key property allowing us to insure that x t actually converge to x * . This proposition states that the primal gap \u2206 (p) t upper-bounds the squared distance to the optimum.Proposition 5. If f is a \u00b5-strongly convex function then, X * = {x * } and we have for all t \u2265 0,and also \u00b5 2Proof. We start from the identityFrom first order optimality conditions, we get for any y * \u2208 Y * and any x \u2208 X ,If f is \u00b5-strongly convex, thenthen combining (108), (110) and (111), we get for any y * = P Y * (y):\u00b5 Corollary 2. Under the same assumption as Thm. 2. Let the t 0 \u2208 N stated in Thm. 2, then for allProof. This proof follows the same idea as the proof of (Lacoste-Julien et al., 2013, Thm C.3). Since we are working with different quantities and that the rates are slightly different from the ones provided in (Lacoste-Julien et al., 2013) we will provide a complete proof of this result. We start from the fundamental descent lemma(125). We use the fact that a usual Frank-Wolfe step produces a sublinear decrease (A.3) that we specify for \u03b3 = 4\u03b7t \u03bb to get a similar equation as(131),which is similar equation as (Lacoste-Julien et al., 2013, Eq.(22)). Let t 1 \u2265 t 0 and {w t } T t1 be a sequence of positive weights. Let \u03c1 t := wt / T t=t 1 wt be the associated normalized weights. The convex combination of (165) give us,We can now use a weighted average such as w t = t \u2212 t 1 . This kind of average leads towhere \u03b7 t := min 2 \u03bb , \u03b1 2 4\u03b4 2 t+2 = a 2 t+2 . Then we can plug that \u2206 t \u2264 min 4\u03b4(t0+2) t+2 , \u03b4 , \u2200t \u2265 t 1 \u2265 t 0 to get,Then,To upper bound M x t+1 2 the idea is to combine the previous equationProp. 4plus the fact that we perform line search) giving,If f is \u00b5-strongly convex we can use Prop. 5 to get,In order to show that at some point we have dist(y t , Y * ) \u2264 \u03b4 \u03b1 we will use Thm. 1 and (138) to get,Then for all t \u2265 t 0 such that dist(y t , Y * ) > \u03b4 \u03b1 we have that,implying that for t \u2265 8(t 0 + 2) \u2212 2 = 8t 0 + 14 we have that \u03b1 dist(y t , Y * ) \u2264 \u03b4 and then,It then implies that for t 1 \u2265 8t 0 + 14,D.3 Proof of Theorem 3This proof starts with the fundamental descent lemma (Lemma 6). It uses the fact that if X is a polytope and if we use an algorithm with a geometric decrease (19) such as Alg. 1 then with a small enough constant step size \u03b7 t we can upper bound the decrease of \u2206 t+1 \u2212 \u2206 t .Lemma 9. Under assumptions of theorem 3, we haveFinally, if f is \u00b5 f -strongly convex, the distance of the current point to the optimal set vanishes as,Proof. To prove the first statement let us start from Lemma 9, for all t \u2265 t 0 ,leading us directly toTo upper bound M x t+1 2 the idea is to combine the two previous equations with M x t+1 \u2212 Mx t+1 2 \u2264 2 \u03bb (L(x t+1 , y t+1 ) \u2212 L(x t+1 , y t+1 )) (Prop. 4) giving,The last statement directly follows from the fact (\u2206 t+1 ) decreases linearly (Lemma 10) and the fact that one can upper bound x t+1 \u2212 x * 2 with the primal and dual suboptimalities (Proposition 5),Then, it easily follows that\nUnsupervised learning from narrated instruction videos. J.-B Alayrac, P Bojanowski, N Agrawal, I Laptev, J Sivic, S Lacoste-Julien, CVPR. J.-B. Alayrac, P. Bojanowski, N. Agrawal, I. Laptev, J. Sivic, and S. Lacoste-Julien. Unsupervised learning from narrated instruction videos. In CVPR, 2016.\n", "annotations": {"author": "[{\"end\":165,\"start\":57},{\"end\":276,\"start\":166},{\"end\":391,\"start\":277}]", "publisher": null, "author_last_name": "[{\"end\":71,\"start\":66},{\"end\":182,\"start\":173},{\"end\":297,\"start\":283}]", "author_first_name": "[{\"end\":65,\"start\":57},{\"end\":172,\"start\":166},{\"end\":282,\"start\":277}]", "author_affiliation": "[{\"end\":164,\"start\":73},{\"end\":275,\"start\":184},{\"end\":390,\"start\":299}]", "title": "[{\"end\":54,\"start\":1},{\"end\":445,\"start\":392}]", "venue": null, "abstract": "[{\"end\":1670,\"start\":447}]", "bib_ref": "[{\"end\":1887,\"start\":1874},{\"end\":1955,\"start\":1923},{\"end\":2715,\"start\":2693},{\"end\":2870,\"start\":2847},{\"end\":3032,\"start\":3013},{\"end\":3115,\"start\":3095},{\"end\":3560,\"start\":3536},{\"end\":3579,\"start\":3560},{\"end\":3793,\"start\":3765},{\"end\":3830,\"start\":3806},{\"end\":3894,\"start\":3875},{\"end\":3912,\"start\":3894},{\"end\":3985,\"start\":3967},{\"end\":4036,\"start\":4012},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":4268,\"start\":4246},{\"end\":4316,\"start\":4287},{\"end\":4618,\"start\":4595},{\"end\":4867,\"start\":4849},{\"end\":5081,\"start\":5062},{\"end\":5100,\"start\":5081},{\"end\":5396,\"start\":5377},{\"end\":6323,\"start\":6303},{\"end\":6344,\"start\":6325},{\"end\":7752,\"start\":7749},{\"end\":8949,\"start\":8930},{\"end\":9306,\"start\":9287},{\"end\":9773,\"start\":9755},{\"end\":9796,\"start\":9778},{\"end\":10029,\"start\":10007},{\"end\":10393,\"start\":10376},{\"end\":11480,\"start\":11464},{\"end\":11726,\"start\":11725},{\"end\":14589,\"start\":14557},{\"end\":17613,\"start\":17592},{\"end\":17632,\"start\":17613},{\"end\":19960,\"start\":19946},{\"end\":19985,\"start\":19960},{\"end\":25745,\"start\":25726},{\"end\":25764,\"start\":25745},{\"end\":28048,\"start\":28026},{\"end\":29054,\"start\":29041},{\"end\":29087,\"start\":29054},{\"end\":29955,\"start\":29934},{\"end\":36333,\"start\":36314},{\"end\":36352,\"start\":36333},{\"end\":37691,\"start\":37655},{\"end\":41351,\"start\":41324},{\"end\":43029,\"start\":43018},{\"end\":43042,\"start\":43029},{\"end\":43222,\"start\":43204},{\"end\":43344,\"start\":43324},{\"end\":48151,\"start\":48132},{\"end\":50258,\"start\":50255}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":68365,\"start\":68188},{\"attributes\":{\"id\":\"fig_1\"},\"end\":69290,\"start\":68366},{\"attributes\":{\"id\":\"fig_2\"},\"end\":69387,\"start\":69291},{\"attributes\":{\"id\":\"fig_3\"},\"end\":69872,\"start\":69388},{\"attributes\":{\"id\":\"fig_4\"},\"end\":70098,\"start\":69873},{\"attributes\":{\"id\":\"fig_5\"},\"end\":70412,\"start\":70099},{\"attributes\":{\"id\":\"fig_6\"},\"end\":70563,\"start\":70413},{\"attributes\":{\"id\":\"fig_7\"},\"end\":70629,\"start\":70564},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":71341,\"start\":70630},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":71753,\"start\":71342},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":77769,\"start\":71754}]", "paragraph": "[{\"end\":2436,\"start\":1686},{\"end\":3116,\"start\":2438},{\"end\":3328,\"start\":3118},{\"end\":4837,\"start\":3330},{\"end\":5989,\"start\":4839},{\"end\":6778,\"start\":5991},{\"end\":7336,\"start\":6780},{\"end\":7654,\"start\":7338},{\"end\":7781,\"start\":7674},{\"end\":8615,\"start\":7837},{\"end\":8880,\"start\":8643},{\"end\":9099,\"start\":8882},{\"end\":9907,\"start\":9101},{\"end\":10231,\"start\":9909},{\"end\":10533,\"start\":10270},{\"end\":10657,\"start\":10581},{\"end\":10787,\"start\":10693},{\"end\":11089,\"start\":10940},{\"end\":11367,\"start\":11091},{\"end\":11824,\"start\":11413},{\"end\":12019,\"start\":11862},{\"end\":13546,\"start\":12126},{\"end\":14129,\"start\":13872},{\"end\":14336,\"start\":14172},{\"end\":14511,\"start\":14405},{\"end\":14667,\"start\":14513},{\"end\":15329,\"start\":14710},{\"end\":15526,\"start\":15351},{\"end\":15939,\"start\":15572},{\"end\":16245,\"start\":15969},{\"end\":16732,\"start\":16270},{\"end\":16949,\"start\":16798},{\"end\":17019,\"start\":17000},{\"end\":17198,\"start\":17021},{\"end\":17575,\"start\":17230},{\"end\":18235,\"start\":17577},{\"end\":18529,\"start\":18287},{\"end\":18655,\"start\":18578},{\"end\":18740,\"start\":18701},{\"end\":19184,\"start\":18794},{\"end\":19663,\"start\":19241},{\"end\":20483,\"start\":19736},{\"end\":20850,\"start\":20630},{\"end\":21315,\"start\":20852},{\"end\":21814,\"start\":21347},{\"end\":22459,\"start\":21875},{\"end\":22706,\"start\":22461},{\"end\":23116,\"start\":23020},{\"end\":23878,\"start\":23118},{\"end\":24190,\"start\":23936},{\"end\":24241,\"start\":24192},{\"end\":24513,\"start\":24243},{\"end\":24663,\"start\":24547},{\"end\":25113,\"start\":24797},{\"end\":25296,\"start\":25115},{\"end\":25513,\"start\":25353},{\"end\":25862,\"start\":25591},{\"end\":26004,\"start\":25864},{\"end\":26156,\"start\":26053},{\"end\":26287,\"start\":26262},{\"end\":26594,\"start\":26535},{\"end\":26703,\"start\":26694},{\"end\":26934,\"start\":26856},{\"end\":27014,\"start\":26936},{\"end\":27300,\"start\":27248},{\"end\":27406,\"start\":27364},{\"end\":27554,\"start\":27458},{\"end\":27742,\"start\":27626},{\"end\":27831,\"start\":27789},{\"end\":28227,\"start\":27860},{\"end\":28448,\"start\":28247},{\"end\":28517,\"start\":28490},{\"end\":29426,\"start\":28825},{\"end\":29485,\"start\":29428},{\"end\":29799,\"start\":29487},{\"end\":30649,\"start\":29801},{\"end\":31063,\"start\":30730},{\"end\":31286,\"start\":31065},{\"end\":31326,\"start\":31288},{\"end\":31993,\"start\":31328},{\"end\":32122,\"start\":32045},{\"end\":32248,\"start\":32160},{\"end\":32473,\"start\":32307},{\"end\":32563,\"start\":32475},{\"end\":32960,\"start\":32636},{\"end\":33042,\"start\":32993},{\"end\":33466,\"start\":33044},{\"end\":33559,\"start\":33554},{\"end\":33703,\"start\":33633},{\"end\":33944,\"start\":33705},{\"end\":34578,\"start\":33977},{\"end\":34733,\"start\":34634},{\"end\":35066,\"start\":34819},{\"end\":36825,\"start\":35068},{\"end\":36996,\"start\":36859},{\"end\":37335,\"start\":37028},{\"end\":37344,\"start\":37337},{\"end\":37702,\"start\":37368},{\"end\":37987,\"start\":37847},{\"end\":38148,\"start\":38035},{\"end\":38436,\"start\":38288},{\"end\":38522,\"start\":38438},{\"end\":39378,\"start\":38524},{\"end\":39644,\"start\":39380},{\"end\":39785,\"start\":39646},{\"end\":39915,\"start\":39849},{\"end\":40203,\"start\":39992},{\"end\":40370,\"start\":40234},{\"end\":40691,\"start\":40401},{\"end\":40911,\"start\":40718},{\"end\":41087,\"start\":40957},{\"end\":41452,\"start\":41166},{\"end\":41564,\"start\":41454},{\"end\":41632,\"start\":41629},{\"end\":41952,\"start\":41679},{\"end\":42338,\"start\":42030},{\"end\":42513,\"start\":42340},{\"end\":42621,\"start\":42589},{\"end\":42844,\"start\":42794},{\"end\":43223,\"start\":42890},{\"end\":43345,\"start\":43225},{\"end\":43462,\"start\":43347},{\"end\":43615,\"start\":43464},{\"end\":43772,\"start\":43702},{\"end\":43877,\"start\":43774},{\"end\":44153,\"start\":43935},{\"end\":44255,\"start\":44219},{\"end\":44587,\"start\":44436},{\"end\":44913,\"start\":44589},{\"end\":44966,\"start\":44915},{\"end\":45102,\"start\":44984},{\"end\":45312,\"start\":45289},{\"end\":45635,\"start\":45467},{\"end\":45964,\"start\":45745},{\"end\":46045,\"start\":45966},{\"end\":46296,\"start\":46098},{\"end\":46420,\"start\":46337},{\"end\":46600,\"start\":46505},{\"end\":46714,\"start\":46646},{\"end\":46841,\"start\":46716},{\"end\":46993,\"start\":46895},{\"end\":47106,\"start\":47077},{\"end\":47395,\"start\":47195},{\"end\":47573,\"start\":47467},{\"end\":47732,\"start\":47575},{\"end\":47812,\"start\":47759},{\"end\":47947,\"start\":47871},{\"end\":48019,\"start\":47949},{\"end\":48152,\"start\":48050},{\"end\":48192,\"start\":48154},{\"end\":48615,\"start\":48473},{\"end\":48747,\"start\":48617},{\"end\":48838,\"start\":48795},{\"end\":48986,\"start\":48884},{\"end\":49070,\"start\":48988},{\"end\":49165,\"start\":49155},{\"end\":49494,\"start\":49418},{\"end\":49543,\"start\":49496},{\"end\":49823,\"start\":49754},{\"end\":49888,\"start\":49825},{\"end\":50081,\"start\":49909},{\"end\":50174,\"start\":50100},{\"end\":50332,\"start\":50176},{\"end\":50481,\"start\":50390},{\"end\":50682,\"start\":50604},{\"end\":51043,\"start\":50979},{\"end\":51320,\"start\":51215},{\"end\":51874,\"start\":51856},{\"end\":52183,\"start\":51987},{\"end\":52357,\"start\":52284},{\"end\":52439,\"start\":52359},{\"end\":52531,\"start\":52496},{\"end\":52563,\"start\":52533},{\"end\":52887,\"start\":52620},{\"end\":53545,\"start\":52889},{\"end\":53903,\"start\":53608},{\"end\":54000,\"start\":53935},{\"end\":54034,\"start\":54002},{\"end\":54240,\"start\":54036},{\"end\":54370,\"start\":54320},{\"end\":54400,\"start\":54372},{\"end\":54559,\"start\":54489},{\"end\":54727,\"start\":54640},{\"end\":54807,\"start\":54729},{\"end\":54913,\"start\":54809},{\"end\":55169,\"start\":55024},{\"end\":55266,\"start\":55226},{\"end\":55354,\"start\":55324},{\"end\":55469,\"start\":55413},{\"end\":55547,\"start\":55525},{\"end\":55633,\"start\":55605},{\"end\":55751,\"start\":55741},{\"end\":55910,\"start\":55865},{\"end\":56149,\"start\":55990},{\"end\":56577,\"start\":56199},{\"end\":56836,\"start\":56655},{\"end\":56868,\"start\":56838},{\"end\":56986,\"start\":56902},{\"end\":57373,\"start\":57043},{\"end\":57669,\"start\":57447},{\"end\":57739,\"start\":57671},{\"end\":58032,\"start\":57977},{\"end\":58189,\"start\":58034},{\"end\":58339,\"start\":58298},{\"end\":58807,\"start\":58716},{\"end\":58974,\"start\":58809},{\"end\":59059,\"start\":58976},{\"end\":59256,\"start\":59210},{\"end\":59572,\"start\":59486},{\"end\":59712,\"start\":59696},{\"end\":59861,\"start\":59729},{\"end\":59969,\"start\":59944},{\"end\":60119,\"start\":59971},{\"end\":60291,\"start\":60146},{\"end\":60509,\"start\":60293},{\"end\":60653,\"start\":60596},{\"end\":60765,\"start\":60655},{\"end\":61107,\"start\":60856},{\"end\":61269,\"start\":61243},{\"end\":61505,\"start\":61409},{\"end\":61673,\"start\":61614},{\"end\":61848,\"start\":61708},{\"end\":61946,\"start\":61921},{\"end\":62096,\"start\":62006},{\"end\":62560,\"start\":62151},{\"end\":62659,\"start\":62562},{\"end\":62749,\"start\":62661},{\"end\":63012,\"start\":62798},{\"end\":63143,\"start\":63096},{\"end\":63258,\"start\":63145},{\"end\":63512,\"start\":63466},{\"end\":63515,\"start\":63514},{\"end\":63699,\"start\":63517},{\"end\":63801,\"start\":63701},{\"end\":63946,\"start\":63844},{\"end\":64059,\"start\":63948},{\"end\":64174,\"start\":64061},{\"end\":64293,\"start\":64176},{\"end\":64382,\"start\":64295},{\"end\":64464,\"start\":64411},{\"end\":64541,\"start\":64466},{\"end\":64604,\"start\":64581},{\"end\":64741,\"start\":64644},{\"end\":64777,\"start\":64743},{\"end\":64850,\"start\":64827},{\"end\":64915,\"start\":64852},{\"end\":64962,\"start\":64917},{\"end\":65011,\"start\":64991},{\"end\":65091,\"start\":65078},{\"end\":65313,\"start\":65123},{\"end\":65426,\"start\":65369},{\"end\":65511,\"start\":65428},{\"end\":65674,\"start\":65617},{\"end\":65783,\"start\":65717},{\"end\":66240,\"start\":65785},{\"end\":66424,\"start\":66242},{\"end\":66611,\"start\":66561},{\"end\":66727,\"start\":66613},{\"end\":66901,\"start\":66729},{\"end\":67023,\"start\":66982},{\"end\":67124,\"start\":67089},{\"end\":67194,\"start\":67180},{\"end\":67543,\"start\":67274},{\"end\":67726,\"start\":67632},{\"end\":67929,\"start\":67728},{\"end\":68051,\"start\":67965},{\"end\":68187,\"start\":68148}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":7836,\"start\":7782},{\"attributes\":{\"id\":\"formula_1\"},\"end\":10580,\"start\":10534},{\"attributes\":{\"id\":\"formula_2\"},\"end\":10692,\"start\":10658},{\"attributes\":{\"id\":\"formula_3\"},\"end\":10939,\"start\":10788},{\"attributes\":{\"id\":\"formula_4\"},\"end\":11412,\"start\":11368},{\"attributes\":{\"id\":\"formula_5\"},\"end\":11861,\"start\":11825},{\"attributes\":{\"id\":\"formula_6\"},\"end\":12107,\"start\":12020},{\"attributes\":{\"id\":\"formula_7\"},\"end\":13818,\"start\":13547},{\"attributes\":{\"id\":\"formula_8\"},\"end\":13871,\"start\":13818},{\"attributes\":{\"id\":\"formula_9\"},\"end\":14404,\"start\":14337},{\"attributes\":{\"id\":\"formula_10\"},\"end\":14709,\"start\":14668},{\"attributes\":{\"id\":\"formula_11\"},\"end\":15571,\"start\":15527},{\"attributes\":{\"id\":\"formula_12\"},\"end\":15968,\"start\":15940},{\"attributes\":{\"id\":\"formula_13\"},\"end\":16797,\"start\":16733},{\"attributes\":{\"id\":\"formula_14\"},\"end\":16999,\"start\":16950},{\"attributes\":{\"id\":\"formula_15\"},\"end\":17229,\"start\":17199},{\"attributes\":{\"id\":\"formula_16\"},\"end\":18286,\"start\":18236},{\"attributes\":{\"id\":\"formula_17\"},\"end\":18577,\"start\":18530},{\"attributes\":{\"id\":\"formula_18\"},\"end\":18700,\"start\":18656},{\"attributes\":{\"id\":\"formula_19\"},\"end\":18793,\"start\":18741},{\"attributes\":{\"id\":\"formula_20\"},\"end\":19735,\"start\":19664},{\"attributes\":{\"id\":\"formula_21\"},\"end\":20629,\"start\":20484},{\"attributes\":{\"id\":\"formula_22\"},\"end\":21874,\"start\":21815},{\"attributes\":{\"id\":\"formula_23\"},\"end\":23019,\"start\":22707},{\"attributes\":{\"id\":\"formula_24\"},\"end\":23935,\"start\":23879},{\"attributes\":{\"id\":\"formula_25\"},\"end\":24546,\"start\":24514},{\"attributes\":{\"id\":\"formula_26\"},\"end\":24796,\"start\":24664},{\"attributes\":{\"id\":\"formula_27\"},\"end\":25352,\"start\":25297},{\"attributes\":{\"id\":\"formula_28\"},\"end\":25590,\"start\":25514},{\"attributes\":{\"id\":\"formula_29\"},\"end\":26052,\"start\":26005},{\"attributes\":{\"id\":\"formula_30\"},\"end\":26261,\"start\":26157},{\"attributes\":{\"id\":\"formula_31\"},\"end\":26534,\"start\":26288},{\"attributes\":{\"id\":\"formula_32\"},\"end\":26693,\"start\":26595},{\"attributes\":{\"id\":\"formula_33\"},\"end\":26855,\"start\":26704},{\"attributes\":{\"id\":\"formula_34\"},\"end\":27247,\"start\":27015},{\"attributes\":{\"id\":\"formula_35\"},\"end\":27363,\"start\":27301},{\"attributes\":{\"id\":\"formula_36\"},\"end\":27457,\"start\":27407},{\"attributes\":{\"id\":\"formula_37\"},\"end\":27625,\"start\":27555},{\"attributes\":{\"id\":\"formula_38\"},\"end\":27788,\"start\":27743},{\"attributes\":{\"id\":\"formula_39\"},\"end\":28246,\"start\":28228},{\"attributes\":{\"id\":\"formula_40\"},\"end\":28489,\"start\":28449},{\"attributes\":{\"id\":\"formula_41\"},\"end\":28746,\"start\":28518},{\"attributes\":{\"id\":\"formula_42\"},\"end\":28824,\"start\":28746},{\"attributes\":{\"id\":\"formula_43\"},\"end\":32044,\"start\":31994},{\"attributes\":{\"id\":\"formula_44\"},\"end\":32635,\"start\":32564},{\"attributes\":{\"id\":\"formula_45\"},\"end\":32992,\"start\":32961},{\"attributes\":{\"id\":\"formula_46\"},\"end\":33553,\"start\":33467},{\"attributes\":{\"id\":\"formula_47\"},\"end\":33632,\"start\":33560},{\"attributes\":{\"id\":\"formula_48\"},\"end\":33976,\"start\":33945},{\"attributes\":{\"id\":\"formula_49\"},\"end\":34818,\"start\":34734},{\"attributes\":{\"id\":\"formula_50\"},\"end\":37027,\"start\":36997},{\"attributes\":{\"id\":\"formula_51\"},\"end\":37367,\"start\":37345},{\"attributes\":{\"id\":\"formula_52\"},\"end\":37846,\"start\":37703},{\"attributes\":{\"id\":\"formula_53\"},\"end\":38034,\"start\":37988},{\"attributes\":{\"id\":\"formula_54\"},\"end\":38287,\"start\":38149},{\"attributes\":{\"id\":\"formula_55\"},\"end\":39991,\"start\":39916},{\"attributes\":{\"id\":\"formula_56\"},\"end\":40233,\"start\":40204},{\"attributes\":{\"id\":\"formula_57\"},\"end\":40400,\"start\":40371},{\"attributes\":{\"id\":\"formula_58\"},\"end\":40956,\"start\":40912},{\"attributes\":{\"id\":\"formula_59\"},\"end\":41165,\"start\":41088},{\"attributes\":{\"id\":\"formula_60\"},\"end\":41628,\"start\":41565},{\"attributes\":{\"id\":\"formula_61\"},\"end\":41678,\"start\":41633},{\"attributes\":{\"id\":\"formula_62\"},\"end\":42029,\"start\":41953},{\"attributes\":{\"id\":\"formula_63\"},\"end\":42588,\"start\":42514},{\"attributes\":{\"id\":\"formula_64\"},\"end\":42684,\"start\":42622},{\"attributes\":{\"id\":\"formula_65\"},\"end\":42793,\"start\":42684},{\"attributes\":{\"id\":\"formula_66\"},\"end\":42889,\"start\":42845},{\"attributes\":{\"id\":\"formula_67\"},\"end\":43701,\"start\":43616},{\"attributes\":{\"id\":\"formula_68\"},\"end\":43934,\"start\":43878},{\"attributes\":{\"id\":\"formula_69\"},\"end\":44218,\"start\":44154},{\"attributes\":{\"id\":\"formula_70\"},\"end\":44435,\"start\":44256},{\"attributes\":{\"id\":\"formula_72\"},\"end\":44983,\"start\":44967},{\"attributes\":{\"id\":\"formula_73\"},\"end\":45288,\"start\":45103},{\"attributes\":{\"id\":\"formula_74\"},\"end\":45466,\"start\":45313},{\"attributes\":{\"id\":\"formula_75\"},\"end\":45744,\"start\":45636},{\"attributes\":{\"id\":\"formula_76\"},\"end\":46097,\"start\":46046},{\"attributes\":{\"id\":\"formula_77\"},\"end\":46336,\"start\":46297},{\"attributes\":{\"id\":\"formula_78\"},\"end\":46504,\"start\":46421},{\"attributes\":{\"id\":\"formula_79\"},\"end\":46645,\"start\":46601},{\"attributes\":{\"id\":\"formula_80\"},\"end\":46894,\"start\":46842},{\"attributes\":{\"id\":\"formula_81\"},\"end\":47076,\"start\":46994},{\"attributes\":{\"id\":\"formula_82\"},\"end\":47194,\"start\":47107},{\"attributes\":{\"id\":\"formula_83\"},\"end\":47466,\"start\":47396},{\"attributes\":{\"id\":\"formula_84\"},\"end\":47758,\"start\":47733},{\"attributes\":{\"id\":\"formula_85\"},\"end\":47870,\"start\":47813},{\"attributes\":{\"id\":\"formula_86\"},\"end\":48049,\"start\":48020},{\"attributes\":{\"id\":\"formula_87\"},\"end\":48232,\"start\":48193},{\"attributes\":{\"id\":\"formula_88\"},\"end\":48472,\"start\":48232},{\"attributes\":{\"id\":\"formula_89\"},\"end\":48794,\"start\":48748},{\"attributes\":{\"id\":\"formula_90\"},\"end\":48883,\"start\":48839},{\"attributes\":{\"id\":\"formula_91\"},\"end\":49154,\"start\":49071},{\"attributes\":{\"id\":\"formula_92\"},\"end\":49417,\"start\":49166},{\"attributes\":{\"id\":\"formula_93\"},\"end\":49753,\"start\":49544},{\"attributes\":{\"id\":\"formula_94\"},\"end\":49908,\"start\":49889},{\"attributes\":{\"id\":\"formula_95\"},\"end\":50099,\"start\":50082},{\"attributes\":{\"id\":\"formula_96\"},\"end\":50389,\"start\":50333},{\"attributes\":{\"id\":\"formula_97\"},\"end\":50519,\"start\":50482},{\"attributes\":{\"id\":\"formula_98\"},\"end\":50603,\"start\":50519},{\"attributes\":{\"id\":\"formula_99\"},\"end\":50978,\"start\":50683},{\"attributes\":{\"id\":\"formula_100\"},\"end\":51214,\"start\":51044},{\"attributes\":{\"id\":\"formula_101\"},\"end\":51855,\"start\":51321},{\"attributes\":{\"id\":\"formula_102\"},\"end\":51986,\"start\":51875},{\"attributes\":{\"id\":\"formula_103\"},\"end\":52283,\"start\":52184},{\"attributes\":{\"id\":\"formula_104\"},\"end\":52495,\"start\":52440},{\"attributes\":{\"id\":\"formula_105\"},\"end\":52619,\"start\":52564},{\"attributes\":{\"id\":\"formula_106\"},\"end\":53607,\"start\":53546},{\"attributes\":{\"id\":\"formula_107\"},\"end\":53934,\"start\":53904},{\"attributes\":{\"id\":\"formula_108\"},\"end\":54319,\"start\":54241},{\"attributes\":{\"id\":\"formula_109\"},\"end\":54488,\"start\":54401},{\"attributes\":{\"id\":\"formula_110\"},\"end\":54639,\"start\":54560},{\"attributes\":{\"id\":\"formula_111\"},\"end\":55023,\"start\":54914},{\"attributes\":{\"id\":\"formula_112\"},\"end\":55225,\"start\":55170},{\"attributes\":{\"id\":\"formula_113\"},\"end\":55323,\"start\":55267},{\"attributes\":{\"id\":\"formula_114\"},\"end\":55412,\"start\":55355},{\"attributes\":{\"id\":\"formula_115\"},\"end\":55524,\"start\":55470},{\"attributes\":{\"id\":\"formula_116\"},\"end\":55604,\"start\":55548},{\"attributes\":{\"id\":\"formula_117\"},\"end\":55740,\"start\":55634},{\"attributes\":{\"id\":\"formula_118\"},\"end\":55864,\"start\":55752},{\"attributes\":{\"id\":\"formula_119\"},\"end\":55989,\"start\":55911},{\"attributes\":{\"id\":\"formula_120\"},\"end\":56654,\"start\":56578},{\"attributes\":{\"id\":\"formula_121\"},\"end\":56901,\"start\":56869},{\"attributes\":{\"id\":\"formula_122\"},\"end\":57446,\"start\":57374},{\"attributes\":{\"id\":\"formula_123\"},\"end\":57923,\"start\":57740},{\"attributes\":{\"id\":\"formula_124\"},\"end\":57976,\"start\":57923},{\"attributes\":{\"id\":\"formula_125\"},\"end\":58297,\"start\":58190},{\"attributes\":{\"id\":\"formula_126\"},\"end\":58715,\"start\":58340},{\"attributes\":{\"id\":\"formula_127\"},\"end\":59209,\"start\":59060},{\"attributes\":{\"id\":\"formula_128\"},\"end\":59485,\"start\":59257},{\"attributes\":{\"id\":\"formula_129\"},\"end\":59695,\"start\":59573},{\"attributes\":{\"id\":\"formula_130\"},\"end\":59728,\"start\":59713},{\"attributes\":{\"id\":\"formula_131\"},\"end\":59943,\"start\":59862},{\"attributes\":{\"id\":\"formula_132\"},\"end\":60595,\"start\":60510},{\"attributes\":{\"id\":\"formula_133\"},\"end\":60855,\"start\":60766},{\"attributes\":{\"id\":\"formula_134\"},\"end\":61242,\"start\":61108},{\"attributes\":{\"id\":\"formula_135\"},\"end\":61408,\"start\":61270},{\"attributes\":{\"id\":\"formula_136\"},\"end\":61613,\"start\":61506},{\"attributes\":{\"id\":\"formula_137\"},\"end\":61707,\"start\":61674},{\"attributes\":{\"id\":\"formula_138\"},\"end\":61920,\"start\":61849},{\"attributes\":{\"id\":\"formula_139\"},\"end\":62005,\"start\":61947},{\"attributes\":{\"id\":\"formula_140\"},\"end\":62150,\"start\":62097},{\"attributes\":{\"id\":\"formula_143\"},\"end\":62797,\"start\":62750},{\"attributes\":{\"id\":\"formula_144\"},\"end\":63095,\"start\":63013},{\"attributes\":{\"id\":\"formula_146\"},\"end\":63465,\"start\":63259},{\"attributes\":{\"id\":\"formula_149\"},\"end\":63843,\"start\":63802},{\"attributes\":{\"id\":\"formula_151\"},\"end\":64410,\"start\":64383},{\"attributes\":{\"id\":\"formula_152\"},\"end\":64580,\"start\":64542},{\"attributes\":{\"id\":\"formula_153\"},\"end\":64643,\"start\":64605},{\"attributes\":{\"id\":\"formula_154\"},\"end\":64826,\"start\":64778},{\"attributes\":{\"id\":\"formula_155\"},\"end\":64990,\"start\":64963},{\"attributes\":{\"id\":\"formula_156\"},\"end\":65077,\"start\":65012},{\"attributes\":{\"id\":\"formula_157\"},\"end\":65122,\"start\":65092},{\"attributes\":{\"id\":\"formula_158\"},\"end\":65368,\"start\":65314},{\"attributes\":{\"id\":\"formula_159\"},\"end\":65616,\"start\":65512},{\"attributes\":{\"id\":\"formula_160\"},\"end\":65716,\"start\":65675},{\"attributes\":{\"id\":\"formula_161\"},\"end\":66452,\"start\":66425},{\"attributes\":{\"id\":\"formula_162\"},\"end\":66560,\"start\":66452},{\"attributes\":{\"id\":\"formula_163\"},\"end\":66981,\"start\":66902},{\"attributes\":{\"id\":\"formula_164\"},\"end\":67088,\"start\":67024},{\"attributes\":{\"id\":\"formula_165\"},\"end\":67179,\"start\":67125},{\"attributes\":{\"id\":\"formula_166\"},\"end\":67273,\"start\":67195},{\"attributes\":{\"id\":\"formula_167\"},\"end\":67631,\"start\":67544},{\"attributes\":{\"id\":\"formula_168\"},\"end\":67964,\"start\":67930},{\"attributes\":{\"id\":\"formula_169\"},\"end\":68147,\"start\":68052}]", "table_ref": null, "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1684,\"start\":1672},{\"attributes\":{\"n\":\"2\"},\"end\":7672,\"start\":7657},{\"attributes\":{\"n\":\"2.1\"},\"end\":8641,\"start\":8618},{\"attributes\":{\"n\":\"2.2\"},\"end\":10268,\"start\":10234},{\"attributes\":{\"n\":\"3\"},\"end\":12124,\"start\":12109},{\"end\":14170,\"start\":14132},{\"attributes\":{\"n\":\"4\"},\"end\":15349,\"start\":15332},{\"attributes\":{\"n\":\"4.1\"},\"end\":16268,\"start\":16248},{\"attributes\":{\"n\":\"4.2\"},\"end\":19239,\"start\":19187},{\"attributes\":{\"n\":\"4.3\"},\"end\":21345,\"start\":21318},{\"attributes\":{\"n\":\"5\"},\"end\":27858,\"start\":27834},{\"end\":30682,\"start\":30652},{\"end\":30728,\"start\":30685},{\"end\":32158,\"start\":32125},{\"end\":32305,\"start\":32251},{\"end\":34596,\"start\":34581},{\"end\":34632,\"start\":34599},{\"end\":36857,\"start\":36828},{\"end\":39847,\"start\":39788},{\"end\":40716,\"start\":40694},{\"end\":56197,\"start\":56152},{\"end\":57041,\"start\":56989},{\"end\":60144,\"start\":60122},{\"end\":69399,\"start\":69389},{\"end\":69884,\"start\":69874},{\"end\":70567,\"start\":70565}]", "table": "[{\"end\":71341,\"start\":70816},{\"end\":71753,\"start\":71513},{\"end\":77769,\"start\":72655}]", "figure_caption": "[{\"end\":68365,\"start\":68190},{\"end\":69290,\"start\":68368},{\"end\":69387,\"start\":69293},{\"end\":69872,\"start\":69401},{\"end\":70098,\"start\":69886},{\"end\":70412,\"start\":70101},{\"end\":70563,\"start\":70415},{\"end\":70629,\"start\":70568},{\"end\":70816,\"start\":70632},{\"end\":71513,\"start\":71344},{\"end\":72655,\"start\":71756}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":29424,\"start\":29418},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":30174,\"start\":30162},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":30392,\"start\":30385},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":30648,\"start\":30634},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":36792,\"start\":36776},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":36824,\"start\":36809}]", "bib_author_first_name": "[{\"end\":82394,\"start\":82390},{\"end\":82405,\"start\":82404},{\"end\":82419,\"start\":82418},{\"end\":82430,\"start\":82429},{\"end\":82440,\"start\":82439},{\"end\":82449,\"start\":82448}]", "bib_author_last_name": "[{\"end\":82402,\"start\":82395},{\"end\":82416,\"start\":82406},{\"end\":82427,\"start\":82420},{\"end\":82437,\"start\":82431},{\"end\":82446,\"start\":82441},{\"end\":82464,\"start\":82450}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":2617244},\"end\":82628,\"start\":82334}]", "bib_title": "[{\"end\":82388,\"start\":82334}]", "bib_author": "[{\"end\":82404,\"start\":82390},{\"end\":82418,\"start\":82404},{\"end\":82429,\"start\":82418},{\"end\":82439,\"start\":82429},{\"end\":82448,\"start\":82439},{\"end\":82466,\"start\":82448}]", "bib_venue": "[{\"end\":82470,\"start\":82466}]"}}}, "year": 2023, "month": 12, "day": 17}