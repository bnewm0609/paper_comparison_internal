{"id": 249062776, "updated": "2022-10-25 07:43:31.544", "metadata": {"title": "Towards More Realistic Generation of Information-Seeking Conversations", "authors": "[{\"first\":\"Gangwoo\",\"last\":\"Kim\",\"middle\":[]},{\"first\":\"Sungdong\",\"last\":\"Kim\",\"middle\":[]},{\"first\":\"Kang\",\"last\":\"Yoo\",\"middle\":[\"Min\"]},{\"first\":\"Jaewoo\",\"last\":\"Kang\",\"middle\":[]}]", "venue": "ArXiv", "journal": "ArXiv", "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "In this paper, we introduce a novel framework SimSeek ( sim ulating information- seek ing conversation from unlabeled documents) and compare two variants of it to provide a deeper perspective into the information-seeking behavior. We \ufb01rst introduce a strong simulator for information- sym metric conversation, SimSeek-sym, where questioner and answerer share all knowledge when conversing with one another. Although it simulates reasonable conversations, we take a further step toward more realistic information-seeking conversation. Hence, we propose SimSeek-asym that assumes information asym metry between two agents, which encourages the questioner to seek new information from an inaccessible document. In our experiments, we demonstrate that SimSeek-asym successfully generates information-seeking conversations for two downstream tasks, CQA and conversational search. In particular, SimSeek-asym improves baseline models by 1.1-1.9 F1 score in QuAC (Choi et al., 2018), and by 1.1 of MRR in OR-QuAC (Qu et al., 2020). Moreover, we thoroughly analyze our synthetic datasets to identify crucial factors for realistic information-seeking conversation.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/corr/abs-2205-12609", "doi": "10.48550/arxiv.2205.12609"}}, "content": {"source": {"pdf_hash": "9f7f67870b6625084166aa7ed58200c75f5947d0", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2205.12609v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "4d3b599cf94101aa8281962d1683427de9cdbef4", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/9f7f67870b6625084166aa7ed58200c75f5947d0.txt", "contents": "\nTowards More Realistic Generation of Information-Seeking Conversations\n\n\nGangwoo Kim gangwoo_kim@korea.ac.kr \nSungdong Kim sungdong.kim@navercorp.com \n* Kang kangj@korea.ac.kr \nMin Yoo \nJaewoo Kang \n\u2020 Korea University \nNaver Ai Lab \nNaver Clova \nTowards More Realistic Generation of Information-Seeking Conversations\n\nIn this paper, we introduce a novel framework SimSeek (simulating information-seeking conversation from unlabeled documents) and compare two variants of it to provide a deeper perspective into the information-seeking behavior. We first introduce a strong simulator for information-symmetric conversation, SimSeek-sym, where questioner and answerer share all knowledge when conversing with one another. Although it simulates reasonable conversations, we take a further step toward more realistic information-seeking conversation. Hence, we propose SimSeekasym that assumes information asymmetry between two agents, which encourages the questioner to seek new information from an inaccessible document. In our experiments, we demonstrate that SimSeek-asym successfully generates information-seeking conversations for two downstream tasks, CQA and conversational search. In particular, SimSeek-asym improves baseline models by 1.1-1.9 F1 score in QuAC , and by 1.1 of MRR in OR-QuAC (Qu et al.,  2020). Moreover, we thoroughly analyze our synthetic datasets to identify crucial factors for realistic information-seeking conversation.\n\nIntroduction\n\nConversational question answering (CQA) involves modeling the information-seeking process of humans' dialogue. In the task, systems are asked to answer context-dependent questions that need to be understood in conversational flow. It makes CQA complex since even the same word could be interpreted differently depending on the context, and almost infinite cases of conversational context can be given with the question. To build robust * Equal contribution. \u2020 Corresponding author Who was their coach? q 2 (a) Information-symmetric Conversation (b) Information-asymmetric Conversation Figure 1: Examples of two conversation scenarios. In the former, the questioner can access the evidence document, allowing them to ask less related information to the conversation (q 1 , q 2 in (a)). In the latter, questioners are encouraged to seek new information from the hidden document. Hence, information-seeking behaviors are frequently observed; open-ended, unanswerable, and \"Anything else?\" questions (q 1 , q 2 , q 3 in (b)) system that can handle innumerable cases, largescale CQA datasets Reddy et al., 2019;Saeidi et al., 2018;Penha et al., 2019;Campos et al., 2020;Feng et al., 2020) have recently been developed. Still, it is practically infeasible to cover most of the interactions in real-world scenarios, which motivates automated methods for generating realistic CQA datasets.\n\nHowever, generating realistic CQA is a more challenging task, which requires synthesizing multiple interdependent ingredients, e.g., conversation history, appropriate follow-up question, and accurate answer from grounding document. Most of the literature has discussed only sub-parts of the overall process. A line of research in conversational question generation (CQG) aims to generate humanlike follow-up questions upon conversational history Pan et al., 2019;Qi et al., 2020;Gu et al., 2021). Another line of research has greatly improved answer accuracy Qu et al., 2019b;Kim et al., 2021;Zhao et al., 2021). In other words, they are limited in assuming that all other ingredients (i.e., held-out conversations by humans and their gold answer) are provided. Thus, the prior approaches cannot construct whole conversations upon the unlabeled corpus and therefore have never shown a practical use of synthetic conversations.\n\nIn this paper, we delve into the problem of generating a realistic CQA dataset from unlabeled documents. We focus on information-asymmetric conversations where reference information is unequally distributed to two agents, encouraging more realistic conversation. As illustrated in Figure  1 (a), when questioners have excessive information, they often assume and ask for external knowledge less relevant to the conversation. On the other hand, information asymmetry drives them to seek new information in conversational style or sometimes fail to do so (q 1 , q 2 , and q 3 in Figure 1 (b)). We claim that simulating these information-seeking behaviors is an important step towards a more realistic generation of CQA.\n\nTo take a further step towards generating realistic CQA, we propose and contrast two novel frameworks, SimSeek (Simulating Information-Seeking conversation) that can generate synthetic conversation upon the unlabeled corpus, replicating each scenario. We first introduce a strong simulator for information-symmetric conversation (1) SimSeek-sym where CQG model generates context-dependent questions based on the answer candidates, which are automatically provided in advance by an extractive model. Although it succeeds in generating reasonable conversations, we propose a more realistic approach that designs informationasymmetry, (2) SimSeek-asym. In SimSeek-asym, the CQG component first asks questions without accessing any answer-containing document and target answer. Then, an answerer model predicts corresponding answers to the questions.\n\nTo demonstrate the effectiveness of SimSeek in a semi-supervised setup, we conduct experiments in one of the challenging CQA benchmarks, QuAC . To the best of our knowledge, it is the first successful adaptation of the synthetic datasets for the semi-supervised CQA. In the experiment, SimSeek-asym consistently improves backbone CQA models by 1.1-1.9 F1 score, outperforming other CQA generation baselines. Besides, our resulting dataset could also enhance dense retrieval models for the conversational search task. Our framework improves the baseline dense retriever, DPR (Karpukhin et al., 2020) on the conversational search benchmark, OR-QuAC (Qu et al., 2020), by 1.1 of MRR and 1.3 of R@5.\n\nTo provide a deeper perspective into the information-seeking behavior, we thoroughly analyze how the two frameworks synthesize the results differently. Following Qi et al. (2020), we quantify various properties, specificity, answer relevance, and informativeness of the synthetic datasets. We compare them with a human-annotated dataset on the metrics and find that information asymmetry makes conversations closer to the human's information-seeking behavior.\n\nOur main contributions are summarized as:\n\n\u2022 We propose a novel framework, SimSeek, which can generate synthetic informationseeking conversations from unlabeled documents.\n\n\u2022 To the best of our knowledge, we are the first to demonstrate the effectiveness of synthetic datasets in the semi-supervised CQA, achieving competitive performance with humans.\n\n\u2022 We provide insight into realistic informationseeking conversations by contrasting two proposed approaches that simulate each CQA scenario.\n\n\nBackground\n\nIn the information-seeking conversation, there are two roles, questioner and answerer, who converse with the specific topic. To provide appropriate information to the questioner, the answerer can utilize the document that consists of answer-containing passage c and its background knowledge B which includes the title of the document and its abstractive description. Let q t is the current question and a t is its corresponding answer at turn t. Formally, CQA systems are required to find correct answer a t to the question q t from the answer-containing passage c based on the conversational history H t = [(q 1 , a 1 ), ..., (q t\u22121 , a t\u22121 )], i.e. p(a t | q t , c, H t ).\n\nTraditionally, a line of CQG research assumes that the questioner can access the answercontaining passage c. In other words, they formulate the task of generating conversational question q t based on the passage c and answer a t , i.e. p(q t | c, a t , H t ) Pan et al., 2019;Gu et al., 2021). They propose the formulation as a straightforward extension of the dominant paradigm in single-turn QA generation, where questions are generated based on the context c and answer a. Recently, Qi et al. (2020) suggest another approach to promote a more realistic scenario for information-seeking conversation. In the setup, CQG modules are blinded to the answer-containing passage. Instead, they are trained to generate conversational question q t , relying on its background information B, i.e. p(q t | B, H t ).\n\n\nSimSeek: Simulating Information-Seeking Conversation\n\nWe introduce two novel frameworks, SimSeek-sym and SimSeek-asym, that generate the synthetic conversations in different CQA scenarios, as illustrated in Figure 2. Each framework tackles the following CQA scenarios, respectively: (1) informationsymmetric conversation where questioner and answerer share all information about the topic (2) information-asymmetric conversation where questioners cannot access the evidence document when asking questions.\n\n\nSimSeek-sym\n\nWe propose SimSeek-sym to simulate the information-symmetric conversation.\n\nSimSeeksym consists of two components, conversational answer extractor (CAE) and answer-grounded conversational question generator (CQG answer ). At every turn t, the CAE identifies candidate spans that are likely to be answers to questions from the evidence passage, considering the conversation history. Then, the CQG prior generates conversational question that is likely to be answered by identified spans (Figure 2 (a)).\n\n\nConversational Answer Extractor\n\nThe component detects spans that are likely to be answered to the subsequent question in the conversation. It aims to select phrases from the passage c which are natural to the conversational flow. Specifically, the CAE model p sym a (a t | H t , c) calculates the likelihood of answer span a t and predicts the most probable prediction\u00e2 t without taking the current question q t . By the likelihood values, we obtain the set of topk answer candidates\u00c2 t = {\u00e2 1 t ,\u00e2 2 t , . . . ,\u00e2 k t }. By jointly encoding the history H t with the passage c, we enable the component to consider conversational flow when extracting answer candidates. We adapt 2D span extraction model proposed by Lewis et al. (2021).\n\nAnswer-grounded CQG Given the passage and answer spans extracted from it, the CQG answer generates a follow-up question on the held-out conversation. Thus, it should satisfy multiple objectives at once; generating proper question for the answer and coherent with the history. Formally speaking, the CQG answer synthesizes the conversational question q based on the history, document, and extracted answer, i.e. p sym q (q t | c, a t , H t ). We employ a T5-based sequence-to-sequence model as backbone of the component (Raffel et al., 2020). In particular, we highlight target answer a t as rationale span in the passage c using a special token, \"<hl>\", following Gu et al. (2021). In addition, we adopt a mask prediction scheme that aligns its objective with that of the pre-training phase, shown to be sample efficient in prior work (Chada and Natarajan, 2021).\n\n\nSimSeek-asym\n\nTo replicate the information-asymmetric scenario, we introduce a novel framework SimSeek-asym consisting of two components, prior-grounded conversational question generator (CQG prior ) and conversational answer finder (CAF). At every turn, the CQG prior first generates conversational question, only relying on prior knowledge (i.e., background information involving the topic) with the conversational history. Then, the CAF comprehends the generated question and returns the most probable answer to the question (Figure 2 (b)).\n\nPrior-grounded CQG We introduce priorgrounded CQG (CQG prior ) that can ask the question from insufficient information. Hence, CQG prior depends neither on the answer at the current turn nor answer-containing passage. Instead, the generator asks question solely based on the prior knowledge about the topic, B. Specifically, it synthesizes conversational question q t from given the history H t and background B, i.e. p asym q (q t | H t , B). For a fair comparison of two CQG components, T5-based sequence generator is adopted to implement the CQG prior , same with the CQG answer . Although they share the same architecture, CQG prior plays a crucial role for simulating more realistic information-seeking conversation. We emphasize that proper level of information insufficiency encourages the model to learn to ask questions that implicate information needs. We further demonstrate a thorough analysis on it in Section 6.\n\n\nConversational Answer Finder\n\nThe conversational answer finder (CAF) annotates answer to the generated question given the evidence passage. Formally, its objective is modeling p asym a (a t | q t , c, H t ). CAF plays the answerer's role in the information-seeking scenario by providing the requested information from the passage c. Note that any CQA model can be adopted as the CAF component, enabling SimSeek-asym to generalize toward other advanced CQA approaches effectively.\n\n\nExperimental Setup\n\nIn this section, we specify our experimental setup and compare our framework to baseline approaches for generating CQA datasets. More implementation and experimental details are in Appendix A.\n\n\nDatasets\n\nQuAC QuAC  consists of 100k QA pairs in information-asymmetric dialogues, where a questioner asks questions based on a topic with background information, and an answerer returns the answers in the form of text spans in Wikipedia document. Restricting the questioners from accessing the answer-containing document, the authors encourage them to seek new information on a topic via conversation. To simulate a semi-supervised setup, we split the original training set of QuAC into three subsets, QuAC seen , QuAC unseen , and the validation set 1 . Detailed statistic is described in Table 6. Following , we evaluate models with the F1 score for QuAC. Since the test set is only available in the QuAC leaderboard, we evaluate models on the development set 2 . We further detail the experimental setup in Appendix A.2.\n\n\nOR-QuAC Qu et al. (2020) extend the original\n\nQuAC dataset to open-domain setup 3 . It assumes that a ground-truth document is not given in advance, which means the answerers do not know what to be asked before a conversation begins. Instead, they first need to search relevant passages from web-scale documents (about 11M chunked passages) based on the given conversational history and current question. After reading the retrieved passage, they predict an answer to the question. Following the original setup in Qu et al. (2020), we only regard previous questions {q 1 , q 2 , ..., q t\u22121 } as history without answers. Since OR-QuAC is similarly partitioned with our QuAC splits (see details in Table 6), we use same synthetic conversations that are used for CQA task. More experimental details are in Appendix A.3. For evaluation, mean reciprocal rank (MRR), Recall@5 (R@5), and Re-call@20 (R@20) are used to evaluate first stage conversational retrieval.\n\n\nSynthetic CQA Generation\n\nTo train all modules in our frameworks, SimSeeksym and SimSeek-asym, we assume source la-\nbeled dataset D = {(B i , c i , q i , a i )} |D| i=0 ,\nwhere the q and a denote all questions and answers up to turn T in a conversation. Once each module is trained using the D, the modules sequentially generates pseudo conversational questionsq and answers\u00e2 on M number of unlabeled doc-\numents C = {(B j ,\u0109 j )} M j=0 and finally result\u015d D = {(B j ,\u0109 j ,q j ,\u00e2 j )} M j=0 .\nFor semi-supervised CQA setup, we set QuAC seen as D and documents in QuAC unseen as C. The number of turns T is set to 6 in our generations. For OR-QuAC experiment, we follow the semi-supervised setup since OR-QuAC shares the same document split with the semi-supervised setup. All CQG models are based on T5-large (Raffel et al., 2020) model, and we use 5 for beam size of beam search and 0.98 for top-p value of nucleus sampling (Holtzman et al., 2020) with 1.2 temperature. We employ the same backbone for the CAF with corresponding CQA student models, RoBERTa-base (R-base), RoBERTa-Large (R-large), and Longformer-large (L-large) Beltagy et al., 2020).\n\n\nBaselines for Synthetic CQA Generation\n\nWe introduce strong baselines for synthesizing CQA datasets and compare them with our methods. For a fair comparison, we train all components of approaches on the same labeled dataset D, and generate the synthetic datasetD on the unlabeled corpus C.\n\nBack-translation Back-translation is one of the most widely used methods for data augmentation in NLP fields (Sennrich et al., 2016;Fadaee et al., 2017;Xie et al., 2020). We translate an existing question q from the labeled dataset D into another target language and then translate it back into the source language to obtain a paraphrased question. We set the target language as German (de) while the source language is English (en). Specifically, we use translation models for both directions (en -> de) and (de -> en), which are pre-trained on WMT-19 (Ng et al., 2019). Elgohary et al. (2019) rewrite conversational questions of QuAC into self-contained questions that could be understood without the conversation. Following Kim et al. (2021), we consider the resulting dataset, CANARD, as an additional dataset for training CQA models. Note that CANARAD train and QuAC seen share the same passages.\n\n\nDe-contextualization\n\nPAQ-CANARD For the single-turn QA generation, Lewis et al. (2021) propose PAQ, the pipeline strategy composed of three phases, answer extraction, question generation, and round-trip filtration. Even though it is not designed to generate context-dependent questions, we generate decontextualized conversations like CANARD (Elgohary et al., 2019). Thus, we fine-tune every component of the PAQ on CANARD train . Then, we include it as one of the baselines leveraging singleturn QA.\n\n\nPAQ-QuAC\n\nWe construct a baseline by using a straightforward way to extend the single-turn QG framework, e.g., PAQ (Lewis et al., 2021), to a conversational setup. We replace the question generator in PAQ with CQG answer model that also takes the conversation history as input. Different from our SimSeek-sym, the baseline utilizes the original answer extractor model of Lewis et al. (2021), which extracts answer candidates regardless of conversational history, i.e. p a (a | c). From a given answer-containing passage c, top-k answer candidates are extracted by the model in advance. Then, we randomly take out an answer from the candidates to feed it to the CQG answer at every turns.\n\n\nCQA Models\n\nAfter building synthetic CQA datasets upon the unlabeled corpus C, the baseline CQA models are trained on the datasets. By comparing the resulting CQA performances, we evaluate the effectiveness of the generated datasetD. We test three backbone architectures for CQA, base and large size of RoBERTa , and Longformer-large (Beltagy et al., 2020). By contrasting various sizes of pre-trained models, we show the different effects of data augmentation. In addition, we involve Longformer architecture that has been shown to be effective for encoding much longer history (Zhao et al., 2021), which achieves competitive performance with the state-of-the-art approach.  Table 1: Comparison over synthetic CQA generation methods based on the development set of QuAC in semisupervised setup. We report F1 scores for the end CQA performance. First, models in each method are trained on labeled dataset D. Then, synthetic CQA datasetD is generated by the each method. Finally, student CQA models in varying size are fine-tuned on the datasets eitherD or D +D.\n\n\nExperimental Results\n\nWe demonstrate the effectiveness of our frameworks, comparing them to the aforementioned baseline approaches. In the following experiments, every approach is measured with the end performance in downstream tasks.\n\n\nSemi-supervised CQA\n\nWe evaluate the effectiveness of our frameworks on a semi-supervised setup which leverages both labeled (D) and synthetic (D) datasets. Table 1 shows the results. The \"Human Annotation\" indicates the student CQA models are trained on the human-annotated dataset, i.e., QuAC unseen , and is understood as upper bound of synthetic dataset generation. On the other hand, the \"None\" is a de-facto baseline that does not use any unlabeled corpus C, but rather trained on the labeled dataset D and its perturbed dataset, i.e., |D| = 0. Similarly, Back-Translation and De-contextualization do not take the C but only perturb or transform the questions in the D. The question augmentation methods often degrade the baseline performance (None), showing limited improvement only in the RoBERTa-large backbone. PAQ-CANARD shows the lowest performance in all CQA backbones when using the synthetic dataset alone (D), which shows that it is tricky to use single-turn QA generation to CQA. How-  ever, adopting CQG model that can generate the conversational questions (PAQ-QuAC) improves CQA performance with a gap of 6-9 F1 scores in the setting. It indicates that CQA models need to be trained to understand the conversational questions.\n\nSimSeek-sym, whose components are history-dependent, achieves higher scores than the baseline approaches. On the other hand, results of the combined training (D +D) show a different tendency. Most of the baselines cause significant performance degradation even though CQA models are trained on larger dataset, which implies the difficulty of generating realistic CQA examples. On the other hand, our proposed framework SimSeek-asym consistently improves CQA perfor- Figure 3: Assessment of synthetic CQA datasets upon three evaluation metrics. Specificity and informativeness are proposed by Qi et al. (2020) to automatically evaluate the quality of generated questions. In addition to those metrics, we further analyze answer relevance which checks the relevance of the answer with given conversational context. We find that the synthetic dataset from SimSeek-sym often too generic (low question specificity) and clearly obvious to be answered (high answer relevance) at the same time. However, we observe the humanannotated dataset (Original) shows moderate scores over all the metrics indicating some ambiguity is in the real scenario. On the other hand, the synthetic dataset from SimSeek-asym-L-large shows the most similar patterns with the human-annotated dataset. mance over all CQA backbones. Specifically, it improves RoBERTa-large and Longformer-large by 1.9 and 1.1 F1 scores compared to the main baseline (None), respectively. Surprisingly, Longformerlarge achieves competitive performance to humans with a gap of only 0.7 when trained with the synthetic dataset by our SimSeek-asym.\n\nMoreover, when using the synthetic dataset only, SimSeek-asym shows dominant performance compared to other baselines. The performance gap increases as the model size gets larger. While the performances of other baseline methods are steady regardless of the CQA backbone, SimSeek-asym achieves a better score with a more capable backbone. It implies that SimSeek-asym could generate a higher quality of synthetic dataset by leveraging better CQA models.\n\n\nUtility in Conversational Search\n\nWe also demonstrate the effectiveness of our synthetic dataset in another information-seeking task, convsersational search. It is an open-domain CQA problem that retrieves relevant document from a given conversational context. Table 2 shows the retrieval performances of baseline passage retireval model, DPR (Karpukhin et al., 2020), and how it is improved by our method on OR-QuAC dataset (Qu et al., 2020). Training the DPR with more steps without additional synthetic dataset significantly degrades the performance, which implies overfitting. SimSeek-sym performs better than further training baseline but still fails to lift the score. SimSeek-asym-L-large, which employs Longformer-large as the backbone for CAF module, only improves the performance of the baseline DPR model. Note that although dense retrievers do not encode any answers to questions on OR-QuAC, retrieval performances vary depending on the capabilities of answerer model. It implies that interacting with a better answerer encourages the questioner to generate more realistic questions that are likely to be asked in information-asymmetric conversation.\n\n6 Analysis and Discussion\n\n\nAssessment of Synthetic Dataset\n\nWe further explore which factors determine the gain from synthetic conversations. For quantifying the properties of question-answer pair, we adopt three metrics, question specificity, answer relevance, and answer informativeness, proposed by Lowe et al. (2017); Qi et al. (2020). We train two additional classifier models. One is specificity classifier p s (q t = specific | H t , q t ) to evaluate specificity of the synthetic questions as suggested by Qi et al. (2020). Another is answer relevance classifier p r (a t = relevance | H t , q t , a t ) judging relevance between conversational context and corresponding answer. We train the classifiers by contrasting negative examples. Specifically, frequent questions which appear more than once in the training dataset or random questions are sampled for the negative examples to train p s by 50% of the time (Qi et al., 2020). To train p r , we select random answers in the same conversation for the negatives by 50% of the time. More implementation details are in Appendix A.4. In addition to the two classifiers, we also adopt the informativeness metric proposed by Qi et al. (2020). It computes how much a t provides distinct and new information compared to previous answers a 1:t\u22121 , i.e., 1 \u2212 max 1\u2264i<t Precision(a t , a i ).\n\nIt is another proxy to judge the usefulness of the corresponding question q t . Figure 3 shows results of three metrics among various synthetic datasets and human-annotated dataset (Original). Especially, we plot the scores (y-axis) by conversational turns (x-axis) to get better understanding. First, we observe our SimSeekasym datasets show similar patterns with the Original until 3rd turn in specificity (Figure 3 (a)). However, the scores increase drastically as conversation progresses while the specificity of human questions increases slowly. In case of SimSeek-sym, it shows lower question specificity across all turns, indicating that the questions are often generic, e.g. \"What else?\" or \"Anything else?\". Even though the general questions can be occurred naturally in information-seeking conversation, they make divergence of the conversation flow as discussed in Qi et al. (2020). The similar tendency is observed in Table 3. Actual percentage of the \"Anything else\" questions from SimSeek-sym is significantly higher than those of original QuAC and SimSeek-asym. Thus, keeping moderate specificity like Original is one of improvement points.\n\nOn the other hand, both answer relevance and informativeness show similar tendency. First, SimSeek-sym shows the highest answer relevance across all turns as shown in Figure 3 (b). And it keeps its informativeness relatively high while informativeness scores of others continuously decrease (Figure 3 (c)). It implies the answers of SimSeek-sym are clearly answerable and the questions for them are less ambiguous which is far from realistic information-seeking. Actually, the number of unanswerable questions in SimSeek-sym are significantly less than others as shown in Table 3. Second, SimSeek-asym-L-large shows the most similar pattern with the Original in both answer relevance and informativeness. It implies that the synthetic questions and answers generated by SimSeek-asym-L-large mimic the realistic   information-seeking conversation of human very well. However, when the RoBERTa-based model is used for the CAF, those two metrics decrease significantly as progress of conversation indicating importance of answerer, again. Table 4 presents intrinsic evaluation results of our two kinds of CQG models. Scores represent the lexical similarity of the generated questions with the ground-truth questions when ground-truth conversational history is given. The sub-component of SimSeek-sym, CQG answer significantly outperforms CQG prior in BLEU scores of all n-gram levels. The contrasting results to our experiments (Section 5.1) imply that accurate generation grounded on the answer is not enough to generate realistic conversation. Instead, we presume other vital factors, such as question based on information asymmetry, proper answer selection in natural conversational flow, and their chained interactions, contribute to a better synthetic CQA generation.\n\n\nIntrinsic Evaluation of CQG models\n\nSimSeek-sym\n\nTitle : Native Americans in the United States Section Title : Self-determination Document c : \u00b7 \u00b7 \u00b7 Upset with tribal government and the failures of the federal government to enforce treaty rights, about 300 Oglala Lakota and AIM activists took control of Wounded Knee on February 27, 1973. Indian activists from around the country joined them at Pine Ridge, and the occupation became a symbol of rising American Indian identity and power. Federal law enforcement officials and the national guard cordoned off the town, and the two sides had a standoff for 71 days. \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 q 3 : What happened at Wounded Knee? a 3 : Indian activists from around the country joined them at Pine Ridge, and the occupation became a symbol of rising American Indian identity and power. q 4 : What happened after they took control of Pine Ridge? a 4 : Federal law enforcement officials and the national guard cordoned off the town, and the two sides had a standoff for 71 days. q 5 : What happened during the standoff? a 5 : During much gunfire, one United States Marshal was wounded and paralyzed.\n\n\n\u00b7 \u00b7 \u00b7\n\nSimSeek-asym Title : Thor Heyerdahl Section Title : Kon-Tiki expedition\n\nBackground B Thor Heyerdahl (October 6, 1914-April 18, 2002) was a Norwegian adventurer and ethnographer with a background in zoology, botany, and geography. He became notable for his Kon-Tiki expedition in 1947, \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 \u00b7 q 4 : What were some of the things he found on the Kon-Tiki expedition? a 4 : The raft proved to be highly manoeuvrable, and fish congregated between the nine balsa logs in such numbers that ancient sailors could have possibly relied on fish for hydration in the absence of other sources of fresh water. q 5 : Are there any other interesting aspects about this article? a 5 : The documentary film of the expedition entitled Kon-Tiki won an Academy Award in 1951. q 6 : Why did the film win an Academy Award? a 6 : CANNOTANSWER Table 5: Examples of the resulting datasets simulated by SimSeek-sym and SimSeek-asym. In the first case (above), SimSeek-sym asks unspecific questions repeatedly, which can effortlessly achieve the goals, answer relevance and coherence with the conversation; but it leads to the shallow conversation. On the contrary, SimSeek-asym successfully mimics diverse information-seeking behaviors that are commonly occurred in human dialogue.\n\n\nQualitative Analysis\n\nWe explore how SimSeek-sym fails to simulate realistic conversations, but SimSeek-asym successfully mimics information-seeking behaviors. The first case in Table 5 shows the synthetic conversation simulated by SimSeek-sym. In the example, consecutive and disjoint spans are selected for answers from the evidence document as the conversation progresses. Moreover, all questions contain a common phrase \"What happened \u00b7 \u00b7 \u00b7 \" while mentioning keywords that have appeared in previous answers. Asking these ambiguous questions repeatedly would be the best option for the answer-grounded CQG to achieve answer relevance and coherence with the conversation easily.\n\nOn the other hand, we observe various information-seeking behaviors in the second case from our SimSeek-asym. The lack of information impels questioners to ask open-ended questions using uncertain words such as \"some of the things\" in q 4 . When they cannot find adequate follow-up questions on the conversation, they ask an additional information as in q 5 . They sometimes fail to acquire new knowledge when the question cannot be answered by the evidence document (see q 6 , a 6 ).\n\n\nRelated work\n\nConversational Question Answering With the advent of recent large-scale CQA datasets Reddy et al., 2019), numerous studies proposed methods to resolve the challenging task. Most works focused on developing model structures (Zhu et al., 2018;Qu et al., 2019a,b) that are specialized in the CQA task. Several works demonstrated the effectiveness of the flow mechanism in CQA . Most recently, leveraging self-contained questions (Kim et al., 2021) or encoding longer context (Zhao et al., 2021) have been shown to be effective in the task.\n\nSynthetic QA Generation Many question generation (QG) researches have sparked advances in various QA tasks (Dhingra et al., 2018;Dong et al., 2019;Puri et al., 2020;Lewis et al., 2021). Usually, it is used for data augmentation, unsupervised or semisupervised QA, and domain adaptation. Most of early studies propose to generate them in a clozestyle (Dhingra et al., 2018; or by using pre-defined templates (Fabbri et al., 2020). Recent studies for the synthetic QA generation propose the pipeline strategies composed of three subphases, answer extraction, question generation, and various data selection steps such as round-trip filtration Puri et al., 2020;Lewis et al., 2021).\n\n\nConversational Question Generation\n\nMany works attempt to generate human-like conversational questions. Pan et al. (2019);  introduce the challenge of CQG and successfully extend the single-turn question generation to consider conversational input. Their proposed models show effectiveness compared to single-turn question generators. However, most of the works are based on the information-symmetric assumption that can access the evidence document (Pan et al., 2019;Nakanishi et al., 2019;Gu et al., 2021). Recently, Qi et al. (2020) study information-asymmetric conversation. They first attempt to generate the conversational questions without evidence document and provide various analyses for the questions. Our work is different from the previous works in that we generate a whole conversation based on both CQA scenarios when only unlabeled document is given. Also, we successfully adapt the synthetic datasets to semisupervised CQA.\n\nAssessment of synthetic conversations Most CQG works compare their methods on automatic reference-based evaluation such as BLEU and ROUGE scores (Pan et al., 2019;Nakanishi et al., 2019;Gu et al., 2021). However, the reference-based evaluation is limited in measuring directed generation and inappropriate to measure open-ended generation problem. To mitigate the problem in response generation, Lowe et al. (2017) explore model-based evaluation. Similarly, Mehri and Eskenazi (2020) propose referencefree evaluation protocol for open-domain dialogue based on pre-trained dialogue model. For another open-ended generation, information-asymmetric conversation, Qi et al. (2020) propose model-based evaluation metrics, specificity and informativeness, to evaluate synthetic conversational questions. We also inherit those metrics to compare synthetic conversations from two CQA scenarios.\n\n\nConclusion\n\nIn this work, we propose a novel framework, Sim-Seek, simulating information-seeking conversation from given unlabeled documents. We assume two scenarios according to the existence of information symmetry and compare them in the semi-supervised CQA and conversational search task. Experimental result shows that our SimSeekasym based on an information-asymmetric scenario achieves competitive performance gain with a human upper bound. Moreover, we provide insightful analyses to help understand the informationseeking conversation better. As a result, we find the clue that asking questions with proper specificity and ambiguity is an important step to simulate more realistic conversations in terms of informationseeking.\n\nFigure 2 :\n2Overview of our frameworks, SimSeek-sym and SimSeek-asym. (a) SimSeek-sym consists of answergrounded CQG and conversational answer extractor to simulate information-symmetric conversation. Both models can access the same evidence passage. (b) SimSeek-asym consists of prior-grounded CQG and conversational answer finder to simulate information-aymmetric conversation. Each model access background knowledge B and evidence passage c to output question and answer, respectively.\n\nTable 2 :\n2Evaluation results of conversational passage retrieval on OR-QuAC test set. The R and L indicate RoBERTa and Longformer architectures are used for the CAF model, respectively.\n\nTable 3 :\n3Categorical analysis for comparing synthetic \ndatasets with the original QuAC. We report data of the \nSimSeek-asym based on Longformer-large. For scal-\nable analysis, we automatically count \"Anything else?\" \nquestions by checking question contains certain strings \n(e.g., \"other\" and \"else\") \n\nTrained on Model \nB-1 \nB-2 \nB-3 B-4 \n\nQuACseen \nCQGanswer 28.2 18.0 11.9 9.1 \nCQGprior \n23.9 14.4 \n9.0 \n6.4 \n\nQuAC f ull \nCQGanswer 29.6 19.3 12.8 9.7 \nCQGprior \n24.5 15.2 \n9.8 \n7.4 \n\n\n\nTable 4 :\n4Automatic evaluation over two different CQG models of our frameworks on QuAC development set. The B-* indicate BLEU scores.\nSubsets are partitioned following Elgohary et al. (2019) 2 quac.ai 3 github.com/prdwb/orconvqa-release\nAcknowledgementsThe authors would like to thank to Jung-Woo Ha and other members of NAVER AI for their constructive comments.A Implementation DetailsAll our implementations are based on huggingface's transformers library(Wolf et al., 2019)and NAVER Smart Machine Learning (NSML) platform(Sung et al., 2017;Kim et al., 2018).A.1 Training models in SimSeekWe train overall four models, CAE, CQG answer , CQG prior , and CAF on QuAC seen split for Sim-Seek. We optimize all models using AdamW optimizer with linear learning rate (lr) scheduling(Kingma and Ba, 2017). The best performing checkpoint is selected according to validation score.We employ 2D span extraction model proposed in PAQ with bert-base-uncased backbone for CAELewis et al., 2021). We find using previous question and answer pair, (q t\u22121 , a t\u22121 ), instead of the whole history H t is enough to get reasonable performance. The qa pair is appended to c with [SEP] token for input representation. We set overall maximum sequence length to 512 and the maximum history length 32. We train it for 3 epochs with 8 for batch size, 3e-5 for lr on 1 32GB V100 GPU. To evaluate the model, we check whether the ground-truth answer span a t is in the predicted top-10 answer spans\u00c2 t , i.e. Recall@10.For both CQG models, we employ same t5-large backbone but different input representations. First, c, <sep>, q 1 , <sep>, a 1 , ..., a t\u22121 , <mask>, a t , <sep> are concatenated to represent input for CQG answer , where the <sep> and <mask> are special seperator and masking token, respectively. And the output representation of it is concatenation of <bos>, q t , and <eos>. As mentioned in Section 3.1, the c is highlighted by <hl> tokens to emphasize rationale for a t(Gu et al., 2021). Second, B, <sep>, q 1 , <sep>, a 1 , ..., a t\u22121 , <mask> are concatenated to represent input for CQG prior and the output representation is the same with that of CQG answer . Actually, the B is composed of three textual inputs, title, section title, and background (abstractive description) (Please seeTable 5). They are also concatenated with the <sep> token to represent the B. The masked question prediction scheme is inspired byChada and Natarajan (2021)and we find the scheme is more sample efficient in our preliminary experiment. We train both CQG models for 10 epochs with 16 for batch size, 3e-5 for lr, 0.1 for lr warming up, and 0.01 for weight decay on 2 32GB V100 GPUs. We set maximum sequence length for the input representations to 512 and maximum context length to 384. The context means c and B for CQG answer and CQG prior , respectively.We adopt three CQA backbone architectures, RoBERTa-base, RoBERTa-large , and Longformer-large(Beltagy et al., 2020), which are shown to be effective in CQA task. Please note that any CQA models can be used for CAF model as a teacher. For all CQA models, we concatenate the title, sub-title, and previous history to question text, separating with the special token[SEP]. We train all models for 2 epochs without weight decay on all datasets and set maximum answer length 64. CQA models return \"CANNOTANSWER\" when all scores of answer logits do not exceed a pre-defined threshold. RoBERTa backbones are trained for batch size 12 per each GPU without weight decay. We set the maximum length for query and sequence as 128 and 512, respectively. Due to their limitation of the input sequence length, a single question-answer pair at previous turn (t \u2212 1) is included to the input, shown to be most effective in prior works(Qu et al., 2019a). When Longformer architecture is adopted, we find the optimal setup of the maximum length for query and sequence as 768 and 2048, respectively. It encodes all previous history and titles when providing answers. They are trained with batch size 1 per each GPU. For large size of models, we train them with learning rate 1.5e-5 on 8 32GB V100 GPUs.A.2 Semi-supervised CQAWe split the original QuAC dataset into two subsets of QuAC seen and QuAC unseen , following CA-NARD Elgohary et al. (2019). To control the effect of sample size, we generate maximum 6 questionanswer pairs for each passage when using SimSeek and PAQ-based QA generation approaches. When simulating conversations with SimSeek-sym, final answers are randomly selected among top-5 span candidates detected by the answer extractor. In addition, we use technique for considering unanswerable questions at the answer extraction step. Those special answers are included to answer candidates whenever the answer extractor fails to provide topk candidates. For all components, we use the same hyperparameter setup as they are trained, otherwise specified.Table 6: Data statistics of QuAC dataset used in our experiments. Note that we use questions and answers in QuAC unseen to represent human upper bound. OR-QuAC also contains 11M of chunked passages collection for the retrieval. We split datasets following CA-NARD(Elgohary et al., 2019), which is smilar with OR-QuAC(Qu et al., 2020)A.3 Conversational SearchWe employ dual-encoder based dense retriever, DPR, for our baseline(Karpukhin et al., 2020). Especially, we initialize the encoders with pre-trained DPR model on Natural Questions(Kwiatkowski et al., 2019). To represent query input, we concatenate questions {q 1 , q 2 , ..., q t } with [SEP] token. We truncate the input length when longer than 128 but retain first question q 1 at the same time(Qu et al., 2020). The context input is concatenation c and its title with[SEP]. The maximum length for the context input is 384. We train the model for 10 epochs with 128 for batch size, 3e-5 for lr, 0.1 for lr warming up, and 0.01 for weight decay. All DPR models are trained by using in-batch negative without any usage of hard negatives(Karpukhin et al., 2020).A.4 Specificity and Answer Relevance ClassifierFollowingQi et al. (2020), we train specificity classifier and also answer relevance classifier to evaluate synthetic conversations. Based on a single encoder, binary classification is conducted to discriminate positive and negative examples as next sentence prediction task of . The negative sampling schemes are described in Section 6.1. All models are initialized with pre-trained BERT-large , bert-large-uncased, and trained for 3 epochs with 1e-5 for lr on 1 32GB V100 GPU.B Data StatisticsTable 6shows data statistics used in our experiments.\nSynthetic qa corpora generation with roundtrip consistency. Chris Alberti, Daniel Andor, Emily Pitler, Jacob Devlin, Michael Collins, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. the 57th Annual Meeting of the Association for Computational LinguisticsChris Alberti, Daniel Andor, Emily Pitler, Jacob De- vlin, and Michael Collins. 2019. Synthetic qa cor- pora generation with roundtrip consistency. In Pro- ceedings of the 57th Annual Meeting of the Asso- ciation for Computational Linguistics, pages 6168- 6173.\n\nLongformer: The long-document transformer. Iz Beltagy, Matthew E Peters, Arman Cohan, arXiv:2004.05150Iz Beltagy, Matthew E. Peters, and Arman Cohan. 2020. Longformer: The long-document transformer. arXiv:2004.05150.\n\nDoqa-accessing domain-specific faqs via conversational qa. Jon Ander Campos, Arantxa Otegi, Aitor Soroa, Jan Milan Deriu, Mark Cieliebak, Eneko Agirre, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. the 58th Annual Meeting of the Association for Computational LinguisticsJon Ander Campos, Arantxa Otegi, Aitor Soroa, Jan Milan Deriu, Mark Cieliebak, and Eneko Agirre. 2020. Doqa-accessing domain-specific faqs via con- versational qa. In Proceedings of the 58th Annual Meeting of the Association for Computational Lin- guistics, pages 7302-7314.\n\nFewshotqa: A simple framework for few-shot learning of question answering tasks using pre-trained text-totext models. Rakesh Chada, Pradeep Natarajan, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. the 2021 Conference on Empirical Methods in Natural Language ProcessingRakesh Chada and Pradeep Natarajan. 2021. Few- shotqa: A simple framework for few-shot learning of question answering tasks using pre-trained text-to- text models. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Process- ing, pages 6081-6090.\n\nGraphflow: Exploiting conversation flow with graph neural networks for conversational machine comprehension. Yu Chen, Lingfei Wu, Mohammed J Zaki, arXiv:1908.00059arXiv preprintYu Chen, Lingfei Wu, and Mohammed J Zaki. 2019. Graphflow: Exploiting conversation flow with graph neural networks for conversational machine compre- hension. arXiv preprint arXiv:1908.00059.\n\nEunsol Choi, He He, Mohit Iyyer, Mark Yatskar, Wentau Yih, Yejin Choi, Percy Liang, Luke Zettlemoyer, arXiv:1808.07036Quac: Question answering in context. arXiv preprintEunsol Choi, He He, Mohit Iyyer, Mark Yatskar, Wen- tau Yih, Yejin Choi, Percy Liang, and Luke Zettle- moyer. 2018. Quac: Question answering in context. arXiv preprint arXiv:1808.07036.\n\nBert: Pre-training of deep bidirectional transformers for language understanding. Jacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, NAACL. Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. Bert: Pre-training of deep bidirectional transformers for language understand- ing. In NAACL.\n\nSimple and effective semi-supervised question answering. Bhuwan Dhingra, Danish Danish, Dheeraj Rajagopal, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies2Short PapersBhuwan Dhingra, Danish Danish, and Dheeraj Ra- jagopal. 2018. Simple and effective semi-supervised question answering. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers), pages 582-587.\n\nUnified language model pre-training for natural language understanding and generation. Li Dong, Nan Yang, Wenhui Wang, Furu Wei, Xiaodong Liu, Yu Wang, Jianfeng Gao, Ming Zhou, Hsiao-Wuen Hon, Advances in Neural Information Processing Systems. 32Li Dong, Nan Yang, Wenhui Wang, Furu Wei, Xi- aodong Liu, Yu Wang, Jianfeng Gao, Ming Zhou, and Hsiao-Wuen Hon. 2019. Unified language model pre-training for natural language understand- ing and generation. Advances in Neural Information Processing Systems, 32.\n\nCan you unpack that? learning to rewrite questions-in-context. Ahmed Elgohary, Denis Peskov, Jordan Boyd-Graber, Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP). the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)Ahmed Elgohary, Denis Peskov, and Jordan Boyd- Graber. 2019. Can you unpack that? learning to rewrite questions-in-context. In Proceedings of the 2019 Conference on Empirical Methods in Natu- ral Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages 5918-5924.\n\nTemplatebased question generation from retrieved sentences for improved unsupervised question answering. Alexander Richard Fabbri, Patrick Ng, Zhiguo Wang, Ramesh Nallapati, Bing Xiang, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. the 58th Annual Meeting of the Association for Computational LinguisticsAlexander Richard Fabbri, Patrick Ng, Zhiguo Wang, Ramesh Nallapati, and Bing Xiang. 2020. Template- based question generation from retrieved sentences for improved unsupervised question answering. In Proceedings of the 58th Annual Meeting of the Asso- ciation for Computational Linguistics, pages 4508- 4513.\n\nData augmentation for lowresource neural machine translation. Marzieh Fadaee, Arianna Bisazza, Christof Monz, arXiv:1705.00440arXiv preprintMarzieh Fadaee, Arianna Bisazza, and Christof Monz. 2017. Data augmentation for low- resource neural machine translation. arXiv preprint arXiv:1705.00440.\n\n2020. doc2dial: A goal-oriented document-grounded dialogue dataset. Song Feng, Hui Wan, Chulaka Gunasekara, Siva Patel, Sachindra Joshi, Luis Lastras, 10.18653/v1/2020.emnlp-main.652Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)Online. Association for Computational LinguisticsSong Feng, Hui Wan, Chulaka Gunasekara, Siva Patel, Sachindra Joshi, and Luis Lastras. 2020. doc2dial: A goal-oriented document-grounded dia- logue dataset. In Proceedings of the 2020 Confer- ence on Empirical Methods in Natural Language Processing (EMNLP), pages 8118-8128, Online. As- sociation for Computational Linguistics.\n\nInterconnected question generation with coreference alignment and conversation flow modeling. Yifan Gao, Piji Li, Irwin King, Michael R Lyu, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics (ACL). the 57th Annual Meeting of the Association for Computational Linguistics (ACL)Yifan Gao, Piji Li, Irwin King, and Michael R Lyu. 2019. Interconnected question generation with coreference alignment and conversation flow mod- eling. In Proceedings of the 57th Annual Meet- ing of the Association for Computational Linguistics (ACL), pages 4853-4862.\n\nChaincqg: Flow-aware conversational question generation. Jing Gu, Mostafa Mirshekari, Zhou Yu, Aaron Sisto, Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume. the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main VolumeJing Gu, Mostafa Mirshekari, Zhou Yu, and Aaron Sisto. 2021. Chaincqg: Flow-aware conversational question generation. In Proceedings of the 16th Con- ference of the European Chapter of the Association for Computational Linguistics: Main Volume, pages 2061-2070.\n\nThe curious case of neural text degeneration. Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, Yejin Choi, Ari Holtzman, Jan Buys, Li Du, Maxwell Forbes, and Yejin Choi. 2020. The curious case of neural text degeneration.\n\nFlowqa: Grasping flow in history for conversational machine comprehension. Hsin-Yuan, Eunsol Huang, Wen-Tau Choi, Yih, International Conference on Learning Representations. Hsin-Yuan Huang, Eunsol Choi, and Wen-tau Yih. 2018. Flowqa: Grasping flow in history for conver- sational machine comprehension. In International Conference on Learning Representations.\n\nDense passage retrieval for open-domain question answering. Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, Wen-Tau Yih, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih. 2020. Dense passage retrieval for open-domain question answering. In Proceedings of the 2020 Conference on Empirical Methods in Nat- ural Language Processing (EMNLP), pages 6769- 6781.\n\nLearn to resolve conversational dependency: A consistency training framework for conversational question answering. Gangwoo Kim, Hyunjae Kim, Jungsoo Park, Jaewoo Kang, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing. the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language ProcessingLong Papers1Gangwoo Kim, Hyunjae Kim, Jungsoo Park, and Jae- woo Kang. 2021. Learn to resolve conversational dependency: A consistency training framework for conversational question answering. In Proceed- ings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th Interna- tional Joint Conference on Natural Language Pro- cessing (Volume 1: Long Papers), pages 6130-6141.\n\nHanjoo Kim, Minkyu Kim, Dongjoo Seo, Jinwoong Kim, Heungseok Park, Soeun Park, Hyunwoo Jo, Kyunghyun Kim, Youngil Yang, Youngkwan Kim, arXiv:1810.09957Nsml: Meet the mlaas platform with a real-world case study. arXiv preprintHanjoo Kim, Minkyu Kim, Dongjoo Seo, Jinwoong Kim, Heungseok Park, Soeun Park, Hyunwoo Jo, KyungHyun Kim, Youngil Yang, Youngkwan Kim, et al. 2018. Nsml: Meet the mlaas platform with a real-world case study. arXiv preprint arXiv:1810.09957.\n\nAdam: A method for stochastic optimization. P Diederik, Jimmy Kingma, Ba, Diederik P. Kingma and Jimmy Ba. 2017. Adam: A method for stochastic optimization.\n\nNatural questions: A benchmark for question answering research. Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, Transactions of the Association for Computational Linguistics (TACL). 7Tom Kwiatkowski, Jennimaria Palomaki, Olivia Red- field, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, et al. 2019. Natural questions: A bench- mark for question answering research. Transac- tions of the Association for Computational Linguis- tics (TACL), 7:452-466.\n\nUnsupervised question answering by cloze translation. Patrick Lewis, Ludovic Denoyer, Sebastian Riedel, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. the 57th Annual Meeting of the Association for Computational LinguisticsPatrick Lewis, Ludovic Denoyer, and Sebastian Riedel. 2019. Unsupervised question answering by cloze translation. In Proceedings of the 57th Annual Meet- ing of the Association for Computational Linguistics, pages 4896-4910.\n\nPaq: 65 million probably-asked questions and what you can do with them. Patrick Lewis, Yuxiang Wu, Linqing Liu, Pasquale Minervini, Heinrich K\u00fcttler, Aleksandra Piktus, Pontus Stenetorp, Sebastian Riedel, Transactions of the Association for Computational Linguistics. 9Patrick Lewis, Yuxiang Wu, Linqing Liu, Pasquale Minervini, Heinrich K\u00fcttler, Aleksandra Piktus, Pon- tus Stenetorp, and Sebastian Riedel. 2021. Paq: 65 million probably-asked questions and what you can do with them. Transactions of the Association for Computational Linguistics, 9:1098-1115.\n\n. Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, Veselin Stoyanov, Roberta: A robustly optimized bert pretraining approachYinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man- dar Joshi, Danqi Chen, Omer Levy, Mike Lewis, Luke Zettlemoyer, and Veselin Stoyanov. 2019. Roberta: A robustly optimized bert pretraining ap- proach.\n\nTowards an automatic Turing test: Learning to evaluate dialogue responses. Ryan Lowe, Michael Noseworthy, Iulian Vlad Serban, Nicolas Angelard-Gontier, Yoshua Bengio, Joelle Pineau, 10.18653/v1/P17-1103Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. the 55th Annual Meeting of the Association for Computational LinguisticsVancouver, CanadaAssociation for Computational Linguistics1Long Papers) (ACL)Ryan Lowe, Michael Noseworthy, Iulian Vlad Ser- ban, Nicolas Angelard-Gontier, Yoshua Bengio, and Joelle Pineau. 2017. Towards an automatic Turing test: Learning to evaluate dialogue responses. In Proceedings of the 55th Annual Meeting of the As- sociation for Computational Linguistics (Volume 1: Long Papers) (ACL), pages 1116-1126, Vancouver, Canada. Association for Computational Linguistics.\n\nUnsupervised evaluation of interactive dialog with dialogpt. Shikib Mehri, Maxine Eskenazi, Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue. the 21th Annual Meeting of the Special Interest Group on Discourse and DialogueShikib Mehri and Maxine Eskenazi. 2020. Unsuper- vised evaluation of interactive dialog with dialogpt. In Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 225-235.\n\nTowards answer-unaware conversational question generation. Mao Nakanishi, Tetsunori Kobayashi, Yoshihiko Hayashi, 10.18653/v1/D19-5809Proceedings of the 2nd Workshop on Machine Reading for Question Answering. the 2nd Workshop on Machine Reading for Question AnsweringHong Kong, ChinaAssociation for Computational LinguisticsMao Nakanishi, Tetsunori Kobayashi, and Yoshihiko Hayashi. 2019. Towards answer-unaware conversa- tional question generation. In Proceedings of the 2nd Workshop on Machine Reading for Question An- swering, pages 63-71, Hong Kong, China. Associa- tion for Computational Linguistics.\n\nFacebook FAIR's WMT19 news translation task submission. Nathan Ng, Kyra Yee, Alexei Baevski, Myle Ott, Michael Auli, Sergey Edunov, 10.18653/v1/W19-5333Proceedings of the Fourth Conference on Machine Translation. the Fourth Conference on Machine TranslationFlorence, ItalyAssociation for Computational Linguistics2Shared Task Papers, Day 1)Nathan Ng, Kyra Yee, Alexei Baevski, Myle Ott, Michael Auli, and Sergey Edunov. 2019. Facebook FAIR's WMT19 news translation task submission. In Proceedings of the Fourth Conference on Ma- chine Translation (Volume 2: Shared Task Papers, Day 1), pages 314-319, Florence, Italy. Association for Computational Linguistics.\n\nReinforced dynamic reasoning for conversational question generation. Boyuan Pan, Hao Li, Ziyu Yao, Deng Cai, Huan Sun, Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics. the 57th Annual Meeting of the Association for Computational LinguisticsBoyuan Pan, Hao Li, Ziyu Yao, Deng Cai, and Huan Sun. 2019. Reinforced dynamic reasoning for con- versational question generation. In Proceedings of the 57th Annual Meeting of the Association for Com- putational Linguistics, pages 2114-2124.\n\nIntroducing mantis: a novel multi-domain information seeking dialogues dataset. Gustavo Penha, Alexandru Balan, Claudia Hauff, arXiv:1912.04639arXiv preprintGustavo Penha, Alexandru Balan, and Claudia Hauff. 2019. Introducing mantis: a novel multi-domain in- formation seeking dialogues dataset. arXiv preprint arXiv:1912.04639.\n\nTraining question answering models from synthetic data. Raul Puri, Ryan Spring, Mohammad Shoeybi, Mostofa Patwary, Bryan Catanzaro, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)Raul Puri, Ryan Spring, Mohammad Shoeybi, Mostofa Patwary, and Bryan Catanzaro. 2020. Training ques- tion answering models from synthetic data. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 5811-5826.\n\nStay hungry, stay focused: Generating informative and specific questions in information-seeking conversations. Peng Qi, Yuhao Zhang, Christopher D Manning, Findings of the Association for Computational Linguistics: EMNLP 2020. Peng Qi, Yuhao Zhang, and Christopher D Manning. 2020. Stay hungry, stay focused: Generating infor- mative and specific questions in information-seeking conversations. In Findings of the Association for Computational Linguistics: EMNLP 2020, pages 25-40.\n\nOpen-retrieval conversational question answering. Chen Qu, Liu Yang, Cen Chen, Minghui Qiu, Bruce Croft, Mohit Iyyer, Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval. the 43rd International ACM SIGIR conference on research and development in Information RetrievalChen Qu, Liu Yang, Cen Chen, Minghui Qiu, W Bruce Croft, and Mohit Iyyer. 2020. Open-retrieval con- versational question answering. In Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval, pages 539-548.\n\nBert with history answer embedding for conversational question answering. Chen Qu, Liu Yang, Minghui Qiu, Bruce Croft, Yongfeng Zhang, Mohit Iyyer, Proceedings of the 42nd International ACM SIGIR Conference on Research and Development in Information Retrieval. the 42nd International ACM SIGIR Conference on Research and Development in Information RetrievalChen Qu, Liu Yang, Minghui Qiu, W Bruce Croft, Yongfeng Zhang, and Mohit Iyyer. 2019a. Bert with history answer embedding for conversational ques- tion answering. In Proceedings of the 42nd Inter- national ACM SIGIR Conference on Research and Development in Information Retrieval, pages 1133- 1136.\n\nAttentive history selection for conversational question answering. Chen Qu, Liu Yang, Minghui Qiu, Yongfeng Zhang, Cen Chen, Bruce Croft, Mohit Iyyer, Proceedings of the 28th ACM International Conference on Information and Knowledge Management. the 28th ACM International Conference on Information and Knowledge ManagementChen Qu, Liu Yang, Minghui Qiu, Yongfeng Zhang, Cen Chen, W Bruce Croft, and Mohit Iyyer. 2019b. Attentive history selection for conversational ques- tion answering. In Proceedings of the 28th ACM In- ternational Conference on Information and Knowl- edge Management, pages 1391-1400.\n\nExploring the limits of transfer learning with a unified text-to-text transformer. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J Liu, Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2020. Exploring the limits of transfer learning with a unified text-to-text trans- former.\n\nCoqa: A conversational question answering challenge. Siva Reddy, Danqi Chen, Christopher D Manning, Transactions of the Association for Computational Linguistics. 7Siva Reddy, Danqi Chen, and Christopher D Manning. 2019. Coqa: A conversational question answering challenge. Transactions of the Association for Com- putational Linguistics, 7:249-266.\n\nMarzieh Saeidi, Max Bartolo, Patrick Lewis, Sameer Singh, Tim Rockt\u00e4schel, Mike Sheldon, Guillaume Bouchard, Sebastian Riedel, arXiv:1809.01494Interpretation of natural language rules in conversational machine reading. arXiv preprintMarzieh Saeidi, Max Bartolo, Patrick Lewis, Sameer Singh, Tim Rockt\u00e4schel, Mike Sheldon, Guillaume Bouchard, and Sebastian Riedel. 2018. Interpreta- tion of natural language rules in conversational ma- chine reading. arXiv preprint arXiv:1809.01494.\n\nImproving neural machine translation models with monolingual data. Rico Sennrich, Barry Haddow, Alexandra Birch, 10.18653/v1/P16-1009Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics. the 54th Annual Meeting of the Association for Computational LinguisticsBerlin, GermanyLong Papers1Association for Computational LinguisticsRico Sennrich, Barry Haddow, and Alexandra Birch. 2016. Improving neural machine translation mod- els with monolingual data. In Proceedings of the 54th Annual Meeting of the Association for Compu- tational Linguistics (Volume 1: Long Papers), pages 86-96, Berlin, Germany. Association for Computa- tional Linguistics.\n\nNako Sung, Minkyu Kim, Hyunwoo Jo, Youngil Yang, Jingwoong Kim, Leonard Lausen, Youngkwan Kim, Gayoung Lee, Donghyun Kwak, Jung-Woo Ha, arXiv:1712.05902Nsml: A machine learning platform that enables you to focus on your models. arXiv preprintNako Sung, Minkyu Kim, Hyunwoo Jo, Youngil Yang, Jingwoong Kim, Leonard Lausen, Youngkwan Kim, Gayoung Lee, Donghyun Kwak, Jung-Woo Ha, et al. 2017. Nsml: A machine learning platform that en- ables you to focus on your models. arXiv preprint arXiv:1712.05902.\n\nHuggingface's transformers: State-of-the-art natural language processing. Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, R\u00e9mi Louf, Morgan Funtowicz, arXiv:1910.03771arXiv preprintThomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pier- ric Cistac, Tim Rault, R\u00e9mi Louf, Morgan Fun- towicz, et al. 2019. Huggingface's transformers: State-of-the-art natural language processing. arXiv preprint arXiv:1910.03771.\n\nUnsupervised data augmentation for consistency training. Qizhe Xie, Zihang Dai, Eduard Hovy, Thang Luong, Quoc Le, Advances in Neural Information Processing Systems. 33Qizhe Xie, Zihang Dai, Eduard Hovy, Thang Luong, and Quoc Le. 2020. Unsupervised data augmenta- tion for consistency training. Advances in Neural Information Processing Systems, 33:6256-6268.\n\nRor: Read-over-read for long document machine reading comprehension. Jing Zhao, Junwei Bao, Yifan Wang, Yongwei Zhou, Youzheng Wu, Xiaodong He, Bowen Zhou, arXiv:2109.04780arXiv preprintJing Zhao, Junwei Bao, Yifan Wang, Yongwei Zhou, Youzheng Wu, Xiaodong He, and Bowen Zhou. 2021. Ror: Read-over-read for long document machine reading comprehension. arXiv preprint arXiv:2109.04780.\n\nSdnet: Contextualized attention-based deep network for conversational question answering. Chenguang Zhu, Michael Zeng, Xuedong Huang, arXiv:1812.03593arXiv preprintChenguang Zhu, Michael Zeng, and Xuedong Huang. 2018. Sdnet: Contextualized attention-based deep network for conversational question answering. arXiv preprint arXiv:1812.03593.\n", "annotations": {"author": "[{\"end\":110,\"start\":74},{\"end\":151,\"start\":111},{\"end\":177,\"start\":152},{\"end\":186,\"start\":178},{\"end\":199,\"start\":187},{\"end\":219,\"start\":200},{\"end\":233,\"start\":220},{\"end\":246,\"start\":234}]", "publisher": null, "author_last_name": "[{\"end\":85,\"start\":82},{\"end\":123,\"start\":120},{\"end\":158,\"start\":154},{\"end\":185,\"start\":182},{\"end\":198,\"start\":194},{\"end\":218,\"start\":202},{\"end\":232,\"start\":229},{\"end\":245,\"start\":240}]", "author_first_name": "[{\"end\":81,\"start\":74},{\"end\":119,\"start\":111},{\"end\":153,\"start\":152},{\"end\":181,\"start\":178},{\"end\":193,\"start\":187},{\"end\":201,\"start\":200},{\"end\":225,\"start\":220},{\"end\":228,\"start\":226},{\"end\":239,\"start\":234}]", "author_affiliation": null, "title": "[{\"end\":71,\"start\":1},{\"end\":317,\"start\":247}]", "venue": null, "abstract": "[{\"end\":1449,\"start\":319}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b37\"},\"end\":2571,\"start\":2552},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":2591,\"start\":2571},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":2610,\"start\":2591},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2630,\"start\":2610},{\"end\":2648,\"start\":2630},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":3311,\"start\":3294},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":3327,\"start\":3311},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":3343,\"start\":3327},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":3424,\"start\":3407},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":3441,\"start\":3424},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":3459,\"start\":3441},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":5941,\"start\":5917},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":6007,\"start\":5990},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":6218,\"start\":6202},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":7961,\"start\":7944},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":7977,\"start\":7961},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":8187,\"start\":8171},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":10253,\"start\":10234},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":10796,\"start\":10775},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":10936,\"start\":10920},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":11118,\"start\":11091},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":14650,\"start\":14634},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":15910,\"start\":15889},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":16028,\"start\":16005},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":16230,\"start\":16209},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":16657,\"start\":16634},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":16677,\"start\":16657},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":16694,\"start\":16677},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":17095,\"start\":17078},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":17119,\"start\":17097},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":17269,\"start\":17252},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":17516,\"start\":17497},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":17795,\"start\":17772},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":18068,\"start\":18048},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":18323,\"start\":18304},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":18979,\"start\":18957},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":19221,\"start\":19202},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":21780,\"start\":21764},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":23592,\"start\":23568},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":23667,\"start\":23650},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":24710,\"start\":24692},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":24728,\"start\":24712},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":24920,\"start\":24904},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":25328,\"start\":25311},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":25587,\"start\":25571},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":26627,\"start\":26611},{\"end\":29921,\"start\":29905},{\"end\":29936,\"start\":29921},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":32355,\"start\":32336},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":32492,\"start\":32474},{\"end\":32511,\"start\":32492},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":32695,\"start\":32677},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":32742,\"start\":32723},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":32918,\"start\":32896},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":32936,\"start\":32918},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":32954,\"start\":32936},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":32973,\"start\":32954},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":33161,\"start\":33139},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":33217,\"start\":33196},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":33448,\"start\":33430},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":33467,\"start\":33448},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":33592,\"start\":33575},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":33939,\"start\":33921},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":33962,\"start\":33939},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":33978,\"start\":33962},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":34006,\"start\":33990},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":34576,\"start\":34558},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":34599,\"start\":34576},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":34615,\"start\":34599},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":34827,\"start\":34809},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":34896,\"start\":34871},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":35089,\"start\":35073}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":36527,\"start\":36038},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":36715,\"start\":36528},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":37206,\"start\":36716},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":37342,\"start\":37207}]", "paragraph": "[{\"end\":2846,\"start\":1465},{\"end\":3774,\"start\":2848},{\"end\":4493,\"start\":3776},{\"end\":5341,\"start\":4495},{\"end\":6038,\"start\":5343},{\"end\":6499,\"start\":6040},{\"end\":6542,\"start\":6501},{\"end\":6672,\"start\":6544},{\"end\":6852,\"start\":6674},{\"end\":6994,\"start\":6854},{\"end\":7683,\"start\":7009},{\"end\":8491,\"start\":7685},{\"end\":8999,\"start\":8548},{\"end\":9089,\"start\":9015},{\"end\":9516,\"start\":9091},{\"end\":10254,\"start\":9552},{\"end\":11119,\"start\":10256},{\"end\":11665,\"start\":11136},{\"end\":12592,\"start\":11667},{\"end\":13074,\"start\":12625},{\"end\":13289,\"start\":13097},{\"end\":14117,\"start\":13302},{\"end\":15077,\"start\":14166},{\"end\":15195,\"start\":15106},{\"end\":15485,\"start\":15251},{\"end\":16231,\"start\":15573},{\"end\":16523,\"start\":16274},{\"end\":17426,\"start\":16525},{\"end\":17930,\"start\":17451},{\"end\":18620,\"start\":17943},{\"end\":19684,\"start\":18635},{\"end\":19921,\"start\":19709},{\"end\":21170,\"start\":19945},{\"end\":22768,\"start\":21172},{\"end\":23222,\"start\":22770},{\"end\":24387,\"start\":23259},{\"end\":24414,\"start\":24389},{\"end\":25733,\"start\":24450},{\"end\":26890,\"start\":25735},{\"end\":28661,\"start\":26892},{\"end\":28711,\"start\":28700},{\"end\":29794,\"start\":28713},{\"end\":29875,\"start\":29804},{\"end\":31064,\"start\":29877},{\"end\":31748,\"start\":31089},{\"end\":32234,\"start\":31750},{\"end\":32787,\"start\":32251},{\"end\":33468,\"start\":32789},{\"end\":34411,\"start\":33507},{\"end\":35299,\"start\":34413},{\"end\":36037,\"start\":35314}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":15250,\"start\":15196},{\"attributes\":{\"id\":\"formula_1\"},\"end\":15572,\"start\":15486}]", "table_ref": "[{\"end\":13891,\"start\":13884},{\"end\":14823,\"start\":14816},{\"end\":19306,\"start\":19299},{\"end\":20088,\"start\":20081},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":23493,\"start\":23486},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":26672,\"start\":26665},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":27471,\"start\":27464},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":27935,\"start\":27928},{\"end\":30636,\"start\":30629},{\"end\":31252,\"start\":31245}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1463,\"start\":1451},{\"attributes\":{\"n\":\"2\"},\"end\":7007,\"start\":6997},{\"attributes\":{\"n\":\"3\"},\"end\":8546,\"start\":8494},{\"attributes\":{\"n\":\"3.1\"},\"end\":9013,\"start\":9002},{\"end\":9550,\"start\":9519},{\"attributes\":{\"n\":\"3.2\"},\"end\":11134,\"start\":11122},{\"end\":12623,\"start\":12595},{\"attributes\":{\"n\":\"4\"},\"end\":13095,\"start\":13077},{\"attributes\":{\"n\":\"4.1\"},\"end\":13300,\"start\":13292},{\"end\":14164,\"start\":14120},{\"attributes\":{\"n\":\"4.2\"},\"end\":15104,\"start\":15080},{\"attributes\":{\"n\":\"4.3\"},\"end\":16272,\"start\":16234},{\"end\":17449,\"start\":17429},{\"end\":17941,\"start\":17933},{\"attributes\":{\"n\":\"4.4\"},\"end\":18633,\"start\":18623},{\"attributes\":{\"n\":\"5\"},\"end\":19707,\"start\":19687},{\"attributes\":{\"n\":\"5.1\"},\"end\":19943,\"start\":19924},{\"attributes\":{\"n\":\"5.2\"},\"end\":23257,\"start\":23225},{\"attributes\":{\"n\":\"6.1\"},\"end\":24448,\"start\":24417},{\"attributes\":{\"n\":\"6.2\"},\"end\":28698,\"start\":28664},{\"end\":29802,\"start\":29797},{\"attributes\":{\"n\":\"6.3\"},\"end\":31087,\"start\":31067},{\"attributes\":{\"n\":\"7\"},\"end\":32249,\"start\":32237},{\"end\":33505,\"start\":33471},{\"attributes\":{\"n\":\"8\"},\"end\":35312,\"start\":35302},{\"end\":36049,\"start\":36039},{\"end\":36538,\"start\":36529},{\"end\":36726,\"start\":36717},{\"end\":37217,\"start\":37208}]", "table": "[{\"end\":37206,\"start\":36728}]", "figure_caption": "[{\"end\":36527,\"start\":36051},{\"end\":36715,\"start\":36540},{\"end\":37342,\"start\":37219}]", "figure_ref": "[{\"end\":2058,\"start\":2050},{\"end\":4066,\"start\":4057},{\"end\":4361,\"start\":4353},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":8709,\"start\":8701},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":9514,\"start\":9501},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":11663,\"start\":11650},{\"end\":21646,\"start\":21638},{\"end\":25823,\"start\":25815},{\"end\":26156,\"start\":26143},{\"end\":27071,\"start\":27059},{\"end\":27196,\"start\":27183}]", "bib_author_first_name": "[{\"end\":43877,\"start\":43872},{\"end\":43893,\"start\":43887},{\"end\":43906,\"start\":43901},{\"end\":43920,\"start\":43915},{\"end\":43936,\"start\":43929},{\"end\":44415,\"start\":44413},{\"end\":44432,\"start\":44425},{\"end\":44434,\"start\":44433},{\"end\":44448,\"start\":44443},{\"end\":44650,\"start\":44647},{\"end\":44672,\"start\":44665},{\"end\":44685,\"start\":44680},{\"end\":44696,\"start\":44693},{\"end\":44702,\"start\":44697},{\"end\":44714,\"start\":44710},{\"end\":44731,\"start\":44726},{\"end\":45301,\"start\":45295},{\"end\":45316,\"start\":45309},{\"end\":45873,\"start\":45871},{\"end\":45887,\"start\":45880},{\"end\":45900,\"start\":45892},{\"end\":45902,\"start\":45901},{\"end\":46138,\"start\":46132},{\"end\":46147,\"start\":46145},{\"end\":46157,\"start\":46152},{\"end\":46169,\"start\":46165},{\"end\":46185,\"start\":46179},{\"end\":46196,\"start\":46191},{\"end\":46208,\"start\":46203},{\"end\":46220,\"start\":46216},{\"end\":46575,\"start\":46570},{\"end\":46592,\"start\":46584},{\"end\":46606,\"start\":46600},{\"end\":46620,\"start\":46612},{\"end\":46869,\"start\":46863},{\"end\":46885,\"start\":46879},{\"end\":46901,\"start\":46894},{\"end\":47593,\"start\":47591},{\"end\":47603,\"start\":47600},{\"end\":47616,\"start\":47610},{\"end\":47627,\"start\":47623},{\"end\":47641,\"start\":47633},{\"end\":47649,\"start\":47647},{\"end\":47664,\"start\":47656},{\"end\":47674,\"start\":47670},{\"end\":47691,\"start\":47681},{\"end\":48081,\"start\":48076},{\"end\":48097,\"start\":48092},{\"end\":48112,\"start\":48106},{\"end\":48901,\"start\":48892},{\"end\":48909,\"start\":48902},{\"end\":48925,\"start\":48918},{\"end\":48936,\"start\":48930},{\"end\":48949,\"start\":48943},{\"end\":48965,\"start\":48961},{\"end\":49514,\"start\":49507},{\"end\":49530,\"start\":49523},{\"end\":49548,\"start\":49540},{\"end\":49813,\"start\":49809},{\"end\":49823,\"start\":49820},{\"end\":49836,\"start\":49829},{\"end\":49853,\"start\":49849},{\"end\":49870,\"start\":49861},{\"end\":49882,\"start\":49878},{\"end\":50575,\"start\":50570},{\"end\":50585,\"start\":50581},{\"end\":50595,\"start\":50590},{\"end\":50609,\"start\":50602},{\"end\":50611,\"start\":50610},{\"end\":51122,\"start\":51118},{\"end\":51134,\"start\":51127},{\"end\":51151,\"start\":51147},{\"end\":51161,\"start\":51156},{\"end\":51708,\"start\":51705},{\"end\":51722,\"start\":51719},{\"end\":51731,\"start\":51729},{\"end\":51743,\"start\":51736},{\"end\":51757,\"start\":51752},{\"end\":51972,\"start\":51966},{\"end\":51987,\"start\":51980},{\"end\":52309,\"start\":52301},{\"end\":52327,\"start\":52321},{\"end\":52339,\"start\":52334},{\"end\":52352,\"start\":52345},{\"end\":52366,\"start\":52360},{\"end\":52377,\"start\":52371},{\"end\":52391,\"start\":52386},{\"end\":52405,\"start\":52398},{\"end\":53009,\"start\":53002},{\"end\":53022,\"start\":53015},{\"end\":53035,\"start\":53028},{\"end\":53048,\"start\":53042},{\"end\":53780,\"start\":53774},{\"end\":53792,\"start\":53786},{\"end\":53805,\"start\":53798},{\"end\":53819,\"start\":53811},{\"end\":53834,\"start\":53825},{\"end\":53846,\"start\":53841},{\"end\":53860,\"start\":53853},{\"end\":53874,\"start\":53865},{\"end\":53887,\"start\":53880},{\"end\":53903,\"start\":53894},{\"end\":54286,\"start\":54285},{\"end\":54302,\"start\":54297},{\"end\":54466,\"start\":54463},{\"end\":54490,\"start\":54480},{\"end\":54507,\"start\":54501},{\"end\":54525,\"start\":54518},{\"end\":54540,\"start\":54535},{\"end\":54554,\"start\":54549},{\"end\":54572,\"start\":54564},{\"end\":54587,\"start\":54582},{\"end\":54605,\"start\":54600},{\"end\":54620,\"start\":54614},{\"end\":55088,\"start\":55081},{\"end\":55103,\"start\":55096},{\"end\":55122,\"start\":55113},{\"end\":55597,\"start\":55590},{\"end\":55612,\"start\":55605},{\"end\":55624,\"start\":55617},{\"end\":55638,\"start\":55630},{\"end\":55658,\"start\":55650},{\"end\":55678,\"start\":55668},{\"end\":55693,\"start\":55687},{\"end\":55714,\"start\":55705},{\"end\":56089,\"start\":56083},{\"end\":56099,\"start\":56095},{\"end\":56110,\"start\":56105},{\"end\":56125,\"start\":56118},{\"end\":56136,\"start\":56130},{\"end\":56149,\"start\":56144},{\"end\":56160,\"start\":56156},{\"end\":56171,\"start\":56167},{\"end\":56183,\"start\":56179},{\"end\":56204,\"start\":56197},{\"end\":56553,\"start\":56549},{\"end\":56567,\"start\":56560},{\"end\":56586,\"start\":56580},{\"end\":56607,\"start\":56600},{\"end\":56632,\"start\":56626},{\"end\":56647,\"start\":56641},{\"end\":57379,\"start\":57373},{\"end\":57393,\"start\":57387},{\"end\":57859,\"start\":57856},{\"end\":57880,\"start\":57871},{\"end\":57901,\"start\":57892},{\"end\":58466,\"start\":58460},{\"end\":58475,\"start\":58471},{\"end\":58487,\"start\":58481},{\"end\":58501,\"start\":58497},{\"end\":58514,\"start\":58507},{\"end\":58527,\"start\":58521},{\"end\":59141,\"start\":59135},{\"end\":59150,\"start\":59147},{\"end\":59159,\"start\":59155},{\"end\":59169,\"start\":59165},{\"end\":59179,\"start\":59175},{\"end\":59676,\"start\":59669},{\"end\":59693,\"start\":59684},{\"end\":59708,\"start\":59701},{\"end\":59979,\"start\":59975},{\"end\":59990,\"start\":59986},{\"end\":60007,\"start\":59999},{\"end\":60024,\"start\":60017},{\"end\":60039,\"start\":60034},{\"end\":60602,\"start\":60598},{\"end\":60612,\"start\":60607},{\"end\":60633,\"start\":60620},{\"end\":61024,\"start\":61020},{\"end\":61032,\"start\":61029},{\"end\":61042,\"start\":61039},{\"end\":61056,\"start\":61049},{\"end\":61067,\"start\":61062},{\"end\":61080,\"start\":61075},{\"end\":61639,\"start\":61635},{\"end\":61647,\"start\":61644},{\"end\":61661,\"start\":61654},{\"end\":61672,\"start\":61667},{\"end\":61688,\"start\":61680},{\"end\":61701,\"start\":61696},{\"end\":62289,\"start\":62285},{\"end\":62297,\"start\":62294},{\"end\":62311,\"start\":62304},{\"end\":62325,\"start\":62317},{\"end\":62336,\"start\":62333},{\"end\":62348,\"start\":62343},{\"end\":62361,\"start\":62356},{\"end\":62913,\"start\":62908},{\"end\":62926,\"start\":62922},{\"end\":62940,\"start\":62936},{\"end\":62959,\"start\":62950},{\"end\":62971,\"start\":62965},{\"end\":62987,\"start\":62980},{\"end\":63001,\"start\":62996},{\"end\":63011,\"start\":63008},{\"end\":63021,\"start\":63016},{\"end\":63023,\"start\":63022},{\"end\":63304,\"start\":63300},{\"end\":63317,\"start\":63312},{\"end\":63337,\"start\":63324},{\"end\":63605,\"start\":63598},{\"end\":63617,\"start\":63614},{\"end\":63634,\"start\":63627},{\"end\":63648,\"start\":63642},{\"end\":63659,\"start\":63656},{\"end\":63677,\"start\":63673},{\"end\":63696,\"start\":63687},{\"end\":63716,\"start\":63707},{\"end\":64153,\"start\":64149},{\"end\":64169,\"start\":64164},{\"end\":64187,\"start\":64178},{\"end\":64767,\"start\":64763},{\"end\":64780,\"start\":64774},{\"end\":64793,\"start\":64786},{\"end\":64805,\"start\":64798},{\"end\":64821,\"start\":64812},{\"end\":64834,\"start\":64827},{\"end\":64852,\"start\":64843},{\"end\":64865,\"start\":64858},{\"end\":64879,\"start\":64871},{\"end\":64894,\"start\":64886},{\"end\":65346,\"start\":65340},{\"end\":65361,\"start\":65353},{\"end\":65375,\"start\":65369},{\"end\":65388,\"start\":65382},{\"end\":65406,\"start\":65399},{\"end\":65424,\"start\":65417},{\"end\":65437,\"start\":65430},{\"end\":65449,\"start\":65446},{\"end\":65461,\"start\":65457},{\"end\":65474,\"start\":65468},{\"end\":65849,\"start\":65844},{\"end\":65861,\"start\":65855},{\"end\":65873,\"start\":65867},{\"end\":65885,\"start\":65880},{\"end\":65897,\"start\":65893},{\"end\":66221,\"start\":66217},{\"end\":66234,\"start\":66228},{\"end\":66245,\"start\":66240},{\"end\":66259,\"start\":66252},{\"end\":66274,\"start\":66266},{\"end\":66287,\"start\":66279},{\"end\":66297,\"start\":66292},{\"end\":66633,\"start\":66624},{\"end\":66646,\"start\":66639},{\"end\":66660,\"start\":66653}]", "bib_author_last_name": "[{\"end\":43885,\"start\":43878},{\"end\":43899,\"start\":43894},{\"end\":43913,\"start\":43907},{\"end\":43927,\"start\":43921},{\"end\":43944,\"start\":43937},{\"end\":44423,\"start\":44416},{\"end\":44441,\"start\":44435},{\"end\":44454,\"start\":44449},{\"end\":44663,\"start\":44651},{\"end\":44678,\"start\":44673},{\"end\":44691,\"start\":44686},{\"end\":44708,\"start\":44703},{\"end\":44724,\"start\":44715},{\"end\":44738,\"start\":44732},{\"end\":45307,\"start\":45302},{\"end\":45326,\"start\":45317},{\"end\":45878,\"start\":45874},{\"end\":45890,\"start\":45888},{\"end\":45907,\"start\":45903},{\"end\":46143,\"start\":46139},{\"end\":46150,\"start\":46148},{\"end\":46163,\"start\":46158},{\"end\":46177,\"start\":46170},{\"end\":46189,\"start\":46186},{\"end\":46201,\"start\":46197},{\"end\":46214,\"start\":46209},{\"end\":46232,\"start\":46221},{\"end\":46582,\"start\":46576},{\"end\":46598,\"start\":46593},{\"end\":46610,\"start\":46607},{\"end\":46630,\"start\":46621},{\"end\":46877,\"start\":46870},{\"end\":46892,\"start\":46886},{\"end\":46911,\"start\":46902},{\"end\":47598,\"start\":47594},{\"end\":47608,\"start\":47604},{\"end\":47621,\"start\":47617},{\"end\":47631,\"start\":47628},{\"end\":47645,\"start\":47642},{\"end\":47654,\"start\":47650},{\"end\":47668,\"start\":47665},{\"end\":47679,\"start\":47675},{\"end\":47695,\"start\":47692},{\"end\":48090,\"start\":48082},{\"end\":48104,\"start\":48098},{\"end\":48124,\"start\":48113},{\"end\":48916,\"start\":48910},{\"end\":48928,\"start\":48926},{\"end\":48941,\"start\":48937},{\"end\":48959,\"start\":48950},{\"end\":48971,\"start\":48966},{\"end\":49521,\"start\":49515},{\"end\":49538,\"start\":49531},{\"end\":49553,\"start\":49549},{\"end\":49818,\"start\":49814},{\"end\":49827,\"start\":49824},{\"end\":49847,\"start\":49837},{\"end\":49859,\"start\":49854},{\"end\":49876,\"start\":49871},{\"end\":49890,\"start\":49883},{\"end\":50579,\"start\":50576},{\"end\":50588,\"start\":50586},{\"end\":50600,\"start\":50596},{\"end\":50615,\"start\":50612},{\"end\":51125,\"start\":51123},{\"end\":51145,\"start\":51135},{\"end\":51154,\"start\":51152},{\"end\":51167,\"start\":51162},{\"end\":51717,\"start\":51709},{\"end\":51727,\"start\":51723},{\"end\":51734,\"start\":51732},{\"end\":51750,\"start\":51744},{\"end\":51762,\"start\":51758},{\"end\":51964,\"start\":51955},{\"end\":51978,\"start\":51973},{\"end\":51992,\"start\":51988},{\"end\":51997,\"start\":51994},{\"end\":52319,\"start\":52310},{\"end\":52332,\"start\":52328},{\"end\":52343,\"start\":52340},{\"end\":52358,\"start\":52353},{\"end\":52369,\"start\":52367},{\"end\":52384,\"start\":52378},{\"end\":52396,\"start\":52392},{\"end\":52409,\"start\":52406},{\"end\":53013,\"start\":53010},{\"end\":53026,\"start\":53023},{\"end\":53040,\"start\":53036},{\"end\":53053,\"start\":53049},{\"end\":53784,\"start\":53781},{\"end\":53796,\"start\":53793},{\"end\":53809,\"start\":53806},{\"end\":53823,\"start\":53820},{\"end\":53839,\"start\":53835},{\"end\":53851,\"start\":53847},{\"end\":53863,\"start\":53861},{\"end\":53878,\"start\":53875},{\"end\":53892,\"start\":53888},{\"end\":53907,\"start\":53904},{\"end\":54295,\"start\":54287},{\"end\":54309,\"start\":54303},{\"end\":54313,\"start\":54311},{\"end\":54478,\"start\":54467},{\"end\":54499,\"start\":54491},{\"end\":54516,\"start\":54508},{\"end\":54533,\"start\":54526},{\"end\":54547,\"start\":54541},{\"end\":54562,\"start\":54555},{\"end\":54580,\"start\":54573},{\"end\":54598,\"start\":54588},{\"end\":54612,\"start\":54606},{\"end\":54624,\"start\":54621},{\"end\":55094,\"start\":55089},{\"end\":55111,\"start\":55104},{\"end\":55129,\"start\":55123},{\"end\":55603,\"start\":55598},{\"end\":55615,\"start\":55613},{\"end\":55628,\"start\":55625},{\"end\":55648,\"start\":55639},{\"end\":55666,\"start\":55659},{\"end\":55685,\"start\":55679},{\"end\":55703,\"start\":55694},{\"end\":55721,\"start\":55715},{\"end\":56093,\"start\":56090},{\"end\":56103,\"start\":56100},{\"end\":56116,\"start\":56111},{\"end\":56128,\"start\":56126},{\"end\":56142,\"start\":56137},{\"end\":56154,\"start\":56150},{\"end\":56165,\"start\":56161},{\"end\":56177,\"start\":56172},{\"end\":56195,\"start\":56184},{\"end\":56213,\"start\":56205},{\"end\":56558,\"start\":56554},{\"end\":56578,\"start\":56568},{\"end\":56598,\"start\":56587},{\"end\":56624,\"start\":56608},{\"end\":56639,\"start\":56633},{\"end\":56654,\"start\":56648},{\"end\":57385,\"start\":57380},{\"end\":57402,\"start\":57394},{\"end\":57869,\"start\":57860},{\"end\":57890,\"start\":57881},{\"end\":57909,\"start\":57902},{\"end\":58469,\"start\":58467},{\"end\":58479,\"start\":58476},{\"end\":58495,\"start\":58488},{\"end\":58505,\"start\":58502},{\"end\":58519,\"start\":58515},{\"end\":58534,\"start\":58528},{\"end\":59145,\"start\":59142},{\"end\":59153,\"start\":59151},{\"end\":59163,\"start\":59160},{\"end\":59173,\"start\":59170},{\"end\":59183,\"start\":59180},{\"end\":59682,\"start\":59677},{\"end\":59699,\"start\":59694},{\"end\":59714,\"start\":59709},{\"end\":59984,\"start\":59980},{\"end\":59997,\"start\":59991},{\"end\":60015,\"start\":60008},{\"end\":60032,\"start\":60025},{\"end\":60049,\"start\":60040},{\"end\":60605,\"start\":60603},{\"end\":60618,\"start\":60613},{\"end\":60641,\"start\":60634},{\"end\":61027,\"start\":61025},{\"end\":61037,\"start\":61033},{\"end\":61047,\"start\":61043},{\"end\":61060,\"start\":61057},{\"end\":61073,\"start\":61068},{\"end\":61086,\"start\":61081},{\"end\":61642,\"start\":61640},{\"end\":61652,\"start\":61648},{\"end\":61665,\"start\":61662},{\"end\":61678,\"start\":61673},{\"end\":61694,\"start\":61689},{\"end\":61707,\"start\":61702},{\"end\":62292,\"start\":62290},{\"end\":62302,\"start\":62298},{\"end\":62315,\"start\":62312},{\"end\":62331,\"start\":62326},{\"end\":62341,\"start\":62337},{\"end\":62354,\"start\":62349},{\"end\":62367,\"start\":62362},{\"end\":62920,\"start\":62914},{\"end\":62934,\"start\":62927},{\"end\":62948,\"start\":62941},{\"end\":62963,\"start\":62960},{\"end\":62978,\"start\":62972},{\"end\":62994,\"start\":62988},{\"end\":63006,\"start\":63002},{\"end\":63014,\"start\":63012},{\"end\":63027,\"start\":63024},{\"end\":63310,\"start\":63305},{\"end\":63322,\"start\":63318},{\"end\":63345,\"start\":63338},{\"end\":63612,\"start\":63606},{\"end\":63625,\"start\":63618},{\"end\":63640,\"start\":63635},{\"end\":63654,\"start\":63649},{\"end\":63671,\"start\":63660},{\"end\":63685,\"start\":63678},{\"end\":63705,\"start\":63697},{\"end\":63723,\"start\":63717},{\"end\":64162,\"start\":64154},{\"end\":64176,\"start\":64170},{\"end\":64193,\"start\":64188},{\"end\":64772,\"start\":64768},{\"end\":64784,\"start\":64781},{\"end\":64796,\"start\":64794},{\"end\":64810,\"start\":64806},{\"end\":64825,\"start\":64822},{\"end\":64841,\"start\":64835},{\"end\":64856,\"start\":64853},{\"end\":64869,\"start\":64866},{\"end\":64884,\"start\":64880},{\"end\":64897,\"start\":64895},{\"end\":65351,\"start\":65347},{\"end\":65367,\"start\":65362},{\"end\":65380,\"start\":65376},{\"end\":65397,\"start\":65389},{\"end\":65415,\"start\":65407},{\"end\":65428,\"start\":65425},{\"end\":65444,\"start\":65438},{\"end\":65455,\"start\":65450},{\"end\":65466,\"start\":65462},{\"end\":65484,\"start\":65475},{\"end\":65853,\"start\":65850},{\"end\":65865,\"start\":65862},{\"end\":65878,\"start\":65874},{\"end\":65891,\"start\":65886},{\"end\":65900,\"start\":65898},{\"end\":66226,\"start\":66222},{\"end\":66238,\"start\":66235},{\"end\":66250,\"start\":66246},{\"end\":66264,\"start\":66260},{\"end\":66277,\"start\":66275},{\"end\":66290,\"start\":66288},{\"end\":66302,\"start\":66298},{\"end\":66637,\"start\":66634},{\"end\":66651,\"start\":66647},{\"end\":66666,\"start\":66661}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":189762081},\"end\":44368,\"start\":43812},{\"attributes\":{\"doi\":\"arXiv:2004.05150\",\"id\":\"b1\"},\"end\":44586,\"start\":44370},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":218487043},\"end\":45175,\"start\":44588},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":237420912},\"end\":45760,\"start\":45177},{\"attributes\":{\"doi\":\"arXiv:1908.00059\",\"id\":\"b4\"},\"end\":46130,\"start\":45762},{\"attributes\":{\"doi\":\"arXiv:1808.07036\",\"id\":\"b5\"},\"end\":46486,\"start\":46132},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":52967399},\"end\":46804,\"start\":46488},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":4570782},\"end\":47502,\"start\":46806},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":147704286},\"end\":48011,\"start\":47504},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":202771124},\"end\":48785,\"start\":48013},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":216144850},\"end\":49443,\"start\":48787},{\"attributes\":{\"doi\":\"arXiv:1705.00440\",\"id\":\"b11\"},\"end\":49739,\"start\":49445},{\"attributes\":{\"doi\":\"10.18653/v1/2020.emnlp-main.652\",\"id\":\"b12\",\"matched_paper_id\":226262425},\"end\":50474,\"start\":49741},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":189927819},\"end\":51059,\"start\":50476},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":231839700},\"end\":51657,\"start\":51061},{\"attributes\":{\"id\":\"b15\"},\"end\":51878,\"start\":51659},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":53113561},\"end\":52239,\"start\":51880},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":215737187},\"end\":52884,\"start\":52241},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":235593227},\"end\":53772,\"start\":52886},{\"attributes\":{\"doi\":\"arXiv:1810.09957\",\"id\":\"b19\"},\"end\":54239,\"start\":53774},{\"attributes\":{\"id\":\"b20\"},\"end\":54397,\"start\":54241},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":86611921},\"end\":55025,\"start\":54399},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":186206974},\"end\":55516,\"start\":55027},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":231924957},\"end\":56079,\"start\":55518},{\"attributes\":{\"id\":\"b24\"},\"end\":56472,\"start\":56081},{\"attributes\":{\"doi\":\"10.18653/v1/P17-1103\",\"id\":\"b25\",\"matched_paper_id\":1880070},\"end\":57310,\"start\":56474},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":219980605},\"end\":57795,\"start\":57312},{\"attributes\":{\"doi\":\"10.18653/v1/D19-5809\",\"id\":\"b27\",\"matched_paper_id\":207917437},\"end\":58402,\"start\":57797},{\"attributes\":{\"doi\":\"10.18653/v1/W19-5333\",\"id\":\"b28\",\"matched_paper_id\":196621535},\"end\":59064,\"start\":58404},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":196171642},\"end\":59587,\"start\":59066},{\"attributes\":{\"doi\":\"arXiv:1912.04639\",\"id\":\"b30\"},\"end\":59917,\"start\":59589},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":211258652},\"end\":60485,\"start\":59919},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":216867510},\"end\":60968,\"start\":60487},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":218869571},\"end\":61559,\"start\":60970},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":153312701},\"end\":62216,\"start\":61561},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":201669002},\"end\":62823,\"start\":62218},{\"attributes\":{\"id\":\"b36\"},\"end\":63245,\"start\":62825},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":52055325},\"end\":63596,\"start\":63247},{\"attributes\":{\"doi\":\"arXiv:1809.01494\",\"id\":\"b38\"},\"end\":64080,\"start\":63598},{\"attributes\":{\"doi\":\"10.18653/v1/P16-1009\",\"id\":\"b39\",\"matched_paper_id\":15600925},\"end\":64761,\"start\":64082},{\"attributes\":{\"doi\":\"arXiv:1712.05902\",\"id\":\"b40\"},\"end\":65264,\"start\":64763},{\"attributes\":{\"doi\":\"arXiv:1910.03771\",\"id\":\"b41\"},\"end\":65785,\"start\":65266},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":195873898},\"end\":66146,\"start\":65787},{\"attributes\":{\"doi\":\"arXiv:2109.04780\",\"id\":\"b43\"},\"end\":66532,\"start\":66148},{\"attributes\":{\"doi\":\"arXiv:1812.03593\",\"id\":\"b44\"},\"end\":66874,\"start\":66534}]", "bib_title": "[{\"end\":43870,\"start\":43812},{\"end\":44645,\"start\":44588},{\"end\":45293,\"start\":45177},{\"end\":46568,\"start\":46488},{\"end\":46861,\"start\":46806},{\"end\":47589,\"start\":47504},{\"end\":48074,\"start\":48013},{\"end\":48890,\"start\":48787},{\"end\":49807,\"start\":49741},{\"end\":50568,\"start\":50476},{\"end\":51116,\"start\":51061},{\"end\":51953,\"start\":51880},{\"end\":52299,\"start\":52241},{\"end\":53000,\"start\":52886},{\"end\":54461,\"start\":54399},{\"end\":55079,\"start\":55027},{\"end\":55588,\"start\":55518},{\"end\":56547,\"start\":56474},{\"end\":57371,\"start\":57312},{\"end\":57854,\"start\":57797},{\"end\":58458,\"start\":58404},{\"end\":59133,\"start\":59066},{\"end\":59973,\"start\":59919},{\"end\":60596,\"start\":60487},{\"end\":61018,\"start\":60970},{\"end\":61633,\"start\":61561},{\"end\":62283,\"start\":62218},{\"end\":63298,\"start\":63247},{\"end\":64147,\"start\":64082},{\"end\":65842,\"start\":65787}]", "bib_author": "[{\"end\":43887,\"start\":43872},{\"end\":43901,\"start\":43887},{\"end\":43915,\"start\":43901},{\"end\":43929,\"start\":43915},{\"end\":43946,\"start\":43929},{\"end\":44425,\"start\":44413},{\"end\":44443,\"start\":44425},{\"end\":44456,\"start\":44443},{\"end\":44665,\"start\":44647},{\"end\":44680,\"start\":44665},{\"end\":44693,\"start\":44680},{\"end\":44710,\"start\":44693},{\"end\":44726,\"start\":44710},{\"end\":44740,\"start\":44726},{\"end\":45309,\"start\":45295},{\"end\":45328,\"start\":45309},{\"end\":45880,\"start\":45871},{\"end\":45892,\"start\":45880},{\"end\":45909,\"start\":45892},{\"end\":46145,\"start\":46132},{\"end\":46152,\"start\":46145},{\"end\":46165,\"start\":46152},{\"end\":46179,\"start\":46165},{\"end\":46191,\"start\":46179},{\"end\":46203,\"start\":46191},{\"end\":46216,\"start\":46203},{\"end\":46234,\"start\":46216},{\"end\":46584,\"start\":46570},{\"end\":46600,\"start\":46584},{\"end\":46612,\"start\":46600},{\"end\":46632,\"start\":46612},{\"end\":46879,\"start\":46863},{\"end\":46894,\"start\":46879},{\"end\":46913,\"start\":46894},{\"end\":47600,\"start\":47591},{\"end\":47610,\"start\":47600},{\"end\":47623,\"start\":47610},{\"end\":47633,\"start\":47623},{\"end\":47647,\"start\":47633},{\"end\":47656,\"start\":47647},{\"end\":47670,\"start\":47656},{\"end\":47681,\"start\":47670},{\"end\":47697,\"start\":47681},{\"end\":48092,\"start\":48076},{\"end\":48106,\"start\":48092},{\"end\":48126,\"start\":48106},{\"end\":48918,\"start\":48892},{\"end\":48930,\"start\":48918},{\"end\":48943,\"start\":48930},{\"end\":48961,\"start\":48943},{\"end\":48973,\"start\":48961},{\"end\":49523,\"start\":49507},{\"end\":49540,\"start\":49523},{\"end\":49555,\"start\":49540},{\"end\":49820,\"start\":49809},{\"end\":49829,\"start\":49820},{\"end\":49849,\"start\":49829},{\"end\":49861,\"start\":49849},{\"end\":49878,\"start\":49861},{\"end\":49892,\"start\":49878},{\"end\":50581,\"start\":50570},{\"end\":50590,\"start\":50581},{\"end\":50602,\"start\":50590},{\"end\":50617,\"start\":50602},{\"end\":51127,\"start\":51118},{\"end\":51147,\"start\":51127},{\"end\":51156,\"start\":51147},{\"end\":51169,\"start\":51156},{\"end\":51719,\"start\":51705},{\"end\":51729,\"start\":51719},{\"end\":51736,\"start\":51729},{\"end\":51752,\"start\":51736},{\"end\":51764,\"start\":51752},{\"end\":51966,\"start\":51955},{\"end\":51980,\"start\":51966},{\"end\":51994,\"start\":51980},{\"end\":51999,\"start\":51994},{\"end\":52321,\"start\":52301},{\"end\":52334,\"start\":52321},{\"end\":52345,\"start\":52334},{\"end\":52360,\"start\":52345},{\"end\":52371,\"start\":52360},{\"end\":52386,\"start\":52371},{\"end\":52398,\"start\":52386},{\"end\":52411,\"start\":52398},{\"end\":53015,\"start\":53002},{\"end\":53028,\"start\":53015},{\"end\":53042,\"start\":53028},{\"end\":53055,\"start\":53042},{\"end\":53786,\"start\":53774},{\"end\":53798,\"start\":53786},{\"end\":53811,\"start\":53798},{\"end\":53825,\"start\":53811},{\"end\":53841,\"start\":53825},{\"end\":53853,\"start\":53841},{\"end\":53865,\"start\":53853},{\"end\":53880,\"start\":53865},{\"end\":53894,\"start\":53880},{\"end\":53909,\"start\":53894},{\"end\":54297,\"start\":54285},{\"end\":54311,\"start\":54297},{\"end\":54315,\"start\":54311},{\"end\":54480,\"start\":54463},{\"end\":54501,\"start\":54480},{\"end\":54518,\"start\":54501},{\"end\":54535,\"start\":54518},{\"end\":54549,\"start\":54535},{\"end\":54564,\"start\":54549},{\"end\":54582,\"start\":54564},{\"end\":54600,\"start\":54582},{\"end\":54614,\"start\":54600},{\"end\":54626,\"start\":54614},{\"end\":55096,\"start\":55081},{\"end\":55113,\"start\":55096},{\"end\":55131,\"start\":55113},{\"end\":55605,\"start\":55590},{\"end\":55617,\"start\":55605},{\"end\":55630,\"start\":55617},{\"end\":55650,\"start\":55630},{\"end\":55668,\"start\":55650},{\"end\":55687,\"start\":55668},{\"end\":55705,\"start\":55687},{\"end\":55723,\"start\":55705},{\"end\":56095,\"start\":56083},{\"end\":56105,\"start\":56095},{\"end\":56118,\"start\":56105},{\"end\":56130,\"start\":56118},{\"end\":56144,\"start\":56130},{\"end\":56156,\"start\":56144},{\"end\":56167,\"start\":56156},{\"end\":56179,\"start\":56167},{\"end\":56197,\"start\":56179},{\"end\":56215,\"start\":56197},{\"end\":56560,\"start\":56549},{\"end\":56580,\"start\":56560},{\"end\":56600,\"start\":56580},{\"end\":56626,\"start\":56600},{\"end\":56641,\"start\":56626},{\"end\":56656,\"start\":56641},{\"end\":57387,\"start\":57373},{\"end\":57404,\"start\":57387},{\"end\":57871,\"start\":57856},{\"end\":57892,\"start\":57871},{\"end\":57911,\"start\":57892},{\"end\":58471,\"start\":58460},{\"end\":58481,\"start\":58471},{\"end\":58497,\"start\":58481},{\"end\":58507,\"start\":58497},{\"end\":58521,\"start\":58507},{\"end\":58536,\"start\":58521},{\"end\":59147,\"start\":59135},{\"end\":59155,\"start\":59147},{\"end\":59165,\"start\":59155},{\"end\":59175,\"start\":59165},{\"end\":59185,\"start\":59175},{\"end\":59684,\"start\":59669},{\"end\":59701,\"start\":59684},{\"end\":59716,\"start\":59701},{\"end\":59986,\"start\":59975},{\"end\":59999,\"start\":59986},{\"end\":60017,\"start\":59999},{\"end\":60034,\"start\":60017},{\"end\":60051,\"start\":60034},{\"end\":60607,\"start\":60598},{\"end\":60620,\"start\":60607},{\"end\":60643,\"start\":60620},{\"end\":61029,\"start\":61020},{\"end\":61039,\"start\":61029},{\"end\":61049,\"start\":61039},{\"end\":61062,\"start\":61049},{\"end\":61075,\"start\":61062},{\"end\":61088,\"start\":61075},{\"end\":61644,\"start\":61635},{\"end\":61654,\"start\":61644},{\"end\":61667,\"start\":61654},{\"end\":61680,\"start\":61667},{\"end\":61696,\"start\":61680},{\"end\":61709,\"start\":61696},{\"end\":62294,\"start\":62285},{\"end\":62304,\"start\":62294},{\"end\":62317,\"start\":62304},{\"end\":62333,\"start\":62317},{\"end\":62343,\"start\":62333},{\"end\":62356,\"start\":62343},{\"end\":62369,\"start\":62356},{\"end\":62922,\"start\":62908},{\"end\":62936,\"start\":62922},{\"end\":62950,\"start\":62936},{\"end\":62965,\"start\":62950},{\"end\":62980,\"start\":62965},{\"end\":62996,\"start\":62980},{\"end\":63008,\"start\":62996},{\"end\":63016,\"start\":63008},{\"end\":63029,\"start\":63016},{\"end\":63312,\"start\":63300},{\"end\":63324,\"start\":63312},{\"end\":63347,\"start\":63324},{\"end\":63614,\"start\":63598},{\"end\":63627,\"start\":63614},{\"end\":63642,\"start\":63627},{\"end\":63656,\"start\":63642},{\"end\":63673,\"start\":63656},{\"end\":63687,\"start\":63673},{\"end\":63707,\"start\":63687},{\"end\":63725,\"start\":63707},{\"end\":64164,\"start\":64149},{\"end\":64178,\"start\":64164},{\"end\":64195,\"start\":64178},{\"end\":64774,\"start\":64763},{\"end\":64786,\"start\":64774},{\"end\":64798,\"start\":64786},{\"end\":64812,\"start\":64798},{\"end\":64827,\"start\":64812},{\"end\":64843,\"start\":64827},{\"end\":64858,\"start\":64843},{\"end\":64871,\"start\":64858},{\"end\":64886,\"start\":64871},{\"end\":64899,\"start\":64886},{\"end\":65353,\"start\":65340},{\"end\":65369,\"start\":65353},{\"end\":65382,\"start\":65369},{\"end\":65399,\"start\":65382},{\"end\":65417,\"start\":65399},{\"end\":65430,\"start\":65417},{\"end\":65446,\"start\":65430},{\"end\":65457,\"start\":65446},{\"end\":65468,\"start\":65457},{\"end\":65486,\"start\":65468},{\"end\":65855,\"start\":65844},{\"end\":65867,\"start\":65855},{\"end\":65880,\"start\":65867},{\"end\":65893,\"start\":65880},{\"end\":65902,\"start\":65893},{\"end\":66228,\"start\":66217},{\"end\":66240,\"start\":66228},{\"end\":66252,\"start\":66240},{\"end\":66266,\"start\":66252},{\"end\":66279,\"start\":66266},{\"end\":66292,\"start\":66279},{\"end\":66304,\"start\":66292},{\"end\":66639,\"start\":66624},{\"end\":66653,\"start\":66639},{\"end\":66668,\"start\":66653}]", "bib_venue": "[{\"end\":44033,\"start\":43946},{\"end\":44411,\"start\":44370},{\"end\":44827,\"start\":44740},{\"end\":45414,\"start\":45328},{\"end\":45869,\"start\":45762},{\"end\":46285,\"start\":46250},{\"end\":46637,\"start\":46632},{\"end\":47055,\"start\":46913},{\"end\":47746,\"start\":47697},{\"end\":48301,\"start\":48126},{\"end\":49060,\"start\":48973},{\"end\":49505,\"start\":49445},{\"end\":50017,\"start\":49923},{\"end\":50710,\"start\":50617},{\"end\":51289,\"start\":51169},{\"end\":51703,\"start\":51659},{\"end\":52051,\"start\":51999},{\"end\":52505,\"start\":52411},{\"end\":53217,\"start\":53055},{\"end\":53983,\"start\":53925},{\"end\":54283,\"start\":54241},{\"end\":54694,\"start\":54626},{\"end\":55218,\"start\":55131},{\"end\":55784,\"start\":55723},{\"end\":56763,\"start\":56676},{\"end\":57498,\"start\":57404},{\"end\":58004,\"start\":57931},{\"end\":58615,\"start\":58556},{\"end\":59272,\"start\":59185},{\"end\":59667,\"start\":59589},{\"end\":60145,\"start\":60051},{\"end\":60712,\"start\":60643},{\"end\":61199,\"start\":61088},{\"end\":61820,\"start\":61709},{\"end\":62461,\"start\":62369},{\"end\":62906,\"start\":62825},{\"end\":63408,\"start\":63347},{\"end\":63815,\"start\":63741},{\"end\":64302,\"start\":64215},{\"end\":64989,\"start\":64915},{\"end\":65338,\"start\":65266},{\"end\":65951,\"start\":65902},{\"end\":66215,\"start\":66148},{\"end\":66622,\"start\":66534},{\"end\":44107,\"start\":44035},{\"end\":44901,\"start\":44829},{\"end\":45487,\"start\":45416},{\"end\":47184,\"start\":47057},{\"end\":48463,\"start\":48303},{\"end\":49134,\"start\":49062},{\"end\":50098,\"start\":50019},{\"end\":50790,\"start\":50712},{\"end\":51396,\"start\":51291},{\"end\":52586,\"start\":52507},{\"end\":53366,\"start\":53219},{\"end\":55292,\"start\":55220},{\"end\":56854,\"start\":56765},{\"end\":57579,\"start\":57500},{\"end\":58080,\"start\":58006},{\"end\":58676,\"start\":58617},{\"end\":59346,\"start\":59274},{\"end\":60226,\"start\":60147},{\"end\":61297,\"start\":61201},{\"end\":61918,\"start\":61822},{\"end\":62540,\"start\":62463},{\"end\":64391,\"start\":64304}]"}}}, "year": 2023, "month": 12, "day": 17}