{"id": 237353321, "updated": "2023-10-05 23:28:33.715", "metadata": {"title": "ReGen: Reinforcement Learning for Text and Knowledge Base Generation using Pretrained Language Models", "authors": "[{\"first\":\"Pierre\",\"last\":\"Dognin\",\"middle\":[]},{\"first\":\"Inkit\",\"last\":\"Padhi\",\"middle\":[]},{\"first\":\"Igor\",\"last\":\"Melnyk\",\"middle\":[]},{\"first\":\"Payel\",\"last\":\"Das\",\"middle\":[]}]", "venue": "EMNLP", "journal": "Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing", "publication_date": {"year": 2021, "month": null, "day": null}, "abstract": "Automatic construction of relevant Knowledge Bases (KBs) from text, and generation of semantically meaningful text from KBs are both long-standing goals in Machine Learning. In this paper, we present ReGen, a bidirectional generation of text and graph leveraging Reinforcement Learning to improve performance. Graph linearization enables us to re-frame both tasks as a sequence to sequence generation problem regardless of the generative direction, which in turn allows the use of Reinforcement Learning for sequence training where the model itself is employed as its own critic leading to Self-Critical Sequence Training (SCST). We present an extensive investigation demonstrating that the use of RL via SCST benefits graph and text generation on WebNLG+ 2020 and TekGen datasets. Our system provides state-of-the-art results on WebNLG+ 2020 by significantly improving upon published results from the WebNLG 2020+ Challenge for both text-to-graph and graph-to-text generation tasks. More details at https://github.com/IBM/regen.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2108.12472", "mag": null, "acl": "2021.emnlp-main.83", "pubmed": null, "pubmedcentral": null, "dblp": "conf/emnlp/DogninPMD21", "doi": "10.18653/v1/2021.emnlp-main.83"}}, "content": {"source": {"pdf_hash": "fa7f6d9a76bf64f71212aae0e6c2378efa43c997", "pdf_src": "ACL", "pdf_uri": "[\"https://www.aclanthology.org/2021.emnlp-main.83.pdf\"]", "oa_url_match": true, "oa_info": {"license": "CCBY", "open_access_url": "https://aclanthology.org/2021.emnlp-main.83.pdf", "status": "HYBRID"}}, "grobid": {"id": "021133019f65a8e93a73fb5a3a6ced4a470c8a01", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/fa7f6d9a76bf64f71212aae0e6c2378efa43c997.txt", "contents": "\nReGen: Reinforcement Learning for Text and Knowledge Base Generation using Pretrained Language Models\nAssociation for Computational LinguisticsCopyright Association for Computational LinguisticsNovember 7-11, 2021. 2021\n\nPierre L Dognin pdognin@us.ibm.com \nIBM Research\nIBM Research\nIBM Research\nIBM Research\n\n\nInkit Padhi \nIBM Research\nIBM Research\nIBM Research\nIBM Research\n\n\nIgor Melnyk igor.melnyk@ibm.com \nIBM Research\nIBM Research\nIBM Research\nIBM Research\n\n\nPayel Das \nIBM Research\nIBM Research\nIBM Research\nIBM Research\n\n\nReGen: Reinforcement Learning for Text and Knowledge Base Generation using Pretrained Language Models\n\nProceedings of the 2021 Conference on Empirical Methods in Natural Language Processing\nthe 2021 Conference on Empirical Methods in Natural Language ProcessingAssociation for Computational LinguisticsNovember 7-11, 2021. 20211084\nAutomatic construction of relevant Knowledge Bases (KBs) from text, and generation of semantically meaningful text from KBs are both long-standing goals in Machine Learning. In this paper, we present ReGen, a bidirectional generation of text and graph leveraging Reinforcement Learning (RL) to improve performance. Graph linearization enables us to re-frame both tasks as a sequence to sequence generation problem regardless of the generative direction, which in turn allows the use of Reinforcement Learning for sequence training where the model itself is employed as its own critic leading to Self-Critical Sequence Training (SCST). We present an extensive investigation demonstrating that the use of RL via SCST benefits graph and text generation on WebNLG+ 2020 and TEKGEN datasets.Our system provides state-of-the-art results on WebNLG+ 2020 by significantly improving upon published results from the WebNLG 2020+ Challenge for both text-to-graph and graph-to-text generation tasks. More details in https://github.com/IBM/regen.\n\nIntroduction\n\nGraph representation of knowledge is a powerful tool to capture real-world information where complex relationships between node entities can be efficiently encoded. Automatic generation of Knowledge Bases (KBs) from free-form text and its counterpart of generating semantically relevant text from KBs are both active and challenging research topics.\n\nRecently, there has been an increased interest in leveraging Pretrained Language Models (PLMs) to improve performance for text generation from graph, or graph-to-text (G2T) task (Ribeiro et al., 2020). Indeed, large PLMs like T5 (Raffel et al., 2020) and BART (Lewis et al., 2020) that have been pretrained on vast amount of diverse and variedly structured data, are particularly good candidates for generating natural looking text from graph data.\n\nBART-and T5-related models have been employed by top performers in public challenges such as the WebNLG+ 2020 Challenge (Castro Ferreira et al., 2020b) where both graph-to-text and textto-graph (T2G) tasks are offered, under the names RDF-to-Text and Text-to-RDF (semantic parsing) respectively; RDF stands for Resource Description Framework, a standard for describing web resources. One can notice that more teams entered the competition for the G2T task than for T2G as the latter is a much harder task. Best models generally use PLMs and fine-tune them for the target modality at hand (either graph or text). This is possible by re-framing the T2G and G2T generations as a sequence to sequence (Seq2Seq) generation problem, which suits fine-tuning PLMs well. One can therefore hope to leverage the large pretraining of PLMs to improve the overall generation quality.\n\nThe Seq2Seq formulation requires any input graph to be linearized as a sequence, which is not unique. This creates an opportunity for data augmentation where multiple linearizations are provided to the model at training time so the model learns the content represented by the graph, not the order of its sequential representation.\n\nIn this work, we are interested in leveraging the power of PLMs for both G2T and T2G generation tasks, and will demonstrate the strength of our approach by improving upon the best results of the WebNLG+ 2020 Challenge (rev 3.0) as reported by Castro Ferreira et al. (2020a) for both T2G (Semantic Parsing) and G2T (Data-to-Text) tasks. We will also present results for the TEKGEN Corpus (Agarwal et al., 2021) to show performance on a different, much larger dataset. To illustrate the task of generation, Fig. 1 provides examples of G2T and T2G outputs obtained using the proposed generation framework. The first two sentences of the abstract of this paper were used as input for T2G using our best model. The model generates a graph from the input text by simultaneously extracting Figure 1: Actual examples of generation for Text-to-Graph and Graph-to-Text tasks using our best RL models. The first two sentences of the abstract were processed through our best models. First, a graph was created capturing the facts from the input sentences. Then, this graph was used as input to generate text. Despite a strong domain mismatch between input data and models, the generated paragraph is capturing most of the original sentences content. Both models were trained using RL, specifically Self-Critical Sequence Training (SCST). relevant nodes and linking them coherently. For the G2T task, another model starts from the generated graph and generates semantically relevant text from it. As one can appreciate, the final text is quite readable and captures most facts from the original abstract sentences despite a strong domain mismatch between input data and training data, which both models were built on.\n\nSince both T2G and G2T generative tasks can be formulated as a Seq2Seq problem, we propose to use Reinforcement Learning (RL) as part of the PLMs fine-tuning on the target domain data. For both G2T and T2G tasks, a differentiable function such as the cross-entropy (CE) loss function is often used, since minimizing it results in maximizing the probability of generating the correct token/word. However, when it comes to evaluating a model's performance, benchmarks often use BLEU (Pa Pa Aung et al., 2020), METEOR (Lavie and Agarwal, 2007), and chrF++ (Popovi\u0107, 2017) for G2T, or simply F1, Precision, and Recall scores for T2G, none of which being differentiable. During training, one hopes that by minimizing the CE loss, the model will tend towards better prediction of the target tokens, hence improving on evaluation metrics as a beneficial by-product. Thankfully, RL provides a framework where we can update our model parameters so to improve evaluation metrics directly. Mixed Incremental Cross-Entropy Reinforce from Ranzato et al. (2016) introduced using REINFORCE (Williams, 1992) for sequence training. We propose to use one of its variant known as Self-Critical Sequence Training (SCST) (Rennie et al., 2017) for both T2G and G2T training.\n\nIn summary, our main contributions are: \u2022 We propose to use RL-based sequence training, specifically SCST, for both G2T and T2G tasks. This is the first time that RL based training is proposed to the bi-directional generation of text and graph. To the best of our knowledge, the present work is the first time it is introduced for a T2G task. \u2022 We demonstrate that our approach provides better performance than the best systems reported for the WebNLG 2020+ Challenge. \u2022 We provide a thorough investigation of SCSTbased training for both T2G and G2T tasks, including best rewards combination. \u2022 We constructed subject and relation-object boundaries from TEKGEN sentence-triples pairs and showed performance of our approach for both T2G and G2T tasks. \u2022 We adapted the large-scale TEKGEN corpus (Agarwal et al., 2021) for T2G and G2T tasks and confirmed the benefit of SCST-based fine-tuning approach over CE-trained baselines.\n\n\nRelated work\n\nIn the WebNLG+ 2020 Challenge, most top performing models relied on fine-tuning of PLMs. Interestingly, all four top teams in this Challenge proposed quite different approaches while leveraging PLMs. 1 st place Amazon AI (Guo et al., 2020a) pipelined a relational graph convolutional network (R-GCN) and a T5 PLM with some canonicalization rules. 2 nd place OSU Neural NLG (Li et al., 2020), the closest to our approach in spirit, used T5 and mBART PLMs to fine-tune after special data preprocessing. 3 rd place FBConvAI (Yang et al., 2020) used BART PLM and multiple strategies to model input RDFs. 4 th place bt5 employed a T5 PLM trained in a bi-lingual approach on English and Russian, even using WMT English/Russian parallel corpus.\n\nRecently, Dognin et al. (2020); Guo et al. (2020bGuo et al. ( , 2021 proposed models trained to generate in both T2G and G2T directions, with consistency cycles created to enable the use of unsupervised datasets.\n\nIn contrast, our approach of fine-tuning a T5 PLM is fully supervised but can produce either the specialized models for T2G and G2T tasks alone, or a hybrid model that can handle both T/G inputs simultaneously to generate the corresponding translated G/T outputs.\n\nNote that in contrast to many WebNLG+ 2020 Challenge participants, e.g. Li et al. (2020), no preprocessing of the data is performed for text, while for graph triples, we add tokens to mark subject, predicate, and object positions in their linearized sequence representation. Moreover, data augmentation is performed by allowing random shuffling of triples order in graph linearization to avoid a model to learn the exact order of triples, especially for the T2G task.\n\nWhile the use of RL training in PLM has been explored in many works, the approach of Chen et al. (2020) is closest to ours. However, their work focuses on the improved text generation in the context of natural question generation, while in our algorithm we use it for graph-to-text and text-to-graph generations.\n\n\nModels\n\nModels are trained on a dataset D composed of a set of (x T , x G ) i samples, where superscript i denotes the i-th sample in D, x T is made of text (one or more sentences), and x G is a corresponding graph represented as a list of triples x G = [(s 1 , p 1 , o 1 ), . . . , (s K , p K , o K )], where the k-th triple is composed of a subject s k , predicate (relationship) p k , and object o k . For G2T, the model is given x G as input and must generatex T . A cross-entropy loss is computed as an expectation:\nL T CE = E xT\u223cD log p G2T \u03b8 (x T ) ,(1)\nwhere p G2T \u03b8 (x T ) is the distribution of the generated sequencex T = T G2T (x G ), T G2T (.) being the transformation from graph to text. Our model is parameterized by \u03b8, and x T is effectively sampled from the marginal distribution of text samples from D.\n\nx T = [\u0175 1 ,\u0175 2 , . . . ,\u0175 T ] is a sequence of generated tokens/words. Similarly, for training a T2G model, the cross-entropy loss used in training is simply\nL G CE = E xG\u223cD log p T2G \u03b8 (x G ) ,(2)\nwhere p T2G \u03b8 (x G ) is the distribution of the generated graphx G = T T2G (x T ), T T2G (.) being the transformation from text to graph, and where x G is drawn from the marginal distribution of graph samples from D.\n\nIn both Eq. (1) and Eq. (2), x G must be expressed as a sequence of tokens t j such that a list of triples x G turns into a list of tokens [t 1 , t 2 , \u00b7 \u00b7 \u00b7 , t M ]. This is simply done by adding tokens marking the subject, predicate, and object boundaries in the sequence such that each triple (s k , p k , o k ) is turned into a sequence such as\n[<S>, w s 1 , <P>, w p 1 , w p 2 , <O>, w o 1 , w o 2 , w o 3 ]\n, assuming our subject is made of 1 token, our predicate of 2 tokens, and our object of 3 tokens in this example. <S>,<P>, and <O> are just special marker tokens to help the model know where subject, predicate and objects are located in the sequence.\n\nWe start from a pretrained encoder-decoder M model that we fine-tune on either T2G to get M T , or G2T task to get M G . We also propose a third kind of model M T+G to be fine-tuned on both T2G and G2T samples, i.e. the model will learn to generate in any direction, by supplying an input sample x = [x T ; x G ] and corresponding target for it. Input from each modality is prefixed by a task specific string to distinguish transfer directions (\"Text to Graph:\" for x T and \"Graph to Text:\" for x G ). For M T+G models, the cross-entropy loss is similarly defined as for Eq. (1) and Eq.\n\n(2) such that L T+G CE = E x\u223cD [ log p \u03b8 (x)]. All models are shown in Fig. 2. By convention, we refer to models in this paper by their input modality T, G, or T+G.\n\n\nReinforcement Learning\n\nSequence generation can be seen as an agent making sequential decisions of picking words from a given vocabulary. The agent reacts to its environment by accounting for past predictions and getting rewarded along the way, while its state is defined by the partial sequence generated so far. This interpretation enables the reformulation of Seq2Seq generation within the Reinforcement Learning (RL) framework (Sutton and Barto, 2018;Silver, 2015). More precisely, a sequence generation task can be recast as a Markov Decision Process (MDP) where the agent behavior follows a policy \u03c0(a t |s t ). Action a t corresponds to picking a particular word w t at time t from a vocabulary V, conditioned on state s t expressed as the partial sequence generation s t =x 1:t = [\u0175 1 , . . . ,\u0175 t ], that is sequence of words/tokens already picked. \u03c0(a t |s t ) is a stochastic policy that defines a probability distribution of a t . Once the action a t is taken,\nEncoder x t Decoder x tg L ce (x tg , x g ) L rl (x tg , x g ) M t Encoder x g Decoder x gt L ce (x gt , x t ) L rl (x gt , x t ) M g Specialized models M t , M g x t x g Encoder Decoder x tg x gt L ce x tg x gt , x g x t L rl x tg x gt , x g x t Hybrid model M t+g\nNotations:\n\nx .t : text x .g : graph Figure 2: Specialized and hybrid models rely on the same losses for fine-tuning. However, specialized models are dedicated to a particular generation task while hybrid models can handle both generation directions.\n\nthe agent receives a reward r t = r(s t , a t ) before it transitions to the next state s t+1 . A sequence of actions a 1:T = [a 1 , . . . , a T ] is selected until the end of generation is reached. The agent aims at maximizing the expectation of cumulative reward\nJ(\u03c0) = E \u03c4 T t=1 \u03b3 t r t = E \u03c4 [R(\u03c4 )](3)\nwhere \u03b3 is a discounting factor used to control the horizon of the cumulative reward, \u03b3 \u2208 [0, 1]. The expectation is taken over trajectories \u03c4 , sequences made of {s 1 , a 1 , r 1 , . . . , s T , a T , r T }, where a t was chosen from policy \u03c0(a t |s t ). RL provides both on-policy and off-policy approaches to maximize J(\u03c0) in Eq. (3). We are particularly interested in on-policy techniques that rely on data samples generated from the model to train, especially since our models start from large fine-tuned PLMs that can already generate good samples. This helps avoid the common drawback of on-policy techniques of generating poor samples at first when trained from scratch. . Policy-based methods focus on a parameterized policy \u03c0 \u03b8 where \u03b8 is optimized to maximize J(\u03c0 \u03b8 ). The policy \u03c0 \u03b8 (a t |s t ) is the PLM generative model p \u03b8 , CE fine-tuned as described at the beginning of Section 3. REINFORCE, presented by Williams (1992), allows the optimization of a model's parameters \u03b8 by maximizing the expected value of the wordbased reward R w (x T ) of generated sequencex T = [\u0175 1 , . . . ,\u0175 T ]. For notation convenience, note that R w (x T ) = R(\u03c4 ) since we are now dealing with sequence of words/tokensx T selected by the actions in trajectory \u03c4 . We will also use the R(x T ) notation for simplicity. In order to match common Deep Learning conventions, we can minimize a loss expressed as the negative value of the expected cumulative reward:\nL RL = [\u0175 1 ,...,\u0175 T ] p \u03b8 (\u0175 1 , . . . ,\u0175 T )R w (\u0175 1 , . . . ,\u0175 T ) = E [\u0175 1 ,...,\u0175 T ]\u223cp \u03b8 R w (\u0175 1 , . . . ,\u0175 T ), = Ex T \u223cp \u03b8 R w (x T ). (4) R w (x T )\nis the reward for the generated text which is often associated with non-differentiable metrics such as BLEU, METEOR, chrF, etc. Note that in sequence generation, these metrics-based rewards are available only once a whole sequence is generated, trading sparsity/delay of reward for quality (i.e. we use the full sequence reward, not an estimation of partial future reward). We circumvent the non-differentiability issue by using the REIN-FORCE policy gradient method:\n\u2207 \u03b8 L RL \u221d (R(x T ) b) \u2207 \u03b8 log p \u03b8 (x T ),(5)\nwhere b is a baseline used to reduce the variance of our gradient estimate. b can be any function, even a random variable, as long as it is independent of the actions taken to generatex T , as described in Chapter 13.4 from Sutton and Barto (2018). In Self-Critical Sequence Training (SCST) (Rennie et al., 2017), b is chosen to be the reward of x * T , the output generated by the model by greedy max generation, hence the model serving as its own critic:\n\u2207 \u03b8 L SCST \u221d (R(x T ) R(x * T )) \u2207 \u03b8 log p \u03b8 (x T ),(6)\nwherex T is sampled from our model and x * T is generated by greedy max. An interesting property of the baseline is that if R(x T ) > R(x * T ), sampledx T has higher reward than x * T , then the model is updated to reinforce the choices made by this generation. In the opposite case where R(x T ) < R(x * T ), the model update will take the negative gradient to subdue such generation. When R(x T ) = R(x * T ), no update is performed on the model since the gradient is effectively zeroed out, regardless of the individual values R(x T ) and R(x * T ). This happens whenx T and x * T are identical (greedy-max and sampled sequences are the same). In that case the sample is lost for RL as no update to the model will result from this sample. Basically, REINFORCE is a Monte Carlo method of learning where a gradient update is applied in the direction decided by how R(x T ) compares to baseline b, the role of b being to reduce the variance of the gradient estimate. Variations around REINFORCE exist on how to apply the gradients, such as MIXER from Ranzato et al. (2016), or on how to evaluate the baseline (Luo, 2020) to minimize the gradient variance.\n\nIn our training, PLMs are first fine-tuned using L CE loss. Once they reach a good generation quality, the training is switched to RL fine-tuning by minimizing L SCST .\n\n\nExperimental Setup\n\nIn this Section, we present the experimental setup used for all the results reported in this paper. Models We used T5 PLMs from Wolf et al. (2020) for our experiments for two distinct models, t5large (770M parameters) and t5-base (220M parameters), with a special focus on t5-large as it is the best performing of the two on various NLP tasks. Models were fine-tuned to be either specialized on T2G (M T ) or G2T (M G ) task, or to accommodate both directions of generation (M T+G ). Data processing Graphs are often represented as list of triples. However our model expects a sequence of input words/tokens to work on. The linearization of graph triples is obviously ambiguous as there are many ways to traverse a graph (Breadth First Search, Depth First Search, random walk, etc.). In practice, we linearize the triples in the order of the list provided by the dataset, but use this inherent linearization ambiguity as an opportunity to do data-augmentation. Indeed, models are first fine-tuned using cross-entropy loss that strongly penalizes generation if it is in any different order than the ground truth order. To avoid the model to overfit to our data and memorize observed triples order, we augment the data by including a few permutations of the graph triples.\n\nDuring graph linearization, we encode the subject, predicate, and object positions by using <S>,<P>,<O> tokens. In practice, we expand the model vocabulary with these special indivisible tokens that are not split during tokenization. No other preprocessing is done on the data for training. We explored masked and span-masked LM fine-tuning to match T5 pretraining (Raffel et al., 2020) which did not lead to any noticeable improvements.\n\n\nDatasets\n\nWebNLG+ 2020 We report results on WebNLG+ 2020 (v3.0) used in the WebNLG 2020 Challenge (Castro Ferreira et al., 2020b). The Challenge comprises of two tasks: RDF-to-text generation (G2T), and Text-to-RDF semantic parsing (T2G). The Resource Description Framework (RDF) language is used to encode DBpedia and is commonly used in linked data framework. WebNLG+ uses RDF to encode graphs as sets of triples which are associated to one or more lexicalizations of one or more sentences each. Data for English and Russian are provided, but we only worked on the English subset made of 13,211 train, 1,667 dev, 2,155 testA (semantic parsing), and 1,779 testB (data-to-text) samples (triples sets w/ lexicalizations). The data is clustered semantically into 16 categories seen in train and dev sets (Airport, Astronaut, Building, etc.), while 3 categories (Film, Scientist, and Musical-Work) were introduced in test and are unseen, i.e. not present in training; see Castro Ferreira et al. (2020a) for more details. Results are aggregated for all, seen, and unseen categories during evaluation. Note that in the literature, prior works sometimes report 'WebNLG' results on previous dataset version, with completely different performance ranges. We compare all our results to WebNLG+ 2020 (v3.0) numbers reported by Castro Ferreira et al. (2020a) in their Table 6 for G2T,  and Table 10 for T2G tasks, using the provided official scoring scripts. TEKGEN To further study the robustness of our system, we also provide experiments using TEK-GEN dataset recently introduced in Agarwal et al. Query Service. Additionally, we limit the validation set and test set to 5K and 50K sentence-triples pairs respectively. Our training split after processing contains 6.3 million sentence-triples pairs. As a contribution to the work, we will present the steps to augment TEKGEN dataset with appropriate subject, object and relation boundaries, which enables conventional evaluation of research systems. An example of the processed TEKGEN is shown in Fig. 3 in Appendix.\n\nMetrics WebNLG+ 2020 provides automatic metrics to evaluate models. For G2T, we used BLEU, BLEU_NLTK, METEOR, and chrF++ that are provided by the challenge. For T2G, F1, Precision, and Recall scores are utilized and computed for 4 levels of match: Exact, Ent_Type, Partial and Strict as described in Castro Ferreira et al. (2020a), which loosely correspond to different levels of relaxation of how close a match of an entity must be to the ground truth in content and position in a triple. Note that when generating graphs/RDFs, scoring metrics explore all possible permutations of a graph edges. For TEKGEN, we use the same metrics as for WebNLG+ 2020.\n\n\nResults\n\nFor all experiments, PLMs were first exposed to the target datasets (WebNLG+, TEKGEN) by finetuning using L CE loss. They were then switched to RL training by optimizing the L SCST loss. Although no exact recipe has been established for Seq2Seq RL-training, starting from a good CE model helps RL training performance in practice (Ranzato et al., 2016;Rennie et al., 2017). Therefore, we followed the subsequent simple approach: During fine-tuning, the evaluations are conducted on the validation set. From the CE phase, the best performing model iteration is selected based on the METEOR and F1 score for the G2T and T2G tasks, respectively, to pursue RL fine-tuning. In case of G2T, potential ties in METEOR scores among candidate models, are resolved by using BLEU_NLTK, followed by the chrF++ metric. Note that early stopping selection of CE models led to good performance for t5-base models as well. During the SCST phase, the best model iteration on the validation set is selected and its performance numbers on the test set are reported in our tables.\n\nWebNLG+ 2020 G2T For the WebNLG+ 2020 Challenge, the results of the top four systems for RDF-to-text task can be found in Tab   all metrics achieving state-of-the-art results to our knowledge. The gain obtained by SCST alone is quite significant and demonstrates the benefits of RL fine-tuning for this task. We report our best model results in Tab. 1, as well as mean and standard deviation results for multiple random number generator seeds in Tab. 10 in Appendix. When averaging results for few seeded models, sustained gains from SCST are seen for all metrics. Multiple reward candidates were investigated (BLEU, BLEU_NLTK, METEOR, chrF) as well as some linear combinations of pairs of them, as can be seen in Tab. 7 in Appendix. In Tab. 7, for t5-large, METEOR is consistently the best SCST reward, and improves all the other metrics scores as well. However, for 'smaller' models such as t5-base, BLEU_NLTK is revealed to be the best reward for improving BLEU performance as expected. Again, SCST brings significant gains across all the metrics in that case. Note that for t5-base model, selecting a METEOR reward improves METEOR results significantly as reported in Tab. 9 in Appendix.\n\nAnother interesting fact is that early stopping of CE model G2T.CE.ES (at 5 epochs) leads to the best SCST model G2T.RL.ES for t5-base, while selecting the best CE model G2T.CE.best (at 11 epochs) still showed some gains from SCST model G2T.RL.best. SCST needs a good starting point, but a better CE model that has seen a lot more epochs of our dataset maybe harder for SCST to stir in a better solution in the parameter space.\n\nMoreover, the test split contains unseen categories not present in the validation dataset which render choices based on validation sub-optimal for the test dataset. The best models we report in this work are specialized models M G . Early in our investigation, hybrid models were the best performing model for G2T reaching 0.547 BLEU, 0.543 BLEU_NLTK and 0.417 METEOR, and first to beat the Challenge winning team. However, when batch size became larger (20-24 samples), the specialized models took the lead and retain it still.\n\nFor training, we optimized all our models using AdamW (Loshchilov and Hutter, 2017), variant of the Adam optimizer with default values of \u03b2 = [0.9, 0.999] and weight decay of 10 \u22122 . For learning rate, we used 5.10 \u22126 for all our experiments as it was better than 10 \u22125 and 10 \u22126 as seen in Tab. 8 in Appendix. All our models were trained with 20-24 minibatch size on WebNLG. Further details on our experimental setup are provided in the Appendix in Section A.\n\nWebNLG+ 2020 T2G Results for the Text-to-RDF task are reported in Tab. 2 for all categories. Results for our best model on seen and unseen categories are given in Tab. 6 in Appendix. Amazon AI and bt5 are the top performing teams. Again, the proposed ReGen T2G.CE model shows strong results that are better in term of all metrics, for all matching categories. In themselves, these numbers are a de-facto new state-of-the-art for this dataset, as far as we know. SCST model T2G.RL fails to improve on this model though. The exact F1 metric was used as reward, but the model could never pull ahead of the CE model in our experiments. The exact F1 metric may not be a strong enough reward to really capture the dynamics of graph generation properly for WebNLG+ as it is very rigid in its measure (one must have an exact match), although the same reward gave good results on our second dataset TEKGEN. A more sensitive metric could possibly help. We even tried to use n-gram based metrics (like BLEU) but to no avail. We further address this issue at the end on this Section. TEKGEN G2T For the TEKGEN dataset, we present our results on Graph-to-Text generation in Tab. 3. Similar to the experiments in WebNLG+, we pick the best model during the CE fine-tuning based on the METEOR score and proceed with the RL fine-tuning. We observe that the RL fine-tuning step helps boost the test split scores on all metrics. It is worth noting that the scores are slightly under-  estimating the potential of our system because of the nature of the sentences in the TEKGEN dataset. Unlike WebNLG+, in a paired text-graph sample in TEKGEN, the linearized graph does not usually cover all the concepts described in the corresponding text. This leads to underestimating when the hypothesis is scored against the reference using n-gram metrics.\n\n\nTEKGEN T2G\n\nResults for the Text-to-Graph for TEKGEN are reported in Tab. 4. Once the CE finetuning is done, we continue with the RL fine-tuning using exact F1 as reward. The performance is consistent with what we observe in G2T task for TEK-GEN, where SCST step boosts the performance of the model. Since, we reformulate this dataset (refer Section 4.1) to offer as T2G and G2T tasks, our approach is the first attempt in understanding the nature of TEKGEN dataset and our methods provide a baseline for future research. Please note that for both T2G and G2T tasks in TEKGEN, we only start a t5-large PLM.\n\nSummary Results on WebNLG+ 2020 and TEK-GEN demonstrated that RL fine-tuning of models leads to significant improvements of results for T2G and G2T, establishing new state-of-the-art results for both tasks. For WebNLG+, T2G was a challenging task for RL fine-tuning. In further work, we plan to address this issue by investigating two points: First, look into a more sensible graphdependent sampling for graph structures, rather than the current multinomial sampling of the best tokens at each generation step. Second, try a different reward schemes where the reward is more attuned to the challenges of graph generation as well as graph structure, allowing for some curriculum learning, or increasing the harshness of rewards gradually during training. Results on TEKGEN showed that RL fine-tuning is a viable option even on large-scale datasets. To enrich this quantitative study of ReGen, we provide a few qualitative cherry picked results in Tab. 11 and Tab. 12 in Appendix.\n\n\nConclusions\n\nIn this paper, we proposed to use RL for improving upon current generation for text-to-graph and graph-to-text tasks for the WebNLG+ 2020 Challenge dataset using pre-trained LMs. We not only defined a novel Seq2Seq training of models in T2G and G2T generation tasks, but we established stateof-the-art results for WebNLG+ for both tasks, significantly improving on the previously published results. We provided extensive analyses of our results and of the steps taken to reach these improvements. We then expanded our approach to large scale training by means of TEKGEN where we demonstrated that RL fine-tuning provides a robust way to improve upon regular model finetuning within a dataset that is orders of magnitude larger than the WebNLG+ starting point. We established gains despite a weaker content overlap in text-graph data pairs for TEKGEN. Along the way, we constructed subject, and relation-object boundaries from TEKGEN sentence-triples pairs that we plan on releasing to benefit the research community. Future work will focus on developing a variant of SCST that leverages the unique structure of graph by either performing of more sensible graphdependent sampling, or by investigating different reward schemes more attuned to integrating the content and structure of graphs.\n\n\nBroader Impact Statement\n\nThe techniques proposed in this paper are inherently dependent on the training data and the PLMs used for fine-tuning on this data. The models do benefit from the large amount of data seen by the PLM they are derived from, however it is fair to assume that any detectable bias in the original data or PLMs would most likely be transferred to the text-to-graph and graph-to-text generative models. This is something to keep in mind when building these generative models. Public datasets were used for all experiments. The TEKGEN with recreated boundaries does not change the underlying data and should not add any further noise nor bias to the original data. \n\n\nReferences\n\n\nA Training Setup\n\nAll our experiments were run using NVIDIA V100 GPUs for training and validation, some trainings were done on A100. We distributed our training to 2-4 GPUs depending on availability. Each training epoch for CE ranged from 30 minutes to 1 hour depending on number of GPUs utilized.\n\nValidation and testing (1,779 and 2,155 samples for testA and testB of WebNLG+ 2020) lasted from 40 minutes to 1 hour depending on machines. Computation was dominated by beam search generation as we used beam search with beam size of 5 and a max sequence length of 192 (since linearized graph sequence can be quite long). We used the official scoring scripts released by WebNLG+ 2020 Challenge to score all our experiments. The evaluation of graph being the most computationally expensive as all possible matching combinations are tested in what looks like a factorial complexity, taking scoring of set of triples larger than 8 from impractical to not feasible.\n\nAll our models were built using PyTorch. Total effective batch sizes were set to either 20 or 24 samples for our distributed training. We adjusted the batch size on each worker to ensure consistent global batch size of 20 or 24.\n\nWe did some search on learning rates for t5large training and SCST rewards, see discussion and results in Section C.\n\nAll our trainings have a seeded random number generator for reproducibility. We also report results on WebNLG+ 2020 G2T tasks for each training setup by showing results for 3 models from different seeds, and provide means and standard deviations of these results in Tab. 10.\n\n\nB WebNLG+ 2020 Results per\n\nCategories for Best G2T and T2G Models\n\nIn Tab. 5, we are reporting results for all WebNLG+ 2020 categories for our best CE and RL models. While results for unseen categories are much worse than for seen categories, RL fine-tuning manages to improve on both seen and unseen categories.\n\nTab. 6 provides results for seen, unseen and all categories for our best CE model ReGen T2G.CE which established state-of-the-art results on T2G task of WebNLG+ 2020 Challenge dataset.\n\n\nC Ablation Studies\n\nIn Tables 7 and 8 we present ablation studies of different optimized metrics and learning rates for SCST training. As can be seen from Table 7, when METEOR is used as a reward, we get the best performance across all the metrics. We also tried using a combination of multiple rewards with different scaling but did not get any gain over the single metric rewards. In Table 8. we also show the effect of learning rate on SCST performance. Using lr = 5 \u00b7 10 \u22126 gave us the best performance, while higher rates, such as 10 \u22124 , led to unstable training and collapse of SCST.\n\n\nD G2T Results t5-base models for SCST with METEOR Reward\n\nResults for SCST fine-tuning of t5-base models using a METEOR reward are compiled in Tab. 9. Clearly, these models achieve better METEOR results as expected since they are RL optimized on this metric.\n\n\nE G2T Results for Models from Multiple Random Seeds\n\nAll our training have a seeded random number generator for reproducibility. We also report the mean and standard deviations for all our G2T models. Each model setup was run 3 times using three independent and distinct seeds, following the same exact process. This is to ensure that our results are not just the product of a lucky system configuration or otherwise advantageous random shuffling of our training dataset. All results are reported in Tab. 10. The gain reported between CE and RL for our t5large models are clearly still showing after average of all 3 models from distinct random seeds. For t5-base, gains between CE and RL are still present, albeit smaller than for our best systems.\n\n\nF Generation Examples for G2T and T2G\n\nWe present some cherry-picked examples for G2T in Tab. 12 and for T2G in Tab. 11 for both WebNLG and TEKGEN datasets.\n\n\nG Processed TEKGEN Dataset\n\nIn Fig. 3 we show an example of our processing of TEKGEN dataset in establishing subject, relation, object boundaries. This enables both training and evaluating systems for T2G and G2T tasks.      \n\n\nThese policy-based(Williams, 1992;  Zaremba and Sutskever, 2016)  and actor-critic based techniques(Bahdanau et al., 2017;Rennie et al., 2017) have been studied for text generation and often update the underlying model with policy gradient(Ranzato et al., 2016; Li et al., 2016;Tan et al., 2019;Paulus et al., 2017)\n\n\n. The graph-sentence alignments are curated using Wikipedia and Wikidata. This serves as a perfect large scale test-bed for both G2T and T2G tasks. Unfortunately, this dataset lacks in entity/relation/object boundaries, which makes it difficult to evaluate systems for T2G tasks. In order to address this issue, we further process the triple-text (with no triple boundaries) to create list of triples using Wikidata properties lookup, via WikidataWebNLG G2T \nBLEU\u2191 \nBLEU\u2191 \nNLTK \n\nMETEOR\u2191 chrF++\u2191 \nTeam/model \n\nAmazon AI (Shanghai) (Guo et al., 2020a) \n0.540 \n0.535 \n0.417 \n0.690 \nOSU Neural NLG (Li et al., 2020) \n0.535 \n0.532 \n0.414 \n0.688 \nFBConvAI (Yang et al., 2020) \n0.527 \n0.523 \n0.413 \n0.686 \nbt5 (Agarwal et al., 2020) \n0.517 \n0.517 \n0.411 \n0.679 \n\nReGen (Ours) G2T.CE t5-large \n0.553 \n0.549 \n0.418 \n0.694 \nReGen (Ours) G2T.RL t5-large \n0.563 \n0.559 \n0.425 \n0.706 \n\nReGen (Ours) G2T.CE.ES t5-base (early CE) \n0.522 \n0.518 \n0.404 \n0.675 \nReGen (Ours) G2T.RL.ES t5-base (early CE) \n0.531 \n0.527 \n0.410 \n0.686 \n\nReGen (Ours) G2T.CE.best t5-base (best CE) \n0.524 \n0.520 \n0.404 \n0.677 \nReGen (Ours) G2T.RL.best t5-base (best CE) \n0.527 \n0.523 \n0.408 \n0.681 \n\nTable 1: G2T Best results on WebNLG 2020 Challenge (v3.0) dataset. The first four rows were the top performers \nof the Challenge. Results for CE and RL models are presented for our ReGen systems so to show gains from using \nSCST. Our G2T.RL is the best system overall, fine-tuning a t5-large model using METEOR reward. G2T.RL.ES \nand G2T.RL.best show the impact of using early stopping (ES) or best CE selection for starting SCST fine-tuning \non a t5-base smaller model while using BLEU_NLTK reward. \n\n\n\nTable 2 :\n2T2G Best results on WebNLG+ 2020 (v3.0) dataset. The top two teams were the first and second place winner of the Challeneg. Our T2G.CE model improves upon all metrics for all matching schemes, providing a new state-of-the-art results for this Challenge task. T2G.RL models, while still better than previous best results, does not improve upon its CE counterpart.TEKGEN G2T \nBLEU\u2191 \nBLEU\u2191 \nNLTK \n\nMETEOR\u2191 chrF++\u2191 \nModel \n\nReGen-CE \nVal \n0.240 \n0.241 \n0.231 \n0.400 \nTest \n0.241 \n0.242 \n0.233 \n0.405 \n\nReGen-SCST \nVal \n0.258 \n0.259 \n0.240 \n0.418 \nTest \n0.262 \n0.262 \n0.242 \n0.422 \n\n\n\nTable 3 :\n3G2T Results for TEKGEN dataset. ReGen-CE establishes a baseline on this dataset. ReGen-SCST consistently improve on the baseline on all metrics, for validation and test sets.\n\nTable 4 :\n4T2G TEKGEN Results: ReGen-CE establishes a baseline of the dataset. ReGen-SCST improves results on the test set compared to ReGen-CE.\n\n\nJiwei Li, Will Monroe, Alan Ritter, Michel Galley, Jianfeng Gao, and Dan Jurafsky. 2016. Deep reinforcement learning for dialogue generation. Xintong Li, Aleksandre Maskharashvili, Symon Jory Stevens-Guille, and Michael White. 2020. Leveraging large pretrained models for WebNLG 2020. In Proceedings of the 3rd International Workshop on Natural Language Generation from the Semantic Web (WebNLG+), pages 117-124, Dublin, Ireland (Virtual). Association for Computational Linguistics. Ilya Loshchilov and Frank Hutter. 2017. Fixing weight decay regularization in adam. CoRR, abs/1711.05101. Quentin Lhoest, and Alexander Rush. 2020. Transformers: State-of-the-art natural language processing. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, pages 38-45, Online. Association for Computational Linguistics. Zixiaofan Yang, Arash Einolghozati, Hakan Inan, Keith Diedrick, Angela Fan, Pinar Donmez, and Sonal Gupta. 2020. Improving text-to-text pretrained models for the graph-to-text task. In Proceedings of the 3rd International Workshop on Natural Language Generation from the Semantic Web (WebNLG+), pages 107-116, Dublin, Ireland (Virtual). Association for Computational Linguistics. Wojciech Zaremba and Ilya Sutskever. 2016. Reinforcement learning neural turing machines -revised.Oshin Agarwal, Heming Ge, Siamak Shakeri, and \nRami Al-Rfou. 2021. Knowledge graph based syn-\nthetic corpus generation for knowledge-enhanced \nlanguage model pre-training. In Proceedings of the \n2021 Conference of the North American Chapter of \nthe Association for Computational Linguistics: Hu-\nman Language Technologies, pages 3554-3565, On-\nline. Association for Computational Linguistics. \n\nOshin Agarwal, Mihir Kale, Heming Ge, Siamak Shak-\neri, and Rami Al-Rfou. 2020. Machine transla-\ntion aided bilingual data-to-text generation and se-\nmantic parsing. In Proceedings of the 3rd Interna-\ntional Workshop on Natural Language Generation \nfrom the Semantic Web (WebNLG+), pages 125-130, \nDublin, Ireland (Virtual). Association for Computa-\ntional Linguistics. \n\nDzmitry Bahdanau, Philemon Brakel, Kelvin Xu, \nAnirudh Goyal, Ryan Lowe, Joelle Pineau, Aaron C. \nCourville, and Yoshua Bengio. 2017. An actor-critic \nalgorithm for sequence prediction. In 5th Inter-\nnational Conference on Learning Representations, \nICLR 2017, Toulon, France, April 24-26, 2017, Con-\nference Track Proceedings. OpenReview.net. \n\nThiago Castro Ferreira, Claire Gardent, Nikolai \nIlinykh, Chris van der Lee, Simon Mille, Diego \nMoussallem, and Anastasia Shimorina. 2020a. The \n2020 bilingual, bi-directional WebNLG+ shared \ntask: Overview and evaluation results (WebNLG+ \n2020). In Proceedings of the 3rd International Work-\nshop on Natural Language Generation from the Se-\nmantic Web (WebNLG+), pages 55-76, Dublin, Ire-\nland (Virtual). Association for Computational Lin-\nguistics. \n\nThiago Castro Ferreira, Claire Gardent, Nikolai \nIlinykh, Chris van der Lee, Simon Mille, Diego \nMoussallem, and Anastasia Shimorina, editors. \n2020b. Proceedings of the 3rd International Work-\nshop on Natural Language Generation from the Se-\nmantic Web (WebNLG+). Association for Computa-\ntional Linguistics, Dublin, Ireland (Virtual). \n\nYu Chen, Lingfei Wu, and Mohammed J. Zaki. 2020. \nReinforcement learning based graph-to-sequence \nmodel for natural question generation. In 8th Inter-\nnational Conference on Learning Representations, \nICLR 2020, Addis Ababa, Ethiopia, April 26-30, \n2020. OpenReview.net. \n\nPierre Dognin, Igor Melnyk, Inkit Padhi, Cicero \nNogueira dos Santos, and Payel Das. 2020. Du-\nalTKB: A Dual Learning Bridge between Text and \nKnowledge Base. In Proceedings of the 2020 Con-\nference on Empirical Methods in Natural Language \nProcessing (EMNLP), pages 8605-8616, Online. As-\nsociation for Computational Linguistics. \n\nQipeng Guo, Zhijing Jin, Ning Dai, Xipeng Qiu, Xi-\nangyang Xue, David Wipf, and Zheng Zhang. 2020a. \n\u221a 2 : A plan-and-pretrain approach for knowledge \ngraph-to-text generation. In Proceedings of the 3rd \nInternational Workshop on Natural Language Gen-\neration from the Semantic Web (WebNLG+), pages \n100-106, Dublin, Ireland (Virtual). Association for \nComputational Linguistics. \n\nQipeng Guo, Zhijing Jin, Xipeng Qiu, Weinan Zhang, \nDavid Wipf, and Zheng Zhang. 2020b. CycleGT: \nUnsupervised graph-to-text and text-to-graph gener-\nation via cycle training. In Proceedings of the 3rd In-\nternational Workshop on Natural Language Genera-\ntion from the Semantic Web (WebNLG+), pages 77-\n88, Dublin, Ireland (Virtual). Association for Com-\nputational Linguistics. \n\nQipeng Guo, Zhijing Jin, Ziyu Wang, Xipeng Qiu, \nWeinan Zhang, Jun Zhu, Zheng Zhang, and David \nWipf. 2021. Fork or fail: Cycle-consistent train-\ning with many-to-one mappings. In The 24th In-\nternational Conference on Artificial Intelligence and \nStatistics, AISTATS 2021, April 13-15, 2021, Vir-\ntual Event, volume 130 of Proceedings of Machine \nLearning Research, pages 1828-1836. PMLR. \n\nAlon Lavie and Abhaya Agarwal. 2007. METEOR: An \nautomatic metric for MT evaluation with high levels \nof correlation with human judgments. In Proceed-\nings of the Second Workshop on Statistical Machine \nTranslation, pages 228-231, Prague, Czech Repub-\nlic. Association for Computational Linguistics. \n\nMike Lewis, Yinhan Liu, Naman Goyal, Mar-\njan Ghazvininejad, Abdelrahman Mohamed, Omer \nLevy, Veselin Stoyanov, and Luke Zettlemoyer. \n2020. BART: Denoising sequence-to-sequence pre-\ntraining for natural language generation, translation, \nand comprehension. In Proceedings of the 58th An-\nnual Meeting of the Association for Computational \nLinguistics, pages 7871-7880, Online. Association \nfor Computational Linguistics. \n\n\n\n\nWebNLG G2T Best Models Category BLEU\u2191BLEU\u2191 NLTKMETEOR\u2191 chrF++\u2191 \n\nOurs t5-large ReGen-CE \nunseen \n48.76 \n0.489 \n0.397 \n0.653 \nseen \n59.73 \n0.592 \n0.433 \n0.722 \nall \n55.26 \n0.549 \n0.418 \n0.694 \n\nOurs t5-large ReGen-SCST \nunseen \n49.06 \n0.493 \n0.404 \n0.665 \nseen \n61.22 \n0.605 \n0.440 \n0.734 \nall \n56.25 \n0.559 \n0.425 \n0.706 \n\n\n\nTable 5 :\n5G2T: Results for seen, unseen, and all categories subsets in WebNLG+ 2020 Challenge Test dataset. As expected, unseen categories much worse results than for seen categories. RL fine-tuning manages to improve on both seen and unseen categories.WebNLG T2G \nMatch \nF1\u2191 \nPrecision\u2191 Recall\u2191 \nReGen T2G.CE \n\nunseen \n\nExact \n0.5809 \n0.5662 \n0.6069 \nEnt_Type 0.7014 \n0.6741 \n0.7497 \nPartial \n0.6453 \n0.6241 \n0.6826 \nStrict \n0.5754 \n0.5608 \n0.6012 \n\nseen \n\nExact \n0.8322 \n0.8286 \n0.8384 \nEnt_Type 0.8878 \n0.8811 \n0.8998 \nPartial \n0.8604 \n0.8553 \n0.8696 \nStrict \n0.8317 \n0.8282 \n0.8379 \n\nall \n\nExact \n0.7229 \n0.7144 \n0.7376 \nEnt_Type 0.8067 \n0.7910 \n0.8345 \nPartial \n0.7668 \n0.7547 \n0.7882 \nStrict \n0.7202 \n0.7118 \n0.7349 \n\n\n\nTable 6 :\n6T2G: Results for seen, unseen, and all categories subsets in WebNLG+ 2020 Challenge Test dataset. As expected the performance drops significantly for unseen categories and are the best for seen categories.SCST Reward \nBLEU\u2191 \nBLEU\u2191 \nNLTK \n\nMETEOR\u2191 chrF++\u2191 \n\nBLEU \n0.556 \n0.552 \n0.420 \n0.698 \nBLEU NLTK \n0.558 \n0.554 \n0.422 \n0.700 \nMETEOR \n0.563 \n0.559 \n0.425 \n0.706 \nchrF++ \n0.554 \n0.551 \n0.423 \n0.701 \n1 /2\u00b7METEOR+ 1 /2\u00b7BLEU NLTK \n0.555 \n0.551 \n0.421 \n0.699 \n2 /3\u00b7METEOR+ 1 /3\u00b7BLEU NLTK \n0.547 \n0.543 \n0.419 \n0.697 \n\n\n\nTable 7 :\n7Ablation study of metrics used as rewards in SCST for t5-large models. The results shown are on the test split.Learning Rate BLEU\u2191 \nBLEU\u2191 \nNLTK \n\nMETEOR\u2191 chrF++\u2191 \n\n10 \u22126 \n0.553 \n0.549 \n0.420 \n0.698 \n5 \u00b7 10 \u22126 \n0.558 \n0.554 \n0.422 \n0.700 \n10 \u22125 \n0.544 \n0.542 \n0.419 \n0.696 \n\n\n\nTable 8 :\n8Ablation study on learning rates in SCST (using BLEU NLTK as the optimized metric) ReGen G2T.RL.ES.meteor t5-base (early CE) ReGen G2T.RL.best.meteor t5-base (best CE)WebNLG G2T \nBLEU\u2191 \nBLEU\u2191 \nNLTK \n\nMETEOR\u2191 chrF++\u2191 \nTeam/model \n\n0.527 \n0.523 \n0.413 \n0.689 \n0.528 \n0.526 \n0.412 \n0.681 \n\n\n\nTable 9 :\n9G2T: Best results for t5-base fine-tuned with SCST using METEOR as reward.Team Name \nBLEU\u2191 \nBLEU\u2191 \nNLTK \n\nMETEOR\u2191 \nchrF++\u2191 \n\n\nAutomatic Myanmar image captioning using CNN and LSTM-based language model. Pa San Pa, Win Pa Aung, Tin Pa, Lay Nwe, Proceedings of the 1st Joint Workshop on Spoken Language Technologies for Under-resourced languages (SLTU) and Collaboration and Computing for Under-Resourced Languages (CCURL). the 1st Joint Workshop on Spoken Language Technologies for Under-resourced languages (SLTU) and Collaboration and Computing for Under-Resourced Languages (CCURL)Marseille, FranceEuropean Language Resources associationSan Pa Pa Aung, Win Pa Pa, and Tin Lay Nwe. 2020. Automatic Myanmar image captioning us- ing CNN and LSTM-based language model. In Proceedings of the 1st Joint Workshop on Spoken Language Technologies for Under-resourced lan- guages (SLTU) and Collaboration and Computing for Under-Resourced Languages (CCURL), pages 139-143, Marseille, France. European Language Re- sources association.\n\nA deep reinforced model for abstractive summarization. Romain Paulus, Caiming Xiong, Richard Socher, Romain Paulus, Caiming Xiong, and Richard Socher. 2017. A deep reinforced model for abstractive sum- marization.\n\nchrF++: words helping character n-grams. Maja Popovi\u0107, 10.18653/v1/W17-4770Proceedings of the Second Conference on Machine Translation. the Second Conference on Machine TranslationCopenhagen, DenmarkAssociation for Computational LinguisticsMaja Popovi\u0107. 2017. chrF++: words helping charac- ter n-grams. In Proceedings of the Second Con- ference on Machine Translation, pages 612-618, Copenhagen, Denmark. Association for Computa- tional Linguistics.\n\nExploring the limits of transfer learning with a unified text-to-text transformer. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J Liu, Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2020. Exploring the limits of transfer learning with a unified text-to-text trans- former.\n\nSequence level training with recurrent neural networks. Aurelio Marc, Sumit Ranzato, Michael Chopra, Wojciech Auli, Zaremba, 4th International Conference on Learning Representations. San Juan, Puerto RicoConference Track ProceedingsMarc'Aurelio Ranzato, Sumit Chopra, Michael Auli, and Wojciech Zaremba. 2016. Sequence level train- ing with recurrent neural networks. In 4th Inter- national Conference on Learning Representations, ICLR 2016, San Juan, Puerto Rico, May 2-4, 2016, Conference Track Proceedings.\n\nSelf-critical sequence training for image captioning. J Steven, Etienne Rennie, Youssef Marcheret, Jerret Mroueh, Vaibhava Ross, Goel, 10.1109/CVPR.2017.1312017 IEEE Conference on Computer Vision and Pattern Recognition. Honolulu, HI, USASteven J. Rennie, Etienne Marcheret, Youssef Mroueh, Jerret Ross, and Vaibhava Goel. 2017. Self-critical sequence training for image captioning. In 2017 IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017, Honolulu, HI, USA, July 21-26, 2017, pages 1179-1195. IEEE Computer So- ciety.\n\nHinrich Sch\u00fctze, and Iryna Gurevych. 2020. Investigating pretrained language models for graph-to-text generation. F R Leonardo, Martin Ribeiro, Schmitt, Leonardo F. R. Ribeiro, Martin Schmitt, Hinrich Sch\u00fctze, and Iryna Gurevych. 2020. Investigating pretrained language models for graph-to-text gener- ation.\n\nDavid Silver, Lectures on reinforcement learning. David Silver. 2015. Lectures on reinforcement learn- ing. URL: https://www.davidsilver.uk/ teaching/.\n\nReinforcement Learning: An Introduction. Richard S Sutton, Andrew G Barto, Bradford Book, Cambridge, MA, USARichard S. Sutton and Andrew G. Barto. 2018. Rein- forcement Learning: An Introduction. A Bradford Book, Cambridge, MA, USA.\n\nConnecting the dots between mle and rl for sequence prediction. Zhiting Bowen Tan, Zichao Hu, Yang, Ruslan Salakhutdinov, and Eric XingBowen Tan, Zhiting Hu, Zichao Yang, Ruslan Salakhut- dinov, and Eric Xing. 2019. Connecting the dots be- tween mle and rl for sequence prediction.\n\nSimple statistical gradientfollowing algorithms for connectionist reinforcement learning. J Ronald, Williams, Machine learning. 83-4Ronald J Williams. 1992. Simple statistical gradient- following algorithms for connectionist reinforce- ment learning. Machine learning, 8(3-4):229-256.\n\n. Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Clara Patrick Von Platen, Yacine Ma, Julien Jernite, Canwen Plu, Teven Le Xu, Sylvain Scao, Gugger, Mariama DrameThomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pier- ric Cistac, Tim Rault, Remi Louf, Morgan Funtow- icz, Joe Davison, Sam Shleifer, Patrick von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger, Mariama Drame,\n\n. Regen G2t Ce, t5-large 0.543\u00b10.007 0.540\u00b10.007 0.416\u00b10.002 0.691\u00b10.002ReGen G2T.CE t5-large 0.543\u00b10.007 0.540\u00b10.007 0.416\u00b10.002 0.691\u00b10.002\n\n. Regen G2t , t5-large 0.553\u00b10.007 0.550\u00b10.007 0.422\u00b10.002 0.702\u00b10.003ReGen G2T.RL t5-large 0.553\u00b10.007 0.550\u00b10.007 0.422\u00b10.002 0.702\u00b10.003\n\nRegen G2t Ce, ES t5-base (early CE). ReGen G2T.CE.ES t5-base (early CE)\n\nRegen G2t Rl, ES t5-base (early CE). ReGen G2T.RL.ES t5-base (early CE)\n\n. Regen G2t Ce, best t5-base. best CEReGen G2T.CE.best t5-base (best CE)\n\n. Regen G2t Rl, best t5-base. best CEReGen G2T.RL.best t5-base (best CE)\n\n. G2t Rl Regen, Es, early CE) 0.525\u00b10.007 0.521\u00b10.007 0.412\u00b10.002 0.687\u00b10.003meteor t5-baseReGen G2T.RL.ES.meteor t5-base (early CE) 0.525\u00b10.007 0.521\u00b10.007 0.412\u00b10.002 0.687\u00b10.003\n\n. G2t Rl Regen, Best, best CE) 0.527\u00b10.007 0.524\u00b10.007 0.410\u00b10.002 0.686\u00b10.003meteor t5-baseReGen G2T.RL.best.meteor t5-base (best CE) 0.527\u00b10.007 0.524\u00b10.007 0.410\u00b10.002 0.686\u00b10.003\n\nResults means and standard deviations (SD), shown as mean\u00b1SD, for CE and SCST trained models. Table. 10Table 10: Results means and standard deviations (SD), shown as mean\u00b1SD, for CE and SCST trained models\n\nAn example from the processed TEKGEN dataset. The original dataset lacks KG boundaries, which makes it difficult to evaluate T2G systems efficiently. Type Sentence / Graph Source The Pontiac Rageous began and ended its production in 1997 on an assembly line in Detroit, a city in Michigan. Gold Pontiac_Rageous \u2666 productionStartYear \u2666 1997 \u2666 Pontiac_Rageous \u2666 assembly \u2666 Michigan \u2666 Pontiac_Rageous \u2666 assembly \u2666 Detroit \u2666 Pontiac_Rageous \u2666 productionEndYear \u2666 1997 \u2666 Detroit \u2666 type \u2666 City. Michigan3Figure 3: An example from the processed TEKGEN dataset. The original dataset lacks KG boundaries, which makes it difficult to evaluate T2G systems efficiently. Type Sentence / Graph Source The Pontiac Rageous began and ended its production in 1997 on an assembly line in Detroit, a city in Michigan. Gold Pontiac_Rageous \u2666 productionStartYear \u2666 1997 \u2666 Pontiac_Rageous \u2666 assembly \u2666 Michigan \u2666 Pontiac_Rageous \u2666 assembly \u2666 Detroit \u2666 Pontiac_Rageous \u2666 productionEndYear \u2666 1997 \u2666 Detroit \u2666 type \u2666 City_(Michigan)\n\nAfrican Americans are one of the ethnic groups. Abraham A. Ribicoff was married to Ruth Ribicoff. Gold Abraham_A._Ribicoff \u2666 spouse \u2666 \"Ruth Ribicoff\" \u2666 Abraham_A._Ribicoff \u2666 birthPlace \u2666 United_States \u2666 United_States \u2666 ethnicGroup \u2666 African_Americans \u2666 Abraham_A._Ribicoff \u2666 nationality \u2666 United_States Hyp-CE Abraham_A._Ribicoff \u2666 birthPlace \u2666 United_States \u2666 Abraham_A._Ribicoff \u2666 spouse \u2666 \"Ruth Ribicoff\" \u2666 United_States \u2666 ethnicGroup \u2666 African_Americans Hyp-SCST Abraham_A._Ribicoff \u2666 birthPlace \u2666 United_States \u2666 Abraham_A._Ribicoff \u2666 spouse \u2666 \"Ruth Ribicoff\" \u2666 Abraham_A._Ribicoff \u2666 nationality \u2666 American \u2666 United_States \u2666 ethnicGroup \u2666 African_Americans Source Super Capers. 98.0Hyp-CE Pontiac_Rageous \u2666 assembly \u2666 Detroit \u2666 Pontiac_Rageous \u2666 modelYears \u2666 1997 \u2666 Pontiac_Rageous \u2666 modelYears \u2666 1997 \u2666 Detroit \u2666 isPartOf \u2666 Michigan Hyp-SCST Pontiac_Rageous \u2666 assembly \u2666 Detroit \u2666 Pontiac_Rageous \u2666 modelYears \u2666 1997 \u2666 Pontiac_Rageous \u2666 assembly \u2666 Michigan Source In the United States, where Abraham A, Ribicoff was born. Stacy Katzmanis a 98 minute film starring Michael Rooker and Tom Sizemore. Gold Super_Capers \u2666 editing \u2666 Stacy_Katzman \u2666 Super_Capers \u2666 starring \u2666 Michael_Rooker \u2666 Su-per_Capers \u2666 starring \u2666 Tom_Sizemore \u2666 Super_Capers \u2666 runtime |Hyp-CE Pontiac_Rageous \u2666 assembly \u2666 Detroit \u2666 Pontiac_Rageous \u2666 modelYears \u2666 1997 \u2666 Pontiac_Rageous \u2666 modelYears \u2666 1997 \u2666 Detroit \u2666 isPartOf \u2666 Michigan Hyp-SCST Pontiac_Rageous \u2666 assembly \u2666 Detroit \u2666 Pontiac_Rageous \u2666 modelYears \u2666 1997 \u2666 Pontiac_Rageous \u2666 assembly \u2666 Michigan Source In the United States, where Abraham A, Ribicoff was born, African Americans are one of the ethnic groups. Abraham A. Ribicoff was married to Ruth Ribicoff. Gold Abraham_A._Ribicoff \u2666 spouse \u2666 \"Ruth Ribicoff\" \u2666 Abraham_A._Ribicoff \u2666 birthPlace \u2666 United_States \u2666 United_States \u2666 ethnicGroup \u2666 African_Americans \u2666 Abraham_A._Ribicoff \u2666 nationality \u2666 United_States Hyp-CE Abraham_A._Ribicoff \u2666 birthPlace \u2666 United_States \u2666 Abraham_A._Ribicoff \u2666 spouse \u2666 \"Ruth Ribicoff\" \u2666 United_States \u2666 ethnicGroup \u2666 African_Americans Hyp-SCST Abraham_A._Ribicoff \u2666 birthPlace \u2666 United_States \u2666 Abraham_A._Ribicoff \u2666 spouse \u2666 \"Ruth Ribicoff\" \u2666 Abraham_A._Ribicoff \u2666 nationality \u2666 American \u2666 United_States \u2666 ethnicGroup \u2666 African_Americans Source Super Capers, edited by Stacy Katzman, is a 98 minute film starring Michael Rooker and Tom Sizemore. Gold Super_Capers \u2666 editing \u2666 Stacy_Katzman \u2666 Super_Capers \u2666 starring \u2666 Michael_Rooker \u2666 Su- per_Capers \u2666 starring \u2666 Tom_Sizemore \u2666 Super_Capers \u2666 runtime | 98.0\n\nSu-per_Capers \u2666 starring \u2666 Michael_Rooker \u2666 Super_Capers \u2666 editor \u2666 Stacy_Katzman Hyp-SCST Super_Capers \u2666 starring \u2666 Tom_Sizemore \u2666 Super_Capers \u2666 length \u2666 98.0 (minutes) \u2666 Super_Capers \u2666 starring \u2666 Michael_Rooker \u2666 Super_Capers \u2666 editor \u2666 Stacy_Katzman Source Doctor George Cary (1611-1680), Professor of Sacred Theology, lord of the manor of Clovelly. Hyp-CE Super_Capers \u2666 starring \u2666 Tom_Sizemore \u2666 Super_Capers \u2666 timeOut \u2666 \"980.0\"(minutes) \u2666. Devonwas Dean of Exeter between 1663 and 1680 (amongst other duties responsible for the maintenance and decoration of Exeter CathedralHyp-CE Super_Capers \u2666 starring \u2666 Tom_Sizemore \u2666 Super_Capers \u2666 timeOut \u2666 \"980.0\"(minutes) \u2666 Su- per_Capers \u2666 starring \u2666 Michael_Rooker \u2666 Super_Capers \u2666 editor \u2666 Stacy_Katzman Hyp-SCST Super_Capers \u2666 starring \u2666 Tom_Sizemore \u2666 Super_Capers \u2666 length \u2666 98.0 (minutes) \u2666 Super_Capers \u2666 starring \u2666 Michael_Rooker \u2666 Super_Capers \u2666 editor \u2666 Stacy_Katzman Source Doctor George Cary (1611-1680), Professor of Sacred Theology, lord of the manor of Clovelly, Devon, was Dean of Exeter between 1663 and 1680 (amongst other duties responsible for the maintenance and decoration of Exeter Cathedral).\n\n1611-1680) \u2666 position held \u2666 Dean of Exeter \u2666 start time \u2666 01 January 1663 \u2666 date of birth \u2666 00 1611 \u2666 date of. Cary Gold George, death \u2666 00 1680Gold George Cary (1611-1680) \u2666 position held \u2666 Dean of Exeter \u2666 start time \u2666 01 January 1663 \u2666 date of birth \u2666 00 1611 \u2666 date of death \u2666 00 1680\n\n) \u2666 date of birth \u2666 01 January 1611 \u2666 date of death \u2666 01. -Ce George Hyp, Cary, priestHyp-CE George Cary (priest) \u2666 date of birth \u2666 01 January 1611 \u2666 date of death \u2666 01 January 1680\n\npriest) \u2666 position held \u2666 Dean of Exeter \u2666 date of birth \u2666 01 January 1611 \u2666 date of death \u2666 01. -Scst George Hyp, Cary, Hyp-SCST George Cary (priest) \u2666 position held \u2666 Dean of Exeter \u2666 date of birth \u2666 01 January 1611 \u2666 date of death \u2666 01 January 1680\n\nBahamian general election \u2666 point in time \u2666 10 April 1968 \u2666 country \u2666 The Bahamas \u2666 applies to jurisdiction \u2666 The Bahamas Hyp-CE 1968 Bahamian general election \u2666 point in time. Source Early general elections were held in the Bahamas on 10. 10Source Early general elections were held in the Bahamas on 10 April 1968. Gold 1968 Bahamian general election \u2666 point in time \u2666 10 April 1968 \u2666 country \u2666 The Bahamas \u2666 applies to jurisdiction \u2666 The Bahamas Hyp-CE 1968 Bahamian general election \u2666 point in time \u2666 10 April 1968\n\nBahamian general election \u2666 point in time \u2666 10 April 1968 \u2666 country \u2666 The Bahamas Source The school was established on 6 January 1930, by former education minister, CWW Kannangara, who additionally founded two other colleges located in central Ceylon. Gold Kattankudy Central College \u2666 instance of \u2666 School Hyp-CE Government Polytechnic. - Hyp, Scst, Colombo \u2666 inception \u2666 00 1930Hyp-SCST 1968 Bahamian general election \u2666 point in time \u2666 10 April 1968 \u2666 country \u2666 The Bahamas Source The school was established on 6 January 1930, by former education minister, CWW Kannangara, who additionally founded two other colleges located in central Ceylon. Gold Kattankudy Central College \u2666 instance of \u2666 School Hyp-CE Government Polytechnic , Colombo \u2666 inception \u2666 00 1930\n\nFor each source (Text), we show the ground truth (Gold) and system generated hypothesis from the best CE (Hyp-CE) and SCST models (Hyp-SCST). -Scst Government Hyp, Polytechnic, Colombo \u2666 inception \u2666 00 1930 \u2666 instance of \u2666 School Table 11: Few cherry-picked generation for T2G task for WebNLG+ 2020 (top three) and TEKGEN (bottom three). Note that the set of triples in WebNLG+ takes the form x G =. s 1 \u2666p 1 \u2666o 1 ), . . . , (s K \u2666p K \u2666o K )], whereas the same for TEKGEN is of form x G = [s\u2666(p 1 \u2666o 1 ), . . . , (p K \u2666o K )] Type Graph / Sentence Source McVeagh_of_the_South_Seas \u2666 starring \u2666 Harry_Carey_(actor_born_1878) \u2666Hyp-SCST Government Polytechnic , Colombo \u2666 inception \u2666 00 1930 \u2666 instance of \u2666 School Table 11: Few cherry-picked generation for T2G task for WebNLG+ 2020 (top three) and TEKGEN (bottom three). For each source (Text), we show the ground truth (Gold) and system generated hypothesis from the best CE (Hyp-CE) and SCST models (Hyp-SCST). Note that the set of triples in WebNLG+ takes the form x G = [(s 1 \u2666p 1 \u2666o 1 ), . . . , (s K \u2666p K \u2666o K )], whereas the same for TEKGEN is of form x G = [s\u2666(p 1 \u2666o 1 ), . . . , (p K \u2666o K )] Type Graph / Sentence Source McVeagh_of_the_South_Seas \u2666 starring \u2666 Harry_Carey_(actor_born_1878) \u2666\n\nGold Born in 1878, Harry Carey later grew up to write and star in the movie McVeagh of the South Seas. \u2666 Mcveagh_Of_The_South_Seas, Harry_Carey_, McVeagh_of_the_South_Seas \u2666 writer \u2666 Harry_Carey_(actor_born_1878) Gold Born in 1878, Harry Carey later grew up to write and star in the movie McVeagh of the South Seas.\n\nHarry Carey, who was born in 1878, wrote and starred the film of McVeagh of the South Seas. Hyp-CE McVeagh of the South Seas was written by Harry Carey, who was born in 1878. Hyp-SCST McVeagh of the South Seas was written by Harry Carey and starred the actor Harry Carey. Harry Carey, 1878, wrote and appeared in the movie McVeagh of the South Seas. 1878Harry Carey, born in 1878, wrote and appeared in the movie McVeagh of the South Seas. Harry Carey, who was born in 1878, wrote and starred the film of McVeagh of the South Seas. Hyp-CE McVeagh of the South Seas was written by Harry Carey, who was born in 1878. Hyp-SCST McVeagh of the South Seas was written by Harry Carey and starred the actor Harry Carey who was born in 1878.\n\nAleksandr Prudnikov who is 185 cm tall is a member of the youth side of FC Spartak Moscow. The home ground of FC Spartak Moscow is Otkrytiye Arena. Aleksandr Prudnikov is 185.0 cm tall and played for the FC Spartak Moscow at the Otkrytiye Arena. Hyp-CE Aleksandr Prudnikov is 185 cm tall and played for FC Spartak Moscow's youth team at the Otkrytiye Arena. Hyp-SCST Aleksandr Prudnikov is 185 cm tall and played for the youth team of FC. \u2666 Aleksandr_Prudnikov \u2666 Youthclub \u2666 Fc_Spartak_Moscow \u2666 Fc_Spartak_Moscow \u2666 Ground \u2666 Otkrytiye_Arena Gold Aleksandr, Prudnikov, 185cm tall played for FC Spartak Moscow's youth team. FC Spartak Moscow is based in the Otkrytiye Arena. Spartak Moscow whose home ground is the Otkrytiye ArenaSource Aleksandr_Prudnikov \u2666 height \u2666 185.0 (centimetres) \u2666 Aleksandr_Prudnikov \u2666 youthclub \u2666 FC_Spartak_Moscow \u2666 FC_Spartak_Moscow \u2666 ground \u2666 Otkrytiye_Arena Gold Aleksandr Prudnikov, 185cm tall played for FC Spartak Moscow's youth team. FC Spartak Moscow is based in the Otkrytiye Arena. Aleksandr Prudnikov who is 185 cm tall is a member of the youth side of FC Spartak Moscow. The home ground of FC Spartak Moscow is Otkrytiye Arena. Aleksandr Prudnikov is 185.0 cm tall and played for the FC Spartak Moscow at the Otkrytiye Arena. Hyp-CE Aleksandr Prudnikov is 185 cm tall and played for FC Spartak Moscow's youth team at the Otkrytiye Arena. Hyp-SCST Aleksandr Prudnikov is 185 cm tall and played for the youth team of FC Spartak Moscow whose home ground is the Otkrytiye Arena.\n\n\u2666 Baku_Turkish_Martyrs'_Memorial \u2666 location \u2666 Azerbaijan Gold The Native name of the Baku Turkish Martyrs' Memorial is \"T\u00fcrk\u015eehitleri An\u0131t\u0131\" which is located in Azerbaijan. The native name of the Baku Turkish Martyrs' Memorial is T\u00fcrk\u015eehitleri An\u0131t\u0131 located in Azerbaijan. The native name for the Baku Turkish Martyrs' Memorial is T\u00fcrk\u015eehitleri An\u0131t\u0131. Source Baku_Turkish_Martyrs&apos;_Memorial \u2666 Nativename, \u2666 &quot;t\u00fcrk\u015fehitleri An\u0131t\u0131, Hyp-CE The native name of the Baku Turkish Martyrs' Memorial in Azerbaijan is T\u00fcrk\u015eehitleri An\u0131t\u0131. Hyp-SCST The Baku Turkish Martyrs' Memorial is located in Azerbaijan and is known locally as T\u00fcrk\u015eehitleri An\u0131t\u0131. Azerbaijanwhich is located in BakuSource Baku_Turkish_Martyrs'_Memorial \u2666 nativeName \u2666 \"T\u00fcrk\u015eehitleri An\u0131t\u0131\" \u2666 Baku_Turkish_Martyrs'_Memorial \u2666 location \u2666 Azerbaijan Gold The Native name of the Baku Turkish Martyrs' Memorial is \"T\u00fcrk\u015eehitleri An\u0131t\u0131\" which is located in Azerbaijan. The native name of the Baku Turkish Martyrs' Memorial is T\u00fcrk\u015eehitleri An\u0131t\u0131 located in Azerbaijan. The native name for the Baku Turkish Martyrs' Memorial is T\u00fcrk\u015eehitleri An\u0131t\u0131, which is located in Baku, Azerbaijan. Hyp-CE The native name of the Baku Turkish Martyrs' Memorial in Azerbaijan is T\u00fcrk\u015eehitleri An\u0131t\u0131. Hyp-SCST The Baku Turkish Martyrs' Memorial is located in Azerbaijan and is known locally as T\u00fcrk\u015eehitleri An\u0131t\u0131.\n\nSource John Banister (anatomist) \u2666 occupation \u2666 Surgeon \u2666 date of birth \u2666 01 January 1533 \u2666 date of death \u2666 01 January 1610 Gold John Banister (1533-1610) was an English anatomist, surgeon and teacher. Hyp-CE John Banister (1533-1610) was an English surgeon. Hyp-SCST John Banister (1533-1610) was an English surgeon and anatomist. Source John Banister (anatomist) \u2666 occupation \u2666 Surgeon \u2666 date of birth \u2666 01 January 1533 \u2666 date of death \u2666 01 January 1610 Gold John Banister (1533-1610) was an English anatomist, surgeon and teacher. Hyp-CE John Banister (1533-1610) was an English surgeon. Hyp-SCST John Banister (1533-1610) was an English surgeon and anatomist.\n\nTV) \u2666 country \u2666 United States \u2666 instance of \u2666 Television station Gold WNPT, virtual channel 8 (VHF digital channel 7), is a PBS member television station licensed to. Wnpt Source, Nashville, Tennessee, United StatesSource WNPT (TV) \u2666 country \u2666 United States \u2666 instance of \u2666 Television station Gold WNPT, virtual channel 8 (VHF digital channel 7), is a PBS member television station licensed to Nashville, Tennessee, United States.\n\nUHF digital channel 15), is a Fox-affiliated television station licensed to Portland. -Ce Hyp, Wnpt, 3Oregon, United StatesHyp-CE WNPT, virtual channel 3 (UHF digital channel 15), is a Fox-affiliated television station licensed to Portland, Oregon, United States.\n\nUHF digital channel 16), is a Public Broadcasting Service (PBS) member television station licensed to Portland. -Scst Hyp, Wnpt, 4Oregon, United StatesHyp-SCST WNPT, virtual channel 4 (UHF digital channel 16), is a Public Broadcasting Service (PBS) member television station licensed to Portland, Oregon, United States.\n\nGold Our Lady of the Presentation Cathedral, Natal was inaugurated on November 21, 1988, and is located in the district of Cidade Alta in Natal, capital of the Brazilian state of Rio Grande do Norte. Hyp-CE Our Lady of the Presentation Cathedral, Natal was built in 1988. Hyp-SCST Our Lady of the Presentation Cathedral. Source Our Lady of the Presentation Cathedral, Natal \u2666 inception \u2666 21 November. Source Our Lady of the Presentation Cathedral, Natal \u2666 inception \u2666 21 November 1988 Gold Our Lady of the Presentation Cathedral, Natal was inaugurated on November 21, 1988, and is located in the district of Cidade Alta in Natal, capital of the Brazilian state of Rio Grande do Norte. Hyp-CE Our Lady of the Presentation Cathedral, Natal was built in 1988. Hyp-SCST Our Lady of the Presentation Cathedral, Natal was consecrated on 21 November 1988.\n\nFor each source (Graph), we show the ground truth (Gold) and system generated hypothesis from the best CE (Hyp-CE) and SCST models (Hyp-SCST). Table 12: Few cherry-picked generation for G2T task for WebNLG+ 2020 (top three) and TEKGEN (bottom three). Note that the set of triples in WebNLG+ 2020 takes the form x G =. s 1 \u2666p 1 \u2666o 1 ), . . . , (s K \u2666p K \u2666o K )], whereas the same for TEKGEN is of form x G = [s\u2666(p 1 \u2666o 1 ), . . . , (p K \u2666o K )Table 12: Few cherry-picked generation for G2T task for WebNLG+ 2020 (top three) and TEKGEN (bottom three). For each source (Graph), we show the ground truth (Gold) and system generated hypothesis from the best CE (Hyp-CE) and SCST models (Hyp-SCST). Note that the set of triples in WebNLG+ 2020 takes the form x G = [(s 1 \u2666p 1 \u2666o 1 ), . . . , (s K \u2666p K \u2666o K )], whereas the same for TEKGEN is of form x G = [s\u2666(p 1 \u2666o 1 ), . . . , (p K \u2666o K )]\n", "annotations": {"author": "[{\"end\":311,\"start\":222},{\"end\":378,\"start\":312},{\"end\":465,\"start\":379},{\"end\":530,\"start\":466}]", "publisher": "[{\"end\":144,\"start\":103},{\"end\":833,\"start\":792}]", "author_last_name": "[{\"end\":237,\"start\":231},{\"end\":323,\"start\":318},{\"end\":390,\"start\":384},{\"end\":475,\"start\":472}]", "author_first_name": "[{\"end\":228,\"start\":222},{\"end\":230,\"start\":229},{\"end\":317,\"start\":312},{\"end\":383,\"start\":379},{\"end\":471,\"start\":466}]", "author_affiliation": "[{\"end\":310,\"start\":258},{\"end\":377,\"start\":325},{\"end\":464,\"start\":412},{\"end\":529,\"start\":477}]", "title": "[{\"end\":102,\"start\":1},{\"end\":632,\"start\":531}]", "venue": "[{\"end\":720,\"start\":634}]", "abstract": "[{\"end\":1896,\"start\":863}]", "bib_ref": "[{\"end\":2463,\"start\":2441},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2513,\"start\":2492},{\"end\":2543,\"start\":2518},{\"end\":2864,\"start\":2833},{\"end\":4189,\"start\":4166},{\"end\":4325,\"start\":4303},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":6128,\"start\":6103},{\"end\":6162,\"start\":6130},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":6190,\"start\":6175},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":6669,\"start\":6648},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":6843,\"start\":6822},{\"end\":7692,\"start\":7670},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":8209,\"start\":8192},{\"end\":8607,\"start\":8590},{\"end\":8626,\"start\":8607},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":9125,\"start\":9109},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":12935,\"start\":12911},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":12948,\"start\":12935},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":16654,\"start\":16631},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":17993,\"start\":17972},{\"end\":18415,\"start\":18397},{\"end\":19051,\"start\":18990},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":19927,\"start\":19906},{\"end\":20110,\"start\":20079},{\"end\":21328,\"start\":21298},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":23058,\"start\":23036},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":23078,\"start\":23058},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":35918,\"start\":35902},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":36026,\"start\":36006},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":36145,\"start\":36123},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":36179,\"start\":36162},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":36199,\"start\":36179}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":36199,\"start\":35882},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":37866,\"start\":36200},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":38457,\"start\":37867},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":38644,\"start\":38458},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":38790,\"start\":38645},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":44533,\"start\":38791},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":44859,\"start\":44534},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":45586,\"start\":44860},{\"attributes\":{\"id\":\"tab_9\",\"type\":\"table\"},\"end\":46116,\"start\":45587},{\"attributes\":{\"id\":\"tab_10\",\"type\":\"table\"},\"end\":46403,\"start\":46117},{\"attributes\":{\"id\":\"tab_11\",\"type\":\"table\"},\"end\":46703,\"start\":46404},{\"attributes\":{\"id\":\"tab_12\",\"type\":\"table\"},\"end\":46840,\"start\":46704}]", "paragraph": "[{\"end\":2261,\"start\":1912},{\"end\":2711,\"start\":2263},{\"end\":3582,\"start\":2713},{\"end\":3914,\"start\":3584},{\"end\":5620,\"start\":3916},{\"end\":6874,\"start\":5622},{\"end\":7802,\"start\":6876},{\"end\":8556,\"start\":7819},{\"end\":8770,\"start\":8558},{\"end\":9035,\"start\":8772},{\"end\":9504,\"start\":9037},{\"end\":9818,\"start\":9506},{\"end\":10341,\"start\":9829},{\"end\":10641,\"start\":10382},{\"end\":10801,\"start\":10643},{\"end\":11058,\"start\":10842},{\"end\":11408,\"start\":11060},{\"end\":11723,\"start\":11473},{\"end\":12311,\"start\":11725},{\"end\":12477,\"start\":12313},{\"end\":13452,\"start\":12504},{\"end\":13729,\"start\":13719},{\"end\":13969,\"start\":13731},{\"end\":14235,\"start\":13971},{\"end\":15734,\"start\":14278},{\"end\":16360,\"start\":15893},{\"end\":16863,\"start\":16407},{\"end\":18076,\"start\":16920},{\"end\":18246,\"start\":18078},{\"end\":19539,\"start\":18269},{\"end\":19978,\"start\":19541},{\"end\":22039,\"start\":19991},{\"end\":22694,\"start\":22041},{\"end\":23764,\"start\":22706},{\"end\":24957,\"start\":23766},{\"end\":25386,\"start\":24959},{\"end\":25916,\"start\":25388},{\"end\":26378,\"start\":25918},{\"end\":28205,\"start\":26380},{\"end\":28814,\"start\":28220},{\"end\":29794,\"start\":28816},{\"end\":31099,\"start\":29810},{\"end\":31786,\"start\":31128},{\"end\":32099,\"start\":31820},{\"end\":32762,\"start\":32101},{\"end\":32992,\"start\":32764},{\"end\":33110,\"start\":32994},{\"end\":33386,\"start\":33112},{\"end\":33455,\"start\":33417},{\"end\":33702,\"start\":33457},{\"end\":33888,\"start\":33704},{\"end\":34481,\"start\":33911},{\"end\":34742,\"start\":34542},{\"end\":35494,\"start\":34798},{\"end\":35653,\"start\":35536},{\"end\":35881,\"start\":35684}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":10381,\"start\":10342},{\"attributes\":{\"id\":\"formula_1\"},\"end\":10841,\"start\":10802},{\"attributes\":{\"id\":\"formula_2\"},\"end\":11472,\"start\":11409},{\"attributes\":{\"id\":\"formula_3\"},\"end\":13718,\"start\":13453},{\"attributes\":{\"id\":\"formula_4\"},\"end\":14277,\"start\":14236},{\"attributes\":{\"id\":\"formula_5\"},\"end\":15892,\"start\":15735},{\"attributes\":{\"id\":\"formula_6\"},\"end\":16406,\"start\":16361},{\"attributes\":{\"id\":\"formula_7\"},\"end\":16919,\"start\":16864}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":21368,\"start\":21338},{\"end\":23891,\"start\":23888},{\"attributes\":{\"ref_id\":\"tab_10\"},\"end\":33928,\"start\":33914},{\"attributes\":{\"ref_id\":\"tab_10\"},\"end\":34053,\"start\":34046},{\"attributes\":{\"ref_id\":\"tab_11\"},\"end\":34284,\"start\":34277}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1910,\"start\":1898},{\"attributes\":{\"n\":\"2\"},\"end\":7817,\"start\":7805},{\"attributes\":{\"n\":\"3\"},\"end\":9827,\"start\":9821},{\"attributes\":{\"n\":\"3.1\"},\"end\":12502,\"start\":12480},{\"attributes\":{\"n\":\"4\"},\"end\":18267,\"start\":18249},{\"attributes\":{\"n\":\"4.1\"},\"end\":19989,\"start\":19981},{\"attributes\":{\"n\":\"5\"},\"end\":22704,\"start\":22697},{\"end\":28218,\"start\":28208},{\"attributes\":{\"n\":\"6\"},\"end\":29808,\"start\":29797},{\"attributes\":{\"n\":\"7\"},\"end\":31126,\"start\":31102},{\"end\":31799,\"start\":31789},{\"end\":31818,\"start\":31802},{\"end\":33415,\"start\":33389},{\"end\":33909,\"start\":33891},{\"end\":34540,\"start\":34484},{\"end\":34796,\"start\":34745},{\"end\":35534,\"start\":35497},{\"end\":35682,\"start\":35656},{\"end\":37877,\"start\":37868},{\"end\":38468,\"start\":38459},{\"end\":38655,\"start\":38646},{\"end\":44870,\"start\":44861},{\"end\":45597,\"start\":45588},{\"end\":46127,\"start\":46118},{\"end\":46414,\"start\":46405},{\"end\":46714,\"start\":46705}]", "table": "[{\"end\":37866,\"start\":36649},{\"end\":38457,\"start\":38241},{\"end\":44533,\"start\":40140},{\"end\":44859,\"start\":44583},{\"end\":45586,\"start\":45115},{\"end\":46116,\"start\":45804},{\"end\":46403,\"start\":46240},{\"end\":46703,\"start\":46583},{\"end\":46840,\"start\":46790}]", "figure_caption": "[{\"end\":36199,\"start\":35884},{\"end\":36649,\"start\":36202},{\"end\":38241,\"start\":37879},{\"end\":38644,\"start\":38470},{\"end\":38790,\"start\":38657},{\"end\":40140,\"start\":38793},{\"end\":44583,\"start\":44536},{\"end\":45115,\"start\":44872},{\"end\":45804,\"start\":45599},{\"end\":46240,\"start\":46129},{\"end\":46583,\"start\":46416},{\"end\":46790,\"start\":46716}]", "figure_ref": "[{\"end\":4427,\"start\":4421},{\"end\":4707,\"start\":4699},{\"end\":12390,\"start\":12384},{\"end\":13764,\"start\":13756},{\"end\":22026,\"start\":22020},{\"end\":35693,\"start\":35687}]", "bib_author_first_name": "[{\"end\":46920,\"start\":46918},{\"end\":46932,\"start\":46929},{\"end\":46935,\"start\":46933},{\"end\":46945,\"start\":46942},{\"end\":47804,\"start\":47798},{\"end\":47820,\"start\":47813},{\"end\":47835,\"start\":47828},{\"end\":48003,\"start\":47999},{\"end\":48497,\"start\":48492},{\"end\":48510,\"start\":48506},{\"end\":48524,\"start\":48520},{\"end\":48543,\"start\":48534},{\"end\":48555,\"start\":48549},{\"end\":48571,\"start\":48564},{\"end\":48585,\"start\":48580},{\"end\":48595,\"start\":48592},{\"end\":48605,\"start\":48600},{\"end\":48607,\"start\":48606},{\"end\":48894,\"start\":48887},{\"end\":48906,\"start\":48901},{\"end\":48923,\"start\":48916},{\"end\":48940,\"start\":48932},{\"end\":49397,\"start\":49396},{\"end\":49413,\"start\":49406},{\"end\":49429,\"start\":49422},{\"end\":49447,\"start\":49441},{\"end\":49464,\"start\":49456},{\"end\":49999,\"start\":49998},{\"end\":50001,\"start\":50000},{\"end\":50018,\"start\":50012},{\"end\":50199,\"start\":50194},{\"end\":50395,\"start\":50388},{\"end\":50397,\"start\":50396},{\"end\":50412,\"start\":50406},{\"end\":50414,\"start\":50413},{\"end\":50652,\"start\":50645},{\"end\":50670,\"start\":50664},{\"end\":50955,\"start\":50954},{\"end\":51158,\"start\":51152},{\"end\":51173,\"start\":51165},{\"end\":51187,\"start\":51181},{\"end\":51200,\"start\":51194},{\"end\":51218,\"start\":51211},{\"end\":51236,\"start\":51229},{\"end\":51249,\"start\":51242},{\"end\":51261,\"start\":51258},{\"end\":51273,\"start\":51269},{\"end\":51286,\"start\":51280},{\"end\":51301,\"start\":51298},{\"end\":51314,\"start\":51311},{\"end\":51330,\"start\":51325},{\"end\":51357,\"start\":51351},{\"end\":51368,\"start\":51362},{\"end\":51384,\"start\":51378},{\"end\":51395,\"start\":51390},{\"end\":51398,\"start\":51396},{\"end\":51410,\"start\":51403},{\"end\":51738,\"start\":51733},{\"end\":51742,\"start\":51739},{\"end\":51881,\"start\":51876},{\"end\":51885,\"start\":51882},{\"end\":52020,\"start\":52015},{\"end\":52024,\"start\":52021},{\"end\":52093,\"start\":52088},{\"end\":52097,\"start\":52094},{\"end\":52168,\"start\":52163},{\"end\":52172,\"start\":52169},{\"end\":52242,\"start\":52237},{\"end\":52246,\"start\":52243},{\"end\":52314,\"start\":52311},{\"end\":52317,\"start\":52315},{\"end\":52496,\"start\":52493},{\"end\":52499,\"start\":52497},{\"end\":57706,\"start\":57702},{\"end\":57949,\"start\":57939},{\"end\":58173,\"start\":58161},{\"end\":59175,\"start\":59174},{\"end\":59758,\"start\":59742},{\"end\":60956,\"start\":60955},{\"end\":61446,\"start\":61441},{\"end\":63774,\"start\":63768},{\"end\":63846,\"start\":63825},{\"end\":65616,\"start\":65612},{\"end\":65966,\"start\":65963},{\"end\":66259,\"start\":66254}]", "bib_author_last_name": "[{\"end\":46927,\"start\":46921},{\"end\":46940,\"start\":46936},{\"end\":46948,\"start\":46946},{\"end\":46957,\"start\":46950},{\"end\":47811,\"start\":47805},{\"end\":47826,\"start\":47821},{\"end\":47842,\"start\":47836},{\"end\":48011,\"start\":48004},{\"end\":48504,\"start\":48498},{\"end\":48518,\"start\":48511},{\"end\":48532,\"start\":48525},{\"end\":48547,\"start\":48544},{\"end\":48562,\"start\":48556},{\"end\":48578,\"start\":48572},{\"end\":48590,\"start\":48586},{\"end\":48598,\"start\":48596},{\"end\":48611,\"start\":48608},{\"end\":48899,\"start\":48895},{\"end\":48914,\"start\":48907},{\"end\":48930,\"start\":48924},{\"end\":48945,\"start\":48941},{\"end\":48954,\"start\":48947},{\"end\":49404,\"start\":49398},{\"end\":49420,\"start\":49414},{\"end\":49439,\"start\":49430},{\"end\":49454,\"start\":49448},{\"end\":49469,\"start\":49465},{\"end\":49475,\"start\":49471},{\"end\":50010,\"start\":50002},{\"end\":50026,\"start\":50019},{\"end\":50035,\"start\":50028},{\"end\":50206,\"start\":50200},{\"end\":50404,\"start\":50398},{\"end\":50420,\"start\":50415},{\"end\":50662,\"start\":50653},{\"end\":50673,\"start\":50671},{\"end\":50679,\"start\":50675},{\"end\":50962,\"start\":50956},{\"end\":50972,\"start\":50964},{\"end\":51163,\"start\":51159},{\"end\":51179,\"start\":51174},{\"end\":51192,\"start\":51188},{\"end\":51209,\"start\":51201},{\"end\":51227,\"start\":51219},{\"end\":51240,\"start\":51237},{\"end\":51256,\"start\":51250},{\"end\":51267,\"start\":51262},{\"end\":51278,\"start\":51274},{\"end\":51296,\"start\":51287},{\"end\":51309,\"start\":51302},{\"end\":51323,\"start\":51315},{\"end\":51349,\"start\":51331},{\"end\":51360,\"start\":51358},{\"end\":51376,\"start\":51369},{\"end\":51388,\"start\":51385},{\"end\":51401,\"start\":51399},{\"end\":51415,\"start\":51411},{\"end\":51423,\"start\":51417},{\"end\":51745,\"start\":51743},{\"end\":52027,\"start\":52025},{\"end\":52100,\"start\":52098},{\"end\":52175,\"start\":52173},{\"end\":52249,\"start\":52247},{\"end\":52323,\"start\":52318},{\"end\":52327,\"start\":52325},{\"end\":52505,\"start\":52500},{\"end\":52511,\"start\":52507},{\"end\":57718,\"start\":57707},{\"end\":57953,\"start\":57950},{\"end\":57959,\"start\":57955},{\"end\":58177,\"start\":58174},{\"end\":58183,\"start\":58179},{\"end\":59179,\"start\":59176},{\"end\":59185,\"start\":59181},{\"end\":59762,\"start\":59759},{\"end\":59775,\"start\":59764},{\"end\":60982,\"start\":60957},{\"end\":60996,\"start\":60984},{\"end\":61452,\"start\":61447},{\"end\":62457,\"start\":62342},{\"end\":62468,\"start\":62459},{\"end\":63823,\"start\":63775},{\"end\":63852,\"start\":63847},{\"end\":65623,\"start\":65617},{\"end\":65970,\"start\":65967},{\"end\":65976,\"start\":65972},{\"end\":66263,\"start\":66260},{\"end\":66269,\"start\":66265}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":218974214},\"end\":47741,\"start\":46842},{\"attributes\":{\"id\":\"b1\"},\"end\":47956,\"start\":47743},{\"attributes\":{\"doi\":\"10.18653/v1/W17-4770\",\"id\":\"b2\",\"matched_paper_id\":12942757},\"end\":48407,\"start\":47958},{\"attributes\":{\"id\":\"b3\"},\"end\":48829,\"start\":48409},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":7147309},\"end\":49340,\"start\":48831},{\"attributes\":{\"doi\":\"10.1109/CVPR.2017.131\",\"id\":\"b5\",\"matched_paper_id\":206594923},\"end\":49882,\"start\":49342},{\"attributes\":{\"id\":\"b6\"},\"end\":50192,\"start\":49884},{\"attributes\":{\"id\":\"b7\"},\"end\":50345,\"start\":50194},{\"attributes\":{\"id\":\"b8\"},\"end\":50579,\"start\":50347},{\"attributes\":{\"id\":\"b9\"},\"end\":50862,\"start\":50581},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":2332513},\"end\":51148,\"start\":50864},{\"attributes\":{\"id\":\"b11\"},\"end\":51729,\"start\":51150},{\"attributes\":{\"doi\":\"t5-large 0.543\u00b10.007 0.540\u00b10.007 0.416\u00b10.002 0.691\u00b10.002\",\"id\":\"b12\"},\"end\":51872,\"start\":51731},{\"attributes\":{\"doi\":\"t5-large 0.553\u00b10.007 0.550\u00b10.007 0.422\u00b10.002 0.702\u00b10.003\",\"id\":\"b13\"},\"end\":52013,\"start\":51874},{\"attributes\":{\"id\":\"b14\"},\"end\":52086,\"start\":52015},{\"attributes\":{\"id\":\"b15\"},\"end\":52159,\"start\":52088},{\"attributes\":{\"id\":\"b16\"},\"end\":52233,\"start\":52161},{\"attributes\":{\"id\":\"b17\"},\"end\":52307,\"start\":52235},{\"attributes\":{\"doi\":\"early CE) 0.525\u00b10.007 0.521\u00b10.007 0.412\u00b10.002 0.687\u00b10.003\",\"id\":\"b18\"},\"end\":52489,\"start\":52309},{\"attributes\":{\"doi\":\"best CE) 0.527\u00b10.007 0.524\u00b10.007 0.410\u00b10.002 0.686\u00b10.003\",\"id\":\"b19\"},\"end\":52673,\"start\":52491},{\"attributes\":{\"id\":\"b20\"},\"end\":52880,\"start\":52675},{\"attributes\":{\"id\":\"b21\"},\"end\":53888,\"start\":52882},{\"attributes\":{\"doi\":\"98.0\",\"id\":\"b22\"},\"end\":56420,\"start\":53890},{\"attributes\":{\"id\":\"b23\"},\"end\":57588,\"start\":56422},{\"attributes\":{\"doi\":\"death \u2666 00 1680\",\"id\":\"b24\"},\"end\":57879,\"start\":57590},{\"attributes\":{\"id\":\"b25\"},\"end\":58062,\"start\":57881},{\"attributes\":{\"id\":\"b26\"},\"end\":58315,\"start\":58064},{\"attributes\":{\"id\":\"b27\"},\"end\":58834,\"start\":58317},{\"attributes\":{\"doi\":\"Colombo \u2666 inception \u2666 00 1930\",\"id\":\"b28\"},\"end\":59598,\"start\":58836},{\"attributes\":{\"id\":\"b29\"},\"end\":60850,\"start\":59600},{\"attributes\":{\"id\":\"b30\"},\"end\":61167,\"start\":60852},{\"attributes\":{\"id\":\"b31\"},\"end\":61901,\"start\":61169},{\"attributes\":{\"id\":\"b32\"},\"end\":63414,\"start\":61903},{\"attributes\":{\"id\":\"b33\"},\"end\":64778,\"start\":63416},{\"attributes\":{\"id\":\"b34\"},\"end\":65443,\"start\":64780},{\"attributes\":{\"id\":\"b35\"},\"end\":65875,\"start\":65445},{\"attributes\":{\"id\":\"b36\"},\"end\":66140,\"start\":65877},{\"attributes\":{\"id\":\"b37\"},\"end\":66461,\"start\":66142},{\"attributes\":{\"id\":\"b38\"},\"end\":67311,\"start\":66463},{\"attributes\":{\"id\":\"b39\"},\"end\":68199,\"start\":67313}]", "bib_title": "[{\"end\":46916,\"start\":46842},{\"end\":47997,\"start\":47958},{\"end\":48885,\"start\":48831},{\"end\":49394,\"start\":49342},{\"end\":50952,\"start\":50864},{\"end\":52767,\"start\":52675},{\"end\":53170,\"start\":52882},{\"end\":54571,\"start\":53890},{\"end\":56774,\"start\":56422},{\"end\":58492,\"start\":58317},{\"end\":59740,\"start\":59600},{\"end\":61439,\"start\":61169},{\"end\":63766,\"start\":63416},{\"end\":66782,\"start\":66463},{\"end\":67454,\"start\":67313}]", "bib_author": "[{\"end\":46929,\"start\":46918},{\"end\":46942,\"start\":46929},{\"end\":46950,\"start\":46942},{\"end\":46959,\"start\":46950},{\"end\":47813,\"start\":47798},{\"end\":47828,\"start\":47813},{\"end\":47844,\"start\":47828},{\"end\":48013,\"start\":47999},{\"end\":48506,\"start\":48492},{\"end\":48520,\"start\":48506},{\"end\":48534,\"start\":48520},{\"end\":48549,\"start\":48534},{\"end\":48564,\"start\":48549},{\"end\":48580,\"start\":48564},{\"end\":48592,\"start\":48580},{\"end\":48600,\"start\":48592},{\"end\":48613,\"start\":48600},{\"end\":48901,\"start\":48887},{\"end\":48916,\"start\":48901},{\"end\":48932,\"start\":48916},{\"end\":48947,\"start\":48932},{\"end\":48956,\"start\":48947},{\"end\":49406,\"start\":49396},{\"end\":49422,\"start\":49406},{\"end\":49441,\"start\":49422},{\"end\":49456,\"start\":49441},{\"end\":49471,\"start\":49456},{\"end\":49477,\"start\":49471},{\"end\":50012,\"start\":49998},{\"end\":50028,\"start\":50012},{\"end\":50037,\"start\":50028},{\"end\":50208,\"start\":50194},{\"end\":50406,\"start\":50388},{\"end\":50422,\"start\":50406},{\"end\":50664,\"start\":50645},{\"end\":50675,\"start\":50664},{\"end\":50681,\"start\":50675},{\"end\":50964,\"start\":50954},{\"end\":50974,\"start\":50964},{\"end\":51165,\"start\":51152},{\"end\":51181,\"start\":51165},{\"end\":51194,\"start\":51181},{\"end\":51211,\"start\":51194},{\"end\":51229,\"start\":51211},{\"end\":51242,\"start\":51229},{\"end\":51258,\"start\":51242},{\"end\":51269,\"start\":51258},{\"end\":51280,\"start\":51269},{\"end\":51298,\"start\":51280},{\"end\":51311,\"start\":51298},{\"end\":51325,\"start\":51311},{\"end\":51351,\"start\":51325},{\"end\":51362,\"start\":51351},{\"end\":51378,\"start\":51362},{\"end\":51390,\"start\":51378},{\"end\":51403,\"start\":51390},{\"end\":51417,\"start\":51403},{\"end\":51425,\"start\":51417},{\"end\":51747,\"start\":51733},{\"end\":51888,\"start\":51876},{\"end\":52029,\"start\":52015},{\"end\":52102,\"start\":52088},{\"end\":52177,\"start\":52163},{\"end\":52251,\"start\":52237},{\"end\":52325,\"start\":52311},{\"end\":52329,\"start\":52325},{\"end\":52507,\"start\":52493},{\"end\":52513,\"start\":52507},{\"end\":57720,\"start\":57702},{\"end\":57955,\"start\":57939},{\"end\":57961,\"start\":57955},{\"end\":58179,\"start\":58161},{\"end\":58185,\"start\":58179},{\"end\":59181,\"start\":59174},{\"end\":59187,\"start\":59181},{\"end\":59764,\"start\":59742},{\"end\":59777,\"start\":59764},{\"end\":60984,\"start\":60955},{\"end\":60998,\"start\":60984},{\"end\":61454,\"start\":61441},{\"end\":62459,\"start\":62342},{\"end\":62470,\"start\":62459},{\"end\":63825,\"start\":63768},{\"end\":63854,\"start\":63825},{\"end\":65625,\"start\":65612},{\"end\":65972,\"start\":65963},{\"end\":65978,\"start\":65972},{\"end\":66265,\"start\":66254},{\"end\":66271,\"start\":66265}]", "bib_venue": "[{\"end\":47315,\"start\":47137},{\"end\":48157,\"start\":48094},{\"end\":49035,\"start\":49014},{\"end\":49580,\"start\":49563},{\"end\":56874,\"start\":56869},{\"end\":64077,\"start\":64067},{\"end\":47135,\"start\":46959},{\"end\":47796,\"start\":47743},{\"end\":48092,\"start\":48033},{\"end\":48490,\"start\":48409},{\"end\":49012,\"start\":48956},{\"end\":49561,\"start\":49498},{\"end\":49996,\"start\":49884},{\"end\":50242,\"start\":50208},{\"end\":50386,\"start\":50347},{\"end\":50643,\"start\":50581},{\"end\":50990,\"start\":50974},{\"end\":52050,\"start\":52029},{\"end\":52123,\"start\":52102},{\"end\":52774,\"start\":52769},{\"end\":53369,\"start\":53172},{\"end\":54916,\"start\":54577},{\"end\":56867,\"start\":56776},{\"end\":57700,\"start\":57590},{\"end\":57937,\"start\":57881},{\"end\":58159,\"start\":58064},{\"end\":58555,\"start\":58494},{\"end\":59172,\"start\":58836},{\"end\":59936,\"start\":59777},{\"end\":60953,\"start\":60852},{\"end\":61517,\"start\":61454},{\"end\":62340,\"start\":61903},{\"end\":64065,\"start\":63854},{\"end\":65110,\"start\":64780},{\"end\":65610,\"start\":65445},{\"end\":65961,\"start\":65877},{\"end\":66252,\"start\":66142},{\"end\":66862,\"start\":66784},{\"end\":67562,\"start\":67456}]"}}}, "year": 2023, "month": 12, "day": 17}