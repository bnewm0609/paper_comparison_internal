{"id": 201645162, "updated": "2023-10-06 23:51:42.977", "metadata": {"title": "AdvHat: Real-world adversarial attack on ArcFace Face ID system", "authors": "[{\"first\":\"Stepan\",\"last\":\"Komkov\",\"middle\":[]},{\"first\":\"Aleksandr\",\"last\":\"Petiushko\",\"middle\":[]}]", "venue": "2020 25th International Conference on Pattern Recognition (ICPR)", "journal": null, "publication_date": {"year": 2019, "month": null, "day": null}, "abstract": "In this paper we propose a novel easily reproducible technique to attack the best public Face ID system ArcFace in different shooting conditions. To create an attack, we print the rectangular paper sticker on a common color printer and put it on the hat. The adversarial sticker is prepared with a novel algorithm for off-plane transformations of the image which imitates sticker location on the hat. Such an approach confuses the state-of-the-art public Face ID model LResNet100E-IR, ArcFace@ms1m-refine-v2 and is transferable to other Face ID models.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "1908.08705", "mag": "2969664989", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/icpr/KomkovP20", "doi": "10.1109/icpr48806.2021.9412236"}}, "content": {"source": {"pdf_hash": "c2a8180671764928b68af7089d8192cadc1f162a", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/1908.08705v1.pdf\"]", "oa_url_match": true, "oa_info": {"license": null, "open_access_url": "http://arxiv.org/pdf/1908.08705", "status": "GREEN"}}, "grobid": {"id": "28895ec8323c875c2592e69a3f5e108dfad4fb44", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/c2a8180671764928b68af7089d8192cadc1f162a.txt", "contents": "\nADVHAT: REAL-WORLD ADVERSARIAL ATTACK ON ARCFACE FACE ID SYSTEM\n\n\nStepan Komkov komkov.stepan@huawei.com \nLomonosov Moscow State University\nMaTIS Chair\n\nIntelligent Systems Lab\nHuawei Moscow Research Center\n\n\nAleksandr Petiushko petyushko.alexander1@huawei.com \nLomonosov Moscow State University\nMaTIS Chair\n\nIntelligent Systems Lab\nHuawei Moscow Research Center\n\n\nADVHAT: REAL-WORLD ADVERSARIAL ATTACK ON ARCFACE FACE ID SYSTEM\nIndex Terms-real-worldadversarial attacksFace IDArcFace\nIn this paper we propose a novel easily reproducible technique to attack the best public Face ID system ArcFace in different shooting conditions. To create an attack, we print the rectangular paper sticker on a common color printer and put it on the hat. The adversarial sticker is prepared with a novel algorithm for off-plane transformations of the image which imitates sticker location on the hat. Such an approach confuses the state-of-the-art public Face ID model LResNet100E-IR, ArcFace@ms1m-refine-v2 and is transferable to other Face ID models.\n\nINTRODUCTION\n\nLast years face recognition systems based on deep learning and massive training data provided a very high level of recognition which outperforms human level of verification [1] as well as identification [2].\n\nIn the beginning, only the big corporations could afford training of the Face ID models on a huge amount of private data (e.g. 200M of faces in [3]). Later, with the introduction of quite big public datasets (mostly CASIA-WebFace [4] and MS-Celeb-1M [5]) and new types of losses for training Face ID models (in particular, angular-based losses: L-Softmax [6], A-Softmax [7], AM-Softmax [8,9] and ArcFace [10]), even the models trained with public datasets by independent researchers can be of the same (or similar) performance as the proprietary models provided by large companies. For example, the ArcFace (Insightface) solution is comparable with Microsoft and Google models in such challenges as Megaface [11,12], NIST FRVT [13], and Trillion Pairs [14].\n\nNowadays, an increasing emphasis has been placed on the adversarial attacks on deep neural networks. One of the reasons for this is that adversarial attacks can be implemented in the real world [25]. Recently, a form of adversarial attack [15] on previous generation Face ID models has been proposed [29,42]. A drawback of the proposed methods is that you need to cut out complex shape object from the paper. Another drawback is that shooting conditions (lighting, angle of the face and background) were fixed. In this work we propose an easily reproducible (rectangular image, printed and stuck to a hat) practical adversarial attack called AdvHat on the best public Face ID model LResNet100E-IR, ArcFace@ms1m-refine-v2 [16]. Demonstration of AdvHat is depicted in Figure 1. The advantages of the proposed AdvHat can be summarized as follows:\n\n\u2022 We implemented a real-world adversarial attack on the state-of-the-art public Face ID system using sticker on the hat.\n\n\u2022 The attack is easily reproducible. It is necessary to print only a color rectangle.\n\n\u2022 One attack works in different shooting conditions.\n\n\u2022 We present a novel technique of the sticker projection to the image during the attack to make it real-like. arXiv:1908.08705v1 [cs.CV] 23 Aug 2019\n\n\u2022 The attack is transferable to other Face ID models.\n\nThe source code 1 and video demonstration 2 are available on the Internet.\n\n\nBACKGROUND AND RELATED WORKS\n\nFirstly we review the adversarial attacks as our work uses the concept of adversarial attack. Second, we touch the emerging area of adversarial attacks in the real world, or in other words practical attacks, since our work aims to construct an adversarial attack working under conditions of the real world (as a contrast to simple attack on pixels in the digital domain).\n\n\nAdversarial attacks\n\nThe whole concept of adversarial attacks is quite simple: let us slightly change the input to a classifying neural net so that the recognized class will change from correct to some other class (first adversarial attacks were made only on classifiers). The pioneering work [15] formulates the task as follows:\n\n\u2022 Minimize ||r|| 2 so as:\n1. f (x) = c gt , 2. f (x + r) = c t = c gt , 3. x + r \u2208 [0, 1] m ,\nwhere x \u2208 [0, 1] m is an input to a classifier f , c gt -correct ground truth class for x, c t = c gt -target class for x + r, r \u2208 [0, 1] m -small perturbation to x that we need to construct.\n\nNote that if we need to get the incorrect class, the attack is called untargeted (or dodging in face recognition cases), and if we need to get the specific predefined class c t , the attack is called targeted (or impersonation in face recognition cases).\n\nIn [15] the authors propose to use a quasi-newton L-BFGS-B method to solve the task formulated above. Simpler and more efficient method called Fast Gradient-Sign Method (FGSM) is proposed in [17]. This method suggests using the gradients with respect to the input and constructing an adversarial image using the following formula:\nx = x + sign \u2207 x L(\u03b8, x, c gt ) (or x = x \u2212 sign \u2207 x L(\u03b8, x, c t ) in case of targeted attack).\nHere L(\u03b8, x, y) is a loss function (e.g. cross-entropy) which depends on the weights of the model \u03b8, input x, and label y. Note that usually one step is not enough and we need to do a number of iterations described above each time using the projection to the initial input space (e.g.\n\nx \u2208 [0, 1] m ). It is called projected gradient descent (PGD) [18].\n\nIt turns out that using momentum for the iterative procedure of an adversarial example construction is a good way to increase the robustness of the adversarial attack [19].\n\nAll the aforementioned adversarial attacks suggest that we restrict the maximum per-pixel perturbation (in case of image as an input) i.e. use L \u221e norm. Another interesting case is when we do not concentrate on the maximum perturbation but we strive to achieve the fewest possible number of pixels to be attacked (L 0 norm). One of the first examples of such attack is the Jacobian-based Saliency Map Attack (JSMA) [20], where the saliency maps are constructed of the pixels that are the most prone to cause the misclassification.\n\nAnother extreme case of attack for the L 0 norm is a onepixel attack [21]. The authors use differential evolution for this specific case, the algorithm which lies in the class of evolutionary algorithms.\n\nIt should be mentioned that not only classification neural nets are prone to adversarial attacks. There are also attacks for detection and segmentation [22].\n\nAnother interesting property of the adversarial attacks is that they are transferable between different neural networks [15]. An attack prepared using one model can successfully confuse another model with different architecture and training dataset.\n\nUsually, the adversarial attacks which are constructed using the specific architecture and even the weights of the attacked model are called white-box attacks. If the attack has no access to model weights then it is called a black-box attack [23].\n\nUsually, attacks are constructed for the specific input (e.g. photo of some object). This is called an input-aware attack. Adversarial attacks are called universal when one successful adversarial perturbation can be applied for any image [24].\n\nIn this work we concentrate on a white-box input-aware adversarial attack as the first step of our research.\n\n\nAttacks in physical world\n\nAlthough adversarial attacks are quite successful in the digital domain (where we can change the image on the pixel level before feeding it to a classifier), in the physical (i.e. real) world the efficiency of adversarial attacks is still questionable. Kurakin et al. demonstrate the potential for further research in this domain [25]. They discovered that if an adversarial image is printed on the paper and then shot by a camera phone it still can successfully fool classification network.\n\nIt turns out that the most successful paradigm to construct the real-world adversarial examples is an Expectation Over Transformation (EOT) algorithm [26]. This approach takes into account that in the real world the object usually undergoes a set of transformations (scaling, jittering, brightness and contrast changes, etc). The task is to find an adversarial example which is robust under this set of transformations T and can be formulated as follows:\n\n\u2022 Find such arg max r E g\u223cT P (c t |g(x + r)) so as:\n1. f (x) = c gt = c t ,\n\nFig. 2:\n\nSchema of the whole pipeline of the attack. First, we reshape sticker to a real-look form. Second, we project it on the face images. Third, we transform images into the ArcFace input templates using slightly different parameters for the transformation. Finally, we feed templates to the ArcFace, evaluate cosine similarities and TV loss. Thus we can get the gradients signs which are used to modify the sticker image.\n2. E g\u223cT ||g(x + r) \u2212 g(x)|| p < , 3. x + r \u2208 [0, 1] m ,\nwhere we use the notion of -vicinity in some L p space.\n\nOne of the first papers adopting this idea is Adversarial Patch [27]. In this work the authors use EOT for a set of transformations including rotations and translations to construct the universal patch for the ImageNet [28] classifier. It is noteworthy that the authors do not concentrate on L p norms for perturbations where p \u2265 1 but on L 0 norm.\n\nAnother work with the usage of L 0 -limited attacks proposes to attack facial recognition neural nets with the adversarial eyeglasses [29]. The authors propose a method to print adversarial perturbation on the eyeglasses frame with the help of Total Variation (TV) loss and non-printability score (NPS). TV loss is designed to make the image more smooth. Thus it makes an attack more stable for different image interpolation methods on the devices and makes it more inconspicuousness for human. NPS is designed to deal with the difference in digital RGB-values and the ability of real printers to reproduce these values.\n\nIn general, most of the subsequent works for the realworld attack use the concepts of L 0 -limited perturbation, EOT, TV loss, and NPS. Let us briefly list them. In [30] the authors construct the physical attack for the traffic sign recognition model using EOT and NPS for making either adversarial posters (attacking the whole traffic sign area) or adversarial stickers (black and white stickers on the real traffic sign). The works of [31,32] use some form of EOT to attack traffic sign recognition model too.\n\nA number of works are devoted to adversarial attacks on traffic sign detectors in the real world. One of the first works [33] proposes an adversarial attack on Faster R-CNN [34] stop sign detector using a sort of EOT (handcrafted estimation of a viewing map). Several works used EOT, NPS, and TV loss to attack Faster R-CNN, YOLOv2 [35] based traffic sign recognition models [36,37,38].\n\nAnother interesting approach [39] uses the concept of nested adversarial examples where separate non-overlapping adversarial perturbations are generated for close and far distances. This attack is designed for Faster R-CNN and YOLOv3 [40].\n\nA few works are devoted to more complex approaches. One of such works [41] proposes to use EOT, NPS, and TV loss for fooling YOLOv2-based person detector. Another one [42] is devoted to fooling the Face ID system using adversarial generative nets (a sort of GANs [43]) where the generator produces the eyeglasses frame perturbation.\n\n\nPROPOSED METHOD\n\nIn the real-use scenario of the Face ID system, not every captured person is known. That is why predicted similarity with the top-1 class should exceed some predefined threshold to treat face as recognized.\n\nThe goal of our paper is to create a rectangular image which can be stuck on the hat and induce Face ID system to decrease similarity to ground truth class below the decision threshold.\n\nIn order to achieve this goal we use an attack pipeline which can be described as follows: 1) We apply a novel offplane transformation to the rectangular image which imitates the form of the rectangular image after placing it on the hat. 2) We project the obtained image on the high-quality face image with small perturbations in the projection parameters to make our attack more robust. 3) We transform the obtained image to the standard template of ArcFace input. 4) We reduce the sum of two parameters: TV loss of the initial rectangular image and cosine similarity between the embedding for the obtained image and the anchor embedding calculated by ArcFace. A schema of the whole pipeline is illustrated in Figure 2.\n\n\nOff-Plain Sticker Transformation\n\nWe split transformations that occur during placing a sticker on the hat into two steps: the off-plane bending of the sticker and pitch rotation of the sticker. Both of these transformations are illustrated in Figure 3.\n\nWe simulate the off-plane bending as a parabolic transformation in the 3d space which maps each point of the sticker with initial coordinates (x, y, 0) to the new point with coordinates (x , y, z ). New points are placed on the parabolic cylinder given by the equation z = a \u00b7 x 2 . The origin of all axes is placed in the middle of the sticker. After this transformation, the new z (off-plane) coordinate of each point of the sticker is equal to a \u00b7 x 2 and x = a \u00b7 (|x| \u00b7 x 2 + 1 4 \u00b7 a 2 +\n+ 1 4 \u00b7 a 2 \u00b7 ln (|x| + x 2 + 1 4 \u00b7 a 2 ) \u2212 1 4 \u00b7 a 2 \u00b7 ln ( 1 2 \u00b7 a )).\nThis formula guarantees that the geometric length of the sticker does not change.\n\nTo simulate the pitch rotation of the sticker we apply a 3d affine transformation to the obtained coordinates.\n\nWe change the parabola rate and the angle of rotation a little during the attack to make the attack more robust since we can not evaluate exact values of these parameters.\n\n\nSticker Projection\n\nWe use Spatial Transformer Layer (STL) to project the obtained sticker on the image of the face [44]. We slightly change the parameters of the projection during the attack.\n\nIt is crucial to project sticker on the high-quality image of the face. The image interpolation methods, which are applied in the Face ID system and which create a standard template of the face, use the values of neighboring pixels. That is why if we project sticker onto the small face (which is fed to the ArcFace input) then the RGB values on the sticker boundaries differ from that in a real-use scenario since they use values of face pixels too.\n\n\nFinal Transformation\n\nWe transform images with the sticker to a standard template for ArcFace using STL. Same as before, we change transformation parameters a little during the attack.\n\n\nLoss Function\n\nWe feed a batch of images obtained by using various parameters to the ArcFace input. The first loss to minimize is a cosine similarity between obtained embeddings e x and some anchor embedding e a for the person:\nL sim (x, a) = cos(e x , e a )\nWe minimize a TV loss also concerning the reasons as mentioned earlier. We formulate TV loss as follows:\nTV(x) = i,j (x i,j \u2212 x i+1,j ) 2 + (x i,j \u2212 x i,j+1 ) 2 1 2\nThe final loss is the weighted sum of the aforementioned losses:\nL f inal (x, a) = L sim (x, a) + \u03bb \u00b7 T V (x),\nwhere \u03bb is a weight for the TV loss (1e \u2212 4 in our experiments).\n\nWe do not use NPS loss since it do not make an influence in our experiments.\n\n\nEXPERIMENTS AND RESULTS\n\nWe use an image of 400 \u00d7 900 pixels in our experiments as a sticker image. We project the sticker image to a 600x600 image of the face and then transform it to the 112x112 image.\n\n\nAttack Method\n\nAs stated earlier, we randomly modify images before feeding them to the ArcFace. We construct a batch of generated images and calculate average gradients on the initial sticker using the whole pipeline. We can evaluate gradients in a straight-forward way since each transformation is differentiable.\n\nNote that stickers on each image from the batch are the same during one iteration. Only transformations parameters are different. We use Iterative FGSM with momentum and several heuristics that were efficient in our experiments.\n\nWe split our attack into two stages. During the first stage, we use step value equal to 5 255 and momentum equal to 0.9. During the second stage, we use step value equal to 1 255 and momentum equal to 0.995. The weight of the TV loss is always equal to 1e \u2212 4.\n\nWe use one fixed image with the sticker as a validation where we set up all the parameters to the most real-like looking values.\n\nWe interpolate the last 100 validation values by a linear function using the least square method: after 100 iterations for the first stage and after 200 iterations for the second stage. If the angular coefficient of this linear function is not less than zero then: 1) in the first stage we pass to the second stage of the attack; 2) in the second stage we stop the attack.\n\n\nSticker Localization\n\nTo find out which place is the best for sticker position, we make two experiments with the sticker localization. First, we attack the image in the digital domain with a sticker placed on various height above the eyez line. It turns out, that the lower placement leads to the better validation values. Further, we change the placement of the sticker after each iteration with respect to the values of gradients on the spatial transformer layer parameters. We limit the possible places for the sticker to make it higher than the eyes. The sticker always moves down to the eyes in our experiments.\n\nGiven the above, we put a hat and sticker at the lowest possible position during the attack to achieve the best results. Thus, we put on the hat in our experiments down to the eyes (see Figure 1).\n\nSome examples of typical adversarial stickers are depicted in Figure 4. It looks like the model draws a raised eyebrows on the sticker. According to the article [45], eyebrows are the most important feature for the face recognition by a human. That is why we believe that some sort of raised eyebrows appears on the sticker. The model draws the most important feature of the face and eyebrows are raised because it is the only reason which makes eyebrows higher than usual.\n\n\nTesting Protocol\n\nSince it is rather simple to attack a batch of images successfully using the sticker in the digital domain and since the main goal of this paper is to attack the Face ID system in the physi- cal world, we concentrate only on the attacks in the real world. Detailed studies of our approach applied to the digital domain are out of the scope of this work. At first, we evaluate the success and characteristics of the attacks in the fixed conditions. During this experiment, we use only full-face photos with uniform light. On the next step, we research the robustness of our attack to different angles of the face rotation and light conditions. Finally, we explore the transferability of prepared attacks to other models.\n\nWe use first 1000 classes from the CASIA-WebFace dataset as other classes of the recognizer. We do not introduce percent of successful dodging attacks since the success of the attack depend on the threshold which is used in the Face ID system. It can significantly vary according to the purpose of face recognition 3 . Instead of the ratio of successes, we explore the following values:\n\n\u2022 Cosine similarity between ground truth embedding and embedding for a photo with a hat. This is a baseline similarity.\n\n\u2022 Cosine similarity between ground truth embedding and embedding for a photo with an adversarial sticker. This is a final similarity.\n\n\u2022 The difference between baseline similarity and final similarity.\n\n\u2022 The top-1 similarity to the 1000 classes from CASIA. \n\n\nExperiments with fixed conditions\n\nWe start with the experiments where all photos and real-world testing are made in the same conditions. We evaluate the values for 10 people with different age and gender: four females of age 30, 23, 16, 5 and six males of age 36, 32, 29, 24, 24, 8. We use 3 photos of each person to create an attack: a simple photo which we need to calculate the ground truth embedding; a photo with the hat which we need to calculate the baseline similarity and obtain the adversarial sticker; a photo with the white sticker on the hat which we need to find parameters of the sticker transformations for this person. Then we print the adversarial sticker for each person and make the fourth photo with this sticker on the hat to obtain final values. We use boxplot to show the distributions of the obtained values (see Figure 5). As can be seen, adversarial stickers significantly reduce similarity to the ground truth class. Only one attack achieves similarity more than 0.2 in the real world and the same attack achieves similarity to the top-1 class from CASIA less than 0.2. Thus, similarity to the top-1 class from the first 1000 CASIA classes is almost always bigger than similarity to the ground truth although it is not the aim of our attack. It is noteworthy that in most cases the adversarial sticker reduces similarity to the ground truth on more than 0.5. Both attacks that decrease similarity by less than 0.5 relate to children under 10 years old. The baseline similarity is initially smaller for children.\n\n\nExperiments with various conditions\n\nIn order to examine the robustness of our approach to different shooting conditions, we make 22 extra photos for 4 persons from the first 10. These photos consist of 11 pairs. Each pair is made in the same conditions. The first photo of each pair is a photo in a hat that is used to evaluate baseline similarity. The second photo of each pair is a photo in a hat with an adversarial sticker that is used to evaluate the final similarity. 8 pairs correspond to the different combination of head tilts (lean forward, lean back, turn left, turn right) and 3 pairs correspond to different lighting conditions. Examples of shooting condi-  tions are depicted in Figure 6. It is worth noting that we use stickers from the previous step without making new attacks.\n\nThe results are illustrated in Figure 7. Although final similarity increases, the attack still works. We do not want to jump to a conclusion since the testing set is crucially small but we believe that our approach is robust to rotations of the head that keep sticker visible.\n\nWe find out that the bigger area of the sticker on the photo leads to the lower similarity. When the head leans forward, the final similarity is still less than 0.2 and it gradually increases while the head rises. Using better projective and rendering technique and larger adversarial accessories (e.g. using of all area of the hat for the attack) can make you fully unrecognizable for surveillance cameras.\n\n\nExperiments with transferability\n\nFinally, we examine the robustness of our attacks to other Face ID models. The models have been taken from In-sightFace Model Zoo [16]. These networks have different architectures and they used different loss functions and datasets for training in comparison to the LResNet100E-IR, ArcFace@ms1m-refine-v2.\n\nWe use photos from the first experiment to evaluate similarities: a full-face photo, a photo in a hat, a photo with an adversarial sticker on the hat. We calculate the baseline and final similarities for each of 10 persons. The differences between the baseline and final similarities for each model are depicted in Figure 8 using boxplots.\n\nWe observe that our real-world attack behaves like a usual adversarial attack in the digital domain. Although the strength of the attack decreases, it still makes a person less recognizable.\n\n\nCONCLUSION AND FUTURE WORK\n\nWe have proposed a novel method to attack the Face ID system called AdvHat. Our method can be easily reproducible as well as it can efficiently attack the best public Face ID model in different shooting conditions. Experimental results verified the robustness of our attack to the state-of-the-art Face ID system ArcFace. In the future, we would like to apply our model on state-of-the-art face detectors.\n\n\nACKNOWLEDGMENTS\n\nAuthors would like to thank their family members and colleagues from Huawei Moscow Research Center for help in conducting experiments, and I. Mazurenko and Y. Xiong from Intelligent Systems Laboratory for guidance and support.\n\nFig. 1 :\n1A novel approach to attack the Facial Recognition system. A sticker placed on the hat significantly reduces the similarity to the ground truth class. Similarity to the ground truth decreases by 0.592 on the left pair and by 0.429 on the right pair.\n\nFig. 3 :\n3When we put a rectangular sticker on the hat, it bends and rotates.\n\nFig. 4 :\n4Examples of the adversarial stickers.\n\nFig. 5 :\n5Blue: Cosine similarities between anchor images and images with a hat. Orange: Cosine similarities between anchor images and images with an adversarial sticker. Green: Differences between aforementioned similarities. Red: The top-1 similarity to the first 1000 classes from CASIA.\n\nFig. 6 :\n6We make 11 extra photos for some persons to examine the power of the attack in the various conditions. Poses from 1 to 11 are placed from left to right from top to the bottom.\n\nFig. 7 :\n7Baseline and final similarity for various shooting conditions. Different persons are depicted with different colors. Circle markers are used to show final similarity with adversarial sticker and x markers are used to show baseline similarity.\n\nFig. 8 :\n8Differences between baseline and final similarities of one attack on different models. LResNet100E was used to prepare the attack.\nhttps://github.com/papermsucode/advhat 2 https://youtu.be/a4iNg0wWBsQ\nA threshold for ArcFace varies from 0.328 to 0.823 according to the results on IJB-B Still Images Identification test with FAR from 1e \u2212 1 to 1e \u2212 3.\n\nDeepface: Closing the gap to human-level performance in face verification. Y Taigman, M Yang, M Ranzato, L Wolf, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionY. Taigman, M. Yang, M. Ranzato, and L. Wolf, \"Deep- face: Closing the gap to human-level performance in face verification\", In Proceedings of the IEEE confer- ence on computer vision and pattern recognition, pp. 1701-1708 (2014).\n\nWeb-Scale Training for Face Identification. Y Taigman, M Yang, M Ranzato, L Wolf, arXiv:1406.5266arXiv preprintY. Taigman, M. Yang, M. Ranzato, and L. Wolf, \"Web- Scale Training for Face Identification\", arXiv preprint arXiv:1406.5266 (2014).\n\nFaceNet: A Unified Embedding for Face Recognition and Clustering. F Schroff, D Kalenichenko, J Philbin, arXiv:1503.03832arXiv preprintF. Schroff, D. Kalenichenko, and J. Philbin, \"FaceNet: A Unified Embedding for Face Recognition and Clus- tering\", arXiv preprint arXiv:1503.03832 (2015).\n\nLearning Face Representation from Scratch. D Yi, Z Lei, S Liao, S Li, arXiv:1411.7923arXiv preprintD. Yi, Z. Lei, S. Liao, and S. Li, \"Learning Face Representation from Scratch\", arXiv preprint arXiv:1411.7923 (2014).\n\nY Guo, L Zhang, Y Hu, X He, J Gao, arXiv:1607.08221MS-Celeb-1M: A Dataset and Benchmark for Large-Scale Face Recognition. arXiv preprintY. Guo, L. Zhang, Y. Hu, X. He, and J. Gao, \"MS- Celeb-1M: A Dataset and Benchmark for Large-Scale Face Recognition\", arXiv preprint arXiv:1607.08221 (2016).\n\nLarge-Margin Softmax Loss for Convolutional Neural Networks. W Liu, Y Wen, Z Yu, M Yang, arXiv:1612.02295arXiv preprintW. Liu, Y. Wen, Z. Yu, and M. Yang, \"Large-Margin Softmax Loss for Convolutional Neural Networks\", arXiv preprint arXiv:1612.02295 (2016).\n\nW Liu, Y Wen, Z Yu, M Li, B Raj, L Song, arXiv:1704.08063SphereFace: Deep Hypersphere Embedding for Face Recognition. arXiv preprintW. Liu, Y. Wen, Z. Yu, M. Li, B. Raj, and L. Song, \"SphereFace: Deep Hypersphere Embedding for Face Recognition\", arXiv preprint arXiv:1704.08063 (2017).\n\nAdditive Margin Softmax for Face Verification. F Wang, W Liu, H Liu, J Cheng, arXiv:1801.05599arXiv preprintF. Wang, W. Liu, H. Liu, and J. Cheng, \"Additive Margin Softmax for Face Verification\", arXiv preprint arXiv:1801.05599 (2018).\n\nCosFace: Large Margin Cosine Loss for Deep Face Recognition. H Wang, Y Wang, Z Zhou, X Ji, D Gong, J Zhou, Z Li, W Liu, arXiv:1801.09414arXiv preprintH. Wang, Y. Wang, Z. Zhou, X. Ji, D. Gong, J. Zhou, Z. Li, and W. Liu, \"CosFace: Large Margin Co- sine Loss for Deep Face Recognition\", arXiv preprint arXiv:1801.09414 (2018).\n\nArcface: Additive angular margin loss for deep face recognition. J Deng, J Guo, N Xue, S Zafeiriou, arXiv:1801.07698arXiv preprintJ. Deng, J. Guo, N. Xue, and S. Zafeiriou, \"Arcface: Additive angular margin loss for deep face recognition\", arXiv preprint arXiv:1801.07698 (2018).\n\nD Miller, E Brossard, S Seitz, I Kemelmacher-Shlizerman, arXiv:1505.02108MegaFace: A Million Faces for Recognition at Scale. arXiv preprintD. Miller, E. Brossard, S. Seitz, and I. Kemelmacher- Shlizerman, \"MegaFace: A Million Faces for Recogni- tion at Scale\", arXiv preprint arXiv:1505.02108 (2015).\n\nI Kemelmacher-Shlizerman, S Seitz, D Miller, E Brossard, arXiv:1512.00596The MegaFace Benchmark: 1 Million Faces for Recognition at Scale. arXiv preprintI. Kemelmacher-Shlizerman, S. Seitz, D. Miller, and E. Brossard, \"The MegaFace Benchmark: 1 Mil- lion Faces for Recognition at Scale\", arXiv preprint arXiv:1512.00596 (2015).\n\nOngoing Face Recognition Vendor Test (FRVT) Part 2: Identification. P Grother, M Ngan, K Hanaoka, NIST Interagency/Internal Report. 8238P. Grother, M. Ngan, and K. Hanaoka, \"Ongoing Face Recognition Vendor Test (FRVT) Part 2: Identification\", NIST Interagency/Internal Report (NISTIR) -8238.\n\nMs-celeb-1m challenge 3: Face feature test/trillion pairs. Ms-celeb-1m challenge 3: Face feature test/trillion pairs, http://trillionpairs.deepglint. com/.\n\nC Szegedy, W Zaremba, I Sutskever, J Bruna, D Erhan, I Goodfellow, R Fergus, arXiv:1312.6199Intriguing properties of neural networks. arXiv preprintC. Szegedy, W. Zaremba, I. Sutskever, J. Bruna, D. Erhan, I. Goodfellow, and R. Fergus, \"Intrigu- ing properties of neural networks\", arXiv preprint arXiv:1312.6199 (2013).\n\nInsightFace Model Zoo, LResNet100E-IR, ArcFace@ms1m-refine-v2. InsightFace Model Zoo, LResNet100E-IR, ArcFace@ms1m-refine-v2, https://github.\n\nExplaining and harnessing adversarial examples. I Goodfellow, J Shlens, C Szegedy, arXiv:1412.6572arXiv preprintI. Goodfellow, J. Shlens, and C. Szegedy, \"Explaining and harnessing adversarial examples\", arXiv preprint arXiv:1412.6572 (2014).\n\nTowards deep learning models resistant to adversarial examples. A Madry, A Makelov, L Schmidt, D Tsipras, A Vladu, arXiv:1706.06083arXiv preprintA. Madry, A. Makelov, L. Schmidt, D. Tsipras, and A. Vladu, \"Towards deep learning models re- sistant to adversarial examples\", arXiv preprint arXiv:1706.06083 (2017).\n\n. Y Dong, F Liao, T Pang, H Su, J Zhu, X Hu, J Li, arXiv:1710.06081Boosting Adversarial Attacks with Momentum. arXiv preprintY. Dong, F. Liao, T. Pang, H. Su, J. Zhu, X. Hu, and J. Li, \"Boosting Adversarial Attacks with Momentum\", arXiv preprint arXiv:1710.06081 (2017).\n\nThe limitations of deep learning in adversarial settings. N Papernot, P Mcdaniel, S Jha, M Fredrikson, Z Celik, A Swami, arXiv:1511.07528arXiv preprintN. Papernot, P. McDaniel, S. Jha, M. Fredrikson, Z. Ce- lik, and A. Swami, \"The limitations of deep learning in adversarial settings\", arXiv preprint arXiv:1511.07528 (2015).\n\nOne pixel attack for fooling deep neural networks. J Su, D Vargas, S Kouichi, arXiv:1710.08864arXiv preprintJ. Su, D. Vargas, and S. Kouichi, \"One pixel at- tack for fooling deep neural networks\", arXiv preprint arXiv:1710.08864 (2017).\n\nAdversarial examples for semantic segmentation and object detection. C Xie, J Wang, Z Zhang, Y Zhou, L Xie, A Yuille, arXiv:1703.08603arXiv preprintC. Xie, J. Wang, Z. Zhang, Y. Zhou, L. Xie, and A. Yuille, \"Adversarial examples for semantic seg- mentation and object detection\", arXiv preprint arXiv:1703.08603 (2017).\n\nPractical black-box attacks against machine learning. N Papernot, P Mcdaniel, I Goodfellow, S Jha, Z Celik, A Swami, arXiv:1602.02697arXiv preprintN. Papernot, P. McDaniel, I. Goodfellow, S. Jha, Z. Ce- lik, and A. Swami, \"Practical black-box attacks against machine learning\", arXiv preprint arXiv:1602.02697 (2016).\n\nUniversal adversarial perturbations. S Moosavi-Dezfooli, A Fawzi, O Fawzi, P Frossard, arXiv:1610.08401arXiv preprintS. Moosavi-Dezfooli, A. Fawzi, O. Fawzi, and P. Frossard, \"Universal adversarial perturbations\", arXiv preprint arXiv:1610.08401 (2016).\n\nAdversarial examples in the physical world. A Kurakin, I Goodfellow, S Bengio, arXiv:1607.02533arXiv preprintA. Kurakin, I. Goodfellow, and S. Bengio, \"Adver- sarial examples in the physical world\", arXiv preprint arXiv:1607.02533 (2016).\n\nSynthesizing robust adversarial examples. A Athalye, I Sutskever, arXiv:1707.07397arXiv preprintA. Athalye, and I. Sutskever, \"Synthesizing robust ad- versarial examples\", arXiv preprint arXiv:1707.07397 (2017).\n\nAdversarial patch. T Brown, D Mane, A Roy, M Abadi, J Gilmer, arXiv:1712.09665arXiv preprintT. Brown, D. Mane, A. Roy, M. Abadi, and J. Gilmer, \"Adversarial patch\", arXiv preprint arXiv:1712.09665 (2017).\n\nImageNet: A Large-Scale Hierarchical Image Database. J Deng, W Dong, R Socher, L.-J Li, K Li, L Fei-Fei, Proceedings of the 2009 IEEE Computer Vision and Pattern Recognition. the 2009 IEEE Computer Vision and Pattern RecognitionJ. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei- Fei,, \"ImageNet: A Large-Scale Hierarchical Image Database\", In Proceedings of the 2009 IEEE Computer Vision and Pattern Recognition, pp. 248-255 (2009).\n\nAccessorize to a crime: Real and stealthy attacks on stateof-the-art face recognition. M Sharif, S Bhagavatula, L Bauer, M Reiter, Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security. the 2016 ACM SIGSAC Conference on Computer and Communications SecurityM. Sharif, S. Bhagavatula, L. Bauer, and M. Reiter, \"Ac- cessorize to a crime: Real and stealthy attacks on state- of-the-art face recognition\", In Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communi- cations Security, pp. 1528-1540 (2016).\n\nRobust physical-world attacks on deep learning models. K Eykholt, I Evtimov, E Fernandes, B Li, A Rahmati, C Xiao, A Prakash, T Kohno, D Song, arXiv:1707.08945arXiv preprintK. Eykholt, I. Evtimov, E. Fernandes, B. Li, A. Rahmati, C. Xiao, A. Prakash, T. Kohno, and D. Song, \"Robust physical-world attacks on deep learning models\", arXiv preprint arXiv:1707.08945 (2017).\n\nC Sitawarin, A Bhagoji, A Mosenia, P Mittal, M Chiang, arXiv:1801.02780Rogue Signs: Deceiving Traffic Sign Recognition with Malicious Ads and Logos. arXiv preprintC. Sitawarin, A. Bhagoji, A. Mosenia, P. Mittal, and M. Chiang, \"Rogue Signs: Deceiving Traffic Sign Recognition with Malicious Ads and Logos\", arXiv preprint arXiv:1801.02780 (2018).\n\nDARTS: Deceiving Autonomous Cars with Toxic Signs. C Sitawarin, A Bhagoji, A Mosenia, M Chiang, P Mittal, arXiv:1802.06430arXiv preprintC. Sitawarin, A. Bhagoji, A. Mosenia, M. Chiang, and P. Mittal, \"DARTS: Deceiving Autonomous Cars with Toxic Signs\", arXiv preprint arXiv:1802.06430 (2018).\n\nAdversarial Examples that Fool Detectors. J Lu, H Sibai, E Fabry, arXiv:1712.02494arXiv preprintJ. Lu, H. Sibai, and E. Fabry, \"Adversarial Examples that Fool Detectors\", arXiv preprint arXiv:1712.02494 (2017).\n\nFaster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks. Kaiming Shaoqing Ren, Ross He, Jian Girshick, Sun, arXiv:1506.01497arXiv preprintShaoqing Ren, Kaiming He, Ross Girshick, Jian Sun \"Faster R-CNN: Towards Real-Time Object Detec- tion with Region Proposal Networks\", arXiv preprint arXiv:1506.01497 (2015).\n\nJ Redmon, A Farhadi, arXiv:1612.08242YOLO9000: Better, Faster, Stronger. arXiv preprintJ. Redmon and A. Farhadi, \"YOLO9000: Better, Faster, Stronger\", arXiv preprint arXiv:1612.08242 (2016).\n\nRobust physical adversarial attack on faster r-cnn object detector. S Chen, C Cornelius, J Martin, D Chau, arXiv:1804.05810arXiv preprintS. Chen, C. Cornelius, J. Martin, and D. Chau, \"Robust physical adversarial attack on faster r-cnn object detec- tor\", arXiv preprint arXiv:1804.05810 (2018).\n\nK Eykholt, I Evtimov, E Fernandes, B Li, D Song, T Kohno, A Rahmati, A Prakash, F Tramer, arXiv:1712.08062Note on attacking object detectors with adversarial stickers. arXiv preprintK. Eykholt, I. Evtimov, E. Fernandes, B. Li, D. Song, T. Kohno, A. Rahmati, A. Prakash, and F. Tramer, \"Note on attacking object detectors with adversarial stickers\", arXiv preprint arXiv:1712.08062 (2017).\n\nPhysical Adversarial Examples for Object Detectors. K Eykholt, I Evtimov, E Fernandes, B Li, A Rahmati, F Tramer, A Prakash, T Kohno, D Song, arXiv:1807.07769arXiv preprintK. Eykholt, I. Evtimov, E. Fernandes, B. Li, A. Rahmati, F. Tramer, A. Prakash, T. Kohno, and D. Song, \"Physi- cal Adversarial Examples for Object Detectors\", arXiv preprint arXiv:1807.07769 (2018).\n\nY Zhao, H Zhu, R Liang, Q Shen, S Zhang, K Chen, arXiv:1812.10217Seeing isn't Believing: Practical Adversarial Attack Against Object Detectors. arXiv preprintY. Zhao, H. Zhu, R. Liang, Q. Shen, S. Zhang, and K. Chen, \"Seeing isn't Believing: Practical Adversar- ial Attack Against Object Detectors\", arXiv preprint arXiv:1812.10217 (2018).\n\nJ Redmon, A Farhadi, arXiv:1804.02767YOLOv3: An Incremental Improvement. arXiv preprintJ. Redmon and A. Farhadi, \"YOLOv3: An Incremen- tal Improvement\", arXiv preprint arXiv:1804.02767 (2018).\n\nFooling automated surveillance cameras: adversarial patches to attack person detection. S Thys, W Ranst, T Goedeme, arXiv:1904.08653arXiv preprintS. Thys, W. Ranst, and T. Goedeme, \"Fooling automated surveillance cameras: adversarial patches to attack person detection\", arXiv preprint arXiv:1904.08653 (2019).\n\nA General Framework for Adversarial Examples with Objectives. M Sharif, S Bhagavatula, L Bauer, M Reiter, arXiv:1801.00349arXiv preprintM. Sharif, S. Bhagavatula, L. Bauer, and M. Reiter, \"A General Framework for Adversarial Examples with Ob- jectives\", arXiv preprint arXiv:1801.00349 (2018).\n\n. I Goodfellow, J Pouget-Abadie, M Mirza, B Xu, D Warde-Farley, S Ozair, A Courville, Y Bengio, arXiv:1406.2661Generative Adversarial Networks. arXiv preprintI. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Ben- gio, \"Generative Adversarial Networks\", arXiv preprint arXiv:1406.2661 (2014).\n\nSpatial transformer networks. M Jaderberg, K Simonyan, A Zisserman, Advances in neural information processing systems. M. Jaderberg, K. Simonyan, and A. Zisserman, \"Spatial transformer networks\", In Advances in neural informa- tion processing systems, pp. 2017-2025 (2015).\n\nFace recognition by humans: Nineteen results all computer vision researchers should know about. P Sinha, B Balas, Y Ostrovsky, R Russell, Proceedings of the IEEE. the IEEE94P. Sinha, B. Balas, Y. Ostrovsky, and R. Russell, \"Face recognition by humans: Nineteen results all computer vision researchers should know about\", In Proceedings of the IEEE, vol. 94, No 11, pp. 1948-1962 (2006).\n", "annotations": {"author": "[{\"end\":209,\"start\":67},{\"end\":365,\"start\":210}]", "publisher": null, "author_last_name": "[{\"end\":80,\"start\":74},{\"end\":229,\"start\":220}]", "author_first_name": "[{\"end\":73,\"start\":67},{\"end\":219,\"start\":210}]", "author_affiliation": "[{\"end\":152,\"start\":107},{\"end\":208,\"start\":154},{\"end\":308,\"start\":263},{\"end\":364,\"start\":310}]", "title": "[{\"end\":64,\"start\":1},{\"end\":429,\"start\":366}]", "venue": null, "abstract": "[{\"end\":1038,\"start\":486}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":1230,\"start\":1227},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":1260,\"start\":1257},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":1410,\"start\":1407},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":1496,\"start\":1493},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":1516,\"start\":1513},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":1621,\"start\":1618},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":1636,\"start\":1633},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":1652,\"start\":1649},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":1654,\"start\":1652},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":1671,\"start\":1667},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":1975,\"start\":1971},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":1978,\"start\":1975},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":1994,\"start\":1990},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":2019,\"start\":2015},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":2220,\"start\":2216},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":2265,\"start\":2261},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":2326,\"start\":2322},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":2329,\"start\":2326},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":2747,\"start\":2743},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":4113,\"start\":4109},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":4697,\"start\":4693},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":4885,\"start\":4881},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":5469,\"start\":5465},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":5643,\"start\":5639},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":6065,\"start\":6061},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":6251,\"start\":6247},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":6539,\"start\":6535},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":6666,\"start\":6662},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":7039,\"start\":7035},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":7284,\"start\":7280},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":7759,\"start\":7755},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":8072,\"start\":8068},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":9061,\"start\":9057},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":9216,\"start\":9212},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":9481,\"start\":9477},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":10134,\"start\":10130},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":10406,\"start\":10402},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":10409,\"start\":10406},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":10603,\"start\":10599},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":10655,\"start\":10651},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":10814,\"start\":10810},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":10857,\"start\":10853},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":10860,\"start\":10857},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":10863,\"start\":10860},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":10899,\"start\":10895},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":11104,\"start\":11100},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":11181,\"start\":11177},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":11278,\"start\":11274},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":11374,\"start\":11370},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":13885,\"start\":13881},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":17779,\"start\":17775},{\"end\":19882,\"start\":19860},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":22794,\"start\":22790}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":24440,\"start\":24181},{\"attributes\":{\"id\":\"fig_1\"},\"end\":24519,\"start\":24441},{\"attributes\":{\"id\":\"fig_2\"},\"end\":24568,\"start\":24520},{\"attributes\":{\"id\":\"fig_3\"},\"end\":24860,\"start\":24569},{\"attributes\":{\"id\":\"fig_4\"},\"end\":25047,\"start\":24861},{\"attributes\":{\"id\":\"fig_5\"},\"end\":25301,\"start\":25048},{\"attributes\":{\"id\":\"fig_6\"},\"end\":25443,\"start\":25302}]", "paragraph": "[{\"end\":1261,\"start\":1054},{\"end\":2020,\"start\":1263},{\"end\":2865,\"start\":2022},{\"end\":2987,\"start\":2867},{\"end\":3074,\"start\":2989},{\"end\":3128,\"start\":3076},{\"end\":3278,\"start\":3130},{\"end\":3333,\"start\":3280},{\"end\":3409,\"start\":3335},{\"end\":3813,\"start\":3442},{\"end\":4145,\"start\":3837},{\"end\":4172,\"start\":4147},{\"end\":4432,\"start\":4241},{\"end\":4688,\"start\":4434},{\"end\":5020,\"start\":4690},{\"end\":5401,\"start\":5117},{\"end\":5470,\"start\":5403},{\"end\":5644,\"start\":5472},{\"end\":6176,\"start\":5646},{\"end\":6381,\"start\":6178},{\"end\":6540,\"start\":6383},{\"end\":6791,\"start\":6542},{\"end\":7040,\"start\":6793},{\"end\":7285,\"start\":7042},{\"end\":7395,\"start\":7287},{\"end\":7916,\"start\":7425},{\"end\":8372,\"start\":7918},{\"end\":8426,\"start\":8374},{\"end\":8878,\"start\":8461},{\"end\":8991,\"start\":8936},{\"end\":9341,\"start\":8993},{\"end\":9963,\"start\":9343},{\"end\":10476,\"start\":9965},{\"end\":10864,\"start\":10478},{\"end\":11105,\"start\":10866},{\"end\":11439,\"start\":11107},{\"end\":11665,\"start\":11459},{\"end\":11852,\"start\":11667},{\"end\":12574,\"start\":11854},{\"end\":12829,\"start\":12611},{\"end\":13322,\"start\":12831},{\"end\":13477,\"start\":13396},{\"end\":13589,\"start\":13479},{\"end\":13762,\"start\":13591},{\"end\":13957,\"start\":13785},{\"end\":14409,\"start\":13959},{\"end\":14596,\"start\":14434},{\"end\":14826,\"start\":14614},{\"end\":14962,\"start\":14858},{\"end\":15087,\"start\":15023},{\"end\":15198,\"start\":15134},{\"end\":15276,\"start\":15200},{\"end\":15482,\"start\":15304},{\"end\":15799,\"start\":15500},{\"end\":16029,\"start\":15801},{\"end\":16291,\"start\":16031},{\"end\":16421,\"start\":16293},{\"end\":16795,\"start\":16423},{\"end\":17414,\"start\":16820},{\"end\":17612,\"start\":17416},{\"end\":18087,\"start\":17614},{\"end\":18827,\"start\":18108},{\"end\":19215,\"start\":18829},{\"end\":19336,\"start\":19217},{\"end\":19471,\"start\":19338},{\"end\":19539,\"start\":19473},{\"end\":19596,\"start\":19541},{\"end\":21139,\"start\":19634},{\"end\":21936,\"start\":21179},{\"end\":22214,\"start\":21938},{\"end\":22623,\"start\":22216},{\"end\":22965,\"start\":22660},{\"end\":23306,\"start\":22967},{\"end\":23498,\"start\":23308},{\"end\":23934,\"start\":23529},{\"end\":24180,\"start\":23954}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":4240,\"start\":4173},{\"attributes\":{\"id\":\"formula_1\"},\"end\":5116,\"start\":5021},{\"attributes\":{\"id\":\"formula_2\"},\"end\":8450,\"start\":8427},{\"attributes\":{\"id\":\"formula_3\"},\"end\":8935,\"start\":8879},{\"attributes\":{\"id\":\"formula_4\"},\"end\":13395,\"start\":13323},{\"attributes\":{\"id\":\"formula_5\"},\"end\":14857,\"start\":14827},{\"attributes\":{\"id\":\"formula_6\"},\"end\":15022,\"start\":14963},{\"attributes\":{\"id\":\"formula_7\"},\"end\":15133,\"start\":15088}]", "table_ref": null, "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":1052,\"start\":1040},{\"attributes\":{\"n\":\"2.\"},\"end\":3440,\"start\":3412},{\"attributes\":{\"n\":\"2.1.\"},\"end\":3835,\"start\":3816},{\"attributes\":{\"n\":\"2.2.\"},\"end\":7423,\"start\":7398},{\"end\":8459,\"start\":8452},{\"attributes\":{\"n\":\"3.\"},\"end\":11457,\"start\":11442},{\"attributes\":{\"n\":\"3.1.\"},\"end\":12609,\"start\":12577},{\"attributes\":{\"n\":\"3.2.\"},\"end\":13783,\"start\":13765},{\"attributes\":{\"n\":\"3.3.\"},\"end\":14432,\"start\":14412},{\"attributes\":{\"n\":\"3.4.\"},\"end\":14612,\"start\":14599},{\"attributes\":{\"n\":\"4.\"},\"end\":15302,\"start\":15279},{\"attributes\":{\"n\":\"4.1.\"},\"end\":15498,\"start\":15485},{\"attributes\":{\"n\":\"4.2.\"},\"end\":16818,\"start\":16798},{\"attributes\":{\"n\":\"4.3.\"},\"end\":18106,\"start\":18090},{\"attributes\":{\"n\":\"4.4.\"},\"end\":19632,\"start\":19599},{\"attributes\":{\"n\":\"4.5.\"},\"end\":21177,\"start\":21142},{\"attributes\":{\"n\":\"4.6.\"},\"end\":22658,\"start\":22626},{\"attributes\":{\"n\":\"5.\"},\"end\":23527,\"start\":23501},{\"attributes\":{\"n\":\"6.\"},\"end\":23952,\"start\":23937},{\"end\":24190,\"start\":24182},{\"end\":24450,\"start\":24442},{\"end\":24529,\"start\":24521},{\"end\":24578,\"start\":24570},{\"end\":24870,\"start\":24862},{\"end\":25057,\"start\":25049},{\"end\":25311,\"start\":25303}]", "table": null, "figure_caption": "[{\"end\":24440,\"start\":24192},{\"end\":24519,\"start\":24452},{\"end\":24568,\"start\":24531},{\"end\":24860,\"start\":24580},{\"end\":25047,\"start\":24872},{\"end\":25301,\"start\":25059},{\"end\":25443,\"start\":25313}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":2796,\"start\":2788},{\"end\":12573,\"start\":12565},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":12828,\"start\":12820},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":17611,\"start\":17602},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":17684,\"start\":17676},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":20446,\"start\":20438},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":21844,\"start\":21836},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":21977,\"start\":21969},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":23290,\"start\":23282}]", "bib_author_first_name": "[{\"end\":25741,\"start\":25740},{\"end\":25752,\"start\":25751},{\"end\":25760,\"start\":25759},{\"end\":25771,\"start\":25770},{\"end\":26196,\"start\":26195},{\"end\":26207,\"start\":26206},{\"end\":26215,\"start\":26214},{\"end\":26226,\"start\":26225},{\"end\":26462,\"start\":26461},{\"end\":26473,\"start\":26472},{\"end\":26489,\"start\":26488},{\"end\":26729,\"start\":26728},{\"end\":26735,\"start\":26734},{\"end\":26742,\"start\":26741},{\"end\":26750,\"start\":26749},{\"end\":26905,\"start\":26904},{\"end\":26912,\"start\":26911},{\"end\":26921,\"start\":26920},{\"end\":26927,\"start\":26926},{\"end\":26933,\"start\":26932},{\"end\":27261,\"start\":27260},{\"end\":27268,\"start\":27267},{\"end\":27275,\"start\":27274},{\"end\":27281,\"start\":27280},{\"end\":27459,\"start\":27458},{\"end\":27466,\"start\":27465},{\"end\":27473,\"start\":27472},{\"end\":27479,\"start\":27478},{\"end\":27485,\"start\":27484},{\"end\":27492,\"start\":27491},{\"end\":27793,\"start\":27792},{\"end\":27801,\"start\":27800},{\"end\":27808,\"start\":27807},{\"end\":27815,\"start\":27814},{\"end\":28044,\"start\":28043},{\"end\":28052,\"start\":28051},{\"end\":28060,\"start\":28059},{\"end\":28068,\"start\":28067},{\"end\":28074,\"start\":28073},{\"end\":28082,\"start\":28081},{\"end\":28090,\"start\":28089},{\"end\":28096,\"start\":28095},{\"end\":28375,\"start\":28374},{\"end\":28383,\"start\":28382},{\"end\":28390,\"start\":28389},{\"end\":28397,\"start\":28396},{\"end\":28591,\"start\":28590},{\"end\":28601,\"start\":28600},{\"end\":28613,\"start\":28612},{\"end\":28622,\"start\":28621},{\"end\":28893,\"start\":28892},{\"end\":28919,\"start\":28918},{\"end\":28928,\"start\":28927},{\"end\":28938,\"start\":28937},{\"end\":29290,\"start\":29289},{\"end\":29301,\"start\":29300},{\"end\":29309,\"start\":29308},{\"end\":29672,\"start\":29671},{\"end\":29683,\"start\":29682},{\"end\":29694,\"start\":29693},{\"end\":29707,\"start\":29706},{\"end\":29716,\"start\":29715},{\"end\":29725,\"start\":29724},{\"end\":29739,\"start\":29738},{\"end\":30185,\"start\":30184},{\"end\":30199,\"start\":30198},{\"end\":30209,\"start\":30208},{\"end\":30445,\"start\":30444},{\"end\":30454,\"start\":30453},{\"end\":30465,\"start\":30464},{\"end\":30476,\"start\":30475},{\"end\":30487,\"start\":30486},{\"end\":30697,\"start\":30696},{\"end\":30705,\"start\":30704},{\"end\":30713,\"start\":30712},{\"end\":30721,\"start\":30720},{\"end\":30727,\"start\":30726},{\"end\":30734,\"start\":30733},{\"end\":30740,\"start\":30739},{\"end\":31025,\"start\":31024},{\"end\":31037,\"start\":31036},{\"end\":31049,\"start\":31048},{\"end\":31056,\"start\":31055},{\"end\":31070,\"start\":31069},{\"end\":31079,\"start\":31078},{\"end\":31345,\"start\":31344},{\"end\":31351,\"start\":31350},{\"end\":31361,\"start\":31360},{\"end\":31601,\"start\":31600},{\"end\":31608,\"start\":31607},{\"end\":31616,\"start\":31615},{\"end\":31625,\"start\":31624},{\"end\":31633,\"start\":31632},{\"end\":31640,\"start\":31639},{\"end\":31907,\"start\":31906},{\"end\":31919,\"start\":31918},{\"end\":31931,\"start\":31930},{\"end\":31945,\"start\":31944},{\"end\":31952,\"start\":31951},{\"end\":31961,\"start\":31960},{\"end\":32209,\"start\":32208},{\"end\":32229,\"start\":32228},{\"end\":32238,\"start\":32237},{\"end\":32247,\"start\":32246},{\"end\":32471,\"start\":32470},{\"end\":32482,\"start\":32481},{\"end\":32496,\"start\":32495},{\"end\":32709,\"start\":32708},{\"end\":32720,\"start\":32719},{\"end\":32899,\"start\":32898},{\"end\":32908,\"start\":32907},{\"end\":32916,\"start\":32915},{\"end\":32923,\"start\":32922},{\"end\":32932,\"start\":32931},{\"end\":33139,\"start\":33138},{\"end\":33147,\"start\":33146},{\"end\":33155,\"start\":33154},{\"end\":33168,\"start\":33164},{\"end\":33174,\"start\":33173},{\"end\":33180,\"start\":33179},{\"end\":33614,\"start\":33613},{\"end\":33624,\"start\":33623},{\"end\":33639,\"start\":33638},{\"end\":33648,\"start\":33647},{\"end\":34130,\"start\":34129},{\"end\":34141,\"start\":34140},{\"end\":34152,\"start\":34151},{\"end\":34165,\"start\":34164},{\"end\":34171,\"start\":34170},{\"end\":34182,\"start\":34181},{\"end\":34190,\"start\":34189},{\"end\":34201,\"start\":34200},{\"end\":34210,\"start\":34209},{\"end\":34447,\"start\":34446},{\"end\":34460,\"start\":34459},{\"end\":34471,\"start\":34470},{\"end\":34482,\"start\":34481},{\"end\":34492,\"start\":34491},{\"end\":34846,\"start\":34845},{\"end\":34859,\"start\":34858},{\"end\":34870,\"start\":34869},{\"end\":34881,\"start\":34880},{\"end\":34891,\"start\":34890},{\"end\":35131,\"start\":35130},{\"end\":35137,\"start\":35136},{\"end\":35146,\"start\":35145},{\"end\":35387,\"start\":35380},{\"end\":35406,\"start\":35402},{\"end\":35415,\"start\":35411},{\"end\":35637,\"start\":35636},{\"end\":35647,\"start\":35646},{\"end\":35897,\"start\":35896},{\"end\":35905,\"start\":35904},{\"end\":35918,\"start\":35917},{\"end\":35928,\"start\":35927},{\"end\":36126,\"start\":36125},{\"end\":36137,\"start\":36136},{\"end\":36148,\"start\":36147},{\"end\":36161,\"start\":36160},{\"end\":36167,\"start\":36166},{\"end\":36175,\"start\":36174},{\"end\":36184,\"start\":36183},{\"end\":36195,\"start\":36194},{\"end\":36206,\"start\":36205},{\"end\":36568,\"start\":36567},{\"end\":36579,\"start\":36578},{\"end\":36590,\"start\":36589},{\"end\":36603,\"start\":36602},{\"end\":36609,\"start\":36608},{\"end\":36620,\"start\":36619},{\"end\":36630,\"start\":36629},{\"end\":36641,\"start\":36640},{\"end\":36650,\"start\":36649},{\"end\":36888,\"start\":36887},{\"end\":36896,\"start\":36895},{\"end\":36903,\"start\":36902},{\"end\":36912,\"start\":36911},{\"end\":36920,\"start\":36919},{\"end\":36929,\"start\":36928},{\"end\":37229,\"start\":37228},{\"end\":37239,\"start\":37238},{\"end\":37511,\"start\":37510},{\"end\":37519,\"start\":37518},{\"end\":37528,\"start\":37527},{\"end\":37797,\"start\":37796},{\"end\":37807,\"start\":37806},{\"end\":37822,\"start\":37821},{\"end\":37831,\"start\":37830},{\"end\":38032,\"start\":38031},{\"end\":38046,\"start\":38045},{\"end\":38063,\"start\":38062},{\"end\":38072,\"start\":38071},{\"end\":38078,\"start\":38077},{\"end\":38094,\"start\":38093},{\"end\":38103,\"start\":38102},{\"end\":38116,\"start\":38115},{\"end\":38401,\"start\":38400},{\"end\":38414,\"start\":38413},{\"end\":38426,\"start\":38425},{\"end\":38742,\"start\":38741},{\"end\":38751,\"start\":38750},{\"end\":38760,\"start\":38759},{\"end\":38773,\"start\":38772}]", "bib_author_last_name": "[{\"end\":25749,\"start\":25742},{\"end\":25757,\"start\":25753},{\"end\":25768,\"start\":25761},{\"end\":25776,\"start\":25772},{\"end\":26204,\"start\":26197},{\"end\":26212,\"start\":26208},{\"end\":26223,\"start\":26216},{\"end\":26231,\"start\":26227},{\"end\":26470,\"start\":26463},{\"end\":26486,\"start\":26474},{\"end\":26497,\"start\":26490},{\"end\":26732,\"start\":26730},{\"end\":26739,\"start\":26736},{\"end\":26747,\"start\":26743},{\"end\":26753,\"start\":26751},{\"end\":26909,\"start\":26906},{\"end\":26918,\"start\":26913},{\"end\":26924,\"start\":26922},{\"end\":26930,\"start\":26928},{\"end\":26937,\"start\":26934},{\"end\":27265,\"start\":27262},{\"end\":27272,\"start\":27269},{\"end\":27278,\"start\":27276},{\"end\":27286,\"start\":27282},{\"end\":27463,\"start\":27460},{\"end\":27470,\"start\":27467},{\"end\":27476,\"start\":27474},{\"end\":27482,\"start\":27480},{\"end\":27489,\"start\":27486},{\"end\":27497,\"start\":27493},{\"end\":27798,\"start\":27794},{\"end\":27805,\"start\":27802},{\"end\":27812,\"start\":27809},{\"end\":27821,\"start\":27816},{\"end\":28049,\"start\":28045},{\"end\":28057,\"start\":28053},{\"end\":28065,\"start\":28061},{\"end\":28071,\"start\":28069},{\"end\":28079,\"start\":28075},{\"end\":28087,\"start\":28083},{\"end\":28093,\"start\":28091},{\"end\":28100,\"start\":28097},{\"end\":28380,\"start\":28376},{\"end\":28387,\"start\":28384},{\"end\":28394,\"start\":28391},{\"end\":28407,\"start\":28398},{\"end\":28598,\"start\":28592},{\"end\":28610,\"start\":28602},{\"end\":28619,\"start\":28614},{\"end\":28645,\"start\":28623},{\"end\":28916,\"start\":28894},{\"end\":28925,\"start\":28920},{\"end\":28935,\"start\":28929},{\"end\":28947,\"start\":28939},{\"end\":29298,\"start\":29291},{\"end\":29306,\"start\":29302},{\"end\":29317,\"start\":29310},{\"end\":29680,\"start\":29673},{\"end\":29691,\"start\":29684},{\"end\":29704,\"start\":29695},{\"end\":29713,\"start\":29708},{\"end\":29722,\"start\":29717},{\"end\":29736,\"start\":29726},{\"end\":29746,\"start\":29740},{\"end\":30196,\"start\":30186},{\"end\":30206,\"start\":30200},{\"end\":30217,\"start\":30210},{\"end\":30451,\"start\":30446},{\"end\":30462,\"start\":30455},{\"end\":30473,\"start\":30466},{\"end\":30484,\"start\":30477},{\"end\":30493,\"start\":30488},{\"end\":30702,\"start\":30698},{\"end\":30710,\"start\":30706},{\"end\":30718,\"start\":30714},{\"end\":30724,\"start\":30722},{\"end\":30731,\"start\":30728},{\"end\":30737,\"start\":30735},{\"end\":30743,\"start\":30741},{\"end\":31034,\"start\":31026},{\"end\":31046,\"start\":31038},{\"end\":31053,\"start\":31050},{\"end\":31067,\"start\":31057},{\"end\":31076,\"start\":31071},{\"end\":31085,\"start\":31080},{\"end\":31348,\"start\":31346},{\"end\":31358,\"start\":31352},{\"end\":31369,\"start\":31362},{\"end\":31605,\"start\":31602},{\"end\":31613,\"start\":31609},{\"end\":31622,\"start\":31617},{\"end\":31630,\"start\":31626},{\"end\":31637,\"start\":31634},{\"end\":31647,\"start\":31641},{\"end\":31916,\"start\":31908},{\"end\":31928,\"start\":31920},{\"end\":31942,\"start\":31932},{\"end\":31949,\"start\":31946},{\"end\":31958,\"start\":31953},{\"end\":31967,\"start\":31962},{\"end\":32226,\"start\":32210},{\"end\":32235,\"start\":32230},{\"end\":32244,\"start\":32239},{\"end\":32256,\"start\":32248},{\"end\":32479,\"start\":32472},{\"end\":32493,\"start\":32483},{\"end\":32503,\"start\":32497},{\"end\":32717,\"start\":32710},{\"end\":32730,\"start\":32721},{\"end\":32905,\"start\":32900},{\"end\":32913,\"start\":32909},{\"end\":32920,\"start\":32917},{\"end\":32929,\"start\":32924},{\"end\":32939,\"start\":32933},{\"end\":33144,\"start\":33140},{\"end\":33152,\"start\":33148},{\"end\":33162,\"start\":33156},{\"end\":33171,\"start\":33169},{\"end\":33177,\"start\":33175},{\"end\":33188,\"start\":33181},{\"end\":33621,\"start\":33615},{\"end\":33636,\"start\":33625},{\"end\":33645,\"start\":33640},{\"end\":33655,\"start\":33649},{\"end\":34138,\"start\":34131},{\"end\":34149,\"start\":34142},{\"end\":34162,\"start\":34153},{\"end\":34168,\"start\":34166},{\"end\":34179,\"start\":34172},{\"end\":34187,\"start\":34183},{\"end\":34198,\"start\":34191},{\"end\":34207,\"start\":34202},{\"end\":34215,\"start\":34211},{\"end\":34457,\"start\":34448},{\"end\":34468,\"start\":34461},{\"end\":34479,\"start\":34472},{\"end\":34489,\"start\":34483},{\"end\":34499,\"start\":34493},{\"end\":34856,\"start\":34847},{\"end\":34867,\"start\":34860},{\"end\":34878,\"start\":34871},{\"end\":34888,\"start\":34882},{\"end\":34898,\"start\":34892},{\"end\":35134,\"start\":35132},{\"end\":35143,\"start\":35138},{\"end\":35152,\"start\":35147},{\"end\":35400,\"start\":35388},{\"end\":35409,\"start\":35407},{\"end\":35424,\"start\":35416},{\"end\":35429,\"start\":35426},{\"end\":35644,\"start\":35638},{\"end\":35655,\"start\":35648},{\"end\":35902,\"start\":35898},{\"end\":35915,\"start\":35906},{\"end\":35925,\"start\":35919},{\"end\":35933,\"start\":35929},{\"end\":36134,\"start\":36127},{\"end\":36145,\"start\":36138},{\"end\":36158,\"start\":36149},{\"end\":36164,\"start\":36162},{\"end\":36172,\"start\":36168},{\"end\":36181,\"start\":36176},{\"end\":36192,\"start\":36185},{\"end\":36203,\"start\":36196},{\"end\":36213,\"start\":36207},{\"end\":36576,\"start\":36569},{\"end\":36587,\"start\":36580},{\"end\":36600,\"start\":36591},{\"end\":36606,\"start\":36604},{\"end\":36617,\"start\":36610},{\"end\":36627,\"start\":36621},{\"end\":36638,\"start\":36631},{\"end\":36647,\"start\":36642},{\"end\":36655,\"start\":36651},{\"end\":36893,\"start\":36889},{\"end\":36900,\"start\":36897},{\"end\":36909,\"start\":36904},{\"end\":36917,\"start\":36913},{\"end\":36926,\"start\":36921},{\"end\":36934,\"start\":36930},{\"end\":37236,\"start\":37230},{\"end\":37247,\"start\":37240},{\"end\":37516,\"start\":37512},{\"end\":37525,\"start\":37520},{\"end\":37536,\"start\":37529},{\"end\":37804,\"start\":37798},{\"end\":37819,\"start\":37808},{\"end\":37828,\"start\":37823},{\"end\":37838,\"start\":37832},{\"end\":38043,\"start\":38033},{\"end\":38060,\"start\":38047},{\"end\":38069,\"start\":38064},{\"end\":38075,\"start\":38073},{\"end\":38091,\"start\":38079},{\"end\":38100,\"start\":38095},{\"end\":38113,\"start\":38104},{\"end\":38123,\"start\":38117},{\"end\":38411,\"start\":38402},{\"end\":38423,\"start\":38415},{\"end\":38436,\"start\":38427},{\"end\":38748,\"start\":38743},{\"end\":38757,\"start\":38752},{\"end\":38770,\"start\":38761},{\"end\":38781,\"start\":38774}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":2814088},\"end\":26149,\"start\":25665},{\"attributes\":{\"doi\":\"arXiv:1406.5266\",\"id\":\"b1\"},\"end\":26393,\"start\":26151},{\"attributes\":{\"doi\":\"arXiv:1503.03832\",\"id\":\"b2\"},\"end\":26683,\"start\":26395},{\"attributes\":{\"doi\":\"arXiv:1411.7923\",\"id\":\"b3\"},\"end\":26902,\"start\":26685},{\"attributes\":{\"doi\":\"arXiv:1607.08221\",\"id\":\"b4\"},\"end\":27197,\"start\":26904},{\"attributes\":{\"doi\":\"arXiv:1612.02295\",\"id\":\"b5\"},\"end\":27456,\"start\":27199},{\"attributes\":{\"doi\":\"arXiv:1704.08063\",\"id\":\"b6\"},\"end\":27743,\"start\":27458},{\"attributes\":{\"doi\":\"arXiv:1801.05599\",\"id\":\"b7\"},\"end\":27980,\"start\":27745},{\"attributes\":{\"doi\":\"arXiv:1801.09414\",\"id\":\"b8\"},\"end\":28307,\"start\":27982},{\"attributes\":{\"doi\":\"arXiv:1801.07698\",\"id\":\"b9\"},\"end\":28588,\"start\":28309},{\"attributes\":{\"doi\":\"arXiv:1505.02108\",\"id\":\"b10\"},\"end\":28890,\"start\":28590},{\"attributes\":{\"doi\":\"arXiv:1512.00596\",\"id\":\"b11\"},\"end\":29219,\"start\":28892},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":196052024},\"end\":29512,\"start\":29221},{\"attributes\":{\"id\":\"b13\"},\"end\":29669,\"start\":29514},{\"attributes\":{\"doi\":\"arXiv:1312.6199\",\"id\":\"b14\"},\"end\":29991,\"start\":29671},{\"attributes\":{\"id\":\"b15\"},\"end\":30134,\"start\":29993},{\"attributes\":{\"doi\":\"arXiv:1412.6572\",\"id\":\"b16\"},\"end\":30378,\"start\":30136},{\"attributes\":{\"doi\":\"arXiv:1706.06083\",\"id\":\"b17\"},\"end\":30692,\"start\":30380},{\"attributes\":{\"doi\":\"arXiv:1710.06081\",\"id\":\"b18\"},\"end\":30964,\"start\":30694},{\"attributes\":{\"doi\":\"arXiv:1511.07528\",\"id\":\"b19\"},\"end\":31291,\"start\":30966},{\"attributes\":{\"doi\":\"arXiv:1710.08864\",\"id\":\"b20\"},\"end\":31529,\"start\":31293},{\"attributes\":{\"doi\":\"arXiv:1703.08603\",\"id\":\"b21\"},\"end\":31850,\"start\":31531},{\"attributes\":{\"doi\":\"arXiv:1602.02697\",\"id\":\"b22\"},\"end\":32169,\"start\":31852},{\"attributes\":{\"doi\":\"arXiv:1610.08401\",\"id\":\"b23\"},\"end\":32424,\"start\":32171},{\"attributes\":{\"doi\":\"arXiv:1607.02533\",\"id\":\"b24\"},\"end\":32664,\"start\":32426},{\"attributes\":{\"doi\":\"arXiv:1707.07397\",\"id\":\"b25\"},\"end\":32877,\"start\":32666},{\"attributes\":{\"doi\":\"arXiv:1712.09665\",\"id\":\"b26\"},\"end\":33083,\"start\":32879},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":57246310},\"end\":33524,\"start\":33085},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":207241700},\"end\":34072,\"start\":33526},{\"attributes\":{\"doi\":\"arXiv:1707.08945\",\"id\":\"b29\"},\"end\":34444,\"start\":34074},{\"attributes\":{\"doi\":\"arXiv:1801.02780\",\"id\":\"b30\"},\"end\":34792,\"start\":34446},{\"attributes\":{\"doi\":\"arXiv:1802.06430\",\"id\":\"b31\"},\"end\":35086,\"start\":34794},{\"attributes\":{\"doi\":\"arXiv:1712.02494\",\"id\":\"b32\"},\"end\":35298,\"start\":35088},{\"attributes\":{\"doi\":\"arXiv:1506.01497\",\"id\":\"b33\"},\"end\":35634,\"start\":35300},{\"attributes\":{\"doi\":\"arXiv:1612.08242\",\"id\":\"b34\"},\"end\":35826,\"start\":35636},{\"attributes\":{\"doi\":\"arXiv:1804.05810\",\"id\":\"b35\"},\"end\":36123,\"start\":35828},{\"attributes\":{\"doi\":\"arXiv:1712.08062\",\"id\":\"b36\"},\"end\":36513,\"start\":36125},{\"attributes\":{\"doi\":\"arXiv:1807.07769\",\"id\":\"b37\"},\"end\":36885,\"start\":36515},{\"attributes\":{\"doi\":\"arXiv:1812.10217\",\"id\":\"b38\"},\"end\":37226,\"start\":36887},{\"attributes\":{\"doi\":\"arXiv:1804.02767\",\"id\":\"b39\"},\"end\":37420,\"start\":37228},{\"attributes\":{\"doi\":\"arXiv:1904.08653\",\"id\":\"b40\"},\"end\":37732,\"start\":37422},{\"attributes\":{\"doi\":\"arXiv:1801.00349\",\"id\":\"b41\"},\"end\":38027,\"start\":37734},{\"attributes\":{\"doi\":\"arXiv:1406.2661\",\"id\":\"b42\"},\"end\":38368,\"start\":38029},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":6099034},\"end\":38643,\"start\":38370},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":2541311},\"end\":39031,\"start\":38645}]", "bib_title": "[{\"end\":25738,\"start\":25665},{\"end\":29287,\"start\":29221},{\"end\":33136,\"start\":33085},{\"end\":33611,\"start\":33526},{\"end\":38398,\"start\":38370},{\"end\":38739,\"start\":38645}]", "bib_author": "[{\"end\":25751,\"start\":25740},{\"end\":25759,\"start\":25751},{\"end\":25770,\"start\":25759},{\"end\":25778,\"start\":25770},{\"end\":26206,\"start\":26195},{\"end\":26214,\"start\":26206},{\"end\":26225,\"start\":26214},{\"end\":26233,\"start\":26225},{\"end\":26472,\"start\":26461},{\"end\":26488,\"start\":26472},{\"end\":26499,\"start\":26488},{\"end\":26734,\"start\":26728},{\"end\":26741,\"start\":26734},{\"end\":26749,\"start\":26741},{\"end\":26755,\"start\":26749},{\"end\":26911,\"start\":26904},{\"end\":26920,\"start\":26911},{\"end\":26926,\"start\":26920},{\"end\":26932,\"start\":26926},{\"end\":26939,\"start\":26932},{\"end\":27267,\"start\":27260},{\"end\":27274,\"start\":27267},{\"end\":27280,\"start\":27274},{\"end\":27288,\"start\":27280},{\"end\":27465,\"start\":27458},{\"end\":27472,\"start\":27465},{\"end\":27478,\"start\":27472},{\"end\":27484,\"start\":27478},{\"end\":27491,\"start\":27484},{\"end\":27499,\"start\":27491},{\"end\":27800,\"start\":27792},{\"end\":27807,\"start\":27800},{\"end\":27814,\"start\":27807},{\"end\":27823,\"start\":27814},{\"end\":28051,\"start\":28043},{\"end\":28059,\"start\":28051},{\"end\":28067,\"start\":28059},{\"end\":28073,\"start\":28067},{\"end\":28081,\"start\":28073},{\"end\":28089,\"start\":28081},{\"end\":28095,\"start\":28089},{\"end\":28102,\"start\":28095},{\"end\":28382,\"start\":28374},{\"end\":28389,\"start\":28382},{\"end\":28396,\"start\":28389},{\"end\":28409,\"start\":28396},{\"end\":28600,\"start\":28590},{\"end\":28612,\"start\":28600},{\"end\":28621,\"start\":28612},{\"end\":28647,\"start\":28621},{\"end\":28918,\"start\":28892},{\"end\":28927,\"start\":28918},{\"end\":28937,\"start\":28927},{\"end\":28949,\"start\":28937},{\"end\":29300,\"start\":29289},{\"end\":29308,\"start\":29300},{\"end\":29319,\"start\":29308},{\"end\":29682,\"start\":29671},{\"end\":29693,\"start\":29682},{\"end\":29706,\"start\":29693},{\"end\":29715,\"start\":29706},{\"end\":29724,\"start\":29715},{\"end\":29738,\"start\":29724},{\"end\":29748,\"start\":29738},{\"end\":30198,\"start\":30184},{\"end\":30208,\"start\":30198},{\"end\":30219,\"start\":30208},{\"end\":30453,\"start\":30444},{\"end\":30464,\"start\":30453},{\"end\":30475,\"start\":30464},{\"end\":30486,\"start\":30475},{\"end\":30495,\"start\":30486},{\"end\":30704,\"start\":30696},{\"end\":30712,\"start\":30704},{\"end\":30720,\"start\":30712},{\"end\":30726,\"start\":30720},{\"end\":30733,\"start\":30726},{\"end\":30739,\"start\":30733},{\"end\":30745,\"start\":30739},{\"end\":31036,\"start\":31024},{\"end\":31048,\"start\":31036},{\"end\":31055,\"start\":31048},{\"end\":31069,\"start\":31055},{\"end\":31078,\"start\":31069},{\"end\":31087,\"start\":31078},{\"end\":31350,\"start\":31344},{\"end\":31360,\"start\":31350},{\"end\":31371,\"start\":31360},{\"end\":31607,\"start\":31600},{\"end\":31615,\"start\":31607},{\"end\":31624,\"start\":31615},{\"end\":31632,\"start\":31624},{\"end\":31639,\"start\":31632},{\"end\":31649,\"start\":31639},{\"end\":31918,\"start\":31906},{\"end\":31930,\"start\":31918},{\"end\":31944,\"start\":31930},{\"end\":31951,\"start\":31944},{\"end\":31960,\"start\":31951},{\"end\":31969,\"start\":31960},{\"end\":32228,\"start\":32208},{\"end\":32237,\"start\":32228},{\"end\":32246,\"start\":32237},{\"end\":32258,\"start\":32246},{\"end\":32481,\"start\":32470},{\"end\":32495,\"start\":32481},{\"end\":32505,\"start\":32495},{\"end\":32719,\"start\":32708},{\"end\":32732,\"start\":32719},{\"end\":32907,\"start\":32898},{\"end\":32915,\"start\":32907},{\"end\":32922,\"start\":32915},{\"end\":32931,\"start\":32922},{\"end\":32941,\"start\":32931},{\"end\":33146,\"start\":33138},{\"end\":33154,\"start\":33146},{\"end\":33164,\"start\":33154},{\"end\":33173,\"start\":33164},{\"end\":33179,\"start\":33173},{\"end\":33190,\"start\":33179},{\"end\":33623,\"start\":33613},{\"end\":33638,\"start\":33623},{\"end\":33647,\"start\":33638},{\"end\":33657,\"start\":33647},{\"end\":34140,\"start\":34129},{\"end\":34151,\"start\":34140},{\"end\":34164,\"start\":34151},{\"end\":34170,\"start\":34164},{\"end\":34181,\"start\":34170},{\"end\":34189,\"start\":34181},{\"end\":34200,\"start\":34189},{\"end\":34209,\"start\":34200},{\"end\":34217,\"start\":34209},{\"end\":34459,\"start\":34446},{\"end\":34470,\"start\":34459},{\"end\":34481,\"start\":34470},{\"end\":34491,\"start\":34481},{\"end\":34501,\"start\":34491},{\"end\":34858,\"start\":34845},{\"end\":34869,\"start\":34858},{\"end\":34880,\"start\":34869},{\"end\":34890,\"start\":34880},{\"end\":34900,\"start\":34890},{\"end\":35136,\"start\":35130},{\"end\":35145,\"start\":35136},{\"end\":35154,\"start\":35145},{\"end\":35402,\"start\":35380},{\"end\":35411,\"start\":35402},{\"end\":35426,\"start\":35411},{\"end\":35431,\"start\":35426},{\"end\":35646,\"start\":35636},{\"end\":35657,\"start\":35646},{\"end\":35904,\"start\":35896},{\"end\":35917,\"start\":35904},{\"end\":35927,\"start\":35917},{\"end\":35935,\"start\":35927},{\"end\":36136,\"start\":36125},{\"end\":36147,\"start\":36136},{\"end\":36160,\"start\":36147},{\"end\":36166,\"start\":36160},{\"end\":36174,\"start\":36166},{\"end\":36183,\"start\":36174},{\"end\":36194,\"start\":36183},{\"end\":36205,\"start\":36194},{\"end\":36215,\"start\":36205},{\"end\":36578,\"start\":36567},{\"end\":36589,\"start\":36578},{\"end\":36602,\"start\":36589},{\"end\":36608,\"start\":36602},{\"end\":36619,\"start\":36608},{\"end\":36629,\"start\":36619},{\"end\":36640,\"start\":36629},{\"end\":36649,\"start\":36640},{\"end\":36657,\"start\":36649},{\"end\":36895,\"start\":36887},{\"end\":36902,\"start\":36895},{\"end\":36911,\"start\":36902},{\"end\":36919,\"start\":36911},{\"end\":36928,\"start\":36919},{\"end\":36936,\"start\":36928},{\"end\":37238,\"start\":37228},{\"end\":37249,\"start\":37238},{\"end\":37518,\"start\":37510},{\"end\":37527,\"start\":37518},{\"end\":37538,\"start\":37527},{\"end\":37806,\"start\":37796},{\"end\":37821,\"start\":37806},{\"end\":37830,\"start\":37821},{\"end\":37840,\"start\":37830},{\"end\":38045,\"start\":38031},{\"end\":38062,\"start\":38045},{\"end\":38071,\"start\":38062},{\"end\":38077,\"start\":38071},{\"end\":38093,\"start\":38077},{\"end\":38102,\"start\":38093},{\"end\":38115,\"start\":38102},{\"end\":38125,\"start\":38115},{\"end\":38413,\"start\":38400},{\"end\":38425,\"start\":38413},{\"end\":38438,\"start\":38425},{\"end\":38750,\"start\":38741},{\"end\":38759,\"start\":38750},{\"end\":38772,\"start\":38759},{\"end\":38783,\"start\":38772}]", "bib_venue": "[{\"end\":25919,\"start\":25857},{\"end\":33313,\"start\":33260},{\"end\":33814,\"start\":33744},{\"end\":38816,\"start\":38808},{\"end\":25855,\"start\":25778},{\"end\":26193,\"start\":26151},{\"end\":26459,\"start\":26395},{\"end\":26726,\"start\":26685},{\"end\":27024,\"start\":26955},{\"end\":27258,\"start\":27199},{\"end\":27574,\"start\":27515},{\"end\":27790,\"start\":27745},{\"end\":28041,\"start\":27982},{\"end\":28372,\"start\":28309},{\"end\":28713,\"start\":28663},{\"end\":29029,\"start\":28965},{\"end\":29351,\"start\":29319},{\"end\":29571,\"start\":29514},{\"end\":29803,\"start\":29763},{\"end\":30054,\"start\":29993},{\"end\":30182,\"start\":30136},{\"end\":30442,\"start\":30380},{\"end\":30803,\"start\":30761},{\"end\":31022,\"start\":30966},{\"end\":31342,\"start\":31293},{\"end\":31598,\"start\":31531},{\"end\":31904,\"start\":31852},{\"end\":32206,\"start\":32171},{\"end\":32468,\"start\":32426},{\"end\":32706,\"start\":32666},{\"end\":32896,\"start\":32879},{\"end\":33258,\"start\":33190},{\"end\":33742,\"start\":33657},{\"end\":34127,\"start\":34074},{\"end\":34593,\"start\":34517},{\"end\":34843,\"start\":34794},{\"end\":35128,\"start\":35088},{\"end\":35378,\"start\":35300},{\"end\":35707,\"start\":35673},{\"end\":35894,\"start\":35828},{\"end\":36291,\"start\":36231},{\"end\":36565,\"start\":36515},{\"end\":37029,\"start\":36952},{\"end\":37299,\"start\":37265},{\"end\":37508,\"start\":37422},{\"end\":37794,\"start\":37734},{\"end\":38171,\"start\":38140},{\"end\":38487,\"start\":38438},{\"end\":38806,\"start\":38783}]"}}}, "year": 2023, "month": 12, "day": 17}