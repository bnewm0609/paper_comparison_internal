{"id": 252972804, "updated": "2023-01-27 06:32:11.729", "metadata": {"title": "Generative and reinforcement learning approaches for the automated de novo design of bioactive compounds", "authors": "[{\"first\":\"Maria\",\"last\":\"Korshunova\",\"middle\":[]},{\"first\":\"Niles\",\"last\":\"Huang\",\"middle\":[]},{\"first\":\"Stephen\",\"last\":\"Capuzzi\",\"middle\":[]},{\"first\":\"Dmytro\",\"last\":\"Radchenko\",\"middle\":[\"S.\"]},{\"first\":\"Olena\",\"last\":\"Savych\",\"middle\":[]},{\"first\":\"Yuriy\",\"last\":\"Moroz\",\"middle\":[\"S.\"]},{\"first\":\"Carrow\",\"last\":\"Wells\",\"middle\":[\"I.\"]},{\"first\":\"Timothy\",\"last\":\"Willson\",\"middle\":[\"M.\"]},{\"first\":\"Alexander\",\"last\":\"Tropsha\",\"middle\":[]},{\"first\":\"Olexandr\",\"last\":\"Isayev\",\"middle\":[]}]", "venue": "Communications Chemistry", "journal": "Communications Chemistry", "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "Deep generative neural networks have been used increasingly in computational chemistry for de novo design of molecules with desired properties. Many deep learning approaches employ reinforcement learning for optimizing the target properties of the generated molecules. However, the success of this approach is often hampered by the problem of sparse rewards as the majority of the generated molecules are expectedly predicted as inactives. We propose several technical innovations to address this problem and improve the balance between exploration and exploitation modes in reinforcement learning. In a proof-of-concept study, we demonstrate the application of the deep generative recurrent neural network architecture enhanced by several proposed technical tricks to design inhibitors of the epidermal growth factor (EGFR) and further experimentally validate their potency. The proposed technical solutions are expected to substantially improve the success rate of finding novel bioactive compounds for specific biological targets using generative and reinforcement learning approaches.", "fields_of_study": null, "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": "9814657", "dblp": null, "doi": "10.1038/s42004-022-00733-0"}}, "content": {"source": {"pdf_hash": "a1ec530dc3b89a75406646913e67be39d46b690c", "pdf_src": "PubMedCentral", "pdf_uri": null, "oa_url_match": false, "oa_info": {"license": "CCBY", "open_access_url": "https://www.nature.com/articles/s42004-022-00733-0.pdf", "status": "GOLD"}}, "grobid": {"id": "c7b8c35325b9718b4b54d3433e776bfead0d75ac", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/a1ec530dc3b89a75406646913e67be39d46b690c.txt", "contents": "\nGenerative and reinforcement learning approaches for the automated de novo design of bioactive compounds Supplementary material\n\n\nMaria Korshunova \nDepartment of Chemistry\nMellon College of Science\nCarnegie Mellon University\nPittsburghPennsylvaniaUnited States of America\n\nComputational Biology Department\nSchool of Computer Science\nCarnegie Mellon University\nPittsburghPennsylvaniaUnited States of America\n\nNiles Huang \nDepartment of Biochemistry\nUniversity of Oxford\nOxfordUnited Kingdom\n\nStephen Capuzzi \nLaboratory for Molecular Modeling\nUNC Eshelman School of Pharmacy\nUniversity of North Carolina at Chapel Hill\nChapel Hill\n\nNorth Carolina\nUnited States of America\n\nDmytro S Radchenko \nEnamine Ltd\n78 Chervonotkatska Street02094Ukraine\n\nTaras Shevchenko National University of Kyiv\nVolodymyrska Street 6001601KyivUkraine\n\nOlena Savych \nEnamine Ltd\n78 Chervonotkatska Street02094Ukraine\n\nYuriy S Moroz \nTaras Shevchenko National University of Kyiv\nVolodymyrska Street 6001601KyivUkraine\n\nChemspace LLC\nChervonotkatska Street 85, Suite 102094KyivUkraine\n\nCarrow I Wells \nStructual Genomics Consortium\nUNC Eshelman School of Pharmacy\nUniversity of North Carolina at Chapel Hill\nChapel Hill\n\nNorth Carolina\nUnited States of America\n\nTimothy M Willson \nStructual Genomics Consortium\nUNC Eshelman School of Pharmacy\nUniversity of North Carolina at Chapel Hill\nChapel Hill\n\nNorth Carolina\nUnited States of America\n\nAlexander Tropsha \nLaboratory for Molecular Modeling\nUNC Eshelman School of Pharmacy\nUniversity of North Carolina at Chapel Hill\nChapel Hill\n\nNorth Carolina\nUnited States of America\n\nOlexandr Isayev olexandr@olexandrisayev.com \nDepartment of Chemistry\nMellon College of Science\nCarnegie Mellon University\nPittsburghPennsylvaniaUnited States of America\n\nComputational Biology Department\nSchool of Computer Science\nCarnegie Mellon University\nPittsburghPennsylvaniaUnited States of America\n\nGenerative and reinforcement learning approaches for the automated de novo design of bioactive compounds Supplementary material\n* Correspondence: (O.I.)\n\n\nEnzyme inhibition in the presence of 10 \u00b5M ATP.\n\nQED score distributions Figure S1. Distributions of QED score for molecules from various sourcesgenerated with model pre-trained on ChEMBL, ChEMBL, Enamine REAL, DrugBank. Each distribution is computed based on 10000 randomly sampled molecules Summary of replay trick results, extended Figure S2. Combined effects of fine-tuning and reinforcement learning. Models were trained for 20 epochs for nine different combinations of fine-tuning and experience replay with the following options: no fine-tuning, 20 iterations of fine-tuning, or 100 iterations of fine-tuning; and no experience replay, 10 iterations of experience replay, and 20 iterations of experience replay. The number of policy gradient steps was adjusted so that each training epoch had 25 iterations of replay and policy gradient (e.g. 25 policy steps for 0 replay steps and 15 policy steps for 10 replay steps).\n\n\nReplay ratio benchmark\n\nModels were trained with experience replay only. Each training condition used 25 iterations policy steps: either 25 and 0, 5 and 20, 10 and 15, 15 and 10, or 20 and 5 iterations of policy gradient and experience replay, respectively. Similar to the fine-tuning benchmark, the model with no experience replay (25 and 0 iterations of policy gradient and experience replay, respectively) fails to generate active molecules and maintains a high valid fraction. Inclusion of experience replay results in successful learning with simultaneous decrease in valid fraction. Unlike the fine-tuning benchmark however, the number of experience replay steps does not have a clear effect on model quality. In these experiments, model quality is largely determined by the presence or absence of experience replay steps. \n\n\nVarying replay ratio, with fine-tuning kept constant\n\nTo see how fine-tuning and experience replay interact, models were trained with both techniques. Each training condition used 20 iterations of fine-tuning and 25 iterations policy steps: either 25 and 0, 5 and 20, 10 and 15, 15 and 10, or 20 and 5 iterations of policy gradient and experience replay, respectively. Unlike the experiment with experience replay and no fine-tuning, this experiment shows a graded response to the number of experience replay steps. The condition with no experience replay steps performs worst, with the lowest active fraction and severe overfitting, as indicated by a low valid fraction. The condition with 5 replay steps and 20 policy gradient steps produces both higher valid and active fractions. The other three conditions perform even better, although the differences between them are small. \n\n\nReplay library\n\nThe most common scaffolds in the replay libraries used for training are shown below. The generated actives library consists of molecules generated by the pre-trained model. 160,000 molecules were generated by the ChEMBL-trained molecule, and 216 molecules had non-zero predicted activities against EGFR. These molecules were admitted into the generated actives library. This library has a high proportion of quinazoline scaffolds, as well as a smaller proportion of thiophene-fused rings. The Enamine replay library consists of molecules from the Enamine kinase library. We first selected molecules with nonzero activities against EGFR, as predicted by the random forest ensemble. We then filtered these molecules to remove Murcko scaffolds present in the experimental EGFR library. This step ensured that the replay buffer molecules were dissimilar from molecules known to be active. The final Enamine replay library had 219 molecules. This library has a high enrichment of thiophene-fused rings. This is likely because the filtration step removes molecules with quinazoline scaffolds known to be active; nevertheless, even the nonfiltered Enamine library has a high occurrence of thiophene-fused rings. Figure S5. The 12 most common Murcko scaffolds for replay libraries used in training. Two replay libraries were used in training: a generated actives library, and an Enamine replay library. Scaffolds are sorted with decreasing counts from left to right, then from top to bottom. The most common scaffolds had counts and percentages as follows: 22 out of 216 predicted active molecules (10.2%) for the generated actives library, and 11 out of 219 (5.02%) for the Enamine replay library.\n\n\nReplay buffer similarity distributions\n\nModels were trained using one of three replay libraries: an empty replay library (empty buffer), the replay library from the model (generated actives), and the enamine library selected as above (Enamine). The distributions of Tanimoto fingerprint similarities for the active molecules (probability exceeding 0.75) of each library are shown below. The generated libraries for the empty buffer and the Enamine replay buffer have high similarities, which suggests some degree of overfitting. \n\n\nTimelapsed evolution of libraries\n\nTo investigate the progress of model training, we modified the training procedure to produce 'snapshot' libraries of 16,000 molecules every 2 epochs for 20 epochs of training. The distributions of similarities were then calculated for each library. Over training, the generated libraries have higher similarities. As the model learns to generate active molecules, it generates molecules from a restricted chemical space of active molecules. \n\n\nNumber of iterations\n\nModels were trained for different numbers of epochs to see how the model behaves in response to overtraining. The model was trained with 20 iterations of fine-tuning, 15 iterations of policy gradient, and 10 iterations of experience replay, for either 10, 20, 50, or 100 epochs. The model learns significantly by 20 epochs, and further training steps gradually show reduced margins for active fraction. Interestingly, the model maintains high valid fraction and active fraction at high epochs, suggesting that the model is robust to training steps. Figure S8. Evolution of active and valid fractions over training. Each training condition used 15 iterations of policy gradient, 10 iterations of experience replay, and 20 iterations of fine-tuning per epoch. Models were trained for 10, 20, 50, or 100 epochs. Solid lines represent training, small dots represent data at each epoch, and large dots represent data from the fully-trained model.\n\nFigure S3 .\nS3Evolution of active and valid fractions over training. Each training condition used 25 policy steps per epoch: either 25 and 0, 5 and 20, 10 and 15, 15 and 10, or 20 and 5 iterations of policy gradient and experience replay, respectively. Solid lines represent training, small dots represent data at each epoch, and large dots represent data from the fully-trained model. Graphs are color-coded by the number of experience replay steps used per epoch.\n\nFigure S4 .\nS4Evolution of active and valid fractions over training. Each training condition used 20 iterations of fine-tuning and 25 policy steps per epoch: either 25 and 0, 5 and 20, 10 and 15, 15 and 10, or 20 and 5 iterations of policy gradient and experience replay, respectively. Solid lines represent training, small dots represent data at each epoch, and large dots represent data from the fully-trained model. Graphs are colorcoded by the number of experience replay steps used per epoch.\n\nFigure S6 .\nS6Distributions of Tanimoto similarities for libraries generated after training on different replay buffers. Distribution means are marked by vertical solid lines, and distribution standard deviations from the mean are marked by vertical dashed lines. The distribution of pairwise fingerprint similarities provide a global picture of library diversity. The distribution of maximum fingerprint similarities represents the distribution of nearest neighbors and informs on the local density around each molecule.\n\nFigure S7 .\nS7Distributions of Tanimoto similarities for libraries generated after different points in training. Models were trained for 20 epochs, with 15 iterations of policy gradient, 10 iterations of experience replay, and 20 iterations of fine-tuning per epoch. Distribution means are marked by vertical solid lines, and distribution standard deviations from the mean are marked by vertical dashed lines. The distribution of pairwise fingerprint similarities provide a global picture of library diversity. The distribution of maximum fingerprint similarities represents the distribution of nearest neighbors and informs on the local density around each molecule.\n\nTable S1 .\nS1EGFR enzyme inhibition of 4-anilinoquinazolinesEnzyme inhibition in the presence of 10 \u00b5M ATP. -, not tested due to poor solubility.Predicted actives \n\nCompound 5 \n6 \n7 8 3' \n4' \n5' \n\nEGFR \n% I at \n1 \u00b5M \n\nEGFR \npIC50 \n\nZINC000092611293 \n\nH \nF \nH H H F \nH \n12 \n\nZINC000000099087 \n\nH \nBr \nH H H F \nH \n96 \n7.5 \n\nZINC000302791534 \n\nH \nH \nH F Cl NH2 \nCl \n47 \n5.9 \n\nZINC000301931984 \n\nH \nF \nH H Cl NH2 \nCl \n89 \n7.4 \n\nZINC000480349471 \n\nF \nH \nH H F CH3 \nH \n83 \n6.7 \n\nZINC000302555896 \n\nH OCH3 F H F OCH2CH2OCH3 \nH \n12 \n\nZINC000480418233 \n\nF \nH \nH H F OCH2CH2OCH3 \nH \n8 \n\nZINC000605398532 \n\nH \nH \nCl H H OCH2CH(OH)(CH3)2 \nH \n18 \n\nZINC000301175853 \n\nH \nH \nCl H H OCH2CH2CONHCH3 \nH \n12 \n\nZINC000301950472 \n\nH \nF \nH H H CH2CH2N(CH3)2 \nH \n10 \n\nZINC000301275665 \n\nH \nH \nCl H H CH2N(Ac)cPr \nH \n-\n\nZINC000041479925 \n\nH \nF \nH H H N(CH2CH2CH2CH2) \nH \n8 \n\nZINC000089266948 \n\nH \nF \nH H H N(CH2CH2CH(N(CH3)2)CH2CH2) \nH \n14 \n\nZINC000302845052 \n\nH \nH \nH F H N(CH2CH2CH(N(CH3)2)CH2CH2) \nH \n12 \n\nZINC000301979927 \n\nH \nBr \nH H H N(CH2CH2CH(N(CH3)2)CH2CH2) \nH \n8 \n\nZINC000261436963 \n\nH \nBr \nH H H N(CH2CH2CH(CONH2)CH2CH2) \nH \n-\n\nZINC000737413605 \n\nH \nBr \nH H H N(CH2CH2CH(CH2N(CH3)2)CH2CH2) H \n14 \n\nStaurosporine \n\n100 \n7.1 \n\nPredicted inactives \n\nCompound 5 \n6 \n7 8 3' \n4' \n5' \n\nEGFR % \nI at 1 \n\u00b5M \n\nEGFR \npIC50 \n\nZINC000572311742 \n\nH \nH \nCl H H OCH2CH2CH2OH \nH \n0 \n\nZINC000302873009 \n\nH \nH \nH F Cl OCH2CH2OCH3 \nH \n16 \n\nZINC000440544230 \n\nH \nF \nH H H O(cC6H10-2-OH) \nH \n4 \n\nZINC000594704454 \n\nH \nCl \nH H H CH2CH2N(CH3)2 \nH \n8 \n\nZINC000112964683 \n\nH \nBr \nH H H N(CH2CH2CH(OH)CH2CH2) \nH \n10 \n\n\n", "annotations": {"author": "[{\"end\":408,\"start\":131},{\"end\":491,\"start\":409},{\"end\":672,\"start\":492},{\"end\":828,\"start\":673},{\"end\":893,\"start\":829},{\"end\":1059,\"start\":894},{\"end\":1235,\"start\":1060},{\"end\":1414,\"start\":1236},{\"end\":1597,\"start\":1415},{\"end\":1902,\"start\":1598}]", "publisher": null, "author_last_name": "[{\"end\":147,\"start\":137},{\"end\":420,\"start\":415},{\"end\":507,\"start\":500},{\"end\":691,\"start\":682},{\"end\":841,\"start\":835},{\"end\":907,\"start\":902},{\"end\":1074,\"start\":1069},{\"end\":1253,\"start\":1246},{\"end\":1432,\"start\":1425},{\"end\":1613,\"start\":1607}]", "author_first_name": "[{\"end\":136,\"start\":131},{\"end\":414,\"start\":409},{\"end\":499,\"start\":492},{\"end\":679,\"start\":673},{\"end\":681,\"start\":680},{\"end\":834,\"start\":829},{\"end\":899,\"start\":894},{\"end\":901,\"start\":900},{\"end\":1066,\"start\":1060},{\"end\":1068,\"start\":1067},{\"end\":1243,\"start\":1236},{\"end\":1245,\"start\":1244},{\"end\":1424,\"start\":1415},{\"end\":1606,\"start\":1598}]", "author_affiliation": "[{\"end\":272,\"start\":149},{\"end\":407,\"start\":274},{\"end\":490,\"start\":422},{\"end\":630,\"start\":509},{\"end\":671,\"start\":632},{\"end\":742,\"start\":693},{\"end\":827,\"start\":744},{\"end\":892,\"start\":843},{\"end\":992,\"start\":909},{\"end\":1058,\"start\":994},{\"end\":1193,\"start\":1076},{\"end\":1234,\"start\":1195},{\"end\":1372,\"start\":1255},{\"end\":1413,\"start\":1374},{\"end\":1555,\"start\":1434},{\"end\":1596,\"start\":1557},{\"end\":1766,\"start\":1643},{\"end\":1901,\"start\":1768}]", "title": "[{\"end\":128,\"start\":1},{\"end\":2030,\"start\":1903}]", "venue": null, "abstract": null, "bib_ref": null, "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":8853,\"start\":8387},{\"attributes\":{\"id\":\"fig_1\"},\"end\":9352,\"start\":8854},{\"attributes\":{\"id\":\"fig_2\"},\"end\":9875,\"start\":9353},{\"attributes\":{\"id\":\"fig_3\"},\"end\":10544,\"start\":9876},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":12125,\"start\":10545}]", "paragraph": "[{\"end\":2105,\"start\":2058},{\"end\":2984,\"start\":2107},{\"end\":3816,\"start\":3011},{\"end\":4700,\"start\":3873},{\"end\":6409,\"start\":4719},{\"end\":6941,\"start\":6452},{\"end\":7420,\"start\":6979},{\"end\":8386,\"start\":7445}]", "formula": null, "table_ref": null, "section_header": "[{\"end\":3009,\"start\":2987},{\"end\":3871,\"start\":3819},{\"end\":4717,\"start\":4703},{\"end\":6450,\"start\":6412},{\"end\":6977,\"start\":6944},{\"end\":7443,\"start\":7423},{\"end\":8399,\"start\":8388},{\"end\":8866,\"start\":8855},{\"end\":9365,\"start\":9354},{\"end\":9888,\"start\":9877},{\"end\":10556,\"start\":10546}]", "table": "[{\"end\":12125,\"start\":10691}]", "figure_caption": "[{\"end\":8853,\"start\":8402},{\"end\":9352,\"start\":8869},{\"end\":9875,\"start\":9368},{\"end\":10544,\"start\":9891},{\"end\":10691,\"start\":10559}]", "figure_ref": "[{\"end\":2140,\"start\":2131},{\"end\":2402,\"start\":2393},{\"end\":5933,\"start\":5924},{\"end\":8003,\"start\":7994}]", "bib_author_first_name": null, "bib_author_last_name": null, "bib_entry": null, "bib_title": null, "bib_author": null, "bib_venue": null}}}, "year": 2023, "month": 12, "day": 17}