{"id": 219179914, "updated": "2023-10-06 14:45:05.799", "metadata": {"title": "TIMME: Twitter Ideology-detection via Multi-task Multi-relational Embedding", "authors": "[{\"first\":\"Zhiping\",\"last\":\"Xiao\",\"middle\":[]},{\"first\":\"Weiping\",\"last\":\"Song\",\"middle\":[]},{\"first\":\"Haoyan\",\"last\":\"Xu\",\"middle\":[]},{\"first\":\"Zhicheng\",\"last\":\"Ren\",\"middle\":[]},{\"first\":\"Yizhou\",\"last\":\"Sun\",\"middle\":[]}]", "venue": null, "journal": "Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining", "publication_date": {"year": 2020, "month": null, "day": null}, "abstract": "We aim at solving the problem of predicting people's ideology, or political tendency. We estimate it by using Twitter data, and formalize it as a classification problem. Ideology-detection has long been a challenging yet important problem. Certain groups, such as the policy makers, rely on it to make wise decisions. Back in the old days when labor-intensive survey-studies were needed to collect public opinions, analyzing ordinary citizens' political tendencies was uneasy. The rise of social medias, such as Twitter, has enabled us to gather ordinary citizen's data easily. However, the incompleteness of the labels and the features in social network datasets is tricky, not to mention the enormous data size and the heterogeneousity. The data differ dramatically from many commonly-used datasets, thus brings unique challenges. In our work, first we built our own datasets from Twitter. Next, we proposed TIMME, a multi-task multi-relational embedding model, that works efficiently on sparsely-labeled heterogeneous real-world dataset. It could also handle the incompleteness of the input features. Experimental results showed that TIMME is overall better than the state-of-the-art models for ideology detection on Twitter. Our findings include: links can lead to good classification outcomes without text; conservative voice is under-represented on Twitter; follow is the most important relation to predict ideology; retweet and mention enhance a higher chance of like, etc. Last but not least, TIMME could be extended to other datasets and tasks in theory.", "fields_of_study": "[\"Computer Science\",\"Mathematics\"]", "external_ids": {"arxiv": "2006.01321", "mag": "3102042889", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/kdd/0001SXRS20", "doi": "10.1145/3394486.3403275"}}, "content": {"source": {"pdf_hash": "8ade0f3bbe8d8251c5de9ef39886a13055f463e5", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2006.01321v3.pdf\"]", "oa_url_match": false, "oa_info": {"license": null, "open_access_url": "https://dl.acm.org/doi/pdf/10.1145/3394486.3403275", "status": "BRONZE"}}, "grobid": {"id": "60b6fbd87b2350b6059605e620894f534d1a767c", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/8ade0f3bbe8d8251c5de9ef39886a13055f463e5.txt", "contents": "\nTIMME: Twitter Ideology-detection via Multi-task Multi-relational Embedding\nAugust 23-27, 2020. August 23-27, 2020\n\nZhiping Xiao \nWeiping Song weiping.song@pku.edu.cn \nHaoyan Xu \nZhicheng Ren \nYizhou Sun yzsun@cs.ucla.edu \nZhiping Xiao \nWeiping Song \nHaoyan Xu \nZhicheng Ren \nYizhou Sun \n\nCS Department\nCS Department\nSchool of EECS\nUCLA\nLos AngelesCAUnited States\n\n\nCollege of Control Science and Engineering\nPeking University\nBeijingChina\n\n\nCS Department\nZhejiang University Hangzhou\nChina\n\n\nCS Department\nUCLA\nLos AngelesCAUnited States\n\n\nUCLA\nLos AngelesCAUnited States\n\nTIMME: Twitter Ideology-detection via Multi-task Multi-relational Embedding\n\nKDD\nthe 26th ACM SIGKDD Conference on Knowl-edge Discovery and Data Mining USB Stick (KDD '20)20August 23-27, 2020. August 23-27, 202010.1145/3394486.3403275ACM ISBN 978-1-4503-7998-4/20/08. . . $15.00 Virtual Event, USA. ACM, New York, NY, USA, 11 pages. https://doi.org/10. 1145/3394486.3403275CCS CONCEPTS \u2022 Computing methodologies \u2192 Multi-task learning; Neural networks\nWe aim at solving the problem of predicting people's ideology, or political tendency. We estimate it by using Twitter data, and formalize it as a classification problem. Ideology-detection has long been a challenging yet important problem. Certain groups, such as the policy makers, rely on it to make wise decisions. Back in the old days when labor-intensive survey-studies were needed to collect public opinions, analyzing ordinary citizens' political tendencies was uneasy. The rise of social medias, such as Twitter, has enabled us to gather ordinary citizen's data easily. However, the incompleteness of the labels and the features in social network datasets is tricky, not to mention the enormous data size and the heterogeneousity. The data differ dramatically from many commonly-used datasets, thus brings unique challenges. In our work, first we built our own datasets from Twitter. Next, we proposed TIMME, a multitask multi-relational embedding model, that works efficiently on sparsely-labeled heterogeneous real-world dataset. It could also handle the incompleteness of the input features. Experimental results showed that TIMME is overall better than the state-of-the-art models for ideology detection on Twitter. Our findings include: links can lead to good classification outcomes without text; conservative voice is under-represented on Twitter; follow is the most important relation to predict ideology; retweet and mention enhance a higher chance of like, etc. Last but not least, TIMME could be extended to other datasets and tasks in theory.\n\nINTRODUCTION\n\nStudies on ideology never fails to attract people's interests. Ideology here refers to the political stance or tendency of people, often reflected as left-or right-leaning. Measuring the politicians' ideology helps predict some important decisions' final outcomes, but it does not provide more insights into ordinary citizens' views, which are also of decisive significance. Decades ago, social scientists have already started using probabilistic models to study the voting behaviors of the politicians. But seldom did they study the mass population's opinions, for the survey-based study is extremely labor-intensive and hard-to-scale [1,27]. The booming development of social networks in the recent years shed light on detecting ordinary people's ideology. In social networks, people are more relaxed than in an offline interview, and behave naturally. Social networks, in return, has shaped people's habits, giving rise to opinion leaders, encouraging youngsters' political involvement [25].\n\nMost existing approaches of ideology detection on social networks focus on text [5,8,[15][16][17]. Most of their methodologies based on probabilistic models, following the long-lasting tradition started by social scientists. Some others [2,13,17,29] noticed the advantages of neural networks, but seldom do they focus on links. We will show that the social-network links' contribution to ideology detection has been under-estimated.\n\nAn intuitive explanation of how links could be telling is illustrated in Figure 1. Different types of links come into being for different reasons. We have five relation types among users on Twitter today: follow, retweet, reply, mention, like, and the relations affect each other. For instance, after Rosa retweet from Derica and mention her, Derica reply to her; when Isabel mention some politicians in her posts, the politician's followers might come to interact with her. One might mention or reply to debate, but like always stands for agreement. The relations could reflect some opinions that a user would never tell you verbally. Words could be easily disguised, and there is always a problem called \"the silent majority\", for most people are unwilling to express.\n\nYet there are some uniqueness of Twitter dataset, bringing about many challenges. It is especially the case when existing approaches are mostly dealing with smaller datasets with much sparser links than ours, such as academic graphs, text-word graphs, and knowledgegraphs. First, our Twitter dataset is large and the links are relatively dense (Section 4). Some models such as GraphSAGE [14] will be super slow sampling our graph. Second, labels are extremely sparse, less than 1%. Most approaches will suffer from severe over-fitting, and the lack of reliable evaluation. Third, features are always incomplete, for in real-life datasets like Twitter, many accounts are removed or blocked. Fourth, modeling the heterogeneity is nontrivial. Many existing methods designed for homogeneous networks tend to ignore the information brought by the types of links.\n\nExisting works can not address the above challenges well. Even though some realized the importance of links [9,13], they failed to provide an embedding. Most people learn an embedding by separating the heterogeneous graph into different homogeneous views entirely, and combine them in the very end.\n\nWe propose to solve the above-listed problems by TIMME (Twitter Ideology-detection via Multi-task Multi-relational Embedding), a model good at handling sparsely-labeled large graph, utilizing multiple relation types, and optionally dealing with missing features. Our code with data is released on Github at https://github. com/PatriciaXiao/TIMME. Our major contributions are:\n\n\u2022 We propose TIMME for ideology detection on Twitter, whose encoder captures the interactions between different relations, and decoder treats different relations separately while measuring the importance of each relation to ideology detection. \u2022 The experimental results have proved that TIMME outperforms the state-of-the-art models. Case studies showed that conservative voice is typically under-represented on Twitter. There are also many findings on the relations' interactions. \u2022 The large-scale dataset we crawled, cleaned, and labeled (Appendix A) provides a new benchmark to study heterogeneous information networks.\n\nIn this paper, we will walk through the related work in Section 2, introduce the preliminaries and the definition of the problem we are working on in Section 3, followed by the details of the model we propose in Section 4, experimental results and discussions in Section 5, and Section 6 for conclusion.\n\n\nRELATED WORK 2.1 Ideology Detection\n\nIdeology detection in general could be naturally divided into two directions, based on the targets to predict: of the politicians [7,24,28], and of the ordinary citizens [1, 2, 5, 8, 13, 15-17, 20, 23, 29]. The work conducted on ordinary citizens could also be categorized into two types according to the source of data being used: intentionally collected via strategies like survey [1,20], and directly collected such as from news articles [2] or from social networks [13,15,17]. Some studies take advantages from both sides, asking self-reported responses from a group of users selected from social networks [29], and some researchers admitted the limitations of survey experiments [23]. Emerging from social science, probabilistic models have been widely used for such kinds of analysis since the early 1980s [2,13,28]. On the other hand, on social network datasets, it is quite intuitive trying to extract information from text data to do ideology-detection [5,8,[15][16][17], only a few paid attention to links [9,13]. Our work differs from them all, since: (1) unlike probabilistic models, we use GNN approaches to solve this problem, so that we take advantage of the high-efficient computational resources, and we have the embeddings for further analysis; (2) we focus on relations among users, and proved how telling those relations are.\n\n\nGraph Neural Networks (GNN)\n\n2.2.1 Graph Convolutional Networks (GCN). Inspired by the great success of convolutional neural networks (CNN), researchers have been seeking for its extension onto information networks [11,19] to learn the entities' embeddings. The Graph Convolutional Networks (GCN) [19] could be regarded as an approximation of spectraldomain convolution of the graph signals. A deeper insight [21] shows that the key reason why GCN works so well on classification tasks is that its operation is a form of Laplacian smoothing, and concludes the potential over-smoothing problem, as well as emphasizes the harm of the lack of labels.\n\nGCN convolutional operation could also be viewed as sampling and aggregating of the neighborhood information, such as Graph-SAGE [14] and FastGCN [4], enabling training in batches. To improve GraphSAGE's expressiveness, GIN [40] is developed, enabling more complex forms of aggregation. In practice, due to the sampling time cost brought by our links' high density, GIN, GraphSAGE and its extension onto heterogeneous information network such as HetGNN [43] and GATNE [3] are not very suitable on our datasets.\n\nThe relational-GCN (r-GCN) [32] extends GCN onto heterogeneous information networks. A very large number of relation-types |R| ends up in overwhelming parameters, thus they put some constraints on the weight matrices, referred to as weight-matrix decomposition. GEM [22] is almost a special case of r-GCN. Unfortunately, their code is kept confidential. According to the descriptions in their paper, they have a component of similar use as the attention weights \u03b1 in our encoder, but it is treated as a free parameter.\n\nAnother way of dealing with multiple link types is well-represented by SHINE [38], who treats the heterogeneous types of links as separated homogeneous links, and combines embeddings from all relations in the end. SHINE did not make good use of the multiple relations to its full potential, modeling the relations without allowing complex interactions among them. GTN [42] is similar with SHINE in splitting the graph into separate views and combining the output at the very end. Besides, GTN uses meta-path, thus is potentially more expressive than SHINE, but would rely heavily on the quality and quantity of the meta-paths being used.\n\n\nGraph Attention\n\nNetworks. Graph Attention Networks (GAT) [36] is another nontrivial direction to go under the topic of graph neural networks. It incorporates attention into propagation by applying self-attention on the neighbors. Multi-head mechanism is often used to ensure stability.\n\nAn extension of GAT on heterogeneous information networks is Heterogeneous Graph Attention Network, HAN [39]. Beside inheriting the node-level attention from GAT, it considers different relation types by sampling its neighbors from different meta-paths. It first conducts type-specific transformation and compute the importance of neighbors of each node. After that, it aggregates the coefficients of all neighbor nodes to update the current node's representation. In addition, to obtain more comprehensive information, it conducts semantic-level attention, which takes the result of node-level attention as input and computes the importance of each meta-path. We use HAN as an important baseline in our experiments.\n\n\nMulti-Task Learning (MTL)\n\nIn multi-task learning (MTL) settings, there are multiple tasks sharing the same inductive bias jointly trained. Ideally, the performance of every task should benefit from leveraging auxiliary knowledge from each other. As is concluded in an overview [31], MTL could be applied with or without neural network structure. On neural network structure, the most common approach is to do hard parameter-sharing, where the tasks share some hidden layers. The most common way of optimizing an MTL problem is to solve it by joint-training fashion, with joint loss computed as a weighted combination of losses from different tasks [18]. It has a very wide range of applications, such as the DMT-Demographic Models [37] where multiple aspects of Twitter data (e.g. text, images) are fed into different tasks and trained jointly. Aron and Nirmal et al. [10] also apply MTL on Twitter, separating the tasks by user categories. Our multi-task design differs from theirs, and treat node classification and link prediction on different relation types as different tasks.\n\n\nPROBLEM DEFINITION\n\nOur goal is to predict Twitter users' ideologies, by learning the ideology embedding of users in a political-centered social network. \n\n. , E R }} Each possible edge from the i th node to the j th , represented as e i j \u2208 E has a weight value w i j > 0 associated to it, where w i j = 0 representing e i j E. In our case, G is a directed graph. In general, we have \u27e8v i , v j \u27e9 \u27e8v j , v i \u27e9 and w i j w ji .\n\nTwitter data G T wit t er contains T = 1 type of entities (users), and R = 5 different types of edges (relations) among the entities, namely follow, retweet, like, mention, reply.\nG T wit t er = {V, {E 1 , E 2 , E 3 , E 4 , E 5 }}\nDetailed description about Twitter data is included in Appendix A, and we call the subgraph we selected from Twitter-network a political-centered social network, which is defined as follows:\nDefinition 3.2. (Political-Centered Social Network)\nThe politicalcentered social network is a special case of directed heterogeneous information network. With a pre-defined politicians set P, in our selected heterogeneous network G T wit t er , \u2200e = \u27e8v i , v j \u27e9 \u2208 E r where r \u2208 {1, 2, . . . , R}, there has to be either v i \u2208 P or v j \u2208 P. All the politicians in this dataset have ground-truth labels indicating their political stance. The political-centered social networks are represented as G p .\n\nWe would like to leverage the information we have to learn the representation of the users, which could help us reveal their ideologies. Due to the lack of Independent representatives (only two in total), we consider the binary-set labels only: { liberal, conservative }. Democratic on liberal side, Republican for conservative.\nDefinition 3.3. (Multi-task Multi-relational Network Embed- ding) Given a network G p = {V, {E 1 , E 2 , E 3 , E 4 , E 5 }}\nwhere the number of nodes is |V | = N , the goal of TIMME is to learn such a representation h i \u2208 R d where d \u226a N for \u2200v i \u2208 V, that captures the categorical information of nodes, such as their ideology tendencies. As a measurement, we want the representation H \u2208 R N \u00d7d , to success on both node-classification and link-prediction.\n\n\nMETHODOLOGY\n\nThe general architecture of our proposed model is illustrated in Figure 2. It contains two components: encoder and decoder. The encoder contains two multi-relational convolutional layers. The output of the encoder is passed on to the decoder, who handles the downstream tasks.\n\n\nMulti-Relation Encoder\n\nAs mentioned before in Section 1, the challenges faced by the encoder part are the large data scale, the heterogeneous link types, and the missing features.\n\nGCN is very effective in learning the nodes' embeddings, especially good at classification tasks. Meanwhile, it is also naturally efficient, in terms of handling the large amount of vertices N .\n\nRandom-walk-based approaches such as node2vec [12] with time complexity O(a 2 N ), where a is the average degree of the graph, suffer from the relatively-high degree in our dataset. On the other hand, GCN-based approaches are naturally efficient here. Like is analyzed in Cluster-GCN [6], the time complexity of the standard GCN model is  Figure 2: The general architecture of our model, with the encoder shown in details. Grey blocks represent missing features. Our model can either handle them by treating them as learnable parameters, or use one-hot features.\nO(L\u2225A\u2225 0 F + LN F 2 ), where L is\nlinearly when N increases. A GCN model's layer-wise propagation could be written as:\nH (l +1) = \u03c3 \u00c2 H (l ) W (l ) \u00c2 =D 1 2 (A + I N )D 1\n2 , whereD is defined as the diagonal matrix and A the adjacency matrix. D ii , the diagonal element d i , is equal to the sum of all the edges attached to v i ;\nH (l ) \u2208 R N \u00d7d (l )\nis the d (l ) -dimensional representation of the N nodes at the l th layer;\nW (l ) \u2208 R d (l ) \u00d7d (l +1)\nis the weight parameters at layer l which is similar with that of an ordinary MLP model 1 . In a certain way,\u00c2 could be viewed as A after being normalized. We propose to model the heterogeneous types of links and their interactions in the encoder. Otherwise, if we split the views like many others did, the model will never be expressive enough to capture the interactions among relations. For any given politicalcentered graph G P , let's denote the total number of nodes |V | = N , the number of relations |R| = R, the set of nodes V, the set of relations R, and E r being the set of links under relation r \u2208 R. Representation being learned after layer l (l \u2208 {1, 2}) is represented as H (l ) \u2208 R N \u00d7d (l ) , and the input features form the matrix H (0) \u2208 R N \u00d7d (0) .R where |R| = 2R+1 represents all relations in the original direction (R), the relations in reversed direction (R), and an identicalmatrix relation (1). Our dataset has |R| = R = 5, so it should be fine not to conduct a weight-matrix decomposition like r-GCN [32]. We 1 MLP here refers to Multi-layer Perceptron. model the layer-wise propagation at Layer l + 1 as:\nH (l +1) = \u03c3 r \u2208R \u03b1 r\u00c2r H (l ) W (l ) r where H (l ) \u2208 R N \u00d7d (l )\nis used to denote the representation of the nodes after the l th encoder layer, and the initial input feature is H (0) .\nA r =D 1 2 r (A r + I N )D 1 2\nr is defined in similar way as\u00c2 in GCN, but it is calculated per relation. The activation function \u03c3 we use is ReLU.\nBy default, \u03b1 == [\u03b1 1 , . . . \u03b1 r . . . ] T \u2208 R 2R+1 is calculated by scaled dot-product self-attention over the outputs of H (l +1) r =\u00c2 r H (l ) W (l ) r : A = Attention(Q, K, V ) = so f tmax QK T \u221a d V \u2208 R (2R+1)\u00d7d where Q = K = V \u2208 R (2R+1)\u00d7d comes from the 2R + 1 matrices H (l +1) r \u2208 R N \u00d7d , stacking up as O \u2208 R (2R+1)\u00d7N \u00d7d ,\ntaking an average over the N entities. We calculate an attention to apply to the 2R + 1 outputs as:\n\u03b1 = so f tmax sum col QK T \u221a d \u2208 R 2R+1\nwhere sum col (X ) takes the sum of each column in X \u2208 R d 1 \u00d7d 2 and ends up in a vector \u2208 R d 2 .\n\nThe last problem to solve is that the initial features H (0) is often incomplete in real life. In most cases, people would go by onehot features or randomized features. But we want to enable our model to use the real features, even if the real-features are incomplete. Inspired by graph representation learning strategies such as LINE [35], we proposed to treat the unknown features as trainable parameters. That is, for a graph G p whose vertice set is V, V f eatur ed V f eatur el ess = and V f eatur ed V f eatur el ess = V, for any node with valid feature \u2200v i \u2208 V f eatur ed , the node's feature vector H j is unknown and treated as a trainable parameter. The generation of the features will be discussed in the Appendix A. In brief, TIMME can handle any missing input feature.\n\n\nMulti-Task Decoder\n\nWe propose TIMME as a multi-task learning model such that the sparsity of the labels could be overcome with the help of the link information. As is shown in Figure 3, we propose two architectures of the multi-task decoder. When we test it on a single-task i, we simply disable the remaining losses but a single L i , and name our model in single-task mode TIMME-single.\n\nL 0 is defined the same way as was proposed in [19], in our case a binary cross-entropy loss:\nL 0 = \u2212 y \u2208Y t r ain y log(y) + (1 \u2212 y) log(1 \u2212 y)\nwhere Y t r ain contains the labels in the training set we have. L 1 , . . . L R are link-prediction losses, calculated by binary crossentropy loss between link-labels and the predicted link scores' logits. To keep the links asymmetric, we used Neural Tensor Network (NTN) structure [33], with simplification inspired by DistMult [41]. We set the number of slices be k = 1 for W r \u2208 R d \u00d7d \u00d7k , omitting  Figure 3: The two types of decoder in our multi-task framework, referred to as TIMME and TIMME-hierarchical.\n\nthe linear transformer U , and restricting the weight matrices W r each being a diagonal matrix. For convenience, we refer to this link-prediction cell as TIMME-NTN.\nConsider triplet (v i , r , v j ), and denote the encoder output of v i , v j \u2208 V as h i , h j \u2208 R d ,\nthe score function of the link is calculated as:\ns(i, r , j) = h i W r h j + V h i h j + b\nwhere W r \u2208 R d \u00d7d is a diagonal matrix for any \u2200r \u2208 R. W r , V \u2208 R 2d and b \u2208 R are all parameters to be learned. Group-truth label of a positive (existing) link is 1, otherwise 0. The first decoder-architecture TIMME sums all R + 1 losses as L = R i=0 L i . Without average, each task's loss is directly proportional to the amount of data points sampled at the current batch. Low-resource tasks will take a smaller portion. This is the most straightforward design of a MTL decoder.\n\nThe second, TIMME-hierarchical, has \u03bb = [\u03bb 1 , . . . , \u03bb | R | ] T being computed via self-attention on the average embedding over the R link-prediction task-specific embeddings. Here, L = R i=0 L i is the same with TIMME. TIMME-hierarchical essentially derives the node-label information from the link relations, thus provides some insights on each relation's importance to ideology prediction. TIMME, TIMME-hierarchical, TIMME-single models share exactly the same encoder architecture.\n\n\nEXPERIMENTS\n\nIn this section, we introduce the dataset we crawled, cleaned and labeled, together with our experimental results and analysis.  Table 1. Data prepared is described in Appendix A, ready by April, 2019. In brief, we did: (1) Collecting some Twitter accounts of the politicians P;\n\n\nData Preparation\n\n(2) For every politician \u2200p \u2208 P, crawl her/his most-recent s followers and s followees, putting them in a candidate set C.  (3) For every candidate c \u2208 C, we also crawl their most-recent s followers to make the follow relation more complete. (4) For every user u \u2208 P \u222aC, crawl their tweets as much as possible, until we hit the limit (\u2248 3, 200) set by Twitter API. (5) From the followers & followees we collect follow relation, from the tweets we extract: retweet, mention, reply, like. (6) Select different groups of users from C, based on how many connections they have with members in P, and making those groups into the 4 subsets, as is shown in Table 1. (7) We filter the relations within any selected group so that if a relation e = \u27e8v i , v j \u27e9 \u2208 G p , there must be v i \u2208 G p and v j \u2208 G p .\n\nOur four datasets represent different user groups. PureP contains only the politicians. P50 contains politicians and users keen on political affairs. P20\u223c50 is politicians with the group of users who are of moderate interests on politics. P+all is a union set of the three, plus some randomly-selected outliers of politics. P+all is the most challenging subset to all models. More details on the dataset, including how we generated features and how we tried to get more labels, are all described in details in Appendix A.   Table 3: Link-prediction measured by ROC-AUC/PR-AUC.\n\n\nPerformance Evaluation\n\nIn practice, we found that we do not need any features for nodes, and use one-hot encoding vector as initial feature. We split the train, validation, and test set of node labels by 8:1:1, keep it the same across all datasets and throughout all models, measuring the labels' prediction quality by F1-score and accuracy. For link-prediction tasks, we split all positive links into training, validation, and testing sets by 85:5:10, keeping same portion across all datasets and all models, evaluating by ROC-AUC and PR-AUC. 2 \n\n\nBaseline Methods.\n\nWe have explored a lot of possible baseline models. Some methods we mentioned in section 2, HetGNN [43], GATNE [3] and GTN [42] generally converge \u2248 10 \u223c 100 times slower than our model on any task. GraphSAGE [14] is not very suitable on our dataset. Moreover, other well-designed models such as GIN [40] are way too different from our approach at a very fundamental level, thus are not considered as baselines. Some other methods such as GEM [22] and SHINE [38] should be capable of handling the dataset at this scale, but they are not releasing their code to the public, and we can not easily guarantee reproduction.\n\nWe decided to use the three baselines: GCN, r-GCN and HAN. They are closely-related to our model, open-sourced, and efficient. We understand that none of them were specifically designed for social-networks. Early explorations without tuning them resulted in terrible outcomes. To make the comparisons fair, we did a lot of work in hyper-parameter optimization, so that their performances are significantly improved. The GCN baseline treats all links as the same type and put them into one adjacency matrix. We also extend the baseline models to new tasks that were not mentioned in their original papers. We refer to GCN+ and HAN+ as the GCNbase-model or HAN-base-model with TIMME-NTN attached to it. By comparing with GCN/GCN+, we show that reserving heterogeneousity is beneficial. Comparing with r-GCN, we prove that their design is not as suitable for social networks as ours. With HAN/HAN+ we show that, although their model is potentially more expressive, our model still outperforms theirs in most cases, even after we carefully improved it to its highest potential (Appendix C). We did not have to tune the hyper-parameters of TIMME models closely as hard, thanks to its robustness. HAN+ has an expressive and flexible structure that helps it achieve high in some tasks. The downsides of HAN/HAN+ are also obvious: it easily gets over-fitting, and is extremely sensitive to dataset statistics, with large memory consumption that typically more than 32G to run tasks on P+all, where TIMME models takes less than 4G space with the same hidden size and embedding dimensions as the baseline model's settings.\n\n\nTIMME.\n\nTo stabilize training, we would have to use the step-decay learning rate scheduler, the same with that for ResNet. The optimizer we use is Adam, kept consistent with GCN and r-GCN. We do not need input features for nodes, thus our encoder utilizes one-hot embedding by default. One of the many advantages of TIMME is how robust it is to the hyper-parameters and all other settings, reflected by that the same default parameter settings serve all experiments well. Like many others have done before, to avoid information leakage, whenever we run tasks involving link-prediction, we will remove all link-prediction test-set links from our adjacency matrices.\n\nIt is shown in Table 2 and 3 that multi-task models TIMME and TIMME-hierarchical are generally better than TIMME-single on most tasks. Even TIMME-single is superior to the baseline models most of the times. TIMME models are stable and scalable. The classification task, despite the many labels we manually added, easily over-estimating the models. Models trained on single nodeclassification task will easily get over-fitted. If we force them to keep training after convergence, only multi-task TIMME models keep stable. The baselines and TIMME-single suffer from dramatic performance-drop, especially HAN/HAN+. r ), and the encoder output embeddings (H (2) ). Red for ground-truth republican nodes, blue for democratic.  training-curves of TIMME-single with one-hot features, randomized features, partly-known-partly-randomized features, and with partly-known-partly-trainable features. The results are collected from P50 dataset. To make it easier to compare, we have fixed training epochs 300 for node-classification, and 200 for follow-relation link-prediction. It is shown that text feature is significantly better than randomized feature, and treating the missing part of the text-generated feature as trainable is better than treat it as fixed randomized feature. However, one-hot feature always outperforms them all, essentially means that relations are more reliable and less noisy than text information in training our network embedding. We have proved in Appendix B that the 2R + 1 weight matrices at the first convolutional layer captures the nodes' learned features when using one-hot features. Experimental evidence is shown in Figure 4. It shows that although worse than the encoder output, the first embedding layer also captured the features of nodes. The embedding comes from epoch 300, node-classification task on PureP.\n\n\nCase Studies\n\n\nPerformance Measurement on News Agency.\n\nA good measurement of our prediction's quality would be on some users with ground-truth tendency, but unlabeled in our dataset. News agents' accounts are typically such users, as is shown in Figure 8. Among them we select some of the agencies believed to have clear tendencies. 3 The continuous scores we have for prediction come from the softmax of the last-layer output of our node-classification task, which is in the format of (prob l e f t , prob r i\u0434ht ). Right in the middle represents (prob l e f t , prob r i\u0434ht ) = (0.5, 0.5), left-most being (1.0, 0.0), right-most (0.0, 1.0). For most cases, our model's predictions agree with people's common belief. But CNN News is an 3 We fetch most of the ground-truth labels of the news agents from the public voting results on https://www.allsides.com/media-bias/media-bias-ratings, got them after the prediction results are ready. interesting case. It is believed to be extremely left, but predicted as slightly-left-leaning centrist. Some others have findings supporting our results: CNN is actually only a little bit left-leaning. 4 Although the public tends to believe that CNN is extremely liberal, it is more reasonable to consider it as centrist biased towards left-side. People's opinion on news agencies' tendencies might be polarized. Besides, although there are significantly more famous news agencies on the liberal side, those right-leaning ones tend to support their side more firmly.\n\n\nGeography Distribution.\n\nConsider results from the largest dataset (P+all), and with predictions coming out from TIMMEhierarchical. We predict each Twitter user's ideology as either liberal or conservative. Then we calculate the percentage of the users on both sides, and depict it in Figure 6. Darkest red represents p \u2208 [0, 1 8 ] of users in that area are liberal, remaining [ 7 8 , 1] are conservative; darkest blue areas have [ 7 8 , 1] users being liberal, 50 Figure 9: The impact of training on single-link-prediction tasks, on Pure-P (left), P50 (middle), P+all (right) dataset respectively.\n\n[0, 1 8 ] conservative. The intermediate colors represent the evenlydivided ranges in between. The users' locations are collected from the public information in their account profile. From our observation, conservative people are typically under-represented. 56 For instance, as a well-known firmly-conservative state, Utah (UT) is only shown as slightly right-leaning on our map. This is intuitively reasonable, since Twitter users are also biased. Typically biased towards youngsters and urban citizens. Although we are able to solve the problem of silent-majority by utilizing their link relations instead of text expressions, we know nothing about offline ideology. We suppose that some areas are silent on Twitter, and this guess is supported by the county-level results at Florida, shown in Figure 7. This time the color-code represents evenlydivided seven ranges from [0, 1 7 ] to [ 6 7 , 1], because of the necessity of reserving one color for representing silent areas (denoted as white for N/A). The silent counties, typically some rural areas, have no user in our dataset, inferring that people living there do not use Twitter very often. The remaining parts of the graph makes complete sense, demonstrating a typical swing state. 7\n\n\nCorrelated Relations.\n\nWhen we train TIMME-single with only one relation type, some other relations' predictions benefit from it, and are becoming more and more accurate. We assume that, if by training on relation r i we achieve a good performance on relation r j , then we say relation r i probably leads to r j . As is shown in Figure 9, relations among politicians are relatively independent except that all other relations might stimulate like. In more ordinary user groups, reply is the one that significantly benefit from all other relations. It is also interesting to observe that the highly-political P50 shows that like leads to retweet, while from more ordinary users' perspective once they liked they are less likely to retweet. The relations among the relations are asymmetric.\n\n\nRelation's Contributions to Ideology\n\nDetection. The importance of each relation to ideology prediction could be measured by the value of the corresponding \u03bb r values in the decoder of TIMME-hierarchical. All the values are close to 0.2 in practice, in retweet mention follow reply like PureP P50 P20~50 P+all [0.99, 2.01], but still has some common trends, as is shown in Figure  10. Despite that reply pops out rather than follow on PureP, we still insist that follow is the most important relation. That is because we only crawled the most recent about 5000 followers / followees. If a follow happened long time ago, we would not capture it. The follow relation is especially incomplete on PureP.\n\n\nCONCLUSION\n\nThe TIMME models we proposed handles multiple relations, with a multi-relational encoder, and multi-task decoder. We step aside the silent-majority problem by relying mostly on the relations, instead of the text information. Optionally, we accept incomplete input features, but we showed that links are able to do well on generating the ideology embedding without additional text information. From our observation, links help much more than naively-processed text in ideology-detection problem, and follow is the most important relation to ideology detection. We also concluded from visualizing the state-level overall ideology map that conservative voices tend to be under-represented on Twitter. Meanwhile we confirmed that public opinions on news agencies' ideology could be polarized, with very obvious tendencies. Our model could be easily extended to any other social network embedding problem, such as on any other dataset like Facebook as long as the dataset is legally available, and of course it works on predicting other tendencies like preferring Superman or Batman. We also believe that our dataset would be beneficial to the community. At the early stage of this work, Haoran Wang 8 contributed a lot to a nicely-implemented first version of the model, benefiting the rest of our work. Meanwhile, Zhiwen Hu 9 explored the related methods' efficiencies, and his works shed light on our way.\n\n\nACKNOWLEDGEMENT\n\nOur team also received some external help from Yupeng Gu. He offered us his crawler code and his old dataset as references.\n\n\nA DATA PREPARATION\n\nWe target at building a dataset representing the political-centered social network (Section 3), a selected subset from the giant Twitter network. Handling this dataset would be challenging. For example, for GraphSAGE, neighborhood-sampling can not be easily done both effectively and efficiently. Our dataset reaches the blind spots of many existing models.\n\nThe tools we used to crawl politicians' name lists from the government website, and their potential Twitter accounts from Google, is Scrapy. 10 To legally and reliably crawl from Twitter data, we first applied for Developer API from Twitter 11 , and then used Tweepy 12 for crawling. We set very strict rate limits for our crawlers so as not to harm any server. Our dataset is released at https://github.com/PatriciaXiao/TIMME. Raw data was collected by April, 2019.\n\n\nA.1 Twitter IDs Preparation\n\nLet us take the same notation as in Section 3, describing the process as: to construct G p = {V, {E 1 , E 2 , E 3 , E 4 , E 5 }}, we first select the users to be included V, then we include the links among vertices in V under each relation r \u2208 R = {1, 2, 3, 4, 5} into E r accordingly.\n\nA.1.1 Politicians Twitter IDs. As is described briefly in Section 5.1, we need to start from a set of politicians P, which we treat as seeds for further crawling.\n\nTo start with, we first get the name list of the recently-active politicians, consists of: \u2022 The union-set of 115 t h and 116 t h US congress members, where we observe a lot of overlap between the two groups; 13 \u2022 Recent-years' presidents and their cabinets; 14 \u2022 Additional politicians must be included: Hilary Clinton, who was running for the president of the United States not long ago; Michelle Obama, who was the former First Lady. Next, with the help of Google, we crawled the most-likely Twitter names and IDs of the politicians. We do so automatically, by providing Google a politician's name and the keyword \"twitter\", and parsing the first response. Then after manual filtering, we have 583 politicians' Twitter accounts available, who make up our politicians set P. Anyone else to be included in our dataset must be in the 1-hop neighborhood of a politician (Section 3).\n\nA.1.2 Candidate Non-Politicians Twitter IDs. With the help of Twitter Developer API, we are able to get the full followers and followees list of any Twitter user.\n\nHowever, it is not affordable to include all followers and followees of the politicians, thus we set a limit on window size s when crawling the candidate non-politicians list, only accepting the mostrecent s = 5, 000 followers or followees of any politician. These followers and followees we collected form a raw candidate set C r aw . Then we remove the politicians from this set, resulting in the final candidates set C = C r aw \u2212 P. \u2200v i \u2208 C, we apply the same window size s = 5, 000 and crawled their most recent s followers, s followees. All follower-followee pairs are stored into a database for the convenience of the following steps.\n\nA.1.3 Selecting Subgroups from Candidates. C is still too large a user set, and chaotic, as we don't know anything about its components. To conduct meaningful analysis, we need to select some meaningful subgroups from it, such as a very-political subgroup, and a political-outliers subgroup, etc.\n\nThe criteria we used to select the desired subgroups of users is some thresholds. We define a political-measurement t i for each user v i \u2208 C, who is followed by t i,1 politicians p \u2208 P, and meanwhile following t i,2 politicians, thus t i is computed by t i = max(t i,1 , t i,2 ).\n\nThen we set a threshold range t, set upon each t i , used for filtering the groups of users. Considering we set t as threshold range for graph G p , \u2200v i \u2208 V, if t i \u2208 t, then v i \u2208 G p , otherwise v i G p . By having t = {\u221e}, we select a minimum subgraph containing purely politicians, resulting in our PureP dataset. t \u2208 [50, \u221e) allows us to select a small group of users who are keen on political topics, together with the politicians, being our P50 dataset. t \u2208 [20, 50) for less-political users, plus the politicians, being our P20\u223c50 dataset. t \u2208 [20, \u221e) includes all nodes v i whose t i \u2265 20. We want to have a dataset representing more general users, containing some users from each group. Therefore, we include another 3, 000 users randomly selected from the group t \u2208 [1,5). Adding these random political-outlier users will make the dataset resembles the real network even more. Putting together the politicians, t \u2208 [20, \u221e) group, and the 3, 000 random outliers from t \u2208 [0, 5) group, we form the dataset P+all. Ideally, P+all has representatives of all groups of users on Twitter. The statistics are concluded in Table 1.\n\n\nA.2 Relation Preparation\n\nOnly the follow relation is directly observed and already wellprepared at this stage (stored in a database, as we mentioned before). Other Twitter relations: retweet, mention, like, reply, must be concluded from tweets. We distinguish the different relation types from the tweets by the tweets' fields in responded JSON from API. For example, there are some fields indicating if an \"\" mark is a mention, a retweet, or it links to nothing. According to our observation, the fields in the Json file responded from Twitter API might change across time. We don't know when will it be the next update, so there's no ground-truth solution for this part. We suggest whoever want to do so test the crawler first on her/his own account, trying all behaviors to conclude some patterns. Note: rate limit applies. 15 Due to the Twitter official API limits, the maximum amount of tweets we could crawl for each user along the timeline is around 3, 200. Therefore, all relations are incomplete. All links we have only reflect some recent interactions among the users.\n\n\nA.3 Feature Preparation\n\nWe get feature from text, using a user's tweets posted to generate her/his feature. Although there has been some recent advances in NLP with transformer-based structures, such as BERT and XLNet, Sentence-BERT [30] found that BERT / XLNet embeddings are generally performing worse than GloVe [26] average on sentence-level tasks. Not to mention the computational cost of transformers. We therefore use GloVe-average of the words as features, Wikipedia 2014 + Gigaword 5 (300d) pre-trained version. When we apply the average-GloVe embedding on tweet-level, and want to tell the ideology behind the tweets, we could easily achieve \u2248 72.84% accuracy, using a 2-layers MLP, after only 200 epochs of training.\n\n\nA.4 Label Preparation\n\nIf we are to use only the 583 labels from the politicians, the evaluation will always be untrustworthy. To overcome this issue, we manually expand the labels. We first crawled the users' profiles of \u2200v i \u2208 P \u222a C, getting their information such as location and account description. Next, using the descriptions, searching for the words democratic, republican, conservative, liberal, their correct spell and variations, we have a large group of candidates. Then we do manual filtering to get rid of the uncertain users, reading their descriptions and recent tweets. We successfully included 2, 976 high-quality new labels in the end. Those labels make the node-classification task significantly more stable and reliable.\n\n\nB PROOF OF WEIGHT BEING FEATURE\n\nStarting from our layer-wise propagation formula, we have that, at the first convolutional layer (notations in Section 4): r \u2208 R N \u00d7d (1) . From another point of view, it is equivalent as having input features beingH (0) = W (0) r \u2208 R N \u00d7d (1) , and setW (0) r \u2208 R d (1) \u00d7d (1) = I d (1) being fixed identical matrix not to be updated. That's the reason why we believe that W \nH (1) = \u03c3 r \u2208R \u03b1 r\u00c2r H (0) W (0) r where H (0) \u2208 N \u00d7 d (\n\nC BASELINE HYPER-PARAMETER AND ARCHITECTURAL OPTIMIZATIONS C.1 Applying GCN model Directly\n\nAs is discussed in Section 2, due to the uniqueness of the politicalcentered social network dataset, most of the existing models won't work well under our problem settings. We want to examine how well could GCN do when treating all relations as the same, ignoring the heterogeneous types. Very interestingly, without much work on hyper-parameter optimization, we only increased the hidden size and added the learning rate scheduler, it works pretty well. This phenomenon could potentially be an indirect evidence that relations are correlated, in addition to the discussions in Section 5.\n\n\nC.2 Missing-Task Completion\n\nWe compare our model's performance on each task with the baselines. Ideally, we want models working on heterogeneous information networks with both node-classification task and link-prediction task as our baselines, so that we could compare with them directly. However, the situation we faced was not as easy as such. For instance, GCN and HAN never considered applying themselves directly on link-prediction tasks. But we all know that once we have the embeddings of the nodes, link prediction is doable.\n\nTherefore, we decided that whenever a baseline originally couldn't handle a task, we lend it our decoder's task-specific cells. This decision brings about some significant improvements on the link prediction performances of NTN+ and GCN+, since TIMME-NTN is powerful and efficient for link-prediction. Just in case, we also decide that when a node-classification task is missing, we should add a linear transformation layer with output units 2, the same as what we did, and apply a simple cross-entropy loss. From this perspective, it is no longer fair to compare them with r-GCN directly. To distinguish them from others' standard models, we add a plus sign \"+\" to the names, indicating that \"we lend it our cells\".\n\n\nC.3 Optimizing r-GCN\n\nThe most important contribution of r-GCN is the weight-matrix decomposition methods. This mechanism would be very helpful in reducing the parameters, especially when the number of relations R is super high. However, in our case where R is small, the weightdecomposition operation is counter-effective. The first option, basis decomposition, the number of basis b is easily being larger than R. In the second option, block-diagonal decomposition, reduces the parameter size too dramatically, and harms the model's performance.\n\nReviewing the experiments reported in the r-GCN paper, seeing how they chose these hyper-parameters across datasets, we found that when R is small, they often chose basis-decomposition with b = 0. We go by the same option, which works well in practice.\n\n\nC.4 Optimizing HAN\n\nHAN/HAN+, in general, because of the complex structure with a lot of parameters, gets easily over-fitting. What makes things worse, its training curve is never stable, and our early tryouts on using validation set to automatically stop it at an optimal point did not work well. We had do it manually, by verifying when its best result appears on the validation set and when over-fitting starts, finding the right time to stop training. By default, we set learning rate 0.005, regularization parameter 0.001, the semantic-level attention-vector dimension 128, multi-head-attention cell's number of heads K = 8. We set the hyper-parameters in the TIMME-NTN component of HAN+ the same with ours. Optimizing HAN was a tough work to do, for it requires re-adapting every choices we made on every dataset for every task. Adding more meta-path would potentially boosting its performance, but the computational cost will be overwhelming. Another observation is that, TIMME models are significantly better than HAN/HAN+ in handling imperfect features. When using GloVe-average features, TIMME models typically perform about 1% worse than using one-hot features, while HAN/HAN+ experience performance-drop up to around 10%.\n\nFigure 1 :\n1An example of different relation types on Twitter. Derica is on liberal (left) side while Rosa is on the conservative (right) side. Isabel does not have significant tendency.\n\n\nDefinition 3.1. (Heterogeneous Information Network) Following previous work [34], we say that an information network G = {V, E}, where number of vertices is |V | = N , is a heterogeneous information network, when there are |T | = T types of vertices, |R| = R types of edges, and max(T , R) > 1. G could be represented as G = {{V 1 ,\n\n\nknown and fixed. For \u2200v j \u2208 V f eatur el ess , the corresponding row vector H (0)\n\n\nCrawling. The statics of the political-centered social network datasets we have are listed in\n\nFigure 4\n45.3.1 Selection of Input Features.To justify the reason why we do not need any features for nodes, we show the node-classification : t-SNE of matrices onto 2D space. Showing reply (and reversed), friend (and reversed) weight matrices of the first convolutional layer (W (0)\n\nFigure 5 :\n5Illustration of impact of features. Random features in blue, partly-know partly randomized (and fixed) in yellow, partly-known partly-trainable in green, one-hot in red.\n\nFigure 6 :Figure 7 :Figure 8 :\n678Overall ideology on Twitter in each state. Overall ideology on Twitter, Florida (FL). The News Agencies' Ideologies. Text colors come from the public's voting online, blue for left and red for right, black for middle (centrist). Length represents the value from the last layer, reflecting the extent.\n\nFigure 10 :\n10Illustration of \u03bb value in decoder on each dataset.\n\n\nThis work is partially supported by NSF III-1705169, NSF CAREER Award 1741634, NSF #1937599, DARPA HR00112090027, Okawa Foundation Grant, and Amazon Research Award. Weiping Song is supported by National Key Research and Development Program of China with Grant No. 2018AAA0101900/ 2018AAA0101902 as well as the National Natural Science Foundation of China (NSFC Grant No. 61772039 and No. 91646202).\n\n\n0) is the input feature-matrix. When using one-hot embedding of features, H (0) = I and d (0) = N , thus the right-hand-side is equivalent with \u03c3 r \u2208R \u03b1 r\u00c2r W own plays the role of H (0) W (0) r when H (0) I . Previously, relation r 's propagation could be viewed as aggregation of a linear transformation (W (0) r ) done on H (0) , from the neighborhood (\u00c2 r ) of each node under relation r . Now, it could simply be viewed as the propagation of W (0)\n\n\nthe nodes' learned features under relation r .\n\n\nthe number of layers, \u2225A\u2225 0 the number of non-zeros in the adjacency matrix, F the number of features. Note that the time complexity increases\u2026\u2026 \n\nN Features \n\nMulti-relational GCN \n\n2|R| Adjacency matrixes \n1 Identical matrix \n\n\u2026\u2026 \n\nW 1 \n\nW 2 \n\nEncoder \n\nDecoder \n\n\u03c3 \n\nLayer 1 \nLayer 2 \n\nW 2|R| \n\nW 2|R|+1 \n\n\u03b1 1 \n\nW 2|R|+1 \n\n\u03b1 2 \n\n\u03b1 2|R| \n\n\u03b1 2|R|+1 \n\n\u2026\u2026 \n\nN Embeddings \n\n\u2026\u2026 \n\nW 1 \n\nW 2 \n\n\u03c3 \n\nW 2|R| \n\n\u03b1 1 \n\n\u03b1 2 \n\n\u03b1 2|R| \n\n\u03b1 2|R|+1 \n\nEntity Classification \n\nLink Prediction \n\n\u2026\u2026 \n\nRelation #1 \n\nRelation #2 \n\nRelation #|R| \n\nloss L \n\nTasks \n\n\n\nTable 1 :\n1Descriptive statistics of the three selected subsets of our dataset.\n\nTable 2 :\n2Node classification measured by F1-score/accuracy.Model \nPureP \nP50 \nP20\u223c50 \nP+all \n\nFollow Relation \n\nGCN+ \n0.8696/0.6167 \n0.9593/0.8308 \n0.9870/0.9576 \n0.9855/0.9329 \nr-GCN \n0.8596/0.6091 \n0.9488/0.8023 \n0.9872/0.9537 \n0.9685/0.9201 \nHAN+ \n0.8891/0.7267 \n0.9598/0.8642 \n0.9620/0.8850 \n0.9723/0.9256 \n\nTIMME-single \n0.8809/0.6325 \n0.9717/0.8792 \n0.9920/0.9709 \n0.9936/0.9696 \nTIMME \n0.8763/0.6324 \n0.9811/0.9154 \n0.9945/0.9799 \n0.9943/0.9736 \nTIMME-hierarchical \n0.8812/0.6409 \n0.9809/0.9145 \n0.9984/0.9813 \n0.9944/0.9739 \n\nReply Relation \n\nGCN+ \n0.8602/0.7306 \n0.9625/0.9022 \n0.9381/0.8665 \n0.9705/0.9154 \nr-GCN \n0.7962/0.6279 \n0.9421/0.8714 \n0.8868/0.7815 \n0.9640/0.9085 \nHAN+ \n0.8445/0.6359 \n0.9598/0.8616 \n0.9495/0.8664 \n0.9757/0.9210 \n\nTIMME-single \n0.8685/0.7018 \n0.9695/0.9307 \n0.9593/0.9070 \n0.9775/0.9508 \nTIMME \n0.9077/0.8004 \n0.9781/0.9417 \n0.9747/0.9347 \n0.9849/0.9612 \nTIMME-hierarchical \n0.9224/0.8152 \n0.9766/0.9409 \n0.9737/0.9341 \n0.9854/0.9629 \n\nRetweet Relation \n\nGCN+ \n0.8955/0.7145 \n0.9574/0.8493 \n0.9351/0.8408 \n0.9724/0.9303 \nr-GCN \n0.8865/0.6895 \n0.9411/0.8084 \n0.9063/0.7728 \n0.9735/0.9326 \nHAN+ \n0.7646/0.6139 \n0.9658/0.9213 \n0.9478/0.8962 \n0.9750/0.9424 \n\nTIMME-single \n0.9015/ 0.7202 \n0.9754/0.9127 \n0.9673/0.9073 \n0.9824/0.9424 \nTIMME \n0.9094/0.7285 \n0.9779/0.9181 \n0.9772/0.9291 \n0.9858/0.9511 \nTIMME-hierarchical \n0.9105/0.7344 \n0.9780/0.9190 \n0.9766/0.9275 \n0.9869/0.9543 \n\nLike Relation \n\nGCN+ \n0.9007/0.7259 \n0.9527/0.8499 \n0.9349/0.8400 \n0.9690/0.9032 \nr-GCN \n0.8924/0.7161 \n0.9343/0.7966 \n0.9038/0.7681 \n0.9510/0.8945 \nHAN+ \n0.8606/0.6176 \n0.9733/0.8851 \n0.9611/0.9062 \n0.9894/0.9481 \n\nTIMME-single \n0.9113/0.7654 \n0.9725/0.9119 \n0.9655/0.9069 \n0.9796/0.9374 \nTIMME \n0.9249/0.7926 \n0.9753/0.9171 \n0.9759/0.9292 \n0.9846/0.9504 \nTIMME-hierarchical \n0.9278/0.7945 \n0.9752/0.9175 \n0.9752/0.9271 \n0.9851/0.9518 \n\nMention Relation \n\nGCN+ \n0.8480/0.6233 \n0.9602/0.8617 \n0.9261/0.8170 \n0.9665/0.8910 \nr-GCN \n0.8312/0.6023 \n0.9382/0.7963 \n0.8938/0.7563 \n0.9640/0.8902 \nHAN+ \n0.9000/0.7206 \n0.9573/0.8616 \n0.9574/0.8891 \n0.9724/0.9119 \n\nTIMME-single \n0.8587/0.6502 \n0.9713/0.8981 \n0.9614/0.8923 \n0.9725/0.9096 \nTIMME \n0.8684/0.6689 \n0.9730/0.9035 \n0.9730/0.9185 \n0.9839/0.9446 \nTIMME-hierarchical \n0.8643/0.6597 \n0.9732/0.9046 \n0.9723/0.9166 \n0.9846/0.9463 \n\n\nAUC refers to Area Under Curve, PR for precision-recall curve, ROC for receiver operating characteristic curve.\nhttps://libguides.com.edu/c.php?g=649909&p=4556556\nNational General Election Polls data partly available at https://www.realclearpolitics.\nhttps://scrapy.org/ 11 https://developer.twitter.com/ 12 https://www.tweepy.org/ 13 Congress members' name list with party information is publicly available at https: //www.congress.gov/members . 14 Obama and Trump's cabinet is publicly available at https://obamawhitehouse. archives.gov/administration/cabinet and https://www.whitehouse.gov/the-trumpadministration/the-cabinet/ respectively\nhttps://developer.twitter.com/en/docs/basics/rate-limiting\n\nCompare with the visualization of previous election at. Compare with the visualization of previous election at https://en.wikipedia.org/wiki/ Political_party_strength_in_U.S._states.\n\nThe ground-truth election outcome in Florida at. The ground-truth election outcome in Florida at 2016 is at https://en.wikipedia.org/ wiki/2016_United_States_presidential_election_in_Florida.\n\nMass political attitudes and the survey response. Christopher H Achen, American Political Science Review. 69Christopher H Achen. 1975. Mass political attitudes and the survey response. American Political Science Review 69, 4 (1975), 1218-1231.\n\nMulti-task ordinal regression for jointly predicting the trustworthiness and the leading political ideology of news media. Ramy Baly, Georgi Karadzhov, Abdelrhman Saleh, James Glass, Preslav Nakov, arXiv:1904.00542arXiv preprintRamy Baly, Georgi Karadzhov, Abdelrhman Saleh, James Glass, and Preslav Nakov. 2019. Multi-task ordinal regression for jointly predicting the trustworthiness and the leading political ideology of news media. arXiv preprint arXiv:1904.00542 (2019).\n\nRepresentation learning for attributed multiplex heterogeneous network. Yukuo Cen, Xu Zou, Jianwei Zhang, Hongxia Yang, Jingren Zhou, Jie Tang, Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data MiningYukuo Cen, Xu Zou, Jianwei Zhang, Hongxia Yang, Jingren Zhou, and Jie Tang. 2019. Representation learning for attributed multiplex heterogeneous network. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 1358-1368.\n\nFastgcn: fast learning with graph convolutional networks via importance sampling. Jie Chen, Tengfei Ma, Cao Xiao, arXiv:1801.10247arXiv preprintJie Chen, Tengfei Ma, and Cao Xiao. 2018. Fastgcn: fast learning with graph convolutional networks via importance sampling. arXiv preprint arXiv:1801.10247 (2018).\n\nOpinionaware Knowledge Graph for Political Ideology Detection. Wei Chen, Xiao Zhang, Tengjiao Wang, Bishan Yang, Yi Li, IJCAI. Wei Chen, Xiao Zhang, Tengjiao Wang, Bishan Yang, and Yi Li. 2017. Opinion- aware Knowledge Graph for Political Ideology Detection.. In IJCAI. 3647-3653.\n\nCluster-gcn: An efficient algorithm for training deep and large graph convolutional networks. Wei-Lin Chiang, Xuanqing Liu, Si Si, Yang Li, Samy Bengio, Cho-Jui Hsieh, Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data MiningWei-Lin Chiang, Xuanqing Liu, Si Si, Yang Li, Samy Bengio, and Cho-Jui Hsieh. 2019. Cluster-gcn: An efficient algorithm for training deep and large graph convolutional networks. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 257-266.\n\nThe statistical analysis of roll call data. Joshua Clinton, Simon Jackman, Douglas Rivers, American Political Science Review. 98Joshua Clinton, Simon Jackman, and Douglas Rivers. 2004. The statistical analysis of roll call data. American Political Science Review 98, 2 (2004), 355-370.\n\nPredicting the political alignment of twitter users. D Michael, Bruno Conover, Jacob Gon\u00e7alves, Alessandro Ratkiewicz, Filippo Flammini, Menczer, 2011 IEEE third international conference on privacy, security, risk and trust and 2011 IEEE third international conference on social computing. IEEEMichael D Conover, Bruno Gon\u00e7alves, Jacob Ratkiewicz, Alessandro Flammini, and Filippo Menczer. 2011. Predicting the political alignment of twitter users. In 2011 IEEE third international conference on privacy, security, risk and trust and 2011 IEEE third international conference on social computing. IEEE, 192-199.\n\nPolitical polarization on twitter. D Michael, Jacob Conover, Matthew Ratkiewicz, Bruno Francisco, Filippo Gon\u00e7alves, Alessandro Menczer, Flammini, Fifth international AAAI conference on weblogs and social media. Michael D Conover, Jacob Ratkiewicz, Matthew Francisco, Bruno Gon\u00e7alves, Filippo Menczer, and Alessandro Flammini. 2011. Political polarization on twitter. In Fifth international AAAI conference on weblogs and social media.\n\nPredicting the Demographics of Twitter Users from Website Traffic Data. Aron Culotta, Ravi Kumar, Jennifer Cutler, AAAI. Austin, TX15Aron Culotta, Nirmal Ravi Kumar, and Jennifer Cutler. 2015. Predicting the Demographics of Twitter Users from Website Traffic Data.. In AAAI, Vol. 15. Austin, TX, 72-8.\n\nConvolutional neural networks on graphs with fast localized spectral filtering. Micha\u00ebl Defferrard, Xavier Bresson, Pierre Vandergheynst, Advances in neural information processing systems. Micha\u00ebl Defferrard, Xavier Bresson, and Pierre Vandergheynst. 2016. Convolu- tional neural networks on graphs with fast localized spectral filtering. In Advances in neural information processing systems. 3844-3852.\n\nnode2vec: Scalable feature learning for networks. Aditya Grover, Jure Leskovec, Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining. the 22nd ACM SIGKDD international conference on Knowledge discovery and data miningAditya Grover and Jure Leskovec. 2016. node2vec: Scalable feature learning for networks. In Proceedings of the 22nd ACM SIGKDD international conference on Knowledge discovery and data mining. 855-864.\n\nIdeology detection for twitter users with heterogeneous types of links. Yupeng Gu, Ting Chen, Yizhou Sun, Bingyu Wang, arXiv:1612.08207arXiv preprintYupeng Gu, Ting Chen, Yizhou Sun, and Bingyu Wang. 2016. Ideology de- tection for twitter users with heterogeneous types of links. arXiv preprint arXiv:1612.08207 (2016).\n\nInductive representation learning on large graphs. Will Hamilton, Zhitao Ying, Jure Leskovec, Advances in neural information processing systems. Will Hamilton, Zhitao Ying, and Jure Leskovec. 2017. Inductive representation learning on large graphs. In Advances in neural information processing systems. 1024-1034.\n\nPolitical ideology detection using recursive neural networks. Mohit Iyyer, Peter Enns, Jordan Boyd-Graber, Philip Resnik, Proceedings of the 52nd. the 52ndMohit Iyyer, Peter Enns, Jordan Boyd-Graber, and Philip Resnik. 2014. Political ideology detection using recursive neural networks. In Proceedings of the 52nd\n\nAnnual Meeting of the Association for Computational Linguistics. Long Papers1Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 1113-1122.\n\nIdentifying stance by analyzing political discourse on twitter. Kristen Johnson, Dan Goldwasser, Proceedings of the First Workshop on NLP and Computational Social Science. the First Workshop on NLP and Computational Social ScienceKristen Johnson and Dan Goldwasser. 2016. Identifying stance by analyzing political discourse on twitter. In Proceedings of the First Workshop on NLP and Computational Social Science. 66-75.\n\nMining twitter for fine-grained political opinion polarity classification, ideology detection and sarcasm detection. Sandeepa Kannangara, Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining. the Eleventh ACM International Conference on Web Search and Data MiningSandeepa Kannangara. 2018. Mining twitter for fine-grained political opinion polarity classification, ideology detection and sarcasm detection. In Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining. 751-752.\n\nMulti-task learning using uncertainty to weigh losses for scene geometry and semantics. Alex Kendall, Yarin Gal, Roberto Cipolla, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionAlex Kendall, Yarin Gal, and Roberto Cipolla. 2018. Multi-task learning using uncertainty to weigh losses for scene geometry and semantics. In Proceedings of the IEEE conference on computer vision and pattern recognition. 7482-7491.\n\nSemi-supervised classification with graph convolutional networks. N Thomas, Max Kipf, Welling, arXiv:1609.02907arXiv preprintThomas N Kipf and Max Welling. 2016. Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907 (2016).\n\nThe national boundaries of solidarity: a survey experiment on solidarity with unemployed people in the European Union. Theresa Kuhn, Aaron Kamm, European Political Science Review. 11Theresa Kuhn and Aaron Kamm. 2019. The national boundaries of solidarity: a survey experiment on solidarity with unemployed people in the European Union. European Political Science Review 11, 2 (2019), 179-195.\n\nDeeper insights into graph convolutional networks for semi-supervised learning. Qimai Li, Zhichao Han, Xiao-Ming Wu, Thirty-Second AAAI Conference on Artificial Intelligence. Qimai Li, Zhichao Han, and Xiao-Ming Wu. 2018. Deeper insights into graph convolutional networks for semi-supervised learning. In Thirty-Second AAAI Conference on Artificial Intelligence.\n\nHeterogeneous graph neural networks for malicious account detection. Ziqi Liu, Chaochao Chen, Xinxing Yang, Jun Zhou, Xiaolong Li, Le Song, Proceedings of the 27th ACM International Conference on Information and Knowledge Management. the 27th ACM International Conference on Information and Knowledge ManagementZiqi Liu, Chaochao Chen, Xinxing Yang, Jun Zhou, Xiaolong Li, and Le Song. 2018. Heterogeneous graph neural networks for malicious account detection. In Proceedings of the 27th ACM International Conference on Information and Knowledge Management. 2077-2085.\n\nTrust across political conflicts: Evidence from a survey experiment in divided societies. Sergio Martini, Mariano Torcal, Party Politics. 25Sergio Martini and Mariano Torcal. 2019. Trust across political conflicts: Evidence from a survey experiment in divided societies. Party Politics 25, 2 (2019), 126-139.\n\nTea party in the house: A hierarchical ideal point topic model and its application to republican legislators in the 112th congress. Viet-An, Jordan Nguyen, Philip Boyd-Graber, Kristina Resnik, Miler, Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing. the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language ProcessingLong Papers1Viet-An Nguyen, Jordan Boyd-Graber, Philip Resnik, and Kristina Miler. 2015. Tea party in the house: A hierarchical ideal point topic model and its application to republican legislators in the 112th congress. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers). 1438- 1448.\n\nDoes Twitter motivate involvement in politics? Tweeting, opinion leadership, and political engagement. Chang Sup, Park , Computers in Human Behavior. 29Chang Sup Park. 2013. Does Twitter motivate involvement in politics? Tweeting, opinion leadership, and political engagement. Computers in Human Behavior 29, 4 (2013), 1641-1648.\n\nGlove: Global vectors for word representation. Jeffrey Pennington, Richard Socher, Christopher D Manning, Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP. the 2014 conference on empirical methods in natural language processing (EMNLPJeffrey Pennington, Richard Socher, and Christopher D Manning. 2014. Glove: Global vectors for word representation. In Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP). 1532-1543.\n\nPopulism, ideology and contradiction: mapping young people's political views. Gary Pollock, Tom Brock, Mark Ellison, The Sociological Review. 63Gary Pollock, Tom Brock, and Mark Ellison. 2015. Populism, ideology and contradiction: mapping young people's political views. The Sociological Review 63 (2015), 141-166.\n\nA spatial model for legislative roll call analysis. T Keith, Howard Poole, Rosenthal, American Journal of Political Science. Keith T Poole and Howard Rosenthal. 1985. A spatial model for legislative roll call analysis. American Journal of Political Science (1985), 357-384.\n\nBeyond binary labels: political ideology prediction of twitter users. Daniel Preo\u0163iuc-Pietro, Ye Liu, Daniel Hopkins, Lyle Ungar, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. the 55th Annual Meeting of the Association for Computational LinguisticsLong Papers1Daniel Preo\u0163iuc-Pietro, Ye Liu, Daniel Hopkins, and Lyle Ungar. 2017. Beyond binary labels: political ideology prediction of twitter users. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 729-740.\n\nNils Reimers, Iryna Gurevych, arXiv:1908.10084Sentence-bert: Sentence embeddings using siamese bert-networks. arXiv preprintNils Reimers and Iryna Gurevych. 2019. Sentence-bert: Sentence embeddings using siamese bert-networks. arXiv preprint arXiv:1908.10084 (2019).\n\nAn overview of multi-task learning in. Sebastian Ruder, arXiv:1706.05098deep neural networks. arXiv preprintSebastian Ruder. 2017. An overview of multi-task learning in deep neural net- works. arXiv preprint arXiv:1706.05098 (2017).\n\nModeling relational data with graph convolutional networks. Michael Schlichtkrull, N Thomas, Peter Kipf, Rianne Bloem, Van Den, Ivan Berg, Max Titov, Welling, European Semantic Web Conference. SpringerMichael Schlichtkrull, Thomas N Kipf, Peter Bloem, Rianne Van Den Berg, Ivan Titov, and Max Welling. 2018. Modeling relational data with graph convolutional networks. In European Semantic Web Conference. Springer, 593-607.\n\nReasoning with neural tensor networks for knowledge base completion. Richard Socher, Danqi Chen, D Christopher, Andrew Manning, Ng, Advances in neural information processing systems. Richard Socher, Danqi Chen, Christopher D Manning, and Andrew Ng. 2013. Rea- soning with neural tensor networks for knowledge base completion. In Advances in neural information processing systems. 926-934.\n\nMining heterogeneous information networks: principles and methodologies. Yizhou Sun, Jiawei Han, Synthesis Lectures on Data Mining and Knowledge Discovery. 3Yizhou Sun and Jiawei Han. 2012. Mining heterogeneous information networks: principles and methodologies. Synthesis Lectures on Data Mining and Knowledge Discovery 3, 2 (2012), 1-159.\n\nLine: Large-scale information network embedding. Jian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, Qiaozhu Mei, Proceedings of the 24th international conference on world wide web. the 24th international conference on world wide webJian Tang, Meng Qu, Mingzhe Wang, Ming Zhang, Jun Yan, and Qiaozhu Mei. 2015. Line: Large-scale information network embedding. In Proceedings of the 24th international conference on world wide web. 1067-1077.\n\nPetar Veli\u010dkovi\u0107, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, Yoshua Bengio, arXiv:1710.10903Graph attention networks. arXiv preprintPetar Veli\u010dkovi\u0107, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. 2017. Graph attention networks. arXiv preprint arXiv:1710.10903 (2017).\n\nTwitter demographic classification using deep multi-modal multi-task learning. Prashanth Vijayaraghavan, Soroush Vosoughi, Deb Roy, Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. the 55th Annual Meeting of the Association for Computational LinguisticsShort Papers2Prashanth Vijayaraghavan, Soroush Vosoughi, and Deb Roy. 2017. Twitter demo- graphic classification using deep multi-modal multi-task learning. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers). 478-483.\n\nShine: Signed heterogeneous information network embedding for sentiment link prediction. Hongwei Wang, Fuzheng Zhang, Min Hou, Xing Xie, Minyi Guo, Qi Liu, Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining. the Eleventh ACM International Conference on Web Search and Data MiningHongwei Wang, Fuzheng Zhang, Min Hou, Xing Xie, Minyi Guo, and Qi Liu. 2018. Shine: Signed heterogeneous information network embedding for sentiment link prediction. In Proceedings of the Eleventh ACM International Conference on Web Search and Data Mining. 592-600.\n\nHeterogeneous graph attention network. Xiao Wang, Houye Ji, Chuan Shi, Bai Wang, Yanfang Ye, Peng Cui, Philip S Yu, The World Wide Web Conference. Xiao Wang, Houye Ji, Chuan Shi, Bai Wang, Yanfang Ye, Peng Cui, and Philip S Yu. 2019. Heterogeneous graph attention network. In The World Wide Web Conference. 2022-2032.\n\n. Keyulu Xu, Weihua Hu, Jure Leskovec, Stefanie Jegelka, arXiv:1810.00826arXiv preprintKeyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. 2018. How powerful are graph neural networks? arXiv preprint arXiv:1810.00826 (2018).\n\nBishan Yang, Wen-Tau Yih, Xiaodong He, Jianfeng Gao, Li Deng, arXiv:1412.6575Embedding entities and relations for learning and inference in knowledge bases. arXiv preprintBishan Yang, Wen-tau Yih, Xiaodong He, Jianfeng Gao, and Li Deng. 2014. Em- bedding entities and relations for learning and inference in knowledge bases. arXiv preprint arXiv:1412.6575 (2014).\n\nGraph Transformer Networks. Seongjun Yun, Minbyul Jeong, Raehyun Kim, Jaewoo Kang, Hyunwoo J Kim, Advances in Neural Information Processing Systems. Seongjun Yun, Minbyul Jeong, Raehyun Kim, Jaewoo Kang, and Hyunwoo J Kim. 2019. Graph Transformer Networks. In Advances in Neural Information Processing Systems. 11960-11970.\n\nHeterogeneous graph neural network. Chuxu Zhang, Dongjin Song, Chao Huang, Ananthram Swami, Nitesh V Chawla, Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data MiningChuxu Zhang, Dongjin Song, Chao Huang, Ananthram Swami, and Nitesh V Chawla. 2019. Heterogeneous graph neural network. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. 793-803.\n", "annotations": {"author": "[{\"end\":130,\"start\":117},{\"end\":168,\"start\":131},{\"end\":179,\"start\":169},{\"end\":193,\"start\":180},{\"end\":223,\"start\":194},{\"end\":237,\"start\":224},{\"end\":251,\"start\":238},{\"end\":262,\"start\":252},{\"end\":276,\"start\":263},{\"end\":288,\"start\":277},{\"end\":365,\"start\":289},{\"end\":441,\"start\":366},{\"end\":492,\"start\":442},{\"end\":540,\"start\":493},{\"end\":574,\"start\":541}]", "publisher": null, "author_last_name": "[{\"end\":129,\"start\":125},{\"end\":143,\"start\":139},{\"end\":178,\"start\":176},{\"end\":192,\"start\":189},{\"end\":204,\"start\":201},{\"end\":236,\"start\":232},{\"end\":250,\"start\":246},{\"end\":261,\"start\":259},{\"end\":275,\"start\":272}]", "author_first_name": "[{\"end\":124,\"start\":117},{\"end\":138,\"start\":131},{\"end\":175,\"start\":169},{\"end\":188,\"start\":180},{\"end\":200,\"start\":194},{\"end\":231,\"start\":224},{\"end\":245,\"start\":238},{\"end\":258,\"start\":252},{\"end\":271,\"start\":263},{\"end\":283,\"start\":277},{\"end\":287,\"start\":284}]", "author_affiliation": "[{\"end\":364,\"start\":290},{\"end\":440,\"start\":367},{\"end\":491,\"start\":443},{\"end\":539,\"start\":494},{\"end\":573,\"start\":542}]", "title": "[{\"end\":76,\"start\":1},{\"end\":650,\"start\":575}]", "venue": "[{\"end\":655,\"start\":652}]", "abstract": "[{\"end\":2588,\"start\":1026}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3243,\"start\":3240},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":3246,\"start\":3243},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":3597,\"start\":3593},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":3683,\"start\":3680},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3685,\"start\":3683},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":3689,\"start\":3685},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":3693,\"start\":3689},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":3697,\"start\":3693},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3840,\"start\":3837},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":3843,\"start\":3840},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":3846,\"start\":3843},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":3849,\"start\":3846},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":5197,\"start\":5193},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":5776,\"start\":5773},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":5779,\"start\":5776},{\"end\":7444,\"start\":7441},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":7447,\"start\":7444},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":7450,\"start\":7447},{\"end\":7516,\"start\":7481},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":7697,\"start\":7694},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":7700,\"start\":7697},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":7755,\"start\":7752},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":7784,\"start\":7780},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":7787,\"start\":7784},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":7790,\"start\":7787},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":7925,\"start\":7921},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":7999,\"start\":7995},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":8126,\"start\":8123},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":8129,\"start\":8126},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":8132,\"start\":8129},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":8276,\"start\":8273},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":8278,\"start\":8276},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":8282,\"start\":8278},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":8286,\"start\":8282},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":8290,\"start\":8286},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":8330,\"start\":8327},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":8333,\"start\":8330},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":8878,\"start\":8874},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":8881,\"start\":8878},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":8960,\"start\":8956},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":9072,\"start\":9068},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":9441,\"start\":9437},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":9457,\"start\":9454},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":9536,\"start\":9532},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":9765,\"start\":9761},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":9779,\"start\":9776},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":9851,\"start\":9847},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":10090,\"start\":10086},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":10421,\"start\":10417},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":10712,\"start\":10708},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":11042,\"start\":11038},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":11376,\"start\":11372},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":12269,\"start\":12265},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":12640,\"start\":12636},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":12723,\"start\":12719},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":12860,\"start\":12856},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":15933,\"start\":15929},{\"end\":16170,\"start\":16167},{\"end\":17612,\"start\":17608},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":17825,\"start\":17822},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":17937,\"start\":17933},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":19290,\"start\":19286},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":20178,\"start\":20174},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":20559,\"start\":20555},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":20606,\"start\":20602},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":24360,\"start\":24359},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":24486,\"start\":24482},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":24497,\"start\":24494},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":24510,\"start\":24506},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":24596,\"start\":24592},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":24687,\"start\":24683},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":24830,\"start\":24826},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":24845,\"start\":24841},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":27941,\"start\":27938},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":29461,\"start\":29460},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":29865,\"start\":29864},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":30268,\"start\":30267},{\"end\":30963,\"start\":30960},{\"end\":31016,\"start\":31013},{\"end\":31069,\"start\":31066},{\"end\":31241,\"start\":31238},{\"end\":31495,\"start\":31493},{\"end\":32116,\"start\":32113},{\"end\":32127,\"start\":32124},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":36057,\"start\":36055},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":37124,\"start\":37122},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":39914,\"start\":39911},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":39916,\"start\":39914},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":41099,\"start\":41097},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":41589,\"start\":41585},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":41671,\"start\":41667},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":42996,\"start\":42993},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":43102,\"start\":43099},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":43146,\"start\":43143}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":47457,\"start\":47270},{\"attributes\":{\"id\":\"fig_1\"},\"end\":47792,\"start\":47458},{\"attributes\":{\"id\":\"fig_2\"},\"end\":47876,\"start\":47793},{\"attributes\":{\"id\":\"fig_3\"},\"end\":47972,\"start\":47877},{\"attributes\":{\"id\":\"fig_4\"},\"end\":48257,\"start\":47973},{\"attributes\":{\"id\":\"fig_6\"},\"end\":48440,\"start\":48258},{\"attributes\":{\"id\":\"fig_7\"},\"end\":48776,\"start\":48441},{\"attributes\":{\"id\":\"fig_8\"},\"end\":48843,\"start\":48777},{\"attributes\":{\"id\":\"fig_9\"},\"end\":49244,\"start\":48844},{\"attributes\":{\"id\":\"fig_10\"},\"end\":49699,\"start\":49245},{\"attributes\":{\"id\":\"fig_11\"},\"end\":49748,\"start\":49700},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":50293,\"start\":49749},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":50374,\"start\":50294},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":52672,\"start\":50375}]", "paragraph": "[{\"end\":3598,\"start\":2604},{\"end\":4032,\"start\":3600},{\"end\":4804,\"start\":4034},{\"end\":5663,\"start\":4806},{\"end\":5963,\"start\":5665},{\"end\":6340,\"start\":5965},{\"end\":6966,\"start\":6342},{\"end\":7271,\"start\":6968},{\"end\":8656,\"start\":7311},{\"end\":9306,\"start\":8688},{\"end\":9818,\"start\":9308},{\"end\":10338,\"start\":9820},{\"end\":10977,\"start\":10340},{\"end\":11266,\"start\":10997},{\"end\":11984,\"start\":11268},{\"end\":13069,\"start\":12014},{\"end\":13226,\"start\":13092},{\"end\":13499,\"start\":13228},{\"end\":13680,\"start\":13501},{\"end\":13922,\"start\":13732},{\"end\":14423,\"start\":13975},{\"end\":14753,\"start\":14425},{\"end\":15210,\"start\":14878},{\"end\":15502,\"start\":15226},{\"end\":15685,\"start\":15529},{\"end\":15881,\"start\":15687},{\"end\":16445,\"start\":15883},{\"end\":16564,\"start\":16480},{\"end\":16778,\"start\":16617},{\"end\":16875,\"start\":16800},{\"end\":18038,\"start\":16904},{\"end\":18226,\"start\":18106},{\"end\":18374,\"start\":18258},{\"end\":18809,\"start\":18710},{\"end\":18949,\"start\":18850},{\"end\":19733,\"start\":18951},{\"end\":20125,\"start\":19756},{\"end\":20220,\"start\":20127},{\"end\":20785,\"start\":20272},{\"end\":20952,\"start\":20787},{\"end\":21104,\"start\":21056},{\"end\":21630,\"start\":21147},{\"end\":22119,\"start\":21632},{\"end\":22413,\"start\":22135},{\"end\":23233,\"start\":22434},{\"end\":23811,\"start\":23235},{\"end\":24361,\"start\":23838},{\"end\":25001,\"start\":24383},{\"end\":26615,\"start\":25003},{\"end\":27282,\"start\":26626},{\"end\":29123,\"start\":27284},{\"end\":30631,\"start\":29182},{\"end\":31232,\"start\":30659},{\"end\":32477,\"start\":31234},{\"end\":33269,\"start\":32503},{\"end\":33971,\"start\":33310},{\"end\":35389,\"start\":33986},{\"end\":35532,\"start\":35409},{\"end\":35912,\"start\":35555},{\"end\":36380,\"start\":35914},{\"end\":36697,\"start\":36412},{\"end\":36861,\"start\":36699},{\"end\":37744,\"start\":36863},{\"end\":37908,\"start\":37746},{\"end\":38551,\"start\":37910},{\"end\":38849,\"start\":38553},{\"end\":39131,\"start\":38851},{\"end\":40266,\"start\":39133},{\"end\":41348,\"start\":40295},{\"end\":42079,\"start\":41376},{\"end\":42823,\"start\":42105},{\"end\":43235,\"start\":42859},{\"end\":43974,\"start\":43386},{\"end\":44511,\"start\":44006},{\"end\":45229,\"start\":44513},{\"end\":45779,\"start\":45254},{\"end\":46033,\"start\":45781},{\"end\":47269,\"start\":46056}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":13731,\"start\":13681},{\"attributes\":{\"id\":\"formula_1\"},\"end\":13974,\"start\":13923},{\"attributes\":{\"id\":\"formula_2\"},\"end\":14877,\"start\":14754},{\"attributes\":{\"id\":\"formula_3\"},\"end\":16479,\"start\":16446},{\"attributes\":{\"id\":\"formula_4\"},\"end\":16616,\"start\":16565},{\"attributes\":{\"id\":\"formula_5\"},\"end\":16799,\"start\":16779},{\"attributes\":{\"id\":\"formula_6\"},\"end\":16903,\"start\":16876},{\"attributes\":{\"id\":\"formula_7\"},\"end\":18105,\"start\":18039},{\"attributes\":{\"id\":\"formula_8\"},\"end\":18257,\"start\":18227},{\"attributes\":{\"id\":\"formula_9\"},\"end\":18709,\"start\":18375},{\"attributes\":{\"id\":\"formula_10\"},\"end\":18849,\"start\":18810},{\"attributes\":{\"id\":\"formula_11\"},\"end\":20271,\"start\":20221},{\"attributes\":{\"id\":\"formula_12\"},\"end\":21055,\"start\":20953},{\"attributes\":{\"id\":\"formula_13\"},\"end\":21146,\"start\":21105},{\"attributes\":{\"id\":\"formula_14\"},\"end\":43292,\"start\":43236}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":22271,\"start\":22264},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":23091,\"start\":23084},{\"end\":23766,\"start\":23759},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":27306,\"start\":27299},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":40265,\"start\":40258}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2602,\"start\":2590},{\"attributes\":{\"n\":\"2\"},\"end\":7309,\"start\":7274},{\"attributes\":{\"n\":\"2.2\"},\"end\":8686,\"start\":8659},{\"attributes\":{\"n\":\"2.2.2\"},\"end\":10995,\"start\":10980},{\"attributes\":{\"n\":\"2.3\"},\"end\":12012,\"start\":11987},{\"attributes\":{\"n\":\"3\"},\"end\":13090,\"start\":13072},{\"attributes\":{\"n\":\"4\"},\"end\":15224,\"start\":15213},{\"attributes\":{\"n\":\"4.1\"},\"end\":15527,\"start\":15505},{\"attributes\":{\"n\":\"4.2\"},\"end\":19754,\"start\":19736},{\"attributes\":{\"n\":\"5\"},\"end\":22133,\"start\":22122},{\"attributes\":{\"n\":\"5.1\"},\"end\":22432,\"start\":22416},{\"attributes\":{\"n\":\"5.2\"},\"end\":23836,\"start\":23814},{\"attributes\":{\"n\":\"5.2.1\"},\"end\":24381,\"start\":24364},{\"attributes\":{\"n\":\"5.2.2\"},\"end\":26624,\"start\":26618},{\"attributes\":{\"n\":\"5.3\"},\"end\":29138,\"start\":29126},{\"attributes\":{\"n\":\"5.3.2\"},\"end\":29180,\"start\":29141},{\"attributes\":{\"n\":\"5.3.3\"},\"end\":30657,\"start\":30634},{\"attributes\":{\"n\":\"5.3.4\"},\"end\":32501,\"start\":32480},{\"attributes\":{\"n\":\"5.3.5\"},\"end\":33308,\"start\":33272},{\"attributes\":{\"n\":\"6\"},\"end\":33984,\"start\":33974},{\"attributes\":{\"n\":\"7\"},\"end\":35407,\"start\":35392},{\"end\":35553,\"start\":35535},{\"end\":36410,\"start\":36383},{\"end\":40293,\"start\":40269},{\"end\":41374,\"start\":41351},{\"end\":42103,\"start\":42082},{\"end\":42857,\"start\":42826},{\"end\":43384,\"start\":43294},{\"end\":44004,\"start\":43977},{\"end\":45252,\"start\":45232},{\"end\":46054,\"start\":46036},{\"end\":47281,\"start\":47271},{\"end\":47982,\"start\":47974},{\"end\":48269,\"start\":48259},{\"end\":48472,\"start\":48442},{\"end\":48789,\"start\":48778},{\"end\":50304,\"start\":50295},{\"end\":50385,\"start\":50376}]", "table": "[{\"end\":50293,\"start\":49893},{\"end\":52672,\"start\":50437}]", "figure_caption": "[{\"end\":47457,\"start\":47283},{\"end\":47792,\"start\":47460},{\"end\":47876,\"start\":47795},{\"end\":47972,\"start\":47879},{\"end\":48257,\"start\":47984},{\"end\":48440,\"start\":48271},{\"end\":48776,\"start\":48476},{\"end\":48843,\"start\":48792},{\"end\":49244,\"start\":48846},{\"end\":49699,\"start\":49247},{\"end\":49748,\"start\":49702},{\"end\":49893,\"start\":49751},{\"end\":50374,\"start\":50306},{\"end\":50437,\"start\":50387}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":4115,\"start\":4107},{\"end\":15299,\"start\":15291},{\"end\":16230,\"start\":16222},{\"end\":19921,\"start\":19913},{\"end\":20685,\"start\":20677},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":28934,\"start\":28926},{\"end\":29381,\"start\":29373},{\"end\":30927,\"start\":30919},{\"end\":31107,\"start\":31099},{\"end\":32039,\"start\":32031},{\"end\":32818,\"start\":32810},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":33655,\"start\":33645}]", "bib_author_first_name": "[{\"end\":54125,\"start\":54121},{\"end\":54138,\"start\":54132},{\"end\":54160,\"start\":54150},{\"end\":54173,\"start\":54168},{\"end\":54188,\"start\":54181},{\"end\":54552,\"start\":54547},{\"end\":54560,\"start\":54558},{\"end\":54573,\"start\":54566},{\"end\":54588,\"start\":54581},{\"end\":54602,\"start\":54595},{\"end\":54612,\"start\":54609},{\"end\":55150,\"start\":55147},{\"end\":55164,\"start\":55157},{\"end\":55172,\"start\":55169},{\"end\":55440,\"start\":55437},{\"end\":55451,\"start\":55447},{\"end\":55467,\"start\":55459},{\"end\":55480,\"start\":55474},{\"end\":55489,\"start\":55487},{\"end\":55757,\"start\":55750},{\"end\":55774,\"start\":55766},{\"end\":55782,\"start\":55780},{\"end\":55791,\"start\":55787},{\"end\":55800,\"start\":55796},{\"end\":55816,\"start\":55809},{\"end\":56342,\"start\":56336},{\"end\":56357,\"start\":56352},{\"end\":56374,\"start\":56367},{\"end\":56633,\"start\":56632},{\"end\":56648,\"start\":56643},{\"end\":56663,\"start\":56658},{\"end\":56685,\"start\":56675},{\"end\":56705,\"start\":56698},{\"end\":57227,\"start\":57226},{\"end\":57242,\"start\":57237},{\"end\":57259,\"start\":57252},{\"end\":57277,\"start\":57272},{\"end\":57296,\"start\":57289},{\"end\":57318,\"start\":57308},{\"end\":57704,\"start\":57700},{\"end\":57718,\"start\":57714},{\"end\":57734,\"start\":57726},{\"end\":58018,\"start\":58011},{\"end\":58037,\"start\":58031},{\"end\":58053,\"start\":58047},{\"end\":58392,\"start\":58386},{\"end\":58405,\"start\":58401},{\"end\":58879,\"start\":58873},{\"end\":58888,\"start\":58884},{\"end\":58901,\"start\":58895},{\"end\":58913,\"start\":58907},{\"end\":59177,\"start\":59173},{\"end\":59194,\"start\":59188},{\"end\":59205,\"start\":59201},{\"end\":59504,\"start\":59499},{\"end\":59517,\"start\":59512},{\"end\":59530,\"start\":59524},{\"end\":59550,\"start\":59544},{\"end\":60001,\"start\":59994},{\"end\":60014,\"start\":60011},{\"end\":60477,\"start\":60469},{\"end\":60986,\"start\":60982},{\"end\":61001,\"start\":60996},{\"end\":61014,\"start\":61007},{\"end\":61466,\"start\":61465},{\"end\":61478,\"start\":61475},{\"end\":61794,\"start\":61787},{\"end\":61806,\"start\":61801},{\"end\":62147,\"start\":62142},{\"end\":62159,\"start\":62152},{\"end\":62174,\"start\":62165},{\"end\":62499,\"start\":62495},{\"end\":62513,\"start\":62505},{\"end\":62527,\"start\":62520},{\"end\":62537,\"start\":62534},{\"end\":62552,\"start\":62544},{\"end\":62559,\"start\":62557},{\"end\":63092,\"start\":63086},{\"end\":63109,\"start\":63102},{\"end\":63453,\"start\":63447},{\"end\":63468,\"start\":63462},{\"end\":63490,\"start\":63482},{\"end\":64347,\"start\":64342},{\"end\":64357,\"start\":64353},{\"end\":64624,\"start\":64617},{\"end\":64644,\"start\":64637},{\"end\":64666,\"start\":64653},{\"end\":65158,\"start\":65154},{\"end\":65171,\"start\":65168},{\"end\":65183,\"start\":65179},{\"end\":65445,\"start\":65444},{\"end\":65459,\"start\":65453},{\"end\":65743,\"start\":65737},{\"end\":65763,\"start\":65761},{\"end\":65775,\"start\":65769},{\"end\":65789,\"start\":65785},{\"end\":66240,\"start\":66236},{\"end\":66255,\"start\":66250},{\"end\":66552,\"start\":66543},{\"end\":66805,\"start\":66798},{\"end\":66822,\"start\":66821},{\"end\":66836,\"start\":66831},{\"end\":66849,\"start\":66843},{\"end\":66870,\"start\":66866},{\"end\":66880,\"start\":66877},{\"end\":67239,\"start\":67232},{\"end\":67253,\"start\":67248},{\"end\":67261,\"start\":67260},{\"end\":67281,\"start\":67275},{\"end\":67632,\"start\":67626},{\"end\":67644,\"start\":67638},{\"end\":67948,\"start\":67944},{\"end\":67959,\"start\":67955},{\"end\":67971,\"start\":67964},{\"end\":67982,\"start\":67978},{\"end\":67993,\"start\":67990},{\"end\":68006,\"start\":67999},{\"end\":68346,\"start\":68341},{\"end\":68366,\"start\":68359},{\"end\":68384,\"start\":68377},{\"end\":68402,\"start\":68395},{\"end\":68417,\"start\":68411},{\"end\":68429,\"start\":68423},{\"end\":68756,\"start\":68747},{\"end\":68780,\"start\":68773},{\"end\":68794,\"start\":68791},{\"end\":69341,\"start\":69334},{\"end\":69355,\"start\":69348},{\"end\":69366,\"start\":69363},{\"end\":69376,\"start\":69372},{\"end\":69387,\"start\":69382},{\"end\":69395,\"start\":69393},{\"end\":69870,\"start\":69866},{\"end\":69882,\"start\":69877},{\"end\":69892,\"start\":69887},{\"end\":69901,\"start\":69898},{\"end\":69915,\"start\":69908},{\"end\":69924,\"start\":69920},{\"end\":69938,\"start\":69930},{\"end\":70154,\"start\":70148},{\"end\":70165,\"start\":70159},{\"end\":70174,\"start\":70170},{\"end\":70193,\"start\":70185},{\"end\":70385,\"start\":70379},{\"end\":70399,\"start\":70392},{\"end\":70413,\"start\":70405},{\"end\":70426,\"start\":70418},{\"end\":70434,\"start\":70432},{\"end\":70780,\"start\":70772},{\"end\":70793,\"start\":70786},{\"end\":70808,\"start\":70801},{\"end\":70820,\"start\":70814},{\"end\":70836,\"start\":70827},{\"end\":71110,\"start\":71105},{\"end\":71125,\"start\":71118},{\"end\":71136,\"start\":71132},{\"end\":71153,\"start\":71144},{\"end\":71169,\"start\":71161}]", "bib_author_last_name": "[{\"end\":53822,\"start\":53803},{\"end\":54130,\"start\":54126},{\"end\":54148,\"start\":54139},{\"end\":54166,\"start\":54161},{\"end\":54179,\"start\":54174},{\"end\":54194,\"start\":54189},{\"end\":54556,\"start\":54553},{\"end\":54564,\"start\":54561},{\"end\":54579,\"start\":54574},{\"end\":54593,\"start\":54589},{\"end\":54607,\"start\":54603},{\"end\":54617,\"start\":54613},{\"end\":55155,\"start\":55151},{\"end\":55167,\"start\":55165},{\"end\":55177,\"start\":55173},{\"end\":55445,\"start\":55441},{\"end\":55457,\"start\":55452},{\"end\":55472,\"start\":55468},{\"end\":55485,\"start\":55481},{\"end\":55492,\"start\":55490},{\"end\":55764,\"start\":55758},{\"end\":55778,\"start\":55775},{\"end\":55785,\"start\":55783},{\"end\":55794,\"start\":55792},{\"end\":55807,\"start\":55801},{\"end\":55822,\"start\":55817},{\"end\":56350,\"start\":56343},{\"end\":56365,\"start\":56358},{\"end\":56381,\"start\":56375},{\"end\":56641,\"start\":56634},{\"end\":56656,\"start\":56649},{\"end\":56673,\"start\":56664},{\"end\":56696,\"start\":56686},{\"end\":56714,\"start\":56706},{\"end\":56723,\"start\":56716},{\"end\":57235,\"start\":57228},{\"end\":57250,\"start\":57243},{\"end\":57270,\"start\":57260},{\"end\":57287,\"start\":57278},{\"end\":57306,\"start\":57297},{\"end\":57326,\"start\":57319},{\"end\":57336,\"start\":57328},{\"end\":57712,\"start\":57705},{\"end\":57724,\"start\":57719},{\"end\":57741,\"start\":57735},{\"end\":58029,\"start\":58019},{\"end\":58045,\"start\":58038},{\"end\":58067,\"start\":58054},{\"end\":58399,\"start\":58393},{\"end\":58414,\"start\":58406},{\"end\":58882,\"start\":58880},{\"end\":58893,\"start\":58889},{\"end\":58905,\"start\":58902},{\"end\":58918,\"start\":58914},{\"end\":59186,\"start\":59178},{\"end\":59199,\"start\":59195},{\"end\":59214,\"start\":59206},{\"end\":59510,\"start\":59505},{\"end\":59522,\"start\":59518},{\"end\":59542,\"start\":59531},{\"end\":59557,\"start\":59551},{\"end\":60009,\"start\":60002},{\"end\":60025,\"start\":60015},{\"end\":60488,\"start\":60478},{\"end\":60994,\"start\":60987},{\"end\":61005,\"start\":61002},{\"end\":61022,\"start\":61015},{\"end\":61473,\"start\":61467},{\"end\":61483,\"start\":61479},{\"end\":61492,\"start\":61485},{\"end\":61799,\"start\":61795},{\"end\":61811,\"start\":61807},{\"end\":62150,\"start\":62148},{\"end\":62163,\"start\":62160},{\"end\":62177,\"start\":62175},{\"end\":62503,\"start\":62500},{\"end\":62518,\"start\":62514},{\"end\":62532,\"start\":62528},{\"end\":62542,\"start\":62538},{\"end\":62555,\"start\":62553},{\"end\":62564,\"start\":62560},{\"end\":63100,\"start\":63093},{\"end\":63116,\"start\":63110},{\"end\":63445,\"start\":63438},{\"end\":63460,\"start\":63454},{\"end\":63480,\"start\":63469},{\"end\":63497,\"start\":63491},{\"end\":63504,\"start\":63499},{\"end\":64351,\"start\":64348},{\"end\":64635,\"start\":64625},{\"end\":64651,\"start\":64645},{\"end\":64674,\"start\":64667},{\"end\":65166,\"start\":65159},{\"end\":65177,\"start\":65172},{\"end\":65191,\"start\":65184},{\"end\":65451,\"start\":65446},{\"end\":65465,\"start\":65460},{\"end\":65476,\"start\":65467},{\"end\":65759,\"start\":65744},{\"end\":65767,\"start\":65764},{\"end\":65783,\"start\":65776},{\"end\":65795,\"start\":65790},{\"end\":66248,\"start\":66241},{\"end\":66264,\"start\":66256},{\"end\":66558,\"start\":66553},{\"end\":66819,\"start\":66806},{\"end\":66829,\"start\":66823},{\"end\":66841,\"start\":66837},{\"end\":66855,\"start\":66850},{\"end\":66864,\"start\":66857},{\"end\":66875,\"start\":66871},{\"end\":66886,\"start\":66881},{\"end\":66895,\"start\":66888},{\"end\":67246,\"start\":67240},{\"end\":67258,\"start\":67254},{\"end\":67273,\"start\":67262},{\"end\":67289,\"start\":67282},{\"end\":67293,\"start\":67291},{\"end\":67636,\"start\":67633},{\"end\":67648,\"start\":67645},{\"end\":67953,\"start\":67949},{\"end\":67962,\"start\":67960},{\"end\":67976,\"start\":67972},{\"end\":67988,\"start\":67983},{\"end\":67997,\"start\":67994},{\"end\":68010,\"start\":68007},{\"end\":68357,\"start\":68347},{\"end\":68375,\"start\":68367},{\"end\":68393,\"start\":68385},{\"end\":68409,\"start\":68403},{\"end\":68421,\"start\":68418},{\"end\":68436,\"start\":68430},{\"end\":68771,\"start\":68757},{\"end\":68789,\"start\":68781},{\"end\":68798,\"start\":68795},{\"end\":69346,\"start\":69342},{\"end\":69361,\"start\":69356},{\"end\":69370,\"start\":69367},{\"end\":69380,\"start\":69377},{\"end\":69391,\"start\":69388},{\"end\":69399,\"start\":69396},{\"end\":69875,\"start\":69871},{\"end\":69885,\"start\":69883},{\"end\":69896,\"start\":69893},{\"end\":69906,\"start\":69902},{\"end\":69918,\"start\":69916},{\"end\":69928,\"start\":69925},{\"end\":69941,\"start\":69939},{\"end\":70157,\"start\":70155},{\"end\":70168,\"start\":70166},{\"end\":70183,\"start\":70175},{\"end\":70201,\"start\":70194},{\"end\":70390,\"start\":70386},{\"end\":70403,\"start\":70400},{\"end\":70416,\"start\":70414},{\"end\":70430,\"start\":70427},{\"end\":70439,\"start\":70435},{\"end\":70784,\"start\":70781},{\"end\":70799,\"start\":70794},{\"end\":70812,\"start\":70809},{\"end\":70825,\"start\":70821},{\"end\":70840,\"start\":70837},{\"end\":71116,\"start\":71111},{\"end\":71130,\"start\":71126},{\"end\":71142,\"start\":71137},{\"end\":71159,\"start\":71154},{\"end\":71176,\"start\":71170}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":53558,\"start\":53376},{\"attributes\":{\"id\":\"b1\"},\"end\":53751,\"start\":53560},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":143606941},\"end\":53996,\"start\":53753},{\"attributes\":{\"doi\":\"arXiv:1904.00542\",\"id\":\"b3\"},\"end\":54473,\"start\":53998},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":146121289},\"end\":55063,\"start\":54475},{\"attributes\":{\"doi\":\"arXiv:1801.10247\",\"id\":\"b5\"},\"end\":55372,\"start\":55065},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":33053989},\"end\":55654,\"start\":55374},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":159042192},\"end\":56290,\"start\":55656},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":7487820},\"end\":56577,\"start\":56292},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":12320930},\"end\":57189,\"start\":56579},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":2155574},\"end\":57626,\"start\":57191},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":10347997},\"end\":57929,\"start\":57628},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":3016223},\"end\":58334,\"start\":57931},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":207238980},\"end\":58799,\"start\":58336},{\"attributes\":{\"doi\":\"arXiv:1612.08207\",\"id\":\"b14\"},\"end\":59120,\"start\":58801},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":4755450},\"end\":59435,\"start\":59122},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":216636598},\"end\":59750,\"start\":59437},{\"attributes\":{\"id\":\"b17\"},\"end\":59928,\"start\":59752},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":15078449},\"end\":60350,\"start\":59930},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":22373433},\"end\":60892,\"start\":60352},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":4800342},\"end\":61397,\"start\":60894},{\"attributes\":{\"doi\":\"arXiv:1609.02907\",\"id\":\"b21\"},\"end\":61666,\"start\":61399},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":191830365},\"end\":62060,\"start\":61668},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":11118105},\"end\":62424,\"start\":62062},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":53038390},\"end\":62994,\"start\":62426},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":152188784},\"end\":63304,\"start\":62996},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":216654599},\"end\":64237,\"start\":63306},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":206614511},\"end\":64568,\"start\":64239},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":1957433},\"end\":65074,\"start\":64570},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":145075204},\"end\":65390,\"start\":65076},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":153517672},\"end\":65665,\"start\":65392},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":27843613},\"end\":66234,\"start\":65667},{\"attributes\":{\"doi\":\"arXiv:1908.10084\",\"id\":\"b32\"},\"end\":66502,\"start\":66236},{\"attributes\":{\"doi\":\"arXiv:1706.05098\",\"id\":\"b33\",\"matched_paper_id\":90063862},\"end\":66736,\"start\":66504},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":5458500},\"end\":67161,\"start\":66738},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":8429835},\"end\":67551,\"start\":67163},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":207319031},\"end\":67893,\"start\":67553},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":8399404},\"end\":68339,\"start\":67895},{\"attributes\":{\"doi\":\"arXiv:1710.10903\",\"id\":\"b38\"},\"end\":68666,\"start\":68341},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":26939597},\"end\":69243,\"start\":68668},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":20401422},\"end\":69825,\"start\":69245},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":81978964},\"end\":70144,\"start\":69827},{\"attributes\":{\"doi\":\"arXiv:1810.00826\",\"id\":\"b42\"},\"end\":70377,\"start\":70146},{\"attributes\":{\"doi\":\"arXiv:1412.6575\",\"id\":\"b43\"},\"end\":70742,\"start\":70379},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":202763464},\"end\":71067,\"start\":70744},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":198952485},\"end\":71585,\"start\":71069}]", "bib_title": "[{\"end\":53801,\"start\":53753},{\"end\":54545,\"start\":54475},{\"end\":55435,\"start\":55374},{\"end\":55748,\"start\":55656},{\"end\":56334,\"start\":56292},{\"end\":56630,\"start\":56579},{\"end\":57224,\"start\":57191},{\"end\":57698,\"start\":57628},{\"end\":58009,\"start\":57931},{\"end\":58384,\"start\":58336},{\"end\":59171,\"start\":59122},{\"end\":59497,\"start\":59437},{\"end\":59992,\"start\":59930},{\"end\":60467,\"start\":60352},{\"end\":60980,\"start\":60894},{\"end\":61785,\"start\":61668},{\"end\":62140,\"start\":62062},{\"end\":62493,\"start\":62426},{\"end\":63084,\"start\":62996},{\"end\":63436,\"start\":63306},{\"end\":64340,\"start\":64239},{\"end\":64615,\"start\":64570},{\"end\":65152,\"start\":65076},{\"end\":65442,\"start\":65392},{\"end\":65735,\"start\":65667},{\"end\":66541,\"start\":66504},{\"end\":66796,\"start\":66738},{\"end\":67230,\"start\":67163},{\"end\":67624,\"start\":67553},{\"end\":67942,\"start\":67895},{\"end\":68745,\"start\":68668},{\"end\":69332,\"start\":69245},{\"end\":69864,\"start\":69827},{\"end\":70770,\"start\":70744},{\"end\":71103,\"start\":71069}]", "bib_author": "[{\"end\":53824,\"start\":53803},{\"end\":54132,\"start\":54121},{\"end\":54150,\"start\":54132},{\"end\":54168,\"start\":54150},{\"end\":54181,\"start\":54168},{\"end\":54196,\"start\":54181},{\"end\":54558,\"start\":54547},{\"end\":54566,\"start\":54558},{\"end\":54581,\"start\":54566},{\"end\":54595,\"start\":54581},{\"end\":54609,\"start\":54595},{\"end\":54619,\"start\":54609},{\"end\":55157,\"start\":55147},{\"end\":55169,\"start\":55157},{\"end\":55179,\"start\":55169},{\"end\":55447,\"start\":55437},{\"end\":55459,\"start\":55447},{\"end\":55474,\"start\":55459},{\"end\":55487,\"start\":55474},{\"end\":55494,\"start\":55487},{\"end\":55766,\"start\":55750},{\"end\":55780,\"start\":55766},{\"end\":55787,\"start\":55780},{\"end\":55796,\"start\":55787},{\"end\":55809,\"start\":55796},{\"end\":55824,\"start\":55809},{\"end\":56352,\"start\":56336},{\"end\":56367,\"start\":56352},{\"end\":56383,\"start\":56367},{\"end\":56643,\"start\":56632},{\"end\":56658,\"start\":56643},{\"end\":56675,\"start\":56658},{\"end\":56698,\"start\":56675},{\"end\":56716,\"start\":56698},{\"end\":56725,\"start\":56716},{\"end\":57237,\"start\":57226},{\"end\":57252,\"start\":57237},{\"end\":57272,\"start\":57252},{\"end\":57289,\"start\":57272},{\"end\":57308,\"start\":57289},{\"end\":57328,\"start\":57308},{\"end\":57338,\"start\":57328},{\"end\":57714,\"start\":57700},{\"end\":57726,\"start\":57714},{\"end\":57743,\"start\":57726},{\"end\":58031,\"start\":58011},{\"end\":58047,\"start\":58031},{\"end\":58069,\"start\":58047},{\"end\":58401,\"start\":58386},{\"end\":58416,\"start\":58401},{\"end\":58884,\"start\":58873},{\"end\":58895,\"start\":58884},{\"end\":58907,\"start\":58895},{\"end\":58920,\"start\":58907},{\"end\":59188,\"start\":59173},{\"end\":59201,\"start\":59188},{\"end\":59216,\"start\":59201},{\"end\":59512,\"start\":59499},{\"end\":59524,\"start\":59512},{\"end\":59544,\"start\":59524},{\"end\":59559,\"start\":59544},{\"end\":60011,\"start\":59994},{\"end\":60027,\"start\":60011},{\"end\":60490,\"start\":60469},{\"end\":60996,\"start\":60982},{\"end\":61007,\"start\":60996},{\"end\":61024,\"start\":61007},{\"end\":61475,\"start\":61465},{\"end\":61485,\"start\":61475},{\"end\":61494,\"start\":61485},{\"end\":61801,\"start\":61787},{\"end\":61813,\"start\":61801},{\"end\":62152,\"start\":62142},{\"end\":62165,\"start\":62152},{\"end\":62179,\"start\":62165},{\"end\":62505,\"start\":62495},{\"end\":62520,\"start\":62505},{\"end\":62534,\"start\":62520},{\"end\":62544,\"start\":62534},{\"end\":62557,\"start\":62544},{\"end\":62566,\"start\":62557},{\"end\":63102,\"start\":63086},{\"end\":63118,\"start\":63102},{\"end\":63447,\"start\":63438},{\"end\":63462,\"start\":63447},{\"end\":63482,\"start\":63462},{\"end\":63499,\"start\":63482},{\"end\":63506,\"start\":63499},{\"end\":64353,\"start\":64342},{\"end\":64360,\"start\":64353},{\"end\":64637,\"start\":64617},{\"end\":64653,\"start\":64637},{\"end\":64676,\"start\":64653},{\"end\":65168,\"start\":65154},{\"end\":65179,\"start\":65168},{\"end\":65193,\"start\":65179},{\"end\":65453,\"start\":65444},{\"end\":65467,\"start\":65453},{\"end\":65478,\"start\":65467},{\"end\":65761,\"start\":65737},{\"end\":65769,\"start\":65761},{\"end\":65785,\"start\":65769},{\"end\":65797,\"start\":65785},{\"end\":66250,\"start\":66236},{\"end\":66266,\"start\":66250},{\"end\":66560,\"start\":66543},{\"end\":66821,\"start\":66798},{\"end\":66831,\"start\":66821},{\"end\":66843,\"start\":66831},{\"end\":66857,\"start\":66843},{\"end\":66866,\"start\":66857},{\"end\":66877,\"start\":66866},{\"end\":66888,\"start\":66877},{\"end\":66897,\"start\":66888},{\"end\":67248,\"start\":67232},{\"end\":67260,\"start\":67248},{\"end\":67275,\"start\":67260},{\"end\":67291,\"start\":67275},{\"end\":67295,\"start\":67291},{\"end\":67638,\"start\":67626},{\"end\":67650,\"start\":67638},{\"end\":67955,\"start\":67944},{\"end\":67964,\"start\":67955},{\"end\":67978,\"start\":67964},{\"end\":67990,\"start\":67978},{\"end\":67999,\"start\":67990},{\"end\":68012,\"start\":67999},{\"end\":68359,\"start\":68341},{\"end\":68377,\"start\":68359},{\"end\":68395,\"start\":68377},{\"end\":68411,\"start\":68395},{\"end\":68423,\"start\":68411},{\"end\":68438,\"start\":68423},{\"end\":68773,\"start\":68747},{\"end\":68791,\"start\":68773},{\"end\":68800,\"start\":68791},{\"end\":69348,\"start\":69334},{\"end\":69363,\"start\":69348},{\"end\":69372,\"start\":69363},{\"end\":69382,\"start\":69372},{\"end\":69393,\"start\":69382},{\"end\":69401,\"start\":69393},{\"end\":69877,\"start\":69866},{\"end\":69887,\"start\":69877},{\"end\":69898,\"start\":69887},{\"end\":69908,\"start\":69898},{\"end\":69920,\"start\":69908},{\"end\":69930,\"start\":69920},{\"end\":69943,\"start\":69930},{\"end\":70159,\"start\":70148},{\"end\":70170,\"start\":70159},{\"end\":70185,\"start\":70170},{\"end\":70203,\"start\":70185},{\"end\":70392,\"start\":70379},{\"end\":70405,\"start\":70392},{\"end\":70418,\"start\":70405},{\"end\":70432,\"start\":70418},{\"end\":70441,\"start\":70432},{\"end\":70786,\"start\":70772},{\"end\":70801,\"start\":70786},{\"end\":70814,\"start\":70801},{\"end\":70827,\"start\":70814},{\"end\":70842,\"start\":70827},{\"end\":71118,\"start\":71105},{\"end\":71132,\"start\":71118},{\"end\":71144,\"start\":71132},{\"end\":71161,\"start\":71144},{\"end\":71178,\"start\":71161}]", "bib_venue": "[{\"end\":53430,\"start\":53376},{\"end\":53607,\"start\":53560},{\"end\":53857,\"start\":53824},{\"end\":54119,\"start\":53998},{\"end\":54715,\"start\":54619},{\"end\":55145,\"start\":55065},{\"end\":55499,\"start\":55494},{\"end\":55920,\"start\":55824},{\"end\":56416,\"start\":56383},{\"end\":56867,\"start\":56725},{\"end\":57401,\"start\":57338},{\"end\":57747,\"start\":57743},{\"end\":58118,\"start\":58069},{\"end\":58514,\"start\":58416},{\"end\":58871,\"start\":58801},{\"end\":59265,\"start\":59216},{\"end\":59582,\"start\":59559},{\"end\":59815,\"start\":59752},{\"end\":60100,\"start\":60027},{\"end\":60576,\"start\":60490},{\"end\":61101,\"start\":61024},{\"end\":61463,\"start\":61399},{\"end\":61846,\"start\":61813},{\"end\":62235,\"start\":62179},{\"end\":62658,\"start\":62566},{\"end\":63132,\"start\":63118},{\"end\":63667,\"start\":63506},{\"end\":64387,\"start\":64360},{\"end\":64769,\"start\":64676},{\"end\":65216,\"start\":65193},{\"end\":65515,\"start\":65478},{\"end\":65884,\"start\":65797},{\"end\":66344,\"start\":66282},{\"end\":66596,\"start\":66576},{\"end\":66929,\"start\":66897},{\"end\":67344,\"start\":67295},{\"end\":67707,\"start\":67650},{\"end\":68078,\"start\":68012},{\"end\":68478,\"start\":68454},{\"end\":68887,\"start\":68800},{\"end\":69487,\"start\":69401},{\"end\":69972,\"start\":69943},{\"end\":70534,\"start\":70456},{\"end\":70891,\"start\":70842},{\"end\":71274,\"start\":71178},{\"end\":54798,\"start\":54717},{\"end\":56003,\"start\":55922},{\"end\":57759,\"start\":57749},{\"end\":58599,\"start\":58516},{\"end\":59592,\"start\":59584},{\"end\":60160,\"start\":60102},{\"end\":60649,\"start\":60578},{\"end\":61165,\"start\":61103},{\"end\":62737,\"start\":62660},{\"end\":63815,\"start\":63669},{\"end\":64849,\"start\":64771},{\"end\":65958,\"start\":65886},{\"end\":68131,\"start\":68080},{\"end\":68961,\"start\":68889},{\"end\":69560,\"start\":69489},{\"end\":71357,\"start\":71276}]"}}}, "year": 2023, "month": 12, "day": 17}