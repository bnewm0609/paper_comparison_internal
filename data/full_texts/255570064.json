{"id": 255570064, "updated": "2023-11-11 00:50:08.717", "metadata": {"title": "SiFall: Practical Online Fall Detection with RF Sensing", "authors": "[{\"first\":\"Sijie\",\"last\":\"Ji\",\"middle\":[]},{\"first\":\"Yaxiong\",\"last\":\"Xie\",\"middle\":[]},{\"first\":\"Mo\",\"last\":\"Li\",\"middle\":[]}]", "venue": "The 20th ACM Conference on Embedded Networked Sensor Systems, 2022", "journal": "Proceedings of the 20th ACM Conference on Embedded Networked Sensor Systems", "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "Falls are one of the leading causes of death in the elderly people aged 65 and above. In order to prevent death by sending prompt fall detection alarms, non-invasive radio-frequency (RF) based fall detection has attracted significant attention, due to its wide coverage and privacy preserving nature. Existing RF-based fall detection systems process fall as an activity classification problem and assume that human falls introduce reproducible patterns to the RF signals. We, however, argue that the fall is essentially an accident, hence, its impact is uncontrollable and unforeseeable. We propose to solve the fall detection problem in a fundamentally different manner. Instead of directly identifying the human falls which are difficult to quantify, we recognize the normal repeatable human activities and then identify the fall as abnormal activities out of the normal activity distribution. We implement our idea and build a prototype based on commercial Wi-Fi. We conduct extensive experiments with 16 human subjects. The experiment results show that our system can achieve high fall detection accuracy and adapt to different environments for real-time fall detection.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/sensys/JiX022", "doi": "10.1145/3560905.3568517"}}, "content": {"source": {"pdf_hash": "8e789b64d8442eb2ae131147a6eb75e714b01763", "pdf_src": "ACM", "pdf_uri": "[\"https://export.arxiv.org/pdf/2301.03773v2.pdf\"]", "oa_url_match": false, "oa_info": {"license": null, "open_access_url": "https://dl.acm.org/doi/pdf/10.1145/3560905.3568517", "status": "BRONZE"}}, "grobid": {"id": "c9719d2ecf851e98b38bb0ec8d82ab6577efd5c2", "type": "plain-text", "url": "s3://ai2-s2-science-parse-plus-prod/parse-results/s2orc_worker/8e789b64d8442eb2ae131147a6eb75e714b01763.txt", "contents": "\nSiFall: Practical Online Fall Detection with RF Sensing\nNovember 6-9, 2022\n\nSijie Ji sijie001@e.ntu.edu.sg \nMo Li limo@ntu.edu.sg \nSijie Ji \nYaxiong Xie yaxiongx@buffalo.edu \nMo Li \n\nYaxiong Xie\nNanyang Technological University Singapore\nSingapore\n\n\nNanyang Technological University Singapore\nBoston, BostonMA, USA. ACM, MASingapore, USA\n\nSiFall: Practical Online Fall Detection with RF Sensing\n\nACM Conference on Embedded Networked Sensor Systems (SenSys '22)\n2022November 6-9, 202210.1145/3560905.3568517University at Buffalo Buffalo, New York ACM Reference Format: 15 pages. https://CCS CONCEPTS \u2022 Human-centered computing \u2192 Ubiquitous and mobile com- puting systems and tools\u2022 Computer systems organization \u2192 Real-time systems\u2022 Applied computing \u2192 Health care in- formation systems\u2022 Computing methodologies \u2192 Machine learning KEYWORDS Self-supervised Learning, Wireless Sensing, Real-time System, Adap- tive Segmentation, Fall Detection, Device-free\nFalls are one of the leading causes of death in the elderly people aged 65 and above. In order to prevent death by sending prompt fall detection alarms, non-invasive radio-frequency (RF) based fall detection has attracted significant attention, due to its wide coverage and privacy preserving nature. Existing RF-based fall detection systems process fall as an activity classification problem and assume that human falls introduce reproducible patterns to the RF signals. We, however, argue that the fall is essentially an accident, hence, its impact is uncontrollable and unforeseeable. We propose to solve the fall detection problem in a fundamentally different manner. Instead of directly identifying the human falls which are difficult to quantify, we recognize the normal repeatable human activities and then identify the fall as abnormal activities out of the normal activity distribution. We implement our idea and build a prototype based on commercial Wi-Fi. We conduct extensive experiments with 16 human subjects. The experiment results show that our system can achieve high fall detection accuracy and adapt to different environments for real-time fall detection.\n\nINTRODUCTION\n\nmedical attention and directly cost $34 billion [7]. Clinical reports show that timely treatment (<1 hour) can prevent deaths from fatal falls [58]. Therefore, an effective fall detection system is necessary to facilitate timely treatment and benefit the current aging society where more and more elderly people are living alone [12].\n\nExisting fall detection solutions can be classified into two categories: wearable-based solutions and device-free solutions. Medical research has reported that wearable-based solutions do not work well in practice due to the burden of carrying and charging those devices from time to time [16]. In contrast, device-free solutions including computer vision (CV) based, acoustic-based, and RF-based are more user-friendly. Among them, the CV-based solutions cannot work under dim light conditions, occlusions and often compromises user privacy. The acoustic-based solutions are limited by its sensing range (<4.5m) [56] and possibly subject to restriction by ambient loudness (<40dB SPL) [33]. However, RF-based solutions are not constrained by the above and also cost-effective as they take the advantage of existing ubiquitous communication infrastructures such as WiFi APs.\n\nExisting RF-based fall detection systems [38,51,53,57] consider falls as a type of normal human activity and applies traditional human activity recognition method to identify the falls out of similar activities such as sitting, sleeping and jumping. Generally, the solution consists of off-line training and on-line inference. During the off-line training, the system builds up a model based on feature engineering [38,57] or machine learning [51,53], to separate the falls from other human activities. The RF signals are collected for training purposes when the human being performs a set of predefined activities, such as falling, sitting and jumping. The system then applies the trained model to identify falls from the received signals. All existing solutions implicitly assume that human falls introduce reproducible patterns to the RF signals which can be captured by the trained model and used to differentiate the falls from other activities.\n\nIn this paper, we revisit such a problem and argue that the signal patterns introduced by human falls are full of randomness and consequently hard to be fully captured by trained templates. Our key intuition is that the human fall, by its nature, is an accident that is unforeseeable and the human reaction is highly uncontrollable, introducing highly dynamic disturbance to the wireless signals. Specifically, as depicted in Figure 1, there are diverse causes of human falls, such as a stumble, a slip, loss of consciousness, loss of balance, a sudden fright, etc, which may result in randomness, e.g., a stumble or a slip may result in displacement of the human body. In contrast, a person stays at the same place if he loses his consciousness. In addition, the free range of movement in the joints of human body brings in another level of randomness when the human being cannot properly control his behavior during the falls. Extracting representative features of the human falls becomes impractical because of such uncontrolled randomness. Even collecting adequate data is challenging because one person can hardly repeat real and uncontrollable falls.\n\nWith the above observation, in this paper we handle the fall detection problem in a fundamentally different manner. Instead of seeking features to characterize the unforeseeable and uncontrollable human falls, we turn to solving an easier problem: recognizing normal repeatable human activities including but not limited to jumping, sitting, and walking. We formulate fall detection as adaptive anomaly detection and identity an abnormal activity that cannot be classified as any of the known activities as a fall. Our hypothesis is that after an adequate time period of training, a selfsupervised learning process will eventually perfect the model to differentiate uncontrolled falls from other repeated controlled human activities. To prune the search space and speed up the convergence of the model training, we apply analyzable signal processing to early filter out non-fall human activities with distinguishable signal features. Our observation suggests that falls change the status of the human body in a short period of time and thus introduce high frequency components to the signal variations. We feed the identified suspicious fall-like activities to a deep neural network called FallNet to recognize the true falls. Specifically, the FallNet trains an auto-encoder [22] to learn a compressed representation of normal fall-like activities. When used for inference, the autodecoder is only able to accurately reconstruct the normal fall-like activities but not real human falls. The FallNet, therefore, identifies the activities that result in large reconstruction error as falls. After deployment, the FallNet is continuously updated using the freshly collected data in a self-supervised manner, so it evolves to adapt to the local propagation environment and the particular human subjects that the system monitors. We expect that the FallNet will eventually perfect its detection accuracy and false alarm rate over time.\n\nTo realize our idea, we implement a Self-supervised Incremental learning Fall detection system, SiFall. To the best of our knowledge, SiFall is the first RF-based fall detection system that can work in real time for online fall detection on a daily basis across different human, different environments and different types of activities. SiFall possesses the following three advantages:\n\n\u2022 SiFall works with daily human activities in runtime -WiFi CSI samples are dynamically processed, segmented, and discriminated to detect ongoing \"falls\". \u2022 SiFall's self-learning process can adapt to the variation of human subjects, environment, and types of falls. The core anomaly detection model of SiFall evolves during its use;\n\n\u2022 SiFall separates the signal processing from its machine learning model, which is designed to be lightweight and may easily be accommodated at the edge devices.\n\nThe developed SiFall prototype has been comprehensively evaluated with a total amount of over 92 hours of test data collected from 16 human subjects of different ages and genders. During our experimental evaluation, SiFall is able to achieve 98.3% accuracy in a real-world setting with extensive movements. During a continuous three-day adoption in a normal living environment, SiFall is able to detect 94.1% falls with only one false alarm in the end.\n\n\nCHALLENGES AND OPPORTUNITIES\n\nThis section first discusses the challenges in developing a practical RF-based fall detection system and then presents the key observations and opportunities.\n\n\nChallenges\n\n\nFall Ambiguity.\n\nThere is no uniform quantitative definition of \"fall\" in medicine, biology, or physics. According to the World Health Organization (WHO), fall is a subjective term, which is measured by the level of discomfort in the human body after a person accidentally lies on the ground or other low level [37]. As a result, it is hard to identify a quantified signal template to feature the \"fall\" when performing RF sensing. Besides, the orientation and the reflection surface of the human body may impact the reflected RF signal which leads to inter-activity similarities (e.g., falling v.s. lying down) [1,31]. Other factors including deployment layout and individual difference may also contribute to the ambiguity in defining and quantifying the \"fall\" in the RF signal space.\n\n2.1.2 Data Scarcity. Recent advances in deep learning allow learning powerful discriminative models from a number of representative samples [14], which may bypass the difficulty in defining precise signal templates of \"falls\". However, since the \"falls\" are high exceptional human activities that often occur uncontrollably, it is extremely difficult to obtain sufficient repeatable real-life data samples containing different types of falls, leading to a data scarcity issue. Most existing fall detection studies depend on learning from artificial fall samples collected from the laboratory environment and thus may have gaps in detecting real falls that take place in daily life. The lack of fall data may also result in class distribution skews where the learned model is biased towards the majority types of falls and may have poor predictive performance for other types of falls. As long as the types of falls are not sufficiently emulated, the learned model may be unreliable with poor generalizability.\n\n\nUnstructured Input\n\nSignal. Human motions, even of the same type, may last for different durations of time, and as a result, the relevant RF signals are unstructured and of different lengths. The processing of variable-length input signals is very different from processing fixed-length data samples in many machine learning models. Real-time processing of variable-length sequences is particularly difficult because data structurization techniques like sequence padding or dynamic template mapping can hardly be applied in real time [50]. In addition, real-time segmentation of the RF signals from consecutive activities is also challenging, the inaccuracy of which may lead to inconsistency of features in the machine learning model. Most existing fall detection solutions assume pre-defined fixed-length RF signal input.\n\n\nOpportunities\n\nWhile the practical challenges suggest extreme difficulties in learning the RF templates of human falls, we observe that there is an opportunity on the other hand to categorize human daily activities as they are usually repeatable and there exist plenty daily data samples for training a model to describe them. To showcase such an observation, Figure 2b visualizes the extracted WiFi signal features after short time Fourier transformation (STFT) across various human activities (details in \u00a73.2). Figure 2a depicts the STFT segments collected from the same testing human subject and Figure 2b depicts those collected from three different human subjects. It is obvious to see that the daily human activities give very consistent STFT patterns, e.g., the kneeling and sitting patterns in Figure 2a.\n\nEven across different human subjects the patterns of the same daily activities remain consistent, e.g., the kneeling and sitting patterns in Figure 2b. The \"falls\" however appear highly varied and nonrepeatable across the types, e.g., the \"stop fall\", \"walk fall\", and \"slow fall\" (details in \u00a74.2), as well as the testing human subjects. The above observations suggest that it is reliable to train a model to accurately describe the normal daily activities and as an opportunity to identify \"falls\" as abnormal outlier output from such a model. As there are plenty of daily activities to see when the system is deployed in reality, a self-supervised learning scheme may continuously perfect the trained model with improved accuracy in distinguishing the falls from normal daily activities.\n\n\nSYSTEM DESIGN\n\nA desired fall detection system should have the following characteristics: (i) it must work in real-time and detect falls with run-time data input; (ii) it must be able to evolve itself without involving human efforts to label the data samples; (iii) it must adapt to environment and different users. In this section, we present the design of SiFall, a system that accommodates the above design considerations. We begin with the system overview followed by fall-like activity segmentation and the design of FallNet.\n\n\nOverview\n\nSiFall consists of a front-end to process RF signals and a back-end server to train the neural network model and detect the fall, as shown in Figure 3.\n\nSiFall's front-end collects WiFi channel state information (CSI) measurements, denoises the CSI and extracts the dynamic component of the CSI to obtain an approximate RF-signal description of human movement. Finally, a lightweight algorithm is used to quantify the motion intensity and segment the RF signals accordingly ( \u00a73.2). In the end, SiFall applies short-time Fourier transformation (STFT) to derive the time-frequency spectrum of each piece of segmented RF signal clip and supplies the STFT spectrum to the back-end server for fall detection. The purpose of the front-end signal processing is two folded: to early rule out normal activities that possess clear daily activity features, and to present segmented RF signals with data cleansing. Typical daily human movements without high-frequency components are expected to be filtered out to narrow down the learning space of the back-end neural network model.\n\nIn the back-end server, a self-evolving deep neural network called FallNet takes the segmented RF signal as input and identify the falls from the normal fall-like activities. The FallNet is designed based on the auto-encoder framework to do the self-supervised learning where the encoder learns a nonlinear mapping from the unstructured RF-signal space to uniformed compact latent feature space and thus addresses challenge from the unstructured input signal. The decoder learns the mapping from the latent space back to the RF-signal space with the goal of reconstructing the original RF-signal as closely as possible. After training with a large number of repeated regular human activities, the FallNet establishes a Gaussian mixture distribution of normal human activities in the latent space ( \u00a73.3) and thus is capable of accurately recognizing and recovering the RF-signal clips of normal activities. When deployed, the FallNet classifies the fall-like RF-signal clips that can be well reconstructed as normal daily activities and those RF-signal clips that cannot be reconstructed as falls. The FallNet is continuously updated with RF-signal clips of repeatedly-appearing normal human activities fed from the front-end ( \u00a73.4). (1) where ( , ) represents the signals carried at subcarrier frequency and time point and ( , ) denotes the CSI value at . The CSI describes how the RF signals are transformed by the current wireless channel -the amplitude attenuation and phase rotation of different frequency components due to multipath reflection, diffraction, and scattering by objects in the environment. On top of that, RF chipset processing at WiFi transceivers may introduce additional distortion and noises [59,60]. Therefore, we perform necessary data cleaning to eliminate the impact of the hardware imperfections.\n\n\nRF signal Segmentation\n\nThe CSI consists of a static part induced by ambient environment and a dynamic part related to human movement . CSI is also subject to WiFi hardware distortion \u210e . Therefore, we model the overall CSI as:\n( , ) = ( ( , ) + ( , )) \u00b7 \u210e ( , ) = ( ( , ) + ( , )) \u00b7 1 ( ) 2 ( , )+ 3 ( )+ 4(2)\nwhere 1 ( ) is the amplitude scaling caused by automatic gain control (AGC), 2 ( , ) represents the phase offset introduced by the combination of packet detection delay (PDD), sampling frequency offset (SFO) and sampling time offset (STO), 3 ( ) is the phase offset caused by the carrier frequency offset (CFO), and 4 is the initial phase offset of the radio chains. We utilize relatively clean CSI amplitude and mitigate the impact of noisy CSI phase by calculating the conjugate multiplication of CSI as\u02c6( , ) for each subcarrier:\n( , ) \u2261 ( , ) ( , ) = 2 1 ( ) | ( , ) + ( , )| 2 ,(3)\nThe resulting\u02c6( , ) is still affected by the amplitude scaling 1 ( ) that AGC introduces. To visualize the impact of 1 ( ), we collect CSI measurements from a static environment and calculate CSI amplitude across subcarriers in Figure 4 (upper left), from which we see that the CSI amplitude curves across subcarriers are similar but not identical. The reason is that the amplitude scaling factor 1 ( ) is time-varying but consistent across subcarriers. We note that, because of the amplitude scaling factor, the CSI amplitude of a single subcarrier\u02c6( , ) is time-varying even when the environment is static and thus cannot capture the dynamics introduced by the human motion.\n\n\nCapturing Channel Dynamics.\n\nWe use the variations of the CSI amplitude curve to capture the channel dynamics introduced by human motion. To illustrate the intuition, we plot the CSI amplitude when the human is moving in Figure 4 (upper right), from which we see that the shape of amplitude curve varies significantly in non-static environment. We use cosine similarity to quantify the similarity between consecutive CSI measurements:\n( ) = \u27e8\u02c6( ),\u02c6( \u22121 )\u27e9 |\u02c6( )||\u02c6( \u22121 )| (4) where\u02c6( ) = [\u02c6( 1 , ), \u00b7 \u00b7 \u00b7\u02c6( , )]\nrepresents the CSI amplitude vector of all subcarriers sampled at -th time point. We plot the calculated S(t) for CSI collected from both static and non-static environment in Figure 4 (bottom), from which we see the variation of the ( ) accurately captures the dynamics of the wireless channels, because the normalization operation to compute similarity essentially removes the effect of AGC and thus 1 ( ) is removed. We note that, the similarity ( ) is affected by CSI sampled at two time point, so its value may also vary when the sampling interval varies, adding another unpredictable factor. In our implementation, we introduce a reference vector \u00ec = [1, . . . , 1] and derive ( ) as the similarity between the\u02c6( ) and the reference vector. We use the variance of S(t) across 0.1s and above a threshold \u0393 to detect the human movement.\n\n\nSegmenting Fall-like Activities.\n\nTo forge efficient online detection and relatively consistent feature extraction, we propose a heuristic algorithm to segment fall-like activities from continuous monitored RF signals. The key observation is that a fall and fall-like activity (e.g. Sit, Jump and Squat) usually comes to a full pause at the end of the motion before transitioning to next movement, which may be due to the direction change of the movement (vertical to horizontal). Similar observation has been reported in previous studies with WiFi [53] and RFID [10] signals as well. Therefore, we segment ( ) in a backtracking manner from an observation of motion pause, which is easier to capture than the actual start of an activity. Meanwhile, as the channel dynamic is caused by the human movements, we derive an approximate acceleration descriptor to help further filter out daily movements accompanied by a pause with low-intensity (e.g. walk and stop). In addition, we assume the RF signals collected after a fall are also useful and thus a greedy algorithm is used to keep monitoring the ( ) to window the entire fall-like activity. The approximate is computed by using the relationship [43]:\n( ) = d 2 dt 2 ( ) = d dt ( )(5)\nwhere is wave-length of the subcarrier wave, ( ) is the Doppler frequency shift. We approximate d d ( ) by computing STFT of ( ) as STFT is used to capture the frequency component in a small time duration and the frequency component change is caused by the relative movement between transceivers and the reflecting human body. Denote the STFT spectrum as S \u2208 R \u00d7 , where is the fix frequency bins and is the number of time bins. For each time bins, we have a vector of approximate d d ( ) denote as \u00ec, \u00ec \u2208 R . We search ( ) as the function of indices of frequency bins that exceed the noise floor via dynamic programming such that:\nmax(v) = argmax 1 ,\u00b7\u00b7\u00b7 , =1 S , , s.t. | \u2212 \u22121 | <= 1; = 2, \u00b7 \u00b7 \u00b7 , .(6)\n( ) \u225c d d ( ) so ( ) may be obtained by calculating ( ). We consider ( ) > \u0398 = 2.5 indicates a potential fall-like activity as the human normal acceleration in walking is less than 2.5 / 2 [63]. Figure 5a is the STFT spectrum derived from ( ) contained in Figure 4 and Figure 5b is the ( ) derived from the STFT contained in Figure 5a.\n\nWhen applied in real time, once the variance of ( ) is estimated below \u0393, suggesting a pause after a move, SiFall records the time as and then searches if there exists ( ) > 2.5 in the past five seconds ( \u2208 [ \u2212 5, ]) and records the ( ) and its corresponding time as . An online greedy change point detection algorithm [28] is applied to continuously update for one second afterwards to obtain * :\nC ( : * ) + < C ( : * +1 )(7)\nwhere C stands for the error of the linear regression and is a penalty value. The rationale behind is that the RF signals collected after the fall-like activity may also contain useful information for identifying the fall.\n\nIn the end, SiFall extracts ( ) between \u2212 3 , * and performs STFT on ( ) to obtain the fall-like segments. The additional three-second time before is used to include as complete falllike activity as possible because we would rather contain redundant signal data as compared to missing any possible important data. Note that the lengths of STFT segments and their corresponding spectrums are variable because the time between and * depends on the duration of the captured activity. Following that, the STFT segment of the fall-like activity is supplied to the neural network in the back-end for affirmative fall detection. Algorithm 1 defines the whole backtracking segmentation process.\n\n\nAlgorithm 1: Fall-like Segmentation Algorithm\n\nInput: ( ); Threshold: \u0398, \u0393; Penalty: ; if movstd(S(t),fs/10) < \u0393; then record as , S=STFT([S(t-5fs),...,\nS(t)]); if ( ) > \u0398 then record ; while < + do err( )=C ( : ); if err(t) > err(t-1) + then * = \u2212 1 continue; temp = [ ( \u2212 3 ), ( * )]; seg = STFT(temp);\n\nFallNet Design\n\nThe difficulty now lies in identifying ongoing falls from those RF clips of fall-like activities. This section elaborates on the design of FallNet, which is able to further identify falls from the RF clips of fall-like activities. Specifically, we learn the complicated distribution of normal fall-like activities by a variational auto-encoder based FallNet. When used for inference, the FallNet is only able to accurately reconstruct the normal fall-like activities but not real human falls. We, therefore, identify the activities that result in large reconstruction error as falls. We first construct the core encoder-decoder architecture of FallNet, which does not rely on data annotation and is able to accept unstructured input data. Then, we elaborate on some special designs of FallNet to cope with particular issues. Finally, we import the variational inference technique to FallNet to make it more generalizable.\n\n3.3.1 FallNet Architecture. We design FallNet based on autoencoder architecture which is a well-known deep learning framework to compress data without labels. The ability to compress data shows its high ability to understand the intrinsic relationship between the compressed data and the original data, hence, a trained encoder is also widely used as a feature extractor. We train the encoderdecoder only based on the fall-like STFT segments collected from daily activities so the FallNet learns the representative features of daily activities. When used for inference, the encoder-decoder is able to fully reconstruct the signals of those repeatedly seen normal activities.\n\nEncoder. The input to the network is the signal clip of the th activity \u2208 R \u00d7 ( )\u00d7 from a total number of activities, where the is a chosen frequency resolution of the STFT image, ( ) is the time duration of the activity, which might vary across activities, and is the number of spatial streams(between Tx and Rx antennas). Therefore, the complete information of the three domains, i.e., time, frequency and spatial, are fed into the FallNet. The encoder of the FallNet learns a nonlinear transformation F E : X \u2192 Z that maps the original data space X \u2286 R ( ) with variable dimensions and inconsistency to a compact latent feature space Z \u2286 R with uniform dimension. ( ) denotes the flattened dimension of and represents the dimension of the latent space of features that are most representative to describe the activities such that:\nz = F E (x, \u0398 E )\nwhere \u0398 E is a set of parameters of the encoder. As the encoder learns the most representative features and automatically filters out the redundancy, it works well with the STFT segments, which may be longer than the actual activities.\n\nThe ability of the encoder to project variable-length data space into a uniform latent feature space is owing to our fully convolutional network structure design of the building blocks. The convolution operation itself intrinsically can cope with input of varying lengths, although many people don't notice this because the convolution operation is usually used to process images that are of same length. The convolution operator in fact works on local tensor regions and depends only on relative spatial coordinates determinated by the convolution kernel size [19] (refer to Appendix B for more details). As a result, when using the \"same padding\" [19] in a convolution layer, for an input with dimension \u00d7 ( ) \u00d7 , the output will be with the dimension of \u00d7 ( ) \u00d7 \u2032 , where the only change is the channel dimension \u2032 , depending on the number of convolution filters. In particular, the encoder of FallNet consists of five building blocks of decreased size that are stacked together. Each building block consists of two convolution layers with instance normalization (IN) [52], an activation function of LeakyReLU [61], and a max-pooling layer. All convolution layers fix the convolution filter size to 3 which simulates a larger filter while keeping the benefits of smaller filter sizes in order to reduce the computational overhead [48]. IN is used to cope with the antenna imbalance issue. LeakyReLU is the activation function to bring in non-linearity ability of the network and it can avoid the dying ReLU problem. Max-pooling is used to achieve translation in-variance over small spatial shifts in the input tensor [49]. The max-pooling layer will decrease the size of the input to half so that the final output size of each building block is /2 \u00d7 ( )/2 \u00d7 \u2032 . At the end of the five building blocks, we first average pooling the feature values along the time dimension with an index to record its dimension. Note that \u2032 is determinated by the number of convolution filters which is controlled by us and the is fixed, a fully connected layer hence can be used to conduct channel-wise linear transformation to map the tensor to a fixed-length vector with dimension that represents the extracted features.\n\nDecoder. The decoder learns to reconstruct the input signal from the output of the encoder, such that\nx = F D (z, \u0398 D )\nwherex is the reconstructed signal, and \u0398 D is a set of parameters of the decoder. To reconstruct\u02c6, the decoder needs up-sampling oprations to map back to the size ( ) of the original input smaple ( ). In consequence, the decoder and the encoder are symmetric with the same number of building blocks, except that the maxpooling layers at the encoder is replaced by up-pooling layers at the decoder. As up-pooling [6] utilizes the 2-bit indices stored during max-pooling operation in the encoding phase and up-samples the feature map by filling the values directly to the index position and zero-padding the remaining positions. It avoids parameter learning to reduce the computation overhead. Figure 7 illustrates the uppooling operations.Another small detail is that the decoder first uses the record index from the previous average pooling operation to zero-pad the back to the dimension before the fully connected layer, then goes through the five identical building blocks of the decoder.\n\nConsequently, the goal of the FallNet is to learn the parameter sets of encoder and decoder satisfying:\n\u0398 E ,\u0398 D = arg min \u0398 E ,\u0398 D E \u223cX \u2225x \u2212 F D (F E (x, \u0398 E ) , \u0398 D ) \u2225 2\nIt is worth noting that this learning process only needs the input sample and does not require any labelled data, therefore, it can benefit from substantial and easily accessible RF samples of daily activities.\n\n\n3.3.2\n\nCoping with Antenna Imbalance. CSI collcted from different antennas may have different amplitudes, which lead to the imbalance of the power of STFT spectrums. The removal of AGC impact in the CSI denoising phase further amplifies this issue. As the channels of input tensor corresponds to different Tx-Rx antenna streams, the FallNet adopts IN that normalizes the antenna streams with learnable affine parameters , to cope with the antenna imbalance:\nIN , ( ) \u2261 + , where = \u2212 \u221a 2 +\nwhere and 2 are computed across spatial dimensions independently for each channel so that every spectrum has the same range of values. is a small constant added for numerical stability. Noted that the FallNet removes the commonly adopted Batch Normalization (BN), as the data samples in our case are generated online and may follow different distributions. IN has the same characteristics as BN does, which helps the entire neural network to alleviate gradient saturation and accelerate convergence [24] (refer to Appendix A for more details).\n\n\nCoping with RF Data Scarcity.\n\nAlthough the training of the FallNet is free from data annotation, making it possible to continuously learn from daily fall-like activities, it is not realistic to enumerate all possible fall-like activities. Besides, some types of activities may be relatively dominant owing to specific user activity patterns. As a result, FallNet may be prone to be overfitted. To make the FallNet resistant to such overfitting and be generalized to function properly, instead of using a vector with dimension to represent the learned fall-like activity features, we adopt a bottleneck layer with stochastic sampling operation to make the FallNet become probabilistic.\n\nThe reason for doing this is based on our observation (Figure 2) that fall-like activities of the same type are similar, though not identical. By introducing this prior knowledge, we can construct the obtained samples with certain distributions and assume that the same type of activities come from the corresponding distribution to obtain more general sample characteristics. We, therefore, import such prior knowledge into the network, allowing the neural network to learn more generalizable features from the limited data. In particular, we assume that each of the features of the RF signals follows a normal distribution due to different body shapes or orientations. Refer to Figure 2b to see that the same actions performed by a single person or multiple persons have similarity due to the kinematic consistency. Thus, in the feature space, samples from each normal activity group are supposed to follow an -dimensional Gaussian distribution as the activities from the same group (e.g., sit, bow, or jump) are repeated and controlled. We denote a certain activity group as with number of ( ) samples. Ideally, all normal samples from different daily activities together form a mixture distribution of Gaussian.\n\nWith such prior knowledge, we therefore impose the constraint to FallNet's learning process and force it to learn a mixture Gaussian distribution over the latent feature space, rather than learning a vector of feature representations that may be over-fitted with limited data samples. To this end, we modify the output of the encoder from to two vectors and that represents mean and variance of the activity group Ac that each training sample belongs to, respectively, where , \u2208 R , is the number of features. The FallNet learns the two vectors to parameterize the feature distribution of . A constrain loss is added to minimize the Kullback-Leibler (KL) divergence between the learned disrtibution of the parametric representation and the desired distribution ( | \u2208 ) \u223c N , 2 such that:\nL c = \u2212 1 2 =1 2 ( ) + 2 ( ) \u2212 log 2 ( ) \u2212 1\nwhere ( ) and ( ) denote the -th element of the -dimensional vectors and . In such a way, each activity is modeled as a multivariate Gaussian distribution with -dimensional features in the latent space. Different activities have different mean vectors and variance vectors to represent different Gaussian distributions. As the number of samples increases, the hidden space gradually forms a complex Gaussian mixture distribution:\n( ) = \u2208 | , 2\nIf the latent distribution is valid, correspondingly, any of the latent space samples from the distribution should be able to reconstruct well. Therefore, the input of the decoder now becomes a that is stochastically sampled from the corresponding and such that\nx = F D z \u223c N , 2 , \u0398 D\nwhere represents a random sampling operation. On the other hand, the back-propagation of training neural network requires deterministic operations at each neural network nodes which iteratively pass the gradients and apply the chain rule. The stochastic sampling operation however is not a continuous function and thus not differentiable to obtain the gradient. To make the neural network trainable, the FallNet adopts the reparameterization technique [30]. It generates random from a standard normal distribution N (0, 1) independent of the neural network nodes. The latent sample is obtained through scaling and transformation by = + \u00d7 . The reparameterization allows to be sampled from the corresponding distribution of and at each iteration while the random sampling itself is not involved in the training process. As the sampled is deterministic at each iteration its gradient can be back-propagated to train the entire neural. Consequently, the objective of the FallNet is revised:\narg min , ,\u0398 D E \u223cX \u2225 \u2212 F D (( + \u00d7 , \u0398 D ) \u2225 2 , \u223c N (0, 1)\nIn addition, the FallNet design also employs data augmentation scheme to compensate the data scarcity and improve model generality. The FallNet imposes two specific augmentation schemes: (i) To simulate a low SNR scenario, before being converted to STFT spectrums, for each segmented ( ), we add Gaussian white noises, which equals to adding noises in the channel domain of the input tensor; (ii) To alleviate the limitation of time resolution due to the fixed STFT window length. Each input tensor goes through three rounds of random horizontal shift [42], with the shifting length smaller than the STFT window length. At the end we are able to fabricate 24\u00d7 the amount of original data to augment the training size.\n\n\nOnline Detection and Model Updating\n\nAfter pre-training with a normal activity dataset , the FallNet has established the distribution of the anchor daily activities in the latent feature space. Let each activity segment go through the FallNet, we can derive the statistics of reconstruction error of the dataset including its average and median . In the online detection phase, the FallNet takes the real time segmented STFT samples for inference in a single run, and measures its reconstruction error . If > 2 , it is detected as a fall and at the same time and remain unchanged. If < < 2 , the system takes it as a suspicious daily activity and saves the segmented samples for feature reference, but and are recalculated and updated accordingly. Once the change of exceeds a threshold, the system takes it as an indication of significant change in the environment. If < , the system updates the and and then performs data augmentation where a mini-batch of augmented data samples are fed to the FallNet for retraining the model. Therefore, the system keeps evolving with the feedback of reconstruction error and adaptively updates the threshold to determine falls.\n\nAs the system runs in real-time, the incoming fall-like samples for inference may bring two types of distribution shift, one being the semantic shift caused by the individualized movement patterns across people, the other being the covariance shift due to environment variation over time. As SiFall eliminates the environment impact by extracting the dynamics of RF signals, the covariance shift is well accommodated along with the continuous update of the FallNet. The saved suspicious daily data samples are utilized to deal with the semantic shift. Whenever an adequate amount of suspicious daily data samples (i.e., 50 as set in our current implementation) are collected, SiFall performs principal components analysis (PCA) to reduce the dimension to and then performs mean-shift clustering [41] to identify clusters. Two criteria are applied to handle the cluster points, namely, representativeness and diversity. We examine the largest cluster as it indicates many repeatable activities which are unlikely to be human falls. SiFall retrieves the signal segment of the centroid of the largest cluster, produces 24\u00d7 augmented data, and feeds that to the FallNet for model retraining. SiFall also notices when there is a cluster that is far away from other clusters. The cluster is taken as a potential undiscovered user activity group and its signal segments are kept for later examination when adequate amount of such suspicious data are collected. The remaining signal segments are discarded and the counter is updated till next time the number of saved samples reaches 50.\n\nBased on the above described mechanism of automatic model update, SiFall does not require explicit human intervention for most of the time. Only when a \"fall\" is detected SiFall triggers an alarm for possible human intervention. The corresponding data samples are saved with a timestamp regardless whether the detected \"fall\" is a true positive or false positive. The human user may examine the saved \"fall\" samples at any later time to decide whether they are true positives in which case the samples are discarded, or false positives in which case the samples are augmented and fed back to the FallNet for retraining.\n\n\nEVALUATION\n\nIn this section, we evaluate the performance of SiFall. We first introduce our experimental settings and then present the results.\n\n\nExperimental Setting\n\nWe implement SiFall with two commercial off-the-shelf (COTS) APs as the Tx and Rx to collect the WiFi CSI, one laptop connected to the Wi-Fi receiver to serve as the front-end edge server and one back-end server. We use a camera to capture the ground truth.\n\nHardware. We use COTS COMPEX WPJ558 equipped with Atheros SoC QCA9558 in the experiment. We let these two APs transmits 200 packets per second on a 20MHz channel in 2.4GHz frequency band. We fix the Modulation and Coding Scheme (MCS) to reduce packet loss and noises. We use Atheros-CSI-Tool [59] to collect raw CSI data. The receiver forwards the collected CSI to the ThinkPad T430 laptop with an Intel Core i5-3360M CPU to process the RF signals and generate STFT segments (as introduced in Section 3.1). We use a Linux desktop computer equipped with Intel Core i9-9820X CPU and one Nvidia 2080Ti GPUs to work as the back-end server Testbed. We test SiFall based on three testbeds -an emulated \"bedroom\" with an enclosed space measured 4.32m \u00d7 8.24m for comprehensive evaluation (testbed 1), a real apartment room measured 7.85m \u00d7 4.47m for system adoption test on a daily basis (testbed 2), as well as a big open area measured 9.54m \u00d7 7.05m to test the effective sensing range of the system (testbed 3). Figure 8 depicts the three different testbeds. The marked Tx and Rx indicate the locations of the WiFi Tx and Rx antennas.\n\nGround Truth. We use a camera to record the detailed human activities at a frame rate of 30fps, and manually analyze the recorded video clips to generate the ground truth. We use network time protocol (NTP) to synchronise the time in the camera recordings and the collected Wi-Fi CSI data.\n\nFallNet Pretraining. We pre-train the FallNet with the data collected intermittently during 3 months in testbed 1, including 1447 sets of STFT segments of sitting, jumping, swinging, bowing, running, and other daily activities, augmented 24 times to produce a total number of 34,728 samples. Correlation among raw samples is removed by OpenCV, and the weight parameters are initiated by kaiming initialization [21]. The model was trained by Adam [29] optimizer on 4 Nvidia 2080Ti GPU for 2 hours.\n\nTesting Subjects. We recruit 16 volunteers (11 males and five females) with ages between 21 and 56 to take part in our experimental evaluation (with IRB approval). Table 1 summarizes the detailed information of all volunteers. The testing subjects are highly diverse in their age, weight, and height. Specifically, the body weight of our volunteers varies from 42kg to 100kg. Their body height varies from 155cm to 186cm, and their age varies from 21 to 56 years old.\n\nRT-Fall. We compare the performance of SiFall with RT-Fall [53], which is, to the best of our knowledge, the only RF-based fall detection system which claims being able to achieve real time fall detection in practice. RT-Fall identifies fall-like activities based on  \n\n\nEnd-to-end Evaluation\n\nWe first conduct intensive movement experiments with 12 subjects and report the end-to-end performance. After that, the proposed system components are evaluated based on the detailed experiment results.\n\n\n4.2.1\n\nMethodology. 12 testing subjects (#P1,#P6-#P16) are involved to conduct the experiment in a sequential order. Each testing subject is requested to move freely around one and half an hours inside the bedroom testbed as depicted in Figure 8. We request each of them to perform the following actions at their will when they move around: \"jump\", \"squat\", \"sit to the floor\", \"sit to the chair\", \"knee down\", and \"bow\" at least three times at different locations and with different body orientations. Other than the requested type of movements, they are free to perform any other activities at their will. We summarize other fall-like movements that are hard to quantify as \"swing\". To mimic unconscious falls as much as possible while meeting the IRB requirement on risk control, we set up a safety mattress and experiment with the falls of three categories [4,32,46]: (1) for \"walk fall\", the subject is asked to walk around the mat and instantly fall on the mat once a random alarm is triggered by us -the fall is performed regardless the instant body orientation of the testing subject; (2) for \"stop fall\", the subject stands still on the mat and tries to dodge the tennis balls thrown at her -if she happens to fall the activity is noted as a valid \"stop fall\", and as swing activity otherwise; (3) for \"slow fall\", the subject keeps standing still until we give a random alarm when she simulates a slow fall on the mat. Table 2 illustrates the three categories of falls with corresponding real life scenes and examples. It is worth noting that regardless of the type of falls, the falling orientation is random during the experiments based on the reaction of the subject. During the experiment, SiFall continuously operates and each of the 12 testing subjects enters the bedroom in sequence. The total experiment duration for all 12 testing subjects is about 19.3 hours. The FallNet model is continuously maintained and updated throughout the experiment. We evaluate the performance with True Positive Rate (TPR) and False Positive Rate (FPR) metrics, where TPR is true falls out of SiFall reported falls and FPR is falsely reported falls out of other activities. The accuracy is calculated by the percentage of correctly detected falls and non-falls against the ground truth.\n\n\nOverall\n\nPerformance. During the 19.3 hours experiment, SiFall captures a total number of 1497 fall-like activities, of which 523 segments are intentional activities performed by the testing subjects (including 123 falls and 400 required fall-like activities). Among the 123 falls, 60 are \"walk fall\", 33 are \"slow fall\" and 30 are \"stop fall\". We derive the TPR and FPR in about every 20 minutes and plot the results over time in Figure 9, where TPR is represented by the black solid line and FPR is represented by the balck dashed line. Both the TPR and FPR vary over time as the FallNet model continuously evolves when more training data are collected from the testing subjects. We see a clear trend of improvement on both the TPR and FPR.\n\nFirst, the TPR improves quickly over time. From 83% at the beginning of the experiment, the TPR constantly improves over time and reaches 100% within 4 hours of operation, which demonstrates SiFall's capability in accurately identifying the abnormal falls from normal daily activities. Second, the FPR of SiFall improves greatly over time. The falsely reported falls by SiFall are 6.7 per hour in the first two hours and eventually drops to below 1 per hour in the last two hours of the experiment. While the TPR shows a clear trend of improvement over time, the FPR occasionally fluctuates, especially during the experiment of each individual testing subject. That is mainly due to the fact that our experiment does not restrict how each testing subject performs certain activities, and as a result some testing subjects may choose to perform more activities similar to falls, and in different orders. For example, one (#P9) prefers challenging SiFall system by performing more \"sit on the floor\" activity which is more similar to \"slow falls\" and results fluctuated FPR during his experiment. If we focus on the FPR statistics by the end of each testing subject's experiment (the gray line), we may see steadily improved performance. At the end of the 19.3 hour experiment, SiFall is able to achieve 100% TPR and 1.8% FPR.\n\nWe simultaneously run RT-Fall for comparison and plot the achieved TPR and FPR of RT-Fall in red in Figure 9. We find that during the real time operation RT-Fall achieves a much lower performance, with its TPR of 64.9% and FPR of 49.2%. Since RT-Fall does not have the ability to self-evolve, it cannot gain performance over time and it fluctuates across different testing subjects. Overall the comparative results show huge comparative advantage of SiFall over the SOTA available real-time RF fall detection approach.\n\n\nFallNet Visualization.\n\nWe visualize the FallNet input and output to demonstrate the rationale when applying FallNet to detect the falls. Specifically, we impose three checkpoints during the experiment (as indicated in Figure 9 as CKPT1 to CKPT3, after the test of subject #P6, #P11, and #P15, respectively). At each checkpoint, we freeze the FallNet model and memorize it for detailed investigation. We feed different RF signal segments collected from normal activities and falls into the restored FallNet models at the three checkpoints, respectively, to examine the reconstructed output from the FallNet. In Figure 10, we plot the STFT segments of the input signal and the reconstructed STFT segments by the FallNet for different types of falls (Figure 10a) and other ordinary activities (Figure 10b). We clearly see that while most STFT segments of most ordinary activities can be recovered by the FallNet the STFT of falls cannot. We also observe that as the model evolves (from CKPT1 to CKPT3), the reconstruction errors of all the falls increase while the reconstruction errors of ordinary activities decrease. Note that the errors is computed as the L2-norm of the difference between the FallNet input and output. The reconstruction errors of falls are order of magnitude higher than those of ordinary activities.\n\nThe visualization suggests that the FallNet is able to continuously learn better latent distribution to describe the human daily activities and based on that make more accurate detection of falls as outliers.\n\nNotably the low-frequency part of the spectrum and the end-ofmotion part remain clear despite the deteriorating quality of the reconstructed STFT samples of falls, which suggests that the FallNet  indeed utilizes the low-frequency and end-of-motion features in discriminating the samples.\n\n\nSiFall Segmentation\n\nPerformance. The segmentation algorithm of SiFall depends on detecting the status of human movement and is threshold based. We separately evaluate the accuracy of the movement detector and the threshold sensitivity. Movement Detection. We classify the human movement into three levels. Body level movement refers to the whole body movement involving position change, such as walking and running. Torso level movement refers to torso movement without position change, such as bow and squat. Limbs level movement refers to limbs and hands movements at minor scale such as shaking hands and typing. Figure 11a reports the percentage of relative error (false negative rate) of the corresponding movement detection results when testing subjects move freely in testbed environment 1. The figure plots the cumulative distribution based on the movements from 12 testing subjects (#P1, and #P6-16). The experiment logs SiFall movement detection performance at body level, torso level and limbs level movement with median error of 0.5%, 1.1%, and 1.8%, and 90thpercentile error of 1.2%, 1.6% and 3.7%, respectively. Threshold Sensitivity. To quantitatively evaluate the reliability of the threshold \u0398 = 2.5 as fixed in the SiFall implementation, we derive the maximal frequency of each human movement and project to its acceleration. Figure 11b depicts the cumulative distribution of the projected acceleration for different types of movements. We see that all fall activities have their derived acceleration above the threshold and the majority of other fall-like activities are also captured with the current threshold setting. On the other hand, most ordinary walk and run movements are screened out by the threshold. 12.5% of bow activities are screened out as well. The result suggests that the threshold setting is effective in screening falls and fall-like activities. It is also obvious that SiFall is robust to the threshold setting -its accuracy will not be impaired when the threshold falls in the range between 2 to 3.7.\n\nSegmentation Length. Following the strategy of \"more is better than less\", the SiFall segmentation algorithm aims at capturing the activities with redundancy in their time durations. Figure 12 compares the lengths of SiFall captured segments and the corresponding ground truth time durations of the activities. In general the SiFall segments have an average duration of 5.1s, which is longer than the actual activity duration averaged at 2.6s. Additional 2.5s signal data are included in the SiFall segments for redundancy. Overall, SiFall segmentation algorithm introduces necessary redundancy in extracting the signal segments while maintaining the signal processing overhead on the extra signal durations acceptable.  \n\n\nDaily Life Adoption Test\n\nIn the above experiment, human subjects were asked to continuously perform a large number of falls and fall-like activities in a short time duration for comprehensive evaluation. To further challenge our system and understand the long-term performance in a more realistic setting, we adopt SiFall with pretrained FallNet from the emulated bedroom (testbed 1) to a real apartment room (testbed 2). We conduct a continuous three day evaluation with one testing subject (#P2) working and living inside the testing room day and night. A total number of 204 fall-like activities (67 on day 1, 63 on day 2, and 74 on day 3, respectively) are captured at the front end and sent to the FallNet for fall inference. Totally 12 false alarms are triggered (9 on day 1, 2 on day 2, and 1 on day3, respectively). Figure 13 depicts those false alarms and their occurrence time. After verifying with the testing subject, the first-day false alarms mainly come from sitting on the sofa and they are phased out gradually with the model update. The first false alarm on the second day is raised when an object falls from the wardrobe and the testing subject picks it up immediately. The second false alarm on the same day is raised when the subject jumps and dives into the sofa from the back of the sofa. The last false alarm on the third day is triggered when the testing subject does handstand on the Yoga mat. We see a clear trend that the false alarms dramatically reduce when the FallNet model is continuously updated over time. Quantitatively, the false alarm rate decreases from 13.4% on the first day to 1.4% on the last day. The experiment results suggest that SiFall has the ability to learn from personalized daily activities, and build evolved models for more accurate fall detection. However, some rarely-seen combination of movements may still trigger the false alarm, which we expect would reduce when SiFall continues to see more repeated occurrences of such activities over longer time of deployment.\n\nAfter the three day continuous monitoring of the daily activities with SiFall, we perform a purposed experiment to evaluate its detection accuracy of true falls. We freeze the model update of SiFall, and let the testing subject perform ten emulated \"stop falls\" and \"slow falls\" following the same methodology illustrated in \u00a74.1. The falls are performed across 5 different locations in the room (shown as \"X\" in Figure 8). We then pour a lot of powder on the floor, let the testing subject wear safety gear, keep jogging in the room till five \"walk falls\" are collected. Apart from those, the testing subject also simulates a fall that rolls from the bed as well as a slipping fall when trying to sit on the office chair. SiFall can detect all the above falls except for the rolling fall from the bed with 94.1% detection rate, demonstrating the high reliability of SiFall in real-life application. \n\n\nEffective Covering Range\n\nAs SiFall captures fall-like activities based on sensing the wireless channel dynamics, we want to evaluate its effective sensing range. We deploy SiFall with the pretrained FallNet from the \"bedroom\" environment (testbed 1) to a bigger open area (testbed 3) without fine tuning the model. Three testing subjects (#P3,#P4 and #P5) are requested to perform \"jump\", \"sit to the floor\", \"swing\", and \"walk fall\" (each for five times with a random sequence) repeatedly in three different areas (as depicted in Figure 8) with a distance of 1-3 meters, 3-5 meters, and 5-7 meters, respectively, to the LOS link of the Wi-Fi transceivers. Figure 14 reports the TPR and FPR of the three testing subjects when experimented in the three different areas. We see that SiFall performance is robust when adopted across the environment. The accuracy is reasonably good when the testing subjects move to as far as 5m away from the Wi-Fi link. The average TPR and FPR in area A1 and area A2 were 73.3% and 20%, 73.3% and 22.2%, respectively. When the distance increases to 7m in area A3, the average TPR drops significantly to 40% and the FPR drops to 4.4% at the same time due to failures in detecting and segmenting all fall-like activities. Note that when directly migrating the FallNet model to a new environment (from the \"bedroom\" in testbed 1 to the big open area in testbed 3), SiFall still achieves an average accuracy of 78.3% which is impressive. We expect the accuracy will further improve with time when more human activities are captured and consumed by the FallNet model to evolve.\n\n\nComputation Overhead\n\nWe provide a quantitative analysis of the SiFall's computation overhead. We utilize the Pytorch-OpCounter tool to measure the computation cost in flops (floating-point operations per second) of FallNet and some representative CNN-based models used in other applications. As Figure 15a depicts, FallNet falls in between the ultralightweight model (e.g., MobileNetV2) and the medium-weight models (eg., Densenet121 and AlexNet), which indicates FallNet is a relatively lightweight model.   We also measure the end to end latency of SiFall operation in our testbed, and summarize the result in Table 15b. The average inference time and the model parameter update time are measured on a single NVIDIA 2080Ti GPU. Once SiFall front-end detects a fall-like activity, it triggers a warning and waits for the FallNet at the back-end to generate the alarm for confirmed falls. We measure the warning delay (alarm delay) by averaging the time interval between the system warning time (alarm time) and the ground truth ending time of the fall-like activities (fall). The major delay of the system comes from the signal segmentation, where SiFall keeps monitoring the channel dynamics for 1s.\n\n\nRELATED WORK\n\nRF-based fall detection. Existing RF-based fall detection systems [23,38,45,51,53,57] all assume repeatable human fall patterns and follow pre-defined fall templates in the feature space for detection. Most of them depend on manually segmented signal clips for inference. Aryokee [51] utilizes CNN to extract features of human fall as opposed to previous manual feature extraction approaches [38,51,53,57]. However, the samples are collected offline with the same length, the Aryokee model is not able to deal with varying length RF samples and the system cannot run in real-time. FallDefi [38] improves the performance by using the combined features of previous approaches and adopting more WiFi links for gathering RF signals. There are some general RF based human activity recognition systems including Witrack [2], CARM [55] and HAR-SANet [11] which treat fall as one of the ordinary human activities and can only capture few types of falls. To the best of our knowledge, RT-Fall is the most practical solution of real time fall detection, which however as suggested in our experimental evaluation cannot provide high accuracy with realistic falls occurring in practice. Although Defall [23] claims real-time fall detection capability, it uses a human-like dummy to do the experiment to learn the fall template, and thus it can only detect simulated \"hard fall\", which is falling from a standstill position at a certain height, by its nature significantly limits its application in practice.\n\nOther fall detection solutions. Other than RF-based fall detection, there are CV-based fall detection approaches [13,17,64] that take optical measurements by camera or infrared sensors for analysis. Those solutions are often criticized for compromising human privacy. Wearable-based fall detection methods either require the user to carry the device [3,9] or wear the device [27] which are intrusive and thus not the most desired way for fall detection [44]. The acoustic-based [15] method is limited by ambient noise. Sensor fusion-based fall detection [34,69] is believed to be more reliable as various sensors may complement each other in different situations, but generally leads to higher cost and deployment overhead. Among them, some works claim they detect falls based on anomaly detection [9,17]. A CV-based approach [17] collects a balanced dataset with fall and non-fall samples and use a supervised anomaly detection method. A wearable-based approach [9] learns a fixed boundary in feature space to separate daily activity and the anomaly fall, which cannot cope with unseen daily activities and falls.\n\nDeep learning based RF sensing. Deep learning has recently been widely adopted to various wireless sensing applications, including physiological sensing [67], food and liquid sensing [20], gesture recognition [68], body skeletons reconstructing [36,65,66], localization [5] and etc [8,18,25].Those solutions cannot be directly applied to detecting human falls. Most of them do not support the neural network update during run time and often require extensive data collection and annotation to facilitate the model training. Anomaly detection. While anomaly detection is well-studied in the literature, anomaly detection for high-dimensional data in realtime remains challenging [39]. Traditional methods such as One-Class SVM [47], Kernel Density Estimation [40] and Tree-based Isolation Forest [35] all fail to operate online due to unsatisfactory computational scalability and the curse of dimensionality. Thanks to the rapid development of deep learning technology, a lot of deep learning based anomaly detection methods have been proposed [54,62,70] with similar frameworks that consist of three parts: feature extraction, feature representation learning, and end-to-end anomaly score learning. We design FallNet based on this skeleton and make it capable to run in real-time with unstructured input signal data, to fill the gap in the literature, as most deep learning based methods are capable to only structured datasets and lack real-time practices. Self-supervised learning. Self-supervised learning techniques support learning representations from a large amount of unlabeled data and based on that representation to serve downstream classification tasks with a few labeled instances [26]. As an alternative solution to establish a representation of daily human activities, selfsupervised learning still faces the challenge in the lack of labels for unforeseeable human fall types. From a different perspective, SiFall deals with the domain variations by building an anomaly detection neural network model and continuously evolving the model to represent high-level semantics of normal daily activities.\n\n\nDISCUSSION & CONCLUSION\n\nThis paper proposes SiFall, a self-supervised incremental learning human fall detection system. SiFall leverages Wi-Fi RF signals and is able to detect daily human falls in real time. Extensive experiment results demonstrate that SiFall achieves high accuracy in human fall detection and is resilient to varied human subjects, environment, and different types of falls. The design of SiFall makes an important contribution towards building practical and reliable RF-based fall detection systems. The current study is still limited in its lack of real fall samples, especially of elderly aged above 60. Since SiFall relies on wireless channel dynamics to catch human activities, it is currently limited to working with single room occupancy. We leave the exploration to the above two limitations to future work when developing SiFall into higher technology readiness levels.\n\n\nACKNOWLEDGMENTS\n\nWe sincerely thank the shepherd and reviewers for their insightful comments and suggestions. We also thank all volunteers for their participation in our experiments. This research is supported by the National Research Foundation Singapore under its Industry Alignment Fund -Pre-positioning (IAF-PP) Funding Initiative, and Ministry of Education Singapore MOE AcRF Tier 2 MOE-T2EP20220-0004. Any opinions, findings and conclusions or recommendations expressed in this material are those of the authors and do not reflect the views of National Research Foundation Singapore and other funding agencies.\n\nFigure 1 :\n1Diversity of falls.\n\nFigure 2 :\n2STFT segments across activities and testing subjects.\n\nFigure 3 :\n3Overview of SiFall\n\n\nExtraction and Denoising. The received WiFi signal can be modeled as: ( , ) = ( , ) \u00d7 ( , )\n\nFigure 4 :\n4Static CSI Amplitude (upper left), Dynamic CSI Amplitude (upper right) and the Extract Channel Dynamic ( ), gray is the ground truth static.\n\nFigure 5 :\n5The STFT spectrum and the corresponding acceleration of channel dynamic.\n\nFigure 6 :\n6The FallNet Architecture: the encoder, decoder and bottleneck layer.\n\nFigure 7 :\n7Up-pooling diagram.\n\nFigure 8 :\n8The environment of the three testbeds and their floor plans.to maintain the FallNet and perform real-time inference to detect the falls.\n\n\n-defined threshold on the measured CSI phase difference between two Rx antennas and segments the collected CSI stream with a fixed 3s time window. RT-Fall then feeds the derived statistical phase and amplitude features of the CSI segment into a pre-trained SVM model to identify falls. We reproduce the system and train an SVM classification model of RT-Fall with the data collected from our testbed, the same as what we use to pretrain our FallNet.\n\nFigure 9 :\n9System end-to-end performance evolution over time across different test subjects.\n\n\noriginal and reconstructed STFT segments of Falls. (b) The original and reconstructed STFT segments of other activities.\n\nFigure 10 :\n10Visualization of the FallNet original input and reconstructed output STFT segments.\n\nFigure 11 :\n11SiFall (a) segmentation performance of movement detection error and (b) the acceleration distribution of different types of movements.\n\nFigure 12 :\n12Comparison of the ground truth and SiFall segmented lengths of different activities.\n\nFigure 13 :\n13False alarms that occur during the daily life adoption test across three days.\n\nFigure 14 :\n14Accuracy of different person at different link distances\n\n\n) FallNet model complexity compared with SOTA CNN-based models.\n\nFigure 15 :\n15SiFall computation overhead.\n\nTable 1 :\n1Summary of the testing subjects\n\nTable 2 :\n2Types of Falls slip, stumble scenes: rushing to answer the telephone, slipping in the bathroom, and tripping over the cable, etc.Types Examples \n\n\"walk fall\" \n\n\"stop fall\" \n\nlost balance, lost consciousness \nscenes: coming out of bed, epileptic seizure, stroke, \nand heart attack, etc. \n\n\"slow fall\" \n\ndizziness/vertigo, weakness \nscenes: arthritis pain, transfer to a dim room, postural hypotension, \nand vision disorder, etc. \n\n\nA INSTANCE NORM VS BATCH NORMThe equation of Instance Norm is the same as Batch Norm such that:where , are affine parameters learned from data; ( ), ( ) are the mean and standard deviation. The difference of the two norm just the way that how the statistical descriptors and are obtained. Given an input batch \u2208 R \u00d7 \u00d7 \u00d7 , Batch Norm normalizes the mean and standard deviation for each individual feature channel to a whole batch:As Batch Norm uses mini-batch statistics during training phase and replace them with average mean and variance across batches during inference phase, which implicitly requires consistency distribution of training domain and inference domain. SiFall is an online detection system and the samples keep generated that might induce difference across different person and environments so that we use Instance Norm which normalize as per sample:B CONVOLUTION OPERATION INDEPENDENT TO THE INPUT SIZE.The \"convolution\" operation in the neural network is different from the \"convolution\" in the signal processing domain. Indeed, the convolution operation is an element-wise multiplication and summation over a local region of the input tensor. The operation is repeated in sequential local regions until the whole tensor has been calculated. Each learnable filter in convolution operation with dimension \u2208 R \u00d7 , where denotes the kernel size, i.e., the size of the local region that calculates the multiplication. Let \u2208 R \u00d7 \u00d7 denote the input tensor. The convolution operation calculates output such that:, where is the number of learnable filters. The 'same padding' technique help choose proper and so that = , = . Consequently, convolution layer are able to adapt to the input tensor with arbitrary size.\nCapturing the human figure through a wall. Fadel Adib, Chen-Yu Hsu, Hongzi Mao, Dina Katabi, Fr\u00e9do Durand, ACM Transactions on Graphics (TOG). 34Fadel Adib, Chen-Yu Hsu, Hongzi Mao, Dina Katabi, and Fr\u00e9do Durand. 2015. Capturing the human figure through a wall. ACM Transactions on Graphics (TOG) 34, 6 (2015), 1-13.\n\n3d tracking via body radio reflections. Zach Fadel Adib, Dina Kabelac, Robert C Katabi, Miller, 11th {USENIX} Symposium on Networked Systems Design and Implementation. Fadel Adib, Zach Kabelac, Dina Katabi, and Robert C Miller. 2014. 3d tracking via body radio reflections. In 11th {USENIX} Symposium on Networked Systems Design and Implementation ({NSDI} 14). 317-329.\n\nAccelerometerbased fall detection for smartphones. Bruno Aguiar, Tiago Rocha, Joana Silva, Ines Sousa, IEEE International Symposium on Medical Measurements and Applications (MeMeA). IEEE. Bruno Aguiar, Tiago Rocha, Joana Silva, and Ines Sousa. 2014. Accelerometer- based fall detection for smartphones. In 2014 IEEE International Symposium on Medical Measurements and Applications (MeMeA). IEEE, 1-6.\n\nCommon types of falls in the elderly population, their associated risk factors and prevention in a tertiary care center. Meshari Attar, M Yaser, Alsinnari, Mohammed S Alqarni, M Ziad, Abdulmalek Bukhari, Abdulkarim W Alzahrani, Ammar Abukhodair, Maryam Qadi, Alotibi, Jastaniah, Cureus. 135Meshari Attar, Yaser M Alsinnari, Mohammed S Alqarni, Ziad M Bukhari, Ab- dulmalek Alzahrani, Abdulkarim W Abukhodair, Ammar Qadi, Maryam Alotibi, and Nisreen A Jastaniah. 2021. Common types of falls in the elderly population, their associated risk factors and prevention in a tertiary care center. Cureus 13, 5 (2021).\n\nAbhishek Rajkumar Sethi, Deepak Vasisht, and Dinesh Bharadia. 2020. Deep learning based wireless localization for indoor navigation. Roshan Ayyalasomayajula, Aditya Arun, Chenfeng Wu, Sanatan Sharma, Proceedings of the 26th Annual International Conference on Mobile Computing and Networking. the 26th Annual International Conference on Mobile Computing and NetworkingRoshan Ayyalasomayajula, Aditya Arun, Chenfeng Wu, Sanatan Sharma, Ab- hishek Rajkumar Sethi, Deepak Vasisht, and Dinesh Bharadia. 2020. Deep learning based wireless localization for indoor navigation. In Proceedings of the 26th Annual International Conference on Mobile Computing and Networking. 1-14.\n\nSegnet: A deep convolutional encoder-decoder architecture for image segmentation. IEEE transactions on pattern analysis and machine intelligence. Vijay Badrinarayanan, Alex Kendall, Roberto Cipolla, 39Vijay Badrinarayanan, Alex Kendall, and Roberto Cipolla. 2017. Segnet: A deep convolutional encoder-decoder architecture for image segmentation. IEEE trans- actions on pattern analysis and machine intelligence 39, 12 (2017), 2481-2495.\n\nThe direct costs of fatal and non-fatal falls among older adults-United States. R Elizabeth, Judy A Burns, Robin Stevens, Lee, Journal of safety research. 58Elizabeth R Burns, Judy A Stevens, and Robin Lee. 2016. The direct costs of fatal and non-fatal falls among older adults-United States. Journal of safety research 58 (2016), 99-103.\n\nTeaching rf to sense without rf training measurements. Hong Cai, Belal Korany, R Chitra, Yasamin Karanam, Mostofi, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies. the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies4Hong Cai, Belal Korany, Chitra R Karanam, and Yasamin Mostofi. 2020. Teach- ing rf to sense without rf training measurements. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 4, 4 (2020), 1-22.\n\nA smartphone-based system for detecting falls using anomaly detection. Vincenzo Carletti, Antonio Greco, Alessia Saggese, Mario Vento, International Conference on Image Analysis and Processing. SpringerVincenzo Carletti, Antonio Greco, Alessia Saggese, and Mario Vento. 2017. A smartphone-based system for detecting falls using anomaly detection. In Interna- tional Conference on Image Analysis and Processing. Springer, 490-499.\n\nRF-IDH: An intelligent fall detection system for hemodialysis patients via COTS RFID. Yi Chen, Fu Xiao, Haiping Huang, Lijuan Sun, Future Generation Computer Systems. 113Yi Chen, Fu Xiao, Haiping Huang, and Lijuan Sun. 2020. RF-IDH: An intelligent fall detection system for hemodialysis patients via COTS RFID. Future Generation Computer Systems 113 (2020), 13-24.\n\nRF-Based Human Activity Recognition Using Signal Adapted Convolutional Neural Network. Zhe Chen, Chao Cai, Tianyue Zheng, Jun Luo, Jie Xiong, Xin Wang, IEEE Transactions on Mobile Computing. Zhe Chen, Chao Cai, Tianyue Zheng, Jun Luo, Jie Xiong, and Xin Wang. 2021. RF- Based Human Activity Recognition Using Signal Adapted Convolutional Neural Network. IEEE Transactions on Mobile Computing (2021).\n\nGlobal aging: Challenges for community psychology. Tak Sheung, Kenneth Cheng, Heller, American Journal of Community Psychology. 44Sheung-Tak Cheng and Kenneth Heller. 2009. Global aging: Challenges for community psychology. American Journal of Community Psychology 44, 1-2 (2009), 161-173.\n\nHome camera-based fall detection system for the elderly. Alberto Koldo De Miguel, Miguel Brunete, Ernesto Hernando, Gambao, Sensors. 172864Koldo De Miguel, Alberto Brunete, Miguel Hernando, and Ernesto Gambao. 2017. Home camera-based fall detection system for the elderly. Sensors 17, 12 (2017), 2864.\n\nImagenet: A large-scale hierarchical image database. Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, Li Fei-Fei, 2009 IEEE conference on computer vision and pattern recognition. IeeeJia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. 2009. Imagenet: A large-scale hierarchical image database. In 2009 IEEE conference on computer vision and pattern recognition. Ieee, 248-255.\n\nAudio-based Active and Assisted Living: A review of selected applications and future trends. Vladimir Despotovic, Peter Pocta, Andrej Zgank, Computers in Biology and Medicine. 106027Vladimir Despotovic, Peter Pocta, and Andrej Zgank. 2022. Audio-based Ac- tive and Assisted Living: A review of selected applications and future trends. Computers in Biology and Medicine (2022), 106027.\n\nFalls among older adults: An overview. Prevention, Centers for Disease Control. Centers for Disease Control, Prevention, et al. 2010. Falls among older adults: An overview.\n\nAnomaly detection in smart houses: Monitoring elderly daily behavior for fall detecting. M Yves, Galv\u00e3o, A Vinicius, Albuquerque, J T Bruno, Fernandes, M\u00eauser, Valen\u00e7a, IEEE Latin American Conference on Computational Intelligence (LA-CCI). IEEE. Yves M Galv\u00e3o, Vinicius A Albuquerque, Bruno JT Fernandes, and M\u00eauser JS Valen\u00e7a. 2017. Anomaly detection in smart houses: Monitoring elderly daily be- havior for fall detecting. In 2017 IEEE Latin American Conference on Computational Intelligence (LA-CCI). IEEE, 1-6.\n\nRF Vital Sign Sensing under Free Body Movement. Jian Gong, Xinyu Zhang, Kaixin Lin, Ju Ren, Yaoxue Zhang, Wenxun Qiu, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies. 5Jian Gong, Xinyu Zhang, Kaixin Lin, Ju Ren, Yaoxue Zhang, and Wenxun Qiu. 2021. RF Vital Sign Sensing under Free Body Movement. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 5, 3 (2021), 1-22.\n\n. Ian Goodfellow, Yoshua Bengio, Aaron Courville, Yoshua Bengio, Deep learning. 1MIT press CambridgeIan Goodfellow, Yoshua Bengio, Aaron Courville, and Yoshua Bengio. 2016. Deep learning. Vol. 1. MIT press Cambridge.\n\nFood and liquid sensing in practical environments using rfids. Unsoo Ha, Junshan Leng, Alaa Khaddaj, Fadel Adib, 17th {USENIX} Symposium on Networked Systems Design and Implementation. 20Unsoo Ha, Junshan Leng, Alaa Khaddaj, and Fadel Adib. 2020. Food and liquid sensing in practical environments using rfids. In 17th {USENIX} Symposium on Networked Systems Design and Implementation ({NSDI} 20). 1083-1100.\n\nDelving deep into rectifiers: Surpassing human-level performance on imagenet classification. Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, Proceedings of the IEEE international conference on computer vision. the IEEE international conference on computer visionKaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. 2015. Delving deep into rectifiers: Surpassing human-level performance on imagenet classification. In Proceedings of the IEEE international conference on computer vision. 1026-1034.\n\nReducing the dimensionality of data with neural networks. E Geoffrey, Hinton, R Ruslan, Salakhutdinov, science. 313Geoffrey E Hinton and Ruslan R Salakhutdinov. 2006. Reducing the dimensional- ity of data with neural networks. science 313, 5786 (2006), 504-507.\n\nDeFall: Environment-Independent Passive Fall Detection using WiFi. Yuqian Hu, Feng Zhang, Chenshu Wu, Beibei Wang, Kj Ray Liu, IEEE Internet of Things Journal. Yuqian Hu, Feng Zhang, Chenshu Wu, Beibei Wang, and KJ Ray Liu. 2021. DeFall: Environment-Independent Passive Fall Detection using WiFi. IEEE Internet of Things Journal (2021).\n\nBatch normalization: Accelerating deep network training by reducing internal covariate shift. Sergey Ioffe, Christian Szegedy, arXiv:1502.03167arXiv preprintSergey Ioffe and Christian Szegedy. 2015. Batch normalization: Accelerating deep network training by reducing internal covariate shift. arXiv preprint arXiv:1502.03167 (2015).\n\nTowards 3D human pose construction using wifi. Wenjun Jiang, Hongfei Xue, Chenglin Miao, Shiyang Wang, Sen Lin, Chong Tian, Srinivasan Murali, Haochen Hu, Zhi Sun, Lu Su, Proceedings of the 26th Annual International Conference on Mobile Computing and Networking. the 26th Annual International Conference on Mobile Computing and NetworkingWenjun Jiang, Hongfei Xue, Chenglin Miao, Shiyang Wang, Sen Lin, Chong Tian, Srinivasan Murali, Haochen Hu, Zhi Sun, and Lu Su. 2020. Towards 3D human pose construction using wifi. In Proceedings of the 26th Annual International Conference on Mobile Computing and Networking. 1-14.\n\nSelf-supervised visual feature learning with deep neural networks: A survey. Longlong Jing, Yingli Tian, 43Longlong Jing and Yingli Tian. 2020. Self-supervised visual feature learning with deep neural networks: A survey. IEEE transactions on pattern analysis and machine intelligence 43, 11 (2020), 4037-4058.\n\nA comparison of wearable fitness devices. Kanitthika Kaewkannate, Soochan Kim, BMC public health. 16Kanitthika Kaewkannate and Soochan Kim. 2016. A comparison of wearable fitness devices. BMC public health 16, 1 (2016), 1-16.\n\nOptimal detection of changepoints with a linear computational cost. Rebecca Killick, Paul Fearnhead, Eckley, J. Amer. Statist. Assoc. 107Rebecca Killick, Paul Fearnhead, and Idris A Eckley. 2012. Optimal detection of changepoints with a linear computational cost. J. Amer. Statist. Assoc. 107, 500 (2012), 1590-1598.\n\nAdam: A method for stochastic optimization. P Diederik, Jimmy Kingma, Ba, arXiv:1412.6980arXiv preprintDiederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic opti- mization. arXiv preprint arXiv:1412.6980 (2014).\n\nP Diederik, Max Kingma, Welling, arXiv:1312.6114Auto-encoding variational bayes. arXiv preprintDiederik P Kingma and Max Welling. 2013. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114 (2013).\n\nXmodalid: Using wifi for through-wall person identification from candidate video footage. Belal Korany, R Chitra, Hong Karanam, Yasamin Cai, Mostofi, The 25th Annual International Conference on Mobile Computing and Networking. Belal Korany, Chitra R Karanam, Hong Cai, and Yasamin Mostofi. 2019. Xmodal- id: Using wifi for through-wall person identification from candidate video footage. In The 25th Annual International Conference on Mobile Computing and Networking. 1-15.\n\nAssessment and management of falls in older people. Emily Kwan, Sharon E Straus, CMAJ. 186Emily Kwan and Sharon E Straus. 2014. Assessment and management of falls in older people. CMAJ 186, 16 (2014), E610-E621.\n\nFM-track: pushing the limits of contactless multi-target tracking using acoustic signals. Dong Li, Jialin Liu, Jie Sunghoon Ivan Lee, Xiong, Proceedings of the 18th Conference on Embedded Networked Sensor Systems. the 18th Conference on Embedded Networked Sensor SystemsDong Li, Jialin Liu, Sunghoon Ivan Lee, and Jie Xiong. 2020. FM-track: pushing the limits of contactless multi-target tracking using acoustic signals. In Proceedings of the 18th Conference on Embedded Networked Sensor Systems. 150-163.\n\nBi-LSTM network for multimodal continuous human activity recognition and fall detection. Haobo Li, Aman Shrestha, Hadi Heidari, Julien Le Kernec, Francesco Fioranelli, IEEE Sensors Journal. 20Haobo Li, Aman Shrestha, Hadi Heidari, Julien Le Kernec, and Francesco Fio- ranelli. 2019. Bi-LSTM network for multimodal continuous human activity recognition and fall detection. IEEE Sensors Journal 20, 3 (2019), 1191-1201.\n\nIsolation forest. Tony Fei, Kai Ming Liu, Zhi-Hua Ting, Zhou, eighth ieee international conference on data mining. IEEEFei Tony Liu, Kai Ming Ting, and Zhi-Hua Zhou. 2008. Isolation forest. In 2008 eighth ieee international conference on data mining. IEEE, 413-422.\n\nReal-time arm skeleton tracking and gesture inference tolerant to missing wearable sensors. Yang Liu, Zhenjiang Li, Zhidan Liu, Kaishun Wu, Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services. the 17th Annual International Conference on Mobile Systems, Applications, and ServicesYang Liu, Zhenjiang Li, Zhidan Liu, and Kaishun Wu. 2019. Real-time arm skeleton tracking and gesture inference tolerant to missing wearable sensors. In Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services. 287-299.\n\nWorld Health Organization, World Health Organization. Ageing, and Life Course Unit. WHO global report on falls prevention in older age. World Health OrganizationWorld Health Organization, World Health Organization. Ageing, and Life Course Unit. 2008. WHO global report on falls prevention in older age. World Health Organization.\n\nFallDeFi: Ubiquitous fall detection using commodity Wi-Fi devices. Sameera Palipana, David Rojas, Piyush Agrawal, Dirk Pesch, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies. the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies1Sameera Palipana, David Rojas, Piyush Agrawal, and Dirk Pesch. 2018. FallDeFi: Ubiquitous fall detection using commodity Wi-Fi devices. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 1, 4 (2018), 1-25.\n\nLongbing Cao, and Anton Van Den Hengel. 2021. Deep learning for anomaly detection: A review. Guansong Pang, Chunhua Shen, ACM Computing Surveys (CSUR). 54Guansong Pang, Chunhua Shen, Longbing Cao, and Anton Van Den Hengel. 2021. Deep learning for anomaly detection: A review. ACM Computing Surveys (CSUR) 54, 2 (2021), 1-38.\n\nOn estimation of a probability density function and mode. The annals of mathematical statistics. Emanuel Parzen, 33Emanuel Parzen. 1962. On estimation of a probability density function and mode. The annals of mathematical statistics 33, 3 (1962), 1065-1076.\n\nScikit-learn: Machine learning in Python. Fabian Pedregosa, Ga\u00ebl Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, Journal of machine learning research. 12Fabian Pedregosa, Ga\u00ebl Varoquaux, Alexandre Gramfort, Vincent Michel, Bertrand Thirion, Olivier Grisel, Mathieu Blondel, Peter Prettenhofer, Ron Weiss, Vincent Dubourg, et al. 2011. Scikit-learn: Machine learning in Python. Journal of machine learning research 12, Oct (2011), 2825-2830.\n\npytorch. v1.7.1. TORCHVISION.TRANSFORMS. pytorch. v1.7.1. TORCHVISION.TRANSFORMS. https://pytorch.org/docs/stable/ torchvision/transforms.\n\nWidar: Decimeter-level passive tracking via velocity monitoring with commodity Wi-Fi. Chenshu Kun Qian, Zheng Wu, Yunhao Yang, Kyle Liu, Jamieson, Proceedings of the 18th ACM International Symposium on Mobile Ad Hoc Networking and Computing. the 18th ACM International Symposium on Mobile Ad Hoc Networking and ComputingKun Qian, Chenshu Wu, Zheng Yang, Yunhao Liu, and Kyle Jamieson. 2017. Widar: Decimeter-level passive tracking via velocity monitoring with commodity Wi-Fi. In Proceedings of the 18th ACM International Symposium on Mobile Ad Hoc Networking and Computing. 1-10.\n\nA survey on recent advances in wearable fall detection systems. Anita Ramachandran, Anupama Karuppiah, BioMed research international. 2020Anita Ramachandran and Anupama Karuppiah. 2020. A survey on recent ad- vances in wearable fall detection systems. BioMed research international 2020 (2020).\n\nTagfall: Towards unobstructive fine-grained fall detection based on uhf passive rfid tags. Wenjie Ruan, Lina Yao, Z Quan, Nickolas Sheng, Xue Falkner, Tao Li, Gu, proceedings of the 12th EAI International Conference on Mobile and Ubiquitous Systems: Computing, Networking and Services on 12th EAI International Conference on Mobile and Ubiquitous Systems: Computing, Networking and Services. the 12th EAI International Conference on Mobile and Ubiquitous Systems: Computing, Networking and Services on 12th EAI International Conference on Mobile and Ubiquitous Systems: Computing, Networking and ServicesWenjie Ruan, Lina Yao, Quan Z Sheng, Nickolas Falkner, Xue Li, and Tao Gu. 2015. Tagfall: Towards unobstructive fine-grained fall detection based on uhf passive rfid tags. In proceedings of the 12th EAI International Conference on Mobile and Ubiquitous Systems: Computing, Networking and Services on 12th EAI International Conference on Mobile and Ubiquitous Systems: Computing, Networking and Services. 140-149.\n\nFalls in older people: epidemiology, risk factors and strategies for prevention. Laurence Z Rubenstein, Age and ageing. 35Laurence Z Rubenstein. 2006. Falls in older people: epidemiology, risk factors and strategies for prevention. Age and ageing 35, suppl_2 (2006), ii37-ii41.\n\nEstimating the support of a high-dimensional distribution. Bernhard Sch\u00f6lkopf, C John, John Platt, Alex J Shawe-Taylor, Robert C Smola, Williamson, Neural computation. 13Bernhard Sch\u00f6lkopf, John C Platt, John Shawe-Taylor, Alex J Smola, and Robert C Williamson. 2001. Estimating the support of a high-dimensional distribution. Neural computation 13, 7 (2001), 1443-1471.\n\nKaren Simonyan, Andrew Zisserman, arXiv:1409.1556Very deep convolutional networks for large-scale image recognition. arXiv preprintKaren Simonyan and Andrew Zisserman. 2014. Very deep convolutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556 (2014).\n\nGoing deeper with convolutions. Christian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, Andrew Rabinovich, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionChristian Szegedy, Wei Liu, Yangqing Jia, Pierre Sermanet, Scott Reed, Dragomir Anguelov, Dumitru Erhan, Vincent Vanhoucke, and Andrew Rabinovich. 2015. Going deeper with convolutions. In Proceedings of the IEEE conference on computer vision and pattern recognition. 1-9.\n\nTime series classification for varying length series. Chang Wei Tan, Francois Petitjean, Eamonn Keogh, Geoffrey I Webb, arXiv:1910.04341arXiv preprintChang Wei Tan, Francois Petitjean, Eamonn Keogh, and Geoffrey I Webb. 2019. Time series classification for varying length series. arXiv preprint arXiv:1910.04341 (2019).\n\nRF-based fall monitoring using convolutional neural networks. Yonglong Tian, Guang-He Lee, Hao He, Chen-Yu Hsu, Dina Katabi, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies. the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies2Yonglong Tian, Guang-He Lee, Hao He, Chen-Yu Hsu, and Dina Katabi. 2018. RF-based fall monitoring using convolutional neural networks. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 2, 3 (2018), 1-24.\n\nImproved texture networks: Maximizing quality and diversity in feed-forward stylization and texture synthesis. Dmitry Ulyanov, Andrea Vedaldi, Victor Lempitsky, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionDmitry Ulyanov, Andrea Vedaldi, and Victor Lempitsky. 2017. Improved texture networks: Maximizing quality and diversity in feed-forward stylization and texture synthesis. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 6924-6932.\n\nRT-Fall: A real-time and contactless fall detection system with commodity WiFi devices. Hao Wang, Daqing Zhang, Yasha Wang, Junyi Ma, Yuxiang Wang, Shengjie Li, IEEE Transactions on Mobile Computing. 16Hao Wang, Daqing Zhang, Yasha Wang, Junyi Ma, Yuxiang Wang, and Shengjie Li. 2016. RT-Fall: A real-time and contactless fall detection system with commodity WiFi devices. IEEE Transactions on Mobile Computing 16, 2 (2016), 511-526.\n\nEffective end-to-end unsupervised outlier detection via inlier priority of discriminative network. Siqi Wang, Yijie Zeng, Xinwang Liu, En Zhu, Jianping Yin, Chuanfu Xu, Marius Kloft, Advances in neural information processing systems. 32Siqi Wang, Yijie Zeng, Xinwang Liu, En Zhu, Jianping Yin, Chuanfu Xu, and Marius Kloft. 2019. Effective end-to-end unsupervised outlier detection via inlier priority of discriminative network. Advances in neural information processing systems 32 (2019).\n\nUnderstanding and modeling of wifi signal based human activity recognition. Wei Wang, Alex X Liu, Muhammad Shahzad, Kang Ling, Sanglu Lu, Proceedings of the 21st annual international conference on mobile computing and networking. the 21st annual international conference on mobile computing and networkingWei Wang, Alex X Liu, Muhammad Shahzad, Kang Ling, and Sanglu Lu. 2015. Understanding and modeling of wifi signal based human activity recognition. In Proceedings of the 21st annual international conference on mobile computing and networking. 65-76.\n\nPush the limit of acoustic gesture recognition. Yanwen Wang, Jiaxing Shen, Yuanqing Zheng, IEEE Transactions on Mobile Computing. Yanwen Wang, Jiaxing Shen, and Yuanqing Zheng. 2020. Push the limit of acoustic gesture recognition. IEEE Transactions on Mobile Computing (2020).\n\nWifall: Device-free fall detection by wireless networks. Yuxi Wang, Kaishun Wu, Lionel M Ni, IEEE Transactions on Mobile Computing. 16Yuxi Wang, Kaishun Wu, and Lionel M Ni. 2016. Wifall: Device-free fall detection by wireless networks. IEEE Transactions on Mobile Computing 16, 2 (2016), 581- 594.\n\nHow dangerous are falls in old people at home? British medical journal. - Oh Wilder, T A Smith, Thorp, Clinical research ed.). 2822132OH Wilder-Smith and TA Thorp. 1981. How dangerous are falls in old people at home? British medical journal (Clinical research ed.) 282, 6282 (1981), 2132.\n\nPrecise power delay profiling with commodity Wi-Fi. Yaxiong Xie, Zhenjiang Li, Mo Li, IEEE Transactions on Mobile Computing. 18Yaxiong Xie, Zhenjiang Li, and Mo Li. 2018. Precise power delay profiling with commodity Wi-Fi. IEEE Transactions on Mobile Computing 18, 6 (2018), 1342- 1355.\n\nmD-Track: Leveraging multi-dimensionality for passive indoor Wi-Fi tracking. Yaxiong Xie, Jie Xiong, Mo Li, Kyle Jamieson, The 25th Annual International Conference on Mobile Computing and Networking. Yaxiong Xie, Jie Xiong, Mo Li, and Kyle Jamieson. 2019. mD-Track: Leveraging multi-dimensionality for passive indoor Wi-Fi tracking. In The 25th Annual International Conference on Mobile Computing and Networking. 1-16.\n\nEmpirical evaluation of rectified activations in convolutional network. Bing Xu, Naiyan Wang, Tianqi Chen, Mu Li, arXiv:1505.00853arXiv preprintBing Xu, Naiyan Wang, Tianqi Chen, and Mu Li. 2015. Empirical evaluation of rectified activations in convolutional network. arXiv preprint arXiv:1505.00853 (2015).\n\nLearning deep representations of appearance and motion for anomalous event detection. Dan Xu, Elisa Ricci, Yan Yan, Jingkuan Song, Nicu Sebe, arXiv:1510.01553arXiv preprintDan Xu, Elisa Ricci, Yan Yan, Jingkuan Song, and Nicu Sebe. 2015. Learning deep representations of appearance and motion for anomalous event detection. arXiv preprint arXiv:1510.01553 (2015).\n\nA novel walking speed estimation scheme and its application to treadmill control for gait rehabilitation. Jungwon Yoon, Hyung-Soon Park, Diane Louise Damiano, Journal of neuroengineering and rehabilitation. 9Jungwon Yoon, Hyung-Soon Park, and Diane Louise Damiano. 2012. A novel walking speed estimation scheme and its application to treadmill control for gait rehabilitation. Journal of neuroengineering and rehabilitation 9, 1 (2012), 1-13.\n\nComputer vision based fall detection by a convolutional neural network. Miao Yu, Liyun Gong, Stefanos Kollias, Proceedings of the 19th ACM International Conference on Multimodal Interaction. the 19th ACM International Conference on Multimodal InteractionMiao Yu, Liyun Gong, and Stefanos Kollias. 2017. Computer vision based fall detection by a convolutional neural network. In Proceedings of the 19th ACM International Conference on Multimodal Interaction. 416-420.\n\nThrough-wall human pose estimation using radio signals. Mingmin Zhao, Tianhong Li, Mohammad Abu Alsheikh, Yonglong Tian, Hang Zhao, Antonio Torralba, Dina Katabi, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionMingmin Zhao, Tianhong Li, Mohammad Abu Alsheikh, Yonglong Tian, Hang Zhao, Antonio Torralba, and Dina Katabi. 2018. Through-wall human pose estimation using radio signals. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 7356-7365.\n\nRF-based 3D skeletons. Mingmin Zhao, Yonglong Tian, Hang Zhao, Mohammad Abu Alsheikh, Tianhong Li, Rumen Hristov, Zachary Kabelac, Dina Katabi, Antonio Torralba, Proceedings of the 2018 Conference of the ACM Special Interest Group on Data Communication. the 2018 Conference of the ACM Special Interest Group on Data CommunicationMingmin Zhao, Yonglong Tian, Hang Zhao, Mohammad Abu Alsheikh, Tianhong Li, Rumen Hristov, Zachary Kabelac, Dina Katabi, and Antonio Torralba. 2018. RF-based 3D skeletons. In Proceedings of the 2018 Conference of the ACM Special Interest Group on Data Communication. 267-281.\n\nLearning sleep stages from radio signals: A conditional adversarial architecture. Mingmin Zhao, Shichao Yue, Dina Katabi, Tommi S Jaakkola, Matt T Bianchi, PMLRInternational Conference on Machine Learning. Mingmin Zhao, Shichao Yue, Dina Katabi, Tommi S Jaakkola, and Matt T Bianchi. 2017. Learning sleep stages from radio signals: A conditional adversarial archi- tecture. In International Conference on Machine Learning. PMLR, 4100-4109.\n\nZero-effort cross-domain gesture recognition with Wi-Fi. Yue Zheng, Yi Zhang, Kun Qian, Guidong Zhang, Yunhao Liu, Chenshu Wu, Zheng Yang, Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services. the 17th Annual International Conference on Mobile Systems, Applications, and ServicesYue Zheng, Yi Zhang, Kun Qian, Guidong Zhang, Yunhao Liu, Chenshu Wu, and Zheng Yang. 2019. Zero-effort cross-domain gesture recognition with Wi-Fi. In Proceedings of the 17th Annual International Conference on Mobile Systems, Applications, and Services. 313-325.\n\nFall detection using convolutional neural network with multi-sensor fusion. Xu Zhou, Li-Chang Qian, Peng-Jie You, Ze-Gang Ding, Yu-Qi Han, 2018 IEEE international conference on Multimedia & Expo Workshops (ICMEW). IEEEXu Zhou, Li-Chang Qian, Peng-Jie You, Ze-Gang Ding, and Yu-Qi Han. 2018. Fall detection using convolutional neural network with multi-sensor fusion. In 2018 IEEE international conference on Multimedia & Expo Workshops (ICMEW). IEEE.\n\nDeep autoencoding gaussian mixture model for unsupervised anomaly detection. Bo Zong, Qi Song, Martin Renqiang Min, Wei Cheng, Cristian Lumezanu, Daeki Cho, Haifeng Chen, International conference on learning representations. Bo Zong, Qi Song, Martin Renqiang Min, Wei Cheng, Cristian Lumezanu, Daeki Cho, and Haifeng Chen. 2018. Deep autoencoding gaussian mixture model for unsupervised anomaly detection. In International conference on learning represen- tations.\n", "annotations": {"author": "[{\"end\":108,\"start\":77},{\"end\":131,\"start\":109},{\"end\":141,\"start\":132},{\"end\":175,\"start\":142},{\"end\":182,\"start\":176},{\"end\":249,\"start\":183},{\"end\":339,\"start\":250}]", "publisher": null, "author_last_name": "[{\"end\":85,\"start\":83},{\"end\":114,\"start\":112},{\"end\":140,\"start\":138},{\"end\":153,\"start\":150}]", "author_first_name": "[{\"end\":82,\"start\":77},{\"end\":111,\"start\":109},{\"end\":137,\"start\":132},{\"end\":149,\"start\":142},{\"end\":178,\"start\":176},{\"end\":181,\"start\":179}]", "author_affiliation": "[{\"end\":248,\"start\":184},{\"end\":338,\"start\":251}]", "title": "[{\"end\":56,\"start\":1},{\"end\":395,\"start\":340}]", "venue": "[{\"end\":461,\"start\":397}]", "abstract": "[{\"end\":2129,\"start\":955}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b6\"},\"end\":2196,\"start\":2193},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":2292,\"start\":2288},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":2478,\"start\":2474},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":2774,\"start\":2770},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":3098,\"start\":3094},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":3171,\"start\":3167},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":3402,\"start\":3398},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":3405,\"start\":3402},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":3408,\"start\":3405},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":3411,\"start\":3408},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":3776,\"start\":3772},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":3779,\"start\":3776},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":3804,\"start\":3800},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":3807,\"start\":3804},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":6747,\"start\":6743},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":9259,\"start\":9255},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":9559,\"start\":9556},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":9562,\"start\":9559},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":9877,\"start\":9873},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":11283,\"start\":11279},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":16516,\"start\":16512},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":16519,\"start\":16516},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":20108,\"start\":20104},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":20122,\"start\":20118},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":20756,\"start\":20752},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":21688,\"start\":21684},{\"end\":21763,\"start\":21751},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":22155,\"start\":22151},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":26748,\"start\":26744},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":26836,\"start\":26832},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":27259,\"start\":27255},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":27301,\"start\":27297},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":27521,\"start\":27517},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":27808,\"start\":27804},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":28929,\"start\":28926},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":30885,\"start\":30881},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":34851,\"start\":34847},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":35999,\"start\":35995},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":38130,\"start\":38126},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":40256,\"start\":40252},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":41796,\"start\":41792},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":41832,\"start\":41828},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":42412,\"start\":42408},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":43712,\"start\":43709},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":43715,\"start\":43712},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":43718,\"start\":43715},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":43944,\"start\":43941},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":58147,\"start\":58143},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":58150,\"start\":58147},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":58153,\"start\":58150},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":58156,\"start\":58153},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":58159,\"start\":58156},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":58162,\"start\":58159},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":58361,\"start\":58357},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":58473,\"start\":58469},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":58476,\"start\":58473},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":58479,\"start\":58476},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":58482,\"start\":58479},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":58671,\"start\":58667},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":58894,\"start\":58891},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":58905,\"start\":58901},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":58924,\"start\":58920},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":59272,\"start\":59268},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":59691,\"start\":59687},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":59694,\"start\":59691},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":59697,\"start\":59694},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":59927,\"start\":59924},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":59929,\"start\":59927},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":59953,\"start\":59949},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":60031,\"start\":60027},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":60056,\"start\":60052},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":60132,\"start\":60128},{\"attributes\":{\"ref_id\":\"b68\"},\"end\":60135,\"start\":60132},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":60375,\"start\":60372},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":60378,\"start\":60375},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":60404,\"start\":60400},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":60540,\"start\":60537},{\"attributes\":{\"ref_id\":\"b66\"},\"end\":60847,\"start\":60843},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":60877,\"start\":60873},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":60903,\"start\":60899},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":60939,\"start\":60935},{\"attributes\":{\"ref_id\":\"b64\"},\"end\":60942,\"start\":60939},{\"attributes\":{\"ref_id\":\"b65\"},\"end\":60945,\"start\":60942},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":60963,\"start\":60960},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":60975,\"start\":60972},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":60978,\"start\":60975},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":60981,\"start\":60978},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":61372,\"start\":61368},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":61420,\"start\":61416},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":61452,\"start\":61448},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":61489,\"start\":61485},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":61737,\"start\":61733},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":61740,\"start\":61737},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":61743,\"start\":61740},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":62388,\"start\":62384}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":64356,\"start\":64324},{\"attributes\":{\"id\":\"fig_1\"},\"end\":64423,\"start\":64357},{\"attributes\":{\"id\":\"fig_2\"},\"end\":64455,\"start\":64424},{\"attributes\":{\"id\":\"fig_3\"},\"end\":64549,\"start\":64456},{\"attributes\":{\"id\":\"fig_4\"},\"end\":64703,\"start\":64550},{\"attributes\":{\"id\":\"fig_5\"},\"end\":64789,\"start\":64704},{\"attributes\":{\"id\":\"fig_6\"},\"end\":64871,\"start\":64790},{\"attributes\":{\"id\":\"fig_7\"},\"end\":64904,\"start\":64872},{\"attributes\":{\"id\":\"fig_8\"},\"end\":65054,\"start\":64905},{\"attributes\":{\"id\":\"fig_9\"},\"end\":65506,\"start\":65055},{\"attributes\":{\"id\":\"fig_10\"},\"end\":65601,\"start\":65507},{\"attributes\":{\"id\":\"fig_11\"},\"end\":65724,\"start\":65602},{\"attributes\":{\"id\":\"fig_12\"},\"end\":65823,\"start\":65725},{\"attributes\":{\"id\":\"fig_13\"},\"end\":65973,\"start\":65824},{\"attributes\":{\"id\":\"fig_14\"},\"end\":66073,\"start\":65974},{\"attributes\":{\"id\":\"fig_15\"},\"end\":66167,\"start\":66074},{\"attributes\":{\"id\":\"fig_16\"},\"end\":66239,\"start\":66168},{\"attributes\":{\"id\":\"fig_17\"},\"end\":66305,\"start\":66240},{\"attributes\":{\"id\":\"fig_18\"},\"end\":66349,\"start\":66306},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":66393,\"start\":66350},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":66836,\"start\":66394}]", "paragraph": "[{\"end\":2479,\"start\":2145},{\"end\":3355,\"start\":2481},{\"end\":4307,\"start\":3357},{\"end\":5465,\"start\":4309},{\"end\":7398,\"start\":5467},{\"end\":7785,\"start\":7400},{\"end\":8120,\"start\":7787},{\"end\":8283,\"start\":8122},{\"end\":8737,\"start\":8285},{\"end\":8928,\"start\":8770},{\"end\":9731,\"start\":8961},{\"end\":10742,\"start\":9733},{\"end\":11568,\"start\":10765},{\"end\":12384,\"start\":11586},{\"end\":13176,\"start\":12386},{\"end\":13709,\"start\":13194},{\"end\":13873,\"start\":13722},{\"end\":14793,\"start\":13875},{\"end\":16621,\"start\":14795},{\"end\":16851,\"start\":16648},{\"end\":17467,\"start\":16935},{\"end\":18198,\"start\":17522},{\"end\":18635,\"start\":18230},{\"end\":19552,\"start\":18713},{\"end\":20757,\"start\":19589},{\"end\":21422,\"start\":20791},{\"end\":21830,\"start\":21495},{\"end\":22229,\"start\":21832},{\"end\":22482,\"start\":22260},{\"end\":23170,\"start\":22484},{\"end\":23325,\"start\":23220},{\"end\":24416,\"start\":23495},{\"end\":25092,\"start\":24418},{\"end\":25927,\"start\":25094},{\"end\":26181,\"start\":25946},{\"end\":28391,\"start\":26183},{\"end\":28494,\"start\":28393},{\"end\":29505,\"start\":28513},{\"end\":29610,\"start\":29507},{\"end\":29890,\"start\":29680},{\"end\":30350,\"start\":29900},{\"end\":30925,\"start\":30382},{\"end\":31613,\"start\":30959},{\"end\":32830,\"start\":31615},{\"end\":33619,\"start\":32832},{\"end\":34094,\"start\":33665},{\"end\":34370,\"start\":34109},{\"end\":35382,\"start\":34395},{\"end\":36160,\"start\":35443},{\"end\":37329,\"start\":36200},{\"end\":38910,\"start\":37331},{\"end\":39531,\"start\":38912},{\"end\":39676,\"start\":39546},{\"end\":39958,\"start\":39701},{\"end\":41089,\"start\":39960},{\"end\":41380,\"start\":41091},{\"end\":41878,\"start\":41382},{\"end\":42347,\"start\":41880},{\"end\":42617,\"start\":42349},{\"end\":42845,\"start\":42643},{\"end\":45133,\"start\":42855},{\"end\":45878,\"start\":45145},{\"end\":47204,\"start\":45880},{\"end\":47724,\"start\":47206},{\"end\":49048,\"start\":47751},{\"end\":49258,\"start\":49050},{\"end\":49548,\"start\":49260},{\"end\":51594,\"start\":49572},{\"end\":52317,\"start\":51596},{\"end\":54345,\"start\":52346},{\"end\":55247,\"start\":54347},{\"end\":56855,\"start\":55276},{\"end\":58060,\"start\":56880},{\"end\":59572,\"start\":58077},{\"end\":60688,\"start\":59574},{\"end\":62803,\"start\":60690},{\"end\":63704,\"start\":62831},{\"end\":64323,\"start\":63724}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":16934,\"start\":16852},{\"attributes\":{\"id\":\"formula_1\"},\"end\":17521,\"start\":17468},{\"attributes\":{\"id\":\"formula_2\"},\"end\":18712,\"start\":18636},{\"attributes\":{\"id\":\"formula_3\"},\"end\":20790,\"start\":20758},{\"attributes\":{\"id\":\"formula_4\"},\"end\":21494,\"start\":21423},{\"attributes\":{\"id\":\"formula_5\"},\"end\":22259,\"start\":22230},{\"attributes\":{\"id\":\"formula_6\"},\"end\":23477,\"start\":23326},{\"attributes\":{\"id\":\"formula_7\"},\"end\":25945,\"start\":25928},{\"attributes\":{\"id\":\"formula_8\"},\"end\":28512,\"start\":28495},{\"attributes\":{\"id\":\"formula_9\"},\"end\":29679,\"start\":29611},{\"attributes\":{\"id\":\"formula_10\"},\"end\":30381,\"start\":30351},{\"attributes\":{\"id\":\"formula_11\"},\"end\":33664,\"start\":33620},{\"attributes\":{\"id\":\"formula_12\"},\"end\":34108,\"start\":34095},{\"attributes\":{\"id\":\"formula_13\"},\"end\":34394,\"start\":34371},{\"attributes\":{\"id\":\"formula_14\"},\"end\":35442,\"start\":35383}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":42051,\"start\":42044},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":44284,\"start\":44277},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":57480,\"start\":57471}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2143,\"start\":2131},{\"attributes\":{\"n\":\"2\"},\"end\":8768,\"start\":8740},{\"attributes\":{\"n\":\"2.1\"},\"end\":8941,\"start\":8931},{\"attributes\":{\"n\":\"2.1.1\"},\"end\":8959,\"start\":8944},{\"attributes\":{\"n\":\"2.1.3\"},\"end\":10763,\"start\":10745},{\"attributes\":{\"n\":\"2.2\"},\"end\":11584,\"start\":11571},{\"attributes\":{\"n\":\"3\"},\"end\":13192,\"start\":13179},{\"attributes\":{\"n\":\"3.1\"},\"end\":13720,\"start\":13712},{\"attributes\":{\"n\":\"3.2\"},\"end\":16646,\"start\":16624},{\"attributes\":{\"n\":\"3.2.2\"},\"end\":18228,\"start\":18201},{\"attributes\":{\"n\":\"3.2.3\"},\"end\":19587,\"start\":19555},{\"end\":23218,\"start\":23173},{\"attributes\":{\"n\":\"3.3\"},\"end\":23493,\"start\":23479},{\"end\":29898,\"start\":29893},{\"attributes\":{\"n\":\"3.3.3\"},\"end\":30957,\"start\":30928},{\"attributes\":{\"n\":\"3.4\"},\"end\":36198,\"start\":36163},{\"attributes\":{\"n\":\"4\"},\"end\":39544,\"start\":39534},{\"attributes\":{\"n\":\"4.1\"},\"end\":39699,\"start\":39679},{\"attributes\":{\"n\":\"4.2\"},\"end\":42641,\"start\":42620},{\"end\":42853,\"start\":42848},{\"attributes\":{\"n\":\"4.2.2\"},\"end\":45143,\"start\":45136},{\"attributes\":{\"n\":\"4.2.3\"},\"end\":47749,\"start\":47727},{\"attributes\":{\"n\":\"4.2.4\"},\"end\":49570,\"start\":49551},{\"attributes\":{\"n\":\"4.3\"},\"end\":52344,\"start\":52320},{\"attributes\":{\"n\":\"4.4\"},\"end\":55274,\"start\":55250},{\"attributes\":{\"n\":\"4.5\"},\"end\":56878,\"start\":56858},{\"attributes\":{\"n\":\"5\"},\"end\":58075,\"start\":58063},{\"attributes\":{\"n\":\"6\"},\"end\":62829,\"start\":62806},{\"end\":63722,\"start\":63707},{\"end\":64335,\"start\":64325},{\"end\":64368,\"start\":64358},{\"end\":64435,\"start\":64425},{\"end\":64561,\"start\":64551},{\"end\":64715,\"start\":64705},{\"end\":64801,\"start\":64791},{\"end\":64883,\"start\":64873},{\"end\":64916,\"start\":64906},{\"end\":65518,\"start\":65508},{\"end\":65737,\"start\":65726},{\"end\":65836,\"start\":65825},{\"end\":65986,\"start\":65975},{\"end\":66086,\"start\":66075},{\"end\":66180,\"start\":66169},{\"end\":66318,\"start\":66307},{\"end\":66360,\"start\":66351},{\"end\":66404,\"start\":66395}]", "table": "[{\"end\":66836,\"start\":66535}]", "figure_caption": "[{\"end\":64356,\"start\":64337},{\"end\":64423,\"start\":64370},{\"end\":64455,\"start\":64437},{\"end\":64549,\"start\":64458},{\"end\":64703,\"start\":64563},{\"end\":64789,\"start\":64717},{\"end\":64871,\"start\":64803},{\"end\":64904,\"start\":64885},{\"end\":65054,\"start\":64918},{\"end\":65506,\"start\":65057},{\"end\":65601,\"start\":65520},{\"end\":65724,\"start\":65604},{\"end\":65823,\"start\":65740},{\"end\":65973,\"start\":65839},{\"end\":66073,\"start\":65989},{\"end\":66167,\"start\":66089},{\"end\":66239,\"start\":66183},{\"end\":66305,\"start\":66242},{\"end\":66349,\"start\":66321},{\"end\":66393,\"start\":66362},{\"end\":66535,\"start\":66406}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":4743,\"start\":4735},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":11940,\"start\":11931},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":12094,\"start\":12085},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":12383,\"start\":12374},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":12536,\"start\":12527},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":13872,\"start\":13864},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":17758,\"start\":17750},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":18430,\"start\":18422},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":18896,\"start\":18888},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":21699,\"start\":21690},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":21773,\"start\":21764},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":21829,\"start\":21820},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":29214,\"start\":29206},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":31678,\"start\":31669},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":32304,\"start\":32295},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":40975,\"start\":40967},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":43093,\"start\":43085},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":45575,\"start\":45567},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":47314,\"start\":47306},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":47954,\"start\":47946},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":48347,\"start\":48338},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":48486,\"start\":48475},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":48530,\"start\":48518},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":50178,\"start\":50168},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":50906,\"start\":50896},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":51788,\"start\":51779},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":53154,\"start\":53145},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":54768,\"start\":54760},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":55790,\"start\":55782},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":55917,\"start\":55908},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":57164,\"start\":57154}]", "bib_author_first_name": "[{\"end\":68613,\"start\":68608},{\"end\":68627,\"start\":68620},{\"end\":68639,\"start\":68633},{\"end\":68649,\"start\":68645},{\"end\":68663,\"start\":68658},{\"end\":68927,\"start\":68923},{\"end\":68944,\"start\":68940},{\"end\":68962,\"start\":68954},{\"end\":69310,\"start\":69305},{\"end\":69324,\"start\":69319},{\"end\":69337,\"start\":69332},{\"end\":69349,\"start\":69345},{\"end\":69784,\"start\":69777},{\"end\":69793,\"start\":69792},{\"end\":69833,\"start\":69832},{\"end\":69850,\"start\":69840},{\"end\":69870,\"start\":69860},{\"end\":69872,\"start\":69871},{\"end\":69889,\"start\":69884},{\"end\":69908,\"start\":69902},{\"end\":70406,\"start\":70400},{\"end\":70431,\"start\":70425},{\"end\":70446,\"start\":70438},{\"end\":70458,\"start\":70451},{\"end\":71089,\"start\":71084},{\"end\":71110,\"start\":71106},{\"end\":71127,\"start\":71120},{\"end\":71457,\"start\":71456},{\"end\":71473,\"start\":71469},{\"end\":71475,\"start\":71474},{\"end\":71488,\"start\":71483},{\"end\":71775,\"start\":71771},{\"end\":71786,\"start\":71781},{\"end\":71796,\"start\":71795},{\"end\":71812,\"start\":71805},{\"end\":72294,\"start\":72286},{\"end\":72312,\"start\":72305},{\"end\":72327,\"start\":72320},{\"end\":72342,\"start\":72337},{\"end\":72734,\"start\":72732},{\"end\":72743,\"start\":72741},{\"end\":72757,\"start\":72750},{\"end\":72771,\"start\":72765},{\"end\":73102,\"start\":73099},{\"end\":73113,\"start\":73109},{\"end\":73126,\"start\":73119},{\"end\":73137,\"start\":73134},{\"end\":73146,\"start\":73143},{\"end\":73157,\"start\":73154},{\"end\":73467,\"start\":73464},{\"end\":73483,\"start\":73476},{\"end\":73768,\"start\":73761},{\"end\":73792,\"start\":73786},{\"end\":73809,\"start\":73802},{\"end\":74063,\"start\":74060},{\"end\":74073,\"start\":74070},{\"end\":74087,\"start\":74080},{\"end\":74102,\"start\":74096},{\"end\":74110,\"start\":74107},{\"end\":74117,\"start\":74115},{\"end\":74511,\"start\":74503},{\"end\":74529,\"start\":74524},{\"end\":74543,\"start\":74537},{\"end\":75060,\"start\":75059},{\"end\":75076,\"start\":75075},{\"end\":75101,\"start\":75100},{\"end\":75103,\"start\":75102},{\"end\":75538,\"start\":75534},{\"end\":75550,\"start\":75545},{\"end\":75564,\"start\":75558},{\"end\":75572,\"start\":75570},{\"end\":75584,\"start\":75578},{\"end\":75598,\"start\":75592},{\"end\":75927,\"start\":75924},{\"end\":75946,\"start\":75940},{\"end\":75960,\"start\":75955},{\"end\":75978,\"start\":75972},{\"end\":76208,\"start\":76203},{\"end\":76220,\"start\":76213},{\"end\":76231,\"start\":76227},{\"end\":76246,\"start\":76241},{\"end\":76649,\"start\":76642},{\"end\":76661,\"start\":76654},{\"end\":76677,\"start\":76669},{\"end\":76687,\"start\":76683},{\"end\":77111,\"start\":77110},{\"end\":77131,\"start\":77130},{\"end\":77388,\"start\":77382},{\"end\":77397,\"start\":77393},{\"end\":77412,\"start\":77405},{\"end\":77423,\"start\":77417},{\"end\":77436,\"start\":77430},{\"end\":77753,\"start\":77747},{\"end\":77770,\"start\":77761},{\"end\":78040,\"start\":78034},{\"end\":78055,\"start\":78048},{\"end\":78069,\"start\":78061},{\"end\":78083,\"start\":78076},{\"end\":78093,\"start\":78090},{\"end\":78104,\"start\":78099},{\"end\":78121,\"start\":78111},{\"end\":78137,\"start\":78130},{\"end\":78145,\"start\":78142},{\"end\":78153,\"start\":78151},{\"end\":78693,\"start\":78685},{\"end\":78706,\"start\":78700},{\"end\":78971,\"start\":78961},{\"end\":78992,\"start\":78985},{\"end\":79221,\"start\":79214},{\"end\":79235,\"start\":79231},{\"end\":79509,\"start\":79508},{\"end\":79525,\"start\":79520},{\"end\":79692,\"start\":79691},{\"end\":79706,\"start\":79703},{\"end\":79995,\"start\":79990},{\"end\":80005,\"start\":80004},{\"end\":80018,\"start\":80014},{\"end\":80035,\"start\":80028},{\"end\":80432,\"start\":80427},{\"end\":80445,\"start\":80439},{\"end\":80447,\"start\":80446},{\"end\":80682,\"start\":80678},{\"end\":80693,\"start\":80687},{\"end\":80702,\"start\":80699},{\"end\":81189,\"start\":81184},{\"end\":81198,\"start\":81194},{\"end\":81213,\"start\":81209},{\"end\":81229,\"start\":81223},{\"end\":81250,\"start\":81241},{\"end\":81536,\"start\":81532},{\"end\":81545,\"start\":81542},{\"end\":81550,\"start\":81546},{\"end\":81563,\"start\":81556},{\"end\":81877,\"start\":81873},{\"end\":81892,\"start\":81883},{\"end\":81903,\"start\":81897},{\"end\":81916,\"start\":81909},{\"end\":82781,\"start\":82774},{\"end\":82797,\"start\":82792},{\"end\":82811,\"start\":82805},{\"end\":82825,\"start\":82821},{\"end\":83328,\"start\":83320},{\"end\":83342,\"start\":83335},{\"end\":83657,\"start\":83650},{\"end\":83860,\"start\":83854},{\"end\":83876,\"start\":83872},{\"end\":83897,\"start\":83888},{\"end\":83915,\"start\":83908},{\"end\":83932,\"start\":83924},{\"end\":83949,\"start\":83942},{\"end\":83965,\"start\":83958},{\"end\":83980,\"start\":83975},{\"end\":83998,\"start\":83995},{\"end\":84013,\"start\":84006},{\"end\":84585,\"start\":84578},{\"end\":84601,\"start\":84596},{\"end\":84612,\"start\":84606},{\"end\":84623,\"start\":84619},{\"end\":85143,\"start\":85138},{\"end\":85165,\"start\":85158},{\"end\":85467,\"start\":85461},{\"end\":85478,\"start\":85474},{\"end\":85485,\"start\":85484},{\"end\":85500,\"start\":85492},{\"end\":85511,\"start\":85508},{\"end\":85524,\"start\":85521},{\"end\":86734,\"start\":86726},{\"end\":86747,\"start\":86746},{\"end\":86758,\"start\":86754},{\"end\":86770,\"start\":86766},{\"end\":86772,\"start\":86771},{\"end\":86795,\"start\":86787},{\"end\":87044,\"start\":87039},{\"end\":87061,\"start\":87055},{\"end\":87362,\"start\":87353},{\"end\":87375,\"start\":87372},{\"end\":87389,\"start\":87381},{\"end\":87401,\"start\":87395},{\"end\":87417,\"start\":87412},{\"end\":87432,\"start\":87424},{\"end\":87450,\"start\":87443},{\"end\":87465,\"start\":87458},{\"end\":87483,\"start\":87477},{\"end\":87969,\"start\":87964},{\"end\":87987,\"start\":87979},{\"end\":88005,\"start\":87999},{\"end\":88021,\"start\":88013},{\"end\":88023,\"start\":88022},{\"end\":88301,\"start\":88293},{\"end\":88316,\"start\":88308},{\"end\":88325,\"start\":88322},{\"end\":88337,\"start\":88330},{\"end\":88347,\"start\":88343},{\"end\":88866,\"start\":88860},{\"end\":88882,\"start\":88876},{\"end\":88898,\"start\":88892},{\"end\":89407,\"start\":89404},{\"end\":89420,\"start\":89414},{\"end\":89433,\"start\":89428},{\"end\":89445,\"start\":89440},{\"end\":89457,\"start\":89450},{\"end\":89472,\"start\":89464},{\"end\":89854,\"start\":89850},{\"end\":89866,\"start\":89861},{\"end\":89880,\"start\":89873},{\"end\":89888,\"start\":89886},{\"end\":89902,\"start\":89894},{\"end\":89915,\"start\":89908},{\"end\":89926,\"start\":89920},{\"end\":90321,\"start\":90318},{\"end\":90332,\"start\":90328},{\"end\":90334,\"start\":90333},{\"end\":90348,\"start\":90340},{\"end\":90362,\"start\":90358},{\"end\":90375,\"start\":90369},{\"end\":90852,\"start\":90846},{\"end\":90866,\"start\":90859},{\"end\":90881,\"start\":90873},{\"end\":91137,\"start\":91133},{\"end\":91151,\"start\":91144},{\"end\":91162,\"start\":91156},{\"end\":91164,\"start\":91163},{\"end\":91449,\"start\":91448},{\"end\":91462,\"start\":91461},{\"end\":91464,\"start\":91463},{\"end\":91725,\"start\":91718},{\"end\":91740,\"start\":91731},{\"end\":91747,\"start\":91745},{\"end\":92038,\"start\":92031},{\"end\":92047,\"start\":92044},{\"end\":92057,\"start\":92055},{\"end\":92066,\"start\":92062},{\"end\":92450,\"start\":92446},{\"end\":92461,\"start\":92455},{\"end\":92474,\"start\":92468},{\"end\":92483,\"start\":92481},{\"end\":92772,\"start\":92769},{\"end\":92782,\"start\":92777},{\"end\":92793,\"start\":92790},{\"end\":92807,\"start\":92799},{\"end\":92818,\"start\":92814},{\"end\":93161,\"start\":93154},{\"end\":93178,\"start\":93168},{\"end\":93190,\"start\":93185},{\"end\":93197,\"start\":93191},{\"end\":93568,\"start\":93564},{\"end\":93578,\"start\":93573},{\"end\":93593,\"start\":93585},{\"end\":94023,\"start\":94016},{\"end\":94038,\"start\":94030},{\"end\":94051,\"start\":94043},{\"end\":94074,\"start\":94066},{\"end\":94085,\"start\":94081},{\"end\":94099,\"start\":94092},{\"end\":94114,\"start\":94110},{\"end\":94561,\"start\":94554},{\"end\":94576,\"start\":94568},{\"end\":94587,\"start\":94583},{\"end\":94602,\"start\":94594},{\"end\":94625,\"start\":94617},{\"end\":94635,\"start\":94630},{\"end\":94652,\"start\":94645},{\"end\":94666,\"start\":94662},{\"end\":94682,\"start\":94675},{\"end\":95226,\"start\":95219},{\"end\":95240,\"start\":95233},{\"end\":95250,\"start\":95246},{\"end\":95264,\"start\":95259},{\"end\":95266,\"start\":95265},{\"end\":95281,\"start\":95277},{\"end\":95283,\"start\":95282},{\"end\":95638,\"start\":95635},{\"end\":95648,\"start\":95646},{\"end\":95659,\"start\":95656},{\"end\":95673,\"start\":95666},{\"end\":95687,\"start\":95681},{\"end\":95700,\"start\":95693},{\"end\":95710,\"start\":95705},{\"end\":96249,\"start\":96247},{\"end\":96264,\"start\":96256},{\"end\":96279,\"start\":96271},{\"end\":96292,\"start\":96285},{\"end\":96304,\"start\":96299},{\"end\":96702,\"start\":96700},{\"end\":96711,\"start\":96709},{\"end\":96724,\"start\":96718},{\"end\":96733,\"start\":96725},{\"end\":96742,\"start\":96739},{\"end\":96758,\"start\":96750},{\"end\":96774,\"start\":96769},{\"end\":96787,\"start\":96780}]", "bib_author_last_name": "[{\"end\":68618,\"start\":68614},{\"end\":68631,\"start\":68628},{\"end\":68643,\"start\":68640},{\"end\":68656,\"start\":68650},{\"end\":68670,\"start\":68664},{\"end\":68938,\"start\":68928},{\"end\":68952,\"start\":68945},{\"end\":68969,\"start\":68963},{\"end\":68977,\"start\":68971},{\"end\":69317,\"start\":69311},{\"end\":69330,\"start\":69325},{\"end\":69343,\"start\":69338},{\"end\":69355,\"start\":69350},{\"end\":69790,\"start\":69785},{\"end\":69799,\"start\":69794},{\"end\":69810,\"start\":69801},{\"end\":69830,\"start\":69812},{\"end\":69838,\"start\":69834},{\"end\":69858,\"start\":69851},{\"end\":69882,\"start\":69873},{\"end\":69900,\"start\":69890},{\"end\":69913,\"start\":69909},{\"end\":69922,\"start\":69915},{\"end\":69933,\"start\":69924},{\"end\":70423,\"start\":70407},{\"end\":70436,\"start\":70432},{\"end\":70449,\"start\":70447},{\"end\":70465,\"start\":70459},{\"end\":71104,\"start\":71090},{\"end\":71118,\"start\":71111},{\"end\":71135,\"start\":71128},{\"end\":71467,\"start\":71458},{\"end\":71481,\"start\":71476},{\"end\":71496,\"start\":71489},{\"end\":71501,\"start\":71498},{\"end\":71779,\"start\":71776},{\"end\":71793,\"start\":71787},{\"end\":71803,\"start\":71797},{\"end\":71820,\"start\":71813},{\"end\":71829,\"start\":71822},{\"end\":72303,\"start\":72295},{\"end\":72318,\"start\":72313},{\"end\":72335,\"start\":72328},{\"end\":72348,\"start\":72343},{\"end\":72739,\"start\":72735},{\"end\":72748,\"start\":72744},{\"end\":72763,\"start\":72758},{\"end\":72775,\"start\":72772},{\"end\":73107,\"start\":73103},{\"end\":73117,\"start\":73114},{\"end\":73132,\"start\":73127},{\"end\":73141,\"start\":73138},{\"end\":73152,\"start\":73147},{\"end\":73162,\"start\":73158},{\"end\":73474,\"start\":73468},{\"end\":73489,\"start\":73484},{\"end\":73497,\"start\":73491},{\"end\":73784,\"start\":73769},{\"end\":73800,\"start\":73793},{\"end\":73818,\"start\":73810},{\"end\":73826,\"start\":73820},{\"end\":74068,\"start\":74064},{\"end\":74078,\"start\":74074},{\"end\":74094,\"start\":74088},{\"end\":74105,\"start\":74103},{\"end\":74113,\"start\":74111},{\"end\":74125,\"start\":74118},{\"end\":74522,\"start\":74512},{\"end\":74535,\"start\":74530},{\"end\":74549,\"start\":74544},{\"end\":74845,\"start\":74835},{\"end\":75065,\"start\":75061},{\"end\":75073,\"start\":75067},{\"end\":75085,\"start\":75077},{\"end\":75098,\"start\":75087},{\"end\":75109,\"start\":75104},{\"end\":75120,\"start\":75111},{\"end\":75128,\"start\":75122},{\"end\":75137,\"start\":75130},{\"end\":75543,\"start\":75539},{\"end\":75556,\"start\":75551},{\"end\":75568,\"start\":75565},{\"end\":75576,\"start\":75573},{\"end\":75590,\"start\":75585},{\"end\":75602,\"start\":75599},{\"end\":75938,\"start\":75928},{\"end\":75953,\"start\":75947},{\"end\":75970,\"start\":75961},{\"end\":75985,\"start\":75979},{\"end\":76211,\"start\":76209},{\"end\":76225,\"start\":76221},{\"end\":76239,\"start\":76232},{\"end\":76251,\"start\":76247},{\"end\":76652,\"start\":76650},{\"end\":76667,\"start\":76662},{\"end\":76681,\"start\":76678},{\"end\":76691,\"start\":76688},{\"end\":77120,\"start\":77112},{\"end\":77128,\"start\":77122},{\"end\":77138,\"start\":77132},{\"end\":77153,\"start\":77140},{\"end\":77391,\"start\":77389},{\"end\":77403,\"start\":77398},{\"end\":77415,\"start\":77413},{\"end\":77428,\"start\":77424},{\"end\":77440,\"start\":77437},{\"end\":77759,\"start\":77754},{\"end\":77778,\"start\":77771},{\"end\":78046,\"start\":78041},{\"end\":78059,\"start\":78056},{\"end\":78074,\"start\":78070},{\"end\":78088,\"start\":78084},{\"end\":78097,\"start\":78094},{\"end\":78109,\"start\":78105},{\"end\":78128,\"start\":78122},{\"end\":78140,\"start\":78138},{\"end\":78149,\"start\":78146},{\"end\":78156,\"start\":78154},{\"end\":78698,\"start\":78694},{\"end\":78711,\"start\":78707},{\"end\":78983,\"start\":78972},{\"end\":78996,\"start\":78993},{\"end\":79229,\"start\":79222},{\"end\":79245,\"start\":79236},{\"end\":79253,\"start\":79247},{\"end\":79518,\"start\":79510},{\"end\":79532,\"start\":79526},{\"end\":79536,\"start\":79534},{\"end\":79701,\"start\":79693},{\"end\":79713,\"start\":79707},{\"end\":79722,\"start\":79715},{\"end\":80002,\"start\":79996},{\"end\":80012,\"start\":80006},{\"end\":80026,\"start\":80019},{\"end\":80039,\"start\":80036},{\"end\":80048,\"start\":80041},{\"end\":80437,\"start\":80433},{\"end\":80454,\"start\":80448},{\"end\":80685,\"start\":80683},{\"end\":80697,\"start\":80694},{\"end\":80720,\"start\":80703},{\"end\":80727,\"start\":80722},{\"end\":81192,\"start\":81190},{\"end\":81207,\"start\":81199},{\"end\":81221,\"start\":81214},{\"end\":81239,\"start\":81230},{\"end\":81261,\"start\":81251},{\"end\":81540,\"start\":81537},{\"end\":81554,\"start\":81551},{\"end\":81568,\"start\":81564},{\"end\":81574,\"start\":81570},{\"end\":81881,\"start\":81878},{\"end\":81895,\"start\":81893},{\"end\":81907,\"start\":81904},{\"end\":81919,\"start\":81917},{\"end\":82790,\"start\":82782},{\"end\":82803,\"start\":82798},{\"end\":82819,\"start\":82812},{\"end\":82831,\"start\":82826},{\"end\":83333,\"start\":83329},{\"end\":83347,\"start\":83343},{\"end\":83664,\"start\":83658},{\"end\":83870,\"start\":83861},{\"end\":83886,\"start\":83877},{\"end\":83906,\"start\":83898},{\"end\":83922,\"start\":83916},{\"end\":83940,\"start\":83933},{\"end\":83956,\"start\":83950},{\"end\":83973,\"start\":83966},{\"end\":83993,\"start\":83981},{\"end\":84004,\"start\":83999},{\"end\":84021,\"start\":84014},{\"end\":84594,\"start\":84586},{\"end\":84604,\"start\":84602},{\"end\":84617,\"start\":84613},{\"end\":84627,\"start\":84624},{\"end\":84637,\"start\":84629},{\"end\":85156,\"start\":85144},{\"end\":85175,\"start\":85166},{\"end\":85472,\"start\":85468},{\"end\":85482,\"start\":85479},{\"end\":85490,\"start\":85486},{\"end\":85506,\"start\":85501},{\"end\":85519,\"start\":85512},{\"end\":85527,\"start\":85525},{\"end\":85531,\"start\":85529},{\"end\":86490,\"start\":86469},{\"end\":86744,\"start\":86735},{\"end\":86752,\"start\":86748},{\"end\":86764,\"start\":86759},{\"end\":86785,\"start\":86773},{\"end\":86801,\"start\":86796},{\"end\":86813,\"start\":86803},{\"end\":87053,\"start\":87045},{\"end\":87071,\"start\":87062},{\"end\":87370,\"start\":87363},{\"end\":87379,\"start\":87376},{\"end\":87393,\"start\":87390},{\"end\":87410,\"start\":87402},{\"end\":87422,\"start\":87418},{\"end\":87441,\"start\":87433},{\"end\":87456,\"start\":87451},{\"end\":87475,\"start\":87466},{\"end\":87494,\"start\":87484},{\"end\":87977,\"start\":87970},{\"end\":87997,\"start\":87988},{\"end\":88011,\"start\":88006},{\"end\":88028,\"start\":88024},{\"end\":88306,\"start\":88302},{\"end\":88320,\"start\":88317},{\"end\":88328,\"start\":88326},{\"end\":88341,\"start\":88338},{\"end\":88354,\"start\":88348},{\"end\":88874,\"start\":88867},{\"end\":88890,\"start\":88883},{\"end\":88908,\"start\":88899},{\"end\":89412,\"start\":89408},{\"end\":89426,\"start\":89421},{\"end\":89438,\"start\":89434},{\"end\":89448,\"start\":89446},{\"end\":89462,\"start\":89458},{\"end\":89475,\"start\":89473},{\"end\":89859,\"start\":89855},{\"end\":89871,\"start\":89867},{\"end\":89884,\"start\":89881},{\"end\":89892,\"start\":89889},{\"end\":89906,\"start\":89903},{\"end\":89918,\"start\":89916},{\"end\":89932,\"start\":89927},{\"end\":90326,\"start\":90322},{\"end\":90338,\"start\":90335},{\"end\":90356,\"start\":90349},{\"end\":90367,\"start\":90363},{\"end\":90378,\"start\":90376},{\"end\":90857,\"start\":90853},{\"end\":90871,\"start\":90867},{\"end\":90887,\"start\":90882},{\"end\":91142,\"start\":91138},{\"end\":91154,\"start\":91152},{\"end\":91167,\"start\":91165},{\"end\":91459,\"start\":91450},{\"end\":91470,\"start\":91465},{\"end\":91477,\"start\":91472},{\"end\":91729,\"start\":91726},{\"end\":91743,\"start\":91741},{\"end\":91750,\"start\":91748},{\"end\":92042,\"start\":92039},{\"end\":92053,\"start\":92048},{\"end\":92060,\"start\":92058},{\"end\":92075,\"start\":92067},{\"end\":92453,\"start\":92451},{\"end\":92466,\"start\":92462},{\"end\":92479,\"start\":92475},{\"end\":92486,\"start\":92484},{\"end\":92775,\"start\":92773},{\"end\":92788,\"start\":92783},{\"end\":92797,\"start\":92794},{\"end\":92812,\"start\":92808},{\"end\":92823,\"start\":92819},{\"end\":93166,\"start\":93162},{\"end\":93183,\"start\":93179},{\"end\":93205,\"start\":93198},{\"end\":93571,\"start\":93569},{\"end\":93583,\"start\":93579},{\"end\":93601,\"start\":93594},{\"end\":94028,\"start\":94024},{\"end\":94041,\"start\":94039},{\"end\":94064,\"start\":94052},{\"end\":94079,\"start\":94075},{\"end\":94090,\"start\":94086},{\"end\":94108,\"start\":94100},{\"end\":94121,\"start\":94115},{\"end\":94566,\"start\":94562},{\"end\":94581,\"start\":94577},{\"end\":94592,\"start\":94588},{\"end\":94615,\"start\":94603},{\"end\":94628,\"start\":94626},{\"end\":94643,\"start\":94636},{\"end\":94660,\"start\":94653},{\"end\":94673,\"start\":94667},{\"end\":94691,\"start\":94683},{\"end\":95231,\"start\":95227},{\"end\":95244,\"start\":95241},{\"end\":95257,\"start\":95251},{\"end\":95275,\"start\":95267},{\"end\":95291,\"start\":95284},{\"end\":95644,\"start\":95639},{\"end\":95654,\"start\":95649},{\"end\":95664,\"start\":95660},{\"end\":95679,\"start\":95674},{\"end\":95691,\"start\":95688},{\"end\":95703,\"start\":95701},{\"end\":95715,\"start\":95711},{\"end\":96254,\"start\":96250},{\"end\":96269,\"start\":96265},{\"end\":96283,\"start\":96280},{\"end\":96297,\"start\":96293},{\"end\":96308,\"start\":96305},{\"end\":96707,\"start\":96703},{\"end\":96716,\"start\":96712},{\"end\":96737,\"start\":96734},{\"end\":96748,\"start\":96743},{\"end\":96767,\"start\":96759},{\"end\":96778,\"start\":96775},{\"end\":96792,\"start\":96788}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":4535542},\"end\":68881,\"start\":68565},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":2467259},\"end\":69252,\"start\":68883},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":9292624},\"end\":69654,\"start\":69254},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":235391885},\"end\":70265,\"start\":69656},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":218537514},\"end\":70936,\"start\":70267},{\"attributes\":{\"id\":\"b5\"},\"end\":71374,\"start\":70938},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":46825937},\"end\":71714,\"start\":71376},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":228082261},\"end\":72213,\"start\":71716},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":43478987},\"end\":72644,\"start\":72215},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":221667549},\"end\":73010,\"start\":72646},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":234920502},\"end\":73411,\"start\":73012},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":5295609},\"end\":73702,\"start\":73413},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":10016549},\"end\":74005,\"start\":73704},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":57246310},\"end\":74408,\"start\":74007},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":251858454},\"end\":74794,\"start\":74410},{\"attributes\":{\"id\":\"b15\"},\"end\":74968,\"start\":74796},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":46845592},\"end\":75484,\"start\":74970},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":236318059},\"end\":75920,\"start\":75486},{\"attributes\":{\"id\":\"b18\"},\"end\":76138,\"start\":75922},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":215540880},\"end\":76547,\"start\":76140},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":13740328},\"end\":77050,\"start\":76549},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":262637400},\"end\":77313,\"start\":77052},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":244342421},\"end\":77651,\"start\":77315},{\"attributes\":{\"doi\":\"arXiv:1502.03167\",\"id\":\"b23\"},\"end\":77985,\"start\":77653},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":214796512},\"end\":78606,\"start\":77987},{\"attributes\":{\"id\":\"b25\"},\"end\":78917,\"start\":78608},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":206980261},\"end\":79144,\"start\":78919},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":5627005},\"end\":79462,\"start\":79146},{\"attributes\":{\"doi\":\"arXiv:1412.6980\",\"id\":\"b28\"},\"end\":79689,\"start\":79464},{\"attributes\":{\"doi\":\"arXiv:1312.6114\",\"id\":\"b29\"},\"end\":79898,\"start\":79691},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":203691615},\"end\":80373,\"start\":79900},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":19629847},\"end\":80586,\"start\":80375},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":227154362},\"end\":81093,\"start\":80588},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":208845734},\"end\":81512,\"start\":81095},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":6505449},\"end\":81779,\"start\":81514},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":189926753},\"end\":82374,\"start\":81781},{\"attributes\":{\"id\":\"b36\"},\"end\":82705,\"start\":82376},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":4063197},\"end\":83225,\"start\":82707},{\"attributes\":{\"id\":\"b38\"},\"end\":83551,\"start\":83227},{\"attributes\":{\"id\":\"b39\"},\"end\":83810,\"start\":83553},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":10659969},\"end\":84350,\"start\":83812},{\"attributes\":{\"id\":\"b41\"},\"end\":84490,\"start\":84352},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":3988414},\"end\":85072,\"start\":84492},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":210957267},\"end\":85368,\"start\":85074},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":1266091},\"end\":86386,\"start\":85370},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":9688078},\"end\":86665,\"start\":86388},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":2110475},\"end\":87037,\"start\":86667},{\"attributes\":{\"doi\":\"arXiv:1409.1556\",\"id\":\"b47\"},\"end\":87319,\"start\":87039},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":206592484},\"end\":87908,\"start\":87321},{\"attributes\":{\"doi\":\"arXiv:1910.04341\",\"id\":\"b49\"},\"end\":88229,\"start\":87910},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":52295205},\"end\":88747,\"start\":88231},{\"attributes\":{\"id\":\"b51\",\"matched_paper_id\":5917270},\"end\":89314,\"start\":88749},{\"attributes\":{\"id\":\"b52\",\"matched_paper_id\":1153012},\"end\":89749,\"start\":89316},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":202775174},\"end\":90240,\"start\":89751},{\"attributes\":{\"id\":\"b54\",\"matched_paper_id\":7644967},\"end\":90796,\"start\":90242},{\"attributes\":{\"id\":\"b55\",\"matched_paper_id\":214636908},\"end\":91074,\"start\":90798},{\"attributes\":{\"id\":\"b56\",\"matched_paper_id\":10821451},\"end\":91374,\"start\":91076},{\"attributes\":{\"id\":\"b57\",\"matched_paper_id\":73106215},\"end\":91664,\"start\":91376},{\"attributes\":{\"id\":\"b58\",\"matched_paper_id\":9786871},\"end\":91952,\"start\":91666},{\"attributes\":{\"id\":\"b59\",\"matched_paper_id\":53684845},\"end\":92372,\"start\":91954},{\"attributes\":{\"doi\":\"arXiv:1505.00853\",\"id\":\"b60\"},\"end\":92681,\"start\":92374},{\"attributes\":{\"doi\":\"arXiv:1510.01553\",\"id\":\"b61\"},\"end\":93046,\"start\":92683},{\"attributes\":{\"id\":\"b62\",\"matched_paper_id\":14514734},\"end\":93490,\"start\":93048},{\"attributes\":{\"id\":\"b63\",\"matched_paper_id\":13723046},\"end\":93958,\"start\":93492},{\"attributes\":{\"id\":\"b64\",\"matched_paper_id\":47020925},\"end\":94529,\"start\":93960},{\"attributes\":{\"id\":\"b65\",\"matched_paper_id\":51927460},\"end\":95135,\"start\":94531},{\"attributes\":{\"doi\":\"PMLR\",\"id\":\"b66\",\"matched_paper_id\":8137251},\"end\":95576,\"start\":95137},{\"attributes\":{\"id\":\"b67\",\"matched_paper_id\":189926759},\"end\":96169,\"start\":95578},{\"attributes\":{\"id\":\"b68\",\"matched_paper_id\":54443772},\"end\":96621,\"start\":96171},{\"attributes\":{\"id\":\"b69\",\"matched_paper_id\":51805340},\"end\":97087,\"start\":96623}]", "bib_title": "[{\"end\":68606,\"start\":68565},{\"end\":68921,\"start\":68883},{\"end\":69303,\"start\":69254},{\"end\":69775,\"start\":69656},{\"end\":70398,\"start\":70267},{\"end\":71454,\"start\":71376},{\"end\":71769,\"start\":71716},{\"end\":72284,\"start\":72215},{\"end\":72730,\"start\":72646},{\"end\":73097,\"start\":73012},{\"end\":73462,\"start\":73413},{\"end\":73759,\"start\":73704},{\"end\":74058,\"start\":74007},{\"end\":74501,\"start\":74410},{\"end\":74833,\"start\":74796},{\"end\":75057,\"start\":74970},{\"end\":75532,\"start\":75486},{\"end\":76201,\"start\":76140},{\"end\":76640,\"start\":76549},{\"end\":77108,\"start\":77052},{\"end\":77380,\"start\":77315},{\"end\":78032,\"start\":77987},{\"end\":78959,\"start\":78919},{\"end\":79212,\"start\":79146},{\"end\":79988,\"start\":79900},{\"end\":80425,\"start\":80375},{\"end\":80676,\"start\":80588},{\"end\":81182,\"start\":81095},{\"end\":81530,\"start\":81514},{\"end\":81871,\"start\":81781},{\"end\":82772,\"start\":82707},{\"end\":83318,\"start\":83227},{\"end\":83852,\"start\":83812},{\"end\":84576,\"start\":84492},{\"end\":85136,\"start\":85074},{\"end\":85459,\"start\":85370},{\"end\":86467,\"start\":86388},{\"end\":86724,\"start\":86667},{\"end\":87351,\"start\":87321},{\"end\":88291,\"start\":88231},{\"end\":88858,\"start\":88749},{\"end\":89402,\"start\":89316},{\"end\":89848,\"start\":89751},{\"end\":90316,\"start\":90242},{\"end\":90844,\"start\":90798},{\"end\":91131,\"start\":91076},{\"end\":91446,\"start\":91376},{\"end\":91716,\"start\":91666},{\"end\":92029,\"start\":91954},{\"end\":93152,\"start\":93048},{\"end\":93562,\"start\":93492},{\"end\":94014,\"start\":93960},{\"end\":94552,\"start\":94531},{\"end\":95217,\"start\":95137},{\"end\":95633,\"start\":95578},{\"end\":96245,\"start\":96171},{\"end\":96698,\"start\":96623}]", "bib_author": "[{\"end\":68620,\"start\":68608},{\"end\":68633,\"start\":68620},{\"end\":68645,\"start\":68633},{\"end\":68658,\"start\":68645},{\"end\":68672,\"start\":68658},{\"end\":68940,\"start\":68923},{\"end\":68954,\"start\":68940},{\"end\":68971,\"start\":68954},{\"end\":68979,\"start\":68971},{\"end\":69319,\"start\":69305},{\"end\":69332,\"start\":69319},{\"end\":69345,\"start\":69332},{\"end\":69357,\"start\":69345},{\"end\":69792,\"start\":69777},{\"end\":69801,\"start\":69792},{\"end\":69812,\"start\":69801},{\"end\":69832,\"start\":69812},{\"end\":69840,\"start\":69832},{\"end\":69860,\"start\":69840},{\"end\":69884,\"start\":69860},{\"end\":69902,\"start\":69884},{\"end\":69915,\"start\":69902},{\"end\":69924,\"start\":69915},{\"end\":69935,\"start\":69924},{\"end\":70425,\"start\":70400},{\"end\":70438,\"start\":70425},{\"end\":70451,\"start\":70438},{\"end\":70467,\"start\":70451},{\"end\":71106,\"start\":71084},{\"end\":71120,\"start\":71106},{\"end\":71137,\"start\":71120},{\"end\":71469,\"start\":71456},{\"end\":71483,\"start\":71469},{\"end\":71498,\"start\":71483},{\"end\":71503,\"start\":71498},{\"end\":71781,\"start\":71771},{\"end\":71795,\"start\":71781},{\"end\":71805,\"start\":71795},{\"end\":71822,\"start\":71805},{\"end\":71831,\"start\":71822},{\"end\":72305,\"start\":72286},{\"end\":72320,\"start\":72305},{\"end\":72337,\"start\":72320},{\"end\":72350,\"start\":72337},{\"end\":72741,\"start\":72732},{\"end\":72750,\"start\":72741},{\"end\":72765,\"start\":72750},{\"end\":72777,\"start\":72765},{\"end\":73109,\"start\":73099},{\"end\":73119,\"start\":73109},{\"end\":73134,\"start\":73119},{\"end\":73143,\"start\":73134},{\"end\":73154,\"start\":73143},{\"end\":73164,\"start\":73154},{\"end\":73476,\"start\":73464},{\"end\":73491,\"start\":73476},{\"end\":73499,\"start\":73491},{\"end\":73786,\"start\":73761},{\"end\":73802,\"start\":73786},{\"end\":73820,\"start\":73802},{\"end\":73828,\"start\":73820},{\"end\":74070,\"start\":74060},{\"end\":74080,\"start\":74070},{\"end\":74096,\"start\":74080},{\"end\":74107,\"start\":74096},{\"end\":74115,\"start\":74107},{\"end\":74127,\"start\":74115},{\"end\":74524,\"start\":74503},{\"end\":74537,\"start\":74524},{\"end\":74551,\"start\":74537},{\"end\":74847,\"start\":74835},{\"end\":75067,\"start\":75059},{\"end\":75075,\"start\":75067},{\"end\":75087,\"start\":75075},{\"end\":75100,\"start\":75087},{\"end\":75111,\"start\":75100},{\"end\":75122,\"start\":75111},{\"end\":75130,\"start\":75122},{\"end\":75139,\"start\":75130},{\"end\":75545,\"start\":75534},{\"end\":75558,\"start\":75545},{\"end\":75570,\"start\":75558},{\"end\":75578,\"start\":75570},{\"end\":75592,\"start\":75578},{\"end\":75604,\"start\":75592},{\"end\":75940,\"start\":75924},{\"end\":75955,\"start\":75940},{\"end\":75972,\"start\":75955},{\"end\":75987,\"start\":75972},{\"end\":76213,\"start\":76203},{\"end\":76227,\"start\":76213},{\"end\":76241,\"start\":76227},{\"end\":76253,\"start\":76241},{\"end\":76654,\"start\":76642},{\"end\":76669,\"start\":76654},{\"end\":76683,\"start\":76669},{\"end\":76693,\"start\":76683},{\"end\":77122,\"start\":77110},{\"end\":77130,\"start\":77122},{\"end\":77140,\"start\":77130},{\"end\":77155,\"start\":77140},{\"end\":77393,\"start\":77382},{\"end\":77405,\"start\":77393},{\"end\":77417,\"start\":77405},{\"end\":77430,\"start\":77417},{\"end\":77442,\"start\":77430},{\"end\":77761,\"start\":77747},{\"end\":77780,\"start\":77761},{\"end\":78048,\"start\":78034},{\"end\":78061,\"start\":78048},{\"end\":78076,\"start\":78061},{\"end\":78090,\"start\":78076},{\"end\":78099,\"start\":78090},{\"end\":78111,\"start\":78099},{\"end\":78130,\"start\":78111},{\"end\":78142,\"start\":78130},{\"end\":78151,\"start\":78142},{\"end\":78158,\"start\":78151},{\"end\":78700,\"start\":78685},{\"end\":78713,\"start\":78700},{\"end\":78985,\"start\":78961},{\"end\":78998,\"start\":78985},{\"end\":79231,\"start\":79214},{\"end\":79247,\"start\":79231},{\"end\":79255,\"start\":79247},{\"end\":79520,\"start\":79508},{\"end\":79534,\"start\":79520},{\"end\":79538,\"start\":79534},{\"end\":79703,\"start\":79691},{\"end\":79715,\"start\":79703},{\"end\":79724,\"start\":79715},{\"end\":80004,\"start\":79990},{\"end\":80014,\"start\":80004},{\"end\":80028,\"start\":80014},{\"end\":80041,\"start\":80028},{\"end\":80050,\"start\":80041},{\"end\":80439,\"start\":80427},{\"end\":80456,\"start\":80439},{\"end\":80687,\"start\":80678},{\"end\":80699,\"start\":80687},{\"end\":80722,\"start\":80699},{\"end\":80729,\"start\":80722},{\"end\":81194,\"start\":81184},{\"end\":81209,\"start\":81194},{\"end\":81223,\"start\":81209},{\"end\":81241,\"start\":81223},{\"end\":81263,\"start\":81241},{\"end\":81542,\"start\":81532},{\"end\":81556,\"start\":81542},{\"end\":81570,\"start\":81556},{\"end\":81576,\"start\":81570},{\"end\":81883,\"start\":81873},{\"end\":81897,\"start\":81883},{\"end\":81909,\"start\":81897},{\"end\":81921,\"start\":81909},{\"end\":82792,\"start\":82774},{\"end\":82805,\"start\":82792},{\"end\":82821,\"start\":82805},{\"end\":82833,\"start\":82821},{\"end\":83335,\"start\":83320},{\"end\":83349,\"start\":83335},{\"end\":83666,\"start\":83650},{\"end\":83872,\"start\":83854},{\"end\":83888,\"start\":83872},{\"end\":83908,\"start\":83888},{\"end\":83924,\"start\":83908},{\"end\":83942,\"start\":83924},{\"end\":83958,\"start\":83942},{\"end\":83975,\"start\":83958},{\"end\":83995,\"start\":83975},{\"end\":84006,\"start\":83995},{\"end\":84023,\"start\":84006},{\"end\":84596,\"start\":84578},{\"end\":84606,\"start\":84596},{\"end\":84619,\"start\":84606},{\"end\":84629,\"start\":84619},{\"end\":84639,\"start\":84629},{\"end\":85158,\"start\":85138},{\"end\":85177,\"start\":85158},{\"end\":85474,\"start\":85461},{\"end\":85484,\"start\":85474},{\"end\":85492,\"start\":85484},{\"end\":85508,\"start\":85492},{\"end\":85521,\"start\":85508},{\"end\":85529,\"start\":85521},{\"end\":85533,\"start\":85529},{\"end\":86492,\"start\":86469},{\"end\":86746,\"start\":86726},{\"end\":86754,\"start\":86746},{\"end\":86766,\"start\":86754},{\"end\":86787,\"start\":86766},{\"end\":86803,\"start\":86787},{\"end\":86815,\"start\":86803},{\"end\":87055,\"start\":87039},{\"end\":87073,\"start\":87055},{\"end\":87372,\"start\":87353},{\"end\":87381,\"start\":87372},{\"end\":87395,\"start\":87381},{\"end\":87412,\"start\":87395},{\"end\":87424,\"start\":87412},{\"end\":87443,\"start\":87424},{\"end\":87458,\"start\":87443},{\"end\":87477,\"start\":87458},{\"end\":87496,\"start\":87477},{\"end\":87979,\"start\":87964},{\"end\":87999,\"start\":87979},{\"end\":88013,\"start\":87999},{\"end\":88030,\"start\":88013},{\"end\":88308,\"start\":88293},{\"end\":88322,\"start\":88308},{\"end\":88330,\"start\":88322},{\"end\":88343,\"start\":88330},{\"end\":88356,\"start\":88343},{\"end\":88876,\"start\":88860},{\"end\":88892,\"start\":88876},{\"end\":88910,\"start\":88892},{\"end\":89414,\"start\":89404},{\"end\":89428,\"start\":89414},{\"end\":89440,\"start\":89428},{\"end\":89450,\"start\":89440},{\"end\":89464,\"start\":89450},{\"end\":89477,\"start\":89464},{\"end\":89861,\"start\":89850},{\"end\":89873,\"start\":89861},{\"end\":89886,\"start\":89873},{\"end\":89894,\"start\":89886},{\"end\":89908,\"start\":89894},{\"end\":89920,\"start\":89908},{\"end\":89934,\"start\":89920},{\"end\":90328,\"start\":90318},{\"end\":90340,\"start\":90328},{\"end\":90358,\"start\":90340},{\"end\":90369,\"start\":90358},{\"end\":90380,\"start\":90369},{\"end\":90859,\"start\":90846},{\"end\":90873,\"start\":90859},{\"end\":90889,\"start\":90873},{\"end\":91144,\"start\":91133},{\"end\":91156,\"start\":91144},{\"end\":91169,\"start\":91156},{\"end\":91461,\"start\":91448},{\"end\":91472,\"start\":91461},{\"end\":91479,\"start\":91472},{\"end\":91731,\"start\":91718},{\"end\":91745,\"start\":91731},{\"end\":91752,\"start\":91745},{\"end\":92044,\"start\":92031},{\"end\":92055,\"start\":92044},{\"end\":92062,\"start\":92055},{\"end\":92077,\"start\":92062},{\"end\":92455,\"start\":92446},{\"end\":92468,\"start\":92455},{\"end\":92481,\"start\":92468},{\"end\":92488,\"start\":92481},{\"end\":92777,\"start\":92769},{\"end\":92790,\"start\":92777},{\"end\":92799,\"start\":92790},{\"end\":92814,\"start\":92799},{\"end\":92825,\"start\":92814},{\"end\":93168,\"start\":93154},{\"end\":93185,\"start\":93168},{\"end\":93207,\"start\":93185},{\"end\":93573,\"start\":93564},{\"end\":93585,\"start\":93573},{\"end\":93603,\"start\":93585},{\"end\":94030,\"start\":94016},{\"end\":94043,\"start\":94030},{\"end\":94066,\"start\":94043},{\"end\":94081,\"start\":94066},{\"end\":94092,\"start\":94081},{\"end\":94110,\"start\":94092},{\"end\":94123,\"start\":94110},{\"end\":94568,\"start\":94554},{\"end\":94583,\"start\":94568},{\"end\":94594,\"start\":94583},{\"end\":94617,\"start\":94594},{\"end\":94630,\"start\":94617},{\"end\":94645,\"start\":94630},{\"end\":94662,\"start\":94645},{\"end\":94675,\"start\":94662},{\"end\":94693,\"start\":94675},{\"end\":95233,\"start\":95219},{\"end\":95246,\"start\":95233},{\"end\":95259,\"start\":95246},{\"end\":95277,\"start\":95259},{\"end\":95293,\"start\":95277},{\"end\":95646,\"start\":95635},{\"end\":95656,\"start\":95646},{\"end\":95666,\"start\":95656},{\"end\":95681,\"start\":95666},{\"end\":95693,\"start\":95681},{\"end\":95705,\"start\":95693},{\"end\":95717,\"start\":95705},{\"end\":96256,\"start\":96247},{\"end\":96271,\"start\":96256},{\"end\":96285,\"start\":96271},{\"end\":96299,\"start\":96285},{\"end\":96310,\"start\":96299},{\"end\":96709,\"start\":96700},{\"end\":96718,\"start\":96709},{\"end\":96739,\"start\":96718},{\"end\":96750,\"start\":96739},{\"end\":96769,\"start\":96750},{\"end\":96780,\"start\":96769},{\"end\":96794,\"start\":96780}]", "bib_venue": "[{\"end\":68706,\"start\":68672},{\"end\":69049,\"start\":68979},{\"end\":69440,\"start\":69357},{\"end\":69941,\"start\":69935},{\"end\":70557,\"start\":70467},{\"end\":71082,\"start\":70938},{\"end\":71529,\"start\":71503},{\"end\":71914,\"start\":71831},{\"end\":72407,\"start\":72350},{\"end\":72811,\"start\":72777},{\"end\":73201,\"start\":73164},{\"end\":73539,\"start\":73499},{\"end\":73835,\"start\":73828},{\"end\":74190,\"start\":74127},{\"end\":74584,\"start\":74551},{\"end\":74874,\"start\":74847},{\"end\":75214,\"start\":75139},{\"end\":75687,\"start\":75604},{\"end\":76000,\"start\":75987},{\"end\":76323,\"start\":76253},{\"end\":76760,\"start\":76693},{\"end\":77162,\"start\":77155},{\"end\":77473,\"start\":77442},{\"end\":77745,\"start\":77653},{\"end\":78248,\"start\":78158},{\"end\":78683,\"start\":78608},{\"end\":79015,\"start\":78998},{\"end\":79278,\"start\":79255},{\"end\":79506,\"start\":79464},{\"end\":79770,\"start\":79739},{\"end\":80125,\"start\":80050},{\"end\":80460,\"start\":80456},{\"end\":80800,\"start\":80729},{\"end\":81283,\"start\":81263},{\"end\":81627,\"start\":81576},{\"end\":82022,\"start\":81921},{\"end\":82458,\"start\":82376},{\"end\":82916,\"start\":82833},{\"end\":83377,\"start\":83349},{\"end\":83648,\"start\":83553},{\"end\":84059,\"start\":84023},{\"end\":84391,\"start\":84352},{\"end\":84732,\"start\":84639},{\"end\":85206,\"start\":85177},{\"end\":85760,\"start\":85533},{\"end\":86506,\"start\":86492},{\"end\":86833,\"start\":86815},{\"end\":87154,\"start\":87088},{\"end\":87573,\"start\":87496},{\"end\":87962,\"start\":87910},{\"end\":88439,\"start\":88356},{\"end\":88987,\"start\":88910},{\"end\":89514,\"start\":89477},{\"end\":89983,\"start\":89934},{\"end\":90470,\"start\":90380},{\"end\":90926,\"start\":90889},{\"end\":91206,\"start\":91169},{\"end\":91501,\"start\":91479},{\"end\":91789,\"start\":91752},{\"end\":92152,\"start\":92077},{\"end\":92444,\"start\":92374},{\"end\":92767,\"start\":92683},{\"end\":93253,\"start\":93207},{\"end\":93681,\"start\":93603},{\"end\":94200,\"start\":94123},{\"end\":94783,\"start\":94693},{\"end\":95341,\"start\":95297},{\"end\":95818,\"start\":95717},{\"end\":96383,\"start\":96310},{\"end\":96846,\"start\":96794},{\"end\":70634,\"start\":70559},{\"end\":71984,\"start\":71916},{\"end\":76814,\"start\":76762},{\"end\":78325,\"start\":78250},{\"end\":80858,\"start\":80802},{\"end\":82110,\"start\":82024},{\"end\":82986,\"start\":82918},{\"end\":84812,\"start\":84734},{\"end\":85974,\"start\":85762},{\"end\":87637,\"start\":87575},{\"end\":88509,\"start\":88441},{\"end\":89051,\"start\":88989},{\"end\":90547,\"start\":90472},{\"end\":93746,\"start\":93683},{\"end\":94264,\"start\":94202},{\"end\":94860,\"start\":94785},{\"end\":95906,\"start\":95820}]"}}}, "year": 2023, "month": 12, "day": 17}