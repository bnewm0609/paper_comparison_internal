{"id": 234487049, "updated": "2023-11-04 01:34:01.375", "metadata": {"title": "Retrieval-Augmented Generation for Code Summarization via Hybrid GNN", "authors": "[{\"first\":\"Shangqing\",\"last\":\"Liu\",\"middle\":[]},{\"first\":\"Yu\",\"last\":\"Chen\",\"middle\":[]},{\"first\":\"Xiaofei\",\"last\":\"Xie\",\"middle\":[]},{\"first\":\"Jingkai\",\"last\":\"Siow\",\"middle\":[]},{\"first\":\"Yang\",\"last\":\"Liu\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2020, "month": null, "day": null}, "abstract": "Source code summarization aims to generate natural language summaries from structured code snippets for better understanding code functionalities. However, automatic code summarization is challenging due to the complexity of the source code and the language gap between the source code and natural language summaries. Most previous approaches either rely on retrieval-based (which can take advantage of similar examples seen from the retrieval database, but have low generalization performance) or generation-based methods (which have better generalization performance, but cannot take advantage of similar examples). This paper proposes a novel retrieval-augmented mechanism to combine the benefits of both worlds. Furthermore, to mitigate the limitation of Graph Neural Networks (GNNs) on capturing global graph structure information of source code, we propose a novel attention-based dynamic graph to complement the static graph representation of the source code, and design a hybrid message passing GNN for capturing both the local and global structural information. To evaluate the proposed approach, we release a new challenging benchmark, crawled from diversified large-scale open-source C projects (total 95k+ unique functions in the dataset). Our method achieves the state-of-the-art performance, improving existing methods by 1.42, 2.44 and 1.29 in terms of BLEU-4, ROUGE-L and METEOR.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2006.05405", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": null, "doi": null}}, "content": {"source": {"pdf_hash": "7c0b558bf433c5aaaf774cd5d3c767bfd3dbe123", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2006.05405v5.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "1a56b1bc1c201182e1686ba3f54608e6eb8651f9", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/7c0b558bf433c5aaaf774cd5d3c767bfd3dbe123.txt", "contents": "\nRETRIEVAL-AUGMENTED GENERATION FOR CODE SUMMARIZATION VIA HYBRID GNN\n\n\nShangqing Liu \nNanyang Technology University\n\n\nYu Chen \nRensselaer Polytechnic Institute\n\n\n\u2020 \nXiaofei Xie \nNanyang Technology University\n\n\n\u2020 \nJingkai Siow \nNanyang Technology University\n\n\nYang Liu \nNanyang Technology University\n\n\nRETRIEVAL-AUGMENTED GENERATION FOR CODE SUMMARIZATION VIA HYBRID GNN\nPublished as a conference paper at ICLR 2021\nSource code summarization aims to generate natural language summaries from structured code snippets for better understanding code functionalities. However, automatic code summarization is challenging due to the complexity of the source code and the language gap between the source code and natural language summaries. Most previous approaches either rely on retrieval-based (which can take advantage of similar examples seen from the retrieval database, but have low generalization performance) or generation-based methods (which have better generalization performance, but cannot take advantage of similar examples). This paper proposes a novel retrieval-augmented mechanism to combine the benefits of both worlds. Furthermore, to mitigate the limitation of Graph Neural Networks (GNNs) on capturing global graph structure information of source code, we propose a novel attention-based dynamic graph to complement the static graph representation of the source code, and design a hybrid message passing GNN for capturing both the local and global structural information. To evaluate the proposed approach, we release a new challenging benchmark, crawled from diversified large-scale open-source C projects (total 95k+ unique functions in the dataset). Our method achieves the state-of-the-art performance, improving existing methods by 1.42, 2.44 and 1.29 . On the use of automated text summarization techniques for summarizing source code. . Summarizing source code with transferred api knowledge. 2018b.Srinivasan Iyer, Ioannis Konstas, Alvin Cheung, and Luke Zettlemoyer. Summarizing source code using a neural attention model. In\n\nINTRODUCTION\n\nWith software growing in size and complexity, developers tend to spend nearly 90% (Wan et al., 2018) effort on software maintenance (e.g., version iteration and bug fix) in the completed life cycle of software development. Source code summary, in the form of natural language, plays a critical role in the comprehension and maintenance process and greatly reduces the effort of reading and comprehending programs. However, manually writing code summaries is tedious and timeconsuming, and with the acceleration of software iteration, it has become a heavy burden for software developers. Hence, source code summarization which automates concise descriptions of programs is meaningful.\n\nAutomatic source code summarization is a crucial yet far from the settled problem. The key challenges include: 1) the source code and the natural language summary are heterogeneous, which means they may not share common lexical tokens, synonyms, or language structures and 2) the source code is complex with complicated logic and variable grammatical structure, making it hard to learn the semantics. Conventionally, information retrieval (IR) techniques have been widely used in code summarization (Eddy et al., 2013;Haiduc et al., 2010;Wong et al., 2015;2013). Since code duplication (Kamiya et al., 2002;Li et al., 2006) is common in \"big code\" (Allamanis et al., 2018), early works summarize the new programs by retrieving the similar code snippet in the existing code database and use its summary directly. Essentially, the retrieval-based approaches transform the code summarization to the code similarity calculation task, which may achieve promising performance on similar programs, but are limited in generalization, i.e. they have poorer performance on programs that are very different from the code database.\n\nTo improve the generalization performance, recent works focus on generation-based approaches. Some works explore Seq2Seq architectures (Bahdanau et al., 2014;Luong et al., 2015) to generate summaries from the given source code. The Seq2Seq-based approaches (Iyer et al., 2016;Hu et al., 2018a;Alon et al., 2018) usually treat the source code or abstract syntax tree parsed from the source code as a sequence and follow a paradigm of encoder-decoder with the attention mechanism for generating a summary. However, these works only rely on sequential models, which are struggling to capture the rich semantics of source code e.g., control dependencies and data dependencies. In addition, generation-based approaches typically cannot take advantage of similar examples from the retrieval database, as retrieval-based approaches do.\n\nTo better learn the semantics of the source code, Allamanis et al. (Allamanis et al., 2017) lighted up this field by representing programs as graphs. Some follow-up works (Fernandes et al., 2018) attempted to encode more code structures (e.g., control flow, program dependencies) into code graphs with graph neural networks (GNNs), and achieved the promising performance than the sequencebased approaches. Existing works (Allamanis et al., 2017;Fernandes et al., 2018) usually convert code into graph-structured input during preprocessing, and directly consume it via modern neural networks (e.g., GNNs) for computing node and graph embeddings. However, most GNN-based encoders only allow message passing among nodes within a k-hop neighborhood (where k is usually a small number such as 4) to avoid over-smoothing (Zhao & Akoglu, 2019;Chen et al., 2020a), thus capture only local neighborhood information and ignore global interactions among nodes. Even there are some works ) that try to address this challenging with deep GCNs (i.e., 56 layers) (Kipf & Welling, 2016) by the residual connection (He et al., 2016), however, the computation cost cannot endure in the program especially for a large and complex program.\n\nTo address these challenges, we propose a framework for automatic code summarization, namely Hybrid GNN (HGNN). Specifically, from the source code, we first construct a code property graph (CPG) based on the abstract syntax tree (AST) with different types of edges (i.e., Flow To, Reach). In order to combine the benefits of both retrieval-based and generation-based methods, we propose a retrieval-based augmentation mechanism to retrieve the source code that is most similar to the current program from the retrieval database (excluding the current program itself), and add the retrieved code as well as the corresponding summary as auxiliary information for training the model. In order to go beyond local graph neighborhood information, and capture global interactions in the program, we further propose an attention-based dynamic graph by learning global attention scores (i.e., edge weights) in the augmented static CPG. Then, a hybrid message passing (HMP) is performed on both static and dynamic graphs. We also release a new code summarization benchmark by crawling data from popular and diversified projects containing 95k+ functions in C programming language and make it public 1 . We highlight our main contributions as follows:\n\n\u2022 We propose a general-purpose framework for automatic code summarization, which combines the benefits of both retrieval-based and generation-based methods via a retrieval-based augmentation mechanism.\n\n\u2022 We innovate a Hybrid GNN by fusing the static graph (based on code property graph) and dynamic graph (via structure-aware global attention mechanism) to mitigate the limitation of the GNN on capturing global graph information.\n\n\u2022 We release a new challenging C benchmark for the task of source code summarization.\n\n\u2022 We conduct an extensive experiment to evaluate our framework. The proposed approach achieves the state-of-the-art performance and improves existing approaches by 1.42, 2.44 and 1.29 in terms of BLEU-4, ROUGE-L and METEOR metrics.\n\n\nHYBRID GNN FRAMEWORK\n\nIn this section, we introduce the proposed framework Hybrid GNN (HGNN), as shown in Figure 1, which mainly includes four components: 1) Retrieval-augmented Static Graph Construction (c.f., Section 2.2), which incorporates retrieved code-summary pairs to augment the original code for learning. 2) Attention-based Dynamic Graph Construction (c.f., Section 2.3), which allows message passing among any pair of nodes via a structure-aware global attention mechanism. 3) HGNN, (c.f.,  Figure 1: The overall architecture of the proposed HGNN framework.\n\nSection 2.4), which incorporates information from both static graphs and dynamic graphs with Hybrid Message Passing. 4) Decoder (c.f., Section 2.5), which utilizes an attention-based LSTM (Hochreiter & Schmidhuber, 1997) model to generate a summary.\n\n\nPROBLEM FORMULATION\n\nIn this work, we focus on generating natural language summaries for the given functions (Wan et al., 2018;Zhang et al., 2020). A simple example is illustrated in Listing 1, which is crawled from Linux Kernel. Our goal is to generate the best summary \"set the time of day clock\" based on the given source code. Formally, we define a dataset as D = {(c, s)|c \u2208 C, s \u2208 S}, where c is the source code of a function in the function set C and s represents its targeted summary in the summary set S. The task of code summarization is, given a source code c, to generate the best summary consisting of a sequence of tokens\u015d = (t 1 , t 2 , ..., t T ) that maximizes the conditional likelihood\u015d = argmax s P (s|c). The source code of a function can be represented as Code Property Graph (CPG) (Yamaguchi et al., 2014), which is built on the abstract syntax tree (AST) with different type of edges (i.e., Flow To, Control, Define/Use, Reach). Formally, one raw function c could be represented by a multi-edged graph g(V, E), where V is the set of AST nodes, (v, u) \u2208 E denotes the edge between the node v and the node u. A node v consists of two parts: the node sequence and the node type. An illustrative example is shown in Figure 2. For example, in the red node, a%2 == 0 is the node sequence and Condition is the node type. An edge (v, u) has a type, named edge type, e.g., AST type and Flow To type. For more details about the CPG, please refer to Appendix A.\n\nInitialization Representation. Given a CPG, we utilize a BiLSTM to encode its nodes. We represent each token of the node sequence and each edge type using the learned embedding matrix E seqtoken and E edgetype , respectively. Then nodes and edges of the CPG can be encoded as: where l is the number of tokens in the node sequence of v. For the sake of simplicity, in the following section, we use h v and e v,u to represent the embedding of the node v and the edge (v, u), respectively, i.e., encode_node(v) and encode_edge (v, u). Given the source code c of a function as well as the CPG g(V, E), H c \u2208 R m\u00d7d denotes the initial node matrix of the CPG, where m is the total number of nodes in the CPG and d is the dimension of the node embedding.\nh1, ..., h l = BiLSTM(E seqtoken v,1 , ..., E seqtoken v,l ) encode_node(v) = [h \u2192 l ; h \u2190 1 ] encode_edge(v, u) = E edgetype v,u if (v, u) \u2208 E else 0(\n\nRETRIEVAL-BASED AUGMENTATION\n\nWhile retrieval-based methods can perform reasonably well on examples that are similar to those examples from a retrieval database, they typically have low generalization performance and might perform poorly on dissimilar examples. On the contrary, generation-based methods usually have better generalization performance, but cannot take advantage of similar examples from the retrieval database. In this work, we propose to combine the benefits of the two worlds, and design a retrieval-augmented generation framework for the task of code summarization.\n\nIn principle, the goal of code summarization is to learn a mapping from source code c to the natural language summary s = f (c). In other words, for any source code c , a code summarization system can produce its summary s = f (c ). Inspired by this observation, conceptually, we can derive the following formulation s = f (c) \u2212 f (c ) + s . This tells us that we can actually compute the semantic difference between c and c , and further obtain the desired summary s for c by considering both the above semantic difference and s which is the summary for c . Mathmatically, our goal becomes to learn a function which takes as input (c, c , s ), and outputs the summary s for c, that is, s = g(c, c , s ). This motivates us to design our Retrieval-based Augmentation mechanism, as detailed below.\n\nStep 1: Retrieving. For each sample (c, s) \u2208 D, we retrieve the most similar sample: (c , s ) = argmax (c ,s )\u2208D sim(c, c ), where c = c , D is a given retrieval database and sim(c, c ) is the text similarity. Following Zhang et al. (2020), we utilize Lucene for retrieval and calculate the similarity score z between the source code c and the retrieved code c via dynamic programming (Bellman, 1966), namely, z = 1 \u2212 dis(c,c ) max(|c|,|c |) , where dis(c, c ) is the text edit distance.\n\nStep 2: Retrieved Code-based Augmentation. Given the retrieved source code c for the current sample c, we adopt a fusion strategy to inject retrieved semantics into the current sample. The fusion strategy is based on their initial graph representations (H c and H c ) with an attention mechanism:\n\n\u2022 To capture the relevance between c and c , we design an attention function, which computes the attention score matrix A aug based on the embeddings of each pair of nodes in CPGs of c and c :\nA aug \u221d exp(ReLU(H c W C )ReLU(H c W Q ) T )(2)\nwhere W C , W Q \u2208 R d\u00d7d is the weight matrix with d-dim embedding size and ReLU is the rectified linear unit. \u2022 We then multiply the attention matrix A aug with the retrieved representation H c to inject the retrieved features into H c :\nH c = zA aug H c (3) where z \u2208 [0, 1]\nis the similarity score and computed from Step 1, which is introduced to weaken the negative impact of c on the original training data c, i.e., when the similarity of c and c is low. \u2022 Finally, we merge H c and the original H c to get the final representation of c.\ncomp = H c + H c(4)\nwhere comp is the augmented node representation additionally encoding the retrieved semantics.\n\nStep 3: Retrieved Summary-based Augmentation. We further encode the retrieved summary s with another BiLSTM model. We represent each token t i of s using the learned embedding matrix E seqtoken . Then s can be encoded as:\nh t 1 , ..., h t T = BiLSTM(E seqtoken t 1 , ..., E seqtoken t T )(5)\nwhere h t i is the hidden state of the BiLSTM model for the token t i in s and T is the length of s . We multiply [h t 1 ; ...; h t T ] with the similarity score z, computed from Step 1, and concatenate it with the graph encoding results (i.e., the GNN encoder outputs) to obtain the input, namely, [GNN output ; zh t 1 ; ...; zh t T ], to the decoder.\n\n\nATTENTION-BASED DYNAMIC GRAPH\n\nDue to that GNN-based encoders usually consider the k-hop neighborhood, the global relation among nodes in the static graph (see Section 2.2.1) may be ignored. In order to better capture the global semantics of source code, based on the static graph, we propose to dynamically construct a graph via structure-aware global attention mechanism, which allows message passing among any pair of nodes. The attention-based dynamic graph can better capture the global dependency among nodes, and thus supplement the static graph.\n\nStructure-aware Global Attention. The construction of the dynamic graph is motivated by the structure-aware self-attention mechanism proposed in Zhu et al. (2019). Given the static graph, we compute a corresponding dense adjacency matrix A dyn based on a structure-aware global attention mechanism, and obtain the constructed graph, namely, attention-based dynamic graph.\nA dyn v,u = ReLU(h T v W Q )(ReLU(h T u W K ) + ReLU(e T v,u W R )) T \u221a d(6)\nwhere h v , h u \u2208 comp are the augmented node embedding for any node pair (v, u) in the CPG. Note that the global attention considers each pair of nodes of the CPG, regardless of whether there is an edge between them. e v,u \u2208 R de is the edge embedding and W Q , W K \u2208 R d\u00d7d , W R \u2208 R de\u00d7d are parameter matrices, d e and d are the dimensions of edge embedding and node embedding, respectively. The adjacency matrix A dyn will be further row normalized to obtain\u00c3 dyn , which will be used to compute dynamic message passing (see Section 2.4).\nA dyn = softmax(A dyn )(7)\n\nHYBRID GNN\n\nTo better incorporate the information of the static graph and the dynamic graph, we propose the Hybrid Message Passing (HMP), which are performed on both retrieval-augmented static graph and attention-based dynamic graph.\n\nStatic Message Passing. For every node v at each computation hop k in the static graph, we apply an aggregation function to calculate the aggregated vector h k v by considering a set of neighboring node embeddings computed from the previous hop.\nh k v = SUM({h k\u22121 u |\u2200u \u2208 N (v) })(8)\nwhere N (v) is a set of the neighboring nodes which are directly connected with v. For each node v, h 0 v is the initial augmented node embedding of v, i.e., h v \u2208 comp. Dynamic Message Passing. The node information and edge information are propagated on the attention-based dynamic graph with the adjacency matrices\u00c3 dyn , defined as\nh k v = u\u00c3 dyn v,u (W V h k\u22121 u + W F e v,u )(9)\nwhere v and u are any pair of nodes, W V \u2208 R d\u00d7d , W F \u2208 R d\u00d7de are learned matrices, and e v,u is the embedding of the edge connecting v and u. Similarly, h 0 v is the initial augmented node embedding of v in comp.\n\nHybrid Message Passing. Given the static/dynamic aggregated vectors h k v /h k v for static and dynamic graphs, we fuse both vectors and feed the resulting vector to a Gated Recurrent Unit (GRU) to update node representations.\nf k v = GRU(f k\u22121 v , Fuse(h k v , h k v ))(10)\nwhere f 0 v is the augmented node initialization in comp. The fusion function Fuse is designed as a gated sum of two inputs.\nFuse(a, b) = z a + (1 \u2212 z) b z = \u03c3(W z [a; b; a b; a \u2212 b] + b z )(11)\nwhere W z and b z are learnable weight matrix and vector, is the component-wise multiplication, \u03c3 is a sigmoid function and z is a gating vector. After n hops of GNN computation, we obtain the final node representation f n v and then apply max-pooling over all nodes {f n v |\u2200v \u2208 V} to get the graph representation.\n\n\nDECODER\n\nThe decoder is similar with other state-of-the-art Seq2seq models (Bahdanau et al., 2014;Luong et al., 2015) where an attention-based LSTM decoder is used. The decoder takes the input of the concatenation of the node representation and the representation of the retrieved summary s , namely, [f n v1 ; ...; f n vm ; zh t 1 ; ...; zh t T ], where m is the number of nodes in the input CPG graph. The initial hidden state of the decoder is the fusion (Eq. 11) of the graph representation and the weighted (i.e., multiply similarity score z) final state of the retrieved summary BiLSTM encoder.\n\nWe train the model with the cross-entropy loss, defined as L = t \u2212logP (s * t |c, s * <t ), where s * t is the word at the t-th position of the ground-truth output and c is the source code of the function. To alleviate the exposure bias, we utilize schedule teacher forcing (Bengio et al., 2015). During the inference, we use beam search to generate final results.\n\n\nEXPERIMENTS\n\n\nSETUP\n\nWe evaluate our proposed framework against a number of state-of-the-art methods. Specifically, we classify the selected baseline methods into three groups: 1) Retrieval-based approaches: TF-IDF (Haiduc et al., 2010) and NNGen , 2) Sequence-based approaches: CODE-NN (Iyer et al., 2016;Barone & Sennrich, 2017), Transformer (Ahmad et al., 2020), Hybrid-DRL (Wan et al., 2018), Rencos (Zhang et al., 2020) and Dual model (Wei et al., 2019), 3) Graphbased approaches: SeqGNN (Fernandes et al., 2018). In addition, we implemented two another graph-based baselines: GCN2Seq and GAT2Seq, which respectively adopt the Graph Convolution (Kipf & Welling, 2016) and Graph Attention (Velickovic et al., 2018) as the encoder and a LSTM as the decoder for generating summaries. Note that Rencos (Zhang et al., 2020) combines the retrieval information into Seq2Seq model, we classify it into Sequence-based approaches. More detailed description about baselines and the configuration of HGNN can be found in the Appendix B and C.\n\nExisting benchmarks (Barone & Sennrich, 2017;Hu et al., 2018b) are all based on high-level programming language i.e., Java, Python. Furthermore, they have been confirmed to have extensive duplication, making the model overfit to the training data that overlapped with the testset (Fernandes et al., 2018;Allamanis, 2019). We are the first to explore neural summarization on C programming language, and make our C Code Summarization Dataset (CCSD) public to benefit academia and industry. We crawled from popular C repositories on GitHub and extracted function-summary pairs based on the documents of functions. After a deduplication process, we kept 95k+ unique functionsummary pairs. To further test the model generalization ability, we construct in-domain functions and out-of-domain functions by dividing the projects into two sets, denoted as a and b. For each project in a, we randomly select some of the functions in this project as the training data and the unselected functions are the in-domain validation/test data. All functions in projects b are regarded as out-of-domain test data. Finally, we obtain 84,316 training functions, 4,432 in-domain validation functions, 4,203 in-domain test functions and 2,330 out-of-domain test functions. For the retrieval augmentation, we use the training set as the retrieval database, i.e., D = D (see Step 1 in Section 2.2.2). For more details about data processing, please refer to Appendix D. Similar to previous works (Zhang et al., 2020;Wan et al., 2018;Fernandes et al., 2018;Iyer et al., 2016), BLEU (Papineni et al., 2002), METEOR (Banerjee & Lavie, 2005) and ROUGE-L (Lin, 2004) are used as our automatic evaluation metrics. These metrics are popular for evaluating machine translation and text summarization tasks. Except for these automatic metrics, we also conduct a human evaluation study. We invite 5 PhD students and 10 master students as volunteers, who have rich C programming experiences. The volunteers are asked to rank summaries generated from the anonymized approaches from 1 to 5 (i.e., 1: Poor, 2: Marginal, 3: Acceptable, 4: Good, 5: Excellent) based on the relevance of the generated summary to the source code and the degree of similarity between the generated summary and the actual summary. Specifically, we randomly choose 50 functions for each model with the corresponding generated summaries and ground-truths. We calculate the average score and the higher the score, the better the quality. Table 1 shows the evaluation results including two parts: the comparison with baselines and the ablation study. Consider the comparison with state-of-the-art baselines, in general, we find that our proposed model outperforms existing methods by a significant margin on both in-domain and out-of-domain datasets, and shows good generalization performance. Compared with others, on in-domain dataset, the retrieval-based approaches could achieve competitive performance on BLEU-4, however ROUGE-L and METEOR are fare less than ours. Moreover, they do not perform well on the out-of-domain dataset. Compared with the graph-based approaches (i.e., GCN2Seq, GAT2Seq and SeqGNN), even without augmentation (HGNN w/o augment), our approach still outperforms them, which further demonstrates the effectiveness of Hybrid GNN for additionally capturing global graph information. Compared with Rencos that also considers the retrieved information in the Seq2Seq model, its performance is still lower than HGNN. On the overall dataset including both of in-domain and out-of-domain data, our model achieves 14.01, 30.89 and 14.50, outperforming current state-of-the-art method Rencos by 1.42, 2.44 and 1.29 in terms of BLEU-4, ROUGE-L and METEOR metrics.\n\n\nCOMPARISON WITH THE BASELINES\n\n\nABLATION STUDY\n\nWe also conduct an ablation study to evaluate the impact of different components of our framework, e.g., retrieval-based augmentation, static graph and dynamic graph in the last row of Table 1. Overall, we found that 1) retrieval-augmented mechanism could contribute to the overall model performance (HGNN vs. HGNN w/o augment). Compared with HGNN, we see that the performance of HGNN w/o static and HGNN w/o dynamic decreases, which demonstrates the effectiveness of the Hybrid GNN and 2) the performance without static graph is worse than the performance without dynamic graph in ROUGE-L and METEOR, however, BLEU-4 is higher than the performance without dynamic graph.\n\nTo further understand the impact of the static graph and dynamic graph, we evaluate the performance without augmentation and static graph/dynamic graph (see HGNN w/o augment& static and HGNN w/o augment& dynamic). Compared with HGNN w/o augment, the results further confirm the effectiveness of the Hybrid GNN (i.e., static graph and dynamic graph).  , we can see that code-based augmentation could have some improvement, but the effect is not significant compared with summary-based augmentation. We conjecture that, due to that the code and summary are heterogeneous, the summary-based augmentation has a more direct impact on the code summarization task. When combining both code-based augmentation and summary-based augmentation, we can achieve the best results (i.e., 14.01, 30.89, 14.50). We plan to explore more code-based augmentation (e.g., semantic-equivalent code transformation) in our future work.\n\n\nHUMAN EVALUATION\n\nAs shown in Table 2, we perform a human evaluation on the overall dataset to assess the quality of the generated summaries by our approach, NNGen, Transformer, Rencos and SeqGNN in terms of relevance and similarity. As depicted in Table 1, NNGen, Rencos and SeqGNN are the best retrieval-based, sequence-based, and graph-based approaches, respectively. We also compare with Transformer as it has been widely used in natural language processing. The results show that our method can generate better summaries which are more relevant with the source code and more similar with the ground-truth summaries.\n\n\nCASE STUDY\n\nTo perform qualitative analysis, we present two examples with generated summaries by different methods from the overall data set, shown in Table 3. We can see that, in the first example, our approach can learn more code semantics, i.e., p is a self-defined struct variable. Thus, we could generate a token object for the variable p. However, other models can only produce string. Example 2 is a more difficult function with the functionality to \"release reference of cedar\", as compared to other baselines, our approach effectively captures the functionality and generates a more precise summary.\n\n\nEXTENSION ON THE PYTHON DATASET\n\nWe conducted additional experiments on a public dataset, i.e., the Python Code Summarization Dataset (PCSD), which was also used in Rencos (the most competitive baseline in our paper). We follow the setting of Rencos and split PCSD into the training set, validation set and testing set with fractions of 60%, 20% and 20%. We construct the static graph based on AST. The decoding step is set to 50, followed by Rencos, and the other settings are the same with CCSD. We compare our methods on PCSD against various competitive baselines, i.e., NNGen, CODE-NN, Rencos and Transformer, which are either retrieval-based, generation-based or hybrid methods. The results are shown in Table 4. The results indicate that, compared with the best results from NNGen, CODE-NN, Rencos and Transformer, our method can improve the performance by 0.40, 3.70 and 1.41 in terms of BLEU-4, ROUGE-L and METEOR. We also conduct the ablation study on PCSD to demonstrate the usefulness of the static graph (i.e., HGNN w/o dynamic) and dynamic graph (i.e., HGNN w/o static). The results also demonstrate that both static graph and dynamic graph can contribute to our framework. In summary, the results on both our released benchmark (CCSD) and existing benchmark (PCSD) demonstrate the effectiveness and the scalability of our method.\n\n\nRELATED WORK\n\nSource Code Summarization Early works (Eddy et al., 2013;Haiduc et al., 2010;Wong et al., 2015;2013) for code summarization focused on using information retrieval to retrieve summaries. Later works attempted to employ attentional Seq2Seq model on the source code (Iyer et al., 2016;Siow et al., 2020) or some variants, i.e., AST (Hu et al., 2018a;Alon et al., 2018; for generation. However, these works are based on sequential models, ignoring rich code semantics. Some latest attempts (LeClair et al., 2020;Fernandes et al., 2018) embedded program semantics into GNNs. but they mainly rely on simple representations, which are limited to learn full semantics.\n\nGraph Neural Networks Over the past few years, GNNs (Li et al., 2015;Hamilton et al., 2017;Kipf & Welling, 2016;Chen et al., 2020b) have attracted increasing attention with many successful applications in computer vision (Norcliffe-Brown et al., 2018), natural language processing (Xu et al., 2018a;Chen et al., 2020d;c;e). Because by design GNNs can model graph-structured data, recently, some works have extended the widely used Seq2Seq architectures to Graph2Seq architectures for various tasks including machine translation (Beck et al., 2018), and graph (e.g., AMR, SQL)-to-text generation (Zhu et al., 2019;Xu et al., 2018b). Some works have also attempted to encode programs with graphs for diverse tasks e.g., VARNAMING/VARMISUSE (Allamanis et al., 2017), Source Code Vulnerability Detection . As compared to these works, we innovate a hybrid message passing GNN performed on both static graph and dynamic graph for message fusion.\n\n\nCONCLUSION AND FUTURE WORK\n\nIn this paper, we proposed a general-purpose framework for automatic code summarization. A novel retrieval-augmented mechanism is proposed for combining the benefits of both retrieval-based and generation-based approaches. Moreover, to capture global semantics among nodes, we develop a hybrid message passing GNN based on both static and dynamic graphs. The evaluation shows that our approach improves state-of-the-art techniques substantially. Our future work includes: 1) we plan to introduce more information such as API knowledge to learn the better semantics of programs, 2) we explore more code-based augmentation techniques to improve the performance and 3) we plan to adopt the existing techniques such as Xie et al., 2019a;b;Ma et al., 2018) to evaluate the robustness of the trained model.\n\n\nACKNOWLEDGEMENT\n\n\nAppendices\n\n\nA DETAILS ON CODE PROPERTY GRAPH\n\nCode Property Graph (CPG) (Yamaguchi et al., 2014), which is constructed on abstract syntax tree (AST), combines different edges (i.e., Flow to, Control) to represent the semantics of the program. We describe each representation combining with Figure 2 as follows:\n\n\u2022 Abstract Syntax Tree (AST). AST contains syntactic information for a program and omits irrelevant details that have no effect on the semantics. Figure 2 shows the completed AST nodes on the left simple program and each node has a code sequence in the first line and type attribute in the second line. The black arrows represent the child-parent relations among ASTs.\n\n\u2022 Control Flow Graph (CFG). Compared with AST highlighting the syntactic structure, CFG displays statement execution order, i.e., the possible order in which statements may be executed and the conditions that must be met for this to happen. Each statement in the program is treated as an independent node as well as a designated entry and exit node. Based on the keywords if, for, goto, break and continue, control flow graphs can be easily built and \"Flow to\" with green dashed arrows in Figure 2 represents this flow order.\n\n\u2022 Program Dependency Graph (PDG). PDG includes data dependencies and control dependencies: 1) data dependencies are described as the definition of a variable in a statement reaches the usage of the same variable at another statement. In Figure 2, the variable \"b\" is defined in the statement \"int b = a++\" and used in \"call (b)\". Hence, there is a \"Reach\" edge with blue arrows point from \"int b = a++\" to \"call (b)\". Furthermore, Define/Use edge with orange double arrows denotes the definition and usage of the variable. 2) different from CFG displaying the execution process of the complete program, control dependencies define the execution of a statement may be dependent on the value of a predicate, which more focus on the statement itself. For instance, the statements \"int b = a++\" and \"call(b)\" are only performed \"if a is even\". Therefore, a red double arrow \"Control\" points from \"if (a % 2) == 0\" to \"int b = a++\" and \"call(b)\".\n\n\nB DETAILS ON BASELINE METHODS\n\nWe compare our approach with existing baselines. They can be divided into three groups: Retrievalbased approaches, Sequence-based approaches and Graph-based approaches. For papers that provide the source code, we directly reproduce their methods on CCSD dataset. Otherwise, we reimplement their approaches with reference to the papers.\n\n\nB.1 RETRIEVAL-BASED APPROACHES\n\nTF-IDF (Haiduc et al., 2010) is the abbreviation of Term Frequency-Inverse Document Frequency, which is adopted in the early code summarization (Haiduc et al., 2010). It transforms programs into weight vectors by calculating term frequency and inverse document frequency. We retrieve the summary of the most similar programs by calculating the cosine similarity on the weighted vectors.\n\nNNGen ) is a retrieved-based approach to produce commit messages for code changes.\n\nWe reproduce such an algorithm on code summarization. Specifically, we retrieve the most similar top-k code snippets on a bag-of-words model and prioritizes the summary in terms of BLEU-4 scores in top-k code snippets. Transformer (Ahmad et al., 2020) adopts the transformer architecture (Vaswani et al., 2017) with self-attention to capture long dependency in the code for source code summrization.\n\n\nB.2 SEQUENCE-BASED APPROACHES\n\n\nCODE-NN\n\nHybrid-DRL (Wan et al., 2018) is a reinforcement learning-based approach, which incorporates AST and sequential code snippets into a deep reinforcement learning framework and employ evaluation metrics e.g., BLEU as the reward.\n\nDual Model (Wei et al., 2019) propose a dual training framework by training code summarization and code generation tasks simultaneously to boost each task performance.\n\nRencos (Zhang et al., 2020) is the retrieval-based Seq2Seq model for code summarization. it utilized a pretrained Seq2Seq model during the testing phase by computing a joint probability conditioned on both the original source code and retrieved the most similar source code for the summary generation. Compared with Rencos, we propose a novel retrieval-augmented mechanism for the similar source code and use it at the model training phase.\n\n\nB.3 GRAPH-BASED APPROACHES\n\nWe also compared with some latest GNN-based works, employing graph neural network for source code summarization.\n\nGCN2Seq, GAT2Seq modify Graph Convolution Network (Kipf & Welling, 2016) and Graph Attention Network (Velickovic et al., 2018) to perform convolution operation and attention operation on the code property graph for learning and followed by a LSTM to generate summaries. We implement the related code from scratch. (Fernandes et al., 2018) combines GGNNs and standard sequence encoders for summarization. They take the code and relationships between elements of the code as input. Specially, a BiLSTM is employed on the code sequence to learn representations and each source code token is modelled as a node in the graph, and employed GGNN for graph-level learning. Since our node sequences are sub-sequence of source code rather than individual token, we adjust to slice the output of BiLSTM and sum each token representation in node sequences as node initial representation for summarization. Furthermore, we implement the related code from scratch.\n\n\nSeqGNN\n\n\nC MODEL SETTINGS\n\nWe embed the most frequent 40,000 words in the training set with 512-dims and set the hidden size of BiLSTM to 256 and the concatenated state size for both directions is 512. The dropout is set to 0.3 after the word embedding layer and BiLSTM. We set GNN hops to 1 for the best performance. The optimizer is selected with Adam with an initial learning rate of 0.001. The batch size is set to 64 and early stop for 10. The beam search width is set to 5 as usual. All experiments are conducted on the DGX server with four Nvidia Graphics Tesla V100 and each epoch takes 6 minutes averagely. All hyperparameters are tuned with grid search on the validation set.\n\n\nD DETAILS ON DATA PREPARATION\n\nIt is non-trivial to obtain high-quality datasets for code summarization. We noticed that despite some previous works (Barone & Sennrich, 2017;Hu et al., 2018b) released their datasets, however, they are all based on high-level programming languages i.e. Java, Python. We are the first to explore summarization on C programming language. Specifically, we crawled from popular C repositories (e.g., Linux and QEMU) on GitHub, and then extracted separate function-summary pairs from these projects. Specifically, we extracted functions and associated comments marked by special characters \"/**\" and \"*/\" over the function declaration. These comments can be considered as explanations of the functions. We filtered out functions with line exceeding 1000 and any other comments inside the function, and the first sentence was selected as the summary. A similar practice can be found in (Jiang et al., 2017). Totally, we collected 500k+ raw function-summary pairs. Furthermore, functions with token size greater than 150 were removed for computational efficiency and there were 130k+ functions left. Since duplication is very common in existing datasets (Fernandes et al., 2018), followed by Allamanis (2019), we performed a de-duplication process and removed functions with similarity over 80%. Specifically, we calculated the cosine similarity by encoding the raw functions into vectors with sklearn. Finally, we kept 95k+ unique functions. We name this dataset C Code Summarization Dataset (CCSD). To testify model generalization ability, we randomly selected \n\nSource\nCode: int pdc_tod_set(unsigned long sec, unsigned long usec){ int retval; unsigned long flags; spin_lock_irqsave(&pdc_lock, flags); retval = mem_pdc_call(PDC_TOD, PDC_TOD_WRITE, sec, usec); spin_unlock_irqrestore(&pdc_lock, flags); return retval; } Ground-Truth: set the time of day clock Listing 1: An example in our dataset crawled from Linux Kernel.\n\nFigure 2 :\n2An example of Code Property Graph (CPG).\n\n\n(Iyer et al., 2016;Barone & Sennrich, 2017) adopts an attention-based Seq2Seq model to generate summaries on the source code.\n\nTable 1 :\n1Automatic evaluation results (in %) on the CCSD test set.In-domain \nOut-of-domain \nOverall \nMethods \nBLEU-4 ROUGE-L METEOR BLEU-4 ROUGE-L METEOR BLEU-4 ROUGE-L METEOR \nTF-IDF \n15.20 \n27.98 \n13.74 \n5.50 \n15.37 \n6.84 \n12.19 \n23.49 \n11.43 \nNNGen \n15.97 \n28.14 \n13.82 \n5.74 \n16.33 \n7.18 \n12.76 \n23.93 \n11.58 \nCODE-NN \n10.08 \n26.17 \n11.33 \n3.86 \n15.25 \n6.19 \n8.24 \n22.28 \n9.61 \nHybrid-DRL \n9.29 \n30.00 \n12.47 \n6.30 \n24.19 \n10.30 \n8.42 \n28.64 \n11.73 \nTransformer \n12.91 \n28.04 \n13.83 \n5.75 \n18.62 \n9.89 \n10.69 \n24.65 \n12.02 \nDual Model \n11.49 \n29.20 \n13.24 \n5.25 \n21.31 \n9.14 \n9.61 \n26.40 \n11.87 \nRencos \n14.80 \n31.41 \n14.64 \n7.54 \n23.12 \n10.35 \n12.59 \n28.45 \n13.21 \nGCN2Seq \n9.79 \n26.59 \n11.65 \n4.06 \n18.96 \n7.76 \n7.91 \n23.67 \n10.23 \nGAT2Seq \n10.52 \n26.17 \n11.88 \n3.80 \n16.94 \n6.73 \n8.29 \n22.63 \n10.00 \nSeqGNN \n10.51 \n29.84 \n13.14 \n4.94 \n20.80 \n9.50 \n8.87 \n26.34 \n11.93 \nHGNN w/o augment & static \n11.75 \n29.59 \n13.86 \n5.57 \n22.14 \n9.41 \n9.98 \n26.94 \n12.05 \nHGNN w/o augment & dynamic 11.85 \n29.51 \n13.54 \n5.45 \n21.89 \n9.59 \n9.93 \n26.80 \n12.21 \nHGNN w/o augment \n12.33 \n29.99 \n13.78 \n5.45 \n22.07 \n9.46 \n10.26 \n27.17 \n12.32 \nHGNN w/o static \n15.93 \n33.67 \n15.67 \n7.72 \n24.69 \n10.63 \n13.44 \n30.47 \n13.98 \nHGNN w/o dynamic \n15.77 \n33.84 \n15.67 \n7.64 \n24.72 \n10.73 \n13.31 \n30.59 \n14.01 \nHGNN \n16.72 \n34.29 \n16.25 \n7.85 \n24.74 \n11.05 \n14.01 \n30.89 \n14.50 \n\n\n\nTable 2 :\n2Human evaluation results on the CCSD test set.Metrics \nNNGen Transformer Rencos SeqGNN HGNN \nRelevance \n3.23 \n3.17 \n3.48 \n3.09 \n3.69 \nSimilarity \n3.18 \n3.02 \n3.32 \n3.06 \n3.51 \n\n\n\nTable 3 :\n3Examples of generated summaries on the CCSD test set.Example \nExample 1 \nExample 2 \n\nSource Code \n\nstatic void strInit(Str *p){ \np->z = 0; \np->nAlloc = 0; \np->nUsed = 0; \n} \n\nvoid ReleaseCedar(CEDAR *c){ \nif (c == NULL) \nreturn; \nif (Release(c->ref) == 0) \nCleanupCedar(c); \n} \n\nGround-Truth \ninitialize a str object \nrelease reference of the cedar \nNNGen \nfree the string \nrelease the virtual host \nTransformer \nreset a string \nrelease of the cancel object \nRencos \nappend a raw string to the json string \nrelease of the cancel object \nSeqGNN \ninitialize the string \nrelease cedar communication mode \nHGNN \ninitialize a string object \nrelease reference of cedar \n\nWe also conduct experiments to investigate the impact of code-based augmentation and summary-\nbased augmentation. Overall, we found that the summary-based augmentation could contribute more \nthan the code-based augmentation. For example, after adding the code-based augmentation, the \nperformance can be 10.22, 27.54 and 12.49 in terms of BLUE-4, ROUGE-L and METEOR on the \noverall dataset. With the summary-based augmentation, the results can reach to 13.76, 30.59 and \n14.11. Compared with the results without augmentation (i.e., 10.26. 27.17, 12.32 with HGNN w/o \naugment)\n\nTable 4 :\n4Automatic evaluation results (in %) on the PCSD test set.Methods \nBLEU-4 ROUGE-L METEOR \nNNGen \n21.60 \n31.61 \n15.96 \nCODE-NN \n16.39 \n28.99 \n13.68 \nTransformer \n17.06 \n31.16 \n14.37 \nRencos \n24.02 \n36.21 \n18.07 \nHGNN w/o static \n24.06 \n38.28 \n18.66 \nHGNN w/o dynamic \n24.13 \n38.64 \n18.93 \nHGNN \n24.42 \n39.91 \n19.48 \n\n\n\nTable 5 :\n5More Examples of generated summaries on the CCSD test set.\nhttps://github.com/shangqing-liu/CCSD-benchmark-for-code-summarization\nThis research is supported by the National Research Foundation, Singapore under its AI Singapore Programme (AISG Award No: AISG2-RP-2020-019), the National Research Foundation under its National Cybersecurity R&D Program (Award No. NRF2018NCR-NCR005-0001), the Singapore National Research Foundation under NCR Award Number NRF2018NCR-NSOE003-0001 and NRF Investigatorship NRFI06-2020-0022.ExampleExample1(Yamaguchi et al., 2014)was applied to construct the code property graph.E MORE EXAMPLESWe show more examples along with the retrieved code and summary by dynamic programming inTable 5and we can find that HGNN can generate more high-quality summries based on our approach.\nA transformer-based approach for source code summarization. Saikat Wasi Uddin Ahmad, Baishakhi Chakraborty, Kai-Wei Ray, Chang, arXiv:2005.00653arXiv preprintWasi Uddin Ahmad, Saikat Chakraborty, Baishakhi Ray, and Kai-Wei Chang. A transformer-based approach for source code summarization. arXiv preprint arXiv:2005.00653, 2020.\n\nThe adverse effects of code duplication in machine learning models of code. Miltiadis Allamanis, Proceedings of the 2019 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software. the 2019 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and SoftwareMiltiadis Allamanis. The adverse effects of code duplication in machine learning models of code. In Proceedings of the 2019 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software, pp. 143-153, 2019.\n\nLearning to represent programs with graphs. Miltiadis Allamanis, Marc Brockschmidt, Mahmoud Khademi, arXiv:1711.00740arXiv preprintMiltiadis Allamanis, Marc Brockschmidt, and Mahmoud Khademi. Learning to represent programs with graphs. arXiv preprint arXiv:1711.00740, 2017.\n\nA survey of machine learning for big code and naturalness. Miltiadis Allamanis, T Earl, Premkumar Barr, Charles Devanbu, Sutton, ACM Computing Surveys (CSUR). 514Miltiadis Allamanis, Earl T Barr, Premkumar Devanbu, and Charles Sutton. A survey of machine learning for big code and naturalness. ACM Computing Surveys (CSUR), 51(4):1-37, 2018.\n\nUri Alon, Shaked Brody, Omer Levy, Eran Yahav, arXiv:1808.01400Generating sequences from structured representations of code. 2arXiv preprintUri Alon, Shaked Brody, Omer Levy, and Eran Yahav. code2seq: Generating sequences from structured representations of code. arXiv preprint arXiv:1808.01400, 2018.\n\nNeural machine translation by jointly learning to align and translate. Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio, arXiv:1409.0473arXiv preprintDzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly learning to align and translate. arXiv preprint arXiv:1409.0473, 2014.\n\nMeteor: An automatic metric for mt evaluation with improved correlation with human judgments. Satanjeev Banerjee, Alon Lavie, Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization. the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarizationSatanjeev Banerjee and Alon Lavie. Meteor: An automatic metric for mt evaluation with improved correlation with human judgments. In Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization, pp. 65-72, 2005.\n\nA parallel corpus of python functions and documentation strings for automated code documentation and code generation. Antonio Valerio, Miceli Barone, Rico Sennrich, arXiv:1707.02275arXiv preprintAntonio Valerio Miceli Barone and Rico Sennrich. A parallel corpus of python functions and documentation strings for automated code documentation and code generation. arXiv preprint arXiv:1707.02275, 2017.\n\nGraph-to-sequence learning using gated graph neural networks. Daniel Beck, Gholamreza Haffari, Trevor Cohn, arXiv:1806.09835arXiv preprintDaniel Beck, Gholamreza Haffari, and Trevor Cohn. Graph-to-sequence learning using gated graph neural networks. arXiv preprint arXiv:1806.09835, 2018.\n\nDynamic programming. Richard Bellman, Science. 1533731Richard Bellman. Dynamic programming. Science, 153(3731):34-37, 1966.\n\nScheduled sampling for sequence prediction with recurrent neural networks. Samy Bengio, Oriol Vinyals, Navdeep Jaitly, Noam Shazeer, Advances in Neural Information Processing Systems. Samy Bengio, Oriol Vinyals, Navdeep Jaitly, and Noam Shazeer. Scheduled sampling for sequence prediction with recurrent neural networks. In Advances in Neural Information Processing Systems, pp. 1171-1179, 2015.\n\nMeasuring and relieving the oversmoothing problem for graph neural networks from the topological view. Deli Chen, Yankai Lin, Wei Li, Peng Li, Jie Zhou, Xu Sun, AAAI. Deli Chen, Yankai Lin, Wei Li, Peng Li, Jie Zhou, and Xu Sun. Measuring and relieving the over- smoothing problem for graph neural networks from the topological view. In AAAI, pp. 3438-3445, 2020a.\n\nIterative deep graph learning for graph neural networks: Better and robust node embeddings. Yu Chen, Lingfei Wu, Mohammed Zaki, Advances in Neural Information Processing Systems. 33Yu Chen, Lingfei Wu, and Mohammed Zaki. Iterative deep graph learning for graph neural networks: Better and robust node embeddings. Advances in Neural Information Processing Systems, 33, 2020b.\n\nGraphflow: Exploiting conversation flow with graph neural networks for conversational machine comprehension. Yu Chen, Lingfei Wu, Mohammed J Zaki, Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence. the Twenty-Ninth International Joint Conference on Artificial IntelligenceYu Chen, Lingfei Wu, and Mohammed J. Zaki. Graphflow: Exploiting conversation flow with graph neural networks for conversational machine comprehension. In Proceedings of the Twenty- Ninth International Joint Conference on Artificial Intelligence, pp. 1230-1236. International Joint Conferences on Artificial Intelligence Organization, 2020c.\n\nReinforcement learning based graph-to-sequence model for natural question generation. Yu Chen, Lingfei Wu, Mohammed J Zaki, Proceedings of the 8th International Conference on Learning Representations. the 8th International Conference on Learning RepresentationsYu Chen, Lingfei Wu, and Mohammed J. Zaki. Reinforcement learning based graph-to-sequence model for natural question generation. In Proceedings of the 8th International Conference on Learning Representations, Apr. 26-30, 2020d.\n\nToward subgraph guided knowledge graph question generation with graph neural networks. Yu Chen, Lingfei Wu, Mohammed J Zaki, arXiv:2004.06015arXiv preprintYu Chen, Lingfei Wu, and Mohammed J Zaki. Toward subgraph guided knowledge graph question generation with graph neural networks. arXiv preprint arXiv:2004.06015, 2020e.\n\nDeepstellar: Model-based quantitative analysis of stateful deep learning systems. Xiaoning Du, Xiaofei Xie, Yi Li, Lei Ma, Yang Liu, Jianjun Zhao, Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software EngineeringXiaoning Du, Xiaofei Xie, Yi Li, Lei Ma, Yang Liu, and Jianjun Zhao. Deepstellar: Model-based quantitative analysis of stateful deep learning systems. In Proceedings of the 2019 27th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering, pp. 477-487, 2019.\n\nNeuralmachine-translation-based commit message generation: how far are we?. Zhongxin Liu, Xin Xia, Ahmed E Hassan, David Lo, Zhenchang Xing, Xinyu Wang, Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering. the 33rd ACM/IEEE International Conference on Automated Software EngineeringZhongxin Liu, Xin Xia, Ahmed E Hassan, David Lo, Zhenchang Xing, and Xinyu Wang. Neural- machine-translation-based commit message generation: how far are we? In Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering, pp. 373-384, 2018.\n\nEffective approaches to attention-based neural machine translation. Minh-Thang Luong, Hieu Pham, Christopher D Manning, arXiv:1508.04025arXiv preprintMinh-Thang Luong, Hieu Pham, and Christopher D Manning. Effective approaches to attention-based neural machine translation. arXiv preprint arXiv:1508.04025, 2015.\n\nMulti-granularity testing criteria for deep learning systems. Lei Ma, Felix Juefei-Xu, Fuyuan Zhang, Jiyuan Sun, Minhui Xue, Bo Li, Chunyang Chen, Ting Su, Li Li, Yang Liu, Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering. the 33rd ACM/IEEE International Conference on Automated Software EngineeringLei Ma, Felix Juefei-Xu, Fuyuan Zhang, Jiyuan Sun, Minhui Xue, Bo Li, Chunyang Chen, Ting Su, Li Li, Yang Liu, et al. Deepgauge: Multi-granularity testing criteria for deep learning systems. In Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering, pp. 120-131, 2018.\n\nLearning conditioned graph structures for interpretable visual question answering. Will Norcliffe-Brown, Stathis Vafeias, Sarah Parisot, Advances in Neural Information Processing Systems. Will Norcliffe-Brown, Stathis Vafeias, and Sarah Parisot. Learning conditioned graph structures for interpretable visual question answering. In Advances in Neural Information Processing Systems, pp. 8344-8353, 2018.\n\nBleu: a method for automatic evaluation of machine translation. Kishore Papineni, Salim Roukos, Todd Ward, Wei-Jing Zhu, Proceedings of the 40th annual meeting on association for computational linguistics. the 40th annual meeting on association for computational linguisticsAssociation for Computational LinguisticsKishore Papineni, Salim Roukos, Todd Ward, and Wei-Jing Zhu. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th annual meeting on association for computational linguistics, pp. 311-318. Association for Computational Linguistics, 2002.\n\nCore: Automating review recommendation for code changes. Kai Jing, Cuiyun Siow, Lingling Gao, Sen Fan, Yang Chen, Liu, 2020 IEEE 27th International Conference on Software Analysis, Evolution and Reengineering (SANER). IEEEJing Kai Siow, Cuiyun Gao, Lingling Fan, Sen Chen, and Yang Liu. Core: Automating review recommendation for code changes. In 2020 IEEE 27th International Conference on Software Analysis, Evolution and Reengineering (SANER), pp. 284-295. IEEE, 2020.\n\nAttention is all you need. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, Illia Polosukhin, Advances in neural information processing systems. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Advances in neural information processing systems, pp. 5998-6008, 2017.\n\nGraph attention networks. ArXiv. Petar Velickovic, Guillem Cucurull, A Casanova, A Romero, P Li\u00f2, Yoshua Bengio, abs/1710.10903Petar Velickovic, Guillem Cucurull, A. Casanova, A. Romero, P. Li\u00f2, and Yoshua Bengio. Graph attention networks. ArXiv, abs/1710.10903, 2018.\n\nImproving automatic source code summarization via deep reinforcement learning. Yao Wan, Zhou Zhao, Min Yang, Guandong Xu, Haochao Ying, Jian Wu, Philip S Yu, Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering. the 33rd ACM/IEEE International Conference on Automated Software EngineeringYao Wan, Zhou Zhao, Min Yang, Guandong Xu, Haochao Ying, Jian Wu, and Philip S Yu. Improving automatic source code summarization via deep reinforcement learning. In Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering, pp. 397-407, 2018.\n\nCode generation as a dual task of code summarization. Bolin Wei, Ge Li, Xin Xia, Zhiyi Fu, Zhi Jin, Advances in Neural Information Processing Systems. Bolin Wei, Ge Li, Xin Xia, Zhiyi Fu, and Zhi Jin. Code generation as a dual task of code summariza- tion. In Advances in Neural Information Processing Systems, pp. 6563-6573, 2019.\n\nAutocomment: Mining question and answer sites for automatic comment generation. Edmund Wong, Jinqiu Yang, Lin Tan, 28th IEEE/ACM International Conference on Automated Software Engineering (ASE). IEEEEdmund Wong, Jinqiu Yang, and Lin Tan. Autocomment: Mining question and answer sites for automatic comment generation. In 2013 28th IEEE/ACM International Conference on Automated Software Engineering (ASE), pp. 562-567. IEEE, 2013.\n\nClocom: Mining existing source code for automatic comment generation. Edmund Wong, Taiyue Liu, Lin Tan, IEEE 22nd International Conference on Software Analysis, Evolution, and Reengineering (SANER). IEEEEdmund Wong, Taiyue Liu, and Lin Tan. Clocom: Mining existing source code for automatic comment generation. In 2015 IEEE 22nd International Conference on Software Analysis, Evolution, and Reengineering (SANER), pp. 380-389. IEEE, 2015.\n\nDeephunter: a coverage-guided fuzz testing framework for deep neural networks. Xiaofei Xie, Lei Ma, Felix Juefei-Xu, Minhui Xue, Hongxu Chen, Yang Liu, Jianjun Zhao, Bo Li, Jianxiong Yin, Simon See, Proceedings of the 28th ACM SIGSOFT International Symposium on Software Testing and Analysis. the 28th ACM SIGSOFT International Symposium on Software Testing and AnalysisXiaofei Xie, Lei Ma, Felix Juefei-Xu, Minhui Xue, Hongxu Chen, Yang Liu, Jianjun Zhao, Bo Li, Jianxiong Yin, and Simon See. Deephunter: a coverage-guided fuzz testing framework for deep neural networks. In Proceedings of the 28th ACM SIGSOFT International Symposium on Software Testing and Analysis, pp. 146-157, 2019a.\n\nDiffchaser: Detecting disagreements for deep neural networks. Xiaofei Xie, Lei Ma, Haijun Wang, Yuekang Li, Yang Liu, Xiaohong Li, IJCAI. Xiaofei Xie, Lei Ma, Haijun Wang, Yuekang Li, Yang Liu, and Xiaohong Li. Diffchaser: Detecting disagreements for deep neural networks. In IJCAI, pp. 5772-5778, 2019b.\n\nGraph2seq: Graph to sequence learning with attention-based neural networks. Kun Xu, Lingfei Wu, Zhiguo Wang, Vadim Sheinin, arXiv:1804.00823arXiv preprintKun Xu, Lingfei Wu, Zhiguo Wang, and Vadim Sheinin. Graph2seq: Graph to sequence learning with attention-based neural networks. arXiv preprint arXiv:1804.00823, 2018a.\n\nSql-to-text generation with graph-to-sequence model. Kun Xu, Lingfei Wu, Zhiguo Wang, Mo Yu, Liwei Chen, Vadim Sheinin, arXiv:1809.05255arXiv preprintKun Xu, Lingfei Wu, Zhiguo Wang, Mo Yu, Liwei Chen, and Vadim Sheinin. Sql-to-text generation with graph-to-sequence model. arXiv preprint arXiv:1809.05255, 2018b.\n\nModeling and discovering vulnerabilities with code property graphs. Fabian Yamaguchi, Nico Golde, Daniel Arp, Konrad Rieck, 2014 IEEE Symposium on Security and Privacy. IEEEFabian Yamaguchi, Nico Golde, Daniel Arp, and Konrad Rieck. Modeling and discovering vulnera- bilities with code property graphs. In 2014 IEEE Symposium on Security and Privacy, pp. 590-604. IEEE, 2014.\n\nRetrieval-based neural source code summarization. Jian Zhang, Xu Wang, Hongyu Zhang, Hailong Sun, Xudong Liu, Proceedings of the 42nd International Conference on Software Engineering. the 42nd International Conference on Software EngineeringIEEEJian Zhang, Xu Wang, Hongyu Zhang, Hailong Sun, and Xudong Liu. Retrieval-based neural source code summarization. In Proceedings of the 42nd International Conference on Software Engineering. IEEE, 2020.\n\nLingxiao Zhao, Leman Akoglu, arXiv:1909.12223Pairnorm: Tackling oversmoothing in gnns. arXiv preprintLingxiao Zhao and Leman Akoglu. Pairnorm: Tackling oversmoothing in gnns. arXiv preprint arXiv:1909.12223, 2019.\n\nDevign: Effective vulnerability identification by learning comprehensive program semantics via graph neural networks. Yaqin Zhou, Shangqing Liu, Jingkai Siow, Xiaoning Du, Yang Liu, Advances in Neural Information Processing Systems. Yaqin Zhou, Shangqing Liu, Jingkai Siow, Xiaoning Du, and Yang Liu. Devign: Effective vulnera- bility identification by learning comprehensive program semantics via graph neural networks. In Advances in Neural Information Processing Systems, pp. 10197-10207, 2019.\n\nModeling graph structure in transformer for better amr-to-text generation. Jie Zhu, Junhui Li, Muhua Zhu, Longhua Qian, Min Zhang, Guodong Zhou, arXiv:1909.00136arXiv preprintJie Zhu, Junhui Li, Muhua Zhu, Longhua Qian, Min Zhang, and Guodong Zhou. Modeling graph structure in transformer for better amr-to-text generation. arXiv preprint arXiv:1909.00136, 2019.\n", "annotations": {"author": "[{\"end\":118,\"start\":72},{\"end\":162,\"start\":119},{\"end\":165,\"start\":163},{\"end\":210,\"start\":166},{\"end\":213,\"start\":211},{\"end\":259,\"start\":214},{\"end\":301,\"start\":260}]", "publisher": null, "author_last_name": "[{\"end\":85,\"start\":82},{\"end\":126,\"start\":122},{\"end\":177,\"start\":174},{\"end\":226,\"start\":222},{\"end\":268,\"start\":265}]", "author_first_name": "[{\"end\":81,\"start\":72},{\"end\":121,\"start\":119},{\"end\":164,\"start\":163},{\"end\":173,\"start\":166},{\"end\":212,\"start\":211},{\"end\":221,\"start\":214},{\"end\":264,\"start\":260}]", "author_affiliation": "[{\"end\":117,\"start\":87},{\"end\":161,\"start\":128},{\"end\":209,\"start\":179},{\"end\":258,\"start\":228},{\"end\":300,\"start\":270}]", "title": "[{\"end\":69,\"start\":1},{\"end\":370,\"start\":302}]", "venue": null, "abstract": "[{\"end\":2049,\"start\":416}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b25\"},\"end\":2164,\"start\":2147},{\"end\":3269,\"start\":3250},{\"end\":3289,\"start\":3269},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":3307,\"start\":3289},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":3312,\"start\":3307},{\"end\":3358,\"start\":3337},{\"end\":3374,\"start\":3358},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3423,\"start\":3399},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":4030,\"start\":4007},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":4049,\"start\":4030},{\"end\":4148,\"start\":4129},{\"end\":4165,\"start\":4148},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":4183,\"start\":4165},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":4793,\"start\":4769},{\"end\":4897,\"start\":4873},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":5147,\"start\":5123},{\"end\":5170,\"start\":5147},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":5538,\"start\":5517},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":5557,\"start\":5538},{\"end\":5772,\"start\":5750},{\"end\":5817,\"start\":5800},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":8869,\"start\":8851},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":8888,\"start\":8869},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":9570,\"start\":9546},{\"end\":10748,\"start\":10742},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":12741,\"start\":12722},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":12902,\"start\":12887},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":15552,\"start\":15535},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":18417,\"start\":18394},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":18436,\"start\":18417},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":19216,\"start\":19195},{\"end\":19524,\"start\":19503},{\"end\":19594,\"start\":19567},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":19618,\"start\":19594},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":19683,\"start\":19665},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":19712,\"start\":19692},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":19746,\"start\":19728},{\"end\":19805,\"start\":19774},{\"end\":19960,\"start\":19938},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":20006,\"start\":19981},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":20111,\"start\":20091},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":20370,\"start\":20345},{\"end\":20387,\"start\":20370},{\"end\":20629,\"start\":20605},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":20645,\"start\":20629},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":21815,\"start\":21795},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":21832,\"start\":21815},{\"end\":21855,\"start\":21832},{\"end\":21873,\"start\":21855},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":21903,\"start\":21880},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":21936,\"start\":21912},{\"end\":28326,\"start\":28307},{\"end\":28346,\"start\":28326},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":28364,\"start\":28346},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":28369,\"start\":28364},{\"end\":28551,\"start\":28532},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":28569,\"start\":28551},{\"end\":28616,\"start\":28594},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":28634,\"start\":28616},{\"end\":28777,\"start\":28755},{\"end\":28800,\"start\":28777},{\"end\":29000,\"start\":28978},{\"end\":29022,\"start\":29000},{\"end\":29043,\"start\":29022},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":29062,\"start\":29043},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":29182,\"start\":29152},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":29230,\"start\":29212},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":29249,\"start\":29230},{\"end\":29251,\"start\":29249},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":29253,\"start\":29251},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":29478,\"start\":29459},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":29544,\"start\":29526},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":29561,\"start\":29544},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":29693,\"start\":29669},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":30634,\"start\":30616},{\"end\":30636,\"start\":30634},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":30652,\"start\":30636},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":30819,\"start\":30795},{\"end\":33442,\"start\":33421},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":34059,\"start\":34037},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":34220,\"start\":34203},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":34449,\"start\":34431},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":34616,\"start\":34596},{\"end\":35246,\"start\":35224},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":35300,\"start\":35275},{\"end\":35512,\"start\":35488},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":36989,\"start\":36964},{\"end\":37006,\"start\":36989},{\"end\":37748,\"start\":37728},{\"end\":38019,\"start\":37995},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":38865,\"start\":38841}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":38765,\"start\":38405},{\"attributes\":{\"id\":\"fig_1\"},\"end\":38819,\"start\":38766},{\"attributes\":{\"id\":\"fig_2\"},\"end\":38947,\"start\":38820},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":40307,\"start\":38948},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":40497,\"start\":40308},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":41750,\"start\":40498},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":42078,\"start\":41751},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":42149,\"start\":42079}]", "paragraph": "[{\"end\":2749,\"start\":2065},{\"end\":3870,\"start\":2751},{\"end\":4700,\"start\":3872},{\"end\":5921,\"start\":4702},{\"end\":7163,\"start\":5923},{\"end\":7366,\"start\":7165},{\"end\":7596,\"start\":7368},{\"end\":7683,\"start\":7598},{\"end\":7916,\"start\":7685},{\"end\":8488,\"start\":7941},{\"end\":8739,\"start\":8490},{\"end\":10216,\"start\":8763},{\"end\":10965,\"start\":10218},{\"end\":11703,\"start\":11149},{\"end\":12500,\"start\":11705},{\"end\":12989,\"start\":12502},{\"end\":13287,\"start\":12991},{\"end\":13481,\"start\":13289},{\"end\":13767,\"start\":13530},{\"end\":14071,\"start\":13806},{\"end\":14186,\"start\":14092},{\"end\":14409,\"start\":14188},{\"end\":14832,\"start\":14480},{\"end\":15388,\"start\":14866},{\"end\":15761,\"start\":15390},{\"end\":16381,\"start\":15839},{\"end\":16643,\"start\":16422},{\"end\":16890,\"start\":16645},{\"end\":17264,\"start\":16930},{\"end\":17529,\"start\":17314},{\"end\":17757,\"start\":17531},{\"end\":17930,\"start\":17806},{\"end\":18316,\"start\":18001},{\"end\":18919,\"start\":18328},{\"end\":19285,\"start\":18921},{\"end\":20323,\"start\":19309},{\"end\":24038,\"start\":20325},{\"end\":24760,\"start\":24089},{\"end\":25672,\"start\":24762},{\"end\":26295,\"start\":25693},{\"end\":26906,\"start\":26310},{\"end\":28252,\"start\":26942},{\"end\":28929,\"start\":28269},{\"end\":29870,\"start\":28931},{\"end\":30701,\"start\":29901},{\"end\":31033,\"start\":30769},{\"end\":31403,\"start\":31035},{\"end\":31930,\"start\":31405},{\"end\":32873,\"start\":31932},{\"end\":33242,\"start\":32907},{\"end\":33663,\"start\":33277},{\"end\":33747,\"start\":33665},{\"end\":34148,\"start\":33749},{\"end\":34418,\"start\":34192},{\"end\":34587,\"start\":34420},{\"end\":35029,\"start\":34589},{\"end\":35172,\"start\":35060},{\"end\":36124,\"start\":35174},{\"end\":36812,\"start\":36154},{\"end\":38404,\"start\":36846}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":11117,\"start\":10966},{\"attributes\":{\"id\":\"formula_1\"},\"end\":13529,\"start\":13482},{\"attributes\":{\"id\":\"formula_2\"},\"end\":13805,\"start\":13768},{\"attributes\":{\"id\":\"formula_3\"},\"end\":14091,\"start\":14072},{\"attributes\":{\"id\":\"formula_4\"},\"end\":14479,\"start\":14410},{\"attributes\":{\"id\":\"formula_5\"},\"end\":15838,\"start\":15762},{\"attributes\":{\"id\":\"formula_6\"},\"end\":16408,\"start\":16382},{\"attributes\":{\"id\":\"formula_7\"},\"end\":16929,\"start\":16891},{\"attributes\":{\"id\":\"formula_8\"},\"end\":17313,\"start\":17265},{\"attributes\":{\"id\":\"formula_9\"},\"end\":17805,\"start\":17758},{\"attributes\":{\"id\":\"formula_10\"},\"end\":18000,\"start\":17931}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":22804,\"start\":22797},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":24281,\"start\":24274},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":25712,\"start\":25705},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":25931,\"start\":25924},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":26456,\"start\":26449},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":27625,\"start\":27618}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2063,\"start\":2051},{\"attributes\":{\"n\":\"2\"},\"end\":7939,\"start\":7919},{\"attributes\":{\"n\":\"2.1\"},\"end\":8761,\"start\":8742},{\"attributes\":{\"n\":\"2.2.2\"},\"end\":11147,\"start\":11119},{\"attributes\":{\"n\":\"2.3\"},\"end\":14864,\"start\":14835},{\"attributes\":{\"n\":\"2.4\"},\"end\":16420,\"start\":16410},{\"attributes\":{\"n\":\"2.5\"},\"end\":18326,\"start\":18319},{\"attributes\":{\"n\":\"3\"},\"end\":19299,\"start\":19288},{\"attributes\":{\"n\":\"3.1\"},\"end\":19307,\"start\":19302},{\"attributes\":{\"n\":\"3.2\"},\"end\":24070,\"start\":24041},{\"attributes\":{\"n\":\"3.3\"},\"end\":24087,\"start\":24073},{\"attributes\":{\"n\":\"3.4\"},\"end\":25691,\"start\":25675},{\"attributes\":{\"n\":\"3.5\"},\"end\":26308,\"start\":26298},{\"attributes\":{\"n\":\"3.6\"},\"end\":26940,\"start\":26909},{\"attributes\":{\"n\":\"4\"},\"end\":28267,\"start\":28255},{\"attributes\":{\"n\":\"5\"},\"end\":29899,\"start\":29873},{\"attributes\":{\"n\":\"6\"},\"end\":30719,\"start\":30704},{\"end\":30732,\"start\":30722},{\"end\":30767,\"start\":30735},{\"end\":32905,\"start\":32876},{\"end\":33275,\"start\":33245},{\"end\":34180,\"start\":34151},{\"end\":34190,\"start\":34183},{\"end\":35058,\"start\":35032},{\"end\":36133,\"start\":36127},{\"end\":36152,\"start\":36136},{\"end\":36844,\"start\":36815},{\"end\":38412,\"start\":38406},{\"end\":38777,\"start\":38767},{\"end\":38958,\"start\":38949},{\"end\":40318,\"start\":40309},{\"end\":40508,\"start\":40499},{\"end\":41761,\"start\":41752},{\"end\":42089,\"start\":42080}]", "table": "[{\"end\":40307,\"start\":39017},{\"end\":40497,\"start\":40366},{\"end\":41750,\"start\":40563},{\"end\":42078,\"start\":41820}]", "figure_caption": "[{\"end\":38765,\"start\":38413},{\"end\":38819,\"start\":38779},{\"end\":38947,\"start\":38822},{\"end\":39017,\"start\":38960},{\"end\":40366,\"start\":40320},{\"end\":40563,\"start\":40510},{\"end\":41820,\"start\":41763},{\"end\":42149,\"start\":42091}]", "figure_ref": "[{\"end\":8033,\"start\":8025},{\"end\":8430,\"start\":8422},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":9986,\"start\":9978},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":31021,\"start\":31013},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":31189,\"start\":31181},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":31902,\"start\":31894},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":32177,\"start\":32169}]", "bib_author_first_name": "[{\"end\":42964,\"start\":42958},{\"end\":42992,\"start\":42983},{\"end\":43013,\"start\":43006},{\"end\":43313,\"start\":43304},{\"end\":43883,\"start\":43874},{\"end\":43899,\"start\":43895},{\"end\":43921,\"start\":43914},{\"end\":44174,\"start\":44165},{\"end\":44187,\"start\":44186},{\"end\":44203,\"start\":44194},{\"end\":44217,\"start\":44210},{\"end\":44452,\"start\":44449},{\"end\":44465,\"start\":44459},{\"end\":44477,\"start\":44473},{\"end\":44488,\"start\":44484},{\"end\":44830,\"start\":44823},{\"end\":44850,\"start\":44841},{\"end\":44862,\"start\":44856},{\"end\":45165,\"start\":45156},{\"end\":45180,\"start\":45176},{\"end\":45821,\"start\":45814},{\"end\":45837,\"start\":45831},{\"end\":45850,\"start\":45846},{\"end\":46166,\"start\":46160},{\"end\":46183,\"start\":46173},{\"end\":46199,\"start\":46193},{\"end\":46416,\"start\":46409},{\"end\":46592,\"start\":46588},{\"end\":46606,\"start\":46601},{\"end\":46623,\"start\":46616},{\"end\":46636,\"start\":46632},{\"end\":47017,\"start\":47013},{\"end\":47030,\"start\":47024},{\"end\":47039,\"start\":47036},{\"end\":47048,\"start\":47044},{\"end\":47056,\"start\":47053},{\"end\":47065,\"start\":47063},{\"end\":47370,\"start\":47368},{\"end\":47384,\"start\":47377},{\"end\":47397,\"start\":47389},{\"end\":47763,\"start\":47761},{\"end\":47777,\"start\":47770},{\"end\":47790,\"start\":47782},{\"end\":47792,\"start\":47791},{\"end\":48395,\"start\":48393},{\"end\":48409,\"start\":48402},{\"end\":48422,\"start\":48414},{\"end\":48424,\"start\":48423},{\"end\":48886,\"start\":48884},{\"end\":48900,\"start\":48893},{\"end\":48913,\"start\":48905},{\"end\":48915,\"start\":48914},{\"end\":49212,\"start\":49204},{\"end\":49224,\"start\":49217},{\"end\":49232,\"start\":49230},{\"end\":49240,\"start\":49237},{\"end\":49249,\"start\":49245},{\"end\":49262,\"start\":49255},{\"end\":49957,\"start\":49949},{\"end\":49966,\"start\":49963},{\"end\":49977,\"start\":49972},{\"end\":49979,\"start\":49978},{\"end\":49993,\"start\":49988},{\"end\":50007,\"start\":49998},{\"end\":50019,\"start\":50014},{\"end\":50547,\"start\":50537},{\"end\":50559,\"start\":50555},{\"end\":50579,\"start\":50566},{\"end\":50848,\"start\":50845},{\"end\":50858,\"start\":50853},{\"end\":50876,\"start\":50870},{\"end\":50890,\"start\":50884},{\"end\":50902,\"start\":50896},{\"end\":50910,\"start\":50908},{\"end\":50923,\"start\":50915},{\"end\":50934,\"start\":50930},{\"end\":50941,\"start\":50939},{\"end\":50950,\"start\":50946},{\"end\":51519,\"start\":51515},{\"end\":51544,\"start\":51537},{\"end\":51559,\"start\":51554},{\"end\":51908,\"start\":51901},{\"end\":51924,\"start\":51919},{\"end\":51937,\"start\":51933},{\"end\":51952,\"start\":51944},{\"end\":52488,\"start\":52485},{\"end\":52501,\"start\":52495},{\"end\":52516,\"start\":52508},{\"end\":52525,\"start\":52522},{\"end\":52535,\"start\":52531},{\"end\":52933,\"start\":52927},{\"end\":52947,\"start\":52943},{\"end\":52961,\"start\":52957},{\"end\":52975,\"start\":52970},{\"end\":52992,\"start\":52987},{\"end\":53005,\"start\":53000},{\"end\":53007,\"start\":53006},{\"end\":53021,\"start\":53015},{\"end\":53035,\"start\":53030},{\"end\":53365,\"start\":53360},{\"end\":53385,\"start\":53378},{\"end\":53397,\"start\":53396},{\"end\":53409,\"start\":53408},{\"end\":53419,\"start\":53418},{\"end\":53431,\"start\":53425},{\"end\":53679,\"start\":53676},{\"end\":53689,\"start\":53685},{\"end\":53699,\"start\":53696},{\"end\":53714,\"start\":53706},{\"end\":53726,\"start\":53719},{\"end\":53737,\"start\":53733},{\"end\":53750,\"start\":53742},{\"end\":54261,\"start\":54256},{\"end\":54269,\"start\":54267},{\"end\":54277,\"start\":54274},{\"end\":54288,\"start\":54283},{\"end\":54296,\"start\":54293},{\"end\":54621,\"start\":54615},{\"end\":54634,\"start\":54628},{\"end\":54644,\"start\":54641},{\"end\":55043,\"start\":55037},{\"end\":55056,\"start\":55050},{\"end\":55065,\"start\":55062},{\"end\":55493,\"start\":55486},{\"end\":55502,\"start\":55499},{\"end\":55512,\"start\":55507},{\"end\":55530,\"start\":55524},{\"end\":55542,\"start\":55536},{\"end\":55553,\"start\":55549},{\"end\":55566,\"start\":55559},{\"end\":55575,\"start\":55573},{\"end\":55589,\"start\":55580},{\"end\":55600,\"start\":55595},{\"end\":56167,\"start\":56160},{\"end\":56176,\"start\":56173},{\"end\":56187,\"start\":56181},{\"end\":56201,\"start\":56194},{\"end\":56210,\"start\":56206},{\"end\":56224,\"start\":56216},{\"end\":56483,\"start\":56480},{\"end\":56495,\"start\":56488},{\"end\":56506,\"start\":56500},{\"end\":56518,\"start\":56513},{\"end\":56783,\"start\":56780},{\"end\":56795,\"start\":56788},{\"end\":56806,\"start\":56800},{\"end\":56815,\"start\":56813},{\"end\":56825,\"start\":56820},{\"end\":56837,\"start\":56832},{\"end\":57116,\"start\":57110},{\"end\":57132,\"start\":57128},{\"end\":57146,\"start\":57140},{\"end\":57158,\"start\":57152},{\"end\":57473,\"start\":57469},{\"end\":57483,\"start\":57481},{\"end\":57496,\"start\":57490},{\"end\":57511,\"start\":57504},{\"end\":57523,\"start\":57517},{\"end\":57876,\"start\":57868},{\"end\":57888,\"start\":57883},{\"end\":58206,\"start\":58201},{\"end\":58222,\"start\":58213},{\"end\":58235,\"start\":58228},{\"end\":58250,\"start\":58242},{\"end\":58259,\"start\":58255},{\"end\":58660,\"start\":58657},{\"end\":58672,\"start\":58666},{\"end\":58682,\"start\":58677},{\"end\":58695,\"start\":58688},{\"end\":58705,\"start\":58702},{\"end\":58720,\"start\":58713}]", "bib_author_last_name": "[{\"end\":42981,\"start\":42965},{\"end\":43004,\"start\":42993},{\"end\":43017,\"start\":43014},{\"end\":43024,\"start\":43019},{\"end\":43323,\"start\":43314},{\"end\":43893,\"start\":43884},{\"end\":43912,\"start\":43900},{\"end\":43929,\"start\":43922},{\"end\":44184,\"start\":44175},{\"end\":44192,\"start\":44188},{\"end\":44208,\"start\":44204},{\"end\":44225,\"start\":44218},{\"end\":44233,\"start\":44227},{\"end\":44457,\"start\":44453},{\"end\":44471,\"start\":44466},{\"end\":44482,\"start\":44478},{\"end\":44494,\"start\":44489},{\"end\":44839,\"start\":44831},{\"end\":44854,\"start\":44851},{\"end\":44869,\"start\":44863},{\"end\":45174,\"start\":45166},{\"end\":45186,\"start\":45181},{\"end\":45829,\"start\":45822},{\"end\":45844,\"start\":45838},{\"end\":45859,\"start\":45851},{\"end\":46171,\"start\":46167},{\"end\":46191,\"start\":46184},{\"end\":46204,\"start\":46200},{\"end\":46424,\"start\":46417},{\"end\":46599,\"start\":46593},{\"end\":46614,\"start\":46607},{\"end\":46630,\"start\":46624},{\"end\":46644,\"start\":46637},{\"end\":47022,\"start\":47018},{\"end\":47034,\"start\":47031},{\"end\":47042,\"start\":47040},{\"end\":47051,\"start\":47049},{\"end\":47061,\"start\":47057},{\"end\":47069,\"start\":47066},{\"end\":47375,\"start\":47371},{\"end\":47387,\"start\":47385},{\"end\":47402,\"start\":47398},{\"end\":47768,\"start\":47764},{\"end\":47780,\"start\":47778},{\"end\":47797,\"start\":47793},{\"end\":48400,\"start\":48396},{\"end\":48412,\"start\":48410},{\"end\":48429,\"start\":48425},{\"end\":48891,\"start\":48887},{\"end\":48903,\"start\":48901},{\"end\":48920,\"start\":48916},{\"end\":49215,\"start\":49213},{\"end\":49228,\"start\":49225},{\"end\":49235,\"start\":49233},{\"end\":49243,\"start\":49241},{\"end\":49253,\"start\":49250},{\"end\":49267,\"start\":49263},{\"end\":49961,\"start\":49958},{\"end\":49970,\"start\":49967},{\"end\":49986,\"start\":49980},{\"end\":49996,\"start\":49994},{\"end\":50012,\"start\":50008},{\"end\":50024,\"start\":50020},{\"end\":50553,\"start\":50548},{\"end\":50564,\"start\":50560},{\"end\":50587,\"start\":50580},{\"end\":50851,\"start\":50849},{\"end\":50868,\"start\":50859},{\"end\":50882,\"start\":50877},{\"end\":50894,\"start\":50891},{\"end\":50906,\"start\":50903},{\"end\":50913,\"start\":50911},{\"end\":50928,\"start\":50924},{\"end\":50937,\"start\":50935},{\"end\":50944,\"start\":50942},{\"end\":50954,\"start\":50951},{\"end\":51535,\"start\":51520},{\"end\":51552,\"start\":51545},{\"end\":51567,\"start\":51560},{\"end\":51917,\"start\":51909},{\"end\":51931,\"start\":51925},{\"end\":51942,\"start\":51938},{\"end\":51956,\"start\":51953},{\"end\":52493,\"start\":52489},{\"end\":52506,\"start\":52502},{\"end\":52520,\"start\":52517},{\"end\":52529,\"start\":52526},{\"end\":52540,\"start\":52536},{\"end\":52545,\"start\":52542},{\"end\":52941,\"start\":52934},{\"end\":52955,\"start\":52948},{\"end\":52968,\"start\":52962},{\"end\":52985,\"start\":52976},{\"end\":52998,\"start\":52993},{\"end\":53013,\"start\":53008},{\"end\":53028,\"start\":53022},{\"end\":53046,\"start\":53036},{\"end\":53376,\"start\":53366},{\"end\":53394,\"start\":53386},{\"end\":53406,\"start\":53398},{\"end\":53416,\"start\":53410},{\"end\":53423,\"start\":53420},{\"end\":53438,\"start\":53432},{\"end\":53683,\"start\":53680},{\"end\":53694,\"start\":53690},{\"end\":53704,\"start\":53700},{\"end\":53717,\"start\":53715},{\"end\":53731,\"start\":53727},{\"end\":53740,\"start\":53738},{\"end\":53753,\"start\":53751},{\"end\":54265,\"start\":54262},{\"end\":54272,\"start\":54270},{\"end\":54281,\"start\":54278},{\"end\":54291,\"start\":54289},{\"end\":54300,\"start\":54297},{\"end\":54626,\"start\":54622},{\"end\":54639,\"start\":54635},{\"end\":54648,\"start\":54645},{\"end\":55048,\"start\":55044},{\"end\":55060,\"start\":55057},{\"end\":55069,\"start\":55066},{\"end\":55497,\"start\":55494},{\"end\":55505,\"start\":55503},{\"end\":55522,\"start\":55513},{\"end\":55534,\"start\":55531},{\"end\":55547,\"start\":55543},{\"end\":55557,\"start\":55554},{\"end\":55571,\"start\":55567},{\"end\":55578,\"start\":55576},{\"end\":55593,\"start\":55590},{\"end\":55604,\"start\":55601},{\"end\":56171,\"start\":56168},{\"end\":56179,\"start\":56177},{\"end\":56192,\"start\":56188},{\"end\":56204,\"start\":56202},{\"end\":56214,\"start\":56211},{\"end\":56227,\"start\":56225},{\"end\":56486,\"start\":56484},{\"end\":56498,\"start\":56496},{\"end\":56511,\"start\":56507},{\"end\":56526,\"start\":56519},{\"end\":56786,\"start\":56784},{\"end\":56798,\"start\":56796},{\"end\":56811,\"start\":56807},{\"end\":56818,\"start\":56816},{\"end\":56830,\"start\":56826},{\"end\":56845,\"start\":56838},{\"end\":57126,\"start\":57117},{\"end\":57138,\"start\":57133},{\"end\":57150,\"start\":57147},{\"end\":57164,\"start\":57159},{\"end\":57479,\"start\":57474},{\"end\":57488,\"start\":57484},{\"end\":57502,\"start\":57497},{\"end\":57515,\"start\":57512},{\"end\":57527,\"start\":57524},{\"end\":57881,\"start\":57877},{\"end\":57895,\"start\":57889},{\"end\":58211,\"start\":58207},{\"end\":58226,\"start\":58223},{\"end\":58240,\"start\":58236},{\"end\":58253,\"start\":58251},{\"end\":58263,\"start\":58260},{\"end\":58664,\"start\":58661},{\"end\":58675,\"start\":58673},{\"end\":58686,\"start\":58683},{\"end\":58700,\"start\":58696},{\"end\":58711,\"start\":58706},{\"end\":58725,\"start\":58721}]", "bib_entry": "[{\"attributes\":{\"doi\":\"arXiv:2005.00653\",\"id\":\"b0\"},\"end\":43226,\"start\":42898},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":56482376},\"end\":43828,\"start\":43228},{\"attributes\":{\"doi\":\"arXiv:1711.00740\",\"id\":\"b2\"},\"end\":44104,\"start\":43830},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":207591052},\"end\":44447,\"start\":44106},{\"attributes\":{\"doi\":\"arXiv:1808.01400\",\"id\":\"b4\"},\"end\":44750,\"start\":44449},{\"attributes\":{\"doi\":\"arXiv:1409.0473\",\"id\":\"b5\"},\"end\":45060,\"start\":44752},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":7164502},\"end\":45694,\"start\":45062},{\"attributes\":{\"doi\":\"arXiv:1707.02275\",\"id\":\"b7\"},\"end\":46096,\"start\":45696},{\"attributes\":{\"doi\":\"arXiv:1806.09835\",\"id\":\"b8\"},\"end\":46386,\"start\":46098},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":2242825},\"end\":46511,\"start\":46388},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":1820089},\"end\":46908,\"start\":46513},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":202539008},\"end\":47274,\"start\":46910},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":214003631},\"end\":47650,\"start\":47276},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":199064619},\"end\":48305,\"start\":47652},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":199577786},\"end\":48795,\"start\":48307},{\"attributes\":{\"doi\":\"arXiv:2004.06015\",\"id\":\"b15\"},\"end\":49120,\"start\":48797},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":199501946},\"end\":49871,\"start\":49122},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":52070089},\"end\":50467,\"start\":49873},{\"attributes\":{\"doi\":\"arXiv:1508.04025\",\"id\":\"b18\"},\"end\":50781,\"start\":50469},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":36353796},\"end\":51430,\"start\":50783},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":49317766},\"end\":51835,\"start\":51432},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":11080756},\"end\":52426,\"start\":51837},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":209439473},\"end\":52898,\"start\":52428},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":13756489},\"end\":53325,\"start\":52900},{\"attributes\":{\"doi\":\"abs/1710.10903\",\"id\":\"b24\"},\"end\":53595,\"start\":53327},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":52069701},\"end\":54200,\"start\":53597},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":202769028},\"end\":54533,\"start\":54202},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":10506832},\"end\":54965,\"start\":54535},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":16690920},\"end\":55405,\"start\":54967},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":195891060},\"end\":56096,\"start\":55407},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":199466350},\"end\":56402,\"start\":56098},{\"attributes\":{\"doi\":\"arXiv:1804.00823\",\"id\":\"b31\"},\"end\":56725,\"start\":56404},{\"attributes\":{\"doi\":\"arXiv:1809.05255\",\"id\":\"b32\"},\"end\":57040,\"start\":56727},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":2231082},\"end\":57417,\"start\":57042},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":211163834},\"end\":57866,\"start\":57419},{\"attributes\":{\"doi\":\"arXiv:1909.12223\",\"id\":\"b35\"},\"end\":58081,\"start\":57868},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":202539112},\"end\":58580,\"start\":58083},{\"attributes\":{\"doi\":\"arXiv:1909.00136\",\"id\":\"b37\"},\"end\":58944,\"start\":58582}]", "bib_title": "[{\"end\":43302,\"start\":43228},{\"end\":44163,\"start\":44106},{\"end\":45154,\"start\":45062},{\"end\":46407,\"start\":46388},{\"end\":46586,\"start\":46513},{\"end\":47011,\"start\":46910},{\"end\":47366,\"start\":47276},{\"end\":47759,\"start\":47652},{\"end\":48391,\"start\":48307},{\"end\":49202,\"start\":49122},{\"end\":49947,\"start\":49873},{\"end\":50843,\"start\":50783},{\"end\":51513,\"start\":51432},{\"end\":51899,\"start\":51837},{\"end\":52483,\"start\":52428},{\"end\":52925,\"start\":52900},{\"end\":53674,\"start\":53597},{\"end\":54254,\"start\":54202},{\"end\":54613,\"start\":54535},{\"end\":55035,\"start\":54967},{\"end\":55484,\"start\":55407},{\"end\":56158,\"start\":56098},{\"end\":57108,\"start\":57042},{\"end\":57467,\"start\":57419},{\"end\":58199,\"start\":58083}]", "bib_author": "[{\"end\":42983,\"start\":42958},{\"end\":43006,\"start\":42983},{\"end\":43019,\"start\":43006},{\"end\":43026,\"start\":43019},{\"end\":43325,\"start\":43304},{\"end\":43895,\"start\":43874},{\"end\":43914,\"start\":43895},{\"end\":43931,\"start\":43914},{\"end\":44186,\"start\":44165},{\"end\":44194,\"start\":44186},{\"end\":44210,\"start\":44194},{\"end\":44227,\"start\":44210},{\"end\":44235,\"start\":44227},{\"end\":44459,\"start\":44449},{\"end\":44473,\"start\":44459},{\"end\":44484,\"start\":44473},{\"end\":44496,\"start\":44484},{\"end\":44841,\"start\":44823},{\"end\":44856,\"start\":44841},{\"end\":44871,\"start\":44856},{\"end\":45176,\"start\":45156},{\"end\":45188,\"start\":45176},{\"end\":45831,\"start\":45814},{\"end\":45846,\"start\":45831},{\"end\":45861,\"start\":45846},{\"end\":46173,\"start\":46160},{\"end\":46193,\"start\":46173},{\"end\":46206,\"start\":46193},{\"end\":46426,\"start\":46409},{\"end\":46601,\"start\":46588},{\"end\":46616,\"start\":46601},{\"end\":46632,\"start\":46616},{\"end\":46646,\"start\":46632},{\"end\":47024,\"start\":47013},{\"end\":47036,\"start\":47024},{\"end\":47044,\"start\":47036},{\"end\":47053,\"start\":47044},{\"end\":47063,\"start\":47053},{\"end\":47071,\"start\":47063},{\"end\":47377,\"start\":47368},{\"end\":47389,\"start\":47377},{\"end\":47404,\"start\":47389},{\"end\":47770,\"start\":47761},{\"end\":47782,\"start\":47770},{\"end\":47799,\"start\":47782},{\"end\":48402,\"start\":48393},{\"end\":48414,\"start\":48402},{\"end\":48431,\"start\":48414},{\"end\":48893,\"start\":48884},{\"end\":48905,\"start\":48893},{\"end\":48922,\"start\":48905},{\"end\":49217,\"start\":49204},{\"end\":49230,\"start\":49217},{\"end\":49237,\"start\":49230},{\"end\":49245,\"start\":49237},{\"end\":49255,\"start\":49245},{\"end\":49269,\"start\":49255},{\"end\":49963,\"start\":49949},{\"end\":49972,\"start\":49963},{\"end\":49988,\"start\":49972},{\"end\":49998,\"start\":49988},{\"end\":50014,\"start\":49998},{\"end\":50026,\"start\":50014},{\"end\":50555,\"start\":50537},{\"end\":50566,\"start\":50555},{\"end\":50589,\"start\":50566},{\"end\":50853,\"start\":50845},{\"end\":50870,\"start\":50853},{\"end\":50884,\"start\":50870},{\"end\":50896,\"start\":50884},{\"end\":50908,\"start\":50896},{\"end\":50915,\"start\":50908},{\"end\":50930,\"start\":50915},{\"end\":50939,\"start\":50930},{\"end\":50946,\"start\":50939},{\"end\":50956,\"start\":50946},{\"end\":51537,\"start\":51515},{\"end\":51554,\"start\":51537},{\"end\":51569,\"start\":51554},{\"end\":51919,\"start\":51901},{\"end\":51933,\"start\":51919},{\"end\":51944,\"start\":51933},{\"end\":51958,\"start\":51944},{\"end\":52495,\"start\":52485},{\"end\":52508,\"start\":52495},{\"end\":52522,\"start\":52508},{\"end\":52531,\"start\":52522},{\"end\":52542,\"start\":52531},{\"end\":52547,\"start\":52542},{\"end\":52943,\"start\":52927},{\"end\":52957,\"start\":52943},{\"end\":52970,\"start\":52957},{\"end\":52987,\"start\":52970},{\"end\":53000,\"start\":52987},{\"end\":53015,\"start\":53000},{\"end\":53030,\"start\":53015},{\"end\":53048,\"start\":53030},{\"end\":53378,\"start\":53360},{\"end\":53396,\"start\":53378},{\"end\":53408,\"start\":53396},{\"end\":53418,\"start\":53408},{\"end\":53425,\"start\":53418},{\"end\":53440,\"start\":53425},{\"end\":53685,\"start\":53676},{\"end\":53696,\"start\":53685},{\"end\":53706,\"start\":53696},{\"end\":53719,\"start\":53706},{\"end\":53733,\"start\":53719},{\"end\":53742,\"start\":53733},{\"end\":53755,\"start\":53742},{\"end\":54267,\"start\":54256},{\"end\":54274,\"start\":54267},{\"end\":54283,\"start\":54274},{\"end\":54293,\"start\":54283},{\"end\":54302,\"start\":54293},{\"end\":54628,\"start\":54615},{\"end\":54641,\"start\":54628},{\"end\":54650,\"start\":54641},{\"end\":55050,\"start\":55037},{\"end\":55062,\"start\":55050},{\"end\":55071,\"start\":55062},{\"end\":55499,\"start\":55486},{\"end\":55507,\"start\":55499},{\"end\":55524,\"start\":55507},{\"end\":55536,\"start\":55524},{\"end\":55549,\"start\":55536},{\"end\":55559,\"start\":55549},{\"end\":55573,\"start\":55559},{\"end\":55580,\"start\":55573},{\"end\":55595,\"start\":55580},{\"end\":55606,\"start\":55595},{\"end\":56173,\"start\":56160},{\"end\":56181,\"start\":56173},{\"end\":56194,\"start\":56181},{\"end\":56206,\"start\":56194},{\"end\":56216,\"start\":56206},{\"end\":56229,\"start\":56216},{\"end\":56488,\"start\":56480},{\"end\":56500,\"start\":56488},{\"end\":56513,\"start\":56500},{\"end\":56528,\"start\":56513},{\"end\":56788,\"start\":56780},{\"end\":56800,\"start\":56788},{\"end\":56813,\"start\":56800},{\"end\":56820,\"start\":56813},{\"end\":56832,\"start\":56820},{\"end\":56847,\"start\":56832},{\"end\":57128,\"start\":57110},{\"end\":57140,\"start\":57128},{\"end\":57152,\"start\":57140},{\"end\":57166,\"start\":57152},{\"end\":57481,\"start\":57469},{\"end\":57490,\"start\":57481},{\"end\":57504,\"start\":57490},{\"end\":57517,\"start\":57504},{\"end\":57529,\"start\":57517},{\"end\":57883,\"start\":57868},{\"end\":57897,\"start\":57883},{\"end\":58213,\"start\":58201},{\"end\":58228,\"start\":58213},{\"end\":58242,\"start\":58228},{\"end\":58255,\"start\":58242},{\"end\":58265,\"start\":58255},{\"end\":58666,\"start\":58657},{\"end\":58677,\"start\":58666},{\"end\":58688,\"start\":58677},{\"end\":58702,\"start\":58688},{\"end\":58713,\"start\":58702},{\"end\":58727,\"start\":58713}]", "bib_venue": "[{\"end\":43576,\"start\":43459},{\"end\":45421,\"start\":45313},{\"end\":47964,\"start\":47890},{\"end\":48568,\"start\":48508},{\"end\":49550,\"start\":49418},{\"end\":50195,\"start\":50119},{\"end\":51125,\"start\":51049},{\"end\":52111,\"start\":52043},{\"end\":53924,\"start\":53848},{\"end\":55777,\"start\":55700},{\"end\":57660,\"start\":57603},{\"end\":42956,\"start\":42898},{\"end\":43457,\"start\":43325},{\"end\":43872,\"start\":43830},{\"end\":44263,\"start\":44235},{\"end\":44572,\"start\":44512},{\"end\":44821,\"start\":44752},{\"end\":45311,\"start\":45188},{\"end\":45812,\"start\":45696},{\"end\":46158,\"start\":46098},{\"end\":46433,\"start\":46426},{\"end\":46695,\"start\":46646},{\"end\":47075,\"start\":47071},{\"end\":47453,\"start\":47404},{\"end\":47888,\"start\":47799},{\"end\":48506,\"start\":48431},{\"end\":48882,\"start\":48797},{\"end\":49416,\"start\":49269},{\"end\":50117,\"start\":50026},{\"end\":50535,\"start\":50469},{\"end\":51047,\"start\":50956},{\"end\":51618,\"start\":51569},{\"end\":52041,\"start\":51958},{\"end\":52644,\"start\":52547},{\"end\":53097,\"start\":53048},{\"end\":53358,\"start\":53327},{\"end\":53846,\"start\":53755},{\"end\":54351,\"start\":54302},{\"end\":54728,\"start\":54650},{\"end\":55164,\"start\":55071},{\"end\":55698,\"start\":55606},{\"end\":56234,\"start\":56229},{\"end\":56478,\"start\":56404},{\"end\":56778,\"start\":56727},{\"end\":57209,\"start\":57166},{\"end\":57601,\"start\":57529},{\"end\":57953,\"start\":57913},{\"end\":58314,\"start\":58265},{\"end\":58655,\"start\":58582}]"}}}, "year": 2023, "month": 12, "day": 17}