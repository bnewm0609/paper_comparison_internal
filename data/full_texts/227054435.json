{"id": 227054435, "updated": "2023-10-06 08:38:30.688", "metadata": {"title": "Cylindrical and Asymmetrical 3D Convolution Networks for LiDAR Segmentation", "authors": "[{\"first\":\"Xinge\",\"last\":\"Zhu\",\"middle\":[]},{\"first\":\"Hui\",\"last\":\"Zhou\",\"middle\":[]},{\"first\":\"Tai\",\"last\":\"Wang\",\"middle\":[]},{\"first\":\"Fangzhou\",\"last\":\"Hong\",\"middle\":[]},{\"first\":\"Yuexin\",\"last\":\"Ma\",\"middle\":[]},{\"first\":\"Wei\",\"last\":\"Li\",\"middle\":[]},{\"first\":\"Hongsheng\",\"last\":\"Li\",\"middle\":[]},{\"first\":\"Dahua\",\"last\":\"Lin\",\"middle\":[]}]", "venue": "ArXiv", "journal": "ArXiv", "publication_date": {"year": 2020, "month": 11, "day": 19}, "abstract": "State-of-the-art methods for large-scale driving-scene LiDAR segmentation often project the point clouds to 2D space and then process them via 2D convolution. Although this corporation shows the competitiveness in the point cloud, it inevitably alters and abandons the 3D topology and geometric relations. A natural remedy is to utilize the3D voxelization and 3D convolution network. However, we found that in the outdoor point cloud, the improvement obtained in this way is quite limited. An important reason is the property of the outdoor point cloud, namely sparsity and varying density. Motivated by this investigation, we propose a new framework for the outdoor LiDAR segmentation, where cylindrical partition and asymmetrical 3D convolution networks are designed to explore the 3D geometric pat-tern while maintaining these inherent properties. Moreover, a point-wise refinement module is introduced to alleviate the interference of lossy voxel-based label encoding. We evaluate the proposed model on two large-scale datasets, i.e., SemanticKITTI and nuScenes. Our method achieves the 1st place in the leaderboard of SemanticKITTI and outperforms existing methods on nuScenes with a noticeable margin, about 4%. Furthermore, the proposed 3D framework also generalizes well to LiDAR panoptic segmentation and LiDAR 3D detection.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2011.10033", "mag": "3105266714", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/cvpr/Zhu0WHM00L21", "doi": "10.1109/cvpr46437.2021.00981"}}, "content": {"source": {"pdf_hash": "bf872d5e3fcf46f44a1b9dd76ee0db9a8cc98e06", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2011.10033v1.pdf\"]", "oa_url_match": true, "oa_info": {"license": null, "open_access_url": "http://arxiv.org/pdf/2011.10033", "status": "GREEN"}}, "grobid": {"id": "0dbc0abbded632a218b3c82bf4ed3eae69da8b6c", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/bf872d5e3fcf46f44a1b9dd76ee0db9a8cc98e06.txt", "contents": "\nCylindrical and Asymmetrical 3D Convolution Networks for LiDAR Segmentation\n\n\nXinge Zhu \nChinese University of Hong Kong\nShanghaiTech University Inceptio \u2021 Nanyang Technological University\n\n\nHui Zhou \nChinese University of Hong Kong\nShanghaiTech University Inceptio \u2021 Nanyang Technological University\n\n\nTai Wang \nChinese University of Hong Kong\nShanghaiTech University Inceptio \u2021 Nanyang Technological University\n\n\nFangzhou Hong \nChinese University of Hong Kong\nShanghaiTech University Inceptio \u2021 Nanyang Technological University\n\n\nYuexin Ma \nChinese University of Hong Kong\nShanghaiTech University Inceptio \u2021 Nanyang Technological University\n\n\nWei Li \nChinese University of Hong Kong\nShanghaiTech University Inceptio \u2021 Nanyang Technological University\n\n\nHongsheng Li \nChinese University of Hong Kong\nShanghaiTech University Inceptio \u2021 Nanyang Technological University\n\n\nDahua Lin \nChinese University of Hong Kong\nShanghaiTech University Inceptio \u2021 Nanyang Technological University\n\n\nCylindrical and Asymmetrical 3D Convolution Networks for LiDAR Segmentation\n\nState-of-the-art methods for large-scale driving-scene LiDAR segmentation often project the point clouds to 2D space and then process them via 2D convolution. Although this corporation shows the competitiveness in the point cloud, it inevitably alters and abandons the 3D topology and geometric relations. A natural remedy is to utilize the 3D voxelization and 3D convolution network. However, we found that in the outdoor point cloud, the improvement obtained in this way is quite limited. An important reason is the property of the outdoor point cloud, namely sparsity and varying density. Motivated by this investigation, we propose a new framework for the outdoor LiDAR segmentation, where cylindrical partition and asymmetrical 3D convolution networks are designed to explore the 3D geometric pattern while maintaining these inherent properties. Moreover, a point-wise refinement module is introduced to alleviate the interference of lossy voxel-based label encoding. We evaluate the proposed model on two large-scale datasets, i.e., SemanticKITTI and nuScenes. Our method achieves the 1st place in the leaderboard of SemanticKITTI 1 and outperforms existing methods on nuScenes with a noticeable margin, about 4%. Furthermore, the proposed 3D framework also generalizes well to LiDAR panoptic segmentation and LiDAR 3D detection.\n\nIntroduction\n\n3D LiDAR sensor has become an indispensable device in modern autonomous driving vehicles. It captures more precise and farther-away distance measurements of the surrounding environments than conventional visual cameras. The measurements of the sensor naturally form 3D point clouds that can be used to realize a thorough scene under-standing for autonomous driving planning and execution, in which LiDAR segmentation is crucial for driving-scene understanding. It aims to identify the pre-defined categories of each 3D point, such as car, truck, pedestrian, etc., which provides point-wise perception information of the overall 3D scene.\n\nRecently, the advances in deep learning have significantly pushed forward the state of the art in image segmentation. Some existing LiDAR segmentation approaches follow this route to project the 3D point clouds onto a 2D space and process them via 2D convolution networks, including range image based [27,42] and bird's-eye-view image based [51]. However, this group of methods lose and alter the accurate 3D geometric information during the 3Dto-2D projection (as shown in the top row of Fig. 1a).\n\nA natural alternative is to utilize the 3D partition and 3D convolution networks to process the point cloud and maintain their 3D geometric relations. However, in our initial attempts, we directly apply the 3D voxelization [14,9] and 3D convolution networks to outdoor LiDAR point cloud, only to find very limited performance gain (as shown in Fig. 1b). Our investigation into this issue reveals a key difficulty of outdoor LiDAR point cloud, namely sparsity and varying density, which is also the key difference to indoor scenes with dense and uniform-density points. However, previous 3D voxelization methods consider the point cloud as a uniform one and split them via the uniform cube, while neglecting the varying-density property of outdoor point cloud. Consequently, this effect to apply the 3D partition to outdoor point cloud is met with fundamental difficulty.\n\nMotivated by these findings, we propose a new framework to outdoor LiDAR segmentation that consists of two key components, i.e., 3D cylindrical partition and asymmetrical 3D convolution networks, which maintain the 3D geometric information and handle these issues from partition and networks, respectively. Here, cylindrical partition resorts to the cylinder coordinates to divide the point cloud dynamically according to the distance (Regions that are far  Figure 1: (a) Range Image (2D projection) v.s. Cubic Partition v.s. Cylindrical Partition. From top row, it can be found that range image abandons the 3D topology, where 2d convolution processes points in different locations (far away from each other in green circles). From bottom part, cylindrical partition generates the more balanced point distribution than cubic partition (89% v.s. 61% cells containing points). (b) Applying the regular 3D voxel partition and 3D convolution directly (i.e., 3DVoxel) gets limited performance gain compared to projection-based (2D) methods [51,16,27,45], while our method achieves a remarkable performance gain by further tackling the inherent difficulty of outdoor LiDAR point clouds (showing results on SemanticKITTI dataset).\n\naway from the origin have much sparse points, thus requiring a larger cell), which produces a more balanced point distribution (as shown in Fig. 1a); while asymmetrical 3D convolution networks strengthen the horizontal and vertical kernels to match the point distribution of objects in the driving scene and enhance the robustness to the sparsity. Moreover, voxel based methods might divide the points with different categories into the same cell and cell label encoding would inevitably cause the information loss. To alleviate the interference of lossy label encoding, a pointwise module is introduced to further refine the features obtained from voxel-based network. Overall, the corporation of these components well maintains the geometric relation and tackle the difficulty of outdoor point cloud, thus improving the effectiveness of 3D frameworks.\n\nWe evaluate the proposed method on two largescale outdoor datasets, including SemanticKITTI [2] and nuScenes [5]. Our method achieves the 1st place in the leaderboard of SemanticKITTI and also outperforms the existing methods on nuScenes with a large margin. We also extend the proposed cylindrical partition and asymmetrical 3D convolution networks to LiDAR panoptic segmentation and LiDAR 3D detection. Experimental results show its strong generalization capability and scalability.\n\nThe contributions of this work mainly lie in three aspects: (1) We reposition the focus of outdoor LiDAR segmentation from 2D projection to 3D structure, and further investigate the inherent properties (difficulties) of outdoor point cloud. (2) We introduce a new framework to explore the 3D geometric pattern and tackle these difficulties caused by sparsity and varying density, through cylindrical partition and asymmetrical 3D convolution networks.\n\n(3) The proposed method achieves the state of art on Se-manticKITTI and nuScenes, and also shows strong generalization capability on LiDAR panoptic segmentation and LiDAR 3D detection.\n\n\nRelated Work\n\nIndoor-scene Point Cloud Segmentation. Indoorscene point clouds carry out some properties, including generally uniform density, small number of points, and small range of the scene. Mainstream methods [29,36,44,41,37,24,12,50,46,38,28,30] of indoor point cloud segmentation learn the point features based on the raw point directly, which are often based on the pioneering work, i.e., Point-Net, and promote the effectiveness of sampling, grouping and ordering to achieve the better performance. Another group of methods utilize the clustering algorithm [41,37] to extract the hierarchical point features. However, these methods focusing on indoor point cloud are limited to adapt to the outdoor point cloud under the property of varying density and large range of scenes, and the large number of points also result in the computational difficulties for these methods when deploying from indoor to outdoor.\n\nOutdoor-scene Point Cloud Segmentation. Most existing outdoor-scene point cloud segmentation methods [16,10,27,1,48,20] focus on converting the 3D point cloud to 2D grids, to enable the usage of 2D Convolutional Neural Networks. SqueezeSeg [42], Darknet [2], Squeeze-Segv2 [43], and RangeNet++ [27] utilize the spherical projection mechanism, which converts the point cloud to a frontal-view image or a range image, and adopt the 2D convolution network on the pseudo image for point cloud seg- mentation. PolarNet [51] follows the bird's-eye-view projection, which projects point cloud data into bird's-eye-view representation under the polar coordinates. However, these 3D-to-2D projection methods inevitably loss and alter the 3D topology and fails to model the geometric information.\n\n3D Voxel Partition. 3D voxel partition is another routine of point cloud encoding [15,35,14,9,25]. It converts a point cloud into 3D voxels, which mainly retains the 3D geometric information. OccuSeg [15], SSCN [14] and SEG-Cloud [35] follow this line to utilize the voxel partition and apply regular 3D convolutions for LiDAR segmentation. It is worth noting that while the aforementioned efforts have shown encouraging results, the improvement in the outdoor LiDAR point cloud remains limited. As mentioned above, a common issue is that these methods neglect the inherent properties of outdoor LiDAR point cloud, namely, sparsity and varying density. Compared to these methods, our proposed method resorts to the 3D cylindrical partition and asymmetrical 3D convolution networks to tackle these difficulties.\n\nNetwork Architectures for Segmentation. Fully Convolutional Network [23] is the fundamental work in the deep-learning era. Built upon the FCN, many works aim to improve the performance via exploring the dilated convolution, multi-scale context modeling and attention modeling, including DeepLab [6,7] and PSP [52]. Recent work utilizes the neural architecture search to find the more effective backbone for the segmentation [22,33]. Moreover, U-Net [31] proposes a symmetric architecture to incorpo-rate the low-level features. With the great success of U-Net on 2D benchmarks and its good flexibility , many studies for LiDAR segmentation adapt the U-Net to the 3D space [9]. We also follow this structure to construct our asymmetrical 3D convolution networks.\n\n\nMethodology\n\n\nFramework Overview\n\nIn the context of semantic segmentation, given a point cloud, our task is to assign the semantic label to each point. Based on the comparison between 2D and 3D representation and investigation of the inherent properties of outdoor LiDAR point cloud, we desire to obtain a framework which explores the 3D geometric information and handles the difficulty caused by sparsity and varying-density. To this end, we propose a new outdoor segmentation approach based on the 3D partition and 3D convolution networks. To handle these difficulties of outdoor LiDAR point cloud, namely sparsity and varying density, we first employ the cylindrical partition to generate the more balanced point distribution (more robust to varying density), then apply the asymmetrical 3D convolution networks to power the horizontal and vertical weights, thus well matching the object point distribution in driving scene and enhancing the robustness to the sparsity.\n\nAs shown in the top half of Fig. 2, the framework consists of two major components, including cylindrical partition and asymmetrical 3D convolution networks. The Li- DAR point cloud is first divided by the cylindrical partition and the features extracted from MLP is then reassigned based on this partition. Asymmetrical 3D convolution networks are then used to generate the voxel-wise outputs. Finally, a point-wise module is introduced to alleviate the interference of lossy cell-label encoding, thus refining the outputs. In the following sections, we will present these components in detail.\n\n\nCylindrical Partition\n\nAs mentioned above, outdoor-scene LiDAR point cloud possesses the property of varying density, where nearby region has much greater density than farther-away region. Therefore, uniform cells splitting the varying-density points would fall into an imbalanced distribution (for example, larger proportion of empty cells). While in the cylinder coordinate system, it utilizes the increasing grid size to cover the farther-away region, and thus more evenly distributes the points across different regions and gives an more balanced representation against the varying density. We perform a statistic to show the proportion of non-empty cells across different distances in Fig. 3. It can be found that with the distance goes far, cylindrical partition maintains a balanced non-empty proportion due to the increasing grid size while cubic partition suffers the imbalanced distribution, especially in the farther-away regions (about 6 times less than cylindrical partition). Moreover, unlike these projectionbased methods project the point to the 2D view, cylindrical partition maintains the 3D grid representation to retain the geometric structure.\n\nThe workflow is illustrated in Fig. 4. We first transform the points on Cartesian coordinate system to the Cylinder coordinate system. This step transforms the points (x, y, z) to points (\u03c1, \u03b8, z), where radius \u03c1 (distance to origin in x-y axis) and azimuth \u03b8 (angle from x-axis to y-axis) are calculated. Then cylindrical partition performs the split on these three dimensions, note that in the cylinder coordinate, more farther-away region, larger cell. Point-wise features obtained from the MLP are reassigned based on the result of this partition to get the cylindrical features. After these steps, we unroll the cylinder from 0-degree and get the 3D cylindrical representation R \u2208 C \u00d7 H \u00d7 W \u00d7 L, where C denotes the feature dimension and H, W, L mean the radius, azimuth and height. Subsequent asymmetrical 3D convolution networks will be performing on this representation.\n\n\nAsymmetrical 3D Convolution Network\n\nSince the driving-scene point cloud carries out the specific object shape distribution, including car, truck, bus, motorcycle and other cubic objects, we aim to follow this observation to enhance the representational power of a standard 3D convolution. Moreover, recent literature [40,11] also shows that the central crisscross weights count more in the square convolution kernel. In this way, we devise the asymmetrical residual block to strengthen the horizontal and vertical responses and match the object point distribution. Based on the proposed asymmetrical residual block, we further build the asymmetrical downsample block and asymmetrical upsample block to perform the downsample and upsample operation. Moreover, a dimensiondecomposition based context modeling (termed as DDCM) is introduced to explore the high-rank global context in decomposite-aggregate strategy. We detail these components in the bottom of Fig. 2 Asymmetrical Residual Block Motivated by the observation and conclusion in [40,11], the asymmetrical residual block strengthens the horizontal and vertical kernels, which matches the point distribution of object in the driving scene and explicitly makes the skeleton of the kernel powerful, thus enhancing the robustness to the sparsity of outdoor Li-DAR point cloud. We use the Car and Motorcycle as the example to show the asymmetrical residual block in Fig. 5,  where 3D convolutions are performing on the cylindrical grids. Moreover, the proposed asymmetrical residual block also saves the computation and memory cost compared to the regular square-kernel 3D convolution block. By incorporating the asymmetrical residual block, the asymmetrical downsample block and upsample block are designed and our asymmetrical 3D convolution networks are built via stacking these downsample and upsample blocks.\n\n\nDimension-Decomposition based Context Modeling\n\nSince the global context features should be high-rank to have enough capacity to capture the large context varieties [49], it is hard to construct these features directly. We follow the tensor decomposition theory [8] to build the high-rank context as a combination of low-rank tensors, where we use three rank-1 kernels to obtain the low-rank features and then aggregate them together to get the final global context.\n\n\nPoint-wise Refinement Module\n\nPartition-based methods predict one label for each cell. Although partition-based methods effectively explore the large-range point cloud, however, this group of method, including cube-based and cylinder-based, inevitably suffers from the lossy cell-label encoding, e.g., points with different categories are divided into same cell, and this case would cause the information loss. We make a statistic to show the effect of different label encoding methods in Fig. 6, where majority encoding means using the major category of points inside a cell as the cell label and minority encoding indicates using the minor category as the cell label. It can be observed that both of them cannot reach the 100 percent mIoU (ideal encoding) and inevitably have the information loss. Here, the point-wise refinement module is introduced to alleviate the interference of lossy cell-label encoding. We first project the voxel-wise features to the point-wise based on the point-voxel mapping  Figure 6: Upper bound of mIoU with different label encoding methods (i.e., majority and minority encoding). It can be found that no matter what encoding methods are, the information loss always occurs, which is also the reason for point-wise refinement.\n\nafter 3D convolution networks as the input, and fuses them together to refine the output.\n\n\nObjective Function\n\nThe total objective of our method consists of two components, including voxel-wise loss and point-wise loss. It can be formulated as L = L voxel + L point . For the voxel-wise loss (L voxel ), we follow the existing methods [10,16] and use the weighted cross-entropy loss and lovasz-softmax [4] loss to maximize the point accuracy and the intersectionover-union score, respectively. For point-wise loss (L point ), we only use the weighted cross-entropy loss to supervise the training. During inference, the output from point-wise refinement module is used as the final output. For the optimizer, Adam with an initial learning rate of 1e \u22123 is employed.\n\n\nExperiments\n\nIn this section, we first provide the detailed experimental setup, then evaluate the proposed method on two largescale datasets, i.e., SemanticKITTI and nuScenes. Furthermore, extensive ablation studies are conducted to validate each component. In the end, we extend our method to Li-DAR panoptic segmentation and 3D detection to verify its scalability and generalization ability.\n\n\nDataset and Metric\n\nSemanticKITTI [2] is a large-scale driving-scene dataset for point cloud segmentation, including semantic segmentation and panoptic segmentation. It is derived from the   KITTI Vision Odometry Benchmark and collected in Germany with the Velodyne-HDLE64 LiDAR. The dataset consists of 22 sequences, splitting sequences 00 to 10 as training set (where sequence 08 is used as the validation set), and sequences 11 to 21 as test set. 19 classes are remained for training and evaluation after merging classes with different moving status and ignore classes with very few points.\n- - - - - - - - - - - - - - - - - -\nnuScenes [5] It collects 1000 scenes of 20s duration with 32 beams LiDAR sensor. The number of total frames is 40,000, which is sampled at 20Hz. They also officially split the data into training and validation set. After merging similar classes and removing rare classes, total 16 classes for the LiDAR semantic segmentation are remained.\n\nFor both two datasets, cylindrical partition splits these point clouds into 3D representation with the size = 480 \u00d7 360 \u00d7 32, where three dimensions indicate the radius, angle and height, respectively.\n\nEvaluation Metric To evaluate the proposed method, we follow the official guidance to leverage mean intersectionover-union (mIoU) as the evaluation metric defined in [2,5], which can be formulated as:\nIoU i = T Pi\nT Pi+F Pi+F Ni where T P i , F P i , F N i represent true positive, false positive, and false negative predictions for class i and the mIoU is the mean value of IoU i over all classes.\n\n\nResults on SemanticKITTI\n\nIn this experiment, we compare the results of our proposed method with existing state-of-the-art LiDAR segmentation methods on SemanticKITTI test set. As shown in Table 1, our method outperforms all existing methods in term of mIoU. Compared to the projection-based methods on 2D space, including Darknet53 [2], SqueezeSegv3 [45], RangeNet++ [27] and PolarNet [51], our method achieves 8% \u223c 17% performance gain in term of mIoU due to the modeling of 3D geometric information. Compared to some voxel partition and 3D convolution based methods, including FusionNet [48], TORANDONet [13] (multi-view fusion based method) and SPVNAS [33] (utilizing the neural architecture search for LiDAR segmentation), the proposed method also performs better than these 3D convolution based methods, where the cylindrical partition and asymmetrical 3D convolution networks well handle the difficulty of driving-scene LiDAR point cloud that is neglected by these methods.\n\n\nResults on nuScenes\n\nSince nuScenes dataset does not release the evaluation server for LiDAR segmentation, we report the results on the validation set, where RangeNet++ and Salsanext per- form the post-processing. As shown in Table 2, our method achieves better performance than existing methods in all categories. Specifically, the proposed method obtains about 4% \u223c 7% performance gain than projection-based methods. Moreover, for these categories with sparse points, such as bicycle and pedestrian, our method significantly outperforms existing approaches, which also demonstrates the effectiveness of the proposed method to tackle the sparsity and varying density.\n\n\nAblation Studies\n\nIn this section, we perform the thorough ablation experiments to investigate the effect of different components in our method. We also design several variants of asymmetrical residual block to verify our claim that strengthening the horizontal and vertical kernels power the representation ability for driving-scene point cloud.\n\n\nEffects of Network Components\n\nIn this part, we make several variants of our model to validate the contributions of different components. The results on SemanticKITTI validation set are reported in Table 3. Baseline method denotes the framework using 3D voxel partition and 3D convolution networks. It can be observed that cylindrical partition performs much better than cubic-based partition with about 3% mIoU gain and asymmetrical 3D convolution networks also significantly boost the performance about 3% improvement, which demonstrates that both cylindrical partition and asymmetrical 3D convolution networks are crucial in the proposed method. Furthermore, dimension-decomposition based context modeling delivers the effective global context features, which yields an improvement of 1.4%. Point-wise refinement module further pushes forward the performance based on the strong model, about 0.7%.\n\n\nVariants of Asymmetrical Residual Block\n\nTo verify the effectiveness of the proposed asymmetrical residual block, we design several variants of asymmetrical residual block to investigate the effect of horizontal and vertical kernel enhancement (as shown in Fig. 7). The first variant is the regular residual block without any asymmetrical structure. The second one is the 1D-asymmetrical residual block, which utilizes the 1D asymmetrical kernels without height and  also strengthens the horizontal and vertical kernels in onedimension.\n\nWe conduct the ablation studies on SemanticKITTI validation set. Note that we use the cylindrical partition as the partition method and stack these proposed variants to build the 3D convolution networks. We report the results in Table 4. It can be found that although the 1D-Asymmetrical residual block only powers the horizontal and vertical kernels in one-dimension without considering the height, it still achieves 1.3% gain in term of mIoU, which demonstrates the effectiveness of horizontal and vertical kernel strengthening. After taking the height into the consideration, the proposed asymmetrical residual block further matches the object distribution in driving scene and powers the skeleton of kernels to enhance the robustness to the sparsity. From Table 4, the proposed asymmetrical residual block significantly boosts the performance with about 3% improvements, where large improvement can be observed on some instance categories (about 10% gain), including truck, person and motorcycle, because it matches the point distribution of object and enhances the representational power.\n\n\nGeneralization Analyses\n\nIn this section, we extend the proposed cylindrical partition and asymmetrical 3D convolution networks to other LiDAR-based tasks, including LiDAR panoptic segmentation and LiDAR 3D detection. These experimental results demonstrate the generalization ability of our proposed method and its effectiveness on LiDAR point cloud processing. In what follows, we will describe these two tasks and present how we adapt the proposed model in details.  Generalize to LiDAR Panoptic Segmentation Panoptic segmentation is first proposed in [18] as a new task, in which semantic segmentation is performed for background classes and instance segmentation for foreground classes and these two groups of category are also termed as stuff and things classes, respectively. Behley et al. [3] extend the task to LiDAR point clouds and propose the LiDAR panoptic segmentation. In this experiment, we conduct the panoptic segmentation on SemanticKITTI dataset and report results on the validation set. For the evaluation metrics, we follow the metrics defined in [3], where they are the same as that of image panoptic segmentation defined in [18] including Panoptic Quality (PQ), Segmentation Quality (SQ) and Recognition Quality (RQ) which are calculated across all classes. PQ \u2020 is defined by swapping PQ of each stuff class to its IoU and averaging over all classes like PQ does. Since the categories in panoptic segmentation contain two groups, i.e., stuff and things, these metrics are also performed separately on these two groups, including PQ Th , PQ St , RQ Th , RQ St , SQ Th and SQ St , where Panoptic Quality (PQ) is usually used as the first criteria.\n\nIn this experiment, we use the proposed cylindrical partition as the partition method and asymmetrical 3D convolution networks as the backbone. Moreover, a semantic branch is used to output the semantic labels for stuff categories, and an instance branch is introduced to generate the instance-level features and further extract their instance IDs for things categories through heuristic clustering algorithms (we use mean-shift in the implementation).\n\nWe report the results in Table 5. It can be found that our method achieves much better performance than existing methods [26,17]. In terms of PQ, we have about 4.7% point improvement, and particularly for the thing categories, our method significantly outperforms state-of-the-art in terms of PQ Th and PQ St with a large margin of 10% points. Experimental results demonstrate the effectiveness of the proposed method and its good generalization ability.\n\nGeneralize to LiDAR 3D Detection LiDAR 3D detection aims to localize and classify the multi-class objects in the point cloud. SECOND [47] first utilizes the 3D voxelization and 3D convolution networks to perform the single-stage 3D detection. In this experiment, we follow SECOND method and replace the regular voxelization and 3D convolution with the proposed cylindrical partition and asymmetrical 3D convolution networks, respectively. Similarly, to verify its scalability, we also extend the proposed modules to SSN [53]. The experiments are conducted on nuScenes dataset and the cylindrical partition also generates the 480 \u00d7 360 \u00d7 32 representation. For the evaluation metrics, we follow the official metrics defined in nuScenes, i.e., mean average precision (mAP) and nuScenes detection score (NDS).\n\nThe results are shown in Table 6. PP + Reconfig [39] is a partition enhancement approach based on PointPillar [21], while our SECOND + CyAs performs better with similar backbone, which indicates the superiority of the cylindrical partition. We then extend the proposed method (i.e., CyAs) to two baseline methods, termed as SECOND + CyAs and SSN + CyAs, respectively. By comparing these two models with their extensions, it can be observed that the proposed Cylindrical partition and Asymmetrical 3D convolution networks boost the performance consistently, even for the strong baseline i.e., SSN, which demonstrates the effectiveness and scalability of our model.\n\n\nConclusion\n\nIn this paper, we have proposed a cylindrical and asymmetrical 3D convolution networks for LiDAR segmentation, where it maintains the 3D geometric relation. Specifically, two key components, the cylinder partition and asymmetrical 3D convolution networks, are designed to handle the inherent difficulties in outdoor LiDAR point cloud, namely sparsity and varying density, effectively and robustly. We conduct the extensive experiments and ablation studies, where the model achieves the 1st place in SemanticKITTI and state-of-the-art in nuScenes, and keeps good generalization ability to other LiDAR based tasks, including LiDAR panoptic segmentation and LiDAR 3D detection.\n\nFigure 2 :\n2(1): Top half is the overall framework. Here, LiDAR point cloud is fed into MLP to get the point-wise features and then these features are reassigned based on the cylinderical partition. Asymmetrical 3D convolution networks are then used to generate the voxel-wise outputs. Finally, a point-wise module is introduced to refine these outputs.(2): Bottom half elaborates four components, including Asymmetrical Downsample block (AD), Asymmetrical Upsample blcok (AU), Asymmetrical residual block (A) and Dimension-Decomposition based Context Modeling (DDCM).\n\nFigure 3 :\n3The proportion of non-empty cells at different distances between cylindrical and cubic partition (The results are calculated on the training set of SemanticKITTI). It can be found that cylinder partition makes a higher non-empty proportion and more balanced point distribution, especially for farther-away regions.\n\nFigure 4 :\n4The pipeline of cylindrical partition. We first transform the Cartesian coordinate to Cylinder coordinate and then assign the point-wise features to the structured representation based on the cylindrical partition.\n\nFigure 5 :\n5An illustration of asymmetrical residual block, where two asymmetrical kernels are stacked to power the skeleton. It can be observed that asymmetrical residual block focuses on the horizontal and vertical kernels.\n\nFigure 7 :\n7We design three blocks for ablation studies of asymmetrical residual block, including (1) regular residual block , (2) 1D-asymmetrical residual block without height and (3) the proposed asymmetrical residual block.\n\n\ntable. Then the point-wise module takes both point features before andcar \nbicycle \nmotorcycle \nperson \nparking \nsidewalk \nfence \ntrunk \npole \nvegetation \nroad \n\n1.00 \n\n0.98 \n\n0.96 \n\n0.94 \n\n0.92 \n\n0.90 \n\n0.88 \n\n0.86 \n\nideal encoding \nmajority encoding \nminority encoding \n\n\n\nTable 1 :\n1Results of our proposed method and state-of-the-art LiDAR Segmentation methods on SemanticKITTI test set. Note that all results are obtained from the literature, where post-processing, flip & rotation test ensemble, etc. are also applied.Methods \nmIoU \ncar \nbicycle \nmotorcycle \n\ntruck \nother-vehicle \n\nperson \nbicyclist \nmotorcyclist \n\nroad \nparking \nsidewalk \nother-ground \n\nbuilding \nfence \nvegetation \n\ntrunk \nterrain \npole \ntraffic \n\nTangentConv [34] \n35.9 \n86.8 1.3 12.7 11.6 10.2 17.1 20.2 0.5 82.9 15.2 61.7 9.0 82.8 44.2 75.5 42.5 55.5 30.2 22.2 \nDarknet53 [2] \n49.9 \n86.4 24.5 32.7 25.5 22.6 36.2 33.6 4.7 91.8 64.8 74.6 27.9 84.1 55.0 78.3 50.1 64.0 38.9 52.2 \nRandLA-Net [16] \n50.3 \n94.0 19.8 21.4 42.7 38.7 47.5 48.8 4.6 90.4 56.9 67.9 15.5 81.1 49.7 78.3 60.3 59.0 44.2 38.1 \nRangeNet++ [27] \n52.2 \n91.4 25.7 34.4 25.7 23.0 38.3 38.8 4.8 91.8 65.0 75.2 27.8 87.4 58.6 80.5 55.1 64.6 47.9 55.9 \nPolarNet [51] \n54.3 \n93.8 40.3 30.1 22.9 28.5 43.2 40.2 5.6 90.8 61.7 74.4 21.7 90.0 61.3 84.0 65.5 67.8 51.8 57.5 \nSqueezeSegv3 [45] \n55.9 \n92.5 38.7 36.5 29.6 33.0 45.6 46.2 20.1 91.7 63.4 74.8 26.4 89.0 59.4 82.0 58.7 65.4 49.6 58.9 \nSalsanext [10] \n59.5 \n91.9 48.3 38.6 38.9 31.9 60.2 59.0 19.4 91.7 63.7 75.8 29.1 90.2 64.2 81.8 63.6 66.5 54.3 62.1 \nKPConv [36] \n58.8 \n96.0 32.0 42.5 33.4 44.3 61.5 61.6 11.8 88.8 61.3 72.7 31.6 95.0 64.2 84.8 69.2 69.1 56.4 47.4 \nFusionNet [48] \n61.3 \n95.3 47.5 37.7 41.8 34.5 59.5 56.8 11.9 91.8 68.8 77.1 30.8 92.5 69.4 84.5 69.8 68.5 60.4 66.5 \nKPRNet [19] \n63.1 \n95.5 54.1 47.9 23.6 42.6 65.9 65.0 16.5 93.2 73.9 80.6 30.2 91.7 68.4 85.7 69.8 71.2 58.7 64.1 \nTORANDONet [13] \n63.1 \n94.2 55.7 48.1 40.0 38.2 63.6 60.1 34.9 89.7 66.3 74.5 28.7 91.3 65.6 85.6 67.0 71.5 58.0 65.9 \nSPVNAS [33] \n66.4 \n-\n\n\nTable 2 :\n2Results of our proposed method and other LiDAR Segmentation methods on nuScenes validation set.Methods \nmIoU \nbarrier \nbicycle \n\nbus \ncar \nconstruction \nmotorcycle \npedestrian \ntraffic-cone \n\ntrailer \ntruck \ndriveable \n\nother \nsidewalk \nterrain \nmanmade \nvegetation \n\nRangeNet++ [27] \n65.5 \n66.0 21.3 77.2 80.9 30.2 66.8 69.6 52.1 54.2 72.3 94.1 66.6 63.5 70.1 83.1 79.8 \nPolarNet [51] \n71.0 \n74.7 28.2 85.3 90.9 35.1 77.5 71.3 58.8 57.4 76.1 96.5 71.1 74.7 74.0 87.3 85.7 \nSalsanext [10] \n72.2 \n74.8 34.1 85.9 88.4 42.2 72.4 72.2 63.1 61.3 76.5 96.0 70.8 71.2 71.5 86.7 84.4 \nOurs \n76.1 \n76.4 40.3 91.2 93.8 51.3 78.0 78.9 64.9 62.1 84.4 96.8 71.6 76.4 75.4 90.5 87.4 \n\n\n\nTable 3 :\n3Ablation studies for network components on Se-manticKITTI validation set. PR denotes the point-wise refinement module.Baseline Cylinder Asym-CNN DDCM PR mIoU \n\n58.1 \n\n\n61.0 \n\n\n\n63.8 \n\n\n\n\n65.2 \n\n\n\n\n65.9 \n\n\n\nTable 4 :\n4Ablation studies for asymmetrical residual block.Methods \nmIoU \nRegular residual block \n61.0 \n1D-Asymmetrical residual block 62.0 \nAsymmetrical residual block \n63.8 \n\n\n\nTable 5 :\n5LiDAR panoptic segmentation results on the validation set of SemanticKITTI. Th RQ Th SQ Th PQ St RQ St SQ St mIoU KPConv [36] + PV-RCNN [32] 51.7 57.4 63.1 78.9 46.8Method \nPQ \nPQ  \u2020 \nRQ \nSQ \nPQ 56.8 \n81.5 \n55.2 \n67.8 \n77.1 \n63.1 \nPointGroup [17] \n46.1 54.0 56.6 74.6 47.7 \n55.9 \n73.8 \n45.0 \n57.1 \n75.1 \n55.7 \nLPASD [26] \n36.5 46.1 \n-\n-\n-\n28.2 \n-\n-\n-\n-\n50.7 \nOurs \n56.4 \n62 \n67.1 76.5 58.8 \n66.8 \n75.8 \n54.8 \n67.4 \n77.1 \n63.5 \n\n\n\nTable 6 :\n6LiDAR 3D detection results on nuScenes dataset. CyAs denotes the Cylindrical partition and Asymmetrical 3D convolution networks.Methods \nmAP NDS \nPointPillar [21] \n30.5 45.3 \nPP + Reconfig [39] 32.5 50.6 \nSECOND [47] \n31.6 46.8 \nSECOND + CyAs \n36.4 51.7 \nSSN [53] \n46.3 56.9 \nSSN + CyAs \n47.7 58.2 \n\n\nThe method is in the 1st place before CVPR deadline. * denotes the equal contribution and code at https://github.com/xinge008/ Cylinder3D. Corresponding email: zhuxinge123@gmail.com\n\n3d-mininet: Learning a 2d representation from point clouds for fast and efficient 3d lidar semantic segmentation. I\u00f1igo Alonso, Luis Riazuelo, Luis Montesano, Ana C Murillo, arXiv:2002.10893arXiv preprintI\u00f1igo Alonso, Luis Riazuelo, Luis Montesano, and Ana C Murillo. 3d-mininet: Learning a 2d representation from point clouds for fast and efficient 3d lidar semantic segmen- tation. arXiv preprint arXiv:2002.10893, 2020. 2\n\nSemantickitti: A dataset for semantic scene understanding of lidar sequences. Jens Behley, Martin Garbade, Andres Milioto, Sven Behnke, Cyrill Stachniss, and Jurgen Gall. 56ICCVJens Behley, Martin Garbade, Andres Milioto, Jan Quen- zel, Sven Behnke, Cyrill Stachniss, and Jurgen Gall. Se- mantickitti: A dataset for semantic scene understanding of lidar sequences. In ICCV, pages 9297-9307, 2019. 2, 5, 6\n\nA benchmark for lidar-based panoptic segmentation based on kitti. Jens Behley, Andres Milioto, Cyrill Stachniss, arXiv:2003.02371arXiv preprintJens Behley, Andres Milioto, and Cyrill Stachniss. A bench- mark for lidar-based panoptic segmentation based on kitti. arXiv preprint arXiv:2003.02371, 2020. 8\n\nThe lov\u00e1sz-softmax loss: A tractable surrogate for the optimization of the intersection-over-union measure in neural networks. Maxim Berman, Amal Rannen Triki, Matthew B Blaschko, CVPR. Maxim Berman, Amal Rannen Triki, and Matthew B Blaschko. The lov\u00e1sz-softmax loss: A tractable surrogate for the optimization of the intersection-over-union measure in neural networks. In CVPR, pages 4413-4421, 2018. 5\n\nHolger Caesar, Varun Bankiti, Alex H Lang, Sourabh Vora, Venice Erin Liong, Qiang Xu, Anush Krishnan, Yu Pan, Giancarlo Baldan, Oscar Beijbom, arXiv:1903.11027nuscenes: A multimodal dataset for autonomous driving. 26arXiv preprintHolger Caesar, Varun Bankiti, Alex H Lang, Sourabh Vora, Venice Erin Liong, Qiang Xu, Anush Krishnan, Yu Pan, Giancarlo Baldan, and Oscar Beijbom. nuscenes: A mul- timodal dataset for autonomous driving. arXiv preprint arXiv:1903.11027, 2019. 2, 6\n\nDeeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected crfs. Liang-Chieh Chen, George Papandreou, Iasonas Kokkinos, Kevin Murphy, Alan L Yuille, IEEE transactions on pattern analysis and machine intelligence. 40Liang-Chieh Chen, George Papandreou, Iasonas Kokkinos, Kevin Murphy, and Alan L Yuille. Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolu- tion, and fully connected crfs. IEEE transactions on pattern analysis and machine intelligence, 40(4):834-848, 2017. 3\n\nEncoder-decoder with atrous separable convolution for semantic image segmentation. Yukun Liang-Chieh Chen, George Zhu, Florian Papandreou, Hartwig Schroff, Adam, ECCV. Liang-Chieh Chen, Yukun Zhu, George Papandreou, Florian Schroff, and Hartwig Adam. Encoder-decoder with atrous separable convolution for semantic image segmentation. In ECCV, pages 801-818, 2018. 3\n\nTensor low-rank reconstruction for semantic segmentation. Wanli Chen, Xinge Zhu, Ruoqi Sun, Junjun He, Ruiyu Li, Xiaoyong Shen, Bei Yu, arXiv:2008.00490arXiv preprintWanli Chen, Xinge Zhu, Ruoqi Sun, Junjun He, Ruiyu Li, Xiaoyong Shen, and Bei Yu. Tensor low-rank re- construction for semantic segmentation. arXiv preprint arXiv:2008.00490, 2020. 5\n\nnet: learning dense volumetric segmentation from sparse annotation. Ahmed \u00d6zg\u00fcn \u00c7 I\u00e7ek, Abdulkadir, S Soeren, Thomas Lienkamp, Olaf Brox, Ronneberger, MICCAI. Springer133d u-\u00d6zg\u00fcn \u00c7 i\u00e7ek, Ahmed Abdulkadir, Soeren S Lienkamp, Thomas Brox, and Olaf Ronneberger. 3d u-net: learning dense volumetric segmentation from sparse annotation. In MICCAI, pages 424-432. Springer, 2016. 1, 3\n\nSalsanext: Fast, uncertainty-aware semantic segmentation of lidar point clouds for autonomous driving. Tiago Cortinhal, George Tzelepis, Eren Erdal Aksoy, 56Tiago Cortinhal, George Tzelepis, and Eren Erdal Aksoy. Salsanext: Fast, uncertainty-aware semantic segmentation of lidar point clouds for autonomous driving, 2020. 2, 5, 6\n\nAcnet: Strengthening the kernel skeletons for powerful cnn via asymmetric convolution blocks. Xiaohan Ding, Yuchen Guo, Guiguang Ding, Jungong Han, ICCV. Xiaohan Ding, Yuchen Guo, Guiguang Ding, and Jungong Han. Acnet: Strengthening the kernel skeletons for power- ful cnn via asymmetric convolution blocks. In ICCV, pages 1911-1920, 2019. 4\n\nBastian Leibe, and Matthias Nie\u00dfner. 3d-mpa: Multi-proposal aggregation for 3d semantic instance segmentation. Francis Engelmann, Martin Bokeloh, Alireza Fathi, CVPR. 2020Francis Engelmann, Martin Bokeloh, Alireza Fathi, Bastian Leibe, and Matthias Nie\u00dfner. 3d-mpa: Multi-proposal ag- gregation for 3d semantic instance segmentation. In CVPR, pages 9031-9040, 2020. 2\n\nTornado-net: multiview total variation semantic segmentation with diamond inception module. Martin Gerdzhev, Ryan Razani, Ehsan Taghavi, Bingbing Liu, arXiv:2008.10544arXiv preprintMartin Gerdzhev, Ryan Razani, Ehsan Taghavi, and Bing- bing Liu. Tornado-net: multiview total variation seman- tic segmentation with diamond inception module. arXiv preprint arXiv:2008.10544, 2020. 6\n\n3d semantic segmentation with submanifold sparse convolutional networks. Benjamin Graham, Martin Engelcke, Laurens Van Der Maaten, CVPR. 13Benjamin Graham, Martin Engelcke, and Laurens Van Der Maaten. 3d semantic segmentation with submanifold sparse convolutional networks. In CVPR, pages 9224-9232, 2018. 1, 3\n\nOccuseg: Occupancy-aware 3d instance segmentation. Lei Han, Tian Zheng, Lan Xu, Lu Fang, CVPR. 2020Lei Han, Tian Zheng, Lan Xu, and Lu Fang. Occuseg: Occupancy-aware 3d instance segmentation. In CVPR, pages 2940-2949, 2020. 3\n\nRandla-net: Efficient semantic segmentation of large-scale point clouds. Qingyong Hu, Bo Yang, Linhai Xie, Stefano Rosa, Yulan Guo, Zhihua Wang, Niki Trigoni, Andrew Markham, CVPR. 56Qingyong Hu, Bo Yang, Linhai Xie, Stefano Rosa, Yulan Guo, Zhihua Wang, Niki Trigoni, and Andrew Markham. Randla-net: Efficient semantic segmentation of large-scale point clouds. In CVPR, pages 11108-11117, 2020. 2, 5, 6\n\nPointgroup: Dual-set point grouping for 3d instance segmentation. Li Jiang, Hengshuang Zhao, Shaoshuai Shi, Shu Liu, Chi-Wing Fu, Jiaya Jia, CVPR. Li Jiang, Hengshuang Zhao, Shaoshuai Shi, Shu Liu, Chi- Wing Fu, and Jiaya Jia. Pointgroup: Dual-set point grouping for 3d instance segmentation. In CVPR, pages 4867-4876, 2020. 8\n\nPanoptic segmentation. Alexander Kirillov, Kaiming He, Ross Girshick, Carsten Rother, Piotr Doll\u00e1r, CVPR. Alexander Kirillov, Kaiming He, Ross Girshick, Carsten Rother, and Piotr Doll\u00e1r. Panoptic segmentation. In CVPR, pages 9404-9413, 2019. 8\n\nKprnet: Improving projection-based lidar semantic segmentation. Deyvid Kochanov, Olaf Fatemeh Karimi Nejadasl, Booij, arXiv:2007.12668arXiv preprintDeyvid Kochanov, Fatemeh Karimi Nejadasl, and Olaf Booij. Kprnet: Improving projection-based lidar semantic segmentation. arXiv preprint arXiv:2007.12668, 2020. 6\n\nLarge-scale point cloud semantic segmentation with superpoint graphs. Loic Landrieu, Martin Simonovsky, CVPR. Loic Landrieu and Martin Simonovsky. Large-scale point cloud semantic segmentation with superpoint graphs. In CVPR, pages 4558-4567, 2018. 2\n\nPointpillars: Fast encoders for object detection from point clouds. Alex H Lang, Sourabh Vora, Holger Caesar, Lubing Zhou, Jiong Yang, Oscar Beijbom, CVPR. Alex H Lang, Sourabh Vora, Holger Caesar, Lubing Zhou, Jiong Yang, and Oscar Beijbom. Pointpillars: Fast encoders for object detection from point clouds. In CVPR, pages 12697-12705, 2019. 8\n\nAutodeeplab: Hierarchical neural architecture search for semantic image segmentation. Chenxi Liu, Liang-Chieh Chen, Florian Schroff, Hartwig Adam, Wei Hua, Alan L Yuille, Li Fei-Fei, CVPR. Chenxi Liu, Liang-Chieh Chen, Florian Schroff, Hartwig Adam, Wei Hua, Alan L Yuille, and Li Fei-Fei. Auto- deeplab: Hierarchical neural architecture search for semantic image segmentation. In CVPR, pages 82-92, 2019. 3\n\nFully convolutional networks for semantic segmentation. Jonathan Long, Evan Shelhamer, Trevor Darrell, CVPR. Jonathan Long, Evan Shelhamer, and Trevor Darrell. Fully convolutional networks for semantic segmentation. In CVPR, pages 3431-3440, 2015. 3\n\nLearning to segment 3d point clouds in 2d image space. Yecheng Lyu, Xinming Huang, Ziming Zhang, CVPR. 2020Yecheng Lyu, Xinming Huang, and Ziming Zhang. Learning to segment 3d point clouds in 2d image space. In CVPR, pages 12255-12264, 2020. 2\n\nVv-net: Voxel vae net with group convolutions for point cloud segmentation. Hsien-Yu Meng, Lin Gao, Yu-Kun Lai, Dinesh Manocha, ICCV. Hsien-Yu Meng, Lin Gao, Yu-Kun Lai, and Dinesh Manocha. Vv-net: Voxel vae net with group convolutions for point cloud segmentation. In ICCV, pages 8500-8508, 2019. 3\n\nLiDAR Panoptic Segmentation for Autonomous Driving. A Milioto, J Behley, C Mccool, C Stachniss, A. Milioto, J. Behley, C. McCool, and C. Stachniss. LiDAR Panoptic Segmentation for Autonomous Driving. 2020. 8\n\nRangenet++: Fast and accurate lidar semantic segmentation. Andres Milioto, Ignacio Vizzo, Jens Behley, Cyrill Stachniss, IROS. IEEE6Andres Milioto, Ignacio Vizzo, Jens Behley, and Cyrill Stachniss. Rangenet++: Fast and accurate lidar semantic segmentation. In IROS, pages 4213-4220. IEEE, 2019. 1, 2, 6\n\nJsis3d: joint semantic-instance segmentation of 3d point clouds with multi-task pointwise networks and multi-value conditional random fields. Quang-Hieu Pham, Thanh Nguyen, Binh-Son, Gemma Hua, Sai-Kit Roig, Yeung, CVPR. Quang-Hieu Pham, Thanh Nguyen, Binh-Son Hua, Gemma Roig, and Sai-Kit Yeung. Jsis3d: joint semantic-instance segmentation of 3d point clouds with multi-task pointwise networks and multi-value conditional random fields. In CVPR, pages 8827-8836, 2019. 2\n\nPointnet: Deep learning on point sets for 3d classification and segmentation. Hao Charles R Qi, Kaichun Su, Leonidas J Mo, Guibas, CVPR. Charles R Qi, Hao Su, Kaichun Mo, and Leonidas J Guibas. Pointnet: Deep learning on point sets for 3d classification and segmentation. In CVPR, pages 652-660, 2017. 2\n\nSanja Fidler, and Raquel Urtasun. 3d graph neural networks for rgbd semantic segmentation. Xiaojuan Qi, Renjie Liao, Jiaya Jia, ICCV. Xiaojuan Qi, Renjie Liao, Jiaya Jia, Sanja Fidler, and Raquel Urtasun. 3d graph neural networks for rgbd semantic seg- mentation. In ICCV, pages 5199-5208, 2017. 2\n\nU-net: Convolutional networks for biomedical image segmentation. Olaf Ronneberger, Philipp Fischer, Thomas Brox, MICCAI. SpringerOlaf Ronneberger, Philipp Fischer, and Thomas Brox. U-net: Convolutional networks for biomedical image segmentation. In MICCAI, pages 234-241. Springer, 2015. 3\n\nPv-rcnn: Pointvoxel feature set abstraction for 3d object detection. Shaoshuai Shi, Chaoxu Guo, Li Jiang, Zhe Wang, Jianping Shi, Xiaogang Wang, Hongsheng Li, CVPR. Shaoshuai Shi, Chaoxu Guo, Li Jiang, Zhe Wang, Jianping Shi, Xiaogang Wang, and Hongsheng Li. Pv-rcnn: Point- voxel feature set abstraction for 3d object detection. In CVPR, pages 10529-10538, 2020. 8\n\nSearching efficient 3d architectures with sparse point-voxel convolution. Haotian Tang, Zhijian Liu, Shengyu Zhao, Yujun Lin, Ji Lin, Hanrui Wang, Song Han, arXiv:2007.1610036arXiv preprintHaotian Tang, Zhijian Liu, Shengyu Zhao, Yujun Lin, Ji Lin, Hanrui Wang, and Song Han. Searching efficient 3d archi- tectures with sparse point-voxel convolution. arXiv preprint arXiv:2007.16100, 2020. 3, 6\n\nTangent convolutions for dense prediction in 3d. Maxim Tatarchenko, Jaesik Park, Vladlen Koltun, Qian-Yi Zhou, CVPR. Maxim Tatarchenko, Jaesik Park, Vladlen Koltun, and Qian- Yi Zhou. Tangent convolutions for dense prediction in 3d. In CVPR, pages 3887-3896, 2018. 6\n\nSegcloud: Semantic segmentation of 3d point clouds. Lyne Tchapmi, Christopher Choy, Iro Armeni, Junyoung Gwak, Silvio Savarese, IEEE3Lyne Tchapmi, Christopher Choy, Iro Armeni, JunYoung Gwak, and Silvio Savarese. Segcloud: Semantic segmen- tation of 3d point clouds. In 3DV, pages 537-547. IEEE, 2017. 3\n\nKpconv: Flexible and deformable convolution for point clouds. Hugues Thomas, R Charles, Jean-Emmanuel Qi, Beatriz Deschaud, Fran\u00e7ois Marcotegui, Leonidas J Goulette, Guibas, ICCV. Hugues Thomas, Charles R Qi, Jean-Emmanuel Deschaud, Beatriz Marcotegui, Fran\u00e7ois Goulette, and Leonidas J Guibas. Kpconv: Flexible and deformable convolution for point clouds. In ICCV, pages 6411-6420, 2019. 2, 6, 8\n\nPetar Veli\u010dkovi\u0107, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, Yoshua Bengio, arXiv:1710.10903Graph attention networks. arXiv preprintPetar Veli\u010dkovi\u0107, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. Graph at- tention networks. arXiv preprint arXiv:1710.10903, 2017. 2\n\nGraph attention convolution for point cloud semantic segmentation. Lei Wang, Yuchun Huang, Yaolin Hou, Shenman Zhang, Jie Shan, CVPR. Lei Wang, Yuchun Huang, Yaolin Hou, Shenman Zhang, and Jie Shan. Graph attention convolution for point cloud seman- tic segmentation. In CVPR, pages 10296-10305, 2019. 2\n\nReconfigurable voxels: A new representation for lidar-based point clouds. Conference on Robot Learning. Tai Wang, Xinge Zhu, Dahua Lin, Tai Wang, Xinge Zhu, and Dahua Lin. Reconfigurable vox- els: A new representation for lidar-based point clouds. Con- ference on Robot Learning, 2020. 8\n\nShape robust text detection with progressive scale expansion network. Wenhai Wang, Enze Xie, Xiang Li, Wenbo Hou, Tong Lu, Gang Yu, Shuai Shao, CVPR. Wenhai Wang, Enze Xie, Xiang Li, Wenbo Hou, Tong Lu, Gang Yu, and Shuai Shao. Shape robust text detection with progressive scale expansion network. In CVPR, pages 9336- 9345, 2019. 4\n\nDynamic graph cnn for learning on point clouds. Yue Wang, Yongbin Sun, Ziwei Liu, E Sanjay, Sarma, Justin M Michael M Bronstein, Solomon, Acm Transactions On Graphics (tog). 385Yue Wang, Yongbin Sun, Ziwei Liu, Sanjay E Sarma, Michael M Bronstein, and Justin M Solomon. Dynamic graph cnn for learning on point clouds. Acm Transactions On Graphics (tog), 38(5):1-12, 2019. 2\n\nSqueezeseg: Convolutional neural nets with recurrent crf for real-time road-object segmentation from 3d lidar point cloud. Bichen Wu, Alvin Wan, Xiangyu Yue, Kurt Keutzer, ICRA. IEEE1Bichen Wu, Alvin Wan, Xiangyu Yue, and Kurt Keutzer. Squeezeseg: Convolutional neural nets with recurrent crf for real-time road-object segmentation from 3d lidar point cloud. In ICRA, pages 1887-1893. IEEE, 2018. 1, 2\n\nSqueezesegv2: Improved model structure and unsupervised domain adaptation for road-object segmentation from a lidar point cloud. Bichen Wu, Xuanyu Zhou, Sicheng Zhao, Xiangyu Yue, Kurt Keutzer, ICRA. Bichen Wu, Xuanyu Zhou, Sicheng Zhao, Xiangyu Yue, and Kurt Keutzer. Squeezesegv2: Improved model structure and unsupervised domain adaptation for road-object segmenta- tion from a lidar point cloud. In ICRA, pages 4376-4382. IEEE, 2019. 2\n\nPointconv: Deep convolutional networks on 3d point clouds. Wenxuan Wu, Zhongang Qi, Li Fuxin, CVPR. Wenxuan Wu, Zhongang Qi, and Li Fuxin. Pointconv: Deep convolutional networks on 3d point clouds. In CVPR, pages 9621-9630, 2019. 2\n\nSqueeze-segv3: Spatially-adaptive convolution for efficient pointcloud segmentation. Chenfeng Xu, Bichen Wu, Zining Wang, Wei Zhan, Peter Vajda, Kurt Keutzer, Masayoshi Tomizuka, arXiv:2004.0180326arXiv preprintChenfeng Xu, Bichen Wu, Zining Wang, Wei Zhan, Peter Vajda, Kurt Keutzer, and Masayoshi Tomizuka. Squeeze- segv3: Spatially-adaptive convolution for efficient point- cloud segmentation. arXiv preprint arXiv:2004.01803, 2020. 2, 6\n\nPointasnl: Robust point clouds processing using nonlocal neural networks with adaptive sampling. Xu Yan, Chaoda Zheng, Zhen Li, Sheng Wang, Shuguang Cui, CVPR. Xu Yan, Chaoda Zheng, Zhen Li, Sheng Wang, and Shuguang Cui. Pointasnl: Robust point clouds processing using nonlocal neural networks with adaptive sampling. In CVPR, pages 5589-5598, 2020. 2\n\nSecond: Sparsely embedded convolutional detection. Yan Yan, Yuxing Mao, Bo Li, Sensors. 18103337Yan Yan, Yuxing Mao, and Bo Li. Second: Sparsely embed- ded convolutional detection. Sensors, 18(10):3337, 2018. 8\n\nDeep fusionnet for point cloud semantic segmentation. Feihu Zhang, Jin Fang, Benjamin Wah, Philip Torr, ECCV. 26Feihu Zhang, Jin Fang, Benjamin Wah, and Philip Torr. Deep fusionnet for point cloud semantic segmentation. ECCV, 2020. 2, 6\n\nCo-occurrent features in semantic segmentation. Hang Zhang, Han Zhang, Chenguang Wang, Junyuan Xie, CVPR. Hang Zhang, Han Zhang, Chenguang Wang, and Junyuan Xie. Co-occurrent features in semantic segmentation. In CVPR, pages 548-557, 2019. 5\n\nFusion-aware point convolution for online semantic 3d scene segmentation. Jiazhao Zhang, Chenyang Zhu, Lintao Zheng, Kai Xu, CVPR. 2020Jiazhao Zhang, Chenyang Zhu, Lintao Zheng, and Kai Xu. Fusion-aware point convolution for online semantic 3d scene segmentation. In CVPR, pages 4534-4543, 2020. 2\n\nPolarnet: An improved grid representation for online lidar point clouds semantic segmentation. Yang Zhang, Zixiang Zhou, Philip David, Xiangyu Yue, Zerong Xi, Boqing Gong, Hassan Foroosh, CVPR. 6Yang Zhang, Zixiang Zhou, Philip David, Xiangyu Yue, Ze- rong Xi, Boqing Gong, and Hassan Foroosh. Polarnet: An improved grid representation for online lidar point clouds se- mantic segmentation. In CVPR, pages 9601-9610, 2020. 1, 2, 3, 6\n\nPyramid scene parsing network. Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, Jiaya Jia, CVPR. Hengshuang Zhao, Jianping Shi, Xiaojuan Qi, Xiaogang Wang, and Jiaya Jia. Pyramid scene parsing network. In CVPR, pages 2881-2890, 2017. 3\n\nSsn: Shape signature networks for multi-class object detection from point clouds. Xinge Zhu, Yuexin Ma, Tai Wang, Yan Xu, Jianping Shi, Dahua Lin, ECCV. 8Xinge Zhu, Yuexin Ma, Tai Wang, Yan Xu, Jianping Shi, and Dahua Lin. Ssn: Shape signature networks for multi-class object detection from point clouds. ECCV, 2020. 8\n", "annotations": {"author": "[{\"end\":191,\"start\":79},{\"end\":303,\"start\":192},{\"end\":415,\"start\":304},{\"end\":532,\"start\":416},{\"end\":645,\"start\":533},{\"end\":755,\"start\":646},{\"end\":871,\"start\":756},{\"end\":984,\"start\":872}]", "publisher": null, "author_last_name": "[{\"end\":88,\"start\":85},{\"end\":200,\"start\":196},{\"end\":312,\"start\":308},{\"end\":429,\"start\":425},{\"end\":542,\"start\":540},{\"end\":652,\"start\":650},{\"end\":768,\"start\":766},{\"end\":881,\"start\":878}]", "author_first_name": "[{\"end\":84,\"start\":79},{\"end\":195,\"start\":192},{\"end\":307,\"start\":304},{\"end\":424,\"start\":416},{\"end\":539,\"start\":533},{\"end\":649,\"start\":646},{\"end\":765,\"start\":756},{\"end\":877,\"start\":872}]", "author_affiliation": "[{\"end\":190,\"start\":90},{\"end\":302,\"start\":202},{\"end\":414,\"start\":314},{\"end\":531,\"start\":431},{\"end\":644,\"start\":544},{\"end\":754,\"start\":654},{\"end\":870,\"start\":770},{\"end\":983,\"start\":883}]", "title": "[{\"end\":76,\"start\":1},{\"end\":1060,\"start\":985}]", "venue": null, "abstract": "[{\"end\":2397,\"start\":1062}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b26\"},\"end\":3357,\"start\":3353},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":3360,\"start\":3357},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":3397,\"start\":3393},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":3779,\"start\":3775},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":3781,\"start\":3779},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":5464,\"start\":5460},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":5467,\"start\":5464},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":5470,\"start\":5467},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":5473,\"start\":5470},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":6600,\"start\":6597},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":6617,\"start\":6614},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":7235,\"start\":7232},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":7850,\"start\":7846},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":7853,\"start\":7850},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":7856,\"start\":7853},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":7859,\"start\":7856},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":7862,\"start\":7859},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":7865,\"start\":7862},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":7868,\"start\":7865},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":7871,\"start\":7868},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":7874,\"start\":7871},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":7877,\"start\":7874},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":7880,\"start\":7877},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":7883,\"start\":7880},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":8202,\"start\":8198},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":8205,\"start\":8202},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":8657,\"start\":8653},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":8660,\"start\":8657},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":8663,\"start\":8660},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":8665,\"start\":8663},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":8668,\"start\":8665},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":8671,\"start\":8668},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":8796,\"start\":8792},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":8809,\"start\":8806},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":8829,\"start\":8825},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":8850,\"start\":8846},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":9070,\"start\":9066},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":9426,\"start\":9422},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":9429,\"start\":9426},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":9432,\"start\":9429},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":9434,\"start\":9432},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":9437,\"start\":9434},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":9544,\"start\":9540},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":9555,\"start\":9551},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":9574,\"start\":9570},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":10224,\"start\":10220},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":10450,\"start\":10447},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":10452,\"start\":10450},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":10465,\"start\":10461},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":10580,\"start\":10576},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":10583,\"start\":10580},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":10605,\"start\":10601},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":10827,\"start\":10824},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":14857,\"start\":14853},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":14860,\"start\":14857},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":15579,\"start\":15575},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":15582,\"start\":15579},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":16575,\"start\":16571},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":16671,\"start\":16668},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":18476,\"start\":18472},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":18479,\"start\":18476},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":18542,\"start\":18539},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":19337,\"start\":19334},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":19942,\"start\":19939},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":20642,\"start\":20639},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":20644,\"start\":20642},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":21210,\"start\":21207},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":21229,\"start\":21225},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":21246,\"start\":21242},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":21264,\"start\":21260},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":21468,\"start\":21464},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":21485,\"start\":21481},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":21534,\"start\":21530},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":25972,\"start\":25968},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":26213,\"start\":26210},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":26485,\"start\":26482},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":26565,\"start\":26561},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":27664,\"start\":27660},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":27667,\"start\":27664},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":28132,\"start\":28128},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":28519,\"start\":28515},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":28855,\"start\":28851},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":28917,\"start\":28913},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":30172,\"start\":30169}]", "figure": "[{\"attributes\":{\"id\":\"fig_1\"},\"end\":30725,\"start\":30156},{\"attributes\":{\"id\":\"fig_2\"},\"end\":31053,\"start\":30726},{\"attributes\":{\"id\":\"fig_3\"},\"end\":31281,\"start\":31054},{\"attributes\":{\"id\":\"fig_5\"},\"end\":31508,\"start\":31282},{\"attributes\":{\"id\":\"fig_7\"},\"end\":31736,\"start\":31509},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":32012,\"start\":31737},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":33776,\"start\":32013},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":34460,\"start\":33777},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":34677,\"start\":34461},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":34857,\"start\":34678},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":35298,\"start\":34858},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":35611,\"start\":35299}]", "paragraph": "[{\"end\":3050,\"start\":2413},{\"end\":3550,\"start\":3052},{\"end\":4422,\"start\":3552},{\"end\":5648,\"start\":4424},{\"end\":6503,\"start\":5650},{\"end\":6989,\"start\":6505},{\"end\":7442,\"start\":6991},{\"end\":7628,\"start\":7444},{\"end\":8550,\"start\":7645},{\"end\":9338,\"start\":8552},{\"end\":10150,\"start\":9340},{\"end\":10913,\"start\":10152},{\"end\":11888,\"start\":10950},{\"end\":12485,\"start\":11890},{\"end\":13652,\"start\":12511},{\"end\":14532,\"start\":13654},{\"end\":16403,\"start\":14572},{\"end\":16872,\"start\":16454},{\"end\":18134,\"start\":16905},{\"end\":18225,\"start\":18136},{\"end\":18901,\"start\":18248},{\"end\":19297,\"start\":18917},{\"end\":19893,\"start\":19320},{\"end\":20268,\"start\":19930},{\"end\":20471,\"start\":20270},{\"end\":20673,\"start\":20473},{\"end\":20871,\"start\":20687},{\"end\":21854,\"start\":20900},{\"end\":22525,\"start\":21878},{\"end\":22874,\"start\":22546},{\"end\":23777,\"start\":22908},{\"end\":24316,\"start\":23821},{\"end\":25411,\"start\":24318},{\"end\":27083,\"start\":25439},{\"end\":27537,\"start\":27085},{\"end\":27993,\"start\":27539},{\"end\":28801,\"start\":27995},{\"end\":29466,\"start\":28803},{\"end\":30155,\"start\":29481}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":19929,\"start\":19894},{\"attributes\":{\"id\":\"formula_1\"},\"end\":20686,\"start\":20674}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":21070,\"start\":21063},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":22090,\"start\":22083},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":23082,\"start\":23075},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":24554,\"start\":24547},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":25085,\"start\":25078},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":27571,\"start\":27564},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":28835,\"start\":28828}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":2411,\"start\":2399},{\"attributes\":{\"n\":\"2.\"},\"end\":7643,\"start\":7631},{\"attributes\":{\"n\":\"3.\"},\"end\":10927,\"start\":10916},{\"attributes\":{\"n\":\"3.1.\"},\"end\":10948,\"start\":10930},{\"attributes\":{\"n\":\"3.2.\"},\"end\":12509,\"start\":12488},{\"attributes\":{\"n\":\"3.3.\"},\"end\":14570,\"start\":14535},{\"end\":16452,\"start\":16406},{\"attributes\":{\"n\":\"3.4.\"},\"end\":16903,\"start\":16875},{\"attributes\":{\"n\":\"3.5.\"},\"end\":18246,\"start\":18228},{\"attributes\":{\"n\":\"4.\"},\"end\":18915,\"start\":18904},{\"attributes\":{\"n\":\"4.1.\"},\"end\":19318,\"start\":19300},{\"attributes\":{\"n\":\"4.2.\"},\"end\":20898,\"start\":20874},{\"attributes\":{\"n\":\"4.3.\"},\"end\":21876,\"start\":21857},{\"attributes\":{\"n\":\"4.4.\"},\"end\":22544,\"start\":22528},{\"end\":22906,\"start\":22877},{\"end\":23819,\"start\":23780},{\"attributes\":{\"n\":\"4.5.\"},\"end\":25437,\"start\":25414},{\"attributes\":{\"n\":\"5.\"},\"end\":29479,\"start\":29469},{\"end\":30167,\"start\":30157},{\"end\":30737,\"start\":30727},{\"end\":31065,\"start\":31055},{\"end\":31293,\"start\":31283},{\"end\":31520,\"start\":31510},{\"end\":32023,\"start\":32014},{\"end\":33787,\"start\":33778},{\"end\":34471,\"start\":34462},{\"end\":34688,\"start\":34679},{\"end\":34868,\"start\":34859},{\"end\":35309,\"start\":35300}]", "table": "[{\"end\":32012,\"start\":31809},{\"end\":33776,\"start\":32263},{\"end\":34460,\"start\":33884},{\"end\":34677,\"start\":34591},{\"end\":34857,\"start\":34739},{\"end\":35298,\"start\":35035},{\"end\":35611,\"start\":35439}]", "figure_caption": "[{\"end\":30725,\"start\":30169},{\"end\":31053,\"start\":30739},{\"end\":31281,\"start\":31067},{\"end\":31508,\"start\":31295},{\"end\":31736,\"start\":31522},{\"end\":31809,\"start\":31739},{\"end\":32263,\"start\":32025},{\"end\":33884,\"start\":33789},{\"end\":34591,\"start\":34473},{\"end\":34739,\"start\":34690},{\"end\":35035,\"start\":34870},{\"end\":35439,\"start\":35311}]", "figure_ref": "[{\"end\":3549,\"start\":3541},{\"end\":3903,\"start\":3896},{\"end\":4890,\"start\":4882},{\"end\":5798,\"start\":5790},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":11924,\"start\":11918},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":13184,\"start\":13178},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":13691,\"start\":13685},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":15499,\"start\":15493},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":15962,\"start\":15956},{\"end\":17370,\"start\":17364},{\"end\":17889,\"start\":17881},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":24043,\"start\":24037}]", "bib_author_first_name": "[{\"end\":35914,\"start\":35909},{\"end\":35927,\"start\":35923},{\"end\":35942,\"start\":35938},{\"end\":35957,\"start\":35954},{\"end\":35959,\"start\":35958},{\"end\":36303,\"start\":36299},{\"end\":36318,\"start\":36312},{\"end\":36334,\"start\":36328},{\"end\":36697,\"start\":36693},{\"end\":36712,\"start\":36706},{\"end\":36728,\"start\":36722},{\"end\":37063,\"start\":37058},{\"end\":37076,\"start\":37072},{\"end\":37083,\"start\":37077},{\"end\":37098,\"start\":37091},{\"end\":37100,\"start\":37099},{\"end\":37342,\"start\":37336},{\"end\":37356,\"start\":37351},{\"end\":37370,\"start\":37366},{\"end\":37372,\"start\":37371},{\"end\":37386,\"start\":37379},{\"end\":37399,\"start\":37393},{\"end\":37404,\"start\":37400},{\"end\":37417,\"start\":37412},{\"end\":37427,\"start\":37422},{\"end\":37440,\"start\":37438},{\"end\":37455,\"start\":37446},{\"end\":37469,\"start\":37464},{\"end\":37939,\"start\":37928},{\"end\":37952,\"start\":37946},{\"end\":37972,\"start\":37965},{\"end\":37988,\"start\":37983},{\"end\":38001,\"start\":37997},{\"end\":38003,\"start\":38002},{\"end\":38457,\"start\":38452},{\"end\":38482,\"start\":38476},{\"end\":38495,\"start\":38488},{\"end\":38515,\"start\":38508},{\"end\":38799,\"start\":38794},{\"end\":38811,\"start\":38806},{\"end\":38822,\"start\":38817},{\"end\":38834,\"start\":38828},{\"end\":38844,\"start\":38839},{\"end\":38857,\"start\":38849},{\"end\":38867,\"start\":38864},{\"end\":39159,\"start\":39154},{\"end\":39187,\"start\":39186},{\"end\":39202,\"start\":39196},{\"end\":39217,\"start\":39213},{\"end\":39575,\"start\":39570},{\"end\":39593,\"start\":39587},{\"end\":39608,\"start\":39604},{\"end\":39614,\"start\":39609},{\"end\":39899,\"start\":39892},{\"end\":39912,\"start\":39906},{\"end\":39926,\"start\":39918},{\"end\":39940,\"start\":39933},{\"end\":40259,\"start\":40252},{\"end\":40277,\"start\":40271},{\"end\":40294,\"start\":40287},{\"end\":40608,\"start\":40602},{\"end\":40623,\"start\":40619},{\"end\":40637,\"start\":40632},{\"end\":40655,\"start\":40647},{\"end\":40973,\"start\":40965},{\"end\":40988,\"start\":40982},{\"end\":41006,\"start\":40999},{\"end\":41258,\"start\":41255},{\"end\":41268,\"start\":41264},{\"end\":41279,\"start\":41276},{\"end\":41286,\"start\":41284},{\"end\":41512,\"start\":41504},{\"end\":41519,\"start\":41517},{\"end\":41532,\"start\":41526},{\"end\":41545,\"start\":41538},{\"end\":41557,\"start\":41552},{\"end\":41569,\"start\":41563},{\"end\":41580,\"start\":41576},{\"end\":41596,\"start\":41590},{\"end\":41904,\"start\":41902},{\"end\":41922,\"start\":41912},{\"end\":41938,\"start\":41929},{\"end\":41947,\"start\":41944},{\"end\":41961,\"start\":41953},{\"end\":41971,\"start\":41966},{\"end\":42196,\"start\":42187},{\"end\":42214,\"start\":42207},{\"end\":42223,\"start\":42219},{\"end\":42241,\"start\":42234},{\"end\":42255,\"start\":42250},{\"end\":42479,\"start\":42473},{\"end\":42494,\"start\":42490},{\"end\":42795,\"start\":42791},{\"end\":42812,\"start\":42806},{\"end\":43047,\"start\":43041},{\"end\":43061,\"start\":43054},{\"end\":43074,\"start\":43068},{\"end\":43089,\"start\":43083},{\"end\":43101,\"start\":43096},{\"end\":43113,\"start\":43108},{\"end\":43412,\"start\":43406},{\"end\":43429,\"start\":43418},{\"end\":43443,\"start\":43436},{\"end\":43460,\"start\":43453},{\"end\":43470,\"start\":43467},{\"end\":43480,\"start\":43476},{\"end\":43482,\"start\":43481},{\"end\":43493,\"start\":43491},{\"end\":43793,\"start\":43785},{\"end\":43804,\"start\":43800},{\"end\":43822,\"start\":43816},{\"end\":44042,\"start\":44035},{\"end\":44055,\"start\":44048},{\"end\":44069,\"start\":44063},{\"end\":44309,\"start\":44301},{\"end\":44319,\"start\":44316},{\"end\":44331,\"start\":44325},{\"end\":44343,\"start\":44337},{\"end\":44579,\"start\":44578},{\"end\":44590,\"start\":44589},{\"end\":44600,\"start\":44599},{\"end\":44610,\"start\":44609},{\"end\":44800,\"start\":44794},{\"end\":44817,\"start\":44810},{\"end\":44829,\"start\":44825},{\"end\":44844,\"start\":44838},{\"end\":45191,\"start\":45181},{\"end\":45203,\"start\":45198},{\"end\":45227,\"start\":45222},{\"end\":45240,\"start\":45233},{\"end\":45594,\"start\":45591},{\"end\":45616,\"start\":45609},{\"end\":45629,\"start\":45621},{\"end\":45631,\"start\":45630},{\"end\":45917,\"start\":45909},{\"end\":45928,\"start\":45922},{\"end\":45940,\"start\":45935},{\"end\":46186,\"start\":46182},{\"end\":46207,\"start\":46200},{\"end\":46223,\"start\":46217},{\"end\":46486,\"start\":46477},{\"end\":46498,\"start\":46492},{\"end\":46506,\"start\":46504},{\"end\":46517,\"start\":46514},{\"end\":46532,\"start\":46524},{\"end\":46546,\"start\":46538},{\"end\":46562,\"start\":46553},{\"end\":46856,\"start\":46849},{\"end\":46870,\"start\":46863},{\"end\":46883,\"start\":46876},{\"end\":46895,\"start\":46890},{\"end\":46903,\"start\":46901},{\"end\":46915,\"start\":46909},{\"end\":46926,\"start\":46922},{\"end\":47226,\"start\":47221},{\"end\":47246,\"start\":47240},{\"end\":47260,\"start\":47253},{\"end\":47276,\"start\":47269},{\"end\":47496,\"start\":47492},{\"end\":47517,\"start\":47506},{\"end\":47527,\"start\":47524},{\"end\":47544,\"start\":47536},{\"end\":47557,\"start\":47551},{\"end\":47813,\"start\":47807},{\"end\":47823,\"start\":47822},{\"end\":47846,\"start\":47833},{\"end\":47858,\"start\":47851},{\"end\":47877,\"start\":47869},{\"end\":47898,\"start\":47890},{\"end\":47900,\"start\":47899},{\"end\":48148,\"start\":48143},{\"end\":48168,\"start\":48161},{\"end\":48186,\"start\":48179},{\"end\":48204,\"start\":48197},{\"end\":48219,\"start\":48213},{\"end\":48231,\"start\":48225},{\"end\":48537,\"start\":48534},{\"end\":48550,\"start\":48544},{\"end\":48564,\"start\":48558},{\"end\":48577,\"start\":48570},{\"end\":48588,\"start\":48585},{\"end\":48879,\"start\":48876},{\"end\":48891,\"start\":48886},{\"end\":48902,\"start\":48897},{\"end\":49137,\"start\":49131},{\"end\":49148,\"start\":49144},{\"end\":49159,\"start\":49154},{\"end\":49169,\"start\":49164},{\"end\":49179,\"start\":49175},{\"end\":49188,\"start\":49184},{\"end\":49198,\"start\":49193},{\"end\":49446,\"start\":49443},{\"end\":49460,\"start\":49453},{\"end\":49471,\"start\":49466},{\"end\":49478,\"start\":49477},{\"end\":49500,\"start\":49494},{\"end\":49502,\"start\":49501},{\"end\":49899,\"start\":49893},{\"end\":49909,\"start\":49904},{\"end\":49922,\"start\":49915},{\"end\":49932,\"start\":49928},{\"end\":50308,\"start\":50302},{\"end\":50319,\"start\":50313},{\"end\":50333,\"start\":50326},{\"end\":50347,\"start\":50340},{\"end\":50357,\"start\":50353},{\"end\":50680,\"start\":50673},{\"end\":50693,\"start\":50685},{\"end\":50700,\"start\":50698},{\"end\":50940,\"start\":50932},{\"end\":50951,\"start\":50945},{\"end\":50962,\"start\":50956},{\"end\":50972,\"start\":50969},{\"end\":50984,\"start\":50979},{\"end\":50996,\"start\":50992},{\"end\":51015,\"start\":51006},{\"end\":51388,\"start\":51386},{\"end\":51400,\"start\":51394},{\"end\":51412,\"start\":51408},{\"end\":51422,\"start\":51417},{\"end\":51437,\"start\":51429},{\"end\":51696,\"start\":51693},{\"end\":51708,\"start\":51702},{\"end\":51716,\"start\":51714},{\"end\":51913,\"start\":51908},{\"end\":51924,\"start\":51921},{\"end\":51939,\"start\":51931},{\"end\":51951,\"start\":51945},{\"end\":52144,\"start\":52140},{\"end\":52155,\"start\":52152},{\"end\":52172,\"start\":52163},{\"end\":52186,\"start\":52179},{\"end\":52416,\"start\":52409},{\"end\":52432,\"start\":52424},{\"end\":52444,\"start\":52438},{\"end\":52455,\"start\":52452},{\"end\":52733,\"start\":52729},{\"end\":52748,\"start\":52741},{\"end\":52761,\"start\":52755},{\"end\":52776,\"start\":52769},{\"end\":52788,\"start\":52782},{\"end\":52799,\"start\":52793},{\"end\":52812,\"start\":52806},{\"end\":53110,\"start\":53100},{\"end\":53125,\"start\":53117},{\"end\":53139,\"start\":53131},{\"end\":53152,\"start\":53144},{\"end\":53164,\"start\":53159},{\"end\":53403,\"start\":53398},{\"end\":53415,\"start\":53409},{\"end\":53423,\"start\":53420},{\"end\":53433,\"start\":53430},{\"end\":53446,\"start\":53438},{\"end\":53457,\"start\":53452}]", "bib_author_last_name": "[{\"end\":35921,\"start\":35915},{\"end\":35936,\"start\":35928},{\"end\":35952,\"start\":35943},{\"end\":35967,\"start\":35960},{\"end\":36310,\"start\":36304},{\"end\":36326,\"start\":36319},{\"end\":36342,\"start\":36335},{\"end\":36704,\"start\":36698},{\"end\":36720,\"start\":36713},{\"end\":36738,\"start\":36729},{\"end\":37070,\"start\":37064},{\"end\":37089,\"start\":37084},{\"end\":37109,\"start\":37101},{\"end\":37349,\"start\":37343},{\"end\":37364,\"start\":37357},{\"end\":37377,\"start\":37373},{\"end\":37391,\"start\":37387},{\"end\":37410,\"start\":37405},{\"end\":37420,\"start\":37418},{\"end\":37436,\"start\":37428},{\"end\":37444,\"start\":37441},{\"end\":37462,\"start\":37456},{\"end\":37477,\"start\":37470},{\"end\":37944,\"start\":37940},{\"end\":37963,\"start\":37953},{\"end\":37981,\"start\":37973},{\"end\":37995,\"start\":37989},{\"end\":38010,\"start\":38004},{\"end\":38474,\"start\":38458},{\"end\":38486,\"start\":38483},{\"end\":38506,\"start\":38496},{\"end\":38523,\"start\":38516},{\"end\":38529,\"start\":38525},{\"end\":38804,\"start\":38800},{\"end\":38815,\"start\":38812},{\"end\":38826,\"start\":38823},{\"end\":38837,\"start\":38835},{\"end\":38847,\"start\":38845},{\"end\":38862,\"start\":38858},{\"end\":38870,\"start\":38868},{\"end\":39172,\"start\":39160},{\"end\":39184,\"start\":39174},{\"end\":39194,\"start\":39188},{\"end\":39211,\"start\":39203},{\"end\":39222,\"start\":39218},{\"end\":39235,\"start\":39224},{\"end\":39585,\"start\":39576},{\"end\":39602,\"start\":39594},{\"end\":39620,\"start\":39615},{\"end\":39904,\"start\":39900},{\"end\":39916,\"start\":39913},{\"end\":39931,\"start\":39927},{\"end\":39944,\"start\":39941},{\"end\":40269,\"start\":40260},{\"end\":40285,\"start\":40278},{\"end\":40300,\"start\":40295},{\"end\":40617,\"start\":40609},{\"end\":40630,\"start\":40624},{\"end\":40645,\"start\":40638},{\"end\":40659,\"start\":40656},{\"end\":40980,\"start\":40974},{\"end\":40997,\"start\":40989},{\"end\":41021,\"start\":41007},{\"end\":41262,\"start\":41259},{\"end\":41274,\"start\":41269},{\"end\":41282,\"start\":41280},{\"end\":41291,\"start\":41287},{\"end\":41515,\"start\":41513},{\"end\":41524,\"start\":41520},{\"end\":41536,\"start\":41533},{\"end\":41550,\"start\":41546},{\"end\":41561,\"start\":41558},{\"end\":41574,\"start\":41570},{\"end\":41588,\"start\":41581},{\"end\":41604,\"start\":41597},{\"end\":41910,\"start\":41905},{\"end\":41927,\"start\":41923},{\"end\":41942,\"start\":41939},{\"end\":41951,\"start\":41948},{\"end\":41964,\"start\":41962},{\"end\":41975,\"start\":41972},{\"end\":42205,\"start\":42197},{\"end\":42217,\"start\":42215},{\"end\":42232,\"start\":42224},{\"end\":42248,\"start\":42242},{\"end\":42262,\"start\":42256},{\"end\":42488,\"start\":42480},{\"end\":42518,\"start\":42495},{\"end\":42525,\"start\":42520},{\"end\":42804,\"start\":42796},{\"end\":42823,\"start\":42813},{\"end\":43052,\"start\":43048},{\"end\":43066,\"start\":43062},{\"end\":43081,\"start\":43075},{\"end\":43094,\"start\":43090},{\"end\":43106,\"start\":43102},{\"end\":43121,\"start\":43114},{\"end\":43416,\"start\":43413},{\"end\":43434,\"start\":43430},{\"end\":43451,\"start\":43444},{\"end\":43465,\"start\":43461},{\"end\":43474,\"start\":43471},{\"end\":43489,\"start\":43483},{\"end\":43501,\"start\":43494},{\"end\":43798,\"start\":43794},{\"end\":43814,\"start\":43805},{\"end\":43830,\"start\":43823},{\"end\":44046,\"start\":44043},{\"end\":44061,\"start\":44056},{\"end\":44075,\"start\":44070},{\"end\":44314,\"start\":44310},{\"end\":44323,\"start\":44320},{\"end\":44335,\"start\":44332},{\"end\":44351,\"start\":44344},{\"end\":44587,\"start\":44580},{\"end\":44597,\"start\":44591},{\"end\":44607,\"start\":44601},{\"end\":44620,\"start\":44611},{\"end\":44808,\"start\":44801},{\"end\":44823,\"start\":44818},{\"end\":44836,\"start\":44830},{\"end\":44854,\"start\":44845},{\"end\":45196,\"start\":45192},{\"end\":45210,\"start\":45204},{\"end\":45220,\"start\":45212},{\"end\":45231,\"start\":45228},{\"end\":45245,\"start\":45241},{\"end\":45252,\"start\":45247},{\"end\":45607,\"start\":45595},{\"end\":45619,\"start\":45617},{\"end\":45634,\"start\":45632},{\"end\":45642,\"start\":45636},{\"end\":45920,\"start\":45918},{\"end\":45933,\"start\":45929},{\"end\":45944,\"start\":45941},{\"end\":46198,\"start\":46187},{\"end\":46215,\"start\":46208},{\"end\":46228,\"start\":46224},{\"end\":46490,\"start\":46487},{\"end\":46502,\"start\":46499},{\"end\":46512,\"start\":46507},{\"end\":46522,\"start\":46518},{\"end\":46536,\"start\":46533},{\"end\":46551,\"start\":46547},{\"end\":46565,\"start\":46563},{\"end\":46861,\"start\":46857},{\"end\":46874,\"start\":46871},{\"end\":46888,\"start\":46884},{\"end\":46899,\"start\":46896},{\"end\":46907,\"start\":46904},{\"end\":46920,\"start\":46916},{\"end\":46930,\"start\":46927},{\"end\":47238,\"start\":47227},{\"end\":47251,\"start\":47247},{\"end\":47267,\"start\":47261},{\"end\":47281,\"start\":47277},{\"end\":47504,\"start\":47497},{\"end\":47522,\"start\":47518},{\"end\":47534,\"start\":47528},{\"end\":47549,\"start\":47545},{\"end\":47566,\"start\":47558},{\"end\":47820,\"start\":47814},{\"end\":47831,\"start\":47824},{\"end\":47849,\"start\":47847},{\"end\":47867,\"start\":47859},{\"end\":47888,\"start\":47878},{\"end\":47909,\"start\":47901},{\"end\":47917,\"start\":47911},{\"end\":48159,\"start\":48149},{\"end\":48177,\"start\":48169},{\"end\":48195,\"start\":48187},{\"end\":48211,\"start\":48205},{\"end\":48223,\"start\":48220},{\"end\":48238,\"start\":48232},{\"end\":48542,\"start\":48538},{\"end\":48556,\"start\":48551},{\"end\":48568,\"start\":48565},{\"end\":48583,\"start\":48578},{\"end\":48593,\"start\":48589},{\"end\":48884,\"start\":48880},{\"end\":48895,\"start\":48892},{\"end\":48906,\"start\":48903},{\"end\":49142,\"start\":49138},{\"end\":49152,\"start\":49149},{\"end\":49162,\"start\":49160},{\"end\":49173,\"start\":49170},{\"end\":49182,\"start\":49180},{\"end\":49191,\"start\":49189},{\"end\":49203,\"start\":49199},{\"end\":49451,\"start\":49447},{\"end\":49464,\"start\":49461},{\"end\":49475,\"start\":49472},{\"end\":49485,\"start\":49479},{\"end\":49492,\"start\":49487},{\"end\":49522,\"start\":49503},{\"end\":49531,\"start\":49524},{\"end\":49902,\"start\":49900},{\"end\":49913,\"start\":49910},{\"end\":49926,\"start\":49923},{\"end\":49940,\"start\":49933},{\"end\":50311,\"start\":50309},{\"end\":50324,\"start\":50320},{\"end\":50338,\"start\":50334},{\"end\":50351,\"start\":50348},{\"end\":50365,\"start\":50358},{\"end\":50683,\"start\":50681},{\"end\":50696,\"start\":50694},{\"end\":50706,\"start\":50701},{\"end\":50943,\"start\":50941},{\"end\":50954,\"start\":50952},{\"end\":50967,\"start\":50963},{\"end\":50977,\"start\":50973},{\"end\":50990,\"start\":50985},{\"end\":51004,\"start\":50997},{\"end\":51024,\"start\":51016},{\"end\":51392,\"start\":51389},{\"end\":51406,\"start\":51401},{\"end\":51415,\"start\":51413},{\"end\":51427,\"start\":51423},{\"end\":51441,\"start\":51438},{\"end\":51700,\"start\":51697},{\"end\":51712,\"start\":51709},{\"end\":51719,\"start\":51717},{\"end\":51919,\"start\":51914},{\"end\":51929,\"start\":51925},{\"end\":51943,\"start\":51940},{\"end\":51956,\"start\":51952},{\"end\":52150,\"start\":52145},{\"end\":52161,\"start\":52156},{\"end\":52177,\"start\":52173},{\"end\":52190,\"start\":52187},{\"end\":52422,\"start\":52417},{\"end\":52436,\"start\":52433},{\"end\":52450,\"start\":52445},{\"end\":52458,\"start\":52456},{\"end\":52739,\"start\":52734},{\"end\":52753,\"start\":52749},{\"end\":52767,\"start\":52762},{\"end\":52780,\"start\":52777},{\"end\":52791,\"start\":52789},{\"end\":52804,\"start\":52800},{\"end\":52820,\"start\":52813},{\"end\":53115,\"start\":53111},{\"end\":53129,\"start\":53126},{\"end\":53142,\"start\":53140},{\"end\":53157,\"start\":53153},{\"end\":53168,\"start\":53165},{\"end\":53407,\"start\":53404},{\"end\":53418,\"start\":53416},{\"end\":53428,\"start\":53424},{\"end\":53436,\"start\":53434},{\"end\":53450,\"start\":53447},{\"end\":53461,\"start\":53458}]", "bib_entry": "[{\"attributes\":{\"doi\":\"arXiv:2002.10893\",\"id\":\"b0\"},\"end\":36219,\"start\":35795},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":199441943},\"end\":36625,\"start\":36221},{\"attributes\":{\"doi\":\"arXiv:2003.02371\",\"id\":\"b2\"},\"end\":36929,\"start\":36627},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":4716955},\"end\":37334,\"start\":36931},{\"attributes\":{\"doi\":\"arXiv:1903.11027\",\"id\":\"b4\"},\"end\":37813,\"start\":37336},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":3429309},\"end\":38367,\"start\":37815},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":3638670},\"end\":38734,\"start\":38369},{\"attributes\":{\"doi\":\"arXiv:2008.00490\",\"id\":\"b7\"},\"end\":39084,\"start\":38736},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":2164893},\"end\":39465,\"start\":39086},{\"attributes\":{\"id\":\"b9\"},\"end\":39796,\"start\":39467},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":199543841},\"end\":40139,\"start\":39798},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":214727628},\"end\":40508,\"start\":40141},{\"attributes\":{\"doi\":\"arXiv:2008.10544\",\"id\":\"b12\"},\"end\":40890,\"start\":40510},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":10154243},\"end\":41202,\"start\":40892},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":212725768},\"end\":41429,\"start\":41204},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":208290898},\"end\":41834,\"start\":41431},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":214795000},\"end\":42162,\"start\":41836},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":4853375},\"end\":42407,\"start\":42164},{\"attributes\":{\"doi\":\"arXiv:2007.12668\",\"id\":\"b18\"},\"end\":42719,\"start\":42409},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":4396837},\"end\":42971,\"start\":42721},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":55701967},\"end\":43318,\"start\":42973},{\"attributes\":{\"id\":\"b21\"},\"end\":43727,\"start\":43320},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":1629541},\"end\":43978,\"start\":43729},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":212675132},\"end\":44223,\"start\":43980},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":53279704},\"end\":44524,\"start\":44225},{\"attributes\":{\"id\":\"b25\"},\"end\":44733,\"start\":44526},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":199478000},\"end\":45037,\"start\":44735},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":90262893},\"end\":45511,\"start\":45039},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":5115938},\"end\":45816,\"start\":45513},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":2738523},\"end\":46115,\"start\":45818},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":3719281},\"end\":46406,\"start\":46117},{\"attributes\":{\"id\":\"b31\"},\"end\":46773,\"start\":46408},{\"attributes\":{\"doi\":\"arXiv:2007.16100\",\"id\":\"b32\"},\"end\":47170,\"start\":46775},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":4592390},\"end\":47438,\"start\":47172},{\"attributes\":{\"id\":\"b34\"},\"end\":47743,\"start\":47440},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":121328056},\"end\":48141,\"start\":47745},{\"attributes\":{\"doi\":\"arXiv:1710.10903\",\"id\":\"b36\"},\"end\":48465,\"start\":48143},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":198164185},\"end\":48770,\"start\":48467},{\"attributes\":{\"id\":\"b38\"},\"end\":49059,\"start\":48772},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":46966180},\"end\":49393,\"start\":49061},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":94822},\"end\":49768,\"start\":49395},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":206853127},\"end\":50171,\"start\":49770},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":52815788},\"end\":50612,\"start\":50173},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":53720607},\"end\":50845,\"start\":50614},{\"attributes\":{\"doi\":\"arXiv:2004.01803\",\"id\":\"b44\"},\"end\":51287,\"start\":50847},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":211677426},\"end\":51640,\"start\":51289},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":52957856},\"end\":51852,\"start\":51642},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":221354813},\"end\":52090,\"start\":51854},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":198363310},\"end\":52333,\"start\":52092},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":212717754},\"end\":52632,\"start\":52335},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":214727956},\"end\":53067,\"start\":52634},{\"attributes\":{\"id\":\"b51\",\"matched_paper_id\":5299559},\"end\":53314,\"start\":53069},{\"attributes\":{\"id\":\"b52\",\"matched_paper_id\":214801993},\"end\":53634,\"start\":53316}]", "bib_title": "[{\"end\":36297,\"start\":36221},{\"end\":37056,\"start\":36931},{\"end\":37926,\"start\":37815},{\"end\":38450,\"start\":38369},{\"end\":39152,\"start\":39086},{\"end\":39890,\"start\":39798},{\"end\":40250,\"start\":40141},{\"end\":40963,\"start\":40892},{\"end\":41253,\"start\":41204},{\"end\":41502,\"start\":41431},{\"end\":41900,\"start\":41836},{\"end\":42185,\"start\":42164},{\"end\":42789,\"start\":42721},{\"end\":43039,\"start\":42973},{\"end\":43404,\"start\":43320},{\"end\":43783,\"start\":43729},{\"end\":44033,\"start\":43980},{\"end\":44299,\"start\":44225},{\"end\":44792,\"start\":44735},{\"end\":45179,\"start\":45039},{\"end\":45589,\"start\":45513},{\"end\":45907,\"start\":45818},{\"end\":46180,\"start\":46117},{\"end\":46475,\"start\":46408},{\"end\":47219,\"start\":47172},{\"end\":47805,\"start\":47745},{\"end\":48532,\"start\":48467},{\"end\":49129,\"start\":49061},{\"end\":49441,\"start\":49395},{\"end\":49891,\"start\":49770},{\"end\":50300,\"start\":50173},{\"end\":50671,\"start\":50614},{\"end\":51384,\"start\":51289},{\"end\":51691,\"start\":51642},{\"end\":51906,\"start\":51854},{\"end\":52138,\"start\":52092},{\"end\":52407,\"start\":52335},{\"end\":52727,\"start\":52634},{\"end\":53098,\"start\":53069},{\"end\":53396,\"start\":53316}]", "bib_author": "[{\"end\":35923,\"start\":35909},{\"end\":35938,\"start\":35923},{\"end\":35954,\"start\":35938},{\"end\":35969,\"start\":35954},{\"end\":36312,\"start\":36299},{\"end\":36328,\"start\":36312},{\"end\":36344,\"start\":36328},{\"end\":36706,\"start\":36693},{\"end\":36722,\"start\":36706},{\"end\":36740,\"start\":36722},{\"end\":37072,\"start\":37058},{\"end\":37091,\"start\":37072},{\"end\":37111,\"start\":37091},{\"end\":37351,\"start\":37336},{\"end\":37366,\"start\":37351},{\"end\":37379,\"start\":37366},{\"end\":37393,\"start\":37379},{\"end\":37412,\"start\":37393},{\"end\":37422,\"start\":37412},{\"end\":37438,\"start\":37422},{\"end\":37446,\"start\":37438},{\"end\":37464,\"start\":37446},{\"end\":37479,\"start\":37464},{\"end\":37946,\"start\":37928},{\"end\":37965,\"start\":37946},{\"end\":37983,\"start\":37965},{\"end\":37997,\"start\":37983},{\"end\":38012,\"start\":37997},{\"end\":38476,\"start\":38452},{\"end\":38488,\"start\":38476},{\"end\":38508,\"start\":38488},{\"end\":38525,\"start\":38508},{\"end\":38531,\"start\":38525},{\"end\":38806,\"start\":38794},{\"end\":38817,\"start\":38806},{\"end\":38828,\"start\":38817},{\"end\":38839,\"start\":38828},{\"end\":38849,\"start\":38839},{\"end\":38864,\"start\":38849},{\"end\":38872,\"start\":38864},{\"end\":39174,\"start\":39154},{\"end\":39186,\"start\":39174},{\"end\":39196,\"start\":39186},{\"end\":39213,\"start\":39196},{\"end\":39224,\"start\":39213},{\"end\":39237,\"start\":39224},{\"end\":39587,\"start\":39570},{\"end\":39604,\"start\":39587},{\"end\":39622,\"start\":39604},{\"end\":39906,\"start\":39892},{\"end\":39918,\"start\":39906},{\"end\":39933,\"start\":39918},{\"end\":39946,\"start\":39933},{\"end\":40271,\"start\":40252},{\"end\":40287,\"start\":40271},{\"end\":40302,\"start\":40287},{\"end\":40619,\"start\":40602},{\"end\":40632,\"start\":40619},{\"end\":40647,\"start\":40632},{\"end\":40661,\"start\":40647},{\"end\":40982,\"start\":40965},{\"end\":40999,\"start\":40982},{\"end\":41023,\"start\":40999},{\"end\":41264,\"start\":41255},{\"end\":41276,\"start\":41264},{\"end\":41284,\"start\":41276},{\"end\":41293,\"start\":41284},{\"end\":41517,\"start\":41504},{\"end\":41526,\"start\":41517},{\"end\":41538,\"start\":41526},{\"end\":41552,\"start\":41538},{\"end\":41563,\"start\":41552},{\"end\":41576,\"start\":41563},{\"end\":41590,\"start\":41576},{\"end\":41606,\"start\":41590},{\"end\":41912,\"start\":41902},{\"end\":41929,\"start\":41912},{\"end\":41944,\"start\":41929},{\"end\":41953,\"start\":41944},{\"end\":41966,\"start\":41953},{\"end\":41977,\"start\":41966},{\"end\":42207,\"start\":42187},{\"end\":42219,\"start\":42207},{\"end\":42234,\"start\":42219},{\"end\":42250,\"start\":42234},{\"end\":42264,\"start\":42250},{\"end\":42490,\"start\":42473},{\"end\":42520,\"start\":42490},{\"end\":42527,\"start\":42520},{\"end\":42806,\"start\":42791},{\"end\":42825,\"start\":42806},{\"end\":43054,\"start\":43041},{\"end\":43068,\"start\":43054},{\"end\":43083,\"start\":43068},{\"end\":43096,\"start\":43083},{\"end\":43108,\"start\":43096},{\"end\":43123,\"start\":43108},{\"end\":43418,\"start\":43406},{\"end\":43436,\"start\":43418},{\"end\":43453,\"start\":43436},{\"end\":43467,\"start\":43453},{\"end\":43476,\"start\":43467},{\"end\":43491,\"start\":43476},{\"end\":43503,\"start\":43491},{\"end\":43800,\"start\":43785},{\"end\":43816,\"start\":43800},{\"end\":43832,\"start\":43816},{\"end\":44048,\"start\":44035},{\"end\":44063,\"start\":44048},{\"end\":44077,\"start\":44063},{\"end\":44316,\"start\":44301},{\"end\":44325,\"start\":44316},{\"end\":44337,\"start\":44325},{\"end\":44353,\"start\":44337},{\"end\":44589,\"start\":44578},{\"end\":44599,\"start\":44589},{\"end\":44609,\"start\":44599},{\"end\":44622,\"start\":44609},{\"end\":44810,\"start\":44794},{\"end\":44825,\"start\":44810},{\"end\":44838,\"start\":44825},{\"end\":44856,\"start\":44838},{\"end\":45198,\"start\":45181},{\"end\":45212,\"start\":45198},{\"end\":45222,\"start\":45212},{\"end\":45233,\"start\":45222},{\"end\":45247,\"start\":45233},{\"end\":45254,\"start\":45247},{\"end\":45609,\"start\":45591},{\"end\":45621,\"start\":45609},{\"end\":45636,\"start\":45621},{\"end\":45644,\"start\":45636},{\"end\":45922,\"start\":45909},{\"end\":45935,\"start\":45922},{\"end\":45946,\"start\":45935},{\"end\":46200,\"start\":46182},{\"end\":46217,\"start\":46200},{\"end\":46230,\"start\":46217},{\"end\":46492,\"start\":46477},{\"end\":46504,\"start\":46492},{\"end\":46514,\"start\":46504},{\"end\":46524,\"start\":46514},{\"end\":46538,\"start\":46524},{\"end\":46553,\"start\":46538},{\"end\":46567,\"start\":46553},{\"end\":46863,\"start\":46849},{\"end\":46876,\"start\":46863},{\"end\":46890,\"start\":46876},{\"end\":46901,\"start\":46890},{\"end\":46909,\"start\":46901},{\"end\":46922,\"start\":46909},{\"end\":46932,\"start\":46922},{\"end\":47240,\"start\":47221},{\"end\":47253,\"start\":47240},{\"end\":47269,\"start\":47253},{\"end\":47283,\"start\":47269},{\"end\":47506,\"start\":47492},{\"end\":47524,\"start\":47506},{\"end\":47536,\"start\":47524},{\"end\":47551,\"start\":47536},{\"end\":47568,\"start\":47551},{\"end\":47822,\"start\":47807},{\"end\":47833,\"start\":47822},{\"end\":47851,\"start\":47833},{\"end\":47869,\"start\":47851},{\"end\":47890,\"start\":47869},{\"end\":47911,\"start\":47890},{\"end\":47919,\"start\":47911},{\"end\":48161,\"start\":48143},{\"end\":48179,\"start\":48161},{\"end\":48197,\"start\":48179},{\"end\":48213,\"start\":48197},{\"end\":48225,\"start\":48213},{\"end\":48240,\"start\":48225},{\"end\":48544,\"start\":48534},{\"end\":48558,\"start\":48544},{\"end\":48570,\"start\":48558},{\"end\":48585,\"start\":48570},{\"end\":48595,\"start\":48585},{\"end\":48886,\"start\":48876},{\"end\":48897,\"start\":48886},{\"end\":48908,\"start\":48897},{\"end\":49144,\"start\":49131},{\"end\":49154,\"start\":49144},{\"end\":49164,\"start\":49154},{\"end\":49175,\"start\":49164},{\"end\":49184,\"start\":49175},{\"end\":49193,\"start\":49184},{\"end\":49205,\"start\":49193},{\"end\":49453,\"start\":49443},{\"end\":49466,\"start\":49453},{\"end\":49477,\"start\":49466},{\"end\":49487,\"start\":49477},{\"end\":49494,\"start\":49487},{\"end\":49524,\"start\":49494},{\"end\":49533,\"start\":49524},{\"end\":49904,\"start\":49893},{\"end\":49915,\"start\":49904},{\"end\":49928,\"start\":49915},{\"end\":49942,\"start\":49928},{\"end\":50313,\"start\":50302},{\"end\":50326,\"start\":50313},{\"end\":50340,\"start\":50326},{\"end\":50353,\"start\":50340},{\"end\":50367,\"start\":50353},{\"end\":50685,\"start\":50673},{\"end\":50698,\"start\":50685},{\"end\":50708,\"start\":50698},{\"end\":50945,\"start\":50932},{\"end\":50956,\"start\":50945},{\"end\":50969,\"start\":50956},{\"end\":50979,\"start\":50969},{\"end\":50992,\"start\":50979},{\"end\":51006,\"start\":50992},{\"end\":51026,\"start\":51006},{\"end\":51394,\"start\":51386},{\"end\":51408,\"start\":51394},{\"end\":51417,\"start\":51408},{\"end\":51429,\"start\":51417},{\"end\":51443,\"start\":51429},{\"end\":51702,\"start\":51693},{\"end\":51714,\"start\":51702},{\"end\":51721,\"start\":51714},{\"end\":51921,\"start\":51908},{\"end\":51931,\"start\":51921},{\"end\":51945,\"start\":51931},{\"end\":51958,\"start\":51945},{\"end\":52152,\"start\":52140},{\"end\":52163,\"start\":52152},{\"end\":52179,\"start\":52163},{\"end\":52192,\"start\":52179},{\"end\":52424,\"start\":52409},{\"end\":52438,\"start\":52424},{\"end\":52452,\"start\":52438},{\"end\":52460,\"start\":52452},{\"end\":52741,\"start\":52729},{\"end\":52755,\"start\":52741},{\"end\":52769,\"start\":52755},{\"end\":52782,\"start\":52769},{\"end\":52793,\"start\":52782},{\"end\":52806,\"start\":52793},{\"end\":52822,\"start\":52806},{\"end\":53117,\"start\":53100},{\"end\":53131,\"start\":53117},{\"end\":53144,\"start\":53131},{\"end\":53159,\"start\":53144},{\"end\":53170,\"start\":53159},{\"end\":53409,\"start\":53398},{\"end\":53420,\"start\":53409},{\"end\":53430,\"start\":53420},{\"end\":53438,\"start\":53430},{\"end\":53452,\"start\":53438},{\"end\":53463,\"start\":53452}]", "bib_venue": "[{\"end\":35907,\"start\":35795},{\"end\":36390,\"start\":36344},{\"end\":36691,\"start\":36627},{\"end\":37115,\"start\":37111},{\"end\":37548,\"start\":37495},{\"end\":38074,\"start\":38012},{\"end\":38535,\"start\":38531},{\"end\":38792,\"start\":38736},{\"end\":39243,\"start\":39237},{\"end\":39568,\"start\":39467},{\"end\":39950,\"start\":39946},{\"end\":40306,\"start\":40302},{\"end\":40600,\"start\":40510},{\"end\":41027,\"start\":41023},{\"end\":41297,\"start\":41293},{\"end\":41610,\"start\":41606},{\"end\":41981,\"start\":41977},{\"end\":42268,\"start\":42264},{\"end\":42471,\"start\":42409},{\"end\":42829,\"start\":42825},{\"end\":43127,\"start\":43123},{\"end\":43507,\"start\":43503},{\"end\":43836,\"start\":43832},{\"end\":44081,\"start\":44077},{\"end\":44357,\"start\":44353},{\"end\":44576,\"start\":44526},{\"end\":44860,\"start\":44856},{\"end\":45258,\"start\":45254},{\"end\":45648,\"start\":45644},{\"end\":45950,\"start\":45946},{\"end\":46236,\"start\":46230},{\"end\":46571,\"start\":46567},{\"end\":46847,\"start\":46775},{\"end\":47287,\"start\":47283},{\"end\":47490,\"start\":47440},{\"end\":47923,\"start\":47919},{\"end\":48280,\"start\":48256},{\"end\":48599,\"start\":48595},{\"end\":48874,\"start\":48772},{\"end\":49209,\"start\":49205},{\"end\":49567,\"start\":49533},{\"end\":49946,\"start\":49942},{\"end\":50371,\"start\":50367},{\"end\":50712,\"start\":50708},{\"end\":50930,\"start\":50847},{\"end\":51447,\"start\":51443},{\"end\":51728,\"start\":51721},{\"end\":51962,\"start\":51958},{\"end\":52196,\"start\":52192},{\"end\":52464,\"start\":52460},{\"end\":52826,\"start\":52822},{\"end\":53174,\"start\":53170},{\"end\":53467,\"start\":53463}]"}}}, "year": 2023, "month": 12, "day": 17}