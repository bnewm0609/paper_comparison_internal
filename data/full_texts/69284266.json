{"id": 69284266, "updated": "2023-03-31 13:13:41.683", "metadata": {"title": "Community Detection in Social Networks Considering Topic Correlations", "authors": "[{\"first\":\"Yingkui\",\"last\":\"Wang\",\"middle\":[]},{\"first\":\"Di\",\"last\":\"Jin\",\"middle\":[]},{\"first\":\"Katarzyna\",\"last\":\"Musial\",\"middle\":[]},{\"first\":\"Jianwu\",\"last\":\"Dang\",\"middle\":[]}]", "venue": "Proceedings of the AAAI Conference on Artificial Intelligence", "journal": "Proceedings of the AAAI Conference on Artificial Intelligence", "publication_date": {"year": 2019, "month": null, "day": null}, "abstract": "Network contents including node contents and edge contents can be utilized for community detection in social networks. Thus, the topic of each community can be extracted as its semantic information. A plethora of models integrating topic model and network topologies have been proposed. However, a key problem has not been resolved that is the semantic division of a community. Since the definition of community is based on topology, a community might involve several topics. To achieve better community detection results and to better understand the fundamental community semantics, we investigate the correlations of different topics in community detection model. This work models the formation of each edge assuming that users are more likely to communicate with each other when they are in the same community and their topics are closely correlated. A Topic Correlations based Community Detection (TCCD) model is proposed, which can learn community structure and semantic interpretation of each community. Our model is evaluated on two real datasets and is compared with four state-of-the-art methods. Experimental results show that TCCD significantly improves the accuracy of community detection. Finally, a case study shows that TCCD can detect the topic correlations inside a community. And we can infer better semantic interpretation of each community.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": "2904399804", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/aaai/WangJMD19", "doi": "10.1609/aaai.v33i01.3301321"}}, "content": {"source": {"pdf_hash": "0b46c7add8aa092384d2e17f2e60410701d40996", "pdf_src": "MergedPDFExtraction", "pdf_uri": null, "oa_url_match": false, "oa_info": {"license": null, "open_access_url": "https://aaai.org/ojs/index.php/AAAI/article/download/3801/3679", "status": "BRONZE"}}, "grobid": {"id": "018e43d0cc29c362daa0ba78cd3cb5ceb617459f", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/0b46c7add8aa092384d2e17f2e60410701d40996.txt", "contents": "\nCommunity Detection in Social Networks Considering Topic Correlations\n\n\nYingkui Wang \nCollege of Intelligence and Computing\nTianjin University\n300350TianjinChina\n\nDi Jin jindi@tju.edu.cn \nCollege of Intelligence and Computing\nTianjin University\n300350TianjinChina\n\nKatarzyna Musial katarzyna.musial-gabrys@uts.edu.au \nAdvanced Analytics Institute\nSchool of Software\nUniversity of Technology Sydney\nAustralia\n\nJianwu Dang jdang@jaist.ac.jp \nCollege of Intelligence and Computing\nTianjin University\n300350TianjinChina\n\nSchool of Information Science\nJapan Advanced Institute of Science and Technology\nJapan\n\nCommunity Detection in Social Networks Considering Topic Correlations\n\nNetwork contents including node contents and edge contents can be utilized for community detection in social networks. Thus, the topic of each community can be extracted as its semantic information. A plethora of models integrating topic model and network topologies have been proposed. However, a key problem has not been resolved that is the semantic division of a community. Since the definition of community is based on topology, a community might involve several topics. To achieve better community detection results and to better understand the fundamental community semantics, we investigate the correlations of different topics in community detection model. This work models the formation of each edge assuming that users are more likely to communicate with each other when they are in the same community and their topics are closely correlated. A Topic Correlations based Community Detection (TCCD) model is proposed, which can learn community structure and semantic interpretation of each community. Our model is evaluated on two real datasets and is compared with four state-of-the-art methods. Experimental results show that TCCD significantly improves the accuracy of community detection. Finally, a case study shows that TCCD can detect the topic correlations inside a community. And we can infer better semantic interpretation of each community.\n\nIntroduction\n\nIn recent years, research in the area of community detection in networks has become a hot topic (Newman 2006;Fortunato and Hric 2016). This is due to the fact that communities play a very important role in a network and they enable to understand and interpret networks functions and characteristics. Community is defined as a group of nodes that are densely connected internally (Girvan and Newman 2002). Recent community detection methods not only detect community structures but also identify semantics of communities (He et al. 2017a;Zhang et al. 2018). It is significant to understand the innate character of communities as we can learn what users are interested in, what they care about in a community, and how the topic of communities evolves.\n\nIn real social networks, e.g., Weibo, Twitter, and Facebook, users interact with each other talking about different topics. Networks are created based on a large amount of heterogeneous and complex contents, such as microblogs, tweets, and posts. This type of information is considered as node contents or link contents depending on whether it is connected with nodes or links. To understand what topics are connected with a given community, such contents need to be analyzed and used as integral part of community detection process. Approaches that integrate network topologies and node contents have been proposed (Mcauley and Leskovec 2014;Pei, Chakraborty, and Sycara 2015). Recent studies begin to investigate community level diffusion, i.e., modeling diffusion patterns of topics across different communities (Hu et al. 2015). The work in (Cai et al. 2017), for the first time, formalizes the concept of community profiling, which is to characterize the intrinsic nature and extrinsic behavior of a community. Community structure is also incorporated into network embedding methods (Tu et al. 2018).\n\nHowever, several issues have not been well resolved by existing methods. By analyzing a large number of social networks, beyond the observation that a community might focus on several topics , we further found that there are correlations between the topics, which significantly affect community structures. Users focusing on a topic might have great interests in interacting with others focusing on a different topic, which means that these two topics are highly correlated. While there are also opposite situations between two topics, which means that the topics are minorly correlated. Take paper co-authorship network as example. Suppose that the topics in a network include Machine learning, Image processing and Data mining. The correlation between Machine learning and Image processing is closer than that between Image processing and Data mining. To characterize the correlations among latent topics, some studies have made great efforts, such as correlated topic models (Blei and Lafferty 2006;Chen et al. 2013) which replace Dirichlet distribution with logistic normal distribution in LDA, and topic embedding (Li et al. 2016;Jiang et al. 2013;He et al. 2017b;Li et al. 2018a) which represents topics in a low-dimension space. However, none of existing works consider the factor above in community detection. Existing methods are limited to resolve following issues corresponding to the observation.\n\nFirst, topics are inferred from network contents including node contents and edge contents. While edge contents are responsible for the formation of correlations between topics, node contents make no contributions since they are isolated documents that never generate edges. So, node contents and edge contents should be both considered to infer topics. Meanwhile, they should be utilized in different components corresponding to topics and topic correlations respectively. But, none of existing methods integrate node contents and edge contents into a unified model to infer topics and their correlations.\n\nSecond, according to our observation, even though two users focus on two different topics, they are still more likely to interact with each other when those two topics are highly correlated. So, topic correlations have significant effects on the generation of edges and further affect community structures. While, existing methods assume that interactions always occur between users who share the same topics in a community, which ignores the principle of generating edges according to topic correlations.\n\nThird, understanding the fundamental semantics of communities is a challenge. Currently, most methods only detect the topics of communities as their semantics. Then they use top-ranked words to represent topics. The work in  uses whole sentences to interpret communities. In fact, community semantics are far beyond above aspects. Since a community might focus on several topics, what is the mechanism of the composition of topics inside communities? This question leads us to understand communities in a natural way. But, existing work cannot resolve the question.\n\nBased on above discussions, we propose a generative model for community detection which consists of three components. The first part generates all user contents based on users community memberships and their topics. The second generates all link contents based on two endpoint users community memberships and their topics. The third generates each directed link with users community memberships and topic correlations together. Beyond existing work, our work for the first time interprets the mechanism of the composition of topics inside communities and understand communities in a natural way.\n\n\nTopic Correlations based Community Detection Problem Formulation\n\nThe notations used in this paper are summarized in Table 1.\nDefinition 1. A social network is defined by G = (U, E, D),\nwhere U is a set of users. A user is presented by u \u2208 U . E is a set of directed links and D is a set of documents published by users. A directed link is denoted by (i, j) that is from user i to user j. We allow multiple edges to exist between two users. If user i replies to user j multiple times, then there will be multiple edges from user i to user j. Each link is associated with a document and W iq denotes the word list of the q-th link document of user i. Definition 2. A user i's community membership is defined by a |C| dimensional vector \u03c0 i . |C| is the number of communities. For a community c, element \u03c0 i,c represents the probability of belonging to community c. Notations Descriptions U, K, C, T set of users, topics, communities and time stamps W word set of vocabulary D i posts not on links sent by user i E i , e ii \u2032 links sent by user i, directed link from user i to i \u2032 W ij , W iq word list of the j-th post, the q-th link of user i W ijl , W iqr the l-th and the r-th word of W ij , and W iq \u03c0 i multinomial distribution over communities of user i \u03b8 c multinomial distribution over topics of community c \u03c6 k multinomial distribution over words of topic k \u03c8 kc multinomial distribution over time of topic k and community c c ij , g iq community indicator of post and link z ij , y iq topic indicator of post and link t ij , t iq time stamp of post and link \u03b7 gy,g \u2032 y \u2032 the probability of forming a link between community g with topic y and community g \u2032 with topic y \u2032 I i user i's posting preference \u03b1, \u03b2, \u03f5, \u03c1 Dirichlet priors Definition 3. A topic k is defined by a |W | dimensional vector \u03c6 k following a multinomial distribution over vocabulary. For a word w, the element \u03c6 kw represents the probability of belonging to topic k. The number of topics is |K|.\n\nDefinition 4. Topic distribution of a community c is defined by a |K| dimensional vector \u03b8 c . An element \u03b8 ck represents the probability of belonging to topic k.\n\nDefinition 5. Time stamp distribution of community and topic are defined by a |T | dimensional vector \u03c8 kc , c \u2208 C , k \u2208 K .|T | is the number of time stamps. It is a multinomial distribution over time stamps.\n\nDefinition 6. Topic correlation \u03b7 gy,g \u2032 y \u2032 defines the correlation between two topics in different communities. It reflects the tendency of forming a link between user i who is in community g and focus on topic y and user j who is in community g \u2032 and focus on topic y \u2032 .\n\n\nModel Structure\n\nWe design a generative model to properly generate network topology, link contents and node contents. The probabilistic graphical model of TCCD is shown in Fig.1. It includes three main components: a) User post component; b) Link content component; c) Link component.\n\nUser post component. Take a forum network for example, the posts submitted by users are considered as node contents or link contents. Those posts that are never replied by others are processed as node contents. This component has no relation with network topology. But a user's posts have deep relation with his latent community membership and community topics. We generate them on the basis of serval latent factors, i.e., users community membership distribution, community-topic distribution and topic-word distribution.  Table 1.\n\nLink content component. This component generates all link contents of anetwork. The basic idea is that link contents reflect what topics the two users are talking about. Though the link structure of the network plays the key role for community detection, the link contents also provide rich information to the forming of community structure and community topics. It is the basic principle that users in the same community and interested in the same topics are more likely to interact.\n\nLink component. Suppose that user i replies to a post of user i \u2032 at time stamp t. Then we formulate the generation of the directed link E t ii \u2032 from user i to user i \u2032 . Let I i and I i \u2032 represent out-going tendency and in-coming tendency of users i and i \u2032 respectively. They are calculated by (out\u2212degree)i\n(degree)i and (in\u2212degree) i \u2032 (degree) i \u2032 .\nUser's in-degree indicates how many times others reply him while out-degree indicates how many times he replies to others. The value of \u03b7 gy,g \u2032 y \u2032 represents the tendency of forming a link from user i to user i \u2032 where g, y, g \u2032 and y \u2032 equal to g iq , y iq , g i \u2032 q and y i \u2032 q respectively as described in link contents generation component part. In order to integrate \u03b7 gy,g \u2032 y \u2032 , I i and I i \u2032 , we define \u03c9 ij as follows:\n\u03c9 ij = \u03b7 gy,g \u2032 y \u2032 + I i \u00b7 I i \u2032 .\n(1) Finally, we utilize sigmoid function to generate this link.\n\nP\n(E t ii \u2032 = 1|I i , I i \u2032 , g i , g i \u2032 , y, y \u2032 , \u03b7) =\u03c3(\u03c9 ij ) = 1/(1 + e \u2212\u03c9ij ).(2)\nIt is hard to infer a Gibbs sampler for this model. So, we adopt P\u00f3lya-Gamma distribution to model a logistic function (Polson, Scott, and Windle 2013).\n1 1 + e \u2212\u03c9ij = 1 2 \u222b \u221e 0 \u03d5(\u03c9 ij , \u03be ij )P (\u03be ij )d\u03be ij ,(3)\nwhere \u03d5(\u03c9 ij , \u03be ij ) = e (\u03c9ij \u2212\u03beij \u03c9 2 ij )/2 and \u03be ij \u223c P G(1, 0). Then we derive a joint probability distribution:\nP (E t ii \u2032 = 1, \u03be ij ) = 1 2 \u03d5(\u03c9 ij , \u03be ij )P (\u03be ij |1, 0) (4)\nGenerative process.We summarize above generative process as follows. 1. For each topic k = 1, 2, ..., K, (a) Sample the words distribution from a Dirichlet prior:\n\u03c6 k | \u03b2 \u223c Dir(\u03b2); (b) For each community c = 1, 2, ..., C,\ni. Sample the distribution over time stamps from a Dirchlet prior: \u03c8 kc | \u03f5 \u223c Dir(\u03f5) 2. For each community c = 1, 2, ..., C, (a) Sample the distribution over topics from a Dirichlet prior: \u03b8 c | \u03b1 \u223c Dir(\u03b1); 3. For each user i = 1, 2, ..., U, (a) Sample his community distribution from a Dirichlet prior:\n\u03c0 i | \u03c1 \u223c Dir(\u03c1); (b) For each post j = 1, 2, ..., i. Sample community indicator from a Multinomial dis- tribution: c ij | \u03c0 i \u223c M ul(\u03c0 i ); ii. Sample topic indicator from a Multinomial distribu- tion: z ij | \u03b8 cij \u223c M ul(\u03b8 cij ); iii. For each word l = 1, 2, ..., \u2022 Sample word from a Multinomial distribution: w ijl | \u03c6 zij \u223c M ul(\u03c6 zij ); iv. Sample time stamp t ij | \u03c8 zij cij \u223c M ul(\u03c8 zij cij ); (c) For each link q = 1, 2, ...,\ni. Sample community indicator from a Multinomial distribution: g iq | \u03c0 i \u223c M ul(\u03c0 i ); ii. Sample topic indicator from a Multinomial distribution:\ny iq | \u03b8 giq \u223c M ul(\u03b8 giq ); iii. Sample the link from i to i \u2032 : E t ii \u2032 | I i , I i \u2032 , g iq , g i \u2032 q , y iq , y i \u2032 q , \u03b7 \u223c Ber(\u03c3(\u03b7 giqyiq,g i \u2032 q y i \u2032 q +Ii\u00b7I i \u2032 ))\n; iv. For each word r = 1, 2, ...,\n\n\u2022 Sample word from a Multinomial distribution:\nw iqr | \u03c6 yiq \u223c M ul(\u03c6 yiq ); v. Sample time stamp t iq | \u03c8 yiqgiq \u223c M ul(\u03c8 yiqgiq );\n\nModel Inference\n\nUnder this model, given observed data {U, E, D}, our target is to infer {c, z, g, y} and to estimate {\u03c0, \u03b8, \u03c6, \u03c8} and parameter \u03b7. The full posterior distribution of TCCD is:\n\nP (\u03c0, \u03b8, \u03c6, \u03c8, \u03b7, c, z, g, y, \u03be|U, E, D, \u03c1, \u03b1, \u03b2, \u03b5, I, t) \u221d P (\u03c0|\u03c1)P (\u03b8|\u03b1)P (\u03c6|\u03b2)P (\u03c8|\u03b5)P (c, g|\u03c0) \u00b7P (z|c, \u03b8)P (w d |z, \u03c6)P (t d |c, z, \u03c8) \u00b7P (y|g, \u03b8)P (w e |y, \u03c6)P (t e |g, y, \u03c8) \u00b7P (e, \u03be|I, \u03b7, g, y).\n\nThe normalizing constant is difficult to calculate, thereby we adopt collapsed Gibbs sampling (Griffiths and Steyvers 2004;Li et al. 2018b) for approximate inference.\n\n\nApproximate Inference\n\nMarginalizing out {\u03c0, \u03b8, \u03c6, \u03c8} in Eq. (5), we get: P (c, z, g, y|.) \u221d \u222b P (\u03c0|\u03c1)P (c, g|\u03c0)d\u03c0 \u00b7 \u222b P (\u03b8|\u03b1)P (z|c, \u03b8)P (y|g, \u03b8)d\u03b8 \u00b7 \u222b P (\u03c6|\u03b2)P (w d |z, \u03c6)P (w e |y, \u03c6)d\u03c6 \u00b7 \u222b P (\u03c8|\u03b5)P (t d |c, z, \u03c8)P (t e |g, y, \u03c8)d\u03c8 \u00b7P (e, \u03be)).\n\n\n(6)\n\nThe first integral in Eq. (6) is calculated as follows.\n\n\u222b P (\u03c0|\u03c1)P (c, g|\u03c0)d\u03c0\n= \u222b ( |U | \u03a0 i=1 \u0393(|C|\u03c1) (\u0393(\u03c1)) |C| |C| \u03a0 c=1 \u03c0 \u03c1\u22121 ic )( |U | \u03a0 i=1 |Di| \u03a0 j=1 |C| \u03a0 c=1 \u03c0 n (c) j ic ) \u00b7( |U | \u03a0 i=1 |Ei| \u03a0 q=1 |C| \u03a0 c=1 \u03c0 n (g) q ig )d\u03c0 = |U | \u03a0 i=1 \u0393(|C|\u03c1) (\u0393(\u03c1)) C \u222b |U | \u03a0 i=1 |C| \u03a0 c=1 \u03c0 n (c) i +\u03c1\u22121 ic d\u03c0 = |U | \u03a0 i=1 \u0393(|C|\u03c1) (\u0393(\u03c1)) |C| \u00b7 |C| \u03a0 c=1 \u0393(n (c) i + \u03c1) \u0393(n (\u00b7) i + |C|\u03c1) ,(7)\nwhere n (c)\n\ni is the number of posts and links assigned to community c of user i. n (\u00b7) i denotes the total number of posts and links assigned to all communities of user i.\n\nFor the second integral in Eq. (6),\n\u222b P (\u03b8|\u03b1)P (z|c, \u03b8)P (y|g, \u03b8)d\u03b8 = \u222b ( |C| \u03a0 c=1 \u0393(|K|\u03b1) (\u0393(\u03b1)) K |K| \u03a0 k=1 \u03b8 \u03b1\u22121 ck ) \u00b7 |U | \u03a0 i=1 |Di| \u03a0 j=1 |K| \u03a0 k=1 \u03b8 n (k) jc ck |U | \u03a0 i=1 |Ei| \u03a0 q=1 |K| \u03a0 k=1 \u03b8 n (k) qg gk d\u03b8 = |C| \u03a0 c=1 \u0393(|K|\u03b1) (\u0393(\u03b1)) |K| \u00b7 |K| \u03a0 k=1 \u0393(n (k) Dc + n (k) Ec + \u03b1) \u0393(n (\u00b7) Dc + n (\u00b7) Ec + |K|\u03b1) ,(8)\nwhere n Ec denote total number of posts and total number of links assigned to community c integrating all topics respectively.\n\nFor the third integral in Eq. (6),\n\u222b P (\u03c6|\u03b2)P (w d |z, \u03c6)P (w e |y, \u03c6)d\u03c6 = \u222b ( |K| \u03a0 k=1 \u0393(|W |\u03b2) (\u0393(\u03b2)) |W | |W | \u03a0 w=1 \u03c6 \u03b2\u22121 kw ) |U | \u03a0 i=1 |Di| \u03a0 j=1 |W | \u03a0 w=1 \u03c6 n (w) jz zw \u00b7 |U | \u03a0 i=1 |Ei| \u03a0 q=1 |W | \u03a0 w=1 \u03c6 n (w) qy yw d\u03c6 = |K| \u03a0 k=1 \u0393(|W |\u03b2) (\u0393(\u03b2)) |W | \u00b7 |W | \u03a0 w=1 \u0393(n (w) Dk + n (w) Ek + \u03b2) \u0393(n (\u00b7) Dk + n (\u00b7) Ek + |W |\u03b2) ,(9)\nwhere n Ek denote total number of times of word w assigned to topic k in posts and link contents respectively. The last integral in Eq. (6) is calculated as follows.\n\n\u222b P (\u03c8|\u03b5)P (t d |c, z, \u03c8)P (t e |g, y, \u03c8)d\u03c8\n= \u222b |C| \u03a0 c=1 |K| \u03a0 k=1 \u0393(|T |\u03b5) (\u0393(\u03b5)) |T | |T | \u03a0 t=1 \u03c8 \u03b5\u22121 ck |U | \u03a0 i=1 |Di| \u03a0 j=1 |T | \u03a0 t=1 \u03c8 n (t) jcz cz \u00b7 |U | \u03a0 i=1 |Ei| \u03a0 q=1 |T | \u03a0 t=1 \u03c8 n (t) qgy gy d\u03c8 = |C| \u03a0 c=1 |K| \u03a0 k=1 \u0393(|T |\u03b5) (\u0393(\u03b5)) |T | \u00b7 \u222b |C| \u03a0 c=1 |K| \u03a0 k=1 |T | \u03a0 t=1 \u03c8 n (t) Dck +n (t) Eck +\u03b5\u22121 ck d\u03c8 = |C| \u03a0 c=1 |K| \u03a0 k=1 \u0393(|T |\u03b5) (\u0393(\u03b5)) |T | \u00b7 T \u03a0 t=1 \u0393(n (t) Dck + n (t) Eck + \u03b5) \u0393(n (\u00b7) Dck + n (\u00b7) Eck + |T |\u03b5) ,(10)\nwhere n Eck denote total number of posts and total number of links assigned to community c with topic k integrating all time stamps respectively.\n\nFor each post d ij sent by user i, we sample its community membership c ij = c and topic z ij = k.\nP (c ij = c|c \u00acij , z ij = k, t ij = t, g, y, .) = P (c, z, g, y) P (c \u00acij , z, g, y) = n (c) i,\u00acij + \u03c1 n (\u00b7) i,\u00acij + |C|\u03c1 \u00b7 n (k) c,\u00acij + \u03b1 n (\u00b7) c,\u00acij + |K|\u03b1 \u00b7 n (t) ck,\u00acij + \u03b5 n (\u00b7) ck,\u00acij + |T |\u03b5 ,(11)\nwhere n ck,\u00acij means the number of occurrence of time stamp t generated by community c and topic k. All dots denote marginal count, e.g., n (\u00b7) i,\u00acij denotes the total number of posts and links assigned to all communities.\n\nP (z ij = k|z \u00acij , c ij = c, t ij = t, g, y, .)\n\n= P (z, c, g, y) P (z \u00acij , c, g, y)\n= n (k) c,\u00acij + \u03b1 n (\u00b7) c,\u00acij + |K|\u03b1 \u00b7 \u03a0 |W | w=1 \u03a0 n (w) ij \u22121 q=0 (n (w) k,\u00acij + q + \u03b2) \u03a0 n (\u00b7) ij \u22121 q=0 (n (\u00b7) k,\u00acij + q + \u03b2) \u00b7 n (t) ck,\u00acij + \u03b5 n (\u00b7) ck,\u00acij + |T |\u03b5 ,(12)\nwhere n (w) ij denotes number of occurrence of word w appearing in the post d ij . n (w) k,\u00acij denotes number of times of word w assigned to topic k with post d ij excluded. n (\u00b7) k,\u00acij is calculated over all words excluding post d ij . Suppose that e ii \u2032 is the q-th link sent by user i. We sample user i's community membership g iq and topic y iq according to its contents. P (g ij = c|g \u00acij , y ij = k, t ij = t, c, z, .) = P (g, c, z, y) P (g \u00acij , c, z, y)\n= n (c) i,\u00acij + \u03c1 n (\u00b7) i,\u00acij + |C|\u03c1 \u00b7 n (k) c,\u00acij + \u03b1 n (\u00b7) c,\u00acij + |K|\u03b1 \u00b7 n (t)\nck,\u00acij + \u03b5 n (\u00b7) ck,\u00acij + |T |\u03b5 \u00b7 \u03d5(\u03c9 ij , \u03be ij ).\n\n(13) P (y ij = k|y \u00acij , g ij = c, t ij = t, c, z, .)\n\n= P (y, c, z, g) P (y \u00acij , c, z, g)\n= n (k) c,\u00acij + \u03b1 n (\u00b7) c,\u00acij + |K|\u03b1 \u00b7 \u03a0 |W | w=1 \u03a0 n (w) ij \u22121 q=0 (n (w) k,\u00acij + q + \u03b2) \u03a0 n (\u00b7) ij \u22121 q=0 (n (\u00b7) k,\u00acij + q + \u03b2) \u00b7 n (t) ck,\u00acij + \u03b5 n (\u00b7) ck,\u00acij + |T |\u03b5 \u00b7 \u03d5(\u03c9 ij , \u03be ij ).(14)\nAt last we sample \u03be ij .\nP (\u03be ij |.) \u221d e \u2212 1 2 \u03beij \u03c9 2 ij P (\u03be ij |1, 0) = P G(1, \u03c9 ij ). (15)\n\nParameter Estimation\n\nWe obtain above samples by running Gibbs sampler for adequate iterations. Then, we estimate as follows:\n\u03c0 ic = n (c) i + \u03c1 n (\u00b7) i + |C|\u03c1 .\n(16)\n\u03b8 ck = n (k) c + \u03b1 n (\u00b7) c + |K|\u03b1 .\n(17)\n\u03c6 kw = n (w) k + \u03b2 n (\u00b7) k + |W |\u03b2 . (18) \u03c8 kc,t = n (t) ck + \u03b5 n (\u00b7) ck + |T |\u03b5 .(19)\nFor parameter \u03b7, we aggregate all community and topic pairs w.r.t all links.\n\n\nAlgorithm Summarization and Time Complexity\n\nOur inference procedure is shown in Alg.1. T denotes the iterations for convergence. For steps 3-6, we sample community indicator and topic indicator for posts of all users. The total number of users is |U | and |D i | is the number of posts of user i. In line 5, because all counters (e.g., how many times a user is assigned to a community) are recorded in memory, equation 7 takes constant time for a Algorithm 1 Inference for TCCD 1: Initialize \u03b1, \u03b2, \u03f5, \u03c1, \u03b7; 2: for iter = 1 : T do For steps 11-12, we calculate \u03b7. It takes \u0398(|E|). Based on the above discussions, the complexity is linear to the data size. As data size grows bigger, the efficiency turns to be lower. Since our key target is to evaluate the accuracy of community detection, we leave parallel implementation of TCCD as our future work.\n\n\nExperiments\n\nWe evaluate our model on two real datasets and compare it with four state-of-the-art baselines. All experiments are implemented on a computer with Intel 4.2GHz CPUs and 32GB RAMs.\n\n\nDatasets\n\nTo accurately evaluate community detection results of TCCD and other baselines, we choose two real datasets with ground-truth: Reddit dataset and DBLP dataset (Wang, Lai, and Philip 2014).\n\nReddit data covers period from August 25, 2012 to August 31, 2012. It includes three sub-forums: Science, Movie and Politics. So, there are three communities. The threads sent by users are used as node contents. We choose one day as a time snap. DBLP dataset is a paper co-authorship network consisting of publications in three research fields from year 2001 to 2011. So, the number of communities is three. We choose one year as a time snap. For Reddit dataset, we remove users who does not have any posts. For DBLP dataset, we remove authors who publish less than four papers. After removing stop words and stemming by PreTexT2, the statistics of the two datasets are summarized in Table 2. \n\n\nBaselines\n\nWe choose four state-of-the-art baselines to evaluate our model's accuracy:\n\n\u2022 Community Level Diffusion (COLD) (Hu et al. 2015). It generates documents and links based on the same latent community membership factor. It assigns a time stamp vector to each document to identify temporal topics of communities. \u2022 Community Profiling and Detection (CPD) (Cai et al. 2017). This model integrates friendship relations, diffusion links and individual preference to identify community profiling. \u2022 Poisson Mixed-Topic Link Model (PMTLM) . It combines the LDA model and Poisson distribution to generate the text of each node and the links between them. \u2022 Community Role Model (CRM) (Han and Tang 2015). It assigns a role to each user and model friendship links and diffusion links in networks based on users' community assignment.\n\n\nMetrics\n\nTo evaluate the accuracy of the community detection outcomes, we use generalized normalized mutual information (GNMI) (Wu, Xiong, and Chen 2009), F-score and Jaccard index as metrics. F-score is the harmonic mean of precision and recall: F 1 = 2\u00b7 precision \u00b7 recall precision + recall . Jaccard index is defined as J(A, B) = |A \u2229 B| |A \u222a B| (i.e., measuring the similarity of sample set A and B). Table 3 shows the result comparisons between baselines and TCCD on two datasets respectively. TCCD outperforms all baselines for all metrics. For Reddit dataset, there are 3,925 isolated posts. They don't appear on links. Our model separates these isolated posts and link posts, such that they do not participate in the formulation of network topology. Results show that our model achieves 42% GNMI improvement, 3% F-score improvement and 3% Jaccard improvement over the secondbest baseline on Reddit. For DBLP dataset, table 3 shows that our model achieves 38% GNMI improvement, 4% Fscore improvement and 6% Jaccard improvement over the second-best baseline on DBLP.  TCCD is more capable to process those networks with isolated user posts, which is a common case in social networks. Even for those networks without isolated node contents such as paper co-authorship networks, TCCD also outperforms all baselines for all metrics.\n\n\nComparison with Baselines\n\n\nA Case Study\n\nIn this section, we analyze four parameters modeled in TCCD on Reddit dataset. They are topic distribution of communities, word distribution of topics, temporal topics of each community, and topic correlations respectively. (i.e., {\u03b8, \u03c6, \u03c8, \u03b7}).\n\n\u2022 Word distribution of each topic Word clouds of three topics are illustrated in Fig.2. It shows that each topic we detected is meaningful (i.e.,Movie, Politics and Science).\n\n\u2022 Topic distribution of each community In Fig.3 \u2022 Time distribution of community and topic In Fig.3, three plots around each community illustrate temporal variations of corresponding topics. Even though each community has a dominant topic, it also includes some discussions about other two topics. The temporal pattern of the dominant topic denotes how most of users in a community focus on the topic at different timestamps.\n\n\u2022 Topic correlations Fig.4 shows the topic correlations with respect to com- munities. Fig.4(a) is the topic correlations inside community Movie, which represents how users in this community interact with each other. The circle with the biggest weight from topic Movie to itself shows that users in community Movie are more likely to talk about Movie topic. The weights of other links are small, which shows that users focusing on Science and Politics also interact with each other but with much less intense communication. Fig.4(b) is the topic correlations inside community Politics. We can see that there are more users talking about topic Politics. The interactions between other topic pairs also exist but with small weights. Fig.4(c) is the topic correlations inside community Science. In Reddit dataset, the number of posts in Science is less than that in other two communities. So, the interactions are sparser than other two communities. Even so, there are more users talking about topic Science. Fig.4(d) represents the topic correlations between community Science and Politics. As it shows, users in the two communities talk about all topics. The reason is that there are 35 percentage of posts in community Science talking about Politics and 16 percentage of posts talking about Movie. The topic correlations between other community pairs also exists with probability smaller than 0.01. So, we don't present them, which means that users in these two different communities seldom interact with each other. \n\n\nParameter Initiation\n\nWe set |C| and |K| to real value according to ground-truth. For \u03b7, we can initiate it at random. For Dirichlet hyperparameters, we run TCCD under different values. The results show that TCCD is not sensitive to Dirichlet hyperparameters, thus we set them to fixed values (i.e., \u03c1 = 0.01, \u03b1 = 0.001, \u03b2 = 0.1, \u03f5 = 0.001). For the threshold for determining overlapping communities, we test its values from 1/|C| to 0.5 with step 0.1. The experiments show that 1/|C| is the best value. For each user, we choose those communities with probabilities bigger than the threshold as his real communities.\n\n\nConclusion and Discussions\n\nIn this paper, we found that there are correlations between topics, which significantly affect community structures. The observation reveals that existing methods are limited to resolve three key issues: a) How to process node contents and edge contents to infer topics and topic correlations in a unified model; b) How to generate network topology considering the influence of topic correlations; c) How to detect the composition of topics inside communities to understand community semantics. We proposed a generative model (TCCD) for community detection which consists of three components, i.e., user post component, link content component and link component. The experimental results show that our model improves the accuracy of community detection and can detect all topics efficiently. It resolves all above key issues. Our work for the first time interprets the mechanism of the composition of topics inside communities to understand community semantics in a natural way. It can also reveal how the popularity of a topic changes over time in a community. We also found that topic correlations in different communities are not consistent. It is the true reflection of communications of users in communities. Because most users in a community mainly focus on primary topics. For the topics that are talked about by few users , the correlations are small. In fact, the fundamental reason is the limitation of community definition which is only based on network topology.\n\nFigure 1 :\n1The graphical representation of our model. The notations are summarized in\n\n\nEc are the number of posts and the number of links assigned to community c with topic k respectively.\n\n\nEk denote the number of times of word w assigned to topic k in posts and link contents respectively. n (\u00b7) Dk and n(\u00b7)    \n\n\nEck are number of posts and number of links assigned to community c with topic k at time stamp t respectively. n\n\n\n\u00acij is number of posts and links assigned to community c sent by user i excluding current post d ij . n (k) c,\u00acij is number of posts and links assigned to community c with topic k excluding current post d ij . n (t)\n\n\n17: end for specific community. In line 6, to compute the second fraction of equation 8, it takes \u0398(|W |) for a specific topic, where |W | is the size of vocabulary. There are |K| topics. So, steps 3-6 takes \u0398(|U | \u00d7 |D| \u00d7 |C| + |U | \u00d7 |D| \u00d7 |K| \u00d7 |W |). In steps 7-10, it computes community indicator, topic indicator and \u03be ij for all links. The number of all links is |E|. Equation 9 and equation 11 takes constant time. Equation 10 takes \u0398(|W |). So, steps 7-10 takes \u0398(|E|\u00d7|C|+|E|\u00d7|K|\u00d7|W |).\n\nFigure 2 :\n2Word clouds of three topics: Movie, Science and Politics.\n\nFigure 3 :\n3Topic distribution of three communities and time distribution of community and topic. Colors represent topics. Circles represent communities.\n\nFigure 4 :\n4Topic correlations with respect to communities. Big circles with labels represent communities (i.e. Movie, Politics and Science). Solid circles with colors represent topics. The weighted arc with different width represents topic correlations. Figure (a) to (c) represent the topic correlations inside communities: Movie, Politics and Science. Figure (d) is the topic correlations between community Science and Politics.\n\nTable 1 :\n1Notations\n\nTable 2 :\n2Summarization of datasets with ground-truth#users \n#links \n#user posts #words \nReddit 23,820 51,149 \n3,925 \n14,370 \nDBLP 24,241 209,351 \n68,702 \n7,769 \n\n\n\nTable 3 :\n3Experimental results comparations on Reddit and DBLPMetrics Datasets \nMethods \n(%) \nCOLD CPD CRM PMTLM Ours \n\nNMI \nReddit 16.24 13.12 38.47 41.61 59.07 \nDBLP 31.77 25.56 20.99 14.94 44.23 \n\nF-score \nReddit 59.81 80.49 69.96 64.30 82.95 \nDBLP 74.90 78.66 70.50 72.01 81.50 \n\nJaccard \nReddit 44.82 70.68 56.49 57.36 72.64 \nDBLP 60.45 65.26 55.39 56.28 69.10 \n\n\n\n\n, three doughnut charts represent three communities (i.e., Movie, Politics and Science). Each color on doughnuts denotes one topic. As it shows, topic Movie and Politics are dominant in community Movie and Politics respectively. But for community Science, though the topic Science is dominant, there are 35 percentage of posts talking about Politics and 16 percentage of posts talking about Movie.\nAcknowledgmentsThis work was supported by the National Key R&D Program of China (No. 2018YFC0809800) and the Natural Science Foundation of China (No. 61772361, 61572353).\nCorrelated topic models. D Blei, J Lafferty, Advances in neural information processing systems. 18147Blei, D., and Lafferty, J. 2006. Correlated topic models. Advances in neural information processing systems 18:147.\n\nFrom community detection to community profiling. H Cai, V W Zheng, F Zhu, K C Chang, .-C Huang, Z , Proceedings of the VLDB Endowment. 107Cai, H.; Zheng, V. W.; Zhu, F.; Chang, K. C.-C.; and Huang, Z. 2017. From community detection to community profiling. Proceedings of the VLDB Endowment 10(7):817-828.\n\nScalable inference for logistic-normal topic models. J Chen, J Zhu, Z Wang, X Zheng, B Zhang, Advances in Neural Information Processing Systems. Chen, J.; Zhu, J.; Wang, Z.; Zheng, X.; and Zhang, B. 2013. Scalable inference for logistic-normal topic models. In Ad- vances in Neural Information Processing Systems, 2445- 2453.\n\nCommunity detection in networks: A user guide. S Fortunato, D Hric, Physics Reports. 659Fortunato, S., and Hric, D. 2016. Community detection in networks: A user guide. Physics Reports 659:1-44.\n\nCommunity structure in social and biological networks. M Girvan, M E Newman, Proceedings of the national academy of sciences. the national academy of sciences99Girvan, M., and Newman, M. E. 2002. Community struc- ture in social and biological networks. Proceedings of the national academy of sciences 99(12):7821-7826.\n\nFinding scientific topics. T L Griffiths, M Steyvers, Proceedings of the National academy of Sciences. 1011supplGriffiths, T. L., and Steyvers, M. 2004. Finding scientific topics. Proceedings of the National academy of Sciences 101(suppl 1):5228-5235.\n\nProbabilistic community and role model for social networks. Y Han, J Tang, Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data MiningACMHan, Y., and Tang, J. 2015. Probabilistic community and role model for social networks. In Proceedings of the 21th ACM SIGKDD International Conference on Knowl- edge Discovery and Data Mining, 407-416. ACM.\n\nJoint identification of network communities and semantics via integrative modeling of network topologies and node contents. D He, Z Feng, D Jin, X Wang, W Zhang, AAAI. He, D.; Feng, Z.; Jin, D.; Wang, X.; and Zhang, W. 2017a. Joint identification of network communities and semantics via integrative modeling of network topologies and node contents. In AAAI.\n\nEfficient correlated topic modeling with topic embedding. J He, Z Hu, T Berg-Kirkpatrick, Y Huang, E P Xing, Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data MiningACMHe, J.; Hu, Z.; Berg-Kirkpatrick, T.; Huang, Y.; and Xing, E. P. 2017b. Efficient correlated topic modeling with topic embedding. In Proceedings of the 23rd ACM SIGKDD In- ternational Conference on Knowledge Discovery and Data Mining, 225-233. ACM.\n\nCommunity level diffusion extraction. Z Hu, J Yao, B Cui, E Xing, Proceedings of the. theHu, Z.; Yao, J.; Cui, B.; and Xing, E. 2015. Commu- nity level diffusion extraction. In Proceedings of the 2015\n\nACM SIGMOD International Conference on Management of Data. ACMACM SIGMOD International Conference on Management of Data, 1555-1569. ACM.\n\nBeyond click graph: Topic modeling for search engine query log analysis. D Jiang, K W Leung, .-T Ng, W Li, H , International Conference on Database Systems for Advanced Applications. SpringerJiang, D.; Leung, K. W.-T.; Ng, W.; and Li, H. 2013. Be- yond click graph: Topic modeling for search engine query log analysis. In International Conference on Database Sys- tems for Advanced Applications, 209-223. Springer.\n\nRobust detection of link communities in large social networks by exploiting link semantics. D Jin, X Wang, R He, D He, J Dang, W Zhang, AAAI Conference on Artificial Intelligence. Jin, D.; Wang, X.; He, R.; He, D.; Dang, J.; and Zhang, W. 2018. Robust detection of link communities in large social networks by exploiting link semantics. In AAAI Conference on Artificial Intelligence.\n\nGenerative topic embedding: a continuous representation of documents. S Li, T.-S Chua, J Zhu, C Miao, Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics. the 54th Annual Meeting of the Association for Computational Linguistics1Li, S.; Chua, T.-S.; Zhu, J.; and Miao, C. 2016. Generative topic embedding: a continuous representation of documents. In Proceedings of the 54th Annual Meeting of the Associa- tion for Computational Linguistics (Volume 1: Long Papers), volume 1, 666-675.\n\nDataless text classification: A topic modeling approach with document manifold. X Li, C Li, J Chi, J Ouyang, C Li, Proceedings of the 27th ACM International Conference on Information and Knowledge Management. the 27th ACM International Conference on Information and Knowledge ManagementACMLi, X.; Li, C.; Chi, J.; Ouyang, J.; and Li, C. 2018a. Data- less text classification: A topic modeling approach with doc- ument manifold. In Proceedings of the 27th ACM Interna- tional Conference on Information and Knowledge Manage- ment, 973-982. ACM.\n\nVariance reduction in black-box variational inference by adaptive importance sampling. X Li, C Li, J Chi, J Ouyang, IJCAI. Li, X.; Li, C.; Chi, J.; and Ouyang, J. 2018b. Variance re- duction in black-box variational inference by adaptive im- portance sampling. In IJCAI, 2404-2410.\n\nDiscovering social circles in ego networks. J Mcauley, J Leskovec, Acm Transactions on Knowledge Discovery from Data. 81Mcauley, J., and Leskovec, J. 2014. Discovering social cir- cles in ego networks. Acm Transactions on Knowledge Dis- covery from Data 8(1):1-28.\n\nModularity and community structure in networks. M E Newman, Proceedings of the national academy of sciences. the national academy of sciences103Newman, M. E. 2006. Modularity and community struc- ture in networks. Proceedings of the national academy of sciences 103(23):8577-8582.\n\nNonnegative matrix tri-factorization with graph regularization for community detection in social networks. Y Pei, N Chakraborty, K Sycara, International Conference on Artificial Intelligence. Pei, Y.; Chakraborty, N.; and Sycara, K. 2015. Nonneg- ative matrix tri-factorization with graph regularization for community detection in social networks. In International Conference on Artificial Intelligence, 2083-2089.\n\nBayesian inference for logistic models using p\u00f3lya-gamma latent variables. N G Polson, J G Scott, J Windle, Journal of the American statistical Association. 108504Polson, N. G.; Scott, J. G.; and Windle, J. 2013. Bayesian inference for logistic models using p\u00f3lya-gamma latent variables. Journal of the American statistical Association 108(504):1339-1349.\n\nDeep recursive network embedding with regular equivalence. K Tu, P Cui, X Wang, P S Yu, W Zhu, Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data MiningACMTu, K.; Cui, P.; Wang, X.; Yu, P. S.; and Zhu, W. 2018. Deep recursive network embedding with regular equivalence. In Proceedings of the 24th ACM SIGKDD International Con- ference on Knowledge Discovery & Data Mining, 2357- 2366. ACM.\n\nNeiwalk: community discovery in dynamic content-based networks. C.-D Wang, J.-H Lai, S Y Philip, IEEE transactions on knowledge and data engineering. 267Wang, C.-D.; Lai, J.-H.; and Philip, S. Y. 2014. Nei- walk: community discovery in dynamic content-based net- works. IEEE transactions on knowledge and data engineer- ing 26(7):1734-1748.\n\nAdapting the right measures for k-means clustering. J Wu, H Xiong, J Chen, Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining. the 15th ACM SIGKDD international conference on Knowledge discovery and data miningACMWu, J.; Xiong, H.; and Chen, J. 2009. Adapting the right measures for k-means clustering. In Proceedings of the 15th ACM SIGKDD international conference on Knowledge dis- covery and data mining, 877-886. ACM.\n\nFinding communities with hierarchical semantics by distinguishing general and specialized topics. G Zhang, D Jin, J Gao, P Jiao, F Fogelman-Souli\u00e9, X Huang, IJCAI. Zhang, G.; Jin, D.; Gao, J.; Jiao, P.; Fogelman-Souli\u00e9, F.; and Huang, X. 2018. Finding communities with hierarchical semantics by distinguishing general and specialized topics. In IJCAI, 3648-3654.\n\nScalable text and link analysis with mixed-topic link models. Y Zhu, X Yan, L Getoor, C Moore, ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. Zhu, Y.; Yan, X.; Getoor, L.; and Moore, C. 2013. Scalable text and link analysis with mixed-topic link models. In ACM SIGKDD International Conference on Knowledge Discov- ery and Data Mining, 473-481.\n", "annotations": {"author": "[{\"end\":163,\"start\":73},{\"end\":265,\"start\":164},{\"end\":409,\"start\":266},{\"end\":605,\"start\":410}]", "publisher": null, "author_last_name": "[{\"end\":85,\"start\":81},{\"end\":170,\"start\":167},{\"end\":282,\"start\":276},{\"end\":421,\"start\":417}]", "author_first_name": "[{\"end\":80,\"start\":73},{\"end\":166,\"start\":164},{\"end\":275,\"start\":266},{\"end\":416,\"start\":410}]", "author_affiliation": "[{\"end\":162,\"start\":87},{\"end\":264,\"start\":189},{\"end\":408,\"start\":319},{\"end\":516,\"start\":441},{\"end\":604,\"start\":518}]", "title": "[{\"end\":70,\"start\":1},{\"end\":675,\"start\":606}]", "venue": null, "abstract": "[{\"end\":2037,\"start\":677}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b17\"},\"end\":2162,\"start\":2149},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2186,\"start\":2162},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":2456,\"start\":2432},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":2590,\"start\":2573},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":2608,\"start\":2590},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":3447,\"start\":3420},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":3481,\"start\":3447},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3635,\"start\":3619},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3666,\"start\":3649},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":3908,\"start\":3892},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":4913,\"start\":4889},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":4930,\"start\":4913},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":5046,\"start\":5030},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":5064,\"start\":5046},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":5080,\"start\":5064},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":5095,\"start\":5080},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":12662,\"start\":12630},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":14879,\"start\":14850},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":14894,\"start\":14879},{\"end\":15659,\"start\":15656},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":20684,\"start\":20656},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":21522,\"start\":21506},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":21762,\"start\":21745},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":22087,\"start\":22068},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":22371,\"start\":22346}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":28179,\"start\":28092},{\"attributes\":{\"id\":\"fig_1\"},\"end\":28283,\"start\":28180},{\"attributes\":{\"id\":\"fig_2\"},\"end\":28408,\"start\":28284},{\"attributes\":{\"id\":\"fig_3\"},\"end\":28523,\"start\":28409},{\"attributes\":{\"id\":\"fig_4\"},\"end\":28741,\"start\":28524},{\"attributes\":{\"id\":\"fig_5\"},\"end\":29239,\"start\":28742},{\"attributes\":{\"id\":\"fig_6\"},\"end\":29310,\"start\":29240},{\"attributes\":{\"id\":\"fig_7\"},\"end\":29465,\"start\":29311},{\"attributes\":{\"id\":\"fig_8\"},\"end\":29898,\"start\":29466},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":29920,\"start\":29899},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":30086,\"start\":29921},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":30457,\"start\":30087},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":30857,\"start\":30458}]", "paragraph": "[{\"end\":2802,\"start\":2053},{\"end\":3909,\"start\":2804},{\"end\":5319,\"start\":3911},{\"end\":5927,\"start\":5321},{\"end\":6434,\"start\":5929},{\"end\":7001,\"start\":6436},{\"end\":7598,\"start\":7003},{\"end\":7726,\"start\":7667},{\"end\":9574,\"start\":7787},{\"end\":9738,\"start\":9576},{\"end\":9949,\"start\":9740},{\"end\":10225,\"start\":9951},{\"end\":10511,\"start\":10245},{\"end\":11045,\"start\":10513},{\"end\":11531,\"start\":11047},{\"end\":11844,\"start\":11533},{\"end\":12321,\"start\":11890},{\"end\":12421,\"start\":12358},{\"end\":12424,\"start\":12423},{\"end\":12663,\"start\":12511},{\"end\":12841,\"start\":12724},{\"end\":13068,\"start\":12906},{\"end\":13431,\"start\":13128},{\"end\":14014,\"start\":13867},{\"end\":14222,\"start\":14188},{\"end\":14270,\"start\":14224},{\"end\":14549,\"start\":14375},{\"end\":14754,\"start\":14551},{\"end\":14922,\"start\":14756},{\"end\":15171,\"start\":14948},{\"end\":15234,\"start\":15179},{\"end\":15257,\"start\":15236},{\"end\":15582,\"start\":15571},{\"end\":15744,\"start\":15584},{\"end\":15781,\"start\":15746},{\"end\":16196,\"start\":16070},{\"end\":16232,\"start\":16198},{\"end\":16703,\"start\":16538},{\"end\":16748,\"start\":16705},{\"end\":17293,\"start\":17148},{\"end\":17393,\"start\":17295},{\"end\":17822,\"start\":17600},{\"end\":17872,\"start\":17824},{\"end\":17910,\"start\":17874},{\"end\":18549,\"start\":18087},{\"end\":18682,\"start\":18632},{\"end\":18737,\"start\":18684},{\"end\":18775,\"start\":18739},{\"end\":18993,\"start\":18969},{\"end\":19190,\"start\":19087},{\"end\":19231,\"start\":19227},{\"end\":19272,\"start\":19268},{\"end\":19436,\"start\":19360},{\"end\":20289,\"start\":19484},{\"end\":20484,\"start\":20305},{\"end\":20685,\"start\":20497},{\"end\":21380,\"start\":20687},{\"end\":21469,\"start\":21394},{\"end\":22216,\"start\":21471},{\"end\":23555,\"start\":22228},{\"end\":23845,\"start\":23600},{\"end\":24021,\"start\":23847},{\"end\":24448,\"start\":24023},{\"end\":25967,\"start\":24450},{\"end\":26586,\"start\":25992},{\"end\":28091,\"start\":26617}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":7786,\"start\":7727},{\"attributes\":{\"id\":\"formula_1\"},\"end\":11889,\"start\":11845},{\"attributes\":{\"id\":\"formula_2\"},\"end\":12357,\"start\":12322},{\"attributes\":{\"id\":\"formula_3\"},\"end\":12510,\"start\":12425},{\"attributes\":{\"id\":\"formula_4\"},\"end\":12723,\"start\":12664},{\"attributes\":{\"id\":\"formula_5\"},\"end\":12905,\"start\":12842},{\"attributes\":{\"id\":\"formula_6\"},\"end\":13127,\"start\":13069},{\"attributes\":{\"id\":\"formula_7\"},\"end\":13866,\"start\":13432},{\"attributes\":{\"id\":\"formula_8\"},\"end\":14187,\"start\":14015},{\"attributes\":{\"id\":\"formula_9\"},\"end\":14356,\"start\":14271},{\"attributes\":{\"id\":\"formula_11\"},\"end\":15570,\"start\":15258},{\"attributes\":{\"id\":\"formula_12\"},\"end\":16069,\"start\":15782},{\"attributes\":{\"id\":\"formula_13\"},\"end\":16537,\"start\":16233},{\"attributes\":{\"id\":\"formula_14\"},\"end\":17147,\"start\":16749},{\"attributes\":{\"id\":\"formula_15\"},\"end\":17599,\"start\":17394},{\"attributes\":{\"id\":\"formula_16\"},\"end\":18086,\"start\":17911},{\"attributes\":{\"id\":\"formula_17\"},\"end\":18631,\"start\":18550},{\"attributes\":{\"id\":\"formula_18\"},\"end\":18968,\"start\":18776},{\"attributes\":{\"id\":\"formula_19\"},\"end\":19063,\"start\":18994},{\"attributes\":{\"id\":\"formula_20\"},\"end\":19226,\"start\":19191},{\"attributes\":{\"id\":\"formula_21\"},\"end\":19267,\"start\":19232},{\"attributes\":{\"id\":\"formula_22\"},\"end\":19359,\"start\":19273}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":7725,\"start\":7718},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":11044,\"start\":11037},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":21378,\"start\":21371},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":22632,\"start\":22625}]", "section_header": "[{\"end\":2051,\"start\":2039},{\"end\":7665,\"start\":7601},{\"end\":10243,\"start\":10228},{\"end\":14373,\"start\":14358},{\"end\":14946,\"start\":14925},{\"end\":15177,\"start\":15174},{\"end\":19085,\"start\":19065},{\"end\":19482,\"start\":19439},{\"end\":20303,\"start\":20292},{\"end\":20495,\"start\":20487},{\"end\":21392,\"start\":21383},{\"end\":22226,\"start\":22219},{\"end\":23583,\"start\":23558},{\"end\":23598,\"start\":23586},{\"end\":25990,\"start\":25970},{\"end\":26615,\"start\":26589},{\"end\":28103,\"start\":28093},{\"end\":29251,\"start\":29241},{\"end\":29322,\"start\":29312},{\"end\":29477,\"start\":29467},{\"end\":29909,\"start\":29900},{\"end\":29931,\"start\":29922},{\"end\":30097,\"start\":30088}]", "table": "[{\"end\":30086,\"start\":29976},{\"end\":30457,\"start\":30151}]", "figure_caption": "[{\"end\":28179,\"start\":28105},{\"end\":28283,\"start\":28182},{\"end\":28408,\"start\":28286},{\"end\":28523,\"start\":28411},{\"end\":28741,\"start\":28526},{\"end\":29239,\"start\":28744},{\"end\":29310,\"start\":29253},{\"end\":29465,\"start\":29324},{\"end\":29898,\"start\":29479},{\"end\":29920,\"start\":29911},{\"end\":29976,\"start\":29933},{\"end\":30151,\"start\":30099},{\"end\":30857,\"start\":30460}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":10405,\"start\":10400},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":23933,\"start\":23928},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":24070,\"start\":24065},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":24122,\"start\":24117},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":24476,\"start\":24471},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":24545,\"start\":24537},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":24982,\"start\":24974},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":25189,\"start\":25181},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":25464,\"start\":25456}]", "bib_author_first_name": "[{\"end\":31055,\"start\":31054},{\"end\":31063,\"start\":31062},{\"end\":31297,\"start\":31296},{\"end\":31304,\"start\":31303},{\"end\":31306,\"start\":31305},{\"end\":31315,\"start\":31314},{\"end\":31322,\"start\":31321},{\"end\":31324,\"start\":31323},{\"end\":31335,\"start\":31332},{\"end\":31344,\"start\":31343},{\"end\":31607,\"start\":31606},{\"end\":31615,\"start\":31614},{\"end\":31622,\"start\":31621},{\"end\":31630,\"start\":31629},{\"end\":31639,\"start\":31638},{\"end\":31928,\"start\":31927},{\"end\":31941,\"start\":31940},{\"end\":32132,\"start\":32131},{\"end\":32142,\"start\":32141},{\"end\":32144,\"start\":32143},{\"end\":32424,\"start\":32423},{\"end\":32426,\"start\":32425},{\"end\":32439,\"start\":32438},{\"end\":32710,\"start\":32709},{\"end\":32717,\"start\":32716},{\"end\":33243,\"start\":33242},{\"end\":33249,\"start\":33248},{\"end\":33257,\"start\":33256},{\"end\":33264,\"start\":33263},{\"end\":33272,\"start\":33271},{\"end\":33537,\"start\":33536},{\"end\":33543,\"start\":33542},{\"end\":33549,\"start\":33548},{\"end\":33569,\"start\":33568},{\"end\":33578,\"start\":33577},{\"end\":33580,\"start\":33579},{\"end\":34062,\"start\":34061},{\"end\":34068,\"start\":34067},{\"end\":34075,\"start\":34074},{\"end\":34082,\"start\":34081},{\"end\":34437,\"start\":34436},{\"end\":34446,\"start\":34445},{\"end\":34448,\"start\":34447},{\"end\":34459,\"start\":34456},{\"end\":34465,\"start\":34464},{\"end\":34471,\"start\":34470},{\"end\":34872,\"start\":34871},{\"end\":34879,\"start\":34878},{\"end\":34887,\"start\":34886},{\"end\":34893,\"start\":34892},{\"end\":34899,\"start\":34898},{\"end\":34907,\"start\":34906},{\"end\":35235,\"start\":35234},{\"end\":35244,\"start\":35240},{\"end\":35252,\"start\":35251},{\"end\":35259,\"start\":35258},{\"end\":35766,\"start\":35765},{\"end\":35772,\"start\":35771},{\"end\":35778,\"start\":35777},{\"end\":35785,\"start\":35784},{\"end\":35795,\"start\":35794},{\"end\":36317,\"start\":36316},{\"end\":36323,\"start\":36322},{\"end\":36329,\"start\":36328},{\"end\":36336,\"start\":36335},{\"end\":36557,\"start\":36556},{\"end\":36568,\"start\":36567},{\"end\":36827,\"start\":36826},{\"end\":36829,\"start\":36828},{\"end\":37168,\"start\":37167},{\"end\":37175,\"start\":37174},{\"end\":37190,\"start\":37189},{\"end\":37552,\"start\":37551},{\"end\":37554,\"start\":37553},{\"end\":37564,\"start\":37563},{\"end\":37566,\"start\":37565},{\"end\":37575,\"start\":37574},{\"end\":37893,\"start\":37892},{\"end\":37899,\"start\":37898},{\"end\":37906,\"start\":37905},{\"end\":37914,\"start\":37913},{\"end\":37916,\"start\":37915},{\"end\":37922,\"start\":37921},{\"end\":38414,\"start\":38410},{\"end\":38425,\"start\":38421},{\"end\":38432,\"start\":38431},{\"end\":38434,\"start\":38433},{\"end\":38741,\"start\":38740},{\"end\":38747,\"start\":38746},{\"end\":38756,\"start\":38755},{\"end\":39258,\"start\":39257},{\"end\":39267,\"start\":39266},{\"end\":39274,\"start\":39273},{\"end\":39281,\"start\":39280},{\"end\":39289,\"start\":39288},{\"end\":39308,\"start\":39307},{\"end\":39586,\"start\":39585},{\"end\":39593,\"start\":39592},{\"end\":39600,\"start\":39599},{\"end\":39610,\"start\":39609}]", "bib_author_last_name": "[{\"end\":31060,\"start\":31056},{\"end\":31072,\"start\":31064},{\"end\":31301,\"start\":31298},{\"end\":31312,\"start\":31307},{\"end\":31319,\"start\":31316},{\"end\":31330,\"start\":31325},{\"end\":31341,\"start\":31336},{\"end\":31612,\"start\":31608},{\"end\":31619,\"start\":31616},{\"end\":31627,\"start\":31623},{\"end\":31636,\"start\":31631},{\"end\":31645,\"start\":31640},{\"end\":31938,\"start\":31929},{\"end\":31946,\"start\":31942},{\"end\":32139,\"start\":32133},{\"end\":32151,\"start\":32145},{\"end\":32436,\"start\":32427},{\"end\":32448,\"start\":32440},{\"end\":32714,\"start\":32711},{\"end\":32722,\"start\":32718},{\"end\":33246,\"start\":33244},{\"end\":33254,\"start\":33250},{\"end\":33261,\"start\":33258},{\"end\":33269,\"start\":33265},{\"end\":33278,\"start\":33273},{\"end\":33540,\"start\":33538},{\"end\":33546,\"start\":33544},{\"end\":33566,\"start\":33550},{\"end\":33575,\"start\":33570},{\"end\":33585,\"start\":33581},{\"end\":34065,\"start\":34063},{\"end\":34072,\"start\":34069},{\"end\":34079,\"start\":34076},{\"end\":34087,\"start\":34083},{\"end\":34443,\"start\":34438},{\"end\":34454,\"start\":34449},{\"end\":34462,\"start\":34460},{\"end\":34468,\"start\":34466},{\"end\":34876,\"start\":34873},{\"end\":34884,\"start\":34880},{\"end\":34890,\"start\":34888},{\"end\":34896,\"start\":34894},{\"end\":34904,\"start\":34900},{\"end\":34913,\"start\":34908},{\"end\":35238,\"start\":35236},{\"end\":35249,\"start\":35245},{\"end\":35256,\"start\":35253},{\"end\":35264,\"start\":35260},{\"end\":35769,\"start\":35767},{\"end\":35775,\"start\":35773},{\"end\":35782,\"start\":35779},{\"end\":35792,\"start\":35786},{\"end\":35798,\"start\":35796},{\"end\":36320,\"start\":36318},{\"end\":36326,\"start\":36324},{\"end\":36333,\"start\":36330},{\"end\":36343,\"start\":36337},{\"end\":36565,\"start\":36558},{\"end\":36577,\"start\":36569},{\"end\":36836,\"start\":36830},{\"end\":37172,\"start\":37169},{\"end\":37187,\"start\":37176},{\"end\":37197,\"start\":37191},{\"end\":37561,\"start\":37555},{\"end\":37572,\"start\":37567},{\"end\":37582,\"start\":37576},{\"end\":37896,\"start\":37894},{\"end\":37903,\"start\":37900},{\"end\":37911,\"start\":37907},{\"end\":37919,\"start\":37917},{\"end\":37926,\"start\":37923},{\"end\":38419,\"start\":38415},{\"end\":38429,\"start\":38426},{\"end\":38441,\"start\":38435},{\"end\":38744,\"start\":38742},{\"end\":38753,\"start\":38748},{\"end\":38761,\"start\":38757},{\"end\":39264,\"start\":39259},{\"end\":39271,\"start\":39268},{\"end\":39278,\"start\":39275},{\"end\":39286,\"start\":39282},{\"end\":39305,\"start\":39290},{\"end\":39314,\"start\":39309},{\"end\":39590,\"start\":39587},{\"end\":39597,\"start\":39594},{\"end\":39607,\"start\":39601},{\"end\":39616,\"start\":39611}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":5490327},\"end\":31245,\"start\":31029},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":2392114},\"end\":31551,\"start\":31247},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":5872316},\"end\":31878,\"start\":31553},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":12845103},\"end\":32074,\"start\":31880},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":2444655},\"end\":32394,\"start\":32076},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":15671300},\"end\":32647,\"start\":32396},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":207227233},\"end\":33116,\"start\":32649},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":12246137},\"end\":33476,\"start\":33118},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":12118784},\"end\":34021,\"start\":33478},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":13642519},\"end\":34223,\"start\":34023},{\"attributes\":{\"id\":\"b10\"},\"end\":34361,\"start\":34225},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":7469018},\"end\":34777,\"start\":34363},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":19119861},\"end\":35162,\"start\":34779},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":12075649},\"end\":35683,\"start\":35164},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":53034414},\"end\":36227,\"start\":35685},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":51608060},\"end\":36510,\"start\":36229},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":108475},\"end\":36776,\"start\":36512},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":2774707},\"end\":37058,\"start\":36778},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":6707501},\"end\":37474,\"start\":37060},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":2859721},\"end\":37831,\"start\":37476},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":50776812},\"end\":38344,\"start\":37833},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":14484908},\"end\":38686,\"start\":38346},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":10079637},\"end\":39157,\"start\":38688},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":51610035},\"end\":39521,\"start\":39159},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":176425},\"end\":39895,\"start\":39523}]", "bib_title": "[{\"end\":31052,\"start\":31029},{\"end\":31294,\"start\":31247},{\"end\":31604,\"start\":31553},{\"end\":31925,\"start\":31880},{\"end\":32129,\"start\":32076},{\"end\":32421,\"start\":32396},{\"end\":32707,\"start\":32649},{\"end\":33240,\"start\":33118},{\"end\":33534,\"start\":33478},{\"end\":34059,\"start\":34023},{\"end\":34434,\"start\":34363},{\"end\":34869,\"start\":34779},{\"end\":35232,\"start\":35164},{\"end\":35763,\"start\":35685},{\"end\":36314,\"start\":36229},{\"end\":36554,\"start\":36512},{\"end\":36824,\"start\":36778},{\"end\":37165,\"start\":37060},{\"end\":37549,\"start\":37476},{\"end\":37890,\"start\":37833},{\"end\":38408,\"start\":38346},{\"end\":38738,\"start\":38688},{\"end\":39255,\"start\":39159},{\"end\":39583,\"start\":39523}]", "bib_author": "[{\"end\":31062,\"start\":31054},{\"end\":31074,\"start\":31062},{\"end\":31303,\"start\":31296},{\"end\":31314,\"start\":31303},{\"end\":31321,\"start\":31314},{\"end\":31332,\"start\":31321},{\"end\":31343,\"start\":31332},{\"end\":31347,\"start\":31343},{\"end\":31614,\"start\":31606},{\"end\":31621,\"start\":31614},{\"end\":31629,\"start\":31621},{\"end\":31638,\"start\":31629},{\"end\":31647,\"start\":31638},{\"end\":31940,\"start\":31927},{\"end\":31948,\"start\":31940},{\"end\":32141,\"start\":32131},{\"end\":32153,\"start\":32141},{\"end\":32438,\"start\":32423},{\"end\":32450,\"start\":32438},{\"end\":32716,\"start\":32709},{\"end\":32724,\"start\":32716},{\"end\":33248,\"start\":33242},{\"end\":33256,\"start\":33248},{\"end\":33263,\"start\":33256},{\"end\":33271,\"start\":33263},{\"end\":33280,\"start\":33271},{\"end\":33542,\"start\":33536},{\"end\":33548,\"start\":33542},{\"end\":33568,\"start\":33548},{\"end\":33577,\"start\":33568},{\"end\":33587,\"start\":33577},{\"end\":34067,\"start\":34061},{\"end\":34074,\"start\":34067},{\"end\":34081,\"start\":34074},{\"end\":34089,\"start\":34081},{\"end\":34445,\"start\":34436},{\"end\":34456,\"start\":34445},{\"end\":34464,\"start\":34456},{\"end\":34470,\"start\":34464},{\"end\":34474,\"start\":34470},{\"end\":34878,\"start\":34871},{\"end\":34886,\"start\":34878},{\"end\":34892,\"start\":34886},{\"end\":34898,\"start\":34892},{\"end\":34906,\"start\":34898},{\"end\":34915,\"start\":34906},{\"end\":35240,\"start\":35234},{\"end\":35251,\"start\":35240},{\"end\":35258,\"start\":35251},{\"end\":35266,\"start\":35258},{\"end\":35771,\"start\":35765},{\"end\":35777,\"start\":35771},{\"end\":35784,\"start\":35777},{\"end\":35794,\"start\":35784},{\"end\":35800,\"start\":35794},{\"end\":36322,\"start\":36316},{\"end\":36328,\"start\":36322},{\"end\":36335,\"start\":36328},{\"end\":36345,\"start\":36335},{\"end\":36567,\"start\":36556},{\"end\":36579,\"start\":36567},{\"end\":36838,\"start\":36826},{\"end\":37174,\"start\":37167},{\"end\":37189,\"start\":37174},{\"end\":37199,\"start\":37189},{\"end\":37563,\"start\":37551},{\"end\":37574,\"start\":37563},{\"end\":37584,\"start\":37574},{\"end\":37898,\"start\":37892},{\"end\":37905,\"start\":37898},{\"end\":37913,\"start\":37905},{\"end\":37921,\"start\":37913},{\"end\":37928,\"start\":37921},{\"end\":38421,\"start\":38410},{\"end\":38431,\"start\":38421},{\"end\":38443,\"start\":38431},{\"end\":38746,\"start\":38740},{\"end\":38755,\"start\":38746},{\"end\":38763,\"start\":38755},{\"end\":39266,\"start\":39257},{\"end\":39273,\"start\":39266},{\"end\":39280,\"start\":39273},{\"end\":39288,\"start\":39280},{\"end\":39307,\"start\":39288},{\"end\":39316,\"start\":39307},{\"end\":39592,\"start\":39585},{\"end\":39599,\"start\":39592},{\"end\":39609,\"start\":39599},{\"end\":39618,\"start\":39609}]", "bib_venue": "[{\"end\":32234,\"start\":32202},{\"end\":32907,\"start\":32824},{\"end\":33770,\"start\":33687},{\"end\":34112,\"start\":34109},{\"end\":35427,\"start\":35355},{\"end\":35971,\"start\":35894},{\"end\":36919,\"start\":36887},{\"end\":38107,\"start\":38026},{\"end\":38946,\"start\":38863},{\"end\":31123,\"start\":31074},{\"end\":31380,\"start\":31347},{\"end\":31696,\"start\":31647},{\"end\":31963,\"start\":31948},{\"end\":32200,\"start\":32153},{\"end\":32497,\"start\":32450},{\"end\":32822,\"start\":32724},{\"end\":33284,\"start\":33280},{\"end\":33685,\"start\":33587},{\"end\":34107,\"start\":34089},{\"end\":34282,\"start\":34225},{\"end\":34544,\"start\":34474},{\"end\":34957,\"start\":34915},{\"end\":35353,\"start\":35266},{\"end\":35892,\"start\":35800},{\"end\":36350,\"start\":36345},{\"end\":36628,\"start\":36579},{\"end\":36885,\"start\":36838},{\"end\":37250,\"start\":37199},{\"end\":37631,\"start\":37584},{\"end\":38024,\"start\":37928},{\"end\":38494,\"start\":38443},{\"end\":38861,\"start\":38763},{\"end\":39321,\"start\":39316},{\"end\":39692,\"start\":39618}]"}}}, "year": 2023, "month": 12, "day": 17}