{"id": 215772200, "updated": "2023-11-10 23:35:55.288", "metadata": {"title": "Detection of Atrial Fibrillation Using 1D Convolutional Neural Network.", "authors": "[{\"first\":\"Chaur-Heh\",\"last\":\"Hsieh\",\"middle\":[]},{\"first\":\"Yan-Shuo\",\"last\":\"Li\",\"middle\":[]},{\"first\":\"Bor-Jiunn\",\"last\":\"Hwang\",\"middle\":[]},{\"first\":\"Ching-Hua\",\"last\":\"Hsiao\",\"middle\":[]}]", "venue": "Sensors", "journal": "Sensors", "publication_date": {"year": 2020, "month": null, "day": null}, "abstract": "The automatic detection of atrial fibrillation (AF) is crucial for its association with the risk of embolic stroke. Most of the existing AF detection methods usually convert 1D time-series electrocardiogram (ECG) signal into 2D spectrogram to train a complex AF detection system, which results in heavy training computation and high implementation cost. This paper proposes an AF detection method based on an end-to-end 1D convolutional neural network (CNN) architecture to raise the detection accuracy and reduce network complexity. By investigating the impact of major components of a convolutional block on detection accuracy and using grid search to obtain optimal hyperparameters of the CNN, we develop a simple, yet effective 1D CNN. Since the dataset provided by PhysioNet Challenge 2017 contains ECG recordings with different lengths, we also propose a length normalization algorithm to generate equal-length records to meet the requirement of CNN. Experimental results and analysis indicate that our method of 1D CNN achieves an average F1 score of 78.2%, which has better detection accuracy with lower network complexity, as compared with the existing deep learning-based methods.", "fields_of_study": "[\"Medicine\"]", "external_ids": {"arxiv": null, "mag": "3015494572", "acl": null, "pubmed": "32290113", "pubmedcentral": "7180882", "dblp": "journals/sensors/HsiehLHH20", "doi": "10.3390/s20072136"}}, "content": {"source": {"pdf_hash": "a824267373b73f62321190820271972612307c7e", "pdf_src": "PubMedCentral", "pdf_uri": null, "oa_url_match": false, "oa_info": {"license": "CCBY", "open_access_url": "https://www.mdpi.com/1424-8220/20/7/2136/pdf", "status": "GOLD"}}, "grobid": {"id": "be97a111341630df5efb81054001a5402f9b6e44", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/a824267373b73f62321190820271972612307c7e.txt", "contents": "\nDetection of Atrial Fibrillation Using 1D Convolutional Neural Network\nPublished: 10 April 2020\n\nChaur-Heh Hsieh \nCollege of Artificial Intelligence\nYango University\n350015FuzhouChina\n\nYan-Shuo Li \nDepartment of Computer and Communication Engineering\nMing Chuan University\nTaoyuan 333Taiwan\n\nBor-Jiunn Hwang bjhwang@mail.mcu.edu.tw \nDepartment of Computer and Communication Engineering\nMing Chuan University\nTaoyuan 333Taiwan\n\nChing-Hua Hsiao \nDepartment of Computer and Communication Engineering\nMing Chuan University\nTaoyuan 333Taiwan\n\nDetection of Atrial Fibrillation Using 1D Convolutional Neural Network\nPublished: 10 April 202010.3390/s20072136Received: 28 February 2020; Accepted: 8 April 2020;sensors Article * Correspondence:electrocardiogram (ECG)atrial fibrillation (AF)convolutional neural network (CNN)deep learning\nThe automatic detection of atrial fibrillation (AF) is crucial for its association with the risk of embolic stroke. Most of the existing AF detection methods usually convert 1D time-series electrocardiogram (ECG) signal into 2D spectrogram to train a complex AF detection system, which results in heavy training computation and high implementation cost. This paper proposes an AF detection method based on an end-to-end 1D convolutional neural network (CNN) architecture to raise the detection accuracy and reduce network complexity. By investigating the impact of major components of a convolutional block on detection accuracy and using grid search to obtain optimal hyperparameters of the CNN, we develop a simple, yet effective 1D CNN. Since the dataset provided by PhysioNet Challenge 2017 contains ECG recordings with different lengths, we also propose a length normalization algorithm to generate equal-length records to meet the requirement of CNN. Experimental results and analysis indicate that our method of 1D CNN achieves an average F 1 score of 78.2%, which has better detection accuracy with lower network complexity, as compared with the existing deep learning-based methods.\n\nIntroduction\n\nAn arrhythmia is an irregular heart beating problem. A common type of arrhythmia is atrial fibrillation (AF) caused by abnormal sinus rhythm and irregular heartbeat which could lead to complications such as heart attack [1]. According to a report from the National Institute of Health, there are 2.2 million Americans suffering from AF and the possibility of having a stroke increases with age. A recent investigation [2] showed a 12% increase in the number of people in the UK diagnosed with heart failure from 2002 to 2014. These increasing heart disease problems lead to a heavy financial burden among countries. A study [3] showed that the average economic cost of heart failure was estimated at about USD 108 billion in 197 countries. Due to the increase of atrial fibrillation, development of an effective automatic detection method for AF from electrocardiogram (ECG) signals is valuable for healthcare. However, so far it is still a challenging task for computers due to its episodic nature [4,5].\n\nECG is a medical signal which tests the abnormality of the heart by measuring its electrical activity. A beat of ECG signals can be observed by five characteristic waves-P, Q, R, S, and T-as shown in Figure 1 [6]. P wave stands for atrial depolarization; QRS complex corresponds to the depolarization of the right and left ventricles, and contraction of the ventricular muscles; T wave represents repolarization of the ventricles. The abnormality of the ECG signal is generally identified by using classification techniques [7], which are achieved by extracting the features of the ECG that can discriminate the defined categories. Conventionally, the features are derived from the magnitude, duration, and area of the QRS, T, and possibly P waves [8].\n\nIn order to improve detection and classification performance of ECG signals, several analysis methods based on conventional machine learning have been developed [8][9][10][11][12][13][14][15][16][17][18]. They first obtain hand-crafted features through conventional feature extraction and selection algorithms, and then train a classification model using these features. The typical features such as QRS complex, R-R interval, R amplitude difference, and heart rate turbulence offset, are extracted from ECG signals. Various classifiers have been applied to the problem including particle swarm optimization (PSO), support vector machines (SVM), self-organizing map (SOM), fuzzy c-means (FCM) clustering, rough sets, k-nearest neighbor (KNN), artificial neural network (ANN) classifier, and quantum neural network (QNN) [8][9][10][11][12][13][14][15][16][17][18][19].\n\nThe quality of extracted features significantly affects the performance of the detection/classification. However, the hand-crafted features are not generally robust with respect to many variations, such as scaling, noise, displacement, etc. Recently, deep learning (DL) has achieved great success in various problems, especially in computer vision and speech recognition. Several researchers have applied DL frameworks such as stacked auto-encoder, convolutional neural networks (CNNs), and long short-term memory (LSTM) for the analysis of ECG signals [20][21][22][23][24].\n\nLuo et al. [20] presents a patient-specific deep neural network (DNN) heartbeat classifier. A stacked denoising auto-encoder (SDA) is pretrained by a time-frequency spectrogram obtained with unlabeled modified frequency slice wavelet transform. Then, a deep neural network model is initialized by the parameters of the trained SDA and then updated with fine-tuning.\n\nIn another study [21], the authors apply the approach of Hannun et al. [22] who constructed a 34-layer 1D ResNet for classification of the PhysioNet Challenge dataset. They also slightly modified the ResNet by reducing the number of filters per convolutional layer and using different input segment lengths. For simplicity we refer to the two methods as ResNet-1 and ResNet-2, respectively.\n\nWarrick et al. [23] proposed a CL3 (one CNN and three LSTMs) network for ECG classification that consists of two learning stages: representation learning and sequence learning. The former The characteristics of AF can be diagnosed by ECG, including no clear P wave, abnormal pattern of R-R interval, irregularity of heart beating, and small oscillation (frequency 4-8 Hz) of ECG baseline.\n\nThe abnormality of the ECG signal is generally identified by using classification techniques [7], which are achieved by extracting the features of the ECG that can discriminate the defined categories. Conventionally, the features are derived from the magnitude, duration, and area of the QRS, T, and possibly P waves [8].\n\nIn order to improve detection and classification performance of ECG signals, several analysis methods based on conventional machine learning have been developed [8][9][10][11][12][13][14][15][16][17][18]. They first obtain hand-crafted features through conventional feature extraction and selection algorithms, and then train a classification model using these features. The typical features such as QRS complex, R-R interval, R amplitude difference, and heart rate turbulence offset, are extracted from ECG signals. Various classifiers have been applied to the problem including particle swarm optimization (PSO), support vector machines (SVM), self-organizing map (SOM), fuzzy c-means (FCM) clustering, rough sets, k-nearest neighbor (KNN), artificial neural network (ANN) classifier, and quantum neural network (QNN) [8][9][10][11][12][13][14][15][16][17][18][19].\n\nThe quality of extracted features significantly affects the performance of the detection/classification. However, the hand-crafted features are not generally robust with respect to many variations, such as scaling, noise, displacement, etc. Recently, deep learning (DL) has achieved great success in various problems, especially in computer vision and speech recognition. Several researchers have applied DL frameworks such as stacked auto-encoder, convolutional neural networks (CNNs), and long short-term memory (LSTM) for the analysis of ECG signals [20][21][22][23][24].\n\nLuo et al. [20] presents a patient-specific deep neural network (DNN) heartbeat classifier. A stacked denoising auto-encoder (SDA) is pretrained by a time-frequency spectrogram obtained with unlabeled modified frequency slice wavelet transform. Then, a deep neural network model is initialized by the parameters of the trained SDA and then updated with fine-tuning.\n\nIn another study [21], the authors apply the approach of Hannun et al. [22] who constructed a 34-layer 1D ResNet for classification of the PhysioNet Challenge dataset. They also slightly modified the ResNet by reducing the number of filters per convolutional layer and using different input segment lengths. For simplicity we refer to the two methods as ResNet-1 and ResNet-2, respectively. Warrick et al. [23] proposed a CL3 (one CNN and three LSTMs) network for ECG classification that consists of two learning stages: representation learning and sequence learning. The former employs a 1D CNN to extract local and discriminative features of input signals; the latter is implemented with three stacked LSTM layers to learn long-term features.\n\nZihlmann and colleagues [24] proposed a method which applies the spectrogram of the ECG signal to train on a convolutional recurrent neural network (CRNN). This method first transforms ECG data into a 2D spectrogram using fast Fourier transform. The spectrogram is fed into a stack of 2D convolutional blocks and then a three-layer bidirectional LSTM network is followed for feature aggregation. However, the network complexity is rather high with more than 10 million training parameters.\n\nIn summary, the existing ML-based methods utilize expert knowledge to extract features, which is both time consuming and error-prone. The DL-based methods can be categorized into 1D and 2D schemes. In the 1D scheme, the time-series 1D data is directly fed into the neural network. On the contrary, for the 2D scheme, the time-series signal is converted into a 2D form (i.e., a spectrogram) before inputting the subsequent neural network. Compared to 1D schemes, 2D schemes improve the classification accuracy by around 3% [21,23,24] but at the cost of overhead of conversion and increasing the network complexity.\n\nIn order to raise the detection accuracy and reduce network complexity, this paper proposes an AF detection method based on an end-to-end 1D CNN architecture. By investigating the impact of major components of a convolutional block on detection accuracy and using grid search to obtain optimal hyperparameters of CNN, we develop a simple, yet effective 1D CNN. The 1D time-series raw data is fed into the network without any conversion. In addition, this AF detection is data driven, (i.e., the features of the ECG signal and classification model are learnt from input data directly). Since the dataset provided by PhysioNet Challenge 2017 contains ECG recordings with different lengths, we also propose a length normalization algorithm to generate equal-length records to meet the requirement of the CNN.\n\nConventionally, prediction accuracy (detection or classification accuracy) is often used as a metric for the evaluation of DNN-based classifiers. However, the complexity of DNNs is also important since it affects the computational load and implementation cost of a system. Thus, in this paper we use prediction accuracy and network complexity, presented in our previous work [25], as the metrics for the evaluation and comparison of the deep neural networks. The major contributions of this work are summarized as follows:\n\n\u2022\n\nWe propose a simple, yet effective AF detection method based on end-to-end 1D CNN architecture to classify time-series 1D ECG signal directly without converting it to 2D data. Through exhaustive evaluation, we prove our method achieves better detection accuracy than the existing DL-based methods. In addition, the proposed method reduces network complexity significantly, as compared with the second-ranked method, CRNN.\n\n\n\u2022\n\nWe study the effect of the batch normalization and pooling methods on detection accuracy, and then design the best network by combing the grid search method.\n\n\n\u2022\n\nWe present a length normalization algorithm to solve variable length of ECG recordings.\n\nThe remainder of this paper is organized as follows. Section 2 first gives an overview of the proposed method, describes the data pre-processing algorithm, and then the design of 1D CNN. The numerical analysis and performance comparison are given in Section 3. Finally, the conclusion is drawn in Section 4.\n\n\nProposed AF Detection\n\n\nSystem Overview\n\nThe proposed AF detection system shown in Figure 2 includes data length normalization, offline training, and online prediction. The length of ECG recordings of the dataset we used is variable, and thus not suitable for the deep neural network. Therefore, we developed a pre-processing algorithm to make each recording fixed in length. The dataset contains four classes of ECG signals: AF, Normal, Noisy, and Other. The detection of AF is easily formulated as a classification problem. Thus, we designed a 1D CNN for the classification of the ECG signals. The classifier design consists of training and inference. In the training phase, the 1D CNN predicts one of the four classes for training data. The loss (error) between the predicted output and ground truth output is calculated and then back-propagates to each layer of the network so as to update the parameters of the network iteratively. An optimal network model is obtained when the iteration process converges. In the inference phase, the test data is applied to the 1D CNN with the optimal model, and the predicted result is generated.\n\nSensors 2020, 20, x FOR PEER REVIEW 4 of 18 designed a 1D CNN for the classification of the ECG signals. The classifier design consists of training and inference. In the training phase, the 1D CNN predicts one of the four classes for training data. The loss (error) between the predicted output and ground truth output is calculated and then backpropagates to each layer of the network so as to update the parameters of the network iteratively. An optimal network model is obtained when the iteration process converges. In the inference phase, the test data is applied to the 1D CNN with the optimal model, and the predicted result is generated. \n\n\nData Length Normalization\n\nDue to the difficulty of putting variable-length data into a deep neural network, length normalization, which makes each recording into a segment with a fixed length, should be performed first. The length normalization problem is rather common across many domains. In studies by Andreotti et al. [21] and Zhou et al. [26], the authors manually preset a required length (called length threshold here), and then cut the original data into segments with the required length. The method is rather simple, but its major problem is that the setting of the length threshold is done manually, which does not consider the characteristic of the dataset. Setting length threshold to any value in the range of the recording lengths (9 s to 61 s) will generate bias. The problem is how to minimize the bias by generating an appropriate length threshold in an automatic mechanism.\n\nIn this work, we develop a histogram-based length normalization algorithm, which automatically determines the length threshold value using the histogram distribution of the length of the recordings. The length threshold calculated by this algorithm is 30 s, which corresponds to 9000 samples since the sampling rate is 300 samples per second. The histogram of the lengths of 8528 recordings is shown in Figure 3. It indicates that the length of the majority of data falls in the range of 30 s. Obviously, our algorithm can adapt the characteristic changes of input data and will create the least bias in the statistical sense since it considers the most frequent data length as a threshold. \n\n\nData Length Normalization\n\nDue to the difficulty of putting variable-length data into a deep neural network, length normalization, which makes each recording into a segment with a fixed length, should be performed first. The length normalization problem is rather common across many domains. In studies by Andreotti et al. [21] and Zhou et al. [26], the authors manually preset a required length (called length threshold here), and then cut the original data into segments with the required length. The method is rather simple, but its major problem is that the setting of the length threshold is done manually, which does not consider the characteristic of the dataset. Setting length threshold to any value in the range of the recording lengths (9 s to 61 s) will generate bias. The problem is how to minimize the bias by generating an appropriate length threshold in an automatic mechanism.\n\nIn this work, we develop a histogram-based length normalization algorithm, which automatically determines the length threshold value using the histogram distribution of the length of the recordings. The length threshold calculated by this algorithm is 30 s, which corresponds to 9000 samples since the sampling rate is 300 samples per second. The histogram of the lengths of 8528 recordings is shown in Figure 3. It indicates that the length of the majority of data falls in the range of 30 s. Obviously, our algorithm can adapt the characteristic changes of input data and will create the least bias in the statistical sense since it considers the most frequent data length as a threshold.  The normalization algorithm not only solves the variable length data problem but also generates more data to train the deep neural network. The pseudocode of the algorithm is shown in Algorithm 1. If the recording contains just 9000 samples (30 s), this recording will be used directly without any modification. If the recording contains more than 9000 samples, multiple segments will be generated with 50% overlap between adjacent segments. Each segment from the same recording has 9000 samples and will be assigned the same label. For instance, an AF recording containing 18,600 samples (61 s) will be replaced by four segments containing 9000 samples and labeled as AF. Finally, if the length is less than 9000, we concatenate the recording with the same label to reach 9000 samples. After pre-processing, the number of recordings for AF, Normal, Noisy, and Other is 903, 5959, 299, and 2990, respectively, increasing from 8528 to 10,151 in total. The design of deep neural network architecture is rather challenging, and involves several aspects such as performance metric, loss function, optimization algorithm, and hyperparameter setting [27]. The hyperparameter setting includes the settings of the number of hidden layers, number of neurons and number of channels for every layer, learning rate, batch size, batch normalization, pooling, and so forth. Transfer learning has been widely used in 2D images. Several excellent pretrained 2D networks such as LeNet, AlexNet, VGG, Inception, and ResNet can be applied to other image processing tasks just with simple fine-tuning [28,29]. However, there are very few pre-trained networks in one dimension, hence we designed the network from scratch. Based on our experiences and utilizing the grid search [27], we obtained a 10-layer architecture through the process of trial and error. The normalization algorithm not only solves the variable length data problem but also generates more data to train the deep neural network. The pseudocode of the algorithm is shown in Algorithm 1. If the recording contains just 9000 samples (30 s), this recording will be used directly without any modification. If the recording contains more than 9000 samples, multiple segments will be generated with 50% overlap between adjacent segments. Each segment from the same recording has 9000 samples and will be assigned the same label. For instance, an AF recording containing 18,600 samples (61 s) will be replaced by four segments containing 9000 samples and labeled as AF. Finally, if the length is less than 9000, we concatenate the recording with the same label to reach 9000 samples. After pre-processing, the number of recordings for AF, Normal, Noisy, and Other is 903, 5959, 299, and 2990, respectively, increasing from 8528 to 10,151 in total. The design of deep neural network architecture is rather challenging, and involves several aspects such as performance metric, loss function, optimization algorithm, and hyperparameter setting [27]. The hyperparameter setting includes the settings of the number of hidden layers, number of neurons and number of channels for every layer, learning rate, batch size, batch normalization, pooling, and so forth. Transfer learning has been widely used in 2D images. Several excellent pre-trained 2D networks such as LeNet, AlexNet, VGG, Inception, and ResNet can be applied to other image processing tasks just with simple fine-tuning [28,29]. However, there are very few pre-trained networks in one dimension, hence we designed the network from scratch. Based on our experiences and utilizing the grid search [27], we obtained a 10-layer architecture through the process of trial and error. The proposed architecture contains 10 convolutional blocks, 2 fully-connected layers, and a Softmax layer as the output prediction, as shown in Table 1. The convolutional block consists of a convolutional layer, a Rectified Linear Unit (ReLU) layer, and a Maxpooling layer. We added a batch normalization (BN) layer [30] after ReLU activation only in the first convolutional block to normalize the input layer by adjusting and scaling the activations. BN normalizes the input to zero mean and unit variance, which improves the performance and stability of the deep neural network [27]. Five convolutional blocks are then followed with a dropout layer. The next convolutional blocks share the same structure and then apply a dropout layer. In the last block, we only applied a convolutional layer and a ReLU layer. The arrangements of batch normalization and pooling methods affect the prediction accuracy, which will be discussed in the following section. As shown in Table 1, the filter size of the convolutional layer starts with 32, meaning 32 kernels will convolve with input data and output 32 feature maps. The filter size is increased by multiplication of 2 every 2 blocks in order to retrieve more combinatory features. The kernel size in all layers is set to five for the reduction of computational load. We downsampled each convolutional output by means of a pooling layer with a kernel size of two and used the Softmax function in the last layer to produce prediction probability over the four output classes. The Softmax function, defined in Equation (1), maps the real-valued input into prediction probability. Ground truth labels are transformed into one-hot encoding vector. In our case, we have four labels: AF, Normal, Noisy, and Other. Each label is a vector, containing either 1 or 0. If the label is \"AF,\" the one-hot encoding vector will be [1, 0, 0, 0], giving the probability of each label.\nWeSo f tmax(z j ) = e z j K k=1 e z k , j = 1, . . . K,(1)\n\nCNN Learning\n\nThe CNN model is obtained by training with the adaptive moment estimation (Adam) [31], which is a variant of the stochastic gradient descent (SGD) optimization algorithm. The Adam utilizes the backpropagation (BP) method to learn the parameter set of the neural network by minimizing the loss function which corresponds to the difference between network prediction and the ground truth.\n\nIn this CNN, we choose the cross-entropy as loss function, J(x, y, \u03b8) defined in Equation (2). The learning of the network is to minimize J(x, y, \u03b8) with respect to network parameter set \u03b8.\nJ(x, y, \u03b8) = \u2212 K i=1 x i logy i ,(2)\nwhere x and y denote the ground truth and the predicted output of the CNN, respectively, and K is the minibatch size.\n\nIn backpropagation training, the parameter set \u03b8 of the CNN is obtained by an iterative update as [32]:\n\u03b8 t \u2190 \u03b8 t\u22121 \u2212 \u03b7m t \u221av t + \u03b5 ,(3)\nwhere \u03b7 is a fixed learning rate; \u03b5 is a very small constant;m t andv t are the bias-corrected first moment estimate and the biased-corrected second moment estimate, respectively, which are defined elsewhere [32]. Adam is an adaptive learning rate method, which computes individual learning rates for different parameters. The default learning rate is 0.001 [32]. Generally, a large learning rate will make a model learn faster while a small learning rate will maintain better stability in the learning process. In the 1D CNN, the dropout layer is also employed between the two convolutional blocks to avoid overfitting. The dropout layer will randomly choose a percentage of neurons and update only the weights of the remaining neurons during training. [27]. We set the dropout parameter to be 0.5, which means half of the neurons will not be updated.\n\n\nNumerical Analysis\n\n\nDataset\n\nThe dataset we used is provided by PhysioNet Challenge 2017, containing 8528 single lead variable-length ECG recordings lasting from 9 s to 61 s. The recordings are sampled at 300 Hz and have been bandpass filtered by the AliveCor KardiaMobile device, which generates lead I (LA-RA, i.e., when electrodes are placed on the subject's left arm and right arm) equivalent ECG recordings [7]. ECG recordings are transmitted over the air using 19 kHz carrier frequency, digitized at 44.1 kHz and 24-bit resolution, and stored as 300 Hz and 16-bit files with a bandwidth of 0.5-40 Hz and a \u00b15 mV dynamic range [7]. The dataset is composed of four classes, including 771 AF (atrial fibrillation), 5154 Normal (normal sinus rhythm), 46 Noisy (too noisy to be recognized), and 2557 Other (other rhythm), which were annotated by experienced experts. The waveforms of examples of the four classes are shown in Figure 4. The \"Other\" represents recordings that can be clearly classified but do not belong to any of the other three classes (i.e., AF, Normal or Noisy). After data length normalization, the number of recordings becomes 10,151. The increase of data samples is beneficial for training in avoidance of overfitting.  \n\n\nEvaluation Metrics\n\nAs stated before, the proposed system predicts the input ECG record as one of the four classes. We adopt F1 score to evaluate the prediction (detection) performance, which is calculated as \n\nPrecision and recall metrics can be derived from the confusion matrix, which shows the performance of a classification algorithm. Each row of the matrix stands for a predicted class while each column represents a ground truth class. The subscript indicates the number of classifications. For example, A represents AF as ground truth but predicted noisy as the outcome. A confusion matrix of four classes [33] is shown in Table 2.  \n\n\nEvaluation Metrics\n\nAs stated before, the proposed system predicts the input ECG record as one of the four classes. We adopt F 1 score to evaluate the prediction (detection) performance, which is calculated as\nF 1 (%) = 2 * Precision * Recall Precision + Recall * 100,(4)\nPrecision and recall metrics can be derived from the confusion matrix, which shows the performance of a classification algorithm. Each row of the matrix stands for a predicted class while each column represents a ground truth class. The subscript indicates the number of classifications. For example, A represents AF as ground truth but predicted noisy as the outcome. A confusion matrix of four classes [33] is shown in Table 2. To calculate F 1 of each class, we transform the confusion matrix of size 4 \u00d7 4 into that of size 2 \u00d7 2. Each row and column contain two classes: target label and remaining label. A 2 \u00d7 2 confusion matrix of AF is shown in Table 3. \"Non-AF\" includes Normal, Noisy, and Other classes. Precision, recall, and accuracy of AF are calculated as follows:\nPrecision = A a A a + NA a ,(5)Recall = A a A a + A na ,(6)Accuracy = A a + NA na A a + NA a + A na + NA na ,(7)\nAccuracy is used in most cases in terms of evaluating how good the classification is. However, accuracy is inadequate for an unbalanced dataset due to the majority of negative class. Therefore, we use F 1 score as an alternative measure since it is a balance of precision and recall metrics and is useful when dealing with uneven class distribution [32].\n\nF 1 scores for the other classes (i.e., Normal (F 1N ), Noise (F 1~) , and Other (F 1O )), are calculated in the same way as AF (F 1A ). The overall detection performance of the proposed method is evaluated by the average of F 1 scores of the four classes [33] as follows:\nAverage F 1 = F 1N + F 1\u223c + F 1A + F 1O 4 ,(8)\n\nK-Fold Cross-Validation\n\nK-fold cross-validation (K-fold CV) is the most popular method in various applications of machine learning [27,34,35]. Stratified K-fold CV is a stratified-sampling version of K-fold which returns stratified folds: each set contains approximately the same percentage of samples of each target class as the complete set. It is superior to regular K-fold CV, especially for imbalanced classifications. As mentioned in the previous section, the sample distribution of the four classes in the pre-processed dataset which contains 10,151 segments (AF = 903, Normal = 5959, Noisy, = 299 and Other = 2990) is imbalanced. Therefore, we utilize stratified K-fold CV rather than regular K-fold CV.\n\nIn order to find the best K value, we divided the pre-processed dataset into training and test subsets with different size ratios, and then did training and testing for each size ratio. The results are shown in Table 4. It indicates that the train/test ratio of 80:20 achieves the best detection performance, which corresponds to K = 5. Therefore, we used a stratified five-fold CV in our work. The average F 1 score of a class is calculated by averaging F 1 of all folds, and the results are 79.1%, 90.7%, 65.3%, and 76% for AF, Normal, Noisy, and Other, respectively. \n\n\nHyperparameter Optimization\n\nWe performed a grid search algorithm over number of layers, kernel size, batch size, and learning rate, for hyperparameter optimization in training. Given a set of parameters for training, grid search yields an optimal model which maximizes accuracy on independent datasets. The suggested learning rate of 0.001 in Adam optimizer [31] is used as a base. In order to find the best accuracy around the base learning rate, we chose one parameter greater than the base and three more less than the base to form a set for learning rate as Lr \u2208 {0.00005, 0.0001, 0.0005, 0.001, 0.005}. We selected five elements to form a batch-size set which started from 30 and increased by 20; i.e., Bs \u2208 {30, 50, 70, 90, 110}. Three kinds of kernel sizes were selected as Ks \u2208 {3, 5, 7}. As for number of layers in our case, the upper limit was 12 since we decreased the dimensionality of feature map after every convolutional layer. We define the set of number of layers as N \u2208 {8, 9, 10, 11}. The combination of the above parameter sets yields 300 neural network architectures. We applied the grid search to obtain an optimal architecture and used four Graphics Processing Units (GPUs) (Nvidia GTX 1080 Ti) to speed up training.\n\n\nResults and Analysis\n\n\nPrediction Accuracy\n\nEach recording is assigned a label as AF, Normal, Noisy, or Other. The proposed 1D CNN model will infer the label on the test set. Using the grid search, we can obtain the best model and evaluate the average F 1 score, which is the average of the four classes.\n\nApplying the grid search to the dataset, we obtained the results demonstrated in Table 5. The table shows the best average F 1 score and standard deviation \u03c3 under various combinations of network hyperparameters including number of convolutional layers, filter kernel size, batch size, and learning rate. For instance, for the CNN with eight convolutional layers, the first row of the table lists the best F 1 scores of kernel sizes of 3, 5, and 7 with corresponding optimal batch sizes of 50, 50, and 70 and learning rates of 0.001, 0.001, and 0.0005, respectively. It is noted that for 11 convolutional layers, there is no output when kernel size is greater than 3. This is because there was no sufficient data to perform convolution in the last convolutional layer since the feature maps are downsampled using pooling at every convolutional layer. This table also shows the total number of network parameters for each architecture combination.  Table 5 indicates that the best combination is: number of layers = 10, kernel size = 5, learning rate = 0.0001, batch size = 30. The combination reaches average F 1 score of 77.8%. Since the batch size of 30 is the searching lower bound, we further ran a small grid search with batch sizes of 10 and 20. The results show that the average F 1 score of batch size of 10 and 20 is 76.4 and 77.1, respectively. This proves batch size of 30 is the best parameter. Figure 5 shows the normalized average confusion matrix of five folds. The diagonal shows the number of correctly predicted records for each class. The off-diagonals display the number of misclassifications for each class. It is seen that 21 AF records are misclassified as other. This is because some AF records contain characteristics of the class \"Other.\" An example of an AF record which is misclassified as other is shown in Figure 6. In this figure, the orange rectangle shows that the ECG waveform has AF characteristics, which are affected by the abnormal mode of the R-R interval, while the yellow rectangle indicates that the ECG waveform does not have the characteristics of AF, Noisy, or Normal. Figure 5 also indicates imbalanced dataset problem. For the test set, the total number of records of the Normal class is 1215, and the total number of the records of the remaining classes is only 816. In other words, the Normal class dominates the training, and it is possible the learned model will tilt to the normal class.\n\n\n7\n\nN/A N/A N/A N/A N/A Table 5 indicates that the best combination is: number of layers = 10, kernel size = 5, learning rate = 0.0001, batch size = 30. The combination reaches average F1 score of 77.8%. Since the batch size of 30 is the searching lower bound, we further ran a small grid search with batch sizes of 10 and 20. The results show that the average F1 score of batch size of 10 and 20 is 76.4 and 77.1, respectively. This proves batch size of 30 is the best parameter. Figure 5 shows the normalized average confusion matrix of five folds. The diagonal shows the number of correctly predicted records for each class. The off-diagonals display the number of misclassifications for each class. It is seen that 21 AF records are misclassified as other. This is because some AF records contain characteristics of the class \"Other.\" An example of an AF record which is misclassified as other is shown in Figure 6. In this figure, the orange rectangle shows that the ECG waveform has AF characteristics, which are affected by the abnormal mode of the R-R interval, while the yellow rectangle indicates that the ECG waveform does not have the characteristics of AF, Noisy, or Normal. Figure 5 also indicates imbalanced dataset problem. For the test set, the total number of records of the Normal class is 1215, and the total number of the records of the remaining classes is only 816. In other words, the Normal class dominates the training, and it is possible the learned model will tilt to the normal class.  \n\n\nNetwork Architecture Analysis\n\nBatch normalization is a renowned regularization technique that accelerates training [30] and is widely used in modern network architecture [22]. Maxpooling is a strategy that downsamples feature maps and is mostly placed after the convolutional layer for feature reduction [36]. Although these strategies proven to be robust and useful in several application domains, we conducted an experiment to look into the performance changes under various arrangements of batch normalization and Maxpooling. The proposed 1D CNN architecture shown in Table 1 contains only one batch normalization layer placed after the first convolutional layer, and one Maxpooling layer for every convolutional layer, except the last convolution layer. For convenience, the architecture is denoted as Proposed-1. Moreover, we replace every Maxpooling layer of Proposed-1 with average pooling, and denote this as Proposed-2. \n\n\nNetwork Architecture Analysis\n\nBatch normalization is a renowned regularization technique that accelerates training [30] and is widely used in modern network architecture [22]. Maxpooling is a strategy that downsamples feature maps and is mostly placed after the convolutional layer for feature reduction [36]. Although these strategies proven to be robust and useful in several application domains, we conducted an experiment to look into the performance changes under various arrangements of batch normalization and Maxpooling. The proposed 1D CNN architecture shown in Table 1 contains only one batch normalization layer placed after the first convolutional layer, and one Maxpooling layer for every convolutional layer, except the last convolution layer. For convenience, the architecture is denoted as Proposed-1. Moreover, we replace every Maxpooling layer of Proposed-1 with average pooling, and denote this as Proposed-2.\n\nWe also designed four variants of Proposed-1 and one variant of Proposed-2 as follows. The variants of Proposed-1 include (a) All-BN: add one batch normalization layer after every convolutional layer; (b) No-BN: no batch normalization layer in the network; (c) Maxpooling: add the Proposed-1 with one Maxpooling layer before the flatten layer; (d) Max-average pooling: add Proposed-1 with one average pooling layer before the flatten layer, which combines Maxpooling and average pooling. The variant of Proposed-2 is to add one average pooling layer before the flatten layer into the Proposed-2 network, which is denoted as Extra-Average. Table 6 shows the average F 1 scores of the four labels for the two proposed networks and their variants. The detection performance of All-BN degrades significantly, as compared to No-BN or our Proposed-1 architecture. This is due to gradient explosion [37] in deep layer that makes the network hard to train. Furthermore, batch normalization leads to instability of training [37]. Training/validation accuracy of the models All-BN and No-BN are depicted in Figures 7 and 8, respectively. It is seen that the accuracy curve on the validation set fluctuates drastically for All-BN (Figure 7) while the accuracy curve for No-BN ( Figure 8) is relatively smooth. respectively. It is seen that the accuracy curve on the validation set fluctuates drastically for All-BN ( Figure 7) while the accuracy curve for No-BN ( Figure 8) is relatively smooth.    A vanilla CNN usually combines the convolutional layer and Maxpooling layer as a block and repeats this before the flatten layer [36]. We investigated how the Maxpooling layer placed before the flatten layer affects accuracy. The result shown as \"Maxpooling\" in Table 6 reflects that the accuracy degrades significantly, and this variant yields the worst accuracy. The reason can be traced back to the characteristics of Maxpooling. In Maxpooling operation, it only keeps the maximum element and removes the others. This method may not preserve the originality of the data and is likely to eliminate the distinguishing features in the same pooling region [38].\n\nIn order to investigate the effect of pooling methods, we replace Maxpooling in Proposed-1 with average pooling, and the result is shown as Proposed-2 in Table 6. It is obvious that Proposed-2 outperforms Proposed-1 and its variants. This may be due to the effect that average pooling keeps A vanilla CNN usually combines the convolutional layer and Maxpooling layer as a block and repeats this before the flatten layer [36]. We investigated how the Maxpooling layer placed before the flatten layer affects accuracy. The result shown as \"Maxpooling\" in Table 6 reflects that the accuracy degrades significantly, and this variant yields the worst accuracy. The reason can be traced back to the characteristics of Maxpooling. In Maxpooling operation, it only keeps the maximum element and removes the others. This method may not preserve the originality of the data and is likely to eliminate the distinguishing features in the same pooling region [38].\n\nIn order to investigate the effect of pooling methods, we replace Maxpooling in Proposed-1 with average pooling, and the result is shown as Proposed-2 in Table 6. It is obvious that Proposed-2 outperforms Proposed-1 and its variants. This may be due to the effect that average pooling keeps most information from previous layer and is able to pass this down layer by layer. In addition, the performance of Proposed-2 slightly degrades if we add one average pooling layer before flatten layer (Extra-Average in Table 6). However, the F 1 score drops by 10% if we add one Maxpooling layer before the flatten layer in Proposed-1. The experiment shows that using average pooling is more stable than using Maxpooling.\n\n\nNetwork Complexity Analysis\n\nTo evaluate the network complexity, we estimated the total number of network training parameters using the deep learning platform Keras. The parameters of each layer, excluding non-trainable layers such as the pooling layer, dropout, and flatten layer, are shown in Table 7. The total number of network training parameters of the proposed 1D CNN is approximately 3 million.\n\nFor comparison, we also built up the CRNN using Keras and calculated the total number of network training parameters of the CRNN. The CRNN architecture mainly consists of two networks: 2D CNN and LSTM. The 2D CNN uses four convolutional blocks. Each block is made up of six 2D convolutional layers, followed by batch normalization and ReLU activation. The last layer of a block applies Maxpooling with a kernel size of 2. Feature maps from the Maxpooling layer are flattened before feeding into a three-layer bidirectional LSTM network. The total number of training parameters of CRNN is 10,149,440, which is three times more than ours and requires huge computation in training. Note that the transformation of 1D ECG signal to 2D spectrogram is not taken into account. In addition, 2D convolution of 24 layers and three-layer LSTM dominate the network complexity of the CRNN. \n\n\nComparison of Various Methods\n\nTo prove the effectiveness of our AF detection system, we compared it with the existing DL-based methods [21,23,24]. The DL-based methods include 1D schemes: ResNet-1, ResNet-2, and CL3-I (CL3 experiment I [23]), and 2D scheme: CRNN, as mentioned in Section 1. The comparison metrics include detection accuracy of cross-validation and total number of network training parameters.\n\nA detection accuracy comparison of our model with the existing DL-based methods for each class is summarized in Table 8. It indicates that our proposed method achieves better prediction accuracy for all classes. In addition, the detection performance of AF of this method is more than 4% higher than the second best CRNN.  Table 9 shows the comparison using the metrics of average F 1 score of four classes and average F 1 score of three classes (excluding Noisy), and the total number of parameters. The results indicate that the proposed networks achieve an average F 1 score higher than the existing networks. The existing 1D schemes, ResNet-1, ResNet-2 and CL3-I, perform much worse than our networks and CRNN in average F 1 score of four classes. In addition, our network outperforms the CRNN with much lower network complexity (less than 1/3). This implies that both training cost and implementation cost of the proposed deep neural network are significantly lower than those of the CRNN. \n\n\nConclusions\n\nThis paper developed an end-to-end 1D CNN for the AF detection from time-series ECG data. By studying the impact of the BN and pooling methods on detection accuracy and combing the grid search method to obtain optimal hyperparameters, we designed a simple, yet effective 1D CNN network. We also developed a length normalization algorithm, which automatically determines the length threshold value. The algorithm made variable-length ECG records, fixed-length ones, and augmented training data. The algorithm adapted the characteristic change of data by using the histogram information of the input data.\n\nIn the literatre, BN is widely used to improve performance. However, in our application, when the BN layer was added subsequently to every convolutional layer (All-BN), F 1 score dropped 7%, as compared to the case without BN (No-BN). When the BN layer was added only subsequently to the first convolutional layer (our Proposed-1 architecture), F 1 score was further improved by 1.6%, as compared to No-BN. Although BN was able to speed up learning, our experiment indicated that it could lead to instability in training. As for pooling methods, we found that average pooling is able to keep information from the previous layer and pass to a latter layer, while Maxpooling only keeps the maximum value, which may lose important information sometimes. The experimental results showed that average pooling achieved a slightly higher F 1 score than Maxpooling, and it was more stable in training.\n\nThrough exhaustive evaluation, we proved our 1D CNN method achieved better cross-validation detection accuracy than the existing methods. In addition, the proposed method reduced network complexity significantly, as compared with the second-ranked method, CRNN. Applying spatial pyramid pooling [39], which does not require fixed input size, in replacement of the flatten layer, and investigating a better way to solve the problem of extremely imbalanced dataset will be the future directions.\n\nFigure 1 .\n1Electrocardiogram.\n\nFigure 1 .\n1Electrocardiogram.\n\nFigure 2 .\n2Flowchart of the proposed atrial fibrillation (AF) detection method. ECG: electrocardiogram; CNN: convolutional neural network.\n\nFigure 2 .\n2Flowchart of the proposed atrial fibrillation (AF) detection method. ECG: electrocardiogram; CNN: convolutional neural network.\n\nFigure 3 .\n3Data length histogram distribution.\n\nAlgorithm 1 .\n1Pseudocode of data length normalization. 1: IF the length of the recording is greater than 9000 samples 2: Chop recording into 9000 samples with 50% overlap between segments 3: IF the length of the recording is less than 9000 samples 4: DATA: = copy the recording 5: Append DATA in the back of the recording 6: DO step 5 until the appended recording reaches 9000 samples 7: IF the length of the recording is equal to 9000 samples 8: Preserve the recording 2.3. 1D CNN Design 2.3.1. CNN Architecture\n\nFigure 3 .\n3Data length histogram distribution.\n\nAlgorithm 1 .\n1Pseudocode of data length normalization.1: IF the length of the recording is greater than 9000 samples 2: Chop recording into 9000 samples with 50% overlap between segments 3: IF the length of the recording is less than 9000 samples 4: DATA: = copy the recording 5: Append DATA in the back of the recording 6: DO step 5 until the appended recording reaches 9000 samples 7: IF the length of the recording is equal to\n\nFigure 4 .\n4ECG examples of four classes: Normal, AF, Other, and Noisy.\n\nFigure 4 .\n4ECG examples of four classes: Normal, AF, Other, and Noisy.\n\nFigure 5 .\n5Normalized average confusion matrix of five folds.\n\nFigure 5 . 18 Figure 6 .\n5186Normalized average confusion matrix of five folds.Sensors 2020, 20, x FOR PEER REVIEW 12 of AF record which is misclassified as other.\n\nFigure 6 .\n6AF record which is misclassified as other.\n\nFigure 7 .\n7Training accuracy of All-BN.\n\nFigure 7 .\n7Training accuracy of All-BN.\n\nFigure 7 .\n7Training accuracy of All-BN.\n\nFigure 8 .\n8Training accuracy of No-BN.\n\nFigure 8 .\n8Training accuracy of No-BN.\n\nTable 1 .\n1Parameters of each layer of proposed 1D convolutional neural network (CNN).Layers \nParameters \nActivation \n\nConv1D \nFilter 32/kernel \n5 \nReLU \n\nBN \nMaxpooling \n2 \n\nConv1D \nFilter 32/kernel \n5 \nReLU \n\nMaxpooling \n2 \n\nConv1D \nFilter 64/kernel \n5 \nReLU \n\nMaxpooling \n2 \n\nConv1D \nFilter 64/kernel \n5 \nReLU \n\nMaxpooling \n2 \n\nConv1D \nFilter 128/kernel \n5 \nReLU \n\nMaxpooling \n2 \n\nConv1D \nFilter 128/kernel \n5 \nReLU \n\nMaxpooling \n2 \nDropout \n0.5 \n\nConv1D \nFilter 256/kernel \n5 \nReLU \n\nMaxpooling \n2 \n\nConv1D \nFilter 256/kernel \n5 \nReLU \n\nMaxpooling \n2 \nDropout \n0.5 \n\nConv1D \nFilter 512/kernel \n5 \nReLU \n\nMaxpooling \n2 \nDropout \n0.5 \n\nConv1D \nFilter 512/kernel \n5 \nReLU \n\nFlatten \nDense \n128 \nReLU \nDropout \n0.5 \nDense \n32 \nReLU \nDense \n4 \nSoftmax \n\n\n\nTable 2 .\n2Confusion matrix of four classes.Ground Truth \nAF \n(A) \n\nNormal \n(N) \n\nNoisy \n(~) \n\nOther \n(O) \n\nPredicted \n\nAF (a) \nAa \nN a \n\u00e3 \nO a \n\nNormal \n(n) \nAn \nN n \n\u00f1 \nO n \n\nNoisy \n(~) \nA~ \n\u00d1 \n~ \n\u00d5 \n\nOther \n(o) \nAo \nN o \n\u00f5 \nO o \n\n\n\nTable 2 .\n2Confusion matrix of four classes.Ground Truth \n\nAF \n(A) \n\nNormal \n(N) \n\nNoisy \n(~) \n\nOther \n(O) \nPredicted \nAF (a) \nA a \nN a~a \nO a \nNormal \n(n) \nA n \nN n~n \nO n \n\nNoisy \n(~) \nA~N~~~O\u00d5 \n\nther \n(o) \nA o \nN o~o \nO o \n\n\n\nTable 3 .\n3Confusion matrix of two classes.Ground Truth \n\nAF (A) \nNon-AF \n(NA) \n\nPredicted \nAF (a) \nA a \nNA a \n\nNon-AF \n(na) \nA na \nNA na \n\n\n\nTable 4 .\n4F 1 scores using different train/test ratio.Train/Test \nAF \nNormal \nNoisy \nOther \nAverage \n\n60:40 \n72.0 \n90.0 \n60.0 \n69.0 \n72.75 \n70:30 \n76.0 \n90.0 \n60.0 \n70.0 \n74.00 \n80:20 \n77.0 \n89.0 \n67.0 \n74.0 \n76.75 \n90:10 \n76.9 \n90.0 \n62.1 \n72.8 \n75.45 \n\n\nTable 5 .\n5The best average F 1 under various combinations of hyperparameters.Layer \nKernel \nSize \n\nBatch \nSize \n\nLearning \nRate \nAverage F 1 \n\u03c3 \nTotal Number of \nParameters \n\n8 \n\n3 \n50 \n0.001 \n69.4 \n12.5 \n2,558,340 \n5 \n50 \n0.001 \n72.2 \n12.9 \n2,687,428 \n7 \n70 \n0.0005 \n73.6 \n11.4 \n2,816,516 \n\n9 \n\n3 \n50 \n0.001 \n76.6 \n9.6 \n1,608,324 \n5 \n50 \n0.0001 \n77.2 \n9.9 \n1,868,484 \n7 \n30 \n0.0005 \n76.8 \n11.4 \n2,128,644 \n\n10 \n\n3 \n90 \n0.0005 \n77.0 \n9.4 \n2,428,292 \n5 \n30 \n0.0001 \n77.8 \n9.1 \n3,212,740 \n7 \n50 \n0.001 \n76.4 \n10.6 \n3,997,188 \n\n11 \n\n3 \n50 \n0.0005 \n77.1 \n9.9 \n2,625,412 \n5 \nN/A \nN/A \nN/A \nN/A \nN/A \n7 \nN/A \nN/A \nN/A \nN/A \nN/A \n\n\n\nTable 6 .\n6Average F 1 scores of proposed networks and their variants.Neural Networks \nAverage F 1 Score \nTotal Number of Parameters \n\nProposed-1 \n77.8 \n3,212,740 \nAll-BN \n69.2 \n3,216,644 \nNo-BN \n76.2 \n3,212,676 \nMaxpooling \n67.7 \n2,885,060 \nMax-Average pooling \n75.6 \n2,885,060 \nProposed-2 \n78.2 \n3,212,740 \nExtra-Average \n77.4 \n2,885,060 \n\nSensors 2020, 20, x FOR PEER REVIEW \n13 of 18 \n\n\n\nTable 7 .\n7Training parameters of the proposed 1D CNN. Total number of network training parameters: 3,212,740Layer Type \nOutput Shape \nParameters \n\nConv1D \n8996 \u00d7 32 \n192 \nBatch Normalization \n8996 \u00d7 32 \n128 \nConv1D \n4494 \u00d7 32 \n5152 \nConv1D \n2243 \u00d7 64 \n10,304 \nConv1D \n1117 \u00d7 64 \n20,544 \nConv1D \n554 \u00d7 128 \n41,088 \nConv1D \n273 \u00d7 128 \n82,048 \nConv1D \n132 \u00d7 256 \n164,096 \nConv1D \n62 \u00d7 256 \n327,936 \nConv1D \n27 \u00d7 512 \n655,872 \nConv1D \n9 \u00d7 512 \n1,311,232 \nDense \n128 \n589,952 \nDense \n32 \n4128 \nDense \n4 \n132 \n\n\nTable 8 .\n8Comparison of prediction accuracy of various methods.Methods \nAF (A) \nNormal (N) \nNoisy (~) \nOther (O) \n\nProposed-1 \n79.1 \n90.7 \n65.3 \n76.0 \nProposed-2 \n80.8 \n90.4 \n66.2 \n75.3 \nCRNN \n76.4 \n88.8 \n64.5 \n72.6 \nResNet-1 \n65.7 \n90.2 \n64.0 \n69.8 \nResNet-2 \n67.7 \n88.5 \n65.6 \n66.6 \nCL3-I \n76.0 \n90.1 \n47.1 \n75.2 \n\n\n\nTable 9 .\n9Comparison of average F 1 score and total number of parameters of various methods.Methods \nAverage F 1 Score of \nA, N,~, and O \n\nAverage F 1 Score of \nA, N, and O \n\nTotal Number of \nParameters \n\nProposed-1 \n77.8 \n81.9 \n3,212,740 \nProposed-2 \n78.2 \n82.2 \n3,212,740 \nCRNN \n75.6 \n79.3 \n10,149,440 \nResNet-1 \n72.4 \n75.2 \n10,466,148 \nResNet-2 \n72.1 \n74.3 \n1,219,508 \nCL3-I \n72.1 \n80.4 \n206,334 \n\n\nAtrial Fibrillation. Atrial Fibrillation. Available online: https://www.mayoclinic.org/diseases-conditions/atrial-fibrillation/ symptoms-causes/syc-20350624 (accessed on 18 October 2019).\n\nTemporal trends and patterns in heart failure incidence: A population-based study of 4 million individuals. N Conrad, A Judge, J Tran, H Mohseni, D Hedgecott, A P Crespillo, M Allison, H Hemingway, J G Cleland, J J Mcmurray, 10.1016/S0140-6736(17)32520-5Lancet. 391Conrad, N.; Judge, A.; Tran, J.; Mohseni, H.; Hedgecott, D.; Crespillo, A.P.; Allison, M.; Hemingway, H.; Cleland, J.G.; McMurray, J.J.V. Temporal trends and patterns in heart failure incidence: A population-based study of 4 million individuals. Lancet 2018, 391, 572-580. [CrossRef]\n\nThe annual global economic burden of heart failure. C Cook, G Cole, P Asaria, R Jabbour, D P Francis, 10.1016/j.ijcard.2013.12.028Int. J. Cardiol. 171PubMedCook, C.; Cole, G.; Asaria, P.; Jabbour, R.; Francis, D.P. The annual global economic burden of heart failure. Int. J. Cardiol. 2014, 171, 368-376. [CrossRef] [PubMed]\n\nAtrial fibrillation: mechanistic insights and treatment options. S T Mathew, J Patel, S Joseph, 10.1016/j.ejim.2009.07.011Eur. J. Intern. Med. 20PubMedMathew, S.T.; Patel, J.; Joseph, S. Atrial fibrillation: mechanistic insights and treatment options. Eur. J. Intern. Med. 2009, 20, 672-681. [CrossRef] [PubMed]\n\nAutomatic online detection of atrial fibrillation based on symbolic dynamics and Shannon entropy. X Zhou, H Ding, B Ung, P M Emma, Y Zhang, 10.1186/1475-925X-13-18Biomed. Eng. Online. 13Zhou, X.; Ding, H.; Ung, B.; Emma, P.M.; Zhang, Y. Automatic online detection of atrial fibrillation based on symbolic dynamics and Shannon entropy. Biomed. Eng. Online 2014, 13, 18. [CrossRef]\n\nA 12-lead electrocardiogram database for arrhythmia research covering more than 10,000 patients. J Zheng, J Zhang, S Danioko, H Yao, H Guo, C Rakovski, 10.1038/s41597-020-0386-xSci. Data 2020, 7, 48. [CrossRefZheng, J.; Zhang, J.; Danioko, S.; Yao, H.; Guo, H.; Rakovski, C. A 12-lead electrocardiogram database for arrhythmia research covering more than 10,000 patients. Sci. Data 2020, 7, 48. [CrossRef]\n\nAF classification from a short single lead ECG recording: The PhysioNet Computing in Cardiology Challenge. G D Clifford, C Liu, B Moody, L H Lehman, I Silva, Q Li, A E Johnson, R G Mark, Proceedings of the 2017 Computing in Cardiology (CinC). the 2017 Computing in Cardiology (CinC)Rennes, France44Clifford, G.D.; Liu, C.; Moody, B.; Lehman, L.H.; Silva, I.; Li, Q.; Johnson, A.E.; Mark, R.G. AF classification from a short single lead ECG recording: The PhysioNet Computing in Cardiology Challenge 2017. In Proceedings of the 2017 Computing in Cardiology (CinC), Rennes, France, 24-27 September 2017; Volume 44, pp. 1-4.\n\nClassification of electrocardiogram signals with RS and quantum neural networks. X Tang, L Shu, 10.14257/ijmue.2014.9.2.37Int. J. Multimed. Ubiquitous Eng. 92136Tang, X.; Shu, L. Classification of electrocardiogram signals with RS and quantum neural networks. Int. J. Multimed. Ubiquitous Eng. 2014, 9, 363-372. [CrossRef] Sensors 2020, 20, 2136\n\nECG beat recognition using fuzzy hybrid neural network. S Osowski, T H Linh, 10.1109/10.959322IEEE Trans. Biomed. Eng. 48Osowski, S.; Linh, T.H. ECG beat recognition using fuzzy hybrid neural network. IEEE Trans. Biomed. Eng. 2001, 48, 1265-1271. [CrossRef]\n\nOn-line heartbeat recognition using Hermite polynomials and neuron-fuzzy network. T H Linh, S Osowski, M Stodolski, 10.1109/TIM.2003.816841IEEE Trans. Instrum. Meas. 52Linh, T.H.; Osowski, S.; Stodolski, M. On-line heartbeat recognition using Hermite polynomials and neuron-fuzzy network. IEEE Trans. Instrum. Meas. 2003, 52, 1224-1231. [CrossRef]\n\nA rough set-based inference engine for ECG classification. S Mitra, M Mitra, B B Chaudhuri, 10.1109/TIM.2006.884279IEEE Trans. Instrum. Meas. 55Mitra, S.; Mitra, M.; Chaudhuri, B.B. A rough set-based inference engine for ECG classification. IEEE Trans. Instrum. Meas. 2006, 55, 2198-2206. [CrossRef]\n\nClassification of electrocardiogram signals with support vector machines and particle swarm optimization. F Melgani, Y Bazi, 10.1109/TITB.2008.923147IEEE Trans. Inf. Technol. Biomed. 12Melgani, F.; Bazi, Y. Classification of electrocardiogram signals with support vector machines and particle swarm optimization. IEEE Trans. Inf. Technol. Biomed. 2008, 12, 667-677. [CrossRef]\n\nHeartbeat classification using feature selection driven by database generalization criteria. M Llamedo, J P Mart\u00ednez, 10.1109/TBME.2010.2068048IEEE Trans. Biomed. Eng. 58PubMedLlamedo, M.; Mart\u00ednez, J.P. Heartbeat classification using feature selection driven by database generalization criteria. IEEE Trans. Biomed. Eng. 2011, 58, 616-625. [CrossRef] [PubMed]\n\nECG arrhythmia recognition via a neuro-SVM-KNN hybrid classifier with virtual QRS image-based geometrical features. M R Homaeinezhad, S A Atyabi, E Tavakkoli, H N Toosi, A Ghaffari, R Ebrahimpour, 10.1016/j.eswa.2011.08.025Expert Syst. Appl. 39Homaeinezhad, M.R.; Atyabi, S.A.; Tavakkoli, E.; Toosi, H.N.; Ghaffari, A.; Ebrahimpour, R. ECG arrhythmia recognition via a neuro-SVM-KNN hybrid classifier with virtual QRS image-based geometrical features. Expert Syst. Appl. 2012, 39, 2047-2058. [CrossRef]\n\nECG signal processing for abnormalities detection using multi-resolution wavelet transform and artificial neural network classifier. H M Rai, A Trivedi, S Shukla, 10.1016/j.measurement.2013.05.021Measurement. 46Rai, H.M.; Trivedi, A.; Shukla, S. ECG signal processing for abnormalities detection using multi-resolution wavelet transform and artificial neural network classifier. Measurement 2013, 46, 3238-3246. [CrossRef]\n\nA novel fuzzy c-means method for classifying heartbeat cases from ECG signals. Y C Yeh, W J Wang, C W Chiou, 10.1016/j.measurement.2010.08.019Measurement. 43Yeh, Y.C.; Wang, W.J.; Chiou, C.W. A novel fuzzy c-means method for classifying heartbeat cases from ECG signals. Measurement 2010, 43, 1542-1555. [CrossRef]\n\nFiducial feature reduction analysis for electrocardiogram (ECG) based biometric recognition. M M Tantawi, K Revett, A B M Salem, M F Tolba, 10.1007/s10844-012-0214-7J. Intell. Inf. Syst. 40CrossRefTantawi, M.M.; Revett, K.; Salem, A.B.M.; Tolba, M.F. Fiducial feature reduction analysis for electrocardiogram (ECG) based biometric recognition. J. Intell. Inf. Syst. 2013, 40, 17-39. [CrossRef]\n\nA patient adaptable ECG beat classifier based on neural networks. A D Gaetano, S Panunzi, F Rinaldi, A Risi, M Sciandrone, 10.1016/j.amc.2009.03.013Appl. Math. Comput. 213Gaetano, A.D.; Panunzi, S.; Rinaldi, F.; Risi, A.; Sciandrone, M. A patient adaptable ECG beat classifier based on neural networks. Appl. Math. Comput. 2009, 213, 243-249. [CrossRef]\n\nIdentifying normal, AF and other abnormal ECG rhythms using a cascaded binary classifier. S Datta, C Puri, A Mukherjee, R Banerjee, A D Choudhury, R Singh, A Ukil, S Bandyopadhyay, A Pal, S Khandelwal, Proceedings of the 2017 Computing in Cardiology (CinC). the 2017 Computing in Cardiology (CinC)Rennes, France44Datta, S.; Puri, C.; Mukherjee, A.; Banerjee, R.; Choudhury, A.D.; Singh, R.; Ukil, A.; Bandyopadhyay, S.; Pal, A.; Khandelwal, S. Identifying normal, AF and other abnormal ECG rhythms using a cascaded binary classifier. In Proceedings of the 2017 Computing in Cardiology (CinC), Rennes, France, 24-27 September 2017; Volume 44, pp. 1-4.\n\nPatient-specific deep architectural model for ECG classification. K Luo, J Li, Z Wang, A Cuschieri, 10.1155/2017/4108720J. Healthc. Eng. Luo, K.; Li, J.; Wang, Z.; Cuschieri, A. Patient-specific deep architectural model for ECG classification. J. Healthc. Eng. 2017, 2017, 4108720. [CrossRef]\n\nComparing feature-based classifiers and convolutional neural networks to detect arrhythmia from short segments of ECG. F Andreotti, O Carr, M A F Pimentel, A Mahdi, M D Vos, Proceedings of the 2017 Computing in Cardiology (CinC). the 2017 Computing in Cardiology (CinC)Rennes, France44Andreotti, F.; Carr, O.; Pimentel, M.A.F.; Mahdi, A.; Vos, M.D. Comparing feature-based classifiers and convolutional neural networks to detect arrhythmia from short segments of ECG. In Proceedings of the 2017 Computing in Cardiology (CinC), Rennes, France, 24-27 September 2017; Volume 44, pp. 1-4.\n\nCardiologist-Level Arrhythmia Detection with Convolutional Neural Networks. A Y Hannun, P Rajpurkar, M Haghpanahi, G H Tison, C Bourn, M P Turakhia, A Y Ng, 10.1038/s41591-018-0268-3Nat. Med. 25Hannun, A.Y.; Rajpurkar, P.; Haghpanahi, M.; Tison, G.H.; Bourn, C.; Turakhia, M.P.; Ng, A.Y. Cardiologist- Level Arrhythmia Detection with Convolutional Neural Networks. Nat. Med. 2019, 25, 65-69. [CrossRef]\n\nCardiac arrhythmia detection from ECG combining convolutional and long short-term memory networks. P Warrick, M N Homsi, Proceedings of the 2017 Computing in Cardiology (CinC). the 2017 Computing in Cardiology (CinC)Rennes, France44Warrick, P.; Homsi, M.N. Cardiac arrhythmia detection from ECG combining convolutional and long short-term memory networks. In Proceedings of the 2017 Computing in Cardiology (CinC), Rennes, France, 24-27 September 2017; Volume 44, pp. 1-4.\n\nConvolutional recurrent neural networks for electrocardiogram classification. M Zihlmann, D Perekrestenko, M Tschannen, Proceedings of the 2017 Computing in Cardiology (CinC). the 2017 Computing in Cardiology (CinC)Rennes, France44Zihlmann, M.; Perekrestenko, D.; Tschannen, M. Convolutional recurrent neural networks for electrocardiogram classification. In Proceedings of the 2017 Computing in Cardiology (CinC), Rennes, France, 24-27 September 2017; Volume 44, pp. 1-4.\n\nDeep learning-based indoor localization using received signal strength and channel state information. C H Hsieh, J Y Chen, B H Nien, 10.1109/ACCESS.2019.2903487IEEE Access. 7Hsieh, C.H.; Chen, J.Y.; Nien, B.H. Deep learning-based indoor localization using received signal strength and channel state information. IEEE Access 2019, 7, 33256-33267. [CrossRef]\n\nEarthquake detection in 1-D time series data with feature selection and dictionary learning. Z Zhou, Y Lin, Z Zhang, Y Wu, P Johnson, 10.1785/0220180315Seismol. Res. Lett. 90Zhou, Z.; Lin, Y.; Zhang, Z.; Wu, Y.; Johnson, P. Earthquake detection in 1-D time series data with feature selection and dictionary learning. Seismol. Res. Lett. 2019, 90, 563-572. [CrossRef]\n\nDeep Learning. I Goodfellow, Y Bengio, A Courville, MIT PressCambridge, MA, USAGoodfellow, I.; Bengio, Y.; Courville, A. Deep Learning; MIT Press: Cambridge, MA, USA, 2016.\n\nA survey of transfer learning. K Weiss, T M Khoshgoftaar, D Wang, 10.1186/s40537-016-0043-6J. Big Data. 39Weiss, K.; Khoshgoftaar, T.M.; Wang, D. A survey of transfer learning. J. Big Data 2016, 3, 9. [CrossRef]\n\nA Survey on Deep Transfer Learning. C Tan, F Sun, T Kong, W Zhang, C Yang, C Liu, 10.1007/978-3-030-01424-7_27Proceedings of the 27th International Conference on Artificial Neural Networks. the 27th International Conference on Artificial Neural NetworksRhodes, Greece; Cham, SwitzerlandSpringerTan, C.; Sun, F.; Kong, T.; Zhang, W.; Yang, C.; Liu, C. A Survey on Deep Transfer Learning. In Proceedings of the 27th International Conference on Artificial Neural Networks, Rhodes, Greece, 4-7 October 2018, Part III; Springer: Cham, Switzerland, 2018. [CrossRef]\n\nBatch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift. S Ioffe, C Szegedy, arXiv:1502.03167Ioffe, S.; Szegedy, C. Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift. arXiv 2015, arXiv:1502.03167.\n\nD P Kingma, J Ba, Adam, arXiv:1412.6980A Method for Stochastic Optimization. arXiv. Kingma, D.P.; Ba, J. Adam: A Method for Stochastic Optimization. arXiv 2014, arXiv:1412.6980.\n\nThe truth of the f-measure. Y Sasaki, Teaching Tutorial Materials. Manchester, UKUniversity of ManchesterSasaki, Y. The truth of the f-measure. In Teaching Tutorial Materials; University of Manchester: Manchester, UK, 2007.\n\nComponents of a New Research Resource for Complex Physiologic Signals. A L Goldberger, L A N Amaral, L Glass, J M Hausdorff, P C Ivanov, R G Mark, J E Mietus, G B Moody, C K Peng, H E Stanley, Physiobank Physiotoolkit Physionet. 10123Goldberger, A.L.; Amaral, L.A.N.; Glass, L.; Hausdorff, J.M.; Ivanov, P.C.; Mark, R.G.; Mietus, J.E.; Moody, G.B.; Peng, C.K.; Stanley, H.E. Components of a New Research Resource for Complex Physiologic Signals. Physiobank Physiotoolkit Physionet 2003, 101, 23.\n\nThe Elements of Statistical Learning. T Hastie, R Tibshirani, J Friedman, SpringerNew York, NY, USAHastie, T.; Tibshirani, R.; Friedman, J. The Elements of Statistical Learning; Springer: New York, NY, USA, 2008.\n\nG James, D Witten, T Hastie, R Tibshirani, An Introduction to Statistical Learning. New York, NY, USASpringer7th ed.James, G.; Witten, D.; Hastie, T.; Tibshirani, R. An Introduction to Statistical Learning, 7th ed.; Springer: New York, NY, USA, 2017.\n\nK Simonyan, A Zisserman, arXiv:1409.1556Very Deep Convolutional Networks for Large-Scale Image Recognition. arXiv 2019. Simonyan, K.; Zisserman, A. Very Deep Convolutional Networks for Large-Scale Image Recognition. arXiv 2019, arXiv:1409.1556.\n\nG Yang, J Pennington, V Rao, J Sohl-Dickstein, S S Schoenholz, arXiv:1902.08129A Mean Field Theory of Batch Normalization. arXiv 2019. Yang, G.; Pennington, J.; Rao, V.; Sohl-Dickstein, J.; Schoenholz, S.S. A Mean Field Theory of Batch Normalization. arXiv 2019, arXiv:1902.08129.\n\nMixed pooling for convolutional neural networks. D Yu, H Wang, P Chen, Z Wei, Rough Sets and Knowledge Technology: 9th International Conference. Cham, SwitzerlandSpringerYu, D.; Wang, H.; Chen, P.; Wei, Z. Mixed pooling for convolutional neural networks. In Rough Sets and Knowledge Technology: 9th International Conference; Springer: Cham, Switzerland, 2014; pp. 364-375.\n\nSpatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition. K He, X Zhang, S Ren, J Sun, 10.1109/TPAMI.2015.2389824IEEE Trans. Pattern Anal. Mach. Intell. 37He, K.; Zhang, X.; Ren, S.; Sun, J. Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition. IEEE Trans. Pattern Anal. Mach. Intell. 2015, 37, 1904-1916. [CrossRef]\n\nThis article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license. \u00a9 2020 by the authors. Licensee MDPI. Basel, Switzerland\u00a9 2020 by the authors. Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (http://creativecommons.org/licenses/by/4.0/).\n", "annotations": {"author": "[{\"end\":185,\"start\":98},{\"end\":292,\"start\":186},{\"end\":427,\"start\":293},{\"end\":538,\"start\":428}]", "publisher": null, "author_last_name": "[{\"end\":113,\"start\":108},{\"end\":197,\"start\":195},{\"end\":308,\"start\":303},{\"end\":443,\"start\":438}]", "author_first_name": "[{\"end\":107,\"start\":98},{\"end\":194,\"start\":186},{\"end\":302,\"start\":293},{\"end\":437,\"start\":428}]", "author_affiliation": "[{\"end\":184,\"start\":115},{\"end\":291,\"start\":199},{\"end\":426,\"start\":334},{\"end\":537,\"start\":445}]", "title": "[{\"end\":71,\"start\":1},{\"end\":609,\"start\":539}]", "venue": null, "abstract": "[{\"end\":2021,\"start\":830}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2260,\"start\":2257},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2458,\"start\":2455},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2664,\"start\":2661},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3039,\"start\":3036},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":3041,\"start\":3039},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3256,\"start\":3253},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":3571,\"start\":3568},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":3795,\"start\":3792},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":3962,\"start\":3959},{\"end\":3965,\"start\":3962},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3969,\"start\":3965},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":3973,\"start\":3969},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":3977,\"start\":3973},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":3981,\"start\":3977},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":3985,\"start\":3981},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":3989,\"start\":3985},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":3993,\"start\":3989},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":3997,\"start\":3993},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":4001,\"start\":3997},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":4621,\"start\":4618},{\"end\":4624,\"start\":4621},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":4628,\"start\":4624},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":4632,\"start\":4628},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":4636,\"start\":4632},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":4640,\"start\":4636},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":4644,\"start\":4640},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":4648,\"start\":4644},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":4652,\"start\":4648},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":4656,\"start\":4652},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":4660,\"start\":4656},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":4664,\"start\":4660},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":5224,\"start\":5220},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":5228,\"start\":5224},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":5232,\"start\":5228},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":5236,\"start\":5232},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":5240,\"start\":5236},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":5258,\"start\":5254},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":5631,\"start\":5627},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":5685,\"start\":5681},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":6021,\"start\":6017},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":6488,\"start\":6485},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":6712,\"start\":6709},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":6879,\"start\":6876},{\"end\":6882,\"start\":6879},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":6886,\"start\":6882},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":6890,\"start\":6886},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":6894,\"start\":6890},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":6898,\"start\":6894},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":6902,\"start\":6898},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":6906,\"start\":6902},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":6910,\"start\":6906},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":6914,\"start\":6910},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":6918,\"start\":6914},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":7538,\"start\":7535},{\"end\":7541,\"start\":7538},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":7545,\"start\":7541},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":7549,\"start\":7545},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":7553,\"start\":7549},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":7557,\"start\":7553},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":7561,\"start\":7557},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":7565,\"start\":7561},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":7569,\"start\":7565},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":7573,\"start\":7569},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":7577,\"start\":7573},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":7581,\"start\":7577},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":8141,\"start\":8137},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":8145,\"start\":8141},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":8149,\"start\":8145},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":8153,\"start\":8149},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":8157,\"start\":8153},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":8175,\"start\":8171},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":8548,\"start\":8544},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":8602,\"start\":8598},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":8937,\"start\":8933},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":9301,\"start\":9297},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":10290,\"start\":10286},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":10293,\"start\":10290},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":10296,\"start\":10293},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":11565,\"start\":11561},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":14817,\"start\":14813},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":14838,\"start\":14834},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":16406,\"start\":16402},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":16427,\"start\":16423},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":18814,\"start\":18810},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":19251,\"start\":19247},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":19254,\"start\":19251},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":19426,\"start\":19422},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":20652,\"start\":20648},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":21090,\"start\":21086},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":21093,\"start\":21090},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":21265,\"start\":21261},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":21663,\"start\":21659},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":21927,\"start\":21923},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":23416,\"start\":23412},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":24167,\"start\":24163},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":24414,\"start\":24410},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":24564,\"start\":24560},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":24960,\"start\":24956},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":25473,\"start\":25470},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":25693,\"start\":25690},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":26923,\"start\":26919},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":27629,\"start\":27625},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":28466,\"start\":28462},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":28729,\"start\":28725},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":28926,\"start\":28922},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":28929,\"start\":28926},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":28932,\"start\":28929},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":30440,\"start\":30436},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":35705,\"start\":35701},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":35760,\"start\":35756},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":35894,\"start\":35890},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":36638,\"start\":36634},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":36693,\"start\":36689},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":36827,\"start\":36823},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":38345,\"start\":38341},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":38468,\"start\":38464},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":39070,\"start\":39066},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":39596,\"start\":39592},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":40023,\"start\":40019},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":40549,\"start\":40545},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":42691,\"start\":42687},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":42694,\"start\":42691},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":42697,\"start\":42694},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":42792,\"start\":42788},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":45773,\"start\":45769}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":45999,\"start\":45968},{\"attributes\":{\"id\":\"fig_1\"},\"end\":46031,\"start\":46000},{\"attributes\":{\"id\":\"fig_4\"},\"end\":46172,\"start\":46032},{\"attributes\":{\"id\":\"fig_5\"},\"end\":46313,\"start\":46173},{\"attributes\":{\"id\":\"fig_7\"},\"end\":46362,\"start\":46314},{\"attributes\":{\"id\":\"fig_8\"},\"end\":46877,\"start\":46363},{\"attributes\":{\"id\":\"fig_9\"},\"end\":46926,\"start\":46878},{\"attributes\":{\"id\":\"fig_10\"},\"end\":47358,\"start\":46927},{\"attributes\":{\"id\":\"fig_14\"},\"end\":47431,\"start\":47359},{\"attributes\":{\"id\":\"fig_16\"},\"end\":47504,\"start\":47432},{\"attributes\":{\"id\":\"fig_17\"},\"end\":47568,\"start\":47505},{\"attributes\":{\"id\":\"fig_18\"},\"end\":47733,\"start\":47569},{\"attributes\":{\"id\":\"fig_19\"},\"end\":47789,\"start\":47734},{\"attributes\":{\"id\":\"fig_20\"},\"end\":47831,\"start\":47790},{\"attributes\":{\"id\":\"fig_21\"},\"end\":47873,\"start\":47832},{\"attributes\":{\"id\":\"fig_22\"},\"end\":47915,\"start\":47874},{\"attributes\":{\"id\":\"fig_23\"},\"end\":47956,\"start\":47916},{\"attributes\":{\"id\":\"fig_24\"},\"end\":47997,\"start\":47957},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":48752,\"start\":47998},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":48987,\"start\":48753},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":49216,\"start\":48988},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":49358,\"start\":49217},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":49615,\"start\":49359},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":50242,\"start\":49616},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":50634,\"start\":50243},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":51141,\"start\":50635},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":51461,\"start\":51142},{\"attributes\":{\"id\":\"tab_9\",\"type\":\"table\"},\"end\":51864,\"start\":51462}]", "paragraph": "[{\"end\":3042,\"start\":2037},{\"end\":3796,\"start\":3044},{\"end\":4665,\"start\":3798},{\"end\":5241,\"start\":4667},{\"end\":5608,\"start\":5243},{\"end\":6000,\"start\":5610},{\"end\":6390,\"start\":6002},{\"end\":6713,\"start\":6392},{\"end\":7582,\"start\":6715},{\"end\":8158,\"start\":7584},{\"end\":8525,\"start\":8160},{\"end\":9271,\"start\":8527},{\"end\":9762,\"start\":9273},{\"end\":10377,\"start\":9764},{\"end\":11184,\"start\":10379},{\"end\":11708,\"start\":11186},{\"end\":11711,\"start\":11710},{\"end\":12134,\"start\":11713},{\"end\":12297,\"start\":12140},{\"end\":12390,\"start\":12303},{\"end\":12699,\"start\":12392},{\"end\":13839,\"start\":12743},{\"end\":14487,\"start\":13841},{\"end\":15383,\"start\":14517},{\"end\":16076,\"start\":15385},{\"end\":16972,\"start\":16106},{\"end\":23256,\"start\":16974},{\"end\":23717,\"start\":23331},{\"end\":23908,\"start\":23719},{\"end\":24063,\"start\":23946},{\"end\":24168,\"start\":24065},{\"end\":25054,\"start\":24202},{\"end\":26301,\"start\":25087},{\"end\":26513,\"start\":26324},{\"end\":26946,\"start\":26515},{\"end\":27158,\"start\":26969},{\"end\":27999,\"start\":27221},{\"end\":28467,\"start\":28113},{\"end\":28741,\"start\":28469},{\"end\":29502,\"start\":28815},{\"end\":30074,\"start\":29504},{\"end\":31317,\"start\":30106},{\"end\":31624,\"start\":31364},{\"end\":34065,\"start\":31626},{\"end\":35582,\"start\":34071},{\"end\":36515,\"start\":35616},{\"end\":37447,\"start\":36549},{\"end\":39597,\"start\":37449},{\"end\":40550,\"start\":39599},{\"end\":41264,\"start\":40552},{\"end\":41669,\"start\":41296},{\"end\":42548,\"start\":41671},{\"end\":42961,\"start\":42582},{\"end\":43958,\"start\":42963},{\"end\":44577,\"start\":43974},{\"end\":45472,\"start\":44579},{\"end\":45967,\"start\":45474}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":23315,\"start\":23257},{\"attributes\":{\"id\":\"formula_1\"},\"end\":23945,\"start\":23909},{\"attributes\":{\"id\":\"formula_2\"},\"end\":24201,\"start\":24169},{\"attributes\":{\"id\":\"formula_4\"},\"end\":27220,\"start\":27159},{\"attributes\":{\"id\":\"formula_5\"},\"end\":28031,\"start\":28000},{\"attributes\":{\"id\":\"formula_6\"},\"end\":28059,\"start\":28031},{\"attributes\":{\"id\":\"formula_7\"},\"end\":28112,\"start\":28059},{\"attributes\":{\"id\":\"formula_8\"},\"end\":28788,\"start\":28742}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":21494,\"start\":21487},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":22318,\"start\":22311},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":26943,\"start\":26936},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":27649,\"start\":27642},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":27881,\"start\":27874},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":29722,\"start\":29715},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":31714,\"start\":31707},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":32581,\"start\":32574},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":34098,\"start\":34091},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":36164,\"start\":36157},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":37097,\"start\":37090},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":38095,\"start\":38088},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":39206,\"start\":39199},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":39760,\"start\":39753},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":40159,\"start\":40152},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":40713,\"start\":40706},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":41069,\"start\":41062},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":41569,\"start\":41562},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":43082,\"start\":43075},{\"attributes\":{\"ref_id\":\"tab_9\"},\"end\":43293,\"start\":43286}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":2035,\"start\":2023},{\"end\":12138,\"start\":12137},{\"end\":12301,\"start\":12300},{\"attributes\":{\"n\":\"2.\"},\"end\":12723,\"start\":12702},{\"attributes\":{\"n\":\"2.1.\"},\"end\":12741,\"start\":12726},{\"attributes\":{\"n\":\"2.2.\"},\"end\":14515,\"start\":14490},{\"attributes\":{\"n\":\"2.2.\"},\"end\":16104,\"start\":16079},{\"attributes\":{\"n\":\"2.3.2.\"},\"end\":23329,\"start\":23317},{\"attributes\":{\"n\":\"3.\"},\"end\":25075,\"start\":25057},{\"attributes\":{\"n\":\"3.1.\"},\"end\":25085,\"start\":25078},{\"attributes\":{\"n\":\"3.2.\"},\"end\":26322,\"start\":26304},{\"attributes\":{\"n\":\"3.2.\"},\"end\":26967,\"start\":26949},{\"attributes\":{\"n\":\"3.3.\"},\"end\":28813,\"start\":28790},{\"attributes\":{\"n\":\"3.4.\"},\"end\":30104,\"start\":30077},{\"attributes\":{\"n\":\"3.5.\"},\"end\":31340,\"start\":31320},{\"attributes\":{\"n\":\"3.5.1.\"},\"end\":31362,\"start\":31343},{\"end\":34069,\"start\":34068},{\"attributes\":{\"n\":\"3.5.2.\"},\"end\":35614,\"start\":35585},{\"attributes\":{\"n\":\"3.5.2.\"},\"end\":36547,\"start\":36518},{\"attributes\":{\"n\":\"3.5.3.\"},\"end\":41294,\"start\":41267},{\"attributes\":{\"n\":\"3.5.4.\"},\"end\":42580,\"start\":42551},{\"attributes\":{\"n\":\"4.\"},\"end\":43972,\"start\":43961},{\"end\":45979,\"start\":45969},{\"end\":46011,\"start\":46001},{\"end\":46043,\"start\":46033},{\"end\":46184,\"start\":46174},{\"end\":46325,\"start\":46315},{\"end\":46377,\"start\":46364},{\"end\":46889,\"start\":46879},{\"end\":46941,\"start\":46928},{\"end\":47370,\"start\":47360},{\"end\":47443,\"start\":47433},{\"end\":47516,\"start\":47506},{\"end\":47594,\"start\":47570},{\"end\":47745,\"start\":47735},{\"end\":47801,\"start\":47791},{\"end\":47843,\"start\":47833},{\"end\":47885,\"start\":47875},{\"end\":47927,\"start\":47917},{\"end\":47968,\"start\":47958},{\"end\":48008,\"start\":47999},{\"end\":48763,\"start\":48754},{\"end\":48998,\"start\":48989},{\"end\":49227,\"start\":49218},{\"end\":49369,\"start\":49360},{\"end\":49626,\"start\":49617},{\"end\":50253,\"start\":50244},{\"end\":50645,\"start\":50636},{\"end\":51152,\"start\":51143},{\"end\":51472,\"start\":51463}]", "table": "[{\"end\":48752,\"start\":48085},{\"end\":48987,\"start\":48798},{\"end\":49216,\"start\":49033},{\"end\":49358,\"start\":49261},{\"end\":49615,\"start\":49415},{\"end\":50242,\"start\":49695},{\"end\":50634,\"start\":50314},{\"end\":51141,\"start\":50745},{\"end\":51461,\"start\":51207},{\"end\":51864,\"start\":51556}]", "figure_caption": "[{\"end\":45999,\"start\":45981},{\"end\":46031,\"start\":46013},{\"end\":46172,\"start\":46045},{\"end\":46313,\"start\":46186},{\"end\":46362,\"start\":46327},{\"end\":46877,\"start\":46379},{\"end\":46926,\"start\":46891},{\"end\":47358,\"start\":46943},{\"end\":47431,\"start\":47372},{\"end\":47504,\"start\":47445},{\"end\":47568,\"start\":47518},{\"end\":47733,\"start\":47599},{\"end\":47789,\"start\":47747},{\"end\":47831,\"start\":47803},{\"end\":47873,\"start\":47845},{\"end\":47915,\"start\":47887},{\"end\":47956,\"start\":47929},{\"end\":47997,\"start\":47970},{\"end\":48085,\"start\":48010},{\"end\":48798,\"start\":48765},{\"end\":49033,\"start\":49000},{\"end\":49261,\"start\":49229},{\"end\":49415,\"start\":49371},{\"end\":49695,\"start\":49628},{\"end\":50314,\"start\":50255},{\"end\":50745,\"start\":50647},{\"end\":51207,\"start\":51154},{\"end\":51556,\"start\":51474}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":3252,\"start\":3244},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":12793,\"start\":12785},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":15796,\"start\":15788},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":17385,\"start\":17377},{\"attributes\":{\"ref_id\":\"fig_14\"},\"end\":25993,\"start\":25985},{\"attributes\":{\"ref_id\":\"fig_17\"},\"end\":33041,\"start\":33033},{\"attributes\":{\"ref_id\":\"fig_19\"},\"end\":33470,\"start\":33462},{\"attributes\":{\"ref_id\":\"fig_17\"},\"end\":33748,\"start\":33740},{\"attributes\":{\"ref_id\":\"fig_17\"},\"end\":34556,\"start\":34548},{\"attributes\":{\"ref_id\":\"fig_19\"},\"end\":34985,\"start\":34977},{\"attributes\":{\"ref_id\":\"fig_17\"},\"end\":35263,\"start\":35255},{\"attributes\":{\"ref_id\":\"fig_20\"},\"end\":38561,\"start\":38546},{\"attributes\":{\"ref_id\":\"fig_20\"},\"end\":38677,\"start\":38668},{\"attributes\":{\"ref_id\":\"fig_23\"},\"end\":38724,\"start\":38716},{\"attributes\":{\"ref_id\":\"fig_20\"},\"end\":38863,\"start\":38855},{\"attributes\":{\"ref_id\":\"fig_23\"},\"end\":38910,\"start\":38902},{\"end\":44812,\"start\":44805}]", "bib_author_first_name": "[{\"end\":52164,\"start\":52163},{\"end\":52174,\"start\":52173},{\"end\":52183,\"start\":52182},{\"end\":52191,\"start\":52190},{\"end\":52202,\"start\":52201},{\"end\":52215,\"start\":52214},{\"end\":52217,\"start\":52216},{\"end\":52230,\"start\":52229},{\"end\":52241,\"start\":52240},{\"end\":52254,\"start\":52253},{\"end\":52256,\"start\":52255},{\"end\":52267,\"start\":52266},{\"end\":52269,\"start\":52268},{\"end\":52658,\"start\":52657},{\"end\":52666,\"start\":52665},{\"end\":52674,\"start\":52673},{\"end\":52684,\"start\":52683},{\"end\":52695,\"start\":52694},{\"end\":52697,\"start\":52696},{\"end\":52996,\"start\":52995},{\"end\":52998,\"start\":52997},{\"end\":53008,\"start\":53007},{\"end\":53017,\"start\":53016},{\"end\":53342,\"start\":53341},{\"end\":53350,\"start\":53349},{\"end\":53358,\"start\":53357},{\"end\":53365,\"start\":53364},{\"end\":53367,\"start\":53366},{\"end\":53375,\"start\":53374},{\"end\":53722,\"start\":53721},{\"end\":53731,\"start\":53730},{\"end\":53740,\"start\":53739},{\"end\":53751,\"start\":53750},{\"end\":53758,\"start\":53757},{\"end\":53765,\"start\":53764},{\"end\":54139,\"start\":54138},{\"end\":54141,\"start\":54140},{\"end\":54153,\"start\":54152},{\"end\":54160,\"start\":54159},{\"end\":54169,\"start\":54168},{\"end\":54171,\"start\":54170},{\"end\":54181,\"start\":54180},{\"end\":54190,\"start\":54189},{\"end\":54196,\"start\":54195},{\"end\":54198,\"start\":54197},{\"end\":54209,\"start\":54208},{\"end\":54211,\"start\":54210},{\"end\":54736,\"start\":54735},{\"end\":54744,\"start\":54743},{\"end\":55058,\"start\":55057},{\"end\":55069,\"start\":55068},{\"end\":55071,\"start\":55070},{\"end\":55343,\"start\":55342},{\"end\":55345,\"start\":55344},{\"end\":55353,\"start\":55352},{\"end\":55364,\"start\":55363},{\"end\":55669,\"start\":55668},{\"end\":55678,\"start\":55677},{\"end\":55687,\"start\":55686},{\"end\":55689,\"start\":55688},{\"end\":56017,\"start\":56016},{\"end\":56028,\"start\":56027},{\"end\":56382,\"start\":56381},{\"end\":56393,\"start\":56392},{\"end\":56395,\"start\":56394},{\"end\":56767,\"start\":56766},{\"end\":56769,\"start\":56768},{\"end\":56785,\"start\":56784},{\"end\":56787,\"start\":56786},{\"end\":56797,\"start\":56796},{\"end\":56810,\"start\":56809},{\"end\":56812,\"start\":56811},{\"end\":56821,\"start\":56820},{\"end\":56833,\"start\":56832},{\"end\":57288,\"start\":57287},{\"end\":57290,\"start\":57289},{\"end\":57297,\"start\":57296},{\"end\":57308,\"start\":57307},{\"end\":57658,\"start\":57657},{\"end\":57660,\"start\":57659},{\"end\":57667,\"start\":57666},{\"end\":57669,\"start\":57668},{\"end\":57677,\"start\":57676},{\"end\":57679,\"start\":57678},{\"end\":57988,\"start\":57987},{\"end\":57990,\"start\":57989},{\"end\":58001,\"start\":58000},{\"end\":58011,\"start\":58010},{\"end\":58015,\"start\":58012},{\"end\":58024,\"start\":58023},{\"end\":58026,\"start\":58025},{\"end\":58356,\"start\":58355},{\"end\":58358,\"start\":58357},{\"end\":58369,\"start\":58368},{\"end\":58380,\"start\":58379},{\"end\":58391,\"start\":58390},{\"end\":58399,\"start\":58398},{\"end\":58735,\"start\":58734},{\"end\":58744,\"start\":58743},{\"end\":58752,\"start\":58751},{\"end\":58765,\"start\":58764},{\"end\":58777,\"start\":58776},{\"end\":58779,\"start\":58778},{\"end\":58792,\"start\":58791},{\"end\":58801,\"start\":58800},{\"end\":58809,\"start\":58808},{\"end\":58826,\"start\":58825},{\"end\":58833,\"start\":58832},{\"end\":59363,\"start\":59362},{\"end\":59370,\"start\":59369},{\"end\":59376,\"start\":59375},{\"end\":59384,\"start\":59383},{\"end\":59710,\"start\":59709},{\"end\":59723,\"start\":59722},{\"end\":59731,\"start\":59730},{\"end\":59735,\"start\":59732},{\"end\":59747,\"start\":59746},{\"end\":59756,\"start\":59755},{\"end\":59758,\"start\":59757},{\"end\":60253,\"start\":60252},{\"end\":60255,\"start\":60254},{\"end\":60265,\"start\":60264},{\"end\":60278,\"start\":60277},{\"end\":60292,\"start\":60291},{\"end\":60294,\"start\":60293},{\"end\":60303,\"start\":60302},{\"end\":60312,\"start\":60311},{\"end\":60314,\"start\":60313},{\"end\":60326,\"start\":60325},{\"end\":60328,\"start\":60327},{\"end\":60680,\"start\":60679},{\"end\":60691,\"start\":60690},{\"end\":60693,\"start\":60692},{\"end\":61133,\"start\":61132},{\"end\":61145,\"start\":61144},{\"end\":61162,\"start\":61161},{\"end\":61631,\"start\":61630},{\"end\":61633,\"start\":61632},{\"end\":61642,\"start\":61641},{\"end\":61644,\"start\":61643},{\"end\":61652,\"start\":61651},{\"end\":61654,\"start\":61653},{\"end\":61980,\"start\":61979},{\"end\":61988,\"start\":61987},{\"end\":61995,\"start\":61994},{\"end\":62004,\"start\":62003},{\"end\":62010,\"start\":62009},{\"end\":62270,\"start\":62269},{\"end\":62284,\"start\":62283},{\"end\":62294,\"start\":62293},{\"end\":62460,\"start\":62459},{\"end\":62469,\"start\":62468},{\"end\":62471,\"start\":62470},{\"end\":62487,\"start\":62486},{\"end\":62678,\"start\":62677},{\"end\":62685,\"start\":62684},{\"end\":62692,\"start\":62691},{\"end\":62700,\"start\":62699},{\"end\":62709,\"start\":62708},{\"end\":62717,\"start\":62716},{\"end\":63297,\"start\":63296},{\"end\":63306,\"start\":63305},{\"end\":63481,\"start\":63480},{\"end\":63483,\"start\":63482},{\"end\":63493,\"start\":63492},{\"end\":63688,\"start\":63687},{\"end\":63956,\"start\":63955},{\"end\":63958,\"start\":63957},{\"end\":63972,\"start\":63971},{\"end\":63976,\"start\":63973},{\"end\":63986,\"start\":63985},{\"end\":63995,\"start\":63994},{\"end\":63997,\"start\":63996},{\"end\":64010,\"start\":64009},{\"end\":64012,\"start\":64011},{\"end\":64022,\"start\":64021},{\"end\":64024,\"start\":64023},{\"end\":64032,\"start\":64031},{\"end\":64034,\"start\":64033},{\"end\":64044,\"start\":64043},{\"end\":64046,\"start\":64045},{\"end\":64055,\"start\":64054},{\"end\":64057,\"start\":64056},{\"end\":64065,\"start\":64064},{\"end\":64067,\"start\":64066},{\"end\":64420,\"start\":64419},{\"end\":64430,\"start\":64429},{\"end\":64444,\"start\":64443},{\"end\":64596,\"start\":64595},{\"end\":64605,\"start\":64604},{\"end\":64615,\"start\":64614},{\"end\":64625,\"start\":64624},{\"end\":64848,\"start\":64847},{\"end\":64860,\"start\":64859},{\"end\":65094,\"start\":65093},{\"end\":65102,\"start\":65101},{\"end\":65116,\"start\":65115},{\"end\":65123,\"start\":65122},{\"end\":65141,\"start\":65140},{\"end\":65143,\"start\":65142},{\"end\":65425,\"start\":65424},{\"end\":65431,\"start\":65430},{\"end\":65439,\"start\":65438},{\"end\":65447,\"start\":65446},{\"end\":65829,\"start\":65828},{\"end\":65835,\"start\":65834},{\"end\":65844,\"start\":65843},{\"end\":65851,\"start\":65850}]", "bib_author_last_name": "[{\"end\":52171,\"start\":52165},{\"end\":52180,\"start\":52175},{\"end\":52188,\"start\":52184},{\"end\":52199,\"start\":52192},{\"end\":52212,\"start\":52203},{\"end\":52227,\"start\":52218},{\"end\":52238,\"start\":52231},{\"end\":52251,\"start\":52242},{\"end\":52264,\"start\":52257},{\"end\":52278,\"start\":52270},{\"end\":52663,\"start\":52659},{\"end\":52671,\"start\":52667},{\"end\":52681,\"start\":52675},{\"end\":52692,\"start\":52685},{\"end\":52705,\"start\":52698},{\"end\":53005,\"start\":52999},{\"end\":53014,\"start\":53009},{\"end\":53024,\"start\":53018},{\"end\":53347,\"start\":53343},{\"end\":53355,\"start\":53351},{\"end\":53362,\"start\":53359},{\"end\":53372,\"start\":53368},{\"end\":53381,\"start\":53376},{\"end\":53728,\"start\":53723},{\"end\":53737,\"start\":53732},{\"end\":53748,\"start\":53741},{\"end\":53755,\"start\":53752},{\"end\":53762,\"start\":53759},{\"end\":53774,\"start\":53766},{\"end\":54150,\"start\":54142},{\"end\":54157,\"start\":54154},{\"end\":54166,\"start\":54161},{\"end\":54178,\"start\":54172},{\"end\":54187,\"start\":54182},{\"end\":54193,\"start\":54191},{\"end\":54206,\"start\":54199},{\"end\":54216,\"start\":54212},{\"end\":54741,\"start\":54737},{\"end\":54748,\"start\":54745},{\"end\":55066,\"start\":55059},{\"end\":55076,\"start\":55072},{\"end\":55350,\"start\":55346},{\"end\":55361,\"start\":55354},{\"end\":55374,\"start\":55365},{\"end\":55675,\"start\":55670},{\"end\":55684,\"start\":55679},{\"end\":55699,\"start\":55690},{\"end\":56025,\"start\":56018},{\"end\":56033,\"start\":56029},{\"end\":56390,\"start\":56383},{\"end\":56404,\"start\":56396},{\"end\":56782,\"start\":56770},{\"end\":56794,\"start\":56788},{\"end\":56807,\"start\":56798},{\"end\":56818,\"start\":56813},{\"end\":56830,\"start\":56822},{\"end\":56845,\"start\":56834},{\"end\":57294,\"start\":57291},{\"end\":57305,\"start\":57298},{\"end\":57315,\"start\":57309},{\"end\":57664,\"start\":57661},{\"end\":57674,\"start\":57670},{\"end\":57685,\"start\":57680},{\"end\":57998,\"start\":57991},{\"end\":58008,\"start\":58002},{\"end\":58021,\"start\":58016},{\"end\":58032,\"start\":58027},{\"end\":58366,\"start\":58359},{\"end\":58377,\"start\":58370},{\"end\":58388,\"start\":58381},{\"end\":58396,\"start\":58392},{\"end\":58410,\"start\":58400},{\"end\":58741,\"start\":58736},{\"end\":58749,\"start\":58745},{\"end\":58762,\"start\":58753},{\"end\":58774,\"start\":58766},{\"end\":58789,\"start\":58780},{\"end\":58798,\"start\":58793},{\"end\":58806,\"start\":58802},{\"end\":58823,\"start\":58810},{\"end\":58830,\"start\":58827},{\"end\":58844,\"start\":58834},{\"end\":59367,\"start\":59364},{\"end\":59373,\"start\":59371},{\"end\":59381,\"start\":59377},{\"end\":59394,\"start\":59385},{\"end\":59720,\"start\":59711},{\"end\":59728,\"start\":59724},{\"end\":59744,\"start\":59736},{\"end\":59753,\"start\":59748},{\"end\":59762,\"start\":59759},{\"end\":60262,\"start\":60256},{\"end\":60275,\"start\":60266},{\"end\":60289,\"start\":60279},{\"end\":60300,\"start\":60295},{\"end\":60309,\"start\":60304},{\"end\":60323,\"start\":60315},{\"end\":60331,\"start\":60329},{\"end\":60688,\"start\":60681},{\"end\":60699,\"start\":60694},{\"end\":61142,\"start\":61134},{\"end\":61159,\"start\":61146},{\"end\":61172,\"start\":61163},{\"end\":61639,\"start\":61634},{\"end\":61649,\"start\":61645},{\"end\":61659,\"start\":61655},{\"end\":61985,\"start\":61981},{\"end\":61992,\"start\":61989},{\"end\":62001,\"start\":61996},{\"end\":62007,\"start\":62005},{\"end\":62018,\"start\":62011},{\"end\":62281,\"start\":62271},{\"end\":62291,\"start\":62285},{\"end\":62304,\"start\":62295},{\"end\":62466,\"start\":62461},{\"end\":62484,\"start\":62472},{\"end\":62492,\"start\":62488},{\"end\":62682,\"start\":62679},{\"end\":62689,\"start\":62686},{\"end\":62697,\"start\":62693},{\"end\":62706,\"start\":62701},{\"end\":62714,\"start\":62710},{\"end\":62721,\"start\":62718},{\"end\":63303,\"start\":63298},{\"end\":63314,\"start\":63307},{\"end\":63490,\"start\":63484},{\"end\":63496,\"start\":63494},{\"end\":63502,\"start\":63498},{\"end\":63695,\"start\":63689},{\"end\":63969,\"start\":63959},{\"end\":63983,\"start\":63977},{\"end\":63992,\"start\":63987},{\"end\":64007,\"start\":63998},{\"end\":64019,\"start\":64013},{\"end\":64029,\"start\":64025},{\"end\":64041,\"start\":64035},{\"end\":64052,\"start\":64047},{\"end\":64062,\"start\":64058},{\"end\":64075,\"start\":64068},{\"end\":64427,\"start\":64421},{\"end\":64441,\"start\":64431},{\"end\":64453,\"start\":64445},{\"end\":64602,\"start\":64597},{\"end\":64612,\"start\":64606},{\"end\":64622,\"start\":64616},{\"end\":64636,\"start\":64626},{\"end\":64857,\"start\":64849},{\"end\":64870,\"start\":64861},{\"end\":65099,\"start\":65095},{\"end\":65113,\"start\":65103},{\"end\":65120,\"start\":65117},{\"end\":65138,\"start\":65124},{\"end\":65154,\"start\":65144},{\"end\":65428,\"start\":65426},{\"end\":65436,\"start\":65432},{\"end\":65444,\"start\":65440},{\"end\":65451,\"start\":65448},{\"end\":65832,\"start\":65830},{\"end\":65841,\"start\":65836},{\"end\":65848,\"start\":65845},{\"end\":65855,\"start\":65852}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":52053,\"start\":51866},{\"attributes\":{\"doi\":\"10.1016/S0140-6736(17)32520-5\",\"id\":\"b1\",\"matched_paper_id\":3473105},\"end\":52603,\"start\":52055},{\"attributes\":{\"doi\":\"10.1016/j.ijcard.2013.12.028\",\"id\":\"b2\",\"matched_paper_id\":37732970},\"end\":52928,\"start\":52605},{\"attributes\":{\"doi\":\"10.1016/j.ejim.2009.07.011\",\"id\":\"b3\",\"matched_paper_id\":207227305},\"end\":53241,\"start\":52930},{\"attributes\":{\"doi\":\"10.1186/1475-925X-13-18\",\"id\":\"b4\",\"matched_paper_id\":14717889},\"end\":53622,\"start\":53243},{\"attributes\":{\"doi\":\"10.1038/s41597-020-0386-x\",\"id\":\"b5\"},\"end\":54029,\"start\":53624},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":4610832},\"end\":54652,\"start\":54031},{\"attributes\":{\"doi\":\"10.14257/ijmue.2014.9.2.37\",\"id\":\"b7\",\"matched_paper_id\":3101667},\"end\":54999,\"start\":54654},{\"attributes\":{\"doi\":\"10.1109/10.959322\",\"id\":\"b8\",\"matched_paper_id\":6964298},\"end\":55258,\"start\":55001},{\"attributes\":{\"doi\":\"10.1109/TIM.2003.816841\",\"id\":\"b9\"},\"end\":55607,\"start\":55260},{\"attributes\":{\"doi\":\"10.1109/TIM.2006.884279\",\"id\":\"b10\",\"matched_paper_id\":17011989},\"end\":55908,\"start\":55609},{\"attributes\":{\"doi\":\"10.1109/TITB.2008.923147\",\"id\":\"b11\",\"matched_paper_id\":7854606},\"end\":56286,\"start\":55910},{\"attributes\":{\"doi\":\"10.1109/TBME.2010.2068048\",\"id\":\"b12\",\"matched_paper_id\":25244582},\"end\":56648,\"start\":56288},{\"attributes\":{\"doi\":\"10.1016/j.eswa.2011.08.025\",\"id\":\"b13\",\"matched_paper_id\":6413448},\"end\":57152,\"start\":56650},{\"attributes\":{\"doi\":\"10.1016/j.measurement.2013.05.021\",\"id\":\"b14\",\"matched_paper_id\":62636895},\"end\":57576,\"start\":57154},{\"attributes\":{\"doi\":\"10.1016/j.measurement.2010.08.019\",\"id\":\"b15\",\"matched_paper_id\":119724303},\"end\":57892,\"start\":57578},{\"attributes\":{\"doi\":\"10.1007/s10844-012-0214-7\",\"id\":\"b16\",\"matched_paper_id\":14044336},\"end\":58287,\"start\":57894},{\"attributes\":{\"doi\":\"10.1016/j.amc.2009.03.013\",\"id\":\"b17\",\"matched_paper_id\":15452899},\"end\":58642,\"start\":58289},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":4616975},\"end\":59294,\"start\":58644},{\"attributes\":{\"doi\":\"10.1155/2017/4108720\",\"id\":\"b19\",\"matched_paper_id\":27243731},\"end\":59588,\"start\":59296},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":4645832},\"end\":60174,\"start\":59590},{\"attributes\":{\"doi\":\"10.1038/s41591-018-0268-3\",\"id\":\"b21\",\"matched_paper_id\":11797512},\"end\":60578,\"start\":60176},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":3238161},\"end\":61052,\"start\":60580},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":4604972},\"end\":61526,\"start\":61054},{\"attributes\":{\"doi\":\"10.1109/ACCESS.2019.2903487\",\"id\":\"b24\",\"matched_paper_id\":85501981},\"end\":61884,\"start\":61528},{\"attributes\":{\"doi\":\"10.1785/0220180315\",\"id\":\"b25\"},\"end\":62252,\"start\":61886},{\"attributes\":{\"id\":\"b26\"},\"end\":62426,\"start\":62254},{\"attributes\":{\"doi\":\"10.1186/s40537-016-0043-6\",\"id\":\"b27\",\"matched_paper_id\":740063},\"end\":62639,\"start\":62428},{\"attributes\":{\"doi\":\"10.1007/978-3-030-01424-7_27\",\"id\":\"b28\",\"matched_paper_id\":51929263},\"end\":63200,\"start\":62641},{\"attributes\":{\"doi\":\"arXiv:1502.03167\",\"id\":\"b29\"},\"end\":63478,\"start\":63202},{\"attributes\":{\"doi\":\"arXiv:1412.6980\",\"id\":\"b30\"},\"end\":63657,\"start\":63480},{\"attributes\":{\"id\":\"b31\"},\"end\":63882,\"start\":63659},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":642375},\"end\":64379,\"start\":63884},{\"attributes\":{\"id\":\"b33\"},\"end\":64593,\"start\":64381},{\"attributes\":{\"id\":\"b34\"},\"end\":64845,\"start\":64595},{\"attributes\":{\"doi\":\"arXiv:1409.1556\",\"id\":\"b35\"},\"end\":65091,\"start\":64847},{\"attributes\":{\"doi\":\"arXiv:1902.08129\",\"id\":\"b36\"},\"end\":65373,\"start\":65093},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":17351470},\"end\":65747,\"start\":65375},{\"attributes\":{\"doi\":\"10.1109/TPAMI.2015.2389824\",\"id\":\"b38\",\"matched_paper_id\":436933},\"end\":66111,\"start\":65749},{\"attributes\":{\"id\":\"b39\"},\"end\":66542,\"start\":66113}]", "bib_title": "[{\"end\":52161,\"start\":52055},{\"end\":52655,\"start\":52605},{\"end\":52993,\"start\":52930},{\"end\":53339,\"start\":53243},{\"end\":54136,\"start\":54031},{\"end\":54733,\"start\":54654},{\"end\":55055,\"start\":55001},{\"end\":55340,\"start\":55260},{\"end\":55666,\"start\":55609},{\"end\":56014,\"start\":55910},{\"end\":56379,\"start\":56288},{\"end\":56764,\"start\":56650},{\"end\":57285,\"start\":57154},{\"end\":57655,\"start\":57578},{\"end\":57985,\"start\":57894},{\"end\":58353,\"start\":58289},{\"end\":58732,\"start\":58644},{\"end\":59360,\"start\":59296},{\"end\":59707,\"start\":59590},{\"end\":60250,\"start\":60176},{\"end\":60677,\"start\":60580},{\"end\":61130,\"start\":61054},{\"end\":61628,\"start\":61528},{\"end\":61977,\"start\":61886},{\"end\":62457,\"start\":62428},{\"end\":62675,\"start\":62641},{\"end\":63685,\"start\":63659},{\"end\":63953,\"start\":63884},{\"end\":65422,\"start\":65375},{\"end\":65826,\"start\":65749},{\"end\":66246,\"start\":66113}]", "bib_author": "[{\"end\":52173,\"start\":52163},{\"end\":52182,\"start\":52173},{\"end\":52190,\"start\":52182},{\"end\":52201,\"start\":52190},{\"end\":52214,\"start\":52201},{\"end\":52229,\"start\":52214},{\"end\":52240,\"start\":52229},{\"end\":52253,\"start\":52240},{\"end\":52266,\"start\":52253},{\"end\":52280,\"start\":52266},{\"end\":52665,\"start\":52657},{\"end\":52673,\"start\":52665},{\"end\":52683,\"start\":52673},{\"end\":52694,\"start\":52683},{\"end\":52707,\"start\":52694},{\"end\":53007,\"start\":52995},{\"end\":53016,\"start\":53007},{\"end\":53026,\"start\":53016},{\"end\":53349,\"start\":53341},{\"end\":53357,\"start\":53349},{\"end\":53364,\"start\":53357},{\"end\":53374,\"start\":53364},{\"end\":53383,\"start\":53374},{\"end\":53730,\"start\":53721},{\"end\":53739,\"start\":53730},{\"end\":53750,\"start\":53739},{\"end\":53757,\"start\":53750},{\"end\":53764,\"start\":53757},{\"end\":53776,\"start\":53764},{\"end\":54152,\"start\":54138},{\"end\":54159,\"start\":54152},{\"end\":54168,\"start\":54159},{\"end\":54180,\"start\":54168},{\"end\":54189,\"start\":54180},{\"end\":54195,\"start\":54189},{\"end\":54208,\"start\":54195},{\"end\":54218,\"start\":54208},{\"end\":54743,\"start\":54735},{\"end\":54750,\"start\":54743},{\"end\":55068,\"start\":55057},{\"end\":55078,\"start\":55068},{\"end\":55352,\"start\":55342},{\"end\":55363,\"start\":55352},{\"end\":55376,\"start\":55363},{\"end\":55677,\"start\":55668},{\"end\":55686,\"start\":55677},{\"end\":55701,\"start\":55686},{\"end\":56027,\"start\":56016},{\"end\":56035,\"start\":56027},{\"end\":56392,\"start\":56381},{\"end\":56406,\"start\":56392},{\"end\":56784,\"start\":56766},{\"end\":56796,\"start\":56784},{\"end\":56809,\"start\":56796},{\"end\":56820,\"start\":56809},{\"end\":56832,\"start\":56820},{\"end\":56847,\"start\":56832},{\"end\":57296,\"start\":57287},{\"end\":57307,\"start\":57296},{\"end\":57317,\"start\":57307},{\"end\":57666,\"start\":57657},{\"end\":57676,\"start\":57666},{\"end\":57687,\"start\":57676},{\"end\":58000,\"start\":57987},{\"end\":58010,\"start\":58000},{\"end\":58023,\"start\":58010},{\"end\":58034,\"start\":58023},{\"end\":58368,\"start\":58355},{\"end\":58379,\"start\":58368},{\"end\":58390,\"start\":58379},{\"end\":58398,\"start\":58390},{\"end\":58412,\"start\":58398},{\"end\":58743,\"start\":58734},{\"end\":58751,\"start\":58743},{\"end\":58764,\"start\":58751},{\"end\":58776,\"start\":58764},{\"end\":58791,\"start\":58776},{\"end\":58800,\"start\":58791},{\"end\":58808,\"start\":58800},{\"end\":58825,\"start\":58808},{\"end\":58832,\"start\":58825},{\"end\":58846,\"start\":58832},{\"end\":59369,\"start\":59362},{\"end\":59375,\"start\":59369},{\"end\":59383,\"start\":59375},{\"end\":59396,\"start\":59383},{\"end\":59722,\"start\":59709},{\"end\":59730,\"start\":59722},{\"end\":59746,\"start\":59730},{\"end\":59755,\"start\":59746},{\"end\":59764,\"start\":59755},{\"end\":60264,\"start\":60252},{\"end\":60277,\"start\":60264},{\"end\":60291,\"start\":60277},{\"end\":60302,\"start\":60291},{\"end\":60311,\"start\":60302},{\"end\":60325,\"start\":60311},{\"end\":60333,\"start\":60325},{\"end\":60690,\"start\":60679},{\"end\":60701,\"start\":60690},{\"end\":61144,\"start\":61132},{\"end\":61161,\"start\":61144},{\"end\":61174,\"start\":61161},{\"end\":61641,\"start\":61630},{\"end\":61651,\"start\":61641},{\"end\":61661,\"start\":61651},{\"end\":61987,\"start\":61979},{\"end\":61994,\"start\":61987},{\"end\":62003,\"start\":61994},{\"end\":62009,\"start\":62003},{\"end\":62020,\"start\":62009},{\"end\":62283,\"start\":62269},{\"end\":62293,\"start\":62283},{\"end\":62306,\"start\":62293},{\"end\":62468,\"start\":62459},{\"end\":62486,\"start\":62468},{\"end\":62494,\"start\":62486},{\"end\":62684,\"start\":62677},{\"end\":62691,\"start\":62684},{\"end\":62699,\"start\":62691},{\"end\":62708,\"start\":62699},{\"end\":62716,\"start\":62708},{\"end\":62723,\"start\":62716},{\"end\":63305,\"start\":63296},{\"end\":63316,\"start\":63305},{\"end\":63492,\"start\":63480},{\"end\":63498,\"start\":63492},{\"end\":63504,\"start\":63498},{\"end\":63697,\"start\":63687},{\"end\":63971,\"start\":63955},{\"end\":63985,\"start\":63971},{\"end\":63994,\"start\":63985},{\"end\":64009,\"start\":63994},{\"end\":64021,\"start\":64009},{\"end\":64031,\"start\":64021},{\"end\":64043,\"start\":64031},{\"end\":64054,\"start\":64043},{\"end\":64064,\"start\":64054},{\"end\":64077,\"start\":64064},{\"end\":64429,\"start\":64419},{\"end\":64443,\"start\":64429},{\"end\":64455,\"start\":64443},{\"end\":64604,\"start\":64595},{\"end\":64614,\"start\":64604},{\"end\":64624,\"start\":64614},{\"end\":64638,\"start\":64624},{\"end\":64859,\"start\":64847},{\"end\":64872,\"start\":64859},{\"end\":65101,\"start\":65093},{\"end\":65115,\"start\":65101},{\"end\":65122,\"start\":65115},{\"end\":65140,\"start\":65122},{\"end\":65156,\"start\":65140},{\"end\":65430,\"start\":65424},{\"end\":65438,\"start\":65430},{\"end\":65446,\"start\":65438},{\"end\":65453,\"start\":65446},{\"end\":65834,\"start\":65828},{\"end\":65843,\"start\":65834},{\"end\":65850,\"start\":65843},{\"end\":65857,\"start\":65850}]", "bib_venue": "[{\"end\":54327,\"start\":54274},{\"end\":58955,\"start\":58902},{\"end\":59873,\"start\":59820},{\"end\":60810,\"start\":60757},{\"end\":61283,\"start\":61230},{\"end\":62927,\"start\":62831},{\"end\":63740,\"start\":63726},{\"end\":64696,\"start\":64679},{\"end\":65537,\"start\":65520},{\"end\":66304,\"start\":66286},{\"end\":51885,\"start\":51866},{\"end\":52315,\"start\":52309},{\"end\":52750,\"start\":52735},{\"end\":53071,\"start\":53052},{\"end\":53425,\"start\":53406},{\"end\":53719,\"start\":53624},{\"end\":54272,\"start\":54218},{\"end\":54808,\"start\":54776},{\"end\":55118,\"start\":55095},{\"end\":55424,\"start\":55399},{\"end\":55749,\"start\":55724},{\"end\":56091,\"start\":56059},{\"end\":56454,\"start\":56431},{\"end\":56890,\"start\":56873},{\"end\":57361,\"start\":57350},{\"end\":57731,\"start\":57720},{\"end\":58079,\"start\":58059},{\"end\":58455,\"start\":58437},{\"end\":58900,\"start\":58846},{\"end\":59431,\"start\":59416},{\"end\":59818,\"start\":59764},{\"end\":60366,\"start\":60358},{\"end\":60755,\"start\":60701},{\"end\":61228,\"start\":61174},{\"end\":61699,\"start\":61688},{\"end\":62056,\"start\":62038},{\"end\":62267,\"start\":62254},{\"end\":62530,\"start\":62519},{\"end\":62829,\"start\":62751},{\"end\":63294,\"start\":63202},{\"end\":63562,\"start\":63519},{\"end\":63724,\"start\":63697},{\"end\":64111,\"start\":64077},{\"end\":64417,\"start\":64381},{\"end\":64677,\"start\":64638},{\"end\":64965,\"start\":64887},{\"end\":65226,\"start\":65172},{\"end\":65518,\"start\":65453},{\"end\":65921,\"start\":65883},{\"end\":66284,\"start\":66248}]"}}}, "year": 2023, "month": 12, "day": 17}