{"id": 4776668, "updated": "2023-03-25 16:25:11.694", "metadata": {"title": "Drain: An Online Log Parsing Approach with Fixed Depth Tree", "authors": "[{\"first\":\"Pinjia\",\"last\":\"He\",\"middle\":[]},{\"first\":\"Jieming\",\"last\":\"Zhu\",\"middle\":[]},{\"first\":\"Zibin\",\"last\":\"Zheng\",\"middle\":[]},{\"first\":\"Michael\",\"last\":\"Lyu\",\"middle\":[\"R.\"]}]", "venue": "2017 IEEE International Conference on Web Services (ICWS)", "journal": "2017 IEEE International Conference on Web Services (ICWS)", "publication_date": {"year": 2017, "month": null, "day": null}, "abstract": "Logs, which record valuable system runtime information, have been widely employed in Web service management by service providers and users. A typical log analysis based Web service management procedure is to first parse raw log messages because of their unstructured format, and then apply data mining models to extract critical system behavior information, which can assist Web service management. Most of the existing log parsing methods focus on offline, batch processing of logs. However, as the volume of logs increases rapidly, model training of offline log parsing methods, which employs all existing logs after log collection, becomes time consuming. To address this problem, we propose an online log parsing method, namely Drain, that can parse logs in a streaming and timely manner. To accelerate the parsing process, Drain uses a fixed depth parse tree, which encodes specially designed rules for parsing. We evaluate Drain on five real-world log data sets with more than 10 million raw log messages. The experimental results show that Drain has the highest accuracy on four data sets, and comparable accuracy on the remaining one. Besides, Drain obtains 51.85%~81.47% improvement in running time compared with the state-of-the-art online parser. We also conduct a case study on an anomaly detection task using Drain in the parsing step, which determines the effectiveness of Drain in log analysis.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": "2754665629", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/icws/HeZZL17", "doi": "10.1109/icws.2017.13"}}, "content": {"source": {"pdf_hash": "767d34c006b04bb08d5a5c17ef600270059eac9e", "pdf_src": "MergedPDFExtraction", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "20bed596d0b6f601db2afd3e4b3211dd67732dd9", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/767d34c006b04bb08d5a5c17ef600270059eac9e.txt", "contents": "\nDrain: An Online Log Parsing Approach with Fixed Depth Tree\n\n\nPinjia He pjhe@cse.cuhk.edu.hk \nJieming Zhu jmzhu@cse.cuhk.edu.hk \nZibin Zheng \nKey Laboratory of Machine Intelligence and Advanced Computing (Sun Yat-sen University), Ministry of Education School of Data and Computer Science, Sun Yat-sen University\nChina\n\nMichael R Lyu lyu@cse.cuhk.edu.hk \n\nComputer Science and Engineering Department\nThe Chinese University of Hong Kong\nChina\n\nDrain: An Online Log Parsing Approach with Fixed Depth Tree\n10.1109/ICWS.2017.13Index Terms-Log parsingOnline algorithmLog analysisWeb service management\nLogs, which record valuable system runtime information, have been widely employed in Web service management by service providers and users. A typical log analysis based Web service management procedure is to first parse raw log messages because of their unstructured format; and then apply data mining models to extract critical system behavior information, which can assist Web service management. Most of the existing log parsing methods focus on offline, batch processing of logs. However, as the volume of logs increases rapidly, model training of offline log parsing methods, which employs all existing logs after log collection, becomes time consuming. To address this problem, we propose an online log parsing method, namely Drain, that can parse logs in a streaming and timely manner. To accelerate the parsing process, Drain uses a fixed depth parse tree, which encodes specially designed rules for parsing. We evaluate Drain on five real-world log data sets with more than 10 million raw log messages. The experimental results show that Drain has the highest accuracy on four data sets, and comparable accuracy on the remaining one. Besides, Drain obtains 51.85%\u223c81.47% improvement in running time compared with the state-of-theart online parser. We also conduct a case study on an anomaly detection task using Drain in the parsing step, which determines the effectiveness of Drain in log analysis.\n\nI. INTRODUCTION\n\nThe prevalence of cloud computing, which enables ondemand service delivery, has made Service-oriented Architecture (SOA) a dominant architectural style. Nowadays, more and more developers leverage existing Web services to build their own systems because of their rich functionality and \"plug-and-play\" property. Although developing Web service based system is convenient and lightweight, Web service management is a significant challenge for both service providers and users. Specifically, service providers (e.g., Amazon EC2 [1]) are expected to provide services with no failures or SLA (service-level agreement) violations to a large number of users. Similarly, service users need to effectively and efficiently manage the adopted services, which have been discussed in many recent works (e.g., Web service monitoring [2]). In this context, log analysis based service management techniques, which employ service logs to achieve automatic or semiautomatic service management, have been widely studied.\n\nLogs are usually the only data resource available that records service runtime information. In general, a log message is a line of text printed by logging statements (e.g., printf(), logging.info()) written by developers. Thus, log analysis techniques, which apply data mining models to get insights of system behaviors, are in widespread use for service management. For service providers, there are studies in anomaly detection [3], [4], fault diagnosis [5], [6] and performance improvement [7]. For service users, typical examples include business model mining [8], [9] and user behavior analysis [10], [11].\n\nMost of the data mining models used in these log analysis techniques require structured input (e.g., an event list or a matrix). However, raw log messages are usually unstructured, because developers are allowed to write free-text log messages in source code. Thus, the first step of log analysis is log parsing, where unstructured log messages are transformed into structured events. An unstructured log message, as in the following example, usually contains various forms of system runtime information: timestamp (records the occurring time of an event), verbosity level (indicate the severity level of an event, e.g., INFO), and raw message content (free-text description of a service operation).\n\nTraditionally, log parsing relies heavily on regular expressions [12], which are designed and maintained manually by developers. However, this manual method is not suitable for logs generated by modern services for the following three reasons. First, the volume of logs is increasing rapidly, which makes the manual method prohibitive. For example, a largescale service system can generate 50 GB logs (120\u223c200 million lines) per hour [13]. Second, as open-source platforms (e.g., Github) and Web service become popular, a system often consists of components written by hundreds of developers globally [3]. Thus, people in charge of the regular expressions may not know the original logging purpose, which makes manual management even harder. Third, logging statements in modern systems updates frequently (e.g., hundreds of new logging statements every month [14]). In order to maintain a correct regular expression set, developers need to check all logging statements regularly, which is tedious and error-prone.\n\nLog parsing is widely studied to parse the raw log messages automatically. Most of existing log parsers focus on offline, batch processing. For example, Xu et al. [3] design a method to automatically generate regular expressions based on source code. However, source code is often inaccessible in practice (e.g., Web service components). For general log parsing, recent studies propose data-driven methods [4], [15], which directly extract log templates from raw log messages. These log parsers are offline, and limited by the memory of a single computer. Besides, they fail to align with the log collecting manner. A typical log collection system has a log shipper installed on each node to forward log entries in a streaming manner to a centralized server that contains a log parser [16]. The offline log parsers need to employ all logs after log collection for a certain period (e.g., 1h) for the parser training. In contrast, an online log parser parses logs in a streaming manner, and it does not require an offline training step. Thus, current systems highly demand online log parsing, which is only studied in a few preliminary works [16], [17]. However, we observe that the parsers proposed in these works are not accurate and efficient enough, which make them not eligible for log parsing in modern Web service or Web service based systems.\n\nIn this paper, we propose an online log parsing method, namely Drain, that can accurately and efficiently parse raw log messages in a streaming manner. Drain does not require source code or any information other than raw log messages. Drain can automatically extract log templates from raw log messages and split them into disjoint log groups. It employs a parse tree with fixed depth to guide the log group search process, which effectively avoids constructing a very deep and unbalanced tree. Besides, specially designed parsing rules are compactly encoded in the parse tree nodes. We evaluate Drain on five real-world log data sets with more than 10 million raw log messages. Drain demonstrates the highest accuracy on four data sets, and comparable accuracy on the remaining one. Besides, Drain obtains 51.8%\u223c81.47% improvement in running time compared with the state-of-the-art online parser [16]. We also demonstrate the effectiveness of Drain in log analysis by tackling a real-world anomaly detection task [3].\n\nIn summary, our paper makes the following contributions:\n\n\u2022 This paper presents the design of an online log parsing method (Drain), which encodes specially designed parsing rules in a parse tree with fixed depth. \u2022 Extensive experiments have been conducted on five realworld log data sets, which determine the superiority of Drain in terms of accuracy and efficiency. \u2022 The source code of Drain has been publicly released [18], allowing for easy use by researchers and practitioners for future study. The remainder of this paper is organized as follows. Section II presents the overview of log parsing process. Section III describes our online log parsing method, Drain. We evaluate the performance of Drain in Section IV. Related work is introduced in Section V. Finally, we conclude this paper in Section VI.\n\n\nII. OVERVIEW OF LOG PARSING\n\nThe goal of log parsing is to transform raw log messages into structured log messages, as described in Figure 1.  Specifically, raw log messages are unstructured data, including timestamps and raw message contents. The raw log messages in Figure 1 are simplified HDFS raw log messages collected on the Amazon EC2 platform [3]. In the parsing process, a parser distinguishes between the constant part and variable part of each raw log message. The constant part is tokens that describe a system operation template (i.e., log event), such as \"Receiving block * src: * dest: *\" in Figure 1; while the variable part is the remaining tokens (e.g, \"blk 3587\") that carry dynamic runtime system information. A typical structured log message contains a matched log event and fields of interest (e.g, the HDFS block ID \"blk 3587\"). Typical log parsers [4], [15], [16], [17] regard log parsing as a clustering problem, where they cluster raw log messages with the same log event into a log group. The following section introduces our proposed log parser, which clusters the raw log messages into different log groups in a streaming manner.\n\n\nIII. METHODOLOGY\n\nIn this section, we briefly introduce Drain, a fixed depth tree based online log parsing method. When a new raw log message arrives, Drain will preprocess it by simple regular expressions based on domain knowledge. Then we search a log group (i.e., leaf node of the tree) by following the speciallydesigned rules encoded in the internal nodes of the tree. If a suitable log group is found, the log message will be matched with the log event stored in that log group. Otherwise, a new log group will be created based on the log message. In the following, we first introduce the structure of the fixed depth tree (i.e., parse tree). Then we explain how Drain parses raw log messages by searching the nodes of the parse tree.\n\n\nA. Overall Tree Structure\n\nWhen a raw log message arrives, an online log parser needs to search the most suitable log group for it, or create a new log group. In this process, a simple solution is to compare the raw log message with log event stored in each log group one by one. However, this solution is very slow because the number of log groups increases rapidly in parsing. To accelerate this process, we design a parse tree with fixed depth to guide the log group search, which effectively bounds the number of log groups that a raw log message needs to compare with.\n\nThe parse tree is illustrated in Figure 2. The root node is in the top layer of the parse tree; the bottom layer contains the leaf nodes; other nodes in the tree are internal nodes. Root node and internal nodes encode specially-designed rules to guide the search process. They do not contain any log groups. Each path in the parse tree ends with a leaf node, which stores a list of log groups, and we only plot one leaf node here for simplicity. Each log group has two parts: log event and log IDs. Log event is the template that best describes the log messages in this group, which consists of the constant part of a log message. Log IDs records the IDs of log messages in this group. One special design of the parse tree is that the depth of all leaf nodes are the same and are fixed by a predefined parameter depth. For example, the depth of the leaf nodes in Figure 2 is fixed to 3. This parameter bounds the number of nodes Drain visits during the search process, which greatly improves its efficiency. Besides, to avoid tree branch explosion, we employ a parameter maxChild, which restricts the maximum number of children of a node. In the following, for clarity, we define an n-th layer node as a node whose depth is n. Besides, unless otherwise stated, we use the parse tree in Figure 2 as an example in following explanation.\n\n\nB. Step 1: Preprocess by Domain Knowledge\n\nAccording to our previous empirical study on existing log parsing methods [19], preprocessing can improve parsing accuracy. Thus, before employing the parse tree, we preprocess the raw log message when it arrives. Specifically, Drain allows users to provide simple regular expressions based on domain knowledge that represent commonly-used variables, such as IP address and block ID. Then Drain will remove the tokens matched from the raw log message by these regular expressions. For example, block IDs in Figure 1 will be removed by \"blk [0-9]+\".\n\nThe regular expressions employed in this step are often very simple, because they are used to match tokens instead of log messages. Besides, a data set usually requires only a few such regular expressions. For example, the data sets used in our evaluation section require at most two such regular expressions.\n\n\nC. Step 2: Search by Log Message Length\n\nIn this step and step 3, we explain how we traverse the parse tree according to the encoded rules and finally find a leaf node.\n\nDrain starts from the root node of the parse tree with the preprocessed log message. The 1-st layer nodes in the parse tree represent log groups whose log messages are of different log message lengths. By log message length, we mean the number of tokens in a log message. In this step, Drain selects a path to a 1-st layer node based on the log message length of the preprocessed log message. For example, for log message \"Receive from node 4\", Drain traverse to the internal node \"Length: 4\" in Figure 2. This is based on the assumption that log messages with the same log event will probably have the same log message length. Although it is possible that log messages with the same log event have different log message lengths, it can be handled by simple postprocessing. Besides, our experiments in Section IV-B demonstrate the superiority of Drain in terms of parsing accuracy even without postprocessing.\n\n\nD. Step 3: Search by Preceding Tokens\n\nIn this step, Drain traverses from a 1-st layer node, which is searched in step 2, to a leaf node. This step is based on the assumption that tokens in the beginning positions of a log message are more likely to be constants. Specifically, Drain selects the next internal node by the tokens in the beginning positions of the log message. For example, for log message \"Receive from node 4\", Drain traverses from 1-st layer node \"Length: 4\" to 2-nd layer node \"Receive\" because the token in the first position of the log message is \"Receive\". Then Drain will traverse to the leaf node linked with internal node \"Receive\", and go to step 4.\n\nThe number of internal nodes that Drain traverses in this step is (depth \u2212 2), where depth is the parse tree parameter restricting the depth of all leaf nodes. Thus, there are (depth\u2212 2) layers that encode the first (depth \u2212 2) tokens in the log messages as search rules. In the example above, we use the parse tree in Figure 2 for simplicity, whose depth is 3, so we search by only the token in the first position. In practice, Drain can consider more preceding tokens with larger depth settings. Note that if depth is 2, Drain only considers the first layer used by step 2.\n\nIn some cases, a log message may start with a parameter, for example, \"120 bytes received\". These kinds of log messages can lead to branch explosion in the parse tree because each parameter (e.g., 120) will be encoded in an internal node. To avoid branch explosion, we only consider tokens that do not contain digits in this step. If a token contains digits, it will match a special internal node \"*\". For example, for the log message above, Drain will traverse to the internal node \"*\" instead of \"120\". Besides, we also define a parameter maxChild, which restricts the maximum number of children of a node. If a node already has maxChild children, any non-matched tokens will match the special internal node \"*\" among all its children.\n\n\nE. Step 4: Search by Token Similarity\n\nBefore this step, Drain has traversed to a leaf node, which contains a list of log groups. The log messages in these log groups comply with the rules encoded in the internal nodes along the path. For example, the log group in Figure 2 has log event \"Receive from node *\", where the log messages contain 4 tokens and start with token \"Receive\".\n\nIn this step, Drain selects the most suitable log group from the log group list. We calculate the similarity simSeq between the log message and the log event of each log group. simSeq is defined as following:\nsimSeq = n i=1 equ(seq 1 (i), seq 2 (i)) n ,(1)\nwhere seq 1 and seq 2 represent the log message and the log event respectively; seq(i) is the i-th token of the sequence; n is the log message length of the sequences; function equ is defined as following:\nequ(t 1 , t 2 ) = 1 if t 1 = t 2 0 otherwise(2)\nwhere t 1 and t 2 are two tokens. After finding the log group with the largest simSeq, we compare it with a predefined similarity threshold st. If simSeq \u2265 st, Drain returns the group as the most suitable log group. Otherwise, Drain returns a flag (e.g., None in Python) to indicate no suitable log group.\n\n\nF. Step 5: Update the Parse Tree\n\nIf a suitable log group is returned in step 4, Drain will add the log ID of the current log message to the log IDs in the returned log group. Besides, the log event in the returned log group will be updated. Specifically, Drain scans the tokens in the same position of the log message and the log event. If the two tokens are the same, we do not modify the token in that token position. Otherwise, we update the token in that token position by wildcard (i.e., *) in the log event.\n\nIf Drain cannot find a suitable log group, it creates a new log group based on the current log message, where log IDs contains only the ID of the log message and log event is exactly the log message. Then, Drain will update the parse tree with the new log group. Intuitively, Drain traverses from the root node to a leaf node that should contain the new log group, and adds the missing internal nodes and leaf node accordingly along the path. For example, assume the current parse tree is the tree in the left-hand side of Figure 3, and a new log message \"Receive 120 bytes\" arrives. Then Drain will update the parse tree to the right-hand side tree in Figure 3. Note that the new internal node in the 3-rd layer is encoded as \"*\" because the token \"120\" contains digits.\n\n\nIV. EVALUATION\n\nA. Experimental Settings 1) Log Data Sets: The log data sets used in our evaluation are summarized in Table I. These five real-world data sets range from supercomputer logs (BGL and HPC) to distributed  system logs (HDFS and Zookeeper) to standalone software logs (Proxifier). Companies rarely release their log data to the public, because it may violates confidential clauses. We obtained three log data sets from other researchers with their generous support. Specifically, BGL is a log data set collected by Lawrence Livermore National Labs (LLNL) from Blue-Gene/L supercomputer system [20]. HPC logs are collected from a high performance cluster, which has 49 nodes with 6,152 cores and 128GB memory per node [21]. HDFS is a log data set collected from a 203-node cluster on Amazon EC2 platform in [3]. We also collect two log data sets for evaluation. One is collected from Zookeeper installed on a 32-node cluster in our lab. The other are logs of a standalone software Proxifier.\n\n\n2) Comparison:\n\nTo prove the effectiveness of Drain, we compare its performance with four existing log parsing methods in terms of accuracy, efficiency and effectiveness on subsequent log mining tasks. Specifically, two of them are offline log parsers, and the other two are online log parsers. The ideas of these log parsers are briefly introduced as following:\n\n\u2022 LKE [4]: This is an offline log parsing method developed by Microsoft. It employs hierarchical clustering and heuristic rules. \u2022 IPLoM [15]: IPLoM conducts a three-step hierarchical partitioning before template generation in an offline manner. \u2022 SHISO [17]: In this online parser, a tree with predefined number of children in each node is used to guide log group searching. \u2022 Spell [16]: This method uses longest common sequence to search log group in an online manner. It accelerates the searching process by subsequence matching and prefix tree.\n\n\n3) Evaluation Metric and Experimental Setup:\n\nWe use Fmeasure [22], [23], which is a typical evaluation metric for clustering algorithms, to evaluate the accuracy of log parsing methods. The definition of accuracy is as the following.\nAccuracy = 2 * P recision * Recall P recision + Recall ,(3)\nwhere P recision and Recall are defined as follows:\nP recision = T P T P + F P ,(4)Recall = T P T P + F N ,(5)\nwhere a true positive (T P ) decision assigns two log messages with the same log event to the same log group; a false positive (F P ) decision assigns two log messages with different log events to the same log group; and a false negative (F N) decision assigns two log messages with the same log event to different log groups. This evaluation metric is also used in our previous study [19] on existing log parsers. We run all experiments on a Linux server with Intel Xeon E5-2670v2 CPU and 128GB DDR3 1600 RAM, running 64bit Ubuntu 14.04.2 with Linux kernel 3.16.0. We run each experiment 10 times to avoid bias. For the preprocessing step of Drain (step 1), we remove obvious parameters in log messages (i.e., IP addresses in HPC&Zookeeper&HDFS, core IDs in BGL, block IDs in HDFS and application IDs in Proxifier). The parameter setting of Drain is shown in Table II. Besides, we empirically set maxChild to 100 for all experiments. The number of children of a tree node rarely exceeds maxChild, because the encoded rules in the parse tree can already distribute the logs evenly to different paths. We also re-tune the parameters of other log parsers to optimize their performance, which is not presented here because of the space limit. We put them in our released source code [18] for further reference.\n\n\nB. Accuracy of Drain\n\nAccuracy demonstrates how well a log parser matches raw log messages with the correct log events. Accuracy is important because parsing errors can degrade the performance of subsequent log mining task. Intuitively, an offline log parsing method could obtain higher accuracy compared with an online one, because an offline method enjoys all raw log messages at the beginning of parsing, while an online method adjusts its parsing model gradually in the parsing process.  In this section, we evaluate the accuracy of two offline and two online log parsing methods on the data sets described in Table I. The evaluation results are in Table III. LKE fails to handle the data sets except Proxifier, because its O(n 2 ) time complexity makes it too slow for the other data sets. Thus, for the other four data sets, as with the existing work [19], [24], we evaluate LKE's accuracy on sample data sets with 2k log messages randomly extracted from the original ones, while all parsers are evaluated on the 2k sample data sets in our previous paper [19].\n\nWe observe that the proposed online parsing method, namely Drain, obtains the best accuracy on four data sets, even compared with the offline log parsing methods. For data set Proxifier, Drain also has the second best accuracy (i.e., 0.86), and it is comparable to Spell, which obtains the highest accuracy (0.87) on this data set. LKE is not that good on some data sets, because it employs an aggressive clustering strategy, which can lead to under-partitioning. IPLoM obtains high accuracy on most data sets because of its specially-designed heuristic rules. SHISO uses the similarity of characters in log messages to search the corresponding log events. This strategy is too coarse-grained, which causes inaccuracy. Spell is accurate, but its strategy only based on longest common subsequence can lead to under-partitioning. Drain has the overall best accuracy for three reasons. First, it compounds both the log message length and the first few tokens, which are effective and specially-designed rules, to construct the fixed depth tree. Second, Drain only uses tokens that do not contain digits to guide the searching process, which effectively avoids over-partitioning. Third, the tunable tree depth and similar threshold st allows users to conduct fine-grained tuning on different data sets.\n\n\nC. Efficiency of Drain\n\nTo evaluate the efficiency of Drain, we measure the running time of it and four existing log parsers on five real-world log data sets described in Table I. In Table IV, we demonstrate the running time of these log parsers. LKE fails to handle four data sets in reasonable time (i.e., days or weeks), so we mark the corresponding results as not available.\n\nConsidering online parsing methods, SHISO takes too much time on some data sets (e.g., takes more than 3h on BGL). This is mainly because SHISO only limits the number of children for its tree nodes, which can cause very deep parse tree. Spell obtains better efficiency performance, because it employs a prefix tree structure to store all log events found, which greatly reduces its running time. However, Spell does not restrict the depth of its prefix tree either, and it calculates the longest common subsequence between two log messages, which is time consuming. Compared with the existing online parsing methods, our proposed Drain requires the least running time on all five data sets. Specifically, Drain only needs 2 min to parse 4m BGL log messages and 6 min to parse 10m HDFS log messages. Drain greatly improves the running time of existing online parsing methods. The improvements on the five real-world data sets are at least 51.85%, and it reduce 81.47% running time on HPC. Drain also outperforms the existing offline log parsing methods. It requires less running time than IPLoM on all five data sets. Moreover, as an online log parsing method, Drain is not limited by the memory of a single computer, which is the bottleneck of most offline log parsing methods. For example, IPLoM needs to load all log messages into computer memory, and it will construct extra data structures of comparable size in runtime. Thus, although IPLoM is efficient too, it may fail to handle large-scale log data. Drain is not limited by the memory of single computer, because it processes the log messages one by one.  BGL  400  4k  40k  400k  4m  HPC  600  3k  15k  75k  375k  HDFS  1k  10k  100k  1m  10m  Zookeeper  4k  8k  16k  32k  64k  Proxifier  600  1200  2400  4800  9600 Because log size of modern systems is rapidly increasing, a log parsing method is expected to handle large-scale log data. Thus, to simulate the increasing of log size, we also measure the running time of these log parsers on 25 sampled log data sets with varying log size (i.e., number of log messages) as described in Table V. The log messages in these sampled data sets are randomly extracted from the real-world data sets in Table I.\n\nThe evaluation results are illustrated in Figure 4, which is in logarithmic scale. In this figure, we observe that, compared with other methods, the running time of LKE raises faster as the log size increases. Because the time complexity of LKE is O(n 2 ), and the time complexity of other methods is O(n), while n is the number of log messages. IPLoM is comparable to Drain, but it requires substantial amounts of memory as explained above. Online parsing methods (i.e., SHISO, Spell, Drain) process log message one by one, and they all use a parse tree to accelerate the log event search process. Drain is faster than others because of two main reasons. First, Drain enjoys linear time complexity. The time complexity of Drain is O( (d + cm)n ), where d is the depth of the parse tree, c is the number of candidate log groups in the leaf node, m is the log message length, and n is the number of log messages. Obviously, d and m are constants. c can also be regarded as a constant, because the quantity of candidate log groups in each leaf node is nearly the same, and the number of log groups is far less than that of log messages. Thus, the time complexity of Drain is O(n). For SHISO and Spell, the depth of the parse tree could increase during the parsing process. Second, we use the specially-designed simSeq to calculate the similarity between a log message and a log event candidate. Its time complexity is O(m 1 + m 2 ), while m 1 and m 2 are number of tokens in them respectively. In Drain, m 1 = m 2 . By comparison, SHISO and Spell calculate the longest common subsequence between two sequences, whose time complexity is O(m 1 m 2 ).\n\n\nD. Effectiveness of Drain on Real-World Anomaly Detection Task\n\nIn previous sections, we demonstrate the superiority of Drain in terms of accuracy and efficiency. Although high accuracy is necessary for log parsing methods, it does not guarantee good performance in the subsequent log mining task. For example, because log mining could be sensitive to some critical events, little parsing error may cause an order of magnitude performance degradation in log mining [19]. To evaluate the effectiveness of Drain on subsequent log mining tasks, we conduct a case study on a real-world anomaly detection task.\n\nWe use the HDFS log data set in this case study. Specifically, raw log messages in the HDFS data set [3] records system operations on 575,061 HDFS blocks with a total of 29 log event types. Among these blocks, 16,838 are manually labeled as anomalies by the original authors. In the original paper [3], the authors employ Principal Component Analysis (PCA) to detect these anomalies. Next, we will briefly introduce the anomaly detection workflow, including log parsing and log mining. In log parsing step, all the raw log messages are parsed into structured log messages. Each structured log message contains the corresponding HDFS block ID and a log event. A source code-based log parsing method is used in the original paper, which is not discussed here because source code is inaccessible in many cases (e.g., in third party libraries). In log mining, we first use the structured log messages to generate an event count matrix, where each row represents an HDFS block; each column represents a log event type; each cell counts the occurrence of an event on a certain HDFS block. Then we use TF-IDF [25] to preprocess the event count matrix. Intuitively, TF-IDF gives lower weights to common event types, which are less likely to contribute to the anomaly detection process. Finally, the event count matrix is fed into PCA, which automatically marks the blocks as normal or abnormal.\n\nIn our case study, we evaluate the performance of the anomaly detection task with different log parsing methods  used in the parsing step. Specifically, we use different log parsing methods to parse the HDFS raw log messages respectively and, hence, we obtain different sets of structured log messages. For example, an HDFS block ID could match with different log events by using different log parsing methods. Then, we generate different event count matrices, and fed them into PCA, respectively. The experimental results are shown in Table VI. In this table, reported anomaly is the number of anomalies reported by the PCA model; detected anomaly is the number of true anomalies reported; f alse alarm is the number of wrongly reported ones. We use four existing log parsing methods to handle the parsing step of this anomaly detection task. We do not use LKE because it cannot handle this large amount of data. Ground truth is the experiment using exactly correct parsed results.\n\nWe can observe that Drain obtains nearly the optimal anomaly detection performance. It detects 10, 720 true anomalies with only 278 false alarms. Although 37% of anomalies have not been detected, it is caused by the log mining step. Because even when all the log messages are correctly parsed, the log mining model still leaves 34% of anomalies at large. Note that although IPLoM demonstrates the same anomaly detection performance as Drain, their parsing results are different. We also observe that SHISO, although has a high parsing accuracy (0.93), does not perform well in this anomaly detection task. By using SHISO, we would report 1, 907 false alarms, which are 6 times worse than others. This will largely increase the workload of developers, because they usually need to manually check the anomalies reported. Among the online parsing methods, Drain not only has the highest parsing accuracy as demonstrated in Section IV-B, but also obtains nearly optimal performance in the anomaly detection case study.\n\n\nV. RELATED WORK\n\nLog Analysis for Service Management. Logs, which records system runtime information, are in widespread use for service management tasks, such as business model mining [8], [9], user behavior analysis [10], [11], anomaly detection [3], [4], [26], fault diagnosis [5], [6], performance improvement [7], etc. Log parsing is a critical step to enable automated and effective log analysis [19], because most of these techniques require structured log messages as input. Thus, we believe our proposed online parsing method can benefit these techniques and future studies on log analysis.\n\nLog Parsing. Log parsing has been widely studied in recent years. Xu et al. [3] design a source code based log parser that achieves high accuracy. However, source code is often inaccessible in practice (e.g., Web service components). Some other work proposes data-driven approaches (LKE [4], IPLoM [15], SHISO [17], Spell [16]), in which data mining techniques are employed to extract log templates and split raw log messages into different log groups accordingly. Specifically, LKE and IPLoM are offline log parsers, which are studied in our previous evaluation study on offline log parsers [19]. SHISO and Spell are online log parsers, which parse log messages in a streaming manner, and are not limited by the memory of a single computer. In this paper, we propose an online log parser, namely Drain, that greatly outperforms existing online log parsers in terms of both accuracy and efficiency. It even performs better than the state-of-the-art offline parsers.\n\nReliability of Web Service Systems. Many recent studies focus on enhancing the reliability of Web service systems. Cubo et al. [27] use dynamic software product lines to reconfigure service failures dynamically. Service selection and recommendation are also widely studied [28], [29]. These studies usually employ QoS (quality of service) values to characterize the reliability of different Web services. Jurca et al. [30] propose a reliable QoS monitoring technique based on client feedback. Yao et al. [31] develop a model with accountability for business and QoS compliance. Besides, Chen et al. [32] propose a performance prediction method for component-based applications. Our proposed online log parser is critical for log analysis techniques, which can complement with these methods in reliability enhancement for Web service systems. The log analysis methods can also improve the reliability of many existing service systems [33], [34], [35].\n\n\nVI. CONCLUSION\n\nLog parsing is critical for log analysis based Web service management techniques. This paper proposes an online log parsing method, namely Drain, that parses raw log messages in a streaming manner. Drain adopts a fixed depth parse tree to accelerate the log group search process, which encodes specially designed rules in its tree nodes. To evaluate the effectiveness of Drain, we conduct experiments on five realworld log data sets. The experimental results show that Drain greatly outperforms existing online log parsers in terms of accuracy and efficiency. Drain even obtains better performance than the state-of-the-art offline log parsers, which are limited by the memory of a single computer. Besides, we conduct a case study on a real-world anomaly detection task, which demonstrates the effectiveness of Drain on log analysis tasks.\n\nFig. 1 :\n1Overview of Log Parsing\n\nFig. 2 :\n2Structure of Parse Tree in Drain (depth = 3)\n\nFig. 3 :\n3Parse Tree Update Example (depth = 4)\n\nFig. 4 :\n4Running Time of Log Parsing Methods on Data Sets in Different Size\n\nTABLE I :\nISummary of Log Data SetsSystem \nDescription \n#Log Messages Log Message Length \n#Events \nBlueGene/L \nSupercomputer \nHigh Performance \nCluster \n(Los Alamos) \nHDFS \nHadoop File System \n11,175,629 \n8~29 \n29 \nDistributed \nSystem Coordinator \nProxifier \nProxy Client \n10,108 \n10~27 \n8 \n\n80 \n\n376 \n\nHPC \n433,490 \n6~104 \n105 \n\nBGL \n10~102 \n4,747,963 \n\nZookeeper \n74,380 \n8~27 \n\n\nTABLE II :\nIIParameter Setting of DrainBGL \nHPC \nHDFS \nZookeeper \nProxifier \ndepth \n3 \n4 \n3 \n3 \n4 \nst \n0.3 \n0.4 \n0.5 \n0.3 \n0.3 \n\n\n\nTABLE III :\nIIIParsing Accuracy of Log Parsing MethodsBGL \nHPC \nHDFS \nZookeeper \nProxifier \n\nLKE \n0.67 \n0.17 \n0.57 \n0.78 \n0.85 \nIPLoM \n0.99 \n0.65 \n0.99 \n0.99 \n0.85 \n\nSHISO \n0.87 \n0.53 \n0.93 \n0.68 \n0.85 \nSpell \n0.98 \n0.82 \n0.87 \n0.99 \n0.87 \nDrain \n0.99 \n0.84 \n0.99 \n0.99 \n0.86 \n\nOffline Log Parsers \n\nOnline Log Parsers \n\n\n\nTABLE IV :\nIVRunning Time (Sec) of Log Parsing MethodsBGL \nHPC \nHDFS \nZookeeper \nProxifier \n\nLKE \nN/A \nN/A \nN/A \nN/A \n8888.49 \nIPLoM \n140.57 \n12.74 \n333.03 \n2.17 \n0.38 \n\nSHISO \n10964.55 \n582.14 \n6649.23 \n87.61 \n8.41 \nSpell \n447.14 \n47.28 \n676.45 \n5.27 \n0.87 \nDrain \n115.96 \n8.76 \n325.7 \n1.81 \n0.27 \nImprovement \n74.07% \n81.47% \n51.85% \n65.65% \n68.97% \n\nOffline Log Parsers \n\nOnline Log Parsers \n\n\n\nTABLE V :\nVLog Size of Sample Datasets for Efficiency Experiments\n\nTABLE VI :\nVIAnomaly Detection with Different Log Parsing Methods (16,838 True Anomalies)Parsing \nReported \nDetected \nFalse \nAccuracy \nAnomaly \nAnomaly \nAlarm \nIPLoM \n0.99 \n10,998 \n10,720 (63%) \n278 (2.5%) \nSHISO \n0.93 \n13,050 \n11,143 (66%) 1,907 (14.6%) \nSpell \n0.87 \n10,949 \n10,674 (63%) \n275 (2.5%) \nDrain \n0.99 \n10,998 \n10,720 (63%) \n278 (2.5%) \nGround truth \n1.00 \n11,473 \n11,195 (66%) \n278 (2.4%) \n\n\nAuthorized licensed use limited to: Chinese University of Hong Kong. Downloaded on December 03,2020 at 03:01:38 UTC from IEEE Xplore. Restrictions apply.\n\nAmazon ec2. Amazon ec2. [Online]. Available: https://aws.amazon.com/tw/ec2/\n\nLog2: A cost-aware logging mechanism for performance diagnosis. R Ding, H Zhou, J Lou, H Zhang, Q Lin, Q Fu, D Zhang, T Xie, ATC'15: Proc. of the USENIX Annual Technical Conference. R. Ding, H. Zhou, J. Lou, H. Zhang, Q. Lin, Q. Fu, D. Zhang, and T. Xie, \"Log2: A cost-aware logging mechanism for performance diagnosis,\" in ATC'15: Proc. of the USENIX Annual Technical Conference, 2015.\n\nDetecting largescale system problems by mining console logs. W Xu, L Huang, A Fox, D Patterson, M Jordon, SOSP'09: Proc. of the ACM Symposium on Operating Systems Principles. W. Xu, L. Huang, A. Fox, D. Patterson, and M. Jordon, \"Detecting large- scale system problems by mining console logs,\" in SOSP'09: Proc. of the ACM Symposium on Operating Systems Principles, 2009.\n\nExecution anomaly detection in distributed systems through unstructured log analysis. Q Fu, J Lou, Y Wang, J Li, ICDM'09: Proc. of International Conference on Data Mining. Q. Fu, J. Lou, Y. Wang, and J. Li, \"Execution anomaly detection in distributed systems through unstructured log analysis,\" in ICDM'09: Proc. of International Conference on Data Mining, 2009.\n\nEffective software fault localization using an rbf neural network. W E Wong, V Debroy, R Golden, X Xu, B Thuraisingham, TR'12: IEEE Transactions on Reliability. W. E. Wong, V. Debroy, R. Golden, X. Xu, and B. Thuraisingham, \"Effective software fault localization using an rbf neural network,\" TR'12: IEEE Transactions on Reliability, 2012.\n\nUilog: Improving log-based fault diagnosis by log analysis. D Q Zou, H Qin, H Jin, Journal of Computer Science and Technology. 315D. Q. Zou, H. Qin, and H. Jin, \"Uilog: Improving log-based fault diagnosis by log analysis,\" Journal of Computer Science and Technology, vol. 31, no. 5, pp. 1038-1052, 2016.\n\nPersonalized ranking for digital libraries based on log analysis. Y Sun, H Li, I G Councill, J Huang, W C Lee, C L Giles, WIDM'08: Proc. of the 10th ACM workshop on Web information and data management. Y. Sun, H. Li, I. G. Councill, J. Huang, W. C. Lee, and C. L. Giles, \"Personalized ranking for digital libraries based on log analysis,\" in WIDM'08: Proc. of the 10th ACM workshop on Web information and data management, 2008, pp. 133-140.\n\nProcess mining on noisy logs-can log sanitization help to improve performance?. H J Cheng, A Kumar, Decision Support Systems. 79H. J. Cheng and A. Kumar, \"Process mining on noisy logs-can log sanitization help to improve performance?\" Decision Support Systems, vol. 79, pp. 138-149, 2015.\n\nDeriving protocol models from imperfect service conversation logs. H R Motahari-Nezhad, R Saint-Paul, B Benatallah, F Casati, TKDE'08: IEEE Transactions on Knowledge and Data Engineering. 20H. R. Motahari-Nezhad, R. Saint-Paul, B. Benatallah, and F. Casati, \"Deriving protocol models from imperfect service conversation logs,\" TKDE'08: IEEE Transactions on Knowledge and Data Engineering, vol. 20, no. 12, pp. 1683-1698, 2008.\n\nPrediction of web user behavior by discovering temporal relational rules from web log data. X Yu, M Li, I Paik, K H Ryu, DEXA'12: Proc. of the 23rd International Conference on Database and Expert Systems Applications. X. Yu, M. Li, I. Paik, and K. H. Ryu, \"Prediction of web user behavior by discovering temporal relational rules from web log data,\" in DEXA'12: Proc. of the 23rd International Conference on Database and Expert Systems Applications, 2012, pp. 31-38.\n\nBusiness process mining from e-commerce web logs. N Poggi, V Muthusamy, D Carrera, R Khalaf, Business Process Management. N. Poggi, V. Muthusamy, D. Carrera, and R. Khalaf, \"Business process mining from e-commerce web logs,\" in Business Process Management, 2013, pp. 65-80.\n\nUsing SEC. D Lang, USENIX ;login: Magazine. 38D. Lang, \"Using SEC,\" USENIX ;login: Magazine, vol. 38, 2013.\n\nToward fine-grained, unsupervised, scalable performance diagnosis for production cloud computing systems. H Mi, H Wang, Y Zhou, M R Lyu, H Cai, IEEE Transactions on Parallel and Distributed Systems. 24H. Mi, H. Wang, Y. Zhou, M. R. Lyu, and H. Cai, \"Toward fine-grained, unsupervised, scalable performance diagnosis for production cloud com- puting systems,\" IEEE Transactions on Parallel and Distributed Systems, vol. 24, pp. 1245-1255, 2013.\n\nSystem problem detection by mining console logs. W Xu, University of California, BerkeleyPh.D. dissertationW. Xu, \"System problem detection by mining console logs,\" Ph.D. dissertation, University of California, Berkeley, 2010.\n\nA lightweight algorithm for message type extraction in system application logs. A Makanju, A Zincir-Heywood, E Milios, TKDE'12: IEEE Transactions on Knowledge and Data Engineering. A. Makanju, A. Zincir-Heywood, and E. Milios, \"A lightweight algo- rithm for message type extraction in system application logs,\" TKDE'12: IEEE Transactions on Knowledge and Data Engineering, 2012.\n\nSpell: Streaming parsing of system event logs. M Du, F Li, ICDM'16 Proc. of the 16th International Conference on Data Mining. M. Du and F. Li, \"Spell: Streaming parsing of system event logs,\" in ICDM'16 Proc. of the 16th International Conference on Data Mining, 2016.\n\nIncremental mining of system log format. M Mizutani, SCC'13: Proc. of the 10th International Conference on Services Computing. M. Mizutani, \"Incremental mining of system log format,\" in SCC'13: Proc. of the 10th International Conference on Services Computing, 2013.\n\nDrain source code. Drain source code. [Online]. Available: http://appsrv.cse.cuhk.edu.hk/ \u223c pjhe/Drain.py\n\nAn evaluation study on log parsing and its use in log mining. P He, J Zhu, S He, J Li, M R Lyu, DSN'16: Proc. of the. 46P. He, J. Zhu, S. He, J. Li, and M. R. Lyu, \"An evaluation study on log parsing and its use in log mining,\" in DSN'16: Proc. of the 46th\n\nAnnual IEEE/IFIP International Conference on Dependable Systems and Networks. Annual IEEE/IFIP International Conference on Dependable Systems and Networks, 2016.\n\nWhat supercomputers say: A study of five system logs. A Oliner, J Stearley, DSN'07. A. Oliner and J. Stearley, \"What supercomputers say: A study of five system logs,\" in DSN'07, 2007.\n\nOperational data to support and enable computer science research. L A N S Llc, L. A. N. S. LLC. Operational data to support and enable computer science research. [Online]. Available: http://institutes.lanl.gov/data/fdata\n\nIntroduction to Information Retrieval. C Manning, P Raghavan, H Schutze, Cambridge University PressC. Manning, P. Raghavan, and H. Schutze, Introduction to Information Retrieval. Cambridge University Press, 2008.\n\nEvaluation of clustering. Evaluation of clustering. [Online]. Available: http://nlp.stanford.edu/ IR-book/html/htmledition/evaluation-of-clustering-1.html\n\nLogSig: generating system events from raw textual logs. L Tang, T Li, C Perng, CIKM'11: Proc. of ACM International Conference on Information and Knowledge Management. L. Tang, T. Li, and C. Perng, \"LogSig: generating system events from raw textual logs,\" in CIKM'11: Proc. of ACM International Conference on Information and Knowledge Management, 2011.\n\nTerm weighting approaches in automatic text retrival. G Salton, C Buckley, Cornell, Tech. Rep. G. Salton and C. Buckley, \"Term weighting approaches in automatic text retrival,\" Cornell, Tech. Rep., 1987.\n\nRealtime anomaly detection in streams of execution traces. W Zhang, F Bastani, I L Yen, K Hulin, F Bastani, L Khan, HASE'16: Proc. of the 14th International Symposium on High-Assurance Systems Engineering. W. Zhang, F. Bastani, I. L. Yen, K. Hulin, F. Bastani, and L. Khan, \"Real- time anomaly detection in streams of execution traces,\" in HASE'16: Proc. of the 14th International Symposium on High-Assurance Systems Engineering, 2012, pp. 32-39.\n\nReconfiguration of service failures in damasco using dynamic software product lines. J Cubo, N Gamez, E Pimentel, L Fuentes, SCC'15: Proc. of the 12nd International Conference on Services Computing. J. Cubo, N. Gamez, E. Pimentel, and L. Fuentes, \"Reconfiguration of service failures in damasco using dynamic software product lines,\" in SCC'15: Proc. of the 12nd International Conference on Services Computing, 2015, pp. 114-121.\n\nWeb services selection in support of reliable web service choreography. S Y Hwang, W P Liao, C H Lee, ICWS'10: Proc. of the 17th International Conference on Web Services. S. Y. Hwang, W. P. Liao, and C. H. Lee, \"Web services selection in support of reliable web service choreography,\" in ICWS'10: Proc. of the 17th International Conference on Web Services, 2010, pp. 115-122.\n\nA temporal-aware hybrid collaborative recommendation method for cloud service. S Meng, Z Zhou, T Huang, D Li, S Wang, F Fei, W Wang, W Dou, ICWS'16: Proc. of the 23rd International Conference on Web Services. S. Meng, Z. Zhou, T. Huang, D. Li, S. Wang, F. Fei, W. Wang, and W. Dou, \"A temporal-aware hybrid collaborative recommendation method for cloud service,\" in ICWS'16: Proc. of the 23rd International Conference on Web Services, 2016, pp. 252-259.\n\nReliable qos monitoring based on client feedback. R Jurca, B Faltings, W Binder, WWW'07: Proc. of the 16th International Conference on World Wide Web. R. Jurca, B. Faltings, and W. Binder, \"Reliable qos monitoring based on client feedback,\" in WWW'07: Proc. of the 16th International Conference on World Wide Web, 2007, pp. 1003-1012.\n\nModelling collaborative services for business and qos compliance. J Yao, S Chen, C Wang, D Levy, J Zic, ICWS'11: Proc. of the 18th International Conference on Web Services. J. Yao, S. Chen, C. Wang, D. Levy, and J. Zic, \"Modelling collaborative services for business and qos compliance,\" in ICWS'11: Proc. of the 18th International Conference on Web Services, 2011, pp. 299-306.\n\nPerformance prediction of component-based applications. S Chen, Y Liu, I Gorton, A Liu, JSS'05: Journal of Systems and Software. 74S. Chen, Y. Liu, I. Gorton, and A. Liu, \"Performance prediction of component-based applications,\" JSS'05: Journal of Systems and Software, vol. 74, no. 1, pp. 35-43, 2005.\n\nAutomotive cloud service systems based on service-oriented architecture and its evaluation. A Iwai, M Aoyama, CLOUD'11: Proc. of the 4th International Conference on Cloud Computing. A. Iwai and M. Aoyama, \"Automotive cloud service systems based on service-oriented architecture and its evaluation,\" in CLOUD'11: Proc. of the 4th International Conference on Cloud Computing, 2011.\n\nSensor data as a service-a federated platform for mobile data-centric service development and sharing. J Zhang, B Iannucci, M Hennessy, K Gopal, S Xiao, S Kumar, D Pfeffer, B Aljedia, Y Ren, M Griss, S Rosenberg, J Cao, A Rowe, SCC'13: Proc. of the 10th International Conference on Services Computing. J. Zhang, B. Iannucci, M. Hennessy, K. Gopal, S. Xiao, S. Kumar, D. Pfeffer, B. Aljedia, Y. Ren, M. Griss, S. Rosenberg, J. Cao, and A. Rowe, \"Sensor data as a service-a federated platform for mobile data-centric service development and sharing,\" in SCC'13: Proc. of the 10th International Conference on Services Computing, 2013.\n\nEverything as a service (xaas) on the cloud: origins, current and future trends. Y Duan, G Fu, N Zhou, X Sun, N C Narendra, B Hu, CLOUD'15: Proc. of the 8th International Conference on Cloud Computing. Y. Duan, G. Fu, N. Zhou, X. Sun, N. C. Narendra, and B. Hu, \"Everything as a service (xaas) on the cloud: origins, current and future trends,\" in CLOUD'15: Proc. of the 8th International Conference on Cloud Computing, 2015, pp. 621-628.\n", "annotations": {"author": "[{\"end\":94,\"start\":63},{\"end\":129,\"start\":95},{\"end\":319,\"start\":130},{\"end\":354,\"start\":320},{\"end\":442,\"start\":355}]", "publisher": null, "author_last_name": "[{\"end\":72,\"start\":70},{\"end\":106,\"start\":103},{\"end\":141,\"start\":136},{\"end\":333,\"start\":330}]", "author_first_name": "[{\"end\":69,\"start\":63},{\"end\":102,\"start\":95},{\"end\":135,\"start\":130},{\"end\":327,\"start\":320},{\"end\":329,\"start\":328}]", "author_affiliation": "[{\"end\":318,\"start\":143},{\"end\":441,\"start\":356}]", "title": "[{\"end\":60,\"start\":1},{\"end\":502,\"start\":443}]", "venue": null, "abstract": "[{\"end\":2005,\"start\":597}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2553,\"start\":2550},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2847,\"start\":2844},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3460,\"start\":3457},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3465,\"start\":3462},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":3486,\"start\":3483},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3491,\"start\":3488},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":3523,\"start\":3520},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":3594,\"start\":3591},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":3599,\"start\":3596},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3631,\"start\":3627},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":3637,\"start\":3633},{\"end\":4266,\"start\":4261},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":4410,\"start\":4406},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":4779,\"start\":4775},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":4945,\"start\":4942},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":5204,\"start\":5200},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":5522,\"start\":5519},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":5765,\"start\":5762},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":5771,\"start\":5767},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":6145,\"start\":6141},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":6501,\"start\":6497},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":6507,\"start\":6503},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":7608,\"start\":7604},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":7724,\"start\":7721},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":8153,\"start\":8149},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":8894,\"start\":8891},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":9415,\"start\":9412},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":9421,\"start\":9417},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":9427,\"start\":9423},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":9433,\"start\":9429},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":12477,\"start\":12473},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":19439,\"start\":19435},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":19563,\"start\":19559},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":19651,\"start\":19648},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":20208,\"start\":20205},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":20340,\"start\":20336},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":20457,\"start\":20453},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":20587,\"start\":20583},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":20817,\"start\":20813},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":20823,\"start\":20819},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":21546,\"start\":21542},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":22441,\"start\":22437},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":23328,\"start\":23324},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":23334,\"start\":23330},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":23532,\"start\":23528},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":29549,\"start\":29545},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":29791,\"start\":29788},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":29988,\"start\":29985},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":30793,\"start\":30789},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":33263,\"start\":33260},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":33268,\"start\":33265},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":33297,\"start\":33293},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":33303,\"start\":33299},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":33326,\"start\":33323},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":33331,\"start\":33328},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":33337,\"start\":33333},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":33358,\"start\":33355},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":33363,\"start\":33360},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":33392,\"start\":33389},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":33481,\"start\":33477},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":33755,\"start\":33752},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":33966,\"start\":33963},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":33978,\"start\":33974},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":33990,\"start\":33986},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":34002,\"start\":33998},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":34272,\"start\":34268},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":34774,\"start\":34770},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":34920,\"start\":34916},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":34926,\"start\":34922},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":35065,\"start\":35061},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":35151,\"start\":35147},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":35246,\"start\":35242},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":35580,\"start\":35576},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":35586,\"start\":35582},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":35592,\"start\":35588}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":36487,\"start\":36453},{\"attributes\":{\"id\":\"fig_1\"},\"end\":36543,\"start\":36488},{\"attributes\":{\"id\":\"fig_2\"},\"end\":36592,\"start\":36544},{\"attributes\":{\"id\":\"fig_3\"},\"end\":36670,\"start\":36593},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":37052,\"start\":36671},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":37183,\"start\":37053},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":37506,\"start\":37184},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":37904,\"start\":37507},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":37971,\"start\":37905},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":38378,\"start\":37972}]", "paragraph": "[{\"end\":3026,\"start\":2024},{\"end\":3638,\"start\":3028},{\"end\":4339,\"start\":3640},{\"end\":5354,\"start\":4341},{\"end\":6705,\"start\":5356},{\"end\":7725,\"start\":6707},{\"end\":7783,\"start\":7727},{\"end\":8537,\"start\":7785},{\"end\":9698,\"start\":8569},{\"end\":10441,\"start\":9719},{\"end\":11017,\"start\":10471},{\"end\":12353,\"start\":11019},{\"end\":12947,\"start\":12399},{\"end\":13258,\"start\":12949},{\"end\":13429,\"start\":13302},{\"end\":14340,\"start\":13431},{\"end\":15018,\"start\":14382},{\"end\":15595,\"start\":15020},{\"end\":16334,\"start\":15597},{\"end\":16719,\"start\":16376},{\"end\":16929,\"start\":16721},{\"end\":17183,\"start\":16978},{\"end\":17537,\"start\":17232},{\"end\":18054,\"start\":17574},{\"end\":18827,\"start\":18056},{\"end\":19832,\"start\":18846},{\"end\":20197,\"start\":19851},{\"end\":20748,\"start\":20199},{\"end\":20985,\"start\":20797},{\"end\":21097,\"start\":21046},{\"end\":22464,\"start\":21157},{\"end\":23533,\"start\":22489},{\"end\":24833,\"start\":23535},{\"end\":25214,\"start\":24860},{\"end\":27429,\"start\":25216},{\"end\":29077,\"start\":27431},{\"end\":29685,\"start\":29144},{\"end\":31073,\"start\":29687},{\"end\":32057,\"start\":31075},{\"end\":33073,\"start\":32059},{\"end\":33674,\"start\":33093},{\"end\":34641,\"start\":33676},{\"end\":35593,\"start\":34643},{\"end\":36452,\"start\":35612}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":16977,\"start\":16930},{\"attributes\":{\"id\":\"formula_1\"},\"end\":17231,\"start\":17184},{\"attributes\":{\"id\":\"formula_2\"},\"end\":21045,\"start\":20986},{\"attributes\":{\"id\":\"formula_3\"},\"end\":21129,\"start\":21098},{\"attributes\":{\"id\":\"formula_4\"},\"end\":21156,\"start\":21129}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":18955,\"start\":18948},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":22025,\"start\":22017},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":23088,\"start\":23081},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":23129,\"start\":23120},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":25027,\"start\":25007},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":26991,\"start\":26830},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":27319,\"start\":27312},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":27428,\"start\":27421},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":31619,\"start\":31611}]", "section_header": "[{\"end\":2022,\"start\":2007},{\"end\":8567,\"start\":8540},{\"end\":9717,\"start\":9701},{\"end\":10469,\"start\":10444},{\"end\":12397,\"start\":12356},{\"end\":13300,\"start\":13261},{\"end\":14380,\"start\":14343},{\"end\":16374,\"start\":16337},{\"end\":17572,\"start\":17540},{\"end\":18844,\"start\":18830},{\"end\":19849,\"start\":19835},{\"end\":20795,\"start\":20751},{\"end\":22487,\"start\":22467},{\"end\":24858,\"start\":24836},{\"end\":29142,\"start\":29080},{\"end\":33091,\"start\":33076},{\"end\":35610,\"start\":35596},{\"end\":36462,\"start\":36454},{\"end\":36497,\"start\":36489},{\"end\":36553,\"start\":36545},{\"end\":36602,\"start\":36594},{\"end\":36681,\"start\":36672},{\"end\":37064,\"start\":37054},{\"end\":37196,\"start\":37185},{\"end\":37518,\"start\":37508},{\"end\":37915,\"start\":37906},{\"end\":37983,\"start\":37973}]", "table": "[{\"end\":37052,\"start\":36707},{\"end\":37183,\"start\":37093},{\"end\":37506,\"start\":37239},{\"end\":37904,\"start\":37562},{\"end\":38378,\"start\":38062}]", "figure_caption": "[{\"end\":36487,\"start\":36464},{\"end\":36543,\"start\":36499},{\"end\":36592,\"start\":36555},{\"end\":36670,\"start\":36604},{\"end\":36707,\"start\":36683},{\"end\":37093,\"start\":37067},{\"end\":37239,\"start\":37200},{\"end\":37562,\"start\":37521},{\"end\":37971,\"start\":37917},{\"end\":38062,\"start\":37986}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":8680,\"start\":8672},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":8816,\"start\":8808},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":9155,\"start\":9147},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":11060,\"start\":11052},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":11890,\"start\":11882},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":12313,\"start\":12305},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":12914,\"start\":12906},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":13935,\"start\":13927},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":15347,\"start\":15339},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":16610,\"start\":16602},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":18587,\"start\":18579},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":18717,\"start\":18709},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":27481,\"start\":27473}]", "bib_author_first_name": "[{\"end\":38676,\"start\":38675},{\"end\":38684,\"start\":38683},{\"end\":38692,\"start\":38691},{\"end\":38699,\"start\":38698},{\"end\":38708,\"start\":38707},{\"end\":38715,\"start\":38714},{\"end\":38721,\"start\":38720},{\"end\":38730,\"start\":38729},{\"end\":39061,\"start\":39060},{\"end\":39067,\"start\":39066},{\"end\":39076,\"start\":39075},{\"end\":39083,\"start\":39082},{\"end\":39096,\"start\":39095},{\"end\":39459,\"start\":39458},{\"end\":39465,\"start\":39464},{\"end\":39472,\"start\":39471},{\"end\":39480,\"start\":39479},{\"end\":39804,\"start\":39803},{\"end\":39806,\"start\":39805},{\"end\":39814,\"start\":39813},{\"end\":39824,\"start\":39823},{\"end\":39834,\"start\":39833},{\"end\":39840,\"start\":39839},{\"end\":40138,\"start\":40137},{\"end\":40140,\"start\":40139},{\"end\":40147,\"start\":40146},{\"end\":40154,\"start\":40153},{\"end\":40449,\"start\":40448},{\"end\":40456,\"start\":40455},{\"end\":40462,\"start\":40461},{\"end\":40464,\"start\":40463},{\"end\":40476,\"start\":40475},{\"end\":40485,\"start\":40484},{\"end\":40487,\"start\":40486},{\"end\":40494,\"start\":40493},{\"end\":40496,\"start\":40495},{\"end\":40905,\"start\":40904},{\"end\":40907,\"start\":40906},{\"end\":40916,\"start\":40915},{\"end\":41182,\"start\":41181},{\"end\":41184,\"start\":41183},{\"end\":41203,\"start\":41202},{\"end\":41217,\"start\":41216},{\"end\":41231,\"start\":41230},{\"end\":41635,\"start\":41634},{\"end\":41641,\"start\":41640},{\"end\":41647,\"start\":41646},{\"end\":41655,\"start\":41654},{\"end\":41657,\"start\":41656},{\"end\":42061,\"start\":42060},{\"end\":42070,\"start\":42069},{\"end\":42083,\"start\":42082},{\"end\":42094,\"start\":42093},{\"end\":42297,\"start\":42296},{\"end\":42501,\"start\":42500},{\"end\":42507,\"start\":42506},{\"end\":42515,\"start\":42514},{\"end\":42523,\"start\":42522},{\"end\":42525,\"start\":42524},{\"end\":42532,\"start\":42531},{\"end\":42889,\"start\":42888},{\"end\":43148,\"start\":43147},{\"end\":43159,\"start\":43158},{\"end\":43177,\"start\":43176},{\"end\":43495,\"start\":43494},{\"end\":43501,\"start\":43500},{\"end\":43758,\"start\":43757},{\"end\":44153,\"start\":44152},{\"end\":44159,\"start\":44158},{\"end\":44166,\"start\":44165},{\"end\":44172,\"start\":44171},{\"end\":44178,\"start\":44177},{\"end\":44180,\"start\":44179},{\"end\":44566,\"start\":44565},{\"end\":44576,\"start\":44575},{\"end\":44763,\"start\":44762},{\"end\":44769,\"start\":44764},{\"end\":44958,\"start\":44957},{\"end\":44969,\"start\":44968},{\"end\":44981,\"start\":44980},{\"end\":45345,\"start\":45344},{\"end\":45353,\"start\":45352},{\"end\":45359,\"start\":45358},{\"end\":45696,\"start\":45695},{\"end\":45706,\"start\":45705},{\"end\":45906,\"start\":45905},{\"end\":45915,\"start\":45914},{\"end\":45926,\"start\":45925},{\"end\":45928,\"start\":45927},{\"end\":45935,\"start\":45934},{\"end\":45944,\"start\":45943},{\"end\":45955,\"start\":45954},{\"end\":46380,\"start\":46379},{\"end\":46388,\"start\":46387},{\"end\":46397,\"start\":46396},{\"end\":46409,\"start\":46408},{\"end\":46798,\"start\":46797},{\"end\":46800,\"start\":46799},{\"end\":46809,\"start\":46808},{\"end\":46811,\"start\":46810},{\"end\":46819,\"start\":46818},{\"end\":46821,\"start\":46820},{\"end\":47182,\"start\":47181},{\"end\":47190,\"start\":47189},{\"end\":47198,\"start\":47197},{\"end\":47207,\"start\":47206},{\"end\":47213,\"start\":47212},{\"end\":47221,\"start\":47220},{\"end\":47228,\"start\":47227},{\"end\":47236,\"start\":47235},{\"end\":47608,\"start\":47607},{\"end\":47617,\"start\":47616},{\"end\":47629,\"start\":47628},{\"end\":47960,\"start\":47959},{\"end\":47967,\"start\":47966},{\"end\":47975,\"start\":47974},{\"end\":47983,\"start\":47982},{\"end\":47991,\"start\":47990},{\"end\":48330,\"start\":48329},{\"end\":48338,\"start\":48337},{\"end\":48345,\"start\":48344},{\"end\":48355,\"start\":48354},{\"end\":48670,\"start\":48669},{\"end\":48678,\"start\":48677},{\"end\":49062,\"start\":49061},{\"end\":49071,\"start\":49070},{\"end\":49083,\"start\":49082},{\"end\":49095,\"start\":49094},{\"end\":49104,\"start\":49103},{\"end\":49112,\"start\":49111},{\"end\":49121,\"start\":49120},{\"end\":49132,\"start\":49131},{\"end\":49143,\"start\":49142},{\"end\":49150,\"start\":49149},{\"end\":49159,\"start\":49158},{\"end\":49172,\"start\":49171},{\"end\":49179,\"start\":49178},{\"end\":49673,\"start\":49672},{\"end\":49681,\"start\":49680},{\"end\":49687,\"start\":49686},{\"end\":49695,\"start\":49694},{\"end\":49702,\"start\":49701},{\"end\":49704,\"start\":49703},{\"end\":49716,\"start\":49715}]", "bib_author_last_name": "[{\"end\":38681,\"start\":38677},{\"end\":38689,\"start\":38685},{\"end\":38696,\"start\":38693},{\"end\":38705,\"start\":38700},{\"end\":38712,\"start\":38709},{\"end\":38718,\"start\":38716},{\"end\":38727,\"start\":38722},{\"end\":38734,\"start\":38731},{\"end\":39064,\"start\":39062},{\"end\":39073,\"start\":39068},{\"end\":39080,\"start\":39077},{\"end\":39093,\"start\":39084},{\"end\":39103,\"start\":39097},{\"end\":39462,\"start\":39460},{\"end\":39469,\"start\":39466},{\"end\":39477,\"start\":39473},{\"end\":39483,\"start\":39481},{\"end\":39811,\"start\":39807},{\"end\":39821,\"start\":39815},{\"end\":39831,\"start\":39825},{\"end\":39837,\"start\":39835},{\"end\":39854,\"start\":39841},{\"end\":40144,\"start\":40141},{\"end\":40151,\"start\":40148},{\"end\":40158,\"start\":40155},{\"end\":40453,\"start\":40450},{\"end\":40459,\"start\":40457},{\"end\":40473,\"start\":40465},{\"end\":40482,\"start\":40477},{\"end\":40491,\"start\":40488},{\"end\":40502,\"start\":40497},{\"end\":40913,\"start\":40908},{\"end\":40922,\"start\":40917},{\"end\":41200,\"start\":41185},{\"end\":41214,\"start\":41204},{\"end\":41228,\"start\":41218},{\"end\":41238,\"start\":41232},{\"end\":41638,\"start\":41636},{\"end\":41644,\"start\":41642},{\"end\":41652,\"start\":41648},{\"end\":41661,\"start\":41658},{\"end\":42067,\"start\":42062},{\"end\":42080,\"start\":42071},{\"end\":42091,\"start\":42084},{\"end\":42101,\"start\":42095},{\"end\":42302,\"start\":42298},{\"end\":42504,\"start\":42502},{\"end\":42512,\"start\":42508},{\"end\":42520,\"start\":42516},{\"end\":42529,\"start\":42526},{\"end\":42536,\"start\":42533},{\"end\":42892,\"start\":42890},{\"end\":43156,\"start\":43149},{\"end\":43174,\"start\":43160},{\"end\":43184,\"start\":43178},{\"end\":43498,\"start\":43496},{\"end\":43504,\"start\":43502},{\"end\":43767,\"start\":43759},{\"end\":44156,\"start\":44154},{\"end\":44163,\"start\":44160},{\"end\":44169,\"start\":44167},{\"end\":44175,\"start\":44173},{\"end\":44184,\"start\":44181},{\"end\":44573,\"start\":44567},{\"end\":44585,\"start\":44577},{\"end\":44773,\"start\":44770},{\"end\":44966,\"start\":44959},{\"end\":44978,\"start\":44970},{\"end\":44989,\"start\":44982},{\"end\":45350,\"start\":45346},{\"end\":45356,\"start\":45354},{\"end\":45365,\"start\":45360},{\"end\":45703,\"start\":45697},{\"end\":45714,\"start\":45707},{\"end\":45912,\"start\":45907},{\"end\":45923,\"start\":45916},{\"end\":45932,\"start\":45929},{\"end\":45941,\"start\":45936},{\"end\":45952,\"start\":45945},{\"end\":45960,\"start\":45956},{\"end\":46385,\"start\":46381},{\"end\":46394,\"start\":46389},{\"end\":46406,\"start\":46398},{\"end\":46417,\"start\":46410},{\"end\":46806,\"start\":46801},{\"end\":46816,\"start\":46812},{\"end\":46825,\"start\":46822},{\"end\":47187,\"start\":47183},{\"end\":47195,\"start\":47191},{\"end\":47204,\"start\":47199},{\"end\":47210,\"start\":47208},{\"end\":47218,\"start\":47214},{\"end\":47225,\"start\":47222},{\"end\":47233,\"start\":47229},{\"end\":47240,\"start\":47237},{\"end\":47614,\"start\":47609},{\"end\":47626,\"start\":47618},{\"end\":47636,\"start\":47630},{\"end\":47964,\"start\":47961},{\"end\":47972,\"start\":47968},{\"end\":47980,\"start\":47976},{\"end\":47988,\"start\":47984},{\"end\":47995,\"start\":47992},{\"end\":48335,\"start\":48331},{\"end\":48342,\"start\":48339},{\"end\":48352,\"start\":48346},{\"end\":48359,\"start\":48356},{\"end\":48675,\"start\":48671},{\"end\":48685,\"start\":48679},{\"end\":49068,\"start\":49063},{\"end\":49080,\"start\":49072},{\"end\":49092,\"start\":49084},{\"end\":49101,\"start\":49096},{\"end\":49109,\"start\":49105},{\"end\":49118,\"start\":49113},{\"end\":49129,\"start\":49122},{\"end\":49140,\"start\":49133},{\"end\":49147,\"start\":49144},{\"end\":49156,\"start\":49151},{\"end\":49169,\"start\":49160},{\"end\":49176,\"start\":49173},{\"end\":49184,\"start\":49180},{\"end\":49678,\"start\":49674},{\"end\":49684,\"start\":49682},{\"end\":49692,\"start\":49688},{\"end\":49699,\"start\":49696},{\"end\":49713,\"start\":49705},{\"end\":49719,\"start\":49717}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":38609,\"start\":38534},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":12573648},\"end\":38997,\"start\":38611},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":2239051},\"end\":39370,\"start\":38999},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":16707374},\"end\":39734,\"start\":39372},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":3329645},\"end\":40075,\"start\":39736},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":7290743},\"end\":40380,\"start\":40077},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":17534058},\"end\":40822,\"start\":40382},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":8643838},\"end\":41112,\"start\":40824},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":11893284},\"end\":41540,\"start\":41114},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":28562962},\"end\":42008,\"start\":41542},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":11853108},\"end\":42283,\"start\":42010},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":56594823},\"end\":42392,\"start\":42285},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":1027883},\"end\":42837,\"start\":42394},{\"attributes\":{\"id\":\"b13\"},\"end\":43065,\"start\":42839},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":7683158},\"end\":43445,\"start\":43067},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":206784678},\"end\":43714,\"start\":43447},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":16655537},\"end\":43981,\"start\":43716},{\"attributes\":{\"id\":\"b17\"},\"end\":44088,\"start\":43983},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":9995103},\"end\":44346,\"start\":44090},{\"attributes\":{\"id\":\"b19\"},\"end\":44509,\"start\":44348},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":7146384},\"end\":44694,\"start\":44511},{\"attributes\":{\"id\":\"b21\"},\"end\":44916,\"start\":44696},{\"attributes\":{\"id\":\"b22\"},\"end\":45130,\"start\":44918},{\"attributes\":{\"id\":\"b23\"},\"end\":45286,\"start\":45132},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":207191250},\"end\":45639,\"start\":45288},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":7725217},\"end\":45844,\"start\":45641},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":9396039},\"end\":46292,\"start\":45846},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":2502573},\"end\":46723,\"start\":46294},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":15794450},\"end\":47100,\"start\":46725},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":10082157},\"end\":47555,\"start\":47102},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":14268605},\"end\":47891,\"start\":47557},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":7471781},\"end\":48271,\"start\":47893},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":15475945},\"end\":48575,\"start\":48273},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":8416932},\"end\":48956,\"start\":48577},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":14676530},\"end\":49589,\"start\":48958},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":8201466},\"end\":50029,\"start\":49591}]", "bib_title": "[{\"end\":38673,\"start\":38611},{\"end\":39058,\"start\":38999},{\"end\":39456,\"start\":39372},{\"end\":39801,\"start\":39736},{\"end\":40135,\"start\":40077},{\"end\":40446,\"start\":40382},{\"end\":40902,\"start\":40824},{\"end\":41179,\"start\":41114},{\"end\":41632,\"start\":41542},{\"end\":42058,\"start\":42010},{\"end\":42294,\"start\":42285},{\"end\":42498,\"start\":42394},{\"end\":43145,\"start\":43067},{\"end\":43492,\"start\":43447},{\"end\":43755,\"start\":43716},{\"end\":44150,\"start\":44090},{\"end\":44563,\"start\":44511},{\"end\":45342,\"start\":45288},{\"end\":45693,\"start\":45641},{\"end\":45903,\"start\":45846},{\"end\":46377,\"start\":46294},{\"end\":46795,\"start\":46725},{\"end\":47179,\"start\":47102},{\"end\":47605,\"start\":47557},{\"end\":47957,\"start\":47893},{\"end\":48327,\"start\":48273},{\"end\":48667,\"start\":48577},{\"end\":49059,\"start\":48958},{\"end\":49670,\"start\":49591}]", "bib_author": "[{\"end\":38683,\"start\":38675},{\"end\":38691,\"start\":38683},{\"end\":38698,\"start\":38691},{\"end\":38707,\"start\":38698},{\"end\":38714,\"start\":38707},{\"end\":38720,\"start\":38714},{\"end\":38729,\"start\":38720},{\"end\":38736,\"start\":38729},{\"end\":39066,\"start\":39060},{\"end\":39075,\"start\":39066},{\"end\":39082,\"start\":39075},{\"end\":39095,\"start\":39082},{\"end\":39105,\"start\":39095},{\"end\":39464,\"start\":39458},{\"end\":39471,\"start\":39464},{\"end\":39479,\"start\":39471},{\"end\":39485,\"start\":39479},{\"end\":39813,\"start\":39803},{\"end\":39823,\"start\":39813},{\"end\":39833,\"start\":39823},{\"end\":39839,\"start\":39833},{\"end\":39856,\"start\":39839},{\"end\":40146,\"start\":40137},{\"end\":40153,\"start\":40146},{\"end\":40160,\"start\":40153},{\"end\":40455,\"start\":40448},{\"end\":40461,\"start\":40455},{\"end\":40475,\"start\":40461},{\"end\":40484,\"start\":40475},{\"end\":40493,\"start\":40484},{\"end\":40504,\"start\":40493},{\"end\":40915,\"start\":40904},{\"end\":40924,\"start\":40915},{\"end\":41202,\"start\":41181},{\"end\":41216,\"start\":41202},{\"end\":41230,\"start\":41216},{\"end\":41240,\"start\":41230},{\"end\":41640,\"start\":41634},{\"end\":41646,\"start\":41640},{\"end\":41654,\"start\":41646},{\"end\":41663,\"start\":41654},{\"end\":42069,\"start\":42060},{\"end\":42082,\"start\":42069},{\"end\":42093,\"start\":42082},{\"end\":42103,\"start\":42093},{\"end\":42304,\"start\":42296},{\"end\":42506,\"start\":42500},{\"end\":42514,\"start\":42506},{\"end\":42522,\"start\":42514},{\"end\":42531,\"start\":42522},{\"end\":42538,\"start\":42531},{\"end\":42894,\"start\":42888},{\"end\":43158,\"start\":43147},{\"end\":43176,\"start\":43158},{\"end\":43186,\"start\":43176},{\"end\":43500,\"start\":43494},{\"end\":43506,\"start\":43500},{\"end\":43769,\"start\":43757},{\"end\":44158,\"start\":44152},{\"end\":44165,\"start\":44158},{\"end\":44171,\"start\":44165},{\"end\":44177,\"start\":44171},{\"end\":44186,\"start\":44177},{\"end\":44575,\"start\":44565},{\"end\":44587,\"start\":44575},{\"end\":44775,\"start\":44762},{\"end\":44968,\"start\":44957},{\"end\":44980,\"start\":44968},{\"end\":44991,\"start\":44980},{\"end\":45352,\"start\":45344},{\"end\":45358,\"start\":45352},{\"end\":45367,\"start\":45358},{\"end\":45705,\"start\":45695},{\"end\":45716,\"start\":45705},{\"end\":45914,\"start\":45905},{\"end\":45925,\"start\":45914},{\"end\":45934,\"start\":45925},{\"end\":45943,\"start\":45934},{\"end\":45954,\"start\":45943},{\"end\":45962,\"start\":45954},{\"end\":46387,\"start\":46379},{\"end\":46396,\"start\":46387},{\"end\":46408,\"start\":46396},{\"end\":46419,\"start\":46408},{\"end\":46808,\"start\":46797},{\"end\":46818,\"start\":46808},{\"end\":46827,\"start\":46818},{\"end\":47189,\"start\":47181},{\"end\":47197,\"start\":47189},{\"end\":47206,\"start\":47197},{\"end\":47212,\"start\":47206},{\"end\":47220,\"start\":47212},{\"end\":47227,\"start\":47220},{\"end\":47235,\"start\":47227},{\"end\":47242,\"start\":47235},{\"end\":47616,\"start\":47607},{\"end\":47628,\"start\":47616},{\"end\":47638,\"start\":47628},{\"end\":47966,\"start\":47959},{\"end\":47974,\"start\":47966},{\"end\":47982,\"start\":47974},{\"end\":47990,\"start\":47982},{\"end\":47997,\"start\":47990},{\"end\":48337,\"start\":48329},{\"end\":48344,\"start\":48337},{\"end\":48354,\"start\":48344},{\"end\":48361,\"start\":48354},{\"end\":48677,\"start\":48669},{\"end\":48687,\"start\":48677},{\"end\":49070,\"start\":49061},{\"end\":49082,\"start\":49070},{\"end\":49094,\"start\":49082},{\"end\":49103,\"start\":49094},{\"end\":49111,\"start\":49103},{\"end\":49120,\"start\":49111},{\"end\":49131,\"start\":49120},{\"end\":49142,\"start\":49131},{\"end\":49149,\"start\":49142},{\"end\":49158,\"start\":49149},{\"end\":49171,\"start\":49158},{\"end\":49178,\"start\":49171},{\"end\":49186,\"start\":49178},{\"end\":49680,\"start\":49672},{\"end\":49686,\"start\":49680},{\"end\":49694,\"start\":49686},{\"end\":49701,\"start\":49694},{\"end\":49715,\"start\":49701},{\"end\":49721,\"start\":49715}]", "bib_venue": "[{\"end\":38544,\"start\":38534},{\"end\":38791,\"start\":38736},{\"end\":39172,\"start\":39105},{\"end\":39542,\"start\":39485},{\"end\":39895,\"start\":39856},{\"end\":40202,\"start\":40160},{\"end\":40582,\"start\":40504},{\"end\":40948,\"start\":40924},{\"end\":41300,\"start\":41240},{\"end\":41758,\"start\":41663},{\"end\":42130,\"start\":42103},{\"end\":42327,\"start\":42304},{\"end\":42591,\"start\":42538},{\"end\":42886,\"start\":42839},{\"end\":43246,\"start\":43186},{\"end\":43571,\"start\":43506},{\"end\":43841,\"start\":43769},{\"end\":44000,\"start\":43983},{\"end\":44206,\"start\":44186},{\"end\":44424,\"start\":44348},{\"end\":44593,\"start\":44587},{\"end\":44760,\"start\":44696},{\"end\":44955,\"start\":44918},{\"end\":45156,\"start\":45132},{\"end\":45453,\"start\":45367},{\"end\":45734,\"start\":45716},{\"end\":46050,\"start\":45962},{\"end\":46491,\"start\":46419},{\"end\":46894,\"start\":46827},{\"end\":47309,\"start\":47242},{\"end\":47706,\"start\":47638},{\"end\":48064,\"start\":47997},{\"end\":48400,\"start\":48361},{\"end\":48757,\"start\":48687},{\"end\":49258,\"start\":49186},{\"end\":49791,\"start\":49721}]"}}}, "year": 2023, "month": 12, "day": 17}