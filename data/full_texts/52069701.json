{"id": 52069701, "updated": "2023-10-03 05:21:21.136", "metadata": {"title": "Improving Automatic Source Code Summarization via Deep Reinforcement Learning", "authors": "[{\"first\":\"Yao\",\"last\":\"Wan\",\"middle\":[]},{\"first\":\"Zhou\",\"last\":\"Zhao\",\"middle\":[]},{\"first\":\"Min\",\"last\":\"Yang\",\"middle\":[]},{\"first\":\"Guandong\",\"last\":\"Xu\",\"middle\":[]},{\"first\":\"Haochao\",\"last\":\"Ying\",\"middle\":[]},{\"first\":\"Jian\",\"last\":\"Wu\",\"middle\":[]},{\"first\":\"Philip\",\"last\":\"Yu\",\"middle\":[\"S.\"]}]", "venue": null, "journal": "Proceedings of the 33rd ACM/IEEE International Conference on Automated Software Engineering", "publication_date": {"year": 2018, "month": 11, "day": 17}, "abstract": "Code summarization provides a high level natural language description of the function performed by code, as it can benefit the software maintenance, code categorization and retrieval. To the best of our knowledge, most state-of-the-art approaches follow an encoder-decoder framework which encodes the code into a hidden space and then decode it into natural language space, suffering from two major drawbacks: a) Their encoders only consider the sequential content of code, ignoring the tree structure which is also critical for the task of code summarization, b) Their decoders are typically trained to predict the next word by maximizing the likelihood of next ground-truth word with previous ground-truth word given. However, it is expected to generate the entire sequence from scratch at test time. This discrepancy can cause an \\textit{exposure bias} issue, making the learnt decoder suboptimal. In this paper, we incorporate an abstract syntax tree structure as well as sequential content of code snippets into a deep reinforcement learning framework (i.e., actor-critic network). The actor network provides the confidence of predicting the next word according to current state. On the other hand, the critic network evaluates the reward value of all possible extensions of the current state and can provide global guidance for explorations. We employ an advantage reward composed of BLEU metric to train both networks. Comprehensive experiments on a real-world dataset show the effectiveness of our proposed model when compared with some state-of-the-art methods.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "1811.07234", "mag": "2951883879", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/corr/abs-1811-07234", "doi": "10.1145/3238147.3238206"}}, "content": {"source": {"pdf_hash": "384d473b0e49bd6c7515764770e0196769f3bec9", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/1811.07234v1.pdf\"]", "oa_url_match": false, "oa_info": {"license": null, "open_access_url": "https://opus.lib.uts.edu.au/bitstream/10453/126042/4/OCC-121665_AM.pdf", "status": "GREEN"}}, "grobid": {"id": "f2fc43d63873002a677d851fbac98d8a53809723", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/384d473b0e49bd6c7515764770e0196769f3bec9.txt", "contents": "\nImproving Automatic Source Code Summarization via Deep Reinforcement Learning\n\n\nYao Wan \nCollege of Computer Science and Technology\nZhejiang University\nHangzhouChina\n\nZhou Zhao \nCollege of Computer Science and Technology\nZhejiang University\nHangzhouChina\n\nMin Yang min.yang@siat.ac.cn \nShenzhen Institutes of Advanced Technology\nChinese Academy of Sciences\nChina\n\nGuandong Xu guandong.xu@uts.edu.au \nAdvanced Analytics Institute\nUniversity of Technology Sydney\nSydneyAustralia\n\nHaochao Ying \nCollege of Computer Science and Technology\nZhejiang University\nHangzhouChina\n\nJian Wu \nCollege of Computer Science and Technology\nZhejiang University\nHangzhouChina\n\nPhilip S Yu psyu@uic.edu \nDepartment of Computer Science\nUniversity of Illinois at Chicago\nIllinoisUSA\n\nInstitute for Data Science\nTsinghua University\nBeijingChina\n\nImproving Automatic Source Code Summarization via Deep Reinforcement Learning\n\nCode summarization provides a high level natural language description of the function performed by code, as it can benefit the software maintenance, code categorization and retrieval. To the best of our knowledge, most state-of-the-art approaches follow an encoder-decoder framework which encodes the code into a hidden space and then decode it into natural language space, suffering from two major drawbacks: a) Their encoders only consider the sequential content of code, ignoring the tree structure which is also critical for the task of code summarization; b) Their decoders are typically trained to predict the next word by maximizing the likelihood of next groundtruth word with previous ground-truth word given. However, it is expected to generate the entire sequence from scratch at test time. This discrepancy can cause an exposure bias issue, making the learnt decoder suboptimal. In this paper, we incorporate an abstract syntax tree structure as well as sequential content of code snippets into a deep reinforcement learning framework (i.e., actor-critic network). The actor network provides the confidence of predicting the next word according to current state. On the other hand, the critic network evaluates the reward value of all possible extensions of the current state and can provide global guidance for explorations. We employ an advantage reward composed of BLEU metric to train both networks. Comprehensive experiments on a real-world dataset show the effectiveness of our proposed model when compared with some state-of-the-art methods.\n\nI. INTRODUCTION\n\nIn the life cycle of software development (e.g., implementation, testing and maintenance), nearly 90% of effort is used for maintenance, and much of this effort is spent on understanding the maintenance task and related software source codes [1]. Thus, documentation which provides a high level description of the task performed by code is always a must for software maintenance. Even though various techniques have been developed to facilitate the programmer during the implementation and testing of software, documenting code with comments remains a labour-intensive task, making few real-world software projects adequately document the code to reduce future maintenance costs [2], [3]. It's nontrivial for a novice programmer to write good comments for source codes. A good comment should at least has the following characteristics: a) Correctness. The comments should correctly clarify the intent of code. b) Fluency. The comments should be fluent natural languages that can be easily read and understood by maintainers. c) Consistency. The comments should follow a standard style/format for better code reading. Code summarization is a task that tries to comprehend code and automatically generate descriptions directly from the source code. The summarization of code can also be viewed as a form of document expansion. Successful code summarization can not only benefit the maintenance of source codes [4], [5], but also be used to improve the performance of code search using natural language queries [6], [7] and code categorization [8].\n\nMotivation. Recent research has made inroads towards automatic generation of natural language descriptions of software. As far as we know, most of existing code summarization methods learn the semantic representation of source codes based on statistical language models [9], [4], and then generate comments based on templates or rules [10]. With the development of deep learning, some neural translation models [11], [5], [12] have also been introduced for code summarization, which mainly follow an encoder-decoder framework. They generally employ recurrent neural networks (RNN e.g., LSTM [13]) to encode the code snippets and utilize another RNN to decode that hidden state to coherent sentences. These models are typically trained to maximize the likelihood of the next word on the assumption that previous words and ground-truth are given. These models are limited from two aspects: a) The code sequential and structural information is not fully utilized on feature representation, which is critical for code understanding. For example, given two simple expressions \"f=a+b\" and \"f=c+d\", although they are quite different as two lexical sequences, they share the same structure (e.g., abstractive syntax tree). b) These models, also termed \"teacher-forcing\", suffer from the exposure bias since in testing time the ground-truth is missing and previously generated words from the trained model distribution are used to predict the next word [14]. Figure 1(b) presents a simple illustration of the discrepancy among training and testing process in these classical encoder-decoder models. In the testing phase, this exposure bias makes error accumulated and makes these models suboptimal, not able to generate those words which are appropriate but with low probability to be drawn in the training phase.   Contribution. In this paper, we aim to address these two mentioned issues. To effectively capture the structural (or syntactic) information of code snippets, we employ abstract syntax tree (AST) [15], a data structure widely used in compilers, to represent the structure of program code. Figure 1a shows an example of Python code snippet and its corresponding AST. The root node is a composite node of type FunctionDef, while the leaf nodes which are typed as Name are tokens of code snippets. It's worth mentioning that the tokens from AST parsing may be different from those from word segmentation. In our paper, we consider both of them. We parse the code snippets into ASTs, and then propose an AST-based LSTM model [16] to represent the structure of code. We also use another LSTM model [13] to represent the sequential information of code. Besides, we apply a hybrid attention layer to fuse the structure representation and sequential representation of code on predicting the word, considering the alignment between predicted word and source word.\n\nTo overcome the exposure bias, we draw on the insights of deep reinforcement learning, which integrates exploration and exploitation into a whole framework. Instead of learning a sequential recurrent model to greedily look for the next correct word, we utilize an actor network and a critic network to jointly determine the next best word at each time step. The actor network, which provides the confidence of predicting the next word according to current state, serves as a local guidance. The critic network, which evaluates the reward value of all possible extensions of the current state, serves as a global guidance. Our framework is able to include the good words that are with low probability to be drawn by using the actor network alone. To learn these two networks more efficiently, we start with pretraining an actor network using standard supervised learning with cross entropy loss, and pretraining a critic network with mean square loss. Then, we update the actor and critic networks according to the advantage reward composed of BLEU metric via policy gradient. We summarize our main contributions as follows.\n\n\u2022 We propose a more comprehensive representation method for source code, with one AST-based LSTM for the structure of source code, and another LSTM for the sequential content of source code. Furthermore, a hybrid attention layer is applied to fuse these two representations.\n\n\u2022 To the best of our knowledge, it is the first time that we propose an advanced deep reinforcement learning framework, named actor-critic network, to cope with the exposure bias issue existing in most traditional maximum likelihood-based code summarization frameworks. \u2022 We validate our proposed model on a real-world dataset of 108,726 Python code snippets. Comprehensive experiments show the effectiveness of our proposed model when compared with some state-of-the-art methods. Organization. The remainder of this paper is organized as follows. We provide some background knowledge on neural language model, RNN encoder-decoder model and reinforcement learning in Section II for a better understanding of our proposed model. We also formally define the problem in Section II. Section III gives an overview of our proposed framework. Section IV presents a hybrid embedding approach for code representation. Section V shows our proposed deep reinforcement learning framework (i.e., actor-critic network). Section VI describes the dataset used in our experiment and shows the experimental results and analysis. Section VII shows some threats to validity and limitations existing in our model. Section VIII highlights some works related to this paper. Finally, we conclude this paper in Section IX.\n\n\nII. BACKGROUND\n\nAs we declared before, the code summarization task can be seen as a text generation task given the source code. In this section, we first present some background knowledge on text generation which will be used in this paper, including language model, attentional RNN encoder-decoder model and reinforcement learning for better decoding. To start with, we introduce some basic notations and terminologies. Let x = (x 1 , x 2 , . . . , x |x| ) denote a sequence of source code snippet, y = (y 1 , y 2 , . . . , y |y| ) denote a sequence of generated words, where | \u00b7 | denotes the length of sequence. Let T denote the maximum step of decoding in the encoder-decoder framework. We will often use notation y m...l to refer to subsequences of the form (y m , . . . , y l ). D = {(x 1 , y 1 ), (x 2 , y 2 ), . . . , (x N , y N )} is the training dataset, where N is the size of training set.\n\n\nA. Language Model\n\nLanguage model computes the probability of occurrence of a number of words in a particular sequence. The probability of a sequence of T words {y 1 , . . . , y T } is denoted as p(y 1 , . . . , y T ). Since the number of words coming before a word, y i , varies depending on its location in the input document, p(y 1 , . . . , y T ) is usually conditioned on a window of n previous words rather than all previous words:\np(y 1:T ) = i=T i=1 p(y i |y 1:i\u22121 ) \u2248 i=T i=1 p(y i |y i\u2212(n\u22121):i\u22121 ). (1)\nThis kind of n-grams approach suffers apparent limitations [17], [18]. For example, the n-gram model probabilities can not be derived directly from the frequency counts, because models derived this way have severe problems when confronted with some n-grams that have not been explicitly seen before. The neural language model is a language model based on neural networks. Unlike the n-gram model which predicts a word based on a fixed number of predecessor words, a neural language model can predict a word by predecessor words with longer distances. Figure 2(a) shows the basic structure of a RNN. The neural network includes three layers, that is, an input layer which maps each word to a vector, a recurrent hidden layer which recurrently computes and updates a hidden state after reading each word, and an output layer which estimates the probabilities of the following word given the current hidden state. The RNN reads the words in the sentence one by one, and predicts the possible following word at each time step. At step t, it estimates the probability of the following word p(y t+1 |y 1:t ) by the following steps: First, the current word y t is mapped to a vector by the input layer e. Then, it generates the hidden state h t at time t according to the previous hidden state h t\u22121 and the current input y t :\nh t = f (h t\u22121 , e(y t )).(2)\nHere, two common options for f are long short-term memory (LSTM) [13] and the gated recurrent unit (GRU) [19]. Finally, the p(y t+1 |y 1:t ) is predicted according to the current hidden state h t : p(y t+1 |y 1:\nt ) = g(h t ),(3)\nwhere g is a stochastic output layer (typically a softmax for discrete outputs) that generates output tokens.\n\n\nB. Attentional RNN Encoder-Decoder Model\n\nRNN encoder-decoder has two recurrent neural networks. The encoder transforms the code snippet x into a sequence of hidden states (h 1 , h 2 , . . . , h |x| ) with a RNN, while the decoder uses another RNN to generate one word y t+1 at a time in the target space. \n\n\n1) Encoder:\n\nAs a RNN, the encoder has a hidden state, which is a fixed-length vector. At the time step t, the encoder computes the hidden state h t by:\nh t = f (h t\u22121 , c t\u22121 , e(x t ))).(4)\nHere, f is the hidden layer which has two main options, i.e., LSTM and GRU. The last symbol of x should be an end-of-sequence (< eos >) symbol which notifies the encoder to stop and output the final hidden state h T , which is used as a vector representation of x.\n\n2) Decoder: The output of the decoder is the target sequence y = (y 1 , \u00b7 \u00b7 \u00b7 , y T ). One input of the decoder is a < start > symbol denoting the beginning of the target sequence. At the time step t, the decoder computes the hidden state h t and the conditional distribution of the next symbol y t+1 by:\np(y t+1 |y t ) = g(h t , c t ),(5)\nwhere g is a stochastic output layer and c t is the distinct context vector for y t , computed by:\nc t = |x| j=1 \u03b1 t,j h j ,(6)\nwhere \u03b1 t,j is the attention weight of y t on h j [20].\n\n3) Training Goal: The encoder and decoder networks are jointly trained to maximize the following objective:\nmax \u03b8 L(\u03b8) = max \u03b8 E (x,y)\u223cD log p(y|x; \u03b8),(7)\nwhere \u03b8 is the set of the model parameters. We can see that this classical encoder-decoder framework targets on maximizing the likelihood of ground-truth word conditioned on previously generated words. As we have mentioned above, the maximum likelihood based encoder-decoder framework suffers the exposure bias issue. Motivated by this, we introduce the reinforcement learning technique for better decoding. \n\n\nC. Reinforcement Learning for Better Decoding\n\nThe reinforcement learning is an approach that interacts with the real environment and learns the optimal policy from the reward signal. It tries to generate text from scratch without ground truth in the testing phase. Under this approach, the text generation process can be viewed as a Markov Decision Process (MDP) {S, A, P, R, \u03b3}. In the MDP setting, state s t at time step t consists of the source code snippets x and the words/actions predicted until t, y 0 , y 1 , . . . , y t . The action space is the dictionary Y that the words are drawn from, i.e., y t \u2282 Y. With the definition of the state, the state transition function P is s t+1 = {s t , y t+1 }, where the action y t+1 becomes a part of the next state s t+1 and the reward r t+1 is received. \u03b3 \u2208 [0, 1] is the discount factor. The objective of generation process is to find a policy that maximizes the expected reward of generation sentence sampled from the model's policy:\nmax \u03b8 L(\u03b8) = max \u03b8 E x\u223cD y\u223cP \u03b8 (\u00b7|x) [R(\u0177, x)],(8)\nwhere \u03b8 is the parameter of policy needed to be learnt, D is the training set,\u0177 is the predicted actions/words, and R is the reward function. Our problem can be formulated as follows.\n\nGiven a code snippet x = (x 1 , x 2 , . . . , x |x| ), our goal is to find a policy that generates a sequence of words y = (y 1 , y 2 , . . . , y |y| ) from dictionary Y with the objective of maximizing the expected reward.\n\nTo learn the policy, many approaches have been proposed, which are mainly categorized into two classes [21]. a) The policy-based approaches (e.g., REINFORCE [22]) which optimizes the policy directly via policy gradient. b) The valuebased approaches (e.g., Q-learning [23]) which learns the Qfunction, and in each time the agent selects the action with highest Q-value. It has been verified that the policy-based methods may suffer from a variance issue and the value-based methods may suffer from a bias issue [24]. Thus in our paper, we adopt the actor-critic learning method which is a more advanced technique that has the advantage of both policy-and value-based methods.\n\n\nIII. OVERVIEW OF PROPOSED FRAMEWORK\n\nIn this section, we firstly have a simple overview on the workflow of how to get a trained model for code summarization. Then we present an overview of the network architecture of our proposed deep reinforcement learning based model. Figure  3 shows the overall workflow of how to get a trained model. It includes an offline training stage and an online summarization stage. In the training stage, we prepare a large-scale corpus of annotated < code, comment > pairs. The annotated pairs are then fed into our proposed deep reinforcement learning model for training. After training, we can get a trained actor network. Then, given a code snippet, corresponding comment can be generated by the trained actor network. Figure 4 is an overview of the network architecture of our proposed deep reinforcement learning based model. The architecture of our model follows the actor-critic framework [25], which has been successfully adopted in the decisionmaking scenarios such as AlphaGo [26]. We split the framework into four submodules. (a) Hybrid code representation (cf. Sec. IV). This module is used to represent the source code into a hidden space, which is also called encoder in the encoderdecoder framework. (b) Hybrid attention (cf. Sec. V-A1). On decoding the encoded hidden space into the comment space, the attention layer is used to assign different weights to the code snippet tokens for better generation. (c) Text generation (cf. Sec. V-A2). This module is a RNN-based generative network, which is used to generate the next word based on previous generated words. (d) Critic (cf. Sec. V-B). This module is used to evaluate whether the generated word is good or not.\n\nSince the generated tokens on (d) can also been seen as actions, we can also called the process (a)-(b)-(c) as actor network. Compared with the architecture of traditional encoderdecoder framework, our proposed model has an additional critic module used to evaluate the value of action taken under current state. The process (a)-(b)-(c)-(d) can also be called as critic network. We can see that the actor and critic networks share the modules (a)-(b)-(c), reducing the number of learning parameters a lot. We will elaborate each component in this framework in the following sections.\n\n\nIV. HYBRID REPRESENTATION OF CODE\n\nDifferent from previous methods that just utilize sequential tokens to represent code, we also consider the structure information of source code. In this section, we present a hybrid embedding approach for code representation. We apply an LSTM to represent the lexical level of code, and an AST-based LSTM to represent the syntactic level of code.\n\n\nA. Lexical Level\n\nThe key insight into lexical level representation of source code is that comments are always extracted from the lexical of code, such as the function name, variable name and so on. It's apparent that we apply an RNN (e.g., LSTM) to represent the sequential information of source code. In our paper, the LSTM is adopted.\n\n\nB. Syntactic Level\n\nIn executing a program, a compiler decomposes a program into constituents and produces intermediate code according to the syntax of the language. AST is one type of intermediate \nh txt 1 h txt 2 h txt n \u21b5 txt i d txt j g s t+1 f s T . . . y t y t+1 y T MLP V \u21e1 V \u21e1 (c) Text generation (d) Critic\nNotes: code that represents the hierarchical syntactic structure of a program [27]. We represent the syntactic level of source code from the aspect of AST embedding. Similar to a traditional LSTM unit, we propose AST-based LSTM where the LSTM unit also contains an input gate, a memory cell and an output gate. Different from a standard LSTM unit which only has one forget gate for its previous unit, an AST-based LSTM unit contains multiple forget gates. Given an AST, for any node j, let the hidden state and memory cell of its l-th child be h jl and c jl respectively. Refer to [16], the hidden state is updated as follows:\nActor network: (a)-(b)-(c) Critic network: (a)-(b)-(c)-(d)i j = \u03c3(W (i) x j + N l=1 U (i) l h jl + b (i) ), f jk = \u03c3(W (f ) x j + N l=1 U (f ) kl h jl + b (f ) ), o j = \u03c3(W (o) x j + N l=1 U (o) l h jl + b (o) ), u j = tanh(W (u) x j + N l=1 U (u) l h jl + b (u) ), c j = i j u j + N l=1 f jl c jl , h j = o j tanh(c j ),(9)\nwhere k = 1, 2, \u00b7 \u00b7 \u00b7 , N . Each of i j , f jk , o j and u j denotes an input gate, a forget gate, an output gate, and a state for updating the memory cell, respectively. W (\u00b7) and U (\u00b7) are weight matrices, b (\u00b7) is a bias vector, and x j is the word embedding of the j-th node. \u03c3(\u00b7) is the logistic function, and the operator denotes element-wise multiplication between vectors. It's worth mentioning that when the tree is simply a chain, namely N = 1, the AST-based LSTM unit reduces to the standard LSTM. Figure 2 shows the structure of RNN and Tree-RNN.\n\nNotice that the number of children N varies for different nodes of different ASTs, which may cause problem in parameter-sharing. For simplification, we transform the generated ASTs to binary trees by the following two steps which have been adopted in [28]: a) Split nodes with more than 2 children, generate a new right child together with the old left child as its children, and then put all children except the leftmost as the children of this new node. Repeat this operation in a top-down way until only nodes with 0, 1, 2 children left; b) Combine nodes with 1 child with its child.\n\n\nV. DEEP REINFORCEMENT LEARNING FOR CODE SUMMARIZATION\n\nIn this section, we introduce the advanced deep learning framework named actor-critic network, which has been successfully used in the AlphaGo [26]. We introduce the actor and critic network respectively and then present how to train them simultaneously.\n\n\nA. Actor Network\n\nAfter obtaining the representation of code snippet, we need to decode it into comment. Here we describe how we generate comment from the hidden space with a hybrid attention layer.\n\n1) Hybrid Attention: Different parts of the code make different contributions to the final output of comment. We adopt an attention mechanism [20] which has been successfully used in neural machine translation. In the attention layer, we have two attention scores, one \u03b1 str t (j) for structural representation and another \u03b1 txt t (j) for sequential representation of code. At t-th step of the decoding process, the attention scores \u03b1 str t (j) and \u03b1 txt t (j) are calculated as follows: \n\u03b1 str t (j) = exp(h str j \u00b7 s t ) n k=1 exp(h str k \u00b7 s t ) , \u03b1 txt t (j) = exp(h txt j \u00b7 s t ) n k=1 exp(h txt k \u00b7 s t ) ,(10)d str t = n t=1 \u03b1 str t (j)h str j , d txt t = n t=1 \u03b1 txt t (j)h txt j .(11)\nTo integrate the structural context vector and the textual vector, we concatenate them firstly and then feed them into an one-layer linear network:\nd t = W dt [d str t ; d txt t ] + b dt ),(12)\nwhere [d str t ; d txt t ] is the concatenation of d str t and d txt t . The context vector is then used for the (t + 1)-th word prediction by putting an additional hidden layer s t :\ns t = tanh(W c [s t ; d t ] + b d ),(13)\nwhere [s t ; d t ] is the concatenation of s t and d t .\n\n2) Text Generation: The model predicts the t-th word by using a softmax function. Let p \u03c0 denote a policy \u03c0 determined by the actor network, p \u03c0 (y t |s t ) denote the probability distribution of generating t-th word y t , we can get the following equation:\np \u03c0 (y t |s t ) = sof tmax(W s s t + b s ).(14)\n\nB. Critic Network\n\nUnlike traditional encoder-decoder framework that generates sequence directly via maximizing likelihood of next word given the ground truth word, we directly optimize the evaluation metrics such as BLEU [29] for code summarization. We apply a critic network to approximate the value of generated action at time step t. Different from the actor network, this critic network outputs a single value instead of a probability distribution on each decoding step. Before introducing critic network, we introduce the value function.\n\nGiven the policy \u03c0, sampled actions and reward function, the value function V \u03c0 is defined as the prediction of total reward from the state s t at step t under policy \u03c0, which is formulated as follows:\n\nV \u03c0 (s t ) = Es t+1:T ,\ny t:T T \u2212t l=0 r t+l |y t+1 , \u00b7 \u00b7 \u00b7 , y T , h ,(15)\nwhere T is the max step of decoding; h is the representation of code snippet. For code summarization, we can only obtain an evaluation score (BLEU) when the sequence generation process (or episode) is finished. The episode terminates when step exceeds the max-step T or generating the end-of-sequence (EOS) token. Therefore, we define the reward as follows:\nr t = 0 t < T BLEU t = T or EOS .(16)\nMathematically, the critic network tries to minimize the following loss function, where mean square error is used.\nL(\u03c6) = 1 2 V \u03c0 (s t ) \u2212 V \u03c0 \u03c6 (s t ) 2 ,(17)\nwhere V \u03c0 (s t ) is the target value, V \u03c0 \u03c6 (s t ) is the value predicted by critic network and \u03c6 is the parameter of critic network.\n\n\nC. Model Training\n\nWe use the policy gradient method to optimize policy directly, which is widely used in reinforcement learning. For actor network, the goal of training is to minimize the negative expected reward, which can be defined as L(\u03b8) = \u2212E y 1,...,T \u223c\u03c0 ( T l=t r t ), where \u03b8 is the parameter of actor network. Denote all the parameters as \u0398 = {\u03b8, \u03c6}, the total loss of our model can be represented as L(\u0398) = L(\u03b8) + L(\u03c6).\n\nFor policy gradient, it is typically better to train an expression of the following form according to [30]:\n\u2207 \u03b8 L(\u0398) = E[ T \u22121 t=0\nA \u03c0 (s t , y t+1 )\u2207 \u03b8 log \u03c0 \u03b8 (y t+1 |s t )], (18) where A \u03c0 (s t , y t+1 ) is advantage function. The reason why we choose advantage function is that it achieves smaller variance when compared with some other ones such as TD residual and reward with baseline [30].\n\nAccording to the definition of advantage function, we can formulate the advantage function as follows. One can refer to [30] for more details.\nA \u03c0 (s t , y t ) = Q \u03c0 (s t , y t ) \u2212 V \u03c0 (s t ),(19)\nwhere Q \u03c0 (s t , y t ) is the state-action value function which is defined as Q \u03c0 (s t , y t ) = Es t+1:T , y t+1:T T \u2212t l=0 r t+l . From this formulation, we can find that the advantage function measures whether or not the action is better or worse than the policy's default behavior. Therefore, a step in the policy gradient direction can increase the probability of better-than-average actions and decrease the probability of worse-than-average actions.\n\nOn the other hand, the gradient of critic network is calculated as follows:\n\u2207 \u03c6 L(\u0398) = T \u22121 t=0 [V \u03c0 (s t ) \u2212 V \u03c0 \u03c6 (s t )]\u2207 \u03c6 V \u03c0 \u03c6 (s t ).(20)\nWe employ stochastic gradient descend with the diagonal variant of AdaGrad [31] to optimize the parameters of our framework. Algorithm 1 summarizes our proposed model described above.\n\n\nVI. EXPERIMENTS AND ANALYSIS\n\nTo evaluate our proposed approach, in this section, we conduct experiments to answer the following questions: 1: Initialize actor \u03c0 y t+1|s t and critic V \u03c0 (s t ) with random weights \u03b8 and \u03c6; 2: Pre-train the actor to predict ground truth y t given {y 1 , \u00b7 \u00b7 \u00b7 , y t\u22121 } by minimizing Eq. 7; 3: Pre-train the critic to estimate V (s t ) with fixed actor; 4: for t = 1 \u2192 T do 5:\n\nReceive a random example, and generate sequence of actions {y 1 , \u00b7 \u00b7 \u00b7 , y T } according to current policy \u03c0 \u03b8 ; 6: Calculate advantage estimate A \u03c0 according to Eq. 19; 7: Update critic weights \u03c6 using the gradient in Eq. 20; 8: Update actor weights \u03b8 using the gradient in Eq. 18.\n\n\u2022 RQ3. What's the performance of our proposed model on the datasets with different code or comment length? We ask RQ1 to evaluate our deep reinforcement learningbased model compared to some state-of-the-art baselines. We ask RQ2 in order to evaluate each component of our model. We ask RQ3 to evaluate our model when varying the length of code or comment. In the following subsections, we first describe the dataset, some evaluation metrics and the training details. Then, we introduce some baselines for RQ1. Finally, we report our results and analysis for the research questions.\n\n\nA. Dataset Preparation\n\nWe evaluate the performance of our proposed method using the dataset in [32], which is obtained from a popular open source projects hosting platform, GitHub 1 . The dataset contains 108,726 code-comment pairs. The vocabulary size of code and comment is 50,400 and 31,350, respectively. For crossvalidation, We shuffle the dataset and use the first 60% for training, 20% for validation and the remaining for testing. To construct the tree-structure of code, we parse Python code into abstract syntax trees via ast 2 lib. To convert code into sequential text, we tokenize the code by {. , \" ' : ; ) ( ! (space)}, which has been used in [8]. We tokenize the comment by {(space)}. Figure 5 shows the length distribution of code and comment on testing data. From Figure 5a, we can find that the lengths of most code snippets are located between 20 to 60. This verifies the quote in [33] \"Functions should hardly ever be 20 lines long\". In Python language, the limited length should be shorter. From Figure 5b, we can notice that the length of nearly all the comments are between 5 to 15. This reveals the comment sequence that we need to generate will not be too long.\n\n\nB. Evaluation Metrics\n\nWe evaluate the performance of our proposed model based on four widely-used evaluation criteria in the area of neural machine translation and image captioning, i.e., BLEU [29], ME-TEOR [34], ROUGE-L [35] and CIDER [36]. BLEU measures the average n-gram precision on a set of reference sentences, with a penalty for short sentences. METEOR is recall-oriented 1 https://github.com/ 2 https://docs.python.org/2/library/ast.html   and measures how well our model captures content from the references in our output. ROUGE-L takes into account sentence level structure similarity naturally and identifies longest cooccurring in sequence n-grams automatically. CIDER is a consensus based evaluation protocol for image captioning.\n\n\nC. Training Details\n\nThe hidden size of the encoder and decoder LSTM networks are both set to be 512, and the word embedding size is set to be 512. The mini-batch size is set to be 64, while the learning rate is set to be 0.001. We pretrain both actor network and critic network with 10 epochs each, and train the actor-critic network simultaneously 10 epoches. We record the perplexity 3 /reward every 50 iterations. Figure 6 shows the perplexity and reward curves of our method. All the experiments in this paper are implemented with Python 2.7, and run on a computer with an 2.2 GHz Intel Core i7 CPU, 64 GB 1600 MHz DDR3 RAM, and a Titan X GPU with 12 GB memory, running Ubuntu 16.04.\n\n\nD. RQ1: Compared to Baselines\n\nWe compare our model with the following baselines: \u2022 Seq2Seq [37] is a classical encoder-decoder framework in neural machine translation, which encodes the source sentences into a hidden space, and decodes it into target sentences. In our comparison, the encoder and decoder are both based on LSTM. \u2022 Seq2Seq+Attn [20] is a derived version of Seq2Seq model with an attentional layer for word alignment. \u2022 Tree2Seq [28] follows the same architecture with Seq2Seq and applies AST-based LSTM as encoder for the task of code clone detection.   Table I shows the experimental results of comparison between our proposed model and some previous ones. From this table, we can find that our proposed model outperforms other baselines in almost all of evaluation metrics. When comparing Seq2Seq/Tree2Seq with its correspond attention-based version, we can see that attention is really effective in aligning the code tokens with comment tokens. We can also find that the performance of simply encoding the tree structure of code is worse than that of simply encoding the code as sequence. This can be illustrated by that the words of comments are always drawn from the tokens of code. Thus, our model which considers both the structure and sequential information of code achieves the best performance in this comparison. Table II shows the effectiveness of some main components in our proposed model. From this table, comparing the results of Seq2Seq+ Attn/Tree2Seq+Attn with and without (Table I) deep reinforcement learning (DRL), we can see that the proposed DRL component can really boost the performance of comment generation for source code. We can also find the proposed approach of integrating the LSTM for content and AST-based LSTM for structure is effective on representing the code as compared with the corresponding non-hybrid ones in Table I. Furthermore, it also verifies that our proposed hybrid attention mechanism works well in our model.\n\n\nE. RQ2: Component Analysis\n\n\nF. RQ3: Parameter Analysis\n\nWe vary the length of code and comment since the code length may have an effect on the representation of code and the comment length may have an effect on the performance of text generation. Figure 7 and Figure 8 show the performance of our proposed method when compared with two baselines on datasets of varying code lengths and comment lengths, respectively.\n\nFrom Figure 7, we can see that our model performs best when compared with other baselines on four metrics with respect to different code lengths. Additionally, we can see that the our proposed model has a stable performance even though the code length increases dramatically. We attribute this effect to the hybrid representation we adopt in our model. For Figure 8, recall the comment length distribution in Figure  5b. Since nearly all the comment lengths of testing data are under 20, we ignore the performance analysis over the samples whose comment length are larger than 20. From this figure, we can see the performances of our model and baselines vary dramatically on four metrics with respect to different comment lengths.\n\n\nG. Qualitative Analysis and Visualization\n\nWe show two examples in Table III. It's clear that the generated comments by our model are closest to the ground truth. Although those models without DRL can generate some tokens which are also in the ground truth, they can't predict those tokens which are not frequently appeared in the training data. On the contrary, our deep reinforcement learning based model can generate some tokens which are closer to the ground truth, like git, symbolic. This can be illustrated by the fact that our model has a more comprehensive exploration on the word space and optimizes the BLEU score directly.\n\nIn Table III, we also visualize two attentions in our proposed model for the target sentences. For example, for Case 1 with target sentence check if git is installed ., we can notice that the str-attn (left of figure) focuses more on tokens like OSError, False, git, version, which represent the structure of code. On the other hand, the attention of txt-attn (right of figure) is comparatively dispersed, and have a focus on some tokens like def, which is of little significance for code summarization. This verifies our assumption that LSTM can capture the sequential content of code, and AST-based LSTM can capture the structure information of code. Thus, it's reasonable to fuse them together for a better representation.\n\n\nVII. THREATS TO VALIDITY AND LIMITATIONS\n\nOne threat to validity is that our approach is experimented only on Python code collected from GitHub, so they may not be representative of all the comments. However, Python is a popular programming language used in a large number of projects. In the future, we will extend our approach to other programming languages. Another threat to validity is on the metrics we choose for evaluation. It has always been a tough challenge to evaluate the similarity between two sentences for the tasks such as neural machine translation [37], image captioning [39]. In this paper, we only adopt four popular automatic metrics, it is necessary for us to evaluate the performance of generated text from more perspectives, such as human evaluation. Furthermore, in the deep reinforcement learning perspective, we only set the BLEU score of generated sentence as the reward. It's well known that for a reinforcement learning method, one of the biggest challenge is how to design a reward function to measure the value of action correctly, and it is still an open problem. In our future work, we plan to devise a reward function that can reflect the value of each action more correctly.\n\n\nVIII. RELATED WORK A. Deep Code Representation\n\nWith the successful development of deep learning, it has also become more and more prevalent for representing source code in the domain of software engineering research. Gu et al. [40] use a sequence-to-sequence deep neural network [37], originally introduced for statistical machine translation, to learn intermediate distributed vector representations of natural language queries which they use to predict relevant API sequences. Mou et al. [41] learn distributed vector representations using custom convolutional neural networks to represent features of snippets of code, then they assume that student solutions to various coursework problems have been intermixed and seek to recover the solution-to-problem mapping via classification. Li et al. [19] learn distributed vector representations for the nodes of a memory heap and use the learned representations to synthesize candidate formal specifications for the code that produces the heap. Piech et al. [42] and Parisotto et al. [43] learn distributed representations of source code input/output pairs and use them to assess and review student assignments or to guide program synthesis from examples. Neural codegenerative models of code also use distributed representations to capture context, which is a common practice in natural language processing. For example, the work of Maddison and Tarlow [44] and other neural language models (e.g. LSTMs in Dam et al. [45]) describe context distributed representations while sequentially generating code. Ling et al. [46] and Allamanis et al. [47] combine the code-context distributed representation with distributed representations of other modalities (e.g. natural language) to synthesize code.\n\n\nB. Source Code Summarization\n\nCode summarization is a novel task in the area of software engineering and has drawn great attention in recent years. The existing works for code summarization can be mainly categorized as rule based approaches [10], statistical language model based approaches [4] and deep learning based approaches [11], [5], [12]. Sridhara et al. [10] construct a software word usage model first, and generate comment according to the tokenized function/variable names via rules. Movshovitz-Attias et al. [4] predict comments from Java source files using topic models and n-grams. In [11], the authors introduce an attentional neural network that employs convolution on the input tokens to detect local time-invariant and long-range topical attention features to summarize source code snippets into short, descriptive function name-like summaries. Iyer et al. [5] propose to use LSTM networks with attention to produce sentences that describe C# code snippets and SQL queries. In Haije's thesis [12], the code summarization problem is modeled as a machine translation task, and some translation models such as Seq2Seq [37] and Seq2Seq with attention [20] are employed. Unlike previous studies, we take the tree structure and sequential content of source code into consideration for a better representation of code.\n\n\nC. Deep Reinforcement Learning\n\nReinforcement learning [22], [25], [48], concerned with how software agents ought to take actions in an environment so as to maximize the cumulative reward, is well suited for the task of decision-making. Recently, professional-level computer Go program has been designed by Silver et al. [26] using deep neural networks and Monte Carlo Tree Search. Humanlevel gaming control [49] has been achieved through deep Q-learning. A visual navigation system [50] has been proposed recently based on actor-critic reinforcement learning model. Text generation can also be formulated as a decision-making problem and there have been several reinforcement learningbased works on this specific tasks, including image captioning [51], dialogue generation [52] and sentence simplification [53]. Ren et al. [51] propose an actor-critic deep reinforcement learning model with an embedding reward for image captioning. Li et al. [52] integrate a developer-defined reward with REINFORCE algorithm for dialogue generation. In this paper, we follow an actor-critic reinforcement learning framework, while our focus is on encoding the structural and sequential information of code snippets simultaneously with an attention mechanism.\n\n\nIX. CONCLUSION\n\nIn this paper, we first point out two issues (i.e., code representation and exposure bias) existing in traditional code summarization works. To handle these two issues, we first encode the structure and sequential content of code via ASTbased LSTM and LSTM respectively. Then we add a hybrid attention layer to integrate them together. We then feed the code representation vector into a deep reinforcement learning framework, named actor-critic network. Comprehensive experiments on a real-world dataset show that our proposed model outperforms other competitive baselines and achieves stateof-the-art performance on several automatic metrics, namely BLEU, METEOR, ROUGE-L and CIDER. For future work, in the first place, we plan to design a copy mechanism to cope with rare words which are out of our vocabulary, and extend our experiments to other programming languages such as Java. Due to the low efficiency of LSTM, we also plan to apply some other networks such as convolutional neural network (CNN) for code representation.\n\n\nAn example of abstractive syntax tree (AST).\n\n\nThe limitation of maximum likelihood based text generation.\n\nFigure 1 :\n1An illustration of the motivation of our paper. Traditional methods suffer from the following two limitations: a) On representing the code, the structure information of code is always ignored. b) Traditional maximum likelihood based methods suffer from the exposure bias issue.\n\nFigure 2 :\n2RNN and Tree-RNN (adapted from[16]).\n\nFigure 3 :\n3An overall workflow of getting a trained model.\n\nFigure 4 :\n4An overview of our proposed deep reinforcement learning framework for code summarization.\n\n\nwhere n is the number of code tokens; h (\u00b7) j \u00b7 s t is the inner project of h (\u00b7) j and s t , which is used to directly calculate the similarity score between h (\u00b7) j and s t . The t-th context vector d (\u00b7) t is calculated as the summarization vector weighted by \u03b1 (\u00b7) t (j):\n\n\u2022 RQ1 .\nRQ1Does our proposed approach improve the performance of code summarization when compared with some state-of-the-art approaches? \u2022 RQ2. What's the effectiveness of each component for our proposed model? For example, what about the performance of hybrid code representation and reinforcement learning respectively? Algorithm 1 Actor-Critic training for code summarization.\n\nFigure 5 :\n5Length\n\nFigure 6 :\n6Iteration of training perplexity and reward.\n\nFigure 7 :Figure 8 :\n78Experimental results of our proposed method and some baselines on different metrics w.r.t. varying code length. Experimental results of our proposed method and some baselines on different metrics w.r.t. varying comment length.\n\nTable I :\nIComparison of the overall performance between our model and previous methods. (Best scores are in boldface.) \n\nBLEU-1 \nBLEU-2 BLEU-3 \nBLEU-4 \nMETEOR ROUGE-L CIDER \nSeq2Seq \n0.1660 \n0.0251 \n0.0100 \n0.0056 \n0.0535 \n0.2838 \n0.1262 \nSeq2Seq+Attn \n0.1897 \n0.0419 \n0.0200 \n0.0133 \n0.0649 \n0.3083 \n0.2594 \nTree2Seq \n0.1649 \n0.0236 \n0.0096 \n0.0053 \n0.0501 \n0.2794 \n0.1168 \nTree2Seq+Attn \n0.1887 \n0.0417 \n0.0197 \n0.0129 \n0.0644 \n0.3068 \n0.2331 \nHybrid2Seq+Attn+DRL (Our) 0.2527 \n0.1033 \n0.0640 \n0.0441 \n0.0929 \n0.3913 \n0.7501 \n\n\n\nTable II :\nIIEffectiveness of each component for our proposed model. (Best scores are in boldface.)BLEU-1 \nBLEU-2 \nBLEU-3 BLEU-4 \nMETEOR ROUGE-L CIDER \nSeq2Seq+Attn+DRL \n0.2421 \n0.0919 \n0.0513 \n0.0325 \n0.0882 \n0.3935 \n0.6390 \nTree2Seq+Attn+DRL \n0.2309 \n0.0854 \n0.0499 \n0.0338 \n0.0843 \n0.3767 \n0.6060 \nHybrid2Seq \n0.1837 \n0.0379 \n0.0183 \n0.0122 \n0.0604 \n0.3020 \n0.2223 \nHybrid2Seq+Attn \n0.1965 \n0.0516 \n0.0280 \n0.0189 \n0.0693 \n0.3154 \n0.3475 \nHybrid2Seq+Attn+DRL (Our) 0.2527 \n0.1033 \n0.0640 \n0.0441 \n0.0929 \n0.3913 \n0.7501 \n\n\u2022 Tree2Seq+Attn [38] is a derived version of Tree2Seq \nmodel with an attentional layer, which has been applied \nin neural machine translation \n\u2022 Hybrid2Seq(+Attn+DRL) represents three versions of our \nproposed model with/without Attn/DRL component. \n\n\nTable III :\nIIIExamples of code summarization generated by each model and attention visualization of our model.Seq2Seq+Attn   return true if the user has access to the specified resource .a decorator that returns a new class that will return a new class name .Hybrid2Seq+Attn returns the number of git modules that are not installed . return the path to the currently running server .Case 1 \nCase 2 \n\nCode snippet \n\ndef _has_git(): \ntry: subprocess.check_call( \n[git, --version], \nstdout=subprocess.DEVNULL, \nstderr=subprocess.DEVNULL) \nexcept(OSError, subprocess \n.CalledProcessError): \nreturn False \nelse: return True \n\ndef tensor3(name=None,dtype=None): \nif (dtype is None): \ndtype=config.floatX \ntype=CudaNdarrayType( \ndtype=dtype, \nbroadcastable= \n(False, False, False)) \nreturn type(name) \n\nGround truth \ncheck if git is installed . \nreturn a symbolic 3-d variable . \n\nSeq2Seq \nhelper function to create a new figure \nmanager instance . \nyaml \n\nTree2Seq+Attn \ntest that validate folders throws a \nfoldermissingerror . \nhelper function for #4957 . \n\nHybrid2Seq+Attn+DRL \nreturns true if git is installed . \nreturn a symbolic graph . \n\nAttention visualization \n\ndef \nsubprocess \nsubprocess \n\nOSError \nFalse \n'git' \n'--version' \nsubprocess \n\nTrue \n<EOS> \n\ncheck \nif \ngit \nis \ninstalled \n. \n<EOS> \n\ndef \n<unk> \n\ntry \nsubprocess \ncheck_call \n\n['git' \n'--version'] \n\nstdout \nsubprocess \nDEVNULL \n\nstderr \nsubprocess \nDEVNULL \nexcept \nOSError \nsubprocess \nCalledProcessError \n\nreturn \n<unk> \nreturn \n<EOS> \n\n0.0 \n\n0.5 \n\n1.0 \n\nNone \nNone \nconfig \nFalse \nFalse \ntype \nname \ndtype \nFalse \nCudaNdarrayType \n\ndtype \ntype \ndtype \nname \ndtype \n<EOS> \n\nreturn \na \nsymbolic \n3-d \nvariable \n. \n<EOS> \n\ndef \n<unk> \nname \nNone \ndtype \nNone \n\nif \ndtype \n\nis \nNone \ndtype \nconfig \n<unk> \nCudaNdarrayType \n\ndtype \ndtype \nbroadcastable \n\nFalse \nFalse \nFalse \nreturn \ntype \nname \n\n0.0 \n\n0.5 \n\n1.0 \n\n\nPerplexity is a function of cross entropy loss, which has been widely used in evaluation of many natural language processing tasks.\n\nSoftware maintenance management. B P Lientz, E B Swanson, B. P. Lientz and E. B. Swanson, \"Software maintenance management,\" 1980.\n\nA study of the documentation essential to software maintenance. S C B Souza, N Anquetil, K M De Oliveira, Proceedings of the 23rd annual international conference on Design of communication: documenting & designing for pervasive information. the 23rd annual international conference on Design of communication: documenting & designing for pervasive informationACMS. C. B. de Souza, N. Anquetil, and K. M. de Oliveira, \"A study of the documentation essential to software maintenance,\" in Proceedings of the 23rd annual international conference on Design of communication: documenting & designing for pervasive information. ACM, 2005, pp. 68-75.\n\nA survey of documentation practice within corrective maintenance. M Kajko-Mattsson, Empirical Software Engineering. 101M. Kajko-Mattsson, \"A survey of documentation practice within correc- tive maintenance,\" Empirical Software Engineering, vol. 10, no. 1, pp. 31-55, 2005.\n\nNatural language models for predicting programming comments. D Movshovitz-Attias, W W Cohen, D. Movshovitz-Attias and W. W. Cohen, \"Natural language models for predicting programming comments,\" 2013.\n\nSummarizing source code using a neural attention model. S Iyer, I Konstas, A Cheung, L Zettlemoyer, ACL. S. Iyer, I. Konstas, A. Cheung, and L. Zettlemoyer, \"Summarizing source code using a neural attention model.\" in ACL (1), 2016.\n\nFrom query to usable code: An analysis of stack overflow code snippets. D Yang, A Hussain, C V Lopes, Mining Software Repositories (MSR), 2016 IEEE/ACM 13th Working Conference on. IEEED. Yang, A. Hussain, and C. V. Lopes, \"From query to usable code: An analysis of stack overflow code snippets,\" in Mining Software Repositories (MSR), 2016 IEEE/ACM 13th Working Conference on. IEEE, 2016, pp. 391-401.\n\nQuery expansion based on crowd knowledge for code search. L Nie, H Jiang, Z Ren, Z Sun, X Li, IEEE Transactions on Services Computing. 95L. Nie, H. Jiang, Z. Ren, Z. Sun, and X. Li, \"Query expansion based on crowd knowledge for code search,\" IEEE Transactions on Services Computing, vol. 9, no. 5, pp. 771-783, 2016.\n\nAutomatic categorization with deep neural network for open-source java projects. A T Nguyen, T N Nguyen, Proceedings of the 39th International Conference on Software Engineering Companion. the 39th International Conference on Software Engineering CompanionIEEE PressA. T. Nguyen and T. N. Nguyen, \"Automatic categorization with deep neural network for open-source java projects,\" in Proceedings of the 39th International Conference on Software Engineering Companion. IEEE Press, 2017, pp. 164-166.\n\nLearning to generate pseudo-code from source code using statistical machine translation (t). Y Oda, H Fudaba, G Neubig, H Hata, S Sakti, T Toda, S Nakamura, 30th IEEE/ACM International Conference on. IEEEAutomated Software Engineering (ASE)Y. Oda, H. Fudaba, G. Neubig, H. Hata, S. Sakti, T. Toda, and S. Nakamura, \"Learning to generate pseudo-code from source code using statistical machine translation (t),\" in Automated Software Engineering (ASE), 2015 30th IEEE/ACM International Conference on. IEEE, 2015, pp. 574-584.\n\nTowards automatically generating summary comments for java methods. G Sridhara, E Hill, D Muppaneni, L Pollock, K Vijay-Shanker, Proceedings of the IEEE/ACM international conference on Automated software engineering. the IEEE/ACM international conference on Automated software engineeringACMG. Sridhara, E. Hill, D. Muppaneni, L. Pollock, and K. Vijay-Shanker, \"Towards automatically generating summary comments for java methods,\" in Proceedings of the IEEE/ACM international conference on Automated software engineering. ACM, 2010, pp. 43-52.\n\nA convolutional attention network for extreme summarization of source code. M Allamanis, H Peng, C Sutton, International Conference on Machine Learning. M. Allamanis, H. Peng, and C. Sutton, \"A convolutional attention network for extreme summarization of source code,\" in International Conference on Machine Learning, 2016, pp. 2091-2100.\n\nAutomatic comment generation using a neural translation model. T Haije, B O K Intelligentie, E Gavves, H Heuer, T. Haije, B. O. K. Intelligentie, E. Gavves, and H. Heuer, \"Automatic comment generation using a neural translation model,\" 2016.\n\nLong short-term memory. S Hochreiter, J Schmidhuber, Neural computation. 98S. Hochreiter and J. Schmidhuber, \"Long short-term memory,\" Neural computation, vol. 9, no. 8, pp. 1735-1780, 1997.\n\nSequence level training with recurrent neural networks. M Ranzato, S Chopra, M Auli, W Zaremba, arXiv:1511.06732arXiv preprintM. Ranzato, S. Chopra, M. Auli, and W. Zaremba, \"Sequence level train- ing with recurrent neural networks,\" arXiv preprint arXiv:1511.06732, 2015.\n\nClone detection using abstract syntax trees. I D Baxter, A Yahin, L Moura, M Sant&apos;anna, L Bier, Proceedings., International Conference on. International Conference onIEEEin Software MaintenanceI. D. Baxter, A. Yahin, L. Moura, M. Sant'Anna, and L. Bier, \"Clone detection using abstract syntax trees,\" in Software Maintenance, 1998. Proceedings., International Conference on. IEEE, 1998, pp. 368-377.\n\nImproved semantic representations from tree-structured long short-term memory networks. K S Tai, R Socher, C D Manning, arXiv:1503.00075arXiv preprintK. S. Tai, R. Socher, and C. D. Manning, \"Improved semantic represen- tations from tree-structured long short-term memory networks,\" arXiv preprint arXiv:1503.00075, 2015.\n\nTwo decades of statistical language modeling: Where do we go from here. R Rosenfeld, Proceedings of the IEEE. the IEEE88R. Rosenfeld, \"Two decades of statistical language modeling: Where do we go from here?\" Proceedings of the IEEE, vol. 88, no. 8, pp. 1270-1278, 2000.\n\nA fast and simple algorithm for training neural probabilistic language models. A Mnih, Y W Teh, arXiv:1206.6426arXiv preprintA. Mnih and Y. W. Teh, \"A fast and simple algorithm for training neural probabilistic language models,\" arXiv preprint arXiv:1206.6426, 2012.\n\nGated graph sequence neural networks. Y Li, D Tarlow, M Brockschmidt, R Zemel, arXiv:1511.05493arXiv preprintY. Li, D. Tarlow, M. Brockschmidt, and R. Zemel, \"Gated graph sequence neural networks,\" arXiv preprint arXiv:1511.05493, 2015.\n\nNeural machine translation by jointly learning to align and translate. D Bahdanau, K Cho, Y Bengio, arXiv:1409.0473arXiv preprintD. Bahdanau, K. Cho, and Y. Bengio, \"Neural machine translation by jointly learning to align and translate,\" arXiv preprint arXiv:1409.0473, 2014.\n\nIntroduction to reinforcement learning. R S Sutton, A G Barto, MIT press Cambridge135R. S. Sutton and A. G. Barto, Introduction to reinforcement learning. MIT press Cambridge, 1998, vol. 135.\n\nSimple statistical gradient-following algorithms for connectionist reinforcement learning. R J Williams, Reinforcement Learning. SpringerR. J. Williams, \"Simple statistical gradient-following algorithms for con- nectionist reinforcement learning,\" in Reinforcement Learning. Springer, 1992, pp. 5-32.\n\nQ-learning. C J Watkins, P Dayan, Machine learning. 83-4C. J. Watkins and P. Dayan, \"Q-learning,\" Machine learning, vol. 8, no. 3-4, pp. 279-292, 1992.\n\nDeep reinforcement learning for sequence to sequence models. Y Keneshloo, T Shi, C K Reddy, N Ramakrishnan, arXiv:1805.09461arXiv preprintY. Keneshloo, T. Shi, C. K. Reddy, and N. Ramakrishnan, \"Deep reinforcement learning for sequence to sequence models,\" arXiv preprint arXiv:1805.09461, 2018.\n\nActor-critic algorithms. V R Konda, J N Tsitsiklis, Advances in neural information processing systems. V. R. Konda and J. N. Tsitsiklis, \"Actor-critic algorithms,\" in Advances in neural information processing systems, 2000, pp. 1008-1014.\n\nMastering the game of go with deep neural networks and tree search. D Silver, A Huang, C J Maddison, A Guez, L Sifre, G Van Den Driessche, J Schrittwieser, I Antonoglou, V Panneershelvam, M Lanctot, S Dieleman, Nature. 5297587D. Silver, A. Huang, C. J. Maddison, A. Guez, L. Sifre, G. Van Den Driessche, J. Schrittwieser, I. Antonoglou, V. Panneershelvam, M. Lanctot, and S. Dieleman, \"Mastering the game of go with deep neural networks and tree search,\" Nature, vol. 529, no. 7587, pp. 484-489, 2016.\n\nCompilers, principles, techniques. A V Aho, R Sethi, J D Ullman, Addison Wesley79A. V. Aho, R. Sethi, and J. D. Ullman, \"Compilers, principles, techniques,\" Addison Wesley, vol. 7, no. 8, p. 9, 1986.\n\nSupervised deep features for software functional clone detection by exploiting lexical and syntactical information in source code. H H Wei, M Li, H. H. Wei and M. Li, \"Supervised deep features for software functional clone detection by exploiting lexical and syntactical information in source code,\" 2017.\n\nBleu: a method for automatic evaluation of machine translation. K Papineni, S Roukos, T Ward, W J Zhu, Proceedings of the 40th annual meeting on association for computational linguistics. the 40th annual meeting on association for computational linguisticsAssociation for Computational LinguisticsK. Papineni, S. Roukos, T. Ward, and W. J. Zhu, \"Bleu: a method for automatic evaluation of machine translation,\" in Proceedings of the 40th annual meeting on association for computational linguistics. Association for Computational Linguistics, 2002, pp. 311-318.\n\nHighdimensional continuous control using generalized advantage estimation. J Schulman, P Moritz, S Levine, M Jordan, P Abbeel, arXiv:1506.02438arXiv preprintJ. Schulman, P. Moritz, S. Levine, M. Jordan, and P. Abbeel, \"High- dimensional continuous control using generalized advantage estimation,\" arXiv preprint arXiv:1506.02438, 2015.\n\nAdaptive subgradient methods for online learning and stochastic optimization. J Duchi, E Hazan, Y Singer, Journal of Machine Learning Research. 12J. Duchi, E. Hazan, and Y. Singer, \"Adaptive subgradient methods for online learning and stochastic optimization,\" Journal of Machine Learning Research, vol. 12, no. Jul, pp. 2121-2159, 2011.\n\nA parallel corpus of python functions and documentation strings for automated code documentation and code generation. A V M Barone, R Sennrich, arXiv:1707.02275arXiv preprintA. V. M. Barone and R. Sennrich, \"A parallel corpus of python functions and documentation strings for automated code documentation and code generation,\" arXiv preprint arXiv:1707.02275, 2017.\n\nClean code: a handbook of agile software craftsmanship. R C Martin, Pearson EducationR. C. Martin, Clean code: a handbook of agile software craftsmanship. Pearson Education, 2009.\n\nMeteor: An automatic metric for mt evaluation with improved correlation with human judgments. S Banerjee, A Lavie, Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization. the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization29S. Banerjee and A. Lavie, \"Meteor: An automatic metric for mt evaluation with improved correlation with human judgments,\" in Proceedings of the acl workshop on intrinsic and extrinsic evaluation measures for machine translation and/or summarization, vol. 29, 2005, pp. 65-72.\n\nRouge: A package for automatic evaluation of summaries. C Y Lin, Text Summarization Branches Out. C. Y. Lin, \"Rouge: A package for automatic evaluation of summaries,\" Text Summarization Branches Out, 2004.\n\nCider: Consensusbased image description evaluation. R Vedantam, C Lawrence Zitnick, D Parikh, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionR. Vedantam, C. Lawrence Zitnick, and D. Parikh, \"Cider: Consensus- based image description evaluation,\" in Proceedings of the IEEE conference on computer vision and pattern recognition, 2015, pp. 4566- 4575.\n\nSequence to sequence learning with neural networks. I Sutskever, O Vinyals, Q V Le, Advances in neural information processing systems. I. Sutskever, O. Vinyals, and Q. V. Le, \"Sequence to sequence learning with neural networks,\" in Advances in neural information processing systems, 2014, pp. 3104-3112.\n\nTree-to-sequence attentional neural machine translation. A Eriguchi, K Hashimoto, Y Tsuruoka, arXiv:1603.06075arXiv preprintA. Eriguchi, K. Hashimoto, and Y. Tsuruoka, \"Tree-to-sequence atten- tional neural machine translation,\" arXiv preprint arXiv:1603.06075, 2016.\n\nReevaluating automatic metrics for image captioning. M Kilickaya, A Erdem, N Ikizler-Cinbis, E Erdem, arXiv:1612.07600arXiv preprintM. Kilickaya, A. Erdem, N. Ikizler-Cinbis, and E. Erdem, \"Re- evaluating automatic metrics for image captioning,\" arXiv preprint arXiv:1612.07600, 2016.\n\nDeep api learning. X Gu, H Zhang, D Zhang, S Kim, Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering. the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software EngineeringACMX. Gu, H. Zhang, D. Zhang, and S. Kim, \"Deep api learning,\" in Proceedings of the 2016 24th ACM SIGSOFT International Symposium on Foundations of Software Engineering. ACM, 2016, pp. 631-642.\n\nConvolutional neural networks over tree structures for programming language processing. L Mou, G Li, L Zhang, T Wang, Z Jin, AAAI. 234L. Mou, G. Li, L. Zhang, T. Wang, and Z. Jin, \"Convolutional neural networks over tree structures for programming language processing.\" in AAAI, vol. 2, no. 3, 2016, p. 4.\n\nLearning program embeddings to propagate feedback on student code. C Piech, J Huang, A Nguyen, M Phulsuksombati, M Sahami, L Guibas, arXiv:1505.05969arXiv preprintC. Piech, J. Huang, A. Nguyen, M. Phulsuksombati, M. Sahami, and L. Guibas, \"Learning program embeddings to propagate feedback on student code,\" arXiv preprint arXiv:1505.05969, 2015.\n\nNeuro-symbolic program synthesis. E Parisotto, A Mohamed, R Singh, L Li, D Zhou, P Kohli, arXiv:1611.01855arXiv preprintE. Parisotto, A. Mohamed, R. Singh, L. Li, D. Zhou, and P. Kohli, \"Neuro-symbolic program synthesis,\" arXiv preprint arXiv:1611.01855, 2016.\n\nStructured generative models of natural source code. C Maddison, D Tarlow, International Conference on Machine Learning. C. Maddison and D. Tarlow, \"Structured generative models of natural source code,\" in International Conference on Machine Learning, 2014, pp. 649-657.\n\nA deep language model for software code. H K Dam, T Tran, T Pham, arXiv:1608.02715arXiv preprintH. K. Dam, T. Tran, and T. Pham, \"A deep language model for software code,\" arXiv preprint arXiv:1608.02715, 2016.\n\nLatent predictor networks for code generation. W Ling, E Grefenstette, K M Hermann, T Ko\u010disk\u1ef3, A Senior, F Wang, P Blunsom, arXiv:1603.06744arXiv preprintW. Ling, E. Grefenstette, K. M. Hermann, T. Ko\u010disk\u1ef3, A. Senior, F. Wang, and P. Blunsom, \"Latent predictor networks for code generation,\" arXiv preprint arXiv:1603.06744, 2016.\n\nBimodal modelling of source code and natural language. M Allamanis, D Tarlow, A Gordon, Y Wei, International Conference on Machine Learning. M. Allamanis, D. Tarlow, A. Gordon, and Y. Wei, \"Bimodal modelling of source code and natural language,\" in International Conference on Machine Learning, 2015, pp. 2123-2132.\n\nPolicy gradient methods for reinforcement learning with function approximation. R S Sutton, D A Mcallester, S P Singh, Y Mansour, Advances in neural information processing systems. R. S. Sutton, D. A. McAllester, S. P. Singh, and Y. Mansour, \"Policy gradient methods for reinforcement learning with function approximation,\" in Advances in neural information processing systems, 2000, pp. 1057- 1063.\n\nHuman-level control through deep reinforcement learning. V Mnih, K Kavukcuoglu, D Silver, A A Rusu, J Veness, M G Bellemare, A Graves, M Riedmiller, A K Fidjeland, G Ostrovski, Nature. 5187540V. Mnih, K. Kavukcuoglu, D. Silver, A. A. Rusu, J. Veness, M. G. Bellemare, A. Graves, M. Riedmiller, A. K. Fidjeland, G. Ostrovski et al., \"Human-level control through deep reinforcement learning,\" Nature, vol. 518, no. 7540, pp. 529-533, 2015.\n\nTarget-driven visual navigation in indoor scenes using deep reinforcement learning. Y Zhu, R Mottaghi, E Kolve, J J Lim, A Gupta, L Fei-Fei, A Farhadi, Robotics and Automation (ICRA. Y. Zhu, R. Mottaghi, E. Kolve, J. J. Lim, A. Gupta, L. Fei-Fei, and A. Farhadi, \"Target-driven visual navigation in indoor scenes using deep reinforcement learning,\" in Robotics and Automation (ICRA), 2017 IEEE International Conference on. IEEE, 2017, pp. 3357-3364.\n\nDeep reinforcement learning-based image captioning with embedding reward. Z Ren, X Wang, N Zhang, X Lv, L J Li, Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference. Z. Ren, X. Wang, N. Zhang, X. Lv, and L. J. Li, \"Deep reinforcement learning-based image captioning with embedding reward,\" in Computer Vision and Pattern Recognition (CVPR), 2017 IEEE Conference on. IEEE, 2017, pp. 1151-1159.\n\nDeep reinforcement learning for dialogue generation. J Li, W Monroe, A Ritter, M Galley, J Gao, D Jurafsky, arXiv:1606.01541arXiv preprintJ. Li, W. Monroe, A. Ritter, M. Galley, J. Gao, and D. Jurafsky, \"Deep reinforcement learning for dialogue generation,\" arXiv preprint arXiv:1606.01541, 2016.\n\nSentence simplification with deep reinforcement learning. X Zhang, M Lapata, Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. the 2017 Conference on Empirical Methods in Natural Language ProcessingX. Zhang and M. Lapata, \"Sentence simplification with deep reinforce- ment learning,\" in Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, 2017, pp. 584-594.\n", "annotations": {"author": "[{\"end\":167,\"start\":81},{\"end\":256,\"start\":168},{\"end\":364,\"start\":257},{\"end\":478,\"start\":365},{\"end\":570,\"start\":479},{\"end\":657,\"start\":571},{\"end\":822,\"start\":658}]", "publisher": null, "author_last_name": "[{\"end\":88,\"start\":85},{\"end\":177,\"start\":173},{\"end\":265,\"start\":261},{\"end\":376,\"start\":374},{\"end\":491,\"start\":487},{\"end\":578,\"start\":576},{\"end\":669,\"start\":667}]", "author_first_name": "[{\"end\":84,\"start\":81},{\"end\":172,\"start\":168},{\"end\":260,\"start\":257},{\"end\":373,\"start\":365},{\"end\":486,\"start\":479},{\"end\":575,\"start\":571},{\"end\":664,\"start\":658},{\"end\":666,\"start\":665}]", "author_affiliation": "[{\"end\":166,\"start\":90},{\"end\":255,\"start\":179},{\"end\":363,\"start\":287},{\"end\":477,\"start\":401},{\"end\":569,\"start\":493},{\"end\":656,\"start\":580},{\"end\":760,\"start\":684},{\"end\":821,\"start\":762}]", "title": "[{\"end\":78,\"start\":1},{\"end\":900,\"start\":823}]", "venue": null, "abstract": "[{\"end\":2462,\"start\":902}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2726,\"start\":2723},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3163,\"start\":3160},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3168,\"start\":3165},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3892,\"start\":3889},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":3897,\"start\":3894},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3992,\"start\":3989},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":3997,\"start\":3994},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":4025,\"start\":4022},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":4301,\"start\":4298},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":4306,\"start\":4303},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":4367,\"start\":4363},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":4443,\"start\":4439},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":4448,\"start\":4445},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":4454,\"start\":4450},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":4623,\"start\":4619},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":5476,\"start\":5472},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":6034,\"start\":6030},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":6559,\"start\":6555},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":6631,\"start\":6627},{\"end\":8562,\"start\":8561},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":11071,\"start\":11067},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":11077,\"start\":11073},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":12428,\"start\":12424},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":12468,\"start\":12464},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":13990,\"start\":13986},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":16113,\"start\":16109},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":16167,\"start\":16163},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":16277,\"start\":16273},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":16520,\"start\":16516},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":17614,\"start\":17610},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":17704,\"start\":17700},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":20105,\"start\":20101},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":20608,\"start\":20604},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":21790,\"start\":21786},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":22326,\"start\":22322},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":22782,\"start\":22778},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":24340,\"start\":24336},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":26168,\"start\":26164},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":26243,\"start\":26239},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":26457,\"start\":26453},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":26584,\"start\":26580},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":27339,\"start\":27335},{\"end\":27973,\"start\":27971},{\"end\":28030,\"start\":28028},{\"end\":28087,\"start\":28085},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":28826,\"start\":28822},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":29387,\"start\":29384},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":29631,\"start\":29627},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":30114,\"start\":30110},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":30128,\"start\":30124},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":30142,\"start\":30138},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":30157,\"start\":30153},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":31704,\"start\":31700},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":31804,\"start\":31800},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":36421,\"start\":36417},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":36444,\"start\":36440},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":37296,\"start\":37292},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":37348,\"start\":37344},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":37559,\"start\":37555},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":37865,\"start\":37861},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":38074,\"start\":38070},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":38100,\"start\":38096},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":38470,\"start\":38466},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":38534,\"start\":38530},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":38633,\"start\":38629},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":38659,\"start\":38655},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":39056,\"start\":39052},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":39105,\"start\":39102},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":39145,\"start\":39141},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":39150,\"start\":39147},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":39156,\"start\":39152},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":39178,\"start\":39174},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":39335,\"start\":39332},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":39415,\"start\":39411},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":39690,\"start\":39687},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":39826,\"start\":39822},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":39949,\"start\":39945},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":39981,\"start\":39977},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":40203,\"start\":40199},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":40209,\"start\":40205},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":40215,\"start\":40211},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":40469,\"start\":40465},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":40556,\"start\":40552},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":40631,\"start\":40627},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":40896,\"start\":40892},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":40922,\"start\":40918},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":40955,\"start\":40951},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":40972,\"start\":40968},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":41092,\"start\":41088},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":42884,\"start\":42880}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":42483,\"start\":42437},{\"attributes\":{\"id\":\"fig_1\"},\"end\":42545,\"start\":42484},{\"attributes\":{\"id\":\"fig_2\"},\"end\":42836,\"start\":42546},{\"attributes\":{\"id\":\"fig_3\"},\"end\":42886,\"start\":42837},{\"attributes\":{\"id\":\"fig_4\"},\"end\":42947,\"start\":42887},{\"attributes\":{\"id\":\"fig_5\"},\"end\":43050,\"start\":42948},{\"attributes\":{\"id\":\"fig_6\"},\"end\":43328,\"start\":43051},{\"attributes\":{\"id\":\"fig_7\"},\"end\":43709,\"start\":43329},{\"attributes\":{\"id\":\"fig_9\"},\"end\":43729,\"start\":43710},{\"attributes\":{\"id\":\"fig_10\"},\"end\":43787,\"start\":43730},{\"attributes\":{\"id\":\"fig_11\"},\"end\":44038,\"start\":43788},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":44570,\"start\":44039},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":45347,\"start\":44571},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":47230,\"start\":45348}]", "paragraph": "[{\"end\":4026,\"start\":2481},{\"end\":6888,\"start\":4028},{\"end\":8013,\"start\":6890},{\"end\":8289,\"start\":8015},{\"end\":9588,\"start\":8291},{\"end\":10492,\"start\":9607},{\"end\":10932,\"start\":10514},{\"end\":12328,\"start\":11008},{\"end\":12570,\"start\":12359},{\"end\":12698,\"start\":12589},{\"end\":13007,\"start\":12743},{\"end\":13162,\"start\":13023},{\"end\":13466,\"start\":13202},{\"end\":13772,\"start\":13468},{\"end\":13906,\"start\":13808},{\"end\":13991,\"start\":13936},{\"end\":14100,\"start\":13993},{\"end\":14556,\"start\":14148},{\"end\":15544,\"start\":14606},{\"end\":15779,\"start\":15596},{\"end\":16004,\"start\":15781},{\"end\":16680,\"start\":16006},{\"end\":18394,\"start\":16720},{\"end\":18979,\"start\":18396},{\"end\":19364,\"start\":19017},{\"end\":19704,\"start\":19385},{\"end\":19905,\"start\":19727},{\"end\":20649,\"start\":20023},{\"end\":21533,\"start\":20975},{\"end\":22121,\"start\":21535},{\"end\":22433,\"start\":22179},{\"end\":22634,\"start\":22454},{\"end\":23124,\"start\":22636},{\"end\":23477,\"start\":23330},{\"end\":23707,\"start\":23524},{\"end\":23805,\"start\":23749},{\"end\":24064,\"start\":23807},{\"end\":24657,\"start\":24133},{\"end\":24860,\"start\":24659},{\"end\":24885,\"start\":24862},{\"end\":25295,\"start\":24938},{\"end\":25448,\"start\":25334},{\"end\":25627,\"start\":25494},{\"end\":26060,\"start\":25649},{\"end\":26169,\"start\":26062},{\"end\":26458,\"start\":26193},{\"end\":26602,\"start\":26460},{\"end\":27113,\"start\":26657},{\"end\":27190,\"start\":27115},{\"end\":27443,\"start\":27260},{\"end\":27855,\"start\":27476},{\"end\":28140,\"start\":27857},{\"end\":28723,\"start\":28142},{\"end\":29913,\"start\":28750},{\"end\":30661,\"start\":29939},{\"end\":31352,\"start\":30685},{\"end\":33331,\"start\":31386},{\"end\":33751,\"start\":33391},{\"end\":34483,\"start\":33753},{\"end\":35120,\"start\":34529},{\"end\":35847,\"start\":35122},{\"end\":37061,\"start\":35892},{\"end\":38808,\"start\":37112},{\"end\":40141,\"start\":38841},{\"end\":41388,\"start\":40176},{\"end\":42436,\"start\":41407}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":11007,\"start\":10933},{\"attributes\":{\"id\":\"formula_1\"},\"end\":12358,\"start\":12329},{\"attributes\":{\"id\":\"formula_2\"},\"end\":12588,\"start\":12571},{\"attributes\":{\"id\":\"formula_3\"},\"end\":13201,\"start\":13163},{\"attributes\":{\"id\":\"formula_4\"},\"end\":13807,\"start\":13773},{\"attributes\":{\"id\":\"formula_5\"},\"end\":13935,\"start\":13907},{\"attributes\":{\"id\":\"formula_6\"},\"end\":14147,\"start\":14101},{\"attributes\":{\"id\":\"formula_7\"},\"end\":15595,\"start\":15545},{\"attributes\":{\"id\":\"formula_8\"},\"end\":20022,\"start\":19906},{\"attributes\":{\"id\":\"formula_9\"},\"end\":20708,\"start\":20650},{\"attributes\":{\"id\":\"formula_10\"},\"end\":20974,\"start\":20708},{\"attributes\":{\"id\":\"formula_11\"},\"end\":23252,\"start\":23125},{\"attributes\":{\"id\":\"formula_12\"},\"end\":23329,\"start\":23252},{\"attributes\":{\"id\":\"formula_13\"},\"end\":23523,\"start\":23478},{\"attributes\":{\"id\":\"formula_14\"},\"end\":23748,\"start\":23708},{\"attributes\":{\"id\":\"formula_15\"},\"end\":24112,\"start\":24065},{\"attributes\":{\"id\":\"formula_16\"},\"end\":24937,\"start\":24886},{\"attributes\":{\"id\":\"formula_17\"},\"end\":25333,\"start\":25296},{\"attributes\":{\"id\":\"formula_18\"},\"end\":25493,\"start\":25449},{\"attributes\":{\"id\":\"formula_19\"},\"end\":26192,\"start\":26170},{\"attributes\":{\"id\":\"formula_20\"},\"end\":26656,\"start\":26603},{\"attributes\":{\"id\":\"formula_21\"},\"end\":27259,\"start\":27191}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":31933,\"start\":31926},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":32704,\"start\":32696},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":32872,\"start\":32863},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":33230,\"start\":33223},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":34562,\"start\":34553},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":35134,\"start\":35125}]", "section_header": "[{\"end\":2479,\"start\":2464},{\"end\":9605,\"start\":9591},{\"end\":10512,\"start\":10495},{\"end\":12741,\"start\":12701},{\"end\":13021,\"start\":13010},{\"end\":14604,\"start\":14559},{\"end\":16718,\"start\":16683},{\"end\":19015,\"start\":18982},{\"end\":19383,\"start\":19367},{\"end\":19725,\"start\":19707},{\"end\":22177,\"start\":22124},{\"end\":22452,\"start\":22436},{\"end\":24131,\"start\":24114},{\"end\":25647,\"start\":25630},{\"end\":27474,\"start\":27446},{\"end\":28748,\"start\":28726},{\"end\":29937,\"start\":29916},{\"end\":30683,\"start\":30664},{\"end\":31384,\"start\":31355},{\"end\":33360,\"start\":33334},{\"end\":33389,\"start\":33363},{\"end\":34527,\"start\":34486},{\"end\":35890,\"start\":35850},{\"end\":37110,\"start\":37064},{\"end\":38839,\"start\":38811},{\"end\":40174,\"start\":40144},{\"end\":41405,\"start\":41391},{\"end\":42557,\"start\":42547},{\"end\":42848,\"start\":42838},{\"end\":42898,\"start\":42888},{\"end\":42959,\"start\":42949},{\"end\":43337,\"start\":43330},{\"end\":43721,\"start\":43711},{\"end\":43741,\"start\":43731},{\"end\":43809,\"start\":43789},{\"end\":44049,\"start\":44040},{\"end\":44582,\"start\":44572},{\"end\":45360,\"start\":45349}]", "table": "[{\"end\":44570,\"start\":44051},{\"end\":45347,\"start\":44671},{\"end\":47230,\"start\":45733}]", "figure_caption": "[{\"end\":42483,\"start\":42439},{\"end\":42545,\"start\":42486},{\"end\":42836,\"start\":42559},{\"end\":42886,\"start\":42850},{\"end\":42947,\"start\":42900},{\"end\":43050,\"start\":42961},{\"end\":43328,\"start\":43053},{\"end\":43709,\"start\":43341},{\"end\":43729,\"start\":43723},{\"end\":43787,\"start\":43743},{\"end\":44038,\"start\":43812},{\"end\":44671,\"start\":44585},{\"end\":45733,\"start\":45364}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":5486,\"start\":5478},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":6132,\"start\":6123},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":11567,\"start\":11559},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":16963,\"start\":16954},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":17444,\"start\":17436},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":21492,\"start\":21484},{\"attributes\":{\"ref_id\":\"fig_9\"},\"end\":29435,\"start\":29427},{\"attributes\":{\"ref_id\":\"fig_9\"},\"end\":29517,\"start\":29508},{\"attributes\":{\"ref_id\":\"fig_9\"},\"end\":29753,\"start\":29744},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":31090,\"start\":31082},{\"end\":33590,\"start\":33582},{\"end\":33603,\"start\":33595},{\"end\":33766,\"start\":33758},{\"end\":34118,\"start\":34110},{\"attributes\":{\"ref_id\":\"fig_9\"},\"end\":34172,\"start\":34162},{\"end\":35499,\"start\":35492}]", "bib_author_first_name": "[{\"end\":47398,\"start\":47397},{\"end\":47400,\"start\":47399},{\"end\":47410,\"start\":47409},{\"end\":47412,\"start\":47411},{\"end\":47561,\"start\":47560},{\"end\":47565,\"start\":47562},{\"end\":47574,\"start\":47573},{\"end\":47586,\"start\":47585},{\"end\":47588,\"start\":47587},{\"end\":48207,\"start\":48206},{\"end\":48476,\"start\":48475},{\"end\":48497,\"start\":48496},{\"end\":48499,\"start\":48498},{\"end\":48672,\"start\":48671},{\"end\":48680,\"start\":48679},{\"end\":48691,\"start\":48690},{\"end\":48701,\"start\":48700},{\"end\":48922,\"start\":48921},{\"end\":48930,\"start\":48929},{\"end\":48941,\"start\":48940},{\"end\":48943,\"start\":48942},{\"end\":49311,\"start\":49310},{\"end\":49318,\"start\":49317},{\"end\":49327,\"start\":49326},{\"end\":49334,\"start\":49333},{\"end\":49341,\"start\":49340},{\"end\":49652,\"start\":49651},{\"end\":49654,\"start\":49653},{\"end\":49664,\"start\":49663},{\"end\":49666,\"start\":49665},{\"end\":50163,\"start\":50162},{\"end\":50170,\"start\":50169},{\"end\":50180,\"start\":50179},{\"end\":50190,\"start\":50189},{\"end\":50198,\"start\":50197},{\"end\":50207,\"start\":50206},{\"end\":50215,\"start\":50214},{\"end\":50663,\"start\":50662},{\"end\":50675,\"start\":50674},{\"end\":50683,\"start\":50682},{\"end\":50696,\"start\":50695},{\"end\":50707,\"start\":50706},{\"end\":51216,\"start\":51215},{\"end\":51229,\"start\":51228},{\"end\":51237,\"start\":51236},{\"end\":51543,\"start\":51542},{\"end\":51552,\"start\":51551},{\"end\":51556,\"start\":51553},{\"end\":51573,\"start\":51572},{\"end\":51583,\"start\":51582},{\"end\":51747,\"start\":51746},{\"end\":51761,\"start\":51760},{\"end\":51971,\"start\":51970},{\"end\":51982,\"start\":51981},{\"end\":51992,\"start\":51991},{\"end\":52000,\"start\":51999},{\"end\":52234,\"start\":52233},{\"end\":52236,\"start\":52235},{\"end\":52246,\"start\":52245},{\"end\":52255,\"start\":52254},{\"end\":52264,\"start\":52263},{\"end\":52282,\"start\":52281},{\"end\":52683,\"start\":52682},{\"end\":52685,\"start\":52684},{\"end\":52692,\"start\":52691},{\"end\":52702,\"start\":52701},{\"end\":52704,\"start\":52703},{\"end\":52990,\"start\":52989},{\"end\":53268,\"start\":53267},{\"end\":53276,\"start\":53275},{\"end\":53278,\"start\":53277},{\"end\":53495,\"start\":53494},{\"end\":53501,\"start\":53500},{\"end\":53511,\"start\":53510},{\"end\":53527,\"start\":53526},{\"end\":53766,\"start\":53765},{\"end\":53778,\"start\":53777},{\"end\":53785,\"start\":53784},{\"end\":54012,\"start\":54011},{\"end\":54014,\"start\":54013},{\"end\":54024,\"start\":54023},{\"end\":54026,\"start\":54025},{\"end\":54256,\"start\":54255},{\"end\":54258,\"start\":54257},{\"end\":54479,\"start\":54478},{\"end\":54481,\"start\":54480},{\"end\":54492,\"start\":54491},{\"end\":54681,\"start\":54680},{\"end\":54694,\"start\":54693},{\"end\":54701,\"start\":54700},{\"end\":54703,\"start\":54702},{\"end\":54712,\"start\":54711},{\"end\":54942,\"start\":54941},{\"end\":54944,\"start\":54943},{\"end\":54953,\"start\":54952},{\"end\":54955,\"start\":54954},{\"end\":55225,\"start\":55224},{\"end\":55235,\"start\":55234},{\"end\":55244,\"start\":55243},{\"end\":55246,\"start\":55245},{\"end\":55258,\"start\":55257},{\"end\":55266,\"start\":55265},{\"end\":55275,\"start\":55274},{\"end\":55296,\"start\":55295},{\"end\":55313,\"start\":55312},{\"end\":55327,\"start\":55326},{\"end\":55345,\"start\":55344},{\"end\":55356,\"start\":55355},{\"end\":55695,\"start\":55694},{\"end\":55697,\"start\":55696},{\"end\":55704,\"start\":55703},{\"end\":55713,\"start\":55712},{\"end\":55715,\"start\":55714},{\"end\":55992,\"start\":55991},{\"end\":55994,\"start\":55993},{\"end\":56001,\"start\":56000},{\"end\":56232,\"start\":56231},{\"end\":56244,\"start\":56243},{\"end\":56254,\"start\":56253},{\"end\":56262,\"start\":56261},{\"end\":56264,\"start\":56263},{\"end\":56805,\"start\":56804},{\"end\":56817,\"start\":56816},{\"end\":56827,\"start\":56826},{\"end\":56837,\"start\":56836},{\"end\":56847,\"start\":56846},{\"end\":57145,\"start\":57144},{\"end\":57154,\"start\":57153},{\"end\":57163,\"start\":57162},{\"end\":57524,\"start\":57523},{\"end\":57528,\"start\":57525},{\"end\":57538,\"start\":57537},{\"end\":57829,\"start\":57828},{\"end\":57831,\"start\":57830},{\"end\":58048,\"start\":58047},{\"end\":58060,\"start\":58059},{\"end\":58637,\"start\":58636},{\"end\":58639,\"start\":58638},{\"end\":58840,\"start\":58839},{\"end\":58852,\"start\":58851},{\"end\":58861,\"start\":58853},{\"end\":58872,\"start\":58871},{\"end\":59285,\"start\":59284},{\"end\":59298,\"start\":59297},{\"end\":59309,\"start\":59308},{\"end\":59311,\"start\":59310},{\"end\":59595,\"start\":59594},{\"end\":59607,\"start\":59606},{\"end\":59620,\"start\":59619},{\"end\":59860,\"start\":59859},{\"end\":59873,\"start\":59872},{\"end\":59882,\"start\":59881},{\"end\":59900,\"start\":59899},{\"end\":60112,\"start\":60111},{\"end\":60118,\"start\":60117},{\"end\":60127,\"start\":60126},{\"end\":60136,\"start\":60135},{\"end\":60620,\"start\":60619},{\"end\":60627,\"start\":60626},{\"end\":60633,\"start\":60632},{\"end\":60642,\"start\":60641},{\"end\":60650,\"start\":60649},{\"end\":60906,\"start\":60905},{\"end\":60915,\"start\":60914},{\"end\":60924,\"start\":60923},{\"end\":60934,\"start\":60933},{\"end\":60952,\"start\":60951},{\"end\":60962,\"start\":60961},{\"end\":61221,\"start\":61220},{\"end\":61234,\"start\":61233},{\"end\":61245,\"start\":61244},{\"end\":61254,\"start\":61253},{\"end\":61260,\"start\":61259},{\"end\":61268,\"start\":61267},{\"end\":61502,\"start\":61501},{\"end\":61514,\"start\":61513},{\"end\":61762,\"start\":61761},{\"end\":61764,\"start\":61763},{\"end\":61771,\"start\":61770},{\"end\":61779,\"start\":61778},{\"end\":61980,\"start\":61979},{\"end\":61988,\"start\":61987},{\"end\":62004,\"start\":62003},{\"end\":62006,\"start\":62005},{\"end\":62017,\"start\":62016},{\"end\":62028,\"start\":62027},{\"end\":62038,\"start\":62037},{\"end\":62046,\"start\":62045},{\"end\":62320,\"start\":62319},{\"end\":62333,\"start\":62332},{\"end\":62343,\"start\":62342},{\"end\":62353,\"start\":62352},{\"end\":62662,\"start\":62661},{\"end\":62664,\"start\":62663},{\"end\":62674,\"start\":62673},{\"end\":62676,\"start\":62675},{\"end\":62690,\"start\":62689},{\"end\":62692,\"start\":62691},{\"end\":62701,\"start\":62700},{\"end\":63040,\"start\":63039},{\"end\":63048,\"start\":63047},{\"end\":63063,\"start\":63062},{\"end\":63073,\"start\":63072},{\"end\":63075,\"start\":63074},{\"end\":63083,\"start\":63082},{\"end\":63093,\"start\":63092},{\"end\":63095,\"start\":63094},{\"end\":63108,\"start\":63107},{\"end\":63118,\"start\":63117},{\"end\":63132,\"start\":63131},{\"end\":63134,\"start\":63133},{\"end\":63147,\"start\":63146},{\"end\":63506,\"start\":63505},{\"end\":63513,\"start\":63512},{\"end\":63525,\"start\":63524},{\"end\":63534,\"start\":63533},{\"end\":63536,\"start\":63535},{\"end\":63543,\"start\":63542},{\"end\":63552,\"start\":63551},{\"end\":63563,\"start\":63562},{\"end\":63947,\"start\":63946},{\"end\":63954,\"start\":63953},{\"end\":63962,\"start\":63961},{\"end\":63971,\"start\":63970},{\"end\":63977,\"start\":63976},{\"end\":63979,\"start\":63978},{\"end\":64336,\"start\":64335},{\"end\":64342,\"start\":64341},{\"end\":64352,\"start\":64351},{\"end\":64362,\"start\":64361},{\"end\":64372,\"start\":64371},{\"end\":64379,\"start\":64378},{\"end\":64639,\"start\":64638},{\"end\":64648,\"start\":64647}]", "bib_author_last_name": "[{\"end\":47407,\"start\":47401},{\"end\":47420,\"start\":47413},{\"end\":47571,\"start\":47566},{\"end\":47583,\"start\":47575},{\"end\":47600,\"start\":47589},{\"end\":48222,\"start\":48208},{\"end\":48494,\"start\":48477},{\"end\":48505,\"start\":48500},{\"end\":48677,\"start\":48673},{\"end\":48688,\"start\":48681},{\"end\":48698,\"start\":48692},{\"end\":48713,\"start\":48702},{\"end\":48927,\"start\":48923},{\"end\":48938,\"start\":48931},{\"end\":48949,\"start\":48944},{\"end\":49315,\"start\":49312},{\"end\":49324,\"start\":49319},{\"end\":49331,\"start\":49328},{\"end\":49338,\"start\":49335},{\"end\":49344,\"start\":49342},{\"end\":49661,\"start\":49655},{\"end\":49673,\"start\":49667},{\"end\":50167,\"start\":50164},{\"end\":50177,\"start\":50171},{\"end\":50187,\"start\":50181},{\"end\":50195,\"start\":50191},{\"end\":50204,\"start\":50199},{\"end\":50212,\"start\":50208},{\"end\":50224,\"start\":50216},{\"end\":50672,\"start\":50664},{\"end\":50680,\"start\":50676},{\"end\":50693,\"start\":50684},{\"end\":50704,\"start\":50697},{\"end\":50721,\"start\":50708},{\"end\":51226,\"start\":51217},{\"end\":51234,\"start\":51230},{\"end\":51244,\"start\":51238},{\"end\":51549,\"start\":51544},{\"end\":51570,\"start\":51557},{\"end\":51580,\"start\":51574},{\"end\":51589,\"start\":51584},{\"end\":51758,\"start\":51748},{\"end\":51773,\"start\":51762},{\"end\":51979,\"start\":51972},{\"end\":51989,\"start\":51983},{\"end\":51997,\"start\":51993},{\"end\":52008,\"start\":52001},{\"end\":52243,\"start\":52237},{\"end\":52252,\"start\":52247},{\"end\":52261,\"start\":52256},{\"end\":52279,\"start\":52265},{\"end\":52287,\"start\":52283},{\"end\":52689,\"start\":52686},{\"end\":52699,\"start\":52693},{\"end\":52712,\"start\":52705},{\"end\":53000,\"start\":52991},{\"end\":53273,\"start\":53269},{\"end\":53282,\"start\":53279},{\"end\":53498,\"start\":53496},{\"end\":53508,\"start\":53502},{\"end\":53524,\"start\":53512},{\"end\":53533,\"start\":53528},{\"end\":53775,\"start\":53767},{\"end\":53782,\"start\":53779},{\"end\":53792,\"start\":53786},{\"end\":54021,\"start\":54015},{\"end\":54032,\"start\":54027},{\"end\":54267,\"start\":54259},{\"end\":54489,\"start\":54482},{\"end\":54498,\"start\":54493},{\"end\":54691,\"start\":54682},{\"end\":54698,\"start\":54695},{\"end\":54709,\"start\":54704},{\"end\":54725,\"start\":54713},{\"end\":54950,\"start\":54945},{\"end\":54966,\"start\":54956},{\"end\":55232,\"start\":55226},{\"end\":55241,\"start\":55236},{\"end\":55255,\"start\":55247},{\"end\":55263,\"start\":55259},{\"end\":55272,\"start\":55267},{\"end\":55293,\"start\":55276},{\"end\":55310,\"start\":55297},{\"end\":55324,\"start\":55314},{\"end\":55342,\"start\":55328},{\"end\":55353,\"start\":55346},{\"end\":55365,\"start\":55357},{\"end\":55701,\"start\":55698},{\"end\":55710,\"start\":55705},{\"end\":55722,\"start\":55716},{\"end\":55998,\"start\":55995},{\"end\":56004,\"start\":56002},{\"end\":56241,\"start\":56233},{\"end\":56251,\"start\":56245},{\"end\":56259,\"start\":56255},{\"end\":56268,\"start\":56265},{\"end\":56814,\"start\":56806},{\"end\":56824,\"start\":56818},{\"end\":56834,\"start\":56828},{\"end\":56844,\"start\":56838},{\"end\":56854,\"start\":56848},{\"end\":57151,\"start\":57146},{\"end\":57160,\"start\":57155},{\"end\":57170,\"start\":57164},{\"end\":57535,\"start\":57529},{\"end\":57547,\"start\":57539},{\"end\":57838,\"start\":57832},{\"end\":58057,\"start\":58049},{\"end\":58066,\"start\":58061},{\"end\":58643,\"start\":58640},{\"end\":58849,\"start\":58841},{\"end\":58869,\"start\":58862},{\"end\":58879,\"start\":58873},{\"end\":59295,\"start\":59286},{\"end\":59306,\"start\":59299},{\"end\":59314,\"start\":59312},{\"end\":59604,\"start\":59596},{\"end\":59617,\"start\":59608},{\"end\":59629,\"start\":59621},{\"end\":59870,\"start\":59861},{\"end\":59879,\"start\":59874},{\"end\":59897,\"start\":59883},{\"end\":59906,\"start\":59901},{\"end\":60115,\"start\":60113},{\"end\":60124,\"start\":60119},{\"end\":60133,\"start\":60128},{\"end\":60140,\"start\":60137},{\"end\":60624,\"start\":60621},{\"end\":60630,\"start\":60628},{\"end\":60639,\"start\":60634},{\"end\":60647,\"start\":60643},{\"end\":60654,\"start\":60651},{\"end\":60912,\"start\":60907},{\"end\":60921,\"start\":60916},{\"end\":60931,\"start\":60925},{\"end\":60949,\"start\":60935},{\"end\":60959,\"start\":60953},{\"end\":60969,\"start\":60963},{\"end\":61231,\"start\":61222},{\"end\":61242,\"start\":61235},{\"end\":61251,\"start\":61246},{\"end\":61257,\"start\":61255},{\"end\":61265,\"start\":61261},{\"end\":61274,\"start\":61269},{\"end\":61511,\"start\":61503},{\"end\":61521,\"start\":61515},{\"end\":61768,\"start\":61765},{\"end\":61776,\"start\":61772},{\"end\":61784,\"start\":61780},{\"end\":61985,\"start\":61981},{\"end\":62001,\"start\":61989},{\"end\":62014,\"start\":62007},{\"end\":62025,\"start\":62018},{\"end\":62035,\"start\":62029},{\"end\":62043,\"start\":62039},{\"end\":62054,\"start\":62047},{\"end\":62330,\"start\":62321},{\"end\":62340,\"start\":62334},{\"end\":62350,\"start\":62344},{\"end\":62357,\"start\":62354},{\"end\":62671,\"start\":62665},{\"end\":62687,\"start\":62677},{\"end\":62698,\"start\":62693},{\"end\":62709,\"start\":62702},{\"end\":63045,\"start\":63041},{\"end\":63060,\"start\":63049},{\"end\":63070,\"start\":63064},{\"end\":63080,\"start\":63076},{\"end\":63090,\"start\":63084},{\"end\":63105,\"start\":63096},{\"end\":63115,\"start\":63109},{\"end\":63129,\"start\":63119},{\"end\":63144,\"start\":63135},{\"end\":63157,\"start\":63148},{\"end\":63510,\"start\":63507},{\"end\":63522,\"start\":63514},{\"end\":63531,\"start\":63526},{\"end\":63540,\"start\":63537},{\"end\":63549,\"start\":63544},{\"end\":63560,\"start\":63553},{\"end\":63571,\"start\":63564},{\"end\":63951,\"start\":63948},{\"end\":63959,\"start\":63955},{\"end\":63968,\"start\":63963},{\"end\":63974,\"start\":63972},{\"end\":63982,\"start\":63980},{\"end\":64339,\"start\":64337},{\"end\":64349,\"start\":64343},{\"end\":64359,\"start\":64353},{\"end\":64369,\"start\":64363},{\"end\":64376,\"start\":64373},{\"end\":64388,\"start\":64380},{\"end\":64645,\"start\":64640},{\"end\":64655,\"start\":64649}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":47494,\"start\":47364},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":9333486},\"end\":48138,\"start\":47496},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":14585311},\"end\":48412,\"start\":48140},{\"attributes\":{\"id\":\"b3\"},\"end\":48613,\"start\":48414},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":8820379},\"end\":48847,\"start\":48615},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":10548729},\"end\":49250,\"start\":48849},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":4808574},\"end\":49568,\"start\":49252},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":1736602},\"end\":50067,\"start\":49570},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":15979705},\"end\":50592,\"start\":50069},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":9790585},\"end\":51137,\"start\":50594},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":2723946},\"end\":51477,\"start\":51139},{\"attributes\":{\"id\":\"b11\"},\"end\":51720,\"start\":51479},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":1915014},\"end\":51912,\"start\":51722},{\"attributes\":{\"doi\":\"arXiv:1511.06732\",\"id\":\"b13\"},\"end\":52186,\"start\":51914},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":12834606},\"end\":52592,\"start\":52188},{\"attributes\":{\"doi\":\"arXiv:1503.00075\",\"id\":\"b15\"},\"end\":52915,\"start\":52594},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":10959945},\"end\":53186,\"start\":52917},{\"attributes\":{\"doi\":\"arXiv:1206.6426\",\"id\":\"b17\"},\"end\":53454,\"start\":53188},{\"attributes\":{\"doi\":\"arXiv:1511.05493\",\"id\":\"b18\"},\"end\":53692,\"start\":53456},{\"attributes\":{\"doi\":\"arXiv:1409.0473\",\"id\":\"b19\"},\"end\":53969,\"start\":53694},{\"attributes\":{\"id\":\"b20\"},\"end\":54162,\"start\":53971},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":2332513},\"end\":54464,\"start\":54164},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":208910339},\"end\":54617,\"start\":54466},{\"attributes\":{\"doi\":\"arXiv:1805.09461\",\"id\":\"b23\"},\"end\":54914,\"start\":54619},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":207779694},\"end\":55154,\"start\":54916},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":515925},\"end\":55657,\"start\":55156},{\"attributes\":{\"id\":\"b26\"},\"end\":55858,\"start\":55659},{\"attributes\":{\"id\":\"b27\"},\"end\":56165,\"start\":55860},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":11080756},\"end\":56727,\"start\":56167},{\"attributes\":{\"doi\":\"arXiv:1506.02438\",\"id\":\"b29\"},\"end\":57064,\"start\":56729},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":538820},\"end\":57403,\"start\":57066},{\"attributes\":{\"doi\":\"arXiv:1707.02275\",\"id\":\"b31\"},\"end\":57770,\"start\":57405},{\"attributes\":{\"id\":\"b32\"},\"end\":57951,\"start\":57772},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":7164502},\"end\":58578,\"start\":57953},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":964287},\"end\":58785,\"start\":58580},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":9026666},\"end\":59230,\"start\":58787},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":7961699},\"end\":59535,\"start\":59232},{\"attributes\":{\"doi\":\"arXiv:1603.06075\",\"id\":\"b37\"},\"end\":59804,\"start\":59537},{\"attributes\":{\"doi\":\"arXiv:1612.07600\",\"id\":\"b38\"},\"end\":60090,\"start\":59806},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":11540100},\"end\":60529,\"start\":60092},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":1914494},\"end\":60836,\"start\":60531},{\"attributes\":{\"doi\":\"arXiv:1505.05969\",\"id\":\"b41\"},\"end\":61184,\"start\":60838},{\"attributes\":{\"doi\":\"arXiv:1611.01855\",\"id\":\"b42\"},\"end\":61446,\"start\":61186},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":5737841},\"end\":61718,\"start\":61448},{\"attributes\":{\"doi\":\"arXiv:1608.02715\",\"id\":\"b44\"},\"end\":61930,\"start\":61720},{\"attributes\":{\"doi\":\"arXiv:1603.06744\",\"id\":\"b45\"},\"end\":62262,\"start\":61932},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":2706277},\"end\":62579,\"start\":62264},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":1211821},\"end\":62980,\"start\":62581},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":205242740},\"end\":63419,\"start\":62982},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":2305273},\"end\":63870,\"start\":63421},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":2899486},\"end\":64280,\"start\":63872},{\"attributes\":{\"doi\":\"arXiv:1606.01541\",\"id\":\"b51\"},\"end\":64578,\"start\":64282},{\"attributes\":{\"id\":\"b52\",\"matched_paper_id\":7473831},\"end\":65011,\"start\":64580}]", "bib_title": "[{\"end\":47558,\"start\":47496},{\"end\":48204,\"start\":48140},{\"end\":48669,\"start\":48615},{\"end\":48919,\"start\":48849},{\"end\":49308,\"start\":49252},{\"end\":49649,\"start\":49570},{\"end\":50160,\"start\":50069},{\"end\":50660,\"start\":50594},{\"end\":51213,\"start\":51139},{\"end\":51744,\"start\":51722},{\"end\":52231,\"start\":52188},{\"end\":52987,\"start\":52917},{\"end\":54253,\"start\":54164},{\"end\":54476,\"start\":54466},{\"end\":54939,\"start\":54916},{\"end\":55222,\"start\":55156},{\"end\":56229,\"start\":56167},{\"end\":57142,\"start\":57066},{\"end\":58045,\"start\":57953},{\"end\":58634,\"start\":58580},{\"end\":58837,\"start\":58787},{\"end\":59282,\"start\":59232},{\"end\":60109,\"start\":60092},{\"end\":60617,\"start\":60531},{\"end\":61499,\"start\":61448},{\"end\":62317,\"start\":62264},{\"end\":62659,\"start\":62581},{\"end\":63037,\"start\":62982},{\"end\":63503,\"start\":63421},{\"end\":63944,\"start\":63872},{\"end\":64636,\"start\":64580}]", "bib_author": "[{\"end\":47409,\"start\":47397},{\"end\":47422,\"start\":47409},{\"end\":47573,\"start\":47560},{\"end\":47585,\"start\":47573},{\"end\":47602,\"start\":47585},{\"end\":48224,\"start\":48206},{\"end\":48496,\"start\":48475},{\"end\":48507,\"start\":48496},{\"end\":48679,\"start\":48671},{\"end\":48690,\"start\":48679},{\"end\":48700,\"start\":48690},{\"end\":48715,\"start\":48700},{\"end\":48929,\"start\":48921},{\"end\":48940,\"start\":48929},{\"end\":48951,\"start\":48940},{\"end\":49317,\"start\":49310},{\"end\":49326,\"start\":49317},{\"end\":49333,\"start\":49326},{\"end\":49340,\"start\":49333},{\"end\":49346,\"start\":49340},{\"end\":49663,\"start\":49651},{\"end\":49675,\"start\":49663},{\"end\":50169,\"start\":50162},{\"end\":50179,\"start\":50169},{\"end\":50189,\"start\":50179},{\"end\":50197,\"start\":50189},{\"end\":50206,\"start\":50197},{\"end\":50214,\"start\":50206},{\"end\":50226,\"start\":50214},{\"end\":50674,\"start\":50662},{\"end\":50682,\"start\":50674},{\"end\":50695,\"start\":50682},{\"end\":50706,\"start\":50695},{\"end\":50723,\"start\":50706},{\"end\":51228,\"start\":51215},{\"end\":51236,\"start\":51228},{\"end\":51246,\"start\":51236},{\"end\":51551,\"start\":51542},{\"end\":51572,\"start\":51551},{\"end\":51582,\"start\":51572},{\"end\":51591,\"start\":51582},{\"end\":51760,\"start\":51746},{\"end\":51775,\"start\":51760},{\"end\":51981,\"start\":51970},{\"end\":51991,\"start\":51981},{\"end\":51999,\"start\":51991},{\"end\":52010,\"start\":51999},{\"end\":52245,\"start\":52233},{\"end\":52254,\"start\":52245},{\"end\":52263,\"start\":52254},{\"end\":52281,\"start\":52263},{\"end\":52289,\"start\":52281},{\"end\":52691,\"start\":52682},{\"end\":52701,\"start\":52691},{\"end\":52714,\"start\":52701},{\"end\":53002,\"start\":52989},{\"end\":53275,\"start\":53267},{\"end\":53284,\"start\":53275},{\"end\":53500,\"start\":53494},{\"end\":53510,\"start\":53500},{\"end\":53526,\"start\":53510},{\"end\":53535,\"start\":53526},{\"end\":53777,\"start\":53765},{\"end\":53784,\"start\":53777},{\"end\":53794,\"start\":53784},{\"end\":54023,\"start\":54011},{\"end\":54034,\"start\":54023},{\"end\":54269,\"start\":54255},{\"end\":54491,\"start\":54478},{\"end\":54500,\"start\":54491},{\"end\":54693,\"start\":54680},{\"end\":54700,\"start\":54693},{\"end\":54711,\"start\":54700},{\"end\":54727,\"start\":54711},{\"end\":54952,\"start\":54941},{\"end\":54968,\"start\":54952},{\"end\":55234,\"start\":55224},{\"end\":55243,\"start\":55234},{\"end\":55257,\"start\":55243},{\"end\":55265,\"start\":55257},{\"end\":55274,\"start\":55265},{\"end\":55295,\"start\":55274},{\"end\":55312,\"start\":55295},{\"end\":55326,\"start\":55312},{\"end\":55344,\"start\":55326},{\"end\":55355,\"start\":55344},{\"end\":55367,\"start\":55355},{\"end\":55703,\"start\":55694},{\"end\":55712,\"start\":55703},{\"end\":55724,\"start\":55712},{\"end\":56000,\"start\":55991},{\"end\":56006,\"start\":56000},{\"end\":56243,\"start\":56231},{\"end\":56253,\"start\":56243},{\"end\":56261,\"start\":56253},{\"end\":56270,\"start\":56261},{\"end\":56816,\"start\":56804},{\"end\":56826,\"start\":56816},{\"end\":56836,\"start\":56826},{\"end\":56846,\"start\":56836},{\"end\":56856,\"start\":56846},{\"end\":57153,\"start\":57144},{\"end\":57162,\"start\":57153},{\"end\":57172,\"start\":57162},{\"end\":57537,\"start\":57523},{\"end\":57549,\"start\":57537},{\"end\":57840,\"start\":57828},{\"end\":58059,\"start\":58047},{\"end\":58068,\"start\":58059},{\"end\":58645,\"start\":58636},{\"end\":58851,\"start\":58839},{\"end\":58871,\"start\":58851},{\"end\":58881,\"start\":58871},{\"end\":59297,\"start\":59284},{\"end\":59308,\"start\":59297},{\"end\":59316,\"start\":59308},{\"end\":59606,\"start\":59594},{\"end\":59619,\"start\":59606},{\"end\":59631,\"start\":59619},{\"end\":59872,\"start\":59859},{\"end\":59881,\"start\":59872},{\"end\":59899,\"start\":59881},{\"end\":59908,\"start\":59899},{\"end\":60117,\"start\":60111},{\"end\":60126,\"start\":60117},{\"end\":60135,\"start\":60126},{\"end\":60142,\"start\":60135},{\"end\":60626,\"start\":60619},{\"end\":60632,\"start\":60626},{\"end\":60641,\"start\":60632},{\"end\":60649,\"start\":60641},{\"end\":60656,\"start\":60649},{\"end\":60914,\"start\":60905},{\"end\":60923,\"start\":60914},{\"end\":60933,\"start\":60923},{\"end\":60951,\"start\":60933},{\"end\":60961,\"start\":60951},{\"end\":60971,\"start\":60961},{\"end\":61233,\"start\":61220},{\"end\":61244,\"start\":61233},{\"end\":61253,\"start\":61244},{\"end\":61259,\"start\":61253},{\"end\":61267,\"start\":61259},{\"end\":61276,\"start\":61267},{\"end\":61513,\"start\":61501},{\"end\":61523,\"start\":61513},{\"end\":61770,\"start\":61761},{\"end\":61778,\"start\":61770},{\"end\":61786,\"start\":61778},{\"end\":61987,\"start\":61979},{\"end\":62003,\"start\":61987},{\"end\":62016,\"start\":62003},{\"end\":62027,\"start\":62016},{\"end\":62037,\"start\":62027},{\"end\":62045,\"start\":62037},{\"end\":62056,\"start\":62045},{\"end\":62332,\"start\":62319},{\"end\":62342,\"start\":62332},{\"end\":62352,\"start\":62342},{\"end\":62359,\"start\":62352},{\"end\":62673,\"start\":62661},{\"end\":62689,\"start\":62673},{\"end\":62700,\"start\":62689},{\"end\":62711,\"start\":62700},{\"end\":63047,\"start\":63039},{\"end\":63062,\"start\":63047},{\"end\":63072,\"start\":63062},{\"end\":63082,\"start\":63072},{\"end\":63092,\"start\":63082},{\"end\":63107,\"start\":63092},{\"end\":63117,\"start\":63107},{\"end\":63131,\"start\":63117},{\"end\":63146,\"start\":63131},{\"end\":63159,\"start\":63146},{\"end\":63512,\"start\":63505},{\"end\":63524,\"start\":63512},{\"end\":63533,\"start\":63524},{\"end\":63542,\"start\":63533},{\"end\":63551,\"start\":63542},{\"end\":63562,\"start\":63551},{\"end\":63573,\"start\":63562},{\"end\":63953,\"start\":63946},{\"end\":63961,\"start\":63953},{\"end\":63970,\"start\":63961},{\"end\":63976,\"start\":63970},{\"end\":63984,\"start\":63976},{\"end\":64341,\"start\":64335},{\"end\":64351,\"start\":64341},{\"end\":64361,\"start\":64351},{\"end\":64371,\"start\":64361},{\"end\":64378,\"start\":64371},{\"end\":64390,\"start\":64378},{\"end\":64647,\"start\":64638},{\"end\":64657,\"start\":64647}]", "bib_venue": "[{\"end\":47855,\"start\":47737},{\"end\":49826,\"start\":49759},{\"end\":50882,\"start\":50811},{\"end\":52359,\"start\":52332},{\"end\":53035,\"start\":53027},{\"end\":56423,\"start\":56355},{\"end\":58301,\"start\":58193},{\"end\":59022,\"start\":58960},{\"end\":60335,\"start\":60247},{\"end\":64816,\"start\":64745},{\"end\":47395,\"start\":47364},{\"end\":47735,\"start\":47602},{\"end\":48254,\"start\":48224},{\"end\":48473,\"start\":48414},{\"end\":48718,\"start\":48715},{\"end\":49027,\"start\":48951},{\"end\":49385,\"start\":49346},{\"end\":49757,\"start\":49675},{\"end\":50267,\"start\":50226},{\"end\":50809,\"start\":50723},{\"end\":51290,\"start\":51246},{\"end\":51540,\"start\":51479},{\"end\":51793,\"start\":51775},{\"end\":51968,\"start\":51914},{\"end\":52330,\"start\":52289},{\"end\":52680,\"start\":52594},{\"end\":53025,\"start\":53002},{\"end\":53265,\"start\":53188},{\"end\":53492,\"start\":53456},{\"end\":53763,\"start\":53694},{\"end\":54009,\"start\":53971},{\"end\":54291,\"start\":54269},{\"end\":54516,\"start\":54500},{\"end\":54678,\"start\":54619},{\"end\":55017,\"start\":54968},{\"end\":55373,\"start\":55367},{\"end\":55692,\"start\":55659},{\"end\":55989,\"start\":55860},{\"end\":56353,\"start\":56270},{\"end\":56802,\"start\":56729},{\"end\":57208,\"start\":57172},{\"end\":57521,\"start\":57405},{\"end\":57826,\"start\":57772},{\"end\":58191,\"start\":58068},{\"end\":58676,\"start\":58645},{\"end\":58958,\"start\":58881},{\"end\":59365,\"start\":59316},{\"end\":59592,\"start\":59537},{\"end\":59857,\"start\":59806},{\"end\":60245,\"start\":60142},{\"end\":60660,\"start\":60656},{\"end\":60903,\"start\":60838},{\"end\":61218,\"start\":61186},{\"end\":61567,\"start\":61523},{\"end\":61759,\"start\":61720},{\"end\":61977,\"start\":61932},{\"end\":62403,\"start\":62359},{\"end\":62760,\"start\":62711},{\"end\":63165,\"start\":63159},{\"end\":63602,\"start\":63573},{\"end\":64052,\"start\":63984},{\"end\":64333,\"start\":64282},{\"end\":64743,\"start\":64657}]"}}}, "year": 2023, "month": 12, "day": 17}