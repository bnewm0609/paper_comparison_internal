{"id": 257757019, "updated": "2023-10-05 02:42:40.144", "metadata": {"title": "A comprehensive evaluation of ChatGPT's zero-shot Text-to-SQL capability", "authors": "[{\"first\":\"Aiwei\",\"last\":\"Liu\",\"middle\":[]},{\"first\":\"Xuming\",\"last\":\"Hu\",\"middle\":[]},{\"first\":\"Lijie\",\"last\":\"Wen\",\"middle\":[]},{\"first\":\"Philip\",\"last\":\"Yu\",\"middle\":[\"S.\"]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2023, "month": null, "day": null}, "abstract": "This paper presents the first comprehensive analysis of ChatGPT's Text-to-SQL ability. Given the recent emergence of large-scale conversational language model ChatGPT and its impressive capabilities in both conversational abilities and code generation, we sought to evaluate its Text-to-SQL performance. We conducted experiments on 12 benchmark datasets with different languages, settings, or scenarios, and the results demonstrate that ChatGPT has strong text-to-SQL abilities. Although there is still a gap from the current state-of-the-art (SOTA) model performance, considering that the experiment was conducted in a zero-shot scenario, ChatGPT's performance is still impressive. Notably, in the ADVETA (RPL) scenario, the zero-shot ChatGPT even outperforms the SOTA model that requires fine-tuning on the Spider dataset by 4.1\\%, demonstrating its potential for use in practical applications. To support further research in related fields, we have made the data generated by ChatGPT publicly available at https://github.com/THU-BPM/chatgpt-sql.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2303.13547", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/corr/abs-2303-13547", "doi": "10.48550/arxiv.2303.13547"}}, "content": {"source": {"pdf_hash": "6034a1ed44de01ffc18cd2265223ed2bf1d216cd", "pdf_src": "Arxiv", "pdf_uri": "[\"https://export.arxiv.org/pdf/2303.13547v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "f3dad89335406d13e32ab2a18151dcb5c82dfe48", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/6034a1ed44de01ffc18cd2265223ed2bf1d216cd.txt", "contents": "\nA comprehensive evaluation of ChatGPT's zero-shot Text-to-SQL capability\n\n\nAiwei Liu \nTsinghua University\n\n\nXuming Hu \nTsinghua University\n\n\nLijie Wen \nTsinghua University\n\n\nPhilip S Yu \nTsinghua University\n\n\nUniversity of Illinois at Chicago\n\n\nA comprehensive evaluation of ChatGPT's zero-shot Text-to-SQL capability\nTo support further research in related fields, we have made the data generated by ChatGPT publicly available at https://github.com/THU-BPM/chatgpt-sql.\nThis paper presents the first comprehensive analysis of ChatGPT's Text-to-SQL ability. Given the recent emergence of large-scale conversational language model ChatGPT and its impressive capabilities in both conversational abilities and code generation, we sought to evaluate its Text-to-SQL performance. We conducted experiments on 12 benchmark datasets with different languages, settings, or scenarios, and the results demonstrate that ChatGPT has strong text-to-SQL abilities. Although there is still a gap from the current state-of-the-art (SOTA) model performance, considering that the experiment was conducted in a zero-shot scenario, ChatGPT's performance is still impressive. Notably, in the ADVETA (RPL) scenario, the zero-shot ChatGPT even outperforms the SOTA model that requires fine-tuning on the Spider dataset by 4.1%, demonstrating its potential for use in practical applications. To support further research in related fields, we have made the data generated by ChatGPT publicly available at https://github.com/THU-BPM/chatgpt-sql.\n\nIntroduction\n\nWith the increasing attention given to large-scale language models, they have become an essential component in natural language processing. As the size of pre-trained models grows, their usage is also gradually changing. Different from models such as BERT (Devlin et al., 2018) and T5 (Raffel et al., 2020), which require fine-tuning with a small amount of data, models such as GPT-3 (Brown et al., 2020), require the prompt design to generate target outputs. The recent ChatGPT 1 model, which employs Reinforcement Learning for Human Feedback (RLHF) (Christiano et al., 2017), simplifies prompt design, enabling better utilization of the zero-shot ability of large-scale pre-trained models in a conversational way. Based on this, many works 1 https://chat.openai.com/ have begun to analyze the zero-shot ability of Chat-GPT in various natural language processing tasks, such as information extraction (Wei et al., 2023), text summarization , and mathematical abilities (Frieder et al., 2023). Due to Chat-GPT's strong ability in code generation and the fact that code generation models usually require a large amount of annotated data to produce good results, a zero-shot code generation model is very important. This paper first conducts a comprehensive evaluation of ChatGPT's zero-shot performance on a challenging code generation task: Text-to-SQL.\n\nThe Text-to-SQL task involves converting user input text into SQL statements that can be executed on a database, allowing non-expert users to better access the contents of a database. The design of Text-to-SQL models is typically challenging because they need to work across different databases and consider various user text input text and database structures. Due to the complexity of the Text-to-SQL task, a comprehensive evaluation of its performance requires consideration of a variety of scenarios in addition to the classic Spider dataset (Yu et al., 2018). For example, Spider-SYN (Gan et al., 2021a) focuses on scenarios where the data schema mentioned in the user text input is synonymous with the database schema, Spider-DK (Gan et al., 2021b) considers scenarios where the input question contains additional knowledge, Spider-CG (Gan et al., 2022) emphasizes the combination generalization ability of models, and ADVETA (Pi et al., 2022) considers scenarios where column names in the database have been modified. Additionally, to better reflect real-world scenarios, SParC (Yu et al., 2019b) and CoSQL (Yu et al., 2019a) incorporate multi-turn interaction between the user and the system. Finally, to evaluate models' multilingual capabilities, CSpider (Min et al., 2019) and DuSQL (Wang et al., 2020) evaluate Text-to-SQL performance in Chinese.\n\nDuring our experiments, we evaluate the ability of ChatGPT on 12 different Text-to-SQL benchmark datasets. Based on the experimental results, we conclude the following observations:\n\n1. Compared to the current state-of-the-art (SOTA) model that uses complete training data, ChatGPT without using task-specific training data only performs 14% worse. This already demonstrates that ChatGPT is a strong zero-shot Text-to-SQL converter.\n\n2. The robustness of ChatGPT in generating SQL statements is very strong, and the performance gap between ChatGPT and the SOTA models is only 7.8% on some robustness settings of the Spider dataset, which is lower than the 14% gap on the standard Spider dataset.\n\n3. In the ADVETA (Pi et al., 2022) scenario where the column names in the database are adversarially modified, ChatGPT's performance even surpasses that of the current SOTA models by 4.1%.\n\n4. The Exact Match metric of the data generated by ChatGPT is very low because there are many different ways to express SQLs with the same purpose. Therefore, we mainly use execution accuracy as the evaluation metric.\n\nOverall, our experiments demonstrate that Chat-GPT has strong Text-to-SQL capabilities and robustness, and it outperforms SOTA models in certain scenarios.\n\n\nMethod\n\nIn order to enable ChatGPT to generate accurate SQL outputs, we utilized the prompt as shown in Figure 1. To ensure a fair demonstration of ChatGPT's Text-to-SQL capabilities, we directly adopted the Text-to-SQL prompt used in the Ope-nAI demo webwite 2 without conducting further prompt exploration. The upper half of Figure 1 represents the prompt in a single-turn Text-to-SQL scenario, where only the database and question information is required in the prompt. Meanwhile, in order to facilitate further evaluations, we emphasize in the prompt that the generated SQL statements can be executed in an SQLite database. The lower half of Figure 1 represents the prompt in a multi-turn Text-to-SQL    (Zhong et al., 2020) could achieve high code coverage from a distilled test suite of the database, which is also based on execution. Note that we do not use the main-stream exact match accuracy, as SQL queries that achieve the same goal can often be expressed in different ways, making it difficult for zero-shot ChatGPT models to achieve high exact match accuracy.\n\nBaselines. Due to our exclusive reliance on execution-based evaluation, we did not employ baselines such as RatSQL (Wang et al., 2019) and\n\nLGESQL (Cao et al., 2021), which generate only SQL skeletons without generating values. Instead, we primarily utilized three baselines: (1) PICARD (Scholak et al., 2021) is a method for constraining auto-regressive decoders of language models through incremental parsing.\n\n(2) RASAT (Qi et al., 2022) introduces relation-aware selfattention into transformer models and also utilizes constrained auto-regressive decoders.\n\n(3) RESD-SQL  proposes a ranking-enhanced encoding and skeleton-aware decoding framework to decouple the schema linking and the skeleton parsing. Among those, PICARD and RASAT are based on T5-3B (Raffel et al., 2020) model.\n\n\nMain Experiment\n\nEvaluation on Spider Dataset. In Table 1  gap in test suite accuracy, it is remarkable that ChatGPT achieved such results in a zero-shot scenario considering that it was not fine-tuned on the Spider training set.\n\nEvaluation on Spider-SYN and Spider-Realistic Datasets. Table 1 also includes a comparison of ChatGPT's performance on the Spider-SYN and Spider-Realistic datasets. The main difference between these datasets and the Spider dev set is that they eliminate the explicit appearance of the database schema in the questions. Overall, although ChatGPT still performs well on these two settings, the performance gap between ChatGPT and the original SOTA models becomes slightly larger than that on the Spider dataset. This suggests that the current models have already achieved sufficient robustness in these two scenarios.\n\nEvaluation on Spider-DK and ADVETA Datasets. In Table 2, we further compare and analyze ChatGPT's performance on Spider-DK, ADVETA (RPL), and ADVETA (ADD). We find that ChatGPT performs exceptionally well on these datasets, with very small performance gaps compared to the current SOTA models. In fact, ChatGPT outperforms all current SOTA models on ADVETA (RPL). For the Spider-DK dataset, we speculate that ChatGPT's excellent performance is due to its additional knowledge provided by the large-scale pretraining. As for scenarios such as ADVETA, where the dataset's column names undergo adversarial modifications, the poor generalization performance of current models may be due to the significant distribution difference from the original dataset. Overall, ChatGPT exhibits strong robustness in scenarios that require additional knowledge or adversarial modifications are applied to the database column names.\n\nEvaluation on Spider-CG Dataset. In Table   Methods    3, we further analyze ChatGPT's ability in the compositional generalization scenario. We found that in Spider-CG (SUB), SQL substructures are replaced to form combinations that do not exist in the training set. In this scenario, ChatGPT even outperforms the original Spider dev set. Even on the more challenging Spider-CG (APP) dataset, ChatGPT achieves strong performance, and the performance gap with SOTA models is relatively smaller than that on the original Spider dataset. Overall, since ChatGPT is a zero-shot model, it is not as affected by compositional generalization as the SOTA models. Overall, zero-shot models have greater advantages in the compositional generalization setting.\n\nEvaluation on multi-turn Text-to-SQL scenarios. Given ChatGPT's strong contextual modeling ability, we further evaluate its performance on multi-turn Text-to-SQL scenarios: SPARC and COSQL. As shown in Table 4, ChatGPT exhibits strong multi-turn Text-to-SQL ability. Although there is still a gap compared to the current SOTA models, the gap is relatively smaller compared to the single-turn Spider dataset. Meanwhile, Chat-GPT also performs better on CoSQL datasets with more average interactions, which also indicates that ChatGPT's strong contextual modeling ability is very helpful for multi-turn Text-to-SQL.\n\nEvaluation on Chinese Text-to-SQL scenarios.\n\nWe further evaluate ChatGPT's Text-to-SQL ability on other languages in Table 5. The experiments are mainly conducted on two datasets, CSpider and DuSQL, where only the questions are in Chinese for CSpider and both the schema names and questions are in Chinese for DuSQL. The results show that while ChatGPT performs well in the Chinese Text-to-SQL scenario, there is still a performance gap compared to the English Text-to-SQL scenario. Moreover, the performance is even worse when the table names and column names are also in Chinese, with a large number of generated SQL queries being non-executable and a lower execution accuracy. This suggests the cross-lingual generalization ability of ChatGPT requires further improvement.\n\n\nCase Study\n\nIn Table 6, we present four typical prediction errors made by ChatGPT on the Spider dev dataset. The first error case shows that ChatGPT tends to design JOIN statements more finely by using LEFT JOIN, but this level of granularity is not present in the original Spider dev dataset. The second error case arises from ChatGPT's confusion regarding the database structure, and it is not clear which column the term \"full name\" specifically refers to. The third example's error was due to the generated SQL statement lacking correct semantic interpretation, resulting in incorrect output for the \"where\" clauses with nested SQL statements. The fourth case of error is due to errors in copying specific values, where the case sensitivity of the original value was not preserved when regenerating the value. In summary, ChatGPT's errors mostly occur in small details, and some of these issues can be addressed and improved in later stages of development, such as in the first, third, and fourth cases. However, for errors like the second case, which indicate a lack of understanding of the database schema, further improvements to the model's ability may be necessary to resolve them.\n\n\nRelated Work\n\nText-to-SQL is an important semantic parsing task that converts natural language questions posed by  users into SQL statements that can be executed on a database. On the classic Spider dataset (Yu et al., 2018), many classic works such as RatSQL (Wang et al., 2019) and LGESQL (Cao et al., 2021) have achieved excellent results. Since Text-to-SQL is a very complex task involving both user input questions and database structure, the robustness of the model is crucial. To further explore this issue, Gan et al. (2021a) proposed the Spider-SYN dataset to evaluate the robustness of models under synonym substitution scenarios. Some works, such as Proton  and ISESL-SQL (Liu et al., 2022), are also devoted to improving the robustness of models in this scenario. Meanwhile, many works explore the robustness of the Textto-SQL task in other scenarios. The Spider-DK dataset (Gan et al., 2021b) evaluates the robustness of models in scenarios requiring additional knowl-edge. The Spider-Realistic dataset (Deng et al., 2020) removes the explicit appearance of dataset schema information in user questions, thereby increasing the difficulty of the original task. The Spider-CG dataset (Gan et al., 2022) evaluates the robustness of models in compositional generalization scenarios. The ADVETA dataset (Pi et al., 2022) evaluates the robustness of models in scenarios involving adversarial modifications of database table information. In addition, to verify the robustness of models in cross-lingual scenarios, CSpider (Min et al., 2019) and DuSQL (Wang et al., 2020) have been proposed to evaluate the robustness of models in the Chinese language. To evaluate the performance of Text-to-SQL in more realistic scenarios, SParC (Yu et al., 2019b) and CoSQL (Yu et al., 2019a) have been proposed to evaluate the performance of multi-turn Text-to-SQL. Models such as STAR (Cai et al., 2022) and CQR-SQL (Xiao et al., 2022) have also achieved good results in this scenario.\n\nCurrently, several methods have been attempted to explore the improvement of large-scale language models for Text-to-SQL models. The PICARD (Scholak et al., 2021) and RASAT (Qi et al., 2022) utilize the T5-3B model, but still require the training data for fine-tuning. Rajkumar et al. (2022) investigated the Text-to-SQL capabilities of the GPT3 model in a zero-shot setting. Cheng et al. (2022) proposed the BINDER model based on the GPT3 codex, which has similar Text-to-SQL generation capabilities with the need for in-context exemplar annotations. However, these works do not provide a comprehensive evaluation of Textto-SQL and are limited to a few datasets without other robustness settings. In this work, we are the first to evaluate the comprehensive Text-to-SQL capabilities of ChatGPT.\n\n\nConclusion\n\nIn this work, we conducted a comprehensive analysis of ChatGPT's zero-shot ability in Text-to-SQL. We found that even without using any training data, ChatGPT still has strong Text-to-SQL ability, although there is still some gap compared to the current SOTA models. Additionally, ChatGPT demonstrated strong robustness, performing relatively better on most robustness benchmarks and even surpassing the current SOTA models on the ADVETA benchmark. Although this paper has made some findings, we only utilize a common prompt to eval-uate ChatGPT's ability. And in future work, better prompts could be designed to explore ChatGPT's Text-to-SQL ability.\n\n\nFuture work\n\nIn future work, we will primarily consider the following two directions to further explore ChatGPT's capabilities in the Text-to-SQL task. Firstly, we will conduct more interactions with ChatGPT to address the issue of generating non-executable SQL statements. We can design ChatGPT to engage in multi-turn dialogues with the provided database error messages to further ensure the validity of generated SQL statements. Secondly, we will add more highly correlated in-context examples to the prompt to enhance ChatGPT's ability to generate Text-to-SQL.\n\nFigure 1 :\n12 https://platform.openai.com/examples/default-sqltranslate ### Complete sqlite SQL query only and with no explanation ### Sqlite SQL tables, with their properties: # # AREA_CODE_STATE(area_code,state); # CONTESTANTS(contestant_number,contestant_name); # VOTES(vote_id,phone_number,state,contestant_number,created). # ### Return the names of the contestants whose names contain the substring 'Al' . SELECT SELECT contestant_name from contestants where contestant_name like %al% ### Complete sqlite SQL query only and with no explanation ### Sqlite SQL tables, with their properties: # # airlines(uid,Airline,Abbreviation,Country); # airports(City,AirportCode,AirportName,Country,CountryAbbrev); # flights(Airline,FlightNo,SourceAirport,DestAirport). # ### What are all the abbreviations? SELECT SELECT * FROM AIRLINES ### Complete sqlite SQL query only and with no explanation ### Sqlite SQL tables, with their properties: # # airlines(uid,Airline,Abbreviation,Country); # airports(City,AirportCode,AirportName,Country,CountryAbbrev); # flights(Airline,FlightNo,SourceAirport,DestAirport). # ### What are all the abbreviations? SELECT ### What is the abbreviation for Jetblue Airways? SELECT SELECT * FROM AIRLINES WHERE Airline = \"JetBlue Airways\" ### What is the country corresponding it? SELECT SELECT Country FROM AIRLINES WHERE Airline = \"JetBlue Airways\" Example prompts for Text-to-SQL using ChatGPT. The prompt at the top is for a single-turn scenario, while the one below is for multi-turn scenarios where only new questions are added in each interaction. scenario, where the prompt for the first interaction is the same as that in the single-turn scenario, and for subsequent interactions, only the new questions are required. We conduct extensive experiments on twelve public benchmark datasets as follows: (1) Spider (Yu et al., 2018) is a large-scale cross-domain Text-to-SQL benchmark. It contains 8659 training samples across 146 databases and 1034 evaluation samples across 20 databases. (2) Spider-SYN (Gan et al., 2021a) is a challenging variant of the Spider evaluation dataset. Spider-SYN is constructed by manually modifying natural language questions with synonym substitutions. (3) Spider-DK (Gan et al., 2021b) is a humancurated dataset based on Spider, which samples 535 question-SQL pairs across 10 databases from the Spider development set and modifies them to incorporate the domain knowledge. (4) Spider-Realistic (Deng et al., 2020) is a new evaluation set based on the Spider dev set with explicit mentions of column names removed, which contains 508 samples. (5) Spider-CG(SUB)\n\n\nLEFT JOIN concert ON stadium.Stadium_ID = concert.Stadium_ID GROUP BY stadium.Name; Gold: SELECT T2.name , count(*) FROM concert AS T1 JOIN stadium AS T2 ON T1.stadium_id = T2.stadium_id GROUP BY T1.stadium_id Question:How many car models were produced by the maker with full name American Motor Company? ChatGPT: SELECT COUNT(*) FROM model_list WHERE Maker = 'American Motor Company' Gold: SELECT count(*) FROM CAR_MAKERS AS T1 JOIN model_list AS T2 ON T1.Id = T2.Maker WHERE T1.FullName = 'American Motor Company'; Question: How many cars have a larger accelerate than the car with the largest horsepower? ChatGPT: SELECT COUNT(*) FROM cars_data WHERE Accelerate > (SELECT MAX(Horsepower) FROM cars_data) Gold: SELECT COUNT(*) FROM CARS_DATA WHERE Accelerate > (SELECT Accelerate FROM CARS_DATA ORDER BY Horsepower DESC LIMIT 1); Question: What is the abbreviation of Airline \"JetBlue Airways\"? ChatGPT: SELECT Abbreviation FROM airlines WHERE Airline = 'Jetblue Airways' ; Gold: SELECT Abbreviation FROM AIRLINES WHERE Airline = \"JetBlue Airways\";\n\n\nTable 1: Comparison of the performance of ChatGPT and other models on Spider, Spider-SYN, and Spider-Realistic datasets.SPIDER \nSPIDER-SYN \nSPIDER-REALISTIC \n\nVA \nEX \nTS \nVA \nEX \nTS \nVA \nEX \nTS \nT5-3B + PICARD \n98.4 \n79.3 \n69.4 98.2 \n69.8 \n61.8 97.1 \n71.4 \n61.7 \nRASAT + PICARD \n98.8 \n80.5 \n70.3 98.3 \n70.7 \n62.4 97.4 \n71.9 \n62.6 \nRESDSQL-3B + NatSQL 99.1 \n84.1 \n73.5 98.8 \n76.9 \n66.8 98.4 \n81.9 \n70.1 \nChatGPT \n97.7 70.1(14\u2193) 60.1 96.2 58.6(18.3\u2193) 48.5 96.8 63.4(18.5 \u2193) 49.2 \n\nMethods / Datasets \nSPIDER-DK \nADVETA(RPL) \nADVETA(ADD) \n\nVA \nEX \nTS VA \nEX \nTS VA \nEX \nTS \nT5-3B + PICARD \n97.8 \n62.5 \n-\n92.7 \n50.6 \n-\n97.2 \n69.4 \n-\nRASAT + PICARD \n98.5 \n63.9 \n-\n92.9 \n51.5 \n-\n97.4 \n70.7 \n-\nRESDSQL-3B + NatSQL 98.8 \n66.0 \n-\n93.9 \n54.4 \n-\n97.9 \n71.9 \n-\nChatGPT \n96.4 62.6(3.4 \u2193) \n-\n91.4 58.5(4.1 \u2191) \n-\n93.1 68.1(3.8 \u2193) \n-\n\n\n\nTable 2 :\n2Performance of different methods on the Spider-DK, ADVETA(RPL) and ADVETA(ADD) benchmark datasets.and Spider-CG(APP)(Gan et al., 2022) are two evaluation datasets to measure the compositional generalization of models, which is constructed by sub-sentence substitution between different examples and appending a sub-sentence into another sentence separately. (6) ADVETA(rpl) and ADVETA(add)(Pi et al., 2022) are two challenging test datasets for the Spider dataset which are composed of adversarial replacements of column names and the addition of new column names, respectively. (7) CSpider(Min et al., 2019) dataset is constructed by translating Spider into Chinese, which is the same size as the origin Spider dataset (8) DuSQL(Wang et al., 2020) is a larger scale Chinese Text-to-SQL dataset with 23,797 question/SQL pairs. (9) SParC(Yu et al., 2019b) and CoSQL(Yu et al., 2019a) are two multi-turn Text-to-SQL dataset with 1625 and 1007 questions in the dev set separately.Evaluation Metrics. We mainly adopt three \nevaluation metrics which are valid SQL (VA), \nexecution accuracy(EX), and test-suite accuracy \n(TS). Valid SQL (VA) is the proportion of SQL \nstatements that can be executed successfully. \nExecution accuracy (EX) is the proportion of data \nwhere the execution results match the standard \nSQL statements. Test-suite accuracy (TS) \n\nTable 3 :\n3Performance of different methods on the Spider-CG(SUB) and Spider-CG(APP) benchmark datasets.\n\nTable 4 :\n4The performance of ChatGPT on two multiturn Text-to-SQL datasets: SParC and CoSQL.Methods / Datasets \nCSPIDER \nDUSQL \n\nVA \nEX VA EX \nChatGPT \n96.0 65.1 82.7 53.7 \n\n\n\nTable 5 :\n5The performance of ChatGPT on two Chinese Text-to-SQL datasets: CSpider and DuSQL.\n\nTable 6 :\n6Case study: We selected four cases of incorrect predictions generated by ChatGPT on the Spider development set for analysis.\n\nLanguage models are few-shot learners. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Advances in neural information processing systems. 33Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems, 33:1877-1901.\n\nStar: Sql guided pretraining for context-dependent text-to-sql parsing. Zefeng Cai, Xiangyu Li, Binyuan Hui, Min Yang, Bowen Li, Binhua Li, Zheng Cao, Weijie Li, Fei Huang, Luo Si, arXiv:2210.11888arXiv preprintZefeng Cai, Xiangyu Li, Binyuan Hui, Min Yang, Bowen Li, Binhua Li, Zheng Cao, Weijie Li, Fei Huang, Luo Si, et al. 2022. Star: Sql guided pre- training for context-dependent text-to-sql parsing. arXiv preprint arXiv:2210.11888.\n\nLgesql: line graph enhanced text-to-sql model with mixed local and nonlocal relations. Ruisheng Cao, Lu Chen, Zhi Chen, Yanbin Zhao, Su Zhu, Kai Yu, arXiv:2106.01093arXiv preprintRuisheng Cao, Lu Chen, Zhi Chen, Yanbin Zhao, Su Zhu, and Kai Yu. 2021. Lgesql: line graph en- hanced text-to-sql model with mixed local and non- local relations. arXiv preprint arXiv:2106.01093.\n\nBinding language models in symbolic languages. Zhoujun Cheng, Tianbao Xie, Peng Shi, Chengzu Li, Rahul Nadkarni, Yushi Hu, Caiming Xiong, Dragomir Radev, Mari Ostendorf, Luke Zettlemoyer, arXiv:2210.02875arXiv preprintZhoujun Cheng, Tianbao Xie, Peng Shi, Chengzu Li, Rahul Nadkarni, Yushi Hu, Caiming Xiong, Dragomir Radev, Mari Ostendorf, Luke Zettlemoyer, et al. 2022. Binding language models in symbolic languages. arXiv preprint arXiv:2210.02875.\n\nDeep reinforcement learning from human preferences. Advances in neural information processing systems. Jan Paul F Christiano, Tom Leike, Miljan Brown, Shane Martic, Dario Legg, Amodei, 30Paul F Christiano, Jan Leike, Tom Brown, Miljan Mar- tic, Shane Legg, and Dario Amodei. 2017. Deep re- inforcement learning from human preferences. Ad- vances in neural information processing systems, 30.\n\nXiang Deng, Ahmed Hassan Awadallah, Christopher Meek, Oleksandr Polozov, Huan Sun, Matthew Richardson, arXiv:2010.127732020. Structure-grounded pretraining for text-to-sql. arXiv preprintXiang Deng, Ahmed Hassan Awadallah, Christopher Meek, Oleksandr Polozov, Huan Sun, and Matthew Richardson. 2020. Structure-grounded pretraining for text-to-sql. arXiv preprint arXiv:2010.12773.\n\nJacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, arXiv:1810.04805Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprintJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for language understand- ing. arXiv preprint arXiv:1810.04805.\n\nSimon Frieder, Luca Pinchetti, Ryan-Rhys Griffiths, Tommaso Salvatori, Thomas Lukasiewicz, arXiv:2301.13867Philipp Christian Petersen, Alexis Chevalier, and Julius Berner. 2023. Mathematical capabilities of chatgpt. arXiv preprintSimon Frieder, Luca Pinchetti, Ryan-Rhys Grif- fiths, Tommaso Salvatori, Thomas Lukasiewicz, Philipp Christian Petersen, Alexis Chevalier, and Julius Berner. 2023. Mathematical capabilities of chatgpt. arXiv preprint arXiv:2301.13867.\n\nMeasuring and improving compositional generalization in text-to-sql via component alignment. Yujian Gan, Xinyun Chen, Qiuping Huang, Matthew Purver, 10.48550/ARXIV.2205.02054Yujian Gan, Xinyun Chen, Qiuping Huang, and Matthew Purver. 2022. Measuring and improving compositional generalization in text-to-sql via com- ponent alignment.\n\nTowards robustness of textto-sql models against synonym substitution. Yujian Gan, Xinyun Chen, Qiuping Huang, Matthew Purver, R John, Jinxia Woodward, Pengsheng Xie, Huang, Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing. the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language ProcessingLong Papers1Yujian Gan, Xinyun Chen, Qiuping Huang, Matthew Purver, John R Woodward, Jinxia Xie, and Peng- sheng Huang. 2021a. Towards robustness of text- to-sql models against synonym substitution. In Pro- ceedings of the 59th Annual Meeting of the Associa- tion for Computational Linguistics and the 11th In- ternational Joint Conference on Natural Language Processing (Volume 1: Long Papers), pages 2505- 2515.\n\nExploring underexplored limitations of cross-domain text-to-sql generalization. Yujian Gan, Xinyun Chen, Matthew Purver, arXiv:2109.05157arXiv preprintYujian Gan, Xinyun Chen, and Matthew Purver. 2021b. Exploring underexplored limitations of cross-domain text-to-sql generalization. arXiv preprint arXiv:2109.05157.\n\nDecoupling the skeleton parsing and schema linking for text-to-sql. Haoyang Li, Jing Zhang, Cuiping Li, Hong Chen, arXiv:2302.05965arXiv preprintHaoyang Li, Jing Zhang, Cuiping Li, and Hong Chen. 2023. Decoupling the skeleton parsing and schema linking for text-to-sql. arXiv preprint arXiv:2302.05965.\n\nSemantic enhanced text-to-sql parsing via iteratively learning schema linking graph. Aiwei Liu, Xuming Hu, Li Lin, Lijie Wen, Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. the 28th ACM SIGKDD Conference on Knowledge Discovery and Data MiningAiwei Liu, Xuming Hu, Li Lin, and Lijie Wen. 2022. Semantic enhanced text-to-sql parsing via iteratively learning schema linking graph. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, pages 1021-1030.\n\nA pilot study for chinese sql semantic parsing. Qingkai Min, Yuefeng Shi, Yue Zhang, arXiv:1909.13293arXiv preprintQingkai Min, Yuefeng Shi, and Yue Zhang. 2019. A pilot study for chinese sql semantic parsing. arXiv preprint arXiv:1909.13293.\n\nTowards robustness of text-to-SQL models against natural and realistic adversarial table perturbation. Xinyu Pi, Bing Wang, Yan Gao, Jiaqi Guo, Zhoujun Li, Jian-Guang Lou, 10.18653/v1/2022.acl-long.142Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics. the 60th Annual Meeting of the Association for Computational LinguisticsDublin, IrelandLong Papers1Association for Computational LinguisticsXinyu Pi, Bing Wang, Yan Gao, Jiaqi Guo, Zhoujun Li, and Jian-Guang Lou. 2022. Towards robustness of text-to-SQL models against natural and realistic adversarial table perturbation. In Proceedings of the 60th Annual Meeting of the Association for Compu- tational Linguistics (Volume 1: Long Papers), pages 2007-2022, Dublin, Ireland. Association for Com- putational Linguistics.\n\nRasat: Integrating relational structures into pretrained seq2seq model for text-tosql. Jiexing Qi, Jingyao Tang, Ziwei He, Xiangpeng Wan, Chenghu Zhou, Xinbing Wang, Quanshi Zhang, Zhouhan Lin, arXiv:2205.06983arXiv preprintJiexing Qi, Jingyao Tang, Ziwei He, Xiangpeng Wan, Chenghu Zhou, Xinbing Wang, Quanshi Zhang, and Zhouhan Lin. 2022. Rasat: Integrating relational structures into pretrained seq2seq model for text-to- sql. arXiv preprint arXiv:2205.06983.\n\nExploring the limits of transfer learning with a unified text-to-text transformer. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J Liu, The Journal of Machine Learning Research. 211Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J Liu. 2020. Exploring the limits of transfer learning with a unified text-to-text trans- former. The Journal of Machine Learning Research, 21(1):5485-5551.\n\nEvaluating the text-to-sql capabilities of large language models. Nitarshan Rajkumar, Raymond Li, Dzmitry Bahdanau, arXiv:2204.00498arXiv preprintNitarshan Rajkumar, Raymond Li, and Dzmitry Bah- danau. 2022. Evaluating the text-to-sql capabil- ities of large language models. arXiv preprint arXiv:2204.00498.\n\nPicard: Parsing incrementally for constrained auto-regressive decoding from language models. Torsten Scholak, Nathan Schucher, Dzmitry Bahdanau, arXiv:2109.05093arXiv preprintTorsten Scholak, Nathan Schucher, and Dzmitry Bah- danau. 2021. Picard: Parsing incrementally for constrained auto-regressive decoding from language models. arXiv preprint arXiv:2109.05093.\n\nRat-sql: Relation-aware schema encoding and linking for text-to-sql parsers. Bailin Wang, Richard Shin, Xiaodong Liu, Oleksandr Polozov, Matthew Richardson, arXiv:1911.04942arXiv preprintBailin Wang, Richard Shin, Xiaodong Liu, Olek- sandr Polozov, and Matthew Richardson. 2019. Rat-sql: Relation-aware schema encoding and linking for text-to-sql parsers. arXiv preprint arXiv:1911.04942.\n\nJiaan Wang, Yunlong Liang, Fandong Meng, Zhixu Li, Jianfeng Qu, Jie Zhou, arXiv:2302.14229Crosslingual summarization via chatgpt. arXiv preprintJiaan Wang, Yunlong Liang, Fandong Meng, Zhixu Li, Jianfeng Qu, and Jie Zhou. 2023. Cross- lingual summarization via chatgpt. arXiv preprint arXiv:2302.14229.\n\nProton: Probing schema linking information from pre-trained language models for text-to-sql parsing. Lihan Wang, Binyuan Bowen Qin, Bowen Hui, Min Li, Bailin Yang, Binhua Wang, Jian Li, Fei Sun, Luo Huang, Si, Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining. the 28th ACM SIGKDD Conference on Knowledge Discovery and Data MiningLihan Wang, Bowen Qin, Binyuan Hui, Bowen Li, Min Yang, Bailin Wang, Binhua Li, Jian Sun, Fei Huang, Luo Si, et al. 2022. Proton: Probing schema link- ing information from pre-trained language models for text-to-sql parsing. In Proceedings of the 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, pages 1889-1898.\n\nDusql: A large-scale and pragmatic chinese text-tosql dataset. Lijie Wang, Ao Zhang, Kun Wu, Ke Sun, Zhenghua Li, Hua Wu, Min Zhang, Haifeng Wang, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)Lijie Wang, Ao Zhang, Kun Wu, Ke Sun, Zhenghua Li, Hua Wu, Min Zhang, and Haifeng Wang. 2020. Dusql: A large-scale and pragmatic chinese text-to- sql dataset. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Process- ing (EMNLP), pages 6923-6935.\n\nZeroshot information extraction via chatting with chatgpt. Xiang Wei, Xingyu Cui, Ning Cheng, Xiaobin Wang, Xin Zhang, Shen Huang, Pengjun Xie, Jinan Xu, Yufeng Chen, Meishan Zhang, arXiv:2302.10205arXiv preprintXiang Wei, Xingyu Cui, Ning Cheng, Xiaobin Wang, Xin Zhang, Shen Huang, Pengjun Xie, Jinan Xu, Yufeng Chen, Meishan Zhang, et al. 2023. Zero- shot information extraction via chatting with chatgpt. arXiv preprint arXiv:2302.10205.\n\nCqr-sql: Conversational question reformulation enhanced context-dependent text-to-sql parsers. Dongling Xiao, Linzheng Chai, Qian-Wen Zhang, Zhao Yan, Zhoujun Li, Yunbo Cao, arXiv:2205.07686arXiv preprintDongling Xiao, Linzheng Chai, Qian-Wen Zhang, Zhao Yan, Zhoujun Li, and Yunbo Cao. 2022. Cqr-sql: Conversational question reformulation en- hanced context-dependent text-to-sql parsers. arXiv preprint arXiv:2205.07686.\n\nCosql: A conversational text-to-sql challenge towards cross-domain natural language interfaces to databases. Tao Yu, Rui Zhang, Yang He, Suyi Er, Eric Li, Bo Xue, Pang, Victoria Xi, Yi Lin, Tianze Chern Tan, Zihan Shi, Li, arXiv:1909.05378arXiv preprintTao Yu, Rui Zhang, He Yang Er, Suyi Li, Eric Xue, Bo Pang, Xi Victoria Lin, Yi Chern Tan, Tianze Shi, Zihan Li, et al. 2019a. Cosql: A conversational text-to-sql challenge towards cross-domain natural language interfaces to databases. arXiv preprint arXiv:1909.05378.\n\nSpider: A large-scale human-labeled dataset for complex and cross-domain semantic parsing and text-to-sql task. Tao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga, Dongxu Wang, Zifan Li, James Ma, Irene Li, Qingning Yao, Shanelle Roman, arXiv:1809.08887arXiv preprintTao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga, Dongxu Wang, Zifan Li, James Ma, Irene Li, Qingn- ing Yao, Shanelle Roman, et al. 2018. Spider: A large-scale human-labeled dataset for complex and cross-domain semantic parsing and text-to-sql task. arXiv preprint arXiv:1809.08887.\n\nTao Yu, Rui Zhang, Michihiro Yasunaga, Yi Chern Tan, Xi Victoria Lin, Suyi Li, Heyang Er, Irene Li, Bo Pang, Tao Chen, arXiv:1906.02285Sparc: Crossdomain semantic parsing in context. arXiv preprintTao Yu, Rui Zhang, Michihiro Yasunaga, Yi Chern Tan, Xi Victoria Lin, Suyi Li, Heyang Er, Irene Li, Bo Pang, Tao Chen, et al. 2019b. Sparc: Cross- domain semantic parsing in context. arXiv preprint arXiv:1906.02285.\n\nSemantic evaluation for text-to-sql with distilled test suites. Ruiqi Zhong, Tao Yu, Dan Klein, arXiv:2010.02840arXiv preprintRuiqi Zhong, Tao Yu, and Dan Klein. 2020. Seman- tic evaluation for text-to-sql with distilled test suites. arXiv preprint arXiv:2010.02840.\n", "annotations": {"author": "[{\"end\":108,\"start\":76},{\"end\":141,\"start\":109},{\"end\":174,\"start\":142},{\"end\":245,\"start\":175}]", "publisher": null, "author_last_name": "[{\"end\":85,\"start\":82},{\"end\":118,\"start\":116},{\"end\":151,\"start\":148},{\"end\":186,\"start\":184}]", "author_first_name": "[{\"end\":81,\"start\":76},{\"end\":115,\"start\":109},{\"end\":147,\"start\":142},{\"end\":181,\"start\":175},{\"end\":183,\"start\":182}]", "author_affiliation": "[{\"end\":107,\"start\":87},{\"end\":140,\"start\":120},{\"end\":173,\"start\":153},{\"end\":208,\"start\":188},{\"end\":244,\"start\":210}]", "title": "[{\"end\":73,\"start\":1},{\"end\":318,\"start\":246}]", "venue": null, "abstract": "[{\"end\":1518,\"start\":471}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b6\"},\"end\":1811,\"start\":1790},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":1840,\"start\":1819},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":1938,\"start\":1918},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":2110,\"start\":2085},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":2454,\"start\":2436},{\"end\":2526,\"start\":2504},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":3452,\"start\":3435},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3497,\"start\":3478},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":3643,\"start\":3624},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":3748,\"start\":3730},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":3838,\"start\":3821},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":3992,\"start\":3974},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":4021,\"start\":4003},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":4172,\"start\":4154},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":4202,\"start\":4183},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":4980,\"start\":4963},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":6241,\"start\":6221},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":6722,\"start\":6703},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":6753,\"start\":6735},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":6896,\"start\":6875},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":7028,\"start\":7011},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":7366,\"start\":7345},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":12700,\"start\":12683},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":12755,\"start\":12736},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":12785,\"start\":12767},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":13009,\"start\":12991},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":13177,\"start\":13159},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":13381,\"start\":13362},{\"end\":13511,\"start\":13492},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":13689,\"start\":13671},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":13804,\"start\":13787},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":14022,\"start\":14004},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":14052,\"start\":14033},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":14230,\"start\":14212},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":14259,\"start\":14241},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":14372,\"start\":14354},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":14404,\"start\":14385},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":14618,\"start\":14596},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":14646,\"start\":14629},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":14747,\"start\":14725},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":14851,\"start\":14832},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":21129,\"start\":21111},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":21401,\"start\":21384},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":21603,\"start\":21585},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":21742,\"start\":21724},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":21849,\"start\":21831},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":21877,\"start\":21859}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":19107,\"start\":16485},{\"attributes\":{\"id\":\"fig_1\"},\"end\":20160,\"start\":19108},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":20982,\"start\":20161},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":22344,\"start\":20983},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":22450,\"start\":22345},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":22627,\"start\":22451},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":22722,\"start\":22628},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":22859,\"start\":22723}]", "paragraph": "[{\"end\":2887,\"start\":1534},{\"end\":4247,\"start\":2889},{\"end\":4430,\"start\":4249},{\"end\":4681,\"start\":4432},{\"end\":4944,\"start\":4683},{\"end\":5134,\"start\":4946},{\"end\":5353,\"start\":5136},{\"end\":5510,\"start\":5355},{\"end\":6586,\"start\":5521},{\"end\":6726,\"start\":6588},{\"end\":6999,\"start\":6728},{\"end\":7148,\"start\":7001},{\"end\":7373,\"start\":7150},{\"end\":7605,\"start\":7393},{\"end\":8222,\"start\":7607},{\"end\":9138,\"start\":8224},{\"end\":9887,\"start\":9140},{\"end\":10502,\"start\":9889},{\"end\":10548,\"start\":10504},{\"end\":11280,\"start\":10550},{\"end\":12473,\"start\":11295},{\"end\":14454,\"start\":12490},{\"end\":15251,\"start\":14456},{\"end\":15917,\"start\":15266},{\"end\":16484,\"start\":15933}]", "formula": null, "table_ref": "[{\"end\":7433,\"start\":7426},{\"end\":7670,\"start\":7663},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":8279,\"start\":8272},{\"end\":9191,\"start\":9176},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":10098,\"start\":10091},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":10629,\"start\":10622},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":11305,\"start\":11298}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1532,\"start\":1520},{\"attributes\":{\"n\":\"2\"},\"end\":5519,\"start\":5513},{\"attributes\":{\"n\":\"3.2\"},\"end\":7391,\"start\":7376},{\"attributes\":{\"n\":\"3.3\"},\"end\":11293,\"start\":11283},{\"attributes\":{\"n\":\"4\"},\"end\":12488,\"start\":12476},{\"attributes\":{\"n\":\"5\"},\"end\":15264,\"start\":15254},{\"attributes\":{\"n\":\"6\"},\"end\":15931,\"start\":15920},{\"end\":16496,\"start\":16486},{\"end\":20993,\"start\":20984},{\"end\":22355,\"start\":22346},{\"end\":22461,\"start\":22452},{\"end\":22638,\"start\":22629},{\"end\":22733,\"start\":22724}]", "table": "[{\"end\":20982,\"start\":20283},{\"end\":22344,\"start\":21972},{\"end\":22627,\"start\":22545}]", "figure_caption": "[{\"end\":19107,\"start\":16498},{\"end\":20160,\"start\":19110},{\"end\":20283,\"start\":20163},{\"end\":21972,\"start\":20995},{\"end\":22450,\"start\":22357},{\"end\":22545,\"start\":22463},{\"end\":22722,\"start\":22640},{\"end\":22859,\"start\":22735}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":5625,\"start\":5617},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":5848,\"start\":5840},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":6167,\"start\":6159}]", "bib_author_first_name": "[{\"end\":22903,\"start\":22900},{\"end\":22919,\"start\":22911},{\"end\":22930,\"start\":22926},{\"end\":22945,\"start\":22938},{\"end\":22960,\"start\":22955},{\"end\":22962,\"start\":22961},{\"end\":22979,\"start\":22971},{\"end\":22996,\"start\":22990},{\"end\":23016,\"start\":23010},{\"end\":23030,\"start\":23024},{\"end\":23045,\"start\":23039},{\"end\":23457,\"start\":23451},{\"end\":23470,\"start\":23463},{\"end\":23482,\"start\":23475},{\"end\":23491,\"start\":23488},{\"end\":23503,\"start\":23498},{\"end\":23514,\"start\":23508},{\"end\":23524,\"start\":23519},{\"end\":23536,\"start\":23530},{\"end\":23544,\"start\":23541},{\"end\":23555,\"start\":23552},{\"end\":23915,\"start\":23907},{\"end\":23923,\"start\":23921},{\"end\":23933,\"start\":23930},{\"end\":23946,\"start\":23940},{\"end\":23955,\"start\":23953},{\"end\":23964,\"start\":23961},{\"end\":24250,\"start\":24243},{\"end\":24265,\"start\":24258},{\"end\":24275,\"start\":24271},{\"end\":24288,\"start\":24281},{\"end\":24298,\"start\":24293},{\"end\":24314,\"start\":24309},{\"end\":24326,\"start\":24319},{\"end\":24342,\"start\":24334},{\"end\":24354,\"start\":24350},{\"end\":24370,\"start\":24366},{\"end\":24755,\"start\":24752},{\"end\":24778,\"start\":24775},{\"end\":24792,\"start\":24786},{\"end\":24805,\"start\":24800},{\"end\":24819,\"start\":24814},{\"end\":25047,\"start\":25042},{\"end\":25059,\"start\":25054},{\"end\":25066,\"start\":25060},{\"end\":25089,\"start\":25078},{\"end\":25105,\"start\":25096},{\"end\":25119,\"start\":25115},{\"end\":25132,\"start\":25125},{\"end\":25429,\"start\":25424},{\"end\":25446,\"start\":25438},{\"end\":25460,\"start\":25454},{\"end\":25474,\"start\":25466},{\"end\":25793,\"start\":25788},{\"end\":25807,\"start\":25803},{\"end\":25828,\"start\":25819},{\"end\":25847,\"start\":25840},{\"end\":25865,\"start\":25859},{\"end\":26353,\"start\":26347},{\"end\":26365,\"start\":26359},{\"end\":26379,\"start\":26372},{\"end\":26394,\"start\":26387},{\"end\":26666,\"start\":26660},{\"end\":26678,\"start\":26672},{\"end\":26692,\"start\":26685},{\"end\":26707,\"start\":26700},{\"end\":26717,\"start\":26716},{\"end\":26730,\"start\":26724},{\"end\":26750,\"start\":26741},{\"end\":27575,\"start\":27569},{\"end\":27587,\"start\":27581},{\"end\":27601,\"start\":27594},{\"end\":27881,\"start\":27874},{\"end\":27890,\"start\":27886},{\"end\":27905,\"start\":27898},{\"end\":27914,\"start\":27910},{\"end\":28200,\"start\":28195},{\"end\":28212,\"start\":28206},{\"end\":28219,\"start\":28217},{\"end\":28230,\"start\":28225},{\"end\":28689,\"start\":28682},{\"end\":28702,\"start\":28695},{\"end\":28711,\"start\":28708},{\"end\":28986,\"start\":28981},{\"end\":28995,\"start\":28991},{\"end\":29005,\"start\":29002},{\"end\":29016,\"start\":29011},{\"end\":29029,\"start\":29022},{\"end\":29044,\"start\":29034},{\"end\":29782,\"start\":29775},{\"end\":29794,\"start\":29787},{\"end\":29806,\"start\":29801},{\"end\":29820,\"start\":29811},{\"end\":29833,\"start\":29826},{\"end\":29847,\"start\":29840},{\"end\":29861,\"start\":29854},{\"end\":29876,\"start\":29869},{\"end\":30240,\"start\":30235},{\"end\":30253,\"start\":30249},{\"end\":30267,\"start\":30263},{\"end\":30286,\"start\":30277},{\"end\":30298,\"start\":30292},{\"end\":30314,\"start\":30307},{\"end\":30328,\"start\":30323},{\"end\":30338,\"start\":30335},{\"end\":30350,\"start\":30343},{\"end\":30752,\"start\":30743},{\"end\":30770,\"start\":30763},{\"end\":30782,\"start\":30775},{\"end\":31087,\"start\":31080},{\"end\":31103,\"start\":31097},{\"end\":31121,\"start\":31114},{\"end\":31436,\"start\":31430},{\"end\":31450,\"start\":31443},{\"end\":31465,\"start\":31457},{\"end\":31480,\"start\":31471},{\"end\":31497,\"start\":31490},{\"end\":31748,\"start\":31743},{\"end\":31762,\"start\":31755},{\"end\":31777,\"start\":31770},{\"end\":31789,\"start\":31784},{\"end\":31802,\"start\":31794},{\"end\":31810,\"start\":31807},{\"end\":32153,\"start\":32148},{\"end\":32167,\"start\":32160},{\"end\":32184,\"start\":32179},{\"end\":32193,\"start\":32190},{\"end\":32204,\"start\":32198},{\"end\":32217,\"start\":32211},{\"end\":32228,\"start\":32224},{\"end\":32236,\"start\":32233},{\"end\":32245,\"start\":32242},{\"end\":32812,\"start\":32807},{\"end\":32821,\"start\":32819},{\"end\":32832,\"start\":32829},{\"end\":32839,\"start\":32837},{\"end\":32853,\"start\":32845},{\"end\":32861,\"start\":32858},{\"end\":32869,\"start\":32866},{\"end\":32884,\"start\":32877},{\"end\":33408,\"start\":33403},{\"end\":33420,\"start\":33414},{\"end\":33430,\"start\":33426},{\"end\":33445,\"start\":33438},{\"end\":33455,\"start\":33452},{\"end\":33467,\"start\":33463},{\"end\":33482,\"start\":33475},{\"end\":33493,\"start\":33488},{\"end\":33504,\"start\":33498},{\"end\":33518,\"start\":33511},{\"end\":33890,\"start\":33882},{\"end\":33905,\"start\":33897},{\"end\":33920,\"start\":33912},{\"end\":33932,\"start\":33928},{\"end\":33945,\"start\":33938},{\"end\":33955,\"start\":33950},{\"end\":34323,\"start\":34320},{\"end\":34331,\"start\":34328},{\"end\":34343,\"start\":34339},{\"end\":34352,\"start\":34348},{\"end\":34361,\"start\":34357},{\"end\":34368,\"start\":34366},{\"end\":34388,\"start\":34380},{\"end\":34395,\"start\":34393},{\"end\":34407,\"start\":34401},{\"end\":34424,\"start\":34419},{\"end\":34848,\"start\":34845},{\"end\":34856,\"start\":34853},{\"end\":34867,\"start\":34864},{\"end\":34883,\"start\":34874},{\"end\":34900,\"start\":34894},{\"end\":34912,\"start\":34907},{\"end\":34922,\"start\":34917},{\"end\":34932,\"start\":34927},{\"end\":34945,\"start\":34937},{\"end\":34959,\"start\":34951},{\"end\":35283,\"start\":35280},{\"end\":35291,\"start\":35288},{\"end\":35308,\"start\":35299},{\"end\":35321,\"start\":35319},{\"end\":35335,\"start\":35333},{\"end\":35354,\"start\":35350},{\"end\":35365,\"start\":35359},{\"end\":35375,\"start\":35370},{\"end\":35382,\"start\":35380},{\"end\":35392,\"start\":35389},{\"end\":35763,\"start\":35758},{\"end\":35774,\"start\":35771},{\"end\":35782,\"start\":35779}]", "bib_author_last_name": "[{\"end\":22909,\"start\":22904},{\"end\":22924,\"start\":22920},{\"end\":22936,\"start\":22931},{\"end\":22953,\"start\":22946},{\"end\":22969,\"start\":22963},{\"end\":22988,\"start\":22980},{\"end\":23008,\"start\":22997},{\"end\":23022,\"start\":23017},{\"end\":23037,\"start\":23031},{\"end\":23052,\"start\":23046},{\"end\":23461,\"start\":23458},{\"end\":23473,\"start\":23471},{\"end\":23486,\"start\":23483},{\"end\":23496,\"start\":23492},{\"end\":23506,\"start\":23504},{\"end\":23517,\"start\":23515},{\"end\":23528,\"start\":23525},{\"end\":23539,\"start\":23537},{\"end\":23550,\"start\":23545},{\"end\":23558,\"start\":23556},{\"end\":23919,\"start\":23916},{\"end\":23928,\"start\":23924},{\"end\":23938,\"start\":23934},{\"end\":23951,\"start\":23947},{\"end\":23959,\"start\":23956},{\"end\":23967,\"start\":23965},{\"end\":24256,\"start\":24251},{\"end\":24269,\"start\":24266},{\"end\":24279,\"start\":24276},{\"end\":24291,\"start\":24289},{\"end\":24307,\"start\":24299},{\"end\":24317,\"start\":24315},{\"end\":24332,\"start\":24327},{\"end\":24348,\"start\":24343},{\"end\":24364,\"start\":24355},{\"end\":24382,\"start\":24371},{\"end\":24773,\"start\":24756},{\"end\":24784,\"start\":24779},{\"end\":24798,\"start\":24793},{\"end\":24812,\"start\":24806},{\"end\":24824,\"start\":24820},{\"end\":24832,\"start\":24826},{\"end\":25052,\"start\":25048},{\"end\":25076,\"start\":25067},{\"end\":25094,\"start\":25090},{\"end\":25113,\"start\":25106},{\"end\":25123,\"start\":25120},{\"end\":25143,\"start\":25133},{\"end\":25436,\"start\":25430},{\"end\":25452,\"start\":25447},{\"end\":25464,\"start\":25461},{\"end\":25484,\"start\":25475},{\"end\":25801,\"start\":25794},{\"end\":25817,\"start\":25808},{\"end\":25838,\"start\":25829},{\"end\":25857,\"start\":25848},{\"end\":25877,\"start\":25866},{\"end\":26357,\"start\":26354},{\"end\":26370,\"start\":26366},{\"end\":26385,\"start\":26380},{\"end\":26401,\"start\":26395},{\"end\":26670,\"start\":26667},{\"end\":26683,\"start\":26679},{\"end\":26698,\"start\":26693},{\"end\":26714,\"start\":26708},{\"end\":26722,\"start\":26718},{\"end\":26739,\"start\":26731},{\"end\":26754,\"start\":26751},{\"end\":26761,\"start\":26756},{\"end\":27579,\"start\":27576},{\"end\":27592,\"start\":27588},{\"end\":27608,\"start\":27602},{\"end\":27884,\"start\":27882},{\"end\":27896,\"start\":27891},{\"end\":27908,\"start\":27906},{\"end\":27919,\"start\":27915},{\"end\":28204,\"start\":28201},{\"end\":28215,\"start\":28213},{\"end\":28223,\"start\":28220},{\"end\":28234,\"start\":28231},{\"end\":28693,\"start\":28690},{\"end\":28706,\"start\":28703},{\"end\":28717,\"start\":28712},{\"end\":28989,\"start\":28987},{\"end\":29000,\"start\":28996},{\"end\":29009,\"start\":29006},{\"end\":29020,\"start\":29017},{\"end\":29032,\"start\":29030},{\"end\":29048,\"start\":29045},{\"end\":29785,\"start\":29783},{\"end\":29799,\"start\":29795},{\"end\":29809,\"start\":29807},{\"end\":29824,\"start\":29821},{\"end\":29838,\"start\":29834},{\"end\":29852,\"start\":29848},{\"end\":29867,\"start\":29862},{\"end\":29880,\"start\":29877},{\"end\":30247,\"start\":30241},{\"end\":30261,\"start\":30254},{\"end\":30275,\"start\":30268},{\"end\":30290,\"start\":30287},{\"end\":30305,\"start\":30299},{\"end\":30321,\"start\":30315},{\"end\":30333,\"start\":30329},{\"end\":30341,\"start\":30339},{\"end\":30354,\"start\":30351},{\"end\":30761,\"start\":30753},{\"end\":30773,\"start\":30771},{\"end\":30791,\"start\":30783},{\"end\":31095,\"start\":31088},{\"end\":31112,\"start\":31104},{\"end\":31130,\"start\":31122},{\"end\":31441,\"start\":31437},{\"end\":31455,\"start\":31451},{\"end\":31469,\"start\":31466},{\"end\":31488,\"start\":31481},{\"end\":31508,\"start\":31498},{\"end\":31753,\"start\":31749},{\"end\":31768,\"start\":31763},{\"end\":31782,\"start\":31778},{\"end\":31792,\"start\":31790},{\"end\":31805,\"start\":31803},{\"end\":31815,\"start\":31811},{\"end\":32158,\"start\":32154},{\"end\":32177,\"start\":32168},{\"end\":32188,\"start\":32185},{\"end\":32196,\"start\":32194},{\"end\":32209,\"start\":32205},{\"end\":32222,\"start\":32218},{\"end\":32231,\"start\":32229},{\"end\":32240,\"start\":32237},{\"end\":32251,\"start\":32246},{\"end\":32255,\"start\":32253},{\"end\":32817,\"start\":32813},{\"end\":32827,\"start\":32822},{\"end\":32835,\"start\":32833},{\"end\":32843,\"start\":32840},{\"end\":32856,\"start\":32854},{\"end\":32864,\"start\":32862},{\"end\":32875,\"start\":32870},{\"end\":32889,\"start\":32885},{\"end\":33412,\"start\":33409},{\"end\":33424,\"start\":33421},{\"end\":33436,\"start\":33431},{\"end\":33450,\"start\":33446},{\"end\":33461,\"start\":33456},{\"end\":33473,\"start\":33468},{\"end\":33486,\"start\":33483},{\"end\":33496,\"start\":33494},{\"end\":33509,\"start\":33505},{\"end\":33524,\"start\":33519},{\"end\":33895,\"start\":33891},{\"end\":33910,\"start\":33906},{\"end\":33926,\"start\":33921},{\"end\":33936,\"start\":33933},{\"end\":33948,\"start\":33946},{\"end\":33959,\"start\":33956},{\"end\":34326,\"start\":34324},{\"end\":34337,\"start\":34332},{\"end\":34346,\"start\":34344},{\"end\":34355,\"start\":34353},{\"end\":34364,\"start\":34362},{\"end\":34372,\"start\":34369},{\"end\":34378,\"start\":34374},{\"end\":34391,\"start\":34389},{\"end\":34399,\"start\":34396},{\"end\":34417,\"start\":34408},{\"end\":34428,\"start\":34425},{\"end\":34432,\"start\":34430},{\"end\":34851,\"start\":34849},{\"end\":34862,\"start\":34857},{\"end\":34872,\"start\":34868},{\"end\":34892,\"start\":34884},{\"end\":34905,\"start\":34901},{\"end\":34915,\"start\":34913},{\"end\":34925,\"start\":34923},{\"end\":34935,\"start\":34933},{\"end\":34949,\"start\":34946},{\"end\":34965,\"start\":34960},{\"end\":35286,\"start\":35284},{\"end\":35297,\"start\":35292},{\"end\":35317,\"start\":35309},{\"end\":35331,\"start\":35322},{\"end\":35348,\"start\":35336},{\"end\":35357,\"start\":35355},{\"end\":35368,\"start\":35366},{\"end\":35378,\"start\":35376},{\"end\":35387,\"start\":35383},{\"end\":35397,\"start\":35393},{\"end\":35769,\"start\":35764},{\"end\":35777,\"start\":35775},{\"end\":35788,\"start\":35783}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":218971783},\"end\":23377,\"start\":22861},{\"attributes\":{\"doi\":\"arXiv:2210.11888\",\"id\":\"b1\"},\"end\":23818,\"start\":23379},{\"attributes\":{\"doi\":\"arXiv:2106.01093\",\"id\":\"b2\"},\"end\":24194,\"start\":23820},{\"attributes\":{\"doi\":\"arXiv:2210.02875\",\"id\":\"b3\"},\"end\":24647,\"start\":24196},{\"attributes\":{\"id\":\"b4\"},\"end\":25040,\"start\":24649},{\"attributes\":{\"doi\":\"arXiv:2010.12773\",\"id\":\"b5\"},\"end\":25422,\"start\":25042},{\"attributes\":{\"doi\":\"arXiv:1810.04805\",\"id\":\"b6\"},\"end\":25786,\"start\":25424},{\"attributes\":{\"doi\":\"arXiv:2301.13867\",\"id\":\"b7\"},\"end\":26252,\"start\":25788},{\"attributes\":{\"doi\":\"10.48550/ARXIV.2205.02054\",\"id\":\"b8\"},\"end\":26588,\"start\":26254},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":235293739},\"end\":27487,\"start\":26590},{\"attributes\":{\"doi\":\"arXiv:2109.05157\",\"id\":\"b10\"},\"end\":27804,\"start\":27489},{\"attributes\":{\"doi\":\"arXiv:2302.05965\",\"id\":\"b11\"},\"end\":28108,\"start\":27806},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":251402700},\"end\":28632,\"start\":28110},{\"attributes\":{\"doi\":\"arXiv:1909.13293\",\"id\":\"b13\"},\"end\":28876,\"start\":28634},{\"attributes\":{\"doi\":\"10.18653/v1/2022.acl-long.142\",\"id\":\"b14\",\"matched_paper_id\":248780123},\"end\":29686,\"start\":28878},{\"attributes\":{\"doi\":\"arXiv:2205.06983\",\"id\":\"b15\"},\"end\":30150,\"start\":29688},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":204838007},\"end\":30675,\"start\":30152},{\"attributes\":{\"doi\":\"arXiv:2204.00498\",\"id\":\"b17\"},\"end\":30985,\"start\":30677},{\"attributes\":{\"doi\":\"arXiv:2109.05093\",\"id\":\"b18\"},\"end\":31351,\"start\":30987},{\"attributes\":{\"doi\":\"arXiv:1911.04942\",\"id\":\"b19\"},\"end\":31741,\"start\":31353},{\"attributes\":{\"doi\":\"arXiv:2302.14229\",\"id\":\"b20\"},\"end\":32045,\"start\":31743},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":250089255},\"end\":32742,\"start\":32047},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":227033589},\"end\":33342,\"start\":32744},{\"attributes\":{\"doi\":\"arXiv:2302.10205\",\"id\":\"b23\"},\"end\":33785,\"start\":33344},{\"attributes\":{\"doi\":\"arXiv:2205.07686\",\"id\":\"b24\"},\"end\":34209,\"start\":33787},{\"attributes\":{\"doi\":\"arXiv:1909.05378\",\"id\":\"b25\"},\"end\":34731,\"start\":34211},{\"attributes\":{\"doi\":\"arXiv:1809.08887\",\"id\":\"b26\"},\"end\":35278,\"start\":34733},{\"attributes\":{\"doi\":\"arXiv:1906.02285\",\"id\":\"b27\"},\"end\":35692,\"start\":35280},{\"attributes\":{\"doi\":\"arXiv:2010.02840\",\"id\":\"b28\"},\"end\":35960,\"start\":35694}]", "bib_title": "[{\"end\":22898,\"start\":22861},{\"end\":26658,\"start\":26590},{\"end\":28193,\"start\":28110},{\"end\":28979,\"start\":28878},{\"end\":30233,\"start\":30152},{\"end\":32146,\"start\":32047},{\"end\":32805,\"start\":32744}]", "bib_author": "[{\"end\":22911,\"start\":22900},{\"end\":22926,\"start\":22911},{\"end\":22938,\"start\":22926},{\"end\":22955,\"start\":22938},{\"end\":22971,\"start\":22955},{\"end\":22990,\"start\":22971},{\"end\":23010,\"start\":22990},{\"end\":23024,\"start\":23010},{\"end\":23039,\"start\":23024},{\"end\":23054,\"start\":23039},{\"end\":23463,\"start\":23451},{\"end\":23475,\"start\":23463},{\"end\":23488,\"start\":23475},{\"end\":23498,\"start\":23488},{\"end\":23508,\"start\":23498},{\"end\":23519,\"start\":23508},{\"end\":23530,\"start\":23519},{\"end\":23541,\"start\":23530},{\"end\":23552,\"start\":23541},{\"end\":23560,\"start\":23552},{\"end\":23921,\"start\":23907},{\"end\":23930,\"start\":23921},{\"end\":23940,\"start\":23930},{\"end\":23953,\"start\":23940},{\"end\":23961,\"start\":23953},{\"end\":23969,\"start\":23961},{\"end\":24258,\"start\":24243},{\"end\":24271,\"start\":24258},{\"end\":24281,\"start\":24271},{\"end\":24293,\"start\":24281},{\"end\":24309,\"start\":24293},{\"end\":24319,\"start\":24309},{\"end\":24334,\"start\":24319},{\"end\":24350,\"start\":24334},{\"end\":24366,\"start\":24350},{\"end\":24384,\"start\":24366},{\"end\":24775,\"start\":24752},{\"end\":24786,\"start\":24775},{\"end\":24800,\"start\":24786},{\"end\":24814,\"start\":24800},{\"end\":24826,\"start\":24814},{\"end\":24834,\"start\":24826},{\"end\":25054,\"start\":25042},{\"end\":25078,\"start\":25054},{\"end\":25096,\"start\":25078},{\"end\":25115,\"start\":25096},{\"end\":25125,\"start\":25115},{\"end\":25145,\"start\":25125},{\"end\":25438,\"start\":25424},{\"end\":25454,\"start\":25438},{\"end\":25466,\"start\":25454},{\"end\":25486,\"start\":25466},{\"end\":25803,\"start\":25788},{\"end\":25819,\"start\":25803},{\"end\":25840,\"start\":25819},{\"end\":25859,\"start\":25840},{\"end\":25879,\"start\":25859},{\"end\":26359,\"start\":26347},{\"end\":26372,\"start\":26359},{\"end\":26387,\"start\":26372},{\"end\":26403,\"start\":26387},{\"end\":26672,\"start\":26660},{\"end\":26685,\"start\":26672},{\"end\":26700,\"start\":26685},{\"end\":26716,\"start\":26700},{\"end\":26724,\"start\":26716},{\"end\":26741,\"start\":26724},{\"end\":26756,\"start\":26741},{\"end\":26763,\"start\":26756},{\"end\":27581,\"start\":27569},{\"end\":27594,\"start\":27581},{\"end\":27610,\"start\":27594},{\"end\":27886,\"start\":27874},{\"end\":27898,\"start\":27886},{\"end\":27910,\"start\":27898},{\"end\":27921,\"start\":27910},{\"end\":28206,\"start\":28195},{\"end\":28217,\"start\":28206},{\"end\":28225,\"start\":28217},{\"end\":28236,\"start\":28225},{\"end\":28695,\"start\":28682},{\"end\":28708,\"start\":28695},{\"end\":28719,\"start\":28708},{\"end\":28991,\"start\":28981},{\"end\":29002,\"start\":28991},{\"end\":29011,\"start\":29002},{\"end\":29022,\"start\":29011},{\"end\":29034,\"start\":29022},{\"end\":29050,\"start\":29034},{\"end\":29787,\"start\":29775},{\"end\":29801,\"start\":29787},{\"end\":29811,\"start\":29801},{\"end\":29826,\"start\":29811},{\"end\":29840,\"start\":29826},{\"end\":29854,\"start\":29840},{\"end\":29869,\"start\":29854},{\"end\":29882,\"start\":29869},{\"end\":30249,\"start\":30235},{\"end\":30263,\"start\":30249},{\"end\":30277,\"start\":30263},{\"end\":30292,\"start\":30277},{\"end\":30307,\"start\":30292},{\"end\":30323,\"start\":30307},{\"end\":30335,\"start\":30323},{\"end\":30343,\"start\":30335},{\"end\":30356,\"start\":30343},{\"end\":30763,\"start\":30743},{\"end\":30775,\"start\":30763},{\"end\":30793,\"start\":30775},{\"end\":31097,\"start\":31080},{\"end\":31114,\"start\":31097},{\"end\":31132,\"start\":31114},{\"end\":31443,\"start\":31430},{\"end\":31457,\"start\":31443},{\"end\":31471,\"start\":31457},{\"end\":31490,\"start\":31471},{\"end\":31510,\"start\":31490},{\"end\":31755,\"start\":31743},{\"end\":31770,\"start\":31755},{\"end\":31784,\"start\":31770},{\"end\":31794,\"start\":31784},{\"end\":31807,\"start\":31794},{\"end\":31817,\"start\":31807},{\"end\":32160,\"start\":32148},{\"end\":32179,\"start\":32160},{\"end\":32190,\"start\":32179},{\"end\":32198,\"start\":32190},{\"end\":32211,\"start\":32198},{\"end\":32224,\"start\":32211},{\"end\":32233,\"start\":32224},{\"end\":32242,\"start\":32233},{\"end\":32253,\"start\":32242},{\"end\":32257,\"start\":32253},{\"end\":32819,\"start\":32807},{\"end\":32829,\"start\":32819},{\"end\":32837,\"start\":32829},{\"end\":32845,\"start\":32837},{\"end\":32858,\"start\":32845},{\"end\":32866,\"start\":32858},{\"end\":32877,\"start\":32866},{\"end\":32891,\"start\":32877},{\"end\":33414,\"start\":33403},{\"end\":33426,\"start\":33414},{\"end\":33438,\"start\":33426},{\"end\":33452,\"start\":33438},{\"end\":33463,\"start\":33452},{\"end\":33475,\"start\":33463},{\"end\":33488,\"start\":33475},{\"end\":33498,\"start\":33488},{\"end\":33511,\"start\":33498},{\"end\":33526,\"start\":33511},{\"end\":33897,\"start\":33882},{\"end\":33912,\"start\":33897},{\"end\":33928,\"start\":33912},{\"end\":33938,\"start\":33928},{\"end\":33950,\"start\":33938},{\"end\":33961,\"start\":33950},{\"end\":34328,\"start\":34320},{\"end\":34339,\"start\":34328},{\"end\":34348,\"start\":34339},{\"end\":34357,\"start\":34348},{\"end\":34366,\"start\":34357},{\"end\":34374,\"start\":34366},{\"end\":34380,\"start\":34374},{\"end\":34393,\"start\":34380},{\"end\":34401,\"start\":34393},{\"end\":34419,\"start\":34401},{\"end\":34430,\"start\":34419},{\"end\":34434,\"start\":34430},{\"end\":34853,\"start\":34845},{\"end\":34864,\"start\":34853},{\"end\":34874,\"start\":34864},{\"end\":34894,\"start\":34874},{\"end\":34907,\"start\":34894},{\"end\":34917,\"start\":34907},{\"end\":34927,\"start\":34917},{\"end\":34937,\"start\":34927},{\"end\":34951,\"start\":34937},{\"end\":34967,\"start\":34951},{\"end\":35288,\"start\":35280},{\"end\":35299,\"start\":35288},{\"end\":35319,\"start\":35299},{\"end\":35333,\"start\":35319},{\"end\":35350,\"start\":35333},{\"end\":35359,\"start\":35350},{\"end\":35370,\"start\":35359},{\"end\":35380,\"start\":35370},{\"end\":35389,\"start\":35380},{\"end\":35399,\"start\":35389},{\"end\":35771,\"start\":35758},{\"end\":35779,\"start\":35771},{\"end\":35790,\"start\":35779}]", "bib_venue": "[{\"end\":27074,\"start\":26927},{\"end\":28391,\"start\":28322},{\"end\":29255,\"start\":29168},{\"end\":32412,\"start\":32343},{\"end\":33066,\"start\":32987},{\"end\":23103,\"start\":23054},{\"end\":23449,\"start\":23379},{\"end\":23905,\"start\":23820},{\"end\":24241,\"start\":24196},{\"end\":24750,\"start\":24649},{\"end\":25213,\"start\":25161},{\"end\":25582,\"start\":25502},{\"end\":26002,\"start\":25895},{\"end\":26345,\"start\":26254},{\"end\":26925,\"start\":26763},{\"end\":27567,\"start\":27489},{\"end\":27872,\"start\":27806},{\"end\":28320,\"start\":28236},{\"end\":28680,\"start\":28634},{\"end\":29166,\"start\":29079},{\"end\":29773,\"start\":29688},{\"end\":30396,\"start\":30356},{\"end\":30741,\"start\":30677},{\"end\":31078,\"start\":30987},{\"end\":31428,\"start\":31353},{\"end\":31871,\"start\":31833},{\"end\":32341,\"start\":32257},{\"end\":32985,\"start\":32891},{\"end\":33401,\"start\":33344},{\"end\":33880,\"start\":33787},{\"end\":34318,\"start\":34211},{\"end\":34843,\"start\":34733},{\"end\":35461,\"start\":35415},{\"end\":35756,\"start\":35694}]"}}}, "year": 2023, "month": 12, "day": 17}