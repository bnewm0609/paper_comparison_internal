{"id": 211677851, "updated": "2023-10-06 18:24:38.036", "metadata": {"title": "Benchmarking Graph Neural Networks", "authors": "[{\"first\":\"Vijay\",\"last\":\"Dwivedi\",\"middle\":[\"Prakash\"]},{\"first\":\"Chaitanya\",\"last\":\"Joshi\",\"middle\":[\"K.\"]},{\"first\":\"Anh\",\"last\":\"Luu\",\"middle\":[\"Tuan\"]},{\"first\":\"Thomas\",\"last\":\"Laurent\",\"middle\":[]},{\"first\":\"Yoshua\",\"last\":\"Bengio\",\"middle\":[]},{\"first\":\"Xavier\",\"last\":\"Bresson\",\"middle\":[]}]", "venue": "Journal of Machine Learning Research (JMLR), 2022", "journal": "ArXiv", "publication_date": {"year": 2020, "month": null, "day": null}, "abstract": "In the last few years, graph neural networks (GNNs) have become the standard toolkit for analyzing and learning from data on graphs. This emerging field has witnessed an extensive growth of promising techniques that have been applied with success to computer science, mathematics, biology, physics and chemistry. But for any successful field to become mainstream and reliable, benchmarks must be developed to quantify progress. This led us in March 2020 to release a benchmark framework that i) comprises of a diverse collection of mathematical and real-world graphs, ii) enables fair model comparison with the same parameter budget to identify key architectures, iii) has an open-source, easy-to-use and reproducible code infrastructure, and iv) is flexible for researchers to experiment with new theoretical ideas. As of December 2022, the GitHub repository has reached 2,000 stars and 380 forks, which demonstrates the utility of the proposed open-source framework through the wide usage by the GNN community. In this paper, we present an updated version of our benchmark with a concise presentation of the aforementioned framework characteristics, an additional medium-sized molecular dataset AQSOL, similar to the popular ZINC, but with a real-world measured chemical target, and discuss how this framework can be leveraged to explore new GNN designs and insights. As a proof of value of our benchmark, we study the case of graph positional encoding (PE) in GNNs, which was introduced with this benchmark and has since spurred interest of exploring more powerful PE for Transformers and GNNs in a robust experimental setting.", "fields_of_study": "[\"Computer Science\",\"Mathematics\"]", "external_ids": {"arxiv": "2003.00982", "mag": "3007332492", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/jmlr/DwivediJL0BB23", "doi": null}}, "content": {"source": {"pdf_hash": "d08a0eb7024dff5c4fabd58144a38031633d4e1a", "pdf_src": "Arxiv", "pdf_uri": "[\"https://export.arxiv.org/pdf/2003.00982v5.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "5750321e20cffd020c4cd00c4681dd4c10372fa8", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/d08a0eb7024dff5c4fabd58144a38031633d4e1a.txt", "contents": "\nBenchmarking Graph Neural Networks\n\n\nVijay Prakash Dwivedi \nNanyang Technological University\nSingapore\n\nChaitanya K Joshi chaitanya.joshi@cl.cam.ac.uk \nUniversity of Cambridge\nUK\n\nAnh Tuan Luu \nNanyang Technological University\nSingapore\n\nThomas Laurent tlaurent@lmu.edu \nLoyola Marymount University\nUSA\n\nYoshua Bengio yoshua.bengio@mila.quebec \nUniversity of Montr\u00e9al\nMilaCanada\n\nXavier Bresson xaviercs@nus.edu.sg \nNational University of Singapore\n\n\nBenchmarking Graph Neural Networks\nGraph Neural NetworksBenchmarkingGraph DatasetsExploration Tool\nIn the last few years, graph neural networks (GNNs) have become the standard toolkit for analyzing and learning from data on graphs. This emerging field has witnessed an extensive growth of promising techniques that have been applied with success to computer science, mathematics, biology, physics and chemistry. But for any successful field to become mainstream and reliable, benchmarks must be developed to quantify progress. This led us in March 2020 to release a benchmark framework that i) comprises of a diverse collection of mathematical and real-world graphs, ii) enables fair model comparison with the same parameter budget to identify key architectures, iii) has an open-source, easy-to-use and reproducible code infrastructure, and iv) is flexible for researchers to experiment with new theoretical ideas. As of December 2022, the GitHub repository 1 has reached 2,000 stars and 380 forks, which demonstrates the utility of the proposed open-source framework through the wide usage by the GNN community. In this paper, we present an updated version of our benchmark with a concise presentation of the aforementioned framework characteristics, an additional medium-sized molecular dataset AQSOL, similar to the popular ZINC, but with a real-world measured chemical target, and discuss how this framework can be leveraged to explore new GNN designs and insights. As a proof of value of our benchmark, we study the case of graph positional encoding (PE) in GNNs, which was introduced with this benchmark and has since spurred interest of exploring more powerful PE for Transformers and GNNs in a robust experimental setting.\n\nIntroduction\n\nGraph neural networks have benefitted from a great interest recently with numerous methods being developed for diverse domains including chemistry (Duvenaud et al., 2015;Gilmer et al., 2017), physics (Cranmer et al., 2019;Sanchez-Gonzalez et al., 2020), social sciences (Monti et al., 2019), transportation (Derrow-Pinion et al., 2021), knowledge graphs (Schlichtkrull et al., 2018;Chami et al., 2020), recommendation (Monti et al., 2017b;Ying et al., 2018), and neuroscience (Griffa et al., 2017). Developing powerful and expressive GNN architectures is a key concern towards practical applications and real-world adoption of graph machine learning.\n\nHowever, tracking progress is often challenging in the absence of a community-standard benchmark as models that are evaluated on traditionally-used datasets with inconsistent experimental comparisons make it difficult to differentiate complex, simple and graph-agnostic architectures (Hoang and Maehara, 2019;Chen et al., 2019a;Errica et al., 2019).  We introduce an opensource GNN benchmarking framework (see Fig 1) that brings forward a set of diverse medium-scale datasets which are discriminative to benchmark different GNN models when compared fairly on fixed parameter budgets. The existing collection of datasets, the protocol to use the same parameter budgets for comparison, and the modular coding infrastructure has been widely used to prototype powerful GNN ideas and develop new insights, as shown by 2000+ stars and 380+ forks of the GitHub repository from its first release in March 2020, and 470+ citations gathered by the ArXiv technical report according to Google Scholar. Aspects of the benchmark have led to facilitating several interesting studies for GNNs such as on (i) the aggregation functions and filters (Corso et al., 2020;Tailor et al., 2021;Elhag et al., 2022), (ii) improving expressive power of GNNs (Valsesia et al., 2021;Bouritsas et al., 2022;Bevilacqua et al., 2021), (iii) pooling mechanisms (Mesquita et al., 2020), (iv) graph-specific normalization and regularization (Chen et al., 2022;Zhang et al., 2021), and (v) GNNs' robustness and efficiency (Wei and Hu, 2022;Tailor et al., 2020) among other ideas contributed in the literature. In this paper, we provide an updated overview of the proposed framework that extends on the previous collection of datasets to (a) include a number of essential mathematical datasets which can be used to test specific theoretical graph properties, and (b) incorporate another molecular dataset, AQSOL (Sorkun et al., 2019) that has real-world experimental solubility targets unlike ZINC's computed targets, resulting in a collection of 12 datasets (see Table 1). The remainder of the paper discusses a proof of concept of the benchmark that can be used to explore and develop new insights for GNNs.\n\n\nBenchmarking Graph Neural Networks\n\n\nOverview of GNN Benchmarking Framework\n\nDatasets. Collecting representative, realistic and medium-to-large scale graph datasets presents several challenges. It is unclear what theoretical tools can define the quality of a dataset or validate its statistical representativeness for a given task. Similarly, there are several arbitrary choices when preparing graphs, such as node and edge features. Finally, very large graph datasets also present a computational challenge and require extensive GPU resources to be studied (Chiang et al., 2019;Rossi et al., 2020;Hu et al., 2021).\n\n\nHow can the benchmark be used to explore new insights?\n\nThe proposed benchmarking framework can be used to test new research ideas at the level of data preprocessing, improving the GNN layers and normalization schemes, or even to substantiate the performance of a novel GNN model. Such studies are conveniently facilitated given the set of diverse datasets and the rigorous comparison of different experiments on same parameter budgets. At any stage, a modular component of the framework, such as data, layers, etc., can be modified and multiple experiments on the datasets can be conducted fairly and with ease. Indeed, we employ the framework to perform multiple studies, out of which we present here the insight of positional encodings for GNNs using Laplacian eigenvectors, for an example, while the remainder is included in the appendix.\n\nGraph Positional Encoding. Nodes in a graph do not have any canonical positional information. In the absence of available features, nodes are anonymous, such as the nodes in CSL, CYCLES or GraphTheoryProp datasets in our benchmark. As such, message passing based GCNs perform either poorly or fail completely to detect the class of the graph, such as isomorphic class, or cycles (Murphy et al., 2019;Loukas, 2020). We proposed the use of Laplacian eigenvectors (Belkin and Niyogi, 2003) as node positional encoding by building on top of corresponding dataset files in the data module as shown in the pseudo-code snippet alongside. In other words, the positional encoding p i for a node i can be added to its features x i as x i = x i + p i . Similarly, other ideas can be explored by leveraging respective modules of the framework (in Fig 1) for which we direct to README of our GitHub repository. We used the benchmark to validate and also quantified the improvement provided by this idea. The Laplacian PE effectively improved the MP-GCNs (message-passing based Graph Convolutional Networks) on the the 3 synthetics datasets mentioned previously and other real-world datasets, including the newly added AQSOL dataset. A detailed presentation of the PE with experiments are in Appendix E.1. After the introduction of Laplacian PE through this benchmark, new ideas followed up in the literature for improving PE (Beaini et al., 2021;Wang et al., 2022;Lim et al., 2022;Kreuzer et al., 2021;Ying et al., 2021;Mialon et al., 2021), thus demonstrating how the identification of first principles using the proposed benchmark can steer GNN research.\n\n\nConclusion\n\nThis paper introduces an open-source benchmarking framework for Graph Neural Networks that is modular, easy-to-use, and can be leveraged to quickly yet robustly test new GNN ideas and explore insights that direct further research. The benchmark led us to propose graph PE that has remained an interesting avenue of exploration since the first release of our benchmark. We also perform additional studies on investigation of different GNN categories, and edge representations for link prediction, the details of which are included in the appendix for interested readers.\n\n\nA. Related Work\n\nIn the last few years, graph neural networks (GNNs) have seen a great surge of interest with promising methods being developed for myriad of domains including chemistry (Duvenaud et al., 2015;Gilmer et al., 2017), physics (Cranmer et al., 2019;Sanchez-Gonzalez et al., 2020), social sciences (Kipf and Welling, 2017;Monti et al., 2019), knowledge graphs (Schlichtkrull et al., 2018;Chami et al., 2020), recommendation (Monti et al., 2017b;Ying et al., 2018), and neuroscience (Griffa et al., 2017). Historically, three classes of GNNs have been developed. The first models (Scarselli et al., 2009;Bruna et al., 2013;Defferrard et al., 2016;Sukhbaatar et al., 2016;Kipf and Welling, 2017;Hamilton et al., 2017) aimed at extending the original convolutional neural networks (LeCun et al., 1995(LeCun et al., , 1998 to graphs. The second class enhanced the original models with anisotropic operations on graphs (Perona and Malik, 1990), such as attention and gating mechanisms (Battaglia et al., 2016;Marcheggiani and Titov, 2017;Monti et al., 2017a;Veli\u010dkovi\u0107 et al., 2018;Bresson and Laurent, 2017). The recent third class has introduced GNNs that improve upon theoretical limitations of previous models Morris et al., 2019;Maron et al., 2019a;Chen et al., 2019b;Murphy et al., 2019;Srinivasan and Ribeiro, 2020). Specifically, the first two classes can only differentiate simple non-isomorphic graphs and cannot separate automorphic nodes. Developing powerful and theoretically expressive GNN architectures is a key concern towards practical applications and real-world adoption of graph machine learning. However, tracking recent progress has been challenging as most models are evaluated on small datasets such as Cora, Citeseer and TU, which are inappropriate to differentiate complex, simple and graph-agnostic architectures (Hoang and Maehara, 2019;Chen et al., 2019a), and do not have consensus on a unifying experimental setting (Errica et al., 2019;.\n\nConsequently, our motivation is to benchmark GNNs to identify and quantify what types of architectures, first principles or mechanisms are universal, generalizable, and scalable when we move to larger and more challenging datasets. Benchmarking provides a strong paradigm to answer these fundamental questions. It has proved to be beneficial for driving progress, identifying essential ideas, and solving domain-specific problems in several areas of science (Weber et al., 2019). Recently, the famous 2012 ImageNet challenge (Deng et al., 2009) has provided a benchmark dataset that has triggered the deep learning revolution (Krizhevsky et al., 2012;Malik, 2017). Nevertheless, designing successful benchmarks is highly challenging as it requires both a coding framework with a rigorous experimental setting for fair comparisons, all while being reproducible, as well as using appropriate datasets that can statistically separate model performance. The lack of benchmarks has been a major issue in GNN literature as the aforementioned requirements have not been rigorously enforced.\n\n\nB. Graph Neural Network Pipeline\n\nIn this section, we describe the experimental pipeline for the two broad classes of GNN architectures that are benchmarked in this framework as representative GNN classes -Message Passing Graph Convolutional Networks (MP-GCNs), which are based on the message passing framework formalized in Gilmer et al. (2017), and Weisfeiler Lehman GNNs (WL-GNNs), which improves the theoretical limitations of MP-GCNs and align expressivity power to the WL-tests to distinguish non-isomorphic graphs. The two pipelines are illustrated in Figure 3 for GCNs and Figure 4 for WL-GNNs.\n\nIn Section B.1, we describe the components of the setup of the GCN class with vanilla GCN (Kipf and Welling, 2017), GraphSage (Hamilton et al., 2017), MoNet (Monti et al., 2017a), GAT (Veli\u010dkovi\u0107 et al., 2018), and GatedGCN (Bresson and Laurent, 2017), including the input layers, the GNN layers and the task based MLP classifier layers. We also include the description of GIN  in this section as this model can be interpreted as a GCN, although it was designed to differentiate non-isomorphic graphs. In Section B.2, we present the GNN layers and the task based MLP classifier layers for the class of WL-GNN models with Ring-GNNs (Chen et al., 2019b) and 3WL-GNNs (Maron et al., 2019a Figure 3: A standard experimental pipeline for GCNs, which embeds the graph node and edge features, performs several GNN layers to compute convolutional features, and finally makes a prediction through a task-specific MLP layer.\n\n\nB.1 Message-Passing GCNs\n\nFor this class, we consider the widely used message passing-based graph convolutional networks (MP-GCNs), which update node representations from one layer to the other according to the formula:\nh +1 i = f (h i , {h j } j\u2208N i ).\nNote that the update equation is local, only depending on the neighborhood N i of node i, and independent of graph size, making the space/time complexity O(E) reducing to O(n) for sparse graphs. Thus, MP-GCNs are highly parallelizable on GPUs and are implemented via sparse matrix multiplications in modern graph machine learning frameworks (Wang et al., 2019;. MP-GCNs draw parallels to ConvNets for computer vision (LeCun et al., 1998) by considering a convolution operation with shared weights across the graph domain.\n\n\nB.1.1 Input Layer\n\nGiven a graph, we are given node features \u03b1 i \u2208 R a\u00d71 for each node i and (optionally) edge features \u03b2 ij \u2208 R b\u00d71 for each edge connecting node i and node j. The input features \u03b1 i and \u03b2 ij are embedded to d-dimensional hidden features h =0 i and e =0 ij via a simple linear projection before passing them to a graph neural network:\nh 0 i = U 0 \u03b1 i + u 0 ; e 0 ij = V 0 \u03b2 ij + v 0 ,(1)\nNode feat.\n\nEdge feat.\n\n\nInput Tensor WL-GNN Layer Prediction Layer\n\nInput 3D Figure 4: A standard experimental pipeline for WL-GNNs, which inputs to a GNN a graph with all node and edge information (if available) represented by a dense tensor, performs several GNN layer computations over the dense tensor, and finally makes a prediction through a task-specific MLP layer.\n\nwhere U 0 \u2208 R d\u00d7a , V 0 \u2208 R d\u00d7b and u 0 , v 0 \u2208 R d . If the input node/edge features are one-hot vectors of discrete variables, then biases u 0 , v 0 are not used.\n\n\nB.1.2 GCN layers\n\nEach GCN layer computes d-dimensional representations for the nodes/edges of the graph through recursive neighborhood diffusion (or message passing), where each graph node gathers features from its neighbors to represent local graph structure. Stacking L GCN layers allows the network to build node representations from the L-hop neighborhood of each node. Let h i denote the feature vector at layer associated with node i. The updated features h +1 i at the next layer + 1 are obtained by applying non-linear transformations to the central feature vector h i and the feature vectors h j for all nodes j in the neighborhood of node i (defined by the graph structure). This guarantees the transformation to build local reception fields, such as in standard ConvNets for computer vision, and be invariant to both graph size and vertex re-indexing.\n\nThus, the most generic version of a feature vector h +1 i at vertex i at the next layer in the GNN is:\nh +1 i = f h i , {h j : j \u2192 i} ,(2)\nwhere {j \u2192 i} denotes the set of neighboring nodes j pointed to node i, which can be replaced by {j \u2208 N i }, the set of neighbors of node i, if the graph is undirected. In other words, a GNN is defined by a mapping f taking as input a vector h i (the feature vector of the center vertex) as well as an un-ordered set of vectors {h j } (the feature vectors of all neighboring vertices), see Figure 5. The arbitrary choice of the mapping f defines an instantiation of a class of GNNs.\n\nGraph ConvNets (GCN) (Kipf and Welling, 2017) In the simplest formulation of GNNs, vanilla Graph ConvNets iteratively update node features via an isotropic averaging operation over the neighborhood node features, i.e.,\nh +1 i = ReLU U Mean j\u2208N i h j ,(3)= ReLU U 1 deg i j\u2208N i h j ,(4)\nwhere U \u2208 R d\u00d7d (a bias is also used, but omitted for clarity purpose), deg i is the in-degree of node i, see Figure 6. Eq. (3) is called a convolution as it is a linear approximation of a localized spectral convolution. Note that it is possible to add the central node features h i in the update (3) by using self-loops or residual connections. The GCN model in Kipf and Welling (2017) use symmetric normalization instead of the isotropic averaging, to result in the following node update equation:\nh +1 i = ReLU U 1 deg i deg j j\u2208N i h j ,(5)\nGraphSage (Hamilton et al., 2017) GraphSage improves upon the simple GCN model by explicitly incorporating each node's own features from the previous layer in its update equation:\u0125\n+1 i = ReLU U Concat h i , Mean j\u2208N i h j ,(6)\nwhere U \u2208 R d\u00d72d , see Figure 7. Observe that the transformation applied to the central node features h i is different to the transformation carried out to the neighborhood features h j . The node features are then projected onto the 2 -unit ball before being passed to the next layer: The authors also define more sophisticated neighborhood aggregation functions, such as Max-pooling or LSTM aggregators:\nh +1 i =\u0125 +1 i \u0125 +1 i 2 .(7)h +1 i = ReLU U Concat h i , Max j\u2208N i ReLU V h j ,(8)h +1 i = ReLU U Concat h i , LSTM j\u2208N i h j ,(9)\nwhere V \u2208 R d\u00d7d and the LSTM cell also uses learnable weights. In our experiments, we use the Max-pooling version of GraphSage, Eq.(8).\n\nGraph Attention Network (GAT) (Veli\u010dkovi\u0107 et al., 2018) GAT uses an attention mechanism (Bahdanau et al., 2014) to introduce anisotropy in the neighborhood aggregation function. The network employs a multi-headed architecture to increase the learning capacity, similar to the Transformer (Vaswani et al., 2017;Joshi, 2020). The node update equation is given by:\nh +1 i = Concat K k=1 ELU j\u2208N i e k, ij U k, h j ,(10)\nwhere U k, \u2208 R d K \u00d7d are the K linear projection heads, and e k, ij are the attention coefficients for each head defined as:\ne k, ij = exp(\u00ea k, ij ) j \u2208N i exp(\u00ea k, ij ) ,(11)e k, ij = LeakyReLU V k, Concat U k, h i , U k, h j ,(12)\nwhere V k, \u2208 R 2d K , see Figure 8. GAT learns a mean over each node's neighborhood features sparsely weighted by the importance of each neighbor.\n\nMoNet (Monti et al., 2017a) The MoNet model introduces a general architecture to learn on graphs and manifolds using the Bayesian Gaussian Mixture Model (GMM) (Dempster  , 1977). In the case of graphs, the node update equation is defined as:\nh +1 i = ReLU K k=1 j\u2208N i e k, ij U k, h j ,(13)e k, ij = exp \u2212 1 2 (u ij \u2212 \u00b5 k ) T (\u03a3 k ) \u22121 (u ij \u2212 \u00b5 k ) ,(14)u ij = Tanh A (deg \u22121/2 i , deg \u22121/2 j ) T + a ,(15)\nwhere U k, \u2208 R d\u00d7d , \u00b5 k , (\u03a3 k ) \u22121 , a \u2208 R 2 and A \u2208 R 2\u00d72 are the (learnable) parameters of the GMM, see Figure 9.\n\nGated Graph ConvNet (GatedGCN) (Bresson and Laurent, 2017) GatedGCN considers residual connections, batch normalization and edge gates (Marcheggiani and Titov, 2017) to design another anisotropic variant of GCN. The authors propose to explicitly update edge features along with node features:\nh +1 i = h i + ReLU BN U h i + j\u2208N i e ij V h j ,(16)\nwhere U , V \u2208 R d\u00d7d , is the Hadamard product, and the edge gates e ij are defined as:\ne ij = \u03c3(\u00ea ij ) j \u2208N i \u03c3(\u00ea ij ) + \u03b5 ,(17)e ij =\u00ea \u22121 ij + ReLU BN A h \u22121 i + B h \u22121 j + C \u00ea \u22121 ij ,(18)\nwhere \u03c3 is the sigmoid function, \u03b5 is a small fixed constant for numerical stability, A , B , C \u2208 R d\u00d7d , see Figure 10. Note that the edge gates (17) can be regarded as a soft attention process, Graph Isomorphism Networks (GIN)  The GIN architecture is based the Weisfeiler-Lehman Isomorphism Test (Weisfeiler and Lehman, 1968) to study the expressive power of GNNs. The node update equation is defined as:\nh +1 i = ReLU U ReLU BN V \u0125 +1 i ,(19)h +1 i = (1 + ) h i + j\u2208N i h j ,(20)\nwhere is a learnable constant, U , V \u2208 R d\u00d7d , BN denotes Batch Normalization. See Figure  11 for illustration of the update equation.\n\n\nNormalization and Residual Connections\n\nAs a final note, we augment each messagepassing GCN layer with batch normalization (BN) (Ioffe and Szegedy, 2015) and residual connections (He et al., 2016). As such, we consider a more specific class of GCNs than (2):\nh +1 i = h i + \u03c3 BN \u0125 +1 i ,(21)h +1 i = g GCN h i , {h j : j \u2192 i} ,(22)\nwhere \u03c3 is a non-linear activation function and g GCN is a specific message-passing GCN layer.\n\n\nB.1.3 Task-based Layer\n\nThe final component of each network is a prediction layer to compute task-dependent outputs, which are given to a loss function to train the network parameters in an end-to-end manner. The input of the prediction layer is the result of the final message-passing GCN layer for each node of the graph (except GIN, which uses features from all intermediate layers).\n\nGraph classifier layer To perform graph classification, we first build a d-dimensional graph-level vector representation y G by averaging over all node features in the final GCN layer:\ny G = 1 V V i=0 h L i ,(23)\nThe graph features are then passed to a MLP, which outputs un-normalized logits/scores y pred \u2208 R C for each class:\ny pred = P ReLU (Q y G ) ,(24)\nwhere P \u2208 R d\u00d7C , Q \u2208 R d\u00d7d , C is the number of classes. Finally, we minimize the cross-entropy loss between the logits and groundtruth labels.\n\nGraph regression layer For graph regression, we compute y G using Eq.(23) and pass it to a MLP which gives the prediction score y pred \u2208 R:\ny pred = P ReLU (Q y G ) ,(25)\nwhere P \u2208 R d\u00d71 , Q \u2208 R d\u00d7d . The L1-loss between the predicted score and the groundtruth score is minimized during the training.\n\nNode classifier layer For node classification, we independently pass each node's feature vector to a MLP for computing the un-normalized logits y i,pred \u2208 R C for each class:\ny i,pred = P ReLU Q h L i ,(26)\nwhere P \u2208 R d\u00d7C , Q \u2208 R d\u00d7d . The cross-entropy loss weighted inversely by the class size is used during training.\n\nEdge classifier layer To make a prediction for each graph edge e ij , we first concatenate node features h i and h j from the final GNN layer. The concatenated edge features are then passed to a MLP for computing the un-normalized logits y ij,pred \u2208 R C for each class:\ny ij,pred = P ReLU Q Concat h L i , h L j ,(27)\nwhere P \u2208 R d\u00d7C , Q \u2208 R d\u00d72d . The standard cross-entropy loss between the logits and groundtruth labels is used.\n\n\nB.2 Weisfeiler-Lehman GNNs\n\nWeisfeiler-Lehman GNNs are the second GNN class we include in our benchmarking framework which are based on the WL test (Weisfeiler and Lehman, 1968).  introduced GIN-Graph Isomorphism Network, a provable 1-WL GNN, which can distinguish two nonisomorphic graphs w.r.t. the 1-WL test. Higher k-WL isomorphic tests lead to more We use 3WLGNNs (Maron et al., 2019a) and RingGNNs (Chen et al., 2019b) as the GNN instances in this class, the experimental pipeline of which are described as follows.\n\n\nB.2.1 Input Tensor\n\nFor a given graph with adjacency matrix A \u2208 R n\u00d7n , node features h node \u2208 R n\u00d7d and edge features h edge \u2208 R n\u00d7n\u00d7de , the input tensor to the RingGNN and 3WL-GNN networks is defined as\nh =0 \u2208 R n\u00d7n\u00d7(1+d+de) ,(28)\nwhere\nh =0 i,j,1 = A ij \u2208 R, \u2200i, j(29)h =0 i,j,2:d+1 = h node i \u2208 R d , \u2200i = j 0 , \u2200i = j (30) h =0 i,j,d+2:d+de+1 = h edge ij \u2208 R de(31)\n\nB.2.2 WL-GNN layers\n\n3WL-GNNs (Maron et al., 2019a) These networks introduced an architecture that can distinguish two non-isomorphic graphs with the 3-WL test. The layer update equation of 3WL-GNNs is defined as:\nh +1 = Concat M W 1 (h ) . M W 2 (h ), M W 3 (h ) ,(32)\nwhere h , h +1 \u2208 R n\u00d7n\u00d7d , and M W are 2-layer MLPs applied along the feature dimension:\nM W ={Wa,W b } (h) = \u03c3 h W a W b ,(33)\nwhere W a , W b \u2208 R d\u00d7d . As h \u2208 R n\u00d7n\u00d7d , the MLP (33) is implemented with a standard 2D-convolutional layer with 1 \u00d7 1 kernel size. Eventually, the matrix multiplication in (32) is carried out along the first and second dimensions such that:\nM W 1 (h) . M W 2 (h) i,j,k = n p=1 M W 1 (h) i,p,k . M W 2 (h) p,j,k ,(34)\nwith complexity O(n 3 ).\n\nRing-GNNs (Chen et al., 2019b) These models proposed to improve the order-2 equivariant GNNs of Maron et al. (2019b) with the multiplication of two equivariant linear layers. The layer update equation of Ring-GNNs is designed as:\nh +1 = \u03c3 w 1 L W 1 (h ) + w 2 L W 2 (h ).L W 3 (h ) ,(35)\nwhere h , h +1 \u2208 R n\u00d7n\u00d7d , w 1,2 \u2208 R, and L W are the equivariant linear layers defined as\nL W (h) i,j,k = 17 p=1 d q=1 W p,q,k L i (h) i,j,q ,(36)\nwhere W \u2208 R d\u00d7d\u00d717 and {L i } 15 i=1 is the set of all basis functions for all linear equivariant functions from R n\u00d7n \u2192 R n\u00d7n (see Appendix A in Maron et al. (2019b) for the complete list of these 15 operations) and {L i } 17 i=16 are the basis for the bias terms. Matrix multiplication in (35) also implies a time complexity O(n 3 ).\n\n\nB.2.3 Task-based network layers\n\nWe describe the final network layers depending on the task at hand. The loss functions corresponding to the task are the same as the GCNs, and presented in Section B.1.3.\n\nGraph classifier layer We have followed the original author implementations in Maron et al. (2019a,b); Chen et al. (2019b) to design the classifier layer for 3WL-GNNs and Ring-GNNs. Similar to Xu et al. (2018, the classifier layer for Ring-GNNs uses features from all intermediate layers and then passes the features to a MLP:\ny G = Concat L =1 n i,j=1 h ij \u2208 R Ld ,(37)y pred = P ReLU (Q y G ) \u2208 R C ,(38)\nwhere P \u2208 R d\u00d7C , Q \u2208 R Ld\u00d7d , C is the number of classes. For 3WL-GNNs, Eqn. (37) is replaced by a diagonal and off-diagonal max pooling readout Maron et al. (2019a,b) at every layer:\ny G = Concat max i h ii , max i =j h ij \u2208 R 2d ,(39)\nand the final prediction score is defined as:\ny pred = L =1 P y G \u2208 R C ,(40)\nwhere P \u2208 R 2d\u00d7C , C is the number of classes.\n\nGraph regression layer Similar to the graph classifier layer with P \u2208 R d\u00d71 for Ring-GNNs, and P \u2208 R 2d\u00d71 for 3WL-GNNs.\n\nNode classifier layer For node classification, the prediction in Ring-GNNs is done as follows:\ny node i = Concat L =1 n j=1 h ij \u2208 R Ld ,(41)y i,pred = P ReLU Q y node i \u2208 R C ,(42)\nwhere P \u2208 R d\u00d7C , Q \u2208 R Ld\u00d7d , C is the number of classes.\n\nIn 3WL-GNNs, the final prediction score is defined as:\ny node, i = n j=1 h ij \u2208 R d ,(43)y i,pred = L =1 P y node, i \u2208 R C ,(44)\nwhere P \u2208 R d\u00d7C , C is the number of classes.\n\nEdge classifier layer For link prediction, for both Ring-GNNs and 3WL-GNNs, the edge features are obtained by concatenating the node features such as:\ny node i = Concat L =1 n j=1 h ij \u2208 R Ld ,(45)y ij,pred = P ReLU Q Concat y node i , y node j \u2208 R C ,(46)\nwhere P \u2208 R d\u00d7C , Q \u2208 R 2Ld\u00d7d , C is the number of classes.\n\n\nC. Datasets and Benchmarking Experiments\n\nIn this section, we provide details on the datasets included in the benchmarking framework (Table 1) and the numerical results of the experiments using the GNN described in Section B, which also consists experiments from a simple graph-agnostic baseline for every dataset that parallelly applies an MLP on each node's feature vector, independent of other nodes. For complete statistics of the data, see Table 2. The experimental overview in terms of the training strategy, reporting of results and the parameter budget used for fair comparison are described first, as follows.  Training. We use the Adam optimizer (Kingma and Ba, 2014) with the same learning rate decay strategy for all models. An initial learning rate is selected in {10 \u22122 , 10 \u22123 , 10 \u22124 } which is reduced by half if the validation loss does not improve after a fixed number of epochs, in the range 5-25. We do not set a maximum number of epochs -the training is stopped either when the learning rate has reached the small value of 10 \u22126 , or the computational time reaches 12 hours. We run each experiment with 4 different seeds and report the statistics of the 4 results. More details are provided in each experimental sub-sections.\n\nTask-based network layer. The node representations generated by the final layer of GCNs, or the dense tensor obtained at the final layer of the higher order WL-GNNs, are passed to a network suffix which is usually a downstream MLP of 3 layers. For GIN, RingGNN, and 3WL-GNN, we follow the original instructions of network suffixes to consider feature outputs from each layer of the network, similar to that of Jumping Knowledge Networks (Xu et al., 2018). Refer to the equations in the Sections B.1.3 and B.2.3 for more details.\n\nParameter budgets. Our goal is not to find the optimal set of hyperparameters for a specific GNN model (which is computationally expensive), but to compare and benchmark the model and/or their building blocks within a budget of parameters. Therefore, we decide on using two parameter budgets: (1) 100k parameters for each GNNs for all the tasks, and (2) 500k parameters for GNNs for which we investigate scaling a model to larger parameters and deeper layers. The number of hidden layers and hidden dimensions are selected accordingly to match these budgets. The configuration details of each single experiment can be found in our modular coding infrastructure on GitHub.\n\n\nC.1 Graph Regression with ZINC dataset\n\nFor the ZINC dataset in our benchmark, we use a subset (12K) of ZINC molecular graphs (250K) dataset (Irwin et al., 2012) to regress a molecular property known as the constrained solubility which is the term logP \u2212 SA \u2212 cycle (octanol-water partition coefficients, logP , penalized by the synthetic accessibility score, SA, and number of long cycles, cycle). For each molecular graph, the node features are the types of heavy atoms and the edge features  are the types of bonds between them. ZINC has been used popularly for research related to molecular graph generation (Jin et al., 2018;.\n\nSplitting. ZINC has 10, 000 train, 1, 000 validation and 1, 000 test graphs.\n\nTraining. For the learning rate strategy across all GNNs, an initial learning rate is set to 1 \u00d7 10 \u22123 , the reduce factor is 0.5, and the stopping learning rate is 1 \u00d7 10 \u22125 . The patience value is 5 for 3WLGNN and RingGNN, and 10 for all other GNNs. Performance Measure. The performance measure is the mean absolute error (MAE) between the predicted and the groundtruth constrained solubility for each molecular graph.\n\nResults. The numerical results are presented in Table 3 and analysed in Section D collectively with other benchmarking results.\n\n\nC.2 Graph Regression with AQSOL dataset\n\nAQSOL dataset is based on AqSolDB (Sorkun et al., 2019) which is a standardized database of 9, 982 molecular graphs with their aqueous solubility values, collected from 9 different data sources. The aqueous solubility targets are collected from experimental measurements and standardized to LogS units in AqSolDB. We use these final values as the property to regress in the AQSOL dataset which is the resultant collection after we filter out few graphs with no edges (bonds) and a small number of graphs with missing node feature values. Thus, the total molecular graphs are 9, 823. For each molecular graph, the node features are the types of heavy atoms and the edge features are the types of bonds between them.\n\nSplitting. We provide a scaffold splitting  of the dataset in the ratio 8 : 1 : 1 to have 7, 831 train, 996 validation and 996 test graphs.\n\nTraining. For the learning rate strategy across all GNNs, an initial learning rate is set to 1 \u00d7 10 \u22123 , the reduce factor is 0.5, and the stopping learning rate is 1 \u00d7 10 \u22125 . The patience value is 5 for 3WLGNN and RingGNN, and 10 for all other GNNs. Performance Measure. Similar to ZINC, the performance measure is the mean absolute error (MAE) between the predicted and the actual aqueous solubility values.\n\nResults. The numerical results are presented in Table 4 and analysed in Section D.   \n\n\nAQSOL\n\n\nC.3 Link Prediction with OGBL-COLLAB dataset\n\nOGBL-COLLAB is a link prediction dataset proposed by OGB  corresponding to a collaboration network between approximately 235K scientists, indexed by Microsoft Academic Graph . Nodes represent scientists and edges denote collaborations between them. For node features, OGB provides 128-dimensional vectors, obtained by averaging the word embeddings of a scientist's papers. The year and number of co-authored papers in a given year are concatenated to form edge features. The graph can also be viewed as a dynamic multi-graph, since two nodes may have multiple temporal edges between if they collaborate over multiple years. Splitting. We use the realistic training, validation and test edge splits provided by OGB. Specifically, they use collaborations until 2017 as training edges, those in 2018 as validation edges, and those in 2019 as test edges.\n\nTraining. All GNNs use a consistent learning rate strategy: an initial learning rate is set to 1 \u00d7 10 \u22123 , the reduce factor is 0.5, the patience value is 10, and the stopping learning rate is 1 \u00d7 10 \u22125 . Performance Measure. We use the evaluator provided by OGB, which aims to measure a model's ability to predict future collaboration relationships given past collaborations. Specifically, they rank each true collaboration among a set of 100,000 randomly-sampled negative collaborations, and count the ratio of positive edges that are ranked at K-place or above (Hits@K, with K = 50). Matrix Factorization Baseline. In addition to GNNs, we report performance for a simple matrix factorization baseline , which trains 256-dimensional embeddings for  each of the 235K nodes. Comparing GNNs to matrix factorization tells us whether models leverage node features in addition to graph structure, as matrix factorization can be thought of as feature-agnostic.\n\nResults. The numerical results are presented in Table 5 and discussed in Section D.\n\n\nC.4 Node Classification with WikiCS dataset\n\nWikiCS is a node classification dataset based on an extracted subset of Wikipedia's Computer Science articles (Mernyei and Cangea, 2020). It is a single graph dataset with 11, 701 nodes and 216, 123 edges where each node corresponds to an article, and each edge corresponds to a hyperlink. Each node belongs to a label out of total 10 classes representing the article's category. The average of the article text's pre-trained GloVe word embeddings (Pennington et al., 2014) is assigned as 300-dimensional node features. Compared to previous single-graph node classification benchmarks such as Cora and Citeseer, WikiCS dataset has denser node neighborhoods and each node's connectivity is spread across nodes from varying class labels. Additionally, as shown in Mernyei and Cangea (2020), the average shortest path length in WikiCS is smaller compared to Cora and Citeseer. Thus, on average, a larger node neighborhood and smaller shortest path length makes WikiCS an appropriate benchmark to test out neighborhood computation functions in GNNs' design. Splitting. We follow the splitting defined in Mernyei and Cangea (2020) that has 20 different training, validation and early stopping splits consisting of 5% nodes, 22.5% nodes and 22.5% nodes of each class respectively. 50% nodes from each class, which are not in the training or validation split, are assigned as test splits. We combine the two original validation (22.5% nodes) and early stopping (22.5% nodes) splits to make the new validation (45% nodes) splits since we do not use separate early stopping splits in our benchmark.\n\nTraining. As consistent learning rate strategy across GNNs, an initial learning rate is set to 1 \u00d7 10 \u22122 , the reduce factor is 0.5, the patience value is 25, and the stopping learning rate is 1 \u00d7 10 \u22125 . Since there are 20 different training and validation splits, the training is done 20 times using these splits, and evaluated on the single test split. This is done for 4 times with 4 different seeds. Finally, the average of the 20 \u00d7 4 = 80 runs is reported.\n\nPerformance Measure. The performance measure is the classification accuracy between the predicted and groundtruth label for each node.\n\nResults. The numerical results are presented in Table 6 and discussed in Section D.\n\n\nC.5 Graph Classification with Super-pixel (MNIST/CIFAR10) datasets\n\nThe super-pixels datasets test graph classification using the popular MNIST and CIFAR10 image classification datasets. Our main motivation to use these datasets is as sanity-checks: we expect most GNNs to perform close to 100% for MNIST and well enough for CIFAR10. Besides, the use of super-pixel image datasets is suggestive of the way image datasets can be used for graph learning research. The original MNIST and CIFAR10 images are converted to graphs using super-pixels. Super-pixels represent small regions of homogeneous intensity in images, and can be extracted with the SLIC technique (Achanta et al., 2012). We use SLIC super-pixels from (Knyazev et al., 2019) 2 . For each sample, we build a k-nearest neighbor adjacency matrix with\nW k\u2212NN ij = exp \u2212 x i \u2212 x j 2 \u03c3 2 x ,(47)\nwhere x i , x j are the 2-D coordinates of super-pixels i, j, and \u03c3 x is the scale parameter defined as the averaged distance x k of the k nearest neighbors for each node. We use k = 8 for both MNIST and CIFAR10, whereas the maximum number of super-pixels (nodes) are 75 and 150 for MNIST and CIFAR10, respectively. The resultant graphs are of sizes 40-75 nodes for MNIST and 85-150 nodes for CIFAR10. Figure 14 presents visualizations of the super-pixel graphs.\n\nSplitting. We use the standard splits of MNIST and CIFAR10. MNIST has 55, 000 train, 5, 000 validation, 10, 000 test graphs and CIFAR10 has 45, 000 train, 5, 000 validation, 10, 000 test graphs. The 5, 000 graphs for validation set are randomly sampled from the training set and the same splits are used for every GNN.\n\nTraining. The learning decay rate strategy is adopted with an initial learning rate of 1 \u00d7 10 \u22123 , reduce factor 0.5, patience value 10, and the stopping learning rate 1 \u00d7 10 \u22125 for all GNNs, except for 3WLGNN and RingGNN where we experienced a difficulty in training, leading us to slightly adjust their learning rate schedule hyperparameters. For both 3WLGNN and RingGNN, the patience value is changed to 5. For RingGNN, the initial learning rate is changed to 1 \u00d7 10 \u22124 and the stopping learning rate is changed to 1 \u00d7 10 \u22126 . Performance Measure. The classification accuracy between the predicted and groundtruth label for each graph is the performance measure.\n\nResults. The numerical results are presented in Table 7 and discussed in Section D.\n\n\nC.6 Node Classification with SBM (PATTERN/CLUSTER) datasets\n\nThe SBM datasets consider node-level tasks of graph pattern recognition (Scarselli et al., 2009) -PATTERN and semi-supervised graph clustering -CLUSTER. The graphs are generated with the Stochastic Block Model (SBM) (Abbe, 2017), which is widely used to model communities in social networks by modulating the intra-and extra-communities   connections, thereby controlling the difficulty of the task. A SBM is a random graph which assigns communities to each node as follows: any two vertices are connected with the probability p if they belong to the same community, or they are connected with the probability q if they belong to different communities (the value of q acts as the noise level). PATTERN: The graph pattern recognition task, presented in Scarselli et al. (2009), aims at finding a fixed graph pattern P embedded in larger graphs G of variable sizes. For all data, we generate graphs G with 5 communities with sizes randomly selected between [5,35]. The SBM of each community is p = 0.5, q = 0.35, and the node features on G are generated with a uniform random distribution with a vocabulary of size 3, i.e. {0, 1, 2}. We randomly generate 100 patterns P composed of 20 nodes with intra-probability p P = 0.5 and extra-probability q P = 0.5 (i.e., 50% of nodes in P are connected to G). The node features for P are also generated as a random signal with values {0, 1, 2}. The graphs are of sizes 44-188 nodes. The output node labels have value 1 if the node belongs to P and value 0 if it is in G.\n\nCLUSTER: For the semi-supervised clustering task, we generate 6 SBM clusters with sizes randomly selected between [5, 35] and probabilities p = 0.55, q = 0.25. The graphs are of sizes 40-190 nodes. Each node can take an input feature value in {0, 1, 2  is 1, the node belongs to class 0, value 2 corresponds to class 1, . . . , value 6 corresponds to class 5. Otherwise, if the value is 0, the class of the node is unknown and will be inferred by the GNN. There is only one labelled node that is randomly assigned to each community and most node features are set to 0. The output node labels are defined as the community/cluster class labels.\n\nSplitting. The PATTERN dataset has 10, 000 train, 2, 000 validation, 2, 000 test graphs and CLUSTER dataset has 10, 000 train, 1, 000 validation, 1, 000 test graphs. We save the generated splits and use the same sets in all models for fair comparison.\n\nTraining. As presented in the standard experimental protocol in Section C, we use Adam optimizer with a learning rate decay strategy. For all GNNs, an initial learning rate is set to 1 \u00d7 10 \u22123 , the reduce factor is 0.5, the patience value is 5, and the stopping learning rate is 1 \u00d7 10 \u22125 . Performance Measure. The performance measure is the average node-level accuracy weighted with respect to the class sizes.\n\nResults. Our numerical results are presented in Table 8 and discussed in Section D together with other benchmark results.\n\n\nC.7 Edge Classification/Link Prediction with TSP dataset\n\nLeveraging machine learning for solving NP-hard combinatorial optimization problems (COPs) has been the focus of intense research in recent years (Vinyals et al., 2015;. Recently proposed learning-driven solvers for COPs (Khalil et al., 2017;Kool et al., 2019;Joshi et al., 2019) combine GNNs with classical search to predict approximate solutions directly from problem instances (represented as graphs). Consider the intensively studied Travelling Salesman Problem (TSP), which asks the following question: \"Given a list of cities and the distances between each pair of cities, what is the shortest possible route that visits each city and returns to the origin city?\" Formally, given a 2D Euclidean graph, one needs to find an optimal sequence of nodes, called a tour, with minimal total edge weights (tour length). TSP's multi-scale nature makes it a challenging graph task which requires reasoning about both local node neighborhoods as well as global graph structure.\n\nFor our experiments with TSP, we follow the learning-based approach to COPs described in Joshi et al. (2022), where a GNN is the backbone architecture for assigning probabilities to each edge as belonging/not belonging to the predicted solution set. The probabilities are then converted into discrete decisions through graph search techniques. Each instance is a graph of n node locations sampled uniformly in the unit square S = {x i } n i=1 and x i \u2208 [0, 1] 2 . We generate problems of varying size and complexity by uniformly sampling the number of nodes n \u2208 [50, 500] for each instance.\n\nIn order to isolate the impact of the backbone GNN architectures from the search component, we pose TSP as a binary edge classification task, with the groundtruth value for each edge belonging to the TSP tour given by Concorde (Applegate et al., 2006). For scaling to large instances, we use sparse k = 25 nearest neighbor graphs instead of full graphs, following (Khalil et al., 2017). See Figure 15 for sample TSP instances of various sizes.\n\nSplitting. TSP has 10, 000 train, 1, 000 validation and 1, 000 test graphs. Training. All GNNs use a consistent learning rate strategy: an initial learning rate is set to 1 \u00d7 10 \u22123 , the reduce factor is 0.5, the patience value is 10, and the stopping learning rate is 1 \u00d7 10 \u22125 . Performance Measure. Given the high class imbalance, i.e., only the edges in the TSP tour have positive label, we use the F1 score for the positive class as our performance measure. Non-learnt Baseline. In addition to reporting performance of GNNs, we compare with a simple k-nearest neighbor heuristic baseline, defined as follows: Predict true for the edges corresponding to the k nearest neighbors of each node, and false for all other edges. We set k = 2 for optimal performance. Comparing GNNs to the non-learnt baseline tells us whether models learn something more sophisticated than identifying a node's nearest neighbors. Results. The numerical results are presented in Table 9 and analysed in Section D.  \n\n\nC.8 Graph Classification and Isomorphism Testing with CSL dataset\n\nThe Circular Skip Link dataset is a symmetric graph dataset introduced in Murphy et al.\n\n(2019) to test the expressivity of GNNs. Each CSL graph is a 4-regular graph with edges connected to form a cycle and containing skip-links between nodes. Formally, it is denoted by G N,C where N is the number of nodes and C is the isomorphism class which is the skip-link length of the graph. We use the same dataset G 41,C with C \u2208 {2, 3, 4, 5, 6, 9, 11, 12, 13, 16}. The dataset is class-balanced with 15 graphs for every C resulting in a total of 150 graphs. Splitting. We perform a 5-fold cross validation split, following Murphy et al. (2019), which gives 5 sets of train, validation and test data indices in the ratio 3 : 1 : 1. We use stratified sampling to ensure that the class distribution remains the same across splits. The indices are saved and used across all experiments for fair comparisons.\n\nTraining. For the learning rate strategy across all GNNs, an initial learning rate is set to 5 \u00d7 10 \u22124 , the reduce factor is 0.5, the patience value is 5, and the stopping learning rate is 1 \u00d7 10 \u22126 . We train on the 5-fold cross validation with 20 different seeds of initialization, following Chen et al. (2019b). Performance Measure. We use graph classification accuracy between the predicted labels and groundtruth labels as our performance measure. The model performance is evaluated on the test split of the 5 folds at every run, and following Murphy et al. (2019); Chen et al. (2019b), we report the maximum, minimum, average and the standard deviation of the 100 scores, i.e., 20 runs of 5-folds.\n\nResults. The numerical results are reported in Table 10 and analyzed in Section E.1. In this paper, we use CSL primarily to validate the impact of having Graph Positional Encodings  (Section E.1) that is proposed as a demonstration of our benchmarking framework to steer new GNN research.\n\n\nC.9 Cycle Detection with CYCLES dataset\n\nThe CYCLES is a dataset synthetically generated by Loukas (2020) which contains equal number of graphs with and without cycles of fixed lengths. The task is a binary classification task to detect whether a graph has cycle or not. Though there are several forms of the dataset used in Loukas (2020) in terms of the number of nodes and cycle lengths, we select the dataset variant marked with having node size 56 and cycle length 6, based on the difficulty results shown by the author. The graphs have nodes in the range 37-65. Splitting. We use the same dataset splits as in Loukas (2020). Originally there 10,000 graphs each in the training and test sets. We sample 1,000 class balanced graphs from the training set to be used as validation samples. Therefore, the resulting CYCLES dataset has 9,000 train/ 1,000 validation/10,000 test graphs with all the sets having class-balanced samples. We show results on different sizes of training samples following the original author of CYCLES dataset.\n\nTraining. For the learning rate strategy, an initial learning rate is set to 1 \u00d7 10 \u22124 , the reduce factor is 0.5, the patience value is 10, and the stopping learning rate is 1 \u00d7 10 \u22126 . Following Loukas (2020), we train using a varying sample size from 200 to 5, 000 out of the training graphs and report the results accordingly. The reported results are based on 4 runs with 4 different seeds.\n\nPerformance Measure. The classification accuracy between the predicted and groundtruth label for whether a graph has cycle or not is the performance measure.\n\nResults. Similar to the CSL dataset (Section C.8), we use the CYCLES dataset mainly for the validation of the Graph Positional Encodings (Section E.1) proposed as an outcome of this benchmarking framework. As such, we train only a subset of MP-GCNs (GINs and GatedGCNs) and report the respective results. The numerical results are reported in Table  11 and analyzed in Section E.1.  C.10 Multi-task graph properties with GraphTheoryProp dataset Corso et al. (2020) proposed a synthetic dataset of undirected and unweighted graphs of diverse types randomly generated for a multi-task benchmarking of 6 graph-theoretic properties, 3 at the node-level and 3 at the graph-level. We call this dataset as GraphTheoryProp.\n\nThe node-level tasks are to determine single source shortest paths (Dist.), node eccentricity (Ecc.), and Laplacian features LX given a node feature vector X (Lap.) The graph-level tasks are graph connectivity (Conn.), diameter (Diam.) and spectral radius (Rad.). The dataset has graph sizes in the range of 15-24 nodes which have random identifiers as input features. This dataset is crucial to benchmark the robustness of a GNN to predict specific or overall of all the 6 properties, as these may share subroutines such as graph traversals, despite the tasks being different graph properties (Corso et al., 2020).  Splitting. We use the same splitting sets as in Corso et al. (2020) which has 5,120 train, 640 validation, 1,280 test graphs. Training. For the learning rate strategy, an initial learning rate is set to 1 \u00d7 10 \u22123 , the reduce factor is 0.5, the patience value is 15, and the stopping learning rate is 1 \u00d7 10 \u22126 . The reported results are based on 4 runs with 4 different seeds. Performance Measure. For performance measure, Log 10 MSE is reported between the predicted and groundtruth values for each single task. Besides, an average performance measure is reported which is the combined average of all the 6 tasks. Results. As with the CSL and CYCLES datasets (Sections C.8, C.9), we use GraphThe-oryProp in this paper for the validation of Graph Positional Encodings, Section E.1. The numerical results are reported in Table 12 and analyzed in Section E.1.\n\n\nD. Analysis and Discussion of Benchmarking Results\n\nThis section highlights the main take-home messages from the experiments in Section C on the datasets in the proposed framework, which evaluate the GNNs from Section B with the experimental setup described in Section C and respective sub-sections of each datasets.\n\nGraph-agnostic NNs perform poorly. As a sanity check, we compare all GNNs to a simple graph-agnostic MLP baseline which updates each node independent of oneother, h +1 i = \u03c3 W h i , and passes these features to the task-based layer. MLP presents consistently low scores across all datasets (Tables 3-10), which shows the necessity to use graph structure for these tasks. All proposed datasets used in our study are appropriate to statistically separate GNN performance, which has remained an issue with the widely used but small graph datasets (Errica et al., 2019;Luzhnica et al., 2019).\n\nGCNs outperform WL-GNNs on the proposed datasets. Although provably powerful in terms of graph isomorphism tests and invariant function approximation (Maron et al., 2019c;Chen et al., 2019b;Morris et al., 2019), the recent 3WLGNNs and RingGNNs were not able to outperform GCNs for our medium-scale datasets, as shown in Tables 3-5 and 7-9. These new models are limited in terms of space/time complexities, with O(n 2 )/O(n 3 ) respectively, not allowing them to scale to larger datasets. On the contrary, GCNs with linear complexity w.r.t. the number of nodes for sparse graphs, can scale conveniently to 16 layers and show the best performance on all datasets. 3WL-GNNs and RingGNNs face loss divergence and/or out-of-memory errors when trying to build deeper networks.\n\nAnisotropic mechanisms improve GCNs. Among the models in the GCN class, the best results point towards the anisotropic models, particularly GAT and GatedGCN, which are based on sparse and dense attention mechanisms, respectively. For instance, results for ZINC, AQSOL, WikiCS, MNIST, CIFAR10, PATTERN and CLUSTER in respective Tables 3, 4, 6, 7, 8 show that the performance of the 100K-parameter anisotropic GNNs (GCN with symmetric normalization, GAT, MoNet, GatedGCN) are consistently better than the isotropic models (vanilla GCN, GraphSage), except for vanilla GCN-WikiCS, GraphSage-MNIST and MoNet-CIFAR10. Table 14, discussed later, dissects and demonstrates the importance of anisotropy for the link prediction tasks, TSP and COLLAB. Overall, our results suggest that understanding the expressive power of attention-based neighborhood aggregation functions is a meaningful avenue of research.\n\nUnderlying challenges for training WL-GNNs. We consistently observe a relatively high standard deviation in the performance of WL-GNNs (recall that we average across 4 runs using 4 different seeds). We attribute this fluctuation to the absence of universal training procedures like batching and batch normalization, as these GNNs operate on dense rank-2 tensors of variable sizes. On the other hand, GCNs running on sparse tensors better leverage batched training and normalization for stable and fast training. Leading graph machine learning libraries represent batches of graphs as sparse block diagonal matrices, enabling batched training of GCNs through parallelized computation (Jia et al., 2019).\n\nDense tensors are incompatible with the prevalent approach, disabling the use of batch normalization for WL-GNNs. We experimented with layer normalization (Ba et al., 2016) but without success. We were also unable to train WL-GNNs on CPU memory for the single COLLAB graph, see Table 5. Practical applications of the new WL-GNNs may require redesigning the best practices and common building blocks of deep learning, i.e. batching of variable-sized data, normalization schemes, and residual connections.\n\n3WL-GNNs perform the best among their class. Among the models in the WL-GNN class, 3WL-GNN provide better results than its similar counter-part RingGNN and achieves close to the best performance for AQSOL, see Table 4. The GIN model, while being less expressive, is able to scale better and provides overall good performance.\n\n\nE. Studies using the Benchmarking Framework\n\nOne of the primary goals of this benchmarking framework is to facilitate researchers to perform new explorations conveniently and develop insights that improve our overall understanding of graph neural networks. This section provides a demonstration of two such studies that we carry out by leveraging the datasets and the coding infrastructure which are part of this framework. First, we explore the absence of positional information in graphs for MP-GCNs which induces their low representation power. As a result, we develop a new insight that Laplacian eigenvectors can very simply be used as graph positional encodings and improve MP-GCNs. This insight has been received keenly in the recent literature and there are a number of works that propose positional encoding schemes with some addressing the challenges of using Laplacian eigenvectors (Kreuzer et al., 2021;Wang et al., 2022;Lim et al., 2022). Second, we study and show how the modification of existing MP-GCNs with joint edge representations help the models perform comparatively better than their vanilla counterparts.\n\n\nE.1 Laplacian Positional Encodings\n\nAs discussed in Section D, MP-GCNs outperforms WL-GNNs on the diverse collection of datasets included in our proposed benchmark despite having theoretical limitations derived from the alignment of MP-GCNs to the WL-tests. Also, WL-GNNs were found to be computationally infeasible on medium and large scale datasets. Motivated by these results, we propose 'Graph Positional Encodings' using Laplacian eigenvectors, thus referred as Laplacian Positional Encodings, to improve the theoretical shortcomings of MP-GCNs, which allows us to retain the computationally efficiency offered by the message-passing framework and improve the MP-GCNs performance.\n\n\nE.1.1 Related Work\n\nIn Murphy et al. (2019); Srinivasan and Ribeiro (2020), it was pointed out that standard MP-GCNs might perform poorly when dealing with graphs that exhibit some symmetries in their structures, such as node or edge isomorphism. This is related to the limitation of MP-GCNs due to their equivalence to the 1-WL test Morris et al., 2019).\n\nThe equivalence is based on the condition when MP-GCNs handle anonymous nodes (Loukas, 2020), i.e. nodes do not have unique node features. To address this issue of anonymous MP-GCNs, Murphy et al. (2019) introduced a framework, called Graph Relational Pooling (GRP), that assigns to each node an identifier that depends on the index ordering. This approach can be computationally expensive as it requires to account for all n! node permutations, thus requiring some sampling in practice.  proposed learnable position-aware embeddings based on random anchor sets of nodes for pairwise node (or, link) tasks. However, the random selection of anchor sets has limitations and their approach is not applicable on inductive node tasks. Similarly, one could think of using full or partial random node identifiers for breaking node-anonymity. Yet, it suffers from generalization to unseen graphs Loukas, 2020).  proposed the use of distance encoding as node attributes which captures distances between nodes using power(s) of random walk matrix. However, their failure on distance regular graphs  and the cost of computing the power matrices may be limiting to scale to diverse and medium to large-scale graphs. We improve upon these works and propose the use of Laplacian eigenvectors as positional encodings.\n\n\nE.1.2 Laplacian eigenvectors as Positional Encodings\n\nWe keep the overall MP-GCN architecture and simply add positional features to each node before processing the graph through the MP-GCN. Intuitively, the positional features should be chosen such that nodes which are far apart in the graph have different positional features whereas nodes which are nearby have similar positional features. As node positional features, we propose to use graph Laplacian eigenvectors (Belkin and Niyogi, 2003), which have less ambiguities and which better describe the distance between nodes on the graph. Formally, Laplacian eigenvectors are spectral techniques that embed the graphs into the Euclidean space. These vectors form a meaningful local coordinate system, while preserving the global graph structure. Mathematically, they are defined via the factorization of the graph Laplacian matrix;\n\u2206 = I \u2212 D \u22121/2 AD \u22121/2 = U T \u039bU,(48)\nwhere A is the n \u00d7 n adjacency matrix, D is the degree matrix, and \u039b, U correspond respectively to the eigenvalues and eigenvectors. Laplacian eigenvectors also represent a natural generalization of the Transformer (Vaswani et al., 2017) positional encodings (PE) for graphs as the eigenvectors of a discrete line (NLP graph) are the cosine and sinusoidal functions. The computational complexity O(E 3/2 ), with E being the number of edges, can be improved with, e.g. the Nystrom method (Fowlkes et al., 2004). The eigenvectors are defined up to the factor \u00b11 (after being normalized to unit length), so the sign of eigenvectors will be randomly flipped during training. For the experiments, we use the k smallest non-trivial eigenvectors, where the k value is given in the respective experiment tables in Section C as the dimensions of the PE. The smallest eigenvectors provide smooth encoding coordinates of neighboring nodes. See Section E.1.4 for additional discussion about positional encodings and the reasoning behind our decision to use random sign flipping.\n\n\nE.1.3 Experiments and Analysis\n\nWe first use the mathematical graphs such as CSL, CYCLES and GraphTheoryProp included in our benchmark (Sections C.8-C.10) to validate the proposed Laplacian PE as simple augmentations in MP-GCNs to improve their performance on the datasets. On CSL dataset, Table 10 compares the MP-GCNs using the Laplacian eigenvectors as PE and the WL-GNNs. The MP-GCN models were the most accurate with 99% of mean accuracy, while 3WL-GNN obtained 97% and RingGNN 25% with our experimental setting. Similarly, in Table 11 for CYCLES dataset and Table 12 for GraphTheoryProp dataset, where we simply select 2 representative MP-GCNs (GINs and GatedGCNs), we observe a consistent improvement in the performance when GINs and GatedGCNs are augmented with Laplacian PE. This demonstrates the importance of positional features to successfully detect cycles in a graph, and also predict critical theoretical and geometric properties in a graph. Next, we study ZINC, AQSOL, WikiCS, PATTERN, CLUSTER and COLLAB with PE (note that MNIST, CIFAR10 and TSP do not need PE as the nodes in these graphs already have features describing their positions in R 2 ). We observe a boost of performance for ZINC, AQSOL and CLUSTER (it was expected as eigenvectors are good indicators of clusters (Von Luxburg, 2007)), an improvement for PATTERN, and statistically the same result for COLLAB, see the respective tables in Section C. This way, MP-GCNs can be augmented with Laplacian PE to overcome their limitations of not being able to detect simple graph symmetries. Additionally, PEs also boost the models' performance on real-world graph learning tasks.\n\n\nE.1.4 Challenges with using Laplacian eigenvectors\n\nIdeally, positional encodings (PEs) should be unique for each node, and nodes which are far apart in the graph should have different positional features whereas nodes which are nearby have similar positional features. Note that in a graph that has some symmetries, positional features cannot be assigned in a canonical way. For example, if node i and node j are structurally symmetric, and we have positional features p i = a, p j = b that differentiate them, then it is also possible to arbitrary choose p i = b, p j = a since i and j are completely symmetric by definition. In other words, the PE is always arbitrary up to the number of symmetries in the graph. As a consequence, the network will have to learn to deal with these ambiguities during training. The simplest possible positional encodings is to give an (arbitrary) ordering to the nodes, among n! possible orderings. During training, the orderings are uniformly sampled from the n! possible choices in order for the network to learn to be independent to these arbitrary choices (Murphy et al., 2019).\n\nWe propose an alternative to reduce the sampling space, and therefore the amount of ambiguities to be resolved by the network. Laplacian eigenvectors are hybrid positional and structural encodings, as they are invariant by node re-parametrization. However, they are also limited by natural symmetries such as the arbitrary sign of eigenvectors (after being normalized to have unit length). The number of possible sign flips is 2 k , where k is the number of eigenvectors. In practice we choose k n, and therefore 2 k is much smaller n! (the number of possible ordering of the nodes). During the training, the eigenvectors will be uniformly sampled at random between the 2 k possibilities. If we do not seek to learn the invariance w.r.t. all possible sign flips of eigenvectors, then we can remove the sign ambiguity   Numerical results for different positional encodings are reported in Table 13. For all results, we use the GatedGCN model (Bresson and Laurent, 2017). We study 5 types of positional encodings; EigVecs-k corresponds to the smallest non-trivial k eigenvectors, Rand sign(EigVecs) randomly flips the sign of the k smallest non-trivial eigenvectors in each batch, Abs(EigVecs) takes the absolute value of the k eigenvectors, Fixed node ordering uses the original node ordering of graphs, and Rand node ordering randomly permutes ordering of nodes in each batch. We observed that the best results are consistently produced with the Laplacian PEs with random sign flipping at training. For index PEs, randomly permuting the ordering of nodes also improves significantly the performances over keeping fixed the original node ordering. However, Laplacian PEs clearly outperform index PEs.\n\n\nE.2 Edge representations for link prediction.\n\n\nE.2.1 With GatedGCN and GAT\n\nThe TSP and COLLAB edge classification tasks present an interesting empirical result for GCNs: Isotropic models (vanilla GCN, GraphSage) are consistently outperformed by their Anisotropic counterparts which use joint representations of adjacent nodes as edge features during aggregation (GAT, GatedGCN). In this section, we systematically study the impact of anisotropy by instantiating three variants of GAT and GatedGCN:\n\n(1) Isotropic aggregation (such as vanilla GCNs (Kipf and Welling, 2017)) with node updates of the form: Table 14;\nh +1 i = \u03c3 j\u2208N i W h j , identified by (E.Feat,E.Repr =x,x) in\n(49)\n\n(2) Anisotropy using edge features (such as GAT by default (Veli\u010dkovi\u0107 et al., 2018)) with node updates as:\nh +1 i = \u03c3 j\u2208N i f V (h i , h j ) \u00b7 W h j , with (E.Feat,E.Repr = ,x);(50)\nand (3) Anisotropy with edge features and explicit edge representations updated at each layer with node/edge updates as (such as in GatedGCN by default (Bresson and Laurent, 2017)):\nh +1 i = \u03c3 j\u2208N i e ij \u00b7 W h j , e +1 ij = f V h i , h j , e ij ), with (E.Feat,E.Repr = , ). (51)\nThe formal update equations of the three variants of GatedGCN are: Isotropic, similar to vanilla GCNs with sum aggregation:\nh +1 i = h i + ReLU BN U h i + j\u2208N i V h j , where U , V \u2208 R d\u00d7d .(52)\nAnisotropic with intermediate edge features computed as joint representations of adjacent node features at each layer:\nh +1 i = h i + ReLU BN U h i + j\u2208N i e ij V h j ,(53)e ij = \u03c3(\u00ea ij ) j \u2208N i \u03c3(\u00ea ij ) + \u03b5 ,\u00ea ij = A h \u22121 i + B h \u22121 j ,(54)\nwhere U , V \u2208 R d\u00d7d , is the Hadamard product, and e ij are the edge gates.\n\nAnisotropic with edge features as well as explicit edge representations updated across layers in addition to node features, as in GatedGCN by default, Eq. (16):\nh +1 i = h i + ReLU BN U h i + j\u2208N i e ij V h j ,(55)e ij = \u03c3(\u00ea ij ) j \u2208N i \u03c3(\u00ea ij ) + \u03b5 ,(56)e ij =\u00ea \u22121 ij + ReLU BN A h \u22121 i + B h \u22121 j + C \u00ea \u22121 ij ,(57)\nwhere U , V \u2208 R d\u00d7d , is the Hadamard product, and e ij are the edge gates. The input edge features from the datasets (e.g. distances for TSP, collaboration year and frequency for COLLAB) can optionally be used to initialize the edge representations\u00ea =0 ij . Note that there may be a multitude of approaches to instantiating anisotropic GNNs and using edge features (Battaglia et al., 2016;Sanchez-Gonzalez et al., 2018;Brockschmidt, 2019) besides the ones we consider.\n\nThe formal update equations of the three variants of GAT are: Isotropic, similar to multi-headed vanilla GCNs with sum aggregation:\nh +1 i = Concat K k=1 ELU BN j\u2208N i U k, h j , where U k, \u2208 R d K \u00d7d .(58)\nAnisotropic with intermediate edge features computed as joint representations of adjacent node features at each layer, as in GAT by default, Eq. (10):\nh +1 i = h i + ELU BN Concat K k=1 j\u2208N i e k, ij U k, h j ,(59)e k, ij = exp(\u00ea k, ij ) j \u2208N i exp(\u00ea k, ij ) ,\u00ea k, ij = LeakyReLU V k, Concat U k, h i , U k, h j , (60) where U k, \u2208 R d K \u00d7d , V k, \u2208 R 2d\nK are the K linear projection heads and e k, ij are the attention coefficients for each head. Anisotropic with edge features as well as explicit edge representations updated across layers in addition to node features:\nh +1 i = h i + ELU BN Concat K k=1 j\u2208N i a k, ij U k, h j ,(61)e +1 ij = e ij + ELU BN Concat K k=1 B k, Concat A k, e ij , U k, h i , U k, h j ,(62)a k, ij = exp(\u00e2 k, ij ) j \u2208N i exp(\u00e2 k, ij ) ,(63)a k, ij = LeakyReLU V k, Concat A k, e ij , U k, h i , U k, h j ,(64)where U k, \u2208 R d K \u00d7d , V k, \u2208 R 3d K , A k, \u2208 R d K \u00d7d , B k, \u2208 R d K \u00d7 3d\nK are the K linear projection heads and a k, ij are the attention coefficients for each head. The input edge features from the datasets can optionally be used to initialize the edge representations e =0 ij .\n\n\nNumerical Experiments and Analysis\n\nIn Table 14, we show the experiments of the three variants of GatedGCN and GAT on TSP and COLLAB. GatedGCN-E and GAT-E in Table are models using input edge features from the datasets to initialize the edge representations e ij . As maintaining edge representations comes with a time and memory cost for the large COLLAB graph, all models use a reduced budget of 27K parameters to fit the GPU memory, and are allowed to train for a maximum of 24 hours for convergence.  On both TSP and COLLAB, upgrading isotropic models with edge features significantly boosts performance given the same model parameters (e.g. 0.75 vs. 0.64 F1 score on TSP, 50.6% vs. 35.9% Hits@50 on COLLAB for GatedGCN with edge features vs. the isotropic variant). Maintaining explicit edge representations across layers further improves F1 score for TSP, especially when initializing the edge representations with euclidean distances between nodes (e.g. 0.78 vs. 0.67 F1 score for GAT-E vs. standard GAT). On COLLAB, adding explicit edge representations and inputs degrades performance, suggesting that the features (collaboration frequency and year) are not useful for the link prediction task (e.g. 47.2 vs. 51.5 Hits@50 for GatedGCN-E vs. GatedGCN). As suggested by , it would be interesting to treat COLLAB as a multi-graph with temporal edges, motivating the development of task-specific anisotropic edge representations beyond generic attention and gating mechanisms.\n\n\nE.2.2 With GraphSage\n\nInterestingly, in Table 5 for COLLAB, we found that the isotropic GraphSage with max aggregation performs close to GAT and GatedGCN models, both of which perform anisotropic mean aggregation. On the other hand, models which use sum aggregation (GIN, MoNet) are unable to beat the simple matrix factorization baseline. This result indicates that aggregation functions which are invariant to node degree (max and mean) provide a powerful inductive bias for COLLAB.\n\nWe instantiate two anisotropic variants of GraphSage, as described in the following paragraphs, and compare them to GAT and GatedGCN on COLLAB in Table 15. We find that upgrading max aggregators with edge features does not significantly boost performance. On the other hand, maintaining explicit edge representations across layers hurts the models, presumably due to using very small hidden dimensions. (As previously mentioned, maintaining representations for both 235K nodes and 2.3M edges leads to significant GPU memory usage and requires using smaller hidden dimensions.)  Isotropic, as in GraphSage by default, Eq. (8):\nh +1 i = h i + ReLU BN U Concat h i , Max j\u2208N i ReLU V h j ,(65)\nwhere U \u2208 R d\u00d72d , V \u2208 R d\u00d7d . Anisotropic with intermediate edge features computed as joint representations of adjacent node features at each layer:\nh +1 i = h i + ReLU BN U Concat h i , Max j\u2208N i ReLU \u03c3 e ij V h j ,(66)e ij = A h \u22121 i + h \u22121 j ,(67)\nwhere U \u2208 R d\u00d72d , V , A \u2208 R d\u00d7d , is the Hadamard product, and e ij are the edge gates. Anisotropic with edge features as well as explicit edge representations updated across layers in addition to node features:\nh +1 i = h i + ReLU BN U Concat h i , Max j\u2208N i ReLU \u03c3 \u00ea ij V h j ,(68)e ij = A h \u22121 i + h \u22121 j + B e \u22121 ij , e +1 ij = e ij + ReLU BN \u00ea ij ,(69)\nwhere U \u2208 R d\u00d72d , V , A , B \u2208 R d\u00d7d , is the Hadamard product, and\u00ea ij are the edge gates. The input edge features from the datasets can optionally be used to initialize the edge representations e =0 ij .\n\n\nF. Experiments on TU datasets\n\nApart from the proposed datasets in our benchmark (Section C), we perform experiments on 3 TU datasets for graph classification -ENZYMES, DD and PROTEINS. Our goal is to empirically highlight some of the challenges of using these conventional datasets for benchmarking GNNs.  Table 16: Performance on the TU datasets with 10-fold cross validation (higher is better). Two runs of all the experiments using the same hyperparameters but different random seeds are shown separately to note the differences in ranking and variation for reproducibility. The top 3 performance scores are highlighted as First, Second, Third.\n\nSplitting. Since the 3 TU datasets that we use do not have standard splits, we perform a 10-fold cross validation split which gives 10 sets of train, validation and test data indices in the ratio 8 : 1 : 1. We use stratified sampling to ensure that the class distribution remains the same across splits. The indices are saved and used across all experiments for fair comparisons. There are 480 train/60 validation/60 test graphs for ENZYMES, 941 train/118 validation/119 test graphs for DD, and 889 train/112 validation/112 test graphs for PROTEINS datasets in each of the folds. Training. We use Adam optimizer with a similar learning rate strategy as used in our benchmark's experimental protocol. An initial learning rate is tuned from a range of 1 \u00d7 10 \u22123 to 7 \u00d7 10 \u22125 using grid search for every GNN models. The learning rate reduce factor is 0.5, the patience value is 25 and the stopping learning rate is 1 \u00d7 10 \u22126 . Performance Measure. We use classification accuracy between the predicted labels and groundtruth labels as our performance measure. The model performance is evaluated on the test split of the 10 folds for all TU datasets, and reported as the average and the standard deviation of the 10 scores.\n\nOur numerical results on the TU datasets -ENZYMES, DD and PROTEINS are presented in Table 16. We observe all NNs have similar statistical test performance as the standard deviation is quite large. We also report a second run of these experiments with the same experimental protocol, i.e. the same 10-fold splitting and hyperparameters but different initialization (seed). We observe a change of model ranking, which we attribute to the small size of the datasets and the non-determinism of gradient descent optimizers. We also observe that, for DD and PROTEINS, the graph-agnostic MLP baselines perform as good as GNNs. Our observations reiterate how experiments on the small TU datasets are difficult to determine which GNNs are powerful and robust.\n\n\nG. A Note on Graph Size Normalization\n\nIntuitively, batching graphs of variable sizes may lead to node representation at different scales, making it difficult to learn the optimal statistics \u00b5 and \u03c3 for BatchNorm across irregular batch sizes and variable graphs. A preliminary version of this work introduced a graph size normalization technique called GraphNorm, which normalizes the node features h i w.r.t. the graph size, i.e.,h\ni = h i \u00d7 1 \u221a V ,(70)\nwhere V is the number of graph nodes. The GraphNorm layer is placed before the BatchNorm layer.\n\nWe would like to note that GraphNorm does not have any concrete theoretical basis as of now, and was proposed based on initially promising empirical results on datasets such as ZINC and CLUSTER. Future work shall investigate more principled approaches towards designing normalization layers for graph structured data.\n\n\nH. Elaboration on Benchmarking Design Choices\n\nIn Section 2, we provided a brief overview on the design choices that we had to make to build the proposed benchmarking framework. In particular, the decisions on the selection of the specific graph datasets that we have included in this framework, the necessity to constraint model parameters for comparison of GNNs' performance, and whether a standard codebase with data, training, evaluation pipelines is required can be derived from several reasonings. In this section, we provide an elaborate discussion on these factors and how possible extensions can be developed in future with ease and as per required by a research agenda. Datasets. Our collection of datasets is based on medium-scale size and criteria of diversity in terms of the end-application domains, learning tasks at graph-, edge-, or node-levels, and their source of construction being real or mathematical. The medium-scale size of datasets enables quick prototyping of novel ideas and robust analysis could be generated in single experiments in as less as 12 hours of maximum time per experiment. Similarly, the diversity ensures a model can be tested on not just one end-application domain but a number of such domains. However, despite the best efforts, after any collection of datasets in such a research area where a general GNN architecture is expected to be robust to a variety of tasks and domains, there could always be need of additional datasets. Due to this necessity, the proposed framework can be extended with new datasets conveniently by any researchers adopting it. We have also observed the open-sourced GitHub repo of our framework being used accordingly with an example repo being https://github.com/karl-zhao/benchmarking-gnns-pyg (Zhao et al., 2020) which extends the framework with additional node classification datasets as well as adopts it in Pytorch Geometric  instead of DGL. Such adoption of our framework demonstrates its flexibility and the supported convenient extensions. We provide detailed instructions on adding new datasets to the framework in our GitHub repository's README . Parameter Budgets. As we have already mentioned, we designed the framework with the objective that it is used to conveniently 'identify first principles' in GNNs' research and not drive a model towards achieving SOTA performance. To enforce this, a straightforward and sound choice is to constraint model parameters and fix it to a specific number (as eg. 100k and 500k) when comparing two or more GNNs. With this choice, we can likely rely on the inference that performance gains are coming from architectural designs and not merely large trainable parameters. The parameter budgeting also tells that the proposed framework may not be ideal to optimize a model to achieve SOTA by tuning hyperparameters, increasing model size to as much parameters as a server can fit, etc. However, we believe we condition the framework to be suitable for identifying performance trends and infer which first principles work robustly across different model experiments. Once such principles are identified, models can further be scaled without any constraints to achieve SOTA performance targeted benchmarks, beyond the datasets we included here. Codebase. A major contribution of this work is the release of the open-source coding infrastructure on GitHub. As observed since the first release in March 2020, the framework has been used extensively to develop new ideas in the field. In the existing literature prior to this work (Errica et al., 2019), it was a major issue that different research papers in this field adopted inconsistent model comparison methods. Our framework addresses this need of having a standard codebase that helps in training and evaluating GNNs on a collection of appropriate datasets with consistent settings. While a limiting perspective to such codebase can be that it restricts on the diverse choices which researchers often adopt in deep learning to fully realise the capabilities of a model, we understand that we have set out specific objectives of the need of the proposed coding infrastructure and any extensions with other training settings to the codebase can be done by augmenting methods or modules that applies to each model in a fair and consistent way. SBM-CLUSTER. The plots show the memory allocated during the model's forward pass using a batch of graphs (128 graphs for ZINC and 64 for SBM-CLUSTER) and is computed by using PyTorch's torch.cuda.memory_allocated(device) functionality. Overall, it can be observed that GatedGCN is a relatively higher memory-intensive model as compared with GCN and GAT, see Section B.1 for the respective models' equations.\n\nFigure 1 :\n1Overview sketch of the proposed GNN benchmarking framework with different modular components. This benchmark is built upon DGL and PyTorch libraries.\n\nFigure 2 :\n2class NameOfDataset(torch.utils.data.Dataset):def __init__(self, name='name_of_dataset'): # existing code to load dataset def _add_positional_encodings(self, args): # new code that precomputes and adds # positional encoding using eigenvectors Primary code block in data module to implement Graph PE.\n\nFigure 5 :\n5A generic graph neural network layer. Figure adapted fromBresson and Laurent (2017).\n\nReLUFigure 6 Figure 7 :\n67GraphSage Layer\n\nFigure 9 :\n9MoNet Layer et al.\n\nFigure 11 :\n11GIN Layer related to the standard sparse attention mechanism (Bahdanau et al., 2014). Different from other anisotropic GNNs, the GatedGCN architecture explicitly maintains edge features\u00ea ij at each layer, following Bresson and Laurent (2019); Joshi et al. (2019).\n\nFigure 12 :Figure 13 :\n12133WLRingGNN Layer discriminative k-WL GNNs in(Morris et al., 2019;Maron et al., 2019a). However, k-WL GNNs require the use of tensors of rank k, which is intractable in practice for k > 2.As a result, Maron et al. (2019a) proposed a model, namely 3-WL GNNs, that uses rank-2 tensors while being 3-WL provable. This 3-WL model improves the space/time complexities of Morris et al. (2019) from O(n 3 )/O(n 4 ) to O(n 2 )/O(n 3 ) respectively.\n\nFigure 15 :\n15Sample graphs from the TSP dataset. Nodes are colored blue and edges on the groundtruth TSP tours are colored red.\n\n\nof eigenvectors by taking the absolute value. This choice seriously degrades the expressivity power of the positional features.\n\nFigure 16 :\n16Memory consumed by the GPU device in a forward pass of a batch during training. All GNNs shown here have 500k learnable parameters. Batch size is 128 for ZINC and 64 for SBM-CLUSTER.\n\n\n).Node feat. \n\nEdge feat. \n\nG \nr \na \np \nh \n\ue233 \n\n{ \n} \u210e \n\n0 \n\n{ \n} \n\n0 \n\nEmbedding \n\nEmbedding \n\n1 \n2 \n\n0 \n3 \n\n2 \n4 \n\n1 \n3 \n\n3 \n4 \n\n0 \n1 \n\nL \na \ny \ne \nr \n\u2113 \n: \n{ \n} \n, \n{ \n} \n\u210e \n\n\u2113 \n\u2113 \n\nL \na \ny \ne \nr \n\u2113 \n+ \n1 \n: \n{ \n} \n, \n{ \n} \n\u210e \n\n\u2113 \n+ \n1 \n\u2113 \n+ \n1 \n\n1 \n2 \n\n0 \n3 \n\n2 \n4 \n\n1 \n3 \n\n3 \n4 \n\n0 \n1 \n\n\u210e \n\n0 \n\n\u210e \n\n2 \n\n\u210e \n\n1 \n\n\u210e \n\n4 \n\n\u210e \n\n3 \n\n\u210e \n\n0 \n\n\u210e \n\n2 \n\n\u210e \n\n1 \n\n\u210e \n\n4 \n\n\u210e \n\n3 \n\nG \nN \nN \n\n\u2113 \n\n\u210e \n\nMLP \nNode Predictions \n\n1 \n\n\ue242 \n\u2211 \n\n= \n0 \n\n\ue242 \n\n\u210e \n\nGraph Prediction \nMLP \n\nC \no \nn \nc \na \nt \n( \n, \n) \n\u210e \n\u210e \n\nEdge Predictions \nMLP \n\nInput Layer \nGNN Layer \n\n\u00d7 \n\nPrediction Layer \n\n\n\nTable 2 :\n2Summary statistics of all datasets. Numbers in parentheses of Node features and Edge features are the dimensions. S.P. denotes shortest path.\n\n\nZINC Model L #Param Test MAE\u00b1s.d. Train MAE\u00b1s.d. #Epoch Epoch/TotalMLP \n4 \n108975 \n0.706\u00b10.006 \n0.644\u00b10.005 \n116.75 \n1.01s/0.03hr \nvanilla GCN \n4 \n103077 \n0.459\u00b10.006 \n0.343\u00b10.011 \n196.25 \n2.89s/0.16hr \n16 \n505079 \n0.367\u00b10.011 \n0.128\u00b10.019 \n197.00 \n12.78s/0.71hr \nGraphSage \n4 \n94977 \n0.468\u00b10.003 \n0.251\u00b10.004 \n147.25 \n3.74s/0.15hr \n16 \n505341 \n0.398\u00b10.002 \n0.081\u00b10.009 \n145.50 \n16.61s/0.68hr \nGCN \n4 \n103077 \n0.416\u00b10.006 \n0.313\u00b10.011 \n159.50 \n1.53s/0.07hr \n16 \n505079 \n0.278\u00b10.003 \n0.101\u00b10.011 \n159.25 \n3.66s/0.16hr \nMoNet \n4 \n106002 \n0.397\u00b10.010 \n0.318\u00b10.016 \n188.25 \n1.97s/0.10hr \n16 \n504013 \n0.292\u00b10.006 \n0.093\u00b10.014 \n171.75 \n10.82s/0.52hr \nGAT \n4 \n102385 \n0.475\u00b10.007 \n0.317\u00b10.006 \n137.50 \n2.93s/0.11hr \n16 \n531345 \n0.384\u00b10.007 \n0.067\u00b10.004 \n144.00 \n12.98s/0.53hr \nGatedGCN \n4 \n105735 \n0.435\u00b10.011 \n0.287\u00b10.014 \n173.50 \n5.76s/0.28hr \nGatedGCN-E \n4 \n105875 \n0.375\u00b10.003 \n0.236\u00b10.007 \n194.75 \n5.37s/0.29hr \n16 \n504309 \n0.282\u00b10.015 \n0.074\u00b10.016 \n166.75 \n20.50s/0.96hr \nGatedGCN-E-PE 16 \n505011 \n0.214\u00b10.013 \n0.067\u00b10.019 \n185.00 \n10.70s/0.56hr \nGIN \n4 \n103079 \n0.387\u00b10.015 \n0.319\u00b10.015 \n153.25 \n2.29s/0.10hr \n16 \n509549 \n0.526\u00b10.051 \n0.444\u00b10.039 \n147.00 \n10.22s/0.42hr \nRingGNN \n2 \n97978 \n0.512\u00b10.023 \n0.383\u00b10.020 \n90.25 \n327.65s/8.32hr \nRingGNN-E \n2 \n104403 \n0.363\u00b10.026 \n0.243\u00b10.025 \n95.00 \n366.29s/9.76hr \n2 \n527283 \n0.353\u00b10.019 \n0.236\u00b10.019 \n79.75 \n293.94s/6.63hr \n8 \n510305 \nDiverged \nDiverged \nDiverged \nDiverged \n3WLGNN \n3 \n102150 \n0.407\u00b10.028 \n0.272\u00b10.037 \n111.25 \n286.23s/8.88hr \n3WLGNN-E \n3 \n103098 \n0.256\u00b10.054 \n0.140\u00b10.044 \n117.25 \n334.69s/10.90hr \n3 \n507603 \n0.303\u00b10.068 \n0.173\u00b10.041 \n120.25 \n329.49s/11.08hr \n8 \n582824 \n0.303\u00b10.057 \n0.246\u00b10.043 \n52.50 \n811.27s/12.15hr \n\n\n\nTable 3 :\n3Benchmarking results for ZINC for graph regression. Results (lower is better) are averaged over 4 runs with 4 different seeds. Red: the best model, Violet: good models. The suffix -E denotes the use of available edge features, and the suffix -PE denote the use of Laplacian Eigenvectors as node positional encodings with dimension 8.\n\n\nModel L #Param TestMAE\u00b1s.d. TrainMAE\u00b1s.d. Epochs Epoch/TotalMLP \n4 \n114525 \n1.744\u00b10.016 \n1.413\u00b10.042 \n85.75 \n0.61s/0.02hr \n\nvanilla GCN \n4 \n108442 \n1.483\u00b10.014 \n0.791\u00b10.034 \n110.25 \n1.14s/0.04hr \n16 \n511443 \n1.458\u00b10.011 \n0.567\u00b10.027 \n121.50 \n2.83s/0.10hr \nGraphSage \n4 \n109620 \n1.431\u00b10.010 \n0.666\u00b10.027 \n106.00 \n1.51s/0.05hr \n16 \n509078 \n1.402\u00b10.013 \n0.402\u00b10.013 \n110.50 \n3.20s/0.10hr \n\nGCN \n4 \n108442 \n1.372\u00b10.020 \n0.593\u00b10.030 \n135.00 \n1.28s/0.05hr \n16 \n511443 \n1.333\u00b10.013 \n0.382\u00b10.018 \n137.25 \n3.31s/0.13hr \nMoNet \n4 \n109332 \n1.395\u00b10.027 \n0.557\u00b10.022 \n125.50 \n1.68s/0.06hr \n16 \n507750 \n1.501\u00b10.056 \n0.444\u00b10.024 \n110.00 \n3.62s/0.11hr \nGAT \n4 \n108289 \n1.441\u00b10.023 \n0.678\u00b10.021 \n104.50 \n1.92s/0.06hr \n16 \n540673 \n1.403\u00b10.008 \n0.386\u00b10.014 \n111.75 \n4.44s/0.14hr \nGatedGCN \n4 \n108325 \n1.352\u00b10.034 \n0.576\u00b10.056 \n142.75 \n2.28s/0.09hr \n16 \n507039 \n1.355\u00b10.016 \n0.465\u00b10.038 \n99.25 \n5.52s/0.16hr \nGatedGCN-E \n4 \n108535 \n1.295\u00b10.016 \n0.544\u00b10.033 \n116.25 \n2.29s/0.08hr \n16 \n507273 \n1.308\u00b10.013 \n0.367\u00b10.012 \n110.25 \n5.61s/0.18hr \nGatedGCN-E-PE 16 \n507663 \n0.996\u00b10.008 \n0.372\u00b10.016 \n105.25 \n5.70s/0.30hr \n\nGIN \n4 \n107149 \n1.894\u00b10.024 \n0.660\u00b10.027 \n115.75 \n1.55s/0.05hr \n16 \n514137 \n1.962\u00b10.058 \n0.850\u00b10.054 \n128.50 \n3.97s/0.14hr \nRingGNN \n2 \n116643 \n20.264\u00b17.549 \n0.625\u00b10.018 \n54.25 \n113.99s/1.76hr \nRingGNN-E \n2 \n123157 \n3.769\u00b11.012 \n0.470\u00b10.022 \n63.75 \n125.17s/2.26hr \n2 \n523935 \nDiverged \nDiverged \nDiverged \nDiverged \n8 \n-\nDiverged \nDiverged \nDiverged \nDiverged \n3WLGNN \n3 \n110919 \n1.154\u00b10.050 \n0.434\u00b10.026 \n66.75 \n130.92s/2.48hr \n3 \n525423 \n1.108\u00b10.036 \n0.405\u00b10.031 \n70.75 \n131.12s/2.62hr \n3WLGNN-E \n3 \n112104 \n1.042\u00b10.064 \n0.307\u00b10.024 \n68.50 \n139.04s/2.70hr \n3 \n528123 \n1.052\u00b10.034 \n0.287\u00b10.023 \n67.00 \n140.43s/2.67hr \n8 \n-\nDiverged \nDiverged \nDiverged \nDiverged \n\n\n\nTable 4 :\n4Benchmarking results for AQSOL for graph regression. Results (lower is better) are averaged over 4 runs with 4 different seeds. Red: the best model, Violet: good models. The suffix -E denotes the use of available edge features, and the suffix -PE denote the use of Laplacian Eigenvectors as node positional encodings with dimension 4.OGBL-COLLAB Model L #Param Test Hits\u00b1s.d. Train Hits\u00b1s.d. #Epoch Epoch/TotalMLP 3 \n39441 \n20.350\u00b12.168 \n29.807\u00b13.360 \n147.50 \n2.09s/0.09hr \n\nvanilla GCN 3 \n40479 \n50.422\u00b11.131 \n92.112\u00b10.991 \n122.50 \n351.05s/12.04hr \nGraphSage 3 \n39856 \n51.618\u00b10.690 \n99.949\u00b10.052 \n152.75 \n277.93s/11.87hr \n\nGCN 3 \n40479 \n48.956\u00b11.143 \n87.385\u00b12.056 \n142.25 \n7.66s/0.31hr \nMoNet 3 \n39751 \n36.144\u00b12.191 \n61.156\u00b13.973 \n167.50 \n26.69s/1.26hr \nGAT 3 \n42637 \n51.501\u00b10.962 \n97.851\u00b11.114 \n157.00 \n18.12s/0.80hr \nGatedGCN 3 \n40965 \n52.635\u00b11.168 \n96.103\u00b11.876 \n95.00 \n453.47s/12.09hr \nGatedGCN-PE 3 \n41889 \n52.849\u00b11.345 \n96.165\u00b10.453 \n94.75 \n452.75s/12.08hr \nGatedGCN-E 3 \n40965 \n49.212\u00b11.560 \n88.747\u00b11.058 \n95.00 \n451.21s/12.03hr \n\nGIN 3 \n39544 \n41.730\u00b12.284 \n70.555\u00b14.444 \n140.25 \n8.66s/0.34hr \n\nRingGNN -\n-\nOOM \nRingGNN and 3WLGNN rely \non dense tensors which leads \nto OOM on both GPU and \nCPU memory. \n3WLGNN -\n-\nOOM \n\nMatrix Fact. -60546561 \n44.206\u00b10.452 \n100.000\u00b10.000 \n254.33 \n2.66s/0.21hr \n\n\n\nTable 5 :\n5Benchmarking results for OGBL-COLLAB for link prediction. Results (higher is better) are averaged over 4 runs with 4 different seeds. Red: the best model, Violet: good models. The suffix -E denotes the use of available edge features, and the suffix -PE denote the use of Laplacian Eigenvectors as node positional encodings with dimension 20.\n\n\nWikiCSModel L #Param Test Acc.\u00b1s.d. Train Acc.\u00b1s.d. #Epoch Epoch/TotalMLP 4 \n110710 \n59.452\u00b12.327 \n85.347\u00b15.440 \n322.46 \n0.01s/0.03hr \n\nvanilla GCN 4 \n104560 \n77.103\u00b10.830 \n98.918\u00b10.619 \n293.84 \n0.05s/0.10hr \nGraphSage 4 \n101775 \n74.767\u00b10.950 \n99.976\u00b10.095 \n303.68 \n0.06s/0.12hr \n\nGCN 4 \n104560 \n77.469\u00b10.854 \n98.925\u00b10.590 \n299.85 \n0.06s/0.11hr \nMoNet 4 \n106182 \n77.431\u00b10.669 \n98.737\u00b10.710 \n355.81 \n0.17s/0.36hr \nMoNet-PE 4 \n107862 \n77.481\u00b10.712 \n98.767\u00b10.726 \n357.74 \n0.19s/0.81hr \nGAT 4 \n105520 \n76.908\u00b10.821 \n99.914\u00b10.262 \n275.48 \n1.12s/2.22hr \nGatedGCN 4 \n109280 \nOOM \n\nGIN 4 \n109782 \n75.857\u00b10.577 \n99.575\u00b10.388 \n321.25 \n0.06s/0.13hr \n\n\n\nTable 6 :\n6Benchmarking results for WikiCS for node classification. Results (higher is better) are averaged over 4 runs with 4 different seeds. Red: the best model, Violet: good models. The suffix -PE denote the use of Laplacian Eigenvectors as node positional encodings with dimension 20.\n\nTable 7 :\n7Benchmarking results for Super-pixels datasets for graph classification. Results (higher is better) are averaged over 4 runs with 4 different seeds. Red: the best model, Violet: good models.\n\n\n, .., 6}. If the value PATTERN CLUSTER Model L #Param Test Acc.\u00b1s.d. Train Acc.\u00b1s.d. #Epoch Epoch/Total #Param Test Acc.\u00b1s.d. Train Acc.\u00b1s.d. #Epoch Epoch/TotalMLP \n4 \n105263 \n50.519\u00b10.000 \n50.487\u00b10.014 \n42.25 \n8.95s/0.11hr \n106015 \n20.973\u00b10.004 \n20.938\u00b10.002 \n42.25 \n5.83s/0.07hr \n\nvanilla GCN \n4 \n100923 \n63.880\u00b10.074 \n65.126\u00b10.135 \n105.00 \n118.85s/3.51hr \n101655 \n53.445\u00b12.029 \n54.041\u00b12.197 \n70.00 \n65.72s/1.30hr \n16 \n500823 \n71.892\u00b10.334 \n78.409\u00b11.592 \n81.50 \n492.19s/11.31hr \n501687 \n68.498\u00b10.976 \n71.729\u00b12.212 \n79.75 \n270.28s/6.08hr \nGraphSage \n4 \n101739 \n50.516\u00b10.001 \n50.473\u00b10.014 \n43.75 \n93.41s/1.17hr \n102187 \n50.454\u00b10.145 \n54.374\u00b10.203 \n64.00 \n53.56s/0.97hr \n16 \n502842 \n50.492\u00b10.001 \n50.487\u00b10.005 \n46.50 \n391.19s/5.19hr \n503350 \n63.844\u00b10.110 \n86.710\u00b10.167 \n57.75 \n225.61s/3.70hr \n\nGCN \n4 \n100923 \n85.498\u00b10.045 \n85.598\u00b10.043 \n65.00 \n19.21s/0.36hr \n101655 \n47.828\u00b11.510 \n48.258\u00b11.607 \n63.50 \n12.84s/0.23hr \n16 \n500823 \n85.614\u00b10.032 \n86.034\u00b10.087 \n66.00 \n37.08s/0.70hr \n501687 \n69.026\u00b11.372 \n73.749\u00b12.570 \n77.75 \n30.20s/0.66hr \nMoNet \n4 \n103775 \n85.482\u00b10.037 \n85.569\u00b10.044 \n89.75 \n35.71s/0.90hr \n104227 \n58.064\u00b10.131 \n58.454\u00b10.183 \n76.25 \n24.29s/0.52hr \n16 \n511487 \n85.582\u00b10.038 \n85.720\u00b10.068 \n81.75 \n68.49s/1.58hr \n511999 \n66.407\u00b10.540 \n67.727\u00b10.649 \n77.75 \n47.82s/1.05hr \nGAT \n4 \n109936 \n75.824\u00b11.823 \n77.883\u00b11.632 \n96.00 \n20.92s/0.57hr \n110700 \n57.732\u00b10.323 \n58.331\u00b10.342 \n67.25 \n14.17s/0.27hr \n16 \n526990 \n78.271\u00b10.186 \n90.212\u00b10.476 \n53.50 \n50.33s/0.77hr \n527874 \n70.587\u00b10.447 \n76.074\u00b11.362 \n73.50 \n35.94s/0.75hr \nGatedGCN \n4 \n104003 \n84.480\u00b10.122 \n84.474\u00b10.155 \n78.75 \n139.01s/3.09hr \n104355 \n60.404\u00b10.419 \n61.618\u00b10.536 \n94.50 \n79.97s/2.13hr \n16 \n502223 \n85.568\u00b10.088 \n86.007\u00b10.123 \n65.25 \n644.71s/11.91hr \n502615 \n73.840\u00b10.326 \n87.880\u00b10.908 \n60.00 \n400.07s/6.81hr \nGatedGCN-PE 16 \n502457 \n86.508\u00b10.085 \n86.801\u00b10.133 \n65.75 \n647.94s/12.08hr \n504253 \n76.082\u00b10.196 \n88.919\u00b10.720 \n57.75 \n399.66s/6.58hr \n\nGIN \n4 \n100884 \n85.590\u00b10.011 \n85.852\u00b10.030 \n93.00 \n15.24s/0.40hr \n103544 \n58.384\u00b10.236 \n59.480\u00b10.337 \n74.75 \n10.71s/0.23hr \n16 \n508574 \n85.387\u00b10.136 \n85.664\u00b10.116 \n86.75 \n25.14s/0.62hr \n517570 \n64.716\u00b11.553 \n65.973\u00b11.816 \n80.75 \n20.67s/0.47hr \nRingGNN \n2 \n105206 \n86.245\u00b10.013 \n86.118\u00b10.034 \n75.00 \n573.37s/12.17hr \n104746 \n42.418\u00b120.063 \n42.520\u00b120.212 \n74.50 \n428.24s/8.79hr \n2 \n504766 \n86.244\u00b10.025 \n86.105\u00b10.021 \n72.00 \n595.97s/12.15hr \n524202 \n22.340\u00b10.000 \n22.304\u00b10.000 \n43.25 \n501.84s/6.22hr \n8 \n505749 \nDiverged \nDiverged \nDiverged \nDiverged \n514380 \nDiverged \nDiverged \nDiverged \nDiverged \n3WLGNN \n3 \n103572 \n85.661\u00b10.353 \n85.608\u00b10.337 \n95.00 \n304.79s/7.88hr \n105552 \n57.130\u00b16.539 \n57.404\u00b16.597 \n116.00 \n219.51s/6.52hr \n3 \n502872 \n85.341\u00b10.207 \n85.270\u00b10.198 \n81.75 \n424.23s/9.56hr \n507252 \n55.489\u00b17.863 \n55.736\u00b18.024 \n66.00 \n319.98s/5.79hr \n8 \n581716 \nDiverged \nDiverged \nDiverged \nDiverged \n586788 \nDiverged \nDiverged \nDiverged \nDiverged \n\n\n\nTable 8 :\n8Benchmarking results for SBMs datasets for node classification. Results (higher is better) are averaged over 4 runs with 4 different seeds. Red: the best model, Violet: good models. The suffix -PE denote the use of Laplacian Eigenvectors as node positional encodings with dimension 2 for PATTERN and 20 for CLUSTER.\n\n\nTSP Model L #Param Test F1\u00b1s.d. Train F1\u00b1s.d. #Epoch Epoch/TotalMLP \n4 \n96956 \n0.544\u00b10.001 \n0.544\u00b10.001 \n164.25 \n50.15s/2.31hr \n\nvanilla GCN \n4 \n95702 \n0.630\u00b10.001 \n0.631\u00b10.001 \n261.00 \n152.89s/11.15hr \nGraphSage \n4 \n99263 \n0.665\u00b10.003 \n0.669\u00b10.003 \n266.00 \n157.26s/11.68hr \n\nGCN \n4 \n95702 \n0.643\u00b10.001 \n0.645\u00b10.002 \n261.67 \n57.84s/4.23hr \nMoNet \n4 \n99007 \n0.641\u00b10.002 \n0.643\u00b10.002 \n282.00 \n84.46s/6.65hr \nGAT \n4 \n96182 \n0.671\u00b10.002 \n0.673\u00b10.002 \n328.25 \n68.23s/6.25hr \nGatedGCN \n4 \n97858 \n0.791\u00b10.003 \n0.793\u00b10.003 \n159.00 \n218.20s/9.72hr \nGatedGCN-E \n4 \n97858 \n0.808\u00b10.003 \n0.811\u00b10.003 \n197.00 \n218.51s/12.04hr \nGatedGCN-E 16 \n500770 \n0.838\u00b10.002 \n0.850\u00b10.001 \n53.00 \n807.23s/12.17hr \n\nGIN \n4 \n99002 \n0.656\u00b10.003 \n0.660\u00b10.003 \n273.50 \n72.73s/5.56hr \nRingGNN \n2 \n106862 \n0.643\u00b10.024 \n0.644\u00b10.024 \n2.00 \n17850.52s/17.19hr \n2 \n507938 \n0.704\u00b10.003 \n0.705\u00b10.003 \n3.00 \n12835.53s/16.08hr \n8 \n506564 \nDiverged \nDiverged \nDiverged \nDiverged \n3WLGNN \n3 \n106366 \n0.694\u00b10.073 \n0.695\u00b10.073 \n2.00 \n17468.81s/16.59hr \n3 \n506681 \n0.288\u00b10.311 \n0.290\u00b10.312 \n2.00 \n17190.17s/16.51hr \n8 \n508832 \nOOM \nOOM \nOOM \nOOM \n\nk-NN Heuristic \nk =2 \nTest F1: 0.693 \n\n\n\nTable 9 :\n9Benchmarking results for TSP for edge classification. Results (higher is better) are averaged over 4 runs with 4 different seeds. Red: the best model, Violet: good models. The suffix -E denotes the use of available edge features.\n\nTable 10 :\n10Results for the CSL dataset, with and without Laplacian Positional Encodings. Results are from 5-fold cross validation, run 20 times with different seeds. Red: the best model, Violet: good models. The dimension of node positional encoding with Laplacian eigenvectors is 20.\n\nTable 11 :\n11Test accuracy on the CYCLES dataset. Results (higher is better) are averaged over 4 runs \nwith 4 different seeds. The performance on test sets with models trained on varying train data size is \nshow, following Vignac et al. (2020). Bold shows the best result out of a GNN's two model instances \nthat use and not use PE. The dimension for PE is 20. \n\n\n\nTable 12 :\n12Mean Log 10 MSE for each task over 4 runs with 4 different seeds. Average denotes the combined average of all the tasks. Log 10 MSE is on the test set (lower is better). Bold shows the best result out of a GNN's two model instances that use and not use PE. The dimension for PE is 12.\n\n\nPE type L #Param Test Acc.\u00b1s.d. Train Acc.\u00b1s.d. #Epochs Epoch/Total PE type L #Param Test MAE\u00b1s.d. Train MAE\u00b1s.d. #Epochs Epoch/TotalCSL \n\nNo PE 4 \n104007 \n10.000\u00b10.000 \n10.000\u00b10.000 \n54.00 \n0.58s/0.05hr \nEigVecs-20 4 \n105407 \n68.633\u00b17.143 \n99.811\u00b10.232 \n107.16 \n0.59s/0.09hr \nRand sign(EigVecs) 4 \n105407 \n99.767\u00b10.394 \n99.689\u00b10.550 \n188.76 \n0.59s/0.16hr \nAbs(EigVecs) 4 \n105407 \n99.433\u00b11.133 \n100.000\u00b10.000 \n143.64 \n0.60s/0.12hr \nFixed node ordering 4 \n106807 \n10.533\u00b14.469 \n76.056\u00b114.136 \n60.56 \n0.59s/0.05hr \nRand node ordering 4 \n106807 \n11.133\u00b12.571 \n10.944\u00b12.106 \n91.60 \n0.60s/0.08hr \n\nPATTERN \n\nNo PE 16 \n502223 \n85.605\u00b10.105 \n85.999\u00b10.145 \n62.00 \n646.03s/11.36hr \nEigVecs-2 16 \n505421 \n86.029\u00b10.085 \n86.955\u00b10.227 \n65.00 \n645.36s/11.94hr \nRand sign(EigVecs) 16 \n502457 \n86.508\u00b10.085 \n86.801\u00b10.133 \n65.75 \n647.94s/12.08hr \nAbs(EigVecs) 16 \n505421 \n86.393\u00b10.037 \n87.011\u00b10.172 \n62.00 \n645.90s/11.41hr \nFixed node ordering 16 \n516887 \n80.133\u00b10.202 \n98.416\u00b10.141 \n45.00 \n643.23s/8.27hr \nRand node ordering 16 \n516887 \n85.767\u00b10.044 \n85.998\u00b10.063 \n64.50 \n645.09s/11.79hr \n\nCLUSTER \n\nNo PE 16 \n502615 \n73.684\u00b10.348 \n88.356\u00b11.577 \n61.50 \n399.44s/6.97hr \nEigVecs-20 16 \n504253 \n75.520\u00b10.395 \n89.332\u00b11.297 \n49.75 \n400.50s/5.70hr \nRand sign(EigVecs) 16 \n504253 \n76.082\u00b10.196 \n88.919\u00b10.720 \n57.75 \n399.66s/6.58hr \nAbs(EigVecs) 16 \n504253 \n73.796\u00b10.234 \n91.125\u00b11.248 \n58.75 \n398.97s/6.68hr \nFixed node ordering 16 \n517435 \n69.232\u00b10.265 \n92.298\u00b10.712 \n51.00 \n400.40s/5.82hr \nRand node ordering 16 \n517435 \n74.656\u00b10.314 \n82.940\u00b11.718 \n61.00 \n397.75s/6.88hr \n\nCOLLAB \nNo PE 3 \n40965 \n52.635\u00b11.168 \n96.103\u00b11.876 \n95.00 \n453.47s/12.09hr \nEigVecs-20 3 \n41889 \n52.326\u00b10.678 \n96.700\u00b11.296 \n95.00 \n452.40s/12.10hr \nRand sign(EigVecs) 3 \n41889 \n52.849\u00b11.345 \n96.165\u00b10.453 \n94.75 \n452.75s/12.08hr \nAbs(EigVecs) 3 \n41889 \n51.419\u00b11.109 \n95.984\u00b11.157 \n95.00 \n451.36s/12.07hr \n\nZINC \n\nNo PE 16 \n504153 \n0.354\u00b10.012 \n0.095\u00b10.012 \n165.25 \n10.52s/0.49hr \nEigVecs-8 16 \n505011 \n0.319\u00b10.010 \n0.038\u00b10.007 \n143.25 \n10.62s/0.43hr \nRand sign(EigVecs) 16 \n505011 \n0.214\u00b10.013 \n0.067\u00b10.019 \n185.00 \n10.70s/0.56hr \nAbs(EigVecs) 16 \n505011 \n0.214\u00b10.009 \n0.035\u00b10.011 \n167.50 \n10.61s/0.50hr \nFixed node ordering 16 \n507195 \n0.431\u00b10.007 \n0.044\u00b10.009 \n118.25 \n10.62s/0.35hr \nRand node ordering 16 \n507195 \n0.321\u00b10.015 \n0.177\u00b10.015 \n184.75 \n10.55s/0.55hr \n\n\n\nTable 13 :\n13Study of positional encodings (PEs) with the GatedGCN model (Bresson and Laurent, \n2017). Performance reported on the test sets of CSL, ZINC, PATTERN, CLUSTER and COLLAB \n(higher is better, except for ZINC). Red: the best model. \n\n\n\n\nModel E.Feat. E.Repr. L #Param Test Acc.\u00b1s.d. Train Acc.\u00b1s.d. #Epochs Epoch/TotalTSP \n\nGatedGCN \n\nx \nx \n4 \n99026 \n0.646\u00b10.002 \n0.648\u00b10.002 \n197.50 \n150.83s/8.34hr \nx \n4 \n98174 \n0.757\u00b10.009 \n0.760\u00b10.009 \n218.25 \n197.80s/12.06hr \n4 \n97858 \n0.791\u00b10.003 \n0.793\u00b10.003 \n159.00 \n218.20s/9.72hr \nGatedGCN-E \n4 \n97858 \n0.808\u00b10.003 \n0.811\u00b10.003 \n197.00 \n218.51s/12.04hr \n\nGAT \n\nx \nx \n4 \n95462 \n0.643\u00b10.001 \n0.644\u00b10.001 \n132.75 \n325.22s/12.10hr \nx \n4 \n96182 \n0.671\u00b10.002 \n0.673\u00b10.002 \n328.25 \n68.23s/6.25hr \n4 \n96762 \n0.748\u00b10.022 \n0.749\u00b10.022 \n93.00 \n462.22s/12.10hr \nGAT-E \n4 \n96762 \n0.782\u00b10.006 \n0.783\u00b10.006 \n98.00 \n438.37s/12.11hr \n\nCOLLAB \n\nGatedGCN \n\nx \nx \n3 \n26593 \n35.989\u00b11.549 \n60.586\u00b14.251 \n148.00 \n263.62s/10.90h \nx \n3 \n26715 \n50.668\u00b10.291 \n96.128\u00b10.576 \n172.00 \n384.39s/18.44hr \n3 \n27055 \n51.537\u00b11.038 \n96.524\u00b11.704 \n188.67 \n376.67s/19.85hr \nGatedGCN-E \n3 \n27055 \n47.212\u00b12.016 \n85.801\u00b10.984 \n156.67 \n377.04s/16.49hr \n\nGAT \n\nx \nx \n3 \n28201 \n41.141\u00b10.701 \n70.344\u00b11.837 \n153.50 \n371.50s/15.97hr \nx \n3 \n28561 \n50.662\u00b10.687 \n96.085\u00b10.499 \n174.50 \n403.52s/19.69hr \n3 \n26676 \n49.674\u00b10.105 \n92.665\u00b10.719 \n201.00 \n349.19s/19.59hr \nGAT-E \n3 \n26676 \n44.989\u00b11.395 \n82.230\u00b14.941 \n120.67 \n328.29s/11.10hr \n\n\n\nTable 14 :\n14Study of anisotropy and edge representations for link prediction on TSP and COLLAB.Red: the best model, Violet: good models.\n\nTable 15 :\n15Study of anisotropic edge features and representations for link prediction on COLLAB, including GraphSage models. Red: the best model, Violet: good models.\n\n\nTest Acc.\u00b1s.d. Train Acc.\u00b1s.d. #Epoch Epoch/Total Test Acc.\u00b1s.d. Train Acc.\u00b1s.d. #Epoch Epoch/TotalModel L #Param \nseed 1 \nseed 2 \nENZYMES \n\nMLP 4 OOM \nOOM \nOOM \nOOM \nOOM \nOOM \nOOM \nOOM \n3WLGNN 3 \n104124 \nOOM \nOOM \nOOM \nOOM \nOOM \nOOM \nOOM \nOOM \n\nPROTEINS \n\n. https://github.com/bknyaz/graph_attention_pool\nAcknowledgmentsXB is supported by NRF Fellowship NRFF2017-10, NUS-R-252-000-B97-133 and A*STAR Grant ID A20H4g2141. This research is supported by Nanyang Technological University, under SUG Grant (020724-00001). The authors thank the reviewers and the editor for their comments and suggestions, which greatly improved the manuscript.I. HardwareTiming research code can be tricky due to differences of implementations and hardware acceleration. Nonetheless, we take a practical view and report the average wall clock time per epoch and the total training time for each model. All experiments were implemented in DGL/PyTorch. We run experiments for MNIST, CIFAR10, ZINC, AQSOL, TSP, COLLAB, WikiCS, CSL, CYCLES, GraphTheoryProp and TUs on an Intel Xeon CPU E5-2690 v4 server with 4 Nvidia 1080Ti GPUs (11 GB), and for PATTERN and CLUSTER on an Intel Xeon Gold 6132 CPU with 4 Nvidia 2080Ti (11 GB) GPUs. Each experiment was run on a single GPU and 4 experiments were run on the server at any given time (on different GPUs). We run each experiment for a maximum of 12 hours.J. Memory UsageFor datasets that contain graphs with variable sizes, the memory consumed during training by the GPU device changes at each batch of graphs. We report inFigure 16the GPU memory consumption during the training of GCN, GAT and GatedGCN on two datasets-ZINC and\nCommunity detection and stochastic block models: recent developments. Emmanuel Abbe, The Journal of Machine Learning Research. 181Emmanuel Abbe. Community detection and stochastic block models: recent developments. The Journal of Machine Learning Research, 18(1):6446-6531, 2017.\n\nSlic superpixels compared to state-of-the-art superpixel methods. Radhakrishna Achanta, Appu Shaji, Kevin Smith, Aurelien Lucchi, Pascal Fua, Sabine Susstrunk, 0162-8828IEEE Trans. Pattern Anal. Mach. Intell. 3411Radhakrishna Achanta, Appu Shaji, Kevin Smith, Aurelien Lucchi, Pascal Fua, and Sabine Susstrunk. Slic superpixels compared to state-of-the-art superpixel methods. IEEE Trans. Pattern Anal. Mach. Intell., 34(11):2274-2282, November 2012. ISSN 0162-8828.\n\nDavid Applegate, Ribert Bixby, Vasek Chvatal, William Cook, Concorde tsp solver. David Applegate, Ribert Bixby, Vasek Chvatal, and William Cook. Concorde tsp solver, 2006.\n\nJimmy Lei Ba, Jamie Ryan Kiros, Geoffrey E Hinton, Layer normalization. NeurIPS workshop on Deep Learning. Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E Hinton. Layer normalization. NeurIPS workshop on Deep Learning, 2016.\n\nNeural machine translation by jointly learning to align and translate. Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio, arXiv:1409.0473arXiv preprintDzmitry Bahdanau, Kyunghyun Cho, and Yoshua Bengio. Neural machine translation by jointly learning to align and translate. arXiv preprint arXiv:1409.0473, 2014.\n\nInteraction networks for learning about objects, relations and physics. Peter Battaglia, Razvan Pascanu, Matthew Lai, Danilo Jimenez Rezende, Advances in neural information processing systems. Peter Battaglia, Razvan Pascanu, Matthew Lai, Danilo Jimenez Rezende, et al. Interac- tion networks for learning about objects, relations and physics. In Advances in neural information processing systems, pages 4502-4510, 2016.\n\nDirectional graph networks. Dominique Beaini, Saro Passaro, Vincent L\u00e9tourneau, Will Hamilton, Gabriele Corso, Pietro Li\u00f2, International Conference on Machine Learning. PMLRDominique Beaini, Saro Passaro, Vincent L\u00e9tourneau, Will Hamilton, Gabriele Corso, and Pietro Li\u00f2. Directional graph networks. In International Conference on Machine Learning, pages 748-758. PMLR, 2021.\n\nLaplacian eigenmaps for dimensionality reduction and data representation. Mikhail Belkin, Partha Niyogi, Neural computation. 156Mikhail Belkin and Partha Niyogi. Laplacian eigenmaps for dimensionality reduction and data representation. Neural computation, 15(6):1373-1396, 2003.\n\nMachine learning for combinatorial optimization: a methodological tour d'horizon. Yoshua Bengio, Andrea Lodi, Antoine Prouvost, arXiv:1811.06128arXiv preprintYoshua Bengio, Andrea Lodi, and Antoine Prouvost. Machine learning for combinatorial optimization: a methodological tour d'horizon. arXiv preprint arXiv:1811.06128, 2018.\n\nBeatrice Bevilacqua, Fabrizio Frasca, Derek Lim, Balasubramaniam Srinivasan, Chen Cai, Gopinath Balamurugan, Haggai Michael M Bronstein, Maron, arXiv:2110.02910Equivariant subgraph aggregation networks. arXiv preprintBeatrice Bevilacqua, Fabrizio Frasca, Derek Lim, Balasubramaniam Srinivasan, Chen Cai, Gopinath Balamurugan, Michael M Bronstein, and Haggai Maron. Equivariant subgraph aggregation networks. arXiv preprint arXiv:2110.02910, 2021.\n\nImproving graph neural network expressivity via subgraph isomorphism counting. Giorgos Bouritsas, Fabrizio Frasca, P Stefanos, Michael Zafeiriou, Bronstein, IEEE Transactions on Pattern Analysis and Machine Intelligence. Giorgos Bouritsas, Fabrizio Frasca, Stefanos P Zafeiriou, and Michael Bronstein. Improving graph neural network expressivity via subgraph isomorphism counting. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2022.\n\n. Xavier Bresson, Thomas Laurent, arXiv:1711.07553Residual gated graph convnets. arXiv preprintXavier Bresson and Thomas Laurent. Residual gated graph convnets. arXiv preprint arXiv:1711.07553, 2017.\n\nA two-step graph convolutional decoder for molecule generation. Xavier Bresson, Thomas Laurent, NeurIPS Workshop on Machine Learning and the Physical Sciences. Xavier Bresson and Thomas Laurent. A two-step graph convolutional decoder for molecule generation. In NeurIPS Workshop on Machine Learning and the Physical Sciences, 2019.\n\nGnn-film: Graph neural networks with feature-wise linear modulation. Marc Brockschmidt, arXiv:1906.12192arXiv preprintMarc Brockschmidt. Gnn-film: Graph neural networks with feature-wise linear modulation. arXiv preprint arXiv:1906.12192, 2019.\n\nJoan Bruna, Wojciech Zaremba, Arthur Szlam, Yann Lecun, arXiv:1312.6203Spectral networks and locally connected networks on graphs. arXiv preprintJoan Bruna, Wojciech Zaremba, Arthur Szlam, and Yann LeCun. Spectral networks and locally connected networks on graphs. arXiv preprint arXiv:1312.6203, 2013.\n\nLowdimensional hyperbolic knowledge graph embeddings. Ines Chami, Adva Wolf, Da-Cheng Juan, Frederic Sala, Sujith Ravi, Christopher R\u00e9, arXiv:2005.00545arXiv preprintInes Chami, Adva Wolf, Da-Cheng Juan, Frederic Sala, Sujith Ravi, and Christopher R\u00e9. Low- dimensional hyperbolic knowledge graph embeddings. arXiv preprint arXiv:2005.00545, 2020.\n\nAre powerful graph neural nets necessary? a dissection on graph classification. Ting Chen, Song Bian, Yizhou Sun, Ting Chen, Song Bian, and Yizhou Sun. Are powerful graph neural nets necessary? a dissection on graph classification, 2019a.\n\nLearning graph normalization for graph neural networks. Yihao Chen, Xin Tang, Xianbiao Qi, Chun-Guang Li, Rong Xiao, Neurocomputing. Yihao Chen, Xin Tang, Xianbiao Qi, Chun-Guang Li, and Rong Xiao. Learning graph normalization for graph neural networks. Neurocomputing, 2022.\n\nOn the equivalence between graph isomorphism testing and function approximation with gnns. Zhengdao Chen, Soledad Villar, Lei Chen, Joan Bruna, Advances in Neural Information Processing Systems. Zhengdao Chen, Soledad Villar, Lei Chen, and Joan Bruna. On the equivalence between graph isomorphism testing and function approximation with gnns. In Advances in Neural Information Processing Systems, pages 15868-15876, 2019b.\n\nClustergcn: An efficient algorithm for training deep and large graph convolutional networks. Wei-Lin Chiang, Xuanqing Liu, Si Si, Yang Li, Samy Bengio, Cho-Jui Hsieh, Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data MiningWei-Lin Chiang, Xuanqing Liu, Si Si, Yang Li, Samy Bengio, and Cho-Jui Hsieh. Cluster- gcn: An efficient algorithm for training deep and large graph convolutional networks. In Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pages 257-266, 2019.\n\nPrincipal neighbourhood aggregation for graph nets. Gabriele Corso, Luca Cavalleri, Dominique Beaini, Pietro Li\u00f2, Petar Veli\u010dkovi\u0107, Advances in Neural Information Processing Systems. 33Gabriele Corso, Luca Cavalleri, Dominique Beaini, Pietro Li\u00f2, and Petar Veli\u010dkovi\u0107. Principal neighbourhood aggregation for graph nets. Advances in Neural Information Processing Systems, 33:13260-13271, 2020.\n\nLearning symbolic physics with graph networks. Rui Miles D Cranmer, Peter Xu, Shirley Battaglia, Ho, arXiv:1909.05862arXiv preprintMiles D Cranmer, Rui Xu, Peter Battaglia, and Shirley Ho. Learning symbolic physics with graph networks. arXiv preprint arXiv:1909.05862, 2019.\n\nConvolutional neural networks on graphs with fast localized spectral filtering. Micha\u00ebl Defferrard, Xavier Bresson, Pierre Vandergheynst, Advances in Neural Information Processing Systems. 29Micha\u00ebl Defferrard, Xavier Bresson, and Pierre Vandergheynst. Convolutional neural networks on graphs with fast localized spectral filtering. In Advances in Neural Information Processing Systems 29, pages 3844-3852. 2016.\n\nMaximum likelihood from incomplete data via the em algorithm. P Arthur, Nan M Dempster, Donald B Laird, Rubin, Journal of the Royal Statistical Society: Series B (Methodological). 391Arthur P Dempster, Nan M Laird, and Donald B Rubin. Maximum likelihood from in- complete data via the em algorithm. Journal of the Royal Statistical Society: Series B (Methodological), 39(1):1-22, 1977.\n\nImageNet: A Large-Scale Hierarchical Image Database. J Deng, W Dong, R Socher, L.-J Li, K Li, L Fei-Fei, CVPR09. J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. ImageNet: A Large-Scale Hierarchical Image Database. In CVPR09, 2009.\n\nEta prediction with graph neural networks in google maps. Austin Derrow-Pinion, Jennifer She, David Wong, Oliver Lange, Todd Hester, Luis Perez, Marc Nunkesser, Seongjae Lee, Xueying Guo, Brett Wiltshire, Proceedings of the 30th ACM International Conference on Information & Knowledge Management. the 30th ACM International Conference on Information & Knowledge ManagementAustin Derrow-Pinion, Jennifer She, David Wong, Oliver Lange, Todd Hester, Luis Perez, Marc Nunkesser, Seongjae Lee, Xueying Guo, Brett Wiltshire, et al. Eta prediction with graph neural networks in google maps. In Proceedings of the 30th ACM International Conference on Information & Knowledge Management, pages 3767-3776, 2021.\n\nConvolutional networks on graphs for learning molecular fingerprints. Dougal David K Duvenaud, Jorge Maclaurin, Rafael Iparraguirre, Timothy Bombarell, Al\u00e1n Hirzel, Ryan P Aspuru-Guzik, Adams, Advances in neural information processing systems. David K Duvenaud, Dougal Maclaurin, Jorge Iparraguirre, Rafael Bombarell, Timothy Hirzel, Al\u00e1n Aspuru-Guzik, and Ryan P Adams. Convolutional networks on graphs for learning molecular fingerprints. In Advances in neural information processing systems, pages 2224-2232, 2015.\n\nGraph anisotropic diffusion for molecules. A A Ahmed, Gabriele Elhag, Hannes Corso, Michael M St\u00e4rk, Bronstein, ICLR2022 Machine Learning for Drug Discovery. Ahmed AA Elhag, Gabriele Corso, Hannes St\u00e4rk, and Michael M Bronstein. Graph anisotropic diffusion for molecules. In ICLR2022 Machine Learning for Drug Discovery, 2022.\n\nA fair comparison of graph neural networks for graph classification. Federico Errica, Marco Podda, Davide Bacciu, Alessio Micheli, Federico Errica, Marco Podda, Davide Bacciu, and Alessio Micheli. A fair comparison of graph neural networks for graph classification, 2019.\n\nFast graph representation learning with pytorch geometric. Matthias Fey, Jan Eric Lenssen, ICLR Workshop on Representation Learning on Graphs and Manifolds. Matthias Fey and Jan Eric Lenssen. Fast graph representation learning with pytorch geometric. ICLR Workshop on Representation Learning on Graphs and Manifolds, 2019.\n\nSpectral grouping using the nystrom method. Charless Fowlkes, Serge Belongie, Fan Chung, Jitendra Malik, IEEE transactions on pattern analysis and machine intelligence. 26Charless Fowlkes, Serge Belongie, Fan Chung, and Jitendra Malik. Spectral grouping using the nystrom method. IEEE transactions on pattern analysis and machine intelligence, 26 (2):214-225, 2004.\n\nNeural message passing for quantum chemistry. Justin Gilmer, S Samuel, Schoenholz, F Patrick, Oriol Riley, George E Vinyals, Dahl, Proceedings of the 34th International Conference on Machine Learning. the 34th International Conference on Machine Learning70Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, and George E Dahl. Neural message passing for quantum chemistry. In Proceedings of the 34th International Conference on Machine Learning-Volume 70, pages 1263-1272. JMLR. org, 2017.\n\nTransient networks of spatio-temporal connectivity map communication pathways in brain functional systems. Alessandra Griffa, Benjamin Ricaud, Kirell Benzi, Xavier Bresson, Alessandro Daducci, Pierre Vandergheynst, Jean-Philippe Thiran, Patric Hagmann, NeuroImage. 155Alessandra Griffa, Benjamin Ricaud, Kirell Benzi, Xavier Bresson, Alessandro Daducci, Pierre Vandergheynst, Jean-Philippe Thiran, and Patric Hagmann. Transient networks of spatio-temporal connectivity map communication pathways in brain functional systems. NeuroImage, 155:490-502, 2017.\n\nInductive representation learning on large graphs. Will Hamilton, Zhitao Ying, Jure Leskovec, Advances in Neural Information Processing Systems. Will Hamilton, Zhitao Ying, and Jure Leskovec. Inductive representation learning on large graphs. In Advances in Neural Information Processing Systems, pages 1024-1034, 2017.\n\nDeep residual learning for image recognition. Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, The IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In The IEEE Conference on Computer Vision and Pattern Recognition (CVPR), June 2016.\n\nRevisiting graph neural networks: All we have is low-pass filters. N T Hoang, Takanori Maehara, abs/1905.09550ArXiv. NT Hoang and Takanori Maehara. Revisiting graph neural networks: All we have is low-pass filters. ArXiv, abs/1905.09550, 2019.\n\nOpen graph benchmark: Datasets for machine learning on graphs. Weihua Hu, Matthias Fey, Marinka Zitnik, Yuxiao Dong, Hongyu Ren, Bowen Liu, Michele Catasta, Jure Leskovec, Advances in neural information processing systems. 33Weihua Hu, Matthias Fey, Marinka Zitnik, Yuxiao Dong, Hongyu Ren, Bowen Liu, Michele Catasta, and Jure Leskovec. Open graph benchmark: Datasets for machine learning on graphs. Advances in neural information processing systems, 33:22118-22133, 2020.\n\nOgblsc: A large-scale challenge for machine learning on graphs. Weihua Hu, Matthias Fey, Hongyu Ren, Maho Nakata, Yuxiao Dong, Jure Leskovec, arXiv:2103.09430arXiv preprintWeihua Hu, Matthias Fey, Hongyu Ren, Maho Nakata, Yuxiao Dong, and Jure Leskovec. Ogb- lsc: A large-scale challenge for machine learning on graphs. arXiv preprint arXiv:2103.09430, 2021.\n\nBatch normalization: Accelerating deep network training by reducing internal covariate shift. Sergey Ioffe, Christian Szegedy, arXiv:1502.03167arXiv preprintSergey Ioffe and Christian Szegedy. Batch normalization: Accelerating deep network training by reducing internal covariate shift. arXiv preprint arXiv:1502.03167, 2015.\n\nZinc: a free tool to discover chemistry for biology. J John, Teague Irwin, Sterling, M Michael, Erin S Mysinger, Ryan G Bolstad, Coleman, Journal of chemical information and modeling. 527John J Irwin, Teague Sterling, Michael M Mysinger, Erin S Bolstad, and Ryan G Coleman. Zinc: a free tool to discover chemistry for biology. Journal of chemical information and modeling, 52(7):1757-1768, 2012.\n\nRedundancyfree computation graphs for graph neural networks. Zhihao Jia, Sina Lin, Rex Ying, Jiaxuan You, Jure Leskovec, Alex Aiken, arXiv:1906.03707arXiv preprintZhihao Jia, Sina Lin, Rex Ying, Jiaxuan You, Jure Leskovec, and Alex Aiken. Redundancy- free computation graphs for graph neural networks. arXiv preprint arXiv:1906.03707, 2019.\n\nJunction tree variational autoencoder for molecular graph generation. Wengong Jin, Regina Barzilay, Tommi Jaakkola, arXiv:1802.04364arXiv preprintWengong Jin, Regina Barzilay, and Tommi Jaakkola. Junction tree variational autoencoder for molecular graph generation. arXiv preprint arXiv:1802.04364, 2018.\n\nTransformers are graph neural networks. The Gradient. Chaitanya Joshi, Chaitanya Joshi. Transformers are graph neural networks. The Gradient, 2020.\n\nAn efficient graph convolutional network technique for the travelling salesman problem. K Chaitanya, Thomas Joshi, Xavier Laurent, Bresson, arXiv:1906.01227arXiv preprintChaitanya K Joshi, Thomas Laurent, and Xavier Bresson. An efficient graph convolutional network technique for the travelling salesman problem. arXiv preprint arXiv:1906.01227, 2019.\n\nLearning the travelling salesperson problem requires rethinking generalization. K Chaitanya, Quentin Joshi, Louis-Martin Cappart, Thomas Rousseau, Laurent, Constraints. Chaitanya K Joshi, Quentin Cappart, Louis-Martin Rousseau, and Thomas Laurent. Learning the travelling salesperson problem requires rethinking generalization. Constraints, pages 1-29, 2022.\n\nLearning combinatorial optimization algorithms over graphs. Elias Khalil, Hanjun Dai, Yuyu Zhang, Bistra Dilkina, Le Song, Advances in Neural Information Processing Systems. Elias Khalil, Hanjun Dai, Yuyu Zhang, Bistra Dilkina, and Le Song. Learning combinatorial optimization algorithms over graphs. In Advances in Neural Information Processing Systems, pages 6348-6358, 2017.\n\nAdam: A method for stochastic optimization. P Diederik, Jimmy Kingma, Ba, arXiv:1412.6980arXiv preprintDiederik P Kingma and Jimmy Ba. Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980, 2014.\n\nSemi-supervised classification with graph convolutional networks. N Thomas, Max Kipf, Welling, International Conference on Learning Representations (ICLR. Thomas N. Kipf and Max Welling. Semi-supervised classification with graph convolutional networks. In International Conference on Learning Representations (ICLR), 2017.\n\nUnderstanding attention and generalization in graph neural networks. Boris Knyazev, W Graham, Mohamed R Taylor, Amer, arXiv:1905.02850arXiv preprintBoris Knyazev, Graham W Taylor, and Mohamed R Amer. Understanding attention and generalization in graph neural networks. arXiv preprint arXiv:1905.02850, 2019.\n\nAttention, learn to solve routing problems. Wouter Kool, Max Herke Van Hoof, Welling, International Conference on Learning Representations. Wouter Kool, Herke van Hoof, and Max Welling. Attention, learn to solve routing problems! In International Conference on Learning Representations, 2019.\n\nRethinking graph transformers with spectral attention. Devin Kreuzer, Dominique Beaini, Will Hamilton, Vincent L\u00e9tourneau, Prudencio Tossou, Advances in Neural Information Processing Systems. 342021Devin Kreuzer, Dominique Beaini, Will Hamilton, Vincent L\u00e9tourneau, and Prudencio Tossou. Rethinking graph transformers with spectral attention. Advances in Neural Information Processing Systems, 34, 2021.\n\nImagenet classification with deep convolutional neural networks. Alex Krizhevsky, Ilya Sutskever, Geoffrey E Hinton, Advances in Neural Information Processing Systems 25: 26th Annual Conference on Neural Information Processing Systems. Alex Krizhevsky, Ilya Sutskever, and Geoffrey E. Hinton. Imagenet classification with deep convolutional neural networks. In Advances in Neural Information Processing Systems 25: 26th Annual Conference on Neural Information Processing Systems 2012., pages 1106-1114, 2012.\n\nConvolutional networks for images, speech, and time series. Yann Lecun, Yoshua Bengio, Yann LeCun, Yoshua Bengio, et al. Convolutional networks for images, speech, and time series. 1995.\n\nGradient-based learning applied to document recognition. Yann Lecun, L\u00e9on Bottou, Yoshua Bengio, Patrick Haffner, Proceedings of the IEEE. 8611Yann LeCun, L\u00e9on Bottou, Yoshua Bengio, and Patrick Haffner. Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11):2278-2324, 1998.\n\nDistance encoding-design provably more powerful gnns for structural representation learning. Pan Li, Yanbang Wang, Hongwei Wang, Jure Leskovec, arXiv:2009.00142arXiv preprintPan Li, Yanbang Wang, Hongwei Wang, and Jure Leskovec. Distance encoding-design provably more powerful gnns for structural representation learning. arXiv preprint arXiv:2009.00142, 2020.\n\nSign and basis invariant networks for spectral graph representation learning. Derek Lim, Joshua David Robinson, Lingxiao Zhao, Tess Smidt, Suvrit Sra, Haggai Maron, Stefanie Jegelka, ICLR 2022 Workshop on Geometrical and Topological Representation Learning. Derek Lim, Joshua David Robinson, Lingxiao Zhao, Tess Smidt, Suvrit Sra, Haggai Maron, and Stefanie Jegelka. Sign and basis invariant networks for spectral graph representation learning. In ICLR 2022 Workshop on Geometrical and Topological Representation Learning, 2022.\n\nWhat graph neural networks cannot learn: depth vs width. Andreas Loukas, International Conference on Learning Representations. Andreas Loukas. What graph neural networks cannot learn: depth vs width. In International Conference on Learning Representations, 2020. URL https://openreview.net/forum? id=B1l2bp4YwS.\n\nEnxhell Luzhnica, Ben Day, Pietro Li\u00f2, arXiv:1905.04682On graph classification networks, datasets and baselines. arXiv preprintEnxhell Luzhnica, Ben Day, and Pietro Li\u00f2. On graph classification networks, datasets and baselines. arXiv preprint arXiv:1905.04682, 2019.\n\nTechnical perspective: What led computer vision to deep learning?. Jitendra Malik, 0001-0782Commun. ACM. 606Jitendra Malik. Technical perspective: What led computer vision to deep learning? Commun. ACM, 60(6):82-83, May 2017. ISSN 0001-0782.\n\nEncoding sentences with graph convolutional networks for semantic role labeling. Diego Marcheggiani, Ivan Titov, arXiv:1703.04826arXiv preprintDiego Marcheggiani and Ivan Titov. Encoding sentences with graph convolutional networks for semantic role labeling. arXiv preprint arXiv:1703.04826, 2017.\n\nProvably powerful graph networks. Heli Haggai Maron, Hadar Ben-Hamu, Yaron Serviansky, Lipman, Advances in Neural Information Processing Systems. Haggai Maron, Heli Ben-Hamu, Hadar Serviansky, and Yaron Lipman. Provably powerful graph networks. In Advances in Neural Information Processing Systems, pages 2153-2164, 2019a.\n\nHeli Haggai Maron, Ben-Hamu, Nadav Shamir, and Yaron Lipman. Invariant and equivariant graph networks. International Conference on Learning Representations. Haggai Maron, Heli Ben-Hamu, Nadav Shamir, and Yaron Lipman. Invariant and equivariant graph networks. International Conference on Learning Representations, 2019b.\n\nOn the universality of invariant networks. Haggai Maron, Ethan Fetaya, Nimrod Segol, Yaron Lipman, International Conference on Machine Learning. Haggai Maron, Ethan Fetaya, Nimrod Segol, and Yaron Lipman. On the universality of invariant networks. International Conference on Machine Learning, 2019c.\n\nWiki-cs: A wikipedia-based benchmark for graph neural networks. P\u00e9ter Mernyei, C\u0103t\u0103lina Cangea, arXiv:2007.02901arXiv preprintP\u00e9ter Mernyei and C\u0103t\u0103lina Cangea. Wiki-cs: A wikipedia-based benchmark for graph neural networks. arXiv preprint arXiv:2007.02901, 2020.\n\nRethinking pooling in graph neural networks. Diego Mesquita, Amauri Souza, Samuel Kaski, Advances in Neural Information Processing Systems. 33Diego Mesquita, Amauri Souza, and Samuel Kaski. Rethinking pooling in graph neural networks. Advances in Neural Information Processing Systems, 33:2220-2231, 2020.\n\nGraphit: Encoding graph structure in transformers. Gr\u00e9goire Mialon, Dexiong Chen, Margot Selosse, Julien Mairal, arXiv:2106.05667arXiv preprintGr\u00e9goire Mialon, Dexiong Chen, Margot Selosse, and Julien Mairal. Graphit: Encoding graph structure in transformers. arXiv preprint arXiv:2106.05667, 2021.\n\nGeometric deep learning on graphs and manifolds using mixture model cnns. Federico Monti, Davide Boscaini, Jonathan Masci, Emanuele Rodola, Jan Svoboda, Michael M Bronstein, 10.1109/cvpr.2017.576IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Federico Monti, Davide Boscaini, Jonathan Masci, Emanuele Rodola, Jan Svoboda, and Michael M. Bronstein. Geometric deep learning on graphs and manifolds using mixture model cnns. 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Jul 2017a. doi: 10.1109/cvpr.2017.576.\n\nGeometric matrix completion with recurrent multi-graph neural networks. Federico Monti, Michael Bronstein, Xavier Bresson, Advances in Neural Information Processing Systems. Federico Monti, Michael Bronstein, and Xavier Bresson. Geometric matrix completion with recurrent multi-graph neural networks. In Advances in Neural Information Processing Systems, pages 3697-3707, 2017b.\n\nFake news detection on social media using geometric deep learning. Federico Monti, Fabrizio Frasca, Davide Eynard, Damon Mannion, Michael M Bronstein, arXiv:1902.06673arXiv preprintFederico Monti, Fabrizio Frasca, Davide Eynard, Damon Mannion, and Michael M Bronstein. Fake news detection on social media using geometric deep learning. arXiv preprint arXiv:1902.06673, 2019.\n\nWeisfeiler and leman go neural: Higher-order graph neural networks. Christopher Morris, Martin Ritzert, Matthias Fey, L William, Jan Eric Hamilton, Gaurav Lenssen, Martin Rattan, Grohe, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence33Christopher Morris, Martin Ritzert, Matthias Fey, William L Hamilton, Jan Eric Lenssen, Gaurav Rattan, and Martin Grohe. Weisfeiler and leman go neural: Higher-order graph neu- ral networks. In Proceedings of the AAAI Conference on Artificial Intelligence, volume 33, pages 4602-4609, 2019.\n\nRelational pooling for graph representations. Ryan Murphy, Balasubramaniam Srinivasan, Vinayak Rao, Bruno Ribeiro, International Conference on Machine Learning. Ryan Murphy, Balasubramaniam Srinivasan, Vinayak Rao, and Bruno Ribeiro. Relational pooling for graph representations. In International Conference on Machine Learning, pages 4663-4673, 2019.\n\n. Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas K\u00f6pf, Edward Yang, Zach Devito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, Soumith Chintala, Pytorch: An imperative style, high-performance deep learning libraryAdam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas K\u00f6pf, Edward Yang, Zach DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang, Junjie Bai, and Soumith Chintala. Pytorch: An imperative style, high-performance deep learning library, 2019.\n\nGlove: Global vectors for word representation. Jeffrey Pennington, Richard Socher, Christopher D Manning, Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP). the 2014 conference on empirical methods in natural language processing (EMNLP)Jeffrey Pennington, Richard Socher, and Christopher D Manning. Glove: Global vectors for word representation. In Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP), pages 1532-1543, 2014.\n\nScale-space and edge detection using anisotropic diffusion. Pietro Perona, Jitendra Malik, IEEE Transactions on pattern analysis and machine intelligence. 127Pietro Perona and Jitendra Malik. Scale-space and edge detection using anisotropic diffusion. IEEE Transactions on pattern analysis and machine intelligence, 12(7):629-639, 1990.\n\nEmanuele Rossi, Fabrizio Frasca, Ben Chamberlain, Davide Eynard, Michael Bronstein, Federico Monti, arXiv:2004.11198Sign: Scalable inception graph neural networks. arXiv preprintEmanuele Rossi, Fabrizio Frasca, Ben Chamberlain, Davide Eynard, Michael Bronstein, and Federico Monti. Sign: Scalable inception graph neural networks. arXiv preprint arXiv:2004.11198, 2020.\n\nGraph networks as learnable physics engines for inference and control. Alvaro Sanchez-Gonzalez, Nicolas Heess, Jost Tobias Springenberg, Josh Merel, Martin Riedmiller, Raia Hadsell, Peter Battaglia, International Conference on Machine Learning. Alvaro Sanchez-Gonzalez, Nicolas Heess, Jost Tobias Springenberg, Josh Merel, Martin Riedmiller, Raia Hadsell, and Peter Battaglia. Graph networks as learnable physics engines for inference and control. In International Conference on Machine Learning, pages 4470-4479, 2018.\n\nAlvaro Sanchez-Gonzalez, Jonathan Godwin, Tobias Pfaff, Rex Ying, Jure Leskovec, Peter W Battaglia, arXiv:2002.09405Learning to simulate complex physics with graph networks. arXiv preprintAlvaro Sanchez-Gonzalez, Jonathan Godwin, Tobias Pfaff, Rex Ying, Jure Leskovec, and Peter W Battaglia. Learning to simulate complex physics with graph networks. arXiv preprint arXiv:2002.09405, 2020.\n\nThe Graph Neural Network Model. F Scarselli, M Gori, A Tsoi, M Hagenbuchner, G Monfardini, IEEE Transactions on Neural Networks. 201F. Scarselli, M. Gori, A. Tsoi, M. Hagenbuchner, and G. Monfardini. The Graph Neural Network Model. IEEE Transactions on Neural Networks, 20(1):61-80, 2009.\n\nModeling relational data with graph convolutional networks. Michael Schlichtkrull, N Thomas, Peter Kipf, Rianne Bloem, Van Den, Ivan Berg, Max Titov, Welling, European Semantic Web Conference. SpringerMichael Schlichtkrull, Thomas N Kipf, Peter Bloem, Rianne Van Den Berg, Ivan Titov, and Max Welling. Modeling relational data with graph convolutional networks. In European Semantic Web Conference, pages 593-607. Springer, 2018.\n\nAqsoldb, a curated reference set of aqueous solubility and 2d descriptors for a diverse set of compounds. Abhishek Murat Cihan Sorkun, S\u00fcleyman Khetan, Er, Scientific data. 61Murat Cihan Sorkun, Abhishek Khetan, and S\u00fcleyman Er. Aqsoldb, a curated reference set of aqueous solubility and 2d descriptors for a diverse set of compounds. Scientific data, 6 (1):1-8, 2019.\n\nOn the equivalence between node embeddings and structural graph representations. Balasubramaniam Srinivasan, Bruno Ribeiro, International Conference on Learning Representations. Balasubramaniam Srinivasan and Bruno Ribeiro. On the equivalence between node em- beddings and structural graph representations. International Conference on Learning Representations, 2020.\n\nLearning multiagent communication with backpropagation. Sainbayar Sukhbaatar, Rob Fergus, Advances in Neural Information Processing Systems. D. D. Lee, M. Sugiyama, U. V. Luxburg, I. Guyon, and R. Garnett29Sainbayar Sukhbaatar, arthur szlam, and Rob Fergus. Learning multiagent communication with backpropagation. In D. D. Lee, M. Sugiyama, U. V. Luxburg, I. Guyon, and R. Garnett, editors, Advances in Neural Information Processing Systems 29, pages 2244-2252. 2016.\n\nDegree-quant: Quantization-aware training for graph neural networks. A Shyam, Javier Tailor, Nicholas D Fernandez-Marques, Lane, arXiv:2008.05000arXiv preprintShyam A Tailor, Javier Fernandez-Marques, and Nicholas D Lane. Degree-quant: Quantization-aware training for graph neural networks. arXiv preprint arXiv:2008.05000, 2020.\n\nDo we need anisotropic graph neural networks?. A Shyam, Felix Tailor, Pietro Opolka, Nicholas Donald Lio, Lane, International Conference on Learning Representations. Shyam A Tailor, Felix Opolka, Pietro Lio, and Nicholas Donald Lane. Do we need anisotropic graph neural networks? In International Conference on Learning Representations, 2021.\n\nRan-gnns: breaking the capacity limits of graph neural networks. Diego Valsesia, Giulia Fracastoro, Enrico Magli, IEEE Transactions on Neural Networks and Learning Systems. Diego Valsesia, Giulia Fracastoro, and Enrico Magli. Ran-gnns: breaking the capacity limits of graph neural networks. IEEE Transactions on Neural Networks and Learning Systems, 2021.\n\nAttention is all you need. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, Illia Polosukhin, Advances in neural information processing systems. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Advances in neural information processing systems, pages 5998-6008, 2017.\n\nPetar Veli\u010dkovi\u0107, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Li\u00f2, Yoshua Bengio, Graph Attention Networks. International Conference on Learning Representations. Petar Veli\u010dkovi\u0107, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Li\u00f2, and Yoshua Bengio. Graph Attention Networks. International Conference on Learning Repre- sentations, 2018.\n\nBuilding powerful and equivariant graph neural networks with structural message-passing. Clement Vignac, Andreas Loukas, Pascal Frossard, Clement Vignac, Andreas Loukas, and Pascal Frossard. Building powerful and equivariant graph neural networks with structural message-passing, 2020.\n\nPointer networks. Oriol Vinyals, Meire Fortunato, Navdeep Jaitly, Advances in Neural Information Processing Systems. Oriol Vinyals, Meire Fortunato, and Navdeep Jaitly. Pointer networks. In Advances in Neural Information Processing Systems, pages 2692-2700, 2015.\n\nA tutorial on spectral clustering. Ulrike Von, Luxburg , Statistics and computing. 174Ulrike Von Luxburg. A tutorial on spectral clustering. Statistics and computing, 17(4): 395-416, 2007.\n\nEquivariant and stable positional encoding for more powerful graph neural networks. Haorui Wang, Haoteng Yin, Muhan Zhang, Pan Li, International Conference on Learning Representations. Haorui Wang, Haoteng Yin, Muhan Zhang, and Pan Li. Equivariant and stable positional encoding for more powerful graph neural networks. In International Conference on Learning Representations, 2022.\n\nMicrosoft academic graph: When experts are not enough. Kuansan Wang, Zhihong Shen, Chiyuan Huang, Chieh-Han Wu, Yuxiao Dong, Anshul Kanakia, Quantitative Science Studies. 11Kuansan Wang, Zhihong Shen, Chiyuan Huang, Chieh-Han Wu, Yuxiao Dong, and Anshul Kanakia. Microsoft academic graph: When experts are not enough. Quantitative Science Studies, 1(1):396-413, 2020.\n\nMinjie Wang, Lingfan Yu, Da Zheng, Quan Gan, Yu Gai, Zihao Ye, Mufei Li, Jinjing Zhou, Qi Huang, Chao Ma, Ziyue Huang, Qipeng Guo, Hao Zhang, Haibin Lin, Junbo Zhao, Jinyang Li, Alexander J Smola, Zheng Zhang, Deep graph library: Towards efficient and scalable deep learning on graphs. ICLR Workshop on Representation Learning on Graphs and Manifolds. Minjie Wang, Lingfan Yu, Da Zheng, Quan Gan, Yu Gai, Zihao Ye, Mufei Li, Jinjing Zhou, Qi Huang, Chao Ma, Ziyue Huang, Qipeng Guo, Hao Zhang, Haibin Lin, Junbo Zhao, Jinyang Li, Alexander J Smola, and Zheng Zhang. Deep graph library: Towards efficient and scalable deep learning on graphs. ICLR Workshop on Representation Learning on Graphs and Manifolds, 2019.\n\nEssential guidelines for computational method benchmarking. M Lukas, Wouter Weber, Robrecht Saelens, Charlotte Cannoodt, Alexander Soneson, Hapfelmeier, P Paul, Anne-Laure Gardner, Yvan Boulesteix, Mark D Saeys, Robinson, Genome biology. 201125Lukas M Weber, Wouter Saelens, Robrecht Cannoodt, Charlotte Soneson, Alexander Hapfelmeier, Paul P Gardner, Anne-Laure Boulesteix, Yvan Saeys, and Mark D Robinson. Essential guidelines for computational method benchmarking. Genome biology, 20(1):125, 2019.\n\nEvaluating graph neural networks under graph sampling scenarios. Qiang Wei, Guangmin Hu, PeerJ Computer Science. 8901Qiang Wei and Guangmin Hu. Evaluating graph neural networks under graph sampling scenarios. PeerJ Computer Science, 8:e901, 2022.\n\nA reduction of a graph to a canonical form and an algebra arising during this reduction. Nauchno-Technicheskaya Informatsia. Boris Weisfeiler, Andrei A Lehman, 2Boris Weisfeiler and Andrei A Lehman. A reduction of a graph to a canonical form and an algebra arising during this reduction. Nauchno-Technicheskaya Informatsia, 2(9):12-16, 1968.\n\nKeyulu Xu, Chengtao Li, Yonglong Tian, Tomohiro Sonobe, Ken-Ichi Kawarabayashi, Stefanie Jegelka, arXiv:1806.03536Representation learning on graphs with jumping knowledge networks. arXiv preprintKeyulu Xu, Chengtao Li, Yonglong Tian, Tomohiro Sonobe, Ken-ichi Kawarabayashi, and Stefanie Jegelka. Representation learning on graphs with jumping knowledge networks. arXiv preprint arXiv:1806.03536, 2018.\n\nHow powerful are graph neural networks?. Keyulu Xu, Weihua Hu, Jure Leskovec, Stefanie Jegelka, International Conference on Learning Representations. Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. How powerful are graph neural networks? In International Conference on Learning Representations, 2019.\n\nDo transformers really perform badly for graph representation?. Chengxuan Ying, Tianle Cai, Shengjie Luo, Shuxin Zheng, Guolin Ke, Di He, Yanming Shen, Tie-Yan Liu, Advances in Neural Information Processing Systems. 342021Chengxuan Ying, Tianle Cai, Shengjie Luo, Shuxin Zheng, Guolin Ke, Di He, Yanming Shen, and Tie-Yan Liu. Do transformers really perform badly for graph representation? Advances in Neural Information Processing Systems, 34, 2021.\n\nGraph convolutional neural networks for web-scale recommender systems. Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, L William, Jure Hamilton, Leskovec, Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining. the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data MiningRex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L Hamilton, and Jure Leskovec. Graph convolutional neural networks for web-scale recommender systems. In Proceedings of the 24th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, pages 974-983, 2018.\n\nPosition-aware graph neural networks. Jiaxuan You, Rex Ying, Jure Leskovec, International Conference on Machine Learning. Jiaxuan You, Rex Ying, and Jure Leskovec. Position-aware graph neural networks. Interna- tional Conference on Machine Learning, 2019.\n\nSsfg: Stochastically scaling features and gradients for regularizing graph convolutional networks. Haimin Zhang, Min Xu, Guoqiang Zhang, Kenta Niwa, arXiv:2102.10338arXiv preprintHaimin Zhang, Min Xu, Guoqiang Zhang, and Kenta Niwa. Ssfg: Stochastically scaling features and gradients for regularizing graph convolutional networks. arXiv preprint arXiv:2102.10338, 2021.\n\nA pipeline for fair comparison of graph neural networks in node classification tasks. Wentao Zhao, Dalin Zhou, Xinguo Qiu, Wei Jiang, Wentao Zhao, Dalin Zhou, Xinguo Qiu, and Wei Jiang. A pipeline for fair comparison of graph neural networks in node classification tasks, 2020.\n\nTowards deeper graph neural networks with differentiable group normalization. Kaixiong Zhou, Xiao Huang, Yuening Li, Daochen Zha, Rui Chen, Xia Hu, Advances in Neural Information Processing Systems. 33Kaixiong Zhou, Xiao Huang, Yuening Li, Daochen Zha, Rui Chen, and Xia Hu. Towards deeper graph neural networks with differentiable group normalization. Advances in Neural Information Processing Systems, 33:4917-4928, 2020.\n", "annotations": {"author": "[{\"end\":104,\"start\":38},{\"end\":180,\"start\":105},{\"end\":238,\"start\":181},{\"end\":304,\"start\":239},{\"end\":380,\"start\":305},{\"end\":451,\"start\":381}]", "publisher": null, "author_last_name": "[{\"end\":59,\"start\":52},{\"end\":122,\"start\":117},{\"end\":193,\"start\":190},{\"end\":253,\"start\":246},{\"end\":318,\"start\":312},{\"end\":395,\"start\":388}]", "author_first_name": "[{\"end\":43,\"start\":38},{\"end\":51,\"start\":44},{\"end\":114,\"start\":105},{\"end\":116,\"start\":115},{\"end\":184,\"start\":181},{\"end\":189,\"start\":185},{\"end\":245,\"start\":239},{\"end\":311,\"start\":305},{\"end\":387,\"start\":381}]", "author_affiliation": "[{\"end\":103,\"start\":61},{\"end\":179,\"start\":153},{\"end\":237,\"start\":195},{\"end\":303,\"start\":272},{\"end\":379,\"start\":346},{\"end\":450,\"start\":417}]", "title": "[{\"end\":35,\"start\":1},{\"end\":486,\"start\":452}]", "venue": null, "abstract": "[{\"end\":2183,\"start\":551}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b26\"},\"end\":2369,\"start\":2346},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":2389,\"start\":2369},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":2421,\"start\":2399},{\"attributes\":{\"ref_id\":\"b76\"},\"end\":2451,\"start\":2421},{\"attributes\":{\"ref_id\":\"b68\"},\"end\":2489,\"start\":2469},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":2534,\"start\":2506},{\"attributes\":{\"ref_id\":\"b78\"},\"end\":2581,\"start\":2553},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":2600,\"start\":2581},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":2638,\"start\":2617},{\"attributes\":{\"ref_id\":\"b99\"},\"end\":2656,\"start\":2638},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":2696,\"start\":2675},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":3160,\"start\":3135},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":3179,\"start\":3160},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":3199,\"start\":3179},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":4001,\"start\":3981},{\"attributes\":{\"ref_id\":\"b83\"},\"end\":4021,\"start\":4001},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":4040,\"start\":4021},{\"attributes\":{\"ref_id\":\"b84\"},\"end\":4105,\"start\":4082},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":4128,\"start\":4105},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":4152,\"start\":4128},{\"attributes\":{\"ref_id\":\"b64\"},\"end\":4202,\"start\":4179},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":4276,\"start\":4257},{\"attributes\":{\"ref_id\":\"b101\"},\"end\":4295,\"start\":4276},{\"attributes\":{\"ref_id\":\"b94\"},\"end\":4355,\"start\":4337},{\"attributes\":{\"ref_id\":\"b82\"},\"end\":4375,\"start\":4355},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":5605,\"start\":5584},{\"attributes\":{\"ref_id\":\"b74\"},\"end\":5624,\"start\":5605},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":5640,\"start\":5624},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":6888,\"start\":6867},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":6901,\"start\":6888},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":6974,\"start\":6949},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":7921,\"start\":7900},{\"attributes\":{\"ref_id\":\"b90\"},\"end\":7939,\"start\":7921},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":7956,\"start\":7939},{\"end\":7977,\"start\":7956},{\"end\":7995,\"start\":7977},{\"attributes\":{\"ref_id\":\"b65\"},\"end\":8015,\"start\":7995},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":8927,\"start\":8904},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":8947,\"start\":8927},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":8979,\"start\":8957},{\"attributes\":{\"ref_id\":\"b76\"},\"end\":9009,\"start\":8979},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":9051,\"start\":9027},{\"attributes\":{\"ref_id\":\"b68\"},\"end\":9070,\"start\":9051},{\"attributes\":{\"ref_id\":\"b78\"},\"end\":9117,\"start\":9089},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":9136,\"start\":9117},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":9174,\"start\":9153},{\"attributes\":{\"ref_id\":\"b99\"},\"end\":9192,\"start\":9174},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":9232,\"start\":9211},{\"attributes\":{\"ref_id\":\"b77\"},\"end\":9332,\"start\":9308},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":9351,\"start\":9332},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":9375,\"start\":9351},{\"attributes\":{\"ref_id\":\"b81\"},\"end\":9399,\"start\":9375},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":9422,\"start\":9399},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":9444,\"start\":9422},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":9526,\"start\":9507},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":9547,\"start\":9526},{\"attributes\":{\"ref_id\":\"b73\"},\"end\":9667,\"start\":9643},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":9733,\"start\":9709},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":9762,\"start\":9733},{\"attributes\":{\"ref_id\":\"b66\"},\"end\":9782,\"start\":9762},{\"attributes\":{\"ref_id\":\"b86\"},\"end\":9806,\"start\":9782},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":9832,\"start\":9806},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":9958,\"start\":9938},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":9978,\"start\":9958},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":9997,\"start\":9978},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":10017,\"start\":9997},{\"attributes\":{\"ref_id\":\"b80\"},\"end\":10046,\"start\":10017},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":10589,\"start\":10564},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":10608,\"start\":10589},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":10692,\"start\":10671},{\"attributes\":{\"ref_id\":\"b93\"},\"end\":11173,\"start\":11153},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":11239,\"start\":11220},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":11346,\"start\":11321},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":11358,\"start\":11346},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":12126,\"start\":12106},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":12534,\"start\":12511},{\"attributes\":{\"ref_id\":\"b66\"},\"end\":12563,\"start\":12542},{\"attributes\":{\"ref_id\":\"b86\"},\"end\":12594,\"start\":12569},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":12636,\"start\":12609},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":13036,\"start\":13016},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":13070,\"start\":13050},{\"attributes\":{\"ref_id\":\"b92\"},\"end\":13916,\"start\":13897},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":13993,\"start\":13973},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":16560,\"start\":16536},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":17379,\"start\":17356},{\"attributes\":{\"ref_id\":\"b86\"},\"end\":18303,\"start\":18278},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":18359,\"start\":18336},{\"attributes\":{\"ref_id\":\"b85\"},\"end\":18558,\"start\":18536},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":18570,\"start\":18558},{\"attributes\":{\"ref_id\":\"b66\"},\"end\":19074,\"start\":19053},{\"end\":19224,\"start\":19217},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":19632,\"start\":19605},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":19739,\"start\":19709},{\"attributes\":{\"ref_id\":\"b95\"},\"end\":20439,\"start\":20410},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":20885,\"start\":20860},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":20928,\"start\":20911},{\"attributes\":{\"ref_id\":\"b95\"},\"end\":23291,\"start\":23262},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":23504,\"start\":23483},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":23538,\"start\":23518},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":24062,\"start\":24041},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":24785,\"start\":24765},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":24871,\"start\":24851},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":25357,\"start\":25337},{\"end\":25835,\"start\":25813},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":25856,\"start\":25837},{\"attributes\":{\"ref_id\":\"b96\"},\"end\":25942,\"start\":25927},{\"end\":26309,\"start\":26287},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":28040,\"start\":28031},{\"attributes\":{\"ref_id\":\"b96\"},\"end\":29066,\"start\":29049},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":29977,\"start\":29957},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":30446,\"start\":30428},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":34607,\"start\":34581},{\"attributes\":{\"ref_id\":\"b72\"},\"end\":34944,\"start\":34919},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":35258,\"start\":35233},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":35596,\"start\":35571},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":37432,\"start\":37410},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":37486,\"start\":37464},{\"attributes\":{\"ref_id\":\"b77\"},\"end\":39295,\"start\":39272},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":39428,\"start\":39416},{\"attributes\":{\"ref_id\":\"b77\"},\"end\":39975,\"start\":39952},{\"end\":40158,\"start\":40155},{\"end\":40161,\"start\":40158},{\"attributes\":{\"ref_id\":\"b88\"},\"end\":42374,\"start\":42352},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":42448,\"start\":42427},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":42466,\"start\":42448},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":42485,\"start\":42466},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":43288,\"start\":43269},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":44023,\"start\":43999},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":44157,\"start\":44136},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":45919,\"start\":45899},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":46495,\"start\":46476},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":46751,\"start\":46731},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":46772,\"start\":46753},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":47283,\"start\":47270},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":47516,\"start\":47503},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":47806,\"start\":47793},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":49236,\"start\":49217},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":50103,\"start\":50083},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":50173,\"start\":50154},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":51850,\"start\":51829},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":51872,\"start\":51850},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":52046,\"start\":52025},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":52065,\"start\":52046},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":52085,\"start\":52065},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":54249,\"start\":54231},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":54424,\"start\":54407},{\"end\":56000,\"start\":55978},{\"attributes\":{\"ref_id\":\"b90\"},\"end\":56018,\"start\":56000},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":56035,\"start\":56018},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":56947,\"start\":56927},{\"attributes\":{\"ref_id\":\"b80\"},\"end\":56978,\"start\":56949},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":57258,\"start\":57238},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":57353,\"start\":57339},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":57464,\"start\":57444},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":58162,\"start\":58149},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":59060,\"start\":59035},{\"attributes\":{\"ref_id\":\"b85\"},\"end\":59724,\"start\":59702},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":59996,\"start\":59974},{\"attributes\":{\"ref_id\":\"b89\"},\"end\":61868,\"start\":61849},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":63328,\"start\":63307},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":64299,\"start\":64272},{\"end\":65412,\"start\":65397},{\"attributes\":{\"ref_id\":\"b86\"},\"end\":65802,\"start\":65777},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":66080,\"start\":66053},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":67402,\"start\":67378},{\"attributes\":{\"ref_id\":\"b75\"},\"end\":67432,\"start\":67402},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":67451,\"start\":67432},{\"attributes\":{\"ref_id\":\"b102\"},\"end\":77578,\"start\":77559},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":79357,\"start\":79336},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":81083,\"start\":81057},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":81532,\"start\":81511},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":81552,\"start\":81532}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":80673,\"start\":80511},{\"attributes\":{\"id\":\"fig_1\"},\"end\":80986,\"start\":80674},{\"attributes\":{\"id\":\"fig_2\"},\"end\":81084,\"start\":80987},{\"attributes\":{\"id\":\"fig_3\"},\"end\":81127,\"start\":81085},{\"attributes\":{\"id\":\"fig_4\"},\"end\":81159,\"start\":81128},{\"attributes\":{\"id\":\"fig_5\"},\"end\":81438,\"start\":81160},{\"attributes\":{\"id\":\"fig_6\"},\"end\":81906,\"start\":81439},{\"attributes\":{\"id\":\"fig_8\"},\"end\":82036,\"start\":81907},{\"attributes\":{\"id\":\"fig_9\"},\"end\":82166,\"start\":82037},{\"attributes\":{\"id\":\"fig_10\"},\"end\":82364,\"start\":82167},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":82936,\"start\":82365},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":83090,\"start\":82937},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":84779,\"start\":83091},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":85125,\"start\":84780},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":86888,\"start\":85126},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":88207,\"start\":86889},{\"attributes\":{\"id\":\"tab_9\",\"type\":\"table\"},\"end\":88561,\"start\":88208},{\"attributes\":{\"id\":\"tab_10\",\"type\":\"table\"},\"end\":89204,\"start\":88562},{\"attributes\":{\"id\":\"tab_11\",\"type\":\"table\"},\"end\":89495,\"start\":89205},{\"attributes\":{\"id\":\"tab_13\",\"type\":\"table\"},\"end\":89698,\"start\":89496},{\"attributes\":{\"id\":\"tab_14\",\"type\":\"table\"},\"end\":92566,\"start\":89699},{\"attributes\":{\"id\":\"tab_15\",\"type\":\"table\"},\"end\":92894,\"start\":92567},{\"attributes\":{\"id\":\"tab_16\",\"type\":\"table\"},\"end\":94035,\"start\":92895},{\"attributes\":{\"id\":\"tab_17\",\"type\":\"table\"},\"end\":94277,\"start\":94036},{\"attributes\":{\"id\":\"tab_19\",\"type\":\"table\"},\"end\":94565,\"start\":94278},{\"attributes\":{\"id\":\"tab_21\",\"type\":\"table\"},\"end\":94930,\"start\":94566},{\"attributes\":{\"id\":\"tab_23\",\"type\":\"table\"},\"end\":95229,\"start\":94931},{\"attributes\":{\"id\":\"tab_24\",\"type\":\"table\"},\"end\":97550,\"start\":95230},{\"attributes\":{\"id\":\"tab_25\",\"type\":\"table\"},\"end\":97796,\"start\":97551},{\"attributes\":{\"id\":\"tab_26\",\"type\":\"table\"},\"end\":98992,\"start\":97797},{\"attributes\":{\"id\":\"tab_27\",\"type\":\"table\"},\"end\":99131,\"start\":98993},{\"attributes\":{\"id\":\"tab_29\",\"type\":\"table\"},\"end\":99301,\"start\":99132},{\"attributes\":{\"id\":\"tab_30\",\"type\":\"table\"},\"end\":99560,\"start\":99302}]", "paragraph": "[{\"end\":2849,\"start\":2199},{\"end\":5023,\"start\":2851},{\"end\":5641,\"start\":5103},{\"end\":6486,\"start\":5700},{\"end\":8131,\"start\":6488},{\"end\":8715,\"start\":8146},{\"end\":10693,\"start\":8735},{\"end\":11778,\"start\":10695},{\"end\":12383,\"start\":11815},{\"end\":13299,\"start\":12385},{\"end\":13521,\"start\":13328},{\"end\":14077,\"start\":13556},{\"end\":14431,\"start\":14099},{\"end\":14495,\"start\":14485},{\"end\":14507,\"start\":14497},{\"end\":14858,\"start\":14554},{\"end\":15024,\"start\":14860},{\"end\":15890,\"start\":15045},{\"end\":15994,\"start\":15892},{\"end\":16513,\"start\":16031},{\"end\":16733,\"start\":16515},{\"end\":17300,\"start\":16801},{\"end\":17526,\"start\":17346},{\"end\":17979,\"start\":17574},{\"end\":18246,\"start\":18111},{\"end\":18609,\"start\":18248},{\"end\":18790,\"start\":18665},{\"end\":19045,\"start\":18899},{\"end\":19288,\"start\":19047},{\"end\":19572,\"start\":19455},{\"end\":19866,\"start\":19574},{\"end\":20007,\"start\":19921},{\"end\":20518,\"start\":20111},{\"end\":20729,\"start\":20595},{\"end\":20990,\"start\":20772},{\"end\":21158,\"start\":21064},{\"end\":21547,\"start\":21185},{\"end\":21733,\"start\":21549},{\"end\":21877,\"start\":21762},{\"end\":22053,\"start\":21909},{\"end\":22194,\"start\":22055},{\"end\":22355,\"start\":22226},{\"end\":22531,\"start\":22357},{\"end\":22678,\"start\":22564},{\"end\":22949,\"start\":22680},{\"end\":23111,\"start\":22998},{\"end\":23635,\"start\":23142},{\"end\":23843,\"start\":23658},{\"end\":23877,\"start\":23872},{\"end\":24224,\"start\":24032},{\"end\":24369,\"start\":24281},{\"end\":24652,\"start\":24409},{\"end\":24753,\"start\":24729},{\"end\":24984,\"start\":24755},{\"end\":25133,\"start\":25043},{\"end\":25526,\"start\":25191},{\"end\":25732,\"start\":25562},{\"end\":26060,\"start\":25734},{\"end\":26325,\"start\":26141},{\"end\":26424,\"start\":26379},{\"end\":26503,\"start\":26457},{\"end\":26624,\"start\":26505},{\"end\":26720,\"start\":26626},{\"end\":26866,\"start\":26808},{\"end\":26922,\"start\":26868},{\"end\":27042,\"start\":26997},{\"end\":27194,\"start\":27044},{\"end\":27360,\"start\":27301},{\"end\":28610,\"start\":27405},{\"end\":29140,\"start\":28612},{\"end\":29813,\"start\":29142},{\"end\":30447,\"start\":29856},{\"end\":30525,\"start\":30449},{\"end\":30947,\"start\":30527},{\"end\":31076,\"start\":30949},{\"end\":31834,\"start\":31120},{\"end\":31975,\"start\":31836},{\"end\":32387,\"start\":31977},{\"end\":32474,\"start\":32389},{\"end\":33381,\"start\":32531},{\"end\":34338,\"start\":33383},{\"end\":34423,\"start\":34340},{\"end\":36060,\"start\":34471},{\"end\":36524,\"start\":36062},{\"end\":36660,\"start\":36526},{\"end\":36745,\"start\":36662},{\"end\":37559,\"start\":36816},{\"end\":38064,\"start\":37602},{\"end\":38384,\"start\":38066},{\"end\":39051,\"start\":38386},{\"end\":39136,\"start\":39053},{\"end\":40710,\"start\":39200},{\"end\":41354,\"start\":40712},{\"end\":41607,\"start\":41356},{\"end\":42022,\"start\":41609},{\"end\":42145,\"start\":42024},{\"end\":43178,\"start\":42206},{\"end\":43770,\"start\":43180},{\"end\":44215,\"start\":43772},{\"end\":45212,\"start\":44217},{\"end\":45369,\"start\":45282},{\"end\":46179,\"start\":45371},{\"end\":46885,\"start\":46181},{\"end\":47175,\"start\":46887},{\"end\":48214,\"start\":47219},{\"end\":48611,\"start\":48216},{\"end\":48770,\"start\":48613},{\"end\":49487,\"start\":48772},{\"end\":50964,\"start\":49489},{\"end\":51283,\"start\":51019},{\"end\":51873,\"start\":51285},{\"end\":52645,\"start\":51875},{\"end\":53546,\"start\":52647},{\"end\":54250,\"start\":53548},{\"end\":54755,\"start\":54252},{\"end\":55082,\"start\":54757},{\"end\":56213,\"start\":55130},{\"end\":56901,\"start\":56252},{\"end\":57259,\"start\":56924},{\"end\":58563,\"start\":57261},{\"end\":59449,\"start\":58620},{\"end\":60553,\"start\":59487},{\"end\":62209,\"start\":60588},{\"end\":63329,\"start\":62264},{\"end\":65030,\"start\":63331},{\"end\":65532,\"start\":65110},{\"end\":65648,\"start\":65534},{\"end\":65716,\"start\":65712},{\"end\":65825,\"start\":65718},{\"end\":66082,\"start\":65901},{\"end\":66304,\"start\":66181},{\"end\":66494,\"start\":66376},{\"end\":66693,\"start\":66618},{\"end\":66855,\"start\":66695},{\"end\":67481,\"start\":67012},{\"end\":67614,\"start\":67483},{\"end\":67839,\"start\":67689},{\"end\":68261,\"start\":68044},{\"end\":68813,\"start\":68606},{\"end\":70296,\"start\":68852},{\"end\":70783,\"start\":70321},{\"end\":71410,\"start\":70785},{\"end\":71625,\"start\":71476},{\"end\":71940,\"start\":71728},{\"end\":72292,\"start\":72087},{\"end\":72943,\"start\":72326},{\"end\":74163,\"start\":72945},{\"end\":74915,\"start\":74165},{\"end\":75350,\"start\":74957},{\"end\":75468,\"start\":75373},{\"end\":75787,\"start\":75470},{\"end\":80510,\"start\":75837}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":13555,\"start\":13522},{\"attributes\":{\"id\":\"formula_1\"},\"end\":14484,\"start\":14432},{\"attributes\":{\"id\":\"formula_2\"},\"end\":16030,\"start\":15995},{\"attributes\":{\"id\":\"formula_3\"},\"end\":16769,\"start\":16734},{\"attributes\":{\"id\":\"formula_4\"},\"end\":16800,\"start\":16769},{\"attributes\":{\"id\":\"formula_5\"},\"end\":17345,\"start\":17301},{\"attributes\":{\"id\":\"formula_6\"},\"end\":17573,\"start\":17527},{\"attributes\":{\"id\":\"formula_7\"},\"end\":18008,\"start\":17980},{\"attributes\":{\"id\":\"formula_8\"},\"end\":18062,\"start\":18008},{\"attributes\":{\"id\":\"formula_9\"},\"end\":18110,\"start\":18062},{\"attributes\":{\"id\":\"formula_10\"},\"end\":18664,\"start\":18610},{\"attributes\":{\"id\":\"formula_11\"},\"end\":18841,\"start\":18791},{\"attributes\":{\"id\":\"formula_12\"},\"end\":18898,\"start\":18841},{\"attributes\":{\"id\":\"formula_13\"},\"end\":19337,\"start\":19289},{\"attributes\":{\"id\":\"formula_14\"},\"end\":19402,\"start\":19337},{\"attributes\":{\"id\":\"formula_15\"},\"end\":19454,\"start\":19402},{\"attributes\":{\"id\":\"formula_16\"},\"end\":19920,\"start\":19867},{\"attributes\":{\"id\":\"formula_17\"},\"end\":20049,\"start\":20008},{\"attributes\":{\"id\":\"formula_18\"},\"end\":20110,\"start\":20049},{\"attributes\":{\"id\":\"formula_19\"},\"end\":20557,\"start\":20519},{\"attributes\":{\"id\":\"formula_20\"},\"end\":20594,\"start\":20557},{\"attributes\":{\"id\":\"formula_21\"},\"end\":21023,\"start\":20991},{\"attributes\":{\"id\":\"formula_22\"},\"end\":21063,\"start\":21023},{\"attributes\":{\"id\":\"formula_23\"},\"end\":21761,\"start\":21734},{\"attributes\":{\"id\":\"formula_24\"},\"end\":21908,\"start\":21878},{\"attributes\":{\"id\":\"formula_25\"},\"end\":22225,\"start\":22195},{\"attributes\":{\"id\":\"formula_26\"},\"end\":22563,\"start\":22532},{\"attributes\":{\"id\":\"formula_27\"},\"end\":22997,\"start\":22950},{\"attributes\":{\"id\":\"formula_28\"},\"end\":23871,\"start\":23844},{\"attributes\":{\"id\":\"formula_29\"},\"end\":23910,\"start\":23878},{\"attributes\":{\"id\":\"formula_30\"},\"end\":24009,\"start\":23910},{\"attributes\":{\"id\":\"formula_31\"},\"end\":24280,\"start\":24225},{\"attributes\":{\"id\":\"formula_32\"},\"end\":24408,\"start\":24370},{\"attributes\":{\"id\":\"formula_33\"},\"end\":24728,\"start\":24653},{\"attributes\":{\"id\":\"formula_34\"},\"end\":25042,\"start\":24985},{\"attributes\":{\"id\":\"formula_35\"},\"end\":25190,\"start\":25134},{\"attributes\":{\"id\":\"formula_36\"},\"end\":26104,\"start\":26061},{\"attributes\":{\"id\":\"formula_37\"},\"end\":26140,\"start\":26104},{\"attributes\":{\"id\":\"formula_38\"},\"end\":26378,\"start\":26326},{\"attributes\":{\"id\":\"formula_39\"},\"end\":26456,\"start\":26425},{\"attributes\":{\"id\":\"formula_40\"},\"end\":26767,\"start\":26721},{\"attributes\":{\"id\":\"formula_41\"},\"end\":26807,\"start\":26767},{\"attributes\":{\"id\":\"formula_42\"},\"end\":26957,\"start\":26923},{\"attributes\":{\"id\":\"formula_43\"},\"end\":26996,\"start\":26957},{\"attributes\":{\"id\":\"formula_44\"},\"end\":27241,\"start\":27195},{\"attributes\":{\"id\":\"formula_45\"},\"end\":27300,\"start\":27241},{\"attributes\":{\"id\":\"formula_46\"},\"end\":37601,\"start\":37560},{\"attributes\":{\"id\":\"formula_47\"},\"end\":59486,\"start\":59450},{\"attributes\":{\"id\":\"formula_48\"},\"end\":65711,\"start\":65649},{\"attributes\":{\"id\":\"formula_49\"},\"end\":65900,\"start\":65826},{\"attributes\":{\"id\":\"formula_50\"},\"end\":66180,\"start\":66083},{\"attributes\":{\"id\":\"formula_51\"},\"end\":66375,\"start\":66305},{\"attributes\":{\"id\":\"formula_52\"},\"end\":66548,\"start\":66495},{\"attributes\":{\"id\":\"formula_53\"},\"end\":66617,\"start\":66548},{\"attributes\":{\"id\":\"formula_54\"},\"end\":66909,\"start\":66856},{\"attributes\":{\"id\":\"formula_55\"},\"end\":66950,\"start\":66909},{\"attributes\":{\"id\":\"formula_56\"},\"end\":67011,\"start\":66950},{\"attributes\":{\"id\":\"formula_57\"},\"end\":67688,\"start\":67615},{\"attributes\":{\"id\":\"formula_58\"},\"end\":67903,\"start\":67840},{\"attributes\":{\"id\":\"formula_59\"},\"end\":68043,\"start\":67903},{\"attributes\":{\"id\":\"formula_60\"},\"end\":68325,\"start\":68262},{\"attributes\":{\"id\":\"formula_61\"},\"end\":68411,\"start\":68325},{\"attributes\":{\"id\":\"formula_62\"},\"end\":68461,\"start\":68411},{\"attributes\":{\"id\":\"formula_63\"},\"end\":68530,\"start\":68461},{\"attributes\":{\"id\":\"formula_64\"},\"end\":68605,\"start\":68530},{\"attributes\":{\"id\":\"formula_65\"},\"end\":71475,\"start\":71411},{\"attributes\":{\"id\":\"formula_66\"},\"end\":71697,\"start\":71626},{\"attributes\":{\"id\":\"formula_67\"},\"end\":71727,\"start\":71697},{\"attributes\":{\"id\":\"formula_68\"},\"end\":72012,\"start\":71941},{\"attributes\":{\"id\":\"formula_69\"},\"end\":72086,\"start\":72012},{\"attributes\":{\"id\":\"formula_70\"},\"end\":75372,\"start\":75351}]", "table_ref": "[{\"end\":4885,\"start\":4878},{\"end\":27504,\"start\":27496},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":27815,\"start\":27808},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":31004,\"start\":30997},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":32444,\"start\":32437},{\"attributes\":{\"ref_id\":\"tab_9\"},\"end\":34395,\"start\":34388},{\"attributes\":{\"ref_id\":\"tab_11\"},\"end\":36717,\"start\":36710},{\"attributes\":{\"ref_id\":\"tab_13\"},\"end\":39108,\"start\":39101},{\"attributes\":{\"ref_id\":\"tab_15\"},\"end\":42079,\"start\":42072},{\"attributes\":{\"ref_id\":\"tab_17\"},\"end\":45183,\"start\":45176},{\"attributes\":{\"ref_id\":\"tab_19\"},\"end\":46942,\"start\":46934},{\"attributes\":{\"ref_id\":\"tab_21\"},\"end\":49124,\"start\":49115},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":50935,\"start\":50927},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":51588,\"start\":51575},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":53267,\"start\":53259},{\"attributes\":{\"ref_id\":\"tab_9\"},\"end\":54537,\"start\":54530},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":54974,\"start\":54967},{\"attributes\":{\"ref_id\":\"tab_19\"},\"end\":60854,\"start\":60846},{\"attributes\":{\"ref_id\":\"tab_21\"},\"end\":61096,\"start\":61088},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":61128,\"start\":61120},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":64227,\"start\":64219},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":65647,\"start\":65639},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":68863,\"start\":68855},{\"attributes\":{\"ref_id\":\"tab_9\"},\"end\":70346,\"start\":70339},{\"attributes\":{\"ref_id\":\"tab_9\"},\"end\":70939,\"start\":70931},{\"attributes\":{\"ref_id\":\"tab_11\"},\"end\":72610,\"start\":72602},{\"attributes\":{\"ref_id\":\"tab_11\"},\"end\":74257,\"start\":74249}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":2197,\"start\":2185},{\"end\":5060,\"start\":5026},{\"attributes\":{\"n\":\"2.\"},\"end\":5101,\"start\":5063},{\"attributes\":{\"n\":\"3.\"},\"end\":5698,\"start\":5644},{\"attributes\":{\"n\":\"4.\"},\"end\":8144,\"start\":8134},{\"end\":8733,\"start\":8718},{\"end\":11813,\"start\":11781},{\"end\":13326,\"start\":13302},{\"end\":14097,\"start\":14080},{\"end\":14552,\"start\":14510},{\"end\":15043,\"start\":15027},{\"end\":20770,\"start\":20732},{\"end\":21183,\"start\":21161},{\"end\":23140,\"start\":23114},{\"end\":23656,\"start\":23638},{\"end\":24030,\"start\":24011},{\"end\":25560,\"start\":25529},{\"end\":27403,\"start\":27363},{\"end\":29854,\"start\":29816},{\"end\":31118,\"start\":31079},{\"end\":32482,\"start\":32477},{\"end\":32529,\"start\":32485},{\"end\":34469,\"start\":34426},{\"end\":36814,\"start\":36748},{\"end\":39198,\"start\":39139},{\"end\":42204,\"start\":42148},{\"end\":45280,\"start\":45215},{\"end\":47217,\"start\":47178},{\"end\":51017,\"start\":50967},{\"end\":55128,\"start\":55085},{\"end\":56250,\"start\":56216},{\"end\":56922,\"start\":56904},{\"end\":58618,\"start\":58566},{\"end\":60586,\"start\":60556},{\"end\":62262,\"start\":62212},{\"end\":65078,\"start\":65033},{\"end\":65108,\"start\":65081},{\"end\":68850,\"start\":68816},{\"end\":70319,\"start\":70299},{\"end\":72324,\"start\":72295},{\"end\":74955,\"start\":74918},{\"end\":75835,\"start\":75790},{\"end\":80522,\"start\":80512},{\"end\":80685,\"start\":80675},{\"end\":80998,\"start\":80988},{\"end\":81109,\"start\":81086},{\"end\":81139,\"start\":81129},{\"end\":81172,\"start\":81161},{\"end\":81462,\"start\":81440},{\"end\":81919,\"start\":81908},{\"end\":82179,\"start\":82168},{\"end\":82947,\"start\":82938},{\"end\":84790,\"start\":84781},{\"end\":86899,\"start\":86890},{\"end\":88218,\"start\":88209},{\"end\":89215,\"start\":89206},{\"end\":89506,\"start\":89497},{\"end\":92577,\"start\":92568},{\"end\":94046,\"start\":94037},{\"end\":94289,\"start\":94279},{\"end\":94577,\"start\":94567},{\"end\":94942,\"start\":94932},{\"end\":97562,\"start\":97552},{\"end\":99004,\"start\":98994},{\"end\":99143,\"start\":99133}]", "table": "[{\"end\":82936,\"start\":82369},{\"end\":84779,\"start\":83160},{\"end\":86888,\"start\":85188},{\"end\":88207,\"start\":87311},{\"end\":89204,\"start\":88634},{\"end\":92566,\"start\":89861},{\"end\":94035,\"start\":92961},{\"end\":94930,\"start\":94580},{\"end\":97550,\"start\":95365},{\"end\":97796,\"start\":97565},{\"end\":98992,\"start\":97880},{\"end\":99560,\"start\":99403}]", "figure_caption": "[{\"end\":80673,\"start\":80524},{\"end\":80986,\"start\":80687},{\"end\":81084,\"start\":81000},{\"end\":81127,\"start\":81112},{\"end\":81159,\"start\":81141},{\"end\":81438,\"start\":81175},{\"end\":81906,\"start\":81467},{\"end\":82036,\"start\":81922},{\"end\":82166,\"start\":82039},{\"end\":82364,\"start\":82182},{\"end\":82369,\"start\":82367},{\"end\":83090,\"start\":82949},{\"end\":83160,\"start\":83093},{\"end\":85125,\"start\":84792},{\"end\":85188,\"start\":85128},{\"end\":87311,\"start\":86901},{\"end\":88561,\"start\":88220},{\"end\":88634,\"start\":88564},{\"end\":89495,\"start\":89217},{\"end\":89698,\"start\":89508},{\"end\":89861,\"start\":89701},{\"end\":92894,\"start\":92579},{\"end\":92961,\"start\":92897},{\"end\":94277,\"start\":94048},{\"end\":94565,\"start\":94292},{\"end\":95229,\"start\":94945},{\"end\":95365,\"start\":95232},{\"end\":97880,\"start\":97799},{\"end\":99131,\"start\":99007},{\"end\":99301,\"start\":99146},{\"end\":99403,\"start\":99304}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":3267,\"start\":3261},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":7329,\"start\":7323},{\"end\":12348,\"start\":12340},{\"end\":12370,\"start\":12362},{\"end\":13079,\"start\":13071},{\"end\":14571,\"start\":14563},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":16429,\"start\":16421},{\"end\":16919,\"start\":16911},{\"end\":17605,\"start\":17597},{\"end\":18933,\"start\":18925},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":19571,\"start\":19563},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":20230,\"start\":20221},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":20688,\"start\":20678},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":38013,\"start\":38004},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":40963,\"start\":40955},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":44172,\"start\":44163}]", "bib_author_first_name": "[{\"end\":101033,\"start\":101025},{\"end\":101314,\"start\":101302},{\"end\":101328,\"start\":101324},{\"end\":101341,\"start\":101336},{\"end\":101357,\"start\":101349},{\"end\":101372,\"start\":101366},{\"end\":101384,\"start\":101378},{\"end\":101709,\"start\":101704},{\"end\":101727,\"start\":101721},{\"end\":101740,\"start\":101735},{\"end\":101757,\"start\":101750},{\"end\":101882,\"start\":101877},{\"end\":101886,\"start\":101883},{\"end\":101896,\"start\":101891},{\"end\":101901,\"start\":101897},{\"end\":101917,\"start\":101909},{\"end\":101919,\"start\":101918},{\"end\":102180,\"start\":102173},{\"end\":102200,\"start\":102191},{\"end\":102212,\"start\":102206},{\"end\":102489,\"start\":102484},{\"end\":102507,\"start\":102501},{\"end\":102524,\"start\":102517},{\"end\":102536,\"start\":102530},{\"end\":102871,\"start\":102862},{\"end\":102884,\"start\":102880},{\"end\":102901,\"start\":102894},{\"end\":102918,\"start\":102914},{\"end\":102937,\"start\":102929},{\"end\":102951,\"start\":102945},{\"end\":103292,\"start\":103285},{\"end\":103307,\"start\":103301},{\"end\":103579,\"start\":103573},{\"end\":103594,\"start\":103588},{\"end\":103608,\"start\":103601},{\"end\":103829,\"start\":103821},{\"end\":103850,\"start\":103842},{\"end\":103864,\"start\":103859},{\"end\":103885,\"start\":103870},{\"end\":103902,\"start\":103898},{\"end\":103916,\"start\":103908},{\"end\":103936,\"start\":103930},{\"end\":104355,\"start\":104348},{\"end\":104375,\"start\":104367},{\"end\":104385,\"start\":104384},{\"end\":104403,\"start\":104396},{\"end\":104729,\"start\":104723},{\"end\":104745,\"start\":104739},{\"end\":104992,\"start\":104986},{\"end\":105008,\"start\":105002},{\"end\":105328,\"start\":105324},{\"end\":105505,\"start\":105501},{\"end\":105521,\"start\":105513},{\"end\":105537,\"start\":105531},{\"end\":105549,\"start\":105545},{\"end\":105863,\"start\":105859},{\"end\":105875,\"start\":105871},{\"end\":105890,\"start\":105882},{\"end\":105905,\"start\":105897},{\"end\":105918,\"start\":105912},{\"end\":105936,\"start\":105925},{\"end\":106237,\"start\":106233},{\"end\":106248,\"start\":106244},{\"end\":106261,\"start\":106255},{\"end\":106454,\"start\":106449},{\"end\":106464,\"start\":106461},{\"end\":106479,\"start\":106471},{\"end\":106494,\"start\":106484},{\"end\":106503,\"start\":106499},{\"end\":106769,\"start\":106761},{\"end\":106783,\"start\":106776},{\"end\":106795,\"start\":106792},{\"end\":106806,\"start\":106802},{\"end\":107194,\"start\":107187},{\"end\":107211,\"start\":107203},{\"end\":107219,\"start\":107217},{\"end\":107228,\"start\":107224},{\"end\":107237,\"start\":107233},{\"end\":107253,\"start\":107246},{\"end\":107796,\"start\":107788},{\"end\":107808,\"start\":107804},{\"end\":107829,\"start\":107820},{\"end\":107844,\"start\":107838},{\"end\":107855,\"start\":107850},{\"end\":108181,\"start\":108178},{\"end\":108204,\"start\":108199},{\"end\":108216,\"start\":108209},{\"end\":108494,\"start\":108487},{\"end\":108513,\"start\":108507},{\"end\":108529,\"start\":108523},{\"end\":108884,\"start\":108883},{\"end\":108896,\"start\":108893},{\"end\":108898,\"start\":108897},{\"end\":108917,\"start\":108909},{\"end\":109262,\"start\":109261},{\"end\":109270,\"start\":109269},{\"end\":109278,\"start\":109277},{\"end\":109291,\"start\":109287},{\"end\":109297,\"start\":109296},{\"end\":109303,\"start\":109302},{\"end\":109518,\"start\":109512},{\"end\":109542,\"start\":109534},{\"end\":109553,\"start\":109548},{\"end\":109566,\"start\":109560},{\"end\":109578,\"start\":109574},{\"end\":109591,\"start\":109587},{\"end\":109603,\"start\":109599},{\"end\":109623,\"start\":109615},{\"end\":109636,\"start\":109629},{\"end\":109647,\"start\":109642},{\"end\":110233,\"start\":110227},{\"end\":110257,\"start\":110252},{\"end\":110275,\"start\":110269},{\"end\":110297,\"start\":110290},{\"end\":110313,\"start\":110309},{\"end\":110328,\"start\":110322},{\"end\":110720,\"start\":110719},{\"end\":110722,\"start\":110721},{\"end\":110738,\"start\":110730},{\"end\":110752,\"start\":110746},{\"end\":110767,\"start\":110760},{\"end\":110769,\"start\":110768},{\"end\":111081,\"start\":111073},{\"end\":111095,\"start\":111090},{\"end\":111109,\"start\":111103},{\"end\":111125,\"start\":111118},{\"end\":111344,\"start\":111336},{\"end\":111353,\"start\":111350},{\"end\":111358,\"start\":111354},{\"end\":111653,\"start\":111645},{\"end\":111668,\"start\":111663},{\"end\":111682,\"start\":111679},{\"end\":111698,\"start\":111690},{\"end\":112020,\"start\":112014},{\"end\":112030,\"start\":112029},{\"end\":112052,\"start\":112051},{\"end\":112067,\"start\":112062},{\"end\":112081,\"start\":112075},{\"end\":112083,\"start\":112082},{\"end\":112592,\"start\":112582},{\"end\":112609,\"start\":112601},{\"end\":112624,\"start\":112618},{\"end\":112638,\"start\":112632},{\"end\":112658,\"start\":112648},{\"end\":112674,\"start\":112668},{\"end\":112703,\"start\":112690},{\"end\":112718,\"start\":112712},{\"end\":113087,\"start\":113083},{\"end\":113104,\"start\":113098},{\"end\":113115,\"start\":113111},{\"end\":113406,\"start\":113399},{\"end\":113418,\"start\":113411},{\"end\":113434,\"start\":113426},{\"end\":113444,\"start\":113440},{\"end\":113776,\"start\":113775},{\"end\":113778,\"start\":113777},{\"end\":113794,\"start\":113786},{\"end\":114022,\"start\":114016},{\"end\":114035,\"start\":114027},{\"end\":114048,\"start\":114041},{\"end\":114063,\"start\":114057},{\"end\":114076,\"start\":114070},{\"end\":114087,\"start\":114082},{\"end\":114100,\"start\":114093},{\"end\":114114,\"start\":114110},{\"end\":114498,\"start\":114492},{\"end\":114511,\"start\":114503},{\"end\":114523,\"start\":114517},{\"end\":114533,\"start\":114529},{\"end\":114548,\"start\":114542},{\"end\":114559,\"start\":114555},{\"end\":114888,\"start\":114882},{\"end\":114905,\"start\":114896},{\"end\":115169,\"start\":115168},{\"end\":115182,\"start\":115176},{\"end\":115201,\"start\":115200},{\"end\":115215,\"start\":115211},{\"end\":115217,\"start\":115216},{\"end\":115234,\"start\":115228},{\"end\":115579,\"start\":115573},{\"end\":115589,\"start\":115585},{\"end\":115598,\"start\":115595},{\"end\":115612,\"start\":115605},{\"end\":115622,\"start\":115618},{\"end\":115637,\"start\":115633},{\"end\":115931,\"start\":115924},{\"end\":115943,\"start\":115937},{\"end\":115959,\"start\":115954},{\"end\":116223,\"start\":116214},{\"end\":116398,\"start\":116397},{\"end\":116416,\"start\":116410},{\"end\":116430,\"start\":116424},{\"end\":116743,\"start\":116742},{\"end\":116762,\"start\":116755},{\"end\":116782,\"start\":116770},{\"end\":116798,\"start\":116792},{\"end\":117087,\"start\":117082},{\"end\":117102,\"start\":117096},{\"end\":117112,\"start\":117108},{\"end\":117126,\"start\":117120},{\"end\":117138,\"start\":117136},{\"end\":117446,\"start\":117445},{\"end\":117462,\"start\":117457},{\"end\":117686,\"start\":117685},{\"end\":117698,\"start\":117695},{\"end\":118017,\"start\":118012},{\"end\":118028,\"start\":118027},{\"end\":118044,\"start\":118037},{\"end\":118046,\"start\":118045},{\"end\":118302,\"start\":118296},{\"end\":118312,\"start\":118309},{\"end\":118606,\"start\":118601},{\"end\":118625,\"start\":118616},{\"end\":118638,\"start\":118634},{\"end\":118656,\"start\":118649},{\"end\":118678,\"start\":118669},{\"end\":119020,\"start\":119016},{\"end\":119037,\"start\":119033},{\"end\":119057,\"start\":119049},{\"end\":119059,\"start\":119058},{\"end\":119525,\"start\":119521},{\"end\":119539,\"start\":119533},{\"end\":119710,\"start\":119706},{\"end\":119722,\"start\":119718},{\"end\":119737,\"start\":119731},{\"end\":119753,\"start\":119746},{\"end\":120056,\"start\":120053},{\"end\":120068,\"start\":120061},{\"end\":120082,\"start\":120075},{\"end\":120093,\"start\":120089},{\"end\":120405,\"start\":120400},{\"end\":120417,\"start\":120411},{\"end\":120423,\"start\":120418},{\"end\":120442,\"start\":120434},{\"end\":120453,\"start\":120449},{\"end\":120467,\"start\":120461},{\"end\":120479,\"start\":120473},{\"end\":120495,\"start\":120487},{\"end\":120916,\"start\":120909},{\"end\":121172,\"start\":121165},{\"end\":121186,\"start\":121183},{\"end\":121198,\"start\":121192},{\"end\":121508,\"start\":121500},{\"end\":121762,\"start\":121757},{\"end\":121781,\"start\":121777},{\"end\":122013,\"start\":122009},{\"end\":122033,\"start\":122028},{\"end\":122049,\"start\":122044},{\"end\":122303,\"start\":122299},{\"end\":122670,\"start\":122664},{\"end\":122683,\"start\":122678},{\"end\":122698,\"start\":122692},{\"end\":122711,\"start\":122706},{\"end\":122992,\"start\":122987},{\"end\":123010,\"start\":123002},{\"end\":123238,\"start\":123233},{\"end\":123255,\"start\":123249},{\"end\":123269,\"start\":123263},{\"end\":123554,\"start\":123546},{\"end\":123570,\"start\":123563},{\"end\":123583,\"start\":123577},{\"end\":123599,\"start\":123593},{\"end\":123877,\"start\":123869},{\"end\":123891,\"start\":123885},{\"end\":123910,\"start\":123902},{\"end\":123926,\"start\":123918},{\"end\":123938,\"start\":123935},{\"end\":123955,\"start\":123948},{\"end\":123957,\"start\":123956},{\"end\":124428,\"start\":124420},{\"end\":124443,\"start\":124436},{\"end\":124461,\"start\":124455},{\"end\":124803,\"start\":124795},{\"end\":124819,\"start\":124811},{\"end\":124834,\"start\":124828},{\"end\":124848,\"start\":124843},{\"end\":124865,\"start\":124858},{\"end\":124867,\"start\":124866},{\"end\":125183,\"start\":125172},{\"end\":125198,\"start\":125192},{\"end\":125216,\"start\":125208},{\"end\":125223,\"start\":125222},{\"end\":125236,\"start\":125233},{\"end\":125241,\"start\":125237},{\"end\":125258,\"start\":125252},{\"end\":125274,\"start\":125268},{\"end\":125743,\"start\":125739},{\"end\":125767,\"start\":125752},{\"end\":125787,\"start\":125780},{\"end\":125798,\"start\":125793},{\"end\":126052,\"start\":126048},{\"end\":126064,\"start\":126061},{\"end\":126081,\"start\":126072},{\"end\":126093,\"start\":126089},{\"end\":126106,\"start\":126101},{\"end\":126124,\"start\":126117},{\"end\":126139,\"start\":126133},{\"end\":126155,\"start\":126149},{\"end\":126168,\"start\":126161},{\"end\":126185,\"start\":126181},{\"end\":126199,\"start\":126194},{\"end\":126218,\"start\":126211},{\"end\":126231,\"start\":126225},{\"end\":126242,\"start\":126238},{\"end\":126257,\"start\":126251},{\"end\":126273,\"start\":126266},{\"end\":126288,\"start\":126282},{\"end\":126309,\"start\":126303},{\"end\":126321,\"start\":126319},{\"end\":126334,\"start\":126328},{\"end\":126347,\"start\":126340},{\"end\":126871,\"start\":126864},{\"end\":126891,\"start\":126884},{\"end\":126913,\"start\":126900},{\"end\":127397,\"start\":127391},{\"end\":127414,\"start\":127406},{\"end\":127677,\"start\":127669},{\"end\":127693,\"start\":127685},{\"end\":127705,\"start\":127702},{\"end\":127725,\"start\":127719},{\"end\":127741,\"start\":127734},{\"end\":127761,\"start\":127753},{\"end\":128116,\"start\":128110},{\"end\":128142,\"start\":128135},{\"end\":128154,\"start\":128150},{\"end\":128161,\"start\":128155},{\"end\":128180,\"start\":128176},{\"end\":128194,\"start\":128188},{\"end\":128211,\"start\":128207},{\"end\":128226,\"start\":128221},{\"end\":128566,\"start\":128560},{\"end\":128593,\"start\":128585},{\"end\":128608,\"start\":128602},{\"end\":128619,\"start\":128616},{\"end\":128630,\"start\":128626},{\"end\":128646,\"start\":128641},{\"end\":128648,\"start\":128647},{\"end\":128983,\"start\":128982},{\"end\":128996,\"start\":128995},{\"end\":129004,\"start\":129003},{\"end\":129012,\"start\":129011},{\"end\":129028,\"start\":129027},{\"end\":129307,\"start\":129300},{\"end\":129324,\"start\":129323},{\"end\":129338,\"start\":129333},{\"end\":129351,\"start\":129345},{\"end\":129372,\"start\":129368},{\"end\":129382,\"start\":129379},{\"end\":129785,\"start\":129777},{\"end\":129814,\"start\":129806},{\"end\":130137,\"start\":130122},{\"end\":130155,\"start\":130150},{\"end\":130474,\"start\":130465},{\"end\":130490,\"start\":130487},{\"end\":130948,\"start\":130947},{\"end\":130962,\"start\":130956},{\"end\":130981,\"start\":130971},{\"end\":131257,\"start\":131256},{\"end\":131270,\"start\":131265},{\"end\":131285,\"start\":131279},{\"end\":131302,\"start\":131294},{\"end\":131309,\"start\":131303},{\"end\":131623,\"start\":131618},{\"end\":131640,\"start\":131634},{\"end\":131659,\"start\":131653},{\"end\":131943,\"start\":131937},{\"end\":131957,\"start\":131953},{\"end\":131971,\"start\":131967},{\"end\":131985,\"start\":131980},{\"end\":132002,\"start\":131997},{\"end\":132015,\"start\":132010},{\"end\":132017,\"start\":132016},{\"end\":132031,\"start\":132025},{\"end\":132045,\"start\":132040},{\"end\":132344,\"start\":132339},{\"end\":132364,\"start\":132357},{\"end\":132382,\"start\":132375},{\"end\":132400,\"start\":132393},{\"end\":132415,\"start\":132409},{\"end\":132427,\"start\":132421},{\"end\":132802,\"start\":132795},{\"end\":132818,\"start\":132811},{\"end\":132833,\"start\":132827},{\"end\":133016,\"start\":133011},{\"end\":133031,\"start\":133026},{\"end\":133050,\"start\":133043},{\"end\":133299,\"start\":133293},{\"end\":133312,\"start\":133305},{\"end\":133538,\"start\":133532},{\"end\":133552,\"start\":133545},{\"end\":133563,\"start\":133558},{\"end\":133574,\"start\":133571},{\"end\":133894,\"start\":133887},{\"end\":133908,\"start\":133901},{\"end\":133922,\"start\":133915},{\"end\":133939,\"start\":133930},{\"end\":133950,\"start\":133944},{\"end\":133963,\"start\":133957},{\"end\":134207,\"start\":134201},{\"end\":134221,\"start\":134214},{\"end\":134228,\"start\":134226},{\"end\":134240,\"start\":134236},{\"end\":134248,\"start\":134246},{\"end\":134259,\"start\":134254},{\"end\":134269,\"start\":134264},{\"end\":134281,\"start\":134274},{\"end\":134290,\"start\":134288},{\"end\":134302,\"start\":134298},{\"end\":134312,\"start\":134307},{\"end\":134326,\"start\":134320},{\"end\":134335,\"start\":134332},{\"end\":134349,\"start\":134343},{\"end\":134360,\"start\":134355},{\"end\":134374,\"start\":134367},{\"end\":134388,\"start\":134379},{\"end\":134390,\"start\":134389},{\"end\":134403,\"start\":134398},{\"end\":134977,\"start\":134976},{\"end\":134991,\"start\":134985},{\"end\":135007,\"start\":134999},{\"end\":135026,\"start\":135017},{\"end\":135046,\"start\":135037},{\"end\":135070,\"start\":135069},{\"end\":135087,\"start\":135077},{\"end\":135101,\"start\":135097},{\"end\":135120,\"start\":135114},{\"end\":135488,\"start\":135483},{\"end\":135502,\"start\":135494},{\"end\":135796,\"start\":135791},{\"end\":135815,\"start\":135809},{\"end\":135817,\"start\":135816},{\"end\":136015,\"start\":136009},{\"end\":136028,\"start\":136020},{\"end\":136041,\"start\":136033},{\"end\":136056,\"start\":136048},{\"end\":136073,\"start\":136065},{\"end\":136097,\"start\":136089},{\"end\":136460,\"start\":136454},{\"end\":136471,\"start\":136465},{\"end\":136480,\"start\":136476},{\"end\":136499,\"start\":136491},{\"end\":136799,\"start\":136790},{\"end\":136812,\"start\":136806},{\"end\":136826,\"start\":136818},{\"end\":136838,\"start\":136832},{\"end\":136852,\"start\":136846},{\"end\":136859,\"start\":136857},{\"end\":136871,\"start\":136864},{\"end\":136885,\"start\":136878},{\"end\":137252,\"start\":137249},{\"end\":137266,\"start\":137259},{\"end\":137278,\"start\":137271},{\"end\":137289,\"start\":137285},{\"end\":137305,\"start\":137304},{\"end\":137319,\"start\":137315},{\"end\":137852,\"start\":137845},{\"end\":137861,\"start\":137858},{\"end\":137872,\"start\":137868},{\"end\":138169,\"start\":138163},{\"end\":138180,\"start\":138177},{\"end\":138193,\"start\":138185},{\"end\":138206,\"start\":138201},{\"end\":138528,\"start\":138522},{\"end\":138540,\"start\":138535},{\"end\":138553,\"start\":138547},{\"end\":138562,\"start\":138559},{\"end\":138801,\"start\":138793},{\"end\":138812,\"start\":138808},{\"end\":138827,\"start\":138820},{\"end\":138839,\"start\":138832},{\"end\":138848,\"start\":138845},{\"end\":138858,\"start\":138855}]", "bib_author_last_name": "[{\"end\":101038,\"start\":101034},{\"end\":101322,\"start\":101315},{\"end\":101334,\"start\":101329},{\"end\":101347,\"start\":101342},{\"end\":101364,\"start\":101358},{\"end\":101376,\"start\":101373},{\"end\":101394,\"start\":101385},{\"end\":101719,\"start\":101710},{\"end\":101733,\"start\":101728},{\"end\":101748,\"start\":101741},{\"end\":101762,\"start\":101758},{\"end\":101889,\"start\":101887},{\"end\":101907,\"start\":101902},{\"end\":101926,\"start\":101920},{\"end\":102189,\"start\":102181},{\"end\":102204,\"start\":102201},{\"end\":102219,\"start\":102213},{\"end\":102499,\"start\":102490},{\"end\":102515,\"start\":102508},{\"end\":102528,\"start\":102525},{\"end\":102552,\"start\":102537},{\"end\":102878,\"start\":102872},{\"end\":102892,\"start\":102885},{\"end\":102912,\"start\":102902},{\"end\":102927,\"start\":102919},{\"end\":102943,\"start\":102938},{\"end\":102955,\"start\":102952},{\"end\":103299,\"start\":103293},{\"end\":103314,\"start\":103308},{\"end\":103586,\"start\":103580},{\"end\":103599,\"start\":103595},{\"end\":103617,\"start\":103609},{\"end\":103840,\"start\":103830},{\"end\":103857,\"start\":103851},{\"end\":103868,\"start\":103865},{\"end\":103896,\"start\":103886},{\"end\":103906,\"start\":103903},{\"end\":103928,\"start\":103917},{\"end\":103956,\"start\":103937},{\"end\":103963,\"start\":103958},{\"end\":104365,\"start\":104356},{\"end\":104382,\"start\":104376},{\"end\":104394,\"start\":104386},{\"end\":104413,\"start\":104404},{\"end\":104424,\"start\":104415},{\"end\":104737,\"start\":104730},{\"end\":104753,\"start\":104746},{\"end\":105000,\"start\":104993},{\"end\":105016,\"start\":105009},{\"end\":105341,\"start\":105329},{\"end\":105511,\"start\":105506},{\"end\":105529,\"start\":105522},{\"end\":105543,\"start\":105538},{\"end\":105555,\"start\":105550},{\"end\":105869,\"start\":105864},{\"end\":105880,\"start\":105876},{\"end\":105895,\"start\":105891},{\"end\":105910,\"start\":105906},{\"end\":105923,\"start\":105919},{\"end\":105939,\"start\":105937},{\"end\":106242,\"start\":106238},{\"end\":106253,\"start\":106249},{\"end\":106265,\"start\":106262},{\"end\":106459,\"start\":106455},{\"end\":106469,\"start\":106465},{\"end\":106482,\"start\":106480},{\"end\":106497,\"start\":106495},{\"end\":106508,\"start\":106504},{\"end\":106774,\"start\":106770},{\"end\":106790,\"start\":106784},{\"end\":106800,\"start\":106796},{\"end\":106812,\"start\":106807},{\"end\":107201,\"start\":107195},{\"end\":107215,\"start\":107212},{\"end\":107222,\"start\":107220},{\"end\":107231,\"start\":107229},{\"end\":107244,\"start\":107238},{\"end\":107259,\"start\":107254},{\"end\":107802,\"start\":107797},{\"end\":107818,\"start\":107809},{\"end\":107836,\"start\":107830},{\"end\":107848,\"start\":107845},{\"end\":107866,\"start\":107856},{\"end\":108197,\"start\":108182},{\"end\":108207,\"start\":108205},{\"end\":108226,\"start\":108217},{\"end\":108230,\"start\":108228},{\"end\":108505,\"start\":108495},{\"end\":108521,\"start\":108514},{\"end\":108543,\"start\":108530},{\"end\":108891,\"start\":108885},{\"end\":108907,\"start\":108899},{\"end\":108923,\"start\":108918},{\"end\":108930,\"start\":108925},{\"end\":109267,\"start\":109263},{\"end\":109275,\"start\":109271},{\"end\":109285,\"start\":109279},{\"end\":109294,\"start\":109292},{\"end\":109300,\"start\":109298},{\"end\":109311,\"start\":109304},{\"end\":109532,\"start\":109519},{\"end\":109546,\"start\":109543},{\"end\":109558,\"start\":109554},{\"end\":109572,\"start\":109567},{\"end\":109585,\"start\":109579},{\"end\":109597,\"start\":109592},{\"end\":109613,\"start\":109604},{\"end\":109627,\"start\":109624},{\"end\":109640,\"start\":109637},{\"end\":109657,\"start\":109648},{\"end\":110250,\"start\":110234},{\"end\":110267,\"start\":110258},{\"end\":110288,\"start\":110276},{\"end\":110307,\"start\":110298},{\"end\":110320,\"start\":110314},{\"end\":110341,\"start\":110329},{\"end\":110348,\"start\":110343},{\"end\":110728,\"start\":110723},{\"end\":110744,\"start\":110739},{\"end\":110758,\"start\":110753},{\"end\":110775,\"start\":110770},{\"end\":110786,\"start\":110777},{\"end\":111088,\"start\":111082},{\"end\":111101,\"start\":111096},{\"end\":111116,\"start\":111110},{\"end\":111133,\"start\":111126},{\"end\":111348,\"start\":111345},{\"end\":111366,\"start\":111359},{\"end\":111661,\"start\":111654},{\"end\":111677,\"start\":111669},{\"end\":111688,\"start\":111683},{\"end\":111704,\"start\":111699},{\"end\":112027,\"start\":112021},{\"end\":112037,\"start\":112031},{\"end\":112049,\"start\":112039},{\"end\":112060,\"start\":112053},{\"end\":112073,\"start\":112068},{\"end\":112091,\"start\":112084},{\"end\":112097,\"start\":112093},{\"end\":112599,\"start\":112593},{\"end\":112616,\"start\":112610},{\"end\":112630,\"start\":112625},{\"end\":112646,\"start\":112639},{\"end\":112666,\"start\":112659},{\"end\":112688,\"start\":112675},{\"end\":112710,\"start\":112704},{\"end\":112726,\"start\":112719},{\"end\":113096,\"start\":113088},{\"end\":113109,\"start\":113105},{\"end\":113124,\"start\":113116},{\"end\":113409,\"start\":113407},{\"end\":113424,\"start\":113419},{\"end\":113438,\"start\":113435},{\"end\":113448,\"start\":113445},{\"end\":113784,\"start\":113779},{\"end\":113802,\"start\":113795},{\"end\":114025,\"start\":114023},{\"end\":114039,\"start\":114036},{\"end\":114055,\"start\":114049},{\"end\":114068,\"start\":114064},{\"end\":114080,\"start\":114077},{\"end\":114091,\"start\":114088},{\"end\":114108,\"start\":114101},{\"end\":114123,\"start\":114115},{\"end\":114501,\"start\":114499},{\"end\":114515,\"start\":114512},{\"end\":114527,\"start\":114524},{\"end\":114540,\"start\":114534},{\"end\":114553,\"start\":114549},{\"end\":114568,\"start\":114560},{\"end\":114894,\"start\":114889},{\"end\":114913,\"start\":114906},{\"end\":115174,\"start\":115170},{\"end\":115188,\"start\":115183},{\"end\":115198,\"start\":115190},{\"end\":115209,\"start\":115202},{\"end\":115226,\"start\":115218},{\"end\":115242,\"start\":115235},{\"end\":115251,\"start\":115244},{\"end\":115583,\"start\":115580},{\"end\":115593,\"start\":115590},{\"end\":115603,\"start\":115599},{\"end\":115616,\"start\":115613},{\"end\":115631,\"start\":115623},{\"end\":115643,\"start\":115638},{\"end\":115935,\"start\":115932},{\"end\":115952,\"start\":115944},{\"end\":115968,\"start\":115960},{\"end\":116229,\"start\":116224},{\"end\":116408,\"start\":116399},{\"end\":116422,\"start\":116417},{\"end\":116438,\"start\":116431},{\"end\":116447,\"start\":116440},{\"end\":116753,\"start\":116744},{\"end\":116768,\"start\":116763},{\"end\":116790,\"start\":116783},{\"end\":116807,\"start\":116799},{\"end\":116816,\"start\":116809},{\"end\":117094,\"start\":117088},{\"end\":117106,\"start\":117103},{\"end\":117118,\"start\":117113},{\"end\":117134,\"start\":117127},{\"end\":117143,\"start\":117139},{\"end\":117455,\"start\":117447},{\"end\":117469,\"start\":117463},{\"end\":117473,\"start\":117471},{\"end\":117693,\"start\":117687},{\"end\":117703,\"start\":117699},{\"end\":117712,\"start\":117705},{\"end\":118025,\"start\":118018},{\"end\":118035,\"start\":118029},{\"end\":118053,\"start\":118047},{\"end\":118059,\"start\":118055},{\"end\":118307,\"start\":118303},{\"end\":118327,\"start\":118313},{\"end\":118336,\"start\":118329},{\"end\":118614,\"start\":118607},{\"end\":118632,\"start\":118626},{\"end\":118647,\"start\":118639},{\"end\":118667,\"start\":118657},{\"end\":118685,\"start\":118679},{\"end\":119031,\"start\":119021},{\"end\":119047,\"start\":119038},{\"end\":119066,\"start\":119060},{\"end\":119531,\"start\":119526},{\"end\":119546,\"start\":119540},{\"end\":119716,\"start\":119711},{\"end\":119729,\"start\":119723},{\"end\":119744,\"start\":119738},{\"end\":119761,\"start\":119754},{\"end\":120059,\"start\":120057},{\"end\":120073,\"start\":120069},{\"end\":120087,\"start\":120083},{\"end\":120102,\"start\":120094},{\"end\":120409,\"start\":120406},{\"end\":120432,\"start\":120424},{\"end\":120447,\"start\":120443},{\"end\":120459,\"start\":120454},{\"end\":120471,\"start\":120468},{\"end\":120485,\"start\":120480},{\"end\":120503,\"start\":120496},{\"end\":120923,\"start\":120917},{\"end\":121181,\"start\":121173},{\"end\":121190,\"start\":121187},{\"end\":121202,\"start\":121199},{\"end\":121514,\"start\":121509},{\"end\":121775,\"start\":121763},{\"end\":121787,\"start\":121782},{\"end\":122026,\"start\":122014},{\"end\":122042,\"start\":122034},{\"end\":122060,\"start\":122050},{\"end\":122068,\"start\":122062},{\"end\":122316,\"start\":122304},{\"end\":122326,\"start\":122318},{\"end\":122676,\"start\":122671},{\"end\":122690,\"start\":122684},{\"end\":122704,\"start\":122699},{\"end\":122718,\"start\":122712},{\"end\":123000,\"start\":122993},{\"end\":123017,\"start\":123011},{\"end\":123247,\"start\":123239},{\"end\":123261,\"start\":123256},{\"end\":123275,\"start\":123270},{\"end\":123561,\"start\":123555},{\"end\":123575,\"start\":123571},{\"end\":123591,\"start\":123584},{\"end\":123606,\"start\":123600},{\"end\":123883,\"start\":123878},{\"end\":123900,\"start\":123892},{\"end\":123916,\"start\":123911},{\"end\":123933,\"start\":123927},{\"end\":123946,\"start\":123939},{\"end\":123967,\"start\":123958},{\"end\":124434,\"start\":124429},{\"end\":124453,\"start\":124444},{\"end\":124469,\"start\":124462},{\"end\":124809,\"start\":124804},{\"end\":124826,\"start\":124820},{\"end\":124841,\"start\":124835},{\"end\":124856,\"start\":124849},{\"end\":124877,\"start\":124868},{\"end\":125190,\"start\":125184},{\"end\":125206,\"start\":125199},{\"end\":125220,\"start\":125217},{\"end\":125231,\"start\":125224},{\"end\":125250,\"start\":125242},{\"end\":125266,\"start\":125259},{\"end\":125281,\"start\":125275},{\"end\":125288,\"start\":125283},{\"end\":125750,\"start\":125744},{\"end\":125778,\"start\":125768},{\"end\":125791,\"start\":125788},{\"end\":125806,\"start\":125799},{\"end\":126059,\"start\":126053},{\"end\":126070,\"start\":126065},{\"end\":126087,\"start\":126082},{\"end\":126099,\"start\":126094},{\"end\":126115,\"start\":126107},{\"end\":126131,\"start\":126125},{\"end\":126147,\"start\":126140},{\"end\":126159,\"start\":126156},{\"end\":126179,\"start\":126169},{\"end\":126192,\"start\":126186},{\"end\":126209,\"start\":126200},{\"end\":126223,\"start\":126219},{\"end\":126236,\"start\":126232},{\"end\":126249,\"start\":126243},{\"end\":126264,\"start\":126258},{\"end\":126280,\"start\":126274},{\"end\":126301,\"start\":126289},{\"end\":126317,\"start\":126310},{\"end\":126326,\"start\":126322},{\"end\":126338,\"start\":126335},{\"end\":126356,\"start\":126348},{\"end\":126882,\"start\":126872},{\"end\":126898,\"start\":126892},{\"end\":126921,\"start\":126914},{\"end\":127404,\"start\":127398},{\"end\":127420,\"start\":127415},{\"end\":127683,\"start\":127678},{\"end\":127700,\"start\":127694},{\"end\":127717,\"start\":127706},{\"end\":127732,\"start\":127726},{\"end\":127751,\"start\":127742},{\"end\":127767,\"start\":127762},{\"end\":128133,\"start\":128117},{\"end\":128148,\"start\":128143},{\"end\":128174,\"start\":128162},{\"end\":128186,\"start\":128181},{\"end\":128205,\"start\":128195},{\"end\":128219,\"start\":128212},{\"end\":128236,\"start\":128227},{\"end\":128583,\"start\":128567},{\"end\":128600,\"start\":128594},{\"end\":128614,\"start\":128609},{\"end\":128624,\"start\":128620},{\"end\":128639,\"start\":128631},{\"end\":128658,\"start\":128649},{\"end\":128993,\"start\":128984},{\"end\":129001,\"start\":128997},{\"end\":129009,\"start\":129005},{\"end\":129025,\"start\":129013},{\"end\":129039,\"start\":129029},{\"end\":129321,\"start\":129308},{\"end\":129331,\"start\":129325},{\"end\":129343,\"start\":129339},{\"end\":129357,\"start\":129352},{\"end\":129366,\"start\":129359},{\"end\":129377,\"start\":129373},{\"end\":129388,\"start\":129383},{\"end\":129397,\"start\":129390},{\"end\":129804,\"start\":129786},{\"end\":129821,\"start\":129815},{\"end\":129825,\"start\":129823},{\"end\":130148,\"start\":130138},{\"end\":130163,\"start\":130156},{\"end\":130485,\"start\":130475},{\"end\":130497,\"start\":130491},{\"end\":130954,\"start\":130949},{\"end\":130969,\"start\":130963},{\"end\":130999,\"start\":130982},{\"end\":131005,\"start\":131001},{\"end\":131263,\"start\":131258},{\"end\":131277,\"start\":131271},{\"end\":131292,\"start\":131286},{\"end\":131313,\"start\":131310},{\"end\":131319,\"start\":131315},{\"end\":131632,\"start\":131624},{\"end\":131651,\"start\":131641},{\"end\":131665,\"start\":131660},{\"end\":131951,\"start\":131944},{\"end\":131965,\"start\":131958},{\"end\":131978,\"start\":131972},{\"end\":131995,\"start\":131986},{\"end\":132008,\"start\":132003},{\"end\":132023,\"start\":132018},{\"end\":132038,\"start\":132032},{\"end\":132056,\"start\":132046},{\"end\":132355,\"start\":132345},{\"end\":132373,\"start\":132365},{\"end\":132391,\"start\":132383},{\"end\":132407,\"start\":132401},{\"end\":132419,\"start\":132416},{\"end\":132434,\"start\":132428},{\"end\":132809,\"start\":132803},{\"end\":132825,\"start\":132819},{\"end\":132842,\"start\":132834},{\"end\":133024,\"start\":133017},{\"end\":133041,\"start\":133032},{\"end\":133057,\"start\":133051},{\"end\":133303,\"start\":133300},{\"end\":133543,\"start\":133539},{\"end\":133556,\"start\":133553},{\"end\":133569,\"start\":133564},{\"end\":133577,\"start\":133575},{\"end\":133899,\"start\":133895},{\"end\":133913,\"start\":133909},{\"end\":133928,\"start\":133923},{\"end\":133942,\"start\":133940},{\"end\":133955,\"start\":133951},{\"end\":133971,\"start\":133964},{\"end\":134212,\"start\":134208},{\"end\":134224,\"start\":134222},{\"end\":134234,\"start\":134229},{\"end\":134244,\"start\":134241},{\"end\":134252,\"start\":134249},{\"end\":134262,\"start\":134260},{\"end\":134272,\"start\":134270},{\"end\":134286,\"start\":134282},{\"end\":134296,\"start\":134291},{\"end\":134305,\"start\":134303},{\"end\":134318,\"start\":134313},{\"end\":134330,\"start\":134327},{\"end\":134341,\"start\":134336},{\"end\":134353,\"start\":134350},{\"end\":134365,\"start\":134361},{\"end\":134377,\"start\":134375},{\"end\":134396,\"start\":134391},{\"end\":134409,\"start\":134404},{\"end\":134983,\"start\":134978},{\"end\":134997,\"start\":134992},{\"end\":135015,\"start\":135008},{\"end\":135035,\"start\":135027},{\"end\":135054,\"start\":135047},{\"end\":135067,\"start\":135056},{\"end\":135075,\"start\":135071},{\"end\":135095,\"start\":135088},{\"end\":135112,\"start\":135102},{\"end\":135126,\"start\":135121},{\"end\":135136,\"start\":135128},{\"end\":135492,\"start\":135489},{\"end\":135505,\"start\":135503},{\"end\":135807,\"start\":135797},{\"end\":135824,\"start\":135818},{\"end\":136018,\"start\":136016},{\"end\":136031,\"start\":136029},{\"end\":136046,\"start\":136042},{\"end\":136063,\"start\":136057},{\"end\":136087,\"start\":136074},{\"end\":136105,\"start\":136098},{\"end\":136463,\"start\":136461},{\"end\":136474,\"start\":136472},{\"end\":136489,\"start\":136481},{\"end\":136507,\"start\":136500},{\"end\":136804,\"start\":136800},{\"end\":136816,\"start\":136813},{\"end\":136830,\"start\":136827},{\"end\":136844,\"start\":136839},{\"end\":136855,\"start\":136853},{\"end\":136862,\"start\":136860},{\"end\":136876,\"start\":136872},{\"end\":136889,\"start\":136886},{\"end\":137257,\"start\":137253},{\"end\":137269,\"start\":137267},{\"end\":137283,\"start\":137279},{\"end\":137302,\"start\":137290},{\"end\":137313,\"start\":137306},{\"end\":137328,\"start\":137320},{\"end\":137338,\"start\":137330},{\"end\":137856,\"start\":137853},{\"end\":137866,\"start\":137862},{\"end\":137881,\"start\":137873},{\"end\":138175,\"start\":138170},{\"end\":138183,\"start\":138181},{\"end\":138199,\"start\":138194},{\"end\":138211,\"start\":138207},{\"end\":138533,\"start\":138529},{\"end\":138545,\"start\":138541},{\"end\":138557,\"start\":138554},{\"end\":138568,\"start\":138563},{\"end\":138806,\"start\":138802},{\"end\":138818,\"start\":138813},{\"end\":138830,\"start\":138828},{\"end\":138843,\"start\":138840},{\"end\":138853,\"start\":138849},{\"end\":138861,\"start\":138859}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":9134861},\"end\":101234,\"start\":100955},{\"attributes\":{\"doi\":\"0162-8828\",\"id\":\"b1\",\"matched_paper_id\":1806278},\"end\":101702,\"start\":101236},{\"attributes\":{\"id\":\"b2\"},\"end\":101875,\"start\":101704},{\"attributes\":{\"id\":\"b3\"},\"end\":102100,\"start\":101877},{\"attributes\":{\"doi\":\"arXiv:1409.0473\",\"id\":\"b4\"},\"end\":102410,\"start\":102102},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":2200675},\"end\":102832,\"start\":102412},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":222141692},\"end\":103209,\"start\":102834},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":14879317},\"end\":103489,\"start\":103211},{\"attributes\":{\"doi\":\"arXiv:1811.06128\",\"id\":\"b8\"},\"end\":103819,\"start\":103491},{\"attributes\":{\"doi\":\"arXiv:2110.02910\",\"id\":\"b9\"},\"end\":104267,\"start\":103821},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":219708613},\"end\":104719,\"start\":104269},{\"attributes\":{\"doi\":\"arXiv:1711.07553\",\"id\":\"b11\"},\"end\":104920,\"start\":104721},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":182952747},\"end\":105253,\"start\":104922},{\"attributes\":{\"doi\":\"arXiv:1906.12192\",\"id\":\"b13\"},\"end\":105499,\"start\":105255},{\"attributes\":{\"doi\":\"arXiv:1312.6203\",\"id\":\"b14\"},\"end\":105803,\"start\":105501},{\"attributes\":{\"doi\":\"arXiv:2005.00545\",\"id\":\"b15\"},\"end\":106151,\"start\":105805},{\"attributes\":{\"id\":\"b16\"},\"end\":106391,\"start\":106153},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":221878917},\"end\":106668,\"start\":106393},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":168169990},\"end\":107092,\"start\":106670},{\"attributes\":{\"id\":\"b19\"},\"end\":107734,\"start\":107094},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":215745143},\"end\":108129,\"start\":107736},{\"attributes\":{\"doi\":\"arXiv:1909.05862\",\"id\":\"b21\"},\"end\":108405,\"start\":108131},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":3016223},\"end\":108819,\"start\":108407},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":4193919},\"end\":109206,\"start\":108821},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":57246310},\"end\":109452,\"start\":109208},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":237303762},\"end\":110155,\"start\":109454},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":1690180},\"end\":110674,\"start\":110157},{\"attributes\":{\"id\":\"b27\"},\"end\":111002,\"start\":110676},{\"attributes\":{\"id\":\"b28\"},\"end\":111275,\"start\":111004},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":70349949},\"end\":111599,\"start\":111277},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":2384316},\"end\":111966,\"start\":111601},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":9665943},\"end\":112473,\"start\":111968},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":5009168},\"end\":113030,\"start\":112475},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":4755450},\"end\":113351,\"start\":113032},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":206594692},\"end\":113706,\"start\":113353},{\"attributes\":{\"doi\":\"abs/1905.09550\",\"id\":\"b35\",\"matched_paper_id\":162183860},\"end\":113951,\"start\":113708},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":218487328},\"end\":114426,\"start\":113953},{\"attributes\":{\"doi\":\"arXiv:2103.09430\",\"id\":\"b37\"},\"end\":114786,\"start\":114428},{\"attributes\":{\"doi\":\"arXiv:1502.03167\",\"id\":\"b38\"},\"end\":115113,\"start\":114788},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":9759396},\"end\":115510,\"start\":115115},{\"attributes\":{\"doi\":\"arXiv:1906.03707\",\"id\":\"b40\"},\"end\":115852,\"start\":115512},{\"attributes\":{\"doi\":\"arXiv:1802.04364\",\"id\":\"b41\"},\"end\":116158,\"start\":115854},{\"attributes\":{\"id\":\"b42\"},\"end\":116307,\"start\":116160},{\"attributes\":{\"doi\":\"arXiv:1906.01227\",\"id\":\"b43\"},\"end\":116660,\"start\":116309},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":247595029},\"end\":117020,\"start\":116662},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":3486660},\"end\":117399,\"start\":117022},{\"attributes\":{\"doi\":\"arXiv:1412.6980\",\"id\":\"b46\"},\"end\":117617,\"start\":117401},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":3144218},\"end\":117941,\"start\":117619},{\"attributes\":{\"doi\":\"arXiv:1905.02850\",\"id\":\"b48\"},\"end\":118250,\"start\":117943},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":59608816},\"end\":118544,\"start\":118252},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":235368041},\"end\":118949,\"start\":118546},{\"attributes\":{\"id\":\"b51\",\"matched_paper_id\":195908774},\"end\":119459,\"start\":118951},{\"attributes\":{\"id\":\"b52\"},\"end\":119647,\"start\":119461},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":14542261},\"end\":119958,\"start\":119649},{\"attributes\":{\"doi\":\"arXiv:2009.00142\",\"id\":\"b54\"},\"end\":120320,\"start\":119960},{\"attributes\":{\"id\":\"b55\",\"matched_paper_id\":247158269},\"end\":120850,\"start\":120322},{\"attributes\":{\"id\":\"b56\",\"matched_paper_id\":195833273},\"end\":121163,\"start\":120852},{\"attributes\":{\"doi\":\"arXiv:1905.04682\",\"id\":\"b57\"},\"end\":121431,\"start\":121165},{\"attributes\":{\"doi\":\"0001-0782\",\"id\":\"b58\",\"matched_paper_id\":21346812},\"end\":121674,\"start\":121433},{\"attributes\":{\"doi\":\"arXiv:1703.04826\",\"id\":\"b59\"},\"end\":121973,\"start\":121676},{\"attributes\":{\"id\":\"b60\",\"matched_paper_id\":166228757},\"end\":122297,\"start\":121975},{\"attributes\":{\"id\":\"b61\"},\"end\":122619,\"start\":122299},{\"attributes\":{\"id\":\"b62\",\"matched_paper_id\":59316743},\"end\":122921,\"start\":122621},{\"attributes\":{\"doi\":\"arXiv:2007.02901\",\"id\":\"b63\"},\"end\":123186,\"start\":122923},{\"attributes\":{\"id\":\"b64\",\"matched_paper_id\":225039814},\"end\":123493,\"start\":123188},{\"attributes\":{\"doi\":\"arXiv:2106.05667\",\"id\":\"b65\"},\"end\":123793,\"start\":123495},{\"attributes\":{\"doi\":\"10.1109/cvpr.2017.576\",\"id\":\"b66\",\"matched_paper_id\":301319},\"end\":124346,\"start\":123795},{\"attributes\":{\"id\":\"b67\",\"matched_paper_id\":18052422},\"end\":124726,\"start\":124348},{\"attributes\":{\"doi\":\"arXiv:1902.06673\",\"id\":\"b68\"},\"end\":125102,\"start\":124728},{\"attributes\":{\"id\":\"b69\",\"matched_paper_id\":52919090},\"end\":125691,\"start\":125104},{\"attributes\":{\"id\":\"b70\",\"matched_paper_id\":70350010},\"end\":126044,\"start\":125693},{\"attributes\":{\"id\":\"b71\"},\"end\":126815,\"start\":126046},{\"attributes\":{\"id\":\"b72\",\"matched_paper_id\":1957433},\"end\":127329,\"start\":126817},{\"attributes\":{\"id\":\"b73\",\"matched_paper_id\":14502908},\"end\":127667,\"start\":127331},{\"attributes\":{\"doi\":\"arXiv:2004.11198\",\"id\":\"b74\"},\"end\":128037,\"start\":127669},{\"attributes\":{\"id\":\"b75\",\"matched_paper_id\":46929424},\"end\":128558,\"start\":128039},{\"attributes\":{\"doi\":\"arXiv:2002.09405\",\"id\":\"b76\"},\"end\":128948,\"start\":128560},{\"attributes\":{\"id\":\"b77\",\"matched_paper_id\":206756462},\"end\":129238,\"start\":128950},{\"attributes\":{\"id\":\"b78\",\"matched_paper_id\":5458500},\"end\":129669,\"start\":129240},{\"attributes\":{\"id\":\"b79\",\"matched_paper_id\":199491456},\"end\":130039,\"start\":129671},{\"attributes\":{\"id\":\"b80\",\"matched_paper_id\":203610479},\"end\":130407,\"start\":130041},{\"attributes\":{\"id\":\"b81\",\"matched_paper_id\":6925519},\"end\":130876,\"start\":130409},{\"attributes\":{\"doi\":\"arXiv:2008.05000\",\"id\":\"b82\"},\"end\":131207,\"start\":130878},{\"attributes\":{\"id\":\"b83\",\"matched_paper_id\":247158476},\"end\":131551,\"start\":131209},{\"attributes\":{\"id\":\"b84\",\"matched_paper_id\":232404749},\"end\":131908,\"start\":131553},{\"attributes\":{\"id\":\"b85\",\"matched_paper_id\":13756489},\"end\":132337,\"start\":131910},{\"attributes\":{\"id\":\"b86\"},\"end\":132704,\"start\":132339},{\"attributes\":{\"id\":\"b87\"},\"end\":132991,\"start\":132706},{\"attributes\":{\"id\":\"b88\",\"matched_paper_id\":5692837},\"end\":133256,\"start\":132993},{\"attributes\":{\"id\":\"b89\",\"matched_paper_id\":3264198},\"end\":133446,\"start\":133258},{\"attributes\":{\"id\":\"b90\",\"matched_paper_id\":247187735},\"end\":133830,\"start\":133448},{\"attributes\":{\"id\":\"b91\",\"matched_paper_id\":210872675},\"end\":134199,\"start\":133832},{\"attributes\":{\"id\":\"b92\"},\"end\":134914,\"start\":134201},{\"attributes\":{\"id\":\"b93\",\"matched_paper_id\":54443545},\"end\":135416,\"start\":134916},{\"attributes\":{\"id\":\"b94\",\"matched_paper_id\":247270897},\"end\":135664,\"start\":135418},{\"attributes\":{\"id\":\"b95\"},\"end\":136007,\"start\":135666},{\"attributes\":{\"doi\":\"arXiv:1806.03536\",\"id\":\"b96\"},\"end\":136411,\"start\":136009},{\"attributes\":{\"id\":\"b97\",\"matched_paper_id\":52895589},\"end\":136724,\"start\":136413},{\"attributes\":{\"id\":\"b98\",\"matched_paper_id\":235376852},\"end\":137176,\"start\":136726},{\"attributes\":{\"id\":\"b99\",\"matched_paper_id\":46949657},\"end\":137805,\"start\":137178},{\"attributes\":{\"id\":\"b100\",\"matched_paper_id\":174800449},\"end\":138062,\"start\":137807},{\"attributes\":{\"doi\":\"arXiv:2102.10338\",\"id\":\"b101\"},\"end\":138434,\"start\":138064},{\"attributes\":{\"id\":\"b102\"},\"end\":138713,\"start\":138436},{\"attributes\":{\"id\":\"b103\",\"matched_paper_id\":219636286},\"end\":139138,\"start\":138715}]", "bib_title": "[{\"end\":101023,\"start\":100955},{\"end\":101300,\"start\":101236},{\"end\":102482,\"start\":102412},{\"end\":102860,\"start\":102834},{\"end\":103283,\"start\":103211},{\"end\":104346,\"start\":104269},{\"end\":104984,\"start\":104922},{\"end\":106447,\"start\":106393},{\"end\":106759,\"start\":106670},{\"end\":107185,\"start\":107094},{\"end\":107786,\"start\":107736},{\"end\":108485,\"start\":108407},{\"end\":108881,\"start\":108821},{\"end\":109259,\"start\":109208},{\"end\":109510,\"start\":109454},{\"end\":110225,\"start\":110157},{\"end\":110717,\"start\":110676},{\"end\":111334,\"start\":111277},{\"end\":111643,\"start\":111601},{\"end\":112012,\"start\":111968},{\"end\":112580,\"start\":112475},{\"end\":113081,\"start\":113032},{\"end\":113397,\"start\":113353},{\"end\":113773,\"start\":113708},{\"end\":114014,\"start\":113953},{\"end\":115166,\"start\":115115},{\"end\":116740,\"start\":116662},{\"end\":117080,\"start\":117022},{\"end\":117683,\"start\":117619},{\"end\":118294,\"start\":118252},{\"end\":118599,\"start\":118546},{\"end\":119014,\"start\":118951},{\"end\":119704,\"start\":119649},{\"end\":120398,\"start\":120322},{\"end\":120907,\"start\":120852},{\"end\":121498,\"start\":121433},{\"end\":122007,\"start\":121975},{\"end\":122662,\"start\":122621},{\"end\":123231,\"start\":123188},{\"end\":123867,\"start\":123795},{\"end\":124418,\"start\":124348},{\"end\":125170,\"start\":125104},{\"end\":125737,\"start\":125693},{\"end\":126862,\"start\":126817},{\"end\":127389,\"start\":127331},{\"end\":128108,\"start\":128039},{\"end\":128980,\"start\":128950},{\"end\":129298,\"start\":129240},{\"end\":129775,\"start\":129671},{\"end\":130120,\"start\":130041},{\"end\":130463,\"start\":130409},{\"end\":131254,\"start\":131209},{\"end\":131616,\"start\":131553},{\"end\":131935,\"start\":131910},{\"end\":133009,\"start\":132993},{\"end\":133291,\"start\":133258},{\"end\":133530,\"start\":133448},{\"end\":133885,\"start\":133832},{\"end\":134974,\"start\":134916},{\"end\":135481,\"start\":135418},{\"end\":136452,\"start\":136413},{\"end\":136788,\"start\":136726},{\"end\":137247,\"start\":137178},{\"end\":137843,\"start\":137807},{\"end\":138791,\"start\":138715}]", "bib_author": "[{\"end\":101040,\"start\":101025},{\"end\":101324,\"start\":101302},{\"end\":101336,\"start\":101324},{\"end\":101349,\"start\":101336},{\"end\":101366,\"start\":101349},{\"end\":101378,\"start\":101366},{\"end\":101396,\"start\":101378},{\"end\":101721,\"start\":101704},{\"end\":101735,\"start\":101721},{\"end\":101750,\"start\":101735},{\"end\":101764,\"start\":101750},{\"end\":101891,\"start\":101877},{\"end\":101909,\"start\":101891},{\"end\":101928,\"start\":101909},{\"end\":102191,\"start\":102173},{\"end\":102206,\"start\":102191},{\"end\":102221,\"start\":102206},{\"end\":102501,\"start\":102484},{\"end\":102517,\"start\":102501},{\"end\":102530,\"start\":102517},{\"end\":102554,\"start\":102530},{\"end\":102880,\"start\":102862},{\"end\":102894,\"start\":102880},{\"end\":102914,\"start\":102894},{\"end\":102929,\"start\":102914},{\"end\":102945,\"start\":102929},{\"end\":102957,\"start\":102945},{\"end\":103301,\"start\":103285},{\"end\":103316,\"start\":103301},{\"end\":103588,\"start\":103573},{\"end\":103601,\"start\":103588},{\"end\":103619,\"start\":103601},{\"end\":103842,\"start\":103821},{\"end\":103859,\"start\":103842},{\"end\":103870,\"start\":103859},{\"end\":103898,\"start\":103870},{\"end\":103908,\"start\":103898},{\"end\":103930,\"start\":103908},{\"end\":103958,\"start\":103930},{\"end\":103965,\"start\":103958},{\"end\":104367,\"start\":104348},{\"end\":104384,\"start\":104367},{\"end\":104396,\"start\":104384},{\"end\":104415,\"start\":104396},{\"end\":104426,\"start\":104415},{\"end\":104739,\"start\":104723},{\"end\":104755,\"start\":104739},{\"end\":105002,\"start\":104986},{\"end\":105018,\"start\":105002},{\"end\":105343,\"start\":105324},{\"end\":105513,\"start\":105501},{\"end\":105531,\"start\":105513},{\"end\":105545,\"start\":105531},{\"end\":105557,\"start\":105545},{\"end\":105871,\"start\":105859},{\"end\":105882,\"start\":105871},{\"end\":105897,\"start\":105882},{\"end\":105912,\"start\":105897},{\"end\":105925,\"start\":105912},{\"end\":105941,\"start\":105925},{\"end\":106244,\"start\":106233},{\"end\":106255,\"start\":106244},{\"end\":106267,\"start\":106255},{\"end\":106461,\"start\":106449},{\"end\":106471,\"start\":106461},{\"end\":106484,\"start\":106471},{\"end\":106499,\"start\":106484},{\"end\":106510,\"start\":106499},{\"end\":106776,\"start\":106761},{\"end\":106792,\"start\":106776},{\"end\":106802,\"start\":106792},{\"end\":106814,\"start\":106802},{\"end\":107203,\"start\":107187},{\"end\":107217,\"start\":107203},{\"end\":107224,\"start\":107217},{\"end\":107233,\"start\":107224},{\"end\":107246,\"start\":107233},{\"end\":107261,\"start\":107246},{\"end\":107804,\"start\":107788},{\"end\":107820,\"start\":107804},{\"end\":107838,\"start\":107820},{\"end\":107850,\"start\":107838},{\"end\":107868,\"start\":107850},{\"end\":108199,\"start\":108178},{\"end\":108209,\"start\":108199},{\"end\":108228,\"start\":108209},{\"end\":108232,\"start\":108228},{\"end\":108507,\"start\":108487},{\"end\":108523,\"start\":108507},{\"end\":108545,\"start\":108523},{\"end\":108893,\"start\":108883},{\"end\":108909,\"start\":108893},{\"end\":108925,\"start\":108909},{\"end\":108932,\"start\":108925},{\"end\":109269,\"start\":109261},{\"end\":109277,\"start\":109269},{\"end\":109287,\"start\":109277},{\"end\":109296,\"start\":109287},{\"end\":109302,\"start\":109296},{\"end\":109313,\"start\":109302},{\"end\":109534,\"start\":109512},{\"end\":109548,\"start\":109534},{\"end\":109560,\"start\":109548},{\"end\":109574,\"start\":109560},{\"end\":109587,\"start\":109574},{\"end\":109599,\"start\":109587},{\"end\":109615,\"start\":109599},{\"end\":109629,\"start\":109615},{\"end\":109642,\"start\":109629},{\"end\":109659,\"start\":109642},{\"end\":110252,\"start\":110227},{\"end\":110269,\"start\":110252},{\"end\":110290,\"start\":110269},{\"end\":110309,\"start\":110290},{\"end\":110322,\"start\":110309},{\"end\":110343,\"start\":110322},{\"end\":110350,\"start\":110343},{\"end\":110730,\"start\":110719},{\"end\":110746,\"start\":110730},{\"end\":110760,\"start\":110746},{\"end\":110777,\"start\":110760},{\"end\":110788,\"start\":110777},{\"end\":111090,\"start\":111073},{\"end\":111103,\"start\":111090},{\"end\":111118,\"start\":111103},{\"end\":111135,\"start\":111118},{\"end\":111350,\"start\":111336},{\"end\":111368,\"start\":111350},{\"end\":111663,\"start\":111645},{\"end\":111679,\"start\":111663},{\"end\":111690,\"start\":111679},{\"end\":111706,\"start\":111690},{\"end\":112029,\"start\":112014},{\"end\":112039,\"start\":112029},{\"end\":112051,\"start\":112039},{\"end\":112062,\"start\":112051},{\"end\":112075,\"start\":112062},{\"end\":112093,\"start\":112075},{\"end\":112099,\"start\":112093},{\"end\":112601,\"start\":112582},{\"end\":112618,\"start\":112601},{\"end\":112632,\"start\":112618},{\"end\":112648,\"start\":112632},{\"end\":112668,\"start\":112648},{\"end\":112690,\"start\":112668},{\"end\":112712,\"start\":112690},{\"end\":112728,\"start\":112712},{\"end\":113098,\"start\":113083},{\"end\":113111,\"start\":113098},{\"end\":113126,\"start\":113111},{\"end\":113411,\"start\":113399},{\"end\":113426,\"start\":113411},{\"end\":113440,\"start\":113426},{\"end\":113450,\"start\":113440},{\"end\":113786,\"start\":113775},{\"end\":113804,\"start\":113786},{\"end\":114027,\"start\":114016},{\"end\":114041,\"start\":114027},{\"end\":114057,\"start\":114041},{\"end\":114070,\"start\":114057},{\"end\":114082,\"start\":114070},{\"end\":114093,\"start\":114082},{\"end\":114110,\"start\":114093},{\"end\":114125,\"start\":114110},{\"end\":114503,\"start\":114492},{\"end\":114517,\"start\":114503},{\"end\":114529,\"start\":114517},{\"end\":114542,\"start\":114529},{\"end\":114555,\"start\":114542},{\"end\":114570,\"start\":114555},{\"end\":114896,\"start\":114882},{\"end\":114915,\"start\":114896},{\"end\":115176,\"start\":115168},{\"end\":115190,\"start\":115176},{\"end\":115200,\"start\":115190},{\"end\":115211,\"start\":115200},{\"end\":115228,\"start\":115211},{\"end\":115244,\"start\":115228},{\"end\":115253,\"start\":115244},{\"end\":115585,\"start\":115573},{\"end\":115595,\"start\":115585},{\"end\":115605,\"start\":115595},{\"end\":115618,\"start\":115605},{\"end\":115633,\"start\":115618},{\"end\":115645,\"start\":115633},{\"end\":115937,\"start\":115924},{\"end\":115954,\"start\":115937},{\"end\":115970,\"start\":115954},{\"end\":116231,\"start\":116214},{\"end\":116410,\"start\":116397},{\"end\":116424,\"start\":116410},{\"end\":116440,\"start\":116424},{\"end\":116449,\"start\":116440},{\"end\":116755,\"start\":116742},{\"end\":116770,\"start\":116755},{\"end\":116792,\"start\":116770},{\"end\":116809,\"start\":116792},{\"end\":116818,\"start\":116809},{\"end\":117096,\"start\":117082},{\"end\":117108,\"start\":117096},{\"end\":117120,\"start\":117108},{\"end\":117136,\"start\":117120},{\"end\":117145,\"start\":117136},{\"end\":117457,\"start\":117445},{\"end\":117471,\"start\":117457},{\"end\":117475,\"start\":117471},{\"end\":117695,\"start\":117685},{\"end\":117705,\"start\":117695},{\"end\":117714,\"start\":117705},{\"end\":118027,\"start\":118012},{\"end\":118037,\"start\":118027},{\"end\":118055,\"start\":118037},{\"end\":118061,\"start\":118055},{\"end\":118309,\"start\":118296},{\"end\":118329,\"start\":118309},{\"end\":118338,\"start\":118329},{\"end\":118616,\"start\":118601},{\"end\":118634,\"start\":118616},{\"end\":118649,\"start\":118634},{\"end\":118669,\"start\":118649},{\"end\":118687,\"start\":118669},{\"end\":119033,\"start\":119016},{\"end\":119049,\"start\":119033},{\"end\":119068,\"start\":119049},{\"end\":119533,\"start\":119521},{\"end\":119548,\"start\":119533},{\"end\":119718,\"start\":119706},{\"end\":119731,\"start\":119718},{\"end\":119746,\"start\":119731},{\"end\":119763,\"start\":119746},{\"end\":120061,\"start\":120053},{\"end\":120075,\"start\":120061},{\"end\":120089,\"start\":120075},{\"end\":120104,\"start\":120089},{\"end\":120411,\"start\":120400},{\"end\":120434,\"start\":120411},{\"end\":120449,\"start\":120434},{\"end\":120461,\"start\":120449},{\"end\":120473,\"start\":120461},{\"end\":120487,\"start\":120473},{\"end\":120505,\"start\":120487},{\"end\":120925,\"start\":120909},{\"end\":121183,\"start\":121165},{\"end\":121192,\"start\":121183},{\"end\":121204,\"start\":121192},{\"end\":121516,\"start\":121500},{\"end\":121777,\"start\":121757},{\"end\":121789,\"start\":121777},{\"end\":122028,\"start\":122009},{\"end\":122044,\"start\":122028},{\"end\":122062,\"start\":122044},{\"end\":122070,\"start\":122062},{\"end\":122318,\"start\":122299},{\"end\":122328,\"start\":122318},{\"end\":122678,\"start\":122664},{\"end\":122692,\"start\":122678},{\"end\":122706,\"start\":122692},{\"end\":122720,\"start\":122706},{\"end\":123002,\"start\":122987},{\"end\":123019,\"start\":123002},{\"end\":123249,\"start\":123233},{\"end\":123263,\"start\":123249},{\"end\":123277,\"start\":123263},{\"end\":123563,\"start\":123546},{\"end\":123577,\"start\":123563},{\"end\":123593,\"start\":123577},{\"end\":123608,\"start\":123593},{\"end\":123885,\"start\":123869},{\"end\":123902,\"start\":123885},{\"end\":123918,\"start\":123902},{\"end\":123935,\"start\":123918},{\"end\":123948,\"start\":123935},{\"end\":123969,\"start\":123948},{\"end\":124436,\"start\":124420},{\"end\":124455,\"start\":124436},{\"end\":124471,\"start\":124455},{\"end\":124811,\"start\":124795},{\"end\":124828,\"start\":124811},{\"end\":124843,\"start\":124828},{\"end\":124858,\"start\":124843},{\"end\":124879,\"start\":124858},{\"end\":125192,\"start\":125172},{\"end\":125208,\"start\":125192},{\"end\":125222,\"start\":125208},{\"end\":125233,\"start\":125222},{\"end\":125252,\"start\":125233},{\"end\":125268,\"start\":125252},{\"end\":125283,\"start\":125268},{\"end\":125290,\"start\":125283},{\"end\":125752,\"start\":125739},{\"end\":125780,\"start\":125752},{\"end\":125793,\"start\":125780},{\"end\":125808,\"start\":125793},{\"end\":126061,\"start\":126048},{\"end\":126072,\"start\":126061},{\"end\":126089,\"start\":126072},{\"end\":126101,\"start\":126089},{\"end\":126117,\"start\":126101},{\"end\":126133,\"start\":126117},{\"end\":126149,\"start\":126133},{\"end\":126161,\"start\":126149},{\"end\":126181,\"start\":126161},{\"end\":126194,\"start\":126181},{\"end\":126211,\"start\":126194},{\"end\":126225,\"start\":126211},{\"end\":126238,\"start\":126225},{\"end\":126251,\"start\":126238},{\"end\":126266,\"start\":126251},{\"end\":126282,\"start\":126266},{\"end\":126303,\"start\":126282},{\"end\":126319,\"start\":126303},{\"end\":126328,\"start\":126319},{\"end\":126340,\"start\":126328},{\"end\":126358,\"start\":126340},{\"end\":126884,\"start\":126864},{\"end\":126900,\"start\":126884},{\"end\":126923,\"start\":126900},{\"end\":127406,\"start\":127391},{\"end\":127422,\"start\":127406},{\"end\":127685,\"start\":127669},{\"end\":127702,\"start\":127685},{\"end\":127719,\"start\":127702},{\"end\":127734,\"start\":127719},{\"end\":127753,\"start\":127734},{\"end\":127769,\"start\":127753},{\"end\":128135,\"start\":128110},{\"end\":128150,\"start\":128135},{\"end\":128176,\"start\":128150},{\"end\":128188,\"start\":128176},{\"end\":128207,\"start\":128188},{\"end\":128221,\"start\":128207},{\"end\":128238,\"start\":128221},{\"end\":128585,\"start\":128560},{\"end\":128602,\"start\":128585},{\"end\":128616,\"start\":128602},{\"end\":128626,\"start\":128616},{\"end\":128641,\"start\":128626},{\"end\":128660,\"start\":128641},{\"end\":128995,\"start\":128982},{\"end\":129003,\"start\":128995},{\"end\":129011,\"start\":129003},{\"end\":129027,\"start\":129011},{\"end\":129041,\"start\":129027},{\"end\":129323,\"start\":129300},{\"end\":129333,\"start\":129323},{\"end\":129345,\"start\":129333},{\"end\":129359,\"start\":129345},{\"end\":129368,\"start\":129359},{\"end\":129379,\"start\":129368},{\"end\":129390,\"start\":129379},{\"end\":129399,\"start\":129390},{\"end\":129806,\"start\":129777},{\"end\":129823,\"start\":129806},{\"end\":129827,\"start\":129823},{\"end\":130150,\"start\":130122},{\"end\":130165,\"start\":130150},{\"end\":130487,\"start\":130465},{\"end\":130499,\"start\":130487},{\"end\":130956,\"start\":130947},{\"end\":130971,\"start\":130956},{\"end\":131001,\"start\":130971},{\"end\":131007,\"start\":131001},{\"end\":131265,\"start\":131256},{\"end\":131279,\"start\":131265},{\"end\":131294,\"start\":131279},{\"end\":131315,\"start\":131294},{\"end\":131321,\"start\":131315},{\"end\":131634,\"start\":131618},{\"end\":131653,\"start\":131634},{\"end\":131667,\"start\":131653},{\"end\":131953,\"start\":131937},{\"end\":131967,\"start\":131953},{\"end\":131980,\"start\":131967},{\"end\":131997,\"start\":131980},{\"end\":132010,\"start\":131997},{\"end\":132025,\"start\":132010},{\"end\":132040,\"start\":132025},{\"end\":132058,\"start\":132040},{\"end\":132357,\"start\":132339},{\"end\":132375,\"start\":132357},{\"end\":132393,\"start\":132375},{\"end\":132409,\"start\":132393},{\"end\":132421,\"start\":132409},{\"end\":132436,\"start\":132421},{\"end\":132811,\"start\":132795},{\"end\":132827,\"start\":132811},{\"end\":132844,\"start\":132827},{\"end\":133026,\"start\":133011},{\"end\":133043,\"start\":133026},{\"end\":133059,\"start\":133043},{\"end\":133305,\"start\":133293},{\"end\":133315,\"start\":133305},{\"end\":133545,\"start\":133532},{\"end\":133558,\"start\":133545},{\"end\":133571,\"start\":133558},{\"end\":133579,\"start\":133571},{\"end\":133901,\"start\":133887},{\"end\":133915,\"start\":133901},{\"end\":133930,\"start\":133915},{\"end\":133944,\"start\":133930},{\"end\":133957,\"start\":133944},{\"end\":133973,\"start\":133957},{\"end\":134214,\"start\":134201},{\"end\":134226,\"start\":134214},{\"end\":134236,\"start\":134226},{\"end\":134246,\"start\":134236},{\"end\":134254,\"start\":134246},{\"end\":134264,\"start\":134254},{\"end\":134274,\"start\":134264},{\"end\":134288,\"start\":134274},{\"end\":134298,\"start\":134288},{\"end\":134307,\"start\":134298},{\"end\":134320,\"start\":134307},{\"end\":134332,\"start\":134320},{\"end\":134343,\"start\":134332},{\"end\":134355,\"start\":134343},{\"end\":134367,\"start\":134355},{\"end\":134379,\"start\":134367},{\"end\":134398,\"start\":134379},{\"end\":134411,\"start\":134398},{\"end\":134985,\"start\":134976},{\"end\":134999,\"start\":134985},{\"end\":135017,\"start\":134999},{\"end\":135037,\"start\":135017},{\"end\":135056,\"start\":135037},{\"end\":135069,\"start\":135056},{\"end\":135077,\"start\":135069},{\"end\":135097,\"start\":135077},{\"end\":135114,\"start\":135097},{\"end\":135128,\"start\":135114},{\"end\":135138,\"start\":135128},{\"end\":135494,\"start\":135483},{\"end\":135507,\"start\":135494},{\"end\":135809,\"start\":135791},{\"end\":135826,\"start\":135809},{\"end\":136020,\"start\":136009},{\"end\":136033,\"start\":136020},{\"end\":136048,\"start\":136033},{\"end\":136065,\"start\":136048},{\"end\":136089,\"start\":136065},{\"end\":136107,\"start\":136089},{\"end\":136465,\"start\":136454},{\"end\":136476,\"start\":136465},{\"end\":136491,\"start\":136476},{\"end\":136509,\"start\":136491},{\"end\":136806,\"start\":136790},{\"end\":136818,\"start\":136806},{\"end\":136832,\"start\":136818},{\"end\":136846,\"start\":136832},{\"end\":136857,\"start\":136846},{\"end\":136864,\"start\":136857},{\"end\":136878,\"start\":136864},{\"end\":136891,\"start\":136878},{\"end\":137259,\"start\":137249},{\"end\":137271,\"start\":137259},{\"end\":137285,\"start\":137271},{\"end\":137304,\"start\":137285},{\"end\":137315,\"start\":137304},{\"end\":137330,\"start\":137315},{\"end\":137340,\"start\":137330},{\"end\":137858,\"start\":137845},{\"end\":137868,\"start\":137858},{\"end\":137883,\"start\":137868},{\"end\":138177,\"start\":138163},{\"end\":138185,\"start\":138177},{\"end\":138201,\"start\":138185},{\"end\":138213,\"start\":138201},{\"end\":138535,\"start\":138522},{\"end\":138547,\"start\":138535},{\"end\":138559,\"start\":138547},{\"end\":138570,\"start\":138559},{\"end\":138808,\"start\":138793},{\"end\":138820,\"start\":138808},{\"end\":138832,\"start\":138820},{\"end\":138845,\"start\":138832},{\"end\":138855,\"start\":138845},{\"end\":138863,\"start\":138855}]", "bib_venue": "[{\"end\":101080,\"start\":101040},{\"end\":101443,\"start\":101405},{\"end\":101783,\"start\":101764},{\"end\":101982,\"start\":101928},{\"end\":102171,\"start\":102102},{\"end\":102603,\"start\":102554},{\"end\":103001,\"start\":102957},{\"end\":103334,\"start\":103316},{\"end\":103571,\"start\":103491},{\"end\":104022,\"start\":103981},{\"end\":104488,\"start\":104426},{\"end\":105080,\"start\":105018},{\"end\":105322,\"start\":105255},{\"end\":105630,\"start\":105572},{\"end\":105857,\"start\":105805},{\"end\":106231,\"start\":106153},{\"end\":106524,\"start\":106510},{\"end\":106863,\"start\":106814},{\"end\":107357,\"start\":107261},{\"end\":107917,\"start\":107868},{\"end\":108176,\"start\":108131},{\"end\":108594,\"start\":108545},{\"end\":108999,\"start\":108932},{\"end\":109319,\"start\":109313},{\"end\":109749,\"start\":109659},{\"end\":110399,\"start\":110350},{\"end\":110832,\"start\":110788},{\"end\":111071,\"start\":111004},{\"end\":111432,\"start\":111368},{\"end\":111768,\"start\":111706},{\"end\":112167,\"start\":112099},{\"end\":112738,\"start\":112728},{\"end\":113175,\"start\":113126},{\"end\":113519,\"start\":113450},{\"end\":113823,\"start\":113818},{\"end\":114174,\"start\":114125},{\"end\":114490,\"start\":114428},{\"end\":114880,\"start\":114788},{\"end\":115297,\"start\":115253},{\"end\":115571,\"start\":115512},{\"end\":115922,\"start\":115854},{\"end\":116212,\"start\":116160},{\"end\":116395,\"start\":116309},{\"end\":116829,\"start\":116818},{\"end\":117194,\"start\":117145},{\"end\":117443,\"start\":117401},{\"end\":117772,\"start\":117714},{\"end\":118010,\"start\":117943},{\"end\":118390,\"start\":118338},{\"end\":118736,\"start\":118687},{\"end\":119185,\"start\":119068},{\"end\":119519,\"start\":119461},{\"end\":119786,\"start\":119763},{\"end\":120051,\"start\":119960},{\"end\":120578,\"start\":120505},{\"end\":120977,\"start\":120925},{\"end\":121276,\"start\":121220},{\"end\":121536,\"start\":121525},{\"end\":121755,\"start\":121676},{\"end\":122119,\"start\":122070},{\"end\":122454,\"start\":122328},{\"end\":122764,\"start\":122720},{\"end\":122985,\"start\":122923},{\"end\":123326,\"start\":123277},{\"end\":123544,\"start\":123495},{\"end\":124055,\"start\":123990},{\"end\":124520,\"start\":124471},{\"end\":124793,\"start\":124728},{\"end\":125351,\"start\":125290},{\"end\":125852,\"start\":125808},{\"end\":127017,\"start\":126923},{\"end\":127484,\"start\":127422},{\"end\":127831,\"start\":127785},{\"end\":128282,\"start\":128238},{\"end\":128732,\"start\":128676},{\"end\":129077,\"start\":129041},{\"end\":129431,\"start\":129399},{\"end\":129842,\"start\":129827},{\"end\":130217,\"start\":130165},{\"end\":130548,\"start\":130499},{\"end\":130945,\"start\":130878},{\"end\":131373,\"start\":131321},{\"end\":131724,\"start\":131667},{\"end\":132107,\"start\":132058},{\"end\":132514,\"start\":132436},{\"end\":132793,\"start\":132706},{\"end\":133108,\"start\":133059},{\"end\":133339,\"start\":133315},{\"end\":133631,\"start\":133579},{\"end\":134001,\"start\":133973},{\"end\":134551,\"start\":134411},{\"end\":135152,\"start\":135138},{\"end\":135529,\"start\":135507},{\"end\":135789,\"start\":135666},{\"end\":136188,\"start\":136123},{\"end\":136561,\"start\":136509},{\"end\":136940,\"start\":136891},{\"end\":137436,\"start\":137340},{\"end\":137927,\"start\":137883},{\"end\":138161,\"start\":138064},{\"end\":138520,\"start\":138436},{\"end\":138912,\"start\":138863},{\"end\":107440,\"start\":107359},{\"end\":109826,\"start\":109751},{\"end\":112222,\"start\":112169},{\"end\":125399,\"start\":125353},{\"end\":127098,\"start\":127019},{\"end\":137519,\"start\":137438}]"}}}, "year": 2023, "month": 12, "day": 17}