{"id": 207847663, "updated": "2023-10-06 21:33:08.652", "metadata": {"title": "ERASER: A Benchmark to Evaluate Rationalized NLP Models", "authors": "[{\"first\":\"Jay\",\"last\":\"DeYoung\",\"middle\":[]},{\"first\":\"Sarthak\",\"last\":\"Jain\",\"middle\":[]},{\"first\":\"Nazneen Fatema\",\"last\":\"Rajani\",\"middle\":[]},{\"first\":\"Eric\",\"last\":\"Lehman\",\"middle\":[]},{\"first\":\"Caiming\",\"last\":\"Xiong\",\"middle\":[]},{\"first\":\"Richard\",\"last\":\"Socher\",\"middle\":[]},{\"first\":\"Byron C.\",\"last\":\"Wallace\",\"middle\":[]}]", "venue": "ACL", "journal": "Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics", "publication_date": {"year": 2020, "month": null, "day": null}, "abstract": "State-of-the-art models in NLP are now predominantly based on deep neural networks that are opaque in terms of how they come to make predictions. This limitation has increased interest in designing more interpretable deep models for NLP that reveal the \u2018reasoning\u2019 behind model outputs. But work in this direction has been conducted on different datasets and tasks with correspondingly unique aims and metrics; this makes it difficult to track progress. We propose the Evaluating Rationales And Simple English Reasoning (ERASER a benchmark to advance research on interpretable models in NLP. This benchmark comprises multiple datasets and tasks for which human annotations of \u201crationales\u201d (supporting evidence) have been collected. We propose several metrics that aim to capture how well the rationales provided by models align with human rationales, and also how faithful these rationales are (i.e., the degree to which provided rationales influenced the corresponding predictions). Our hope is that releasing this benchmark facilitates progress on designing more interpretable NLP systems. The benchmark, code, and documentation are available at https://www.eraserbenchmark.com/", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "1911.03429", "mag": "3035503910", "acl": "2020.acl-main.408", "pubmed": null, "pubmedcentral": null, "dblp": "conf/acl/DeYoungJRLXSW20", "doi": "10.18653/v1/2020.acl-main.408"}}, "content": {"source": {"pdf_hash": "5cca704b6b30081dbbc4acf79e254a35e5e14b84", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/1911.03429v2.pdf\"]", "oa_url_match": false, "oa_info": {"license": "CCBY", "open_access_url": "https://www.aclweb.org/anthology/2020.acl-main.408.pdf", "status": "HYBRID"}}, "grobid": {"id": "788868e90a21c82bda8ce24a674cd12f391d11c9", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/5cca704b6b30081dbbc4acf79e254a35e5e14b84.txt", "contents": "\nERASER: A Benchmark to Evaluate Rationalized NLP Models\n\n\n\u22c6\u03a8Jay Deyoung \nEqual contribution. \u03a8 Khoury College of Computer Sciences\nNortheastern University \u03a6 Salesforce Research\n94301Palo AltoCA\n\nSarthakJain \u22c6\u03c8 \nEqual contribution. \u03a8 Khoury College of Computer Sciences\nNortheastern University \u03a6 Salesforce Research\n94301Palo AltoCA\n\nNazneen Fatema \nEqual contribution. \u03a8 Khoury College of Computer Sciences\nNortheastern University \u03a6 Salesforce Research\n94301Palo AltoCA\n\nRajani \u22c6\u03c6 \nEqual contribution. \u03a8 Khoury College of Computer Sciences\nNortheastern University \u03a6 Salesforce Research\n94301Palo AltoCA\n\nEric Lehman \nEqual contribution. \u03a8 Khoury College of Computer Sciences\nNortheastern University \u03a6 Salesforce Research\n94301Palo AltoCA\n\nCaiming Xiong \nEqual contribution. \u03a8 Khoury College of Computer Sciences\nNortheastern University \u03a6 Salesforce Research\n94301Palo AltoCA\n\n\u03a6 \nEqual contribution. \u03a8 Khoury College of Computer Sciences\nNortheastern University \u03a6 Salesforce Research\n94301Palo AltoCA\n\nRichard Socher \nEqual contribution. \u03a8 Khoury College of Computer Sciences\nNortheastern University \u03a6 Salesforce Research\n94301Palo AltoCA\n\nByron C Wallace \nEqual contribution. \u03a8 Khoury College of Computer Sciences\nNortheastern University \u03a6 Salesforce Research\n94301Palo AltoCA\n\nERASER: A Benchmark to Evaluate Rationalized NLP Models\n\nState-of-the-art models in NLP are now predominantly based on deep neural networks that are generally opaque in terms of how they come to specific predictions. This limitation has led to increased interest in designing more interpretable deep models for NLP that can reveal the 'reasoning' underlying model outputs. But work in this direction has been conducted on different datasets and tasks with correspondingly unique aims and metrics; this makes it difficult to track progress.We propose the Evaluating Rationales And Simple English Reasoning (ERASER) benchmark to advance research on interpretable models in NLP. This benchmark comprises multiple datasets and tasks for which human annotations of \"rationales\" (supporting evidence) have been collected. We propose several metrics that aim to capture how well the rationales provided by models align with human rationales, and also how faithful these rationales are (i.e., the degree to which provided rationales influenced the corresponding predictions). Our hope is that releasing this benchmark facilitates progress on designing more interpretable NLP systems. The benchmark, code, and documentation are available at: www.eraserbenchmark.com.\n\nIntroduction\n\nInterest has recently grown in interpretable NLP systems that can reveal how and why models make their predictions. But work in this direction has been conducted on different datasets with correspondingly different metrics, and the inherent subjectivity in defining what constitutes 'interpretability' has translated into researchers using different metrics to quantify performance. We aim to facilitate measurable progress on designing interpretable NLP models by releasing a standardized benchmark of datasets -augmented and repurposed\n\n\nCommonsense Explanations (CoS-E)\n\nWhere do you find the most amount of leafs?\n\n\n(a) Compost pile (b) Flowers (c) Forest (d) Field (e) Ground\n\n\nMovie Reviews\n\nIn this movie, \u2026 Plots to take over the world. The acting is great! The soundtrack is run-of-the-mill, but the action more than makes up for it (a) Positive (b) Negative\n\n\nEvidence Inference\n\nArticle Patients for this trial were recruited \u2026 Compared with 0.9% saline, 120 mg of inhaled nebulized furosemide had no effect on breathlessness during exercise.  from pre-existing corpora, and spanning a range of NLP tasks -and associated metrics for measuring the quality of rationales. We refer to this as the Evaluating Rationales And Simple English Reasoning (ERASER) benchmark.\n\nIn curating and releasing ERASER we take inspiration from the stickiness of the GLUE (Wang et al., 2019b) and SuperGLUE (Wang et al., 2019a) benchmarks for evaluating progress in natural language understanding tasks. These have enabled rapid progress on models for general language representation learning. We believe the still somewhat nascent subfield of interpretable NLP stands to similarly benefit from an analogous collection of standardized datasets/tasks and metrics.\n\n'Interpretability' is a broad topic with many possible realizations (Doshi-Velez and Kim, 2017;Lipton, 2016). In ERASER we focus specifically on rationales, i.e., snippets of text from a source doc-ument that support a particular categorization. All datasets contained in ERASER include such rationales, explicitly marked by annotators as supporting particular categorizations. By definition rationales should be sufficient to categorize documents, but they may not be comprehensive. Therefore, for some datasets we have collected comprehensive rationales, i.e., in which all evidence supporting a classification has been marked.\n\nHow one measures the 'quality' of extracted rationales will invariably depend on their intended use. With this in mind, we propose a suite of metrics to evaluate rationales that might be appropriate for different scenarios. Broadly, this includes measures of agreement with human-provided rationales, and assessments of faithfulness. The latter aim to capture the extent to which rationales provided by a model in fact informed its predictions.\n\nWhile we propose metrics that we think are reasonable, we view the problem of designing metrics for evaluating rationales -especially for capturing faithfulness -as a topic for further research that we hope that ERASER will help facilitate. We plan to revisit the metrics proposed here in future iterations of the benchmark, ideally with input from the community. Notably, while we provide a 'leaderboard', this is perhaps better viewed as a 'results board'; we do not privilege any one particular metric. Instead, we hope that ERASER permits comparison between models that provide rationales with respect to different criteria of interest.\n\nWe provide baseline models and report their performance across the corpora in ERASER. While implementing and initially evaluating these baselines, we found that no single 'off-the-shelf' architecture was readily adaptable to datasets with very different average input lengths and associated rationale snippets. This suggests a need for the development of new models capable of consuming potentially lengthy input documents and adaptively providing rationales at the level of granularity appropriate for a given task. ERASER provides a resource to develop such models, as it comprises datasets with a wide range of input text and rationale lengths (Section 4).\n\nIn sum, we introduce the ERASER benchmark (www.eraserbenchmark.com), a unified set of diverse NLP datasets (repurposed from existing corpora, including sentiment analysis, Natural Language Inference, and Question Answering tasks, among others) in a standardized format featuring human rationales for decisions, along with the starter code and tools, baseline models, and standardized metrics for rationales.\n\n\nDesiderata for Rationales\n\nIn this section we discuss properties that might be desirable in rationales, and the metrics we propose to quantify these (for evaluation). We attempt to operationalize these criteria formally in Section 5.\n\nAs one simple metric, we can assess the degree to which the rationales extracted by a model agree with those highlighted by human annotators. To measure exact and partial match, we propose adopting metrics from named entity recognition (NER) and object detection. In addition, we consider more granular ranking metrics that account for the individual weights assigned to tokens (when models assign such token-level scores, that is).\n\nOne distinction to make when evaluating rationales is the degree to which explanation for predictions is desired. In some cases it may be important that rationales tell us why a model made the prediction that it did, i.e., that rationales are faithful. In other settings, we may be satisfied with \"plausible\" rationales, even if these are not faithful.\n\nAnother key consideration is whether one wants rationales that are comprehensive, rather than simply sufficient. A comprehensive set of rationales comprises all snippets that support a given label. Put another way, if we remove a comprehensive set of rationales from an instance, there should be no way to categorize it (Yu et al., 2019). ERASER permits evaluation of comprehensiveness by including exhaustive annotated rationales that we have collected for some of datasets in the benchmark.\n\n\nRelated Work\n\nInterpretability in NLP is a large and fast-growing area, and we do not attempt to provide a comprehensive overview here. Instead, we focus on directions particularly relevant to ERASER, i.e., prior work on models that provide rationales for their predictions.\n\nLearning to Explain. In ERASER we assume that rationales (marked by humans) are provided during training. However, models will of course not always have access to such direct supervision. This has motivated work on methods that can explain (or \"rationalize\") model predictions using only instance-level supervision.\n\nIn the context of modern neural models for text classification, one might use variants of attention  to extract rationales. Attention mechanisms learn to assign soft weights to (usually contextualized) token representations, and so one can extract highly weighted tokens as rationales. However, attention weights do not in general provide faithful explanations for predictions (Jain and Wallace, 2019;Serrano and Smith, 2019;Wiegreffe and Pinter, 2019;Zhong et al., 2019;Pruthi et al., 2019;Brunner et al., 2019;Moradi et al., 2019;Vashishth et al., 2019). This likely owes to encoders entangling inputs, which complicates the interpretation of attention weights over contextualized representations. In some cases, however, faithfulness may not be a primary concern. 1 By contrast, hard attention mechanisms discretely extract snippets from the input to pass to the classifier, and so by construction provide a sort of faithfulness in their explanations. Recent work has therefore pursued hard attention mechanisms as a means of providing explanations (Lei et al., 2016;Yu et al., 2019). Lei et al. (2016) proposed instantiating two models with their own parameters; an encoder to extract rationales, and a decoder that consumes the snippets it selects to make a prediction. They trained these models jointly. This is complicated by the discrete snippet selection performed by the encoder, which precludes gradientbased parameter estimation. They instead propose adopting a REINFORCE (Williams, 1992) style optimization technique.\n\nPost-hoc explanation. Another strand of work in the interpretability literature considers post-hoc explanation methods. Such methods seek to explain why a given model made its prediction on a given input, most commonly in form of token level importance scores. Many of these methods rely on differentiability of the output with respect to inputs (Sundararajan et al., 2017;Smilkov et al., 2017). These types of explanations often have clear inherent semantics (e.g., simple gradients tell us exactly how perturbing inputs affects outputs), but they may nonetheless be difficult for humans to understand due to counterintuitive behaviors (Feng et al., 2018). 1 Interestingly, (Zhong et al., 2019) report that attention provides plausible but not faithful (explanatory) rationales. In other related work, Pruthi et al. (2019) show that one can easily learn to deceive using attention weights. These findings further highlight that one should be mindful of what criteria one wants rationales to fulfill.\n\nAnother class of 'black-box' methods do not require any specific conditions on models. Examples include LIME (Ribeiro et al., 2016) and Alvarez-Melis and Jaakkola (2017); these methods approximate model behavior locally by repeatedly asking model to make predictions over perturbed inputs and fitting a explainable low complexity model over these predictions.\n\nAcquiring rationales. In addition to potentially providing model transparency, collecting rationales from annotators may afford greater efficiency in terms of model performance realized given a fixed amount of annotator effort (Zaidan and Eisner, 2008). In particular, recent work McDonnell et al. (2017McDonnell et al. ( , 2016 has observed that at least for some tasks, asking annotators to provide rationales justifying their categorizations does not impose much overhead, in terms of effort.\n\nActive learning (AL) (Settles, 2012) is a complementary strategy for reducing annotator effort that entails the model selecting the examples with which it is to be trained. Sharma et al. (2015) explored actively collecting both instance labels and supporting rationales. Their work suggests that selecting instances via an acquisition function specifically designed for learning with rationales can provide predictive gains over standard AL methods. A limitation of this work is that they relied on simulated rationales, for want of access to datasets with marked rationales; a gap that our work addresses.\n\nLearning from Rationales. Work on learning from rationales that have been explicitly provided by users for text classification dates back over a decade (Zaidan et al., 2007;Zaidan and Eisner, 2008). Earlier efforts proposed extending standard discriminative models like Support Vector Machines (SVMs) with regularization terms that penalized parameter estimates which disagreed with provided rationales (Zaidan et al., 2007;Small et al., 2011). Other efforts have attempted to specify generative models of rationales (Zaidan and Eisner, 2008).\n\nMore recent work has looked to exploit rationales in training neural text classification models. For example, Zhang et al. (2016) proposed a rationale-augmented Convolutional Neural Network (CNN) for text classification, explicitly trained to identify sentences supporting document categorizations. Strout et al. (2019) have demonstrated that providing this model with target ra-tionales at train time results in the model providing rationales at test time that are preferred by humans (compared to rationales provided when the model learns to weight sentences in an end-to-end fashion). Other recent work has proposed training 'pipeline' models in which one model learns to extract rationales (using available rationale supervision), and a second, independent model is trained to make predictions on the basis of these (Lehman et al., 2019;Chen et al., 2019).\n\nElsewhere, Camburu et al. (2018) enriched the SNLI (Bowman et al., 2015) corpus with human rationales and trained an RNN for this task with the aim of being able to justify its predictions, in addition to learning better universal sentence representations. The authors used perplexity and BLEU scores as well as a manual scoring of a random sample of explanations.\n\nRajani et al. (2019) augmented the Common-senseQA (Talmor et al., 2019) corpus with rationales and trained a transformer (Vaswani et al., 2017) based GPT (Radford et al.) language model with an objective of using explanations to improve performance on the downstream task. Here the authors used perplexity to evaluate performance. The same work (Rajani et al., 2019) also pursued an innovative approach of training the model to generate natural language explanations directly, such that these agree with human provided free-text justifications. We view abstractive explanation as an exciting direction for future work, but here we focus on extractive rationalization.\n\nThe above efforts have measured rationale or explanation quality as a function of agreement with human rationales. This is natural in the setting in which supervision over rationales is assumed to be providing, as extracting these becomes a secondary predictive target which can be directly measured. However, agreement with human rationales demonstrates only plausibility; it does not guarantee that the model actually relied on the provided snippets to come to its prediction. Rationales that do meet these criterion are termed faithful: we discuss these two potential properties of rationales in more detail below. Importantly, we provide metrics that aim to measure these.\n\n\nDatasets in ERASER\n\nIn this section we describe the datasets that comprise the proposed rationales benchmark. All datasets constitute predictive tasks for which we distribute both reference labels and spans marked by humans, in a standardized format. For some of the datasets we have acquired comprehensive rationales from humans for a subset of instances. This permits evaluation of model recall, with respect to extracted rationales.\n\nWe distribute train, validation, and test sets for all corpora (see Appendix A for processing details). We ensure that these sets comprise disjoint sets of source documents to avoid contamination. 2 We have made the decision to distribute the test sets publicly, 3 in part because we do not view the 'correct' metrics to use as settled. We plan to acquire additional human annotations on held-out portions of some of the included corpora so as to offer hidden test set evaluation opportunities in the future.\n\nEvidence inference (Lehman et al., 2019). This is a dataset of full-text articles describing the conduct and results of randomized controlled trials (RCTs). The task is to infer whether a given intervention is reported to either significantly increase, significantly decrease, or have no significant effect on a specified outcome, as compared to a comparator of interest. A justifying rationale extracted from the text should be provided to support the inference. As the original annotations are not necessarily exhaustive, we collect exhaustive annotations on a subset of the test data 4 .\n\nBoolQ (Clark et al., 2019). This corpus consists of passages selected from Wikipedia, and yes/no questions generated from these passages. As the original Wikipedia article versions used were not maintained, we have made a best-effort attempt to recover these, and then find within them the passages answering the corresponding questions. For public release, we acquired comprehensive annotations on a subset of documents in our test set 4 .\n\nMovie Reviews (Zaidan and Eisner, 2008). One of the original datasets providing extractive rationales, the movies dataset has positive or negative sentiment labels on movie reviews. As the included rationale annotations are not necessarily comprehensive (i.e., annotators were not asked to mark all  text supporting a label), we collect a comprehensive evaluation set on the final fold of the original dataset (Pang and Lee, 2004) 4 .\n\nFEVER (Thorne et al., 2018). FEVER 1.0 (short for Fact Extraction and VERification) is a factchecking dataset. The task is to verify claims from textual sources. In particular, each claim is to be classified as supported, refuted or not enough information with reference to a collection of potentially relevant source texts. We restrict this dataset to supported or refuted.\n\nMultiRC (Khashabi et al., 2018). This is a reading comprehension dataset composed of questions with multiple correct answers that by construction depend on information from multiple sentences. In MultiRC, each Rationale is associated with a question, while answers are independent of one another. We convert each rationale/question/answer triplet into an instance within our dataset. Each answer candidate then has a label of True or False. In ERASER, models are evaluated both for their 'downstream' performance (i.e., performance on the actual classification task) and with respect to the rationales that they extract. For the former we rely on the established metrics for the respective tasks. Here we describe the metrics we propose to evaluate the quality of extracted rationales. We do not claim that these are necessarily the best metrics for evaluating rationales, but they are reasonable starting measures. We hope the release of ERASER will spur additional research into how best to measure the quality of model explanations in the context of NLP.\n\n\nAgreement with human rationales\n\nThe simplest means of evaluating rationales extracted by models is to measure how well they agree with those marked by humans. To this end we propose two classes of metrics: those based on exact matches, and ranking metrics that provide a measure of the model's ability to discriminate between evidence and non-evidence tokens (appropriate for models that provide soft scores for tokens). For the former, we borrow from Named Entity Recognition (NER); we effectively measure the overlap between spans extracted and marked. Specifically, given an extracted set of l rationales {r 1 , ..., r l } extracted for instance i, we compute precision, recall, and F1 with respect to m human rationales {h 1 , ..., h m }.\n\nExact match is a particularly harsh metric in that it may not reflect subjective rationale quality; consider that an extra token destroys the match but not (usually) the meaning. We therefore consider softer variants. Intersection-Over-Union (IOU), borrowed from computer vision (Everingham et al., 2010), permits credit assignment in the case of partial matches. We define IOU on a token level: for two spans x, y, it is the size of the overlap of the tokens covered by the spans divided by the size of the union. We count a prediction as a match if it overlaps with any of the ground truth rationales by more than some threshold (0.5 for this work). We compute true positives from these matches; other measures (false positives, false negatives) are computed normally, and yield a more forgiving precision, recall, and F-measure.\n\nWe provide two additional relaxations of the exact match metric. First, a token-level precision, recall, and F1 allow for a broader sense of model coverage, although these ignore contiguousness, which is likely a desirable property of rationales. Systems may also provide a sentence-level decision as a second relaxed scoring metric. In general we consider token and span-level metrics superior to sentence metrics as they are more granular, but some datasets have meaningful sentence level annotations. 5 Our second class of metrics considers rankings. This rewards models for assigning relatively highscores to marked tokens. In particular, we take the Area Under the Precision-Recall curve (AUPRC) constructed by sweeping a threshold over token scores.\n\nIn general, the rationales we have for tasks are sufficient to make judgments, but not necessarily comprehensive. However, for some datasets we have explicitly collected comprehensive rationales for at least a subset of the test set. Therefore, on these datasets recall evaluates comprehensiveness directly (it does so only noisily on other datasets). We highlight which corpora contain comprehensive rationales in the test set in Table 4.\n\n\nMeasuring faithfulness\n\nAbove we proposed simple metrics for agreement with human-provided rationales. But as discussed above, a model may provide rationales that are plausible (and agree with those marked by humans) but that it did not in fact rely on to come to its disposition. In some scenarios this may be acceptable, but in many settings one may want rationales that actually explain model predictions, i.e., rationales extracted for an instance in this case ought to have meaningfully influenced its prediction for the same. We refer to these as faithful rationales.\n\nHow best to measure the faithfulness of rationales is an open question. In this first version of ERASER we propose a few straightforward metrics motivated by prior work (Zaidan et al., 2007;Yu et al., 2019). In particular, following Yu et al. (2019) we define metrics intended to capture the comprehensiveness and sufficiency of rationales, respectively. The former should capture whether all features needed to come to a prediction were selected, and the latter should tell us whether the extracted rationales contain enough signal to come to a disposition.\n\nComprehensiveness. To calculate rationale comprehensiveness we create contrast examples (Zaidan et al., 2007) by taking an input instance x i with rationales r i and erasing from the former all tokens found in the latter. That is, we construct a contrast example for x i ,x i , which is x i with the rationales removed. Assuming a simple classification setting, letp ij be the original prediction provided by a model m for the predicted class j:p ij = m(x i ) j . Then we consider the predicted probability from the model for the same class once the supporting rationales are stripped:p ij = m(x i ). Intuitively, the model ought to be less confident in its prediction once rationales are removed from x i . We can measure this as:\ncomprehensiveness =p ij \u2212p ij(1)\nIf this is high, this implies that the rationales were indeed influential in the prediction; if it is low, then this suggests that they were not. A negative value here means that the model became more confident in its prediction after the rationales were removed; this would seem quite counter-intuitive if the rationales were indeed the reason for its prediction in the first place.\n\nSufficiency. The second metric for measuring the faithfulness of rationales that we use is intended to capture the degree to which the snippets within the extracted rationales are adequate for a model to make a prediction. Denote byp ij the predicted probability of class j using only rationales r i . Then:\nsufficiency =p ij \u2212p ij(2)\nThese metrics are illustrated in Figure 2. As defined, the above measures have assumed discrete rationales r i . We would like also to evaluate the faithfulness of continuous importance scores assigned to tokens by models. Here we adopt a simple approach for this. We convert soft scores over features s i provided by a model into discrete rationales r i by taking the top\u2212k d values, where k d is a threshold for dataset d. We set k d to the average rationale length provided by humans for dataset d (see Table 4). Intuitively, this says: How much does the model prediction change if we remove a number of tokens equal to what humans use (on average for this dataset) in order of the importance scores assigned to these by the model. Once we have discretized the soft scores into rationales in this way, we compute the faithfulness scores as per Equations 1 and 2. This approach is conceptually simple. It is also computationally cheap to evaluate, in contrast to measures that require per-token measurements, e.g., importance score correlations with 'leave-one-out' scores (Jain and Wallace, 2019), or counting how many 'important' tokens need to be erased before a prediction flips (Serrano and Smith, 2019). However, the necessity of discretizing continuous scores forces us to rely on the rather ad-hoc application of threshold k d . We believe that picking this based on human rationale annotations per dataset is reasonable, but acknowledge that alternative choice of threshold may yield quite different results for a given model and rationale set. It may be better to construct curves of this measure across varying k d and compare these, but this is both subtle (such curves will not necessarily be monotonic) and computationally intensive.\n\nUltimately, we hope that ERASER inspires additional research into designing faithfulness metrics for rationales. We plan to incorporate additional such metrics into future versions of the benchmark, if appropriate.\n\n\nBaseline Models\n\nOur focus in this work is primarily on the ERASER benchmark itself, rather than on any particular model(s). However, to establish initial empirical results that might provide a starting point for future work, we evaluate several baseline models across the corpora in ERASER. 6 We broadly class these into models that assign 'soft' (continuous) scores to tokens, and those that perform a 'hard' (discrete) selection over inputs. We additionally consider models specifically designed to select individual tokens (and very short sequences) as rationales, as compared to longer snippets.\n\nWe describe these models in the following subsections. All of our implementations are available in the ERASER repository. Note that we do not aim to provide, by any means, a comprehensive suite of models: rather, our aim is to establish a reasonable starting point for additional work on such models.\n\nAll of the datasets in ERASER have a similar structure: inputs, rationales, labels. But they differ considerably in length (Table 4), both of documents and corresponding rationales. We found that p(Forest|x i )\n\n\n< l a t e x i t s h a 1 _ b a s e 6 4 = \" o u g n m b + N i P K I 2 t l w 1 o M y Z A t v k 8 c = \" > A A A C B X i c b V D J S g N B E O 2 J W 4 x b 1 K M e B o M Q L 2 E m C n o M C u I x g l k g M 4 S e T i V p 0 r P Q X S M J 4 1 y 8 + C t e P C j i 1 X / w 5 t / Y W Q 6 a + K D g 8 V 4 V V f W 8 S H C F l v V t Z J a W V 1 b X s u u 5 j c 2 t 7 Z 3 8 7 l 5 d h b F k U G O h C G X T o w o E D 6 C G H\n\nA U 0 I w n U 9 w Q 0 v M H V 2 G / c g 1 Q 8 D O 5 w F I H r 0 1 7 A u 5 x R 1 F I 7 f + j 0 K S Z R W k w c h C E m 1 6 E E h W n 6 M G z z k 3 a + Y J W s C c x F Y s 9 I g c x Q b e e / n E 7 I Y h 8 C Z I I q 1 b K t C N 2 E S u R M Q J p z Y g U R Z Q P a g 5 a m A f V B u c n k i 9 Q 8 1 k r H 7 I Z S V 4 D m R P 0 9 k V B f q Z H v 6 U 6 f Y l / N e 2 P x P 6 8 V Y / f C T X g Q x Q g B m y 7 q x s L E 0 B x H Y n a 4 B I Z i p A l l k u t b T d a n k j L U w e V 0 C P b 8 y 4 u k X i 7 Z p 6 X y 7 V m h c j m L I 0 s O y B E p E p u c k w q 5 I V V S I 4 w 8 k m f y S t 6 M J + P F e D c + p q 0 Z Y z a z T / 7 A + P w B u O K Z W Q = = < / l a t e x i t > Where do you find the most amount of leafs?  this motivated use of different models for datasets, appropriate to their sizes and rationale granularities. In our case this was in fact necessitated by computational constraints, as we were unable to run larger models on lengthier documents such as those within Evidence Inference. We hope that this benchmark motivates design of models that provide rationales that can flexibly adapt to varying input lengths and expected rationale granularities. Indeed, only with such models can we perform comparisons across datasets.\nL W p E k r 3 Q m K Y 4 J K 1 g Y N g v V Q z k o S C d c P x 7 c z v P j J t u J I P M E l Z k J C h 5 D G n B K z k 9 4 G L i O V P 0 w E f V G t u 3 Z 0 D r x K v I D V U o D W o f v U j R b O E S a C C G O N 7 b g p B T j R w K t i 0 0 s 8 M S w k d k y H z L Z U k Y S b I 5 y d P 8 Z l V I h w r b U s C n q u / J 3 K S G D N J Q t u Z E B i Z Z W 8 m / u f 5 G c T X Q c 5 l m g G T d L E o z g Q G h W f / 4 4 h r R k F M L C F U c 3 s r p i O i C Q W b U s W G 4 C 2 / v E o 6 j b p 3 U W / c X 9 a a N 0 U c Z X S C T t E 5 8 t A V a q I 7 1 E J t R J F C z + g V v T n g v D j v\n\nHard selection\n\nModels that perform hard selection may be viewed as comprising two independent modules: an encoder which is responsible for extracting snippets of inputs, and a decoder that makes a prediction based only on the text provided by the encoder. We consider two variants of such models. Lei et al. (2016). In this model, the encoder induces a binary mask over inputs x, z. The decoder consumes the attributes of x indicated by z to make a prediction\u0177. The components are typically trained jointly. This end-to-end training is complicated by the use of (non-differentiable) hard attention, i.e., the binary mask z, which means it is not possible to train the model using variants of gradient descent. Instead, Lei et al. (2016) propose using REINFORCE (Williams, 1992) style estimation, minimizing the loss over expected binary vectors z yielded from the encoder.\n\nOne of the advantages of this approach is that it need not have access to marked rationales; it can learn to rationalize on the basis of instance labels alone. However, given that here we do have access to rationales in the training data, we experiment with a variant in which we train the encoder explicitly using rationale-level annotations.\n\nIn our implementation of Lei et al. (2016), we drop in two independent BERT (Devlin et al., 2018) base modules with bidirectional LSTM (Hochreiter and Schmidhuber, 1997) on top to induce contextualized representations of tokens for the encoder and decoder (the decoder, in addition, uses additive attention to collapse the LSTM hidden representations to a single vector), respectively. The encoder generates a scalar (denoting the probability of selecting that token) for each LSTM hidden state using a feedfoward layer and sigmoid. In the model where we do use human rationales during training, we minimize binary cross entropy between our sigmoid output and the ground truth rationale. Thus our final loss function is composed of decoder classification loss, reinforce estimator loss (details can be found in Lei et al. (2016)) and if used, a rationale supervision loss.\n\nPipeline models. These are simple models in which we first train the encoder to extract rationales, and then train the decoder to perform prediction using only rationales. No parameters are shared between the two models. Realizing this type of approach is possible only when one has access to direct rationale supervision in order to train the encoder (which in general we assume in ERASER).\n\nHere we first consider a simple pipeline that first segments inputs into sentences. It passes these, one at a time, through a Gated Recurrent Unit (GRU)  to yield hidden representations that we compose via an attentive decoding layer . This aggregate representation is then passed to a classification module which predicts whether the corresponding sentence is a rationale (or not). A second model, using effectively the same architecture but parameterized independently, consumes the outputs (rationales) from the first to make predictions. This simple model is described at length in prior work (Lehman et al., 2019). We further consider a 'BERT-to-BERT' pipeline, where we replace each stage with a BERT module for prediction (Devlin et al., 2018).\n\nIn all pipeline models, we train each stage independently. The rationale identification stage is trained using approximate sentence boundaries from our source annotations, with randomly sampled negative examples at each epoch. The classification stage uses the same positive rationales as the identification stage, a kind of teacher forcing. See Appendix C for more detail.\n\n\nSoft selection\n\nA subset of datasets in ERASER contain tokenlevel annotations, i.e., in these cases individual words and/or comparatively short sequences of words are marked as supporting classification decisions. These are: MultiRC, Movies, e-SNLI, and CoS-E. For these datasets we consider a model that passes tokens through BERT (Devlin et al., 2018) to induce contextualized representations that are then passed to a bi-directional LSTM (Hochreiter and Schmidhuber, 1997). The hidden representations from the LSTM are collapsed into a single vector using additive attention  and finally through a linear layer followed by a sigmoid to yield (per-token) relevance predictions. We use the LSTM layer in part to bypass the 512 word limit imposed by BERT; when we exceed this length, we effectively start encoding a 'new' sequence (setting the positional index to 0) via BERT. The hope is that the LSTM layer learns to compensate for this. We have not yet trained this model on larger corpora due to computational constraints. For now we instead use a similar setup as above for Evidence Inference, BoolQ, and FEVER, except we swap in GloVe 300-d embeddings (Pennington et al., 2014) in place of BERT representations for tokens.\n\nFor these models we consider input gradients (with respect to output) and attention induced over contextualized representations as 'soft' scores.\n\n\nEvaluation\n\nPerformance IOU F1 Token F1\n\nEvidence Inference (Lehman et al., 2019) 0  Here we present initial results for the baseline models discussed in Section 6, with respect to the metrics proposed in Section 5. We present results in two parts, reflecting the two classes of rationales discussed above: 'hard' approaches that perform discrete selection of snippets and 'soft' methods that assign continuous importance scores to tokens.   First, in Table 3 we evaluate models that perform discrete selection of rationales. We view these models as faithful by design, because by construction we know what snippets of text the decoder used to make a prediction. 7 Therefore, for these methods we report only metrics that measure agreement with human annotations.\n\nDue to computational constraints, we are currently unable to run our BERT-based implementation of Lei et al. (2016) over larger corpora. Conversely, Lehman et al. (2019) assumes a setting in which rationale are sentences, and so is not appropriate for datasets in which rationales tend to comprise only very short spans. Again, in our view this highlights the need for models that can rationalize at varying levels of granularity, depending on what is appropriate.\n\nWe observe that for the \"rationalizing\" model of Lei et al. (2016), exploiting rationale-level supervision generally improves agreement with humanprovided rationales, which is consistent with prior work (Zhang et al., 2016;Strout et al., 2019). Here, Lei et al. (2016) consistently outperform the simple pipeline model from Lehman et al. (2019). Furthermore, Lei et al. (2016) outperforms the 'BERT-to-BERT' pipeline on the comparable datasets for the final classification tasks. This may be an artifact of the amount of text each model can select: 'BERTto-BERT' is limited to sentences, while Lei et al. (2016) can select any subset of the text.\n\nIn Table 4 we report metrics for models that assign soft (continuous) importance scores to individual tokens. For these models we again measure downstream (task) performance (F1 or accuracy, as appropriate). Here the models are actually the same, and so downstream performance is equivalent. To assess the quality of token scores with respect to human annotations, we report the Area Under the Precision Recall Curve (AUPRC). Finally, as these scoring functions assign only soft scores to inputs (and may still use all inputs to come to a particular prediction), we report the metrics intended to measure faithfulness defined above: comprehensiveness and sufficiency. Here we observe that the simple gradient attribution yields consistently more 'faithful' rationales with respect to comprehensiveness, and in a slight majority of cases also with respect to sufficiency. Interestingly, however, attention weights yield better AUPRCs. 7 Note that this further assumes that the encoder and decoder do not share parameters.\n\nWe view these as preliminary results and intend to implement and evaluate additional baselines in the near future. Critically, we see a need for establishing the performance of a single architecture across ERASER, which comprises datasets of very different size, and featuring rationales at differing granularities.\n\n\nDiscussion\n\nWe have described a new publicly available Evaluating Rationales And Simple English Reasoning (ERASER) benchmark. This comprises seven datasets, all of which have both instance level labels and corresponding supporting snippets ('rationales') marked by human annotators. We have augmented many of these datasets with additional annotations, and converted them into a standard format comprising inputs, rationales, and outputs. ERASER is intended to facilitate progress on explainable models for NLP.\n\nWe have proposed several metrics intended to measure the quality of rationales extracted by models, both in terms of agreement with human annotations, and in terms of 'faithfulness' with respect to comprehensiveness and sufficiency. We believe these metrics provide reasonable means of comparison of specific aspects of interpretability. However, we view the problem of measuring faithfulness, in particular, a topic ripe for additional research; we hope that ERASER facilitates this.\n\nMore generally, our hope is that ERASER facilitates progress on designing and comparing relative strengths and weaknesses of interpretable NLP models across a variety of tasks and datasets. We aim to continually update this benchmark and the corresponding metrics that it defines. In contrast to most benchmarks, we are not privileging any one measure of performance. Our view is that for interpretability, different models may excel at different things, and our aim for ERASER is to facilitate meaningful contrastive comparisons that highlight which models excel with respect to particular metrics of interest (e.g., certain models may provide superior faithfulness, though with lower predictive performance). We host a leaderboard, but allow for sorting with respect to any metric of interest.\n\nThe ERASER datasets, code for working with the data and performing evaluations, and our baseline model implementations are all available at: www.eraserbenchmark.com, which we will be continuously updating. C Hyperparameter and training details C.1 (Lei et al., 2016) \n\n\nmodels\n\nFor these models, we set the sparsity rate at 0.01 and we set the contiguity loss weight to 2 times sparsity rate (following the original paper). We used bert-base-uncased (Wolf et al., 2019) as token embedder and Bidirectional LSTM with 128 dimensional hidden state in each direction. A dropout (Srivastava et al., 2014) rate of 0.2 was used before feeding the hidden representations to attention layer in decoder and linear layer in encoder. One layer MLP with 128 dimensional hidden state and ReLU activation was used to compute the decoder output distribution.\n\nA learning rate of 2e-5 with Adam (Kingma and Ba, 2014) optimizer was used for all models and we only fine-tuned top two layers of BERT encoder. Th models were trained for 20 epochs and early stopping with patience of 5 epochs was used. The best model was selected on validation set using the final task performance metric.\n\nThe input for the above model was encoded in form of [CLS] document [SEP] query [SEP].\n\nThis model was implemented using AllenNLP library (Gardner et al., 2017).\n\n\nC.2 BERT-LSTM/GloVe-LSTM\n\nThis model is essentially the same as decoder in previous section. The BERT-LSTM uses the same hyperparameter and GloVe-LSTM is trained with a learning rate of 1e-2.\n\n\nC.3 (Lehman et al., 2019) models\n\nWith the exception of the Evidence Inference dataset, these models were trained using the GLoVe (Pennington et al., 2014) 200 dimension word vectors, and Evidence Inference using the (Pyysalo et al., 2013) PubMed word vectors. We use Adam (Kingma and Ba, 2014) with a learning rate of 1e-3, Dropout (Srivastava et al., 2014) of 0.05 at each layer (embedding, GRU, attention layer) of the model, for 50 epochs with a patience of 10. We monitor validation loss, and keep the best model on the validation set.\n\n\nC.4 BERT-to-BERT model\n\nWe primarily used the bert-base-uncased model for both portions of the identification and classification pipeline, with the sole exception being Evidence Inference with SciBERT (Beltagy et al., 2019).\n\n( a )\naSig. decreased (b) No sig. difference (c) Sig. increased Prompt With respect to breathlessness, what is the reported difference between patients receiving placebo and those receiving furosemide? e-SNLI H A man in an orange vest leans over a pickup truck P A man is touching a truck (a) Entailment (b) Contradiction (c) Neutral\n\nFigure 1 :\n1Examples of instances, labels, and rationales illustrative of four (out of seven) datasets included in ERASER. The 'erased' snippets are rationales.\n\nFigure 2 :\n2Illustration of faithfulness scoring metrics, comprehensiveness and sufficiency, on the Commonsense Explanations (CoS-E) dataset. For the former, erasing the tokens comprising the provided rationale (x i ) ought to decrease model confidence in the output 'Forest'. For the latter, the model should be able to come to a similar disposition regarding 'Forest' using only the rationales r i .\n\n! Table 1 :\n!1Overview of datasets in the proposed rationales benchmark. These numbers reflect any additional processing completed from the original datasets. Comprehensive rationales mean that all supporting evidence is marked;!denotes cases where this is (more or less) true by default; \u25c7, \u25c6 are datasets for which we have collected comprehensive rationales for either a subset or all of the test datasets, respectively; are datasets for which we do not have comprehensive rationales.Name \n\nSize (train/dev/test) \nComprehensive? \nEvidence Inference \n7958 / 972 / 959 \n\u25c7 \nBoolQ \n6363 / 1491 / 2817 \n\u25c7 \nMovie Reviews \n1600 / 200 / 200 \n\u25c6 \nFEVER \n97957 / 6122 / 6111 \n\nMultiRC \n24029 / 3214 / 4848 \n\n! \n\nCoS-E \n8733 / 1092 / 1092 \n\n! \n\ne-SNLI \n911938 / 16449 / 16429 \n\nDataset \nLabels Instances Documents Sentences Tokens \n\nEvidence Inference \n3 \n9889 \n2411 \n156.0 \n4760.6 \nBoolQ \n2 \n10671 \n7030 \n175.2 \n3580.1 \nMovie Reviews \n2 \n2000 \n1999 \n36.8 \n774.1 \nFEVER \n2 \n110190 \n4099 \n12.1 \n326.5 \nMultiRC \n2 \n32091 \n539 \n14.9 \n302.5 \nCoS-E \n5 \n10917 \n10917 \n1.0 \n27.6 \ne-SNLI \n3 \n568939 \n944565 \n1.7 \n16.0 \n\n\n\nTable 2 :\n2General dataset statistics: number of labels, instances, unique documents, and average numbers of sentences and tokens in documents, across the publicly released train/validation/test splits in ERASER. For CoS-E and e-SNLI, the sentence counts are not meaningful as the partitioning of question/sentence/answer formatting is an arbitrary choice in this framework.\n\n\nCommonsense Explanations (CoS-E)(Rajani et al., 2019). This corpus comprises multiplechoice questions and answers from(Talmor et al., 2019) along with supporting rationales. The rationales in this case come in the form both of highlighted (extracted) supporting snippets and freetext, open-ended descriptions of reasoning. Given our focus on extractive rationales, ERASER includes only the former for now. Following the suggestions of(Talmor et al., 2019), we repartition the training and validation sets to provide a canonical test split. e-SNLI(Camburu et al., 2018). This dataset extends on the widely known SNLI dataset(Bowman et al., 2015) by including rationales in the form of tokens in the premise and/or hypothesis as well open-ended natural language explanations. The authors had restrictions on what can be included as rationale depending on the label. For entailment pairs, annotators were required to highlight at least one word in the premise. For contradiction pairs, the annotators had to highlight at least one word in both the premise and the hypothesis. For neutral pairs, annotators were only allowed to highlight words in the hypothesis. We use the highlighted text as rationales for our ERASER benchmark.\n\nTable 3 :\n3Performance of models that perform 'hard' \n(discrete) rationale selection. All models are super-\nvised at the rationale level except for those marked \nwith (u), which learn only from instance-level supervi-\nsion (for comparison). The  \u2020 denotes cases in which \nwe believe the rationale training degenerated due to \nthe REINFORCE style learning. Performance here is \naccuracy (CoS-E) and macro-averaged F1 (all others). \nRationale evaluations for Evidence Inference, FEVER, \nand BoolQ include the non-comprehensive subset. \n\n\n\n\nPerformance AUPRC Comprehensiveness \u2191 Sufficiency \u2193Evidence Inference (k d =20%) \nGloVe-LSTM + Attention \n0.428 \n0.506 \n0.001 \n-0.022 \nGloVe-LSTM + Simple Gradient \n0.428 \n0.020 \n0.009 \n-0.079 \n\nBoolQ (k d =10%) \nGloVe-LSTM + Attention \n0.631 \n0.525 \n-0.001 \n0.028 \nGloVe-LSTM + Simple Gradient \n0.631 \n0.072 \n0.015 \n0.104 \n\nMovie Reviews (k d =10%) \nBERT-LSTM + Attention \n0.974 \n0.467 \n0.091 \n0.035 \nBERT-LSTM + Simple Gradient \n0.974 \n0.441 \n0.113 \n0.052 \n\nFEVER (k d =20%) \nGloVe-LSTM + Attention \n0.660 \n0.617 \n-0.011 \n0.129 \nGloVe-LSTM + Simple Gradient \n0.660 \n0.271 \n0.070 \n0.077 \n\nMultiRC (k d =20%) \nBERT-LSTM + Attention \n0.655 \n0.240 \n0.145 \n0.085 \nBERT-LSTM + Simple Gradient \n0.655 \n0.224 \n0.164 \n0.079 \n\nCoS-E (k d =30%) \nBERT-LSTM + Attention \n0.487 \n0.607 \n0.124 \n0.175 \nBERT-LSTM + Simple Gradient \n0.487 \n0.585 \n0.160 \n0.196 \n\ne-SNLI (k d =30%) \nBERT-LSTM + Attention \n0.960 \n0.394 \n0.115 \n0.622 \nBERT-LSTM + Simple Gradient \n0.960 \n0.418 \n0.451 \n0.419 \n\n\n\nTable 4 :\n4Metrics for 'soft' scoring models. Performance refers to macro-averaged F1 for MultiRC, Movies, and e-SNLI, and accuracy for COS-E. Area Under the Precision Recall Curve (AUPRC) captures agreement between token rankings induced by scores and human annotations. Comprehensiveness and sufficiency are proposed measures of faithfulness; bigger numbers imply better performance for the former, and smaller numbers do so for the latter. These two measures depend on a dataset-specific threshold k d to discretize token scores (Section 5.2).Dataset \nCohen \u03ba \nF1 \nP \nR \n#Annotators/doc #Documents \nEvidence Inference \n-\n-\n-\n-\n-\n-\nBoolQ \n0.618 \u00b1 0.194 0.617 \u00b1 0.227 0.647 \u00b1 0.260 0.726 \u00b1 0.217 \n3 \n199 \nMovie Reviews \n0.712 \u00b1 0.135 0.799 \u00b1 0.138 0.693 \u00b1 0.153 0.989 \u00b1 0.102 \n2 \n96 \nFEVER \n0.854 \u00b1 0.196 0.871 \u00b1 0.197 0.931 \u00b1 0.205 0.855 \u00b1 0.198 \n2 \n24 \nMultiRC \n0.728 \u00b1 0.268 0.749 \u00b1 0.265 0.695 \u00b1 0.284 0.910 \u00b1 0.259 \n2 \n99 \nCoS-E \n0.619 \u00b1 0.308 0.654 \u00b1 0.317 0.626 \u00b1 0.319 0.792 \u00b1 0.371 \n2 \n100 \ne-SNLI \n0.743 \u00b1 0.162 0.799 \u00b1 0.130 0.812 \u00b1 0.154 0.853 \u00b1 0.124 \n3 \n9807 \n\n\n\nTable 5 :\n5Human agreement numbers with respect to rationales. For Movie Reviews and BoolQ we calculate the mean agreement of individual annotators with the majority vote per token, over the two-three annotators we hired via Upwork and Amazon Turk, respectively. The e-SNLI dataset already comprised three annotators, and for this we calculate mean agreement between individuals and the majority. For CoS-E, MultiRC, and FEVER, members of our team annotated a subset to use a comparison to the (majority of, where appropriate) existing rationales. We collected comprehensive rationales for evidence inference from Medical Doctors; given that they have a high amount of expertise, we would expect agreement to be high, but have not yet collected redundant comprehensive annotations.\nExcept for BoolQ, wherein source documents in the original train and validation set were not disjoint and we preserve this structure in our dataset. Questions, of course, are disjoint.3  Consequently, for datasets that have been part of previous benchmarks with other aims (namely, GLUE/superGLUE) but which we have re-purposed for work on rationales in ERASER, e.g., BoolQ(Clark et al., 2019), we have carved out for release test sets from the original validation sets.4  Annotation details are in Appendix B.\nMultiRC and FEVER both have sentence level annotations only\nWe plan to continue adding baseline model implementations, which we will make available at http://www. eraserbenchmark.com.\nhttps://spacy.io/ 9 http://www.upwork.com\nWe trained with the standard BERT parameters of a learning rate of 1e-5, Adam (Kingma and Ba, 2014), for 10 epochs. We monitor validation loss, and keep the best model on the validation set.Appendix A Dataset PreprocessingWe describe what, if any, additional processing we perform on a per-dataset basis. All datasets were converted to a unified format.MultiRC(Khashabi et al., 2018)We perform minimal processing. We use the validation set as the testing set for public release.Evidence Inference(Lehman et al., 2019)We perform minimal processing. As not all of the provided evidence spans come with offsets, we delete any prompts that had no grounded evidence spans.Movie reviews(Zaidan and Eisner, 2008)We perform minimal processing. We use the ninth fold as the validation set, and collect annotations on the tenth fold for comprehensive evaluation.FEVER(Thorne et al., 2018)We perform substantial processing for FEVER -we delete the \"Not Enough Info\" claim class, delete any claims with support in more than one document, and repartition the validation set into a validation and a test set for this benchmark (using the test set would compromise the information retrieval portion of the original FEVER task). We ensure that there is no document overlap between train, validation, and test sets (we use Pearce to ensure this, as conceptually a claim may be supported by facts in more than one document). We ensure that the validation set contains the documents used to create the FEVER symmetric dataset(Schuster et al., 2019) (unfortunately, the documents used to create the validation and test sets overlap so we cannot provide this partitioning). Additionally, we clean up some encoding errors in the dataset via Speer (2019).BoolQ(Clark et al., 2019)The BoolQ dataset required substantial processing. The original dataset did not retain source Wikipedia articles or collection dates. In order to identify the source paragraphs, we download the 12/20/18 Wikipedia archive, and use FuzzyWuzzy https://github. com/seatgeek/fuzzywuzzy to identify the source paragraph span that best matches the original release. If the Levenshtein distance ratio does not reach a score of at least 90, the corresponding instance is removed. For public release, we use the official validation set for testing, and repartition train into a training and validation set. e-SNLI(Camburu et al., 2018)We perform minimal processing. We separate the premise and hypothesis statements into separate documents.Commonsense Explanations (CoS-E) (Rajani et al., 2019) We perform minimal processing, primarily deletion of any questions without a rationale or questions with rationales that were not possible to automatically map back to the underlying text. As recommended by the authors of Talmor et al.(2019)sets into a train, validation, and test set for this benchmark. We encode the entire question and answers as a prompt and convert the problem into a five-class prediction. We also convert the \"Sanity\" datasets for user convenience. All datasets in ERASER were tokenized using spaCy 8 library (with SciSpacy(Neumann et al., 2019)for Evidence Inference). In addition, we also split all datasets except e-SNLI and CoS-E into sentences using the same library.B Annotation detailsWe collected comprehensive rationales for a subset of some test sets to accurately evaluate model recall of rationales.1. Movies. We used the Upwork Platform 9 to hire two fluent english speakers to annotate each of the 200 documents in our test set. Workers were paid at rate of USD 8.5 per hour and on average, it took them 5 min to annotate a document. Each annotator was asked to annotate a set of 6 documents and compared against in-house annotations (by authors).2. Evidence Inference. We again used Upwork to hire 4 medical professionals fluent in english and having passed a pilot of 3 documents. 125 documents were annotated (only once by one of the annotators, which we felt was appropriate given their high-level of expertise) with an average cost of USD 13 per document. Average time spent of single document was 31 min.3. BoolQ. We used Amazon Mechanical Turk (MTurk) to collect reference comprehensive rationales from randomly selected 199 documents from our test set (ranging in 800 to 1500 tokens in length). Only workers from AU, NZ, CA, US, GB with more than 10K approved HITs and an approval rate of greater than 98% were eligible. For every document, 3 annotations were collected and workers were paid USD 1.50 per HIT. The average work time (obtained through MTurk interface) was 21 min. We did not anticipate the task taking so long (on average); the effective low pay rate was unintended.\nA causal framework for explaining the predictions of black-box sequence-to-sequence models. David Alvarez-Melis, Tommi Jaakkola, Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. the 2017 Conference on Empirical Methods in Natural Language ProcessingDavid Alvarez-Melis and Tommi Jaakkola. 2017. A causal framework for explaining the predictions of black-box sequence-to-sequence models. In Pro- ceedings of the 2017 Conference on Empirical Meth- ods in Natural Language Processing, pages 412- 421.\n\nNeural machine translation by jointly learning to align and translate. Dzmitry Bahdanau, Kyunghyun Cho, Yoshua Bengio, arXiv:1409.0473arXiv preprintDzmitry Bahdanau, Kyunghyun Cho, and Yoshua Ben- gio. 2014. Neural machine translation by jointly learning to align and translate. arXiv preprint arXiv:1409.0473.\n\nScibert: Pretrained language model for scientific text. Iz Beltagy, Kyle Lo, Arman Cohan, EMNLP. Iz Beltagy, Kyle Lo, and Arman Cohan. 2019. Scib- ert: Pretrained language model for scientific text. In EMNLP.\n\nA large annotated corpus for learning natural language inference. R Samuel, Gabor Bowman, Christopher Angeli, Christopher D Potts, Manning, Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP). the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP)Association for Computational LinguisticsSamuel R. Bowman, Gabor Angeli, Christopher Potts, and Christopher D. Manning. 2015. A large anno- tated corpus for learning natural language inference. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing (EMNLP). Association for Computational Linguistics.\n\nOn the validity of self-attention as explanation in transformer models. Gino Brunner, Yang Liu, Dami\u00e1n Pascual, Oliver Richter, Roger Wattenhofer, arXiv:1908.04211arXiv preprintGino Brunner, Yang Liu, Dami\u00e1n Pascual, Oliver Richter, and Roger Wattenhofer. 2019. On the va- lidity of self-attention as explanation in transformer models. arXiv preprint arXiv:1908.04211.\n\ne-snli: Natural language inference with natural language explanations. Oana-Maria Camburu, Tim Rockt\u00e4schel, Thomas Lukasiewicz, Phil Blunsom, Advances in Neural Information Processing Systems. Oana-Maria Camburu, Tim Rockt\u00e4schel, Thomas Lukasiewicz, and Phil Blunsom. 2018. e-snli: Nat- ural language inference with natural language expla- nations. In Advances in Neural Information Process- ing Systems, pages 9539-9549.\n\nSeeing things from a different angle: Discovering diverse perspectives about claims. Sihao Chen, Daniel Khashabi, Wenpeng Yin, Chris Callison-Burch, Dan Roth, 10.18653/v1/N19-1053Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL). the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)Minneapolis, MinnesotaSihao Chen, Daniel Khashabi, Wenpeng Yin, Chris Callison-Burch, and Dan Roth. 2019. Seeing things from a different angle: Discovering diverse perspec- tives about claims. In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL), pages 542- 557, Minneapolis, Minnesota.\n\nLearning phrase representations using rnn encoder-decoder for statistical machine translation. Kyunghyun Cho, Bart Van Merri\u00ebnboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, Yoshua Bengio, arXiv:1406.1078arXiv preprintKyunghyun Cho, Bart Van Merri\u00ebnboer, Caglar Gul- cehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, and Yoshua Bengio. 2014. Learning phrase representations using rnn encoder-decoder for statistical machine translation. arXiv preprint arXiv:1406.1078.\n\nBoolq: Exploring the surprising difficulty of natural yes/no questions. Christopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski, Michael Collins, Kristina Toutanova, NAACL. Christopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski, Michael Collins, and Kristina Toutanova. 2019. Boolq: Exploring the surprising difficulty of natural yes/no questions. In NAACL.\n\nJacob Devlin, Ming-Wei Chang, Kenton Lee, Kristina Toutanova, arXiv:1810.04805Bert: Pre-training of deep bidirectional transformers for language understanding. arXiv preprintJacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2018. Bert: Pre-training of deep bidirectional transformers for language understand- ing. arXiv preprint arXiv:1810.04805.\n\nTowards a rigorous science of interpretable machine learning. Finale Doshi, - Velez, Been Kim, arXiv:1702.08608arXiv preprintFinale Doshi-Velez and Been Kim. 2017. Towards a rigorous science of interpretable machine learning. arXiv preprint arXiv:1702.08608.\n\nThe pascal visual object classes (voc) challenge. Mark Everingham, Luc Van Gool, K I Christopher, John Williams, Andrew Winn, Zisserman, 10.1007/s11263-009-0275-4International Journal of Computer Vision. 882Mark Everingham, Luc Van Gool, Christopher K. I. Williams, John Winn, and Andrew Zisserman. 2010. The pascal visual object classes (voc) challenge. In- ternational Journal of Computer Vision, 88(2):303- 338.\n\nEric Shi Feng, Wallace, Mohit Grissom, Pedro Iyyer, Jordan Rodriguez, Boyd-Graber, arXiv:1804.07781Pathologies of neural models make interpretations difficult. arXiv preprintShi Feng, Eric Wallace, II Grissom, Mohit Iyyer, Pe- dro Rodriguez, Jordan Boyd-Graber, et al. 2018. Pathologies of neural models make interpretations difficult. arXiv preprint arXiv:1804.07781.\n\nAllennlp: A deep semantic natural language processing platform. Matt Gardner, Joel Grus, Mark Neumann, Oyvind Tafjord, Pradeep Dasigi, Nelson F Liu, Matthew Peters, Michael Schmitz, Luke S Zettlemoyer, Matt Gardner, Joel Grus, Mark Neumann, Oyvind Tafjord, Pradeep Dasigi, Nelson F. Liu, Matthew Peters, Michael Schmitz, and Luke S. Zettlemoyer. 2017. Allennlp: A deep semantic natural language processing platform.\n\nLong short-term memory. Sepp Hochreiter, J\u00fcrgen Schmidhuber, Neural computation. 98Sepp Hochreiter and J\u00fcrgen Schmidhuber. 1997. Long short-term memory. Neural computation, 9(8):1735-1780.\n\nAttention is not explanation. Sarthak Jain, C Byron, Wallace, arXiv:1902.10186arXiv preprintSarthak Jain and Byron C Wallace. 2019. Attention is not explanation. arXiv preprint arXiv:1902.10186.\n\nLooking Beyond the Surface: A Challenge Set for Reading Comprehension over Multiple Sentences. Daniel Khashabi, Snigdha Chaturvedi, Michael Roth, Shyam Upadhyay, Dan Roth, Proc. of the Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL). of the Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL)Daniel Khashabi, Snigdha Chaturvedi, Michael Roth, Shyam Upadhyay, and Dan Roth. 2018. Looking Beyond the Surface: A Challenge Set for Reading Comprehension over Multiple Sentences. In Proc. of the Annual Conference of the North American Chapter of the Association for Computational Lin- guistics (NAACL).\n\nAdam: A method for stochastic optimization. P Diederik, Jimmy Kingma, Ba, abs/1412.6980CoRRDiederik P. Kingma and Jimmy Ba. 2014. Adam: A method for stochastic optimization. CoRR, abs/1412.6980.\n\nInferring which medical treatments work from reports of clinical trials. Eric Lehman, Jay Deyoung, Regina Barzilay, Byron C Wallace, Proceedings of the North American Chapter of the Association for Computational Linguistics (NAACL). the North American Chapter of the Association for Computational Linguistics (NAACL)Eric Lehman, Jay DeYoung, Regina Barzilay, and By- ron C Wallace. 2019. Inferring which medical treat- ments work from reports of clinical trials. In Pro- ceedings of the North American Chapter of the As- sociation for Computational Linguistics (NAACL), pages 3705-3717.\n\nRationalizing neural predictions. Tao Lei, Regina Barzilay, Tommi Jaakkola, Tao Lei, Regina Barzilay, and Tommi Jaakkola. 2016. Rationalizing neural predictions. pages 107-117.\n\nZachary C Lipton, arXiv:1606.03490The mythos of model interpretability. arXiv preprintZachary C Lipton. 2016. The mythos of model inter- pretability. arXiv preprint arXiv:1606.03490.\n\nThe many benefits of annotator rationales for relevance judgments. Tyler Mcdonnell, Mucahid Kutlu, IJCAI. Tamer Elsayed, and Matthew LeaseTyler McDonnell, Mucahid Kutlu, Tamer Elsayed, and Matthew Lease. 2017. The many benefits of anno- tator rationales for relevance judgments. In IJCAI, pages 4909-4913.\n\nWhy is that relevant? collecting annotator rationales for relevance judgments. Tyler Mcdonnell, Matthew Lease, Mucahid Kutlu, Tamer Elsayed, Fourth AAAI Conference on Human Computation and Crowdsourcing. Tyler McDonnell, Matthew Lease, Mucahid Kutlu, and Tamer Elsayed. 2016. Why is that relevant? col- lecting annotator rationales for relevance judgments. In Fourth AAAI Conference on Human Computation and Crowdsourcing.\n\nInterrogating the explanatory power of attention in neural machine translation. Pooya Moradi, Nishant Kambhatla, Anoop Sarkar, arXiv:1910.00139arXiv preprintPooya Moradi, Nishant Kambhatla, and Anoop Sarkar. 2019. Interrogating the explanatory power of atten- tion in neural machine translation. arXiv preprint arXiv:1910.00139.\n\nMark Neumann, Daniel King, Iz Beltagy, and Waleed Ammar. 2019. Scispacy: Fast and robust models for biomedical natural language processing. Mark Neumann, Daniel King, Iz Beltagy, and Waleed Ammar. 2019. Scispacy: Fast and robust models for biomedical natural language processing.\n\nA sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts. Bo Pang, Lillian Lee, 10.3115/1218955.1218990Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL-04). the 42nd Annual Meeting of the Association for Computational Linguistics (ACL-04)Barcelona, SpainBo Pang and Lillian Lee. 2004. A sentimental edu- cation: Sentiment analysis using subjectivity sum- marization based on minimum cuts. In Proceed- ings of the 42nd Annual Meeting of the Association for Computational Linguistics (ACL-04), pages 271- 278, Barcelona, Spain.\n\nAn improved algorithm for finding the strongly connected components of a directed graph. J David, Pearce, David J Pearce. An improved algorithm for finding the strongly connected components of a directed graph.\n\nGlove: Global vectors for word representation. Jeffrey Pennington, Richard Socher, Christopher Manning, 10.3115/v1/D14-1162Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)Doha, QatarAssociation for Computational LinguisticsJeffrey Pennington, Richard Socher, and Christopher Manning. 2014. Glove: Global vectors for word rep- resentation. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Process- ing (EMNLP), pages 1532-1543, Doha, Qatar. Asso- ciation for Computational Linguistics.\n\nLearning to deceive with attention-based explanations. Danish Pruthi, Mansi Gupta, Bhuwan Dhingra, Graham Neubig, Zachary C Lipton, arXiv:1909.07913arXiv preprintDanish Pruthi, Mansi Gupta, Bhuwan Dhingra, Gra- ham Neubig, and Zachary C Lipton. 2019. Learning to deceive with attention-based explanations. arXiv preprint arXiv:1909.07913.\n\nDistributional semantics resources for biomedical text processing. Sampo Pyysalo, Filip Ginter, Hans Moen, Tapio Salakoski, Sophia Ananiadou, Sampo Pyysalo, Filip Ginter, Hans Moen, Tapio Salakoski, and Sophia Ananiadou. 2013. Distribu- tional semantics resources for biomedical text pro- cessing.\n\nTim Salimans, and Ilya Sutskever. Improving language understanding by generative pre-training. Alec Radford, Karthik Narasimhan, Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. Improving language understanding by generative pre-training.\n\nExplain yourself! leveraging language models for commonsense reasoning. Bryan Nazneen Fatema Rajani, Caiming Mccann, Richard Xiong, Socher, Proceedings of the Association for Computational Linguistics (ACL). the Association for Computational Linguistics (ACL)Nazneen Fatema Rajani, Bryan McCann, Caiming Xiong, and Richard Socher. 2019. Explain yourself! leveraging language models for commonsense rea- soning. Proceedings of the Association for Compu- tational Linguistics (ACL).\n\nwhy should i trust you?: Explaining the predictions of any classifier. Marco Ribeiro, Sameer Singh, Carlos Guestrin, Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Demonstrations. the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: DemonstrationsMarco Ribeiro, Sameer Singh, and Carlos Guestrin. 2016. why should i trust you?: Explaining the pre- dictions of any classifier. In Proceedings of the 2016 Conference of the North American Chapter of the Association for Computational Linguistics: Demon- strations, pages 97-101.\n\nTowards debiasing fact verification models. Tal Schuster, J Darsh, Yun Jie Serene Shah, Daniel Yeo, Enrico Filizzola, Regina Santus, Barzilay, abs/1908.05267CoRRTal Schuster, Darsh J. Shah, Yun Jie Serene Yeo, Daniel Filizzola, Enrico Santus, and Regina Barzilay. 2019. Towards debiasing fact verification models. CoRR, abs/1908.05267.\n\nSofia Serrano, A Noah, Smith, arXiv:1906.03731Is attention interpretable. arXiv preprintSofia Serrano and Noah A Smith. 2019. Is attention interpretable? arXiv preprint arXiv:1906.03731.\n\nActive learning. Burr Settles, Synthesis Lectures on Artificial Intelligence and Machine Learning. 61Burr Settles. 2012. Active learning. Synthesis Lec- tures on Artificial Intelligence and Machine Learn- ing, 6(1):1-114.\n\nActive learning with rationales for text classification. Manali Sharma, Di Zhuang, Mustafa Bilgic, Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesManali Sharma, Di Zhuang, and Mustafa Bilgic. 2015. Active learning with rationales for text classification. In Proceedings of the 2015 Conference of the North American Chapter of the Association for Computa- tional Linguistics: Human Language Technologies, pages 441-451.\n\nThe constrained weight space svm: learning with ranked features. Kevin Small, C Byron, Carla E Wallace, Thomas A Brodley, Trikalinos, Proceedings of the International Conference on International Conference on Machine Learning (ICML). the International Conference on International Conference on Machine Learning (ICML)Kevin Small, Byron C Wallace, Carla E Brodley, and Thomas A Trikalinos. 2011. The constrained weight space svm: learning with ranked features. In Pro- ceedings of the International Conference on Inter- national Conference on Machine Learning (ICML), pages 865-872.\n\nDaniel Smilkov, Nikhil Thorat, Been Kim, Fernanda Vi\u00e9gas, Martin Wattenberg, arXiv:1706.03825Smoothgrad: removing noise by adding noise. arXiv preprintDaniel Smilkov, Nikhil Thorat, Been Kim, Fernanda Vi\u00e9gas, and Martin Wattenberg. 2017. Smoothgrad: removing noise by adding noise. arXiv preprint arXiv:1706.03825.\n\n. Robyn Speer, 10.5281/zenodo.2591652ftfy. Zenodo. Version. 5Robyn Speer. 2019. ftfy. Zenodo. Version 5.5.\n\nDropout: A simple way to prevent neural networks from overfitting. Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, Ruslan Salakhutdinov, Journal of Machine Learning Research. 15Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan Salakhutdinov. 2014. Dropout: A simple way to prevent neural networks from overfitting. Journal of Machine Learning Re- search, 15:1929-1958.\n\nJulia Strout, Ye Zhang, Raymond J Mooney, arXiv:1905.13714Do human rationales improve machine explanations? arXiv preprint. Julia Strout, Ye Zhang, and Raymond J Mooney. 2019. Do human rationales improve machine expla- nations? arXiv preprint arXiv:1905.13714.\n\nAxiomatic attribution for deep networks. Mukund Sundararajan, Ankur Taly, Qiqi Yan, Proceedings of the 34th International Conference on Machine Learning. the 34th International Conference on Machine LearningJMLR. org70Mukund Sundararajan, Ankur Taly, and Qiqi Yan. 2017. Axiomatic attribution for deep networks. In Pro- ceedings of the 34th International Conference on Machine Learning-Volume 70, pages 3319-3328. JMLR. org.\n\nCommonsenseQA: A question answering challenge targeting commonsense knowledge. Alon Talmor, Jonathan Herzig, Nicholas Lourie, Jonathan Berant, 10.18653/v1/N19-1421Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesMinneapolis, MinnesotaLong and Short Papers1Association for Computational LinguisticsAlon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant. 2019. CommonsenseQA: A ques- tion answering challenge targeting commonsense knowledge. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), pages 4149-4158, Minneapolis, Minnesota. Associ- ation for Computational Linguistics.\n\nFEVER: a Large-scale Dataset for Fact Extraction and VERification. James Thorne, Andreas Vlachos, Christos Christodoulopoulos, Arpit Mittal, Proceedings of the North American Chapter of the Association for Computational Linguistics (NAACL). the North American Chapter of the Association for Computational Linguistics (NAACL)James Thorne, Andreas Vlachos, Christos Christodoulopoulos, and Arpit Mittal. 2018. FEVER: a Large-scale Dataset for Fact Extraction and VERification. In Proceedings of the North American Chapter of the Association for Computa- tional Linguistics (NAACL), pages 809-819.\n\nShikhar Vashishth, Shyam Upadhyay, Gaurav Singh Tomar, Manaal Faruqui, arXiv:1909.11218Attention interpretability across nlp tasks. arXiv preprintShikhar Vashishth, Shyam Upadhyay, Gaurav Singh Tomar, and Manaal Faruqui. 2019. Attention in- terpretability across nlp tasks. arXiv preprint arXiv:1909.11218.\n\nAttention is all you need. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, Illia Polosukhin, Advances in neural information processing systems. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. 2017. Attention is all you need. In Advances in neural information pro- cessing systems, pages 5998-6008.\n\nSuperglue: A stickier benchmark for general-purpose language understanding systems. Alex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, Samuel R Bowman, abs/1905.00537CoRR. Alex Wang, Yada Pruksachatkun, Nikita Nangia, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R. Bowman. 2019a. Superglue: A stickier benchmark for general-purpose language understanding systems. CoRR, abs/1905.00537.\n\nGLUE: A multi-task benchmark and analysis platform for natural language understanding. Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, Samuel R Bowman, International Conference on Learning Representations. Alex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R. Bowman. 2019b. GLUE: A multi-task benchmark and analysis plat- form for natural language understanding. In Inter- national Conference on Learning Representations.\n\nAttention is not not explanation. Sarah Wiegreffe, Yuval Pinter, arXiv:1908.04626arXiv preprintSarah Wiegreffe and Yuval Pinter. 2019. Atten- tion is not not explanation. arXiv preprint arXiv:1908.04626.\n\nSimple statistical gradientfollowing algorithms for connectionist reinforcement learning. J Ronald, Williams, Machine learning. 83-4Ronald J Williams. 1992. Simple statistical gradient- following algorithms for connectionist reinforce- ment learning. Machine learning, 8(3-4):229-256.\n\nHuggingface's transformers: State-of-the-art natural language processing. Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pierric Cistac, Tim Rault, R&apos;emi Louf, Morgan Funtowicz, Jamie Brew, abs/1910.03771ArXiv. Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi, Pier- ric Cistac, Tim Rault, R'emi Louf, Morgan Funtow- icz, and Jamie Brew. 2019. Huggingface's trans- formers: State-of-the-art natural language process- ing. ArXiv, abs/1910.03771.\n\nRethinking cooperative rationalization: Introspective extraction and complement control. Mo Yu, Shiyu Chang, Yang Zhang, Tommi S Jaakkola, arXiv:1910.13294arXiv preprintMo Yu, Shiyu Chang, Yang Zhang, and Tommi S Jaakkola. 2019. Rethinking cooperative rationaliza- tion: Introspective extraction and complement con- trol. arXiv preprint arXiv:1910.13294.\n\nUsing annotator rationales to improve machine learning for text categorization. Omar Zaidan, Jason Eisner, Christine Piatko, Proceedings of the conference of the North American chapter of the Association for Computational Linguistics (NAACL). the conference of the North American chapter of the Association for Computational Linguistics (NAACL)Omar Zaidan, Jason Eisner, and Christine Piatko. 2007. Using annotator rationales to improve ma- chine learning for text categorization. In Proceed- ings of the conference of the North American chap- ter of the Association for Computational Linguistics (NAACL), pages 260-267.\n\nModeling annotators: A generative approach to learning from annotator rationales. F Omar, Jason Zaidan, Eisner, Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP). the Conference on Empirical Methods in Natural Language Processing (EMNLP)Omar F Zaidan and Jason Eisner. 2008. Modeling an- notators: A generative approach to learning from an- notator rationales. In Proceedings of the Conference on Empirical Methods in Natural Language Process- ing (EMNLP), pages 31-40.\n\nRationale-augmented convolutional neural networks for text classification. Ye Zhang, Iain Marshall, Byron C Wallace, Proceedings of the Conference on Empirical Methods in Natural Language Processing. the Conference on Empirical Methods in Natural Language ProcessingNIH Public Access2016795Ye Zhang, Iain Marshall, and Byron C Wallace. 2016. Rationale-augmented convolutional neural networks for text classification. In Proceedings of the Con- ference on Empirical Methods in Natural Language Processing (EMNLP), volume 2016, page 795. NIH Public Access.\n\nFine-grained sentiment analysis with faithful attention. Ruiqi Zhong, Steven Shao, Kathleen Mckeown, arXiv:1908.06870arXiv preprintRuiqi Zhong, Steven Shao, and Kathleen McKeown. 2019. Fine-grained sentiment analysis with faithful attention. arXiv preprint arXiv:1908.06870.\n", "annotations": {"author": "[{\"end\":195,\"start\":59},{\"end\":333,\"start\":196},{\"end\":471,\"start\":334},{\"end\":604,\"start\":472},{\"end\":739,\"start\":605},{\"end\":876,\"start\":740},{\"end\":1001,\"start\":877},{\"end\":1139,\"start\":1002},{\"end\":1278,\"start\":1140}]", "publisher": null, "author_last_name": "[{\"end\":72,\"start\":65},{\"end\":210,\"start\":208},{\"end\":348,\"start\":342},{\"end\":481,\"start\":479},{\"end\":616,\"start\":610},{\"end\":753,\"start\":748},{\"end\":1016,\"start\":1010},{\"end\":1155,\"start\":1148}]", "author_first_name": "[{\"end\":64,\"start\":61},{\"end\":207,\"start\":203},{\"end\":341,\"start\":334},{\"end\":478,\"start\":472},{\"end\":609,\"start\":605},{\"end\":747,\"start\":740},{\"end\":878,\"start\":877},{\"end\":1009,\"start\":1002},{\"end\":1145,\"start\":1140},{\"end\":1147,\"start\":1146}]", "author_affiliation": "[{\"end\":194,\"start\":74},{\"end\":332,\"start\":212},{\"end\":470,\"start\":350},{\"end\":603,\"start\":483},{\"end\":738,\"start\":618},{\"end\":875,\"start\":755},{\"end\":1000,\"start\":880},{\"end\":1138,\"start\":1018},{\"end\":1277,\"start\":1157}]", "title": "[{\"end\":56,\"start\":1},{\"end\":1334,\"start\":1279}]", "venue": null, "abstract": "[{\"end\":2536,\"start\":1336}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b48\"},\"end\":3934,\"start\":3914},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":3969,\"start\":3949},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":4401,\"start\":4374},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":4414,\"start\":4401},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":8456,\"start\":8439},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":9608,\"start\":9584},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":9632,\"start\":9608},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":9659,\"start\":9632},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":9678,\"start\":9659},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":9698,\"start\":9678},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":9719,\"start\":9698},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":9739,\"start\":9719},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":9762,\"start\":9739},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":10277,\"start\":10259},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":10293,\"start\":10277},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":10312,\"start\":10295},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":11112,\"start\":11085},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":11133,\"start\":11112},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":11395,\"start\":11376},{\"end\":11398,\"start\":11397},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":11434,\"start\":11414},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":11562,\"start\":11542},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":11872,\"start\":11850},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":12354,\"start\":12329},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":12405,\"start\":12383},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":12430,\"start\":12405},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":12634,\"start\":12620},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":12792,\"start\":12772},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":13380,\"start\":13359},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":13404,\"start\":13380},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":13631,\"start\":13610},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":13650,\"start\":13631},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":13749,\"start\":13724},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":13881,\"start\":13862},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":14071,\"start\":14051},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":14593,\"start\":14572},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":14611,\"start\":14593},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":14646,\"start\":14625},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":14686,\"start\":14665},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":15051,\"start\":15030},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":15123,\"start\":15101},{\"end\":15150,\"start\":15134},{\"end\":16963,\"start\":16962},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":17315,\"start\":17294},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":17893,\"start\":17873},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":18348,\"start\":18323},{\"end\":18741,\"start\":18719},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":18772,\"start\":18751},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":19152,\"start\":19129},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":21230,\"start\":21205},{\"end\":22264,\"start\":22263},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":23723,\"start\":23702},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":23739,\"start\":23723},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":23782,\"start\":23766},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":24202,\"start\":24181},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":26788,\"start\":26763},{\"end\":27839,\"start\":27838},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":31221,\"start\":31204},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":31643,\"start\":31626},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":32168,\"start\":32151},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":32223,\"start\":32202},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":32294,\"start\":32261},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":32954,\"start\":32937},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":34011,\"start\":33990},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":34143,\"start\":34122},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":34875,\"start\":34854},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":34997,\"start\":34963},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":35705,\"start\":35680},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":35981,\"start\":35960},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":36780,\"start\":36763},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":36834,\"start\":36814},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":37197,\"start\":37180},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":37354,\"start\":37334},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":37374,\"start\":37354},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":37399,\"start\":37382},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":37475,\"start\":37455},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":37507,\"start\":37490},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":37742,\"start\":37725},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":41181,\"start\":41163},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":41384,\"start\":41365},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":41514,\"start\":41489},{\"end\":42169,\"start\":42164},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":42244,\"start\":42222},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":42597,\"start\":42572},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":42681,\"start\":42659},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":42800,\"start\":42775},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":43208,\"start\":43186},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":45645,\"start\":45624},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":45731,\"start\":45710},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":46047,\"start\":46026},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":46160,\"start\":46138},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":46236,\"start\":46215},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":50587,\"start\":50567}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":43544,\"start\":43210},{\"attributes\":{\"id\":\"fig_1\"},\"end\":43706,\"start\":43545},{\"attributes\":{\"id\":\"fig_4\"},\"end\":44109,\"start\":43707},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":45213,\"start\":44110},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":45589,\"start\":45214},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":46818,\"start\":45590},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":47355,\"start\":46819},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":48332,\"start\":47356},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":49410,\"start\":48333},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":50193,\"start\":49411}]", "paragraph": "[{\"end\":3089,\"start\":2552},{\"end\":3169,\"start\":3126},{\"end\":3419,\"start\":3250},{\"end\":3827,\"start\":3442},{\"end\":4304,\"start\":3829},{\"end\":4935,\"start\":4306},{\"end\":5381,\"start\":4937},{\"end\":6023,\"start\":5383},{\"end\":6684,\"start\":6025},{\"end\":7093,\"start\":6686},{\"end\":7329,\"start\":7123},{\"end\":7763,\"start\":7331},{\"end\":8117,\"start\":7765},{\"end\":8611,\"start\":8119},{\"end\":8888,\"start\":8628},{\"end\":9205,\"start\":8890},{\"end\":10737,\"start\":9207},{\"end\":11739,\"start\":10739},{\"end\":12100,\"start\":11741},{\"end\":12597,\"start\":12102},{\"end\":13205,\"start\":12599},{\"end\":13750,\"start\":13207},{\"end\":14612,\"start\":13752},{\"end\":14978,\"start\":14614},{\"end\":15647,\"start\":14980},{\"end\":16325,\"start\":15649},{\"end\":16763,\"start\":16348},{\"end\":17273,\"start\":16765},{\"end\":17865,\"start\":17275},{\"end\":18307,\"start\":17867},{\"end\":18743,\"start\":18309},{\"end\":19119,\"start\":18745},{\"end\":20178,\"start\":19121},{\"end\":20924,\"start\":20214},{\"end\":21757,\"start\":20926},{\"end\":22514,\"start\":21759},{\"end\":22955,\"start\":22516},{\"end\":23531,\"start\":22982},{\"end\":24091,\"start\":23533},{\"end\":24824,\"start\":24093},{\"end\":25241,\"start\":24858},{\"end\":25550,\"start\":25243},{\"end\":27327,\"start\":25578},{\"end\":27543,\"start\":27329},{\"end\":28146,\"start\":27563},{\"end\":28448,\"start\":28148},{\"end\":28660,\"start\":28450},{\"end\":30314,\"start\":29072},{\"end\":31779,\"start\":30922},{\"end\":32124,\"start\":31781},{\"end\":32998,\"start\":32126},{\"end\":33391,\"start\":33000},{\"end\":34144,\"start\":33393},{\"end\":34519,\"start\":34146},{\"end\":35750,\"start\":34538},{\"end\":35897,\"start\":35752},{\"end\":35939,\"start\":35912},{\"end\":36663,\"start\":35941},{\"end\":37129,\"start\":36665},{\"end\":37777,\"start\":37131},{\"end\":38799,\"start\":37779},{\"end\":39116,\"start\":38801},{\"end\":39630,\"start\":39131},{\"end\":40116,\"start\":39632},{\"end\":40913,\"start\":40118},{\"end\":41182,\"start\":40915},{\"end\":41757,\"start\":41193},{\"end\":42082,\"start\":41759},{\"end\":42170,\"start\":42084},{\"end\":42245,\"start\":42172},{\"end\":42439,\"start\":42274},{\"end\":42982,\"start\":42476},{\"end\":43209,\"start\":43009}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":24857,\"start\":24825},{\"attributes\":{\"id\":\"formula_1\"},\"end\":25577,\"start\":25551},{\"attributes\":{\"id\":\"formula_2\"},\"end\":30904,\"start\":30315}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":22954,\"start\":22947},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":26091,\"start\":26084},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":28582,\"start\":28573},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":36359,\"start\":36352},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":37789,\"start\":37782}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2550,\"start\":2538},{\"end\":3124,\"start\":3092},{\"end\":3232,\"start\":3172},{\"end\":3248,\"start\":3235},{\"end\":3440,\"start\":3422},{\"attributes\":{\"n\":\"2\"},\"end\":7121,\"start\":7096},{\"attributes\":{\"n\":\"3\"},\"end\":8626,\"start\":8614},{\"attributes\":{\"n\":\"4\"},\"end\":16346,\"start\":16328},{\"attributes\":{\"n\":\"5.1\"},\"end\":20212,\"start\":20181},{\"attributes\":{\"n\":\"5.2\"},\"end\":22980,\"start\":22958},{\"attributes\":{\"n\":\"6\"},\"end\":27561,\"start\":27546},{\"end\":29070,\"start\":28663},{\"attributes\":{\"n\":\"6.1\"},\"end\":30920,\"start\":30906},{\"attributes\":{\"n\":\"6.2\"},\"end\":34536,\"start\":34522},{\"attributes\":{\"n\":\"7\"},\"end\":35910,\"start\":35900},{\"attributes\":{\"n\":\"8\"},\"end\":39129,\"start\":39119},{\"end\":41191,\"start\":41185},{\"end\":42272,\"start\":42248},{\"end\":42474,\"start\":42442},{\"end\":43007,\"start\":42985},{\"end\":43216,\"start\":43211},{\"end\":43556,\"start\":43546},{\"end\":43718,\"start\":43708},{\"end\":44122,\"start\":44111},{\"end\":45224,\"start\":45215},{\"end\":46829,\"start\":46820},{\"end\":48343,\"start\":48334},{\"end\":49421,\"start\":49412}]", "table": "[{\"end\":45213,\"start\":44597},{\"end\":47355,\"start\":46831},{\"end\":48332,\"start\":47409},{\"end\":49410,\"start\":48880}]", "figure_caption": "[{\"end\":43544,\"start\":43218},{\"end\":43706,\"start\":43558},{\"end\":44109,\"start\":43720},{\"end\":44597,\"start\":44125},{\"end\":45589,\"start\":45226},{\"end\":46818,\"start\":45592},{\"end\":47409,\"start\":47358},{\"end\":48880,\"start\":48345},{\"end\":50193,\"start\":49423}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":25619,\"start\":25611}]", "bib_author_first_name": "[{\"end\":55698,\"start\":55693},{\"end\":55719,\"start\":55714},{\"end\":56217,\"start\":56210},{\"end\":56237,\"start\":56228},{\"end\":56249,\"start\":56243},{\"end\":56509,\"start\":56507},{\"end\":56523,\"start\":56519},{\"end\":56533,\"start\":56528},{\"end\":56728,\"start\":56727},{\"end\":56742,\"start\":56737},{\"end\":56762,\"start\":56751},{\"end\":56782,\"start\":56771},{\"end\":56784,\"start\":56783},{\"end\":57389,\"start\":57385},{\"end\":57403,\"start\":57399},{\"end\":57415,\"start\":57409},{\"end\":57431,\"start\":57425},{\"end\":57446,\"start\":57441},{\"end\":57764,\"start\":57754},{\"end\":57777,\"start\":57774},{\"end\":57797,\"start\":57791},{\"end\":57815,\"start\":57811},{\"end\":58196,\"start\":58191},{\"end\":58209,\"start\":58203},{\"end\":58227,\"start\":58220},{\"end\":58238,\"start\":58233},{\"end\":58258,\"start\":58255},{\"end\":58963,\"start\":58954},{\"end\":58973,\"start\":58969},{\"end\":58997,\"start\":58991},{\"end\":59015,\"start\":59008},{\"end\":59031,\"start\":59026},{\"end\":59048,\"start\":59042},{\"end\":59064,\"start\":59058},{\"end\":59444,\"start\":59433},{\"end\":59458,\"start\":59452},{\"end\":59472,\"start\":59464},{\"end\":59483,\"start\":59480},{\"end\":59504,\"start\":59497},{\"end\":59522,\"start\":59514},{\"end\":59740,\"start\":59735},{\"end\":59757,\"start\":59749},{\"end\":59771,\"start\":59765},{\"end\":59785,\"start\":59777},{\"end\":60167,\"start\":60161},{\"end\":60176,\"start\":60175},{\"end\":60188,\"start\":60184},{\"end\":60413,\"start\":60409},{\"end\":60429,\"start\":60426},{\"end\":60441,\"start\":60440},{\"end\":60443,\"start\":60442},{\"end\":60461,\"start\":60457},{\"end\":60478,\"start\":60472},{\"end\":60779,\"start\":60775},{\"end\":60804,\"start\":60799},{\"end\":60819,\"start\":60814},{\"end\":60833,\"start\":60827},{\"end\":61213,\"start\":61209},{\"end\":61227,\"start\":61223},{\"end\":61238,\"start\":61234},{\"end\":61254,\"start\":61248},{\"end\":61271,\"start\":61264},{\"end\":61286,\"start\":61280},{\"end\":61288,\"start\":61287},{\"end\":61301,\"start\":61294},{\"end\":61317,\"start\":61310},{\"end\":61331,\"start\":61327},{\"end\":61333,\"start\":61332},{\"end\":61590,\"start\":61586},{\"end\":61609,\"start\":61603},{\"end\":61789,\"start\":61782},{\"end\":61797,\"start\":61796},{\"end\":62049,\"start\":62043},{\"end\":62067,\"start\":62060},{\"end\":62087,\"start\":62080},{\"end\":62099,\"start\":62094},{\"end\":62113,\"start\":62110},{\"end\":62702,\"start\":62701},{\"end\":62718,\"start\":62713},{\"end\":62930,\"start\":62926},{\"end\":62942,\"start\":62939},{\"end\":62958,\"start\":62952},{\"end\":62974,\"start\":62969},{\"end\":62976,\"start\":62975},{\"end\":63478,\"start\":63475},{\"end\":63490,\"start\":63484},{\"end\":63506,\"start\":63501},{\"end\":63875,\"start\":63870},{\"end\":63894,\"start\":63887},{\"end\":64194,\"start\":64189},{\"end\":64213,\"start\":64206},{\"end\":64228,\"start\":64221},{\"end\":64241,\"start\":64236},{\"end\":64619,\"start\":64614},{\"end\":64635,\"start\":64628},{\"end\":64652,\"start\":64647},{\"end\":64868,\"start\":64864},{\"end\":64884,\"start\":64878},{\"end\":65247,\"start\":65245},{\"end\":65261,\"start\":65254},{\"end\":65848,\"start\":65847},{\"end\":66024,\"start\":66017},{\"end\":66044,\"start\":66037},{\"end\":66064,\"start\":66053},{\"end\":66674,\"start\":66668},{\"end\":66688,\"start\":66683},{\"end\":66702,\"start\":66696},{\"end\":66718,\"start\":66712},{\"end\":66734,\"start\":66727},{\"end\":66736,\"start\":66735},{\"end\":67025,\"start\":67020},{\"end\":67040,\"start\":67035},{\"end\":67053,\"start\":67049},{\"end\":67065,\"start\":67060},{\"end\":67083,\"start\":67077},{\"end\":67351,\"start\":67347},{\"end\":67368,\"start\":67361},{\"end\":67588,\"start\":67583},{\"end\":67619,\"start\":67612},{\"end\":67635,\"start\":67628},{\"end\":68069,\"start\":68064},{\"end\":68085,\"start\":68079},{\"end\":68099,\"start\":68093},{\"end\":68682,\"start\":68679},{\"end\":68694,\"start\":68693},{\"end\":68716,\"start\":68702},{\"end\":68729,\"start\":68723},{\"end\":68741,\"start\":68735},{\"end\":68759,\"start\":68753},{\"end\":68977,\"start\":68972},{\"end\":68988,\"start\":68987},{\"end\":69181,\"start\":69177},{\"end\":69446,\"start\":69440},{\"end\":69457,\"start\":69455},{\"end\":69473,\"start\":69466},{\"end\":70097,\"start\":70092},{\"end\":70106,\"start\":70105},{\"end\":70119,\"start\":70114},{\"end\":70121,\"start\":70120},{\"end\":70137,\"start\":70131},{\"end\":70139,\"start\":70138},{\"end\":70616,\"start\":70610},{\"end\":70632,\"start\":70626},{\"end\":70645,\"start\":70641},{\"end\":70659,\"start\":70651},{\"end\":70674,\"start\":70668},{\"end\":70933,\"start\":70928},{\"end\":71107,\"start\":71101},{\"end\":71128,\"start\":71120},{\"end\":71141,\"start\":71137},{\"end\":71158,\"start\":71154},{\"end\":71176,\"start\":71170},{\"end\":71460,\"start\":71455},{\"end\":71471,\"start\":71469},{\"end\":71488,\"start\":71479},{\"end\":71764,\"start\":71758},{\"end\":71784,\"start\":71779},{\"end\":71795,\"start\":71791},{\"end\":72226,\"start\":72222},{\"end\":72243,\"start\":72235},{\"end\":72260,\"start\":72252},{\"end\":72277,\"start\":72269},{\"end\":73157,\"start\":73152},{\"end\":73173,\"start\":73166},{\"end\":73191,\"start\":73183},{\"end\":73217,\"start\":73212},{\"end\":73688,\"start\":73681},{\"end\":73705,\"start\":73700},{\"end\":73722,\"start\":73716},{\"end\":73742,\"start\":73736},{\"end\":74022,\"start\":74016},{\"end\":74036,\"start\":74032},{\"end\":74050,\"start\":74046},{\"end\":74064,\"start\":74059},{\"end\":74081,\"start\":74076},{\"end\":74094,\"start\":74089},{\"end\":74096,\"start\":74095},{\"end\":74110,\"start\":74104},{\"end\":74124,\"start\":74119},{\"end\":74508,\"start\":74504},{\"end\":74519,\"start\":74515},{\"end\":74541,\"start\":74535},{\"end\":74559,\"start\":74550},{\"end\":74573,\"start\":74567},{\"end\":74588,\"start\":74583},{\"end\":74599,\"start\":74595},{\"end\":74612,\"start\":74606},{\"end\":74614,\"start\":74613},{\"end\":74972,\"start\":74968},{\"end\":74988,\"start\":74979},{\"end\":75002,\"start\":74996},{\"end\":75017,\"start\":75012},{\"end\":75028,\"start\":75024},{\"end\":75041,\"start\":75035},{\"end\":75043,\"start\":75042},{\"end\":75390,\"start\":75385},{\"end\":75407,\"start\":75402},{\"end\":75647,\"start\":75646},{\"end\":75922,\"start\":75916},{\"end\":75937,\"start\":75929},{\"end\":75951,\"start\":75945},{\"end\":75964,\"start\":75958},{\"end\":75982,\"start\":75975},{\"end\":76000,\"start\":75993},{\"end\":76013,\"start\":76006},{\"end\":76025,\"start\":76022},{\"end\":76043,\"start\":76033},{\"end\":76056,\"start\":76050},{\"end\":76073,\"start\":76068},{\"end\":76467,\"start\":76465},{\"end\":76477,\"start\":76472},{\"end\":76489,\"start\":76485},{\"end\":76502,\"start\":76497},{\"end\":76504,\"start\":76503},{\"end\":76816,\"start\":76812},{\"end\":76830,\"start\":76825},{\"end\":76848,\"start\":76839},{\"end\":77437,\"start\":77436},{\"end\":77449,\"start\":77444},{\"end\":77942,\"start\":77940},{\"end\":77954,\"start\":77950},{\"end\":77970,\"start\":77965},{\"end\":77972,\"start\":77971},{\"end\":78483,\"start\":78478},{\"end\":78497,\"start\":78491},{\"end\":78512,\"start\":78504}]", "bib_author_last_name": "[{\"end\":55712,\"start\":55699},{\"end\":55728,\"start\":55720},{\"end\":56226,\"start\":56218},{\"end\":56241,\"start\":56238},{\"end\":56256,\"start\":56250},{\"end\":56517,\"start\":56510},{\"end\":56526,\"start\":56524},{\"end\":56539,\"start\":56534},{\"end\":56735,\"start\":56729},{\"end\":56749,\"start\":56743},{\"end\":56769,\"start\":56763},{\"end\":56790,\"start\":56785},{\"end\":56799,\"start\":56792},{\"end\":57397,\"start\":57390},{\"end\":57407,\"start\":57404},{\"end\":57423,\"start\":57416},{\"end\":57439,\"start\":57432},{\"end\":57458,\"start\":57447},{\"end\":57772,\"start\":57765},{\"end\":57789,\"start\":57778},{\"end\":57809,\"start\":57798},{\"end\":57823,\"start\":57816},{\"end\":58201,\"start\":58197},{\"end\":58218,\"start\":58210},{\"end\":58231,\"start\":58228},{\"end\":58253,\"start\":58239},{\"end\":58263,\"start\":58259},{\"end\":58967,\"start\":58964},{\"end\":58989,\"start\":58974},{\"end\":59006,\"start\":58998},{\"end\":59024,\"start\":59016},{\"end\":59040,\"start\":59032},{\"end\":59056,\"start\":59049},{\"end\":59071,\"start\":59065},{\"end\":59450,\"start\":59445},{\"end\":59462,\"start\":59459},{\"end\":59478,\"start\":59473},{\"end\":59495,\"start\":59484},{\"end\":59512,\"start\":59505},{\"end\":59532,\"start\":59523},{\"end\":59747,\"start\":59741},{\"end\":59763,\"start\":59758},{\"end\":59775,\"start\":59772},{\"end\":59795,\"start\":59786},{\"end\":60173,\"start\":60168},{\"end\":60182,\"start\":60177},{\"end\":60192,\"start\":60189},{\"end\":60424,\"start\":60414},{\"end\":60438,\"start\":60430},{\"end\":60455,\"start\":60444},{\"end\":60470,\"start\":60462},{\"end\":60483,\"start\":60479},{\"end\":60494,\"start\":60485},{\"end\":60788,\"start\":60780},{\"end\":60797,\"start\":60790},{\"end\":60812,\"start\":60805},{\"end\":60825,\"start\":60820},{\"end\":60843,\"start\":60834},{\"end\":60856,\"start\":60845},{\"end\":61221,\"start\":61214},{\"end\":61232,\"start\":61228},{\"end\":61246,\"start\":61239},{\"end\":61262,\"start\":61255},{\"end\":61278,\"start\":61272},{\"end\":61292,\"start\":61289},{\"end\":61308,\"start\":61302},{\"end\":61325,\"start\":61318},{\"end\":61345,\"start\":61334},{\"end\":61601,\"start\":61591},{\"end\":61621,\"start\":61610},{\"end\":61794,\"start\":61790},{\"end\":61803,\"start\":61798},{\"end\":61812,\"start\":61805},{\"end\":62058,\"start\":62050},{\"end\":62078,\"start\":62068},{\"end\":62092,\"start\":62088},{\"end\":62108,\"start\":62100},{\"end\":62118,\"start\":62114},{\"end\":62711,\"start\":62703},{\"end\":62725,\"start\":62719},{\"end\":62729,\"start\":62727},{\"end\":62937,\"start\":62931},{\"end\":62950,\"start\":62943},{\"end\":62967,\"start\":62959},{\"end\":62984,\"start\":62977},{\"end\":63482,\"start\":63479},{\"end\":63499,\"start\":63491},{\"end\":63515,\"start\":63507},{\"end\":63635,\"start\":63619},{\"end\":63885,\"start\":63876},{\"end\":63900,\"start\":63895},{\"end\":64204,\"start\":64195},{\"end\":64219,\"start\":64214},{\"end\":64234,\"start\":64229},{\"end\":64249,\"start\":64242},{\"end\":64626,\"start\":64620},{\"end\":64645,\"start\":64636},{\"end\":64659,\"start\":64653},{\"end\":64876,\"start\":64869},{\"end\":64889,\"start\":64885},{\"end\":65252,\"start\":65248},{\"end\":65265,\"start\":65262},{\"end\":65854,\"start\":65849},{\"end\":65862,\"start\":65856},{\"end\":66035,\"start\":66025},{\"end\":66051,\"start\":66045},{\"end\":66072,\"start\":66065},{\"end\":66681,\"start\":66675},{\"end\":66694,\"start\":66689},{\"end\":66710,\"start\":66703},{\"end\":66725,\"start\":66719},{\"end\":66743,\"start\":66737},{\"end\":67033,\"start\":67026},{\"end\":67047,\"start\":67041},{\"end\":67058,\"start\":67054},{\"end\":67075,\"start\":67066},{\"end\":67093,\"start\":67084},{\"end\":67359,\"start\":67352},{\"end\":67379,\"start\":67369},{\"end\":67610,\"start\":67589},{\"end\":67626,\"start\":67620},{\"end\":67641,\"start\":67636},{\"end\":67649,\"start\":67643},{\"end\":68077,\"start\":68070},{\"end\":68091,\"start\":68086},{\"end\":68108,\"start\":68100},{\"end\":68691,\"start\":68683},{\"end\":68700,\"start\":68695},{\"end\":68721,\"start\":68717},{\"end\":68733,\"start\":68730},{\"end\":68751,\"start\":68742},{\"end\":68766,\"start\":68760},{\"end\":68776,\"start\":68768},{\"end\":68985,\"start\":68978},{\"end\":68993,\"start\":68989},{\"end\":69000,\"start\":68995},{\"end\":69189,\"start\":69182},{\"end\":69453,\"start\":69447},{\"end\":69464,\"start\":69458},{\"end\":69480,\"start\":69474},{\"end\":70103,\"start\":70098},{\"end\":70112,\"start\":70107},{\"end\":70129,\"start\":70122},{\"end\":70147,\"start\":70140},{\"end\":70159,\"start\":70149},{\"end\":70624,\"start\":70617},{\"end\":70639,\"start\":70633},{\"end\":70649,\"start\":70646},{\"end\":70666,\"start\":70660},{\"end\":70685,\"start\":70675},{\"end\":70939,\"start\":70934},{\"end\":71118,\"start\":71108},{\"end\":71135,\"start\":71129},{\"end\":71152,\"start\":71142},{\"end\":71168,\"start\":71159},{\"end\":71190,\"start\":71177},{\"end\":71467,\"start\":71461},{\"end\":71477,\"start\":71472},{\"end\":71495,\"start\":71489},{\"end\":71777,\"start\":71765},{\"end\":71789,\"start\":71785},{\"end\":71799,\"start\":71796},{\"end\":72233,\"start\":72227},{\"end\":72250,\"start\":72244},{\"end\":72267,\"start\":72261},{\"end\":72284,\"start\":72278},{\"end\":73164,\"start\":73158},{\"end\":73181,\"start\":73174},{\"end\":73210,\"start\":73192},{\"end\":73224,\"start\":73218},{\"end\":73698,\"start\":73689},{\"end\":73714,\"start\":73706},{\"end\":73734,\"start\":73723},{\"end\":73750,\"start\":73743},{\"end\":74030,\"start\":74023},{\"end\":74044,\"start\":74037},{\"end\":74057,\"start\":74051},{\"end\":74074,\"start\":74065},{\"end\":74087,\"start\":74082},{\"end\":74102,\"start\":74097},{\"end\":74117,\"start\":74111},{\"end\":74135,\"start\":74125},{\"end\":74513,\"start\":74509},{\"end\":74533,\"start\":74520},{\"end\":74548,\"start\":74542},{\"end\":74565,\"start\":74560},{\"end\":74581,\"start\":74574},{\"end\":74593,\"start\":74589},{\"end\":74604,\"start\":74600},{\"end\":74621,\"start\":74615},{\"end\":74977,\"start\":74973},{\"end\":74994,\"start\":74989},{\"end\":75010,\"start\":75003},{\"end\":75022,\"start\":75018},{\"end\":75033,\"start\":75029},{\"end\":75050,\"start\":75044},{\"end\":75400,\"start\":75391},{\"end\":75414,\"start\":75408},{\"end\":75654,\"start\":75648},{\"end\":75664,\"start\":75656},{\"end\":75927,\"start\":75923},{\"end\":75943,\"start\":75938},{\"end\":75956,\"start\":75952},{\"end\":75973,\"start\":75965},{\"end\":75991,\"start\":75983},{\"end\":76004,\"start\":76001},{\"end\":76020,\"start\":76014},{\"end\":76031,\"start\":76026},{\"end\":76048,\"start\":76044},{\"end\":76066,\"start\":76057},{\"end\":76078,\"start\":76074},{\"end\":76470,\"start\":76468},{\"end\":76483,\"start\":76478},{\"end\":76495,\"start\":76490},{\"end\":76513,\"start\":76505},{\"end\":76823,\"start\":76817},{\"end\":76837,\"start\":76831},{\"end\":76855,\"start\":76849},{\"end\":77442,\"start\":77438},{\"end\":77456,\"start\":77450},{\"end\":77464,\"start\":77458},{\"end\":77948,\"start\":77943},{\"end\":77963,\"start\":77955},{\"end\":77980,\"start\":77973},{\"end\":78489,\"start\":78484},{\"end\":78502,\"start\":78498},{\"end\":78520,\"start\":78513}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":5509327},\"end\":56137,\"start\":55601},{\"attributes\":{\"doi\":\"arXiv:1409.0473\",\"id\":\"b1\"},\"end\":56449,\"start\":56139},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":202558505},\"end\":56659,\"start\":56451},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":14604520},\"end\":57311,\"start\":56661},{\"attributes\":{\"doi\":\"arXiv:1908.04211\",\"id\":\"b4\"},\"end\":57681,\"start\":57313},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":54040953},\"end\":58104,\"start\":57683},{\"attributes\":{\"doi\":\"10.18653/v1/N19-1053\",\"id\":\"b6\",\"matched_paper_id\":85556928},\"end\":58857,\"start\":58106},{\"attributes\":{\"doi\":\"arXiv:1406.1078\",\"id\":\"b7\"},\"end\":59359,\"start\":58859},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":165163607},\"end\":59733,\"start\":59361},{\"attributes\":{\"doi\":\"arXiv:1810.04805\",\"id\":\"b9\"},\"end\":60097,\"start\":59735},{\"attributes\":{\"doi\":\"arXiv:1702.08608\",\"id\":\"b10\"},\"end\":60357,\"start\":60099},{\"attributes\":{\"doi\":\"10.1007/s11263-009-0275-4\",\"id\":\"b11\",\"matched_paper_id\":4246903},\"end\":60773,\"start\":60359},{\"attributes\":{\"doi\":\"arXiv:1804.07781\",\"id\":\"b12\"},\"end\":61143,\"start\":60775},{\"attributes\":{\"id\":\"b13\"},\"end\":61560,\"start\":61145},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":1915014},\"end\":61750,\"start\":61562},{\"attributes\":{\"doi\":\"arXiv:1902.10186\",\"id\":\"b15\"},\"end\":61946,\"start\":61752},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":5112038},\"end\":62655,\"start\":61948},{\"attributes\":{\"doi\":\"abs/1412.6980\",\"id\":\"b17\"},\"end\":62851,\"start\":62657},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":102352181},\"end\":63439,\"start\":62853},{\"attributes\":{\"id\":\"b19\"},\"end\":63617,\"start\":63441},{\"attributes\":{\"doi\":\"arXiv:1606.03490\",\"id\":\"b20\"},\"end\":63801,\"start\":63619},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":5771562},\"end\":64108,\"start\":63803},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":6166051},\"end\":64532,\"start\":64110},{\"attributes\":{\"doi\":\"arXiv:1910.00139\",\"id\":\"b23\"},\"end\":64862,\"start\":64534},{\"attributes\":{\"id\":\"b24\"},\"end\":65143,\"start\":64864},{\"attributes\":{\"doi\":\"10.3115/1218955.1218990\",\"id\":\"b25\",\"matched_paper_id\":388},\"end\":65756,\"start\":65145},{\"attributes\":{\"id\":\"b26\"},\"end\":65968,\"start\":65758},{\"attributes\":{\"doi\":\"10.3115/v1/D14-1162\",\"id\":\"b27\",\"matched_paper_id\":1957433},\"end\":66611,\"start\":65970},{\"attributes\":{\"doi\":\"arXiv:1909.07913\",\"id\":\"b28\"},\"end\":66951,\"start\":66613},{\"attributes\":{\"id\":\"b29\"},\"end\":67250,\"start\":66953},{\"attributes\":{\"id\":\"b30\"},\"end\":67509,\"start\":67252},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":174803111},\"end\":67991,\"start\":67511},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":13029170},\"end\":68633,\"start\":67993},{\"attributes\":{\"doi\":\"abs/1908.05267\",\"id\":\"b33\"},\"end\":68970,\"start\":68635},{\"attributes\":{\"doi\":\"arXiv:1906.03731\",\"id\":\"b34\"},\"end\":69158,\"start\":68972},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":30334806},\"end\":69381,\"start\":69160},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":5832223},\"end\":70025,\"start\":69383},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":18731059},\"end\":70608,\"start\":70027},{\"attributes\":{\"doi\":\"arXiv:1706.03825\",\"id\":\"b38\"},\"end\":70924,\"start\":70610},{\"attributes\":{\"doi\":\"10.5281/zenodo.2591652\",\"id\":\"b39\"},\"end\":71032,\"start\":70926},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":6844431},\"end\":71453,\"start\":71034},{\"attributes\":{\"doi\":\"arXiv:1905.13714\",\"id\":\"b41\"},\"end\":71715,\"start\":71455},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":16747630},\"end\":72141,\"start\":71717},{\"attributes\":{\"doi\":\"10.18653/v1/N19-1421\",\"id\":\"b43\",\"matched_paper_id\":53296520},\"end\":73083,\"start\":72143},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":4711425},\"end\":73679,\"start\":73085},{\"attributes\":{\"doi\":\"arXiv:1909.11218\",\"id\":\"b45\"},\"end\":73987,\"start\":73681},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":13756489},\"end\":74418,\"start\":73989},{\"attributes\":{\"doi\":\"abs/1905.00537\",\"id\":\"b47\",\"matched_paper_id\":143424870},\"end\":74879,\"start\":74420},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":5034059},\"end\":75349,\"start\":74881},{\"attributes\":{\"doi\":\"arXiv:1908.04626\",\"id\":\"b49\"},\"end\":75554,\"start\":75351},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":2332513},\"end\":75840,\"start\":75556},{\"attributes\":{\"doi\":\"abs/1910.03771\",\"id\":\"b51\",\"matched_paper_id\":204509627},\"end\":76374,\"start\":75842},{\"attributes\":{\"doi\":\"arXiv:1910.13294\",\"id\":\"b52\"},\"end\":76730,\"start\":76376},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":3061036},\"end\":77352,\"start\":76732},{\"attributes\":{\"id\":\"b54\",\"matched_paper_id\":635609},\"end\":77863,\"start\":77354},{\"attributes\":{\"id\":\"b55\",\"matched_paper_id\":6262432},\"end\":78419,\"start\":77865},{\"attributes\":{\"doi\":\"arXiv:1908.06870\",\"id\":\"b56\"},\"end\":78695,\"start\":78421}]", "bib_title": "[{\"end\":55691,\"start\":55601},{\"end\":56505,\"start\":56451},{\"end\":56725,\"start\":56661},{\"end\":57752,\"start\":57683},{\"end\":58189,\"start\":58106},{\"end\":59431,\"start\":59361},{\"end\":60407,\"start\":60359},{\"end\":61584,\"start\":61562},{\"end\":62041,\"start\":61948},{\"end\":62924,\"start\":62853},{\"end\":63868,\"start\":63803},{\"end\":64187,\"start\":64110},{\"end\":65243,\"start\":65145},{\"end\":66015,\"start\":65970},{\"end\":67581,\"start\":67511},{\"end\":68062,\"start\":67993},{\"end\":69175,\"start\":69160},{\"end\":69438,\"start\":69383},{\"end\":70090,\"start\":70027},{\"end\":71099,\"start\":71034},{\"end\":71756,\"start\":71717},{\"end\":72220,\"start\":72143},{\"end\":73150,\"start\":73085},{\"end\":74014,\"start\":73989},{\"end\":74502,\"start\":74420},{\"end\":74966,\"start\":74881},{\"end\":75644,\"start\":75556},{\"end\":75914,\"start\":75842},{\"end\":76810,\"start\":76732},{\"end\":77434,\"start\":77354},{\"end\":77938,\"start\":77865}]", "bib_author": "[{\"end\":55714,\"start\":55693},{\"end\":55730,\"start\":55714},{\"end\":56228,\"start\":56210},{\"end\":56243,\"start\":56228},{\"end\":56258,\"start\":56243},{\"end\":56519,\"start\":56507},{\"end\":56528,\"start\":56519},{\"end\":56541,\"start\":56528},{\"end\":56737,\"start\":56727},{\"end\":56751,\"start\":56737},{\"end\":56771,\"start\":56751},{\"end\":56792,\"start\":56771},{\"end\":56801,\"start\":56792},{\"end\":57399,\"start\":57385},{\"end\":57409,\"start\":57399},{\"end\":57425,\"start\":57409},{\"end\":57441,\"start\":57425},{\"end\":57460,\"start\":57441},{\"end\":57774,\"start\":57754},{\"end\":57791,\"start\":57774},{\"end\":57811,\"start\":57791},{\"end\":57825,\"start\":57811},{\"end\":58203,\"start\":58191},{\"end\":58220,\"start\":58203},{\"end\":58233,\"start\":58220},{\"end\":58255,\"start\":58233},{\"end\":58265,\"start\":58255},{\"end\":58969,\"start\":58954},{\"end\":58991,\"start\":58969},{\"end\":59008,\"start\":58991},{\"end\":59026,\"start\":59008},{\"end\":59042,\"start\":59026},{\"end\":59058,\"start\":59042},{\"end\":59073,\"start\":59058},{\"end\":59452,\"start\":59433},{\"end\":59464,\"start\":59452},{\"end\":59480,\"start\":59464},{\"end\":59497,\"start\":59480},{\"end\":59514,\"start\":59497},{\"end\":59534,\"start\":59514},{\"end\":59749,\"start\":59735},{\"end\":59765,\"start\":59749},{\"end\":59777,\"start\":59765},{\"end\":59797,\"start\":59777},{\"end\":60175,\"start\":60161},{\"end\":60184,\"start\":60175},{\"end\":60194,\"start\":60184},{\"end\":60426,\"start\":60409},{\"end\":60440,\"start\":60426},{\"end\":60457,\"start\":60440},{\"end\":60472,\"start\":60457},{\"end\":60485,\"start\":60472},{\"end\":60496,\"start\":60485},{\"end\":60790,\"start\":60775},{\"end\":60799,\"start\":60790},{\"end\":60814,\"start\":60799},{\"end\":60827,\"start\":60814},{\"end\":60845,\"start\":60827},{\"end\":60858,\"start\":60845},{\"end\":61223,\"start\":61209},{\"end\":61234,\"start\":61223},{\"end\":61248,\"start\":61234},{\"end\":61264,\"start\":61248},{\"end\":61280,\"start\":61264},{\"end\":61294,\"start\":61280},{\"end\":61310,\"start\":61294},{\"end\":61327,\"start\":61310},{\"end\":61347,\"start\":61327},{\"end\":61603,\"start\":61586},{\"end\":61623,\"start\":61603},{\"end\":61796,\"start\":61782},{\"end\":61805,\"start\":61796},{\"end\":61814,\"start\":61805},{\"end\":62060,\"start\":62043},{\"end\":62080,\"start\":62060},{\"end\":62094,\"start\":62080},{\"end\":62110,\"start\":62094},{\"end\":62120,\"start\":62110},{\"end\":62713,\"start\":62701},{\"end\":62727,\"start\":62713},{\"end\":62731,\"start\":62727},{\"end\":62939,\"start\":62926},{\"end\":62952,\"start\":62939},{\"end\":62969,\"start\":62952},{\"end\":62986,\"start\":62969},{\"end\":63484,\"start\":63475},{\"end\":63501,\"start\":63484},{\"end\":63517,\"start\":63501},{\"end\":63637,\"start\":63619},{\"end\":63887,\"start\":63870},{\"end\":63902,\"start\":63887},{\"end\":64206,\"start\":64189},{\"end\":64221,\"start\":64206},{\"end\":64236,\"start\":64221},{\"end\":64251,\"start\":64236},{\"end\":64628,\"start\":64614},{\"end\":64647,\"start\":64628},{\"end\":64661,\"start\":64647},{\"end\":64878,\"start\":64864},{\"end\":64891,\"start\":64878},{\"end\":65254,\"start\":65245},{\"end\":65267,\"start\":65254},{\"end\":65856,\"start\":65847},{\"end\":65864,\"start\":65856},{\"end\":66037,\"start\":66017},{\"end\":66053,\"start\":66037},{\"end\":66074,\"start\":66053},{\"end\":66683,\"start\":66668},{\"end\":66696,\"start\":66683},{\"end\":66712,\"start\":66696},{\"end\":66727,\"start\":66712},{\"end\":66745,\"start\":66727},{\"end\":67035,\"start\":67020},{\"end\":67049,\"start\":67035},{\"end\":67060,\"start\":67049},{\"end\":67077,\"start\":67060},{\"end\":67095,\"start\":67077},{\"end\":67361,\"start\":67347},{\"end\":67381,\"start\":67361},{\"end\":67612,\"start\":67583},{\"end\":67628,\"start\":67612},{\"end\":67643,\"start\":67628},{\"end\":67651,\"start\":67643},{\"end\":68079,\"start\":68064},{\"end\":68093,\"start\":68079},{\"end\":68110,\"start\":68093},{\"end\":68693,\"start\":68679},{\"end\":68702,\"start\":68693},{\"end\":68723,\"start\":68702},{\"end\":68735,\"start\":68723},{\"end\":68753,\"start\":68735},{\"end\":68768,\"start\":68753},{\"end\":68778,\"start\":68768},{\"end\":68987,\"start\":68972},{\"end\":68995,\"start\":68987},{\"end\":69002,\"start\":68995},{\"end\":69191,\"start\":69177},{\"end\":69455,\"start\":69440},{\"end\":69466,\"start\":69455},{\"end\":69482,\"start\":69466},{\"end\":70105,\"start\":70092},{\"end\":70114,\"start\":70105},{\"end\":70131,\"start\":70114},{\"end\":70149,\"start\":70131},{\"end\":70161,\"start\":70149},{\"end\":70626,\"start\":70610},{\"end\":70641,\"start\":70626},{\"end\":70651,\"start\":70641},{\"end\":70668,\"start\":70651},{\"end\":70687,\"start\":70668},{\"end\":70941,\"start\":70928},{\"end\":71120,\"start\":71101},{\"end\":71137,\"start\":71120},{\"end\":71154,\"start\":71137},{\"end\":71170,\"start\":71154},{\"end\":71192,\"start\":71170},{\"end\":71469,\"start\":71455},{\"end\":71479,\"start\":71469},{\"end\":71497,\"start\":71479},{\"end\":71779,\"start\":71758},{\"end\":71791,\"start\":71779},{\"end\":71801,\"start\":71791},{\"end\":72235,\"start\":72222},{\"end\":72252,\"start\":72235},{\"end\":72269,\"start\":72252},{\"end\":72286,\"start\":72269},{\"end\":73166,\"start\":73152},{\"end\":73183,\"start\":73166},{\"end\":73212,\"start\":73183},{\"end\":73226,\"start\":73212},{\"end\":73700,\"start\":73681},{\"end\":73716,\"start\":73700},{\"end\":73736,\"start\":73716},{\"end\":73752,\"start\":73736},{\"end\":74032,\"start\":74016},{\"end\":74046,\"start\":74032},{\"end\":74059,\"start\":74046},{\"end\":74076,\"start\":74059},{\"end\":74089,\"start\":74076},{\"end\":74104,\"start\":74089},{\"end\":74119,\"start\":74104},{\"end\":74137,\"start\":74119},{\"end\":74515,\"start\":74504},{\"end\":74535,\"start\":74515},{\"end\":74550,\"start\":74535},{\"end\":74567,\"start\":74550},{\"end\":74583,\"start\":74567},{\"end\":74595,\"start\":74583},{\"end\":74606,\"start\":74595},{\"end\":74623,\"start\":74606},{\"end\":74979,\"start\":74968},{\"end\":74996,\"start\":74979},{\"end\":75012,\"start\":74996},{\"end\":75024,\"start\":75012},{\"end\":75035,\"start\":75024},{\"end\":75052,\"start\":75035},{\"end\":75402,\"start\":75385},{\"end\":75416,\"start\":75402},{\"end\":75656,\"start\":75646},{\"end\":75666,\"start\":75656},{\"end\":75929,\"start\":75916},{\"end\":75945,\"start\":75929},{\"end\":75958,\"start\":75945},{\"end\":75975,\"start\":75958},{\"end\":75993,\"start\":75975},{\"end\":76006,\"start\":75993},{\"end\":76022,\"start\":76006},{\"end\":76033,\"start\":76022},{\"end\":76050,\"start\":76033},{\"end\":76068,\"start\":76050},{\"end\":76080,\"start\":76068},{\"end\":76472,\"start\":76465},{\"end\":76485,\"start\":76472},{\"end\":76497,\"start\":76485},{\"end\":76515,\"start\":76497},{\"end\":76825,\"start\":76812},{\"end\":76839,\"start\":76825},{\"end\":76857,\"start\":76839},{\"end\":77444,\"start\":77436},{\"end\":77458,\"start\":77444},{\"end\":77466,\"start\":77458},{\"end\":77950,\"start\":77940},{\"end\":77965,\"start\":77950},{\"end\":77982,\"start\":77965},{\"end\":78491,\"start\":78478},{\"end\":78504,\"start\":78491},{\"end\":78522,\"start\":78504}]", "bib_venue": "[{\"end\":55889,\"start\":55818},{\"end\":56976,\"start\":56897},{\"end\":58526,\"start\":58403},{\"end\":62350,\"start\":62239},{\"end\":63169,\"start\":63086},{\"end\":65485,\"start\":65388},{\"end\":66279,\"start\":66189},{\"end\":67770,\"start\":67719},{\"end\":68355,\"start\":68241},{\"end\":69753,\"start\":69626},{\"end\":70344,\"start\":70261},{\"end\":71924,\"start\":71871},{\"end\":72599,\"start\":72450},{\"end\":73409,\"start\":73326},{\"end\":77076,\"start\":76975},{\"end\":77631,\"start\":77557},{\"end\":78131,\"start\":78065},{\"end\":55816,\"start\":55730},{\"end\":56208,\"start\":56139},{\"end\":56546,\"start\":56541},{\"end\":56895,\"start\":56801},{\"end\":57383,\"start\":57313},{\"end\":57874,\"start\":57825},{\"end\":58401,\"start\":58285},{\"end\":58952,\"start\":58859},{\"end\":59539,\"start\":59534},{\"end\":59893,\"start\":59813},{\"end\":60159,\"start\":60099},{\"end\":60561,\"start\":60521},{\"end\":60933,\"start\":60874},{\"end\":61207,\"start\":61145},{\"end\":61641,\"start\":61623},{\"end\":61780,\"start\":61752},{\"end\":62237,\"start\":62120},{\"end\":62699,\"start\":62657},{\"end\":63084,\"start\":62986},{\"end\":63473,\"start\":63441},{\"end\":63689,\"start\":63653},{\"end\":63907,\"start\":63902},{\"end\":64312,\"start\":64251},{\"end\":64612,\"start\":64534},{\"end\":65002,\"start\":64891},{\"end\":65386,\"start\":65290},{\"end\":65845,\"start\":65758},{\"end\":66187,\"start\":66093},{\"end\":66666,\"start\":66613},{\"end\":67018,\"start\":66953},{\"end\":67345,\"start\":67252},{\"end\":67717,\"start\":67651},{\"end\":68239,\"start\":68110},{\"end\":68677,\"start\":68635},{\"end\":69044,\"start\":69018},{\"end\":69257,\"start\":69191},{\"end\":69624,\"start\":69482},{\"end\":70259,\"start\":70161},{\"end\":70745,\"start\":70703},{\"end\":70984,\"start\":70963},{\"end\":71228,\"start\":71192},{\"end\":71577,\"start\":71513},{\"end\":71869,\"start\":71801},{\"end\":72448,\"start\":72306},{\"end\":73324,\"start\":73226},{\"end\":73811,\"start\":73768},{\"end\":74186,\"start\":74137},{\"end\":74641,\"start\":74637},{\"end\":75104,\"start\":75052},{\"end\":75383,\"start\":75351},{\"end\":75682,\"start\":75666},{\"end\":76099,\"start\":76094},{\"end\":76463,\"start\":76376},{\"end\":76973,\"start\":76857},{\"end\":77555,\"start\":77466},{\"end\":78063,\"start\":77982},{\"end\":78476,\"start\":78421}]"}}}, "year": 2023, "month": 12, "day": 17}