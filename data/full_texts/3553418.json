{"id": 3553418, "updated": "2023-09-29 09:38:24.476", "metadata": {"title": "An EMG Gesture Recognition System with Flexible High-Density Sensors and Brain-Inspired High-Dimensional Classifier", "authors": "[{\"first\":\"Ali\",\"last\":\"Moin\",\"middle\":[]},{\"first\":\"Andy\",\"last\":\"Zhou\",\"middle\":[]},{\"first\":\"Abbas\",\"last\":\"Rahimi\",\"middle\":[]},{\"first\":\"Simone\",\"last\":\"Benatti\",\"middle\":[]},{\"first\":\"Alisha\",\"last\":\"Menon\",\"middle\":[]},{\"first\":\"Senam\",\"last\":\"Tamakloe\",\"middle\":[]},{\"first\":\"Jonathan\",\"last\":\"Ting\",\"middle\":[]},{\"first\":\"Natasha\",\"last\":\"Yamamoto\",\"middle\":[]},{\"first\":\"Yasser\",\"last\":\"Khan\",\"middle\":[]},{\"first\":\"Fred\",\"last\":\"Burghardt\",\"middle\":[]},{\"first\":\"Luca\",\"last\":\"Benini\",\"middle\":[]},{\"first\":\"Ana\",\"last\":\"Arias\",\"middle\":[\"C.\"]},{\"first\":\"Jan\",\"last\":\"Rabaey\",\"middle\":[\"M.\"]}]", "venue": "2018 IEEE International Symposium on Circuits and Systems (ISCAS)", "journal": "2018 IEEE International Symposium on Circuits and Systems (ISCAS)", "publication_date": {"year": 2018, "month": 2, "day": 28}, "abstract": "EMG-based gesture recognition shows promise for human-machine interaction. Systems are often afflicted by signal and electrode variability which degrades performance over time. We present an end-to-end system combating this variability using a large-area, high-density sensor array and a robust classification algorithm. EMG electrodes are fabricated on a flexible substrate and interfaced to a custom wireless device for 64-channel signal acquisition and streaming. We use brain-inspired high-dimensional (HD) computing for processing EMG features in one-shot learning. The HD algorithm is tolerant to noise and electrode misplacement and can quickly learn from few gestures without gradient descent or back-propagation. We achieve an average classification accuracy of 96.64% for five gestures, with only 7% degradation when training and testing across different days. Our system maintains this accuracy when trained with only three trials of gestures; it also demonstrates comparable accuracy with the state-of-the-art when trained with one trial.", "fields_of_study": "[\"Computer Science\",\"Engineering\"]", "external_ids": {"arxiv": "1802.10237", "mag": "2964092203", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/iscas/MoinZRBMTTYKBBA18", "doi": "10.1109/iscas.2018.8351613"}}, "content": {"source": {"pdf_hash": "799a9835fe68717f6d3c54f3276307375a9c9306", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/1802.10237v2.pdf\"]", "oa_url_match": true, "oa_info": {"license": null, "open_access_url": "http://arxiv.org/pdf/1802.10237", "status": "GREEN"}}, "grobid": {"id": "3df9566b7d1a9dbb0186c13d4dc3575723d502bb", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/799a9835fe68717f6d3c54f3276307375a9c9306.txt", "contents": "\nAn EMG Gesture Recognition System with Flexible High-Density Sensors and Brain-Inspired High-Dimensional Classifier\n\n\nAli Moin \nBerkeley Wireless Research Center\nEECS Department\nUniversity of California\nBerkeley\n\nAndy Zhou \nBerkeley Wireless Research Center\nEECS Department\nUniversity of California\nBerkeley\n\nAbbas Rahimi \nBerkeley Wireless Research Center\nEECS Department\nUniversity of California\nBerkeley\n\nIntegrated System Laboratory\nETH Zurich\nSwitzerland\n\nSimone Benatti \nDEI\nUniversity of Bologna\nItaly\n\nAlisha Menon \nBerkeley Wireless Research Center\nEECS Department\nUniversity of California\nBerkeley\n\nSenam Tamakloe \nBerkeley Wireless Research Center\nEECS Department\nUniversity of California\nBerkeley\n\nJonathan Ting \nBerkeley Wireless Research Center\nEECS Department\nUniversity of California\nBerkeley\n\nNatasha Yamamoto \nBerkeley Wireless Research Center\nEECS Department\nUniversity of California\nBerkeley\n\nYasser Khan \nBerkeley Wireless Research Center\nEECS Department\nUniversity of California\nBerkeley\n\nFred Burghardt \nBerkeley Wireless Research Center\nEECS Department\nUniversity of California\nBerkeley\n\nLuca Benini \nIntegrated System Laboratory\nETH Zurich\nSwitzerland\n\nDEI\nUniversity of Bologna\nItaly\n\nAna C Arias \nBerkeley Wireless Research Center\nEECS Department\nUniversity of California\nBerkeley\n\nJan M Rabaey \nBerkeley Wireless Research Center\nEECS Department\nUniversity of California\nBerkeley\n\nAn EMG Gesture Recognition System with Flexible High-Density Sensors and Brain-Inspired High-Dimensional Classifier\n\nEMG-based gesture recognition shows promise for human-machine interaction. Systems are often afflicted by signal and electrode variability which degrades performance over time.We present an end-to-end system combating this variability using a large-area, high-density sensor array and a robust classification algorithm. EMG electrodes are fabricated on a flexible substrate and interfaced to a custom wireless device for 64-channel signal acquisition and streaming. We use braininspired high-dimensional (HD) computing for processing EMG features in one-shot learning. The HD algorithm is tolerant to noise and electrode misplacement and can quickly learn from few gestures without gradient descent or back-propagation. We achieve an average classification accuracy of 96.64% for five gestures, with only 7% degradation when training and testing across different days. Our system maintains this accuracy when trained with only three trials of gestures; it also demonstrates comparable accuracy with the state-of-the-art when trained with one trial.\n\nI. INTRODUCTION\n\nHand gestures are an integral part of human-human communication and can be leveraged for more natural humanmachine interaction (HMI). They are a fast and effective physical medium for communicating with and controlling intelligent devices. Accurate and efficient gesture recognition enables intuitive control for applications ranging from polyarticulated prosthetic hands [1] to mobile and game interfaces [2]. Hand gestures may be recognized based on muscular activity measured using electromyography (EMG), the detection of field potentials representing the superimposed electrical activity of muscle fibers. Surface EMG is a non-invasive method of acquiring these signals by placing recording electrodes directly on the surface of the skin.\n\nBoth research work [3], [4], [5] and commercial products [6] have demonstrated great potential for machine learning techniques to decode EMG and enable natural gesture recognition. Most of these systems are composed of an array of EMG sensors placed on the forearm and connected to a PC for acquiring data and running pattern recognition algorithms [1]. Over a single acquisition session, these systems can achieve classification accuracies above 90% in recognition of 5-6 gestures with an array of 3-8 sensors. Nevertheless, classification accuracy depends highly on precise electrode positioning for sufficient muscle coverage. For systems with low electrodecounts, inaccurate positioning can result in recording insufficient information for gesture recognition.\n\nFurthermore, the EMG signal can be highly variable, and it is challenging to have a reliable interface which reaches the same accuracy over multiple acquisition sessions. This performance variability is mostly caused by muscle fiber crosstalk, skin perspiration, and by changes in the skin-electrode interface. Moreover, even small variations in sensor positioning over multiple sessions can further decrease the classification performance. For instance, an accuracy degradation of 27% is observed when training and testing are performed on different sessions for a 14-sensor EMG system classifying 7 gestures using a random forest algorithm [7]. In the same vein, a support vector machine (SVM) algorithm suffers from a 30% accuracy drop with a single training session and multiple classification sessions [8].\n\nA promising solution to assure sufficient muscle coverage is to acquire EMG signals from a dense array of sensors [9], obtaining a fine-grained coverage of the muscular surface. Commercial active sensors [10] are not suited for use with dense arrays as they are large and cumbersome due to the integrated active conditioning circuitry. Passive single-lead electrodes must be applied one-by-one, which is inconvenient for daily use of the HMI. In contrast, a matrix of passive EMG sensors can be built into a flexible printed circuit board (PCB) and easily positioned on the skin, enabling high-density and small form-factor multichannel EMG acquisition [9]. All electrodes can be placed at once, and the flexible nature of such an array allows it to conform to the curvature of the arm, ensuring good signal quality. Dense electrode spacing on a large array increases channel-count and can easily lead to bulky signal acquisition systems, so a small form-factor and wireless device is desirable.\n\nAdditionally, an intrinsically robust classification algorithm is needed to process the large number of noisy inputs and mitigate the effects of signal variability. Brain-inspired highdimensional (HD) computing [11] is a promising avenue that can overcome low signal-to-noise ratio and large data variability to perform robust decision making and classifica- tion [12]. The HD computational paradigm provides generality, scalability, and fast one-shot learning, making it a prime candidate for processing multidimensional sensor data such as EMG [13], electroencephalography (EEG) [14], etc. This paper presents two major contributions: (1) an end-toend, high-density, wireless EMG gesture recognition system featuring a compact wearable device; and (2) the use of brain-inspired HD computing to improve the robustness of classification using variable data from a large number of noisy sensors. The proposed system wirelessly acquires 64 channels of EMG from a flexible PCB sensor array connected to a dedicated biopotential readout device [15], [16]. We implement an enhanced version of our previous work demonstrating HD computing for classification of EMG signals recorded from four gel-based electrodes [13]. We extensively evaluate the classification accuracy and its robustness over three acquisition sessions, including repositioning of the array strip. We show how the HD algorithm is easily scaled to operate with 64 channels, tolerates noise, and can be trained quickly from a single trial of each gesture, paving the way toward extremely fast calibration and online learning.\n\n\nII. SYSTEM OVERVIEW\n\nThe gesture recognition device is composed of two main components: a high-density flexible electrode array, and a wireless neural-signal acquisition device.\n\n\nA. Flexible Electrode Array\n\nA high-density flexible electrode array serves as the interface between the skin and the neural recording circuitry ( Figure 1). 64 uniformly-distributed electrodes are laid out in a 16 \u00d7 4 grid on a 200 \u00b5m-thick flexible substrate wide enough to cover the circumference of the forearm (29.3 cm \u00d7 8.2 cm). The size and flexibility of the substrate guarantee full, stable coverage of all muscles used for different gestures. The electrodes (4.3 mm diameter) and traces are fabricated out of copper. A piece of conductive hydrogel tape is applied to each electrode to help maintain good contact with the skin.\n\nInterfacing flexible electronics with rigid PCBs (recording module) is often challenging. This is solved by designing a small form-factor adapter board which has a zero insertion force (ZIF) connector for connecting the flexible array on one side, and a DF-12 connector for connecting the recording module on the other side.  \n\n\nB. Wireless Neural Recording Module\n\nA compact wireless module attaches to and interfaces with the electrode array to record, digitize, and wirelessly transmit the raw EMG signals to a base station ( Figure 2). The device is based on our previous design for a closed-loop artifact-free neuromodulation platform [15], [16]. Two custom neuromodulation ICs [17] (NMICs by Cortera Neurotechnologies, Inc.) provide 128 recording front-ends in a small footprint, and an SoC FPGA with a 166 MHz ARM Cortex-M3 processor (SmartFusion2 M2S060T, Microsemi) acts as the master module aggregating data. The digitized raw data is transmitted by a 2.4 GHz low-energy radio (nRF51822, Nordic Semiconductor) to a base-station. Table I summarizes main device specifications. The device is powered by a 500 mAh 4.1 V Li-ion battery providing up to 11 hours of streaming.\n\nData is streamed to a wireless base-station connected to a laptop running a text-based MATLAB (MathWorks, Inc.) GUI for configuring the device, instructing the subject, visualizing and storing data, and performing classification.\n\n\nIII. HIGH-DIMENSIONAL (HD) COMPUTING\n\nThe human brain contains billions of neurons and synapses, suggesting that large circuits are fundamental to its computational power. High-dimensional (HD) computing [11] explores this idea by looking at computing with vectors of very high dimensionality, e.g. 10,000. HD vectors can be combined into new vectors using well-defined vector space operations while maintaining the original information with high probability. They can be compared for similarity using a distance metric over the HD vector space.\n\nHD vectors are initially taken from a 10,000-dimensional space and have an equal number of randomly placed +1s and \u22121s. Such HD vectors are used to represent the basic elements in the system (e.g., the electrodes [13], [14]), and are stored in an item memory (IM) that functions as a fixed symbol table.\n\nThe following vector space operations can be used on the elements of the IM to encode information: Point-wise multiplication (*), or binding, takes two vectors and yields a third vector that is dissimilar (orthogonal) to the two. Pointwise addition (+), or bundling, takes several vectors and yields their mean vector that is maximally similar to all of them. These operations, along with scalar multiplication (\u00d7) and permutation (\u03c1) of vector components for sequences, form an algebraic field beyond arithmetic and linear algebra.\n\n\nA. Preprocessing\n\nThe EMG signal is recorded from 64 single-ended channels all referenced to a single Ag/AgCl patch electrode placed on the elbow. The acquired signal is a mixture of the EMG potentials and time-varying offset and noise, but the desired feature is the envelope of the high-frequency EMG. Hence, some preprocessing is needed in order to make it suitable for the HD classifier.\n\nThe preprocessing chain is illustrated in Figure 3. The first step is the elimination of the power line interference by a notch filter at 60 Hz with Q-factor of 50. Additionally, an 8th-order Butterworth band-pass filter for frequencies between 1 and 200 Hz cancels the undesired frequency components such as DC offset and drift.\n\nTo extract the envelope, we take the absolute value of the signal and apply a moving average filter with window size of 100. Finally, the data is normalized per channel, and downsampled by a factor of 100, i.e. 10 samples per second are fed to the HD classifier described in the next section.\n\n\nB. HD classifier\n\nThe HD algorithm encodes windows of EMG signals into HD vectors that are ultimately used for robust learning and classification. The input features at each time point are the preprocessed and downsampled scalar values for each electrode. We encode the input features at a single time point into a spatial HD vector, S t . The IM assigns a unique orthogonal HD vector to every electrode, i.e., E 1 \u22a5 E 2 ... \u22a5 E 64 . To represent the preprocessed scalar value (v t i ) of an electrode i at time t, we simply multiply the scalar with the corresponding HD vector: E i \u00d7v t i . These vectors are added across all electrodes to compute the spatial HD vector representing the input features:\nS t = \u03c3( 64 i=1 E i \u00d7 v t i )\nwhere \u03c3 is a bipolar thresholder that turns a positive element to +1 and a negative element to \u22121. This new spatial encoder computes the sum of the electrode vectors weighted by the scalars, and naturally maps a large number of features to a single spatial HD vector.\n\nNext, we need to encode a sequence of n spatial HD vectors to capture relevant temporal information into a final spatiotemporal vector by using permutation: G = n t=1 \u03c1 t\u22121 S t where \u03c1 k is a rotation over k positions of the HD vector. For the preprocessed EMG signals subsampled at 10 Hz, we observe that a temporal window of 5 samples, i.e., n = 5 yields the best classification results.\n\nTo train the classifier, we use the G spatiotemporal HD vectors to build an associative memory (AM) containing an HD vector representing each gesture label. During training, all spatiotemporal HD vectors computed over a labeled gesture window are accumulated (summed) to form a prototype HD vector representing that gesture. The prototype HD vector is thresholded by \u03c3 and stored in the AM. For classification, newly computed spatiotemporal HD vectors are compared to each entry of the AM using cosine similarity as the distance metric. The classified gesture is that of the closest gesture vector in the AM.\n\n\nIV. EXPERIMENTAL RESULTS\n\n\nA. Generating Dataset\n\nWe acquired EMG gesture data from three healthy, adult male subjects 1 . Each subject participated in three data collection sessions across different days, where the electrode array was reapplied with fresh hydrogel tape for each session. For Sessions 1 and 2, the array was placed in approximately the same position each time (Figure 1). A training data set and testing data set were recorded 30 minutes apart during Session 1, and a second testing data set was recorded 24 hours later in Session 2. For Session 3, new training and testing data sets  were recorded with the array in a different orientation 1 week after Sessions 1 and 2. Each data set contained ten trials of four hard gestures (fist, raise, lower, open) ( Figure 4) held for 5 seconds each in different sequences. Each sequence began and ended with rest, which we treated as a fifth gesture. Centered 3-second segments of each 5-second gesture were labeled for inclusion in the testing and training sets.\n\nPreprocessed features for each gesture were averaged and arranged in matrices for visualization as heat maps of muscular activity (Figure 4). For Session 3, the array was rotated from its Session 1-2 position. This can be seen in the differences of the heat maps, though the large, high-density array maintained full coverage of muscle activity across all sessions.\n\n\nB. Classification Results\n\nTo quantify single-and across-session classification accuracies, the HD classifier was trained on Session 1 and tested on Sessions 1 and 2. During testing, we generated a classification result for every 500-ms window sliding by 100 ms. Accuracies for three subjects, calculated as the percentage of classification results that matched the labeled gesture, are shown in Table II. Single-session accuracies were on average 96.64%. For comparison, single-session accuracy using an SVM classifier on similarly processed signals [10] is 88.96% for 5 gestures [8]. Training and testing across Sessions 1 and 2 resulted in accuracy degradation of only about 7%, a large improvement over degradations of more than 30% using the SVM classifier [8]. We attribute this robustness to the high channel density and ability of HD computing to overcome variance in signal quality and electrode placement.\n\nSimple majority voting of the classification results over a 1.1-second window of classifications (11 results) further improved accuracy on average by 1.5%. This is an insignificant improvement due to high baseline accuracy.\n\nThe HD algorithm was also successfully used to train and test on Session 3, demonstrating that the high-density array could record sufficient information for accurate classification in multiple orientations. When trained on Session 1 data, the classifier could not classify Session 3 gestures directly with good accuracy. However, we anticipate that a simple remapping of the input features could be implemented to recover the accuracy.\n\nLimiting the number of trials used for training the classifier only marginally degraded performance. Figure 5 plots the classification accuracy averaged over all three subjects for training set sizes from 1 to 10 trials. Maximum performance (96.64%) is achieved when training on only 3 trials, and training on a single trial can deliver acceptable accuracy (89.19%) for true one-shot learning.\n\nV. CONCLUSION Robustness and reliability of gesture recognition are big challenges in designing an EMG-based HMI. Electrode misplacement over multiple sessions is the root cause of accuracy degradation, which can be higher than 30%. We have presented a system for EMG-based gesture classification combining a flexible high density electrode array, a dedicated biopotential acquisition device, and a brain-inspired classification algorithm. Large area coverage and dense electrode spacing ensures sufficient muscular coverage without requiring precise placement. Furthermore, the wireless and compact signal acquisition device promotes comfort and ease of use. Finally, the HD algorithm achieves high classification accuracy without substantial degradation over multiple sessions, and can be trained using minimal amounts of data.\n\nFig. 1 .\n1Flexible electrode array with attached wireless biosignal acquisition device (left) positioned on the arm (right).\n\nFig. 2 .\n2Wireless biosignal acquisition device with important blocks annotated.\n\nFig. 3 .\n3Preprocessing and spatiotemporal encoding for EMG-based gesture recognition where v t i is the preprocessed scalar value of electrode i at time t, S t (spatial HD vector) is the output of spatial encoder at time t, and G (spatiotemporal HD vector) is the output of temporal encoder.\n\nFig. 4 .\n4Dataset gestures (a) with the associated normalized activity maps for different sessions (Subject 1 shown) (b). Pixels correspond to electrode positions in the array.\n\nFig. 5 .\n5Classification accuracy for different number of training trials.\n\nTABLE I WIRELESS\nIBIOSIGNAL ACQUISITION DEVICE SPECIFICATIONSNumber of Recording Channels \n128 \nADC Sample Rate \n1 kS/s \nADC Resolution \n15 bits \nInput Range \n100 mVpp \nNoise Floor \n1.65 \u00b5Vrms \nNumber of Channels Wirelessly Streamed \n96 \nWireless Data Rate \n2 Mbps \nPCB Dimensions \n3.3 cm \u00d7 3.56 cm \nWeight (w/ battery) \n6.62 g (17.18 g) \nBattery Life \n11 hr \n\n\n\nTABLE II CLASSIFICATION\nIIACCURACY RESULTSSame Session \nAcross Sessions \nSame Session Rotated \nNo Vote \n1s Vote \nNo Vote \n1s Vote \nNo Vote \n1s Vote \nSub. 1 \n99.44% \n100% \n90.97% \n93.26% \n99.57% \n100% \nSub. 2 \n98.87% \n98.99% \n98.68% \n98.88% \n97.67% \n98.29% \nSub. 3 \n91.61% \n93.03% \n79.69% \n82.64% \n90.81% \n95.61% \nAvg. \n96.64% \n97.34% \n89.78% \n91.59% \n96.02% \n97.97% \n\n\nDataset and processing scripts available at https://github.com/amoin/flexemg\n\nA prosthetic hand body area controller based on efficient pattern recognition control strategies. S Benatti, B Milosevic, E Farella, E Gruppioni, L Benini, Sensors. 174869S. Benatti, B. Milosevic, E. Farella, E. Gruppioni, and L. Benini, \"A prosthetic hand body area controller based on efficient pattern recognition control strategies,\" Sensors, vol. 17, no. 4, p. 869, 2017.\n\nHand gesture recognition and virtual game control based on 3D accelerometer and EMG sensors. X Zhang, X Chen, W Wang, J Yang, V Lantz, K.-Q Wang, Proceedings of the 14th international conference on Intelligent user interfaces. the 14th international conference on Intelligent user interfacesACMX. Zhang, X. Chen, W.-h. Wang, J.-h. Yang, V. Lantz, and K.-q. Wang, \"Hand gesture recognition and virtual game control based on 3D accelerometer and EMG sensors,\" in Proceedings of the 14th international conference on Intelligent user interfaces. ACM, 2009, pp. 401-406.\n\nAn adaptation strategy of using lda classifier for EMG pattern recognition. H Zhang, Y Zhao, F Yao, L Xu, P Shang, G Li, 35th Annual International Conference of the IEEE. H. Zhang, Y. Zhao, F. Yao, L. Xu, P. Shang, and G. Li, \"An adaptation strategy of using lda classifier for EMG pattern recognition,\" in EMBC, 2013 35th Annual International Conference of the IEEE, July 2013.\n\nElectromygraphy (EMG) signal based hand gesture recognition using artificial neural network (ann). M Ahsan, M Ibrahimy, O Khalifa, Mechatronics (ICOM), 2011 4th International Conference On. M. Ahsan, M. Ibrahimy, and O. Khalifa, \"Electromygraphy (EMG) signal based hand gesture recognition using artificial neural network (ann),\" in Mechatronics (ICOM), 2011 4th International Conference On, May 2011, pp. 1-6.\n\nSupport vector machine-based classification scheme for myoelectric control applied to upper limb. M A Oskoei, H Hu, IEEE transactions on biomedical engineering. 558M. A. Oskoei and H. Hu, \"Support vector machine-based classification scheme for myoelectric control applied to upper limb,\" IEEE transac- tions on biomedical engineering, vol. 55, no. 8, pp. 1956-1965, 2008.\n\nThalmic Labs Myo Armband. 20\"Thalmic Labs Myo Armband,\" 2017, (Date last accessed 20-Nov- 2017). [Online]. Available: https://www.thalmic.com/\n\nRepeatability of grasp recognition for robotic hand prosthesis control based on sEMG data. F Palermo, M Cognolato, A Gijsberts, H M\u00fcller, B Caputo, M Atzori, Rehabilitation Robotics (ICORR. F. Palermo, M. Cognolato, A. Gijsberts, H. M\u00fcller, B. Caputo, and M. Atzori, \"Repeatability of grasp recognition for robotic hand prosthe- sis control based on sEMG data,\" in Rehabilitation Robotics (ICORR), 2017 International Conference on. IEEE, 2017, pp. 1154-1159.\n\nAnalysis of robust implementation of an EMG pattern recognition based control. S Benatti, E Farella, E Gruppioni, L Benini, Proceedings of the International Conference on Bio-inspired Systems and Signal Processing. the International Conference on Bio-inspired Systems and Signal ProcessingBIOSTEC 2014S. Benatti, E. Farella, E. Gruppioni, and L. Benini, \"Analysis of robust implementation of an EMG pattern recognition based control,\" in Proceedings of the International Conference on Bio-inspired Systems and Signal Processing (BIOSTEC 2014), 2014, pp. 45-54.\n\nOT Bioelettronica Electrodes. 20\"OT Bioelettronica Electrodes,\" 2014, (Date last accessed 20-Nov- 2017). [Online]. Available: http://www.otbioelettronica.it/\n\nOttobock 13e200 myobock electrode. \"Ottobock 13e200 myobock electrode,\" 2016. [Online]. Available: https://professionals.ottobockus.com/c/Electrode/p/13E200 \u223c 550\n\nHyperdimensional computing: An introduction to computing in distributed representation with high-dimensional random vectors. P Kanerva, 10.1007/s12559-009-9009-8Cognitive Computation. 12P. Kanerva, \"Hyperdimensional computing: An introduction to computing in distributed representation with high-dimensional random vectors,\" Cognitive Computation, vol. 1, no. 2, pp. 139-159, 2009. [Online]. Available: http://dx.doi.org/10.1007/s12559-009-9009-8\n\nHigh-dimensional computing as a nanoscalable paradigm. A Rahimi, S Datta, D Kleyko, E P Frady, B Olshausen, P Kanerva, J M Rabaey, IEEE Transactions on Circuits and Systems I: Regular Papers. 649A. Rahimi, S. Datta, D. Kleyko, E. P. Frady, B. Olshausen, P. Kanerva, and J. M. Rabaey, \"High-dimensional computing as a nanoscalable paradigm,\" IEEE Transactions on Circuits and Systems I: Regular Papers, vol. 64, no. 9, pp. 2508-2521, Sept 2017.\n\nHyperdimensional biosignal processing: A case study for EMG-based hand gesture recognition. A Rahimi, S Benatti, P Kanerva, L Benini, J M Rabaey, Rebooting Computing (ICRC), IEEE International Conference on. IEEEA. Rahimi, S. Benatti, P. Kanerva, L. Benini, and J. M. Rabaey, \"Hyperdimensional biosignal processing: A case study for EMG-based hand gesture recognition,\" in Rebooting Computing (ICRC), IEEE In- ternational Conference on. IEEE, 2016, pp. 1-8.\n\nHyperdimensional computing for blind and one-shot classification of EEG error-related potentials. A Rahimi, A Tchouprina, P Kanerva, J D R Mill\u00e1n, J M Rabaey, 10.1007/s11036-017-0942-6Mobile Networks and ApplicationsA. Rahimi, A. Tchouprina, P. Kanerva, J. d. R. Mill\u00e1n, and J. M. Rabaey, \"Hyperdimensional computing for blind and one-shot classification of EEG error-related potentials,\" Mobile Networks and Applications, Oct 2017. [Online]. Available: https://doi.org/10.1007/s11036-017-0942-6\n\nPowering and communication for omni: A distributed and modular closed-loop neuromodulation device. A Moin, G Alexandrov, B C Johnson, I Izyumin, F Burghardt, K Shah, S Pannu, E Alon, R Muller, J M Rabaey, IEEE 38th Annual International Conference of the. IEEE. A. Moin, G. Alexandrov, B. C. Johnson, I. Izyumin, F. Burghardt, K. Shah, S. Pannu, E. Alon, R. Muller, and J. M. Rabaey, \"Powering and communication for omni: A distributed and modular closed-loop neuromodulation device,\" in Engineering in Medicine and Biology Society (EMBC), 2016 IEEE 38th Annual International Conference of the. IEEE, 2016, pp. 4471-4474.\n\nWand: A 128-channel, closed-loop, wireless artifact-free neuromodulation device. A Zhou, S R Santacruz, B C Johnson, G Alexandrov, A Moin, F L Burghardt, J M Rabaey, J M Carmena, R Muller, arXiv:1708.00556arXiv preprintA. Zhou, S. R. Santacruz, B. C. Johnson, G. Alexandrov, A. Moin, F. L. Burghardt, J. M. Rabaey, J. M. Carmena, and R. Muller, \"Wand: A 128- channel, closed-loop, wireless artifact-free neuromodulation device,\" arXiv preprint arXiv:1708.00556, 2017.\n\nAn implantable 700\u00b5w 64-channel neuromodulation ic for simultaneous recording and stimulation with rapid artifact recovery. B C Johnson, S Gambini, I Izyumin, A Moin, A Zhou, G Alexandrov, S R Santacruz, J M Rabaey, J M Carmena, R Muller, VLSI Circuits, 2017 Symposium on. B. C. Johnson, S. Gambini, I. Izyumin, A. Moin, A. Zhou, G. Alexan- drov, S. R. Santacruz, J. M. Rabaey, J. M. Carmena, and R. Muller, \"An implantable 700\u00b5w 64-channel neuromodulation ic for simultaneous recording and stimulation with rapid artifact recovery,\" in VLSI Circuits, 2017 Symposium on. IEEE, 2017, pp. C48-C49.\n", "annotations": {"author": "[{\"end\":213,\"start\":119},{\"end\":309,\"start\":214},{\"end\":461,\"start\":310},{\"end\":510,\"start\":462},{\"end\":609,\"start\":511},{\"end\":710,\"start\":610},{\"end\":810,\"start\":711},{\"end\":913,\"start\":811},{\"end\":1011,\"start\":914},{\"end\":1112,\"start\":1012},{\"end\":1211,\"start\":1113},{\"end\":1309,\"start\":1212},{\"end\":1408,\"start\":1310}]", "publisher": null, "author_last_name": "[{\"end\":127,\"start\":123},{\"end\":223,\"start\":219},{\"end\":322,\"start\":316},{\"end\":476,\"start\":469},{\"end\":523,\"start\":518},{\"end\":624,\"start\":616},{\"end\":724,\"start\":720},{\"end\":827,\"start\":819},{\"end\":925,\"start\":921},{\"end\":1026,\"start\":1017},{\"end\":1124,\"start\":1118},{\"end\":1223,\"start\":1218},{\"end\":1322,\"start\":1316}]", "author_first_name": "[{\"end\":122,\"start\":119},{\"end\":218,\"start\":214},{\"end\":315,\"start\":310},{\"end\":468,\"start\":462},{\"end\":517,\"start\":511},{\"end\":615,\"start\":610},{\"end\":719,\"start\":711},{\"end\":818,\"start\":811},{\"end\":920,\"start\":914},{\"end\":1016,\"start\":1012},{\"end\":1117,\"start\":1113},{\"end\":1215,\"start\":1212},{\"end\":1217,\"start\":1216},{\"end\":1313,\"start\":1310},{\"end\":1315,\"start\":1314}]", "author_affiliation": "[{\"end\":212,\"start\":129},{\"end\":308,\"start\":225},{\"end\":407,\"start\":324},{\"end\":460,\"start\":409},{\"end\":509,\"start\":478},{\"end\":608,\"start\":525},{\"end\":709,\"start\":626},{\"end\":809,\"start\":726},{\"end\":912,\"start\":829},{\"end\":1010,\"start\":927},{\"end\":1111,\"start\":1028},{\"end\":1177,\"start\":1126},{\"end\":1210,\"start\":1179},{\"end\":1308,\"start\":1225},{\"end\":1407,\"start\":1324}]", "title": "[{\"end\":116,\"start\":1},{\"end\":1524,\"start\":1409}]", "venue": null, "abstract": "[{\"end\":2574,\"start\":1526}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2968,\"start\":2965},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3002,\"start\":2999},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3360,\"start\":3357},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3365,\"start\":3362},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":3370,\"start\":3367},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3398,\"start\":3395},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":3690,\"start\":3687},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":4749,\"start\":4746},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":4914,\"start\":4911},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":5034,\"start\":5031},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":5125,\"start\":5121},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":5573,\"start\":5570},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":6129,\"start\":6125},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":6282,\"start\":6278},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":6464,\"start\":6460},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":6499,\"start\":6495},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":6958,\"start\":6954},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":6964,\"start\":6960},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":7125,\"start\":7121},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":8965,\"start\":8961},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":8971,\"start\":8967},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":9008,\"start\":9004},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":9943,\"start\":9939},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":10499,\"start\":10495},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":10505,\"start\":10501},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":16094,\"start\":16090},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":16123,\"start\":16120},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":16304,\"start\":16301}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":18469,\"start\":18344},{\"attributes\":{\"id\":\"fig_1\"},\"end\":18551,\"start\":18470},{\"attributes\":{\"id\":\"fig_2\"},\"end\":18845,\"start\":18552},{\"attributes\":{\"id\":\"fig_3\"},\"end\":19023,\"start\":18846},{\"attributes\":{\"id\":\"fig_4\"},\"end\":19099,\"start\":19024},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":19462,\"start\":19100},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":19832,\"start\":19463}]", "paragraph": "[{\"end\":3336,\"start\":2593},{\"end\":4102,\"start\":3338},{\"end\":4915,\"start\":4104},{\"end\":5912,\"start\":4917},{\"end\":7500,\"start\":5914},{\"end\":7680,\"start\":7524},{\"end\":8319,\"start\":7712},{\"end\":8647,\"start\":8321},{\"end\":9501,\"start\":8687},{\"end\":9732,\"start\":9503},{\"end\":10280,\"start\":9773},{\"end\":10585,\"start\":10282},{\"end\":11119,\"start\":10587},{\"end\":11513,\"start\":11140},{\"end\":11844,\"start\":11515},{\"end\":12138,\"start\":11846},{\"end\":12844,\"start\":12159},{\"end\":13142,\"start\":12875},{\"end\":13533,\"start\":13144},{\"end\":14143,\"start\":13535},{\"end\":15169,\"start\":14196},{\"end\":15536,\"start\":15171},{\"end\":16454,\"start\":15566},{\"end\":16679,\"start\":16456},{\"end\":17117,\"start\":16681},{\"end\":17512,\"start\":17119},{\"end\":18343,\"start\":17514}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":12874,\"start\":12845}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":9367,\"start\":9360},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":15943,\"start\":15935}]", "section_header": "[{\"end\":2591,\"start\":2576},{\"end\":7522,\"start\":7503},{\"end\":7710,\"start\":7683},{\"end\":8685,\"start\":8650},{\"end\":9771,\"start\":9735},{\"end\":11138,\"start\":11122},{\"end\":12157,\"start\":12141},{\"end\":14170,\"start\":14146},{\"end\":14194,\"start\":14173},{\"end\":15564,\"start\":15539},{\"end\":18353,\"start\":18345},{\"end\":18479,\"start\":18471},{\"end\":18561,\"start\":18553},{\"end\":18855,\"start\":18847},{\"end\":19033,\"start\":19025},{\"end\":19117,\"start\":19101},{\"end\":19487,\"start\":19464}]", "table": "[{\"end\":19462,\"start\":19162},{\"end\":19832,\"start\":19506}]", "figure_caption": "[{\"end\":18469,\"start\":18355},{\"end\":18551,\"start\":18481},{\"end\":18845,\"start\":18563},{\"end\":19023,\"start\":18857},{\"end\":19099,\"start\":19035},{\"end\":19162,\"start\":19119},{\"end\":19506,\"start\":19490}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":7838,\"start\":7830},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":8858,\"start\":8850},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":11565,\"start\":11557},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":14533,\"start\":14523},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":14929,\"start\":14921},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":15310,\"start\":15301},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":17228,\"start\":17220}]", "bib_author_first_name": "[{\"end\":20010,\"start\":20009},{\"end\":20021,\"start\":20020},{\"end\":20034,\"start\":20033},{\"end\":20045,\"start\":20044},{\"end\":20058,\"start\":20057},{\"end\":20383,\"start\":20382},{\"end\":20392,\"start\":20391},{\"end\":20400,\"start\":20399},{\"end\":20408,\"start\":20407},{\"end\":20416,\"start\":20415},{\"end\":20428,\"start\":20424},{\"end\":20933,\"start\":20932},{\"end\":20942,\"start\":20941},{\"end\":20950,\"start\":20949},{\"end\":20957,\"start\":20956},{\"end\":20963,\"start\":20962},{\"end\":20972,\"start\":20971},{\"end\":21336,\"start\":21335},{\"end\":21345,\"start\":21344},{\"end\":21357,\"start\":21356},{\"end\":21747,\"start\":21746},{\"end\":21749,\"start\":21748},{\"end\":21759,\"start\":21758},{\"end\":22257,\"start\":22256},{\"end\":22268,\"start\":22267},{\"end\":22281,\"start\":22280},{\"end\":22294,\"start\":22293},{\"end\":22304,\"start\":22303},{\"end\":22314,\"start\":22313},{\"end\":22705,\"start\":22704},{\"end\":22716,\"start\":22715},{\"end\":22727,\"start\":22726},{\"end\":22740,\"start\":22739},{\"end\":23636,\"start\":23635},{\"end\":24014,\"start\":24013},{\"end\":24024,\"start\":24023},{\"end\":24033,\"start\":24032},{\"end\":24043,\"start\":24042},{\"end\":24045,\"start\":24044},{\"end\":24054,\"start\":24053},{\"end\":24067,\"start\":24066},{\"end\":24078,\"start\":24077},{\"end\":24080,\"start\":24079},{\"end\":24496,\"start\":24495},{\"end\":24506,\"start\":24505},{\"end\":24517,\"start\":24516},{\"end\":24528,\"start\":24527},{\"end\":24538,\"start\":24537},{\"end\":24540,\"start\":24539},{\"end\":24961,\"start\":24960},{\"end\":24971,\"start\":24970},{\"end\":24985,\"start\":24984},{\"end\":24996,\"start\":24995},{\"end\":25000,\"start\":24997},{\"end\":25010,\"start\":25009},{\"end\":25012,\"start\":25011},{\"end\":25459,\"start\":25458},{\"end\":25467,\"start\":25466},{\"end\":25481,\"start\":25480},{\"end\":25483,\"start\":25482},{\"end\":25494,\"start\":25493},{\"end\":25505,\"start\":25504},{\"end\":25518,\"start\":25517},{\"end\":25526,\"start\":25525},{\"end\":25535,\"start\":25534},{\"end\":25543,\"start\":25542},{\"end\":25553,\"start\":25552},{\"end\":25555,\"start\":25554},{\"end\":26063,\"start\":26062},{\"end\":26071,\"start\":26070},{\"end\":26073,\"start\":26072},{\"end\":26086,\"start\":26085},{\"end\":26088,\"start\":26087},{\"end\":26099,\"start\":26098},{\"end\":26113,\"start\":26112},{\"end\":26121,\"start\":26120},{\"end\":26123,\"start\":26122},{\"end\":26136,\"start\":26135},{\"end\":26138,\"start\":26137},{\"end\":26148,\"start\":26147},{\"end\":26150,\"start\":26149},{\"end\":26161,\"start\":26160},{\"end\":26575,\"start\":26574},{\"end\":26577,\"start\":26576},{\"end\":26588,\"start\":26587},{\"end\":26599,\"start\":26598},{\"end\":26610,\"start\":26609},{\"end\":26618,\"start\":26617},{\"end\":26626,\"start\":26625},{\"end\":26640,\"start\":26639},{\"end\":26642,\"start\":26641},{\"end\":26655,\"start\":26654},{\"end\":26657,\"start\":26656},{\"end\":26667,\"start\":26666},{\"end\":26669,\"start\":26668},{\"end\":26680,\"start\":26679}]", "bib_author_last_name": "[{\"end\":20018,\"start\":20011},{\"end\":20031,\"start\":20022},{\"end\":20042,\"start\":20035},{\"end\":20055,\"start\":20046},{\"end\":20065,\"start\":20059},{\"end\":20389,\"start\":20384},{\"end\":20397,\"start\":20393},{\"end\":20405,\"start\":20401},{\"end\":20413,\"start\":20409},{\"end\":20422,\"start\":20417},{\"end\":20433,\"start\":20429},{\"end\":20939,\"start\":20934},{\"end\":20947,\"start\":20943},{\"end\":20954,\"start\":20951},{\"end\":20960,\"start\":20958},{\"end\":20969,\"start\":20964},{\"end\":20975,\"start\":20973},{\"end\":21342,\"start\":21337},{\"end\":21354,\"start\":21346},{\"end\":21365,\"start\":21358},{\"end\":21756,\"start\":21750},{\"end\":21762,\"start\":21760},{\"end\":22265,\"start\":22258},{\"end\":22278,\"start\":22269},{\"end\":22291,\"start\":22282},{\"end\":22301,\"start\":22295},{\"end\":22311,\"start\":22305},{\"end\":22321,\"start\":22315},{\"end\":22713,\"start\":22706},{\"end\":22724,\"start\":22717},{\"end\":22737,\"start\":22728},{\"end\":22747,\"start\":22741},{\"end\":23644,\"start\":23637},{\"end\":24021,\"start\":24015},{\"end\":24030,\"start\":24025},{\"end\":24040,\"start\":24034},{\"end\":24051,\"start\":24046},{\"end\":24064,\"start\":24055},{\"end\":24075,\"start\":24068},{\"end\":24087,\"start\":24081},{\"end\":24503,\"start\":24497},{\"end\":24514,\"start\":24507},{\"end\":24525,\"start\":24518},{\"end\":24535,\"start\":24529},{\"end\":24547,\"start\":24541},{\"end\":24968,\"start\":24962},{\"end\":24982,\"start\":24972},{\"end\":24993,\"start\":24986},{\"end\":25007,\"start\":25001},{\"end\":25019,\"start\":25013},{\"end\":25464,\"start\":25460},{\"end\":25478,\"start\":25468},{\"end\":25491,\"start\":25484},{\"end\":25502,\"start\":25495},{\"end\":25515,\"start\":25506},{\"end\":25523,\"start\":25519},{\"end\":25532,\"start\":25527},{\"end\":25540,\"start\":25536},{\"end\":25550,\"start\":25544},{\"end\":25562,\"start\":25556},{\"end\":26068,\"start\":26064},{\"end\":26083,\"start\":26074},{\"end\":26096,\"start\":26089},{\"end\":26110,\"start\":26100},{\"end\":26118,\"start\":26114},{\"end\":26133,\"start\":26124},{\"end\":26145,\"start\":26139},{\"end\":26158,\"start\":26151},{\"end\":26168,\"start\":26162},{\"end\":26585,\"start\":26578},{\"end\":26596,\"start\":26589},{\"end\":26607,\"start\":26600},{\"end\":26615,\"start\":26611},{\"end\":26623,\"start\":26619},{\"end\":26637,\"start\":26627},{\"end\":26652,\"start\":26643},{\"end\":26664,\"start\":26658},{\"end\":26677,\"start\":26670},{\"end\":26687,\"start\":26681}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":20872387},\"end\":20287,\"start\":19911},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":3774768},\"end\":20854,\"start\":20289},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":3050701},\"end\":21234,\"start\":20856},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":44974405},\"end\":21646,\"start\":21236},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":17162934},\"end\":22019,\"start\":21648},{\"attributes\":{\"id\":\"b5\"},\"end\":22163,\"start\":22021},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":3926045},\"end\":22623,\"start\":22165},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":15953456},\"end\":23185,\"start\":22625},{\"attributes\":{\"id\":\"b8\"},\"end\":23344,\"start\":23187},{\"attributes\":{\"id\":\"b9\"},\"end\":23508,\"start\":23346},{\"attributes\":{\"doi\":\"10.1007/s12559-009-9009-8\",\"id\":\"b10\",\"matched_paper_id\":733980},\"end\":23956,\"start\":23510},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":10569020},\"end\":24401,\"start\":23958},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":12008695},\"end\":24860,\"start\":24403},{\"attributes\":{\"doi\":\"10.1007/s11036-017-0942-6\",\"id\":\"b13\"},\"end\":25357,\"start\":24862},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":8843931},\"end\":25979,\"start\":25359},{\"attributes\":{\"doi\":\"arXiv:1708.00556\",\"id\":\"b15\"},\"end\":26448,\"start\":25981},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":34911506},\"end\":27045,\"start\":26450}]", "bib_title": "[{\"end\":20007,\"start\":19911},{\"end\":20380,\"start\":20289},{\"end\":20930,\"start\":20856},{\"end\":21333,\"start\":21236},{\"end\":21744,\"start\":21648},{\"end\":22254,\"start\":22165},{\"end\":22702,\"start\":22625},{\"end\":23633,\"start\":23510},{\"end\":24011,\"start\":23958},{\"end\":24493,\"start\":24403},{\"end\":25456,\"start\":25359},{\"end\":26572,\"start\":26450}]", "bib_author": "[{\"end\":20020,\"start\":20009},{\"end\":20033,\"start\":20020},{\"end\":20044,\"start\":20033},{\"end\":20057,\"start\":20044},{\"end\":20067,\"start\":20057},{\"end\":20391,\"start\":20382},{\"end\":20399,\"start\":20391},{\"end\":20407,\"start\":20399},{\"end\":20415,\"start\":20407},{\"end\":20424,\"start\":20415},{\"end\":20435,\"start\":20424},{\"end\":20941,\"start\":20932},{\"end\":20949,\"start\":20941},{\"end\":20956,\"start\":20949},{\"end\":20962,\"start\":20956},{\"end\":20971,\"start\":20962},{\"end\":20977,\"start\":20971},{\"end\":21344,\"start\":21335},{\"end\":21356,\"start\":21344},{\"end\":21367,\"start\":21356},{\"end\":21758,\"start\":21746},{\"end\":21764,\"start\":21758},{\"end\":22267,\"start\":22256},{\"end\":22280,\"start\":22267},{\"end\":22293,\"start\":22280},{\"end\":22303,\"start\":22293},{\"end\":22313,\"start\":22303},{\"end\":22323,\"start\":22313},{\"end\":22715,\"start\":22704},{\"end\":22726,\"start\":22715},{\"end\":22739,\"start\":22726},{\"end\":22749,\"start\":22739},{\"end\":23646,\"start\":23635},{\"end\":24023,\"start\":24013},{\"end\":24032,\"start\":24023},{\"end\":24042,\"start\":24032},{\"end\":24053,\"start\":24042},{\"end\":24066,\"start\":24053},{\"end\":24077,\"start\":24066},{\"end\":24089,\"start\":24077},{\"end\":24505,\"start\":24495},{\"end\":24516,\"start\":24505},{\"end\":24527,\"start\":24516},{\"end\":24537,\"start\":24527},{\"end\":24549,\"start\":24537},{\"end\":24970,\"start\":24960},{\"end\":24984,\"start\":24970},{\"end\":24995,\"start\":24984},{\"end\":25009,\"start\":24995},{\"end\":25021,\"start\":25009},{\"end\":25466,\"start\":25458},{\"end\":25480,\"start\":25466},{\"end\":25493,\"start\":25480},{\"end\":25504,\"start\":25493},{\"end\":25517,\"start\":25504},{\"end\":25525,\"start\":25517},{\"end\":25534,\"start\":25525},{\"end\":25542,\"start\":25534},{\"end\":25552,\"start\":25542},{\"end\":25564,\"start\":25552},{\"end\":26070,\"start\":26062},{\"end\":26085,\"start\":26070},{\"end\":26098,\"start\":26085},{\"end\":26112,\"start\":26098},{\"end\":26120,\"start\":26112},{\"end\":26135,\"start\":26120},{\"end\":26147,\"start\":26135},{\"end\":26160,\"start\":26147},{\"end\":26170,\"start\":26160},{\"end\":26587,\"start\":26574},{\"end\":26598,\"start\":26587},{\"end\":26609,\"start\":26598},{\"end\":26617,\"start\":26609},{\"end\":26625,\"start\":26617},{\"end\":26639,\"start\":26625},{\"end\":26654,\"start\":26639},{\"end\":26666,\"start\":26654},{\"end\":26679,\"start\":26666},{\"end\":26689,\"start\":26679}]", "bib_venue": "[{\"end\":20074,\"start\":20067},{\"end\":20514,\"start\":20435},{\"end\":21025,\"start\":20977},{\"end\":21424,\"start\":21367},{\"end\":21807,\"start\":21764},{\"end\":22045,\"start\":22021},{\"end\":22353,\"start\":22323},{\"end\":22838,\"start\":22749},{\"end\":23215,\"start\":23187},{\"end\":23379,\"start\":23346},{\"end\":23692,\"start\":23671},{\"end\":24148,\"start\":24089},{\"end\":24609,\"start\":24549},{\"end\":24958,\"start\":24862},{\"end\":25618,\"start\":25564},{\"end\":26060,\"start\":25981},{\"end\":26721,\"start\":26689},{\"end\":20580,\"start\":20516},{\"end\":22914,\"start\":22840}]"}}}, "year": 2023, "month": 12, "day": 17}