{"id": 250340302, "updated": "2023-12-14 08:39:37.749", "metadata": {"title": "Graph Trend Filtering Networks for Recommendation", "authors": "[{\"first\":\"Wenqi\",\"last\":\"Fan\",\"middle\":[]},{\"first\":\"Xiaorui\",\"last\":\"Liu\",\"middle\":[]},{\"first\":\"Wei\",\"last\":\"Jin\",\"middle\":[]},{\"first\":\"Xiangyu\",\"last\":\"Zhao\",\"middle\":[]},{\"first\":\"Jiliang\",\"last\":\"Tang\",\"middle\":[]},{\"first\":\"Qing\",\"last\":\"Li\",\"middle\":[]}]", "venue": "ArXiv", "journal": "Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval", "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "Recommender systems aim to provide personalized services to users and are playing an increasingly important role in our daily lives. The key of recommender systems is to predict how likely users will interact with items based on their historical online behaviors, e.g., clicks, add-to-cart, purchases, etc. To exploit these user-item interactions, there are increasing efforts on considering the user-item interactions as a user-item bipartite graph and then performing information propagation in the graph via Graph Neural Networks (GNNs). Given the power of GNNs in graph representation learning, these GNNs-based recommendation methods have remarkably boosted the recommendation performance. Despite their success, most existing GNNs-based recommender systems overlook the existence of interactions caused by unreliable behaviors (e.g., random/bait clicks) and uniformly treat all the interactions, which can lead to sub-optimal and unstable performance. In this paper, we investigate the drawbacks (e.g., non-adaptive propagation and non-robustness) of existing GNN-based recommendation methods. To address these drawbacks, we introduce a principled graph trend collaborative filtering method and propose the Graph Trend Filtering Networks for recommendations (GTN) that can capture the adaptive reliability of the interactions. Comprehensive experiments and ablation studies are presented to verify and understand the effectiveness of the proposed framework. Our implementation based on PyTorch is available: https://github.com/wenqifan03/GTN-SIGIR2022.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/sigir/FanL0ZT022", "doi": "10.1145/3477495.3531985"}}, "content": {"source": {"pdf_hash": "ab294f6f10259d0ff22ca500db350b3a666ffe42", "pdf_src": "ACM", "pdf_uri": "[\"https://arxiv.org/pdf/2108.05552v2.pdf\"]", "oa_url_match": false, "oa_info": {"license": null, "open_access_url": null, "status": "CLOSED"}}, "grobid": {"id": "ec481fd03c9ee16324a7b265c66441c78395978c", "type": "plain-text", "url": "s3://ai2-s2-science-parse-plus-prod/parse-results/s2orc_worker/ab294f6f10259d0ff22ca500db350b3a666ffe42.txt", "contents": "\nGraph Trend Filtering Networks for Recommendation\nACMCopyright ACMJuly 11-15, 2022. 2022. July 11-15, 2022\n\nWenqi Fan wenqifan03@gmail.com \nXiaorui Liu xiaorui@msu.edu \nWei Jin jinwei2@msu.edu \nXiangyu Zhao xianzhao@cityu.edu.hk \nJiliang Tang \nQing Li \nWenqi Fan \nXiaorui Liu \nWei Jin \nXiangyu Zhao \nJiliang Tang \nQing Li \n\nThe Hong Kong Polytechnic University\nMichigan State University\nMichigan State University\nCity University of Hong\nKong\n\n\nMichigan State University\nThe Hong Kong Polytechnic University\n\n\nGraph Trend Filtering Networks for Recommendation\n\nProceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '22)\nthe 45th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '22)Madrid, Spain; Madrid, SpainACMJuly 11-15, 2022. 2022. July 11-15, 202210.1145/3477495.3531985CCS CONCEPTS \u2022 Information systems \u2192 Recommender systems. * Equal contributions. \u2020 Xiangyu Zhao is the corresponding author. ACM ISBN 978-1-4503-8732-3/22/07. . . $15.00 ACM Reference Format: New York, NY, USA, 10 pages. https://Collaborative FilteringRecommendationEmbedding PropagationGraph Neural NetworksTrend FilteringGraph Trend Filtering\nRecommender systems aim to provide personalized services to users and are playing an increasingly important role in our daily lives.The key of recommender systems is to predict how likely users will interact with items based on their historical online behaviors, e.g., clicks, add-to-cart, purchases, etc. To exploit these user-item interactions, there are increasing efforts on considering the useritem interactions as a user-item bipartite graph and then performing information propagation in the graph via Graph Neural Networks (GNNs). Given the power of GNNs in graph representation learning, these GNNs-based recommendation methods have remarkably boosted the recommendation performance. Despite their success, most existing GNNs-based recommender systems overlook the existence of interactions caused by unreliable behaviors (e.g., random/bait clicks) and uniformly treat all the interactions, which can lead to sub-optimal and unstable performance. In this paper, we investigate the drawbacks (e.g., non-adaptive propagation and non-robustness) of existing GNN-based recommendation methods. To address these drawbacks, we introduce a principled graph trend collaborative filtering method and propose the Graph Trend Filtering Networks for recommendations (GTN) that can capture the adaptive reliability of the interactions. Comprehensive experiments and ablation studies are presented to verify and understand the effectiveness of the proposed framework. Our implementation based on PyTorch is available 1 .\n\nINTRODUCTION\n\nPersonalized recommendations aim to alleviate information overload problem through assisting users in discovering items of interest, and they have been deployed to many user-oriented online services such as E-commerce (e.g., Amazon, Taobao), and Social Media sites (e.g., Facebook, Twitter, Weibo) [3,4,16,21,55]. The key of recommender systems is to predict whether users are likely to interact with items based on the historical interactions [5,12,20,56], including clicks, add-to-cart, purchases, etc. As a widely used solution, collaborative filtering (CF) techniques are developed to model historical user-item interactions, assuming that users who behave similarly are likely to have similar preferences towards items [4,15].\n\nAmong various collaborative filtering techniques, matrix factorization (MF) is the most popular one [21]. It embeds users and items into the vectorized representations (i.e., embeddings) and models the user-item interaction via the inner products between the user and item representations [11,37]. Later on, neural collaborative filtering (NeuCF) model is proposed to replace the inner product in MF model with neural networks in order to model the nonlinear interactions between users and items [21]. However, in these models, the user-item interactions are only considered in the objective function for model training, which leads to unsatisfactory exploitation of the interaction data. To better exploit the user-item interactions as well as the high-order connectivity therein, graph collaborative filtering models such as NGCF [46] and LightGCN [20] propose to explicitly propagate the user embedding e and item embedding e according to the user-item interaction through the  Figure 1: An illustration on unreliable user-item interactions. User 2 bought a one-time item (i.e., Handbag) for his mother's birthday present; User 3 was affected by the click-bait issue and was 'cheated' to interact with an item (i.e., Ring) by the attractive exposure features (e.g., headline or cover of the item).\n\npropagation:\ne +1 = 1 \u221a\ufe01 |N ( )| \u2211\ufe01 \u2208N ( ) 1 \u221a\ufe01 |N ( )| e ,(1)e +1 = 1 \u221a\ufe01 |N ( )| \u2211\ufe01 \u2208N ( ) 1 \u221a\ufe01 |N ( )| e(2)\nwhere N ( ) denotes the set of items that user interacts with and N ( ) denotes the set of users who interact with item . Such embedding propagation motivated by the feature aggregation in graph neural networks (GNNs) [9,13,22,31,32,34,51] is the key for graph collaborative filtering models to significantly advance the state-of-art of recommender systems. Despite their success, prior manner of modeling user-item relationships is insufficient to discover the heterogeneous reliability of interactions among instances in recommender systems. The key reason is that most existing deep recommender systems uniformly treat all the interactions. For instance, as shown in the propagation rule (1), the item embedding e is propagated to all relevant users equally. This leads to sub-optimal representation learning for recommendations based on the historical behavior data since the reliability of the interactions is often heterogeneous.\n\nIn fact, in most e-commerce platforms, a large portion of clicks (e.g., random/bait clicks) are not directly related to purchases and many purchases end up with negative reviews, where users' implicit feedback (e.g., click and purchase) is unreliable and cannot reflect the actual satisfaction and preferences of users [30,42,43,50]. As shown in Figure 1, with financial incentive, some sellers can sell their items with attractive exposure features (e.g., headline or cover of items), so as to deliberately mislead buyers (e.g., user 3) to interact (e.g., clicks, add-to-cart, purchases, etc.), which is known as click-bait issue; a user (i.e., user 2), who is interested in electronic products, purchased a one-time item (i.e., handbag) for his mother's birthday present. Worse still, such unreliable feedback may dominate the entire training dataset, and is hard to identify or prune, which may hinder the recommender systems from learning the actual user/item representations based on the user-item graph and make the recommender systems vulnerable to unreliable interactions.\n\nThe aforementioned deficiency significantly limits the applications of existing collaborative filtering methods in real-world recommender systems. Therefore, it is desired to design a new collaborative filtering method that adaptively propagates the embedding in recommender systems, which can lead to more accurate and robust recommendations. In this paper, inspired by the concepts of trend filtering [25,39] and graph trend filtering [32,48], we propose Graph Trend filtering Networks (GTN) to capture and learn the adaptive importance of the interactions in recommender systems. Our major contributions can be summarized as follows:\n\n\u2022 We investigate the drawbacks of existing GNNs-based recommendation methods such as non-adaptive propagation and nonrobustness from the perspective of Laplacian smoothness; \u2022 We introduce a principled graph trend collaborative filtering technique and propose a novel graph trend filtering networks framework (GTN) to capture the adaptive reliability of the interactions between users and items in recommender systems.\n\n\u2022 Comprehensive experiments and ablation study on various realworld datasets are conducted to demonstrate the superiority of the proposed framework.\n\n\nPRELIMINARY\n\nIn this section, we introduce the notations used in this paper and briefly review some preliminaries about embedding propagation in GNNs-based collaborative filtering.\n\n\nNotations and Definitions\n\nWe use bold upper-case letters such as E to denote matrices and bold lower-case letters such as e to define vectors. Given a matrix E \u2208 R ( + )\u00d7 , we use E to denote its -th row and E to denote its element in -th row and -th column. We define the Frobenius norm and \u2113 1 norm of matrix E as \u2225E\u2225 = \u221a\ufe03 E 2 and \u2225E\u2225 1 = |E |, respectively. We define\n\u2225E\u2225 2 = max (E) where max (E)\nis the largest singular value of E. Given two matrices E, F \u2208 R \u00d7 , we define their inner product as \u27e8E, F\u27e9 = tr(E \u22a4 F).\n\nThe historical interactions between users and items in recommender systems can be naturally represented as a bipartite graph G = {V, E}, where the node set V includes user nodes { 1 , . . . , } and item nodes { +1 , . . . , + }, and the implicit interactions can be denoted as the edges between user nodes and item nodes in the graph. We denote the undirected edge set as E = { 1 , . . . , | E | }.\n\nThe graph structure of G can be represented as an adjacent matrix A \u2208 R ( + )\u00d7( + ) , where A = 1 when there exists an edge or interaction between nodes and . Note that there is no direct interaction within users or items so that the graph is a bipartite graph. We use N ( ) to denote the neighboring nodes of node , including itself. The graph Laplacian matrix is defined as L = D \u2212 A, where D is the diagonal degree matrix. Let \u0394 \u2208 {\u22121, 0, 1} | E |\u00d7 | V | be the oriented incident matrix, which contains one row for each edge. If \u2113 = ( , ), then \u0394 has the \u2113-th row as:\n\u0394 \u2113 = (0, . . . , \u22121 , . . . , 1 , . . . , 0),\nwhere the edge orientation can be arbitrary. In addition, we denote the embeddings of nodes in graph G as:\nE = [ e 1 , \u00b7 \u00b7 \u00b7 , e users embeddings\n, e +1 , \u00b7 \u00b7 \u00b7 , e + item embeddings\n] \u22a4 \u2208 R ( + )\u00d7(3)\nwhere is the dimension of embeddings.\n\n\nEmbedding Propagation and Smoothness\n\nGiven the embeddings E , the embedding propagation (i.e, Eq. (1) and Eq. (2)) in GNNs-based collaborative filtering can be written in a matrix form:\nE +1 =\u00c3E(4)\nwhere\u00c3 =D \u2212 1 2\u00c2D \u2212 1 2 and\u00c2 = A + I whose degree matrix isD. The propagation is motivated by the graph convolutional operator in graph neural networks [27], and it is shown as solving the Laplacian smoothing problem [34] to enforce embedding smoothness over the user-item interactions arg min\nE\u2208R ( + ) \u00d7 tr(E \u22a4 (I \u2212\u00c3)E).(5)\nIn other words, the embedding propagation in Eq (4) is equivalent to the gradient descent on problem (5) with the initialization E and stepsize 1/2. It can be rewritten in an edge-wise form as:\ntr(E \u22a4 (I \u2212\u00c3)E) = \u2211\ufe01 ( , ) \u2208 E \u2225 e \u221a + 1 \u2212 e \u221a\ufe01 + 1 \u2225 2 2(6)\nwith being the node degree of node . It is clear that the embedding propagation essentially enforces the user embedding e and item embedding e to be close (i.e., embedding smoothness), if there exist interactions between them. As a result, their inner products become large, which can provide positive predictions on the recommendation. However, the embedding smoothness is equally imposed over all the interactions as showed in Eq. (6). Consequently, the embedding propagation might cause inappropriate smoothness caused by unreliable interactions such as unintended clicks. For instance, if a user randomly clicks some items, it doesn't necessarily mean the user actually likes the items. Unfortunately, the embedding propagation due to these interactions will enforce the user embedding to be similar to those items. As a result, the recommender system will rank these items at the top for the user's recommendation. Such non-adaptive propagation results in the non-robustness of graph collaborative filtering, which limits the application in real-world recommender systems where unreliable interactions widely exist.\n\nTo verify the non-robustness of such embedding propagation, we conduct a preliminary study to assess the performance of a representative graph collaborative filtering method when the interactions between users and items contain different ratios of random noise. This is evaluated by injecting random user-item interactions into the datasets. The experimental results are shown in Figure 2. It can be observed that the performance of LightGCN [20] drops significantly when the interactions between users and items become more noisy, which confirms our discussion.\n\n\nTHE PROPOSED METHOD\n\nIn this section, we motivate the idea of graph trend collaborative filtering which models adaptive smoothness over the interactions, and introduce the corresponding algorithm. Finally, we present the overall recommendation framework as well as the training process.\n\n\nDesign Motivation\n\nThe non-adaptive and non-robust characteristics of embedding propagation in existing graph collaborative filtering methods have been discussed and verified in Section 2.2. To build a more reliable and robust recommender system, we aim to design a new collaborative filtering method that models the adaptive smoothness over the user-item interactions. Motivated by the concepts of trend filtering [25,39] and graph trend filtering [48], we propose the following embedding smoothness objective for user-item graph in recommendations:\n\narg min\nE\u2208R ( + ) \u00d7 1 2 \u2225E \u2212 E in \u2225 2 + \u2225\u0394E\u2225 1 ,(7)\nwhere E in contains the initial embeddings of items and users.\u0394 = \u0394D \u2212 1 2 is the incident matrix normalized by the square root of node degrees 2 . is a hyper-parameter to control the strength of the embedding smoothness. The first term preserves the proximity with the initial embedding of users and items, and the second term imposes embedding smoothness over the interactions E since\n\u2225\u0394E\u2225 1 = \u2211\ufe01 ( , ) \u2208 E \u2225 e \u221a + 1 \u2212 e \u221a\ufe01 + 1 \u2225 1 .(8)\nIt can be also rewritten as\n\u2225\u0394E\u2225 1 = \u2211\ufe01 ( , ) \u2208 E W \u00b7 \u2225 e \u221a + 1 \u2212 e \u221a\ufe01 + 1 \u2225 2 2 (9) where W = \u2225 e \u221a +1 \u2212 e \u221a +1 \u2225 1 \u2225 e \u221a +1 \u2212 e \u221a +1 \u2225 2 2 .\nComparing with the objective in Eq. (6), \u2225\u0394E\u2225 1 can be considered as a re-weighted version of tr(E \u22a4 (I \u2212\u00c3)E) where the smoothness over the interaction ( , ) in the user-item graph is weighted by\nW . Note that W is small if e \u221a +1\nis far away from\ne \u221a +1 , while W is large if e \u221a +1 is close to e \u221a +1\n. Therefore, if an interaction happens between a user and an item that has significantly different embeddings, such interaction might be unreliable or might not reflect the actual preference of the user, so that it should be down weighted.\n\nThe embedding smoothness prior defined in Eq. (7) inherits the adaptive smoothness property from graph trend filtering that has been shown to adapt to inhomogeneity in the level of smoothness of signal and tend to provide piecewise polynomial (e.g., piecewise constant) signal over the graph [48]. Specifically, the sparsity induced by the penalty \u2225\u0394E\u2225 1 implies that many of the embedding differences e\n\u221a +1 \u2212 e \u221a +1\nare zeros across the edges ( , ) if the embedding difference is sufficiently small. In other words, if the user and item embeddings are very similar, the filtering will make them even more closer. Moreover, the penalty is able to tolerate large embedding differences. That is to say, if the user and item embeddings are significantly different, the filtering will maintain the difference, which avoids improper smoothing. Therefore, it leads to more robust and adaptive propagation. \n\n\nGraph Trend Collaborative Filtering\n\nWith the defined smoothness assumption in Eq. (7), we here derive an efficient algorithm to achieve the desired adaptive smoothness property for user-item graph in recommendations. The objective in Eq. (7) is convex so that any local minimum is equivalent to the global minimum. Moreover, it is composed by a smooth function (E) = 1 2 \u2225E \u2212 E in \u2225 2 and a nonsmooth function (E) = \u2225\u0394E\u2225 1 , which are further coupled by the normalized incident matrix\u0394 of the user-item graph. To decouple these two components, we first reformulate the problem as an equivalent constrained problem:\nmin E,F 1 2 \u2225E \u2212 E in \u2225 2 + \u2225F\u2225 1 s.t. F =\u0394E\nThis is equivalent to the following saddle point problem by introducing the Lagrangian multipliers Y \u2208 R | E |\u00d7 :\nmin E,F max Y 1 2 \u2225E \u2212 E in \u2225 2 + \u27e8\u0394E, Y\u27e9 + \u2225F\u2225 1 + \u27e8\u2212F, Y\u27e9.\nUsing the conjugate function for (F) = \u2225F\u2225 1 :\n* (Y) sup X \u27e8Y, X\u27e9 \u2212 (X),\nthe saddle point problem can we rewritten as:\nmin E max Y 1 2 \u2225E \u2212 E in \u2225 2 + \u27e8\u0394E, Y\u27e9 \u2212 * (Y).\nThen we can apply the primal-dual algorithm, Proximal Alternating Predictor-Corrector (PAPC) [33], to obtain the following iterative solver:\n\u0112 +1 = E \u2212 (E \u2212 E in ) \u2212\u0394 \u22a4 Y (10) Y +1 = prox * (Y +\u0394\u0112 +1 )(11)E +1 = E \u2212 (E \u2212 E in ) \u2212\u0394 \u22a4 Y +1(12)\nwhere prox * (X) = arg min Z 1 2 \u2225Z \u2212 X\u2225 2 + * (Z), and and are the primal and dual stepsizes to be specified later. The first step in Eq. (10) is a gradient descent step on the primal variable E , and the second step in Eq. (11) is a proximal dual ascent step on the dual variable Y based on the primal prediction\u0112 +1 . The third step in Eq. (12) is a gradient descent step on the primal variable based on the dual variable Y +1 .\n\nNext we describe the computation for the proximal operator prox * (X). By definition, the proximal operator of 1 (X) is defined as:\nprox 1 (X) = arg min Z 1 2 \u2225Z \u2212 X\u2225 2 + \u2225Z\u2225 1 ,\nwhich is equivalent to the soft-thresholding operator:\n(X) = sign(X ) max(|X | \u2212 , 0) = X \u2212 sign(X ) min(|X |, ).\nUsing the Moreau's decomposition principle [1] \nX = prox * (X) + prox 1 ( X ),\nwe can derive:\nprox * (X) = X \u2212 prox 1 ( X ) = X \u2212 X \u2212 sign( X ) min(| X |, ) = sign(X) min(|X|, ).\nParameter settings. We provide the following theorem to ensure the convergence of the derived iteration solver and provide guidance on the parameter settings.\n\nTheorem 1. Under the stepsize setting = 1 and = 1 2 , the iterations in Eq. (10), (11) and (12) are guaranteed to converge to the optimal solution of problem (7).\n\nProof. It is proved in the work [33] that the iterations in Eq. (10), (11) and (12) converge to the optimal solution if the parameters satisfy < 2 and \u2264 [8]. Therefore, to ensure convergence, it is sufficient to choose = 1 < 2 and\n1 \u2225\u0394\u0394 \u22a4 \u2225 2 , where = 1 is the Lipschitz constant of \u2207\u2225E \u2212 E in \u2225 2 = E \u2212 E in . Note that \u2225L\u2225 2 = \u2225\u0394 \u22a4\u0394 \u2225 2 = \u2225\u0394\u0394 \u22a4 \u2225 2 \u2264 2= 1 2 \u2264 1 \u2225\u0394\u0394 \u22a4 \u2225 2 .\n\u25a1\n\nUnder the parameter setting implied by Theorem 1, the iterative solver can be simplified and summarized in Figure 3. Complexity analysis. The proposed graph trend collaborative filtering in Figure 3 is efficient and scalable. The major computation cost comes from three sparse matrix multiplications, including \u0394 \u22a4 Y ,\u0394\u0112 +1 and\u0394 \u22a4 Y +1 . Note that the last one\u0394 \u22a4 Y only needs to be computed in the output step but not in each iteration. The where |E | is the number of interactions between users and items and is the dimension of embedding. Thus, the computation complexity is in the same order as the embedding propagation in Eq. (4).\n\uf8f1 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f2 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f3\u0112 +1 = E in \u2212\u0394 \u22a4 \u0232 Y +1 = Y + 1 2\u0394\u0112 +1 Y +1 = sign(\u0232 +1 ) min(|\u0232 +1 |, ) Output: E +1 = E in \u2212\u0394 \u22a4 Y +1\n\nGraph Trend Filtering Networks\n\nIn this subsection, we introduce the graph trend filtering networks (GTN) which includes four major components: 1) embedding initialization; 2) embedding filtering; 3) model prediction; and 4) model training. Embedding initialization. Given the general situations where only the user-item interaction data is available while there is no features for the user or item, we first randomly initialize the user and item embeddings:\nE in = [ e 0 1 , \u00b7 \u00b7 \u00b7 , e 0 users embeddings , e 0 +1 , \u00b7 \u00b7 \u00b7 , e 0 + item embeddings ] \u22a4 \u2208 R ( + )\u00d7 .\nIn some applications where the features of users or items are available, we can either use the given features or concatenate them with randomly initialized embeddings. Embedding Filtering. Given the initialized user and item embeddings E in , we apply the proposed graph trend collaborative filtering (GTCF as showed in Figure 3) on E in \u2208 R ( + )\u00d7 with iterations, such that we can extract the final representations of users and items:\nE = [ e 1 , \u00b7 \u00b7 \u00b7 , e users embeddings\n, e +1 , \u00b7 \u00b7 \u00b7 , e + item embeddings ] \u22a4 \u2208 R ( + )\u00d7 which encodes the user-item interaction information and follows the embedding smoothness assumption in Eq. (7). Model Prediction. Finally, the model prediction on whether a user is interested in an item is defined as the inner product between their final representations E :\u02c6= e e . The prediction will be used as the ranking score for recommendation generation. Model Training. The model parameters to be learned are the initial user and item embeddings E in . To train a good set of model parameters of our proposed method, we need to identify an objective function to optimize. In this paper, we adopt the pairwise BPR loss [37] to optimize model parameters based on the implicit feedback in recommendations, assuming that score predictions on the observed interactions should be higher than the unobserved interactions:\nL BPR = \u2211\ufe01 ( , , ) \u2208 \u2212 ln (\u02c6\u2212\u02c6) + \u2225E in \u2225 2 ,\nwhere controls the 2 regularization to reduce the risk of overfitting. (\u00b7) is the Sigmoid function. The set = {( , , )|( , ) \u2208 E, ( , ) \u2209 E} denotes the pairwise training data, where ( , ) \u2208 E indicates that the interactions between user and item is observed (positive), while ( , ) \u2209 E indicates that the interaction between user and item is not observed (negative).\n\n\nEXPERIMENT 4.1 Experimental Settings\n4.1.1 Datasets.\nTo demonstrate the effectiveness of the proposed method, we conduct comprehensive experiments on four widely used benchmark datasets in recommender systems, including Gowalla, Yelp2018, Amazon-Book, and LastFM. The first three datasets are released by NGCF [46] and LightGCN [20]; the LastFM dataset is provided by KGAT [45]. For fair comparison, we closely follow the experimental setting of LightGCN 3 . In the training phase, each observed user-item interaction is treated as a positive instance, while we conduct negative sampling to randomly sample one unobserved item and pair it with the user as a negative instance. The statistical summary of these four datasets can be found in Table 1. GNNs, which is an extension of NGCF [46] by removing feature transformation and nonlinear activation, achieving the state-ofthe-art performance for recommendations. Note that in this work, we don't compare with SGL [49], one of the state-of-art recommendation methods with self-supervised learning (SSL) enhanced on loss objective. What's more, the contribution of SGL is totally orthogonal to the contributions in our work, since we are designing a new collaborative filter for recommendations, regardless of the loss function. We will explore combination between our proposed GTN and SSL in the future.\n\n\nEvaluation Metrics.\n\nIn order to evaluate the quality of recommendation results for ranking task, we adopt two widely used evaluation metrics: Recall@ and Normalized Discounted Cumulative Gain (NDCG@ ) [20,46]. By default, we set the value of as 20. Note that higher values of Recall@ and NDCG@ indicate better performance for recommendations. We report the average metrics for all users in the test set. \n\n\nPerformance Comparison of Recommender Systems\n\nWe first compare the performance of all recommendation methods. Table 2 reports the overall performance comparison with regard to Recall@20 and NDCG@20 metrics on four datasets. We make the following observations:\n\n\u2022 Our proposed GTN achieves the best performance, and consistently outperforms all the baselines across all datasets in terms of all metrics. For instance, it significantly improves the strongest baselines by 12.77% on NDCG@20 and 9.61% on Recall@20 in LastFM dataset. Such improvement demonstrates the effectiveness of our proposed method and we attribute it to the imposed local adaptive smoothness over the user-item interactions. The local adaptive smoothness greatly improves the adaptiveness of the aggregation scheme in GNN-based models and alleviates the vulnerability to noisy user-item interactions. Hence, it justifies the great potential of studying graph trend filtering in recommender systems. \u2022 As an earlier CF method, Matrix Factorization (MF) shows relatively poor performance for recommendations, while others like NeuCF and GNN-based methods show much stronger performance. This suggests the powerful capability on representation learning of deep neural networks techniques in recommendations. \u2022 The results of NGCF and DGCF are at the same level, being better than MF and NeuCF methods. It demonstrates the importance of modeling the local structure of a node in the user-item graph to enhance the representation learning of users and items. By stacking propagation layers, most GNN-based recommendation methods can effectively capture collaborative signals via highorder connectivity. 6 https://github.com/wenqifan03/GTN-SIGIR2022\n\n\u2022 LightGCN is a strong baseline as it almost beats MF, NeuCF, GC-MC, NGCF, Mult-VAE, and DGCF in all datasets. It inherits the characteristics of NGCF as well as the embedding propagation scheme of GNNs. However, during the embedding propagation process, LightGCN tends to enforce the user embedding and item embedding to be close if there exist interactions between them. It can result in inappropriate smoothness caused by unreliable interactions such as unintended clicks, thus leading to sub-optimal performance. On the contrary, the proposed GTN provides adaptive embedding smoothness over the user-item interactions by taking advantage of graph trend filtering. As a result, our proposed method routinely achieves better recommendation performance than LightGCN in terms of Recall@20 and NDCG@20 metrics on four datasets.\n\n\nStudy of Robustness and Adaptive Smoothness\n\n4.3.1 Robustness against random perturbation. As the useritem graph may contain a large portion of unreliable or noisy edges (e.g., random or bait clicks) which cannot reflect the actual satisfaction and preferences of users in real-world systems, developing a robust GNN-based recommender system against such noise is essential in providing high-quality recommendations and improving user online experience. We now investigate the robustness of different GNN-based recommendation methods under different severity of noise, i.e., different ratios of noisy edges in the user-item graph. Specifically, we perturb the test data by randomly injecting a certain ratio of edges and evaluate the recommendation performance of the models trained on clean data. In addition, we vary the ratio of noisy edges in the range of {5%, 6%, 8%, 10%, 15%, 20%, 30%, 50%}. Note that we also call the aforementioned noise ratio as perturbation rate.\n\nThe main results are shown in Figure 4. From the figure, we can see that our proposed method GTN consistently outperforms all other baselines (i.e., NGCF and LightGCN), implying that our method can effectively resist random noises in user-item graph for recommendations. This promising performance can be attributed to the consideration of adaptive embedding smoothness over useritem interactions that are modeled by the proposed graph trend collaborative filtering. It is worth noting that under higher noise ratio, GTN method even outperforms the baselines by a larger margin. Specifically, the performance of LightGCN significantly drops when the perturbation rate is larger than 20% especially on Gowalla and Yelp2018; the performance of NGCF is almost the worst though relatively stable against random perturbation. On  Recall@20 NDCG@20 Recall@20 NDCG@20 Recall@20 NDCG@20 Recall@20 NDCG@20 the contrary, GTN maintains its high performance across different noise ratios, which demonstrates its superior robustness.\n\n\nSparsity pattern.\n\nTo further investigate the piecewise constant trend captured by the proposed graph trend collaborative filtering, we study the sparsity patterns in the user-item embedding differences over the interactions,\u0394E . We define the sparsity ratio as the portion of elements whose absolute value is less than 0.2. The results are summarized in Table 4. It can be observed that for all datasets, the proposed GTN has a much larger portion of sparse elements in the embedding differences than others. This verifies the trend captured by the proposed GTCF. \n\n\nAblation Study of GTN\n\n4.4.1 Effect of . We first investigate the impact of the hyperparameter in GTN. The value of controls the impact of the embedding smoothness. Figure 5 shows the performance change of GTN w.r.t. Recall@20 and NDCG@20. The value of is searched from 0 to 9. We can find that GTN is relatively insensitive to . More specifically, when is larger than 2, the recommendation performance keeps stable. Moreover, increasing the value of from 0 to 1 significantly improves the recommendation performance, indicating that the smoothness captured by the proposed graph trend collaborative filtering is helpful.\n\n\nEffect of Number of Layers.\n\nTo study whether our proposed method GTN can benefit from stacking more propagation layers, we vary the number of layers in the range of {1, 2, 3, 4, 5} and report the performance of NGCF, LightGCN and GTN on all datasets in Table 3. From the table, we make the following observations:\n\n\u2022 With the increase of model depth, the recommendation performances of all GNN-based methods first increase and then decrease. Clearly, in most cases, the GNN-based methods achieve the peak performance with a model depth of 3, while more layers can degrade the prediction performance. This finding is consistent with the general observation of existing GNN-based methods such as NGCF and LightGCN. \u2022 Comparing with other methods (i.e., NGCF and LightGCN), we can observe that GTN achieves the best prediction performance on four datasets w.r.t. Recall@20 and NDCG@20 in most cases. More specifically, with five layers, our proposed method GTN achieves significant improvement over the strongest baselines by 19% on Recall@20 and 23% on NDCG@20 in LastFM dataset. These general observations justify the effectiveness of adaptive smoothness captured by graph trend collaborative filtering.\n\n\n4.4.3\n\nConvergence of GTCF. In Figure 6, the loss value of the objective in Eq. (7) is showed during the filtering process. Those four curves for different datasets verify the convergence of the proposed graph trend collaborative filtering.\n\n\nEffect of Training Epochs.\n\nWe plot the performance curves of NGCF, LightGCN and GTN w.r.t. training epochs in Figure 7. From the figure, we can observe that at the same epoch GTN always outperforms the other two methods and it also converges faster than the other two methods in most cases.\n\n\nRELATED WORK 5.1 Collaborative Filtering\n\nCollaborative Filtering (CF) is one of the most popular techniques in the modern recommender systems [41,57]. It assumes that users who behave similarly are likely to have similar preferences towards items [38]. To capture users' preferences towards items, one widely used paradigm of CF technique is to decompose useritem interaction data into embedding vectors of users and items [14]. For instance, among the various collaborative filtering techniques, matrix factorization (MF) is the most popular one, which aims to learn representation vectors to represent users and items and performs inner product between them to make predictions [37,52]. Later on, with the great success of deep neural networks on nonlinear representation learning [17,29,44,54], recent efforts have been made to apply deep neural networks to recommendation tasks and they have shown promising prediction performance. For example, NeuCF [21] is proposed to replace the inner product of MF model with nonlinear neural networks to model non-linear interactions between users and items. DSCF [18] adopts a bidirectional long short-term memory network (Bi-LSTM) based deep   language model to implicitly capture information from high-order neighbors to enhance user representations for recommendations.\n\n\nGNNs-based Recommender Systems\n\nDespite the great success achieved by the aforementioned CF methods, most of them treat each interaction as an independent instance and fail to capture deep collaborative signals between users and items, easily leading to sub-optimal representations of users and items [46]. Recent years have witnessed the great success of graph neural networks (GNNs) techniques in representation learning for graph data [10, 22-24, 35, 51]. The main idea of GNNs adopts a message-passing scheme to learn node embedding from local neighbors via aggregation and transformation operations. Meanwhile, data in recommender systems can be naturally denoted as graphs, where users and items can be denoted as nodes and their implicit interactions can be denoted as edges in the graph [16]. Hence, it is desirable to build recommender systems based on graph neural networks to capture deep collaborative signals in the user-item graph. For example, as the extension of a famous GNN variant GraphSage [19] in recommender systems, PinSage [53] is applied to learn the embedding of nodes in web-scale graphs for item recommendation. GraphRec [15,16] introduces a graph attention network framework to encoder user-item interactions and user-user social relations for social recommendations. NGCF [46] proposes to explicitly encode collaborative signals in the form of high-order connectivities by message-passing propagation for recommendations. Later on, LightGCN [20] is introduced to largely simplify the NGCF model by removing feature transformation and nonlinear activation, achieving the state-of-the-art prediction performance for recommendations.\n\n\nTrend Filtering\n\n\u2113 1 trend filtering [25] was first proposed in 2009 to estimate the trend in time series data. Later on, it was studied for nonparametric regression to provide adaptive piecewise polynomial estimation which adapts to the local level of smoothness [7,32,39,40]. Ortelli et.al [36] proposed to extend the trend filtering for tensor denoising. The idea of trend filtering was also extended to the general graph signal by generalizing the difference operator on 1D grid to the graph difference operator on general graphs [6,48]. It also exhibited piecewise polynomial behaviors on graphs. The work of [7] proposed multi-resolution local sets based piecewise-constant and piecewise-smooth dictionaries as graph signal representations on graphs. Recently, graph trend filtering also inspires the design of graph neural networks such as Elastic GNNs [32], which have been shown to be much more robust against adversarial graph attacks due to the enhanced local smoothness. To the best of our knowledge, trend filtering has not been studied in recommender systems. In this work, we make the first attempt to investigate trend filtering as a new collaborative filtering technique for recommender systems, and we hope the novel and principled design of graph trend filtering networks (GTN) can provide new inspirations in this important field.\n\n\nCONCLUSION\n\nAlthough existing graph neural networks based recommender systems achieve promising prediction performance, they are unable to discover the heterogeneous reliability of interactions among instances during the embedding propagation. In this work, we first analyze the drawbacks of the existing state-of-art GNNsbased collaborative filtering methods, such as non-adaptive propagation and non-robustness through the perspective of Laplacian smoothing in the user-item graph. To address these drawbacks, we introduce a principled graph trend collaborative filtering technique and propose a novel graph trend filtering networks framework (GTN) to capture the adaptive reliability of the interactions between users and items. Extensive experiments on four real-world datasets demonstrate the effectiveness of our proposed method. Moreover, the empirical study also demonstrates the benefits of modeling the adaptive reliability of the interactions between users and items for recommendations.\n\nFigure 2 :\n2Performance of LightGCN under different interaction perturbation rates.\n\nFigure 3 :\n3Graph Trend Collaborative Filtering (GTCF).\n\nFigure 4 :Figure 5 :\n45Recommendation performance under different perturbation rates. The effect of hyper-parameter under Recall@20 and NDCG@20 metrics.\n\nFigure 6 :\n6Loss value of Eq. (7) in the graph trend collaborative filtering process.\n\nFigure 7 :\n7Performance curves of NGCF, LightGCN, and GTN during training.\n\n\ncomputation complexity for each iteration is in the order (|E | )Topic 2: Collaborative Filtering \nSIGIR '22, July 11-15, 2022, Madrid, Spain \n\n\nTable 1 :\n1Basic statistics of benchmark datasets. NeuCF[21]: This method is the very first DNNs based collaborative filtering which stacks multiple hidden layers to capture their non-linear user and item interactions.\u2022 GC-MC [2]: The method proposes a graph auto-encoder framework for recommendations and generates representations of users and items through a form of differentiable message passing on the user-item graph. \u2022 Mult-VAE [28] 4 : This method develops a variant of Variational AutoEncoder (VAE) for item-based CF. \u2022 NGCF [46]: This method is the very first GNNs based CF to incorporate the high-order connectivity of user-item interactions for recommendations. \u2022 DGCF [47] 5 : This method is a disentangled CF to learn representations for different latent user intentions via GNNs, so as to exploit diverse relationships among users and items. \u2022 LightGCN [20] 3 : The method is a state-of-the-art CF based onDatasets \nUser-Item Interaction \n#Users #Items #Interactions \nGowalla \n29,858 \n40,981 \n1,027,370 \nYelp2018 \n31,668 \n38,048 \n1,561,406 \nAmazon-Book \n52,643 \n91,599 \n2,984,108 \nLastFM \n23,566 \n48,123 \n3,034,796 \n\n4.1.2 Baselines. To evaluate the effectiveness, we compare our \nproposed method with the following baselines: \n\u2022 MF [37]: This is the most classic CF method optimized by the \nBayesian Personalized Ranking (BPR) loss. \n\u2022 \n\nTable 2 :\n2The comparison of overall performance.Datasets \nGowalla \nYelp2018 \nAmazon-Book \nLastFM \nMetrics \nRecall@20 NDCG@20 Recall@20 NDCG@20 Recall@20 NDCG@20 Recall@20 NDCG@20 \n\nMethod \n\nMF \n0.1299 \n0.111 \n0.0436 \n0.0353 \n0.0252 \n0.0198 \n0.0725 \n0.0614 \nNeuCF \n0.1406 \n0.1211 \n0.045 \n0.0364 \n0.0259 \n0.0202 \n0.0723 \n0.0637 \nGC-MC \n0.1395 \n0.1204 \n0.0462 \n0.0379 \n0.0288 \n0.0224 \n0.0804 \n0.0736 \nNGCF \n0.156 \n0.1324 \n0.0581 \n0.0475 \n0.0338 \n0.0266 \n0.0774 \n0.0693 \nMult-VAE \n0.1641 \n0.1335 \n0.0584 \n0.045 \n0.0407 \n0.0315 \n0.078 \n0.07 \nDGCF \n0.1794 \n0.1521 \n0.064 \n0.0522 \n0.0399 \n0.0308 \n0.0794 \n0.0748 \nLightGCN \n0.1823 \n0.1553 \n0.0649 \n0.0525 \n0.042 \n0.0327 \n0.085 \n0.076 \nGTN (Ours) \n0.187 \n0.1588 \n0.0679 \n0.0554 \n0.045 \n0.0346 \n0.0932 \n0.0857 \nRelative Improvement (%) \n2.59 \n2.26 \n4.62 \n5.59 \n7.15 \n5.95 \n9.61 \n12.77 \n\n4.1.4 Parameter Settings. We implement our proposed model \nbased on PyTorch 6 . For embedding size , we tested the value \nof {16, 32, 64, 128, 256, 512}. The batch size and learning rate were \nsearched in {128, 512, 1024, 2048} and {0.0005, 0.001, 0.005, 0.01, 0.05, 0.1}, \nrespectively. We employ the Adam [26] to optimize the objective \nfunction in a mini-batch manner, where we first randomly sample \nmini-batch observed entries and then we pair it with an unobserved \nitem that is uniformly sampled from N ( ) for each observed \ninteraction ( , ). Note that we adopt the default hyper-parameters \nas suggested by the corresponding papers for all baselines, and we \nclosely follow the settings of the NGCF and LightGCN 3 for a fair \ncomparison. \n\n\n\nTable 3 :\n3The effect of the number of layers.Datasets \nGowalla \nYelp2018 \nAmazon-Book \nLastFM \nMethod \n\n\nTable 4 :\n4Sparsity ratio in the user-item embedding differences.Datasets \nGowalla Yelp2018 Amazon-Book LastFM \nMethod \nNGCF \n0.045 \n0.0289 \n0.0403 \n0.0835 \nLightGCN \n0.017 \n0.017 \n0.0233 \n0.0218 \nGTN (Ours) \n0.1241 \n0.1424 \n0.2612 \n0.2282 \n\n\nThe purpose of normalization is to ensure numerical stability and to reduce the dominating impacts of nodes with high degrees.\nhttps://github.com/gusye1234/LightGCN-PyTorch 4 https://github.com/dawenl/vae_cf 5 https://github.com/xiangwang1223/disentangled_graph_collaborative_filtering\nACKNOWLEDGMENTSThe research described in this paper has been partly supported by NSFC (project no.\nH Heinz, Patrick L Bauschke, Combettes, Convex Analysis and Monotone Operator Theory in Hilbert Spaces. Springer Publishing Company1st ed.. IncorporatedHeinz H. Bauschke and Patrick L. Combettes. 2011. Convex Analysis and Monotone Operator Theory in Hilbert Spaces (1st ed.). Springer Publishing Company, Incorporated.\n\nRianne Van Den, Thomas N Berg, Max Kipf, Welling, arXiv:1706.02263Graph convolutional matrix completion. arXiv preprintRianne van den Berg, Thomas N Kipf, and Max Welling. 2017. Graph convolutional matrix completion. arXiv preprint arXiv:1706.02263 (2017).\n\nBo Chen, Xiangyu Zhao, Yejing Wang, arXiv:2204.01390Wenqi Fan, Huifeng Guo, and Ruiming Tang. 2022. Automated Machine Learning for Deep Recommender Systems: A Survey. arXiv preprintBo Chen, Xiangyu Zhao, Yejing Wang, Wenqi Fan, Huifeng Guo, and Ruiming Tang. 2022. Automated Machine Learning for Deep Recommender Systems: A Survey. arXiv preprint arXiv:2204.01390 (2022).\n\nAttentive collaborative filtering: Multimedia recommendation with item-and component-level attention. Jingyuan Chen, Hanwang Zhang, Xiangnan He, Liqiang Nie, Wei Liu, Tat-Seng Chua, SIGIR. Jingyuan Chen, Hanwang Zhang, Xiangnan He, Liqiang Nie, Wei Liu, and Tat- Seng Chua. 2017. Attentive collaborative filtering: Multimedia recommendation with item-and component-level attention. In SIGIR. 335-344.\n\nAutoGSR: Neural Architecture Search for Graph-based Session Recommendation. Jingfan Chen, Guanghui Zhu, Haojun Hou, Chunfeng Yuan, Yihua Huang, SIGIR. Jingfan Chen, Guanghui Zhu, Haojun Hou, Chunfeng Yuan, and Yihua Huang. 2022. AutoGSR: Neural Architecture Search for Graph-based Session Recommendation. In SIGIR.\n\nSignal denoising on graphs via graph filtering. Siheng Chen, Aliaksei Sandryhaila, M F Jos\u00e9, Jelena Moura, Kovacevic, GlobalSIP. IEEE. Siheng Chen, Aliaksei Sandryhaila, Jos\u00e9 MF Moura, and Jelena Kovacevic. 2014. Signal denoising on graphs via graph filtering. In GlobalSIP. IEEE, 872-876.\n\nRepresentations of piecewise smooth signals on graphs. Siheng Chen, Rohan Varma, Aarti Singh, Jelena Kova\u010devi\u0107, 2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEESiheng Chen, Rohan Varma, Aarti Singh, and Jelena Kova\u010devi\u0107. 2016. Representations of piecewise smooth signals on graphs. In 2016 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEE, 6370-6374.\n\nR K Fan, Fan Chung Chung, Graham, Spectral graph theory. Number 92. American Mathematical SocFan RK Chung and Fan Chung Graham. 1997. Spectral graph theory. Number 92. American Mathematical Soc.\n\nCharu Aggarwal, and Jiliang Tang. 2020. Epidemic graph convolutional network. Tyler Derr, Yao Ma, Wenqi Fan, Xiaorui Liu, WSDM. Tyler Derr, Yao Ma, Wenqi Fan, Xiaorui Liu, Charu Aggarwal, and Jiliang Tang. 2020. Epidemic graph convolutional network. In WSDM. 160-168.\n\nSigned graph convolutional networks. Tyler Derr, Yao Ma, Jiliang Tang, 2018 IEEE International Conference on Data Mining (ICDM). IEEETyler Derr, Yao Ma, and Jiliang Tang. 2018. Signed graph convolutional networks. In 2018 IEEE International Conference on Data Mining (ICDM). IEEE, 929-934.\n\nWenqi Fan, Tyler Derr, Yao Ma, Jianping Wang, Jiliang Tang, Qing Li, Deep Adversarial Social Recommendation. In IJCAI. Wenqi Fan, Tyler Derr, Yao Ma, Jianping Wang, Jiliang Tang, and Qing Li. 2019. Deep Adversarial Social Recommendation. In IJCAI. 1351-1357.\n\nAttacking Black-box Recommendations via Copying Cross-domain User Profiles. Wenqi Fan, Tyler Derr, Xiangyu Zhao, Yao Ma, Hui Liu, Jianping Wang, Jiliang Tang, Qing Li, ICDE. IEEEWenqi Fan, Tyler Derr, Xiangyu Zhao, Yao Ma, Hui Liu, Jianping Wang, Jiliang Tang, and Qing Li. 2021. Attacking Black-box Recommendations via Copying Cross-domain User Profiles. In ICDE. IEEE, 1583-1594.\n\nWenqi Fan, Wei Jin, Xiaorui Liu, Han Xu, Xianfeng Tang, Suhang Wang, Qing Li, Jiliang Tang, Jianping Wang, C Aggarwal, arXiv:2108.03388Jointly Attacking Graph Neural Network and its Explanations. arXiv preprintWenqi Fan, Wei Jin, Xiaorui Liu, Han Xu, Xianfeng Tang, Suhang Wang, Qing Li, Jiliang Tang, Jianping Wang, and C. Aggarwal. 2021. Jointly Attacking Graph Neural Network and its Explanations. arXiv preprint arXiv:2108.03388 (2021).\n\nDeep modeling of social relations for recommendation. Wenqi Fan, Qing Li, Min Cheng, Thirty-Second AAAI Conference on Artificial Intelligence. Wenqi Fan, Qing Li, and Min Cheng. 2018. Deep modeling of social relations for recommendation. In Thirty-Second AAAI Conference on Artificial Intelligence.\n\nGraph neural networks for social recommendation. Wenqi Fan, Yao Ma, Qing Li, Yuan He, Eric Zhao, Jiliang Tang, Dawei Yin, Wenqi Fan, Yao Ma, Qing Li, Yuan He, Eric Zhao, Jiliang Tang, and Dawei Yin. 2019. Graph neural networks for social recommendation. In WWW. 417-426.\n\nJiliang Tang, and Dawei Yin. 2020. A graph neural network framework for social recommendations. Wenqi Fan, Yao Ma, Qing Li, Jianping Wang, Guoyong Cai, IEEE TKDE. Wenqi Fan, Yao Ma, Qing Li, Jianping Wang, Guoyong Cai, Jiliang Tang, and Dawei Yin. 2020. A graph neural network framework for social recommendations. IEEE TKDE (2020).\n\nDeep adversarial canonical correlation analysis. Wenqi Fan, Yao Ma, Han Xu, Xiaorui Liu, Jianping Wang, Qing Li, Jiliang Tang, Proceedings of the 2020 SIAM International Conference on Data Mining (SDM). SIAM. the 2020 SIAM International Conference on Data Mining (SDM). SIAMWenqi Fan, Yao Ma, Han Xu, Xiaorui Liu, Jianping Wang, Qing Li, and Jiliang Tang. 2020. Deep adversarial canonical correlation analysis. In Proceedings of the 2020 SIAM International Conference on Data Mining (SDM). SIAM, 352-360.\n\nWenqi Fan, Yao Ma, Dawei Yin, Jianping Wang, Jiliang Tang, Qing Li, Deep social collaborative filtering. In RecSys. Wenqi Fan, Yao Ma, Dawei Yin, Jianping Wang, Jiliang Tang, and Qing Li. 2019. Deep social collaborative filtering. In RecSys. 305-313.\n\nInductive representation learning on large graphs. Rex William L Hamilton, Jure Ying, Leskovec, NeurIPS. William L Hamilton, Rex Ying, and Jure Leskovec. 2017. Inductive representation learning on large graphs. In NeurIPS. 1025-1035.\n\nLightGCN: Simplifying and Powering Graph Convolution Network for Recommendation. Xiangnan He, X Kuan Deng, Y Wang, Yongdong Li, Meng Zhang, Wang, ACM SIGIRXiangnan He, Kuan Deng, X. Wang, Y. Li, Yongdong Zhang, and Meng Wang. 2020. LightGCN: Simplifying and Powering Graph Convolution Network for Recommendation. ACM SIGIR (2020).\n\n. Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, Tat-Seng Chua, Neural Collaborative Filtering. WWWXiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. Neural Collaborative Filtering. WWW (2017).\n\nNode similarity preserving graph convolutional networks. Wei Jin, Tyler Derr, Yiqi Wang, Yao Ma, Zitao Liu, Jiliang Tang, Proceedings of the 14th ACM International Conference on Web Search and Data Mining. the 14th ACM International Conference on Web Search and Data MiningWei Jin, Tyler Derr, Yiqi Wang, Yao Ma, Zitao Liu, and Jiliang Tang. 2021. Node similarity preserving graph convolutional networks. In Proceedings of the 14th ACM International Conference on Web Search and Data Mining. 148-156.\n\nAutomated self-supervised learning for graphs. Wei Jin, Xiaorui Liu, Xiangyu Zhao, Yao Ma, Neil Shah, Jiliang Tang, arXiv:2106.05470arXiv preprintWei Jin, Xiaorui Liu, Xiangyu Zhao, Yao Ma, Neil Shah, and Jiliang Tang. 2021. Automated self-supervised learning for graphs. arXiv preprint arXiv:2106.05470 (2021).\n\nWei Jin, Yao Ma, Xiaorui Liu, Xianfeng Tang, Suhang Wang, and Jiliang Tang. 2020. Graph structure learning for robust graph neural networks. In KDD. Wei Jin, Yao Ma, Xiaorui Liu, Xianfeng Tang, Suhang Wang, and Jiliang Tang. 2020. Graph structure learning for robust graph neural networks. In KDD. 66-74.\n\n2009. \u2113 1 trend filtering. Seung-Jean Kim, Kwangmoo Koh, Stephen Boyd, Dimitry Gorinevsky, SIAM review. 51Seung-Jean Kim, Kwangmoo Koh, Stephen Boyd, and Dimitry Gorinevsky. 2009. \u2113 1 trend filtering. SIAM review 51, 2 (2009), 339-360.\n\nAdam: A Method for Stochastic Optimization. P Diederik, Jimmy Kingma, Ba, ICLR. Diederik P. Kingma and Jimmy Ba. 2015. Adam: A Method for Stochastic Optimization. In ICLR.\n\nSemi-supervised classification with graph convolutional networks. N Thomas, Max Kipf, Welling, arXiv:1609.02907arXiv preprintThomas N Kipf and Max Welling. 2016. Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907 (2016).\n\nVariational Autoencoders for Collaborative Filtering. Dawen Liang, R Krishnan, M Hoffman, T Jebara, WWWDawen Liang, R. Krishnan, M. Hoffman, and T. Jebara. 2018. Variational Autoencoders for Collaborative Filtering. WWW (2018).\n\nDoes Gender Matter? Towards Fairness in Dialogue Systems. Haochen Liu, Jamell Dacon, Wenqi Fan, Hui Liu, Zitao Liu, Jiliang Tang, Proceedings of the 28th International Conference on Computational Linguistics. the 28th International Conference on Computational LinguisticsHaochen Liu, Jamell Dacon, Wenqi Fan, Hui Liu, Zitao Liu, and Jiliang Tang. 2020. Does Gender Matter? Towards Fairness in Dialogue Systems. In Proceedings of the 28th International Conference on Computational Linguistics. 4403-4416.\n\nHaochen Liu, Yiqi Wang, Wenqi Fan, Xiaorui Liu, Yaxin Li, Shaili Jain, K Anil, Jiliang Jain, Tang, arXiv:2107.06641Trustworthy AI: A Computational Perspective. arXiv preprintHaochen Liu, Yiqi Wang, Wenqi Fan, Xiaorui Liu, Yaxin Li, Shaili Jain, Anil K Jain, and Jiliang Tang. 2021. Trustworthy AI: A Computational Perspective. arXiv preprint arXiv:2107.06641 (2021).\n\nGraph Neural Networks with Adaptive Residual. Xiaorui Liu, Jiayuan Ding, Wei Jin, Han Xu, Yao Ma, Zitao Liu, Jiliang Tang, NeurIPS. Xiaorui Liu, Jiayuan Ding, Wei Jin, Han Xu, Yao Ma, Zitao Liu, and Jiliang Tang. 2021. Graph Neural Networks with Adaptive Residual. In NeurIPS.\n\nElastic Graph Neural Networks. Xiaorui Liu, Wei Jin, Yao Ma, Yaxin Li, Hua Liu, Yiqi Wang, Ming Yan, Jiliang Tang, ICML. PMLR. Xiaorui Liu, Wei Jin, Yao Ma, Yaxin Li, Hua Liu, Yiqi Wang, Ming Yan, and Jiliang Tang. 2021. Elastic Graph Neural Networks. In ICML. PMLR, 6837-6849.\n\nOn a generalization of the iterative soft-thresholding algorithm for the case of non-separable penalty. Ignace Loris, Caroline Verhoeven, Inverse Problems. 27125007Ignace Loris and Caroline Verhoeven. 2011. On a generalization of the iterative soft-thresholding algorithm for the case of non-separable penalty. Inverse Problems 27, 12 (2011), 125007.\n\nA Unified View on Graph Neural Networks as Graph Signal Denoising. Yao Ma, Xiaorui Liu, Tong Zhao, Yozen Liu, Jiliang Tang, Neil Shah, 10.1145/3459637.34822251202\u00e2\u20ac\"1211Proceedings of the 30th ACM International Conference on Information Knowledge Management (Virtual Event. the 30th ACM International Conference on Information Knowledge Management (Virtual EventQueensland, Australia; New York, NY, USAAssociation for Computing MachineryCIKM '21)Yao Ma, Xiaorui Liu, Tong Zhao, Yozen Liu, Jiliang Tang, and Neil Shah. 2021. A Unified View on Graph Neural Networks as Graph Signal Denoising. In Proceedings of the 30th ACM International Conference on Information Knowledge Management (Virtual Event, Queensland, Australia) (CIKM '21). Association for Computing Machinery, New York, NY, USA, 1202\u00e2\u20ac\"1211. https://doi.org/10. 1145/3459637.3482225\n\nDeep Learning on Graphs. Yao Ma, Jiliang Tang, Cambridge University PressYao Ma and Jiliang Tang. 2020. Deep Learning on Graphs. Cambridge University Press.\n\nFrancesco Ortelli, Sara Van De Geer, arXiv:2101.10692Tensor denoising with trend filtering. arXiv preprintFrancesco Ortelli and Sara van de Geer. 2021. Tensor denoising with trend filtering. arXiv preprint arXiv:2101.10692 (2021).\n\nBPR: Bayesian Personalized Ranking from Implicit Feedback. C Steffen Rendle, Zeno Freudenthaler, L Gantner, Schmidt-Thieme, UAI. Steffen Rendle, C. Freudenthaler, Zeno Gantner, and L. Schmidt-Thieme. 2009. BPR: Bayesian Personalized Ranking from Implicit Feedback. In UAI.\n\nSocial recommendation: a review. Jiliang Tang, Xia Hu, Huan Liu, Social Network Analysis and Mining. 3Jiliang Tang, Xia Hu, and Huan Liu. 2013. Social recommendation: a review. Social Network Analysis and Mining 3, 4 (2013), 1113-1133.\n\nAdaptive piecewise polynomial estimation via trend filtering. J Ryan, Tibshirani, Annals of statistics. 42Ryan J Tibshirani et al. 2014. Adaptive piecewise polynomial estimation via trend filtering. Annals of statistics 42, 1 (2014), 285-323.\n\nTomoya Wakayama, Shonosuke Sugasawa, arXiv:2104.02456Locally Adaptive Smoothing for Functional Data. arXiv preprintTomoya Wakayama and Shonosuke Sugasawa. 2021. Locally Adaptive Smoothing for Functional Data. arXiv preprint arXiv:2104.02456 (2021).\n\nCollaborative deep learning for recommender systems. Hao Wang, Naiyan Wang, Dit-Yan Yeung, ACM KDD. Hao Wang, Naiyan Wang, and Dit-Yan Yeung. 2015. Collaborative deep learning for recommender systems. In ACM KDD. 1235-1244.\n\nShoujin Wang, Liang Hu, Yan Wang, Longbing Cao, Z Quan, Mehmet Sheng, Orgun, arXiv:2001.04830Sequential recommender systems: challenges, progress and prospects. arXiv preprintShoujin Wang, Liang Hu, Yan Wang, Longbing Cao, Quan Z Sheng, and Mehmet Orgun. 2019. Sequential recommender systems: challenges, progress and prospects. arXiv preprint arXiv:2001.04830 (2019).\n\nXiangnan He, Hanwang Zhang, and Tat-Seng Chua. 2021. Clicks can be cheating: Counterfactual recommendation for mitigating clickbait issue. Wenjie Wang, Fuli Feng, ACM SIGIR. Wenjie Wang, Fuli Feng, Xiangnan He, Hanwang Zhang, and Tat-Seng Chua. 2021. Clicks can be cheating: Counterfactual recommendation for mitigating clickbait issue. In ACM SIGIR. 1288-1297.\n\nGlobaland-local aware data generation for the class imbalance problem. Wentao Wang, Suhang Wang, Wenqi Fan, Zitao Liu, Jiliang Tang, Proceedings of the 2020 SIAM International Conference on Data Mining (SDM). SIAM. the 2020 SIAM International Conference on Data Mining (SDM). SIAMWentao Wang, Suhang Wang, Wenqi Fan, Zitao Liu, and Jiliang Tang. 2020. Global- and-local aware data generation for the class imbalance problem. In Proceedings of the 2020 SIAM International Conference on Data Mining (SDM). SIAM, 307-315.\n\nKgat: Knowledge graph attention network for recommendation. Xiang Wang, Xiangnan He, Yixin Cao, Meng Liu, Tat-Seng Chua, ACM KDD. Xiang Wang, Xiangnan He, Yixin Cao, Meng Liu, and Tat-Seng Chua. 2019. Kgat: Knowledge graph attention network for recommendation. In ACM KDD. 950-958.\n\nXiang Wang, Xiangnan He, Meng Wang, Fuli Feng, and Tat-Seng Chua. 2019. Neural Graph Collaborative Filtering. ACM SIGIR. Xiang Wang, Xiangnan He, Meng Wang, Fuli Feng, and Tat-Seng Chua. 2019. Neural Graph Collaborative Filtering. ACM SIGIR (2019).\n\nDisentangled Graph Collaborative Filtering. Xiang Wang, A Hongye Jin, Xiangnan Zhang, Tong He, Tat-Seng Xu, Chua, ACM SIGIRXiang Wang, Hongye Jin, A. Zhang, Xiangnan He, Tong Xu, and Tat-Seng Chua. 2020. Disentangled Graph Collaborative Filtering. ACM SIGIR (2020).\n\nTrend Filtering on Graphs. Yu-Xiang Wang, James Sharpnack, Alexander J Smola, Ryan J Tibshirani, Journal of Machine Learning Research. 17Yu-Xiang Wang, James Sharpnack, Alexander J Smola, and Ryan J Tibshirani. 2016. Trend Filtering on Graphs. Journal of Machine Learning Research 17 (2016), 1-41.\n\nSelf-supervised graph learning for recommendation. Jiancan Wu, Xiang Wang, Fuli Feng, Xiangnan He, Liang Chen, Jianxun Lian, Xing Xie, ACM SIGIR. Jiancan Wu, Xiang Wang, Fuli Feng, Xiangnan He, Liang Chen, Jianxun Lian, and Xing Xie. 2021. Self-supervised graph learning for recommendation. In ACM SIGIR. 726-735.\n\nCollaborative denoising auto-encoders for top-n recommender systems. Yao Wu, Christopher Dubois, Alice X Zheng, Martin Ester, WSDM. Yao Wu, Christopher DuBois, Alice X Zheng, and Martin Ester. 2016. Collaborative denoising auto-encoders for top-n recommender systems. In WSDM. 153-162.\n\nZonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, S Yu Philip, A comprehensive survey on graph neural networks. IEEE transactions on neural networks and learning systems. 32Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and S Yu Philip. 2020. A comprehensive survey on graph neural networks. IEEE transactions on neural networks and learning systems 32, 1 (2020), 4-24.\n\nDeep Matrix Factorization Models for Recommender Systems. Xinyu Hong-Jian Xue, Jianbing Dai, Shujian Zhang, Jiajun Huang, Chen, IJCAI. Melbourne, Australia17Hong-Jian Xue, Xinyu Dai, Jianbing Zhang, Shujian Huang, and Jiajun Chen. 2017. Deep Matrix Factorization Models for Recommender Systems.. In IJCAI, Vol. 17. Melbourne, Australia, 3203-3209.\n\nGraph convolutional neural networks for web-scale recommender systems. Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, L William, Jure Hamilton, Leskovec, Rex Ying, Ruining He, Kaifeng Chen, Pong Eksombatchai, William L Hamilton, and Jure Leskovec. 2018. Graph convolutional neural networks for web-scale recommender systems. In KDD. 974-983.\n\nMulti-type Urban Crime Prediction. Xiangyu Zhao, Wenqi Fan, Hui Liu, Jiliang Tang, Thirty-Second AAAI Conference on Artificial Intelligence. Xiangyu Zhao, Wenqi Fan, Hui Liu, and Jiliang Tang. 2022. Multi-type Urban Crime Prediction. Thirty-Second AAAI Conference on Artificial Intelligence (2022).\n\nAutoloss: Automated loss function search in recommendations. Xiangyu Zhao, Haochen Liu, Wenqi Fan, Hui Liu, Jiliang Tang, Chong Wang, ACM KDD. Xiangyu Zhao, Haochen Liu, Wenqi Fan, Hui Liu, Jiliang Tang, and Chong Wang. 2021. Autoloss: Automated loss function search in recommendations. In ACM KDD. 3959-3967.\n\nAutoemb: Automated embedding dimensionality search in streaming recommendations. Xiangyu Zhao, Haochen Liu, Wenqi Fan, Hui Liu, Jiliang Tang, Chong Wang, Ming Chen, Xudong Zheng, Xiaobing Liu, and Xiwang Yang. 2021. ICDM. IEEEXiangyu Zhao, Haochen Liu, Wenqi Fan, Hui Liu, Jiliang Tang, Chong Wang, Ming Chen, Xudong Zheng, Xiaobing Liu, and Xiwang Yang. 2021. Autoemb: Automated embedding dimensionality search in streaming recommendations. In ICDM. IEEE, 896-905.\n\nRecommendations with Negative Feedback via Pairwise Deep Reinforcement Learning. Xiangyu Zhao, Liang Zhang, Zhuoye Ding, Long Xia, Jiliang Tang, Dawei Yin, KDD. ACMXiangyu Zhao, Liang Zhang, Zhuoye Ding, Long Xia, Jiliang Tang, and Dawei Yin. 2018. Recommendations with Negative Feedback via Pairwise Deep Reinforcement Learning. In KDD. ACM, 1040-1048.\n", "annotations": {"author": "[{\"end\":140,\"start\":109},{\"end\":169,\"start\":141},{\"end\":194,\"start\":170},{\"end\":230,\"start\":195},{\"end\":244,\"start\":231},{\"end\":253,\"start\":245},{\"end\":264,\"start\":254},{\"end\":277,\"start\":265},{\"end\":286,\"start\":278},{\"end\":300,\"start\":287},{\"end\":314,\"start\":301},{\"end\":323,\"start\":315},{\"end\":443,\"start\":324},{\"end\":509,\"start\":444}]", "publisher": "[{\"end\":54,\"start\":51},{\"end\":824,\"start\":821}]", "author_last_name": "[{\"end\":118,\"start\":115},{\"end\":152,\"start\":149},{\"end\":177,\"start\":174},{\"end\":207,\"start\":203},{\"end\":243,\"start\":239},{\"end\":252,\"start\":250},{\"end\":263,\"start\":260},{\"end\":276,\"start\":273},{\"end\":285,\"start\":282},{\"end\":299,\"start\":295},{\"end\":313,\"start\":309}]", "author_first_name": "[{\"end\":114,\"start\":109},{\"end\":148,\"start\":141},{\"end\":173,\"start\":170},{\"end\":202,\"start\":195},{\"end\":238,\"start\":231},{\"end\":249,\"start\":245},{\"end\":259,\"start\":254},{\"end\":272,\"start\":265},{\"end\":281,\"start\":278},{\"end\":294,\"start\":287},{\"end\":308,\"start\":301},{\"end\":319,\"start\":315},{\"end\":322,\"start\":320}]", "author_affiliation": "[{\"end\":442,\"start\":325},{\"end\":508,\"start\":445}]", "title": "[{\"end\":50,\"start\":1},{\"end\":559,\"start\":510}]", "venue": "[{\"end\":684,\"start\":561}]", "abstract": "[{\"end\":2746,\"start\":1232}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3063,\"start\":3060},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3065,\"start\":3063},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":3068,\"start\":3065},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":3071,\"start\":3068},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":3074,\"start\":3071},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":3209,\"start\":3206},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":3212,\"start\":3209},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":3215,\"start\":3212},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":3218,\"start\":3215},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3489,\"start\":3486},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":3492,\"start\":3489},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":3599,\"start\":3595},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":3788,\"start\":3784},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":3791,\"start\":3788},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":3995,\"start\":3991},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":4331,\"start\":4327},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":4349,\"start\":4345},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":5128,\"start\":5125},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":5131,\"start\":5128},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":5134,\"start\":5131},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":5137,\"start\":5134},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":5140,\"start\":5137},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":5143,\"start\":5140},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":5146,\"start\":5143},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":6167,\"start\":6163},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":6170,\"start\":6167},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":6173,\"start\":6170},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":6176,\"start\":6173},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":7333,\"start\":7329},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":7336,\"start\":7333},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":7367,\"start\":7363},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":7370,\"start\":7367},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":10456,\"start\":10452},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":10521,\"start\":10517},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":12449,\"start\":12445},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":13276,\"start\":13272},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":13279,\"start\":13276},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":13310,\"start\":13306},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":14883,\"start\":14879},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":16592,\"start\":16588},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":17509,\"start\":17506},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":17888,\"start\":17884},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":18002,\"start\":17998},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":18040,\"start\":18036},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":18049,\"start\":18045},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":18122,\"start\":18119},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":20830,\"start\":20826},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":21753,\"start\":21749},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":21771,\"start\":21767},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":21816,\"start\":21812},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":22228,\"start\":22224},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":22407,\"start\":22403},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":23001,\"start\":22997},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":23004,\"start\":23001},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":24873,\"start\":24872},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":30830,\"start\":30826},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":30833,\"start\":30830},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":30935,\"start\":30931},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":31111,\"start\":31107},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":31368,\"start\":31364},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":31371,\"start\":31368},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":31471,\"start\":31467},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":31474,\"start\":31471},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":31477,\"start\":31474},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":31480,\"start\":31477},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":31643,\"start\":31639},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":31795,\"start\":31791},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":32308,\"start\":32304},{\"end\":32460,\"start\":32441},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":32802,\"start\":32798},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":33017,\"start\":33013},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":33054,\"start\":33050},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":33156,\"start\":33152},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":33159,\"start\":33156},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":33309,\"start\":33305},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":33478,\"start\":33474},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":33707,\"start\":33703},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":33933,\"start\":33930},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":33936,\"start\":33933},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":33939,\"start\":33936},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":33942,\"start\":33939},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":33962,\"start\":33958},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":34203,\"start\":34200},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":34206,\"start\":34203},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":34283,\"start\":34280},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":34530,\"start\":34526},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":36684,\"start\":36680}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":36102,\"start\":36018},{\"attributes\":{\"id\":\"fig_1\"},\"end\":36159,\"start\":36103},{\"attributes\":{\"id\":\"fig_2\"},\"end\":36313,\"start\":36160},{\"attributes\":{\"id\":\"fig_4\"},\"end\":36400,\"start\":36314},{\"attributes\":{\"id\":\"fig_5\"},\"end\":36476,\"start\":36401},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":36622,\"start\":36477},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":37976,\"start\":36623},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":39556,\"start\":37977},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":39662,\"start\":39557},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":39906,\"start\":39663}]", "paragraph": "[{\"end\":3493,\"start\":2762},{\"end\":4795,\"start\":3495},{\"end\":4809,\"start\":4797},{\"end\":5842,\"start\":4907},{\"end\":6924,\"start\":5844},{\"end\":7562,\"start\":6926},{\"end\":7982,\"start\":7564},{\"end\":8132,\"start\":7984},{\"end\":8315,\"start\":8148},{\"end\":8689,\"start\":8345},{\"end\":8840,\"start\":8720},{\"end\":9240,\"start\":8842},{\"end\":9812,\"start\":9242},{\"end\":9966,\"start\":9860},{\"end\":10042,\"start\":10006},{\"end\":10098,\"start\":10061},{\"end\":10287,\"start\":10139},{\"end\":10593,\"start\":10300},{\"end\":10819,\"start\":10626},{\"end\":12001,\"start\":10881},{\"end\":12565,\"start\":12003},{\"end\":12854,\"start\":12589},{\"end\":13407,\"start\":12876},{\"end\":13416,\"start\":13409},{\"end\":13847,\"start\":13461},{\"end\":13927,\"start\":13900},{\"end\":14238,\"start\":14043},{\"end\":14290,\"start\":14274},{\"end\":14585,\"start\":14346},{\"end\":14990,\"start\":14587},{\"end\":15488,\"start\":15005},{\"end\":16106,\"start\":15528},{\"end\":16265,\"start\":16152},{\"end\":16373,\"start\":16327},{\"end\":16445,\"start\":16400},{\"end\":16635,\"start\":16495},{\"end\":17168,\"start\":16737},{\"end\":17301,\"start\":17170},{\"end\":17403,\"start\":17349},{\"end\":17510,\"start\":17463},{\"end\":17556,\"start\":17542},{\"end\":17800,\"start\":17642},{\"end\":17964,\"start\":17802},{\"end\":18196,\"start\":17966},{\"end\":18344,\"start\":18343},{\"end\":18982,\"start\":18346},{\"end\":19566,\"start\":19140},{\"end\":20107,\"start\":19671},{\"end\":21022,\"start\":20147},{\"end\":21436,\"start\":21069},{\"end\":22792,\"start\":21492},{\"end\":23200,\"start\":22816},{\"end\":23463,\"start\":23250},{\"end\":24917,\"start\":23465},{\"end\":25746,\"start\":24919},{\"end\":26723,\"start\":25794},{\"end\":27745,\"start\":26725},{\"end\":28313,\"start\":27767},{\"end\":28937,\"start\":28339},{\"end\":29254,\"start\":28969},{\"end\":30143,\"start\":29256},{\"end\":30386,\"start\":30153},{\"end\":30680,\"start\":30417},{\"end\":32000,\"start\":30725},{\"end\":33663,\"start\":32035},{\"end\":35016,\"start\":33683},{\"end\":36017,\"start\":35031}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":4859,\"start\":4810},{\"attributes\":{\"id\":\"formula_1\"},\"end\":4906,\"start\":4859},{\"attributes\":{\"id\":\"formula_2\"},\"end\":8719,\"start\":8690},{\"attributes\":{\"id\":\"formula_3\"},\"end\":9859,\"start\":9813},{\"attributes\":{\"id\":\"formula_4\"},\"end\":10005,\"start\":9967},{\"attributes\":{\"id\":\"formula_5\"},\"end\":10060,\"start\":10043},{\"attributes\":{\"id\":\"formula_6\"},\"end\":10299,\"start\":10288},{\"attributes\":{\"id\":\"formula_7\"},\"end\":10625,\"start\":10594},{\"attributes\":{\"id\":\"formula_8\"},\"end\":10880,\"start\":10820},{\"attributes\":{\"id\":\"formula_9\"},\"end\":13460,\"start\":13417},{\"attributes\":{\"id\":\"formula_10\"},\"end\":13899,\"start\":13848},{\"attributes\":{\"id\":\"formula_11\"},\"end\":14042,\"start\":13928},{\"attributes\":{\"id\":\"formula_12\"},\"end\":14273,\"start\":14239},{\"attributes\":{\"id\":\"formula_13\"},\"end\":14345,\"start\":14291},{\"attributes\":{\"id\":\"formula_14\"},\"end\":15004,\"start\":14991},{\"attributes\":{\"id\":\"formula_15\"},\"end\":16151,\"start\":16107},{\"attributes\":{\"id\":\"formula_16\"},\"end\":16326,\"start\":16266},{\"attributes\":{\"id\":\"formula_17\"},\"end\":16399,\"start\":16374},{\"attributes\":{\"id\":\"formula_18\"},\"end\":16494,\"start\":16446},{\"attributes\":{\"id\":\"formula_19\"},\"end\":16700,\"start\":16636},{\"attributes\":{\"id\":\"formula_20\"},\"end\":16736,\"start\":16700},{\"attributes\":{\"id\":\"formula_21\"},\"end\":17348,\"start\":17302},{\"attributes\":{\"id\":\"formula_22\"},\"end\":17462,\"start\":17404},{\"attributes\":{\"id\":\"formula_23\"},\"end\":17541,\"start\":17511},{\"attributes\":{\"id\":\"formula_24\"},\"end\":17641,\"start\":17557},{\"attributes\":{\"id\":\"formula_25\"},\"end\":18321,\"start\":18197},{\"attributes\":{\"id\":\"formula_26\"},\"end\":18342,\"start\":18321},{\"attributes\":{\"id\":\"formula_27\"},\"end\":19106,\"start\":18983},{\"attributes\":{\"id\":\"formula_28\"},\"end\":19670,\"start\":19567},{\"attributes\":{\"id\":\"formula_29\"},\"end\":20146,\"start\":20108},{\"attributes\":{\"id\":\"formula_30\"},\"end\":21068,\"start\":21023},{\"attributes\":{\"id\":\"formula_31\"},\"end\":21491,\"start\":21476}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":22186,\"start\":22179},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":23321,\"start\":23314},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":28110,\"start\":28103},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":29201,\"start\":29194}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2760,\"start\":2748},{\"attributes\":{\"n\":\"2\"},\"end\":8146,\"start\":8135},{\"attributes\":{\"n\":\"2.1\"},\"end\":8343,\"start\":8318},{\"attributes\":{\"n\":\"2.2\"},\"end\":10137,\"start\":10101},{\"attributes\":{\"n\":\"3\"},\"end\":12587,\"start\":12568},{\"attributes\":{\"n\":\"3.1\"},\"end\":12874,\"start\":12857},{\"attributes\":{\"n\":\"3.2\"},\"end\":15526,\"start\":15491},{\"attributes\":{\"n\":\"3.3\"},\"end\":19138,\"start\":19108},{\"attributes\":{\"n\":\"4\"},\"end\":21475,\"start\":21439},{\"attributes\":{\"n\":\"4.1.3\"},\"end\":22814,\"start\":22795},{\"attributes\":{\"n\":\"4.2\"},\"end\":23248,\"start\":23203},{\"attributes\":{\"n\":\"4.3\"},\"end\":25792,\"start\":25749},{\"attributes\":{\"n\":\"4.3.2\"},\"end\":27765,\"start\":27748},{\"attributes\":{\"n\":\"4.4\"},\"end\":28337,\"start\":28316},{\"attributes\":{\"n\":\"4.4.2\"},\"end\":28967,\"start\":28940},{\"end\":30151,\"start\":30146},{\"attributes\":{\"n\":\"4.4.4\"},\"end\":30415,\"start\":30389},{\"attributes\":{\"n\":\"5\"},\"end\":30723,\"start\":30683},{\"attributes\":{\"n\":\"5.2\"},\"end\":32033,\"start\":32003},{\"attributes\":{\"n\":\"5.3\"},\"end\":33681,\"start\":33666},{\"attributes\":{\"n\":\"6\"},\"end\":35029,\"start\":35019},{\"end\":36029,\"start\":36019},{\"end\":36114,\"start\":36104},{\"end\":36181,\"start\":36161},{\"end\":36325,\"start\":36315},{\"end\":36412,\"start\":36402},{\"end\":36633,\"start\":36624},{\"end\":37987,\"start\":37978},{\"end\":39567,\"start\":39558},{\"end\":39673,\"start\":39664}]", "table": "[{\"end\":36622,\"start\":36544},{\"end\":37976,\"start\":37545},{\"end\":39556,\"start\":38027},{\"end\":39662,\"start\":39604},{\"end\":39906,\"start\":39729}]", "figure_caption": "[{\"end\":36102,\"start\":36031},{\"end\":36159,\"start\":36116},{\"end\":36313,\"start\":36184},{\"end\":36400,\"start\":36327},{\"end\":36476,\"start\":36414},{\"end\":36544,\"start\":36479},{\"end\":37545,\"start\":36635},{\"end\":38027,\"start\":37989},{\"end\":39604,\"start\":39569},{\"end\":39729,\"start\":39675}]", "figure_ref": "[{\"end\":4484,\"start\":4476},{\"end\":6198,\"start\":6190},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":12391,\"start\":12383},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":18461,\"start\":18453},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":18544,\"start\":18536},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":19999,\"start\":19991},{\"end\":26763,\"start\":26755},{\"end\":28489,\"start\":28481},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":30185,\"start\":30177},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":30508,\"start\":30500}]", "bib_author_first_name": "[{\"end\":40293,\"start\":40292},{\"end\":40308,\"start\":40301},{\"end\":40310,\"start\":40309},{\"end\":40618,\"start\":40612},{\"end\":40634,\"start\":40628},{\"end\":40636,\"start\":40635},{\"end\":40646,\"start\":40643},{\"end\":40872,\"start\":40870},{\"end\":40886,\"start\":40879},{\"end\":40899,\"start\":40893},{\"end\":41353,\"start\":41345},{\"end\":41367,\"start\":41360},{\"end\":41383,\"start\":41375},{\"end\":41395,\"start\":41388},{\"end\":41404,\"start\":41401},{\"end\":41418,\"start\":41410},{\"end\":41728,\"start\":41721},{\"end\":41743,\"start\":41735},{\"end\":41755,\"start\":41749},{\"end\":41769,\"start\":41761},{\"end\":41781,\"start\":41776},{\"end\":42015,\"start\":42009},{\"end\":42030,\"start\":42022},{\"end\":42045,\"start\":42044},{\"end\":42047,\"start\":42046},{\"end\":42060,\"start\":42054},{\"end\":42313,\"start\":42307},{\"end\":42325,\"start\":42320},{\"end\":42338,\"start\":42333},{\"end\":42352,\"start\":42346},{\"end\":42688,\"start\":42687},{\"end\":42690,\"start\":42689},{\"end\":42699,\"start\":42696},{\"end\":42705,\"start\":42700},{\"end\":42966,\"start\":42961},{\"end\":42976,\"start\":42973},{\"end\":42986,\"start\":42981},{\"end\":42999,\"start\":42992},{\"end\":43194,\"start\":43189},{\"end\":43204,\"start\":43201},{\"end\":43216,\"start\":43209},{\"end\":43448,\"start\":43443},{\"end\":43459,\"start\":43454},{\"end\":43469,\"start\":43466},{\"end\":43482,\"start\":43474},{\"end\":43496,\"start\":43489},{\"end\":43507,\"start\":43503},{\"end\":43784,\"start\":43779},{\"end\":43795,\"start\":43790},{\"end\":43809,\"start\":43802},{\"end\":43819,\"start\":43816},{\"end\":43827,\"start\":43824},{\"end\":43841,\"start\":43833},{\"end\":43855,\"start\":43848},{\"end\":43866,\"start\":43862},{\"end\":44091,\"start\":44086},{\"end\":44100,\"start\":44097},{\"end\":44113,\"start\":44106},{\"end\":44122,\"start\":44119},{\"end\":44135,\"start\":44127},{\"end\":44148,\"start\":44142},{\"end\":44159,\"start\":44155},{\"end\":44171,\"start\":44164},{\"end\":44186,\"start\":44178},{\"end\":44194,\"start\":44193},{\"end\":44587,\"start\":44582},{\"end\":44597,\"start\":44593},{\"end\":44605,\"start\":44602},{\"end\":44882,\"start\":44877},{\"end\":44891,\"start\":44888},{\"end\":44900,\"start\":44896},{\"end\":44909,\"start\":44905},{\"end\":44918,\"start\":44914},{\"end\":44932,\"start\":44925},{\"end\":44944,\"start\":44939},{\"end\":45201,\"start\":45196},{\"end\":45210,\"start\":45207},{\"end\":45219,\"start\":45215},{\"end\":45232,\"start\":45224},{\"end\":45246,\"start\":45239},{\"end\":45488,\"start\":45483},{\"end\":45497,\"start\":45494},{\"end\":45505,\"start\":45502},{\"end\":45517,\"start\":45510},{\"end\":45531,\"start\":45523},{\"end\":45542,\"start\":45538},{\"end\":45554,\"start\":45547},{\"end\":45945,\"start\":45940},{\"end\":45954,\"start\":45951},{\"end\":45964,\"start\":45959},{\"end\":45978,\"start\":45970},{\"end\":45992,\"start\":45985},{\"end\":46003,\"start\":45999},{\"end\":46246,\"start\":46243},{\"end\":46271,\"start\":46267},{\"end\":46516,\"start\":46508},{\"end\":46522,\"start\":46521},{\"end\":46535,\"start\":46534},{\"end\":46550,\"start\":46542},{\"end\":46559,\"start\":46555},{\"end\":46769,\"start\":46761},{\"end\":46778,\"start\":46774},{\"end\":46792,\"start\":46785},{\"end\":46807,\"start\":46800},{\"end\":46816,\"start\":46813},{\"end\":46829,\"start\":46821},{\"end\":47061,\"start\":47058},{\"end\":47072,\"start\":47067},{\"end\":47083,\"start\":47079},{\"end\":47093,\"start\":47090},{\"end\":47103,\"start\":47098},{\"end\":47116,\"start\":47109},{\"end\":47553,\"start\":47550},{\"end\":47566,\"start\":47559},{\"end\":47579,\"start\":47572},{\"end\":47589,\"start\":47586},{\"end\":47598,\"start\":47594},{\"end\":47612,\"start\":47605},{\"end\":47819,\"start\":47816},{\"end\":47828,\"start\":47825},{\"end\":47840,\"start\":47833},{\"end\":48159,\"start\":48149},{\"end\":48173,\"start\":48165},{\"end\":48186,\"start\":48179},{\"end\":48200,\"start\":48193},{\"end\":48404,\"start\":48403},{\"end\":48420,\"start\":48415},{\"end\":48599,\"start\":48598},{\"end\":48611,\"start\":48608},{\"end\":48860,\"start\":48855},{\"end\":48869,\"start\":48868},{\"end\":48881,\"start\":48880},{\"end\":48892,\"start\":48891},{\"end\":49095,\"start\":49088},{\"end\":49107,\"start\":49101},{\"end\":49120,\"start\":49115},{\"end\":49129,\"start\":49126},{\"end\":49140,\"start\":49135},{\"end\":49153,\"start\":49146},{\"end\":49542,\"start\":49535},{\"end\":49552,\"start\":49548},{\"end\":49564,\"start\":49559},{\"end\":49577,\"start\":49570},{\"end\":49588,\"start\":49583},{\"end\":49599,\"start\":49593},{\"end\":49607,\"start\":49606},{\"end\":49621,\"start\":49614},{\"end\":49956,\"start\":49949},{\"end\":49969,\"start\":49962},{\"end\":49979,\"start\":49976},{\"end\":49988,\"start\":49985},{\"end\":49996,\"start\":49993},{\"end\":50006,\"start\":50001},{\"end\":50019,\"start\":50012},{\"end\":50219,\"start\":50212},{\"end\":50228,\"start\":50225},{\"end\":50237,\"start\":50234},{\"end\":50247,\"start\":50242},{\"end\":50255,\"start\":50252},{\"end\":50265,\"start\":50261},{\"end\":50276,\"start\":50272},{\"end\":50289,\"start\":50282},{\"end\":50570,\"start\":50564},{\"end\":50586,\"start\":50578},{\"end\":50882,\"start\":50879},{\"end\":50894,\"start\":50887},{\"end\":50904,\"start\":50900},{\"end\":50916,\"start\":50911},{\"end\":50929,\"start\":50922},{\"end\":50940,\"start\":50936},{\"end\":51685,\"start\":51682},{\"end\":51697,\"start\":51690},{\"end\":51824,\"start\":51815},{\"end\":51838,\"start\":51834},{\"end\":52107,\"start\":52106},{\"end\":52128,\"start\":52124},{\"end\":52145,\"start\":52144},{\"end\":52361,\"start\":52354},{\"end\":52371,\"start\":52368},{\"end\":52380,\"start\":52376},{\"end\":52621,\"start\":52620},{\"end\":52808,\"start\":52802},{\"end\":52828,\"start\":52819},{\"end\":53108,\"start\":53105},{\"end\":53121,\"start\":53115},{\"end\":53135,\"start\":53128},{\"end\":53284,\"start\":53277},{\"end\":53296,\"start\":53291},{\"end\":53304,\"start\":53301},{\"end\":53319,\"start\":53311},{\"end\":53326,\"start\":53325},{\"end\":53339,\"start\":53333},{\"end\":53792,\"start\":53786},{\"end\":53803,\"start\":53799},{\"end\":54087,\"start\":54081},{\"end\":54100,\"start\":54094},{\"end\":54112,\"start\":54107},{\"end\":54123,\"start\":54118},{\"end\":54136,\"start\":54129},{\"end\":54595,\"start\":54590},{\"end\":54610,\"start\":54602},{\"end\":54620,\"start\":54615},{\"end\":54630,\"start\":54626},{\"end\":54644,\"start\":54636},{\"end\":54818,\"start\":54813},{\"end\":54833,\"start\":54825},{\"end\":54842,\"start\":54838},{\"end\":55112,\"start\":55107},{\"end\":55120,\"start\":55119},{\"end\":55141,\"start\":55133},{\"end\":55153,\"start\":55149},{\"end\":55166,\"start\":55158},{\"end\":55365,\"start\":55357},{\"end\":55377,\"start\":55372},{\"end\":55398,\"start\":55389},{\"end\":55400,\"start\":55399},{\"end\":55412,\"start\":55408},{\"end\":55414,\"start\":55413},{\"end\":55687,\"start\":55680},{\"end\":55697,\"start\":55692},{\"end\":55708,\"start\":55704},{\"end\":55723,\"start\":55715},{\"end\":55733,\"start\":55728},{\"end\":55747,\"start\":55740},{\"end\":55758,\"start\":55754},{\"end\":56016,\"start\":56013},{\"end\":56032,\"start\":56021},{\"end\":56046,\"start\":56041},{\"end\":56048,\"start\":56047},{\"end\":56062,\"start\":56056},{\"end\":56238,\"start\":56231},{\"end\":56249,\"start\":56243},{\"end\":56262,\"start\":56255},{\"end\":56276,\"start\":56269},{\"end\":56290,\"start\":56283},{\"end\":56302,\"start\":56298},{\"end\":56702,\"start\":56697},{\"end\":56726,\"start\":56718},{\"end\":56739,\"start\":56732},{\"end\":56753,\"start\":56747},{\"end\":57062,\"start\":57059},{\"end\":57076,\"start\":57069},{\"end\":57088,\"start\":57081},{\"end\":57099,\"start\":57095},{\"end\":57115,\"start\":57114},{\"end\":57129,\"start\":57125},{\"end\":57381,\"start\":57374},{\"end\":57393,\"start\":57388},{\"end\":57402,\"start\":57399},{\"end\":57415,\"start\":57408},{\"end\":57707,\"start\":57700},{\"end\":57721,\"start\":57714},{\"end\":57732,\"start\":57727},{\"end\":57741,\"start\":57738},{\"end\":57754,\"start\":57747},{\"end\":57766,\"start\":57761},{\"end\":58038,\"start\":58031},{\"end\":58052,\"start\":58045},{\"end\":58063,\"start\":58058},{\"end\":58072,\"start\":58069},{\"end\":58085,\"start\":58078},{\"end\":58097,\"start\":58092},{\"end\":58108,\"start\":58104},{\"end\":58505,\"start\":58498},{\"end\":58517,\"start\":58512},{\"end\":58531,\"start\":58525},{\"end\":58542,\"start\":58538},{\"end\":58555,\"start\":58548},{\"end\":58567,\"start\":58562}]", "bib_author_last_name": "[{\"end\":40299,\"start\":40294},{\"end\":40319,\"start\":40311},{\"end\":40330,\"start\":40321},{\"end\":40626,\"start\":40619},{\"end\":40641,\"start\":40637},{\"end\":40651,\"start\":40647},{\"end\":40660,\"start\":40653},{\"end\":40877,\"start\":40873},{\"end\":40891,\"start\":40887},{\"end\":40904,\"start\":40900},{\"end\":41358,\"start\":41354},{\"end\":41373,\"start\":41368},{\"end\":41386,\"start\":41384},{\"end\":41399,\"start\":41396},{\"end\":41408,\"start\":41405},{\"end\":41423,\"start\":41419},{\"end\":41733,\"start\":41729},{\"end\":41747,\"start\":41744},{\"end\":41759,\"start\":41756},{\"end\":41774,\"start\":41770},{\"end\":41787,\"start\":41782},{\"end\":42020,\"start\":42016},{\"end\":42042,\"start\":42031},{\"end\":42052,\"start\":42048},{\"end\":42066,\"start\":42061},{\"end\":42077,\"start\":42068},{\"end\":42318,\"start\":42314},{\"end\":42331,\"start\":42326},{\"end\":42344,\"start\":42339},{\"end\":42362,\"start\":42353},{\"end\":42694,\"start\":42691},{\"end\":42711,\"start\":42706},{\"end\":42719,\"start\":42713},{\"end\":42971,\"start\":42967},{\"end\":42979,\"start\":42977},{\"end\":42990,\"start\":42987},{\"end\":43003,\"start\":43000},{\"end\":43199,\"start\":43195},{\"end\":43207,\"start\":43205},{\"end\":43221,\"start\":43217},{\"end\":43452,\"start\":43449},{\"end\":43464,\"start\":43460},{\"end\":43472,\"start\":43470},{\"end\":43487,\"start\":43483},{\"end\":43501,\"start\":43497},{\"end\":43510,\"start\":43508},{\"end\":43788,\"start\":43785},{\"end\":43800,\"start\":43796},{\"end\":43814,\"start\":43810},{\"end\":43822,\"start\":43820},{\"end\":43831,\"start\":43828},{\"end\":43846,\"start\":43842},{\"end\":43860,\"start\":43856},{\"end\":43869,\"start\":43867},{\"end\":44095,\"start\":44092},{\"end\":44104,\"start\":44101},{\"end\":44117,\"start\":44114},{\"end\":44125,\"start\":44123},{\"end\":44140,\"start\":44136},{\"end\":44153,\"start\":44149},{\"end\":44162,\"start\":44160},{\"end\":44176,\"start\":44172},{\"end\":44191,\"start\":44187},{\"end\":44203,\"start\":44195},{\"end\":44591,\"start\":44588},{\"end\":44600,\"start\":44598},{\"end\":44611,\"start\":44606},{\"end\":44886,\"start\":44883},{\"end\":44894,\"start\":44892},{\"end\":44903,\"start\":44901},{\"end\":44912,\"start\":44910},{\"end\":44923,\"start\":44919},{\"end\":44937,\"start\":44933},{\"end\":44948,\"start\":44945},{\"end\":45205,\"start\":45202},{\"end\":45213,\"start\":45211},{\"end\":45222,\"start\":45220},{\"end\":45237,\"start\":45233},{\"end\":45250,\"start\":45247},{\"end\":45492,\"start\":45489},{\"end\":45500,\"start\":45498},{\"end\":45508,\"start\":45506},{\"end\":45521,\"start\":45518},{\"end\":45536,\"start\":45532},{\"end\":45545,\"start\":45543},{\"end\":45559,\"start\":45555},{\"end\":45949,\"start\":45946},{\"end\":45957,\"start\":45955},{\"end\":45968,\"start\":45965},{\"end\":45983,\"start\":45979},{\"end\":45997,\"start\":45993},{\"end\":46006,\"start\":46004},{\"end\":46265,\"start\":46247},{\"end\":46276,\"start\":46272},{\"end\":46286,\"start\":46278},{\"end\":46519,\"start\":46517},{\"end\":46532,\"start\":46523},{\"end\":46540,\"start\":46536},{\"end\":46553,\"start\":46551},{\"end\":46565,\"start\":46560},{\"end\":46571,\"start\":46567},{\"end\":46772,\"start\":46770},{\"end\":46783,\"start\":46779},{\"end\":46798,\"start\":46793},{\"end\":46811,\"start\":46808},{\"end\":46819,\"start\":46817},{\"end\":46834,\"start\":46830},{\"end\":47065,\"start\":47062},{\"end\":47077,\"start\":47073},{\"end\":47088,\"start\":47084},{\"end\":47096,\"start\":47094},{\"end\":47107,\"start\":47104},{\"end\":47121,\"start\":47117},{\"end\":47557,\"start\":47554},{\"end\":47570,\"start\":47567},{\"end\":47584,\"start\":47580},{\"end\":47592,\"start\":47590},{\"end\":47603,\"start\":47599},{\"end\":47617,\"start\":47613},{\"end\":47823,\"start\":47820},{\"end\":47831,\"start\":47829},{\"end\":47844,\"start\":47841},{\"end\":48163,\"start\":48160},{\"end\":48177,\"start\":48174},{\"end\":48191,\"start\":48187},{\"end\":48211,\"start\":48201},{\"end\":48413,\"start\":48405},{\"end\":48427,\"start\":48421},{\"end\":48431,\"start\":48429},{\"end\":48606,\"start\":48600},{\"end\":48616,\"start\":48612},{\"end\":48625,\"start\":48618},{\"end\":48866,\"start\":48861},{\"end\":48878,\"start\":48870},{\"end\":48889,\"start\":48882},{\"end\":48899,\"start\":48893},{\"end\":49099,\"start\":49096},{\"end\":49113,\"start\":49108},{\"end\":49124,\"start\":49121},{\"end\":49133,\"start\":49130},{\"end\":49144,\"start\":49141},{\"end\":49158,\"start\":49154},{\"end\":49546,\"start\":49543},{\"end\":49557,\"start\":49553},{\"end\":49568,\"start\":49565},{\"end\":49581,\"start\":49578},{\"end\":49591,\"start\":49589},{\"end\":49604,\"start\":49600},{\"end\":49612,\"start\":49608},{\"end\":49626,\"start\":49622},{\"end\":49632,\"start\":49628},{\"end\":49960,\"start\":49957},{\"end\":49974,\"start\":49970},{\"end\":49983,\"start\":49980},{\"end\":49991,\"start\":49989},{\"end\":49999,\"start\":49997},{\"end\":50010,\"start\":50007},{\"end\":50024,\"start\":50020},{\"end\":50223,\"start\":50220},{\"end\":50232,\"start\":50229},{\"end\":50240,\"start\":50238},{\"end\":50250,\"start\":50248},{\"end\":50259,\"start\":50256},{\"end\":50270,\"start\":50266},{\"end\":50280,\"start\":50277},{\"end\":50294,\"start\":50290},{\"end\":50576,\"start\":50571},{\"end\":50596,\"start\":50587},{\"end\":50885,\"start\":50883},{\"end\":50898,\"start\":50895},{\"end\":50909,\"start\":50905},{\"end\":50920,\"start\":50917},{\"end\":50934,\"start\":50930},{\"end\":50945,\"start\":50941},{\"end\":51688,\"start\":51686},{\"end\":51702,\"start\":51698},{\"end\":51832,\"start\":51825},{\"end\":51850,\"start\":51839},{\"end\":52122,\"start\":52108},{\"end\":52142,\"start\":52129},{\"end\":52153,\"start\":52146},{\"end\":52169,\"start\":52155},{\"end\":52366,\"start\":52362},{\"end\":52374,\"start\":52372},{\"end\":52384,\"start\":52381},{\"end\":52626,\"start\":52622},{\"end\":52638,\"start\":52628},{\"end\":52817,\"start\":52809},{\"end\":52837,\"start\":52829},{\"end\":53113,\"start\":53109},{\"end\":53126,\"start\":53122},{\"end\":53141,\"start\":53136},{\"end\":53289,\"start\":53285},{\"end\":53299,\"start\":53297},{\"end\":53309,\"start\":53305},{\"end\":53323,\"start\":53320},{\"end\":53331,\"start\":53327},{\"end\":53345,\"start\":53340},{\"end\":53352,\"start\":53347},{\"end\":53797,\"start\":53793},{\"end\":53808,\"start\":53804},{\"end\":54092,\"start\":54088},{\"end\":54105,\"start\":54101},{\"end\":54116,\"start\":54113},{\"end\":54127,\"start\":54124},{\"end\":54141,\"start\":54137},{\"end\":54600,\"start\":54596},{\"end\":54613,\"start\":54611},{\"end\":54624,\"start\":54621},{\"end\":54634,\"start\":54631},{\"end\":54649,\"start\":54645},{\"end\":54823,\"start\":54819},{\"end\":54836,\"start\":54834},{\"end\":54847,\"start\":54843},{\"end\":55117,\"start\":55113},{\"end\":55131,\"start\":55121},{\"end\":55147,\"start\":55142},{\"end\":55156,\"start\":55154},{\"end\":55169,\"start\":55167},{\"end\":55175,\"start\":55171},{\"end\":55370,\"start\":55366},{\"end\":55387,\"start\":55378},{\"end\":55406,\"start\":55401},{\"end\":55425,\"start\":55415},{\"end\":55690,\"start\":55688},{\"end\":55702,\"start\":55698},{\"end\":55713,\"start\":55709},{\"end\":55726,\"start\":55724},{\"end\":55738,\"start\":55734},{\"end\":55752,\"start\":55748},{\"end\":55762,\"start\":55759},{\"end\":56019,\"start\":56017},{\"end\":56039,\"start\":56033},{\"end\":56054,\"start\":56049},{\"end\":56068,\"start\":56063},{\"end\":56241,\"start\":56239},{\"end\":56253,\"start\":56250},{\"end\":56267,\"start\":56263},{\"end\":56281,\"start\":56277},{\"end\":56296,\"start\":56291},{\"end\":56309,\"start\":56303},{\"end\":56716,\"start\":56703},{\"end\":56730,\"start\":56727},{\"end\":56745,\"start\":56740},{\"end\":56759,\"start\":56754},{\"end\":56765,\"start\":56761},{\"end\":57067,\"start\":57063},{\"end\":57079,\"start\":57077},{\"end\":57093,\"start\":57089},{\"end\":57112,\"start\":57100},{\"end\":57123,\"start\":57116},{\"end\":57138,\"start\":57130},{\"end\":57148,\"start\":57140},{\"end\":57386,\"start\":57382},{\"end\":57397,\"start\":57394},{\"end\":57406,\"start\":57403},{\"end\":57420,\"start\":57416},{\"end\":57712,\"start\":57708},{\"end\":57725,\"start\":57722},{\"end\":57736,\"start\":57733},{\"end\":57745,\"start\":57742},{\"end\":57759,\"start\":57755},{\"end\":57771,\"start\":57767},{\"end\":58043,\"start\":58039},{\"end\":58056,\"start\":58053},{\"end\":58067,\"start\":58064},{\"end\":58076,\"start\":58073},{\"end\":58090,\"start\":58086},{\"end\":58102,\"start\":58098},{\"end\":58113,\"start\":58109},{\"end\":58510,\"start\":58506},{\"end\":58523,\"start\":58518},{\"end\":58536,\"start\":58532},{\"end\":58546,\"start\":58543},{\"end\":58560,\"start\":58556},{\"end\":58571,\"start\":58568}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":40610,\"start\":40292},{\"attributes\":{\"doi\":\"arXiv:1706.02263\",\"id\":\"b1\"},\"end\":40868,\"start\":40612},{\"attributes\":{\"doi\":\"arXiv:2204.01390\",\"id\":\"b2\"},\"end\":41241,\"start\":40870},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":20970043},\"end\":41643,\"start\":41243},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":250340201},\"end\":41959,\"start\":41645},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":1418033},\"end\":42250,\"start\":41961},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":7056947},\"end\":42685,\"start\":42252},{\"attributes\":{\"id\":\"b7\"},\"end\":42881,\"start\":42687},{\"attributes\":{\"id\":\"b8\"},\"end\":43150,\"start\":42883},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":57362238},\"end\":43441,\"start\":43152},{\"attributes\":{\"id\":\"b10\"},\"end\":43701,\"start\":43443},{\"attributes\":{\"id\":\"b11\"},\"end\":44084,\"start\":43703},{\"attributes\":{\"doi\":\"arXiv:2108.03388\",\"id\":\"b12\"},\"end\":44526,\"start\":44086},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":19221752},\"end\":44826,\"start\":44528},{\"attributes\":{\"id\":\"b14\"},\"end\":45098,\"start\":44828},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":225612365},\"end\":45432,\"start\":45100},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":216467748},\"end\":45938,\"start\":45434},{\"attributes\":{\"id\":\"b17\"},\"end\":46190,\"start\":45940},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":4755450},\"end\":46425,\"start\":46192},{\"attributes\":{\"id\":\"b19\"},\"end\":46757,\"start\":46427},{\"attributes\":{\"id\":\"b20\"},\"end\":46999,\"start\":46759},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":227054126},\"end\":47501,\"start\":47001},{\"attributes\":{\"doi\":\"arXiv:2106.05470\",\"id\":\"b22\"},\"end\":47814,\"start\":47503},{\"attributes\":{\"id\":\"b23\"},\"end\":48120,\"start\":47816},{\"attributes\":{\"id\":\"b24\"},\"end\":48357,\"start\":48122},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":6628106},\"end\":48530,\"start\":48359},{\"attributes\":{\"doi\":\"arXiv:1609.02907\",\"id\":\"b26\"},\"end\":48799,\"start\":48532},{\"attributes\":{\"id\":\"b27\"},\"end\":49028,\"start\":48801},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":204838020},\"end\":49533,\"start\":49030},{\"attributes\":{\"doi\":\"arXiv:2107.06641\",\"id\":\"b29\"},\"end\":49901,\"start\":49535},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":244838846},\"end\":50179,\"start\":49903},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":235826319},\"end\":50458,\"start\":50181},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":119145087},\"end\":50810,\"start\":50460},{\"attributes\":{\"doi\":\"10.1145/3459637.3482225\",\"id\":\"b33\",\"matched_paper_id\":222133312},\"end\":51655,\"start\":50812},{\"attributes\":{\"id\":\"b34\"},\"end\":51813,\"start\":51657},{\"attributes\":{\"id\":\"b35\"},\"end\":52045,\"start\":51815},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":10795036},\"end\":52319,\"start\":52047},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":14899273},\"end\":52556,\"start\":52321},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":2117600},\"end\":52800,\"start\":52558},{\"attributes\":{\"id\":\"b39\"},\"end\":53050,\"start\":52802},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":4833213},\"end\":53275,\"start\":53052},{\"attributes\":{\"id\":\"b41\"},\"end\":53645,\"start\":53277},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":235185402},\"end\":54008,\"start\":53647},{\"attributes\":{\"id\":\"b43\"},\"end\":54528,\"start\":54010},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":159042183},\"end\":54811,\"start\":54530},{\"attributes\":{\"id\":\"b45\"},\"end\":55061,\"start\":54813},{\"attributes\":{\"id\":\"b46\"},\"end\":55328,\"start\":55063},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":7531970},\"end\":55627,\"start\":55330},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":224814335},\"end\":55942,\"start\":55629},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":6392154},\"end\":56229,\"start\":55944},{\"attributes\":{\"id\":\"b50\"},\"end\":56637,\"start\":56231},{\"attributes\":{\"id\":\"b51\",\"matched_paper_id\":27308776},\"end\":56986,\"start\":56639},{\"attributes\":{\"id\":\"b52\"},\"end\":57337,\"start\":56988},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":250304225},\"end\":57637,\"start\":57339},{\"attributes\":{\"id\":\"b54\",\"matched_paper_id\":235422459},\"end\":57948,\"start\":57639},{\"attributes\":{\"id\":\"b55\",\"matched_paper_id\":211505919},\"end\":58415,\"start\":57950},{\"attributes\":{\"id\":\"b56\",\"matched_paper_id\":3350305},\"end\":58770,\"start\":58417}]", "bib_title": "[{\"end\":41343,\"start\":41243},{\"end\":41719,\"start\":41645},{\"end\":42007,\"start\":41961},{\"end\":42305,\"start\":42252},{\"end\":42959,\"start\":42883},{\"end\":43187,\"start\":43152},{\"end\":44580,\"start\":44528},{\"end\":45194,\"start\":45100},{\"end\":45481,\"start\":45434},{\"end\":46241,\"start\":46192},{\"end\":47056,\"start\":47001},{\"end\":48147,\"start\":48122},{\"end\":48401,\"start\":48359},{\"end\":49086,\"start\":49030},{\"end\":49947,\"start\":49903},{\"end\":50210,\"start\":50181},{\"end\":50562,\"start\":50460},{\"end\":50877,\"start\":50812},{\"end\":52104,\"start\":52047},{\"end\":52352,\"start\":52321},{\"end\":52618,\"start\":52558},{\"end\":53103,\"start\":53052},{\"end\":53784,\"start\":53647},{\"end\":54079,\"start\":54010},{\"end\":54588,\"start\":54530},{\"end\":55355,\"start\":55330},{\"end\":55678,\"start\":55629},{\"end\":56011,\"start\":55944},{\"end\":56695,\"start\":56639},{\"end\":57372,\"start\":57339},{\"end\":57698,\"start\":57639},{\"end\":58029,\"start\":57950},{\"end\":58496,\"start\":58417}]", "bib_author": "[{\"end\":40301,\"start\":40292},{\"end\":40321,\"start\":40301},{\"end\":40332,\"start\":40321},{\"end\":40628,\"start\":40612},{\"end\":40643,\"start\":40628},{\"end\":40653,\"start\":40643},{\"end\":40662,\"start\":40653},{\"end\":40879,\"start\":40870},{\"end\":40893,\"start\":40879},{\"end\":40906,\"start\":40893},{\"end\":41360,\"start\":41345},{\"end\":41375,\"start\":41360},{\"end\":41388,\"start\":41375},{\"end\":41401,\"start\":41388},{\"end\":41410,\"start\":41401},{\"end\":41425,\"start\":41410},{\"end\":41735,\"start\":41721},{\"end\":41749,\"start\":41735},{\"end\":41761,\"start\":41749},{\"end\":41776,\"start\":41761},{\"end\":41789,\"start\":41776},{\"end\":42022,\"start\":42009},{\"end\":42044,\"start\":42022},{\"end\":42054,\"start\":42044},{\"end\":42068,\"start\":42054},{\"end\":42079,\"start\":42068},{\"end\":42320,\"start\":42307},{\"end\":42333,\"start\":42320},{\"end\":42346,\"start\":42333},{\"end\":42364,\"start\":42346},{\"end\":42696,\"start\":42687},{\"end\":42713,\"start\":42696},{\"end\":42721,\"start\":42713},{\"end\":42973,\"start\":42961},{\"end\":42981,\"start\":42973},{\"end\":42992,\"start\":42981},{\"end\":43005,\"start\":42992},{\"end\":43201,\"start\":43189},{\"end\":43209,\"start\":43201},{\"end\":43223,\"start\":43209},{\"end\":43454,\"start\":43443},{\"end\":43466,\"start\":43454},{\"end\":43474,\"start\":43466},{\"end\":43489,\"start\":43474},{\"end\":43503,\"start\":43489},{\"end\":43512,\"start\":43503},{\"end\":43790,\"start\":43779},{\"end\":43802,\"start\":43790},{\"end\":43816,\"start\":43802},{\"end\":43824,\"start\":43816},{\"end\":43833,\"start\":43824},{\"end\":43848,\"start\":43833},{\"end\":43862,\"start\":43848},{\"end\":43871,\"start\":43862},{\"end\":44097,\"start\":44086},{\"end\":44106,\"start\":44097},{\"end\":44119,\"start\":44106},{\"end\":44127,\"start\":44119},{\"end\":44142,\"start\":44127},{\"end\":44155,\"start\":44142},{\"end\":44164,\"start\":44155},{\"end\":44178,\"start\":44164},{\"end\":44193,\"start\":44178},{\"end\":44205,\"start\":44193},{\"end\":44593,\"start\":44582},{\"end\":44602,\"start\":44593},{\"end\":44613,\"start\":44602},{\"end\":44888,\"start\":44877},{\"end\":44896,\"start\":44888},{\"end\":44905,\"start\":44896},{\"end\":44914,\"start\":44905},{\"end\":44925,\"start\":44914},{\"end\":44939,\"start\":44925},{\"end\":44950,\"start\":44939},{\"end\":45207,\"start\":45196},{\"end\":45215,\"start\":45207},{\"end\":45224,\"start\":45215},{\"end\":45239,\"start\":45224},{\"end\":45252,\"start\":45239},{\"end\":45494,\"start\":45483},{\"end\":45502,\"start\":45494},{\"end\":45510,\"start\":45502},{\"end\":45523,\"start\":45510},{\"end\":45538,\"start\":45523},{\"end\":45547,\"start\":45538},{\"end\":45561,\"start\":45547},{\"end\":45951,\"start\":45940},{\"end\":45959,\"start\":45951},{\"end\":45970,\"start\":45959},{\"end\":45985,\"start\":45970},{\"end\":45999,\"start\":45985},{\"end\":46008,\"start\":45999},{\"end\":46267,\"start\":46243},{\"end\":46278,\"start\":46267},{\"end\":46288,\"start\":46278},{\"end\":46521,\"start\":46508},{\"end\":46534,\"start\":46521},{\"end\":46542,\"start\":46534},{\"end\":46555,\"start\":46542},{\"end\":46567,\"start\":46555},{\"end\":46573,\"start\":46567},{\"end\":46774,\"start\":46761},{\"end\":46785,\"start\":46774},{\"end\":46800,\"start\":46785},{\"end\":46813,\"start\":46800},{\"end\":46821,\"start\":46813},{\"end\":46836,\"start\":46821},{\"end\":47067,\"start\":47058},{\"end\":47079,\"start\":47067},{\"end\":47090,\"start\":47079},{\"end\":47098,\"start\":47090},{\"end\":47109,\"start\":47098},{\"end\":47123,\"start\":47109},{\"end\":47559,\"start\":47550},{\"end\":47572,\"start\":47559},{\"end\":47586,\"start\":47572},{\"end\":47594,\"start\":47586},{\"end\":47605,\"start\":47594},{\"end\":47619,\"start\":47605},{\"end\":47825,\"start\":47816},{\"end\":47833,\"start\":47825},{\"end\":47846,\"start\":47833},{\"end\":48165,\"start\":48149},{\"end\":48179,\"start\":48165},{\"end\":48193,\"start\":48179},{\"end\":48213,\"start\":48193},{\"end\":48415,\"start\":48403},{\"end\":48429,\"start\":48415},{\"end\":48433,\"start\":48429},{\"end\":48608,\"start\":48598},{\"end\":48618,\"start\":48608},{\"end\":48627,\"start\":48618},{\"end\":48868,\"start\":48855},{\"end\":48880,\"start\":48868},{\"end\":48891,\"start\":48880},{\"end\":48901,\"start\":48891},{\"end\":49101,\"start\":49088},{\"end\":49115,\"start\":49101},{\"end\":49126,\"start\":49115},{\"end\":49135,\"start\":49126},{\"end\":49146,\"start\":49135},{\"end\":49160,\"start\":49146},{\"end\":49548,\"start\":49535},{\"end\":49559,\"start\":49548},{\"end\":49570,\"start\":49559},{\"end\":49583,\"start\":49570},{\"end\":49593,\"start\":49583},{\"end\":49606,\"start\":49593},{\"end\":49614,\"start\":49606},{\"end\":49628,\"start\":49614},{\"end\":49634,\"start\":49628},{\"end\":49962,\"start\":49949},{\"end\":49976,\"start\":49962},{\"end\":49985,\"start\":49976},{\"end\":49993,\"start\":49985},{\"end\":50001,\"start\":49993},{\"end\":50012,\"start\":50001},{\"end\":50026,\"start\":50012},{\"end\":50225,\"start\":50212},{\"end\":50234,\"start\":50225},{\"end\":50242,\"start\":50234},{\"end\":50252,\"start\":50242},{\"end\":50261,\"start\":50252},{\"end\":50272,\"start\":50261},{\"end\":50282,\"start\":50272},{\"end\":50296,\"start\":50282},{\"end\":50578,\"start\":50564},{\"end\":50598,\"start\":50578},{\"end\":50887,\"start\":50879},{\"end\":50900,\"start\":50887},{\"end\":50911,\"start\":50900},{\"end\":50922,\"start\":50911},{\"end\":50936,\"start\":50922},{\"end\":50947,\"start\":50936},{\"end\":51690,\"start\":51682},{\"end\":51704,\"start\":51690},{\"end\":51834,\"start\":51815},{\"end\":51852,\"start\":51834},{\"end\":52124,\"start\":52106},{\"end\":52144,\"start\":52124},{\"end\":52155,\"start\":52144},{\"end\":52171,\"start\":52155},{\"end\":52368,\"start\":52354},{\"end\":52376,\"start\":52368},{\"end\":52386,\"start\":52376},{\"end\":52628,\"start\":52620},{\"end\":52640,\"start\":52628},{\"end\":52819,\"start\":52802},{\"end\":52839,\"start\":52819},{\"end\":53115,\"start\":53105},{\"end\":53128,\"start\":53115},{\"end\":53143,\"start\":53128},{\"end\":53291,\"start\":53277},{\"end\":53301,\"start\":53291},{\"end\":53311,\"start\":53301},{\"end\":53325,\"start\":53311},{\"end\":53333,\"start\":53325},{\"end\":53347,\"start\":53333},{\"end\":53354,\"start\":53347},{\"end\":53799,\"start\":53786},{\"end\":53810,\"start\":53799},{\"end\":54094,\"start\":54081},{\"end\":54107,\"start\":54094},{\"end\":54118,\"start\":54107},{\"end\":54129,\"start\":54118},{\"end\":54143,\"start\":54129},{\"end\":54602,\"start\":54590},{\"end\":54615,\"start\":54602},{\"end\":54626,\"start\":54615},{\"end\":54636,\"start\":54626},{\"end\":54651,\"start\":54636},{\"end\":54825,\"start\":54813},{\"end\":54838,\"start\":54825},{\"end\":54849,\"start\":54838},{\"end\":55119,\"start\":55107},{\"end\":55133,\"start\":55119},{\"end\":55149,\"start\":55133},{\"end\":55158,\"start\":55149},{\"end\":55171,\"start\":55158},{\"end\":55177,\"start\":55171},{\"end\":55372,\"start\":55357},{\"end\":55389,\"start\":55372},{\"end\":55408,\"start\":55389},{\"end\":55427,\"start\":55408},{\"end\":55692,\"start\":55680},{\"end\":55704,\"start\":55692},{\"end\":55715,\"start\":55704},{\"end\":55728,\"start\":55715},{\"end\":55740,\"start\":55728},{\"end\":55754,\"start\":55740},{\"end\":55764,\"start\":55754},{\"end\":56021,\"start\":56013},{\"end\":56041,\"start\":56021},{\"end\":56056,\"start\":56041},{\"end\":56070,\"start\":56056},{\"end\":56243,\"start\":56231},{\"end\":56255,\"start\":56243},{\"end\":56269,\"start\":56255},{\"end\":56283,\"start\":56269},{\"end\":56298,\"start\":56283},{\"end\":56311,\"start\":56298},{\"end\":56718,\"start\":56697},{\"end\":56732,\"start\":56718},{\"end\":56747,\"start\":56732},{\"end\":56761,\"start\":56747},{\"end\":56767,\"start\":56761},{\"end\":57069,\"start\":57059},{\"end\":57081,\"start\":57069},{\"end\":57095,\"start\":57081},{\"end\":57114,\"start\":57095},{\"end\":57125,\"start\":57114},{\"end\":57140,\"start\":57125},{\"end\":57150,\"start\":57140},{\"end\":57388,\"start\":57374},{\"end\":57399,\"start\":57388},{\"end\":57408,\"start\":57399},{\"end\":57422,\"start\":57408},{\"end\":57714,\"start\":57700},{\"end\":57727,\"start\":57714},{\"end\":57738,\"start\":57727},{\"end\":57747,\"start\":57738},{\"end\":57761,\"start\":57747},{\"end\":57773,\"start\":57761},{\"end\":58045,\"start\":58031},{\"end\":58058,\"start\":58045},{\"end\":58069,\"start\":58058},{\"end\":58078,\"start\":58069},{\"end\":58092,\"start\":58078},{\"end\":58104,\"start\":58092},{\"end\":58115,\"start\":58104},{\"end\":58512,\"start\":58498},{\"end\":58525,\"start\":58512},{\"end\":58538,\"start\":58525},{\"end\":58548,\"start\":58538},{\"end\":58562,\"start\":58548},{\"end\":58573,\"start\":58562}]", "bib_venue": "[{\"end\":45708,\"start\":45643},{\"end\":47274,\"start\":47207},{\"end\":49301,\"start\":49239},{\"end\":51214,\"start\":51086},{\"end\":54290,\"start\":54225},{\"end\":56794,\"start\":56774},{\"end\":40394,\"start\":40332},{\"end\":40715,\"start\":40678},{\"end\":41035,\"start\":40922},{\"end\":41430,\"start\":41425},{\"end\":41794,\"start\":41789},{\"end\":42094,\"start\":42079},{\"end\":42450,\"start\":42364},{\"end\":42753,\"start\":42721},{\"end\":43009,\"start\":43005},{\"end\":43279,\"start\":43223},{\"end\":43560,\"start\":43512},{\"end\":43777,\"start\":43703},{\"end\":44280,\"start\":44221},{\"end\":44669,\"start\":44613},{\"end\":44875,\"start\":44828},{\"end\":45261,\"start\":45252},{\"end\":45641,\"start\":45561},{\"end\":46054,\"start\":46008},{\"end\":46295,\"start\":46288},{\"end\":46506,\"start\":46427},{\"end\":46866,\"start\":46836},{\"end\":47205,\"start\":47123},{\"end\":47548,\"start\":47503},{\"end\":47963,\"start\":47846},{\"end\":48224,\"start\":48213},{\"end\":48437,\"start\":48433},{\"end\":48596,\"start\":48532},{\"end\":48853,\"start\":48801},{\"end\":49237,\"start\":49160},{\"end\":49693,\"start\":49650},{\"end\":50033,\"start\":50026},{\"end\":50306,\"start\":50296},{\"end\":50614,\"start\":50598},{\"end\":51084,\"start\":50981},{\"end\":51680,\"start\":51657},{\"end\":51905,\"start\":51868},{\"end\":52174,\"start\":52171},{\"end\":52420,\"start\":52386},{\"end\":52660,\"start\":52640},{\"end\":52901,\"start\":52855},{\"end\":53150,\"start\":53143},{\"end\":53436,\"start\":53370},{\"end\":53819,\"start\":53810},{\"end\":54223,\"start\":54143},{\"end\":54658,\"start\":54651},{\"end\":54932,\"start\":54849},{\"end\":55105,\"start\":55063},{\"end\":55463,\"start\":55427},{\"end\":55773,\"start\":55764},{\"end\":56074,\"start\":56070},{\"end\":56417,\"start\":56311},{\"end\":56772,\"start\":56767},{\"end\":57057,\"start\":56988},{\"end\":57478,\"start\":57422},{\"end\":57780,\"start\":57773},{\"end\":58164,\"start\":58115},{\"end\":58576,\"start\":58573}]"}}}, "year": 2023, "month": 12, "day": 17}