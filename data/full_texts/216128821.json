{"id": 216128821, "updated": "2022-01-26 19:06:03.714", "metadata": {"title": "Deep learning for the determination of myometrial invasion depth and automatic lesion identification in endometrial cancer MR imaging: a preliminary study in a single institution", "authors": "[{\"middle\":[],\"last\":\"Chen\",\"first\":\"Xiaojun\"},{\"middle\":[],\"last\":\"Wang\",\"first\":\"Yida\"},{\"middle\":[],\"last\":\"Shen\",\"first\":\"Minhua\"},{\"middle\":[],\"last\":\"Yang\",\"first\":\"Bingyi\"},{\"middle\":[],\"last\":\"Zhou\",\"first\":\"Qing\"},{\"middle\":[],\"last\":\"Yi\",\"first\":\"Yinqiao\"},{\"middle\":[],\"last\":\"Liu\",\"first\":\"Weifeng\"},{\"middle\":[],\"last\":\"Zhang\",\"first\":\"Guofu\"},{\"middle\":[],\"last\":\"Yang\",\"first\":\"Guang\"},{\"middle\":[],\"last\":\"Zhang\",\"first\":\"He\"}]", "venue": "European Radiology", "journal": "European Radiology", "publication_date": {"year": 2020, "month": null, "day": null}, "abstract": "To determine the diagnostic performance of a deep learning (DL) model in evaluating myometrial invasion (MI) depth on T2-weighted imaging (T2WI)\u2013based endometrial cancer (EC) MR imaging (ECM). We retrospectively enrolled 530 patients with pathologically proven EC at our institution between January 1, 2013, and December 31, 2017. All imaging data were reviewed on picture archiving and communication systems (PACS) server. Both sagittal and coronal T2WI-based MR images were used for lesion area determination. All MR images were divided into two groups: deep (more than 50%) and shallow (less than 50%) MI based on their pathological diagnosis. We trained a detection model based on YOLOv3 algorithm to locate the lesion area on ECM. Then, the detected regions were fed into a classification model based on DL network to identify MI depth automatically. In the testing dataset, the trained model detected lesion regions with an average precision rate of 77.14% and 86.67% in both sagittal and coronal images, respectively. The classification model yielded an accuracy of 84.78%, a sensitivity of 66.67%, a specificity of 87.50%, a positive predictive value of 44.44%, and a negative predictive value of 94.59% in determining deep MI. The radiologists and trained network model together yielded an accuracy of 86.2%, a sensitivity of 77.8%, a specificity of 87.5%, a positive predictive value of 48.3%, and a negative predictive value of 96.3%. In this study, the DL network model derived from MR imaging provided a competitive, time-efficient diagnostic performance in MI depth identification. \u2022 The models established with the deep learning method could help improve the diagnostic confidence and performance of MI identification based on endometrial cancer MR imaging. \u2022 The models enabled the classification of endometrial cancer MR images to the two categories with a sensitivity of 0.67, a specificity of 0.88, and an accuracy of 0.85. \u2022 Using the detected lesion region to evaluate myometrial invasion depth could remove redundant information in the image and provide more effective features.", "fields_of_study": "[\"Medicine\"]", "external_ids": {"arxiv": null, "mag": "3018913999", "acl": null, "pubmed": "32337640", "pubmedcentral": null, "dblp": null, "doi": "10.1007/s00330-020-06870-1"}}, "content": {"source": {"pdf_hash": "3d8644be5e0cfc2cd7c3fd37bc1f53b875a4e807", "pdf_src": "Springer", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "a80ae80680b88274842dbb56b0772b6690a65555", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/3d8644be5e0cfc2cd7c3fd37bc1f53b875a4e807.txt", "contents": "\nDeep learning for the determination of myometrial invasion depth and automatic lesion identification in endometrial cancer MR imaging: a preliminary study in a single institution\n\n\nXiaojun Chen \nDepartment of Gynecology, Obstetrics and Gynecology Hospital\nFudan University\nShanghaiPeople's Republic of China\n\nYida Wang \nShanghai Key Laboratory of Magnetic Resonance\nEast China Normal University\nShanghaiPeople's Republic of China\n\nMinhua Shen \nDepartment of Radiology, Obstetrics and Gynecology Hospital\nFudan University\nShanghaiPeople's Republic of China\n\nBingyi Yang gyang@phy.ecnu.edu.cn \nDepartment of Gynecology, Obstetrics and Gynecology Hospital\nFudan University\nShanghaiPeople's Republic of China\n\nQing Zhou \nDepartment of Radiology, Obstetrics and Gynecology Hospital\nFudan University\nShanghaiPeople's Republic of China\n\nYinqiao Yi \nShanghai Key Laboratory of Magnetic Resonance\nEast China Normal University\nShanghaiPeople's Republic of China\n\nWeifeng Liu \nDepartment of Radiology, Guangzhou First People's Hospital, the Second Affiliated Hospital of South\nChina University of Technology\nGuangzhouPeople's Republic of China\n\nGuofu Zhang \nDepartment of Radiology, Obstetrics and Gynecology Hospital\nFudan University\nShanghaiPeople's Republic of China\n\nGuang Yang \nShanghai Key Laboratory of Magnetic Resonance\nEast China Normal University\nShanghaiPeople's Republic of China\n\nHe Zhang dr.zhanghe@yahoo.com \nDepartment of Radiology, Obstetrics and Gynecology Hospital\nFudan University\nShanghaiPeople's Republic of China\n\n\nIMAGING INFORMATICS AND ARTIFICIAL INTELLIGENCE\n\n\nDeep learning for the determination of myometrial invasion depth and automatic lesion identification in endometrial cancer MR imaging: a preliminary study in a single institution\nReceived: 29 December 2019 / Revised: 14 March 2020 / Accepted: 6 April 2020 # European Society of Radiology 2020 / Published online: 26 April 2020 European Radiology (2020) 30:4985-4994Xiaojun Chen and Yida Wang contributed equally to this work. Electronic supplementary material The online version of this article (https://doi.org/10.1007/s00330-020-06870-1) contains supplementary material, which is available to authorized users. * Guang Yang * He ZhangEndometrial cancer Magnetic resonance imaging Deep learning Neoplasm staging\nObjective To determine the diagnostic performance of a deep learning (DL) model in evaluating myometrial invasion (MI) depth on T2-weighted imaging (T2WI)-based endometrial cancer (EC) MR imaging (ECM). Methods We retrospectively enrolled 530 patients with pathologically proven EC at our institution between January 1, 2013, and December 31, 2017. All imaging data were reviewed on picture archiving and communication systems (PACS) server. Both sagittal and coronal T2WI-based MR images were used for lesion area determination. All MR images were divided into two groups: deep (more than 50%) and shallow (less than 50%) MI based on their pathological diagnosis. We trained a detection model based on YOLOv3 algorithm to locate the lesion area on ECM. Then, the detected regions were fed into a classification model based on DL network to identify MI depth automatically. Results In the testing dataset, the trained model detected lesion regions with an average precision rate of 77.14% and 86.67% in both sagittal and coronal images, respectively. The classification model yielded an accuracy of 84.78%, a sensitivity of 66.67%, a specificity of 87.50%, a positive predictive value of 44.44%, and a negative predictive value of 94.59% in determining deep MI. The radiologists and trained network model together yielded an accuracy of 86.2%, a sensitivity of 77.8%, a specificity of 87.5%, a positive predictive value of 48.3%, and a negative predictive value of 96.3%. Conclusion In this study, the DL network model derived from MR imaging provided a competitive, time-efficient diagnostic performance in MI depth identification. Key Points \u2022 The models established with the deep learning method could help improve the diagnostic confidence and performance of MI identification based on endometrial cancer MR imaging. \u2022 The models enabled the classification of endometrial cancer MR images to the two categories with a sensitivity of 0.67, a specificity of 0.88, and an accuracy of 0.85. \u2022 Using the detected lesion region to evaluate myometrial invasion depth could remove redundant information in the image and provide more effective features.\n\nIntroduction\n\nEndometrial cancer (EC) is the most common gynecologic malignancy [1], with nearly 320,000 reported newly diagnosed cases per year worldwide [2]. Surgery is the main treatment for EC patients. Myometrial invasion (MI) depth is one of the main criteria to decide whether patients should receive lymphadenectomy and its extending during surgical operation [3,4]. Simple hysterectomy without lymphadenectomy is appropriate for low-risk EC patients, while pelvic and para-aortic lymphadenectomy is often suggested for high-risk patients [5]. Therefore, precise evaluation of depth of MI before operation provides valuable information in decision-making [6]. Magnetic resonance imaging (MRI) is widely used in clinical units for the diagnosis, staging, and classification of gynecological malignancies [7][8][9]. The published results for MI depth evaluation on MRI varied, with the sensitivity (SEN) ranging from 42 to 100% and the specificity (SPE) from 85 to 93%. Recent studies reported that tumor volume measurement on ECM was associated with deep MI and lymph node metastases (LNMs) and could be regarded as a negative prognostic indicator for EC patients [10][11][12][13]. One study reported that a tumor-uterine volume ratio greater than 25% could be used to predict deep MI with high accuracy (ACC) with a SEN of 100% and a SPE of 93% [13]. Quantitative measurements on MRI have higher diagnostic performance in deep MI identification than direct observation by radiologists; sometimes, it is inaccurate to assess some invisible EC lesion on MRI. In one computerized-diagnostic model study, MRI-based texture model yielded a SEN and SPE of 79.3% and 82.3%, respectively, in deep MI evaluation [14]. Reported studies to date have shown the relatively unsatisfied SEN and SPE for MI evaluation on ECM. The results mainly depended on manual cancer volume calculation and individuals' interpretation, varying on both institutional modalities and operators' experience. Lack of standardization in evaluation limits its application in clinical practice. Intraoperative frozen section diagnosis is another option for MI evaluation; however, the result is not as accurate as final pathological diagnosis [15].\n\nDeep learning technology with convolutional neural networks (CNNs) is a new method of computer-aided diagnosis that allows automatic capture of targeted area after training process [16][17][18][19][20][21][22].To our knowledge, no research has been published on the use of DL on ECM to automatically judge MI depth. From this point of view, the aim of this study was twofold: first, we tried to establish a machine learning (ML) network to automatically determine MI depth on T2WI-based ECM using DL method with sufficient training data having known MI status labels; secondly, we compared the assessment of computerized network learning model with radiologists' results in judging MI depth.\n\n\nMaterial and methods\n\n\nPatients\n\nOur institutional review board (Gynecological and Obstetric Hospital, School of Medicine, Fudan University, P. R. China) approved this retrospective study, and the requirement for informed consent was waived for all participants. From January 1, 2013, to December 31, 2017, the data of 743 patients with clinically suspected EC were retrieved from the PACS server of our institution. The inclusion criteria were as follows: (1) female patients with clinical suspicion of EC; (2) pelvic MRI scan for EC before surgery. The exclusion criteria were as follows: (1) previous gynecological malignancy; (2) previous pelvic surgery/radiation therapy; (3) severe breathing-motive artifacts; (4) missing of MRI data (claustrophobia or MRI examination in other institutions) or final histological results. Finally, the total number of patients in the studied sample was 530 (average age, 54 \u00b1 9.0 years). The sample comprised 440 patients with endometrioid EC and 90 patients with nonendometrioid subtypes of EC. All included samples were pathologically proven by laparoscopy or laparotomy. We randomly selected 313 cases (57 deep/256 shallow) as the training dataset to train the model parameters, 79 cases (24 deep/55 shallow) as the validation dataset to choose the hyperparameters of the model, and 138 cases (18 deep/120 shallow) as the test dataset to evaluate the performance of the established model (Table 1).\n\n\nMR acquisition and interpretation\n\nMR was performed using a 1.5-T MR system (Magnetom Avanto, Siemens) with a phased-array coil. The routine MR protocols used for the assessment of pelvic masses included axial turbo spin-echo (TSE) T1-weighted imaging (T1WI), coronal TSE T2WI, and axial/sagittal TSE fat-saturated T2WI (FS T2WI). For axial images, the transverse plane was perpendicular to the long axis of the uterine body; for sagittal images, the longitudinal plane was parallel to the main body of the uterus. Diffusion-weighted imaging (DWI) was performed in the axial plane using an echo-planar imaging two-dimensional (EP2D) sequence and parallel acquisition technique, with b values of 0, 100, and 800 s/mm 2 . Contrast-enhanced pelvic imaging was acquired at multiple phases of contrast medium enhancement in both the sagittal and axial planes. The detailed MR acquisition parameters are listed in Supplementary Table 1. All ECM lesion interpretations were performed by two experienced radiologists (H.Z. and G.Z., both with more than 10 years of experience). The tumor maximum diameter (MD), cervix invasion, and node condition were separately recorded for each patient. Clinical characteristics (age, stage, and grade) were also retrieved through the hospital information system. The MI depth on MRI was graded with a 5-point scale, which assessed the diagnostic confidence in detecting MI as follows: 5 = definitely invading more than 50% of the myometrium, 4 = possibly more than 50% of the myometrium, 3 = equivocal, 2 = possibly less than 50% of the myometrium, and 1 = definitely less than 50% of the myometrium. For any disagreements about the MI status identification, either consensus was achieved after discussion or the senior radiologist's (G.Z.) opinion was accepted due to extensive experience. We considered scores of 4 and 5 as the positive group.\n\n\nMRI lesion labeling\n\nLesion segmentation was performed by two experienced radiologists (H.Z. and M.S.). Whole lesion segmentation was manually outlined with MATLAB (version R2015b, MathWorks) on each slice with detected lesions. We did not outline the lesion margin; instead, we drew a square box to encompass the lesion and surrounding structure (Fig. 1). These bounding boxes were treated as ground truth of the detection model. Two protocols (sagittal FS-T2WI and coronal T2WI) were selected for the whole lesion identification.\n\n\nData preparation and processing\n\nThere were 530 cases in the studied sample, including 99 deep and 431 shallow MI cases. We randomly selected 313 cases (57 deep/256 shallow) including 4806 images in total as the training dataset to train the model parameters, 79 cases (24 deep/55 shallow) including 1154 images in total as the validation dataset to choose the hyperparameters of the model, and 138 cases (18 deep/120 shallow) including 2070 images in total as the testing dataset to evaluate the performance of the established model (Table 1). Since cases labeled as shallow MI outnumbered those as deep MI, the imbalance between these two classes may have a serious negative effect on the performance of the model. Over-sampling is a solving method in addressing the class imbalance problem, which copies the small class until it contains as many examples as the other class [23]. During the training process, we over-sampled the deep MI cases to the same number as the shallow MI cases and data augmentation was used to improve the robustness of the model, with random rotation from \u2212 12 to 12 degrees, stretching from 0.8 to 1.2, and shifting from \u2212 10 to 10 pixels for each slice.\n\n\nTraining the ML networks\n\nHere, we proposed a two-stage automatic DL method based on a CNN for the evaluation of MI depth (Fig. 2). YOLOv3 model is a state-of-the-art CNN model aiming for object detection that uses features from the entire image to predict the bounding box for each region of interest [24]. Firstly, we used the YOLOv3 model to detect lesion regions in the ECM images, which was pretrained on the ImageNet classification task [25]. The original MR images and bounding boxes outlined by radiologists were used as the input data to train the YOLOv3 model. Secondly, another CNN-based Resnet network [26] was used to classify MI depth (deep or shallow MI). The original sagittal and coronal MR images were cropped to patches of 96 \u00d7 96 matrices, centered at the lesion bounding box, and covered the whole lesion area (shown in Fig. 2). One sagittal and one coronal patch in each case were combined as a paired patch. The paired patches were input into the network through a convolutional layer and a Resnet block, and the features of the two patches were concatenated together. The concatenated features were input into one 1 \u00d7 1 convolution layer, two Resnet blocks, three fully connected layers, and one softmax layer (Fig. 3). The detailed training environment was summarized in the supplementary file. \n\n\nValidating the algorithm\n\n\nStatistics\n\nIn the test group, the diagnostic performance of radiologist and the computer model for deep MI identification was compared with that of histological diagnosis. Regarding the pathological diagnosis as the golden standard, the ACC, SEN, SPE, positive predictive value (PPV), and negative predictive value (NPV) were expressed as percentages with 95% confidence intervals (CIs). The area under the receiver operating characteristic curve (ROC) was calculated for both the radiologist and the proposed algorithm in classifying MI depth. \n\n\nResults\n\n\nPerformance of the automatic lesion detection model on ECM\n\nThe detection results for both sagittal and coronal images are shown in Fig. 1. In the test dataset, the detection model achieved an average precision of 77.14% and 86.67% based on 0.5 intersection over union in sagittal and coronal images, respectively. The corresponding precision-recall (PR) curves [27] are shown in Fig. 4.\n\n\nDiagnostic performance of the classification model in MI identification on ECM\n\nTreating deep MI as positive, we evaluated the performance of the proposed algorithm on the test dataset with the ROC curve (Fig. 5), and the model achieved an area under the ROC curve (AUC) of 0.78 (95% CI, 0.714-0.798; p < 0.001). The confusion matrix for the DL results and the pathological labels are shown in Table 2. The proposed method achieved a good performance on the determination of MI depth with an ACC of 84.8%, a SEN of 66. 6%, a SPE of 87.5%, a PPVof 44.4%, and a NPV of 94.6% (Table 3).\n\n\nComparative results between DL and radiologists in detecting deep MI on ECM\n\nThe computerized program performed better than the radiologist in determining deep MI based on ECM. However, the diagnostic performance discrepancy between the computer model and radiologists did not differ significantly (p = 0.313). In 7 cases, both the computer model and radiologist made an incorrect evaluation of MI status; in 11 cases, the computer model made a correct evaluation while the radiologist did not; and in 5 cases, the radiologist made a correct evaluation while the computer model did not. The most common diagnostic error between both the radiologist and computer model was the false positive error incorrectly classifying the cases with shallow MI as deep MI on MRI (   Table 4. Both the doctors and computer achieved the highest ACC in MI evaluation in the tumors with less than 2 cm in the diameter group (94% and 86.5%). For tumor diameter between 2 and 4 cm, the computer had higher ACC than the radiologist (84.5% vs 72.4%); for tumors with more than 4 cm, the computer still had better performance than the radiologist (ACC, 80% vs 63.3%). The radiologist's judgments were more heavily influenced by the tumor size than the computer.\n\n\nDiscussion\n\nIn the present study, by using a CNN-based DL method on ECM data, we designed a computerized model to locate the lesion area and evaluate the MI depth automatically. The proposed model yielded a SEN of 66.6%, a SPE of 87.5%, and an ACC of 84.8% on the determination of MI depth. We found that this computerized model showed a better and more timeefficient performance in judging the MI depth than radiologists.\n\nIn one study, the authors established a ML model to predict LNM in EC patients that yielded an ACC between 84.2 and 88.9% for LNM and between 85.0 and 97.6% for para-aortic LNM [28]. However, the parameters used for training the algorithmic models were mainly clinicopathological (tumor grade, histologic type, pelvic or para-aortic node metastatic status, and so on) and biological characteristics including tumor diameter, depth of MI, and lymphovascular space invasion. In contrast, our algorithm only requires image data to train the model and make the prediction. Another study recently reported that automated image analysis and random forest classification can be used to classify normal, premalignant, and malignant endometrial tissues by analyzing wholeslide digital pathological images [29]. Compared with the ECM radiomics study [14], which needed to outline the visible cancer lesion on MR images, we only placed a box encompassing the suspected lesion and surrounding normal anatomic structure as was done in one previous study [30]. We believe that this procedure could help decrease the operator-dependent segmentation bias and improve the efficiency of the workflow, as case-by-case labeling is timeconsuming and lacks standardization to some extent.\n\nHerein, we proposed an efficient and effective approach with the YOLOv3-based network detection model and a Resnet-based classification model to capture rich features in MR images from a large amount of data. Similar networks have been reported in several medical research studies [31,32]. This diagnostic model achieved a high ACC in deep MI identification, and with the help of the computer model, the diagnostic ACC of the radiologists was improved by nearly 10% with high efficiency. In the present study, for deep MI evaluation, the false positive error was the most common diagnostic error for both the radiologists and computer. In the present study, the computer showed relatively good consistency and high ACC in MI depth identification especially for the large tumor. This means that this trained network has the potential to be used in clinical scenarios. The possible reason for this may be that the large EC tumor occupied most of the uterine cavity and could distract radiologists from making a right judgments.\n\nThe difference between our study with previous studies is that the extensive experiences and manual tumor segmentation is not necessary for computer analysis. Compared to extracting features over the entire image for evaluating MI   There are also some limitations in our work. First, the number of deep MI cases used to train DL networks was relatively small; further study can be carried out on a larger sample or with multicenter ECM data. Second, our study extracted twodimensional lesion patches (paired patch images) as the input of the classification model, which might fail to fully utilize the volume information and capture the spatial information. Third, we only input T2WI dataset into the DL network for training, which is different with radiologists' reading session in clinical setting that all MRI dataset (T1WI, T2WI, DWI, and post-contrast MRI) is available. Although patients will benefit more from contrast-free MRI, we believe further study is needed to explore the true learning difference between one and multiple MR acquisitions as input image dataset.\n\nIn summary, our results suggest that the DL network models derived from ECM provide a competitive, timeefficient diagnostic performance in MI depth identification and can help clinicians stage EC with high ACC.  Fig. 6 A 67-year-old patient with endometrial adenocarcinoma. On the gross specimen (a), the tumor invaded the myometrium less than 50% (red arrowheads); cervix invasion was observed (asterisk). On sagittal T2WI (b), the tumor occupied the posterior part of uterus (white arrowheads), extending downwardly to cervix with intact stroma. For this case, the MI depth is relatively difficult to be accurately determined on MRI\n\nFig. 1\n1The detected lesion region on T2WI. The detected lesion region by Yolov3 network (the red box) and operator (the green box, ground truth) are shown on sagittal (top) and coronal (below) T2WI\n\nFig. 3 2 Fig. 2\n322The Resnet network architecture. It consisted of two inputs, three convolution layers (Convs), four Resnet blocks, three fully connected layers (FC), and one softmax layer. Each Resnet block contained two 3 \u00d7 3 Convs and one max-pooling layer with stride The flowchart of the proposed method. A CNN based on Yolov3 algorithm was used to detect lesion region (red rectangle box) and another CNN based on Resnet was applied to classify MI Depth of input patches (green rectangle box)\n\nFig. 5\n5ROC analysis with the trained network for classifying MI depth in three kinds of dataset. The ROC curves for training (red), validation (green), and testing (blue) dataset show the corresponding AUCs of 0.85, 0.81, and 0.78 computer and radiologist according to the tumor MD category are summarized in\n\n\nTP = true positive, TN = true negative, FP = false positive, FN = false negative, N = TP + TN + FP + FN\n\nTable 1 Clinical\n1and pathological \ndata summaries in training, \nvalidation, and independent test \ngroup \n\nTraining data \nValidation data \nTesting data \np value \n\nClinical features \nn = 313 \nn = 79 \nn = 138 \nAge (year) \n46.5 \u00b1 4.9 \n57.0 \u00b1 10.2 \n53.5 \u00b1 10.1 \n0.584 \nBMI (kg/m 2 ) \n25.7 \u00b1 0.98 \n26.5 \u00b1 3.30 \n26.5 \u00b1 3.80 \n0.730 \nMenopausal status \n0.873 \nYes \n168 \n43 \n72 \n\nNo \n145 \n36 \n58 \nPathological type \n0.025 \nEndometrioid type \n274 \n61 \n105 \nGrade 1 \n188 \n35 \n68 \n0.035 \nGrade 2 \n49 \n19 \n21 \nGrade 3 \n37 \n7 \n16 \nOther subtypes \n39 \n18 \n33 \nFIGO stage \n0.000 \nStage 1 \n252 \n64 \n86 \nStage 2 \n22 \n5 \n17 \nStage 3 \n37 \n10 \n34 \nStage 4 \n2 \n1 \nMaximum diameter(mm) \n29.0 \u00b1 18.1 \n29.6 \u00b1 17.9 \n30.4 \u00b1 22.7 \n0.8 \nMyometrial invasion \n0.578 \n< 50%* \n256 \n55 \n120 \n\u2265 50% # \n57 \n24 \n18 \nCervix invasion  \u2020 \n0.844 \nNo \n258 \n65 \n111 \n\nYes \n55 \n14 \n27 \nMetastatic pelvic nodes \n0.868 \nYes \n24 \n7 \n25 \nNo \n253 \n60 \n105 \n\nFIGO, International Federation of Gynecology and Obstetrics; BMI, body mass index; *the lesions locate in both \nendometrium and less than 50% of myometrium; # the lesions reach out the uterus cavity;  \u2020 both mucosa and \nstroma in cervix involved by EC; grade reports are not available in 34 patients; lymph nodes status are not \navailable in 84 patients \n\n\nTable 2 )\n2. \n\n\nTable 3\n3Diagnostic performance comparison between radiologist and computer in determining deep MI depth in the testing group at reference standard in the patient-based evaluation (95 %CI) based on ECMN \nTP TN FP FN SEN \nSPE \nPPV \nNPV \nACC \n\nRadiologist \n138 11 97 23 7 61.1% \n(38.6-79.7%) \n\n80.8% \n(72.9-76.9%) \n\n32.4% \n(19.1-49.2%) \n\n93.3% \n(86.8-96.7%) \n\n78.3% \n(70.7-84.3%) \nComputer \n138 12 105 15 6 66.6% \n(43.8-83.7%) \n\n87.5% \n(80.4-92.3%) \n\n44.4% \n(27.6-62.7%) \n\n94.6% \n(88.7-97.5%) \n\n84.8% \n(77.9-89.8%) \nRadiologist and \ncomputer \n\n138 14 105 15 4 77.8% \n(54.8-91.0%) \n\n87.5% \n(80.4-92.3%) \n\n48.3% \n(31.4-65.6%) \n\n96.3% \n(90.9-98.6%) \n\n86.2% \n(79.5-91.0%) \n\n\n\nTable 2\n2The discrepancy between computer and radiologist in MI depth evaluation taking the pathologic diagnosis as the golden standard in the test group based on ECM depth one time, our two-stage approach avoided hand-crafted feature engineering and automatically extracted image features relevant to lesion detection. Lesion patches on both the sagittal and coronal MR images were simultaneously fed into the network, which allowed the detection model to use relevant features in two protocols of MR image dataset. Since the number of deep MI cases used to train the model was much smaller than that of shallow cases, the proposed model might fail to capture all MRI features of the deep MI cases, and this may be the reason why our present model exhibited a low SEN and PPV. Besides, we did not evaluate the LNM status because the number of positive samples was too small to train an efficient CNN model. However, we believe it will be an important research work in the near future.Pathologic diagnosis \nTotal p value \n\nComputer \nDeep MI Shallow MI \n0.313 \nDeep MI \n12 \n15 \n27 \nShallow MI \n6 \n105 \n111 \nRadiologist \nDeep MI \n11 \n23 \n34 \nShallow MI \n7 \n97 \n104 \n\n\nTable 4\n4Diagnostic performance comparison between radiologist and computer in determining deep MI depth in the testing group at reference standard in the diameter-based evaluation (95 %CI) based on ECM Tumor MD N TP TN FP FN SEN SPE PPV NPV ACC TP = true positive, TN = true negative, FP = false positive, FN = false negative, N = TP + TN + FP + FN\u2264 2 cm \n50 \nRadiologist \n-47 1 2 20% (21.2-74.2%) 97.9% \n(89.1-99.6%) \n\n33.3% (3.6-87.1%) 95.9% \n(86.3-98.9%) \n\n94.0% \n(83.8-97.9%) \nComputer \n-44 4 2 16.7% (1.8-69.0%) 90.8% \n(79.5-96.2%) \n\n10% (1.1-53.7%) 94.7% \n(84.3-98.3%) \n\n86.5% \n(74.7-93.3%) \n> 2 cm and \n\u2264 4 cm \n\n58 \n\nRadiologist \n2 40 13 3 40% (11.8-76.9%) 75.5% \n(62.4-85.1%) \n\n13.3% (3.7-37.9%) 93.0% \n(81.4-97.6%) \n\n72.4% \n(59.7-82.2%) \nComputer \n2 47 6 3 40% (11.8-76.9%) 88.7% \n(77.4-94.7%) \n\n25.0% (7.2-59.1%) 94.0% \n(83.8-97.9%) \n\n84.5% \n(73.1-91.6%) \n> 4 cm \n30 \nRadiologist \n9 10 9 2 81.8% \n(52.3-94.9%) \n\n52.6% \n(31.7-72.7%) \n\n50% (29.0-71.0%) 83.3% \n(55.2-95.3%) \n\n63.3% \n(45.5-78.1%) \nComputer \n10 14 5 1 90.9% \n(62.3-98.4% \n\n73.7% \n(51.2-88.2%) \n\n66.7% \n(41.7-84.8%) \n\n93.3% \n(70.2-98.8%) \n\n80.0% \n(62.7-90.5%) \n\n\nCompliance with ethical standardsGuarantor The scientific guarantor of this publication is Guofu Zhang.Conflict of interestThe authors of this manuscript declare no relationships with any companies whose products or services may be related to the subject matter of the article.Statistics and biometry No complex statistical methods were necessary for this paper.Informed consent Written informed consent was waived by the Institutional Review Board.Ethical approval Institutional Review Board approval was obtained.Methodology\u2022 Retrospective \u2022 Diagnostic or prognostic study \u2022 Performed at one institution\nEndometrial cancer. P Morice, A Leary, C Creutzberg, N Abu-Rustum, E Darai, 10.1016/S0140-6736(15)00130-0Lancet. 38715Morice P, Leary A, Creutzberg C, Abu-Rustum N, Darai E (2016) Endometrial cancer. Lancet 387:1094-1108. https://doi.org/10. 1016/S0140-6736(15)00130-0\n\nCancer statistics. R L Siegel, K D Miller, A Jemal, 10.3322/caac.21551CA Cancer J Clin. 69Siegel RL, Miller KD, Jemal A (2019) Cancer statistics, 2019. CA Cancer J Clin 69:7-34. https://doi.org/10.3322/caac.21551\n\nEndometrial cancer MRI staging: updated guidelines of the European Society of Urogenital Radiology. S Nougaret, M Horta, E Sala, 10.1007/s00330-018-5515-yEur Radiol. 29Nougaret S, Horta M, Sala E et al (2019) Endometrial cancer MRI staging: updated guidelines of the European Society of Urogenital Radiology. Eur Radiol 29:792-805. https://doi.org/10.1007/ s00330-018-5515-y\n\nPreoperative MR imaging for ESMO-ESGO-ESTRO classification of endometrial cancer. P Lavaud, B Fedida, G Canlorbe, S Bendifallah, E Darai, I Thomassin-Naggara, Lavaud P, Fedida B, Canlorbe G, Bendifallah S, Darai E, Thomassin-Naggara I (2018) Preoperative MR imaging for ESMO-ESGO-ESTRO classification of endometrial cancer.\n\n. 10.1016/j.diii.2018.01.01001.010Diagn Interv Imaging. 99Diagn Interv Imaging 99:387-396. https://doi.org/10.1016/j.diii. 2018.01.010\n\nCancer of the corpus uteri. F Amant, M R Mirza, M Koskas, C L Creutzberg, Int J Gynecol Obstet. 143S2Amant F, Mirza MR, Koskas M, Creutzberg CL (2018) Cancer of the corpus uteri. Int J Gynecol Obstet 143(S2):37-50\n\nEndometrial cancer: ESMO clinical practice guidelines for diagnosis, treatment and follow-up. N Colombo, E Preti, F Landoni, 10.1093/annonc/mdt353Ann Oncol. 24Colombo N, Preti E, Landoni F et al (2013) Endometrial cancer: ESMO clinical practice guidelines for diagnosis, treatment and fol- low-up. Ann Oncol 24:vi33-vvi8. https://doi.org/10.1093/annonc/ mdt353\n\nCan MRI help assess aggressiveness of endometrial cancer?. M Ahmed, J F Al-Khafaji, C A Class, 10.1016/j.crad.2018.05.002Clin Radiol. 73Ahmed M, Al-Khafaji JF, Class CA et al (2018) Can MRI help assess aggressiveness of endometrial cancer? Clin Radiol 73: 833.e11-833.e18. https://doi.org/10.1016/j.crad.2018.05.002\n\nThe added role of MR imaging in treatment stratification of patients with gynecologic malignancies: what the radiologist needs to know. E Sala, A G Rockall, S J Freeman, Radiology. 266Sala E, Rockall AG, Freeman SJ et al (2013) The added role of MR imaging in treatment stratification of patients with gynecologic ma- lignancies: what the radiologist needs to know. Radiology 266: 717-740\n\nMagnetic resonance imaging radiomics in categorizing ovarian masses and predicting clinical outcome: a preliminary study. H Zhang, Y Mao, X Chen, 10.1007/s00330-019-06124-9Eur Radiol. 29Zhang H, Mao Y, Chen X et al (2019) Magnetic resonance imaging radiomics in categorizing ovarian masses and predicting clinical outcome: a preliminary study. Eur Radiol 29:3358-3371. https:// doi.org/10.1007/s00330-019-06124-9\n\nPreoperative magnetic resonance volumetry in predicting myometrial invasion, lymphovascular space invasion, and tumor grade: is it valuable in International Federation of Gynecology and Obstetrics Stage I Endometrial Cancer?. H Sahin, F C Sarioglu, M Bagci, T Karadeniz, H Uluer, M Sanci, 10.1097/IGC.0000000000001208Int J Gynecol Cancer. 28Sahin H, Sarioglu FC, Bagci M, Karadeniz T, Uluer H, Sanci M. (2018) Preoperative magnetic resonance volumetry in predicting myometrial invasion, lymphovascular space invasion, and tumor grade: is it valuable in International Federation of Gynecology and Obstetrics Stage I Endometrial Cancer? Int J Gynecol Cancer 28:666-674. https://doi.org/10.1097/IGC.0000000000001208\n\nPredicting parametrial invasion in cervical carcinoma (stages IB1, IB2, and IIA): diagnostic accuracy of T2-weighted imaging combined with DWI at 3 T. J R Qu, L Qin, X Li, 10.2214/AJR.17.18104Am J Roentgenol. 210Qu JR, Qin L, Li X et al (2018) Predicting parametrial invasion in cervical carcinoma (stages IB1, IB2, and IIA): diagnostic accuracy of T2-weighted imaging combined with DWI at 3 T. Am J Roentgenol 210:677-684. https://doi.org/10.2214/AJR.17.18104\n\nPreoperative tumor size is associated with deep myometrial invasion and lymph node metastases and is a negative prognostic indicator for patients with endometrial carcinoma. K Nakamura, K Nakayama, N Ishikawa, 10.18632/oncotarget.25248Oncotarget. 9Nakamura K, Nakayama K, Ishikawa N et al (2018) Preoperative tumor size is associated with deep myometrial invasion and lymph node metastases and is a negative prognostic indicator for patients with endometrial carcinoma. Oncotarget 9:23164-23172. https:// doi.org/10.18632/oncotarget.25248\n\nEndometrial cancer: combined MR volumetry and diffusion-weighted imaging for assessment of myometrial and lymphovascular invasion and tumor grade. S Nougaret, C Reinhold, S S Alsharif, 10.1148/radiol.15141212Radiology. 276Nougaret S, Reinhold C, Alsharif SS et al (2015) Endometrial can- cer: combined MR volumetry and diffusion-weighted imaging for assessment of myometrial and lymphovascular invasion and tumor grade. Radiology 276:797-808. https://doi.org/10.1148/radiol. 15141212\n\nEndometrial carcinoma: MR imaging-based texture model for preoperative risk stratification -a preliminary analysis1. Y Ueno, B Forghani, R Forghani, 10.1148/radiol.2017161950Radiology. 284Ueno Y, Forghani B, Forghani R et al (2017) Endometrial carcino- ma: MR imaging-based texture model for preoperative risk stratifi- cation -a preliminary analysis1. Radiology 284:748-757. https:// doi.org/10.1148/radiol.2017161950\n\nPreoperative MRI and intraoperative frozen section diagnosis of myometrial invasion in patients with endometrial cancer. T Tanaka, Y Terai, Y J Ono, 10.1097/IGC.0000000000000470Int J Gynecol Cancer. 25Tanaka T, Terai Y, Ono YJ et al (2015) Preoperative MRI and intraoperative frozen section diagnosis of myometrial invasion in patients with endometrial cancer. Int J Gynecol Cancer 25:879- 883. https://doi.org/10.1097/IGC.0000000000000470\n\nA survey on deep learning in medical image analysis. G Litjens, T Kooi, B E Bejnordi, 10.1016/j.media.2017.07.005Med Image Anal. 42Litjens G, Kooi T, Bejnordi BE et al (2017) A survey on deep learning in medical image analysis. Med Image Anal 42:60-88. https://doi.org/10.1016/j.media.2017.07.005\n\nDeep learning in medical image analysis. D Shen, G Wu, H-I Suk, 10.1146/annurev-bioeng-071516-044442Annu Rev Biomed Eng. 19Shen D, Wu G, Suk H-I (2017) Deep learning in medical image analysis. Annu Rev Biomed Eng 19:221-248. https://doi.org/10. 1146/annurev-bioeng-071516-044442\n\nDeep learning to improve breast cancer detection on screening mammography. L Shen, L R Margolies, J H Rothstein, E Fluder, R Mcbride, W Sieh, 10.1038/s41598-019-48995-4Sci Rep. 9Shen L, Margolies LR, Rothstein JH, Fluder E, McBride R, Sieh W (2019) Deep learning to improve breast cancer detection on screen- ing mammography. Sci Rep 9. https://doi.org/10.1038/s41598-019- 48995-4\n\nClassification of tumor epithelium and stroma by exploiting image features learned by deep convolutional neural networks. Y Du, R Zhang, A Zargari, 10.1007/s10439-018-2095-6Ann Biomed Eng. 46Du Y, Zhang R, Zargari A et al (2018) Classification of tumor epithelium and stroma by exploiting image features learned by deep convolutional neural networks. Ann Biomed Eng 46:1988-1999. https://doi.org/10.1007/s10439-018-2095-6\n\nDeep learning provides a new computed tomography-based prognostic biomarker for recurrence prediction in high-grade serous ovarian cancer. Radiother Oncol 171-177. S Wang, Z Liu, Y Rong, 10.1016/j.radonc.2018.10.019Wang S, Liu Z, Rong Y et al (2016) Deep learning provides a new computed tomography-based prognostic biomarker for recurrence prediction in high-grade serous ovarian cancer. Radiother Oncol 171-177. https://doi.org/10.1016/j.radonc.2018.10.019\n\nComputer-aided diagnosis of prostate cancer using a deep convolutional neural network from multiparametric MRI. Y Song, Y D Zhang, X Yan, 10.1002/jmri.26047J Magn Reson Imaging. 48Song Y, Zhang YD, Yan X et al (2018) Computer-aided diagnosis of prostate cancer using a deep convolutional neural network from multiparametric MRI. J Magn Reson Imaging 48:1570-1577. https://doi.org/10.1002/jmri.26047\n\nDeep learning for medical image processing: overview, challenges and future. M I Razzak, S Naz, A Zaib, Classification in BioApps. Dey N, Ashour A, Borra SChamSpringer26Razzak MI, Naz S, Zaib A (2017) Deep learning for medical image processing: overview, challenges and future. in: Dey N, Ashour A, Borra S (eds) Classification in BioApps. Lecture Notes in Computational Vision and Biomechanics, vol 26. Springer, Cham\n\nTraining cost-sensitive neural networks with methods addressing the class imbalance problem. Z H Zhou, X Y Liu, 10.1109/TKDE.2006.17IEEE Trans Knowl Data Eng. 18Zhou ZH, Liu XY (2006) Training cost-sensitive neural networks with methods addressing the class imbalance problem. IEEE Trans Knowl Data Eng 18:63-77. https://doi.org/10.1109/TKDE.2006.17\n\n. J Redmon, A Farhadi, C Ap, 10.1111/j.1753-4887.1978.tb03704.xNutr Rev. 36Redmon J, Farhadi A, Ap C (2018) YOLOv3. Nutr Rev 36:346- 348. https://doi.org/10.1111/j.1753-4887.1978.tb03704.x\n\nImageNet large scale visual recognition challenge. O Russakovsky, J Deng, H Su, 10.1007/s11263-015-0816-yInt J Comput Vis. 115Russakovsky O, Deng J, Su H et al (2015) ImageNet large scale visual recognition challenge. Int J Comput Vis 115:211-252. https://doi.org/10.1007/s11263-015-0816-y\n\nK He, X Zhang, S Ren, J Sun, 10.3389/fpsyg.2013.00124arXiv:151203385v1 7:171-180Deep residual learning for image recognition. arXiv preprintHe K, Zhang X, Ren S, Sun J (2015) Deep residual learning for image recognition. arXiv preprint arXiv:151203385v1 7:171-180. https://doi.org/10.3389/fpsyg.2013.00124\n\nThe relationship between precisionrecall and ROC curves. J Davis, M Goadrich, 10.1145/1143844.1143874Proceedings of the 23rd International Conference on Machine Learning. the 23rd International Conference on Machine Learning148Davis J, Goadrich M (2006) The relationship between precision- recall and ROC curves. Proceedings of the 23rd International Conference on Machine Learning 148:233-240. https://doi.org/ 10.1145/1143844.1143874\n\nA novel prediction method for lymph node involvement in endometrial cancer: machi learning. E G\u00fcnakan, S Atan, A N Haberal, \u0130 A K\u00fc\u00e7\u00fcky\u0131ld\u0131z, E G\u00f6k\u00e7e, A Ayhan, 10.1136/ijgc-2018-000033Int J Gynecol Cancer. 29G\u00fcnakan E, Atan S, Haberal AN, K\u00fc\u00e7\u00fcky\u0131ld\u0131z \u0130A, G\u00f6k\u00e7e E, Ayhan A (2019) A novel prediction method for lymph node involvement in endometrial cancer: machi learning. Int J Gynecol Cancer 29: 320-324. https://doi.org/10.1136/ijgc-2018-000033\n\nA new classification of benign, premalignant, and malignant endometrial tissues using machine learning applied to 1413 candidate variables. M J Downing, D J Papke, S Tyekucheva, G L Mutter, 10.1097/PGP.0000000000000615Int J Gynecol Pathol. Downing MJ, Papke DJ, Tyekucheva S, Mutter GL (2019) A new classification of benign, premalignant, and malignant endometrial tissues using machine learning applied to 1413 candidate variables. Int J Gynecol Pathol. https://doi.org/10.1097/PGP. 0000000000000615\n\nDeep learning with convolutional neural network for differentiation of liver masses at dynamic contrast-enhanced CT: a preliminary study. K Yasaka, H Akai, O Abe, S Kiryu, 10.1148/radiol.2017170706Radiology. 286Yasaka K, Akai H, Abe O, Kiryu S (2018) Deep learning with convolutional neural network for differentiation of liver masses at dynamic contrast-enhanced CT: a preliminary study. Radiology 286:887-896. https://doi.org/10.1148/radiol.2017170706\n\nDetecting and classifying lesions in mammograms with deep learning. D Ribli, A Horv\u00e1th, Z Unger, P Pollner, I Csabai, 10.1038/s41598-018-22437-zSci Rep. 84165Ribli D, Horv\u00e1th A, Unger Z, Pollner P, Csabai I (2018) Detecting and classifying lesions in mammograms with deep learning. Sci Rep 8:4165. https://doi.org/10.1038/s41598-018-22437-z\n\nEfficient framework for identifying, locating, detecting and classifying MRI brain tumor in MRI images. T Pandiselvi, R Maheswaran, 10.1007/s10916-019-1253-1J Med Syst. 43189Pandiselvi T, Maheswaran R (2019) Efficient framework for iden- tifying, locating, detecting and classifying MRI brain tumor in MRI images. J Med Syst 43:189. https://doi.org/10.1007/s10916-019- 1253-1\n\nPublisher's note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations. Publisher's note Springer Nature remains neutral with regard to jurisdic- tional claims in published maps and institutional affiliations.\n", "annotations": {"author": "[{\"start\":\"182\",\"end\":\"309\"},{\"start\":\"310\",\"end\":\"431\"},{\"start\":\"432\",\"end\":\"557\"},{\"start\":\"558\",\"end\":\"706\"},{\"start\":\"707\",\"end\":\"830\"},{\"start\":\"831\",\"end\":\"953\"},{\"start\":\"954\",\"end\":\"1134\"},{\"start\":\"1135\",\"end\":\"1260\"},{\"start\":\"1261\",\"end\":\"1383\"},{\"start\":\"1384\",\"end\":\"1527\"},{\"start\":\"1528\",\"end\":\"1578\"}]", "publisher": null, "author_last_name": "[{\"start\":\"190\",\"end\":\"194\"},{\"start\":\"315\",\"end\":\"319\"},{\"start\":\"439\",\"end\":\"443\"},{\"start\":\"565\",\"end\":\"569\"},{\"start\":\"712\",\"end\":\"716\"},{\"start\":\"839\",\"end\":\"841\"},{\"start\":\"962\",\"end\":\"965\"},{\"start\":\"1141\",\"end\":\"1146\"},{\"start\":\"1267\",\"end\":\"1271\"},{\"start\":\"1387\",\"end\":\"1392\"}]", "author_first_name": "[{\"start\":\"182\",\"end\":\"189\"},{\"start\":\"310\",\"end\":\"314\"},{\"start\":\"432\",\"end\":\"438\"},{\"start\":\"558\",\"end\":\"564\"},{\"start\":\"707\",\"end\":\"711\"},{\"start\":\"831\",\"end\":\"838\"},{\"start\":\"954\",\"end\":\"961\"},{\"start\":\"1135\",\"end\":\"1140\"},{\"start\":\"1261\",\"end\":\"1266\"},{\"start\":\"1384\",\"end\":\"1386\"}]", "author_affiliation": "[{\"start\":\"196\",\"end\":\"308\"},{\"start\":\"321\",\"end\":\"430\"},{\"start\":\"445\",\"end\":\"556\"},{\"start\":\"593\",\"end\":\"705\"},{\"start\":\"718\",\"end\":\"829\"},{\"start\":\"843\",\"end\":\"952\"},{\"start\":\"967\",\"end\":\"1133\"},{\"start\":\"1148\",\"end\":\"1259\"},{\"start\":\"1273\",\"end\":\"1382\"},{\"start\":\"1415\",\"end\":\"1526\"},{\"start\":\"1529\",\"end\":\"1577\"}]", "title": "[{\"start\":\"1\",\"end\":\"179\"},{\"start\":\"1579\",\"end\":\"1757\"}]", "venue": null, "abstract": "[{\"start\":\"2292\",\"end\":\"4440\"}]", "bib_ref": "[{\"start\":\"4522\",\"end\":\"4525\",\"attributes\":{\"ref_id\":\"b0\"}},{\"start\":\"4597\",\"end\":\"4600\",\"attributes\":{\"ref_id\":\"b1\"}},{\"start\":\"4810\",\"end\":\"4813\",\"attributes\":{\"ref_id\":\"b2\"}},{\"start\":\"4813\",\"end\":\"4815\",\"attributes\":{\"ref_id\":\"b3\"}},{\"start\":\"4989\",\"end\":\"4992\",\"attributes\":{\"ref_id\":\"b5\"}},{\"start\":\"5105\",\"end\":\"5108\",\"attributes\":{\"ref_id\":\"b6\"}},{\"start\":\"5253\",\"end\":\"5256\",\"attributes\":{\"ref_id\":\"b7\"}},{\"start\":\"5256\",\"end\":\"5259\",\"attributes\":{\"ref_id\":\"b8\"}},{\"start\":\"5259\",\"end\":\"5262\",\"attributes\":{\"ref_id\":\"b9\"}},{\"start\":\"5613\",\"end\":\"5617\",\"attributes\":{\"ref_id\":\"b10\"}},{\"start\":\"5617\",\"end\":\"5621\",\"attributes\":{\"ref_id\":\"b11\"}},{\"start\":\"5621\",\"end\":\"5625\",\"attributes\":{\"ref_id\":\"b12\"}},{\"start\":\"5625\",\"end\":\"5629\",\"attributes\":{\"ref_id\":\"b13\"}},{\"start\":\"5795\",\"end\":\"5799\",\"attributes\":{\"ref_id\":\"b13\"}},{\"start\":\"6153\",\"end\":\"6157\",\"attributes\":{\"ref_id\":\"b14\"}},{\"start\":\"6656\",\"end\":\"6660\",\"attributes\":{\"ref_id\":\"b15\"}},{\"start\":\"6844\",\"end\":\"6848\",\"attributes\":{\"ref_id\":\"b16\"}},{\"start\":\"6848\",\"end\":\"6852\",\"attributes\":{\"ref_id\":\"b17\"}},{\"start\":\"6852\",\"end\":\"6856\",\"attributes\":{\"ref_id\":\"b18\"}},{\"start\":\"6856\",\"end\":\"6860\",\"attributes\":{\"ref_id\":\"b19\"}},{\"start\":\"6860\",\"end\":\"6864\",\"attributes\":{\"ref_id\":\"b20\"}},{\"start\":\"6864\",\"end\":\"6868\",\"attributes\":{\"ref_id\":\"b21\"}},{\"start\":\"6868\",\"end\":\"6872\",\"attributes\":{\"ref_id\":\"b22\"}},{\"start\":\"7987\",\"end\":\"7990\",\"attributes\":{\"ref_id\":\"b1\"}},{\"start\":\"12089\",\"end\":\"12093\",\"attributes\":{\"ref_id\":\"b23\"}},{\"start\":\"12702\",\"end\":\"12706\",\"attributes\":{\"ref_id\":\"b24\"}},{\"start\":\"12843\",\"end\":\"12847\",\"attributes\":{\"ref_id\":\"b25\"}},{\"start\":\"13014\",\"end\":\"13018\",\"attributes\":{\"ref_id\":\"b26\"}},{\"start\":\"14671\",\"end\":\"14675\",\"attributes\":{\"ref_id\":\"b27\"}},{\"start\":\"17127\",\"end\":\"17131\",\"attributes\":{\"ref_id\":\"b28\"}},{\"start\":\"17746\",\"end\":\"17750\",\"attributes\":{\"ref_id\":\"b29\"}},{\"start\":\"17790\",\"end\":\"17794\",\"attributes\":{\"ref_id\":\"b14\"}},{\"start\":\"17991\",\"end\":\"17995\",\"attributes\":{\"ref_id\":\"b30\"}},{\"start\":\"18499\",\"end\":\"18503\",\"attributes\":{\"ref_id\":\"b31\"}},{\"start\":\"18503\",\"end\":\"18506\",\"attributes\":{\"ref_id\":\"b32\"}}]", "figure": "[{\"start\":\"20958\",\"end\":\"21157\",\"attributes\":{\"id\":\"fig_0\"}},{\"start\":\"21158\",\"end\":\"21659\",\"attributes\":{\"id\":\"fig_1\"}},{\"start\":\"21660\",\"end\":\"21970\",\"attributes\":{\"id\":\"fig_2\"}},{\"start\":\"21971\",\"end\":\"22076\",\"attributes\":{\"id\":\"fig_3\"}},{\"start\":\"22077\",\"end\":\"23342\",\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"}},{\"start\":\"23343\",\"end\":\"23358\",\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"}},{\"start\":\"23359\",\"end\":\"24028\",\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"}},{\"start\":\"24029\",\"end\":\"25194\",\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"}},{\"start\":\"25195\",\"end\":\"26330\",\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"}}]", "paragraph": "[{\"start\":\"4456\",\"end\":\"6661\"},{\"start\":\"6663\",\"end\":\"7354\"},{\"start\":\"7390\",\"end\":\"8798\"},{\"start\":\"8836\",\"end\":\"10675\"},{\"start\":\"10699\",\"end\":\"11209\"},{\"start\":\"11245\",\"end\":\"12397\"},{\"start\":\"12426\",\"end\":\"13720\"},{\"start\":\"13762\",\"end\":\"14296\"},{\"start\":\"14369\",\"end\":\"14696\"},{\"start\":\"14779\",\"end\":\"15282\"},{\"start\":\"15362\",\"end\":\"16523\"},{\"start\":\"16538\",\"end\":\"16948\"},{\"start\":\"16950\",\"end\":\"18216\"},{\"start\":\"18218\",\"end\":\"19243\"},{\"start\":\"19245\",\"end\":\"20321\"},{\"start\":\"20323\",\"end\":\"20957\"}]", "formula": null, "table_ref": "[{\"start\":\"8788\",\"end\":\"8797\",\"attributes\":{\"ref_id\":\"tab_1\"}},{\"start\":\"9709\",\"end\":\"9730\",\"attributes\":{\"ref_id\":\"tab_1\"}},{\"start\":\"11746\",\"end\":\"11754\",\"attributes\":{\"ref_id\":\"tab_1\"}},{\"start\":\"15093\",\"end\":\"15100\",\"attributes\":{\"ref_id\":\"tab_3\"}},{\"start\":\"15272\",\"end\":\"15281\",\"attributes\":{\"ref_id\":\"tab_4\"}},{\"start\":\"16054\",\"end\":\"16061\",\"attributes\":{\"ref_id\":\"tab_6\"}}]", "section_header": "[{\"start\":\"4442\",\"end\":\"4454\"},{\"start\":\"7357\",\"end\":\"7377\"},{\"start\":\"7380\",\"end\":\"7388\"},{\"start\":\"8801\",\"end\":\"8834\"},{\"start\":\"10678\",\"end\":\"10697\"},{\"start\":\"11212\",\"end\":\"11243\"},{\"start\":\"12400\",\"end\":\"12424\"},{\"start\":\"13723\",\"end\":\"13747\"},{\"start\":\"13750\",\"end\":\"13760\"},{\"start\":\"14299\",\"end\":\"14306\"},{\"start\":\"14309\",\"end\":\"14367\"},{\"start\":\"14699\",\"end\":\"14777\"},{\"start\":\"15285\",\"end\":\"15360\"},{\"start\":\"16526\",\"end\":\"16536\"},{\"start\":\"20959\",\"end\":\"20965\"},{\"start\":\"21159\",\"end\":\"21174\"},{\"start\":\"21661\",\"end\":\"21667\"},{\"start\":\"22078\",\"end\":\"22094\"},{\"start\":\"23344\",\"end\":\"23353\"},{\"start\":\"23360\",\"end\":\"23367\"},{\"start\":\"24030\",\"end\":\"24037\"},{\"start\":\"25196\",\"end\":\"25203\"}]", "table": "[{\"start\":\"22096\",\"end\":\"23342\"},{\"start\":\"23355\",\"end\":\"23358\"},{\"start\":\"23561\",\"end\":\"24028\"},{\"start\":\"25015\",\"end\":\"25194\"},{\"start\":\"25545\",\"end\":\"26330\"}]", "figure_caption": "[{\"start\":\"20967\",\"end\":\"21157\"},{\"start\":\"21178\",\"end\":\"21659\"},{\"start\":\"21669\",\"end\":\"21970\"},{\"start\":\"21973\",\"end\":\"22076\"},{\"start\":\"23369\",\"end\":\"23561\"},{\"start\":\"24039\",\"end\":\"25015\"},{\"start\":\"25205\",\"end\":\"25545\"}]", "figure_ref": "[{\"start\":\"11025\",\"end\":\"11033\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"12522\",\"end\":\"12530\"},{\"start\":\"13241\",\"end\":\"13248\"},{\"start\":\"13634\",\"end\":\"13642\"},{\"start\":\"14441\",\"end\":\"14447\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"14689\",\"end\":\"14695\"},{\"start\":\"14903\",\"end\":\"14910\",\"attributes\":{\"ref_id\":\"fig_2\"}},{\"start\":\"20535\",\"end\":\"20541\"}]", "bib_author_first_name": "[{\"start\":\"26957\",\"end\":\"26958\"},{\"start\":\"26967\",\"end\":\"26968\"},{\"start\":\"26976\",\"end\":\"26977\"},{\"start\":\"26990\",\"end\":\"26991\"},{\"start\":\"27004\",\"end\":\"27005\"},{\"start\":\"27226\",\"end\":\"27227\"},{\"start\":\"27228\",\"end\":\"27229\"},{\"start\":\"27238\",\"end\":\"27239\"},{\"start\":\"27240\",\"end\":\"27241\"},{\"start\":\"27250\",\"end\":\"27251\"},{\"start\":\"27521\",\"end\":\"27522\"},{\"start\":\"27533\",\"end\":\"27534\"},{\"start\":\"27542\",\"end\":\"27543\"},{\"start\":\"27879\",\"end\":\"27880\"},{\"start\":\"27889\",\"end\":\"27890\"},{\"start\":\"27899\",\"end\":\"27900\"},{\"start\":\"27911\",\"end\":\"27912\"},{\"start\":\"27926\",\"end\":\"27927\"},{\"start\":\"27935\",\"end\":\"27936\"},{\"start\":\"28286\",\"end\":\"28287\"},{\"start\":\"28295\",\"end\":\"28296\"},{\"start\":\"28297\",\"end\":\"28298\"},{\"start\":\"28306\",\"end\":\"28307\"},{\"start\":\"28316\",\"end\":\"28317\"},{\"start\":\"28318\",\"end\":\"28319\"},{\"start\":\"28567\",\"end\":\"28568\"},{\"start\":\"28578\",\"end\":\"28579\"},{\"start\":\"28587\",\"end\":\"28588\"},{\"start\":\"28894\",\"end\":\"28895\"},{\"start\":\"28903\",\"end\":\"28904\"},{\"start\":\"28905\",\"end\":\"28906\"},{\"start\":\"28919\",\"end\":\"28920\"},{\"start\":\"28921\",\"end\":\"28922\"},{\"start\":\"29288\",\"end\":\"29289\"},{\"start\":\"29296\",\"end\":\"29297\"},{\"start\":\"29298\",\"end\":\"29299\"},{\"start\":\"29309\",\"end\":\"29310\"},{\"start\":\"29311\",\"end\":\"29312\"},{\"start\":\"29664\",\"end\":\"29665\"},{\"start\":\"29673\",\"end\":\"29674\"},{\"start\":\"29680\",\"end\":\"29681\"},{\"start\":\"30182\",\"end\":\"30183\"},{\"start\":\"30191\",\"end\":\"30192\"},{\"start\":\"30193\",\"end\":\"30194\"},{\"start\":\"30205\",\"end\":\"30206\"},{\"start\":\"30214\",\"end\":\"30215\"},{\"start\":\"30227\",\"end\":\"30228\"},{\"start\":\"30236\",\"end\":\"30237\"},{\"start\":\"30821\",\"end\":\"30822\"},{\"start\":\"30823\",\"end\":\"30824\"},{\"start\":\"30829\",\"end\":\"30830\"},{\"start\":\"30836\",\"end\":\"30837\"},{\"start\":\"31306\",\"end\":\"31307\"},{\"start\":\"31318\",\"end\":\"31319\"},{\"start\":\"31330\",\"end\":\"31331\"},{\"start\":\"31819\",\"end\":\"31820\"},{\"start\":\"31831\",\"end\":\"31832\"},{\"start\":\"31843\",\"end\":\"31844\"},{\"start\":\"31845\",\"end\":\"31846\"},{\"start\":\"32274\",\"end\":\"32275\"},{\"start\":\"32282\",\"end\":\"32283\"},{\"start\":\"32294\",\"end\":\"32295\"},{\"start\":\"32698\",\"end\":\"32699\"},{\"start\":\"32708\",\"end\":\"32709\"},{\"start\":\"32717\",\"end\":\"32718\"},{\"start\":\"32719\",\"end\":\"32720\"},{\"start\":\"33071\",\"end\":\"33072\"},{\"start\":\"33082\",\"end\":\"33083\"},{\"start\":\"33090\",\"end\":\"33091\"},{\"start\":\"33092\",\"end\":\"33093\"},{\"start\":\"33357\",\"end\":\"33358\"},{\"start\":\"33365\",\"end\":\"33366\"},{\"start\":\"33371\",\"end\":\"33374\"},{\"start\":\"33671\",\"end\":\"33672\"},{\"start\":\"33679\",\"end\":\"33680\"},{\"start\":\"33681\",\"end\":\"33682\"},{\"start\":\"33694\",\"end\":\"33695\"},{\"start\":\"33696\",\"end\":\"33697\"},{\"start\":\"33709\",\"end\":\"33710\"},{\"start\":\"33719\",\"end\":\"33720\"},{\"start\":\"33730\",\"end\":\"33731\"},{\"start\":\"34100\",\"end\":\"34101\"},{\"start\":\"34106\",\"end\":\"34107\"},{\"start\":\"34115\",\"end\":\"34116\"},{\"start\":\"34565\",\"end\":\"34566\"},{\"start\":\"34573\",\"end\":\"34574\"},{\"start\":\"34580\",\"end\":\"34581\"},{\"start\":\"34973\",\"end\":\"34974\"},{\"start\":\"34981\",\"end\":\"34982\"},{\"start\":\"34983\",\"end\":\"34984\"},{\"start\":\"34992\",\"end\":\"34993\"},{\"start\":\"35338\",\"end\":\"35339\"},{\"start\":\"35340\",\"end\":\"35341\"},{\"start\":\"35350\",\"end\":\"35351\"},{\"start\":\"35357\",\"end\":\"35358\"},{\"start\":\"35774\",\"end\":\"35775\"},{\"start\":\"35776\",\"end\":\"35777\"},{\"start\":\"35784\",\"end\":\"35785\"},{\"start\":\"35786\",\"end\":\"35787\"},{\"start\":\"36034\",\"end\":\"36035\"},{\"start\":\"36044\",\"end\":\"36045\"},{\"start\":\"36055\",\"end\":\"36056\"},{\"start\":\"36273\",\"end\":\"36274\"},{\"start\":\"36288\",\"end\":\"36289\"},{\"start\":\"36296\",\"end\":\"36297\"},{\"start\":\"36513\",\"end\":\"36514\"},{\"start\":\"36519\",\"end\":\"36520\"},{\"start\":\"36528\",\"end\":\"36529\"},{\"start\":\"36535\",\"end\":\"36536\"},{\"start\":\"36877\",\"end\":\"36878\"},{\"start\":\"36886\",\"end\":\"36887\"},{\"start\":\"37349\",\"end\":\"37350\"},{\"start\":\"37360\",\"end\":\"37361\"},{\"start\":\"37368\",\"end\":\"37369\"},{\"start\":\"37370\",\"end\":\"37371\"},{\"start\":\"37381\",\"end\":\"37382\"},{\"start\":\"37383\",\"end\":\"37384\"},{\"start\":\"37398\",\"end\":\"37399\"},{\"start\":\"37407\",\"end\":\"37408\"},{\"start\":\"37843\",\"end\":\"37844\"},{\"start\":\"37845\",\"end\":\"37846\"},{\"start\":\"37856\",\"end\":\"37857\"},{\"start\":\"37858\",\"end\":\"37859\"},{\"start\":\"37867\",\"end\":\"37868\"},{\"start\":\"37881\",\"end\":\"37882\"},{\"start\":\"37883\",\"end\":\"37884\"},{\"start\":\"38343\",\"end\":\"38344\"},{\"start\":\"38353\",\"end\":\"38354\"},{\"start\":\"38361\",\"end\":\"38362\"},{\"start\":\"38368\",\"end\":\"38369\"},{\"start\":\"38728\",\"end\":\"38729\"},{\"start\":\"38737\",\"end\":\"38738\"},{\"start\":\"38748\",\"end\":\"38749\"},{\"start\":\"38757\",\"end\":\"38758\"},{\"start\":\"38768\",\"end\":\"38769\"},{\"start\":\"39106\",\"end\":\"39107\"},{\"start\":\"39120\",\"end\":\"39121\"}]", "bib_author_last_name": "[{\"start\":\"26959\",\"end\":\"26965\"},{\"start\":\"26969\",\"end\":\"26974\"},{\"start\":\"26978\",\"end\":\"26988\"},{\"start\":\"26992\",\"end\":\"27002\"},{\"start\":\"27006\",\"end\":\"27011\"},{\"start\":\"27230\",\"end\":\"27236\"},{\"start\":\"27242\",\"end\":\"27248\"},{\"start\":\"27252\",\"end\":\"27257\"},{\"start\":\"27523\",\"end\":\"27531\"},{\"start\":\"27535\",\"end\":\"27540\"},{\"start\":\"27544\",\"end\":\"27548\"},{\"start\":\"27881\",\"end\":\"27887\"},{\"start\":\"27891\",\"end\":\"27897\"},{\"start\":\"27901\",\"end\":\"27909\"},{\"start\":\"27913\",\"end\":\"27924\"},{\"start\":\"27928\",\"end\":\"27933\"},{\"start\":\"27937\",\"end\":\"27954\"},{\"start\":\"28288\",\"end\":\"28293\"},{\"start\":\"28299\",\"end\":\"28304\"},{\"start\":\"28308\",\"end\":\"28314\"},{\"start\":\"28320\",\"end\":\"28330\"},{\"start\":\"28569\",\"end\":\"28576\"},{\"start\":\"28580\",\"end\":\"28585\"},{\"start\":\"28589\",\"end\":\"28596\"},{\"start\":\"28896\",\"end\":\"28901\"},{\"start\":\"28907\",\"end\":\"28917\"},{\"start\":\"28923\",\"end\":\"28928\"},{\"start\":\"29290\",\"end\":\"29294\"},{\"start\":\"29300\",\"end\":\"29307\"},{\"start\":\"29313\",\"end\":\"29320\"},{\"start\":\"29666\",\"end\":\"29671\"},{\"start\":\"29675\",\"end\":\"29678\"},{\"start\":\"29682\",\"end\":\"29686\"},{\"start\":\"30184\",\"end\":\"30189\"},{\"start\":\"30195\",\"end\":\"30203\"},{\"start\":\"30207\",\"end\":\"30212\"},{\"start\":\"30216\",\"end\":\"30225\"},{\"start\":\"30229\",\"end\":\"30234\"},{\"start\":\"30238\",\"end\":\"30243\"},{\"start\":\"30825\",\"end\":\"30827\"},{\"start\":\"30831\",\"end\":\"30834\"},{\"start\":\"30838\",\"end\":\"30840\"},{\"start\":\"31308\",\"end\":\"31316\"},{\"start\":\"31320\",\"end\":\"31328\"},{\"start\":\"31332\",\"end\":\"31340\"},{\"start\":\"31821\",\"end\":\"31829\"},{\"start\":\"31833\",\"end\":\"31841\"},{\"start\":\"31847\",\"end\":\"31855\"},{\"start\":\"32276\",\"end\":\"32280\"},{\"start\":\"32284\",\"end\":\"32292\"},{\"start\":\"32296\",\"end\":\"32304\"},{\"start\":\"32700\",\"end\":\"32706\"},{\"start\":\"32710\",\"end\":\"32715\"},{\"start\":\"32721\",\"end\":\"32724\"},{\"start\":\"33073\",\"end\":\"33080\"},{\"start\":\"33084\",\"end\":\"33088\"},{\"start\":\"33094\",\"end\":\"33102\"},{\"start\":\"33359\",\"end\":\"33363\"},{\"start\":\"33367\",\"end\":\"33369\"},{\"start\":\"33375\",\"end\":\"33378\"},{\"start\":\"33673\",\"end\":\"33677\"},{\"start\":\"33683\",\"end\":\"33692\"},{\"start\":\"33698\",\"end\":\"33707\"},{\"start\":\"33711\",\"end\":\"33717\"},{\"start\":\"33721\",\"end\":\"33728\"},{\"start\":\"33732\",\"end\":\"33736\"},{\"start\":\"34102\",\"end\":\"34104\"},{\"start\":\"34108\",\"end\":\"34113\"},{\"start\":\"34117\",\"end\":\"34124\"},{\"start\":\"34567\",\"end\":\"34571\"},{\"start\":\"34575\",\"end\":\"34578\"},{\"start\":\"34582\",\"end\":\"34586\"},{\"start\":\"34975\",\"end\":\"34979\"},{\"start\":\"34985\",\"end\":\"34990\"},{\"start\":\"34994\",\"end\":\"34997\"},{\"start\":\"35342\",\"end\":\"35348\"},{\"start\":\"35352\",\"end\":\"35355\"},{\"start\":\"35359\",\"end\":\"35363\"},{\"start\":\"35778\",\"end\":\"35782\"},{\"start\":\"35788\",\"end\":\"35791\"},{\"start\":\"36036\",\"end\":\"36042\"},{\"start\":\"36046\",\"end\":\"36053\"},{\"start\":\"36057\",\"end\":\"36059\"},{\"start\":\"36275\",\"end\":\"36286\"},{\"start\":\"36290\",\"end\":\"36294\"},{\"start\":\"36298\",\"end\":\"36300\"},{\"start\":\"36515\",\"end\":\"36517\"},{\"start\":\"36521\",\"end\":\"36526\"},{\"start\":\"36530\",\"end\":\"36533\"},{\"start\":\"36537\",\"end\":\"36540\"},{\"start\":\"36879\",\"end\":\"36884\"},{\"start\":\"36888\",\"end\":\"36896\"},{\"start\":\"37351\",\"end\":\"37358\"},{\"start\":\"37362\",\"end\":\"37366\"},{\"start\":\"37372\",\"end\":\"37379\"},{\"start\":\"37385\",\"end\":\"37396\"},{\"start\":\"37400\",\"end\":\"37405\"},{\"start\":\"37409\",\"end\":\"37414\"},{\"start\":\"37847\",\"end\":\"37854\"},{\"start\":\"37860\",\"end\":\"37865\"},{\"start\":\"37869\",\"end\":\"37879\"},{\"start\":\"37885\",\"end\":\"37891\"},{\"start\":\"38345\",\"end\":\"38351\"},{\"start\":\"38355\",\"end\":\"38359\"},{\"start\":\"38363\",\"end\":\"38366\"},{\"start\":\"38370\",\"end\":\"38375\"},{\"start\":\"38730\",\"end\":\"38735\"},{\"start\":\"38739\",\"end\":\"38746\"},{\"start\":\"38750\",\"end\":\"38755\"},{\"start\":\"38759\",\"end\":\"38766\"},{\"start\":\"38770\",\"end\":\"38776\"},{\"start\":\"39108\",\"end\":\"39118\"},{\"start\":\"39122\",\"end\":\"39132\"}]", "bib_entry": "[{\"start\":\"26937\",\"end\":\"27205\",\"attributes\":{\"matched_paper_id\":\"9896914\",\"id\":\"b0\",\"doi\":\"10.1016/S0140-6736(15)00130-0\"}},{\"start\":\"27207\",\"end\":\"27419\",\"attributes\":{\"matched_paper_id\":\"1514000\",\"id\":\"b1\",\"doi\":\"10.3322/caac.21551\"}},{\"start\":\"27421\",\"end\":\"27795\",\"attributes\":{\"matched_paper_id\":\"49667337\",\"id\":\"b2\",\"doi\":\"10.1007/s00330-018-5515-y\"}},{\"start\":\"27797\",\"end\":\"28120\",\"attributes\":{\"id\":\"b3\"}},{\"start\":\"28122\",\"end\":\"28256\",\"attributes\":{\"id\":\"b4\",\"doi\":\"10.1016/j.diii.2018.01.010\"}},{\"start\":\"28258\",\"end\":\"28471\",\"attributes\":{\"matched_paper_id\":\"5209785\",\"id\":\"b5\"}},{\"start\":\"28473\",\"end\":\"28833\",\"attributes\":{\"matched_paper_id\":\"4503688\",\"id\":\"b6\"}},{\"start\":\"28835\",\"end\":\"29150\",\"attributes\":{\"matched_paper_id\":\"48354575\",\"id\":\"b7\"}},{\"start\":\"29152\",\"end\":\"29540\",\"attributes\":{\"matched_paper_id\":\"43302446\",\"id\":\"b8\"}},{\"start\":\"29542\",\"end\":\"29954\",\"attributes\":{\"matched_paper_id\":\"102353715\",\"id\":\"b9\"}},{\"start\":\"29956\",\"end\":\"30668\",\"attributes\":{\"matched_paper_id\":\"22323507\",\"id\":\"b10\"}},{\"start\":\"30670\",\"end\":\"31130\",\"attributes\":{\"matched_paper_id\":\"3458310\",\"id\":\"b11\"}},{\"start\":\"31132\",\"end\":\"31670\",\"attributes\":{\"matched_paper_id\":\"43949965\",\"id\":\"b12\"}},{\"start\":\"31672\",\"end\":\"32155\",\"attributes\":{\"matched_paper_id\":\"207591708\",\"id\":\"b13\"}},{\"start\":\"32157\",\"end\":\"32575\",\"attributes\":{\"matched_paper_id\":\"4874977\",\"id\":\"b14\"}},{\"start\":\"32577\",\"end\":\"33016\",\"attributes\":{\"matched_paper_id\":\"33424654\",\"id\":\"b15\"}},{\"start\":\"33018\",\"end\":\"33314\",\"attributes\":{\"matched_paper_id\":\"2088679\",\"id\":\"b16\"}},{\"start\":\"33316\",\"end\":\"33594\",\"attributes\":{\"matched_paper_id\":\"7961631\",\"id\":\"b17\"}},{\"start\":\"33596\",\"end\":\"33976\",\"attributes\":{\"matched_paper_id\":\"201656654\",\"id\":\"b18\"}},{\"start\":\"33978\",\"end\":\"34399\",\"attributes\":{\"matched_paper_id\":\"51722153\",\"id\":\"b19\"}},{\"start\":\"34401\",\"end\":\"34859\",\"attributes\":{\"id\":\"b20\"}},{\"start\":\"34861\",\"end\":\"35259\",\"attributes\":{\"matched_paper_id\":\"4891203\",\"id\":\"b21\"}},{\"start\":\"35261\",\"end\":\"35679\",\"attributes\":{\"matched_paper_id\":\"6736412\",\"id\":\"b22\"}},{\"start\":\"35681\",\"end\":\"36030\",\"attributes\":{\"matched_paper_id\":\"14487659\",\"id\":\"b23\"}},{\"start\":\"36032\",\"end\":\"36220\",\"attributes\":{\"id\":\"b24\"}},{\"start\":\"36222\",\"end\":\"36511\",\"attributes\":{\"matched_paper_id\":\"2930547\",\"id\":\"b25\"}},{\"start\":\"36513\",\"end\":\"36818\",\"attributes\":{\"id\":\"b26\"}},{\"start\":\"36820\",\"end\":\"37255\",\"attributes\":{\"matched_paper_id\":\"207159665\",\"id\":\"b27\"}},{\"start\":\"37257\",\"end\":\"37701\",\"attributes\":{\"matched_paper_id\":\"73440982\",\"id\":\"b28\"}},{\"start\":\"37703\",\"end\":\"38203\",\"attributes\":{\"matched_paper_id\":\"173994344\",\"id\":\"b29\"}},{\"start\":\"38205\",\"end\":\"38658\",\"attributes\":{\"matched_paper_id\":\"3435294\",\"id\":\"b30\"}},{\"start\":\"38660\",\"end\":\"39000\",\"attributes\":{\"matched_paper_id\":\"3933481\",\"id\":\"b31\"}},{\"start\":\"39002\",\"end\":\"39377\",\"attributes\":{\"matched_paper_id\":\"160014428\",\"id\":\"b32\"}},{\"start\":\"39379\",\"end\":\"39652\",\"attributes\":{\"id\":\"b33\"}}]", "bib_title": "[{\"start\":\"26937\",\"end\":\"26955\"},{\"start\":\"27207\",\"end\":\"27224\"},{\"start\":\"27421\",\"end\":\"27519\"},{\"start\":\"28258\",\"end\":\"28284\"},{\"start\":\"28473\",\"end\":\"28565\"},{\"start\":\"28835\",\"end\":\"28892\"},{\"start\":\"29152\",\"end\":\"29286\"},{\"start\":\"29542\",\"end\":\"29662\"},{\"start\":\"29956\",\"end\":\"30180\"},{\"start\":\"30670\",\"end\":\"30819\"},{\"start\":\"31132\",\"end\":\"31304\"},{\"start\":\"31672\",\"end\":\"31817\"},{\"start\":\"32157\",\"end\":\"32272\"},{\"start\":\"32577\",\"end\":\"32696\"},{\"start\":\"33018\",\"end\":\"33069\"},{\"start\":\"33316\",\"end\":\"33355\"},{\"start\":\"33596\",\"end\":\"33669\"},{\"start\":\"33978\",\"end\":\"34098\"},{\"start\":\"34861\",\"end\":\"34971\"},{\"start\":\"35261\",\"end\":\"35336\"},{\"start\":\"35681\",\"end\":\"35772\"},{\"start\":\"36222\",\"end\":\"36271\"},{\"start\":\"36820\",\"end\":\"36875\"},{\"start\":\"37257\",\"end\":\"37347\"},{\"start\":\"37703\",\"end\":\"37841\"},{\"start\":\"38205\",\"end\":\"38341\"},{\"start\":\"38660\",\"end\":\"38726\"},{\"start\":\"39002\",\"end\":\"39104\"}]", "bib_author": "[{\"start\":\"26957\",\"end\":\"26967\"},{\"start\":\"26967\",\"end\":\"26976\"},{\"start\":\"26976\",\"end\":\"26990\"},{\"start\":\"26990\",\"end\":\"27004\"},{\"start\":\"27004\",\"end\":\"27013\"},{\"start\":\"27226\",\"end\":\"27238\"},{\"start\":\"27238\",\"end\":\"27250\"},{\"start\":\"27250\",\"end\":\"27259\"},{\"start\":\"27521\",\"end\":\"27533\"},{\"start\":\"27533\",\"end\":\"27542\"},{\"start\":\"27542\",\"end\":\"27550\"},{\"start\":\"27879\",\"end\":\"27889\"},{\"start\":\"27889\",\"end\":\"27899\"},{\"start\":\"27899\",\"end\":\"27911\"},{\"start\":\"27911\",\"end\":\"27926\"},{\"start\":\"27926\",\"end\":\"27935\"},{\"start\":\"27935\",\"end\":\"27956\"},{\"start\":\"28286\",\"end\":\"28295\"},{\"start\":\"28295\",\"end\":\"28306\"},{\"start\":\"28306\",\"end\":\"28316\"},{\"start\":\"28316\",\"end\":\"28332\"},{\"start\":\"28567\",\"end\":\"28578\"},{\"start\":\"28578\",\"end\":\"28587\"},{\"start\":\"28587\",\"end\":\"28598\"},{\"start\":\"28894\",\"end\":\"28903\"},{\"start\":\"28903\",\"end\":\"28919\"},{\"start\":\"28919\",\"end\":\"28930\"},{\"start\":\"29288\",\"end\":\"29296\"},{\"start\":\"29296\",\"end\":\"29309\"},{\"start\":\"29309\",\"end\":\"29322\"},{\"start\":\"29664\",\"end\":\"29673\"},{\"start\":\"29673\",\"end\":\"29680\"},{\"start\":\"29680\",\"end\":\"29688\"},{\"start\":\"30182\",\"end\":\"30191\"},{\"start\":\"30191\",\"end\":\"30205\"},{\"start\":\"30205\",\"end\":\"30214\"},{\"start\":\"30214\",\"end\":\"30227\"},{\"start\":\"30227\",\"end\":\"30236\"},{\"start\":\"30236\",\"end\":\"30245\"},{\"start\":\"30821\",\"end\":\"30829\"},{\"start\":\"30829\",\"end\":\"30836\"},{\"start\":\"30836\",\"end\":\"30842\"},{\"start\":\"31306\",\"end\":\"31318\"},{\"start\":\"31318\",\"end\":\"31330\"},{\"start\":\"31330\",\"end\":\"31342\"},{\"start\":\"31819\",\"end\":\"31831\"},{\"start\":\"31831\",\"end\":\"31843\"},{\"start\":\"31843\",\"end\":\"31857\"},{\"start\":\"32274\",\"end\":\"32282\"},{\"start\":\"32282\",\"end\":\"32294\"},{\"start\":\"32294\",\"end\":\"32306\"},{\"start\":\"32698\",\"end\":\"32708\"},{\"start\":\"32708\",\"end\":\"32717\"},{\"start\":\"32717\",\"end\":\"32726\"},{\"start\":\"33071\",\"end\":\"33082\"},{\"start\":\"33082\",\"end\":\"33090\"},{\"start\":\"33090\",\"end\":\"33104\"},{\"start\":\"33357\",\"end\":\"33365\"},{\"start\":\"33365\",\"end\":\"33371\"},{\"start\":\"33371\",\"end\":\"33380\"},{\"start\":\"33671\",\"end\":\"33679\"},{\"start\":\"33679\",\"end\":\"33694\"},{\"start\":\"33694\",\"end\":\"33709\"},{\"start\":\"33709\",\"end\":\"33719\"},{\"start\":\"33719\",\"end\":\"33730\"},{\"start\":\"33730\",\"end\":\"33738\"},{\"start\":\"34100\",\"end\":\"34106\"},{\"start\":\"34106\",\"end\":\"34115\"},{\"start\":\"34115\",\"end\":\"34126\"},{\"start\":\"34565\",\"end\":\"34573\"},{\"start\":\"34573\",\"end\":\"34580\"},{\"start\":\"34580\",\"end\":\"34588\"},{\"start\":\"34973\",\"end\":\"34981\"},{\"start\":\"34981\",\"end\":\"34992\"},{\"start\":\"34992\",\"end\":\"34999\"},{\"start\":\"35338\",\"end\":\"35350\"},{\"start\":\"35350\",\"end\":\"35357\"},{\"start\":\"35357\",\"end\":\"35365\"},{\"start\":\"35774\",\"end\":\"35784\"},{\"start\":\"35784\",\"end\":\"35793\"},{\"start\":\"36034\",\"end\":\"36044\"},{\"start\":\"36044\",\"end\":\"36055\"},{\"start\":\"36055\",\"end\":\"36061\"},{\"start\":\"36273\",\"end\":\"36288\"},{\"start\":\"36288\",\"end\":\"36296\"},{\"start\":\"36296\",\"end\":\"36302\"},{\"start\":\"36513\",\"end\":\"36519\"},{\"start\":\"36519\",\"end\":\"36528\"},{\"start\":\"36528\",\"end\":\"36535\"},{\"start\":\"36535\",\"end\":\"36542\"},{\"start\":\"36877\",\"end\":\"36886\"},{\"start\":\"36886\",\"end\":\"36898\"},{\"start\":\"37349\",\"end\":\"37360\"},{\"start\":\"37360\",\"end\":\"37368\"},{\"start\":\"37368\",\"end\":\"37381\"},{\"start\":\"37381\",\"end\":\"37398\"},{\"start\":\"37398\",\"end\":\"37407\"},{\"start\":\"37407\",\"end\":\"37416\"},{\"start\":\"37843\",\"end\":\"37856\"},{\"start\":\"37856\",\"end\":\"37867\"},{\"start\":\"37867\",\"end\":\"37881\"},{\"start\":\"37881\",\"end\":\"37893\"},{\"start\":\"38343\",\"end\":\"38353\"},{\"start\":\"38353\",\"end\":\"38361\"},{\"start\":\"38361\",\"end\":\"38368\"},{\"start\":\"38368\",\"end\":\"38377\"},{\"start\":\"38728\",\"end\":\"38737\"},{\"start\":\"38737\",\"end\":\"38748\"},{\"start\":\"38748\",\"end\":\"38757\"},{\"start\":\"38757\",\"end\":\"38768\"},{\"start\":\"38768\",\"end\":\"38778\"},{\"start\":\"39106\",\"end\":\"39120\"},{\"start\":\"39120\",\"end\":\"39134\"}]", "bib_venue": "[{\"start\":\"27042\",\"end\":\"27048\"},{\"start\":\"27277\",\"end\":\"27293\"},{\"start\":\"27575\",\"end\":\"27585\"},{\"start\":\"27797\",\"end\":\"27877\"},{\"start\":\"28156\",\"end\":\"28176\"},{\"start\":\"28332\",\"end\":\"28352\"},{\"start\":\"28619\",\"end\":\"28628\"},{\"start\":\"28956\",\"end\":\"28967\"},{\"start\":\"29322\",\"end\":\"29331\"},{\"start\":\"29714\",\"end\":\"29724\"},{\"start\":\"30273\",\"end\":\"30293\"},{\"start\":\"30862\",\"end\":\"30877\"},{\"start\":\"31367\",\"end\":\"31377\"},{\"start\":\"31880\",\"end\":\"31889\"},{\"start\":\"32331\",\"end\":\"32340\"},{\"start\":\"32754\",\"end\":\"32774\"},{\"start\":\"33131\",\"end\":\"33145\"},{\"start\":\"33416\",\"end\":\"33435\"},{\"start\":\"33764\",\"end\":\"33771\"},{\"start\":\"34151\",\"end\":\"34165\"},{\"start\":\"34401\",\"end\":\"34563\"},{\"start\":\"35017\",\"end\":\"35037\"},{\"start\":\"35365\",\"end\":\"35390\"},{\"start\":\"35813\",\"end\":\"35838\"},{\"start\":\"36095\",\"end\":\"36103\"},{\"start\":\"36327\",\"end\":\"36343\"},{\"start\":\"36593\",\"end\":\"36637\"},{\"start\":\"36921\",\"end\":\"36989\"},{\"start\":\"37440\",\"end\":\"37460\"},{\"start\":\"37921\",\"end\":\"37941\"},{\"start\":\"38402\",\"end\":\"38411\"},{\"start\":\"38804\",\"end\":\"38811\"},{\"start\":\"39159\",\"end\":\"39169\"},{\"start\":\"39379\",\"end\":\"39513\"},{\"start\":\"35416\",\"end\":\"35420\"},{\"start\":\"36991\",\"end\":\"37044\"}]"}}}, "year": 2023, "month": 12, "day": 17}