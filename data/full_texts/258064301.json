{"id": 258064301, "updated": "2023-05-17 15:47:49.881", "metadata": {"title": "Combining data and theory for derivable scientific discovery with AI-Descartes", "authors": "[{\"first\":\"Cristina\",\"last\":\"Cornelio\",\"middle\":[]},{\"first\":\"Sanjeeb\",\"last\":\"Dash\",\"middle\":[]},{\"first\":\"Vernon\",\"last\":\"Austel\",\"middle\":[]},{\"first\":\"Tyler\",\"last\":\"Josephson\",\"middle\":[\"R.\"]},{\"first\":\"Joao\",\"last\":\"Goncalves\",\"middle\":[]},{\"first\":\"Kenneth\",\"last\":\"Clarkson\",\"middle\":[\"L.\"]},{\"first\":\"Nimrod\",\"last\":\"Megiddo\",\"middle\":[]},{\"first\":\"Bachir\",\"last\":\"El Khadir\",\"middle\":[]},{\"first\":\"Lior\",\"last\":\"Horesh\",\"middle\":[]}]", "venue": "Nature Communications", "journal": "Nature Communications", "publication_date": {"year": 2023, "month": 4, "day": 12}, "abstract": "Scientists aim to discover meaningful formulae that accurately describe experimental data. Mathematical models of natural phenomena can be manually created from domain knowledge and fitted to data, or, in contrast, created automatically from large datasets with machine-learning algorithms. The problem of incorporating prior knowledge expressed as constraints on the functional form of a learned model has been studied before, while finding models that are consistent with prior knowledge expressed via general logical axioms is an open problem. We develop a method to enable principled derivations of models of natural phenomena from axiomatic knowledge and experimental data by combining logical reasoning with symbolic regression. We demonstrate these concepts for Kepler\u2019s third law of planetary motion, Einstein\u2019s relativistic time-dilation law, and Langmuir\u2019s theory of adsorption. We show we can discover governing laws from few data points when logical reasoning is used to distinguish between candidate formulae having similar error on the data.", "fields_of_study": "[\"Medicine\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": "37045814", "pubmedcentral": "10097814", "dblp": null, "doi": "10.1038/s41467-023-37236-y"}}, "content": {"source": {"pdf_hash": "11c7099ef5fd42a63a3ba0e439630ad6600d05fb", "pdf_src": "Springer", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "ea9ce60027df976318e9d0d6d3bee40f99e31db5", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/11c7099ef5fd42a63a3ba0e439630ad6600d05fb.txt", "contents": "\nCombining data and theory for derivable scientific discovery with AI-Descartes Check for updates\n2023. 1777 1 1234567890\n\nCristina Cornelio c.cornelio@samsung.com \nIBM Research-Mathematics and Theoretical Computer Science\nNew YorkNYUSA\n\nSamsung AI-Machine Learning and Data Intelligence\nCambridgeUK\n\nSanjeeb Dash \nIBM Research-Mathematics and Theoretical Computer Science\nNew YorkNYUSA\n\nVernon Austel \nIBM Research-Mathematics and Theoretical Computer Science\nNew YorkNYUSA\n\nTyler R Josephson \nDepartment of Chemical, Biochemical, and Environmental Engineering\nUniversity of Maryland\nBaltimore CountyMDUSA\n\nDepartment of Chemistry and Chemical Theory Center\nUniversity of Minnesota\nMinneapolisMNUSA\n\nJoao Goncalves \nIBM Research-Mathematics and Theoretical Computer Science\nNew YorkNYUSA\n\nKenneth L Clarkson \nIBM Research-Mathematics and Theoretical Computer Science\nNew YorkNYUSA\n\nNimrod Megiddo \nIBM Research-Mathematics and Theoretical Computer Science\nNew YorkNYUSA\n\nBachir El Khadir \nIBM Research-Mathematics and Theoretical Computer Science\nNew YorkNYUSA\n\n&amp; Lior Horesh \nIBM Research-Mathematics and Theoretical Computer Science\nNew YorkNYUSA\n\nComputer Science\nColumbia University\nNew YorkNYUSA\n\nCombining data and theory for derivable scientific discovery with AI-Descartes Check for updates\n\nNature Communications |\n1412345678902023. 1777 1 123456789010.1038/s41467-023-37236-yReceived: 28 October 2021 Accepted: 8 March 2023Article\nScientists aim to discover meaningful formulae that accurately describe experimental data. Mathematical models of natural phenomena can be manually created from domain knowledge and fitted to data, or, in contrast, created automatically from large datasets with machine-learning algorithms. The problem of incorporating prior knowledge expressed as constraints on the functional form of a learned model has been studied before, while finding models that are consistent with prior knowledge expressed via general logical axioms is an open problem. We develop a method to enable principled derivations of models of natural phenomena from axiomatic knowledge and experimental data by combining logical reasoning with symbolic regression. We demonstrate these concepts for Kepler's third law of planetary motion, Einstein's relativistic time-dilation law, and Langmuir's theory of adsorption. We show we can discover governing laws from few data points when logical reasoning is used to distinguish between candidate formulae having similar error on the data.Artificial neural networks (NN) and statistical regression are commonly used to automate the discovery of patterns and relations in data. NNs return \"black-box\" models, where the underlying functions are typically used for prediction only. In standard regression, the functional form is determined in advance, so model discovery amounts to parameter fitting. In symbolic regression (SR) 1, 2 , the functional form is not determined in advance, but is instead composed from operators in a given list (e.g., + , \u2212 , \u00d7 , and \u00f7) and calculated from the data. SR models are typically more \"interpretable\" than NN models, and require less data. Thus, for discovering laws of nature in symbolic form from experimental data, SR may work better than NNs or fixed-form regression 3 ; integration of NNs with SR has been a topic of recent research in neuro-symbolic AI 4-6 . A major challenge in SR is to identify, out of many models that fit the data, those that are scientifically meaningful. Schmidt and Lipson 3 identify meaningful functions as those that balance accuracy and complexity. However many such expressions exist for a given dataset, and not all are consistent with the known background theory.Another approach would be to start from the known background theory, but there are no existing practical reasoning tools that generate theorems consistent with experimental data from a set of known axioms. Automated Theorem Provers (ATPs), the most widely-used reasoning tools, instead solve the task of proving a conjecture for a given logical theory. Computational complexity is a major challenge for ATPs; for certain types of logic, proving a conjecture is undecidable. Moreover, deriving models from a logical theory using formal reasoning tools is especially difficult when arithmetic and calculus operators are involved (e.g., see the work of Grigoryev et al. 7  for the case of inequalities). Machine-learning techniques have been used to improve the performance of ATPs, for example, by using reinforcement learning to guide the search process 8 . This research area has received much attention recently 9-11 . Nature Communications | (2023) 14:1777 1234567890():,; 1234567890():,;Numerical error values, pointwise reasoning error values, and generalization error values are shown. We also give an analysis of the variable dependence of candidate solutions. For simplicity of notation, in the table we use the variables d, m1, m2 and p, while referring to the scaled counterparts. We assume that all the errors are relative.\n\nModels that are derivable, and not merely empirically accurate, are appealing because they are arguably correct, predictive, and insightful. We attempt to obtain such models by combining a novel mathematical-optimization-based SR method with a reasoning system. This yields an end-to-end discovery system, which extracts formulas from data via SR, and then furnishes either a formal proof of derivability of the formula from a set of axioms, or a proof of inconsistency. We present novel measures that indicate how close a formula is to a derivable formula, when the model is provably non-derivable, and we calculate the values of these measures using our reasoning system. In earlier work combining machine learning with reasoning, Marra et al. 12 use a logic-based description to constrain the output of a GAN neural architecture for generating images. Scott et al. 13 and Ashok et al. 14 combine machine-learning tools and reasoning engines to search for functional forms that satisfy prespecified constraints. They augment the initial dataset with new points in order to improve the efficiency of learning methods and the accuracy of the final model. Kubalik et al. 15 also exploit prior knowledge to create additional data points. However, these works only consider constraints on the functional form to be learned, and do not incorporate general background-theory axioms (logic constraints that describe the other laws and unmeasured variables that are involved in the phenomenon).\n\n\nResults\n\n\nDiscovery as a formal mathematical problem\n\nOur automated scientific discovery method aims to discover an unknown symbolic model y = f *(x) (bold letters indicate vectors) where x is the vector (x 1 , \u2026, x n ) of independent variables, and y is the dependent variable. The discovered model f (an approximation of f *) should fit a collection of m data points, ((X 1 , Y 1 ), \u22ef , (X m , Y m )), be derivable from a background theory, have low complexity and bounded prediction error. More specifically, the inputs to our system are 4-tuples hB,C,D,Mi as follows.\n\n\u2022 Background Knowledge B: a set of domain-specific axioms expressed as logic formulae. They involve x, y, and possibly more variables that are necessary to formulate the background theory. In this work we focus mainly on first-order-logic formulae with equality, inequality and basic arithmetic operators. We assume that the background theory B is complete, that is, it contains all the axioms necessary to comprehensively explain the phenomena under consideration, and consistent, that is, the axioms do not contradict one another. These two assumptions guarantee that there exists a unique derivable function f B that logically represents the variable of interest y. Note that although the derivable function is unique, there may exist different functional forms that are equivalent on the domain of interest. Considering the domain with two points {0, 1} for a variable x, the two functional forms f (x) = x and f (x) = x 2 both define the same function. \u2022 A Hypothesis Class C: a set of admissible symbolic models defined by a grammar, a set of invariance constraints to avoid redundant expressions (e.g., A + B is equivalent to B + A) and constraints on the functional form (e.g., monotonicity). \n\n\nGeneralized notion of distance\n\nIn general, there may not exist a function f 2 C that fits the data exactly and is derivable from B. This could happen because the symbolic model generating the data might not belong to C, the sensors used to collect the data might give noisy measurements, or the background knowledge might be inaccurate or incomplete. To quantify the compatibility of a symbolic model with data and background theory, we introduce the notion of distance between a model f and B. Roughly, it reflects the error between the predictions of f and the predictions of a formula f B derivable from B (thus, the distance equals zero when f is derivable from B). Figure 1 provides a visualization of these two notions of distance for the problem of learning Kepler's third law of planetary motion from solar-system data and background theory.\n\n\nIntegration of statistical and symbolic AI\n\nOur system consists mainly of an SR module and a reasoning module. The SR module returns multiple candidate symbolic models (or formulae) expressing y as a function of x 1 , \u2026, x n and that fit the data. For each of these models, the system outputs the distance \u03b5( f ) between f and D and the distance \u03b2( f ) between f and B. We will also be referring to \u03b5( f ) and \u03b2( f ) as errors. These functions are also tested to see if they satisfy the specified constraints on the functional form (in C) and the modeler-specified level of accuracy and complexity (in M). When the models are passed to the reasoning module (along with the background theory B), they are tested for derivability. If a model is found to be derivable from B, it is returned as the chosen model for prediction; otherwise, if the reasoning module concludes that no candidate model is derivable, it is necessary to either collect additional data or add constraints. In this case, the reasoning module will return a quality assessment of the input set of candidate hypotheses based on the distance \u03b2, removing models that do not satisfy the modeler-specified bounds on \u03b2. The distance (or error) \u03b2 is computed between a function (or formula) f, derived from numerical data, and the derivable function f B which is implicitly defined by the set of axioms in B and is logically represented by the variable of interest y. The distance between the function f B and any other formula f depends only on the background theory and the formula f and not on any particular functional form of f B . Moreover, the reasoning module can prove that a model is not derivable by returning counterexample points that satisfy B but do not fit the model. The numerical data, background theory, and a discovered model are depicted for Kepler's third law of planetary motion giving the orbital period of a planet in the solar system. The data consists of measurements (m 1 , m 2 , d, p) of the mass of the sun m 1 , the orbital period p and mass m 2 for each planet and its distance d from the sun. The background theory amounts to Newton's laws of motion, i.e., the formulae for centrifugal force, gravitational force, and equilibrium conditions. The 4-tuples (m 1 , m 2 , d, p) are projected into (m 1 + m 2 , d, p). The blue manifold represents solutions of f B , which is the function derivable from the background-theory axioms that represents the variable of interest. The gray manifold represents solutions of the discovered model f. The double arrows indicate the distances \u03b2 ( f ) and \u03b5( f ).\n\nInterplay between data and theory in AI-Descartes SR is typically solved with genetic programming (GP) [1][2][3]16 , however methods based on mixed-integer nonlinear programming (MINLP) have recently been proposed [17][18][19] . In this work, we develop a new MINLP-based SR solver (described in the Supplementary Information). The input consists of a subset of the operators { + , \u00c0 , \u00d7 , \u00c4 , ffi p , log , exp}, an upper bound on expression complexity, and an upper bound on the number of constants used that do not equal 1. Given a dataset, the system formulates multiple MINLP instances to find an expression that minimizes the least-square error. Each instance is solved approximately, subject to a time limit. Both linear and nonlinear constraints can be imposed. In particular, dimensional consistency is imposed when physical dimensions of variables are available.\n\nWe use KeYmaera X 20 as a reasoning tool; it is an ATP for hybrid systems and combines different types of reasoning: deductive, realalgebraic, and computer-algebraic reasoning. We also use Mathematica 21 for certain types of analysis of symbolic expressions. While a formula found by any grammar-based system (such as an SR system) is syntactically correct, it may contradict the axioms of the theory or not be derivable from them. In some cases, a formula may not be derivable as the theory may not have enough axioms; the formula may be provable under an extended axiom set or an alternative one (e.g., using a relativistic set of axioms rather than a \"Newtonian\" one).\n\nAn overview of our system seen as a discovery cycle is shown in Fig. 2. Our discovery cycle is inspired by Descartes who advanced the scientific method and emphasized the role that logical deduction, and not empirical evidence alone, plays in forming and validating scientific discoveries. Our present approach differs from implementations of the scientific method that obtain hypotheses from theory and then check them against data; instead we obtain hypotheses from data and assess them against theory. A more detailed schematic of the system is depicted in Fig. 3, where the colored components correspond to the system we present in this work, and the gray components refer to standard techniques for scientific discovery that we have not yet integrated into our current implementation.\n\n\nExperimental validation\n\nWe tested the different capabilities of our system on three problems (more details in the Methods section). First, we considered the problem of deriving Kepler's third law of planetary motion, providing reasoning-based measures to analyze the quality and generalizablity of the generated formulae. Extracting this law from experimental data is challenging, especially when the masses involved are of very different magnitudes. This is the case for the solar system, where the solar mass is much larger than the planetary masses. The reasoning module helps in choosing between different candidate formulae and identifying the one that generalizes well: using our data and theory integration we were able to re-discover Kepler's third law. We then considered Einstein's time-dilation formula. Although we did not recover this formula from data, we used the reasoning module to identify the formula that generalizes best. Moreover, analyzing the reasoning errors with two different sets of axioms (one with \"Newtonian\" assumptions and one relativistic), we were able to identify the theory that better explains the phenomenon. Finally, we considered Langmuir's adsorption equation, whose background theory contains material-dependent coefficients. By relating these coefficients to the ones in the SR-generated models via existential quantification, we were able to logically prove one of the extracted formulae.\n\n\nDiscussion\n\nWe have demonstrated the value of combining logical reasoning with symbolic regression in obtaining meaningful symbolic models of physical phenomena, in the sense that they are consistent with background theory and generalize well in a domain that is significantly larger than the experimental data. The synthesis of regression and reasoning yields better models than can be obtained by SR or logical reasoning alone.\n\nImprovements or replacements of individual system components and introduction of new modules such as abductive reasoning or experimental design 22 (not described in this work for the sake of brevity) would extend the capabilities of the overall system. A deeper integration of reasoning and regression can help synthesize models that are both data driven and based on first principles, and lead to a revolution in the scientific discovery process. The discovery of models Article https://doi.org/10.1038/s41467-023-37236-y that are consistent with prior knowledge will accelerate scientific discovery, and enable going beyond existing discovery paradigms.\n\n\nMethods\n\nWe next describe in detail the methodologies used to address the three problems studied to validate our method: Kepler's third law of planetary motion, relativistic time dilation, and Langmuir's adsorption equation.\n\n\nKepler's third law of planetary motion\n\nKepler's law relates the distance d between two bodies (e.g., the sun and a planet in the solar system) and their orbital periods. It can be expressed as\np = ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi ffi 4\u03c0 2 d 3 G m 1 + m 2 \u00c0 \u00c1 s ,\u00f01\u00de\nwhere p is the period, G is the gravitational constant, and m 1 and m 2 are the two masses. It can be derived using the following axioms of the background theory B, describing the center of mass (axiom K1), the distance between bodies (axiom K2), the gravitational force (axiom K3), the centrifugal force (axiom K4), the force balance (axiom K5), and the period (axiom K6):\nK1: Center of mass m 1 d 1 = m 2 d 2 K2: Distance between bodies d = d 1 + d 2 K3: Gravitational force F g = Gm 1 m 2 d 2 K4: Centrifugal force F c = m 2 d 2 w 2 K5: Force balance F g = F c K6: Period definition p = 2\u03c0 w K7: Positivity constraints m 1 > 0, m 2 > 0, p > 0, d 1 > 0, d 2 > 0:\u00f02\u00de\nWe consider three real-world datasets: planets of the solar system (from the NASA Planetary Fact Sheet 23 ), the solar-system planets along with exoplanets from Trappist-1 and the GJ 667 system (from the NASA exoplanet archive 24 ), and binary stars 25 . These datasets contain measurements of pairs of masses (a sun and a planet for the first two, and two suns for the third), the distance between them, and the orbital period of the planet around its sun in the first two datasets or the orbital period around the common center of mass in the third dataset. The data we use is given in the Supplementary Information. Note that the dataset does not contain measurements for a number of variables in the axiom system, such as d 1 , d 2 , F g , etc.\n\nThe goal is to recover Kepler's third law (Eq. (1)) from the data, that is, to obtain p as the above-stated function of d, m 1 and m 2 .\n\nThe SR module takes as input the set of operators { + , \u00c0 , \u00d7 , \u00c4 ,\u221a } and outputs a set of candidate formulas. None of the formulae obtained via SR are derivable, though some are close approximations to derivable formulae. We evaluate the quality of these formulae by writing a logic program for calculating the error \u03b2 of a formula with respect to a derivable formula. We use three measures, defined below, to assess the correctness of a data-driven formula from a reasoning viewpoint: the pointwise reasoning error, the generalization reasoning error, and variable dependence.\n\nPointwise reasoning error. The key idea is to compute a distance between a formula generated from the numerical data and some derivable formula that is implicitly defined by the axiom set. The distance is measured by the l 2 or l 1 norm applied to the differences between the values of the numerically-derived formula and a derivable formula at the points in the dataset. This definition can be extended to other norms.\n\nWe compute the relative error of numerically derived formula f (x) applied to the m data points X i (i = 1, \u2026, m) with respect to f B \u00f0x\u00de, derivable from the axioms via the following expressions:\n\u03b2 r 2 = ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi ffi X m i = 1 f \u00f0X i \u00de \u00c0 f B \u00f0X i \u00de f B \u00f0X i \u00de ! 2 v u u t and \u03b2 r 1 = max 1 \u2264 i \u2264 m | f \u00f0X i \u00de \u00c0 f B \u00f0X i \u00de| | f B \u00f0X i \u00de| ( )\u00f03\u00de\nwhere f B \u00f0X i \u00de denotes a derivable formula for the variable of interest y evaluated at the data point X i . The KeYmaera formulation of these two measures for the first formula of Table 1 can be found in the Supplementary Information. Absolute-error variants of the first and second expressions in Eq. (3) Colored components correspond to our system, and gray components indicate standard techniques for scientific discovery (humandriven or artificial) that have not been integrated into the current system. The colors match the respective components of the discovery cycle of Fig. 2. The present system generates hypotheses from data using symbolic regression, which are posed as conjectures to an automated deductive reasoning system, which proves or disproves them based on background theory or provides reasoningbased quality measures.\n\nare denoted by \u03b2 a 2 ,\u03b2 a 1 , respectively. The numerical (data) error measures \u03b5 r 2 and \u03b5 r 1 are defined by replacing f B \u00f0X i \u00de by Y i in Eq. (3). Analogous to \u03b2 a 2 and \u03b2 a 1 , we also define absolute-numerical-error measures \u03b5 a 2 and \u03b5 a 1 . Table 1 reports in columns 5 and 6 the values of \u03b2 r 2 and \u03b2 r 1 , respectively. It also reports the relative numerical errors \u03b5 r 2 and \u03b5 r 1 in columns 3 and 4, measured by the l 2 and l 1 norms, respectively, for the candidate expressions given in column 2 when evaluated on the points in the dataset. We minimize the absolute l 2 error \u03b5 a 2 (and not the relative error \u03b5 r 2 ), when obtaining candidate expressions via symbolic regression.\n\nThe pointwise reasoning errors \u03b2 2 and \u03b2 1 are not very informative if SR yields a low-error candidate expression (measured with respect to the data), and the data itself satisfies the background theory up to a small error, which indeed is the case with the data we use; the reasoning errors and numerical errors are very similar.\n\nGeneralization reasoning error. Even when one can find a function that fits given data points well, it is challenging to obtain a function that generalizes well, that is, one which yields good results at points of the domain not equal to the data points. Let \u03b2 r 1,S be calculated for a candidate formula f (x) over a domain S that is not equal to the original set of data points as follows:\n\u03b2 r 1,S = max x2S | f \u00f0x\u00de \u00c0 f B \u00f0x\u00de| | f B \u00f0x\u00de| & ' ,\u00f04\u00de\nwhere we consider the relative error and, as before, the function f B \u00f0x\u00de is not known, but is implicitly defined by the axioms in the background theory. We call this measure the relative generalization reasoning error. If we do not divide by f B \u00f0x\u00de in the above expression, we get the corresponding absolute version \u03b2 a 1,S . For the Kepler dataset, we let S be the smallest multi-dimensional interval (or Cartesian product of intervals on the real line) containing all data points. In column 7 of Table 1, we show the relative generalization reasoning error \u03b2 r 1,S on the Kepler datasets with S defined as above. If this error is roughly the same as \u03b2 r 1 the pointwise relative reasoning error for l 1 (e.g., for the solar system dataset) then the formula extracted from the numerical data is as accurate at points in S as it is at the original data points.\n\nVariable dependence. In order to check if the functional dependence of a candidate formula on a specific variable is accurate, we compute the generalization error over a domain S 0 where the domain of this variable is extended by an order of magnitude beyond the smallest interval containing the values of the variable in the dataset. Thus we can check whether there exist special conditions under which the formula does not hold. We modify the endpoints of an interval by one order of magnitude, one variable at a time. If we notice an increase in the generalization reasoning error while modifying intervals for one variable, we deem the candidate formula as missing a dependency on that variable. A missing dependency might occur, for example, because the exponent for a variable is incorrect, or that variable is not considered at all when it should be. One can get further insight into the type of dependency by analyzing how the error varies (e.g., linearly or exponentially). Table 1 provides, in columns 8-10, results regarding the candidate formulae for Kepler's third law. For each formula, the dependencies on m 1 , m 2 , and d are indicated by 1 or 0 (for correct or incorrect dependency). For example, the candidate formula p = ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi 0:1319d 3 p for the solar system does not depend on either mass, and the dependency analysis suggests that the formula approximates well the phenomenon in the solar system, but not for larger masses.\n\nThe best formula for the binary-star dataset, ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi d 3 =\u00f00:9967m 1 + m 2 \u00de q , has no missing dependency (all ones in columns 8-10), that is, it generalizes well; increasing the domain along any variable does not increase the generalized reasoning error. Figure 4 provides a visualization of the two errors \u03b5 r 2 and \u03b2 r 2 for the first three functions of Table 1 (solar-system dataset) and the ground truth f \u00c3 .\n\n\nRelativistic time dilation\n\nEinstein's theory of relativity postulates that the speed of light is constant, and implies that two observers in relative motion to each other will experience time differently and observe different clock frequencies. The frequency f for a clock moving at speed v is related to the frequency f 0 of a stationary clock by the formula\nf \u00c0 f 0 f 0 = ffiffiffiffiffiffiffiffiffiffiffiffi ffi 1 \u00c0 v 2 c 2 r \u00c0 1 ,\u00f05\u00de\nwhere c is the speed of light. This formula was recently confirmed experimentally by Chou et al. 26 using high precision atomic clocks. We test our system on the experimental data reported by Chou et al. 26 which consists of measurements of v and associated values of \u00f0 f \u00c0 f 0 \u00de=f 0 , reproduced in the Supplementary Information. We take the axioms for derivation of the time dilation formula from the work of Behroozi 27 and Smith 28 . These are also listed in the Supplementary Information and involve variables that are not present in the experimental data.\n\nIn Table 2 we give some functions obtained by our SR module (using { + , \u00c0 , \u00d7 , \u00c4 ,\u221a } as the set of input operators) along with the numerical errors of the associated functions and generalization reasoning errors. The sixth column gives the set S as an interval for v for which our reasoning module can verify that the absolute generalization reasoning error of the function in the first column is at most 1. The last column gives the interval for v for which we can verify a relative generalization reasoning error of at most 2%. Even though the last function has low relative error according to this metric, it can be ruled out as a reasonable candidate if one assumes the target function should be continuous (it has a singularity at v = 1). Thus, even though we cannot obtain the original function, we obtain another which generalizes well, as it yields excellent predictions for a very large range of velocities.\n\nIn this case, our system can also help rule out alternative axioms. Consider replacing the axiom that the speed of light is a constant value c by a \"Newtonian\" assumption that light behaves like other mechanical objects: if emitted from an object with velocity v in a direction perpendicular to the direction of motion of the object, it has velocity ffiffiffiffiffiffiffiffiffiffiffiffiffi ffi v 2 + c 2 p . Replacing c by ffiffiffiffiffiffiffiffiffiffiffiffiffi ffi v 2 + c 2 p (in axiom R2 in the Supplementary Information to obtain R2') produces a self-consistent axiom system (as confirmed by the theorem prover), albeit one leading to no time dilation. Our reasoning module concludes that none of the functions in Table 2 is compatible with this updated axiom system: the absolute generalization reasoning error is greater than 1 even on the dataset domain, as well as the pointwise reasoning error. Consequently, the data is used indirectly to discriminate between axiom systems relevant for the phenomenon under study; SR poses only accurate formulae as conjectures.\n\n\nLangmuir's adsorption equation\n\nThe Langmuir adsorption equation (Nobel Prize in Chemistry, 1932) 29 describes a chemical process in which gas molecules contact a surface, and relates the loading q on the surface to the pressure p of the gas:\nq = q max K a p 1 + K a p :\u00f06\u00de\nThe constants q max and K a characterize the maximum loading and the adsorption strength, respectively. A similar model for a material with two types of adsorption sites yields:\nq = q max,1 K a,1 p 1 + K a,1 p + q max,2 K a,2 p 1 + K a,2 p ,\u00f07\u00de\nwith parameters for maximum loading and adsorption strength on each type of site. The parameters in Eqs. (6) and (7) fit experimental data using linear or nonlinear regression, and depend on the material, gas, and temperature. We used data from Langmuir's 1918 publication 29 for methane adsorption on mica at a temperature of 90 K, and also data from the work of Sun et al. 30 (Table 1) for isobutane adsorption on silicalite at a temperature of 277 K. In both cases, observed values of q are given for specific values of p; the goal is to express q as a function of p. We give the SR module the operators { + , \u2212 , \u00d7 , \u00f7}, and obtain the best fitting functions with two and four constants. The code ran for 20 minutes on 45 cores, and seven of these functions are displayed for each dataset.\n\nTo encode the background theory, following Langmuir's original theory 29 , we elicited the following set A of axioms: \n\nHere, S 0 is the total number of sites, of which S are unoccupied and S a are occupied (L1). The adsorption rate r ads is proportional to the pressure p and the number of unoccupied sites (L2). The desorption rate r des is proportional to the number of occupied sites (L3). At equilibrium, r ads = r des (L4), and the total amount adsorbed, q, is the number of occupied sites (L5) because the model assumes each site adsorbs at most one molecule. Langmuir solved these equations to obtain\nq = S 0 \u00f0k ads =k des \u00dep 1 + \u00f0k ads =k des \u00dep ,\u00f09\u00de\nwhich corresponds to Eq. (6), where q max = S 0 and K a = k ads /k des . An axiomatic formulation for the multi-site Langmuir expression is described in the Supplementary Information. Additionally, constants and variables are constrained to be positive (e.g., S 0 > 0, S > 0, and S a > 0) or non-negative (e.g., q \u2265 0). The logic formulation to prove is:\n\u00f0C^A\u00de ! f ,\u00f010\u00de\nwhere C is the conjunction of the non-negativity constraints, A is a conjunction of the axioms, the union of C and A constitutes the background theory B, and f is the formula we wish to prove. SR can only generate numerical expressions involving the (dependent and independent) variables occurring in the input data, with certain values for constants; for example, the expression f = p/ (0.709p + 0.157). The expressions built from variables and constants from the background theory, such as Eq. (9), involve the constants (in their symbolic form) explicitly: for example, k ads and k des appear explicitly in Eq. (9) while SR only generates a numerical instance of the ratio of these constants. Thus, we cannot use Formula (10) directly to prove formulae generated from SR. Instead, we replace each numerical constant of the formula by a logic variable c i : for example, the formula f = p/(0.709p + 0.157) is replaced by f 0 = p=\u00f0c 1 p + c 2 \u00de, introducing two new variables c 1 and c 2 . We then quantify the new variables  (\u03b5, \u03b2), where \u03b5 represents distance to data, and \u03b2 represents distance to background theory. Both distances are computed with an appropriate norm on the scaled data. existentially, and define a new set of non-negativity constraints C 0 . In the example above we will have C 0 = c 1 > 0^c 2 > 0.\n\nThe final formulation to prove is:\n9c 1 \u00c1 \u00c1 \u00c1 9c n \u00f0C^A\u00de ! \u00f0 f 0^C0 \u00de: \u00f011\u00de\nFor example, f 0 = p=\u00f0c 1 p + c 2 \u00de is proved true if the reasoner can prove that there exist values of c 1 and c 2 such that f 0 satisfies the background theory A and the constraints C. Here c 1 and c 2 can be functions of constants k ads , k des , S 0 , and/or real numbers, but not the variables q and p.\n\nWe also consider background knowledge in the form of a list of desired properties of the relation between p and q, which helps trim the set of candidate formulae. Thus, we define a collection K of constraints on f, where q = f ( p), enforcing monotonicity or certain types of limiting behavior (see Supplementary Information). We use Mathematica 21 to verify that a candidate function satisfies the constraints in K.\n\nIn Table 3, column 1 gives the data source, and column 2 gives the \"hyperparameters\" used in our SR experiments: we allow either two or four constants in the derived expressions. Furthermore, as the first constraint C1 from K can be modeled by simply adding the data point p = q = 0, we also experiment with an \"extra point\".\n\nColumn 3 displays a derived expression, while columns 4 and 5 give, respectively, the relative numerical errors \u03b5 r 2 and \u03b5 r 1 . If the expression can be derived from our background theory, then we indicate that in column 6. These results are visualized in Fig. 5. Column 7 indicates the number of constraints from K that each expression satisfies, verified by Mathematica. Among the top two-constant expressions, f 1 fits the data better than f 2 , which is derivable from the background theory, whereas f 1 is not.\n\nWhen we search for four-constant expressions 29 , we get much smaller errors than Eq. (6) or even Eq. (7), but we do not obtain the twosite formula (Eq. (7)) as a candidate expression. For the dataset from Sun et al. 30 , g 2 has a form equivalent to Langmuir's one-site formula, and g 5 and g 7 have forms equivalent to Langmuir's two-site formula, with appropriate values of q max,i and K a,i for i = 1, 2.\n\n\nSystem limitations and future improvements\n\nOur results on three problems and associated data are encouraging and provide the foundations of a new approach to automated scientific discovery. However our work is only a first, although crucial, step towards completing the missing links in automating the scientific method.\n\nOne limitation of the reasoning component is the assumption of correctness and completeness of the background theory. The incompleteness could be partially solved by the introduction of abductive reasoning 31 (as depicted in Fig. 3). Abduction is a logic technique that aims to find explanations of an (or a set of) observation, given a logical theory. The explanation axioms are produced in a way that satisfy the following: (1) the explanation axioms are consistent with the original logical theory and (2) the observation can be deduced by the new enhanced theory (the original logical theory combined with the explanation axioms). In our context the logical theory corresponds to the set of background knowledge axioms that describe a scientific phenomenon, the observation is one of the formulas extracted from the numerical data and the explanations are the missing axioms in the incomplete background theory.\n\nHowever the availability of background theory axioms in machine readable format for physics and other natural sciences is currently limited. Acquiring axioms could potentially be automated (or partially automated) using knowledge extraction techniques. Extraction from technical books or articles that describe a natural science phenomenon can be done by, for example, deep learning methods (e.g. the work of Pfahler and Morik 32 , Alexeeva et al. 33 , or Wang and Liu 34 ) both from NL plain text or semi-structured text such as LateX or HTML. Despite the recent advancements in this research field, the quality of the existing tools remains quite inadequate with respect to the scope of our system.\n\nAnother limitation of our system, that heavily depends on the tools used, is the scaling behavior. Excessive computational complexity is a major challenge for automated theorem provers (ATPs): for certain types of logic (including the one that we use), proving a conjecture is undecidable. Deriving models from a logical theory using formal reasoning tools is even more difficult when using complex arithmetic and calculus operators. Moreover, the run-time variance of a theorem prover is very large: the system can at times solve some \"large\" problems while having difficulties with some \"smaller\" problems. Recent developments in the neuro-symbolic area use deeplearning techniques to enhance standard theorem provers (e.g., see Crouse et al. 8 ). We are still at the early stages of this research and there is still a lot that can be done. We envision that the performance and capability (in terms of speed and expressivity) of theorem provers will improve with time. Symbolic regression tools, including the one based on solving mixed-integer nonlinear programs (MINLP) that we developed, often take an excessive amount of time to explore the space of possible symbolic expressions and find one that has low error and expression complexity, especially with noisy data. In practice, the worst-case solution time for MINLP solvers (including BARON) grows exponentially with input data encoding size (additional details in the Supplementary Information). However, MINLP solver performance and genetic programming based symbolic regression solvers are active areas of research.\n\nOur proposed system could benefit from other improvements in individual components (especially in the functionality available). For example, Keymaera only supports differential equations in time and not in other variables and does not support higher order logic; BARON cannot handle differential equations.\n\nBeyond improving individual components, our system can be improved by introducing techniques such as experimental design (not described in this work but envisioned in Fig. 3). A fundamental question in the holistic view of the discovery process is what data should be collected to give us maximum information regarding the underlying model. The goal of optimal experimental design (OED) is to find an The values of v are defined in m/s. optimal sequence of data acquisition steps such that the uncertainty associated with the inferred parameters, or some predicted quantity derived from them, is minimized with respect to a statistical or information theoretic criterion. In many realistic settings, experimentation may be restricted or costly, providing limited support for any given hypothesis as to the underlying functional form. It is therefore critical at times to incorporate an effective OED framework. In the context of model discovery, a large body of work addresses the question of experimental design for predetermined functional forms, and another body of research addresses the selection of a model (functional form) out of a set of candidates. A framework that can deal with both the functional form and the continuous set of parameters that define the model behavior is obviously desirable 22 ; one that consistently accounts for logical derivability or knowledge-oriented considerations 35 would be even better.\n\n\nData availability\n\nThe data used in this study are available in the AI-Descartes GitHub repository 36 : https://github.com/IBM/AI-Descartes.\n\n\nCode availability\n\nThe code used for this work can be found, freely available, at the AI-Descartes GitHub repository 36 : https://github.com/IBM/AI-Descartes.  (* This expression is also generated when using four constants, and also when the extra point (0, 0) is added).\n\n\u2022\nData D: a set of m examples, each providing certain values for x 1 , \u2026, x n , and y. \u2022 Modeler Preferences M: a set of numerical parameters (e.g., error bounds on accuracy).\n\nFig. 1 |\n1Visualization of relevant sets and their distances.\n\nFig. 2 |\n2An interpretation of the scientific method as implemented by our system. The colors match the respective components of the system inFig. 3.\n\nFig. 3 |\n3System overview.\n\n\nAdsorption rate model r ads = k ads pS L3: Desorption rate model r des = k des S a L4: Equilibrium assumption r ads = r des L5: Mass balance on q q = S a :\n\nFig. 4 |\n4Depiction of symbolic models for Kepler's third law of planetary motion giving the orbital period of a planet in the solar system. The models produced by our SR system are represented by points\n\nFig. 5 |\n5Symbolic regression solutions to two adsorption datasets. Fig. 5a refers to the methane adsorption on mica at a temperature of 90 K, while Fig. 5b refers to the isobutane adsorption on silicalite at a temperature of 277 K. f 2 and g 2 are equivalent to the single-site Langmuir equation; g 5 and g 7 are equivalent to the twosite Langmuir equation.\n\nTable 1\n1| Error values of candidate solutions for the Kepler dataset \n\n1 \n2 \n3 \n4 \n5 \n6 \n7 \n8 \n9 \n1 0 \nDataset \nCandidate formula \nnumerical error \npoint. reas. err. \ngen. reas. error \ndependencies \n\np = \n\u03b5 r \n\n2 \n\n\u03b5 r \n\n1 \n\n\u03b2 r \n\n2 \n\n\u03b2 r \n\n1 \n\n\u03b2 r \n\n1,S \n\nm 1 \nm 2 \nd \n\nSolar \nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi ffi \n0:1319d 3 \n\np \n0.0129 \n0.0064 \n0.0146 \n0.0052 \n0.0052 \n0 \n0 \n1 \nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi \n0:1316\u00f0d 3 + d\u00de \n\nq \n1.9348 \n1.7498 \n1.9385 \n1.7533 \n1.7559 \n0 \n0 \n0 \n\n(0.03765d 3 + d 2 )/(2 + d) \n0.3102 \n0.2766 \n0.3095 \n0.2758 \n0.2758 \n0 \n0 \n0 \n\nExoplanet \nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi \n0:1319d \n3 =m 1 \n\nq \n0.0845 \n0.0819 \n0.0231 \n0.0052 \n0.0052 \n0 \n0 \n1 \n\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi ffi \nm 2 \n1 m 3 \n2 =d + 0:1319 d \n3 =m 1 \nq \n0.1988 \n0.1636 \n0.1320 \n0.1097 \n>550 \n0 \n0 \n0 \n\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi \n\u00f01 \u00c0 0:7362m 1 \u00ded \n3 =2 \n\nq \n1.2246 \n0.4697 \n1.2418 \n0.4686 \n0.4686 \n0 \n0 \n1 \n\nBinary stars \n1=\u00f0d \n2 m 2 \n1 \u00de + 1=\u00f0dm 2 \n2 \u00de \u00c0 m 3 \n1 m 2 \n2 + \n\nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi ffi \n0:4787d \n3 =m 2 + d \n2 m 2 \n\n2 \n\nq \n0.0023 \n0.0015 \n0.0059 \n0.0050 \nTimeout \n0 \n0 \n0 \n\n\u00f0 \n\nffiffiffiffiffi ffi \nd 3 \n\np \n+ m 3 \n1 m 2 = \n\nffiffiffi \nd \np \n\u00de= \nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi \nm 1 + m 2 \np \n0.0032 \n0.0031 \n0.0038 \n0.0031 \nTimeout \n0 \n0 \n0 \nffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi ffi \nd 3 =\u00f00:9967m 1 + m 2 \u00de \n\nq \n0.0058 \n0.0053 \n0.0014 \n0.0008 \n0.0020 \n1 \n1 \n1 \n\n\nTable 2 |\n2Candidate functions derived from time dilation data, and associated error valuesCandidate \nNumerical Error Absolute \nNumerical Error Relative \nS s.t. Absolute \nS s.t. Relative \nformula \nGen. Reas. Error \nGen. Reas. Error \nf = \n\u03b5 a \n\n2 \n\n\u03b5 a \n\n1 \n\n\u03b5 r \n\n2 \n\n\u03b5 r \n\n1 \n\n\u03b2 a \n\n1,S \n\n1 \n\u03b2 r \n\n1,S \n\n:02 \n\n\u22120.00563v 2 \n0.3822 \n0.3067 \n1.0811 \n0.0018 \n37 \u2264 v \u2264 115 \n37 \u2264 v \u2264 10 8 \n\nv \n\n1 + 0:00689v \u00c0 v \n0.3152 \n0.2097 \n1.0125 \n0.0069 \n37 \u2264 v \u2264 49 \n37 \u2264 v \u2264 38 \n\n\u00c00:00537 v 2 ffiffiffiffiffiffiffiffi ffi \n\nv + v 2 \np \n\n\u00f0v\u00c01\u00de \n\n0.3027 \n0.2299 \n1.2544 \n0.0021 \n37 \u2264 v \u2264 98 \n37 \u2264 v \u2264 109 \n\n\u00c00:00545 \n\nv 4 \n\nffiffiffiffiffiffiffiffiffiffiffiffi \n\nv 2 + v \u00c02 \np \n\u00f0v\u00c01\u00de \n\n0.3238 \n0.2531 \n1.1308 \n0.0010 \n37 \u2264 v \u2264 126 \n37 \u2264 v \u2264 10 7 \n\n\n\nTable 3 |\n3Results on two datasets for theLangmuir problem    1 \n2 \n3 \n4 \n5 \n6 \n7 \nData \nCondition \nCandidate formula \nNumerical Error \nKeYmaera \nK \n\nq = \n\u03b5 r \n\n2 \n\n\u03b5 r \n\n1 \n\nprovability \nconstr. \n\nLangmuir 29 (Table IX) \n2 const. \nf 1 : (p 2 + 2p \u2212 1)/(0.00888p 2 + 0.118p) \n0.0631 \n0.0486 \nTimeout \n2/5 \n\nf 2 : p/(0.00927p + 0.0759) * \n0.1799 \n0.1258 \nYes \n5/5 \n\n4 const. \nf 3 : (p 2 \u2212 10.5p \u2212 15)/(0.00892p 2 \u2212 1.23) \n0.0443 \n0.0295 \nTimeout \n2/5 \n\nf 4 : (8.86p + 13.9)/(0.0787p + 1) \n0.0658 \n0.0465 \nNo \n4/5 \n\nf 5 : p 2 /(0.00895p 2 + 0.0934p \u2212 0.0860) \n0.0759 \n0.0496 \nNo \n2/5 \n\n4 const. extra-point \nf 6 : (p 2 + p)/(0.00890p 2 + 0.106p \u22120.0311) \n0.0683 \n0.0470 \nTimeout \n2/5 \n\nf 7 : (112p 2 \u2212 p)/(p 2 + 10.4p \u2212 9.66) \n0.0771 \n0.0532 \nTimeout \n3/5 \n\nSun et al. 30 (Table 1) \n2 const. \ng 1 : (p + 3)/(0.584p + 4.01) \n0.1625 \n0.1007 \nNo \n4/5 \n\ng 2 : p/(0.709p + 0.157) \n0.9680 \n0.5120 \nYes \n5/5 \n\n4 const. \ng 3 : (0.0298p 2 + 1)/(0.0185p 2 + 1.16) \u2212 0.000905/p 2 \n0.1053 \n0.0538 \nTimeout \n2/5 \n\ng 4 : 1/(p 2 + 1) + (2.53p \u2212 1)/(1.54p + 2.77) \n0.1300 \n0.0725 \nTimeout \n3/5 \n\n4 const. extra-point \ng 5 : (1.74p 2 + 7.61p)/(p 2 + 9.29p + 0.129) \n0.1119 \n0.0996 \nTimeout \n5/5 \n\ng 6 : (0.226p 2 + 0.762p \u2212 7.62 \u22c5 10 \u22124 )/(0.131p 2 + p) \n0.1540 \n0.0935 \nTimeout \n2/5 \n\ng 7 : (4.78p 2 + 26.6p)/(2.71p 2 + 30.4p + 1) \n0.1239 \n0.1364 \nTimeout \n5/5 \n\n\nNature Communications | (2023) 14:1777\n\u00a9 The Author(s) 2023\nAcknowledgementsWe thank J. Ilja Siepmann for initially suggesting adsorption as a problem for symbolic regression. We thank James Chin-wen Chou for providing the atomic clock data. Funding: This work was supported in part by the Defense Advanced Research Projects Agency (DARPA) (PA-18-02-02). The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright notation thereon. T.R.J. was supported by the U.S. Department of Energy (DOE), Office of Basic Energy Sciences, Division of Chemical Sciences, Geosciences and Biosciences (DE-FG02-17ER16362), as well as startup funding from the University of Maryland, Baltimore County. T.R.J. also gratefully acknowledges the University of Minnesota Institute for Mathematics and its Applications (IMA).Author contributionsC.C. conceptualized the overarching derivable symbolic discovery architecture, designed the project, designed and implemented the reasoning module, designed and discussed the experiments, performed the experiments for the reasoning module and for the comparison with the state of the art, analyzed and formatted the data, formalized the scientific theories, formatted code and data for the release, wrote and edited the manuscript, and designed the figures. S.D. conceptualized the overarching derivable symbolic discovery architecture, designed the project, designed the SR module architecture, designed and discussed the experiments, performed the experiments for the SR module, analyzed and formatted the data, and wrote and edited the manuscript. V.A. designed and implemented the SR module. T.R.J. identified target problems and experimental datasets, formalized the scientific theories, discussed the experiments, designed the figures, and wrote and edited the manuscript. J.G. prepared the data, executed the computational experiments for the SR module and for the comparison with the state of the art, formatted code and data for the release, and edited the manuscript. K.C. discussed and designed the overarching project, discussed the experiments, and edited and revised the manuscript. N.M. discussed and designed the overarching project, discussed the experiments, provided conceptual advice, and edited the manuscript. B.E.K. designedfigure 1, discussed the reasoning measures, and edited the manuscript. L.H. conceptualized the overarching derivable symbolic discovery architecture, designed the project, designed the experiments, analyzed the results per validation of the framework, and wrote and edited the manuscript.Competing interestsThe authors declare no competing interests. Correspondence and requests for materials should be addressed to Cristina Cornelio or Lior Horesh.Peer review information Nature Communications thanks Joseph Scott, Hiroaki Kitano and the other, anonymous reviewer(s) for their contribution to the peer review of this work. Peer review reports are available.Reprints and permissions information is available at http://www.nature.com/reprintsPublisher's note Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.Open Access This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article's Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article's Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit http://creativecommons.org/ licenses/by/4.0/.\nGenetic Programming: On the Programming of Computers by Means of Natural Selection. J R Koza, MIT PressCambridgeKoza, J. R. Genetic Programming: On the Programming of Compu- ters by Means of Natural Selection. (MIT Press, Cambridge, 1992).\n\nGenetic Programming II: Automatic Discovery of Reusable Programs. J R Koza, MIT PressCambridgeKoza, J. R. Genetic Programming II: Automatic Discovery of Reusable Programs. (MIT Press, Cambridge, 1994).\n\nDistilling free-form natural laws from experimental data. M Schmidt, H Lipson, Science. 324Schmidt, M. & Lipson, H. Distilling free-form natural laws from experimental data. Science 324, 81-85 (2009).\n\nExtrapolation and learning equations. G Martius, C H Lampert, Proceedings of the 29th Conference on Neural Information Processing Systems (NIPS-16. the 29th Conference on Neural Information Processing Systems (NIPS-16Martius, G. & Lampert, C. H. Extrapolation and learning equations. In Proceedings of the 29th Conference on Neural Information Proces- sing Systems (NIPS-16) (2016).\n\nDiscovering physical concepts with neural networks. R Iten, T Metger, H Wilming, L Rio, R Renner, Physical Review Letters. 124Iten, R., Metger, T., Wilming, H., Rio, L. & Renner, R. Discovering physical concepts with neural networks. Physical Review Letters 124, (2020).\n\nA physics-inspired method for symbolic regression. S.-M Udrescu, M Tegmark, Feynman, Science Advances. 616Udrescu, S.-M. & Tegmark, M. AI Feynman: A physics-inspired method for symbolic regression. Science Advances 6.16 (2020).\n\nComplexity of semialgebraic proofs. D Grigoryev, E Hirsch, D Pasechnik, Moscow Math. J. 2Grigoryev, D., Hirsch, E. & Pasechnik, D. Complexity of semi- algebraic proofs. Moscow Math. J. 2, 647-679 (2002).\n\nA deep reinforcement learning based approach to learning transferable proof guidance strategies. M Crouse, Proceedings of the Thirty-Fifth AAAI Conference on Artificial Intelligence (AAAI-21. the Thirty-Fifth AAAI Conference on Artificial Intelligence (AAAI-21Crouse, M. et al. A deep reinforcement learning based approach to learning transferable proof guidance strategies. In Proceedings of the Thirty-Fifth AAAI Conference on Artificial Intelligence (AAAI- 21) (2021).\n\nStructured semidefinite programs and semialgebraic geometry methods in robustness and optimization. P A Parrilo, Caltech. Ph.D. thesisParrilo, P. A. Structured semidefinite programs and semialgebraic geometry methods in robustness and optimization. Ph.D. thesis, Caltech, Pasadena (2000).\n\nSum-of-squares proofs and the quest toward optimal algorithms. B Barak, D Steurer, International Congress of Mathematicians (ICM). Seoul, South KoreaBarak, B. & Steurer, D. Sum-of-squares proofs and the quest toward optimal algorithms. International Congress of Mathematicians (ICM), Seoul, South Korea, August 13-21, 2014.\n\nLearning dynamic polynomial proofs. A Fawzi, M Malinowski, H Fawzi, O Fawzi, Proceedings of Advances in Neural Information Processing Systems (NeurIPS). Advances in Neural Information Processing Systems (NeurIPS)32Fawzi, A., Malinowski, M., Fawzi, H. & Fawzi, O. Learning dynamic polynomial proofs. In Proceedings of Advances in Neural Informa- tion Processing Systems (NeurIPS) 32, 41817-4190 (2019).\n\nConstraint-based visual generation. G Marra, F Giannini, M Diligenti, M Gori, Artificial Neural Networks and Machine Learning -ICANN 2019: Image Processing: 28th International Conference on Artificial Neural Networks, Proceedings. Marra, G., Giannini, F., Diligenti, M. & Gori, M. Constraint-based visual generation. In Artificial Neural Networks and Machine Learn- ing -ICANN 2019: Image Processing: 28th International Conference on Artificial Neural Networks, Proceedings, 565-577 (2019).\n\nJ Scott, M Panju, V Ganesh, Lgml, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence34Logic Guided Machine LearningScott, J., Panju, M., & Ganesh, V. LGML: Logic Guided Machine Learning (Student Abstract). In Proceedings of the AAAI Conference on Artificial Intelligence, 34, 13909-13910 (2020).\n\nLogic guided genetic algorithms (student abstract). D Ashok, J Scott, S J Wetzel, M Panju, V Ganesh, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence35Ashok, D., Scott, J., Wetzel, S. J., Panju, M. & Ganesh, V. Logic gui- ded genetic algorithms (student abstract). In Proceedings of the AAAI Conference on Artificial Intelligence 35, 15753-15754 (2021).\n\nSymbolic regression driven by training data and prior knowledge. J Kubal\u00edk, E Derner, R Babu\u0161ka, Proceedings of the 2020 Genetic and Evolutionary Computation Conference. the 2020 Genetic and Evolutionary Computation ConferenceKubal\u00edk, J., Derner, E. & Babu\u0161ka, R. Symbolic regression driven by training data and prior knowledge. In Proceedings of the 2020 Genetic and Evolutionary Computation Conference, 958-966 (2020).\n\nSymbolic regression via genetic programming. D A Augusto, H J Barbosa, Proceedings 6th Brazilian Symp. Neural Networks. 6th Brazilian Symp. Neural NetworksIEEEAugusto, D. A. & Barbosa, H. J. Symbolic regression via genetic programming. In Proceedings 6th Brazilian Symp. Neural Networks, 173-178 (IEEE, 2000).\n\nGlobally optimal symbolic regression. V Austel, NIPS Symposium on Interpretable Machine Learning. Austel, V. et al. Globally optimal symbolic regression. NIPS Sym- posium on Interpretable Machine Learning (2017).\n\nData-and theory-driven techniques for surrogate-based optimization. A Cozad, Pittsburgh, PACarnegie MellonPh.D. thesisCozad, A. Data-and theory-driven techniques for surrogate-based optimization. Ph.D. thesis, Carnegie Mellon, Pittsburgh, PA (2014).\n\nA global MINLP approach to symbolic regression. A Cozad, N V Sahinidis, Math. Program. Ser. B. 170Cozad, A. & Sahinidis, N. V. A global MINLP approach to symbolic regression. Math. Program. Ser. B 170, 97-119 (2018).\n\nKeYmaera X: An axiomatic tactical theorem prover for hybrid systems. N Fulton, S Mitsch, J.-D Quesel, M V\u00f6lp, A Platzer, Proceedings of the International Conference on Automated Deduction. the International Conference on Automated Deduction25Fulton, N., Mitsch, S., Quesel, J.-D., V\u00f6lp, M. & Platzer, A. KeYmaera X: An axiomatic tactical theorem prover for hybrid systems. In Proceedings of the International Conference on Automated Deduction, CADE-25 (2015).\n\n. Wolfram Mathematica, 12Wolfram Mathematica. https://www.wolfram.com. Version: 12.\n\nBayesian experimental design for symbolic discovery. K L Clarkson, Preprint atClarkson, K. L. et al. Bayesian experimental design for symbolic discovery. Preprint at https://arxiv.org/abs/2211.15860 (2022).\n\n. Nasa Planets Factsheet, NASA. Planets Factsheet. https://nssdc.gsfc.nasa.gov/planetary/ factsheet/ (2017).\n\n. Nasa Exoplanet Archive, NASA. Exoplanet Archive. https://exoplanetarchive.ipac.caltech. edu/ (2017).\n\nOrbits of five visual binary stars. B Novakovi\u0107, Baltic Astronomy. 16Novakovi\u0107, B. Orbits of five visual binary stars. Baltic Astronomy 16, 435-442 (2007).\n\nOptical clocks and relativity. C W Chou, D B Hume, T Rosenband, D J Wineland, Science. 329Chou, C. W., Hume, D. B., Rosenband, T. & Wineland, D. J. Optical clocks and relativity. Science 329, 1630-1632 (2010).\n\nA simple derivation of time dilation and length contraction in special relativity. F Behroozi, Phys. Teach. 52Behroozi, F. A simple derivation of time dilation and length con- traction in special relativity. Phys. Teach. 52, 410-412 (2014).\n\nA simple electromagnetic model for the light clock of special relativity. G S Smith, Eur. J. Phys. 32Smith, G. S. A simple electromagnetic model for the light clock of special relativity. Eur. J. Phys. 32, 1585-1595 (2011).\n\nThe adsorption of gases on plane surfaces of glass, mica and platinum. I Langmuir, J. Amer. Chem. Soc. 40Langmuir, I. The adsorption of gases on plane surfaces of glass, mica and platinum. J. Amer. Chem. Soc. 40, 1361-1403 (1918).\n\nAdsorption equilibria of C1 to C4 alkanes, CO2, and SF6 on silicalite. M S Sun, D B Shah, H H Xu, O Talu, J. Phys. Chem. 102Sun, M. S., Shah, D. B., Xu, H. H. & Talu, O. Adsorption equilibria of C1 to C4 alkanes, CO2, and SF6 on silicalite. J. Phys. Chem. 102, 1466-1473 (1998).\n\nAbduction. I Douven, The Stanford Encyclopedia of Philosophy. Zalta, E. N.Metaphysics Research Lab, Stanford UniversitySummer 2021 ednDouven, I. Abduction. In Zalta, E. N. (ed.) The Stanford Encyclopedia of Philosophy (Metaphysics Research Lab, Stanford University, 2021), Summer 2021 edn.\n\nSemantic search in millions of equations. L Pfahler, K Morik, Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, KDD-20. the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, KDD-20Association for Computing MachineryPfahler, L. & Morik, K. Semantic search in millions of equations. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining, KDD-20, 135-143 (Association for Computing Machinery, 2020).\n\nMathAlign: Linking formula identifiers to their contextual natural language descriptions. M Alexeeva, Proceedings of the 12th Language Resources and Evaluation Conference. the 12th Language Resources and Evaluation ConferenceEuropean Language Resources AssociationAlexeeva, M. et al. MathAlign: Linking formula identifiers to their contextual natural language descriptions. In Proceedings of the 12th Language Resources and Evaluation Conference, 2204-2212 (Eur- opean Language Resources Association, 2020).\n\nTranslating math formula images to LaTeX sequences using deep neural networks with sequence-level training. Z Wang, J.-C S Liu, Int. J. Document Anal. Recognit. 24Wang, Z. & Liu, J.-C. S. Translating math formula images to LaTeX sequences using deep neural networks with sequence-level train- ing. Int. J. Document Anal. Recognit. 24, 63-75 (2021).\n\nNumerical methods for experimental design of large-scale linear ill-posed inverse problems. E Haber, L Horesh, L Tenorio, Inverse Problems. 2455012Haber, E., Horesh, L. & Tenorio, L. Numerical methods for experi- mental design of large-scale linear ill-posed inverse problems. Inverse Problems 24, 055012 (2008).\n\nAI-Descartes GitHub repository] Combining data and theory for derivable scientific discovery with AI-Descartes. C Cornelio, Cornelio, C. et al. [AI-Descartes GitHub repository] Combining data and theory for derivable scientific discovery with AI-Descartes. https://github.com/IBM/AI-Descartes (2023).\n", "annotations": {"author": "[{\"end\":300,\"start\":123},{\"end\":387,\"start\":301},{\"end\":475,\"start\":388},{\"end\":700,\"start\":476},{\"end\":789,\"start\":701},{\"end\":882,\"start\":790},{\"end\":971,\"start\":883},{\"end\":1062,\"start\":972},{\"end\":1206,\"start\":1063}]", "publisher": null, "author_last_name": "[{\"end\":140,\"start\":132},{\"end\":313,\"start\":309},{\"end\":401,\"start\":395},{\"end\":493,\"start\":484},{\"end\":715,\"start\":706},{\"end\":808,\"start\":800},{\"end\":897,\"start\":890},{\"end\":988,\"start\":982},{\"end\":1080,\"start\":1069}]", "author_first_name": "[{\"end\":131,\"start\":123},{\"end\":308,\"start\":301},{\"end\":394,\"start\":388},{\"end\":481,\"start\":476},{\"end\":483,\"start\":482},{\"end\":705,\"start\":701},{\"end\":797,\"start\":790},{\"end\":799,\"start\":798},{\"end\":889,\"start\":883},{\"end\":978,\"start\":972},{\"end\":981,\"start\":979},{\"end\":1068,\"start\":1063}]", "author_affiliation": "[{\"end\":236,\"start\":165},{\"end\":299,\"start\":238},{\"end\":386,\"start\":315},{\"end\":474,\"start\":403},{\"end\":606,\"start\":495},{\"end\":699,\"start\":608},{\"end\":788,\"start\":717},{\"end\":881,\"start\":810},{\"end\":970,\"start\":899},{\"end\":1061,\"start\":990},{\"end\":1153,\"start\":1082},{\"end\":1205,\"start\":1155}]", "title": "[{\"end\":97,\"start\":1},{\"end\":1303,\"start\":1207}]", "venue": "[{\"end\":1328,\"start\":1305}]", "abstract": "[{\"end\":5033,\"start\":1446}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b11\"},\"end\":5783,\"start\":5781},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":5905,\"start\":5903},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":5925,\"start\":5923},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":6207,\"start\":6205},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":11852,\"start\":11849},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":11855,\"start\":11852},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":11858,\"start\":11855},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":11860,\"start\":11858},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":11964,\"start\":11960},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":11968,\"start\":11964},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":11972,\"start\":11968},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":12823,\"start\":12821},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":16099,\"start\":16097},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":18044,\"start\":18040},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":18065,\"start\":18063},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":25939,\"start\":25937},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":26046,\"start\":26044},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":26275,\"start\":26273},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":28500,\"start\":28498},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":29027,\"start\":29024},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":29194,\"start\":29192},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":29296,\"start\":29294},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":29786,\"start\":29784},{\"end\":32801,\"start\":32787},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":33764,\"start\":33762},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":33936,\"start\":33934},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":35818,\"start\":35816},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":36816,\"start\":36815},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":39265,\"start\":39263},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":39363,\"start\":39361},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":39489,\"start\":39487},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":39650,\"start\":39648}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":39979,\"start\":39803},{\"attributes\":{\"id\":\"fig_1\"},\"end\":40042,\"start\":39980},{\"attributes\":{\"id\":\"fig_2\"},\"end\":40193,\"start\":40043},{\"attributes\":{\"id\":\"fig_3\"},\"end\":40221,\"start\":40194},{\"attributes\":{\"id\":\"fig_4\"},\"end\":40379,\"start\":40222},{\"attributes\":{\"id\":\"fig_5\"},\"end\":40584,\"start\":40380},{\"attributes\":{\"id\":\"fig_6\"},\"end\":40944,\"start\":40585},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":42915,\"start\":40945},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":43650,\"start\":42916},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":44997,\"start\":43651}]", "paragraph": "[{\"end\":6522,\"start\":5035},{\"end\":7096,\"start\":6579},{\"end\":8299,\"start\":7098},{\"end\":9152,\"start\":8334},{\"end\":11744,\"start\":9199},{\"end\":12618,\"start\":11746},{\"end\":13291,\"start\":12620},{\"end\":14082,\"start\":13293},{\"end\":15519,\"start\":14110},{\"end\":15951,\"start\":15534},{\"end\":16608,\"start\":15953},{\"end\":16835,\"start\":16620},{\"end\":17031,\"start\":16878},{\"end\":17518,\"start\":17145},{\"end\":18561,\"start\":17813},{\"end\":18699,\"start\":18563},{\"end\":19280,\"start\":18701},{\"end\":19701,\"start\":19282},{\"end\":19898,\"start\":19703},{\"end\":21018,\"start\":20177},{\"end\":21713,\"start\":21020},{\"end\":22045,\"start\":21715},{\"end\":22438,\"start\":22047},{\"end\":23358,\"start\":22496},{\"end\":24858,\"start\":23360},{\"end\":25398,\"start\":24860},{\"end\":25761,\"start\":25429},{\"end\":26401,\"start\":25840},{\"end\":27322,\"start\":26403},{\"end\":28397,\"start\":27324},{\"end\":28642,\"start\":28432},{\"end\":28851,\"start\":28674},{\"end\":29712,\"start\":28919},{\"end\":29832,\"start\":29714},{\"end\":30322,\"start\":29834},{\"end\":30728,\"start\":30374},{\"end\":32066,\"start\":30745},{\"end\":32102,\"start\":32068},{\"end\":32451,\"start\":32144},{\"end\":32869,\"start\":32453},{\"end\":33196,\"start\":32871},{\"end\":33715,\"start\":33198},{\"end\":34125,\"start\":33717},{\"end\":34449,\"start\":34172},{\"end\":35366,\"start\":34451},{\"end\":36068,\"start\":35368},{\"end\":37647,\"start\":36070},{\"end\":37955,\"start\":37649},{\"end\":39385,\"start\":37957},{\"end\":39528,\"start\":39407},{\"end\":39802,\"start\":39550}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":17144,\"start\":17032},{\"attributes\":{\"id\":\"formula_1\"},\"end\":17812,\"start\":17519},{\"attributes\":{\"id\":\"formula_2\"},\"end\":20176,\"start\":19899},{\"attributes\":{\"id\":\"formula_3\"},\"end\":22495,\"start\":22439},{\"attributes\":{\"id\":\"formula_4\"},\"end\":25839,\"start\":25762},{\"attributes\":{\"id\":\"formula_5\"},\"end\":28673,\"start\":28643},{\"attributes\":{\"id\":\"formula_6\"},\"end\":28918,\"start\":28852},{\"attributes\":{\"id\":\"formula_8\"},\"end\":30373,\"start\":30323},{\"attributes\":{\"id\":\"formula_9\"},\"end\":30744,\"start\":30729},{\"attributes\":{\"id\":\"formula_10\"},\"end\":32143,\"start\":32103}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":20366,\"start\":20359},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":21276,\"start\":21269},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":23003,\"start\":22996},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":24350,\"start\":24343},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":26413,\"start\":26406},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":28050,\"start\":28043},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":29306,\"start\":29297},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":32881,\"start\":32874}]", "section_header": "[{\"end\":6532,\"start\":6525},{\"end\":6577,\"start\":6535},{\"end\":8332,\"start\":8302},{\"end\":9197,\"start\":9155},{\"end\":14108,\"start\":14085},{\"end\":15532,\"start\":15522},{\"end\":16618,\"start\":16611},{\"end\":16876,\"start\":16838},{\"end\":25427,\"start\":25401},{\"end\":28430,\"start\":28400},{\"end\":34170,\"start\":34128},{\"end\":39405,\"start\":39388},{\"end\":39548,\"start\":39531},{\"end\":39805,\"start\":39804},{\"end\":39989,\"start\":39981},{\"end\":40052,\"start\":40044},{\"end\":40203,\"start\":40195},{\"end\":40389,\"start\":40381},{\"end\":40594,\"start\":40586},{\"end\":40953,\"start\":40946},{\"end\":42926,\"start\":42917},{\"end\":43661,\"start\":43652}]", "table": "[{\"end\":42915,\"start\":40955},{\"end\":43650,\"start\":43008},{\"end\":44997,\"start\":43714}]", "figure_caption": "[{\"end\":39979,\"start\":39806},{\"end\":40042,\"start\":39991},{\"end\":40193,\"start\":40054},{\"end\":40221,\"start\":40205},{\"end\":40379,\"start\":40224},{\"end\":40584,\"start\":40391},{\"end\":40944,\"start\":40596},{\"end\":43008,\"start\":42928},{\"end\":43714,\"start\":43663}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":8981,\"start\":8973},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":13363,\"start\":13357},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":13859,\"start\":13853},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":20762,\"start\":20756},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":25248,\"start\":25240},{\"end\":31778,\"start\":31772},{\"end\":32778,\"start\":32752},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":33462,\"start\":33456},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":34682,\"start\":34676},{\"end\":37524,\"start\":37498},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":38131,\"start\":38124}]", "bib_author_first_name": "[{\"end\":49147,\"start\":49146},{\"end\":49149,\"start\":49148},{\"end\":49370,\"start\":49369},{\"end\":49372,\"start\":49371},{\"end\":49565,\"start\":49564},{\"end\":49576,\"start\":49575},{\"end\":49747,\"start\":49746},{\"end\":49758,\"start\":49757},{\"end\":49760,\"start\":49759},{\"end\":50145,\"start\":50144},{\"end\":50153,\"start\":50152},{\"end\":50163,\"start\":50162},{\"end\":50174,\"start\":50173},{\"end\":50181,\"start\":50180},{\"end\":50419,\"start\":50415},{\"end\":50430,\"start\":50429},{\"end\":50630,\"start\":50629},{\"end\":50643,\"start\":50642},{\"end\":50653,\"start\":50652},{\"end\":50896,\"start\":50895},{\"end\":51372,\"start\":51371},{\"end\":51374,\"start\":51373},{\"end\":51625,\"start\":51624},{\"end\":51634,\"start\":51633},{\"end\":51923,\"start\":51922},{\"end\":51932,\"start\":51931},{\"end\":51946,\"start\":51945},{\"end\":51955,\"start\":51954},{\"end\":52326,\"start\":52325},{\"end\":52335,\"start\":52334},{\"end\":52347,\"start\":52346},{\"end\":52360,\"start\":52359},{\"end\":52782,\"start\":52781},{\"end\":52791,\"start\":52790},{\"end\":52800,\"start\":52799},{\"end\":53190,\"start\":53189},{\"end\":53199,\"start\":53198},{\"end\":53208,\"start\":53207},{\"end\":53210,\"start\":53209},{\"end\":53220,\"start\":53219},{\"end\":53229,\"start\":53228},{\"end\":53619,\"start\":53618},{\"end\":53630,\"start\":53629},{\"end\":53640,\"start\":53639},{\"end\":54021,\"start\":54020},{\"end\":54023,\"start\":54022},{\"end\":54034,\"start\":54033},{\"end\":54036,\"start\":54035},{\"end\":54325,\"start\":54324},{\"end\":54569,\"start\":54568},{\"end\":54800,\"start\":54799},{\"end\":54809,\"start\":54808},{\"end\":54811,\"start\":54810},{\"end\":55039,\"start\":55038},{\"end\":55049,\"start\":55048},{\"end\":55062,\"start\":55058},{\"end\":55072,\"start\":55071},{\"end\":55080,\"start\":55079},{\"end\":55439,\"start\":55432},{\"end\":55569,\"start\":55568},{\"end\":55571,\"start\":55570},{\"end\":55729,\"start\":55725},{\"end\":55737,\"start\":55730},{\"end\":55839,\"start\":55835},{\"end\":55849,\"start\":55840},{\"end\":55974,\"start\":55973},{\"end\":56126,\"start\":56125},{\"end\":56128,\"start\":56127},{\"end\":56136,\"start\":56135},{\"end\":56138,\"start\":56137},{\"end\":56146,\"start\":56145},{\"end\":56159,\"start\":56158},{\"end\":56161,\"start\":56160},{\"end\":56389,\"start\":56388},{\"end\":56622,\"start\":56621},{\"end\":56624,\"start\":56623},{\"end\":56844,\"start\":56843},{\"end\":57076,\"start\":57075},{\"end\":57078,\"start\":57077},{\"end\":57085,\"start\":57084},{\"end\":57087,\"start\":57086},{\"end\":57095,\"start\":57094},{\"end\":57097,\"start\":57096},{\"end\":57103,\"start\":57102},{\"end\":57296,\"start\":57295},{\"end\":57618,\"start\":57617},{\"end\":57629,\"start\":57628},{\"end\":58187,\"start\":58186},{\"end\":58714,\"start\":58713},{\"end\":58725,\"start\":58721},{\"end\":58727,\"start\":58726},{\"end\":59048,\"start\":59047},{\"end\":59057,\"start\":59056},{\"end\":59067,\"start\":59066},{\"end\":59382,\"start\":59381}]", "bib_author_last_name": "[{\"end\":49154,\"start\":49150},{\"end\":49377,\"start\":49373},{\"end\":49573,\"start\":49566},{\"end\":49583,\"start\":49577},{\"end\":49755,\"start\":49748},{\"end\":49768,\"start\":49761},{\"end\":50150,\"start\":50146},{\"end\":50160,\"start\":50154},{\"end\":50171,\"start\":50164},{\"end\":50178,\"start\":50175},{\"end\":50188,\"start\":50182},{\"end\":50427,\"start\":50420},{\"end\":50438,\"start\":50431},{\"end\":50447,\"start\":50440},{\"end\":50640,\"start\":50631},{\"end\":50650,\"start\":50644},{\"end\":50663,\"start\":50654},{\"end\":50903,\"start\":50897},{\"end\":51382,\"start\":51375},{\"end\":51631,\"start\":51626},{\"end\":51642,\"start\":51635},{\"end\":51929,\"start\":51924},{\"end\":51943,\"start\":51933},{\"end\":51952,\"start\":51947},{\"end\":51961,\"start\":51956},{\"end\":52332,\"start\":52327},{\"end\":52344,\"start\":52336},{\"end\":52357,\"start\":52348},{\"end\":52365,\"start\":52361},{\"end\":52788,\"start\":52783},{\"end\":52797,\"start\":52792},{\"end\":52807,\"start\":52801},{\"end\":52813,\"start\":52809},{\"end\":53196,\"start\":53191},{\"end\":53205,\"start\":53200},{\"end\":53217,\"start\":53211},{\"end\":53226,\"start\":53221},{\"end\":53236,\"start\":53230},{\"end\":53627,\"start\":53620},{\"end\":53637,\"start\":53631},{\"end\":53648,\"start\":53641},{\"end\":54031,\"start\":54024},{\"end\":54044,\"start\":54037},{\"end\":54332,\"start\":54326},{\"end\":54575,\"start\":54570},{\"end\":54806,\"start\":54801},{\"end\":54821,\"start\":54812},{\"end\":55046,\"start\":55040},{\"end\":55056,\"start\":55050},{\"end\":55069,\"start\":55063},{\"end\":55077,\"start\":55073},{\"end\":55088,\"start\":55081},{\"end\":55451,\"start\":55440},{\"end\":55580,\"start\":55572},{\"end\":55747,\"start\":55738},{\"end\":55857,\"start\":55850},{\"end\":55984,\"start\":55975},{\"end\":56133,\"start\":56129},{\"end\":56143,\"start\":56139},{\"end\":56156,\"start\":56147},{\"end\":56170,\"start\":56162},{\"end\":56398,\"start\":56390},{\"end\":56630,\"start\":56625},{\"end\":56853,\"start\":56845},{\"end\":57082,\"start\":57079},{\"end\":57092,\"start\":57088},{\"end\":57100,\"start\":57098},{\"end\":57108,\"start\":57104},{\"end\":57303,\"start\":57297},{\"end\":57626,\"start\":57619},{\"end\":57635,\"start\":57630},{\"end\":58196,\"start\":58188},{\"end\":58719,\"start\":58715},{\"end\":58731,\"start\":58728},{\"end\":59054,\"start\":59049},{\"end\":59064,\"start\":59058},{\"end\":59075,\"start\":59068},{\"end\":59391,\"start\":59383}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":49301,\"start\":49062},{\"attributes\":{\"id\":\"b1\"},\"end\":49504,\"start\":49303},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":7366016},\"end\":49706,\"start\":49506},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":13253311},\"end\":50090,\"start\":49708},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":51865583},\"end\":50362,\"start\":50092},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":167217655},\"end\":50591,\"start\":50364},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":1555301},\"end\":50796,\"start\":50593},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":207881094},\"end\":51269,\"start\":50798},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":122626142},\"end\":51559,\"start\":51271},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":7460982},\"end\":51884,\"start\":51561},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":174799595},\"end\":52287,\"start\":51886},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":50774118},\"end\":52779,\"start\":52289},{\"attributes\":{\"id\":\"b12\"},\"end\":53135,\"start\":52781},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":235363891},\"end\":53551,\"start\":53137},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":216553809},\"end\":53973,\"start\":53553},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":41000755},\"end\":54284,\"start\":53975},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":51991832},\"end\":54498,\"start\":54286},{\"attributes\":{\"id\":\"b17\"},\"end\":54749,\"start\":54500},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":49414701},\"end\":54967,\"start\":54751},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":10192340},\"end\":55428,\"start\":54969},{\"attributes\":{\"id\":\"b20\"},\"end\":55513,\"start\":55430},{\"attributes\":{\"id\":\"b21\"},\"end\":55721,\"start\":55515},{\"attributes\":{\"id\":\"b22\"},\"end\":55831,\"start\":55723},{\"attributes\":{\"id\":\"b23\"},\"end\":55935,\"start\":55833},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":118414542},\"end\":56092,\"start\":55937},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":124455011},\"end\":56303,\"start\":56094},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":122304716},\"end\":56545,\"start\":56305},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":124817393},\"end\":56770,\"start\":56547},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":93633665},\"end\":57002,\"start\":56772},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":99838684},\"end\":57282,\"start\":57004},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":240780461},\"end\":57573,\"start\":57284},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":220073736},\"end\":58094,\"start\":57575},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":218974195},\"end\":58603,\"start\":58096},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":202542423},\"end\":58953,\"start\":58605},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":6826238},\"end\":59267,\"start\":58955},{\"attributes\":{\"id\":\"b35\"},\"end\":59569,\"start\":59269}]", "bib_title": "[{\"end\":49562,\"start\":49506},{\"end\":49744,\"start\":49708},{\"end\":50142,\"start\":50092},{\"end\":50413,\"start\":50364},{\"end\":50627,\"start\":50593},{\"end\":50893,\"start\":50798},{\"end\":51369,\"start\":51271},{\"end\":51622,\"start\":51561},{\"end\":51920,\"start\":51886},{\"end\":52323,\"start\":52289},{\"end\":53187,\"start\":53137},{\"end\":53616,\"start\":53553},{\"end\":54018,\"start\":53975},{\"end\":54322,\"start\":54286},{\"end\":54797,\"start\":54751},{\"end\":55036,\"start\":54969},{\"end\":55971,\"start\":55937},{\"end\":56123,\"start\":56094},{\"end\":56386,\"start\":56305},{\"end\":56619,\"start\":56547},{\"end\":56841,\"start\":56772},{\"end\":57073,\"start\":57004},{\"end\":57293,\"start\":57284},{\"end\":57615,\"start\":57575},{\"end\":58184,\"start\":58096},{\"end\":58711,\"start\":58605},{\"end\":59045,\"start\":58955}]", "bib_author": "[{\"end\":49156,\"start\":49146},{\"end\":49379,\"start\":49369},{\"end\":49575,\"start\":49564},{\"end\":49585,\"start\":49575},{\"end\":49757,\"start\":49746},{\"end\":49770,\"start\":49757},{\"end\":50152,\"start\":50144},{\"end\":50162,\"start\":50152},{\"end\":50173,\"start\":50162},{\"end\":50180,\"start\":50173},{\"end\":50190,\"start\":50180},{\"end\":50429,\"start\":50415},{\"end\":50440,\"start\":50429},{\"end\":50449,\"start\":50440},{\"end\":50642,\"start\":50629},{\"end\":50652,\"start\":50642},{\"end\":50665,\"start\":50652},{\"end\":50905,\"start\":50895},{\"end\":51384,\"start\":51371},{\"end\":51633,\"start\":51624},{\"end\":51644,\"start\":51633},{\"end\":51931,\"start\":51922},{\"end\":51945,\"start\":51931},{\"end\":51954,\"start\":51945},{\"end\":51963,\"start\":51954},{\"end\":52334,\"start\":52325},{\"end\":52346,\"start\":52334},{\"end\":52359,\"start\":52346},{\"end\":52367,\"start\":52359},{\"end\":52790,\"start\":52781},{\"end\":52799,\"start\":52790},{\"end\":52809,\"start\":52799},{\"end\":52815,\"start\":52809},{\"end\":53198,\"start\":53189},{\"end\":53207,\"start\":53198},{\"end\":53219,\"start\":53207},{\"end\":53228,\"start\":53219},{\"end\":53238,\"start\":53228},{\"end\":53629,\"start\":53618},{\"end\":53639,\"start\":53629},{\"end\":53650,\"start\":53639},{\"end\":54033,\"start\":54020},{\"end\":54046,\"start\":54033},{\"end\":54334,\"start\":54324},{\"end\":54577,\"start\":54568},{\"end\":54808,\"start\":54799},{\"end\":54823,\"start\":54808},{\"end\":55048,\"start\":55038},{\"end\":55058,\"start\":55048},{\"end\":55071,\"start\":55058},{\"end\":55079,\"start\":55071},{\"end\":55090,\"start\":55079},{\"end\":55453,\"start\":55432},{\"end\":55582,\"start\":55568},{\"end\":55749,\"start\":55725},{\"end\":55859,\"start\":55835},{\"end\":55986,\"start\":55973},{\"end\":56135,\"start\":56125},{\"end\":56145,\"start\":56135},{\"end\":56158,\"start\":56145},{\"end\":56172,\"start\":56158},{\"end\":56400,\"start\":56388},{\"end\":56632,\"start\":56621},{\"end\":56855,\"start\":56843},{\"end\":57084,\"start\":57075},{\"end\":57094,\"start\":57084},{\"end\":57102,\"start\":57094},{\"end\":57110,\"start\":57102},{\"end\":57305,\"start\":57295},{\"end\":57628,\"start\":57617},{\"end\":57637,\"start\":57628},{\"end\":58198,\"start\":58186},{\"end\":58721,\"start\":58713},{\"end\":58733,\"start\":58721},{\"end\":59056,\"start\":59047},{\"end\":59066,\"start\":59056},{\"end\":59077,\"start\":59066},{\"end\":59393,\"start\":59381}]", "bib_venue": "[{\"end\":49144,\"start\":49062},{\"end\":49367,\"start\":49303},{\"end\":49592,\"start\":49585},{\"end\":49854,\"start\":49770},{\"end\":50213,\"start\":50190},{\"end\":50465,\"start\":50449},{\"end\":50679,\"start\":50665},{\"end\":50988,\"start\":50905},{\"end\":51391,\"start\":51384},{\"end\":51690,\"start\":51644},{\"end\":52037,\"start\":51963},{\"end\":52518,\"start\":52367},{\"end\":52876,\"start\":52815},{\"end\":53299,\"start\":53238},{\"end\":53721,\"start\":53650},{\"end\":54093,\"start\":54046},{\"end\":54382,\"start\":54334},{\"end\":54566,\"start\":54500},{\"end\":54844,\"start\":54823},{\"end\":55156,\"start\":55090},{\"end\":55566,\"start\":55515},{\"end\":56002,\"start\":55986},{\"end\":56179,\"start\":56172},{\"end\":56411,\"start\":56400},{\"end\":56644,\"start\":56632},{\"end\":56873,\"start\":56855},{\"end\":57123,\"start\":57110},{\"end\":57344,\"start\":57305},{\"end\":57741,\"start\":57637},{\"end\":58266,\"start\":58198},{\"end\":58764,\"start\":58733},{\"end\":59093,\"start\":59077},{\"end\":59379,\"start\":59269},{\"end\":49925,\"start\":49856},{\"end\":51058,\"start\":50990},{\"end\":51710,\"start\":51692},{\"end\":52098,\"start\":52039},{\"end\":52924,\"start\":52878},{\"end\":53347,\"start\":53301},{\"end\":53779,\"start\":53723},{\"end\":54130,\"start\":54095},{\"end\":55209,\"start\":55158},{\"end\":57832,\"start\":57743},{\"end\":58321,\"start\":58268}]"}}}, "year": 2023, "month": 12, "day": 17}