{"id": 220484640, "updated": "2023-11-08 08:02:35.366", "metadata": {"title": "Deep Feedback Network for Recommendation", "authors": "[{\"first\":\"Ruobing\",\"last\":\"Xie\",\"middle\":[]},{\"first\":\"Cheng\",\"last\":\"Ling\",\"middle\":[]},{\"first\":\"Yalong\",\"last\":\"Wang\",\"middle\":[]},{\"first\":\"Rui\",\"last\":\"Wang\",\"middle\":[]},{\"first\":\"Feng\",\"last\":\"Xia\",\"middle\":[]},{\"first\":\"Leyu\",\"last\":\"Lin\",\"middle\":[]}]", "venue": "Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence", "journal": "Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence", "publication_date": {"year": 2020, "month": null, "day": null}, "abstract": "Both explicit and implicit feedbacks can reflect user opinions on items, which are essential for learning user preferences in recommendation. However, most current recommendation algorithms merely focus on implicit positive feedbacks (e.g., click), ignoring other informative user behaviors. In this paper, we aim to jointly consider explicit/implicit and positive/negative feedbacks to learn user unbiased preferences for recommendation. Specifically, we propose a novel Deep feedback network (DFN) modeling click, unclick and dislike behaviors. DFN has an internal feedback interaction component that captures fine-grained interactions between individual behaviors, and an external feedback interaction component that uses precise but relatively rare feedbacks (click/dislike) to extract useful information from rich but noisy feedbacks (unclick). In experiments, we conduct both offline and online evaluations on a real-world recommendation system WeChat Top Stories used by millions of users. The significant improvements verify the effectiveness and robustness of DFN. The source code is in https://github.com/qqxiaochongqq/DFN.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": "3035313290", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/ijcai/XieLWWXL20", "doi": "10.24963/ijcai.2020/349"}}, "content": {"source": {"pdf_hash": "26aa0719e1719b70e33fff51e0a8ccf6ac3a60c7", "pdf_src": "MergedPDFExtraction", "pdf_uri": null, "oa_url_match": false, "oa_info": {"license": null, "open_access_url": "https://www.ijcai.org/proceedings/2020/0349.pdf", "status": "BRONZE"}}, "grobid": {"id": "d96fbd380f87e0af2dbacbfc75ad93e52c64465f", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/26aa0719e1719b70e33fff51e0a8ccf6ac3a60c7.txt", "contents": "\nDeep Feedback Network for Recommendation\n\n\nRuobing Xie ruobingxie@tencent.com \nWeChat Search Application Department\nTencentChina\n\nCheng Ling \nWeChat Search Application Department\nTencentChina\n\nYalong Wang \nWeChat Search Application Department\nTencentChina\n\nRui Wang \nWeChat Search Application Department\nTencentChina\n\nFeng Xia \nWeChat Search Application Department\nTencentChina\n\nLeyu Lin \nWeChat Search Application Department\nTencentChina\n\nDeep Feedback Network for Recommendation\n\nBoth explicit and implicit feedbacks can reflect user opinions on items, which are essential for learning user preferences in recommendation. However, most current recommendation algorithms merely focus on implicit positive feedbacks (e.g., click), ignoring other informative user behaviors. In this paper, we aim to jointly consider explicit/implicit and positive/negative feedbacks to learn user unbiased preferences for recommendation. Specifically, we propose a novel Deep feedback network (DFN) modeling click, unclick and dislike behaviors. DFN has an internal feedback interaction component that captures fine-grained interactions between individual behaviors, and an external feedback interaction component that uses precise but relatively rare feedbacks (click/dislike) to extract useful information from rich but noisy feedbacks (unclick). In experiments, we conduct both offline and online evaluations on a real-world recommendation system WeChat Top Stories used by millions of users. The significant improvements verify the effectiveness and robustness of DFN. The source code is in https://github.com/qqxiaochongqq/DFN.\n\nIntroduction\n\nPersonalized recommendation systems aim to provide customized items for users according to their preferences. They have been widely used in various fields including video [Covington et al., 2016] and E-commerce [Feng et al., 2019].\n\nThere are plenty of recommendation systems personalized with user-item interactions. Such informative signals are categorized into two types, namely the explicit feedback and the implicit feedback [Liu et al., 2010]. The explicit feedback comes from user direct opinions on items (e.g., star ratings or like/dislike). It could precisely indicate users' real preferences, while it is rather challenging to collect such feedback. In contrast, the implicit feedback mainly derives from user behaviors that imply indirect opinions (e.g., click or unclick). It is much easier to collect such implicit feedbacks from enormous numbers of user behaviors in real-world recommenda- * indicates equal contribution tion systems. However, implicit feedbacks struggle with their inherent noises and the natural scarcity of negative feedbacks, which gravely harm the accuracy in learning user's unbiased preferences [Hu et al., 2008].\n\n\nImplicit positive feedback (click) WeChat Top Stories\n\nBreaking news! IJCAI-2020 will be held on July.\n\nMichelin recommendation: Top 10 delicious food you can not miss.\n\n\nIJCAI committee\n\nMichelin restaurant click Implicit negative feedback (unclick)\n\n\nWeChat Top Stories\n\nBreaking news! IJCAI-2020 will be held on July.\n\nMichelin recommendation: Top 10 delicious food you can not miss.\n\n\nIJCAI committee\n\n\nMichelin restaurant\n\n\nExplicit negative feedback (dislike) WeChat Top Stories\n\nBreaking news! IJCAI-2020 will be held on July.\n\nMichelin recommendation: Top 10 delicious food you can not miss. Recently, recommendation systems usually regard the personalized recommendation as a Click-Through Rate (CTR) prediction task. Therefore, it is natural that most recommendation algorithms mainly concentrate on the implicit positive feedbacks such as clicks, which could be easily collected in practice. These models are directly optimized with click behaviors and CTR-oriented objectives, which will inevitably result in the following problems. First, CTR-oriented objectives usually concentrate on what users like, ignoring what users dislike. Simply relying on these implicit positive feedbacks will make models tend to provide homogeneous and myopic results, which will eventually harm user experiences [Zhao et al., 2018a]. Therefore, negative feedbacks should be considered in recommendation. Second, besides passively receiving information chosen by models, users also need effective and efficient feedback mechanisms to actively interact with recommendation systems. Moreover, there are also gaps between users' implicit feedbacks and their real preferences (click does not always mean like) . It confirms the necessity of explicit feedbacks in recommendation.\n\nMultiple explicit/implicit and positive/negative feedbacks can complement each other and reflect user unbiased preferences in recommendation. There are some efforts jointly con-sider both explicit and implicit feedbacks with Collaborative filtering [Liu et al., 2010] and multi-task learning [Hadash et al., 2018]. However, the negative feedbacks in these works are usually ignored or only locate in explicit feedbacks, which are precise but rare. Some works consider unclick or missing behaviors as implicit negative feedbacks to multiply negative signals [Zhao et al., 2018b]. Unfortunately, the noises in such implicit negative feedbacks crucially limit the performances, since these implicit negative feedbacks may be caused by various reasons besides dislike [He et al., 2016].\n\nIn this paper, we concentrate on improving recommendation performances with different types of explicit/implicit and positive/negative feedbacks. To address the problems in conventional methods, we propose a novel Deep feedback network (DFN), which jointly considers multiple feedbacks and their interactions in deep model based recommendation. Fig 1 shows a brief example of different types of feedbacks used in DFN, including implicit positive feedback (i.e., click), implicit negative feedback (i.e., unclick) and explicit negative feedback (i.e., dislike). Specifically, we first conduct transformer over the target item and behaviors separately in each feedback sequence to capture internal behavior-level interactions. Next, we utilize high-quality but relatively rare click and dislike behaviors to denoise rich but noisy unclick behaviors with external feedback-level interactions. These distilled feedback features are combined with other features and then fed into the feature interaction module with Wide, FM and Deep components. The main advantage of DFN is that it successfully combines multiple feedbacks to learn user unbiased positive and negative preferences for recommendation, which solves the dilemma of quality and quantity in feedbacks.\n\nIn experiments, we conduct both offline and online evaluations on a well-known recommendation system WeChat Top Stories widely used by hundreds of millions of users. We also conduct parameter analyses and ablation tests to show the effectiveness and robustness of our model. The main contributions of DFN are concluded as follows:\n\n\u2022 To the best of our knowledge, we are the first to combine implicit positive feedbacks, implicit negative feedbacks, explicit negative feedbacks and their interactions in deep neural recommendation.\n\n\u2022 We propose a novel deep feedback network, which creatively uses both internal and external feedback interactions to learn user unbiased preferences. We also jointly consider multiple feedback losses in optimization.\n\n\u2022 The significant improvements in both offline and online evaluations confirm the effectiveness and robustness of DFN in real-world recommendation systems.  et al., 2010]. There are plenty of efforts that jointly consider multiple feedbacks with CF [Koren, 2008;Liu et al., 2010;Zhang et al., 2018], bayesian ranking model [Liu et al., 2017] and weak supervision [Jadidinejad et al., 2019]. Some works aim to conduct feature mapping or transfer learning to build relations between explicit and implicit feedbacks [Pan et al., 2016]. Most algorithms combine explicit and implicit feedbacks in multi-task learning framework [Hadash et al., 2018;Jadidinejad et al., 2019] to jointly solve ranking and rating tasks. In DFN, we use high-quality but relatively rare explicit feedbacks to guild feature extraction in rich but noisy implicit negative feedbacks for CTR and dislike prediction.\n\nNegative Feedbacks. Negative feedbacks are essential for modeling user preferences but hard to collect [Jawaheer et al., 2010]. Conventional methods usually regard all missing or unclicked data as negative feedbacks in CF-based models [Hu et al., 2008]. However, it also brings in large numbers of noises, since unclick does not always indicate dislike . To distill the real negative signals in implicit feedbacks, some models use exposure variables [Liang et al., 2016] or popularity [He et al., 2016]. Zhao et al.\n\n[2018b] conducts reinforcement learning with both click and unclick sequences as features. In contrast, explicit negative feedbacks could directly reflect user's negative opinions [Jawaheer et al., 2010;Zhao et al., 2018a], while their scarcity limits their usage in deep-based models. To the best of our knowledge, we are the first to encode click, unclick, dislike behaviors and their interactions into deep neural recommendation, considering negative signals in both implicit and explicit feedbacks.\n\n\nMethodology\n\nWe aim to jointly consider multiple explicit/implicit and positive/negative feedbacks to learn user unbiased preferences for recommendation. Specifically, we conduct the DFN model on a real-world recommendation system, and collect three types of feedbacks in user historical behaviors as follows:\n\n\u2022 Implicit positive feedbacks. The implicit positive feedbacks are the most widely-used feedbacks in large-scale recommendation, which are satisfactory in both quantity and quality. Following most conventional models, we consider the click behavior sequence {c 1 , \u00b7 \u00b7 \u00b7 , c n1 } as the implicit positive feedback used in DFN. \u2022 Explicit negative feedbacks. Explicit feedbacks are high-quality but rare in read-world recommendation. We  use the dislike button attached to each item to collect explicit negative feedback sequence as {d 1 , \u00b7 \u00b7 \u00b7 , d n2 }. \u2022 Implicit negative feedbacks. We regard the impressed but unclick behavior sequence {u 1 , \u00b7 \u00b7 \u00b7 , u n3 } as the implicit negative feedbacks. This unclick behavior is the vast majority of all types of feedbacks, while it seriously struggles with noises and false-negative signals.\n\nDFN attempts to use high-quality click and dislike behaviors as instructors to extract useful information from unclick behaviors. It is also easy to add other feedbacks in DFN.\n\n\nOverall Architecture\n\nThe Deep feedback network mainly consists of two modules, namely the deep feedback interaction module and the feature interaction module. First, the deep feedback interaction module takes multiple feedbacks as inputs to extract user unbiased positive and negative preferences, with the help of internal and external feedback interactions. Second, the refined feedback features are combined with other informative features such as user profiles, item features and recommendation contexts. We implement Wide, FM and Deep components for feature aggregation. Finally, the outputs of feature interaction module are fed into fully connected and Softmax layers for model optimization with both positive and negative losses. \n\n\nDeep Feedback Interaction Module\n\nThe deep feedback interaction module in Fig 2 (b) takes implicit positive (click), explicit negative (dislike) and implicit negative (unclick) feedbacks with target item as inputs. We conduct two components to learn from the interactions inside and between different types of feedbacks.\n\n\nInternal Feedback Interaction Component\n\nThis component focuses on the interactions between target item and individual behaviors within a certain type of feedback. We conduct a multi-head self-attention over behaviors following Vaswani et al. [2017]. All behavior features consist of their item embeddings and position embeddings, and are projected into a joint semantic space to form the behavior embeddings. Taking the click behavior for instance, we combine the target item t with the behavior embeddings of click sequence to form the input matrix B c = {t, c 1 , \u00b7 \u00b7 \u00b7 , c n1 }.\n\nThe query, key, value matrices are calculated as:\nQ = W Q B c , K = W K B c , V = W V B c ,(1)\nwhere W Q , W K , W V are projection matrices. We then calculate the self-attention as follows:\nAttention(Q, K, V) = softmax( Q K \u221a n h )V,(2)\nwhere n h is the dimension of query, key and value. The i-th head of the total h multi-heads is calculated as:\nhead i = Attention(W Q i Q, W K i K, W V i V).(3)W Q i , W K i , W V i \u2208 R n h \u00d7n h /h\nare weighting matrices for the i-th head. The final output matrix of self-attention is:\nF c = concat(head 1 , \u00b7 \u00b7 \u00b7 , head h ) \u00b7 W O ,(4)\nW O \u2208 R n h \u00d7n h is a projection matrix. Finally, we conduct an average pooling over all n + 1 output embeddings in F c to generate the implicit positive feedback embedding f c as:\nf c = Average pooling(F c ), f c \u2208 R n h .(5)\nWe also use the same transformer with type-specific hyperparameters to generate the explicit negative feedback embedding f d and the implicit negative feedback embedding f u from dislike and unclick behaviors respectively. The internal feedback interaction component well captures behavior-level interactions between target item and behaviors in each type of feedback sequence. It can provide user positive and negative preferences related to the target item.\n\nExternal Feedback Interaction Component Implicit negative feedbacks are sufficient but extremely noisy. In general, unclick behaviors seem to imply negative signals, while items exposed to users are carefully chosen by certain strategies, which may also contain user interests from coarsegrained aspects. The external feedback interaction component aims to distinguish what users really like and dislike in unclick behaviors, according to strong feedbacks in click and dislike behaviors. Specifically, we conduct two vanilla attentions, which considers implicit positive and explicit negative feedback embeddings f c and f d as instructors to guild positive and negative preference extractions from unclick sequences {u 1 , \u00b7 \u00b7 \u00b7 , u n3 }. We formalize the unclick-dislike interaction embedding f ud with dislike and unclick behaviors as:\nf ud = n3 i=1 \u03b1 i u i , \u03b1 i = f (f d , u i ) n3 j=1 f (f d , u j ) ,(6)\nwhere the weighting score function f (a, b) is defined as: f (a, b) = MLP (concat(a, b, a \u2212 b, a b)).\n\nWe regard as the element-wise product and use a 2-layer Multi-layer perceptron (MLP). f d contains user's strong negative preferences refined from explicit negative feedbacks related to target item. It helps vanilla attention to extract items that users truly dislike in unclick behaviors. We also amplify the positive voices in unclick behaviors with implicit positive feedback embedding f c similarly as follows:\nf uc = n3 i=1 \u03b2 i u i , \u03b2 i = f (f c , u i ) n3 j=1 f (f c , u j ) .(8)\nAt last, we combine all five feedback features to generate the final refined feedback feature f F eed as follows:\nf F eed = {f c , f d , f u , f uc , f ud }.(9)\nThe implicit positive and explicit negative feedbacks f c and f d are regarded as strong positive and negative signals, while the rest unclick-related feedbacks are regarded as weak signals.\n\n\nFeature Interaction Module\n\nIn feature interaction, we combine the refined feedback feature with other features including user profiles, item features and recommendation contexts. Following Guo et al.\n\n[2017], we group these sparse features into m fields {x 1 , \u00b7 \u00b7 \u00b7 , x m } including continuous fields (e.g., age) and categorical fields (e.g., location \ny W ide i = w i x i + b i , w i , x i \u2208 R n f i .(10\n) w i is the weighting vector of the i-th one-hot field embedding x i , and b i is the bias. n f i is the dimension of x i . FM Component The FM component captures the secondorder feature interactions between all features. The input embeddings of FM is the combination of all dense features and final refined feedback features as F = {f 1 , \u00b7 \u00b7 \u00b7 , f m , f F eed }. We follow the Bi-interaction layer in He and Chua [2017] and generate the output embedding y F M as follows:\ny F M = m+5 i=1 m+5 j=i+1 f i f j , f i , f j \u2208 F .(11)\nDeep Component In Deep component, we implement a 2layer MLP to learn high-order feature interactions. The input is the concatenation of dense features and feedback features represented as f (0) = concat(f 1 , \u00b7 \u00b7 \u00b7 , f m , f F eed ). We have:\ny Deep = f (2) , f (i+1) = ReLU(W (i) f (i) + b (i) ),(12)\nwhere f (i) is the output embedding of the i-th layer. W (i) is the weighting matrix and b (i) is the bias of the i-th layer. Finally, we concatenate all outputs from three components to generate the aggregated feature embedding y as:\ny = concat(y W ide , y F M , y Deep ).(13)\n\nOptimization Objective\n\nWe utilize click, unclick and dislike behaviors for supervised training. The predicted click probability is calculated with the aggregated feature embedding y as follows:\np(x) = \u03c3(w p y).(14)\nw p is the weighting vector, and \u03c3(\u00b7) is the sigmoid function. The loss function of DFN consists of three parts corresponding to click, unclick and dislike behaviors as:\nL = \u2212 1 N (\u03bb c Sc log p(x) + \u03bb u Su log(1 \u2212 p(x)) + \u03bb d S d log(1 \u2212 p(x))).(15)\nThe train set has N instances grouped into click set S c , dislike set S d and unclick set S u . \u03bb c , \u03bb d , \u03bb u are weights of different losses to measure the importances of different feedbacks.\n\n\nExperiments\n\n\nDatasets\n\nSince there are few large-scale datasets having click, unclick and dislike behaviors, we build a new dataset MultiFeed from a real-world recommendation system WeChat Top Stories after data masking. Precisely, we randomly collect 448 million user behaviors from 20.3 million users on 3.1 million items, considering the behaviors in the first few days as train set and the rest as test set. These user behaviors include implicit positive (click), implicit negative ( \n\n\nCompetitors and Experimental Settings\n\nCompetitors We implement eight classical models as baselines for evaluation. All models (DFN and baselines) use the same features including all feedbacks for fair comparisons.\n\nProceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence (IJCAI-20)\n\n\u2022 FM [Rendle, 2010]. Factorization machine (FM) models second-order feature interactions for CTR prediction. FM is considered as the base model in evaluation. , for these models usually rely on customized feedbacks or multi-task learning, which are hard to be adapted to our CTR and dislike prediction tasks. Experimental Settings In DFN, the max length of all three behavior sequences is 30 and the feature field number is 47. The dimension of each feature embeddings n h = 64, and the dimension of 2-layer MLP in Deep is 32 and 16. In training, we utilize Adam with the batch size to be 64. The weights of click, unclick and dislike losses \u03bb c : \u03bb u : \u03bb d = 1 : 1 : 10. We conduct the grid search for parameters. All models follow the same experimental settings for fair comparisons.\n\n\nCTR Prediction\n\nWe first evaluate DFN on the classical CTR prediction to verify its capability in modeling user positive preferences. Evaluation Protocol In CTR prediction task, we utilize a widely-used metric Area Under Curve (AUC) for evaluation. Following Yan et al. [2014], we further bring in RelaImpr to measure the relative improvements over base model (i.e., FM in our setting). Since AUC is 0.5 from a random strategy, the RelaImpr in this task is formalized as:\nRelaImpr = AUC(measured model) \u2212 0.5 AUC(base model) \u2212 0.5 \u2212 1.(16)\nWe do not use Logloss as evaluation metric, for the loss functions of DFN and other baselines are different. Experimental Results Table 2 shows the results of CTR prediction on MultiFeed, from which we can find that:\n\n(1) DFN significantly outperforms all baselines on AUC and achieves 11.85% relative improvement over base model. We also conduct a significance test to verify that DFN outperforms baselines with the significance level \u03b1 = 0.01. Note that all baselines also use multiple feedbacks as features. The impressive improvements over strong baselines indicate that DFN could well capture informative messages in implicit and  explicit feedbacks, which are essential for modeling user unbiased positive preferences in recommendation.\n\n(2) The advantages of DFN mainly derive from the deep feedback interaction module. First, the internal feedback interaction component successfully captures fine-grained interactions between the target item and individual behaviors with transformer. It could extract user preferences from behaviorlevel interactions inside different types of feedbacks. Second, the external feedback interaction component uses precise but relatively rare feedbacks to denoise rich but noisy unclick behaviors with vanilla attention. Therefore, DFN can solve the dilemma of quantity and quality. In ablation test, we will give detailed analyses on different components of DFN.\n\n\nDislike Prediction\n\nThe significant improvements in CTR prediction have shown that DFN could well learn user positive preferences. In this subsection, we further propose a new dislike prediction task to evaluate DFN in modeling user negative preferences. Evaluation Protocol The dislike behavior usually indicates a strong negative signal. A timely feedback mechanism could rapidly capture user's instant preferences from dislike behaviors and improve user experience. We propose the dislike prediction task, which aims to predict what users dislike in recommended items and avoid disappointing users. Following CTR prediction, we also use AUC and RelaImpr as metrics, regarding 1 \u2212 p(x) as the predicted dislike probability.   Table 3 demonstrates the results of dislike prediction. We can observe that:\n\n\nExperimental Results\n\n(1) DFN achieves the best performance on AUC with the significance level \u03b1 = 0.01. It indicates that DFN could learn both user positive and negative preferences and respond timely to explicit negative feedbacks. Note that dislike prediction needs algorithms to make fine-grained discriminations, for all impressed items (including disliked items) are relatively good candidates selected by algorithms. Currently, dislike behavior only accounts for 0.15% of all feedbacks in our system, while it has already shown its power in CTR and dislike predictions. The improvements will be more significant with the mutual promotion of more negative feedbacks and better models.\n\n(2) The impressive improvement comes from two points: (i) DFN considers explicit negative feedbacks in loss function, which directly optimizes the dislike prediction. (ii) The deep feedback interaction module brings in both internal and external feedback interactions, which better extracts informative user unbiased preferences for recommendation.\n\n(3) For fair models comparisons, we further add the dislike loss in DFN to some strong baselines (e.g., DIN+). The results are also improved but still far worse than DFN, which confirms the power of both dislike loss and the feedback interaction module of DFN. Moreover, we find that the relative performances of baselines on CTR and dislike predictions are different. It is natural since they do not specifically optimize dislike loss, and thus are unstable in dislike prediction.\n\n\nAblation Tests\n\nIn Table 4, we conduct an ablation test to show the effectiveness and necessity of different components in deep feedback interaction module. We observe that: (1) DFN (click) performs better than DFN (w/o feedbacks), which confirms the significance of click behaviors. (2) The significant improvement from DFN (click) to DFN (internal) also verifies that unclick and dislike behaviors could provide complementary information that helps to learn user unbiased preferences. (3) Comparing with DFN (internal) and DFN (All), we can find that the external feedback interaction still makes a notable improvement, which confirms that the external feedback interaction component is beneficial in DFN.   Experimental Results We find that: (1) DFN achieves consistent improvements on CTR and LCTR metrics over DIN, which confirms that DFN performs well in real-world CTR prediction. The improvement of AUT also implies that users are willing to spend more time using our system, since DFN could provide better recommended items. (2) The significant improvement in DTR shows that DFN is capable of modeling user negative preferences in recommendation, which is essential for improving user experience in practice.  \n\n\nParameter Analysis\n\nWe further conduct a parameter analysis on different weights of dislike loss \u03bb d in Eq. (15) to measure the impact of dislike loss function on both CTR and dislike prediction. In Fig. 3, we evaluate DFN with different \u03bb d on these two task. We find that: (1) in CTR prediction, DFN achieves the best performance when \u03bb d = 10. The performance will get worse if \u03bb d is set too low or too high. It indicates that dislike feedbacks are useful not only as features, but also as loss function, while too many weights on dislike feedbacks will harm the learning of user positive preferences.\n\n(2) As \u03bb d grows bigger, the performance of dislike prediction also becomes better, while the AUC growth will gradually slow down when \u03bb d gets too high. It is natural that the dislike loss function could benefit dislike prediction, which has also been verified in Sec. 4.4. However, the performance growth is not endless, which confirms the importance of balancing positive and negative feedbacks. In experiments, we choose \u03bb d = 10 to jointly consider both CTR (we concern more about) and dislike prediction tasks.\n\n\nConclusion and Future Work\n\nIn this paper, we propose a Deep feedback network (DFN), which considers both explicit/implicit and positive/negative feedbacks to learn user unbiased preferences. DFN uses internal behavior-level and external feedback-level interactions in multiple feedbacks. The significant improvements in offline and online verify the effectiveness and robustness of DFN. In future, we will use more sophisticated ranking models for feature interactions. Moreover, we will explore other explicit feedbacks to improve recommendation interpretability.\n\nFigure 1 :\n1An example of multiple feedbacks in WeChat Top Stories.\n\nFigure 2 :\n2The overall architecture of Deep feedback network and deep feedback interaction module.\n\n\nFig 2 (a)illustrates the overall architecture of DFN.\n\n\u2022\nWide&Deep [Cheng et al., 2016]. Wide&Deep consists of a Wide part that handles raw features, and a Deep part that extracts high-order feature interactions.\u2022 NFM[He and Chua, 2017]. NFM uses a bi-interaction layer before DNN layers for feature interaction.\u2022 AFM [Xiao et al., 2017]. AFM brings in attention over feature interactions from the bi-interaction layer. \u2022 DeepFM [Guo et al., 2017]. DeepFM replaces the Wide component in Wide&Deep with a FM layer. \u2022 DCN [Wang et al., 2017]. DCN captures the boundeddegree feature interactions with its cross network. \u2022 DIN [Zhou et al., 2018]. DIN is a classical model for session-based recommendation. It considers the weights of items in user historical behaviors with attention. \u2022 AutoInt [Song et al., 2019]. AutoInt introduces selfattentive neural network for feature interactions. We do not compare with other models like Hadash et al. [2018] and Jadidinejad et al. [2019]\n\nFigure 3 :\n3Analysis on different weights of dislike loss \u03bb d .\n\n\n). All fields are represented as one-hot embeddings. A lookup table is used to generate the dense feature of all fields as {f 1 , \u00b7 \u00b7 \u00b7 , f m }. We implement Wide, FM and Deep components for feature interaction. Wide Component The Wide component is a generalized linear model widely used in recommendation[Cheng et al., 2016]. The output of the Wide component y W ide is a mdimensional vector, where the i-th element is calculated as:\n\nTable 2 :\n2Results of CTR prediction on MultiFeed dataset.\n\nTable 3 :\n3Results of dislike prediction on MultiFeed dataset.\n\nTable 4 :\n4Ablation tests for DFN on CTR prediction.4.6 Online A/B TestOnline System and Evaluation Protocol We conduct an online A/B test to evaluate DFN on WeChat Top Stories used by millions of users. The compared baseline is DIN with other online modules unchanged. We use four evaluation metrics including CTR, list-wise CTR (LCTR), average using time (AUT) and dislike-through rate (DTR). We conduct the A/B test with nearly 870 thousand users, and report the improvements instead of detailed values inTable 5.\n\n\nDFN+1.17% +0.65% +0.52% -33.17%model \nCTR \nLCTR \nAUT \nDTR \n\n\n\nTable 5 :\n5Online A/B tests on WeChat Top Stories.\nProceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence \n\nXiangnan He and Tat-Seng Chua. Neural factorization machines for sparse predictive analytics. [ References, Cheng, Hanwang Zhang, Min-Yen Kan, and Tat-Seng Chua. Fast matrix factorization for online recommendation with implicit feedback. Guy Hadash, Oren Sar Shalom, and Rita OsadchyProceedings of SIGIRReferences [Cheng et al., 2016] Heng-Tze Cheng, Levent Koc, Jeremi- ah Harmsen, Tal Shaked, Tushar Chandra, Hrishi Aradhye, Glen Anderson, Greg Corrado, Wei Chai, Mustafa Ispir, et al. Wide & deep learning for recommender systems. In Proceedings of the 1st workshop on deep learning for recommender systems, 2016. [Covington et al., 2016] Paul Covington, Jay Adams, and Emre Sargin. Deep neural networks for youtube recom- mendations. In Proceedings of RecSys, 2016. [Feng et al., 2019] Yufei Feng, Fuyu Lv, Weichen Shen, Menghan Wang, Fei Sun, Yu Zhu, and Keping Yang. Deep session interest network for click-through rate prediction. In Proceedings of IJCAI, 2019. [Guo et al., 2017] Huifeng Guo, Ruiming Tang, Yunming Ye, Zhenguo Li, and Xiuqiang He. Deepfm: a factorization-machine based neural network for ctr predic- tion. In Proceedings of IJCAI, 2017. [Hadash et al., 2018] Guy Hadash, Oren Sar Shalom, and Rita Osadchy. Rank and rate: multi-task learning for rec- ommender systems. In Proceedings of RecSys, 2018. [He and Chua, 2017] Xiangnan He and Tat-Seng Chua. Neu- ral factorization machines for sparse predictive analytics. In Proceedings of SIGIR, 2017. [He et al., 2016] Xiangnan He, Hanwang Zhang, Min-Yen Kan, and Tat-Seng Chua. Fast matrix factorization for on- line recommendation with implicit feedback. In Proceed- ings of SIGIR, 2016.\n\nMenghan Wang, Mingming Gong, Xiaolin Zheng, and Kun Zhang. Modeling dynamic missingness of implicit feedback for recommendation. Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence. Zhou, Jinze Bai, Junshuai Song, Xiaofei Liu, Zhengchao Zhao, Xiusi Chen, and Jun Gaothe Twenty-Ninth International Joint Conference on Artificial IntelligenceQuangui Zhang, Longbing Cao, Chengzhang Zhu, Zhiqiang Li, and Jinguang Sun. IJCAI-20et al., 2008] Yifan Hu, Yehuda Koren, and Chris Volin- sky. Collaborative filtering for implicit feedback datasets. In Proceedings of ICDM, 2008. [Jadidinejad et al., 2019] Amir H Jadidinejad, Craig Mac- donald, and Iadh Ounis. Unifying explicit and implicit feedback for rating prediction and ranking recommenda- tion tasks. In Proceedings of ICTIR, 2019. [Jawaheer et al., 2010] Gawesh Jawaheer, Martin Szomszor, and Patty Kostkova. Comparison of implicit and explicit feedback from an online music recommendation service. In proceedings of HetRec, 2010. [Koren, 2008] Yehuda Koren. Factorization meets the neigh- borhood: a multifaceted collaborative filtering model. In Proceedings of KDD, 2008. [Liang et al., 2016] Dawen Liang, Laurent Charlin, James McInerney, and David M Blei. Modeling user exposure in recommendation. In Proceedings of WWW, 2016. [Liu et al., 2010] Nathan N Liu, Evan W Xiang, Min Zhao, and Qiang Yang. Unifying explicit and implicit feedback for collaborative filtering. In Proceedings of CIKM, 2010. [Liu et al., 2017] Jian Liu, Chuan Shi, Binbin Hu, Shenghua Liu, and S Yu Philip. Personalized ranking recommenda- tion via integrating multiple feedbacks. In PAKDD, 2017. [Pan et al., 2016] Weike Pan, Shanchuan Xia, Zhuode Liu, Xiaogang Peng, and Zhong Ming. Mixed factorization for collaborative recommendation with heterogeneous explicit feedbacks. Information Sciences, 2016. [Rendle, 2010] Steffen Rendle. Factorization machines. In Proceedings of ICDM, 2010. [Sarwar et al., 2001] Badrul Munir Sarwar, George Karypis, Joseph A Konstan, John Riedl, et al. Item-based collabora- tive filtering recommendation algorithms. In WWW, 2001. [Song et al., 2019] Weiping Song, Chence Shi, Zhiping Xi- ao, Zhijian Duan, Yewen Xu, Ming Zhang, and Jian Tang. Autoint: Automatic feature interaction learning via self- attentive neural networks. In Proceedings of CIKM, 2019. [Sun et al., 2019] Fei Sun, Jun Liu, Jian Wu, Changhua Pei, Xiao Lin, Wenwu Ou, and Peng Jiang. Bert4rec: Sequen- tial recommendation with bidirectional encoder represen- tations from transformer. In Proceedings of CIKM, 2019. [Vaswani et al., 2017] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Proceedings of NIPS, 2017. [Wang et al., 2017] Ruoxi Wang, Bin Fu, Gang Fu, and Min- gliang Wang. Deep & cross network for ad click predic- tions. In Proceedings of ADKDD, 2017. [Wang et al., 2018] Menghan Wang, Mingming Gong, Xi- aolin Zheng, and Kun Zhang. Modeling dynamic miss- ingness of implicit feedback for recommendation. In Pro- ceedings of NIPS, 2018. [Xiao et al., 2017] Jun Xiao, Hao Ye, Xiangnan He, Han- wang Zhang, Fei Wu, and Tat-Seng Chua. Attentional factorization machines: Learning the weight of feature in- teractions via attention networks. In IJCAI, 2017. [Yan et al., 2014] Ling Yan, Wu-Jun Li, Gui-Rong Xue, and Dingyi Han. Coupled group lasso for web-scale ctr pre- diction in display advertising. In Proceedings of ICML, 2014. [Zhang et al., 2018] Quangui Zhang, Longbing Cao, Chengzhang Zhu, Zhiqiang Li, and Jinguang Sun. Cou- pledcf: Learning explicit and implicit user-item couplings in recommendation for deep collaborative filtering. In Proceedings of IJCAI, 2018. [Zhao et al., 2018a] Qian Zhao, F Maxwell Harper, Gedim- inas Adomavicius, and Joseph A Konstan. Explicit or implicit feedback? engagement or satisfaction?: a field experiment on machine-learning-based recommender sys- tems. In Proceedings of SAC, 2018. [Zhao et al., 2018b] Xiangyu Zhao, Liang Zhang, Zhuoye Ding, Long Xia, Jiliang Tang, and Dawei Yin. Recom- mendations with negative feedback via pairwise deep re- inforcement learning. In Proceedings of KDD, 2018. [Zhou et al., 2018] Chang Zhou, Jinze Bai, Junshuai Song, Xiaofei Liu, Zhengchao Zhao, Xiusi Chen, and Jun Gao. Atrank: An attention-based user behavior modeling frame- work for recommendation. In Proceedings of AAAI, 2018. Proceedings of the Twenty-Ninth International Joint Conference on Artificial Intelligence (IJCAI-20)\n", "annotations": {"author": "[{\"end\":130,\"start\":44},{\"end\":193,\"start\":131},{\"end\":257,\"start\":194},{\"end\":318,\"start\":258},{\"end\":379,\"start\":319},{\"end\":440,\"start\":380}]", "publisher": null, "author_last_name": "[{\"end\":55,\"start\":52},{\"end\":141,\"start\":137},{\"end\":205,\"start\":201},{\"end\":266,\"start\":262},{\"end\":327,\"start\":324},{\"end\":388,\"start\":385}]", "author_first_name": "[{\"end\":51,\"start\":44},{\"end\":136,\"start\":131},{\"end\":200,\"start\":194},{\"end\":261,\"start\":258},{\"end\":323,\"start\":319},{\"end\":384,\"start\":380}]", "author_affiliation": "[{\"end\":129,\"start\":80},{\"end\":192,\"start\":143},{\"end\":256,\"start\":207},{\"end\":317,\"start\":268},{\"end\":378,\"start\":329},{\"end\":439,\"start\":390}]", "title": "[{\"end\":41,\"start\":1},{\"end\":481,\"start\":441}]", "venue": null, "abstract": "[{\"end\":1616,\"start\":483}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":1827,\"start\":1803},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":1862,\"start\":1843},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2080,\"start\":2062},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2783,\"start\":2766},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":4113,\"start\":4093},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":4823,\"start\":4805},{\"end\":4869,\"start\":4848},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":5133,\"start\":5113},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":5337,\"start\":5320},{\"end\":7522,\"start\":7509},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":7614,\"start\":7601},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":7631,\"start\":7614},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":7650,\"start\":7631},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":7693,\"start\":7675},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":7741,\"start\":7715},{\"end\":7883,\"start\":7865},{\"end\":7995,\"start\":7974},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":8020,\"start\":7995},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":8364,\"start\":8341},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":8490,\"start\":8473},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":8708,\"start\":8688},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":8740,\"start\":8723},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":8958,\"start\":8935},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":8977,\"start\":8958},{\"end\":11902,\"start\":11896},{\"end\":16185,\"start\":16179},{\"end\":18368,\"start\":18354},{\"end\":19413,\"start\":19407},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":27871,\"start\":27851}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":26396,\"start\":26328},{\"attributes\":{\"id\":\"fig_1\"},\"end\":26497,\"start\":26397},{\"attributes\":{\"id\":\"fig_2\"},\"end\":26553,\"start\":26498},{\"attributes\":{\"id\":\"fig_3\"},\"end\":27478,\"start\":26554},{\"attributes\":{\"id\":\"fig_4\"},\"end\":27543,\"start\":27479},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":27980,\"start\":27544},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":28040,\"start\":27981},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":28104,\"start\":28041},{\"attributes\":{\"id\":\"tab_9\",\"type\":\"table\"},\"end\":28622,\"start\":28105},{\"attributes\":{\"id\":\"tab_10\",\"type\":\"table\"},\"end\":28685,\"start\":28623},{\"attributes\":{\"id\":\"tab_11\",\"type\":\"table\"},\"end\":28737,\"start\":28686}]", "paragraph": "[{\"end\":1863,\"start\":1632},{\"end\":2784,\"start\":1865},{\"end\":2889,\"start\":2842},{\"end\":2955,\"start\":2891},{\"end\":3037,\"start\":2975},{\"end\":3107,\"start\":3060},{\"end\":3173,\"start\":3109},{\"end\":3320,\"start\":3273},{\"end\":4554,\"start\":3322},{\"end\":5338,\"start\":4556},{\"end\":6598,\"start\":5340},{\"end\":6930,\"start\":6600},{\"end\":7131,\"start\":6932},{\"end\":7350,\"start\":7133},{\"end\":8236,\"start\":7352},{\"end\":8753,\"start\":8238},{\"end\":9257,\"start\":8755},{\"end\":9569,\"start\":9273},{\"end\":10407,\"start\":9571},{\"end\":10585,\"start\":10409},{\"end\":11327,\"start\":10610},{\"end\":11650,\"start\":11364},{\"end\":12235,\"start\":11694},{\"end\":12286,\"start\":12237},{\"end\":12427,\"start\":12332},{\"end\":12585,\"start\":12475},{\"end\":12760,\"start\":12673},{\"end\":12991,\"start\":12811},{\"end\":13497,\"start\":13038},{\"end\":14337,\"start\":13499},{\"end\":14511,\"start\":14410},{\"end\":14927,\"start\":14513},{\"end\":15113,\"start\":15000},{\"end\":15351,\"start\":15161},{\"end\":15554,\"start\":15382},{\"end\":15709,\"start\":15556},{\"end\":16237,\"start\":15763},{\"end\":16536,\"start\":16294},{\"end\":16830,\"start\":16596},{\"end\":17069,\"start\":16899},{\"end\":17260,\"start\":17091},{\"end\":17536,\"start\":17341},{\"end\":18028,\"start\":17563},{\"end\":18245,\"start\":18070},{\"end\":18347,\"start\":18247},{\"end\":19134,\"start\":18349},{\"end\":19608,\"start\":19153},{\"end\":19893,\"start\":19677},{\"end\":20419,\"start\":19895},{\"end\":21078,\"start\":20421},{\"end\":21885,\"start\":21101},{\"end\":22578,\"start\":21910},{\"end\":22928,\"start\":22580},{\"end\":23411,\"start\":22930},{\"end\":24633,\"start\":23430},{\"end\":25241,\"start\":24656},{\"end\":25759,\"start\":25243},{\"end\":26327,\"start\":25790}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":12331,\"start\":12287},{\"attributes\":{\"id\":\"formula_1\"},\"end\":12474,\"start\":12428},{\"attributes\":{\"id\":\"formula_2\"},\"end\":12635,\"start\":12586},{\"attributes\":{\"id\":\"formula_3\"},\"end\":12672,\"start\":12635},{\"attributes\":{\"id\":\"formula_4\"},\"end\":12810,\"start\":12761},{\"attributes\":{\"id\":\"formula_5\"},\"end\":13037,\"start\":12992},{\"attributes\":{\"id\":\"formula_6\"},\"end\":14409,\"start\":14338},{\"attributes\":{\"id\":\"formula_8\"},\"end\":14999,\"start\":14928},{\"attributes\":{\"id\":\"formula_9\"},\"end\":15160,\"start\":15114},{\"attributes\":{\"id\":\"formula_10\"},\"end\":15762,\"start\":15710},{\"attributes\":{\"id\":\"formula_11\"},\"end\":16293,\"start\":16238},{\"attributes\":{\"id\":\"formula_12\"},\"end\":16595,\"start\":16537},{\"attributes\":{\"id\":\"formula_13\"},\"end\":16873,\"start\":16831},{\"attributes\":{\"id\":\"formula_14\"},\"end\":17090,\"start\":17070},{\"attributes\":{\"id\":\"formula_15\"},\"end\":17340,\"start\":17261},{\"attributes\":{\"id\":\"formula_16\"},\"end\":19676,\"start\":19609}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":19814,\"start\":19807},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":21816,\"start\":21809},{\"attributes\":{\"ref_id\":\"tab_9\"},\"end\":23440,\"start\":23433}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1630,\"start\":1618},{\"end\":2840,\"start\":2787},{\"end\":2973,\"start\":2958},{\"end\":3058,\"start\":3040},{\"end\":3191,\"start\":3176},{\"end\":3213,\"start\":3194},{\"end\":3271,\"start\":3216},{\"attributes\":{\"n\":\"3\"},\"end\":9271,\"start\":9260},{\"attributes\":{\"n\":\"3.1\"},\"end\":10608,\"start\":10588},{\"attributes\":{\"n\":\"3.2\"},\"end\":11362,\"start\":11330},{\"end\":11692,\"start\":11653},{\"attributes\":{\"n\":\"3.3\"},\"end\":15380,\"start\":15354},{\"attributes\":{\"n\":\"3.4\"},\"end\":16897,\"start\":16875},{\"attributes\":{\"n\":\"4\"},\"end\":17550,\"start\":17539},{\"attributes\":{\"n\":\"4.1\"},\"end\":17561,\"start\":17553},{\"attributes\":{\"n\":\"4.2\"},\"end\":18068,\"start\":18031},{\"attributes\":{\"n\":\"4.3\"},\"end\":19151,\"start\":19137},{\"attributes\":{\"n\":\"4.4\"},\"end\":21099,\"start\":21081},{\"end\":21908,\"start\":21888},{\"attributes\":{\"n\":\"4.5\"},\"end\":23428,\"start\":23414},{\"attributes\":{\"n\":\"4.7\"},\"end\":24654,\"start\":24636},{\"attributes\":{\"n\":\"5\"},\"end\":25788,\"start\":25762},{\"end\":26339,\"start\":26329},{\"end\":26408,\"start\":26398},{\"end\":26556,\"start\":26555},{\"end\":27490,\"start\":27480},{\"end\":27991,\"start\":27982},{\"end\":28051,\"start\":28042},{\"end\":28115,\"start\":28106},{\"end\":28696,\"start\":28687}]", "table": "[{\"end\":28685,\"start\":28656}]", "figure_caption": "[{\"end\":26396,\"start\":26341},{\"end\":26497,\"start\":26410},{\"end\":26553,\"start\":26500},{\"end\":27478,\"start\":26557},{\"end\":27543,\"start\":27492},{\"end\":27980,\"start\":27546},{\"end\":28040,\"start\":27993},{\"end\":28104,\"start\":28053},{\"end\":28622,\"start\":28117},{\"end\":28656,\"start\":28625},{\"end\":28737,\"start\":28698}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":11413,\"start\":11404},{\"end\":14509,\"start\":14484},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":24841,\"start\":24835}]", "bib_author_first_name": "[{\"end\":28925,\"start\":28924}]", "bib_author_last_name": "[{\"end\":28936,\"start\":28926},{\"end\":28943,\"start\":28938}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":2021204},\"end\":30490,\"start\":28830},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":54044974},\"end\":35046,\"start\":30492}]", "bib_title": "[{\"end\":28922,\"start\":28830},{\"end\":30619,\"start\":30492}]", "bib_author": "[{\"end\":28938,\"start\":28924},{\"end\":28945,\"start\":28938}]", "bib_venue": "[{\"end\":30870,\"start\":30796},{\"end\":29066,\"start\":28945},{\"end\":30710,\"start\":30621}]"}}}, "year": 2023, "month": 12, "day": 17}