{"id": 247362809, "updated": "2023-10-05 16:13:58.514", "metadata": {"title": "Internet-augmented language models through few-shot prompting for open-domain question answering", "authors": "[{\"first\":\"Angeliki\",\"last\":\"Lazaridou\",\"middle\":[]},{\"first\":\"Elena\",\"last\":\"Gribovskaya\",\"middle\":[]},{\"first\":\"Wojciech\",\"last\":\"Stokowiec\",\"middle\":[]},{\"first\":\"Nikolai\",\"last\":\"Grigorev\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "In this work, we aim to capitalize on the unique few-shot capabilities of large-scale language models (LSLMs) to overcome some of their challenges with respect to grounding to factual and up-to-date information. Motivated by semi-parametric language models (LMs), which ground their decisions in external retrieved evidence, we use few-shot prompting to learn to condition LMs on information returned from the web using Google Search, a broad and constantly updated knowledge source. Our approach does not involve fine-tuning or learning additional parameters, thus making it applicable to any LM, offering therefore a strong baseline. Indeed, we find that LMs conditioned on the web surpass performance of closed-book models of similar, or even larger, model sizes in open-domain question answering. Finally, we find that increasing the inference-time compute of models, achieved via using multiple retrieved evidences to generate multiple answers followed by a reranking stage that uses scores generated by the same LMs, leads to better performance and alleviates lower performance of smaller few-shot LMs. All in all, our findings suggest that it might be beneficial to slow down the race towards the biggest model and instead shift attention towards finding more effective ways to use models, including but not limited to, better prompting or increasing inference-time compute.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2203.05115", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/corr/abs-2203-05115", "doi": "10.48550/arxiv.2203.05115"}}, "content": {"source": {"pdf_hash": "c70eb74e09c41e8fcc71dd59e3b4d631f657f7cd", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2203.05115v2.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "0112e011a3d795b6bffe4ac54af5176b82ac8321", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/c70eb74e09c41e8fcc71dd59e3b4d631f657f7cd.txt", "contents": "\nInternet-augmented language models through few-shot prompting for open-domain question answering\n\n\nAngeliki Lazaridou angeliki@deepmind.com \nDeepMind\nLondonUK\n\nElena Gribovskaya egribovskaya@deepmind.com \nDeepMind\nLondonUK\n\nWojciech Stokowiec wstokowiec@deepmind.com \nDeepMind\nLondonUK\n\nNikolai Grigorev nikolaig@deepmind.com \nDeepMind\nLondonUK\n\nInternet-augmented language models through few-shot prompting for open-domain question answering\n\nIn this work, we aim to capitalize on the unique few-shot capabilities of large-scale language models (LSLMs) to overcome some of their challenges with respect to grounding to factual and up-to-date information. Motivated by semi-parametric language models (LMs), which ground their decisions in external retrieved evidence, we use few-shot prompting to learn to condition LMs on information returned from the web using Google Search, a broad and constantly updated knowledge source. Our approach does not involve fine-tuning or learning additional parameters, thus making it applicable to any LM, offering therefore a strong baseline. Indeed, we find that LMs conditioned on the web surpass performance of closed-book models of similar, or even larger, model sizes in open-domain question answering. Finally, we find that increasing the inference-time compute of models, achieved via using multiple retrieved evidences to generate multiple answers followed by a reranking stage that uses scores generated by the same LMs, leads to better performance and alleviates lower performance of smaller few-shot LMs. All in all, our findings suggest that it might be beneficial to slow down the race towards the biggest model and instead shift attention towards finding more effective ways to use models, including but not limited to, better prompting or increasing inference-time compute. * Equal contribution.Preprint. Under review.\n\nIntroduction\n\nUndoubtedly, large-scale language models (LSLMs) present a research breakthrough for language research, particularly for their state-of-the-art language modeling results [1,2] and impressive generative capabilities. Above all, increasing scale has made few-shot learning a defining new paradigm for language models (LMs). Due to the versatility of prompting, these models can now be quickly adapted using only a handful of examples to perform tasks ranging from question answering and numeric reasoning to creative writing [3]. All these considerations place few-shot LSLMs at an excellent position to be used as building blocks for open-ended and \"in the wild\" user interactions.\n\nDespite these successes, few-shot LSLMs still lack a key ingredient; they are susceptible to hallucinations [4] caused by incorrect retrieval of knowledge stored in their weights or due to the model having incomplete or outdated knowledge. As for many user interactions we expect factuality to play an important role, it is imperative to find ways to keep LSLMs up-to-date and grounded to factual and new information as it becomes available. As the current trend sees the size of these models to continually grow, mitigating those issues should rely on flexible and robust approaches that can be easily transferred to different domains and tasks.\n\nHere, we aim to capitalize on the unique benefits offered by pre-trained LSLMs and propose to overcome some of their limitations by drawing ideas from semi-parametric models [5][6][7][8] that ground their decisions in external retrieved evidence to reduce hallucinations and improve factuality [9]. Specifically, we use the Internet as a source of up-to-date knowledge, and rely on the powerful few-shot capabilities of these LSLMs to learn how to use it effectively for answering questions. Taking open-domain question answering as a task where factual correctness is vital, we design a system that given a question uses a retrieval model to retrieve relevant documents from the Internet. Then, using few-shot learning we prompt the model to answer the question via conditioning on the retrieved documents, without the need to fine-tune or learn extra parameters. As a retrieval system we use a search engine -in particular Google Search -allowing us to treat the whole web as a knowledge source. While Wikipedia has been the dominant knowledge source driving progress on a multitude of tasks, given the current progress and the quest towards more complex interactions, there has never been a better time to widen their scope, embracing the opportunities working with the whole web, such as considering a wider range of topics and views, as well as the many challenges, such as working with more noisy and potentially uncurated and unsafe text in the wild. Indeed, there is momentum building up in breaking away from Wikipedia-only research [10][11][12][13].\n\nTo test the effectiveness of equipping LSLMs with Internet search on open-domain question answering, we use a mix of single-hop and multi-hop, language generation and classification tasks. We find that our biggest LSLMs benefit from conditioning on the web through few-shot prompting. For the language generation tasks, we see a relative performance increase of 15%-30% over the commonly used closed-book few-shot approach. Surprisingly, we find that our method achieves gains, albeit smaller, even on complex multi-hop questions, despite the fact that these questions suffer from higher retrieval errors. Moreover, we see that in certain cases conditioning models on the Internet makes up performance-wise for their smaller size. While perhaps the mainstream view places scaling models' parameters as the primary way to increase their few-shot performance, our results add to the stream of work that emphasizes instead better use of the models' powerful prompting abilities [14,15]. As such, our approach presents a lightweight method applicable to virtually any pre-trained LM without the need for fine-tuning or adding extra learnable parameters. Finally, increasing the inferencetime compute of models via sampling multiple answers and reranking using scores computed from the same LSLMs not only adds further performance gains, but also alleviates generally decreased performance of smaller few-shot LMs, partly closing their performance gap with larger models.\n\nAll in all, our findings hint at the possibility of slowing down the race towards the biggest model and instead shifting the attention to more targeted and effective use of models' few-shot capabilities in combination with increasing inference-time compute, a generally more scalable approach.\n\n\nRelated Work\n\nSemi-parametric language models Semi-parametric LMs have been recently gaining momentum [5,6,16,17], extending monolithic parametric models with information from a knowledge source. This process facilitates overcoming distribution shift (e.g., domain or temporal) in a flexible way by simply updating the external knowledge. When applied to question answering tasks [7,8,18], they surpass performance of parametric-only models -they are able to efficiently handle an increasing number of retrieved passages and ground their predictions into additional information, thus reducing hallucinations and improving factuality. However, to be faithful to their input, these models need to be trained (or fine-tuned) to attend to the additional input. In contrast, our work pushes the limits of few-shot prompting as a way to learn to condition on external evidence, which requires no additional parameters, thus making our method applicable to virtually any pre-trained LM.\n\nWeb as knowledge source Open-domain question answering traditionally has been studying carefully constructed benchmarks, where answerability of questions from Wikipedia has been confirmed through annotations. Recently a new trend emerged -using the whole web as knowledge source to support more varied and rich interactions. Augenstein et al. [19] and Fan et al. [20] make use of web data through commercial search engines as a part of building more diverse datasets for fact-checking. On the other hand, Piktus et al. [12] find that considering the web as a retrieval source brings material gains to knowledge intensive tasks, despite any difficulties with building a search index from an order of magnitude more (noisy) data than Wikipedia. To avoid similar challenges with building and maintaining a search index, recent work that aims in improving factuality in user interactions adopts the use of commercial search engines as building block for their systems [10,11,13,21]. Similar to us, Nakano et al. [11] analyze benefits of increasing compute at inference time. However, unlike us, they either target open-ended dialogue interactions [10,13] or focus on optimizing performance using more intensive techniques like fine-tuning and reinforcement learning [11,21]. In our work, we take a more light-weight approach without introducing learnable parameters. We push the limits of few-shot prompting and emphasize the need to establish strong baselines, aiming at gaining insights into the strengths and weaknesses of this generally applicable, due to its simplicity, approach.\n\n3 Few-shot prompting for Internet-augmented Language Models\n\nIn this section, we describe our approach for improving the performance of pre-trained LMs in the task of open-domain question answering. Specifically, we propose to use few-shot prompting as a flexible and robust way to condition any pre-trained LSLM on external evidence, allowing for better grounding to factual and up-to-date information. Our approach consists of 3 steps (see Appendix A.1 for an illustration of the method). First, given a question we retrieve a set of relevant documents from the web using a search engine ( \u00a73.1). We then use the retrieved evidence to condition the LM through few-shot prompting ( \u00a73.2). Finally, we generate multiple candidate answers from each evidence and, to select the best answer, rerank them using scores computed using the same LM ( \u00a73.3).\n\n\nRetrieve: Google Search for document retrieval\n\nGiven a question q, we need to obtain a set of relevant documents D which would allow us to extend the model's knowledge to factual and (potentially) new information not already present in its weights. With a view to more realistic and open-ended user interactions, we retrieve documents using an off-the-shelf search engine, i.e., Google Search. Specifically, we use each question q verbatim as a query and issue a call to Google Search via the Google Search API. 1 For each question, we retrieve the top 20 urls and parse their HTML content to extract clean text, resulting in a set of documents D per question q. While using the question verbatim as a search query is a plain vanilla approach, we find this to be an adequate first step, especially since search engines typically perform additional steps (e.g., query expansion) for improved user interactions. Nevertheless, and as we will discuss later in Section 5.1, the complexity of certain (multi-hop) questions pose problems to this simple approach, calling for more sophisticated learning to search approaches [22, 10, 11].\n\nAs documents in D can originate from news or Wikipedia articles to whole books, they tend to be long, with an average length of 2,056 words. As this exceeds the input sequence length of models, we condition the model on shorter excerpts extracted from the documents in D. Specifically, we first chunk all documents into paragraphs of 6 sentences. We then embed q and the paragraphs using TF-IDF and using cosine similarity we produce a (ranked) list of evidence paragraphs P, thus only using in the prompt smaller, more relevant parts of the full documents.\n\nOverall, using Google Search allows us to tap into the diverse and ever-growing content on the web, instead of being confined on the information found in the static snapshots of the curated content on Wikipedia, a commonly used knowledge source in question answering tasks. In addition to the above benefits, we found that Google Search and the web offers also practical performance gains and is on-par (even sometimes outperforming) current Wikipedia-based state-of-the art dense retrievers (see Section 5). We discuss broader limitations and opportunities of using search engines in Section 6.\n\n\nPrompt: Few-shot prompting for conditioning on evidence\n\nGiven a question q and a set of retrieved paragraphs P, we use few-shot prompting to condition pre-trained LMs on the paragraphs. This is done by taking the conventional k-shot prompting for (closed-book) QA, that only considers tuples of questions, answers , and extending it with an evidence paragraph, resulting in a prompt of the form Evidence: ... Question: ... Answer: ... In all experiments we set k = 15. In Section 4 we give details on how we obtain the evidence, question, answer triplets to populate the prompt.\n\nWhile experimenting with prompts, we found that swapping the question with the evidence, thus increasing the distance between questions and answers, yielded consistently lower results across all our datasets. We hypothesize that this is another manifestation of LMs' struggles to incorporate information from longer contexts; further performance increase could be achieved by selecting in-context examples for the prompt retrieved based on similarity to the question being answered [23].\n\n\nRerank: Increasing inference-time compute via answer reranking\n\nIncreasing compute of models via scaling the number of parameters, hence increasing training-time compute, has been shown to improve performance of models in various few-shot tasks [3,2]. Here, we ask whether similar gains can be obtained when scaling the inference-time compute. While there are multiple ways this can be achieved (e.g., considering different adaptive computation methods or the recently proposed chain-of-thought reasoning LMs [24]), here we do it through sampling multiple answers from the model, which we then rerank using different probabilistic factorizations of the question answering task as scoring functions.\n\nSpecifically, as P contains retrieved paragraphs ordered via their similarity to question q, we select the top n = 50, use each one separately to prompt the model and produce multiple candidate answers for each paragraph (for classification tasks we produce a distribution over all class labels for each paragraph). Overall, this allows us to consider a larger number of possible answers candidates while overcoming potential retrieval errors -considering more paragraphs increases retrieval recall.\n\nGiven an answer a i for a question q conditioned on each of the n retrieved paragraph p i , we consider the following ways for estimating the answer probability: (i) direct inference, where we choose an answer that maximizes p(a | q) = n i=1 p tf idf (p i | q) \u00b7 p(a i | q, p i ), referred to as RAG throughout this work as it is inspired from the model of Lewis et al. [7] (ii) Noisy channel inference, where we choose an answer that maximizes p(\na i , q | p i ) = p(q | ai, pi)\u00b7p(ai | pi) p(q | pi)\n, [25,26]. (iii) Product-of-Experts (PoE), which combines all probabilities used above, in addition to p(p i | q). 2 Pre-trained LSLMs as scorers All conditional probabilities are computed using LMs that we k-shot prompt for producing the respective distributions (k = 15) (see Appendix A.4 for example prompts). In this way, we turn LMs into models of arbitrary probabilities, which to the best of our knowledge is something that has not been explored before. Exception to this is p tf idf (p i | q) that is computed as the normalized cosine similarities between the TF-IDF passage and question representations -as the passages tend to be long, we found it challenging to derive reliable estimates of p(p i | q) using prompted LMs.\n\n\nExperimental Setup\n\nDatasets We use 3 question answering datasets: the single-hop NQ [27], and the multi-hop HOTPOTQA [28] and STRATEGYQA [29]; and a fact-checking multi-hop dataset FEVER [30]. We select these datasets as they allow us to consider a mixture of language generation (NQ, HOTPOTQA) and classification (2-way for STRATEGYQA, 3-way for FEVER) tasks, as well as single-and multihop questions. We represent all items in the datasets as tuples q, A, G , where q is the question, A is the the set of possible answers (or a single class label for the classification datasets), and G is the set of gold evidence documents provided by the dataset. For the few-shot learning, we use the prompt format presented in Section 3.2 and create dataset-specific 15-shot prompts (for each of the datasets, we use the same set of questions for the few-shot examples), for a total of 4 prompts (for computing different scoring probabilities), populating them with the necessary evidence, question, answer triplets from each dataset. 3 As evidence, we use the gold evidence documents in G. Evaluation metrics To evaluate the performance on these tasks, we report exact match for generation tasks and accuracy for classification tasks. Moreover, to better understand the interaction between retrieval and subsequent QA performance, we introduce a retrieval score. For generation tasks, we calculate answer recall in the conditioning evidence paragraphs P. For classification tasks, since the answer takes the form of a class label, we instead compute the normalized word overlap (excluding stopwords) between the gold paragraph G and each of the conditioning paragraphs in P, and report the maximum word overlap achieved among the paragraphs P.\n\nLanguage Models All experiments in this work use the GOPHER LM of 280 billion parameters [2]. Alongside this model, and in order and to answer questions regarding scaling, we also use smaller models of the same family abbreviated by their number of parameters, i.e., 44M, 117M, 400M, 1B and 7B. Besides the number of parameters, the models also differ in the input sequence length: 2048 for 7B and 280B, and 1024 for 44M, 117M, 400M, and 1B. All models were trained on MassiveText for 300 billion tokens. For generation tasks, we use nucleus decoding, with parameters 0.8 for the probability cut-off and temperature of 1. Open-domain question answering models Here, we describe the open-domain question answering systems we build, all based on LMs presented above.\n\nWe first describe our open-book models (referred to as OB), which condition on the provided evidence to generate an answer. OB Google will use the Google retrieved paragraphs. For each question q we will generate 4 candidate answers a for each of the 50 paragraphs p, for a total of 200 answers. We will then select the best answer a * as arg max a f (a , p, q), where f is a pre-defined scoring function. In its basic form, OB a|q,p Google will use as scoring function f only the probability returned by the question answering model. Models OB Noisy Channel Google ,OB RAG Google and OB PoE Google will use the noisy channel, direct inference and PoE factorizations, introduced in Section 3.3. Moreover, to better assess the performance of few-shot prompting, we design a model that assumes an oracle retrieval system -OB Gold conditions on gold evidence passages for each question provided by the datasets.\n\nFinally, as a baseline model, we will use a pre-trained LM without evidence, prompting it with question, answer tuples. This is the conventional way found in the literature of few-shot language models [3] for performing open-domain question answering. These models are usually referred to as closed-book, as they do not use any knowledge source (unlike open-book), but solely rely on the knowledge encoded in their weights during training. We refer to these models as CB.\n\nTo fairly compare the different models, we need to account for the fact that OB Google searches for the right answer in a big pool of candidates generated by conditioning on multiple paragraphs; for both CB and OB Gold we sample 200 answers, and select the one with the highest probability. 4  Note that in this work we use probabilities of class labels directly, whereas in [2] these probabilities were used as features for a classification model based on multi-class logistic regression. Table 1: Results on 4 question answering datasets using the GOPHER-280B model.\n\n\nResults\n\n\nConditioning a large-scale language model on Google search results\n\nHere, we assess the effectiveness of our method for improving the performance of pre-trained LMs on open-domain question answering. We start with Gopher-280B, the best LM among the ones considered in this work, containing 280 billion parameters; we test whether using few-shot prompting as a way to condition on external retrieved evidence (i.e., OB a|q,p Google ) improves the performance of Gopher-280B over its closed-book version (i.e. CB), which uses knowledge solely in its weights. Table 1 summarizes the results on our 4 datasets.\n\nOverall, we find that, indeed, conditioning Gopher-280B on the Google Search results leads to improved performance on all datasets, despite the fact that both Gopher-280B open-and closedmodels use the same underlying LM. We see stronger performance over the closed-book version for the generation tasks, with the relative improvements reaching 30% on the NQ dataset. For NQ and HOTPOTQA, stronger performance is driven by higher retrieval recall and strong extractive behaviour of the model, very frequently producing an answer present in the conditioning evidence, a welcomed feature for extractive tasks (i.e., generated answer is present in evidence in 89.4% and 70.5% cases, for NQ and HOTPOTQA respectively). We also see gains, albeit smaller in scale, for the more reasoning classification tasks, indicating that few-shot prompting with retrieved evidence is beneficial over and above its extractive power.\n\nRetrieval performance Turning to the retrieval performance achieved by Google Search (see Retrieval performance column in Table 1), we see that the effectiveness of our approach of using the question verbatim as a search query heavily depends on the complexity of the questions in each dataset. Compare for example a typical question in the single-hop NQ \"How many episodes in season 2 breaking bad?\", where recall@50 reaches 85%, with one from HOTPOTQA \"What is the relationship of Yeshahework Yilma's mother to the man who was Ethiopia's emperor from 1930 to 1974\", where recall performance drops to 55.5%. Indeed, performance on multi-hop datasets (HOTPOTQA and STRATEGYQA) is generally worse than in the single-hop ones (NQ and FEVER). In fact, STRATEGYQA sees the smallest relative increase in performance with respect to the closedbook version; questions in this dataset, albeit somewhat artificial, are inventive and involve linking non-trivial, normally unrelated facts (e.g., \"Could a sloth hypothetically watch an entire episode of Scrubs underwater?\"), stress-testing performance of retrieval models.\n\nCompared to current Wikipedia-based state-of-the-art models, which require training on the specific datasets, we find that the generic Google Search retrieval outperforms DPR [32] on NQ (DPR recall@50 84%), while is only marginally outperformed by MDR [33] on HOTPOTQA (MDR recall@20 52.1% vs ours recall@20 50.1%). Google Search acts here as a zero-shot retrieval, capable of generalizing on different tasks and knowledge corpus. Overall, our results demonstrate the potential of integrating search engines with LSLMs.\n\nFinally, our probabilistic reranking further improves performance: across all datasets, OB PoE Google outperforms consistently the simpler OB a|q,p Google , widening the gap between closed-book and Googleconditioned model. We provide more in-depth discussion of reranking results in Section 5.2.\n\n\nAblations\n\nEffect of Reranking In Table 1 (see columns #sampled answers:1), we ablate the use of rankingeven conditioning on a single Google evidence can bring gains over the closed-book model, evident by the higher performance achieved by OB no reranking Google compared to CB.  Note that, besides p(a|q, p), which is computed using Gopher-280B, the remaining probabilities used to compute the 3 scores, i.e., PoE, RAG and Noisy Channel, are obtained by few-shot prompting the smaller 7B model. We find that that reranking with factorizations that consider scores beyond just the answer probability improve performance across all datasets, despite the fact that we do not train specialized models for deriving the extra scores but rather use an order of magnitude smaller prompted LMs.\n\nLooking at the individual scores, we find p(a | q, p i ) and p(q | p i , a) to be most informative -this last probability captures how well the model can \"explain\" the question given a retrieved evidence and an answer. In fact, as also show in Appendix A.2, this score could be reliably used for reranking passages that are more predictive of the final answer. On the other hand, p(p i | q, a), while being correlated to p(q | p i , a), has a higher variance (likely due to varying length of the passages) and is much less informative overall. Among the three factorizations that we consider, the lowest performance is consistently observed for the RAG-inspired factorization. We attribute this to the way the passage relevance is derived: as we do not use p(p i | q, a) from the model, we instead rely on normalized cosine similarities between TF-IDF vectors which, as we show in Appendix A.2, are more reliable than the passage probabilities from the LM, but less accurate than p(q | p i , a).\n\nWhile more elaborate scores are able to reduce the gap with the in-domain fine-tuned models (compare column SOTA with column OB PoE Google in Table 1), in line with previous work [34] we find that few-shot prompting still generally lags behind the specialist models. However, this should be considered in perspective of how generalizeable our setup is to a diverse set of questions, from single-hop to multi-hop to fact-checking, turning any LM to a retrieval-augmented LM.\n\nOracle retrieval The results of OB Gold can be treated as upper-bound since the conditioning information is gold evidence (hence assuming oracle retrieval) -these results suggest that there is room for improvement in relying more on the conditioning evidence. We envision several directions: if we remain within the few-shot paradigm, more accurate prompt optimization, like in-context example selection, can further boost results [23], while, constrained decoding [35,36] can be a way to condition the model at inference-time, by explicitly grounding an answer in the provided evidence.  So far, we observed that conditioning a 280 billion LM on retrieved evidence from Google Search resulted in improved performance over the closed-book version of the same LM. But are these gains only confined on the (very) largescale regime or could this method be used to also boost performance of smaller models? To answer this, we compute the open-and closedbook performance of 5 additional models containing 44M, 117M, 400M, 1B and 7B parameters. We follow the same approach as before; we use k-shot learning to prompt for the open-book models using Google Search results and k-shot learning to prompt for question, answer for the closed-book models, with k = 15. In Figure 2 we present results as a function of models' parameters in millions, for open-book (in solid lines) and closed-book models (dashed lines) models. We report accuracy for the classification tasks (left figure) and exact match for the generation tasks (right figure).\n\n\nScaling analysis of open-and closed-book models\n\nConditioning smaller models on retrieved evidence is particularly beneficial for the generation tasks, which given reliable evidence can be more extractive in nature. In fact, making use of external evidence does not simply improve the factuality of the models through grounding to external sources, but in many cases results in smaller open-book models outperforming bigger closed-book models. Indeed, for both NQ (in green lines) and HOTPOTQA (in purple lines) the open-book 7B model overtakes the closed-book 280B model, while for the NQ this is also the case for the even smaller 1B. Despite the simplicity of the approach and the potential errors introduced by the retrieval method, conditioning through few-shot prompting can, to some extent, make up for a smaller model size.\n\nHowever, we also see that for the more reasoning tasks, i.e., FEVER (in black lines) and STRATEGYQA (in blue lines), the gains manifest mostly in the 7B models, though are smaller. For the (relatively) smaller models, their closed-book performance fluctuates around the random baseline. As such, grounding to factual information is perhaps a secondary concern in those cases; retrieval can boost reasoning capabilities for models with pre-existing good reasoning skills (as in the case of 280B), but cannot compensate for general lack of reasoning abilities.  The main driver of performance improvements of few-shot LMs has been scaling their model size. Increasing training-time compute is thus spent in injecting (and potentially memorizing) Internet-scale data. Here, we put forward a different hypothesis; we posit that we can improve performance of smaller LMs by giving them direct access to the Internet, thus freeing trainingtime compute which could then be spent to increasing their inference-time compute. 5 While there are many ways to achieve that, here we choose to increase models' compute via using multiple Google retrieved paragraphs to sample candidate answers for each and then reranking those answers using the functions introduced in Section 3.3. We focus on the 3 biggest models used in this study, comparing the open-book version of 1B and 7B with the closed-book version of Gopher-280B. We conduct this study on NQ. Figure 3-left presents exact match performance on NQ as a function of number of paragraphs (and hence candidate answers we are sampling and reranking). We see that considering more than the top 1 paragraph improves performance of models. Moreover, as evident by the slight upward slops, considering gradually more paragraphs benefits those scoring functions that incorporate some notion of paragraph \"goodness\", i.e., RAG (in purple lines) and PoE (in green lines) and Noisy Channel (in orange lines). In contrary, reranking only using the probability p(a|q, p) of the answer under the model (in blue lines) results in decreased performance after a certain point. We hypothesize that this is potentially due to some pathological behaviour of the model, e.g., assigning high probability to candidate answers that exist in the conditioning evidence but are otherwise wrong. This is consistent with findings in Machine Translation which find that reranking only using the forward probability gives worse results as the number of candidates increases beyond a certain threshold [37].\n\n\nIncreasing inference-time compute\n\nMore interestingly, we find that using as little as 5 paragraphs from Google Search, in conjunction with the 7B model (in dashed lines for the different scoring functions) surpasses the performance of closedbook Gopher-280B model (horizontal black line), suggesting that searching the Internet is worth more than 273 billion parameters. Finally, Figure 3-right presents a similar plot, but as a function of FLOPs; this accounts for additional factors, on top of the number of Google retrieved paragraphs, like models' size and compute spent to calculate the scores for each of the scoring functions. Closed-book Gopher-280B spends compute for implicitly combining retrieving the facts that are memorized in its weights, and then reason over them. By explicitly outsourcing the memorization of facts and their retrieval to Google Search, the same inference-time compute can now be spent more effectively in reranking more samples with a smaller model. As such, for the same or less inference-time compute, reranking models achieve better performance, as indicated by all the lines being to the left of the blue dot in the horizontal dashed line, i.e., the FLOPs of the closed-book Gopher-280B.  Google compared to CB, using few-shot prompting as a way to condition on evidence is an effective way of incorporating truly new information into the QA system. However, despite having access to updated information, the performance of OB a|q,p Google on post-2020 questions is substantially lower than the performance on the complete set of questions, suggesting that conflicting parametric (i.e., in language model) and contextual (i.e., in retrieved evidence) knowledge poses challenges for retrieval-based models [39]. 6 \n\n\nKeeping\n\n\nDiscussion\n\nTowards more open-ended and \"in the wild\" user interactions, in this work we presented a straightforward method targeted to alleviate some of the challenges faced by LSLMs with respect to grounding to factual and up-to-date information. The core of our method lies in combining the powerful few-shot abilities of LSLMs with a state-of-the-art retrieval model, i.e., Google Search, for access to a broad and constantly updated knowledge source, the whole web. We applied our method on open-domain question answering and found that, despite its simplicity, using few-shot prompting to condition models on the web provides an effective approach for increasing models' factuality. Improvements were not just confined to the largest LMs; we saw increases in performance across the board of model sizes, with smaller open-book models often surpassing performance of bigger few-shot closed-book models. Further gains were achieved when increasing inference-time compute via using multiple retrieved evidences to generate multiple answers followed by a reranking stage that uses scores computed by the same LMs. Our approach offers a simple way to turn virtually any pre-trained LM to a retrieval-augmented LM model without the need for fine-tuning or adding learnable parameters.\n\nMainstream view places scaling LMs' parameters as the primary way to increase their few-shot performance. However, our findings suggest that inference-type interventions, such as more targeted use of few-shot abilities and increase of inference-time compute, can bring significant gains. This may slow down the race towards the biggest LM and instead shift the attention towards finding more effective ways to use existing models.\n\nLimitations Despite their progress, LSLMs are still sometimes outperformed by fine-tuned, and even smaller, models [34]. While our targeted interventions were successful in closing this gap on open-domain question answering, we are still behind in-domain fine-tuned models. For reasoning tasks, retrieval was able to improve only the largest amongst the considered models. Moreover, while we have considered a wide-range of diverse question answering datasets, our current experiments only capture a small fraction of (simple) user interactions where factuality plays a crucial role.\n\nThe deterioration of search results for multi-hop questions highlights the importance of a better approach to interacting with the Internet. This is particularly challenging for the general-purpose and powerful, yet black-box, search engines, where gradient-based learning is infeasible due to the discrete bottleneck introduced by working directly with words. We expect that \"learning to search\" approaches could boost performance of the overall system [22, 10,11], where complex queries could be decomposed into simpler sub-queries, akin to approaches in question decomposition [40,41]. While these tasks have not yet been tackled with LSLMs and few-shot prompting, we believe that it would be a reasonable first approach.\n\nFinally, in an attempt to work towards open-ended interactions and improve our system's performance, we used a commercial search engine as a retrieval model, allowing us to work with the whole web as a knowledge source. Since we are not confined to working only with the curated and \"sanitized\" Wikipedia, we anticipate a number of safety issues to arise, including misinformation, harmful content. While we have relied on the underlying safety nets of the search engines we use, more work should be put in place scoping out and better understanding the risks and, most importantly, providing effective ways to mitigate those. As working with the whole Web gains more momentum, we expect to see more work that surfaces and tackles these points. Another potential concern is reproducibility of the research results given that we do not have as tight control over retrieval results as in the case of offline retrieval. 7 This might, indeed, create some discrepancies over longer time horizons, not only due to changes in the underlying search engine logic, but also because new published documents might provide more direct answers. Overall we believe that potential benefits of understanding how to use Google Search with LSLMs overweight the potential downsides, if done responsibly.\n\n[11] Reiichiro Nakano, Jacob  Answer Recall p(passage|question) p(question|passage) TF-IDF DPR Figure 5: Comparing NQ answer recall when reranking Google Search passages using LSLMs-derived scores against DPR retriever on Wikipedia .\n\n\nA.3 QA Prompts\n\nBellow we provide the prompts used for each of the datasets to create the open-book models. The prompts for building the closed-book model is derived by omitting the Evidence part of the prompt.  Evidence: Malware, short for malicious software, is an umbrella term used to refer to a variety of forms of harmful or intrusive software, including computer viruses, worms, Trojan horses, ransomware, spyware, adware, scareware, and other malicious programs. It can take the form of executable code, scripts, active content, and other software. Malware is defined by its malicious intent, acting against the requirements of the computer user --and so does not include software that causes unintentional harm due to some deficiency.   5,1906) was an Austrian physicist and philosopher whose greatest achievement was in the development of statistical mechanics, which explains and predicts how the properties of atoms (such as mass, charge, and structure) determine the physical properties of matter (such as viscosity, thermal conductivity, and diffusion). Evidence: Otello (] ) is an opera in four acts by Giuseppe Verdi to an Italian libretto by Arrigo Boito, based on Shakespeare's play \"Othello\". It was Verdi's penultimate opera, and was first performed at the Teatro alla Scala, Milan, on 5 February 1887. After Aida (original title: \"Verdi's Messiah\") is a 1985 play-with-music by Julian Mitchell. It is about Giuseppe Verdi, and the pressure put upon him after his attempt to retire from composing. Continued insistent prodding from his friends eventually results in one of his greatest masterpieces, the opera \"Otello\", which premiered in 1887. Evidence: Silicon is a key material for the production of semiconductor chips. A silicon shortage would mean fewer semiconductor chips could be produced. A business that produces fewer products than normal will receive lower than normal revenue.  Evidence: Since Trump 's inauguration , Conway has been embroiled in a series of controversies , including using the phrase alternative facts '' , making reference to a Bowling Green massacre '' that never occurred , claiming Michael Flynn had the full confidence of the president hours before he was dismissed , and publicly endorsing commercial products associated with the president 's daughter Ivanka Trump .     Patel, an Indian boy from Pondicherry who explores issues of spirituality and practicality from an early age. He survives 227 days after a shipwreck while stranded on a lifeboat in the Pacific Ocean with a Bengal tiger named Richard Parker.\n\n\n\u2192 \u2192\n\nQuestion: the general term for software that is designed to damage disable or steal data is Evidence: Malware. Malware, short for malicious software, is an umbrella term used to refer to a variety of forms of harmful or intrusive software, including computer viruses, worms, Trojan horses, ransomware, spyware, adware, scareware, and other malicious programs. It can take the form of executable code, scripts, active content, and other software. Malware is defined by its malicious intent, acting against the requirements of the computer user --and so does not include software that causes unintentional harm due to some deficiency.\n\n\n\u2192 \u2192 \u2192\n\nQuestion: who sings the theme tune to mum on bbc2 Evidence: Mum (TV series  \n\nFigure 1 :\n1Question answering performance on all 4 datasets using Gopher-280B OB Google model in combination with different answer scoring functions for reranking the answers generated for each of the top 50 Google retrieved paragraphs. Effect of different scoring functions Figure 1 presents a comparison of the 4 different scoring functions introduced in Section 3.3.\n\nFigure 2 :\n2Scaling analysis of open-book (solid lines) and closed-book (dashed lines) question answering models using LMs of varying sizes ranging from 44M to 280B parameters.\n\nFigure 3 :\n3Scaling analysis on the NQ dataset: exact match as a function of number of conditioned paragraphs (left) and FLOPs (right).\n\nFigure 4 :\n4Schematic representation of the method presented in Section 3.\n\n26 -\n26Evidence: No. Name Field Affiliation Date of Appointment Date of Retirement Roopa Ganguly Art Bharatiya Janata Party 04-Oct-2016 03-Oct-2022 Sambhaji Raje Social work Bharatiya Janata Party 07-Jun-2016 03-May-2022 Suresh Gopi Art Bharatiya Janata Party 25-Apr-2016 24-Apr-2022 Subramanian Swamy Economics Bharatiya Janata Party 25-Apr-2016 24-Apr-2022 5 Narendra Jadhav Economics Nominated 25-Apr-2016 24-Apr-2022 6 Mary Kom Sport Nominated 25-Apr-2016 24-Apr-2022 7 Swapan Dasgupta Journalism Nominated 25-Apr-2016 24-Apr-2022 8 K.T.S. Tulsi Law Nominated 25-Feb-2014 24-Feb-2020 9 K. Parasaran Law Nominated 09-Jun-2012 28-Jun-2018 10 Rekha Art Nominated 27-Apr-2012 26-Apr-2018 11 Sachin Tendulkar Social service Nominated 27-Apr-2012 26-Apr-2018 12 Anu Aga Business Nominated 27-Apr-2012 AprQuestion: who was the first lady nominated member of the rajya sabha Answer: Mary Kom Evidence: The McChicken is a chicken sandwich sold by the international fast-food chain McDonald's. The sandwich consists of a toasted wheat bun, a breaded chicken patty, shredded lettuce, and mayonnaise. \u2192 Question: what is on a mcchicken sandwich from mcdonalds Answer: a breaded chicken patty Evidence: Life of Pi is a Canadian fantasy adventure novel by Yann Martel published in 2001. The protagonist is Piscine Molitor \"Pi\" Patel, an Indian boy from Pondicherry who explores issues of spirituality and practicality from an early age. He survives 227 days after a shipwreck while stranded on a lifeboat in the Pacific Ocean with a Bengal tiger named Richard Parker. \u2192 \u2192 Question: what is the tigers name in life of pi Answer: Richard Parker\n\n\nQuestion: the general term for software that is designed to damage disable or steal data is Answer: Malware Evidence: Mum Genre Sitcom Created by Stefan Golaszewski Written by Stefan Golaszewski Directed by Richard Laxton Stefan Golaszewski Starring Lesley Manville Peter Mullan Sam Swainsbury Lisa McGrillis Opening theme Cups by Lulu and the Lampshades Country of origin United Kingdom Original language (s) English No. of series No. of episodes 12 (to 27 March 2018) Production Running time 30 minutes Production company (s) Big Talk Productions Distributor ITV Studios Release Original network BBC Two (2016-present) BBC Two HD (2016-present) Picture format 16: 9 1080i Audio format Stereo Original release 13 May 2016 (2016-05-13) --present \u2192 \u2192 \u2192 \u2192 Question: who sings the theme tune to mum on bbc2 Answer: Lulu and the Lampshades Evidence: The Chess World Cup 2017 was a 128-player single-elimination chess tournament, held in Tbilisi, Georgia, from 2 to 27 September 2017. It was won by Armenian grandmaster Levon Aronian. This was the second time he had won the Chess World Cup, 12 years after his first win in 2005. \u2192 Question: where was the world chess tournament 2017 held Answer: Tbilisi, Georgia Evidence: T.J. Miller as Randy Kevin Michael Richardson as Rosie, others David Koechner as Robert \"Bob Pogo\" Pogrohvich, Frank's obese, chainsmoking boss. Kevin Farley as Babe, Carl, others Gary Cole as Rodger Dunbarton, the owner and founder of the airlines where Frank and his co-workers work. Joe Buck as Lou Gagliardi, others John DiMaggio as Scoop Dunbarton, Roger Dunbarton's racist and moronic nephew. Allison Janney as Henrietta Van Horne T.J. Miller as Randy Michael K. Williams as Smoky \u2192 \u2192 \u2192 Question: who voices randy in f is for family Answer: T.J. Miller Evidence: Las Vegas Stadium is the working name for a domed stadium under construction in Paradise, Nevada for the Las Vegas Raiders of the National Football League (NFL) and the UNLV Rebels football team from the University of Nevada, Las Vegas (UNLV). It is located on about 62 acres west of Mandalay Bay at Russell Road and Hacienda Avenue and between Polaris Avenue and Dean Martin Drive, just west of Interstate 15. Construction of the $1.9 billion stadium began in September 2017 and is expected to be completed in time for the 2020 NFL season. \u2192 \u2192 \u2192 Question: where are they building the new raiders stadium Answer: Paradise, Nevada Evidence: At the time of its initial public offering (IPO) on the stock market in June 1992, Starbucks had 140 outlets, with a revenue of US $ 73.5 million, up from US $1.3 million in 1987. The company's market value was US $271 million by this time. The 12% portion of the company that was sold raised around US $25 million for the company, which facilitated a doubling of the number of stores over the next two years. By September 1992, Starbucks ' share price had risen by 70% to over 100 times the earnings per share of the previous year.\n\n\nQuestion: What machine has the same name as another machine created by Ludwig Boltzmann? Answer: Boltzmann machine Evidence: Graham Linehan ( ; born 22 May 1968) is an Irish television comedy writer and director who, often in partnership with Arthur Mathews, has written or co-written a number of popular television comedies. He is most noted for the sitcoms \"Father Ted\", \"Black Books\" and \"The IT Crowd\". Amongst others, he has also worked on \"Big Train\", \"Count Arthur Strong\", \"Brass Eye\" and \"The Fast Show\". The IT Crowd is a British sitcom byChannel 4, written by Graham Linehan, produced by Ash Atalla and starring Chris O'Dowd, Richard Ayoade, Katherine Parkinson, and Matt Berry. \u2192 \u2192 \u2192 Question: Graham Linehan was the creator of the Ash Atalla-produced sitcom for what UK channel? Answer: Channel 4 Evidence: Andrea Ch\u00e9nier is a verismo opera in four acts by the composer Umberto Giordano, set to an Italian libretto by Luigi Illica. It was first performed on 28 March 1896 at La Scala, Milan. The opera's story is based loosely on the life of the French poet Andr\u00e9 Ch\u00e9nier (1762-1794), who was executed during the French Revolution. The character Carlo G\u00e9rard is partly based on Jean-Lambert Tallien, a leading figure in the Revolution. \"La mamma morta \" (They killed my mother) is an aria from act 3 of the 1896 opera \"Andrea Ch\u00e9nier\" by Umberto Giordano. \u2192 \u2192 \u2192 Question: What is the name of the third act in a play where a character named Carlo G\u00e9rard is partly based on a revolutionary figure? Answer: La mamma morta Evidence: Richard Masur (born November 20, 1948) is an American actor who has appeared in more than 80 movies. From 1995 to 1999, he served two terms as president of the Screen Actors Guild (SAG). Masur currently sits on the Corporate Board of the Motion Picture & Television Fund. License to Drive is a 1988 teen adventure film written by Neil Tolkin and directed by Greg Beeman in his feature film directorial debut. It stars Corey Haim, Corey Feldman, Heather Graham, Carol Kane, Richard Masur, Michael Manasseri and Nina Siemaszko. \u2192 \u2192 \u2192 Question: License to Drive featured what future president of the Screen Actors Guild? Answer: Richard Masur Evidence: The British Broadcasting Corporation (BBC) is a British public service broadcaster with its headquarters at Broadcasting House in London. The BBC is the world's oldest national broadcasting organisation and the largest broadcaster in the world by number of employees. It employs over 20,950 staff in total, 16,672 of whom are in public sector broadcasting. The total number of staff is 35,402 when part-time, flexible, and fixed contract staff are included. Tenko was a television drama, co-produced by the BBC and the ABC. \u2192 \u2192 \u2192 Question: Where is the headquarters for the service broadcaster the show Tenko is on? Answer: Broadcasting House in London Evidence: Thomas Matthew \"Tom\" Chappell (born 1943) is an American businessman and manufacturer and co-founder of Tom's of Maine in 1970. Tom's of Maine is a brandname and manufacturer of natural-ingredients-only personal care products, a majority-owned subsidiary of Colgate-Palmolive since 2006. The company's products are intentionally mostly made without ingredients that are: chemically derived, have a negative environmental impact, or are tested on animals. While most of its products are vegan, some contain propolis and/or beeswax sourced from bees. \u2192 \u2192 \u2192 Question: Thomas Matthew \"Tom\" Chappell co-founded a commpany in 1970 that manufactures what products? Answer: natural-ingredients-only personal care products Evidence: Francis Bacon, 1st Viscount St Alban, {'1': \", '2': \", '3': \", '4': \"} ( ; 22 January 15619 April 1626) was an English philosopher, statesman, scientist, jurist, orator, and author. He served both as Attorney General and as Lord Chancellor of England. After his death, he remained extremely influential through his works, especially as philosophical advocate and practitioner of the scientific method during the scientific revolution. James Spedding (28 June 1808 -9 March 1881) was an English author, chiefly known as the editor of the works of Francis Bacon. Question: James Spedding was chiefly known as the editor of the works of an author who served both as Attorney General and as what? Answer: Lord Chancellor of England Evidence: Romeo Montague (Italian: \"Romeo Montecchi\" ) is the protagonist of William Shakespeare's tragedy \"Romeo and Juliet\".The son of Montague and his wife, he secretly loves and marries Juliet, a member of the rival House of Capulet. Forced into exile after slaying Juliet's cousin, Tybalt, in a duel, Romeo commits suicide upon hearing falsely of Juliet's death. Benvolio is a fictional character in Shakespeare's drama \"Romeo and Juliet\". He is Montague's nephew and Romeo's cousin. Benvolio serves as an unsuccessful peacemaker in the play, attempting to prevent violence between the Capulet and Montague families. character does this protagonist, who secretly loves and marries a member of the rival house, of William Shakespeare's tragedy that has a fictional character Benvolio slay? \u2192 Answer: Tybalt Evidence: Francesca Schiavone (] ; born 23 June 1980 in Milan) is an Italian tennis player who turned professional in 1998. She won the 2010 French Open singles title, becoming the first Italian woman to win a Grand Slam event in singles. She was also runner-up at the 2011 French Open. Her career high ranking is world No. 4, achieved on 31 January 2011. To date, Schiavone is the last one handed-backhand player to win a Grand Slam title on the women's tour. Carly Gullickson (born November 26, 1986) is a former American professional tennis player. \u2192 \u2192 \u2192 Question: What occupation have Carly Gullickson and Francesca Schiavone both held? Answer: professional tennis player.\n\n\nQuestion: Where was the opera, which was the subject of After Aida, first performed? Answer: Teatro alla Scala Evidence: The Commodore 16 is a home computer made by Commodore International with a 6502-compatible 7501 or 8501 CPU, released in 1984 and intended to be an entry-level computer to replace the VIC-20. A cost-reduced version, the Commodore 116, was sold only in Europe. In the middle of 1984 a Brazilian company called Prol\u00f3gica, which made its own versions of 8 bits US computers, brought to the Brazilian market a new equipment for its personal computer series called \"CP\" (shorten of Personal Computer in Portuguese). \u2192 \u2192 \u2192 Question: Were the Commodore 16 and Prol\u00f3gica CP-400 from the same country? Answer: no A.3.3 StrategyQA Evidence: The Albanian Declaration of Independence is written in Albanian, Gheg, Tosk, and Ottoman Turkish. The Arvanite Greek's are a major Tosk speaking group of southern Albania. \u2192 Question: Can an Arvanite Greek understand some of the Albanian Declaration of Independence? Answer: true Evidence: An anxious person may benefit from medication or therapy. The Wizard of Oz cannot give courage to anyone. Question: Would an anxious person benefit from receiving courage from the Wizard of Oz? Answer: false\n\n\n\u2192 Question: Would a silicon shortage be bad for Intel's sales? Answer: true Evidence: The Superbowl is the championship game of the National Football League The National Football League is a sports league for American football American football enjoys the majority of its popularity in the United States The bengal fox is found exclusively on the Indian subcontinent \u2192 \u2192 Question: Is a bengal fox likely to see the Superbowl? Answer: false Evidence: The letter B is the second letter in the Latin Alphabet. There was one total lunar eclipse in 2008. Question: Does the letter B's place in alphabet exceed number of 2008 total lunar eclipses? Answer: true Evidence: The Battle of Baghdad was the U.S. invasion of Baghdad in the year 2003. Justin Bieber's album Believe was released in 2012. Question: Did U.S. soldiers listen to Justin Bieber's Believe album during the Battle of Baghdad? Answer: false Evidence: The Italian Renaissance was a period of history from the 13th century to 1600. A theocracy is a type of rule in which religious leaders have power. Friar Girolamo Savonarola was the ruler of Florence, after driving out the Medici family, from November 1494 -23 May 1498. \u2192 Question: Was Florence a Theocracy during Italian Renaissance? Answer: true Evidence: The Tohoku earthquake led to the Fukushima Daiichi nuclear power plant meltdown Nuclear meltdowns lead to a release of deadly levels of radiation Godzilla draws power from radiation and is not hurt by it \u2192 Question: Could Godzilla have been killed by the Tohoku earthquake? Answer: false Evidence: Robert Moses Grove was a baseball player nicknamed Lefty Grove. Pablo Escobar had several nicknames including: Don Pablo, El Padrino, and El Patr\u00f3n. \u2192 Question: Did Pablo Escobar's nickname collection outshine Robert Moses Grove's? Answer: true Evidence: Anaheim is the biggest city in Orange County, California Anaheim was founded by fifty German families People from Germany speak German Question: Did the founders of the biggest city in Orange County, California speak Italian? Answer: false Evidence: Aerosmith is an American rock band that has five active members. The 2020 Mitsubishi Outlander has flexible seating that allows for seven seat capacity. \u2192 Question: Can Aerosmith fit in a 2020 Mitsubishi Outlander? Answer: true Evidence: The War in Vietnam (1945-46) lasted around 6 months. The gestation period for a llama is 11 months. Question: Could a llama birth twice during War in Vietnam (1945-46)? Answer: false\n\n\nKellyanne Conway has been embroiled in a series of controversies. Answer: true Evidence: The village has around 2000 families . This village is famous for the celebrations of Batukamma festival celebrated during Dushera.People from near by villages come here to play Batukamma . \u2192 Question: Tatum O'Neal had three children with juvenile arthritis. Answer: error Evidence: It is being directed by Brian Fee , a storyboard artist on Cars -LRB-2006 -RRB-and Cars 2 -LRB-2011 -RRB-. Question: Cars 3 isn't the third Cars movie Brian Fee has worked on. Answer: false Evidence: Shut Up '' is a song by English Grime artist and MC Stormzy . Question: Shut Up is a song. Answer: true Evidence: Patrice Loko , French former footballer Question: The dramatic film The Good German was directed by Steven Soderburgh. Answer: error Evidence: Poseidon grossed $ 181,674,817 at the worldwide box office on a budget of $ 160 million . Question: Poseidon lost $181,674,817. Answer: false Evidence: Qui-Gon Jinn is a fictional character in the Star Wars franchise , portrayed by Liam Neeson as the main protagonist of the 1999 film Star Wars : Episode I --The Phantom Menace '' . \u2192 Question: Qui-Gon Jinn is a character in the Star Wars franchise. Answer: true Evidence: It is only known from a partial skull and several vertebrae , but comparisons with other species of monitor lizard put its size between 60 and in length . \u2192 Question: The Mormon population has grown significantly since 1980. Answer: error Evidence: Python features a dynamic type system and automatic memory management and supports multiple programming paradigms , including object-oriented , imperative , functional programming , and procedural styles . \u2192 Question: Python lacks a dynamic type system. Answer: false Evidence: The series was nominated for four Annie Awards in 2017 , winning three in the categories of Outstanding Achievement in Character Animation , Character Design , and Storyboarding in an Animated Television/Broadcast Production . Trollhunters is an American computer-animated fantasy television series created for Netflix by Guillermo del Toro and produced by DreamWorks Animation and Double Dare You . \u2192 \u2192 Question: Trollhunters is animated. Answer: true Evidence: Guillermo Kuschel -LRB-born 1918 -RRB-, Chile-born entomologist living in New Zealand Maximilian Kuschel -LRB-1851 --1909 -RRB-, German ornithologist and oologist \u2192 Question: Shawn Carlson is American and German. Answer: error Evidence: Kutcher subsequently appeared in more romantic comedies , including Guess Who -LRB-2005 -RRB-, A Lot Like Love -LRB-2005 -RRB-, What Happens in Vegas -LRB-2008 -RRB-, and No Strings Attached -LRB-2011 -RRB-. No Strings Attached is a 2011 American romantic comedy film directed by Ivan Reitman and written by Elizabeth Meriwether .\n\n\nEvidence: List of nominated members of Rajya Sabha. No. Name Field Affiliation Date of Appointment Date of Retirement Roopa Ganguly Art Bharatiya Janata Party 04-Oct-2016 03-Oct-2022 Sambhaji Raje Social work Bharatiya Janata Party 07-Jun-2016 03-May-2022 Suresh Gopi Art Bharatiya Janata Party 25-Apr-2016 24-Apr-2022 Subramanian Swamy Economics Bharatiya Janata Party 25-Apr-2016 24-Apr-2022 5 Narendra Jadhav Economics Nominated 25-Apr-2016 24-Apr-2022 6 Mary Kom Sport Nominated 25-Apr-2016 24-Apr-2022 7 Swapan Dasgupta Journalism Nominated 25-Apr-2016 24-Apr-2022 8 K.T.S. Tulsi Law Nominated 25-Feb-2014 24-Feb-2020 9 K. Parasaran Law Nominated 09-Jun-2012 28-Jun-2018 10 Rekha Art Nominated 27-Apr-2012 26-Apr-2018 11 Sachin Tendulkar Social service Nominated 27-Apr-2012 26-Apr-2018 12 Anu Aga Business Nominated 27-Apr-2012 26-Apr-2018\n\n26 -\n26\u2192 Question: where was the movie the glass castle filmed Evidence: The Glass Castle (film). Principal photography began on May 20, 2016, in Welch, West Virginia. Question: who was the first lady nominated member of the rajya sabha Evidence: List of nominated members of Rajya Sabha. No. Name Field Affiliation Date of Appointment Date of Retirement Roopa Ganguly Art Bharatiya Janata Party 04-Oct-2016 03-Oct-2022 Sambhaji Raje Social work Bharatiya Janata Party 07-Jun-2016 03-May-2022 Suresh Gopi Art Bharatiya Janata Party 25-Apr-2016 24-Apr-2022 Subramanian Swamy Economics Bharatiya Janata Party 25-Apr-2016 24-Apr-2022 5 Narendra Jadhav Economics Nominated 25-Apr-2016 24-Apr-2022 6 Mary Kom Sport Nominated 25-Apr-2016 24-Apr-2022 7 Swapan Dasgupta Journalism Nominated 25-Apr-2016 24-Apr-2022 8 K.T.S. Tulsi Law Nominated 25-Feb-2014 24-Feb-2020 9 K. Parasaran Law Nominated 09-Jun-2012 28-Jun-2018 10 Rekha Art Nominated 27-Apr-2012 26-Apr-2018 11 Sachin Tendulkar Social service Nominated 27-Apr-2012 26-Apr-2018 12 Anu Aga Business Nominated 27-Apr-2012 AprQuestion: what is on a mcchicken sandwich from mcdonalds Evidence: McChicken. The McChicken is a chicken sandwich sold by the international fast-food chain McDonald's. The sandwich consists of a toasted wheat bun, a breaded chicken patty, shredded lettuce, and mayonnaise. \u2192 Question: what is the tigers name in life of pi Evidence: Life of Pi. Life of Pi is a Canadian fantasy adventure novel by Yann Martel published in 2001. The protagonist is Piscine Molitor \"Pi\"\n\n\nQuestion: what are the main functions of the stem Evidence: Plant stem. Support for and the elevation of leaves, flowers and fruits. The stems keep the leaves in the light and provide a place for the plant to keep its flowers and fruits. Transport of fluids between the roots and the shoots in the xylem and phloem Storage of nutrients Production of new living tissue. The normal lifespan of plant cells is one to three years. Stems have cells called meristems that annually generate new living tissue.\n\n\nQA model up-to-dateQuestions \nAll Post-2020 \nCB \n26.3 \n15.8 \nOB \n\na|q,p \nGoogle \n\n28.1 \n22.4 \n\n\n\nTable 2 :\n2Exact Match performance on SituatedQA.We now test whether using a commercial engine as a source of upto-date information about the world can help stale models answer questions about new events. Since Gopher-280B was trained with data up to (and including) November 2020, questions about facts beyond that date would not have been seen in its training data. To derive such questions, we use the SituatedQA dataset[38] which contains questions grounded in different dates.Table 2presents the exact match results on the complete development set of questions (all) -we also create a smaller subset of 80 questions about facts in 2021 and beyond to test adaptation to new information (post-2020). As evident by the higher performance of OB a|q,p\n\n\nHilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christopher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, et al. Webgpt: Browser-assisted question-answering with human feedback. arXiv preprint arXiv:2112.09332, 2021. Devendra Sachan, Siva Reddy, Will Hamilton, Chris Dyer, and Dani Yogatama. End-to-end training of multi-document reader and retriever for open-domain question answering. Advances in Neural Information Processing Systems, 34, 2021.[12] Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Dmytro Okhonko, Samuel Broscheit, \nGautier Izacard, Patrick Lewis, Barlas Oguz, Edouard Grave, Wen-tau Yih, et al. The web \nis your oyster-knowledge-intensive nlp against a very large web corpus. arXiv preprint \narXiv:2112.09924, 2021. \n\n[13] Romal Thoppilan, Daniel De Freitas, Jamie Hall, Noam Shazeer, Apoorv Kulshreshtha, Heng-\nTze Cheng, Alicia Jin, Taylor Bos, Leslie Baker, Yu Du, et al. Lamda: Language models for \ndialog applications. arXiv preprint arXiv:2201.08239, 2022. \n\n[14] Ohad Rubin, Jonathan Herzig, and Jonathan Berant. Learning to retrieve prompts for in-context \nlearning. arXiv preprint arXiv:2112.08633, 2021. \n\n[15] Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and Weizhu Chen. \nWhat makes good in-context examples for gpt-3? arXiv preprint arXiv:2101.06804, 2021. \n\n[16] Dani Yogatama, Cyprien de Masson d'Autume, and Lingpeng Kong. Adaptive semiparametric \nlanguage models. Transactions of the Association for Computational Linguistics, 2021. \n\n[17] Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie \nMillican, George van den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark, \net al. Improving language models by retrieving from trillions of tokens. arXiv preprint \narXiv:2112.04426, 2021. \n\n[18] [19] Isabelle Augenstein, Christina Lioma, Dongsheng Wang, Lucas Chaves Lima, Casper Hansen, \nChristian Hansen, and Jakob Grue Simonsen. MultiFC: A real-world multi-domain dataset for \nevidence-based fact checking of claims. In Proceedings of the 2019 Conference on Empirical \nMethods in Natural Language Processing and the 9th International Joint Conference on Natural \nLanguage Processing (EMNLP-IJCNLP), 2019. \n\n[20] Angela Fan, Aleksandra Piktus, Fabio Petroni, Guillaume Wenzek, Marzieh Saeidi, Andreas \nVlachos, Antoine Bordes, and Sebastian Riedel. Generating fact checking briefs. arXiv preprint \narXiv:2011.05448, 2020. \n\n[21] Jacob Menick, Maja Trebacz, Vladimir Mikulik, John Aslanides, Francis Song, Martin Chad-\nwick, Mia Glaese, Susannah Young, Lucy Campbell-Gillingham, Geoffrey Irving, and Nat \nMcAleese. Teaching language models to support answers with verified quotes. arXiv submission, \n2022. \n\n[22] Leonard Adolphs, Benjamin Boerschinger, Christian Buck, Michelle Chen Huebscher, Massi-\nmiliano Ciaramita, Lasse Espeholt, Thomas Hofmann, and Yannic Kilcher. Boosting search \nengines with interactive agents. arXiv preprint arXiv:2109.00527, 2021. \n\n[23] Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. \nPre-train, prompt, and predict: A systematic survey of prompting methods in natural language \nprocessing. arXiv preprint arXiv:2107.13586, 2021. \n\n[24] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le, and Denny \nZhou. Chain of thought prompting elicits reasoning in large language models. arXiv preprint \narXiv:2201.11903, 2022. \n\n[25] Abdessamad Echihabi and Daniel Marcu. A noisy-channel approach to question answering. \nTechnical report, University of Southern California, Maria Del Rey, Information Sciences \nInstitute, 2003. \n\n[26] Mike Lewis and Angela Fan. Generative question answering: Learning to answer the whole \nquestion. In ICLR, 2019. \n\n\n\nEvidence: \"Your Love\" is a song by the English rock band the Outfield, taken from their debut album Play Deep(1985). The song was penned by the band's guitarist John Spinks. \u2192 Question: who sings i just want to use your love tonight Answer: English rock band the Outfield Evidence: Principal photography began on May 20, 2016, in Welch, West Virginia. Question: where was the movie the glass castle filmed Answer: in Welch, West VirginiaA.3.1 NQ \n\nEvidence: Top 20 rankings as of 16 October 2017 Rank Change Team Points Germany 1631 Brazil 1619 Portugal 1446 Argentina 1445 5 Belgium 1333 6 Poland \n1323 7 France 1226 8 Spain 1218 9 Chile 1173 10 Peru 1160 11 Switzerland 1134 12 England 1116 13 Colombia 1095 14 Wales 1072 15 Italy 1066 16 \nMexico 1060 17 Uruguay 1034 18 Croatia 1013 19 7 Denmark 1001 20 9 Netherlands 931 * Change from 14 September 2017 Complete rankings at FIFA.com \n\n\u2192 \n\u2192 \nQuestion: who has been ranked no. 1 in the latest football rankings announced by fifa \nAnswer: Germany \n\n\n\n\nQuestion: who become the ceo of it wipro company in 2016 Answer: Abid Ali Neemuchwala Evidence: WINNER: Geoffrey Zakarian Episode 5 6 7 8 Comments Zakarian WIN IN IN CO IN CO WIN WIN The Next Iron Chef Falkner IN IN WIN IN CO WIN CO OUT Elim: Pressure Chiarello IN CO IN WIN IN IN OUT Elim: Passion Guarnaschelli IN WIN IN IN IN IN OUT Burrell IN IN IN IN WIN OUT Elim: Risk Samuelsson CO IN IN IN OUT Elim: Storytelling MacMillan WIN IN CO OUT Elim: Improvisation Hughes IN IN OUT Elim: Ingenuity Irvine IN OUT Elim: Transformation Mendelsohn OUT Elim: Resourcefulness Evidence: Support for and the elevation of leaves, flowers and fruits. The stems keep the leaves in the light and provide a place for the plant to keep its flowers and fruits. Transport of fluids between the roots and the shoots in the xylem and phloem Storage of nutrients Production of new living tissue. The normal lifespan of plant cells is one to three years. Stems have cells called meristems that annually generate new living tissue.\u2192 \n\u2192 \n\u2192 \nQuestion: when did starbucks become a publicly traded company \nAnswer: June 1992 \n\nEvidence: At the end of December 31, 2015, its employee strength was 170,664. Abid Ali Neemuchwala was appointed as Wipro's CEO after T.K. stepped \ndown in early 2016. \n\u2192 \n\u2192 \n\u2192 \n\u2192 \nQuestion: who wins the next iron chef super chefs \nAnswer: Zakarian \n\u2192 \n\u2192 \n\u2192 \nQuestion: what are the main functions of the stem \nAnswer: Production of new living tissue \n\nA.3.2 HotPotQA \n\nEvidence: Seesaw is a musical with a book by Michael Bennett, music by Cy Coleman, and lyrics by Dorothy Fields. Michael Bennett (April 8, 1943 -\nJuly 2, 1987) was an American musical theatre director, writer, choreographer, and dancer. He won seven Tony Awards for his choreography and \ndirection of Broadway shows and was nominated for an additional eleven. \n\n\u2192 \n\u2192 \nQuestion: When was the writer of Seesaw born? \nAnswer: April 8, 1943 \n\nEvidence: Heinrich August Marschner (16 August 1795 -14 December 1861) was the most important composer of German opera between Weber and Wagner. \nCarl Maria Friedrich Ernst von Weber (18 or 19 November 1786 5 June 1826) was a German composer, conductor, pianist, guitarist and critic, and \nwas one of the first significant composers of the Romantic school. \n\n\u2192 \n\u2192 \nQuestion: Heinrich Marschner was a composer who performed in the time frame after one of the first significant composers in what school of work? \nAnswer: Romantic \n\nEvidence: The Elliott-Donaldson House is a historic mansion in Okolona, Mississippi, U.S.. It was built in 1850, a decade prior to the American Civil \nWar of 1861-1865. By the end of the war, in 1865, Confederate States Army General Nathan Bedford Forrest stayed in the house to rest. It has been \nlisted on the National Register of Historic Places since September 15, 1980. Nathan Bedford Forrest (July 13, 1821 -October 29, 1877), called \nBedford Forrest in his lifetime, was a lieutenant general in the Confederate Army during the American Civil War. \n\n\u2192 \n\u2192 \n\u2192 \nQuestion: What lieutenant general stayed in the Elliott-Donaldson House? \nAnswer: Nathan Bedford Forrest \n\nEvidence: Luca Parmitano (born 27 September 1976 in Patern\u00f2, Sicily) is an Italian engineer and astronaut in the European Astronaut Corps for the \nEuropean Space Agency (ESA). The astronauts work on missions at the International Space Station. He was selected as an ESA astronaut in May 2009. \nProf. Dr. Ulrich Hans Walter (born February 9, 1954) is a German physicist/engineer and a former DFVLR astronaut. \n\n\u2192 \n\u2192 \nQuestion: who is younger Ulrich Walter or Luca Parmitano? \nAnswer: Luca Parmitano \n\nEvidence: A Boltzmann machine is a type of stochastic recurrent neural network (and Markov Random Field). Ludwig Eduard Boltzmann (February 20, 1844 \n-September \n\n\nEvidence: Ivan the Terrible was nicknamed terrible because of his harsh rule. Ivan the Terrible's father, Vasili III Ivanovich, was nicknamed Vasili the Adequate. Ivan the Terrible's grandfather, Ivan III Vasilyevich, was nicknamed Ivan the Great. \u2192 Question: Did Ivan the Terrible's father and grandfather have nicer nicknames? Answer: true Evidence: The Beatles were active from 1960 until 1969. Disco began to appear around 1972. Question: Did the Beatles write any music in the Disco genre? Answer: false Evidence: Ganymede is a moon of Jupiter. Jupiter is the largest planet in our solar system. The solar system is part of the Milky Way galaxy. Evidence: Segarra served as Military Aide to the Military Governor of Puerto Rico Theodore Roosevelt , Jr. and during World War II commanded the 65th Evidence: With an estimated 92.7 million inhabitants , it is the world 's 14th-most-populous country , and the ninth-most-populous Asian country . Question: Vietnam is not the ninth most populous Asian country. Answer: falseQuestion: Is Ganymede in the Milky Way galaxy? \nAnswer: true \n\nA.3.4 FEVER \n\nInfantry Regiment . \n\u2192 \nQuestion: Raees (film) features a Pakistani actress in a lead role. \nAnswer: error \n\n\n\n\nwho was the first lady nominated member of the rajya sabha Evidence: McChicken. The McChicken is a chicken sandwich sold by the international fast-food chain McDonald's. The sandwich consists of a toasted wheat bun, a breaded chicken patty, shredded lettuce, and mayonnaise. \u2192 Answer: a breaded chicken patty Question: what is on a mcchicken sandwich from mcdonalds Evidence: Life of Pi. Life of Pi is a Canadian fantasy adventure novel by Yann Martel published in 2001. The protagonist is Piscine Molitor \"Pi\"Patel, an Indian boy from Pondicherry who explores issues of spirituality and practicality from an early age.He survives 227 days after a shipwreck while stranded on a lifeboat in the Pacific Ocean with a Bengal tiger named Richard Parker. \u2192 \u2192 Answer: Richard Parker Question: what is the tigers name in life of pi Evidence: Malware. Malware, short for malicious software, is an umbrella term used to refer to a variety of forms of harmful or intrusive software, including computer viruses, worms, Trojan horses, ransomware, spyware, adware, scareware, and other malicious programs. It can take the form of executable code, scripts, active content, and other software. Malware is defined by its malicious intent, acting against the requirements of the computer user --and so does not include software that causes unintentional harm due to some deficiency. Malware Question: the general term for software that is designed to damage disable or steal data is Evidence: Mum (TV series). Mum Genre Sitcom Created by Stefan Golaszewski Written by Stefan Golaszewski Directed by Richard Laxton Stefan Golaszewski Starring Lesley Manville Peter Mullan Sam Swainsbury Lisa McGrillis Opening theme Cups by Lulu and the Lampshades Country of origin United Kingdom Original language (s) English No. of series No. of episodes 12 (to 27 March 2018) Production Running time 30 minutes Production company (s) Big Talk Productions Distributor ITV Studios Release Original network BBC Two (2016-present) BBC Two HD (2016-present) Picture format 16: 9 1080i Audio format Stereo Original release 13 May 2016 (2016-05-13) --present Answer: Lulu and the Lampshades Question: who sings the theme tune to mum on bbc2 Evidence: Chess World Cup 2017. The Chess World Cup 2017 was a 128-player single-elimination chess tournament, held in Tbilisi, Georgia, from 2 to 27 September 2017. It was won by Armenian grandmaster Levon Aronian. This was the second time he had won the Chess World Cup, 12 years after his first win in 2005. \u2192 \u2192 Answer: Tbilisi, Georgia Question: where was the world chess tournament 2017 held Evidence: F Is for Family. T.J. Miller as Randy Kevin Michael Richardson as Rosie, others David Koechner as Robert \"Bob Pogo\" Pogrohvich, Frank's obese, chainsmoking boss. Kevin Farley as Babe, Carl, others Gary Cole as Rodger Dunbarton, the owner and founder of the airlines where Frank and his co-workers work. Joe Buck as Lou Gagliardi, others John DiMaggio as Scoop Dunbarton, Roger Dunbarton's racist and moronic nephew. Allison Janney as Henrietta Van Horne T.J. Miller as Randy Michael K. Williams as Smoky \u2192 \u2192 \u2192 Answer: T.J. Miller Question: who voices randy in f is for family Evidence: Las Vegas Stadium. Las Vegas Stadium is the working name for a domed stadium under construction in Paradise, Nevada for the Las Vegas Raiders of the National Football League (NFL) and the UNLV Rebels football team from the University of Nevada, Las Vegas (UNLV). It is located on about 62 acres west of Mandalay Bay at Russell Road and Hacienda Avenue and between Polaris Avenue and Dean Martin Drive, just west of Interstate 15. Construction of the $1.9 billion stadium began in September 2017 and is expected to be completed in time for the 2020 NFL season. Paradise, Nevada Question: where are they building the new raiders stadium Evidence: Starbucks. At the time of its initial public offering (IPO) on the stock market in June 1992, Starbucks had 140 outlets, with a revenue of US $ 73.5 million, up from US $1.3 million in 1987. The company's market value was US $271 million by this time. The 12% portion of the company that was sold raised around US $25 million for the company, which facilitated a doubling of the number of stores over the next two years. By September 1992, Starbucks ' share price had risen by 70% to over 100 times the earnings per share of the previous year. Question: when did starbucks become a publicly traded company Evidence: Wipro. At the end of December 31, 2015, its employee strength was 170,664. Abid Ali Neemuchwala was appointed as Wipro's CEO after T.K. stepped down in early 2016. \u2192 Answer: Abid Ali Neemuchwala Question: who become the ceo of it wipro company in 2016 Evidence: The Next Iron Chef. WINNER: Geoffrey Zakarian Episode 5 6 7 8 Comments Zakarian WIN IN IN CO IN CO WIN WIN The Next Iron Chef Falkner IN IN WIN IN CO WIN CO OUT Elim: Pressure Chiarello IN CO IN WIN IN IN OUT Elim: Passion Guarnaschelli IN WIN IN IN IN IN OUT Burrell IN IN IN IN WIN OUT Elim: Risk Samuelsson CO IN IN IN OUT Elim: Storytelling MacMillan WIN IN CO OUT Elim: Improvisation Hughes IN IN OUT Elim: Ingenuity Irvine IN OUT Elim: Transformation Mendelsohn OUT Elim: Resourcefulness \u2192 \u2192 \u2192 Answer: Zakarian Question: who wins the next iron chef super chefs Evidence: Plant stem. Support for and the elevation of leaves, flowers and fruits. The stems keep the leaves in the light and provide a place for the plant to keep its flowers and fruits. Transport of fluids between the roots and the shoots in the xylem and phloem Storage of nutrients Production of new living tissue. The normal lifespan of plant cells is one to three years. Stems have cells called meristems that annually generate new living tissue. Production of new living tissue Question: what are the main functions of the stem A.4.2 Calculating p(q | p i ) Same as above, but omitting the Answer field of the prompt. Question: who has been ranked no. 1 in the latest football rankings announced by fifa Evidence: FIFA World Rankings. Top 20 rankings as of 16 October 2017 Rank Change Team Points Germany 1631 Brazil 1619 Portugal 1446 Argentina 1445 5 Belgium 1333 6 Poland 1323 7 France 1226 8 Spain 1218 9 Chile 1173 10 Peru 1160 11 Switzerland 1134 12 England 1116 13 Colombia 1095 14 Wales 1072 15 Italy 1066 16 Mexico 1060 17 Uruguay 1034 18 Croatia 1013 19 7 Denmark 1001 20 9 Netherlands 931 * Change from 14 September 2017 Complete rankings at FIFA.com Question: who sings i just want to use your love tonight Evidence: Your Love (The Outfield song). \"Your Love\" is a song by the English rock band the Outfield, taken from their debut album Play Deep (1985). The song was penned by the band's guitarist John Spinks.\u2192 \n\u2192 \n\u2192 \n\u2192 \n\u2192 \nAnswer: Mary Kom \nQuestion: \u2192 \n\u2192 \n\u2192 \nAnswer: \u2192 \n\u2192 \n\u2192 \n\u2192 \n\u2192 \n\u2192 \n\u2192 \nAnswer: \u2192 \n\u2192 \n\u2192 \nAnswer: June 1992 \n\u2192 \n\u2192 \n\u2192 \nAnswer: A.4.3 Calculating p(p i | q) \n\n\u2192 \n\u2192 \n\u2192 \n\n\n\n\n). Mum Genre Sitcom Created by Stefan Golaszewski Written by Stefan Golaszewski Directed by Richard Laxton Stefan Golaszewski Starring Lesley Manville Peter Mullan Sam Swainsbury Lisa McGrillis Opening theme Cups by Lulu and the Lampshades Country of origin United Kingdom Original language (s) English No. of series No. of episodes 12 (to 27 March 2018) Production Running time 30 minutes Production company (s) Big Talk Productions Distributor ITV Studios Release Original network BBC Two (2016-present) BBC Two HD (2016-present) Picture format 16: 9 1080i Audio format Stereo Original release 13 May 2016 (2016-05-13) --present Question: where was the world chess tournament 2017 held Evidence: Chess World Cup 2017. The Chess World Cup 2017 was a 128-player single-elimination chess tournament, held in Tbilisi, Georgia, from 2 to 27 September 2017. It was won by Armenian grandmaster Levon Aronian. This was the second time he had won the Chess World Cup, 12 years after his first win in 2005. Question: who voices randy in f is for family Evidence: F Is for Family. T.J. Miller as Randy Kevin Michael Richardson as Rosie, others David Koechner as Robert \"Bob Pogo\" Pogrohvich, Frank's obese, chainsmoking boss. Kevin Farley as Babe, Carl, others Gary Cole as Rodger Dunbarton, the owner and founder of the airlines where Frank and his co-workers work. Joe Buck as Lou Gagliardi, others John DiMaggio as Scoop Dunbarton, Roger Dunbarton's racist and moronic nephew. Allison Janney as Henrietta Van Horne T.J. Miller as Randy Michael K. Williams as Smoky Question: where are they building the new raiders stadium Evidence: Las Vegas Stadium. Las Vegas Stadium is the working name for a domed stadium under construction in Paradise, Nevada for the Las Vegas Raiders of the National Football League (NFL) and the UNLV Rebels football team from the University of Nevada, Las Vegas (UNLV). It is located on about 62 acres west of Mandalay Bay at Russell Road and Hacienda Avenue and between Polaris Avenue and Dean Martin Drive, just west of Interstate 15. Construction of the $1.9 billion stadium began in September 2017 and is expected to be completed in time for the 2020 NFL season. Question: when did starbucks become a publicly traded company Evidence: Starbucks. At the time of its initial public offering (IPO) on the stock market in June 1992, Starbucks had 140 outlets, with a revenue of US $ 73.5 million, up from US $1.3 million in 1987. The company's market value was US $271 million by this time. The 12% portion of the company that was sold raised around US $25 million for the company, which facilitated a doubling of the number of stores over the next two years. By September 1992, Starbucks ' share price had risen by 70% to over 100 times the earnings per share of the previous year. Question: who become the ceo of it wipro company in 2016 Evidence: Wipro. At the end of December 31, 2015, its employee strength was 170,664. Abid Ali Neemuchwala was appointed as Wipro's CEO after T.K. stepped down in early 2016. \u2192 Question: who wins the next iron chef super chefs Evidence: The Next Iron Chef. WINNER: Geoffrey Zakarian Episode 5 6 7 8 Comments Zakarian WIN IN IN CO IN CO WIN WIN The Next Iron Chef Falkner IN IN WIN IN CO WIN CO OUT Elim: Pressure Chiarello IN CO IN WIN IN IN OUT Elim: Passion Guarnaschelli IN WIN IN IN IN IN OUT Burrell IN IN IN IN WIN OUT Elim: Risk Samuelsson CO IN IN IN OUT Elim: Storytelling MacMillan WIN IN CO OUT Elim: Improvisation Hughes IN IN OUT Elim: Ingenuity Irvine IN OUT Elim: Transformation Mendelsohn OUT Elim: Resourcefulness\u2192 \n\u2192 \n\u2192 \n\u2192 \n\n\u2192 \n\u2192 \n\n\u2192 \n\u2192 \n\u2192 \n\n\u2192 \n\u2192 \n\u2192 \n\u2192 \n\u2192 \n\u2192 \n\n\nhttps://developers.google.com/custom-search\nThe interpolation weights of probabilities are optimized on a held-out set of 10% of data.3 See Appendix A.3 for the prompts we used for each dataset.\nWe found that performance plateaued near the 50 samples -using the same prompt to sample many answers results in decreased diversity.\n Khandelwal et al. [5]  also find that training smaller models with large datastores surpasses perplexity performance of bigger language models.\nThe published test set results for the fine-tuned open-book and closed-book are 23.0% and 18.3%[38].7 Upon acceptance, we will make the Google Retrieved urls used for our experiments public for reproducibility.\nAcknowledgementsWe thank Chris Dyer and Kris Cao for their valuable feedback at various stages of this project, and Domenic Donato for helping us develop some of the initial ideas that lead to this project. We would also like to thank the DeepMind researchers who have contributed in building the internal language modelling codebase and the associated tools our research was built upon. Finally, we would like to thank our colleagues in the DeepMind Language team for their insightful comments and suggestions.\nLanguage models are unsupervised multitask learners. OpenAI blog. Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, Ilya Sutskever, et al. Language models are unsupervised multitask learners. OpenAI blog, 2019.\n\n. Jack W Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann, H Francis Song, John Aslanides, Sarah Henderson, Roman Ring, Susannah Young, Eliza Rutherford, Tom Hennigan, Jacob Menick, Albin Cassirer, Richard Powell, George Van Den Driessche, Lisa Anne Hendricks, Maribeth Rauh, Po-Sen Huang, Amelia Glaese, Johannes Welbl, Sumanth Dathathri, Saffron Huang, Jonathan Uesato, John Mellor, Irina Higgins, Antonia Creswell, Nat Mcaleese, Amy Wu, Erich Elsen, M Siddhant, Elena Jayakumar, David Buchatskaya, Esme Budden, Karen Sutherland, Michela Simonyan, Laurent Paganini, Lena Sifre, Xiang Lorraine Martens, Adhiguna Li, Aida Kuncoro, Elena Nematzadeh, Domenic Gribovskaya, Donato, arXiv:2112.11446Oriol Vinyals, Kareem Ayoub. Angeliki Lazaridou, Arthur Mensch, Jean-Baptiste Lespiau, Maria Tsimpoukelli, Nikolai Grigorev, Doug Fritz, Thibault Sottiaux, Mantas Pajarskas, Toby Pohlen, Zhitao Gong, Daniel Toyama, Cyprien de Masson d'Autume, Yujia Li, Tayfun Terzi, Vladimir Mikulik, Igor Babuschkin, Aidan Clark, Diego de Las Casas, Aurelia Guy, Chris Jones, James Bradbury, Matthew Johnson, Blake A. Hechtman, Laura Weidinger, Iason Gabriel, William S. Isaac, Edward Lockhart, Simon OsinderoarXiv preprintDemis Hassabis, Koray Kavukcuoglu, and Geoffrey Irving. Scaling language models: Methods, analysis & insights from training gopherJack W. Rae, Sebastian Borgeaud, Trevor Cai, Katie Millican, Jordan Hoffmann, H. Francis Song, John Aslanides, Sarah Henderson, Roman Ring, Susannah Young, Eliza Rutherford, Tom Hennigan, Jacob Menick, Albin Cassirer, Richard Powell, George van den Driessche, Lisa Anne Hendricks, Maribeth Rauh, Po-Sen Huang, Amelia Glaese, Johannes Welbl, Sumanth Dathathri, Saffron Huang, Jonathan Uesato, John Mellor, Irina Higgins, Antonia Creswell, Nat McAleese, Amy Wu, Erich Elsen, Siddhant M. Jayakumar, Elena Buchatskaya, David Budden, Esme Sutherland, Karen Simonyan, Michela Paganini, Laurent Sifre, Lena Martens, Xiang Lorraine Li, Adhiguna Kuncoro, Aida Nematzadeh, Elena Gribovskaya, Domenic Donato, Angeliki Lazaridou, Arthur Mensch, Jean-Baptiste Lespiau, Maria Tsimpoukelli, Nikolai Grigorev, Doug Fritz, Thibault Sottiaux, Mantas Pajarskas, Toby Pohlen, Zhitao Gong, Daniel Toyama, Cyprien de Masson d'Autume, Yujia Li, Tayfun Terzi, Vladimir Mikulik, Igor Babuschkin, Aidan Clark, Diego de Las Casas, Aurelia Guy, Chris Jones, James Bradbury, Matthew Johnson, Blake A. Hechtman, Laura Weidinger, Iason Gabriel, William S. Isaac, Edward Lockhart, Simon Osindero, Laura Rimell, Chris Dyer, Oriol Vinyals, Kareem Ayoub, Jeff Stanway, Lorrayne Bennett, Demis Hassabis, Koray Kavukcuoglu, and Geoffrey Irving. Scaling language models: Methods, analysis & insights from training gopher. arXiv preprint arXiv:2112.11446, 2021.\n\nLanguage models are few-shot learners. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Advances in neural information processing systems. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are few-shot learners. Advances in neural information processing systems, 2020.\n\nJoshua Maynez, Shashi Narayan, Bernd Bohnet, Ryan Mcdonald, arXiv:2005.00661On faithfulness and factuality in abstractive summarization. arXiv preprintJoshua Maynez, Shashi Narayan, Bernd Bohnet, and Ryan McDonald. On faithfulness and factuality in abstractive summarization. arXiv preprint arXiv:2005.00661, 2020.\n\nGeneralization through memorization: Nearest neighbor language models. Urvashi Khandelwal, Omer Levy, Dan Jurafsky, Luke Zettlemoyer, Mike Lewis, arXiv:1911.00172arXiv preprintUrvashi Khandelwal, Omer Levy, Dan Jurafsky, Luke Zettlemoyer, and Mike Lewis. Gen- eralization through memorization: Nearest neighbor language models. arXiv preprint arXiv:1911.00172, 2019.\n\nKelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, Ming-Wei Chang, arXiv:2002.08909Realm: Retrieval-augmented language model pre-training. arXiv preprintKelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Ming-Wei Chang. Realm: Retrieval-augmented language model pre-training. arXiv preprint arXiv:2002.08909, 2020.\n\nRetrieval-augmented generation for knowledge-intensive nlp tasks. Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich K\u00fcttler, Mike Lewis, Wen-Tau Yih, Tim Rockt\u00e4schel, Sebastian Riedel, Douwe Kiela, Advances in Neural Information Processing Systems. Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich K\u00fcttler, Mike Lewis, Wen-tau Yih, Tim Rockt\u00e4schel, Sebastian Riedel, and Douwe Kiela. Retrieval-augmented generation for knowledge-intensive nlp tasks. In Advances in Neural Information Processing Systems, 2020.\n\nLeveraging passage retrieval with generative models for open domain question answering. Gautier Izacard, Edouard Grave, arXiv:2007.01282arXiv preprintGautier Izacard and Edouard Grave. Leveraging passage retrieval with generative models for open domain question answering. arXiv preprint arXiv:2007.01282, 2020.\n\nRetrieval augmentation reduces hallucination in conversation. Kurt Shuster, Spencer Poff, Moya Chen, Douwe Kiela, Jason Weston, arXiv:2104.07567arXiv preprintKurt Shuster, Spencer Poff, Moya Chen, Douwe Kiela, and Jason Weston. Retrieval augmenta- tion reduces hallucination in conversation. arXiv preprint arXiv:2104.07567, 2021.\n\nInternet-augmented dialogue generation. Mojtaba Komeili, Kurt Shuster, Jason Weston, arXiv:2107.07566arXiv preprintMojtaba Komeili, Kurt Shuster, and Jason Weston. Internet-augmented dialogue generation. arXiv preprint arXiv:2107.07566, 2021.\n\nNatural questions: a benchmark for question answering research. Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Matthew Kelcey, Jacob Devlin, Kenton Lee, Kristina N Toutanova, Llion Jones, Ming-Wei Chang, Andrew Dai, Jakob Uszkoreit, Quoc Le, Slav Petrov, Transactions of the Association of Computational Linguistics. Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Matthew Kelcey, Jacob Devlin, Kenton Lee, Kristina N. Toutanova, Llion Jones, Ming-Wei Chang, Andrew Dai, Jakob Uszkoreit, Quoc Le, and Slav Petrov. Natural questions: a benchmark for question answering research. Transactions of the Association of Computational Linguistics, 2019.\n\nHotpotQA: A dataset for diverse, explainable multi-hop question answering. Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William Cohen, Ruslan Salakhutdinov, Christopher D Manning, Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing. the 2018 Conference on Empirical Methods in Natural Language ProcessingZhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William Cohen, Ruslan Salakhutdinov, and Christopher D. Manning. HotpotQA: A dataset for diverse, explainable multi-hop question answering. In Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing, 2018.\n\nDid aristotle use a laptop? a question answering benchmark with implicit reasoning strategies. Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, Jonathan Berant, Transactions of the Association for Computational Linguistics. Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, and Jonathan Berant. Did aristotle use a laptop? a question answering benchmark with implicit reasoning strategies. Transactions of the Association for Computational Linguistics, 2021.\n\nFEVER: a large-scale dataset for fact extraction and VERification. James Thorne, Andreas Vlachos, Christos Christodoulopoulos, Arpit Mittal, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies1Long Papers)James Thorne, Andreas Vlachos, Christos Christodoulopoulos, and Arpit Mittal. FEVER: a large-scale dataset for fact extraction and VERification. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), 2018.\n\nA multi-level attention model for evidence-based fact checking. Canasai Kruengkrai, Junichi Yamagishi, Xin Wang, arXiv:2106.00950arXiv preprintCanasai Kruengkrai, Junichi Yamagishi, and Xin Wang. A multi-level attention model for evidence-based fact checking. arXiv preprint arXiv:2106.00950, 2021.\n\nVladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, Wen-Tau Yih, arXiv:2004.04906Dense passage retrieval for open-domain question answering. arXiv preprintVladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih. Dense passage retrieval for open-domain question answering. arXiv preprint arXiv:2004.04906, 2020.\n\nAnswering complex open-domain questions with multi-hop dense retrieval. Wenhan Xiong, Lorraine Xiang, Srini Li, Jingfei Iyer, Patrick Du, William Yang Lewis, Yashar Wang, Wen-Tau Mehdad, Sebastian Yih, Douwe Riedel, Kiela, arXiv:2009.12756arXiv preprintWenhan Xiong, Xiang Lorraine Li, Srini Iyer, Jingfei Du, Patrick Lewis, William Yang Wang, Yashar Mehdad, Wen-tau Yih, Sebastian Riedel, Douwe Kiela, et al. Answering complex open-domain questions with multi-hop dense retrieval. arXiv preprint arXiv:2009.12756, 2020.\n\nFinetuned language models are zero-shot learners. Jason Wei, Maarten Bosma, Y Vincent, Kelvin Zhao, Adams Wei Guu, Brian Yu, Nan Lester, Du, M Andrew, Quoc V Dai, Le, arXiv:2109.01652arXiv preprintJason Wei, Maarten Bosma, Vincent Y Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan Du, Andrew M Dai, and Quoc V Le. Finetuned language models are zero-shot learners. arXiv preprint arXiv:2109.01652, 2021.\n\nFast lexically constrained decoding with dynamic beam allocation for neural machine translation. Matt Post, David Vilar, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies1Long Papers)Matt Post and David Vilar. Fast lexically constrained decoding with dynamic beam allocation for neural machine translation. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers), 2018.\n\nNeurologic a* esque decoding: Constrained text generation with lookahead heuristics. Ximing Lu, Sean Welleck, Peter West, Liwei Jiang, Jungo Kasai, Daniel Khashabi, Lianhui Ronan Le Bras, Youngjae Qin, Rowan Yu, Zellers, arXiv:2112.08726arXiv preprintXiming Lu, Sean Welleck, Peter West, Liwei Jiang, Jungo Kasai, Daniel Khashabi, Ronan Le Bras, Lianhui Qin, Youngjae Yu, Rowan Zellers, et al. Neurologic a* esque decoding: Con- strained text generation with lookahead heuristics. arXiv preprint arXiv:2112.08726, 2021.\n\nOn nmt search errors and model errors: Cat got your tongue?. Felix Stahlberg, Bill Byrne, arXiv:1908.10090arXiv preprintFelix Stahlberg and Bill Byrne. On nmt search errors and model errors: Cat got your tongue? arXiv preprint arXiv:1908.10090, 2019.\n\nSituatedQA: Incorporating extra-linguistic contexts into QA. J Q Michael, Eunsol Zhang, Choi, Proceedings of the Conference on Empirical Methods in Natural Language Processing. the Conference on Empirical Methods in Natural Language Processing2021Michael J.Q. Zhang and Eunsol Choi. SituatedQA: Incorporating extra-linguistic contexts into QA. Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), 2021.\n\nEntity-based knowledge conflicts in question answering. Shayne Longpre, Kartik Perisetla, Anthony Chen, Nikhil Ramesh, Chris Dubois, Sameer Singh, arXiv:2109.05052arXiv preprintShayne Longpre, Kartik Perisetla, Anthony Chen, Nikhil Ramesh, Chris DuBois, and Sameer Singh. Entity-based knowledge conflicts in question answering. arXiv preprint arXiv:2109.05052, 2021.\n\nMulti-hop reading comprehension through question decomposition and rescoring. Sewon Min, Victor Zhong, Luke Zettlemoyer, Hannaneh Hajishirzi, arXiv:1906.02916arXiv preprintSewon Min, Victor Zhong, Luke Zettlemoyer, and Hannaneh Hajishirzi. Multi-hop reading com- prehension through question decomposition and rescoring. arXiv preprint arXiv:1906.02916, 2019.\n\nUnsupervised question decomposition for question answering. Ethan Perez, Patrick Lewis, Kyunghyun Wen Tau Yih, Douwe Cho, Kiela, EMNLP. Ethan Perez, Patrick Lewis, Wen tau Yih, Kyunghyun Cho, and Douwe Kiela. Unsupervised question decomposition for question answering. In EMNLP, 2020.\n", "annotations": {"author": "[{\"end\":160,\"start\":100},{\"end\":224,\"start\":161},{\"end\":287,\"start\":225},{\"end\":346,\"start\":288}]", "publisher": null, "author_last_name": "[{\"end\":118,\"start\":109},{\"end\":178,\"start\":167},{\"end\":243,\"start\":234},{\"end\":304,\"start\":296}]", "author_first_name": "[{\"end\":108,\"start\":100},{\"end\":166,\"start\":161},{\"end\":233,\"start\":225},{\"end\":295,\"start\":288}]", "author_affiliation": "[{\"end\":159,\"start\":142},{\"end\":223,\"start\":206},{\"end\":286,\"start\":269},{\"end\":345,\"start\":328}]", "title": "[{\"end\":97,\"start\":1},{\"end\":443,\"start\":347}]", "venue": null, "abstract": "[{\"end\":1871,\"start\":445}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2060,\"start\":2057},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2062,\"start\":2060},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2413,\"start\":2410},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2680,\"start\":2677},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":3394,\"start\":3391},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3397,\"start\":3394},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":3400,\"start\":3397},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":3403,\"start\":3400},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":3514,\"start\":3511},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":4763,\"start\":4759},{\"end\":4767,\"start\":4763},{\"end\":4771,\"start\":4767},{\"end\":4775,\"start\":4771},{\"end\":5757,\"start\":5753},{\"end\":5760,\"start\":5757},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":6647,\"start\":6644},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":6649,\"start\":6647},{\"end\":6652,\"start\":6649},{\"end\":6655,\"start\":6652},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":6925,\"start\":6922},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":6927,\"start\":6925},{\"end\":6930,\"start\":6927},{\"end\":7870,\"start\":7866},{\"end\":7890,\"start\":7886},{\"end\":8046,\"start\":8042},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":8491,\"start\":8487},{\"end\":8494,\"start\":8491},{\"end\":8497,\"start\":8494},{\"end\":8500,\"start\":8497},{\"end\":8535,\"start\":8531},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":8670,\"start\":8666},{\"end\":8673,\"start\":8670},{\"end\":8789,\"start\":8785},{\"end\":8792,\"start\":8789},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":10472,\"start\":10471},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":13567,\"start\":13564},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":13569,\"start\":13567},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":14893,\"start\":14890},{\"end\":15027,\"start\":15023},{\"end\":15030,\"start\":15027},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":15137,\"start\":15136},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":15845,\"start\":15841},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":15878,\"start\":15874},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":15898,\"start\":15894},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":15948,\"start\":15944},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":16783,\"start\":16782},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":17585,\"start\":17582},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":19373,\"start\":19370},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":19934,\"start\":19933},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":20020,\"start\":20017},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":23037,\"start\":23033},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":23114,\"start\":23110},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":25645,\"start\":25641},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":26406,\"start\":26402},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":26409,\"start\":26406},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":29321,\"start\":29320},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":30822,\"start\":30818},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":32575,\"start\":32571},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":32578,\"start\":32577},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":34429,\"start\":34425},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":35357,\"start\":35354},{\"end\":35360,\"start\":35357},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":35479,\"start\":35475},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":35482,\"start\":35479},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":36539,\"start\":36538},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":37890,\"start\":37888},{\"end\":37895,\"start\":37890},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":61579,\"start\":61575},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":82336,\"start\":82335},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":82774,\"start\":82770},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":82776,\"start\":82775}]", "figure": "[{\"attributes\":{\"id\":\"fig_1\"},\"end\":40809,\"start\":40438},{\"attributes\":{\"id\":\"fig_3\"},\"end\":40987,\"start\":40810},{\"attributes\":{\"id\":\"fig_4\"},\"end\":41124,\"start\":40988},{\"attributes\":{\"id\":\"fig_5\"},\"end\":41200,\"start\":41125},{\"attributes\":{\"id\":\"fig_6\"},\"end\":42834,\"start\":41201},{\"attributes\":{\"id\":\"fig_7\"},\"end\":45797,\"start\":42835},{\"attributes\":{\"id\":\"fig_8\"},\"end\":51594,\"start\":45798},{\"attributes\":{\"id\":\"fig_9\"},\"end\":52846,\"start\":51595},{\"attributes\":{\"id\":\"fig_10\"},\"end\":55343,\"start\":52847},{\"attributes\":{\"id\":\"fig_11\"},\"end\":58156,\"start\":55344},{\"attributes\":{\"id\":\"fig_12\"},\"end\":59004,\"start\":58157},{\"attributes\":{\"id\":\"fig_13\"},\"end\":60547,\"start\":59005},{\"attributes\":{\"id\":\"fig_14\"},\"end\":61052,\"start\":60548},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":61150,\"start\":61053},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":61903,\"start\":61151},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":65671,\"start\":61904},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":66674,\"start\":65672},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":70450,\"start\":66675},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":71664,\"start\":70451},{\"attributes\":{\"id\":\"tab_9\",\"type\":\"table\"},\"end\":78559,\"start\":71665},{\"attributes\":{\"id\":\"tab_10\",\"type\":\"table\"},\"end\":82200,\"start\":78560}]", "paragraph": "[{\"end\":2567,\"start\":1887},{\"end\":3215,\"start\":2569},{\"end\":4776,\"start\":3217},{\"end\":6244,\"start\":4778},{\"end\":6539,\"start\":6246},{\"end\":7521,\"start\":6556},{\"end\":9104,\"start\":7523},{\"end\":9165,\"start\":9106},{\"end\":9955,\"start\":9167},{\"end\":11089,\"start\":10006},{\"end\":11648,\"start\":11091},{\"end\":12245,\"start\":11650},{\"end\":12827,\"start\":12305},{\"end\":13316,\"start\":12829},{\"end\":14017,\"start\":13383},{\"end\":14518,\"start\":14019},{\"end\":14967,\"start\":14520},{\"end\":15753,\"start\":15021},{\"end\":17491,\"start\":15776},{\"end\":18257,\"start\":17493},{\"end\":19167,\"start\":18259},{\"end\":19640,\"start\":19169},{\"end\":20210,\"start\":19642},{\"end\":20829,\"start\":20291},{\"end\":21743,\"start\":20831},{\"end\":22856,\"start\":21745},{\"end\":23377,\"start\":22858},{\"end\":23674,\"start\":23379},{\"end\":24463,\"start\":23688},{\"end\":25460,\"start\":24465},{\"end\":25935,\"start\":25462},{\"end\":27468,\"start\":25937},{\"end\":28302,\"start\":27520},{\"end\":30823,\"start\":28304},{\"end\":32579,\"start\":30861},{\"end\":33876,\"start\":32604},{\"end\":34308,\"start\":33878},{\"end\":34893,\"start\":34310},{\"end\":35619,\"start\":34895},{\"end\":36904,\"start\":35621},{\"end\":37139,\"start\":36906},{\"end\":39711,\"start\":37158},{\"end\":40351,\"start\":39719},{\"end\":40437,\"start\":40361}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":15020,\"start\":14968}]", "table_ref": "[{\"end\":20139,\"start\":20132},{\"end\":20787,\"start\":20780},{\"end\":21874,\"start\":21867},{\"end\":23718,\"start\":23711},{\"end\":25611,\"start\":25604}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1885,\"start\":1873},{\"attributes\":{\"n\":\"2\"},\"end\":6554,\"start\":6542},{\"attributes\":{\"n\":\"3.1\"},\"end\":10004,\"start\":9958},{\"attributes\":{\"n\":\"3.2\"},\"end\":12303,\"start\":12248},{\"attributes\":{\"n\":\"3.3\"},\"end\":13381,\"start\":13319},{\"attributes\":{\"n\":\"4\"},\"end\":15774,\"start\":15756},{\"attributes\":{\"n\":\"5\"},\"end\":20220,\"start\":20213},{\"attributes\":{\"n\":\"5.1\"},\"end\":20289,\"start\":20223},{\"attributes\":{\"n\":\"5.2\"},\"end\":23686,\"start\":23677},{\"attributes\":{\"n\":\"5.3\"},\"end\":27518,\"start\":27471},{\"attributes\":{\"n\":\"5.4\"},\"end\":30859,\"start\":30826},{\"attributes\":{\"n\":\"5.5\"},\"end\":32589,\"start\":32582},{\"attributes\":{\"n\":\"6\"},\"end\":32602,\"start\":32592},{\"end\":37156,\"start\":37142},{\"end\":39717,\"start\":39714},{\"end\":40359,\"start\":40354},{\"end\":40449,\"start\":40439},{\"end\":40821,\"start\":40811},{\"end\":40999,\"start\":40989},{\"end\":41136,\"start\":41126},{\"end\":41206,\"start\":41202},{\"end\":59010,\"start\":59006},{\"end\":61161,\"start\":61152}]", "table": "[{\"end\":61150,\"start\":61074},{\"end\":65671,\"start\":62376},{\"end\":66674,\"start\":66111},{\"end\":70450,\"start\":67687},{\"end\":71664,\"start\":71478},{\"end\":78559,\"start\":78384},{\"end\":82200,\"start\":82151}]", "figure_caption": "[{\"end\":40809,\"start\":40451},{\"end\":40987,\"start\":40823},{\"end\":41124,\"start\":41001},{\"end\":41200,\"start\":41138},{\"end\":42834,\"start\":41209},{\"end\":45797,\"start\":42837},{\"end\":51594,\"start\":45800},{\"end\":52846,\"start\":51597},{\"end\":55343,\"start\":52849},{\"end\":58156,\"start\":55346},{\"end\":59004,\"start\":58159},{\"end\":60547,\"start\":59013},{\"end\":61052,\"start\":60550},{\"end\":61074,\"start\":61055},{\"end\":61903,\"start\":61163},{\"end\":62376,\"start\":61906},{\"end\":66111,\"start\":65674},{\"end\":67687,\"start\":66677},{\"end\":71478,\"start\":70453},{\"end\":78384,\"start\":71667},{\"end\":82151,\"start\":78562}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":27204,\"start\":27196},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":29752,\"start\":29744},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":31215,\"start\":31207},{\"end\":37009,\"start\":37001}]", "bib_author_first_name": "[{\"end\":83468,\"start\":83464},{\"end\":83485,\"start\":83478},{\"end\":83495,\"start\":83490},{\"end\":83508,\"start\":83503},{\"end\":83520,\"start\":83515},{\"end\":83533,\"start\":83529},{\"end\":83712,\"start\":83708},{\"end\":83714,\"start\":83713},{\"end\":83729,\"start\":83720},{\"end\":83746,\"start\":83740},{\"end\":83757,\"start\":83752},{\"end\":83774,\"start\":83768},{\"end\":83786,\"start\":83785},{\"end\":83794,\"start\":83787},{\"end\":83805,\"start\":83801},{\"end\":83822,\"start\":83817},{\"end\":83839,\"start\":83834},{\"end\":83854,\"start\":83846},{\"end\":83867,\"start\":83862},{\"end\":83883,\"start\":83880},{\"end\":83899,\"start\":83894},{\"end\":83913,\"start\":83908},{\"end\":83931,\"start\":83924},{\"end\":83946,\"start\":83940},{\"end\":83970,\"start\":83966},{\"end\":83975,\"start\":83971},{\"end\":83995,\"start\":83987},{\"end\":84008,\"start\":84002},{\"end\":84022,\"start\":84016},{\"end\":84039,\"start\":84031},{\"end\":84054,\"start\":84047},{\"end\":84073,\"start\":84066},{\"end\":84089,\"start\":84081},{\"end\":84102,\"start\":84098},{\"end\":84116,\"start\":84111},{\"end\":84133,\"start\":84126},{\"end\":84147,\"start\":84144},{\"end\":84161,\"start\":84158},{\"end\":84171,\"start\":84166},{\"end\":84180,\"start\":84179},{\"end\":84196,\"start\":84191},{\"end\":84213,\"start\":84208},{\"end\":84231,\"start\":84227},{\"end\":84245,\"start\":84240},{\"end\":84265,\"start\":84258},{\"end\":84283,\"start\":84276},{\"end\":84298,\"start\":84294},{\"end\":84311,\"start\":84306},{\"end\":84320,\"start\":84312},{\"end\":84338,\"start\":84330},{\"end\":84347,\"start\":84343},{\"end\":84362,\"start\":84357},{\"end\":84382,\"start\":84375},{\"end\":86524,\"start\":86521},{\"end\":86540,\"start\":86532},{\"end\":86551,\"start\":86547},{\"end\":86566,\"start\":86559},{\"end\":86581,\"start\":86576},{\"end\":86583,\"start\":86582},{\"end\":86600,\"start\":86592},{\"end\":86617,\"start\":86611},{\"end\":86637,\"start\":86631},{\"end\":86651,\"start\":86645},{\"end\":86666,\"start\":86660},{\"end\":86990,\"start\":86984},{\"end\":87005,\"start\":86999},{\"end\":87020,\"start\":87015},{\"end\":87033,\"start\":87029},{\"end\":87378,\"start\":87371},{\"end\":87395,\"start\":87391},{\"end\":87405,\"start\":87402},{\"end\":87420,\"start\":87416},{\"end\":87438,\"start\":87434},{\"end\":87674,\"start\":87668},{\"end\":87686,\"start\":87680},{\"end\":87696,\"start\":87692},{\"end\":87711,\"start\":87703},{\"end\":87729,\"start\":87721},{\"end\":88065,\"start\":88058},{\"end\":88078,\"start\":88073},{\"end\":88096,\"start\":88086},{\"end\":88110,\"start\":88105},{\"end\":88128,\"start\":88120},{\"end\":88145,\"start\":88140},{\"end\":88161,\"start\":88153},{\"end\":88175,\"start\":88171},{\"end\":88190,\"start\":88183},{\"end\":88199,\"start\":88196},{\"end\":88222,\"start\":88213},{\"end\":88236,\"start\":88231},{\"end\":88707,\"start\":88700},{\"end\":88724,\"start\":88717},{\"end\":88991,\"start\":88987},{\"end\":89008,\"start\":89001},{\"end\":89019,\"start\":89015},{\"end\":89031,\"start\":89026},{\"end\":89044,\"start\":89039},{\"end\":89304,\"start\":89297},{\"end\":89318,\"start\":89314},{\"end\":89333,\"start\":89328},{\"end\":89568,\"start\":89565},{\"end\":89592,\"start\":89582},{\"end\":89609,\"start\":89603},{\"end\":89627,\"start\":89620},{\"end\":89642,\"start\":89637},{\"end\":89656,\"start\":89651},{\"end\":89674,\"start\":89666},{\"end\":89689,\"start\":89684},{\"end\":89709,\"start\":89702},{\"end\":89723,\"start\":89718},{\"end\":89738,\"start\":89732},{\"end\":89752,\"start\":89744},{\"end\":89754,\"start\":89753},{\"end\":89771,\"start\":89766},{\"end\":89787,\"start\":89779},{\"end\":89801,\"start\":89795},{\"end\":89812,\"start\":89807},{\"end\":89828,\"start\":89824},{\"end\":89837,\"start\":89833},{\"end\":90408,\"start\":90402},{\"end\":90419,\"start\":90415},{\"end\":90432,\"start\":90424},{\"end\":90446,\"start\":90440},{\"end\":90462,\"start\":90455},{\"end\":90476,\"start\":90470},{\"end\":90503,\"start\":90492},{\"end\":90505,\"start\":90504},{\"end\":91063,\"start\":91060},{\"end\":91076,\"start\":91070},{\"end\":91091,\"start\":91087},{\"end\":91105,\"start\":91099},{\"end\":91115,\"start\":91112},{\"end\":91130,\"start\":91122},{\"end\":91522,\"start\":91517},{\"end\":91538,\"start\":91531},{\"end\":91556,\"start\":91548},{\"end\":91582,\"start\":91577},{\"end\":92269,\"start\":92262},{\"end\":92289,\"start\":92282},{\"end\":92304,\"start\":92301},{\"end\":92506,\"start\":92498},{\"end\":92524,\"start\":92518},{\"end\":92536,\"start\":92531},{\"end\":92549,\"start\":92542},{\"end\":92563,\"start\":92557},{\"end\":92574,\"start\":92568},{\"end\":92588,\"start\":92583},{\"end\":92602,\"start\":92595},{\"end\":92990,\"start\":92984},{\"end\":93006,\"start\":92998},{\"end\":93019,\"start\":93014},{\"end\":93031,\"start\":93024},{\"end\":93045,\"start\":93038},{\"end\":93057,\"start\":93050},{\"end\":93062,\"start\":93058},{\"end\":93076,\"start\":93070},{\"end\":93090,\"start\":93083},{\"end\":93108,\"start\":93099},{\"end\":93119,\"start\":93114},{\"end\":93489,\"start\":93484},{\"end\":93502,\"start\":93495},{\"end\":93511,\"start\":93510},{\"end\":93527,\"start\":93521},{\"end\":93539,\"start\":93534},{\"end\":93543,\"start\":93540},{\"end\":93554,\"start\":93549},{\"end\":93562,\"start\":93559},{\"end\":93576,\"start\":93575},{\"end\":93591,\"start\":93585},{\"end\":93941,\"start\":93937},{\"end\":93953,\"start\":93948},{\"end\":94638,\"start\":94632},{\"end\":94647,\"start\":94643},{\"end\":94662,\"start\":94657},{\"end\":94674,\"start\":94669},{\"end\":94687,\"start\":94682},{\"end\":94701,\"start\":94695},{\"end\":94719,\"start\":94712},{\"end\":94743,\"start\":94735},{\"end\":94754,\"start\":94749},{\"end\":95134,\"start\":95129},{\"end\":95150,\"start\":95146},{\"end\":95382,\"start\":95381},{\"end\":95384,\"start\":95383},{\"end\":95400,\"start\":95394},{\"end\":95824,\"start\":95818},{\"end\":95840,\"start\":95834},{\"end\":95859,\"start\":95852},{\"end\":95872,\"start\":95866},{\"end\":95886,\"start\":95881},{\"end\":95901,\"start\":95895},{\"end\":96213,\"start\":96208},{\"end\":96225,\"start\":96219},{\"end\":96237,\"start\":96233},{\"end\":96259,\"start\":96251},{\"end\":96555,\"start\":96550},{\"end\":96570,\"start\":96563},{\"end\":96587,\"start\":96578},{\"end\":96606,\"start\":96601}]", "bib_author_last_name": "[{\"end\":83476,\"start\":83469},{\"end\":83488,\"start\":83486},{\"end\":83501,\"start\":83496},{\"end\":83513,\"start\":83509},{\"end\":83527,\"start\":83521},{\"end\":83543,\"start\":83534},{\"end\":83718,\"start\":83715},{\"end\":83738,\"start\":83730},{\"end\":83750,\"start\":83747},{\"end\":83766,\"start\":83758},{\"end\":83783,\"start\":83775},{\"end\":83799,\"start\":83795},{\"end\":83815,\"start\":83806},{\"end\":83832,\"start\":83823},{\"end\":83844,\"start\":83840},{\"end\":83860,\"start\":83855},{\"end\":83878,\"start\":83868},{\"end\":83892,\"start\":83884},{\"end\":83906,\"start\":83900},{\"end\":83922,\"start\":83914},{\"end\":83938,\"start\":83932},{\"end\":83964,\"start\":83947},{\"end\":83985,\"start\":83976},{\"end\":84000,\"start\":83996},{\"end\":84014,\"start\":84009},{\"end\":84029,\"start\":84023},{\"end\":84045,\"start\":84040},{\"end\":84064,\"start\":84055},{\"end\":84079,\"start\":84074},{\"end\":84096,\"start\":84090},{\"end\":84109,\"start\":84103},{\"end\":84124,\"start\":84117},{\"end\":84142,\"start\":84134},{\"end\":84156,\"start\":84148},{\"end\":84164,\"start\":84162},{\"end\":84177,\"start\":84172},{\"end\":84189,\"start\":84181},{\"end\":84206,\"start\":84197},{\"end\":84225,\"start\":84214},{\"end\":84238,\"start\":84232},{\"end\":84256,\"start\":84246},{\"end\":84274,\"start\":84266},{\"end\":84292,\"start\":84284},{\"end\":84304,\"start\":84299},{\"end\":84328,\"start\":84321},{\"end\":84341,\"start\":84339},{\"end\":84355,\"start\":84348},{\"end\":84373,\"start\":84363},{\"end\":84394,\"start\":84383},{\"end\":84402,\"start\":84396},{\"end\":86530,\"start\":86525},{\"end\":86545,\"start\":86541},{\"end\":86557,\"start\":86552},{\"end\":86574,\"start\":86567},{\"end\":86590,\"start\":86584},{\"end\":86609,\"start\":86601},{\"end\":86629,\"start\":86618},{\"end\":86643,\"start\":86638},{\"end\":86658,\"start\":86652},{\"end\":86673,\"start\":86667},{\"end\":86997,\"start\":86991},{\"end\":87013,\"start\":87006},{\"end\":87027,\"start\":87021},{\"end\":87042,\"start\":87034},{\"end\":87389,\"start\":87379},{\"end\":87400,\"start\":87396},{\"end\":87414,\"start\":87406},{\"end\":87432,\"start\":87421},{\"end\":87444,\"start\":87439},{\"end\":87678,\"start\":87675},{\"end\":87690,\"start\":87687},{\"end\":87701,\"start\":87697},{\"end\":87719,\"start\":87712},{\"end\":87735,\"start\":87730},{\"end\":88071,\"start\":88066},{\"end\":88084,\"start\":88079},{\"end\":88103,\"start\":88097},{\"end\":88118,\"start\":88111},{\"end\":88138,\"start\":88129},{\"end\":88151,\"start\":88146},{\"end\":88169,\"start\":88162},{\"end\":88181,\"start\":88176},{\"end\":88194,\"start\":88191},{\"end\":88211,\"start\":88200},{\"end\":88229,\"start\":88223},{\"end\":88242,\"start\":88237},{\"end\":88715,\"start\":88708},{\"end\":88730,\"start\":88725},{\"end\":88999,\"start\":88992},{\"end\":89013,\"start\":89009},{\"end\":89024,\"start\":89020},{\"end\":89037,\"start\":89032},{\"end\":89051,\"start\":89045},{\"end\":89312,\"start\":89305},{\"end\":89326,\"start\":89319},{\"end\":89340,\"start\":89334},{\"end\":89580,\"start\":89569},{\"end\":89601,\"start\":89593},{\"end\":89618,\"start\":89610},{\"end\":89635,\"start\":89628},{\"end\":89649,\"start\":89643},{\"end\":89664,\"start\":89657},{\"end\":89682,\"start\":89675},{\"end\":89700,\"start\":89690},{\"end\":89716,\"start\":89710},{\"end\":89730,\"start\":89724},{\"end\":89742,\"start\":89739},{\"end\":89764,\"start\":89755},{\"end\":89777,\"start\":89772},{\"end\":89793,\"start\":89788},{\"end\":89805,\"start\":89802},{\"end\":89822,\"start\":89813},{\"end\":89831,\"start\":89829},{\"end\":89844,\"start\":89838},{\"end\":90413,\"start\":90409},{\"end\":90422,\"start\":90420},{\"end\":90438,\"start\":90433},{\"end\":90453,\"start\":90447},{\"end\":90468,\"start\":90463},{\"end\":90490,\"start\":90477},{\"end\":90513,\"start\":90506},{\"end\":91068,\"start\":91064},{\"end\":91085,\"start\":91077},{\"end\":91097,\"start\":91092},{\"end\":91110,\"start\":91106},{\"end\":91120,\"start\":91116},{\"end\":91137,\"start\":91131},{\"end\":91529,\"start\":91523},{\"end\":91546,\"start\":91539},{\"end\":91575,\"start\":91557},{\"end\":91589,\"start\":91583},{\"end\":92280,\"start\":92270},{\"end\":92299,\"start\":92290},{\"end\":92309,\"start\":92305},{\"end\":92516,\"start\":92507},{\"end\":92529,\"start\":92525},{\"end\":92540,\"start\":92537},{\"end\":92555,\"start\":92550},{\"end\":92566,\"start\":92564},{\"end\":92581,\"start\":92575},{\"end\":92593,\"start\":92589},{\"end\":92606,\"start\":92603},{\"end\":92996,\"start\":92991},{\"end\":93012,\"start\":93007},{\"end\":93022,\"start\":93020},{\"end\":93036,\"start\":93032},{\"end\":93048,\"start\":93046},{\"end\":93068,\"start\":93063},{\"end\":93081,\"start\":93077},{\"end\":93097,\"start\":93091},{\"end\":93112,\"start\":93109},{\"end\":93126,\"start\":93120},{\"end\":93133,\"start\":93128},{\"end\":93493,\"start\":93490},{\"end\":93508,\"start\":93503},{\"end\":93519,\"start\":93512},{\"end\":93532,\"start\":93528},{\"end\":93547,\"start\":93544},{\"end\":93557,\"start\":93555},{\"end\":93569,\"start\":93563},{\"end\":93573,\"start\":93571},{\"end\":93583,\"start\":93577},{\"end\":93595,\"start\":93592},{\"end\":93599,\"start\":93597},{\"end\":93946,\"start\":93942},{\"end\":93959,\"start\":93954},{\"end\":94641,\"start\":94639},{\"end\":94655,\"start\":94648},{\"end\":94667,\"start\":94663},{\"end\":94680,\"start\":94675},{\"end\":94693,\"start\":94688},{\"end\":94710,\"start\":94702},{\"end\":94733,\"start\":94720},{\"end\":94747,\"start\":94744},{\"end\":94757,\"start\":94755},{\"end\":94766,\"start\":94759},{\"end\":95144,\"start\":95135},{\"end\":95156,\"start\":95151},{\"end\":95392,\"start\":95385},{\"end\":95406,\"start\":95401},{\"end\":95412,\"start\":95408},{\"end\":95832,\"start\":95825},{\"end\":95850,\"start\":95841},{\"end\":95864,\"start\":95860},{\"end\":95879,\"start\":95873},{\"end\":95893,\"start\":95887},{\"end\":95907,\"start\":95902},{\"end\":96217,\"start\":96214},{\"end\":96231,\"start\":96226},{\"end\":96249,\"start\":96238},{\"end\":96270,\"start\":96260},{\"end\":96561,\"start\":96556},{\"end\":96576,\"start\":96571},{\"end\":96599,\"start\":96588},{\"end\":96610,\"start\":96607},{\"end\":96617,\"start\":96612}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":83704,\"start\":83398},{\"attributes\":{\"doi\":\"arXiv:2112.11446\",\"id\":\"b1\"},\"end\":86480,\"start\":83706},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":218971783},\"end\":86982,\"start\":86482},{\"attributes\":{\"doi\":\"arXiv:2005.00661\",\"id\":\"b3\"},\"end\":87298,\"start\":86984},{\"attributes\":{\"doi\":\"arXiv:1911.00172\",\"id\":\"b4\"},\"end\":87666,\"start\":87300},{\"attributes\":{\"doi\":\"arXiv:2002.08909\",\"id\":\"b5\"},\"end\":87990,\"start\":87668},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":218869575},\"end\":88610,\"start\":87992},{\"attributes\":{\"doi\":\"arXiv:2007.01282\",\"id\":\"b7\"},\"end\":88923,\"start\":88612},{\"attributes\":{\"doi\":\"arXiv:2104.07567\",\"id\":\"b8\"},\"end\":89255,\"start\":88925},{\"attributes\":{\"doi\":\"arXiv:2107.07566\",\"id\":\"b9\"},\"end\":89499,\"start\":89257},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":86611921},\"end\":90325,\"start\":89501},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":52822214},\"end\":90963,\"start\":90327},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":230799347},\"end\":91448,\"start\":90965},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":4711425},\"end\":92196,\"start\":91450},{\"attributes\":{\"doi\":\"arXiv:2106.00950\",\"id\":\"b14\"},\"end\":92496,\"start\":92198},{\"attributes\":{\"doi\":\"arXiv:2004.04906\",\"id\":\"b15\"},\"end\":92910,\"start\":92498},{\"attributes\":{\"doi\":\"arXiv:2009.12756\",\"id\":\"b16\"},\"end\":93432,\"start\":92912},{\"attributes\":{\"doi\":\"arXiv:2109.01652\",\"id\":\"b17\"},\"end\":93838,\"start\":93434},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":4936344},\"end\":94545,\"start\":93840},{\"attributes\":{\"doi\":\"arXiv:2112.08726\",\"id\":\"b19\"},\"end\":95066,\"start\":94547},{\"attributes\":{\"doi\":\"arXiv:1908.10090\",\"id\":\"b20\"},\"end\":95318,\"start\":95068},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":237491751},\"end\":95760,\"start\":95320},{\"attributes\":{\"doi\":\"arXiv:2109.05052\",\"id\":\"b22\"},\"end\":96128,\"start\":95762},{\"attributes\":{\"doi\":\"arXiv:1906.02916\",\"id\":\"b23\"},\"end\":96488,\"start\":96130},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":211258645},\"end\":96774,\"start\":96490}]", "bib_title": "[{\"end\":86519,\"start\":86482},{\"end\":88056,\"start\":87992},{\"end\":89563,\"start\":89501},{\"end\":90400,\"start\":90327},{\"end\":91058,\"start\":90965},{\"end\":91515,\"start\":91450},{\"end\":93935,\"start\":93840},{\"end\":95379,\"start\":95320},{\"end\":96548,\"start\":96490}]", "bib_author": "[{\"end\":83478,\"start\":83464},{\"end\":83490,\"start\":83478},{\"end\":83503,\"start\":83490},{\"end\":83515,\"start\":83503},{\"end\":83529,\"start\":83515},{\"end\":83545,\"start\":83529},{\"end\":83720,\"start\":83708},{\"end\":83740,\"start\":83720},{\"end\":83752,\"start\":83740},{\"end\":83768,\"start\":83752},{\"end\":83785,\"start\":83768},{\"end\":83801,\"start\":83785},{\"end\":83817,\"start\":83801},{\"end\":83834,\"start\":83817},{\"end\":83846,\"start\":83834},{\"end\":83862,\"start\":83846},{\"end\":83880,\"start\":83862},{\"end\":83894,\"start\":83880},{\"end\":83908,\"start\":83894},{\"end\":83924,\"start\":83908},{\"end\":83940,\"start\":83924},{\"end\":83966,\"start\":83940},{\"end\":83987,\"start\":83966},{\"end\":84002,\"start\":83987},{\"end\":84016,\"start\":84002},{\"end\":84031,\"start\":84016},{\"end\":84047,\"start\":84031},{\"end\":84066,\"start\":84047},{\"end\":84081,\"start\":84066},{\"end\":84098,\"start\":84081},{\"end\":84111,\"start\":84098},{\"end\":84126,\"start\":84111},{\"end\":84144,\"start\":84126},{\"end\":84158,\"start\":84144},{\"end\":84166,\"start\":84158},{\"end\":84179,\"start\":84166},{\"end\":84191,\"start\":84179},{\"end\":84208,\"start\":84191},{\"end\":84227,\"start\":84208},{\"end\":84240,\"start\":84227},{\"end\":84258,\"start\":84240},{\"end\":84276,\"start\":84258},{\"end\":84294,\"start\":84276},{\"end\":84306,\"start\":84294},{\"end\":84330,\"start\":84306},{\"end\":84343,\"start\":84330},{\"end\":84357,\"start\":84343},{\"end\":84375,\"start\":84357},{\"end\":84396,\"start\":84375},{\"end\":84404,\"start\":84396},{\"end\":86532,\"start\":86521},{\"end\":86547,\"start\":86532},{\"end\":86559,\"start\":86547},{\"end\":86576,\"start\":86559},{\"end\":86592,\"start\":86576},{\"end\":86611,\"start\":86592},{\"end\":86631,\"start\":86611},{\"end\":86645,\"start\":86631},{\"end\":86660,\"start\":86645},{\"end\":86675,\"start\":86660},{\"end\":86999,\"start\":86984},{\"end\":87015,\"start\":86999},{\"end\":87029,\"start\":87015},{\"end\":87044,\"start\":87029},{\"end\":87391,\"start\":87371},{\"end\":87402,\"start\":87391},{\"end\":87416,\"start\":87402},{\"end\":87434,\"start\":87416},{\"end\":87446,\"start\":87434},{\"end\":87680,\"start\":87668},{\"end\":87692,\"start\":87680},{\"end\":87703,\"start\":87692},{\"end\":87721,\"start\":87703},{\"end\":87737,\"start\":87721},{\"end\":88073,\"start\":88058},{\"end\":88086,\"start\":88073},{\"end\":88105,\"start\":88086},{\"end\":88120,\"start\":88105},{\"end\":88140,\"start\":88120},{\"end\":88153,\"start\":88140},{\"end\":88171,\"start\":88153},{\"end\":88183,\"start\":88171},{\"end\":88196,\"start\":88183},{\"end\":88213,\"start\":88196},{\"end\":88231,\"start\":88213},{\"end\":88244,\"start\":88231},{\"end\":88717,\"start\":88700},{\"end\":88732,\"start\":88717},{\"end\":89001,\"start\":88987},{\"end\":89015,\"start\":89001},{\"end\":89026,\"start\":89015},{\"end\":89039,\"start\":89026},{\"end\":89053,\"start\":89039},{\"end\":89314,\"start\":89297},{\"end\":89328,\"start\":89314},{\"end\":89342,\"start\":89328},{\"end\":89582,\"start\":89565},{\"end\":89603,\"start\":89582},{\"end\":89620,\"start\":89603},{\"end\":89637,\"start\":89620},{\"end\":89651,\"start\":89637},{\"end\":89666,\"start\":89651},{\"end\":89684,\"start\":89666},{\"end\":89702,\"start\":89684},{\"end\":89718,\"start\":89702},{\"end\":89732,\"start\":89718},{\"end\":89744,\"start\":89732},{\"end\":89766,\"start\":89744},{\"end\":89779,\"start\":89766},{\"end\":89795,\"start\":89779},{\"end\":89807,\"start\":89795},{\"end\":89824,\"start\":89807},{\"end\":89833,\"start\":89824},{\"end\":89846,\"start\":89833},{\"end\":90415,\"start\":90402},{\"end\":90424,\"start\":90415},{\"end\":90440,\"start\":90424},{\"end\":90455,\"start\":90440},{\"end\":90470,\"start\":90455},{\"end\":90492,\"start\":90470},{\"end\":90515,\"start\":90492},{\"end\":91070,\"start\":91060},{\"end\":91087,\"start\":91070},{\"end\":91099,\"start\":91087},{\"end\":91112,\"start\":91099},{\"end\":91122,\"start\":91112},{\"end\":91139,\"start\":91122},{\"end\":91531,\"start\":91517},{\"end\":91548,\"start\":91531},{\"end\":91577,\"start\":91548},{\"end\":91591,\"start\":91577},{\"end\":92282,\"start\":92262},{\"end\":92301,\"start\":92282},{\"end\":92311,\"start\":92301},{\"end\":92518,\"start\":92498},{\"end\":92531,\"start\":92518},{\"end\":92542,\"start\":92531},{\"end\":92557,\"start\":92542},{\"end\":92568,\"start\":92557},{\"end\":92583,\"start\":92568},{\"end\":92595,\"start\":92583},{\"end\":92608,\"start\":92595},{\"end\":92998,\"start\":92984},{\"end\":93014,\"start\":92998},{\"end\":93024,\"start\":93014},{\"end\":93038,\"start\":93024},{\"end\":93050,\"start\":93038},{\"end\":93070,\"start\":93050},{\"end\":93083,\"start\":93070},{\"end\":93099,\"start\":93083},{\"end\":93114,\"start\":93099},{\"end\":93128,\"start\":93114},{\"end\":93135,\"start\":93128},{\"end\":93495,\"start\":93484},{\"end\":93510,\"start\":93495},{\"end\":93521,\"start\":93510},{\"end\":93534,\"start\":93521},{\"end\":93549,\"start\":93534},{\"end\":93559,\"start\":93549},{\"end\":93571,\"start\":93559},{\"end\":93575,\"start\":93571},{\"end\":93585,\"start\":93575},{\"end\":93597,\"start\":93585},{\"end\":93601,\"start\":93597},{\"end\":93948,\"start\":93937},{\"end\":93961,\"start\":93948},{\"end\":94643,\"start\":94632},{\"end\":94657,\"start\":94643},{\"end\":94669,\"start\":94657},{\"end\":94682,\"start\":94669},{\"end\":94695,\"start\":94682},{\"end\":94712,\"start\":94695},{\"end\":94735,\"start\":94712},{\"end\":94749,\"start\":94735},{\"end\":94759,\"start\":94749},{\"end\":94768,\"start\":94759},{\"end\":95146,\"start\":95129},{\"end\":95158,\"start\":95146},{\"end\":95394,\"start\":95381},{\"end\":95408,\"start\":95394},{\"end\":95414,\"start\":95408},{\"end\":95834,\"start\":95818},{\"end\":95852,\"start\":95834},{\"end\":95866,\"start\":95852},{\"end\":95881,\"start\":95866},{\"end\":95895,\"start\":95881},{\"end\":95909,\"start\":95895},{\"end\":96219,\"start\":96208},{\"end\":96233,\"start\":96219},{\"end\":96251,\"start\":96233},{\"end\":96272,\"start\":96251},{\"end\":96563,\"start\":96550},{\"end\":96578,\"start\":96563},{\"end\":96601,\"start\":96578},{\"end\":96612,\"start\":96601},{\"end\":96619,\"start\":96612}]", "bib_venue": "[{\"end\":83462,\"start\":83398},{\"end\":84447,\"start\":84420},{\"end\":86724,\"start\":86675},{\"end\":87119,\"start\":87060},{\"end\":87369,\"start\":87300},{\"end\":87807,\"start\":87753},{\"end\":88293,\"start\":88244},{\"end\":88698,\"start\":88612},{\"end\":88985,\"start\":88925},{\"end\":89295,\"start\":89257},{\"end\":89906,\"start\":89846},{\"end\":90601,\"start\":90515},{\"end\":91200,\"start\":91139},{\"end\":91733,\"start\":91591},{\"end\":92260,\"start\":92198},{\"end\":92682,\"start\":92624},{\"end\":92982,\"start\":92912},{\"end\":93482,\"start\":93434},{\"end\":94103,\"start\":93961},{\"end\":94630,\"start\":94547},{\"end\":95127,\"start\":95068},{\"end\":95495,\"start\":95414},{\"end\":95816,\"start\":95762},{\"end\":96206,\"start\":96130},{\"end\":96624,\"start\":96619},{\"end\":90674,\"start\":90603},{\"end\":91862,\"start\":91735},{\"end\":94232,\"start\":94105},{\"end\":95563,\"start\":95497}]"}}}, "year": 2023, "month": 12, "day": 17}