{"id": 250311842, "updated": "2023-10-05 19:18:35.983", "metadata": {"title": "Adversarial Mask: Real-World Universal Adversarial Attack on Face Recognition Model", "authors": "[{\"first\":\"Alon\",\"last\":\"Zolfi\",\"middle\":[]},{\"first\":\"Shai\",\"last\":\"Avidan\",\"middle\":[]},{\"first\":\"Yuval\",\"last\":\"Elovici\",\"middle\":[]},{\"first\":\"Asaf\",\"last\":\"Shabtai\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2021, "month": null, "day": null}, "abstract": "Deep learning-based facial recognition (FR) models have demonstrated state-of-the-art performance in the past few years, even when wearing protective medical face masks became commonplace during the COVID-19 pandemic. Given the outstanding performance of these models, the machine learning research community has shown increasing interest in challenging their robustness. Initially, researchers presented adversarial attacks in the digital domain, and later the attacks were transferred to the physical domain. However, in many cases, attacks in the physical domain are conspicuous, and thus may raise suspicion in real-world environments (e.g., airports). In this paper, we propose Adversarial Mask, a physical universal adversarial perturbation (UAP) against state-of-the-art FR models that is applied on face masks in the form of a carefully crafted pattern. In our experiments, we examined the transferability of our adversarial mask to a wide range of FR model architectures and datasets. In addition, we validated our adversarial mask's effectiveness in real-world experiments (CCTV use case) by printing the adversarial pattern on a fabric face mask. In these experiments, the FR system was only able to identify 3.34% of the participants wearing the mask (compared to a minimum of 83.34% with other evaluated masks). A demo of our experiments can be found at: https://youtu.be/_TXkDO5z11w.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2111.10759", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/pkdd/ZolfiAES22", "doi": "10.1007/978-3-031-26409-2_19"}}, "content": {"source": {"pdf_hash": "fea7e10ef910d4c75724d1e502dbeaf759647879", "pdf_src": "Arxiv", "pdf_uri": "[\"https://export.arxiv.org/pdf/2111.10759v3.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "cc2a9ab0ed04de6350b83abe6b0102c350a4ece8", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/fea7e10ef910d4c75724d1e502dbeaf759647879.txt", "contents": "\nShai Avidan 2 , Yuval Elovici 1\n7 Sep 2022\n\nAlon Zolfi \n\nBen-Gurion University of the Negev\nIsrael\n\n\nTel Aviv University\nIsrael\n\nShai Avidan 2 , Yuval Elovici 1\n7 Sep 2022Adversarial Mask: Real-World Universal Adversarial Attack on Face Recognition ModelsAdversarial Attack \u00b7 Face Recognition \u00b7 Face Mask\nDeep learning-based facial recognition (FR) models have demonstrated state-of-the-art performance in the past few years, even when wearing protective medical face masks became commonplace during the COVID-19 pandemic. Given the outstanding performance of these models, the machine learning research community has shown increasing interest in challenging their robustness. Initially, researchers presented adversarial attacks in the digital domain, and later the attacks were transferred to the physical domain. However, in many cases, attacks in the physical domain are conspicuous, and thus may raise suspicion in real-world environments (e.g., airports). In this paper, we propose Adversarial Mask, a physical universal adversarial perturbation (UAP) against state-of-theart FR models that is applied on face masks in the form of a carefully crafted pattern. In our experiments, we examined the transferability of our adversarial mask to a wide range of FR model architectures and datasets. In addition, we validated our adversarial mask's effectiveness in real-world experiments (CCTV use case) by printing the adversarial pattern on a fabric face mask. In these experiments, the FR system was only able to identify 3.34% of the participants wearing the mask (compared to a minimum of 83.34% with other evaluated masks). A demo of our experiments can be found at: https://youtu.be/_TXkDO5z11w.\n\nIntroduction\n\nFor the past two years, the coronavirus has impacted every aspect of our lives, and its impact will continue for the foreseeable future. Since its emergence, various suggestions have been made to reduce its spread. While the effectiveness of some actions is questionable, there is no doubt that face masks are a key factor in preventing the spread of the virus in crowded and enclosed spaces. The widespread adoption of face masks and the ever-increasing use of deep learningbased facial recognition (FR) models in everyday systems can be leveraged to perpetrate targeted adversarial attacks that will enable attackers to evade such models and compromise their robustness, without raising an alarm. Fig. 1: Illustrating the effect of an adversarial pattern printed on a fabric mask (right), which results in the failure of the FR system to detect the person wearing it, compared to the FR system's ability to detect the same individual without a mask, as well as with a standard disposable mask.\n\nAdversarial attacks in the computer vision domain have gained a lot of interest in recent years, and various ways of fooling image classifiers [9,22] and object detectors [21,23,32] have been proposed. Attacks against FR systems have also been shown to be effective. For example, research has demonstrated that face synthesis in the digital domain can be used to fool FR models [28]. In the physical domain, some of the proposed methods involved wearing adversarial eyeglasses [18], projecting lights on human faces [20], wearing a hat containing an adversarial sticker [14], and using adversarial makeup [10]. However, the proposed attacks are conspicuous and do not allow the attacker to blend in naturally in real-world scenarios, potentially triggering defense systems.\n\nIn this work, we propose a universal adversarial attack that can be used to physically evade FR systems; in this case, an adversarial pattern is printed on a fabric face mask, as shown in Figure 1. To create the adversarial pattern, we use a gradient-based optimization process that aims to cause all identities wearing the mask to be misclassified by the FR model. We first demonstrate the attack's ability to fool state-of-the-art models (e.g., ArcFace [7]) in the digital domain by applying the face mask to every facial image in the dataset (dynamically) using 3D face reconstruction. Then, we print the adversarial pattern on an actual fabric face mask and test it under real-world conditions. The results in the digital domain show that our adversarial mask performs better than all evaluated masks and is transferable to other models. In the physical domain, we show that 96.66% of the participants wearing our mask evaded the detection by the FR system.\n\nThe contributions of our research can be summarized as follows:\n\n-We are the first to present a physical universal adversarial attack that fools FR models, i.e., we craft a single perturbation that causes the FR model to falsely classify all potential attackers as unknown identities, even under diverse conditions (angles, scales, etc.) in a real-world environment (fully-automated CCTV scenario). -In the digital domain, we study the transferability of our attack across different model architectures and datasets. -We present a fully differentiable novel digital masking method that can accurately place any kind of mask on any face, regardless of the position of the head. This method can be used for other computer-vision tasks (e.g., training masked-face detection models).\n\n-We craft an inconspicuous pattern that \"continues\" the contour of the face, allowing a potential attacker to easily blend in with a crowd without raising an alarm, given the variety and widespread use of face masks during the COVID-19 pandemic. However, these attacks only call attention to the potential threat inherent to such models but cannot be transferred to the physical world. Physical Attacks. Physical attacks differ from digital attacks in the way realworld constraints are considered throughout the process of generating the perturbation. Consequently, these constraints allow the perturbations to transfer more easily to the physical world. In recent years, physical attacks on object detectors have gained attention. Chen et al. [5] printed stop signs containing adversarial patterns that evaded detection by the object detector, and Sitawarin et al. [21] deceived autonomous car systems by crafting toxic traffic signs that look similar to the original traffic signs. Methods against person detectors have also been proposed. Thys et al. [23] suggested attaching a small adversarial cardboard plate to a person's body to evade detection. Continuing this line of research, other studies involved printing adversarial patterns on t-shirts, which resulted in a more realistic article of clothing that blends into the environment more naturally [26,27]. A slightly different approach, in which the perturbation affects the sensor's perception of the object by applying a translucent patch on the camera's lens, was also introduced [32]. Numerous studies have demonstrated different ways of fooling FR systems. For example, Shen et al. [20] introduced the visible light-based attack, where lights are projected on human faces. Other studies showed that carefully applied makeup patterns can negatively affect the performance of FR systems [10,30]. Accessories were also shown to be effective; for example, Sharif et al. [18] suggested wearing adversarial eyeglass frames that were crafted using gradient-based methods. Later, GAN methods were used to generate an enhanced version of the adversarial eyeglass frames [19]. Recently, Komkov et al. [14] printed an adversarial paper sticker and placed it on a hat to fool the state-of-the-art ArcFace [7] FR model. However, when implemented on a person, these methods may call attention to the person by causing them to stand out in a crowd given their unnatural appearance. In contrast, we propose a method in which the perturbation is placed on a face mask, a safety measure widely used in the COVID-19 era; in addition, unlike prior work in which the proposed attacks craft tailor-made perturbations (target a single image or person), our universal attack can be applied more widely without the need for an expert to train a tailor-made one. Furthermore, we demonstrate the effectiveness of our method in a real-world use case involving a CCTV system, an aspect not addressed by previous studies.\n\n\nFace Recognition\n\nModels. FR models can be categorized by two main attributes, the model's backbone and the novel loss function, both of which are involved in the training phase. The main architecture used as the backbone in these models is the ResNet [12] architecture, which varies in terms of the number of layers it contains, also referred to as the backbone depth. On top of the backbone, an additional layer (or more) is added, usually containing a novel loss function that is used to train the backbone weights [7,16,24]. Later, when the FR model is used for inference, only the backbone layers are used to generate the embedding vector. Systems. The end-to-end procedure of a fully automated FR system consists of several main steps: (a) Record -a camera records the environment and then produces a series of frames (a video stream); (b) Detect -each frame is analyzed by a face detector to extract cropped faces; (c) Align -the cropped faces are aligned according to the FR model's alignment method; (d) Embed -the aligned facial images serve as input to an FR model f that maps a facial image I f ace to a vector f (I f ace ), also referred to as an embedding vector; (e) Verify -the embedding vector is compared to a list of precalculated embedding vectors (also referred to as ground-truth embedding vectors) using a similarity measure (e.g., cosine similarity). The identity with the highest similarity score is marked as a potential candidate and eventually confirmed if its similarity score surpasses a predefined verification threshold (which depends on the system's use case).\n\n\nMethod\n\nThe objective of our research is to generate an adversarial pattern that can be printed on a face mask and cause FR systems to classify a registered identity as an unknown identity. Further, we aim to create an adversarial pattern that is: (a) universal -it must be effective on any identity from multiple views and angles, and at multiple scales, (b) practical -the pattern should remain adversarial when printed on a fabric mask in the real world, and (c) transferable -it must be effective on different models (backbone depths and loss functions). \n\n\nMask Projection\n\nIn order to digitally train our adversarial mask, we first need to simulate the mask overlay on a person's face in the real world. Therefore, we use 3D face reconstruction to digitally apply a mask on a facial image. Feng et al. [8] introduced an end-to-end approach called UV position map that records the 3D coordinates of a complete facial point cloud using a 2D image. This map records the position information of a 3D face and provides dense correspondence to the semantic meaning of each point in the UV space, allowing us to achieve near-real approximation of the mask on the face, which is essential to the creation of a successful adversarial mask in the real world.\n\nMore formally, we consider our mask M adv \u2208 R w\u00d7h\u00d73 and a rendering function R \u03b8 . The rendering function (partially inspired from [25]) takes a mask M adv and a facial image x face , and applies the mask on the face, resulting in a masked face image R \u03b8 (M adv , x face ). As shown in Figure 2, the pipeline of the mask's projection on the facial image is as follows:\n\n1. Detect the landmark points of the face -given a landmark detector, we extract the landmark points of the face. 2. Map the mask pixels to the facial image -the landmark points of the face extracted in the previous step of the pipeline are used to map the mask pixels to the corresponding location on the facial images. 3. Extract depth features of the face -the facial image is passed to the 3D face reconstruction model to obtain depth features. 4. Transfer 2D facial image to the UV space -the depth features are used to remap the facial image to the UV space. 5. Transfer 2D mask image to the UV space -the depth features are used to remap the mask image to the UV space. 6. Augment mask -to improve the robustness of our adversarial mask, random geometric transformations and color-based augmentations (parameterized by \u03b8) are applied: (i) geometric transformations -random translation and rotation are added to simulate possible distortions in the mask's placement on the face in the real world, and (ii) color-based augmentations -random contrast, brightness, and noise are added to simulate changes in the appearance of the mask that might result from various factors (e.g., lighting, noise or blurring caused when the camera captures the image).\n\n7. Combine and reconstruct -the UV representations of the facial image and the mask are combined, and the combined image is reconstructed back to the regular 2D space, resulting in a masked face image.\n\nUsually, adversarial attacks that employ textile-like objects (e.g., wearable tshirt [26,27]) use thin plate splines (TPSs) [4] to simulate fabric distortions. In contrast to these studies, although we aim to craft a textile-based mask, in our case, the mask form on the face remains steady and is not subject to significant distortions. In addition, our 3D approach allows us to simulate smaller distortions (e.g., caused by the nose shape) without actively using TPSs. Above all, it is important to note that the entire process presented is completely differentiable and allows us to backpropagate and update the mask pixels.\n\n\nPatch Optimization\n\nTo optimize our mask's pixels, we propose an iterative optimization process. In each iteration, we select a random batch of facial images of multiple identities and digitally project the mask on each facial image. We then feed the masked face images to the FR model and obtain the embedding representations. Since our goal is to cause an attacker to be unknown to FR models, we aim to create a patch M adv that will decrease the similarity between the output embedding and the ground-truth embedding e gt (precalculated) for each identity.\n\nMore formally, an FR model f : X w\u00d7h\u00d73 \u2192 R N receives a facial image x \u2208 X (in our case, a masked face image R \u03b8 (M adv , x)) as input and outputs the embedding representation f (R \u03b8 (M adv , x)). Therefore, we minimize the cosine similarity between the embedding vectors and use the following loss function:\nsim (M adv ) = E \u03b8,x [cos(f (R \u03b8 (M adv , x)), e gt )](1)\nSince our method is not system-dependent (i.e., does not use a fixed verification threshold determined by a specific use case), we aim to decrease the similarity to the fullest extent possible, in order to perform the most successful attack.\n\nTo improve the mask's transferability to other models, we train our patch using an ensemble of FR models, denoted as J. We replace 1 with the following:\nsim (M adv ) = E \u03b8,x 1 |J| j cos(f (j) (R \u03b8 (M adv , x)), e (j) gt ),(2)\nwhere f (j) denotes the j th model and e\n(j)\ngt denotes the embedding representation calculated using the j th model.\n\nWe also include the total variation (TV) [18] factor to ensure that the optimizer favors smooth color transitions between neighboring pixels and is calculated on the mask pixels as follows:\nT V = i,k (p i,k \u2212 p i+1,k ) 2 + (p i,k \u2212 p i,k+1 ) 2(3)\nWhen neighboring pixels are not similar, the penalty of this component is greater.\n\nTo be more precise, since the output of sim is in the range of [\u22121, 1] and the output of T V is in the range of [0, 1], we transform sim so it is in the same range ([0, 1]); thus, we replace 2 with the following:\nsim (M adv ) = E \u03b8,x 1 |J| j cos(f (j) (R \u03b8 (M adv , x)), e (j) gt ) + 1 2(4)\nFinally, the optimization problem we solve is as follows:\nmin M adv [ sim (M adv ) + \u03bb * T V (M adv )],(5)\nwhere \u03bb is set at a low value.\n\n\nEvaluation\n\nIn our evaluation, we first run experiments in the digital domain by applying the mask to facial images, using the rendering function R \u03b8 (as explained in Section 3). Then, we evaluate the performance of our adversarial pattern in the physical domain (i.e., real world) by printing it on a fabric mask. Models. We use three different types of loss functions that were originally used to train the models, which are considered state-of-the-art: ArcFace [7], Cos-Face [24], and MagFace [16]. Specifically, we use pretrained models which were trained using the ArcFace and CosFace loss functions [3], with four different ResNet depths (18, 34, 50, and 100) each, and a pretrained ResNet100 backbone originally trained with the MagFace [16] loss function, for a total of nine different models. We examine multiple training variations, using one or more (i.e., ensemble) models to train the adversarial mask and then test it in a white-box setting to evaluate the performance. We also evaluate the transferability of our mask to other unknown models (i.e., black-box setting). Datasets. Throughout this paper, we use three commonly used datasets in the face recognition domain: CASIA-WebFace [29], CelebA [15], and MS-Celeb [11]. For the training phase, we randomly choose 100 different identities (50 men and 50 women) from the CASIA-WebFace dataset. We extract five random facial images for each identity, for a total of 500 facial images.\n\nFor the evaluation phase, we use 200 identities from each dataset (an equal number of men and women from each dataset), evaluating both the performance on the same distribution (different identities from the CASIA-WebFace dataset, \u223c20K images) and the transferability to other datasets (CelebA and MS-Celeb, \u223c6K and \u223c24K images, respectively). Metrics. In our experiments, we quantify the performance of our attack as the ability to decrease the similarity score -specifically the cosine similarity (an approach originally presented in [14]). The cosine similarity calculation is a step required prior to making a binary decision based on a predefined threshold. This evaluation approach does not require a system-dependent predefined threshold and demonstrates our attack's effectiveness. In the physical domain, we also quantify the effectiveness of our attack using two additional metrics, each of which relates to a different stage of an end-to-end FR system: -Recognition rate (RR) = |F rec |/|F det |, where |F rec | denotes the total number of frames in which the identity was correctly recognized (the cosine similarity between the ground-truth embedding and the output embedding surpasses the verification threshold), and |F det | denotes the total number of frames in which a face was detected and analyzed by the FR system. -Persistence detection -since the goal of our adversarial mask is to ensure that an attacker is not identified by the system, we propose a metric that indicates whether the goal was met. An attacker is considered as identified if, within a window of N sliding window frames, the attacker was recognized in N recognized frames (where N recognized \u2264 N sliding window ).\n\nImplementation details. The models we work with in this research only take size 3 \u00d7 112 \u00d7 112 facial images as input. Therefore, We set the size of our patch to be 3\u00d760\u00d7112 to avoid significant downsampling when dynamically rendering the mask to the facial image, and we set the initial color of the mask to white. The pixels are updated using the Adam optimizer [13], where the initial learning rate is set at 10 \u22122 . The weight factor of the TV component in the loss function \u03bb is manually set at 0.1. The source code is available online. 3 Types of face masks evaluated. Since we are the first to present a physical universal perturbation, we compare the effectiveness of our mask with several control masks: (a) Clean -the original facial image without a mask, (b) Advour optimized adversarial mask, (c) Random -a mask with randomly colored pixels, and (d) Blue -a standard disposable blue mask (simple black and white masks were also tested and yielded the same results). In addition, due to our trained mask's resemblance to a human face, the lower face area of a female and male are used as control masks and will be referred to as Female Face and Male Face, respectively. The masks compared in our evaluation are shown in Figure 3. Evaluation setup. Since the state-of-the-art models discussed above were not specifically designed to address the issue of masked faces, we first examine the model's (ResNet100@ArcFace) performance on a number of simple face masks.\n\nFor this evaluation, we use 100 identities from the CASIA-WebFace dataset, where five images of each identity are used to calculate the ground-truth embedding, and the remaining images are applied with different types of masks. To the best of our knowledge, the scientific community has not reached a consensus on the way in which masked face images should be dealt with by FR models. Therefore, we use two approaches for generating the ground-truth embedding: (a) the current approach for unmasked face models -averaging the embedding vectors of the original images only, and (b) an extension of the first approach -in addition to the original images, we create a masked face version for each image (the specific mask is randomly chosen from blue, black, and white masks) and average the embedding vectors of the two versions of the images. We then calculate the cosine similarity between the masked face images' embedding vectors and the two versions of ground-truth embedding vectors generation.\n\nIn Table 1 we can see that although the first approach (w/o Mask) performs better on unmasked images, its performance on masked images is unsatisfactory. On the other hand, the cosine similarity for the second approach (w/Mask) only slightly decreases the cosine similarity on unmasked images (\u223c0.05 decrease) and performs significantly better on masked images (\u223c0.1-0.15 increase). Thus, throughout this section the results we present are obtained using the second approach (the ground-truth embedding vectors used for the training procedure are generated using first approach). It is important to note that by choosing the second approach, we increase the difficulty of deceiving these models, since the ground-truth embedding vectors encapsulate the use of a face mask.\n\n\nDigital Attacks\n\nWe conduct digital experiments to quantify our adversarial mask's effectiveness using the rendering function R \u03b8 (see Section 3), which allows us to dynamically apply masks to the facial images in the test set. Effectiveness of the adversarial mask in a white-box setting. We examine the effectiveness of our attack in a white-box setting in which our mask is optimized and tested on the ResNet100@ArcFace. As shown in Figure 4, our adversarial mask has a significant impact compared to the no mask case, in which the average cosine similarity decreased from \u223c 0.7 to \u223c 0.1. As the case of no mask images represents the upper bound of the cosine similarity, we also perform a targeted attack in which a mask is tailored to each person, to determine the lower bound. The targeted mask results are averaged across all identities in the test set. We can see that the universal mask performs almost as good as a tailor-made mask (\u223c 0.1 difference). The tailor-made masks represent an attack Fig. 4: Distribution of the cosine similarity score across different masks. 'Adv Universal' represents our optimized universal mask, and 'Adv Targeted' represents a tailor-made mask for each identity.\n\nthat is more difficult to detect, since the adversarial pattern varies among different identities. In addition, while the female and male face control masks are also able to decrease the cosine similarity to a lower level (\u223c 0.45), our mask outperforms them both for almost all tested identities. Transferability across backbone depth. We also examine whether our mask can deceive FR models it was not trained on. Since the majority of the models use the ResNet architecture, we evaluate the performance across different depths of the ResNet@ArcFace. The results are presented in Figure 5a. In the figure, we can see that the use of our adversarial mask can cause the cosine similarity to decrease regardless of the model used for training. It can also be seen that our attack generalizes better to unknown models whose architecture depth is closer to that of the trained model. For example, an adversarial mask trained on a model with 100 layers performs better on the models with 34 and 50 layers (decreasing the cosine similarity to 0.182 and 0.168, respectively) than on the 18layer model (0.282). In addition, we see that the mask trained on an ensemble of all models does not outperform a mask trained on a single model in a white-box setting, however the ensemble's effectiveness is seen over all models combined. Transferability across different loss functions. We further demonstrate the adversarial mask's transferability across different model loss functions. We use the ResNet100 backbone in which the weights were trained using one of the following loss functions: ArcFace, CosFace, and MagFace. In Figure 5b, we observe that our method is loss-agnostic, as the decrease in the cosine similarity is seen on for all tested models. However, a mask that was trained using the MagFace model does not generalize as well as the masks trained with other models, where the cosine similarity decreased to 0.065 in the white-box setting but only decreased to 0.255 and 0.2 on the ArcFace and CosFace models, respectively. It is interesting to examine the mask trained by each model (presented in Figure 6).   Whereas there is a resemblance in the contour of the optimized masks, the mask trained using the ResNet100@MagFace backbone ( Figure 6c) learns completely different colors than the other two, in some way providing a possible explanation for its decreased ability to generalize to the ArcFace and CosFace models.\n\nTransferability across datasets. We also find our mask to be effective across different datasets. In another experiment, we train our mask using images from one of the examined datasets (presented earlier in this section) and study its effectiveness on the other datasets (i.e., the ground-truth embedding vectors are generated using another dataset's images). We train all of the masks using the ResNet100@ArcFace. The results show that the impact of using a specific dataset is insignificant, since our mask generalizes over all datasets. For example, when training the mask on the CASIA-WebFace dataset and testing it on the CelebA and MS-Celeb datasets, we respectively obtained an average cosine similarity of 0.128 and 0.114, similar to the white-box setting results (mask trained and tested on images from the CASIA-WebFace dataset, Figure 4). Effect of gender. Another aspect we studied is the effect of a specific gender on the trained mask. The experiments include optimization of the adversarial mask using only female or male identities, and the final masks are presented in Figure 7a and Figure 7b, respectively. The results show that even when training the mask on facial images of a single gender, the cosine similarity decreases to the same level as the mask trained on both genders (\u223c 0.1). In addition, masks trained by a single gender were able to transfer very well to the other gender (male \u2192 female = 0.097, and female \u2192 male = 0.145). Generally, the contour of the trained masks (including the mask trained on both genders, Figure 6a) is quite interesting. Despite the fact that only facial images of female identities were used to train the mask (Figure 7a), the optimized mask has an high resemblance to a male face. More generally, the resemblance of all the trained masks to a male face might indicate there is an underlying bias hidden in these models.\n\n\nPhysical Attacks\n\nFinally, to evaluate the effectiveness of our attack in the real world, we print our digital pattern on two surfaces: on regular paper cut in the shape of a face mask and on a white fabric mask, as shown in Figure 9. In addition, we create a testbed that operates an end-to-end fully automated FR system (explained in Section 2), simulating a CCTV use case. Setup. The system contains: (a) a Dahua IPC-HDBW1431E network camera which records a long corridor, (b) an MTCNN [31] detection model for face detection, preprocessing, and alignment, and (c) an attacked model -we perform a white-box attack in which the model used for training the adversarial mask is also the model under attack, a ResNet100@ArcFace. In addition, we perform an \"offline\" analysis in a black-box setting, in which the facial images are cropped from the original frames and compared to ground-truth embedding vectors generated using other models.\n\nTo calculate the specific verification threshold (set at 0.38), we use a subset of 1,000 identities from the CASIA-WebFace dataset and perform the following procedure. Various face masks are applied (digitally) to each identity's original facial images. Then, we calculate the cosine similarity between the identity's embedding vector and each masked face image. Since we employ a semi-critical security use case (CCTV), we chose the threshold that led to a false accep-  tance rate (FAR) of 1%. Furthermore, to minimize false positive alarms, we used a persistence threshold of N recognized = 7 frames and a sliding window of N sliding window = 10 frames to designate a candidate identity as a valid one. We recruited a group of 15 male and 15 female participants (after approval was granted by the university's ethics committee). Each participant was asked to walk along the corridor seven times, once with each mask evaluated (clean, blue, random, male face, and female face), similar to the digital experiments, and two more times with our adversarial masks printed on paper and fabric. The ground-truth embedding of each participant was calculated using two facial images, where a standard face mask was applied (digitally) to each image, for a total of four facial images. Results. The results of our experiments are shown in Figure 8 where we can see that our adversarial masks (paper and fabric) performed significantly better than the other masks evaluated on every metric, with a high correlation to the cosine similarity results obtained in the digital domain.\n\nIn terms of the RR, the performance of the FR model for the different masks can be divided into four groups (listed in decreasing order): (a) the unmasked version (74.83%), (b) blue and random masks (53.04% and 54.76%, respectively), (c) male and female masks (30.85% and 28.36%, respectively), and (d) our fabric and paper adversarial masks (5.72% and 4.61%, respectively).\n\nIn a realistic case of CCTV use in which an attacker tries to evade the detection of the system, our adversarial fabric mask was able to conceal the identity of 29 out of 30 participants (which represents a persistence detection value of 3.34%), as opposed to the control masks which were able to conceal 5 out of 30 participants at most (persistence detection value of 83.34%).\n\nWe also examine the effectiveness of our masks on models they were not trained on. The results presented in Figure 8 show that our masks have similar adversarial effect on FR models in a black-box setting as in a white-box setting.\n\nAnother aspect we examined in our physical evaluation is the ability to print the adversarial pattern on a real surface. Figures 9b and 9c present the digital adversarial pattern (9a) printed on the different surfaces. Due to the limited ability of a printer to accurately output the original colors onto the fabric, we can see that there is a slight difference in the performance of the masks. Nonetheless, both of our adversarial masks outperformed the other masks evaluated.\n\n\nCountermeasures\n\nWe propose two ways in which our digital masking method can be used to defend against adversarial masks: (a) adversarial training -adversarial (universal and tailor-made) masked face images could be provided to the model during training to improve its robustness; and (b) mask substitution -during the inference phase, every masked face image could be preprocessed so that the worn mask is replaced digitally with a standard one (e.g., blue mask 3b), where the models had satisfactory performance, as shown in Section 4, eliminating the potential threat of an adversarial face mask. An implementation of the mask substitution method on facial images of 100 identities (\u223c 10K images) from the CASIA-WebFace dataset increased the RR from 0.4% (the adversarial mask is applied to the facial images) to 65.5% (the blue mask is applied to the adversarial images). In a physical experiment, in which the blue mask was digitally placed on facial images extracted from the videos frames (videos of participants wearing the adversarial mask), the RR increased from 5.72% to 57.3%.\n\n\nConclusion\n\nIn this paper, we presented a physical universal attack in the form of a face mask against FR systems. Whereas other attack methods used different accessories that are more conspicuous and do not blend naturally in the environment, our mask will not raise any suspicion due to the widespread use of face masks during the COVID-19 pandemic. We demonstrated the effectiveness of our mask in the digital domain, both under white-box and black-box settings. In the physical domain, we showed how our mask is able to prevent the detection of multiple participants in a CCTV use case system. Moreover, we proposed possible countermeasures to deal with such attacks. To sum up, in this research, we highlight the potential risk FR models face from an adversary simply wearing a carefully crafted adversarial face mask in the COVID-19 era.\n\nFig. 2 :\n2Overview of our mask projection method pipeline.\n\nFig. 3 :\n3Examples of facial images w/o mask (a), and when various masks are digitally applied to them (b)-(f).\n\n\nTransferability across various ResNet backbone depths originally trained using the ArcFace loss function. (b) Transferability across various ResNet100 backbones originally trained with different loss functions.\n\nFig. 5 :\n5Transferability experiments measured in terms of cosine similarity. Rows are divided into three groups: control masks, masks trained using a single model, mask trained using all of the models.\n\nFig. 6 :\n6Illustrations of our adversarial masks trained on different ResNet100 backbones, which vary in terms of the original loss function they were trained on.\n\nFig. 7 :\n7The adversarial masks trained on the ResNet100@ArcFace using single gender identities.\n\nFig. 8 :\n8Physical experiments' averaged results on all participants across different evaluated masks and different victim models.\n\nFig. 9 :\n9An illustration of: (a) the digital adversarial mask trained on the ResNet100@ArcFace; (b) the digital pattern printed on fabric mask; and (c) the digital pattern printed on paper.\n\n\n-We propose various countermeasures that can be used during the FR model training and inference phases. have also emerged. Yang et al.[28] designed a digital patch which is placed on a person's forehead to deceive face detectors. Recent studies targeting FR models suggested various techniques. Deb et al.[6] proposed automated adversarial face synthesis, using a generative adversarial network (GAN) to create minimal perturbations. Agarwal et al.[1] and Amada et al.[2] proposed UAPs that can deceive FR models for multiple identities simultaneously.2 Background & Related Work \n\n2.1 Adversarial Attacks \n\nDigital Attacks. Initially, attacks in the digital domain aimed at fooling clas-\nsification models were introduced [9, 22]. While those earlier attacks are based \non methods that generate a perturbation for a single image, Moosavi-Dezfooli et \nal. [17] proposed universal adversarial perturbations (UAPs), which enable any \nimage that is blended with the UAP to fool a DNN. Digital attacks on models \nthat perform more complex computer vision tasks (e.g., face recognition and \nobject detection) \n\nTable 1 :\n1Cosine similarity comparison between two ground-truth embedding generation methods on the Resnet100@ArcFace. Bold indicates better performance.Mask Type No Mask Blue Black White \nCosine \nSimilarity \n\nw/o Mask* \n.732 .399 .407 .428 \nw/Mask** \n.682 .547 .549 .561 \n\n*Embedding vectors created using original facial images. \n**A masked version of the original images is added to the embedding calculation. \n\n\nhttps://github.com/AlonZolfi/AdversarialMask\n\nAre image-agnostic universal adversarial perturbations for face recognition difficult to detect? In. A Agarwal, R Singh, M Vatsa, N Ratha, IEEE 9th International Conference on Biometrics Theory, Applications and Systems (BTAS). IEEEAgarwal, A., Singh, R., Vatsa, M., Ratha, N.: Are image-agnostic universal ad- versarial perturbations for face recognition difficult to detect? In: 2018 IEEE 9th International Conference on Biometrics Theory, Applications and Systems (BTAS). pp. 1-7. IEEE (2018)\n\nUniversal adversarial spoofing attacks against face recognition. T Amada, S P Liew, K Kakizaki, T Araki, 2021 IEEE International Joint Conference on Biometrics (IJCB). IEEEAmada, T., Liew, S.P., Kakizaki, K., Araki, T.: Universal adversarial spoofing attacks against face recognition. In: 2021 IEEE International Joint Conference on Biometrics (IJCB). pp. 1-7. IEEE (2021)\n\nPartial fc: Training 10 million identities on a single machine. X An, X Zhu, Y Xiao, L Wu, M Zhang, Y Gao, B Qin, D Zhang, F Ying, Arxiv 2010.05222An, X., Zhu, X., Xiao, Y., Wu, L., Zhang, M., Gao, Y., Qin, B., Zhang, D., Ying, F.: Partial fc: Training 10 million identities on a single machine. In: Arxiv 2010.05222 (2020)\n\nPrincipal warps: Thin-plate splines and the decomposition of deformations. F L Bookstein, IEEE Transactions. 116Bookstein, F.L.: Principal warps: Thin-plate splines and the decomposition of de- formations. IEEE Transactions on pattern analysis and machine intelligence 11(6), 567-585 (1989)\n\nShapeshifter: Robust physical adversarial attack on faster r-cnn object detector. S T Chen, C Cornelius, J Martin, D H P Chau, Joint European Conference on Machine Learning and Knowledge Discovery in Databases. SpringerChen, S.T., Cornelius, C., Martin, J., Chau, D.H.P.: Shapeshifter: Robust physical adversarial attack on faster r-cnn object detector. In: Joint European Conference on Machine Learning and Knowledge Discovery in Databases. pp. 52-68. Springer (2018)\n\nAdvfaces: Adversarial face synthesis. D Deb, J Zhang, A K Jain, 2020 IEEE International Joint Conference on Biometrics (IJCB). IEEEDeb, D., Zhang, J., Jain, A.K.: Advfaces: Adversarial face synthesis. In: 2020 IEEE International Joint Conference on Biometrics (IJCB). pp. 1-10. IEEE (2020)\n\nArcface: Additive angular margin loss for deep face recognition. J Deng, J Guo, N Xue, S Zafeiriou, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern RecognitionDeng, J., Guo, J., Xue, N., Zafeiriou, S.: Arcface: Additive angular margin loss for deep face recognition. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 4690-4699 (2019)\n\nJoint 3d face reconstruction and dense alignment with position map regression network. Y Feng, F Wu, X Shao, Y Wang, X Zhou, Proceedings of the European Conference on Computer Vision (ECCV). the European Conference on Computer Vision (ECCV)Feng, Y., Wu, F., Shao, X., Wang, Y., Zhou, X.: Joint 3d face reconstruction and dense alignment with position map regression network. In: Proceedings of the European Conference on Computer Vision (ECCV). pp. 534-551 (2018)\n\nI J Goodfellow, J Shlens, C Szegedy, arXiv:1412.6572Explaining and harnessing adversarial examples. arXiv preprintGoodfellow, I.J., Shlens, J., Szegedy, C.: Explaining and harnessing adversarial examples. arXiv preprint arXiv:1412.6572 (2014)\n\nN Guetta, A Shabtai, I Singh, S Momiyama, Y Elovici, arXiv:2109.06467Dodging attack using carefully crafted natural makeup. arXiv preprintGuetta, N., Shabtai, A., Singh, I., Momiyama, S., Elovici, Y.: Dodging attack using carefully crafted natural makeup. arXiv preprint arXiv:2109.06467 (2021)\n\nMs-celeb-1m: A dataset and benchmark for large-scale face recognition. Y Guo, L Zhang, Y Hu, X He, J Gao, European conference on computer vision. SpringerGuo, Y., Zhang, L., Hu, Y., He, X., Gao, J.: Ms-celeb-1m: A dataset and benchmark for large-scale face recognition. In: European conference on computer vision. pp. 87-102. Springer (2016)\n\nDeep residual learning for image recognition. K He, X Zhang, S Ren, J Sun, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionHe, K., Zhang, X., Ren, S., Sun, J.: Deep residual learning for image recognition. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 770-778 (2016)\n\nAdam: A method for stochastic optimization. D P Kingma, J Ba, arXiv:1412.6980arXiv preprintKingma, D.P., Ba, J.: Adam: A method for stochastic optimization. arXiv preprint arXiv:1412.6980 (2014)\n\nAdvhat: Real-world adversarial attack on arcface face id system. S Komkov, A Petiushko, 2020 25th International Conference on Pattern Recognition (ICPR). IEEEKomkov, S., Petiushko, A.: Advhat: Real-world adversarial attack on arcface face id system. In: 2020 25th International Conference on Pattern Recognition (ICPR). pp. 819-826. IEEE (2021)\n\nLarge-scale celebfaces attributes (celeba) dataset. Z Liu, P Luo, X Wang, X Tang, Retrieved August. 1511Liu, Z., Luo, P., Wang, X., Tang, X.: Large-scale celebfaces attributes (celeba) dataset. Retrieved August 15(2018), 11 (2018)\n\nMagface: A universal representation for face recognition and quality assessment. Q Meng, S Zhao, Z Huang, F Zhou, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern RecognitionMeng, Q., Zhao, S., Huang, Z., Zhou, F.: Magface: A universal representation for face recognition and quality assessment. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 14225-14234 (2021)\n\nUniversal adversarial perturbations. S M Moosavi-Dezfooli, A Fawzi, O Fawzi, P Frossard, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionMoosavi-Dezfooli, S.M., Fawzi, A., Fawzi, O., Frossard, P.: Universal adversarial perturbations. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 1765-1773 (2017)\n\nAccessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition. M Sharif, S Bhagavatula, L Bauer, M K Reiter, Proceedings of the 2016 acm sigsac conference on computer and communications security. the 2016 acm sigsac conference on computer and communications securitySharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K.: Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition. In: Proceedings of the 2016 acm sigsac conference on computer and communications security. pp. 1528- 1540 (2016)\n\nA general framework for adversarial examples with objectives. M Sharif, S Bhagavatula, L Bauer, M K Reiter, ACM Transactions on Privacy and Security (TOPS). 223Sharif, M., Bhagavatula, S., Bauer, L., Reiter, M.K.: A general framework for adversarial examples with objectives. ACM Transactions on Privacy and Security (TOPS) 22(3), 1-30 (2019)\n\nVla: A practical visible light-based attack on face recognition systems in physical world. M Shen, Z Liao, L Zhu, K Xu, X Du, Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies. 33Shen, M., Liao, Z., Zhu, L., Xu, K., Du, X.: Vla: A practical visible light-based attack on face recognition systems in physical world. Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies 3(3), 1-19 (2019)\n\nC Sitawarin, A N Bhagoji, A Mosenia, M Chiang, P Mittal, arXiv:1802.06430Darts: Deceiving autonomous cars with toxic signs. arXiv preprintSitawarin, C., Bhagoji, A.N., Mosenia, A., Chiang, M., Mittal, P.: Darts: Deceiving autonomous cars with toxic signs. arXiv preprint arXiv:1802.06430 (2018)\n\nC Szegedy, W Zaremba, I Sutskever, J Bruna, D Erhan, I Goodfellow, R Fergus, arXiv:1312.6199Intriguing properties of neural networks. arXiv preprintSzegedy, C., Zaremba, W., Sutskever, I., Bruna, J., Erhan, D., Goodfellow, I., Fer- gus, R.: Intriguing properties of neural networks. arXiv preprint arXiv:1312.6199 (2013)\n\nFooling automated surveillance cameras: adversarial patches to attack person detection. S Thys, W Van Ranst, T Goedem\u00e9, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition Workshops. the IEEE Conference on Computer Vision and Pattern Recognition WorkshopsThys, S., Van Ranst, W., Goedem\u00e9, T.: Fooling automated surveillance cameras: adversarial patches to attack person detection. In: Proceedings of the IEEE Con- ference on Computer Vision and Pattern Recognition Workshops. pp. 0-0 (2019)\n\nCosface: Large margin cosine loss for deep face recognition. H Wang, Y Wang, Z Zhou, X Ji, D Gong, J Zhou, Z Li, W Liu, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionWang, H., Wang, Y., Zhou, Z., Ji, X., Gong, D., Zhou, J., Li, Z., Liu, W.: Cosface: Large margin cosine loss for deep face recognition. In: Proceedings of the IEEE conference on computer vision and pattern recognition. pp. 5265-5274 (2018)\n\nFacex-zoo: A pytorch toolbox for face recognition. J Wang, Y Liu, Y Hu, H Shi, T Mei, Proceedings of the 29th ACM International Conference on Multimedia. the 29th ACM International Conference on MultimediaWang, J., Liu, Y., Hu, Y., Shi, H., Mei, T.: Facex-zoo: A pytorch toolbox for face recognition. In: Proceedings of the 29th ACM International Conference on Multimedia. pp. 3779-3782 (2021)\n\nMaking an invisibility cloak: Real world adversarial attacks on object detectors. Z Wu, S N Lim, L S Davis, T Goldstein, European Conference on Computer Vision. SpringerWu, Z., Lim, S.N., Davis, L.S., Goldstein, T.: Making an invisibility cloak: Real world adversarial attacks on object detectors. In: European Conference on Com- puter Vision. pp. 1-17. Springer (2020)\n\nAdversarial t-shirt! evading person detectors in a physical world. K Xu, G Zhang, S Liu, Q Fan, M Sun, H Chen, P Y Chen, Y Wang, X Lin, European Conference on Computer Vision. SpringerXu, K., Zhang, G., Liu, S., Fan, Q., Sun, M., Chen, H., Chen, P.Y., Wang, Y., Lin, X.: Adversarial t-shirt! evading person detectors in a physical world. In: European Conference on Computer Vision. pp. 665-681. Springer (2020)\n\nDesign and interpretation of universal adversarial patches in face detection. X Yang, F Wei, H Zhang, J Zhu, Computer Vision-ECCV 2020: 16th European Conference. Glasgow, UKSpringerProceedings, Part XVII 16Yang, X., Wei, F., Zhang, H., Zhu, J.: Design and interpretation of universal adver- sarial patches in face detection. In: Computer Vision-ECCV 2020: 16th European Conference, Glasgow, UK, August 23-28, 2020, Proceedings, Part XVII 16. pp. 174-191. Springer (2020)\n\nD Yi, Z Lei, S Liao, S Z Li, arXiv:1411.7923Learning face representation from scratch. arXiv preprintYi, D., Lei, Z., Liao, S., Li, S.Z.: Learning face representation from scratch. arXiv preprint arXiv:1411.7923 (2014)\n\nB Yin, W Wang, T Yao, J Guo, Z Kong, S Ding, J Li, C Liu, arXiv:2105.03162Advmakeup: A new imperceptible and transferable attack on face recognition. arXiv preprintYin, B., Wang, W., Yao, T., Guo, J., Kong, Z., Ding, S., Li, J., Liu, C.: Adv- makeup: A new imperceptible and transferable attack on face recognition. arXiv preprint arXiv:2105.03162 (2021)\n\nJoint face detection and alignment using multitask cascaded convolutional networks. K Zhang, Z Zhang, Z Li, Y Qiao, IEEE Signal Processing Letters. 2310Zhang, K., Zhang, Z., Li, Z., Qiao, Y.: Joint face detection and alignment using multitask cascaded convolutional networks. IEEE Signal Processing Letters 23(10), 1499-1503 (2016)\n\nThe translucent patch: A physical and universal attack on object detectors. A Zolfi, M Kravchik, Y Elovici, A Shabtai, Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. the IEEE/CVF Conference on Computer Vision and Pattern RecognitionZolfi, A., Kravchik, M., Elovici, Y., Shabtai, A.: The translucent patch: A phys- ical and universal attack on object detectors. In: Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition. pp. 15232-15241 (2021)\n", "annotations": {"author": "[{\"end\":56,\"start\":45},{\"end\":100,\"start\":57},{\"end\":129,\"start\":101}]", "publisher": null, "author_last_name": "[{\"end\":55,\"start\":50}]", "author_first_name": "[{\"end\":49,\"start\":45}]", "author_affiliation": "[{\"end\":99,\"start\":58},{\"end\":128,\"start\":102}]", "title": "[{\"end\":32,\"start\":1},{\"end\":161,\"start\":130}]", "venue": null, "abstract": "[{\"end\":1702,\"start\":306}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b8\"},\"end\":2861,\"start\":2858},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":2864,\"start\":2861},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":2890,\"start\":2886},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":2893,\"start\":2890},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":2896,\"start\":2893},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":3097,\"start\":3093},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":3196,\"start\":3192},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":3235,\"start\":3231},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":3289,\"start\":3285},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3324,\"start\":3320},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":3948,\"start\":3945},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":5981,\"start\":5978},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":6104,\"start\":6100},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":6292,\"start\":6288},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":6595,\"start\":6591},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":6598,\"start\":6595},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":6781,\"start\":6777},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":6885,\"start\":6881},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":7088,\"start\":7084},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":7091,\"start\":7088},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":7169,\"start\":7165},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":7364,\"start\":7360},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":7394,\"start\":7390},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":7495,\"start\":7492},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":8449,\"start\":8445},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":8714,\"start\":8711},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":8717,\"start\":8714},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":8720,\"start\":8717},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":10600,\"start\":10597},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":11180,\"start\":11176},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":12964,\"start\":12960},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":12967,\"start\":12964},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":13002,\"start\":12999},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":15066,\"start\":15062},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":16250,\"start\":16247},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":16265,\"start\":16261},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":16283,\"start\":16279},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":16391,\"start\":16388},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":16531,\"start\":16527},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":16986,\"start\":16982},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":16999,\"start\":16995},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":17018,\"start\":17014},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":17773,\"start\":17769},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":19304,\"start\":19300},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":19479,\"start\":19478},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":28192,\"start\":28188},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":34932,\"start\":34928},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":35102,\"start\":35099},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":35245,\"start\":35242},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":35265,\"start\":35262}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":33675,\"start\":33616},{\"attributes\":{\"id\":\"fig_1\"},\"end\":33788,\"start\":33676},{\"attributes\":{\"id\":\"fig_2\"},\"end\":34001,\"start\":33789},{\"attributes\":{\"id\":\"fig_3\"},\"end\":34205,\"start\":34002},{\"attributes\":{\"id\":\"fig_4\"},\"end\":34369,\"start\":34206},{\"attributes\":{\"id\":\"fig_5\"},\"end\":34467,\"start\":34370},{\"attributes\":{\"id\":\"fig_6\"},\"end\":34599,\"start\":34468},{\"attributes\":{\"id\":\"fig_7\"},\"end\":34791,\"start\":34600},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":35898,\"start\":34792},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":36316,\"start\":35899}]", "paragraph": "[{\"end\":2713,\"start\":1718},{\"end\":3488,\"start\":2715},{\"end\":4451,\"start\":3490},{\"end\":4516,\"start\":4453},{\"end\":5232,\"start\":4518},{\"end\":8190,\"start\":5234},{\"end\":9786,\"start\":8211},{\"end\":10348,\"start\":9797},{\"end\":11043,\"start\":10368},{\"end\":11413,\"start\":11045},{\"end\":12670,\"start\":11415},{\"end\":12873,\"start\":12672},{\"end\":13502,\"start\":12875},{\"end\":14064,\"start\":13525},{\"end\":14374,\"start\":14066},{\"end\":14674,\"start\":14433},{\"end\":14828,\"start\":14676},{\"end\":14942,\"start\":14902},{\"end\":15019,\"start\":14947},{\"end\":15210,\"start\":15021},{\"end\":15350,\"start\":15268},{\"end\":15564,\"start\":15352},{\"end\":15700,\"start\":15643},{\"end\":15780,\"start\":15750},{\"end\":17231,\"start\":15795},{\"end\":18935,\"start\":17233},{\"end\":20408,\"start\":18937},{\"end\":21408,\"start\":20410},{\"end\":22182,\"start\":21410},{\"end\":23389,\"start\":22202},{\"end\":25814,\"start\":23391},{\"end\":27696,\"start\":25816},{\"end\":28637,\"start\":27717},{\"end\":30210,\"start\":28639},{\"end\":30586,\"start\":30212},{\"end\":30966,\"start\":30588},{\"end\":31199,\"start\":30968},{\"end\":31678,\"start\":31201},{\"end\":32769,\"start\":31698},{\"end\":33615,\"start\":32784}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":14432,\"start\":14375},{\"attributes\":{\"id\":\"formula_1\"},\"end\":14901,\"start\":14829},{\"attributes\":{\"id\":\"formula_2\"},\"end\":14946,\"start\":14943},{\"attributes\":{\"id\":\"formula_3\"},\"end\":15267,\"start\":15211},{\"attributes\":{\"id\":\"formula_4\"},\"end\":15642,\"start\":15565},{\"attributes\":{\"id\":\"formula_5\"},\"end\":15749,\"start\":15701}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":21420,\"start\":21413}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1716,\"start\":1704},{\"attributes\":{\"n\":\"2.2\"},\"end\":8209,\"start\":8193},{\"attributes\":{\"n\":\"3\"},\"end\":9795,\"start\":9789},{\"attributes\":{\"n\":\"3.1\"},\"end\":10366,\"start\":10351},{\"attributes\":{\"n\":\"3.2\"},\"end\":13523,\"start\":13505},{\"attributes\":{\"n\":\"4\"},\"end\":15793,\"start\":15783},{\"attributes\":{\"n\":\"4.1\"},\"end\":22200,\"start\":22185},{\"attributes\":{\"n\":\"4.2\"},\"end\":27715,\"start\":27699},{\"attributes\":{\"n\":\"5\"},\"end\":31696,\"start\":31681},{\"attributes\":{\"n\":\"6\"},\"end\":32782,\"start\":32772},{\"end\":33625,\"start\":33617},{\"end\":33685,\"start\":33677},{\"end\":34011,\"start\":34003},{\"end\":34215,\"start\":34207},{\"end\":34379,\"start\":34371},{\"end\":34477,\"start\":34469},{\"end\":34609,\"start\":34601},{\"end\":35909,\"start\":35900}]", "table": "[{\"end\":35898,\"start\":35346},{\"end\":36316,\"start\":36054}]", "figure_caption": "[{\"end\":33675,\"start\":33627},{\"end\":33788,\"start\":33687},{\"end\":34001,\"start\":33791},{\"end\":34205,\"start\":34013},{\"end\":34369,\"start\":34217},{\"end\":34467,\"start\":34381},{\"end\":34599,\"start\":34479},{\"end\":34791,\"start\":34611},{\"end\":35346,\"start\":34794},{\"end\":36054,\"start\":35911}]", "figure_ref": "[{\"end\":2423,\"start\":2417},{\"end\":3686,\"start\":3678},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":11339,\"start\":11331},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":20175,\"start\":20167},{\"end\":22629,\"start\":22621},{\"end\":23195,\"start\":23189},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":23980,\"start\":23971},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":25012,\"start\":25003},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":25498,\"start\":25490},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":25638,\"start\":25629},{\"end\":26664,\"start\":26656},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":26912,\"start\":26903},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":26926,\"start\":26917},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":27372,\"start\":27363},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":27496,\"start\":27486},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":27932,\"start\":27924},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":29979,\"start\":29971},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":31084,\"start\":31076},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":31339,\"start\":31322}]", "bib_author_first_name": "[{\"end\":36465,\"start\":36464},{\"end\":36476,\"start\":36475},{\"end\":36485,\"start\":36484},{\"end\":36494,\"start\":36493},{\"end\":36926,\"start\":36925},{\"end\":36935,\"start\":36934},{\"end\":36937,\"start\":36936},{\"end\":36945,\"start\":36944},{\"end\":36957,\"start\":36956},{\"end\":37299,\"start\":37298},{\"end\":37305,\"start\":37304},{\"end\":37312,\"start\":37311},{\"end\":37320,\"start\":37319},{\"end\":37326,\"start\":37325},{\"end\":37335,\"start\":37334},{\"end\":37342,\"start\":37341},{\"end\":37349,\"start\":37348},{\"end\":37358,\"start\":37357},{\"end\":37635,\"start\":37634},{\"end\":37637,\"start\":37636},{\"end\":37934,\"start\":37933},{\"end\":37936,\"start\":37935},{\"end\":37944,\"start\":37943},{\"end\":37957,\"start\":37956},{\"end\":37967,\"start\":37966},{\"end\":37971,\"start\":37968},{\"end\":38360,\"start\":38359},{\"end\":38367,\"start\":38366},{\"end\":38376,\"start\":38375},{\"end\":38378,\"start\":38377},{\"end\":38678,\"start\":38677},{\"end\":38686,\"start\":38685},{\"end\":38693,\"start\":38692},{\"end\":38700,\"start\":38699},{\"end\":39166,\"start\":39165},{\"end\":39174,\"start\":39173},{\"end\":39180,\"start\":39179},{\"end\":39188,\"start\":39187},{\"end\":39196,\"start\":39195},{\"end\":39544,\"start\":39543},{\"end\":39546,\"start\":39545},{\"end\":39560,\"start\":39559},{\"end\":39570,\"start\":39569},{\"end\":39788,\"start\":39787},{\"end\":39798,\"start\":39797},{\"end\":39809,\"start\":39808},{\"end\":39818,\"start\":39817},{\"end\":39830,\"start\":39829},{\"end\":40155,\"start\":40154},{\"end\":40162,\"start\":40161},{\"end\":40171,\"start\":40170},{\"end\":40177,\"start\":40176},{\"end\":40183,\"start\":40182},{\"end\":40473,\"start\":40472},{\"end\":40479,\"start\":40478},{\"end\":40488,\"start\":40487},{\"end\":40495,\"start\":40494},{\"end\":40873,\"start\":40872},{\"end\":40875,\"start\":40874},{\"end\":40885,\"start\":40884},{\"end\":41090,\"start\":41089},{\"end\":41100,\"start\":41099},{\"end\":41423,\"start\":41422},{\"end\":41430,\"start\":41429},{\"end\":41437,\"start\":41436},{\"end\":41445,\"start\":41444},{\"end\":41684,\"start\":41683},{\"end\":41692,\"start\":41691},{\"end\":41700,\"start\":41699},{\"end\":41709,\"start\":41708},{\"end\":42136,\"start\":42135},{\"end\":42138,\"start\":42137},{\"end\":42158,\"start\":42157},{\"end\":42167,\"start\":42166},{\"end\":42176,\"start\":42175},{\"end\":42619,\"start\":42618},{\"end\":42629,\"start\":42628},{\"end\":42644,\"start\":42643},{\"end\":42653,\"start\":42652},{\"end\":42655,\"start\":42654},{\"end\":43140,\"start\":43139},{\"end\":43150,\"start\":43149},{\"end\":43165,\"start\":43164},{\"end\":43174,\"start\":43173},{\"end\":43176,\"start\":43175},{\"end\":43513,\"start\":43512},{\"end\":43521,\"start\":43520},{\"end\":43529,\"start\":43528},{\"end\":43536,\"start\":43535},{\"end\":43542,\"start\":43541},{\"end\":43874,\"start\":43873},{\"end\":43887,\"start\":43886},{\"end\":43889,\"start\":43888},{\"end\":43900,\"start\":43899},{\"end\":43911,\"start\":43910},{\"end\":43921,\"start\":43920},{\"end\":44170,\"start\":44169},{\"end\":44181,\"start\":44180},{\"end\":44192,\"start\":44191},{\"end\":44205,\"start\":44204},{\"end\":44214,\"start\":44213},{\"end\":44223,\"start\":44222},{\"end\":44237,\"start\":44236},{\"end\":44580,\"start\":44579},{\"end\":44588,\"start\":44587},{\"end\":44601,\"start\":44600},{\"end\":45071,\"start\":45070},{\"end\":45079,\"start\":45078},{\"end\":45087,\"start\":45086},{\"end\":45095,\"start\":45094},{\"end\":45101,\"start\":45100},{\"end\":45109,\"start\":45108},{\"end\":45117,\"start\":45116},{\"end\":45123,\"start\":45122},{\"end\":45563,\"start\":45562},{\"end\":45571,\"start\":45570},{\"end\":45578,\"start\":45577},{\"end\":45584,\"start\":45583},{\"end\":45591,\"start\":45590},{\"end\":45989,\"start\":45988},{\"end\":45995,\"start\":45994},{\"end\":45997,\"start\":45996},{\"end\":46004,\"start\":46003},{\"end\":46006,\"start\":46005},{\"end\":46015,\"start\":46014},{\"end\":46345,\"start\":46344},{\"end\":46351,\"start\":46350},{\"end\":46360,\"start\":46359},{\"end\":46367,\"start\":46366},{\"end\":46374,\"start\":46373},{\"end\":46381,\"start\":46380},{\"end\":46389,\"start\":46388},{\"end\":46391,\"start\":46390},{\"end\":46399,\"start\":46398},{\"end\":46407,\"start\":46406},{\"end\":46768,\"start\":46767},{\"end\":46776,\"start\":46775},{\"end\":46783,\"start\":46782},{\"end\":46792,\"start\":46791},{\"end\":47162,\"start\":47161},{\"end\":47168,\"start\":47167},{\"end\":47175,\"start\":47174},{\"end\":47183,\"start\":47182},{\"end\":47185,\"start\":47184},{\"end\":47382,\"start\":47381},{\"end\":47389,\"start\":47388},{\"end\":47397,\"start\":47396},{\"end\":47404,\"start\":47403},{\"end\":47411,\"start\":47410},{\"end\":47419,\"start\":47418},{\"end\":47427,\"start\":47426},{\"end\":47433,\"start\":47432},{\"end\":47822,\"start\":47821},{\"end\":47831,\"start\":47830},{\"end\":47840,\"start\":47839},{\"end\":47846,\"start\":47845},{\"end\":48147,\"start\":48146},{\"end\":48156,\"start\":48155},{\"end\":48168,\"start\":48167},{\"end\":48179,\"start\":48178}]", "bib_author_last_name": "[{\"end\":36473,\"start\":36466},{\"end\":36482,\"start\":36477},{\"end\":36491,\"start\":36486},{\"end\":36500,\"start\":36495},{\"end\":36932,\"start\":36927},{\"end\":36942,\"start\":36938},{\"end\":36954,\"start\":36946},{\"end\":36963,\"start\":36958},{\"end\":37302,\"start\":37300},{\"end\":37309,\"start\":37306},{\"end\":37317,\"start\":37313},{\"end\":37323,\"start\":37321},{\"end\":37332,\"start\":37327},{\"end\":37339,\"start\":37336},{\"end\":37346,\"start\":37343},{\"end\":37355,\"start\":37350},{\"end\":37363,\"start\":37359},{\"end\":37647,\"start\":37638},{\"end\":37941,\"start\":37937},{\"end\":37954,\"start\":37945},{\"end\":37964,\"start\":37958},{\"end\":37976,\"start\":37972},{\"end\":38364,\"start\":38361},{\"end\":38373,\"start\":38368},{\"end\":38383,\"start\":38379},{\"end\":38683,\"start\":38679},{\"end\":38690,\"start\":38687},{\"end\":38697,\"start\":38694},{\"end\":38710,\"start\":38701},{\"end\":39171,\"start\":39167},{\"end\":39177,\"start\":39175},{\"end\":39185,\"start\":39181},{\"end\":39193,\"start\":39189},{\"end\":39201,\"start\":39197},{\"end\":39557,\"start\":39547},{\"end\":39567,\"start\":39561},{\"end\":39578,\"start\":39571},{\"end\":39795,\"start\":39789},{\"end\":39806,\"start\":39799},{\"end\":39815,\"start\":39810},{\"end\":39827,\"start\":39819},{\"end\":39838,\"start\":39831},{\"end\":40159,\"start\":40156},{\"end\":40168,\"start\":40163},{\"end\":40174,\"start\":40172},{\"end\":40180,\"start\":40178},{\"end\":40187,\"start\":40184},{\"end\":40476,\"start\":40474},{\"end\":40485,\"start\":40480},{\"end\":40492,\"start\":40489},{\"end\":40499,\"start\":40496},{\"end\":40882,\"start\":40876},{\"end\":40888,\"start\":40886},{\"end\":41097,\"start\":41091},{\"end\":41110,\"start\":41101},{\"end\":41427,\"start\":41424},{\"end\":41434,\"start\":41431},{\"end\":41442,\"start\":41438},{\"end\":41450,\"start\":41446},{\"end\":41689,\"start\":41685},{\"end\":41697,\"start\":41693},{\"end\":41706,\"start\":41701},{\"end\":41714,\"start\":41710},{\"end\":42155,\"start\":42139},{\"end\":42164,\"start\":42159},{\"end\":42173,\"start\":42168},{\"end\":42185,\"start\":42177},{\"end\":42626,\"start\":42620},{\"end\":42641,\"start\":42630},{\"end\":42650,\"start\":42645},{\"end\":42662,\"start\":42656},{\"end\":43147,\"start\":43141},{\"end\":43162,\"start\":43151},{\"end\":43171,\"start\":43166},{\"end\":43183,\"start\":43177},{\"end\":43518,\"start\":43514},{\"end\":43526,\"start\":43522},{\"end\":43533,\"start\":43530},{\"end\":43539,\"start\":43537},{\"end\":43545,\"start\":43543},{\"end\":43884,\"start\":43875},{\"end\":43897,\"start\":43890},{\"end\":43908,\"start\":43901},{\"end\":43918,\"start\":43912},{\"end\":43928,\"start\":43922},{\"end\":44178,\"start\":44171},{\"end\":44189,\"start\":44182},{\"end\":44202,\"start\":44193},{\"end\":44211,\"start\":44206},{\"end\":44220,\"start\":44215},{\"end\":44234,\"start\":44224},{\"end\":44244,\"start\":44238},{\"end\":44585,\"start\":44581},{\"end\":44598,\"start\":44589},{\"end\":44609,\"start\":44602},{\"end\":45076,\"start\":45072},{\"end\":45084,\"start\":45080},{\"end\":45092,\"start\":45088},{\"end\":45098,\"start\":45096},{\"end\":45106,\"start\":45102},{\"end\":45114,\"start\":45110},{\"end\":45120,\"start\":45118},{\"end\":45127,\"start\":45124},{\"end\":45568,\"start\":45564},{\"end\":45575,\"start\":45572},{\"end\":45581,\"start\":45579},{\"end\":45588,\"start\":45585},{\"end\":45595,\"start\":45592},{\"end\":45992,\"start\":45990},{\"end\":46001,\"start\":45998},{\"end\":46012,\"start\":46007},{\"end\":46025,\"start\":46016},{\"end\":46348,\"start\":46346},{\"end\":46357,\"start\":46352},{\"end\":46364,\"start\":46361},{\"end\":46371,\"start\":46368},{\"end\":46378,\"start\":46375},{\"end\":46386,\"start\":46382},{\"end\":46396,\"start\":46392},{\"end\":46404,\"start\":46400},{\"end\":46411,\"start\":46408},{\"end\":46773,\"start\":46769},{\"end\":46780,\"start\":46777},{\"end\":46789,\"start\":46784},{\"end\":46796,\"start\":46793},{\"end\":47165,\"start\":47163},{\"end\":47172,\"start\":47169},{\"end\":47180,\"start\":47176},{\"end\":47188,\"start\":47186},{\"end\":47386,\"start\":47383},{\"end\":47394,\"start\":47390},{\"end\":47401,\"start\":47398},{\"end\":47408,\"start\":47405},{\"end\":47416,\"start\":47412},{\"end\":47424,\"start\":47420},{\"end\":47430,\"start\":47428},{\"end\":47437,\"start\":47434},{\"end\":47828,\"start\":47823},{\"end\":47837,\"start\":47832},{\"end\":47843,\"start\":47841},{\"end\":47851,\"start\":47847},{\"end\":48153,\"start\":48148},{\"end\":48165,\"start\":48157},{\"end\":48176,\"start\":48169},{\"end\":48187,\"start\":48180}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":53124252},\"end\":36858,\"start\":36363},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":236187636},\"end\":37232,\"start\":36860},{\"attributes\":{\"doi\":\"Arxiv 2010.05222\",\"id\":\"b2\"},\"end\":37557,\"start\":37234},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":47302},\"end\":37849,\"start\":37559},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":4891043},\"end\":38319,\"start\":37851},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":199577709},\"end\":38610,\"start\":38321},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":8923541},\"end\":39076,\"start\":38612},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":3996281},\"end\":39541,\"start\":39078},{\"attributes\":{\"doi\":\"arXiv:1412.6572\",\"id\":\"b8\"},\"end\":39785,\"start\":39543},{\"attributes\":{\"doi\":\"arXiv:2109.06467\",\"id\":\"b9\"},\"end\":40081,\"start\":39787},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":2908606},\"end\":40424,\"start\":40083},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":206594692},\"end\":40826,\"start\":40426},{\"attributes\":{\"doi\":\"arXiv:1412.6980\",\"id\":\"b12\"},\"end\":41022,\"start\":40828},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":201645162},\"end\":41368,\"start\":41024},{\"attributes\":{\"id\":\"b14\"},\"end\":41600,\"start\":41370},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":232185285},\"end\":42096,\"start\":41602},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":11558223},\"end\":42528,\"start\":42098},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":207241700},\"end\":43075,\"start\":42530},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":132058467},\"end\":43419,\"start\":43077},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":202159689},\"end\":43871,\"start\":43421},{\"attributes\":{\"doi\":\"arXiv:1802.06430\",\"id\":\"b20\"},\"end\":44167,\"start\":43873},{\"attributes\":{\"doi\":\"arXiv:1312.6199\",\"id\":\"b21\"},\"end\":44489,\"start\":44169},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":121124946},\"end\":45007,\"start\":44491},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":68589},\"end\":45509,\"start\":45009},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":231582950},\"end\":45904,\"start\":45511},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":207757900},\"end\":46275,\"start\":45906},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":208310168},\"end\":46687,\"start\":46277},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":209202343},\"end\":47159,\"start\":46689},{\"attributes\":{\"doi\":\"arXiv:1411.7923\",\"id\":\"b28\"},\"end\":47379,\"start\":47161},{\"attributes\":{\"doi\":\"arXiv:2105.03162\",\"id\":\"b29\"},\"end\":47735,\"start\":47381},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":10585115},\"end\":48068,\"start\":47737},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":229363390},\"end\":48576,\"start\":48070}]", "bib_title": "[{\"end\":36462,\"start\":36363},{\"end\":36923,\"start\":36860},{\"end\":37632,\"start\":37559},{\"end\":37931,\"start\":37851},{\"end\":38357,\"start\":38321},{\"end\":38675,\"start\":38612},{\"end\":39163,\"start\":39078},{\"end\":40152,\"start\":40083},{\"end\":40470,\"start\":40426},{\"end\":41087,\"start\":41024},{\"end\":41420,\"start\":41370},{\"end\":41681,\"start\":41602},{\"end\":42133,\"start\":42098},{\"end\":42616,\"start\":42530},{\"end\":43137,\"start\":43077},{\"end\":43510,\"start\":43421},{\"end\":44577,\"start\":44491},{\"end\":45068,\"start\":45009},{\"end\":45560,\"start\":45511},{\"end\":45986,\"start\":45906},{\"end\":46342,\"start\":46277},{\"end\":46765,\"start\":46689},{\"end\":47819,\"start\":47737},{\"end\":48144,\"start\":48070}]", "bib_author": "[{\"end\":36475,\"start\":36464},{\"end\":36484,\"start\":36475},{\"end\":36493,\"start\":36484},{\"end\":36502,\"start\":36493},{\"end\":36934,\"start\":36925},{\"end\":36944,\"start\":36934},{\"end\":36956,\"start\":36944},{\"end\":36965,\"start\":36956},{\"end\":37304,\"start\":37298},{\"end\":37311,\"start\":37304},{\"end\":37319,\"start\":37311},{\"end\":37325,\"start\":37319},{\"end\":37334,\"start\":37325},{\"end\":37341,\"start\":37334},{\"end\":37348,\"start\":37341},{\"end\":37357,\"start\":37348},{\"end\":37365,\"start\":37357},{\"end\":37649,\"start\":37634},{\"end\":37943,\"start\":37933},{\"end\":37956,\"start\":37943},{\"end\":37966,\"start\":37956},{\"end\":37978,\"start\":37966},{\"end\":38366,\"start\":38359},{\"end\":38375,\"start\":38366},{\"end\":38385,\"start\":38375},{\"end\":38685,\"start\":38677},{\"end\":38692,\"start\":38685},{\"end\":38699,\"start\":38692},{\"end\":38712,\"start\":38699},{\"end\":39173,\"start\":39165},{\"end\":39179,\"start\":39173},{\"end\":39187,\"start\":39179},{\"end\":39195,\"start\":39187},{\"end\":39203,\"start\":39195},{\"end\":39559,\"start\":39543},{\"end\":39569,\"start\":39559},{\"end\":39580,\"start\":39569},{\"end\":39797,\"start\":39787},{\"end\":39808,\"start\":39797},{\"end\":39817,\"start\":39808},{\"end\":39829,\"start\":39817},{\"end\":39840,\"start\":39829},{\"end\":40161,\"start\":40154},{\"end\":40170,\"start\":40161},{\"end\":40176,\"start\":40170},{\"end\":40182,\"start\":40176},{\"end\":40189,\"start\":40182},{\"end\":40478,\"start\":40472},{\"end\":40487,\"start\":40478},{\"end\":40494,\"start\":40487},{\"end\":40501,\"start\":40494},{\"end\":40884,\"start\":40872},{\"end\":40890,\"start\":40884},{\"end\":41099,\"start\":41089},{\"end\":41112,\"start\":41099},{\"end\":41429,\"start\":41422},{\"end\":41436,\"start\":41429},{\"end\":41444,\"start\":41436},{\"end\":41452,\"start\":41444},{\"end\":41691,\"start\":41683},{\"end\":41699,\"start\":41691},{\"end\":41708,\"start\":41699},{\"end\":41716,\"start\":41708},{\"end\":42157,\"start\":42135},{\"end\":42166,\"start\":42157},{\"end\":42175,\"start\":42166},{\"end\":42187,\"start\":42175},{\"end\":42628,\"start\":42618},{\"end\":42643,\"start\":42628},{\"end\":42652,\"start\":42643},{\"end\":42664,\"start\":42652},{\"end\":43149,\"start\":43139},{\"end\":43164,\"start\":43149},{\"end\":43173,\"start\":43164},{\"end\":43185,\"start\":43173},{\"end\":43520,\"start\":43512},{\"end\":43528,\"start\":43520},{\"end\":43535,\"start\":43528},{\"end\":43541,\"start\":43535},{\"end\":43547,\"start\":43541},{\"end\":43886,\"start\":43873},{\"end\":43899,\"start\":43886},{\"end\":43910,\"start\":43899},{\"end\":43920,\"start\":43910},{\"end\":43930,\"start\":43920},{\"end\":44180,\"start\":44169},{\"end\":44191,\"start\":44180},{\"end\":44204,\"start\":44191},{\"end\":44213,\"start\":44204},{\"end\":44222,\"start\":44213},{\"end\":44236,\"start\":44222},{\"end\":44246,\"start\":44236},{\"end\":44587,\"start\":44579},{\"end\":44600,\"start\":44587},{\"end\":44611,\"start\":44600},{\"end\":45078,\"start\":45070},{\"end\":45086,\"start\":45078},{\"end\":45094,\"start\":45086},{\"end\":45100,\"start\":45094},{\"end\":45108,\"start\":45100},{\"end\":45116,\"start\":45108},{\"end\":45122,\"start\":45116},{\"end\":45129,\"start\":45122},{\"end\":45570,\"start\":45562},{\"end\":45577,\"start\":45570},{\"end\":45583,\"start\":45577},{\"end\":45590,\"start\":45583},{\"end\":45597,\"start\":45590},{\"end\":45994,\"start\":45988},{\"end\":46003,\"start\":45994},{\"end\":46014,\"start\":46003},{\"end\":46027,\"start\":46014},{\"end\":46350,\"start\":46344},{\"end\":46359,\"start\":46350},{\"end\":46366,\"start\":46359},{\"end\":46373,\"start\":46366},{\"end\":46380,\"start\":46373},{\"end\":46388,\"start\":46380},{\"end\":46398,\"start\":46388},{\"end\":46406,\"start\":46398},{\"end\":46413,\"start\":46406},{\"end\":46775,\"start\":46767},{\"end\":46782,\"start\":46775},{\"end\":46791,\"start\":46782},{\"end\":46798,\"start\":46791},{\"end\":47167,\"start\":47161},{\"end\":47174,\"start\":47167},{\"end\":47182,\"start\":47174},{\"end\":47190,\"start\":47182},{\"end\":47388,\"start\":47381},{\"end\":47396,\"start\":47388},{\"end\":47403,\"start\":47396},{\"end\":47410,\"start\":47403},{\"end\":47418,\"start\":47410},{\"end\":47426,\"start\":47418},{\"end\":47432,\"start\":47426},{\"end\":47439,\"start\":47432},{\"end\":47830,\"start\":47821},{\"end\":47839,\"start\":47830},{\"end\":47845,\"start\":47839},{\"end\":47853,\"start\":47845},{\"end\":48155,\"start\":48146},{\"end\":48167,\"start\":48155},{\"end\":48178,\"start\":48167},{\"end\":48189,\"start\":48178}]", "bib_venue": "[{\"end\":38861,\"start\":38795},{\"end\":39318,\"start\":39269},{\"end\":40642,\"start\":40580},{\"end\":41865,\"start\":41799},{\"end\":42328,\"start\":42266},{\"end\":42821,\"start\":42751},{\"end\":44772,\"start\":44700},{\"end\":45270,\"start\":45208},{\"end\":45716,\"start\":45665},{\"end\":46862,\"start\":46851},{\"end\":48338,\"start\":48272},{\"end\":36589,\"start\":36502},{\"end\":37026,\"start\":36965},{\"end\":37296,\"start\":37234},{\"end\":37666,\"start\":37649},{\"end\":38060,\"start\":37978},{\"end\":38446,\"start\":38385},{\"end\":38793,\"start\":38712},{\"end\":39267,\"start\":39203},{\"end\":39641,\"start\":39595},{\"end\":39909,\"start\":39856},{\"end\":40227,\"start\":40189},{\"end\":40578,\"start\":40501},{\"end\":40870,\"start\":40828},{\"end\":41176,\"start\":41112},{\"end\":41468,\"start\":41452},{\"end\":41797,\"start\":41716},{\"end\":42264,\"start\":42187},{\"end\":42749,\"start\":42664},{\"end\":43232,\"start\":43185},{\"end\":43630,\"start\":43547},{\"end\":43995,\"start\":43946},{\"end\":44301,\"start\":44261},{\"end\":44698,\"start\":44611},{\"end\":45206,\"start\":45129},{\"end\":45663,\"start\":45597},{\"end\":46065,\"start\":46027},{\"end\":46451,\"start\":46413},{\"end\":46849,\"start\":46798},{\"end\":47246,\"start\":47205},{\"end\":47529,\"start\":47455},{\"end\":47883,\"start\":47853},{\"end\":48270,\"start\":48189}]"}}}, "year": 2023, "month": 12, "day": 17}