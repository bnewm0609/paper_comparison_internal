{"id": 204838340, "updated": "2023-10-06 21:50:17.343", "metadata": {"title": "Contrastive Representation Distillation", "authors": "[{\"first\":\"Yonglong\",\"last\":\"Tian\",\"middle\":[]},{\"first\":\"Dilip\",\"last\":\"Krishnan\",\"middle\":[]},{\"first\":\"Phillip\",\"last\":\"Isola\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2019, "month": null, "day": null}, "abstract": "Often we wish to transfer representational knowledge from one neural network to another. Examples include distilling a large network into a smaller one, transferring knowledge from one sensory modality to a second, or ensembling a collection of models into a single estimator. Knowledge distillation, the standard approach to these problems, minimizes the KL divergence between the probabilistic outputs of a teacher and student network. We demonstrate that this objective ignores important structural knowledge of the teacher network. This motivates an alternative objective by which we train a student to capture significantly more information in the teacher's representation of the data. We formulate this objective as contrastive learning. Experiments demonstrate that our resulting new objective outperforms knowledge distillation and other cutting-edge distillers on a variety of knowledge transfer tasks, including single model compression, ensemble distillation, and cross-modal transfer. Our method sets a new state-of-the-art in many transfer tasks, and sometimes even outperforms the teacher network when combined with knowledge distillation. Code: http://github.com/HobbitLong/RepDistiller.", "fields_of_study": "[\"Computer Science\",\"Mathematics\"]", "external_ids": {"arxiv": "1910.10699", "mag": "2995607862", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/iclr/TianKI20", "doi": null}}, "content": {"source": {"pdf_hash": "197498cb2ad787e4f71c05098cee6b10d9d067bd", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/1910.10699v3.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "512c07005e3f0226113ff9fbd249cd5ca1ed6250", "type": "plain-text", "url": "s3://ai2-s2-science-parse-plus-prod/parse-results/s2orc_worker/197498cb2ad787e4f71c05098cee6b10d9d067bd.txt", "contents": "\nCONTRASTIVE REPRESENTATION DISTILLATION\n24 Jan 2022\n\nYonglong Tian yonglong@mit.edu \nMit Csail \nDilip Krishnan dilipkay@google.com \nPhillip Isola phillipi@mit.edu \nCONTRASTIVE REPRESENTATION DISTILLATION\n24 Jan 20220E17FFD5B5EB0B89A188DEA8D52AA0F4arXiv:1910.10699v3[cs.LG]\nOften we wish to transfer representational knowledge from one neural network to another.Examples include distilling a large network into a smaller one, transferring knowledge from one sensory modality to a second, or ensembling a collection of models into a single estimator.Knowledge distillation, the standard approach to these problems, minimizes the KL divergence between the probabilistic outputs of a teacher and student network.We demonstrate that this objective ignores important structural knowledge of the teacher network.This motivates an alternative objective by which we train a student to capture significantly more information in the teacher's representation of the data.We formulate this objective as contrastive learning.Experiments demonstrate that our resulting new objective outperforms knowledge distillation and other cutting-edge distillers on a variety of knowledge transfer tasks, including single model compression, ensemble distillation, and cross-modal transfer.Our method sets a new state-of-the-art in many transfer tasks, and sometimes even outperforms the teacher network when combined with knowledge distillation.\n\nINTRODUCTION\n\nKnowledge distillation (KD) transfers knowledge from one deep learning model (the teacher) to another (the student).The objective originally proposed by Hinton et al. (2015) minimizes the KL divergence between the teacher and student outputs.This formulation makes intuitive sense when the output is a distribution, e.g., a probability mass function over classes.However, often we instead wish to transfer knowledge about a representation.For example, in the problem of \"cross-modal distillation\", we may wish to transfer the representation of an image processing network to a sound (Aytar et al., 2016) or to depth (Gupta et al., 2016) processing network, such that deep features for an image and the associated sound or depth features are highly correlated.In such cases, the KL divergence is undefined.\n\nRepresentational knowledge is structured -the dimensions exhibit complex interdependencies.The original KD objective introduced in (Hinton et al., 2015) treats all dimensions as independent, conditioned on the input.Let y T be the output of the teacher and y S be the output of the student.Then the original KD objective function, \u03c8, has the fully factored form: \u03c8(y S , y T ) = i \u03c6 i (y S i , y T i ) * .Such a factored objective is insufficient for transferring structural knowledge, i.e. dependencies between output dimensions i and j.This is similar to the situation in image generation where an L 2 objective produces blurry results, due to independence assumptions between output dimensions.\n\nTo overcome this problem, we would like an objective that captures correlations and higher order output dependencies.To achieve this, in this paper we leverage the family of contrastive objectives (Gutmann & Hyv\u00e4rinen, 2010;Oord et al., 2018;Arora et al., 2019;Hjelm et al., 2018).These objective functions have been used successfully in recent years for density estimation and representation learning, especially in self-supervised settings.Here we adapt them to the task of knowledge distillation from one deep network to another.We show that it is important to work in representation space, similar to recent works such as Zagoruyko & Komodakis (2016a); Romero et al. (2014).However, note that the loss functions used in those works do not explicitly try to capture correlations or higher-order dependencies in representational space.\nn Q j + h Q 8 p A z a q z U C B 8 b / X L F r b p z k F X i 5 a Q C O e r 9 8 l d v E L M 0 Q m m Y o F p 3 P T c x f k a V 4 U z g t N R L N S a U j e k Q u 5 Z K G q H 2 s / m p U 3 J m l Q E J Y 2 V L G j J X f 0 9 k N N J 6 E g W 2 M 6 J m p J e 9 m f i f 1 0 1 N e O 1 n X C a p Q c k W i 8 J U E B O T 2 d 9 k w B U y I y a W U K a 4 v Z W w E V W U G Z t O y Y b g L b + 8 S l o X V c + t e v e X l d p N H k c R T u A U z s G D K 6 j B H d S h C Q y G 8 A y v 8 O Y I 5 8 V 5 d z 4 W r Q U n n z m G P 3 A + f w A i R 4 2 v < / l a t e x i t > f T (x i ) < l a t e x i t s h a 1 _ b a s e 6 4 = \" k b q D u h Z 8 p I o x S p a y 2 w N L x G g U L W s = \" > A A A B 7 3 i c b V D L S g N B E O z 1 G e M r 6 t H L Y B D i J e y K o M e g F 4 8 R 8 o J k D b O T 2 W T I 7 O w 6 0 y u G k J / w 4 k E R r / 6 O N / / G S b I H T S x o K K q 6 6 e 4 K E i k M u u 6 3 s 7 K 6 t r 6 x m d v K b + / s 7 u 0 X D g 4 b J k 4 1 4 3 U W y 1 i 3 A m q 4 F I r X U a D k r U R z G g W S N 4 P h z d R v P n J t R K x q O E q 4 H 9 G + E q F g F K 3 U C u 9 r p a e u O O s W i m 7 Z n Y E s E y 8 j R c h Q 7 R a + O r 2 Y p R F X y C Q 1 p u 2 5 C f p j q l E w y S f 5 T m p 4 Q t m Q 9 n n b U k U j b v z x 7 N 4 J O b V K j 4 S x t q W Q z N T f E 2 M a G T O K A t s Z U R y Y R W 8 q / u e 1 U w y v / L F Q S Y p c s f m i M J U E Y z J 9 n v S E 5 g z l y B L K t L C 3 E j a g m j K 0 E e V t C N 7 i y 8 u k c V 7 2 3 L J 3 d 1 G s X G d x 5 O A Y T q A E H l x C B W 6 h C n V g I O E Z X u H N e X B eU W y 1 i 3 A m q 4 F I r X U a D k r U R z G g W S N 4 P h z d R v P n J t R K x q O E q 4 H 9 G + E q F g F K 3 U C u 9 r p a e u O O s W i m 7 Z n Y E s E y 8 j R c h Q 7 R a + O r 2 Y p R F X y C Q 1 p u 2 5 C f p j q l E w y S f 5 T m p 4 Q t m Q 9 n n b U k U j b v z x 7 N 4 J O b V K j 4 S x t q W Q z N T f E 2 M a G T O K A t s Z U R y Y R W 8 q / u e 1 U w y v / L F Q S Y p c s f m i M J U E Y z J 9 n v S E 5 g z l y B L K t L C 3 E j a g m j K 0 E e V t C N 7 i y 8 u k c V 7 2 3 L J 3 d 1 G s X G d x 5 O A Y T q A E H l x C B W 6 h C n V g I O E Z X u H N e X B eU W y 1 i 3 A m q 4 F I r X U a D k r U R z G g W S N 4 P h z d R v P n J t R K x q O E q 4 H 9 G + E q F g F K 3 U C u 9 r p a e u O O s W i m 7 Z n Y E s E y 8 j R c h Q 7 R a + O r 2 Y p R F X y C Q 1 p u 2 5 C f p j q l E w y S f 5 T m p 4 Q t m Q 9 n n b U k U j b v z x 7 N 4 J O b V K j 4 S x t q W Q z N T f E 2 M a G T O K A t s Z U R y Y R W 8 q / u e 1 U w y v / L F Q S Y p c s f m i M J U E Y z J 9 n v S E 5 g z l y B L K t L C 3 E j a g m j K 0 E e V t C N 7 i y 8 u k c V 7 2 3 L J 3 d 1 G s X G d x 5 O A Y T q A E H l x C B W 6 h C n V g I O E Z X u H N e X B eU W y 1 i 3 A m q 4 F I r X U a D k r U R z G g W S N 4 P h z d R v P n J t R K x q O E q 4 H 9 G + E q F g F K 3 U C u 9 r p a e u O O s W i m 7 Z n Y E s E y 8 j R c h Q 7 R a + O r 2 Y p R F X y C Q 1 p u 2 5 C f p j q l E w y S f 5 T m p 4 Q t m Q 9 n n b U k U j b v z x 7 N 4 J O b V K j 4 S x t q W Q z N T f E 2 M a G T O K A t s Z U R y Y R W 8 q / u e 1 U w y v / L F Q S Y p c s f m i M J U E Y z J 9 n v S E 5 g z l y B L K t L C 3 E j a g m j K 0 E e V t C N 7 i y 8 u k c V 7 2 3 L J 3 d 1 G s X G d x 5 O A Y T q A E H l x C B W 6 h C n V g I O E Z X u H N e X B e n H f n Y 9 6 6 4 m Q z R / A H z u c P R P + P c w = = < / l a t e x i t > f S (x i ) < l a t e x i t s h a 1 _ b a s e 6 4 = \" b c e B C T M q E P / 3 / J 7 T V Y m V 7 A y h M x M = \" > A A A B 7 3 i c b V D L S g N B E O z 1 G e M r 6 t H L Y B D i J e y K o M e g F 4 8 R z Q O S G G Y n v c m Q 2 d l 1 Z l Y M S 3 7 C i w d F v P o 7 3 v w b J 8 k e N L G g o a j q p r v L j w X X x n W / n a X l l d W 1 9 d x G f n N r e 2 e 3 s L d f 1 1 G i G N Z Y J C L V 9 K l G w S X W D D c C m 7 F C G v o C G / 7 w a u I 3 H l F p H s k 7 M 4 q x E 9 K + 5 A F n 1 F i p G d z f l p 6 6 / K R b K L p l d w q y S L y M F C F D t V v 4 a v c i l o Q o D R N U 6 5 b n x q a T U m U 4 E z j O t x O N M W V D 2 s e W p Z K G q D v p 9 N 4 x O b Z K j w S R s i U N m a q / J 1 I a a j 0 K f d s Z U j P Q 8 9 5 E / M 9 r J S a 4 6 K R c x o l B y W a L g k Q Q E 5 H J 8 6 T H F T I j R p Z Q p r i 9 l b A B V Z Q Z G 1 H e h u D N v 7 x I 6 q d l z y 1 7 N 2 f F y m U W R w 4 O 4 Q h K 4 M E 5 V O A a q l A D B g K e 4\nR X e n A f n x X l 3 P m a t S 0 4 2 c w B / 4 H z + A E N 2 j 3 I = < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" b c e B C T M q E P / 3 /\nJ 7 T V Y m V 7 A y h M x M = \" > A A A B 7 3 i c b V D L S g N B E O z 1 G e M r 6 t H L Y B D i J e y K o M e g F 4 8 R z Q O S G G Y n v c m Q 2 d l 1 Z l Y M S 3 7 C i w d F v P o 7 3 v w b J 8 k e N L G g o a j q p r v L j w X X x n W / n a X l l d W 1 9 d x G f n N r e 2 e 3 s L d f 1 1 G i G N Z Y J C L V 9 K l G w S X W D D c C m 7 F C G v o C G / 7 w a u I 3 H l F p H s k 7 M 4 q x E 9 K + 5 A F n 1 F i p G d z f l p 6 6 / K R b K L p l d w q y S L y M F C F D t V v 4 a v c i l o Q o D R N U 6 5 b n x q a T U m U 4 E z j O t x O N M W V D 2 s e W p Z K G q D v p 9 N 4 x O b Z K j w S R s i U N m a q / J 1 I a a j 0 K f d s Z U j P Q 8 9 5 E / M 9 r J S a 4 6 K R c x o l B y W a L g k Q Q E 5 H J 8 6 T H F T I j R p Z Q p r i 9 l b A B V Z Q Z G 1 H e h u D N v 7 x I 6 q d l z y 1 7 N 2 f F y m U W R w 4 O 4 Q h K 4 M E 5 V O A a q l A D B g K e 4\nR X e n A f n x X l 3 P m a t S 0 4 2 c w B / 4 H z + A E N 2 j 3 I = < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" b c e B C T M q E P / 3 /\nJ 7 T V Y m V 7 A y h M x M = \" > A A A B 7 3 i c b V D L S g N B E O z 1 G e M r 6 t H L Y B D i J e y K o M e g F 4 8 R z Q O S G G Y n v c m Q 2 d l 1 Z l Y M S 3 7 C i w d F v P o 7 3 v w b J 8 k e N L G g o a j q p r v L j w X X x n W / n a X l l d W 1 9 d x G f n N r e 2 e 3 s L d f 1 1 G i G N Z Y J C L V 9 K l G w S X W D D c C m 7 F C G v o C G / 7 w a u I 3 H l F p H s k 7 M 4 q x E 9 K + 5 A F n 1 F i p G d z f l p 6 6 / K R b K L p l d w q y S L y M F C F D t V v 4 a v c i l o Q o D R N U 6 5 b n x q a T U m U 4 E z j O t x O N M W V D 2 s e W p Z K G q D v p 9 N 4 x O b Z K j w S R s i U N m a q / J 1 I a a j 0 K f d s Z U j P Q 8 9 5 E / M 9 r J S a 4 6 K R c x o l B y W a L g k Q Q E 5 H J 8 6 T H F T I j R p Z Q p r i 9 l b A B V Z Q Z G 1 H e h u D N v 7 x I 6 q d l z y 1 7 N 2 f F y m U W R w 4 O 4 Q h K 4 M E 5 V O A a q l A D B g K e 4\nR X e n A f n x X l 3 P m a t S 0 4 2 c w B / 4 H z + A E N 2 j 3 I = < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" b c e B C T M q E P / 3 /\nJ 7 T V Y m V 7 A y h M x M = \" > A A A B 7 3 i c b V D L S g N B E O z 1 G e M r 6 t H L Y B D i J e y K o M e g F 4 8 R z Q O S G G Y n v c m Q 2 d l 1 Z l Y M S 3 7 C i w d F v P o 7 3 v w b J 8 k e N L G g o a j q p r v L j w X X x n W / n a X l l d W 1 9 d x G f n N r e 2 e 3 s L d f 1 1 G i G N Z Y J C L V 9 K l G w S X W D D c C m 7 F C G v o C G / 7 w a u I 3 H l F p H s k 7 M 4 q x E 9 K + 5 A F n 1 F i p G d z f l p 6 6 / K R b K L p l d w q y S L y M F C F D t V v 4 a v c i l o Q o D R N U 6 5 b n x q a T U m U 4 E z j O t x O N M W V D 2 s e W p Z K G q D v p 9 N 4 x O b Z K j w S R s i U N m a q / J 1 I a a j 0 K f d s Z U j P Q 8 9 5 E / M 9 r J S a 4 6 K R c x o l B y W a L g k Q Q E 5 H J 8 6 T H F T I j R p Z Q p r i 9 l b A B V Z Q Z G 1 H e h u D N v 7 x I 6 q d l z y 1 7 N 2 f F y m U W R w 4 O 4 Q h K 4 M E 5 V O A a q l A D B g K e 4\nR X e n A f n x X l 3 P m a t S 0 4 2 c w B / 4 H z + A E N 2 j 3 I = < / l a t e x i t > f S (x j ) < l a t e x i t s h a 1 _ b a s e 6 4 = \" g 3\nY I s q 1 c H G n i d D M h L g A / U L z L M B g = \" > A A A B 7 3 i c b V B N S w M x E J 2 t X 7 V + V T 1 6 C R a h X s q u C H o s e v F Y 0 X 5 A u 5 Z s m m 1 j k + y a Z M W y 9 E 9 4 8 a C I V / + O N / + N a b s H b X 0 w 8 H h v h p l 5 Q c y Z N q 7 7 7 e S W l l d W 1 / L r h Y 3 N r e 2 d 4 u 5 e Q 0 e J I r R O I h 6 p V o A 1 5 U z S u m G G 0 1 a s K B Y B p 8 1 g e D n x m 4 9 U a R b J W z O K q S 9 w X 7 K Q E W y s 1 A r v b s p P 3 f v j b r H k V t w p 0 C L x M l K C D L V u 8 a v T i 0 g i q D S E Y 6 3 b n h s b P 8 X K M M L p u N B J N I 0 x G e I + b V s q s a D a T 6 f 3 j t G R V X o o j J Q t a d B U / T 2 R Y q H 1 S A S 2Y I s q 1 c H G n i d D M h L g A / U L z L M B g = \" > A A A B 7 3 i c b V B N S w M x E J 2 t X 7 V + V T 1 6 C R a h X s q u C H o s e v F YW z O K q S 9 w X 7 K Q E W y s 1 A r v b s p P 3 f v j b r H k V t w p 0 C L x M l K C D L V u 8 a v T i 0 g i q D S E Y 6 3 b n h s b P 8 X K M M L p u N B J N I 0 x G e I + b V s q s a D a T 6 f 3 j t G R V X o o j J Q t a d B U / T 2 R Y q H 1 S A S 2Y I s q 1 c H G n i d D M h L g A / U L z L M B g = \" > A A A B 7 3 i c b V B N S w M x E J 2 t X 7 V + V T 1 6 C R a h X s q u C H o s e v F YW z O K q S 9 w X 7 K Q E W y s 1 A r v b s p P 3 f v j b r H k V t w p 0 C L x M l K C D L V u 8 a v T i 0 g i q D S E Y 6 3 b n h s b P 8 X K M M L p u N B J N I 0 x G e I + b V s q s a D a T 6 f 3 j t G R V X o o j J Q t a d B U / T 2 R Y q H 1 S A S 2Y I s q 1 c H G n i d D M h L g A / U L z L M B g = \" > A A A B 7 3 i c b V B N S w M x E J 2 t X 7 V + V T 1 6 C R a h X s q u C H o s e v F YW z O K q S 9 w X 7 K Q E W y s 1 A r v b s p P 3 f v j b r H k V t w p 0 C L x M l K C D L V u 8 a v T i 0 g i q D S E Y 6 3 b n h s b P 8 X K M M L p u N B J N I 0 x G e I + b V s q s a D a T 6 f 3 j t G R V X o o j J Q t a d B U / T 2 R Y q H 1 S A S 2N I = \" > A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 c W 7 A e 0 o W y 2 k 3 b t Z h N 2 N 2 I J / Q V e P C j i 1 Z / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b / + g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 H 1 F p H s t 7 M 0 n Q j + h Q 8 p A z a q z U e O q X K 2 7 V n Y O s E i 8 n F c h R 7 5 e / e o O Y p R F K w w T V u u u 5 i f E z q g x n A q e l X q o x o W x M h 9 i 1 V N I I t Z / N D 5 2 S M 6 s M S B g r W 9 K Q u f p 7 I q O R 1 p M o s J 0 R N S O 9 7 M 3 E / 7 x u a s J r P + M y S Q 1 K t l g U p o K Y m M y + J g O u k B k x s Y Q y x e 2 t h I 2 o o s z Y b E o 2 B G / 5 5 V X S u q h 6 b t V r X F Z q N 3 k c R T i B U z g H D 6 6 g B n d Q h y Y w Q H i G V 3 h z H p w X 5 9 3 5 W L Q W n H z m G P 7 A + f w B 5 j m M / A = = < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" f 2 y z i m w b R / D g j z p 6 t Z 3 6 0 f H R q N I = \" > A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 c W 7 A e 0 o W y 2 k 3 b t Z h N 2 N 2 I J / Q V e P C j i 1 Z / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b / + g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 H 1 F p H s t 7 M 0 n Q j + h Q 8 p A z a q z U e O q X K 2 7 V n Y O s E i 8 n F c h R 7 5 e / e o O Y p R F K w w T V u u u 5 i f E z q g x n A q e l X q o x o W x M h 9 i 1 V N I I t Z / N D 5 2 S M 6 s M S B g r W 9 K Q u f p 7 I q O R 1 p M o s J 0 R N S O 9 7 M 3 E / 7 x u a s J r P + M y S Q 1 K t l g U p o K Y m M y + J g O u k B k x s Y Q y x e 2 t h I 2 o o s z Y b E o 2 B G / 5 5 V X S u q h 6 b t V r X F Z q N 3 k c R T i B U z g H D 6 6 g B n d Q h y Y w Q H i G V 3 h z H p w X 5 9 3 5 W L Q W n H z m G P 7 A + f w B 5 j m M / A = = < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" f 2 y z i m w b R / D g j z p 6 t Z 3 6 0 f H R q N I = \" > A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 c W 7 A e 0 o W y 2 k 3 b t Z h N 2 N 2 I J / Q V e P C j i 1 Z / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b / + g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 H 1 F p H s t 7 M 0 n Q j + h Q 8 p A z a q z U e O q X K 2 7 V n Y O s E i 8 n F c h R 7 5 e / e o O Y p R F K w w T V u u u 5 i f E z q g x n A q e l X q o x o W x M h 9 i 1 V N I I t Z / N D 5 2 S M 6 s M S B g r W 9 K Q u f p 7 I q O R 1 p M o s J 0 R N S O 9 7 M 3 E / 7 x u a s J r P + M y S Q 1 K t l g U p o K Y m M y + J g O u k B k x s Y Q y x e 2 t h I 2 o o s z Y b E o 2 B G / 5 5 V X S u q h 6 b t V r X F Z q N 3 k c R T i B U z g H D 6 6 g B n d Q h y Y w Q H i G V 3 h z H p w X 5 9 3 5 W L Q W n H z m G P 7 A + f w B 5 j m M / A = = < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" f 2 y z i m w b R / D g j z p 6 t Z 3 6 0 f H R q N I = \" > A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 c W 7 A e 0 o W y 2 k 3 b t Z h N 2 N 2 I J / Q V e P C j i 1 Z / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b / + g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 H 1 F p H s t 7 M 0 n Q j + h Q 8 p A z a q z U e O q X K 2 7 V n Y O s E i 8 n F c h R 7 5 e / e o O Y p R F K w w T V u u u 5 i f E z q g x n A q e l X q o x o W x M h 9 i 1 V N I I t Z / N D 5 2 S M 6 s M S B g r W 9 K Q u f p 7 I q O R 1 p M o s J 0 R N S O 9 7 M 3 E / 7 x u a s J r P + M y S Q 1 K t l g U p o K Y m M y + J g O u k B k x s Y Q y x e 2 t h I 2 o o s z Y b E o 2 B G / 5 5 V X S u q h 6 b t V r X F Z q N 3 k c R T i B U z g H D 6 6 g B n d Q h y Y w Q H i G V 3 h z H p w X 5 9 3 5 W L Q W n H z m G P 7 A + f w B 5 j m M / A = = < / l a t e x i t >\nx < l a t e x i t s h a 1 _ b a s e 6 4 = \" f 2 y z i m w b R / D g j z p 6 t Z 3 6 0 f H R q N I = \" > A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 c W 7 A e 0 o W y 2 k 3 b t Z h N 2 N 2 I J / Q V e P C j i 1 Z / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d   4 W 1 9 Y 3 N r e J 2 a W d 3 b / 2 8 H 4 d u a 3 H 1 F p H s t 7 M 0\n3 b / + g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 H 1 F p H s t 7 M 0 n Q j + h Q 8 p A z a q z U e O q X K 2 7 V n Y O s E i 8 n F c h R 7 5 e / e o O Y p R F K w w T V u u u 5 i f E z q g x n A q e l X q o x o W x M h 9 i 1 V N I I t Z / N D 5 2 S M 6 s M S B g r W 9 K Q u f p 7 I q O R 1 p M o s J 0 R N S O 9 7 M 3 E / 7 x u a s J r P + M y S Q 1 K t l g U p o K Y m M y + J g O u k B k x s Y Q y x e 2 t h I 2 o o s z Y b E o 2 B G / 5 5 V X S u q h 6 b t V r X F Z q N 3 k c R T i B U z g H D 6 6 g B n d Q h y Y w Q H i G V 3 h z+ g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 H 1 F p H s t 7 M 0 n Q j + h Q 8 p A z a q z U e O q X K 2 7 V n Y O s E i 8 n F c h R 7 5 e / e o O Y p R F K w w T V u u u 5 i f E z q g x n A q e l X q o x o W x M h 9 i 1 V N I I t Z / N D 5 2 S M 6 s M S B g r W 9 K Q u f p 7 I q O R 1 p M o s J 0 R N S O 9 7 M 3 E / 7 x u a s J r P + M y S Q 1 K t l g U p o K Y m M y + J g O u k B k x s Y Q y x e 2 t h I 2 o o s z Y b E o 2 B G / 5 5 V X S u q h 6 b t V r X F Z q N 3 k c R T i B U z g H D 6 6 g B n d Q h y Y w Q H i G V 3 h z+ g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 H 1 F p H s t 7 M 0 n Q j + h Q 8 p A z a q z U e O q X K 2 7 V n Y O s E i 8 n F c h R 7 5 e / e o O Y p R F K w w T V u u u 5 i f E z q g x n A q e l X q o x o W x M h 9 i 1 V N I I t Z / N D 5 2 S M 6 s M S B g r W 9 K Q u f p 7 I q O R 1 p M o s J 0 R N S O 9 7 M 3 E / 7 x u a s J r P + M y S Q 1 K t l g U p o K Y m M y + J g O u k B k x s Y Q y x e 2 t h I 2 o o s z Y b E o 2 B G / 5 5 V X S u q h 6 b t V r X F Z q N 3 k c R T i B U z g H D 6 6 g B n d Q h y Y w Q H i G V 3 h z H p w X 5 9 3 5 W L Q W n H z m G P 7 A + f w B 5 j m M / A = = < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" f 2 y z i m w b R / D g j z p 6 t Z 3 6 0 f H R q N I = \" > A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 c W 7 A e 0 o W y 2 k 3 b t Z h N 2 N 2 I J / Q V e P C j i 1 Z / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O+ g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U Cn Q j + h Q 8 p A z a q z U e O q X K 2 7 V n Y O s E i 8 n F c h R 7 5 e / e o O Y p R F K w w T V u u u 5 i f E z q g x n A q e l X q o x o W x M h 9 i 1 V N I I t Z / N D 5 2 S M 6 s M S B g r W 9 K Q u f p 7 I q O R 1 p M o s J 0 R N S O 9 7 M 3 E / 7 x u a s J r P + M y S Q 1 K t l g U p o K Y m M y + J g O u k B k x s Y Q y x e 2 t h I 2 o o s z Y b E o 2 B G / 5 5 V X S u q h 6 b t V r X F Z q N 3 k c R T i B U z g H D 6 6 g B n d Q h y Y w Q H i G V 3 h z H p w X 5 9 3 5 W L Q W n H z m G P 7 A + f w B 5 j m M / A = = < / l a t e x i t > Teacher Student c f T < l a t e x i t s h a 1 _ b a s e 6 4 = \" o U 1 K E 6 i l 3 e 3 6 L u b h + t R i f 1 X 0 p 4 Q = \" > A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 e K / Y I 2 l s 1 2 0 y 7 d b M L u R C i h P 8 G L B 0 W 8 + o u 8 + W / c t j l o 6 4 O B x 3 s z z M w L E i k M u u 6 3 U 1 h b 3 9 j c K m 6 X d n b 3 9 g / K h 0 c t E 6 e a 8 S a L Z a w 7 A T V c C s W b K F D y T q I 5 j Q L J 2 8 H 4 d u a 3 n 7 g 2 I l Y N n C T c j + h Q i V A w i l Z 6 C B 8 b / X L F r b p z k F X i 5 a Q C O e r 9 8 l d v E L M 0 4 g q Z p M Z 0 P T d B P 6 M a B Z N 8 W u q l h i e U j e m Q d y 1 V N O L G z + a n T s m Z V Q Y k j L U t h W S u / p 7 I a G T M J A p s Z 0 R x Z J a 9 m f i f 1 0 0 x v P Y z o Z I U u W K L R W E q C c Z k 9 j c Z C M 0 Z y o k l l G l h b y V s R D V l a N M p 2 R C 8 5 Z d X S e u i 6 r l V 7 / 6 y U r v J 4 y j C C Z z C O X h w B T W 4 g z o 0 g c E Q n u E V 3 h z p v D j vh + t R i f 1 X 0 p 4 Q = \" > A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 e K / Y I 2 l s 1 2 0 y 7 d b M L u R C i h P 8 G L B 0 W 8 + o u 8 + W / c t j l o 6 4 O B x 3 s z z M w L E i k M u u 6 3 U 1 h b 3 9 j c K m 6 X d n b 3 9 g / K h 0 c t E 6 e a 8 S a L Z a w 7 A T V c C s W b K F D y T q I 5 j Q L J 2 8 H 4 d u a 3 n 7 g 2 I l Y N n C T c j + h Q i V A w i l Z 6 C B 8 b / X L F r b p z k F X i 5 a Q C O e r 9 8 l d v E L M 0 4 g q Z p M Z 0 P T d B P 6 M a B Z N 8 W u q l h i e U j e m Q d y 1 V N O L G z + a n T s m Z V Q Y k j L U t h W S u / p 7 I a G T M J A p s Z 0 R x Z J a 9 m f i f 1 0 0 x v P Y z o Z I U u W K L R W E q C c Z k 9 j c Z C M 0 Z y o k l l G l h b y V s R D V l a N M p 2 R C 8 5 Z d X S e u i 6 r l V 7 / 6 y U r v J 4 y j C C Z z C O X h w B T W 4 g z o 0 g c E Q n u E V 3 h z p v D j vh + t R i f 1 X 0 p 4 Q = \" > A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 e K / Y I 2 l s 1 2 0 y 7 d b M L u R C i h P 8 G L B 0 W 8 + o u 8 + W / c t j l o 6 4 O B x 3 s z z M w L E i k M u u 6 3 U 1 h b 3 9 j c K m 6 X d n b 3 9 g / K h 0 c t E 6 e a 8 S a L Z a w 7 A T V c C s W b K F D y T q I 5 j Q L J 2 8 H 4 d u a 3 n 7 g 2 I l Y N n C T c j + h Q i V A w i l Z 6 C B 8 b / X L F r b p z k F X i 5 a Q C O e r 9 8 l d v E L M 0 4 g q Z p M Z 0 P T d B P 6 M a B Z N 8 W u q l h i e U j e m Q d y 1 V N O L G z + a n T s m Z V Q Y k j L U t h W S u / p 7 I a G T M J A p s Z 0 R x Z J a 9 m f i f 1 0 0 x v P Y z o Z I U u W K L R W E q C c Z k 9 j c Z C M 0 Z y o k l l G l h b y V s R D V l a N M p 2 R C 8 5 Z d X S e u i 6 r l V 7 / 6 y U r v J 4 y j C C Z z C O X h w B T W 4 g z o 0 g c E Q n u E V 3 h z p v D j vh + t R i f 1 X 0 p 4 Q = \" > A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 e K / Y I 2 l s 1 2 0 y 7 d b M L u R C i h P 8 G L B 0 W 8 + o u 8 + W / c t j l o 6 4 O B x 3 s z z M w L E i k M u u 6 3 U 1 h b 3 9 j c K m 6 X d n b 3 9 g / K h 0 c t E 6 e a 8 S a L Z a w 7 A T V c C s W b K F D y T q I 5 j Q L J 2 8 H 4 d u a 3 n 7 g 2 I l Y N n C T c j + h Q i V A w i l Z 6 C B 8 b / X L F r b p z k F X i 5 a Q C O e r 9 8 l d v E L M 0 4 g q Z p M Z 0 P T d B P 6 M a B Z N 8 W u q l h i e U j e m Q d y 1 V N O L G z + a n T s m Z V Q Y k j L U t h W S u / p 7 I a G T M J A p s Z 0 R x Z J a 9 m f i f 1 0 0 x v P Y z o Z I U u W K L R W E q C c Z k 9 j c Z C M 0 Z y o k l l G l h b y V s R D V l a N M p 2 R C 8 5 Z d X S e u i 6 r l V 7 / 6 y U r v J 4 y j C C Z z C O X h w B T W 4 g z o 0 g c E Q n u E V 3 h z p v D j v= \" > A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 d K 7 Q e 0 s W y 2 k 3 b p Z h N 2 N 0 I J / Q l e P C j i 1 V / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b / + g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 n 1 B p H s s H M 0 n Q j + h Q 8 p A z a q z U C B 8 b / X L F r b p z k F X i 5 a Q C O e r 9 8 l d v E L M 0 Q m m Y o F p 3 P T c x f k a V 4 U z g t N R L N S a U j e k Q u 5 Z K G q H 2 s / m p U 3 J m l Q E J Y 2 V L G j J X f 0 9 k N N J 6 E g W 2 M 6 J m p J e 9 m f i f 1 0 1 N e O 1 n X C a p Q c k W i 8 J U E B O T 2 d 9 k w B U y I y a W U K a 4 v Z W w E V W U G Z t O y Y b g L b + 8 S l o X V c + t e v e X l d p N H k c R T u A U z s G D K 6 j B H d S h C Q y G 8 A y v 8 O Y I 5 8 V 5 d z 4 W r Q U n n z m G P 3 A + f w A i R 4 2 v < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" K 7 f T 4 8 m 4 n 6 W k K P e w H q 0 D 7 I e o B L M = \" > A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 d K 7 Q e 0 s W y 2 k 3 b p Z h N 2 N 0 I J / Q l e P C j i 1 V / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b / + g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 n 1 B p H s s H M 0 n Q j + h Q 8 p A z a q z U C B 8 b / X L F r b p z k F X i 5 a Q C O e r 9 8 l d v E L M 0 Q m m Y o F p 3 P T c x f k a V 4 U z g t N R L N S a U j e k Q u 5 Z K G q H 2 s / m p U 3 J m l Q E J Y 2 V L G j J X f 0 9 k N N J 6 E g W 2 M 6 J m p J e 9 m f i f 1 0 1 N e O 1 n X C a p Q c k W i 8 J U E B O T 2 d 9 k w B U y I y a W U K a 4 v Z W w E V W U G Z t O y Y b g L b + 8 S l o X V c + t e v e X l d p N H k c R T u A U z s G D K 6 j B H d S h C Q y G 8 A y v 8 O Y I 5 8 V 5 d z 4 W r Q U n n z m G P 3 A + f w A i R 4 2 v < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" K 7 f T 4 8 m 4 n 6 W k K P e w H q 0 D 7 I e o B L M = \" > A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 d K 7 Q e 0 s W y 2 k 3 b p Z h N 2 N 0 I J / Q l e P C j i 1 V / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b / + g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 n 1 B p H s s H M 0 n Q j + h Q 8 p A z a q z U C B 8 b / X L F r b p z k F X i 5 a Q C O e r 9 8 l d v E L M 0 Q m m Y o F p 3 P T c x f k a V 4 U z g t N R L N S a U j e k Q u 5 Z K G q H 2 s / m p U 3 J m l Q E J Y 2 V L G j J X f 0 9 k N N J 6 E g W 2 M 6 J m p J e 9 m f i f 1 0 1 N e O 1 n X C a p Q c k W i 8 J U E B O T 2 d 9 k w B U y I y a W U K a 4 v Z W w E V W U G Z t O y Y b g L b + 8 S l o X V c + t e v e X l d p N H k c R T u A U z s G D K 6 j B H d S h C Q y G 8 A y v 8 O Y I 5 8 V 5 d z 4 W r Q U n n z m G P 3 A + f w A i R 4 2 v < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" K 7 f T 4 8 m 4 n 6 W k K P e w H q 0 D 7 I e o B L M = \" > A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 d K 7 Q e 0 s W y 2 k 3 b p Z h N 2 N 0 I J / Q l e P C j i 1 V / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b / + g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 n 1 B p H s s H M 0 n Q j + h Q 8 p A z a q z U C B 8 b / X L F r b p z k F X i 5 a Q C O e r 9 8 l d v E L M 0 Q m m Y o F p 3 P T c x f k a V 4 U z g t N R L N S a U j e k Q u 5 Z K G q H 2 s / m p U 3 J m l Q E J Y 2 V L G j J X f 0 9 k N N J 6 E g W 2 M 6 J m p J e 9 m f i f 1 0 1 N e O 1 n X C a p Q c k W i 8 J U E B O T 2 d 9 k w B U y I y a W U K a 4 v Z W w E V W U G Z t O y Y b g L b + 8 S l o X V c + t e v e X l d p N H k c R T u A U z s G D K 6 j B H d S h C Q y G 8 A y v 8 O Y I 5 8 V 5 d z 4 W r Q U n n z m G P 3 A + f w A i R 4 2 v < / l a t e x i t > y 2 Y\n< l a t e x i t s h a 1 _ b a s e 6 4 = \" 9 a 6 0 r r 3 c Z w B P m j s k t 6 s 6                 Our objective maximizes a lower-bound to the mutual information between the teacher and student representations.We find that this results in better performance on several knowledge transfer tasks.We conjecture that this is because the contrastive objective better transfers all the information in the teacher's representation, rather than only transferring knowledge about conditionally independent output class probabilities.Somewhat surprisingly, the contrastive objective even improves results on the originally proposed task of distilling knowledge about class probabilities, for example, compressing a large CIFAR100 network into a smaller one that performs almost as well.We believe this is because the correlations between different class probabilities contains useful information that regularizes the learning problem.Our paper forges a connection between two literatures that have evolved mostly independently: knowledge distillation and representation learning.This connection allows us to leverage strong methods from representation learning to significantly improve the SOTA on knowledge distillation.Our contributions are:\nJ u M / W v s = \" > A A A B + n i c b V D L S s N A F L 3 x W e s r 1 a W b w S K 4 K o k I u i y 6 c V n B P q Q J Z T K d t E M n k z A z U U L s p 7 h x o Y h b v 8 S d f + O k z U J b D w w c z r m X e + Y E C W d K O 8 6 3 t b K 6 t r 6 x W d m q b u / s 7 u 3 b t Y O O i l N J a J v E P J a 9 A C v K m a B t z T S n v U R S H A W c d o P J d e F 3 H 6 h U L B Z 3 O k u o H + G R Y C E j W B t p Y N c y 5 D G B v A j r M c E 8 v 5 8 O 7 L r T c G Z A y 8 Q t S R 1 K t A b 2 l z e M S R p R o Q n H S v V d J 9 F + j q V m h N N p 1 U s V T T C Z 4 B H t G y p w R J W f z 6 J P 0 Y l R h i i M p X l C o 5 n 6 e y P H k V J Z F J j J I q J a 9 A r x P 6 + f 6 v D S z 5 l I U k 0 F m R 8 K U 4 5 0 j I o e 0 J B J S j T P D M F E M p M V k T G W m G j T V t W U 4 C 5 + e Z l 0 z h q u 0 3 B v z + v N q 7 K O C h z B M Z y C C x f Q h B t o Q R s I P M I z v MW v s = \" > A A A B + n i c b V D L S s N A F L 3 x W e s r 1 a W b w S K 4 K o k I u i y 6 c V n B P q Q J Z T K d t E M n k z A z U U L s p 7 h x o Y h b v 8 S d f + O k z U J b D w w c z r m X e + Y E C W d K O 8 6 3 t b K 6 t r 6 x W d m q b u / s 7 u 3 b t Y O O i l N J a J v E P J a 9 A C v K m a B t z T S n v U R S H A W c d o P J d e F 3 H 6 h U L B Z 3 O k u o H + G R Y C E j W B t p Y N c y 5 D G B v A j r M c E 8 v 5 8 O 7 L r T c G Z A y 8 Q t S R 1 K t A b 2 l z e M S R p R o Q n H S v V d J 9 F + j q V m h N N p 1 U s V T T C Z 4 B H t G y p w R J W f z 6 J P 0 Y l R h i i M p X l C o 5 n 6 e y P H k V J Z F J j J I q J a 9 A r x P 6 + f 6 v D S z 5 l I U k 0 F m R 8 K U 4 5 0 j I o e 0 J B J S j T P D M F E M p M V k T G W m G j T V t W U 4 C 5 + e Z l 0 z h q u 0 3 B v z + v N q 7 K O C h z B M Z y C C x f Q h B t o Q R s I P M I z v MW v s = \" > A A A B + n i c b V D L S s N A F L 3 x W e s r 1 a W b w S K 4 K o k I u i y 6 c V n B P q Q J Z T K d t E M n k z A z U U L s p 7 h x o Y h b v 8 S d f + O k z U J b D w w c z r m X e + Y E C W d K O 8 6 3 t b K 6 t r 6 x W d m q b u / s 7 u 3 b t Y O O i l N J a J v E P J a 9 A C v K m a B t z T S n v U R S H A W c d o P J d e F 3 H 6 h U L B Z 3 O k u o H + G R Y C E j W B t p Y N c y 5 D G B v A j r M c E 8 v 5 8 O 7 L r T c G Z A y 8 Q t S R 1 K t A b 2 l z e M S R p R o Q n H S v V d J 9 F + j q V m h N N p 1 U s V T T C Z 4 B H t G y p w R J W f z 6 J P 0 Y l R h i i M p X l C o 5 n 6 e y P H k V J Z F J j J I q J a 9 A r x P 6 + f 6 v D S z 5 l I U k 0 F m R 8 K U 4 5 0 j I o e 0 J B J S j T P D M F E M p M V k T G W m G j T V t W U 4 C 5 + e Z l 0 z h q u 0 3 B v z + v N q 7 K O C h z B M Z y C C x f Q h B t o Q R s I P M I z v MW v s = \" > A A A B + n i c b V D L S s N A F L 3 x W e s r 1 a W b w S K 4 K o k I u i y 6 c V n B P q Q J Z T K d t E M n k z A z U U L s p 7 h x o Y h b v 8 S d f + O k z U J b D w w c z r m X e + Y E C W d K O 8 6 3 t b K 6 t r 6 x W d m q b u / s 7 u 3 b t Y O O i l N J a J v E P J a 9 A C v K m a B t z T S n v U R S H A W c d o P J d e F 3 H 6 h U L B Z 3 O k u o H + G R Y C E j W B t p Y N c y 5 D G B v A j r M c E 8 v 5 8 O 7 L r T c G Z A y 8 Q t S R 1 K t A b 2 l z e M S R p R o Q n H S v V d J 9 F + j q V m h N N p 1 U s V T T C Z 4 B H t G y p w R J W f z 6 J P 0 Y l R h i i M p X l C o 5 n 6 e y P H k V J Z F J j J I q J a 9 A r x P 6 + f 6 v D S z 5 l I U k 0 F m R 8 K U 4 5 0 j I o e 0 J B J S j T P D M F E M p M V k T G W m G j T V t W U 4 C 5 + e Z l 0 z h q u 0 3 B v z + v N q 7 K O C h z B M Z y C C x f Q h B t o Q R s I P M I z v M K b 9 W S 9 W O / W x 3 x 0 x S p 3 D u E P r M 8 f 7 u i T y A = = < / l a t e x i t > x 2 X < l a t e x i t s h a 1 _ b a s e 6 4 = \" 0 e R Q J Z k D x 3 q F I c W T B / u K C W b V p O o = \" > A A A B + n i c b V D L S s N A F L 2 p r 1 p f q S 7 d D B b B V U l E q M u i G 5 c V 7 A O a U C b T S T t 0 M g k z E 7 X E f o o b F 4 q 4 9 U v c + T d O 2 i y 0 9 c D A 4 Z x 7 u W d O k H C m t O N 8 W 6 W 1 9 Y 3 N r f J 2 Z W d 3 b / / A r h 5 2 V J x K Q t s k 5 r H s B V h R z g R t a 6 Y 5 7 S W S 4 i j g t B t M r n O / e 0 + l Y r G 4 0 9 O E + h E e C R Y y g r W R B n b 1 E X l M I C / C e k w w z 3 q z g V 1 z 6 s 4 c a J W 4 B a l B g d b A / v K G M U k j K j T h W K m + 6 y T a z 7 D U j H A 6 q 3 i p o g k m E z y i f U M F j q j y s 3 n 0 G T o 1 y h C F s T R P a D R X f 2 9 k O F J q G g V m M o + o l r 1 c / M / r p z q 8 9 D M m k l R T Q R a H w p Q j H a O 8 B z R k k h L N p 4 Z g I p n J i s g Y S 0 y 0 a a t i S n C X v 7 x K O u d 1 1 6 m 7 t x e 1 5 l V R R x m O 4 Q T O w I U G N O E G W t A G A g / w D K / w Z j 1 Z L 9 a 7 9 b E Y L V n F z h H 8 g f X 5 A + v P k 8 Y = < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" 0 e R Q J Z k D x 3 q F I c W T B / u K C W b V p O o = \" > A A A B + n i c b V D L S s N A F L 2 p r 1 p f q S 7 d D B b B V U l E q M u i G 5 c V 7 A O a U C b T S T t 0 M g k z E 7 X E f o o b F 4 q 4 9 U v c + T d O 2 i y 0 9 c D A 4 Z x 7 u W d O k H C m t O N 8 W 6 W 1 9 Y 3 N r f J 2 Z W d 3 b / / A r h 5 2 V J x K Q t s k 5 r H s B V h R z g R t a 6 Y 5 7 S W S 4 i j g t B t M r n O / e 0 + l Y r G 4 0 9 O E + h E e C R Y y g r W R B n b 1 E X l M I C / C e k w w z 3 q z g V 1 z 6 s 4 c a J W 4 B a l B g d b A / v K G M U k j K j T h W K m + 6 y T a z 7 D U j H A 6 q 3 i p o g k m E z y i f U M F j q j y s 3 n 0 G T o 1 y h C F s T R P a D R X f 2 9 k O F J q G g V m M o + o l r 1 c / M / r p z q 8 9 D M m k l R T Q R a H w p Q j H a O 8 B z R k k h L N p 4 Z g I p n J i s g Y S 0 y 0 a a t i S n C X v 7 x K O u d 1 1 6 m 7 t x e 1 5 l V R R x m O 4 Q T O w I U G N O E G W t A G A g / w D K / w Z j 1 Z L 9 a 7 9 b E Y L V n F z h H 8 g f X 5 A + v P k 8 Y = < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" 0 e R Q J Z k D x 3 q F I c W T B / u K C W b V p O o = \" > A A A B + n i c b V D L S s N A F L 2 p r 1 p f q S 7 d D B b B V U l E q M u i G 5 c V 7 A O a U C b T S T t 0 M g k z E 7 X E f o o b F 4 q 4 9 U v c + T d O 2 i y 0 9 c D A 4 Z x 7 u W d O k H C m t O N 8 W 6 W 1 9 Y 3 N r f J 2 Z W d 3 b / / A r h 5 2 V J x K Q t s k 5 r H s B V h R z g R t a 6 Y 5 7 S W S 4 i j g t B t M r n O / e 0 + l Y r G 4 0 9 O E + h E e C R Y y g r W R B n b 1 E X l M I C / C e k w w z 3 q z g V 1 z 6 s 4 c a J W 4 B a l B g d b A / v K G M U k j K j T h W K m + 6 y T a z 7 D U j H A 6 q 3 i p o g k m E z y i f U M F j q j y s 3 n 0 G T o 1 y h C F s T R P a D R X f 2 9 k O F J q G g V m M o + o l r 1 c / M / r p z q 8 9 D M m k l R T Q R a H w p Q j H a O 8 B z R k k h L N p 4 Z g I p n J i s g Y S 0 y 0 a a t i S n C X v 7 x K O u d 1 1 6 m 7 t x e 1 5 l V R R x m O 4 Q T O w I U G N O E G W t A G A g / w D K / w Z j 1 Z L 9 a 7 9 b E Y L V n F z h H 8 g f X 5 A + v P k 8 Y = < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" 0 e R Q J Z k D x 3 q F I c W T B / u K C W b V p O o = \" > A A A B + n i c b V D L S s N A F L 2 p r 1 p f q S 7 d D B b B V U l E q M u i G 5 c V 7 A O a U C b T S T t 0 M g k z E 7 X E f o o b F 4 q 4 9 U v c + T d O 2 i y 0 9 c D A 4 Z x 7 u W d O k H C m t O N 8 W 6 W 1 9 Y 3 N r f J 2 Z W d 3 b / / A r h 5 2 V J x K Q t s k 5 r H s B V h R z g R t a 6 Y 5 7 S W S 4 i j g t B t M r n O / e 0 + l Y r G 4 0 9 O E + h E e C R Y y g r W R B n b 1 E X l M I C / C e k w w z 3 q z g V 1 z 6 s 4 c a J W 4 B a l B g d b A / v K G M U k j K j T h W K m + 6 y T a z 7 D U j H A 6 q 3 i p o g k m E z y i f U M F j q j y s 3 n 0 G T o 1 y h C F s T R P a D R X f 2 9 k O F J q G g V m M o + o l r 1 c / M / r p z q 8 9 D M m k l R T Q R a H w p Q j H a O 8 B z R k k h L N p 4 Z g I p n J i s g Y S 0 y 0 a a t i S n C X v 7 x K O u d 1 1 6 m 7 t x e 1 5 l V R R x m O 4 Q T O w I U G N O E G W t A G A g / w D K / w Z j 1 Z L 9 a 7 9 b E Y L V n F z h H 8 g f X 5 A + v P k 8 Y = < / l a t e x i t >(+ g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 n 1 B p H s s H M 0 n Q j + h Q 8 p A z a q z U C B 8 b / X L F r b p z k F X i 5 a Q C O e r 9 8 l d v E L M 0 Q m m Y o F p 3 P T c x f k a V 4 U z g t N R L N S a U j e k Q u 5 Z K G q H 2 s / m p U 3 J m l Q E J Y 2 V L G j J X f 0 9 k N N J 6 E g W 2 M 6 J m p J e 9 m f i f 1 0 1 N e O 1 n X C a p Q c k W i 8 J U E B O T 2 d 9 k w B U y I y a W U K a 4 v Z W w E V W U G Z t O y Y b g L b + 8 S l o X V c + t e v e X l d p N H k c R T u A U z s G D K 6 j B H d S h C Q y G 8 A y v 8 O Y I 5 8 V 5 d z 4 W r Q U n n z m G P 3 A + f w A i R 4 2 v < / l+ g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 n 1 B p H s s H M 0 n Q j + h Q 8 p A z a q z U C B 8 b / X L F r b p z k F X i 5 a Q C O e r 9 8 l d v E L M 0 Q m m Y o F p 3 P T c x f k a V 4 U z g t N R L N S a U j e k Q u 5 Z K G q H 2 s / m p U 3 J m l Q E J Y 2 V L G j J X f 0 9 k N N J 6 E g W 2 M 6 J m p J e 9 m f i f 1 0 1 N e O 1 n X C a p Q c k W i 8 J U E B O T 2 d 9 k w B U y I y a W U K a 4 v Z W w E V W U G Z t O y Y b g L b + 8 S l o X V c + t e v e X l d p N H k c R T u A U z s G D K 6 j B H d S h C Q y G 8 A y v 8 O Y I 5 8 V 5 d z 4 W r Q U n n z m G P 3 A + f w A i R 4 2 v < / l+ g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 n 1 B p H s s H M 0 n Q j + h Q 8 p A z a q z U C B 8 b / X L F r b p z k F X i 5 a Q C O e r 9 8 l d v E L M 0 Q m m Y o F p 3 P T c x f k a V 4 U z g t N R L N S a U j e k Q u 5 Z K G q H 2 s / m p U 3 J m l Q E J Y 2 V L G j J X f 0 9 k N N J 6 E g W 2 M 6 J m p J e 9 m f i f 1 0 1 N e O 1 n X C a p Q c k W i 8 J U E B O T 2 d 9 k w B U y I y a W U K a 4 v Z W w E V W U G Z t O+ g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 n 1 B p H s s H M 0 n Q j + h Q 8 p A z a q z U C B 8 b / X L F r b p z k F X i 5 a Q C O e r 9 8 l d v E L M 0 Q m m Y o F p 3 P T c x f k a V 4 U z g t N R L N S a U j e k Q u 5 Z K G q H 2 s / m p U 3 J m l Q E J Y 2 V L G j J X f 0 9 k N N J 6 E g W 2 M 6 J m p J e 9 m f i f 1 0 1 N e O 1 n X C a p Q c k W i 8 J U E B O T 2 d 9 k w B U y I y a W U K a 4 v Z W w E V W U G Z t O+ g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 H 1 F p H s t 7 M 0 n Q j + h Q 8 p A z a q z U e O q X K 2 7 V n Y O s E i 8 n F c h R 7 5 e / e o O Y p R F K w w T V u u u 5 i f E z q g x n A q e l X q o x o W x M h 9 i 1 V N I I t Z / N D 5 2 S M 6 s M S B g r W 9 K Q u f p 7 I q O R 1 p M o s J 0 R N S O 9 7 M 3 E / 7 x u a s J r P + M y S Q 1 K t l g U p o K Y m M y + J g O u k B k x s Y Q y x e 2 t h I 2 o o s z Y b E o 2 B G / 5 5 V X S u q h 6 b t V r X F Z q N 3 k c R T i B U z g H D 6 6 g B n d Q h y Y w Q H i G V 3 h z+ g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 H 1 F p H s t 7 M 0 n Q j + h Q 8 p A z a q z U e O q X K 2 7 V n Y O s E i 8 n F c h R 7 5 e / e o O Y p R F K w w T V u u u 5 i f E z q g x n A q e l X q o x o W x M h 9 i 1 V N I I t Z / N D 5 2 S M 6 s M S B g r W 9 K Q u f p 7 I q O R 1 p M o s J 0 R N S O 9 7 M 3 E / 7 x u a s J r P + M y S Q 1 K t l g U p o K Y m M y + J g O u k B k x s Y Q y x e 2 t h I 2 o o s z Y b E o 2 B G / 5 5 V X S u q h 6 b t V r X F Z q N 3 k c R T i B U z g H D 6 6 g B n d Q h y Y w Q H i G V 3 h z+ g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 H 1 F p H s t 7 M 0 n Q j + h Q 8 p A z a q z U e O q X K 2 7 V n Y O s E i 8 n F c h R 7 5 e / e o O Y p R F K w w T V u u u 5 i f E z q g x n A q e l X q o x o W x M h 9 i 1 V N I I t Z / N D 5 2 S M 6 s M S B g r W 9 K Q u f p 7 I q O R 1 p M o s J 0 R N S O 9 7 M 3 E / 7 x u a s J r P + M y S Q 1 K t l g U p o K Y m M y + J g O u k B k x s Y Q y x e 2 t h I 2 o o s z Y b E o 2 B G / 5 5 V X S u q h 6 b t V r X F Z q N 3 k c R T i B U z g H D 6 6 g B n d Q h y Y w Q H i G V 3 h z+ g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 H 1 F p H s t 7 M 0 n Q j + h Q 8 p A z a q z U e O q X K 2 7 V n Y O s E i 8 n F c h R 7 5 e / e o O Y p R F K w w T V u u u 5 i f E z q g x n A q e l X q o x o W x M h 9 i 1 V N I I t Z / N D 5 2 S M 6 s M S B g r W 9 K Q u f p 7 I q O R 1 p M o s J 0 R N S O 9 7 M 3 E / 7 x u a s J r P + M y S Q 1 K t l g U p o K Y m M y + J g O u k B k x s Y Q y x e 2 t h I 2 o o s z Y b E o 2 B G / 5 5 V X S u q h 6 b t V r X F Z q N 3 k c R T i B U z g H D 6 6 g B n d Q h y Y w Q H i G V 3 h z+ g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 H 1 F p H s t 7 M 0 n Q j + h Q 8 p A z a q z U e O q X K 2 7 V n Y O s E i 8 n F c h R 7 5 e / e o O Y p R F K w w T V u u u 5 i f E z q g x n A q e l X q o x o W x M h 9 i 1 V N I I t Z / N D 5 2 S M 6 s M S B g r W 9 K Q u f p 7 I q O R 1 p M o s J 0 R N S O 9 7 M 3 E / 7 x u a s J r P + M y S Q 1 K t l g U p o K Y m M y + J g O u k B k x s Y Q y x e 2 t h I 2 o o s z Y b E o 2 B G / 5 5 V X S u q h 6 b t V r X F Z q N 3 k c R T i B U z g H D 6 6 g B n d Q h y Y w Q H i G V 3 h z+ g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 H 1 F p H s t 7 M 0 n Q j + h Q 8 p A z a q z U e O q X K 2 7 V n Y O s E i 8 n F c h R 7 5 e / e o O Y p R F K w w T V u u u 5 i f E z q g x n A q e l X q o x o W x M h 9 i 1 V N I I t Z / N D 5 2 S M 6 s M S B g r W 9 K Q u f p 7 I q O R 1 p M o s J 0 R N S O 9 7 M 3 E / 7 x u a s J r P + M y S Q 1 K t l g U p o K Y m M y + J g O u k B k x s Y Q y x e 2 t h I 2 o o s z Y b E o 2 B G / 5 5 V X S u q h 6 b t V r X F Z q N 3 k c R T i B U z g H D 6 6 g B n d Q h y Y w Q H i G V 3 h z+ g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 H 1 F p H s t 7 M 0 n Q j + h Q 8 p A z a q z U e O q X K 2 7 V n Y O s E i 8 n F c h R 7 5 e / e o O Y p R F K w w T V u u u 5 i f E z q g x n A q e l X q o x o W x M h 9 i 1 V N I I t Z / N D 5 2 S M 6 s M S B g r W 9 K Q u f p 7 I q O R 1 p M o s J 0 R N S O 9 7 M 3 E / 7 x u a s J r P + M y S Q 1 K t l g U p o K Y m M y + J g O u k B k x s Y Q y x e 2 t h I 2 o o s z Y b E o 2 B G / 5 5 V X S u q h 6 b t V r X F Z q N 3 k c R T i B U z g H D 6 6 g B n d Q h y Y w Q H i G V 3 h z+ g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 H 1 F p H s t 7 M 0 n Q j + h Q 8 p A z a q z U e O q X K 2 7 V n Y O s E i 8 n F c h R 7 5 e / e o O Y p R F K w w T V u u u 5 i f E z q g x n A q e l X q o x o W x M h 9 i 1 V N I I t Z / N D 5 2 S M 6 s M S B g r W 9 K Q u f p 7 I q O R 1 p M o s J 0 R N S O 9 7 M 3 E / 7 x u a s J r P + M y S Q 1 K t l g U p o K Y m M y + J g O u k B k x s Y Q y x e 2 t h I 2 o o s z Y b E o 2 B G / 5 5 V X S u q h 6 b t V r X F Z q N 3 k c R T i B U z g H D 6 6 g B n d Q h y Y w Q H i G V 3 h z+ g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 H 1 F p H s t 7 M 0 n Q j + h Q 8 p A z a q z U e O q X K 2 7 V n Y O s E i 8 n F c h R 7 5 e / e o O Y p R F K w w T V u u u 5 i f E z q g x n A q e l X q o x o W x M h 9 i 1 V N I I t Z / N D 5 2 S M 6 s M S B g r W 9 K Q u f p 7 I q O R 1 p M o s J 0 R N S O 9 7 M 3 E / 7 x u a s J r P + M y S Q 1 K t l g U p o K Y m M y + J g O u k B k x s Y Q y x e 2 t h I 2 o o s z Y b E o 2 B G / 5 5 V X S u q h 6 b t V r X F Z q N 3 k c R T i B U z g H D 6 6 g B n d Q h y Y w Q H i G V 3 h z\n1.A contrastive-based objective for transferring knowledge between deep networks.\n\n2. Applications to model compression, cross-modal transfer, and ensemble distillation.\n\n3. Benchmarking 12 recent distillation methods; CRD outperforms all other methods, e.g., 57% average relative improvement over the original KD (Hinton et al., 2015)  \u2020 , which, surprisingly, performs the second best.\n\n\nRELATED WORK\n\nThe seminal work of Bucilu\u01ce et al. (2006) and Hinton et al. (2015) introduced the idea of knowledge distillation between large, cumbersome models into smaller, faster models without losing too much generalization power.The general motivation was that at training time, the availability of computation allows \"slop\" in model size, and potentially faster learning.But computation and memory constraints at inference time necessitate the use of smaller models.Bucilu\u01ce et al. (2006) achieve this by matching output logits; Hinton et al. (2015) introduced the idea of temperature in the softmax outputs to better represent smaller probabilities in the output of a single sample.These smaller probabilities provide useful information about the learned representation of the teacher model; some tradeoff between large temperatures (which increase entropy) or small temperatures tend to provide the highest transfer of knowledge between student and teacher.The method in (Li et al., 2014) was also closely related to (Hinton et al., 2015).\n\nAttention transfer (Zagoruyko & Komodakis, 2016a) focuses on the features maps of the network as opposed to the output logits.Here the idea is to elicit similar response patterns in the teacher and student feature maps (called \"attention\").However, only feature maps with the same spatial \u2020 Average relative improvement = 1\nN N i=1 Acc i crd \u2212Acc i kd Acc i kd \u2212Acc i van\n, where Acc i crd , Acc i kd , and Acc i van represent the accuracies of CRD, KD, and vanilla training of the i-th student model, respectively.resolution can be combined in this approach, which is a significant limitation since it requires student and teacher networks with very similar architectures.This technique achieves state of the art results for distillation (as measured by the generalization of the student network).FitNets (Romero et al., 2014) also deal with intermediate representations by using regressions to guide the feature activations of the student network.Since Zagoruyko & Komodakis (2016a) do a weighted form of this regression, they tend to perform better.Other papers (Yim et al., 2017;Huang & Wang, 2017;Kim et al., 2018;Yim et al., 2017;Huang & Wang, 2017;Ahn et al., 2019;Koratana et al., 2019) have enforced various criteria based on representations.The contrastive objective we use in this paper is the same as that used in CMC (Tian et al., 2019).But we derive from a different perspective and give a rigorous proof that our objective is a lower bound on mutual information.Our objective is also related to the InfoNCE and NCE objectives introduced in (Oord et al., 2018;Gutmann & Hyv\u00e4rinen, 2010).Oord et al. ( 2018) use contrastive learning in the context of self-supervised representations learning.They show that their objective maximizes a lower bound on mutual information.A very related approach is used in (Hjelm et al., 2018).InfoNCE and NCE are closely related but distinct from adversarial learning (Goodfellow et al., 2014).In (Goodfellow, 2014), it is shown that the NCE objective of Gutmann & Hyv\u00e4rinen (2010) can lead to maximum likelihood learning, but not the adversarial objective.\n\n\nMETHOD\n\nThe key idea of contrastive learning is very general: learn a representation that is close in some metric space for \"positive\" pairs and push apart the representation between \"negative\" pairs.Fig. 1 gives a visual explanation for how we structure contrastive learning for the three tasks we consider: model compression, cross-modal transfer and ensemble distillation.\n\n\nCONTRASTIVE LOSS\n\nGiven two deep neural networks, a teacher f T and a student f S .Let x be the network input; we denote representations at the penultimate layer (before logits) as f T (x) and f S (x) respectively.Let x i represent a training sample, and x j another randomly chosen sample.We would like to push closer the representations f S (x i ) and f T (x i ) while pushing apart f S (x i ) and f T (x j ).For ease of notation, we define random variables S and T for the student and teacher's representations of the data respectively:\nx \u223c p data (x) data(1)S = f S (x) student's representation(2)T = f T (x) teacher's representation(3)\nIntuitively speaking, we will consider the joint distribution p(S, T ) and the product of marginal distributions p(S)p(T ), so that, by maximizing KL divergence between these distributions, we can maximize the mutual information between student and teacher representations.To setup an appropriate loss that can achieve this aim, let us define a distribution q with latent variable C which decides whether a tuple (f T (x i ), f S (x j )) was drawn from the joint (C = 1) or product of marginals (C = 0):\nq(T, S|C = 1) = p(T, S), q(T, S|C = 0) = p(T )p(S)(4)\nNow, suppose in our data, we are given 1 congruent pair (drawn from the joint distribution, i.e. the same input provided to T and S) for every N incongruent pairs (drawn from the product of marginals; independent randomly drawn inputs provided to T and S).Then the priors on the latent C are:\nq(C = 1) = 1 N + 1 , q(C = 0) = N N + 1(5)\nBy simple manipulation and Bayes' rule, the posterior for class C = 1 is given by: q(C = 1|T, S) = q(T, S|C = 1)q(C = 1) q(T, S|C = 0)q(C = 0) + q(x, y|C = 1)q(C = 1)\n\n= p(T, S) p(T, S) + N p(T )p(S)\n\nNext, we observe a connection to mutual information as follows:\nlog q(C = 1|T, S) = log p(T, S) p(T, S) + N p(T )p(S) = \u2212 log(1 + N p(T )p(S) p(T, S) ) \u2264 \u2212 log(N ) + log p(T, S) p(T )p(S)(8)\nThen taking expectation on both sides w.r.t.p(T, S) (equivalently w.r.t.q(T, S|C = 1)) and rearranging, gives us:\nI(T ; S) \u2265 log(N ) + E q(T,S|C=1) log q(C = 1|T, S) MI bound(9)\nwhere I(T ; S) is the mutual information between the distributions of the teacher and student embeddings.Thus maximizing E q(T,S|C=1) log q(C = 1|T, S) w.r.t. the parameters of the student network S increases a lower bound on mutual information.However, we do not know the true distribution q(C = 1|T, S); instead we estimate it by fitting a model h : {T , S} \u2192 [0, 1] to samples from the data distribution q(T, S|C = 1) and q(T, S|C = 0), where T and S represent the domains of the embeddings.We maximize the log likelihood of the data under this model (a binary classification problem):\nL critic (h) = E q(T,S|C=1) [log h(T, S)] + N E q(T,S|C=0) [log(1 \u2212 h(T, S))] (10) h * = arg max h L critic (h) optimal critic(11)\nWe term h the critic since we will be learning representations that optimize the critic's score.Assuming sufficiently expressive h, h * (T, S) = q(C = 1|T, S) (via Gibbs' inequality; see Sec. 6.2.1 for proof), so we can rewrite Eq. 9 in terms of h * :\nI(T ; S) \u2265 log(N ) + E q(T,S|C=1) [log h * (T, S)](12)\nTherefore, we see that the optimal critic is an estimator whose expectation lower-bounds mutual information.We wish to learn a student that maximizes the mutual information between its representation and the teacher's, suggesting the following optimization problem:\nf S * = arg max f S E q(T,S|C=1) [log h * (T, S)](13)\nAn apparent difficulty here is that the optimal critic h * depends on the current student.We can circumvent this difficulty by weakening the bound in (12) to:\nI(T ; S) \u2265 log(N ) + E q(T,S|C=1) [log h * (T, S)] + N E q(T,S|C=0) [log(1 \u2212 h * (T, S))] (14) = log(N ) + L critic (h * ) = log(N ) + max h L critic (h)(15)\u2265 log(N ) + L critic (h)(16)\nThe first line comes about by simply adding N E q(T,S|C=0) [log(1 \u2212 h * (T, S))] to the bound in (12).This term is strictly negative, so the inequality holds.The last line follows from the fact that L critic (h * ) upper-bounds L critic (h).Optimizing (15) w.r.t. the student we have:\nf S * = arg max f S max h L critic (h) our final learning problem (17) = arg max f S max h E q(T,S|C=1) [log h(T, S)] + N E q(T,S|C=0) [log(1 \u2212 h(T, S))](18)\nwhich demonstrates that we may jointly optimize f S at the same time as we learn h.We note that due to (16), f S * = arg max f S L critic (h), for any h, also is a representation that optimizes a lower-bound (a weaker one) on mutual information, so our formulation does not rely on h being optimized perfectly.\n\nWe may choose to represent h with any family of functions that satisfy h : {T , S} \u2192 [0, 1].In practice, we use the following: h(T, S) = e g T (T ) g S (S)/\u03c4 e g T (T ) g S (S)/\u03c4 + N M (19) where M is the cardinality of the dataset and \u03c4 is a temperature that adjusts the concentration level.In practice, since the dimensionality of S and T may be different, g S and g T linearly transform them into the same dimension and further normalize them by L-2 norm before the inner product.The form of Eq. ( 18) is inspired by NCE (Gutmann & Hyv\u00e4rinen, 2010;Wu et al., 2018).Our formulation is similar to the InfoNCE loss (Oord et al., 2018) in that we maximize a lower bound on the mutual information.However we use a different objective and bound, which in our experiments we found to be more effective than InfoNCE.\n\nImplementation.Theoretically, larger N in Eq. 16 leads to tighter lower bound on MI.In practice, to avoid using very large batch size, we follow Wu et al. (2018) and implement a memory buffer that stores latent features of each data sample computed from previous batches.Therefore, during training we can efficiently retrieve a large number of negative samples from the memory buffer.\n\n\nKNOWLEDGE DISTILLATION OBJECTIVE\n\nThe knowledge distillation loss was proposed in Hinton et al. (2015).In addition to the regular cross-entropy loss between the student output y S and one-hot label y, it asks the student network output to be as similar as possible to the teacher output by minimizing the cross-entropy between their output probabilities.The complete objective is:\nL KD = (1 \u2212 \u03b1)H(y, y S ) + \u03b1\u03c1 2 H(\u03c3(z T /\u03c1), \u03c3(z S /\u03c1)) (20)\nwhere \u03c1 is the temperature, \u03b1 is a balancing weight, and \u03c3 is softmax function.H(\u03c3(z T /\u03c1), \u03c3(z S /\u03c1)) is further decomposed into KL(\u03c3(z T /\u03c1)|\u03c3(z S /\u03c1)) and a constant entropy H(\u03c3(z T /\u03c1)).\n\n\nCROSS-MODAL TRANSFER LOSS\n\nIn the cross-modal transfer task shown in Fig. 1(b), a teacher network is trained on a source modality X with large-scale labeled dataset.We then wish to transfer the knowledge to a student network, but adapt it to another dataset or modality Y.But the features of the teacher network are still valuable to help with learning of the student on another domain.In this transfer task, we use the contrastive loss Eq. 10 to match the features of the student and teacher.Additionally, we also consider other distillation objectives, such as KD discussed in previous section, Attention Transfer Zagoruyko & Komodakis (2016a) and FitNet Romero et al. (2014).Such transfer is conducted on a paired but unlabeled dataset D = {(x i , y i )|i = 1, ..., L, x i \u2208 X , y i \u2208 Y}.In this scenario, there is no true label y of such data for the original training task on the source modality, and therefore we ignore the H(y, y S ) term in all objectives that we test.Prior cross-modal work Aytar et al. (2016); Hoffman et al. (2016b;a) uses either L 2 regression or KL-divergence.\n\n\nENSEMBLE DISTILLATION LOSS\n\nIn the case of ensemble distillation shown in 1(c), we have M > 1 teacher networks, f Ti and one student network f S .We adopt the contrastive framework by defining multiple pair-wise contrastive losses between features of each teacher network f Ti and the student network f S .These losses are summed together to give the final loss (to be minimized):  Importantly, some methods that require very similar student and teacher architectures perform quite poorly.E.g.FSP (Yim et al., 2017) cannot even be applied; AT (Ba & Caruana, 2014) and FitNet (Zagoruyko & Komodakis, 2016a) perform very poorly etc.We denote by * methods where we used our reimplementation based on the paper; for all other methods we used author-provided or author-verified code.Average over 3 runs.\nL CRD\u2212EN = H(y, y S ) \u2212 \u03b2 i L critic (T i , S)(21\n\nMODEL COMPRESSION\n\nSetup We experiment on CIFAR-100 and ImageNet with student-teacher combinations of various capacity, such as ResNet (He et al., 2016) or Wide ResNet (WRN) (Zagoruyko & Komodakis, 2016b).loss, which we call CRD (Contrastive Representation Distillation), consistently outperforms all other distillation objectives, including the original KD (an average relative improvement of 57%).Surprisingly, we found that KD works pretty well and none of the other methods consistently outperforms KD on their own.Another observation is that, while switching the teacher student combinations from same to different architectural styles, methods that distill intermediate representations tend to perform worse than methods that distill from the last several layers.For example, the Attention Transfer (AT) and FitNet methods even underperform the vanilla student.In contrast, PKT, SP and CRD that operate on last several layers performs well.This might because, architectures of different styles have their own solution paths mapping from the input to the output, and enforcing the mimic of intermediate representations thus might conflict with such inductive bias.\n\n\nResults on CIFAR100\n\nCapturing inter-class correlations.In Fig. 2, we compute the difference between the correlation matrices of the teacher's and student's logits; for three different students: vanilla student without distillation, trained by AT, KD or CRD (our method).It is clear that the CRD objective captures the most correlation structure in the logit as shown by the smaller differences between teacher and student.This is reflected in reduced error rates.\n\nResults on ImageNet For a fair comparison with Zagoruyko & Komodakis (2016a) and Lan et al.\n\n(2018), we adopt the models from these papers, ResNet-34 as the teacher and ResNet-18 as the student.\n\nAs shown in Table 3, the gap of top-1 accuracy between the teacher and student is 3.56%.The AT method reduces this gap by 0.95%, while ours narrow it by 1.42%, a 50% relative improvement.\n\nResults on ImageNet validates the scalability of our CRD.\n\n\nTransferability of representations\n\nWe are interested in representations, and a primary goal of representation learning is to acquire general knowledge, that is, knowledge that transfers to tasks or datasets that were unseen during training.Therefore, we test if the representations we distill transfer well.A WRN-16-2 student either distills from a WRN-40-2 teacher, or is trained from scratch on CIFAR100.The student serves as a frozen representation extractor (the layer prior to the logit) for images from STL-10 or TinyImageNet (all images downsampled to 32x32).We then train a linear classifier to perform 10-way (for STL-  AT in Table 4.In this setting, all distillation methods except FitNet improve transferability of the learned representations on both STL-10 and TinyImageNet.While the teacher performs the best on the original CIFAR100 dataset, its representations transfer the worst to the other two datasets.This is perhaps the teacher's representations are biased towards the original task.Surprisingly, the student with CRD+KD distillation not only matches its teacher on CIFAR100 (see Table 4), but also transfers much better than the teacher, e.g., 3.6% improvement (STL-10) and 4.1% on TinyImageNet.\n\n\nCROSS-MODAL TRANSFER\n\nWe consider a practical setting where modality X has large amount of labeled data while modality Y does not.Transfering knowledge from X to Y is a common challenge.For example, while large-scale RGB datasets are easily accessible, other modalities such as depth images are much harder to label at scale but have wide applications.We demonstrate the potential of CRD for cross-modal transfer in two scenarios: (a) transfer from luminance to chrominance; (b) transfer from RGB to depth images.\n\nTransferring from Luminance to Chrominace.We work on Lab color space, where L represents Luminance and ab Chrominance.We first train an L network on TinyImageNet with supervision.\n\nThen we transfer knowledge from this L network to ab network on the unlabeled set of STL-10 with different objectives, including FitNet, KD, KD+AT and CRD.For convenience, we use the same architecture for student and teacher (they can also be different).Finally, we evaluate the knowlege of ab network by two means: (1) linear probing: we freeze the ab network and train a linear classifier on top of features from different layers to perform 10-way classification on STL-10 ab images.This is a common practice (Alain & Bengio, 2016;Zhang et al., 2017) to evaluate the quality of network representations; (b) fully finetuning: we fully finetune the ab network to obtain the best accuracy.We also use as a baseline the ab network that is randomly initialized rather than distilled.Architectures investigated include AlexNet, ResNet-18 and ResNet-50.The results shown in Figure 3 show that CRD is more efficient for transferring inter-modal knowledge than other methods.Besides, we also note KD+AT does not improve upon KD, possibly because attention of luminance and chrominance are different and harder to transfer.\n\n\nHYPER-PARAMETERS AND COMPUTATION OVERHEAD\n\nThere are two main hyper-parameters in our contrastive objectives: (1) the number of negative samples N in Eq. 18, and ( 2) temperature \u03c4 which modulates the softmax probability.We adopt WRN-40-2 as teacher and WRN-16-2 as student for parameter analysis.Experiments are conducted on CIFAR100 and the results are shown in Figure 5.The memory bank for storing all 128-d features of ImageNet only costs around 600MB memory, and therefore we store it on GPU memory.\n\n\nNumber of negatives\n\n\nCONCLUSION\n\nWe have developed a novel technique for neural network distillation, using the concept of contrastive objectives, which are usually used for representation learning.We experimented with our objective on a number of applications such as model compression, cross-modal transfer and ensemble distillation, outperforming other distillation objectives by significant margins in all these tasks.Our contrastive objective is the only distillation objective that consistently outperforms knowledge distillation across a wide variety of knowledge transfer tasks.Prior objectives only surpass KD when combined with KD.Contrastive learning is a simple and effective objective with practical benefits.\n\nBy Gibbs' inequality, the max likelihood fit is h (C = c, S = s, T = t) = q(C = c|S = s, T = t), which also implies that h(S = s, T = t) = q(C = 1|S = s, T = t).\n\nWe now demonstrate that our objective in Eq. ( 10) is proportional to a summation over terms Eq. ( 22) for all s \u2208 S and t \u2208 T .\n\nNotice that ( 26) is proportional to Eq. ( 10) from the main paper.For sufficiently expressive h, then, each term inside the expectation in Eq. ( 23) can be maximized, resulting in h * (T = t, S = s) = q(C = 1|T = t, S = t) for all s and t.\n\n\nNETWORK ARCHITECTURES\n\nWide Residual Network (WRN) (Zagoruyko & Komodakis, 2016b).WRN-d-w represnets wide resnet with depth d and width factor w.\n\nresnet (He et al., 2016).We use resnet-d to represent cifar-style resnet with 3 groups of basic blocks, each with 16, 32, and 64 channels respectively.In our experiments, resnet8 x4 and resnet32 x4 indicate a 4 times wider network (namely, with 64, 128, and 256 channels for each of the block)\n\nResNet (He et al., 2016).ResNet-d represents ImageNet-style ResNet with Bottleneck blocks and more channels.\n\nMobileNetV2 Sandler et al. (2018).In our experiments, we use a width multiplier of 0.5.\n\nvgg (Simonyan & Zisserman, 2014).the vgg net used in our experiments are adapted from its original ImageNet counterpart.\n\nShuffleNetV1 (Zhang et al., 2018a), ShuffleNetV2 (Tan et al., 2019).ShuffleNets are proposed for efficient training and we adapt them to input of size 32x32.\n\n\nIMPLEMENTATION DETAILS\n\nAll methods evaluated in our experiments use SGD.\n\nFor CIFAR-100, we initialize the learning rate as 0.05, and decay it by 0.1 every 30 epochs after the first 150 epochs until the last 240 epoch.For MobileNetV2, ShuffleNetV1 and ShuffleNetV2, we use a learning rate of 0.01 as this learning rate is optimal for these models in a grid search, while 0.05 is optimal for other models.\n\nFor ImageNet, we follow the standard PyTorch practice but train for 10 more epochs.Batch size is 64 for CIFAR-100 or 256 for ImageNet.\n\nThe student is trained by a combination of cross-entropy classification objective and a knowledge distillation objective, shown as follows:\nL = L cross\u2212entropy + \u03b2L distill(27)\nFor the weight balance factor \u03b2, we directly use the optimal value from the original paper if it is specified, or do a grid search with teacher WRN-40-2 and student WRN-16-2.This results in the following list of \u03b2 used for different objectives:\n\nTable 7 shows the effect of combining various objectives with KD.Most methods is able to slightly outperform KD after this combination.We also the check the compatibility of our distillation objective with KD and PKT.The combination of CRD and KD/PKT further improves over single CRD objective.\n\n\nADDITIONAL RESULTS ON TRANSFERABILITY OF REPRESENTATIONS\n\nIn addtion to Table 4 shown in the main text, we also evaluate the transferabilit of the representations of various other distillation methods and summarize the results in Table 8.In general, CRD achieves the best transferring accuracy in 7 out of 10 settings.\n\n\nDEEP MUTUAL LEARNING SETTING\n\nIn (Zhang et al., 2018b), a Deep Mutual Learning setting was proposed where the teacher and student networks are trained simultaneously rather than sequentially.The benefit is that not only the student networks but also the teacher models will be improved.Here we investigate the possibility of incorporating different distillation objectives into this training framework.The results are summarizied in Table 9.We observe that in general logit based distillation methods is better than non-logit based distillation methods in this setting, i.e., KD performs the best.We conjecture that during the mutual training phase, KD performs like an advanced label smoothing regularization and does not require the logit to be very accurate.But the feature-based distillation methods are hard to learn knowledge from the teacher model when it is handicapped.On the other hand, we notice that the combination of KD and CRD leads to better performance on the student side, as shown in the last row of Table 9.  6.9 STANDARD DEVIATION FOR RESULTS ON CIFAR-100 BENCHMARK\n\nThe standard deviation over multiple runs on CIFAR-100 benchmark is provided in Table 10 for student and teacher models of the same architectural type, and in Table 11 for student and teacher models of different architectural types.CRD+KD 72.2 35.5 70.5 34.1 74.6 39.3 70.7 34.6 73.1 39.9 Table 8: We measure the transferability of the student network, by evaluating a linear classifier on top of its frozen representations on STL10 (abbreviated as \"STL\") and TinyImageNet (abbreviated as \"TI\").The best accuracy is bolded and the second best is underlined.\n\n\n\nt e x i t s h a 1 _ b a s e 6 4 = \" o U 1 K E 6 i l 3 e 3 6 L u b h + t R i f 1 X 0 p 4 Q = \" > A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 e K / Y I 2 l s 1 2 0 y 7 d b M L u R C i h P 8 G L B 0 W 8 + o u 8 + W / c t j l o 6 4 O B x 3 s z z M w L E i k M u u 6 3 U 1 h b 3 9 j c K m 6 X d n b 3 9 g / K h 0 c t E 6 e a 8 S a L Z a w 7 A T V c C s W b K F D y T q I 5 j Q L J 2 8 H 4 d u a 3 n 7 g 2 I l Y N n C T c j + h Q i V A w i l Z 6 C B 8 b / X L F r b p z k F X i 5 a Q C O e r 9 8 l d v E L M 0 4 g q Z p M Z 0 P T d B P 6 M a B Z N 8 W u q l h i e U j e m Q d y 1V N O L G z + a n T s m Z V Q Y k j L U t h W S u / p 7 I a G T M J A p s Z 0 R x Z J a 9 m f i f 1 0 0 x v P Y z o Z I U u W K L R W E q C c Z k 9 j c Z C M 0 Z y o k l l G l h b y V s R D V l a N M p 2 R C 8 5 Z d X S e u i 6 r l V 7 / 6 y U r v J 4 y j C C Z z C O X h w B T W 4 g z o 0 g c E Q n u E V 3 h z p v D j vz s e i t e D k M 8 f w B 8 7 n D y P L j b A = < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" o U 1 K E 6 i l 3 e 3 6 L u b h + t R i f 1 X 0 p 4 Q = \" > A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 e K / Y I 2 l s 1 2 0 y 7 d b M L u R C i h P 8 G L B 0 W 8 + o u 8 + W / c t j l o 6 4 O B x 3 s z z M w L E i k M u u 6 3 U 1 h b 3 9 j c K m 6 X d n b 3 9 g / K h 0 c t E 6 e a 8 S a L Z a w 7 A T V c C s W b K F D y T q I 5 j Q L J 2 8 H 4 d u a 3 n 7 g 2 I l Y N n C T c j + h Q i V A w i l Z 6 C B 8 b / X L F r b p z k F X i 5 a Q C O e r 9 8 l d v E L M 0 4 g q Z p M Z 0 P T d B P 6 M a B Z N 8 W u q l h i e U j e m Q d y 1V N O L G z + a n T s m Z V Q Y k j L U t h W S u / p 7 I a G T M J A p s Z 0 R x Z J a 9 m f i f 1 0 0 x v P Y z o Z I U u W K L R W E q C c Z k 9 j c Z C M 0 Z y o k l l G l h b y V s R D V l a N M p 2 R C 8 5 Z d X S e u i 6 r l V 7 / 6 y U r v J 4 y j C C Z z C O X h w B T W 4 g z o 0 g c E Q n u E V 3 h z p v D j v z s e i t e D k M 8 f w B 8 7 n D y P L j b A = < / l a t e x i t > < l a t e x i ts h a 1 _ b a s e 6 4 = \" o U 1 K E 6 i l 3 e 3 6 L ub h + t R i f 1 X 0 p 4 Q = \" > A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 e K / YI 2 l s 1 2 0 y 7 d b M L u R C i h P 8 G L B 0 W 8 + o u 8 + W / c t j l o 6 4 O B x 3 s z z M w L E i k M u u 6 3 U 1 h b 3 9 j c K m 6 X d n b 3 9 g / K h 0 c t E 6 e a 8 S a L Z a w 7 AT V c C s W b K F D y T q I 5 j Q L J2 8 H 4 d u a 3 n 7 g 2I l Y N n C T c j + h Q i V A w i l Z 6 C B 8 b / X L F r b p z k F X i 5 a Q C O e r 9 8 l d v E L M 0 4 g q Z p M Z 0 P T d B P 6 M a B Z N 8 W u q l h i e U j e m Q d y 1 V N O L G z + a n T s m Z V Q Y k j L U t h W S u / p 7 I a G T M J A p s Z 0 R x Z J a 9 m f i f 1 0 0 x v P Y z o Z I U u W K L R W E q C c Z k 9 j c Z C M 0 Z y o k l l G l h b y V s R D V l a N M p 2 R C 8 5 Z d X S e u i 6 r l V 7 / 6 y U r v J 4 y j C C Z z C O X h w B T W 4 g z o 0 g c E Q n u E V 3 h z p v D j vz s e i t e D k M 8 f w B 8 7 n D y P L j b A = < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" o U 1 K E 6 i l 3 e 3 6 L u b h + t R i f 1 X 0 p 4 Q = \" > A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 e K / Y I 2 l s 1 2 0 y 7 d b M L u R C i h P 8 G L B 0 W 8 + o u 8 + W / c t j l o 6 4 O B x 3 s z z M w L E i k M u u 6 3 U 1 h b 3 9 j c K m 6 X d n b 3 9 g / K h 0 c t E 6 e a 8 S a L Z a w 7 A T V c C s W b K F D y T q I 5 j Q L J 2 8 H 4 d u a 3 n 7 g 2 I l Y N n C T c j + h Q i V A w i l Z 6 C B 8 b / X L F r b p z k F X i 5 a Q C O e r 9 8 l d v E L M 0 4 g q Z p M Z 0 P T d B P 6 M a B Z N 8 W u q l h i e U j e m Q d y 1 V N O L G z + a n T s m Z V Q Y k j L U t h W S u / p 7 I a G T M J A p s Z 0 R x Z J a 9 m f i f 1 0 0 x v P Y z o Z I U u W K L R W E q C c Z k 9 j c Z C M 0 Z y o k l l G l h b y V s R D V l a N M p 2 R C 8 5 Z d X S e u i 6 r l V 7 / 6 y U r v J 4 y j C C Z z C O X h w B T W 4 g z o 0 g c E Q n u E V 3 h z p v D j v z s e i t e D k M 8 f w B 8 7 n D y P L j b A = < / l a t e x i t > f S < l a t e x i t s h a 1 _ b a s e 6 4 = \" K 7 f T 4 8 m 4 n 6 W k K P e w H q 0 D 7 I e o B L M = \" > A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 d K 7 Q e 0 s W y 2 k 3 b p Z h N 2 N 0 I J / Q l e P C j i 1 V / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b /+ g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 n 1 B p H s s H M 0 n Q j + h Q 8 p A z a q z U C B 8 b / X L F r b p z k F X i 5 a Q C O e r 9 8 l d v E L M 0 Q m m Y o F p 3 P T c x f k a V 4 U z g t N R L N S a U j e k Q u 5 Z K G q H 2 s / m p U 3 J m l Q E J Y 2 V L G j J X f 0 9 k N N J 6 E g W 2 M 6 J m p J e 9 m f i f 1 0 1 N e O 1 n X C a p Q c k W i 8 J U E B O T 2 d 9 k w B U y I y a W U K a 4 v Z W w E V W U G Z t O y Y b g L b + 8 S l o X V c + t e v e X l d p N H k c R T u A U z s G D K 6 j B H d S h C Q y G 8 A y v 8 O Y I 5 8 V 5 d z 4 W r Q U n n z m G P 3 A + f w A i R 4 2 v< / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" K 7 f T 4 8 m 4 n 6 W k K P e w H q 0 D 7I e o B L M = \" > A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 d K 7 Q e 0 s W y 2 k 3 b p Z h N 2 N 0 I J / Q l e P C j i 1 V / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b / + g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 n 1 B p H s s H M 0 n Q j + h Q 8 p A z a q z U C B 8 b / X L F r b p z k F X i 5 a Q C O e r 9 8 l d v E L M 0 Q m m Y o F p 3 P T c x f k a V 4 U z g t N R L N S a U j e k Q u 5 Z K G q H 2 s / m p U 3 J m l Q E J Y 2 V L G j J X f 0 9 k N N J 6 E g W 2 M6 J m p J e 9 m f i f 1 0 1 N e O 1 n X C a p Q c k W i 8 J U E B O T 2 d 9 k w B U y I y a W U K a 4 v Z W w E V W U G Z t O y Y b g L b + 8 S l o X V c + t e v e X l d p N H k c R T u A U z s G D K 6 j B H d S h C Q y G 8 A y v 8 O Y I 5 8 V 5 d z 4 W r Q U n n z m G P 3 A + f w A i R 4 2 v < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" K 7 f T 4 8 m 4 n 6 W k K P e w H q 0 D 7 I e o B L M = \" > A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 d K 7 Q e 0 s W y 2 k 3 b p Z h N 2 N 0 I J / Q l e P C j i 1 V / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b /+ g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 n 1 B p H s s H M 0 n Q j + h Q 8 p A z a q z U C B 8 b / X L F r b p z k F X i 5 a Q C O e r 9 8 l d v E L M 0 Q m m Y o F p 3 P T c x f k a V 4 U z g t N R L N S a U j e k Q u 5 Z K G q H 2 s / m p U 3 J m l Q E J Y 2 V L G j J X f 0 9 k N N J 6 E g W 2 M 6 J m p J e 9 m f i f 1 0 1 N e O 1 n X C a p Q c k W i 8 J U E B O T 2 d 9 k w B U y I y a W U K a 4 v Z W w E V W U G Z t Oy Y b g L b + 8 S l o X V c + t e v e X l d p N H k c R T u A U z s G D K 6 j B H d S h C Q y G 8 A y v 8 O Y I 5 8 V 5 d z 4 W r Q U n n z m G P 3 A + f w A i R 4 2 v < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" K 7 f T 4 8 m 4 n 6 W k K P e w H q 0 D 7 I e o B L M = \" > A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 d K 7 Q e 0 s W y 2 k 3 b p Z h N 2 N 0 I J / Q l e P C j i 1 V / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b / + g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 n 1 B p H s s H M 0\n\n\n\n\nn H f n Y 9 6 6 4 m Q z R / A H z u c P R P + P c w = = < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" k b q D u h Z 8 p I o x S p a y 2 w N L x G g U L W s = \" > A A A B 7 3 i c b V D L S g N B E O z 1 G e M r 6 t H L Y B D i J e y K o M e g F 4 8 R 8 o J k D b O T 2 W T I 7 O w 6 0 y u G k J / w 4 k E R r / 6 O N / / G S b I H T S x o K K q 6 6 e 4 K E i k M u u 6 3 s 7 K 6 t r 6 x m d v K b + / s 7 u 0 X D g 4 b J k 4 1 4 3\n\n\n\n\nn H f n Y 9 6 6 4 m Q z R / A H z u c P R P + P c w = = < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" k b q D u h Z 8 p I o x S p a y 2 w N L x G g U L W s = \" > A A A B 7 3 i c b V D L S g N B E O z 1 G e M r 6 t H L Y B D i J e y K o M e g F 4 8 R 8 o J k D b O T 2 W T I 7 O w 6 0 y u G k J / w 4 k E R r / 6 O N / / G S b I H T S x o K K q 6 6 e 4 K E i k M u u 6 3 s 7 K 6 t r 6 x m d v K b + / s 7 u 0 X D g 4 b J k 4 1 4 3\n\n\n\n\nn H f n Y 9 6 6 4 m Q z R / A H z u c P R P + P c w = = < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" k b q D u h Z 8 p I o x S p a y 2 w N L x G g U L W s = \" > A A A B 7 3 i c b V D L S g N B E O z 1 G e M r 6 t H L Y B D i J e y K o M e g F 4 8 R 8 o J k D b O T 2 W T I 7 O w 6 0 y u G k J / w 4 k E R r / 6 O N / / G S b I H T S x o K K q 6 6 e 4 K E i k M u u 6 3 s 7 K 6 t r 6 x m d v K b + / s 7 u 0 X D g 4 b J k 4 1 4 3\n\n\n\n\nU 2 A z 0 P P e R P z P a y c m P P d T J u P E U E l m i 8 K E I x O h y f O o x x Q l h o 8 s w U Q x e y s i A 6 w w M T a i g g 3 B m 3 9 5 k T R O K p 5 b 8 a 5 P S 9 W L L I 4 8 H M A h l M G D M 6 j C F d S g D g Q 4 P M M r v D k P z o v z 7 n z M W n N O N r M P f + B 8 / g B E + 4 9 z < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" g 3\n\n\n\n\n0 X 5 A u 5 Z s m m 1 j k + y a Z M W y 9 E 9 4 8 a C I V / + O N / + N a b s H b X 0 w 8 H h v h p l 5 Q c y Z N q 7 7 7 e S W l l d W 1 / L r h Y 3 N r e 2 d 4 u 5 e Q 0 e J I r R O I h 6 p V o A 1 5 U z S u m G G 0 1 a s K B Y B p 8 1 g e D n x m 4 9 U a R b J\n\n\n\n\nU 2 A z 0 P P e R P z P a y c m P P d T J u P E U E l m i 8 K E I x O h y f O o x x Q l h o 8 s w U Q x e y s i A 6 w w M T a i g g 3 B m 3 9 5 k T R O K p 5 b 8 a 5 P S 9 W L L I 4 8 H M A h l M G D M 6 j C F d S g D g Q 4 P M M r v D k P z o v z 7 n z M W n N O N r M P f + B 8 / g B E + 4 9 z < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" g 3\n\n\n\n\n0 X 5 A u 5 Z s m m 1 j k + y a Z M W y 9 E 9 4 8 a C I V / + O N / + N a b s H b X 0 w 8 H h v h p l 5 Q c y Z N q 7 7 7 e S W l l d W 1 / L r h Y 3 N r e 2 d 4 u 5 e Q 0 e J I r R O I h 6 p V o A 1 5 U z S u m G G 0 1 a s K B Y B p 8 1 g e D n x m 4 9 U a R b J\n\n\n\n\nU 2 A z 0 P P e R P z P a y c m P P d T J u P E U E l m i 8 K E I x O h y f O o x x Q l h o 8 s w U Q x e y s i A 6 w w M T a i g g 3 B m 3 9 5 k T R O K p 5 b 8 a 5 P S 9 W L L I 4 8 H M A h l M G D M 6 j C F d S g D g Q 4 P M M r v D k P z o v z 7 n z M W n N O N r M P f + B 8 / g B E + 4 9 z < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" g 3\n\n\n\n\n0 X 5 A u 5 Z s m m 1 j k + y a Z M W y 9 E 9 4 8 a C I V / + O N / + N a b s H b X 0 w 8 H h v h p l 5 Q c y Z N q 7 7 7 e S W l l d W 1 / L r h Y 3 N r e 2 d 4 u 5 e Q 0 e J I r R O I h 6 p V o A 1 5 U z S u m G G 0 1 a s K B Y B p 8 1 g e D n x m 4 9 U a R b J\n\n\n\n\nU 2 A z 0 P P e R P z P a y c m P P d T J u P E U E l m i 8 K E I x O h y f O o x x Q l h o 8 s w U Q x e y s i A 6 w w M T a i g g 3 B m 3 9 5 k T R O K p 5 b 8 a 5 P S 9 W L L I 4 8 H M A h l M G D M 6 j C F d S g D g Q 4 P M M r v D k P z o v z 7 n z M W n N O N r M P f + B 8 / g B E + 4 9 z < / l a t e x i t > x < l a t e x i t s h a 1 _ b a s e 6 4 = \" f 2 y z i m w b R / D g j z p 6 t Z 3 6 0 f H R q\n\n\n\n\nH p w X 5 9 3 5 W L Q W n H z m G P 7 A + f w B 5 j m M / A = = < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" f 2 y z i m w b R / D g j z p 6 t Z 3 6 0 f H R q N I = \" > A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 c W 7 A e 0 o W y 2 k 3 b t Z h N 2 N 2 I J / Q V e P C j i 1 Z / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b /\n\n\n\n\nH p w X 5 9 3 5 W L Q W n H z m G P 7 A + f w B 5 j m M / A = = < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" f 2 y z i m w b R / D g j z p 6 t Z 3 6 0 f H R q N I = \" > A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 c W 7 A e 0 o W y 2 k 3 b t Z h N 2 N 2 I J / Q V e P C j i 1 Z / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b /\n\n\n\n\nz s e i t e D k M 8 f w B 8 7 n D y P L j b A = < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" o U 1 K E 6 i l 3 e 3 6 L u b\n\n\n\n\nz s e i t e D k M 8 f w B 8 7 n D y P L j b A = < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" o U 1 K E 6 i l 3 e 3 6 L u b\n\n\n\n\nz s e i t e D k M 8 f w B 8 7 n D y P L j b A = < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" o U 1 K E 6 i l 3 e 3 6 L u b\n\n\n\n\nz s e i t e D k M 8 f w B 8 7 n D y P L j b A = < / l a t e x i t > Teacher Student c f S < l a t e x i t s h a 1 _ b a s e 6 4 = \" K 7 f T 4 8 m 4 n 6 W k K P e w H q 0 D 7 I e o B L M\n\n\n\n\nK b 9 W S 9 W O / W x 3 x 0 x S p 3 D u E P r M 8 f 7 u i T y A = = < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" 9 a 6 0 r r 3 c Z w B P m j s k t 6 s 6 J u M /\n\n\n\n\nK b 9 W S 9 W O / W x 3 x 0 x S p 3 D u E P r M 8 f 7 u i T y A = = < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" 9 a 6 0 r r 3 c Z w B P m j s k t 6 s 6 J u M /\n\n\n\n\nK b 9 W S 9 W O / W x 3 x 0 x S p 3 D u E P r M 8 f 7 u i T y A = = < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" 9 a 6 0 r r 3 c Z w B P m j s k t 6 s 6 J u M /\n\n\n\n\na) Model compression (b) Cross-modal transfer f S < l a t e x i t s h a 1 _ b a s e 6 4 = \" K 7 f T 4 8 m 4 n 6 W k K P e w H q 0 D 7 I e o B L M = \" > A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 d K 7 Q e 0 s W y 2 k 3 b p Z h N 2 N 0 I J / Q l e P C j i 1 V / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b /\n\n\n\n\na t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" K 7 f T 4 8 m 4 n 6 W k K P e w H q 0 D 7 I e o B L M = \" > A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 d K 7 Q e 0 s W y 2 k 3 b p Z h N 2 N 0 I J / Q l e P C j i 1 V / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b /\n\n\n\n\na t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" K 7 f T 4 8 m 4 n 6 W k K P e w H q 0 D 7 I e o B L M = \" > A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 d K 7 Q e 0 s W y 2 k 3 b p Z h N 2 N 0 I J / Q l e P C j i 1 V / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b /\n\n\n\n\ny Y b g L b + 8 S l o X V c + t e v e X l d p N H k c R T u A U z s G D K 6 j B H d S h C Q y G 8 A y v 8 O Y I 5 8 V 5 d z 4 W r Q U n n z m G P 3 A + f w A i R 4 2 v < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" K 7 f T 4 8 m 4 n 6 W k K P e w H q 0 D 7 I e o B L M = \" > A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 d K 7 Q e 0 s W y 2 k 3 b p Z h N 2 N 0 I J / Q l e P C j i 1 V / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b /\n\n\n\n\ny Y b g L b + 8 S l o X V c + t e v e X l d p N H k c R T u A U z s G D K 6 j B H d S h C Q y G 8 A y v 8 O Y I 5 8 V 5 d z 4 W r Q U n n z m G P 3 A + f w A i R 4 2 v < / l a t e x i t > Teachers Student (c) Ensemble distillation x < l a t e x i t s h a 1 _ b a s e 6 4 = \" f 2 y z i m w b R / D g j z p 6 t Z 3 6 0 f H R q N I = \" > A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 c W 7 A e 0 o W y 2 k 3 b t Z h N 2 N 2 I J / Q V e P C j i 1 Z / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b /\n\n\n\n\nH p w X 5 9 3 5 W L Q W n H z m G P 7 A + f w B 5 j m M / A = = < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" f 2 y z i m w b R / D g j z p 6 t Z 3 6 0 f H R q N I = \" > A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 c W 7 A e 0 o W y 2 k 3 b t Z h N 2 N 2 I J / Q V e P C j i 1 Z / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b /\n\n\n\n\nH p w X 5 9 3 5 W L Q W n H z m G P 7 A + f w B 5 j m M / A = = < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" f 2 y z i m w b R / D g j z p 6 t Z 3 6 0 f H R q N I = \" > A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 c W 7 A e 0 o W y 2 k 3 b t Z h N 2 N 2 I J / Q V e P C j i 1 Z / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b /\n\n\n\n\nH p w X 5 9 3 5 W L Q W n H z m G P 7 A + f w B 5 j m M / A = = < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" f 2 y z i m w b R / D g j z p 6 t Z 3 6 0 f H R q N I = \" > A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 c W 7 A e 0 o W y 2 k 3 b t Z h N 2 N 2 I J / Q V e P C j i 1 Z / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b /\n\n\n\n\nH p w X 5 9 3 5 W L Q W n H z m G P 7 A + f w B 5 j m M / A = = < / l a t e x i t > f T1 < l a t e x i t s h a 1 _ b a s e 6 4 = \" E l B G V W R z + t j d O 0 M G g c l M l t 5 b g 4 k = \" > A A A B 7 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E q M e i F 4 8 V + g V t L J v t p l 2 6 2 Y T d i V B C f 4 Q X D 4 p 4 9 f d 4 8 9 + 4 b X P Q 1 g c D j / d m m J k X J F I Y d N 1 v p 7 C x u b W 9 U 9 w t 7 e 0 f H B 6 V j 0 / a J k 4 1 4 y 0 W y 1 h 3 A 2 q 4 F I q 3 U K D k 3 U R z G g W S d 4 L J 3 d z v P H F t R K y a O E 2 4 H 9 G R E q F g F K 3 U C R + z 5 s C b D c o V t + o u Q N a J l 5 M K 5 G g M y l / 9 Y c z S i C t k k h r T 8 9 w E / Y x q F E z y W a m f G p 5 Q N q E j 3 r N U 0 Y g b P 1 u c O y M X V h m S M N a 2 F J K F + n s i o 5 E x 0 y i w n R H F s V n 1 5 u J / X i / F 8 M b P h E p S 5 I o t F 4 W p J B i T + e 9 k K D R n K K e W U K a F v Z W w M d W U o U 2 o Z E P w V l 9 e J + 2 r q u d W v Y f r S v 0 2 j 6 M I Z 3 A O l + B B D e p w D w 1 o A Y M J P M M r v D m J 8 + K 8 O x / L 1 o K T z 5 z C H z i f P x C r j 2 A = < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" E l B G V W R z + t j d O 0 M G g c l M l t 5 b g 4 k = \" > A A A B 7 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E q M e i F 4 8 V + g V t L J v t p l 2 6 2 Y T d i V B C f 4 Q X D4 p 4 9 f d 4 8 9 + 4 bX P Q 1 g c D j / d m m J k X J F I Y d N 1 v p 7 C x u b W 9 U 9 w t 7 e 0 f H B 6 V j 0 / a J k 4 1 4 y 0 W y 1 h 3 A 2 q 4 F I q 3 U K D k 3 U R z G g W S d 4 L J 3 d z v P H F t R K y a O E 2 4 H 9 G R E q F g F K 3 U C R + z 5 s C b D c o V t + o u Q N a J l 5 M K 5 G g M y l / 9 Y c z S i C t k k h r T 8 9 w E / Y x q F E z y W a m f G p 5 Q N q E j 3 r N U 0 Y g b P 1 u c O y M X V h m S M N a 2 F J K F + n s i o 5 E x 0 y i w n R H F s V n 1 5 u J / X i / F 8 M b P h E p S 5 I o t F 4 W p J B i T + e 9 k K D R n K K e W U K a F v Z W w M d W U o U 2 o Z E P w V l 9 e J + 2 r q u d W v Y f r S v 0 2 j 6 M I Z 3 A O l + B B D e p w D w 1 o A Y M J P M M r v D m J 8 + K 8 O x / L 1 o K T z 5 z C H z i f P x C r j 2 A = < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" E l B G V W R z + t j d O 0 M G g c l M l t 5 b g 4 k = \" > A A A B 7 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E q M e i F 4 8 V + g V t L J v t p l 2 6 2 Y T d i V B C f 4 Q X D 4 p 4 9 f d 4 8 9 + 4 b X P Q 1 g c D j / d m m J k X J F I Y d N 1 v p 7 C x u b W 9 U 9 w t 7 e 0 f H B 6 V j 0 / a J k 4 1 4 y 0 W y 1 h 3 A 2 q 4 F I q 3 U K D k 3 U R z G g W S d 4 L J 3 d z v P H F t R K y a O E 2 4 H 9 G R E q F g F K 3 U C R + z 5 s C b D c o V t + o u Q N a J l 5 M K 5 G g M y l / 9 Y c z S i C t k k h r T 8 9 w E / Y x q F E z y W a m f G p 5 Q N q E j 3 r N U 0 Y g b P 1 u c O y M X V h m S M N a 2 F J K F + n s i o 5 E x 0 y i w n R H F s V n 1 5 u J / X i / F 8 M b P h E p S 5 I o t F 4 W p J B i T + e 9 k K D R n K K e W U K a F v Z W w M d W U o U 2 o Z E P w V l 9 e J + 2 r q u d W v Y f r S v0 2 j 6 M I Z 3 A O l + B B D e p w D w 1 o A Y M J P M M r v D m J 8 + K 8 O x / L 1 o K T z 5 z C H z i f P x C r j 2 A = < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" E l B G V W R z + t j d O 0 M G g c l M l t 5 b g 4 k = \" > A A A B 7 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E q M e i F 4 8 V + g V t L J v t p l 2 6 2 Y T d i V B C f 4 Q X D 4 p 4 9 f d 4 8 9 + 4 b X P Q 1 g c D j / d m m J k X J F I Y d N 1 v p 7 C x u b W 9 U 9 w t 7 e 0 f H B 6 V j 0 / a Jk 4 1 4 y 0 W y 1 h 3 A 2 q 4F I q 3 U K D k 3 U R z G g W S d 4 L J 3 d z v P H F t R K y a O E 2 4 H 9 G R E q F g F K 3 U C R + z 5 s C b D c o V t + o u Q N a J l 5 M K 5 G g M y l / 9 Y c z S i C t k k h r T 8 9 w E / Y x q F E z y W a m f G p 5 Q N q E j 3 r N U 0 Y g b P 1 u c O y M X V h m S M N a 2 F J K F + n s i o 5 E x 0 y i w n R H F s V n 1 5 u J / X i / F 8 M b P h E p S 5 I o t F 4 W p J B i T + e 9 k K D R n K K e W U K a F v Z W w M d W U o U 2 o Z E P w V l 9 e J + 2 r q u d W v Y f r S v 0 2 j 6 M I Z 3 A O l + B B D e p w D w 1 o A Y M J P M M r v D m J 8 + K 8 O x / L 1 o K T z 5 z C H z i f P x C r j 2 A = < / l a t e x i t > f T2 < l a t e x i t s h a 1 _ b a s e 6 4 = \" R c Q h e P E j J m W n z B M H Y o 1 W 3 G p y F A k = \" > A A A B 7 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m K o M e i F 4 8 V + g V t L J v t p l 2 6 2 Y T d i V B C f 4 Q X D4 p 4 9 f d 4 8 9 + 4 bX P Q 1 g c D j / d m m J k X J F I Y dN 1 v p 7 C x u b W 9 U 9 w t 7 e 0 f H B 6 V j 0 / a J k 4 1 4 y 0 W y 1 h 3 A 2 q 4F I q 3 U K D k 3 U R z G g W S d 4 L J 3 d z v P H F t R K y a O E 2 4 H 9 G R E q F g F K 3 U C R + z 5 q A 2 G 5 Q r b t V d g K w T L y c V y N E Y l L / 6 w 5 i l E V f I J D W m 5 7 k J + h n V K J j k s 1 I / N T y h b E J H v G e p o h E 3 f r Y 4 d 0 Y u r D I k Y a x t K S Q L 9 f d E R i N j p l F g O y O K Y 7 P q z c X / v F 6 K 4 Y 2 f C Z W k y B V b L g p T S T A m 8 9 / J U G j O U E 4 t o U w L e y t h Y 6 o p Q 5 t Q y Y b g r b 6 8 T t q 1 q u d W v Y e r S v 0 2 j 6 M I Z 3 A O l + D B N d T h H h r Q A g Y T e I Z X e H M S 5 8 V 5 d z 6 W r Q U n n z m F P 3 A + f w A S M I 9 h < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" R c Q h e P E j J m W n z B M H Y o 1 W 3 G p y F A k = \" > A A A B 7 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m K o M e i F 4 8 V + g V t L J v t p l 2 6 2 Y T d i V B C f 4 Q X D4 p 4 9 f d 4 8 9 + 4 bX P Q 1 g c D j / d m m J k X J F I Y dN 1 v p 7 C x u b W 9 U 9 w t 7 e 0 f H B 6 V j 0 / a J k 4 1 4 y 0 W y 1 h 3 A 2 q 4F I q 3 U K D k 3 U R z G g W S d 4 L J 3 d z v P H F t R K y a O E 2 4 H 9 G R E q F g F K 3 U C R + z 5 q A 2 G 5 Q r b t V d g K w T L y c V y N E Y l L / 6 w 5 i l E V f I J D W m 5 7 k J + h n V K J j k s 1 I / N T y h b E J H v G e p o h E 3 f r Y 4 d 0 Y u r D I k Y a x t K S Q L 9 f d E R i N j p l F g O y O K Y 7 P q z c X / v F 6 K 4 Y 2 f C Z W k y B V b L g p T S T A m 8 9 / J U G j O U E 4 t o U w L e y t h Y 6 o p Q 5 t Q y Y b g r b 6 8 T t q 1 q u d W v Y e r S v 0 2 j 6 M I Z 3 A O l + D B N d T h H h r Q A g Y T e I Z X e H M S 5 8 V 5 d z 6 W r Q U n n z m F P 3 A + f w A S M I 9 h < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" R c Q h e P E j J m W n z B M H Y o 1 W 3 G p y F A k = \" > A A A B 7 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m K o M e i F 4 8 V + g V t L J v t p l 2 6 2 Y T d i V B C f 4 Q X D4 p 4 9 f d 4 8 9 + 4 bX P Q 1 g c D j / d m m J k X J F I Y d N 1 v p 7 C x u b W 9 U 9 w t 7 e 0 f H B 6 V j 0 / a J k 4 1 4 y 0 W y 1 h 3 A 2 q 4 F I q 3 U K D k 3 U R z G g W S d 4 L J 3 d z v P H F t R K y a O E 2 4 H 9 G R E q F g F K 3 U C R + z 5 q A 2 G 5 Q r b t V d g K w T L y c V y N E Y l L / 6 w 5 i l E V f I J D W m 5 7 k J + h n V K J j k s 1 I / N T y h b E J H v G e p o h E 3 f r Y 4 d 0 Y u r D I k Y a x t K S Q L 9 f d E R i N j p l F g O y O K Y 7 P q z c X / v F 6 K 4 Y 2 f C Z W k y B Vb L g p T S T A m 8 9 / J U G j O U E 4 t o U w L e y t h Y 6 o p Q 5 t Q y Y b g r b 6 8 T t q 1 q u d W v Y e r S v 0 2 j 6 M I Z 3 A O l + D B N d T h H h r Q A g Y T e I Z X e H M S 5 8 V 5 d z 6 W r Q U n n z m F P 3 A + f w A S M I 9 h < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" R c Q h e P E j J m W n z B M H Y o 1 W 3 G p y F A k = \" > A A A B 7 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 m K o M e i F 4 8 V + g V t L J v t p l 2 6 2 Y T d i V B C f 4 Q X D 4 p 4 9 f d 4 8 9 + 4 b X P Q 1 g c D j / d m m J k X J F I Y d N 1 v p 7 C x u b W 9 U 9 w t 7 e 0 f H B 6 V j 0 / a J k 4 1 4 y 0 W y 1 h 3 A 2 q 4F I q 3 U K D k 3 U R z G g W S d 4 L J 3 d z v P H F t R K y a O E 2 4 H 9 G R E q F g F K 3 U C R + z 5 q A 2 G 5 Q r b t V d g K w T L y c V y N E Y l L / 6 w 5 i l E V f I J D W m 5 7 k J + h n V K J j k s 1 I / N T y h b E J H v G e p o h E 3 f r Y 4 d 0 Y u r D I k Y a x t K S Q L 9 f d E R i N j p l F g O y O K Y 7 P q z c X / v F 6 K 4 Y 2 f C Z W k y B Vb L g p T S T A m 8 9 / J U G j O U E 4 t o U w L e y t h Y 6 o p Q 5 t Q y Y b g r b 6 8 T t q 1 q u d W v Y e r S v 0 2 j 6 M I Z 3 A O l + D B N d T h H h r Q A g Y T e I Z X e H M S 5 8 V 5 d z 6 W r Q U n n z m F P 3 A + f w A S M I 9 h < / l a t e x i t > f T3 < l a t e x i t s h a 1 _ b a s e 6 4 = \" W 6 G r t 1 M 7 4 L r j s K 3 y n o D P h Q I X R T 4 = \" > A A A B 7 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l U 0 G P R i 8 c K / Y I 2 l s 1 2 0 y 7 d b M L u R C i h P 8 K L B 0 W 8 + n u 8 + W / c t j l o 6 4 O B x 3 s z z M w L E i k M u u 6 3 U 1 h b 3 9 j c K m 6 X d n b 3 9 g / K h 0 c t E 6 e a 8 S a L Z a w 7 A T V c C s W b K F D y T q I 5 j Q L J 2 8 H 4 b u a 3 n 7 g 2 I l Y N n C T c j + h Q i V A w i l Z q h 4 9 Z o 3 8 5 7 Z c r b t W d g 6 w S L y c V y F H v l 7 9 6 g 5 i l E V f I J D W m 6 7 k J + h n V K J j k 0 1 I v N T y h b E y H v G u p o h E 3 f j Y / d 0 r O r D I g Y a x t K S R z 9 f d E R i N j J l F g O y O K I 7 P s z c T / v G 6 K 4 Y 2 f C Z W k y B V b L A p T S T A m s 9 / J Q G j O U E 4 s o U w L e y t h I 6 o p Q 5 t Q y Y b g L b + 8 S l o X V c + t e g 9 X l d p t H k c R T u A U z s G D a 6 j B P d S h C Q z G 8 A y v 8 O Y k z o v z 7 n w s W g t O P n M M f + B 8 / g A T t Y 9 i < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" W 6 G r t 1 M 7 4 L r j s K 3 y n o D P h Q I X R T 4 = \" > A A A B 7 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l U 0 G P R i 8 c K / Y I 2 l s 1 2 0 y 7 d b M L u R C i h P 8 K L B 0 W 8 + n u 8 + W / c t j l o 6 4 O B x 3 s z z M w L E i k M u u 6 3 U 1 h b 3 9 j c K m 6 X d n b 3 9 g / K h 0 c t E 6 e a 8 S a L Z a w 7 A T V c C s W b K F D y T q I 5 j Q L J 2 8 H 4 b u a 3 n 7 g 2 I l Y N n C T c j + h Q i V A w i l Z q h 4 9 Z o 3 8 5 7 Z c r b t W d g 6 w S L y c V y F H v l 7 9 6 g 5 i l E V f I J D W m 6 7 k J + h n V K J j k 0 1 I v N T y h b E y H v G u p o h E 3 f j Y / d 0 r O r D I g Y a x t K S R z 9 f d E R i N j J l F g O y O K I 7 P s z c T / v G 6 K 4 Y 2 f C Z W k y B V b L A p T S T A m s 9 / J Q G j O U E 4 s o U w L e y t h I 6 o p Q 5 t Q y Y b g L b + 8 S l o X V c + t e g 9 X l d p t H k c R T u A U z s G D a 6 j B P d S h C Q z G 8 A y v 8 O Y k z o v z 7 n w s W g t O P n M M f + B 8 / g A T t Y 9 i < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" W 6 G r t 1 M 7 4 L r j s K 3 y n o D P h Q I X R T 4 = \" > A A A B 7 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l U 0 G P R i 8 c K / Y I 2 l s 1 2 0 y 7 d b M L u R C i h P 8 K L B 0 W 8 + n u 8 + W / c t j l o 6 4 O B x 3 s z z M w L E i k M u u 6 3 U 1 h b 3 9 j c K m 6 X d n b 3 9 g / K h 0 c t E 6 e a 8 S a L Z a w 7 A T V c C s W b K F D y T q I 5 j Q L J 2 8 H 4 b u a 3 n 7 g 2 I l Y N n C T c j + h Q i V A w i l Z q h 4 9 Z o 3 8 5 7 Z c r b t W d g 6 w S L y c V y F H v l 7 9 6 g 5 i lE V f I J D W m 6 7 k J + h n V K J j k 0 1 I v N T y h b E y H v G u p o h E 3 f j Y / d 0 r O r D I g Y a x t K S R z 9 f d E R i N j J l F g O y O K I 7 P s z c T / v G 6 K 4 Y 2 f C Z W k y B V b L A p T S T A m s 9 / J Q G j O U E 4 s o U w L e y t h I 6 o p Q 5 t Q y Y b g L b + 8 S l o X V c + t e g 9 X l d p t H k c R T u A U z s G D a 6 j B P d S h C Q z G 8 A y v 8 O Y k z o v z 7 n w s W g t O P n M M f + B 8 / g A T t Y 9 i < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" W 6 G r t 1 M 7 4 L r j s K 3 y n o D P h Q I X R T 4 = \" > A A A B 7 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l U 0 G P R i 8 c K / Y I 2 l s 1 2 0 y 7 d b M L u R C i h P 8 K L B 0 W 8 + n u 8 + W / c t j l o 6 4 O B x 3 s z z M w L E i k M u u 6 3 U 1 h b 3 9 j c K m 6 X d n b 3 9 g / K h 0 c t E 6 e a 8 S a L Z a w 7 A T V c C s W b K F D y T q I 5 j Q L J 2 8 H 4 b u a 3 n 7 g 2 I l Y N n C T c j + h Q i V A w i l Z q h 4 9 Z o 3 8 5 7 Z c r b t W d g 6 w S L y c V y F H v l 7 9 6 g 5 i l E V f I J D W m 6 7 k J + h n V K J j k 0 1 I v N T y h b E y H v G u p o h E 3 f j Y / d 0 r O r D I g Y a x t K S R z 9 f d E R i N j J l F g O y O K I 7 P s z c T / v G 6 K 4 Y 2 f C Z W k y B V b L A p T S T A m s 9 / J Q G j O U E 4 s o U w L e y t h I 6 o p Q 5 t Q y Y b g L b + 8 S l o X V c + t e g 9 X l d p t H k c R T u A U z s G D a 6 j B P d S h C Q z G 8 A y v 8 O Y k z o v z 7 n w s W g t O P n M M f + B 8 / g A T t Y 9 i < / l a t e x i t >x < l a t e x i t s h a 1 _ b a s e 6 4 = \" f 2 y z i m w b R / D g j z p 6 t Z 3 6 0 f H R q N I = \" > A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 c W 7 A e 0 o W y 2 k 3 b t Z h N 2 N 2 I J / Q V e P C j i 1 Z / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b / + g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 H 1 F p H s t 7 M 0 n Q j + h Q 8 p A z a q z U e O q X K 2 7 V n Y O s E i 8 n F c h R 7 5 e / e o O Y p R F K w w T V u u u 5 i f E z q g x n A q e l X q o x o W x M h 9 i 1 V N I I t Z / N D 5 2 S M 6 s M S B g r W 9 K Q u f p 7 I q O R 1 p M o s J 0 R N S O 9 7 M 3 E / 7 x u a s J r P + M y S Q 1 K t l g U p o K Y m M y + J g O u k B k x s Y Q y x e 2 t h I 2 o o s z Y b E o 2 B G / 5 5 V X S u q h 6 b t V r X F Z q N 3 k c R T i B U z g H D 6 6 g B n d Q h y Y w Q H i G V 3 h z H p w X 5 9 3 5 W L Q W n H z m G P 7 A + f w B 5 j m M / A = = < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" f 2 y z i m w b R / D g j z p 6 t Z 3 6 0 f H R q N I = \" > A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 c W 7 A e 0 o W y 2 k 3 b t Z h N 2 N 2 I J / Q V e P C j i 1 Z / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b / + g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 H 1 F p H s t 7 M 0 n Q j + h Q 8 p A z a q z U e O q X K 2 7 V n Y O s E i 8 n F c h R 7 5 e / e o O Y p R F K w w T V u u u 5 i f E z q g x n A q e l X q o x o W x M h 9 i 1 V N I I t Z / N D 5 2 S M 6 s M S B g r W 9 K Q u f p 7 I q O R 1 p M o s J 0 R N S O 9 7 M 3 E / 7 x u a s J r P + M y S Q 1 K t l g U p o K Y m M y + J g O u k B k x s Y Q y x e 2 t h I 2 o o s z Y b E o 2 B G / 5 5 V X S u q h 6 b t V r X F Z q N 3 k c R T i B U z g H D 6 6 g B n d Q h y Y w Q H i G V 3 h z H p w X 5 9 3 5 W L Q W n H z m G P 7 A + f w B 5 j m M / A = = < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" f 2 y z i m w b R / D g j z p 6 t Z 3 6 0 f H R q N I = \" > A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 c W 7 A e 0 o W y 2 k 3 b t Z h N 2 N 2 I J / Q V e P C j i 1 Z / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b /+ g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 H 1 F p H s t 7 M 0 n Q j + h Q 8 p A z a q z U e O q X K 2 7 V n Y O s E i 8 n F c h R 7 5 e / e o O Y p R F K w w T V u u u 5 i f E z q g x n A q e l X q o x o W x M h 9 i 1 V N I I t Z / N D 5 2 S M 6 s M S B g r W 9 K Q u f p 7 I q O R 1 p M o s J 0 R N S O 9 7 M 3 E / 7 x u a s J r P + M y S Q 1 K t l g U p o K Y m M y + J g O u k B k x s Y Q y x e 2 t h I 2 o o s z Y b E o 2 B G / 5 5 V X S u q h 6 b t V r X F Z q N 3 k c R T i B U z g H D 6 6 g B n d Q h y Y w Q H i G V 3 h zH p w X 5 9 3 5 W L Q W n H z m G P 7 A + f w B 5 j m M / A = = < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" f 2 y z i m w b R / D g j z p 6 t Z 3 6 0 f H R q N I = \" > A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 c W 7 A e 0 o W y 2 k 3 b t Z h N 2 N 2 I J / Q V e P C j i 1 Z / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b / + g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 H 1 F p H s t 7 M 0 n Q j + h Q 8 p A z a q z U e O q X K 2 7 V n Y O s E i 8 n F c h R 7 5 e / e o O Y p R F K w w T V u u u 5 i f E z q g x n A q e l X q o x o W x M h 9 i 1 V N I I t Z / N D 5 2 S M 6 s M S B g r W 9 K Q u f p 7 I q O R 1 p M o s J 0 R N S O 9 7 M 3 E / 7 x u a s J r P + M y S Q 1 K t l g U p o K Y m M y + J g O u k B k x s Y Q y x e 2 t h I 2 o o s z Y b E o 2 B G / 5 5 V X S u q h 6 b t V r X F Z q N 3 k c R T i B U z g H D 6 6 g B n d Q h y Y w Q H i G V 3 h z H p w X 5 9 3 5 W L Q W n H z m G P 7 A + f w B 5 j m M / A = = < / l a t e x i t > x < l a t e x i t s h a 1 _ b a s e 6 4 = \" f 2 y z i m w b R / D g j z p 6 t Z 3 6 0 f H R q N I = \" > A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 c W 7 A e 0 o W y 2 k 3 b t Z h N 2 N 2 I J / Q V e P C j i 1 Z / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b /\n\n\n\n\nH p w X 5 9 3 5 W L Q W n H z m G P 7 A + f w B 5 j m M / A = = < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" f 2 y z i m w b R / D g j z p 6 t Z 3 6 0 f H R q N I = \" > A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 c W 7 A e 0 o W y 2 k 3 b t Z h N 2 N 2 I J / Q V e P C j i 1 Z / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b /\n\n\n\n\nH p w X 5 9 3 5 W L Q W n H z m G P 7 A + f w B 5 j m M / A = = < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" f 2 y z i m w b R / D g j z p 6 t Z 3 6 0 f H R q N I = \" > A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 c W 7 A e 0 o W y 2 k 3 b t Z h N 2 N 2 I J / Q V e P C j i 1 Z / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b /\n\n\n\n\nH p w X 5 9 3 5 W L Q W n H z m G P 7 A + f w B 5 j m M / A = = < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" f 2 y z i m w b R / D g j z p 6 t Z 3 6 0 f H R q N I = \" > A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 c W 7 A e 0 o W y 2 k 3 b t Z h N 2 N 2 I J / Q V e P C j i 1 Z / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b /\n\n\n\n\nH p w X 5 9 3 5 W L Q W n H z m G P 7 A + f w B 5 j m M / A = = < / l a t e x i t >x < l a t e x i t s h a 1 _ b a s e 6 4 = \" f 2 y z i m w b R / D g j z p 6 t Z 3 6 0 f H R q N I = \" > A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 c W 7 A e 0 o W y2 k 3 b t Z h N 2 N 2 I J / Q V e P C j i 1 Z / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b / + g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 H 1 F p H s t 7 M 0 n Q j + h Q 8 p A z a q z U e O q X K 2 7 V n Y O s E i 8 n F c h R 7 5 e / e o O Y p R F K w w T V u u u 5 i f E z q g x n A q e l X q o x o W x M h 9 i 1 V N I I t Z / N D 5 2 S M 6 s M S B g r W 9 K Q u f p 7 I q O R 1 p M o s J 0 R N S O 9 7 M 3 E / 7 x u a s J r P + M y S Q 1 K t l g U p o K Y m M y + J g O u k B k x s Y Q y x e 2 t h I 2 o o s z Y b E o 2 B G / 5 5 V X S u q h 6 b t V r X F Z q N 3 k c R T i B U z g H D 6 6 g B n d Q h y Y w Q H i G V 3 h z H p w X 5 9 3 5 W L Q W n H z m G P 7 A + f w B 5 j m M / A = = < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" f 2 y z i m w b R / D g j z p 6 t Z 3 6 0 f H R q N I = \" > A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 c W 7 A e 0 o W y 2 k 3 b t Z h N 2 N 2 I J / Q V e P C j i 1 Z / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b / + g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 H 1 F p H s t 7 M 0 n Q j + h Q 8 p A z a q z U e O q X K 2 7 V n Y O s E i 8 n F c h R 7 5 e / e o O Y p R F K w w T V u u u 5 i f E z q g x n A q e l X q o x o W x M h 9 i 1 V N I I t Z / N D 5 2 S M 6 s M S B g r W 9 K Q u f p 7 I q O R 1 p M o s J 0 R N S O 9 7 M 3 E / 7 x u a s J r P + M y S Q 1 K t l g U p o K Y m M y + J g O u k B k x s Y Q y x e 2 t h I 2 o o s z Y b E o 2 B G / 5 5 V X S u q h 6 b t V r X F Z q N 3 k c R T i B U z g H D 6 6 g B n d Q h y Y w Q H i G V 3 h z H p w X5 9 3 5W L Q W n H z m G P 7 A + f w B 5 j m M / A = = < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" f 2 y z i m w b R / D g j z p 6 t Z 3 6 0 f H R q N I = \" > A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 c W 7 A e 0 o W y 2 k 3 b t Z h N 2 N 2 I J / Q V e P C j i 1 Z / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b /+ g f H j U 0 n G q G D Z Z L G L V C a h G w S U 2 D T c C O 4 l C G g U C 2 8 H 4 d u a 3 H 1 F p H s t 7 M 0 n Q j + h Q 8 p A z a q z U e O q X K 2 7 V n Y O s E i 8 n F c h R7 5  e / e o O Y p R F K w w T V u u u 5 i f E z q g x n A q e l X q o x o W x M h 9 i 1 V N I I t Z / N D 5 2 S M 6 s M S B g r W 9 K Q u f p 7 I q O R 1 p M o s J 0 R N S O 9 7 M 3 E / 7 x u a s J r P + M y S Q 1K t l g U p o K Y m M y + J g O u k B k x s Y Q y x e 2 t h I 2 o o s z Y b E o 2 B G / 5 5 V X S u q h 6 b t V r X F Z q N 3 k c R T i B U z g H D 6 6 g B n d Q h y Y w Q H i G V 3 h zH p w X 5 9 3 5 W L Q W n H z m G P 7 A + f w B 5 j m M / A = = < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = \" f 2 y z i m w b R / D g j z p 6 t Z 3 6 0 f H R q N I = \" > A A A B 6 H i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 l E 0 G P R i 8 c W 7 A e 0 o W y 2 k 3 b t Z h N 2 N 2 I J / Q V e P C j i 1 Z / k z X / j t s 1 B W x 8 M P N 6 b Y W Z e k A i u j e t + O 4 W 1 9 Y 3 N r e J 2 a W d 3 b /\n\n\nFigure 1 :\n1\nFigure 1: The three distillation settings we consider: (a) compressing a model, (b) transferring knowledge from one modality (e.g., RGB) to another (e.g., depth), (c) distilling an ensemble of nets into a single network.The constrastive objective encourages the teacher and student to map the same input to close representations (in some metric space), and different inputs to distant representations, as indicated in the shaded circle.\n\n\n) 4 EXPERIMENTS\n4\nWe evaluate our contrastive representation distillation (CRD) framework in three knowledge distillation tasks: (a) model compression of a large network to a smaller one; (b) cross-modal knowledge transfer; (c) ensemble distillation from a group of teachers to a single student network.Datasets (1) CIFAR-100(Krizhevsky & Hinton, 2009) contains 50K training images with 0.5K images per class and 10K test images.(2) ImageNet (Deng et al., 2009) provides 1.2 million images from 1K classes for training and 50K for validation.(3) STL-10 (Coates et al., 2011) consists of a training set of 5K labeled images from 10 classes and 100K unlabeled images, and a test set of 8K images.(4) TinyImageNet (Deng et al., 2009) has 200 classes, each with 500 training images and 50 validaton images.(5) NYU-Depth V2 (Silberman et al., 2012) consists of 1449 indoor images, each labeled with dense depth image and semantic map.\n\n\nFigure 2 :\n2\nFigure 2: The correlations between class logits of a teacher network are ignored by regular cross-entropy.Distillation frameworks use \"soft targets\" (Hinton et al., 2015) which effectively capture such correlations and transfer them to the student network, leading to the success of distillation.We visualize here the difference of correlation matrices of student and teacher logits, for different student networks on a CIFAR-100 knowledge distillation task: (a) Student trained without distillation, showing that the teacher and student cross-correlations are very different; (b) Student distilled by attention transfer (Zagoruyko & Komodakis, 2016a); showing reduced difference (see axis); (c) Student distilled by KL divergence (Hinton et al., 2015), also showing reduced difference; (d) Student distilled by our contrastive objective, showing significant matching between student's and teacher's correlations.In this visualization, we use WRN-40-2 as teacher and WRN-40-1 as student.\n\n\nFigure 3 :\n3\nFigure 3: Top-1 classification accuracy on STL-10 using chrominance image (ab channel in Lab color space).We initialize the chrominance network randomly or by distilling from a luminance network, trained with large-scale labeled images.We evaluate distillation performance by (a) linear probing and (b) fully finetuning.\n\n\nFigure 5 :\n5\nFigure 5: Effects of varying the number of negatives, shown in (a), or the temperature, shown in (b).\n\n\nN\n\nWe have validated differentN : 16, 64, 256, 1024, 4096, 16384.As shown in Figure5(a), increasing N leads to improved performance.However, the difference of error rate between N = 4096 and N = 16384 is less than 0.1%.Therefore, we use N = 16384 for reporting the accuracy while in practice N = 4096 should suffice.Temperature \u03c4 We varied \u03c4 between 0.02 and 0.3.As Figure5(b) illustrates, both extremely high or low temperature lead to a sub-optimal solution.In general, temperatures between 0.05 and 0.2 work well on CIFAR100.All experiments but those on ImageNet use a temperature of 0.1.For ImageNet, we use \u03c4 = 0.07.The optimal temperature may vary across different datasets and require further tuning.Computational Cost We use ResNet-18 on ImageNet for illustration.CRD uses extra 260 MFLOPs, which is about 12% of the original 2 GFLOPs.In practice, we did not notice significant difference of training time on ImageNet (e.g., 1.75 epochs/hour v.s.1.67 epochs/hour on two Titan-V GPUs).\n\n\n\n\ndefining for convenience h (C = 1, S = s, T = t) = h(S = s, T = t) and h (C = 0, S = s, T = t) = 1 \u2212 h(S = s, T = t).The log likelihood function is:E c\u223cq(C|S=s,T =t) [log h (C = c, S = s, T = t)]\n\n\nE\n\ns,t\u223cq(S,T )[E c\u223cq(C|S=s,T =t)  [log h (C = c, S = s, T = t)]] (23) = E c,s,t\u223cq(C,S,T ) [log h (C = c, S = s, T = t)]] (24) = E s,t\u223cq(S,T |C=1)q(C=1) [log h(S = s, T = t)]+ E s,t\u223cq(S,T |C=0)q(C=0) [log(1 \u2212 h(S = s, T = t))] t\u223cq(S,T |C=1) [log h(S = s, T = t)]+ N N + 1 E s,t\u223cq(S,T |C=0) [log(1 \u2212 h(S = s, T = t))]\n\n\nFigure 6 :\n6\nFigure 6:  The correlations between class logits output by the teacher network show the \"dark knowledge\"Hinton et al. (2015) that must be transferred to a student networks.A student network that captures these correlations tends to perform better at the task.We visualize here the difference between correlation matrices of the student and teacher at the logits, for different student networks on a Cifar100 knowledge distillation task: (a) A student trained without distillation; (b) A student distilled by attention transfer Zagoruyko & Komodakis (2016a) (c) A student distilled by KL divergence Hinton et al. (2015); (d) A student distilled by our contrastive objective.Our objective greatly improves the structured knowledge (correlations) in the output units.\n\n\nTable 1 :\n1\nTest accuracy (%) of student networks on CIFAR100 of a number of distillation methods (ours is CRD); see Appendix for citations of other methods.\u2191 denotes outperformance over KD and \u2193 denotes underperformance.We note that CRD is the only method to always outperform KD (and also outperforms all other methods).We denote by * methods where we used our reimplementation based on the paper; for all other methods we used author-provided or author-verified code.Average over 5 runs.\nTeacherWRN-40-2WRN-40-2resnet56resnet110resnet110resnet32x4vgg13StudentWRN-16-2WRN-40-1resnet20resnet20resnet32resnet8x4vgg8Teacher75.6175.6172.3474.3174.3179.4274.64Student73.2671.9869.0669.0671.1472.5070.36KD  *74.9273.5470.6670.6773.0873.3372.98FitNet  *73.58 (\u2193) 72.24 (\u2193) 69.21 (\u2193) 68.99 (\u2193) 71.06 (\u2193) 73.50 (\u2191) 71.02 (\u2193)AT74.08 (\u2193) 72.77 (\u2193) 70.55 (\u2193) 70.22 (\u2193) 72.31 (\u2193) 73.44 (\u2191) 71.43 (\u2193)SP73.83 (\u2193) 72.43 (\u2193) 69.67 (\u2193) 70.04 (\u2193) 72.69 (\u2193) 72.94 (\u2193) 72.68 (\u2193)CC73.56 (\u2193) 72.21 (\u2193) 69.63 (\u2193) 69.48 (\u2193) 71.48 (\u2193) 72.97 (\u2193) 70.71 (\u2193)VID74.11 (\u2193) 73.30 (\u2193) 70.38 (\u2193) 70.16 (\u2193) 72.61 (\u2193) 73.09 (\u2193) 71.23 (\u2193)RKD73.35 (\u2193) 72.22 (\u2193) 69.61 (\u2193) 69.25 (\u2193) 71.82 (\u2193) 71.90 (\u2193) 71.48 (\u2193)PKT74.54 (\u2193) 73.45 (\u2193) 70.34 (\u2193) 70.25 (\u2193) 72.61 (\u2193) 73.64 (\u2191) 72.88 (\u2193)AB72.50 (\u2193) 72.38 (\u2193) 69.47 (\u2193) 69.53 (\u2193) 70.98 (\u2193) 73.17 (\u2193) 70.94 (\u2193)FT  *73.25 (\u2193) 71.59 (\u2193) 69.84 (\u2193) 70.22 (\u2193) 72.37 (\u2193) 72.86 (\u2193) 70.58 (\u2193)FSP  *72.91 (\u2193)n/a69.95 (\u2193) 70.11 (\u2193) 71.89 (\u2193) 72.62 (\u2193) 70.23 (\u2193)NST  *73.68 (\u2193) 72.24 (\u2193) 69.60 (\u2193) 69.53 (\u2193) 71.96 (\u2193) 73.30 (\u2193) 71.53 (\u2193)CRD75.48 (\u2191) 74.14 (\u2191) 71.16 (\u2191) 71.46 (\u2191) 73.48 (\u2191) 75.51 (\u2191) 73.94 (\u2191)CRD+KD 75.64 (\u2191) 74.38 (\u2191) 71.63 (\u2191) 71.56 (\u2191) 73.75 (\u2191) 75.46 (\u2191) 74.29 (\u2191)Teachervgg13ResNet50ResNet50resnet32x4resnet32x4WRN-40-2StudentMobileNetV2MobileNetV2vgg8ShuffleNetV1ShuffleNetV2ShuffleNetV1Teacher74.6479.3479.3479.4279.4275.61Student64.664.670.3670.571.8270.5KD  *67.3767.3573.8174.0774.4574.83FitNet  *64.14 (\u2193)63.16 (\u2193)70.69 (\u2193)73.59 (\u2193)73.54 (\u2193)73.73 (\u2193)AT59.40 (\u2193)58.58 (\u2193)71.84 (\u2193)71.73 (\u2193)72.73 (\u2193)73.32 (\u2193)SP66.30 (\u2193)68.08 (\u2191)73.34 (\u2193)73.48 (\u2193)74.56 (\u2191)74.52 (\u2193)CC64.86 (\u2193)65.43 (\u2193)70.25 (\u2193)71.14 (\u2193)71.29 (\u2193)71.38 (\u2193)VID65.56 (\u2193)67.57 (\u2191)70.30 (\u2193)73.38 (\u2193)73.40 (\u2193)73.61 (\u2193)RKD64.52 (\u2193)64.43 (\u2193)71.50 (\u2193)72.28 (\u2193)73.21 (\u2193)72.21 (\u2193)PKT67.13 (\u2193)66.52 (\u2193)73.01 (\u2193)74.10 (\u2191)74.69 (\u2191)73.89 (\u2193)AB66.06 (\u2193)67.20 (\u2193)70.65 (\u2193)73.55 (\u2193)74.31 (\u2193)73.34 (\u2193)FT  *61.78 (\u2193)60.99 (\u2193)70.29 (\u2193)71.75 (\u2193)72.50 (\u2193)72.03 (\u2193)NST  *58.16 (\u2193)64.96 (\u2193)71.28 (\u2193)74.12 (\u2191)74.68 (\u2191)74.89 (\u2191)CRD69.73 (\u2191)69.11 (\u2191)74.30 (\u2191)75.11 (\u2191)75.65 (\u2191)76.05 (\u2191)CRD+KD69.94 (\u2191)69.54 (\u2191)74.58 (\u2191)75.12 (\u2191)76.05 (\u2191)76.27 (\u2191)\n\nTable 2 :\n2\nTop-1 test accuracy (%) of student networks on CIFAR100 of a number of distillation methods (ours is CRD) for transfer across very different teacher and student architectures.CRD outperforms KD and all other methods.\n\n\n\n\nTable 1 and Table 2 compare top-1 accuracies of different distillation objectives (for details, see Section 6.1).Table 1 investigates students and teachers of the same architectural style, while Table 2 focuses on students and teachers from different architectures.We observe that our\n\n\nTable 3 :\n3\n(Lan et al., 2018)15) rates (%) of student network ResNet-18 on ImageNet validation set.We use ResNet-34 released by PyTorch team as our teacher network, and follow the standard training practice of ImageNet on PyTorch except that we train for 10 more epochs.We compare our CRD with KD(Hinton et al., 2015), AT(Zagoruyko & Komodakis, 2016a)and Online-KD(Lan et al., 2018).\"*\"reportedby the original paper Lan et al. (2018) using an ensemble of online ResNets as teacher, no pretrained ResNet-34 was used.\nTeacher Student ATKDSPCC Online KD * CRD CRD+KDTop-1 26.6930.25 29.30 29.34 29.38 30.0429.4528.8328.62Top-58.5810.93 10.00 10.12 10.20 10.8310.419.879.51\n\nTable 4 :\n4\nWe transfer the representation learned from CIFAR100 to STL-10 and TinyImageNet datasets by freezing the network and training a linear classifier on top of the last feature layer to perform 10-way (STL-10) or 200-way (TinyImageNet) classification.For this experiment, we use the combination of teacher network WRN-40-2 and student network WRN-16-2.Classification accuracies (%) are reported.\nStudent KD AT FitNet CRD CRD+KD TeacherCIFAR100\u2192STL-1069.770.9 70.7 70.3 71.672.268.6CIFAR100\u2192TinyImageNet33.733.9 34.2 33.5 35.635.531.5(a) Accuracy on STL-10 with linear probing(b) Accuracy on STL-10 with fully finetuning\n10)or 200-way (for TinyImageNet) classification to quantify the transferability of the representations.We compare CRD with multiple baselines such as KD and\n\n\nTable 6 :\n6\nAblative study of different contrastive objectives and negative sampling policies on CIFAR100.For contrastive objectives, we compare our objective withInfoNCE (Oord et al., 2018); For negative sampling policy, when given an anchor image xi from the dataset, we consider either randomly sample negative xj such that (a) i = j, or (b) yi = yj where y represents the class label.Average over 5 runs.\nsampling objectiveWRN-40-2 WRN-16-2resnet110 resnet20resnet110 resnet32resnet32x4 resnet8x4vgg13 vgg8i = jInfoNCE Ours74.78 74.4870.56 70.6472.67 72.6474.69 74.6773.24 73.39y i = y jInfoNCE Ours75.15 75.4871.39 71.4673.53 73.4875.22 75.5173.74 73.94\nHjelm et al. (2018)GB to Depth.We transfer the knowledge of a ResNet-18 teacher pretrained on ImageNet to a 5-layer student CNN operating on depth images.We follow a similar transferring procedure on NYU-Depth training set, except that we use a trick of contrasting between local and global features, proposed byHjelm et al. (2018), to overcome the problem of insufficient data samples in the depth domain.Then the student network is further trained to predict semantic segmentation\n\n\nTable 7 :\n7\nTest accuracy (%) of student networks on CIFAR100 of combining distillation methods with KD;we check the compatibility of our objective with KD as well as PKT.\u2191 denotes outperformance over KD and \u2193 denotes underperformance.\nTeacherWRN-40-2resnet110resnet32x4vgg13vgg13ResNet50resnet32x4StudentWRN-16-2resnet20resnet8x4vgg8MobileNetV2vgg8ShuffleNetV2Teacher75.6174.3179.4274.6474.6479.3479.42Student73.2669.0672.5070.3664.6070.3671.82KD74.9270.6773.3372.9867.3773.8174.45FitNet+KD 75.12 (\u2191) 70.67 (\u2191) 74.66 (\u2191) 73.22 (\u2191)66.90 (\u2193)73.24 (\u2193)75.15 (\u2191)AT+KD75.32 (\u2191) 70.97 (\u2191) 74.53 (\u2191) 73.48 (\u2191)65.13 (\u2193)74.01 (\u2191)75.39 (\u2191)SP+KD74.98 (\u2191) 71.02 (\u2191) 74.02 (\u2191) 73.49 (\u2191)68.41 (\u2191)73.52 (\u2193)74.88 (\u2191)CC+KD75.09 (\u2191) 70.88 (\u2191) 74.21 (\u2191) 73.04 (\u2191)68.02 (\u2191)73.48 (\u2193)74.71 (\u2191)VID+KD75.14 (\u2191) 71.10 (\u2191) 74.56 (\u2191) 73.19 (\u2191)68.27 (\u2191)73.46 (\u2193)74.85 (\u2191)RKD+KD74.89 (\u2193) 70.77 (\u2191) 73.79 (\u2191) 72.97 (\u2193)67.87 (\u2191)73.51 (\u2193)74.55 (\u2191)PKT+KD75.33 (\u2191) 70.72 (\u2191) 74.23 (\u2191) 73.25 (\u2191)68.13 (\u2191)73.61 (\u2193)74.66 (\u2191)AB+KD70.27 (\u2193) 70.97 (\u2191) 74.40 (\u2191) 73.35 (\u2191)68.23 (\u2191)73.65 (\u2193)74.99 (\u2191)FT+KD75.15 (\u2191) 70.88 (\u2191) 74.62 (\u2191) 73.44 (\u2191)66.99 (\u2193)72.98 (\u2193)75.06 (\u2191)NST+KD74.67 (\u2193) 71.01 (\u2191) 74.28 (\u2191) 73.33 (\u2191)63.77 (\u2193)71.74 (\u2193)75.24 (\u2191)CRD75.48 (\u2191) 71.46 (\u2191) 75.51 (\u2191) 73.94 (\u2191)69.73 (\u2191)74.30 (\u2191)75.65 (\u2191)CRD+KD75.64 (\u2191) 71.56 (\u2191) 75.46 (\u2191) 74.29 (\u2191)69.94 (\u2191)74.58 (\u2191)76.05 (\u2191)CRD+PKT 75.91 (\u2191) 71.65 (\u2191) 75.90 (\u2191) 74.57 (\u2191)69.59 (\u2191)74.68 (\u2191)75.94 (\u2191)TeacherWRN-40-2resnet56resnet32x4vgg13resnet32x4StudentWRN-16-2resnet20resnet8x4MobileNetV2ShuffleNetV2datasetSTLTISTLTISTLTISTLTISTLTIVanilla69.7 33.7 69.1 30.4 71.8 36.7 64.2 29.1 65.1 28.9KD70.9 33.9 69.1 32.0 71.8 36.2 66.3 29.9 69.5 33.4FitNet70.3 33.5 68.1 29.5 73.5 40.2 66.9 31.4 71.7 36.2AT70.7 34.2 70.1 31.0 74.1 39.2 66.3 28.4 72.5 37.3SP71.3 34.1 68.0 30.2 72.9 37.6 67.8 31.6 68.8 33.4CC70.5 33.7 68.6 30.4 72.1 37.1 66.3 30.6 69.9 34.4VID71.0 34.6 69.9 32.4 73.9 39.6 66.1 31.1 71.4 36.5RKD71.6 35.1 70.6 32.6 73.9 38.8 68.4 32.9 71.5 37.8PKT71.6 34.8 69.1 31.6 73.5 38.0 69.5 33.5 70.7 36.4AB70.8 32.2 68.5 29.7 73.4 37.6 67.6 31.0 71.3 36.2FT71.7 34.7 70.9 33.5 75.2 40.4 68.9 32.5 72.9 38.7FSP69.6 33.6 68.1 30.4 72.4 37.1 n/an/an/an/aNST70.2 32.6 68.5 30.1 73.9 38.7 64.9 27.8 72.3 37.8CRD71.6 35.6 70.2 34.3 74.8 40.2 71.6 35.7 73.5 40.1\nAcknowledgments.We thank Baoyun Peng for providing the code of CC(Peng et al., 2019)and Frederick Tung for verifying our reimplementation of SP (Tung & Mori, 2019).This research was supported in part by Google Cloud and iFlytek.Table5: Performance on the task of using depth to predict semantic segmentation labels.We initialize the depth network either randomly or by distilling from a ImageNet pre-pretrained ResNet-18 teacher.maps from depth images.We note that both knowledge transfer and downstream training are conducted on the same set of images, i.e., the training set.DISTILLATION FROM AN ENSEMBLEBetter classification performance is often achieved by ensembles of deep networks, but these are usually too expensive for inference time, and distillation into a single network is a desirable task.We investigate the KL-divergence based KD and our CRD for this task, using the loss of Sec. 21.The network structures of each teacher and student are identical here, but an ensemble of multiple teachers can still provide rich knowledge for the student.To compare between KD and CRD on CIFAR100 dataset, we use WRN-16-2 and ResNet-20, whose single model error rates are 26.7% and 30.9% respectively.The results of distillation are presented in Figure4, where we vary the number of ensembled teachers.CRD with 8 teachers decreases the error rate of WRN-16-2 to 23.7% and ResNet20 to 28.3%.In addition, CRD works consistently better than KD in all settings we test.These observations suggest that CRD is capable of distilling an ensemble of models into a single one which performs significantly better than a model of the same size that is trained from scratch.InfoNCE v.s. Ours. InfoNCE (Oord et al., 2018) is an alternative contrastive objective which select a single positive out from a set of distractors via a softmax function.We compare InfoNCE with our contrastive objective Eq 18, when using the same number of negatives.The last two rows in Table6show that our objective outperforms InfoNCE in 4 out of 5 teacher-student combinations.ABLATIVE STUDYNegative Sampling.In this paper, we consider two negative sampling plocies when giving an anchor x i : (1) x j j =i for the unsupervised case when we have no labels, or (2) x j yj =yi for supervised case, where y i represents the label associated with sample x i .One might imagine that the first sampling strategy will increase the intra-class variance as we may push apart positives and negatives from the same underlying class, while the second would not.We quantitatively measure and report the gap between these two strategies in Table6, which shows that the classification accuracy by the second sampling strategy is 0.81% higher for our objective and 0.62% higher for InfoNCE than the first one.Published as a conference paper at ICLR 2020\nVariational information distillation for knowledge transfer. Shell Xu Sungsoo Ahn, Andreas Hu, Neil D Damianou, Zhenwen Lawrence, Dai, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern Recognition20191315\n\nUnderstanding intermediate layers using linear classifier probes. Guillaume Alain, Yoshua Bengio, arXiv:1610.016442016arXiv preprint\n\nOrestis Plevrakis, and Nikunj Saunshi. A theoretical analysis of contrastive unsupervised representation learning. Sanjeev Arora, Hrishikesh Khandeparkar, Mikhail Khodak, arXiv:1902.092292019arXiv preprint\n\nSoundnet: Learning sound representations from unlabeled video. Yusuf Aytar, Carl Vondrick, Antonio Torralba, Advances in neural information processing systems. 201615\n\nDo deep nets really need to be deep?. Jimmy Ba, Rich Caruana, Advances in neural information processing systems. 2014\n\nModel compression. Cristian Bucilu\u01ce, Rich Caruana, Alexandru Niculescu-Mizil, Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining. the 12th ACM SIGKDD international conference on Knowledge discovery and data miningACM2006\n\nAn analysis of single-layer networks in unsupervised feature learning. Adam Coates, Andrew Ng, Honglak Lee, Proceedings of the fourteenth international conference on artificial intelligence and statistics. the fourteenth international conference on artificial intelligence and statistics2011\n\nImagenet: A large-scale hierarchical image database. Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, Li Fei-Fei, 2009 IEEE conference on computer vision and pattern recognition. Ieee2009\n\nGenerative adversarial nets. Ian Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, Yoshua Bengio, Advances in neural information processing systems. 2014\n\nOn distinguishability criteria for estimating generative models. Ian J Goodfellow, arXiv:1412.65152014arXiv preprint\n\nCross modal distillation for supervision transfer. Saurabh Gupta, Judy Hoffman, Jitendra Malik, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognition2016\n\nNoise-contrastive estimation: A new estimation principle for unnormalized statistical models. Michael Gutmann, Aapo Hyv\u00e4rinen, Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics. the Thirteenth International Conference on Artificial Intelligence and Statistics201015\n\nDeep residual learning for image recognition. Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognition2016614\n\nKnowledge transfer via distillation of activation boundaries formed by hidden neurons. Byeongho Heo, Minsik Lee, Sangdoo Yun, Jin Young Choi, Proceedings of the AAAI Conference on Artificial Intelligence. the AAAI Conference on Artificial Intelligence20193315\n\nDistilling the knowledge in a neural network. Geoffrey Hinton, Oriol Vinyals, Jeff Dean, arXiv:1503.025312015. 1, 2, 5, 7, 131516arXiv preprint\n\nLearning deep representations by mutual information estimation and maximization. Devon Hjelm, Alex Fedorov, Samuel Lavoie-Marchildon, Karan Grewal, Adam Trischler, Yoshua Bengio, arXiv:1808.0667020181arXiv preprint\n\nLearning with side information through modality hallucination. Judy Hoffman, Saurabh Gupta, Trevor Darrell, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern Recognition2016a\n\nCross-modal adaptation for rgb-d detection. Judy Hoffman, Saurabh Gupta, Jian Leong, Sergio Guadarrama, Trevor Darrell, 2016 IEEE International Conference on Robotics and Automation (ICRA). IEEE2016b\n\nLike what you like: Knowledge distill via neuron selectivity transfer. Zehao Huang, Naiyan Wang, arXiv:1707.0121920171315arXiv preprint\n\nParaphrasing complex network: Network compression via factor transfer. Jangho Kim, Seonguk Park, Nojun Kwak, Advances in Neural Information Processing Systems. 20181315\n\nLit: Learned intermediate representation training for model compression. Animesh Koratana, Daniel Kang, Peter Bailis, Matei Zaharia, International Conference on Machine Learning. 2019\n\nLearning multiple layers of features from tiny images. Alex Krizhevsky, Geoffrey Hinton, 2009CiteseerTechnical report\n\nKnowledge distillation by on-the-fly native ensemble. Xiatian Xu Lan, Shaogang Zhu, Gong, Advances in neural information processing systems. 2018\n\nLearning small-size dnn with outputdistribution-based criteria. Jinyu Li, Rui Zhao, Jui-Ting Huang, Yifan Gong, Fifteenth annual conference of the international speech communication association. 2014\n\nRepresentation learning with contrastive predictive coding. Aaron Van Den Oord, Yazhe Li, Oriol Vinyals, arXiv:1807.037482018. 1, 3, 5, 910arXiv preprint\n\nRelational knowledge distillation. Wonpyo Park, Dongju Kim, Yan Lu, Minsu Cho, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern Recognition20191315\n\nLearning deep representations with probabilistic knowledge transfer. Nikolaos Passalis, Anastasios Tefas, Proceedings of the European Conference on Computer Vision (ECCV). the European Conference on Computer Vision (ECCV)20181315\n\nBaoyun Peng, Xiao Jin, Jiaheng Liu, Shunfeng Zhou, Yichao Wu, Yu Liu, Dongsheng Li, Zhaoning Zhang, arXiv:1904.01802Correlation congruence for knowledge distillation. 20191015arXiv preprint\n\nAdriana Romero, Nicolas Ballas, Samira Ebrahimi Kahou, Antoine Chassang, Carlo Gatta, Yoshua Bengio, Fitnets, arXiv:1412.6550Hints for thin deep nets. 2014. 1, 3, 51315arXiv preprint\n\nMo-bilenetv2: Inverted residuals and linear bottlenecks. Mark Sandler, Andrew Howard, Menglong Zhu, Andrey Zhmoginov, Liang-Chieh Chen, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern Recognition201814\n\nIndoor segmentation and support inference from rgbd images. Nathan Silberman, Derek Hoiem, Pushmeet Kohli, Rob Fergus, European Conference on Computer Vision. 2012\n\nVery deep convolutional networks for large-scale image recognition. Karen Simonyan, Andrew Zisserman, arXiv:1409.1556201414arXiv preprint\n\nMnasnet: Platform-aware neural architecture search for mobile. Mingxing Tan, Bo Chen, Ruoming Pang, Vijay Vasudevan, Mark Sandler, Andrew Howard, Quoc V Le, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern Recognition201914\n\nYonglong Tian, Dilip Krishnan, Phillip Isola, arXiv:1906.05849Contrastive multiview coding. 2019arXiv preprint\n\nSimilarity-preserving knowledge distillation. Frederick Tung, Greg Mori, arXiv:1907.0968220191015arXiv preprint\n\nUnsupervised feature learning via nonparametric instance discrimination. Zhirong Wu, Yuanjun Xiong, Stella X Yu, Dahua Lin, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern Recognition2018\n\nA gift from knowledge distillation: Fast optimization, network minimization and transfer learning. Junho Yim, Donggyu Joo, Jihoon Bae, Junmo Kim, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern Recognition2017. 3, 61315\n\nPaying more attention to attention: Improving the performance of convolutional neural networks via attention transfer. Sergey Zagoruyko, Nikos Komodakis, arXiv:1612.039282016a. 1, 2, 3, 5, 6, 7, 131516arXiv preprint\n\nSergey Zagoruyko, Nikos Komodakis, arXiv:1605.07146Wide residual networks. 2016b614arXiv preprint\n\nSplit-brain autoencoders: Unsupervised learning by cross-channel prediction. Richard Zhang, Phillip Isola, Alexei A Efros, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern Recognition2017\n\nShufflenet: An extremely efficient convolutional neural network for mobile devices. Xiangyu Zhang, Xinyu Zhou, Mengxiao Lin, Jian Sun, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern Recognition2018a14\n\n18 6 APPENDIX 6.1 OTHER METHODS We compare to the following other state-of-the-art methods from the literature: 1. Knowledge Distillation (KD. Ying Zhang, Tao Xiang, Timothy M Hospedales, Huchuan Lu, ; Hinton, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern Recognition2018b. 201515Deep mutual learning\n\nFitnets: Hints for thin deep nets. Romero, 2014\n\n. Attention Transfer (AT) (Zagoruyko & Komodakis. 2016a\n\nSimilarity-Preserving Knowledge Distillation (SP) (Tung & Mori. 2019\n\n. Peng, Correlation Congruence (CC2019\n\nVariational information distillation for knowledge transfer (VID. Ahn , 2019\n\n. Park, Relational Knowledge Distillation (RKD. 2019\n\nLearning deep representations with probabilistic knowledge transfer (PKT). Passalis & Tefas2018\n\nKnowledge transfer via distillation of activation boundaries formed by hidden neurons (AB. Heo, 2019\n\nParaphrasing complex network: Network compression via factor transfer (FT. Kim, 2018\n\nA gift from knowledge distillation: Fast optimization, network minimization and transfer learning (FSP. Yim, 2017\n\nLike what you like: Knowledge distill via neuron selectivity transfer (NST). 2017Huang & Wang\n\n. CONTRASTIVE LOSS -DETAILS. \n\nWe wish to model some true distribution q(C|T = t, S = s). C is a binary variable, so we can model q(C|T = t, S = s) as a Bernoulli distribution with a single parameter h(S = s. S Proof That H * (t, S) ; ) = Q(c = 1|t, ( Fitnets, Romero, 20141100\n\n. At (zagoruyko, Komodakis, 2016a1000\n\n. Sp (tung, Mori, 20193000\n\n. Cc (peng, = 0.022019\n\n. Vid (ahn, 2019\n\n2019): \u03b2 1 = 25 for distance and \u03b2 2 = 50 for angle. Rkd (park, For this loss, we combine both term following the original paper\n\n. Pkt (passalis, Tefas, \u03b2 = 300002018\n\n2019): \u03b2 = 0, distillation happens in a separate pre-training stage where only distillation objective applies. Ab (heo, \n\n. Ft (kim, \u03b2 = 5002018\n\n2017): \u03b2 = 0, distillation happens in a separate pre-training stage where only distillation objective applies. Fsp (yim, \n\n. Nst ( Huang, Wang , 201750\n\nHinton, CRD: \u03b2 = 0.8general \u03b2 \u2208 [0.5, 1.5] works reasonably well. For KD. 2015we follow Eq. 20 and set \u03b1 = 0.9 and T = 4\n\nVISUALIZATION OF THE CORRELATION DISCREPANCY We visualize the correlation discrepancy for different distillation objectives across various combinations of student and teacher networks. As shown in Fig. 6, our contrastive distillation objective siginificantly outperforms other objectives, in terms of minimizing the correlation discrepancy between student and teacher networks. The normalized correlation coefficients are computed at the logit layer\n\nCOMBINING DIFFERENT DISTILLATION OBJECTIVES. \n", "annotations": {"author": "[{\"end\":85,\"start\":54},{\"end\":96,\"start\":86},{\"end\":132,\"start\":97},{\"end\":164,\"start\":133}]", "publisher": null, "author_last_name": "[{\"end\":67,\"start\":63},{\"end\":95,\"start\":90},{\"end\":111,\"start\":103},{\"end\":146,\"start\":141}]", "author_first_name": "[{\"end\":62,\"start\":54},{\"end\":89,\"start\":86},{\"end\":102,\"start\":97},{\"end\":140,\"start\":133}]", "author_affiliation": null, "title": "[{\"end\":40,\"start\":1},{\"end\":204,\"start\":165}]", "venue": null, "abstract": "[{\"end\":1420,\"start\":274}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b14\"},\"end\":1609,\"start\":1589},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2039,\"start\":2019},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":2072,\"start\":2052},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":2395,\"start\":2374},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":3166,\"start\":3139},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":3184,\"start\":3166},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3203,\"start\":3184},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":3222,\"start\":3203},{\"end\":3597,\"start\":3568},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":3619,\"start\":3599},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":44645,\"start\":44624},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":44670,\"start\":44650},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":45082,\"start\":45061},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":45143,\"start\":45123},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":45584,\"start\":45567},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":45634,\"start\":45613},{\"end\":45686,\"start\":45656},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":46464,\"start\":46443},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":46720,\"start\":46702},{\"end\":46739,\"start\":46720},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":46756,\"start\":46739},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":46773,\"start\":46756},{\"end\":46792,\"start\":46773},{\"end\":46809,\"start\":46792},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":46831,\"start\":46809},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":46986,\"start\":46967},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":47211,\"start\":47192},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":47237,\"start\":47211},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":47474,\"start\":47454},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":47575,\"start\":47550},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":47597,\"start\":47579},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":47663,\"start\":47637},{\"end\":51726,\"start\":51722},{\"end\":52018,\"start\":52014},{\"end\":52861,\"start\":52857},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":53223,\"start\":53196},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":53239,\"start\":53223},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":53306,\"start\":53287},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":53646,\"start\":53630},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":53974,\"start\":53954},{\"end\":55152,\"start\":55114},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":55184,\"start\":55164},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":55526,\"start\":55507},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":55550,\"start\":55528},{\"end\":55552,\"start\":55550},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":56115,\"start\":56097},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":56163,\"start\":56143},{\"end\":56205,\"start\":56175},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":56602,\"start\":56585},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":56654,\"start\":56624},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":60983,\"start\":60961},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":61002,\"start\":60983},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":63417,\"start\":63387},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":63507,\"start\":63490},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":63802,\"start\":63785},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":63921,\"start\":63900},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":64009,\"start\":63981},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":64133,\"start\":64112},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":64166,\"start\":64148},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":65897,\"start\":65876},{\"end\":67228,\"start\":67163},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":106509,\"start\":106482},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":110195,\"start\":110175}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":75002,\"start\":67489},{\"attributes\":{\"id\":\"fig_1\"},\"end\":75452,\"start\":75003},{\"attributes\":{\"id\":\"fig_2\"},\"end\":75902,\"start\":75453},{\"attributes\":{\"id\":\"fig_3\"},\"end\":76352,\"start\":75903},{\"attributes\":{\"id\":\"fig_4\"},\"end\":76718,\"start\":76353},{\"attributes\":{\"id\":\"fig_5\"},\"end\":76986,\"start\":76719},{\"attributes\":{\"id\":\"fig_6\"},\"end\":77352,\"start\":76987},{\"attributes\":{\"id\":\"fig_7\"},\"end\":77620,\"start\":77353},{\"attributes\":{\"id\":\"fig_8\"},\"end\":77986,\"start\":77621},{\"attributes\":{\"id\":\"fig_9\"},\"end\":78254,\"start\":77987},{\"attributes\":{\"id\":\"fig_10\"},\"end\":78668,\"start\":78255},{\"attributes\":{\"id\":\"fig_11\"},\"end\":79102,\"start\":78669},{\"attributes\":{\"id\":\"fig_12\"},\"end\":79536,\"start\":79103},{\"attributes\":{\"id\":\"fig_13\"},\"end\":79680,\"start\":79537},{\"attributes\":{\"id\":\"fig_14\"},\"end\":79824,\"start\":79681},{\"attributes\":{\"id\":\"fig_15\"},\"end\":79968,\"start\":79825},{\"attributes\":{\"id\":\"fig_16\"},\"end\":80158,\"start\":79969},{\"attributes\":{\"id\":\"fig_17\"},\"end\":80340,\"start\":80159},{\"attributes\":{\"id\":\"fig_18\"},\"end\":80522,\"start\":80341},{\"attributes\":{\"id\":\"fig_19\"},\"end\":80704,\"start\":80523},{\"attributes\":{\"id\":\"fig_20\"},\"end\":81104,\"start\":80705},{\"attributes\":{\"id\":\"fig_21\"},\"end\":81468,\"start\":81105},{\"attributes\":{\"id\":\"fig_22\"},\"end\":81832,\"start\":81469},{\"attributes\":{\"id\":\"fig_23\"},\"end\":82370,\"start\":81833},{\"attributes\":{\"id\":\"fig_24\"},\"end\":82953,\"start\":82371},{\"attributes\":{\"id\":\"fig_25\"},\"end\":83387,\"start\":82954},{\"attributes\":{\"id\":\"fig_26\"},\"end\":83821,\"start\":83388},{\"attributes\":{\"id\":\"fig_27\"},\"end\":84255,\"start\":83822},{\"attributes\":{\"id\":\"fig_28\"},\"end\":100942,\"start\":84256},{\"attributes\":{\"id\":\"fig_29\"},\"end\":101376,\"start\":100943},{\"attributes\":{\"id\":\"fig_30\"},\"end\":101810,\"start\":101377},{\"attributes\":{\"id\":\"fig_31\"},\"end\":102244,\"start\":101811},{\"attributes\":{\"id\":\"fig_32\"},\"end\":105703,\"start\":102245},{\"attributes\":{\"id\":\"fig_33\"},\"end\":106155,\"start\":105704},{\"attributes\":{\"id\":\"fig_34\"},\"end\":107087,\"start\":106156},{\"attributes\":{\"id\":\"fig_35\"},\"end\":108090,\"start\":107088},{\"attributes\":{\"id\":\"fig_36\"},\"end\":108426,\"start\":108091},{\"attributes\":{\"id\":\"fig_37\"},\"end\":108543,\"start\":108427},{\"attributes\":{\"id\":\"fig_38\"},\"end\":109538,\"start\":108544},{\"attributes\":{\"id\":\"fig_39\"},\"end\":109738,\"start\":109539},{\"attributes\":{\"id\":\"fig_40\"},\"end\":110056,\"start\":109739},{\"attributes\":{\"id\":\"fig_42\"},\"end\":110836,\"start\":110057},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":113443,\"start\":110837},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":113674,\"start\":113444},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":113963,\"start\":113675},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":114635,\"start\":113964},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":115422,\"start\":114636},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":116566,\"start\":115423},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":118841,\"start\":116567}]", "paragraph": "[{\"end\":2241,\"start\":1436},{\"end\":2940,\"start\":2243},{\"end\":3779,\"start\":2942},{\"end\":8210,\"start\":8053},{\"end\":9236,\"start\":9079},{\"end\":10262,\"start\":10105},{\"end\":11277,\"start\":11131},{\"end\":17496,\"start\":17083},{\"end\":29016,\"start\":27783},{\"end\":44281,\"start\":44200},{\"end\":44369,\"start\":44283},{\"end\":44587,\"start\":44371},{\"end\":45635,\"start\":44604},{\"end\":45960,\"start\":45637},{\"end\":47739,\"start\":46009},{\"end\":48117,\"start\":47750},{\"end\":48659,\"start\":48138},{\"end\":49264,\"start\":48761},{\"end\":49611,\"start\":49319},{\"end\":49821,\"start\":49655},{\"end\":49854,\"start\":49823},{\"end\":49919,\"start\":49856},{\"end\":50160,\"start\":50047},{\"end\":50813,\"start\":50225},{\"end\":51196,\"start\":50945},{\"end\":51517,\"start\":51252},{\"end\":51730,\"start\":51572},{\"end\":52201,\"start\":51917},{\"end\":52670,\"start\":52360},{\"end\":53483,\"start\":52672},{\"end\":53869,\"start\":53485},{\"end\":54252,\"start\":53906},{\"end\":54504,\"start\":54314},{\"end\":55597,\"start\":54534},{\"end\":56398,\"start\":55628},{\"end\":57619,\"start\":56469},{\"end\":58086,\"start\":57643},{\"end\":58179,\"start\":58088},{\"end\":58282,\"start\":58181},{\"end\":58471,\"start\":58284},{\"end\":58530,\"start\":58473},{\"end\":59751,\"start\":58569},{\"end\":60267,\"start\":59776},{\"end\":60448,\"start\":60269},{\"end\":61565,\"start\":60450},{\"end\":62072,\"start\":61611},{\"end\":62798,\"start\":62109},{\"end\":62961,\"start\":62800},{\"end\":63091,\"start\":62963},{\"end\":63333,\"start\":63093},{\"end\":63481,\"start\":63359},{\"end\":63776,\"start\":63483},{\"end\":63886,\"start\":63778},{\"end\":63975,\"start\":63888},{\"end\":64097,\"start\":63977},{\"end\":64256,\"start\":64099},{\"end\":64332,\"start\":64283},{\"end\":64664,\"start\":64334},{\"end\":64800,\"start\":64666},{\"end\":64941,\"start\":64802},{\"end\":65223,\"start\":64979},{\"end\":65519,\"start\":65225},{\"end\":65840,\"start\":65580},{\"end\":66929,\"start\":65873},{\"end\":67488,\"start\":66931},{\"end\":75001,\"start\":67492},{\"end\":75451,\"start\":75006},{\"end\":75901,\"start\":75456},{\"end\":76351,\"start\":75906},{\"end\":76717,\"start\":76356},{\"end\":76985,\"start\":76722},{\"end\":77351,\"start\":76990},{\"end\":77619,\"start\":77356},{\"end\":77985,\"start\":77624},{\"end\":78253,\"start\":77990},{\"end\":78667,\"start\":78258},{\"end\":79101,\"start\":78672},{\"end\":79535,\"start\":79106},{\"end\":79679,\"start\":79540},{\"end\":79823,\"start\":79684},{\"end\":79967,\"start\":79828},{\"end\":80157,\"start\":79972},{\"end\":80339,\"start\":80162},{\"end\":80521,\"start\":80344},{\"end\":80703,\"start\":80526},{\"end\":81103,\"start\":80708},{\"end\":81467,\"start\":81108},{\"end\":81831,\"start\":81472},{\"end\":82369,\"start\":81836},{\"end\":82952,\"start\":82374},{\"end\":83386,\"start\":82957},{\"end\":83820,\"start\":83391},{\"end\":84254,\"start\":83825},{\"end\":100941,\"start\":84259},{\"end\":101375,\"start\":100946},{\"end\":101809,\"start\":101380},{\"end\":102243,\"start\":101814},{\"end\":105702,\"start\":102248},{\"end\":106154,\"start\":105718},{\"end\":107086,\"start\":106175},{\"end\":108089,\"start\":107102},{\"end\":108425,\"start\":108105},{\"end\":108542,\"start\":108441},{\"end\":109537,\"start\":108548},{\"end\":109737,\"start\":109542},{\"end\":110055,\"start\":109743},{\"end\":110835,\"start\":110071},{\"end\":111328,\"start\":110850},{\"end\":113673,\"start\":113457},{\"end\":113962,\"start\":113678},{\"end\":114481,\"start\":113977},{\"end\":115040,\"start\":114649},{\"end\":115421,\"start\":115265},{\"end\":115832,\"start\":115436},{\"end\":116565,\"start\":116083},{\"end\":116803,\"start\":116580}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":5292,\"start\":3780},{\"attributes\":{\"id\":\"formula_1\"},\"end\":5871,\"start\":5292},{\"attributes\":{\"id\":\"formula_2\"},\"end\":6450,\"start\":5871},{\"attributes\":{\"id\":\"formula_3\"},\"end\":8052,\"start\":6450},{\"attributes\":{\"id\":\"formula_4\"},\"end\":9078,\"start\":8211},{\"attributes\":{\"id\":\"formula_5\"},\"end\":10104,\"start\":9237},{\"attributes\":{\"id\":\"formula_6\"},\"end\":11130,\"start\":10263},{\"attributes\":{\"id\":\"formula_7\"},\"end\":11941,\"start\":11278},{\"attributes\":{\"id\":\"formula_8\"},\"end\":12084,\"start\":11941},{\"attributes\":{\"id\":\"formula_9\"},\"end\":12339,\"start\":12084},{\"attributes\":{\"id\":\"formula_10\"},\"end\":12482,\"start\":12339},{\"attributes\":{\"id\":\"formula_11\"},\"end\":12737,\"start\":12482},{\"attributes\":{\"id\":\"formula_12\"},\"end\":12880,\"start\":12737},{\"attributes\":{\"id\":\"formula_13\"},\"end\":13135,\"start\":12880},{\"attributes\":{\"id\":\"formula_14\"},\"end\":17082,\"start\":13135},{\"attributes\":{\"id\":\"formula_15\"},\"end\":18082,\"start\":17497},{\"attributes\":{\"id\":\"formula_16\"},\"end\":18661,\"start\":18082},{\"attributes\":{\"id\":\"formula_17\"},\"end\":19636,\"start\":18661},{\"attributes\":{\"id\":\"formula_18\"},\"end\":19711,\"start\":19636},{\"attributes\":{\"id\":\"formula_19\"},\"end\":21226,\"start\":19711},{\"attributes\":{\"id\":\"formula_20\"},\"end\":22095,\"start\":21226},{\"attributes\":{\"id\":\"formula_21\"},\"end\":22964,\"start\":22095},{\"attributes\":{\"id\":\"formula_22\"},\"end\":23833,\"start\":22964},{\"attributes\":{\"id\":\"formula_23\"},\"end\":27782,\"start\":23833},{\"attributes\":{\"id\":\"formula_24\"},\"end\":29888,\"start\":29017},{\"attributes\":{\"id\":\"formula_25\"},\"end\":30751,\"start\":29888},{\"attributes\":{\"id\":\"formula_26\"},\"end\":31614,\"start\":30751},{\"attributes\":{\"id\":\"formula_27\"},\"end\":36740,\"start\":31614},{\"attributes\":{\"id\":\"formula_28\"},\"end\":37389,\"start\":36740},{\"attributes\":{\"id\":\"formula_29\"},\"end\":38038,\"start\":37389},{\"attributes\":{\"id\":\"formula_30\"},\"end\":38513,\"start\":38038},{\"attributes\":{\"id\":\"formula_31\"},\"end\":38988,\"start\":38513},{\"attributes\":{\"id\":\"formula_32\"},\"end\":39567,\"start\":38988},{\"attributes\":{\"id\":\"formula_33\"},\"end\":40146,\"start\":39567},{\"attributes\":{\"id\":\"formula_34\"},\"end\":40725,\"start\":40146},{\"attributes\":{\"id\":\"formula_35\"},\"end\":41304,\"start\":40725},{\"attributes\":{\"id\":\"formula_36\"},\"end\":41883,\"start\":41304},{\"attributes\":{\"id\":\"formula_37\"},\"end\":42462,\"start\":41883},{\"attributes\":{\"id\":\"formula_38\"},\"end\":43041,\"start\":42462},{\"attributes\":{\"id\":\"formula_39\"},\"end\":43620,\"start\":43041},{\"attributes\":{\"id\":\"formula_40\"},\"end\":44199,\"start\":43620},{\"attributes\":{\"id\":\"formula_41\"},\"end\":46008,\"start\":45961},{\"attributes\":{\"id\":\"formula_42\"},\"end\":48682,\"start\":48660},{\"attributes\":{\"id\":\"formula_43\"},\"end\":48721,\"start\":48682},{\"attributes\":{\"id\":\"formula_44\"},\"end\":48760,\"start\":48721},{\"attributes\":{\"id\":\"formula_45\"},\"end\":49318,\"start\":49265},{\"attributes\":{\"id\":\"formula_46\"},\"end\":49654,\"start\":49612},{\"attributes\":{\"id\":\"formula_49\"},\"end\":50046,\"start\":49920},{\"attributes\":{\"id\":\"formula_50\"},\"end\":50224,\"start\":50161},{\"attributes\":{\"id\":\"formula_51\"},\"end\":50944,\"start\":50814},{\"attributes\":{\"id\":\"formula_52\"},\"end\":51251,\"start\":51197},{\"attributes\":{\"id\":\"formula_53\"},\"end\":51571,\"start\":51518},{\"attributes\":{\"id\":\"formula_54\"},\"end\":51888,\"start\":51731},{\"attributes\":{\"id\":\"formula_55\"},\"end\":51916,\"start\":51888},{\"attributes\":{\"id\":\"formula_56\"},\"end\":52359,\"start\":52202},{\"attributes\":{\"id\":\"formula_57\"},\"end\":54312,\"start\":54253},{\"attributes\":{\"id\":\"formula_58\"},\"end\":54313,\"start\":54312},{\"attributes\":{\"id\":\"formula_59\"},\"end\":56448,\"start\":56399},{\"attributes\":{\"id\":\"formula_62\"},\"end\":64978,\"start\":64942}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":17460,\"start\":17427},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":17496,\"start\":17461},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":58303,\"start\":58302},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":59176,\"start\":59175},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":59642,\"start\":59641},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":65232,\"start\":65231},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":65601,\"start\":65600},{\"end\":65759,\"start\":65758},{\"end\":66283,\"start\":66282},{\"end\":66869,\"start\":66868},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":67019,\"start\":67017},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":67098,\"start\":67096}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1434,\"start\":1422},{\"attributes\":{\"n\":\"2\"},\"end\":44602,\"start\":44590},{\"attributes\":{\"n\":\"3\"},\"end\":47748,\"start\":47742},{\"attributes\":{\"n\":\"3.1\"},\"end\":48136,\"start\":48120},{\"attributes\":{\"n\":\"3.2\"},\"end\":53904,\"start\":53872},{\"attributes\":{\"n\":\"3.3\"},\"end\":54532,\"start\":54507},{\"attributes\":{\"n\":\"3.4\"},\"end\":55626,\"start\":55600},{\"attributes\":{\"n\":\"4.1\"},\"end\":56467,\"start\":56450},{\"end\":57641,\"start\":57622},{\"end\":58567,\"start\":58533},{\"attributes\":{\"n\":\"4.2\"},\"end\":59774,\"start\":59754},{\"attributes\":{\"n\":\"4.5\"},\"end\":61609,\"start\":61568},{\"end\":62094,\"start\":62075},{\"attributes\":{\"n\":\"5\"},\"end\":62107,\"start\":62097},{\"attributes\":{\"n\":\"6.3\"},\"end\":63357,\"start\":63336},{\"attributes\":{\"n\":\"6.4\"},\"end\":64281,\"start\":64259},{\"attributes\":{\"n\":\"6.7\"},\"end\":65578,\"start\":65522},{\"attributes\":{\"n\":\"6.8\"},\"end\":65871,\"start\":65843},{\"end\":105715,\"start\":105705},{\"end\":106172,\"start\":106157},{\"end\":107099,\"start\":107089},{\"end\":108102,\"start\":108092},{\"end\":108438,\"start\":108428},{\"end\":108546,\"start\":108545},{\"end\":109741,\"start\":109740},{\"end\":110068,\"start\":110058},{\"end\":110847,\"start\":110838},{\"end\":113454,\"start\":113445},{\"end\":113974,\"start\":113965},{\"end\":114646,\"start\":114637},{\"end\":115433,\"start\":115424},{\"end\":116577,\"start\":116568}]", "table": "[{\"end\":113443,\"start\":111329},{\"end\":114635,\"start\":114482},{\"end\":115264,\"start\":115041},{\"end\":116082,\"start\":115833},{\"end\":118841,\"start\":116804}]", "figure_caption": "[{\"end\":75002,\"start\":67491},{\"end\":75452,\"start\":75005},{\"end\":75902,\"start\":75455},{\"end\":76352,\"start\":75905},{\"end\":76718,\"start\":76355},{\"end\":76986,\"start\":76721},{\"end\":77352,\"start\":76989},{\"end\":77620,\"start\":77355},{\"end\":77986,\"start\":77623},{\"end\":78254,\"start\":77989},{\"end\":78668,\"start\":78257},{\"end\":79102,\"start\":78671},{\"end\":79536,\"start\":79105},{\"end\":79680,\"start\":79539},{\"end\":79824,\"start\":79683},{\"end\":79968,\"start\":79827},{\"end\":80158,\"start\":79971},{\"end\":80340,\"start\":80161},{\"end\":80522,\"start\":80343},{\"end\":80704,\"start\":80525},{\"end\":81104,\"start\":80707},{\"end\":81468,\"start\":81107},{\"end\":81832,\"start\":81471},{\"end\":82370,\"start\":81835},{\"end\":82953,\"start\":82373},{\"end\":83387,\"start\":82956},{\"end\":83821,\"start\":83390},{\"end\":84255,\"start\":83824},{\"end\":100942,\"start\":84258},{\"end\":101376,\"start\":100945},{\"end\":101810,\"start\":101379},{\"end\":102244,\"start\":101813},{\"end\":105703,\"start\":102247},{\"end\":106155,\"start\":105717},{\"end\":107087,\"start\":106174},{\"end\":108090,\"start\":107101},{\"end\":108426,\"start\":108104},{\"end\":108543,\"start\":108440},{\"end\":109538,\"start\":108547},{\"end\":109738,\"start\":109541},{\"end\":110056,\"start\":109742},{\"end\":110836,\"start\":110070},{\"end\":111329,\"start\":110849},{\"end\":113674,\"start\":113456},{\"end\":113963,\"start\":113677},{\"end\":114482,\"start\":113976},{\"end\":115041,\"start\":114648},{\"end\":115833,\"start\":115435},{\"end\":116804,\"start\":116579}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_33\"},\"end\":47948,\"start\":47947},{\"attributes\":{\"ref_id\":\"fig_33\"},\"end\":54582,\"start\":54581},{\"attributes\":{\"ref_id\":\"fig_35\"},\"end\":57687,\"start\":57686},{\"attributes\":{\"ref_id\":\"fig_36\"},\"end\":61327,\"start\":61326},{\"attributes\":{\"ref_id\":\"fig_37\"},\"end\":61940,\"start\":61939}]", "bib_author_first_name": "[{\"end\":121713,\"start\":121708},{\"end\":121716,\"start\":121714},{\"end\":121737,\"start\":121730},{\"end\":121746,\"start\":121742},{\"end\":121748,\"start\":121747},{\"end\":121766,\"start\":121759},{\"end\":122008,\"start\":121999},{\"end\":122022,\"start\":122016},{\"end\":122189,\"start\":122182},{\"end\":122207,\"start\":122197},{\"end\":122229,\"start\":122222},{\"end\":122342,\"start\":122337},{\"end\":122354,\"start\":122350},{\"end\":122372,\"start\":122365},{\"end\":122485,\"start\":122480},{\"end\":122494,\"start\":122490},{\"end\":122588,\"start\":122580},{\"end\":122602,\"start\":122598},{\"end\":122621,\"start\":122612},{\"end\":122906,\"start\":122902},{\"end\":122921,\"start\":122915},{\"end\":122933,\"start\":122926},{\"end\":123180,\"start\":123177},{\"end\":123190,\"start\":123187},{\"end\":123204,\"start\":123197},{\"end\":123219,\"start\":123213},{\"end\":123227,\"start\":123224},{\"end\":123234,\"start\":123232},{\"end\":123351,\"start\":123348},{\"end\":123368,\"start\":123364},{\"end\":123389,\"start\":123384},{\"end\":123401,\"start\":123397},{\"end\":123411,\"start\":123406},{\"end\":123433,\"start\":123426},{\"end\":123446,\"start\":123441},{\"end\":123464,\"start\":123458},{\"end\":123598,\"start\":123595},{\"end\":123600,\"start\":123599},{\"end\":123706,\"start\":123699},{\"end\":123718,\"start\":123714},{\"end\":123736,\"start\":123728},{\"end\":123992,\"start\":123985},{\"end\":124006,\"start\":124002},{\"end\":124258,\"start\":124251},{\"end\":124270,\"start\":124263},{\"end\":124286,\"start\":124278},{\"end\":124296,\"start\":124292},{\"end\":124547,\"start\":124539},{\"end\":124559,\"start\":124553},{\"end\":124572,\"start\":124565},{\"end\":124581,\"start\":124578},{\"end\":124587,\"start\":124582},{\"end\":124767,\"start\":124759},{\"end\":124781,\"start\":124776},{\"end\":124795,\"start\":124791},{\"end\":124944,\"start\":124939},{\"end\":124956,\"start\":124952},{\"end\":124972,\"start\":124966},{\"end\":124997,\"start\":124992},{\"end\":125010,\"start\":125006},{\"end\":125028,\"start\":125022},{\"end\":125141,\"start\":125137},{\"end\":125158,\"start\":125151},{\"end\":125172,\"start\":125166},{\"end\":125378,\"start\":125374},{\"end\":125395,\"start\":125388},{\"end\":125407,\"start\":125403},{\"end\":125421,\"start\":125415},{\"end\":125440,\"start\":125434},{\"end\":125607,\"start\":125602},{\"end\":125621,\"start\":125615},{\"end\":125745,\"start\":125739},{\"end\":125758,\"start\":125751},{\"end\":125770,\"start\":125765},{\"end\":125918,\"start\":125911},{\"end\":125935,\"start\":125929},{\"end\":125947,\"start\":125942},{\"end\":125961,\"start\":125956},{\"end\":126082,\"start\":126078},{\"end\":126103,\"start\":126095},{\"end\":126203,\"start\":126196},{\"end\":126220,\"start\":126212},{\"end\":126358,\"start\":126353},{\"end\":126366,\"start\":126363},{\"end\":126381,\"start\":126373},{\"end\":126394,\"start\":126389},{\"end\":126555,\"start\":126550},{\"end\":126575,\"start\":126570},{\"end\":126585,\"start\":126580},{\"end\":126686,\"start\":126680},{\"end\":126699,\"start\":126693},{\"end\":126708,\"start\":126705},{\"end\":126718,\"start\":126713},{\"end\":126952,\"start\":126944},{\"end\":126973,\"start\":126963},{\"end\":127112,\"start\":127106},{\"end\":127123,\"start\":127119},{\"end\":127136,\"start\":127129},{\"end\":127150,\"start\":127142},{\"end\":127163,\"start\":127157},{\"end\":127170,\"start\":127168},{\"end\":127185,\"start\":127176},{\"end\":127198,\"start\":127190},{\"end\":127304,\"start\":127297},{\"end\":127320,\"start\":127313},{\"end\":127335,\"start\":127329},{\"end\":127344,\"start\":127336},{\"end\":127359,\"start\":127352},{\"end\":127375,\"start\":127370},{\"end\":127389,\"start\":127383},{\"end\":127542,\"start\":127538},{\"end\":127558,\"start\":127552},{\"end\":127575,\"start\":127567},{\"end\":127587,\"start\":127581},{\"end\":127610,\"start\":127599},{\"end\":127832,\"start\":127826},{\"end\":127849,\"start\":127844},{\"end\":127865,\"start\":127857},{\"end\":127876,\"start\":127873},{\"end\":128004,\"start\":127999},{\"end\":128021,\"start\":128015},{\"end\":128141,\"start\":128133},{\"end\":128149,\"start\":128147},{\"end\":128163,\"start\":128156},{\"end\":128175,\"start\":128170},{\"end\":128191,\"start\":128187},{\"end\":128207,\"start\":128201},{\"end\":128222,\"start\":128216},{\"end\":128384,\"start\":128376},{\"end\":128396,\"start\":128391},{\"end\":128414,\"start\":128407},{\"end\":128543,\"start\":128534},{\"end\":128554,\"start\":128550},{\"end\":128681,\"start\":128674},{\"end\":128693,\"start\":128686},{\"end\":128707,\"start\":128701},{\"end\":128709,\"start\":128708},{\"end\":128719,\"start\":128714},{\"end\":128976,\"start\":128971},{\"end\":128989,\"start\":128982},{\"end\":129001,\"start\":128995},{\"end\":129012,\"start\":129007},{\"end\":129300,\"start\":129294},{\"end\":129317,\"start\":129312},{\"end\":129398,\"start\":129392},{\"end\":129415,\"start\":129410},{\"end\":129575,\"start\":129568},{\"end\":129590,\"start\":129583},{\"end\":129604,\"start\":129598},{\"end\":129606,\"start\":129605},{\"end\":129852,\"start\":129845},{\"end\":129865,\"start\":129860},{\"end\":129880,\"start\":129872},{\"end\":129890,\"start\":129886},{\"end\":130193,\"start\":130189},{\"end\":130204,\"start\":130201},{\"end\":130219,\"start\":130212},{\"end\":130221,\"start\":130220},{\"end\":130241,\"start\":130234},{\"end\":130247,\"start\":130246},{\"end\":130717,\"start\":130714},{\"end\":131485,\"start\":131484},{\"end\":131509,\"start\":131505},{\"end\":131526,\"start\":131525},{\"end\":132108,\"start\":132103},{\"end\":132120,\"start\":132116}]", "bib_author_last_name": "[{\"end\":121728,\"start\":121717},{\"end\":121740,\"start\":121738},{\"end\":121757,\"start\":121749},{\"end\":121775,\"start\":121767},{\"end\":121780,\"start\":121777},{\"end\":122014,\"start\":122009},{\"end\":122029,\"start\":122023},{\"end\":122195,\"start\":122190},{\"end\":122220,\"start\":122208},{\"end\":122236,\"start\":122230},{\"end\":122348,\"start\":122343},{\"end\":122363,\"start\":122355},{\"end\":122381,\"start\":122373},{\"end\":122488,\"start\":122486},{\"end\":122502,\"start\":122495},{\"end\":122596,\"start\":122589},{\"end\":122610,\"start\":122603},{\"end\":122637,\"start\":122622},{\"end\":122913,\"start\":122907},{\"end\":122924,\"start\":122922},{\"end\":122937,\"start\":122934},{\"end\":123185,\"start\":123181},{\"end\":123195,\"start\":123191},{\"end\":123211,\"start\":123205},{\"end\":123222,\"start\":123220},{\"end\":123230,\"start\":123228},{\"end\":123242,\"start\":123235},{\"end\":123362,\"start\":123352},{\"end\":123382,\"start\":123369},{\"end\":123395,\"start\":123390},{\"end\":123404,\"start\":123402},{\"end\":123424,\"start\":123412},{\"end\":123439,\"start\":123434},{\"end\":123456,\"start\":123447},{\"end\":123471,\"start\":123465},{\"end\":123611,\"start\":123601},{\"end\":123712,\"start\":123707},{\"end\":123726,\"start\":123719},{\"end\":123742,\"start\":123737},{\"end\":124000,\"start\":123993},{\"end\":124016,\"start\":124007},{\"end\":124261,\"start\":124259},{\"end\":124276,\"start\":124271},{\"end\":124290,\"start\":124287},{\"end\":124300,\"start\":124297},{\"end\":124551,\"start\":124548},{\"end\":124563,\"start\":124560},{\"end\":124576,\"start\":124573},{\"end\":124592,\"start\":124588},{\"end\":124774,\"start\":124768},{\"end\":124789,\"start\":124782},{\"end\":124800,\"start\":124796},{\"end\":124950,\"start\":124945},{\"end\":124964,\"start\":124957},{\"end\":124990,\"start\":124973},{\"end\":125004,\"start\":124998},{\"end\":125020,\"start\":125011},{\"end\":125035,\"start\":125029},{\"end\":125149,\"start\":125142},{\"end\":125164,\"start\":125159},{\"end\":125180,\"start\":125173},{\"end\":125386,\"start\":125379},{\"end\":125401,\"start\":125396},{\"end\":125413,\"start\":125408},{\"end\":125432,\"start\":125422},{\"end\":125448,\"start\":125441},{\"end\":125613,\"start\":125608},{\"end\":125626,\"start\":125622},{\"end\":125749,\"start\":125746},{\"end\":125763,\"start\":125759},{\"end\":125775,\"start\":125771},{\"end\":125927,\"start\":125919},{\"end\":125940,\"start\":125936},{\"end\":125954,\"start\":125948},{\"end\":125969,\"start\":125962},{\"end\":126093,\"start\":126083},{\"end\":126110,\"start\":126104},{\"end\":126210,\"start\":126204},{\"end\":126224,\"start\":126221},{\"end\":126230,\"start\":126226},{\"end\":126361,\"start\":126359},{\"end\":126371,\"start\":126367},{\"end\":126387,\"start\":126382},{\"end\":126399,\"start\":126395},{\"end\":126568,\"start\":126556},{\"end\":126578,\"start\":126576},{\"end\":126593,\"start\":126586},{\"end\":126691,\"start\":126687},{\"end\":126703,\"start\":126700},{\"end\":126711,\"start\":126709},{\"end\":126722,\"start\":126719},{\"end\":126961,\"start\":126953},{\"end\":126979,\"start\":126974},{\"end\":127117,\"start\":127113},{\"end\":127127,\"start\":127124},{\"end\":127140,\"start\":127137},{\"end\":127155,\"start\":127151},{\"end\":127166,\"start\":127164},{\"end\":127174,\"start\":127171},{\"end\":127188,\"start\":127186},{\"end\":127204,\"start\":127199},{\"end\":127311,\"start\":127305},{\"end\":127327,\"start\":127321},{\"end\":127350,\"start\":127345},{\"end\":127368,\"start\":127360},{\"end\":127381,\"start\":127376},{\"end\":127396,\"start\":127390},{\"end\":127405,\"start\":127398},{\"end\":127550,\"start\":127543},{\"end\":127565,\"start\":127559},{\"end\":127579,\"start\":127576},{\"end\":127597,\"start\":127588},{\"end\":127615,\"start\":127611},{\"end\":127842,\"start\":127833},{\"end\":127855,\"start\":127850},{\"end\":127871,\"start\":127866},{\"end\":127883,\"start\":127877},{\"end\":128013,\"start\":128005},{\"end\":128031,\"start\":128022},{\"end\":128145,\"start\":128142},{\"end\":128154,\"start\":128150},{\"end\":128168,\"start\":128164},{\"end\":128185,\"start\":128176},{\"end\":128199,\"start\":128192},{\"end\":128214,\"start\":128208},{\"end\":128225,\"start\":128223},{\"end\":128389,\"start\":128385},{\"end\":128405,\"start\":128397},{\"end\":128420,\"start\":128415},{\"end\":128548,\"start\":128544},{\"end\":128559,\"start\":128555},{\"end\":128684,\"start\":128682},{\"end\":128699,\"start\":128694},{\"end\":128712,\"start\":128710},{\"end\":128723,\"start\":128720},{\"end\":128980,\"start\":128977},{\"end\":128993,\"start\":128990},{\"end\":129005,\"start\":129002},{\"end\":129016,\"start\":129013},{\"end\":129310,\"start\":129301},{\"end\":129327,\"start\":129318},{\"end\":129408,\"start\":129399},{\"end\":129425,\"start\":129416},{\"end\":129581,\"start\":129576},{\"end\":129596,\"start\":129591},{\"end\":129612,\"start\":129607},{\"end\":129858,\"start\":129853},{\"end\":129870,\"start\":129866},{\"end\":129884,\"start\":129881},{\"end\":129894,\"start\":129891},{\"end\":130199,\"start\":130194},{\"end\":130210,\"start\":130205},{\"end\":130232,\"start\":130222},{\"end\":130244,\"start\":130242},{\"end\":130254,\"start\":130248},{\"end\":130473,\"start\":130467},{\"end\":130614,\"start\":130610},{\"end\":130732,\"start\":130728},{\"end\":130971,\"start\":130968},{\"end\":131057,\"start\":131054},{\"end\":131172,\"start\":131169},{\"end\":131503,\"start\":131486},{\"end\":131523,\"start\":131510},{\"end\":131534,\"start\":131527},{\"end\":131542,\"start\":131536},{\"end\":131569,\"start\":131556},{\"end\":131580,\"start\":131571},{\"end\":131603,\"start\":131595},{\"end\":131609,\"start\":131605},{\"end\":131631,\"start\":131623},{\"end\":131655,\"start\":131647},{\"end\":131725,\"start\":131716},{\"end\":131808,\"start\":131795},{\"end\":131815,\"start\":131810},{\"end\":131950,\"start\":131943},{\"end\":131963,\"start\":131956},{\"end\":132097,\"start\":132089},{\"end\":132114,\"start\":132109},{\"end\":132137,\"start\":132131}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":118649278},\"end\":121931,\"start\":121647},{\"attributes\":{\"doi\":\"arXiv:1610.01644\",\"id\":\"b1\"},\"end\":122065,\"start\":121933},{\"attributes\":{\"doi\":\"arXiv:1902.09229\",\"id\":\"b2\"},\"end\":122272,\"start\":122067},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":2915490},\"end\":122440,\"start\":122274},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":11536917},\"end\":122559,\"start\":122442},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":11253972},\"end\":122829,\"start\":122561},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":308212},\"end\":123122,\"start\":122831},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":57246310},\"end\":123317,\"start\":123124},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":10319744},\"end\":123528,\"start\":123319},{\"attributes\":{\"doi\":\"arXiv:1412.6515\",\"id\":\"b9\"},\"end\":123646,\"start\":123530},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":6832420},\"end\":123889,\"start\":123648},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":15816723},\"end\":124203,\"start\":123891},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":206594692},\"end\":124450,\"start\":124205},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":53213211},\"end\":124711,\"start\":124452},{\"attributes\":{\"doi\":\"arXiv:1503.02531\",\"id\":\"b14\"},\"end\":124856,\"start\":124713},{\"attributes\":{\"doi\":\"arXiv:1808.06670\",\"id\":\"b15\"},\"end\":125072,\"start\":124858},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":3033674},\"end\":125328,\"start\":125074},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":13300851},\"end\":125529,\"start\":125330},{\"attributes\":{\"doi\":\"arXiv:1707.01219\",\"id\":\"b18\"},\"end\":125666,\"start\":125531},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":3608236},\"end\":125836,\"start\":125668},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":172133986},\"end\":126021,\"start\":125838},{\"attributes\":{\"id\":\"b21\"},\"end\":126140,\"start\":126023},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":48352434},\"end\":126287,\"start\":126142},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":704391},\"end\":126488,\"start\":126289},{\"attributes\":{\"doi\":\"arXiv:1807.03748\",\"id\":\"b24\"},\"end\":126643,\"start\":126490},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":131765296},\"end\":126873,\"start\":126645},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":52012952},\"end\":127104,\"start\":126875},{\"attributes\":{\"doi\":\"arXiv:1904.01802\",\"id\":\"b27\"},\"end\":127295,\"start\":127106},{\"attributes\":{\"doi\":\"arXiv:1412.6550\",\"id\":\"b28\"},\"end\":127479,\"start\":127297},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":4555207},\"end\":127764,\"start\":127481},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":545361},\"end\":127929,\"start\":127766},{\"attributes\":{\"doi\":\"arXiv:1409.1556\",\"id\":\"b31\"},\"end\":128068,\"start\":127931},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":51891697},\"end\":128374,\"start\":128070},{\"attributes\":{\"doi\":\"arXiv:1906.05849\",\"id\":\"b33\"},\"end\":128486,\"start\":128376},{\"attributes\":{\"doi\":\"arXiv:1907.09682\",\"id\":\"b34\"},\"end\":128599,\"start\":128488},{\"attributes\":{\"id\":\"b35\"},\"end\":128870,\"start\":128601},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":206596723},\"end\":129173,\"start\":128872},{\"attributes\":{\"doi\":\"arXiv:1612.03928\",\"id\":\"b37\"},\"end\":129390,\"start\":129175},{\"attributes\":{\"doi\":\"arXiv:1605.07146\",\"id\":\"b38\"},\"end\":129489,\"start\":129392},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":9658690},\"end\":129759,\"start\":129491},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":24982157},\"end\":130044,\"start\":129761},{\"attributes\":{\"id\":\"b41\"},\"end\":130430,\"start\":130046},{\"attributes\":{\"id\":\"b42\"},\"end\":130479,\"start\":130432},{\"attributes\":{\"id\":\"b43\"},\"end\":130536,\"start\":130481},{\"attributes\":{\"id\":\"b44\"},\"end\":130606,\"start\":130538},{\"attributes\":{\"id\":\"b45\"},\"end\":130646,\"start\":130608},{\"attributes\":{\"id\":\"b46\"},\"end\":130724,\"start\":130648},{\"attributes\":{\"id\":\"b47\"},\"end\":130778,\"start\":130726},{\"attributes\":{\"id\":\"b48\"},\"end\":130875,\"start\":130780},{\"attributes\":{\"id\":\"b49\"},\"end\":130977,\"start\":130877},{\"attributes\":{\"id\":\"b50\"},\"end\":131063,\"start\":130979},{\"attributes\":{\"id\":\"b51\"},\"end\":131178,\"start\":131065},{\"attributes\":{\"id\":\"b52\"},\"end\":131273,\"start\":131180},{\"attributes\":{\"id\":\"b53\"},\"end\":131304,\"start\":131275},{\"attributes\":{\"id\":\"b54\"},\"end\":131552,\"start\":131306},{\"attributes\":{\"id\":\"b55\"},\"end\":131591,\"start\":131554},{\"attributes\":{\"id\":\"b56\"},\"end\":131619,\"start\":131593},{\"attributes\":{\"doi\":\"= 0.02\",\"id\":\"b57\"},\"end\":131643,\"start\":131621},{\"attributes\":{\"id\":\"b58\"},\"end\":131661,\"start\":131645},{\"attributes\":{\"id\":\"b59\"},\"end\":131791,\"start\":131663},{\"attributes\":{\"doi\":\"\u03b2 = 30000\",\"id\":\"b60\"},\"end\":131830,\"start\":131793},{\"attributes\":{\"id\":\"b61\"},\"end\":131952,\"start\":131832},{\"attributes\":{\"doi\":\"\u03b2 = 500\",\"id\":\"b62\"},\"end\":131976,\"start\":131954},{\"attributes\":{\"id\":\"b63\"},\"end\":132099,\"start\":131978},{\"attributes\":{\"id\":\"b64\"},\"end\":132129,\"start\":132101},{\"attributes\":{\"doi\":\"CRD: \u03b2 = 0.8\",\"id\":\"b65\"},\"end\":132251,\"start\":132131},{\"attributes\":{\"id\":\"b66\"},\"end\":132702,\"start\":132253},{\"attributes\":{\"id\":\"b67\"},\"end\":132749,\"start\":132704}]", "bib_title": "[{\"end\":121706,\"start\":121647},{\"end\":122335,\"start\":122274},{\"end\":122478,\"start\":122442},{\"end\":122578,\"start\":122561},{\"end\":122900,\"start\":122831},{\"end\":123175,\"start\":123124},{\"end\":123346,\"start\":123319},{\"end\":123697,\"start\":123648},{\"end\":123983,\"start\":123891},{\"end\":124249,\"start\":124205},{\"end\":124537,\"start\":124452},{\"end\":125135,\"start\":125074},{\"end\":125372,\"start\":125330},{\"end\":125737,\"start\":125668},{\"end\":125909,\"start\":125838},{\"end\":126194,\"start\":126142},{\"end\":126351,\"start\":126289},{\"end\":126678,\"start\":126645},{\"end\":126942,\"start\":126875},{\"end\":127536,\"start\":127481},{\"end\":127824,\"start\":127766},{\"end\":128131,\"start\":128070},{\"end\":128672,\"start\":128601},{\"end\":128969,\"start\":128872},{\"end\":129566,\"start\":129491},{\"end\":129843,\"start\":129761},{\"end\":130187,\"start\":130046}]", "bib_author": "[{\"end\":121730,\"start\":121708},{\"end\":121742,\"start\":121730},{\"end\":121759,\"start\":121742},{\"end\":121777,\"start\":121759},{\"end\":121782,\"start\":121777},{\"end\":122016,\"start\":121999},{\"end\":122031,\"start\":122016},{\"end\":122197,\"start\":122182},{\"end\":122222,\"start\":122197},{\"end\":122238,\"start\":122222},{\"end\":122350,\"start\":122337},{\"end\":122365,\"start\":122350},{\"end\":122383,\"start\":122365},{\"end\":122490,\"start\":122480},{\"end\":122504,\"start\":122490},{\"end\":122598,\"start\":122580},{\"end\":122612,\"start\":122598},{\"end\":122639,\"start\":122612},{\"end\":122915,\"start\":122902},{\"end\":122926,\"start\":122915},{\"end\":122939,\"start\":122926},{\"end\":123187,\"start\":123177},{\"end\":123197,\"start\":123187},{\"end\":123213,\"start\":123197},{\"end\":123224,\"start\":123213},{\"end\":123232,\"start\":123224},{\"end\":123244,\"start\":123232},{\"end\":123364,\"start\":123348},{\"end\":123384,\"start\":123364},{\"end\":123397,\"start\":123384},{\"end\":123406,\"start\":123397},{\"end\":123426,\"start\":123406},{\"end\":123441,\"start\":123426},{\"end\":123458,\"start\":123441},{\"end\":123473,\"start\":123458},{\"end\":123613,\"start\":123595},{\"end\":123714,\"start\":123699},{\"end\":123728,\"start\":123714},{\"end\":123744,\"start\":123728},{\"end\":124002,\"start\":123985},{\"end\":124018,\"start\":124002},{\"end\":124263,\"start\":124251},{\"end\":124278,\"start\":124263},{\"end\":124292,\"start\":124278},{\"end\":124302,\"start\":124292},{\"end\":124553,\"start\":124539},{\"end\":124565,\"start\":124553},{\"end\":124578,\"start\":124565},{\"end\":124594,\"start\":124578},{\"end\":124776,\"start\":124759},{\"end\":124791,\"start\":124776},{\"end\":124802,\"start\":124791},{\"end\":124952,\"start\":124939},{\"end\":124966,\"start\":124952},{\"end\":124992,\"start\":124966},{\"end\":125006,\"start\":124992},{\"end\":125022,\"start\":125006},{\"end\":125037,\"start\":125022},{\"end\":125151,\"start\":125137},{\"end\":125166,\"start\":125151},{\"end\":125182,\"start\":125166},{\"end\":125388,\"start\":125374},{\"end\":125403,\"start\":125388},{\"end\":125415,\"start\":125403},{\"end\":125434,\"start\":125415},{\"end\":125450,\"start\":125434},{\"end\":125615,\"start\":125602},{\"end\":125628,\"start\":125615},{\"end\":125751,\"start\":125739},{\"end\":125765,\"start\":125751},{\"end\":125777,\"start\":125765},{\"end\":125929,\"start\":125911},{\"end\":125942,\"start\":125929},{\"end\":125956,\"start\":125942},{\"end\":125971,\"start\":125956},{\"end\":126095,\"start\":126078},{\"end\":126112,\"start\":126095},{\"end\":126212,\"start\":126196},{\"end\":126226,\"start\":126212},{\"end\":126232,\"start\":126226},{\"end\":126363,\"start\":126353},{\"end\":126373,\"start\":126363},{\"end\":126389,\"start\":126373},{\"end\":126401,\"start\":126389},{\"end\":126570,\"start\":126550},{\"end\":126580,\"start\":126570},{\"end\":126595,\"start\":126580},{\"end\":126693,\"start\":126680},{\"end\":126705,\"start\":126693},{\"end\":126713,\"start\":126705},{\"end\":126724,\"start\":126713},{\"end\":126963,\"start\":126944},{\"end\":126981,\"start\":126963},{\"end\":127119,\"start\":127106},{\"end\":127129,\"start\":127119},{\"end\":127142,\"start\":127129},{\"end\":127157,\"start\":127142},{\"end\":127168,\"start\":127157},{\"end\":127176,\"start\":127168},{\"end\":127190,\"start\":127176},{\"end\":127206,\"start\":127190},{\"end\":127313,\"start\":127297},{\"end\":127329,\"start\":127313},{\"end\":127352,\"start\":127329},{\"end\":127370,\"start\":127352},{\"end\":127383,\"start\":127370},{\"end\":127398,\"start\":127383},{\"end\":127407,\"start\":127398},{\"end\":127552,\"start\":127538},{\"end\":127567,\"start\":127552},{\"end\":127581,\"start\":127567},{\"end\":127599,\"start\":127581},{\"end\":127617,\"start\":127599},{\"end\":127844,\"start\":127826},{\"end\":127857,\"start\":127844},{\"end\":127873,\"start\":127857},{\"end\":127885,\"start\":127873},{\"end\":128015,\"start\":127999},{\"end\":128033,\"start\":128015},{\"end\":128147,\"start\":128133},{\"end\":128156,\"start\":128147},{\"end\":128170,\"start\":128156},{\"end\":128187,\"start\":128170},{\"end\":128201,\"start\":128187},{\"end\":128216,\"start\":128201},{\"end\":128227,\"start\":128216},{\"end\":128391,\"start\":128376},{\"end\":128407,\"start\":128391},{\"end\":128422,\"start\":128407},{\"end\":128550,\"start\":128534},{\"end\":128561,\"start\":128550},{\"end\":128686,\"start\":128674},{\"end\":128701,\"start\":128686},{\"end\":128714,\"start\":128701},{\"end\":128725,\"start\":128714},{\"end\":128982,\"start\":128971},{\"end\":128995,\"start\":128982},{\"end\":129007,\"start\":128995},{\"end\":129018,\"start\":129007},{\"end\":129312,\"start\":129294},{\"end\":129329,\"start\":129312},{\"end\":129410,\"start\":129392},{\"end\":129427,\"start\":129410},{\"end\":129583,\"start\":129568},{\"end\":129598,\"start\":129583},{\"end\":129614,\"start\":129598},{\"end\":129860,\"start\":129845},{\"end\":129872,\"start\":129860},{\"end\":129886,\"start\":129872},{\"end\":129896,\"start\":129886},{\"end\":130201,\"start\":130189},{\"end\":130212,\"start\":130201},{\"end\":130234,\"start\":130212},{\"end\":130246,\"start\":130234},{\"end\":130256,\"start\":130246},{\"end\":130475,\"start\":130467},{\"end\":130642,\"start\":130610},{\"end\":130720,\"start\":130714},{\"end\":130734,\"start\":130728},{\"end\":130973,\"start\":130968},{\"end\":131059,\"start\":131054},{\"end\":131174,\"start\":131169},{\"end\":131505,\"start\":131484},{\"end\":131525,\"start\":131505},{\"end\":131536,\"start\":131525},{\"end\":131544,\"start\":131536},{\"end\":131571,\"start\":131556},{\"end\":131582,\"start\":131571},{\"end\":131605,\"start\":131595},{\"end\":131611,\"start\":131605},{\"end\":131633,\"start\":131623},{\"end\":131657,\"start\":131647},{\"end\":131727,\"start\":131716},{\"end\":131810,\"start\":131795},{\"end\":131817,\"start\":131810},{\"end\":131952,\"start\":131943},{\"end\":131965,\"start\":131956},{\"end\":132099,\"start\":132089},{\"end\":132116,\"start\":132103},{\"end\":132123,\"start\":132116},{\"end\":132139,\"start\":132131}]", "bib_venue": "[{\"end\":121859,\"start\":121782},{\"end\":121997,\"start\":121933},{\"end\":122180,\"start\":122067},{\"end\":122432,\"start\":122383},{\"end\":122553,\"start\":122504},{\"end\":122737,\"start\":122639},{\"end\":123035,\"start\":122939},{\"end\":123307,\"start\":123244},{\"end\":123522,\"start\":123473},{\"end\":123593,\"start\":123530},{\"end\":123821,\"start\":123744},{\"end\":124114,\"start\":124018},{\"end\":124379,\"start\":124302},{\"end\":124655,\"start\":124594},{\"end\":124757,\"start\":124713},{\"end\":124937,\"start\":124858},{\"end\":125259,\"start\":125182},{\"end\":125518,\"start\":125450},{\"end\":125600,\"start\":125531},{\"end\":125826,\"start\":125777},{\"end\":126015,\"start\":125971},{\"end\":126076,\"start\":126023},{\"end\":126281,\"start\":126232},{\"end\":126482,\"start\":126401},{\"end\":126548,\"start\":126490},{\"end\":126801,\"start\":126724},{\"end\":127045,\"start\":126981},{\"end\":127271,\"start\":127222},{\"end\":127446,\"start\":127422},{\"end\":127694,\"start\":127617},{\"end\":127923,\"start\":127885},{\"end\":127997,\"start\":127931},{\"end\":128304,\"start\":128227},{\"end\":128466,\"start\":128438},{\"end\":128532,\"start\":128488},{\"end\":128802,\"start\":128725},{\"end\":129095,\"start\":129018},{\"end\":129292,\"start\":129175},{\"end\":129465,\"start\":129443},{\"end\":129691,\"start\":129614},{\"end\":129973,\"start\":129896},{\"end\":130333,\"start\":130256},{\"end\":130465,\"start\":130432},{\"end\":130529,\"start\":130483},{\"end\":130600,\"start\":130538},{\"end\":130712,\"start\":130648},{\"end\":130772,\"start\":130734},{\"end\":130853,\"start\":130780},{\"end\":130966,\"start\":130877},{\"end\":131052,\"start\":130979},{\"end\":131167,\"start\":131065},{\"end\":131255,\"start\":131180},{\"end\":131302,\"start\":131277},{\"end\":131482,\"start\":131306},{\"end\":131714,\"start\":131663},{\"end\":131941,\"start\":131832},{\"end\":132087,\"start\":131978},{\"end\":132203,\"start\":132151},{\"end\":132629,\"start\":132253},{\"end\":132747,\"start\":132704},{\"end\":121923,\"start\":121861},{\"end\":122822,\"start\":122739},{\"end\":123118,\"start\":123037},{\"end\":123885,\"start\":123823},{\"end\":124197,\"start\":124116},{\"end\":124443,\"start\":124381},{\"end\":124703,\"start\":124657},{\"end\":125323,\"start\":125261},{\"end\":126865,\"start\":126803},{\"end\":127096,\"start\":127047},{\"end\":127758,\"start\":127696},{\"end\":128368,\"start\":128306},{\"end\":128866,\"start\":128804},{\"end\":129159,\"start\":129097},{\"end\":129755,\"start\":129693},{\"end\":130037,\"start\":129975},{\"end\":130397,\"start\":130335}]"}}}, "year": 2023, "month": 12, "day": 17}