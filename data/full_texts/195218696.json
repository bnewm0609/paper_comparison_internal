{"id": 195218696, "updated": "2023-10-07 00:47:47.058", "metadata": {"title": "Probabilistic Logic Neural Networks for Reasoning", "authors": "[{\"first\":\"Meng\",\"last\":\"Qu\",\"middle\":[]},{\"first\":\"Jian\",\"last\":\"Tang\",\"middle\":[]}]", "venue": "ArXiv", "journal": "ArXiv", "publication_date": {"year": 2019, "month": null, "day": null}, "abstract": "Knowledge graph reasoning, which aims at predicting the missing facts through reasoning with the observed facts, is critical to many applications. Such a problem has been widely explored by traditional logic rule-based approaches and recent knowledge graph embedding methods. A principled logic rule-based approach is the Markov Logic Network (MLN), which is able to leverage domain knowledge with first-order logic and meanwhile handle their uncertainty. However, the inference of MLNs is usually very difficult due to the complicated graph structures. Different from MLNs, knowledge graph embedding methods (e.g. TransE, DistMult) learn effective entity and relation embeddings for reasoning, which are much more effective and efficient. However, they are unable to leverage domain knowledge. In this paper, we propose the probabilistic Logic Neural Network (pLogicNet), which combines the advantages of both methods. A pLogicNet defines the joint distribution of all possible triplets by using a Markov logic network with first-order logic, which can be efficiently optimized with the variational EM algorithm. In the E-step, a knowledge graph embedding model is used for inferring the missing triplets, while in the M-step, the weights of logic rules are updated based on both the observed and predicted triplets. Experiments on multiple knowledge graphs prove the effectiveness of pLogicNet over many competitive baselines.", "fields_of_study": "[\"Computer Science\",\"Mathematics\"]", "external_ids": {"arxiv": "1906.08495", "mag": "2970583209", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/nips/Qu019", "doi": null}}, "content": {"source": {"pdf_hash": "f1e3c8113107371a12ee7edc208ca19b5af947b5", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/1906.08495v2.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "353da32dac9dbcddc97f3cd4c9367ed04dd325e5", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/f1e3c8113107371a12ee7edc208ca19b5af947b5.txt", "contents": "\nProbabilistic Logic Neural Networks for Reasoning\n\n\nMeng Qu \nMila -Quebec AI Institute\n\n\nUniversity of Montr\u00e9al\n\n\nJian Tang \nMila -Quebec AI Institute\n\n\nHEC Montr\u00e9al\n\n\nCIFAR AI Research Chair\n\n\nProbabilistic Logic Neural Networks for Reasoning\n\nKnowledge graph reasoning, which aims at predicting the missing facts through reasoning with the observed facts, is critical to many applications. Such a problem has been widely explored by traditional logic rule-based approaches and recent knowledge graph embedding methods. A principled logic rule-based approach is the Markov Logic Network (MLN), which is able to leverage domain knowledge with first-order logic and meanwhile handle the uncertainty. However, the inference in MLNs is usually very difficult due to the complicated graph structures. Different from MLNs, knowledge graph embedding methods (e.g. TransE, DistMult) learn effective entity and relation embeddings for reasoning, which are much more effective and efficient. However, they are unable to leverage domain knowledge. In this paper, we propose the probabilistic Logic Neural Network (pLogicNet), which combines the advantages of both methods. A pLogicNet defines the joint distribution of all possible triplets by using a Markov logic network with first-order logic, which can be efficiently optimized with the variational EM algorithm. In the E-step, a knowledge graph embedding model is used for inferring the missing triplets, while in the M-step, the weights of logic rules are updated based on both the observed and predicted triplets. Experiments on multiple knowledge graphs prove the effectiveness of pLogicNet over many competitive baselines.Another type of methods for reasoning on knowledge graphs are the recent knowledge graph embedding based methods (e.g., TransE [3], DistMult [48]  and ComplEx[44]). These methods learn useful embeddings of entities and relations by projecting existing triplets into low-dimensional spaces.\n\nIntroduction\n\nMany real-world entities are interconnected with each other through various types of relationships, forming massive relational data. Naturally, such relational data can be characterized by a set of (h, r, t) triplets, meaning that entity h has relation r with entity t. To store the triplets, many knowledge graphs have been constructed such as Freebase [14] and WordNet [24]. These graphs have been proven useful in many tasks, such as question answering [49], relation extraction [34] and recommender systems [4]. However, one big challenge of knowledge graphs is that their coverage is limited. Therefore, one fundamental problem is how to predict the missing links based on the existing triplets.\n\nOne type of methods for reasoning on knowledge graphs are the symbolic logic rule-based approaches [12,17,35,41,46]. These rules can be either handcrafted by domain experts [42] or mined from knowledge graphs themselves [10]. Traditional methods such as expert systems [12,17] use hard logic rules for prediction. For example, given a logic rule \u2200x, y, Husband(x, y) \u21d2 Wife(y, x) and a fact that A is the husband of B, we can derive that B is the wife of A. However, in many cases logic rules can be imperfect or even contradictory, and hence effectively modeling the uncertainty of logic rules is very critical. A more principled method for using logic rules is the Markov Logic Network (MLN) [35,39], which combines first-order logic and probabilistic graphical models. MLNs learn the weights of logic rules in a probabilistic framework and thus soundly handle the uncertainty. Such methods have been proven effective for reasoning on knowledge graphs. However, the inference process in MLNs is difficult and inefficient due to the complicated graph structure among triplets. Moreover, the results can be unsatisfactory as many missing triplets cannot be inferred by any rules.\n\nThese embeddings preserve the semantic meanings of entities and relations, and can effectively predict the missing triplets. In addition, they can be efficiently trained with stochastic gradient descent. However, one limitation is that they do not leverage logic rules, which compactly encode domain knowledge and are useful in many applications.\n\nWe are seeking an approach that combines the advantages of both worlds, one which is able to exploit first-order logic rules while handling their uncertainty, infer missing triplets effectively, and can be trained in an efficient way. We propose such an approach called the probabilistic Logic Neural Networks (pLogicNet). A pLogicNet defines the joint distribution of a collection of triplets with a Markov Logic Network [35], which associates each logic rule with a weight and can be effectively trained with the variational EM algorithm [26]. In the variational E-step, we infer the plausibility of the unobserved triplets (i.e., hidden variables) with amortized mean-field inference [11,21,29], in which the variational distribution is parameterized as a knowledge graph embedding model. In the M-step, we update the weights of logic rules by optimizing the pseudolikelihood [1], which is defined on both the observed triplets and those inferred by the knowledge graph embedding model. The framework can be efficiently trained by stochastic gradient descent. Experiments on four benchmark knowledge graphs prove the effectiveness of pLogicNet over many competitive baselines.\n\n\nRelated Work\n\nFirst-order logic rules can compactly encode domain knowledge and have been extensively explored for reasoning. Early methods such as expert systems [12,17] use hard logic rules for reasoning. However, logic rules can be imperfect or even contradictory. Later studies try to model the uncertainty of logic rules by using Horn clauses [5,19,30,46] or database query languages [31,41]. A more principled method is the Markov logic network [35,39], which combines first-order logic with probabilistic graphical models. Despite the effectiveness in a variety of tasks, inference in MLNs remains difficult and inefficient due to the complicated connections between triplets. Moreover, for predicting missing triplets on knowledge graphs, the performance can be limited as many triplets cannot be discovered by any rules. In contrast to them, pLogicNet uses knowledge graph embedding models for inference, which is much more effective by learning useful entity and relation embeddings.\n\nAnother category of approach for knowledge graph reasoning is the knowledge graph embedding method [3,8,28,40,44,45,48], which aims at learning effective embeddings of entities and relations. Generally, these methods design different scoring functions to model different relation patterns for reasoning. For example, TransE [3] defines each relation as a translation vector, which can effectively model the composition and inverse relation patterns. DistMult [48] models the symmetric relation with a bilinear scoring function. ComplEx [44] models the asymmetric relations by using a bilinear scoring function in complex space. RotatE [40] further models multiple relation patterns by defining each relation as a rotation in complex spaces. Despite the effectiveness and efficiency, these methods are not able to leverage logic rules, which are beneficial in many tasks. Recently, there are a few studies on combining logic rules and knowledge graph embedding [9,15]. However, they cannot effectively handle the uncertainty of logic rules. Compared with them, pLogicNet is able to use logic rules and also handle their uncertainty in a more principled way through Markov logic networks.\n\nSome recent work also studies using reinforcement learning for reasoning on knowledge graphs [6,23,38,47], where an agent is trained to search for reasoning paths. However, the performance of these methods is not so competitive. Our pLogicNets are easier to train and also more effective.\n\nLastly, there are also some recent studies trying to combine statistical relational learning and graph neural networks for semi-supervised node classification [33], or using Markov networks for visual dialog reasoning [32,51]. Our work shares similar idea with these studies, but we focus on a different problem, i.e., reasoning with first-order logic on knowledge graphs. There is also a concurrent work using graph neural networks for logic reasoning [50]. Compared to this study which emphasizes more on the inference problem, our work focuses on both the inference and the learning problems.\n\n\nPreliminary\n\n\nProblem Definition\n\nA knowledge graph is a collection of relational facts, each of which is represented as a triplet (h, r, t). Due to the high cost of knowledge graph construction, the coverage of knowledge graphs is usually limited. Therefore, a critical problem on knowledge graphs is to predict the missing facts.\n\nFormally, given a knowledge graph (E, R, O), where E is a set of entities, R is a set of relations, and O is a set of observed (h, r, t) triplets, the goal is to infer the missing triplets by reasoning with the observed triplets. Following existing studies [27], the problem can be reformulated in a probabilistic way. Each triplet (h, r, t) is associated with a binary indicator variable v (h,r,t) . v (h,r,t) = 1 means (h, r, t) is true, and v (h,r,t) = 0 otherwise. Given some true facts v O = {v (h,r,t) = 1} (h,r,t)\u2208O , we aim to predict the labels of the remaining hidden triplets H, i.e., v H = {v (h,r,t) } (h,r,t)\u2208H . We will discuss how to generate the hidden triplets H later in Sec. 4.4.\n\nThis problem has been extensively studied in both traditional logic rule-based methods and recent knowledge graph embedding methods. For logic rule-based methods, we mainly focus on one representative approach, the Markov logic network [35]. Essentially, both types of methods aim to model the joint distribution of the observed and hidden triplets p(v O , v H ). Next, we briefly introduce the Markov logic network (MLN) [35] and the knowledge graph embedding methods [3,40,48].\n\n\nMarkov Logic Network\n\nIn the MLN, a Markov network is designed to define the joint distribution of the observed and the hidden triplets, where the potential function is defined by the first-order logic. Some common logic rules to encode domain knowledge include: (1) Composition Rules. A relation r k is a composition of r i and r j means that for any three entities x, y, z, if x has relation r i with y, and y has relation r j with z, then x has relation r k with z. Formally, we have \u2200x, y, z \u2208 E, v (x,ri,y) \u2227 v (y,rj ,z) \u21d2 v (x,r k ,z) .\n\n(2) Inverse Rules. A relation r j is an inverse of r i indicates that for two entities x, y, if x has relation r i with y, then y has relation r j with x. We can represent the rule as \u2200x, y \u2208 E, v (x,ri,y) \u21d2 v (y,rj ,x) .\n\n(3) Symmetric Rules. A relation r is symmetric means that for any entity pair x, y, if x has relation r with y, then y also has relation r with x. Formally, we have \u2200x, y \u2208 E, v (x,r,y) \u21d2 v (y,r,x) . (4) Subrelation Rules. A relation r j is a subrelation of r i indicates that for any entity pair x, y, if x and y have relation r i , then they also have relation r j . Formally, we have \u2200x, y \u2208 E, v (x,ri,y) \u21d2 v (x,rj ,y) .\n\nFor each logic rule l, we can obtain a set of possible groundings G l by instantiating the entity placeholders in the logic rule with real entities in knowledge graphs. For example, for a subrelation rule, \u2200x, y, v (x,Born in,y) \u21d2 v (x,Live in,y) , two groundings in G l can be v (Newton,Born in,UK) \u21d2 v (Newton,Live in,UK) and v (Einstein,Born in,German) \u21d2 v (Einstein,Live in,German) . We see that the former one is true while the latter one is false. To handle such uncertainty of logic rules, Markov logic networks introduce a weight w l for each rule l, and then the joint distribution of all triplets is defined as follows:\np(v O , v H ) = 1 Z exp \uf8eb \uf8ed l\u2208L w l g\u2208G l 1{g is true} \uf8f6 \uf8f8 = 1 Z exp l\u2208L w l n l (v O , v H ) ,(1)\nwhere n l is the number of true groundings of the logic rule l based on the values of v O and v H .\n\nWith such a formulation, predicting the missing triplets essentially becomes inferring the posterior distribution p(v H |v O ). Exact inference is usually infeasible due to the complicated graph structures, and hence approximation inference is often used such as MCMC [13] and loopy belief propagation [25].\n\n\nKnowledge Graph Embedding\n\nDifferent from the logic rule-based approaches, the knowledge graph embedding methods learn embeddings of entities and relations with the observed facts v O , and then predict the missing facts with the learned entity and relation embeddings. Formally, each entity e \u2208 E and relation r \u2208 R is associated with an embedding x e and x r . Then the joint distribution of all the triplets is defined as:\np(v O , v H ) = (h,r,t)\u2208O\u222aH Ber(v (h,r,t) |f (x h , x r , x t )),(2)\nwhere Ber stands for the Bernoulli distribution, f (x h , x r , x t ) computes the probability that the triplet (h, r, t) is true, with f (\u00b7, \u00b7, \u00b7) being a scoring function on the entity and relation embeddings. For example in TransE, the score function f can be formulated as \u03c3(\u03b3 \u2212 ||x h + x r \u2212 x t ||) according to [40], where \u03c3 is the sigmoid function and \u03b3 is a fixed bias. To learn the entity and relation embeddings, these methods typically treat observed triplets as positive examples and the hidden triplets as negative ones. In other words, these methods seek to maximize log\np(v O = 1, v H = 0).\nThe whole framework can be efficiently optimized with the stochastic gradient descent algorithm. \n\n\nModel\n\nIn this section, we introduce our proposed approach pLogicNet for knowledge graph reasoning, which combines the logic rule-based methods and the knowledge graph embedding methods. To leverage the domain knowledge provided by first-order logic rules, pLogicNet formulates the joint distribution of all triplets with a Markov logic network [35], which is trained with the variational EM algorithm [26], alternating between a variational E-step and an M-step. In the varational E-step, we employ a knowledge graph embedding model to infer the missing triplets, during which the knowledge preserved by the logic rules can be effectively distilled into the learned embeddings. In the M-step, the weights of the logic rules are updated based on both the observed triplets and those inferred by the knowledge graph embedding model. In this way, the knowledge graph embedding model provides extra supervision for weight learning. An overview of pLogicNet is given in Fig. 1.\n\n\nVariational EM\n\nGiven a set of first-order logic rules L = {l i } |L| i=1 , our approach uses a Markov logic network [35] as in Eq. (1) to model the joint distribution of both the observed and hidden triplets:\np w (v O , v H ) = 1 Z exp l w l n l (v O , v H ) ,(3)\nwhere w l is the weight of rule l. The model can be trained by maximizing the log-likelihood of the observed indicator variables, i.e., log p w (v O ). However, directly optimizing the objective is infeasible, as we need to integrate over all the hidden indicator variables v H . Therefore, we instead optimize the evidence lower bound (ELBO) of the log-likelihood function, which is given as follows:\nlog p w (v O ) \u2265 L(q \u03b8 , p w ) = E q \u03b8 (v H ) [log p w (v O , v H ) \u2212 log q \u03b8 (v H )],(4)\nwhere\nq \u03b8 (v H ) is a variational distribution of the hidden variables v H . The equation holds when q \u03b8 (v H ) equals to the true posterior distribution p w (v H |v O )\n. Such a lower bound can be effectively optimized with the variational EM algorithm [26], which consists of a variational E-step and an M-step. In the variational E-step, which is known as the inference procedure, we fix p w and update q \u03b8 to minimize the KL divergence between q \u03b8 (v H ) and p w (v H |v O ). In the M-step, which is known as the learning procedure, we fix q \u03b8 and update p w to maximize the log-likelihood function of all the triplets, i.e.,\nE q \u03b8 (v H ) [log p w (v O , v H )].\nNext, we introduce the details of both steps.\n\n\nE-step: Inference Procedure\n\nFor inference, we aim to infer the posterior distribution of the hidden variables, i.e., p w (v H |v O ). As exact inference is intractable, we approximate the true posterior distribution with a mean-field [29] variational distribution q \u03b8 (v H ), in which each v (h,r,t) is inferred independently for (h, r, t) \u2208 H. To further improve inference, we use amortized inference [11,21], and parameterize q \u03b8 (v (h,r,t) ) with a knowledge graph embedding model. Formally, q \u03b8 (v H ) is formulated as below:\nq \u03b8 (v H ) = (h,r,t)\u2208H q \u03b8 (v (h,r,t) ) = (h,r,t)\u2208H Ber(v (h,r,t) |f (x h , x r , x t )),(5)\nwhere Ber stands for the Bernoulli distribution, and f (\u00b7, \u00b7, \u00b7) is a scoring function defined on triplets as introduced in Sec. 3.3. By minimizing the KL divergence between the variational distribution q \u03b8 (v H ) and the true posterior p w (v H |v O ), the optimal q \u03b8 (v H ) is given by the fixed-point condition:\nlog q \u03b8 (v (h,r,t) ) = E q \u03b8 (v MB(h,r,t) ) [log p w (v (h,r,t) |v MB(h,r,t) )] + const for all (h, r, t) \u2208 H,(6)\nwhere MB(h, r, t) is the Markov blanket of (h, r, t), which contains the triplets that appear together with (h, r, t) in any grounding of the logic rules. For example, from a grounding v (Newton,Born in,UK) \u21d2 v (Newton,Live in,UK) , we can know both triplets are in the Markov blanket of each other.\n\nWith Eq. (6), our goal becomes finding a distribution q \u03b8 that satisfies the condition. However, Eq. (6) involves the expectation with respect to q \u03b8 (v MB(h,r,t) ). To simplify the condition, we follow [16] and estimate the expectation with a samplev MB(h,r,t) = {v (h ,r ,t ) } (h ,r ,t )\u2208MB(h,r,t) . Specifically, for each (h , r , t ) \u2208 MB(h, r, t), if it is observed, we setv (h ,r ,t ) = 1, and otherwisev (h ,r ,t ) \u223c q \u03b8 (v (h ,r ,t ) ). In this way, the right side of Eq. (6) is approximated as log p w (v (h,r,t) |v MB(h,r,t) ), and thus the optimality condition can be further simplified as q \u03b8 (v (h,r,t) ) \u2248 p w (v (h,r,t) |v MB(h,r,t) ).\n\nIntuitively, for each hidden triplet (h, r, t), the knowledge graph embedding model predicts v (h,r,t) through the entity and relation embeddings (i.e., q \u03b8 (v (h,r,t) )), while the logic rules make the prediction by utilizing the triplets connected with (h, r, t) (i.e., p w (v (h,r,t) |v MB(h,r,t) )). If any ,r ,t ) ). Then, the simplified optimality condition tells us that for the optimal knowledge graph embedding model, it should reach a consensus with the logic rules on the distribution of v (h,r,t) for every (h, r, t), i.e., q \u03b8 (v (h,r,t) ) \u2248 p w (v (h,r,t) |v MB(h,r,t) ).\ntriplet (h , r , t ) connected with (h, r, t) is unobserved, we simply fill in v (h ,r ,t ) with a sampl\u00ea v (h ,r ,t ) \u223c q \u03b8 (v (h\nTo learn the optimal q \u03b8 , we use a method similar to [36]. We start by computing p w (v (h,r,t) |v MB(h,r,t) ) with the current q \u03b8 . Then, we fix the value as target, and update q \u03b8 to minimize the reverse KL divergence of q \u03b8 (v (h,r,t) ) and the target p w (v (h,r,t) |v MB(h,r,t) ), leading to the following objective:\nO \u03b8,U = (h,r,t)\u2208H E pw(v (h,r,t) |v MB(h,r,t) ) [log q \u03b8 (v (h,r,t) )].(7)\nTo optimize this objective, we first compute p w (v (h,r,t) |v MB(h,r,t) ) for each hidden triplet (h, r, t).\n\nIf p w (v (h,r,t) = 1|v MB(h,r,t) ) \u2265 \u03c4 triplet with \u03c4 triplet being a hyperparameter, then we treat (h, r, t) as a positive example and train the knowledge graph embedding model to maximize the log-likelihood log q \u03b8 (v (h,r,t) = 1). Otherwise the triplet is treated as a negative example. In this way, the knowledge captured by logic rules can be effectively distilled into the knowledge graph embedding model.\n\nWe can also use the observed triplets in O as positive examples to enhance the knowledge graph embedding model. Therefore, we also optimize the following objective function:\nO \u03b8,L = (h,r,t)\u2208O log q \u03b8 (v (h,r,t) = 1).(8)\nBy adding Eq. (7) and (8), we obtain the overall objective function for q \u03b8 , i.e., O \u03b8 = O \u03b8,U + O \u03b8,L .\n\n\nM-step: Learning Procedure\n\nIn the learning procedure, we will fix q \u03b8 , and update the weights of logic rules w by maximizing the log-likelihood function, i.e.,\nE q \u03b8 (v H ) [log p w (v O , v H )].\nHowever, directly optimizing the loglikelihood function can be difficult, as we need to deal with the partition function, i.e., Z in Eq. (3). Therefore, we follow existing studies [22,35] and instead optimize the pseudolikelihood function [1]:\nP L (w) E q \u03b8 (v H ) [ h,r,t log p w (v (h,r,t) |v O\u222aH\\(h,r,t) )] = E q \u03b8 (v H ) [ h,r,t log p w (v (h,r,t) |v MB(h,r,t) )],\nwhere the second equation is derived from the independence property of the MLN in the Eq. (3).\n\nWe optimize w through the gradient descent algorithm. For each expected conditional distribution E q \u03b8 (v H ) [log p w (v (h,r,t) |v MB(h,r,t) )], suppose v (h,r,t) connects with v MB(h,r,t) through a set of rules.\n\nFor each of such rules l, the derivative with respect to w l is computed as:\nw l E q \u03b8 (v H ) [log p w (v (h,r,t) |v MB(h,r,t) )] y (h,r,t) \u2212 p w (v (h,r,t) = 1|v MB(h,r,t) )(9)\nwhere y (h,r,t) = 1 if (h, r, t) is an observed triplet and y (h, ,r ,t ) ).\nr,t) = q \u03b8 (v (h,r,t) = 1) if (h, r, t) is a hidden one.v MB(h,r,t) = {v (h ,r ,t ) } (h ,r ,t )\u2208MB(h,r,t) is a sample from q \u03b8 . For each (h , r , t ) \u2208 MB(h, r, t),v (h ,r ,t ) = 1 if (h , r , t ) is observed, and otherwisev (h ,r ,t ) \u223c q \u03b8 (v (h\nIntuitively, for each observed triplet (h, r, t) \u2208 O, we seek to maximize p w (v (h,r,t) = 1|v MB(h,r,t) ).\n\nFor each hidden triplet (h, r, t) \u2208 H, we treat q \u03b8 (v (h,r,t) = 1) as target for updating the probability p w (v (h,r,t) = 1|v MB(h,r,t) ). In this way, the knowledge graph embedding model q \u03b8 essentially provides extra supervision to benefit learning the weights of logic rules.\n\n\nOptimization and Prediction\n\nDuring training, we iteratively perform the E-step and the M-step until convergence. Note that there are a huge number of possible hidden triplets (i.e., |E| \u00d7 |R| \u00d7 |E| \u2212 |O|), and handling all of them is impractical for optimization. Therefore, we only include a small number of triplets in the hidden set H. Specifically, an unobserved triplet (h, r, t) is added to H if we can find a grounding [premise] \u21d2 [hypothesis], where the hypothesis is (h, r, t) and the premise only contains triplets in the observed set O. In practice, we can construct H with brute-force search as in [15].\n\nAfter training, according to the fixed-point condition given in Eq. (6), the posterior distribution h,r,t) ). Although we try to encourage the consensus of p w and q \u03b8 during training, they may still give different predictions as different information is used. Therefore, we use both of them for prediction, and we approximate the true posterior distribution p w (v (h,r,t) |v O ) as:\np w (v (h,r,t) |v O ) for (h, r, t) \u2208 H can be characterized by either q \u03b8 (v (h,r,t) ) or p w (v (h,r,t) |v MB(h,r,t) ) withv MB(h,r,t) \u223c q \u03b8 (v MB(p w (v (h,r,t) |v O ) \u221d q \u03b8 (v (h,r,t) ) + \u03bbp w (v (h,r,t) |v MB(h,r,t) ) ,(10)\nwhere \u03bb is a hyperparameter controlling the relative weight of q \u03b8 (v (h,r,t) ) and p w (v (h,r,t) |v MB(h,r,t) ).\n\nIn practice, we also expect to infer the plausibility of the triplets outside H. For each of such triplets (h, r, t), we can still compute q \u03b8 (v (h,r,t) ) through the learned embeddings, but we cannot make predictions with the logic rules, so we simply replace p w (v (h,r,t) = 1|v MB(h,r,t) ) with 0.5 in Eq. 10.\n\n\nExperiment\n\n\nExperiment Settings\n\nDatasets. In experiments, we evaluate the pLogicNet on four benchmark datasets. The FB15k [3] and FB15k-237 [43] datasets are constructed from Freebase [2]. WN18 [3] and WN18RR [8] are constructed from WordNet [24]. The detailed statistics of the datasets are summarized in appendix.\n\n\nEvaluation Metrics.\n\nWe compare different methods on the task of knowledge graph reasoning. For each test triplet, we mask the head or the tail entity, and let each compared method predict the masked entity. Following existing studies [3,48], we use the filtered setting during evaluation. The Mean Rank (MR), Mean Reciprocal Rank (MRR) and Hit@K (H@K) are treated as the evaluation metrics.\n\nCompared Algorithms. We compare with both the knowledge graph embedding methods and rulebased methods. For the knowledge graph embedding methods, we choose five representative methods to compare with, including TransE [3], DistMult [48], HolE [28], ComplEx [44] and ConvE [8]. For the rule-based methods, we compare with the Markov logic network (MLN) [35] and the Bayesian logic programming (BLP) method [7], which model logic rules with Markov networks and Bayesian networks respectively. Besides, we also compare with RUGE [15] and NNE-AER [9], which are hybrid methods that combine knowledge graph embedding and logic rules. As only the results on the FB15k dataset are reported in the RUGE paper, we only compare with RUGE on that dataset. For our approach, we consider two variants, where pLogicNet uses only q \u03b8 to infer the plausibility of unobserved triplets during evaluation, while pLogicNet * uses both q \u03b8 and p w through Eq. (10).\n\nExperimental Setup of pLogicNet. To generate the candidate rules in the pLogicNet, we search for all the possible composition rules, inverse rules, symmetric rules and subrelations rules from the observed triplets, which is similar to [10,15]. Then, we compute the empirical precision of each rule, i.e. p l = |S l \u2229O| |S l | , where S l is the set of triplets extracted by the rule l and O is the set of the observed triplets. We only keep rules whose empirical precision is larger than a threshold \u03c4 rule . TransE [3] is used as the default knowledge graph embedding model to parameterize q \u03b8 . We update the weights of logic rules with gradient descent. The detailed hyperparameters settings are available in the appendix.  The main results on the four datasets are presented in Tab. 1 and 2. We can see that the pLogicNet significantly outperforms the rule-based methods, as pLogicNet uses a knowledge graph embedding model to improve inference. pLogicNet also outperforms all the knowledge graph embedding methods in most cases, where the improvement comes from the capability of exploring the knowledge captured by the logic rules. Moreover, our approach is superior to both hybrid methods (RUGE and NNE-AER) under most metrics, as it handles the uncertainty of logic rules in a more principled way.\n\n\nResults\n\n\nComparing pLogicNet with Other Methods\n\nComparing pLogicNet and pLogicNet * , pLogicNet * uses both q \u03b8 and p w to predict the plausibility of hidden triplets, which outperforms pLogicNet in most cases. The reason is that the information captured by q \u03b8 and p w is different and complementary, so combining them yields better performance.    Figure 2: Convergence analysis.\n\n\nAnalysis of Different Rule Patterns\n\n\nEffect of Knowledge Graph Embedding on Logic Rules\n\nIn the M-step of pLogicNet, we use the learned embeddings to annotate the hidden triplets, and further update the weights of logic rules. Next, we analyze the effect of knowledge graph embeddings on logic rules. Recall that in the E-step, the logic rules are used to annotate the hidden triplets through Eq. (7), and thus collect extra positive training data for embedding learning. To evaluate the performance of logic rules, in each iteration we report the number of positive triplets discovered by logic rules, as well as the precision of the triplets in Tab. 5. We see that as training proceeds, the logic rules can find more triplets with stable precision. This observation proves that the knowledge graph embedding model can indeed provide effective supervision for learning the weights of logic rules.\n\n\nConvergence Analysis\n\nFinally, we present the convergence curves of pLogicNet * on the FB15k and WN18 datasets in Fig. 2. The horizontal axis represents the iteration, and the vertical axis shows the value of Hit@1 (in %). We see that on both datasets, our approach takes only 2-3 iterations to converge, which is very efficient.\n\n\nConclusion\n\nThis paper studies knowledge graph reasoning, and an approach called the pLogicNet is proposed to integrate existing rule-based methods and knowledge graph embedding methods. pLogicNet models the distribution of all the possible triplets with a Markov logic network, which is efficiently optimized with the variational EM algorithm. In the E-step, a knowledge graph embedding model is used to infer the hidden triplets, whereas in the M-step, the weights of rules are updated based on the observed and inferred triplets. Experimental results prove the effectiveness of pLogicNet. In the future, we plan to explore more advanced models for inference, such as relational GCN [37] and RotatE [40].\n\n\nAppendix\n\n\nStatistics of the Datasets\n\nThe statistics of the four datasets are presented in Tab. 6. \n\n\nHyperparameter Settings\n\nIn pLogicNet, we parameterize the variational distribution q \u03b8 as a TransE model [3], and we use the method as used in [40] for training the model. More specifically, we define q \u03b8 (v (h,r,t) ) by using a distance-based formulation, i.e., q \u03b8 (v (h,r,t) = 1) = \u03c3(\u03b3 \u2212 ||x h + x r \u2212 x t ||), where \u03c3 is the sigmoid function and \u03b3 is a hyperparameter, which is fixed during training. We generate negative samples by using self-adversarial negative sampling [40], and use Adam [20] as the optimizer. In addition, we filter out unreliable rules and triplets based on the threshold \u03c4 rule and \u03c4 triplet respectively. During prediction, \u03bb is used to control the relative weight of the knowledge graph embedding model q \u03b8 and the rule-based model p w . The detailed hyperparameter settings can be found in Tab. 7. a For inverse rules and symmetric rules, the threshold is 0.1, whereas for composition rules and subrelations rules, the threshold is 0.6.  Our work is related to existing hybrid methods for combining knowledge graph embedding with logic rules, such as RUGE [15] and NNE-AER [9]. Although these methods can also model the uncertainty of logic rules by using soft rules, our method has some key differences from them.\n\n\nAdditional Comparison with Hybrid Methods\n\nFirst, our approach models the uncertainty of logic rules under the principled framework of Markov logic networks [35]. In all the three methods, each rule is associated with a weight to measure the uncertainty. In both RUGE and NNE-AER, the weights of rules are initialized by other algorithms (i.e., AMIE+ [10]) and then fixed during training. In contrast, our approach can dynamically learn and adjust the weights of logic rules according to the downstream reasoning tasks.\n\nSecond, both RUGE and NNE-AER are specifically designed for the task of knowledge graph reasoning. In contrast, our approach is a general mechanism. Besides knowledge graph reasoning, our approach can also be applied to many other tasks in statistical relational reasoning.\n\nWe also conduct some additional experiments to compare against RUGE and NNE-AER under the same settings as used in RUGE and NNE-AER. More specifically, we use ComplEx [44] as the KGE model. To compare with RUGE, we follow RUGE to use only the inverse and composition rules. To compare with NNE-AER, we follow NNE-AER to use only the inverse and subrelation rules. We present the results in Tab. 8 and 9. We see our approach consistently performs better. The reason is that our approach can dynamically infer the uncertainty of logic rules with Markov logic networks. RotatE [40] is one of the state-of-the-art methods for knowledge graph reasoning, which is able to model several relation patterns. In this section, we conduct some additional experiments to compare against RotatE, where we use RotatE as the KGE model in pLogicNet. The results are presented in Tab. 10. We see that the improvement of pLogicNet over RotatE is not as significant as over TransE, as RotatE can already implicitly model most important rules on the current datasets. However, with Markov logic networks, our framework is general to incorporate any logic rules, many of which could not be modeled by RotatE. This could be quite advantageous in some specific domains.\n\n\nAdditional Comparison with RotatE\n\n?(. 6 Figure 1 :\n61Alan Turing, Nationality, UK) \u2713 \u2713 (Alan Turing, Born in, London) (London, City of, UK) \u2717 (Alan Turing, Politician of, UK) \u2713 (Alan Turing, Live in, UK) Born in \u22c0 City of \u21d2 Nationality 1.5 Na tio na lit y \u21d0 Li ve in 0. 2 Na tio na lit y \u21d0 Po lit ici an of 2Framework overview. Each possible triplet is associated with a binary indicator (circles), indicating whether it is true () or not (). The observed (yellow circles) and hidden (grey circles) indicators are connected by a set of logic rules, with each rule having a weight (red number). For the center triplet, the KGE model predicts its indicator through embeddings, while the logic rules consider the Markov blanket of the triplet (all connected triplets). If any indicator in the Markov blanket is hidden, we simply fill it with the prediction from the KGE model. In the E-step, we use the logic rules to predict the center indicator, and treat it as extra training data for the KGE model. In the M-step, we annotate all hidden indicators with the KGE model, and then update the weights of rules.\n\nTable 1 :\n1Results of reasoning on the FB15k and WN18 datasets. The results of the KGE and the Hybrid methods except for TransE are directly taken from the corresponding papers. H@K is in %.Category \nAlgorithm \nFB15k \nWN18 \nMR \nMRR \nH@1 \nH@3 \nH@10 \nMR \nMRR \nH@1 \nH@3 \nH@10 \n\nKGE \n\nTransE [3] \n40 \n0.730 \n64.5 \n79.3 \n86.4 \n272 \n0.772 \n70.1 \n80.8 \n92.0 \nDistMult [18] \n42 \n0.798 \n-\n-\n89.3 \n655 \n0.797 \n-\n-\n94.6 \nHolE [28] \n-\n0.524 \n40.2 \n61.3 \n73.9 \n-\n0.938 \n93.0 \n94.5 \n94.9 \nComplEx [44] \n-\n0.692 \n59.9 \n75.9 \n84.0 \n-\n0.941 \n93.6 \n94.5 \n94.7 \nConvE [8] \n51 \n0.657 \n55.8 \n72.3 \n83.1 \n374 \n0.943 \n93.5 \n94.6 \n95.6 \n\nRule-based \nBLP [7] \n415 \n0.242 \n15.1 \n26.9 \n42.4 \n736 \n0.643 \n53.7 \n71.7 \n83.0 \nMLN [35] \n352 \n0.321 \n21.0 \n37.0 \n55.0 \n717 \n0.657 \n55.4 \n73.1 \n83.9 \n\nHybrid \nRUGE [15] \n-\n0.768 \n70.3 \n81.5 \n86.5 \n-\n-\n-\n-\n-\nNNE-AER [9] \n-\n0.803 \n76.1 \n83.1 \n87.4 \n-\n0.943 \n94.0 \n94.5 \n94.8 \n\nOurs \npLogicNet \n33 \n0.792 \n71.4 \n85.7 \n90.1 \n255 \n0.832 \n71.6 \n94.4 \n95.7 \npLogicNet  *  \n33 \n0.844 \n81.2 \n86.2 \n90.2 \n254 \n0.945 \n93.9 \n94.7 \n95.8 \n\n\n\nTable 2 :\n2Results of reasoning on the FB15k-237 and WN18RR datasets. The results of the KGE methods except for TransE are directly taken from the corresponding papers. H@K is in %.Category \nAlgorithm \nFB15k-237 \nWN18RR \nMR \nMRR \nH@1 \nH@3 \nH@10 \nMR \nMRR \nH@1 \nH@3 \nH@10 \n\nKGE \n\nTransE [3] \n181 \n0.326 \n22.9 \n36.3 \n52.1 \n3410 \n0.223 \n1.3 \n40.1 \n53.1 \nDistMult [18] \n254 \n0.241 \n15.5 \n26.3 \n41.9 \n5110 \n0.43 \n39 \n44 \n49 \nComplEx [44] \n339 \n0.247 \n15.8 \n27.5 \n42.8 \n5261 \n0.44 \n41 \n46 \n51 \nConvE [8] \n244 \n0.325 \n23.7 \n35.6 \n50.1 \n4187 \n0.43 \n40 \n44 \n52 \n\nRule-based \nBLP [7] \n1985 \n0.092 \n6.2 \n9.8 \n15.0 \n12051 \n0.254 \n18.7 \n31.3 \n35.8 \nMLN [35] \n1980 \n0.098 \n6.7 \n10.3 \n16.0 \n11549 \n0.259 \n19.1 \n32.2 \n36.1 \n\nOurs \npLogicNet \n173 \n0.330 \n23.1 \n36.9 \n52.8 \n3436 \n0.230 \n1.5 \n41.1 \n53.1 \npLogicNet  *  \n173 \n0.332 \n23.7 \n36.7 \n52.4 \n3408 \n0.441 \n39.8 \n44.6 \n53.7 \n\n\n\nTable 3 :\n3Analysis of different rule patterns. H@K is in %.Rule Pattern \nFB15k \nFB15k-237 \nMR MRR H@1 H@3 H@10 MR MRR H@1 H@3 H@10 \nWithout \n40 \n0.730 64.7 \n79.4 \n86.4 \n181 0.326 22.9 \n36.3 \n52.1 \nComposition \n40 \n0.752 69.3 \n78.7 \n86.0 \n173 0.335 24.1 \n37.1 \n52.5 \nInverse \n39 \n0.813 77.7 \n83.1 \n88.1 \n175 0.332 23.8 \n36.7 \n52.4 \nSymmetric \n40 \n0.793 75.0 \n81.7 \n87.1 \n175 0.333 23.8 \n36.8 \n52.4 \nSubrelation \n40 \n0.761 70.2 \n79.8 \n86.6 \n172 0.334 23.9 \n36.8 \n52.5 \n\n\nTable 4 :\n4Comparison of using different knowledge graph embedding methods. H@K is in %. achieves very robust performance with any of the three methods for inference.KGE Method Algorithm \nFB15k \nWN18RR \nMR MRR H@1 H@3 H@10 MR MRR H@1 H@3 H@10 \n\nTransE \npLogicNet \n33 \n0.792 71.4 \n85.7 \n90.1 \n3436 0.230 \n1.5 \n41.1 \n53.1 \npLogicNet  *  \n33 \n0.844 81.2 \n86.2 \n90.2 \n3408 0.441 39.8 \n44.6 \n53.7 \n\nDistMult \npLogicNet \n40 \n0.791 73.1 \n83.2 \n89.5 \n4902 0.442 39.8 \n45.5 \n53.5 \npLogicNet  *  \n39 \n0.815 76.8 \n84.6 \n89.8 \n4894 0.443 39.9 \n45.5 \n53.6 \n\nComplEx \npLogicNet \n39 \n0.776 70.6 \n81.7 \n88.5 \n5266 0.471 43.0 \n49.2 \n55.7 \npLogicNet  *  \n45 \n0.788 73.5 \n82.1 \n88.5 \n5233 0.475 43.5 \n49.2 \n55.7 \n\nIn this part, we compare the performance of pLogicNet with different knowledge graph embedding \nmethods for inference. We use TransE as the default model and compare with two other widely-used \nknowledge graph embedding methods, DistMult [48] and ComplEx [44]. The results on the FB15k \nand WN18RR datasets are presented in Tab. 4. Comparing with the results in Tab. 1 and 2, we see \nthat pLogicNet improves the performance of all the three methods by using logic rules. Moreover, \nthe pLogicNet Iteration \nFB15k \nWN18 \n# Triplets Precision # Triplets Precision \n1 \n64,929 \n79.21% \n11,146 \n80.99% \n2 \n74,717 \n79.31% \n11,430 \n82.06% \n3 \n76,268 \n79.10% \n11,432 \n82.09% \n\n\n\nTable 5 :\n5Effect of KGE on logic rules.72 \n\n73 \n\n74 \n\n75 \n\n76 \n\n1 \n2 \n3 \n4 \n\nFB15k \n\n92 \n\n93 \n\n94 \n\n95 \n\n96 \n\n1 \n2 \n3 \n4 \n\nWN18 \n\n\n\nTable 6 :\n6Dataset statistics.Dataset \n# Entities # Relations # Training # Validation # Test \nFB15k \n14,951 \n1,345 \n483,142 \n50,000 \n59,071 \nWN18 \n40,943 \n18 \n141,442 \n5,000 \n5,000 \nFB15k-237 \n14,541 \n237 \n272,115 \n17,535 \n20,466 \nWN18RR \n40,943 \n11 \n86,835 \n3,034 \n3,134 \n\n\n\nTable 7 :\n7The best hyperparameter setting of pLogicNet on several benchmarks.Dataset \nEmbedding Dim. Batch Size # Negative Samples \n\u03b1 \n\u03b3 Learning Rate \n\u03c4 rule \n\u03c4 triplet \n\u03bb \nFB15k \n1000 \n2048 \n128 \n1.0 24 \n0.0001 \n0.1 or 0.6 a \n0.7 \n0.5 \nWN18 \n500 \n512 \n1024 \n0.5 12 \n0.0001 \n0.1 \n0.5 \n100 \nFB15k-237 \n1000 \n1024 \n256 \n1.0 9 \n0.00005 \n0.6 \n0.7 \n0.5 \nWN18RR \n500 \n512 \n1024 \n0.5 6 \n0.00005 \n0.1 \n0.5 \n100 \n\n\n\nTable 8 :\n8Comparison with RUGE.Algorithm \nFB15k \nMRR H@1 H@3 H@10 \nRUGE [15] 0.768 70.3 \n81.5 \n86.5 \npLogicNet 0.786 73.3 \n82.0 \n88.2 \n\n\n\nTable 9 :\n9Comparison with NNE-AER.Algorithm \nFB15k \nWN18 \nMRR H@1 H@3 H@10 MRR H@1 H@3 H@10 \nNNE-AER [9] 0.803 76.1 \n83.1 \n87.4 \n0.943 94.0 \n94.5 \n94.8 \npLogicNet \n0.827 79.2 \n84.6 \n89.3 \n0.950 94.3 \n95.6 \n96.3 \n\n\n\nTable 10 :\n10Comparison with RotatE.Algorithm \nFB15k \nWN18 \nMR MRR H@1 H@3 H@10 MR MRR H@1 H@3 H@10 \nRotatE [40] \n40 \n0.797 74.6 \n83.0 \n88.4 \n309 0.949 94.4 \n95.2 \n95.9 \npLogicNet \n42 \n0.815 77.6 \n83.8 \n88.7 \n256 0.950 94.5 \n95.3 \n96.1 \n\n\nAcknowledgementsWe would like to thank all the reviewers for the insightful comments. We also thank Prof. Guillaume Rabusseau and Weiping Song for their valuable feedback. Jian Tang is supported by the Natural Sciences and Engineering Research Council of Canada, and the Canada CIFAR AI Chair Program.\nStatistical analysis of non-lattice data. The statistician. J Besag, J. Besag. Statistical analysis of non-lattice data. The statistician, 1975.\n\nFreebase: a collaboratively created graph database for structuring human knowledge. K Bollacker, C Evans, P Paritosh, T Sturge, J Taylor, SIGMOD. K. Bollacker, C. Evans, P. Paritosh, T. Sturge, and J. Taylor. Freebase: a collaboratively created graph database for structuring human knowledge. In SIGMOD, 2008.\n\nTranslating embeddings for modeling multi-relational data. A Bordes, N Usunier, A Garcia-Duran, J Weston, O Yakhnenko, NeurIPS. A. Bordes, N. Usunier, A. Garcia-Duran, J. Weston, and O. Yakhnenko. Translating embeddings for modeling multi-relational data. In NeurIPS, 2013.\n\nKnowledge-based recommender systems. Encyclopedia of library and information systems. R Burke, R. Burke. Knowledge-based recommender systems. Encyclopedia of library and information systems, 2000.\n\nClp (bn): Constraint logic programming for probabilistic knowledge. V S Costa, D Page, M Qazi, J Cussens, UAI. V. S. Costa, D. Page, M. Qazi, and J. Cussens. Clp (bn): Constraint logic programming for probabilistic knowledge. In UAI, 2002.\n\nGo for a walk and arrive at the answer: Reasoning over paths in knowledge bases using reinforcement learning. R Das, S Dhuliawala, M Zaheer, L Vilnis, I Durugkar, A Krishnamurthy, A Smola, A Mccallum, ICLR. R. Das, S. Dhuliawala, M. Zaheer, L. Vilnis, I. Durugkar, A. Krishnamurthy, A. Smola, and A. McCallum. Go for a walk and arrive at the answer: Reasoning over paths in knowledge bases using reinforcement learning. In ICLR, 2018.\n\nProbabilistic inductive logic programming. L De Raedt, K Kersting, Probabilistic Inductive Logic Programming. SpringerL. De Raedt and K. Kersting. Probabilistic inductive logic programming. In Probabilistic Inductive Logic Programming. Springer, 2008.\n\nConvolutional 2d knowledge graph embeddings. T Dettmers, P Minervini, P Stenetorp, S Riedel, AAAI. T. Dettmers, P. Minervini, P. Stenetorp, and S. Riedel. Convolutional 2d knowledge graph embeddings. In AAAI, 2018.\n\nImproving knowledge graph embedding using simple constraints. B Ding, Q Wang, B Wang, L Guo, ACL. B. Ding, Q. Wang, B. Wang, and L. Guo. Improving knowledge graph embedding using simple constraints. In ACL, 2018.\n\nAmie: association rule mining under incomplete evidence in ontological knowledge bases. L A Gal\u00e1rraga, C Teflioudi, K Hose, F Suchanek, WWWL. A. Gal\u00e1rraga, C. Teflioudi, K. Hose, and F. Suchanek. Amie: association rule mining under incomplete evidence in ontological knowledge bases. In WWW, 2013.\n\nAmortized inference in probabilistic reasoning. S Gershman, N Goodman, CogSci. S. Gershman and N. Goodman. Amortized inference in probabilistic reasoning. In CogSci, 2014.\n\nExpert systems. PWS publishing co. J C Giarratano, G Riley, J. C. Giarratano and G. Riley. Expert systems. PWS publishing co., 1998.\n\nMarkov chain Monte Carlo in practice. W R Gilks, S Richardson, D Spiegelhalter, Chapman and Hall/CRCW. R. Gilks, S. Richardson, and D. Spiegelhalter. Markov chain Monte Carlo in practice. Chapman and Hall/CRC, 1995.\n\nFreebase data dumps. Google, Google. Freebase data dumps. https://developers.google.com/freebase/data.\n\nKnowledge graph embedding with iterative guidance from soft rules. S Guo, Q Wang, L Wang, B Wang, L Guo, AAAI. S. Guo, Q. Wang, L. Wang, B. Wang, and L. Guo. Knowledge graph embedding with iterative guidance from soft rules. In AAAI, 2018.\n\nStochastic variational inference. M D Hoffman, D M Blei, C Wang, J Paisley, The Journal of Machine Learning Research. M. D. Hoffman, D. M. Blei, C. Wang, and J. Paisley. Stochastic variational inference. The Journal of Machine Learning Research, 2013.\n\nIntroduction to expert systems. P Jackson, Addison-Wesley Longman Publishing Co., IncP. Jackson. Introduction to expert systems. Addison-Wesley Longman Publishing Co., Inc., 1998.\n\nKnowledge base completion: Baselines strike back. R Kadlec, O Bajgar, J Kleindienst, Workshop on Representation Learning for NLP. R. Kadlec, O. Bajgar, and J. Kleindienst. Knowledge base completion: Baselines strike back. In Workshop on Representation Learning for NLP, 2017.\n\nTowards combining inductive logic programming with bayesian networks. K Kersting, L De Raedt, ICILP. K. Kersting and L. De Raedt. Towards combining inductive logic programming with bayesian networks. In ICILP, 2001.\n\nAdam: A method for stochastic optimization. D P Kingma, J Ba, ICLR. D. P. Kingma and J. Ba. Adam: A method for stochastic optimization. In ICLR, 2014.\n\nAuto-encoding variational bayes. D P Kingma, M Welling, ICLR. D. P. Kingma and M. Welling. Auto-encoding variational bayes. In ICLR, 2014.\n\nLearning the structure of markov logic networks. S Kok, P Domingos, ICML. S. Kok and P. Domingos. Learning the structure of markov logic networks. In ICML, 2005.\n\nMulti-hop knowledge graph reasoning with reward shaping. X V Lin, R Socher, C Xiong, In EMNLP. X. V. Lin, R. Socher, and C. Xiong. Multi-hop knowledge graph reasoning with reward shaping. In EMNLP, 2018.\n\nWordnet: a lexical database for english. G A Miller, Communications of the ACM. G. A. Miller. Wordnet: a lexical database for english. Communications of the ACM, 1995.\n\nLoopy belief propagation for approximate inference: An empirical study. K P Murphy, Y Weiss, M I Jordan, UAI. K. P. Murphy, Y. Weiss, and M. I. Jordan. Loopy belief propagation for approximate inference: An empirical study. In UAI, 1999.\n\nA view of the em algorithm that justifies incremental, sparse, and other variants. R M Neal, G E Hinton, Learning in graphical models. SpringerR. M. Neal and G. E. Hinton. A view of the em algorithm that justifies incremental, sparse, and other variants. In Learning in graphical models. Springer, 1998.\n\nA review of relational machine learning for knowledge graphs. M Nickel, K Murphy, V Tresp, E Gabrilovich, Proceedings of the IEEE. the IEEEM. Nickel, K. Murphy, V. Tresp, and E. Gabrilovich. A review of relational machine learning for knowledge graphs. Proceedings of the IEEE, 2016.\n\nHolographic embeddings of knowledge graphs. M Nickel, L Rosasco, T Poggio, AAAI. M. Nickel, L. Rosasco, and T. Poggio. Holographic embeddings of knowledge graphs. In AAAI, 2016.\n\nAdvanced mean field methods: Theory and practice. M Opper, D Saad, MIT pressM. Opper and D. Saad. Advanced mean field methods: Theory and practice. MIT press, 2001.\n\nProbabilistic horn abduction and bayesian networks. D Poole, Artificial intelligence. D. Poole. Probabilistic horn abduction and bayesian networks. Artificial intelligence, 1993.\n\nStructural logistic regression for link analysis. Departmental Papers (CIS). A Popescul, L H Ungar, 133A. Popescul and L. H. Ungar. Structural logistic regression for link analysis. Departmental Papers (CIS), page 133, 2003.\n\nLearning human-object interactions by graph parsing neural networks. S Qi, W Wang, B Jia, J Shen, S.-C Zhu, In ECCV. S. Qi, W. Wang, B. Jia, J. Shen, and S.-C. Zhu. Learning human-object interactions by graph parsing neural networks. In ECCV, 2018.\n\nGmnn: Graph markov neural networks. M Qu, Y Bengio, J Tang, ICML. M. Qu, Y. Bengio, and J. Tang. Gmnn: Graph markov neural networks. In ICML, 2019.\n\nWeakly-supervised relation extraction by pattern-enhanced embedding learning. M Qu, X Ren, Y Zhang, J Han, WWWM. Qu, X. Ren, Y. Zhang, and J. Han. Weakly-supervised relation extraction by pattern-enhanced embedding learning. In WWW, 2018.\n\nMarkov logic networks. Machine learning. M Richardson, P Domingos, M. Richardson and P. Domingos. Markov logic networks. Machine learning, 2006.\n\nEfficient learning of deep boltzmann machines. R Salakhutdinov, H Larochelle, AISTATS. R. Salakhutdinov and H. Larochelle. Efficient learning of deep boltzmann machines. In AISTATS, 2010.\n\nModeling relational data with graph convolutional networks. M Schlichtkrull, T N Kipf, P Bloem, R Van Den, I Berg, M Titov, Welling, European Semantic Web Conference. M. Schlichtkrull, T. N. Kipf, P. Bloem, R. Van Den Berg, I. Titov, and M. Welling. Modeling relational data with graph convolutional networks. In European Semantic Web Conference, 2018.\n\nM-walk: Learning to walk over graphs using monte carlo tree search. Y Shen, J Chen, P.-S Huang, Y Guo, J Gao, In NeurIPS. Y. Shen, J. Chen, P.-S. Huang, Y. Guo, and J. Gao. M-walk: Learning to walk over graphs using monte carlo tree search. In NeurIPS, 2018.\n\nDiscriminative training of markov logic networks. P Singla, P Domingos, AAAI. P. Singla and P. Domingos. Discriminative training of markov logic networks. In AAAI, 2005.\n\nRotate: Knowledge graph embedding by relational rotation in complex space. Z Sun, Z.-H Deng, J.-Y Nie, J Tang, ICLRZ. Sun, Z.-H. Deng, J.-Y. Nie, and J. Tang. Rotate: Knowledge graph embedding by relational rotation in complex space. ICLR, 2019.\n\nDiscriminative probabilistic models for relational data. B Taskar, P Abbeel, D Koller, UAI. B. Taskar, P. Abbeel, and D. Koller. Discriminative probabilistic models for relational data. In UAI, 2002.\n\nRelational markov networks. Introduction to statistical relational learning. B Taskar, P Abbeel, M.-F Wong, D Koller, B. Taskar, P. Abbeel, M.-F. Wong, and D. Koller. Relational markov networks. Introduction to statistical relational learning, 2007.\n\nObserved versus latent features for knowledge base and text inference. K Toutanova, D Chen, Proceedings of the 3rd Workshop on Continuous Vector Space Models and their Compositionality. the 3rd Workshop on Continuous Vector Space Models and their CompositionalityK. Toutanova and D. Chen. Observed versus latent features for knowledge base and text inference. In Proceedings of the 3rd Workshop on Continuous Vector Space Models and their Compositionality, 2015.\n\nComplex embeddings for simple link prediction. T Trouillon, J Welbl, S Riedel, \u00c9 Gaussier, G Bouchard, ICML. T. Trouillon, J. Welbl, S. Riedel, \u00c9. Gaussier, and G. Bouchard. Complex embeddings for simple link prediction. In ICML, 2016.\n\nKnowledge graph embedding by translating on hyperplanes. Z Wang, J Zhang, J Feng, Z Chen, AAAI. Z. Wang, J. Zhang, J. Feng, and Z. Chen. Knowledge graph embedding by translating on hyperplanes. In AAAI, 2014.\n\nFrom knowledge bases to decision models. The Knowledge Engineering Review. M P Wellman, J S Breese, R P Goldman, M. P. Wellman, J. S. Breese, and R. P. Goldman. From knowledge bases to decision models. The Knowledge Engineering Review, 1992.\n\nDeeppath: A reinforcement learning method for knowledge graph reasoning. W Xiong, T Hoang, W Y Wang, W. Xiong, T. Hoang, and W. Y. Wang. Deeppath: A reinforcement learning method for knowledge graph reasoning. In EMNLP, 2017.\n\nEmbedding entities and relations for learning and inference in knowledge bases. B Yang, W Yih, X He, J Gao, L Deng, ICLRB. Yang, W.-t. Yih, X. He, J. Gao, and L. Deng. Embedding entities and relations for learning and inference in knowledge bases. ICLR, 2015.\n\nInformation extraction over structured data: Question answering with freebase. X Yao, B Van Durme, ACL. X. Yao and B. Van Durme. Information extraction over structured data: Question answering with freebase. In ACL, 2014.\n\nY Zhang, X Chen, Y Yang, A Ramamurthy, B Li, Y Qi, L Song, arXiv:1906.02111Can graph neural networks help logic reasoning. Y. Zhang, X. Chen, Y. Yang, A. Ramamurthy, B. Li, Y. Qi, and L. Song. Can graph neural networks help logic reasoning? arXiv:1906.02111, 2019.\n\nReasoning visual dialogs with structural and partial observations. Z Zheng, W Wang, S Qi, S.-C Zhu, CVPR. Z. Zheng, W. Wang, S. Qi, and S.-C. Zhu. Reasoning visual dialogs with structural and partial observations. In CVPR, 2019.\n", "annotations": {"author": "[{\"end\":114,\"start\":53},{\"end\":194,\"start\":115}]", "publisher": null, "author_last_name": "[{\"end\":60,\"start\":58},{\"end\":124,\"start\":120}]", "author_first_name": "[{\"end\":57,\"start\":53},{\"end\":119,\"start\":115}]", "author_affiliation": "[{\"end\":88,\"start\":62},{\"end\":113,\"start\":90},{\"end\":152,\"start\":126},{\"end\":167,\"start\":154},{\"end\":193,\"start\":169}]", "title": "[{\"end\":50,\"start\":1},{\"end\":244,\"start\":195}]", "venue": null, "abstract": "[{\"end\":1961,\"start\":246}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b13\"},\"end\":2335,\"start\":2331},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":2352,\"start\":2348},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":2437,\"start\":2433},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":2463,\"start\":2459},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2491,\"start\":2488},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":2782,\"start\":2778},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":2785,\"start\":2782},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":2788,\"start\":2785},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":2791,\"start\":2788},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":2794,\"start\":2791},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":2856,\"start\":2852},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":2903,\"start\":2899},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":2952,\"start\":2948},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":2955,\"start\":2952},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":3377,\"start\":3373},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":3380,\"start\":3377},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":4634,\"start\":4630},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":4752,\"start\":4748},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":4899,\"start\":4895},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":4902,\"start\":4899},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":4905,\"start\":4902},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":5090,\"start\":5087},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":5557,\"start\":5553},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":5560,\"start\":5557},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":5741,\"start\":5738},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":5744,\"start\":5741},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":5747,\"start\":5744},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":5750,\"start\":5747},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":5783,\"start\":5779},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":5786,\"start\":5783},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":5845,\"start\":5841},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":5848,\"start\":5845},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":6487,\"start\":6484},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":6489,\"start\":6487},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":6492,\"start\":6489},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":6495,\"start\":6492},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":6498,\"start\":6495},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":6501,\"start\":6498},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":6504,\"start\":6501},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":6712,\"start\":6709},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":6848,\"start\":6844},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":6925,\"start\":6921},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":7024,\"start\":7020},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":7348,\"start\":7345},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":7351,\"start\":7348},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":7669,\"start\":7666},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":7672,\"start\":7669},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":7675,\"start\":7672},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":7678,\"start\":7675},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":8026,\"start\":8022},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":8085,\"start\":8081},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":8088,\"start\":8085},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":8320,\"start\":8316},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":9055,\"start\":9051},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":9735,\"start\":9731},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":9921,\"start\":9917},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":9967,\"start\":9964},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":9970,\"start\":9967},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":9973,\"start\":9970},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":12272,\"start\":12268},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":12306,\"start\":12302},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":13127,\"start\":13123},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":13861,\"start\":13857},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":13918,\"start\":13914},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":14609,\"start\":14605},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":15503,\"start\":15499},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":16199,\"start\":16195},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":16367,\"start\":16363},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":16370,\"start\":16367},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":17522,\"start\":17518},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":18743,\"start\":18739},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":20320,\"start\":20316},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":20323,\"start\":20320},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":20378,\"start\":20375},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":22329,\"start\":22325},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":23506,\"start\":23503},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":23525,\"start\":23521},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":23568,\"start\":23565},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":23578,\"start\":23575},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":23593,\"start\":23590},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":23627,\"start\":23623},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":23937,\"start\":23934},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":23940,\"start\":23937},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":24313,\"start\":24310},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":24328,\"start\":24324},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":24339,\"start\":24335},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":24353,\"start\":24349},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":24367,\"start\":24364},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":24448,\"start\":24444},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":24500,\"start\":24497},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":24622,\"start\":24618},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":24638,\"start\":24635},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":25035,\"start\":25031},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":25277,\"start\":25273},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":25280,\"start\":25277},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":25557,\"start\":25554},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":27386,\"start\":27385},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":28654,\"start\":28650},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":28670,\"start\":28666},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":28886,\"start\":28883},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":28925,\"start\":28921},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":29260,\"start\":29256},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":29279,\"start\":29275},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":29870,\"start\":29866},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":29886,\"start\":29883},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":30188,\"start\":30184},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":30382,\"start\":30378},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":30994,\"start\":30990},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":31401,\"start\":31397},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":31692,\"start\":31690}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":33178,\"start\":32105},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":34221,\"start\":33179},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":35085,\"start\":34222},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":35555,\"start\":35086},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":36921,\"start\":35556},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":37054,\"start\":36922},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":37330,\"start\":37055},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":37739,\"start\":37331},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":37878,\"start\":37740},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":38094,\"start\":37879},{\"attributes\":{\"id\":\"tab_9\",\"type\":\"table\"},\"end\":38334,\"start\":38095}]", "paragraph": "[{\"end\":2677,\"start\":1977},{\"end\":3858,\"start\":2679},{\"end\":4206,\"start\":3860},{\"end\":5387,\"start\":4208},{\"end\":6383,\"start\":5404},{\"end\":7571,\"start\":6385},{\"end\":7861,\"start\":7573},{\"end\":8458,\"start\":7863},{\"end\":8792,\"start\":8495},{\"end\":9493,\"start\":8794},{\"end\":9974,\"start\":9495},{\"end\":10519,\"start\":9999},{\"end\":10742,\"start\":10521},{\"end\":11168,\"start\":10744},{\"end\":11799,\"start\":11170},{\"end\":11998,\"start\":11899},{\"end\":12307,\"start\":12000},{\"end\":12735,\"start\":12337},{\"end\":13390,\"start\":12805},{\"end\":13509,\"start\":13412},{\"end\":14485,\"start\":13519},{\"end\":14697,\"start\":14504},{\"end\":15154,\"start\":14753},{\"end\":15250,\"start\":15245},{\"end\":15874,\"start\":15415},{\"end\":15957,\"start\":15912},{\"end\":16490,\"start\":15989},{\"end\":16899,\"start\":16584},{\"end\":17313,\"start\":17014},{\"end\":17966,\"start\":17315},{\"end\":18553,\"start\":17968},{\"end\":19008,\"start\":18685},{\"end\":19193,\"start\":19084},{\"end\":19607,\"start\":19195},{\"end\":19782,\"start\":19609},{\"end\":19934,\"start\":19829},{\"end\":20098,\"start\":19965},{\"end\":20379,\"start\":20136},{\"end\":20599,\"start\":20505},{\"end\":20815,\"start\":20601},{\"end\":20893,\"start\":20817},{\"end\":21071,\"start\":20995},{\"end\":21429,\"start\":21322},{\"end\":21711,\"start\":21431},{\"end\":22330,\"start\":21743},{\"end\":22716,\"start\":22332},{\"end\":23060,\"start\":22946},{\"end\":23376,\"start\":23062},{\"end\":23696,\"start\":23413},{\"end\":24090,\"start\":23720},{\"end\":25036,\"start\":24092},{\"end\":26343,\"start\":25038},{\"end\":26729,\"start\":26396},{\"end\":27630,\"start\":26822},{\"end\":27962,\"start\":27655},{\"end\":28671,\"start\":27977},{\"end\":28774,\"start\":28713},{\"end\":30024,\"start\":28802},{\"end\":30546,\"start\":30070},{\"end\":30821,\"start\":30548},{\"end\":32068,\"start\":30823}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":11898,\"start\":11800},{\"attributes\":{\"id\":\"formula_1\"},\"end\":12804,\"start\":12736},{\"attributes\":{\"id\":\"formula_2\"},\"end\":13411,\"start\":13391},{\"attributes\":{\"id\":\"formula_3\"},\"end\":14752,\"start\":14698},{\"attributes\":{\"id\":\"formula_4\"},\"end\":15244,\"start\":15155},{\"attributes\":{\"id\":\"formula_5\"},\"end\":15414,\"start\":15251},{\"attributes\":{\"id\":\"formula_6\"},\"end\":15911,\"start\":15875},{\"attributes\":{\"id\":\"formula_7\"},\"end\":16583,\"start\":16491},{\"attributes\":{\"id\":\"formula_8\"},\"end\":17013,\"start\":16900},{\"attributes\":{\"id\":\"formula_9\"},\"end\":18684,\"start\":18554},{\"attributes\":{\"id\":\"formula_10\"},\"end\":19083,\"start\":19009},{\"attributes\":{\"id\":\"formula_11\"},\"end\":19828,\"start\":19783},{\"attributes\":{\"id\":\"formula_12\"},\"end\":20135,\"start\":20099},{\"attributes\":{\"id\":\"formula_13\"},\"end\":20504,\"start\":20380},{\"attributes\":{\"id\":\"formula_14\"},\"end\":20994,\"start\":20894},{\"attributes\":{\"id\":\"formula_15\"},\"end\":21321,\"start\":21072},{\"attributes\":{\"id\":\"formula_16\"},\"end\":22866,\"start\":22717},{\"attributes\":{\"id\":\"formula_17\"},\"end\":22945,\"start\":22866}]", "table_ref": null, "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1975,\"start\":1963},{\"attributes\":{\"n\":\"2\"},\"end\":5402,\"start\":5390},{\"attributes\":{\"n\":\"3\"},\"end\":8472,\"start\":8461},{\"attributes\":{\"n\":\"3.1\"},\"end\":8493,\"start\":8475},{\"attributes\":{\"n\":\"3.2\"},\"end\":9997,\"start\":9977},{\"attributes\":{\"n\":\"3.3\"},\"end\":12335,\"start\":12310},{\"attributes\":{\"n\":\"4\"},\"end\":13517,\"start\":13512},{\"attributes\":{\"n\":\"4.1\"},\"end\":14502,\"start\":14488},{\"attributes\":{\"n\":\"4.2\"},\"end\":15987,\"start\":15960},{\"attributes\":{\"n\":\"4.3\"},\"end\":19963,\"start\":19937},{\"attributes\":{\"n\":\"4.4\"},\"end\":21741,\"start\":21714},{\"attributes\":{\"n\":\"5\"},\"end\":23389,\"start\":23379},{\"attributes\":{\"n\":\"5.1\"},\"end\":23411,\"start\":23392},{\"end\":23718,\"start\":23699},{\"attributes\":{\"n\":\"5.2\"},\"end\":26353,\"start\":26346},{\"attributes\":{\"n\":\"5.2.1\"},\"end\":26394,\"start\":26356},{\"attributes\":{\"n\":\"5.2.2\"},\"end\":26767,\"start\":26732},{\"attributes\":{\"n\":\"5.2.4\"},\"end\":26820,\"start\":26770},{\"attributes\":{\"n\":\"5.2.5\"},\"end\":27653,\"start\":27633},{\"attributes\":{\"n\":\"6\"},\"end\":27975,\"start\":27965},{\"attributes\":{\"n\":\"7\"},\"end\":28682,\"start\":28674},{\"attributes\":{\"n\":\"7.1\"},\"end\":28711,\"start\":28685},{\"attributes\":{\"n\":\"7.2\"},\"end\":28800,\"start\":28777},{\"attributes\":{\"n\":\"7.3\"},\"end\":30068,\"start\":30027},{\"attributes\":{\"n\":\"7.4\"},\"end\":32104,\"start\":32071},{\"end\":32122,\"start\":32106},{\"end\":33189,\"start\":33180},{\"end\":34232,\"start\":34223},{\"end\":35096,\"start\":35087},{\"end\":35566,\"start\":35557},{\"end\":36932,\"start\":36923},{\"end\":37065,\"start\":37056},{\"end\":37341,\"start\":37332},{\"end\":37750,\"start\":37741},{\"end\":37889,\"start\":37880},{\"end\":38106,\"start\":38096}]", "table": "[{\"end\":34221,\"start\":33370},{\"end\":35085,\"start\":34404},{\"end\":35555,\"start\":35147},{\"end\":36921,\"start\":35723},{\"end\":37054,\"start\":36963},{\"end\":37330,\"start\":37086},{\"end\":37739,\"start\":37410},{\"end\":37878,\"start\":37773},{\"end\":38094,\"start\":37915},{\"end\":38334,\"start\":38132}]", "figure_caption": "[{\"end\":33178,\"start\":32125},{\"end\":33370,\"start\":33191},{\"end\":34404,\"start\":34234},{\"end\":35147,\"start\":35098},{\"end\":35723,\"start\":35568},{\"end\":36963,\"start\":36934},{\"end\":37086,\"start\":37067},{\"end\":37410,\"start\":37343},{\"end\":37773,\"start\":37752},{\"end\":37915,\"start\":37891},{\"end\":38132,\"start\":38109}]", "figure_ref": "[{\"end\":14484,\"start\":14478},{\"end\":18286,\"start\":18279},{\"end\":21068,\"start\":21061},{\"end\":22438,\"start\":22432},{\"end\":26706,\"start\":26698},{\"end\":27753,\"start\":27747}]", "bib_author_first_name": "[{\"end\":38698,\"start\":38697},{\"end\":38868,\"start\":38867},{\"end\":38881,\"start\":38880},{\"end\":38890,\"start\":38889},{\"end\":38902,\"start\":38901},{\"end\":38912,\"start\":38911},{\"end\":39154,\"start\":39153},{\"end\":39164,\"start\":39163},{\"end\":39175,\"start\":39174},{\"end\":39191,\"start\":39190},{\"end\":39201,\"start\":39200},{\"end\":39456,\"start\":39455},{\"end\":39636,\"start\":39635},{\"end\":39638,\"start\":39637},{\"end\":39647,\"start\":39646},{\"end\":39655,\"start\":39654},{\"end\":39663,\"start\":39662},{\"end\":39919,\"start\":39918},{\"end\":39926,\"start\":39925},{\"end\":39940,\"start\":39939},{\"end\":39950,\"start\":39949},{\"end\":39960,\"start\":39959},{\"end\":39972,\"start\":39971},{\"end\":39989,\"start\":39988},{\"end\":39998,\"start\":39997},{\"end\":40288,\"start\":40287},{\"end\":40300,\"start\":40299},{\"end\":40543,\"start\":40542},{\"end\":40555,\"start\":40554},{\"end\":40568,\"start\":40567},{\"end\":40581,\"start\":40580},{\"end\":40776,\"start\":40775},{\"end\":40784,\"start\":40783},{\"end\":40792,\"start\":40791},{\"end\":40800,\"start\":40799},{\"end\":41016,\"start\":41015},{\"end\":41018,\"start\":41017},{\"end\":41031,\"start\":41030},{\"end\":41044,\"start\":41043},{\"end\":41052,\"start\":41051},{\"end\":41275,\"start\":41274},{\"end\":41287,\"start\":41286},{\"end\":41435,\"start\":41434},{\"end\":41437,\"start\":41436},{\"end\":41451,\"start\":41450},{\"end\":41572,\"start\":41571},{\"end\":41574,\"start\":41573},{\"end\":41583,\"start\":41582},{\"end\":41597,\"start\":41596},{\"end\":41922,\"start\":41921},{\"end\":41929,\"start\":41928},{\"end\":41937,\"start\":41936},{\"end\":41945,\"start\":41944},{\"end\":41953,\"start\":41952},{\"end\":42130,\"start\":42129},{\"end\":42132,\"start\":42131},{\"end\":42143,\"start\":42142},{\"end\":42145,\"start\":42144},{\"end\":42153,\"start\":42152},{\"end\":42161,\"start\":42160},{\"end\":42381,\"start\":42380},{\"end\":42580,\"start\":42579},{\"end\":42590,\"start\":42589},{\"end\":42600,\"start\":42599},{\"end\":42877,\"start\":42876},{\"end\":42889,\"start\":42888},{\"end\":43068,\"start\":43067},{\"end\":43070,\"start\":43069},{\"end\":43080,\"start\":43079},{\"end\":43209,\"start\":43208},{\"end\":43211,\"start\":43210},{\"end\":43221,\"start\":43220},{\"end\":43365,\"start\":43364},{\"end\":43372,\"start\":43371},{\"end\":43536,\"start\":43535},{\"end\":43538,\"start\":43537},{\"end\":43545,\"start\":43544},{\"end\":43555,\"start\":43554},{\"end\":43725,\"start\":43724},{\"end\":43727,\"start\":43726},{\"end\":43925,\"start\":43924},{\"end\":43927,\"start\":43926},{\"end\":43937,\"start\":43936},{\"end\":43946,\"start\":43945},{\"end\":43948,\"start\":43947},{\"end\":44175,\"start\":44174},{\"end\":44177,\"start\":44176},{\"end\":44185,\"start\":44184},{\"end\":44187,\"start\":44186},{\"end\":44459,\"start\":44458},{\"end\":44469,\"start\":44468},{\"end\":44479,\"start\":44478},{\"end\":44488,\"start\":44487},{\"end\":44726,\"start\":44725},{\"end\":44736,\"start\":44735},{\"end\":44747,\"start\":44746},{\"end\":44911,\"start\":44910},{\"end\":44920,\"start\":44919},{\"end\":45079,\"start\":45078},{\"end\":45284,\"start\":45283},{\"end\":45296,\"start\":45295},{\"end\":45298,\"start\":45297},{\"end\":45502,\"start\":45501},{\"end\":45508,\"start\":45507},{\"end\":45516,\"start\":45515},{\"end\":45523,\"start\":45522},{\"end\":45534,\"start\":45530},{\"end\":45719,\"start\":45718},{\"end\":45725,\"start\":45724},{\"end\":45735,\"start\":45734},{\"end\":45910,\"start\":45909},{\"end\":45916,\"start\":45915},{\"end\":45923,\"start\":45922},{\"end\":45932,\"start\":45931},{\"end\":46113,\"start\":46112},{\"end\":46127,\"start\":46126},{\"end\":46265,\"start\":46264},{\"end\":46282,\"start\":46281},{\"end\":46467,\"start\":46466},{\"end\":46484,\"start\":46483},{\"end\":46486,\"start\":46485},{\"end\":46494,\"start\":46493},{\"end\":46503,\"start\":46502},{\"end\":46514,\"start\":46513},{\"end\":46522,\"start\":46521},{\"end\":46829,\"start\":46828},{\"end\":46837,\"start\":46836},{\"end\":46848,\"start\":46844},{\"end\":46857,\"start\":46856},{\"end\":46864,\"start\":46863},{\"end\":47071,\"start\":47070},{\"end\":47081,\"start\":47080},{\"end\":47267,\"start\":47266},{\"end\":47277,\"start\":47273},{\"end\":47288,\"start\":47284},{\"end\":47295,\"start\":47294},{\"end\":47496,\"start\":47495},{\"end\":47506,\"start\":47505},{\"end\":47516,\"start\":47515},{\"end\":47717,\"start\":47716},{\"end\":47727,\"start\":47726},{\"end\":47740,\"start\":47736},{\"end\":47748,\"start\":47747},{\"end\":47962,\"start\":47961},{\"end\":47975,\"start\":47974},{\"end\":48402,\"start\":48401},{\"end\":48415,\"start\":48414},{\"end\":48424,\"start\":48423},{\"end\":48434,\"start\":48433},{\"end\":48446,\"start\":48445},{\"end\":48649,\"start\":48648},{\"end\":48657,\"start\":48656},{\"end\":48666,\"start\":48665},{\"end\":48674,\"start\":48673},{\"end\":48877,\"start\":48876},{\"end\":48879,\"start\":48878},{\"end\":48890,\"start\":48889},{\"end\":48892,\"start\":48891},{\"end\":48902,\"start\":48901},{\"end\":48904,\"start\":48903},{\"end\":49118,\"start\":49117},{\"end\":49127,\"start\":49126},{\"end\":49136,\"start\":49135},{\"end\":49138,\"start\":49137},{\"end\":49352,\"start\":49351},{\"end\":49360,\"start\":49359},{\"end\":49367,\"start\":49366},{\"end\":49373,\"start\":49372},{\"end\":49380,\"start\":49379},{\"end\":49612,\"start\":49611},{\"end\":49619,\"start\":49618},{\"end\":49756,\"start\":49755},{\"end\":49765,\"start\":49764},{\"end\":49773,\"start\":49772},{\"end\":49781,\"start\":49780},{\"end\":49795,\"start\":49794},{\"end\":49801,\"start\":49800},{\"end\":49807,\"start\":49806},{\"end\":50089,\"start\":50088},{\"end\":50098,\"start\":50097},{\"end\":50106,\"start\":50105},{\"end\":50115,\"start\":50111}]", "bib_author_last_name": "[{\"end\":38704,\"start\":38699},{\"end\":38878,\"start\":38869},{\"end\":38887,\"start\":38882},{\"end\":38899,\"start\":38891},{\"end\":38909,\"start\":38903},{\"end\":38919,\"start\":38913},{\"end\":39161,\"start\":39155},{\"end\":39172,\"start\":39165},{\"end\":39188,\"start\":39176},{\"end\":39198,\"start\":39192},{\"end\":39211,\"start\":39202},{\"end\":39462,\"start\":39457},{\"end\":39644,\"start\":39639},{\"end\":39652,\"start\":39648},{\"end\":39660,\"start\":39656},{\"end\":39671,\"start\":39664},{\"end\":39923,\"start\":39920},{\"end\":39937,\"start\":39927},{\"end\":39947,\"start\":39941},{\"end\":39957,\"start\":39951},{\"end\":39969,\"start\":39961},{\"end\":39986,\"start\":39973},{\"end\":39995,\"start\":39990},{\"end\":40007,\"start\":39999},{\"end\":40297,\"start\":40289},{\"end\":40309,\"start\":40301},{\"end\":40552,\"start\":40544},{\"end\":40565,\"start\":40556},{\"end\":40578,\"start\":40569},{\"end\":40588,\"start\":40582},{\"end\":40781,\"start\":40777},{\"end\":40789,\"start\":40785},{\"end\":40797,\"start\":40793},{\"end\":40804,\"start\":40801},{\"end\":41028,\"start\":41019},{\"end\":41041,\"start\":41032},{\"end\":41049,\"start\":41045},{\"end\":41061,\"start\":41053},{\"end\":41284,\"start\":41276},{\"end\":41295,\"start\":41288},{\"end\":41448,\"start\":41438},{\"end\":41457,\"start\":41452},{\"end\":41580,\"start\":41575},{\"end\":41594,\"start\":41584},{\"end\":41611,\"start\":41598},{\"end\":41777,\"start\":41771},{\"end\":41926,\"start\":41923},{\"end\":41934,\"start\":41930},{\"end\":41942,\"start\":41938},{\"end\":41950,\"start\":41946},{\"end\":41957,\"start\":41954},{\"end\":42140,\"start\":42133},{\"end\":42150,\"start\":42146},{\"end\":42158,\"start\":42154},{\"end\":42169,\"start\":42162},{\"end\":42389,\"start\":42382},{\"end\":42587,\"start\":42581},{\"end\":42597,\"start\":42591},{\"end\":42612,\"start\":42601},{\"end\":42886,\"start\":42878},{\"end\":42898,\"start\":42890},{\"end\":43077,\"start\":43071},{\"end\":43083,\"start\":43081},{\"end\":43218,\"start\":43212},{\"end\":43229,\"start\":43222},{\"end\":43369,\"start\":43366},{\"end\":43381,\"start\":43373},{\"end\":43542,\"start\":43539},{\"end\":43552,\"start\":43546},{\"end\":43561,\"start\":43556},{\"end\":43734,\"start\":43728},{\"end\":43934,\"start\":43928},{\"end\":43943,\"start\":43938},{\"end\":43955,\"start\":43949},{\"end\":44182,\"start\":44178},{\"end\":44194,\"start\":44188},{\"end\":44466,\"start\":44460},{\"end\":44476,\"start\":44470},{\"end\":44485,\"start\":44480},{\"end\":44500,\"start\":44489},{\"end\":44733,\"start\":44727},{\"end\":44744,\"start\":44737},{\"end\":44754,\"start\":44748},{\"end\":44917,\"start\":44912},{\"end\":44925,\"start\":44921},{\"end\":45085,\"start\":45080},{\"end\":45293,\"start\":45285},{\"end\":45304,\"start\":45299},{\"end\":45505,\"start\":45503},{\"end\":45513,\"start\":45509},{\"end\":45520,\"start\":45517},{\"end\":45528,\"start\":45524},{\"end\":45538,\"start\":45535},{\"end\":45722,\"start\":45720},{\"end\":45732,\"start\":45726},{\"end\":45740,\"start\":45736},{\"end\":45913,\"start\":45911},{\"end\":45920,\"start\":45917},{\"end\":45929,\"start\":45924},{\"end\":45936,\"start\":45933},{\"end\":46124,\"start\":46114},{\"end\":46136,\"start\":46128},{\"end\":46279,\"start\":46266},{\"end\":46293,\"start\":46283},{\"end\":46481,\"start\":46468},{\"end\":46491,\"start\":46487},{\"end\":46500,\"start\":46495},{\"end\":46511,\"start\":46504},{\"end\":46519,\"start\":46515},{\"end\":46528,\"start\":46523},{\"end\":46537,\"start\":46530},{\"end\":46834,\"start\":46830},{\"end\":46842,\"start\":46838},{\"end\":46854,\"start\":46849},{\"end\":46861,\"start\":46858},{\"end\":46868,\"start\":46865},{\"end\":47078,\"start\":47072},{\"end\":47090,\"start\":47082},{\"end\":47271,\"start\":47268},{\"end\":47282,\"start\":47278},{\"end\":47292,\"start\":47289},{\"end\":47300,\"start\":47296},{\"end\":47503,\"start\":47497},{\"end\":47513,\"start\":47507},{\"end\":47523,\"start\":47517},{\"end\":47724,\"start\":47718},{\"end\":47734,\"start\":47728},{\"end\":47745,\"start\":47741},{\"end\":47755,\"start\":47749},{\"end\":47972,\"start\":47963},{\"end\":47980,\"start\":47976},{\"end\":48412,\"start\":48403},{\"end\":48421,\"start\":48416},{\"end\":48431,\"start\":48425},{\"end\":48443,\"start\":48435},{\"end\":48455,\"start\":48447},{\"end\":48654,\"start\":48650},{\"end\":48663,\"start\":48658},{\"end\":48671,\"start\":48667},{\"end\":48679,\"start\":48675},{\"end\":48887,\"start\":48880},{\"end\":48899,\"start\":48893},{\"end\":48912,\"start\":48905},{\"end\":49124,\"start\":49119},{\"end\":49133,\"start\":49128},{\"end\":49143,\"start\":49139},{\"end\":49357,\"start\":49353},{\"end\":49364,\"start\":49361},{\"end\":49370,\"start\":49368},{\"end\":49377,\"start\":49374},{\"end\":49385,\"start\":49381},{\"end\":49616,\"start\":49613},{\"end\":49629,\"start\":49620},{\"end\":49762,\"start\":49757},{\"end\":49770,\"start\":49766},{\"end\":49778,\"start\":49774},{\"end\":49792,\"start\":49782},{\"end\":49798,\"start\":49796},{\"end\":49804,\"start\":49802},{\"end\":49812,\"start\":49808},{\"end\":50095,\"start\":50090},{\"end\":50103,\"start\":50099},{\"end\":50109,\"start\":50107},{\"end\":50119,\"start\":50116}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":38781,\"start\":38637},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":207167677},\"end\":39092,\"start\":38783},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":14941970},\"end\":39367,\"start\":39094},{\"attributes\":{\"id\":\"b3\"},\"end\":39565,\"start\":39369},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":3135523},\"end\":39806,\"start\":39567},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":13206339},\"end\":40242,\"start\":39808},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":957577},\"end\":40495,\"start\":40244},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":4328400},\"end\":40711,\"start\":40497},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":19187663},\"end\":40925,\"start\":40713},{\"attributes\":{\"id\":\"b9\"},\"end\":41224,\"start\":40927},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":924780},\"end\":41397,\"start\":41226},{\"attributes\":{\"id\":\"b11\"},\"end\":41531,\"start\":41399},{\"attributes\":{\"id\":\"b12\"},\"end\":41748,\"start\":41533},{\"attributes\":{\"id\":\"b13\"},\"end\":41852,\"start\":41750},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":8535487},\"end\":42093,\"start\":41854},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":5652538},\"end\":42346,\"start\":42095},{\"attributes\":{\"id\":\"b16\"},\"end\":42527,\"start\":42348},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":7557552},\"end\":42804,\"start\":42529},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":15085278},\"end\":43021,\"start\":42806},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":6628106},\"end\":43173,\"start\":43023},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":216078090},\"end\":43313,\"start\":43175},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":9654383},\"end\":43476,\"start\":43315},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":52143467},\"end\":43681,\"start\":43478},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":1671874},\"end\":43850,\"start\":43683},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":16462148},\"end\":44089,\"start\":43852},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":17947141},\"end\":44394,\"start\":44091},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":12161567},\"end\":44679,\"start\":44396},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":6071257},\"end\":44858,\"start\":44681},{\"attributes\":{\"id\":\"b28\"},\"end\":45024,\"start\":44860},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":11707680},\"end\":45204,\"start\":45026},{\"attributes\":{\"id\":\"b30\"},\"end\":45430,\"start\":45206},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":51992868},\"end\":45680,\"start\":45432},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":155093091},\"end\":45829,\"start\":45682},{\"attributes\":{\"id\":\"b33\"},\"end\":46069,\"start\":45831},{\"attributes\":{\"id\":\"b34\"},\"end\":46215,\"start\":46071},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":9383489},\"end\":46404,\"start\":46217},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":5458500},\"end\":46758,\"start\":46406},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":53146473},\"end\":47018,\"start\":46760},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":2636627},\"end\":47189,\"start\":47020},{\"attributes\":{\"id\":\"b39\"},\"end\":47436,\"start\":47191},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":2282762},\"end\":47637,\"start\":47438},{\"attributes\":{\"id\":\"b41\"},\"end\":47888,\"start\":47639},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":5378837},\"end\":48352,\"start\":47890},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":15150247},\"end\":48589,\"start\":48354},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":15027084},\"end\":48799,\"start\":48591},{\"attributes\":{\"id\":\"b45\"},\"end\":49042,\"start\":48801},{\"attributes\":{\"id\":\"b46\"},\"end\":49269,\"start\":49044},{\"attributes\":{\"id\":\"b47\"},\"end\":49530,\"start\":49271},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":2131938},\"end\":49753,\"start\":49532},{\"attributes\":{\"doi\":\"arXiv:1906.02111\",\"id\":\"b49\"},\"end\":50019,\"start\":49755},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":119181348},\"end\":50249,\"start\":50021}]", "bib_title": "[{\"end\":38865,\"start\":38783},{\"end\":39151,\"start\":39094},{\"end\":39633,\"start\":39567},{\"end\":39916,\"start\":39808},{\"end\":40285,\"start\":40244},{\"end\":40540,\"start\":40497},{\"end\":40773,\"start\":40713},{\"end\":41272,\"start\":41226},{\"end\":41919,\"start\":41854},{\"end\":42127,\"start\":42095},{\"end\":42577,\"start\":42529},{\"end\":42874,\"start\":42806},{\"end\":43065,\"start\":43023},{\"end\":43206,\"start\":43175},{\"end\":43362,\"start\":43315},{\"end\":43533,\"start\":43478},{\"end\":43722,\"start\":43683},{\"end\":43922,\"start\":43852},{\"end\":44172,\"start\":44091},{\"end\":44456,\"start\":44396},{\"end\":44723,\"start\":44681},{\"end\":45076,\"start\":45026},{\"end\":45499,\"start\":45432},{\"end\":45716,\"start\":45682},{\"end\":46262,\"start\":46217},{\"end\":46464,\"start\":46406},{\"end\":46826,\"start\":46760},{\"end\":47068,\"start\":47020},{\"end\":47493,\"start\":47438},{\"end\":47959,\"start\":47890},{\"end\":48399,\"start\":48354},{\"end\":48646,\"start\":48591},{\"end\":49609,\"start\":49532},{\"end\":50086,\"start\":50021}]", "bib_author": "[{\"end\":38706,\"start\":38697},{\"end\":38880,\"start\":38867},{\"end\":38889,\"start\":38880},{\"end\":38901,\"start\":38889},{\"end\":38911,\"start\":38901},{\"end\":38921,\"start\":38911},{\"end\":39163,\"start\":39153},{\"end\":39174,\"start\":39163},{\"end\":39190,\"start\":39174},{\"end\":39200,\"start\":39190},{\"end\":39213,\"start\":39200},{\"end\":39464,\"start\":39455},{\"end\":39646,\"start\":39635},{\"end\":39654,\"start\":39646},{\"end\":39662,\"start\":39654},{\"end\":39673,\"start\":39662},{\"end\":39925,\"start\":39918},{\"end\":39939,\"start\":39925},{\"end\":39949,\"start\":39939},{\"end\":39959,\"start\":39949},{\"end\":39971,\"start\":39959},{\"end\":39988,\"start\":39971},{\"end\":39997,\"start\":39988},{\"end\":40009,\"start\":39997},{\"end\":40299,\"start\":40287},{\"end\":40311,\"start\":40299},{\"end\":40554,\"start\":40542},{\"end\":40567,\"start\":40554},{\"end\":40580,\"start\":40567},{\"end\":40590,\"start\":40580},{\"end\":40783,\"start\":40775},{\"end\":40791,\"start\":40783},{\"end\":40799,\"start\":40791},{\"end\":40806,\"start\":40799},{\"end\":41030,\"start\":41015},{\"end\":41043,\"start\":41030},{\"end\":41051,\"start\":41043},{\"end\":41063,\"start\":41051},{\"end\":41286,\"start\":41274},{\"end\":41297,\"start\":41286},{\"end\":41450,\"start\":41434},{\"end\":41459,\"start\":41450},{\"end\":41582,\"start\":41571},{\"end\":41596,\"start\":41582},{\"end\":41613,\"start\":41596},{\"end\":41779,\"start\":41771},{\"end\":41928,\"start\":41921},{\"end\":41936,\"start\":41928},{\"end\":41944,\"start\":41936},{\"end\":41952,\"start\":41944},{\"end\":41959,\"start\":41952},{\"end\":42142,\"start\":42129},{\"end\":42152,\"start\":42142},{\"end\":42160,\"start\":42152},{\"end\":42171,\"start\":42160},{\"end\":42391,\"start\":42380},{\"end\":42589,\"start\":42579},{\"end\":42599,\"start\":42589},{\"end\":42614,\"start\":42599},{\"end\":42888,\"start\":42876},{\"end\":42900,\"start\":42888},{\"end\":43079,\"start\":43067},{\"end\":43085,\"start\":43079},{\"end\":43220,\"start\":43208},{\"end\":43231,\"start\":43220},{\"end\":43371,\"start\":43364},{\"end\":43383,\"start\":43371},{\"end\":43544,\"start\":43535},{\"end\":43554,\"start\":43544},{\"end\":43563,\"start\":43554},{\"end\":43736,\"start\":43724},{\"end\":43936,\"start\":43924},{\"end\":43945,\"start\":43936},{\"end\":43957,\"start\":43945},{\"end\":44184,\"start\":44174},{\"end\":44196,\"start\":44184},{\"end\":44468,\"start\":44458},{\"end\":44478,\"start\":44468},{\"end\":44487,\"start\":44478},{\"end\":44502,\"start\":44487},{\"end\":44735,\"start\":44725},{\"end\":44746,\"start\":44735},{\"end\":44756,\"start\":44746},{\"end\":44919,\"start\":44910},{\"end\":44927,\"start\":44919},{\"end\":45087,\"start\":45078},{\"end\":45295,\"start\":45283},{\"end\":45306,\"start\":45295},{\"end\":45507,\"start\":45501},{\"end\":45515,\"start\":45507},{\"end\":45522,\"start\":45515},{\"end\":45530,\"start\":45522},{\"end\":45540,\"start\":45530},{\"end\":45724,\"start\":45718},{\"end\":45734,\"start\":45724},{\"end\":45742,\"start\":45734},{\"end\":45915,\"start\":45909},{\"end\":45922,\"start\":45915},{\"end\":45931,\"start\":45922},{\"end\":45938,\"start\":45931},{\"end\":46126,\"start\":46112},{\"end\":46138,\"start\":46126},{\"end\":46281,\"start\":46264},{\"end\":46295,\"start\":46281},{\"end\":46483,\"start\":46466},{\"end\":46493,\"start\":46483},{\"end\":46502,\"start\":46493},{\"end\":46513,\"start\":46502},{\"end\":46521,\"start\":46513},{\"end\":46530,\"start\":46521},{\"end\":46539,\"start\":46530},{\"end\":46836,\"start\":46828},{\"end\":46844,\"start\":46836},{\"end\":46856,\"start\":46844},{\"end\":46863,\"start\":46856},{\"end\":46870,\"start\":46863},{\"end\":47080,\"start\":47070},{\"end\":47092,\"start\":47080},{\"end\":47273,\"start\":47266},{\"end\":47284,\"start\":47273},{\"end\":47294,\"start\":47284},{\"end\":47302,\"start\":47294},{\"end\":47505,\"start\":47495},{\"end\":47515,\"start\":47505},{\"end\":47525,\"start\":47515},{\"end\":47726,\"start\":47716},{\"end\":47736,\"start\":47726},{\"end\":47747,\"start\":47736},{\"end\":47757,\"start\":47747},{\"end\":47974,\"start\":47961},{\"end\":47982,\"start\":47974},{\"end\":48414,\"start\":48401},{\"end\":48423,\"start\":48414},{\"end\":48433,\"start\":48423},{\"end\":48445,\"start\":48433},{\"end\":48457,\"start\":48445},{\"end\":48656,\"start\":48648},{\"end\":48665,\"start\":48656},{\"end\":48673,\"start\":48665},{\"end\":48681,\"start\":48673},{\"end\":48889,\"start\":48876},{\"end\":48901,\"start\":48889},{\"end\":48914,\"start\":48901},{\"end\":49126,\"start\":49117},{\"end\":49135,\"start\":49126},{\"end\":49145,\"start\":49135},{\"end\":49359,\"start\":49351},{\"end\":49366,\"start\":49359},{\"end\":49372,\"start\":49366},{\"end\":49379,\"start\":49372},{\"end\":49387,\"start\":49379},{\"end\":49618,\"start\":49611},{\"end\":49631,\"start\":49618},{\"end\":49764,\"start\":49755},{\"end\":49772,\"start\":49764},{\"end\":49780,\"start\":49772},{\"end\":49794,\"start\":49780},{\"end\":49800,\"start\":49794},{\"end\":49806,\"start\":49800},{\"end\":49814,\"start\":49806},{\"end\":50097,\"start\":50088},{\"end\":50105,\"start\":50097},{\"end\":50111,\"start\":50105},{\"end\":50121,\"start\":50111}]", "bib_venue": "[{\"end\":44535,\"start\":44527},{\"end\":48153,\"start\":48076},{\"end\":38695,\"start\":38637},{\"end\":38927,\"start\":38921},{\"end\":39220,\"start\":39213},{\"end\":39453,\"start\":39369},{\"end\":39676,\"start\":39673},{\"end\":40013,\"start\":40009},{\"end\":40352,\"start\":40311},{\"end\":40594,\"start\":40590},{\"end\":40809,\"start\":40806},{\"end\":41013,\"start\":40927},{\"end\":41303,\"start\":41297},{\"end\":41432,\"start\":41399},{\"end\":41569,\"start\":41533},{\"end\":41769,\"start\":41750},{\"end\":41963,\"start\":41959},{\"end\":42211,\"start\":42171},{\"end\":42378,\"start\":42348},{\"end\":42657,\"start\":42614},{\"end\":42905,\"start\":42900},{\"end\":43089,\"start\":43085},{\"end\":43235,\"start\":43231},{\"end\":43387,\"start\":43383},{\"end\":43571,\"start\":43563},{\"end\":43761,\"start\":43736},{\"end\":43960,\"start\":43957},{\"end\":44224,\"start\":44196},{\"end\":44525,\"start\":44502},{\"end\":44760,\"start\":44756},{\"end\":44908,\"start\":44860},{\"end\":45110,\"start\":45087},{\"end\":45281,\"start\":45206},{\"end\":45547,\"start\":45540},{\"end\":45746,\"start\":45742},{\"end\":45907,\"start\":45831},{\"end\":46110,\"start\":46071},{\"end\":46302,\"start\":46295},{\"end\":46571,\"start\":46539},{\"end\":46880,\"start\":46870},{\"end\":47096,\"start\":47092},{\"end\":47264,\"start\":47191},{\"end\":47528,\"start\":47525},{\"end\":47714,\"start\":47639},{\"end\":48074,\"start\":47982},{\"end\":48461,\"start\":48457},{\"end\":48685,\"start\":48681},{\"end\":48874,\"start\":48801},{\"end\":49115,\"start\":49044},{\"end\":49349,\"start\":49271},{\"end\":49634,\"start\":49631},{\"end\":49876,\"start\":49830},{\"end\":50125,\"start\":50121}]"}}}, "year": 2023, "month": 12, "day": 17}