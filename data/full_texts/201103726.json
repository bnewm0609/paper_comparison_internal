{"id": 201103726, "updated": "2023-10-06 23:28:44.626", "metadata": {"title": "Human uncertainty makes classification more robust", "authors": "[{\"first\":\"Joshua\",\"last\":\"Peterson\",\"middle\":[\"C.\"]},{\"first\":\"Ruairidh\",\"last\":\"Battleday\",\"middle\":[\"M.\"]},{\"first\":\"Thomas\",\"last\":\"Griffiths\",\"middle\":[\"L.\"]},{\"first\":\"Olga\",\"last\":\"Russakovsky\",\"middle\":[]}]", "venue": "2019 IEEE/CVF International Conference on Computer Vision (ICCV)", "journal": "2019 IEEE/CVF International Conference on Computer Vision (ICCV)", "publication_date": {"year": 2019, "month": 8, "day": 19}, "abstract": "The classification performance of deep neural networks has begun to asymptote at near-perfect levels. However, their ability to generalize outside the training set and their robustness to adversarial attacks have not. In this paper, we make progress on this problem by training with full label distributions that reflect human perceptual uncertainty. We first present a new benchmark dataset which we call CIFAR10H, containing a full distribution of human labels for each image of the CIFAR10 test set. We then show that, while contemporary classifiers fail to exhibit human-like uncertainty on their own, explicit training on our dataset closes this gap, supports improved generalization to increasingly out-of-training-distribution test datasets, and confers robustness to adversarial attacks.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "1908.07086", "mag": "3005295611", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/iccv/PetersonBGR19", "doi": "10.1109/iccv.2019.00971"}}, "content": {"source": {"pdf_hash": "d2a2be6ce932a0f1939f31cfff4d64ea3d76723d", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/1908.07086v1.pdf\"]", "oa_url_match": true, "oa_info": {"license": null, "open_access_url": "http://arxiv.org/pdf/1908.07086", "status": "GREEN"}}, "grobid": {"id": "c5a9d44efee5e048b15b2d6ebfafe25b9a17d4ff", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/d2a2be6ce932a0f1939f31cfff4d64ea3d76723d.txt", "contents": "\nHuman uncertainty makes classification more robust\n\n\nJoshua C Peterson joshuacp@cs.princeton.edu \nDepartment of Computer Science\nPrinceton University\n\n\nRuairidh M Battleday battleday@cs.princeton.edu \nDepartment of Computer Science\nPrinceton University\n\n\nThomas L Griffiths \nDepartment of Computer Science\nPrinceton University\n\n\nOlga Russakovsky \nDepartment of Computer Science\nPrinceton University\n\n\nHuman uncertainty makes classification more robust\n\nThe classification performance of deep neural networks has begun to asymptote at near-perfect levels. However, their ability to generalize outside the training set and their robustness to adversarial attacks have not. In this paper, we make progress on this problem by training with full label distributions that reflect human perceptual uncertainty. We first present a new benchmark dataset which we call CIFAR10H, containing a full distribution of human labels for each image of the CIFAR10 test set. We then show that, while contemporary classifiers fail to exhibit human-like uncertainty on their own, explicit training on our dataset closes this gap, supports improved generalization to increasingly out-of-training-distribution test datasets, and confers robustness to adversarial attacks.\n\nIntroduction\n\nOn natural-image classification benchmarks, state-ofthe-art convolutional neural network (CNN) models have been said to equal or even surpass human performance, as measured in terms of \"top-1 accuracy\"-the correspondence between the most probable label indicated by the model and the \"ground truth\" label for a test set of heldout images. As accuracy gains have begun to asymptote at near-perfect levels [11], there has been increasing focus on out-of-training-set performance-in particular, the ability to generalize to related stimuli [39], and robustness to adversarial examples [29]. On these tasks, by contrast, CNNs tend to perform rather poorly, whereas humans continue to perform well.\n\nTo redress this problem, and provide a better standard for training classifiers, we suggest an alternative objective: not just trying to capture the most likely label, but trying to capture the full distribution over labels. Errors in classification can be just as informative as the correct answers-a network that confuses a dog with a cat, for example, might be judged to generalize better than one that confuses it with a truck * contributed equally  Figure 1: CIFAR10 images for which humans and our best traditionally-trained CNN (Shake-Shake [11]) agree in their top guess, but systematically differ over other choices.\n\n(see [1]). Indeed, consider the examples shown in Figure 1, in which the CNN can be underconfident, overconfident, or systematically incorrect, and yet receive a perfect accuracy score. Capturing this similarity structure is a key part of effective generalization [19], and an important consideration when building classification models for real-world applications, for example, object avoidance in driverless cars.\n\nPredicting more complete distributions of labels requires first measuring those distributions. Given that we cannot directly extract ground truth perceptual similarity from the world, human categorization behavior is a natural candidate for such a comparison. Indeed, there is often a lack of human consensus on the category of an object, and human errors often convey important information about the structure of the visual world [31]. Beyond complementing training paradigms, collecting these full label distributions from humans to better model human biases and predict their errors is interesting in itself-this time, for example, to help a driverless car infer the actions of nearby human drivers. Finally, although there has been much work scaling the number of images in datasets [18], and investigating label noise [40,12,48], little effort has been put into identifying the benefits from increasing the richness of (informative) label distributions for image classification tasks.\n\nTo these ends, we make the following contributions:\n\n\u2022 We present a novel soft-label dataset which we call CIFAR10H, comprising full label distributions for the entire 10,000-image CIFAR10 test set, utilizing over 500k crowdsourced human categorization judgments.\n\n\u2022 We show that when state-of-the-art CNN classifiers are trained using these soft labels, they generalize better to out-of-sample datasets than hard-label controls.\n\n\u2022 We present a performance benchmark assessing model fit to human labels, and show that models trained using alternative label distributions do not approximate human uncertainty as well.\n\n\u2022 We show that when CNNs are trained to perform well on this benchmark they are significantly more resistant to adversarial attacks.\n\nTaken together, our results support more fine-grained evaluations of model generalization behavior and demonstrate the potential utility of one method for integrating human perceptual similarity into paradigms for training classifiers.\n\n\nRelated Work\n\nHierarchical Classification. Work on using class confusion or hierarchy to improve classification accuracy or robustness dates back to early works of e.g., Griffin and Perona [14], Marszalek and Schmid [34], or Zweig and Weinshall [53]. Class label hierarchies have been used to enable e.g., sharing of representations [47,9,22], effective combination of models [23], or improved accuracy of classification through hierarchical prediction [32,8]. Benchmarks have occasionally proposed using hierarchical metrics for evaluation (e.g., the hierarchical error rate of ILSVRC 2010 and 2011 [41]). Overall though the dominant paradigm has focused on evaluating the top-K accuracy rather analyzing the errors of the system, and the hierarchical structure has been used mostly for training. We argue it is time to rethink this. First, modern large-scale open-world complex datasets no longer guarantee non-overlapping object classes [26], making hierarchical class confusion particularly meaningful. Second, existing methods are becoming remarkably good at top-K accuracy, so an increasing focus on their robustness with regard to adversarial examples [44,13,2] or distributional shift [45,39] is warranted. In this work we present to our knowledge the first large-scale evaluation of generalization to human uncertainty in image classification.\n\nKnowledge Distillation. The label hierarchies used to aid recognition can be manually constructed [6,3], derived from linguistic knowledge bases [10,9], or learned automatically [14,19]. Our work is closest to the former (manual construction), although instead of explicitly constructing a class hierarchy we rely on human confusion between the classes to infer the relationship between the classes for a given image. While being derived from human confusion, our work bears some resemblance to the knowledge distillation approach of [19]. In knowledge distillation, these labels are provided by the smoothed softmax probabilities from a pre-trained classification model. When soft labels are combined with ground truths, a form of model transfer and compression is achieved, because the softmax probabilities carry crucial information. The rationale for this process is similar to our own: networks (and humans) gain great robustness from distilling important information about similarity structure into the distributions we infer over images and their categories. However, the use of a network to provide them (i.e., the standard application of knowledge distillation) is itself problematic without a gold standard to compare to: there is no guarantee that the similarity structure a model has learned is correct.\n\nSoft Labels. One of the core contributions of our work is around using the soft labels provided through human confusion as a replacement for one-hot label encodings. Several methods have been proposed as alternatives to one-hot encodings, e.g., using heuristics to smooth the top-1 label during large-scale 1000+ way classification [43] or incorporating test-time human uncertainty into a collaborative computer vision system [4]. mixup [51] is another recently developed method for automatically generating soft labels based on convex combinations of pairs of examples and their hard labels, and has been shown to improve generalization and adversarial robustness while reducing memorization. However, since the linearity constraint is constant across all pairs of classes, and the labels are one-hot, it is difficult to see how the softness in such labels is a full measure of perceptual likeness.\n\nHuman studies. Lastly, there are a number of studies that also use human experts to provide distributional information over training labels in related classification fields, such as medical diagnosis systems [35,36]. While the theoretical cases these studies present support our own, they do not provide a large-scale testbed for evaluation of other classification models. Notably, the human uncertainty labels frequently don't need to be explicitly collected but will become automatically available in the process of data collection. Much of crowdsourcing work focuses on reconciling human labels and mitigating their disagreement (c.f., Kovashka et al. [25] for a survey). Our approach proposes utilizing these human disagreements to improve the accuracy and robustness of a model, complementing existing work aimed at leveraging \"errors\" in human labeling [27].\n\n\nFrom Labels to Label Distributions\n\nThe standard practice for image classification tasks is to train using \"ground truth\" labels provided in common benchmark datasets, for example, ILSVRC12 [41], and CIFAR10 [28], where the \"true\" category for each image is decided through human consensus (the modal choice) or by the database creators. Although a useful simplification in many cases, we suggest that this approximation introduces a bias into the learning framework that has important distributional implications. To see this, first consider the standard loss minimization objective during training given below:\nmin \u03b8 n i=1 L(f \u03b8 , x i , y i ),(1)\nin which the loss L for a model with parameters \u03b8 is minimized with respect to observed data samples {x i , y i } n i=1 . Our goal in training a model in this way is to generalize well to unseen data: to minimize the expected loss over unobserved labels given observed images {x j } m j=1 drawn from the same underlying data distribution in the future:\n1 m m j=1 c L(f \u03b8 , x j , y j = c) p(y j = c|x j ).(2)\nWhen we consider the second term in this product, we can see that using modal labels during dataset construction would only be an optimal estimator if for any stimulus x, the underlying conditional data distribution p(y|x) is zero for every category c apart from the one assigned by human consensus. By contrast, when we consider the network and human confusions seen in Figure 1, we can see there do exist cases in which this assumption violates human allocation of probabilities. How, then, can we reach a more natural approximation of p(y|x)? For some problems, it is easy to just sample from some real set of data p(x, y), but for image classification, we must rely on humans as a gold standard for providing a good estimate of p(y|x). If we expect the human image label distribution p hum (y|x) to better reflect the natural distribution over categories given an image, we can use it as an improved estimator for p(y|x).\n\nIn the case where f \u03b8 (x) is a distribution p \u03b8 (y|x) and L(f, x, y) is the negative log-likelihood, the expected loss reduces to the cross-entropy between the human distribution and that predicted by the classifier:\n\u2212 1 m m j=1 c p hum (y j = c|x j ) log p \u03b8 (y j = c|x j ). (3)\nThis implies that the optimal strategy for gathering training pairs {x i , y i } n i=1 is to sample them from p hum (y|x). Our dataset provides this distribution directly, so that models may be trained on human labels or evaluated against them, or better approximations of p(y|x) for natural images be found. In turn, better approximation of this underlying data distribution should be expected to give better generalization and robustness.\n\n\nDataset Construction\n\nWhile larger-scale popular datasets such as Ima-geNet [41], Places [52], or COCO [33] might seem like the best starting point, CIFAR10 in particular has several unique and attractive properties. First, the dataset is still of enough interest to the community that state-of-the-art image classifiers are being developed on it [11,21]. Second, the dataset is small enough to allow us to collect substantial human data for the entire test set of images. Third, the low resolution of the images is useful for producing variation in human responses. Human error rates for high resolution images with non-overlapping object categories are sufficiently low that it is hard to get a meaningful signal from a relatively small number of responses. Finally, CIFAR10 contains a number of examples that are close to the category boundaries, in contrast with other datasets that are more carefully curated such that each image is selected to be a good example of the category. Our final CIFAR10H behavioral dataset consists of 511,400 human categorization decisions over the 10,000-image testing subset of CIFAR10 (approx. 50 judgments per image).\n\n\nImage Stimuli\n\nWe collected human judgments for all 10,000 32 \u00d7 32 color images in the testing subset of CIFAR10. This contains 1,000 images for each of the following 10 categories: airplane, automobile, bird, cat, deer, dog, frog, horse, ship, and truck. This allows us to evalulate models pretrained on the CIFAR10 training set using the same testing images, but in terms of a different distribution over labels, detailed in the next section.\n\n\nHuman Judgments\n\nWe collected 511,400 human classifications over our stimulus set via Amazon Mechanical Turk [5]-to our knowledge, the largest of its kind reported in a single study to date. In the task, participants were asked to categorize each image by clicking one of the 10 labels surrounding it as quickly and accurately as possible (but with no time limit). Label positions were shuffled between candidates. After an initial training phase, each participant (2,571 total) categorized 200 images, 20 from each category. Every 20 trials, an obvious image was presented as an attention check, and participants who scored below 75% on these were removed from the final analysis (14 total). We collected 51 judgments per image on average (range: 47 \u2212 63). Average completion time was 15 minutes, and workers were paid $1.50 total. Examples of distributions over categorization judgments for a selection of images is shown in Figure 1.\n\n\nGeneralization Under Distributional Shift\n\nOur general strategy is to train a range of classifiers using our soft labels and assess their performance on heldout validation sets and a number of generalization datasets with increasing distributional shift. We expect the human information about image label uncertainty to be most useful when test datasets are increasingly out-of-distribution.\n\n\nSetup\n\nModels. We trained eight CNN architectures (VGG [42], ResNet [16], Wide ResNet [50], ResNet preact [17], ResNext [49], DenseNet [20], PyramidNet [15], and Shake-Shake [11]) to minimize the crossentropy loss between softmax outputs and the full human-label distributions for images in CIFAR10H. The models were trained using PyTorch [38], adapting the repository found in the footnote. 1 For each architecture, we train 10 models using 10fold cross validation (using 9,000 images for training each time) and at test time average the results across the 10 runs. We use k-fold instead of a single validation set in order to obtain more stable results. We used the default hyperparameters in the repository for all models, following [39] for the sake of reproducibility, except for the learning rate. We trained each model for a maximum of 150 epochs using the Adam [24] optimizer, and performed a grid-search over base learning rates 0.2, 0.1, 0.01, and 0.001 (we found 0.1 to be optimal in all cases).\n\n\nTest Datasets.\n\nA key prediction from section 3 is that the uncertainty in our labels will be increasingly informative when generalizing to increasingly out-of-training-sample distributions. We test this prediction empirically by examining generalization ability to the following datasets:\n\nCIFAR10: This is the standard within-dataset evaluation. Since our CIFAR10H soft labels are for the CIFAR10 test set, here we use the 50,000-images of the standard CIFAR10 training set to instead evaluate the models.\n\nCIFAR10.1v6,v4: These are two 2,000-image nearsample datasets created by [39] to assess overfitting to CIFAR10 \"test\" data often used for validation. The images are taken from TinyImages [46] and match the sub-class distributions in CIFAR10. v6 has 200 images per class while v4 is the original class-unbalanced version (90% overlap).\n\nCINIC10: This is an out-of-sample generalization test. The CINIC10 dataset collected by [7] contains both CIFAR10 images and rescaled ImageNet images from equivalent classes [7]. For example, images from the airplane, aeroplane, plane (airliner) and airplane, aeroplane, plane (bomber) ImageNet classes were allocated to the airplane CIFAR10 top-level class. Here we use only the 210,000 images taken from ImageNet. ImageNet-Far: Finally, as stronger exemplar of distributional shift, we built ImageNet-Far. As above, we used rescaled ImageNet images, but chose classes that might not be under direct inheritance from the CIFAR10synonymous classes. For example, for the CIFAR10 label deer, we included the ImageNet categories ibex, gazelle, and for the CIFAR10 label horse we included the ImageNet category zebra, which was not included in CINIC10.\n\nGeneralization Measures. We evaluate each model on each test set in terms of both accuracy and crossentropy. Accuracy remains a centrally important measure of classification performance for the task of out-of-sample generalization. As accuracy ignores the probability assigned to a guess, we also employ the crossentropy metric to evaluate model behavior: how confident it is in its top prediction, and whether its distribution over alternative categories is sensible. Note that this interpretation arises naturally when computing crossentropy with a one-hot vector, as only the probability mass allocated to the ground-truth choice contributes to the score. Crossentropy becomes even more informative when computed with respect to human soft labels that distribute the mass unlike one-hot vectors. In this case, the second guess of the network, which provides a sense of the most confusable classes for an image, will likely be a large secondary contributor to the loss. To provide a more readily interpretable heuristic measure of this, we introduce a new accuracy measure called second-best accuracy (SBA). While top-1 accuracy may largely asymptote, we expect that gains in SBA may still have a way to go.\n\n\nSoft Labels Hard Labels\n\n\nSoft Labels Hard Labels\n\nSoft Labels Hard Labels Figure 2: Generalization results. Left: accuracy against ground-truth labels, for increasingly out-of-training-sample distributions, averaged across CNNs. Accuracy was higher using human labels for every individual CNN and dataset. Center: crossentropy against ground-truth labels, averaged across CNNs. Loss was lower using human labels for every individual CNN and dataset. Right: Second best accuracy (SBA) for all models using CIFAR10H held out set, averaged across folds.  \n\n\nHuman Labels Improve Generalization\n\nWe train each CNN described above on both one-hot labels (default, control) and on CIFAR10H soft human labels (ours), and evaluate on each of the proposed test sets with increasingly out-of-sample distributions.\n\nOur first finding is that when we train CNNs on CIFAR10H soft labels, their accuracy improves on all generalization datasets compared to our control (Figure 2, left). This pattern was replicated across individual crossvalidation folds for every individual model (not shown).\n\nA key feature of this boost in generalization is that it increases as test datasets become increasingly out-of-trainingdistribution (horizontal axis, left to right). For example, while using human soft labels gives us only a 1% improve-ment (from 83.5% to 84.5%) when evaluated on CIFAR10, the same models when evaluated on ImageNet-Far achieved an accuracy gain of 2% on average (from 49.4% to 51.4%).\n\nThis pattern is even more evident when we consider the crossentropy metric (Figure 2, center). For example, while using human soft labels gives us a 29% reduction in crossentropy (from 0.7 to 0.5) when evaluated on CIFAR10, the same models when evaluated on ImageNet-Far achieve a reduction of 38% on average (from 2.9 to 1.8). These results imply that models trained on our soft labels show better confidence in their correct choices, and allocate more probability to the ground-truth during errors.\n\nFinally, CNNs trained on our soft labels consistently show significant boosts in SBA compared to controls, performing on average 5% better (Figure 2, right). This shows improvement in generalization in a broader sense: the distribution of the most likely two categories has important consequences for the graceful degradation in generalization we hope a good model provides, as well as for the nature of guesses made by a classification model when it is wrong. Figure 3 provides an additional picture of model behavior on our validation folds beyond overall generalization performance. Encouragingly, we find that soft-label-trained models are significantly less confident when incorrect than hard-label-trained controls, but only marginally less confident when correct (Figure 3a), and more generally provide a better fit to patterns of human uncertainty (Figure 3b).\n\n\nAlternative Soft Label Methods\n\nAbove, we show out-of-sample classification benefits arise from training on our human labels. One natural question that arises is whether this improvement is the result of simply training with soft labels (i.e., allowing the model to distribute the probability mass over more than one class), or due to the fact that this distribution explicitly mimics human uncertainty. Here we show the answer is the latter.  Table 1: Crossentropy for each holdout set (columns from left to right: holdout human soft labels (c10H), holdout ground truth labels (c10), the entire CIFAR10.1v4 dataset, and the entire CIFAR10.1v6 dataset. Crossentropy for our human labels decreases substantially after fine-tuning (FT), especially when using human targets. Fine-tuning on human targets also produces the best generalization in terms crossentropy on CIFAR10.1.\n\n\nSetup\n\nTraining. We set out to demonstrate that training with human labels provides benefits even over competitive baselines. We use the same CNN architectures and setup as in Section 5.1 with one notable exception: we pre-train the networks before incorporating the soft labels (this allows us to achieve the best possible fit to humans). To do so, we train using the standard CIFAR10 training protocol using 50,000 images and the optimal hyperparameters in the repository, either largely replicating or surpassing the original accuracies proposed in the papers for each architecture. We then fine-tune each pretrained model using either hardlabel controls or our human soft labels on the CIFAR10 test set. This fine-tuning phase mirrors the training phrase from Section 5.1: we used 10-folds, trained for 150 epochs, and searched over learning rates 0.1, 0.01, and 0.001.\n\nEvaluation. We evaluate the results on the holdout folds of CIFAR10H with both human soft labels and ground truth hard labels, as well as on the ground truth hard labels of both the CIFAR10.1v4 and CIFAR10.1v6 datasets. We also shift our attention to evaluating crossentropy rather than accuracy. With CIFAR10 pretraining, the accuracy of all models is high, but this gives no indication of the level of confidence or the \"reasonableness\" of errors. Crossentropy, on the other hand, does exactly that: measures the level of confidence when evaluated on hard labels and the \"reasonableness\" of errors when evaluated on human soft labels.\n\n\nMethods\n\nTo test for simpler and potentially equally effective alternatives to approximating the uncertainty in human judgments, we include a number of competitive baselines below.\n\nGround Truth Control. The first baseline we consider is a \"control\" fine-tuning condition where we use identical image data splits, but fine-tune using the ground-truth hard labels. This is expected to improve upon the pretrained model as it utilizes the additional 9,000 images previously unseen.\n\nClass-level Penalty. One much simpler alternative to image-level human soft labels is class-level soft labels. That is, instead of specifying how much each image resembles each category, we could simply specify which classes are more confusable on average using a class-level penalty. However, while we know, for example, that dogs and cats are likely more confusable on average than dogs and cars, it's not clear what the optimal class-level penalties should be. Since exhaustively searching for competitive interclass penalties is inefficient, we propose to generate goldstandard penalties by summing and re-normalizing our human probabilities within each class (i.e., resulting in exactly 10 unique soft-label vectors). This also allows us to determine if image-level information in our human soft labels is actually being utilized as opposed to class-level statistics across image exemplars. In this baseline, fine-tuning simply uses these greatly compressed soft vectors as targets.\n\nKnowledge Distillation. As discussed in Section 2, softmax probabilities of a trained neural network can be used as soft labels because they contain information inferred by the network about the similarity between categories and among images. The pretrained networks from this section provide such probabilities and so provide a corresponding baseline. However, we can infer from the results in Section 5.2 that hard-label-trained CNNs infer class probabilities that do not approximate those of humans, because incorporating explicit supervision to humans provides different results in terms of generalization. So, to provide a stronger baseline in this respect, we include an ensemble of the predictions from all eight models (i.e., providing soft predictions due to uncertainty from variation across models).\n\nmixup. mixup is a technique for soft label generation that improves the generalization of natural image classification models trained on CIFAR10 among others [51]-see Section 2. As such, it provides an interesting and competitive baseline with which to compare training with human soft labels. Concretely, mixup generates soft labels by taking convex combinations of pairs of examples, encouraging linear behavior between them. These combinations constitute virtual training examples (x,\u0233) that are sampled from a vicinial distribution, and take on the form\nx = \u03bbx i + (1 \u2212 \u03bb)x j y = \u03bby i + (1 \u2212 \u03bb)y j ,\nwhere (x i , x j ) are examples from the dataset, and (y i , y j ) are their labels. The strength of the interpolation \u03bb \u2208 [0, 1] is sampled according to Beta(\u03b1, \u03b1), where \u03b1 is a hyperparameter. For our mixup baseline, we apply this procedure to the ground truth labels corresponding to each of the same 10 splits used above. For each architecture, we searched for the best value of \u03b1 from 0.1 to 1.0 in increments of 0.1.\n\nSoft Labels Versus Sampling. Finally, we run one additional experiment beyond the soft label baselines above. Results from Section 5 suggest that human soft labels are useful, but how should we best incorporate them into training? In Section 3, we justified using human probabilities as targets to minimize the expected loss. However, another valid option is to sample from p hum (y|x), i.e., sample one-hot labels from categorical distribution parameterized by the human probabilities conditioned on each image. If we sample a new label each time the image is presented to the network for a new gradient update, the label uncertainty will still be incorporated, but there will be additional variation in the gradients that could act as further regularization. To test for any such advantages of label sampling, we fine-tuned a second corresponding set of models using this method, sampling a new label for each image on each epoch.\n\n\nHuman Soft Labels Beat Alternatives\n\nResults are summarized for each architecture and method in Table 1. The first column is our primary measure of fit to humans; the last two assess further generalization.\n\nNote that for pretrained models (first row of each subtable) crossentropy to ground truth labels is always lower than human soft labels, verifying what we expected: human soft labels provide additional information that is not inferred via training with ground truth. This is a first test that the information (informative probabilities) usually inferred by these networks using hard labels (i.e., knowledge distillation) does not agree with humans. We further tested an ensemble of all eight networks in the top rows (i.e., with no fine-tuning on human soft labels), and while this model is more like humans than any individual hard-label-trained model (crossentropy is 0.41), it is still not a substitute for human supervision. The benefit from our labels also appears to manifest during generalization, as in the last two columns (i.e., v4 and v6 holdout sets) they show higher crossentropy than alternative approaches. Next, looking at the same top rows, note that there is little correspondence between recency of the architecture and fit to humans. In fact, Shake-Shake is the state-of-the-art of the eight yet is not one of the top three models in terms of fit to humans.\n\nIn the remaining rows of each sub-table, we can see an increase in fit to humans using our various fine-tuning schemes. This is expected in all cases given that all of these models are ultimately given more data than pretrained models. However, not all fine-tuning methods are equally effective. Importantly, fit to humans (second column) is best when either using our image-level soft labels or sampling hard labels using them (bottom two rows). Interestingly, category soft labels (4th rows) were also effective, but to a lesser degree. mixup was more effective than using ground truth labels alone, but less effective than any methods using human information. Lastly, we note that, while omitted for brevity, we found no loss in accuracy when using human labels in any of the conditions that utilized them.\n\n\nRobustness to Adversarial Attacks\n\nBecause our soft labels contain information about the similarity structure of images that is relevant to the structure of perceptual boundaries, we might expect that representations learned in service of predicting them would be more robust to adversarial attacks, particularly in cases where similar categories make for good attack targets. Moreover, subsequent explorations of knowledge distillation [19,37] have demonstrated that such practices can support adversarial robustness. If human judgments of perceptual similar-  Table 2: Accuracy and crossentropy after FGSM attacks on the CIFAR10-tuned (baseline) and CIFAR10H-tuned networks. Using human labels always results in lower (better) crossentropy, and in the majority of cases, higher accuracy.\n\nity are superior to those inferred by CNNs-in the form of p(y|x)-we would expect distillation of human knowledge into a CNN would at the very least also increase robustness.\n\nSetup. We use the same pretrained and fine-tuned (hard versus soft) models from Section 6. To measure robustness after each training scheme, we evaluate both accuracy and crossentropy (the latter again being a more sensitive measure of both confidence and entropy) against the hard class labels. As attack methods, we evaluate two additive noise attacks: the Fast Gradient Sign Method (FGSM) [29], and Projected Gradient Descent (PGD) [30], using the mister ed toolkit 2 for PyTorch. For both methods, we explored \u221e bounds of 4 to 8 in increments of 1. Since we found no significant differences in the results, we report all attack results using a constant \u221e bound of 4 for brevity.\n\nHuman Soft Labels Confer Robustness. FGSM results are reported in Table 2, averaged over all 10,000 images in the CIFAR10 test set. In all cases, crossentropy (which attack methods seek to maximize) is much lower (roughly half) after attacking the human-tuned network compared to fine-tuning with original one-hot labels. For five out of eight architectures, accuracy also improves when using human soft targets. The two largest differences (Wide Resnet and ResNet preact) favor the human labels as well. Note that no explicit (defensive) training was required to obtain these improvements beyond previous training with human labels. Without active defensive training, PGD is expected to drive accuracy to 0% given enough iterations. To explore the intrinsic defenses of our two label-training conditions to PGD attacks, we plot the increase in loss for each architecture and label-training scheme in Figure 4. While accuracy was driven to 0% for each network when trained on standard labels, and 1% for each network with human labels, 2 github.com/revbucket/mister_ed/ Soft Labels Hard Labels PGD Iteration Crossentropy Figure 4: Crossentropy as a function of PGD iteration. Successive iterations increase crossentropy as expected, but more slowly after soft-label fine-tuning.\n\nloss for the former is driven up much more rapidly, whereas the latter asymptotes quickly. Put simply, a much higher degree of effort is required to successfully attack networks that behave more like humans.\n\n\nDiscussion\n\nIn this work, we have demonstrated that incorporating information about human category uncertainty at the imagelevel can help protect against the perils of distributional shift and adversarial attacks. Notably, common classification benchmarks often do not naturally provide such protections on their own [45]. Further, besides explicitly incorporating this information, it gives a way of measuring whether our learning algorithms are inferring good similarity structure (beyond just top-1 performance). If we can begin to find good learning procedures that derive such information, we can obtain human-like robustness in our models without the need of explicit human supervision. However, developing such a robust models will take significant time and research-our dataset provides a first step (an initial gold standard with respect to a popular benchmark) in measuring this progress, even when not used for training.\n\nAlthough our data collection method does not immediately seem to scale to larger training sets, it's certainly possible to collect informative label distributions at a cost comparable to what we often spend on compute to find better top-1-fitting architectures. Interestingly, we found that the bulk of human uncertainty is concentrated in approximately 30% of the images in our dataset, meaning straightforward and much more efficient methods for mining only these more informative labels can be employed. In any case, we see the main contribution of such datasets as testing environments for algorithms intended for much larger datasets.\n\nFigure 3 :\n3(A) Mean confidence for correctly/incorrectly classified examples after hard/soft label training. Soft-label models are far less confident when incorrect than hard-label controls, and only slightly less confident when correct. (B) Soft label training yields predictions that distribute probability mass more like people, with the same top choice.\ngithub.com/hysts/pytorch_image_classification; model identifiers vgg 15 BN 64, resnet basic 110, wrn 28 10, resnet preact bottleneck 164, resnext 29 8x64d, densenet BC 100 12, pyramidnet basic 110 270, shake shake 26 2x64d SSI cutout16 (output folder names).\nAcknowledgements. This work was supported by grant number 1718550 from the National Science Foundation.\nJean-Fran\u00e7ois Bonnefon, and Iyad Rahwan. The moral machine experiment. Edmond Awad, Sohan Dsouza, Richard Kim, Jonathan Schulz, Joseph Henrich, Azim Shariff, Nature. 563772959Edmond Awad, Sohan Dsouza, Richard Kim, Jonathan Schulz, Joseph Henrich, Azim Shariff, Jean-Fran\u00e7ois Bon- nefon, and Iyad Rahwan. The moral machine experiment. Nature, 563(7729):59, 2018.\n\nWild patterns: Ten years after the rise of adversarial machine learning. Battista Biggio, Fabio Roli, Pattern Recognition. 84Battista Biggio and Fabio Roli. Wild patterns: Ten years af- ter the rise of adversarial machine learning. Pattern Recog- nition, 84:317-331, 2018.\n\nCrowdsourcing multi-label classification for taxonomy creation. Jonathan Bragg, Mausam , Daniel S Weld, Conference on Human Computation and Crowdsourcing (HCOMP). Jonathan Bragg, Mausam, and Daniel S. Weld. Crowd- sourcing multi-label classification for taxonomy creation. In Conference on Human Computation and Crowdsourcing (HCOMP), 2013.\n\nVisual recognition with humans in the loop. Steve Branson, Catherine Wah, Florian Schroff, Boris Babenko, Peter Welinder, Pietro Perona, Serge Belongie, European Conference on Computer Vision (ECCV). Steve Branson, Catherine Wah, Florian Schroff, Boris Babenko, Peter Welinder, Pietro Perona, and Serge Belongie. Visual recognition with humans in the loop. In European Conference on Computer Vision (ECCV), 2010.\n\nAmazon's mechanical turk: A new source of inexpensive, yet high-quality, data?. Michael Buhrmester, Tracy Kwang, Samuel D Gosling, Perspectives on Psychological Science. 61Michael Buhrmester, Tracy Kwang, and Samuel D Gosling. Amazon's mechanical turk: A new source of inexpensive, yet high-quality, data? Perspectives on Psychological Science, 6(1):3-5, 2011.\n\nCascade: Crowdsourcing taxonomy creation. L B Chilton, G Little, D Edge, D S Weld, J A Landay, Conference on Human Factors in Computing Systems (CHI). L. B. Chilton, G. Little, D. Edge, D. S. Weld, and J. A. Lan- day. Cascade: Crowdsourcing taxonomy creation. In Confer- ence on Human Factors in Computing Systems (CHI), 2013.\n\nLuke Nicholas Darlow, Elliot J Crowley, Antreas Antoniou, Amos J Storkey, arXiv:1810.03505CINIC-10 is not imagenet or CIFAR-10. arXiv preprintLuke Nicholas Darlow, Elliot J. Crowley, Antreas Antoniou, and Amos J. Storkey. CINIC-10 is not imagenet or CIFAR- 10. arXiv preprint arXiv:1810.03505, 2018.\n\nLarge-scale object classification using label relation graphs. Jia Deng, Nan Ding, Yangqing Jia, Andrea Frome, Kevin Murphy, Samy Bengio, Yuan Li, Hartmut Neven, Hartwig Adam, European Conference on Computer Vision (ECCV). Jia Deng, Nan Ding, Yangqing Jia, Andrea Frome, Kevin Murphy, Samy Bengio, Yuan Li, Hartmut Neven, and Hartwig Adam. Large-scale object classification using la- bel relation graphs. In European Conference on Computer Vision (ECCV), 2014.\n\nSemantic label sharing for learning with many categories. R Fergus, H Bernal, Y Weiss, A Torralba, European Conference on Computer Vision (ECCV). R. Fergus, H. Bernal, Y. Weiss, and A. Torralba. Semantic label sharing for learning with many categories. In European Conference on Computer Vision (ECCV), 2010.\n\nDevise: A deep visual-semantic embedding model. A Frome, G S Corrado, J Shlens, S Bengio, J Dean, T Mikolov, Advances in Neural Information Processing Systems (NeurIPS). A. Frome, G.S. Corrado, J. Shlens, S. Bengio, J. Dean, and T. Mikolov. Devise: A deep visual-semantic embedding model. In Advances in Neural Information Processing Sys- tems (NeurIPS), 2013.\n\nXavier Gastaldi, arXiv:1705.07485Shake-shake regularization. arXiv preprintXavier Gastaldi. Shake-shake regularization. arXiv preprint arXiv:1705.07485, 2017.\n\nRobust loss functions under label noise for deep neural networks. Aritra Ghosh, Himanshu Kumar, P S Sastry, Conference on Artificial Intelligence (AAAI. Aritra Ghosh, Himanshu Kumar, and PS Sastry. Robust loss functions under label noise for deep neural networks. In Con- ference on Artificial Intelligence (AAAI), 2017.\n\nJ Ian, Goodfellow, arXiv:1412.6572Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples. arXiv preprintIan J Goodfellow, Jonathon Shlens, and Christian Szegedy. Explaining and harnessing adversarial examples. arXiv preprint arXiv:1412.6572, 2014.\n\nLearning and using taxonomies for fast visual categorization. G Griffin, P Perona, Computer Vision and Pattern Recognition (CVPR). G. Griffin and P. Perona. Learning and using taxonomies for fast visual categorization. In Computer Vision and Pattern Recognition (CVPR), 2008.\n\nDeep pyramidal residual networks. Dongyoon Han, Jiwhan Kim, Junmo Kim, Conference on Computer Vision and Pattern Recognition (CVPR. Dongyoon Han, Jiwhan Kim, and Junmo Kim. Deep pyra- midal residual networks. In Conference on Computer Vision and Pattern Recognition (CVPR), 2017.\n\nDeep residual learning for image recognition. Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, Computer Vision and Pattern Recognition (CVPR). Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Computer Vision and Pattern Recognition (CVPR), 2016.\n\nIdentity mappings in deep residual networks. Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, European Conference on Computer Vision (ECCV). Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Identity mappings in deep residual networks. In European Conference on Computer Vision (ECCV), 2016.\n\nJoel Hestness, Sharan Narang, Newsha Ardalani, Gregory F Diamos, Heewoo Jun, Hassan Kianinejad, Md. Mostofa Ali Patwary, Yang Yang, Yanqi Zhou, arXiv:1712.00409Deep learning scaling is predictable, empirically. arXiv preprintJoel Hestness, Sharan Narang, Newsha Ardalani, Gregory F. Diamos, Heewoo Jun, Hassan Kianinejad, Md. Mostofa Ali Patwary, Yang Yang, and Yanqi Zhou. Deep learning scaling is predictable, empirically. arXiv preprint arXiv:1712.00409, 2017.\n\nGeoffrey E Hinton, Oriol Vinyals, Jeffrey Dean, arXiv:1503.02531Distilling the knowledge in a neural network. arXiv preprintGeoffrey E. Hinton, Oriol Vinyals, and Jeffrey Dean. Dis- tilling the knowledge in a neural network. arXiv preprint arXiv:1503.02531, 2015.\n\nDensely connected convolutional networks. Gao Huang, Zhuang Liu, Laurens Van Der Maaten, Kilian Q Weinberger, Computer Vision and Pattern Recognition (CVPR. Gao Huang, Zhuang Liu, Laurens Van Der Maaten, and Kil- ian Q Weinberger. Densely connected convolutional net- works. In Computer Vision and Pattern Recognition (CVPR), 2017.\n\nYanping Huang, Yonglong Cheng, Dehao Chen, Hy-Oukjoong Lee, Jiquan Ngiam, V Quoc, Zhifeng Le, Chen, Gpipe, arXiv:1811.06965Efficient training of giant neural networks using pipeline parallelism. arXiv preprintYanping Huang, Yonglong Cheng, Dehao Chen, Hy- oukJoong Lee, Jiquan Ngiam, Quoc V Le, and Zhifeng Chen. Gpipe: Efficient training of giant neural networks us- ing pipeline parallelism. arXiv preprint arXiv:1811.06965, 2018.\n\nSharing features between objects and their attributes. S J Hwang, F Sha, K Grauman, Computer Vision and Pattern Recognition (CVPR). S.J. Hwang, F. Sha, and K. Grauman. Sharing features be- tween objects and their attributes. In Computer Vision and Pattern Recognition (CVPR), 2011.\n\nVisual concept learning: Combining machine vision and bayesian generalization on concept hierarchies. Y Jia, J T Abbott, J Austerweil, T Griffiths, T Darrell, Advances in Neural Information Processing Systems (NeurIPS). Y. Jia, J.T. Abbott, J. Austerweil, T. Griffiths, and T. Dar- rell. Visual concept learning: Combining machine vision and bayesian generalization on concept hierarchies. In Advances in Neural Information Processing Systems (NeurIPS), 2013.\n\nAdam: A method for stochastic optimization. P Diederik, Jimmy Kingma, Ba, International Conference on Learning Representations (ICLR). Diederik P. Kingma and Jimmy Ba. Adam: A method for stochastic optimization. In International Conference on Learning Representations (ICLR), 2014.\n\nCrowdsourcing in Computer Vision. Foundation and Trends in Computer Graphics and Vision. Adriana Kovashka, Olga Russakovsky, Li Fei-Fei, Kristen Grauman, 10Adriana Kovashka, Olga Russakovsky, Li Fei-Fei, and Kristen Grauman. Crowdsourcing in Computer Vision. Foundation and Trends in Computer Graphics and Vision, 10(3):177-243, 2016.\n\nVisual genome: Connecting language and vision using crowdsourced dense image annotations. Ranjay Krishna, Yuke Zhu, Oliver Groth, Justin Johnson, Kenji Hata, Joshua Kravitz, Stephanie Chen, Yannis Kalantidis, Li-Jia Li, David A Shamma, Michael S Bernstein, Li Fei-Fei, International Journal of Computer Vision (IJCV). 1231Ranjay Krishna, Yuke Zhu, Oliver Groth, Justin Johnson, Kenji Hata, Joshua Kravitz, Stephanie Chen, Yannis Kalan- tidis, Li-Jia Li, David A. Shamma, Michael S. Bernstein, and Li Fei-Fei. Visual genome: Connecting language and vision using crowdsourced dense image annotations. International Journal of Computer Vision (IJCV), 123(1), May 2017.\n\nEmbracing error to enable rapid crowdsourcing. A Ranjay, Kenji Krishna, Stephanie Hata, Joshua Chen, David A Kravitz, Li Shamma, Michael S Fei-Fei, Bernstein, Conference on Human Factors in Computing Systems (CHI). Ranjay A. Krishna, Kenji Hata, Stephanie Chen, Joshua Kravitz, David A. Shamma, Li Fei-Fei, and Michael S. Bern- stein. Embracing error to enable rapid crowdsourcing. In Conference on Human Factors in Computing Systems (CHI), 2016.\n\nLearning multiple layers of features from tiny images. Alex Krizhevsky, CiteseerTechnical reportAlex Krizhevsky. Learning multiple layers of features from tiny images. Technical report, Citeseer, 2009.\n\nAdversarial examples in the physical world. Alexey Kurakin, Ian Goodfellow, Samy Bengio, International Conference on Learning Representations (ICLR). Alexey Kurakin, Ian Goodfellow, and Samy Bengio. Ad- versarial examples in the physical world. In International Conference on Learning Representations (ICLR), 2016.\n\nAdversarial machine learning at scale. Alexey Kurakin, Ian Goodfellow, Samy Bengio, International Conference on Learning Representations (ICLR). Alexey Kurakin, Ian Goodfellow, and Samy Bengio. Adver- sarial machine learning at scale. In International Conference on Learning Representations (ICLR), 2016.\n\nWomen, fire, and dangerous things. George Lakoff, University of Chicago pressGeorge Lakoff. Women, fire, and dangerous things. Univer- sity of Chicago press, 2008.\n\nMaximum margin multi-label structured prediction. C H Lampert, Advances in Neural Information Processing Systems (NeurIPS). C.H. Lampert. Maximum margin multi-label structured pre- diction. In Advances in Neural Information Processing Sys- tems (NeurIPS), 2011.\n\nMicrosoft coco: Common objects in context. Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll\u00e1r, C Lawrence Zitnick, European Conference on Computer Vision (ECCV). Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll\u00e1r, and C Lawrence Zitnick. Microsoft coco: Common objects in context. In European Conference on Computer Vision (ECCV), 2014.\n\nSemantic hierarchies for visual object recognition. M Marszalek, C Schmid, Computer Vision and Pattern Recognition (CVPR). M. Marszalek and C. Schmid. Semantic hierarchies for vi- sual object recognition. In Computer Vision and Pattern Recognition (CVPR), 2007.\n\nCombining crowd and expert labels using decision theoretic active learning. An Thanh Nguyen, Byron C Wallace, Matthew Lease, Conference on Human Computation and Crowdsourcing (HCOMP). An Thanh Nguyen, Byron C Wallace, and Matthew Lease. Combining crowd and expert labels using decision theoretic active learning. In Conference on Human Computation and Crowdsourcing (HCOMP), 2015.\n\nLearning classification models with soft-label information. Quang Nguyen, Hamed Valizadegan, Milos Hauskrecht, Journal of the American Medical Informatics Association. 213Quang Nguyen, Hamed Valizadegan, and Milos Hauskrecht. Learning classification models with soft-label information. Journal of the American Medical Informatics Association, 21(3):501-508, 2014.\n\nDistillation as a defense to adversarial perturbations against deep neural networks. Nicolas Papernot, Patrick Mcdaniel, Xi Wu, Somesh Jha, Ananthram Swami, IEEE Symposium on Security and Privacy (SP). IEEENicolas Papernot, Patrick McDaniel, Xi Wu, Somesh Jha, and Ananthram Swami. Distillation as a defense to adver- sarial perturbations against deep neural networks. In IEEE Symposium on Security and Privacy (SP), pages 582-597. IEEE, 2016.\n\nAutomatic differentiation in PyTorch. Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary Devito, Zeming Lin, Alban Desmaison, Luca Antiga, Adam Lerer, NeurIPS Autodiff Workshop. Adam Paszke, Sam Gross, Soumith Chintala, Gregory Chanan, Edward Yang, Zachary DeVito, Zeming Lin, Al- ban Desmaison, Luca Antiga, and Adam Lerer. Automatic differentiation in PyTorch. In NeurIPS Autodiff Workshop, 2017.\n\nDo cifar-10 classifiers generalize to cifar-10?. Benjamin Recht, Rebecca Roelofs, Ludwig Schmidt, Vaishaal Shankar, arXiv:1806.00451arXiv preprintBenjamin Recht, Rebecca Roelofs, Ludwig Schmidt, and Vaishaal Shankar. Do cifar-10 classifiers generalize to cifar- 10? arXiv preprint arXiv:1806.00451, 2018.\n\nDavid Rolnick, Andreas Veit, Serge J Belongie, Nir Shavit, arXiv:1705.10694Deep learning is robust to massive label noise. arXiv preprintDavid Rolnick, Andreas Veit, Serge J. Belongie, and Nir Shavit. Deep learning is robust to massive label noise. arXiv preprint arXiv:1705.10694, 2017.\n\nImagenet large scale visual recognition challenge. Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, Sanjeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, International Journal of Computer Vision. 1153Olga Russakovsky, Jia Deng, Hao Su, Jonathan Krause, San- jeev Satheesh, Sean Ma, Zhiheng Huang, Andrej Karpathy, Aditya Khosla, Michael Bernstein, et al. Imagenet large scale visual recognition challenge. International Journal of Computer Vision, 115(3):211-252, 2015.\n\nVery deep convolutional networks for large-scale image recognition. Karen Simonyan, Andrew Zisserman, ternational Conference on Learning Representations (ICLR). Karen Simonyan and Andrew Zisserman. Very deep con- volutional networks for large-scale image recognition. In In- ternational Conference on Learning Representations (ICLR), 2014.\n\nRethinking the inception architecture for computer vision. Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, Zbigniew Wojna, Computer Vision and Pattern Recognition (CVPR). Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, and Zbigniew Wojna. Rethinking the inception ar- chitecture for computer vision. In Computer Vision and Pat- tern Recognition (CVPR), 2016.\n\nIntriguing properties of neural networks. Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, Rob Fergus, International Conference on Learning Representations (ICLR). Christian Szegedy, Wojciech Zaremba, Ilya Sutskever, Joan Bruna, Dumitru Erhan, Ian Goodfellow, and Rob Fergus. In- triguing properties of neural networks. In International Con- ference on Learning Representations (ICLR), 2013.\n\nUnbiased look at dataset bias. Antonio Torralba, Alexei A Efros, Computer Vision and Pattern Recognition (CVPR). Antonio Torralba, Alexei A Efros, et al. Unbiased look at dataset bias. In Computer Vision and Pattern Recognition (CVPR), 2011.\n\n80 million tiny images: A large data set for nonparametric object and scene recognition. Antonio Torralba, Rob Fergus, William T Freeman, IEEE Transactions on Pattern Analysis and Machine Intelligence. 3011Antonio Torralba, Rob Fergus, and William T Freeman. 80 million tiny images: A large data set for nonparametric object and scene recognition. IEEE Transactions on Pat- tern Analysis and Machine Intelligence, 30(11):1958-1970, 2008.\n\nSharing visual features for multiclass and multiview object detection. Antonio Torralba, P Kevin, William T Murphy, Freeman, IEEE Transactions on Pattern Analysis and Machine Intelligence. 295Antonio Torralba, Kevin P Murphy, and William T Freeman. Sharing visual features for multiclass and multiview object detection. IEEE Transactions on Pattern Analysis and Ma- chine Intelligence, 29(5):854-869, 2007.\n\nToward robustness against label noise in training deep discriminative neural networks. Arash Vahdat, Advances in Neural Information Processing Systems (NeurIPS. Arash Vahdat. Toward robustness against label noise in train- ing deep discriminative neural networks. In Advances in Neural Information Processing Systems (NeurIPS). 2017.\n\nAggregated residual transformations for deep neural networks. Saining Xie, B Ross, Piotr Girshick, Zhuowen Doll\u00e1r, Kaiming Tu, He, Computer Vision and Pattern Recognition (CVPR). Saining Xie, Ross B Girshick, Piotr Doll\u00e1r, Zhuowen Tu, and Kaiming He. Aggregated residual transformations for deep neural networks. In Computer Vision and Pattern Recogni- tion (CVPR), 2017.\n\nWide residual networks. Sergey Zagoruyko, Nikos Komodakis, British Machine Vision Conference (BMVC). Sergey Zagoruyko and Nikos Komodakis. Wide residual net- works. In British Machine Vision Conference (BMVC), 2016.\n\nmixup: Beyond empirical risk minimization. Hongyi Zhang, Moustapha Cisse, David Yann N Dauphin, Lopez-Paz, International Conference on Learning Representations. Hongyi Zhang, Moustapha Cisse, Yann N Dauphin, and David Lopez-Paz. mixup: Beyond empirical risk minimiza- tion. In International Conference on Learning Representa- tions (ICLR), 2017.\n\nPlaces: A 10 million image database for scene recognition. Bolei Zhou, Agata Lapedriza, Aditya Khosla, Aude Oliva, Antonio Torralba, IEEE Transactions on Pattern Analysis and Machine Intelligence. Bolei Zhou, Agata Lapedriza, Aditya Khosla, Aude Oliva, and Antonio Torralba. Places: A 10 million image database for scene recognition. IEEE Transactions on Pattern Analy- sis and Machine Intelligence, 2017.\n\nExploiting object hierarchy: combining models from different category levels. A Zweig, D Weinshall, International Conference on Computer Vision (ICCV). A. Zweig and D. Weinshall. Exploiting object hierarchy: combining models from different category levels. In Inter- national Conference on Computer Vision (ICCV), 2007.\n", "annotations": {"author": "[{\"end\":152,\"start\":54},{\"end\":255,\"start\":153},{\"end\":329,\"start\":256},{\"end\":401,\"start\":330}]", "publisher": null, "author_last_name": "[{\"end\":71,\"start\":63},{\"end\":173,\"start\":164},{\"end\":274,\"start\":265},{\"end\":346,\"start\":335}]", "author_first_name": "[{\"end\":60,\"start\":54},{\"end\":62,\"start\":61},{\"end\":161,\"start\":153},{\"end\":163,\"start\":162},{\"end\":262,\"start\":256},{\"end\":264,\"start\":263},{\"end\":334,\"start\":330}]", "author_affiliation": "[{\"end\":151,\"start\":99},{\"end\":254,\"start\":202},{\"end\":328,\"start\":276},{\"end\":400,\"start\":348}]", "title": "[{\"end\":51,\"start\":1},{\"end\":452,\"start\":402}]", "venue": null, "abstract": "[{\"end\":1249,\"start\":454}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b10\"},\"end\":1673,\"start\":1669},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":1806,\"start\":1802},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":1851,\"start\":1847},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":2512,\"start\":2508},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2595,\"start\":2592},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":2855,\"start\":2851},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":3439,\"start\":3435},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":3795,\"start\":3791},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":3831,\"start\":3827},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":3834,\"start\":3831},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":3837,\"start\":3834},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":5179,\"start\":5175},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":5206,\"start\":5202},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":5235,\"start\":5231},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":5323,\"start\":5319},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":5325,\"start\":5323},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":5328,\"start\":5325},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":5366,\"start\":5362},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":5443,\"start\":5439},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":5445,\"start\":5443},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":5590,\"start\":5586},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":5930,\"start\":5926},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":6149,\"start\":6145},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":6152,\"start\":6149},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":6154,\"start\":6152},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":6183,\"start\":6179},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":6186,\"start\":6183},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":6441,\"start\":6438},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":6443,\"start\":6441},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":6489,\"start\":6485},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":6491,\"start\":6489},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":6522,\"start\":6518},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":6525,\"start\":6522},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":6878,\"start\":6874},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":7993,\"start\":7989},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":8086,\"start\":8083},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":8098,\"start\":8094},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":8770,\"start\":8766},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":8773,\"start\":8770},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":9217,\"start\":9213},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":9421,\"start\":9417},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":9619,\"start\":9615},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":9637,\"start\":9633},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":12212,\"start\":12208},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":12225,\"start\":12221},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":12239,\"start\":12235},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":12483,\"start\":12479},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":12486,\"start\":12483},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":13849,\"start\":13846},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":15129,\"start\":15125},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":15142,\"start\":15138},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":15160,\"start\":15156},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":15180,\"start\":15176},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":15194,\"start\":15190},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":15209,\"start\":15205},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":15226,\"start\":15222},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":15248,\"start\":15244},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":15413,\"start\":15409},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":15463,\"start\":15462},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":15810,\"start\":15806},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":15943,\"start\":15939},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":16665,\"start\":16661},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":16779,\"start\":16775},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":17015,\"start\":17012},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":17101,\"start\":17098},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":26680,\"start\":26676},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":31121,\"start\":31117},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":31124,\"start\":31121},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":32042,\"start\":32038},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":32085,\"start\":32081},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":34141,\"start\":34137}]", "figure": "[{\"attributes\":{\"id\":\"fig_2\"},\"end\":35752,\"start\":35393}]", "paragraph": "[{\"end\":1958,\"start\":1265},{\"end\":2585,\"start\":1960},{\"end\":3002,\"start\":2587},{\"end\":3993,\"start\":3004},{\"end\":4046,\"start\":3995},{\"end\":4258,\"start\":4048},{\"end\":4424,\"start\":4260},{\"end\":4612,\"start\":4426},{\"end\":4746,\"start\":4614},{\"end\":4983,\"start\":4748},{\"end\":6338,\"start\":5000},{\"end\":7655,\"start\":6340},{\"end\":8556,\"start\":7657},{\"end\":9422,\"start\":8558},{\"end\":10037,\"start\":9461},{\"end\":10426,\"start\":10074},{\"end\":11407,\"start\":10482},{\"end\":11625,\"start\":11409},{\"end\":12129,\"start\":11689},{\"end\":13287,\"start\":12154},{\"end\":13734,\"start\":13305},{\"end\":14673,\"start\":13754},{\"end\":15067,\"start\":14719},{\"end\":16076,\"start\":15077},{\"end\":16368,\"start\":16095},{\"end\":16586,\"start\":16370},{\"end\":16922,\"start\":16588},{\"end\":17772,\"start\":16924},{\"end\":18983,\"start\":17774},{\"end\":19539,\"start\":19037},{\"end\":19790,\"start\":19579},{\"end\":20066,\"start\":19792},{\"end\":20470,\"start\":20068},{\"end\":20972,\"start\":20472},{\"end\":21842,\"start\":20974},{\"end\":22719,\"start\":21877},{\"end\":23595,\"start\":22729},{\"end\":24233,\"start\":23597},{\"end\":24416,\"start\":24245},{\"end\":24715,\"start\":24418},{\"end\":25704,\"start\":24717},{\"end\":26516,\"start\":25706},{\"end\":27075,\"start\":26518},{\"end\":27544,\"start\":27122},{\"end\":28478,\"start\":27546},{\"end\":28687,\"start\":28518},{\"end\":29866,\"start\":28689},{\"end\":30677,\"start\":29868},{\"end\":31469,\"start\":30715},{\"end\":31644,\"start\":31471},{\"end\":32328,\"start\":31646},{\"end\":33608,\"start\":32330},{\"end\":33817,\"start\":33610},{\"end\":34751,\"start\":33832},{\"end\":35392,\"start\":34753}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":10073,\"start\":10038},{\"attributes\":{\"id\":\"formula_1\"},\"end\":10481,\"start\":10427},{\"attributes\":{\"id\":\"formula_2\"},\"end\":11688,\"start\":11626},{\"attributes\":{\"id\":\"formula_3\"},\"end\":27121,\"start\":27076}]", "table_ref": "[{\"end\":22296,\"start\":22289},{\"end\":28584,\"start\":28577},{\"end\":31249,\"start\":31242},{\"end\":32403,\"start\":32396}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":1263,\"start\":1251},{\"attributes\":{\"n\":\"2.\"},\"end\":4998,\"start\":4986},{\"attributes\":{\"n\":\"3.\"},\"end\":9459,\"start\":9425},{\"attributes\":{\"n\":\"4.\"},\"end\":12152,\"start\":12132},{\"attributes\":{\"n\":\"4.1.\"},\"end\":13303,\"start\":13290},{\"attributes\":{\"n\":\"4.2.\"},\"end\":13752,\"start\":13737},{\"attributes\":{\"n\":\"5.\"},\"end\":14717,\"start\":14676},{\"attributes\":{\"n\":\"5.1.\"},\"end\":15075,\"start\":15070},{\"end\":16093,\"start\":16079},{\"end\":19009,\"start\":18986},{\"end\":19035,\"start\":19012},{\"attributes\":{\"n\":\"5.2.\"},\"end\":19577,\"start\":19542},{\"attributes\":{\"n\":\"6.\"},\"end\":21875,\"start\":21845},{\"attributes\":{\"n\":\"6.1.\"},\"end\":22727,\"start\":22722},{\"attributes\":{\"n\":\"6.2.\"},\"end\":24243,\"start\":24236},{\"attributes\":{\"n\":\"6.3.\"},\"end\":28516,\"start\":28481},{\"attributes\":{\"n\":\"7.\"},\"end\":30713,\"start\":30680},{\"attributes\":{\"n\":\"8.\"},\"end\":33830,\"start\":33820},{\"end\":35404,\"start\":35394}]", "table": null, "figure_caption": "[{\"end\":35752,\"start\":35406}]", "figure_ref": "[{\"end\":2422,\"start\":2414},{\"end\":2645,\"start\":2637},{\"end\":10861,\"start\":10853},{\"end\":14672,\"start\":14664},{\"end\":19069,\"start\":19061},{\"end\":19950,\"start\":19941},{\"end\":20556,\"start\":20547},{\"end\":21122,\"start\":21113},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":21443,\"start\":21435},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":21755,\"start\":21744},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":21840,\"start\":21830},{\"end\":33239,\"start\":33231},{\"end\":33459,\"start\":33451}]", "bib_author_first_name": "[{\"end\":36193,\"start\":36187},{\"end\":36205,\"start\":36200},{\"end\":36221,\"start\":36214},{\"end\":36235,\"start\":36227},{\"end\":36250,\"start\":36244},{\"end\":36264,\"start\":36260},{\"end\":36561,\"start\":36553},{\"end\":36575,\"start\":36570},{\"end\":36826,\"start\":36818},{\"end\":36840,\"start\":36834},{\"end\":36849,\"start\":36843},{\"end\":36851,\"start\":36850},{\"end\":37145,\"start\":37140},{\"end\":37164,\"start\":37155},{\"end\":37177,\"start\":37170},{\"end\":37192,\"start\":37187},{\"end\":37207,\"start\":37202},{\"end\":37224,\"start\":37218},{\"end\":37238,\"start\":37233},{\"end\":37597,\"start\":37590},{\"end\":37615,\"start\":37610},{\"end\":37629,\"start\":37623},{\"end\":37631,\"start\":37630},{\"end\":37915,\"start\":37914},{\"end\":37917,\"start\":37916},{\"end\":37928,\"start\":37927},{\"end\":37938,\"start\":37937},{\"end\":37946,\"start\":37945},{\"end\":37948,\"start\":37947},{\"end\":37956,\"start\":37955},{\"end\":37958,\"start\":37957},{\"end\":38204,\"start\":38200},{\"end\":38213,\"start\":38205},{\"end\":38228,\"start\":38222},{\"end\":38230,\"start\":38229},{\"end\":38247,\"start\":38240},{\"end\":38262,\"start\":38258},{\"end\":38264,\"start\":38263},{\"end\":38567,\"start\":38564},{\"end\":38577,\"start\":38574},{\"end\":38592,\"start\":38584},{\"end\":38604,\"start\":38598},{\"end\":38617,\"start\":38612},{\"end\":38630,\"start\":38626},{\"end\":38643,\"start\":38639},{\"end\":38655,\"start\":38648},{\"end\":38670,\"start\":38663},{\"end\":39022,\"start\":39021},{\"end\":39032,\"start\":39031},{\"end\":39042,\"start\":39041},{\"end\":39051,\"start\":39050},{\"end\":39322,\"start\":39321},{\"end\":39331,\"start\":39330},{\"end\":39333,\"start\":39332},{\"end\":39344,\"start\":39343},{\"end\":39354,\"start\":39353},{\"end\":39364,\"start\":39363},{\"end\":39372,\"start\":39371},{\"end\":39641,\"start\":39635},{\"end\":39867,\"start\":39861},{\"end\":39883,\"start\":39875},{\"end\":39892,\"start\":39891},{\"end\":39894,\"start\":39893},{\"end\":40118,\"start\":40117},{\"end\":40461,\"start\":40460},{\"end\":40472,\"start\":40471},{\"end\":40717,\"start\":40709},{\"end\":40729,\"start\":40723},{\"end\":40740,\"start\":40735},{\"end\":41009,\"start\":41002},{\"end\":41021,\"start\":41014},{\"end\":41037,\"start\":41029},{\"end\":41047,\"start\":41043},{\"end\":41312,\"start\":41305},{\"end\":41324,\"start\":41317},{\"end\":41340,\"start\":41332},{\"end\":41350,\"start\":41346},{\"end\":41564,\"start\":41560},{\"end\":41581,\"start\":41575},{\"end\":41596,\"start\":41590},{\"end\":41614,\"start\":41607},{\"end\":41616,\"start\":41615},{\"end\":41631,\"start\":41625},{\"end\":41643,\"start\":41637},{\"end\":41671,\"start\":41656},{\"end\":41685,\"start\":41681},{\"end\":41697,\"start\":41692},{\"end\":42033,\"start\":42025},{\"end\":42035,\"start\":42034},{\"end\":42049,\"start\":42044},{\"end\":42066,\"start\":42059},{\"end\":42335,\"start\":42332},{\"end\":42349,\"start\":42343},{\"end\":42362,\"start\":42355},{\"end\":42387,\"start\":42379},{\"end\":42630,\"start\":42623},{\"end\":42646,\"start\":42638},{\"end\":42659,\"start\":42654},{\"end\":42677,\"start\":42666},{\"end\":42689,\"start\":42683},{\"end\":42698,\"start\":42697},{\"end\":42712,\"start\":42705},{\"end\":43113,\"start\":43112},{\"end\":43115,\"start\":43114},{\"end\":43124,\"start\":43123},{\"end\":43131,\"start\":43130},{\"end\":43443,\"start\":43442},{\"end\":43450,\"start\":43449},{\"end\":43452,\"start\":43451},{\"end\":43462,\"start\":43461},{\"end\":43476,\"start\":43475},{\"end\":43489,\"start\":43488},{\"end\":43846,\"start\":43845},{\"end\":43862,\"start\":43857},{\"end\":44180,\"start\":44173},{\"end\":44195,\"start\":44191},{\"end\":44211,\"start\":44209},{\"end\":44228,\"start\":44221},{\"end\":44516,\"start\":44510},{\"end\":44530,\"start\":44526},{\"end\":44542,\"start\":44536},{\"end\":44556,\"start\":44550},{\"end\":44571,\"start\":44566},{\"end\":44584,\"start\":44578},{\"end\":44603,\"start\":44594},{\"end\":44616,\"start\":44610},{\"end\":44635,\"start\":44629},{\"end\":44645,\"start\":44640},{\"end\":44647,\"start\":44646},{\"end\":44663,\"start\":44656},{\"end\":44665,\"start\":44664},{\"end\":44679,\"start\":44677},{\"end\":45135,\"start\":45134},{\"end\":45149,\"start\":45144},{\"end\":45168,\"start\":45159},{\"end\":45181,\"start\":45175},{\"end\":45193,\"start\":45188},{\"end\":45195,\"start\":45194},{\"end\":45207,\"start\":45205},{\"end\":45223,\"start\":45216},{\"end\":45225,\"start\":45224},{\"end\":45594,\"start\":45590},{\"end\":45788,\"start\":45782},{\"end\":45801,\"start\":45798},{\"end\":45818,\"start\":45814},{\"end\":46099,\"start\":46093},{\"end\":46112,\"start\":46109},{\"end\":46129,\"start\":46125},{\"end\":46401,\"start\":46395},{\"end\":46576,\"start\":46575},{\"end\":46578,\"start\":46577},{\"end\":46839,\"start\":46831},{\"end\":46852,\"start\":46845},{\"end\":46865,\"start\":46860},{\"end\":46881,\"start\":46876},{\"end\":46894,\"start\":46888},{\"end\":46907,\"start\":46903},{\"end\":46922,\"start\":46917},{\"end\":46941,\"start\":46931},{\"end\":47275,\"start\":47274},{\"end\":47288,\"start\":47287},{\"end\":47563,\"start\":47561},{\"end\":47569,\"start\":47564},{\"end\":47583,\"start\":47578},{\"end\":47585,\"start\":47584},{\"end\":47602,\"start\":47595},{\"end\":47932,\"start\":47927},{\"end\":47946,\"start\":47941},{\"end\":47965,\"start\":47960},{\"end\":48324,\"start\":48317},{\"end\":48342,\"start\":48335},{\"end\":48355,\"start\":48353},{\"end\":48366,\"start\":48360},{\"end\":48381,\"start\":48372},{\"end\":48719,\"start\":48715},{\"end\":48731,\"start\":48728},{\"end\":48746,\"start\":48739},{\"end\":48764,\"start\":48757},{\"end\":48779,\"start\":48773},{\"end\":48793,\"start\":48786},{\"end\":48808,\"start\":48802},{\"end\":48819,\"start\":48814},{\"end\":48835,\"start\":48831},{\"end\":48848,\"start\":48844},{\"end\":49162,\"start\":49154},{\"end\":49177,\"start\":49170},{\"end\":49193,\"start\":49187},{\"end\":49211,\"start\":49203},{\"end\":49416,\"start\":49411},{\"end\":49433,\"start\":49426},{\"end\":49445,\"start\":49440},{\"end\":49447,\"start\":49446},{\"end\":49461,\"start\":49458},{\"end\":49755,\"start\":49751},{\"end\":49772,\"start\":49769},{\"end\":49782,\"start\":49779},{\"end\":49795,\"start\":49787},{\"end\":49811,\"start\":49804},{\"end\":49826,\"start\":49822},{\"end\":49838,\"start\":49831},{\"end\":49852,\"start\":49846},{\"end\":49869,\"start\":49863},{\"end\":49885,\"start\":49878},{\"end\":50287,\"start\":50282},{\"end\":50304,\"start\":50298},{\"end\":50623,\"start\":50614},{\"end\":50640,\"start\":50633},{\"end\":50658,\"start\":50652},{\"end\":50669,\"start\":50666},{\"end\":50686,\"start\":50678},{\"end\":50998,\"start\":50989},{\"end\":51016,\"start\":51008},{\"end\":51030,\"start\":51026},{\"end\":51046,\"start\":51042},{\"end\":51061,\"start\":51054},{\"end\":51072,\"start\":51069},{\"end\":51088,\"start\":51085},{\"end\":51425,\"start\":51418},{\"end\":51442,\"start\":51436},{\"end\":51444,\"start\":51443},{\"end\":51726,\"start\":51719},{\"end\":51740,\"start\":51737},{\"end\":51758,\"start\":51749},{\"end\":52147,\"start\":52140},{\"end\":52159,\"start\":52158},{\"end\":52176,\"start\":52167},{\"end\":52569,\"start\":52564},{\"end\":52881,\"start\":52874},{\"end\":52888,\"start\":52887},{\"end\":52900,\"start\":52895},{\"end\":52918,\"start\":52911},{\"end\":52934,\"start\":52927},{\"end\":53215,\"start\":53209},{\"end\":53232,\"start\":53227},{\"end\":53451,\"start\":53445},{\"end\":53468,\"start\":53459},{\"end\":53481,\"start\":53476},{\"end\":53813,\"start\":53808},{\"end\":53825,\"start\":53820},{\"end\":53843,\"start\":53837},{\"end\":53856,\"start\":53852},{\"end\":53871,\"start\":53864},{\"end\":54235,\"start\":54234},{\"end\":54244,\"start\":54243}]", "bib_author_last_name": "[{\"end\":36198,\"start\":36194},{\"end\":36212,\"start\":36206},{\"end\":36225,\"start\":36222},{\"end\":36242,\"start\":36236},{\"end\":36258,\"start\":36251},{\"end\":36272,\"start\":36265},{\"end\":36568,\"start\":36562},{\"end\":36580,\"start\":36576},{\"end\":36832,\"start\":36827},{\"end\":36856,\"start\":36852},{\"end\":37153,\"start\":37146},{\"end\":37168,\"start\":37165},{\"end\":37185,\"start\":37178},{\"end\":37200,\"start\":37193},{\"end\":37216,\"start\":37208},{\"end\":37231,\"start\":37225},{\"end\":37247,\"start\":37239},{\"end\":37608,\"start\":37598},{\"end\":37621,\"start\":37616},{\"end\":37639,\"start\":37632},{\"end\":37925,\"start\":37918},{\"end\":37935,\"start\":37929},{\"end\":37943,\"start\":37939},{\"end\":37953,\"start\":37949},{\"end\":37965,\"start\":37959},{\"end\":38220,\"start\":38214},{\"end\":38238,\"start\":38231},{\"end\":38256,\"start\":38248},{\"end\":38272,\"start\":38265},{\"end\":38572,\"start\":38568},{\"end\":38582,\"start\":38578},{\"end\":38596,\"start\":38593},{\"end\":38610,\"start\":38605},{\"end\":38624,\"start\":38618},{\"end\":38637,\"start\":38631},{\"end\":38646,\"start\":38644},{\"end\":38661,\"start\":38656},{\"end\":38675,\"start\":38671},{\"end\":39029,\"start\":39023},{\"end\":39039,\"start\":39033},{\"end\":39048,\"start\":39043},{\"end\":39060,\"start\":39052},{\"end\":39328,\"start\":39323},{\"end\":39341,\"start\":39334},{\"end\":39351,\"start\":39345},{\"end\":39361,\"start\":39355},{\"end\":39369,\"start\":39365},{\"end\":39380,\"start\":39373},{\"end\":39650,\"start\":39642},{\"end\":39873,\"start\":39868},{\"end\":39889,\"start\":39884},{\"end\":39901,\"start\":39895},{\"end\":40122,\"start\":40119},{\"end\":40134,\"start\":40124},{\"end\":40469,\"start\":40462},{\"end\":40479,\"start\":40473},{\"end\":40721,\"start\":40718},{\"end\":40733,\"start\":40730},{\"end\":40744,\"start\":40741},{\"end\":41012,\"start\":41010},{\"end\":41027,\"start\":41022},{\"end\":41041,\"start\":41038},{\"end\":41051,\"start\":41048},{\"end\":41315,\"start\":41313},{\"end\":41330,\"start\":41325},{\"end\":41344,\"start\":41341},{\"end\":41354,\"start\":41351},{\"end\":41573,\"start\":41565},{\"end\":41588,\"start\":41582},{\"end\":41605,\"start\":41597},{\"end\":41623,\"start\":41617},{\"end\":41635,\"start\":41632},{\"end\":41654,\"start\":41644},{\"end\":41679,\"start\":41672},{\"end\":41690,\"start\":41686},{\"end\":41702,\"start\":41698},{\"end\":42042,\"start\":42036},{\"end\":42057,\"start\":42050},{\"end\":42071,\"start\":42067},{\"end\":42341,\"start\":42336},{\"end\":42353,\"start\":42350},{\"end\":42377,\"start\":42363},{\"end\":42398,\"start\":42388},{\"end\":42636,\"start\":42631},{\"end\":42652,\"start\":42647},{\"end\":42664,\"start\":42660},{\"end\":42681,\"start\":42678},{\"end\":42695,\"start\":42690},{\"end\":42703,\"start\":42699},{\"end\":42715,\"start\":42713},{\"end\":42721,\"start\":42717},{\"end\":42728,\"start\":42723},{\"end\":43121,\"start\":43116},{\"end\":43128,\"start\":43125},{\"end\":43139,\"start\":43132},{\"end\":43447,\"start\":43444},{\"end\":43459,\"start\":43453},{\"end\":43473,\"start\":43463},{\"end\":43486,\"start\":43477},{\"end\":43497,\"start\":43490},{\"end\":43855,\"start\":43847},{\"end\":43869,\"start\":43863},{\"end\":43873,\"start\":43871},{\"end\":44189,\"start\":44181},{\"end\":44207,\"start\":44196},{\"end\":44219,\"start\":44212},{\"end\":44236,\"start\":44229},{\"end\":44524,\"start\":44517},{\"end\":44534,\"start\":44531},{\"end\":44548,\"start\":44543},{\"end\":44564,\"start\":44557},{\"end\":44576,\"start\":44572},{\"end\":44592,\"start\":44585},{\"end\":44608,\"start\":44604},{\"end\":44627,\"start\":44617},{\"end\":44638,\"start\":44636},{\"end\":44654,\"start\":44648},{\"end\":44675,\"start\":44666},{\"end\":44687,\"start\":44680},{\"end\":45142,\"start\":45136},{\"end\":45157,\"start\":45150},{\"end\":45173,\"start\":45169},{\"end\":45186,\"start\":45182},{\"end\":45203,\"start\":45196},{\"end\":45214,\"start\":45208},{\"end\":45233,\"start\":45226},{\"end\":45244,\"start\":45235},{\"end\":45605,\"start\":45595},{\"end\":45796,\"start\":45789},{\"end\":45812,\"start\":45802},{\"end\":45825,\"start\":45819},{\"end\":46107,\"start\":46100},{\"end\":46123,\"start\":46113},{\"end\":46136,\"start\":46130},{\"end\":46408,\"start\":46402},{\"end\":46586,\"start\":46579},{\"end\":46843,\"start\":46840},{\"end\":46858,\"start\":46853},{\"end\":46874,\"start\":46866},{\"end\":46886,\"start\":46882},{\"end\":46901,\"start\":46895},{\"end\":46915,\"start\":46908},{\"end\":46929,\"start\":46923},{\"end\":46949,\"start\":46942},{\"end\":47285,\"start\":47276},{\"end\":47295,\"start\":47289},{\"end\":47576,\"start\":47570},{\"end\":47593,\"start\":47586},{\"end\":47608,\"start\":47603},{\"end\":47939,\"start\":47933},{\"end\":47958,\"start\":47947},{\"end\":47976,\"start\":47966},{\"end\":48333,\"start\":48325},{\"end\":48351,\"start\":48343},{\"end\":48358,\"start\":48356},{\"end\":48370,\"start\":48367},{\"end\":48387,\"start\":48382},{\"end\":48726,\"start\":48720},{\"end\":48737,\"start\":48732},{\"end\":48755,\"start\":48747},{\"end\":48771,\"start\":48765},{\"end\":48784,\"start\":48780},{\"end\":48800,\"start\":48794},{\"end\":48812,\"start\":48809},{\"end\":48829,\"start\":48820},{\"end\":48842,\"start\":48836},{\"end\":48854,\"start\":48849},{\"end\":49168,\"start\":49163},{\"end\":49185,\"start\":49178},{\"end\":49201,\"start\":49194},{\"end\":49219,\"start\":49212},{\"end\":49424,\"start\":49417},{\"end\":49438,\"start\":49434},{\"end\":49456,\"start\":49448},{\"end\":49468,\"start\":49462},{\"end\":49767,\"start\":49756},{\"end\":49777,\"start\":49773},{\"end\":49785,\"start\":49783},{\"end\":49802,\"start\":49796},{\"end\":49820,\"start\":49812},{\"end\":49829,\"start\":49827},{\"end\":49844,\"start\":49839},{\"end\":49861,\"start\":49853},{\"end\":49876,\"start\":49870},{\"end\":49895,\"start\":49886},{\"end\":50296,\"start\":50288},{\"end\":50314,\"start\":50305},{\"end\":50631,\"start\":50624},{\"end\":50650,\"start\":50641},{\"end\":50664,\"start\":50659},{\"end\":50676,\"start\":50670},{\"end\":50692,\"start\":50687},{\"end\":51006,\"start\":50999},{\"end\":51024,\"start\":51017},{\"end\":51040,\"start\":51031},{\"end\":51052,\"start\":51047},{\"end\":51067,\"start\":51062},{\"end\":51083,\"start\":51073},{\"end\":51095,\"start\":51089},{\"end\":51434,\"start\":51426},{\"end\":51450,\"start\":51445},{\"end\":51735,\"start\":51727},{\"end\":51747,\"start\":51741},{\"end\":51766,\"start\":51759},{\"end\":52156,\"start\":52148},{\"end\":52165,\"start\":52160},{\"end\":52183,\"start\":52177},{\"end\":52192,\"start\":52185},{\"end\":52576,\"start\":52570},{\"end\":52885,\"start\":52882},{\"end\":52893,\"start\":52889},{\"end\":52909,\"start\":52901},{\"end\":52925,\"start\":52919},{\"end\":52937,\"start\":52935},{\"end\":52941,\"start\":52939},{\"end\":53225,\"start\":53216},{\"end\":53242,\"start\":53233},{\"end\":53457,\"start\":53452},{\"end\":53474,\"start\":53469},{\"end\":53496,\"start\":53482},{\"end\":53507,\"start\":53498},{\"end\":53818,\"start\":53814},{\"end\":53835,\"start\":53826},{\"end\":53850,\"start\":53844},{\"end\":53862,\"start\":53857},{\"end\":53880,\"start\":53872},{\"end\":54241,\"start\":54236},{\"end\":54254,\"start\":54245}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":36478,\"start\":36116},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":53107276},\"end\":36752,\"start\":36480},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":11974604},\"end\":37094,\"start\":36754},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":16647912},\"end\":37508,\"start\":37096},{\"attributes\":{\"id\":\"b4\"},\"end\":37870,\"start\":37510},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":9912280},\"end\":38198,\"start\":37872},{\"attributes\":{\"doi\":\"arXiv:1810.03505\",\"id\":\"b6\"},\"end\":38499,\"start\":38200},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":10559817},\"end\":38961,\"start\":38501},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":7086636},\"end\":39271,\"start\":38963},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":261138},\"end\":39633,\"start\":39273},{\"attributes\":{\"doi\":\"arXiv:1705.07485\",\"id\":\"b10\"},\"end\":39793,\"start\":39635},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":6546734},\"end\":40115,\"start\":39795},{\"attributes\":{\"doi\":\"arXiv:1412.6572\",\"id\":\"b12\"},\"end\":40396,\"start\":40117},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":12805251},\"end\":40673,\"start\":40398},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":5398883},\"end\":40954,\"start\":40675},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":206594692},\"end\":41258,\"start\":40956},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":6447277},\"end\":41558,\"start\":41260},{\"attributes\":{\"doi\":\"arXiv:1712.00409\",\"id\":\"b17\"},\"end\":42023,\"start\":41560},{\"attributes\":{\"doi\":\"arXiv:1503.02531\",\"id\":\"b18\"},\"end\":42288,\"start\":42025},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":9433631},\"end\":42621,\"start\":42290},{\"attributes\":{\"doi\":\"arXiv:1811.06965\",\"id\":\"b20\"},\"end\":43055,\"start\":42623},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":2241449},\"end\":43338,\"start\":43057},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":481985},\"end\":43799,\"start\":43340},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":6628106},\"end\":44082,\"start\":43801},{\"attributes\":{\"id\":\"b24\"},\"end\":44418,\"start\":44084},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":4492210},\"end\":45085,\"start\":44420},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":7095037},\"end\":45533,\"start\":45087},{\"attributes\":{\"id\":\"b27\"},\"end\":45736,\"start\":45535},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":1257772},\"end\":46052,\"start\":45738},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":9059612},\"end\":46358,\"start\":46054},{\"attributes\":{\"id\":\"b30\"},\"end\":46523,\"start\":46360},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":13430725},\"end\":46786,\"start\":46525},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":14113767},\"end\":47220,\"start\":46788},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":14412825},\"end\":47483,\"start\":47222},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":12521058},\"end\":47865,\"start\":47485},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":8186856},\"end\":48230,\"start\":47867},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":2672720},\"end\":48675,\"start\":48232},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":40027675},\"end\":49103,\"start\":48677},{\"attributes\":{\"doi\":\"arXiv:1806.00451\",\"id\":\"b38\"},\"end\":49409,\"start\":49105},{\"attributes\":{\"doi\":\"arXiv:1705.10694\",\"id\":\"b39\"},\"end\":49698,\"start\":49411},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":2930547},\"end\":50212,\"start\":49700},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":14124313},\"end\":50553,\"start\":50214},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":206593880},\"end\":50945,\"start\":50555},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":604334},\"end\":51385,\"start\":50947},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":2777306},\"end\":51628,\"start\":51387},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":7487588},\"end\":52067,\"start\":51630},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":2741819},\"end\":52475,\"start\":52069},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":9963515},\"end\":52810,\"start\":52477},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":8485068},\"end\":53183,\"start\":52812},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":15276198},\"end\":53400,\"start\":53185},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":3162051},\"end\":53747,\"start\":53402},{\"attributes\":{\"id\":\"b51\",\"matched_paper_id\":2608922},\"end\":54154,\"start\":53749},{\"attributes\":{\"id\":\"b52\",\"matched_paper_id\":7691438},\"end\":54475,\"start\":54156}]", "bib_title": "[{\"end\":36185,\"start\":36116},{\"end\":36551,\"start\":36480},{\"end\":36816,\"start\":36754},{\"end\":37138,\"start\":37096},{\"end\":37588,\"start\":37510},{\"end\":37912,\"start\":37872},{\"end\":38562,\"start\":38501},{\"end\":39019,\"start\":38963},{\"end\":39319,\"start\":39273},{\"end\":39859,\"start\":39795},{\"end\":40458,\"start\":40398},{\"end\":40707,\"start\":40675},{\"end\":41000,\"start\":40956},{\"end\":41303,\"start\":41260},{\"end\":42330,\"start\":42290},{\"end\":43110,\"start\":43057},{\"end\":43440,\"start\":43340},{\"end\":43843,\"start\":43801},{\"end\":44508,\"start\":44420},{\"end\":45132,\"start\":45087},{\"end\":45780,\"start\":45738},{\"end\":46091,\"start\":46054},{\"end\":46573,\"start\":46525},{\"end\":46829,\"start\":46788},{\"end\":47272,\"start\":47222},{\"end\":47559,\"start\":47485},{\"end\":47925,\"start\":47867},{\"end\":48315,\"start\":48232},{\"end\":48713,\"start\":48677},{\"end\":49749,\"start\":49700},{\"end\":50280,\"start\":50214},{\"end\":50612,\"start\":50555},{\"end\":50987,\"start\":50947},{\"end\":51416,\"start\":51387},{\"end\":51717,\"start\":51630},{\"end\":52138,\"start\":52069},{\"end\":52562,\"start\":52477},{\"end\":52872,\"start\":52812},{\"end\":53207,\"start\":53185},{\"end\":53443,\"start\":53402},{\"end\":53806,\"start\":53749},{\"end\":54232,\"start\":54156}]", "bib_author": "[{\"end\":36200,\"start\":36187},{\"end\":36214,\"start\":36200},{\"end\":36227,\"start\":36214},{\"end\":36244,\"start\":36227},{\"end\":36260,\"start\":36244},{\"end\":36274,\"start\":36260},{\"end\":36570,\"start\":36553},{\"end\":36582,\"start\":36570},{\"end\":36834,\"start\":36818},{\"end\":36843,\"start\":36834},{\"end\":36858,\"start\":36843},{\"end\":37155,\"start\":37140},{\"end\":37170,\"start\":37155},{\"end\":37187,\"start\":37170},{\"end\":37202,\"start\":37187},{\"end\":37218,\"start\":37202},{\"end\":37233,\"start\":37218},{\"end\":37249,\"start\":37233},{\"end\":37610,\"start\":37590},{\"end\":37623,\"start\":37610},{\"end\":37641,\"start\":37623},{\"end\":37927,\"start\":37914},{\"end\":37937,\"start\":37927},{\"end\":37945,\"start\":37937},{\"end\":37955,\"start\":37945},{\"end\":37967,\"start\":37955},{\"end\":38222,\"start\":38200},{\"end\":38240,\"start\":38222},{\"end\":38258,\"start\":38240},{\"end\":38274,\"start\":38258},{\"end\":38574,\"start\":38564},{\"end\":38584,\"start\":38574},{\"end\":38598,\"start\":38584},{\"end\":38612,\"start\":38598},{\"end\":38626,\"start\":38612},{\"end\":38639,\"start\":38626},{\"end\":38648,\"start\":38639},{\"end\":38663,\"start\":38648},{\"end\":38677,\"start\":38663},{\"end\":39031,\"start\":39021},{\"end\":39041,\"start\":39031},{\"end\":39050,\"start\":39041},{\"end\":39062,\"start\":39050},{\"end\":39330,\"start\":39321},{\"end\":39343,\"start\":39330},{\"end\":39353,\"start\":39343},{\"end\":39363,\"start\":39353},{\"end\":39371,\"start\":39363},{\"end\":39382,\"start\":39371},{\"end\":39652,\"start\":39635},{\"end\":39875,\"start\":39861},{\"end\":39891,\"start\":39875},{\"end\":39903,\"start\":39891},{\"end\":40124,\"start\":40117},{\"end\":40136,\"start\":40124},{\"end\":40471,\"start\":40460},{\"end\":40481,\"start\":40471},{\"end\":40723,\"start\":40709},{\"end\":40735,\"start\":40723},{\"end\":40746,\"start\":40735},{\"end\":41014,\"start\":41002},{\"end\":41029,\"start\":41014},{\"end\":41043,\"start\":41029},{\"end\":41053,\"start\":41043},{\"end\":41317,\"start\":41305},{\"end\":41332,\"start\":41317},{\"end\":41346,\"start\":41332},{\"end\":41356,\"start\":41346},{\"end\":41575,\"start\":41560},{\"end\":41590,\"start\":41575},{\"end\":41607,\"start\":41590},{\"end\":41625,\"start\":41607},{\"end\":41637,\"start\":41625},{\"end\":41656,\"start\":41637},{\"end\":41681,\"start\":41656},{\"end\":41692,\"start\":41681},{\"end\":41704,\"start\":41692},{\"end\":42044,\"start\":42025},{\"end\":42059,\"start\":42044},{\"end\":42073,\"start\":42059},{\"end\":42343,\"start\":42332},{\"end\":42355,\"start\":42343},{\"end\":42379,\"start\":42355},{\"end\":42400,\"start\":42379},{\"end\":42638,\"start\":42623},{\"end\":42654,\"start\":42638},{\"end\":42666,\"start\":42654},{\"end\":42683,\"start\":42666},{\"end\":42697,\"start\":42683},{\"end\":42705,\"start\":42697},{\"end\":42717,\"start\":42705},{\"end\":42723,\"start\":42717},{\"end\":42730,\"start\":42723},{\"end\":43123,\"start\":43112},{\"end\":43130,\"start\":43123},{\"end\":43141,\"start\":43130},{\"end\":43449,\"start\":43442},{\"end\":43461,\"start\":43449},{\"end\":43475,\"start\":43461},{\"end\":43488,\"start\":43475},{\"end\":43499,\"start\":43488},{\"end\":43857,\"start\":43845},{\"end\":43871,\"start\":43857},{\"end\":43875,\"start\":43871},{\"end\":44191,\"start\":44173},{\"end\":44209,\"start\":44191},{\"end\":44221,\"start\":44209},{\"end\":44238,\"start\":44221},{\"end\":44526,\"start\":44510},{\"end\":44536,\"start\":44526},{\"end\":44550,\"start\":44536},{\"end\":44566,\"start\":44550},{\"end\":44578,\"start\":44566},{\"end\":44594,\"start\":44578},{\"end\":44610,\"start\":44594},{\"end\":44629,\"start\":44610},{\"end\":44640,\"start\":44629},{\"end\":44656,\"start\":44640},{\"end\":44677,\"start\":44656},{\"end\":44689,\"start\":44677},{\"end\":45144,\"start\":45134},{\"end\":45159,\"start\":45144},{\"end\":45175,\"start\":45159},{\"end\":45188,\"start\":45175},{\"end\":45205,\"start\":45188},{\"end\":45216,\"start\":45205},{\"end\":45235,\"start\":45216},{\"end\":45246,\"start\":45235},{\"end\":45607,\"start\":45590},{\"end\":45798,\"start\":45782},{\"end\":45814,\"start\":45798},{\"end\":45827,\"start\":45814},{\"end\":46109,\"start\":46093},{\"end\":46125,\"start\":46109},{\"end\":46138,\"start\":46125},{\"end\":46410,\"start\":46395},{\"end\":46588,\"start\":46575},{\"end\":46845,\"start\":46831},{\"end\":46860,\"start\":46845},{\"end\":46876,\"start\":46860},{\"end\":46888,\"start\":46876},{\"end\":46903,\"start\":46888},{\"end\":46917,\"start\":46903},{\"end\":46931,\"start\":46917},{\"end\":46951,\"start\":46931},{\"end\":47287,\"start\":47274},{\"end\":47297,\"start\":47287},{\"end\":47578,\"start\":47561},{\"end\":47595,\"start\":47578},{\"end\":47610,\"start\":47595},{\"end\":47941,\"start\":47927},{\"end\":47960,\"start\":47941},{\"end\":47978,\"start\":47960},{\"end\":48335,\"start\":48317},{\"end\":48353,\"start\":48335},{\"end\":48360,\"start\":48353},{\"end\":48372,\"start\":48360},{\"end\":48389,\"start\":48372},{\"end\":48728,\"start\":48715},{\"end\":48739,\"start\":48728},{\"end\":48757,\"start\":48739},{\"end\":48773,\"start\":48757},{\"end\":48786,\"start\":48773},{\"end\":48802,\"start\":48786},{\"end\":48814,\"start\":48802},{\"end\":48831,\"start\":48814},{\"end\":48844,\"start\":48831},{\"end\":48856,\"start\":48844},{\"end\":49170,\"start\":49154},{\"end\":49187,\"start\":49170},{\"end\":49203,\"start\":49187},{\"end\":49221,\"start\":49203},{\"end\":49426,\"start\":49411},{\"end\":49440,\"start\":49426},{\"end\":49458,\"start\":49440},{\"end\":49470,\"start\":49458},{\"end\":49769,\"start\":49751},{\"end\":49779,\"start\":49769},{\"end\":49787,\"start\":49779},{\"end\":49804,\"start\":49787},{\"end\":49822,\"start\":49804},{\"end\":49831,\"start\":49822},{\"end\":49846,\"start\":49831},{\"end\":49863,\"start\":49846},{\"end\":49878,\"start\":49863},{\"end\":49897,\"start\":49878},{\"end\":50298,\"start\":50282},{\"end\":50316,\"start\":50298},{\"end\":50633,\"start\":50614},{\"end\":50652,\"start\":50633},{\"end\":50666,\"start\":50652},{\"end\":50678,\"start\":50666},{\"end\":50694,\"start\":50678},{\"end\":51008,\"start\":50989},{\"end\":51026,\"start\":51008},{\"end\":51042,\"start\":51026},{\"end\":51054,\"start\":51042},{\"end\":51069,\"start\":51054},{\"end\":51085,\"start\":51069},{\"end\":51097,\"start\":51085},{\"end\":51436,\"start\":51418},{\"end\":51452,\"start\":51436},{\"end\":51737,\"start\":51719},{\"end\":51749,\"start\":51737},{\"end\":51768,\"start\":51749},{\"end\":52158,\"start\":52140},{\"end\":52167,\"start\":52158},{\"end\":52185,\"start\":52167},{\"end\":52194,\"start\":52185},{\"end\":52578,\"start\":52564},{\"end\":52887,\"start\":52874},{\"end\":52895,\"start\":52887},{\"end\":52911,\"start\":52895},{\"end\":52927,\"start\":52911},{\"end\":52939,\"start\":52927},{\"end\":52943,\"start\":52939},{\"end\":53227,\"start\":53209},{\"end\":53244,\"start\":53227},{\"end\":53459,\"start\":53445},{\"end\":53476,\"start\":53459},{\"end\":53498,\"start\":53476},{\"end\":53509,\"start\":53498},{\"end\":53820,\"start\":53808},{\"end\":53837,\"start\":53820},{\"end\":53852,\"start\":53837},{\"end\":53864,\"start\":53852},{\"end\":53882,\"start\":53864},{\"end\":54243,\"start\":54234},{\"end\":54256,\"start\":54243}]", "bib_venue": "[{\"end\":36280,\"start\":36274},{\"end\":36601,\"start\":36582},{\"end\":36915,\"start\":36858},{\"end\":37294,\"start\":37249},{\"end\":37678,\"start\":37641},{\"end\":38021,\"start\":37967},{\"end\":38326,\"start\":38290},{\"end\":38722,\"start\":38677},{\"end\":39107,\"start\":39062},{\"end\":39441,\"start\":39382},{\"end\":39694,\"start\":39668},{\"end\":39946,\"start\":39903},{\"end\":40237,\"start\":40151},{\"end\":40527,\"start\":40481},{\"end\":40805,\"start\":40746},{\"end\":41099,\"start\":41053},{\"end\":41401,\"start\":41356},{\"end\":41769,\"start\":41720},{\"end\":42133,\"start\":42089},{\"end\":42445,\"start\":42400},{\"end\":42816,\"start\":42746},{\"end\":43187,\"start\":43141},{\"end\":43558,\"start\":43499},{\"end\":43934,\"start\":43875},{\"end\":44171,\"start\":44084},{\"end\":44736,\"start\":44689},{\"end\":45300,\"start\":45246},{\"end\":45588,\"start\":45535},{\"end\":45886,\"start\":45827},{\"end\":46197,\"start\":46138},{\"end\":46393,\"start\":46360},{\"end\":46647,\"start\":46588},{\"end\":46996,\"start\":46951},{\"end\":47343,\"start\":47297},{\"end\":47667,\"start\":47610},{\"end\":48033,\"start\":47978},{\"end\":48432,\"start\":48389},{\"end\":48881,\"start\":48856},{\"end\":49152,\"start\":49105},{\"end\":49532,\"start\":49486},{\"end\":49937,\"start\":49897},{\"end\":50373,\"start\":50316},{\"end\":50740,\"start\":50694},{\"end\":51156,\"start\":51097},{\"end\":51498,\"start\":51452},{\"end\":51830,\"start\":51768},{\"end\":52256,\"start\":52194},{\"end\":52636,\"start\":52578},{\"end\":52989,\"start\":52943},{\"end\":53284,\"start\":53244},{\"end\":53561,\"start\":53509},{\"end\":53944,\"start\":53882},{\"end\":54306,\"start\":54256}]"}}}, "year": 2023, "month": 12, "day": 17}