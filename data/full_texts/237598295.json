{"id": 237598295, "updated": "2022-09-30 01:13:11.202", "metadata": {"title": "End-to-End Federated Learning for Autonomous Driving Vehicles", "authors": "[{\"first\":\"Hongyi\",\"last\":\"Zhang\",\"middle\":[]},{\"first\":\"Jan\",\"last\":\"Bosch\",\"middle\":[]},{\"first\":\"Helena\",\"last\":\"Olsson\",\"middle\":[\"Holmstr\u00f6m\"]}]", "venue": "2021 International Joint Conference on Neural Networks (IJCNN)", "journal": "2021 International Joint Conference on Neural Networks (IJCNN)", "publication_date": {"year": 2021, "month": null, "day": null}, "abstract": "In recent years, with the development of computation capability in devices, companies are eager to investigate and utilize suitable ML/DL methods to improve their service quality. However, with the traditional learning strategy, companies need to first build up a powerful data center to collect and analyze data from the edge and then perform centralized model training, which turns out to be inefficient. Federated Learning has been introduced to solve this challenge. Because of its characteristics such as model-only exchange and parallel training, the technique can not only preserve user data privacy but also accelerate model training speed. The method can easily handle real-time data generated from the edge without taking up a lot of valuable network transmission resources. In this paper, we introduce an approach to end-to-end on-device Machine Learning by utilizing Federated Learning. We validate our approach with an important industrial use case in the field of autonomous driving vehicles, the wheel steering angle prediction. Our results show that Federated Learning can significantly improve the quality of local edge models and also reach the same accuracy level as compared to the traditional centralized Machine Learning approach without its negative effects. Furthermore, Federated Learning can accelerate model training speed and reduce the communication overhead, which proves that this approach has great strength when deploying ML/DL components to various real-world embedded systems.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/ijcnn/ZhangBO21", "doi": "10.1109/ijcnn52387.2021.9533808"}}, "content": {"source": {"pdf_hash": "cedf6d7f4e50c0d0ed0620609455843e877fbc91", "pdf_src": "IEEE", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "df5d2efed402828db25e8e24cc78ad641dabaf48", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/cedf6d7f4e50c0d0ed0620609455843e877fbc91.txt", "contents": "\nEnd-to-End Federated Learning for Autonomous Driving Vehicles\n\n\nHongyi Zhang hongyiz@chalmers.se \nJan Bosch jan.bosch@chalmers.se \nHelena Holmstr\u00f6m Olsson \nMalm\u00f6 University\nMalm\u00f6Sweden\n\n\nChalmers University of Technology\nGothenburgSweden\n\nEnd-to-End Federated Learning for Autonomous Driving Vehicles\n10.1109/IJCNN52387.2021.9533808Index Terms-Federated Learning Machine learning Hetero- geneous computation Software Engineering\nIn recent years, with the development of computation capability in devices, companies are eager to investigate and utilize suitable ML/DL methods to improve their service quality. However, with the traditional learning strategy, companies need to first build up a powerful data center to collect and analyze data from the edge and then perform centralized model training, which turns out to be inefficient. Federated Learning has been introduced to solve this challenge. Because of its characteristics such as model-only exchange and parallel training, the technique can not only preserve user data privacy but also accelerate model training speed. The method can easily handle real-time data generated from the edge without taking up a lot of valuable network transmission resources. In this paper, we introduce an approach to end-to-end on-device Machine Learning by utilizing Federated Learning. We validate our approach with an important industrial use case in the field of autonomous driving vehicles, the wheel steering angle prediction. Our results show that Federated Learning can significantly improve the quality of local edge models and also reach the same accuracy level as compared to the traditional centralized Machine Learning approach without its negative effects. Furthermore, Federated Learning can accelerate model training speed and reduce the communication overhead, which proves that this approach has great strength when deploying ML/DL components to various real-world embedded systems.\n\nI. INTRODUCTION\n\nWith the development of computation capability in devices, Machine Learning and Deep Learning arouse great interests by companies who are eager to utilize ML/DL methods to improve their service quality. However, with the explosive growth of data generated on edge devices, the traditional centralized Machine Learning approaches have shown their weakness, such as data communication overhead, model compatibility, training efficiency, etc. [1] Figure 1 illustrate a traditional Machine Learning approach with the centralized learning framework.\n\nThe diagram contains four stages: 1) data collection from multiple distributed edge devices 2) model training in a central server 3) model validation based on existing testing data 4) model deployment to edge devices. However, the data collected from edge devices need to be transmitted to a central server and perform model training on that enormous data set, which turns out to be inefficient and expensive. In order to solve these challenges, Federated Learning has been introduced as an efficient approach that can distribute learning tasks to edge devices and avoid massive data transmission. Furthermore, due to the characteristics of Federated Learning, on-device training becomes possible and the local model quality can be continuously improved.\n\nAlthough the concept of Federated Learning has significant benefits and potential in AI engineering fields, it is hard for industries and companies to build a reliable and applicable on-device Federated Learning system. Some previous research identified the challenges of deploying AI/ML components into a real-world industrial context. As defined in \"Engineering AI Systems: A Research Agenda\" [2], AI engineering refers to AI/ML-driven software development and deployment in production contexts. We found that the transition from prototype to the production-quality deployment of ML models proves to be challenging for many companies [3] [4].\n\nThe contribution of this paper is threefold. First, we investigate and utilized a two-stream convolutional neural network combined with multi-frame streams. The effectiveness of our network can also inspire future research on image recognition of lane detection. Second, we describe an end-to-end Federated Learning approach to efficiently train Machine Learning models we investigated in a distributed context. Other than that, we demonstrate the comparison of model quality, training efficiency and bandwidth cost between commonly used centralized learning strategies and Federated Learning. Third, we empirically evaluate our approach on the realworld autonomous driving data sets. Based on our results, we demonstrate the strength of Federated Learning compared to traditional centralized learning methods.\n\nThe remainder of this paper is structured as follows. Section II introduces the background of this study. Section III details our research method, including the simulation testbed, machine learning methods and the evaluation metrics. Section IV presents the end-to-end Federated Learning approach proposed in this paper. Sections V evaluates proposed learning approach to empirical data sets. Section VI outlines the discussion on our observed results. Finally, Section VII presents conclusions and future work.\n\n\nII. BACKGROUND\n\n\nA. Federated Learning\n\nWith the introduction of the concept of Federated Learning, there has been increasing interest in how to utilize this technique to optimize the Machine Learning procedure. The first framework was proposed in 2016 [5] which demonstrate the goal of Federated Learning is to learn a global statistical model from numerous edge devices. The whole learning process only involves the sharing of locally-trained models without user data exchange. Particularly, the problem is to minimize the following finite-sum objective function 1:\nmin w f (w), where f (w) := n i=1 \u03bb i f i (w)(1)\nHere, w represents model parameters, n is the total number of edge devices, and f i (w) is the local objective function which is defined by high dimensional tensor w of the i t h device. \u03bb i (\u03bb i \u2265 0 and i \u03bb i = 1) gives the impact of i t h remote device and is defined by users [6]. This formula is also applied throughout this research.\n\nThere are several research studies regarding applying Federated Learning to different industrial scenarios. In [7] and [8], authors applied Federated Learning techniques on the Google Keyboard platform to improve virtual keyboard search suggestion quality and emoji prediction. Their results show the feasibility and benefits of applying federated learning to train models while preventing to transfer of user's data. Wang et al. [9] propose an \"In-Edge AI\" framework that provides collaboration between devices and the aggregation server to exchange learning parameters for better model training in energy and computation constraint user equipment. The results also show that Federated Learning is able to carry out dynamic system-level optimization and application-level enhancement while reducing the unnecessary system communication load. In the automotive field, Lu et al. [10] and Saputra et al. [11] evaluate the failure battery and the energy demand for the electric vehicle network on top of Federated Learning. Their approaches show the effectiveness of privacy-preserving and latency reduction. Their results also suggest that Federated Learning can significantly reduce the communication overhead and effectively protect data privacy for electric vehicle users.\n\nHowever, authors in previous research didn't discuss the impact of model training time and the communication cost when deploying and training models on edge devices. Furthermore, due to the system environment and troubles encountered when deploying Federated Learning into different cases, we propose an end-to-end approach and validate the on-device Federated Learning into a completely different industrial scenario, the steering wheel angle prediction.\n\n\nB. End-to-end Learning in Automotive\n\nCompared with deep learning, the process of traditional machine learning is often composed of multiple independent modules. For example, in natural language processing, the problem includes word segmentation, part-of-speech tagging, syntactic analysis, semantic analysis, etc. As each step is an independent task, the quality of the current result will further affect the next step, which turns out to be inefficient [12]. On the contrary, end-to-end learning eliminates the need for data labelling before each independent learning task is executed. The representation of each network layer is adjusted according to the error directly compared between the ground truth and predicted results until the model converges or the expected effect is achieved.\n\nWith the inspiration of end-to-end learning, the approach was firstly applied in the work [13] where authors designed and developed a deep convolutional neural network to predict the steering wheel angle and control the steer based on the prediction. The training data is collected from single images sampled from video and the ground truth is recorded directly from real-time human behaviour. Xu et al. [14] develop an end-to-end trainable architecture for learning to predict the distribution over future vehicle behaviour from instantaneous monocular camera observations and previous vehicle state. Chen et al. [15] presents an end-to-end learning approach to obtain the proper steering angle to maintain the car in the lane. Their results prove the feasibility of end-to-end learning in the automotive field.\n\nHowever, the previous research for this use case is mainly focusing on the training model in a single-vehicle. In this paper, we will apply Federated Learning to accelerate model training speed and improve the model quality by forming a global knowledge of all participating edge vehicles.\n\n\nIII. METHOD\n\nIn this research, the empirical method and learning procedure described in [16] were applied to make a quantitative measurement and comparison between Federated Learning and traditional centralized learning methods. In the following sections, we present the mathematical notations used in this paper, our testbed, data traces and the convolutional neural network architecture utilized for solving the problem of steering wheel angle prediction.\n\n\nA. Mathematical Notations\n\nWe first introduce the mathematical notations that will be used in the rest of the paper:\n\nA t An image frame matrix at time t\nO t = f (A t , A t\u22121 ) An optical-flow matrix at time t \u03b8 t\nSteering wheel angle at time t\n\n\nB. Data Traces and Testbed\n\nThe data sets used in this paper is SullyChen collection of labelled car driving data sets, which is available on Github [17]. In this collection, there are two data sets (Data set 2017 and Data set 2018) that record different driving information on different routes.\n\nData set 2017 contains approximately 45,500 images, 2.2 GB. The data set records a trajectory of approximately 4km around the Rolling Hills in LA, USA. In this paper, data set 2017 was used for pre-training the model. (The model will be used to initialize edge models before Federated Learning) Data set 2018 contains approximately 63,000 images, 3.1 GB. This data set records a trajectory of approximately 6km along with the Palos Verdes in LA. Data set 2018 was used for end-to-end Federated Learning and model validation. There are three kinds of driving scenarios in the data set, including hill driving, highway driving and town driving. When dealing with hill driving, the steering wheel angles have a wider range compared with highway and city driving. The majority of town and highway driving angle falls within the range [\u221250\u00b0, 50\u00b0] while in hill driving, the range is [\u2212100\u00b0, 100\u00b0]. Figure 2 demonstrate the way how we distribute data set 2018 to edge vehicles to simulate an on-device data environment. In order to provide fruitful evaluation, we conducted the experiments on 4, 8, 16, 32 and 64 edge vehicles. During the distribution, the data were divided into the corresponding number of parts and transferred to edge vehicles. In order to simulate the realworld scenario, each part of the data are consecutive ordered video frame images. Besides, in each edge vehicle, the first 70% video frame images were considered as training set while the rest 30% were acted as the testing set.\n\nIn each edge vehicle, the first 70% data were regarded as the previously recorded driving information while the rest 30% were future information. The models were continuously trained based on the recorded information and perform prediction and validation on the steering wheel angle information by using future driving data.\n\nTable I provides the hardware information for all of the servers. In order to simulate aggregation and edge functions, one server was adopted as the aggregation server while the rest were acted as edge vehicles.\n\n\nC. Machine Learning Method\n\nIn order to further improve the model prediction performance, a two-stream model was firstly proposed in [18] and applied in [19] due to its robustness and lower training cost compared with other networks such as 3D-CNN [20], RNN   [21] and LSTM [22]. In this paper, a two-stream deep Convolutional Neural Network (CNN) was investigated and utilized to perform accurate angle prediction. Figure 3 gives detailed information about the architecture. In our implementation, each stream has two convolutional layers and a max-pooling layer. After concatenating, there are two fully connected layers that are activated by the ReLU function. The model contains two different neural branches which consume spatial information and temporal information as the inputs of two streams and then output the predicted steering angle. For the first stream the model consumes 3 frames of RGB images, which can be denoted as\n{A t\u22122 , A t\u22121 , A t }.\nThe second stream is the two-frame optical flow calculated by two consecutive frames\nO t\u22121 = f ({A t\u22122 , A t\u22121 }) and O t = f ({A t\u22121 , A t }).\nOptical flow is a common temporal representation in video streams, which captures the motion changes between two frames [23]. The method of calculating optical flow applied in this paper is based on Gunnar Farneback's algorithm implemented in OpenCV [24]. Figure 4 demonstrate an example optical flow matrix produced by two consecutive image frame.\n\nThe process of training a local CNN network is to find the best model parameters which cause the minimum difference between the predicted angle and the ground truth steering angle. Therefore, in this case, we chose mean square error Fig. 3. Convolutional neural network description: the two input branches both contain two 3x3 convolution layers. The first layer has 12 output channels and activated with ELU function, while the second has 24 after that followed by 4x4 max pooling. All with stride value equals 2. After concatenating two branches, there are two fully connected layers with 250 and 10 units with the ReLu activation. \nLoss = 1 N N t=1 (\u03b8 t \u2212\u03b8 t ) 2(2)\nHere, N represents the batch size while \u03b8 t and\u03b8 t represent the ground truth and the predicted steering wheel angle value at time t.\n\nDuring the process of model training in each edge vehicles, all the image frames were firstly normalized to [\u22121, 1]. The batch size was 16 while the learning rate was set to 1e \u2212 5. The optimizer utilized here was Adam [25], with parameters \u03b2 1 = 0.6, \u03b2 2 = 0.99 and = 1e \u2212 8.\n\n\nD. Evaluation Metrics and Baseline Model\n\nIn order to provide fruitful results and evaluation, we selected three metrics and two baseline models. The three metrics include angle prediction performance, model training time and bandwidth cost:\n\n\u2022 Angle prediction performance: We used root mean square error (RMSE), a common metric, to measure the difference between prediction results and ground truth.\n\nThe metrics can provide a good estimation of the quality of the trained model in each edge vehicles. \u2022 Model training time: This metric is defined as the time cost for training a model at the edge vehicles. The result is the average of four edge vehicles during one training round. This metric demonstrates the speed of local edge devices updating their knowledge which is crucial and important for those systems which need to quickly evolve to adapt to the rapidly changing environment. The metrics were measured in all the vehicles by checking the model deployment timestamp. \u2022 Bandwidth cost: This metric is defined as the total number of bytes transmitted during the whole training procedure. This metric demonstrates the total communication resources cost of achieving an applicable CNN model.\n\nThe two baseline models include model trained by applying traditional centralized learning approach and the locally trained model without model sharing: data from edge vehicles were firstly collected to a single server. The hyper-parameter applied was the same as Federated Learning which is mentioned in section III-C and the training procedure was also accelerated by Nvidia Tesla T4 GPU. \n\n\nIV. END-TO-END FEDERATED LEARNING\n\nIn this section, we describe the algorithm and the approach applied in this paper. In order to perform on-device end-toend learning based on the input image stream, images are firstly stored in an external storage driver located on each edge vehicles. At the same time, the optical flow information is calculated. When triggering the training threshold, image frames and optical flow frames are fed into a convolutional neural network. The output of the network is then compared to the ground truth for that image frame, which is the recorded steering wheel angle. The weights of the CNN are adjusted using back-propagation to enforce the model output as close as possible to the desired output. Figure 5 illustrates the diagram of the learning procedure in a single edge vehicle. After finishing each training epoch, models in edge vehicles will also be updated to the aggregation server and form a global knowledge among other vehicles ( Figure 6). The aggregation algorithm (Algorithm 1) applied in this paper is FedAvg [26], which is a commonly used Federated Learning algorithm in most of the research. The steps of the FedAvg algorithm is listed below:\n\nStep 1: Edge vehicles locally compute the model; After finishing each five local training epoch, they send updated model results to the aggregation server.\n\nStep 2: The central server performs aggregation by averaging all updated models to form a global knowledge of all local models.\n\nStep 3: The aggregation server sends back the aggregated result to each edge vehicles.\n\nStep 4: Edge vehicles replace the local model and perform further local training by using the global deployed model.\n\nAlgorithm 1: FedAvg: In the system, total K edge vehicles are indexed by k; B is the local mini-batch size; E represents the number of local epochs, and \u03b3 represents the learning rate.\nFunction Server_Function(): initialize w 0 for each round t = 1, 2, ... do m \u2190\u2212 max(C \u00d7 K, 1); S t \u2190\u2212(random set of m clients); for each client k \u2208 S t in parallel do w k t+1 \u2190\u2212 Client U pdate(w t ); end w t+1 \u2190\u2212 K k=1 1 K w k t+1 ; end End Function Function Client_Update(w):\n\u03b2 \u2190\u2212(split P k into batches of size B); for each local epoch i from 1 to E do for batch b \u2208 \u03b2 do w \u2190\u2212 w \u2212 \u03b3\u2207l(w; b); end end return w to server End Function\n\n\nV. EVALUATION\n\nIn this section, we present the experiment results of the presented end-to-end Federated Learning approach to the use case of steering wheel angle prediction. We evaluate the system performance in three aspects (The metrics are defined in section III-D) -(1) Angle prediction performance (2) Model Training Time (3) Bandwidth cost. The results are compared between three different learning strategies, namely traditional centralized learning, independent local learning and Federated Learning. Regardless of different kinds of learning strategies, the same architecture (Detailed settings are defined in section III-C) of the convolutional neural network is applied. Figure 7 illustrates the angle prediction performance between the model trained by Federated Learning (FL) and the locally trained model without any model exchange (Local Fig. 6. Process of Federated Learning with four edge vehicles ML). The results demonstrate that Federated Learning can reach the same accuracy performance as the traditional centralized training method. Besides, compared with the independently trained model, Federated Learning can provide better prediction which is much closer to the ground truth.\n\nNumeric results are provided in Table II. We show detailed results with 4 vehicles that participated in Federated Learning, which provides a clear view of prediction performance in each edge vehicle. The results illustrate that in vehicle 1 and 4, the model of Federated Learning outperforms other baseline models. In vehicle 2 and 3, the model of Federated Learning only performs around 1\u00b0worse than the traditional centralized learning model. Based on our results, we can summarize that the Federated Learning model is able to provide more accurate prediction than the local independently trained model and the behaviour of the Federated Learning model can reach the same accuracy level compared with the centralized learning model.  Table III gives the comparison of total training time and bytes transferred between Federated Learning and two baseline models. The total number of training epochs for all the models is 100 and the model training is accelerated by Nvidia Tesla T4 GPU. The results show that Federated Learning needs slightly more training time than independently locally trained model due to the model exchange time cost. However, the training time of Federated Learning is reduced by about 75% and save about 25% bandwidth compared with the traditional centralized learning method.\n\nIn order to evaluate the impact of the different number of learning vehicles, we perform more experiments with 8, 16, 32, 64 vehicles participated. Table IV gives the overall steering  \n\n\nVI. DISCUSSION\n\nBased on our experiment results, the end-to-end Federated Learning approach has more advantages compared with the commonly used centralized learning approach. A Federated Learning model can achieve the same level of model prediction accuracy but decrease model training time and the bandwidth cost. Furthermore, if we compared with the independently local trained model, because of the model sharing mechanism, Federated Learning can form a global knowledge of the whole datasets which belong to different participated edge vehicles. The model quality is largely enhanced and can achieve much better results.\n\nDue to those advantages, there are a variety of other meaningful use cases that end-to-end Federated Learning can help. The technique reported in this paper can not only be used for steering angle prediction in self-driving vehicles but also other on-device applications, such as camera sensors and motion detection, which requires continuously machine learning model training on the resource-constrained edges. Furthermore, because of the user data privacy and network bandwidth constraints, Federated Learning can be applied in those systems which need a quickly-evolved model to adapt to their rapidly changing environment.\n\nHowever, during the experiments, we also noticed the limitation of the synchronous Federated Learning algorithm when dealing with real-world cases. As in the current experiment, we assumed that all edge vehicles have similar computational capability. A synchronous aggregation protocol requires the server to wait for all of the edge devices to finish their own training round before model aggregation. Since the realworld systems may contain heterogeneous hardware settings and different network environments, asynchronous aggregation protocols can be the next step of current Federated Learning research.\n\n\nVII. CONCLUSION\n\nIn this paper, we describe an approach to end-to-end ondevice Machine Learning by utilizing Federated Learning. We validate our approach with the wheel steering angle prediction in self-driving vehicles. Our results demonstrate the strength and advantage of the model trained under the end-to-end Federated Learning approach. The model can achieve the same level of prediction accuracy compared with the commonly used centralized learning method but reduces training time by 75% and bandwidth cost by 25 % in our case. Note that if the number of participating devices is further increased, the reduction will be more obvious and the strength of Federated Learning will become stronger.\n\nIn the future, we plan to validate our approach in more use cases. Also, we would like to explore more advanced neural networks combined with the Federated Learning method. Furthermore, we plan to investigate more suitable aggregation algorithms and protocols for our end-to-end Federated Learning approach and different real-world industrial scenarios.\n\nACKNOWLEDGEMENT This work was funded by the Chalmers AI Research Center and Software Center. The computations were enabled by resources provided by the Swedish National Infrastructure for Computing (SNIC) at Chalmers Centre for Computational Science and Engineering (C3SE), which is partially funded by the Swedish Research Council through grant agreement no. 2018-05973. The authors would also like to express their gratitude for all the support and suggestions provided by Volvo Car.\n\nFig. 1 .\n1Traditional Centralized Learning System\n\nFig. 2 .\n2The method of data distributing before simulation\n\nFig. 4 .\n4At (c) Ot = f ({A t\u22121 , At}) Example image streams of the optical flow as the local model training loss function:\n\nFig. 5 .\n5Diagram of end-to-end on-device learning procedure in a single vehicle\n\nFig. 7 .\n7The comparison of angle prediction performance on four local vehicle test set with Federated Learning and two baseline models\n\nTABLE I HARDWARE\nISETUP FOR TESTBED SERVERSCPU \nIntel(R) Xeon(R) Gold 6226R \n\nCores \n8 \n\nFrequency \n2.90 GHz \n\nMemory \n32 GB \n\nOS \nLinux 4.15.0-106-generic \n\nGPU \nNvidia Tesla T4 GPU \n\n\n\n\nThe performance can be then compared with the model trained by the Federated Learning approach.\u2022 Locally trained model without model sharing (Local \nML): \nThese baseline models were trained directly on each edge \nvehicles. However, different from Federated Learning, \nthere was no model exchange during the training pro-\ncedure. The prediction performance can be compared \nwith the Federated Learning model to see how Federated \nLearning can outperform those independently trained \nlocal models. \n\n\n\nTABLE II STEERING\nIIWHEEL ANGLE REGRESSION ERROR (RMSE) ON TEST SET OF EACH EDGE VEHICLE (4 VEHICLES IN TOTAL)Vehicle 1 Vehicle 2 Vehicle 3 Vehicle 4 Overall \n\nFL \n3.154 \n8.875 \n17.209 \n5.581 \n10.242 \nML \n5.371 \n7.914 \n16.215 \n7.258 \n10.099 \nLocal ML \n4.017 \n14.775 \n25.670 \n7.313 \n15.419 \n\n\n\nTABLE III TRAINING\nIIIwith the increasing number of edge vehicles, the model prediction performance on the edge is further enhanced. Furthermore, total model training time is linearly decreased corresponding to the increasing number of edge vehicles under the same total amount of edge data. Based on our results, we can summarize that with the participation of more edge vehicles and the larger size of the input datasets, the advantages of Federated Learning will become more obvious.TIME AND BANDWIDTH COST WITH DIFFERENT MODEL \nTRAINING METHODS (4 VEHICLES IN TOTAL) \n\nFL \nML \nLocal ML \nTotal Training Time (sec) \n511.6 2137.2 \n485.3 \nTotal Bytes Transferred (GB) \n1.56 \n2.02 \n-\n\nangle prediction error and total training time of the Federated \nLearning model with the different number of vehicles. The \noverall value provides an overview of prediction performance \namong test datasets that belong to all participated vehicles. We \nobserved that \n\nTABLE IV OVERALL\nIVSTEERING WHEEL ANGLE REGRESSION ERROR (RMSE) AND MODEL TRAINING TIME OF FEDERATED LEARNING MODEL WITH DIFFERENT NUMBER OF VEHICLES PARTICIPATEDNumber of Vehicles \n4 \n8 \n16 \n32 \n64 \n\nError (RMSE) \n10.242 10.649 9.644 9.387 9.251 \nTotal Training Time (sec) \n511.6 \n264.3 \n125.1 \n65.3 \n31.7 \n\n\n\u2022 Traditional Centralized Learning model (ML): This baseline model was trained under the traditional centralized learning approach. Before model training, all the\n\nMachine learning with big data: Challenges and approaches. A , K Grolinger, H F Elyamany, M A Capretz, IEEE Access. 5A. L'heureux, K. Grolinger, H. F. Elyamany, and M. A. Capretz, \"Machine learning with big data: Challenges and approaches,\" IEEE Access, vol. 5, pp. 7776-7797, 2017.\n\nEngineering ai systems: A research agenda. J Bosch, I Crnkovic, H H Olsson, arXiv:2001.07522arXiv preprintJ. Bosch, I. Crnkovic, and H. H. Olsson, \"Engineering ai systems: A research agenda,\" arXiv preprint arXiv:2001.07522, 2020.\n\nMachine learning with big data: Challenges and approaches. A , K Grolinger, H F Elyamany, M A Capretz, IEEE Access. 5A. L'heureux, K. Grolinger, H. F. Elyamany, and M. A. Capretz, \"Machine learning with big data: Challenges and approaches,\" IEEE Access, vol. 5, pp. 7776-7797, 2017.\n\nA taxonomy of software engineering challenges for machine learning systems: An empirical investigation. L E Lwakatare, A Raj, J Bosch, H H Olsson, I Crnkovic, International Conference on Agile Software Development. ChamSpringerL. E. Lwakatare, A. Raj, J. Bosch, H. H. Olsson, and I. Crnkovic, \"A taxonomy of software engineering challenges for machine learning systems: An empirical investigation,\" in International Conference on Agile Software Development. Springer, Cham, 2019, pp. 227-243.\n\nFederated optimization: Distributed machine learning for on-device intelligence. J Kone\u010dn\u1ef3, H B Mcmahan, D Ramage, P Richt\u00e1rik, arXiv:1610.02527arXiv preprintJ. Kone\u010dn\u1ef3, H. B. McMahan, D. Ramage, and P. Richt\u00e1rik, \"Federated optimization: Distributed machine learning for on-device intelligence,\" arXiv preprint arXiv:1610.02527, 2016.\n\nFederated machine learning: Concept and applications. Q Yang, Y Liu, T Chen, Y Tong, ACM Transactions on Intelligent Systems and Technology (TIST). 102Q. Yang, Y. Liu, T. Chen, and Y. Tong, \"Federated machine learning: Concept and applications,\" ACM Transactions on Intelligent Systems and Technology (TIST), vol. 10, no. 2, pp. 1-19, 2019.\n\nFederated learning for mobile keyboard prediction. A Hard, K Rao, R Mathews, S Ramaswamy, F Beaufays, S Augenstein, H Eichner, C Kiddon, D Ramage, arXiv:1811.03604arXiv preprintA. Hard, K. Rao, R. Mathews, S. Ramaswamy, F. Beaufays, S. Augen- stein, H. Eichner, C. Kiddon, and D. Ramage, \"Federated learning for mobile keyboard prediction,\" arXiv preprint arXiv:1811.03604, 2018.\n\nFederated learning for emoji prediction in a mobile keyboard. S Ramaswamy, R Mathews, K Rao, F Beaufays, arXiv:1906.04329arXiv preprintS. Ramaswamy, R. Mathews, K. Rao, and F. Beaufays, \"Federated learning for emoji prediction in a mobile keyboard,\" arXiv preprint arXiv:1906.04329, 2019.\n\nIn-edge ai: Intelligentizing mobile edge computing, caching and communication by federated learning. X Wang, Y Han, C Wang, Q Zhao, X Chen, M Chen, IEEE Network. 335X. Wang, Y. Han, C. Wang, Q. Zhao, X. Chen, and M. Chen, \"In-edge ai: Intelligentizing mobile edge computing, caching and communication by federated learning,\" IEEE Network, vol. 33, no. 5, pp. 156-165, 2019.\n\nCollaborative learning on the edges: A case study on connected vehicles. S Lu, Y Yao, W Shi, 2nd {USENIX} Workshop on Hot Topics in Edge Computing. S. Lu, Y. Yao, and W. Shi, \"Collaborative learning on the edges: A case study on connected vehicles,\" in 2nd {USENIX} Workshop on Hot Topics in Edge Computing (HotEdge 19), 2019.\n\nEnergy demand prediction with federated learning for electric vehicle networks. Y M Saputra, D T Hoang, D N Nguyen, E Dutkiewicz, M D Mueck, S Srikanteswara, arXiv:1909.00907arXiv preprintY. M. Saputra, D. T. Hoang, D. N. Nguyen, E. Dutkiewicz, M. D. Mueck, and S. Srikanteswara, \"Energy demand prediction with federated learning for electric vehicle networks,\" arXiv preprint arXiv:1909.00907, 2019.\n\nDeep speech 2: End-to-end speech recognition in english and mandarin. D Amodei, S Ananthanarayanan, R Anubhai, J Bai, E Battenberg, C Case, J Casper, B Catanzaro, Q Cheng, G Chen, International conference on machine learning. PMLRD. Amodei, S. Ananthanarayanan, R. Anubhai, J. Bai, E. Battenberg, C. Case, J. Casper, B. Catanzaro, Q. Cheng, G. Chen et al., \"Deep speech 2: End-to-end speech recognition in english and mandarin,\" in International conference on machine learning. PMLR, 2016, pp. 173- 182.\n\nEnd to end learning for self-driving cars. M Bojarski, D Testa, D Dworakowski, B Firner, B Flepp, P Goyal, L D Jackel, M Monfort, U Muller, J Zhang, arXiv:1604.07316arXiv preprintM. Bojarski, D. Del Testa, D. Dworakowski, B. Firner, B. Flepp, P. Goyal, L. D. Jackel, M. Monfort, U. Muller, J. Zhang et al., \"End to end learning for self-driving cars,\" arXiv preprint arXiv:1604.07316, 2016.\n\nEnd-to-end learning of driving models from large-scale video datasets. H Xu, Y Gao, F Yu, T Darrell, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionH. Xu, Y. Gao, F. Yu, and T. Darrell, \"End-to-end learning of driving models from large-scale video datasets,\" in Proceedings of the IEEE conference on computer vision and pattern recognition, 2017, pp. 2174- 2182.\n\nEnd-to-end learning for lane keeping of selfdriving cars. Z Chen, X Huang, 2017 IEEE Intelligent Vehicles Symposium (IV). IEEEZ. Chen and X. Huang, \"End-to-end learning for lane keeping of self- driving cars,\" in 2017 IEEE Intelligent Vehicles Symposium (IV). IEEE, 2017, pp. 1856-1860.\n\nMachine learning and software engineering. D Zhang, J J Tsai, Software Quality Journal. 112D. Zhang and J. J. Tsai, \"Machine learning and software engineering,\" Software Quality Journal, vol. 11, no. 2, pp. 87-119, 2003.\n\nCollection of labeled car driving datasets. Sullychen, SullyChen. (2018) Collection of labeled car driving datasets. [Online].\n\nTwo-stream convolutional networks for action recognition in videos. K Simonyan, A Zisserman, Advances in neural information processing systems. K. Simonyan and A. Zisserman, \"Two-stream convolutional networks for action recognition in videos,\" in Advances in neural information processing systems, 2014, pp. 568-576.\n\nTwo-stream convolutional networks for end-to-end learning of self-driving cars. N Fernandez, arXiv:1811.05785arXiv preprintN. Fernandez, \"Two-stream convolutional networks for end-to-end learn- ing of self-driving cars,\" arXiv preprint arXiv:1811.05785, 2018.\n\nSelf-driving car steering angle prediction based on image recognition. S Du, H Guo, A Simpson, arXiv:1912.05440arXiv preprintS. Du, H. Guo, and A. Simpson, \"Self-driving car steering angle pre- diction based on image recognition,\" arXiv preprint arXiv:1912.05440, 2019.\n\nEnd-to-end deep learning for steering autonomous vehicles considering temporal dependencies. H M Eraqi, M N Moustafa, J Honer, arXiv:1710.03804arXiv preprintH. M. Eraqi, M. N. Moustafa, and J. Honer, \"End-to-end deep learning for steering autonomous vehicles considering temporal dependencies,\" arXiv preprint arXiv:1710.03804, 2017.\n\nControlling steering angle for cooperative self-driving vehicles utilizing cnn and lstm-based deep networks. R Valiente, M Zaman, S Ozer, Y P Fallah, 2019 IEEE Intelligent Vehicles Symposium (IV). R. Valiente, M. Zaman, S. Ozer, and Y. P. Fallah, \"Controlling steering angle for cooperative self-driving vehicles utilizing cnn and lstm-based deep networks,\" in 2019 IEEE Intelligent Vehicles Symposium (IV).\n\n. IEEE. IEEE, 2019, pp. 2423-2428.\n\nDetermining optical flow. B K Horn, B G Schunck, Techniques and Applications of Image Understanding. 281B. K. Horn and B. G. Schunck, \"Determining optical flow,\" in Tech- niques and Applications of Image Understanding, vol. 281. Interna- tional Society for Optics and Photonics, 1981, pp. 319-331.\n\nTwo-frame motion estimation based on polynomial expansion. G Farneb\u00e4ck, Scandinavian conference on Image analysis. SpringerG. Farneb\u00e4ck, \"Two-frame motion estimation based on polynomial expansion,\" in Scandinavian conference on Image analysis. Springer, 2003, pp. 363-370.\n\nAdam: A method for stochastic optimization. D P Kingma, J Ba, arXiv:1412.6980arXiv preprintD. P. Kingma and J. Ba, \"Adam: A method for stochastic optimization,\" arXiv preprint arXiv:1412.6980, 2014.\n\nOn the convergence of fedavg on non-iid data. X Li, K Huang, W Yang, S Wang, Z Zhang, arXiv:1907.02189arXiv preprintX. Li, K. Huang, W. Yang, S. Wang, and Z. Zhang, \"On the convergence of fedavg on non-iid data,\" arXiv preprint arXiv:1907.02189, 2019.\n", "annotations": {"author": "[{\"end\":98,\"start\":65},{\"end\":131,\"start\":99},{\"end\":186,\"start\":132},{\"end\":239,\"start\":187}]", "publisher": null, "author_last_name": "[{\"end\":77,\"start\":72},{\"end\":108,\"start\":103},{\"end\":155,\"start\":149}]", "author_first_name": "[{\"end\":71,\"start\":65},{\"end\":102,\"start\":99},{\"end\":138,\"start\":132},{\"end\":148,\"start\":139}]", "author_affiliation": "[{\"end\":185,\"start\":157},{\"end\":238,\"start\":188}]", "title": "[{\"end\":62,\"start\":1},{\"end\":301,\"start\":240}]", "venue": null, "abstract": "[{\"end\":1941,\"start\":430}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2403,\"start\":2400},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3660,\"start\":3657},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3901,\"start\":3898},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3905,\"start\":3902},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":5490,\"start\":5487},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":6133,\"start\":6130},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":6305,\"start\":6302},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":6313,\"start\":6310},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":6624,\"start\":6621},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":7073,\"start\":7069},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":7097,\"start\":7093},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":8383,\"start\":8379},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":8810,\"start\":8806},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":9124,\"start\":9120},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":9334,\"start\":9330},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":9914,\"start\":9910},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":10682,\"start\":10678},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":13003,\"start\":12999},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":13023,\"start\":13019},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":13118,\"start\":13114},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":13130,\"start\":13126},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":13144,\"start\":13140},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":14093,\"start\":14089},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":14223,\"start\":14219},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":15346,\"start\":15342},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":18061,\"start\":18057}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":25460,\"start\":25410},{\"attributes\":{\"id\":\"fig_1\"},\"end\":25521,\"start\":25461},{\"attributes\":{\"id\":\"fig_2\"},\"end\":25646,\"start\":25522},{\"attributes\":{\"id\":\"fig_3\"},\"end\":25728,\"start\":25647},{\"attributes\":{\"id\":\"fig_4\"},\"end\":25865,\"start\":25729},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":26052,\"start\":25866},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":26553,\"start\":26053},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":26846,\"start\":26554},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":27798,\"start\":26847},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":28109,\"start\":27799}]", "paragraph": "[{\"end\":2504,\"start\":1960},{\"end\":3260,\"start\":2506},{\"end\":3906,\"start\":3262},{\"end\":4718,\"start\":3908},{\"end\":5231,\"start\":4720},{\"end\":5801,\"start\":5274},{\"end\":6189,\"start\":5851},{\"end\":7464,\"start\":6191},{\"end\":7921,\"start\":7466},{\"end\":8714,\"start\":7962},{\"end\":9528,\"start\":8716},{\"end\":9819,\"start\":9530},{\"end\":10279,\"start\":9835},{\"end\":10398,\"start\":10309},{\"end\":10435,\"start\":10400},{\"end\":10526,\"start\":10496},{\"end\":10824,\"start\":10557},{\"end\":12324,\"start\":10826},{\"end\":12650,\"start\":12326},{\"end\":12863,\"start\":12652},{\"end\":13800,\"start\":12894},{\"end\":13909,\"start\":13825},{\"end\":14317,\"start\":13969},{\"end\":14953,\"start\":14319},{\"end\":15121,\"start\":14988},{\"end\":15399,\"start\":15123},{\"end\":15643,\"start\":15444},{\"end\":15803,\"start\":15645},{\"end\":16603,\"start\":15805},{\"end\":16996,\"start\":16605},{\"end\":18192,\"start\":17034},{\"end\":18349,\"start\":18194},{\"end\":18478,\"start\":18351},{\"end\":18566,\"start\":18480},{\"end\":18684,\"start\":18568},{\"end\":18870,\"start\":18686},{\"end\":19304,\"start\":19148},{\"end\":20509,\"start\":19322},{\"end\":21812,\"start\":20511},{\"end\":21999,\"start\":21814},{\"end\":22626,\"start\":22018},{\"end\":23254,\"start\":22628},{\"end\":23862,\"start\":23256},{\"end\":24567,\"start\":23882},{\"end\":24922,\"start\":24569},{\"end\":25409,\"start\":24924}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":5850,\"start\":5802},{\"attributes\":{\"id\":\"formula_1\"},\"end\":10495,\"start\":10436},{\"attributes\":{\"id\":\"formula_2\"},\"end\":13824,\"start\":13801},{\"attributes\":{\"id\":\"formula_3\"},\"end\":13968,\"start\":13910},{\"attributes\":{\"id\":\"formula_4\"},\"end\":14987,\"start\":14954},{\"attributes\":{\"id\":\"formula_5\"},\"end\":19147,\"start\":18871}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":20551,\"start\":20543},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":21256,\"start\":21247},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":21970,\"start\":21962}]", "section_header": "[{\"end\":1958,\"start\":1943},{\"end\":5248,\"start\":5234},{\"end\":5272,\"start\":5251},{\"end\":7960,\"start\":7924},{\"end\":9833,\"start\":9822},{\"end\":10307,\"start\":10282},{\"end\":10555,\"start\":10529},{\"end\":12892,\"start\":12866},{\"end\":15442,\"start\":15402},{\"end\":17032,\"start\":16999},{\"end\":19320,\"start\":19307},{\"end\":22016,\"start\":22002},{\"end\":23880,\"start\":23865},{\"end\":25419,\"start\":25411},{\"end\":25470,\"start\":25462},{\"end\":25531,\"start\":25523},{\"end\":25656,\"start\":25648},{\"end\":25738,\"start\":25730},{\"end\":25883,\"start\":25867},{\"end\":26572,\"start\":26555},{\"end\":26866,\"start\":26848},{\"end\":27816,\"start\":27800}]", "table": "[{\"end\":26052,\"start\":25910},{\"end\":26553,\"start\":26150},{\"end\":26846,\"start\":26665},{\"end\":27798,\"start\":27334},{\"end\":28109,\"start\":27962}]", "figure_caption": "[{\"end\":25460,\"start\":25421},{\"end\":25521,\"start\":25472},{\"end\":25646,\"start\":25533},{\"end\":25728,\"start\":25658},{\"end\":25865,\"start\":25740},{\"end\":25910,\"start\":25885},{\"end\":26150,\"start\":26055},{\"end\":26665,\"start\":26575},{\"end\":27334,\"start\":26870},{\"end\":27962,\"start\":27819}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":2412,\"start\":2404},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":11727,\"start\":11719},{\"end\":13290,\"start\":13282},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":14233,\"start\":14225},{\"end\":14558,\"start\":14552},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":17738,\"start\":17730},{\"end\":17982,\"start\":17974},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":19997,\"start\":19989},{\"end\":20166,\"start\":20160}]", "bib_author_first_name": "[{\"end\":28334,\"start\":28333},{\"end\":28338,\"start\":28337},{\"end\":28351,\"start\":28350},{\"end\":28353,\"start\":28352},{\"end\":28365,\"start\":28364},{\"end\":28367,\"start\":28366},{\"end\":28602,\"start\":28601},{\"end\":28611,\"start\":28610},{\"end\":28623,\"start\":28622},{\"end\":28625,\"start\":28624},{\"end\":28850,\"start\":28849},{\"end\":28854,\"start\":28853},{\"end\":28867,\"start\":28866},{\"end\":28869,\"start\":28868},{\"end\":28881,\"start\":28880},{\"end\":28883,\"start\":28882},{\"end\":29179,\"start\":29178},{\"end\":29181,\"start\":29180},{\"end\":29194,\"start\":29193},{\"end\":29201,\"start\":29200},{\"end\":29210,\"start\":29209},{\"end\":29212,\"start\":29211},{\"end\":29222,\"start\":29221},{\"end\":29650,\"start\":29649},{\"end\":29661,\"start\":29660},{\"end\":29663,\"start\":29662},{\"end\":29674,\"start\":29673},{\"end\":29684,\"start\":29683},{\"end\":29960,\"start\":29959},{\"end\":29968,\"start\":29967},{\"end\":29975,\"start\":29974},{\"end\":29983,\"start\":29982},{\"end\":30299,\"start\":30298},{\"end\":30307,\"start\":30306},{\"end\":30314,\"start\":30313},{\"end\":30325,\"start\":30324},{\"end\":30338,\"start\":30337},{\"end\":30350,\"start\":30349},{\"end\":30364,\"start\":30363},{\"end\":30375,\"start\":30374},{\"end\":30385,\"start\":30384},{\"end\":30691,\"start\":30690},{\"end\":30704,\"start\":30703},{\"end\":30715,\"start\":30714},{\"end\":30722,\"start\":30721},{\"end\":31020,\"start\":31019},{\"end\":31028,\"start\":31027},{\"end\":31035,\"start\":31034},{\"end\":31043,\"start\":31042},{\"end\":31051,\"start\":31050},{\"end\":31059,\"start\":31058},{\"end\":31367,\"start\":31366},{\"end\":31373,\"start\":31372},{\"end\":31380,\"start\":31379},{\"end\":31702,\"start\":31701},{\"end\":31704,\"start\":31703},{\"end\":31715,\"start\":31714},{\"end\":31717,\"start\":31716},{\"end\":31726,\"start\":31725},{\"end\":31728,\"start\":31727},{\"end\":31738,\"start\":31737},{\"end\":31752,\"start\":31751},{\"end\":31754,\"start\":31753},{\"end\":31763,\"start\":31762},{\"end\":32094,\"start\":32093},{\"end\":32104,\"start\":32103},{\"end\":32124,\"start\":32123},{\"end\":32135,\"start\":32134},{\"end\":32142,\"start\":32141},{\"end\":32156,\"start\":32155},{\"end\":32164,\"start\":32163},{\"end\":32174,\"start\":32173},{\"end\":32187,\"start\":32186},{\"end\":32196,\"start\":32195},{\"end\":32572,\"start\":32571},{\"end\":32584,\"start\":32583},{\"end\":32593,\"start\":32592},{\"end\":32608,\"start\":32607},{\"end\":32618,\"start\":32617},{\"end\":32627,\"start\":32626},{\"end\":32636,\"start\":32635},{\"end\":32638,\"start\":32637},{\"end\":32648,\"start\":32647},{\"end\":32659,\"start\":32658},{\"end\":32669,\"start\":32668},{\"end\":32992,\"start\":32991},{\"end\":32998,\"start\":32997},{\"end\":33005,\"start\":33004},{\"end\":33011,\"start\":33010},{\"end\":33437,\"start\":33436},{\"end\":33445,\"start\":33444},{\"end\":33710,\"start\":33709},{\"end\":33719,\"start\":33718},{\"end\":33721,\"start\":33720},{\"end\":34085,\"start\":34084},{\"end\":34097,\"start\":34096},{\"end\":34415,\"start\":34414},{\"end\":34667,\"start\":34666},{\"end\":34673,\"start\":34672},{\"end\":34680,\"start\":34679},{\"end\":34960,\"start\":34959},{\"end\":34962,\"start\":34961},{\"end\":34971,\"start\":34970},{\"end\":34973,\"start\":34972},{\"end\":34985,\"start\":34984},{\"end\":35311,\"start\":35310},{\"end\":35323,\"start\":35322},{\"end\":35332,\"start\":35331},{\"end\":35340,\"start\":35339},{\"end\":35342,\"start\":35341},{\"end\":35673,\"start\":35672},{\"end\":35675,\"start\":35674},{\"end\":35683,\"start\":35682},{\"end\":35685,\"start\":35684},{\"end\":36005,\"start\":36004},{\"end\":36264,\"start\":36263},{\"end\":36266,\"start\":36265},{\"end\":36276,\"start\":36275},{\"end\":36466,\"start\":36465},{\"end\":36472,\"start\":36471},{\"end\":36481,\"start\":36480},{\"end\":36489,\"start\":36488},{\"end\":36497,\"start\":36496}]", "bib_author_last_name": "[{\"end\":28348,\"start\":28339},{\"end\":28362,\"start\":28354},{\"end\":28375,\"start\":28368},{\"end\":28608,\"start\":28603},{\"end\":28620,\"start\":28612},{\"end\":28632,\"start\":28626},{\"end\":28864,\"start\":28855},{\"end\":28878,\"start\":28870},{\"end\":28891,\"start\":28884},{\"end\":29191,\"start\":29182},{\"end\":29198,\"start\":29195},{\"end\":29207,\"start\":29202},{\"end\":29219,\"start\":29213},{\"end\":29231,\"start\":29223},{\"end\":29658,\"start\":29651},{\"end\":29671,\"start\":29664},{\"end\":29681,\"start\":29675},{\"end\":29694,\"start\":29685},{\"end\":29965,\"start\":29961},{\"end\":29972,\"start\":29969},{\"end\":29980,\"start\":29976},{\"end\":29988,\"start\":29984},{\"end\":30304,\"start\":30300},{\"end\":30311,\"start\":30308},{\"end\":30322,\"start\":30315},{\"end\":30335,\"start\":30326},{\"end\":30347,\"start\":30339},{\"end\":30361,\"start\":30351},{\"end\":30372,\"start\":30365},{\"end\":30382,\"start\":30376},{\"end\":30392,\"start\":30386},{\"end\":30701,\"start\":30692},{\"end\":30712,\"start\":30705},{\"end\":30719,\"start\":30716},{\"end\":30731,\"start\":30723},{\"end\":31025,\"start\":31021},{\"end\":31032,\"start\":31029},{\"end\":31040,\"start\":31036},{\"end\":31048,\"start\":31044},{\"end\":31056,\"start\":31052},{\"end\":31064,\"start\":31060},{\"end\":31370,\"start\":31368},{\"end\":31377,\"start\":31374},{\"end\":31384,\"start\":31381},{\"end\":31712,\"start\":31705},{\"end\":31723,\"start\":31718},{\"end\":31735,\"start\":31729},{\"end\":31749,\"start\":31739},{\"end\":31760,\"start\":31755},{\"end\":31777,\"start\":31764},{\"end\":32101,\"start\":32095},{\"end\":32121,\"start\":32105},{\"end\":32132,\"start\":32125},{\"end\":32139,\"start\":32136},{\"end\":32153,\"start\":32143},{\"end\":32161,\"start\":32157},{\"end\":32171,\"start\":32165},{\"end\":32184,\"start\":32175},{\"end\":32193,\"start\":32188},{\"end\":32201,\"start\":32197},{\"end\":32581,\"start\":32573},{\"end\":32590,\"start\":32585},{\"end\":32605,\"start\":32594},{\"end\":32615,\"start\":32609},{\"end\":32624,\"start\":32619},{\"end\":32633,\"start\":32628},{\"end\":32645,\"start\":32639},{\"end\":32656,\"start\":32649},{\"end\":32666,\"start\":32660},{\"end\":32675,\"start\":32670},{\"end\":32995,\"start\":32993},{\"end\":33002,\"start\":32999},{\"end\":33008,\"start\":33006},{\"end\":33019,\"start\":33012},{\"end\":33442,\"start\":33438},{\"end\":33451,\"start\":33446},{\"end\":33716,\"start\":33711},{\"end\":33726,\"start\":33722},{\"end\":33941,\"start\":33932},{\"end\":34094,\"start\":34086},{\"end\":34107,\"start\":34098},{\"end\":34425,\"start\":34416},{\"end\":34670,\"start\":34668},{\"end\":34677,\"start\":34674},{\"end\":34688,\"start\":34681},{\"end\":34968,\"start\":34963},{\"end\":34982,\"start\":34974},{\"end\":34991,\"start\":34986},{\"end\":35320,\"start\":35312},{\"end\":35329,\"start\":35324},{\"end\":35337,\"start\":35333},{\"end\":35349,\"start\":35343},{\"end\":35680,\"start\":35676},{\"end\":35693,\"start\":35686},{\"end\":36015,\"start\":36006},{\"end\":36273,\"start\":36267},{\"end\":36279,\"start\":36277},{\"end\":36469,\"start\":36467},{\"end\":36478,\"start\":36473},{\"end\":36486,\"start\":36482},{\"end\":36494,\"start\":36490},{\"end\":36503,\"start\":36498}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":2780717},\"end\":28556,\"start\":28274},{\"attributes\":{\"doi\":\"arXiv:2001.07522\",\"id\":\"b1\"},\"end\":28788,\"start\":28558},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":2780717},\"end\":29072,\"start\":28790},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":152283862},\"end\":29566,\"start\":29074},{\"attributes\":{\"doi\":\"arXiv:1610.02527\",\"id\":\"b4\"},\"end\":29903,\"start\":29568},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":219878182},\"end\":30245,\"start\":29905},{\"attributes\":{\"doi\":\"arXiv:1811.03604\",\"id\":\"b6\"},\"end\":30626,\"start\":30247},{\"attributes\":{\"doi\":\"arXiv:1906.04329\",\"id\":\"b7\"},\"end\":30916,\"start\":30628},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":52343892},\"end\":31291,\"start\":30918},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":174794603},\"end\":31619,\"start\":31293},{\"attributes\":{\"doi\":\"arXiv:1909.00907\",\"id\":\"b10\"},\"end\":32021,\"start\":31621},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":11590585},\"end\":32526,\"start\":32023},{\"attributes\":{\"doi\":\"arXiv:1604.07316\",\"id\":\"b12\"},\"end\":32918,\"start\":32528},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":11913930},\"end\":33376,\"start\":32920},{\"attributes\":{\"id\":\"b14\"},\"end\":33664,\"start\":33378},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":845125},\"end\":33886,\"start\":33666},{\"attributes\":{\"id\":\"b16\"},\"end\":34014,\"start\":33888},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":11797475},\"end\":34332,\"start\":34016},{\"attributes\":{\"doi\":\"arXiv:1811.05785\",\"id\":\"b18\"},\"end\":34593,\"start\":34334},{\"attributes\":{\"doi\":\"arXiv:1912.05440\",\"id\":\"b19\"},\"end\":34864,\"start\":34595},{\"attributes\":{\"doi\":\"arXiv:1710.03804\",\"id\":\"b20\"},\"end\":35199,\"start\":34866},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":104291881},\"end\":35608,\"start\":35201},{\"attributes\":{\"id\":\"b22\"},\"end\":35644,\"start\":35610},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":1371968},\"end\":35943,\"start\":35646},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":15601477},\"end\":36217,\"start\":35945},{\"attributes\":{\"doi\":\"arXiv:1412.6980\",\"id\":\"b25\"},\"end\":36417,\"start\":36219},{\"attributes\":{\"doi\":\"arXiv:1907.02189\",\"id\":\"b26\"},\"end\":36670,\"start\":36419}]", "bib_title": "[{\"end\":28331,\"start\":28274},{\"end\":28847,\"start\":28790},{\"end\":29176,\"start\":29074},{\"end\":29957,\"start\":29905},{\"end\":31017,\"start\":30918},{\"end\":31364,\"start\":31293},{\"end\":32091,\"start\":32023},{\"end\":32989,\"start\":32920},{\"end\":33434,\"start\":33378},{\"end\":33707,\"start\":33666},{\"end\":34082,\"start\":34016},{\"end\":35308,\"start\":35201},{\"end\":35670,\"start\":35646},{\"end\":36002,\"start\":35945}]", "bib_author": "[{\"end\":28337,\"start\":28333},{\"end\":28350,\"start\":28337},{\"end\":28364,\"start\":28350},{\"end\":28377,\"start\":28364},{\"end\":28610,\"start\":28601},{\"end\":28622,\"start\":28610},{\"end\":28634,\"start\":28622},{\"end\":28853,\"start\":28849},{\"end\":28866,\"start\":28853},{\"end\":28880,\"start\":28866},{\"end\":28893,\"start\":28880},{\"end\":29193,\"start\":29178},{\"end\":29200,\"start\":29193},{\"end\":29209,\"start\":29200},{\"end\":29221,\"start\":29209},{\"end\":29233,\"start\":29221},{\"end\":29660,\"start\":29649},{\"end\":29673,\"start\":29660},{\"end\":29683,\"start\":29673},{\"end\":29696,\"start\":29683},{\"end\":29967,\"start\":29959},{\"end\":29974,\"start\":29967},{\"end\":29982,\"start\":29974},{\"end\":29990,\"start\":29982},{\"end\":30306,\"start\":30298},{\"end\":30313,\"start\":30306},{\"end\":30324,\"start\":30313},{\"end\":30337,\"start\":30324},{\"end\":30349,\"start\":30337},{\"end\":30363,\"start\":30349},{\"end\":30374,\"start\":30363},{\"end\":30384,\"start\":30374},{\"end\":30394,\"start\":30384},{\"end\":30703,\"start\":30690},{\"end\":30714,\"start\":30703},{\"end\":30721,\"start\":30714},{\"end\":30733,\"start\":30721},{\"end\":31027,\"start\":31019},{\"end\":31034,\"start\":31027},{\"end\":31042,\"start\":31034},{\"end\":31050,\"start\":31042},{\"end\":31058,\"start\":31050},{\"end\":31066,\"start\":31058},{\"end\":31372,\"start\":31366},{\"end\":31379,\"start\":31372},{\"end\":31386,\"start\":31379},{\"end\":31714,\"start\":31701},{\"end\":31725,\"start\":31714},{\"end\":31737,\"start\":31725},{\"end\":31751,\"start\":31737},{\"end\":31762,\"start\":31751},{\"end\":31779,\"start\":31762},{\"end\":32103,\"start\":32093},{\"end\":32123,\"start\":32103},{\"end\":32134,\"start\":32123},{\"end\":32141,\"start\":32134},{\"end\":32155,\"start\":32141},{\"end\":32163,\"start\":32155},{\"end\":32173,\"start\":32163},{\"end\":32186,\"start\":32173},{\"end\":32195,\"start\":32186},{\"end\":32203,\"start\":32195},{\"end\":32583,\"start\":32571},{\"end\":32592,\"start\":32583},{\"end\":32607,\"start\":32592},{\"end\":32617,\"start\":32607},{\"end\":32626,\"start\":32617},{\"end\":32635,\"start\":32626},{\"end\":32647,\"start\":32635},{\"end\":32658,\"start\":32647},{\"end\":32668,\"start\":32658},{\"end\":32677,\"start\":32668},{\"end\":32997,\"start\":32991},{\"end\":33004,\"start\":32997},{\"end\":33010,\"start\":33004},{\"end\":33021,\"start\":33010},{\"end\":33444,\"start\":33436},{\"end\":33453,\"start\":33444},{\"end\":33718,\"start\":33709},{\"end\":33728,\"start\":33718},{\"end\":33943,\"start\":33932},{\"end\":34096,\"start\":34084},{\"end\":34109,\"start\":34096},{\"end\":34427,\"start\":34414},{\"end\":34672,\"start\":34666},{\"end\":34679,\"start\":34672},{\"end\":34690,\"start\":34679},{\"end\":34970,\"start\":34959},{\"end\":34984,\"start\":34970},{\"end\":34993,\"start\":34984},{\"end\":35322,\"start\":35310},{\"end\":35331,\"start\":35322},{\"end\":35339,\"start\":35331},{\"end\":35351,\"start\":35339},{\"end\":35682,\"start\":35672},{\"end\":35695,\"start\":35682},{\"end\":36017,\"start\":36004},{\"end\":36275,\"start\":36263},{\"end\":36281,\"start\":36275},{\"end\":36471,\"start\":36465},{\"end\":36480,\"start\":36471},{\"end\":36488,\"start\":36480},{\"end\":36496,\"start\":36488},{\"end\":36505,\"start\":36496}]", "bib_venue": "[{\"end\":28388,\"start\":28377},{\"end\":28599,\"start\":28558},{\"end\":28904,\"start\":28893},{\"end\":29287,\"start\":29233},{\"end\":29647,\"start\":29568},{\"end\":30051,\"start\":29990},{\"end\":30296,\"start\":30247},{\"end\":30688,\"start\":30628},{\"end\":31078,\"start\":31066},{\"end\":31439,\"start\":31386},{\"end\":31699,\"start\":31621},{\"end\":32247,\"start\":32203},{\"end\":32569,\"start\":32528},{\"end\":33098,\"start\":33021},{\"end\":33498,\"start\":33453},{\"end\":33752,\"start\":33728},{\"end\":33930,\"start\":33888},{\"end\":34158,\"start\":34109},{\"end\":34412,\"start\":34334},{\"end\":34664,\"start\":34595},{\"end\":34957,\"start\":34866},{\"end\":35396,\"start\":35351},{\"end\":35616,\"start\":35612},{\"end\":35745,\"start\":35695},{\"end\":36058,\"start\":36017},{\"end\":36261,\"start\":36219},{\"end\":36463,\"start\":36419},{\"end\":29293,\"start\":29289},{\"end\":33162,\"start\":33100}]"}}}, "year": 2023, "month": 12, "day": 17}