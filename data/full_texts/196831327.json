{"id": 196831327, "updated": "2023-11-08 08:07:44.022", "metadata": {"title": "Natural Adversarial Examples", "authors": "[{\"first\":\"Dan\",\"last\":\"Hendrycks\",\"middle\":[]},{\"first\":\"Kevin\",\"last\":\"Zhao\",\"middle\":[]},{\"first\":\"Steven\",\"last\":\"Basart\",\"middle\":[]},{\"first\":\"Jacob\",\"last\":\"Steinhardt\",\"middle\":[]},{\"first\":\"Dawn\",\"last\":\"Song\",\"middle\":[]}]", "venue": "2021 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)", "journal": "arXiv: Learning", "publication_date": {"year": 2019, "month": 7, "day": 16}, "abstract": "We introduce natural adversarial examples -- real-world, unmodified, and naturally occurring examples that cause classifier accuracy to significantly degrade. We curate 7,500 natural adversarial examples and release them in an ImageNet classifier test set that we call ImageNet-A. This dataset serves as a new way to measure classifier robustness. Like l_p adversarial examples, ImageNet-A examples successfully transfer to unseen or black-box classifiers. For example, on ImageNet-A a DenseNet-121 obtains around 2% accuracy, an accuracy drop of approximately 90%. Recovering this accuracy is not simple because ImageNet-A examples exploit deep flaws in current classifiers including their over-reliance on color, texture, and background cues. We observe that popular training techniques for improving robustness have little effect, but we show that some architectural changes can enhance robustness to natural adversarial examples. Future research is required to enable robust generalization to this hard ImageNet test set.", "fields_of_study": "[\"Computer Science\",\"Mathematics\"]", "external_ids": {"arxiv": "1907.07174", "mag": "2961301154", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/cvpr/HendrycksZBSS21", "doi": "10.1109/cvpr46437.2021.01501"}}, "content": {"source": {"pdf_hash": "6b7c6942bed1e01310cb6c784c02b7543836d738", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/1907.07174v2.pdf\"]", "oa_url_match": true, "oa_info": {"license": null, "open_access_url": "http://arxiv.org/pdf/1907.07174", "status": "GREEN"}}, "grobid": {"id": "3d94784b93b450ab50042ca4cbb8032376e9f19d", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/6b7c6942bed1e01310cb6c784c02b7543836d738.txt", "contents": "\nNatural Adversarial Examples\n\n\nDan Hendrycks hendrycks@berkeley.edu \nUC Berkeley\nUniversity of Washington\nUniversity of Chicago\nBerkeley, Berkeley\n\nKevin Zhao kwzhao@cs.washington.edu \nUC Berkeley\nUniversity of Washington\nUniversity of Chicago\nBerkeley, Berkeley\n\nSteven Basart steven@ttic.edu \nUC Berkeley\nUniversity of Washington\nUniversity of Chicago\nBerkeley, Berkeley\n\nJacob Steinhardt jsteinhardt@berkeley.edu \nUC Berkeley\nUniversity of Washington\nUniversity of Chicago\nBerkeley, Berkeley\n\nDawn Song dawnsong@berkeley.edu \nUC Berkeley\nUniversity of Washington\nUniversity of Chicago\nBerkeley, Berkeley\n\nNatural Adversarial Examples\n\nWe introduce natural adversarial examples -real-world, unmodified, and naturally occurring examples that cause classifier accuracy to significantly degrade. We curate 7,500 natural adversarial examples and release them in an ImageNet classifier test set that we call IMAGENET-A. This dataset serves as a new way to measure classifier robustness. Like p adversarial examples, IMAGENET-A examples successfully transfer to unseen or black-box classifiers. For example, on IMAGENET-A a DenseNet-121 obtains around 2% accuracy, an accuracy drop of approximately 90%. Recovering this accuracy is not simple because IMAGENET-A examples exploit deep flaws in current classifiers including their over-reliance on color, texture, and background cues. We observe that popular training techniques for improving robustness have little effect, but we show that some architectural changes can enhance robustness to natural adversarial examples. Future research is required to enable robust generalization to this hard ImageNet test set. * Equal Contribution.\n\nIntroduction\n\nResearch on the ImageNet benchmark has led to numerous advances in classification [30], object detection [27], segmentation [19], and perceptual metrics [47]. ImageNet classification improvements have are broadly applicable and are highly predictive of improvements on other tasks [29]. Unfortunately, ImageNet classification accuracy has plateaued, so much that the final ImageNet Challenge competition was in 2017. While this suggests image classification is nearly complete, Recht et al. [37] remind us that ImageNet test examples tend to be relatively simple close-up images, so that the current test set may be too easy and not represent harder images encountered in the real world.\n\nReal-world images may also be constructed or chosen adversarially. Goodfellow et al. [15] define adversarial examples [40] as \"inputs to machine learning models that an attacker has intentionally designed to cause the model to make a mistake.\" Adversarial examples enable measuring worstcase model performance. This we aim to measure under the constraint that examples are naturally occurring. Most adversarial examples research centers around artificial p adversarial examples, which are examples perturbed by nearly worst-case distortions that are small in an p sense. Aside from the known difficulties in evaluating p robustness [7,8], Gilmer et al. [14] point out that p adversarial examples assume an unrealistic threat model because attackers are often free to choose any desired input. Consequently, if an attacker aims to subvert black-box classifier accuracy, they could mimic known errors [14]. We find that model errors on natural adversarial examples are highly consistent. Attackers can reliably and easily create black-box attacks by exploiting these consistent natural model errors, and thus carefully computing gradient perturbations to create an attack is unnecessary. This less restricted threat model has been discussed but not explored thoroughly until now.\n\nWe adversarially curate a hard ImageNet classifier test set which we call IMAGENET-A. These images are natural, unmodified, real-world examples collected from online and are selected to cause a \"model to make a mistake,\" as with synthetic adversarial examples. IMAGENET-A examples cause  Figure 1. In Section 4 we show that IMAGENET-A images successfully transfer to break many unseen or black-box models. As with other black-box adversarial examples, natural adversarial examples are selected to break a fixed model, in this case ResNet-50, but to black-box models they transfer reliably. For example, these images undermine models such as ResNeXt-50 [45] and DenseNet-121 [26], both of which have an IMAGENET-A accuracy rate of less than 3%.\n\nWe examine ways to improve robustness on IMAGENET-A. Numerous techniques have been proposed to improve classifier robustness. Two of these, Stylized ImageNet data augmentation [13] and \u221e adversarial example training on an ImageNet scale [28], hardly increase robustness to natural adversarial examples. However, much greater robustness gains follow from architectural modifications such as self-attention and increasing model size. These results suggest architecture design research as a promising avenue for improving robustness. Code and the IMAGENET-A dataset are available at https://github.com/hendrycks/natural-adv-examples.\n\n\nRelated Work\n\nAdversarial Examples. Adversarial examples are a means to estimate worst-case model performance. While we aim to estimate the worst-case accuracy in natural settings, most use p adversarial attacks. Several other forms of adversarial attacks have been considered in the literature, including elastic deformations [43], adversarial coloring [3,23], and synthesis via generative models [2,39] and evolutionary search [35], among others. Other work has shown how to print 2D [32,5] or 3D [38,1] objects that fool classifiers. For all that, these existing adversarial attacks are all based on synthesized images or objects, and some have questioned whether they provide a reliable window into real-world robustness [14]. Our examples are closer in spirit to the recent thought experiment of an adversarial photographer discussed in Brown et al. [6], and by definition occur in the real world.\n\nRobustness to Train-Test Mismatch. Recht et al. [37] create a new ImageNet test set resembling the original test set as closely as possible. They determined that matching the difficulty of the original ImageNet test set required selecting images deemed the easiest and most obvious by the Mechanical Turkers. IMAGENET-A helps measure generalization to images of harder scenarios, not just the easiest examples. Brendel and Bethge [4] show that classifiers which do not know the spatial ordering of image regions can be competitive on the ImageNet test set, possibly due to the dataset's lack of difficulty. Next, note that judging classifiers by their performance on easy examples has potentially masked many of their shortcomings. For example, Geirhos et al. [13] artificially overwrite each ImageNet image's textures and conclude that classifiers learn to rely on textural cues and under-utilize information about object shape. Recent work proposes a benchmark for evaluating robustness to non-adversarial corruptions called ImageNet-C [20]. They corrupt images with 75 different algorithmically generated corruptions, while in this work we measure robustness to less palpable distribution shift with adversarial data. Our sources of distribution shift also tend to be more realistic, heterogeneous, and varied. Obtaining robustness to varied forms of distribution shift is difficult. For example, [41,12] train on various distortions and show that networks tend to memorize distortions and thereby fail to generalize to new and unseen distortions. Hence, robustly generalizing to unseen long-tail complications in IMAGENET-A, such as translucent shrink wrap that envelopes a toaster, could also be difficult.\n\n\nIMAGENET-A\n\n\nDesign\n\nIMAGENET-A is a dataset of natural adversarial examples, or real-world examples which fool current classifiers. To find natural adversarial examples, we first download numerous images related to an ImageNet class. Thereafter we delete the images that ResNet-50 [18] classifiers correctly classify. With the remaining incorrectly classified examples, we manually select a subset of high-quality images. This process is explicated below.\n\nClass Restrictions. Before adversarially curating data to create IMAGENET-A, we select a 200class subset of ImageNet-1K's 1,000 classes so that errors among these 200 classes would be considered egregious [10]. For instance, wrongly classifying Norwich terriers as Norfolk terriers does less to demonstrate faults in current classifiers than mistaking a Persian cat for a candle. In selecting IMAGENET-A's 200 classes, we adhere to several other design considerations. We avoid rare classes such as \"snow leopard,\" classes which have changed much since 2012 such as \"iPod,\" coarse and abstract ImageNet classes such as \"spiral,\" classes which are often image backdrops such as \"valley,\" and finally classes which tend to overlap such as \"honeycomb,\" \"bee,\" \"bee house,\" and \"bee eater\"; \"eraser,\" \"pencil sharpener\" and \"pencil case\"; \"sink,\" \"medicine cabinet,\" \"pill bottle\" and \"band-aid\"; and so on. The 200 IMAGENET-A classes cover most broad categories spanned by ImageNet-1K. The full class list is in Appendix A.\n\nData Aggregation and Adversarial Selection. Curating a large set of natural adversarial examples requires combing through an even larger set of images. Fortunately, the website iNaturalist has millions of user-labeled images of animals, and Flickr has even more user-tagged images of objects. We download a bevy of images related to each of the 200 ImageNet classes by leveraging userprovided labels and tags. This user-provided information enables us to avoid collecting images based on a search engine's convolutional neural network image ranking algorithms, which would prevent us from finding blindspots in convolutional neural networks. After exporting or scraping data from sites including iNaturalist and Flickr, we adversarially select the images.\n\nWe now describe our adversarial selection process. At a high level, this process has parallels to [39]. They use generative models to create adversarial examples that fool target classifier, and remove examples which fail to fool said target classifier. Rather than sampling synthetic images from the range of a generative model, we sample natural images from the real world. We remove examples which fail to fool our target classifiers, which are based on the commonplace and competitive ResNet-50 architecture. Of the remaining images, we select low-confidence images and ensure each image is valid through human review. This procedure also has similarities to hard-example mining, much like how p adversarial perturbations are hard perturbations selected from an p ball.\n\nMore specifically, we use two ResNet-50s for filtering, one pre-trained on ImageNet-1K and finetuned on the 200 class subset, and one pre-trained on ImageNet-1K where 200 of its 1,000 logits are used in classification. Both classifiers have similar accuracy on the 200 clean test set classes from ImageNet-1K, but we choose two models in order to have a small ensemble. The ResNet-50s perform 10-crop classification of each image, and should any crop be classified correctly by the ResNet-50s, the image is removed. If either ResNet-50 assigns an image greater than 15% confidence in the   correct class, the image is also removed; this is so done because we want natural adversarial examples which yield misclassifications with low confidence in the correct class, like in untargeted adversarial attacks. Now, some classification confusions are greatly over-represented, such as Persian cat and lynx. We would like IMAGENET-A to have great variability in its types of errors and cause classifiers to have a dense confusion matrix. Consequently, we perform a second round of filtering to create a shortlist where each confusion only appears at most 15 times. Finally, we manually select images from this shortlist in order to ensure IMAGENET-A images are simultaneously valid, single-class, and high-quality.\n\nWe concretely describe the process for the dragonfly class. We download 81,413 dragonfly images from iNaturalist, and after performing a basic filter we have 8,925 dragonfly images. In the algorithmically suggested shortlist, 1,452 images remain. From this shortlist, 80 dragonfly images are manually selected, but hundreds more could be chosen. The exact number of natural adversarial examples varies by class. In all, the IMAGENET-A dataset has 7,500 natural adversarial examples.\n\n\nClassifier Failure Modes on IMAGENET-A\n\nThe natural adversarial examples in IMAGENET-A demonstrate numerous failure modes of modern convolutional neural networks. For example, Figure 2 shows that classifiers may predict a class even when the image does not contain the subparts necessary to identify the predicted class. In the leftmost image, the candle is predicted as a jack-o'-lantern with 99.94% confidence, despite the absence of a pumpkin or carved faces. A separate way to measure how well a network learns shape is to test generalization on paintings, cartoons, sketches [42], sculptures, toys, origami, embroidery, and so on, but we avoid such examples and only keep natural images during adversarial filtration. While computer vision models such as the deformable parts model [11] more explicitly represented part configurations, current convolutional neural networks may produce confident predictions without necessary shape evidence.\n\nNetworks may also rely too heavily on texture and color cues (Figure 3), for instance misclassifying a dragonfly as a banana presumably due to a nearby yellow shovel. Since classifiers are taught to associate entire images with an object class, frequently appearing background elements may also become associated with a class, such as hummingbird feeders with hummingbirds or wood with nails ( Figure 4). Other examples include leaf-covered tree branches being associated with the white-headed capuchin monkey class, snow being associated with shovels, and dumpsters with garbage trucks.\n\nA small but sizeable share of IMAGENET-A examples are naturally distorted. That these examples cause our ResNet-50 filters to misclassify is in keeping with previous observations [20,12] that classifiers often fail to generalize to distorted images. These distorted images highlight one way in which the IMAGENET-A dataset is harder than the usual ImageNet test set, so methods which only decorrelate predictions from ResNet-50 are not sufficient to solve IMAGENET-A.\n\nClassifiers also demonstrate fickleness to small scene variations. Figure 6 shows an American alligator swimming. With different frames of the alligator swimming, the classifier prediction varies erratically between classes that are semantically loose and separate. For other images of the swimming alligator, classifiers predict that the alligator is a cliff, lynx, and fox squirrel.\n\nLast, we find that classifiers also overgeneralize [21,22,33], either over-extrapolating a pattern within a class (shadow \u2192 sundial), or incorrectly including nearby categories (car \u2192 limousine). In addition to Figure 7's examples, we find that the classifiers overgeneralize tricycles to bicycles and circles, digital clocks are overgeneralized to keyboards and calculators, and so on. In all, current convolutional networks have pervasive and diverse failure modes that can now be estimated with IMAGENET-A. Figure 5: Classifiers easily succumb to image distortions. Frame overlay, defocus, flora occlusion, and fog distortions make IMAGENET-A more varied and realistic than ImageNet-C and harder than ImageNet-1K's test set.  The Effect of Stylized Data on ImageNet-A Accuracy Figure 9: Training a ResNeXt-50 on Stylized ImageNet (SIN) and both ImageNet and SIN together slightly changes robustness.\n\n\nExperiments\n\n\nContrasting IMAGENET-A Examples to Corrupted and Adversarial \u221e Examples\n\nMuch of the force of the research community has been channeled toward endowing networks with robust representations. We examine the best-in-class robust training techniques. Unfortunately, we find that on natural adversarial examples, these techniques hardly help.\n\n\u221e Adversarial Training. We investigate how much robustness \u221e adversarial training confers. Adversarially training the parameters \u03b8 with loss function L on dataset D involves the objective\nmin \u03b8 E (x,y)\u223cD max x \u2208S L(x , y; \u03b8) where S = {x : x \u2212 x \u221e < \u03b5}.\nSuch \u221e adversarial examples are found through an iterative procedure similar to projected gradient ascent [34],\nx t+1 = \u03a0 x+S x t + \u03b1 sign(\u2207 x L(x, y; \u03b8))\nwhere x 0 is x with random uniform noise U[\u2212\u03b5, \u03b5] added to each pixel.\n\nWe try three different adversarial training schemes with adversaries of different strengths. We train a ResNeXt-50 (32\u00d74d) [45] from scratch on the 200 ImageNet-1K classes appearing in IMAGENET-A. This network trains for 90 epochs. The first five epochs follow a linear warmup learning rate schedule [16], and the learning rate drops by a factor of 0.1 at epochs 30, 60, and 80. We use a batch size of 256, a maximum learning rate of 0.1, a momentum parameter of 0.9, and a weight decay strength of 10 \u22124 . We use standard random horizontal flipping and cropping where each image is of size 224 \u00d7 224 \u00d7 3.\n\nObserve in Figure 8 that augmenting the training data with random uniform noise changes robustness.\n\nAdding noise from a 1-step FGSM adversary slightly increases robustness further. A stronger 10-step \u221e adversary imparts slightly greater IMAGENET-A robustness. However, the model trained on clean data has 89.22% accuracy on the 200 class subset of ImageNet-1K's test set, while uniform noise data augmentation corresponds to an accuracy of 88.93%, FGSM to 83.95%, and PGD to 81.88%. Thus \u221e adversarial training's miniscule robustness gains are hardly worth the cost.\n\nStylized ImageNet Augmentation. In Figure 3, we observe that classifiers may rely too heavily on color and textural features. Geirhos et al. [13] propose making networks rely less on texture by training classifiers on images where textures are transferred from art pieces. They accomplish this by applying style transfer to ImageNet training images to create a dataset they call Stylized ImageNet or SIN for short. We test whether training with SIN images can improve IMAGENET-A robustness.\n\nReducing a ResNeXt-50's texture bias by training with SIN images does little to help IMAGENET-A robustness. For reference, the ResNeXt-50 trained on ImageNet images obtains 89.22% top-1 accuracy on the 200 class subset of ImageNet-1K's test set. If we train a ResNeXt-50 entirely on Stylized ImageNet images, the top-1 accuracy on ImageNet-1K's 200 class test set set is a meager 65.87%. Accuracy increases from 1.31% to 2.09% by switching from normal ImageNet training to adding Stylized ImageNet data augmentation. Notice that the accuracies are still small. This is a consequence of natural adversarial examples successfully transferring to unseen models and architectures. As shown in Figure 9, data augmentation with Stylized ImageNet results in minor IMAGENET-A accuracy changes.  \n\n\nEnhancing Robustness and Uncertainty Estimation on IMAGENET-\nE C [(P(Y = Y |C = c) \u2212 c) 2 ]\n, or the squared discrepancy between the classifier's accuracy at a confidence level and the confidence level. We estimate the RMS Calibration Error using adaptive binning [36,22,17]. Here we take the confidence to be the maximum softmax probability [21].\n\nOur second uncertainty estimation metric is the Area Under the Response Rate Accuracy Curve (AURRA). In a multitude of scenarios, responding only when confident is preferable to predicting falsely. In these experiments, we allow classifiers to respond to a subset of the test set and abstain from predicting the rest. Classifiers with quality uncertainty estimates should be capable identifying examples it is likely to predict falsely and abstain. If a classifier is required to abstain from predicting on 90% of the test set, or equivalently respond to the remaining 10% of the test set, then we should like the classifier's uncertainty estimates to separate correctly and falsely classified examples and have high accuracy on the selected 10%. At a fixed response rate, we should like the accuracy to be as high as possible. At a 100% response rate, the classifier accuracy is the usual test set accuracy. We vary the response rates and compute the corresponding accuracies to obtain the Response Rate Accuracy (RRA) curve. The area under the Response Rate Accuracy curve is the AURRA. To compute the AURRA in this paper, we use the maximum softmax probability to determine which examples receive a response. If the response rate is 10%, we select the top 10% of examples with the highest confidence and compute the accuracy on these examples. An example RRA curve is in Figure 12. Size and Self-Attention. Simply increasing the width and number of layers of a network is sufficient to automatically impart more robustness, calibration, and error detection quality on natural adversarial examples. Increasing network capacity has been shown to improve robustness to p adversarial examples [31], common corruptions [20], and now also IMAGENET-A as demonstrated in Figure 10. Networks are trained on ImageNet-1K without special training techniques.\n\nConvolutional neural networks with self-attention [25] are designed to better capture long-range dependencies and interactions across an image. Self-attention helps GANs learn how to generate images with plausible shape [46], and in classification, self-attention is utilized in state-of-the-art ImageNet-1K models. We consider the self-attention technique called Squeeze-and-Excitation (SE) [24], which won the final ImageNet competition. While integrating Squeeze-and-Excitation into a ResNeXt-101 (32\u00d74d) improves top-1 accuracy on the 200 class subset of ImageNet-1K by less than 1%, SE improves IMAGENET-A accuracy by approximately 10%. An implication is that judging models with ImageNet-1K's now simple test set can obscure a technique's true benefits. Moreover, this form of self-attention greatly improves model calibration and error detection on IMAGENET-A. Full results are shown in Figures 11 and 12. We also found that self-attention improves robustness to common corruptions; a ResNet-50's mean corruption error (mCE) is 76.7% and an SE-ResNet-50 has a 68.2% mCE. Architectural modifications that improve ImageNet-C and ImageNet-1K accuracies can help tremendously on IMAGENET-A.\n\n\nConclusion\n\nIn this paper, we introduced the first expansive dataset of natural adversarial examples. This dataset is challenging for both the computer vision and adversarial example research communities. That is because these naturally occurring images expose common blindspots of current convolutional networks, and closing the gap between ImageNet-1K's test set and IMAGENET-A will require addressing long-standing but under-explored failure modes of current models such as texture over-reliance, overgeneralization, corruption robustness, and more. We found that these failure modes are only slightly less pronounced when models train with stylized ImageNet data augmentation or with adversarial training, while the most improvements in robustness came from modifying the classifier architecture itself. Even with both model scale and self-attention, classifier accuracies are still below that of adversarially trained classifiers on typical \u221e adversarial examples [44], so that natural adversarial examples are in some sense currently more challenging. In this work, we identified several methods that increase natural adversarial example robustness, demonstrated that models have similar blindspots and make correlated errors, and created a hard new ImageNet test set to measure model robustness-an important research aim as computer vision systems are deployed in increasingly precarious environments.\n\n\nAcknowledgments\n\nWe should like to thank Ludwig Schmidt for his extensive and continued suggestions throughout this paper's development, and especially for his initial suggestion to collect naturally instances of common corruptions. We should also like to thank Adam Dziedzic and Saurav Kadavath for their help. This material is in part based upon work supported by the National Science Foundation Frontier Grant. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the author(s) and do not necessarily reflect the views of the National Science Foundation.\n\nFigure 1 :\n1Natural adversarial examples from IMAGENET-A. The red text is a ResNet-50 prediction with its confidence, and the black text is the actual class. Many natural adversarial examples are incorrectly classified with high confidence, despite having no adversarial modifications as they are examples which naturally occur in the physical world. mistakes due to occlusion, weather, and other complications encountered in the long tail of scene configurations, or by exploiting consistent classifier blind spots. Some examples are depicted in\n\nFigure 2 :\n2IMAGENET-A examples demonstrating that classifiers may predict a class even without a plausible shape in the image to support its prediction. The red text is a ResNet-50 prediction, and the black text is the actual class.\n\nFigure 3 :\n3Classifiers frequently rely on color and textural features to a fault, as demonstrated with these dragonfly images.\n\nFigure 4 :\n4Classifiers may use erroneous background cues for prediction. Pictures of nails tend to co-occur with a wood background. Likewise, hummingbird feeders tend to appear in images with hummingbirds but are themselves not hummingbirds.\n\nFigure 6 :\n6Often classifier predictions are erratic and unstable, so that small changes to the scene can cause wildly different predictions.\n\nFigure 7 :Figure 8 :\n78Classifiers overgeneralize. An image with thick vertical and horizontal bars is often predicted to be a rocking chair. Numerous thin lines tend to cause Harvestman spider predictions. Cars and vans are often predicted as limousines, as there is no car nor van class in IMAGENET-A. Shadows with the ground in view often results in sundial predictions. Adversarially training against uniform noise, 1-step (FGSM) and 10-step (PGD) \u221e adversaries slightly changes robustness to natural adversarial examples.\n\nFigure 10 :Figure 11 :\n1011Increasing the capacity of ResNets, DualPathNetworks [9], and ResNeXts improve natural adversarial examples robustness, calibration, and error detection. We show the performance of a ResNet-101, ResNet-152, DPN-68, DPN-98, ResNeXt-101 (32\u00d74d), and ResNeXt-101 (64\u00d74d). Applying self-attention in the form of Squeeze-and-Excitation (SE) can significantly improve natural adversarial examples robustness, calibration, and error detection. This architectural addition proves far more effective than training against stylized images or \u221e adversarial examples.\n\nFigure 12 :\n12The Response Rate Accuracy curve for a ResNeXt-101 (32\u00d74d) with and without Squeeze-and-Excitation (SE). The Response Rate is the percent classified. The accuracy at a n% response rate is the accuracy on the n% of examples where the classifier is most confident.\n\nSynthesizing robust adversarial examples. Anish Athalye, arXiv:1707.07397arXiv preprintAnish Athalye et al. \"Synthesizing robust adversarial examples\". In: arXiv preprint arXiv:1707.07397 (2017).\n\nAdversarial Transformation Networks: Learning to Generate Adversarial Examples. Shumeet Baluja, Ian Fischer, CoRR abs/1703.09387Shumeet Baluja and Ian Fischer. \"Adversarial Transformation Networks: Learning to Generate Adversarial Examples\". In: CoRR abs/1703.09387 (2017).\n\nBig but Imperceptible Adversarial Perturbations via Semantic Manipulation. Anand Bhattad, CoRR abs/1904.06347Anand Bhattad et al. \"Big but Imperceptible Adversarial Perturbations via Semantic Manipula- tion\". In: CoRR abs/1904.06347 (2019).\n\nApproximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet. Wieland Brendel, Matthias Bethge, CoRR abs/1904.00760Wieland Brendel and Matthias Bethge. \"Approximating CNNs with Bag-of-local-Features models works surprisingly well on ImageNet\". In: CoRR abs/1904.00760 (2018).\n\nAdversarial patch. Tom B Brown, arXiv:1712.09665arXiv preprintTom B Brown et al. \"Adversarial patch\". In: arXiv preprint arXiv:1712.09665 (2017).\n\nUnrestricted Adversarial Examples. Tom B Brown, CoRR abs/1809.08352Tom B. Brown et al. \"Unrestricted Adversarial Examples\". In: CoRR abs/1809.08352 (2018).\n\nAdversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods. Nicholas Carlini, David Wagner, Nicholas Carlini and David Wagner. Adversarial Examples Are Not Easily Detected: Bypassing Ten Detection Methods. 2017.\n\nOn Evaluating Adversarial Robustness. Nicholas Carlini, In: arXiv pre-printNicholas Carlini et al. \"On Evaluating Adversarial Robustness\". In: arXiv pre-print (2019).\n\nDual Path Networks. Yunpeng Chen, Yunpeng Chen et al. \"Dual Path Networks\". In: NIPS. 2017.\n\nImageNet: A Large-Scale Hierarchical Image Database. Jia Deng, CVPRJia Deng et al. \"ImageNet: A Large-Scale Hierarchical Image Database\". In: CVPR (2009).\n\nObject Detection with Discriminatively Trained Part-Based Models. Pedro Felzenszwalb, PAMIPedro Felzenszwalb et al. \"Object Detection with Discriminatively Trained Part-Based Models\". In: PAMI (2010).\n\nGeneralisation in humans and deep neural networks\". Robert Geirhos, In: NeurIPS. Robert Geirhos et al. \"Generalisation in humans and deep neural networks\". In: NeurIPS (2018).\n\nImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness. Robert Geirhos, ICLRRobert Geirhos et al. \"ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness\". In: ICLR (2019).\n\nMotivating the Rules of the Game for Adversarial Example Research. Justin Gilmer, CoRR abs/1807.06732Justin Gilmer et al. \"Motivating the Rules of the Game for Adversarial Example Research\". In: CoRR abs/1807.06732 (2018).\n\nAttacking Machine Learning with Adversarial Examples. Ian Goodfellow, OpenAI Blog. Ian Goodfellow et al. \"Attacking Machine Learning with Adversarial Examples\". In: OpenAI Blog (2017).\n\nAccurate, Large Minibatch SGD: Training ImageNet in 1 Hour. Priya Goyal, CoRR abs/1706.02677Priya Goyal et al. \"Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour\". In: CoRR abs/1706.02677 (2017).\n\nOn Calibration of Modern Neural Networks. Chuan Guo, International Conference on Machine Learning. Chuan Guo et al. \"On Calibration of Modern Neural Networks\". In: International Conference on Machine Learning (2017).\n\nDeep Residual Learning for Image Recognition. Kaiming He, CVPRKaiming He et al. \"Deep Residual Learning for Image Recognition\". In: CVPR (2015).\n\n. Kaiming He, Mask R-CNN\". In: CVPR. Kaiming He et al. \"Mask R-CNN\". In: CVPR. 2018.\n\nBenchmarking Neural Network Robustness to Common Corruptions and Perturbations. Dan Hendrycks, Thomas Dietterich, ICLRDan Hendrycks and Thomas Dietterich. \"Benchmarking Neural Network Robustness to Com- mon Corruptions and Perturbations\". In: ICLR (2019).\n\nA Baseline for Detecting Misclassified and Out-of-Distribution Examples in Neural Networks. Dan Hendrycks, Kevin Gimpel, Dan Hendrycks and Kevin Gimpel. \"A Baseline for Detecting Misclassified and Out-of- Distribution Examples in Neural Networks\". In: ICLR (2017).\n\nDeep Anomaly Detection with Outlier Exposure. Dan Hendrycks, Mantas Mazeika, Thomas Dietterich, ICLRDan Hendrycks, Mantas Mazeika, and Thomas Dietterich. \"Deep Anomaly Detection with Outlier Exposure\". In: ICLR (2019).\n\nSemantic Adversarial Examples. Hossein Hosseini, Radha Poovendran, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW). Hossein Hosseini and Radha Poovendran. \"Semantic Adversarial Examples\". In: 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW) (2018), pp. 1695-16955.\n\nSqueeze-and-Excitation Networks. Jie Hu, Li Shen, Gang Sun, 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition. Jie Hu, Li Shen, and Gang Sun. \"Squeeze-and-Excitation Networks\". In: 2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition (2018).\n\nGather-Excite : Exploiting Feature Context in Convolutional Neural Networks. Jie Hu, NeurIPSJie Hu et al. \"Gather-Excite : Exploiting Feature Context in Convolutional Neural Networks\". In: NeurIPS. 2018.\n\nDensely connected convolutional networks. Gao Huang, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionGao Huang et al. \"Densely connected convolutional networks\". In: Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2017.\n\nSpeed/Accuracy Trade-Offs for Modern Convolutional Object Detectors. Jonathan Huang, 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR. Jonathan Huang et al. \"Speed/Accuracy Trade-Offs for Modern Convolutional Object De- tectors\". In: 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2017).\n\nTransfer of Adversarial Robustness Between Perturbation Types. Daniel Kang, CoRR abs/1905.01034Daniel Kang et al. \"Transfer of Adversarial Robustness Between Perturbation Types\". In: CoRR abs/1905.01034 (2019).\n\nDo Better ImageNet Models Transfer Better. Simon Kornblith, Jonathon Shlens, Quoc V Le, CoRR abs/1805.08974Simon Kornblith, Jonathon Shlens, and Quoc V. Le. \"Do Better ImageNet Models Transfer Better?\" In: CoRR abs/1805.08974 (2018).\n\nImageNet Classification with Deep Convolutional Neural Networks. Alex Krizhevsky, Ilya Sutskever, Geoffrey E Hinton, NIPSAlex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. \"ImageNet Classification with Deep Convolutional Neural Networks\". In: NIPS (2012).\n\nAdversarial Machine Learning at Scale\". Alexey Kurakin, Ian Goodfellow, Samy Bengio, ICLRAlexey Kurakin, Ian Goodfellow, and Samy Bengio. \"Adversarial Machine Learning at Scale\". In: ICLR (2017).\n\nAdversarial examples in the physical world. Alexey Kurakin, Ian J Goodfellow, Samy Bengio, CoRR abs/1607.02533Alexey Kurakin, Ian J. Goodfellow, and Samy Bengio. \"Adversarial examples in the physical world\". In: CoRR abs/1607.02533 (2017).\n\nTraining Confidence-calibrated Classifiers for Detecting Out-of-Distribution Samples. Kimin Lee, ICLRKimin Lee et al. \"Training Confidence-calibrated Classifiers for Detecting Out-of-Distribution Samples\". In: ICLR (2018).\n\nTowards Deep Learning Models Resistant to Adversarial Attacks. Aleksander Madry, ICLRAleksander Madry et al. \"Towards Deep Learning Models Resistant to Adversarial Attacks\". In: ICLR (2018).\n\nDeep neural networks are easily fooled: High confidence predictions for unrecognizable images. Anh Mai Nguyen, Jason Yosinski, Jeff Clune, 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR. Anh Mai Nguyen, Jason Yosinski, and Jeff Clune. \"Deep neural networks are easily fooled: High confidence predictions for unrecognizable images\". In: 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (2015), pp. 427-436.\n\nPosterior calibration and exploratory analysis for natural language processing models. Khanh Nguyen, O&apos; Brendan, Connor, EMNLP. Khanh Nguyen and Brendan O'Connor. \"Posterior calibration and exploratory analysis for natural language processing models\". In: EMNLP (2015).\n\nDo ImageNet Classifiers Generalize to ImageNet. Benjamin Recht, ArXiv abs/1902.10811Benjamin Recht et al. \"Do ImageNet Classifiers Generalize to ImageNet?\" In: ArXiv abs/1902.10811 (2019).\n\nAccessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition. Mahmood Sharif, Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security. the 2016 ACM SIGSAC Conference on Computer and Communications SecurityACMMahmood Sharif et al. \"Accessorize to a crime: Real and stealthy attacks on state-of-the-art face recognition\". In: Proceedings of the 2016 ACM SIGSAC Conference on Computer and Communications Security. ACM. 2016, pp. 1528-1540.\n\nConstructing Unrestricted Adversarial Examples with Generative Models. Yang Song, NeurIPSYang Song et al. \"Constructing Unrestricted Adversarial Examples with Generative Models\". In: NeurIPS. 2018.\n\nIntriguing properties of neural networks. Christian Szegedy, Christian Szegedy et al. Intriguing properties of neural networks. 2014.\n\nExamining the Impact of Blur on Recognition by Convolutional Networks. Igor Vasiljevic, Ayan Chakrabarti, Gregory Shakhnarovich, Igor Vasiljevic, Ayan Chakrabarti, and Gregory Shakhnarovich. Examining the Impact of Blur on Recognition by Convolutional Networks. 2016.\n\nLearning Robust Global Representations by Penalizing Local Predictive Power. Haohan Wang, Haohan Wang et al. Learning Robust Global Representations by Penalizing Local Predictive Power. 2019.\n\nSpatially Transformed Adversarial Examples. Chaowei Xiao, CoRR abs/1801.02612Chaowei Xiao et al. \"Spatially Transformed Adversarial Examples\". In: CoRR abs/1801.02612 (2018).\n\nFeature denoising for improving adversarial robustness. Cihang Xie, arXiv:1812.03411arXiv preprintCihang Xie et al. \"Feature denoising for improving adversarial robustness\". In: arXiv preprint arXiv:1812.03411 (2018).\n\nAggregated Residual Transformations for Deep Neural Networks. Saining Xie, CVPRSaining Xie et al. \"Aggregated Residual Transformations for Deep Neural Networks\". In: CVPR (2016).\n\nSelf-Attention Generative Adversarial Networks. Han Zhang, CoRR abs/1805.08318Han Zhang et al. \"Self-Attention Generative Adversarial Networks\". In: CoRR abs/1805.08318 (2018).\n\nThe Unreasonable Effectiveness of Deep Features as a Perceptual Metric. Richard Zhang, CVPRRichard Zhang et al. \"The Unreasonable Effectiveness of Deep Features as a Perceptual Metric\". In: CVPR. 2018.\n\nUrsus americanus, Euarctos americanus;' 'mongoose;' 'ladybug, ladybeetle, lady beetle, ladybird, ladybird beetle;' 'rhinoceros beetle;' 'weevil;' 'fly;' 'bee;' 'ant, emmet, pismire;' 'grasshopper, hopper;' 'walking stick, walkingstick, stick insect;' 'cockroach, roach;' 'mantis, mantid;' 'leafhopper;' 'dragonfly, darning needle, devil's darning needle, sewing needle, snake feeder, snake doctor, mosquito hawk, skeeter hawk;' 'monarch, monarch butterfly, milkweed butterfly, Danaus plexippus;' 'cabbage butterfly;' 'lycaenid, lycaenid butterfly;' 'starfish, sea star;' 'wood rabbit, cottontail, cottontail rabbit;' 'porcupine, hedgehog;' 'fox squirrel, eastern fox squirrel, Sciurus niger;' 'marmot;' 'bison;' 'skunk, polecat, wood pussy;' 'armadillo;' 'baboon;' 'capuchin, ringtail, Cebus capucinus;' 'African elephant, Loxodonta africana;' 'puffer, pufferfish, blowfish, globefish;' 'academic gown, academic robe, judge's robe;' 'accordion, piano accordion, squeeze box;' 'acoustic guitar;' 'airliner;' 'ambulance;' 'apron;' 'balance beam, beam;' 'balloon;' 'banjo;' 'barn;' 'barrow, garden cart, lawn cart, wheelbarrow;' 'basketball;' 'beacon, lighthouse, beacon light, pharos;' 'beaker;' 'bikini, two-piece;' 'bow;' 'bow tie, bow-tie, bowtie;' 'breastplate, aegis, egis;' 'broom;' 'candle, taper, wax light;' 'canoe;' 'castle;' 'cello, violoncello;' 'chain;' 'chest;' 'Christmas stocking;' 'cowboy boot;' 'cradle;' 'dial telephone, dial phone. A Imagenet-A Classes ; Lorikeet;&apos; &apos;hummingbird;&apos; &apos;toucan;&apos; &apos;drake;&apos; &apos;goose;&apos; &apos;koala, Koala Bear, limo;' 'manhole cover;' 'maraca;' 'marimba, xylophone;' 'mask;' 'mitten;' 'mosque;' 'nail;' 'obelisk;' 'ocarina, sweet potato;' 'organ, pipe organ;' 'parachute, chute;' 'parking meter;' 'piggy bank, penny bank;' 'pool table, billiard table, snooker table;' 'puck, hockey puck;' 'quill, quill pen;' 'racket, racquet;' 'reel;' 'revolver, six-gun, six-shooter;' 'rocking chair, rocker;' 'rugby ball;' 'saltshaker, salt shaker;' 'sandal;' 'sax, saxophone;' 'school bus;' 'schooner;' 'sewing machine;' 'shovel;' 'sleeping bag;' 'snowmobile;' 'snowplow, snowplough;' 'soap dispenser;' 'spatula;' 'spider web, spider's web;' 'steam locomotive;' 'stethoscope. studio couch, day bed;' 'submarine, pigboat, sub, U-boat;' 'sundial;' 'suspension bridge;' 'syringe;' 'tank, army tank, armored combat vehicle, armoured combat vehicle;' 'teddy, teddy bear;' 'toaster;' 'torch;' 'tricycle, trike, velocipede;' 'umbrella;' 'unicycle, monocycle;' 'viaduct;' 'volleyball;' 'washer, automatic washer, washing machine;' 'water tower;' 'wine bottle;' 'wreck;' 'guacamole;' 'pretzel;' 'cheeseburger;' 'hotdog, hot dog, red hot;' 'broccoli;' 'cucumber, cuke;' 'bell pepper;' 'mushroom;' 'lemon;' 'banana;' 'custard apple;' 'pomegranate;' 'carbonara;' 'bubble;' 'cliff, drop, drop-off;' 'volcano;' 'ballplayer, baseball player;' 'rapeseed;' 'yellow lady's slipper, yellow lady-slipper, Cypripedium calceolus, Cypripedium parviflorum;' 'corn;' 'acorn.' Their WordNet IDs are as followsA IMAGENET-A Classes The 200 ImageNet classes that we selected for IMAGENET-A are as follows. 'Stingray;' 'goldfinch, Carduelis carduelis;' 'junco, snowbird;' 'robin, American robin, Turdus migra- torius;' 'jay;' 'bald eagle, American eagle, Haliaeetus leucocephalus;' 'vulture;' 'eft;' 'bullfrog, Rana catesbeiana;' 'box turtle, box tortoise;' 'common iguana, iguana, Iguana iguana;' 'agama;' 'African chameleon, Chamaeleo chamaeleon;' 'American alligator, Alligator mississipiensis;' 'garter snake, grass snake;' 'harvestman, daddy longlegs, Phalangium opilio;' 'scorpion;' 'tarantula;' 'centipede;' 'sulphur-crested cockatoo, Kakatoe galerita, Cacatua galerita;' 'lorikeet;' 'hummingbird;' 'toucan;' 'drake;' 'goose;' 'koala, koala bear, kangaroo bear, native bear, Phascolarctos cinereus;' 'jellyfish;' 'sea anemone, anemone;' 'flatworm, platyhelminth;' 'snail;' 'crayfish, crawfish, crawdad, crawdaddy;' 'hermit crab;' 'flamingo;' 'American egret, great white heron, Egretta albus;' 'oystercatcher, oyster catcher;' 'pelican;' 'sea lion;' 'Chihuahua;' 'golden retriever;' 'Rottweiler;' 'German shepherd, Ger- man shepherd dog, German police dog, alsatian;' 'pug, pug-dog;' 'red fox, Vulpes vulpes;' 'Persian cat;' 'lynx, catamount;' 'lion, king of beasts, Panthera leo;' 'American black bear, black bear, Ursus americanus, Euarctos americanus;' 'mongoose;' 'ladybug, ladybeetle, lady beetle, ladybird, ladybird beetle;' 'rhinoceros beetle;' 'weevil;' 'fly;' 'bee;' 'ant, emmet, pismire;' 'grasshopper, hopper;' 'walking stick, walkingstick, stick insect;' 'cockroach, roach;' 'mantis, mantid;' 'leafhopper;' 'drag- onfly, darning needle, devil's darning needle, sewing needle, snake feeder, snake doctor, mosquito hawk, skeeter hawk;' 'monarch, monarch butterfly, milkweed butterfly, Danaus plexippus;' 'cabbage butterfly;' 'lycaenid, lycaenid butterfly;' 'starfish, sea star;' 'wood rabbit, cottontail, cottontail rabbit;' 'porcupine, hedgehog;' 'fox squirrel, eastern fox squirrel, Sciurus niger;' 'marmot;' 'bison;' 'skunk, polecat, wood pussy;' 'armadillo;' 'baboon;' 'capuchin, ringtail, Cebus capucinus;' 'African elephant, Loxodonta africana;' 'puffer, pufferfish, blowfish, globefish;' 'academic gown, academic robe, judge's robe;' 'accordion, piano accordion, squeeze box;' 'acoustic guitar;' 'airliner;' 'ambulance;' 'apron;' 'balance beam, beam;' 'balloon;' 'banjo;' 'barn;' 'barrow, garden cart, lawn cart, wheelbarrow;' 'basketball;' 'beacon, lighthouse, beacon light, pharos;' 'beaker;' 'bikini, two-piece;' 'bow;' 'bow tie, bow-tie, bowtie;' 'breastplate, aegis, egis;' 'broom;' 'candle, taper, wax light;' 'canoe;' 'castle;' 'cello, violoncello;' 'chain;' 'chest;' 'Christmas stocking;' 'cowboy boot;' 'cradle;' 'dial telephone, dial phone;' 'digital clock;' 'doormat, welcome mat;' 'drumstick;' 'dumbbell;' 'envelope;' 'feather boa, boa;' 'flagpole, flagstaff;' 'forklift;' 'fountain;' 'garbage truck, dustcart;' 'goblet;' 'go-kart;' 'golfcart, golf cart;' 'grand piano, grand;' 'hand blower, blow dryer, blow drier, hair dryer, hair drier;' 'iron, smoothing iron;' 'jack-o'-lantern;' 'jeep, landrover;' 'kimono;' 'lighter, light, igniter, ignitor;' 'limousine, limo;' 'manhole cover;' 'maraca;' 'marimba, xylophone;' 'mask;' 'mitten;' 'mosque;' 'nail;' 'obelisk;' 'ocarina, sweet potato;' 'organ, pipe organ;' 'parachute, chute;' 'parking meter;' 'piggy bank, penny bank;' 'pool table, billiard table, snooker table;' 'puck, hockey puck;' 'quill, quill pen;' 'racket, racquet;' 'reel;' 'revolver, six-gun, six-shooter;' 'rocking chair, rocker;' 'rugby ball;' 'saltshaker, salt shaker;' 'sandal;' 'sax, saxophone;' 'school bus;' 'schooner;' 'sewing ma- chine;' 'shovel;' 'sleeping bag;' 'snowmobile;' 'snowplow, snowplough;' 'soap dispenser;' 'spatula;' 'spider web, spider's web;' 'steam locomotive;' 'stethoscope;' 'studio couch, day bed;' 'submarine, pigboat, sub, U-boat;' 'sundial;' 'suspension bridge;' 'syringe;' 'tank, army tank, armored combat vehicle, armoured combat vehicle;' 'teddy, teddy bear;' 'toaster;' 'torch;' 'tricycle, trike, velocipede;' 'umbrella;' 'unicycle, monocycle;' 'viaduct;' 'volleyball;' 'washer, automatic washer, washing ma- chine;' 'water tower;' 'wine bottle;' 'wreck;' 'guacamole;' 'pretzel;' 'cheeseburger;' 'hotdog, hot dog, red hot;' 'broccoli;' 'cucumber, cuke;' 'bell pepper;' 'mushroom;' 'lemon;' 'banana;' 'custard apple;' 'pomegranate;' 'carbonara;' 'bubble;' 'cliff, drop, drop-off;' 'volcano;' 'ballplayer, baseball player;' 'rapeseed;' 'yellow lady's slipper, yellow lady-slipper, Cypripedium calceolus, Cypripedium parviflorum;' 'corn;' 'acorn.' Their WordNet IDs are as follows.\n", "annotations": {"author": "[{\"end\":148,\"start\":32},{\"end\":264,\"start\":149},{\"end\":374,\"start\":265},{\"end\":496,\"start\":375},{\"end\":608,\"start\":497}]", "publisher": null, "author_last_name": "[{\"end\":45,\"start\":36},{\"end\":159,\"start\":155},{\"end\":278,\"start\":272},{\"end\":391,\"start\":381},{\"end\":506,\"start\":502}]", "author_first_name": "[{\"end\":35,\"start\":32},{\"end\":154,\"start\":149},{\"end\":271,\"start\":265},{\"end\":380,\"start\":375},{\"end\":501,\"start\":497}]", "author_affiliation": "[{\"end\":147,\"start\":70},{\"end\":263,\"start\":186},{\"end\":373,\"start\":296},{\"end\":495,\"start\":418},{\"end\":607,\"start\":530}]", "title": "[{\"end\":29,\"start\":1},{\"end\":637,\"start\":609}]", "venue": null, "abstract": "[{\"end\":1682,\"start\":639}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b29\"},\"end\":1784,\"start\":1780},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":1807,\"start\":1803},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":1826,\"start\":1822},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":1855,\"start\":1851},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":1983,\"start\":1979},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":2193,\"start\":2189},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":2476,\"start\":2472},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":2509,\"start\":2505},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":3022,\"start\":3019},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":3024,\"start\":3022},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":3044,\"start\":3040},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":3290,\"start\":3286},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":4322,\"start\":4318},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":4344,\"start\":4340},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":4591,\"start\":4587},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":4652,\"start\":4648},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":5375,\"start\":5371},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":5401,\"start\":5398},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":5404,\"start\":5401},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":5445,\"start\":5442},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":5448,\"start\":5445},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":5477,\"start\":5473},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":5534,\"start\":5530},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":5536,\"start\":5534},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":5547,\"start\":5543},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":5549,\"start\":5547},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":5773,\"start\":5769},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":5902,\"start\":5899},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":6000,\"start\":5996},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":6381,\"start\":6378},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":6712,\"start\":6708},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":6990,\"start\":6986},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":7352,\"start\":7348},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":7355,\"start\":7352},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":7948,\"start\":7944},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":8329,\"start\":8325},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":10001,\"start\":9997},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":13053,\"start\":13049},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":13260,\"start\":13256},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":14189,\"start\":14185},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":14192,\"start\":14189},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":14916,\"start\":14912},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":14919,\"start\":14916},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":14922,\"start\":14919},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":16483,\"start\":16479},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":16727,\"start\":16723},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":16904,\"start\":16900},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":17921,\"start\":17917},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":19326,\"start\":19322},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":19329,\"start\":19326},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":19332,\"start\":19329},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":19404,\"start\":19400},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":21103,\"start\":21099},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":21128,\"start\":21124},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":21312,\"start\":21308},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":21482,\"start\":21478},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":21654,\"start\":21650},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":23427,\"start\":23423}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":25016,\"start\":24469},{\"attributes\":{\"id\":\"fig_1\"},\"end\":25251,\"start\":25017},{\"attributes\":{\"id\":\"fig_2\"},\"end\":25380,\"start\":25252},{\"attributes\":{\"id\":\"fig_3\"},\"end\":25624,\"start\":25381},{\"attributes\":{\"id\":\"fig_4\"},\"end\":25767,\"start\":25625},{\"attributes\":{\"id\":\"fig_5\"},\"end\":26295,\"start\":25768},{\"attributes\":{\"id\":\"fig_6\"},\"end\":26879,\"start\":26296},{\"attributes\":{\"id\":\"fig_7\"},\"end\":27157,\"start\":26880}]", "paragraph": "[{\"end\":2385,\"start\":1698},{\"end\":3664,\"start\":2387},{\"end\":4409,\"start\":3666},{\"end\":5041,\"start\":4411},{\"end\":5946,\"start\":5058},{\"end\":7659,\"start\":5948},{\"end\":8118,\"start\":7683},{\"end\":9140,\"start\":8120},{\"end\":9897,\"start\":9142},{\"end\":10672,\"start\":9899},{\"end\":11982,\"start\":10674},{\"end\":12466,\"start\":11984},{\"end\":13415,\"start\":12509},{\"end\":14004,\"start\":13417},{\"end\":14473,\"start\":14006},{\"end\":14859,\"start\":14475},{\"end\":15763,\"start\":14861},{\"end\":16117,\"start\":15853},{\"end\":16306,\"start\":16119},{\"end\":16484,\"start\":16373},{\"end\":16598,\"start\":16528},{\"end\":17205,\"start\":16600},{\"end\":17306,\"start\":17207},{\"end\":17774,\"start\":17308},{\"end\":18266,\"start\":17776},{\"end\":19055,\"start\":18268},{\"end\":19405,\"start\":19150},{\"end\":21256,\"start\":19407},{\"end\":22451,\"start\":21258},{\"end\":23862,\"start\":22466},{\"end\":24468,\"start\":23882}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":16372,\"start\":16307},{\"attributes\":{\"id\":\"formula_1\"},\"end\":16527,\"start\":16485},{\"attributes\":{\"id\":\"formula_2\"},\"end\":19149,\"start\":19119}]", "table_ref": null, "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1696,\"start\":1684},{\"attributes\":{\"n\":\"2\"},\"end\":5056,\"start\":5044},{\"attributes\":{\"n\":\"3\"},\"end\":7672,\"start\":7662},{\"attributes\":{\"n\":\"3.1\"},\"end\":7681,\"start\":7675},{\"attributes\":{\"n\":\"3.2\"},\"end\":12507,\"start\":12469},{\"attributes\":{\"n\":\"4\"},\"end\":15777,\"start\":15766},{\"attributes\":{\"n\":\"4.1\"},\"end\":15851,\"start\":15780},{\"attributes\":{\"n\":\"4.2\"},\"end\":19118,\"start\":19058},{\"attributes\":{\"n\":\"5\"},\"end\":22464,\"start\":22454},{\"attributes\":{\"n\":\"5.1\"},\"end\":23880,\"start\":23865},{\"end\":24480,\"start\":24470},{\"end\":25028,\"start\":25018},{\"end\":25263,\"start\":25253},{\"end\":25392,\"start\":25382},{\"end\":25636,\"start\":25626},{\"end\":25789,\"start\":25769},{\"end\":26319,\"start\":26297},{\"end\":26892,\"start\":26881}]", "table": null, "figure_caption": "[{\"end\":25016,\"start\":24482},{\"end\":25251,\"start\":25030},{\"end\":25380,\"start\":25265},{\"end\":25624,\"start\":25394},{\"end\":25767,\"start\":25638},{\"end\":26295,\"start\":25792},{\"end\":26879,\"start\":26324},{\"end\":27157,\"start\":26895}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":3962,\"start\":3954},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":12653,\"start\":12645},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":13488,\"start\":13478},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":13820,\"start\":13811},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":14550,\"start\":14542},{\"end\":15080,\"start\":15072},{\"end\":15379,\"start\":15371},{\"end\":15649,\"start\":15641},{\"end\":17226,\"start\":17218},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":17819,\"start\":17811},{\"end\":18965,\"start\":18957},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":20790,\"start\":20781},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":21182,\"start\":21173},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":22170,\"start\":22152}]", "bib_author_first_name": "[{\"end\":27206,\"start\":27201},{\"end\":27443,\"start\":27436},{\"end\":27455,\"start\":27452},{\"end\":27711,\"start\":27706},{\"end\":27970,\"start\":27963},{\"end\":27988,\"start\":27980},{\"end\":28363,\"start\":28360},{\"end\":28365,\"start\":28364},{\"end\":28569,\"start\":28561},{\"end\":28584,\"start\":28579},{\"end\":28760,\"start\":28752},{\"end\":28909,\"start\":28902},{\"end\":29031,\"start\":29028},{\"end\":29202,\"start\":29197},{\"end\":29391,\"start\":29385},{\"end\":29622,\"start\":29616},{\"end\":29857,\"start\":29851},{\"end\":30065,\"start\":30062},{\"end\":30259,\"start\":30254},{\"end\":30447,\"start\":30442},{\"end\":30671,\"start\":30664},{\"end\":30773,\"start\":30766},{\"end\":30933,\"start\":30930},{\"end\":30951,\"start\":30945},{\"end\":31202,\"start\":31199},{\"end\":31219,\"start\":31214},{\"end\":31422,\"start\":31419},{\"end\":31440,\"start\":31434},{\"end\":31456,\"start\":31450},{\"end\":31631,\"start\":31624},{\"end\":31647,\"start\":31642},{\"end\":31970,\"start\":31967},{\"end\":31977,\"start\":31975},{\"end\":31988,\"start\":31984},{\"end\":32290,\"start\":32287},{\"end\":32460,\"start\":32457},{\"end\":32837,\"start\":32829},{\"end\":33164,\"start\":33158},{\"end\":33355,\"start\":33350},{\"end\":33375,\"start\":33367},{\"end\":33388,\"start\":33384},{\"end\":33390,\"start\":33389},{\"end\":33611,\"start\":33607},{\"end\":33628,\"start\":33624},{\"end\":33648,\"start\":33640},{\"end\":33650,\"start\":33649},{\"end\":33850,\"start\":33844},{\"end\":33863,\"start\":33860},{\"end\":33880,\"start\":33876},{\"end\":34051,\"start\":34045},{\"end\":34064,\"start\":34061},{\"end\":34066,\"start\":34065},{\"end\":34083,\"start\":34079},{\"end\":34333,\"start\":34328},{\"end\":34539,\"start\":34529},{\"end\":34756,\"start\":34753},{\"end\":34774,\"start\":34769},{\"end\":34789,\"start\":34785},{\"end\":35202,\"start\":35197},{\"end\":35218,\"start\":35211},{\"end\":35442,\"start\":35434},{\"end\":35671,\"start\":35664},{\"end\":36145,\"start\":36141},{\"end\":36320,\"start\":36311},{\"end\":36479,\"start\":36475},{\"end\":36496,\"start\":36492},{\"end\":36517,\"start\":36510},{\"end\":36756,\"start\":36750},{\"end\":36917,\"start\":36910},{\"end\":37104,\"start\":37098},{\"end\":37330,\"start\":37323},{\"end\":37492,\"start\":37489},{\"end\":37698,\"start\":37691},{\"end\":39273,\"start\":39272},{\"end\":39412,\"start\":39407}]", "bib_author_last_name": "[{\"end\":27214,\"start\":27207},{\"end\":27450,\"start\":27444},{\"end\":27463,\"start\":27456},{\"end\":27719,\"start\":27712},{\"end\":27978,\"start\":27971},{\"end\":27995,\"start\":27989},{\"end\":28208,\"start\":28197},{\"end\":28371,\"start\":28366},{\"end\":28577,\"start\":28570},{\"end\":28591,\"start\":28585},{\"end\":28768,\"start\":28761},{\"end\":28914,\"start\":28910},{\"end\":29036,\"start\":29032},{\"end\":29215,\"start\":29203},{\"end\":29399,\"start\":29392},{\"end\":29630,\"start\":29623},{\"end\":29864,\"start\":29858},{\"end\":30076,\"start\":30066},{\"end\":30265,\"start\":30260},{\"end\":30451,\"start\":30448},{\"end\":30674,\"start\":30672},{\"end\":30776,\"start\":30774},{\"end\":30943,\"start\":30934},{\"end\":30962,\"start\":30952},{\"end\":31212,\"start\":31203},{\"end\":31226,\"start\":31220},{\"end\":31432,\"start\":31423},{\"end\":31448,\"start\":31441},{\"end\":31467,\"start\":31457},{\"end\":31640,\"start\":31632},{\"end\":31658,\"start\":31648},{\"end\":31973,\"start\":31971},{\"end\":31982,\"start\":31978},{\"end\":31992,\"start\":31989},{\"end\":32293,\"start\":32291},{\"end\":32466,\"start\":32461},{\"end\":32843,\"start\":32838},{\"end\":33169,\"start\":33165},{\"end\":33365,\"start\":33356},{\"end\":33382,\"start\":33376},{\"end\":33393,\"start\":33391},{\"end\":33622,\"start\":33612},{\"end\":33638,\"start\":33629},{\"end\":33657,\"start\":33651},{\"end\":33858,\"start\":33851},{\"end\":33874,\"start\":33864},{\"end\":33887,\"start\":33881},{\"end\":34059,\"start\":34052},{\"end\":34077,\"start\":34067},{\"end\":34090,\"start\":34084},{\"end\":34337,\"start\":34334},{\"end\":34545,\"start\":34540},{\"end\":34767,\"start\":34757},{\"end\":34783,\"start\":34775},{\"end\":34795,\"start\":34790},{\"end\":35209,\"start\":35203},{\"end\":35226,\"start\":35219},{\"end\":35234,\"start\":35228},{\"end\":35448,\"start\":35443},{\"end\":35678,\"start\":35672},{\"end\":36150,\"start\":36146},{\"end\":36328,\"start\":36321},{\"end\":36490,\"start\":36480},{\"end\":36508,\"start\":36497},{\"end\":36531,\"start\":36518},{\"end\":36761,\"start\":36757},{\"end\":36922,\"start\":36918},{\"end\":37108,\"start\":37105},{\"end\":37334,\"start\":37331},{\"end\":37498,\"start\":37493},{\"end\":37704,\"start\":37699},{\"end\":39405,\"start\":39274},{\"end\":39417,\"start\":39413}]", "bib_entry": "[{\"attributes\":{\"doi\":\"arXiv:1707.07397\",\"id\":\"b0\"},\"end\":27354,\"start\":27159},{\"attributes\":{\"doi\":\"CoRR abs/1703.09387\",\"id\":\"b1\"},\"end\":27629,\"start\":27356},{\"attributes\":{\"doi\":\"CoRR abs/1904.06347\",\"id\":\"b2\"},\"end\":27871,\"start\":27631},{\"attributes\":{\"doi\":\"CoRR abs/1904.00760\",\"id\":\"b3\"},\"end\":28176,\"start\":27873},{\"attributes\":{\"doi\":\"arXiv:1712.09665\",\"id\":\"b4\"},\"end\":28323,\"start\":28178},{\"attributes\":{\"doi\":\"CoRR abs/1809.08352\",\"id\":\"b5\"},\"end\":28480,\"start\":28325},{\"attributes\":{\"id\":\"b6\"},\"end\":28712,\"start\":28482},{\"attributes\":{\"id\":\"b7\"},\"end\":28880,\"start\":28714},{\"attributes\":{\"id\":\"b8\"},\"end\":28973,\"start\":28882},{\"attributes\":{\"id\":\"b9\"},\"end\":29129,\"start\":28975},{\"attributes\":{\"id\":\"b10\"},\"end\":29331,\"start\":29131},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":52098843},\"end\":29508,\"start\":29333},{\"attributes\":{\"id\":\"b12\"},\"end\":29782,\"start\":29510},{\"attributes\":{\"doi\":\"CoRR abs/1807.06732\",\"id\":\"b13\"},\"end\":30006,\"start\":29784},{\"attributes\":{\"id\":\"b14\"},\"end\":30192,\"start\":30008},{\"attributes\":{\"doi\":\"CoRR abs/1706.02677\",\"id\":\"b15\"},\"end\":30398,\"start\":30194},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":28671436},\"end\":30616,\"start\":30400},{\"attributes\":{\"id\":\"b17\"},\"end\":30762,\"start\":30618},{\"attributes\":{\"id\":\"b18\"},\"end\":30848,\"start\":30764},{\"attributes\":{\"id\":\"b19\"},\"end\":31105,\"start\":30850},{\"attributes\":{\"id\":\"b20\"},\"end\":31371,\"start\":31107},{\"attributes\":{\"id\":\"b21\"},\"end\":31591,\"start\":31373},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":4553898},\"end\":31932,\"start\":31593},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":140309863},\"end\":32208,\"start\":31934},{\"attributes\":{\"id\":\"b24\"},\"end\":32413,\"start\":32210},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":9433631},\"end\":32758,\"start\":32415},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":206595627},\"end\":33093,\"start\":32760},{\"attributes\":{\"doi\":\"CoRR abs/1905.01034\",\"id\":\"b27\"},\"end\":33305,\"start\":33095},{\"attributes\":{\"doi\":\"CoRR abs/1805.08974\",\"id\":\"b28\"},\"end\":33540,\"start\":33307},{\"attributes\":{\"id\":\"b29\"},\"end\":33802,\"start\":33542},{\"attributes\":{\"id\":\"b30\"},\"end\":33999,\"start\":33804},{\"attributes\":{\"doi\":\"CoRR abs/1607.02533\",\"id\":\"b31\"},\"end\":34240,\"start\":34001},{\"attributes\":{\"id\":\"b32\"},\"end\":34464,\"start\":34242},{\"attributes\":{\"id\":\"b33\"},\"end\":34656,\"start\":34466},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":206592585},\"end\":35108,\"start\":34658},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":2879445},\"end\":35384,\"start\":35110},{\"attributes\":{\"doi\":\"ArXiv abs/1902.10811\",\"id\":\"b36\"},\"end\":35574,\"start\":35386},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":207241700},\"end\":36068,\"start\":35576},{\"attributes\":{\"id\":\"b38\"},\"end\":36267,\"start\":36070},{\"attributes\":{\"id\":\"b39\"},\"end\":36402,\"start\":36269},{\"attributes\":{\"id\":\"b40\"},\"end\":36671,\"start\":36404},{\"attributes\":{\"id\":\"b41\"},\"end\":36864,\"start\":36673},{\"attributes\":{\"doi\":\"CoRR abs/1801.02612\",\"id\":\"b42\"},\"end\":37040,\"start\":36866},{\"attributes\":{\"doi\":\"arXiv:1812.03411\",\"id\":\"b43\"},\"end\":37259,\"start\":37042},{\"attributes\":{\"id\":\"b44\"},\"end\":37439,\"start\":37261},{\"attributes\":{\"doi\":\"CoRR abs/1805.08318\",\"id\":\"b45\"},\"end\":37617,\"start\":37441},{\"attributes\":{\"id\":\"b46\"},\"end\":37820,\"start\":37619},{\"attributes\":{\"id\":\"b47\"},\"end\":45528,\"start\":37822}]", "bib_title": "[{\"end\":29383,\"start\":29333},{\"end\":30060,\"start\":30008},{\"end\":30440,\"start\":30400},{\"end\":31622,\"start\":31593},{\"end\":31965,\"start\":31934},{\"end\":32455,\"start\":32415},{\"end\":32827,\"start\":32760},{\"end\":34751,\"start\":34658},{\"end\":35195,\"start\":35110},{\"end\":35662,\"start\":35576}]", "bib_author": "[{\"end\":27216,\"start\":27201},{\"end\":27452,\"start\":27436},{\"end\":27465,\"start\":27452},{\"end\":27721,\"start\":27706},{\"end\":27980,\"start\":27963},{\"end\":27997,\"start\":27980},{\"end\":28210,\"start\":28197},{\"end\":28373,\"start\":28360},{\"end\":28579,\"start\":28561},{\"end\":28593,\"start\":28579},{\"end\":28770,\"start\":28752},{\"end\":28916,\"start\":28902},{\"end\":29038,\"start\":29028},{\"end\":29217,\"start\":29197},{\"end\":29401,\"start\":29385},{\"end\":29632,\"start\":29616},{\"end\":29866,\"start\":29851},{\"end\":30078,\"start\":30062},{\"end\":30267,\"start\":30254},{\"end\":30453,\"start\":30442},{\"end\":30676,\"start\":30664},{\"end\":30778,\"start\":30766},{\"end\":30945,\"start\":30930},{\"end\":30964,\"start\":30945},{\"end\":31214,\"start\":31199},{\"end\":31228,\"start\":31214},{\"end\":31434,\"start\":31419},{\"end\":31450,\"start\":31434},{\"end\":31469,\"start\":31450},{\"end\":31642,\"start\":31624},{\"end\":31660,\"start\":31642},{\"end\":31975,\"start\":31967},{\"end\":31984,\"start\":31975},{\"end\":31994,\"start\":31984},{\"end\":32295,\"start\":32287},{\"end\":32468,\"start\":32457},{\"end\":32845,\"start\":32829},{\"end\":33171,\"start\":33158},{\"end\":33367,\"start\":33350},{\"end\":33384,\"start\":33367},{\"end\":33395,\"start\":33384},{\"end\":33624,\"start\":33607},{\"end\":33640,\"start\":33624},{\"end\":33659,\"start\":33640},{\"end\":33860,\"start\":33844},{\"end\":33876,\"start\":33860},{\"end\":33889,\"start\":33876},{\"end\":34061,\"start\":34045},{\"end\":34079,\"start\":34061},{\"end\":34092,\"start\":34079},{\"end\":34339,\"start\":34328},{\"end\":34547,\"start\":34529},{\"end\":34769,\"start\":34753},{\"end\":34785,\"start\":34769},{\"end\":34797,\"start\":34785},{\"end\":35211,\"start\":35197},{\"end\":35228,\"start\":35211},{\"end\":35236,\"start\":35228},{\"end\":35450,\"start\":35434},{\"end\":35680,\"start\":35664},{\"end\":36152,\"start\":36141},{\"end\":36330,\"start\":36311},{\"end\":36492,\"start\":36475},{\"end\":36510,\"start\":36492},{\"end\":36533,\"start\":36510},{\"end\":36763,\"start\":36750},{\"end\":36924,\"start\":36910},{\"end\":37110,\"start\":37098},{\"end\":37336,\"start\":37323},{\"end\":37500,\"start\":37489},{\"end\":37706,\"start\":37691},{\"end\":39407,\"start\":39272},{\"end\":39419,\"start\":39407}]", "bib_venue": "[{\"end\":27199,\"start\":27159},{\"end\":27434,\"start\":27356},{\"end\":27704,\"start\":27631},{\"end\":27961,\"start\":27873},{\"end\":28195,\"start\":28178},{\"end\":28358,\"start\":28325},{\"end\":28559,\"start\":28482},{\"end\":28750,\"start\":28714},{\"end\":28900,\"start\":28882},{\"end\":29026,\"start\":28975},{\"end\":29195,\"start\":29131},{\"end\":29412,\"start\":29401},{\"end\":29614,\"start\":29510},{\"end\":29849,\"start\":29784},{\"end\":30089,\"start\":30078},{\"end\":30252,\"start\":30194},{\"end\":30497,\"start\":30453},{\"end\":30662,\"start\":30618},{\"end\":30799,\"start\":30778},{\"end\":30928,\"start\":30850},{\"end\":31197,\"start\":31107},{\"end\":31417,\"start\":31373},{\"end\":31745,\"start\":31660},{\"end\":32061,\"start\":31994},{\"end\":32285,\"start\":32210},{\"end\":32545,\"start\":32468},{\"end\":32914,\"start\":32845},{\"end\":33156,\"start\":33095},{\"end\":33348,\"start\":33307},{\"end\":33605,\"start\":33542},{\"end\":33842,\"start\":33804},{\"end\":34043,\"start\":34001},{\"end\":34326,\"start\":34242},{\"end\":34527,\"start\":34466},{\"end\":34866,\"start\":34797},{\"end\":35241,\"start\":35236},{\"end\":35432,\"start\":35386},{\"end\":35765,\"start\":35680},{\"end\":36139,\"start\":36070},{\"end\":36309,\"start\":36269},{\"end\":36473,\"start\":36404},{\"end\":36748,\"start\":36673},{\"end\":36908,\"start\":36866},{\"end\":37096,\"start\":37042},{\"end\":37321,\"start\":37261},{\"end\":37487,\"start\":37441},{\"end\":37689,\"start\":37619},{\"end\":39270,\"start\":37822},{\"end\":32609,\"start\":32547},{\"end\":35837,\"start\":35767}]"}}}, "year": 2023, "month": 12, "day": 17}