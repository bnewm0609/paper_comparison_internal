{"id": 235606372, "updated": "2023-10-06 01:45:22.228", "metadata": {"title": "Real-time Neural Radiance Caching for Path Tracing", "authors": "[{\"first\":\"Thomas\",\"last\":\"Muller\",\"middle\":[]},{\"first\":\"Fabrice\",\"last\":\"Rousselle\",\"middle\":[]},{\"first\":\"Jan\",\"last\":\"Nov'ak\",\"middle\":[]},{\"first\":\"Alexander\",\"last\":\"Keller\",\"middle\":[]}]", "venue": null, "journal": "ACM Transactions on Graphics (TOG)", "publication_date": {"year": 2021, "month": 6, "day": 23}, "abstract": "We present a real-time neural radiance caching method for path-traced global illumination. Our system is designed to handle fully dynamic scenes, and makes no assumptions about the lighting, geometry, and materials. The data-driven nature of our approach sidesteps many difficulties of caching algorithms, such as locating, interpolating, and updating cache points. Since pretraining neural networks to handle novel, dynamic scenes is a formidable generalization challenge, we do away with pretraining and instead achieve generalization via adaptation, i.e. we opt for training the radiance cache while rendering. We employ self-training to provide low-noise training targets and simulate infinite-bounce transport by merely iterating few-bounce training updates. The updates and cache queries incur a mild overhead -- about 2.6ms on full HD resolution -- thanks to a streaming implementation of the neural network that fully exploits modern hardware. We demonstrate significant noise reduction at the cost of little induced bias, and report state-of-the-art, real-time performance on a number of challenging scenarios.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2106.12372", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/tog/MullerRN021", "doi": "10.1145/3450626.3459812"}}, "content": {"source": {"pdf_hash": "1115d5d022c3c15246463a0bc684bb789bfc82dd", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2106.12372v2.pdf\"]", "oa_url_match": true, "oa_info": {"license": null, "open_access_url": "http://arxiv.org/pdf/2106.12372", "status": "GREEN"}}, "grobid": {"id": "70526b3ddb070fd6ff207361c61b47dbe0c81032", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/1115d5d022c3c15246463a0bc684bb789bfc82dd.txt", "contents": "\nReal-time Neural Radiance Caching for Path Tracing\n2021. August 2021\n\nThomas M\u00fcller \nFabrice Rousselle \nNVIDIAJan Nov\u00e1k \nAlexander Keller \nReal-time Neural Radiance Caching for Path Tracing\n\nACM Reference Format\n404362021. August 202110.1145/3450626.3459812Publication date: August 2021.Authors' addresses: Thomas M\u00fcller, NVIDIA, This is the author's version of the work. It is posted here for your personal use. Not for redistribution. 36:2 \u2022 M\u00fcller et al.CCS Concepts: \u2022 Computing methodologies \u2192 Neural networksRay tracingSupervised learning by regressionReinforcement learn- ing Additional Key Words and Phrases: real-time, rendering, deep learning, neural networks, path tracing, radiance caching\nPath tracing + ReSTIR + NRC (Ours) Reference Path tracing + ReSTIR + NRC (Ours) Reference Path tracing + ReSTIR + NRC (Ours) Reference Path tracing + ReSTIR + NRC (Ours) Reference 97 fps 71 fps 88 fps 186 fps 121 fps 111 fps Fig. 1. A path-traced frame from the Zero Day animation (left) and the Living Room scene (right), rendered with 1 sample per pixel each. Direct-illumination sampling such as ReSTIR [Bitterli et al . 2020] reduces noise at the first path vertex, but does not address noise from indirect illumination. We propose to reduce the remaining noise by (online) training a neural network to approximate the radiance field-a new take on classical radiance caching. Terminating the paths into the neural cache not only shortens paths-leading to an overall cost reduction in the Zero Day scene-but also removes most of the remaining noise while introducing little bias. The images were rendered at a resolution of 1920 \u00d7 1080 on a high-end desktop machine (i9 9900k and RTX 3090). Zero Day \u00a9beepleWe present a real-time neural radiance caching method for path-traced global illumination. Our system is designed to handle fully dynamic scenes, and makes no assumptions about the lighting, geometry, and materials. The data-driven nature of our approach sidesteps many difficulties of caching algorithms, such as locating, interpolating, and updating cache points. Since pretraining neural networks to handle novel, dynamic scenes is a formidable generalization challenge, we do away with pretraining and instead achieve generalization via adaptation, i.e. we opt for training the radiance cache while rendering. We employ self-training to provide low-noise training targets and simulate infinite-bounce transport by merely iterating few-bounce training updates. The updates and cache queries incur a mild overhead-about 2.6ms on full HD resolution-thanks to a streaming implementation of the neural network that fully exploits modern hardware. We demonstrate significant noise reduction at the cost of little induced bias, and report state-of-the-art, real-time performance on a number of challenging scenarios.\n\nINTRODUCTION\n\nPath-traced global illumination is a long standing challenge in realtime rendering ]. The problem remains onerous even in offline rendering, especially when considering high-order indirect illumination. Fortunately, radiative quantities feature significant spatial, directional, and temporal correlations, which can be exploited in various ways to accelerate rendering.\n\nOne particularly appealing approach is to cache radiance samples for later reuse. This can be done in a precomputation step [Seyb et al. 2020], or while rendering [Majercik et al. 2019]. Such systems, however, can be difficult to harness, as they often rely on human intervention or involved heuristics to minimize rendering artifacts [Hooker 2016]. We propose to alleviate these difficulties through the use of a neural radiance cache, as neural networks are known to be particularly apt at replacing complex heuristics. Our system is designed according to the following principles:\n\n\u2022 Dynamic content. To handle fully interactive content, the system must support arbitrary dynamics of the camera, lighting, geometry, and materials. We strive for a solution that does not require precomputation. \u2022 Robustness. Case-specific handling eventually leads to complex, brittle systems. Hence, the cache should be agnostic of materials and scene geometry. This is particularly important for user-generated content, where design assumptions cannot be easily enforced. Yet, additional attributes may be provided to the system to improve its rendering quality. \u2022 Predictable performance and resource consumption. Fluctuations in work load and memory usage lead to unstable framerates. We seek a solution with stable runtime overhead and memory footprint, both of which should be independent of scene complexity. The rendering cost must scale at worst linearly with the number of pixels.\n\nThe first two principles-dynamic content and robustness-present a major challenge for pre-trained networks: the trained model must generalize to novel configurations and, worse, content possibly never observed before. This form of generalization has not been demonstrated with previous approaches in the context of learning radiative quantities [Hermosilla et al. 2019;Mildenhall et al. 2020;Ren et al. 2013], and it is unclear if it can ever be achieved. Instead, we build on the simple but powerful realization that the generalization challenge can be completely sidestepped by fast adaptation. We rely solely on optimizing the model online, during rendering. Online learning of neural networks has so-far only been used in offline and interactive rendering [Lehtinen et al. 2018;M\u00fcller et al. 2020]. Fitting the optimization and inference inside the tight rendering loop of real-time applications is a nontrivial task that remains to be tackled.\n\nWe present two key contributions that enable generalization via adaptation in real time. First, we describe an efficient mechanism for optimizing the network using (relatively) inexpensive radiance estimates. The core of this mechanism is self-training of the neural network from its own prediction at a later vertex of the path, providing multi-bounce illumination at the cost of tracing single rays or very short paths.\n\nSecond, we propose a streamlined network architecture designed to maximize the quality-cost tradeoff when rendering fully dynamic scenes. This architecture is key to our system, as its simplicity not only leads to extremely fast convergence but also enables extensive optimizations. To fully exploit these opportunities, we propose a fully fused implementation tailored to modern GPUs; the underlying principles however are general and could be adapted to a range of platforms. We also show how recently proposed input encodings [Mildenhall et al. 2020; can be combined to greatly enhance fidelity even with our severely constrained budget.\n\nAs shown in Figure 1, our system achieves real-time framerates on current hardware and handles a wide range of material and lighting configurations. Our accompanying video demonstrates the temporal adaptation to dynamic geometry and lighting. Lastly, we report preliminary results with an off-the-shelf denoiser demonstrating significantly improved temporal coherence when using our cache.\n\n\nRELATED WORK\n\nReviewing techniques for accelerating global illumination by radiance caching, we focus on precomputation-based techniques, fully dynamic algorithms, and approaches based on artificial neural networks that are most related to our work. For an extensive survey we refer to .\n\nRadiance caching. Most real-time global illumination techniques can be traced back to the seminal work of Ward et al. [1988] on irradiance caching. Modern techniques for modeling diffuse interreflections follow the same assumption that irradiance tends to vary smoothly across the scene, and texture detail can be recovered using albedo modulation. Later, Greger et al. [1998] introduced the irradiance probe volume, which became ubiquitous in modern game engines. The interpolation and location of the various cache records is a key challenge in these techniques, especially when the aforementioned assumptions on smoothness do not hold. While robust, principled solutions exist [Jarosz et al. 2008;K\u0159iv\u00e1nek and Gautron 2009], real-time applications often have to resort to clever heuristics and impose restrictions on scene design to fit their harsh constraints. In order to handle glossy surfaces, which invalidate the Lambertian assumption at the core of irradiance caching algorithms, K\u0159iv\u00e1nek et al. [2005] proposed the use of a radiance cache, representing the directional domain with spherical harmonics. A wealth of recent works further explored the use of radiance caching in offline [Dubouchet et al. 2017;Marco et al. 2018;Zhao et al. 2019] and real-time rendering, where advances in real-time rendering were enabled for example by compression [Vardis et al. 2014], sparse interpolation [Silvennoinen and Lehtinen 2017], pre-convolved environment maps [Rehfeld et al. 2014;Scherzer et al. 2012], and spatial hashing [Binder et al. 2018;Pantaleoni 2020]. In contrast, our own work achieves robustness through online deep learning.\n\nPrecomputation-based techniques. The high computational cost of simulating global illumination spurred the development of precomputation techniques [Arvo 1986;Heckbert 1990], which have been further developed to address the stringent constraints of realtime applications. Assuming both the scene lighting and geometry are fixed, irradiance can be computed and then stored in texture space using lightmaps [Abrash 1997] and in world space using light probes [Oat 2005]. Offering both approaches in one system, Martin and Einarsson [2010] introduced iterated dynamic lighting updates. These techniques are widespread in modern game engines [ Barr\u00e9-Brisebois 2017]. Light probes can be combined with precomputed radiance transfer [Sloan et al. 2002] or visibility [Iwanicki and Sloan 2017;McGuire et al. 2017], to account for (self) occlusion when shading scene objects. While precomputation-based solutions offer a number of indisputable advantages [Seyb et al. 2020], we embrace online caching mechanisms that facilitate dynamically changing scenes without assuming (parts of) the scene to be static or known in advance.\n\nFully dynamic techniques. Dynamic real-time global illumination methods build upon efficient rendering algorithms that reuse shading and visibility computation across pixels, such as photon mapping [Jensen 1996], many-light rendering [Keller 1997] and radiosity maps [Tabellion and Lamorlette 2004], extracting further efficiency through various approximations. Some approximate the scene geometry using a (hierarchical) point cloud, which is then efficiently rasterized into shadow maps [Ritschel et al. 2008] or micro-rendering buffers [Ritschel et al. 2009a]. Volumetric approximations of the scene lighting and geometry [Crassin et al. 2011;Kaplanyan and Dachsbacher 2010], bootstrapped with large numbers of virtual point lights from reflective shadow maps [Dachsbacher and Stamminger 2005], allowed to scale to larger scenes. These approaches are sometimes combined with very efficient screen-space approximations of ambient occlusion [Mittring 2007], directional occlusion [Ritschel et al. 2009b], or reflections [Sousa et al. 2011]. Recently, ray-tracing hardware has been used to compute specific components of light transport online, such as diffuse interreflections [Majercik et al. 2019] or glossy reflections [Deligiannis and Schmid 2019]. Aside of accuracy limitations inherent to the approximations, such as blurring, missing interactions, or assumptions about the material model, a key limitation of many of these techniques is the reliance on a dual representation of the scene which must be continuously refreshed. Our neural radiance cache sidesteps the need for an approximate scene representation by operating on a set of sampled path contributions, which effectively decouples the algorithm from the scene lighting and geometric complexity.\n\nPath guiding. The family of path guiding techniques, originating from Lafortune and Willems [1995] and Jensen [1995], is closely related to that of radiance caching in that they often learn an approximation of incident radiance that is amenable to importance sampling. Recent incident-radiance models tend to be either parametric mixtures [Vorba et al. 2014] or probability trees ], but (neural) normalizing flows are also possible . While these techniques are highly successful in offline rendering of mostly static scenes [Vorba et al. 2019], adapting them to the constraints of animated real-time rendering is non-trivial ongoing work [Dittebrandt et al. 2020]. Methods that use an explicit model of the BRDF [Herholz et al. 2018[Herholz et al. , 2016 or the product integrand M\u00fcller et al. 2020] are likely the most promising to repurpose as radiance caches, as they yield a more accurate scattered-radiance estimate than methods approximating the incident radiance at the previous camera-path vertex.\n\nNeural techniques. Neural networks are capable of approximating various visual phenomena remarkably well, whether they operate in screen space [Nalbach et al. 2017] or in world space, whether they are pre-trained over multiple scenes [Hermosilla et al. 2019;Jiang and Kainz 2021;Kallweit et al. 2017;Nalbach et al. 2017] or fit to single scene [Keller and Dahm 2019;Mildenhall et al. 2020;M\u00fcller et al. 2020;Ren et al. 2013]. The latter approaches are most closely related to ours. Ren et al. [2013] propose to train a set of local neural radiance caches, conditioned on the position of a single point light source. While lighting can be changed dynamically and area lighting can be approximated using a set of point lights at the cost of multiple cache queries, geometry and materials have to remain static as a consequence of the cost of the training procedure. Our technique differs on two important aspects: (i) we use a single neural radiance cache leveraging recently proposed encodings Vaswani et al. 2017] to adapt to local scene variations, and (ii) we train our model online which allows for fully dynamic scenes and readily accounts for all lighting in the scene in a single query. Neural control variates [M\u00fcller et al. 2020] and NeRF [Mildenhall et al. 2020], developed in the context of offline rendering, encompass a radiance cache that is parameterized similarly. The key differences of our work are: (i) a network architecture and implementation designed for a rendering budget on the order of milliseconds instead of minutes, and (ii) integration in a renderer using self-training, which has been connected with Q-learning [Dahm and Keller 2018], to account for infinite bounces of indirect illumination despite tracing paths of finite length.\n\n\nNEURAL RADIANCE CACHING\n\nOur goal is to cache radiance using one single neural network that maps spatio-directional coordinates to radiance values and is trained in real-time to support dynamic scenes. We opt for approximating the scattered radiance as it is the most computationally expensive part of the rendering equation [Kajiya 1986]. The scattered radiance\ns (x, ) := \u222b 2 s (x, , i ) i (x, i ) | cos i | d i(1)\nrepresents the radiative energy leaving point x in direction after being scattered at x. For a given direction of incidence i , the integrand is the product of the bidirectional scattering distribution function (BSDF) s (x, , i ), the incident radiance i (x, i ), and the foreshortening term | cos i |, where i is the angle between i and the surface normal at x. Our neural network approximates s by the cached radiance s . In this section, we discuss the algorithmic choices for building a neural radiance cache that are key to satisfy the design principles outlined in Section 1. Real-time performance is enabled by an optimized fully fused network, which is discussed in Section 4.\n\n\nAlgorithm Overview\n\nRendering a single frame consists of computing pixel colors and updating the neural radiance cache; see Figure 2 for an illustration.\n\nFirst, we trace short rendering paths, one for each pixel, and terminate them as soon as the approximation provided by the radiance cache is deemed sufficiently accurate. We use the heuristic by Bekaert et al. [2003], that was originally developed in the context of\nx 0 / y 0 x 1 y 1 x 2 y 2 y 3 y 4 Predicted (cached) radiance\nShadow ray\n\nTraining radiance T r a in in g s u ffi x Fig. 2. For rendering, we trace short \"rendering\" paths (e.g. x 0 \u00b7 \u00b7 \u00b7 x 2 ) and terminate them into the neural radiance cache; queries of cached radiance s are highlighted by red arrows. To optimize the cache, we extend a small subset of the rendering paths by a few vertices (called \"training suffix\", e.g. y 2 \u00b7 \u00b7 \u00b7 y 4 ). We collect radiance estimates (blue arrows) to update the neural radiance cache along the vertices of the longer training path, reusing the initial path segment that was already traced for rendering. Furthermore, the online training together with the termination of training paths into the cache progressively increases the number of simulated light bounces. photon density estimation, to only query the cache once the spread of the path is sufficiently large to blur small inaccuracies of the cache (more detail in Section 3.4). At each intermediate vertex, we use next-event estimation to integrate light from emitters. To this end, we use screen-space ReSTIR [Bitterli et al. 2020] at the primary vertex and a LightBVH [Moreau et al. 2019], combined with the BSDF via multiple importance sampling [Veach and Guibas 1995], at the subsequent vertices. Truncating the path at the terminal vertex x , we evaluate the neural radiance cache to approximate s (x , ).\n\nSecond, to train the radiance cache, we extend a fraction (typically under 3%) of the short rendering paths by a few vertices-a training suffix. As before, we terminate these longer training paths once the area spread of their suffix is sufficiently large; for that purpose we consider the query vertex x as a primary vertex (see Figure 5). In the majority of cases, the suffix consists of one vertex. The radiance estimates collected along all vertices of the longer training paths are used as reference values for training the radiance cache.\n\nDiscussion. Terminating the paths into the radiance cache saves computation and, importantly, replaces a one-sample estimate with an approximation that aggregates samples from spatially and temporally nearby locations. The variance is thus reduced, however, the viability of caching for real-time applications is still conditioned on how efficiently and quickly we update and query the cache.\n\n\nFast Adaptation of the Cache by Self-training\n\nAs in any data-driven approach, the quality of the approximation depends on the accuracy of the target values s that the network is trained on. The distinct challenge of rendering dynamic scenes in real time requires to continuously adapt the neural radiance cache according to the changing radiance field, for example, due to moving lights or geometry. This means we neither have the luxury of precomputing precise target values s , nor can we tolerate noisy estimates that would slow down convergence.\n\nInstead of estimating target values via Monte Carlo path tracing M\u00fcller et al. 2020], we leverage the neural radiance cache itself by evaluating it at the terminal vertices of the longer training paths. The collected radiance is transported to the preceeding vertices, at each one generating a target value for training the neural network. Updating the neural radiance cache using its own values resembles the concept of Q-learning [Dahm and Keller 2018;Keller and Dahm 2019].\n\nThe self-training approach has two distinct advantages over fully path-traced estimates: it trades a large fraction of the undesired noise for (potential) bias when estimating s . It also allows for capturing global illumination as long as the training procedure is iterated: the radiance learned by one training path is transported using multiple other training paths in the next iteration. Hence, each iteration increases the number of simulated light bounces. This is reminiscent of progressive radiosity algorithms [Martin and Einarsson 2010] that simulate multi-bounce diffuse transport by iterating single-bounce radiative transfer.\n\nHowever, self-training the neural radiance cache also has two caveats: first, the last vertex of the training path may reach scene locations that the radiance cache has not been trained for, which may incur a larger approximation error. The second drawback is that the iterated optimization may simulate only a subset of multibounce illumination rather than all light transport. Specifically, only the transport from emitters that can be reached by training paths will be further bounced around, and only so, if tails of training paths in subsequent frames land near the current optimization points (i.e. y 4 needs to be close to y 2 or y 3 in Figure 2). Both caveats can be alleviated almost for free by making a small fraction of the training paths truly unbiased, thereby injecting correct source values to be propagated by the self-training mechanism. We use = 1/16, i.e. every 16 th training suffix is only terminated by Russian roulette.\n\n\nTemporally Stable Cache Queries\n\nWhen rendering dynamic content, for example changing camera position or animated geometry, the neural radiance cache continuously needs to adapt, forcing us to use a high learning-rate when optimizing the network by gradient descent. In addition, we also perform multiple (in our case 4) gradient descent steps per frame 1 , which leads to even faster adaptation.\n\nHowever, a side effect of such an aggressive optimization schedule are temporal artifacts like flickering and oscillations across the rendered frames-even when the scene and camera are static, because there is noise in the estimated radiance targets.\n\nWe therefore propose to dampen such oscillations by averaging the network weights produced by the optimization. More specifically, we compute an exponential moving average (EMA) of the network weights produced by the th gradient descent step, which creates a second set of weights that we use when evaluating the cache for rendering. The exponential moving average reads\n:= 1 \u2212 \u00b7 + \u00b7 \u22121 \u00b7 \u22121 , where := 1 \u2212(2)\ncorrects the bias of the average for small and \u2208 [0, 1] controls the strength of exponential averaging. We use = 0.99 for a good trade-off between fast adaptation yet temporally stable evolution of the weights ; we illustrate the temporal stability in Figure 3.\n\nNote that the averaging process does not feed back into the training loop; depends on , but not the other way around. Still, recent work suggests that the EMA filtered weights may be closer to the optimum than any of the raw weights produced by the optimizer [Izmailov et al. 2018].\n\nIndeed, Figure 4 shows that when the radiance cache is trained from scratch, its evolution is gradual and quick at the same time.\n\nUsing the cache at the end of paths instead of visualizing it directly filters its approximation error, converging to satisfactory quality in as few as 8 frames (\u223c 70 ms); see the supplementary video for more results on animated content.\n\n\nPath Termination\n\nAll paths are terminated according to a simple heuristic based on the area-spread of path vertices, illustrated as cones in Figure 5; we index the camera vertex as x 0 and the primary vertex as x 1 . Once the spread becomes large enough to blur away the small-scale inaccuracies of our cache (c.f. Figure 12), we terminate the path.\n\nFollowing Bekaert et al. [2003], the area spread along the subpath x 1 \u00b7 \u00b7 \u00b7 x can be cheaply approximated as the sum\n(x 1 \u00b7 \u00b7 \u00b7 x ) = \u2211\ufe01 =2 \u221a\ufe04 \u2225x \u22121 \u2212 x \u2225 2 ( i | x \u22121 , ) | cos i | 2 ,(3)\nwhere is the BSDF sampling PDF and i is the angle between i and the surface normal at x . To terminate a path, we compare the subpath spread (x 1 \u00b7 \u00b7 \u00b7 x ) to the spread at the primary vertex as viewed from the camera, which can be approximated 2 as\n0 := \u2225x 0 \u2212 x 1 \u2225 2 4 cos 1 .\n(4)\n\nThat is, we will terminate a path if (x 1 \u00b7 \u00b7 \u00b7 x ) > \u00b7 0 , where is a hyperparameter that trades variance (longer paths) for bias and speed (shorter paths). We found = 0.01 to yield satisfactory results. Lastly, if the path is selected to become a training path, the heuristic will be used once again, this time to terminate the training suffix when (x \u00b7 \u00b7 \u00b7 x ) > \u00b7 0 is satisfied. The heuristic is illustrated in Figure 5 for a training path, where the short rendering part of the path ends at vertex = 2 and the training suffix at = 4.\n\n\nAmortization in a Real-time Path Tracer\n\nWe target real-time applications, setting ourselves a 16.6 milliseconds rendering budget in order to achieve a framerate of 60 frames per second. That budget includes the tracing of paths, shading at every vertex, as well as querying and updating the cache. In practice, this leaves just a few milliseconds to handle the cache overhead. We not only tackle this using our proposed fully fused network, described in Section 4, but also in the path tracer integration itself.\n\nWe interleave short rendering paths and long training paths by tiling the viewport. Using a single random offset, we promote one path per tile to be a long training path (see Figure 5), resulting in a uniform sparse set of training paths in screen space. This approach of merely prolonging a rendering path to obtain a training path greatly reduces the overhead, as computation is shared between 2 By assuming a spherical image plane and ignoring constant factors. EMA weight = 0.00 EMA weight = 0.90 EMA weight = 0.99 Zero Day Fig. 3. Temporal stability of online learning with three weight-averaging strategies: no averaging (left) and an exponential moving average (EMA) with weights 0.90 and 0.99. The false color images depict temporal stability across 100 frames, measured as the symmetric mean absolute percentage error (SMAPE) averaged over all consecutive pairs of frames; i.e. darker means less variation across frames. To be more meaningful in print, the scene and the camera have been fixed. Please see the accompanying video to best assess the temporal stability.\n\n\nVisualization at first non-specular vertex\n\nProposed use of the cache at the end of short paths  Fig. 4. From-scratch training of the neural radiance cache. We visualize the cache after 1, 2, 4, ..., 1024 frames. Top: to illustrate its training behavior, the radiance cache is visualized directly at the first non-specular vertex. Already after the first 64 frames (\u223c 0.5s) the overall colors are correct and only subtle high-frequency artifacts remain. Bottom: using the cache as proposed, the high-frequency artifacts are hidden behind path indirections and the cache is usable starting from the \u223c 8th frame (i.e. after \u223c 70ms). This confirms that the cache trains sufficiently fast for the online adaptation to animated content; see the supplementary video for more results.\n\nx 0\nx 1 x 2 x 3 x 4 0 (x 1 x 2 ) (x 2 x 3 x 4 )\nT r a in in g s u ffi x Fig. 5. We terminate our short rendering paths into the neural radiance cache once their scattering interactions blur the signal sufficiently well. To this end, we compare the size of the footprint of the path (x 1 x 2 ) to the size of the directly visible surface in the image plane 0 . The longer training paths are terminated by the same heuristic applied to the vertices of the suffix, i.e. we compare (x 2 x 3 x 4 ) to 0 .\n\nthe two. This contrasts with caching techniques based on probe volumes, which use a separate set of rays to update the cache that do not contribute to the image itself.\n\nOnce the tracing is complete, we reconstruct the image by backpropagating the cached radiance from the terminal vertex of each short rendering path. For training paths, we track two values: the aforementioned rendering radiance and the training radiance. For every vertex along a training path, we store the training radiance (along with the vertex information) in an array; it will be used as the target to optimize the cache.\n\nWe shuffle all training records using a linear congruential generator and distribute them over training batches of training records each. The shuffling ensures that the training batches are not correlated with image regions. Each training batch is used to perform a single optimization step of the cache. As we want to ensure a stable work load, we use an adaptive tiling mechanism to match a target training budget; we select = 4 training batches and = 16384 records per batch in practice, for a total of 65536 training records per frame. We dynamically adjust the tile size at each frame based on the number of training records generated during the image reconstruction. Similar to other caching techniques, the cost of training is decoupled from the image resolution, since we use a bounded number of training records. Lastly, we observe that training our neural radiance cache amounts to a regression over many samples from spatially and temporally nearby locations, i.e. a form of path-space denoising. The variance is thus significantly reduced by replacing one-sample radiance estimates with the cache approximation. Ren et al. [2013] showed that solely using the spatio-directional coordinates (x, ) of the scattered radiance as input to a neural network does not allow it to represent radiance well. Therefore, the input is augmented by additional parameters that correlate with the scattered radiance: the surface normal n, the surface roughness , the diffuse reflectance , and the specular reflectance . Being able to exploit such correlations, the neural approximation becomes much more accurate.\n\n\nInput Encoding\n\nIt is easier for the network to identify these correlations when they are (nearly) linear. This is already the case for the diffuse and specular reflectances; we thus input them to the network asis. However, the quantities x, , n, and have a highly non-linear  [Mildenhall et al. 2020], ob denotes oneblob encoding ], sph denotes a conversion to spherical coordinates, normalized to the interval [0, 1] 2 , and id is the identity.\n\n\nParameter\n\nSymbol with Encoding\nPosition x \u2208 R 3 freq(x) \u2208 R 3\u00d712 Scattered dir. \u2208 2 ob(sph( )) \u2208 R 2\u00d74 Surface normal n(x) \u2208 2 ob(sph(n(x))) \u2208 R 2\u00d74 Surface roughness (x, ) \u2208 R ob 1 \u2212 \u2212 (x, ) \u2208 R 4 Diffuse reflectance (x, ) \u2208 R 3 id( (x, )) \u2208 R 3 Specular reflectance (x, ) \u2208 R 3 id( (x, )) \u2208 R 3\nrelation to the scattered radiance. For these quantities, a well-chosen encoding to a higher-dimensional space can make the relation more linear and thereby make the neural approximation more accurate. 3 The extra dimensions do not come for free, as they increase the required memory traffic as well as the cost of the first layer of the neural network. We thus aim at encoding the quantities x, , n, and using as few as possible extra dimensions while still profiting from the linearization.\n\nTo this end, the one-blob encoding ] works well when the scale of the nonlinearities is about the same order of magnitude as the size of the blobs. This is a good fit for , n, and as tiny variations in these parameters typically do not change the scattered radiance much. We thus encode them using a very small number (e.g. = 4) of evenly spaced blobs.\n\nHowever, tiny changes in the position x can cause large variation in the scattered radiance, e.g. along shadow and geometric boundaries or in outdoor environments that are much larger than the view frustum. One-blob encoding is therefore unsuitable for robustly encoding the position within just a few extra dimensions. Instead, we adopt the frequency encoding from transformer networks [Vaswani et al. 2017], introduced to radiance learning by Mildenhall et al. [2020], that leverages a geometric hierarchy of periodic functions to represent a high dynamic range of values in few encoded dimensions. We use 12 sine functions, each with frequency 2 , \u2208 {0, . . . , 11}. To save on dimensions, we found that omitting the cosine terms of the original method does not compromise approximation quality.\n\nIn summary, the input of our neural network is a concatenation of the following: the frequency-encoded position x, the one-blob encoded parameters , n, and , and the raw diffuse albedo and specular reflectance ; see Table 1 for a detailed breakdown. This results in a total of 62 input dimensions to the neural network, which we pad to 64 for compatibility with the hardware matrixmultiplication accelerator. We pad with a value of 1, which allows the network to implicitly learn a bias term (the corresponding columns of the first weight matrix) even though our architecture lacks explicit biases. 128 element wide chunks that are each processed by their own thread block. Since our MLP is narrow ( hidden = in = 64 neurons wide), its weight matrices fit into registers and the intermediate 64 \u00d7 128 neuron activations fit into shared memory. This is key to the superior performance of the fully fused approach.\n\n(c) The matrix multiplication performed by each thread block transforms the -th layer into the pre-activated next layer \u2032 +1 . It is diced into blocks of 16 \u00d7 16 elements to match the size of our hardware-accelerated half-precision matrix multiplier (TensorCore). Each warp of the thread block computes one 16 \u00d7 128 block-row of \u2032 +1 (e.g. the striped area) by first loading the corresponding 16 \u00d7 64 striped weights from into registers and subsequently multiplying them by all 64 \u00d7 16 block-columns of . Thus, each thread block loads the weight matrix from global memory exactly once (the least possible amount), making multiple passes only over which, however, is located in fast shared memory. We compare the throughput of training (left) and inference (right) for a 64 (solid line) and a 128 (dashed line) neurons wide multi-layer perceptron. The relevant batch sizes for our goal of neural radiance caching are small training batches (e.g. 2 14 elements) and large inference batches (e.g. 2 21 elements for evaluating a 1920 \u00d7 1080 frame). For these batch sizes, the speed-up over TensorFlow ranges from 5\u00d7 to 10\u00d7.\n\n\nFULLY FUSED NEURAL NETWORKS\n\nWe implemented our neural network from scratch in a GPU programming language in order to take full advantage of the GPU memory hierarchy. In Figure 7, we compare the performance of this implementation to TensorFlow (v2.5.0) [Abadi et al. 2015], which we outperform by almost an order of magnitude. To understand where this dramatic speedup comes from, we examine the bottleneck of evaluating a fully connected neural network like ours. The computational cost of such a neural network scales quadratically with its width, whereas its memory traffic scales linearly. Modern GPUs have vastly larger computational throughput than they have memory bandwidth, though, meaning that for narrow neural networks like ours, the linear memory traffic is the bottleneck. The key to improving performance is thus to minimize traffic to slow \"global\" memory (VRAM and high-level caches) and to fully utilize fast on-chip memory (low-level caches, \"shared\" memory, and registers).\n\nOur fully fused approach does precisely this: we implement the entire neural network as a single GPU kernel that is designed such that the only slow global memory accesses are reading and writing the network inputs and outputs. Furthermore, implementing the kernel from scratch as opposed to building it out of existing frameworks allows us to specifically tailor the implementation to the network architecture and the GPU that we use. Figure 6 illustrates how the fully fused approach is mapped to the memory hierarchy. Using CUDA terminology: a given batch of input vectors is partitioned into block-column segments that are processed by a single thread block each (Figure 6(b)). The thread blocks independently evaluate the network by alternating between weight-matrix multiplication and element-wise application of the activation function. By making the thread blocks small enough such that all intermediate neuron activations fit into on-chip shared memory, traffic to slow global memory is minimized. This is the key advantage of the fully fused approach and stands in contrast to typical implementations of general matrix multiplication.\n\nWithin a matrix multiplication (Figure 6(c)), each warp of the thread block computes the matrix product of a single block-row (striped area). In our case, the striped weights in are few enough to fit into the registers of the warp and can thus be re-used for every block of \u2032 +1 that the warp computes, yielding an additional performance gain. Furthermore, since each warp loads a distinct block-row of the weight matrix, the entire thread block loads the weight matrix from global memory exactly once, which cannot be reduced further. The only possible remaining reduction of global memory traffic is thus to minimize the number of thread blocks by making them as large as fits into shared memory. On our hardware (NVIDIA RTX 3090) and with our 64-neurons-wide network, this sweet-spot is met when each thread block processes 128 elements of the batch. Each thread block thus computes matrix products of a 64 \u00d7 64 weight matrix with a 64 \u00d7 128 chunk of the data.\n\nTraining the fully fused neural network. For training, the forward and backward passes admit the same matrix multiplication structure as the previously discussed inference pass. However, they require additional global-memory traffic, because intermediate activations and their gradients must be written out for backpropagation. Furthermore, additional matrix multiplications are necessary to turn the results of backpropagation into the gradients of the weight matrices. We compute these additional matrix multiplications using the general matrix multiplication (GEMM) routines of the CUTLASS template library (in split-k mode) as we were unable to produce a faster implementation ourselves.\n\nAll these additional operations make training slower than inference by a factor of roughly 4\u00d7-5\u00d7; see Figure 7.\n\n\nPRACTICAL CONSIDERATIONS\n\nArchitecture. Our fully fused neural network architecture (see Figure 6) comprises of seven fully connected layers. The five hidden layers have 64 neurons each with ReLU activation functions. The output layer reduces the 64 dimensions to three RGB values. None of the layers has a bias vector, as biases did not result in any measurable quality benefit and omitting them makes the fully fused implementation simpler and more efficient. Note that the neural network is shallow enough for vanishing gradients not to be a problem. Hence there is no need for residual layers using skip links to help training, which we confirmed experimentally. Reflectance factorization. To improve textured colors reproduction, we multiply the network output by the sum of the diffuse albedo and specular reflectance (x, ) + (x, ). For Lambertian materials, this amounts to irradiance factorization [Ward et al. 1988], and the network is effectively tasked with learning irradiance as opposed to reflected radiance. However, even in our highly non-Lambertian scenes, the above factorization is helpful. The factorization is not necessary to recover sharp detail-(x, ) and (x, ) are input to the network in any case-but it helps recover colors while letting the cache focus on complementary details; see Figure 8.\n\nHigh-performance primitives for encoding. The one-blob and frequency encodings rely on primitives that are computationally expensive: Gaussian kernels and trigonometric functions. We thus replace the primitives with approximations that are far cheaper to evaluate. Specifically, we replace the Gaussian with a quartic kernel and the sine function with a triangle wave as illustrated in Figure 9, reducing the cost per frame by 0.25 ms with no visible loss of quality.\n\nRelative loss. To facilitate effective training, we use the relative L 2 loss that admits unbiased gradient estimates when the training signal-the reflected radiance s (x, )-is noisy [Lehtinen et al. 2018]. The loss is normalized by the neural prediction:\nL 2 s (x, ), s (x, ; ) := s (x, ) \u2212 s (x, ; ) 2 sg s (x, ; ) 2 + ,(5)\nwhere = 0.01 and sg( \u00b7 ) denotes that its argument is treated as a constant in the optimization, i.e. no gradient is propagated back. Furthermore, for spectral values of s (x, ), we normalize the loss of each color channel by the squared luminance across the spectrum.\n\nOptimizer. The choice of optimizer is crucial to effectively leverage the little training data we have per frame. To this end, we compared multiple first-order optimizers, i.e. stochastic gradient descent (SGD), Adam [Kingma and Ba 2014], and Novograd [Ginsburg et al. 2019]) and found that Adam converges in the fewest iterations while having an overhead of practically zero.\n\nWe also investigated a second order optimizer, Shampoo [Anil et al. 2020;Gupta et al. 2018], which converges with slightly fewer iterations than Adam. However, the 0.3 milliseconds per-frame overhead of our optimized implementation did not justify its benefit in our experiments. We thus use Adam in all results.  Fig. 10. We demonstrate the benefit of our neural radiance cache (NRC) in 1 spp real-time renderings with varied material and lighting complexity. From left to right: our baseline is unbiased path tracing with Russian roulette and next-event estimation driven by a light BVH [Moreau et al. 2019]. Then, we add spatiotemporal reservoir resampling (ReSTIR) [Bitterli et al. 2020] for low-variance direct and NRC for low-variance indirect illumination. Individually, these complementary techniques excel in their respective domains (e.g. ReSTIR in the directly lit Bistro and NRC in the glossy Zero Day scene), but their combination unlocks the biggest improvement. Together, the three techniques reduce the mean relative squared error (MRSE) of path tracing by 1-2 orders of magnitude while incurring a comparatively little performance loss thanks to the drastic path shortening of NRC. In all scenes, the combined technique exceeds 60 frames per second at a resolution of 1920 \u00d7 1080. We also report the perceptually based FLIP metric that is more robust to outliers (\"fireflies\"). \n\n\nRESULTS AND DISCUSSION\n\nWe implemented all components of our neural radiance cache in CUDA, i.e. input encoding, the fully fused network, and the optimizer, the source code of which we release publically [M\u00fcller 2021]. The radiance cache is integrated into a path tracer implemented in Direct3D 12 using the Falcor rendering framework [Benty et al. 2020] with which we generated all results in this paper. All images were rendered at a resolution of 1920 \u00d7 1080 on a high-end desktop machine (i9 9900k and RTX 3090). For each image, we report the mean relative squared error (MRSE) [Rousselle et al. 2011] or its decomposition into relative bias (rBias) and variance (rVar) to aid the reader in gauging the improved Monte Carlo efficiency. When applicable, we also list the perceptually based FLIP metric [Andersson et al. 2020] that is more robust to outliers (\"fireflies\"). Our reference images were created using ReSTIR-enabled path tracing to ensure that we only measure the bias caused by radiance caching and not that of ReSTIR.\n\nReal-time rendering. In Figure 10, we utilize neural radiance caching (NRC) to reduce indirect illumination noise of a path tracer. By combining NRC with complementary direct-lighting techniques, we get global illumination with both low noise and little bias in real-time.\n\nOur baseline is an unbiased path tracer with Russian roulette and next-event estimation driven by a light BVH [Moreau et al. 2019], to which we add screen-space spatiotemporal reservoir resampling (ReSTIR) [Bitterli et al. 2020]. While this algorithm has low variance in its direct lighting estimates (PT+ReSTIR column), it suffers from noisy estimates of indirect lighting, which can be remedied by terminating paths into our cache (PT+ReSTIR+NRC column). Shortening the paths in this way not only results in lower variance but sometimes also in higher framerates due to the low overhead of querying and training the fully fused network.\n\nCompared with path tracing, the combination of ReSTIR and NRC reduces the MRSE by 1-2 orders of magnitude while having a comparatively small impact on performance. In all scenes, the combined technique exceeds 60 frames per second.\n\nWe measure our speedup in Table 2 by letting the baseline converge to equal MRSE as a single rendered frame of our method. The average speedup across the test scenes is 13.6\u00d7.  . 11. Self-training enables efficient learning of indirect radiance that is not captured by short paths: compare the left and middle images, both of which trace paths of the same length (including the sparse set of unbiased training paths described in Section 5). On the right, we provide a reference image obtained by tracing paths that are truncated with Russian roulette.\n\nSelf-training. We compare the performance of self-training to training relying on pure path-tracing. Terminating training paths with our termination heuristic, we set the tail contribution either to black (path-traced training) or to the radiance prediction at the last vertex (self-training). As shown in Figure 11, the self-trained solution accurately captures multi-bounce light transport. The computational overhead of self-training amounts to the cost of querying the radiance cache one additional time for each of the few training paths, which amounts roughly to a 1% overall overhead-a small amount compared with the cost that is saved by not having to trace longer paths to learn global illumination.\n\nQuality of the cache. In Figure 12, we study the quality of the neural radiance cache by visualizing it at the first non-specular vertex. By being agnostic to the materials and geometry of the underlying scenes, the cache handles a wide range of visual phenomena. For example, it handles complex glossy transport in the Zero Day scene, shadow detail at a distance in the Bistro scene, and thin geometry without light leakage, such as the tarp in the Attic scene. The cache also performs well at capturing the overall color of almost every region in each scene.\n\nThe limitations of the cache are twofold. First, the cache does not capture sharp detail very well if that detail is absent from the inputs to the network (e.g. a sharp contact shadow or caustic). And second, the cache exhibits subtle axis-aligned stripes that are a byproduct of the frequency encoding [Mildenhall et al. 2020 12. Converged renderings when querying the cache at the first non-specular vertex, or according to the path termination heuristic. We measure accuracy using the objective relative square bias metric, and the perceptual FLIP metric [Andersson et al. 2020]. The Zero Day scene features complex area lighting, glossy materials, and high-order indirect illumination due to the high albedo of surfaces. The Bistro scene features small geometry and shadow details in a relatively large environment, highlighting the local adaptation afforded by the encoding of the network inputs. The Attic scene is an interesting test case for light leakage as it features a fairly high geometric complexity, including thin elements such as the tarp. In all three scenes, employing the termination heuristic leads to a high quality result that closely resembles the reference image. In particular, the heuristic recovers contact shadows and local ambient occlusion, whereas other real-time caching techniques typically require an additional screen-space ambient occlusion (SSAO) pass to recover these details.\n\nthe frequency encoding to handle a spatial detail at scale (e.g. the accurate far-away shadows in the Bistro scene), we cannot simply switch to a different encoding. All other encodings that we tried either exhibited worse artifacts or did not scale well. Thus, to mask away the remaining cache inaccuracies, we defer its evaluation according to the termination heuristic from Section 3.4. Since the heuristic is based on the path footprint, the cache artifacts are observed through rough reflections and therefore averaged out. The heuristic also leads to fewer cache queries in concavities, where contact-shadow inaccuracies could become an issue. The insets in Figure 12 confirm this observation: combined with the termination heuristic, the cache produces images that are difficult to distinguish from the ground truth, both visually and numerically.\n\nComparison with dynamic diffuse global illumination (DDGI). In Figure 13 we compare the neural cache to DDGI [Majercik et al. 2019]. DDGI is a modern extension of irradiance probes, relying on modulation by the surface normal and albedo to approximate the scattered radiance. As a consequence, DDGI works best on Lambertian materials, which is why we show results using both a Lambertian diffuse BSDF model as well as the more physically based Frostbite model [Lagarde and de Rousiers 2014] that our scenes were modeled with.\n\nDDGI makes an aggressive trade-off for performance and low noise: paths are terminated into the irradiance probes at their first diffuse interaction (as opposed to glossy or specular), which is frequently the primary vertex. Consequently, DDGI is on one hand very performant (paths are short) and has little noise, but on the other hand lacks ambient occlusion and can expose visible bias (e.g. in the Pink Room) due to its limited spatial resolution.\n\nWith NRC, we make the opposite trade-off. We minimize bias at the cost of slightly reduced performance and (sometimes much) more noise. In contrast to DDGI, our neural representation makes no assumptions about the underlying material model, and our path termination criterion helps to avoid the remaining inaccuracies of NRC while also recovering ambient occlusion. The larger cost of our model could thus be offset by the cost of the separate ambient occlusion pass that DDGI requires.  (converged, right trapezoid) to allow for the visual inspection of the bias-variance trade-off. We also report relative bias (rBias) and variance (rVar). DDGI achieves the least variance and runs fastest at the cost of sometimes incurring strong bias, e.g. around problematic geometry in the Pink Room. NRC has much lower bias, however incurring a moderately higher variance and cost. Note that contact shadows and ambient occlusion are implicitly built into NRC via the path termination heuristic, whereas DDGI lacks these visual features, necessitating an additional render pass in practice. Performance breakdown. In Table 3, we analyze the time spent in DDGI and NRC in more detail. We break down the rendering cost into (i) path tracing & shading, (ii) querying the cache/DDGI, and (iii) training the cache/DDGI.\n\nCompared to the PT+ReSTIR baseline, the low path-tracing cost of DDGI and NRC arises from tracing fewer rays: in addition to Russian roulette, DDGI terminates its paths when a diffuse lobe is sampled, and NRC terminates each path according to its footprint. On average, both methods reduce the cost of path tracing by a similar amount of roughly 2.8 ms per frame (25%). However, this improvement is partially offset by the overhead of querying and training or updating the respective caches.\n\nAs expected, querying DDGI is faster than querying our neural network. However, given the reputation of neural networks to be expensive, the difference is smaller than what might be expected: A full-frame DDGI query costs on average 0.58 ms, whereas the neural radiance cache costs 1.59 ms. Both methods are thus well within reasonable cost for real-time settings.\n\nMost interestingly, training the neural radiance cache is cheaper than training the DDGI volume (1.11 ms vs. 1.37 ms on average). This has two reasons. First, NRC is very data efficient, using only 2 16 = 65536 training records per frame. On the other hand, DDGI in our 16 \u00d7 16 \u00d7 16 probe-grid configuration traces 16 3 \u00b7 256 = 1048576 update rays per frame-more than 10 times as many as NRC. Second, the few training paths that are traced for NRC share their first couple of vertices with the paths that need to be traced for rendering anyway, further saving cost.\n\n\nDISCUSSION AND FUTURE WORK\n\nPrecomputation. While we do not perform any precomputation, it could be incorporated by e.g. pre-training a good initial state of the neural network or by utilizing a low-overhead meta-learning technique [Hospedales et al. 2020]. In our design, we consider precomputation as strictly optional and merely to enhance the performance when possible. In fact, as the neural radiance cache rapidly learns the current situation (8 frames are sufficient, see Figure 4), precomputation can be only of limited benefit. Still, it is of interest to explore the utility of static sets of neural network weights and to determine the bounds of the domain of validity of a fixed set of neural network weights.\n\nCache artifacts. While we were able to suppress high-frequency temporal flickering using an exponential moving average over the optimized network weights, subtle low-frequency scintillation remains. Additionally, the frequency encoding causes distracting axisaligned oscillations throughout space. These artifacts are imperceptible when using the neural radiance cache at non-primary path vertices, but in some use cases (e.g. when noise is not an option), using the cache at the primary vertex would be desirable. To this end future work is needed to stabilize the prediction in a visually pleasing manner.\n\nAdditional network inputs. Input encodings alone are not sufficient to learn a detailed, high-frequency representation of features in the scattered radiance that correlate poorly with all of the network inputs. Examples of such features are shadows and caustics, which are unrelated to the local surface attributes that we can easily pass to the network. Shadows and caustics are therefore learned at a much slower rate-or not at all, if the network is too small or the radiance estimates are too noisy. It is thus very interesting to think about additional, simple-to-compute network inputs that correlate well with such features.\n\nOffline rendering. While our neural cache design focuses on realtime rendering, we believe its use of self-training would be beneficial in offline scenarios. Indeed, it allows to capture high-order indirect illumination without the costly tracing and shading of long paths; this could be particularly useful to tackle path-length limitations of batch rendering [Burley et al. 2018].\n\nVolumes. We note that our neural cache parameterization is not tied to a surface representation and can thus also be used in volumetric rendering. A straightforward implementation yields promising results (see Figure 14), but an in-depth investigation needs to be carried out. 14. Neural radiance caching also works in volumetric rendering. We render at 1 spp and report MRSE (left number) and frames per second. Illumination enters the room through a narrow slit in the ceiling and the volume has an isotropic phase function. There is one single neural radiance cache for the scene. For volume queries, undefined parameters (surface roughness, normal, albedo, and specular coefficients) are simply set to default constants.\n\nPath guiding. The main source of noise in our results is the indirect use of the cache. While the indirection results in decreased bias, it also leads to increased variance due to the (hemi-)spherical sampling, even though the cache approximation itself is noise-free. One could consider bringing neural importance sampling ] to real-time applications; as with our neural radiance cache, the cost appears prohibitive at first, yet applying similar principles may prove successful.\n\nImproved path termination. More accurate approximations of the anisotropic area spreads, such as covariance tracing [Belcour et al. 2013] or bundle coherence [Meng et al. 2015], could be used. While we did not encounter specific failure modes of the isotropic approximation of Bekaert et al., scenes with strong anisotropic lighting effects would likely benefit from the aforementioned methods.\n\nAn additional challenge that goes beyond the choice of areaspread approximation is the lack of path termination in long, branching, specular chains of interactions. Consequently, our cache currently provides little benefit when transport is dominated by dielectric materials such as glass, as seen in Figure 15. An improvement of the termination heuristic in such cases, as well as a more accurate cache to resolve sharp specular details, is of high interest. To alleviate this, we believe that a combination with path guiding as well as an improved path termination criterion should be investigated in the future.\n\nDenoising. Our neural radiance cache could be considered a pathspace denoiser, as it effectively performs a regression over spatiotemporal samples to produce noise-free approximations. In Figure 16, we demonstrate that this path-space denoising complements existing screen-space techniques. This preliminary experiment employed an off-the-shelf denoiser that was trained on data not representative of our method, so we expect a tighter coupling of our cache and the denoiser to offer potential for further improvements.\n\n\nCONCLUSION\n\nWe have introduced a real-time neural radiance caching technique for path-traced global illumination. It can handle dynamic content while providing predictable performance and resource consumption, which is enabled by our fully fused neural networks that achieve generalization via online adaptation. While the necessary performance requires a lot of engineering, robustness comes as a collateral. The resulting high rendering quality makes up for the cost of the neural radiance cache, and could be further improved through orthogonal variance reduction techniques such as by path guiding.\n\nThe neural radiance cache is a rather different approach to realtime rendering than previous techniques. It could be characterized as wasteful in terms of compute-some neurons have little impact on the output, yet their contribution is still evaluated. Competing techniques with sophisticated data structures could be characterized as wasteful in terms of memory-the memory is never used in its entirety as queries access only small (random) neighborhoods.  [Hasselgren et al. 2020]. Despite being trained on datasets with noise characteristics much different from our algorithm, the denoiser produces the cleanest results on it, achieving the lowest relative squared bias (left number). Even with denoising enabled, the framerate of our method stays well above 30.\n\nThe neural radiance cache employs fixed function hardware (the GPU tensor cores), and heavily relies on cheap computation, instead of costly memory accesses. This efficiency is reflected in the timings of Table 3, where our neural approach is only twice as expensive as irradiance probes, despite requiring a comparatively massive amount of compute (both implementations are reasonably well optimized). We posit this compute efficiency is the key ingredient of the neural cache robustness. This paradigm-cheap computeappears to be worth investigating [Dally et al. 2020], and we hope it inspires further experiments in applications where compute is typically considered a precious commodity.\n\nFig. 6 .\n6(a) Evaluating a multi-layer perceptron (MLP) for a large batch of inputs (e.g. \u2248 2 21 for a 1920 \u00d7 1080 frame) amounts to alternating weight-matrix multiplication and element-wise application of the activation function. (b) In our fully fused MLP, we parallelize this workload by partitioning the batch into\n\nFig. 7 .\n7Our fully fused neural network outperforms an equivalent XLAenabled TensorFlow (v2.5.0) implementation. Both implementations utilize half precision floating point numbers and TensorCore hardware for matrix multiplication.\n\nmod 2 \u2212\u2212 1 Fig. 9 .\n2191| To avoid expensive mathematical operations, we replace the Gaussian kernel of the one-blob encoding by a quartic kernel and the sine function in the frequency encoding by a triangle wave. With these replacements, the cost per frame is reduced by 0.25ms with no visible loss of quality.\n\nTable 1 .\n1Parameters and their encoding, amounting to 62 dimensions: freq denotes frequency encoding\n\n\nVisualization of factored neural radiance cache at primary vertexRadiance cache Radiance cache = Prediction \u00d7 ReflectanceDirect prediction \nFactorization \n\nFig. 8. Reflectance factorization leads to more accurate textured colors and \nlets the neural prediction focus on complementary detail such as glossy \nhighlights. Note that sharp texture detail is also present when predicting \nthe product, because the reflectance is input to the network in any case. \n\n\n\nTable 2 .\n2Time to converge to equal MRSE.Scene \nMethod \nFrames \nTime MRSE Speedup \n\nAttic \n\nPT+ReSTIR \n7 \n92.5 ms 2.739 \n6.6\u00d7 \nPT+ReSTIR+NRC \n1 \n14.0 ms 2.727 \n\nBistro \n\nPT+ReSTIR \n8 \n110.7 ms 1.498 \n7.6\u00d7 \nPT+ReSTIR+NRC \n1 \n14.6 ms 1.407 \n\nClassroom \n\nPT+ReSTIR \n145 \n2625 ms 5.882 172.7\u00d7 \nPT+ReSTIR+NRC \n1 \n15.2 ms 5.847 \n\nLiving Room \n\nPT+ReSTIR \n53 \n431.5 ms 1.379 49.6\u00d7 \nPT+ReSTIR+NRC \n1 \n8.7 ms 1.376 \n\nPink Room \n\nPT+ReSTIR \n10 \n66.9 ms 0.769 \n8.4\u00d7 \nPT+ReSTIR+NRC \n1 \n8.0 ms 0.765 \n\nZero Day \n\nPT+ReSTIR \n5 \n69.4 ms 3.799 \n6.1\u00d7 \nPT+ReSTIR+NRC \n1 \n11.3 ms 3.430 \n\nAverage \n\nPT+ReSTIR \n16.6 \n154.1 ms 2.037 13.6\u00d7 \nPT+ReSTIR+NRC \n1 \n11.3 ms 1.941 \n\n\n\n\n]. Since we rely ons at heuristic hit \ns at 1 st non-specular hit \ns at heuristic hit \nReference \n\nZero Day \n\nrBias 2 : \n0.3433 \n0.0014 \nFLIP: \n0.1948 \n0.0439 \n\nBistro \n\nrBias 2 : \n0.8447 \n0.0016 \nFLIP: \n0.2290 \n0.0401 \n\nAttic \n\nrBias 2 : \n0.1104 \n0.0017 \nFLIP: \n0.1885 \n0.0479 \n\nFig. \n\n\nFig. 13. Comparison of NRC with DDGI under challenging indirect illumination. Both methods use ReSTIR for direct illumination. Since DDGI caches radiance as an extension of irradiance probes, its implementation assumes a Lambertian diffuse BRDF model and recovers detail through surface normal and albedo modulation. As our scenes were modeled using the Frostbite model[Lagarde and de Rousiers 2014], we show results with both the Frostbite (left) and the Lambertian (right) model. DDGI performs at its best on the Lambertian material that it was designed for, whereas NRC-being agnostic to the BSDF-performs similarly in all situations. For each method, we show results at 1spp (left trapezoid) and 1024sppFrostbite diffuse \nLambertian diffuse (exposure \u00d70.5) \n\nDDGI \nNRC \nReference \nDDGI \nNRC \nReference \n\nZero Day \n\nrVar: 1.917, rBias 2 : 0.057 rVar: 3.757, rBias 2 : 0.006 \nrVar: 1.187, rBias 2 : 0.118 rVar: 3.349, rBias 2 : 0.005 \n96.7 fps \n87.7 fps \n96.8 fps \n86.3 fps \n\nLiving Room \n\nrVar: 0.589, rBias 2 : 0.174 rVar: 0.950, rBias 2 : 0.003 \nrVar: 0.178, rBias 2 : 0.264 rVar: 0.522, rBias 2 : 0.006 \n134 fps \n111 fps \n134 fps \n111 fps \n\nPink Room \n\nrVar: 0.394, rBias 2 : 3.836 rVar: 1.087, rBias 2 : 0.002 \nrVar: 0.232, rBias 2 : 0.542 rVar: 1.297, rBias 2 : 0.008 \n141 fps \n124 fps \n144 fps \n124 fps \n\n\n\nTable 3 .\n3Breakdown of rendering cost by component.Scene \nMethod \nTrace & shade Query Training \n\nAttic \n\nPT+ReSTIR \n12.96 ms \n-\n-\nPT+ReSTIR+DDGI \n11.56 ms 0.64 ms 1.78 ms \nPT+ReSTIR+NRC \n10.88 ms 1.66 ms 1.12 ms \n\nBistro \n\nPT+ReSTIR \n13.75 ms \n-\n-\nPT+ReSTIR+DDGI \n12.71 ms 0.65 ms 1.68 ms \nPT+ReSTIR+NRC \n11.96 ms 1.38 ms 1.11 ms \n\nClassroom \n\nPT+ReSTIR \n18.06 ms \n-\n-\nPT+ReSTIR+DDGI \n12.93 ms 0.59 ms 1.65 ms \nPT+ReSTIR+NRC \n12.28 ms 1.70 ms 1.11 ms \n\nLiving Room \n\nPT+ReSTIR \n8.32 ms \n-\n-\nPT+ReSTIR+DDGI \n5.68 ms 0.52 ms 0.99 ms \nPT+ReSTIR+NRC \n5.82 ms 1.85 ms 1.11 ms \n\nPink Room \n\nPT+ReSTIR \n6.73 ms \n-\n-\nPT+ReSTIR+DDGI \n5.56 ms 0.52 ms 0.89 ms \nPT+ReSTIR+NRC \n5.36 ms 1.54 ms 1.12 ms \n\nZero Day \n\nPT+ReSTIR \n13.89 ms \n-\n-\nPT+ReSTIR+DDGI \n8.34 ms 0.54 ms 1.21 ms \nPT+ReSTIR+NRC \n8.67 ms 1.41 ms 1.09 ms \n\nAverage \n\nPT+ReSTIR \n12.29 ms \n-\n-\nPT+ReSTIR+DDGI \n9.46 ms 0.58 ms 1.37 ms \nPT+ReSTIR+NRC \n9.16 ms 1.59 ms 1.11 ms \n\n\n\n\nFig. 15. 32 spp rendering of the Bistro scene, of which we report MRSE (left number) and render time. The improvement by neural radiance caching is marginal, because it does not address complex, branching specular transport.Path tracing \n+ ReSTIR \n+ NRC (Ours) \nReference \n\nPath tracing \n+ ReSTIR \n+ NRC (Ours) \nReference \n2.79 / 192 ms \n2.45 / 320 ms \n2.10 / 379 ms \n\n\n\n\nFig. 16. The Living Room scene from the teaser image at 1 spp, passed through a deep-learning based real-time denoiserDenoised PT \n+ ReSTIR \n+ NRC (Ours) \nReference \n\nDenoised PT \n+ ReSTIR \n+ NRC (Ours) \nReference \n0.0440 / 59 fps \n0.0268 / 46 fps \n0.0105 / 45 fps \n\n\nEach step uses a disjoint random subset of the training data that was gathered while rendering the frame to prevent the same data from being seen twice.\nThis is analogous to the \"kernel trick\" that is often employed in machine learning to make the data linearly separable[Theodoridis 2008].\nReal-time Neural Radiance Caching for Path Tracing \u2022 36:13\nACKNOWLEDGMENTSThe article is dedicated to our dear friend and colleague Jaroslav K\u0159iv\u00e1nek. The authors thank Nikolaus Binder for his early contributions to the high performance neural networks. Zander Majercik assisted us for the DDGI comparison, and Simon Kallweit contributed to the Falcor integration.\nMart\u00edn Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S Corrado, Andy Davis, Jeffrey Dean, TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems. Mart\u00edn Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado, Andy Davis, Jeffrey Dean, et al. 2015. TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems. http://tensorflow.org/\n\nQuake's lighting model: Surface caching. Michael Abrash, Graphics Programming Black Book. Coriolis Group. 68Michael Abrash. 1997. Quake's lighting model: Surface caching. In Graphics Program- ming Black Book. Coriolis Group, Chapter 68, 1245-1256.\n\nFLIP: A Difference Evaluator for Alternating Images. Pontus Andersson, Jim Nilsson, Tomas Akenine-M\u00f6ller, Magnus Oskarsson, Kalle \u00c5str\u00f6m, Mark D Fairchild, 10.1145/3406183Proc. ACM Comput. Graph. Interact. Tech. 315Pontus Andersson, Jim Nilsson, Tomas Akenine-M\u00f6ller, Magnus Oskarsson, Kalle \u00c5str\u00f6m, and Mark D. Fairchild. 2020. FLIP: A Difference Evaluator for Alternating Images. Proc. ACM Comput. Graph. Interact. Tech. 3, 2, Article 15 (Aug. 2020), 23 pages. https://doi.org/10.1145/3406183\n\nSecond Order Optimization Made Practical. Rohan Anil, Vineet Gupta, Tomer Koren, Kevin Regan, Yoram Singer, arXiv:2002.09018Rohan Anil, Vineet Gupta, Tomer Koren, Kevin Regan, and Yoram Singer. 2020. Second Order Optimization Made Practical. arXiv:2002.09018 (Feb. 2020).\n\nPublication date. Real-time Neural Radiance Caching for Path Tracing. 4015ACM Trans. Graph., Vol. 40, No. 4, Article 36. Publication date: August 2021. Real-time Neural Radiance Caching for Path Tracing \u2022 36:15\n\nBackward Ray Tracing. James Arvo, ACM SIGGRAPH '86 Course Notes -Developments in Ray Tracing. James Arvo. 1986. Backward Ray Tracing. In In ACM SIGGRAPH '86 Course Notes - Developments in Ray Tracing. 259-263.\n\nA Certain Slant of Light: Past, Present and Future Challenges of Global Illumination in Games. Colin Barr\u00e9-Brisebois, Open problems in real-time rendering. ACM SIGGRAPH 2017 Courses. Colin Barr\u00e9-Brisebois. 2017. A Certain Slant of Light: Past, Present and Future Chal- lenges of Global Illumination in Games. In Open problems in real-time rendering. ACM SIGGRAPH 2017 Courses.\n\nA custom designed Density Estimation Method for Light Transport. Philippe Bekaert, Philipp Slusallek, Ronald Cools, Vlastimil Havran, Hans-Peter Seidel, Max-Planck; Saarbr\u00fccken, GermanyInstitut f\u00fcr InformatikTechnical ReportPhilippe Bekaert, Philipp Slusallek, Ronald Cools, Vlastimil Havran, and Hans-Peter Seidel. 2003. A custom designed Density Estimation Method for Light Transport. Technical Report. Max-Planck-Institut f\u00fcr Informatik, Saarbr\u00fccken, Germany.\n\n5D Covariance Tracing for Efficient Defocus and Motion Blur. Laurent Belcour, Cyril Soler, Kartic Subr, Nicolas Holzschuch, Fredo Durand, 10.1145/2487228.2487239ACM Trans. Graph. 3231Laurent Belcour, Cyril Soler, Kartic Subr, Nicolas Holzschuch, and Fredo Durand. 2013. 5D Covariance Tracing for Efficient Defocus and Motion Blur. ACM Trans. Graph. 32, 3, Article Article 31 (July 2013), 18 pages. https://doi.org/10.1145/2487228.2487239\n\nThe Falcor Rendering Framework. Nir Benty, Kai-Hwa Yao, Petrik Clarberg, Lucy Chen, Simon Kallweit, Tim Foley, Matthew Oakes, Conor Lavelle, Chris Wyman, Nir Benty, Kai-Hwa Yao, Petrik Clarberg, Lucy Chen, Simon Kallweit, Tim Foley, Matthew Oakes, Conor Lavelle, and Chris Wyman. 2020. The Falcor Rendering Framework. https://github.com/NVIDIAGameWorks/Falcor https://github.com/ NVIDIAGameWorks/Falcor.\n\nFast Path Space Filtering by Jittered Spatial Hashing. Nikolaus Binder, Sascha Fricke, Alexander Keller, 10.1145/3214745.3214806ACM SIGGRAPH 2018 Talks (SIGGRAPH '18). New York, NY, USA, ArticleAssociation for Computing Machinery71Nikolaus Binder, Sascha Fricke, and Alexander Keller. 2018. Fast Path Space Filtering by Jittered Spatial Hashing. In ACM SIGGRAPH 2018 Talks (SIGGRAPH '18). Association for Computing Machinery, New York, NY, USA, Article 71, 2 pages. https://doi.org/ 10.1145/3214745.3214806\n\nSpatiotemporal reservoir resampling for real-time ray tracing with dynamic direct lighting. Benedikt Bitterli, Chris Wyman, Matt Pharr, Peter Shirley, Aaron Lefohn, Wojciech Jarosz, ACM Transactions on Graphics (Proceedings of SIGGRAPH). 394Benedikt Bitterli, Chris Wyman, Matt Pharr, Peter Shirley, Aaron Lefohn, and Wojciech Jarosz. 2020. Spatiotemporal reservoir resampling for real-time ray tracing with dynamic direct lighting. ACM Transactions on Graphics (Proceedings of SIGGRAPH) 39, 4 (July 2020). https://doi.org/10/gg8xc7\n\nThe Design and Evolution of Disney's Hyperion Renderer. Brent Burley, David Adler, Matt Jen-Yuan Chiang, Hank Driskill, Ralf Habel, Patrick Kelly, Peter Kutz, Yining Karl Li, Daniel Teece, 10.1145/3182159ACM Trans. Graph. 37Brent Burley, David Adler, Matt Jen-Yuan Chiang, Hank Driskill, Ralf Habel, Patrick Kelly, Peter Kutz, Yining Karl Li, and Daniel Teece. 2018. The Design and Evolution of Disney's Hyperion Renderer. ACM Trans. Graph. 37, 3, Article 33 (July 2018), 22 pages. https://doi.org/10.1145/3182159\n\nInteractive Indirect Illumination Using Voxel Cone Tracing. Cyril Crassin, Fabrice Neyret, Miguel Sainz, Simon Green, Elmar Eisemann, http:/arxiv.org/abs/https:/onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-8659.2011.02063.xComputer Graphics Forum. 30Cyril Crassin, Fabrice Neyret, Miguel Sainz, Simon Green, and Elmar Eisemann. 2011. Interactive Indirect Illumination Using Voxel Cone Tracing. Computer Graphics Forum 30, 7 (2011), 1921-1930. https://doi.org/10.1111/j.1467-8659.2011.02063.x arXiv:https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-8659.2011.02063.x\n\nReflective Shadow Maps. Carsten Dachsbacher, Marc Stamminger, 10.1145/1053427.1053460Proceedings of the 2005 Symposium on Interactive 3D Graphics and Games (I3D '05). the 2005 Symposium on Interactive 3D Graphics and Games (I3D '05)New York, NY, USAAssociation for Computing MachineryCarsten Dachsbacher and Marc Stamminger. 2005. Reflective Shadow Maps. In Pro- ceedings of the 2005 Symposium on Interactive 3D Graphics and Games (I3D '05). Association for Computing Machinery, New York, NY, USA, 203-231. https: //doi.org/10.1145/1053427.1053460\n\nLearning Light Transport the Reinforced Way. Ken Dahm, Alexander Keller, Monte Carlo and Quasi-Monte Carlo Methods, Art B. Owen and Peter W. GlynnSpringer International PublishingKen Dahm and Alexander Keller. 2018. Learning Light Transport the Reinforced Way. In Monte Carlo and Quasi-Monte Carlo Methods, Art B. Owen and Peter W. Glynn (Eds.). Springer International Publishing, 181-195.\n\nDomain-Specific Hardware Accelerators. William J Dally, Yatish Turakhia, Song Han, 10.1145/3361682Commun. ACM. 63William J. Dally, Yatish Turakhia, and Song Han. 2020. Domain-Specific Hardware Accelerators. Commun. ACM 63, 7 (June 2020), 48-57. https://doi.org/10.1145/ 3361682\n\nIt Just Works\" Ray-Traced Reflections in 'Battlefield V. Johannes Deligiannis, Game Developers Conference. Johannes Deligiannis and Jan Schmid. 2019. \"It Just Works\" Ray-Traced Reflections in 'Battlefield V'. In Game Developers Conference.\n\nTemporal Sample Reuse for Next Event Estimation and Path Guiding for Real-Time Path Tracing. Addis Dittebrandt, Johannes Hanika, Carsten Dachsbacher, 10.2312/sr.20201135Eurographics Symposium on Rendering -DL-only Track. Carsten Dachsbacher and Matt PharrThe Eurographics AssociationAddis Dittebrandt, Johannes Hanika, and Carsten Dachsbacher. 2020. Temporal Sample Reuse for Next Event Estimation and Path Guiding for Real-Time Path Tracing. In Eurographics Symposium on Rendering -DL-only Track, Carsten Dachsbacher and Matt Pharr (Eds.). The Eurographics Association. https://doi.org/10.2312/sr.20201135\n\nFrequency Based Radiance Cache for Rendering Animations. Adrien Renaud, Laurent Dubouchet, Derek Belcour, Nowrouzezahrai, Proceedings of the Eurographics Symposium on Rendering: Experimental Ideas & Implementations (EGSR '17). the Eurographics Symposium on Rendering: Experimental Ideas & Implementations (EGSR '17)Renaud Adrien Dubouchet, Laurent Belcour, and Derek Nowrouzezahrai. 2017. Fre- quency Based Radiance Cache for Rendering Animations. In Proceedings of the Euro- graphics Symposium on Rendering: Experimental Ideas & Implementations (EGSR '17).\n\n. 10.2312/sre.20171193Eurographics Association. Eurographics Association, Goslar, DEU, 41-53. https://doi.org/10.2312/sre.20171193\n\nBoris Ginsburg, Patrice Castonguay, Oleksii Hrinchuk, Oleksii Kuchaiev, Vitaly Lavrukhin, Ryan Leary, Jason Li, Huyen Nguyen, Jonathan M Cohen, arXiv:1905.11286Stochastic Gradient Methods with Layer-wise Adaptive Moments for Training of Deep Networks. Boris Ginsburg, Patrice Castonguay, Oleksii Hrinchuk, Oleksii Kuchaiev, Vitaly Lavrukhin, Ryan Leary, Jason Li, Huyen Nguyen, and Jonathan M. Cohen. 2019. Stochastic Gradient Methods with Layer-wise Adaptive Moments for Training of Deep Networks. arXiv:1905.11286 (June 2019).\n\nThe irradiance volume. Gene Greger, Peter Shirley, Philip M Hubbard, Donald P Greenberg, IEEE Computer Graphics and Applications. 18Gene Greger, Peter Shirley, Philip M. Hubbard, and Donald P. Greenberg. 1998. The irradiance volume. IEEE Computer Graphics and Applications 18, 2 (1998), 32-43.\n\nVineet Gupta, Tomer Koren, Yoram Singer, arXiv:1802.09568Shampoo: Preconditioned Stochastic Tensor Optimization. Vineet Gupta, Tomer Koren, and Yoram Singer. 2018. Shampoo: Preconditioned Sto- chastic Tensor Optimization. arXiv:1802.09568 (Aug. 2018).\n\nNeural Temporal Adaptive Sampling and Denoising. Jon Hasselgren, Jacob Munkberg, Marco Salvi, Anjul Patney, Aaron Lefohn, http:/arxiv.org/abs/https:/onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.13919Computer Graphics Forum. 39Jon Hasselgren, Jacob Munkberg, Marco Salvi, Anjul Patney, and Aaron Lefohn. 2020. Neural Temporal Adaptive Sampling and Denoising. Computer Graphics Forum 39, 2 (2020), 147-155. https://doi.org/10.1111/cgf.13919 arXiv:https://onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.13919\n\nAdaptive Radiosity Textures for Bidirectional Ray Tracing. S Paul, Heckbert, 10.1145/97880.97895SIGGRAPH Comput. Graph. 24Paul S. Heckbert. 1990. Adaptive Radiosity Textures for Bidirectional Ray Tracing. SIGGRAPH Comput. Graph. 24, 4 (Sept. 1990), 145-154. https://doi.org/10.1145/ 97880.97895\n\nA Unified Manifold Framework for Efficient BRDF Sampling based on Parametric Mixture Models. Sebastian Herholz, Oskar Elek, Jens Schindel, Jaroslav K\u0159iv\u00e1nek, Hendrik P A Lensch, Eurographics Symposium on Rendering -Experimental Ideas & Implementations. Wenzel Jakob and Toshiya HachisukaThe Eurographics AssociationSebastian Herholz, Oskar Elek, Jens Schindel, Jaroslav K\u0159iv\u00e1nek, and Hendrik P. A. Lensch. 2018. A Unified Manifold Framework for Efficient BRDF Sampling based on Parametric Mixture Models. In Eurographics Symposium on Rendering -Experi- mental Ideas & Implementations, Wenzel Jakob and Toshiya Hachisuka (Eds.). The Eurographics Association.\n\nProduct Importance Sampling for Light Transport Path Guiding. Sebastian Herholz, Oskar Elek, Ji\u0159\u00ed Vorba, Hendrik Lensch, Jaroslav K\u0159iv\u00e1nek, 10.1111/cgf.12950Computer Graphics Forum. Sebastian Herholz, Oskar Elek, Ji\u0159\u00ed Vorba, Hendrik Lensch, and Jaroslav K\u0159iv\u00e1nek. 2016. Product Importance Sampling for Light Transport Path Guiding. Computer Graphics Forum (2016). https://doi.org/10.1111/cgf.12950\n\nDeeplearning the Latent Space of Light Transport. Pedro Hermosilla, Sebastian Maisch, Tobias Ritschel, Timo Ropinski, Computer Graphics Forum. 384Pedro Hermosilla, Sebastian Maisch, Tobias Ritschel, and Timo Ropinski. 2019. Deep- learning the Latent Space of Light Transport. Computer Graphics Forum 38, 4 (2019).\n\nVolumetric Global Illumination at Treyarch. John T Hooker, Advances in real-time rendering, part I. ACM SIGGRAPH 2016 Courses. John T. Hooker. 2016. Volumetric Global Illumination at Treyarch. In Advances in real-time rendering, part I. ACM SIGGRAPH 2016 Courses.\n\nTimothy Hospedales, Antreas Antoniou, Paul Micaelli, Amos Storkey, arXiv:2004.05439Meta-Learning in Neural Networks: A Survey. Timothy Hospedales, Antreas Antoniou, Paul Micaelli, and Amos Storkey. 2020. Meta- Learning in Neural Networks: A Survey. arXiv:2004.05439 (April 2020).\n\nPrecomputed Lighting in Call of Duty: Infinite Warfare. Micha\u0142 Iwanicki, Peter-Pike Sloan, Advances in Real-Time Rendering, Part I. ACM SIGGRAPHMicha\u0142 Iwanicki and Peter-Pike Sloan. 2017. Precomputed Lighting in Call of Duty: Infinite Warfare. In Advances in Real-Time Rendering, Part I (ACM SIGGRAPH 2017\n\nAssociation for Computing Machinery. Courses, 10.1145/3084873.3096476New York, NY, USA, ArticleCourses). Association for Computing Machinery, New York, NY, USA, Article 7a, 1 pages. https://doi.org/10.1145/3084873.3096476\n\nAveraging Weights Leads to Wider Optima and Better Generalization. Pavel Izmailov, Dmitrii Podoprikhin, Timur Garipov, Dmitry Vetrov, Andrew Gordon Wilson, arXiv:1803.05407Pavel Izmailov, Dmitrii Podoprikhin, Timur Garipov, Dmitry Vetrov, and Andrew Gor- don Wilson. 2018. Averaging Weights Leads to Wider Optima and Better General- ization. arXiv:1803.05407 (March 2018).\n\nRadiance Caching for Participating Media. Wojciech Jarosz, Craig Donner, Matthias Zwicker, Henrik Wann Jensen, 10.1145/1330511.1330518ACM Trans. Graph. 277Wojciech Jarosz, Craig Donner, Matthias Zwicker, and Henrik Wann Jensen. 2008. Radiance Caching for Participating Media. ACM Trans. Graph. 27, 1, Article 7 (March 2008), 11 pages. https://doi.org/10.1145/1330511.1330518\n\nImportance Driven Path Tracing using the Photon Map. Henrik Wann Jensen, 10.1007/978-3-7091-9430-0_31Rendering Techniques. Vienna, ViennaSpringerHenrik Wann Jensen. 1995. Importance Driven Path Tracing using the Photon Map. In Rendering Techniques. Springer Vienna, Vienna, 326-335. https://doi.org/10.1007/ 978-3-7091-9430-0_31\n\nGlobal Illumination using Photon Maps. Henrik Wann Jensen, Rendering Techniques '96. Xavier Pueyo and Peter Schr\u00f6derVienna, ViennaSpringerHenrik Wann Jensen. 1996. Global Illumination using Photon Maps. In Rendering Techniques '96, Xavier Pueyo and Peter Schr\u00f6der (Eds.). Springer Vienna, Vienna, 21-30.\n\nDeep radiance caching: Convolutional autoencoders deeper in ray tracing. Giulio Jiang, Bernhard Kainz, 10.1016/j.cag.2020.09.007Computers & Graphics. 94Giulio Jiang and Bernhard Kainz. 2021. Deep radiance caching: Convolutional au- toencoders deeper in ray tracing. Computers & Graphics 94 (2021), 22 -31. https://doi.org/10.1016/j.cag.2020.09.007\n\nThe Rendering Equation. James T Kajiya, Computer Graphics. 20James T. Kajiya. 1986. The Rendering Equation. Computer Graphics 20 (1986), 143-150.\n\nDeep Scattering: Rendering Atmospheric Clouds with Radiance-Predicting Neural Networks. Simon Kallweit, Thomas M\u00fcller, Brian Mcwilliams, Markus Gross, 10.1145/3130800.3130880ACM Trans. Graph. 36231Simon Kallweit, Thomas M\u00fcller, Brian McWilliams, Markus Gross, and Jan Nov\u00e1k. 2017. Deep Scattering: Rendering Atmospheric Clouds with Radiance-Predicting Neural Networks. ACM Trans. Graph. 36, 6, Article 231 (Nov. 2017), 11 pages. https://doi.org/10.1145/3130800.3130880\n\nCascaded Light Propagation Volumes for Real-Time Indirect Illumination. Anton Kaplanyan, Carsten Dachsbacher, 10.1145/1730804.1730821Proceedings of the 2010 ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games (I3D '10). the 2010 ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games (I3D '10)New York, NY, USAAssociation for Computing MachineryAnton Kaplanyan and Carsten Dachsbacher. 2010. Cascaded Light Propagation Volumes for Real-Time Indirect Illumination. In Proceedings of the 2010 ACM SIGGRAPH Sym- posium on Interactive 3D Graphics and Games (I3D '10). Association for Computing Machinery, New York, NY, USA, 99-107. https://doi.org/10.1145/1730804.1730821\n\nInstant Radiosity. Alexander Keller, 10.1145/258734.258769Proceedings of the 24th Annual Conference on Computer Graphics and Interactive Techniques (SIGGRAPH '97). the 24th Annual Conference on Computer Graphics and Interactive Techniques (SIGGRAPH '97)USAACM Press/Addison-Wesley Publishing CoAlexander Keller. 1997. Instant Radiosity. In Proceedings of the 24th Annual Conference on Computer Graphics and Interactive Techniques (SIGGRAPH '97). ACM Press/Addison- Wesley Publishing Co., USA, 49-56. https://doi.org/10.1145/258734.258769\n\nAlexander Keller, Ken Dahm, Integral Equations and Machine Learning. 161Alexander Keller and Ken Dahm. 2019. Integral Equations and Machine Learning. Mathematics and Computers in Simulation 161 (2019), 2-12.\n\nAre We Done with Ray Tracing. Alexander Keller, Timo Viitanen, Colin Barr\u00e9-Brisebois, Christoph Schied, Morgan Mcguire, 10.1145/3305366.3329896ACM SIGGRAPH 2019 Courses (SIGGRAPH '19). New York, NY, USA, ArticleAssociation for Computing MachineryAlexander Keller, Timo Viitanen, Colin Barr\u00e9-Brisebois, Christoph Schied, and Morgan McGuire. 2019. Are We Done with Ray Tracing?. In ACM SIGGRAPH 2019 Courses (SIGGRAPH '19). Association for Computing Machinery, New York, NY, USA, Article 3, 381 pages. https://doi.org/10.1145/3305366.3329896\n\nAdam: A Method for Stochastic Optimization. P Diederik, Jimmy Kingma, Ba, arXiv:1412.6980Diederik P. Kingma and Jimmy Ba. 2014. Adam: A Method for Stochastic Optimization. arXiv:1412.6980 (June 2014).\n\nPractical Global Illumination with Irradiance Caching. Jaroslav K\u0159iv\u00e1nek, Pascal Gautron, Morgan & ClaypoolJaroslav K\u0159iv\u00e1nek and Pascal Gautron. 2009. Practical Global Illumination with Irradiance Caching. Morgan & Claypool.\n\nRadiance caching for efficient global illumination computation. Jaroslav K\u0159iv\u00e1nek, Pascal Gautron, Sumanta Pattanaik, Kadi Bouatouch, IEEE Transactions on Visualization and Computer Graphics. 11Jaroslav K\u0159iv\u00e1nek, Pascal Gautron, Sumanta Pattanaik, and Kadi Bouatouch. 2005. Radiance caching for efficient global illumination computation. IEEE Transactions on Visualization and Computer Graphics 11, 5 (2005), 550-561.\n\nA 5D Tree to Reduce the Variance of Monte Carlo Ray Tracing. Eric P Lafortune, Yves D Willems, Proc. EGWR. EGWREric P. Lafortune and Yves D. Willems. 1995. A 5D Tree to Reduce the Variance of Monte Carlo Ray Tracing. In Proc. EGWR. 11-20.\n\nMoving Frostbite to Physically Based Rendering 3.0. S\u00e9bastien Lagarde, Charles De Rousiers, 10.1145/2614028.2615431ACM SIGGRAPH Courses: Physically Based Shading in Theory and Practice. New York, NY, USAACMS\u00e9bastien Lagarde and Charles de Rousiers. 2014. Moving Frostbite to Physically Based Rendering 3.0. In ACM SIGGRAPH Courses: Physically Based Shading in Theory and Practice, Chapter 10 (SIGGRAPH '14). ACM, New York, NY, USA. https://doi.org/10. 1145/2614028.2615431\n\nJaakko Lehtinen, Jacob Munkberg, Jon Hasselgren, Samuli Laine, Tero Karras, Miika Aittala, Timo Aila, arXiv:1803.04189Noise2Noise: Learning Image Restoration without Clean Data. Jaakko Lehtinen, Jacob Munkberg, Jon Hasselgren, Samuli Laine, Tero Karras, Miika Aittala, and Timo Aila. 2018. Noise2Noise: Learning Image Restoration without Clean Data. arXiv:1803.04189 (March 2018).\n\nDynamic Diffuse Global Illumination with Ray-Traced Irradiance Fields. Zander Majercik, Jean-Philippe Guertin, Derek Nowrouzezahrai, Morgan Mcguire, Journal of Computer Graphics Techniques (JCGT). 85Zander Majercik, Jean-Philippe Guertin, Derek Nowrouzezahrai, and Morgan McGuire. 2019. Dynamic Diffuse Global Illumination with Ray-Traced Irradiance Fields. Journal of Computer Graphics Techniques (JCGT) 8, 2 (5 June 2019), 1-30. http: //jcgt.org/published/0008/02/01/\n\nSecond-Order Occlusion-Aware Volumetric Radiance Caching. Julio Marco, Adrian Jarabo, Wojciech Jarosz, Diego Gutierrez, 10.1145/3185225ACM Trans. Graph. 37Julio Marco, Adrian Jarabo, Wojciech Jarosz, and Diego Gutierrez. 2018. Second-Order Occlusion-Aware Volumetric Radiance Caching. ACM Trans. Graph. 37, 2, Article 20 (July 2018), 14 pages. https://doi.org/10.1145/3185225\n\nA Real-Time Radiosity Architecture for Video Games. Sam Martin, Per Einarsson, SIGGRAPH 2010 Course: Advances in Real-Time Rendering in 3D Graphics and Games. Sam Martin and Per Einarsson. 2010. A Real-Time Radiosity Architecture for Video Games. SIGGRAPH 2010 Course: Advances in Real-Time Rendering in 3D Graphics and Games.\n\nReal-Time Global Illumination Using Precomputed Light Field Probes. Morgan Mcguire, Mike Mara, Derek Nowrouzezahrai, David Luebke, 10.1145/3023368.3023378Proceedings of the 21st ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games (I3D '17). the 21st ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games (I3D '17)New York, NY, USA, Article 2Association for Computing Machinery11Morgan McGuire, Mike Mara, Derek Nowrouzezahrai, and David Luebke. 2017. Real- Time Global Illumination Using Precomputed Light Field Probes. In Proceedings of the 21st ACM SIGGRAPH Symposium on Interactive 3D Graphics and Games (I3D '17). Association for Computing Machinery, New York, NY, USA, Article 2, 11 pages. https://doi.org/10.1145/3023368.3023378\n\nMulti-Scale Modeling and Rendering of Granular Materials. Johannes Meng, Marios Papas, Ralf Habel, Carsten Dachsbacher, Steve Marschner, Markus Gross, Wojciech Jarosz, ACM Transactions on Graphics (Proceedings of SIGGRAPH). 344Johannes Meng, Marios Papas, Ralf Habel, Carsten Dachsbacher, Steve Marschner, Markus Gross, and Wojciech Jarosz. 2015. Multi-Scale Modeling and Rendering of Granular Materials. ACM Transactions on Graphics (Proceedings of SIGGRAPH) 34, 4 (July 2015). https://doi.org/10/gfzndr\n\nNeRF: Representing Scenes as Neural Radiance Fields for View Synthesis. Ben Mildenhall, P Pratul, Matthew Srinivasan, Jonathan T Tancik, Ravi Barron, Ren Ramamoorthi, Ng, ECCV. Ben Mildenhall, Pratul P. Srinivasan, Matthew Tancik, Jonathan T. Barron, Ravi Ra- mamoorthi, and Ren Ng. 2020. NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis. In ECCV.\n\nFinding next Gen: CryEngine 2. Martin Mittring, 10.1145/1281500.1281671ACM SIGGRAPH 2007 Courses (SIGGRAPH '07). New York, NY, USAAssociation for Computing MachineryMartin Mittring. 2007. Finding next Gen: CryEngine 2. In ACM SIGGRAPH 2007 Courses (SIGGRAPH '07). Association for Computing Machinery, New York, NY, USA, 97-121. https://doi.org/10.1145/1281500.1281671\n\nDynamic Many-Light Sampling for Real-Time Ray Tracing. Pierre Moreau, Matt Pharr, Petrik Clarberg, 10.2312/hpg.20191191High-Performance Graphics 2019 -Short Papers. Markus Steinberger and Tim FoleyStrasbourg, FranceEurographics AssociationPierre Moreau, Matt Pharr, and Petrik Clarberg. 2019. Dynamic Many-Light Sampling for Real-Time Ray Tracing. In High-Performance Graphics 2019 -Short Papers, Stras- bourg, France, July 8-10, 2019, Markus Steinberger and Tim Foley (Eds.). Eurographics Association, 21-26. https://doi.org/10.2312/hpg.20191191\n\nTiny CUDA Neural Network Framework. Thomas M\u00fcller, Thomas M\u00fcller. 2021. Tiny CUDA Neural Network Framework. https://github.com/nvlabs/tiny-cuda-nn.\n\nPractical Path Guiding for Efficient Light-Transport Simulation. Thomas M\u00fcller, Markus Gross, 10.1111/cgf.13227Computer Graphics Forum. 364Thomas M\u00fcller, Markus Gross, and Jan Nov\u00e1k. 2017. Practical Path Guiding for Efficient Light-Transport Simulation. Computer Graphics Forum 36, 4 (June 2017), 91-100. https://doi.org/10.1111/cgf.13227\n\nNeural Importance Sampling. Thomas M\u00fcller, Brian Mcwilliams, Fabrice Rousselle, Markus Gross, 10.1145/3341156ACM Trans. Graph. 38145Thomas M\u00fcller, Brian McWilliams, Fabrice Rousselle, Markus Gross, and Jan Nov\u00e1k. 2019. Neural Importance Sampling. ACM Trans. Graph. 38, 5, Article 145 (Oct. 2019), 19 pages. https://doi.org/10.1145/3341156\n\nNeural Control Variates. Thomas M\u00fcller, Fabrice Rousselle, Alexander Keller, 10.1145/3414685.3417804ACM Trans. Graph. 39243Thomas M\u00fcller, Fabrice Rousselle, Alexander Keller, and Jan Nov\u00e1k. 2020. Neural Control Variates. ACM Trans. Graph. 39, 6, Article 243 (Nov. 2020), 19 pages. https: //doi.org/10.1145/3414685.3417804\n\nOliver Nalbach, Elena Arabadzhiyska, Dushyant Mehta, Hans-Peter Seidel, Tobias Ritschel, Deep Shading: Convolutional Neural Networks for Screen-Space Shading. 364Oliver Nalbach, Elena Arabadzhiyska, Dushyant Mehta, Hans-Peter Seidel, and Tobias Ritschel. 2017. Deep Shading: Convolutional Neural Networks for Screen-Space Shading. 36, 4 (2017).\n\nIrradiance Volumes for Games. Christopher Oat, Game Developers Conference. Christopher Oat. 2005. Irradiance Volumes for Games. In Game Developers Conference.\n\nOnline path sampling control with progressive spatio-temporal filtering. Jacopo Pantaleoni, arXiv:2005.07547Jacopo Pantaleoni. 2020. Online path sampling control with progressive spatio-temporal filtering. arXiv:2005.07547 (May 2020).\n\nClustered Pre-Convolved Radiance Caching. Hauke Rehfeld, Tobias Zirr, Carsten Dachsbacher, Proceedings of the 14th Eurographics Symposium on Parallel Graphics and Visualization (PGV '14). the 14th Eurographics Symposium on Parallel Graphics and Visualization (PGV '14)Goslar, DEUHauke Rehfeld, Tobias Zirr, and Carsten Dachsbacher. 2014. Clustered Pre-Convolved Radiance Caching. In Proceedings of the 14th Eurographics Symposium on Parallel Graphics and Visualization (PGV '14). Eurographics Association, Goslar, DEU, 25-32.\n\nGlobal Illumination with Radiance Regression Functions. Peiran Ren, Jiaping Wang, Minmin Gong, Stephen Lin, Xin Tong, Baining Guo, 10.1145/2461912.2462009ACM Trans. Graph. 32ArticlePeiran Ren, Jiaping Wang, Minmin Gong, Stephen Lin, Xin Tong, and Baining Guo. 2013. Global Illumination with Radiance Regression Functions. ACM Trans. Graph. 32, 4, Article 130 (July 2013), 12 pages. https://doi.org/10.1145/2461912.2462009\n\nThe State of the Art in Interactive Global Illumination. Tobias Ritschel, Carsten Dachsbacher, Thorsten Grosch, http:/arxiv.org/abs/https:/onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-8659.2012.02093.xComputer Graphics Forum. 31Tobias Ritschel, Carsten Dachsbacher, Thorsten Grosch, and Jan Kautz. 2012. The State of the Art in Interactive Global Illumination. Computer Graphics Fo- rum 31, 1 (2012), 160-188. https://doi.org/10.1111/j.1467-8659.2012.02093.x arXiv:https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-8659.2012.02093.x\n\nMicro-Rendering for Scalable, Parallel Final Gathering. Tobias Ritschel, Thomas Engelhardt, Thorsten Grosch, Hans-Peter Seidel, Jan Kautz, Carsten Dachsbacher, 10.1145/1618452.1618478ACM Trans. Graph. 28Tobias Ritschel, Thomas Engelhardt, Thorsten Grosch, Hans-Peter Seidel, Jan Kautz, and Carsten Dachsbacher. 2009a. Micro-Rendering for Scalable, Parallel Final Gathering. ACM Trans. Graph. 28, 5 (Dec. 2009), 1-8. https://doi.org/10.1145/1618452.1618478\n\nImperfect Shadow Maps for Efficient Computation of Indirect Illumination. Tobias Ritschel, Thorsten Grosch, Min H Kim, Hans-Peter Seidel, Carsten Dachsbacher, 10.1145/1409060.1409082ACM Trans. Graph. 27129Tobias Ritschel, Thorsten Grosch, Min H. Kim, Hans-Peter Seidel, Carsten Dachsbacher, and Jan Kautz. 2008. Imperfect Shadow Maps for Efficient Computation of Indirect Illumination. ACM Trans. Graph. 27, 5, Article 129 (Dec. 2008), 8 pages. https: //doi.org/10.1145/1409060.1409082\n\nApproximating Dynamic Global Illumination in Image Space. Tobias Ritschel, Thorsten Grosch, Hans-Peter Seidel, 10.1145/1507149.1507161Proceedings of the 2009 Symposium on Interactive 3D Graphics and Games (I3D '09). the 2009 Symposium on Interactive 3D Graphics and Games (I3D '09)New York, NY, USAAssociation for Computing MachineryTobias Ritschel, Thorsten Grosch, and Hans-Peter Seidel. 2009b. Approximating Dy- namic Global Illumination in Image Space. In Proceedings of the 2009 Symposium on Interactive 3D Graphics and Games (I3D '09). Association for Computing Machinery, New York, NY, USA, 75-82. https://doi.org/10.1145/1507149.1507161\n\nAdaptive Sampling and Reconstruction Using Greedy Error Minimization. Fabrice Rousselle, Claude Knaus, Matthias Zwicker, 10.1145/2070781.2024193ACM Trans. Graph. 30159Fabrice Rousselle, Claude Knaus, and Matthias Zwicker. 2011. Adaptive Sampling and Reconstruction Using Greedy Error Minimization. ACM Trans. Graph. 30, 6, Article 159 (Dec. 2011), 12 pages. https://doi.org/10.1145/2070781.2024193\n\nPre-Convolved Radiance Caching. Daniel Scherzer, H Chuong, Tobias Nguyen, Hans-Peter Ritschel, Seidel, 10.1111/j.1467-8659.2012.03134.xComput. Graph. Forum. 31Daniel Scherzer, Chuong H. Nguyen, Tobias Ritschel, and Hans-Peter Seidel. 2012. Pre- Convolved Radiance Caching. Comput. Graph. Forum 31, 4 (June 2012), 1391-1397. https://doi.org/10.1111/j.1467-8659.2012.03134.x\n\nThe design and evolution of the UberBake light baking system. Dario Seyb, Peter-Pike Sloan, Ari Silvennoinen, Micha\u0142 Iwanicki, Wojciech Jarosz, ACM Transactions on Graphics (Proceedings of SIGGRAPH). 39Dario Seyb, Peter-Pike Sloan, Ari Silvennoinen, Micha\u0142 Iwanicki, and Wojciech Jarosz. 2020. The design and evolution of the UberBake light baking system. ACM Transac- tions on Graphics (Proceedings of SIGGRAPH) 39, 4 (July 2020).\n\nReal-Time Global Illumination by Precomputed Local Reconstruction from Sparse Radiance Probes. Ari Silvennoinen, Jaakko Lehtinen, 10.1145/3130800.3130852ACM Trans. Graph. 36230Ari Silvennoinen and Jaakko Lehtinen. 2017. Real-Time Global Illumination by Pre- computed Local Reconstruction from Sparse Radiance Probes. ACM Trans. Graph. 36, 6, Article 230 (Nov. 2017), 13 pages. https://doi.org/10.1145/3130800.3130852\n\nPrecomputed Radiance Transfer for Real-Time Rendering in Dynamic, Low-Frequency Lighting Environments. Peter-Pike Sloan, Jan Kautz, John Snyder, 10.1145/566570.566612Proceedings of the 29th Annual Conference on Computer Graphics and Interactive Techniques (SIGGRAPH '02). the 29th Annual Conference on Computer Graphics and Interactive Techniques (SIGGRAPH '02)New York, NY, USAAssociation for Computing MachineryPeter-Pike Sloan, Jan Kautz, and John Snyder. 2002. Precomputed Radiance Transfer for Real-Time Rendering in Dynamic, Low-Frequency Lighting Environments. In Proceedings of the 29th Annual Conference on Computer Graphics and Interactive Techniques (SIGGRAPH '02). Association for Computing Machinery, New York, NY, USA, 527-536. https://doi.org/10.1145/566570.566612\n\nSecrets of CryENGINE 3 Graphics Technology. Tiago Sousa, Nickolay Kasyan, Nicolas Schulz, Advances in Real-Time Rendering in Games: Part I. ACM SIGGRAPH 2011 Courses. Tiago Sousa, Nickolay Kasyan, and Nicolas Schulz. 2011. Secrets of CryENGINE 3 Graphics Technology. In Advances in Real-Time Rendering in Games: Part I. ACM SIGGRAPH 2011 Courses.\n\nAn Approximate Global Illumination System for Computer Generated Films. Eric Tabellion, Arnauld Lamorlette, 10.1145/1186562.1015748ACM SIGGRAPH 2004 Papers (SIGGRAPH '04). New York, NY, USAAssociation for Computing MachineryEric Tabellion and Arnauld Lamorlette. 2004. An Approximate Global Illumination System for Computer Generated Films. In ACM SIGGRAPH 2004 Papers (SIGGRAPH '04). Association for Computing Machinery, New York, NY, USA, 469-476. https: //doi.org/10.1145/1186562.1015748\n\nSergios Theodoridis, Pattern Recognition. ElsevierSergios Theodoridis. 2008. Pattern Recognition. Elsevier.\n\nReal-time Radiance Caching using Chrominance Compression. Kostas Vardis, Georgios Papaioannou, Anastasios Gkaravelis, Journal of Computer Graphics Techniques (JCGT). 34Kostas Vardis, Georgios Papaioannou, and Anastasios Gkaravelis. 2014. Real-time Radiance Caching using Chrominance Compression. Journal of Computer Graphics Techniques (JCGT) 3, 4 (16 December 2014), 111-131. http://jcgt.org/published/ 0003/04/06/\n\n. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, Lukasz Kaiser, Illia Polosukhin, arXiv:1706.03762Attention Is All You Need. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. 2017. Attention Is All You Need. arXiv:1706.03762 (June 2017).\n\nOptimally Combining Sampling Techniques for Monte Carlo Rendering. Eric Veach, Leonidas J Guibas, 10.1145/218380.218498Proc. SIGGRAPH. 419-428. SIGGRAPH. 419-428Eric Veach and Leonidas J. Guibas. 1995. Optimally Combining Sampling Techniques for Monte Carlo Rendering. In Proc. SIGGRAPH. 419-428. https://doi.org/10.1145/ 218380.218498\n\nPath Guiding in Production. Ji\u0159\u00ed Vorba, Johannes Hanika, Sebastian Herholz, Thomas M\u00fcller, Jaroslav K\u0159iv\u00e1nek, Alexander Keller, ACM SIGGRAPH Courses. Ji\u0159\u00ed Vorba, Johannes Hanika, Sebastian Herholz, Thomas M\u00fcller, Jaroslav K\u0159iv\u00e1nek, and Alexander Keller. 2019. Path Guiding in Production. In ACM SIGGRAPH Courses.\n\n. 10.1145/3305366.33280911-18:77ACM18New York, NY, USAACM, New York, NY, USA, 18:1-18:77. https://doi.org/10.1145/3305366.3328091\n\nOn-line Learning of Parametric Mixture Models for Light Transport Simulation. Ji\u0159\u00ed Vorba, Ond\u0159ej Karl\u00edk, Martin \u0160ik, Tobias Ritschel, Jaroslav K\u0159iv\u00e1nek, ACM Trans. Graph. 33Ji\u0159\u00ed Vorba, Ond\u0159ej Karl\u00edk, Martin \u0160ik, Tobias Ritschel, and Jaroslav K\u0159iv\u00e1nek. 2014. On-line Learning of Parametric Mixture Models for Light Transport Simulation. ACM Trans. Graph. 33, 4 (Aug. 2014).\n\nA Ray Tracing Solution for Diffuse Interreflection. Gregory J Ward, Francis M Rubinstein, Robert D Clear, 10.1145/54852.378490Proceedings of the 15th Annual Conference on Computer Graphics and Interactive Techniques (SIGGRAPH '88). the 15th Annual Conference on Computer Graphics and Interactive Techniques (SIGGRAPH '88)New York, NY, USAAssociation for Computing MachineryGregory J. Ward, Francis M. Rubinstein, and Robert D. Clear. 1988. A Ray Tracing Solution for Diffuse Interreflection. In Proceedings of the 15th Annual Conference on Computer Graphics and Interactive Techniques (SIGGRAPH '88). Association for Computing Machinery, New York, NY, USA, 85-92. https://doi.org/10.1145/54852. 378490\n\nView-Dependent Radiance Caching. Yangyang Zhao, Laurent Belcour, Derek Nowrouzezahrai, 10.20380/GI2019.22Proceedings of the 45th Graphics Interface Conference on Proceedings of Graphics Interface 2019 (GI'19). the 45th Graphics Interface Conference on Graphics Interface 2019 (GI'19)Waterloo, CAN, ArticleCanadian Human-Computer Communications Society22Yangyang Zhao, Laurent Belcour, and Derek Nowrouzezahrai. 2019. View-Dependent Radiance Caching. In Proceedings of the 45th Graphics Interface Conference on Proceed- ings of Graphics Interface 2019 (GI'19). Canadian Human-Computer Communications Society, Waterloo, CAN, Article 22, 9 pages. https://doi.org/10.20380/GI2019.22\n", "annotations": {"author": "[{\"end\":85,\"start\":71},{\"end\":104,\"start\":86},{\"end\":121,\"start\":105},{\"end\":139,\"start\":122}]", "publisher": null, "author_last_name": "[{\"end\":84,\"start\":78},{\"end\":103,\"start\":94},{\"end\":120,\"start\":115},{\"end\":138,\"start\":132}]", "author_first_name": "[{\"end\":77,\"start\":71},{\"end\":93,\"start\":86},{\"end\":114,\"start\":111},{\"end\":131,\"start\":122}]", "author_affiliation": null, "title": "[{\"end\":51,\"start\":1},{\"end\":190,\"start\":140}]", "venue": "[{\"end\":212,\"start\":192}]", "abstract": "[{\"end\":2826,\"start\":703}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b73\"},\"end\":3355,\"start\":3337},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":3398,\"start\":3376},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":3560,\"start\":3548},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":5060,\"start\":5036},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":5083,\"start\":5060},{\"attributes\":{\"ref_id\":\"b66\"},\"end\":5099,\"start\":5083},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":5473,\"start\":5451},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":5491,\"start\":5473},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":6617,\"start\":6593},{\"attributes\":{\"ref_id\":\"b85\"},\"end\":7511,\"start\":7493},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":7763,\"start\":7743},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":8087,\"start\":8067},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":8112,\"start\":8087},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":8399,\"start\":8377},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":8604,\"start\":8581},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":8622,\"start\":8604},{\"attributes\":{\"ref_id\":\"b86\"},\"end\":8638,\"start\":8622},{\"attributes\":{\"ref_id\":\"b79\"},\"end\":8762,\"start\":8743},{\"attributes\":{\"ref_id\":\"b74\"},\"end\":8818,\"start\":8786},{\"attributes\":{\"ref_id\":\"b65\"},\"end\":8872,\"start\":8851},{\"attributes\":{\"ref_id\":\"b72\"},\"end\":8893,\"start\":8872},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":8935,\"start\":8915},{\"attributes\":{\"ref_id\":\"b64\"},\"end\":8951,\"start\":8935},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":9189,\"start\":9178},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":9203,\"start\":9189},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":9447,\"start\":9435},{\"attributes\":{\"ref_id\":\"b63\"},\"end\":9496,\"start\":9487},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":9566,\"start\":9539},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":9691,\"start\":9670},{\"attributes\":{\"ref_id\":\"b75\"},\"end\":9776,\"start\":9757},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":9816,\"start\":9791},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":9835,\"start\":9816},{\"attributes\":{\"ref_id\":\"b73\"},\"end\":9994,\"start\":9977},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":10361,\"start\":10349},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":10397,\"start\":10385},{\"attributes\":{\"ref_id\":\"b77\"},\"end\":10449,\"start\":10418},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":10661,\"start\":10639},{\"attributes\":{\"ref_id\":\"b68\"},\"end\":10711,\"start\":10689},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":10796,\"start\":10775},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":10827,\"start\":10796},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":10946,\"start\":10913},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":11106,\"start\":11092},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":11153,\"start\":11131},{\"attributes\":{\"ref_id\":\"b76\"},\"end\":11189,\"start\":11171},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":11350,\"start\":11328},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":11402,\"start\":11373},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":12013,\"start\":11985},{\"end\":12031,\"start\":12025},{\"attributes\":{\"ref_id\":\"b84\"},\"end\":12273,\"start\":12254},{\"attributes\":{\"ref_id\":\"b82\"},\"end\":12458,\"start\":12439},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":12578,\"start\":12553},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":12647,\"start\":12627},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":12669,\"start\":12647},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":12713,\"start\":12695},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":13086,\"start\":13065},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":13180,\"start\":13156},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":13201,\"start\":13180},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":13222,\"start\":13201},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":13242,\"start\":13222},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":13288,\"start\":13266},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":13311,\"start\":13288},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":13330,\"start\":13311},{\"attributes\":{\"ref_id\":\"b66\"},\"end\":13345,\"start\":13330},{\"attributes\":{\"ref_id\":\"b66\"},\"end\":13421,\"start\":13404},{\"attributes\":{\"ref_id\":\"b80\"},\"end\":13934,\"start\":13915},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":14159,\"start\":14139},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":14193,\"start\":14169},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":14585,\"start\":14563},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":15023,\"start\":15011},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":16161,\"start\":16140},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":17337,\"start\":17316},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":17396,\"start\":17376},{\"attributes\":{\"ref_id\":\"b81\"},\"end\":17477,\"start\":17454},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":19194,\"start\":19176},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":19565,\"start\":19543},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":19586,\"start\":19565},{\"end\":20119,\"start\":20108},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":22779,\"start\":22757},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":23536,\"start\":23515},{\"attributes\":{\"ref_id\":\"b66\"},\"end\":29136,\"start\":29119},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":29906,\"start\":29883},{\"end\":30556,\"start\":30555},{\"attributes\":{\"ref_id\":\"b80\"},\"end\":31608,\"start\":31588},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":31670,\"start\":31646},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":34308,\"start\":34290},{\"attributes\":{\"ref_id\":\"b85\"},\"end\":38874,\"start\":38856},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":39944,\"start\":39923},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":40610,\"start\":40588},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":40787,\"start\":40769},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":40805,\"start\":40787},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":41322,\"start\":41303},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":41404,\"start\":41383},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":42328,\"start\":42316},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":42465,\"start\":42447},{\"attributes\":{\"ref_id\":\"b71\"},\"end\":42717,\"start\":42694},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":42939,\"start\":42917},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":43552,\"start\":43532},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":43650,\"start\":43628},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":46446,\"start\":46423},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":46700,\"start\":46678},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":48524,\"start\":48502},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":48882,\"start\":48853},{\"end\":49889,\"start\":49861},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":52362,\"start\":52339},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":54452,\"start\":54433},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":55801,\"start\":55780},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":55840,\"start\":55822},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":58283,\"start\":58260},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":59139,\"start\":59120},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":62036,\"start\":62006},{\"attributes\":{\"ref_id\":\"b78\"},\"end\":64811,\"start\":64794}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":59580,\"start\":59261},{\"attributes\":{\"id\":\"fig_1\"},\"end\":59813,\"start\":59581},{\"attributes\":{\"id\":\"fig_2\"},\"end\":60126,\"start\":59814},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":60229,\"start\":60127},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":60691,\"start\":60230},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":61346,\"start\":60692},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":61634,\"start\":61347},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":62951,\"start\":61635},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":63880,\"start\":62952},{\"attributes\":{\"id\":\"tab_10\",\"type\":\"table\"},\"end\":64252,\"start\":63881},{\"attributes\":{\"id\":\"tab_11\",\"type\":\"table\"},\"end\":64522,\"start\":64253}]", "paragraph": "[{\"end\":3211,\"start\":2842},{\"end\":3796,\"start\":3213},{\"end\":4689,\"start\":3798},{\"end\":5639,\"start\":4691},{\"end\":6062,\"start\":5641},{\"end\":6704,\"start\":6064},{\"end\":7095,\"start\":6706},{\"end\":7385,\"start\":7112},{\"end\":9028,\"start\":7387},{\"end\":10149,\"start\":9030},{\"end\":11913,\"start\":10151},{\"end\":12920,\"start\":11915},{\"end\":14683,\"start\":12922},{\"end\":15048,\"start\":14711},{\"end\":15787,\"start\":15103},{\"end\":15943,\"start\":15810},{\"end\":16210,\"start\":15945},{\"end\":16283,\"start\":16273},{\"end\":17616,\"start\":16285},{\"end\":18162,\"start\":17618},{\"end\":18556,\"start\":18164},{\"end\":19109,\"start\":18606},{\"end\":19587,\"start\":19111},{\"end\":20227,\"start\":19589},{\"end\":21172,\"start\":20229},{\"end\":21571,\"start\":21208},{\"end\":21823,\"start\":21573},{\"end\":22195,\"start\":21825},{\"end\":22496,\"start\":22235},{\"end\":22780,\"start\":22498},{\"end\":22911,\"start\":22782},{\"end\":23150,\"start\":22913},{\"end\":23503,\"start\":23171},{\"end\":23622,\"start\":23505},{\"end\":23944,\"start\":23695},{\"end\":23978,\"start\":23975},{\"end\":24519,\"start\":23980},{\"end\":25035,\"start\":24563},{\"end\":26113,\"start\":25037},{\"end\":26893,\"start\":26160},{\"end\":26898,\"start\":26895},{\"end\":27394,\"start\":26943},{\"end\":27564,\"start\":27396},{\"end\":27993,\"start\":27566},{\"end\":29603,\"start\":27995},{\"end\":30052,\"start\":29622},{\"end\":30086,\"start\":30066},{\"end\":30845,\"start\":30353},{\"end\":31199,\"start\":30847},{\"end\":31999,\"start\":31201},{\"end\":32913,\"start\":32001},{\"end\":34034,\"start\":32915},{\"end\":35030,\"start\":34066},{\"end\":36176,\"start\":35032},{\"end\":37141,\"start\":36178},{\"end\":37834,\"start\":37143},{\"end\":37947,\"start\":37836},{\"end\":39269,\"start\":37976},{\"end\":39738,\"start\":39271},{\"end\":39995,\"start\":39740},{\"end\":40334,\"start\":40066},{\"end\":40712,\"start\":40336},{\"end\":42109,\"start\":40714},{\"end\":43146,\"start\":42136},{\"end\":43420,\"start\":43148},{\"end\":44060,\"start\":43422},{\"end\":44293,\"start\":44062},{\"end\":44846,\"start\":44295},{\"end\":45556,\"start\":44848},{\"end\":46118,\"start\":45558},{\"end\":47535,\"start\":46120},{\"end\":48391,\"start\":47537},{\"end\":48918,\"start\":48393},{\"end\":49371,\"start\":48920},{\"end\":50678,\"start\":49373},{\"end\":51171,\"start\":50680},{\"end\":51537,\"start\":51173},{\"end\":52104,\"start\":51539},{\"end\":52828,\"start\":52135},{\"end\":53437,\"start\":52830},{\"end\":54070,\"start\":53439},{\"end\":54454,\"start\":54072},{\"end\":55180,\"start\":54456},{\"end\":55662,\"start\":55182},{\"end\":56058,\"start\":55664},{\"end\":56674,\"start\":56060},{\"end\":57195,\"start\":56676},{\"end\":57800,\"start\":57210},{\"end\":58567,\"start\":57802},{\"end\":59260,\"start\":58569}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":15102,\"start\":15049},{\"attributes\":{\"id\":\"formula_1\"},\"end\":16272,\"start\":16211},{\"attributes\":{\"id\":\"formula_2\"},\"end\":22234,\"start\":22196},{\"attributes\":{\"id\":\"formula_3\"},\"end\":23694,\"start\":23623},{\"attributes\":{\"id\":\"formula_4\"},\"end\":23974,\"start\":23945},{\"attributes\":{\"id\":\"formula_5\"},\"end\":26942,\"start\":26899},{\"attributes\":{\"id\":\"formula_6\"},\"end\":30352,\"start\":30087},{\"attributes\":{\"id\":\"formula_7\"},\"end\":40065,\"start\":39996}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":32224,\"start\":32217},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":44328,\"start\":44321},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":50488,\"start\":50481},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":58781,\"start\":58774}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2840,\"start\":2828},{\"attributes\":{\"n\":\"2\"},\"end\":7110,\"start\":7098},{\"attributes\":{\"n\":\"3\"},\"end\":14709,\"start\":14686},{\"attributes\":{\"n\":\"3.1\"},\"end\":15808,\"start\":15790},{\"attributes\":{\"n\":\"3.2\"},\"end\":18604,\"start\":18559},{\"attributes\":{\"n\":\"3.3\"},\"end\":21206,\"start\":21175},{\"attributes\":{\"n\":\"3.4\"},\"end\":23169,\"start\":23153},{\"attributes\":{\"n\":\"3.5\"},\"end\":24561,\"start\":24522},{\"end\":26158,\"start\":26116},{\"attributes\":{\"n\":\"3.6\"},\"end\":29620,\"start\":29606},{\"end\":30064,\"start\":30055},{\"attributes\":{\"n\":\"4\"},\"end\":34064,\"start\":34037},{\"attributes\":{\"n\":\"5\"},\"end\":37974,\"start\":37950},{\"attributes\":{\"n\":\"6\"},\"end\":42134,\"start\":42112},{\"attributes\":{\"n\":\"7\"},\"end\":52133,\"start\":52107},{\"attributes\":{\"n\":\"8\"},\"end\":57208,\"start\":57198},{\"end\":59270,\"start\":59262},{\"end\":59590,\"start\":59582},{\"end\":59834,\"start\":59815},{\"end\":60137,\"start\":60128},{\"end\":60702,\"start\":60693},{\"end\":62962,\"start\":62953}]", "table": "[{\"end\":60691,\"start\":60353},{\"end\":61346,\"start\":60735},{\"end\":61634,\"start\":61368},{\"end\":62951,\"start\":62344},{\"end\":63880,\"start\":63005},{\"end\":64252,\"start\":64107},{\"end\":64522,\"start\":64373}]", "figure_caption": "[{\"end\":59580,\"start\":59272},{\"end\":59813,\"start\":59592},{\"end\":60126,\"start\":59838},{\"end\":60229,\"start\":60139},{\"end\":60353,\"start\":60232},{\"end\":60735,\"start\":60704},{\"end\":61368,\"start\":61349},{\"end\":62344,\"start\":61637},{\"end\":63005,\"start\":62964},{\"end\":64107,\"start\":63883},{\"end\":64373,\"start\":64255}]", "figure_ref": "[{\"end\":6726,\"start\":6718},{\"end\":15922,\"start\":15914},{\"end\":16333,\"start\":16327},{\"end\":17956,\"start\":17948},{\"end\":20881,\"start\":20873},{\"end\":22495,\"start\":22487},{\"end\":22798,\"start\":22790},{\"end\":23303,\"start\":23295},{\"end\":23478,\"start\":23469},{\"end\":24404,\"start\":24396},{\"end\":25220,\"start\":25212},{\"end\":25571,\"start\":25565},{\"end\":26219,\"start\":26213},{\"end\":26973,\"start\":26967},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":34215,\"start\":34207},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":35476,\"start\":35468},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":35711,\"start\":35699},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":36218,\"start\":36209},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":37946,\"start\":37938},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":38047,\"start\":38039},{\"end\":39268,\"start\":39260},{\"end\":39665,\"start\":39657},{\"end\":41035,\"start\":41028},{\"end\":43181,\"start\":43172},{\"end\":44476,\"start\":44472},{\"end\":45163,\"start\":45154},{\"end\":45592,\"start\":45583},{\"end\":46449,\"start\":46447},{\"end\":48210,\"start\":48201},{\"end\":48465,\"start\":48456},{\"end\":52594,\"start\":52586},{\"end\":54675,\"start\":54666},{\"end\":56370,\"start\":56361},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":56873,\"start\":56864}]", "bib_author_first_name": "[{\"end\":65185,\"start\":65179},{\"end\":65199,\"start\":65193},{\"end\":65213,\"start\":65209},{\"end\":65228,\"start\":65222},{\"end\":65244,\"start\":65237},{\"end\":65256,\"start\":65251},{\"end\":65268,\"start\":65264},{\"end\":65270,\"start\":65269},{\"end\":65284,\"start\":65280},{\"end\":65299,\"start\":65292},{\"end\":65653,\"start\":65646},{\"end\":65913,\"start\":65907},{\"end\":65928,\"start\":65925},{\"end\":65943,\"start\":65938},{\"end\":65966,\"start\":65960},{\"end\":65983,\"start\":65978},{\"end\":65996,\"start\":65992},{\"end\":65998,\"start\":65997},{\"end\":66397,\"start\":66392},{\"end\":66410,\"start\":66404},{\"end\":66423,\"start\":66418},{\"end\":66436,\"start\":66431},{\"end\":66449,\"start\":66444},{\"end\":66862,\"start\":66857},{\"end\":67146,\"start\":67141},{\"end\":67497,\"start\":67489},{\"end\":67514,\"start\":67507},{\"end\":67532,\"start\":67526},{\"end\":67549,\"start\":67540},{\"end\":67568,\"start\":67558},{\"end\":67956,\"start\":67949},{\"end\":67971,\"start\":67966},{\"end\":67985,\"start\":67979},{\"end\":67999,\"start\":67992},{\"end\":68017,\"start\":68012},{\"end\":68362,\"start\":68359},{\"end\":68377,\"start\":68370},{\"end\":68389,\"start\":68383},{\"end\":68404,\"start\":68400},{\"end\":68416,\"start\":68411},{\"end\":68430,\"start\":68427},{\"end\":68445,\"start\":68438},{\"end\":68458,\"start\":68453},{\"end\":68473,\"start\":68468},{\"end\":68795,\"start\":68787},{\"end\":68810,\"start\":68804},{\"end\":68828,\"start\":68819},{\"end\":69340,\"start\":69332},{\"end\":69356,\"start\":69351},{\"end\":69368,\"start\":69364},{\"end\":69381,\"start\":69376},{\"end\":69396,\"start\":69391},{\"end\":69413,\"start\":69405},{\"end\":69835,\"start\":69830},{\"end\":69849,\"start\":69844},{\"end\":69861,\"start\":69857},{\"end\":69883,\"start\":69879},{\"end\":69898,\"start\":69894},{\"end\":69913,\"start\":69906},{\"end\":69926,\"start\":69921},{\"end\":69939,\"start\":69933},{\"end\":69944,\"start\":69940},{\"end\":69955,\"start\":69949},{\"end\":70354,\"start\":70349},{\"end\":70371,\"start\":70364},{\"end\":70386,\"start\":70380},{\"end\":70399,\"start\":70394},{\"end\":70412,\"start\":70407},{\"end\":70894,\"start\":70887},{\"end\":70912,\"start\":70908},{\"end\":71460,\"start\":71457},{\"end\":71476,\"start\":71467},{\"end\":71849,\"start\":71842},{\"end\":71851,\"start\":71850},{\"end\":71865,\"start\":71859},{\"end\":71880,\"start\":71876},{\"end\":72147,\"start\":72139},{\"end\":72421,\"start\":72416},{\"end\":72443,\"start\":72435},{\"end\":72459,\"start\":72452},{\"end\":72994,\"start\":72988},{\"end\":73010,\"start\":73003},{\"end\":73027,\"start\":73022},{\"end\":73627,\"start\":73622},{\"end\":73645,\"start\":73638},{\"end\":73665,\"start\":73658},{\"end\":73683,\"start\":73676},{\"end\":73700,\"start\":73694},{\"end\":73716,\"start\":73712},{\"end\":73729,\"start\":73724},{\"end\":73739,\"start\":73734},{\"end\":73756,\"start\":73748},{\"end\":73758,\"start\":73757},{\"end\":74179,\"start\":74175},{\"end\":74193,\"start\":74188},{\"end\":74209,\"start\":74203},{\"end\":74211,\"start\":74210},{\"end\":74227,\"start\":74221},{\"end\":74229,\"start\":74228},{\"end\":74453,\"start\":74447},{\"end\":74466,\"start\":74461},{\"end\":74479,\"start\":74474},{\"end\":74752,\"start\":74749},{\"end\":74770,\"start\":74765},{\"end\":74786,\"start\":74781},{\"end\":74799,\"start\":74794},{\"end\":74813,\"start\":74808},{\"end\":75263,\"start\":75262},{\"end\":75601,\"start\":75592},{\"end\":75616,\"start\":75611},{\"end\":75627,\"start\":75623},{\"end\":75646,\"start\":75638},{\"end\":75664,\"start\":75657},{\"end\":75668,\"start\":75665},{\"end\":76229,\"start\":76220},{\"end\":76244,\"start\":76239},{\"end\":76255,\"start\":76251},{\"end\":76270,\"start\":76263},{\"end\":76287,\"start\":76279},{\"end\":76612,\"start\":76607},{\"end\":76634,\"start\":76625},{\"end\":76649,\"start\":76643},{\"end\":76664,\"start\":76660},{\"end\":76920,\"start\":76916},{\"end\":76922,\"start\":76921},{\"end\":77144,\"start\":77137},{\"end\":77164,\"start\":77157},{\"end\":77179,\"start\":77175},{\"end\":77194,\"start\":77190},{\"end\":77480,\"start\":77474},{\"end\":77501,\"start\":77491},{\"end\":78020,\"start\":78015},{\"end\":78038,\"start\":78031},{\"end\":78057,\"start\":78052},{\"end\":78073,\"start\":78067},{\"end\":78088,\"start\":78082},{\"end\":78095,\"start\":78089},{\"end\":78372,\"start\":78364},{\"end\":78386,\"start\":78381},{\"end\":78403,\"start\":78395},{\"end\":78419,\"start\":78413},{\"end\":78424,\"start\":78420},{\"end\":79412,\"start\":79406},{\"end\":79428,\"start\":79420},{\"end\":79711,\"start\":79706},{\"end\":79713,\"start\":79712},{\"end\":79922,\"start\":79917},{\"end\":79939,\"start\":79933},{\"end\":79953,\"start\":79948},{\"end\":79972,\"start\":79966},{\"end\":80376,\"start\":80371},{\"end\":80395,\"start\":80388},{\"end\":81009,\"start\":81000},{\"end\":81529,\"start\":81520},{\"end\":81541,\"start\":81538},{\"end\":81768,\"start\":81759},{\"end\":81781,\"start\":81777},{\"end\":81797,\"start\":81792},{\"end\":81824,\"start\":81815},{\"end\":81839,\"start\":81833},{\"end\":82315,\"start\":82314},{\"end\":82331,\"start\":82326},{\"end\":82535,\"start\":82527},{\"end\":82552,\"start\":82546},{\"end\":82770,\"start\":82762},{\"end\":82787,\"start\":82781},{\"end\":82804,\"start\":82797},{\"end\":82820,\"start\":82816},{\"end\":83182,\"start\":83178},{\"end\":83184,\"start\":83183},{\"end\":83200,\"start\":83196},{\"end\":83202,\"start\":83201},{\"end\":83418,\"start\":83409},{\"end\":83435,\"start\":83428},{\"end\":83837,\"start\":83831},{\"end\":83853,\"start\":83848},{\"end\":83867,\"start\":83864},{\"end\":83886,\"start\":83880},{\"end\":83898,\"start\":83894},{\"end\":83912,\"start\":83907},{\"end\":83926,\"start\":83922},{\"end\":84290,\"start\":84284},{\"end\":84314,\"start\":84301},{\"end\":84329,\"start\":84324},{\"end\":84352,\"start\":84346},{\"end\":84747,\"start\":84742},{\"end\":84761,\"start\":84755},{\"end\":84778,\"start\":84770},{\"end\":84792,\"start\":84787},{\"end\":85116,\"start\":85113},{\"end\":85128,\"start\":85125},{\"end\":85463,\"start\":85457},{\"end\":85477,\"start\":85473},{\"end\":85489,\"start\":85484},{\"end\":85511,\"start\":85506},{\"end\":86205,\"start\":86197},{\"end\":86218,\"start\":86212},{\"end\":86230,\"start\":86226},{\"end\":86245,\"start\":86238},{\"end\":86264,\"start\":86259},{\"end\":86282,\"start\":86276},{\"end\":86298,\"start\":86290},{\"end\":86720,\"start\":86717},{\"end\":86734,\"start\":86733},{\"end\":86750,\"start\":86743},{\"end\":86771,\"start\":86763},{\"end\":86773,\"start\":86772},{\"end\":86786,\"start\":86782},{\"end\":86798,\"start\":86795},{\"end\":87053,\"start\":87047},{\"end\":87446,\"start\":87440},{\"end\":87459,\"start\":87455},{\"end\":87473,\"start\":87467},{\"end\":87975,\"start\":87969},{\"end\":88153,\"start\":88147},{\"end\":88168,\"start\":88162},{\"end\":88456,\"start\":88450},{\"end\":88470,\"start\":88465},{\"end\":88490,\"start\":88483},{\"end\":88508,\"start\":88502},{\"end\":88793,\"start\":88787},{\"end\":88809,\"start\":88802},{\"end\":88830,\"start\":88821},{\"end\":89091,\"start\":89085},{\"end\":89106,\"start\":89101},{\"end\":89130,\"start\":89122},{\"end\":89148,\"start\":89138},{\"end\":89163,\"start\":89157},{\"end\":89472,\"start\":89461},{\"end\":89670,\"start\":89664},{\"end\":89874,\"start\":89869},{\"end\":89890,\"start\":89884},{\"end\":89904,\"start\":89897},{\"end\":90416,\"start\":90410},{\"end\":90429,\"start\":90422},{\"end\":90442,\"start\":90436},{\"end\":90456,\"start\":90449},{\"end\":90465,\"start\":90462},{\"end\":90479,\"start\":90472},{\"end\":90840,\"start\":90834},{\"end\":90858,\"start\":90851},{\"end\":90880,\"start\":90872},{\"end\":91380,\"start\":91374},{\"end\":91397,\"start\":91391},{\"end\":91418,\"start\":91410},{\"end\":91437,\"start\":91427},{\"end\":91449,\"start\":91446},{\"end\":91464,\"start\":91457},{\"end\":91855,\"start\":91849},{\"end\":91874,\"start\":91866},{\"end\":91886,\"start\":91883},{\"end\":91888,\"start\":91887},{\"end\":91904,\"start\":91894},{\"end\":91920,\"start\":91913},{\"end\":92326,\"start\":92320},{\"end\":92345,\"start\":92337},{\"end\":92364,\"start\":92354},{\"end\":92985,\"start\":92978},{\"end\":93003,\"start\":92997},{\"end\":93019,\"start\":93011},{\"end\":93345,\"start\":93339},{\"end\":93357,\"start\":93356},{\"end\":93372,\"start\":93366},{\"end\":93391,\"start\":93381},{\"end\":93748,\"start\":93743},{\"end\":93765,\"start\":93755},{\"end\":93776,\"start\":93773},{\"end\":93797,\"start\":93791},{\"end\":93816,\"start\":93808},{\"end\":94212,\"start\":94209},{\"end\":94233,\"start\":94227},{\"end\":94645,\"start\":94635},{\"end\":94656,\"start\":94653},{\"end\":94668,\"start\":94664},{\"end\":95362,\"start\":95357},{\"end\":95378,\"start\":95370},{\"end\":95394,\"start\":95387},{\"end\":95737,\"start\":95733},{\"end\":95756,\"start\":95749},{\"end\":96160,\"start\":96153},{\"end\":96326,\"start\":96320},{\"end\":96343,\"start\":96335},{\"end\":96367,\"start\":96357},{\"end\":96687,\"start\":96681},{\"end\":96701,\"start\":96697},{\"end\":96715,\"start\":96711},{\"end\":96729,\"start\":96724},{\"end\":96746,\"start\":96741},{\"end\":96759,\"start\":96754},{\"end\":96761,\"start\":96760},{\"end\":96775,\"start\":96769},{\"end\":96789,\"start\":96784},{\"end\":97106,\"start\":97102},{\"end\":97122,\"start\":97114},{\"end\":97124,\"start\":97123},{\"end\":97404,\"start\":97400},{\"end\":97420,\"start\":97412},{\"end\":97438,\"start\":97429},{\"end\":97454,\"start\":97448},{\"end\":97471,\"start\":97463},{\"end\":97491,\"start\":97482},{\"end\":97899,\"start\":97895},{\"end\":97913,\"start\":97907},{\"end\":97928,\"start\":97922},{\"end\":97940,\"start\":97934},{\"end\":97959,\"start\":97951},{\"end\":98250,\"start\":98243},{\"end\":98252,\"start\":98251},{\"end\":98266,\"start\":98259},{\"end\":98268,\"start\":98267},{\"end\":98287,\"start\":98281},{\"end\":98289,\"start\":98288},{\"end\":98935,\"start\":98927},{\"end\":98949,\"start\":98942},{\"end\":98964,\"start\":98959}]", "bib_author_last_name": "[{\"end\":65191,\"start\":65186},{\"end\":65207,\"start\":65200},{\"end\":65220,\"start\":65214},{\"end\":65235,\"start\":65229},{\"end\":65249,\"start\":65245},{\"end\":65262,\"start\":65257},{\"end\":65278,\"start\":65271},{\"end\":65290,\"start\":65285},{\"end\":65304,\"start\":65300},{\"end\":65660,\"start\":65654},{\"end\":65923,\"start\":65914},{\"end\":65936,\"start\":65929},{\"end\":65958,\"start\":65944},{\"end\":65976,\"start\":65967},{\"end\":65990,\"start\":65984},{\"end\":66008,\"start\":65999},{\"end\":66402,\"start\":66398},{\"end\":66416,\"start\":66411},{\"end\":66429,\"start\":66424},{\"end\":66442,\"start\":66437},{\"end\":66456,\"start\":66450},{\"end\":66867,\"start\":66863},{\"end\":67162,\"start\":67147},{\"end\":67505,\"start\":67498},{\"end\":67524,\"start\":67515},{\"end\":67538,\"start\":67533},{\"end\":67556,\"start\":67550},{\"end\":67575,\"start\":67569},{\"end\":67964,\"start\":67957},{\"end\":67977,\"start\":67972},{\"end\":67990,\"start\":67986},{\"end\":68010,\"start\":68000},{\"end\":68024,\"start\":68018},{\"end\":68368,\"start\":68363},{\"end\":68381,\"start\":68378},{\"end\":68398,\"start\":68390},{\"end\":68409,\"start\":68405},{\"end\":68425,\"start\":68417},{\"end\":68436,\"start\":68431},{\"end\":68451,\"start\":68446},{\"end\":68466,\"start\":68459},{\"end\":68479,\"start\":68474},{\"end\":68802,\"start\":68796},{\"end\":68817,\"start\":68811},{\"end\":68835,\"start\":68829},{\"end\":69349,\"start\":69341},{\"end\":69362,\"start\":69357},{\"end\":69374,\"start\":69369},{\"end\":69389,\"start\":69382},{\"end\":69403,\"start\":69397},{\"end\":69420,\"start\":69414},{\"end\":69842,\"start\":69836},{\"end\":69855,\"start\":69850},{\"end\":69877,\"start\":69862},{\"end\":69892,\"start\":69884},{\"end\":69904,\"start\":69899},{\"end\":69919,\"start\":69914},{\"end\":69931,\"start\":69927},{\"end\":69947,\"start\":69945},{\"end\":69961,\"start\":69956},{\"end\":70362,\"start\":70355},{\"end\":70378,\"start\":70372},{\"end\":70392,\"start\":70387},{\"end\":70405,\"start\":70400},{\"end\":70421,\"start\":70413},{\"end\":70906,\"start\":70895},{\"end\":70923,\"start\":70913},{\"end\":71465,\"start\":71461},{\"end\":71483,\"start\":71477},{\"end\":71857,\"start\":71852},{\"end\":71874,\"start\":71866},{\"end\":71884,\"start\":71881},{\"end\":72159,\"start\":72148},{\"end\":72433,\"start\":72422},{\"end\":72450,\"start\":72444},{\"end\":72471,\"start\":72460},{\"end\":73001,\"start\":72995},{\"end\":73020,\"start\":73011},{\"end\":73035,\"start\":73028},{\"end\":73051,\"start\":73037},{\"end\":73636,\"start\":73628},{\"end\":73656,\"start\":73646},{\"end\":73674,\"start\":73666},{\"end\":73692,\"start\":73684},{\"end\":73710,\"start\":73701},{\"end\":73722,\"start\":73717},{\"end\":73732,\"start\":73730},{\"end\":73746,\"start\":73740},{\"end\":73764,\"start\":73759},{\"end\":74186,\"start\":74180},{\"end\":74201,\"start\":74194},{\"end\":74219,\"start\":74212},{\"end\":74239,\"start\":74230},{\"end\":74459,\"start\":74454},{\"end\":74472,\"start\":74467},{\"end\":74486,\"start\":74480},{\"end\":74763,\"start\":74753},{\"end\":74779,\"start\":74771},{\"end\":74792,\"start\":74787},{\"end\":74806,\"start\":74800},{\"end\":74820,\"start\":74814},{\"end\":75268,\"start\":75264},{\"end\":75278,\"start\":75270},{\"end\":75609,\"start\":75602},{\"end\":75621,\"start\":75617},{\"end\":75636,\"start\":75628},{\"end\":75655,\"start\":75647},{\"end\":75675,\"start\":75669},{\"end\":76237,\"start\":76230},{\"end\":76249,\"start\":76245},{\"end\":76261,\"start\":76256},{\"end\":76277,\"start\":76271},{\"end\":76296,\"start\":76288},{\"end\":76623,\"start\":76613},{\"end\":76641,\"start\":76635},{\"end\":76658,\"start\":76650},{\"end\":76673,\"start\":76665},{\"end\":76929,\"start\":76923},{\"end\":77155,\"start\":77145},{\"end\":77173,\"start\":77165},{\"end\":77188,\"start\":77180},{\"end\":77202,\"start\":77195},{\"end\":77489,\"start\":77481},{\"end\":77507,\"start\":77502},{\"end\":77769,\"start\":77762},{\"end\":78029,\"start\":78021},{\"end\":78050,\"start\":78039},{\"end\":78065,\"start\":78058},{\"end\":78080,\"start\":78074},{\"end\":78102,\"start\":78096},{\"end\":78379,\"start\":78373},{\"end\":78393,\"start\":78387},{\"end\":78411,\"start\":78404},{\"end\":78431,\"start\":78425},{\"end\":78769,\"start\":78751},{\"end\":79085,\"start\":79067},{\"end\":79418,\"start\":79413},{\"end\":79434,\"start\":79429},{\"end\":79720,\"start\":79714},{\"end\":79931,\"start\":79923},{\"end\":79946,\"start\":79940},{\"end\":79964,\"start\":79954},{\"end\":79978,\"start\":79973},{\"end\":80386,\"start\":80377},{\"end\":80407,\"start\":80396},{\"end\":81016,\"start\":81010},{\"end\":81536,\"start\":81530},{\"end\":81546,\"start\":81542},{\"end\":81775,\"start\":81769},{\"end\":81790,\"start\":81782},{\"end\":81813,\"start\":81798},{\"end\":81831,\"start\":81825},{\"end\":81847,\"start\":81840},{\"end\":82324,\"start\":82316},{\"end\":82338,\"start\":82332},{\"end\":82342,\"start\":82340},{\"end\":82544,\"start\":82536},{\"end\":82560,\"start\":82553},{\"end\":82779,\"start\":82771},{\"end\":82795,\"start\":82788},{\"end\":82814,\"start\":82805},{\"end\":82830,\"start\":82821},{\"end\":83194,\"start\":83185},{\"end\":83210,\"start\":83203},{\"end\":83426,\"start\":83419},{\"end\":83447,\"start\":83436},{\"end\":83846,\"start\":83838},{\"end\":83862,\"start\":83854},{\"end\":83878,\"start\":83868},{\"end\":83892,\"start\":83887},{\"end\":83905,\"start\":83899},{\"end\":83920,\"start\":83913},{\"end\":83931,\"start\":83927},{\"end\":84299,\"start\":84291},{\"end\":84322,\"start\":84315},{\"end\":84344,\"start\":84330},{\"end\":84360,\"start\":84353},{\"end\":84753,\"start\":84748},{\"end\":84768,\"start\":84762},{\"end\":84785,\"start\":84779},{\"end\":84802,\"start\":84793},{\"end\":85123,\"start\":85117},{\"end\":85138,\"start\":85129},{\"end\":85471,\"start\":85464},{\"end\":85482,\"start\":85478},{\"end\":85504,\"start\":85490},{\"end\":85518,\"start\":85512},{\"end\":86210,\"start\":86206},{\"end\":86224,\"start\":86219},{\"end\":86236,\"start\":86231},{\"end\":86257,\"start\":86246},{\"end\":86274,\"start\":86265},{\"end\":86288,\"start\":86283},{\"end\":86305,\"start\":86299},{\"end\":86731,\"start\":86721},{\"end\":86741,\"start\":86735},{\"end\":86761,\"start\":86751},{\"end\":86780,\"start\":86774},{\"end\":86793,\"start\":86787},{\"end\":86810,\"start\":86799},{\"end\":86814,\"start\":86812},{\"end\":87062,\"start\":87054},{\"end\":87453,\"start\":87447},{\"end\":87465,\"start\":87460},{\"end\":87482,\"start\":87474},{\"end\":87982,\"start\":87976},{\"end\":88160,\"start\":88154},{\"end\":88174,\"start\":88169},{\"end\":88463,\"start\":88457},{\"end\":88481,\"start\":88471},{\"end\":88500,\"start\":88491},{\"end\":88514,\"start\":88509},{\"end\":88800,\"start\":88794},{\"end\":88819,\"start\":88810},{\"end\":88837,\"start\":88831},{\"end\":89099,\"start\":89092},{\"end\":89120,\"start\":89107},{\"end\":89136,\"start\":89131},{\"end\":89155,\"start\":89149},{\"end\":89172,\"start\":89164},{\"end\":89476,\"start\":89473},{\"end\":89681,\"start\":89671},{\"end\":89882,\"start\":89875},{\"end\":89895,\"start\":89891},{\"end\":89916,\"start\":89905},{\"end\":90420,\"start\":90417},{\"end\":90434,\"start\":90430},{\"end\":90447,\"start\":90443},{\"end\":90460,\"start\":90457},{\"end\":90470,\"start\":90466},{\"end\":90483,\"start\":90480},{\"end\":90849,\"start\":90841},{\"end\":90870,\"start\":90859},{\"end\":90887,\"start\":90881},{\"end\":91389,\"start\":91381},{\"end\":91408,\"start\":91398},{\"end\":91425,\"start\":91419},{\"end\":91444,\"start\":91438},{\"end\":91455,\"start\":91450},{\"end\":91476,\"start\":91465},{\"end\":91864,\"start\":91856},{\"end\":91881,\"start\":91875},{\"end\":91892,\"start\":91889},{\"end\":91911,\"start\":91905},{\"end\":91932,\"start\":91921},{\"end\":92335,\"start\":92327},{\"end\":92352,\"start\":92346},{\"end\":92371,\"start\":92365},{\"end\":92995,\"start\":92986},{\"end\":93009,\"start\":93004},{\"end\":93027,\"start\":93020},{\"end\":93354,\"start\":93346},{\"end\":93364,\"start\":93358},{\"end\":93379,\"start\":93373},{\"end\":93400,\"start\":93392},{\"end\":93408,\"start\":93402},{\"end\":93753,\"start\":93749},{\"end\":93771,\"start\":93766},{\"end\":93789,\"start\":93777},{\"end\":93806,\"start\":93798},{\"end\":93823,\"start\":93817},{\"end\":94225,\"start\":94213},{\"end\":94242,\"start\":94234},{\"end\":94651,\"start\":94646},{\"end\":94662,\"start\":94657},{\"end\":94675,\"start\":94669},{\"end\":95368,\"start\":95363},{\"end\":95385,\"start\":95379},{\"end\":95401,\"start\":95395},{\"end\":95747,\"start\":95738},{\"end\":95767,\"start\":95757},{\"end\":96172,\"start\":96161},{\"end\":96333,\"start\":96327},{\"end\":96355,\"start\":96344},{\"end\":96378,\"start\":96368},{\"end\":96695,\"start\":96688},{\"end\":96709,\"start\":96702},{\"end\":96722,\"start\":96716},{\"end\":96739,\"start\":96730},{\"end\":96752,\"start\":96747},{\"end\":96767,\"start\":96762},{\"end\":96782,\"start\":96776},{\"end\":96800,\"start\":96790},{\"end\":97112,\"start\":97107},{\"end\":97131,\"start\":97125},{\"end\":97410,\"start\":97405},{\"end\":97427,\"start\":97421},{\"end\":97446,\"start\":97439},{\"end\":97461,\"start\":97455},{\"end\":97480,\"start\":97472},{\"end\":97498,\"start\":97492},{\"end\":97905,\"start\":97900},{\"end\":97920,\"start\":97914},{\"end\":97932,\"start\":97929},{\"end\":97949,\"start\":97941},{\"end\":97968,\"start\":97960},{\"end\":98257,\"start\":98253},{\"end\":98279,\"start\":98269},{\"end\":98295,\"start\":98290},{\"end\":98940,\"start\":98936},{\"end\":98957,\"start\":98950},{\"end\":98979,\"start\":98965}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":65603,\"start\":65179},{\"attributes\":{\"id\":\"b1\"},\"end\":65852,\"start\":65605},{\"attributes\":{\"doi\":\"10.1145/3406183\",\"id\":\"b2\",\"matched_paper_id\":220643528},\"end\":66348,\"start\":65854},{\"attributes\":{\"doi\":\"arXiv:2002.09018\",\"id\":\"b3\"},\"end\":66621,\"start\":66350},{\"attributes\":{\"id\":\"b4\"},\"end\":66833,\"start\":66623},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":17572120},\"end\":67044,\"start\":66835},{\"attributes\":{\"id\":\"b6\"},\"end\":67422,\"start\":67046},{\"attributes\":{\"id\":\"b7\"},\"end\":67886,\"start\":67424},{\"attributes\":{\"doi\":\"10.1145/2487228.2487239\",\"id\":\"b8\",\"matched_paper_id\":577965},\"end\":68325,\"start\":67888},{\"attributes\":{\"id\":\"b9\"},\"end\":68730,\"start\":68327},{\"attributes\":{\"doi\":\"10.1145/3214745.3214806\",\"id\":\"b10\",\"matched_paper_id\":51974651},\"end\":69238,\"start\":68732},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":218672542},\"end\":69772,\"start\":69240},{\"attributes\":{\"doi\":\"10.1145/3182159\",\"id\":\"b12\",\"matched_paper_id\":51877671},\"end\":70287,\"start\":69774},{\"attributes\":{\"doi\":\"http:/arxiv.org/abs/https:/onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-8659.2011.02063.x\",\"id\":\"b13\",\"matched_paper_id\":15425859},\"end\":70861,\"start\":70289},{\"attributes\":{\"doi\":\"10.1145/1053427.1053460\",\"id\":\"b14\",\"matched_paper_id\":207156246},\"end\":71410,\"start\":70863},{\"attributes\":{\"id\":\"b15\"},\"end\":71801,\"start\":71412},{\"attributes\":{\"doi\":\"10.1145/3361682\",\"id\":\"b16\",\"matched_paper_id\":219841993},\"end\":72080,\"start\":71803},{\"attributes\":{\"id\":\"b17\"},\"end\":72321,\"start\":72082},{\"attributes\":{\"doi\":\"10.2312/sr.20201135\",\"id\":\"b18\",\"matched_paper_id\":220282040},\"end\":72929,\"start\":72323},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":40589154},\"end\":73488,\"start\":72931},{\"attributes\":{\"doi\":\"10.2312/sre.20171193\",\"id\":\"b20\"},\"end\":73620,\"start\":73490},{\"attributes\":{\"doi\":\"arXiv:1905.11286\",\"id\":\"b21\"},\"end\":74150,\"start\":73622},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":5181174},\"end\":74445,\"start\":74152},{\"attributes\":{\"doi\":\"arXiv:1802.09568\",\"id\":\"b23\"},\"end\":74698,\"start\":74447},{\"attributes\":{\"doi\":\"http:/arxiv.org/abs/https:/onlinelibrary.wiley.com/doi/pdf/10.1111/cgf.13919\",\"id\":\"b24\",\"matched_paper_id\":221583018},\"end\":75201,\"start\":74700},{\"attributes\":{\"doi\":\"10.1145/97880.97895\",\"id\":\"b25\",\"matched_paper_id\":564368},\"end\":75497,\"start\":75203},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":52017448},\"end\":76156,\"start\":75499},{\"attributes\":{\"doi\":\"10.1111/cgf.12950\",\"id\":\"b27\",\"matched_paper_id\":35831634},\"end\":76555,\"start\":76158},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":53285532},\"end\":76870,\"start\":76557},{\"attributes\":{\"id\":\"b29\"},\"end\":77135,\"start\":76872},{\"attributes\":{\"doi\":\"arXiv:2004.05439\",\"id\":\"b30\"},\"end\":77416,\"start\":77137},{\"attributes\":{\"id\":\"b31\"},\"end\":77723,\"start\":77418},{\"attributes\":{\"doi\":\"10.1145/3084873.3096476\",\"id\":\"b32\"},\"end\":77946,\"start\":77725},{\"attributes\":{\"doi\":\"arXiv:1803.05407\",\"id\":\"b33\"},\"end\":78320,\"start\":77948},{\"attributes\":{\"doi\":\"10.1145/1330511.1330518\",\"id\":\"b34\",\"matched_paper_id\":15260885},\"end\":78696,\"start\":78322},{\"attributes\":{\"doi\":\"10.1007/978-3-7091-9430-0_31\",\"id\":\"b35\",\"matched_paper_id\":9344202},\"end\":79026,\"start\":78698},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":11340736},\"end\":79331,\"start\":79028},{\"attributes\":{\"doi\":\"10.1016/j.cag.2020.09.007\",\"id\":\"b37\",\"matched_paper_id\":220870698},\"end\":79680,\"start\":79333},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":9226468},\"end\":79827,\"start\":79682},{\"attributes\":{\"doi\":\"10.1145/3130800.3130880\",\"id\":\"b39\",\"matched_paper_id\":221669152},\"end\":80297,\"start\":79829},{\"attributes\":{\"doi\":\"10.1145/1730804.1730821\",\"id\":\"b40\",\"matched_paper_id\":15969508},\"end\":80979,\"start\":80299},{\"attributes\":{\"doi\":\"10.1145/258734.258769\",\"id\":\"b41\",\"matched_paper_id\":489660},\"end\":81518,\"start\":80981},{\"attributes\":{\"id\":\"b42\"},\"end\":81727,\"start\":81520},{\"attributes\":{\"doi\":\"10.1145/3305366.3329896\",\"id\":\"b43\",\"matched_paper_id\":198963603},\"end\":82268,\"start\":81729},{\"attributes\":{\"doi\":\"arXiv:1412.6980\",\"id\":\"b44\"},\"end\":82470,\"start\":82270},{\"attributes\":{\"id\":\"b45\"},\"end\":82696,\"start\":82472},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":8313850},\"end\":83115,\"start\":82698},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":7506343},\"end\":83355,\"start\":83117},{\"attributes\":{\"doi\":\"10.1145/2614028.2615431\",\"id\":\"b48\"},\"end\":83829,\"start\":83357},{\"attributes\":{\"doi\":\"arXiv:1803.04189\",\"id\":\"b49\"},\"end\":84211,\"start\":83831},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":207925155},\"end\":84682,\"start\":84213},{\"attributes\":{\"doi\":\"10.1145/3185225\",\"id\":\"b51\",\"matched_paper_id\":3993777},\"end\":85059,\"start\":84684},{\"attributes\":{\"id\":\"b52\"},\"end\":85387,\"start\":85061},{\"attributes\":{\"doi\":\"10.1145/3023368.3023378\",\"id\":\"b53\",\"matched_paper_id\":1173313},\"end\":86137,\"start\":85389},{\"attributes\":{\"id\":\"b54\",\"matched_paper_id\":11781023},\"end\":86643,\"start\":86139},{\"attributes\":{\"id\":\"b55\",\"matched_paper_id\":213175590},\"end\":87014,\"start\":86645},{\"attributes\":{\"doi\":\"10.1145/1281500.1281671\",\"id\":\"b56\",\"matched_paper_id\":11249937},\"end\":87383,\"start\":87016},{\"attributes\":{\"doi\":\"10.2312/hpg.20191191\",\"id\":\"b57\",\"matched_paper_id\":199485859},\"end\":87931,\"start\":87385},{\"attributes\":{\"id\":\"b58\"},\"end\":88080,\"start\":87933},{\"attributes\":{\"doi\":\"10.1111/cgf.13227\",\"id\":\"b59\",\"matched_paper_id\":9890097},\"end\":88420,\"start\":88082},{\"attributes\":{\"doi\":\"10.1145/3341156\",\"id\":\"b60\",\"matched_paper_id\":51970108},\"end\":88760,\"start\":88422},{\"attributes\":{\"doi\":\"10.1145/3414685.3417804\",\"id\":\"b61\",\"matched_paper_id\":219179383},\"end\":89083,\"start\":88762},{\"attributes\":{\"id\":\"b62\"},\"end\":89429,\"start\":89085},{\"attributes\":{\"id\":\"b63\"},\"end\":89589,\"start\":89431},{\"attributes\":{\"doi\":\"arXiv:2005.07547\",\"id\":\"b64\"},\"end\":89825,\"start\":89591},{\"attributes\":{\"id\":\"b65\",\"matched_paper_id\":20350129},\"end\":90352,\"start\":89827},{\"attributes\":{\"doi\":\"10.1145/2461912.2462009\",\"id\":\"b66\",\"matched_paper_id\":4395124},\"end\":90775,\"start\":90354},{\"attributes\":{\"doi\":\"http:/arxiv.org/abs/https:/onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-8659.2012.02093.x\",\"id\":\"b67\",\"matched_paper_id\":2024417},\"end\":91316,\"start\":90777},{\"attributes\":{\"doi\":\"10.1145/1618452.1618478\",\"id\":\"b68\",\"matched_paper_id\":436316},\"end\":91773,\"start\":91318},{\"attributes\":{\"doi\":\"10.1145/1409060.1409082\",\"id\":\"b69\",\"matched_paper_id\":64700},\"end\":92260,\"start\":91775},{\"attributes\":{\"doi\":\"10.1145/1507149.1507161\",\"id\":\"b70\",\"matched_paper_id\":2049022},\"end\":92906,\"start\":92262},{\"attributes\":{\"doi\":\"10.1145/2070781.2024193\",\"id\":\"b71\",\"matched_paper_id\":11981657},\"end\":93305,\"start\":92908},{\"attributes\":{\"doi\":\"10.1111/j.1467-8659.2012.03134.x\",\"id\":\"b72\",\"matched_paper_id\":12176989},\"end\":93679,\"start\":93307},{\"attributes\":{\"id\":\"b73\",\"matched_paper_id\":219600293},\"end\":94112,\"start\":93681},{\"attributes\":{\"doi\":\"10.1145/3130800.3130852\",\"id\":\"b74\",\"matched_paper_id\":35674656},\"end\":94530,\"start\":94114},{\"attributes\":{\"doi\":\"10.1145/566570.566612\",\"id\":\"b75\",\"matched_paper_id\":324277},\"end\":95311,\"start\":94532},{\"attributes\":{\"id\":\"b76\"},\"end\":95659,\"start\":95313},{\"attributes\":{\"doi\":\"10.1145/1186562.1015748\",\"id\":\"b77\",\"matched_paper_id\":6541329},\"end\":96151,\"start\":95661},{\"attributes\":{\"id\":\"b78\"},\"end\":96260,\"start\":96153},{\"attributes\":{\"id\":\"b79\",\"matched_paper_id\":53463204},\"end\":96677,\"start\":96262},{\"attributes\":{\"doi\":\"arXiv:1706.03762\",\"id\":\"b80\"},\"end\":97033,\"start\":96679},{\"attributes\":{\"doi\":\"10.1145/218380.218498\",\"id\":\"b81\",\"matched_paper_id\":207194026},\"end\":97370,\"start\":97035},{\"attributes\":{\"id\":\"b82\",\"matched_paper_id\":198963706},\"end\":97684,\"start\":97372},{\"attributes\":{\"doi\":\"10.1145/3305366.3328091\",\"id\":\"b83\"},\"end\":97815,\"start\":97686},{\"attributes\":{\"id\":\"b84\",\"matched_paper_id\":7018971},\"end\":98189,\"start\":97817},{\"attributes\":{\"id\":\"b85\",\"matched_paper_id\":38575859},\"end\":98892,\"start\":98191},{\"attributes\":{\"id\":\"b86\",\"matched_paper_id\":197465278},\"end\":99572,\"start\":98894}]", "bib_title": "[{\"end\":65644,\"start\":65605},{\"end\":65905,\"start\":65854},{\"end\":66639,\"start\":66623},{\"end\":66855,\"start\":66835},{\"end\":67139,\"start\":67046},{\"end\":67947,\"start\":67888},{\"end\":68785,\"start\":68732},{\"end\":69330,\"start\":69240},{\"end\":69828,\"start\":69774},{\"end\":70347,\"start\":70289},{\"end\":70885,\"start\":70863},{\"end\":71840,\"start\":71803},{\"end\":72137,\"start\":72082},{\"end\":72414,\"start\":72323},{\"end\":72986,\"start\":72931},{\"end\":74173,\"start\":74152},{\"end\":74747,\"start\":74700},{\"end\":75260,\"start\":75203},{\"end\":75590,\"start\":75499},{\"end\":76218,\"start\":76158},{\"end\":76605,\"start\":76557},{\"end\":76914,\"start\":76872},{\"end\":77472,\"start\":77418},{\"end\":78362,\"start\":78322},{\"end\":78749,\"start\":78698},{\"end\":79065,\"start\":79028},{\"end\":79404,\"start\":79333},{\"end\":79704,\"start\":79682},{\"end\":79915,\"start\":79829},{\"end\":80369,\"start\":80299},{\"end\":80998,\"start\":80981},{\"end\":81757,\"start\":81729},{\"end\":82760,\"start\":82698},{\"end\":83176,\"start\":83117},{\"end\":83407,\"start\":83357},{\"end\":84282,\"start\":84213},{\"end\":84740,\"start\":84684},{\"end\":85111,\"start\":85061},{\"end\":85455,\"start\":85389},{\"end\":86195,\"start\":86139},{\"end\":86715,\"start\":86645},{\"end\":87045,\"start\":87016},{\"end\":87438,\"start\":87385},{\"end\":88145,\"start\":88082},{\"end\":88448,\"start\":88422},{\"end\":88785,\"start\":88762},{\"end\":89459,\"start\":89431},{\"end\":89867,\"start\":89827},{\"end\":90408,\"start\":90354},{\"end\":90832,\"start\":90777},{\"end\":91372,\"start\":91318},{\"end\":91847,\"start\":91775},{\"end\":92318,\"start\":92262},{\"end\":92976,\"start\":92908},{\"end\":93337,\"start\":93307},{\"end\":93741,\"start\":93681},{\"end\":94207,\"start\":94114},{\"end\":94633,\"start\":94532},{\"end\":95355,\"start\":95313},{\"end\":95731,\"start\":95661},{\"end\":96318,\"start\":96262},{\"end\":97100,\"start\":97035},{\"end\":97398,\"start\":97372},{\"end\":97893,\"start\":97817},{\"end\":98241,\"start\":98191},{\"end\":98925,\"start\":98894}]", "bib_author": "[{\"end\":65193,\"start\":65179},{\"end\":65209,\"start\":65193},{\"end\":65222,\"start\":65209},{\"end\":65237,\"start\":65222},{\"end\":65251,\"start\":65237},{\"end\":65264,\"start\":65251},{\"end\":65280,\"start\":65264},{\"end\":65292,\"start\":65280},{\"end\":65306,\"start\":65292},{\"end\":65662,\"start\":65646},{\"end\":65925,\"start\":65907},{\"end\":65938,\"start\":65925},{\"end\":65960,\"start\":65938},{\"end\":65978,\"start\":65960},{\"end\":65992,\"start\":65978},{\"end\":66010,\"start\":65992},{\"end\":66404,\"start\":66392},{\"end\":66418,\"start\":66404},{\"end\":66431,\"start\":66418},{\"end\":66444,\"start\":66431},{\"end\":66458,\"start\":66444},{\"end\":66869,\"start\":66857},{\"end\":67164,\"start\":67141},{\"end\":67507,\"start\":67489},{\"end\":67526,\"start\":67507},{\"end\":67540,\"start\":67526},{\"end\":67558,\"start\":67540},{\"end\":67577,\"start\":67558},{\"end\":67966,\"start\":67949},{\"end\":67979,\"start\":67966},{\"end\":67992,\"start\":67979},{\"end\":68012,\"start\":67992},{\"end\":68026,\"start\":68012},{\"end\":68370,\"start\":68359},{\"end\":68383,\"start\":68370},{\"end\":68400,\"start\":68383},{\"end\":68411,\"start\":68400},{\"end\":68427,\"start\":68411},{\"end\":68438,\"start\":68427},{\"end\":68453,\"start\":68438},{\"end\":68468,\"start\":68453},{\"end\":68481,\"start\":68468},{\"end\":68804,\"start\":68787},{\"end\":68819,\"start\":68804},{\"end\":68837,\"start\":68819},{\"end\":69351,\"start\":69332},{\"end\":69364,\"start\":69351},{\"end\":69376,\"start\":69364},{\"end\":69391,\"start\":69376},{\"end\":69405,\"start\":69391},{\"end\":69422,\"start\":69405},{\"end\":69844,\"start\":69830},{\"end\":69857,\"start\":69844},{\"end\":69879,\"start\":69857},{\"end\":69894,\"start\":69879},{\"end\":69906,\"start\":69894},{\"end\":69921,\"start\":69906},{\"end\":69933,\"start\":69921},{\"end\":69949,\"start\":69933},{\"end\":69963,\"start\":69949},{\"end\":70364,\"start\":70349},{\"end\":70380,\"start\":70364},{\"end\":70394,\"start\":70380},{\"end\":70407,\"start\":70394},{\"end\":70423,\"start\":70407},{\"end\":70908,\"start\":70887},{\"end\":70925,\"start\":70908},{\"end\":71467,\"start\":71457},{\"end\":71485,\"start\":71467},{\"end\":71859,\"start\":71842},{\"end\":71876,\"start\":71859},{\"end\":71886,\"start\":71876},{\"end\":72161,\"start\":72139},{\"end\":72435,\"start\":72416},{\"end\":72452,\"start\":72435},{\"end\":72473,\"start\":72452},{\"end\":73003,\"start\":72988},{\"end\":73022,\"start\":73003},{\"end\":73037,\"start\":73022},{\"end\":73053,\"start\":73037},{\"end\":73638,\"start\":73622},{\"end\":73658,\"start\":73638},{\"end\":73676,\"start\":73658},{\"end\":73694,\"start\":73676},{\"end\":73712,\"start\":73694},{\"end\":73724,\"start\":73712},{\"end\":73734,\"start\":73724},{\"end\":73748,\"start\":73734},{\"end\":73766,\"start\":73748},{\"end\":74188,\"start\":74175},{\"end\":74203,\"start\":74188},{\"end\":74221,\"start\":74203},{\"end\":74241,\"start\":74221},{\"end\":74461,\"start\":74447},{\"end\":74474,\"start\":74461},{\"end\":74488,\"start\":74474},{\"end\":74765,\"start\":74749},{\"end\":74781,\"start\":74765},{\"end\":74794,\"start\":74781},{\"end\":74808,\"start\":74794},{\"end\":74822,\"start\":74808},{\"end\":75270,\"start\":75262},{\"end\":75280,\"start\":75270},{\"end\":75611,\"start\":75592},{\"end\":75623,\"start\":75611},{\"end\":75638,\"start\":75623},{\"end\":75657,\"start\":75638},{\"end\":75677,\"start\":75657},{\"end\":76239,\"start\":76220},{\"end\":76251,\"start\":76239},{\"end\":76263,\"start\":76251},{\"end\":76279,\"start\":76263},{\"end\":76298,\"start\":76279},{\"end\":76625,\"start\":76607},{\"end\":76643,\"start\":76625},{\"end\":76660,\"start\":76643},{\"end\":76675,\"start\":76660},{\"end\":76931,\"start\":76916},{\"end\":77157,\"start\":77137},{\"end\":77175,\"start\":77157},{\"end\":77190,\"start\":77175},{\"end\":77204,\"start\":77190},{\"end\":77491,\"start\":77474},{\"end\":77509,\"start\":77491},{\"end\":77771,\"start\":77762},{\"end\":78031,\"start\":78015},{\"end\":78052,\"start\":78031},{\"end\":78067,\"start\":78052},{\"end\":78082,\"start\":78067},{\"end\":78104,\"start\":78082},{\"end\":78381,\"start\":78364},{\"end\":78395,\"start\":78381},{\"end\":78413,\"start\":78395},{\"end\":78433,\"start\":78413},{\"end\":78771,\"start\":78751},{\"end\":79087,\"start\":79067},{\"end\":79420,\"start\":79406},{\"end\":79436,\"start\":79420},{\"end\":79722,\"start\":79706},{\"end\":79933,\"start\":79917},{\"end\":79948,\"start\":79933},{\"end\":79966,\"start\":79948},{\"end\":79980,\"start\":79966},{\"end\":80388,\"start\":80371},{\"end\":80409,\"start\":80388},{\"end\":81018,\"start\":81000},{\"end\":81538,\"start\":81520},{\"end\":81548,\"start\":81538},{\"end\":81777,\"start\":81759},{\"end\":81792,\"start\":81777},{\"end\":81815,\"start\":81792},{\"end\":81833,\"start\":81815},{\"end\":81849,\"start\":81833},{\"end\":82326,\"start\":82314},{\"end\":82340,\"start\":82326},{\"end\":82344,\"start\":82340},{\"end\":82546,\"start\":82527},{\"end\":82562,\"start\":82546},{\"end\":82781,\"start\":82762},{\"end\":82797,\"start\":82781},{\"end\":82816,\"start\":82797},{\"end\":82832,\"start\":82816},{\"end\":83196,\"start\":83178},{\"end\":83212,\"start\":83196},{\"end\":83428,\"start\":83409},{\"end\":83449,\"start\":83428},{\"end\":83848,\"start\":83831},{\"end\":83864,\"start\":83848},{\"end\":83880,\"start\":83864},{\"end\":83894,\"start\":83880},{\"end\":83907,\"start\":83894},{\"end\":83922,\"start\":83907},{\"end\":83933,\"start\":83922},{\"end\":84301,\"start\":84284},{\"end\":84324,\"start\":84301},{\"end\":84346,\"start\":84324},{\"end\":84362,\"start\":84346},{\"end\":84755,\"start\":84742},{\"end\":84770,\"start\":84755},{\"end\":84787,\"start\":84770},{\"end\":84804,\"start\":84787},{\"end\":85125,\"start\":85113},{\"end\":85140,\"start\":85125},{\"end\":85473,\"start\":85457},{\"end\":85484,\"start\":85473},{\"end\":85506,\"start\":85484},{\"end\":85520,\"start\":85506},{\"end\":86212,\"start\":86197},{\"end\":86226,\"start\":86212},{\"end\":86238,\"start\":86226},{\"end\":86259,\"start\":86238},{\"end\":86276,\"start\":86259},{\"end\":86290,\"start\":86276},{\"end\":86307,\"start\":86290},{\"end\":86733,\"start\":86717},{\"end\":86743,\"start\":86733},{\"end\":86763,\"start\":86743},{\"end\":86782,\"start\":86763},{\"end\":86795,\"start\":86782},{\"end\":86812,\"start\":86795},{\"end\":86816,\"start\":86812},{\"end\":87064,\"start\":87047},{\"end\":87455,\"start\":87440},{\"end\":87467,\"start\":87455},{\"end\":87484,\"start\":87467},{\"end\":87984,\"start\":87969},{\"end\":88162,\"start\":88147},{\"end\":88176,\"start\":88162},{\"end\":88465,\"start\":88450},{\"end\":88483,\"start\":88465},{\"end\":88502,\"start\":88483},{\"end\":88516,\"start\":88502},{\"end\":88802,\"start\":88787},{\"end\":88821,\"start\":88802},{\"end\":88839,\"start\":88821},{\"end\":89101,\"start\":89085},{\"end\":89122,\"start\":89101},{\"end\":89138,\"start\":89122},{\"end\":89157,\"start\":89138},{\"end\":89174,\"start\":89157},{\"end\":89478,\"start\":89461},{\"end\":89683,\"start\":89664},{\"end\":89884,\"start\":89869},{\"end\":89897,\"start\":89884},{\"end\":89918,\"start\":89897},{\"end\":90422,\"start\":90410},{\"end\":90436,\"start\":90422},{\"end\":90449,\"start\":90436},{\"end\":90462,\"start\":90449},{\"end\":90472,\"start\":90462},{\"end\":90485,\"start\":90472},{\"end\":90851,\"start\":90834},{\"end\":90872,\"start\":90851},{\"end\":90889,\"start\":90872},{\"end\":91391,\"start\":91374},{\"end\":91410,\"start\":91391},{\"end\":91427,\"start\":91410},{\"end\":91446,\"start\":91427},{\"end\":91457,\"start\":91446},{\"end\":91478,\"start\":91457},{\"end\":91866,\"start\":91849},{\"end\":91883,\"start\":91866},{\"end\":91894,\"start\":91883},{\"end\":91913,\"start\":91894},{\"end\":91934,\"start\":91913},{\"end\":92337,\"start\":92320},{\"end\":92354,\"start\":92337},{\"end\":92373,\"start\":92354},{\"end\":92997,\"start\":92978},{\"end\":93011,\"start\":92997},{\"end\":93029,\"start\":93011},{\"end\":93356,\"start\":93339},{\"end\":93366,\"start\":93356},{\"end\":93381,\"start\":93366},{\"end\":93402,\"start\":93381},{\"end\":93410,\"start\":93402},{\"end\":93755,\"start\":93743},{\"end\":93773,\"start\":93755},{\"end\":93791,\"start\":93773},{\"end\":93808,\"start\":93791},{\"end\":93825,\"start\":93808},{\"end\":94227,\"start\":94209},{\"end\":94244,\"start\":94227},{\"end\":94653,\"start\":94635},{\"end\":94664,\"start\":94653},{\"end\":94677,\"start\":94664},{\"end\":95370,\"start\":95357},{\"end\":95387,\"start\":95370},{\"end\":95403,\"start\":95387},{\"end\":95749,\"start\":95733},{\"end\":95769,\"start\":95749},{\"end\":96174,\"start\":96153},{\"end\":96335,\"start\":96320},{\"end\":96357,\"start\":96335},{\"end\":96380,\"start\":96357},{\"end\":96697,\"start\":96681},{\"end\":96711,\"start\":96697},{\"end\":96724,\"start\":96711},{\"end\":96741,\"start\":96724},{\"end\":96754,\"start\":96741},{\"end\":96769,\"start\":96754},{\"end\":96784,\"start\":96769},{\"end\":96802,\"start\":96784},{\"end\":97114,\"start\":97102},{\"end\":97133,\"start\":97114},{\"end\":97412,\"start\":97400},{\"end\":97429,\"start\":97412},{\"end\":97448,\"start\":97429},{\"end\":97463,\"start\":97448},{\"end\":97482,\"start\":97463},{\"end\":97500,\"start\":97482},{\"end\":97907,\"start\":97895},{\"end\":97922,\"start\":97907},{\"end\":97934,\"start\":97922},{\"end\":97951,\"start\":97934},{\"end\":97970,\"start\":97951},{\"end\":98259,\"start\":98243},{\"end\":98281,\"start\":98259},{\"end\":98297,\"start\":98281},{\"end\":98942,\"start\":98927},{\"end\":98959,\"start\":98942},{\"end\":98981,\"start\":98959}]", "bib_venue": "[{\"end\":68926,\"start\":68900},{\"end\":71112,\"start\":71030},{\"end\":73246,\"start\":73158},{\"end\":78835,\"start\":78821},{\"end\":79158,\"start\":79144},{\"end\":80622,\"start\":80527},{\"end\":81237,\"start\":81145},{\"end\":81940,\"start\":81914},{\"end\":83228,\"start\":83224},{\"end\":83560,\"start\":83543},{\"end\":85744,\"start\":85638},{\"end\":87146,\"start\":87129},{\"end\":87600,\"start\":87582},{\"end\":90106,\"start\":90015},{\"end\":92560,\"start\":92478},{\"end\":94910,\"start\":94804},{\"end\":95850,\"start\":95833},{\"end\":97196,\"start\":97179},{\"end\":98529,\"start\":98423},{\"end\":99199,\"start\":99104},{\"end\":65371,\"start\":65306},{\"end\":65709,\"start\":65662},{\"end\":66064,\"start\":66025},{\"end\":66390,\"start\":66350},{\"end\":66691,\"start\":66641},{\"end\":66927,\"start\":66869},{\"end\":67227,\"start\":67164},{\"end\":67487,\"start\":67424},{\"end\":68065,\"start\":68049},{\"end\":68357,\"start\":68327},{\"end\":68898,\"start\":68860},{\"end\":69476,\"start\":69422},{\"end\":69994,\"start\":69978},{\"end\":70537,\"start\":70514},{\"end\":71028,\"start\":70948},{\"end\":71455,\"start\":71412},{\"end\":71912,\"start\":71901},{\"end\":72187,\"start\":72161},{\"end\":72542,\"start\":72492},{\"end\":73156,\"start\":73053},{\"end\":73536,\"start\":73512},{\"end\":73872,\"start\":73782},{\"end\":74280,\"start\":74241},{\"end\":74558,\"start\":74504},{\"end\":74921,\"start\":74898},{\"end\":75321,\"start\":75299},{\"end\":75750,\"start\":75677},{\"end\":76338,\"start\":76315},{\"end\":76698,\"start\":76675},{\"end\":76997,\"start\":76931},{\"end\":77262,\"start\":77220},{\"end\":77548,\"start\":77509},{\"end\":77760,\"start\":77725},{\"end\":78013,\"start\":77948},{\"end\":78472,\"start\":78456},{\"end\":78819,\"start\":78799},{\"end\":79111,\"start\":79087},{\"end\":79481,\"start\":79461},{\"end\":79739,\"start\":79722},{\"end\":80019,\"start\":80003},{\"end\":80525,\"start\":80432},{\"end\":81143,\"start\":81039},{\"end\":81587,\"start\":81548},{\"end\":81912,\"start\":81872},{\"end\":82312,\"start\":82270},{\"end\":82525,\"start\":82472},{\"end\":82888,\"start\":82832},{\"end\":83222,\"start\":83212},{\"end\":83541,\"start\":83472},{\"end\":84007,\"start\":83949},{\"end\":84408,\"start\":84362},{\"end\":84835,\"start\":84819},{\"end\":85218,\"start\":85140},{\"end\":85636,\"start\":85543},{\"end\":86361,\"start\":86307},{\"end\":86820,\"start\":86816},{\"end\":87127,\"start\":87087},{\"end\":87548,\"start\":87504},{\"end\":87967,\"start\":87933},{\"end\":88216,\"start\":88193},{\"end\":88547,\"start\":88531},{\"end\":88878,\"start\":88862},{\"end\":89242,\"start\":89174},{\"end\":89504,\"start\":89478},{\"end\":89662,\"start\":89591},{\"end\":90013,\"start\":89918},{\"end\":90524,\"start\":90508},{\"end\":91003,\"start\":90980},{\"end\":91517,\"start\":91501},{\"end\":91973,\"start\":91957},{\"end\":92476,\"start\":92396},{\"end\":93068,\"start\":93052},{\"end\":93462,\"start\":93442},{\"end\":93879,\"start\":93825},{\"end\":94283,\"start\":94267},{\"end\":94802,\"start\":94698},{\"end\":95478,\"start\":95403},{\"end\":95831,\"start\":95792},{\"end\":96193,\"start\":96174},{\"end\":96426,\"start\":96380},{\"end\":96843,\"start\":96818},{\"end\":97177,\"start\":97154},{\"end\":97520,\"start\":97500},{\"end\":97986,\"start\":97970},{\"end\":98421,\"start\":98317},{\"end\":99102,\"start\":98999}]"}}}, "year": 2023, "month": 12, "day": 17}