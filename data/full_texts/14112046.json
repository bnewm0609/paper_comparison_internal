{"id": 14112046, "updated": "2023-11-08 10:51:52.828", "metadata": {"title": "Stochastic First- and Zeroth-order Methods for Nonconvex Stochastic Programming", "authors": "[{\"first\":\"Saeed\",\"last\":\"Ghadimi\",\"middle\":[]},{\"first\":\"Guanghui\",\"last\":\"Lan\",\"middle\":[]}]", "venue": "SIAM J. Optim.", "journal": "SIAM J. Optim.", "publication_date": {"year": 2013, "month": 9, "day": 22}, "abstract": "In this paper, we introduce a new stochastic approximation (SA) type algorithm, namely the randomized stochastic gradient (RSG) method, for solving an important class of nonlinear (possibly nonconvex) stochastic programming (SP) problems. We establish the complexity of this method for computing an approximate stationary point of a nonlinear programming problem. We also show that this method possesses a nearly optimal rate of convergence if the problem is convex. We discuss a variant of the algorithm which consists of applying a post-optimization phase to evaluate a short list of solutions generated by several independent runs of the RSG method, and show that such modification allows to improve significantly the large-deviation properties of the algorithm. These methods are then specialized for solving a class of simulation-based optimization problems in which only stochastic zeroth-order information is available.", "fields_of_study": "[\"Mathematics\",\"Computer Science\"]", "external_ids": {"arxiv": "1309.5549", "mag": "2963470657", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/corr/GhadimiL13", "doi": "10.1137/120880811"}}, "content": {"source": {"pdf_hash": "c3e07c1510cf166b9b3bc882a72bcfd5d96c0c75", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/1309.5549v1.pdf\"]", "oa_url_match": true, "oa_info": {"license": null, "open_access_url": "http://arxiv.org/pdf/1309.5549", "status": "GREEN"}}, "grobid": {"id": "7c42aa6101cbead401e520d5fcd7ad71a5d859f7", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/c3e07c1510cf166b9b3bc882a72bcfd5d96c0c75.txt", "contents": "\nSTOCHASTIC FIRST-AND ZEROTH-ORDER METHODS FOR NONCONVEX STOCHASTIC PROGRAMMING *\n22 Sep 2013\n\nSaeed Ghadimi \nGuanghui Lan \nSTOCHASTIC FIRST-AND ZEROTH-ORDER METHODS FOR NONCONVEX STOCHASTIC PROGRAMMING *\n22 Sep 2013stochastic approximationnonconvex optimizationstochastic programmingsimulation- based optimization\nIn this paper, we introduce a new stochastic approximation (SA) type algorithm, namely the randomized stochastic gradient (RSG) method, for solving an important class of nonlinear (possibly nonconvex) stochastic programming (SP) problems. We establish the complexity of this method for computing an approximate stationary point of a nonlinear programming problem. We also show that this method possesses a nearly optimal rate of convergence if the problem is convex. We discuss a variant of the algorithm which consists of applying a post-optimization phase to evaluate a short list of solutions generated by several independent runs of the RSG method, and show that such modification allows to improve significantly the large-deviation properties of the algorithm. These methods are then specialized for solving a class of simulation-based optimization problems in which only stochastic zeroth-order information is available.\n\n1. Introduction. In 1951, Robbins and Monro in their seminal work [33] proposed a classical stochastic approximation (SA) algorithm for solving stochastic programming (SP) problems. This approach mimics the simplest gradient descent method by using noisy gradient information in place of the exact gradients, and possesses the \"asymptotically optimal\" rate of convergence for solving a class of strongly convex SP problems [4,37]. However, it is usually difficult to implement the \"asymptotically optimal\" stepsize policy, especially in the beginning, so that the algorithms often perform poorly in practice (e.g., [39,Section 4.5.3]). An important improvement of the classical SA was developed by Polyak [31] and Polyak and Juditsky [32], where longer stepsizes were suggested together with the averaging of the obtained iterates. Their methods were shown to be more robust with respect to the selection of stepsizes than the classical SA and also exhibit the \"asymptotically optimal\" rate of convergence for solving strongly convex SP problems. We refer to [23] for an account of the earlier history of SA methods.\n\nThe last few years have seen some significant progress for the development of SA methods for SP. On one hand, new SA type methods are being introduced to solve SP problems which are not necessarily strongly convex. On the other hand, these developments, motivated by complexity theory in convex optimization [24], concerned the convergence properties of SA methods during a finite number of iterations. For example, Nemirovski et al. [23] presented a properly modified SA approach, namely, mirror descent SA for solving general non-smooth convex SP problems. They demonstrated that the mirror descent SA exhibits an optimal O(1/\u01eb 2 ) iteration complexity for solving these problems. This method has been shown in [19,23] to be competitive to the widely-accepted sample average approximation approach (see, e.g., [17,38]) and even significantly outperform it for solving a class of convex SP problems. Similar techniques, based on subgradient averaging, have been proposed in [14,16,27]. While these techniques dealt with non-smooth convex programming problems, Lan [18] presented a unified optimal method for smooth, non-smooth and stochastic optimization, which explicitly takes into account the smoothness of the objective function (see also [11,10] for discussions about strong convexity). However, note that convexity has played an important role in establishing the convergence of all these SA algorithms.\n\nTo the best of our knowledge, none of existing SA algorithms can handle more general SP problems whose objective function is possibly nonconvex.\n\nThis paper focuses on the theoretical development of SA type methods for solving an important class of nonconvex SP problems. More specifically, we study the classical unconstrained nonlinear programming (NLP) problem given in the form of (e.g., [26,30])\nf * := inf x\u2208R n f (x),(1.1)\nwhere f : R n \u2192 R is a differentiable (not necessarily convex), bounded from below, and its gradient \u2207f (\u00b7) satisfies \u2207f (y) \u2212 \u2207f (x) \u2264 L y \u2212 x , \u2200x, y \u2208 R n .\n\nHowever, different from the standard NLP, we assume throughout the paper that we only have access to noisy function values or gradients about the objective function f in (1.1). In particular, in the basic setting, we assume that problem (1.1) is to be solved by iterative algorithms which acquire the gradients of f via subsequent calls to a stochastic first-order oracle (SF O). At iteration k of the algorithm, x k being the input, the SF O outputs a stochastic gradient G(x k , \u03be k ), where \u03be k , k \u2265 1, are random variables whose distributions P k are supported on \u039e k \u2286 R d . The following assumptions are made for the Borel functions G(x k , \u03be k ).\n\nA1: For any k \u2265 1, we have\na) E[G(x k , \u03be k )] = \u2207f (x k ), (1.2) b) E G(x k , \u03be k ) \u2212 \u2207f (x k ) 2 \u2264 \u03c3 2 ,(1.3)\nfor some parameter \u03c3 \u2265 0. Observe that, by (1.2), G(x k , \u03be k ) is an unbiased estimator of \u2207f (x k ) and, by (1.3), the variance of the random variable G(x k , \u03be k ) \u2212 \u2207f (x k ) is bounded. It is worth noting that in the standard setting for SP, the random vectors \u03be k , k = 1, 2, . . ., are independent of each other (and also of x k ) (see, e.g., [24,23]). Our assumption here is slightly weaker since we do not need to assume \u03be k , k = 1, 2, . . ., to be independent. Our study on the aforementioned SP problems has been motivated by a few interesting applications which are briefly outlined as follows.\n\n\u2022 In many machine learning problems, we intend to minimize a regularized loss function f (\u00b7) given by\nf (x) = \u039e L(x, \u03be)dP (\u03be) + r(x),(1.4)\nwhere either the loss function L(x, \u03be) or the regularization r(x) is nonconvex (see, e.g., [21,22]). \u2022 Another important class of problems originate from the so-called endogenous uncertainty in SP. More specifically, the objective functions for these 2 SP problems are given in the form of\nf (x) = \u039e(x)\nF (x, \u03be)dP x (\u03be), (1.5) where the support \u039e(x) and the distribution function P x of the random vector \u03be depend on x. The function f in (1.5) is usually nonconvex even if F (x, \u03be) is convex with respect to x. For example, if the support \u039e does not depend on x, it is often possible to represent dP x = H(x)dP for some fixed distribution P . Typically this transformation results in a nonconvex integrand function.\n\nOther techniques have also been developed to compute unbiased estimators for the gradient of f (\u00b7) in (1.5) (see, e.g., [8,13,20,35]). \u2022 Finally, in simulation-based optimization, the objective function is given by\nf (x) = E \u03be [F (x, \u03be)],\nwhere F (\u00b7, \u03be) is not given explicitly, but through a blackbox simulation procedure (e.g., [1,7]). Therefore, we do not know if the function f is convex or not. Moreover, in these cases, we usually only have access to stochastic zeroth-order information about the function values of f (\u00b7) rather than its gradients. The complexity of the gradient descent method for solving problem (1.1) has been well-understood under the deterministic setting (i.e., \u03c3 = 0 in (1.3)). In particular, Nesterov [26] shows that after running the method for at most N = O(1/\u01eb) steps, we have min k=1,...,N \u2207f (x k ) 2 \u2264 \u01eb (see Gratton et al. [36] for a similar bound for the trust-region methods). Cartis et al. [2] show that this bound is actually tight for the gradient descent method. Note, however, that the analysis in [26] is not applicable to the stochastic setting (i.e., \u03c3 > 0 in (1.3)). Moreover, even if we have min k=1,...,N \u2207f (x k ) 2 \u2264 \u01eb, to find the best solution from {x 1 , . . . , x N } is still difficult since \u2207f (x k ) is not known exactly. Our major contributions in this paper are summarized as follows. Firstly, to solve the aforementioned nonconvex SP problem, we present a randomized stochastic gradient (RSG) method by introducing the following modifications to the classical SA. Instead of taking average of the iterates as in the mirror descent SA for convex SP, we randomly select a solutionx from {x 1 , . . . , x N } according to a certain probability distribution as the output. We show that such a solution satisfies E[ \u2207f (x) 2 ] \u2264 \u01eb after running the method for at most\nN = O(1/\u01eb 2 ) iterations 1 . Moreover, if f (\u00b7) is convex, we show that the relation E[f (x) \u2212 f * ] \u2264 \u01eb always holds.\nWe demonstrate that such a complexity result is nearly optimal for solving convex SP problems (see the discussions after Corollary 2.2).\n\nSecondly, in order to improve the large deviation properties and hence the reliability of the RSG method, we present a two-phase randomized stochastic gradient (2-RSG) method by introducing a post-optimization phase to evaluate a short list of solutions generated by several independent runs of the RSG method. We show that the complexity of the 2-RSG method for computing an (\u01eb, \u039b)-solution of problem (1.1), i.e., a pointx such that Prob{ \u2207f (x) 2 \u2264 \u01eb} \u2265 1 \u2212 \u039b for some \u01eb > 0 and \u039b \u2208 (0, 1), can be bounded by\nO log(1/\u039b)\u03c3 2 \u01eb 1 \u01eb + log(1/\u039b) \u039b .\n1 It should not be too surprising to see that the complexity for the stochastic case is much worse than that for the deterministic case. For example, in the convex case, it is known [26,18] that the complexity for finding an solutionx satisfying f (x) \u2212 f * \u2264 \u01eb will be substantially increased from O(1/ \u221a \u01eb) to O(1/\u01eb 2 ) as one moves from the deterministic to stochastic setting.\n\nWe further show that, under certain light-tail assumption about the SF O, the above complexity bound can be reduced to\nO log(1/\u039b)\u03c3 2 \u01eb 1 \u01eb + log 1 \u039b .\nThirdly, we specialize the RSG method for the case where only stochastic zerothorder information is available. There exists a somewhat long history for the development of zeroth-order (or derivative-free) methods in nonlinear programming (see the monograph by Conn et al. [5] and references therein). However, only few complexity results are available for these types of methods, mostly for convex programming (e.g., [24,28]) and deterministic nonconvex programming problems (e.g., [3,9,28,40]). The stochastic zeroth-order methods studied in this paper are directly motivated by a recent important work due to Nesterov [28]. More specifically, Nesterov proved in [28] some tight bounds for approximating first-order information by zeroth-order information using the Gaussian smoothing technique (see Theorem 3.1). Based on this technique, he presented a series of new complexity results for zeroth-order methods. For example, he established the O (n/\u01eb) complexity, in terms of E[f (x) \u2212 f * ] \u2264 \u01eb, for a zeroth-order method applied to smooth convex programming problems (see in p.19 of [28]) along with some possible acceleration schemes. Here the expectation is taken with respect to the Gaussian random variables used in the algorithms. He had also proved the O(n/\u01eb) complexity, in terms of E[ \u2207f (x) 2 ] \u2264 \u01eb, for solving smooth nonconvex problems (see p.24 of [28]). While these bounds were obtained for solving deterministic optimization problems, Nesterov established the O(n 2 /\u01eb 2 ) complexity, in terms of E[f (x) \u2212 f * ] \u2264 \u01eb, for solving general nonsmooth convex SP problems (see p.17 of [28]).\n\nBy incorporating the Gaussian smoothing technique [28] into the RSG method, we present a randomized stochastic gradient free (RSGF) method for solving a class of simulation-based optimization problems and demonstrate that its iteration complexity for finding the aforementioned \u01eb-solution (i.e., E[ \u2207f (x) 2 ] \u2264 \u01eb) can be bounded by O(n/\u01eb 2 ). To the best of our knowledge, this appears to be the first complexity result for nonconvex stochastic zeroth-order methods in the literature. Moreover, the same RSGF algorithm possesses an O(n/\u01eb 2 ) complexity bound, in terms of E[f (x) \u2212 f * ] \u2264 \u01eb, for solving smooth convex SP problems. It is interesting to observe that this bound has a much weaker dependence on n than the one previously established by Nesterov for solving general nonsmooth convex SP problems (see p.17 of [28]). Such an improvement is obtained by explicitly making use of the smoothness properties of the objective function and carefully choosing the stepsizes and smoothing parameter used in the RSGF method. This paper is organized as follows. We introduce two stochastic first-order methods, i.e., the RSG and 2-RSG methods, for nonconvex SP, and establish their convergence properties in Section 2. We then specialize these methods for solving a class of simulation-based optimization problems in Section 3. Some brief concluding remarks are also presented in Section 4.\n\n1.1. Notation and terminology. As stated in [26], we say that f \u2208 C 1,1 L (R n ) if it is differentiable and\n\u2207f (y) \u2212 \u2207f (x) \u2264 L y \u2212 x , \u2200x, y \u2208 R n . 4 Clearly, we have |f (y) \u2212 f (x) \u2212 \u2207f (x), y \u2212 x | \u2264 L 2 y \u2212 x 2 , \u2200x, y \u2208 R n . (1.6)\nIf, in addition, f (\u00b7) is convex, then\nf (y) \u2212 f (x) \u2212 \u2207f (x), y \u2212 x \u2265 1 2L \u2207f (y) \u2212 \u2207f (x) 2 ,(1.7)\nand\n\u2207f (y) \u2212 \u2207f (x), y \u2212 x \u2265 1 L \u2207f (y) \u2212 \u2207f (x) 2 , \u2200x, y \u2208 R n . (1.8)\n2. Stochastic first-order methods. Our goal in this section is to present and analyze a new class of SA algorithms for solving general smooth nonlinear (possibly nonconvex) SP problems. More specifically, we present the RSG method and establish its convergence properties in Subsection 2.1, and then introduce the 2-RSG method which can significantly improve the large-deviation properties of the RSG method in Subsection 2.2.\n\nWe assume throughout this section that Assumption A1 holds. In some cases, Assumption A1 is augmented by the following \"light-tail\" assumption.\n\n\nA2:\n\nFor any x \u2208 R n and k \u2265 1, we have\nE exp{ G(x, \u03be k ) \u2212 g(x) 2 /\u03c3 2 } \u2264 exp{1}. (2.1)\nIt can be easily seen that Assumption A2 implies Assumption A1.b) by Jensen's inequality.\n\n2.1. The randomized stochastic gradient method. The convergence of existing SA methods requires f (\u00b7) to be convex [23,19,18,11,10]. Moreover, in order to guarantee the convexity of f (\u00b7), one often need to assume that the random variables \u03be k , k \u2265 1, to be independent of the search sequence {x k }. Below we present a new SA-type algorithm that can deal with both convex and nonconvex SP problems, and allow random noises to be dependent on the search sequence. This algorithm is obtained by incorporating a certain randomization scheme into the classical SA method.\n\nA randomized stochastic gradient (RSG) method Input: Initial point x 1 , iteration limit N , stepsizes {\u03b3 k } k\u22651 and probability mass function P R (\u00b7) supported on {1, . . . , N }.\n\nStep 0. Let R be a random variable with probability mass function P R .\n\nStep k = 1, . . . , R. Call the stochastic first-order oracle for computing G(x k , \u03be k ) and set\nx k+1 = x k \u2212 \u03b3 k G(x k , \u03be k ). (2.2)\nOutput x R . A few remarks about the above RSG method are in order. Firstly, in comparison with the classical SA, we have used a random iteration count, R, to terminate the execution of the RSG algorithm. Equivalently, one can view such a randomization scheme from a slightly different perspective described as follows. Instead of terminating the algorithm at the R-th step, one can also run the RSG algorithm for N iterations but randomly choose a search point x R (according to P R ) from its trajectory as the output of the algorithm. Clearly, using the latter scheme, we just need to run the algorithm for the first R iterations and the remaining N \u2212 R iterations are surpluses. Note however, that the primary goal to introduce the random iteration count R is to derive new complexity results for nonconvex SP, rather than save the computational efforts in the last N \u2212 R iterations of the algorithm. Indeed, if R is uniformly distributed, the computational gain from such a randomization scheme is simply a factor of 2. Secondly, the RSG algorithm described above is conceptual only because we have not specified the selection of the stepsizes {\u03b3 k } and the probability mass function P R yet. We will address this issue after establishing some basic convergence properties of the RSG method.\n\nThe following result describes some convergence properties of the RSG method. Theorem 2.1. Suppose that the stepsizes {\u03b3 k } and the probability mass function P R (\u00b7) in the RSG method are chosen such that \u03b3 k < 2/L and\nP R (k) := Prob{R = k} = 2\u03b3 k \u2212 L\u03b3 2 k N k=1 (2\u03b3 k \u2212 L\u03b3 2 k ) , k = 1, ..., N. (2.3)\nThen, under Assumption A1, a) for any N \u2265 1, we have\n1 L E[ \u2207f (x R ) 2 ] \u2264 D 2 f + \u03c3 2 N k=1 \u03b3 2 k N k=1 (2\u03b3 k \u2212 L\u03b3 2 k ) , (2.4)\nwhere the expectation is taken with respect to R and \u03be [N ] := (\u03be 1 , ..., \u03be N ),\nD f := 2 (f (x 1 ) \u2212 f * ) L 1 2 ,(2.\n\n5)\n\nand f * denotes the optimal value of problem (1.1); b) if, in addition, problem (1.1) is convex with an optimal solution x * , then, for any N \u2265 1,\nE[f (x R ) \u2212 f * ] \u2264 D 2 X + \u03c3 2 N k=1 \u03b3 2 k N k=1 (2\u03b3 k \u2212 L\u03b3 2 k ) , (2.6)\nwhere the expectation is taken with respect to R and \u03be [N ] , and\nD X := x 1 \u2212 x * . (2.7) Proof. Display \u03b4 k \u2261 G(x k , \u03be k ) \u2212 \u2207f (x k ), k \u2265 1.\nWe first show part a). Using the assumption that f \u2208 C 1,1 L (R n ), (1.6) and (2.2), we have, for any k = 1, . . . , N ,\nf (x k+1 ) \u2264 f (x k ) + \u2207f (x k ), x k+1 \u2212 x k + L 2 \u03b3 2 k G(x k , \u03be k ) 2 = f (x k ) \u2212 \u03b3 k \u2207f (x k ), G(x k , \u03be k ) + L 2 \u03b3 2 k G(x k , \u03be k ) 2 = f (x k ) \u2212 \u03b3 k \u2207f (x k ) 2 \u2212 \u03b3 k \u2207f (x k ), \u03b4 k + L 2 \u03b3 2 k \u2207f (x k ) 2 + 2 \u2207f (x k ), \u03b4 k + \u03b4 k 2 = f (x k ) \u2212 \u03b3 k \u2212 L 2 \u03b3 2 k \u2207f (x k ) 2 \u2212 \u03b3 k \u2212 L\u03b3 2 k \u2207f (x k ), \u03b4 k + L 2 \u03b3 2 k \u03b4 k 2 . (2.8) 6\nSumming up the above inequalities and re-arranging the terms, we obtain\nN k=1 \u03b3 k \u2212 L 2 \u03b3 2 k \u2207f (x k ) 2 \u2264 f (x 1 ) \u2212 f (x N +1 ) \u2212 N k=1 \u03b3 k \u2212 L\u03b3 2 k \u2207f (x k ), \u03b4 k + L 2 N k=1 \u03b3 2 k \u03b4 k 2 \u2264 f (x 1 ) \u2212 f * \u2212 N k=1 \u03b3 k \u2212 L\u03b3 2 k \u2207f (x k ), \u03b4 k + L 2 N k=1 \u03b3 2 k \u03b4 k 2 , (2.9)\nwhere the last inequality follows from the fact that f (x N +1 ) \u2265 f * . Note that the search point x k is a function of the history \u03be [k\u22121] of the generated random process and hence is random. Taking expectations (with respect to \u03be [N ] ) on both sides of (2.9) and noting that under Assumption A1,\nE[ \u03b4 k 2 ] \u2264 \u03c3 2 , and E[ \u2207f (x k ), \u03b4 k |\u03be [k\u22121] ] = 0, (2.10) we obtain N k=1 \u03b3 k \u2212 L 2 \u03b3 2 k E \u03be [N ] \u2207f (x k ) 2 \u2264 f (x 1 ) \u2212 f * + L\u03c3 2 2 N k=1 \u03b3 2 k (2.11)\nDividing both sides of the above inequality by L N k=1 \u03b3 k \u2212 L\u03b3 2 k /2 and noting that\nE[ \u2207f (x R ) 2 ] = E R,\u03be [N ] [ \u2207f (x R ) 2 ] = N k=1 2\u03b3 k \u2212 L\u03b3 2 k E \u03be [N ] \u2207f (x k ) 2 N k=1 (2\u03b3 k \u2212 L\u03b3 2 k ) , we conclude 1 L E[ \u2207f (x R ) 2 ] \u2264 1 N k=1 (2\u03b3 k \u2212 L\u03b3 2 k ) 2 (f (x 1 ) \u2212 f * ) L + \u03c3 2 N k=1 \u03b3 2 k ,\nwhich, in view of (2.5), clearly implies (2.4). We now show that part b) holds. Display \u03c9 k \u2261 x k \u2212 x * . First observe that, for any k = 1, . . . , N ,\n\u03c9 2 k+1 = x k \u2212 \u03b3 k G(x k , \u03be k ) \u2212 x * 2 = \u03c9 2 k \u2212 2\u03b3 k G(x k , \u03be k ), x k \u2212 x * + \u03b3 2 k G(x k , \u03be k ) 2 = \u03c9 2 k \u2212 2\u03b3 k \u2207f (x k ) + \u03b4 k , x k \u2212 x * + \u03b3 2 k \u2207f (x k ) 2 + 2 \u2207f (x k ), \u03b4 k + \u03b4 k 2 .\nMoreover, in view of (1.8) and the fact that \u2207f (x * ) = 0, we have\n1 L \u2207f (x k ) 2 \u2264 \u2207f (x k ), x k \u2212 x * . (2.12)\nCombining the above two relations, we obtain, for any k = 1, . . . , N ,\n\u03c9 2 k+1 \u2264 \u03c9 2 k \u2212 (2\u03b3 k \u2212 L\u03b3 2 k ) \u2207f (x k ), x k \u2212 x * \u2212 2\u03b3 k x k \u2212 \u03b3 k \u2207f (x k ) \u2212 x * , \u03b4 k + \u03b3 2 k \u03b4 k 2 \u2264 \u03c9 2 k \u2212 (2\u03b3 k \u2212 L\u03b3 2 k )[f (x k ) \u2212 f * ] \u2212 2\u03b3 k x k \u2212 \u03b3 k \u2207f (x k ) \u2212 x * , \u03b4 k + \u03b3 2 k \u03b4 k 2 ,\nwhere the last inequality follows from the convexity of f (\u00b7) and the fact that \u03b3 k \u2264 2/L. Summing up the above inequalities and re-arranging the terms, we have\nN k=1 (2\u03b3 k \u2212 L\u03b3 2 k )[f (x k ) \u2212 f * ] \u2264 \u03c9 2 1 \u2212 \u03c9 2 N +1 \u2212 2 N k=1 \u03b3 k x k \u2212 \u03b3 k \u2207f (x k ) \u2212 x * , \u03b4 k + N k=1 \u03b3 2 k \u03b4 k 2 \u2264 D 2 X \u2212 2 N k=1 \u03b3 k x k \u2212 \u03b3 k \u2207f (x k ) \u2212 x * , \u03b4 k + N k=1 \u03b3 2 k \u03b4 k 2 ,\nwhere the last inequality follows from (2.7) and the fact that \u03c9 N +1 \u2265 0. The rest of the proof is similar to that of part a) and hence the details are skipped.\n\nWe now describe a possible strategy for the selection of the stepsizes {\u03b3 k } in the RSG method. For the sake of simplicity, let us assume that a constant stepsize policy is used, i.e., \u03b3 k = \u03b3, k = 1, . . . , N , for some \u03b3 \u2208 (0, 2/L). Note that the assumption of constant stepsizes does not hurt the efficiency estimate of the RSG method. The following corollary of Theorem 2.1 is obtained by appropriately choosing the parameter \u03b3.\n\nCorollary 2.2. Suppose that the stepsizes {\u03b3 k } are set to\n\u03b3 k = min 1 L ,D \u03c3 \u221a N , k = 1, . . . , N, (2.13)\nfor someD > 0. Also assume that the probability mass function P R (\u00b7) is set to (2.3).\n\nThen, under Assumption A1, we have\n1 L E[ \u2207f (x R ) 2 ] \u2264 B N := LD 2 f N + D + D 2 f D \u03c3 \u221a N , (2.14)\nwhere D f is defined in (2.5). If, in addition, problem (1.1) is convex with an optimal solution x * , then\nE[f (x R ) \u2212 f * ] \u2264 LD 2 X N + D + D 2 X D \u03c3 \u221a N , (2.15)\nwhere D X is defined in (2.7). Proof. Noting that by (2.13), we have\nD 2 f + \u03c3 2 N k=1 \u03b3 2 k N k=1 (2\u03b3 k \u2212 L\u03b3 2 k ) = D 2 f + N \u03c3 2 \u03b3 2 1 N \u03b3 1 (2 \u2212 L\u03b3 1 ) \u2264 D 2 f + N \u03c3 2 \u03b3 2 1 N \u03b3 1 = D 2 f N \u03b3 1 + \u03c3 2 \u03b3 1 \u2264 D 2 f N max L, \u03c3 \u221a \u00d1 D + \u03c3 2D \u03c3 \u221a N \u2264 LD 2 f N + D + D 2 f D \u03c3 \u221a N ,\nwhich together with (2.4) then imply (2.14). Relation (2.15) follows similarly from the above inequality (with D f replaced by D X ) and (2.6).\n\nWe now add a few remarks about the results obtained in Theorem 2.1 and Corollary 2.2. Firstly, as can be seen from (2.11), instead of randomly selecting a solution x R from {x 1 , . . . , x N }, another possibility would be to output the solutionx N such that\n\u2207f (x N ) = min k=1,...,N \u2207f (x k ) . (2.16)\nWe can show that E \u2207f (x N ) goes to zero with similar rates of convergence as in (2.4) and (2.14). However, to use this strategy would require some extra computational effort to compute \u2207f (x k ) for all k = 1, . . . , N . Since \u2207f (x k ) cannot be computed exactly, to estimate them by using Monte-carlo simulation would incur additional approximation errors and raise some reliability issues. On the other hand, the above RSG method does not require any extra computational effort for estimating the gradients \u2207f (x k ) , k = 1, . . . , N . Secondly, observe that in the stepsize policy (2.13), we need to specify a parameter D. While the RSG method converges for any arbitraryD > 0, it can be easily seen from (2.14) and (2.15) that an optimal selection ofD would be D f and D X , respectively, for solving nonconvex and convex SP problems. With such selections, the bounds in (2.14) and (2.15), respectively, reduce to\n1 L E[ \u2207f (x R ) 2 ] \u2264 LD 2 f N + 2D f \u03c3 \u221a N . (2.17)\nand\nE[f (x R ) \u2212 f * ] \u2264 LD 2 X N + 2D X \u03c3 \u221a N . (2.18)\nNote however, that the exact values of D f or D X are rarely known and one often need to setD to a suboptimal value, e.g., certain upper bounds on D f or D X . Thirdly, one possible drawback for the above RSG method is that one need to estimate L to obtain an upper bound on \u03b3 k (see, e.g., (2.13)), which will also possibly affect the selection of P R (see (2.3)). Note that similar requirements also exist for some deterministic first-order methods (e.g., gradient descent and Nesterov's accelerated gradient methods). While under the deterministic setting, one can somehow relax such requirements by using certain line-search procedures to enhance the practical performance of these methods, it is more difficult to devise similar line-search procedures for the stochastic setting, since the exact values of f (x k ) and \u2207f (x k ) are not available. It should be noted, however, that we do not need very accurate estimate for L in the RSG method. Indeed, it can be easily checked that the RSG method exhibits an O(1/ \u221a N ) rate of convergence if the stepsizes {\u03b3 k } are set to\nmin 1 qL ,D \u03c3 \u221a N , k = 1, . . . , N for any q \u2208 [1, \u221a N ].\nIn other words, we can overestimate the value of L by a factor up to \u221a N and the resulting RSG method still exhibits similar rate of convergence. A common practice in stochastic optimization is to estimate L by using the stochastic gradients computed at a small number of trial points (see, e.g., [23,19,11,10]). We have adopted such a strategy in our implementation of the RSG method as described in more details in the technical report associated with this paper [12]. It is also worth noting that, although in general the selection of P R will depend on \u03b3 k and hence on L, such a dependence is not necessary in some special cases. In particular, if the stepsizes {\u03b3 k } are chosen according to a constant stepsize policy (e.g., (2.13)), then R is uniformly distributed on {1, . . . , N }.\n\nFourthly, it is interesting to note that the RSG method allows us to have a unified treatment for both nonconvex and convex SP problems in view of the specification of {\u03b3 k } and P R (\u00b7) (c.f., (2.3) and (2.13)). Recall that the optimal rate of convergence for solving smooth convex SP problems is given by\nO LD 2 X N 2 + D X \u03c3 \u221a N .\nThis bound has been obtained by Lan [18] based on a stochastic counterpart of Nesterov's method [25,26]. Comparing (2.18) with the above bound, the RSG method possesses a nearly optimal rate of convergence, since the second term in (2.18) is unimprovable while the first term in (2.18) can be much improved. Moreover, as shown by Cartis et al. [3], the first term in (2.17) for nonconvex problems is also unimprovable for gradient descent methods. It should be noted, however that the analysis in [3] applies only for gradient descent methods and does not show that the O(1/N ) term is tight for all first-order methods.\n\nFinally, observe that we can use different stepsize policy other than the constant one in (2.13). In particular, it can be shown that the RSG method with the following two stepsize policies will exhibit similar rates of convergence as those in Corollary 2.2.\n\n\u2022 Increasing stepsize policy:\n\u03b3 k = min 1 L ,D \u221a k \u03c3N , k = 1, . . . , N.\n\u2022 Decreasing stepsize policy:\n\u03b3 k = min 1 L ,D \u03c3(kN ) 1 4 , k = 1, . . . , N.\nIntuitively speaking, one may want to choose decreasing stepsizes which, according to the definition of P R (\u00b7) in (2.3), can stop the algorithm earlier. On the other hand, as the algorithm moves forward and local information about the gradient gets better, choosing increasing stepsizes might be a better option. We expect that the practical performance of these stepsize policies will depend on each problem instance to be solved.\n\nWhile Theorem 2.1 and Corollary 2.2 establish the expected convergence performance over many runs of the RSG method, we are also interested in the large-deviation properties for a single run of this method. In particular, we are interested in establishing its complexity for computing an (\u01eb, \u039b)-solution of problem (1.1), i.e., a point x satisfying Prob{ \u2207f (x) 2 \u2264 \u01eb} \u2265 1 \u2212 \u039b for some \u01eb > 0 and \u039b \u2208 (0, 1). By using (2.14) and Markov's inequality, we have\nProb \u2207f (x R ) 2 \u2265 \u03bbLB N \u2264 1 \u03bb , \u2200\u03bb > 0. (2.19)\nIt then follows that the number of calls to SF O performed by the RSG method for finding an (\u01eb, \u039b)-solution, after disregarding a few constant factors, can be bounded by\nO 1 \u039b\u01eb + \u03c3 2 \u039b 2 \u01eb 2 .\n(2.20)\n\nThe above complexity bound is rather pessimistic in terms of its dependence on \u039b. We will investigate one possible way to significantly improve it in next subsection.\n\n\n2.2.\n\nA two-phase randomized stochastic gradient method. In this section, we describe a variant of the RSG method which can considerably improve the complexity bound in (2.20). This procedure consists of two phases: an optimization phase used to generate a list of candidate solutions via a few independent runs of the RSG method and a post-optimization phase in which a solution is selected from this candidate list.\n\n\nA two-phase RSG (2-RSG) method\n\nInput: Initial point x 1 , number of runs S, iteration limit N , and sample size T .\n\nOptimization phase: For s = 1, . . . , S Call the RSG method with input x 1 , iteration limit N , stepsizes {\u03b3 k } in (2.13) and probability mass function P R in (2.3). Letx s be the output of this procedure. Post-optimization phase:\n\nChoose a solutionx * from the candidate list {x 1 , . . . ,x S } such that\ng(x * ) = min s=1,...,S g(x s ) , g(x s ) := 1 T T k=1 G(x s , \u03be k ),(2.21)\nwhere G(x, \u03be k ), k = 1, . . . , T , are the stochastic gradients returned by the SF O. Observe that in (2.21), we define the best solutionx * as the one with the smallest value of g(x s ) , s = 1, . . . , S. Alternatively, one can choosex * from {x 1 , . . . ,x S } such thatf\n(x * ) = min 1,...,Sf (x s ),f (x s ) = 1 T T k=1 F (x s , \u03be k ). (2.22)\nIt should be noted that the 2-RSG method is different from a two-phase procedure for convex stochastic programming by Nesterov and Vial [29], where the average of x 1 , . . . ,x S is chosen as the output solution.\n\nIn the 2-RSG method described above, the number of calls to the SF O are given by S \u00d7 N and S \u00d7 T , respectively, for the optimization phase and post-optimization phase. Also note that we can possibly recycle the same sequence {\u03be k } across all gradient estimations in the post-optimization phase of 2-RSG method. We will provide in Theorem 2.4 below certain bounds on S, N and T , to compute an (\u01eb, \u039b)-solution of problem (1.1).\n\nWe need the following results regarding the large deviations of vector valued martingales (see, e.g., Theorem 2.1 of [15]). Lemma 2.3. Assume that we are given a polish space with Borel probability measure \u00b5 and a sequence of F 0 = {\u2205, \u2126} \u2286 F 1 \u2286 F 2 \u2286 . . . of \u03c3-sub-algebras of Borel \u03c3-algebra of \u2126. Let \u03b6 i \u2208 R n , i = 1, . . . , \u221e, be a martingale-difference sequence of Borel functions on \u2126 such that \u03b6 i is F i measurable and E[\u03b6 i |i \u2212 1] = 0, where E[\u00b7|i], i = 1, 2, . . ., denotes the conditional expectation w.r.t.\nF i and E \u2261 E[\u00b7|0] is the expectation w.r.t. \u00b5. a) If E[ \u03b6 i 2 ] \u2264 \u03c3 2 i for any i \u2265 1, then E[ N i=1 \u03b6 i 2 ] \u2264 N i=1 \u03c3 2 i .\nAs a consequence, we have (1) almost surely for any i \u2265 1, then\n\u2200N \u2265 1, \u03bb \u2265 0 : Prob N i=1 \u03b6 i 2 \u2265 \u03bb N i=1 \u03c3 2 i \u2264 1 \u03bb ; 11 b) If E exp \u03b6 i 2 /\u03c3 2 i |i \u2212 1 \u2264 exp\u2200N \u2265 1, \u03bb \u2265 0 : Prob \uf8f1 \uf8f2 \uf8f3 N i=1 \u03b6 i \u2265 \u221a 2(1 + \u03bb) N i=1 \u03c3 2 i \uf8fc \uf8fd \uf8fe \u2264 exp(\u2212\u03bb 2 /3).\nWe are now ready to describe the main convergence properties of the 2-RSG method. More specifically, Theorem 2.4.a) below shows the convergence rate of this algorithm for a given set of parameters (S, N, T ), while Theorem 2.4.b) establishes the complexity of the 2-RSG method for computing an (\u01eb, \u039b)-solution of problem (1.1).\n\nTheorem 2.4. Under Assumption A1, the following statements hold for the 2-RSG method applied to problem (1.1). a) Let B N be defined in (2.14). We have  \nProb \u2207f (x * ) 2 \u2265 2 4LB N + 3\u03bb\u03c3 2 T \u2264 S + 1 \u03bb + 2 \u2212S , \u2200 \u03bbN = N (\u01eb) := \uf8ee \uf8ef \uf8ef \uf8ef max \uf8f1 \uf8f2 \uf8f3 32L 2 D 2 f \u01eb , 32L D + D 2 f D \u03c3 \u01eb 2 \uf8fc \uf8fd \uf8fe \uf8f9 \uf8fa \uf8fa \uf8fa ,(2.(x s ) + g(x s ) \u2212 \u2207f (x s ) 2 \u2264 min s=1,...,S 2 \u2207f (x s ) 2 + 2 g(x s ) \u2212 \u2207f (x s ) 2 \u2264 2 min s=1,...,S \u2207f (x s ) 2 + 2 max s=1,...,S g(x s ) \u2212 \u2207f (x s ) 2 , which implies that \u2207f (x * ) 2 \u2264 2 g(x * ) 2 + 2 \u2207f (x * ) \u2212 g(x * ) 2 \u2264 4 min s=1,...,S \u2207f (x s ) 2 + 4 max s=1,...,S g(x s ) \u2212 \u2207f (x s ) 2 + 2 \u2207f (x * ) \u2212 g(x * ) 2 . (2.28)\nWe now provide certain probabilistic upper bounds to the three terms in the right hand side of the above inequality. Firstly, using the fact thatx s , 1 \u2264 s \u2264 S, are independent and relation (2.19) (with \u03bb = 2), we have Prob min\ns=1,...,S \u2207f (x s ) 2 \u2265 2LB N = S s=1 Prob \u2207f (x s ) 2 \u2265 2LB N \u2264 2 \u2212S .\n(2.29)\n\nMoreover, denoting \u03b4 s,k = G(x s , \u03be k )\u2212\u2207f (x s ), k = 1, . . . , T , we have g(x s )\u2212\u2207f (x s ) = T k=1 \u03b4 s,k /T . Using this observation, Assumption A1 and Lemma 2.3.a), we conclude that, for any s = 1, . . . , S, (2.30) and that\nProb g(x s ) \u2212 \u2207f (x s ) 2 \u2265 \u03bb\u03c3 2 T = Prob T k=1 \u03b4 s,k 2 \u2265 \u03bbT \u03c3 2 \u2264 1 \u03bb , \u2200\u03bb > 0, which implies that Prob max s=1,...,S g(x s ) \u2212 \u2207f (x s ) 2 \u2265 \u03bb\u03c3 2 T \u2264 S \u03bb , \u2200\u03bb > 0,Prob g(x * ) \u2212 \u2207f (x * ) 2 \u2265 \u03bb\u03c3 2 T \u2264 1 \u03bb , \u2200\u03bb > 0. (2.31)\nThe result then follows by combining relations (2.28), (2.29), (2.30) and (2.31). We now show that part b) holds. Since the 2-RSG method needs to call the RSG method S times with iteration limit N (\u01eb) in the optimization phase, and estimate the gradients g(x s ), s = 1, . . . , S with sample size T (\u01eb) in the post-optimization phase, the total number of calls to the stochastic first-order oracle is bounded by S[N (\u01eb) + T (\u01eb)]. It remains to show thatx * is an (\u01eb, \u039b)-solution of problem (1.1). Noting that by the definitions of B N and N (\u01eb), respectively, in (2.14) and (2.25), we have\nB N (\u01eb) = LD 2 f N (\u01eb) + D + D 2 f D \u03c3 N (\u01eb) \u2264 \u01eb 32L + \u01eb 32L = \u01eb 16L .\nUsing the above observation, (2.26) and setting \u03bb = [2(S + 1)]/\u039b in (2.23), we have\n4LB N (\u01eb) + 3\u03bb\u03c3 2 T (\u01eb) = \u01eb 4 + \u03bb\u039b\u01eb 8(S + 1) = \u01eb 2 ,\nwhich, together with relations (2.23) and (2.24), and the selection of \u03bb, then imply that\nProb \u2207f (x * ) 2 \u2265 \u01eb \u2264 \u039b 2 + 2 \u2212S \u2264 \u039b.\nIt is interesting to compare the complexity bound in (2.27) with the one in (2.20). In view of (2.24), (2.25) and (2.26), the complexity bound in (2.27), after disregarding a few constant factors, is equivalent to\nO log(1/\u039b) \u01eb + \u03c3 2 \u01eb 2 log 1 \u039b + log 2 (1/\u039b)\u03c3 2 \u039b\u01eb . (2.32)\nThe above bound can be considerably smaller than the one in (2.20) up to a factor of 1/ \u039b 2 log(1/\u039b) , when the second terms are the dominating ones in both bounds.\n\nThe following result shows that the bound (2.27) obtained in Theorem 2.4 can be further improved under certain light-tail assumption of SF O.\n\nCorollary 2.5. Under Assumptions A1 and A2, the following statements hold for the 2-RSG method applied to problem (1.1). 13 a) Let B N is defined in (2.14). We have, \u2200 \u03bb > 0,\nProb \u2207f (x * ) 2 \u2265 4 2LB N + 3(1 + \u03bb) 2 \u03c3 2 T \u2264 (S + 1)exp(\u2212\u03bb 2 /3) + 2 \u2212S ;\n(2.33) b) Let \u01eb > 0 and \u039b \u2208 (0, 1) be given. If S and N are set to S(\u039b) and N (\u01eb) as in (2.24) and (2.25), respectively, and the sample size T is set to  (2.36) and that\nT = T \u2032 (\u01ebProb g(x s ) \u2212 \u2207f (x s ) 2 \u2265 2(1 + \u03bb) 2 \u03c3 2 T = Prob T k=1 \u03b4 s,k \u2265 \u221a 2T (1 + \u03bb)\u03c3 \u2264 exp(\u2212\u03bb 2 /3), which implies that Prob max s=1,...,S g(x s ) \u2212 \u2207f (x s ) 2 \u2265 2(1 + \u03bb) 2 \u03c3 2 T \u2264 Sexp(\u2212\u03bb 2 /3), \u2200\u03bb > 0.Prob g(x * ) \u2212 \u2207f (x * ) 2 \u2265 2(1 + \u03bb) 2 \u03c3 2 T \u2264 exp(\u2212\u03bb 2 /3), \u2200\u03bb > 0. (2.37)\nThe result in part a) then follows by combining relations (2.28), (2.29), (2.36) and (2.37).\n\nIn view of (2.24), (2.25) and (2.34), the bound in (2.35), after disregarding a few constant factors, is equivalent to\nO log(1/\u039b) \u01eb + \u03c3 2 \u01eb 2 log 1 \u039b + log 2 (1/\u039b)\u03c3 2 \u01eb . (2.38)\nClearly, the third term of the above bound is significantly smaller than the corresponding one in (2.32) by a factor of 1/\u039b. Moreover, we assume that F (x, \u03be) \u2208 C 1,1 L (R n ) almost surely, which clearly implies f (x) \u2208 C 1,1 L (R n ). Our goal in this section is to specialize the RSG and 2-RSG method, respectively, in Subsections 3.1 and 3.2, to deal with the situation when only stochastic zeroth-order information of f is available.\n\n3.1. The randomized stochastic gradient free method. Throughout this section, we assume that f is represented by a stochastic zeroth-order oracle (SZO). More specifically, at the k-th iteration, x k and \u03be k being the input, the SZO outputs the quantity F (x k , \u03be k ) such that the following assumption holds:\n\nA3: For any k \u2265 1, we have\nE[F (x k , \u03be k )] = f (x k ). (3.2)\nTo exploit zeroth-order information, we consider a smooth approximation of the objective function f . It is well-known (see, e.g., [34], [6] and [41]) that the convolution of f with any nonnegative, measurable and bounded function \u03c8 : R n \u2192 R satisfying R n \u03c8(u) du = 1 is an approximation of f which is at least as smooth as f . One of the most important examples of the function \u03c8 is the probability density function. Here, we use the Gaussian distribution in the convolution. Let u be n-dimensional standard Gaussian random vector and \u00b5 > 0 be the smoothing parameter. Then, a smooth approximation of f is defined as\nf \u00b5 (x) = 1 (2\u03c0) n 2 f (x + \u00b5u)e \u2212 1 2 u 2 du = E u [f (x + \u00b5u)]. (3.\n3)\n\nThe following result due to Nesterov [28] describes some properties of f \u00b5 (\u00b7). Theorem 3.1. The following statements hold for any f \u2208 C 1,1 L . a) The gradient of f \u00b5 given by\n\u2207f \u00b5 (x) = 1 (2\u03c0) n 2 f (x + \u00b5u) \u2212 f (x) \u00b5 ue \u2212 1 2 u 2 du,(3.\n\n4)\n\nis Lipschitz continuous with constant L \u00b5 such that L \u00b5 \u2264 L; b) For any x \u2208 R n ,\n|f \u00b5 (x) \u2212 f (x)| \u2264 \u00b5 2 2 Ln, (3.5) \u2207f \u00b5 (x) \u2212 \u2207f (x) \u2264 \u00b5 2 L(n + 3) 3 2 ; (3.6) c) For any x \u2208 R n , 1 \u00b5 2 E u [{f (x + \u00b5u) \u2212 f (x)} 2 u 2 ] \u2264 \u00b5 2 2 L 2 (n + 6) 3 + 2(n + 4) \u2207f (x) 2 . (3.7)\nIt immediately follows from (3.6) that\n\u2207f \u00b5 (x) 2 \u2264 2 \u2207f (x) 2 + \u00b5 2 2 L 2 (n + 3) 3 , (3.8) \u2207f (x) 2 \u2264 2 \u2207f \u00b5 (x) 2 + \u00b5 2 2 L 2 (n + 3) 3 . (3.9)\nMoreover, denoting f * \u00b5 := min x\u2208R n f \u00b5 (x), (3.10)\n\nwe conclude from (3.5) that |f * \u00b5 \u2212 f * | \u2264 \u00b5 2 Ln/2 and hence that\n\u2212 \u00b5 2 Ln \u2264 [f \u00b5 (x) \u2212 f * \u00b5 ] \u2212 [f (x) \u2212 f * ] \u2264 \u00b5 2 Ln. (3.11)\nBelow we modify the RSG method in subsection (2.1) to use stochastic zerothorder rather than first-order information for solving problem (3.1).\n\nA randomized stochastic gradient free (RSGF) method Input: Initial point x 1 , iteration limit N , stepsizes {\u03b3 k } k\u22651 , probability mass function P R (\u00b7) supported on {1, . . . , N }.\n\nStep 0. Let R be a random variable with probability mass function P R .\n\nStep k = 1, . . . , R. Generate u k by Gaussian random vector generator and call the stochastic zeroth-order oracle for computing G \u00b5 (x k , \u03be k , u k ) given by\nG \u00b5 (x k , \u03be k , u k ) = F (x k + \u00b5u k , \u03be k ) \u2212 F (x k , \u03be k ) \u00b5 u k . (3.12) Set x k+1 = x k \u2212 \u03b3 k G \u00b5 (x k , \u03be k , u k ). (3.13) Output x R .\nNote that the esimator G \u00b5 (x k , \u03be k , u k ) of \u2207f \u00b5 (x k ) in (3.12) was suggested by Nesterov in [28]. Indeed, by (3.4) and Assumption A3, we have (3.14) which implies that G \u00b5 (x, \u03be, u) is an unbiased estimator of \u2207f \u00b5 (x). Hence, if the variance\u03c3 2 \u2261 E \u03be,u [ G \u00b5 (x, \u03be, u) \u2212 \u2207f \u00b5 (x) 2 ] is bounded, we can directly apply the convergence results in Theorem 2.1 to the above RSGF method. However, there still exist a few problems in this approach. Firstly, we do not know an explicit expression of the bound\u03c3 2 . Secondly, this approach does not provide any information regarding how to appropriately specify the smoothing parameter \u00b5. The latter issue is critical for the implementation of the RSGF method. By applying the approximation results in Theorem 3.1 to the functions F (\u00b7, \u03be k ), k = 1, . . . , N , and using a slightly different convergence analysis than the one in Theorem 2.1, we are able to obtain much refined convergence results for the above RSGF method. Then, under Assumptions A1 and A3, a) for any N \u2265 1, we have\nE \u03be,u [G \u00b5 (x, \u03be, u)] = E u [E \u03be [G \u00b5 (x, \u03be, u)|u]] = \u2207f \u00b5 (x),1 L E[ \u2207f (x R ) 2 ] \u2264 1 N k=1 [\u03b3k\u22122L(n+4)\u03b3 2 k ] D 2 f + 2\u00b5 2 (n + 4) 1 + L(n + 4) 2 N k=1 ( \u03b3 k 4 + L\u03b3 2 k ) + 2(n + 4)\u03c3 2 N k=1 \u03b3 2 k , (3.16)\nwhere the expectation is taken with respect to R, \u03be [N ] and u [N ] , and D f is defined in(2.5); b) if, in addition, problem (3.1) is convex with an optimal solution x * , then, for any N \u2265 1,\nE[f (x R ) \u2212 f * ] \u2264 1 2 N k=1 [\u03b3k\u22122(n+4)L\u03b3 2 k ] D 2 X + 2\u00b5 2 L(n + 4) N k=1 \u03b3 k + L(n + 4) 2 \u03b3 2 k + 2(n + 4)\u03c3 2 N k=1 \u03b3 2 k , (3.17)\nwhere the expectation is taken with respect to R, \u03be [N ] and u [N ] , and D X is defined in (2.7).\nProof. Let \u03b6 k \u2261 (\u03be k , u k ), k \u2265 1, \u03b6 [N ] := (\u03b6 1 , ..., \u03b6 N ), and E \u03b6[N ] denote the ex- pectation w.r.t. \u03b6 [N ] . Also denote \u2206 k \u2261 G \u00b5 (x k , \u03be k , u k ) \u2212 \u2207f \u00b5 (x k ) \u2261 G \u00b5 (x k , \u03b6 k ) \u2212 \u2207f \u00b5 (x k ), k \u2265 1.\nUsing the fact that f \u2208 C 1,1 L (R n ), Theorem 3.1.a), (1.6) and (3.13), we have, for any k = 1, . . . , N ,\nf \u00b5 (x k+1 ) \u2264 f \u00b5 (x k ) \u2212 \u03b3 k \u2207f \u00b5 (x k ), G \u00b5 (x k , \u03b6 k ) + L 2 \u03b3 2 k G \u00b5 (x k , \u03b6 k ) 2 = f \u00b5 (x k ) \u2212 \u03b3 k \u2207f \u00b5 (x k ) 2 \u2212 \u03b3 k \u2207f \u00b5 (x k ), \u2206 k + L 2 \u03b3 2 k G \u00b5 (x k , \u03b6 k ) 2 .\n(3.18) Summing up these inequalities, re-arranging the terms and noting that f *\n\u00b5 \u2264 f \u00b5 (x N +1 ), we obtain N k=1 \u03b3 k \u2207f \u00b5 (x k ) 2 \u2264 f \u00b5 (x 1 ) \u2212 f * \u00b5 \u2212 N k=1 \u03b3 k \u2207f \u00b5 (x k ), \u2206 k + L 2 N k=1 \u03b3 2 k G \u00b5 (x k , \u03b6 k ) 2 .\n(3.19) Now, observe that by (3.14),\nE[ \u2207f \u00b5 (x k ), \u2206 k |\u03b6 [k\u22121] ] = 0.\n( 3.20) and that by the assumption F (\u00b7, \u03be k ) \u2208 C 1,1 L (R n ), (3.7) (with f = F (\u00b7, \u03be k )), and (3.12),\nE[ G \u00b5 (x k , \u03b6 k ) 2 |\u03b6 [k\u22121] ] \u2264 2(n + 4)E[ G(x k , \u03be k ) 2 |\u03b6 [k\u22121] ] + \u00b5 2 2 L 2 (n + 6) 3 \u2264 2(n + 4) E[ \u2207f (x k ) 2 |\u03b6 [k\u22121] ] + \u03c3 2 + \u00b5 2 2 L 2 (n + 6) 3 ,(3.\n21) where the second inequality follows from Assumption A1. Taking expectations with respect to \u03b6 [N ] on both sides of (3.19) and using the above two observations, we obtain\nN k=1 \u03b3 k E \u03b6[N ] \u2207f \u00b5 (x k ) 2 \u2264 f \u00b5 (x 1 ) \u2212 f * \u00b5 + L 2 N k=1 \u03b3 2 k 2(n + 4) E \u03b6[N ] [ \u2207f (x k ) 2 ] + \u03c3 2 + \u00b5 2 2 L 2 (n + 6) 3 .\nThe above conclusion together with (3.8) and (3.11) then imply that\nN k=1 \u03b3 k E \u03b6[N ] [ \u2207f (x k ) 2 ] \u2212 \u00b5 2 2 L 2 (n + 3) 3 \u2264 2 [f (x 1 ) \u2212 f * ] + 2\u00b5 2 Ln +2L(n + 4) N k=1 \u03b3 2 k E \u03b6[N ] [ \u2207f (x k ) 2 ] + 2L(n + 4)\u03c3 2 + \u00b5 2 2 L 3 (n + 6) 3 N k=1 \u03b3 2 k . (3.22)\nBy re-arranging the terms and simplifying the constants, we have N k=1\n\u03b3 k \u2212 2L(n + 4)\u03b3 2 k E \u03b6[N ] [ \u2207f (x k ) 2 ] \u2264 2 [f (x 1 ) \u2212 f * ] + 2L(n + 4)\u03c3 2 N k=1 \u03b3 2 k + 2\u00b5 2 Ln + \u00b5 2 2 L 2 N k=1 (n + 3) 3 \u03b3 k + L(n + 6) 3 \u03b3 2 k \u2264 2 [f (x 1 ) \u2212 f * ] + 2L(n + 4)\u03c3 2 N k=1 \u03b3 2 k + 2\u00b5 2 L(n + 4) 1 + L(n + 4) 2 N k=1 ( \u03b3 k 4 + L\u03b3 2 k ) . (3.23)\nDividing both sides of the above inequality by N k=1 \u03b3 k \u2212 2L(n + 4)\u03b3 2 k and noting that\nE[ \u2207f (x R ) 2 ] = E R,\u03b6[N ] [ \u2207f (x R ) 2 ] = N k=1 \u03b3 k \u2212 2L(n + 4)\u03b3 2 k E \u03b6[N ] \u2207f (x k ) 2 N k=1 [\u03b3 k \u2212 2L(n + 4)\u03b3 2 k ]\n, we obtain (3.16). We now show part b). Denote \u03c9 k \u2261 x k \u2212 x * . First observe that, for any k = 1, . . . , N ,\n\u03c9 2 k+1 = x k \u2212 \u03b3 k G \u00b5 (x k , \u03b6 k ) \u2212 x * 2 = \u03c9 2 k \u2212 2\u03b3 k \u2207f \u00b5 (x k ) + \u2206 k , x k \u2212 x * + \u03b3 2 k G \u00b5 (x k , \u03b6 k ) 2 .\nand hence that\n\u03c9 2 N +1 = \u03c9 2 1 \u22122 N k=1 \u03b3 k \u2207f \u00b5 (x k ), x k \u2212x * \u22122 N k=1 \u03b3 k \u2206 k , x k \u2212x * + N k=1 \u03b3 2 k G \u00b5 (x k , \u03b6 k ) 2 .\nTaking expectation w.r.t. \u03b6 \u03b6[N ] on both sides of the above equality, using relation (3.21) and noting that by (3.14),\nE[ \u2206 k , x k \u2212 x * |\u03b6 [k\u22121] ] = 0, we obtain E \u03b6[N ] [\u03c9 2 N +1 ] \u2264 \u03c9 2 1 \u2212 2 N k=1 \u03b3 k E \u03b6[N ] [ \u2207f \u00b5 (x k ), x k \u2212 x * ] + 2(n + 4) N k=1 \u03b3 2 k E \u03b6[N ] [ \u2207f (x k ) 2 ] + 2(n + 4)\u03c3 2 + \u00b5 2 2 L 2 (n + 6) 3 N k=1 \u03b3 2 k \u2264 \u03c9 2 1 \u2212 2 N k=1 \u03b3 k E \u03b6[N ] [f \u00b5 (x k ) \u2212 f \u00b5 (x * )] + 2(n + 4)L N k=1 \u03b3 2 k E \u03b6[N ] [f (x k ) \u2212 f * ] + 2(n + 4)\u03c3 2 + \u00b5 2 2 L 2 (n + 6) 3 N k=1 \u03b3 2 k \u2264 \u03c9 2 1 \u2212 2 N k=1 \u03b3 k E \u03b6[N ] f (x k ) \u2212 f * \u2212 \u00b5 2 Ln + 2(n + 4)L N k=1 \u03b3 2 k E \u03b6[N ] [f (x k ) \u2212 f * ] + 2(n + 4)\u03c3 2 + \u00b5 2 2 L 2 (n + 6) 3 N k=1 \u03b3 2 k ,\nwhere the second inequality follows from (2.12) and the convexity of f \u00b5 , and the last inequality follows from (3.5). Re-arranging the terms in the above inequality, using the facts that \u03c9 2 N +1 \u2265 0 and f (x k ) \u2265 f * , and simplifying the constants, we have\n2 N k=1 \u03b3 k \u2212 2(n + 4)L\u03b3 2 k ) E \u03b6[N ] [f (x k ) \u2212 f * ] \u2264 2 N k=1 \u03b3 k \u2212 (n + 4)L\u03b3 2 k ) E \u03b6[N ] [f (x k ) \u2212 f * ] \u2264 \u03c9 2 1 + 2\u00b5 2 L(n + 4) N k=1 \u03b3 k + 2(n + 4) L 2 \u00b5 2 (n + 4) 2 + \u03c3 2 N k=1 \u03b3 2 k .\nThe rest of proof is similar to part a) and hence the details are skipped.\n\nSimilarly to the RSG method, we can specialize the convergence results in Theorem 3.2 for the RSGF method with a constant stepsize policy. Corollary 3.3. Suppose that the stepsizes {\u03b3 k } are set to\n\u03b3 k = 1 \u221a n + 4 min 1 4L \u221a n + 4 ,D \u03c3 \u221a N , k = 1, . . . , N,(3.24)\nfor someD > 0. Also assume that the probability mass function P R (\u00b7) is set to (3.15) and \u00b5 is chosen such that\n\u00b5 \u2264 D f (n + 4) \u221a 2N (3.25)\nwhere D f and D X are defined in (2.5) and (2.7), respectively. Then, under Assumptions A1 and A3, we have\n1 L E[ \u2207f (x R ) 2 ] \u2264B N := 12(n + 4)LD 2 f N + 4\u03c3 \u221a n + 4 \u221a N D + D 2 f D . (3.26)\nIf, in addition, problem (3.1) is convex with an optimal solution x * and \u00b5 is chosen such that\n\u00b5 \u2264 D X (n + 4) ,\nthen, Therefore, using the above inequalities and (3.16), we obtain\nE[f (x R ) \u2212 f * ] \u2264 5L(n + 4)D 2 X N + 2\u03c3 \u221a n + 4 \u221a N D + D 2 X D .(3.1 L E[ \u2207f (x R ) 2 ] \u2264 2D 2 f + 4\u00b5 2 (n + 4) N \u03b3 1 + \u00b5 2 L(n + 4) 3 + 4(n + 4) \u00b5 2 L 2 (n + 4) 2 + \u03c3 2 \u03b3 1 \u2264 2D 2 f + 4\u00b5 2 (n + 4) N max 4L(n + 4), \u03c3 (n + 4)\u00d1 D + \u00b5 2 L(n + 4) 2 [(n + 4) + 1] + 4 \u221a n + 4D\u03c3 \u221a N ,\nwhich, in view of (3.25), then implies that\n1 L E[ \u2207f (x R ) 2 ] \u2264 2D 2 f N 1 + 1 (n + 4)N 4L(n + 4) + \u03c3 (n + 4)\u00d1 D + LD 2 f 2N [(n + 4) + 1] + 4 \u221a n + 4D\u03c3 \u221a N = LD 2 f N 17(n + 4) 2 + 8 N + 1 2 + 2\u03c3 \u221a n + 4 \u221a N D 2 f D 1 + 1 (n + 4)N + 2D \u2264 12L(n + 4)D 2 f N + 4\u03c3 \u221a n + 4 \u221a N D + D 2 f D .\nA few remarks about the results obtained in Corollary 2.2 are in order. Firstly, similar to the RSG method, we use the same selection of stepsizes {\u03b3 k } and probability mass function P R (\u00b7) in RSGF method for both convex and nonconvex SP problems. In particular, in view of (3.26), the iteration complexity of the RSGF method for finding an \u01eb-solution of problem (3.1) can be bounded by O(n/\u01eb 2 ). Moreover, in view of (3.27), if the problem is convex, a solutionx satisfying E[f (x) \u2212 f * ] \u2264 \u01eb can also be found in O(n/\u01eb 2 ) iterations. This result has a weaker dependence (by a factor of n) than the one established by Nesterov for solving general nonsmooth convex SP problems (see page 17 of [28]). This improvement is obtained since we are dealing with a more special class of SP problems. Also, note that in the case of \u03c3 = 0, the iteration complexity of the RSGF method reduces to O(n/\u01eb) which is is similar to the one obtained by Nesterov [28] for the derivative free random search method when applied to both smooth convex and nonconvex deterministic problems.\n\nSecondly, we need to specifyD for the stepsize policy in (3.24). According to (3.26) and (3.27), an optimal selection ofD would be D f and D X , respectively, for the nonconvex and convex case. With such selections, the bounds in (3.26) and (3.27), respectively, reduce to\n1 L E[ \u2207f (x R ) 2 ] \u2264 12(n + 4)LD 2 f N + 8 \u221a n + 4D f \u03c3 \u221a N , (3.30) E[f (x R ) \u2212 f * ] \u2264 5L(n + 4)D 2 X N + 4 \u221a n + 4D X \u03c3 \u221a N . (3.31)\nSimilarly to the RSG method, we can establish the complexity of the RSGF method for finding an (\u01eb, \u039b)-solution of problem (3.1) for some \u01eb > 0 and \u039b \u2208 (0, 1). More specifically, by using (3.26) and Markov's inequality, we have (3.32) which implies that the total number of calls to the SZO performed by the RSGF method for finding an (\u01eb, \u039b)-solution of (3.1) can be bounded by\nProb \u2207f (x R ) 2 \u2265 \u03bbLB N \u2264 1 \u03bb , \u2200\u03bb > 0,O \uf8f1 \uf8f2 \uf8f3 nL 2 D 2 f \u039b\u01eb + nL 2 \u039b 2 D + D 2 f D 2 \u03c3 2 \u01eb 2 \uf8fc \uf8fd \uf8fe .\n(3.33)\n\nWe will investigate a possible approach to improve the above complexity bound in next subsection.\n\n\n3.2.\n\nA two-phase randomized stochastic gradient free method. In this section, we modify the 2-RSG method to improve the complexity bound in (3.33) for finding an (\u01eb, \u039b)-solution of problem (3.1).\n\nA two-phase RSGF (2-RSGF) method Input: Initial point x 1 , number of runs S, iteration limit N , and sample size T .\n\nOptimization phase: For s = 1, . . . , S Call the RSGF method with input x 1 , iteration limit N , stepsizes {\u03b3 k } in (3.24), probability mass function P R in (3.15), and the smoothing parameter \u00b5 satisfying (3.25). Letx s be the output of this procedure. Post-optimization phase:\n\nChoose a solutionx * from the candidate list {x 1 , . . . ,x S } such that g \u00b5 (x * ) = min s=1,...,S g \u00b5 (x s ) , g \u00b5 (x s ) := 1 T T k=1 G \u00b5 (x s , \u03be k , u k ), (3.34) where G \u00b5 (x, \u03be, u) is defined in (3.12).\n\nThe main convergence properties of the 2-RSGF method are summarized in Theorem 3.4. More specifically, Theorem 3.4.a) establishes the rate of convergence of the 2-RSGF method with a given set of parameters (S, N, T ), while Theorem 3.4.b) shows the complexity of this method for finding an (\u01eb, \u039b)-solution of problem (3.1).\n\nTheorem 3.4. Under Assumptions A1 and A3, the following statements hold for the 2-RSGF method applied to problem (3.1). a) LetB N be defined in (3.26). We have\nProb \u2207f (x * ) 2 \u2265 8LB N + 3(n+4)L 2 D 2 f 2N + 24(n+4)\u03bb T LB N + (n+4)L 2 D 2 f N + \u03c3 2 \u2264 S+1\n\u03bb + 2 \u2212S , \u2200 \u03bb > 0; (3.35) b) Let \u01eb > 0 and \u039b \u2208 (0, 1) be given. If S is set to S(\u039b) as in (2.24), and the iteration limit N and sample size T , respectively, are set to where the last inequality also follows from (3.39). We now provide certain probabilistic bounds on the individual terms in the right hand side of the above inequality. Using  \nD \u2264 \u01eb 36L + \u01eb 18L = \u01eb 12L\n.\n\nHence, we have 8LBN (\u01eb) + 3(n + 4)L 2 D 2\n\n\nLet \u01eb > 0 and \u039b \u2208 (0, 1) be given. If the parameters (S, N, T ) are set to S = S(\u039b) := \u2308log(2/\u039b)\u2309 , (2.24)\n\n\n2-RSG method can compute an (\u01eb, \u039b)-solution of problem (1.1) after taking at most S(\u039b) [N (\u01eb) + T (\u01eb, \u039b)] (2.27) calls to the stochastic first-order oracle. Proof. We first show part a). Observe that by the definition ofx * in (2.21), we have g(x * ) 2 = min s=1,...,S g(x s ) 2 = min s=1,...,S \u2207f\n\n\n2-RSG method can compute an (\u01eb, \u039b)-solution of problem (1.1) in at most S(\u039b) [N (\u01eb) + T \u2032 (\u01eb, \u039b)] (2.35) calls to the stochastic first-order oracle. Proof. We provide the proof of part a) only, since part b) follows immediately from part a) and an argument similar to the one used in the proof of Theorem 2.4.b). Denoting \u03b4 s,k = G(x s , \u03be k ) \u2212 \u2207f (x s ), k = 1, . . . , T , we have g(x s ) \u2212 \u2207f (x s ) = T k=1 \u03b4 s,k /T . Using this observation, Assumption A2 and Lemma 2.3.b), we conclude that, for any s = 1, . . . , S and \u03bb > 0,\n\n3 .\n3Stochastic zeroth-order methods. Our problem of interest in this section is problem (1.1) with f given in (1.4), i.e., f * := inf x\u2208R n f (x) := \u039e F (x, \u03be)dP (\u03be) . (3.1)\n\nTheorem 3 . 2 .\n32Suppose that the stepsizes {\u03b3 k } and the probability mass function P R (\u00b7) in the RSGF method are chosen such that \u03b3 k < 1/[2(n + 4)L] and P R (k) := Prob{R = k} = \u03b3 k \u2212 2L(n + 4)\u03b3 2 k N k=1 [\u03b3 k \u2212 2L(n + 4)\u03b3 2 k ] , k = 1, ..., N. (3.15)\n\n\nthe SZO.Proof. First, observe that by(3.6),(3.25)  and(3.26), we have \u2207f \u00b5 (x) \u2212 \u2207f (x) observation and the definition ofx * in (3.34), we obtaing \u00b5 (x * ) 2 = min s=1,...,S g \u00b5 (x s ) 2 = min s=1,...,S \u2207f (x s ) + g \u00b5 (x s ) \u2212 \u2207f (x s ) 2 \u2264 min s=1,...,S 2 \u2207f (x s ) 2 + g \u00b5 (x s ) \u2212 \u2207f (x s ) 2 \u2264 min s=1,...,S 2 \u2207f (x s ) 2 + 2 g \u00b5 (x s ) \u2212 \u2207f \u00b5 (x s ) 2 + 2 \u2207f \u00b5 (x s ) \u2212 \u2207f (x s ) 2 \u2264 2 min s=1,...,S \u2207f (x s ) 2 + 4 max s=1,...,S g \u00b5 (x s ) \u2212 \u2207f (x s ) \u2207f (x * ) 2 \u2264 2 g \u00b5 (x * ) 2 + 2 \u2207f (x * ) \u2212 g \u00b5 (x * ) 2 \u2264 2 g \u00b5 (x * ) 2 + 4 \u2207f \u00b5 (x * ) \u2212 g \u00b5 (x * ) 2 + 4 \u2207f (x * ) \u2212 \u2207f \u00b5 (x * ) 2 \u2264 4 min s=1,...,S \u2207f (x s ) 2 + 8 max s=1,...,S g \u00b5 (x s ) \u2212 \u2207f (x s ) \u2207f \u00b5 (x * ) \u2212 g \u00b5 (x * ) 2 + 4 \u2207f (x * ) \u2212 \u2207f \u00b5 (x * ) 2 \u2264 4 mins=1,...,S \u2207f (x s ) 2 + 8 max s=1,...,S g \u00b5 (x s ) \u2212 \u2207f (x s ) 2 + 4 \u2207f \u00b5 (x * ) \u2212 g \u00b5 (x * )\n\n\u2207f (x s ) 2 \u2265\n22LB N = S s=1 Prob \u2207f (x s ) 2 \u2265 2LB N \u2264 2 \u2212S .\n\n\ndenote \u2206 s,k = G \u00b5 (x s , \u03be k , u k ) \u2212 \u2207f \u00b5 (x s ), k = 1, . . . , T . Note that, similar to (3.21), we haveE[ G \u00b5 (x s , \u03be k , u k ) 2 ] \u2264 2(n + 4)[E[ G(x s , \u03be) 2 ] + \u00b5 2 2 L 2 (n + 6) 3 \u2264 2(n + 4)[E[ \u2207f (x s ) 2 ] + \u03c3 2 ] + 2\u00b5 2 L 2 (n + 4) 3 .22It then follows from the previous inequality,(3.25)  and(3.26) thatE[ \u2206 s,k 2 ] = E[ G \u00b5 (x s , \u03be k , u k ) \u2212 \u2207f \u00b5 (x s ) 2 ] \u2264 E[ G \u00b5 (x s , \u03be k , u k ) g \u00b5 (x s ) \u2212 \u2207f \u00b5 (x s ) =T k=1 \u2206 s,k /T , we conclude from (3.42), Assumption A1 and Lemma 2.3.a) that, for any s = 1, . . . , S,Prob g \u00b5 (x s ) \u2212 \u2207f \u00b5 (x s ) (x s ) \u2212 \u2207f \u00b5 (x s ) \u00b5 (x * ) \u2212 \u2207f \u00b5 (x * )then follows by combining relations (3.40), (3.41),(3.42), (3.43) and (3.44). We now show part b) holds. Clearly, the total number of calls to SZO in the 2-RSGF method is bounded by 2S[N (\u01eb) +T (\u01eb)]. It then suffices to show thatx * is an (\u01eb, \u039b)-solution of problem (3.1). Noting that by the definitions ofB(N ) andN (\u01eb), respectively, in (3.26) and (3.36), we hav\u0113 BN (\u01eb)\n\n27 )\n27Proof. We prove(3.26)  only since relation(3.27)  can be shown by using similar arguments. First note that by (3.24), we have\u03b3 k \u2264 \n1 \n4(n + 4)L \n, k = 1, . . . , N, \n(3.28) \n\nN \n\nk=1 \n\n\u03b3 k \u2212 2L(n + 4)\u03b3 2 \nk = N \u03b3 1 [1 \u2212 2L(n + 4)\u03b3 1 ] \u2265 \n\nN \u03b3 1 \n2 \n. \n(3.29) \n\n19 \n\n\nMoreover, by setting \u03bb = [2(S + 1)]/\u039b and using(3.36)and(3.37), we obtainUsing these two observations and relation (3.35) with \u03bb = [2(S + 1)]/\u039b, we conclude thatObserve that in the view of (2.24),(3.36)and(3.37), the total number of calls to SZO performed by the 2-RSGF method can be bounded by(3.45) The above bound is considerably smaller than the one in (3.33), up to a factor of O 1/[\u039b 2 log(1/\u039b)] , when the second terms are the dominating ones in both bounds.4. Concluding remarks. In this paper, we present a class of new SA methods for solving the classical unconstrained NLP problem with noisy first-order information.We establish a few new complexity results regarding the computation of an \u01eb-solution for solving this class of problems and show that they are nearly optimal whenever the problem is convex. Moreover, we introduce a post-optimization phase in order to improve the large-deviation properties of the RSG method. These procedures, along with their complexity results, are then specialized for simulation-based optimization problems when only stochastic zeroth-order information is available. In addition, we show that the complexity for gradient-free methods for smooth convex SP can have a much weaker dependence on the dimension n than that for more general nonsmooth convex SP.\nA review of simulation optimization techniques. S Andrad\u00f3ttir, Proceedings of the 1998 Winter Simulation Conference. the 1998 Winter Simulation ConferenceS. Andrad\u00f3ttir. A review of simulation optimization techniques. Proceedings of the 1998 Winter Simulation Conference, pages 151-158.\n\nOn the complexity of steepest descent, newton's and regularized newton's methods for nonconvex unconstrained optimization. C Cartis, N I M Gould, Ph L Toint, SIAM Journal on Optimization. 206C. Cartis, N. I. M. Gould, and Ph. L. Toint. On the complexity of steepest descent, newton's and regularized newton's methods for nonconvex unconstrained optimization. SIAM Journal on Optimization, 20(6):2833-2852, 2010.\n\nOn the oracle complexity of first-order and derivative-free algorithms for smooth nonconvex minimization. C Cartis, N I M Gould, Ph L Toint, SIAM Journal on Optimization. 22C. Cartis, N. I. M. Gould, and Ph. L. Toint. On the oracle complexity of first-order and derivative-free algorithms for smooth nonconvex minimization. SIAM Journal on Opti- mization, 22:66-86, 2012.\n\nOn a stochastic approximation method. K L Chung, Annals of Mathematical Statistics. K.L. Chung. On a stochastic approximation method. Annals of Mathematical Statistics, pages 463-483, 1954.\n\nIntroduction to Derivative-Free Optimization. A R Conn, K Scheinberg, L N Vicente, SIAM, PhiladelphiaA. R. Conn, K. Scheinberg, and L. N. Vicente. Introduction to Derivative-Free Optimization. SIAM, Philadelphia, 2009.\n\nRandomized smoothing for stochastic optimization. J C Duchi, P L Bartlett, M J Wainwright, SIAM Journal on Optimization. 22J. C. Duchi, P. L. Bartlett, and M. J. Wainwright. Randomized smoothing for stochastic optimization. SIAM Journal on Optimization, 22:674-701, 2012.\n\nOptimization for simulation: Theory vs. practice. M Fu, INFORMS Journal on Computing. 14M. Fu. Optimization for simulation: Theory vs. practice. INFORMS Journal on Computing, 14:192-215, 2002.\n\nGradient estimation. M C Fu, Handbooks in Operations Research and Management Science: Simulation. S. G. Henderson and B. L. NelsonElsevierM.C. Fu. Gradient estimation. In S. G. Henderson and B. L. Nelson, editors, Handbooks in Operations Research and Management Science: Simulation, pages 575-616. Elsevier.\n\nSmoothing and worst-case complexity for direct-search methods in nonsmooth optimization. R Garmanjani, L N Vicente, IMA Journal of Numerical Analysis. to appearR. Garmanjani and L. N. Vicente. Smoothing and worst-case complexity for direct-search methods in nonsmooth optimization. IMA Journal of Numerical Analysis, 2012. to appear.\n\nOptimal stochastic approximation algorithms for strongly convex stochastic composite optimization, II: shrinking procedures and optimal algorithms. S Ghadimi, G Lan, SIAM Journal on Optimization. Technical reportunder second-round reviewS. Ghadimi and G. Lan. Optimal stochastic approximation algorithms for strongly convex stochastic composite optimization, II: shrinking procedures and optimal algorithms. Tech- nical report, 2010. SIAM Journal on Optimization (under second-round review).\n\nOptimal stochastic approximation algorithms for strongly convex stochastic composite optimization, I: a generic algorithmic framework. S Ghadimi, G Lan, SIAM Journal on Optimization. 22S. Ghadimi and G. Lan. Optimal stochastic approximation algorithms for strongly convex stochastic composite optimization, I: a generic algorithmic framework. SIAM Journal on Optimization, 22:1469-1492, 2012.\n\nStochastic first-and zeroth-order methods for nonconvex stochastic programming. S Ghadimi, G Lan, SIAM Journal on Optimization. Department of Industrial and Systems Engineering, University of FloridaTechnical reportunder second-round reviewS. Ghadimi and G. Lan. Stochastic first-and zeroth-order methods for nonconvex stochastic programming. Technical report, Department of Industrial and Systems Engineering, Uni- versity of Florida, Gainesville, FL 32611, USA, June 2012. SIAM Journal on Optimization (under second-round review).\n\nGradient Estimation via Perturbation Analysis. P Glasserman, Kluwer Academic PublishersBoston,MassachusettsP. Glasserman. Gradient Estimation via Perturbation Analysis. Kluwer Academic Publishers, Boston,Massachusetts, 2003.\n\nRecursive aggregation of estimators via the mirror descent algorithm with average. Problems of Information Transmission. A Juditsky, A Nazin, A B Tsybakov, N Vayatis, 41A. Juditsky, A. Nazin, A. B. Tsybakov, and N. Vayatis. Recursive aggregation of estimators via the mirror descent algorithm with average. Problems of Information Transmission, 41:n.4, 2005.\n\nLarge deviations of vector-valued martingales in 2-smooth normed spaces. Manuscript, Georgia Institute of Technology. A Juditsky, A Nemirovski, Atlanta, GAE-print: www2.isye.gatech.edu/\u223c nemirovs/LargeDevSubmitted.pdfA. Juditsky and A. Nemirovski. Large deviations of vector-valued martingales in 2-smooth normed spaces. Manuscript, Georgia Institute of Technology, Atlanta, GA, 2008. E-print: www2.isye.gatech.edu/\u223c nemirovs/LargeDevSubmitted.pdf.\n\nLearning by mirror averaging. A Juditsky, P Rigollet, A B Tsybakov, Annals of Statistics. 36A. Juditsky, P. Rigollet, and A. B. Tsybakov. Learning by mirror averaging. Annals of Statis- tics, 36:2183-2206, 2008.\n\nThe sample average approximation method for stochastic discrete optimization. A J Kleywegt, A Shapiro, T Homem De Mello, SIAM Journal on Optimization. 12A. J. Kleywegt, A. Shapiro, and T. Homem de Mello. The sample average approximation method for stochastic discrete optimization. SIAM Journal on Optimization, 12:479-502, 2001.\n\nAn optimal method for stochastic composite optimization. G Lan, Mathematical Programming. 1331G. Lan. An optimal method for stochastic composite optimization. Mathematical Programming, 133(1):365-397, 2012.\n\nValidation analysis of mirror descent stochastic approximation method. G Lan, A Nemirovski, A Shapiro, Mathematical Programming. 134G. Lan, A. Nemirovski, and A. Shapiro. Validation analysis of mirror descent stochastic ap- proximation method. Mathematical Programming, 134:425-458, 2012.\n\nA unified view of the IPA, SF, and LR gradient estimation techniques. P L\u00e9cuyer, Management Science. 3611P. L\u00c9cuyer. A unified view of the IPA, SF, and LR gradient estimation techniques. Management Science, 36(11):1364-1383, 1990.\n\nOnline dictionary learning for sparse coding. J Mairal, F Bach, J Ponce, G Sapiro, ICML. J. Mairal, F. Bach, J. Ponce, and G. Sapiro. Online dictionary learning for sparse coding. In In ICML, pages 689-696, 2009.\n\nBoosting algorithms as gradient descent in function space. L Mason, J Baxter, P Bartlett, M Frean, Proc. NIPS. 12L. Mason, J. Baxter, P. Bartlett, and M. Frean. Boosting algorithms as gradient descent in function space. Proc. NIPS, 12:512-518, 1999.\n\nRobust stochastic approximation approach to stochastic programming. A Nemirovski, A Juditsky, G Lan, A Shapiro, SIAM Journal on Optimization. 19A. Nemirovski, A. Juditsky, G. Lan, and A. Shapiro. Robust stochastic approximation approach to stochastic programming. SIAM Journal on Optimization, 19:1574-1609, 2009.\n\nProblem complexity and method efficiency in optimization. A Nemirovski, D Yudin, Wiley-Interscience Series in Discrete Mathematics. XVA. Nemirovski and D. Yudin. Problem complexity and method efficiency in optimization. Wiley- Interscience Series in Discrete Mathematics. John Wiley, XV, 1983.\n\nA method for unconstrained convex minimization problem with the rate of convergence O(1/k 2 ). Y E Nesterov, Doklady AN SSSR. 269Y. E. Nesterov. A method for unconstrained convex minimization problem with the rate of convergence O(1/k 2 ). Doklady AN SSSR, 269:543-547, 1983.\n\nIntroductory Lectures on Convex Optimization: a basic course. Y E Nesterov, Kluwer Academic PublishersMassachusettsY. E. Nesterov. Introductory Lectures on Convex Optimization: a basic course. Kluwer Aca- demic Publishers, Massachusetts, 2004.\n\nPrimal-dual subgradient methods for convex problems. Y E Nesterov, Mathematical Programming. 120Y. E. Nesterov. Primal-dual subgradient methods for convex problems. Mathematical Pro- gramming, 120:221-259, 2006.\n\nRandom gradient-free minimization of convex functions. Y E Nesterov, Center for Operations Research and Econometrics (CORE), Catholic University of LouvainTechnical reportY. E. Nesterov. Random gradient-free minimization of convex functions. Technical report, Center for Operations Research and Econometrics (CORE), Catholic University of Louvain, January 2010.\n\nConfidence level solutions for stochastic programming. Y E Nesterov, J P Vial, Y. E. Nesterov and J. P. Vial. Confidence level solutions for stochastic programming. 2000.\n\nNumerical optimization. J Nocedal, S J Wright, Springer-VerlagNew York, USAJ. Nocedal and S. J. Wright. Numerical optimization. Springer-Verlag, New York, USA, 1999.\n\nNew stochastic approximation type procedures. B T Polyak, Automat. i Telemekh. 7B.T. Polyak. New stochastic approximation type procedures. Automat. i Telemekh., 7:98-107, 1990.\n\nAcceleration of stochastic approximation by averaging. B T Polyak, A B Juditsky, SIAM J. Control and Optimization. 30B.T. Polyak and A.B. Juditsky. Acceleration of stochastic approximation by averaging. SIAM J. Control and Optimization, 30:838-855, 1992.\n\nA stochastic approximation method. H Robbins, S Monro, Annals of Mathematical Statistics. 22H. Robbins and S. Monro. A stochastic approximation method. Annals of Mathematical Statistics, 22:400-407, 1951.\n\nVariational analysis, ser. Grundlehren der Mathematischen Wissenschaften. R T Rockafellar, R , J.-B Wets, Fundamental Principles of Mathematical SciencesR. T. Rockafellar and R. J.-B. Wets. Variational analysis, ser. Grundlehren der Mathematis- chen Wissenschaften [Fundamental Principles of Mathematical Sciences].\n\n. Springer-Verlag, BerlinSpringer-Verlag, Berlin, 1998.\n\nDiscrete Event Systems: Sensitivity Analysis and Stochastic Optimization by the Score Function Method. R Y Rubinstein, A Shapiro, John Wiley & SonsR.Y. Rubinstein and A. Shapiro. Discrete Event Systems: Sensitivity Analysis and Stochastic Optimization by the Score Function Method. John Wiley & Sons, 1993.\n\nRecursive trust-region methods for multiscale nonlinear optimization. A Sartenaer, S Gratton, Ph L Toint, SIAM Journal on Optimization. 19A. Sartenaer S. Gratton and Ph. L. Toint. Recursive trust-region methods for multiscale nonlinear optimization. SIAM Journal on Optimization, 19:414-444, 2008.\n\nAsymptotic distribution of stochastic approximation. J Sacks, Annals of Mathematical Statistics. 29J. Sacks. Asymptotic distribution of stochastic approximation. Annals of Mathematical Statis- tics, 29:373-409, 1958.\n\nMonte carlo sampling methods. A Shapiro, Stochastic Programming. A. Ruszczy\u0144ski and A. ShapiroAmsterdamNorth-Holland Publishing CompanyA. Shapiro. Monte carlo sampling methods. In A. Ruszczy\u0144ski and A. Shapiro, editors, Stochas- tic Programming. North-Holland Publishing Company, Amsterdam, 2003.\n\nIntroduction to Stochastic Search and Optimization: Estimation, Simulation, and Control. J C Spall, John WileyHoboken, NJJ.C. Spall. Introduction to Stochastic Search and Optimization: Estimation, Simulation, and Control. John Wiley, Hoboken, NJ, 2003.\n\nWorst case complexity of direct search. L N Vicente, EURO Journal on Computational Optimization. to appearL. N. Vicente. Worst case complexity of direct search. EURO Journal on Computational Optimization, 2012. to appear.\n\nOn stochastic gradient and subgradient methods with adaptive steplength sequences. F Yousefian, A Nedic, U V Shanbhag, Automatica. 48F. Yousefian, A. Nedic, and U. V. Shanbhag. On stochastic gradient and subgradient methods with adaptive steplength sequences. Automatica, 48:56-67, 2012.\n", "annotations": {"author": "[{\"end\":109,\"start\":95},{\"end\":123,\"start\":110}]", "publisher": null, "author_last_name": "[{\"end\":108,\"start\":101},{\"end\":122,\"start\":119}]", "author_first_name": "[{\"end\":100,\"start\":95},{\"end\":118,\"start\":110}]", "author_affiliation": null, "title": "[{\"end\":81,\"start\":1},{\"end\":204,\"start\":124}]", "venue": null, "abstract": "[{\"end\":1241,\"start\":315}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b32\"},\"end\":1313,\"start\":1309},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":1669,\"start\":1666},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":1672,\"start\":1669},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":1862,\"start\":1858},{\"end\":1876,\"start\":1862},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":1952,\"start\":1948},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":1981,\"start\":1977},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":2306,\"start\":2302},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":2673,\"start\":2669},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":2799,\"start\":2795},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":3078,\"start\":3074},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":3081,\"start\":3078},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":3177,\"start\":3173},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":3180,\"start\":3177},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":3340,\"start\":3336},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":3343,\"start\":3340},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":3346,\"start\":3343},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":3430,\"start\":3426},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":3609,\"start\":3605},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3612,\"start\":3609},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":4169,\"start\":4165},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":4172,\"start\":4169},{\"end\":5180,\"start\":5175},{\"end\":5247,\"start\":5242},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":5486,\"start\":5482},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":5489,\"start\":5486},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":5975,\"start\":5971},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":5978,\"start\":5975},{\"end\":6206,\"start\":6201},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":6720,\"start\":6717},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":6723,\"start\":6720},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":6726,\"start\":6723},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":6729,\"start\":6726},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":6930,\"start\":6927},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":6932,\"start\":6930},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":7333,\"start\":7329},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":7462,\"start\":7458},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":7531,\"start\":7528},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":7644,\"start\":7640},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":9413,\"start\":9409},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":9416,\"start\":9413},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":10035,\"start\":10032},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":10181,\"start\":10177},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":10184,\"start\":10181},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":10245,\"start\":10242},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":10247,\"start\":10245},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":10250,\"start\":10247},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":10253,\"start\":10250},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":10384,\"start\":10380},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":10428,\"start\":10424},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":10851,\"start\":10847},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":11128,\"start\":11124},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":11362,\"start\":11358},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":11420,\"start\":11416},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":12192,\"start\":12188},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":12807,\"start\":12803},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":14046,\"start\":14042},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":14049,\"start\":14046},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":14052,\"start\":14049},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":14055,\"start\":14052},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":14058,\"start\":14055},{\"end\":17034,\"start\":17030},{\"end\":22265,\"start\":22260},{\"end\":22932,\"start\":22927},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":24011,\"start\":24007},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":24014,\"start\":24011},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":24017,\"start\":24014},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":24020,\"start\":24017},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":24179,\"start\":24175},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":24878,\"start\":24874},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":24938,\"start\":24934},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":24941,\"start\":24938},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":25185,\"start\":25182},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":25338,\"start\":25335},{\"end\":27356,\"start\":27350},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":28596,\"start\":28592},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":29223,\"start\":29219},{\"end\":31493,\"start\":31487},{\"end\":31808,\"start\":31802},{\"end\":32575,\"start\":32569},{\"end\":32738,\"start\":32732},{\"end\":33585,\"start\":33579},{\"end\":33596,\"start\":33590},{\"end\":33651,\"start\":33645},{\"end\":34039,\"start\":34033},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":35169,\"start\":35165},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":35174,\"start\":35171},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":35183,\"start\":35179},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":35769,\"start\":35765},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":37398,\"start\":37394},{\"end\":37416,\"start\":37411},{\"end\":37450,\"start\":37444},{\"end\":38597,\"start\":38593},{\"end\":38608,\"start\":38604},{\"end\":38927,\"start\":38923},{\"end\":38938,\"start\":38934},{\"end\":39735,\"start\":39729},{\"end\":39780,\"start\":39775},{\"end\":39878,\"start\":39872},{\"end\":40405,\"start\":40399},{\"end\":41187,\"start\":41181},{\"end\":41623,\"start\":41617},{\"end\":41649,\"start\":41643},{\"end\":42223,\"start\":42217},{\"end\":42293,\"start\":42288},{\"end\":43064,\"start\":43058},{\"end\":44494,\"start\":44488},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":44769,\"start\":44765},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":45020,\"start\":45016},{\"end\":45203,\"start\":45197},{\"end\":45224,\"start\":45218},{\"end\":45235,\"start\":45229},{\"end\":45785,\"start\":45779},{\"end\":46909,\"start\":46903},{\"end\":47428,\"start\":47422},{\"end\":47753,\"start\":47747}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":48058,\"start\":47950},{\"attributes\":{\"id\":\"fig_1\"},\"end\":48358,\"start\":48059},{\"attributes\":{\"id\":\"fig_2\"},\"end\":48893,\"start\":48359},{\"attributes\":{\"id\":\"fig_3\"},\"end\":49069,\"start\":48894},{\"attributes\":{\"id\":\"fig_4\"},\"end\":49328,\"start\":49070},{\"attributes\":{\"id\":\"fig_5\"},\"end\":50154,\"start\":49329},{\"attributes\":{\"id\":\"fig_6\"},\"end\":50218,\"start\":50155},{\"attributes\":{\"id\":\"fig_7\"},\"end\":51200,\"start\":50219},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":51476,\"start\":51201}]", "paragraph": "[{\"end\":2359,\"start\":1243},{\"end\":3771,\"start\":2361},{\"end\":3917,\"start\":3773},{\"end\":4173,\"start\":3919},{\"end\":4362,\"start\":4203},{\"end\":5018,\"start\":4364},{\"end\":5046,\"start\":5020},{\"end\":5739,\"start\":5132},{\"end\":5842,\"start\":5741},{\"end\":6169,\"start\":5880},{\"end\":6595,\"start\":6183},{\"end\":6811,\"start\":6597},{\"end\":8422,\"start\":6836},{\"end\":8678,\"start\":8542},{\"end\":9191,\"start\":8680},{\"end\":9607,\"start\":9227},{\"end\":9727,\"start\":9609},{\"end\":11364,\"start\":9760},{\"end\":12757,\"start\":11366},{\"end\":12867,\"start\":12759},{\"end\":13036,\"start\":12998},{\"end\":13102,\"start\":13099},{\"end\":13598,\"start\":13172},{\"end\":13743,\"start\":13600},{\"end\":13785,\"start\":13751},{\"end\":13925,\"start\":13836},{\"end\":14496,\"start\":13927},{\"end\":14679,\"start\":14498},{\"end\":14752,\"start\":14681},{\"end\":14851,\"start\":14754},{\"end\":16188,\"start\":14891},{\"end\":16409,\"start\":16190},{\"end\":16547,\"start\":16495},{\"end\":16707,\"start\":16626},{\"end\":16898,\"start\":16751},{\"end\":17040,\"start\":16975},{\"end\":17242,\"start\":17121},{\"end\":17659,\"start\":17588},{\"end\":18163,\"start\":17864},{\"end\":18412,\"start\":18326},{\"end\":18781,\"start\":18629},{\"end\":19047,\"start\":18980},{\"end\":19168,\"start\":19096},{\"end\":19537,\"start\":19377},{\"end\":19900,\"start\":19739},{\"end\":20336,\"start\":19902},{\"end\":20397,\"start\":20338},{\"end\":20534,\"start\":20448},{\"end\":20570,\"start\":20536},{\"end\":20746,\"start\":20639},{\"end\":20874,\"start\":20806},{\"end\":21228,\"start\":21085},{\"end\":21489,\"start\":21230},{\"end\":22458,\"start\":21535},{\"end\":22516,\"start\":22513},{\"end\":23649,\"start\":22569},{\"end\":24502,\"start\":23710},{\"end\":24810,\"start\":24504},{\"end\":25458,\"start\":24838},{\"end\":25718,\"start\":25460},{\"end\":25749,\"start\":25720},{\"end\":25823,\"start\":25794},{\"end\":26304,\"start\":25872},{\"end\":26762,\"start\":26306},{\"end\":26980,\"start\":26811},{\"end\":27010,\"start\":27004},{\"end\":27178,\"start\":27012},{\"end\":27598,\"start\":27187},{\"end\":27717,\"start\":27633},{\"end\":27952,\"start\":27719},{\"end\":28028,\"start\":27954},{\"end\":28382,\"start\":28105},{\"end\":28669,\"start\":28456},{\"end\":29100,\"start\":28671},{\"end\":29626,\"start\":29102},{\"end\":29816,\"start\":29753},{\"end\":30325,\"start\":29998},{\"end\":30480,\"start\":30327},{\"end\":31190,\"start\":30962},{\"end\":31269,\"start\":31263},{\"end\":31502,\"start\":31271},{\"end\":32318,\"start\":31728},{\"end\":32473,\"start\":32390},{\"end\":32616,\"start\":32527},{\"end\":32869,\"start\":32656},{\"end\":33094,\"start\":32930},{\"end\":33237,\"start\":33096},{\"end\":33413,\"start\":33239},{\"end\":33660,\"start\":33491},{\"end\":34040,\"start\":33948},{\"end\":34160,\"start\":34042},{\"end\":34658,\"start\":34220},{\"end\":34969,\"start\":34660},{\"end\":34997,\"start\":34971},{\"end\":35653,\"start\":35034},{\"end\":35726,\"start\":35724},{\"end\":35904,\"start\":35728},{\"end\":36054,\"start\":35973},{\"end\":36285,\"start\":36247},{\"end\":36447,\"start\":36394},{\"end\":36517,\"start\":36449},{\"end\":36725,\"start\":36582},{\"end\":36912,\"start\":36727},{\"end\":36985,\"start\":36914},{\"end\":37148,\"start\":36987},{\"end\":38331,\"start\":37294},{\"end\":38734,\"start\":38541},{\"end\":38969,\"start\":38871},{\"end\":39295,\"start\":39186},{\"end\":39558,\"start\":39478},{\"end\":39736,\"start\":39701},{\"end\":39879,\"start\":39773},{\"end\":40219,\"start\":40045},{\"end\":40421,\"start\":40354},{\"end\":40685,\"start\":40615},{\"end\":41044,\"start\":40955},{\"end\":41281,\"start\":41169},{\"end\":41415,\"start\":41401},{\"end\":41650,\"start\":41531},{\"end\":42436,\"start\":42176},{\"end\":42709,\"start\":42635},{\"end\":42909,\"start\":42711},{\"end\":43090,\"start\":42978},{\"end\":43225,\"start\":43119},{\"end\":43406,\"start\":43311},{\"end\":43492,\"start\":43425},{\"end\":43819,\"start\":43776},{\"end\":45138,\"start\":44067},{\"end\":45412,\"start\":45140},{\"end\":45928,\"start\":45552},{\"end\":46038,\"start\":46032},{\"end\":46137,\"start\":46040},{\"end\":46336,\"start\":46146},{\"end\":46455,\"start\":46338},{\"end\":46738,\"start\":46457},{\"end\":46951,\"start\":46740},{\"end\":47276,\"start\":46953},{\"end\":47437,\"start\":47278},{\"end\":47878,\"start\":47533},{\"end\":47906,\"start\":47905},{\"end\":47949,\"start\":47908}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":4202,\"start\":4174},{\"attributes\":{\"id\":\"formula_1\"},\"end\":5131,\"start\":5047},{\"attributes\":{\"id\":\"formula_2\"},\"end\":5879,\"start\":5843},{\"attributes\":{\"id\":\"formula_3\"},\"end\":6182,\"start\":6170},{\"attributes\":{\"id\":\"formula_4\"},\"end\":6835,\"start\":6812},{\"attributes\":{\"id\":\"formula_5\"},\"end\":8541,\"start\":8423},{\"attributes\":{\"id\":\"formula_6\"},\"end\":9226,\"start\":9192},{\"attributes\":{\"id\":\"formula_7\"},\"end\":9759,\"start\":9728},{\"attributes\":{\"id\":\"formula_8\"},\"end\":12997,\"start\":12868},{\"attributes\":{\"id\":\"formula_9\"},\"end\":13098,\"start\":13037},{\"attributes\":{\"id\":\"formula_10\"},\"end\":13171,\"start\":13103},{\"attributes\":{\"id\":\"formula_11\"},\"end\":13835,\"start\":13786},{\"attributes\":{\"id\":\"formula_12\"},\"end\":14890,\"start\":14852},{\"attributes\":{\"id\":\"formula_13\"},\"end\":16494,\"start\":16410},{\"attributes\":{\"id\":\"formula_14\"},\"end\":16625,\"start\":16548},{\"attributes\":{\"id\":\"formula_15\"},\"end\":16745,\"start\":16708},{\"attributes\":{\"id\":\"formula_16\"},\"end\":16974,\"start\":16899},{\"attributes\":{\"id\":\"formula_17\"},\"end\":17120,\"start\":17041},{\"attributes\":{\"id\":\"formula_18\"},\"end\":17587,\"start\":17243},{\"attributes\":{\"id\":\"formula_19\"},\"end\":17863,\"start\":17660},{\"attributes\":{\"id\":\"formula_20\"},\"end\":18325,\"start\":18164},{\"attributes\":{\"id\":\"formula_21\"},\"end\":18628,\"start\":18413},{\"attributes\":{\"id\":\"formula_22\"},\"end\":18979,\"start\":18782},{\"attributes\":{\"id\":\"formula_23\"},\"end\":19095,\"start\":19048},{\"attributes\":{\"id\":\"formula_24\"},\"end\":19376,\"start\":19169},{\"attributes\":{\"id\":\"formula_25\"},\"end\":19738,\"start\":19538},{\"attributes\":{\"id\":\"formula_26\"},\"end\":20447,\"start\":20398},{\"attributes\":{\"id\":\"formula_27\"},\"end\":20638,\"start\":20571},{\"attributes\":{\"id\":\"formula_28\"},\"end\":20805,\"start\":20747},{\"attributes\":{\"id\":\"formula_29\"},\"end\":21084,\"start\":20875},{\"attributes\":{\"id\":\"formula_30\"},\"end\":21534,\"start\":21490},{\"attributes\":{\"id\":\"formula_31\"},\"end\":22512,\"start\":22459},{\"attributes\":{\"id\":\"formula_32\"},\"end\":22568,\"start\":22517},{\"attributes\":{\"id\":\"formula_33\"},\"end\":23709,\"start\":23650},{\"attributes\":{\"id\":\"formula_34\"},\"end\":24837,\"start\":24811},{\"attributes\":{\"id\":\"formula_35\"},\"end\":25793,\"start\":25750},{\"attributes\":{\"id\":\"formula_36\"},\"end\":25871,\"start\":25824},{\"attributes\":{\"id\":\"formula_37\"},\"end\":26810,\"start\":26763},{\"attributes\":{\"id\":\"formula_38\"},\"end\":27003,\"start\":26981},{\"attributes\":{\"id\":\"formula_39\"},\"end\":28104,\"start\":28029},{\"attributes\":{\"id\":\"formula_40\"},\"end\":28455,\"start\":28383},{\"attributes\":{\"id\":\"formula_41\"},\"end\":29752,\"start\":29627},{\"attributes\":{\"id\":\"formula_42\"},\"end\":29914,\"start\":29817},{\"attributes\":{\"id\":\"formula_43\"},\"end\":29997,\"start\":29914},{\"attributes\":{\"id\":\"formula_44\"},\"end\":30540,\"start\":30481},{\"attributes\":{\"id\":\"formula_45\"},\"end\":30627,\"start\":30540},{\"attributes\":{\"id\":\"formula_46\"},\"end\":30961,\"start\":30627},{\"attributes\":{\"id\":\"formula_47\"},\"end\":31262,\"start\":31191},{\"attributes\":{\"id\":\"formula_48\"},\"end\":31669,\"start\":31503},{\"attributes\":{\"id\":\"formula_49\"},\"end\":31727,\"start\":31669},{\"attributes\":{\"id\":\"formula_50\"},\"end\":32389,\"start\":32319},{\"attributes\":{\"id\":\"formula_51\"},\"end\":32526,\"start\":32474},{\"attributes\":{\"id\":\"formula_52\"},\"end\":32655,\"start\":32617},{\"attributes\":{\"id\":\"formula_53\"},\"end\":32929,\"start\":32870},{\"attributes\":{\"id\":\"formula_54\"},\"end\":33490,\"start\":33414},{\"attributes\":{\"id\":\"formula_55\"},\"end\":33671,\"start\":33661},{\"attributes\":{\"id\":\"formula_56\"},\"end\":33871,\"start\":33671},{\"attributes\":{\"id\":\"formula_57\"},\"end\":33947,\"start\":33871},{\"attributes\":{\"id\":\"formula_58\"},\"end\":34219,\"start\":34161},{\"attributes\":{\"id\":\"formula_59\"},\"end\":35033,\"start\":34998},{\"attributes\":{\"id\":\"formula_60\"},\"end\":35723,\"start\":35654},{\"attributes\":{\"id\":\"formula_61\"},\"end\":35967,\"start\":35905},{\"attributes\":{\"id\":\"formula_62\"},\"end\":36246,\"start\":36055},{\"attributes\":{\"id\":\"formula_63\"},\"end\":36393,\"start\":36286},{\"attributes\":{\"id\":\"formula_64\"},\"end\":36581,\"start\":36518},{\"attributes\":{\"id\":\"formula_65\"},\"end\":37293,\"start\":37149},{\"attributes\":{\"id\":\"formula_66\"},\"end\":38395,\"start\":38332},{\"attributes\":{\"id\":\"formula_67\"},\"end\":38540,\"start\":38395},{\"attributes\":{\"id\":\"formula_68\"},\"end\":38870,\"start\":38735},{\"attributes\":{\"id\":\"formula_69\"},\"end\":39185,\"start\":38970},{\"attributes\":{\"id\":\"formula_70\"},\"end\":39477,\"start\":39296},{\"attributes\":{\"id\":\"formula_71\"},\"end\":39700,\"start\":39559},{\"attributes\":{\"id\":\"formula_72\"},\"end\":39772,\"start\":39737},{\"attributes\":{\"id\":\"formula_73\"},\"end\":40044,\"start\":39880},{\"attributes\":{\"id\":\"formula_74\"},\"end\":40353,\"start\":40220},{\"attributes\":{\"id\":\"formula_75\"},\"end\":40614,\"start\":40422},{\"attributes\":{\"id\":\"formula_76\"},\"end\":40954,\"start\":40686},{\"attributes\":{\"id\":\"formula_77\"},\"end\":41168,\"start\":41045},{\"attributes\":{\"id\":\"formula_78\"},\"end\":41400,\"start\":41282},{\"attributes\":{\"id\":\"formula_79\"},\"end\":41530,\"start\":41416},{\"attributes\":{\"id\":\"formula_80\"},\"end\":42175,\"start\":41651},{\"attributes\":{\"id\":\"formula_81\"},\"end\":42634,\"start\":42437},{\"attributes\":{\"id\":\"formula_82\"},\"end\":42977,\"start\":42910},{\"attributes\":{\"id\":\"formula_83\"},\"end\":43118,\"start\":43091},{\"attributes\":{\"id\":\"formula_84\"},\"end\":43310,\"start\":43226},{\"attributes\":{\"id\":\"formula_85\"},\"end\":43424,\"start\":43407},{\"attributes\":{\"id\":\"formula_86\"},\"end\":43564,\"start\":43493},{\"attributes\":{\"id\":\"formula_87\"},\"end\":43775,\"start\":43564},{\"attributes\":{\"id\":\"formula_88\"},\"end\":44066,\"start\":43820},{\"attributes\":{\"id\":\"formula_89\"},\"end\":45551,\"start\":45413},{\"attributes\":{\"id\":\"formula_90\"},\"end\":45969,\"start\":45929},{\"attributes\":{\"id\":\"formula_91\"},\"end\":46031,\"start\":45969},{\"attributes\":{\"id\":\"formula_92\"},\"end\":47532,\"start\":47438},{\"attributes\":{\"id\":\"formula_93\"},\"end\":47904,\"start\":47879}]", "table_ref": null, "section_header": "[{\"end\":13749,\"start\":13746},{\"end\":16749,\"start\":16747},{\"end\":27185,\"start\":27181},{\"end\":27631,\"start\":27601},{\"end\":35971,\"start\":35969},{\"end\":46144,\"start\":46140},{\"end\":48898,\"start\":48895},{\"end\":49086,\"start\":49071},{\"end\":50169,\"start\":50156},{\"end\":51206,\"start\":51202}]", "table": "[{\"end\":51476,\"start\":51334}]", "figure_caption": "[{\"end\":48058,\"start\":47952},{\"end\":48358,\"start\":48061},{\"end\":48893,\"start\":48361},{\"end\":49069,\"start\":48900},{\"end\":49328,\"start\":49089},{\"end\":50154,\"start\":49331},{\"end\":50218,\"start\":50171},{\"end\":51200,\"start\":50221},{\"end\":51334,\"start\":51209}]", "figure_ref": null, "bib_author_first_name": "[{\"end\":52830,\"start\":52829},{\"end\":53193,\"start\":53192},{\"end\":53203,\"start\":53202},{\"end\":53207,\"start\":53204},{\"end\":53217,\"start\":53215},{\"end\":53219,\"start\":53218},{\"end\":53589,\"start\":53588},{\"end\":53599,\"start\":53598},{\"end\":53603,\"start\":53600},{\"end\":53613,\"start\":53611},{\"end\":53615,\"start\":53614},{\"end\":53894,\"start\":53893},{\"end\":53896,\"start\":53895},{\"end\":54093,\"start\":54092},{\"end\":54095,\"start\":54094},{\"end\":54103,\"start\":54102},{\"end\":54117,\"start\":54116},{\"end\":54119,\"start\":54118},{\"end\":54317,\"start\":54316},{\"end\":54319,\"start\":54318},{\"end\":54328,\"start\":54327},{\"end\":54330,\"start\":54329},{\"end\":54342,\"start\":54341},{\"end\":54344,\"start\":54343},{\"end\":54590,\"start\":54589},{\"end\":54755,\"start\":54754},{\"end\":54757,\"start\":54756},{\"end\":55132,\"start\":55131},{\"end\":55146,\"start\":55145},{\"end\":55148,\"start\":55147},{\"end\":55526,\"start\":55525},{\"end\":55537,\"start\":55536},{\"end\":56006,\"start\":56005},{\"end\":56017,\"start\":56016},{\"end\":56345,\"start\":56344},{\"end\":56356,\"start\":56355},{\"end\":56846,\"start\":56845},{\"end\":57146,\"start\":57145},{\"end\":57158,\"start\":57157},{\"end\":57167,\"start\":57166},{\"end\":57169,\"start\":57168},{\"end\":57181,\"start\":57180},{\"end\":57503,\"start\":57502},{\"end\":57515,\"start\":57514},{\"end\":57865,\"start\":57864},{\"end\":57877,\"start\":57876},{\"end\":57889,\"start\":57888},{\"end\":57891,\"start\":57890},{\"end\":58126,\"start\":58125},{\"end\":58128,\"start\":58127},{\"end\":58140,\"start\":58139},{\"end\":58151,\"start\":58150},{\"end\":58436,\"start\":58435},{\"end\":58658,\"start\":58657},{\"end\":58665,\"start\":58664},{\"end\":58679,\"start\":58678},{\"end\":58947,\"start\":58946},{\"end\":59155,\"start\":59154},{\"end\":59165,\"start\":59164},{\"end\":59173,\"start\":59172},{\"end\":59182,\"start\":59181},{\"end\":59382,\"start\":59381},{\"end\":59391,\"start\":59390},{\"end\":59401,\"start\":59400},{\"end\":59413,\"start\":59412},{\"end\":59642,\"start\":59641},{\"end\":59656,\"start\":59655},{\"end\":59668,\"start\":59667},{\"end\":59675,\"start\":59674},{\"end\":59947,\"start\":59946},{\"end\":59961,\"start\":59960},{\"end\":60279,\"start\":60278},{\"end\":60281,\"start\":60280},{\"end\":60523,\"start\":60522},{\"end\":60525,\"start\":60524},{\"end\":60759,\"start\":60758},{\"end\":60761,\"start\":60760},{\"end\":60974,\"start\":60973},{\"end\":60976,\"start\":60975},{\"end\":61337,\"start\":61336},{\"end\":61339,\"start\":61338},{\"end\":61351,\"start\":61350},{\"end\":61353,\"start\":61352},{\"end\":61478,\"start\":61477},{\"end\":61489,\"start\":61488},{\"end\":61491,\"start\":61490},{\"end\":61667,\"start\":61666},{\"end\":61669,\"start\":61668},{\"end\":61854,\"start\":61853},{\"end\":61856,\"start\":61855},{\"end\":61866,\"start\":61865},{\"end\":61868,\"start\":61867},{\"end\":62090,\"start\":62089},{\"end\":62101,\"start\":62100},{\"end\":62335,\"start\":62334},{\"end\":62337,\"start\":62336},{\"end\":62352,\"start\":62351},{\"end\":62359,\"start\":62355},{\"end\":62738,\"start\":62737},{\"end\":62740,\"start\":62739},{\"end\":62754,\"start\":62753},{\"end\":63013,\"start\":63012},{\"end\":63026,\"start\":63025},{\"end\":63038,\"start\":63036},{\"end\":63040,\"start\":63039},{\"end\":63295,\"start\":63294},{\"end\":63490,\"start\":63489},{\"end\":63847,\"start\":63846},{\"end\":63849,\"start\":63848},{\"end\":64052,\"start\":64051},{\"end\":64054,\"start\":64053},{\"end\":64318,\"start\":64317},{\"end\":64331,\"start\":64330},{\"end\":64340,\"start\":64339},{\"end\":64342,\"start\":64341}]", "bib_author_last_name": "[{\"end\":52842,\"start\":52831},{\"end\":53200,\"start\":53194},{\"end\":53213,\"start\":53208},{\"end\":53225,\"start\":53220},{\"end\":53596,\"start\":53590},{\"end\":53609,\"start\":53604},{\"end\":53621,\"start\":53616},{\"end\":53902,\"start\":53897},{\"end\":54100,\"start\":54096},{\"end\":54114,\"start\":54104},{\"end\":54127,\"start\":54120},{\"end\":54325,\"start\":54320},{\"end\":54339,\"start\":54331},{\"end\":54355,\"start\":54345},{\"end\":54593,\"start\":54591},{\"end\":54760,\"start\":54758},{\"end\":55143,\"start\":55133},{\"end\":55156,\"start\":55149},{\"end\":55534,\"start\":55527},{\"end\":55541,\"start\":55538},{\"end\":56014,\"start\":56007},{\"end\":56021,\"start\":56018},{\"end\":56353,\"start\":56346},{\"end\":56360,\"start\":56357},{\"end\":56857,\"start\":56847},{\"end\":57155,\"start\":57147},{\"end\":57164,\"start\":57159},{\"end\":57178,\"start\":57170},{\"end\":57189,\"start\":57182},{\"end\":57512,\"start\":57504},{\"end\":57526,\"start\":57516},{\"end\":57874,\"start\":57866},{\"end\":57886,\"start\":57878},{\"end\":57900,\"start\":57892},{\"end\":58137,\"start\":58129},{\"end\":58148,\"start\":58141},{\"end\":58166,\"start\":58152},{\"end\":58440,\"start\":58437},{\"end\":58662,\"start\":58659},{\"end\":58676,\"start\":58666},{\"end\":58687,\"start\":58680},{\"end\":58955,\"start\":58948},{\"end\":59162,\"start\":59156},{\"end\":59170,\"start\":59166},{\"end\":59179,\"start\":59174},{\"end\":59189,\"start\":59183},{\"end\":59388,\"start\":59383},{\"end\":59398,\"start\":59392},{\"end\":59410,\"start\":59402},{\"end\":59419,\"start\":59414},{\"end\":59653,\"start\":59643},{\"end\":59665,\"start\":59657},{\"end\":59672,\"start\":59669},{\"end\":59683,\"start\":59676},{\"end\":59958,\"start\":59948},{\"end\":59967,\"start\":59962},{\"end\":60290,\"start\":60282},{\"end\":60534,\"start\":60526},{\"end\":60770,\"start\":60762},{\"end\":60985,\"start\":60977},{\"end\":61348,\"start\":61340},{\"end\":61358,\"start\":61354},{\"end\":61486,\"start\":61479},{\"end\":61498,\"start\":61492},{\"end\":61676,\"start\":61670},{\"end\":61863,\"start\":61857},{\"end\":61877,\"start\":61869},{\"end\":62098,\"start\":62091},{\"end\":62107,\"start\":62102},{\"end\":62349,\"start\":62338},{\"end\":62364,\"start\":62360},{\"end\":62594,\"start\":62579},{\"end\":62751,\"start\":62741},{\"end\":62762,\"start\":62755},{\"end\":63023,\"start\":63014},{\"end\":63034,\"start\":63027},{\"end\":63046,\"start\":63041},{\"end\":63301,\"start\":63296},{\"end\":63498,\"start\":63491},{\"end\":63855,\"start\":63850},{\"end\":64062,\"start\":64055},{\"end\":64328,\"start\":64319},{\"end\":64337,\"start\":64332},{\"end\":64351,\"start\":64343}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":12419623},\"end\":53067,\"start\":52781},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":14854119},\"end\":53480,\"start\":53069},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":7177746},\"end\":53853,\"start\":53482},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":16945044},\"end\":54044,\"start\":53855},{\"attributes\":{\"id\":\"b4\"},\"end\":54264,\"start\":54046},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":1182594},\"end\":54537,\"start\":54266},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":14175285},\"end\":54731,\"start\":54539},{\"attributes\":{\"id\":\"b7\"},\"end\":55040,\"start\":54733},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":1321982},\"end\":55375,\"start\":55042},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":8380223},\"end\":55868,\"start\":55377},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":7671308},\"end\":56262,\"start\":55870},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":14112046},\"end\":56796,\"start\":56264},{\"attributes\":{\"id\":\"b12\"},\"end\":57022,\"start\":56798},{\"attributes\":{\"id\":\"b13\"},\"end\":57382,\"start\":57024},{\"attributes\":{\"id\":\"b14\"},\"end\":57832,\"start\":57384},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":14243118},\"end\":58045,\"start\":57834},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":10288654},\"end\":58376,\"start\":58047},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":15039054},\"end\":58584,\"start\":58378},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":2128449},\"end\":58874,\"start\":58586},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":122552664},\"end\":59106,\"start\":58876},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":7027533},\"end\":59320,\"start\":59108},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":56563221},\"end\":59571,\"start\":59322},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":1767867},\"end\":59886,\"start\":59573},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":60609764},\"end\":60181,\"start\":59888},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":202149403},\"end\":60458,\"start\":60183},{\"attributes\":{\"id\":\"b25\"},\"end\":60703,\"start\":60460},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":14935076},\"end\":60916,\"start\":60705},{\"attributes\":{\"id\":\"b27\"},\"end\":61279,\"start\":60918},{\"attributes\":{\"id\":\"b28\"},\"end\":61451,\"start\":61281},{\"attributes\":{\"id\":\"b29\"},\"end\":61618,\"start\":61453},{\"attributes\":{\"id\":\"b30\"},\"end\":61796,\"start\":61620},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":3548228},\"end\":62052,\"start\":61798},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":16945044},\"end\":62258,\"start\":62054},{\"attributes\":{\"id\":\"b33\"},\"end\":62575,\"start\":62260},{\"attributes\":{\"id\":\"b34\"},\"end\":62632,\"start\":62577},{\"attributes\":{\"id\":\"b35\"},\"end\":62940,\"start\":62634},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":1451815},\"end\":63239,\"start\":62942},{\"attributes\":{\"id\":\"b37\"},\"end\":63457,\"start\":63241},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":117549937},\"end\":63755,\"start\":63459},{\"attributes\":{\"id\":\"b39\"},\"end\":64009,\"start\":63757},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":6301070},\"end\":64232,\"start\":64011},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":406105},\"end\":64521,\"start\":64234}]", "bib_title": "[{\"end\":52827,\"start\":52781},{\"end\":53190,\"start\":53069},{\"end\":53586,\"start\":53482},{\"end\":53891,\"start\":53855},{\"end\":54314,\"start\":54266},{\"end\":54587,\"start\":54539},{\"end\":54752,\"start\":54733},{\"end\":55129,\"start\":55042},{\"end\":55523,\"start\":55377},{\"end\":56003,\"start\":55870},{\"end\":56342,\"start\":56264},{\"end\":57862,\"start\":57834},{\"end\":58123,\"start\":58047},{\"end\":58433,\"start\":58378},{\"end\":58655,\"start\":58586},{\"end\":58944,\"start\":58876},{\"end\":59152,\"start\":59108},{\"end\":59379,\"start\":59322},{\"end\":59639,\"start\":59573},{\"end\":59944,\"start\":59888},{\"end\":60276,\"start\":60183},{\"end\":60756,\"start\":60705},{\"end\":61664,\"start\":61620},{\"end\":61851,\"start\":61798},{\"end\":62087,\"start\":62054},{\"end\":63010,\"start\":62942},{\"end\":63292,\"start\":63241},{\"end\":63487,\"start\":63459},{\"end\":64049,\"start\":64011},{\"end\":64315,\"start\":64234}]", "bib_author": "[{\"end\":52844,\"start\":52829},{\"end\":53202,\"start\":53192},{\"end\":53215,\"start\":53202},{\"end\":53227,\"start\":53215},{\"end\":53598,\"start\":53588},{\"end\":53611,\"start\":53598},{\"end\":53623,\"start\":53611},{\"end\":53904,\"start\":53893},{\"end\":54102,\"start\":54092},{\"end\":54116,\"start\":54102},{\"end\":54129,\"start\":54116},{\"end\":54327,\"start\":54316},{\"end\":54341,\"start\":54327},{\"end\":54357,\"start\":54341},{\"end\":54595,\"start\":54589},{\"end\":54762,\"start\":54754},{\"end\":55145,\"start\":55131},{\"end\":55158,\"start\":55145},{\"end\":55536,\"start\":55525},{\"end\":55543,\"start\":55536},{\"end\":56016,\"start\":56005},{\"end\":56023,\"start\":56016},{\"end\":56355,\"start\":56344},{\"end\":56362,\"start\":56355},{\"end\":56859,\"start\":56845},{\"end\":57157,\"start\":57145},{\"end\":57166,\"start\":57157},{\"end\":57180,\"start\":57166},{\"end\":57191,\"start\":57180},{\"end\":57514,\"start\":57502},{\"end\":57528,\"start\":57514},{\"end\":57876,\"start\":57864},{\"end\":57888,\"start\":57876},{\"end\":57902,\"start\":57888},{\"end\":58139,\"start\":58125},{\"end\":58150,\"start\":58139},{\"end\":58168,\"start\":58150},{\"end\":58442,\"start\":58435},{\"end\":58664,\"start\":58657},{\"end\":58678,\"start\":58664},{\"end\":58689,\"start\":58678},{\"end\":58957,\"start\":58946},{\"end\":59164,\"start\":59154},{\"end\":59172,\"start\":59164},{\"end\":59181,\"start\":59172},{\"end\":59191,\"start\":59181},{\"end\":59390,\"start\":59381},{\"end\":59400,\"start\":59390},{\"end\":59412,\"start\":59400},{\"end\":59421,\"start\":59412},{\"end\":59655,\"start\":59641},{\"end\":59667,\"start\":59655},{\"end\":59674,\"start\":59667},{\"end\":59685,\"start\":59674},{\"end\":59960,\"start\":59946},{\"end\":59969,\"start\":59960},{\"end\":60292,\"start\":60278},{\"end\":60536,\"start\":60522},{\"end\":60772,\"start\":60758},{\"end\":60987,\"start\":60973},{\"end\":61350,\"start\":61336},{\"end\":61360,\"start\":61350},{\"end\":61488,\"start\":61477},{\"end\":61500,\"start\":61488},{\"end\":61678,\"start\":61666},{\"end\":61865,\"start\":61853},{\"end\":61879,\"start\":61865},{\"end\":62100,\"start\":62089},{\"end\":62109,\"start\":62100},{\"end\":62351,\"start\":62334},{\"end\":62355,\"start\":62351},{\"end\":62366,\"start\":62355},{\"end\":62596,\"start\":62579},{\"end\":62753,\"start\":62737},{\"end\":62764,\"start\":62753},{\"end\":63025,\"start\":63012},{\"end\":63036,\"start\":63025},{\"end\":63048,\"start\":63036},{\"end\":63303,\"start\":63294},{\"end\":63500,\"start\":63489},{\"end\":63857,\"start\":63846},{\"end\":64064,\"start\":64051},{\"end\":64330,\"start\":64317},{\"end\":64339,\"start\":64330},{\"end\":64353,\"start\":64339}]", "bib_venue": "[{\"end\":52896,\"start\":52844},{\"end\":53255,\"start\":53227},{\"end\":53651,\"start\":53623},{\"end\":53937,\"start\":53904},{\"end\":54090,\"start\":54046},{\"end\":54385,\"start\":54357},{\"end\":54623,\"start\":54595},{\"end\":54829,\"start\":54762},{\"end\":55191,\"start\":55158},{\"end\":55571,\"start\":55543},{\"end\":56051,\"start\":56023},{\"end\":56390,\"start\":56362},{\"end\":56843,\"start\":56798},{\"end\":57143,\"start\":57024},{\"end\":57500,\"start\":57384},{\"end\":57922,\"start\":57902},{\"end\":58196,\"start\":58168},{\"end\":58466,\"start\":58442},{\"end\":58713,\"start\":58689},{\"end\":58975,\"start\":58957},{\"end\":59195,\"start\":59191},{\"end\":59431,\"start\":59421},{\"end\":59713,\"start\":59685},{\"end\":60018,\"start\":59969},{\"end\":60307,\"start\":60292},{\"end\":60520,\"start\":60460},{\"end\":60796,\"start\":60772},{\"end\":60971,\"start\":60918},{\"end\":61334,\"start\":61281},{\"end\":61475,\"start\":61453},{\"end\":61697,\"start\":61678},{\"end\":61911,\"start\":61879},{\"end\":62142,\"start\":62109},{\"end\":62332,\"start\":62260},{\"end\":62735,\"start\":62634},{\"end\":63076,\"start\":63048},{\"end\":63336,\"start\":63303},{\"end\":63522,\"start\":63500},{\"end\":63844,\"start\":63757},{\"end\":64106,\"start\":64064},{\"end\":64363,\"start\":64353},{\"end\":52935,\"start\":52898},{\"end\":63562,\"start\":63553}]"}}}, "year": 2023, "month": 12, "day": 17}