{"id": 174802983, "updated": "2023-10-07 02:00:22.597", "metadata": {"title": "When Does Label Smoothing Help?", "authors": "[{\"first\":\"Rafael\",\"last\":\"Muller\",\"middle\":[]},{\"first\":\"Simon\",\"last\":\"Kornblith\",\"middle\":[]},{\"first\":\"Geoffrey\",\"last\":\"Hinton\",\"middle\":[]}]", "venue": "ArXiv", "journal": "ArXiv", "publication_date": {"year": 2019, "month": 6, "day": 6}, "abstract": "The generalization and learning speed of a multi-class neural network can often be significantly improved by using soft targets that are a weighted average of the hard targets and the uniform distribution over labels. Smoothing the labels in this way prevents the network from becoming over-confident and label smoothing has been used in many state-of-the-art models, including image classification, language translation and speech recognition. Despite its widespread use, label smoothing is still poorly understood. Here we show empirically that in addition to improving generalization, label smoothing improves model calibration which can significantly improve beam-search. However, we also observe that if a teacher network is trained with label smoothing, knowledge distillation into a student network is much less effective. To explain these observations, we visualize how label smoothing changes the representations learned by the penultimate layer of the network. We show that label smoothing encourages the representations of training examples from the same class to group in tight clusters. This results in loss of information in the logits about resemblances between instances of different classes, which is necessary for distillation, but does not hurt generalization or calibration of the model's predictions.", "fields_of_study": "[\"Computer Science\",\"Mathematics\"]", "external_ids": {"arxiv": "1906.02629", "mag": "2970206392", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/nips/MullerKH19", "doi": null}}, "content": {"source": {"pdf_hash": "b1b11f2e6a835af9c16b5638274f650f58d9ec3d", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/1906.02629v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "f94b3ef53e95c3179b5cacf102950b4d4a302b1f", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/b1b11f2e6a835af9c16b5638274f650f58d9ec3d.txt", "contents": "\nWhen Does Label Smoothing Help?\n\n\nRafael M\u00fcller rafaelmuller@google.com \nSimon Kornblith \nGeoffrey Hinton Google \nBrain Toronto \nWhen Does Label Smoothing Help?\n\nThe generalization and learning speed of a multi-class neural network can often be significantly improved by using soft targets that are a weighted average of the hard targets and the uniform distribution over labels. Smoothing the labels in this way prevents the network from becoming over-confident and label smoothing has been used in many state-of-the-art models, including image classification, language translation and speech recognition. Despite its widespread use, label smoothing is still poorly understood. Here we show empirically that in addition to improving generalization, label smoothing improves model calibration which can significantly improve beam-search. However, we also observe that if a teacher network is trained with label smoothing, knowledge distillation into a student network is much less effective. To explain these observations, we visualize how label smoothing changes the representations learned by the penultimate layer of the network. We show that label smoothing encourages the representations of training examples from the same class to group in tight clusters. This results in loss of information in the logits about resemblances between instances of different classes, which is necessary for distillation, but does not hurt generalization or calibration of the model's predictions. * This work was done as part of the Google AI Residency.Preprint. Under review.\n\nIntroduction\n\nIt is widely known that neural network training is sensitive to the loss that is minimized. Shortly after Rumelhart et al. [1] derived backpropagation for the quadratic loss function, several researchers noted that better classification performance and faster convergence could be attained by performing gradient descent to minimize cross entropy [2,3]. However, even in these early days of neural network research, there were indications that other, more exotic objectives could outperform the standard cross entropy loss [4,5]. More recently, Szegedy et al. [6] introduced label smoothing, which improves accuracy by computing cross entropy not with the \"hard\" targets from the dataset, but with a weighted mixture of these targets with the uniform distribution.\n\nLabel smoothing has been used successfully to improve the accuracy of deep learning models across a range of tasks, including image classification, speech recognition, and machine translation (Table 1). Szegedy et al. [6] originally proposed label smoothing as a strategy that improved the performance of the Inception architecture on the ImageNet dataset, and many state-of-the-art image classification models have incorporated label smoothing into training procedures ever since [7,8,9]. In speech recognition, Chorowski and Jaitly [10] used label smoothing to reduce the word error rate on the WSJ dataset. In machine translation, Vaswani et al. [11] attained a small but important improvement in BLEU score, despite a reduction in perplexity.\n\nAlthough label smoothing is a widely used \"trick\" to improve network performance, not much is known about why and when label smoothing should work. This paper tries to shed light upon behavior of neural networks trained with label smoothing, and we describe several intriguing properties of these networks. Our contributions are as follows:\n\n\u2022 We introduce a novel visualization method based on linear projections of the penultimate layer activations. This visualization provides intuition regarding how representations differ between penultimate layers of networks trained with and without label smoothing. \u2022 We demonstrate that label smoothing implicitly calibrates learned models so that the confidences of their predictions are more aligned with the accuracies of their predictions. \u2022 We show that label smoothing impairs distillation, i.e., when teacher models are trained with label smoothing, student models perform worse. We further show that this adverse effect results from loss of information in the logits.\n\n\nPreliminaries\n\nBefore describing our findings, we provide a mathematical description of label smoothing. Suppose we write the prediction of a neural network as a function of the activations in the penultimate layer\nas p k = e x T w k L l=1 e x T w l ,\nwhere p k is the likelihood the model assigns to the k-th class, w k represents the weights and biases of the last layer, x is the vector containing the activations of the penultimate layer of a neural network concatenated with \"1\" to account for the bias. For a network trained with hard targets, we minimize the expected value of the cross-entropy between the true targets y k and the network's outputs p k as in H(y, p) = K k=1 \u2212y k log(p k ), where y k is \"1\" for the correct class and \"0\" for the rest. For a network trained with a label smoothing of parameter \u03b1, we minimize instead the cross-entropy between the modified targets y LS k and the networks' outputs p k , where y LS k = y k (1 \u2212 \u03b1) + \u03b1/K.\n\n\nPenultimate layer representations\n\nTraining a network with label smoothing encourages the differences between the logit of the correct class and the logits of the incorrect classes to be a constant dependent on \u03b1. By contrast, training a network with hard targets typically results in the correct logit being much larger than the any of the incorrect logits and also allows the incorrect logits to be very different from one another. Intuitively, the logit x T w k of the k-th class can be thought of as a measure of the squared Euclidean distance between the activations of the penultimate layer x and a template w k , as\n||x \u2212 w k || 2 = x T x \u2212 2x T w k + w T k w k .\nHere, each class has a template w k , x T x is factored out when calculating the softmax outputs and w T k w k is usually constant across classes. Therefore, label smoothing encourages the activations of the penultimate layer to be close to the template of the correct class and equally distant to the templates of the incorrect classes. To observe this property of label smoothing, we propose a new visualization scheme based on the following steps: (1) Pick three classes, (2) Find an orthonormal basis of the plane crossing the templates of these three classes, (3) Project the penultimate layer activations of examples from these three classes onto this plane. This visualization shows in 2-D how the activations cluster around the templates and how label smoothing enforces a structure on the distance between the examples and the clusters from the other classes.\n\nIn Fig. 1, we show results of visualizing penultimate layer representations of image classifiers trained on the datasets CIFAR-10, CIFAR-100 and ImageNet with the architectures AlexNet [12], ResNet-56 [13] and Inception-v4 [14], respectively. Table 2 shows the effect of label smoothing on the accuracy of these models. We start by describing visualization results for CIFAR-10 (first row of Fig. 1) for the classes \"airplane,\" \"automobile\" and \"bird.\" The first two columns represent examples from the training and validation set for a network trained without label smoothing (w/o LS). We observe that  the projections are spread into defined but broad clusters. The last two columns show a network trained with a label smoothing factor of 0.1. We observe that now the clusters are much tighter, because label smoothing encourages that each example in training set to be equidistant from all the other class's templates. Therefore, when looking at the projections, the clusters organize in regular triangles when training with label smoothing, whereas the regular triangle structure is less discernible in the case of training with hard-targets (no label smoothing). Note that these networks have similar accuracies despite qualitatively different clustering of activations.\n\nIn the second row, we investigate the activation's geometry for a different pair of dataset/architecture (CIFAR-100/ResNet-56). Again, we observe the same behavior for classes \"beaver,\" \"dolphin,\" \"otter.\" In contrast to the previous example, now the networks trained with label smoothing have better accuracy. Additionally, we observe the different scale of the projections between the network trained with and without label smoothing. With label smoothing, the difference between logits of two classes has to be limited in absolute value to get the desired soft target for the correct and incorrect classes. Without label smoothing, however, the projection can take much higher absolute values, which represent over-confident predictions.\n\nFinally, we test our visualization scheme in an Inception-v4/ImageNet experiment and observe the effect of label smoothing for semantically similar classes, since ImageNet has many fine-grained classes (e.g. different breeds of dogs). The third row represents projections for semantically different classes (tench, meerkat and cleaver) with the behavior similar to previous experiments. The fourth row is more interesting, since we pick two semantically similar classes (toy poodle and miniature poodle) and observe the projection with the presence of a third semantically different one (tench, in blue). With hard targets, the semantically similar classes cluster close to each other with an isotropic spread. On the contrary, with label smoothing these similar classes lie in an arc. In both cases, the semantically similar classes are harder to separate even on the training set, but label smoothing enforces that each example be equidistant to all remaining class's templates, which gives rise to arc shape behavior with respect to other classes. We also observe that when training without label smoothing there is continuous degree of change between the \"tench\" cluster and the \"poodles\" cluster. We can potentially measure \"how much a poodle is a particular tench\". However, when training with label smoothing this information is virtually erased. This erasure of information is shown in the Section 4. Finally, the figure shows that the effect of label smoothing on representations is independent of architecture, dataset and accuracy.\n\n\nImplicit model calibration\n\nBy artificially softening the targets, label smoothing prevents the network from becoming overconfident. But does it improve the calibration of the model by making the confidence of its predictions more accurately represent their accuracy? In this section, we seek to answer this question. Guo et al. [15] have shown that modern neural networks are poorly calibrated and over-confident despite having better performance than better calibrated networks from the past. To measure calibration, the authors computed the estimated expected calibration error (ECE). They demonstrated that a simple post-processing step, temperature scaling, can reduce ECE and calibrate the network. Temperature scaling consists in multiplying the logits by a scalar before applying the softmax operator. Here, we show that label smoothing also reduces ECE and can be used to calibrate a network without the need for temperature scaling.\n\nImage classification. We start by investigating the calibration of image classification models. Fig. 2 (left) shows the 15-bin reliability diagram of a ResNet-56 trained on CIFAR-100. The dashed line represent perfect calibration where the output likelihood (confidence) predicts perfectly the accuracy. Without temperature scaling, the model trained with hard targets (blue line without markers) is clearly over-confident, since in expectation the accuracy is always below the confidence. To calibrate the model, one can tune the softmax temperature a posteriori (blue line with crosses) to a temperature of 1.9. We observe that the reliability diagram slope is now much closer to a slope of 1 and the model is better calibrated. We also show that, in terms of calibration, label smoothing has a similar effect. By training the same model with \u03b1 = 0.05 (green line), we obtain a model that is similarly calibrated compared to temperature scaling. In Table 3, we observe how varying label smoothing and temperature scaling affects ECE. Both methods can be used to reduce ECE to a similar and smaller value than an uncalibrated network trained with hard targets.\n\nWe also performed experiments on ImageNet (Fig. 2 right). Again, the network trained with hard targets (blue curve without markers) is over-confident and achieves a high ECE of 0.071. Using temperature scaling (T= 1.4), ECE is reduced to 0.022 (blue curve with crosses). Although we did not tune \u03b1 extensively, we found that label smoothing of \u03b1 = 0.1 improves ECE to 0.035, resulting in better calibration compared to the unscaled network trained with hard targets.\n\nThese results are somewhat surprising in light of the penultimate layer visualizations of these networks shown in the previous section. Despite trying to collapse the training examples to tiny clusters, these networks generalize and are calibrated. Looking at the label smoothing representations for CIFAR-100 in Fig. 1 (second row, two last columns), we clearly observe this behavior. The red cluster is very tight in the training set, but in the validation set it spreads towards the center representing the full range of confidences for each prediction.\n\nMachine translation. We also investigate the calibration of a model trained on the English-to-German translation task using the Transformer architecture. This setup is interesting for two reasons. First, Vaswani et al. [11] noted that label smoothing with \u03b1 = 0.1 improved the BLEU score of   We start by looking at the reliability diagram (Fig. 3) for a Transformer network trained with hard targets (with and without temperature scaling) and a network trained with label smoothing (\u03b1 = 0.1). We plot calibration of the next-token predictions assuming a correct prefix on the validation set. The results are in agreement with the previous experiments on CIFAR-100 and ImageNet, and indeed the Transformer network [11] with label smoothing is better calibrated than the hard targets alternative.\n\nDespite being better calibrated and achieving better BLEU scores, label smoothing results in worse negative log-likelihoods (NLL) than hard targets. Moreover, temperature scaling with hard targets is insufficient to recover the BLEU score improvement obtained with label smoothing. In Fig. 4, we artificially vary calibration of both networks, using temperature scaling, and analyze the effect upon BLEU and NLL. The left panel shows results for a network trained with hard targets. By increasing the temperature we can both reduce ECE (red, right y-axis) and slightly improve BLEU score (blue left y-axis), but the BLEU score improvement is not enough to match the BLEU score of the network trained with label smoothing (center panel). The network trained with label smoothing is \"automatically calibrated\" and changing the temperature degrades both calibration and BLEU score. Finally, in the right panel, we plot the NLL for both networks, where markers represent the network with label smoothing. The model trained with hard targets achieves better NLL at all temperature scaling settings. Thus, label smoothing improves translation quality measured by BLEU score despite worse NLL, and the difference of BLEU score performance is only partly explained by calibration. Note that the minimum of ECE for this experiment predicts top BLEU score slightly better than NLL. \n\n\nKnowledge distillation\n\nIn this section, we study how the use of label smoothing to train a teacher network affects the ability to distill the teacher's knowledge into a student network. We show that, even when label smoothing improves the accuracy of the teacher network, teachers trained with label smoothing produce inferior student networks compared to teachers trained with hard targets. We first noticed this effect when trying to replicate a result in [16]. A non-convolutional teacher is trained on randomly translated MNIST digits with hard targets and dropout and gets 0.67% test error. Using distillation, this teacher can be used to train a narrower, unregularized student on untranslated digits to get 0.74% test error. If we use label smoothing instead of dropout, the teacher trains much faster and does slightly better (0.59%) but distillation produces a much worse student with 0.91% test error. Something goes seriously wrong with distillation when the teacher is trained with label smoothing.\n\nIn knowledge distillation, we replace the cross-entropy term H(y, p) by the weighted sum (1 \u2212 \u03b2)H(y, p) + \u03b2H(p t (T ), p(T )), where p k (T ) and p t k (T ) are the outputs of the student and teacher after temperature scaling with temperature T , respectively. \u03b2 controls the balance between two tasks: fitting the hard-targets and approximating the softened teacher. The temperature can be viewed as a way to exaggerate the differences between the probabilities of incorrect answers.\n\nBoth label smoothing and knowledge distillation involve fitting a model using soft targets. Knowledge distillation is only useful if it provides an additional gain to the student compared to training the student with label smoothing, which is simpler to implement since it does not require training a teacher network. We quantify this gain experimentally. To demonstrate these ideas, we perform an experiment on the CIFAR-10 dataset. We train a ResNet-56 teacher and we distill to an AlexNet student. We are interested in four results:\n\n1. the teacher's accuracy as a function of the label smoothing factor, 2. the student's baseline accuracy as a function of the label smoothing factor without distillation, 3. the student's accuracy after distillation with temperature scaling to control the smoothness of the teacher's provided targets (teacher trained with hard targets) 4. the student's accuracy after distillation with fixed temperature (T = 1.0 and teacher trained with label smoothing to control the smoothness of the teacher's provided targets)\n\nTo compare all solutions using a single smoothness index, we define the equivalent label smoothing factor \u03b3 which for scenarios 1 and 2 are equal to \u03b1. For scenarios 3 and 4, the smoothness index\nis \u03b3 = E K k=1 (1 \u2212 y k )p t k (T )K/(K \u2212 1)\n, which calculates the mass allocated by the teacher to incorrect examples over the training set. Since the training accuracy is nearly perfect, for all distillation experiments, we consider only the case where \u03b2 = 1, i.e., when the targets are the teacher output and the true labels are ignored.   Next, we distill the teacher trained with hard targets to students using different temperatures, and calculate the corresponding \u03b3 for each temperature (red dashed curve). We observe that all distilled models outperform the baseline student with label smoothing. Finally, we distill information from teachers trained with label smoothing \u03b1 > 0, which have better accuracy (blue dashed curve). The figure shows that using these better performing teachers is no better, and sometimes worse, than training the student directly with label smoothing, as the relative information between logits is \"erased\" when the teacher is trained with label smoothing.\n\nTo observe how label smoothing \"erases\" the information contained in the different similarities that an individual example has to different classes we revisit the visualizations in Fig. 1. Note that we are interested in the visualization of the examples from the training set, since those are the ones used for distillation. For a teacher trained with hard targets (\u03b1 = 0.0), we observe that examples are distributed in broad clusters, which means that different examples from the same class can have very different similarities to other classes. For a teacher trained with label smoothing, we observe the opposite behavior. Label smoothing encourages examples to lie in tight equally separated clusters, so every example of one class has very similar proximities to examples of the other classes. Therefore, a teacher with better accuracy is not necessarily the one that distills better.\n\nOne way to directly quantify information erasure is to calculate the mutual information between the input and the logits. Computing mutual information in high dimensions for unknown distributions is challenging, but here we simplify the problem in several ways. We measure the mutual information between X and Y , where X is a discrete variable representing the index of the training example and Y is continuous representing the difference between two logits (out of K classes). The source of randomness comes from data augmentation and we approximate the distribution of Y as a Gaussian and we estimate the mean and variance from the examples using Monte Carlo samples. The difference of the logits y can be written as y = f (d(z x )), where z x is the input image indexed by x, d(\u00b7) is a random data augmentation function (random shifts for example), and f (\u00b7) is a trained neural network with an image as an input and the difference between two logits as output (resulting in a single dimension real-valued output). The mutual information and its respective approximation are I(X; Y ) = E X,Y [log(p(y|x)) \u2212 log( x p(y|x))] and   6 shows the estimated mutual information between a subset (N = 600 from two classes) of the training examples and the difference of the logits corresponding to these two classes. After initialization, the mutual information is very small, but as the network is trained, first it rapidly increases then it slowly decreases specially for the network trained with label smoothing. This result confirms the intuitions from the last sections. As the representations collapse to small clusters of points, much of the information that could have helped distinguish examples is lost. This results in lower estimated mutual information and poor distillation for teachers trained with label smoothing.\nI(X; Y ) = N x=1 (f (d(z x )) \u2212 \u00b5 x ) 2 /(2\u03c3 2 ) \u2212 log( N x=1 e (f (d(zx))\u2212\u00b5x) 2 /(2\u03c3 2 ) ) , where \u00b5 x = L l=1 f (d(z x ))/L, \u03c3 2 = N x=1 (f (d(z x )) \u2212 \u00b5 x ) 2 /N ,\nFor later stages of training, mutual information stays slightly above log (2), which corresponds to the extreme case where all training examples collapse to two separate clusters. In this case, all the information of the input is discarded except a single bit representing which class the example belongs to, resulting in no extra information in the teacher's logits compared to the information in the labels.\n\n\nRelated work\n\nPereyra et al. [17] showed that label smoothing provides consistent gains across many tasks. That work also proposed a new regularizer based on penalizing low entropy predictions, which the authors term \"confidence penalty.\" They show that label smoothing is equivalent to confidence penalty if the order of the KL divergence between uniform distributions and model's outputs is reversed. They also propose to use distributions other than uniform, resulting in unigram label smoothing (see Table 1) which is advantageous when the output labels' distribution is not balanced. Label smoothing also relates to DisturbLabel [18], which can be seen as label dropout, whereas label smoothing is the marginalized version of label dropout.\n\nCalibration of modern neural networks [15] has been widely investigated for image classification, but calibration of sequence models has been investigated only recently. Ott et al. [19] investigate the sequence level calibration of machine translation models and conclude they are remarkably well calibrated. Kumar and Sarawagi [20] investigate calibration of next-token prediction in language translation. They find that calibration of state-of-the-art models can be improved by a parametric model, resulting in a small increase in BLEU score. However, neither work invesigates the relation between label smoothing during training and calibration. For speech recognition, Chorowski and Jaitly [10] investigate the effect of softmax temperature and label smoothing on decoding accuracy. The authors conclude that both temperature scaling and label smoothing improve word error rates after beam-search (label smoothing performs best), but the relation between calibration and label smoothing/temperature scaling is not described.\n\nAlthough we are unaware of any previous work that shows the adverse effect of label smoothing upon distillation, Kornblith et al. [21] previously demonstrated that label smoothing impairs the accuracy of transfer learning, which similarly depends on the presence of non-class-relevant information in the final layers of the network. Additionally, Chelombiev et al. [22] propose an improved mutual information estimator based on binning and show correlation between compression of softmax layer representations and generalization, which may explain why networks trained with label smoothing generalize so well. This relates to the information bottleneck theory [23,24,25] that explains generalization in terms of compression.\n\n\nConclusion and future work\n\nMany state-of-the-art models are trained with label smoothing, but the inductive bias provided by this technique is not well understood. In this work, we have summarized and explained several behaviors observed while training deep neural networks with label smoothing. We focused on how label smoothing encourages representations in the penultimate layer to group in tight equally distant clusters. This emergent property can be visualized in low dimension thanks to a new visualization scheme that we proposed. Despite having a positive effect on generalization and calibration, label smoothing can hurt distillation. We explain this effect in terms of erasure of information. With label smoothing, the model is encouraged to treat each incorrect class as equally probable. With hard targets, less structure is enforced in later representations, enabling more logit variation across predicted class and/or across examples. This can be quantified by estimating mutual information between input example and output logit and, as we have shown, label smoothing reduces mutual information. This finding suggests a new research direction, focusing on the relationship between label smoothing and the information bottleneck principle, with implications for compression, generalization and information transfer. Finally, we performed extensive experiments on how label smoothing can implicitly calibrate model's predictions. This has big impact on model interpretability, but also, as we have shown, can be critical for downstream tasks that depend on calibrated likelihoods such as beam-search. validation set were used to calculate the ECE and reliability diagram. For calculation of BLEU score (uncased), we use the full validation set 9 .\n\n\nA.4 Inception-v4\n\nThe Inception-v4 architecture was used in the visualization and calibration sections. We reuse a public implementation of the model which be can found at 10 . We modified this code to use a scale parameter for the batch normalization layer, as we found it improved performance. We used a batch size of 4096 and trained the model using stochastic gradient descent with Nesterov momentum of 0.9 and weight decay of 8 \u00d7 10 \u22125 . We took an exponential average of the weights with decay factor 0.9999, and selected the checkpoint that achieved the maximum accuracy during a separate training run where approximately 50,000 images from the ImageNet training set were used for validation.\n\n\nA.5 Fully-connected\n\nFor the distillation results on MNIST we use fully connected networks with 2 layers. 1200 neurons per layer is used on the teacher and 800 layers in the student. For training the teacher, we use \u03b1 = 0.1, random image shifts of plus or minus 2 pixels in both x and y axis (i.e. 25 equiprobable centerings for each case). The initialization distribution is Gaussian with variance 0.03. Learning rate is set 1, except for last layer which is set to 0.1. We used gradient smoothing corresponding to 0.9 times previous gradient plus 0.1 the current one. Finally the learning rate drops linearly to 0 after 100 epochs and no weight decay is used. For training the student during distillation, no data augmentation is used. We used \u03b2 = 0.6, so the original cross-entropy with hard-targets is multiplied by 0.4 and we match the teacher logits with half the squared loss multiplied by 0.6. Note that optimizing for the squared loss is equivalent to picking a high temperature.\n\nFigure 1 :\n1Visualization of penultimate layer's activations of: AlexNet/CIFAR-10 (first row), CIFAR-100/ResNet-56 (second row) and ImageNet/Inception-v4 with three semantically different classes (third row) and two semantically similar classes plus a third one (fourth row).\n\nFigure 2 :\n2Reliability diagram of ResNet-56/CIFAR-100 (left) and Inception-v4/ImageNet (right).\n\nFigure 3 :\n3Reliability diagram of Transformer trained on EN-DE dataset.\n\nFigure 4 :\n4Effect of calibration of Transformer upon BLEU score (blue lines) and NLL (red lines). Curves without markers reflect networks trained without label smoothing while curves with markers represent networks with label smoothing.\n\nFig. 5\n5shows the results of this distillation experiment. We first compare the performance of the teacher network (blue solid curve, top) and student network (light blue solid, bottom) trained without distillation. For this particular setup, increasing \u03b1 improves the teacher's accuracy up to values of \u03b1 = 0.6, while label smoothing slightly degrades the baseline performance of the student networks.\n\nFigure 5 :\n5Performance of distillation fromResNet-56 to AlexNet on CIFAR-10.\n\nFigure 6 :\n6Estimated mutual information evolution during teacher training.\n\n\nL is the number of Monte Carlo samples used to calculate the empirical mean and N is the number of training examples used for mutual information estimation. Here the mutual information is between 0 and log(N ).\n\nFig.\nFig. 6 shows the estimated mutual information between a subset (N = 600 from two classes) of the training examples and the difference of the logits corresponding to these two classes. After initialization, the mutual information is very small, but as the network is trained, first it rapidly increases then it slowly decreases specially for the network trained with label smoothing. This result confirms the intuitions from the last sections. As the representations collapse to small clusters of points, much of the information that could have helped distinguish examples is lost. This results in lower estimated mutual information and poor distillation for teachers trained with label smoothing.\n\nTable 1 :\n1Survey of literature label smoothing results on three supervised learning tasks.DATA SET \nARCHITECTURE \nMETRIC \nVALUE W/O LS VALUE W/ LS \n\nIMAGENET INCEPTION-V2 [6] \nTOP-1 ERROR \n23.1 \n22.8 \nTOP-5 ERROR \n6.3 \n6.1 \nEN-DE \nTRANSFORMER [11] \nBLEU \n25.3 \n25.8 \nPERPLEXITY \n4.67 \n4.92 \nWSJ \nBILSTM+ATT.[10] \nWER \n8.9 \n7.0/6.7 \n\n\n\nTable 2 :\n2Top-1 classification accuracies of networks trained with and without label smoothing used in visualizations.DATA SET \nARCHITECTURE ACCURACY (\u03b1 = 0.0) ACCURACY (\u03b1 = 0.1) \n\nCIFAR-10 \nALEXNET \n86.8 \u00b1 0.2 \n86.7 \u00b1 0.3 \nCIFAR-100 RESNET-56 \n72.1 \u00b1 0.3 \n72.7 \u00b1 0.3 \nIMAGENET \nINCEPTION-V4 \n80.9 \n80.9 \n\n\n\nTable 3 :\n3Expected calibration error (ECE) on different architectures/datasets. their final model despite attaining worse perplexity compared to a model trained with hard targets (\u03b1 = 0.0). So we compare both setups in terms of calibration to verify that label smoothing also improves calibration in this task. Second, compared to image classification, where calibration does not directly affect the metric we care about (accuracy), in language translation, the network's soft outputs are inputs to a second algorithm (beam-search) which is affected by calibration. Since beam-search approximates a maximum likelihood sequence detection algorithm (Viterbi algorithm), we would intuitively expect better performance for a better calibrated model, since the model's confidence predicts better the accuracy of the next token.BASELINE \nTEMP. SCALING \nLABEL SMOOTHING \nDATA SET \nARCHITECTURE ECE (T=1.0, \u03b1 = 0.0) ECE / T (\u03b1 = 0.0) \nECE / \u03b1 (T=1.0) \n\nCIFAR-100 RESNET-56 \n0.150 \n0.021 / 1.9 \n0.024 / 0.05 \nIMAGENET \nINCEPTION-V4 \n0.071 \n0.022 / 1.4 \n0.035 / 0.1 \nEN-DE \nTRANSFORMER \n0.056 \n0.018 / 1.13 \n0.019 / 0.1 \n\n\nhttps://www.tensorflow.org/tutorials/images/deep_cnn 3 https://github.com/tensorflow/models/blob/master/tutorials/image/cifar10/cifar10.py 4 https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/data_generators/cifar.py 5 https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/models/resnet.py 6 https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/data_generators/image_utils.py 7 https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/models/transformer.py 8 https://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/data_generators/translate_ende. py\nhttps://github.com/tensorflow/tensor2tensor/blob/master/tensor2tensor/bin/t2t_bleu.py 10 https://github.com/tensorflow/models/blob/master/research/slim/nets/inception_v4.py\nAppendix A Experimental detailsA.1 AlexNet The AlexNet architecture was used in the visualization section and in the distillation section. In both cases, it was trained on the CIFAR-10 dataset. We split the training set into training and validation (40k/10k) and results are shown in the validation set. Our implementation is based on the public available code in 2 and 3 without exponential weight averaging. The mini-batch size is 128 and we train for 390k iterations with stochastic gradient descent, starting with learning rate 0.1 and droping by a factor of 10 every 130k steps. We multiply the cross-entropy term by 3 and use weight decay of 0.04 in the last two dense layers. Five different seeds were used for each point shown in the figure and we show min/average/max. For visualization of representations of CIFAR-10 a total of 300 examples were used (100 per class). For the distillation results, \u03b2 is set to 1 so distillation is done fully with teacher targets. Note that we use the same training procedure for: training the student without distillation (variable label smoothing), training the student to mimic the teacher trained with hard targets and temperature scaling, and training the student to mimic the teacher trained with variable label smoothing. In the end, the only difference is the targets used. Additionally, when \u03b2 = 1, the temperature of the teacher is important to soften the targets, but the temperature of the student ends up to be just a scalar multiplying the logits and can be learned, therefore we set the student soft-max temperature to 1 for all experiments. For distillation with teacher trained with hard targets, the temperatures tested were 1.A.2 ResNetThe ResNet architecture was used in the visualization, calibration and distillation sections. In all cases, it was trained on the CIFAR-10 and CIFAR-100 datasets4. We split the training set into training and validation (40k/10k) and results are shown in the validation set. Our implementation uses the public available model in5. The mini-batch size is 128 and we train for 64k iterations with stochastic gradient descent with Nesterov momentum of 0.9, starting with learning rate 0.1 and dropping by a factor of 10 at 32k and 48k steps. We multiply the cross-entropy term by 3 and use weight decay of 0.0001. Compared to the implementation in tensor2tensor library, we include gradient clipping of 1.0 and to create a deep network of 56 layers, we set the number of blocks per layer to 9 for the three blocks. We also set the kernel size to 3 instead of 7 to resemble the original ResNet architecture for CIFAR-10 dataset. For visualization of representations of CIFAR-100 a total of 300 examples were used (100 per class). For the calibration experiment, all 10k examples on the validation set were used to calculate the ECE and reliability diagram. The label smoothing values used when training the teacher in the distillation section were 0.0 to 0.75 with steps of 0.15. For the mutual information results we pick the classes \"airplane\" and \"dog\", and calculate the mutual information using 300 examples from the training set of each class. To calculate the average logit per example, we use 5 Monte Carlo samples and estimated mutual information is calculated every 4k training steps. For data augmentation we used random crops and left-right flips as in 6 (cifar_image_augmentation).A.3 TransformerThe Transformer architecture was used in the calibration section. We reuse the public available implementation by the original authors described in7. The dataset can be found in 8 (TranslateEndeWmt32k for around 32k tokens). We used the hyper-parameters provided by the authors of original paper for single GPU training (transformer_base for label smoothing of 0.1, and transformer_ls0 for label smoothing of 0.0). Compared to the original paper, we train for 300k steps instead of 100k and we do not use weight averaging of checkpoints. For the calibration experiment, around 10k tokens of the\nLearning representations by back-propagating errors. Geoffrey E David E Rumelhart, Ronald J Hinton, Williams, Nature. 32319David E Rumelhart, Geoffrey E Hinton, Ronald J Williams, et al. Learning representations by back-propagating errors. Nature, 323:19, 1986.\n\nSupervised learning of probability distributions by neural networks. B Eric, Frank Baum, Wilczek, Neural information processing systems. Eric B Baum and Frank Wilczek. Supervised learning of probability distributions by neural networks. In Neural information processing systems, pages 52-61, 1988.\n\nAccelerated learning in layered neural networks. Complex systems. Sara Solla, Esther Levin, Michael Fleisher, 2Sara Solla, Esther Levin, and Michael Fleisher. Accelerated learning in layered neural networks. Complex systems, 2:625-640, 1988.\n\nAn empirical study of learning speed in back-propagation networks. Scott E Fahlman, Carnegie Mellon University, Computer Science DepartmentTechnical reportScott E Fahlman. An empirical study of learning speed in back-propagation networks. Technical report, Carnegie Mellon University, Computer Science Department, 1988.\n\nIntroduction to the theory of neural computation. A John, Anders Hertz, Richard G Krogh, Palmer, Addison-WesleyJohn A Hertz, Anders Krogh, and Richard G. Palmer. Introduction to the theory of neural computation. Addison-Wesley, 2018.\n\nRethinking the inception architecture for computer vision. Christian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, Zbigniew Wojna, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionChristian Szegedy, Vincent Vanhoucke, Sergey Ioffe, Jon Shlens, and Zbigniew Wojna. Re- thinking the inception architecture for computer vision. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 2818-2826, 2016.\n\nLearning transferable architectures for scalable image recognition. Barret Zoph, Vijay Vasudevan, Jonathon Shlens, Quoc V Le, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionBarret Zoph, Vijay Vasudevan, Jonathon Shlens, and Quoc V Le. Learning transferable architectures for scalable image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 8697-8710, 2018.\n\nRegularized evolution for image classifier architecture search. Esteban Real, Alok Aggarwal, Yanping Huang, Quoc V Le, arXiv:1802.01548arXiv preprintEsteban Real, Alok Aggarwal, Yanping Huang, and Quoc V Le. Regularized evolution for image classifier architecture search. arXiv preprint arXiv:1802.01548, 2018.\n\nYanping Huang, Yonglong Cheng, Dehao Chen, Hyoukjoong Lee, Jiquan Ngiam, V Quoc, Zhifeng Le, Chen, Gpipe, arXiv:1811.06965Efficient training of giant neural networks using pipeline parallelism. arXiv preprintYanping Huang, Yonglong Cheng, Dehao Chen, HyoukJoong Lee, Jiquan Ngiam, Quoc V Le, and Zhifeng Chen. GPipe: Efficient training of giant neural networks using pipeline parallelism. arXiv preprint arXiv:1811.06965, 2018.\n\nTowards better decoding and language model integration in sequence to sequence models. Jan Chorowski, Navdeep Jaitly, Proc. Interspeech. InterspeechJan Chorowski and Navdeep Jaitly. Towards better decoding and language model integration in sequence to sequence models. Proc. Interspeech 2017, pages 523-527, 2017.\n\nAttention is all you need. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, Illia Polosukhin, Advances in neural information processing systems. Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez, \u0141ukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Advances in neural information processing systems, pages 5998-6008, 2017.\n\nImagenet classification with deep convolutional neural networks. Alex Krizhevsky, Ilya Sutskever, Geoffrey E Hinton, Advances in neural information processing systems. Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Imagenet classification with deep convolutional neural networks. In Advances in neural information processing systems, pages 1097-1105, 2012.\n\nDeep residual learning for image recognition. Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionKaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pages 770-778, 2016.\n\nInception-v4, inception-resnet and the impact of residual connections on learning. Christian Szegedy, Sergey Ioffe, Vincent Vanhoucke, Alexander A Alemi, Thirty-First AAAI Conference on Artificial Intelligence. Christian Szegedy, Sergey Ioffe, Vincent Vanhoucke, and Alexander A Alemi. Inception-v4, inception-resnet and the impact of residual connections on learning. In Thirty-First AAAI Conference on Artificial Intelligence, 2017.\n\nOn calibration of modern neural networks. Chuan Guo, Geoff Pleiss, Yu Sun, Kilian Q Weinberger, Proceedings of the 34th International Conference on Machine Learning. the 34th International Conference on Machine Learning70Chuan Guo, Geoff Pleiss, Yu Sun, and Kilian Q Weinberger. On calibration of modern neural networks. In Proceedings of the 34th International Conference on Machine Learning-Volume 70, pages 1321-1330. JMLR. org, 2017.\n\nDistilling the knowledge in a neural network. Geoffrey Hinton, Oriol Vinyals, Jeff Dean, arXiv:1503.02531arXiv preprintGeoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distilling the knowledge in a neural network. arXiv preprint arXiv:1503.02531, 2015.\n\nGabriel Pereyra, George Tucker, Jan Chorowski, \u0141ukasz Kaiser, Geoffrey Hinton, arXiv:1701.06548Regularizing neural networks by penalizing confident output distributions. arXiv preprintGabriel Pereyra, George Tucker, Jan Chorowski, \u0141ukasz Kaiser, and Geoffrey Hinton. Reg- ularizing neural networks by penalizing confident output distributions. arXiv preprint arXiv:1701.06548, 2017.\n\nDisturblabel: Regularizing cnn on the loss layer. Lingxi Xie, Jingdong Wang, Zhen Wei, Meng Wang, Qi Tian, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionLingxi Xie, Jingdong Wang, Zhen Wei, Meng Wang, and Qi Tian. Disturblabel: Regularizing cnn on the loss layer. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 4753-4762, 2016.\n\nAnalyzing uncertainty in neural machine translation. Myle Ott, Michael Auli, David Grangier, International Conference on Machine Learning. Myle Ott, Michael Auli, David Grangier, et al. Analyzing uncertainty in neural machine translation. In International Conference on Machine Learning, pages 3953-3962, 2018.\n\nCalibration of encoder decoder models for neural machine translation. Aviral Kumar, Sunita Sarawagi, arXiv:1903.00802arXiv preprintAviral Kumar and Sunita Sarawagi. Calibration of encoder decoder models for neural machine translation. arXiv preprint arXiv:1903.00802, 2019.\n\nSimon Kornblith, Jonathon Shlens, Quoc V Le, arXiv:1805.08974Do better imagenet models transfer better. arXiv preprintSimon Kornblith, Jonathon Shlens, and Quoc V Le. Do better imagenet models transfer better? arXiv preprint arXiv:1805.08974, 2018.\n\nAdaptive estimators show information compression in deep neural networks. Ivan Chelombiev, Conor Houghton, Cian O&apos; Donnell, arXiv:1902.09037arXiv preprintIvan Chelombiev, Conor Houghton, and Cian O'Donnell. Adaptive estimators show information compression in deep neural networks. arXiv preprint arXiv:1902.09037, 2019.\n\nOpening the black box of deep neural networks via information. Ravid Shwartz, -Ziv , Naftali Tishby, arXiv:1703.00810arXiv preprintRavid Shwartz-Ziv and Naftali Tishby. Opening the black box of deep neural networks via information. arXiv preprint arXiv:1703.00810, 2017.\n\nDeep learning and the information bottleneck principle. Naftali Tishby, Noga Zaslavsky, IEEE Information Theory Workshop (ITW). IEEENaftali Tishby and Noga Zaslavsky. Deep learning and the information bottleneck principle. In 2015 IEEE Information Theory Workshop (ITW), pages 1-5. IEEE, 2015.\n\nNaftali Tishby, C Fernando, William Pereira, Bialek, The information bottleneck method. arXiv preprint physics/0004057. Naftali Tishby, Fernando C Pereira, and William Bialek. The information bottleneck method. arXiv preprint physics/0004057, 2000.\n", "annotations": {"author": "[{\"end\":73,\"start\":35},{\"end\":90,\"start\":74},{\"end\":114,\"start\":91},{\"end\":129,\"start\":115}]", "publisher": null, "author_last_name": "[{\"end\":48,\"start\":42},{\"end\":89,\"start\":80},{\"end\":113,\"start\":107},{\"end\":128,\"start\":121}]", "author_first_name": "[{\"end\":41,\"start\":35},{\"end\":79,\"start\":74},{\"end\":99,\"start\":91},{\"end\":106,\"start\":100},{\"end\":120,\"start\":115}]", "author_affiliation": null, "title": "[{\"end\":32,\"start\":1},{\"end\":161,\"start\":130}]", "venue": null, "abstract": "[{\"end\":1564,\"start\":163}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":1706,\"start\":1703},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":1930,\"start\":1927},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":1932,\"start\":1930},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2106,\"start\":2103},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":2108,\"start\":2106},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":2143,\"start\":2140},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":2567,\"start\":2564},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":2830,\"start\":2827},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":2832,\"start\":2830},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":2834,\"start\":2832},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":2884,\"start\":2880},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":2999,\"start\":2995},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":6227,\"start\":6224},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":6808,\"start\":6804},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":6824,\"start\":6820},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":6846,\"start\":6842},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":10516,\"start\":10512},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":13539,\"start\":13535},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":14034,\"start\":14030},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":15951,\"start\":15947},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":17697,\"start\":17696},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":17863,\"start\":17862},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":22193,\"start\":22190},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":22561,\"start\":22557},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":23166,\"start\":23162},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":23317,\"start\":23313},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":23460,\"start\":23456},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":23607,\"start\":23603},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":23973,\"start\":23969},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":24439,\"start\":24435},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":24674,\"start\":24670},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":24969,\"start\":24965},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":24972,\"start\":24969},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":24975,\"start\":24972},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":26972,\"start\":26970}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":28765,\"start\":28489},{\"attributes\":{\"id\":\"fig_1\"},\"end\":28863,\"start\":28766},{\"attributes\":{\"id\":\"fig_2\"},\"end\":28937,\"start\":28864},{\"attributes\":{\"id\":\"fig_3\"},\"end\":29176,\"start\":28938},{\"attributes\":{\"id\":\"fig_4\"},\"end\":29580,\"start\":29177},{\"attributes\":{\"id\":\"fig_5\"},\"end\":29659,\"start\":29581},{\"attributes\":{\"id\":\"fig_6\"},\"end\":29736,\"start\":29660},{\"attributes\":{\"id\":\"fig_7\"},\"end\":29949,\"start\":29737},{\"attributes\":{\"id\":\"fig_8\"},\"end\":30652,\"start\":29950},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":30988,\"start\":30653},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":31297,\"start\":30989},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":32412,\"start\":31298}]", "paragraph": "[{\"end\":2344,\"start\":1580},{\"end\":3092,\"start\":2346},{\"end\":3434,\"start\":3094},{\"end\":4112,\"start\":3436},{\"end\":4329,\"start\":4130},{\"end\":5075,\"start\":4367},{\"end\":5700,\"start\":5113},{\"end\":6617,\"start\":5749},{\"end\":7894,\"start\":6619},{\"end\":8636,\"start\":7896},{\"end\":10180,\"start\":8638},{\"end\":11125,\"start\":10211},{\"end\":12288,\"start\":11127},{\"end\":12756,\"start\":12290},{\"end\":13314,\"start\":12758},{\"end\":14111,\"start\":13316},{\"end\":15485,\"start\":14113},{\"end\":16499,\"start\":15512},{\"end\":16985,\"start\":16501},{\"end\":17522,\"start\":16987},{\"end\":18040,\"start\":17524},{\"end\":18237,\"start\":18042},{\"end\":19232,\"start\":18283},{\"end\":20122,\"start\":19234},{\"end\":21948,\"start\":20124},{\"end\":22525,\"start\":22116},{\"end\":23273,\"start\":22542},{\"end\":24303,\"start\":23275},{\"end\":25029,\"start\":24305},{\"end\":26795,\"start\":25060},{\"end\":27497,\"start\":26816},{\"end\":28488,\"start\":27521}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":4366,\"start\":4330},{\"attributes\":{\"id\":\"formula_1\"},\"end\":5748,\"start\":5701},{\"attributes\":{\"id\":\"formula_2\"},\"end\":18282,\"start\":18238},{\"attributes\":{\"id\":\"formula_3\"},\"end\":22115,\"start\":21949}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":2547,\"start\":2538},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":6869,\"start\":6862},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":12085,\"start\":12078},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":23039,\"start\":23032}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1578,\"start\":1566},{\"attributes\":{\"n\":\"1.1\"},\"end\":4128,\"start\":4115},{\"attributes\":{\"n\":\"2\"},\"end\":5111,\"start\":5078},{\"attributes\":{\"n\":\"3\"},\"end\":10209,\"start\":10183},{\"attributes\":{\"n\":\"4\"},\"end\":15510,\"start\":15488},{\"attributes\":{\"n\":\"5\"},\"end\":22540,\"start\":22528},{\"attributes\":{\"n\":\"6\"},\"end\":25058,\"start\":25032},{\"end\":26814,\"start\":26798},{\"end\":27519,\"start\":27500},{\"end\":28500,\"start\":28490},{\"end\":28777,\"start\":28767},{\"end\":28875,\"start\":28865},{\"end\":28949,\"start\":28939},{\"end\":29184,\"start\":29178},{\"end\":29592,\"start\":29582},{\"end\":29671,\"start\":29661},{\"end\":29955,\"start\":29951},{\"end\":30663,\"start\":30654},{\"end\":30999,\"start\":30990},{\"end\":31308,\"start\":31299}]", "table": "[{\"end\":30988,\"start\":30745},{\"end\":31297,\"start\":31109},{\"end\":32412,\"start\":32122}]", "figure_caption": "[{\"end\":28765,\"start\":28502},{\"end\":28863,\"start\":28779},{\"end\":28937,\"start\":28877},{\"end\":29176,\"start\":28951},{\"end\":29580,\"start\":29186},{\"end\":29659,\"start\":29594},{\"end\":29736,\"start\":29673},{\"end\":29949,\"start\":29739},{\"end\":30652,\"start\":29956},{\"end\":30745,\"start\":30665},{\"end\":31109,\"start\":31001},{\"end\":32122,\"start\":31310}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":6628,\"start\":6622},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":7017,\"start\":7011},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":11229,\"start\":11223},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":12346,\"start\":12332},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":13077,\"start\":13071},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":13664,\"start\":13656},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":14404,\"start\":14398},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":19421,\"start\":19415},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":21258,\"start\":21257}]", "bib_author_first_name": "[{\"end\":37273,\"start\":37265},{\"end\":37275,\"start\":37274},{\"end\":37301,\"start\":37295},{\"end\":37303,\"start\":37302},{\"end\":37545,\"start\":37544},{\"end\":37557,\"start\":37552},{\"end\":37844,\"start\":37840},{\"end\":37858,\"start\":37852},{\"end\":37873,\"start\":37866},{\"end\":38389,\"start\":38388},{\"end\":38402,\"start\":38396},{\"end\":38417,\"start\":38410},{\"end\":38419,\"start\":38418},{\"end\":38641,\"start\":38632},{\"end\":38658,\"start\":38651},{\"end\":38676,\"start\":38670},{\"end\":38687,\"start\":38684},{\"end\":38704,\"start\":38696},{\"end\":39178,\"start\":39172},{\"end\":39190,\"start\":39185},{\"end\":39210,\"start\":39202},{\"end\":39225,\"start\":39219},{\"end\":39678,\"start\":39671},{\"end\":39689,\"start\":39685},{\"end\":39707,\"start\":39700},{\"end\":39721,\"start\":39715},{\"end\":39926,\"start\":39919},{\"end\":39942,\"start\":39934},{\"end\":39955,\"start\":39950},{\"end\":39972,\"start\":39962},{\"end\":39984,\"start\":39978},{\"end\":39993,\"start\":39992},{\"end\":40007,\"start\":40000},{\"end\":40438,\"start\":40435},{\"end\":40457,\"start\":40450},{\"end\":40696,\"start\":40690},{\"end\":40710,\"start\":40706},{\"end\":40724,\"start\":40720},{\"end\":40738,\"start\":40733},{\"end\":40755,\"start\":40750},{\"end\":40768,\"start\":40763},{\"end\":40770,\"start\":40769},{\"end\":40784,\"start\":40778},{\"end\":40798,\"start\":40793},{\"end\":41161,\"start\":41157},{\"end\":41178,\"start\":41174},{\"end\":41198,\"start\":41190},{\"end\":41200,\"start\":41199},{\"end\":41512,\"start\":41505},{\"end\":41524,\"start\":41517},{\"end\":41540,\"start\":41532},{\"end\":41550,\"start\":41546},{\"end\":41994,\"start\":41985},{\"end\":42010,\"start\":42004},{\"end\":42025,\"start\":42018},{\"end\":42046,\"start\":42037},{\"end\":42048,\"start\":42047},{\"end\":42385,\"start\":42380},{\"end\":42396,\"start\":42391},{\"end\":42407,\"start\":42405},{\"end\":42421,\"start\":42413},{\"end\":42831,\"start\":42823},{\"end\":42845,\"start\":42840},{\"end\":42859,\"start\":42855},{\"end\":43036,\"start\":43029},{\"end\":43052,\"start\":43046},{\"end\":43064,\"start\":43061},{\"end\":43082,\"start\":43076},{\"end\":43099,\"start\":43091},{\"end\":43469,\"start\":43463},{\"end\":43483,\"start\":43475},{\"end\":43494,\"start\":43490},{\"end\":43504,\"start\":43500},{\"end\":43513,\"start\":43511},{\"end\":43935,\"start\":43931},{\"end\":43948,\"start\":43941},{\"end\":43960,\"start\":43955},{\"end\":44266,\"start\":44260},{\"end\":44280,\"start\":44274},{\"end\":44470,\"start\":44465},{\"end\":44490,\"start\":44482},{\"end\":44505,\"start\":44499},{\"end\":44793,\"start\":44789},{\"end\":44811,\"start\":44806},{\"end\":44834,\"start\":44822},{\"end\":45109,\"start\":45104},{\"end\":45123,\"start\":45119},{\"end\":45133,\"start\":45126},{\"end\":45376,\"start\":45369},{\"end\":45389,\"start\":45385},{\"end\":45615,\"start\":45608},{\"end\":45625,\"start\":45624},{\"end\":45643,\"start\":45636}]", "bib_author_last_name": "[{\"end\":37293,\"start\":37276},{\"end\":37310,\"start\":37304},{\"end\":37320,\"start\":37312},{\"end\":37550,\"start\":37546},{\"end\":37562,\"start\":37558},{\"end\":37571,\"start\":37564},{\"end\":37850,\"start\":37845},{\"end\":37864,\"start\":37859},{\"end\":37882,\"start\":37874},{\"end\":38099,\"start\":38084},{\"end\":38394,\"start\":38390},{\"end\":38408,\"start\":38403},{\"end\":38425,\"start\":38420},{\"end\":38433,\"start\":38427},{\"end\":38649,\"start\":38642},{\"end\":38668,\"start\":38659},{\"end\":38682,\"start\":38677},{\"end\":38694,\"start\":38688},{\"end\":38710,\"start\":38705},{\"end\":39183,\"start\":39179},{\"end\":39200,\"start\":39191},{\"end\":39217,\"start\":39211},{\"end\":39228,\"start\":39226},{\"end\":39683,\"start\":39679},{\"end\":39698,\"start\":39690},{\"end\":39713,\"start\":39708},{\"end\":39724,\"start\":39722},{\"end\":39932,\"start\":39927},{\"end\":39948,\"start\":39943},{\"end\":39960,\"start\":39956},{\"end\":39976,\"start\":39973},{\"end\":39990,\"start\":39985},{\"end\":39998,\"start\":39994},{\"end\":40010,\"start\":40008},{\"end\":40016,\"start\":40012},{\"end\":40023,\"start\":40018},{\"end\":40448,\"start\":40439},{\"end\":40464,\"start\":40458},{\"end\":40704,\"start\":40697},{\"end\":40718,\"start\":40711},{\"end\":40731,\"start\":40725},{\"end\":40748,\"start\":40739},{\"end\":40761,\"start\":40756},{\"end\":40776,\"start\":40771},{\"end\":40791,\"start\":40785},{\"end\":40809,\"start\":40799},{\"end\":41172,\"start\":41162},{\"end\":41188,\"start\":41179},{\"end\":41207,\"start\":41201},{\"end\":41515,\"start\":41513},{\"end\":41530,\"start\":41525},{\"end\":41544,\"start\":41541},{\"end\":41554,\"start\":41551},{\"end\":42002,\"start\":41995},{\"end\":42016,\"start\":42011},{\"end\":42035,\"start\":42026},{\"end\":42054,\"start\":42049},{\"end\":42389,\"start\":42386},{\"end\":42403,\"start\":42397},{\"end\":42411,\"start\":42408},{\"end\":42432,\"start\":42422},{\"end\":42838,\"start\":42832},{\"end\":42853,\"start\":42846},{\"end\":42864,\"start\":42860},{\"end\":43044,\"start\":43037},{\"end\":43059,\"start\":43053},{\"end\":43074,\"start\":43065},{\"end\":43089,\"start\":43083},{\"end\":43106,\"start\":43100},{\"end\":43473,\"start\":43470},{\"end\":43488,\"start\":43484},{\"end\":43498,\"start\":43495},{\"end\":43509,\"start\":43505},{\"end\":43518,\"start\":43514},{\"end\":43939,\"start\":43936},{\"end\":43953,\"start\":43949},{\"end\":43969,\"start\":43961},{\"end\":44272,\"start\":44267},{\"end\":44289,\"start\":44281},{\"end\":44480,\"start\":44471},{\"end\":44497,\"start\":44491},{\"end\":44508,\"start\":44506},{\"end\":44804,\"start\":44794},{\"end\":44820,\"start\":44812},{\"end\":44842,\"start\":44835},{\"end\":45117,\"start\":45110},{\"end\":45140,\"start\":45134},{\"end\":45383,\"start\":45377},{\"end\":45399,\"start\":45390},{\"end\":45622,\"start\":45616},{\"end\":45634,\"start\":45626},{\"end\":45651,\"start\":45644},{\"end\":45659,\"start\":45653}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":205001834},\"end\":37473,\"start\":37212},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":10578219},\"end\":37772,\"start\":37475},{\"attributes\":{\"id\":\"b2\"},\"end\":38015,\"start\":37774},{\"attributes\":{\"id\":\"b3\"},\"end\":38336,\"start\":38017},{\"attributes\":{\"id\":\"b4\"},\"end\":38571,\"start\":38338},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":206593880},\"end\":39102,\"start\":38573},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":12227989},\"end\":39605,\"start\":39104},{\"attributes\":{\"doi\":\"arXiv:1802.01548\",\"id\":\"b7\"},\"end\":39917,\"start\":39607},{\"attributes\":{\"doi\":\"arXiv:1811.06965\",\"id\":\"b8\"},\"end\":40346,\"start\":39919},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":9854876},\"end\":40661,\"start\":40348},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":13756489},\"end\":41090,\"start\":40663},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":195908774},\"end\":41457,\"start\":41092},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":206594692},\"end\":41900,\"start\":41459},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":1023605},\"end\":42336,\"start\":41902},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":28671436},\"end\":42775,\"start\":42338},{\"attributes\":{\"doi\":\"arXiv:1503.02531\",\"id\":\"b15\"},\"end\":43027,\"start\":42777},{\"attributes\":{\"doi\":\"arXiv:1701.06548\",\"id\":\"b16\"},\"end\":43411,\"start\":43029},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":10842458},\"end\":43876,\"start\":43413},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":4375156},\"end\":44188,\"start\":43878},{\"attributes\":{\"doi\":\"arXiv:1903.00802\",\"id\":\"b19\"},\"end\":44463,\"start\":44190},{\"attributes\":{\"doi\":\"arXiv:1805.08974\",\"id\":\"b20\"},\"end\":44713,\"start\":44465},{\"attributes\":{\"doi\":\"arXiv:1902.09037\",\"id\":\"b21\"},\"end\":45039,\"start\":44715},{\"attributes\":{\"doi\":\"arXiv:1703.00810\",\"id\":\"b22\"},\"end\":45311,\"start\":45041},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":5541663},\"end\":45606,\"start\":45313},{\"attributes\":{\"id\":\"b24\"},\"end\":45856,\"start\":45608}]", "bib_title": "[{\"end\":37263,\"start\":37212},{\"end\":37542,\"start\":37475},{\"end\":38630,\"start\":38573},{\"end\":39170,\"start\":39104},{\"end\":40433,\"start\":40348},{\"end\":40688,\"start\":40663},{\"end\":41155,\"start\":41092},{\"end\":41503,\"start\":41459},{\"end\":41983,\"start\":41902},{\"end\":42378,\"start\":42338},{\"end\":43461,\"start\":43413},{\"end\":43929,\"start\":43878},{\"end\":45367,\"start\":45313}]", "bib_author": "[{\"end\":37295,\"start\":37265},{\"end\":37312,\"start\":37295},{\"end\":37322,\"start\":37312},{\"end\":37552,\"start\":37544},{\"end\":37564,\"start\":37552},{\"end\":37573,\"start\":37564},{\"end\":37852,\"start\":37840},{\"end\":37866,\"start\":37852},{\"end\":37884,\"start\":37866},{\"end\":38101,\"start\":38084},{\"end\":38396,\"start\":38388},{\"end\":38410,\"start\":38396},{\"end\":38427,\"start\":38410},{\"end\":38435,\"start\":38427},{\"end\":38651,\"start\":38632},{\"end\":38670,\"start\":38651},{\"end\":38684,\"start\":38670},{\"end\":38696,\"start\":38684},{\"end\":38712,\"start\":38696},{\"end\":39185,\"start\":39172},{\"end\":39202,\"start\":39185},{\"end\":39219,\"start\":39202},{\"end\":39230,\"start\":39219},{\"end\":39685,\"start\":39671},{\"end\":39700,\"start\":39685},{\"end\":39715,\"start\":39700},{\"end\":39726,\"start\":39715},{\"end\":39934,\"start\":39919},{\"end\":39950,\"start\":39934},{\"end\":39962,\"start\":39950},{\"end\":39978,\"start\":39962},{\"end\":39992,\"start\":39978},{\"end\":40000,\"start\":39992},{\"end\":40012,\"start\":40000},{\"end\":40018,\"start\":40012},{\"end\":40025,\"start\":40018},{\"end\":40450,\"start\":40435},{\"end\":40466,\"start\":40450},{\"end\":40706,\"start\":40690},{\"end\":40720,\"start\":40706},{\"end\":40733,\"start\":40720},{\"end\":40750,\"start\":40733},{\"end\":40763,\"start\":40750},{\"end\":40778,\"start\":40763},{\"end\":40793,\"start\":40778},{\"end\":40811,\"start\":40793},{\"end\":41174,\"start\":41157},{\"end\":41190,\"start\":41174},{\"end\":41209,\"start\":41190},{\"end\":41517,\"start\":41505},{\"end\":41532,\"start\":41517},{\"end\":41546,\"start\":41532},{\"end\":41556,\"start\":41546},{\"end\":42004,\"start\":41985},{\"end\":42018,\"start\":42004},{\"end\":42037,\"start\":42018},{\"end\":42056,\"start\":42037},{\"end\":42391,\"start\":42380},{\"end\":42405,\"start\":42391},{\"end\":42413,\"start\":42405},{\"end\":42434,\"start\":42413},{\"end\":42840,\"start\":42823},{\"end\":42855,\"start\":42840},{\"end\":42866,\"start\":42855},{\"end\":43046,\"start\":43029},{\"end\":43061,\"start\":43046},{\"end\":43076,\"start\":43061},{\"end\":43091,\"start\":43076},{\"end\":43108,\"start\":43091},{\"end\":43475,\"start\":43463},{\"end\":43490,\"start\":43475},{\"end\":43500,\"start\":43490},{\"end\":43511,\"start\":43500},{\"end\":43520,\"start\":43511},{\"end\":43941,\"start\":43931},{\"end\":43955,\"start\":43941},{\"end\":43971,\"start\":43955},{\"end\":44274,\"start\":44260},{\"end\":44291,\"start\":44274},{\"end\":44482,\"start\":44465},{\"end\":44499,\"start\":44482},{\"end\":44510,\"start\":44499},{\"end\":44806,\"start\":44789},{\"end\":44822,\"start\":44806},{\"end\":44844,\"start\":44822},{\"end\":45119,\"start\":45104},{\"end\":45126,\"start\":45119},{\"end\":45142,\"start\":45126},{\"end\":45385,\"start\":45369},{\"end\":45401,\"start\":45385},{\"end\":45624,\"start\":45608},{\"end\":45636,\"start\":45624},{\"end\":45653,\"start\":45636},{\"end\":45661,\"start\":45653}]", "bib_venue": "[{\"end\":38853,\"start\":38791},{\"end\":39371,\"start\":39309},{\"end\":40496,\"start\":40485},{\"end\":41697,\"start\":41635},{\"end\":42557,\"start\":42504},{\"end\":43661,\"start\":43599},{\"end\":37328,\"start\":37322},{\"end\":37610,\"start\":37573},{\"end\":37838,\"start\":37774},{\"end\":38082,\"start\":38017},{\"end\":38386,\"start\":38338},{\"end\":38789,\"start\":38712},{\"end\":39307,\"start\":39230},{\"end\":39669,\"start\":39607},{\"end\":40111,\"start\":40041},{\"end\":40483,\"start\":40466},{\"end\":40860,\"start\":40811},{\"end\":41258,\"start\":41209},{\"end\":41633,\"start\":41556},{\"end\":42111,\"start\":42056},{\"end\":42502,\"start\":42434},{\"end\":42821,\"start\":42777},{\"end\":43197,\"start\":43124},{\"end\":43597,\"start\":43520},{\"end\":44015,\"start\":43971},{\"end\":44258,\"start\":44190},{\"end\":44567,\"start\":44526},{\"end\":44787,\"start\":44715},{\"end\":45102,\"start\":45041},{\"end\":45439,\"start\":45401},{\"end\":45726,\"start\":45661}]"}}}, "year": 2023, "month": 12, "day": 17}