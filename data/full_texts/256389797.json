{"id": 256389797, "updated": "2023-10-05 04:38:28.982", "metadata": {"title": "REPLUG: Retrieval-Augmented Black-Box Language Models", "authors": "[{\"first\":\"Weijia\",\"last\":\"Shi\",\"middle\":[]},{\"first\":\"Sewon\",\"last\":\"Min\",\"middle\":[]},{\"first\":\"Michihiro\",\"last\":\"Yasunaga\",\"middle\":[]},{\"first\":\"Minjoon\",\"last\":\"Seo\",\"middle\":[]},{\"first\":\"Rich\",\"last\":\"James\",\"middle\":[]},{\"first\":\"Mike\",\"last\":\"Lewis\",\"middle\":[]},{\"first\":\"Luke\",\"last\":\"Zettlemoyer\",\"middle\":[]},{\"first\":\"Wen-tau\",\"last\":\"Yih\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2023, "month": null, "day": null}, "abstract": "We introduce REPLUG, a retrieval-augmented language modeling framework that treats the language model (LM) as a black box and augments it with a tuneable retrieval model. Unlike prior retrieval-augmented LMs that train language models with special cross attention mechanisms to encode the retrieved text, REPLUG simply prepends retrieved documents to the input for the frozen black-box LM. This simple design can be easily applied to any existing retrieval and language models. Furthermore, we show that the LM can be used to supervise the retrieval model, which can then find documents that help the LM make better predictions. Our experiments demonstrate that REPLUG with the tuned retriever significantly improves the performance of GPT-3 (175B) on language modeling by 6.3%, as well as the performance of Codex on five-shot MMLU by 5.1%.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2301.12652", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/corr/abs-2301-12652", "doi": "10.48550/arxiv.2301.12652"}}, "content": {"source": {"pdf_hash": "07b14c24833400b79978b0a5f084803337e30a15", "pdf_src": "Arxiv", "pdf_uri": "[\"https://export.arxiv.org/pdf/2301.12652v4.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "5246771fb5e0adc87ea2fe8117af754e1ade858d", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/07b14c24833400b79978b0a5f084803337e30a15.txt", "contents": "\nREPLUG: Retrieval-Augmented Black-Box Language Models\n\n\nWeijia Shi \nSewon Min \nMichihiro Yasunaga \nMinjoon Seo \nRich James \nMike Lewis \nLuke Zettlemoyer \nWen-Tau Yih \nREPLUG: Retrieval-Augmented Black-Box Language Models\n\nWe introduce REPLUG, a retrieval-augmented language modeling framework that treats the language model (LM) as a black box and augments it with a tuneable retrieval model. Unlike prior retrieval-augmented LMs that train language models with special cross attention mechanisms to encode the retrieved text, REPLUG simply prepends retrieved documents to the input for the frozen black-box LM. This simple design can be easily applied to any existing retrieval and language models. Furthermore, we show that the LM can be used to supervise the retrieval model, which can then find documents that help the LM make better predictions. Our experiments demonstrate that REPLUG with the tuned retriever significantly improves the performance of GPT-3 (175B) on language modeling by 6.3%, as well as the performance of Codex on five-shot MMLU by 5.1%.\n\nIntroduction\n\nLarge language models (LLMs) such as GPT-3 (Brown et al., 2020a) and Codex (Chen et al., 2021a), have demonstrated impressive performance on a wide range of language tasks. These models are typically trained on very large datasets and store a substantial amount of world or domain knowledge implicitly in their parameters. However, they are also prone to hallucination and cannot represent the full long tail of knowledge from the training corpus. Retrieval-augmented language models (Khandelwal et al., 2020;Borgeaud et al., 2022;Izacard et al., 2022b;Yasunaga et al., 2022), in contrast, can retrieve knowledge from an external datastore when needed, potentially reducing hallucination and increasing coverage. Previous approaches of retrieval-augmented language models require access to the internal LM representations (e.g., to train the model Figure 1. Different from previous retrieval-augmented approaches  that enhance a language model with retrieval by updating the LM's parameters, REPLUG treats the language model as a black box and augments it with a frozen or tunable retriever. This black-box assumption makes REPLUG applicable to large LMs (i.e., >100B parameters), which are often served via APIs. Izacard et al., 2022b) or to index the datastore (Khandelwal et al., 2020)), and are thus difficult to be applied to very large LMs. In addition, many best-in-class LLMs can only be accessed through APIs. Internal representations of such models are not exposed and fine-tuning is not supported.\n\nIn this work, we introduce REPLUG (Retrieve and Plug), a new retrieval-augmented LM framework where the language model is viewed as a black box and the retrieval component is added as a tuneable plug-and-play module. Given an input context, REPLUG first retrieves relevant documents from an external corpus using an off-the-shelf retrieval model. The retrieved documents are prepended to the input context and fed into the black-box LM to make the final prediction. Because the LM context length limits the number of documents that can be prepended, we also introduce a new ensemble scheme that encodes the retrieved documents in parallel with the same black-box LM, allowing us to easily trade compute for accuracy. As shown in arXiv:2301.12652v4 [cs.CL] 24 May 2023 Figure 1, REPLUG is extremely flexible and can be used with any existing black-box LM and retrieval model.\n\nWe also introduce REPLUG LSR (REPLUG with LM-Supervised Retrieval), a training scheme that can further improve the initial retrieval model in REPLUG with supervision signals from a black-box language model. The key idea is to adapt the retriever to the LM, which is in contrast to prior work  that adapts language models to the retriever. We use a training objective which prefers retrieving documents that improve language model perplexity, while treating the LM as a frozen, black-box scoring function.\n\nOur experiments show that REPLUG can improve the performance of diverse black-box LMs on both language modeling and downstream tasks, including MMLU (Hendrycks et al., 2021) and open-domain QA (Kwiatkowski et al., 2019;Joshi et al., 2017). For instance, REPLUG can improve Codex (175B) performance on MMLU by 4.5%, achieving comparable results to the 540B, instruction-finetuned Flan-PaLM. Furthermore, tuning the retriever with our training scheme (i.e., REPLUG LSR) leads to additional improvements, including up to 6.3% increase in GPT-3 175B language modeling. To the best of our knowledge, our work is the first to show the benefits of retrieval to large LMs (>100B model parameters), for both reducing LM perplexity and and improving in-context learning performance. We summarize our contributions as follows:\n\n\u2022 We introduce REPLUG ( \u00a73), the first retrievalaugmented language modeling framework for enhancing large black-box language models with retrieval.\n\n\u2022 We propose a training scheme ( \u00a74) to further adapt an off-the-shelf retrieval model to the LM, using the language modeling scores as supervision signals, resulting in improved retrieval quality.\n\n\u2022 Evaluations on language modeling ( \u00a76), open-domain QA and MMLU demonstrate that REPLUG can improve the performance of various language models such as GPT, OPT and BLOOM, including very large models with up to 175B parameters.\n\n\nBackground and Related Work\n\nBlack-box Language Models Large language models (i.e., >100B), such as GPT-3 (Brown et al., 2020a), Codex (Chen et al., 2021a), and Yuan 1.0 , are not open-sourced due to commercial considerations and are only available as black-box APIs, through which users can send queries and receive responses. On the other hand, even open sourced language models such as OPT-175B (Zhang et al., 2022a) and BLOOM-176B (Scao et al., 2022) require significant computational resources to run and finetune locally. For example, finetuning BLOOM-176B requires 72 A100 GPUs (80GB memory, $15k each (Younes Belkda, 2022)), making them inaccessible to researchers and developers with limited resources. Traditionally, retrieval-augmented model frameworks (Khandelwal et al., 2020;Borgeaud et al., 2022;Yu, 2022;Izacard et al., 2022b;Goyal et al., 2022) have focused on the white-box setting, where language models are fine-tuned to incorporate retrieved documents. However, the increasing scale and black-box nature of large language models makes this approach infeasible. To address the challenges posed by large language models, we investigate retrieval-augmentation in the black-box setting, where users only have access to the model predictions and cannot access or modify its parameters.\n\n\nRetrieval-augmented Models\n\nAugmenting language models with relevant information retrieved from various knowledge stores has shown to be effective in improving performance on various NLP tasks, including language modeling (Min et al., 2022;Borgeaud et al., 2022;Khandelwal et al., 2020) and open-domain question answering Izacard et al., 2022b;Hu et al., 2022). Specifically, using the input as query, (1) a retriever first retrieves a set of documents (i.e., sequences of tokens) from a corpus and then (2) a language model incorporates the retrieved documents as additional information to make a final prediction. This style of retrieval can be added to both encoderdecoder (Yu, 2022;Izacard et al., 2022b) and decoder-only models (Khandelwal et al., 2020;Borgeaud et al., 2022;Shi et al., 2022;Rubin et al., 2022). For example, Atlas (Izacard et al., 2022b) finetunes an encoder-decoder model jointly with the retriever by modeling documents as latent variables, while RETRO  changes the decoderonly architecture to incorporate retrieved texts and pretrains the language model from scratch. Both methods require updating the model parameters through gradient descent, which cannot be applied to black-box LMs. Another line of retrieval-augmented LMs such as kNN-LM (Khandelwal et al., 2020;Zhong et al., 2022) retrieves a set of tokens and interpolates between the LM's next token distribution and kNN distributions computed from the retrieved tokens at inference. Although kNN-LM does not require additional training, it requires access to internal LM representations to compute the kNN distribution, which are not always available for large LMs such as GPT-3. In this work, we investigate ways to improve large black-box language models with retrieval. While concurrent work (Mallen et al., 2022;Si et al., 2023;Yu et al., 2023;Khattab et al., 2022) has demonstrated that using a frozen retriever can improve GPT-3 performance on open-domain question answering, we approach the problem in a more general setting, including language modeling and understanding tasks. We also propose an ensemble method to incorporate more documents and a training scheme to further adapt the retriever to large LMs.\n\n\nREPLUG\n\nWe introduce REPLUG (Retrieve and Plug), a new retrievalaugmented LM paradigm where the language model is treated as black box and the retrieval component is added as a potentially tuneable module.\n\nAs shown in Figure 2, given an input context, REPLUG first retrieves a small set of relevant documents from an external corpus using a retriever ( \u00a73.1). Then we pass the concatenation of each retrieved document with the input context through the LM in parallel, and ensemble the predicted probabilities ( \u00a73.2).\n\n\nDocument Retrieval\n\nGiven an input context x, the retriever aims to retrieve a small set of documents from a corpus D = {d 1 ...d m } that are relevant to x. Following prior work Izacard & Grave, 2021b;Ni et al., 2021), we use a dense retriever based on the dual encoder architecture, where an encoder is used to encode both the input context x and the document d. Specifically, the encoder maps each document d \u2208 D to an embedding E(d) by taking the mean pooling of the last hidden representation over the tokens in d. At query time, the same encoder is applied to the input context x to obtain a query embedding E(x). The similarity between the query embedding and the document embedding is computed by their cosine similarity:\ns(d, x) = cos(E(d), E(x))(1)\nThe top-k documents that have the highest similarity scores when compared with the input x are retrieved in this step.\n\nFor efficient retrieval, we precompute the embedding of each document d \u2208 D and construct FAISS index (Johnson et al., 2019) over these embeddings.\n\n\nInput Reformulation\n\nThe retrieved top-k documents provide rich information about the original input context x and can potentially help the LM to make a better prediction. One simple way to incorporate the retrieved documents as part of the input to the LM is to prepend x with all k documents. However, this simple scheme is fundamentally restricted by the number of documents (i.e., k) we can include, given the language model's context window size. To address this limitation, we adopt an ensemble strategy described as follows. Assume D \u2032 \u2282 D consists of k most relevant documents to x, according to the scoring function in Eq. (1). We prepend each document d \u2208 D \u2032 to x, pass this concatenation to the LM separately, and then ensemble output probabilities from all k passes. Formally, given the input context x and its top-k relevant documents D \u2032 , the output probability of the next token y is computed as a weighted average ensemble:\np(y | x, D \u2032 ) = d\u2208D \u2032 p(y | d \u2022 x) \u00b7 \u03bb(d, x),\nwhere \u2022 denotes the concatenation of two sequences and the weight \u03bb(d, x) is based on the similarity score between the document d and the input context x:\n\u03bb(d, x) = e s(d,x) d\u2208D \u2032 e s(d,x)\nAlthough our ensemble method requires running the LM k times, the cross attention is performed between each retrieved document and the input context. Therefore, compared with the method of prepending all the retrieved docu-ments, our ensemble methods do not incur additional computational cost overhead.\n\n\nREPLUG LSR: Training the Dense Retriever\n\nInstead of relying only on existing neural dense retrieval models (Karpukhin et al., 2020a;Izacard et al., 2022a;Su et al., 2022), we further propose REPLUG LSR (REPLUG with LM-Supervised Retrieval), which adapts the retriever in REPLUG by using the LM itself to provide supervision about which documents should be retrieved.\n\nInspired by Sachan et al. (2022), our approach can be seen as adjusting the probabilities of the retrieved documents to match the probabilities of the output sequence perplexities of the language model. In other words, we would like the retriever to find documents that result in lower perplexity scores. As shown in Figure 3, our training algorithm consists of the four steps: (1) retrieving documents and computing the retrieval likelihood ( \u00a74.1), (2) scoring the retrieved documents by the language model ( \u00a74.2), (3) updating the retrieval model parameters by minimizing the KL divergence between the retrieval likelihood and the LM's score distribution ( \u00a74.3), and (4) asynchronous update of the datastore index ( \u00a74.4).\n\n\nComputing Retrieval Likelihood\n\nWe retrieve k documents D \u2032 \u2282 D with the highest similarity scores from a corpus D given an input context x, as described in \u00a73.1. We then compute the retrieval likelihood of each retrieved document d:\nP R (d | x) = e s(d,x)/\u03b3\nd\u2208D \u2032 e s(d,x)/\u03b3 where \u03b3 is a hyperparameter that controls the temerature of the softmax. Ideally, the retrieval likelihood is computed by marginalizing over all the documents in the corpus D, which is intractable in practice. Therefore, we approximate the retrieval likelihood by only marginalizing over the retrieved documents D \u2032 .\n\n\nComputing LM likelihood\n\nWe use the LM as a scoring function to measure how much each document could improve the LM perplexity. Specifically, we first compute P LM (y | d, x), the LM probability of the ground truth output y given the input context x and a document d. The higher the probability, the better the document d i is at improving the LM's perplexity. We then compute the LM likelihood of each document d as follows:\nQ(d | x, y) = e P LM (y|d,x)/\u03b2 d\u2208D \u2032 e P LM (y|d,x)/\u03b2\nwhere \u03b2 is another hyperparameter.\n\n\nLoss Function\n\nGiven the input context x and the corresponding ground truth continuation y, we compute the retrieval likelihood and the language model likelihood. The dense retriever is trained by minimizing the KL divergence between these two distributions:\nL = 1 |B| x\u2208B KL P R (d | x) \u2225 Q LM (d | x, y) ,\nwhere B is a set of input contexts. When minimizing the loss, we can only update the retrieval model parameters. The LM parameters are fixed due to our black-box assumption.\n\n\nAsynchronous Update of the Datastore Index\n\nBecause the parameters in the retriever are updated during the training process, the previously computed document embeddings are no longer up to date. Therefore, following Guu et al. (2020), we recompute the document embeddings and rebuild the efficient search index using the new embeddings every T training steps. Then we use the new document embeddings and index for retrieval, and repeat the training procedure.\n\n\nTraining Setup\n\nIn this section, we describe the details of our training procedure. We first describe the model setting in REPLUG ( \u00a75.1) and then describe the procedure for training the retriever in REPLUG LSR ( \u00a75.2).\n\n\nREPLUG\n\nIn theory, any type of retriever, either dense (Karpukhin et al., 2020b;Ni et al., 2021) or sparse (Robertson et al., 2009), could be used for REPLUG. Following prior work (Izacard et al., 2022b), we use the Contriever (Izacard et al., 2022a) as the retrieval model for REPLUG, as it has demonstrated strong performance.\n\n\nREPLUG LSR\n\nFor REPLUG LSR, we initialize the retriever with the Contriever model (Izacard et al., 2022a). We use GPT-3 Curie (Brown et al., 2020b) as the supervision LM to compute the LM likelihood.\n\nTraining data We use 800K sequences of 256 tokens each, sampled from the Pile training data (Gao et al., 2020), as our training queries. Each query is split into two parts: the first 128 tokens are used as the input context x, and the last 128 tokens are used as the ground truth continuation y. For the external corpus D, we sample 36M documents of 128 tokens from the Pile training data. To avoid trivial retrieval, we ensure that the external corpus documents do not overlap with the documents from which the training queries are sampled.\n\nTraining details To make the training process more efficient, we pre-compute the document embeddings of the external corpus D and create a FAISS index (Johnson et al., 2019) for fast similarity search. Given a query x, we retrieve the top 20 documents from the FAISS index and compute the retrieval likelihood and the LM likelihood with a temperature of 0.1. We train the retriever using the Adam optimizer (Kingma & Ba, 2015) with a learning rate of 2e-5, a batch size of 64, and a warmup ratio of 0.1. We re-compute the document embeddings every 3k steps and fine-tune the retriever for a total of 25k steps.\n\n\nExperiments\n\nWe perform evaluations on both language modeling ( \u00a76.1) and downstream tasks such as MMLU ( \u00a76.\n\n2) and opendomain QA ( \u00a76.3). In all settings, REPLUG\u0129mprove the performance of various black-box language models, showing the effectiveness and generality of our approach.\n\n\nLanguage Modeling\n\nDatasets The Pile (Gao et al., 2020) is a language modeling benchmark that consists of text sources from diverse domains such as web pages, code and academic papers. Following prior work, we report bits per UTF-8 encoded byte (BPB) as the metric on each subset domain.\n\nBaselines We consider GPT-3 and GPT-2 family language model as the baselines. The four models from GPT-3 (Davinci, Curie, Baddage and Ada) are black-box models that are only accessible through API Our model We add REPLUG and REPLUG LSR to the baselines. We randomly subsampled Pile training data (367M documents of 128 tokens) and use them as the retrieval corpus for all models. As the Pile dataset has made efforts to deduplicate documents across train, validation and test splits (Gao et al., 2020), we did not do additional filtering. For both REPLUG and REPLUG LSR, we use a length of 128-token context to do retrieval and adopt the ensemble method (Section 3.2) to incorporate top 10 retrieved documents during inference.\n\nResults Table 1 reports the results of the original baselines, baselines augmented with the REPLUG, and baselines augmented with the REPLUG LSR. We observe that both REPLUG and REPLUG LSR significantly outperform the baselines. This demonstrates that simply adding a retrieval module to a frozen language model (i.e., the black-box setting) is effective at improving the performance of different sized language models on language modeling tasks. Furthermore, REPLUG LSR consistently performs better than REPLUG by a large margin. Specifically, REPLUG LSR results in 7.7% improvement over baselines compared to 4.7% improvement of REPLUG averaged over the 8 models. This indicates that further adapting the retriever to the target LM is beneficial. Baselines We consider two groups of strong previous models as baselines for comparisons. The first group of baselines is the state-of-the-art LLMs including Codex 1 (Chen et al., 2021b), PaLM (Chowdhery et al., 2022), and Flan-PaLM (Chung et al., 2022b). According to Chung et al. (2022b), these three models rank top-3 in the leaderboard of MMLU. The second group of baselines consists of retrieval-augmented language models. We only include Atlas (Izacard et al., 2022b) in this group, as no other retrievalaugmented LMs have been evaluated on the MMLU dataset. Atlas trains both the retriever and the language model, which we consider a white-box retrieval LM setting.\n\nOur model We add REPLUG and REPLUG LSR only to Codex because other models such as PaLM and Flan-PaLM are not accessible to the public. We use the test question as the query to retrieve 10 relevant documents from Wikipedia (2018, December) and prepend each retrieved document to the test question, resulting in 10 separate inputs. These inputs are then separately fed into the language models, and the output probabilities are ensemble together.\n\n1 Code-Davinci-002\n\nResults Table 2 presents the results from the baselines, REPLUG, and REPLUG LSR on the MMLU dataset. We observe that both the REPLUG and REPLUG LSR improve the original Codex model by 4.5% and 5.1%, respectively. In addition, REPLUG LSR largely outperforms the previous retrieval-augmented language model, Atlas, demonstrating the effectiveness of our black-box retrieval language model setting. Although our models slightly underperform Flan-PaLM, this is still a strong result because Flan-PaLM has three times more parameters. We would expect that the REPLUG LSR could further improve Flan-PaLM, if we had access to the model.\n\nAnother interesting observation is that the REPLUG LSR outperforms the original model by 1.9% even in the STEM category. This suggests that retrieval may improve a language model's problem-solving abilities.\n\n\nOpen Domain QA\n\nLastly, we conduct evaluation on two open-domain QA datasets: Natural Questions (NQ) (Kwiatkowski et al., 2019) and TriviaQA (Joshi et al., 2017). Baselines We compare our model with several state-ofthe-art baselines, both in a few-shot setting and with full training data. The first group of models consists of powerful large language models, including Chinchilla , PaLM (Chowdhery et al., 2022), and Codex. These models are all evaluated using in-context learning under the few-shot setting, with Chinchilla and PaLM evaluated using 64 shots, and Codex using 16 shots. The second group of models for comparison includes retrievalaugmented language models such as RETRO (Borgeaud et al., 2021), R2-D2 (Fajcik et al., 2021), and Atlas (Izacard et al., 2022b). All of these retrieval-augmented models are finetuned on the training data, either in a few-shot setting or with full training data. Specifically, Atlas is finetuned on 64 examples in the few-shot setting.\nDatasets\nOur model We add REPLUG and REPLUG LSR to Codex with Wikipedia (2018, December) as the retrieval corpus to evaluate the model in a 16-shot in context learning. Similar to the setting in language modeling and MMLU, we incorporate top-10 retrieved documents using our proposed ensemble method.\n\nResults As shown in Table 3, REPLUG LSR significantly improves the performance of the original Codex by 12.0% on NQ and 5.0% on TQA. It outperforms the previous best However, this result still lags behind the performance of retrieval-augmented language models fine-tuned on the full training data. This is likely due to the presence of nearduplicate test questions in the training set (e.g., Lewis et al. (2021) found that 32.5% of test questions overlap with the training sets in NQ).\n\n7. Analysis 7.1. REPLUG performance gain does not simply come from the ensembling effect\n\nThe core of our method design is the use of an ensemble method that combines output probabilities of different passes, in which each retrieved document is prepended separately to the input and fed into a language model. To study whether the gains come solely from the ensemble method, we compare our method to ensembling random documents. For this, we randomly sample several documents, concatenated each random document with the input, and ensemble the outputs of different runs (referred to as \"random\"). As shown in Figure 6, we evaluated the performance of GPT-3 Curie on Pile when augmented with random documents, documents retrieved by REPLUG, and documents retrieved by REPLUG LSR. We observed that ensembling random documents leads to worse performance, indicating that the performance gains of REPLUG do not solely come from the ensembling effect. Instead, ensembling the relevant documents is crucial for the success of REPLUG. Additionally, as more documents were ensembled, the performance of REPLUG and REPLUG LSR improved monotonically. However, a small number of documents (e.g., 10) was sufficient to achieve large performance gains. Original + RE-PLUG OPT (c) Figure 5. GPT-2, BLOOM and OPT models of varying sizes consistently benefit from REPLUG. The x-axis indicates the size of the language model and the y-axis is its perplexity on Wikitext-103.\n\n\nREPLUG is applicable to diverse language models\n\nHere we further study whether REPLUG could enhance diverse language model families that have been pre-trained using different data and methods. Specifically, we focus on three groups of language models with varying sizes: GPT-2 (117M, 345M, 774M, 1.5B parameters) (Brown et al., 2020a), OPT (125M, 350M, 1.3B, 2.7B, 6.7B, 13B, 30B, 66B) (Zhang et al., 2022b) and BLOOM (560M, 1.1B, 1.7B, 3B and 7B) (Scao et al., 2022). We evaluate each model on Wikitext-103 (Stephen et al., 2017) test data and report its perplexity. For comparison, we augment each model with REPLUG that adopts the ensemble method to incorporate top 10 retrieved documents. Following prior work (Khandelwal et al., 2020), we use Wikitext-103 training data as the retrieval corpus. Figure 5 shows the performance of different-sized language models with and without REPLUG. We observe that the performance gain brought by REPLUG stays consistent with model size. For example, OPT with 125M parameters achieves 6.9% perplexity improvement, while OPT with 66B parameters achieves 5.6% perplexity improvement. Additionally, REPLUG improves the perplexity of all the model families. This indicates that REPLUG is applicable to diverse language models with different sizes.\n\n\nQualitative Analysis: rare entities benefit from retrieval\n\nTo understand why the REPLUG improves language modeling performance, we conducted manual analysis of examples in which the REPLUG results in a decrease in perplexity. We find that REPLUG is more helpful when texts contain rare entities. Figure 6 shows a test context and its continuation from the Wikitext-103 test set. For REPLUG, we use the test context as a query to retrieve a relevant docu-ment from Wikitext-103 training data. We then compute the perplexity of the continuation using the original GPT-2 1.5B and its REPLUG enhanced version. After incorporating the retrieved document, the perplexity of the continuation improves by 11%. Among all tokens in the continuation, we found that REPLUG is most helpful for the rare entity name \"Li Bai\". This is likely because the original LM does not have sufficient information about this rare entity name. However, by incorporating the retrieved document, REPLUG was able to match the name with the relevant information in the retrieved document, resulting in better performance. Figure 6. Rare entities benefit from retrieval. After incorporating the retrieved document during inference, the entity \"Li Bai\" and the token \"greatest\" in the continuation show the most improvement in perplexity (15% for \"Li Bai\" and 5% for \"greatest\"). Other tokens' perplexity changes are within 5%.\n\n\nConclusion\n\nWe introduce REPLUG, a retrieval-augmented language modeling paradigm that treats the language model as a black box and augments it with a tuneable retrieval model. Our evaluation shows that REPLUG can be integrated with any existing language model to improve their performance on language modeling or downstream tasks. This work opens up new possibilities for integrating retrieval into largescale black-box language models and demonstrates even the state-of-the-art large-scale LMs could benefit from retrieval. However, REPLUG lacks interpretability as it is unclear when the model relies on retrieved knowledge or parametric knowledge. Future research could focus on developing more interpretable retrieval-augmented language models.\n\nFigure 2 .\n2REPLUG at inference ( \u00a73). Given an input context, REPLUG first retrieves a small set of relevant documents from an external corpus using a retriever ( \u00a73.1 Document Retrieval). Then it prepends each document separately to the input context and ensembles output probabilities from different passes ( \u00a73.2 Input Reformulation).\n\nFigure 3 .\n3REPLUG LSR training process ( \u00a74). The retriever is trained using the output of a frozen language model as supervision signals.\n\nFigure 4 .\n4Ensembling random documents does not result in improved performance. BPB of Curie augmented with different methods (random, REPLUG and REPLUG LSR) when varying the number of documents (i.e.; number of ensemble times.) model, Atlas, which was fine-tuned with 64 training examples, achieving a new state-of-the-art in the few-shot setting.\n\n\nTable 2. REPLUG and REPLUG LSR improves Codex by 4.5% and 5.1% respectively. Performance on MMLU broken down into 4 categories. The last column averages the performance over these categories. All models are evaluated based on 5-shot in-context learning with direct prompting.6.2. MMLU \n\nDatasets Massive Multi-task Language Understanding \n(MMLU (Hendrycks et al., 2021)) is a multiple choice QA \ndataset that covers exam questions from 57 tasks includ-\ning mathematics, computer science, law, US history and \netc. The 57 tasks are grouped into 4 categories: humani-\nties, STEM, social sciences and other. Following Chung \nModel \n# Parameters Original + REPLUG Gain % + REPLUG LSR Gain % \n\nGPT-2 \nSmall \n117M \n1.33 \n1.26 \n5.3 \n1.21 \n9.0 \nMedium \n345M \n1.20 \n1.14 \n5.0 \n1.11 \n7.5 \nLarge \n774M \n1.19 \n1.15 \n3.4 \n1.09 \n8.4 \nXL \n1.5B \n1.16 \n1.09 \n6.0 \n1.07 \n7.8 \n\nGPT-3 \nAda \n350M \n1.05 \n0.98 \n6.7 \n0.96 \n8.6 \n(black-box) Babbage \n1.3B \n0.95 \n0.90 \n5.3 \n0.88 \n7.4 \nCurie \n6.7B \n0.88 \n0.85 \n3.4 \n0.82 \n6.8 \nDavinci \n175B \n0.80 \n0.77 \n3.8 \n0.75 \n6.3 \n\nTable 1. Both REPLUG and REPLUG LSR consistently enhanced the performance of different language models. Bits per byte \n(BPB) of the Pile using GPT-3 and GPT-2 family models (Original) and their retrieval-augmented versions (+REPLUG and +REPLUG \nLSR. The gain % shows the relative improvement of our models compared to the original language model. \n\nModel \n# Parameters Humanities Social. STEM Other All \n\nCodex \n175B \n74.2 \n76.9 \n57.8 \n70.1 68.3 \nPaLM \n540B \n77.0 \n81.0 \n55.6 \n69.6 69.3 \nFlan-PaLM \n540B \n-\n-\n-\n-\n72.2 \n\nAtlas \n11B \n46.1 \n54.6 \n38.8 \n52.8 47.9 \n\nCodex + REPLUG \n175B \n76.0 \n79.7 \n58.8 \n72.1 71.4 \nCodex + REPLUG LSR 175B \n76.5 \n79.9 \n58.9 \n73.2 71.8 \n\net al. (2022a), we evaluate REPLUG in the 5-shot in-context \nlearning setting. \n\n\nSi et al. (2022) augment Codex with concatenation of 10 documents retrieved by contriever.\n\nImproving language models by retrieving from trillions of tokens. S Borgeaud, A Mensch, J Hoffmann, T Cai, E Rutherford, K Millican, G V D Driessche, J.-B Lespiau, B Damoc, A Clark, arXiv:2112.04426arXiv preprintBorgeaud, S., Mensch, A., Hoffmann, J., Cai, T., Ruther- ford, E., Millican, K., Driessche, G. v. d., Lespiau, J.-B., Damoc, B., Clark, A., et al. Improving language mod- els by retrieving from trillions of tokens. arXiv preprint arXiv:2112.04426, 2021.\n\nImproving language models by retrieving from trillions of tokens. S Borgeaud, A Mensch, J Hoffmann, T Cai, E Rutherford, K Millican, G B Van Den Driessche, J.-B Lespiau, B Damoc, A Clark, International Conference on Machine Learning. PMLRBorgeaud, S., Mensch, A., Hoffmann, J., Cai, T., Ruther- ford, E., Millican, K., Van Den Driessche, G. B., Lespiau, J.-B., Damoc, B., Clark, A., et al. Improving language models by retrieving from trillions of tokens. In Interna- tional Conference on Machine Learning, pp. 2206-2240. PMLR, 2022.\n\nLanguage models are few-shot learners. T Brown, B Mann, N Ryder, M Subbiah, J D Kaplan, P Dhariwal, A Neelakantan, P Shyam, G Sastry, A Askell, S Agarwal, A Herbert-Voss, G Krueger, T Henighan, R Child, A Ramesh, D Ziegler, J Wu, C Winter, C Hesse, M Chen, E Sigler, M Litwin, S Gray, B Chess, J Clark, C Berner, S Mccandlish, A Radford, I Sutskever, Amodei , D , Advances in Neural Information Processing Systems. Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M., and Lin, H.Curran Associates, Inc33Brown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever, I., and Amodei, D. Language models are few-shot learners. In Larochelle, H., Ranzato, M., Hadsell, R., Balcan, M., and Lin, H. (eds.), Advances in Neural Information Processing Systems, volume 33, pp. 1877-1901. Curran Associates, Inc., 2020a. URL https: //proceedings.neurips.cc/paper/2020/file/ 1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf.\n\nLanguage models are few-shot learners. T Brown, B Mann, N Ryder, M Subbiah, J D Kaplan, P Dhariwal, A Neelakantan, P Shyam, G Sastry, A Askell, S Agarwal, A Herbert-Voss, G Krueger, T Henighan, R Child, A Ramesh, D Ziegler, J Wu, C Winter, C Hesse, M Chen, E Sigler, M Litwin, S Gray, B Chess, J Clark, C Berner, S Mccandlish, A Radford, I Sutskever, Amodei , D , Proc. of NeurIPS. of NeurIPSBrown, T., Mann, B., Ryder, N., Subbiah, M., Kaplan, J. D., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D., Wu, J., Winter, C., Hesse, C., Chen, M., Sigler, E., Litwin, M., Gray, S., Chess, B., Clark, J., Berner, C., McCandlish, S., Radford, A., Sutskever, I., and Amodei, D. Language models are few-shot learners. In Proc. of NeurIPS, 2020b. URL https: //proceedings.neurips.cc/paper/2020/file/ 1457c0d6bfcb4967418bfb8ac142f64a-Paper.pdf.\n\n. M Chen, J Tworek, H Jun, Q Yuan, H P De Oliveira Pinto, J Kaplan, H Edwards, Y Burda, N Joseph, G Brockman, A Ray, R Puri, G Krueger, M Petrov, H Khlaaf, G Sastry, P Mishkin, B Chan, S Gray, N Ryder, M Pavlov, A Power, L Kaiser, M Bavarian, C Winter, P Tillet, F P Such, D Cummings, M Plappert, F Chantzis, E Barnes, A Herbert-Voss, W H Guss, A Nichol, A Paino, N Tezak, J Tang, I Babuschkin, S Balaji, S Jain, W Saunders, C Hesse, A N Carr, J Leike, J Achiam, V Misra, E Morikawa, A Radford, M Knight, M Brundage, M Murati, K Mayer, P Welinder, B Mc-Grew, D Amodei, S Mccandlish, I Sutskever, W Zaremba, Evaluating large language models trained on code. CoRR, abs/2107.03374, 2021a. URLChen, M., Tworek, J., Jun, H., Yuan, Q., de Oliveira Pinto, H. P., Kaplan, J., Edwards, H., Burda, Y., Joseph, N., Brockman, G., Ray, A., Puri, R., Krueger, G., Petrov, M., Khlaaf, H., Sastry, G., Mishkin, P., Chan, B., Gray, S., Ryder, N., Pavlov, M., Power, A., Kaiser, L., Bavar- ian, M., Winter, C., Tillet, P., Such, F. P., Cummings, D., Plappert, M., Chantzis, F., Barnes, E., Herbert- Voss, A., Guss, W. H., Nichol, A., Paino, A., Tezak, N., Tang, J., Babuschkin, I., Balaji, S., Jain, S., Saun- ders, W., Hesse, C., Carr, A. N., Leike, J., Achiam, J., Misra, V., Morikawa, E., Radford, A., Knight, M., Brundage, M., Murati, M., Mayer, K., Welinder, P., Mc- Grew, B., Amodei, D., McCandlish, S., Sutskever, I., and Zaremba, W. Evaluating large language models trained on code. CoRR, abs/2107.03374, 2021a. URL https://arxiv.org/abs/2107.03374.\n\n. M Chen, J Tworek, H Jun, Q Yuan, H P De Oliveira Pinto, J Kaplan, H Edwards, Y Burda, N Joseph, G Brockman, A Ray, R Puri, G Krueger, M Petrov, H Khlaaf, G Sastry, P Mishkin, B Chan, S Gray, N Ryder, M Pavlov, A Power, L Kaiser, M Bavarian, C Winter, P Tillet, F P Such, D Cummings, M Plappert, F Chantzis, E Barnes, A Herbert-Voss, W H Guss, A Nichol, A Paino, N Tezak, J Tang, I Babuschkin, S Balaji, S Jain, W Saunders, C Hesse, A N Carr, J Leike, J Achiam, V Misra, E Morikawa, A Radford, M Knight, M Brundage, M Murati, K Mayer, P Welinder, B Mc-Grew, D Amodei, S Mccandlish, I Sutskever, W Zaremba, Evaluating large language models trained on code. CoRR, abs/2107.03374, 2021b. URLChen, M., Tworek, J., Jun, H., Yuan, Q., de Oliveira Pinto, H. P., Kaplan, J., Edwards, H., Burda, Y., Joseph, N., Brockman, G., Ray, A., Puri, R., Krueger, G., Petrov, M., Khlaaf, H., Sastry, G., Mishkin, P., Chan, B., Gray, S., Ryder, N., Pavlov, M., Power, A., Kaiser, L., Bavar- ian, M., Winter, C., Tillet, P., Such, F. P., Cummings, D., Plappert, M., Chantzis, F., Barnes, E., Herbert- Voss, A., Guss, W. H., Nichol, A., Paino, A., Tezak, N., Tang, J., Babuschkin, I., Balaji, S., Jain, S., Saun- ders, W., Hesse, C., Carr, A. N., Leike, J., Achiam, J., Misra, V., Morikawa, E., Radford, A., Knight, M., Brundage, M., Murati, M., Mayer, K., Welinder, P., Mc- Grew, B., Amodei, D., McCandlish, S., Sutskever, I., and Zaremba, W. Evaluating large language models trained on code. CoRR, abs/2107.03374, 2021b. URL https://arxiv.org/abs/2107.03374.\n\nA Chowdhery, S Narang, J Devlin, M Bosma, G Mishra, A Roberts, P Barham, H W Chung, C Sutton, S Gehrmann, arXiv:2204.02311Scaling language modeling with pathways. arXiv preprintChowdhery, A., Narang, S., Devlin, J., Bosma, M., Mishra, G., Roberts, A., Barham, P., Chung, H. W., Sutton, C., Gehrmann, S., et al. Palm: Scaling language modeling with pathways. arXiv preprint arXiv:2204.02311, 2022.\n\nH W Chung, L Hou, S Longpre, B Zoph, Y Tay, W Fedus, E Li, X Wang, M Dehghani, S Brahma, arXiv:2210.11416Scaling instruction-finetuned language models. arXiv preprintChung, H. W., Hou, L., Longpre, S., Zoph, B., Tay, Y., Fedus, W., Li, E., Wang, X., Dehghani, M., Brahma, S., et al. Scaling instruction-finetuned language models. arXiv preprint arXiv:2210.11416, 2022a.\n\nH W Chung, L Hou, S Longpre, B Zoph, Y Tay, W Fedus, E Li, X Wang, M Dehghani, S Brahma, arXiv:2210.11416Scaling instruction-finetuned language models. arXiv preprintChung, H. W., Hou, L., Longpre, S., Zoph, B., Tay, Y., Fedus, W., Li, E., Wang, X., Dehghani, M., Brahma, S., et al. Scaling instruction-finetuned language models. arXiv preprint arXiv:2210.11416, 2022b.\n\nR2-D2: A modular baseline for open-domain question answering. M Fajcik, M Docekal, K Ondrej, P Smrz, 10.18653/v1/2021.findings-emnlp.73Findings of the Association for Computational Linguistics: EMNLP 2021. Punta Cana, Dominican RepublicAssociation for Computational LinguisticsFajcik, M., Docekal, M., Ondrej, K., and Smrz, P. R2- D2: A modular baseline for open-domain question an- swering. In Findings of the Association for Computa- tional Linguistics: EMNLP 2021, pp. 854-870, Punta Cana, Dominican Republic, November 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021. findings-emnlp.73. URL https://aclanthology.org/ 2021.findings-emnlp.73.\n\nThe Pile: An 800gb dataset of diverse text for language modeling. L Gao, S Biderman, S Black, L Golding, T Hoppe, C Foster, J Phang, H He, A Thite, N Nabeshima, S Presser, C ; Leahy, A Friesen, A Banino, T Weber, N R Ke, A P Badia, A Guez, M Mirza, P C Humphreys, K Konyushova, arXiv:2101.00027International Conference on Machine Learning. PMLRarXiv preprintRetrieval-augmented reinforcement learningGao, L., Biderman, S., Black, S., Golding, L., Hoppe, T., Foster, C., Phang, J., He, H., Thite, A., Nabeshima, N., Presser, S., and Leahy, C. The Pile: An 800gb dataset of diverse text for language modeling. arXiv preprint arXiv:2101.00027, 2020. REPLUG: Retrieval-Augmented Black-Box Language Models Goyal, A., Friesen, A., Banino, A., Weber, T., Ke, N. R., Badia, A. P., Guez, A., Mirza, M., Humphreys, P. C., Konyushova, K., et al. Retrieval-augmented reinforce- ment learning. In International Conference on Machine Learning, pp. 7740-7765. PMLR, 2022.\n\nRetrieval augmented language model pre-training. K Guu, K Lee, Z Tung, P Pasupat, Chang , M , International Conference on Machine Learning. PMLRGuu, K., Lee, K., Tung, Z., Pasupat, P., and Chang, M. Retrieval augmented language model pre-training. In International Conference on Machine Learning, pp. 3929- 3938. PMLR, 2020.\n\nMeasuring massive multitask language understanding. D Hendrycks, C Burns, S Basart, A Zou, M Mazeika, D Song, J Steinhardt, International Conference on Learning Representations. Hendrycks, D., Burns, C., Basart, S., Zou, A., Mazeika, M., Song, D., and Steinhardt, J. Measuring massive multitask language understanding. In International Con- ference on Learning Representations, 2021. URL https: //openreview.net/forum?id=d7KBjmI3GmQ.\n\nTraining compute-optimal large language models. J Hoffmann, S Borgeaud, A Mensch, E Buchatskaya, T Cai, E Rutherford, D D L Casas, L A Hendricks, J Welbl, A Clark, arXiv:2203.15556arXiv preprintHoffmann, J., Borgeaud, S., Mensch, A., Buchatskaya, E., Cai, T., Rutherford, E., Casas, D. d. L., Hendricks, L. A., Welbl, J., Clark, A., et al. Training compute-optimal large language models. arXiv preprint arXiv:2203.15556, 2022.\n\nY Hu, H Hua, Z Yang, W Shi, N A Smith, J Luo, Promptcap, arXiv:2211.09699Prompt-guided task-aware image captioning. arXiv preprintHu, Y., Hua, H., Yang, Z., Shi, W., Smith, N. A., and Luo, J. Promptcap: Prompt-guided task-aware image captioning. arXiv preprint arXiv:2211.09699, 2022.\n\nLeveraging passage retrieval with generative models for open domain question answering. G Izacard, E Grave, 10.18653/v1/2021.eacl-main.74Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume. the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main VolumeAssociation for Computational LinguisticsIzacard, G. and Grave, E. Leveraging passage retrieval with generative models for open domain question an- swering. In Proceedings of the 16th Conference of the European Chapter of the Association for Compu- tational Linguistics: Main Volume, pp. 874-880, On- line, April 2021a. Association for Computational Lin- guistics. doi: 10.18653/v1/2021.eacl-main.74. URL https://aclanthology.org/2021.eacl-main.74.\n\nLeveraging passage retrieval with generative models for open domain question answering. G Izacard, E Grave, Proc. of EACL. of EACLIzacard, G. and Grave, E. Leveraging passage retrieval with generative models for open domain question answering. In Proc. of EACL, 2021b. URL https://arxiv.org/ abs/2007.01282.\n\nUnsupervised dense information retrieval with contrastive learning. G Izacard, M Caron, L Hosseini, S Riedel, P Bojanowski, A Joulin, E Grave, Transactions on Machine Learning Research. Izacard, G., Caron, M., Hosseini, L., Riedel, S., Bojanowski, P., Joulin, A., and Grave, E. Unsupervised dense in- formation retrieval with contrastive learning. Trans- actions on Machine Learning Research, 2022a. URL https://openreview.net/forum?id=jKN1pXi7b0.\n\nFew-shot learning with retrieval augmented language models. G Izacard, P Lewis, M Lomeli, L Hosseini, F Petroni, T Schick, J Dwivedi-Yu, A Joulin, S Riedel, E Grave, arXiv:2208.03299arXiv preprintIzacard, G., Lewis, P., Lomeli, M., Hosseini, L., Petroni, F., Schick, T., Dwivedi-Yu, J., Joulin, A., Riedel, S., and Grave, E. Few-shot learning with retrieval augmented lan- guage models. arXiv preprint arXiv:2208.03299, 2022b.\n\nBillion-scale similarity search with gpus. J Johnson, M Douze, H J\u00e9gou, IEEE Transactions on Big Data. 73Johnson, J., Douze, M., and J\u00e9gou, H. Billion-scale similar- ity search with gpus. IEEE Transactions on Big Data, 7 (3):535-547, 2019.\n\nTrivi-aQA: A large scale distantly supervised challenge dataset for reading comprehension. M Joshi, E Choi, D Weld, L Zettlemoyer, 10.18653/v1/P17-1147Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics. the 55th Annual Meeting of the Association for Computational LinguisticsVancouver, Canada1Association for Computational LinguisticsJoshi, M., Choi, E., Weld, D., and Zettlemoyer, L. Trivi- aQA: A large scale distantly supervised challenge dataset for reading comprehension. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pp. 1601-1611, Vancouver, Canada, July 2017. Association for Compu- tational Linguistics. doi: 10.18653/v1/P17-1147. URL https://aclanthology.org/P17-1147.\n\nDense passage retrieval for open-domain question answering. V Karpukhin, B Oguz, S Min, P Lewis, L Wu, S Edunov, D Chen, W Yih, 10.18653/v1/2020.emnlp-main.550Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)OnlineAssociation for Computational LinguisticsKarpukhin, V., Oguz, B., Min, S., Lewis, P., Wu, L., Edunov, S., Chen, D., and Yih, W.-t. Dense passage retrieval for open-domain question answering. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 6769-6781, Online, November 2020a. Association for Computational Lin- guistics. doi: 10.18653/v1/2020.emnlp-main.550. URL https://aclanthology.org/2020.emnlp-main.550.\n\nDense passage retrieval for open-domain question answering. V Karpukhin, B Oguz, S Min, P Lewis, L Wu, S Edunov, D Chen, W Yih, Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)Karpukhin, V., Oguz, B., Min, S., Lewis, P., Wu, L., Edunov, S., Chen, D., and Yih, W.-t. Dense passage retrieval for open-domain question answering. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), pp. 6769-6781, 2020b.\n\nGeneralization through memorization: Nearest neighbor language models. U Khandelwal, O Levy, D Jurafsky, L Zettlemoyer, Lewis , M , International Conference on Learning Representations. Khandelwal, U., Levy, O., Jurafsky, D., Zettlemoyer, L., and Lewis, M. Generalization through memorization: Nearest neighbor language models. In International Conference on Learning Representations, 2020. URL https://openreview.net/forum?id=HklBjCEKvH.\n\nDemonstrate-search-predict: Composing retrieval and language models for knowledgeintensive nlp. O Khattab, K Santhanam, X L Li, D Hall, P Liang, C Potts, M Zaharia, arXiv:2212.14024arXiv preprintKhattab, O., Santhanam, K., Li, X. L., Hall, D., Liang, P., Potts, C., and Zaharia, M. Demonstrate-search-predict: Composing retrieval and language models for knowledge- intensive nlp. arXiv preprint arXiv:2212.14024, 2022.\n\nA method for stochastic optimization. D P Kingma, J Ba, Adam, ICLR (Poster). Kingma, D. P. and Ba, J. Adam: A method for stochastic optimization. In ICLR (Poster), 2015.\n\nT Kwiatkowski, J Palomaki, O Redfield, M Collins, A Parikh, C Alberti, D Epstein, I Polosukhin, J Devlin, K Lee, K Toutanova, L Jones, M Kelcey, M.-W Chang, A M Dai, J Uszkoreit, Q Le, S Petrov, 10.1162/tacl_a_00276Natural questions: A benchmark for question answering research. Transactions of the Association for Computational Linguistics. 7Kwiatkowski, T., Palomaki, J., Redfield, O., Collins, M., Parikh, A., Alberti, C., Epstein, D., Polosukhin, I., Devlin, J., Lee, K., Toutanova, K., Jones, L., Kelcey, M., Chang, M.-W., Dai, A. M., Uszkoreit, J., Le, Q., and Petrov, S. Natural questions: A benchmark for question answering research. Transactions of the Association for Computa- tional Linguistics, 7:452-466, 2019. doi: 10.1162/tacl_a_ 00276. URL https://aclanthology.org/Q19-1026.\n\nRetrieval-augmented generation for knowledge-intensive nlp tasks. P Lewis, E Perez, A Piktus, F Petroni, V Karpukhin, N Goyal, H K\u00fcttler, M Lewis, W.-T Yih, T Rockt\u00e4schel, S Riedel, D Kiela, Lewis, P., Perez, E., Piktus, A., Petroni, F., Karpukhin, V., Goyal, N., K\u00fcttler, H., Lewis, M., Yih, W.-t., Rockt\u00e4schel, T., Riedel, S., and Kiela, D. Retrieval-augmented gen- eration for knowledge-intensive nlp tasks, 2020. URL https://arxiv.org/abs/2005.11401.\n\nQuestion and answer test-train overlap in open-domain question answering datasets. P Lewis, P Stenetorp, S Riedel, Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume. the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main VolumeLewis, P., Stenetorp, P., and Riedel, S. Question and an- swer test-train overlap in open-domain question answer- ing datasets. In Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume, pp. 1000-1008, 2021.\n\nWhen not to trust language models: Investigating effectiveness and limitations of parametric and nonparametric memories. A Mallen, A Asai, V Zhong, R Das, H Hajishirzi, D Khashabi, arXiv:2212.10511arXiv preprintMallen, A., Asai, A., Zhong, V., Das, R., Hajishirzi, H., and Khashabi, D. When not to trust language models: Investi- gating effectiveness and limitations of parametric and non- parametric memories. arXiv preprint arXiv:2212.10511, 2022.\n\nS Min, W Shi, M Lewis, X Chen, W.-T Yih, H Hajishirzi, L Zettlemoyer, arXiv:2212.01349Nonparametric masked language modeling. arXiv preprintMin, S., Shi, W., Lewis, M., Chen, X., Yih, W.-t., Hajishirzi, H., and Zettlemoyer, L. Nonparametric masked language modeling. arXiv preprint arXiv:2212.01349, 2022.\n\nLarge dual encoders are generalizable retrievers. J Ni, C Qu, J Lu, Z Dai, G H \u00c1brego, J Ma, V Y Zhao, Y Luan, K B Hall, M Chang, Yang , Y , Ni, J., Qu, C., Lu, J., Dai, Z., \u00c1brego, G. H., Ma, J., Zhao, V. Y., Luan, Y., Hall, K. B., Chang, M., and Yang, Y. Large dual encoders are generalizable retrievers, 2021. URL https://arxiv.org/abs/2112.07899.\n\nRocketQA: An optimized training approach to dense passage retrieval for open-domain question answering. Y Qu, Y Ding, J Liu, K Liu, R Ren, W X Zhao, D Dong, H Wu, Wang , H , 10.18653/v1/2021.naacl-main.466Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesOnlineAssociation for Computational LinguisticsQu, Y., Ding, Y., Liu, J., Liu, K., Ren, R., Zhao, W. X., Dong, D., Wu, H., and Wang, H. RocketQA: An opti- mized training approach to dense passage retrieval for open-domain question answering. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Hu- man Language Technologies, pp. 5835-5847, Online, June 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.naacl-main.466. URL https: //aclanthology.org/2021.naacl-main.466.\n\nThe probabilistic relevance framework: Bm25 and beyond. S Robertson, H Zaragoza, Foundations and Trends\u00ae in Information Retrieval. 34Robertson, S., Zaragoza, H., et al. The probabilistic rele- vance framework: Bm25 and beyond. Foundations and Trends\u00ae in Information Retrieval, 3(4):333-389, 2009.\n\nLearning to retrieve prompts for in-context learning. O Rubin, J Herzig, J Berant, Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesRubin, O., Herzig, J., and Berant, J. Learning to retrieve prompts for in-context learning. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Lan- guage Technologies, pp. 2655-2671, 2022.\n\n. D S Sachan, M Lewis, D Yogatama, L Zettlemoyer, J Pineau, M Zaheer, arXiv:2206.10658arXiv preprintQuestions are all you need to train a dense passage retrieverSachan, D. S., Lewis, M., Yogatama, D., Zettlemoyer, L., Pineau, J., and Zaheer, M. Questions are all you need to train a dense passage retriever. arXiv preprint arXiv:2206.10658, 2022.\n\nT L Scao, A Fan, C Akiki, E Pavlick, S Ili\u0107, D Hesslow, R Castagn\u00e9, A S Luccioni, F Yvon, M Gall\u00e9, arXiv:2211.05100A 176b-parameter open-access multilingual language model. arXiv preprintScao, T. L., Fan, A., Akiki, C., Pavlick, E., Ili\u0107, S., Hesslow, D., Castagn\u00e9, R., Luccioni, A. S., Yvon, F., Gall\u00e9, M., et al. Bloom: A 176b-parameter open-access multilingual language model. arXiv preprint arXiv:2211.05100, 2022.\n\nNearest neighbor zero-shot inference. W Shi, J Michael, S Gururangan, L Zettlemoyer, Shi, W., Michael, J., Gururangan, S., and Zettlemoyer, L. Nearest neighbor zero-shot inference. 2022.\n\nC Si, Z Gan, Z Yang, S Wang, J Wang, J Boyd-Graber, Wang , L , arXiv:2210.09150Prompting gpt-3 to be reliable. arXiv preprintSi, C., Gan, Z., Yang, Z., Wang, S., Wang, J., Boyd-Graber, J., and Wang, L. Prompting gpt-3 to be reliable. arXiv preprint arXiv:2210.09150, 2022.\n\nPrompting gpt-3 to be reliable. C Si, Z Gan, Z Yang, S Wang, J Wang, J Boyd-Graber, Wang , L , Proc. of ICLR. of ICLRSi, C., Gan, Z., Yang, Z., Wang, S., Wang, J., Boyd-Graber, J., and Wang, L. Prompting gpt-3 to be reliable. In Proc. of ICLR, 2023. URL https://openreview.net/ forum?id=98p5x51L5af.\n\nPointer sentinel mixture models. M Stephen, X Caiming, B James, R Socher, 5th International Conference on Learning Representations. Toulon, FranceConference Track ProceedingsStephen, M., Caiming, X., James, B., and Socher, R. Pointer sentinel mixture models. In 5th International Conference on Learning Representations, ICLR 2017, Toulon, France, April 24-26, 2017, Conference Track Proceedings, 2017.\n\nH Su, J Kasai, Y Wang, Y Hu, M Ostendorf, W.-T Yih, N A Smith, L Zettlemoyer, T Yu, arXiv:2212.09741One embedder, any task: Instruction-finetuned text embeddings. arXiv preprintSu, H., Kasai, J., Wang, Y., Hu, Y., Ostendorf, M., Yih, W.-t., Smith, N. A., Zettlemoyer, L., Yu, T., et al. One embedder, any task: Instruction-finetuned text embeddings. arXiv preprint arXiv:2212.09741, 2022.\n\nYuan 1.0: Large-scale pre-trained language model in zero-shot and few-shot learning. S Wu, X Zhao, T Yu, R Zhang, C Shen, H Liu, F Li, H Zhu, J Luo, L Xu, arXiv:2110.04725arXiv preprintWu, S., Zhao, X., Yu, T., Zhang, R., Shen, C., Liu, H., Li, F., Zhu, H., Luo, J., Xu, L., et al. Yuan 1.0: Large-scale pre-trained language model in zero-shot and few-shot learning. arXiv preprint arXiv:2110.04725, 2021.\n\nM Yasunaga, A Aghajanyan, W Shi, R James, J Leskovec, P Liang, M Lewis, L Zettlemoyer, W Yih, arXiv:2211.12561Retrieval-augmented multimodal language modeling. arXiv preprintYasunaga, M., Aghajanyan, A., Shi, W., James, R., Leskovec, J., Liang, P., Lewis, M., Zettlemoyer, L., and Yih, W.-t. Retrieval-augmented multimodal language modeling. arXiv preprint arXiv:2211.12561, 2022.\n\nA gentle introduction to 8-bit matrix multiplication. Younes Belkda, T D , Younes Belkda, T. D. A gentle introduction to 8-bit matrix multiplication, 2022. URL https://huggingface.co/ blog/hf-bitsandbytes-integration.\n\nRetrieval-augmented generation across heterogeneous knowledge. W Yu, 10.18653/v1/2022.naacl-srw.7Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Student Research Workshop. the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Student Research WorkshopHybrid: Seattle, Washington + OnlineAssociation for Computational LinguisticsYu, W. Retrieval-augmented generation across heteroge- neous knowledge. In Proceedings of the 2022 Confer- ence of the North American Chapter of the Association for Computational Linguistics: Human Language Technolo- gies: Student Research Workshop, pp. 52-58, Hybrid: Seattle, Washington + Online, July 2022. Association for Computational Linguistics. doi: 10.18653/v1/2022. naacl-srw.7. URL https://aclanthology.org/2022. naacl-srw.7.\n\nGenerate rather than retrieve: Large language models are strong context generators. W Yu, D Iter, S Wang, Y Xu, M Ju, S Sanyal, C Zhu, M Zeng, M Jiang, Yu, W., Iter, D., Wang, S., Xu, Y., Ju, M., Sanyal, S., Zhu, C., Zeng, M., and Jiang, M. Generate rather than retrieve: Large language models are strong context generators.\n\nDemocratizing access to large-scale language models with opt-175b. S Zhang, M Diab, L Zettlemoyer, Meta AI. Zhang, S., Diab, M., and Zettlemoyer, L. Democratizing ac- cess to large-scale language models with opt-175b. Meta AI, 2022a.\n\nS Zhang, S Roller, N Goyal, M Artetxe, M Chen, S Chen, C Dewan, M Diab, X Li, X V Lin, arXiv:2205.01068Open pre-trained transformer language models. arXiv preprintZhang, S., Roller, S., Goyal, N., Artetxe, M., Chen, M., Chen, S., Dewan, C., Diab, M., Li, X., Lin, X. V., et al. Opt: Open pre-trained transformer language models. arXiv preprint arXiv:2205.01068, 2022b.\n\nREPLUG: Retrieval-Augmented Black-Box Language Models Knowledge: Arctic Ocean. Although over half of Europe's original forests disappeared through the centuries of deforestation, Europe still has over one quarter of its land area as forest, such as the broadleaf and mixed forests, taiga of Scandinavia and Russia, mixed rainforests of the Caucasus and the Cork oak forests in the western Mediterranean. During recent times, deforestation has been slowed and many trees have been planted. However, in many cases monoculture plantations of conifers have replaced the original mixed natural forest, because these grow quicker. The plantations now cover vast areas of land, but offer poorer habitats for many European Question: As of. Z Zhong, T Lei, Chen , D , Empirical Methods in Natural Language Processing. 2022Training language models with memory augmentation. since 1990 forests have in Europe and have in Africa and the AmericasZhong, Z., Lei, T., and Chen, D. Training language models with memory augmentation. In Empirical Methods in Natural Language Processing (EMNLP), 2022. REPLUG: Retrieval-Augmented Black-Box Language Models Knowledge: Arctic Ocean. Although over half of Europe's original forests disappeared through the centuries of deforestation, Europe still has over one quarter of its land area as forest, such as the broadleaf and mixed forests, taiga of Scandinavia and Russia, mixed rainforests of the Caucasus and the Cork oak forests in the western Mediterranean. During recent times, deforestation has been slowed and many trees have been planted. However, in many cases monoculture plantations of conifers have replaced the original mixed natural forest, because these grow quicker. The plantations now cover vast areas of land, but offer poorer habitats for many European Question: As of 2015, since 1990 forests have in Europe and have in Africa and the Americas.\n\nAccording to recent polls, 56% of those age 18 to 29 favor gay marriage, 68% state environmental protection to be as important as job creation, 52% \"think immigrants\u015btrengthen the country with their hard work and talents. 62% favor a \"tax financed, government-administrated universal health care\" program and 74% \"say\u1e55eople\u015b will\u015bhould have more influence on U.S. laws than the Bible. compared to 37%, 49%, 38%, 47% and 58% among the Question: As of 2019, about what percentage of Americans agree that the state is run for the benefit of all the people? A. 31% B. 46% C. 61% D. 76% Answer: B ..A. \"increased, increased\" B. \"increased, decreased\" C. \"decreased, increased\" D. \"decreased, decreased\" Answer: B Knowledge: Over the past decades, the political outlook of Americans has become more progressive, with those below the age of thirty being considerably more liberal than the overall population. According to recent polls, 56% of those age 18 to 29 favor gay marriage, 68% state environmental protection to be as important as job creation, 52% \"think immigrants\u015btrengthen the country with their hard work and talents,\" 62% favor a \"tax financed, government-administrated universal health care\" program and 74% \"say\u1e55eople\u015b will\u015bhould have more influence on U.S. laws than the Bible, compared to 37%, 49%, 38%, 47% and 58% among the Question: As of 2019, about what percentage of Americans agree that the state is run for the benefit of all the people? A. 31% B. 46% C. 61% D. 76% Answer: B ...\n\nBy the end of 2017, cumulative installed PV capacity reached over 50 GW with nearly 8 GW installed in the year 2017. The country is a leading manufacturer of solar panels and is in the top 4 ranking for countries Question: Which of the following countries generated the most total energy from solar sources in 2019? A. China B. United States C. Germany D. Japan Table 4. Prompt for MMLU Knowledge: received 122,000 buys (excluding WWE Network views), down from the previous year\u015b 199,000 buys. The event is named after the Money In The Bank ladder match, in which multiple wrestlers use ladders to retrieve a briefcase hanging above the ring. The winner is guaranteed a match for the WWE World Heavyweight Championship at a time of their choosing within the next year. On the June 2 episode of \"Raw. Knowledge: last week at a United Nations climate meeting in Germany, China and India should easily exceed the targets they set for themselves in the 2015 Paris Agreement. London, England on; Hollywood, CaliforniaThe stream was broadcast onto YouTube. A sing along version of the film released in over 1,200 US theaters nationwide on April. The film was re-released in Question: When does beaty and the beast take place Answer: Rococo-era ..Knowledge: last week at a United Nations climate meeting in Germany, China and India should easily exceed the targets they set for themselves in the 2015 Paris Agreement... India is now expected to obtain 40 percent of its electricity from non-fossil fuel sources by 2022, eight years ahead of schedule.\" Solar power in Japan has been expanding since the late 1990s. By the end of 2017, cumulative installed PV capacity reached over 50 GW with nearly 8 GW installed in the year 2017. The country is a leading manufacturer of solar panels and is in the top 4 ranking for countries Question: Which of the following countries generated the most total energy from solar sources in 2019? A. China B. United States C. Germany D. Japan Table 4. Prompt for MMLU Knowledge: received 122,000 buys (excluding WWE Network views), down from the previous year\u015b 199,000 buys. The event is named after the Money In The Bank ladder match, in which multiple wrestlers use ladders to retrieve a briefcase hanging above the ring. The winner is guaranteed a match for the WWE World Heavyweight Championship at a time of their choosing within the next year. On the June 2 episode of \"Raw\", Alberto Del Rio qualified for the match by defeating Dolph Ziggler. The following week, following Daniel Bryan being stripped of his WWE World Championship due to injury, Stephanie McMahon changed the Question: Who won the mens money in the bank match? Answer: Braun Strowman Knowledge: in 3D on March 17, 2017. The first official presentation of the film took place at Disney\u015b three-day D23 Expo in August 2015. The world premiere of \"Beauty and the Beast\" took place at Spencer House in London, England on February 23, 2017; and the film later premiered at the El Capitan Theatre in Hollywood, California, on March 2, 2017. The stream was broadcast onto YouTube. A sing along version of the film released in over 1,200 US theaters nationwide on April 7, 2017. The United Kingdom received the same version on April 21, 2017. The film was re-released in Question: When does beaty and the beast take place Answer: Rococo-era ...\n\nLove Yourself\" features an electric guitar and a brief flurry of trumpets as its main instrumentation. During the song, Bieber uses a husky tone in the lower registers. Lyrically, the song is a kiss-off to a narcissistic ex-lover who did Question: love yourself. Love Yourself\" is a song recorded by Canadian singer Justin Bieber for his fourth studio album. The song was released first as a promotional single on November 8, 2015, and later was released as the album\u015b third single. by justin bieber is about who Table 5. Prompt for open-domain QAKnowledge: Love Yourself \"Love Yourself\" is a song recorded by Canadian singer Justin Bieber for his fourth studio album \"Purpose\" (2015). The song was released first as a promotional single on November 8, 2015, and later was released as the album\u015b third single. It was written by Ed Sheeran, Benny Blanco and Bieber, and produced by Blanco. An acoustic pop song, \"Love Yourself\" features an electric guitar and a brief flurry of trumpets as its main instrumentation. During the song, Bieber uses a husky tone in the lower registers. Lyrically, the song is a kiss-off to a narcissistic ex-lover who did Question: love yourself by justin bieber is about who Table 5. Prompt for open-domain QA\n", "annotations": {"author": "[{\"end\":68,\"start\":57},{\"end\":79,\"start\":69},{\"end\":99,\"start\":80},{\"end\":112,\"start\":100},{\"end\":124,\"start\":113},{\"end\":136,\"start\":125},{\"end\":154,\"start\":137},{\"end\":167,\"start\":155}]", "publisher": null, "author_last_name": "[{\"end\":67,\"start\":64},{\"end\":78,\"start\":75},{\"end\":98,\"start\":90},{\"end\":111,\"start\":108},{\"end\":123,\"start\":118},{\"end\":135,\"start\":130},{\"end\":153,\"start\":142},{\"end\":166,\"start\":163}]", "author_first_name": "[{\"end\":63,\"start\":57},{\"end\":74,\"start\":69},{\"end\":89,\"start\":80},{\"end\":107,\"start\":100},{\"end\":117,\"start\":113},{\"end\":129,\"start\":125},{\"end\":141,\"start\":137},{\"end\":162,\"start\":155}]", "author_affiliation": null, "title": "[{\"end\":54,\"start\":1},{\"end\":221,\"start\":168}]", "venue": null, "abstract": "[{\"end\":1064,\"start\":223}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b2\"},\"end\":1144,\"start\":1123},{\"end\":1175,\"start\":1155},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":1589,\"start\":1564},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":1611,\"start\":1589},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":1633,\"start\":1611},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":1655,\"start\":1633},{\"end\":1936,\"start\":1928},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":2316,\"start\":2294},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":2368,\"start\":2343},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":4145,\"start\":4121},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":4191,\"start\":4165},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":4210,\"start\":4191},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":5495,\"start\":5474},{\"end\":5523,\"start\":5503},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":5787,\"start\":5766},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":5822,\"start\":5803},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":6157,\"start\":6132},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":6179,\"start\":6157},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":6188,\"start\":6179},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":6210,\"start\":6188},{\"end\":6229,\"start\":6210},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":6912,\"start\":6894},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":6934,\"start\":6912},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":6958,\"start\":6934},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":7016,\"start\":6994},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":7032,\"start\":7016},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":7358,\"start\":7348},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":7380,\"start\":7358},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":7430,\"start\":7405},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":7452,\"start\":7430},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":7469,\"start\":7452},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":7488,\"start\":7469},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":7532,\"start\":7509},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":7965,\"start\":7940},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":7983,\"start\":7965},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":8473,\"start\":8452},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":8489,\"start\":8473},{\"end\":8505,\"start\":8489},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":8526,\"start\":8505},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":9601,\"start\":9578},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":9617,\"start\":9601},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":10401,\"start\":10380},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":12045,\"start\":12020},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":12067,\"start\":12045},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":12083,\"start\":12067},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":12313,\"start\":12293},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":14841,\"start\":14824},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":15372,\"start\":15347},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":15388,\"start\":15372},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":15423,\"start\":15399},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":15495,\"start\":15472},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":15541,\"start\":15519},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":15728,\"start\":15705},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":15770,\"start\":15749},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":15934,\"start\":15916},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":16540,\"start\":16518},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":16793,\"start\":16774},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":17320,\"start\":17303},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":18056,\"start\":18038},{\"end\":19217,\"start\":19197},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":19248,\"start\":19224},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":19285,\"start\":19264},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":19320,\"start\":19300},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":19504,\"start\":19481},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":21139,\"start\":21113},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":21173,\"start\":21153},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":21424,\"start\":21400},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":21722,\"start\":21699},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":21751,\"start\":21730},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":21786,\"start\":21763},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":22707,\"start\":22688},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":24577,\"start\":24556},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":24650,\"start\":24629},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":24710,\"start\":24691},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":24773,\"start\":24751},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":30324,\"start\":30308}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":28018,\"start\":27679},{\"attributes\":{\"id\":\"fig_1\"},\"end\":28159,\"start\":28019},{\"attributes\":{\"id\":\"fig_2\"},\"end\":28510,\"start\":28160},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":30307,\"start\":28511}]", "paragraph": "[{\"end\":2588,\"start\":1080},{\"end\":3464,\"start\":2590},{\"end\":3970,\"start\":3466},{\"end\":4787,\"start\":3972},{\"end\":4936,\"start\":4789},{\"end\":5135,\"start\":4938},{\"end\":5365,\"start\":5137},{\"end\":6669,\"start\":5397},{\"end\":8874,\"start\":6700},{\"end\":9082,\"start\":8885},{\"end\":9396,\"start\":9084},{\"end\":10128,\"start\":9419},{\"end\":10276,\"start\":10158},{\"end\":10425,\"start\":10278},{\"end\":11369,\"start\":10449},{\"end\":11571,\"start\":11417},{\"end\":11909,\"start\":11606},{\"end\":12279,\"start\":11954},{\"end\":13008,\"start\":12281},{\"end\":13244,\"start\":13043},{\"end\":13604,\"start\":13270},{\"end\":14032,\"start\":13632},{\"end\":14121,\"start\":14087},{\"end\":14382,\"start\":14139},{\"end\":14605,\"start\":14432},{\"end\":15067,\"start\":14652},{\"end\":15289,\"start\":15086},{\"end\":15620,\"start\":15300},{\"end\":15822,\"start\":15635},{\"end\":16365,\"start\":15824},{\"end\":16977,\"start\":16367},{\"end\":17089,\"start\":16993},{\"end\":17263,\"start\":17091},{\"end\":17553,\"start\":17285},{\"end\":18282,\"start\":17555},{\"end\":19703,\"start\":18284},{\"end\":20149,\"start\":19705},{\"end\":20169,\"start\":20151},{\"end\":20800,\"start\":20171},{\"end\":21009,\"start\":20802},{\"end\":21993,\"start\":21028},{\"end\":22294,\"start\":22003},{\"end\":22781,\"start\":22296},{\"end\":22871,\"start\":22783},{\"end\":24240,\"start\":22873},{\"end\":25528,\"start\":24292},{\"end\":26926,\"start\":25591},{\"end\":27678,\"start\":26941}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":10157,\"start\":10129},{\"attributes\":{\"id\":\"formula_1\"},\"end\":11416,\"start\":11370},{\"attributes\":{\"id\":\"formula_2\"},\"end\":11605,\"start\":11572},{\"attributes\":{\"id\":\"formula_3\"},\"end\":13269,\"start\":13245},{\"attributes\":{\"id\":\"formula_4\"},\"end\":14086,\"start\":14033},{\"attributes\":{\"id\":\"formula_5\"},\"end\":14431,\"start\":14383},{\"attributes\":{\"id\":\"formula_6\"},\"end\":22002,\"start\":21994}]", "table_ref": "[{\"end\":18299,\"start\":18292},{\"end\":20186,\"start\":20179},{\"end\":22323,\"start\":22316}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":1078,\"start\":1066},{\"attributes\":{\"n\":\"2.\"},\"end\":5395,\"start\":5368},{\"end\":6698,\"start\":6672},{\"attributes\":{\"n\":\"3.\"},\"end\":8883,\"start\":8877},{\"attributes\":{\"n\":\"3.1.\"},\"end\":9417,\"start\":9399},{\"attributes\":{\"n\":\"3.2.\"},\"end\":10447,\"start\":10428},{\"attributes\":{\"n\":\"4.\"},\"end\":11952,\"start\":11912},{\"attributes\":{\"n\":\"4.1.\"},\"end\":13041,\"start\":13011},{\"attributes\":{\"n\":\"4.2.\"},\"end\":13630,\"start\":13607},{\"attributes\":{\"n\":\"4.3.\"},\"end\":14137,\"start\":14124},{\"attributes\":{\"n\":\"4.4.\"},\"end\":14650,\"start\":14608},{\"attributes\":{\"n\":\"5.\"},\"end\":15084,\"start\":15070},{\"attributes\":{\"n\":\"5.1.\"},\"end\":15298,\"start\":15292},{\"attributes\":{\"n\":\"5.2.\"},\"end\":15633,\"start\":15623},{\"attributes\":{\"n\":\"6.\"},\"end\":16991,\"start\":16980},{\"attributes\":{\"n\":\"6.1.\"},\"end\":17283,\"start\":17266},{\"attributes\":{\"n\":\"6.3.\"},\"end\":21026,\"start\":21012},{\"attributes\":{\"n\":\"7.2.\"},\"end\":24290,\"start\":24243},{\"attributes\":{\"n\":\"7.3.\"},\"end\":25589,\"start\":25531},{\"attributes\":{\"n\":\"8.\"},\"end\":26939,\"start\":26929},{\"end\":27690,\"start\":27680},{\"end\":28030,\"start\":28020},{\"end\":28171,\"start\":28161}]", "table": "[{\"end\":30307,\"start\":28788}]", "figure_caption": "[{\"end\":28018,\"start\":27692},{\"end\":28159,\"start\":28032},{\"end\":28510,\"start\":28173},{\"end\":28788,\"start\":28513}]", "figure_ref": "[{\"end\":3366,\"start\":3358},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":9104,\"start\":9096},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":12606,\"start\":12598},{\"end\":23400,\"start\":23392},{\"end\":24058,\"start\":24050},{\"end\":25051,\"start\":25043},{\"end\":25836,\"start\":25828},{\"end\":26631,\"start\":26623}]", "bib_author_first_name": "[{\"end\":30467,\"start\":30466},{\"end\":30479,\"start\":30478},{\"end\":30489,\"start\":30488},{\"end\":30501,\"start\":30500},{\"end\":30508,\"start\":30507},{\"end\":30522,\"start\":30521},{\"end\":30534,\"start\":30533},{\"end\":30538,\"start\":30535},{\"end\":30554,\"start\":30550},{\"end\":30565,\"start\":30564},{\"end\":30574,\"start\":30573},{\"end\":30934,\"start\":30933},{\"end\":30946,\"start\":30945},{\"end\":30956,\"start\":30955},{\"end\":30968,\"start\":30967},{\"end\":30975,\"start\":30974},{\"end\":30989,\"start\":30988},{\"end\":31001,\"start\":31000},{\"end\":31003,\"start\":31002},{\"end\":31027,\"start\":31023},{\"end\":31038,\"start\":31037},{\"end\":31047,\"start\":31046},{\"end\":31442,\"start\":31441},{\"end\":31451,\"start\":31450},{\"end\":31459,\"start\":31458},{\"end\":31468,\"start\":31467},{\"end\":31479,\"start\":31478},{\"end\":31481,\"start\":31480},{\"end\":31491,\"start\":31490},{\"end\":31503,\"start\":31502},{\"end\":31518,\"start\":31517},{\"end\":31527,\"start\":31526},{\"end\":31537,\"start\":31536},{\"end\":31547,\"start\":31546},{\"end\":31558,\"start\":31557},{\"end\":31574,\"start\":31573},{\"end\":31585,\"start\":31584},{\"end\":31597,\"start\":31596},{\"end\":31606,\"start\":31605},{\"end\":31616,\"start\":31615},{\"end\":31627,\"start\":31626},{\"end\":31633,\"start\":31632},{\"end\":31643,\"start\":31642},{\"end\":31652,\"start\":31651},{\"end\":31660,\"start\":31659},{\"end\":31670,\"start\":31669},{\"end\":31680,\"start\":31679},{\"end\":31688,\"start\":31687},{\"end\":31697,\"start\":31696},{\"end\":31706,\"start\":31705},{\"end\":31716,\"start\":31715},{\"end\":31730,\"start\":31729},{\"end\":31741,\"start\":31740},{\"end\":31759,\"start\":31753},{\"end\":31763,\"start\":31762},{\"end\":32657,\"start\":32656},{\"end\":32666,\"start\":32665},{\"end\":32674,\"start\":32673},{\"end\":32683,\"start\":32682},{\"end\":32694,\"start\":32693},{\"end\":32696,\"start\":32695},{\"end\":32706,\"start\":32705},{\"end\":32718,\"start\":32717},{\"end\":32733,\"start\":32732},{\"end\":32742,\"start\":32741},{\"end\":32752,\"start\":32751},{\"end\":32762,\"start\":32761},{\"end\":32773,\"start\":32772},{\"end\":32789,\"start\":32788},{\"end\":32800,\"start\":32799},{\"end\":32812,\"start\":32811},{\"end\":32821,\"start\":32820},{\"end\":32831,\"start\":32830},{\"end\":32842,\"start\":32841},{\"end\":32848,\"start\":32847},{\"end\":32858,\"start\":32857},{\"end\":32867,\"start\":32866},{\"end\":32875,\"start\":32874},{\"end\":32885,\"start\":32884},{\"end\":32895,\"start\":32894},{\"end\":32903,\"start\":32902},{\"end\":32912,\"start\":32911},{\"end\":32921,\"start\":32920},{\"end\":32931,\"start\":32930},{\"end\":32945,\"start\":32944},{\"end\":32956,\"start\":32955},{\"end\":32974,\"start\":32968},{\"end\":32978,\"start\":32977},{\"end\":33565,\"start\":33564},{\"end\":33573,\"start\":33572},{\"end\":33583,\"start\":33582},{\"end\":33590,\"start\":33589},{\"end\":33598,\"start\":33597},{\"end\":33600,\"start\":33599},{\"end\":33621,\"start\":33620},{\"end\":33631,\"start\":33630},{\"end\":33642,\"start\":33641},{\"end\":33651,\"start\":33650},{\"end\":33661,\"start\":33660},{\"end\":33673,\"start\":33672},{\"end\":33680,\"start\":33679},{\"end\":33688,\"start\":33687},{\"end\":33699,\"start\":33698},{\"end\":33709,\"start\":33708},{\"end\":33719,\"start\":33718},{\"end\":33729,\"start\":33728},{\"end\":33740,\"start\":33739},{\"end\":33748,\"start\":33747},{\"end\":33756,\"start\":33755},{\"end\":33765,\"start\":33764},{\"end\":33775,\"start\":33774},{\"end\":33784,\"start\":33783},{\"end\":33794,\"start\":33793},{\"end\":33806,\"start\":33805},{\"end\":33816,\"start\":33815},{\"end\":33826,\"start\":33825},{\"end\":33828,\"start\":33827},{\"end\":33836,\"start\":33835},{\"end\":33848,\"start\":33847},{\"end\":33860,\"start\":33859},{\"end\":33872,\"start\":33871},{\"end\":33882,\"start\":33881},{\"end\":33898,\"start\":33897},{\"end\":33900,\"start\":33899},{\"end\":33908,\"start\":33907},{\"end\":33918,\"start\":33917},{\"end\":33927,\"start\":33926},{\"end\":33936,\"start\":33935},{\"end\":33944,\"start\":33943},{\"end\":33958,\"start\":33957},{\"end\":33968,\"start\":33967},{\"end\":33976,\"start\":33975},{\"end\":33988,\"start\":33987},{\"end\":33997,\"start\":33996},{\"end\":33999,\"start\":33998},{\"end\":34007,\"start\":34006},{\"end\":34016,\"start\":34015},{\"end\":34026,\"start\":34025},{\"end\":34035,\"start\":34034},{\"end\":34047,\"start\":34046},{\"end\":34058,\"start\":34057},{\"end\":34068,\"start\":34067},{\"end\":34080,\"start\":34079},{\"end\":34090,\"start\":34089},{\"end\":34099,\"start\":34098},{\"end\":34111,\"start\":34110},{\"end\":34122,\"start\":34121},{\"end\":34132,\"start\":34131},{\"end\":34146,\"start\":34145},{\"end\":34159,\"start\":34158},{\"end\":35106,\"start\":35105},{\"end\":35114,\"start\":35113},{\"end\":35124,\"start\":35123},{\"end\":35131,\"start\":35130},{\"end\":35139,\"start\":35138},{\"end\":35141,\"start\":35140},{\"end\":35162,\"start\":35161},{\"end\":35172,\"start\":35171},{\"end\":35183,\"start\":35182},{\"end\":35192,\"start\":35191},{\"end\":35202,\"start\":35201},{\"end\":35214,\"start\":35213},{\"end\":35221,\"start\":35220},{\"end\":35229,\"start\":35228},{\"end\":35240,\"start\":35239},{\"end\":35250,\"start\":35249},{\"end\":35260,\"start\":35259},{\"end\":35270,\"start\":35269},{\"end\":35281,\"start\":35280},{\"end\":35289,\"start\":35288},{\"end\":35297,\"start\":35296},{\"end\":35306,\"start\":35305},{\"end\":35316,\"start\":35315},{\"end\":35325,\"start\":35324},{\"end\":35335,\"start\":35334},{\"end\":35347,\"start\":35346},{\"end\":35357,\"start\":35356},{\"end\":35367,\"start\":35366},{\"end\":35369,\"start\":35368},{\"end\":35377,\"start\":35376},{\"end\":35389,\"start\":35388},{\"end\":35401,\"start\":35400},{\"end\":35413,\"start\":35412},{\"end\":35423,\"start\":35422},{\"end\":35439,\"start\":35438},{\"end\":35441,\"start\":35440},{\"end\":35449,\"start\":35448},{\"end\":35459,\"start\":35458},{\"end\":35468,\"start\":35467},{\"end\":35477,\"start\":35476},{\"end\":35485,\"start\":35484},{\"end\":35499,\"start\":35498},{\"end\":35509,\"start\":35508},{\"end\":35517,\"start\":35516},{\"end\":35529,\"start\":35528},{\"end\":35538,\"start\":35537},{\"end\":35540,\"start\":35539},{\"end\":35548,\"start\":35547},{\"end\":35557,\"start\":35556},{\"end\":35567,\"start\":35566},{\"end\":35576,\"start\":35575},{\"end\":35588,\"start\":35587},{\"end\":35599,\"start\":35598},{\"end\":35609,\"start\":35608},{\"end\":35621,\"start\":35620},{\"end\":35631,\"start\":35630},{\"end\":35640,\"start\":35639},{\"end\":35652,\"start\":35651},{\"end\":35663,\"start\":35662},{\"end\":35673,\"start\":35672},{\"end\":35687,\"start\":35686},{\"end\":35700,\"start\":35699},{\"end\":36645,\"start\":36644},{\"end\":36658,\"start\":36657},{\"end\":36668,\"start\":36667},{\"end\":36678,\"start\":36677},{\"end\":36687,\"start\":36686},{\"end\":36697,\"start\":36696},{\"end\":36708,\"start\":36707},{\"end\":36718,\"start\":36717},{\"end\":36720,\"start\":36719},{\"end\":36729,\"start\":36728},{\"end\":36739,\"start\":36738},{\"end\":37043,\"start\":37042},{\"end\":37045,\"start\":37044},{\"end\":37054,\"start\":37053},{\"end\":37061,\"start\":37060},{\"end\":37072,\"start\":37071},{\"end\":37080,\"start\":37079},{\"end\":37087,\"start\":37086},{\"end\":37096,\"start\":37095},{\"end\":37102,\"start\":37101},{\"end\":37110,\"start\":37109},{\"end\":37122,\"start\":37121},{\"end\":37414,\"start\":37413},{\"end\":37416,\"start\":37415},{\"end\":37425,\"start\":37424},{\"end\":37432,\"start\":37431},{\"end\":37443,\"start\":37442},{\"end\":37451,\"start\":37450},{\"end\":37458,\"start\":37457},{\"end\":37467,\"start\":37466},{\"end\":37473,\"start\":37472},{\"end\":37481,\"start\":37480},{\"end\":37493,\"start\":37492},{\"end\":37847,\"start\":37846},{\"end\":37857,\"start\":37856},{\"end\":37868,\"start\":37867},{\"end\":37878,\"start\":37877},{\"end\":38519,\"start\":38518},{\"end\":38526,\"start\":38525},{\"end\":38538,\"start\":38537},{\"end\":38547,\"start\":38546},{\"end\":38558,\"start\":38557},{\"end\":38567,\"start\":38566},{\"end\":38577,\"start\":38576},{\"end\":38586,\"start\":38585},{\"end\":38592,\"start\":38591},{\"end\":38601,\"start\":38600},{\"end\":38614,\"start\":38613},{\"end\":38625,\"start\":38624},{\"end\":38627,\"start\":38626},{\"end\":38636,\"start\":38635},{\"end\":38647,\"start\":38646},{\"end\":38657,\"start\":38656},{\"end\":38666,\"start\":38665},{\"end\":38668,\"start\":38667},{\"end\":38674,\"start\":38673},{\"end\":38676,\"start\":38675},{\"end\":38685,\"start\":38684},{\"end\":38693,\"start\":38692},{\"end\":38702,\"start\":38701},{\"end\":38704,\"start\":38703},{\"end\":38717,\"start\":38716},{\"end\":39460,\"start\":39459},{\"end\":39467,\"start\":39466},{\"end\":39474,\"start\":39473},{\"end\":39482,\"start\":39481},{\"end\":39497,\"start\":39492},{\"end\":39501,\"start\":39500},{\"end\":39789,\"start\":39788},{\"end\":39802,\"start\":39801},{\"end\":39811,\"start\":39810},{\"end\":39821,\"start\":39820},{\"end\":39828,\"start\":39827},{\"end\":39839,\"start\":39838},{\"end\":39847,\"start\":39846},{\"end\":40220,\"start\":40219},{\"end\":40232,\"start\":40231},{\"end\":40244,\"start\":40243},{\"end\":40254,\"start\":40253},{\"end\":40269,\"start\":40268},{\"end\":40276,\"start\":40275},{\"end\":40290,\"start\":40289},{\"end\":40294,\"start\":40291},{\"end\":40303,\"start\":40302},{\"end\":40305,\"start\":40304},{\"end\":40318,\"start\":40317},{\"end\":40327,\"start\":40326},{\"end\":40600,\"start\":40599},{\"end\":40606,\"start\":40605},{\"end\":40613,\"start\":40612},{\"end\":40621,\"start\":40620},{\"end\":40628,\"start\":40627},{\"end\":40630,\"start\":40629},{\"end\":40639,\"start\":40638},{\"end\":40974,\"start\":40973},{\"end\":40985,\"start\":40984},{\"end\":41788,\"start\":41787},{\"end\":41799,\"start\":41798},{\"end\":42077,\"start\":42076},{\"end\":42088,\"start\":42087},{\"end\":42097,\"start\":42096},{\"end\":42109,\"start\":42108},{\"end\":42119,\"start\":42118},{\"end\":42133,\"start\":42132},{\"end\":42143,\"start\":42142},{\"end\":42518,\"start\":42517},{\"end\":42529,\"start\":42528},{\"end\":42538,\"start\":42537},{\"end\":42548,\"start\":42547},{\"end\":42560,\"start\":42559},{\"end\":42571,\"start\":42570},{\"end\":42581,\"start\":42580},{\"end\":42595,\"start\":42594},{\"end\":42605,\"start\":42604},{\"end\":42615,\"start\":42614},{\"end\":42929,\"start\":42928},{\"end\":42940,\"start\":42939},{\"end\":42949,\"start\":42948},{\"end\":43218,\"start\":43217},{\"end\":43227,\"start\":43226},{\"end\":43235,\"start\":43234},{\"end\":43243,\"start\":43242},{\"end\":43974,\"start\":43973},{\"end\":43987,\"start\":43986},{\"end\":43995,\"start\":43994},{\"end\":44002,\"start\":44001},{\"end\":44011,\"start\":44010},{\"end\":44017,\"start\":44016},{\"end\":44027,\"start\":44026},{\"end\":44035,\"start\":44034},{\"end\":44777,\"start\":44776},{\"end\":44790,\"start\":44789},{\"end\":44798,\"start\":44797},{\"end\":44805,\"start\":44804},{\"end\":44814,\"start\":44813},{\"end\":44820,\"start\":44819},{\"end\":44830,\"start\":44829},{\"end\":44838,\"start\":44837},{\"end\":45363,\"start\":45362},{\"end\":45377,\"start\":45376},{\"end\":45385,\"start\":45384},{\"end\":45397,\"start\":45396},{\"end\":45416,\"start\":45411},{\"end\":45420,\"start\":45419},{\"end\":45828,\"start\":45827},{\"end\":45839,\"start\":45838},{\"end\":45852,\"start\":45851},{\"end\":45854,\"start\":45853},{\"end\":45860,\"start\":45859},{\"end\":45868,\"start\":45867},{\"end\":45877,\"start\":45876},{\"end\":45886,\"start\":45885},{\"end\":46190,\"start\":46189},{\"end\":46192,\"start\":46191},{\"end\":46202,\"start\":46201},{\"end\":46323,\"start\":46322},{\"end\":46338,\"start\":46337},{\"end\":46350,\"start\":46349},{\"end\":46362,\"start\":46361},{\"end\":46373,\"start\":46372},{\"end\":46383,\"start\":46382},{\"end\":46394,\"start\":46393},{\"end\":46405,\"start\":46404},{\"end\":46419,\"start\":46418},{\"end\":46429,\"start\":46428},{\"end\":46436,\"start\":46435},{\"end\":46449,\"start\":46448},{\"end\":46458,\"start\":46457},{\"end\":46471,\"start\":46467},{\"end\":46480,\"start\":46479},{\"end\":46482,\"start\":46481},{\"end\":46489,\"start\":46488},{\"end\":46502,\"start\":46501},{\"end\":46508,\"start\":46507},{\"end\":47181,\"start\":47180},{\"end\":47190,\"start\":47189},{\"end\":47199,\"start\":47198},{\"end\":47209,\"start\":47208},{\"end\":47220,\"start\":47219},{\"end\":47233,\"start\":47232},{\"end\":47242,\"start\":47241},{\"end\":47253,\"start\":47252},{\"end\":47265,\"start\":47261},{\"end\":47272,\"start\":47271},{\"end\":47287,\"start\":47286},{\"end\":47297,\"start\":47296},{\"end\":47654,\"start\":47653},{\"end\":47663,\"start\":47662},{\"end\":47676,\"start\":47675},{\"end\":48309,\"start\":48308},{\"end\":48319,\"start\":48318},{\"end\":48327,\"start\":48326},{\"end\":48336,\"start\":48335},{\"end\":48343,\"start\":48342},{\"end\":48357,\"start\":48356},{\"end\":48639,\"start\":48638},{\"end\":48646,\"start\":48645},{\"end\":48653,\"start\":48652},{\"end\":48662,\"start\":48661},{\"end\":48673,\"start\":48669},{\"end\":48680,\"start\":48679},{\"end\":48694,\"start\":48693},{\"end\":48996,\"start\":48995},{\"end\":49002,\"start\":49001},{\"end\":49008,\"start\":49007},{\"end\":49014,\"start\":49013},{\"end\":49021,\"start\":49020},{\"end\":49023,\"start\":49022},{\"end\":49033,\"start\":49032},{\"end\":49039,\"start\":49038},{\"end\":49041,\"start\":49040},{\"end\":49049,\"start\":49048},{\"end\":49057,\"start\":49056},{\"end\":49059,\"start\":49058},{\"end\":49067,\"start\":49066},{\"end\":49079,\"start\":49075},{\"end\":49083,\"start\":49082},{\"end\":49402,\"start\":49401},{\"end\":49408,\"start\":49407},{\"end\":49416,\"start\":49415},{\"end\":49423,\"start\":49422},{\"end\":49430,\"start\":49429},{\"end\":49437,\"start\":49436},{\"end\":49439,\"start\":49438},{\"end\":49447,\"start\":49446},{\"end\":49455,\"start\":49454},{\"end\":49464,\"start\":49460},{\"end\":49468,\"start\":49467},{\"end\":50388,\"start\":50387},{\"end\":50401,\"start\":50400},{\"end\":50684,\"start\":50683},{\"end\":50693,\"start\":50692},{\"end\":50703,\"start\":50702},{\"end\":51249,\"start\":51248},{\"end\":51251,\"start\":51250},{\"end\":51261,\"start\":51260},{\"end\":51270,\"start\":51269},{\"end\":51282,\"start\":51281},{\"end\":51297,\"start\":51296},{\"end\":51307,\"start\":51306},{\"end\":51595,\"start\":51594},{\"end\":51597,\"start\":51596},{\"end\":51605,\"start\":51604},{\"end\":51612,\"start\":51611},{\"end\":51621,\"start\":51620},{\"end\":51632,\"start\":51631},{\"end\":51640,\"start\":51639},{\"end\":51651,\"start\":51650},{\"end\":51663,\"start\":51662},{\"end\":51665,\"start\":51664},{\"end\":51677,\"start\":51676},{\"end\":51685,\"start\":51684},{\"end\":52053,\"start\":52052},{\"end\":52060,\"start\":52059},{\"end\":52071,\"start\":52070},{\"end\":52085,\"start\":52084},{\"end\":52203,\"start\":52202},{\"end\":52209,\"start\":52208},{\"end\":52216,\"start\":52215},{\"end\":52224,\"start\":52223},{\"end\":52232,\"start\":52231},{\"end\":52240,\"start\":52239},{\"end\":52258,\"start\":52254},{\"end\":52262,\"start\":52261},{\"end\":52509,\"start\":52508},{\"end\":52515,\"start\":52514},{\"end\":52522,\"start\":52521},{\"end\":52530,\"start\":52529},{\"end\":52538,\"start\":52537},{\"end\":52546,\"start\":52545},{\"end\":52564,\"start\":52560},{\"end\":52568,\"start\":52567},{\"end\":52811,\"start\":52810},{\"end\":52822,\"start\":52821},{\"end\":52833,\"start\":52832},{\"end\":52842,\"start\":52841},{\"end\":53181,\"start\":53180},{\"end\":53187,\"start\":53186},{\"end\":53196,\"start\":53195},{\"end\":53204,\"start\":53203},{\"end\":53210,\"start\":53209},{\"end\":53226,\"start\":53222},{\"end\":53233,\"start\":53232},{\"end\":53235,\"start\":53234},{\"end\":53244,\"start\":53243},{\"end\":53259,\"start\":53258},{\"end\":53656,\"start\":53655},{\"end\":53662,\"start\":53661},{\"end\":53670,\"start\":53669},{\"end\":53676,\"start\":53675},{\"end\":53685,\"start\":53684},{\"end\":53693,\"start\":53692},{\"end\":53700,\"start\":53699},{\"end\":53706,\"start\":53705},{\"end\":53713,\"start\":53712},{\"end\":53720,\"start\":53719},{\"end\":53978,\"start\":53977},{\"end\":53990,\"start\":53989},{\"end\":54004,\"start\":54003},{\"end\":54011,\"start\":54010},{\"end\":54020,\"start\":54019},{\"end\":54032,\"start\":54031},{\"end\":54041,\"start\":54040},{\"end\":54050,\"start\":54049},{\"end\":54065,\"start\":54064},{\"end\":54419,\"start\":54413},{\"end\":54429,\"start\":54428},{\"end\":54431,\"start\":54430},{\"end\":54642,\"start\":54641},{\"end\":55600,\"start\":55599},{\"end\":55606,\"start\":55605},{\"end\":55614,\"start\":55613},{\"end\":55622,\"start\":55621},{\"end\":55628,\"start\":55627},{\"end\":55634,\"start\":55633},{\"end\":55644,\"start\":55643},{\"end\":55651,\"start\":55650},{\"end\":55659,\"start\":55658},{\"end\":55909,\"start\":55908},{\"end\":55918,\"start\":55917},{\"end\":55926,\"start\":55925},{\"end\":56077,\"start\":56076},{\"end\":56086,\"start\":56085},{\"end\":56096,\"start\":56095},{\"end\":56105,\"start\":56104},{\"end\":56116,\"start\":56115},{\"end\":56124,\"start\":56123},{\"end\":56132,\"start\":56131},{\"end\":56141,\"start\":56140},{\"end\":56149,\"start\":56148},{\"end\":56155,\"start\":56154},{\"end\":56157,\"start\":56156},{\"end\":57179,\"start\":57178},{\"end\":57188,\"start\":57187},{\"end\":57198,\"start\":57194},{\"end\":57202,\"start\":57201}]", "bib_author_last_name": "[{\"end\":30476,\"start\":30468},{\"end\":30486,\"start\":30480},{\"end\":30498,\"start\":30490},{\"end\":30505,\"start\":30502},{\"end\":30519,\"start\":30509},{\"end\":30531,\"start\":30523},{\"end\":30548,\"start\":30539},{\"end\":30562,\"start\":30555},{\"end\":30571,\"start\":30566},{\"end\":30580,\"start\":30575},{\"end\":30943,\"start\":30935},{\"end\":30953,\"start\":30947},{\"end\":30965,\"start\":30957},{\"end\":30972,\"start\":30969},{\"end\":30986,\"start\":30976},{\"end\":30998,\"start\":30990},{\"end\":31021,\"start\":31004},{\"end\":31035,\"start\":31028},{\"end\":31044,\"start\":31039},{\"end\":31053,\"start\":31048},{\"end\":31448,\"start\":31443},{\"end\":31456,\"start\":31452},{\"end\":31465,\"start\":31460},{\"end\":31476,\"start\":31469},{\"end\":31488,\"start\":31482},{\"end\":31500,\"start\":31492},{\"end\":31515,\"start\":31504},{\"end\":31524,\"start\":31519},{\"end\":31534,\"start\":31528},{\"end\":31544,\"start\":31538},{\"end\":31555,\"start\":31548},{\"end\":31571,\"start\":31559},{\"end\":31582,\"start\":31575},{\"end\":31594,\"start\":31586},{\"end\":31603,\"start\":31598},{\"end\":31613,\"start\":31607},{\"end\":31624,\"start\":31617},{\"end\":31630,\"start\":31628},{\"end\":31640,\"start\":31634},{\"end\":31649,\"start\":31644},{\"end\":31657,\"start\":31653},{\"end\":31667,\"start\":31661},{\"end\":31677,\"start\":31671},{\"end\":31685,\"start\":31681},{\"end\":31694,\"start\":31689},{\"end\":31703,\"start\":31698},{\"end\":31713,\"start\":31707},{\"end\":31727,\"start\":31717},{\"end\":31738,\"start\":31731},{\"end\":31751,\"start\":31742},{\"end\":32663,\"start\":32658},{\"end\":32671,\"start\":32667},{\"end\":32680,\"start\":32675},{\"end\":32691,\"start\":32684},{\"end\":32703,\"start\":32697},{\"end\":32715,\"start\":32707},{\"end\":32730,\"start\":32719},{\"end\":32739,\"start\":32734},{\"end\":32749,\"start\":32743},{\"end\":32759,\"start\":32753},{\"end\":32770,\"start\":32763},{\"end\":32786,\"start\":32774},{\"end\":32797,\"start\":32790},{\"end\":32809,\"start\":32801},{\"end\":32818,\"start\":32813},{\"end\":32828,\"start\":32822},{\"end\":32839,\"start\":32832},{\"end\":32845,\"start\":32843},{\"end\":32855,\"start\":32849},{\"end\":32864,\"start\":32859},{\"end\":32872,\"start\":32868},{\"end\":32882,\"start\":32876},{\"end\":32892,\"start\":32886},{\"end\":32900,\"start\":32896},{\"end\":32909,\"start\":32904},{\"end\":32918,\"start\":32913},{\"end\":32928,\"start\":32922},{\"end\":32942,\"start\":32932},{\"end\":32953,\"start\":32946},{\"end\":32966,\"start\":32957},{\"end\":33570,\"start\":33566},{\"end\":33580,\"start\":33574},{\"end\":33587,\"start\":33584},{\"end\":33595,\"start\":33591},{\"end\":33618,\"start\":33601},{\"end\":33628,\"start\":33622},{\"end\":33639,\"start\":33632},{\"end\":33648,\"start\":33643},{\"end\":33658,\"start\":33652},{\"end\":33670,\"start\":33662},{\"end\":33677,\"start\":33674},{\"end\":33685,\"start\":33681},{\"end\":33696,\"start\":33689},{\"end\":33706,\"start\":33700},{\"end\":33716,\"start\":33710},{\"end\":33726,\"start\":33720},{\"end\":33737,\"start\":33730},{\"end\":33745,\"start\":33741},{\"end\":33753,\"start\":33749},{\"end\":33762,\"start\":33757},{\"end\":33772,\"start\":33766},{\"end\":33781,\"start\":33776},{\"end\":33791,\"start\":33785},{\"end\":33803,\"start\":33795},{\"end\":33813,\"start\":33807},{\"end\":33823,\"start\":33817},{\"end\":33833,\"start\":33829},{\"end\":33845,\"start\":33837},{\"end\":33857,\"start\":33849},{\"end\":33869,\"start\":33861},{\"end\":33879,\"start\":33873},{\"end\":33895,\"start\":33883},{\"end\":33905,\"start\":33901},{\"end\":33915,\"start\":33909},{\"end\":33924,\"start\":33919},{\"end\":33933,\"start\":33928},{\"end\":33941,\"start\":33937},{\"end\":33955,\"start\":33945},{\"end\":33965,\"start\":33959},{\"end\":33973,\"start\":33969},{\"end\":33985,\"start\":33977},{\"end\":33994,\"start\":33989},{\"end\":34004,\"start\":34000},{\"end\":34013,\"start\":34008},{\"end\":34023,\"start\":34017},{\"end\":34032,\"start\":34027},{\"end\":34044,\"start\":34036},{\"end\":34055,\"start\":34048},{\"end\":34065,\"start\":34059},{\"end\":34077,\"start\":34069},{\"end\":34087,\"start\":34081},{\"end\":34096,\"start\":34091},{\"end\":34108,\"start\":34100},{\"end\":34119,\"start\":34112},{\"end\":34129,\"start\":34123},{\"end\":34143,\"start\":34133},{\"end\":34156,\"start\":34147},{\"end\":34167,\"start\":34160},{\"end\":35111,\"start\":35107},{\"end\":35121,\"start\":35115},{\"end\":35128,\"start\":35125},{\"end\":35136,\"start\":35132},{\"end\":35159,\"start\":35142},{\"end\":35169,\"start\":35163},{\"end\":35180,\"start\":35173},{\"end\":35189,\"start\":35184},{\"end\":35199,\"start\":35193},{\"end\":35211,\"start\":35203},{\"end\":35218,\"start\":35215},{\"end\":35226,\"start\":35222},{\"end\":35237,\"start\":35230},{\"end\":35247,\"start\":35241},{\"end\":35257,\"start\":35251},{\"end\":35267,\"start\":35261},{\"end\":35278,\"start\":35271},{\"end\":35286,\"start\":35282},{\"end\":35294,\"start\":35290},{\"end\":35303,\"start\":35298},{\"end\":35313,\"start\":35307},{\"end\":35322,\"start\":35317},{\"end\":35332,\"start\":35326},{\"end\":35344,\"start\":35336},{\"end\":35354,\"start\":35348},{\"end\":35364,\"start\":35358},{\"end\":35374,\"start\":35370},{\"end\":35386,\"start\":35378},{\"end\":35398,\"start\":35390},{\"end\":35410,\"start\":35402},{\"end\":35420,\"start\":35414},{\"end\":35436,\"start\":35424},{\"end\":35446,\"start\":35442},{\"end\":35456,\"start\":35450},{\"end\":35465,\"start\":35460},{\"end\":35474,\"start\":35469},{\"end\":35482,\"start\":35478},{\"end\":35496,\"start\":35486},{\"end\":35506,\"start\":35500},{\"end\":35514,\"start\":35510},{\"end\":35526,\"start\":35518},{\"end\":35535,\"start\":35530},{\"end\":35545,\"start\":35541},{\"end\":35554,\"start\":35549},{\"end\":35564,\"start\":35558},{\"end\":35573,\"start\":35568},{\"end\":35585,\"start\":35577},{\"end\":35596,\"start\":35589},{\"end\":35606,\"start\":35600},{\"end\":35618,\"start\":35610},{\"end\":35628,\"start\":35622},{\"end\":35637,\"start\":35632},{\"end\":35649,\"start\":35641},{\"end\":35660,\"start\":35653},{\"end\":35670,\"start\":35664},{\"end\":35684,\"start\":35674},{\"end\":35697,\"start\":35688},{\"end\":35708,\"start\":35701},{\"end\":36655,\"start\":36646},{\"end\":36665,\"start\":36659},{\"end\":36675,\"start\":36669},{\"end\":36684,\"start\":36679},{\"end\":36694,\"start\":36688},{\"end\":36705,\"start\":36698},{\"end\":36715,\"start\":36709},{\"end\":36726,\"start\":36721},{\"end\":36736,\"start\":36730},{\"end\":36748,\"start\":36740},{\"end\":37051,\"start\":37046},{\"end\":37058,\"start\":37055},{\"end\":37069,\"start\":37062},{\"end\":37077,\"start\":37073},{\"end\":37084,\"start\":37081},{\"end\":37093,\"start\":37088},{\"end\":37099,\"start\":37097},{\"end\":37107,\"start\":37103},{\"end\":37119,\"start\":37111},{\"end\":37129,\"start\":37123},{\"end\":37422,\"start\":37417},{\"end\":37429,\"start\":37426},{\"end\":37440,\"start\":37433},{\"end\":37448,\"start\":37444},{\"end\":37455,\"start\":37452},{\"end\":37464,\"start\":37459},{\"end\":37470,\"start\":37468},{\"end\":37478,\"start\":37474},{\"end\":37490,\"start\":37482},{\"end\":37500,\"start\":37494},{\"end\":37854,\"start\":37848},{\"end\":37865,\"start\":37858},{\"end\":37875,\"start\":37869},{\"end\":37883,\"start\":37879},{\"end\":38523,\"start\":38520},{\"end\":38535,\"start\":38527},{\"end\":38544,\"start\":38539},{\"end\":38555,\"start\":38548},{\"end\":38564,\"start\":38559},{\"end\":38574,\"start\":38568},{\"end\":38583,\"start\":38578},{\"end\":38589,\"start\":38587},{\"end\":38598,\"start\":38593},{\"end\":38611,\"start\":38602},{\"end\":38622,\"start\":38615},{\"end\":38633,\"start\":38628},{\"end\":38644,\"start\":38637},{\"end\":38654,\"start\":38648},{\"end\":38663,\"start\":38658},{\"end\":38671,\"start\":38669},{\"end\":38682,\"start\":38677},{\"end\":38690,\"start\":38686},{\"end\":38699,\"start\":38694},{\"end\":38714,\"start\":38705},{\"end\":38728,\"start\":38718},{\"end\":39464,\"start\":39461},{\"end\":39471,\"start\":39468},{\"end\":39479,\"start\":39475},{\"end\":39490,\"start\":39483},{\"end\":39799,\"start\":39790},{\"end\":39808,\"start\":39803},{\"end\":39818,\"start\":39812},{\"end\":39825,\"start\":39822},{\"end\":39836,\"start\":39829},{\"end\":39844,\"start\":39840},{\"end\":39858,\"start\":39848},{\"end\":40229,\"start\":40221},{\"end\":40241,\"start\":40233},{\"end\":40251,\"start\":40245},{\"end\":40266,\"start\":40255},{\"end\":40273,\"start\":40270},{\"end\":40287,\"start\":40277},{\"end\":40300,\"start\":40295},{\"end\":40315,\"start\":40306},{\"end\":40324,\"start\":40319},{\"end\":40333,\"start\":40328},{\"end\":40603,\"start\":40601},{\"end\":40610,\"start\":40607},{\"end\":40618,\"start\":40614},{\"end\":40625,\"start\":40622},{\"end\":40636,\"start\":40631},{\"end\":40643,\"start\":40640},{\"end\":40654,\"start\":40645},{\"end\":40982,\"start\":40975},{\"end\":40991,\"start\":40986},{\"end\":41796,\"start\":41789},{\"end\":41805,\"start\":41800},{\"end\":42085,\"start\":42078},{\"end\":42094,\"start\":42089},{\"end\":42106,\"start\":42098},{\"end\":42116,\"start\":42110},{\"end\":42130,\"start\":42120},{\"end\":42140,\"start\":42134},{\"end\":42149,\"start\":42144},{\"end\":42526,\"start\":42519},{\"end\":42535,\"start\":42530},{\"end\":42545,\"start\":42539},{\"end\":42557,\"start\":42549},{\"end\":42568,\"start\":42561},{\"end\":42578,\"start\":42572},{\"end\":42592,\"start\":42582},{\"end\":42602,\"start\":42596},{\"end\":42612,\"start\":42606},{\"end\":42621,\"start\":42616},{\"end\":42937,\"start\":42930},{\"end\":42946,\"start\":42941},{\"end\":42955,\"start\":42950},{\"end\":43224,\"start\":43219},{\"end\":43232,\"start\":43228},{\"end\":43240,\"start\":43236},{\"end\":43255,\"start\":43244},{\"end\":43984,\"start\":43975},{\"end\":43992,\"start\":43988},{\"end\":43999,\"start\":43996},{\"end\":44008,\"start\":44003},{\"end\":44014,\"start\":44012},{\"end\":44024,\"start\":44018},{\"end\":44032,\"start\":44028},{\"end\":44039,\"start\":44036},{\"end\":44787,\"start\":44778},{\"end\":44795,\"start\":44791},{\"end\":44802,\"start\":44799},{\"end\":44811,\"start\":44806},{\"end\":44817,\"start\":44815},{\"end\":44827,\"start\":44821},{\"end\":44835,\"start\":44831},{\"end\":44842,\"start\":44839},{\"end\":45374,\"start\":45364},{\"end\":45382,\"start\":45378},{\"end\":45394,\"start\":45386},{\"end\":45409,\"start\":45398},{\"end\":45836,\"start\":45829},{\"end\":45849,\"start\":45840},{\"end\":45857,\"start\":45855},{\"end\":45865,\"start\":45861},{\"end\":45874,\"start\":45869},{\"end\":45883,\"start\":45878},{\"end\":45894,\"start\":45887},{\"end\":46199,\"start\":46193},{\"end\":46205,\"start\":46203},{\"end\":46211,\"start\":46207},{\"end\":46335,\"start\":46324},{\"end\":46347,\"start\":46339},{\"end\":46359,\"start\":46351},{\"end\":46370,\"start\":46363},{\"end\":46380,\"start\":46374},{\"end\":46391,\"start\":46384},{\"end\":46402,\"start\":46395},{\"end\":46416,\"start\":46406},{\"end\":46426,\"start\":46420},{\"end\":46433,\"start\":46430},{\"end\":46446,\"start\":46437},{\"end\":46455,\"start\":46450},{\"end\":46465,\"start\":46459},{\"end\":46477,\"start\":46472},{\"end\":46486,\"start\":46483},{\"end\":46499,\"start\":46490},{\"end\":46505,\"start\":46503},{\"end\":46515,\"start\":46509},{\"end\":47187,\"start\":47182},{\"end\":47196,\"start\":47191},{\"end\":47206,\"start\":47200},{\"end\":47217,\"start\":47210},{\"end\":47230,\"start\":47221},{\"end\":47239,\"start\":47234},{\"end\":47250,\"start\":47243},{\"end\":47259,\"start\":47254},{\"end\":47269,\"start\":47266},{\"end\":47284,\"start\":47273},{\"end\":47294,\"start\":47288},{\"end\":47303,\"start\":47298},{\"end\":47660,\"start\":47655},{\"end\":47673,\"start\":47664},{\"end\":47683,\"start\":47677},{\"end\":48316,\"start\":48310},{\"end\":48324,\"start\":48320},{\"end\":48333,\"start\":48328},{\"end\":48340,\"start\":48337},{\"end\":48354,\"start\":48344},{\"end\":48366,\"start\":48358},{\"end\":48643,\"start\":48640},{\"end\":48650,\"start\":48647},{\"end\":48659,\"start\":48654},{\"end\":48667,\"start\":48663},{\"end\":48677,\"start\":48674},{\"end\":48691,\"start\":48681},{\"end\":48706,\"start\":48695},{\"end\":48999,\"start\":48997},{\"end\":49005,\"start\":49003},{\"end\":49011,\"start\":49009},{\"end\":49018,\"start\":49015},{\"end\":49030,\"start\":49024},{\"end\":49036,\"start\":49034},{\"end\":49046,\"start\":49042},{\"end\":49054,\"start\":49050},{\"end\":49064,\"start\":49060},{\"end\":49073,\"start\":49068},{\"end\":49405,\"start\":49403},{\"end\":49413,\"start\":49409},{\"end\":49420,\"start\":49417},{\"end\":49427,\"start\":49424},{\"end\":49434,\"start\":49431},{\"end\":49444,\"start\":49440},{\"end\":49452,\"start\":49448},{\"end\":49458,\"start\":49456},{\"end\":50398,\"start\":50389},{\"end\":50410,\"start\":50402},{\"end\":50690,\"start\":50685},{\"end\":50700,\"start\":50694},{\"end\":50710,\"start\":50704},{\"end\":51258,\"start\":51252},{\"end\":51267,\"start\":51262},{\"end\":51279,\"start\":51271},{\"end\":51294,\"start\":51283},{\"end\":51304,\"start\":51298},{\"end\":51314,\"start\":51308},{\"end\":51602,\"start\":51598},{\"end\":51609,\"start\":51606},{\"end\":51618,\"start\":51613},{\"end\":51629,\"start\":51622},{\"end\":51637,\"start\":51633},{\"end\":51648,\"start\":51641},{\"end\":51660,\"start\":51652},{\"end\":51674,\"start\":51666},{\"end\":51682,\"start\":51678},{\"end\":51691,\"start\":51686},{\"end\":52057,\"start\":52054},{\"end\":52068,\"start\":52061},{\"end\":52082,\"start\":52072},{\"end\":52097,\"start\":52086},{\"end\":52206,\"start\":52204},{\"end\":52213,\"start\":52210},{\"end\":52221,\"start\":52217},{\"end\":52229,\"start\":52225},{\"end\":52237,\"start\":52233},{\"end\":52252,\"start\":52241},{\"end\":52512,\"start\":52510},{\"end\":52519,\"start\":52516},{\"end\":52527,\"start\":52523},{\"end\":52535,\"start\":52531},{\"end\":52543,\"start\":52539},{\"end\":52558,\"start\":52547},{\"end\":52819,\"start\":52812},{\"end\":52830,\"start\":52823},{\"end\":52839,\"start\":52834},{\"end\":52849,\"start\":52843},{\"end\":53184,\"start\":53182},{\"end\":53193,\"start\":53188},{\"end\":53201,\"start\":53197},{\"end\":53207,\"start\":53205},{\"end\":53220,\"start\":53211},{\"end\":53230,\"start\":53227},{\"end\":53241,\"start\":53236},{\"end\":53256,\"start\":53245},{\"end\":53262,\"start\":53260},{\"end\":53659,\"start\":53657},{\"end\":53667,\"start\":53663},{\"end\":53673,\"start\":53671},{\"end\":53682,\"start\":53677},{\"end\":53690,\"start\":53686},{\"end\":53697,\"start\":53694},{\"end\":53703,\"start\":53701},{\"end\":53710,\"start\":53707},{\"end\":53717,\"start\":53714},{\"end\":53723,\"start\":53721},{\"end\":53987,\"start\":53979},{\"end\":54001,\"start\":53991},{\"end\":54008,\"start\":54005},{\"end\":54017,\"start\":54012},{\"end\":54029,\"start\":54021},{\"end\":54038,\"start\":54033},{\"end\":54047,\"start\":54042},{\"end\":54062,\"start\":54051},{\"end\":54069,\"start\":54066},{\"end\":54426,\"start\":54420},{\"end\":54645,\"start\":54643},{\"end\":55603,\"start\":55601},{\"end\":55611,\"start\":55607},{\"end\":55619,\"start\":55615},{\"end\":55625,\"start\":55623},{\"end\":55631,\"start\":55629},{\"end\":55641,\"start\":55635},{\"end\":55648,\"start\":55645},{\"end\":55656,\"start\":55652},{\"end\":55665,\"start\":55660},{\"end\":55915,\"start\":55910},{\"end\":55923,\"start\":55919},{\"end\":55938,\"start\":55927},{\"end\":56083,\"start\":56078},{\"end\":56093,\"start\":56087},{\"end\":56102,\"start\":56097},{\"end\":56113,\"start\":56106},{\"end\":56121,\"start\":56117},{\"end\":56129,\"start\":56125},{\"end\":56138,\"start\":56133},{\"end\":56146,\"start\":56142},{\"end\":56152,\"start\":56150},{\"end\":56161,\"start\":56158},{\"end\":57185,\"start\":57180},{\"end\":57192,\"start\":57189}]", "bib_entry": "[{\"attributes\":{\"doi\":\"arXiv:2112.04426\",\"id\":\"b0\"},\"end\":30865,\"start\":30400},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":244954723},\"end\":31400,\"start\":30867},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":218971783},\"end\":32615,\"start\":31402},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":218971783},\"end\":33560,\"start\":32617},{\"attributes\":{\"id\":\"b4\"},\"end\":35101,\"start\":33562},{\"attributes\":{\"id\":\"b5\"},\"end\":36642,\"start\":35103},{\"attributes\":{\"doi\":\"arXiv:2204.02311\",\"id\":\"b6\"},\"end\":37040,\"start\":36644},{\"attributes\":{\"doi\":\"arXiv:2210.11416\",\"id\":\"b7\"},\"end\":37411,\"start\":37042},{\"attributes\":{\"doi\":\"arXiv:2210.11416\",\"id\":\"b8\"},\"end\":37782,\"start\":37413},{\"attributes\":{\"doi\":\"10.18653/v1/2021.findings-emnlp.73\",\"id\":\"b9\",\"matched_paper_id\":237439232},\"end\":38450,\"start\":37784},{\"attributes\":{\"doi\":\"arXiv:2101.00027\",\"id\":\"b10\",\"matched_paper_id\":230435736},\"end\":39408,\"start\":38452},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":225626501},\"end\":39734,\"start\":39410},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":221516475},\"end\":40169,\"start\":39736},{\"attributes\":{\"doi\":\"arXiv:2203.15556\",\"id\":\"b13\"},\"end\":40597,\"start\":40171},{\"attributes\":{\"doi\":\"arXiv:2211.09699\",\"id\":\"b14\"},\"end\":40883,\"start\":40599},{\"attributes\":{\"doi\":\"10.18653/v1/2021.eacl-main.74\",\"id\":\"b15\",\"matched_paper_id\":220302360},\"end\":41697,\"start\":40885},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":220302360},\"end\":42006,\"start\":41699},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":249097975},\"end\":42455,\"start\":42008},{\"attributes\":{\"doi\":\"arXiv:2208.03299\",\"id\":\"b18\"},\"end\":42883,\"start\":42457},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":926364},\"end\":43124,\"start\":42885},{\"attributes\":{\"doi\":\"10.18653/v1/P17-1147\",\"id\":\"b20\",\"matched_paper_id\":26501419},\"end\":43911,\"start\":43126},{\"attributes\":{\"doi\":\"10.18653/v1/2020.emnlp-main.550\",\"id\":\"b21\",\"matched_paper_id\":215737187},\"end\":44714,\"start\":43913},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":215737187},\"end\":45289,\"start\":44716},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":207870430},\"end\":45729,\"start\":45291},{\"attributes\":{\"doi\":\"arXiv:2212.14024\",\"id\":\"b24\"},\"end\":46149,\"start\":45731},{\"attributes\":{\"id\":\"b25\"},\"end\":46320,\"start\":46151},{\"attributes\":{\"doi\":\"10.1162/tacl_a_00276\",\"id\":\"b26\"},\"end\":47112,\"start\":46322},{\"attributes\":{\"id\":\"b27\"},\"end\":47568,\"start\":47114},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":221005781},\"end\":48185,\"start\":47570},{\"attributes\":{\"doi\":\"arXiv:2212.10511\",\"id\":\"b29\"},\"end\":48636,\"start\":48187},{\"attributes\":{\"doi\":\"arXiv:2212.01349\",\"id\":\"b30\"},\"end\":48943,\"start\":48638},{\"attributes\":{\"id\":\"b31\"},\"end\":49295,\"start\":48945},{\"attributes\":{\"doi\":\"10.18653/v1/2021.naacl-main.466\",\"id\":\"b32\",\"matched_paper_id\":231815627},\"end\":50329,\"start\":49297},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":207178704},\"end\":50627,\"start\":50331},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":245218561},\"end\":51244,\"start\":50629},{\"attributes\":{\"doi\":\"arXiv:2206.10658\",\"id\":\"b35\"},\"end\":51592,\"start\":51246},{\"attributes\":{\"doi\":\"arXiv:2211.05100\",\"id\":\"b36\"},\"end\":52012,\"start\":51594},{\"attributes\":{\"id\":\"b37\"},\"end\":52200,\"start\":52014},{\"attributes\":{\"doi\":\"arXiv:2210.09150\",\"id\":\"b38\"},\"end\":52474,\"start\":52202},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":252917981},\"end\":52775,\"start\":52476},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":16299141},\"end\":53178,\"start\":52777},{\"attributes\":{\"doi\":\"arXiv:2212.09741\",\"id\":\"b41\"},\"end\":53568,\"start\":53180},{\"attributes\":{\"doi\":\"arXiv:2110.04725\",\"id\":\"b42\"},\"end\":53975,\"start\":53570},{\"attributes\":{\"doi\":\"arXiv:2211.12561\",\"id\":\"b43\"},\"end\":54357,\"start\":53977},{\"attributes\":{\"id\":\"b44\"},\"end\":54576,\"start\":54359},{\"attributes\":{\"doi\":\"10.18653/v1/2022.naacl-srw.7\",\"id\":\"b45\",\"matched_paper_id\":250391000},\"end\":55513,\"start\":54578},{\"attributes\":{\"id\":\"b46\"},\"end\":55839,\"start\":55515},{\"attributes\":{\"id\":\"b47\"},\"end\":56074,\"start\":55841},{\"attributes\":{\"doi\":\"arXiv:2205.01068\",\"id\":\"b48\"},\"end\":56444,\"start\":56076},{\"attributes\":{\"id\":\"b49\",\"matched_paper_id\":256389797},\"end\":58337,\"start\":56446},{\"attributes\":{\"id\":\"b50\"},\"end\":59837,\"start\":58339},{\"attributes\":{\"id\":\"b51\"},\"end\":63174,\"start\":59839},{\"attributes\":{\"id\":\"b52\"},\"end\":64414,\"start\":63176}]", "bib_title": "[{\"end\":30931,\"start\":30867},{\"end\":31439,\"start\":31402},{\"end\":32654,\"start\":32617},{\"end\":37844,\"start\":37784},{\"end\":38516,\"start\":38452},{\"end\":39457,\"start\":39410},{\"end\":39786,\"start\":39736},{\"end\":40971,\"start\":40885},{\"end\":41785,\"start\":41699},{\"end\":42074,\"start\":42008},{\"end\":42926,\"start\":42885},{\"end\":43215,\"start\":43126},{\"end\":43971,\"start\":43913},{\"end\":44774,\"start\":44716},{\"end\":45360,\"start\":45291},{\"end\":46187,\"start\":46151},{\"end\":47651,\"start\":47570},{\"end\":49399,\"start\":49297},{\"end\":50385,\"start\":50331},{\"end\":50681,\"start\":50629},{\"end\":52506,\"start\":52476},{\"end\":52808,\"start\":52777},{\"end\":54639,\"start\":54578},{\"end\":55906,\"start\":55841},{\"end\":57176,\"start\":56446},{\"end\":60637,\"start\":59839},{\"end\":63437,\"start\":63176}]", "bib_author": "[{\"end\":30478,\"start\":30466},{\"end\":30488,\"start\":30478},{\"end\":30500,\"start\":30488},{\"end\":30507,\"start\":30500},{\"end\":30521,\"start\":30507},{\"end\":30533,\"start\":30521},{\"end\":30550,\"start\":30533},{\"end\":30564,\"start\":30550},{\"end\":30573,\"start\":30564},{\"end\":30582,\"start\":30573},{\"end\":30945,\"start\":30933},{\"end\":30955,\"start\":30945},{\"end\":30967,\"start\":30955},{\"end\":30974,\"start\":30967},{\"end\":30988,\"start\":30974},{\"end\":31000,\"start\":30988},{\"end\":31023,\"start\":31000},{\"end\":31037,\"start\":31023},{\"end\":31046,\"start\":31037},{\"end\":31055,\"start\":31046},{\"end\":31450,\"start\":31441},{\"end\":31458,\"start\":31450},{\"end\":31467,\"start\":31458},{\"end\":31478,\"start\":31467},{\"end\":31490,\"start\":31478},{\"end\":31502,\"start\":31490},{\"end\":31517,\"start\":31502},{\"end\":31526,\"start\":31517},{\"end\":31536,\"start\":31526},{\"end\":31546,\"start\":31536},{\"end\":31557,\"start\":31546},{\"end\":31573,\"start\":31557},{\"end\":31584,\"start\":31573},{\"end\":31596,\"start\":31584},{\"end\":31605,\"start\":31596},{\"end\":31615,\"start\":31605},{\"end\":31626,\"start\":31615},{\"end\":31632,\"start\":31626},{\"end\":31642,\"start\":31632},{\"end\":31651,\"start\":31642},{\"end\":31659,\"start\":31651},{\"end\":31669,\"start\":31659},{\"end\":31679,\"start\":31669},{\"end\":31687,\"start\":31679},{\"end\":31696,\"start\":31687},{\"end\":31705,\"start\":31696},{\"end\":31715,\"start\":31705},{\"end\":31729,\"start\":31715},{\"end\":31740,\"start\":31729},{\"end\":31753,\"start\":31740},{\"end\":31762,\"start\":31753},{\"end\":31766,\"start\":31762},{\"end\":32665,\"start\":32656},{\"end\":32673,\"start\":32665},{\"end\":32682,\"start\":32673},{\"end\":32693,\"start\":32682},{\"end\":32705,\"start\":32693},{\"end\":32717,\"start\":32705},{\"end\":32732,\"start\":32717},{\"end\":32741,\"start\":32732},{\"end\":32751,\"start\":32741},{\"end\":32761,\"start\":32751},{\"end\":32772,\"start\":32761},{\"end\":32788,\"start\":32772},{\"end\":32799,\"start\":32788},{\"end\":32811,\"start\":32799},{\"end\":32820,\"start\":32811},{\"end\":32830,\"start\":32820},{\"end\":32841,\"start\":32830},{\"end\":32847,\"start\":32841},{\"end\":32857,\"start\":32847},{\"end\":32866,\"start\":32857},{\"end\":32874,\"start\":32866},{\"end\":32884,\"start\":32874},{\"end\":32894,\"start\":32884},{\"end\":32902,\"start\":32894},{\"end\":32911,\"start\":32902},{\"end\":32920,\"start\":32911},{\"end\":32930,\"start\":32920},{\"end\":32944,\"start\":32930},{\"end\":32955,\"start\":32944},{\"end\":32968,\"start\":32955},{\"end\":32977,\"start\":32968},{\"end\":32981,\"start\":32977},{\"end\":33572,\"start\":33564},{\"end\":33582,\"start\":33572},{\"end\":33589,\"start\":33582},{\"end\":33597,\"start\":33589},{\"end\":33620,\"start\":33597},{\"end\":33630,\"start\":33620},{\"end\":33641,\"start\":33630},{\"end\":33650,\"start\":33641},{\"end\":33660,\"start\":33650},{\"end\":33672,\"start\":33660},{\"end\":33679,\"start\":33672},{\"end\":33687,\"start\":33679},{\"end\":33698,\"start\":33687},{\"end\":33708,\"start\":33698},{\"end\":33718,\"start\":33708},{\"end\":33728,\"start\":33718},{\"end\":33739,\"start\":33728},{\"end\":33747,\"start\":33739},{\"end\":33755,\"start\":33747},{\"end\":33764,\"start\":33755},{\"end\":33774,\"start\":33764},{\"end\":33783,\"start\":33774},{\"end\":33793,\"start\":33783},{\"end\":33805,\"start\":33793},{\"end\":33815,\"start\":33805},{\"end\":33825,\"start\":33815},{\"end\":33835,\"start\":33825},{\"end\":33847,\"start\":33835},{\"end\":33859,\"start\":33847},{\"end\":33871,\"start\":33859},{\"end\":33881,\"start\":33871},{\"end\":33897,\"start\":33881},{\"end\":33907,\"start\":33897},{\"end\":33917,\"start\":33907},{\"end\":33926,\"start\":33917},{\"end\":33935,\"start\":33926},{\"end\":33943,\"start\":33935},{\"end\":33957,\"start\":33943},{\"end\":33967,\"start\":33957},{\"end\":33975,\"start\":33967},{\"end\":33987,\"start\":33975},{\"end\":33996,\"start\":33987},{\"end\":34006,\"start\":33996},{\"end\":34015,\"start\":34006},{\"end\":34025,\"start\":34015},{\"end\":34034,\"start\":34025},{\"end\":34046,\"start\":34034},{\"end\":34057,\"start\":34046},{\"end\":34067,\"start\":34057},{\"end\":34079,\"start\":34067},{\"end\":34089,\"start\":34079},{\"end\":34098,\"start\":34089},{\"end\":34110,\"start\":34098},{\"end\":34121,\"start\":34110},{\"end\":34131,\"start\":34121},{\"end\":34145,\"start\":34131},{\"end\":34158,\"start\":34145},{\"end\":34169,\"start\":34158},{\"end\":35113,\"start\":35105},{\"end\":35123,\"start\":35113},{\"end\":35130,\"start\":35123},{\"end\":35138,\"start\":35130},{\"end\":35161,\"start\":35138},{\"end\":35171,\"start\":35161},{\"end\":35182,\"start\":35171},{\"end\":35191,\"start\":35182},{\"end\":35201,\"start\":35191},{\"end\":35213,\"start\":35201},{\"end\":35220,\"start\":35213},{\"end\":35228,\"start\":35220},{\"end\":35239,\"start\":35228},{\"end\":35249,\"start\":35239},{\"end\":35259,\"start\":35249},{\"end\":35269,\"start\":35259},{\"end\":35280,\"start\":35269},{\"end\":35288,\"start\":35280},{\"end\":35296,\"start\":35288},{\"end\":35305,\"start\":35296},{\"end\":35315,\"start\":35305},{\"end\":35324,\"start\":35315},{\"end\":35334,\"start\":35324},{\"end\":35346,\"start\":35334},{\"end\":35356,\"start\":35346},{\"end\":35366,\"start\":35356},{\"end\":35376,\"start\":35366},{\"end\":35388,\"start\":35376},{\"end\":35400,\"start\":35388},{\"end\":35412,\"start\":35400},{\"end\":35422,\"start\":35412},{\"end\":35438,\"start\":35422},{\"end\":35448,\"start\":35438},{\"end\":35458,\"start\":35448},{\"end\":35467,\"start\":35458},{\"end\":35476,\"start\":35467},{\"end\":35484,\"start\":35476},{\"end\":35498,\"start\":35484},{\"end\":35508,\"start\":35498},{\"end\":35516,\"start\":35508},{\"end\":35528,\"start\":35516},{\"end\":35537,\"start\":35528},{\"end\":35547,\"start\":35537},{\"end\":35556,\"start\":35547},{\"end\":35566,\"start\":35556},{\"end\":35575,\"start\":35566},{\"end\":35587,\"start\":35575},{\"end\":35598,\"start\":35587},{\"end\":35608,\"start\":35598},{\"end\":35620,\"start\":35608},{\"end\":35630,\"start\":35620},{\"end\":35639,\"start\":35630},{\"end\":35651,\"start\":35639},{\"end\":35662,\"start\":35651},{\"end\":35672,\"start\":35662},{\"end\":35686,\"start\":35672},{\"end\":35699,\"start\":35686},{\"end\":35710,\"start\":35699},{\"end\":36657,\"start\":36644},{\"end\":36667,\"start\":36657},{\"end\":36677,\"start\":36667},{\"end\":36686,\"start\":36677},{\"end\":36696,\"start\":36686},{\"end\":36707,\"start\":36696},{\"end\":36717,\"start\":36707},{\"end\":36728,\"start\":36717},{\"end\":36738,\"start\":36728},{\"end\":36750,\"start\":36738},{\"end\":37053,\"start\":37042},{\"end\":37060,\"start\":37053},{\"end\":37071,\"start\":37060},{\"end\":37079,\"start\":37071},{\"end\":37086,\"start\":37079},{\"end\":37095,\"start\":37086},{\"end\":37101,\"start\":37095},{\"end\":37109,\"start\":37101},{\"end\":37121,\"start\":37109},{\"end\":37131,\"start\":37121},{\"end\":37424,\"start\":37413},{\"end\":37431,\"start\":37424},{\"end\":37442,\"start\":37431},{\"end\":37450,\"start\":37442},{\"end\":37457,\"start\":37450},{\"end\":37466,\"start\":37457},{\"end\":37472,\"start\":37466},{\"end\":37480,\"start\":37472},{\"end\":37492,\"start\":37480},{\"end\":37502,\"start\":37492},{\"end\":37856,\"start\":37846},{\"end\":37867,\"start\":37856},{\"end\":37877,\"start\":37867},{\"end\":37885,\"start\":37877},{\"end\":38525,\"start\":38518},{\"end\":38537,\"start\":38525},{\"end\":38546,\"start\":38537},{\"end\":38557,\"start\":38546},{\"end\":38566,\"start\":38557},{\"end\":38576,\"start\":38566},{\"end\":38585,\"start\":38576},{\"end\":38591,\"start\":38585},{\"end\":38600,\"start\":38591},{\"end\":38613,\"start\":38600},{\"end\":38624,\"start\":38613},{\"end\":38635,\"start\":38624},{\"end\":38646,\"start\":38635},{\"end\":38656,\"start\":38646},{\"end\":38665,\"start\":38656},{\"end\":38673,\"start\":38665},{\"end\":38684,\"start\":38673},{\"end\":38692,\"start\":38684},{\"end\":38701,\"start\":38692},{\"end\":38716,\"start\":38701},{\"end\":38730,\"start\":38716},{\"end\":39466,\"start\":39459},{\"end\":39473,\"start\":39466},{\"end\":39481,\"start\":39473},{\"end\":39492,\"start\":39481},{\"end\":39500,\"start\":39492},{\"end\":39504,\"start\":39500},{\"end\":39801,\"start\":39788},{\"end\":39810,\"start\":39801},{\"end\":39820,\"start\":39810},{\"end\":39827,\"start\":39820},{\"end\":39838,\"start\":39827},{\"end\":39846,\"start\":39838},{\"end\":39860,\"start\":39846},{\"end\":40231,\"start\":40219},{\"end\":40243,\"start\":40231},{\"end\":40253,\"start\":40243},{\"end\":40268,\"start\":40253},{\"end\":40275,\"start\":40268},{\"end\":40289,\"start\":40275},{\"end\":40302,\"start\":40289},{\"end\":40317,\"start\":40302},{\"end\":40326,\"start\":40317},{\"end\":40335,\"start\":40326},{\"end\":40605,\"start\":40599},{\"end\":40612,\"start\":40605},{\"end\":40620,\"start\":40612},{\"end\":40627,\"start\":40620},{\"end\":40638,\"start\":40627},{\"end\":40645,\"start\":40638},{\"end\":40656,\"start\":40645},{\"end\":40984,\"start\":40973},{\"end\":40993,\"start\":40984},{\"end\":41798,\"start\":41787},{\"end\":41807,\"start\":41798},{\"end\":42087,\"start\":42076},{\"end\":42096,\"start\":42087},{\"end\":42108,\"start\":42096},{\"end\":42118,\"start\":42108},{\"end\":42132,\"start\":42118},{\"end\":42142,\"start\":42132},{\"end\":42151,\"start\":42142},{\"end\":42528,\"start\":42517},{\"end\":42537,\"start\":42528},{\"end\":42547,\"start\":42537},{\"end\":42559,\"start\":42547},{\"end\":42570,\"start\":42559},{\"end\":42580,\"start\":42570},{\"end\":42594,\"start\":42580},{\"end\":42604,\"start\":42594},{\"end\":42614,\"start\":42604},{\"end\":42623,\"start\":42614},{\"end\":42939,\"start\":42928},{\"end\":42948,\"start\":42939},{\"end\":42957,\"start\":42948},{\"end\":43226,\"start\":43217},{\"end\":43234,\"start\":43226},{\"end\":43242,\"start\":43234},{\"end\":43257,\"start\":43242},{\"end\":43986,\"start\":43973},{\"end\":43994,\"start\":43986},{\"end\":44001,\"start\":43994},{\"end\":44010,\"start\":44001},{\"end\":44016,\"start\":44010},{\"end\":44026,\"start\":44016},{\"end\":44034,\"start\":44026},{\"end\":44041,\"start\":44034},{\"end\":44789,\"start\":44776},{\"end\":44797,\"start\":44789},{\"end\":44804,\"start\":44797},{\"end\":44813,\"start\":44804},{\"end\":44819,\"start\":44813},{\"end\":44829,\"start\":44819},{\"end\":44837,\"start\":44829},{\"end\":44844,\"start\":44837},{\"end\":45376,\"start\":45362},{\"end\":45384,\"start\":45376},{\"end\":45396,\"start\":45384},{\"end\":45411,\"start\":45396},{\"end\":45419,\"start\":45411},{\"end\":45423,\"start\":45419},{\"end\":45838,\"start\":45827},{\"end\":45851,\"start\":45838},{\"end\":45859,\"start\":45851},{\"end\":45867,\"start\":45859},{\"end\":45876,\"start\":45867},{\"end\":45885,\"start\":45876},{\"end\":45896,\"start\":45885},{\"end\":46201,\"start\":46189},{\"end\":46207,\"start\":46201},{\"end\":46213,\"start\":46207},{\"end\":46337,\"start\":46322},{\"end\":46349,\"start\":46337},{\"end\":46361,\"start\":46349},{\"end\":46372,\"start\":46361},{\"end\":46382,\"start\":46372},{\"end\":46393,\"start\":46382},{\"end\":46404,\"start\":46393},{\"end\":46418,\"start\":46404},{\"end\":46428,\"start\":46418},{\"end\":46435,\"start\":46428},{\"end\":46448,\"start\":46435},{\"end\":46457,\"start\":46448},{\"end\":46467,\"start\":46457},{\"end\":46479,\"start\":46467},{\"end\":46488,\"start\":46479},{\"end\":46501,\"start\":46488},{\"end\":46507,\"start\":46501},{\"end\":46517,\"start\":46507},{\"end\":47189,\"start\":47180},{\"end\":47198,\"start\":47189},{\"end\":47208,\"start\":47198},{\"end\":47219,\"start\":47208},{\"end\":47232,\"start\":47219},{\"end\":47241,\"start\":47232},{\"end\":47252,\"start\":47241},{\"end\":47261,\"start\":47252},{\"end\":47271,\"start\":47261},{\"end\":47286,\"start\":47271},{\"end\":47296,\"start\":47286},{\"end\":47305,\"start\":47296},{\"end\":47662,\"start\":47653},{\"end\":47675,\"start\":47662},{\"end\":47685,\"start\":47675},{\"end\":48318,\"start\":48308},{\"end\":48326,\"start\":48318},{\"end\":48335,\"start\":48326},{\"end\":48342,\"start\":48335},{\"end\":48356,\"start\":48342},{\"end\":48368,\"start\":48356},{\"end\":48645,\"start\":48638},{\"end\":48652,\"start\":48645},{\"end\":48661,\"start\":48652},{\"end\":48669,\"start\":48661},{\"end\":48679,\"start\":48669},{\"end\":48693,\"start\":48679},{\"end\":48708,\"start\":48693},{\"end\":49001,\"start\":48995},{\"end\":49007,\"start\":49001},{\"end\":49013,\"start\":49007},{\"end\":49020,\"start\":49013},{\"end\":49032,\"start\":49020},{\"end\":49038,\"start\":49032},{\"end\":49048,\"start\":49038},{\"end\":49056,\"start\":49048},{\"end\":49066,\"start\":49056},{\"end\":49075,\"start\":49066},{\"end\":49082,\"start\":49075},{\"end\":49086,\"start\":49082},{\"end\":49407,\"start\":49401},{\"end\":49415,\"start\":49407},{\"end\":49422,\"start\":49415},{\"end\":49429,\"start\":49422},{\"end\":49436,\"start\":49429},{\"end\":49446,\"start\":49436},{\"end\":49454,\"start\":49446},{\"end\":49460,\"start\":49454},{\"end\":49467,\"start\":49460},{\"end\":49471,\"start\":49467},{\"end\":50400,\"start\":50387},{\"end\":50412,\"start\":50400},{\"end\":50692,\"start\":50683},{\"end\":50702,\"start\":50692},{\"end\":50712,\"start\":50702},{\"end\":51260,\"start\":51248},{\"end\":51269,\"start\":51260},{\"end\":51281,\"start\":51269},{\"end\":51296,\"start\":51281},{\"end\":51306,\"start\":51296},{\"end\":51316,\"start\":51306},{\"end\":51604,\"start\":51594},{\"end\":51611,\"start\":51604},{\"end\":51620,\"start\":51611},{\"end\":51631,\"start\":51620},{\"end\":51639,\"start\":51631},{\"end\":51650,\"start\":51639},{\"end\":51662,\"start\":51650},{\"end\":51676,\"start\":51662},{\"end\":51684,\"start\":51676},{\"end\":51693,\"start\":51684},{\"end\":52059,\"start\":52052},{\"end\":52070,\"start\":52059},{\"end\":52084,\"start\":52070},{\"end\":52099,\"start\":52084},{\"end\":52208,\"start\":52202},{\"end\":52215,\"start\":52208},{\"end\":52223,\"start\":52215},{\"end\":52231,\"start\":52223},{\"end\":52239,\"start\":52231},{\"end\":52254,\"start\":52239},{\"end\":52261,\"start\":52254},{\"end\":52265,\"start\":52261},{\"end\":52514,\"start\":52508},{\"end\":52521,\"start\":52514},{\"end\":52529,\"start\":52521},{\"end\":52537,\"start\":52529},{\"end\":52545,\"start\":52537},{\"end\":52560,\"start\":52545},{\"end\":52567,\"start\":52560},{\"end\":52571,\"start\":52567},{\"end\":52821,\"start\":52810},{\"end\":52832,\"start\":52821},{\"end\":52841,\"start\":52832},{\"end\":52851,\"start\":52841},{\"end\":53186,\"start\":53180},{\"end\":53195,\"start\":53186},{\"end\":53203,\"start\":53195},{\"end\":53209,\"start\":53203},{\"end\":53222,\"start\":53209},{\"end\":53232,\"start\":53222},{\"end\":53243,\"start\":53232},{\"end\":53258,\"start\":53243},{\"end\":53264,\"start\":53258},{\"end\":53661,\"start\":53655},{\"end\":53669,\"start\":53661},{\"end\":53675,\"start\":53669},{\"end\":53684,\"start\":53675},{\"end\":53692,\"start\":53684},{\"end\":53699,\"start\":53692},{\"end\":53705,\"start\":53699},{\"end\":53712,\"start\":53705},{\"end\":53719,\"start\":53712},{\"end\":53725,\"start\":53719},{\"end\":53989,\"start\":53977},{\"end\":54003,\"start\":53989},{\"end\":54010,\"start\":54003},{\"end\":54019,\"start\":54010},{\"end\":54031,\"start\":54019},{\"end\":54040,\"start\":54031},{\"end\":54049,\"start\":54040},{\"end\":54064,\"start\":54049},{\"end\":54071,\"start\":54064},{\"end\":54428,\"start\":54413},{\"end\":54434,\"start\":54428},{\"end\":54647,\"start\":54641},{\"end\":55605,\"start\":55599},{\"end\":55613,\"start\":55605},{\"end\":55621,\"start\":55613},{\"end\":55627,\"start\":55621},{\"end\":55633,\"start\":55627},{\"end\":55643,\"start\":55633},{\"end\":55650,\"start\":55643},{\"end\":55658,\"start\":55650},{\"end\":55667,\"start\":55658},{\"end\":55917,\"start\":55908},{\"end\":55925,\"start\":55917},{\"end\":55940,\"start\":55925},{\"end\":56085,\"start\":56076},{\"end\":56095,\"start\":56085},{\"end\":56104,\"start\":56095},{\"end\":56115,\"start\":56104},{\"end\":56123,\"start\":56115},{\"end\":56131,\"start\":56123},{\"end\":56140,\"start\":56131},{\"end\":56148,\"start\":56140},{\"end\":56154,\"start\":56148},{\"end\":56163,\"start\":56154},{\"end\":57187,\"start\":57178},{\"end\":57194,\"start\":57187},{\"end\":57201,\"start\":57194},{\"end\":57205,\"start\":57201}]", "bib_venue": "[{\"end\":30464,\"start\":30400},{\"end\":31099,\"start\":31055},{\"end\":31815,\"start\":31766},{\"end\":32997,\"start\":32981},{\"end\":36805,\"start\":36766},{\"end\":37192,\"start\":37147},{\"end\":37563,\"start\":37518},{\"end\":37988,\"start\":37919},{\"end\":38790,\"start\":38746},{\"end\":39548,\"start\":39504},{\"end\":39912,\"start\":39860},{\"end\":40217,\"start\":40171},{\"end\":40713,\"start\":40672},{\"end\":41142,\"start\":41022},{\"end\":41820,\"start\":41807},{\"end\":42192,\"start\":42151},{\"end\":42515,\"start\":42457},{\"end\":42986,\"start\":42957},{\"end\":43364,\"start\":43277},{\"end\":44166,\"start\":44072},{\"end\":44938,\"start\":44844},{\"end\":45475,\"start\":45423},{\"end\":45825,\"start\":45731},{\"end\":46226,\"start\":46213},{\"end\":46662,\"start\":46537},{\"end\":47178,\"start\":47114},{\"end\":47805,\"start\":47685},{\"end\":48306,\"start\":48187},{\"end\":48762,\"start\":48724},{\"end\":48993,\"start\":48945},{\"end\":49644,\"start\":49502},{\"end\":50460,\"start\":50412},{\"end\":50854,\"start\":50712},{\"end\":51765,\"start\":51709},{\"end\":52050,\"start\":52014},{\"end\":52311,\"start\":52281},{\"end\":52584,\"start\":52571},{\"end\":52907,\"start\":52851},{\"end\":53341,\"start\":53280},{\"end\":53653,\"start\":53570},{\"end\":54135,\"start\":54087},{\"end\":54411,\"start\":54359},{\"end\":54844,\"start\":54675},{\"end\":55597,\"start\":55515},{\"end\":55947,\"start\":55940},{\"end\":56223,\"start\":56179},{\"end\":57253,\"start\":57205},{\"end\":58559,\"start\":58339},{\"end\":60808,\"start\":60639},{\"end\":63533,\"start\":63439},{\"end\":33009,\"start\":32999},{\"end\":38020,\"start\":37990},{\"end\":41249,\"start\":41144},{\"end\":41829,\"start\":41822},{\"end\":43455,\"start\":43366},{\"end\":44247,\"start\":44168},{\"end\":45019,\"start\":44940},{\"end\":47912,\"start\":47807},{\"end\":49779,\"start\":49646},{\"end\":50983,\"start\":50856},{\"end\":52593,\"start\":52586},{\"end\":52923,\"start\":52909},{\"end\":55036,\"start\":54846},{\"end\":60851,\"start\":60810}]"}}}, "year": 2023, "month": 12, "day": 17}