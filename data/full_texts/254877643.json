{"id": 254877643, "updated": "2023-05-19 04:54:11.193", "metadata": {"title": "Reinforced Clari\ufb01cation Question Generation with Defeasibility Rewards for Disambiguating Social and Moral Situations", "authors": "[{\"first\":\"Valentina\",\"last\":\"Pyatkin\",\"middle\":[]},{\"first\":\"Jena\",\"last\":\"Hwang\",\"middle\":[\"D.\"]},{\"first\":\"Vivek\",\"last\":\"Srikumar\",\"middle\":[]},{\"first\":\"Ximing\",\"last\":\"Lu\",\"middle\":[]},{\"first\":\"Liwei\",\"last\":\"Jiang\",\"middle\":[]},{\"first\":\"Yejin\",\"last\":\"Choi\",\"middle\":[]},{\"first\":\"Chandra\",\"last\":\"Bhagavatula\",\"middle\":[]}]", "venue": "ArXiv", "journal": "ArXiv", "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "Context is vital for commonsense moral reasoning. \u201cLying to a friend\" is wrong if it is meant to deceive them, but may be morally okay if it is intended to protect them. Such nuanced but salient contextual information can potentially \ufb02ip the moral judgment of an ac-tion. Thus, we present C LARIFY D ELPHI , an interactive system that elicits missing contexts of a moral situation by generating clari\ufb01cation questions such as \u201cWhy did you lie to your friend?\". Our approach is inspired by the observation that questions whose potential answers lead to diverging moral judgments are the most informative. We learn to generate questions using Reinforcement Learning, by maximiz-ing the divergence between moral judgements of hypothetical answers to a question. Human evaluation shows that our system generates more relevant , informative and defeasible questions compared to other question generation baselines. C LARIFY D ELPHI assists informed moral reasoning processes by seek-ing additional morally consequential context to disambiguate social and moral situations.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/corr/abs-2212-10409", "doi": "10.48550/arxiv.2212.10409"}}, "content": {"source": {"pdf_hash": "9a0ffb6156763be319a1ea39c9fac4080bc61182", "pdf_src": "Arxiv", "pdf_uri": "[\"https://export.arxiv.org/pdf/2212.10409v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "bcb533d5b2370b0c6a4c90741a590d9f015a4e46", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/9a0ffb6156763be319a1ea39c9fac4080bc61182.txt", "contents": "\nReinforced Clarification Question Generation with Defeasibility Rewards for Disambiguating Social and Moral Situations\n\n\nValentina Pyatkin pyatkiv@biu.ac.il \nIlan University \u2663 University of Utah\nAllen Institute for Artificial Intelligence \u2665 Paul G. Allen School of Computer Science & Engineering\nUniversity of Washington\n\n\nJena D Hwang \nIlan University \u2663 University of Utah\nAllen Institute for Artificial Intelligence \u2665 Paul G. Allen School of Computer Science & Engineering\nUniversity of Washington\n\n\nVivek Srikumar \nIlan University \u2663 University of Utah\nAllen Institute for Artificial Intelligence \u2665 Paul G. Allen School of Computer Science & Engineering\nUniversity of Washington\n\n\n\u2660 \u2663 Ximing \nIlan University \u2663 University of Utah\nAllen Institute for Artificial Intelligence \u2665 Paul G. Allen School of Computer Science & Engineering\nUniversity of Washington\n\n\nLu \u2665 \nIlan University \u2663 University of Utah\nAllen Institute for Artificial Intelligence \u2665 Paul G. Allen School of Computer Science & Engineering\nUniversity of Washington\n\n\nLiwei Jiang \nIlan University \u2663 University of Utah\nAllen Institute for Artificial Intelligence \u2665 Paul G. Allen School of Computer Science & Engineering\nUniversity of Washington\n\n\n\u2665 \nIlan University \u2663 University of Utah\nAllen Institute for Artificial Intelligence \u2665 Paul G. Allen School of Computer Science & Engineering\nUniversity of Washington\n\n\nYejin Choi \nIlan University \u2663 University of Utah\nAllen Institute for Artificial Intelligence \u2665 Paul G. Allen School of Computer Science & Engineering\nUniversity of Washington\n\n\n\u2665 \nIlan University \u2663 University of Utah\nAllen Institute for Artificial Intelligence \u2665 Paul G. Allen School of Computer Science & Engineering\nUniversity of Washington\n\n\nChandra Bhagavatula \nIlan University \u2663 University of Utah\nAllen Institute for Artificial Intelligence \u2665 Paul G. Allen School of Computer Science & Engineering\nUniversity of Washington\n\n\nReinforced Clarification Question Generation with Defeasibility Rewards for Disambiguating Social and Moral Situations\n\nContext is vital for commonsense moral reasoning.\n\nIntroduction\n\nReasoning about a social or moral situation and its interpretation involves thinking about different contexts. Some of which could either support or overturn the initial moral judgement. The situation \"offering a cup of coffee\" would generally receive a positive moral judgment. Further context can help strengthen it (e.g., offering it to a work colleague is kind) or weaken it (e.g., offering coffee to a toddler is an irresponsible act).\n\nEliciting more salient context for various moral situations is non trivial. A natural way to do so is by asking questions. Current moral reasoning models, such as Delphi (Jiang et al., 2022), generate moral judgements given only a situation as input, such as \"offering a cup of coffee\". But they \"offering a cup of coffee\"\n\n\nQuestion Generation\n\nWho did you offer it to?\n\nWhen did you offer it?\n\nin the morning to a toddler to a work colleague Figure 1: The CLARIFYDELPHI question generation approach is trained via reinforcement learning. The reward simulates a set of possible (defeasible) answers to the questions and, using Delphi for feedback, optimizes for maximally diverging answers.\n\nare not able to inquire for more nuanced context, which is left unsaid but could potentially alter the model's predictions. We propose to disambiguate situations through interaction, in a conversational setting between a user and a clarification question generation system. For this purpose we aim to generate questions whose answers add consequential context for making moral judgements.\n\nWe propose a method for clarification question generation based on reinforcement learning. Using Proximal Policy Optimization (PPO) (Schulman et al., 2017;Ouyang et al., 2022) we optimize for questions that could result in morally salient answers. The system \"imagines\" answers to a generated question. As shown in Fig. 1, the reward is calculated by comparing the probability distributions an existing moral reasoning system assigns to the imagined answers. The intuition behind our approach is that we want to optimize for questions that could lead to maximally divergent answers in terms of moral judgements provided by Delphi. While Delphi is far from a perfect moral reasoner, using a trained model allows us to not having to rely on supervised training data for reward computation. Our goal is also to generate questions that can expose model-specific ambiguities. Two possible answers to the question 'Who did you offer a cup of coffee to?' are to a work colleafue or to a toddler. Both answers lead to a difference in moral judgements, captured by the Jensen-Shannon divergence. The question 'When did you offer it?' on the other hand leads to inconsequential answers in terms of moral decision processes.\n\nThe evaluations shows that our approach outperforms other clarification question generation baselines, with the generated questions leading to more consequential answers. We additionally evaluate different types of fine-tuned RL policies and find that a supervised policy trained on a clarification question dataset works best for producing informative questions. Lastly we show that questions help with generating defeasible updates.\n\nOur contributions are as follows. We introduce the task of clarification question generation for social and moral situations, and define a new type of question-relevance. We are additionally releasing a dataset of about 30k crowdsourced clarification questions, a question-enriched defeasible inference dataset and the trained models with their code. 1\n\n\nProblem Setup\n\nGiven a situation, such as \"lie to my friend\", we aim to generate question(s) that are the most relevant in terms of being able to uncover the most consequential context with respect to making a social or moral judgement. While situations could evoke a multitude of potential questions, the following work is concerned with predicting questions whose answers are likely to be consequential. We define consequential questions to be questions whose possible answers could function as either weakeners or strengtheners of the default judgement. The terms weakener and strengthener come from the concept of defeasible inference (Rudinger et al., 2020), which defines a way of reasoning that takes into consideration (new) evidence which could either support (e.g. strengthen) or cancel/weaken an initial inference.\n\nFormally, the task is to predict a question q given a base-situation s. The base situation has a default moral judgement j. For every input tuple of (s i , q i , j i ) there is a hypothetical set of weakening answers A W and a hypothetical set of strengthening answers A S . Adding the additional information obtained from any q i and a i to the base situation s i results in an updated situation s ui , with an updated moral judgement j ui .\n\n\nApproach\n\nOur approach is based on a pipeline consisting of various components which will be described in the following sections. These components are wrapped up in an RL algorithm, with Section 3.2 describing the policy and Section 3.4 describing the reward.\n\n\nCollecting a Dataset of Clarification Questions\n\nIn order to bootstrap a question generation system, we collected a dataset of clarification questions for social and moral situations. The situations are sampled from SOCIAL-CHEM-101 (Forbes et al., 2020) and the COMMONSENSE NORM BANK (Jiang et al., 2022). This dataset consists of crowdsourced questions, enriched with questions generated by GPT-3 (Brown et al., 2020), with about 33k questions for train and about 2500 questions for dev and test respectively. We call the dataset \u03b4-CLARIFY.\n\nA Crowdsourced Dataset of Clarification Questions We crowdsource clarification questions by showing turkers a situation and instructing them to write a clarification question they would ask a colleague that came asking for advice about the situation. 2 Each situation was presented to 5 annotators, resulting in 5 questions per situation. Annotations are collected on Amazon Mechanical Turk, paying on average $15 per hour. We first presented annotators with an open paid qualification task, which we manually evaluated, and then granted a qualification to 145 well-performing annotators.\n\nSilver Data from Defeasible Inference The \u03b4-SOCIAL part of the defeasible inference dataset from Rudinger et al. (2020) consists of (social-) situations together with their default judgement, such as \"It is good to protect your kids\", and updates which weaken (\"Your protection is overbearing\") or strengthen (\"Your child is in a dangerous situation.\") the judgement. These updates could be viewed as potential answers to an implicit question about the base situation, e.g. What are you protecting your child from? -\"Your child is in a dangerous situation.\" We prompt GPT-3 (textdavinci-003) (Brown et al., 2020) to generate these questions in a 5-shot manner, conditioned on the situation and the answer. Fig. 2 shows that the most frequent WH-word used in the crowdsourced questions is what, followed by how and why. Polar (yes/no) questions appear less frequently, likely due to the instructions Turkers received about avoiding these unless no other suitable question comes to mind. 3 tipping people decently Jeff ignores the comment and laughs about it with his boss What did they do for you? What was the comment? Can you afford to tip?\n\n\nDataset Analysis\n\nWhat was the comment? Was the service good?\n\nWhat was the comment? Did the people perform the service adequately?\n\nWhat was the comment?\n\nDo you always tip people well regardless of the service quality?\n\nWho made the comment they were laughing at?  In only 10% of the situations more than 1 Turker asked exactly the same question, but in 90% of sit-uations at least 2 or more questions used the same WH-word and in 8% of the situations all 5 Turkers used the same Wh-word to start the question. This shows that we managed to collect a diverse dataset, which indicates that usually, for a given situation, there is more than one possible salient clarification question to be asked. For the situation \"tipping people decently\" in Tab. 1, all five Turkers chose to start their questions differently. Nevertheless, three out of these five questions ask in one way or the other about the service quality. For the other situation in Tab. 1 4/5 Turkers asked for a specification \"What was the comment?\" and 1 Turker asked about the missing agent role. It is important to note that even if Turkers asked different questions, they might still all be valid clarification questions for moral judgements.\n\nWhile the silver questions, generated by GPT-3 on the defeasible inference dataset, also predominantly start with what ( Fig. 3), why questions are more frequent than how questions, compared to the crowdsourced dataset. The silver questions are generated by conditioning on a weakener or strengthener update to a situation. Since we aim to predict defeasible questions, the most desirable silver questions are those whose answers are both weakeners and strengtheners. In the silver data, 53% of situations have at least one question that has been generated by GPT-3 for both weakener and strengthener updates. The situation \"Your kids should be your number one priority\", for example, has the same question for the weakener update \"They are adult children living on their own with their own families.\" and the strengthener update \"Your children are babies and toddlers.\": What are you kids' ages? Interestingly, when looking only at the subset of forking-path questions in the silver data, we find that the most frequent question start is 'why'. This suggests that it is easiest to come up with both weakener and strengthener answers to why-questions.\n\n\nSupervised Question Generation\n\nThe first sub component is a basic question generation system that outputs a question conditioned on a situation.q = arg max q P (q|s)\n\nWe fine-tune T5-large (Raffel et al., 2020b) on our clarification questions dataset \u03b4-CLARIFY.\n\n\nHypothetical Answer Simulation\n\nGiven a situation s i and the generated question q i (Section 3.2) we want to predict a weakenerstrengthener answer pair a w and a s :\na u = arg max a P (a u |s, q, u)\nWith u \u2208 {weakener, strengthener}.\n\nPrompting One way to elicit a set of opposing answers is through prompting. We instruct GPT-3 to provide a so-called \"bad\" and a so-called \"good\" answer to a question about a situation. For the situation \"learning how to take a joke\" and the question What was the joke?, the two answers could be:\"it was a lighthearted joke among friends\" and \"it was an offensive joke\". In order to determine which of the answers is a weakener and which a strengthener, we compare the difference in Delphi's judgement for s and s + a good or s + a bad .\n\n\nSupervised Answer Generation\n\nThe answergeneration model is trained on the \u03b4-SOCIAL defeasible inference dataset which we enriched with questions (Section 3.1). The input/output of the model looks as follows:\n\nInput <Judgement> + <Situation>, TYPE: <Weakener/Strengthener>, QUESTION: <Question> Output <Answer> Instantiated this could look as follows:\n\nInput It's bad to be a snitch, TYPE: Weakener, QUESTION: Why would being a snitch be beneficial? Output doing so would save someones life or wellbeing.\n\nThe crucial element in the input is the update type, as it allows to generate two types of answers for the same situation and question.\n\nWe train the answer generation model (T5-large) on 77k instances from the question-enriched \u03b4-SOCIAL dataset and about 4k instances obtained through prompting.\n\n\nQuestion Selection\n\nAs a reward for generating a question, we aim to quantify how well the generated questions are able to elicit consequential answers. For this purpose we query Delphi (Jiang et al., 2022) for feedback, using situations updated with answers.\n\n\nSentence Fusion\n\nTo create an updated situation that sounds natural and can be used to query Delphi, the situation s, question q i and answer (both a w and a s separately) have to be fused together into s ui . For example:\n\nSituation changing behavior when drinking Question How do you change your behavior? Answer you become rude Fusing these three would result in the following updated situation: \"changing behavior when drinking by becoming rude\". For that purpose we use GPT-3 (text-curie-001), showing it 4 fusion in-context examples.\n\nDelphi for Feedback Delphi is then queried with the updated situation s ui to produce a judgement. Besides the text output, Delphi also provides a probability distribution over three classes: bad, ok, good. Since Delphi is based on a Seq2Seq model (namely T5), the classification labels are encoded in special tokens. The probability scores of the three categorical classes are thus the probabilities of the tokens representing each of the three classes, normalized by their sum.\n\n\nJS-Divergence\n\nIn order to assess whether the simulated weakener and strengthener answers to the generated questions lead to varying judgement, we calculate the Jensen-Shannon divergence between the Delphi probability distributions j w and j s obtained from two updated situations originating from answers to the same question: JSD(P jw ||P js ).\n\n\nPPO\n\nWe aim to optimize for questions that lead to maximally divergent answers. For that we define a reward function which uses the previously described JS-Divergence, between the Delphi probability distribution of the weakener updated situation and the strengthener updated situation :\nr(s, q, a w , a s ) = JSD(P jw ||P js )\nFrom the RL perspective, the question generation model p(q|s; \u03b8) (Section 3.2) can be viewed as a policy, which produces actions (in the form of question generations) given states (in the form of given situations).\n\nWe maximize the reward using Proximal Policy Optimization (PPO) (Schulman et al., 2017) as our RL algorithm, which previous works have shown to be suitable for NLG tasks (Liu et al., 2022b;Ramamurthy et al., 2022). Our implementation of PPO is an adaptions of Ouyang et al. (2022)'s.\n\nWhen computing reward during training, for each generated question we filter out all its generated answers which either contradict or are entailed (e.g. no new information) by the given situation. We use WaNLI (Liu et al., 2022a) as an off-theshelf NLI model.\n\n\nBaselines\n\nWe compare the RL approach with four other baselines.\n\nQuestion Generation Without RL To assess what additional improvements the RL model provides, we report performance of the supervised question generation model on its own, described in Section 3.2. We decode using nucleus sampling with top-p= 0.6.\n\nPipelines with Question Selection The other two baselines are based on a pipeline approach where, as the first step, a diverse set of questions is generated for a given situation and then, as the second step, the best question is selected according to a score.\n\nIn order to generate a diverse set of questions we fine-tune T5 on \u03b4-CLARIFY, conditioned on a slightly modified input compared to the model from Section 3.2.\n\nInput <Situation>. QUESTION: <wh-word>\n\nOutput <Question> By also conditioning on the first wh-word of the question it is possible to generate different questions. During inference we generate questions for 14 different question starts. 4 We propose two approaches to scoring and ranking these questions.\n\nDiscriminator We train a discriminator classifier which labels these questions as either relevant or irrelevant to a given situation. We then choose the question that has been assigned the relevant label with the highest probability.\n\nThe discriminator is a binary classifier based on DeBERTa (He et al., 2020). The positive examples are situations and their respective 5 questions written by annotators. The negative question examples are sampled from other situations in the same cluster, where each negative question has a ROUGE score \u2265 0.5 with one of the gold question. This type of sampling ensures that the relevant and irrelevant questions are similar enough in order for the model not to overfit on token matching between situation and question.\n\nDivergence Ranking We run the hypothetical answer simulation with feedback from Delphi for each question in the set. This process is the same as the reward function of the RL approach, except that the JS-divergence score is used to rank the questions instead of being used as a reward for question generation. We call this baseline pipeline.\n\nWhy-Baseline We saw in Section 3.1, that questions conditioned on weakener/strengthener updates are usually causal questions. Using the same input/output configuration as in the pipeline baseline, we generate a why-question for each situation.\n\n\nEvaluation and Analysis\n\n\nHuman Evaluation\n\nAutomatic evaluation of questions and their usefulness for clarifying moral situations is tricky. While we do have gold reference questions, we have shown that humans will produce diverse questions for the same situation (Section 3.1) and just because a question does not appear in the reference set does not necessarily indicate that it is not a consequential question. We therefore perform human evaluation of the models' outputs on Amazon Mechanical Turk on the 500 test set instances from \u03b4-CLARIFY. Given a situation and a question Turkers are asked to rate the question along three different attributes:\n\nGrammaticality Is the question grammatical? -yes/no Relevance Does the question fit the situation and is it plausible that someone might ask this question? -very relevant/somewhat relevant/entirely irrelevant Informativeness Can the question lead to new information or does it ask about things already mentioned in the situation? very/somewhat/uninformative Additionally, and most importantly, we aim to evaluate the defeasibility of the questions, e.g. how well the generated questions can elicit weakener or strengthener answers. For this purpose Turkers are given a situation with a question and are first asked to judge this situation (generally ok vs. generally not ok). They then need to say whether they can think of an answer to the question which might support their judgement and then also whether they can think of an answer which would flip their judgement.\n\n\nResults of Human Evaluation\n\nWe first run the grammaticality, relevance and informativeness evaluation. All questions which are given the lowest rating (e.g. irrelevant and/or uninformative) by at least two annotators are excluded from the second evaluation. We found that it does not make sense to ask about defeasibility for questions which already are irrelevant or uninformative: A question that asks about information already present in the base situation will not be able to elicit additional weakening or strengthening context. Figure 5 shows that CLARIFYDELPHI has the biggest percentage of relevant and informative questions in the test set, compared to the baselines. Since all models are based upon the same transformer model fine-tuned on the same data (with slight variations in the input/output setup), it makes sense that the differences in grammaticality among the models are minimal, with the lowest average score being 0.98 and the highest 0.99 (on a scale from 0 to 1, with 1 being grammatical). The evaluation in general shows that a big majority of the generated questions, from all models, are relevant and informative, with the lowest performing model (discriminator) still producing 448/500 questions that are passed on to the next evaluation round. The CLARIFYDELPHI questions also outperform the baselines in terms of defeasibility, as seen in Figure. 2: annotators can more often think of a strengthener answer and/or a weakener answer to our questions. The evaluation also shows that adding the answer-filtering with NLI step to the pipeline improves the question selection on all 4 evaluation criteria. The why-baseline is shown to be a strong baseline, indicating that motives and reasons are important for moral reasoning.\n\n\nHow much supervision does the policy require?\n\nOur approach uses RL in conjunction with a supervised policy that has been fine-tuned on question generation. This has been shown to outperform approaches which use RL on top of a \"vanilla\" lm-policy (such as T5-large) (Ramamurthy et al., 2022). In order to assess the effect of supervision on question generation performance, we trained multiple initial policies on varying percentages of \u03b4-CLARIFY training data: 25%, 50%, 75% and  100%. To compare against more traditional supervised question generation approaches, such as in Honovich et al. (2021), we additionally trained a policy on SQuAD v1.1 data (Rajpurkar et al., 2016). We report three automatic evaluation metrics. To measure informativeness we use an off-the-shelf QA model trained on SQuAD 2.0 from AllenNLP (Gardner et al., 2018). This model either answers a question by pointing to a span in the input or outputs that the question in unanswerable with respect to a given context. For a clarification question to be informative it would not ask about anything already mentioned in the situation. For the QA-metric we thus report the percentage of non-answerable questions. 5 We also report the average maximum BERTScore (Zhang et al., 2019) between a generated question and one of the 5 human written questions in \u03b4-CLARIFY. Lastly we calculate the perplexity of a question following a given situation. Fig. 6 shows the following trends with regards to training a supervised policy. More training data leads to more informative questions. The policy trained on SQuAD produces the most uninformative questions which can be explained by the fact that SQuAD questions are conditioned on existing answers in a text. While performance consistently increases from 25% to 75% of the training data, improvements after 75% are minimal. We conclude that for our use case training on about 5000 (75%) situations with 5 questions each leads to a sufficiently good policy. These results are also supported by the BERTScore. Perplexity, on the other hand, is lower between situations and SQuAD questions than situations and \u03b4-CLARIFY questions. This shows that questions which are too similar to the situations in terms of lexical match, are not the most useful in terms of defeasibility.\n\n\nAnalysis\n\nAnswer Simulation The answer generation model generally succeeds at generating diverse weakener and strengthener answers to the same question: for only about 0.05% of questions per 1000 PPO epochs the model generates the same answer for both weakener and strengthener.\n\nThis type of answer generation could be looked at as question-guided defeasible update generation. Rudinger et al. (2020) introduced the task of Generative Defeasible Inference where, for \u03b4-SOCIAL, they aim to generate an update given a situation, a moral judgement and the update type (e.g. weakener/strengthener). In our answer generation approach we condition on the same input together with a generated question. This intermediate question generation step functions as a type of macro planning which has been shown to be effective for NLG (Puduppully et al., 2022;Narayan et al., 2022). We evaluate our approach on the same test set using the same evaluation metrics as Rudinger et al. (2020). Table 3 shows that by first predicting the question and then the updates as its answers, we improve upon generating defeasible updates for \u03b4-SOCIAL.\n\nQuestions While we provided automatic and human evaluations of our questions in Sections 5.1-BLEU ROUGE \u03b4-SOCIAL (T5-large) 4.22 14.94 \u03b4-SOCIAL (GPT2-XL) 12.16 18.77 CLARIFYD (T5-large) 14.18 34.65 Table 3: Automatic results for strengthener/weakener update generation on the \u03b4-SOCIAL test set. Following Rudinger et al. (2020) we report BLEU-4 (Papineni et al., 2002) and ROUGE-L (Lin and Hovy, 2002). The first two results are from Rudinger et al. (2020). 5.3, it is interesting to also qualitatively inspect the types of generated questions. We identified five different question classes: specification, reason, elaboration, manner and temporal.\n\nThe specification questions are questions that ask about a hyponym of an argument in the base situation, for example, exterminating pests on your property -\"What kind of pests?\". The situations extracted from Social Chemistry often include underspecified pronouns, such as 'something', 'someone' or 'somewhere'. 60% of the situations containing 'something', for example, elicit what-questions from our model. Note that while such specification questions are valid clarification questions, the SQUAD 2.0 QA model would mark them as answerable given the situation. The questions in that category often also start with 'what kind', asking for a specification, for example in the form of an adjective. It is also interesting to see that often when a situation has a missing or implicit semantic argument, such as being anxious sometimes, CLARIFYDELPHI inquires about it: \"What are you anxious about?\"\n\nThe generated why-questions most often ask about the motives and reasons of the agent in the situation, such as Ben tells Maggie that he's traveling alone -\"Why is Ben traveling alone?\". More rarely the model generates questions asking about the viewpoint of the patient in the situation: asking a friend [...] whether your attire is appropriate for an event -\"What is the friend's opinion of your attire?\"\n\n\nInteractive Judgements\n\nWhile we use answer simulation during PPO training, inference only requires a situation as input. The clarification questions can then be used to elicit additional context, in the form of answers, through interaction. Fig. 7 illustrates two examples of such an interaction between a user, Delphi as the moral reasoning system and CLARIFYDELPHI. We limit the interaction to three turns, with two clarification questions. We decided on this number of turns because we found that after more than three turns the sentence fusion started to deteriorate and as a result the questions became less relevant and more repetitive. Also, after 2 questions, it is unlikely that there is missing context which could significantly alter the moral decision. After each turn the situation is being updated with more context and Delphi produces a new decision. This way one can observe how the context affects the model's predictions over multiple turns. Fig. 7 also shows how CLARIFYDELPHI's questions change depending on the answers a user provides. In future research we hope to improve upon the interaction by automatically predicting at what turn the situations don't require additional clarification and by taking turn history into account. We also want to explore training an RL model over multiple turns, instead of a single turn as we did in this work.\n\n\nRelated Work\n\nClarification Questions Clarification question generation has been studied for multiple domains. White et al. (2021) propose an approach for identifying images with questions. Rao and Daum\u00e9 III (2018) aim to clarify StackExchange posts and Majumder et al. (2021) worked on Amazon product descriptions. These types of tasks have a single true answer to the clarification questions: for a given image, for example, we know whether the answer to the question 'Are there people?' is yes or no. The answers to clarification questions for social situations on the other hand are unknown and can only be imagined or obtained through interaction with a participant. To the best of our knowledge we are the first to work on clarification questions in this domain. There are not many datasets for clarification question generation available and the existing datasets are highly domain specific. Kumar and Black (2020), for example, created a dataset from stackexchange posts and Aliannejadi et al. (2019) crowdsourced clarification questions for TREC Web data. In this work we crowdsource a high-quality clarification question dataset for social and moral situations, comprising of more than 30,000 questions.\n\nWhat makes a good clarification question can be defined differently. Most works define a good clarification question through their possible answer(s), in terms of their general utility or informativeness  Figure 7: Interaction between a user and CLARIFYDELPHI. The user inputs a situation and CLARIFYDELPHI answers with a judgement obtained from Delphi and a clarification question, which the user then answers. (Rao and Daum\u00e9 III, 2018;White et al., 2021). Warstadt and Agha (to appear) conduct an analysis of information theoretic measures of question relevance, finding that most existing methods are problematic. Both Rao and Daum\u00e9 III (2018) and Rao and Daum\u00e9 III (2019) treat utility as a binary problem, with the true QAs to a situation being useful. White et al. (2021) chose the question with the highest expected information gain, defined in terms of entropy. We on the other hand define utility in terms of defeasibility. More recently disambiguation through interaction has garnered some interest, with Kuhn et al. (2022) disambiguating questions andNguyen et al. (2022) teaching agents to request assistance.\n\nQuestion Generation While most general question generation approaches are based upon seq2seq models conditioned on an answer (Honovich et al., 2022) or an ontology (Pyatkin et al., 2021), some works have incorporated an RL-based approach. Buck et al. (2018) learn to paraphrase questions with a reward that maximizes the QA answer F1 score. And Rao and Daum\u00e9 III (2019) optimize a binary utility reward, using Reinforce in an adversarial setup for generating clarification questions. In our setup, we use Proximal Policy Optimization (Schulman et al., 2017;Ouyang et al., 2022) with a trained model for feedback as part of the reward.\n\nCommonsense Moral Reasoning Delphi (Jiang et al., 2022) is a commonsense moral reasoning model trained on COMMONSENSE NORM BANK, a dataset with 1.7M instances of descriptive knowledge of people's general sense of what's ethically acceptable or not in everyday situations. COMMON-SENSE NORM BANK is compiled from five existing large-scale datasets, including SOCIAL CHEM-ISTRY (Forbes et al., 2020), ETHICS Commonsense Morality (Hendrycks et al., 2021), MORAL STORIES (Emelin et al., 2021), SOCIAL BIAS IN-FERENCE CORPUS (Sap et al., 2020), and SCRU-PLES (Lourie et al., 2021), containing diverse descriptive social, cultural, and ethical norms contextualized in real world scenarios. Delphi is based on pre-trained UNICORN, a universal commonsense reasoning model, trained on a number of commonsense reasoning tasks. UNICORN is in turn derived from T5-11B, the largest T5 model with 11 billion parameters (Raffel et al., 2020a). Delphi can predict the ethical judgment given a textual description of an everyday situation (e.g., \"helping a friend in need to spread fake news\" is \"wrong\").\n\n\nConclusion\n\nIn this work we introduced CLARIFYDELPHI, which generates clarification questions for social and moral situations. We show how a reinforcement learning approach that optimizes for maximally divergent answers in terms of defeasibility outperforms other clarification question baselines. While we start with a supervised policy, the reward function makes use of already trained models and does not rely on any additional training data. We believe that our questions can be useful for disambiguating or adding more context to situations through interaction.\n\nper hour for all our crowdsourcing data collection and evaluation tasks. Our crowdsourcing tasks do not collect personal information and are strictly limited to gathering workers' general knowledge. We do not keep any deanonymizing information such as MTurk IDs so that the identity of the workers cannot be directly or indirectly ascertained. Finally, our crowdsourcing task meets the standards for exemptions as human research and has obtained the necessary documentation that deems it exempt through our internal IRB procedures.\n\nThe majority of the crowdworkers producing the source data (\u03b4-NLI and Delphi) and the \u03b4-CLARIFY were located in the United States. Due to this, the predictions generated by CLARIFYDELPHI are currently limited to representing only the perspectives of the western culture (particularly the United States). Overcoming the western-centric bias is a compelling direction for future research.\n\nFigure 2 :\n2Distribution of the top-12 most frequent question starts in \u03b4-CLARIFY.\n\nFigure 3 :Figure 4 :\n34Distribution of the most frequent question starts in the silver-questions dataset created by GPT-3. Distribution of the most frequent question starts of the defeasible questions in the silver-questions dataset created by GPT-3.\n\nFigure 5 :\n5Number of questions (out of 500) in test set which received an informativeness and relevance rating > 0.\n\nFigure 6 :\n6Performance of ppo algorithm with different policies: a policy pre-trained on SQUAD and policies pre-trained on different subsets of the \u03b4-CLARIFY dataset. The scores are averaged every 1000 steps, between 1000 and 6000. For QA and BertScore higher is better, while for Perplexity lower is better.\n\nTable 1 :\n1Two examples of situations and their clarification questions, written by five different Turkers.\n\nTable 2 :\n2Defeasibility scores obtained through human \nevaluation. weakener: Can you think of an answer \nto the question that weakens your initial judgement? \nstrengthener: Can you think of an answer ot the ques-\ntion that strengthens your intial judgement? defeasible: \npercentage of questions where annotators could think \nof both a strengthener and weakener answer. \n\n\n\n\nIgnoring a phone call I'm at work Nothing important It's rude. Why are you ignoring the call? It's okay. What was the call about? It's okay. I have no more questions to ask Ignoring a phone call I'm not in the mood for a call No It's rude. Why are you ignoring the call? It's rude. Are you in a hurry? It's rude. I have no more questions to ask Not going to work I'm going to sleep Because I'm annoyed at my boss It's irresponsible. What are you doing instead of going to work? It's irresponsible. Why are you not going to work? It's wrong. I have no more questions to ask Winning a game By stealing and lying It's a board came called \"Lie, Cheat and Steal\" It's good. What did you do to win? It's wrong. What game did you win? It's okay. I have no more questions to ask(a) \n\n(b) \n\n(c) \n\n(d) \n\n\nData and code are available at: https://github. com/ValentinaPy/ClarifyD.\nScreenshots of the annotation interface can be found in the Appendix.\nWe took this decision with the aim of preventing leading questions such as \"Do you intend to give it to a kid?\" for \"offering a cup of coffee\".\nwhat, how who, do, are, did, is where, have, was when, would\nThe Pearson correlation coefficient shows that this metric (moderately) correlates with the human informativeness evaluation (r = 0.31).\nAcknowledgmentsWe thank our colleagues on the Beaker Team at the Allen Institute for AI for helping with the compute infrastructure. This work was supported in-part by DARPA MCS program through NIWC Pacific (N66001-19-2-4031).A Example Appendix B MTurk Interfaces\nAsking clarifying questions in open-domain information-seeking conversations. Mohammad Aliannejadi, Hamed Zamani, Fabio Crestani, W Bruce Croft, Proceedings of the 42nd international acm sigir conference on research and development in information retrieval. the 42nd international acm sigir conference on research and development in information retrievalMohammad Aliannejadi, Hamed Zamani, Fabio Crestani, and W Bruce Croft. 2019. Asking clarify- ing questions in open-domain information-seeking conversations. In Proceedings of the 42nd interna- tional acm sigir conference on research and devel- opment in information retrieval, pages 475-484.\n\nLanguage models are few-shot learners. Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Advances in neural information processing systems. 33Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems, 33:1877-1901.\n\nAsk the right questions: Active question reformulation with reinforcement learning. Christian Buck, Jannis Bulian, Massimiliano Ciaramita, Wojciech Gajewski, Andrea Gesmundo, Neil Houlsby, Wei Wang, International Conference on Learning Representations. Christian Buck, Jannis Bulian, Massimiliano Cia- ramita, Wojciech Gajewski, Andrea Gesmundo, Neil Houlsby, and Wei Wang. 2018. Ask the right questions: Active question reformulation with rein- forcement learning. In International Conference on Learning Representations.\n\nMoral stories: Situated reasoning about norms, intents, actions, and their consequences. Denis Emelin, Le Ronan, Jena D Bras, Maxwell Hwang, Yejin Forbes, Choi, 10.18653/v1/2021.emnlp-main.54Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. the 2021 Conference on Empirical Methods in Natural Language ProcessingOnline and Punta Cana, Dominican RepublicAssociation for Computational LinguisticsDenis Emelin, Ronan Le Bras, Jena D. Hwang, Maxwell Forbes, and Yejin Choi. 2021. Moral sto- ries: Situated reasoning about norms, intents, ac- tions, and their consequences. In Proceedings of the 2021 Conference on Empirical Methods in Nat- ural Language Processing, pages 698-718, Online and Punta Cana, Dominican Republic. Association for Computational Linguistics.\n\nLearning to reason about social and moral norms. Maxwell Forbes, Jena D Hwang, Vered Shwartz, Maarten Sap, Yejin Choi, EMNLP. 101Maxwell Forbes, Jena D Hwang, Vered Shwartz, Maarten Sap, and Yejin Choi. 2020. Social chem- istry 101: Learning to reason about social and moral norms. In EMNLP.\n\nMatt Gardner, Joel Grus, Mark Neumann, Oyvind Tafjord, Pradeep Dasigi, Nelson Liu, Matthew Peters, Michael Schmitz, Luke Zettlemoyer, arXiv:1803.07640Allennlp: A deep semantic natural language processing platform. arXiv preprintMatt Gardner, Joel Grus, Mark Neumann, Oyvind Tafjord, Pradeep Dasigi, Nelson Liu, Matthew Pe- ters, Michael Schmitz, and Luke Zettlemoyer. 2018. Allennlp: A deep semantic natural language process- ing platform. arXiv preprint arXiv:1803.07640.\n\nDeberta: Decoding-enhanced bert with disentangled attention. Pengcheng He, Xiaodong Liu, Jianfeng Gao, Weizhu Chen, International Conference on Learning Representations. Pengcheng He, Xiaodong Liu, Jianfeng Gao, and Weizhu Chen. 2020. Deberta: Decoding-enhanced bert with disentangled attention. In International Conference on Learning Representations.\n\nAligning {ai} with shared human values. Dan Hendrycks, Collin Burns, Steven Basart, Andrew Critch, Jerry Li, Dawn Song, Jacob Steinhardt, International Conference on Learning Representations. Dan Hendrycks, Collin Burns, Steven Basart, Andrew Critch, Jerry Li, Dawn Song, and Jacob Steinhardt. 2021. Aligning {ai} with shared human values. In International Conference on Learning Representa- tions.\n\nTRUE: Re-evaluating factual consistency evaluation. Or Honovich, Roee Aharoni, Jonathan Herzig, Hagai Taitelbaum, Doron Kukliansy, Vered Cohen, Thomas Scialom, Idan Szpektor, Avinatan Hassidim, Yossi Matias, 10.18653/v1/2022.naacl-main.287Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language TechnologiesSeattle, United StatesAssociation for Computational LinguisticsOr Honovich, Roee Aharoni, Jonathan Herzig, Ha- gai Taitelbaum, Doron Kukliansy, Vered Cohen, Thomas Scialom, Idan Szpektor, Avinatan Hassidim, and Yossi Matias. 2022. TRUE: Re-evaluating fac- tual consistency evaluation. In Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 3905-3920, Seattle, United States. Association for Computa- tional Linguistics.\n\nEvaluating factual consistency in knowledgegrounded dialogues via question generation and question answering. Or Honovich, Leshem Choshen, Roee Aharoni, Ella Neeman, Idan Szpektor, Omri Abend, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. the 2021 Conference on Empirical Methods in Natural Language Processing2Or Honovich, Leshem Choshen, Roee Aharoni, Ella Neeman, Idan Szpektor, and Omri Abend. 2021. Q2:: Evaluating factual consistency in knowledge- grounded dialogues via question generation and question answering. In Proceedings of the 2021 Conference on Empirical Methods in Natural Lan- guage Processing, pages 7856-7870.\n\nMaarten Sap, Regina Rini, and Yejin Choi. 2022. Can machines learn morality? the delphi experiment. Liwei Jiang, Jena D Hwang, Chandra Bhagavatula, Jenny Ronan Le Bras, Jesse Liang, Keisuke Dodge, Maxwell Sakaguchi, Jon Forbes, Saadia Borchardt, Yulia Gabriel, Oren Tsvetkov, Etzioni, arXiv:2110.07574arXiv preprintLiwei Jiang, Jena D. Hwang, Chandra Bhagavatula, Ro- nan Le Bras, Jenny Liang, Jesse Dodge, Keisuke Sakaguchi, Maxwell Forbes, Jon Borchardt, Saa- dia Gabriel, Yulia Tsvetkov, Oren Etzioni, Maarten Sap, Regina Rini, and Yejin Choi. 2022. Can ma- chines learn morality? the delphi experiment. arXiv preprint arXiv:2110.07574.\n\nClam: Selective clarification for ambiguous questions with large language models. Lorenz Kuhn, Yarin Gal, Sebastian Farquhar, arXiv:2212.07769arXiv preprintLorenz Kuhn, Yarin Gal, and Sebastian Farquhar. 2022. Clam: Selective clarification for ambiguous ques- tions with large language models. arXiv preprint arXiv:2212.07769.\n\nClarq: A large-scale and diverse dataset for clarification question generation. Vaibhav Kumar, Alan W Black, Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics. the 58th Annual Meeting of the Association for Computational LinguisticsVaibhav Kumar and Alan W Black. 2020. Clarq: A large-scale and diverse dataset for clarification ques- tion generation. In Proceedings of the 58th Annual Meeting of the Association for Computational Lin- guistics, pages 7296-7301.\n\nManual and automatic evaluation of summaries. Chin-Yew Lin, Eduard Hovy, Proceedings of the ACL-02 Workshop on Automatic Summarization. the ACL-02 Workshop on Automatic SummarizationChin-Yew Lin and Eduard Hovy. 2002. Manual and au- tomatic evaluation of summaries. In Proceedings of the ACL-02 Workshop on Automatic Summarization, pages 45-51.\n\nWANLI: Worker and ai collaboration for natural language inference dataset creation. Alisa Liu, Swabha Swayamdipta, Noah A Smith, Yejin Choi, Findings of the Association for Computational Linguistics: EMNLP 2022. Abu Dhabi, United Arab EmiratesAssociation for Computational LinguisticsAlisa Liu, Swabha Swayamdipta, Noah A. Smith, and Yejin Choi. 2022a. WANLI: Worker and ai collab- oration for natural language inference dataset cre- ation. In Findings of the Association for Computa- tional Linguistics: EMNLP 2022, pages 6826-6847, Abu Dhabi, United Arab Emirates. Association for Computational Linguistics.\n\nRainier: Reinforced knowledge introspector for commonsense question answering. Jiacheng Liu, Skyler Hallinan, Ximing Lu, Pengfei He, Sean Welleck, Hannaneh Hajishirzi, Yejin Choi, arXiv:2210.03078arXiv preprintJiacheng Liu, Skyler Hallinan, Ximing Lu, Pengfei He, Sean Welleck, Hannaneh Hajishirzi, and Yejin Choi. 2022b. Rainier: Reinforced knowledge introspec- tor for commonsense question answering. arXiv preprint arXiv:2210.03078.\n\nScruples: A corpus of community ethical judgments on 32, 000 real-life anecdotes. Nicholas Lourie, Yejin Ronan Le Bras, Choi, AAAI. Nicholas Lourie, Ronan Le Bras, and Yejin Choi. 2021. Scruples: A corpus of community ethical judgments on 32, 000 real-life anecdotes. In AAAI.\n\nAsk what's missing and what's useful: Improving clarification question generation using global knowledge. Sudha Bodhisattwa Prasad Majumder, Michel Rao, Julian J Galley, Mcauley, NAACL-HLT. Bodhisattwa Prasad Majumder, Sudha Rao, Michel Galley, and Julian J McAuley. 2021. Ask what's missing and what's useful: Improving clarification question generation using global knowledge. In NAACL-HLT.\n\nShashi Narayan, Joshua Maynez, Reinald Kim Amplayo, Kuzman Ganchev, Annie Louis, Fantine Huot, arXiv:2207.00397Dipanjan Das, and Mirella Lapata. 2022. Conditional generation with a question-answering blueprint. arXiv preprintShashi Narayan, Joshua Maynez, Reinald Kim Am- playo, Kuzman Ganchev, Annie Louis, Fantine Huot, Dipanjan Das, and Mirella Lapata. 2022. Conditional generation with a question-answering blueprint. arXiv preprint arXiv:2207.00397.\n\nA framework for learning to request rich and contextually useful information from humans. Yonatan Khanh X Nguyen, Hal Daum\u00e9 Bisk, Iii, PMLRInternational Conference on Machine Learning. Khanh X Nguyen, Yonatan Bisk, and Hal Daum\u00e9 Iii. 2022. A framework for learning to request rich and contextually useful information from humans. In In- ternational Conference on Machine Learning, pages 16553-16568. PMLR.\n\nLong Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, L Carroll, Pamela Wainwright, Chong Mishkin, Sandhini Zhang, Katarina Agarwal, Alex Slama, Ray, arXiv:2203.02155Training language models to follow instructions with human feedback. arXiv preprintLong Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Car- roll L Wainwright, Pamela Mishkin, Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. 2022. Training language models to follow in- structions with human feedback. arXiv preprint arXiv:2203.02155.\n\nBleu: a method for automatic evaluation of machine translation. Kishore Papineni, Salim Roukos, Todd Ward, Wei-Jing Zhu, Proceedings of the 40th annual meeting of the Association for Computational Linguistics. the 40th annual meeting of the Association for Computational LinguisticsKishore Papineni, Salim Roukos, Todd Ward, and Wei- Jing Zhu. 2002. Bleu: a method for automatic eval- uation of machine translation. In Proceedings of the 40th annual meeting of the Association for Compu- tational Linguistics, pages 311-318.\n\nData-to-text generation with variational sequential planning. Ratish Puduppully, Yao Fu, Mirella Lapata, 10.1162/tacl_a_00484Transactions of the Association for Computational Linguistics. 10Ratish Puduppully, Yao Fu, and Mirella Lapata. 2022. Data-to-text generation with variational sequential planning. Transactions of the Association for Com- putational Linguistics, 10:697-715.\n\nAsking it all: Generating contextualized questions for any semantic role. Valentina Pyatkin, Paul Roit, Julian Michael, Yoav Goldberg, Reut Tsarfaty, Ido Dagan, 10.18653/v1/2021.emnlp-main.108Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. the 2021 Conference on Empirical Methods in Natural Language ProcessingOnline and Punta Cana, Dominican RepublicAssociation for Computational LinguisticsValentina Pyatkin, Paul Roit, Julian Michael, Yoav Goldberg, Reut Tsarfaty, and Ido Dagan. 2021. Ask- ing it all: Generating contextualized questions for any semantic role. In Proceedings of the 2021 Con- ference on Empirical Methods in Natural Language Processing, pages 1429-1441, Online and Punta Cana, Dominican Republic. Association for Compu- tational Linguistics.\n\nExploring the limits of transfer learning with a unified text-totext transformer. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J Liu, Journal of Machine Learning Research. 21140Colin Raffel, Noam Shazeer, Adam Roberts, Kather- ine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, and Peter J. Liu. 2020a. Exploring the limits of transfer learning with a unified text-to- text transformer. Journal of Machine Learning Re- search, 21(140):1-67.\n\nExploring the limits of transfer learning with a unified text-to-text transformer. Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, J Peter, Liu, J. Mach. Learn. Res. 21140Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi Zhou, Wei Li, Peter J Liu, et al. 2020b. Exploring the limits of transfer learning with a unified text-to-text trans- former. J. Mach. Learn. Res., 21(140):1-67.\n\nSquad: 100,000+ questions for machine comprehension of text. Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, Percy Liang, Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing. the 2016 Conference on Empirical Methods in Natural Language ProcessingPranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016. Squad: 100,000+ questions for machine comprehension of text. In Proceedings of the 2016 Conference on Empirical Methods in Natu- ral Language Processing, pages 2383-2392.\n\nIs reinforcement learning (not) for natural language processing. Rajkumar Ramamurthy, Prithviraj Ammanabrolu, Kiant\u00e9 Brantley, Jack Hessel, Rafet Sifa, Christian Bauckhage, Hannaneh Hajishirzi, Yejin Choi, arXiv:2210.01241Benchmarks, baselines, and building blocks for natural language policy optimization. arXiv preprintRajkumar Ramamurthy, Prithviraj Ammanabrolu, Kiant\u00e9 Brantley, Jack Hessel, Rafet Sifa, Christian Bauckhage, Hannaneh Hajishirzi, and Yejin Choi. 2022. Is reinforcement learning (not) for natural language processing?: Benchmarks, baselines, and building blocks for natural language policy optimization. arXiv preprint arXiv:2210.01241.\n\nLearning to ask good questions: Ranking clarification questions using neural expected value of perfect information. Sudha Rao, Hal Daum\u00e9, Iii , Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics. the 56th Annual Meeting of the Association for Computational LinguisticsLong Papers1Sudha Rao and Hal Daum\u00e9 III. 2018. Learning to ask good questions: Ranking clarification questions us- ing neural expected value of perfect information. In Proceedings of the 56th Annual Meeting of the As- sociation for Computational Linguistics (Volume 1: Long Papers), pages 2737-2746.\n\nAnswer-based adversarial training for generating clarification questions. Sudha Rao, Hal Daum\u00e9, Iii , Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies1Sudha Rao and Hal Daum\u00e9 III. 2019. Answer-based adversarial training for generating clarification ques- tions. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Com- putational Linguistics: Human Language Technolo- gies, Volume 1 (Long and Short Papers), pages 143- 155.\n\nThinking like a skeptic: Defeasible inference in natural language. Rachel Rudinger, Vered Shwartz, Jena D Hwang, Chandra Bhagavatula, Maxwell Forbes, Le Ronan, Noah A Bras, Yejin Smith, Choi, 10.18653/v1/2020.findings-emnlp.418Findings of the Association for Computational Linguistics: EMNLP 2020. Online. Association for Computational LinguisticsRachel Rudinger, Vered Shwartz, Jena D. Hwang, Chandra Bhagavatula, Maxwell Forbes, Ronan Le Bras, Noah A. Smith, and Yejin Choi. 2020. Thinking like a skeptic: Defeasible inference in nat- ural language. In Findings of the Association for Computational Linguistics: EMNLP 2020, pages 4661-4675, Online. Association for Computational Linguistics.\n\nSocial bias frames: Reasoning about social and power implications of language. Maarten Sap, Saadia Gabriel, Lianhui Qin, Dan Jurafsky, A Noah, Yejin Smith, Choi, ACL. Maarten Sap, Saadia Gabriel, Lianhui Qin, Dan Juraf- sky, Noah A Smith, and Yejin Choi. 2020. Social bias frames: Reasoning about social and power im- plications of language. In ACL.\n\nJohn Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, Oleg Klimov, arXiv:1707.06347Proximal policy optimization algorithms. arXiv preprintJohn Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. 2017. Proximal policy optimization algorithms. arXiv preprint arXiv:1707.06347.\n\nTesting bayesian measures of relevance in discourse. Alex Warstadt, Omar Agha, Proceedings of Sinn und Bedeutung. Sinn und Bedeutung26to appearAlex Warstadt and Omar Agha. to appear. Testing bayesian measures of relevance in discourse. In Pro- ceedings of Sinn und Bedeutung, volume 26.\n\nOpen-domain clarification question generation without question examples. Julia White, Gabriel Poesia, Robert Hawkins, Dorsa Sadigh, Noah Goodman, Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. the 2021 Conference on Empirical Methods in Natural Language ProcessingJulia White, Gabriel Poesia, Robert Hawkins, Dorsa Sadigh, and Noah Goodman. 2021. Open-domain clarification question generation without question examples. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Process- ing, pages 563-570.\n\nBertscore: Evaluating text generation with bert. Tianyi Zhang, Varsha Kishore, Felix Wu, Q Kilian, Yoav Weinberger, Artzi, International Conference on Learning Representations. Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q Weinberger, and Yoav Artzi. 2019. Bertscore: Eval- uating text generation with bert. In International Conference on Learning Representations.\n", "annotations": {"author": "[{\"end\":323,\"start\":122},{\"end\":502,\"start\":324},{\"end\":683,\"start\":503},{\"end\":860,\"start\":684},{\"end\":1031,\"start\":861},{\"end\":1209,\"start\":1032},{\"end\":1377,\"start\":1210},{\"end\":1554,\"start\":1378},{\"end\":1722,\"start\":1555},{\"end\":1908,\"start\":1723},{\"end\":323,\"start\":122},{\"end\":502,\"start\":324},{\"end\":683,\"start\":503},{\"end\":860,\"start\":684},{\"end\":1031,\"start\":861},{\"end\":1209,\"start\":1032},{\"end\":1377,\"start\":1210},{\"end\":1554,\"start\":1378},{\"end\":1722,\"start\":1555},{\"end\":1908,\"start\":1723}]", "publisher": null, "author_last_name": "[{\"end\":139,\"start\":132},{\"end\":336,\"start\":331},{\"end\":517,\"start\":509},{\"end\":694,\"start\":688},{\"end\":1043,\"start\":1038},{\"end\":1388,\"start\":1384},{\"end\":1742,\"start\":1731},{\"end\":139,\"start\":132},{\"end\":336,\"start\":331},{\"end\":517,\"start\":509},{\"end\":694,\"start\":688},{\"end\":1043,\"start\":1038},{\"end\":1388,\"start\":1384},{\"end\":1742,\"start\":1731}]", "author_first_name": "[{\"end\":131,\"start\":122},{\"end\":328,\"start\":324},{\"end\":330,\"start\":329},{\"end\":508,\"start\":503},{\"end\":685,\"start\":684},{\"end\":687,\"start\":686},{\"end\":863,\"start\":861},{\"end\":865,\"start\":864},{\"end\":1037,\"start\":1032},{\"end\":1211,\"start\":1210},{\"end\":1383,\"start\":1378},{\"end\":1556,\"start\":1555},{\"end\":1730,\"start\":1723},{\"end\":131,\"start\":122},{\"end\":328,\"start\":324},{\"end\":330,\"start\":329},{\"end\":508,\"start\":503},{\"end\":685,\"start\":684},{\"end\":687,\"start\":686},{\"end\":863,\"start\":861},{\"end\":865,\"start\":864},{\"end\":1037,\"start\":1032},{\"end\":1211,\"start\":1210},{\"end\":1383,\"start\":1378},{\"end\":1556,\"start\":1555},{\"end\":1730,\"start\":1723}]", "author_affiliation": "[{\"end\":322,\"start\":159},{\"end\":501,\"start\":338},{\"end\":682,\"start\":519},{\"end\":859,\"start\":696},{\"end\":1030,\"start\":867},{\"end\":1208,\"start\":1045},{\"end\":1376,\"start\":1213},{\"end\":1553,\"start\":1390},{\"end\":1721,\"start\":1558},{\"end\":1907,\"start\":1744},{\"end\":322,\"start\":159},{\"end\":501,\"start\":338},{\"end\":682,\"start\":519},{\"end\":859,\"start\":696},{\"end\":1030,\"start\":867},{\"end\":1208,\"start\":1045},{\"end\":1376,\"start\":1213},{\"end\":1553,\"start\":1390},{\"end\":1721,\"start\":1558},{\"end\":1907,\"start\":1744}]", "title": "[{\"end\":119,\"start\":1},{\"end\":2027,\"start\":1909},{\"end\":119,\"start\":1},{\"end\":2027,\"start\":1909}]", "venue": null, "abstract": "[{\"end\":2078,\"start\":2029},{\"end\":2078,\"start\":2029}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b20\"},\"end\":2726,\"start\":2706},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":3774,\"start\":3751},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":3794,\"start\":3774},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":6287,\"start\":6264},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":7412,\"start\":7391},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":7463,\"start\":7443},{\"end\":7577,\"start\":7551},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":8411,\"start\":8389},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":8904,\"start\":8884},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":12013,\"start\":11992},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":13854,\"start\":13834},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":15912,\"start\":15889},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":16014,\"start\":15995},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":16038,\"start\":16014},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":16339,\"start\":16320},{\"end\":17346,\"start\":17345},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":17724,\"start\":17707},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":22333,\"start\":22308},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":22641,\"start\":22619},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":22719,\"start\":22695},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":22884,\"start\":22862},{\"end\":23229,\"start\":23228},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":23295,\"start\":23275},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":24733,\"start\":24711},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":25180,\"start\":25155},{\"end\":25201,\"start\":25180},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":25308,\"start\":25286},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":25787,\"start\":25765},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":25828,\"start\":25805},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":25861,\"start\":25841},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":25917,\"start\":25894},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":28917,\"start\":28898},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":29001,\"start\":28977},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":29063,\"start\":29041},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":29708,\"start\":29686},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":29795,\"start\":29770},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":30439,\"start\":30414},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":30458,\"start\":30439},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":30648,\"start\":30624},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":30677,\"start\":30653},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":30779,\"start\":30760},{\"end\":31064,\"start\":31017},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":31084,\"start\":31064},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":31273,\"start\":31250},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":31311,\"start\":31289},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":31382,\"start\":31364},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":31682,\"start\":31659},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":31701,\"start\":31682},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":31816,\"start\":31796},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":32158,\"start\":32137},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":32212,\"start\":32188},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":32249,\"start\":32228},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":32299,\"start\":32281},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":32336,\"start\":32315},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":32688,\"start\":32666},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":2726,\"start\":2706},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":3774,\"start\":3751},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":3794,\"start\":3774},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":6287,\"start\":6264},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":7412,\"start\":7391},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":7463,\"start\":7443},{\"end\":7577,\"start\":7551},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":8411,\"start\":8389},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":8904,\"start\":8884},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":12013,\"start\":11992},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":13854,\"start\":13834},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":15912,\"start\":15889},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":16014,\"start\":15995},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":16038,\"start\":16014},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":16339,\"start\":16320},{\"end\":17346,\"start\":17345},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":17724,\"start\":17707},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":22333,\"start\":22308},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":22641,\"start\":22619},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":22719,\"start\":22695},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":22884,\"start\":22862},{\"end\":23229,\"start\":23228},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":23295,\"start\":23275},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":24733,\"start\":24711},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":25180,\"start\":25155},{\"end\":25201,\"start\":25180},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":25308,\"start\":25286},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":25787,\"start\":25765},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":25828,\"start\":25805},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":25861,\"start\":25841},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":25917,\"start\":25894},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":28917,\"start\":28898},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":29001,\"start\":28977},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":29063,\"start\":29041},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":29708,\"start\":29686},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":29795,\"start\":29770},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":30439,\"start\":30414},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":30458,\"start\":30439},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":30648,\"start\":30624},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":30677,\"start\":30653},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":30779,\"start\":30760},{\"end\":31064,\"start\":31017},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":31084,\"start\":31064},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":31273,\"start\":31250},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":31311,\"start\":31289},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":31382,\"start\":31364},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":31682,\"start\":31659},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":31701,\"start\":31682},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":31816,\"start\":31796},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":32158,\"start\":32137},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":32212,\"start\":32188},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":32249,\"start\":32228},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":32299,\"start\":32281},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":32336,\"start\":32315},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":32688,\"start\":32666}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":34423,\"start\":34340},{\"attributes\":{\"id\":\"fig_1\"},\"end\":34675,\"start\":34424},{\"attributes\":{\"id\":\"fig_2\"},\"end\":34793,\"start\":34676},{\"attributes\":{\"id\":\"fig_3\"},\"end\":35104,\"start\":34794},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":35213,\"start\":35105},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":35587,\"start\":35214},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":36384,\"start\":35588},{\"attributes\":{\"id\":\"fig_0\"},\"end\":34423,\"start\":34340},{\"attributes\":{\"id\":\"fig_1\"},\"end\":34675,\"start\":34424},{\"attributes\":{\"id\":\"fig_2\"},\"end\":34793,\"start\":34676},{\"attributes\":{\"id\":\"fig_3\"},\"end\":35104,\"start\":34794},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":35213,\"start\":35105},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":35587,\"start\":35214},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":36384,\"start\":35588}]", "paragraph": "[{\"end\":2534,\"start\":2094},{\"end\":2858,\"start\":2536},{\"end\":2906,\"start\":2882},{\"end\":2930,\"start\":2908},{\"end\":3227,\"start\":2932},{\"end\":3617,\"start\":3229},{\"end\":4832,\"start\":3619},{\"end\":5268,\"start\":4834},{\"end\":5622,\"start\":5270},{\"end\":6450,\"start\":5640},{\"end\":6894,\"start\":6452},{\"end\":7156,\"start\":6907},{\"end\":7700,\"start\":7208},{\"end\":8290,\"start\":7702},{\"end\":9433,\"start\":8292},{\"end\":9497,\"start\":9454},{\"end\":9567,\"start\":9499},{\"end\":9590,\"start\":9569},{\"end\":9656,\"start\":9592},{\"end\":10646,\"start\":9658},{\"end\":11799,\"start\":10648},{\"end\":11968,\"start\":11834},{\"end\":12064,\"start\":11970},{\"end\":12233,\"start\":12099},{\"end\":12301,\"start\":12267},{\"end\":12840,\"start\":12303},{\"end\":13051,\"start\":12873},{\"end\":13194,\"start\":13053},{\"end\":13347,\"start\":13196},{\"end\":13484,\"start\":13349},{\"end\":13645,\"start\":13486},{\"end\":13907,\"start\":13668},{\"end\":14132,\"start\":13927},{\"end\":14449,\"start\":14134},{\"end\":14930,\"start\":14451},{\"end\":15279,\"start\":14948},{\"end\":15568,\"start\":15287},{\"end\":15823,\"start\":15609},{\"end\":16108,\"start\":15825},{\"end\":16369,\"start\":16110},{\"end\":16436,\"start\":16383},{\"end\":16684,\"start\":16438},{\"end\":16946,\"start\":16686},{\"end\":17106,\"start\":16948},{\"end\":17146,\"start\":17108},{\"end\":17412,\"start\":17148},{\"end\":17647,\"start\":17414},{\"end\":18168,\"start\":17649},{\"end\":18511,\"start\":18170},{\"end\":18756,\"start\":18513},{\"end\":19412,\"start\":18803},{\"end\":20283,\"start\":19414},{\"end\":22039,\"start\":20315},{\"end\":24329,\"start\":22089},{\"end\":24610,\"start\":24342},{\"end\":25458,\"start\":24612},{\"end\":26108,\"start\":25460},{\"end\":27006,\"start\":26110},{\"end\":27414,\"start\":27008},{\"end\":28784,\"start\":27441},{\"end\":30000,\"start\":28801},{\"end\":31123,\"start\":30002},{\"end\":31759,\"start\":31125},{\"end\":32849,\"start\":31761},{\"end\":33418,\"start\":32864},{\"end\":33951,\"start\":33420},{\"end\":34339,\"start\":33953},{\"end\":2534,\"start\":2094},{\"end\":2858,\"start\":2536},{\"end\":2906,\"start\":2882},{\"end\":2930,\"start\":2908},{\"end\":3227,\"start\":2932},{\"end\":3617,\"start\":3229},{\"end\":4832,\"start\":3619},{\"end\":5268,\"start\":4834},{\"end\":5622,\"start\":5270},{\"end\":6450,\"start\":5640},{\"end\":6894,\"start\":6452},{\"end\":7156,\"start\":6907},{\"end\":7700,\"start\":7208},{\"end\":8290,\"start\":7702},{\"end\":9433,\"start\":8292},{\"end\":9497,\"start\":9454},{\"end\":9567,\"start\":9499},{\"end\":9590,\"start\":9569},{\"end\":9656,\"start\":9592},{\"end\":10646,\"start\":9658},{\"end\":11799,\"start\":10648},{\"end\":11968,\"start\":11834},{\"end\":12064,\"start\":11970},{\"end\":12233,\"start\":12099},{\"end\":12301,\"start\":12267},{\"end\":12840,\"start\":12303},{\"end\":13051,\"start\":12873},{\"end\":13194,\"start\":13053},{\"end\":13347,\"start\":13196},{\"end\":13484,\"start\":13349},{\"end\":13645,\"start\":13486},{\"end\":13907,\"start\":13668},{\"end\":14132,\"start\":13927},{\"end\":14449,\"start\":14134},{\"end\":14930,\"start\":14451},{\"end\":15279,\"start\":14948},{\"end\":15568,\"start\":15287},{\"end\":15823,\"start\":15609},{\"end\":16108,\"start\":15825},{\"end\":16369,\"start\":16110},{\"end\":16436,\"start\":16383},{\"end\":16684,\"start\":16438},{\"end\":16946,\"start\":16686},{\"end\":17106,\"start\":16948},{\"end\":17146,\"start\":17108},{\"end\":17412,\"start\":17148},{\"end\":17647,\"start\":17414},{\"end\":18168,\"start\":17649},{\"end\":18511,\"start\":18170},{\"end\":18756,\"start\":18513},{\"end\":19412,\"start\":18803},{\"end\":20283,\"start\":19414},{\"end\":22039,\"start\":20315},{\"end\":24329,\"start\":22089},{\"end\":24610,\"start\":24342},{\"end\":25458,\"start\":24612},{\"end\":26108,\"start\":25460},{\"end\":27006,\"start\":26110},{\"end\":27414,\"start\":27008},{\"end\":28784,\"start\":27441},{\"end\":30000,\"start\":28801},{\"end\":31123,\"start\":30002},{\"end\":31759,\"start\":31125},{\"end\":32849,\"start\":31761},{\"end\":33418,\"start\":32864},{\"end\":33951,\"start\":33420},{\"end\":34339,\"start\":33953}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":12266,\"start\":12234},{\"attributes\":{\"id\":\"formula_1\"},\"end\":15608,\"start\":15569},{\"attributes\":{\"id\":\"formula_0\"},\"end\":12266,\"start\":12234},{\"attributes\":{\"id\":\"formula_1\"},\"end\":15608,\"start\":15569}]", "table_ref": "[{\"end\":25317,\"start\":25310},{\"end\":25665,\"start\":25658},{\"end\":25317,\"start\":25310},{\"end\":25665,\"start\":25658}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2092,\"start\":2080},{\"end\":2880,\"start\":2861},{\"attributes\":{\"n\":\"2\"},\"end\":5638,\"start\":5625},{\"attributes\":{\"n\":\"3\"},\"end\":6905,\"start\":6897},{\"attributes\":{\"n\":\"3.1\"},\"end\":7206,\"start\":7159},{\"end\":9452,\"start\":9436},{\"attributes\":{\"n\":\"3.2\"},\"end\":11832,\"start\":11802},{\"attributes\":{\"n\":\"3.3\"},\"end\":12097,\"start\":12067},{\"end\":12871,\"start\":12843},{\"attributes\":{\"n\":\"3.4\"},\"end\":13666,\"start\":13648},{\"end\":13925,\"start\":13910},{\"end\":14946,\"start\":14933},{\"attributes\":{\"n\":\"3.5\"},\"end\":15285,\"start\":15282},{\"attributes\":{\"n\":\"4\"},\"end\":16381,\"start\":16372},{\"attributes\":{\"n\":\"5\"},\"end\":18782,\"start\":18759},{\"attributes\":{\"n\":\"5.1\"},\"end\":18801,\"start\":18785},{\"attributes\":{\"n\":\"5.2\"},\"end\":20313,\"start\":20286},{\"attributes\":{\"n\":\"5.3\"},\"end\":22087,\"start\":22042},{\"attributes\":{\"n\":\"5.4\"},\"end\":24340,\"start\":24332},{\"attributes\":{\"n\":\"6\"},\"end\":27439,\"start\":27417},{\"attributes\":{\"n\":\"7\"},\"end\":28799,\"start\":28787},{\"attributes\":{\"n\":\"8\"},\"end\":32862,\"start\":32852},{\"end\":34351,\"start\":34341},{\"end\":34445,\"start\":34425},{\"end\":34687,\"start\":34677},{\"end\":34805,\"start\":34795},{\"end\":35115,\"start\":35106},{\"end\":35224,\"start\":35215},{\"attributes\":{\"n\":\"1\"},\"end\":2092,\"start\":2080},{\"end\":2880,\"start\":2861},{\"attributes\":{\"n\":\"2\"},\"end\":5638,\"start\":5625},{\"attributes\":{\"n\":\"3\"},\"end\":6905,\"start\":6897},{\"attributes\":{\"n\":\"3.1\"},\"end\":7206,\"start\":7159},{\"end\":9452,\"start\":9436},{\"attributes\":{\"n\":\"3.2\"},\"end\":11832,\"start\":11802},{\"attributes\":{\"n\":\"3.3\"},\"end\":12097,\"start\":12067},{\"end\":12871,\"start\":12843},{\"attributes\":{\"n\":\"3.4\"},\"end\":13666,\"start\":13648},{\"end\":13925,\"start\":13910},{\"end\":14946,\"start\":14933},{\"attributes\":{\"n\":\"3.5\"},\"end\":15285,\"start\":15282},{\"attributes\":{\"n\":\"4\"},\"end\":16381,\"start\":16372},{\"attributes\":{\"n\":\"5\"},\"end\":18782,\"start\":18759},{\"attributes\":{\"n\":\"5.1\"},\"end\":18801,\"start\":18785},{\"attributes\":{\"n\":\"5.2\"},\"end\":20313,\"start\":20286},{\"attributes\":{\"n\":\"5.3\"},\"end\":22087,\"start\":22042},{\"attributes\":{\"n\":\"5.4\"},\"end\":24340,\"start\":24332},{\"attributes\":{\"n\":\"6\"},\"end\":27439,\"start\":27417},{\"attributes\":{\"n\":\"7\"},\"end\":28799,\"start\":28787},{\"attributes\":{\"n\":\"8\"},\"end\":32862,\"start\":32852},{\"end\":34351,\"start\":34341},{\"end\":34445,\"start\":34425},{\"end\":34687,\"start\":34677},{\"end\":34805,\"start\":34795},{\"end\":35115,\"start\":35106},{\"end\":35224,\"start\":35215}]", "table": "[{\"end\":35587,\"start\":35226},{\"end\":36384,\"start\":36360},{\"end\":35587,\"start\":35226},{\"end\":36384,\"start\":36360}]", "figure_caption": "[{\"end\":34423,\"start\":34353},{\"end\":34675,\"start\":34448},{\"end\":34793,\"start\":34689},{\"end\":35104,\"start\":34807},{\"end\":35213,\"start\":35117},{\"end\":36360,\"start\":35590},{\"end\":34423,\"start\":34353},{\"end\":34675,\"start\":34448},{\"end\":34793,\"start\":34689},{\"end\":35104,\"start\":34807},{\"end\":35213,\"start\":35117},{\"end\":36360,\"start\":35590}]", "figure_ref": "[{\"end\":2988,\"start\":2980},{\"end\":3940,\"start\":3934},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":9004,\"start\":8998},{\"end\":10776,\"start\":10769},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":20829,\"start\":20821},{\"end\":21663,\"start\":21656},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":23464,\"start\":23458},{\"end\":27665,\"start\":27659},{\"end\":28384,\"start\":28378},{\"end\":30215,\"start\":30207},{\"end\":2988,\"start\":2980},{\"end\":3940,\"start\":3934},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":9004,\"start\":8998},{\"end\":10776,\"start\":10769},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":20829,\"start\":20821},{\"end\":21663,\"start\":21656},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":23464,\"start\":23458},{\"end\":27665,\"start\":27659},{\"end\":28384,\"start\":28378},{\"end\":30215,\"start\":30207}]", "bib_author_first_name": "[{\"end\":37221,\"start\":37213},{\"end\":37240,\"start\":37235},{\"end\":37254,\"start\":37249},{\"end\":37272,\"start\":37265},{\"end\":37824,\"start\":37821},{\"end\":37840,\"start\":37832},{\"end\":37851,\"start\":37847},{\"end\":37866,\"start\":37859},{\"end\":37881,\"start\":37876},{\"end\":37883,\"start\":37882},{\"end\":37900,\"start\":37892},{\"end\":37917,\"start\":37911},{\"end\":37937,\"start\":37931},{\"end\":37951,\"start\":37945},{\"end\":37966,\"start\":37960},{\"end\":38393,\"start\":38384},{\"end\":38406,\"start\":38400},{\"end\":38427,\"start\":38415},{\"end\":38447,\"start\":38439},{\"end\":38464,\"start\":38458},{\"end\":38479,\"start\":38475},{\"end\":38492,\"start\":38489},{\"end\":38918,\"start\":38913},{\"end\":38929,\"start\":38927},{\"end\":38941,\"start\":38937},{\"end\":38943,\"start\":38942},{\"end\":38957,\"start\":38950},{\"end\":38970,\"start\":38965},{\"end\":39682,\"start\":39675},{\"end\":39695,\"start\":39691},{\"end\":39697,\"start\":39696},{\"end\":39710,\"start\":39705},{\"end\":39727,\"start\":39720},{\"end\":39738,\"start\":39733},{\"end\":39923,\"start\":39919},{\"end\":39937,\"start\":39933},{\"end\":39948,\"start\":39944},{\"end\":39964,\"start\":39958},{\"end\":39981,\"start\":39974},{\"end\":39996,\"start\":39990},{\"end\":40009,\"start\":40002},{\"end\":40025,\"start\":40018},{\"end\":40039,\"start\":40035},{\"end\":40463,\"start\":40454},{\"end\":40476,\"start\":40468},{\"end\":40490,\"start\":40482},{\"end\":40502,\"start\":40496},{\"end\":40790,\"start\":40787},{\"end\":40808,\"start\":40802},{\"end\":40822,\"start\":40816},{\"end\":40837,\"start\":40831},{\"end\":40851,\"start\":40846},{\"end\":40860,\"start\":40856},{\"end\":40872,\"start\":40867},{\"end\":41201,\"start\":41199},{\"end\":41216,\"start\":41212},{\"end\":41234,\"start\":41226},{\"end\":41248,\"start\":41243},{\"end\":41266,\"start\":41261},{\"end\":41283,\"start\":41278},{\"end\":41297,\"start\":41291},{\"end\":41311,\"start\":41307},{\"end\":41330,\"start\":41322},{\"end\":41346,\"start\":41341},{\"end\":42288,\"start\":42286},{\"end\":42305,\"start\":42299},{\"end\":42319,\"start\":42315},{\"end\":42333,\"start\":42329},{\"end\":42346,\"start\":42342},{\"end\":42361,\"start\":42357},{\"end\":42955,\"start\":42950},{\"end\":42967,\"start\":42963},{\"end\":42969,\"start\":42968},{\"end\":42984,\"start\":42977},{\"end\":43003,\"start\":42998},{\"end\":43024,\"start\":43019},{\"end\":43039,\"start\":43032},{\"end\":43054,\"start\":43047},{\"end\":43069,\"start\":43066},{\"end\":43084,\"start\":43078},{\"end\":43101,\"start\":43096},{\"end\":43115,\"start\":43111},{\"end\":43579,\"start\":43573},{\"end\":43591,\"start\":43586},{\"end\":43606,\"start\":43597},{\"end\":43906,\"start\":43899},{\"end\":43918,\"start\":43914},{\"end\":43920,\"start\":43919},{\"end\":44375,\"start\":44367},{\"end\":44387,\"start\":44381},{\"end\":44756,\"start\":44751},{\"end\":44768,\"start\":44762},{\"end\":44786,\"start\":44782},{\"end\":44788,\"start\":44787},{\"end\":44801,\"start\":44796},{\"end\":45365,\"start\":45357},{\"end\":45377,\"start\":45371},{\"end\":45394,\"start\":45388},{\"end\":45406,\"start\":45399},{\"end\":45415,\"start\":45411},{\"end\":45433,\"start\":45425},{\"end\":45451,\"start\":45446},{\"end\":45805,\"start\":45797},{\"end\":45819,\"start\":45814},{\"end\":46104,\"start\":46099},{\"end\":46140,\"start\":46134},{\"end\":46152,\"start\":46146},{\"end\":46154,\"start\":46153},{\"end\":46393,\"start\":46387},{\"end\":46409,\"start\":46403},{\"end\":46425,\"start\":46418},{\"end\":46445,\"start\":46439},{\"end\":46460,\"start\":46455},{\"end\":46475,\"start\":46468},{\"end\":46940,\"start\":46933},{\"end\":46960,\"start\":46957},{\"end\":46966,\"start\":46961},{\"end\":47254,\"start\":47250},{\"end\":47267,\"start\":47263},{\"end\":47274,\"start\":47272},{\"end\":47287,\"start\":47282},{\"end\":47298,\"start\":47297},{\"end\":47314,\"start\":47308},{\"end\":47332,\"start\":47327},{\"end\":47350,\"start\":47342},{\"end\":47366,\"start\":47358},{\"end\":47380,\"start\":47376},{\"end\":47825,\"start\":47818},{\"end\":47841,\"start\":47836},{\"end\":47854,\"start\":47850},{\"end\":47869,\"start\":47861},{\"end\":48348,\"start\":48342},{\"end\":48364,\"start\":48361},{\"end\":48376,\"start\":48369},{\"end\":48746,\"start\":48737},{\"end\":48760,\"start\":48756},{\"end\":48773,\"start\":48767},{\"end\":48787,\"start\":48783},{\"end\":48802,\"start\":48798},{\"end\":48816,\"start\":48813},{\"end\":49555,\"start\":49550},{\"end\":49568,\"start\":49564},{\"end\":49582,\"start\":49578},{\"end\":49601,\"start\":49592},{\"end\":49613,\"start\":49607},{\"end\":49629,\"start\":49622},{\"end\":49643,\"start\":49638},{\"end\":49653,\"start\":49650},{\"end\":49663,\"start\":49658},{\"end\":49665,\"start\":49664},{\"end\":50076,\"start\":50071},{\"end\":50089,\"start\":50085},{\"end\":50103,\"start\":50099},{\"end\":50122,\"start\":50113},{\"end\":50134,\"start\":50128},{\"end\":50150,\"start\":50143},{\"end\":50164,\"start\":50159},{\"end\":50174,\"start\":50171},{\"end\":50180,\"start\":50179},{\"end\":50543,\"start\":50537},{\"end\":50559,\"start\":50555},{\"end\":50577,\"start\":50567},{\"end\":50592,\"start\":50587},{\"end\":51077,\"start\":51069},{\"end\":51100,\"start\":51090},{\"end\":51120,\"start\":51114},{\"end\":51135,\"start\":51131},{\"end\":51149,\"start\":51144},{\"end\":51165,\"start\":51156},{\"end\":51185,\"start\":51177},{\"end\":51203,\"start\":51198},{\"end\":51782,\"start\":51777},{\"end\":51791,\"start\":51788},{\"end\":51802,\"start\":51799},{\"end\":52346,\"start\":52341},{\"end\":52355,\"start\":52352},{\"end\":52366,\"start\":52363},{\"end\":53027,\"start\":53021},{\"end\":53043,\"start\":53038},{\"end\":53057,\"start\":53053},{\"end\":53059,\"start\":53058},{\"end\":53074,\"start\":53067},{\"end\":53095,\"start\":53088},{\"end\":53106,\"start\":53104},{\"end\":53118,\"start\":53114},{\"end\":53120,\"start\":53119},{\"end\":53132,\"start\":53127},{\"end\":53735,\"start\":53728},{\"end\":53747,\"start\":53741},{\"end\":53764,\"start\":53757},{\"end\":53773,\"start\":53770},{\"end\":53785,\"start\":53784},{\"end\":53797,\"start\":53792},{\"end\":54004,\"start\":54000},{\"end\":54020,\"start\":54015},{\"end\":54037,\"start\":54029},{\"end\":54052,\"start\":54048},{\"end\":54066,\"start\":54062},{\"end\":54363,\"start\":54359},{\"end\":54378,\"start\":54374},{\"end\":54672,\"start\":54667},{\"end\":54687,\"start\":54680},{\"end\":54702,\"start\":54696},{\"end\":54717,\"start\":54712},{\"end\":54730,\"start\":54726},{\"end\":55219,\"start\":55213},{\"end\":55233,\"start\":55227},{\"end\":55248,\"start\":55243},{\"end\":55254,\"start\":55253},{\"end\":55267,\"start\":55263},{\"end\":37221,\"start\":37213},{\"end\":37240,\"start\":37235},{\"end\":37254,\"start\":37249},{\"end\":37272,\"start\":37265},{\"end\":37824,\"start\":37821},{\"end\":37840,\"start\":37832},{\"end\":37851,\"start\":37847},{\"end\":37866,\"start\":37859},{\"end\":37881,\"start\":37876},{\"end\":37883,\"start\":37882},{\"end\":37900,\"start\":37892},{\"end\":37917,\"start\":37911},{\"end\":37937,\"start\":37931},{\"end\":37951,\"start\":37945},{\"end\":37966,\"start\":37960},{\"end\":38393,\"start\":38384},{\"end\":38406,\"start\":38400},{\"end\":38427,\"start\":38415},{\"end\":38447,\"start\":38439},{\"end\":38464,\"start\":38458},{\"end\":38479,\"start\":38475},{\"end\":38492,\"start\":38489},{\"end\":38918,\"start\":38913},{\"end\":38929,\"start\":38927},{\"end\":38941,\"start\":38937},{\"end\":38943,\"start\":38942},{\"end\":38957,\"start\":38950},{\"end\":38970,\"start\":38965},{\"end\":39682,\"start\":39675},{\"end\":39695,\"start\":39691},{\"end\":39697,\"start\":39696},{\"end\":39710,\"start\":39705},{\"end\":39727,\"start\":39720},{\"end\":39738,\"start\":39733},{\"end\":39923,\"start\":39919},{\"end\":39937,\"start\":39933},{\"end\":39948,\"start\":39944},{\"end\":39964,\"start\":39958},{\"end\":39981,\"start\":39974},{\"end\":39996,\"start\":39990},{\"end\":40009,\"start\":40002},{\"end\":40025,\"start\":40018},{\"end\":40039,\"start\":40035},{\"end\":40463,\"start\":40454},{\"end\":40476,\"start\":40468},{\"end\":40490,\"start\":40482},{\"end\":40502,\"start\":40496},{\"end\":40790,\"start\":40787},{\"end\":40808,\"start\":40802},{\"end\":40822,\"start\":40816},{\"end\":40837,\"start\":40831},{\"end\":40851,\"start\":40846},{\"end\":40860,\"start\":40856},{\"end\":40872,\"start\":40867},{\"end\":41201,\"start\":41199},{\"end\":41216,\"start\":41212},{\"end\":41234,\"start\":41226},{\"end\":41248,\"start\":41243},{\"end\":41266,\"start\":41261},{\"end\":41283,\"start\":41278},{\"end\":41297,\"start\":41291},{\"end\":41311,\"start\":41307},{\"end\":41330,\"start\":41322},{\"end\":41346,\"start\":41341},{\"end\":42288,\"start\":42286},{\"end\":42305,\"start\":42299},{\"end\":42319,\"start\":42315},{\"end\":42333,\"start\":42329},{\"end\":42346,\"start\":42342},{\"end\":42361,\"start\":42357},{\"end\":42955,\"start\":42950},{\"end\":42967,\"start\":42963},{\"end\":42969,\"start\":42968},{\"end\":42984,\"start\":42977},{\"end\":43003,\"start\":42998},{\"end\":43024,\"start\":43019},{\"end\":43039,\"start\":43032},{\"end\":43054,\"start\":43047},{\"end\":43069,\"start\":43066},{\"end\":43084,\"start\":43078},{\"end\":43101,\"start\":43096},{\"end\":43115,\"start\":43111},{\"end\":43579,\"start\":43573},{\"end\":43591,\"start\":43586},{\"end\":43606,\"start\":43597},{\"end\":43906,\"start\":43899},{\"end\":43918,\"start\":43914},{\"end\":43920,\"start\":43919},{\"end\":44375,\"start\":44367},{\"end\":44387,\"start\":44381},{\"end\":44756,\"start\":44751},{\"end\":44768,\"start\":44762},{\"end\":44786,\"start\":44782},{\"end\":44788,\"start\":44787},{\"end\":44801,\"start\":44796},{\"end\":45365,\"start\":45357},{\"end\":45377,\"start\":45371},{\"end\":45394,\"start\":45388},{\"end\":45406,\"start\":45399},{\"end\":45415,\"start\":45411},{\"end\":45433,\"start\":45425},{\"end\":45451,\"start\":45446},{\"end\":45805,\"start\":45797},{\"end\":45819,\"start\":45814},{\"end\":46104,\"start\":46099},{\"end\":46140,\"start\":46134},{\"end\":46152,\"start\":46146},{\"end\":46154,\"start\":46153},{\"end\":46393,\"start\":46387},{\"end\":46409,\"start\":46403},{\"end\":46425,\"start\":46418},{\"end\":46445,\"start\":46439},{\"end\":46460,\"start\":46455},{\"end\":46475,\"start\":46468},{\"end\":46940,\"start\":46933},{\"end\":46960,\"start\":46957},{\"end\":46966,\"start\":46961},{\"end\":47254,\"start\":47250},{\"end\":47267,\"start\":47263},{\"end\":47274,\"start\":47272},{\"end\":47287,\"start\":47282},{\"end\":47298,\"start\":47297},{\"end\":47314,\"start\":47308},{\"end\":47332,\"start\":47327},{\"end\":47350,\"start\":47342},{\"end\":47366,\"start\":47358},{\"end\":47380,\"start\":47376},{\"end\":47825,\"start\":47818},{\"end\":47841,\"start\":47836},{\"end\":47854,\"start\":47850},{\"end\":47869,\"start\":47861},{\"end\":48348,\"start\":48342},{\"end\":48364,\"start\":48361},{\"end\":48376,\"start\":48369},{\"end\":48746,\"start\":48737},{\"end\":48760,\"start\":48756},{\"end\":48773,\"start\":48767},{\"end\":48787,\"start\":48783},{\"end\":48802,\"start\":48798},{\"end\":48816,\"start\":48813},{\"end\":49555,\"start\":49550},{\"end\":49568,\"start\":49564},{\"end\":49582,\"start\":49578},{\"end\":49601,\"start\":49592},{\"end\":49613,\"start\":49607},{\"end\":49629,\"start\":49622},{\"end\":49643,\"start\":49638},{\"end\":49653,\"start\":49650},{\"end\":49663,\"start\":49658},{\"end\":49665,\"start\":49664},{\"end\":50076,\"start\":50071},{\"end\":50089,\"start\":50085},{\"end\":50103,\"start\":50099},{\"end\":50122,\"start\":50113},{\"end\":50134,\"start\":50128},{\"end\":50150,\"start\":50143},{\"end\":50164,\"start\":50159},{\"end\":50174,\"start\":50171},{\"end\":50180,\"start\":50179},{\"end\":50543,\"start\":50537},{\"end\":50559,\"start\":50555},{\"end\":50577,\"start\":50567},{\"end\":50592,\"start\":50587},{\"end\":51077,\"start\":51069},{\"end\":51100,\"start\":51090},{\"end\":51120,\"start\":51114},{\"end\":51135,\"start\":51131},{\"end\":51149,\"start\":51144},{\"end\":51165,\"start\":51156},{\"end\":51185,\"start\":51177},{\"end\":51203,\"start\":51198},{\"end\":51782,\"start\":51777},{\"end\":51791,\"start\":51788},{\"end\":51802,\"start\":51799},{\"end\":52346,\"start\":52341},{\"end\":52355,\"start\":52352},{\"end\":52366,\"start\":52363},{\"end\":53027,\"start\":53021},{\"end\":53043,\"start\":53038},{\"end\":53057,\"start\":53053},{\"end\":53059,\"start\":53058},{\"end\":53074,\"start\":53067},{\"end\":53095,\"start\":53088},{\"end\":53106,\"start\":53104},{\"end\":53118,\"start\":53114},{\"end\":53120,\"start\":53119},{\"end\":53132,\"start\":53127},{\"end\":53735,\"start\":53728},{\"end\":53747,\"start\":53741},{\"end\":53764,\"start\":53757},{\"end\":53773,\"start\":53770},{\"end\":53785,\"start\":53784},{\"end\":53797,\"start\":53792},{\"end\":54004,\"start\":54000},{\"end\":54020,\"start\":54015},{\"end\":54037,\"start\":54029},{\"end\":54052,\"start\":54048},{\"end\":54066,\"start\":54062},{\"end\":54363,\"start\":54359},{\"end\":54378,\"start\":54374},{\"end\":54672,\"start\":54667},{\"end\":54687,\"start\":54680},{\"end\":54702,\"start\":54696},{\"end\":54717,\"start\":54712},{\"end\":54730,\"start\":54726},{\"end\":55219,\"start\":55213},{\"end\":55233,\"start\":55227},{\"end\":55248,\"start\":55243},{\"end\":55254,\"start\":55253},{\"end\":55267,\"start\":55263}]", "bib_author_last_name": "[{\"end\":37233,\"start\":37222},{\"end\":37247,\"start\":37241},{\"end\":37263,\"start\":37255},{\"end\":37278,\"start\":37273},{\"end\":37830,\"start\":37825},{\"end\":37845,\"start\":37841},{\"end\":37857,\"start\":37852},{\"end\":37874,\"start\":37867},{\"end\":37890,\"start\":37884},{\"end\":37909,\"start\":37901},{\"end\":37929,\"start\":37918},{\"end\":37943,\"start\":37938},{\"end\":37958,\"start\":37952},{\"end\":37973,\"start\":37967},{\"end\":38398,\"start\":38394},{\"end\":38413,\"start\":38407},{\"end\":38437,\"start\":38428},{\"end\":38456,\"start\":38448},{\"end\":38473,\"start\":38465},{\"end\":38487,\"start\":38480},{\"end\":38497,\"start\":38493},{\"end\":38925,\"start\":38919},{\"end\":38935,\"start\":38930},{\"end\":38948,\"start\":38944},{\"end\":38963,\"start\":38958},{\"end\":38977,\"start\":38971},{\"end\":38983,\"start\":38979},{\"end\":39689,\"start\":39683},{\"end\":39703,\"start\":39698},{\"end\":39718,\"start\":39711},{\"end\":39731,\"start\":39728},{\"end\":39743,\"start\":39739},{\"end\":39931,\"start\":39924},{\"end\":39942,\"start\":39938},{\"end\":39956,\"start\":39949},{\"end\":39972,\"start\":39965},{\"end\":39988,\"start\":39982},{\"end\":40000,\"start\":39997},{\"end\":40016,\"start\":40010},{\"end\":40033,\"start\":40026},{\"end\":40051,\"start\":40040},{\"end\":40466,\"start\":40464},{\"end\":40480,\"start\":40477},{\"end\":40494,\"start\":40491},{\"end\":40507,\"start\":40503},{\"end\":40800,\"start\":40791},{\"end\":40814,\"start\":40809},{\"end\":40829,\"start\":40823},{\"end\":40844,\"start\":40838},{\"end\":40854,\"start\":40852},{\"end\":40865,\"start\":40861},{\"end\":40883,\"start\":40873},{\"end\":41210,\"start\":41202},{\"end\":41224,\"start\":41217},{\"end\":41241,\"start\":41235},{\"end\":41259,\"start\":41249},{\"end\":41276,\"start\":41267},{\"end\":41289,\"start\":41284},{\"end\":41305,\"start\":41298},{\"end\":41320,\"start\":41312},{\"end\":41339,\"start\":41331},{\"end\":41353,\"start\":41347},{\"end\":42297,\"start\":42289},{\"end\":42313,\"start\":42306},{\"end\":42327,\"start\":42320},{\"end\":42340,\"start\":42334},{\"end\":42355,\"start\":42347},{\"end\":42367,\"start\":42362},{\"end\":42961,\"start\":42956},{\"end\":42975,\"start\":42970},{\"end\":42996,\"start\":42985},{\"end\":43017,\"start\":43004},{\"end\":43030,\"start\":43025},{\"end\":43045,\"start\":43040},{\"end\":43064,\"start\":43055},{\"end\":43076,\"start\":43070},{\"end\":43094,\"start\":43085},{\"end\":43109,\"start\":43102},{\"end\":43124,\"start\":43116},{\"end\":43133,\"start\":43126},{\"end\":43584,\"start\":43580},{\"end\":43595,\"start\":43592},{\"end\":43615,\"start\":43607},{\"end\":43912,\"start\":43907},{\"end\":43926,\"start\":43921},{\"end\":44379,\"start\":44376},{\"end\":44392,\"start\":44388},{\"end\":44760,\"start\":44757},{\"end\":44780,\"start\":44769},{\"end\":44794,\"start\":44789},{\"end\":44806,\"start\":44802},{\"end\":45369,\"start\":45366},{\"end\":45386,\"start\":45378},{\"end\":45397,\"start\":45395},{\"end\":45409,\"start\":45407},{\"end\":45423,\"start\":45416},{\"end\":45444,\"start\":45434},{\"end\":45456,\"start\":45452},{\"end\":45812,\"start\":45806},{\"end\":45833,\"start\":45820},{\"end\":45839,\"start\":45835},{\"end\":46132,\"start\":46105},{\"end\":46144,\"start\":46141},{\"end\":46161,\"start\":46155},{\"end\":46170,\"start\":46163},{\"end\":46401,\"start\":46394},{\"end\":46416,\"start\":46410},{\"end\":46437,\"start\":46426},{\"end\":46453,\"start\":46446},{\"end\":46466,\"start\":46461},{\"end\":46480,\"start\":46476},{\"end\":46955,\"start\":46941},{\"end\":46971,\"start\":46967},{\"end\":46976,\"start\":46973},{\"end\":47261,\"start\":47255},{\"end\":47270,\"start\":47268},{\"end\":47280,\"start\":47275},{\"end\":47295,\"start\":47288},{\"end\":47306,\"start\":47299},{\"end\":47325,\"start\":47315},{\"end\":47340,\"start\":47333},{\"end\":47356,\"start\":47351},{\"end\":47374,\"start\":47367},{\"end\":47386,\"start\":47381},{\"end\":47391,\"start\":47388},{\"end\":47834,\"start\":47826},{\"end\":47848,\"start\":47842},{\"end\":47859,\"start\":47855},{\"end\":47873,\"start\":47870},{\"end\":48359,\"start\":48349},{\"end\":48367,\"start\":48365},{\"end\":48383,\"start\":48377},{\"end\":48754,\"start\":48747},{\"end\":48765,\"start\":48761},{\"end\":48781,\"start\":48774},{\"end\":48796,\"start\":48788},{\"end\":48811,\"start\":48803},{\"end\":48822,\"start\":48817},{\"end\":49562,\"start\":49556},{\"end\":49576,\"start\":49569},{\"end\":49590,\"start\":49583},{\"end\":49605,\"start\":49602},{\"end\":49620,\"start\":49614},{\"end\":49636,\"start\":49630},{\"end\":49648,\"start\":49644},{\"end\":49656,\"start\":49654},{\"end\":49669,\"start\":49666},{\"end\":50083,\"start\":50077},{\"end\":50097,\"start\":50090},{\"end\":50111,\"start\":50104},{\"end\":50126,\"start\":50123},{\"end\":50141,\"start\":50135},{\"end\":50157,\"start\":50151},{\"end\":50169,\"start\":50165},{\"end\":50177,\"start\":50175},{\"end\":50186,\"start\":50181},{\"end\":50191,\"start\":50188},{\"end\":50553,\"start\":50544},{\"end\":50565,\"start\":50560},{\"end\":50585,\"start\":50578},{\"end\":50598,\"start\":50593},{\"end\":51088,\"start\":51078},{\"end\":51112,\"start\":51101},{\"end\":51129,\"start\":51121},{\"end\":51142,\"start\":51136},{\"end\":51154,\"start\":51150},{\"end\":51175,\"start\":51166},{\"end\":51196,\"start\":51186},{\"end\":51208,\"start\":51204},{\"end\":51786,\"start\":51783},{\"end\":51797,\"start\":51792},{\"end\":52350,\"start\":52347},{\"end\":52361,\"start\":52356},{\"end\":53036,\"start\":53028},{\"end\":53051,\"start\":53044},{\"end\":53065,\"start\":53060},{\"end\":53086,\"start\":53075},{\"end\":53102,\"start\":53096},{\"end\":53112,\"start\":53107},{\"end\":53125,\"start\":53121},{\"end\":53138,\"start\":53133},{\"end\":53144,\"start\":53140},{\"end\":53739,\"start\":53736},{\"end\":53755,\"start\":53748},{\"end\":53768,\"start\":53765},{\"end\":53782,\"start\":53774},{\"end\":53790,\"start\":53786},{\"end\":53803,\"start\":53798},{\"end\":53809,\"start\":53805},{\"end\":54013,\"start\":54005},{\"end\":54027,\"start\":54021},{\"end\":54046,\"start\":54038},{\"end\":54060,\"start\":54053},{\"end\":54073,\"start\":54067},{\"end\":54372,\"start\":54364},{\"end\":54383,\"start\":54379},{\"end\":54678,\"start\":54673},{\"end\":54694,\"start\":54688},{\"end\":54710,\"start\":54703},{\"end\":54724,\"start\":54718},{\"end\":54738,\"start\":54731},{\"end\":55225,\"start\":55220},{\"end\":55241,\"start\":55234},{\"end\":55251,\"start\":55249},{\"end\":55261,\"start\":55255},{\"end\":55278,\"start\":55268},{\"end\":55285,\"start\":55280},{\"end\":37233,\"start\":37222},{\"end\":37247,\"start\":37241},{\"end\":37263,\"start\":37255},{\"end\":37278,\"start\":37273},{\"end\":37830,\"start\":37825},{\"end\":37845,\"start\":37841},{\"end\":37857,\"start\":37852},{\"end\":37874,\"start\":37867},{\"end\":37890,\"start\":37884},{\"end\":37909,\"start\":37901},{\"end\":37929,\"start\":37918},{\"end\":37943,\"start\":37938},{\"end\":37958,\"start\":37952},{\"end\":37973,\"start\":37967},{\"end\":38398,\"start\":38394},{\"end\":38413,\"start\":38407},{\"end\":38437,\"start\":38428},{\"end\":38456,\"start\":38448},{\"end\":38473,\"start\":38465},{\"end\":38487,\"start\":38480},{\"end\":38497,\"start\":38493},{\"end\":38925,\"start\":38919},{\"end\":38935,\"start\":38930},{\"end\":38948,\"start\":38944},{\"end\":38963,\"start\":38958},{\"end\":38977,\"start\":38971},{\"end\":38983,\"start\":38979},{\"end\":39689,\"start\":39683},{\"end\":39703,\"start\":39698},{\"end\":39718,\"start\":39711},{\"end\":39731,\"start\":39728},{\"end\":39743,\"start\":39739},{\"end\":39931,\"start\":39924},{\"end\":39942,\"start\":39938},{\"end\":39956,\"start\":39949},{\"end\":39972,\"start\":39965},{\"end\":39988,\"start\":39982},{\"end\":40000,\"start\":39997},{\"end\":40016,\"start\":40010},{\"end\":40033,\"start\":40026},{\"end\":40051,\"start\":40040},{\"end\":40466,\"start\":40464},{\"end\":40480,\"start\":40477},{\"end\":40494,\"start\":40491},{\"end\":40507,\"start\":40503},{\"end\":40800,\"start\":40791},{\"end\":40814,\"start\":40809},{\"end\":40829,\"start\":40823},{\"end\":40844,\"start\":40838},{\"end\":40854,\"start\":40852},{\"end\":40865,\"start\":40861},{\"end\":40883,\"start\":40873},{\"end\":41210,\"start\":41202},{\"end\":41224,\"start\":41217},{\"end\":41241,\"start\":41235},{\"end\":41259,\"start\":41249},{\"end\":41276,\"start\":41267},{\"end\":41289,\"start\":41284},{\"end\":41305,\"start\":41298},{\"end\":41320,\"start\":41312},{\"end\":41339,\"start\":41331},{\"end\":41353,\"start\":41347},{\"end\":42297,\"start\":42289},{\"end\":42313,\"start\":42306},{\"end\":42327,\"start\":42320},{\"end\":42340,\"start\":42334},{\"end\":42355,\"start\":42347},{\"end\":42367,\"start\":42362},{\"end\":42961,\"start\":42956},{\"end\":42975,\"start\":42970},{\"end\":42996,\"start\":42985},{\"end\":43017,\"start\":43004},{\"end\":43030,\"start\":43025},{\"end\":43045,\"start\":43040},{\"end\":43064,\"start\":43055},{\"end\":43076,\"start\":43070},{\"end\":43094,\"start\":43085},{\"end\":43109,\"start\":43102},{\"end\":43124,\"start\":43116},{\"end\":43133,\"start\":43126},{\"end\":43584,\"start\":43580},{\"end\":43595,\"start\":43592},{\"end\":43615,\"start\":43607},{\"end\":43912,\"start\":43907},{\"end\":43926,\"start\":43921},{\"end\":44379,\"start\":44376},{\"end\":44392,\"start\":44388},{\"end\":44760,\"start\":44757},{\"end\":44780,\"start\":44769},{\"end\":44794,\"start\":44789},{\"end\":44806,\"start\":44802},{\"end\":45369,\"start\":45366},{\"end\":45386,\"start\":45378},{\"end\":45397,\"start\":45395},{\"end\":45409,\"start\":45407},{\"end\":45423,\"start\":45416},{\"end\":45444,\"start\":45434},{\"end\":45456,\"start\":45452},{\"end\":45812,\"start\":45806},{\"end\":45833,\"start\":45820},{\"end\":45839,\"start\":45835},{\"end\":46132,\"start\":46105},{\"end\":46144,\"start\":46141},{\"end\":46161,\"start\":46155},{\"end\":46170,\"start\":46163},{\"end\":46401,\"start\":46394},{\"end\":46416,\"start\":46410},{\"end\":46437,\"start\":46426},{\"end\":46453,\"start\":46446},{\"end\":46466,\"start\":46461},{\"end\":46480,\"start\":46476},{\"end\":46955,\"start\":46941},{\"end\":46971,\"start\":46967},{\"end\":46976,\"start\":46973},{\"end\":47261,\"start\":47255},{\"end\":47270,\"start\":47268},{\"end\":47280,\"start\":47275},{\"end\":47295,\"start\":47288},{\"end\":47306,\"start\":47299},{\"end\":47325,\"start\":47315},{\"end\":47340,\"start\":47333},{\"end\":47356,\"start\":47351},{\"end\":47374,\"start\":47367},{\"end\":47386,\"start\":47381},{\"end\":47391,\"start\":47388},{\"end\":47834,\"start\":47826},{\"end\":47848,\"start\":47842},{\"end\":47859,\"start\":47855},{\"end\":47873,\"start\":47870},{\"end\":48359,\"start\":48349},{\"end\":48367,\"start\":48365},{\"end\":48383,\"start\":48377},{\"end\":48754,\"start\":48747},{\"end\":48765,\"start\":48761},{\"end\":48781,\"start\":48774},{\"end\":48796,\"start\":48788},{\"end\":48811,\"start\":48803},{\"end\":48822,\"start\":48817},{\"end\":49562,\"start\":49556},{\"end\":49576,\"start\":49569},{\"end\":49590,\"start\":49583},{\"end\":49605,\"start\":49602},{\"end\":49620,\"start\":49614},{\"end\":49636,\"start\":49630},{\"end\":49648,\"start\":49644},{\"end\":49656,\"start\":49654},{\"end\":49669,\"start\":49666},{\"end\":50083,\"start\":50077},{\"end\":50097,\"start\":50090},{\"end\":50111,\"start\":50104},{\"end\":50126,\"start\":50123},{\"end\":50141,\"start\":50135},{\"end\":50157,\"start\":50151},{\"end\":50169,\"start\":50165},{\"end\":50177,\"start\":50175},{\"end\":50186,\"start\":50181},{\"end\":50191,\"start\":50188},{\"end\":50553,\"start\":50544},{\"end\":50565,\"start\":50560},{\"end\":50585,\"start\":50578},{\"end\":50598,\"start\":50593},{\"end\":51088,\"start\":51078},{\"end\":51112,\"start\":51101},{\"end\":51129,\"start\":51121},{\"end\":51142,\"start\":51136},{\"end\":51154,\"start\":51150},{\"end\":51175,\"start\":51166},{\"end\":51196,\"start\":51186},{\"end\":51208,\"start\":51204},{\"end\":51786,\"start\":51783},{\"end\":51797,\"start\":51792},{\"end\":52350,\"start\":52347},{\"end\":52361,\"start\":52356},{\"end\":53036,\"start\":53028},{\"end\":53051,\"start\":53044},{\"end\":53065,\"start\":53060},{\"end\":53086,\"start\":53075},{\"end\":53102,\"start\":53096},{\"end\":53112,\"start\":53107},{\"end\":53125,\"start\":53121},{\"end\":53138,\"start\":53133},{\"end\":53144,\"start\":53140},{\"end\":53739,\"start\":53736},{\"end\":53755,\"start\":53748},{\"end\":53768,\"start\":53765},{\"end\":53782,\"start\":53774},{\"end\":53790,\"start\":53786},{\"end\":53803,\"start\":53798},{\"end\":53809,\"start\":53805},{\"end\":54013,\"start\":54005},{\"end\":54027,\"start\":54021},{\"end\":54046,\"start\":54038},{\"end\":54060,\"start\":54053},{\"end\":54073,\"start\":54067},{\"end\":54372,\"start\":54364},{\"end\":54383,\"start\":54379},{\"end\":54678,\"start\":54673},{\"end\":54694,\"start\":54688},{\"end\":54710,\"start\":54703},{\"end\":54724,\"start\":54718},{\"end\":54738,\"start\":54731},{\"end\":55225,\"start\":55220},{\"end\":55241,\"start\":55234},{\"end\":55251,\"start\":55249},{\"end\":55261,\"start\":55255},{\"end\":55278,\"start\":55268},{\"end\":55285,\"start\":55280}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":196623463},\"end\":37780,\"start\":37135},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":218971783},\"end\":38298,\"start\":37782},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":3700344},\"end\":38822,\"start\":38300},{\"attributes\":{\"doi\":\"10.18653/v1/2021.emnlp-main.54\",\"id\":\"b3\",\"matched_paper_id\":229923749},\"end\":39624,\"start\":38824},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":226226666},\"end\":39917,\"start\":39626},{\"attributes\":{\"doi\":\"arXiv:1803.07640\",\"id\":\"b5\"},\"end\":40391,\"start\":39919},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":219531210},\"end\":40745,\"start\":40393},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":220968818},\"end\":41145,\"start\":40747},{\"attributes\":{\"doi\":\"10.18653/v1/2022.naacl-main.287\",\"id\":\"b8\",\"matched_paper_id\":247694170},\"end\":42174,\"start\":41147},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":233289483},\"end\":42848,\"start\":42176},{\"attributes\":{\"doi\":\"arXiv:2110.07574\",\"id\":\"b10\"},\"end\":43489,\"start\":42850},{\"attributes\":{\"doi\":\"arXiv:2212.07769\",\"id\":\"b11\"},\"end\":43817,\"start\":43491},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":219558484},\"end\":44319,\"start\":43819},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":40166767},\"end\":44665,\"start\":44321},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":246016339},\"end\":45276,\"start\":44667},{\"attributes\":{\"doi\":\"arXiv:2210.03078\",\"id\":\"b15\"},\"end\":45713,\"start\":45278},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":221186813},\"end\":45991,\"start\":45715},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":233231257},\"end\":46385,\"start\":45993},{\"attributes\":{\"doi\":\"arXiv:2207.00397\",\"id\":\"b18\"},\"end\":46841,\"start\":46387},{\"attributes\":{\"doi\":\"PMLR\",\"id\":\"b19\",\"matched_paper_id\":246431050},\"end\":47248,\"start\":46843},{\"attributes\":{\"doi\":\"arXiv:2203.02155\",\"id\":\"b20\"},\"end\":47752,\"start\":47250},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":11080756},\"end\":48278,\"start\":47754},{\"attributes\":{\"doi\":\"10.1162/tacl_a_00484\",\"id\":\"b22\",\"matched_paper_id\":247158348},\"end\":48661,\"start\":48280},{\"attributes\":{\"doi\":\"10.18653/v1/2021.emnlp-main.108\",\"id\":\"b23\",\"matched_paper_id\":237485410},\"end\":49466,\"start\":48663},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":204838007},\"end\":49986,\"start\":49468},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":204838007},\"end\":50474,\"start\":49988},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":11816014},\"end\":51002,\"start\":50476},{\"attributes\":{\"doi\":\"arXiv:2210.01241\",\"id\":\"b27\",\"matched_paper_id\":252693405},\"end\":51659,\"start\":51004},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":29152969},\"end\":52265,\"start\":51661},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":102353371},\"end\":52952,\"start\":52267},{\"attributes\":{\"doi\":\"10.18653/v1/2020.findings-emnlp.418\",\"id\":\"b30\",\"matched_paper_id\":226283602},\"end\":53647,\"start\":52954},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":207853290},\"end\":53998,\"start\":53649},{\"attributes\":{\"doi\":\"arXiv:1707.06347\",\"id\":\"b32\"},\"end\":54304,\"start\":54000},{\"attributes\":{\"id\":\"b33\"},\"end\":54592,\"start\":54306},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":239024611},\"end\":55162,\"start\":54594},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":127986044},\"end\":55531,\"start\":55164},{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":196623463},\"end\":37780,\"start\":37135},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":218971783},\"end\":38298,\"start\":37782},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":3700344},\"end\":38822,\"start\":38300},{\"attributes\":{\"doi\":\"10.18653/v1/2021.emnlp-main.54\",\"id\":\"b3\",\"matched_paper_id\":229923749},\"end\":39624,\"start\":38824},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":226226666},\"end\":39917,\"start\":39626},{\"attributes\":{\"doi\":\"arXiv:1803.07640\",\"id\":\"b5\"},\"end\":40391,\"start\":39919},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":219531210},\"end\":40745,\"start\":40393},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":220968818},\"end\":41145,\"start\":40747},{\"attributes\":{\"doi\":\"10.18653/v1/2022.naacl-main.287\",\"id\":\"b8\",\"matched_paper_id\":247694170},\"end\":42174,\"start\":41147},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":233289483},\"end\":42848,\"start\":42176},{\"attributes\":{\"doi\":\"arXiv:2110.07574\",\"id\":\"b10\"},\"end\":43489,\"start\":42850},{\"attributes\":{\"doi\":\"arXiv:2212.07769\",\"id\":\"b11\"},\"end\":43817,\"start\":43491},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":219558484},\"end\":44319,\"start\":43819},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":40166767},\"end\":44665,\"start\":44321},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":246016339},\"end\":45276,\"start\":44667},{\"attributes\":{\"doi\":\"arXiv:2210.03078\",\"id\":\"b15\"},\"end\":45713,\"start\":45278},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":221186813},\"end\":45991,\"start\":45715},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":233231257},\"end\":46385,\"start\":45993},{\"attributes\":{\"doi\":\"arXiv:2207.00397\",\"id\":\"b18\"},\"end\":46841,\"start\":46387},{\"attributes\":{\"doi\":\"PMLR\",\"id\":\"b19\",\"matched_paper_id\":246431050},\"end\":47248,\"start\":46843},{\"attributes\":{\"doi\":\"arXiv:2203.02155\",\"id\":\"b20\"},\"end\":47752,\"start\":47250},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":11080756},\"end\":48278,\"start\":47754},{\"attributes\":{\"doi\":\"10.1162/tacl_a_00484\",\"id\":\"b22\",\"matched_paper_id\":247158348},\"end\":48661,\"start\":48280},{\"attributes\":{\"doi\":\"10.18653/v1/2021.emnlp-main.108\",\"id\":\"b23\",\"matched_paper_id\":237485410},\"end\":49466,\"start\":48663},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":204838007},\"end\":49986,\"start\":49468},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":204838007},\"end\":50474,\"start\":49988},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":11816014},\"end\":51002,\"start\":50476},{\"attributes\":{\"doi\":\"arXiv:2210.01241\",\"id\":\"b27\",\"matched_paper_id\":252693405},\"end\":51659,\"start\":51004},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":29152969},\"end\":52265,\"start\":51661},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":102353371},\"end\":52952,\"start\":52267},{\"attributes\":{\"doi\":\"10.18653/v1/2020.findings-emnlp.418\",\"id\":\"b30\",\"matched_paper_id\":226283602},\"end\":53647,\"start\":52954},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":207853290},\"end\":53998,\"start\":53649},{\"attributes\":{\"doi\":\"arXiv:1707.06347\",\"id\":\"b32\"},\"end\":54304,\"start\":54000},{\"attributes\":{\"id\":\"b33\"},\"end\":54592,\"start\":54306},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":239024611},\"end\":55162,\"start\":54594},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":127986044},\"end\":55531,\"start\":55164}]", "bib_title": "[{\"end\":37211,\"start\":37135},{\"end\":37819,\"start\":37782},{\"end\":38382,\"start\":38300},{\"end\":38911,\"start\":38824},{\"end\":39673,\"start\":39626},{\"end\":40452,\"start\":40393},{\"end\":40785,\"start\":40747},{\"end\":41197,\"start\":41147},{\"end\":42284,\"start\":42176},{\"end\":43897,\"start\":43819},{\"end\":44365,\"start\":44321},{\"end\":44749,\"start\":44667},{\"end\":45795,\"start\":45715},{\"end\":46097,\"start\":45993},{\"end\":46931,\"start\":46843},{\"end\":47816,\"start\":47754},{\"end\":48340,\"start\":48280},{\"end\":48735,\"start\":48663},{\"end\":49548,\"start\":49468},{\"end\":50069,\"start\":49988},{\"end\":50535,\"start\":50476},{\"end\":51067,\"start\":51004},{\"end\":51775,\"start\":51661},{\"end\":52339,\"start\":52267},{\"end\":53019,\"start\":52954},{\"end\":53726,\"start\":53649},{\"end\":54357,\"start\":54306},{\"end\":54665,\"start\":54594},{\"end\":55211,\"start\":55164},{\"end\":37211,\"start\":37135},{\"end\":37819,\"start\":37782},{\"end\":38382,\"start\":38300},{\"end\":38911,\"start\":38824},{\"end\":39673,\"start\":39626},{\"end\":40452,\"start\":40393},{\"end\":40785,\"start\":40747},{\"end\":41197,\"start\":41147},{\"end\":42284,\"start\":42176},{\"end\":43897,\"start\":43819},{\"end\":44365,\"start\":44321},{\"end\":44749,\"start\":44667},{\"end\":45795,\"start\":45715},{\"end\":46097,\"start\":45993},{\"end\":46931,\"start\":46843},{\"end\":47816,\"start\":47754},{\"end\":48340,\"start\":48280},{\"end\":48735,\"start\":48663},{\"end\":49548,\"start\":49468},{\"end\":50069,\"start\":49988},{\"end\":50535,\"start\":50476},{\"end\":51067,\"start\":51004},{\"end\":51775,\"start\":51661},{\"end\":52339,\"start\":52267},{\"end\":53019,\"start\":52954},{\"end\":53726,\"start\":53649},{\"end\":54357,\"start\":54306},{\"end\":54665,\"start\":54594},{\"end\":55211,\"start\":55164}]", "bib_author": "[{\"end\":37235,\"start\":37213},{\"end\":37249,\"start\":37235},{\"end\":37265,\"start\":37249},{\"end\":37280,\"start\":37265},{\"end\":37832,\"start\":37821},{\"end\":37847,\"start\":37832},{\"end\":37859,\"start\":37847},{\"end\":37876,\"start\":37859},{\"end\":37892,\"start\":37876},{\"end\":37911,\"start\":37892},{\"end\":37931,\"start\":37911},{\"end\":37945,\"start\":37931},{\"end\":37960,\"start\":37945},{\"end\":37975,\"start\":37960},{\"end\":38400,\"start\":38384},{\"end\":38415,\"start\":38400},{\"end\":38439,\"start\":38415},{\"end\":38458,\"start\":38439},{\"end\":38475,\"start\":38458},{\"end\":38489,\"start\":38475},{\"end\":38499,\"start\":38489},{\"end\":38927,\"start\":38913},{\"end\":38937,\"start\":38927},{\"end\":38950,\"start\":38937},{\"end\":38965,\"start\":38950},{\"end\":38979,\"start\":38965},{\"end\":38985,\"start\":38979},{\"end\":39691,\"start\":39675},{\"end\":39705,\"start\":39691},{\"end\":39720,\"start\":39705},{\"end\":39733,\"start\":39720},{\"end\":39745,\"start\":39733},{\"end\":39933,\"start\":39919},{\"end\":39944,\"start\":39933},{\"end\":39958,\"start\":39944},{\"end\":39974,\"start\":39958},{\"end\":39990,\"start\":39974},{\"end\":40002,\"start\":39990},{\"end\":40018,\"start\":40002},{\"end\":40035,\"start\":40018},{\"end\":40053,\"start\":40035},{\"end\":40468,\"start\":40454},{\"end\":40482,\"start\":40468},{\"end\":40496,\"start\":40482},{\"end\":40509,\"start\":40496},{\"end\":40802,\"start\":40787},{\"end\":40816,\"start\":40802},{\"end\":40831,\"start\":40816},{\"end\":40846,\"start\":40831},{\"end\":40856,\"start\":40846},{\"end\":40867,\"start\":40856},{\"end\":40885,\"start\":40867},{\"end\":41212,\"start\":41199},{\"end\":41226,\"start\":41212},{\"end\":41243,\"start\":41226},{\"end\":41261,\"start\":41243},{\"end\":41278,\"start\":41261},{\"end\":41291,\"start\":41278},{\"end\":41307,\"start\":41291},{\"end\":41322,\"start\":41307},{\"end\":41341,\"start\":41322},{\"end\":41355,\"start\":41341},{\"end\":42299,\"start\":42286},{\"end\":42315,\"start\":42299},{\"end\":42329,\"start\":42315},{\"end\":42342,\"start\":42329},{\"end\":42357,\"start\":42342},{\"end\":42369,\"start\":42357},{\"end\":42963,\"start\":42950},{\"end\":42977,\"start\":42963},{\"end\":42998,\"start\":42977},{\"end\":43019,\"start\":42998},{\"end\":43032,\"start\":43019},{\"end\":43047,\"start\":43032},{\"end\":43066,\"start\":43047},{\"end\":43078,\"start\":43066},{\"end\":43096,\"start\":43078},{\"end\":43111,\"start\":43096},{\"end\":43126,\"start\":43111},{\"end\":43135,\"start\":43126},{\"end\":43586,\"start\":43573},{\"end\":43597,\"start\":43586},{\"end\":43617,\"start\":43597},{\"end\":43914,\"start\":43899},{\"end\":43928,\"start\":43914},{\"end\":44381,\"start\":44367},{\"end\":44394,\"start\":44381},{\"end\":44762,\"start\":44751},{\"end\":44782,\"start\":44762},{\"end\":44796,\"start\":44782},{\"end\":44808,\"start\":44796},{\"end\":45371,\"start\":45357},{\"end\":45388,\"start\":45371},{\"end\":45399,\"start\":45388},{\"end\":45411,\"start\":45399},{\"end\":45425,\"start\":45411},{\"end\":45446,\"start\":45425},{\"end\":45458,\"start\":45446},{\"end\":45814,\"start\":45797},{\"end\":45835,\"start\":45814},{\"end\":45841,\"start\":45835},{\"end\":46134,\"start\":46099},{\"end\":46146,\"start\":46134},{\"end\":46163,\"start\":46146},{\"end\":46172,\"start\":46163},{\"end\":46403,\"start\":46387},{\"end\":46418,\"start\":46403},{\"end\":46439,\"start\":46418},{\"end\":46455,\"start\":46439},{\"end\":46468,\"start\":46455},{\"end\":46482,\"start\":46468},{\"end\":46957,\"start\":46933},{\"end\":46973,\"start\":46957},{\"end\":46978,\"start\":46973},{\"end\":47263,\"start\":47250},{\"end\":47272,\"start\":47263},{\"end\":47282,\"start\":47272},{\"end\":47297,\"start\":47282},{\"end\":47308,\"start\":47297},{\"end\":47327,\"start\":47308},{\"end\":47342,\"start\":47327},{\"end\":47358,\"start\":47342},{\"end\":47376,\"start\":47358},{\"end\":47388,\"start\":47376},{\"end\":47393,\"start\":47388},{\"end\":47836,\"start\":47818},{\"end\":47850,\"start\":47836},{\"end\":47861,\"start\":47850},{\"end\":47875,\"start\":47861},{\"end\":48361,\"start\":48342},{\"end\":48369,\"start\":48361},{\"end\":48385,\"start\":48369},{\"end\":48756,\"start\":48737},{\"end\":48767,\"start\":48756},{\"end\":48783,\"start\":48767},{\"end\":48798,\"start\":48783},{\"end\":48813,\"start\":48798},{\"end\":48824,\"start\":48813},{\"end\":49564,\"start\":49550},{\"end\":49578,\"start\":49564},{\"end\":49592,\"start\":49578},{\"end\":49607,\"start\":49592},{\"end\":49622,\"start\":49607},{\"end\":49638,\"start\":49622},{\"end\":49650,\"start\":49638},{\"end\":49658,\"start\":49650},{\"end\":49671,\"start\":49658},{\"end\":50085,\"start\":50071},{\"end\":50099,\"start\":50085},{\"end\":50113,\"start\":50099},{\"end\":50128,\"start\":50113},{\"end\":50143,\"start\":50128},{\"end\":50159,\"start\":50143},{\"end\":50171,\"start\":50159},{\"end\":50179,\"start\":50171},{\"end\":50188,\"start\":50179},{\"end\":50193,\"start\":50188},{\"end\":50555,\"start\":50537},{\"end\":50567,\"start\":50555},{\"end\":50587,\"start\":50567},{\"end\":50600,\"start\":50587},{\"end\":51090,\"start\":51069},{\"end\":51114,\"start\":51090},{\"end\":51131,\"start\":51114},{\"end\":51144,\"start\":51131},{\"end\":51156,\"start\":51144},{\"end\":51177,\"start\":51156},{\"end\":51198,\"start\":51177},{\"end\":51210,\"start\":51198},{\"end\":51788,\"start\":51777},{\"end\":51799,\"start\":51788},{\"end\":51805,\"start\":51799},{\"end\":52352,\"start\":52341},{\"end\":52363,\"start\":52352},{\"end\":52369,\"start\":52363},{\"end\":53038,\"start\":53021},{\"end\":53053,\"start\":53038},{\"end\":53067,\"start\":53053},{\"end\":53088,\"start\":53067},{\"end\":53104,\"start\":53088},{\"end\":53114,\"start\":53104},{\"end\":53127,\"start\":53114},{\"end\":53140,\"start\":53127},{\"end\":53146,\"start\":53140},{\"end\":53741,\"start\":53728},{\"end\":53757,\"start\":53741},{\"end\":53770,\"start\":53757},{\"end\":53784,\"start\":53770},{\"end\":53792,\"start\":53784},{\"end\":53805,\"start\":53792},{\"end\":53811,\"start\":53805},{\"end\":54015,\"start\":54000},{\"end\":54029,\"start\":54015},{\"end\":54048,\"start\":54029},{\"end\":54062,\"start\":54048},{\"end\":54075,\"start\":54062},{\"end\":54374,\"start\":54359},{\"end\":54385,\"start\":54374},{\"end\":54680,\"start\":54667},{\"end\":54696,\"start\":54680},{\"end\":54712,\"start\":54696},{\"end\":54726,\"start\":54712},{\"end\":54740,\"start\":54726},{\"end\":55227,\"start\":55213},{\"end\":55243,\"start\":55227},{\"end\":55253,\"start\":55243},{\"end\":55263,\"start\":55253},{\"end\":55280,\"start\":55263},{\"end\":55287,\"start\":55280},{\"end\":37235,\"start\":37213},{\"end\":37249,\"start\":37235},{\"end\":37265,\"start\":37249},{\"end\":37280,\"start\":37265},{\"end\":37832,\"start\":37821},{\"end\":37847,\"start\":37832},{\"end\":37859,\"start\":37847},{\"end\":37876,\"start\":37859},{\"end\":37892,\"start\":37876},{\"end\":37911,\"start\":37892},{\"end\":37931,\"start\":37911},{\"end\":37945,\"start\":37931},{\"end\":37960,\"start\":37945},{\"end\":37975,\"start\":37960},{\"end\":38400,\"start\":38384},{\"end\":38415,\"start\":38400},{\"end\":38439,\"start\":38415},{\"end\":38458,\"start\":38439},{\"end\":38475,\"start\":38458},{\"end\":38489,\"start\":38475},{\"end\":38499,\"start\":38489},{\"end\":38927,\"start\":38913},{\"end\":38937,\"start\":38927},{\"end\":38950,\"start\":38937},{\"end\":38965,\"start\":38950},{\"end\":38979,\"start\":38965},{\"end\":38985,\"start\":38979},{\"end\":39691,\"start\":39675},{\"end\":39705,\"start\":39691},{\"end\":39720,\"start\":39705},{\"end\":39733,\"start\":39720},{\"end\":39745,\"start\":39733},{\"end\":39933,\"start\":39919},{\"end\":39944,\"start\":39933},{\"end\":39958,\"start\":39944},{\"end\":39974,\"start\":39958},{\"end\":39990,\"start\":39974},{\"end\":40002,\"start\":39990},{\"end\":40018,\"start\":40002},{\"end\":40035,\"start\":40018},{\"end\":40053,\"start\":40035},{\"end\":40468,\"start\":40454},{\"end\":40482,\"start\":40468},{\"end\":40496,\"start\":40482},{\"end\":40509,\"start\":40496},{\"end\":40802,\"start\":40787},{\"end\":40816,\"start\":40802},{\"end\":40831,\"start\":40816},{\"end\":40846,\"start\":40831},{\"end\":40856,\"start\":40846},{\"end\":40867,\"start\":40856},{\"end\":40885,\"start\":40867},{\"end\":41212,\"start\":41199},{\"end\":41226,\"start\":41212},{\"end\":41243,\"start\":41226},{\"end\":41261,\"start\":41243},{\"end\":41278,\"start\":41261},{\"end\":41291,\"start\":41278},{\"end\":41307,\"start\":41291},{\"end\":41322,\"start\":41307},{\"end\":41341,\"start\":41322},{\"end\":41355,\"start\":41341},{\"end\":42299,\"start\":42286},{\"end\":42315,\"start\":42299},{\"end\":42329,\"start\":42315},{\"end\":42342,\"start\":42329},{\"end\":42357,\"start\":42342},{\"end\":42369,\"start\":42357},{\"end\":42963,\"start\":42950},{\"end\":42977,\"start\":42963},{\"end\":42998,\"start\":42977},{\"end\":43019,\"start\":42998},{\"end\":43032,\"start\":43019},{\"end\":43047,\"start\":43032},{\"end\":43066,\"start\":43047},{\"end\":43078,\"start\":43066},{\"end\":43096,\"start\":43078},{\"end\":43111,\"start\":43096},{\"end\":43126,\"start\":43111},{\"end\":43135,\"start\":43126},{\"end\":43586,\"start\":43573},{\"end\":43597,\"start\":43586},{\"end\":43617,\"start\":43597},{\"end\":43914,\"start\":43899},{\"end\":43928,\"start\":43914},{\"end\":44381,\"start\":44367},{\"end\":44394,\"start\":44381},{\"end\":44762,\"start\":44751},{\"end\":44782,\"start\":44762},{\"end\":44796,\"start\":44782},{\"end\":44808,\"start\":44796},{\"end\":45371,\"start\":45357},{\"end\":45388,\"start\":45371},{\"end\":45399,\"start\":45388},{\"end\":45411,\"start\":45399},{\"end\":45425,\"start\":45411},{\"end\":45446,\"start\":45425},{\"end\":45458,\"start\":45446},{\"end\":45814,\"start\":45797},{\"end\":45835,\"start\":45814},{\"end\":45841,\"start\":45835},{\"end\":46134,\"start\":46099},{\"end\":46146,\"start\":46134},{\"end\":46163,\"start\":46146},{\"end\":46172,\"start\":46163},{\"end\":46403,\"start\":46387},{\"end\":46418,\"start\":46403},{\"end\":46439,\"start\":46418},{\"end\":46455,\"start\":46439},{\"end\":46468,\"start\":46455},{\"end\":46482,\"start\":46468},{\"end\":46957,\"start\":46933},{\"end\":46973,\"start\":46957},{\"end\":46978,\"start\":46973},{\"end\":47263,\"start\":47250},{\"end\":47272,\"start\":47263},{\"end\":47282,\"start\":47272},{\"end\":47297,\"start\":47282},{\"end\":47308,\"start\":47297},{\"end\":47327,\"start\":47308},{\"end\":47342,\"start\":47327},{\"end\":47358,\"start\":47342},{\"end\":47376,\"start\":47358},{\"end\":47388,\"start\":47376},{\"end\":47393,\"start\":47388},{\"end\":47836,\"start\":47818},{\"end\":47850,\"start\":47836},{\"end\":47861,\"start\":47850},{\"end\":47875,\"start\":47861},{\"end\":48361,\"start\":48342},{\"end\":48369,\"start\":48361},{\"end\":48385,\"start\":48369},{\"end\":48756,\"start\":48737},{\"end\":48767,\"start\":48756},{\"end\":48783,\"start\":48767},{\"end\":48798,\"start\":48783},{\"end\":48813,\"start\":48798},{\"end\":48824,\"start\":48813},{\"end\":49564,\"start\":49550},{\"end\":49578,\"start\":49564},{\"end\":49592,\"start\":49578},{\"end\":49607,\"start\":49592},{\"end\":49622,\"start\":49607},{\"end\":49638,\"start\":49622},{\"end\":49650,\"start\":49638},{\"end\":49658,\"start\":49650},{\"end\":49671,\"start\":49658},{\"end\":50085,\"start\":50071},{\"end\":50099,\"start\":50085},{\"end\":50113,\"start\":50099},{\"end\":50128,\"start\":50113},{\"end\":50143,\"start\":50128},{\"end\":50159,\"start\":50143},{\"end\":50171,\"start\":50159},{\"end\":50179,\"start\":50171},{\"end\":50188,\"start\":50179},{\"end\":50193,\"start\":50188},{\"end\":50555,\"start\":50537},{\"end\":50567,\"start\":50555},{\"end\":50587,\"start\":50567},{\"end\":50600,\"start\":50587},{\"end\":51090,\"start\":51069},{\"end\":51114,\"start\":51090},{\"end\":51131,\"start\":51114},{\"end\":51144,\"start\":51131},{\"end\":51156,\"start\":51144},{\"end\":51177,\"start\":51156},{\"end\":51198,\"start\":51177},{\"end\":51210,\"start\":51198},{\"end\":51788,\"start\":51777},{\"end\":51799,\"start\":51788},{\"end\":51805,\"start\":51799},{\"end\":52352,\"start\":52341},{\"end\":52363,\"start\":52352},{\"end\":52369,\"start\":52363},{\"end\":53038,\"start\":53021},{\"end\":53053,\"start\":53038},{\"end\":53067,\"start\":53053},{\"end\":53088,\"start\":53067},{\"end\":53104,\"start\":53088},{\"end\":53114,\"start\":53104},{\"end\":53127,\"start\":53114},{\"end\":53140,\"start\":53127},{\"end\":53146,\"start\":53140},{\"end\":53741,\"start\":53728},{\"end\":53757,\"start\":53741},{\"end\":53770,\"start\":53757},{\"end\":53784,\"start\":53770},{\"end\":53792,\"start\":53784},{\"end\":53805,\"start\":53792},{\"end\":53811,\"start\":53805},{\"end\":54015,\"start\":54000},{\"end\":54029,\"start\":54015},{\"end\":54048,\"start\":54029},{\"end\":54062,\"start\":54048},{\"end\":54075,\"start\":54062},{\"end\":54374,\"start\":54359},{\"end\":54385,\"start\":54374},{\"end\":54680,\"start\":54667},{\"end\":54696,\"start\":54680},{\"end\":54712,\"start\":54696},{\"end\":54726,\"start\":54712},{\"end\":54740,\"start\":54726},{\"end\":55227,\"start\":55213},{\"end\":55243,\"start\":55227},{\"end\":55253,\"start\":55243},{\"end\":55263,\"start\":55253},{\"end\":55280,\"start\":55263},{\"end\":55287,\"start\":55280}]", "bib_venue": "[{\"end\":37391,\"start\":37280},{\"end\":38024,\"start\":37975},{\"end\":38551,\"start\":38499},{\"end\":39101,\"start\":39015},{\"end\":39750,\"start\":39745},{\"end\":40131,\"start\":40069},{\"end\":40561,\"start\":40509},{\"end\":40937,\"start\":40885},{\"end\":41528,\"start\":41386},{\"end\":42455,\"start\":42369},{\"end\":42948,\"start\":42850},{\"end\":43571,\"start\":43491},{\"end\":44015,\"start\":43928},{\"end\":44455,\"start\":44394},{\"end\":44877,\"start\":44808},{\"end\":45355,\"start\":45278},{\"end\":45845,\"start\":45841},{\"end\":46181,\"start\":46172},{\"end\":46596,\"start\":46498},{\"end\":47026,\"start\":46982},{\"end\":47476,\"start\":47409},{\"end\":47962,\"start\":47875},{\"end\":48466,\"start\":48405},{\"end\":48941,\"start\":48855},{\"end\":49707,\"start\":49671},{\"end\":50212,\"start\":50193},{\"end\":50686,\"start\":50600},{\"end\":51309,\"start\":51226},{\"end\":51892,\"start\":51805},{\"end\":52511,\"start\":52369},{\"end\":53250,\"start\":53181},{\"end\":53814,\"start\":53811},{\"end\":54130,\"start\":54091},{\"end\":54418,\"start\":54385},{\"end\":54826,\"start\":54740},{\"end\":55339,\"start\":55287},{\"end\":37391,\"start\":37280},{\"end\":38024,\"start\":37975},{\"end\":38551,\"start\":38499},{\"end\":39101,\"start\":39015},{\"end\":39750,\"start\":39745},{\"end\":40131,\"start\":40069},{\"end\":40561,\"start\":40509},{\"end\":40937,\"start\":40885},{\"end\":41528,\"start\":41386},{\"end\":42455,\"start\":42369},{\"end\":42948,\"start\":42850},{\"end\":43571,\"start\":43491},{\"end\":44015,\"start\":43928},{\"end\":44455,\"start\":44394},{\"end\":44877,\"start\":44808},{\"end\":45355,\"start\":45278},{\"end\":45845,\"start\":45841},{\"end\":46181,\"start\":46172},{\"end\":46596,\"start\":46498},{\"end\":47026,\"start\":46982},{\"end\":47476,\"start\":47409},{\"end\":47962,\"start\":47875},{\"end\":48466,\"start\":48405},{\"end\":48941,\"start\":48855},{\"end\":49707,\"start\":49671},{\"end\":50212,\"start\":50193},{\"end\":50686,\"start\":50600},{\"end\":51309,\"start\":51226},{\"end\":51892,\"start\":51805},{\"end\":52511,\"start\":52369},{\"end\":53250,\"start\":53181},{\"end\":53814,\"start\":53811},{\"end\":54130,\"start\":54091},{\"end\":54418,\"start\":54385},{\"end\":54826,\"start\":54740},{\"end\":55339,\"start\":55287},{\"end\":37489,\"start\":37393},{\"end\":39215,\"start\":39103},{\"end\":41679,\"start\":41530},{\"end\":42528,\"start\":42457},{\"end\":44089,\"start\":44017},{\"end\":44503,\"start\":44457},{\"end\":44910,\"start\":44879},{\"end\":48036,\"start\":47964},{\"end\":49055,\"start\":48943},{\"end\":50759,\"start\":50688},{\"end\":51966,\"start\":51894},{\"end\":52640,\"start\":52513},{\"end\":54438,\"start\":54420},{\"end\":54899,\"start\":54828},{\"end\":37489,\"start\":37393},{\"end\":39215,\"start\":39103},{\"end\":41679,\"start\":41530},{\"end\":42528,\"start\":42457},{\"end\":44089,\"start\":44017},{\"end\":44503,\"start\":44457},{\"end\":44910,\"start\":44879},{\"end\":48036,\"start\":47964},{\"end\":49055,\"start\":48943},{\"end\":50759,\"start\":50688},{\"end\":51966,\"start\":51894},{\"end\":52640,\"start\":52513},{\"end\":54438,\"start\":54420},{\"end\":54899,\"start\":54828}]"}}}, "year": 2023, "month": 12, "day": 17}