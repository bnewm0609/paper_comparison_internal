{"id": 249225562, "updated": "2023-12-14 07:54:15.249", "metadata": {"title": "Geometric Disentangled Collaborative Filtering", "authors": "[{\"first\":\"Yiding\",\"last\":\"Zhang\",\"middle\":[]},{\"first\":\"Chaozhuo\",\"last\":\"Li\",\"middle\":[]},{\"first\":\"Xing\",\"last\":\"Xie\",\"middle\":[]},{\"first\":\"Xiao\",\"last\":\"Wang\",\"middle\":[]},{\"first\":\"Chuan\",\"last\":\"Shi\",\"middle\":[]},{\"first\":\"Yuming\",\"last\":\"Liu\",\"middle\":[]},{\"first\":\"Hao\",\"last\":\"Sun\",\"middle\":[]},{\"first\":\"Liangjie\",\"last\":\"Zhang\",\"middle\":[]},{\"first\":\"Weiwei\",\"last\":\"Deng\",\"middle\":[]},{\"first\":\"Qi\",\"last\":\"Zhang\",\"middle\":[]}]", "venue": null, "journal": "Proceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval", "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "Learning informative representations of users and items from the historical interactions is crucial to collaborative filtering (CF). Existing CF approaches usually model interactions solely within the Euclidean space. However, the sophisticated user-item interactions inherently present highly non-Euclidean anatomy with various types of geometric patterns (i.e., tree-likeness and cyclic structures). The Euclidean-based models may be inadequate to fully uncover the intent factors beneath such hybrid-geometry interactions. To remedy this deficiency, in this paper, we study the novel problem of Geometric Disentangled Collaborative Filtering (GDCF), which aims to reveal and disentangle the latent intent factors across multiple geometric spaces. A novel generative GDCF model is proposed to learn geometric disentangled representations by inferring the high-level concepts associated with user intentions and various geometries. Empirically, our proposal is extensively evaluated over five real-world datasets, and the experimental results demonstrate the superiority of GDCF.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/sigir/ZhangL0WSLSZDZ22", "doi": "10.1145/3477495.3531982"}}, "content": {"source": {"pdf_hash": "d4220f3182fcecdf7b2327729469eee6caa87d49", "pdf_src": "ACM", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "5a99eef58c29034e4193297cafb70becbf78dd9f", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/d4220f3182fcecdf7b2327729469eee6caa87d49.txt", "contents": "\nGeometric Disentangled Collaborative Filtering\nACMCopyright ACMJuly 11-15, 2022. 2022. July 11-15, 2022\n\nYiding Zhang \nChaozhuo Li \nXiao Wang xiaowang@bupt.edu.cn \nChuan Shi shichuan@bupt.edu.cn \nYuming Liu yumliu@microsoft.com \nHao Sun hasun@microsoft.com \nMicrosoft Beijing \nChina Liangjie Zhang \nWeiwei Deng dedeng@microsoft.com \nMicrosoft Beijing \nChina Qi Zhang \nYiding Zhang \nChaozhuo Li \nXing Xie xing.xie@microsoft.com \nXiao Wang \nChuan Shi \nYuming Liu \nHao Sun \nLiangjie Zhang \nWeiwei Deng \nQi Zhang qizhang@microsoft.com \n\nBeijing University of Posts and Telecommunications\nBeijingChina\n\n\nXing Xie\nMicrosoft Research Asia\nBeijingChina\n\n\nMicrosoft Research Asia\nBeijingChina\n\n\nBeijing University of Posts and Telecommunications\nBeijingChina\n\n\nBeijing University of Posts and Telecommunications\nBeijingChina\n\n\nMicrosoft\nBeijingChina\n\n\nMicrosoft\nBeijingChina\n\n\nMicrosoft\nBeijingChina\n\nGeometric Disentangled Collaborative Filtering\n\nProceedings of the 45th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '22)\nthe 45th International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR '22)Madrid, Spain; Madrid, Spain; New York, NY, USAACM11July 11-15, 2022. 2022. July 11-15, 202210.1145/3477495.3531982* Both authors contributed equally to this research. \u2020 Chuan Shi is a corresponding author. ACM ISBN 978-1-4503-8732-3/22/07. . . $15.00 \u2022 Information systems \u2192 Collaborative filtering. KEYWORDS Collaborative Filtering, Disentangled Representation Learning, Non-Euclidean Geometry ACM Reference Format:\nLearning informative representations of users and items from the historical interactions is crucial to collaborative filtering (CF). Existing CF approaches usually model interactions solely within the Euclidean space. However, the sophisticated user-item interactions inherently present highly non-Euclidean anatomy with various types of geometric patterns (i.e., tree-likeness and cyclic structures). The Euclidean-based models may be inadequate to fully uncover the intent factors beneath such hybrid-geometry interactions. To remedy this deficiency, in this paper, we study the novel problem of Geometric Disentangled Collaborative Filtering (GDCF), which aims to reveal and disentangle the latent intent factors across multiple geometric spaces. A novel generative GDCF model is proposed to learn geometric disentangled representations by inferring the high-level concepts associated with user intentions and various geometries. Empirically, our proposal is extensively evaluated over five real-world datasets, and the experimental results demonstrate the superiority of GDCF.\n\nINTRODUCTION\n\nThe rapid development of information technology has facilitated an explosion of information, leading to the challenge of information overload [1]. Recommender systems mitigate the information overload by suggesting a small set of items for users to meet their personalized interests [26,27,47]. Basically, recommender systems aim at modeling a user's preferences based on her historical interactions (e.g., ratings and clicks) with different items, known as collaborative filtering (CF) [44], and further recommending the user some items that she might be interested in [1].\n\nMost existing CF models follow the paradigm to first learn a set of user/item representations and then build an interaction function to make recommendations based on the learned embeddings [44]. Learning representations that precisely reflect users' preferences based chiefly on user historical behaviors, has been a central point of interest. Matrix Factorization (MF) [24] embeds users and  items as distributed vectors via matrix decomposition. Deep neural networks (DNNs) are further introduced to capture the latent preferences beneath the highly non-linear interactions [15,47]. Recently, graph neural networks (GNNs) have demonstrated great potential in boosting recommendation performance. High-order user-item interactions are explicitly captured by the stacked GNN layers to learn expressive embeddings [14,48]. The representation learning of most CF models is defined in the Euclidean space due to the computational simplicity [43]. However, recent researches have demonstrated that a myriad of data (e.g., data with tree-likeness or cyclic structures) exhibits the highly non-Euclidean latent anatomy [3,25,40,50]. Compared to the conventional Euclidean geometry, non-Euclidean geometries (i.e., hyperbolic or spherical geometry) are more suitable for modeling data with non-Euclidean characteristics. Coincidentally, such non-Euclidean characteristics also inherently exist in the CF scenario. As shown in Figure 1(b), the high-order interactions of user 1 can be naturally extended to a tree-likeness structure based on the interactions in Figure 1(a). This is reasonable as the receptive field tends to be exponentially larger in the higher orders [42]. Euclidean geometry is insufficient to obtain relatively low distortion for embedding such tree structures even using an unbounded number of dimensions [28], but this task would be surprisingly easy for hyperbolic spaces with only 2 dimensions [41]. In addition, users sharing similar preferences may interact with similar items, leading to the cyclic structures in Figure 1(c) (e.g., 4 \u2192 2 \u2192 5 \u2192 3 \u2192 4 ). Such cyclic structures indicate the behavioral similarities between users, which are essentially the collaborative signals leveraged by CF methods [44]. Representing the cyclic structures into the Euclidean space with limited expressivity may result in inferior representations, while spherical geometry is more powerful in modeling data with cyclic structures [3,9].\n\nRecently, several works focus on learning user/item representations within a single type of non-Euclidean space (e.g., hyperbolic space) [36,45,46,52]. However, the underlying structures of user-item interactions are more complicated than the pure trees or spheres. As shown in Figure 1(b), the tree-likeness structure and the cyclic structure (e.g., 1 \u2192 1 \u2192 3 \u2192 2 \u2192 1 ) are nested together, leading to the hybrid geometric characteristics. From this point of view, the single geometry-based hypothesis is inadequate to capture latent intent factors beneath such hybrid structures. To reveal the latent reasons why a user interacted with an item, disentangled representation learning is introduced to learn factorized embeddings to disentangle the latent intent factors [31,32,49,54]. Although existing disentangled CF models learn representations solely within the Euclidean geometry, they motivate us to disentangle the sophisticated characteristics with different geometries.\n\nIn this paper, we propose to perform CF over hybrid geometries via disentangled learning, namely Geometric Disentangled Collaborative Filtering (GDCF). Based on the basic assumption that user-item interactions are latently generated from highly sophisticated intent factors, we further presume that these intent factors should be associated with various geometries. Different intent factors are responsible for generating user-item interactions belonging to different types of geometries. However, how to learn a desirable GDCF model is still obscure. Previous disentangled CF models only focus on uncovering the intent factors, while GDCF further needs to capture the latent correlations between the intent factors and different geometries. In addition, the closeness measurements in different geometries are distinct. For example, distances in spherical spaces are finite while the distances can be infinite in Euclidean and hyperbolic spaces. Since the representations of users and items are defined within different geometries, it is essential to measure the closeness across different geometries in a principled manner.\n\nTo address the mentioned challenges, we make the first attempt to learn geometric disentangled representations and propose a novel generative GDCF model on the basis of variational autoencoders (VAEs). Specifically, the geometric disentangled representations are learned by identifying the high-level geometric concepts associated with user intentions. The concepts represent the intent factors associated with different geometries, which contribute to capturing the task-relevant correlations between latent factors and geometries. To measure the user-item similarities across multiple geometries, we further propose to project the disentangled representations from different spaces into a shared latent space, and thus a universal measurement can be leveraged to calculate their closeness. Our proposal is thoroughly evaluated on five publicly available datasets, and the experimental results demonstrate its superiority.\n\nWe summarize our main contributions as follows:\n\n\u2022 To the best of our knowledge, we are the first to study the novel problem of geometric disentangled collaborative filtering, which is capable of capturing fine-grained geometric characteristics beneath the hybrid user-item interactions. \u2022 We propose a novel GDCF model to learn geometric disentangled representations by identifying the high-level geometryaware concepts associated with user intentions. \u2022 Extensively, we evaluate GDCF on five real-world datasets.\n\nExperimental results demonstrate its superiority.\n\n\nPROBLEM DEFINITION\n\nIn this section, we will formally define the studied problem. A recommendation dataset can be formulated as D = {U, I, E}, in which U = { 1 , 2 , \u00b7 \u00b7 \u00b7 , } denotes a set of users, I = { 1 , 2 , \u00b7 \u00b7 \u00b7 , } is the set of items and E \u2208 {0, 1} \u00d7 consists of the historical interactions between users and items. For convenience, we use f = { : E , = 1} to represent items interacted with user . Given a candidate pair ( , ) consisting of a target user and a potential item , we aim to learn a preference score f , \u2208 {0, 1} to indicate how likely this item should be recommended to the target user. \n\n\nPRELIMINARY\n\nIn this section, we will introduce some preliminary knowledge from the perspective of manifolds, including the basic notations and operators in three geometries (i.e., hyperbolic, Euclidean and spherical geometries). Three types of manifolds M are defined with the constant sectional curvature [5]. The general realizations of these manifolds are the hyperboloid H , the Euclidean space E, as well as the hypersphere S :\nM = \uf8f1 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f2 \uf8f4 \uf8f4 \uf8f4 \uf8f4 \uf8f3 H : { \u2208 R +1 : \u27e8 , \u27e9 = 1/ , 0 > 0}, for < 0 E : R , for = 0 S : { \u2208 R +1 : \u27e8 , \u27e9 = 1/ }, for > 0(1)\nwhere \u27e8\u00b7, \u00b7\u27e9 denotes the curvature-aware scalar product, namely\n\u27e8 , \u27e9 = \u27e8 , \u27e9 = =0 for > 0 and \u27e8 , \u27e9 = \u27e8 , \u27e9 L = \u2212 0 0 + =1\nfor < 0. For M \u2208 {H , S }, a critical notion is tangent space [16], which is useful when the operators are not explicitly defined in the manifolds. The tangent space of M at \u2208 M is defined as a -dimensional vector space approximating M around :\nT M := { \u2208 R +1 : \u27e8 , \u27e9 = 0}.(2)\nThe mapping between manifold M \u2208 {H , S } and its tangent space T M can be achieved by exponential map and logarithmic map [16]. The exponential map projects points from a subset of the tangent space T M to the original manifold M , while the logarithmic map projects points in the opposite direction. For points , \u2208 M , \u2208 T M , such that \u2260 , \u2260 0 and 0 = (1/ \u221a\ufe01 | |, 0, \u00b7 \u00b7 \u00b7 , 0), the exponential map exp (\u00b7) and logarithmic map log (\u00b7) are formally defined as follows:\nexp ( ) = cos ( \u221a\ufe01 | |\u2225 \u2225 ) + sin ( \u221a\ufe01 | |\u2225 \u2225 ) \u221a\ufe01 | |\u2225 \u2225 , log ( ) = cos \u22121 ( \u27e8 , \u27e9 ) sin cos \u22121 ( \u27e8 , \u27e9 ) ( \u2212 \u27e8 , \u27e9 ),(3)\nwhere \u2225 \u2225 = \u221a\ufe01 \u27e8 , \u27e9 denotes the norm of tangent vector, and the curvature-aware trigonometric functions are:\nsin = sin if > 0 sinh if < 0 , cos = cos if > 0 cosh if < 0 .\nTo connect vectors in tangent spaces, we use parallel transport PT \u2212 : T M \u2192 T M [16]:\nPT \u2192 ( ) = \u2212 \u27e8 , \u27e9 1 + \u27e8 , \u27e9 ( + ),(4)\nwhich ensures the transported vectors stay parallel to the connection. In addition, the geodesic distance is defined as:\n( , ) = 1 \u221a\ufe01 | | cos \u22121 ( \u27e8 , \u27e9 ).(5)\nThere are also several widely-used realizations of these spaces, i.e., Poincar\u00e9 ball P for hyperbolic spaces, projected hypersphere D for spherical spaces. Please refer to [43] for more details. Moreover, for Euclidean space E , let , \u2208 E and \u2208 T E , the exponential map is defined as exp ( ) = + , and the logarithmic map is log ( ) = \u2212 . The parallel transport is defined as PT \u2192 ( ) = .\n\n\nMETHODOLOGY\n\nIn this section, we will introduce the details of the GDCF model. First, we will expound the basic model paradigm. Then, the implementations of several major components will be presented. Finally, we will discuss several key points within our proposal.\n\n\nMathematical Paradigm\n\nIn this subsection, we will introduce the basic mathematical paradigm of GDCF. Users may have diverse interests, and these interests can be attributed to various latent concepts. Therefore, we aim to learn a factorized representation for user composed of highlevel concepts. The factorized representation of user is denoted as z = [z (1) , z (2) , \u00b7 \u00b7 \u00b7 , z ( ) ], where z ( ) \u2208 M is a -dimensional concept representation living in the manifold M . z ( ) depicts the preference of user regarding to the th concept. Different from the diverse interests of users, an item usually represents a specific object, which is fixed and explicit [32]. Thus, items are represented by the -dimensional embeddings {h } =1 \u2208 E in Euclidean spaces instead of the factorized vectors.\n\nIn order to model the correlations between items and latent concepts, we design the concept assignment relations for items: 1 , ,2 , \u00b7 \u00b7 \u00b7 , , ] and , indicates whether item belongs to concept . The concept assignment of item is described by a distribution ( , ), which denotes the probability of item belonging to concept and =1 ( , ) = 1. The assignments among different concepts ensure that the user-item interactions can be reconstructed based on different manifolds.\nC = {c } =1 , where c = [ ,\nFollowing previous works [17,23,31], we adopt the variational auto-encoders (VAEs) as the basic paradigms and propose a generative GDCF model. Assuming that the interactions are generated from the true world simulator using the factorized user embedding z along with the concept assignment distribution (C). An appropriate objective function should maximize the marginal likelihood of the user' observed data f in expectation over the distribution of user representation z and item concept assignment C:\nmax E (C) \u222b (f |z , C) (z ) z .(6)\nGiven the historical interactions of user : f = { : E , = 1}, the inferred posterior configurations of z and C can be naturally described by a probability distribution (z |f , C). Moreover, we are also interested in disentangling a user's preferences at a more granular level regarding various aspects of an item. This can be achieved by introducing a constraint over (z |f , C) and matching (z |f , C) to a unit Gaussian prior (z ). Therefore, the constrained optimization problem can be formalized as: \nmax E f \u223cD E (C) E (z |f ,C) log (f |z , C) , subject to (z |f , C)\u2225 (z ) < ,(7)\u210d ( ) ( ) ( , ( ) ) ( ) ( ) ( ) ( , ( ) ) ( ) ( ) ( ) ( , ( ) ) ( ) \u210d ( ) ( ) ( ) log ( ( ) ) log ( ( ) )\nCalculate the similarities between users and items in a shared tangent space where \u2265 0 indicates the strength of the applied constraint. We rewrite Eq. (7) as a Lagrangian under the KKT conditions [19,21]:\nF ( , ; f , z ) = E (C) E (z |f ,C) log (f |z , C) \u2212 (z |f , C) \u2225 (z ) \u2212 ,(8)\nwhere the KKT multiplier \u2265 0 is the regularization coefficient. Since , \u2265 0, according to the complementary slackness KKT condition, Eq. (8) can be re-written as [17]:\nF ( , ; f , z ) \u2265L ( ; f , z , ) = E (C) E (z |f ,C) log (f |z , C) \u2212 (z |f , C) \u2225 (z ) ,(9)\nwhich is the final optimization objective of our model.\n\n\nImplementation\n\nIn this subsection, we will introduce the details of three major components in the implementation of the proposed GDCF model as shown in Figure 2.\n\n\nConcept assignment.\n\nConcept assignment calculates the probabilities of an item assigning to different concepts. We propose a prototype-based concept assignment strategy to prevent overparameterization and low sampling efficiency. Specifically, prototypes {m } =1 are proposed to describe the anchors of the concepts across manifolds. Since items and the prototype m might come from different geometries, we need to map them into a shared space for comparison. One straightforward approach is to assume all the items are represented in the shared tangent space at 0, i.e., T 0 M, and then transform them into M via exp 0 (\u00b7). However, the transformed item representations would be identical and indistinguishable if the prototypes share the same latent space, i.e., M = M +1 [31]. Thus, the prototypes of items should be explicitly incorporated in the transformation process. As shown in Figure 2 (a), we assume that item representations {h } =1 come from T 0 M , and transform them into T m M via parallel transport to obtain the prototype-aware item representations:\nh \u2032 = PT 0\u2192m (h ).(10)\nThen, we define the similarity measurement between h \u2032 and m . A common strategy is to transform h \u2032 into manifold M via exp m (\u00b7).\n\nSimilarities between h \u2032 and m can be measured by their geodesic distance on M . We theoretically prove this approach is equivalent to a simpler operation, i.e., computing the norm of h \u2032 on T m M : The distance between , \u2208 H can be rewritten as:\nH ( , ) = H ( , exp ( )) = 1 \u221a \u2212 cosh \u22121 \u27e8 , cosh( \u221a \u2212 \u2225 \u2225 L ) + sinh( \u221a \u2212 \u2225 \u2225 L ) \u221a \u2212 \u2225 \u2225 L \u27e9 L = 1 \u221a \u2212 cosh \u22121 \u00b7 1 cosh( \u221a \u2212 \u2225 \u2225 L ) =\u2225 \u2225 L = \u2225 log ( )\u2225 L .(11)\nThis theorem also holds for the hypersphere model S following above proposition. For the Poincar\u00e9 ball model P , the distance between , \u2208 P can be rewritten as:\nP ( , ) = P ( , exp ( )) = 2 \u221a \u2212 tanh \u22121 \u221a \u2212 tanh \u221a \u2212 \u2225 \u2225 2 1 \u221a \u2212 = \u2225 \u2225 = \u2225 log ( )\u2225 P .(12)\nThe formulas about P are referred from [43]. The proof of the projected hypersphere model D is similar to the above process. \u25a1 \n, = \u2212\u2225h \u2032 \u2225 .(13)\nThe probability of item belonging to concept can be achieved after a softmax function:\n( , ) = exp( , / ) =1 exp( , / ) ,(14)\nwhere is a hyper-parameter to control the scale of values, and we set \u2208 (0, 1) to obtain a more skewed distribution.\n\n\nGeometric disentangled representation.\n\nUsers may have diverse interests, leading to the disentangled representations w.r.t. different concepts. The prior distribution (z ) is set to a unit Gaussian distribution. The encoder (z |f , C) learns the representations for user based on the high-level concept distributions. As-\nsume (z |f , C) = =1 (z ( ) |f , C), and each (z ( ) |f , C)\nis defined as a multivariate normal distribution with a diagonal co-variance matrix [17].\nLet t = [ ,1 , ,2 , \u00b7 \u00b7 \u00b7 , , ] \u2299 [ ( 1, ), ( 2, ), \u00b7 \u00b7 \u00b7 , ( , )\n] \u2208 E be the probabilities of the interacted items for user belonging to th concept, where \u2299 is the point-wise product. The mean vector ( ) \u2208 M and the standard deviation\n( ) \u2208 T 0 M are calculated by a neural network nn : M \u2192 M 2 with input t : (a ( ) , b ( ) ) = nn exp 0 (t ) ( ) = a ( ) , ( ) = 0 \u00b7 (\u2212 1 2 log 0 (b ( ) )) .(15)\nHere we implement the nn as non-Euclidean neural networks [3,10,53]. Specifically, for the projected manifolds, i.e., D and P , we follow the neural structures proposed in [3,10], which leverage the log 0 and exp 0 to transform the -dimensional representations between tangent spaces and the manifolds. The Euclidean operations are conducted over all the elements for the -dimensional features. However, a -dimensional feature vector in H or S has + 1 elements. If the Euclidean operations nn are directly applied on all the + 1 dimensions, the transformed features would be out of the tangent spaces [53]. To address this challenge, we propose to conduct the Euclidean operations on the last elements. The non-Euclidean operations defined in P or D are equivalent to those defined in H or S , respectively. Please refer to Appendix A.1 for the proposed operations and proofs.\n\nAs shown in Figure 2  , we leverage the wrapped normal distribution [37,43] to build the Gaussian distribution on Riemannian manifolds to generate user representations. Specifically, to sample instances from the distribution WN ( \nz ( ) = exp ( ) PT 0\u2192 ( ) (v ) .(16)\n\nUser behavior reconstruction.\n\nHere we aim to predict which items are most likely to be clicked by the target user. Since the item representations live in the Euclidean space, we can view this space as a tangent space and transform the item representations {h } =1 to M , and then compute their similarities based on the distances. However, the distances in different spaces may have different value scales. For example, the distances in Euclidean or hyperbolic spaces could be theoretically infinite, while for spherical spaces, the distances are finite [16]. To tackle this challenge, we propose to project the user representations z ( ) to the tangent space T 0 M . As shown in Figure 2 (c), the tangent spaces of these manifolds are isomorphic to Euclidean spaces. Therefore, we can leverage Euclidean measurements to calculate the similarities of different geometries. Here we only consider the angle between the representations to avoid the influence of the norm of the representations in different spaces. Therefore, the Euclidean inner product can be employed to measure the similarities between the normalized th concept of user and item in the shared tangent space T 0 M :\n(z ( ) , h ) = \u27e8 0 (z ( ) ) \u2225 log 0 (z ( ) )\u2225 , h \u2225h \u2225 \u27e9.(17)\nUser behaviors can be further reconstructed via the categorical distribution over the items:\n( , |z , C) \u221d =1 (z ( ) , h ).\n\nOptimization\n\nThe trainable parameters of GDCF include concept prototypes {m \u2208 M } =1 , item representations {h \u2208 E } =1 , and the parameters in the neural network nn . We optimize to maximize the training objective in Eq. (9) via Adam [22] and RiemannianAdam [4] for Euclidean and non-Euclidean parameters, respectively. Moreover, since a -dimensional embedding in manifold M \u2208 {H , S } has + 1 elements, we concatenate or remove an element \"0\" at the first dimension of features in the tangent spaces to ensure the vector operations can be conducted in a principal manner.\n\n\nDiscussions\n\nIn this section, we will discuss two key points, i.e., similarity measurements and probability distributions on Riemannian manifolds, as well as the relations to some related methods including disentangled VAEs and mix-curvature representation learning. Similarity measurement. We leverage two types of metrics to measure the similarities: the geodesic distance for concept assignment in Eq. (13), and the Euclidean distance on the tangent spaces for user behavior reconstruction in Eq. (17). These two metrics are employed for different purposes. Concept assignment aims to infer the most likely manifold for item while the geodesic distance thrives on measuring the manifold-specific similarity. Thus, the metric used in the concept assignment is set to geodesic distance. For the behavior reconstruction, we need to measure the similarities between item representations and disentangled user representations on all the manifolds in a universal manner. The disentangled user representations are projected to a shared tangent space, where the Euclidean distance can be utilized as the closeness metric. Probability distribution on Riemannian manifolds. Several approaches have been proposed to generalize the Normal distribution  to Riemannian manifolds, including restricted normal, Riemannian normal, and wrapped normal [9,13,37]. Restricted normal distributions restrict a point of the ambient space sampled from a Gaussian distribution to the manifolds. Von Mises-Fisher distribution [9] is a kind of restricted normal, but it has only a single scalar covariance parameter and cannot parameterize covariance for different dimensions. Riemannian normal distributions [13,34,35] are based on geodesic distance in the manifolds. These distributions aim to maximize the entropy distributions and resemble the Gaussian distribution's properties the closest. However, the resemble process is quite computationally expensive, leading to low efficiency. Wrapped normal distributions [37,43] first sample features from a Gaussian distribution in the tangent space and the sampled features are further transformed to Riemannian manifolds via parallel transport and exponential map. We select wrapped normal distributions in our model due to its computational efficiency. Note that we do not follow the wrapped normal distributions when calculating the probability density function. This is because the density functions are expected to be directly computed on the tangent space instead of the manifolds.\n\nConnections to disentangled VAEs. VAEs have been widely exploited to learn the disentangled representations [17,18,20,31]. Existing disentangled VAEs usually leverage the cosine function to measure the similarities, which ignore the norms of representations. Thus, these disentangled VAEs can be viewed as representation learning on the hypersphere [31]. The key difference between these methods and our proposal is that GDCF learns the representations on different Riemannian manifolds. Multiple Riemannian manifolds endow our proposal with powerful modeling capacity. The major difference between MacridVAE and GDCF is that MacridVAE only focuses on a single manifold (i.e., hypersphere) while GDCF is capable of disentangling representations for different types of manifolds. In addition, MacridVAE aims at learning the one-hot concept assignment relations C, while GDCF does not require the C to be one-hot vectors, leading to a general solution with less restrictions.\n\nConnections to mix-curvature representation learning. Mixcurvature methods [3,11,43] learn the representations by balancing the expressive capacities of different kinds of manifolds. Cross-manifold representations learned by existing mix-curvature methods are defined in the product spaces, i.e., M 1 \u00d7M 2 \u00d7\u00b7 \u00b7 \u00b7\u00d7M . GDCF is fundamentally different from these methods because the representations of GDCF on different manifolds are independent from each other, i.e., M 1 , M 2 , \u00b7 \u00b7 \u00b7 , M , which can preserve the uniqueness of different geometries. Complexity analysis. The time complexity of GDCF is ( ), where is the number of concepts, is the dimension of user/item representations, and are the number of users and items, respectively. The time complexity is on par with the SOTA disentangled models like MacridVAE [31].\n\n\nEXPERIMENTS 5.1 Experimental Setup\n\nDatasets. We conduct the experiments on five real-world datasets, including three MovieLens datasets with different numbers of interactions (MovieLens-100k, MovieLens-1M and MovieLens-20M) [12], AliShop [31] and LastFM [6]. The training/validation/testing partitions are following previous works [27,31]. The statistics of these datasets are shown in Table 1. Baselines. We select the following SOTA CF models as baselines:\n\n\u2022 NGCF [48] is a graph-based CF model to incorporate the high-order connectivity of user-item interactions. \u2022 LightGCN [14] is a SOTA CF recommendation model based on graph convolution network. \u2022 DGCF [49] is a disentangled CF model to learn representations for different latent user intentions via graph convolutional network. \u2022 MacridVAE [31] is also a disentangled model, which leverages VAE to disentangle macro and micro components for user behaviors. \u2022 HyperML [46] is a hyperbolic CF model, which explores metric learning in hyperbolic spaces for recommendation. \u2022 H-VAE [36] is a hyperbolic VAE based CF approach, which employs a hyperbolic VAE to solve the collaborative filtering problem. \u2022 HGCF [45] is a hyperbolic CF method, which is devised to capture the high-order correlations between users and items by using hyperbolic GNN. \u2022 -GCN [3] is a mix-curvature GNN. We modify its loss to the hinge loss to solve the CF problem.\n\nHyper-parameter. We perform the hyper-parameter search on a small validation set. For the proposed GDCF, we set the dimension of embedding as 100 and tune the temperature \u2208 [0, 0.1], \u2208 [0, 100] in Eq. (9), the number of factors \u2208 {1, 2, 3, . . . , 20}, the standard deviation of the prior 0 \u2208 [0.075, 0.5] and the number of hidden layers \u2208 {0, 1, 2, 3} by grid search. We set \u2208 {\u22121, 0, 1} for hyperbolic, Euclidean and spherical geometry, respectively. Moreover, we also tune the following parameters for all methods: learning rate \u2208 [10 \u22126 , 10 \u22122 ], dropout probability \u2208 [0, 1], 2 regularization strength \u2208 [10 \u22128 , 10 \u22122 ]. We tune these hyper-parameters automatically via Optuna [2]. Infrastructure. We implement our model with Pytorch, and conduct the experiments with: CPU: Intel(R) Xeon(R) Platinum 8168 CPU @ 2.70GHz GPU: 24 \u00d7 NVIDIA Tesla V100.\n\n\nMain Results\n\nWe evaluate the performance of our approach on the five popular datasets. Here we implement GDCF with three kinds of manifolds i.e., H , E, and S . To evaluate the effectiveness on top-K recommendation task, we adopt two popular evaluation metrics: Recall@20 and NDCG@20 [14,48,49]. We repeat this process 5 times and report the average scores.  Experimental results are summarized in Table 2, and we can observe that the proposed GDCF achieves SOTA performance on the five datasets across all metrics, demonstrating the effectiveness of the geometric disentangled representation learning. GDCF outperforms the hyperbolic CF methods (e.g., HyperML, H-VAE and HGCF) by a large margin, which verifies that a single hyperbolic space may be insufficient to capture the hybrid geometric characteristics. The disentanglement-based methods (DGCF and MacridVAE) outperform other baselines in most cases, which proves the benefits of factorized representations under the CF scenario. By incorporating the geometric concepts into the disentangled representation learning, GDCF surpasses DGCF and MacridVAE over all the datasets, confirming the superior modeling capacity of our proposal.\n\n\nAblation Study\n\nSince three types of geometries are incorporated in the GDCF model, we further conduct an ablation study to investigate the effectiveness of different geometry combinations. Here we leverage hyperboloid model H and Poincar\u00e9 ball P to describe hyperbolic geometry, hypersphere model S and projected hypersphere D to describe spherical geometry, respectively. We evaluate the performance of GDCF with three types of geometry combinations, and the subscripts are omitted for simplicity: the single geometry H, P, E, S, D; the combinations of two geometries H&E, P&E, E&S, E&D, H&S, P&D; and the combinations of three geometries H&E&S, P&E&D. The numbers of components for different geometries are set to approximately equal.\n\nThe results are reported in Table 3. The best results of all the methods are marked in bold, while the best results within each type of geometry combinations are marked with underlines. One can see that GDCF implemented with three kinds of geometries achieve the best performance in most cases, which demonstrates that all the three geometries contribute to learning expressive and meaningful representations. For the single geometry-based variations, non-Euclidean methods (H, P, S and D) generally outperform Euclidean-based model (E). It demonstrates that the non-Euclidean geometric structures are ubiquitous under the recommendation scenario and our proposal can effectively encode such patterns into representations. Moreover, the simplified version of GDCF with only two geometries (H&E and H&S) already achieve promising performance on MovieLens datasets, revealing the effectiveness of representation learning in multiple geometries. Ablation models implemented with H or S consistently perform better than the counterparts with P and D, which is reasonable as P and D suffer from numerical instability in the optimization process [7,29,39].\n\n\nUniversal Curvature Analysis\n\nPrevious ablation studies raise an interesting question: how to find the most effective combination of these geometries. The simplest approach is to enumerate all the possible combinations and select the candidate with best performance. This enumeration method would be optimal but impractical due to the inefficiency and low scalability [43]. Here we propose an approximate method to tackle this challenge. Specifically, we randomly initialize the curvatures of the components within [\u22121, 1] and view the curvatures of all components as trainable parameters in the training process. Moreover, the sign of curvature is also not constrained. Thus, components are able to change their geometries from hyperbolic (spherical) to spherical (hyperbolic) space to achieve the optimal solutions. Note that \u22250\u2225 = \u2225(1/ \u221a\ufe01 | |, 0, \u00b7 \u00b7 \u00b7 , 0) \u2225 \u21920 \u2212\u2192 \u00b1\u221e, for the hyperboloid H and hypersphere S [43]. Therefore, the universal curvature variation of GDCF leverages the Poincar\u00e9 ball P and the projected hypersphere D for hyperbolic and spherical geometry, respectively. GDCF with the universal curvature is denoted as U. We are interested in comparing U with P&D, since both of them leverage Poincar\u00e9 ball P and projected hypersphere D. Table 4 exhibits the results. The combinations with the best performance are marked in bold. One can see that the variations with universal curvature U outperform P&D in most cases, which indicates U can automatically select more proper geometries. However, U does not converge to some specific curvatures [43], leading to the low generalization. Another limitation of U is that the Euclidean component cannot be incorporated as it cannot ensure will converge to 0 in the training process.\n\n\nParameter Sensitivity Analysis\n\nIn this subsection, we will investigate the effect of two key parameters (the number of concepts and the dimension of embedding ) on the MovieLens-100k and LastFM datasets. Figure 3(a) and 3(b) show the results of GDCF under varying . With the increase of the number of concepts , the performance of GDCF first improves Table 3: Ablation study of the geometry combinations. Best results of all the methods are in bold, and the best results within each type of geometry combinations are underlined.\n\n\nDatasets\n\nMovieLens-100k MovieLens-1M MovieLens-100M Alishop LastFM Metric NDCG@20 Recall@20 NDCG@20 Recall@20 NDCG@20 Recall@20 NDCG@20 Recall@20 NDCG@20 Recall@20  \n\n\nCase Study\n\nIn this subsection, we will investigate whether GDCF can capture the correlations between the latent concepts and the geometric structures. To this end, we provide two cases (items with ID i961 and i4837) in MovieLens-100k dataset. Figure 4 displays the 2-hop ego-graphs centered with different items. One can see that the egograph of i961 is closer to the tree-likeness structures with less cycles compared to i4837. After model training, the concept assignment probabilities calculated by GDCF on different geometries are shown in Figure 4(c) and Figure 4(d). These probabilities reveal that the hyperbolic model H is more important in modeling tree-structures (i961) and spherical model S is crucial in modeling cyclical structures (i4837). This phenomenon demonstrates that our proposal is capable of effectively capturing the intrinsic correlations between the latent concepts and the geometric structures.\n\n\nRELATED WORK\n\nIn this section, we will briefly summarize two related techniques: the disentangled representation learning and the non-Euclidean representation learning, along with their applications on the recommendation scenario.  \n\n\nDisentangled Representation Learning\n\nDisentangled representation learning aims at learning factorized representations that reveal and disentangle the latent intent factors beneath the input dataset, which has been widely used in a myriad of applications. Higgins et al. [17] propose beta-VAE to learn interpretable factorised latent representations from raw image data in an unsupervised manner. Ma et al. [30] introduce the disentangled graph convolutional network to learn disentangled node representations. Yang et al. [51] propose a factorizable graph convolutional network for explicitly disentangling the intertwined relations encoded in a graph. Recently, disentangled representation learning is introduced into the recommendation scenario to boost performance. MacridVAE [31] is designed to infer the high-level concepts associated with user intentions. Wang et al. [49] further devise a disentangled graph collaborative filtering model to encode the high-order interactions into the factorized representations. For the sequential recommendation, Ma et al. [33] introduce a sequence-to-sequence training strategy based on latent self-supervision and disentanglement. By combining the curriculum learning with the disentangled representation learning, Curriculum Disentangled Recommendation model [8] is proposed to efficiently learn disentangled representations from complex and noisy multi-feedbacks. Despite the promising performance, existing disentangled approaches learn representations solely within the Euclidean geometry and ignore the hybrid geometric characteristics of the user-item interactions.\n\n\nNon-Euclidean Representation Learning\n\nA myriad of data exhibits the highly non-Euclidean latent anatomy [3,25,40,50], and non-Euclidean geometries (i.e., hyperbolic or spherical geometry) are more suitable for modeling data with non-Euclidean characteristics compared to Euclidean geometry. Nickel et al. [38] first leverage the hyperbolic space to learn hierarchical representations of symbolic data. HGCN [7] is an inductive hyperbolic GCN designed for hierarchical and scale-free graphs. Mixed-curvature Variational Autoencoder [43] exploits both the hyperbolic and spherical geometries to better modeling data characteristics. In the recommendation scenario, existing works usually focus on modeling interactions with hyperbolic models [46]. Feng et al. [46] propose to learn the representations of check-in activities in a hyperbolic space. Mirvakhabova et al. [36] propose an autoencoder based on hyperbolic geometry for solving collaborative filtering problem. HGCF [45] is devised to capture the high-order correlations between users and items by integrating hyperbolic geometry into graph neural networks. Most exising works focus on learning representations in a single non-Euclidean space, which may be incapable of modeling the hybrid geometric interactions as discussed in the introduction.\n\n\nCONCLUSION\n\nIn this paper, we study the novel problem of geometric disentangled collaborative filtering. Different from existing single geometrybased CF models, we propose a novel GDCF model to incorporate multiple types of geometries to disentangle the sophisticated hybrid patterns of user-item interactions. Specifically, GDCF learns factorized representations that uncover and disentangle the intent factors hidden in the historical interactions, which is capable of learning expressive user/item representations. Extensive experiments are conducted over five publicly available datasets, and the experimental results demonstrate the superiority of GDCF.\n\n\nA SUPPLEMENTARY MATERIAL A.1 Neural Networks in the hypersphere model\n\nTo ensure the transformed features satisfy the spherical geometry, we define hypersphere matrix-vector multiplication to perform the hypersphere matrix-vector multiplication: The hypersphere matrix-vector multiplication also satisfies following theorem:\n\nTheorem A.1. Given a point in spherical space, which is represented by S \u2208 S using hypersphere model or x D \u2208 D D using projected hypersphere ball model [3], respectively. Let M be a \u00d7 matrix, hypersphere matrix-vector multiplication M\u2297 S used in hyperboloid model is equivalent to M\u00f6bius matrix-vector multiplication M\u2297 D used in projected hypersphere model. Proof. Let S \u2208 S , = ( 0 , 1 , . . . , ) \u2208 T 0 S , and M be a \u00d7 matrix, hypersphere matrix-vector multiplication is shown as follows:   \n\nThe hypersphere matrix-vector multiplication is given as following:\nM\u2297 S = 1 \u221a cos( \u221a \u2225 \u2225), sin( \u221a \u2225 \u2225) \u221a \u2225 \u2225 M\u02c6S = S .(23)\nThen we map S to the projected hypersphere model: \nS \u2192D ( S ) = 1 \u221a tan \u2225M\u02c6S \u2225 cos \u22121 ( \u221a 0 S ) 2\u2225\u02c6S \u2225 M\u02c6S \u2225M\u02c6S \u2225 .(24)\nThus, the squared norm of\u02c6S is given as:\n\u2225\u02c6S \u2225 2 = \u2211\ufe01 =1 2 1 + \u2225 D \u2225 2 2 ( D ) 2 = 2 \u2225 D \u2225 1 + \u2225 D \u2225 2 2 .(26)\nBy combining Eq. (24) and Eq. (26), we have:\nS \u2192D ( S ) =(1/ \u221a ) tan \u2225M D \u2225 \u2225 D \u2225 tan \u22121 ( \u221a \u2225 D \u2225) M D \u2225M D \u2225 = D .(27)\nTherefore, hypersphere matrix-vector multiplication is equivalence to M\u00f6bius matrix-vector multiplication. \u25a1 Also, to apply non-linear transformation on the hypersphere model, the hypersphere pointwise non-linear activation can be derived as:\n\nDefinition A.2. Hypersphere pointwise non-linear activation If : R \u2192 R is a pointwise non-linearity map, given two points x = ( 0 , \u00b7 \u00b7 \u00b7 , ) \u2208 S and v = ( 0 , \u00b7 \u00b7 \u00b7 , ) \u2208 T 0 S , the hypersphere version \u2297 is: \u2297 ( ) = exp 0 (\u02c6\u2297 (log 0 ( ))),\u02c6\u2297 ( ) = (0, ( 1 ), . . . , ( ))).\n\nThe hypersphere pointwise non-linear activation has the following property:\n\nTheorem A.2. Given a point in hyperbolic space, it is modeled by x , \u2208 H , using hyperboloid model and x , \u2208 D , using Poincar\u00e9 ball model, respectively. Lorentzian pointwise non-linearity \u2297 (x , ) in the hyperboloid model is equivalent to M\u00f6bius pointwise non-linearity \u2297 (x , ) in the Poincar\u00e9 ball model [10], when (\u00b7) indicates some specific non-linear activation, e.g., Relu, leaklyRelu.\n\nThe proof of Theorem A.2 is similar to Theorem A.1, and we omit it due to the page length limit. \n\nFigure 1 :\n1An illustration of the user-item interactions and the non-Euclidean structures.\n\nFigure 2 :\n2The framework of GDCF.\n\nTheorem 4. 1 .\n1For x, y \u2208 M and M \u2208 {E, S , D , H , P }, the geodesic distance between x and y, is equal to the norm of log x (y) in the tangent space T m M , i.e., (x, y) = \u2225 log x (y)\u2225 . Proof of Theorem 4.1: For Euclidean space E, it is easy to prove that \u2225 log ( )\u2225 = \u2225 \u2212 \u2225 = E ( , ). For the hyperboloid model, let = log ( ), we have = exp ( ).\n\n\n), we need to first sample instances from the tangent space of the manifold T 0 M , i.e., v \u223c N (0, ) \u2208 T 0 M . The geometric disentangled representation z ( ) can be obtained via parallel transporting v from T 0 M to T M , and then projecting it to the manifold T M by exponential map:\n\nFigure 3 :\n3Results of the parameter sensitivity analysis.\n\nFigure 4 :\n4Local topological structures and concept assignments of two cases in MovieLens-100k. The center nodes, 1-hop nodes, 2-hop nodes are marked by red, green, blue circles, respectively.\n\n\nDefinition A.1. (Hypersphere matrix-vector multiplication) If M : R \u2192 R is a linear map with matrix representation, given two points = ( 0 , . . . , ) \u2208 S , = ( 0 , . . . , ) \u2208 T 0 S , we have: M \u2297 ( ) = exp 0 (M(log 0 ( ))),M( ) = (0, M( 1 , . . . , )). (18) Let M be a \u00d7 matrix, M \u2032 be a \u00d7 matrix, x \u2208 S , M\u2297 := M \u2297 ( ), we have matrix associativity as: (M \u2032 M)\u2297 = M \u2032 \u2297 (M\u2297 ).\n\n\nM\u2297 S : = M \u2297 ( S ) = exp 0 M log 0 ( S ) = S , M( ) = 0, M( 1 ,. . . , ).\n\nFor\nS \u2192D ( S ) = D and a shared \u00d7 matrix M, we aim to prove S \u2192D ( S ) = D . For S = ( 0 S , 1 S , . . . , S ) \u2208 S , let\u02c6S = ( 1 S , . . . , S ), and the logarithmic map of S at 0 = 0 ( S ) = (0,\u02c6S ), so we have: M log 0 ( S ) = (0, M\u02c6S ) = .\n\n\nNote that \u2225 \u2225 = \u221a\ufe01 \u27e8 , \u27e9 = \u2225 M\u02c6S \u2225, and 0 S = \u221a\ufe03 1/ \u2212 \u2225\u02c6S \u2225 2 . Moreover, the point D = ( 1 D , . . . , D ) \u2208 D can be mapped into the hypersphere model as following: D \u2192S ( D ) 2 , 2 1 D , . . . , 2 D ) 1 + \u2225 D \u2225 2 = ( 0 S , 1 S , . . . , S ).\n\n\nDifferent from existing single geometry based approaches, we aim to learn the representations for users {z } =1 and items {h } =1 by disentangling user embeddings with different geometries to comprehensively understand the sophisticated interactions.Topic 2: Collaborative Filtering \nSIGIR '22, July 11-15, 2022, Madrid, Spain \n\n\n\nBased on Theorem 4.1, we can measure the similarities by the norm of h \u2032 as:Topic 2: Collaborative Filtering \nSIGIR '22, July 11-15, 2022, Madrid, Spain \n\n\nTable 1 :\n1Statistics of five datasets.Dataset \nMovieLens-100k MovieLens-1M MovieLens-20M AliShop LastFM \n\n#users \n603 \n6,038 \n136,677 \n10,668 \n1,862 \n#items \n5,697 \n3,605 \n20,108 \n20,591 \n14,795 \n#interactions \n47,922 \n836,452 \n9,990,030 \n767,493 89,805 \n#held-out users \n50 \n500 \n10,000 \n4,000 \n200 \n\n\n\nTable 2 :\n2The recommendation performance comparison. Best results are in bold and second best results are underlined.Datasets \nMovieLens-100k \nMovieLens-1M \nMovieLens-20M \nAlishop \nLastFM \n\nMetric \nNDCG@20 Recall@20 NDCG@20 Recall@20 NDCG@20 Recall@20 NDCG@20 Recall@20 NDCG@20 Recall@20 \n\nNGCF \n0.2437 \n0.2997 \n0.2956 \n0.2852 \n0.2979 \n0.3214 \n0.1058 \n0.1175 \n0.2681 \n0.2924 \nLightGCN \n0.2596 \n0.3112 \n0.3115 \n0.3016 \n0.3172 \n0.3498 \n0.1573 \n0.1512 \n0.3116 \n0.3258 \nHyperML \n0.2160 \n0.2549 \n0.2719 \n0.2839 \n0.2631 \n0.2809 \n0.1023 \n0.1061 \n0.2546 \n0.2852 \nH-VAE \n0.2157 \n0.2706 \n0.2729 \n0.3049 \n0.2405 \n0.2737 \n0.1087 \n0.1101 \n0.2667 \n0.2795 \nHGCF \n0.2218 \n0.2701 \n0.2844 \n0.2955 \n0.3093 \n0.3536 \n0.1115 \n0.1135 \n0.2706 \n0.2985 \n-GCN \n0.1912 \n0.2408 \n0.2443 \n0.2351 \n0.2155 \n0.2419 \n0.0846 \n0.0816 \n0.2489 \n0.2582 \nDGCF \n0.2572 \n0.3148 \n0.3252 \n0.3128 \n0.3193 \n0.3626 \n0.1556 \n0.1547 \n0.3062 \n0.3242 \nMacridVAE \n0.2310 \n0.3095 \n0.3241 \n0.3605 \n0.3205 \n0.3965 \n0.1831 \n0.1862 \n0.3072 \n0.3213 \n\nGDCF \n0.2652 \n0.3261 \n0.3314 \n0.3637 \n0.3317 \n0.4052 \n0.1874 \n0.1886 \n0.3173 \n0.3296 \n\n\n\nTable 4 :\n4Results of the universal curvature analysis.Dataset \nMetric \nP&D \nU \nBest \n\nMovieLens-100k \nNDCG@20 0.2526 0.2564 H&E&S \nRecall@20 0.3164 0.3218 H&E&S \n\nMovieLens-1M \nNDCG@20 0.3241 0.3261 H&R&S \nRecall@20 0.3562 0.3557 H&E&S \n\nMovieLens-20M \nNDCG@20 0.3266 0.3301 H&E&S \nRecall@20 0.3934 0.4049 H&E&S \n\nAliShop \nNDCG@20 0.1818 0.1821 \nH&E \nRecall@20 0.1794 0.1814 H&E&S \n\nLastFM \nNDCG@20 0.3099 0.3134 H&E&S \nRecall@20 0.3227 0.3305 \nU \n\nand then drops on both datasets across all metrics. This phenom-\nenon suggests that a suitable number of concepts is needed for \nGDCF, while redundant concepts may introduce noise and lead to \nthe performance decay. Also, figure 3(c) and 3(d) present the results \nof GDCF under varying . With the increase of the dimension of \nembeddings , model performance first improves and then keeps \nsteady. This is reasonable as representations of proper dimensions \nare already capable of fully modeling the interactions, and too large \ndimensions may increase model complexity and effect the training \nefficiency. \n\n\n\n\nTopic 2: Collaborative Filtering SIGIR '22, July 11-15, 2022, Madrid, Spain\nACKNOWLEDGMENTSThis work is supported in part by the National Natural Science Foundation of China (No. U20B2045, 62192784, 62172052, 62002029, 61772082).\nToward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions. Gediminas Adomavicius, Alexander Tuzhilin, IEEE transactions on knowledge and data engineering. 17Gediminas Adomavicius and Alexander Tuzhilin. 2005. Toward the next gen- eration of recommender systems: A survey of the state-of-the-art and possible extensions. IEEE transactions on knowledge and data engineering 17, 6 (2005), 734-749.\n\nOptuna: A Next-generation Hyperparameter Optimization Framework. Takuya Akiba, Shotaro Sano, Toshihiko Yanase, Takeru Ohta, Masanori Koyama, SIGKDD. Takuya Akiba, Shotaro Sano, Toshihiko Yanase, Takeru Ohta, and Masanori Koyama. 2019. Optuna: A Next-generation Hyperparameter Optimization Frame- work. In SIGKDD.\n\nConstant Curvature Graph Convolutional Networks. Gregor Bachmann, Gary B\u00e9cigneul, Octavian-Eugen Ganea, ICML. Gregor Bachmann, Gary B\u00e9cigneul, and Octavian-Eugen Ganea. 2020. Constant Curvature Graph Convolutional Networks. In ICML.\n\nRiemannian Adaptive Optimization Methods. Gary Becigneul, Octavian-Eugen Ganea, ICLR. Gary Becigneul and Octavian-Eugen Ganea. 2019. Riemannian Adaptive Opti- mization Methods. In ICLR.\n\nA panoramic view of Riemannian geometry. Marcel Berger, Springer Science & Business MediaMarcel Berger. 2012. A panoramic view of Riemannian geometry. Springer Science & Business Media.\n\nIv\u00e1n Cantador, Peter Brusilovsky, Tsvi Kuflik, 2nd Workshop on Information Heterogeneity and Fusion in Recommender Systems. RecSys. ACMIv\u00e1n Cantador, Peter Brusilovsky, and Tsvi Kuflik. 2011. 2nd Workshop on Information Heterogeneity and Fusion in Recommender Systems (HetRec 2011). In RecSys. ACM.\n\nInes Chami, Zhitao Ying, Christopher R\u00e9, Jure Leskovec, Hyperbolic graph convolutional neural networks. In NeurIPS. Ines Chami, Zhitao Ying, Christopher R\u00e9, and Jure Leskovec. 2019. Hyperbolic graph convolutional neural networks. In NeurIPS. 4869-4880.\n\nHong Chen, Yudong Chen, Xin Wang, Ruobing Xie, Rui Wang, Feng Xia, and Wenwu Zhu. 2021. Curriculum Disentangled Recommendation with Noisy Multifeedback. 34Hong Chen, Yudong Chen, Xin Wang, Ruobing Xie, Rui Wang, Feng Xia, and Wenwu Zhu. 2021. Curriculum Disentangled Recommendation with Noisy Multi- feedback. NeurIPS 34 (2021).\n\nLuca Tim R Davidson, Nicola De Falorsi, Thomas Cao, Jakub M Kipf, Tomczak, arXiv:1804.00891Hyperspherical variational auto-encoders. arXiv preprintTim R Davidson, Luca Falorsi, Nicola De Cao, Thomas Kipf, and Jakub M Tomczak. 2018. Hyperspherical variational auto-encoders. arXiv preprint arXiv:1804.00891 (2018).\n\nOctavian Ganea, Gary B\u00e9cigneul, Thomas Hofmann, Hyperbolic neural networks. In NeurIPS. Octavian Ganea, Gary B\u00e9cigneul, and Thomas Hofmann. 2018. Hyperbolic neural networks. In NeurIPS. 5350-5360.\n\nLearning mixedcurvature representations in product spaces. Albert Gu, Frederic Sala, Beliz Gunel, Christopher R\u00e9, ICLR. Albert Gu, Frederic Sala, Beliz Gunel, and Christopher R\u00e9. 2018. Learning mixed- curvature representations in product spaces. In ICLR.\n\nMaxwell Harper, Joseph A Konstan, The movielens datasets: History and context. Acm transactions on interactive intelligent systems (tiis). 5F Maxwell Harper and Joseph A Konstan. 2015. The movielens datasets: History and context. Acm transactions on interactive intelligent systems (tiis) 5, 4 (2015), 1-19.\n\nDirectional statistics with the spherical normal distribution. S\u00f8ren Hauberg, S\u00f8ren Hauberg. 2018. Directional statistics with the spherical normal distribution. In FUSION. 704-711.\n\nLightgcn: Simplifying and powering graph convolution network for recommendation. Xiangnan He, Kuan Deng, Xiang Wang, Yan Li, Yongdong Zhang, Meng Wang, SIGIR. Xiangnan He, Kuan Deng, Xiang Wang, Yan Li, Yongdong Zhang, and Meng Wang. 2020. Lightgcn: Simplifying and powering graph convolution network for recommendation. In SIGIR. 639-648.\n\nNeural collaborative filtering. Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, Tat-Seng Chua, Proceedings of the 26th international conference on world wide web. the 26th international conference on world wide webXiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. Neural collaborative filtering. In Proceedings of the 26th international conference on world wide web. 173-182.\n\nSigurdur Helgason. 1979. Differential geometry, Lie groups, and symmetric spaces. Academic press80Sigurdur Helgason. 1979. Differential geometry, Lie groups, and symmetric spaces. Vol. 80. Academic press.\n\nShakir Mohamed, and Alexander Lerchner. 2017. beta-vae: Learning basic visual concepts with a constrained variational framework. Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick, Irina Higgins, Loic Matthey, Arka Pal, Christopher Burgess, Xavier Glorot, Matthew Botvinick, Shakir Mohamed, and Alexander Lerchner. 2017. beta-vae: Learning basic visual concepts with a constrained variational framework. In ICLR. 1024-1034.\n\nLearning to decompose and disentangle representations for video prediction. Jun-Ting Hsieh, Bingbin Liu, De-An Huang, Li Fei-Fei, Juan Carlos Niebles, NeurIPS. Jun-Ting Hsieh, Bingbin Liu, De-An Huang, Li Fei-Fei, and Juan Carlos Niebles. 2018. Learning to decompose and disentangle representations for video prediction. In NeurIPS. 515-524.\n\nNonlinear programming. Kuhn Hw, T Aw, Proceedings of 2nd Berkeley Symposium. 2nd Berkeley SymposiumBerkeleyUniversity of California PressKuhn HW and T AW. 1951. Nonlinear programming. In Proceedings of 2nd Berkeley Symposium, Berkeley: University of California Press. 481-492.\n\nDisentangled Representation Learning for Non-Parallel Text Style Transfer. Vineet John, Lili Mou, Hareesh Bahuleyan, Olga Vechtomova, ACL. Vineet John, Lili Mou, Hareesh Bahuleyan, and Olga Vechtomova. 2019. Disen- tangled Representation Learning for Non-Parallel Text Style Transfer. In ACL. 424-434.\n\nMinima of Functions of Several Variables with Inequalities as Side Conditions. William Karush, Chicago, IL, USADepartment of Mathematics, University of ChicagoMaster's thesisWilliam Karush. 1939. Minima of Functions of Several Variables with Inequalities as Side Conditions. Master's thesis. Department of Mathematics, University of Chicago, Chicago, IL, USA.\n\nAdam: A method for stochastic optimization. P Diederik, Jimmy Kingma, Ba, ICLR. Diederik P Kingma and Jimmy Ba. 2015. Adam: A method for stochastic opti- mization. ICLR (2015).\n\nP Diederik, Max Kingma, Welling, arXiv:1312.6114Auto-encoding variational bayes. arXiv preprintDiederik P Kingma and Max Welling. 2013. Auto-encoding variational bayes. arXiv preprint arXiv:1312.6114 (2013).\n\nMatrix factorization techniques for recommender systems. Yehuda Koren, Robert Bell, Chris Volinsky, Computer. 42Yehuda Koren, Robert Bell, and Chris Volinsky. 2009. Matrix factorization tech- niques for recommender systems. Computer 42, 8 (2009), 30-37.\n\nHyperbolic geometry of complex networks. Dmitri Krioukov, Fragkiskos Papadopoulos, Maksim Kitsak, Amin Vahdat, Mari\u00e1n Bogun\u00e1, Physical Review E. 8236106Dmitri Krioukov, Fragkiskos Papadopoulos, Maksim Kitsak, Amin Vahdat, and Mari\u00e1n Bogun\u00e1. 2010. Hyperbolic geometry of complex networks. Physical Review E 82, 3 (2010), 036106.\n\nCollaborative variational autoencoder for recommender systems. Xiaopeng Li, James She, SIGKDD. Xiaopeng Li and James She. 2017. Collaborative variational autoencoder for recommender systems. In SIGKDD. 305-314.\n\nVariational autoencoders for collaborative filtering. Dawen Liang, G Rahul, Krishnan, D Matthew, Tony Hoffman, Jebara, WWW. Dawen Liang, Rahul G Krishnan, Matthew D Hoffman, and Tony Jebara. 2018. Variational autoencoders for collaborative filtering. In WWW. 689-698.\n\nThe geometry of graphs and some of its algorithmic applications. Nathan Linial, Eran London, Yuri Rabinovich, Combinatorica. 15Nathan Linial, Eran London, and Yuri Rabinovich. 1995. The geometry of graphs and some of its algorithmic applications. Combinatorica 15, 2 (1995), 215-245.\n\nHyperbolic graph neural networks. In NeurIPS. Qi Liu, Maximilian Nickel, Douwe Kiela, Qi Liu, Maximilian Nickel, and Douwe Kiela. 2019. Hyperbolic graph neural networks. In NeurIPS. 8228-8239.\n\nDisentangled graph convolutional networks. Jianxin Ma, Peng Cui, Kun Kuang, Xin Wang, Wenwu Zhu, ICML. PMLR. Jianxin Ma, Peng Cui, Kun Kuang, Xin Wang, and Wenwu Zhu. 2019. Disentangled graph convolutional networks. In ICML. PMLR, 4212-4221.\n\nLearning disentangled representations for recommendation. Jianxin Ma, Chang Zhou, Peng Cui, Hongxia Yang, Wenwu Zhu, NeurIPS. Jianxin Ma, Chang Zhou, Peng Cui, Hongxia Yang, and Wenwu Zhu. 2019. Learn- ing disentangled representations for recommendation. In NeurIPS. 5711-5722.\n\nDisentangled Self-Supervision in Sequential Recommenders. Jianxin Ma, Chang Zhou, Hongxia Yang, Peng Cui, Xin Wang, Wenwu Zhu, SIGKDD. Jianxin Ma, Chang Zhou, Hongxia Yang, Peng Cui, Xin Wang, and Wenwu Zhu. 2020. Disentangled Self-Supervision in Sequential Recommenders. In SIGKDD. 483-491.\n\nDisentangled self-supervision in sequential recommenders. Jianxin Ma, Chang Zhou, Hongxia Yang, Peng Cui, Xin Wang, Wenwu Zhu, SIGKDD. Jianxin Ma, Chang Zhou, Hongxia Yang, Peng Cui, Xin Wang, and Wenwu Zhu. 2020. Disentangled self-supervision in sequential recommenders. In SIGKDD. 483-491.\n\nEmile Mathieu, Charline Le Lan, Chris J Maddison, Ryota Tomioka, Yee Whye Teh, arXiv:1901.06033Continuous Hierarchical Representations with Poincar\u00e9 Variational Auto-Encoders. arXiv preprintEmile Mathieu, Charline Le Lan, Chris J Maddison, Ryota Tomioka, and Yee Whye Teh. 2019. Continuous Hierarchical Representations with Poincar\u00e9 Variational Auto-Encoders. arXiv preprint arXiv:1901.06033 (2019).\n\nRiemannian Continuous Normalizing Flows. Emile Mathieu, Maximilian Nickel, NeurIPS. Emile Mathieu and Maximilian Nickel. 2020. Riemannian Continuous Normaliz- ing Flows. In NeurIPS. 2503-2515.\n\nPerformance of hyperbolic geometry models on top-N recommendation tasks. Leyla Mirvakhabova, Evgeny Frolov, Valentin Khrulkov, Ivan Oseledets, Alexander Tuzhilin, RecSys. Leyla Mirvakhabova, Evgeny Frolov, Valentin Khrulkov, Ivan Oseledets, and Alexander Tuzhilin. 2020. Performance of hyperbolic geometry models on top-N recommendation tasks. In RecSys. 527-532.\n\nA wrapped normal distribution on hyperbolic space for gradient-based learning. Yoshihiro Nagano, Shoichiro Yamaguchi, Yasuhiro Fujita, Masanori Koyama, Yoshihiro Nagano, Shoichiro Yamaguchi, Yasuhiro Fujita, and Masanori Koyama. 2019. A wrapped normal distribution on hyperbolic space for gradient-based learning. In ICML. 4693-4702.\n\nPoincar\u00e9 embeddings for learning hierarchical representations. Maximillian Nickel, Douwe Kiela, NeurIPS. Maximillian Nickel and Douwe Kiela. 2017. Poincar\u00e9 embeddings for learning hierarchical representations. In NeurIPS. 6338-6347.\n\nLearning continuous hierarchies in the lorentz model of hyperbolic geometry. Maximilian Nickel, Douwe Kiela, ICML. Maximilian Nickel and Douwe Kiela. 2018. Learning continuous hierarchies in the lorentz model of hyperbolic geometry. In ICML. 3779-3788.\n\nWei Peng, Tuomas Varanka, Abdelrahman Mostafa, Henglin Shi, Guoying Zhao, arXiv:2101.04562Hyperbolic deep neural networks: A survey. arXiv preprintWei Peng, Tuomas Varanka, Abdelrahman Mostafa, Henglin Shi, and Guoy- ing Zhao. 2021. Hyperbolic deep neural networks: A survey. arXiv preprint arXiv:2101.04562 (2021).\n\nRepresentation tradeoffs for hyperbolic embeddings. Frederic Sala, Chris De Sa, Albert Gu, Christopher R\u00e9, ICML. Frederic Sala, Chris De Sa, Albert Gu, and Christopher R\u00e9. 2018. Representation tradeoffs for hyperbolic embeddings. In ICML. 4457-4466.\n\nGraph Neural Networks for Friend Ranking in Large-scale Social Platforms. Aravind Sankar, Yozen Liu, Jun Yu, Neil Shah, Aravind Sankar, Yozen Liu, Jun Yu, and Neil Shah. 2021. Graph Neural Networks for Friend Ranking in Large-scale Social Platforms. In WWW. 2535-2546.\n\nMixedcurvature Variational Autoencoders. Ondrej Skopek, Octavian-Eugen, Gary Ganea, B\u00e9cigneul, ICLR. Ondrej Skopek, Octavian-Eugen Ganea, and Gary B\u00e9cigneul. 2019. Mixed- curvature Variational Autoencoders. In ICLR.\n\nA survey of collaborative filtering techniques. Xiaoyuan Su, M Taghi, Khoshgoftaar, Advances in artificial intelligence. Xiaoyuan Su and Taghi M Khoshgoftaar. 2009. A survey of collaborative filtering techniques. Advances in artificial intelligence 2009 (2009).\n\nFelipe P\u00e9rez, and Maksims Volkovs. 2021. HGCF: Hyperbolic Graph Convolution Networks for Collaborative Filtering. Jianing Sun, Zhaoyue Cheng, Saba Zuberi, Jianing Sun, Zhaoyue Cheng, Saba Zuberi, Felipe P\u00e9rez, and Maksims Volkovs. 2021. HGCF: Hyperbolic Graph Convolution Networks for Collaborative Filtering. In WWW. 593-601.\n\nHyperML: A Boosting Metric Learning Approach in Hyperbolic Space for Recommender Systems. Yi Lucas Vinh Tran, Shuai Tay, Gao Zhang, Xiaoli Cong, Li, WSDM. Lucas Vinh Tran, Yi Tay, Shuai Zhang, Gao Cong, and Xiaoli Li. 2020. HyperML: A Boosting Metric Learning Approach in Hyperbolic Space for Recommender Systems.. In WSDM. 609-617.\n\nCollaborative deep learning for recommender systems. Hao Wang, Naiyan Wang, Dit-Yan Yeung, SIGKDD. Hao Wang, Naiyan Wang, and Dit-Yan Yeung. 2015. Collaborative deep learning for recommender systems. In SIGKDD. 1235-1244.\n\nNeural graph collaborative filtering. Xiang Wang, Xiangnan He, Meng Wang, Fuli Feng, Tat-Seng Chua, SIGIR. Xiang Wang, Xiangnan He, Meng Wang, Fuli Feng, and Tat-Seng Chua. 2019. Neural graph collaborative filtering. In SIGIR. 165-174.\n\nDisentangled Graph Collaborative Filtering. Xiang Wang, Hongye Jin, An Zhang, Xiangnan He, Tong Xu, Tat-Seng Chua, SIGIR. Xiang Wang, Hongye Jin, An Zhang, Xiangnan He, Tong Xu, and Tat-Seng Chua. 2020. Disentangled Graph Collaborative Filtering. In SIGIR. 1001-1010.\n\nSpherical and hyperbolic embeddings of data. C Richard, Edwin R Wilson, El\u017cbieta Hancock, Robert Pw Pekalska, Duin, 36Richard C Wilson, Edwin R Hancock, El\u017cbieta Pekalska, and Robert PW Duin. 2014. Spherical and hyperbolic embeddings of data. IEEE transactions on pattern analysis and machine intelligence 36, 11 (2014), 2255-2269.\n\nFactorizable Graph Convolutional Networks. Yiding Yang, Zunlei Feng, Mingli Song, Xinchao Wang, NeurIPS. 33Yiding Yang, Zunlei Feng, Mingli Song, and Xinchao Wang. 2020. Factorizable Graph Convolutional Networks. NeurIPS 33 (2020).\n\nWhere are we in embedding spaces?. Sixiao Zhang, Hongxu Chen, Xiao Ming, Lizhen Cui, Hongzhi Yin, Guandong Xu, arXiv:2105.08908A Comprehensive Analysis on Network Embedding Approaches for Recommender Systems. arXiv preprintSixiao Zhang, Hongxu Chen, Xiao Ming, Lizhen Cui, Hongzhi Yin, and Guandong Xu. 2021. Where are we in embedding spaces? A Comprehensive Analysis on Network Embedding Approaches for Recommender Systems. arXiv preprint arXiv:2105.08908 (2021).\n\nLorentzian Graph Convolutional Networks. Yiding Zhang, Xiao Wang, Chuan Shi, Nian Liu, Guojie Song, WWW. Yiding Zhang, Xiao Wang, Chuan Shi, Nian Liu, and Guojie Song. 2021. Lorentzian Graph Convolutional Networks. In WWW. 1249-1261.\n\nDisentangling User Interest and Conformity for Recommendation with Causal Embedding. Yu Zheng, Chen Gao, Xiang Li, Xiangnan He, Depeng Jin, Yong Li, arXiv:2006.11011arXiv preprintYu Zheng, Chen Gao, Xiang Li, Xiangnan He, Depeng Jin, and Yong Li. 2020. Disentangling User Interest and Conformity for Recommendation with Causal Embedding. arXiv preprint arXiv:2006.11011 (2020).\n", "annotations": {"author": "[{\"end\":119,\"start\":106},{\"end\":132,\"start\":120},{\"end\":164,\"start\":133},{\"end\":196,\"start\":165},{\"end\":229,\"start\":197},{\"end\":258,\"start\":230},{\"end\":277,\"start\":259},{\"end\":299,\"start\":278},{\"end\":333,\"start\":300},{\"end\":352,\"start\":334},{\"end\":368,\"start\":353},{\"end\":382,\"start\":369},{\"end\":395,\"start\":383},{\"end\":428,\"start\":396},{\"end\":439,\"start\":429},{\"end\":450,\"start\":440},{\"end\":462,\"start\":451},{\"end\":471,\"start\":463},{\"end\":487,\"start\":472},{\"end\":500,\"start\":488},{\"end\":532,\"start\":501},{\"end\":598,\"start\":533},{\"end\":646,\"start\":599},{\"end\":685,\"start\":647},{\"end\":751,\"start\":686},{\"end\":817,\"start\":752},{\"end\":842,\"start\":818},{\"end\":867,\"start\":843},{\"end\":892,\"start\":868}]", "publisher": "[{\"end\":51,\"start\":48},{\"end\":1223,\"start\":1220}]", "author_last_name": "[{\"end\":118,\"start\":113},{\"end\":131,\"start\":129},{\"end\":142,\"start\":138},{\"end\":174,\"start\":171},{\"end\":207,\"start\":204},{\"end\":237,\"start\":234},{\"end\":276,\"start\":269},{\"end\":298,\"start\":293},{\"end\":311,\"start\":307},{\"end\":351,\"start\":344},{\"end\":367,\"start\":362},{\"end\":381,\"start\":376},{\"end\":394,\"start\":392},{\"end\":404,\"start\":401},{\"end\":438,\"start\":434},{\"end\":449,\"start\":446},{\"end\":461,\"start\":458},{\"end\":470,\"start\":467},{\"end\":486,\"start\":481},{\"end\":499,\"start\":495},{\"end\":509,\"start\":504}]", "author_first_name": "[{\"end\":112,\"start\":106},{\"end\":128,\"start\":120},{\"end\":137,\"start\":133},{\"end\":170,\"start\":165},{\"end\":203,\"start\":197},{\"end\":233,\"start\":230},{\"end\":268,\"start\":259},{\"end\":283,\"start\":278},{\"end\":292,\"start\":284},{\"end\":306,\"start\":300},{\"end\":343,\"start\":334},{\"end\":358,\"start\":353},{\"end\":361,\"start\":359},{\"end\":375,\"start\":369},{\"end\":391,\"start\":383},{\"end\":400,\"start\":396},{\"end\":433,\"start\":429},{\"end\":445,\"start\":440},{\"end\":457,\"start\":451},{\"end\":466,\"start\":463},{\"end\":480,\"start\":472},{\"end\":494,\"start\":488},{\"end\":503,\"start\":501}]", "author_affiliation": "[{\"end\":597,\"start\":534},{\"end\":645,\"start\":600},{\"end\":684,\"start\":648},{\"end\":750,\"start\":687},{\"end\":816,\"start\":753},{\"end\":841,\"start\":819},{\"end\":866,\"start\":844},{\"end\":891,\"start\":869}]", "title": "[{\"end\":47,\"start\":1},{\"end\":939,\"start\":893}]", "venue": "[{\"end\":1064,\"start\":941}]", "abstract": "[{\"end\":2671,\"start\":1591}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2832,\"start\":2829},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":2974,\"start\":2970},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":2977,\"start\":2974},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":2980,\"start\":2977},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":3178,\"start\":3174},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":3260,\"start\":3257},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":3456,\"start\":3452},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":3637,\"start\":3633},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":3843,\"start\":3839},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":3846,\"start\":3843},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":4080,\"start\":4076},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":4083,\"start\":4080},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":4205,\"start\":4201},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":4379,\"start\":4376},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":4382,\"start\":4379},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":4385,\"start\":4382},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":4388,\"start\":4385},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":4930,\"start\":4926},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":5087,\"start\":5083},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":5179,\"start\":5175},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":5488,\"start\":5484},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":5701,\"start\":5698},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":5703,\"start\":5701},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":5847,\"start\":5843},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":5850,\"start\":5847},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":5853,\"start\":5850},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":5856,\"start\":5853},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":6480,\"start\":6476},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":6483,\"start\":6480},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":6486,\"start\":6483},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":6489,\"start\":6486},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":10230,\"start\":10227},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":10670,\"start\":10666},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":11009,\"start\":11005},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":11734,\"start\":11730},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":12110,\"start\":12106},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":12954,\"start\":12951},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":12962,\"start\":12959},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":13257,\"start\":13253},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":13511,\"start\":13510},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":13915,\"start\":13911},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":13918,\"start\":13915},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":13921,\"start\":13918},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":15317,\"start\":15313},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":15320,\"start\":15317},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":15566,\"start\":15562},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":16663,\"start\":16659},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":17816,\"start\":17812},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":18636,\"start\":18632},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":19097,\"start\":19094},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":19100,\"start\":19097},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":19103,\"start\":19100},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":19211,\"start\":19208},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":19214,\"start\":19211},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":19641,\"start\":19637},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":19986,\"start\":19982},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":19989,\"start\":19986},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":20742,\"start\":20738},{\"end\":20822,\"start\":20819},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":21793,\"start\":21789},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":21816,\"start\":21813},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":22539,\"start\":22535},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":22634,\"start\":22630},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":23469,\"start\":23466},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":23472,\"start\":23469},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":23475,\"start\":23472},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":23635,\"start\":23632},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":23818,\"start\":23814},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":23821,\"start\":23818},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":23824,\"start\":23821},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":24127,\"start\":24123},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":24130,\"start\":24127},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":24755,\"start\":24751},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":24758,\"start\":24755},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":24761,\"start\":24758},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":24764,\"start\":24761},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":24996,\"start\":24992},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":25696,\"start\":25693},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":25699,\"start\":25696},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":25702,\"start\":25699},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":26440,\"start\":26436},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":26673,\"start\":26669},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":26687,\"start\":26683},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":26702,\"start\":26699},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":26780,\"start\":26776},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":26783,\"start\":26780},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":26916,\"start\":26912},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":27028,\"start\":27024},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":27110,\"start\":27106},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":27249,\"start\":27245},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":27376,\"start\":27372},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":27487,\"start\":27483},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":27615,\"start\":27611},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":27758,\"start\":27755},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":28533,\"start\":28530},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":28992,\"start\":28988},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":28995,\"start\":28992},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":28998,\"start\":28995},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":31779,\"start\":31776},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":31782,\"start\":31779},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":31785,\"start\":31782},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":32161,\"start\":32157},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":32706,\"start\":32702},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":33353,\"start\":33349},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":35672,\"start\":35668},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":35808,\"start\":35804},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":35924,\"start\":35920},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":36181,\"start\":36177},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":36276,\"start\":36272},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":36467,\"start\":36463},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":36705,\"start\":36702},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":37124,\"start\":37121},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":37127,\"start\":37124},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":37130,\"start\":37127},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":37133,\"start\":37130},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":37326,\"start\":37322},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":37427,\"start\":37424},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":37552,\"start\":37548},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":37761,\"start\":37757},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":37779,\"start\":37775},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":37887,\"start\":37883},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":37994,\"start\":37990},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":39466,\"start\":39463},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":40184,\"start\":40180},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":41193,\"start\":41189}]", "figure": "[{\"attributes\":{\"id\":\"fig_1\"},\"end\":41466,\"start\":41374},{\"attributes\":{\"id\":\"fig_2\"},\"end\":41502,\"start\":41467},{\"attributes\":{\"id\":\"fig_3\"},\"end\":41854,\"start\":41503},{\"attributes\":{\"id\":\"fig_5\"},\"end\":42143,\"start\":41855},{\"attributes\":{\"id\":\"fig_6\"},\"end\":42203,\"start\":42144},{\"attributes\":{\"id\":\"fig_7\"},\"end\":42398,\"start\":42204},{\"attributes\":{\"id\":\"fig_8\"},\"end\":42780,\"start\":42399},{\"attributes\":{\"id\":\"fig_9\"},\"end\":42856,\"start\":42781},{\"attributes\":{\"id\":\"fig_11\"},\"end\":43100,\"start\":42857},{\"attributes\":{\"id\":\"fig_12\"},\"end\":43347,\"start\":43101},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":43678,\"start\":43348},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":43835,\"start\":43679},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":44140,\"start\":43836},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":45222,\"start\":44141},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":46282,\"start\":45223},{\"attributes\":{\"id\":\"tab_10\",\"type\":\"table\"},\"end\":46360,\"start\":46283}]", "paragraph": "[{\"end\":3261,\"start\":2687},{\"end\":5704,\"start\":3263},{\"end\":6684,\"start\":5706},{\"end\":7810,\"start\":6686},{\"end\":8735,\"start\":7812},{\"end\":8784,\"start\":8737},{\"end\":9251,\"start\":8786},{\"end\":9302,\"start\":9253},{\"end\":9917,\"start\":9325},{\"end\":10353,\"start\":9933},{\"end\":10543,\"start\":10480},{\"end\":10848,\"start\":10604},{\"end\":11352,\"start\":10882},{\"end\":11586,\"start\":11477},{\"end\":11735,\"start\":11649},{\"end\":11895,\"start\":11775},{\"end\":12323,\"start\":11934},{\"end\":12591,\"start\":12339},{\"end\":13384,\"start\":12617},{\"end\":13857,\"start\":13386},{\"end\":14389,\"start\":13886},{\"end\":14929,\"start\":14425},{\"end\":15321,\"start\":15116},{\"end\":15567,\"start\":15400},{\"end\":15716,\"start\":15661},{\"end\":15881,\"start\":15735},{\"end\":16952,\"start\":15905},{\"end\":17107,\"start\":16976},{\"end\":17355,\"start\":17109},{\"end\":17679,\"start\":17519},{\"end\":17900,\"start\":17773},{\"end\":18005,\"start\":17919},{\"end\":18161,\"start\":18045},{\"end\":18486,\"start\":18204},{\"end\":18637,\"start\":18548},{\"end\":18874,\"start\":18704},{\"end\":19912,\"start\":19036},{\"end\":20144,\"start\":19914},{\"end\":21365,\"start\":20214},{\"end\":21520,\"start\":21428},{\"end\":22127,\"start\":21567},{\"end\":24641,\"start\":22143},{\"end\":25616,\"start\":24643},{\"end\":26441,\"start\":25618},{\"end\":26903,\"start\":26480},{\"end\":27844,\"start\":26905},{\"end\":28700,\"start\":27846},{\"end\":29894,\"start\":28717},{\"end\":30634,\"start\":29913},{\"end\":31786,\"start\":30636},{\"end\":33532,\"start\":31819},{\"end\":34064,\"start\":33567},{\"end\":34233,\"start\":34077},{\"end\":35159,\"start\":34248},{\"end\":35394,\"start\":35176},{\"end\":37013,\"start\":35435},{\"end\":38320,\"start\":37055},{\"end\":38981,\"start\":38335},{\"end\":39308,\"start\":39055},{\"end\":39806,\"start\":39310},{\"end\":39875,\"start\":39808},{\"end\":39982,\"start\":39932},{\"end\":40092,\"start\":40052},{\"end\":40207,\"start\":40163},{\"end\":40526,\"start\":40284},{\"end\":40803,\"start\":40528},{\"end\":40880,\"start\":40805},{\"end\":41274,\"start\":40882},{\"end\":41373,\"start\":41276}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":10479,\"start\":10354},{\"attributes\":{\"id\":\"formula_1\"},\"end\":10603,\"start\":10544},{\"attributes\":{\"id\":\"formula_2\"},\"end\":10881,\"start\":10849},{\"attributes\":{\"id\":\"formula_3\"},\"end\":11476,\"start\":11353},{\"attributes\":{\"id\":\"formula_4\"},\"end\":11648,\"start\":11587},{\"attributes\":{\"id\":\"formula_5\"},\"end\":11774,\"start\":11736},{\"attributes\":{\"id\":\"formula_6\"},\"end\":11933,\"start\":11896},{\"attributes\":{\"id\":\"formula_7\"},\"end\":13885,\"start\":13858},{\"attributes\":{\"id\":\"formula_8\"},\"end\":14424,\"start\":14390},{\"attributes\":{\"id\":\"formula_9\"},\"end\":15010,\"start\":14930},{\"attributes\":{\"id\":\"formula_10\"},\"end\":15115,\"start\":15010},{\"attributes\":{\"id\":\"formula_11\"},\"end\":15399,\"start\":15322},{\"attributes\":{\"id\":\"formula_12\"},\"end\":15660,\"start\":15568},{\"attributes\":{\"id\":\"formula_13\"},\"end\":16975,\"start\":16953},{\"attributes\":{\"id\":\"formula_14\"},\"end\":17518,\"start\":17356},{\"attributes\":{\"id\":\"formula_15\"},\"end\":17772,\"start\":17680},{\"attributes\":{\"id\":\"formula_16\"},\"end\":17918,\"start\":17901},{\"attributes\":{\"id\":\"formula_17\"},\"end\":18044,\"start\":18006},{\"attributes\":{\"id\":\"formula_18\"},\"end\":18547,\"start\":18487},{\"attributes\":{\"id\":\"formula_19\"},\"end\":18703,\"start\":18638},{\"attributes\":{\"id\":\"formula_20\"},\"end\":19035,\"start\":18875},{\"attributes\":{\"id\":\"formula_21\"},\"end\":20181,\"start\":20145},{\"attributes\":{\"id\":\"formula_22\"},\"end\":21427,\"start\":21366},{\"attributes\":{\"id\":\"formula_23\"},\"end\":21551,\"start\":21521},{\"attributes\":{\"id\":\"formula_25\"},\"end\":39931,\"start\":39876},{\"attributes\":{\"id\":\"formula_26\"},\"end\":40051,\"start\":39983},{\"attributes\":{\"id\":\"formula_28\"},\"end\":40162,\"start\":40093},{\"attributes\":{\"id\":\"formula_29\"},\"end\":40283,\"start\":40208}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":26838,\"start\":26831},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":29109,\"start\":29102},{\"end\":30671,\"start\":30664},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":33050,\"start\":33043},{\"end\":33894,\"start\":33887}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2685,\"start\":2673},{\"attributes\":{\"n\":\"2\"},\"end\":9323,\"start\":9305},{\"attributes\":{\"n\":\"3\"},\"end\":9931,\"start\":9920},{\"attributes\":{\"n\":\"4\"},\"end\":12337,\"start\":12326},{\"attributes\":{\"n\":\"4.1\"},\"end\":12615,\"start\":12594},{\"attributes\":{\"n\":\"4.2\"},\"end\":15733,\"start\":15719},{\"attributes\":{\"n\":\"4.2.1\"},\"end\":15903,\"start\":15884},{\"attributes\":{\"n\":\"4.2.2\"},\"end\":18202,\"start\":18164},{\"attributes\":{\"n\":\"4.2.3\"},\"end\":20212,\"start\":20183},{\"attributes\":{\"n\":\"4.3\"},\"end\":21565,\"start\":21553},{\"attributes\":{\"n\":\"4.4\"},\"end\":22141,\"start\":22130},{\"attributes\":{\"n\":\"5\"},\"end\":26478,\"start\":26444},{\"attributes\":{\"n\":\"5.2\"},\"end\":28715,\"start\":28703},{\"attributes\":{\"n\":\"5.3\"},\"end\":29911,\"start\":29897},{\"attributes\":{\"n\":\"5.4\"},\"end\":31817,\"start\":31789},{\"attributes\":{\"n\":\"5.5\"},\"end\":33565,\"start\":33535},{\"end\":34075,\"start\":34067},{\"attributes\":{\"n\":\"5.6\"},\"end\":34246,\"start\":34236},{\"attributes\":{\"n\":\"6\"},\"end\":35174,\"start\":35162},{\"attributes\":{\"n\":\"6.1\"},\"end\":35433,\"start\":35397},{\"attributes\":{\"n\":\"6.2\"},\"end\":37053,\"start\":37016},{\"attributes\":{\"n\":\"7\"},\"end\":38333,\"start\":38323},{\"end\":39053,\"start\":38984},{\"end\":41385,\"start\":41375},{\"end\":41478,\"start\":41468},{\"end\":41518,\"start\":41504},{\"end\":42155,\"start\":42145},{\"end\":42215,\"start\":42205},{\"end\":42861,\"start\":42858},{\"end\":43846,\"start\":43837},{\"end\":44151,\"start\":44142},{\"end\":45233,\"start\":45224}]", "table": "[{\"end\":43678,\"start\":43600},{\"end\":43835,\"start\":43757},{\"end\":44140,\"start\":43876},{\"end\":45222,\"start\":44260},{\"end\":46282,\"start\":45279}]", "figure_caption": "[{\"end\":41466,\"start\":41387},{\"end\":41502,\"start\":41480},{\"end\":41854,\"start\":41520},{\"end\":42143,\"start\":41857},{\"end\":42203,\"start\":42157},{\"end\":42398,\"start\":42217},{\"end\":42780,\"start\":42401},{\"end\":42856,\"start\":42783},{\"end\":43100,\"start\":42862},{\"end\":43347,\"start\":43103},{\"end\":43600,\"start\":43350},{\"end\":43757,\"start\":43681},{\"end\":43876,\"start\":43848},{\"end\":44260,\"start\":44153},{\"end\":45279,\"start\":45235},{\"end\":46360,\"start\":46285}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":4690,\"start\":4682},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":4825,\"start\":4817},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":5305,\"start\":5297},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":5992,\"start\":5984},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":15880,\"start\":15872},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":16780,\"start\":16772},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":19934,\"start\":19926},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":20872,\"start\":20864},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":33760,\"start\":33740},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":34488,\"start\":34480},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":34789,\"start\":34781},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":34805,\"start\":34797}]", "bib_author_first_name": "[{\"end\":46633,\"start\":46624},{\"end\":46656,\"start\":46647},{\"end\":47032,\"start\":47026},{\"end\":47047,\"start\":47040},{\"end\":47063,\"start\":47054},{\"end\":47078,\"start\":47072},{\"end\":47093,\"start\":47085},{\"end\":47330,\"start\":47324},{\"end\":47345,\"start\":47341},{\"end\":47371,\"start\":47357},{\"end\":47555,\"start\":47551},{\"end\":47581,\"start\":47567},{\"end\":47743,\"start\":47737},{\"end\":47887,\"start\":47883},{\"end\":47903,\"start\":47898},{\"end\":47921,\"start\":47917},{\"end\":48187,\"start\":48183},{\"end\":48201,\"start\":48195},{\"end\":48219,\"start\":48208},{\"end\":48228,\"start\":48224},{\"end\":48441,\"start\":48437},{\"end\":48454,\"start\":48448},{\"end\":48464,\"start\":48461},{\"end\":48478,\"start\":48471},{\"end\":48487,\"start\":48484},{\"end\":48771,\"start\":48767},{\"end\":48794,\"start\":48788},{\"end\":48797,\"start\":48795},{\"end\":48813,\"start\":48807},{\"end\":48826,\"start\":48819},{\"end\":49090,\"start\":49082},{\"end\":49102,\"start\":49098},{\"end\":49120,\"start\":49114},{\"end\":49345,\"start\":49339},{\"end\":49358,\"start\":49350},{\"end\":49370,\"start\":49365},{\"end\":49389,\"start\":49378},{\"end\":49543,\"start\":49536},{\"end\":49558,\"start\":49552},{\"end\":49560,\"start\":49559},{\"end\":49913,\"start\":49908},{\"end\":50117,\"start\":50109},{\"end\":50126,\"start\":50122},{\"end\":50138,\"start\":50133},{\"end\":50148,\"start\":50145},{\"end\":50161,\"start\":50153},{\"end\":50173,\"start\":50169},{\"end\":50409,\"start\":50401},{\"end\":50418,\"start\":50414},{\"end\":50432,\"start\":50425},{\"end\":50447,\"start\":50440},{\"end\":50456,\"start\":50453},{\"end\":50469,\"start\":50461},{\"end\":51133,\"start\":51128},{\"end\":51147,\"start\":51143},{\"end\":51161,\"start\":51157},{\"end\":51178,\"start\":51167},{\"end\":51194,\"start\":51188},{\"end\":51210,\"start\":51203},{\"end\":51550,\"start\":51542},{\"end\":51565,\"start\":51558},{\"end\":51576,\"start\":51571},{\"end\":51586,\"start\":51584},{\"end\":51600,\"start\":51596},{\"end\":51607,\"start\":51601},{\"end\":51836,\"start\":51832},{\"end\":51842,\"start\":51841},{\"end\":52168,\"start\":52162},{\"end\":52179,\"start\":52175},{\"end\":52192,\"start\":52185},{\"end\":52208,\"start\":52204},{\"end\":52476,\"start\":52469},{\"end\":52796,\"start\":52795},{\"end\":52812,\"start\":52807},{\"end\":52930,\"start\":52929},{\"end\":52944,\"start\":52941},{\"end\":53201,\"start\":53195},{\"end\":53215,\"start\":53209},{\"end\":53227,\"start\":53222},{\"end\":53440,\"start\":53434},{\"end\":53461,\"start\":53451},{\"end\":53482,\"start\":53476},{\"end\":53495,\"start\":53491},{\"end\":53510,\"start\":53504},{\"end\":53793,\"start\":53785},{\"end\":53803,\"start\":53798},{\"end\":53993,\"start\":53988},{\"end\":54002,\"start\":54001},{\"end\":54021,\"start\":54020},{\"end\":54035,\"start\":54031},{\"end\":54274,\"start\":54268},{\"end\":54287,\"start\":54283},{\"end\":54300,\"start\":54296},{\"end\":54536,\"start\":54534},{\"end\":54552,\"start\":54542},{\"end\":54566,\"start\":54561},{\"end\":54732,\"start\":54725},{\"end\":54741,\"start\":54737},{\"end\":54750,\"start\":54747},{\"end\":54761,\"start\":54758},{\"end\":54773,\"start\":54768},{\"end\":54990,\"start\":54983},{\"end\":55000,\"start\":54995},{\"end\":55011,\"start\":55007},{\"end\":55024,\"start\":55017},{\"end\":55036,\"start\":55031},{\"end\":55269,\"start\":55262},{\"end\":55279,\"start\":55274},{\"end\":55293,\"start\":55286},{\"end\":55304,\"start\":55300},{\"end\":55313,\"start\":55310},{\"end\":55325,\"start\":55320},{\"end\":55562,\"start\":55555},{\"end\":55572,\"start\":55567},{\"end\":55586,\"start\":55579},{\"end\":55597,\"start\":55593},{\"end\":55606,\"start\":55603},{\"end\":55618,\"start\":55613},{\"end\":55795,\"start\":55790},{\"end\":55813,\"start\":55805},{\"end\":55816,\"start\":55814},{\"end\":55827,\"start\":55822},{\"end\":55829,\"start\":55828},{\"end\":55845,\"start\":55840},{\"end\":55863,\"start\":55855},{\"end\":56237,\"start\":56232},{\"end\":56257,\"start\":56247},{\"end\":56463,\"start\":56458},{\"end\":56484,\"start\":56478},{\"end\":56501,\"start\":56493},{\"end\":56516,\"start\":56512},{\"end\":56537,\"start\":56528},{\"end\":56838,\"start\":56829},{\"end\":56856,\"start\":56847},{\"end\":56876,\"start\":56868},{\"end\":56893,\"start\":56885},{\"end\":57159,\"start\":57148},{\"end\":57173,\"start\":57168},{\"end\":57406,\"start\":57396},{\"end\":57420,\"start\":57415},{\"end\":57576,\"start\":57573},{\"end\":57589,\"start\":57583},{\"end\":57610,\"start\":57599},{\"end\":57627,\"start\":57620},{\"end\":57640,\"start\":57633},{\"end\":57950,\"start\":57942},{\"end\":57962,\"start\":57957},{\"end\":57965,\"start\":57963},{\"end\":57976,\"start\":57970},{\"end\":57992,\"start\":57981},{\"end\":58222,\"start\":58215},{\"end\":58236,\"start\":58231},{\"end\":58245,\"start\":58242},{\"end\":58254,\"start\":58250},{\"end\":58458,\"start\":58452},{\"end\":58487,\"start\":58483},{\"end\":58684,\"start\":58676},{\"end\":58690,\"start\":58689},{\"end\":59012,\"start\":59005},{\"end\":59025,\"start\":59018},{\"end\":59037,\"start\":59033},{\"end\":59311,\"start\":59309},{\"end\":59334,\"start\":59329},{\"end\":59343,\"start\":59340},{\"end\":59357,\"start\":59351},{\"end\":59609,\"start\":59606},{\"end\":59622,\"start\":59616},{\"end\":59636,\"start\":59629},{\"end\":59819,\"start\":59814},{\"end\":59834,\"start\":59826},{\"end\":59843,\"start\":59839},{\"end\":59854,\"start\":59850},{\"end\":59869,\"start\":59861},{\"end\":60062,\"start\":60057},{\"end\":60075,\"start\":60069},{\"end\":60083,\"start\":60081},{\"end\":60099,\"start\":60091},{\"end\":60108,\"start\":60104},{\"end\":60121,\"start\":60113},{\"end\":60328,\"start\":60327},{\"end\":60343,\"start\":60338},{\"end\":60345,\"start\":60344},{\"end\":60362,\"start\":60354},{\"end\":60381,\"start\":60372},{\"end\":60664,\"start\":60658},{\"end\":60677,\"start\":60671},{\"end\":60690,\"start\":60684},{\"end\":60704,\"start\":60697},{\"end\":60889,\"start\":60883},{\"end\":60903,\"start\":60897},{\"end\":60914,\"start\":60910},{\"end\":60927,\"start\":60921},{\"end\":60940,\"start\":60933},{\"end\":60954,\"start\":60946},{\"end\":61361,\"start\":61355},{\"end\":61373,\"start\":61369},{\"end\":61385,\"start\":61380},{\"end\":61395,\"start\":61391},{\"end\":61407,\"start\":61401},{\"end\":61636,\"start\":61634},{\"end\":61648,\"start\":61644},{\"end\":61659,\"start\":61654},{\"end\":61672,\"start\":61664},{\"end\":61683,\"start\":61677},{\"end\":61693,\"start\":61689}]", "bib_author_last_name": "[{\"end\":46645,\"start\":46634},{\"end\":46665,\"start\":46657},{\"end\":47038,\"start\":47033},{\"end\":47052,\"start\":47048},{\"end\":47070,\"start\":47064},{\"end\":47083,\"start\":47079},{\"end\":47100,\"start\":47094},{\"end\":47339,\"start\":47331},{\"end\":47355,\"start\":47346},{\"end\":47377,\"start\":47372},{\"end\":47565,\"start\":47556},{\"end\":47587,\"start\":47582},{\"end\":47750,\"start\":47744},{\"end\":47896,\"start\":47888},{\"end\":47915,\"start\":47904},{\"end\":47928,\"start\":47922},{\"end\":48193,\"start\":48188},{\"end\":48206,\"start\":48202},{\"end\":48222,\"start\":48220},{\"end\":48237,\"start\":48229},{\"end\":48446,\"start\":48442},{\"end\":48459,\"start\":48455},{\"end\":48469,\"start\":48465},{\"end\":48482,\"start\":48479},{\"end\":48492,\"start\":48488},{\"end\":48786,\"start\":48772},{\"end\":48805,\"start\":48798},{\"end\":48817,\"start\":48814},{\"end\":48831,\"start\":48827},{\"end\":48840,\"start\":48833},{\"end\":49096,\"start\":49091},{\"end\":49112,\"start\":49103},{\"end\":49128,\"start\":49121},{\"end\":49348,\"start\":49346},{\"end\":49363,\"start\":49359},{\"end\":49376,\"start\":49371},{\"end\":49392,\"start\":49390},{\"end\":49550,\"start\":49544},{\"end\":49568,\"start\":49561},{\"end\":49921,\"start\":49914},{\"end\":50120,\"start\":50118},{\"end\":50131,\"start\":50127},{\"end\":50143,\"start\":50139},{\"end\":50151,\"start\":50149},{\"end\":50167,\"start\":50162},{\"end\":50178,\"start\":50174},{\"end\":50412,\"start\":50410},{\"end\":50423,\"start\":50419},{\"end\":50438,\"start\":50433},{\"end\":50451,\"start\":50448},{\"end\":50459,\"start\":50457},{\"end\":50474,\"start\":50470},{\"end\":51141,\"start\":51134},{\"end\":51155,\"start\":51148},{\"end\":51165,\"start\":51162},{\"end\":51186,\"start\":51179},{\"end\":51201,\"start\":51195},{\"end\":51220,\"start\":51211},{\"end\":51556,\"start\":51551},{\"end\":51569,\"start\":51566},{\"end\":51582,\"start\":51577},{\"end\":51594,\"start\":51587},{\"end\":51615,\"start\":51608},{\"end\":51839,\"start\":51837},{\"end\":51845,\"start\":51843},{\"end\":52173,\"start\":52169},{\"end\":52183,\"start\":52180},{\"end\":52202,\"start\":52193},{\"end\":52219,\"start\":52209},{\"end\":52483,\"start\":52477},{\"end\":52805,\"start\":52797},{\"end\":52819,\"start\":52813},{\"end\":52823,\"start\":52821},{\"end\":52939,\"start\":52931},{\"end\":52951,\"start\":52945},{\"end\":52960,\"start\":52953},{\"end\":53207,\"start\":53202},{\"end\":53220,\"start\":53216},{\"end\":53236,\"start\":53228},{\"end\":53449,\"start\":53441},{\"end\":53474,\"start\":53462},{\"end\":53489,\"start\":53483},{\"end\":53502,\"start\":53496},{\"end\":53517,\"start\":53511},{\"end\":53796,\"start\":53794},{\"end\":53807,\"start\":53804},{\"end\":53999,\"start\":53994},{\"end\":54008,\"start\":54003},{\"end\":54018,\"start\":54010},{\"end\":54029,\"start\":54022},{\"end\":54043,\"start\":54036},{\"end\":54051,\"start\":54045},{\"end\":54281,\"start\":54275},{\"end\":54294,\"start\":54288},{\"end\":54311,\"start\":54301},{\"end\":54540,\"start\":54537},{\"end\":54559,\"start\":54553},{\"end\":54572,\"start\":54567},{\"end\":54735,\"start\":54733},{\"end\":54745,\"start\":54742},{\"end\":54756,\"start\":54751},{\"end\":54766,\"start\":54762},{\"end\":54777,\"start\":54774},{\"end\":54993,\"start\":54991},{\"end\":55005,\"start\":55001},{\"end\":55015,\"start\":55012},{\"end\":55029,\"start\":55025},{\"end\":55040,\"start\":55037},{\"end\":55272,\"start\":55270},{\"end\":55284,\"start\":55280},{\"end\":55298,\"start\":55294},{\"end\":55308,\"start\":55305},{\"end\":55318,\"start\":55314},{\"end\":55329,\"start\":55326},{\"end\":55565,\"start\":55563},{\"end\":55577,\"start\":55573},{\"end\":55591,\"start\":55587},{\"end\":55601,\"start\":55598},{\"end\":55611,\"start\":55607},{\"end\":55622,\"start\":55619},{\"end\":55803,\"start\":55796},{\"end\":55820,\"start\":55817},{\"end\":55838,\"start\":55830},{\"end\":55853,\"start\":55846},{\"end\":55867,\"start\":55864},{\"end\":56245,\"start\":56238},{\"end\":56264,\"start\":56258},{\"end\":56476,\"start\":56464},{\"end\":56491,\"start\":56485},{\"end\":56510,\"start\":56502},{\"end\":56526,\"start\":56517},{\"end\":56546,\"start\":56538},{\"end\":56845,\"start\":56839},{\"end\":56866,\"start\":56857},{\"end\":56883,\"start\":56877},{\"end\":56900,\"start\":56894},{\"end\":57166,\"start\":57160},{\"end\":57179,\"start\":57174},{\"end\":57413,\"start\":57407},{\"end\":57426,\"start\":57421},{\"end\":57581,\"start\":57577},{\"end\":57597,\"start\":57590},{\"end\":57618,\"start\":57611},{\"end\":57631,\"start\":57628},{\"end\":57645,\"start\":57641},{\"end\":57955,\"start\":57951},{\"end\":57968,\"start\":57966},{\"end\":57979,\"start\":57977},{\"end\":57995,\"start\":57993},{\"end\":58229,\"start\":58223},{\"end\":58240,\"start\":58237},{\"end\":58248,\"start\":58246},{\"end\":58259,\"start\":58255},{\"end\":58465,\"start\":58459},{\"end\":58481,\"start\":58467},{\"end\":58493,\"start\":58488},{\"end\":58504,\"start\":58495},{\"end\":58687,\"start\":58685},{\"end\":58696,\"start\":58691},{\"end\":58710,\"start\":58698},{\"end\":59016,\"start\":59013},{\"end\":59031,\"start\":59026},{\"end\":59044,\"start\":59038},{\"end\":59327,\"start\":59312},{\"end\":59338,\"start\":59335},{\"end\":59349,\"start\":59344},{\"end\":59362,\"start\":59358},{\"end\":59366,\"start\":59364},{\"end\":59614,\"start\":59610},{\"end\":59627,\"start\":59623},{\"end\":59642,\"start\":59637},{\"end\":59824,\"start\":59820},{\"end\":59837,\"start\":59835},{\"end\":59848,\"start\":59844},{\"end\":59859,\"start\":59855},{\"end\":59874,\"start\":59870},{\"end\":60067,\"start\":60063},{\"end\":60079,\"start\":60076},{\"end\":60089,\"start\":60084},{\"end\":60102,\"start\":60100},{\"end\":60111,\"start\":60109},{\"end\":60126,\"start\":60122},{\"end\":60336,\"start\":60329},{\"end\":60352,\"start\":60346},{\"end\":60370,\"start\":60363},{\"end\":60390,\"start\":60382},{\"end\":60396,\"start\":60392},{\"end\":60669,\"start\":60665},{\"end\":60682,\"start\":60678},{\"end\":60695,\"start\":60691},{\"end\":60709,\"start\":60705},{\"end\":60895,\"start\":60890},{\"end\":60908,\"start\":60904},{\"end\":60919,\"start\":60915},{\"end\":60931,\"start\":60928},{\"end\":60944,\"start\":60941},{\"end\":60957,\"start\":60955},{\"end\":61367,\"start\":61362},{\"end\":61378,\"start\":61374},{\"end\":61389,\"start\":61386},{\"end\":61399,\"start\":61396},{\"end\":61412,\"start\":61408},{\"end\":61642,\"start\":61637},{\"end\":61652,\"start\":61649},{\"end\":61662,\"start\":61660},{\"end\":61675,\"start\":61673},{\"end\":61687,\"start\":61684},{\"end\":61696,\"start\":61694}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":206742345},\"end\":46959,\"start\":46515},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":196194314},\"end\":47273,\"start\":46961},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":207930222},\"end\":47507,\"start\":47275},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":52898806},\"end\":47694,\"start\":47509},{\"attributes\":{\"id\":\"b4\"},\"end\":47881,\"start\":47696},{\"attributes\":{\"id\":\"b5\"},\"end\":48181,\"start\":47883},{\"attributes\":{\"id\":\"b6\"},\"end\":48435,\"start\":48183},{\"attributes\":{\"id\":\"b7\"},\"end\":48765,\"start\":48437},{\"attributes\":{\"doi\":\"arXiv:1804.00891\",\"id\":\"b8\"},\"end\":49080,\"start\":48767},{\"attributes\":{\"id\":\"b9\"},\"end\":49278,\"start\":49082},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":108328651},\"end\":49534,\"start\":49280},{\"attributes\":{\"id\":\"b11\"},\"end\":49843,\"start\":49536},{\"attributes\":{\"id\":\"b12\"},\"end\":50026,\"start\":49845},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":211043589},\"end\":50367,\"start\":50028},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":13907106},\"end\":50791,\"start\":50369},{\"attributes\":{\"id\":\"b15\"},\"end\":50997,\"start\":50793},{\"attributes\":{\"id\":\"b16\"},\"end\":51464,\"start\":50999},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":48353154},\"end\":51807,\"start\":51466},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":44060508},\"end\":52085,\"start\":51809},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":52190376},\"end\":52388,\"start\":52087},{\"attributes\":{\"id\":\"b20\"},\"end\":52749,\"start\":52390},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":6628106},\"end\":52927,\"start\":52751},{\"attributes\":{\"doi\":\"arXiv:1312.6114\",\"id\":\"b22\"},\"end\":53136,\"start\":52929},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":58370896},\"end\":53391,\"start\":53138},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":6451908},\"end\":53720,\"start\":53393},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":13480063},\"end\":53932,\"start\":53722},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":3361310},\"end\":54201,\"start\":53934},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":5071936},\"end\":54486,\"start\":54203},{\"attributes\":{\"id\":\"b28\"},\"end\":54680,\"start\":54488},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":174800708},\"end\":54923,\"start\":54682},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":202789109},\"end\":55202,\"start\":54925},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":221191218},\"end\":55495,\"start\":55204},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":221191218},\"end\":55788,\"start\":55497},{\"attributes\":{\"doi\":\"arXiv:1901.06033\",\"id\":\"b33\"},\"end\":56189,\"start\":55790},{\"attributes\":{\"id\":\"b34\",\"matched_paper_id\":219792493},\"end\":56383,\"start\":56191},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":221218530},\"end\":56748,\"start\":56385},{\"attributes\":{\"id\":\"b36\"},\"end\":57083,\"start\":56750},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":25418227},\"end\":57317,\"start\":57085},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":47016889},\"end\":57571,\"start\":57319},{\"attributes\":{\"doi\":\"arXiv:2101.04562\",\"id\":\"b39\"},\"end\":57888,\"start\":57573},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":4753193},\"end\":58139,\"start\":57890},{\"attributes\":{\"id\":\"b41\"},\"end\":58409,\"start\":58141},{\"attributes\":{\"id\":\"b42\"},\"end\":58626,\"start\":58411},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":1805048},\"end\":58889,\"start\":58628},{\"attributes\":{\"id\":\"b44\"},\"end\":59217,\"start\":58891},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":208268313},\"end\":59551,\"start\":59219},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":4833213},\"end\":59774,\"start\":59553},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":150380651},\"end\":60011,\"start\":59776},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":220347145},\"end\":60280,\"start\":60013},{\"attributes\":{\"id\":\"b49\"},\"end\":60613,\"start\":60282},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":222291105},\"end\":60846,\"start\":60615},{\"attributes\":{\"doi\":\"arXiv:2105.08908\",\"id\":\"b51\",\"matched_paper_id\":234778182},\"end\":61312,\"start\":60848},{\"attributes\":{\"id\":\"b52\",\"matched_paper_id\":233241168},\"end\":61547,\"start\":61314},{\"attributes\":{\"doi\":\"arXiv:2006.11011\",\"id\":\"b53\"},\"end\":61926,\"start\":61549}]", "bib_title": "[{\"end\":46622,\"start\":46515},{\"end\":47024,\"start\":46961},{\"end\":47322,\"start\":47275},{\"end\":47549,\"start\":47509},{\"end\":49337,\"start\":49280},{\"end\":50107,\"start\":50028},{\"end\":50399,\"start\":50369},{\"end\":51540,\"start\":51466},{\"end\":51830,\"start\":51809},{\"end\":52160,\"start\":52087},{\"end\":52793,\"start\":52751},{\"end\":53193,\"start\":53138},{\"end\":53432,\"start\":53393},{\"end\":53783,\"start\":53722},{\"end\":53986,\"start\":53934},{\"end\":54266,\"start\":54203},{\"end\":54723,\"start\":54682},{\"end\":54981,\"start\":54925},{\"end\":55260,\"start\":55204},{\"end\":55553,\"start\":55497},{\"end\":56230,\"start\":56191},{\"end\":56456,\"start\":56385},{\"end\":57146,\"start\":57085},{\"end\":57394,\"start\":57319},{\"end\":57940,\"start\":57890},{\"end\":58450,\"start\":58411},{\"end\":58674,\"start\":58628},{\"end\":59307,\"start\":59219},{\"end\":59604,\"start\":59553},{\"end\":59812,\"start\":59776},{\"end\":60055,\"start\":60013},{\"end\":60656,\"start\":60615},{\"end\":60881,\"start\":60848},{\"end\":61353,\"start\":61314}]", "bib_author": "[{\"end\":46647,\"start\":46624},{\"end\":46667,\"start\":46647},{\"end\":47040,\"start\":47026},{\"end\":47054,\"start\":47040},{\"end\":47072,\"start\":47054},{\"end\":47085,\"start\":47072},{\"end\":47102,\"start\":47085},{\"end\":47341,\"start\":47324},{\"end\":47357,\"start\":47341},{\"end\":47379,\"start\":47357},{\"end\":47567,\"start\":47551},{\"end\":47589,\"start\":47567},{\"end\":47752,\"start\":47737},{\"end\":47898,\"start\":47883},{\"end\":47917,\"start\":47898},{\"end\":47930,\"start\":47917},{\"end\":48195,\"start\":48183},{\"end\":48208,\"start\":48195},{\"end\":48224,\"start\":48208},{\"end\":48239,\"start\":48224},{\"end\":48448,\"start\":48437},{\"end\":48461,\"start\":48448},{\"end\":48471,\"start\":48461},{\"end\":48484,\"start\":48471},{\"end\":48494,\"start\":48484},{\"end\":48788,\"start\":48767},{\"end\":48807,\"start\":48788},{\"end\":48819,\"start\":48807},{\"end\":48833,\"start\":48819},{\"end\":48842,\"start\":48833},{\"end\":49098,\"start\":49082},{\"end\":49114,\"start\":49098},{\"end\":49130,\"start\":49114},{\"end\":49350,\"start\":49339},{\"end\":49365,\"start\":49350},{\"end\":49378,\"start\":49365},{\"end\":49394,\"start\":49378},{\"end\":49552,\"start\":49536},{\"end\":49570,\"start\":49552},{\"end\":49923,\"start\":49908},{\"end\":50122,\"start\":50109},{\"end\":50133,\"start\":50122},{\"end\":50145,\"start\":50133},{\"end\":50153,\"start\":50145},{\"end\":50169,\"start\":50153},{\"end\":50180,\"start\":50169},{\"end\":50414,\"start\":50401},{\"end\":50425,\"start\":50414},{\"end\":50440,\"start\":50425},{\"end\":50453,\"start\":50440},{\"end\":50461,\"start\":50453},{\"end\":50476,\"start\":50461},{\"end\":51143,\"start\":51128},{\"end\":51157,\"start\":51143},{\"end\":51167,\"start\":51157},{\"end\":51188,\"start\":51167},{\"end\":51203,\"start\":51188},{\"end\":51222,\"start\":51203},{\"end\":51558,\"start\":51542},{\"end\":51571,\"start\":51558},{\"end\":51584,\"start\":51571},{\"end\":51596,\"start\":51584},{\"end\":51617,\"start\":51596},{\"end\":51841,\"start\":51832},{\"end\":51847,\"start\":51841},{\"end\":52175,\"start\":52162},{\"end\":52185,\"start\":52175},{\"end\":52204,\"start\":52185},{\"end\":52221,\"start\":52204},{\"end\":52485,\"start\":52469},{\"end\":52807,\"start\":52795},{\"end\":52821,\"start\":52807},{\"end\":52825,\"start\":52821},{\"end\":52941,\"start\":52929},{\"end\":52953,\"start\":52941},{\"end\":52962,\"start\":52953},{\"end\":53209,\"start\":53195},{\"end\":53222,\"start\":53209},{\"end\":53238,\"start\":53222},{\"end\":53451,\"start\":53434},{\"end\":53476,\"start\":53451},{\"end\":53491,\"start\":53476},{\"end\":53504,\"start\":53491},{\"end\":53519,\"start\":53504},{\"end\":53798,\"start\":53785},{\"end\":53809,\"start\":53798},{\"end\":54001,\"start\":53988},{\"end\":54010,\"start\":54001},{\"end\":54020,\"start\":54010},{\"end\":54031,\"start\":54020},{\"end\":54045,\"start\":54031},{\"end\":54053,\"start\":54045},{\"end\":54283,\"start\":54268},{\"end\":54296,\"start\":54283},{\"end\":54313,\"start\":54296},{\"end\":54542,\"start\":54534},{\"end\":54561,\"start\":54542},{\"end\":54574,\"start\":54561},{\"end\":54737,\"start\":54725},{\"end\":54747,\"start\":54737},{\"end\":54758,\"start\":54747},{\"end\":54768,\"start\":54758},{\"end\":54779,\"start\":54768},{\"end\":54995,\"start\":54983},{\"end\":55007,\"start\":54995},{\"end\":55017,\"start\":55007},{\"end\":55031,\"start\":55017},{\"end\":55042,\"start\":55031},{\"end\":55274,\"start\":55262},{\"end\":55286,\"start\":55274},{\"end\":55300,\"start\":55286},{\"end\":55310,\"start\":55300},{\"end\":55320,\"start\":55310},{\"end\":55331,\"start\":55320},{\"end\":55567,\"start\":55555},{\"end\":55579,\"start\":55567},{\"end\":55593,\"start\":55579},{\"end\":55603,\"start\":55593},{\"end\":55613,\"start\":55603},{\"end\":55624,\"start\":55613},{\"end\":55805,\"start\":55790},{\"end\":55822,\"start\":55805},{\"end\":55840,\"start\":55822},{\"end\":55855,\"start\":55840},{\"end\":55869,\"start\":55855},{\"end\":56247,\"start\":56232},{\"end\":56266,\"start\":56247},{\"end\":56478,\"start\":56458},{\"end\":56493,\"start\":56478},{\"end\":56512,\"start\":56493},{\"end\":56528,\"start\":56512},{\"end\":56548,\"start\":56528},{\"end\":56847,\"start\":56829},{\"end\":56868,\"start\":56847},{\"end\":56885,\"start\":56868},{\"end\":56902,\"start\":56885},{\"end\":57168,\"start\":57148},{\"end\":57181,\"start\":57168},{\"end\":57415,\"start\":57396},{\"end\":57428,\"start\":57415},{\"end\":57583,\"start\":57573},{\"end\":57599,\"start\":57583},{\"end\":57620,\"start\":57599},{\"end\":57633,\"start\":57620},{\"end\":57647,\"start\":57633},{\"end\":57957,\"start\":57942},{\"end\":57970,\"start\":57957},{\"end\":57981,\"start\":57970},{\"end\":57997,\"start\":57981},{\"end\":58231,\"start\":58215},{\"end\":58242,\"start\":58231},{\"end\":58250,\"start\":58242},{\"end\":58261,\"start\":58250},{\"end\":58467,\"start\":58452},{\"end\":58483,\"start\":58467},{\"end\":58495,\"start\":58483},{\"end\":58506,\"start\":58495},{\"end\":58689,\"start\":58676},{\"end\":58698,\"start\":58689},{\"end\":58712,\"start\":58698},{\"end\":59018,\"start\":59005},{\"end\":59033,\"start\":59018},{\"end\":59046,\"start\":59033},{\"end\":59329,\"start\":59309},{\"end\":59340,\"start\":59329},{\"end\":59351,\"start\":59340},{\"end\":59364,\"start\":59351},{\"end\":59368,\"start\":59364},{\"end\":59616,\"start\":59606},{\"end\":59629,\"start\":59616},{\"end\":59644,\"start\":59629},{\"end\":59826,\"start\":59814},{\"end\":59839,\"start\":59826},{\"end\":59850,\"start\":59839},{\"end\":59861,\"start\":59850},{\"end\":59876,\"start\":59861},{\"end\":60069,\"start\":60057},{\"end\":60081,\"start\":60069},{\"end\":60091,\"start\":60081},{\"end\":60104,\"start\":60091},{\"end\":60113,\"start\":60104},{\"end\":60128,\"start\":60113},{\"end\":60338,\"start\":60327},{\"end\":60354,\"start\":60338},{\"end\":60372,\"start\":60354},{\"end\":60392,\"start\":60372},{\"end\":60398,\"start\":60392},{\"end\":60671,\"start\":60658},{\"end\":60684,\"start\":60671},{\"end\":60697,\"start\":60684},{\"end\":60711,\"start\":60697},{\"end\":60897,\"start\":60883},{\"end\":60910,\"start\":60897},{\"end\":60921,\"start\":60910},{\"end\":60933,\"start\":60921},{\"end\":60946,\"start\":60933},{\"end\":60959,\"start\":60946},{\"end\":61369,\"start\":61355},{\"end\":61380,\"start\":61369},{\"end\":61391,\"start\":61380},{\"end\":61401,\"start\":61391},{\"end\":61414,\"start\":61401},{\"end\":61644,\"start\":61634},{\"end\":61654,\"start\":61644},{\"end\":61664,\"start\":61654},{\"end\":61677,\"start\":61664},{\"end\":61689,\"start\":61677},{\"end\":61698,\"start\":61689}]", "bib_venue": "[{\"end\":46718,\"start\":46667},{\"end\":47108,\"start\":47102},{\"end\":47383,\"start\":47379},{\"end\":47593,\"start\":47589},{\"end\":47735,\"start\":47696},{\"end\":48005,\"start\":47930},{\"end\":48297,\"start\":48239},{\"end\":48588,\"start\":48494},{\"end\":48898,\"start\":48858},{\"end\":49168,\"start\":49130},{\"end\":49398,\"start\":49394},{\"end\":49673,\"start\":49570},{\"end\":49906,\"start\":49845},{\"end\":50185,\"start\":50180},{\"end\":50542,\"start\":50476},{\"end\":50873,\"start\":50793},{\"end\":51126,\"start\":50999},{\"end\":51624,\"start\":51617},{\"end\":51884,\"start\":51847},{\"end\":52224,\"start\":52221},{\"end\":52467,\"start\":52390},{\"end\":52829,\"start\":52825},{\"end\":53008,\"start\":52977},{\"end\":53246,\"start\":53238},{\"end\":53536,\"start\":53519},{\"end\":53815,\"start\":53809},{\"end\":54056,\"start\":54053},{\"end\":54326,\"start\":54313},{\"end\":54532,\"start\":54488},{\"end\":54789,\"start\":54779},{\"end\":55049,\"start\":55042},{\"end\":55337,\"start\":55331},{\"end\":55630,\"start\":55624},{\"end\":55964,\"start\":55885},{\"end\":56273,\"start\":56266},{\"end\":56554,\"start\":56548},{\"end\":56827,\"start\":56750},{\"end\":57188,\"start\":57181},{\"end\":57432,\"start\":57428},{\"end\":57704,\"start\":57663},{\"end\":58001,\"start\":57997},{\"end\":58213,\"start\":58141},{\"end\":58510,\"start\":58506},{\"end\":58747,\"start\":58712},{\"end\":59003,\"start\":58891},{\"end\":59372,\"start\":59368},{\"end\":59650,\"start\":59644},{\"end\":59881,\"start\":59876},{\"end\":60133,\"start\":60128},{\"end\":60325,\"start\":60282},{\"end\":60718,\"start\":60711},{\"end\":61055,\"start\":60975},{\"end\":61417,\"start\":61414},{\"end\":61632,\"start\":61549},{\"end\":50595,\"start\":50544},{\"end\":51916,\"start\":51886}]"}}}, "year": 2023, "month": 12, "day": 17}