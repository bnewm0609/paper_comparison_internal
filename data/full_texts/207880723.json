{"id": 207880723, "updated": "2023-10-06 22:01:58.472", "metadata": {"title": "Energy Efficient Federated Learning Over Wireless Communication Networks", "authors": "[{\"first\":\"Zhaohui\",\"last\":\"Yang\",\"middle\":[]},{\"first\":\"Mingzhe\",\"last\":\"Chen\",\"middle\":[]},{\"first\":\"Walid\",\"last\":\"Saad\",\"middle\":[]},{\"first\":\"Choong\",\"last\":\"Hong\",\"middle\":[\"Seon\"]},{\"first\":\"Mohammad\",\"last\":\"Shikh-Bahaei\",\"middle\":[]}]", "venue": "IEEE Transactions on Wireless Communications", "journal": "IEEE Transactions on Wireless Communications", "publication_date": {"year": 2019, "month": 11, "day": 6}, "abstract": "In this paper, the problem of energy efficient transmission and computation resource allocation for federated learning (FL) over wireless communication networks is investigated. In the considered model, each user exploits limited local computational resources to train a local FL model with its collected data and, then, sends the trained FL model parameters to a base station (BS) which aggregates the local FL model and broadcasts it back to all of the users. Since FL involves an exchange of a learning model between users and the BS, both computation and communication latencies are determined by the learning accuracy level. Meanwhile, due to the limited energy budget of the wireless users, both local computation energy and transmission energy must be considered during the FL process. This joint learning and communication problem is formulated as an optimization problem whose goal is to minimize a weighted sum of the completion time of FL, local computation energy, and transmission energy of all users, that captures the tradeoff of latency and energy consumption for FL. To solve this problem, an iterative algorithm is proposed where, at every step, closed-form solutions for time allocation, bandwidth allocation, power control, computation frequency, and learning accuracy are derived. For the special case that only minimizes the completion time, a bisection-based algorithm is proposed to obtain the optimal solution. Numerical results show that the proposed algorithms can reduce up to 25.6% delay and 37.6% energy consumption compared to conventional FL methods.", "fields_of_study": "[\"Computer Science\",\"Mathematics\"]", "external_ids": {"arxiv": "1911.02417", "mag": "3109847748", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/twc/YangCSHS21", "doi": "10.1109/twc.2020.3037554"}}, "content": {"source": {"pdf_hash": "c125df9f9ea11890f049477a265be00f13d7fad1", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/1911.02417v1.pdf\"]", "oa_url_match": true, "oa_info": {"license": null, "open_access_url": "http://arxiv.org/pdf/1911.02417", "status": "GREEN"}}, "grobid": {"id": "50fd0f0095718d8fb3a10bb8104304776d1d7e25", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/c125df9f9ea11890f049477a265be00f13d7fad1.txt", "contents": "\nEnergy Efficient Federated Learning Over Wireless Communication Networks\n6 Nov 2019\n\nZhaohui Yang yang.zhaohui@kcl.ac.uk \nDepartment of Engineering\nCentre for Telecommunications Research\nKing's College London\nWC2R 2LSUK, Emails\n\nMingzhe Chen mingzhec@princeton.edu. \nDepartment of Engineering\nCentre for Telecommunications Research\nKing's College London\nWC2R 2LSUK, Emails\n\nFellow, IEEEWalid Saad walids@vt.edu. \nDepartment of Engineering\nCentre for Telecommunications Research\nKing's College London\nWC2R 2LSUK, Emails\n\nChoong Seon \nDepartment of Engineering\nCentre for Telecommunications Research\nKing's College London\nWC2R 2LSUK, Emails\n\nSenior Member, IEEEHong \nDepartment of Engineering\nCentre for Telecommunications Research\nKing's College London\nWC2R 2LSUK, Emails\n\nSenior Member, IEEEMohammad Shikh-Bahaei \nDepartment of Engineering\nCentre for Telecommunications Research\nKing's College London\nWC2R 2LSUK, Emails\n\nZ Yang \nDepartment of Electrical and Computer Engineering\nUniversity of Hong Kong\n518172ShenzhenChina\n\nM Shikh-Bahaei \nDepartment of Electrical and Computer Engineering\nUniversity of Hong Kong\n518172ShenzhenChina\n\nW Saad Is With Wireless@vt \nDepartment of Computer Science and Engineering\nVirginia Tech\n24060BlacksburgVAUSA\n\nBradley \nDepartment of Computer Science and Engineering\nVirginia Tech\n24060BlacksburgVAUSA\n\nC Hong cshong@khu.ac.kr.2 \nKyung Hee University\nYongin-si17104Gyeonggi-doRep. of Korea\n\nEnergy Efficient Federated Learning Over Wireless Communication Networks\n6 Nov 20191 M. Chen is with the Electrical Engineering Department of Princeton University, NJ, 08544, USA, and also with the Chinese\nIn this paper, the problem of energy efficient transmission and computation resource allocation for federated learning (FL) over wireless communication networks is investigated. In the considered model, each user exploits limited local computational resources to train a local FL model with its collected data and, then, sends the trained FL model parameters to a base station (BS) which aggregates the local FL model and broadcasts it back to all of the users. Since FL involves an exchange of a learning model between users and the BS, both computation and communication latencies are determined by the learning accuracy level. Meanwhile, due to the limited energy budget of the wireless users, both local computation energy and transmission energy must be considered during the FL process. This joint learning and communication problem is formulated as an optimization problem whose goal is to minimize a weighted sum of the completion time of FL, local computation energy, and transmission energy of all users, that captures the tradeoff of latency and energy consumption for FL. To solve this problem, an iterative algorithm is proposed where, at every step, closed-form solutions for time allocation, bandwidth allocation, power control, computation frequency, and learning accuracy are derived. For the special case that only minimizes the completion time, a bisection-based algorithm is proposed to obtain the optimal solution. Numerical results show that the proposed algorithms can reduce up to 25.6% delay and 37.6% energy consumption compared to conventional FL methods.Index TermsFederated learning, resource allocation, energy efficiency.A preliminary version of this work was submitted to a conference publication [1].\n\nI. INTRODUCTION\n\nIn future wireless systems, due to privacy constraints and limited communication resources for data transmission, it is impractical for all wireless devices to transmit all of their collected data to a data center that can use the collected data to implement centralized machine learning algorithms for data analysis and inference [2]. To this end, distributed learning frameworks are needed, to enable the wireless devices to collaboratively build a shared learning model with training their collected data locally [3]- [9]. One of the most promising distributed learning algorithms is the emerging federated learning (FL) framework that will be adopted in future Internet of Things (IoT) systems [10]- [18]. In FL, wireless devices can cooperatively execute a learning task by only uploading local learning model parameters to the base station (BS) instead of sharing the entirety of their training data [19]. To implement FL over wireless networks, the wireless devices must transmit their local training results over wireless links [20], which can affect the performance of FL due to limited wireless resources (such as time and bandwidth).\n\nIn addition, the limited energy of wireless devices is a key challenge for deploying FL. Indeed, because of these resource constraints, it is necessary to optimize the energy efficiency for FL implementation.\n\nSome of the challenges of FL over wireless networks have been studied in [21]- [27]. To minimize latency, a broadband analog aggregation multi-access scheme was designed in [21] for FL by exploiting the waveform-superposition property of a multi-access channel. An FL training minimization problem was investigated in [22] for cell-free massive multiple-input multipleoutput (MIMO) systems. For FL with redundant data, an energy-aware user scheduling policy was proposed in [23] to maximize the average number of scheduled users. To improve the statistical learning performance for on-device distributed training, the authors in [24] developed a novel sparse and low-rank modeling approach. The work in [25] introduced an energy-efficient strategy for bandwidth allocation under learning performance constraints. However, the works in [21]- [25] focused on the delay/energy for wireless transmission without considering the delay/energy tradeoff between learning and transmission. Recently, the works in [26] and [27] considered both local learning and wireless transmission energy. In [26], we investigated the FL loss function minimization problem with taking into account packet errors over wireless links. However, this prior work ignored the computation delay of local FL model. The authors in [27] considered the sum learning and transmission energy minimization problem for FL, for a case in which all users transmit learning results to the BS. However, the solution in [27] requires all users to upload their learning model synchronously. Meanwhile, the work in [27] did not provide any convergence analysis for FL.\n\nThe main contribution of this paper is a novel energy efficient transmission and computation resource allocation scheme for FL over wireless communication networks. Our key contributions include:\n\n\u2022 We study the performance of FL algorithm over wireless communication networks for a scenario in which each user locally computes its FL model parameters under a given learning accuracy and the BS broadcasts the aggregated FL model parameters to all users. For the considered FL algorithm, we first derive the convergence rate. Then, we obtain the unique models of delay and energy consumption for FL.\n\n\u2022 Considering the tradeoff between delay and total energy for local computation and wireless transmission, we formulate a joint transmission and computation optimization problem aiming to minimize a weighted sum of the completion time and the total energy consumption.\n\nTo solve this problem, an iterative algorithm is proposed with low complexity. At each step of this algorithm, we derive new closed-form solutions for the time allocation, bandwidth allocation, power control, computation frequency, and learning accuracy.\n\n\u2022 To minimize the FL completion time for delay sensitive scenarios, we theoretically show that the completion time is a convex function of the learning accuracy. Based on the theoretical finding, we propose a bisection-based algorithm to obtain the optimal solution.\n\n\u2022 Simulation results show that the proposed scheme that jointly considers transmission and computation optimization can achieve up to 25.6% delay and 37.6% energy reduction compared to the conventional FL methods.\n\nThe rest of this paper is organized as follows. The system model and problem formulation are described in Section II. Section III provides the resource allocation for weighted time and energy minimization. The special case with only minimizing the completion time is given in Section IV. Simulation results are analyzed in Section V. Conclusions are drawn in Section VI.\n\n\nII. SYSTEM MODEL AND PROBLEM FORMULATION\n\nConsider a cellular network that consists of one BS serving a set K of K users, as shown in Fig. 1. Each user k has a local dataset D k with D k data samples. For each dataset D k = {x kl , y kl } D k l=1 , x kl \u2208 R d is an input vector of user k and y kl is its corresponding output 1 .\n\n\nA. FL Model\n\nIn this section, the considered FL algorithm that is implemented over wireless networks is introduced. Hereinafter, the FL model that is trained by each user's dataset is called the local FL model, while the FL model that is generated by the BS using local FL model parameter inputs from all users is called the global FL model.\n\nWe define a vector w to capture the parameters related to the global FL model. We introduce the loss function f (w, x kl , y kl ), that captures the FL performance over input vector x kl and output y kl . For different learning tasks, the loss function will be different. For example, f (w, x kl , y kl ) = 1 2 (x T kl w \u2212 y kl ) 2 for linear regression and f (w, x kl , y kl ) = \u2212 log(1 + exp(\u2212y kl x T kl w)) for logistic regression. Since the dataset of user k is D k , the total loss function of user k will be:\nF k (w, x k1 , y k1 , \u00b7 \u00b7 \u00b7 , x kD k , y kD k ) = 1 D k D k l=1 f (w, x kl , y kl ).(1)\nNote that function f (w, x kl , y kl ) is the loss function of user k with one data sample and function F k (w, x k1 , y k1 , \u00b7 \u00b7 \u00b7 , x kD k , y kD k ) is the total loss function of user k with the whole local dataset.\n\nIn the following, F k (w, x k1 , y k1 , \u00b7 \u00b7 \u00b7 , x kD k , y kD k ) is simplified by F k (w).\n\nIn order to deploy an FL algorithm, it is necessary to train the underlying model. Training is done in order to generate a unified FL model for all users without sharing any datasets. The FL training problem can be formulated as [2], [13], [19]:\nmin w F (w) K k=1 D k D F k (w) = 1 D K k=1 D k l=1 f (w, x kl , y kl ),(2)\nwhere D = K k=1 D k is the total data samples of all users. To solve problem (2), we adopt the FL algorithm of [19], which is summarized in Algorithm 1.\n\nIn Algorithm 1, we can see that, at every FL iteration, each user downloads the global FL model Each user k computes \u2207F k (w (n) ) and sends it to the BS. 4: The BS computes\n\u2207F (w (n) ) = 1 K K k=1 \u2207F k (w (n) ),(3)\nwhich is broadcast to all users. 5: parallel for user k \u2208 K The BS computes\nw (n+1) = w (n) + 1 K K k=1 h (n) k ,(4)\nand broadcasts the value to all users. 10: Set n = n + 1.\n\n11: until the accuracy \u01eb 0 of problem (2)  We define w (n) as the global FL parameter at a given iteration n. In practice, each user computes the local FL problem:\nmin h k \u2208R d G k (w (n) , h k ) F k (w (n) + h k ) \u2212 (\u2207F k (w (n) ) \u2212 \u03be\u2207F (w (n) )) T h k ,(5)\nby using the gradient method with a given accuracy. In problem (5), \u03be is a constant value. The solution h k in problem (5) represents the difference between the global FL parameter and local FL parameter for user k, i.e., w (n) + h k is the local FL parameter of user k at iteration n. Since it is hard to obtain the optimal solution of problem (5) using numerical methods, we obtain a feasible solution of problem (5) with some desired, target accuracy. The solution h (n) k of problem (5) at iteration n under a target accuracy \u03b7 is a point such that:\nG k (w (n) , h (n) k ) \u2212 G k (w (n) , h (n) * k ) \u2264 \u03b7(G k (w (n) , 0) \u2212 G k (w (n) , h (n) * k )),(6)\nwhere h (n) * k is the optimal solution of problem (5).\n\nIn Algorithm 1, the iterative method involves a number of global iterations (i.e., the value of n in Algorithm 1) to achieve a global accuracy \u01eb 0 for the global FL model. In other works, the solution w (n) of problem (2) with accuracy \u01eb 0 is a point such that\nF (w (n) ) \u2212 F (w * ) \u2264 \u01eb 0 (F (w (0) ) \u2212 F (w * )),(7)\nwhere w * is the actual optimal solution of problem (2).\n\nTo analyze the convergence rate of Algorithm 1, we make the following assumption on the loss function. Assume that F k (w) is L-Lipschitz continuous and \u03b3-strongly convex, i.e.,\n\u03b3I \u2207 2 F k (w) LI, \u2200k \u2208 K.(8)\nUnder assumption (8), we provide the following theorem about convergence rate of Algorithm 1,\n\nwhere each user solves its local FL problem with a given accuracy.\nTheorem 1: If we run Algorithm 1 with 0 < \u03be \u2264 \u03b3 L for n \u2265 a 1 \u2212 \u03b7 I 0(9)\niterations with a = 2L 2 \u03b3 2 \u03be ln 1 \u01eb 0 , we have F (w (n) ) \u2212 F (w * ) \u2264 \u01eb 0 (F (w (0) ) \u2212 F (w * )). Proof: See Appendix A.\n\nFrom Theorem 1, we observe that the number of global iterations n increases with the local accuracy. Theorem 1 can be used to derive the total time for performing the entire FL algorithm and transmission energy of all users. From Theorem 1, we can also see that the FL performance depends on parameters L, \u03b3, \u03be, \u01eb 0 and \u03b7. Note that the prior work in [28,Eq. (9)] only studied the number of iterations needed for FL convergence under the special case in which \u03b7 = 0.\n\nTheorem 1 provides a general convergence rate for FL with an arbitrary \u03b7.\n\n\nB. Computation and Transmission Model\n\nThe FL procedure between the users and their serving BS is shown in Fig. 2. user calculates its local FL parameters by using its local data set and the received global FL parameters.\n\n\n1) Local Computation:\n\nWe solve the local learning problem (5) by using the gradient method.\n\nIn particular, the gradient procedure in the (i + 1)-th iteration is given by:\nh (n),(i+1) k = h (n),(i) k \u2212 \u03b4\u2207G k (w (n) , h (n),(i) k ),(10)\nwhere \u03b4 is the step size, h (n),(i) k is the value of h k at the i-th local iteration with given vector\nw (n) , and \u2207G k (w (n) , h (n),(i) k ) is the gradient of function G k (w (n) , h k ) at point h k = h (n),(i) k . We set the initial solution h (n),(0) k = 0.\nNext, in Lemma 1, we derive a lower bound on the number of local iterations needed to achieve a local accuracy \u03b7 in (6).\nLemma 1: Let v = 2 (2\u2212L\u03b4)\u03b4\u03b3 .\nIf we set step \u03b4 < 2 L and run the gradient method i \u2265 v log 2 (1/\u03b7) (11) iterations at each user, we can solve local FL problem (5) with an accuracy \u03b7.\n\nProof: See Appendix B.\n\nThe lower bounded derived in (11) reflects the growing trend for the number of local iterations with respect to accuracy \u03b7. In the following, we use this lower bound to approximate the number of iterations needed for local computations by each user. Let f k be the computation capacity of user k, which is measured by the number of CPU cycles per second. The computation time at user k needed for data processing is:\n\u03c4 k = vC k D k log 2 (1/\u03b7) f k = A k log 2 (1/\u03b7) f k , \u2200k \u2208 K,(12)\nwhere C k (cycles/bit) is the number of CPU cycles required for computing one sample data at user k, v log 2 (1/\u03b7) is a lower bound for the number of local iterations for each user as given by (11), and A k = vC k D k . The approximated energy consumption of user k for calculating the gradients of the local loss function is:\nE C k = \u03baC k D k v log 2 (1/\u03b7)f 2 k = \u03baA k log 2 (1/\u03b7)f 2 k ,(13)\nwhere \u03ba is the effective switched capacitance that depends on the chip architecture [29].\n\n\n2) Wireless Transmission: After local computation, all users upload their local FL parameters\n\nto the BS via frequency domain multiple access (FDMA). FDMA is preferred over TDMA because TDMA requires synchronizations, while FDMA can be implemented in an asynchronous manner.\n\nThe achievable rate of user k can be given by:\nr k = b k log 2 1 + g k p k N 0 b k , \u2200k \u2208 K,(14)\nwhere b k is the bandwidth allocated to user k, p k is the transmit power of user k, g k is the channel gain between user k and the BS, and N 0 is the power spectral density of the Gaussian noise. Due to limited bandwidth of the system, we have:\nK k=1 b k \u2264 B, where B is the total bandwidth.\nIn this step, user k needs to upload the local FL parameters to the BS. Since the dimensions of the vector h (n) k are fixed for all users, the data size that each user needs to upload is constant, and can be denoted by s. To upload data of size s within transmission time t k , we must have:\nt k r k \u2265 s.\nTo transmit data of size s within a time duration t k , the wireless transmit energy of user k will be: Due to the high transmit power at the BS and the high bandwidth that can be used for data broadcasting, the downlink time is neglected compared to the uplink data transmission time. It can be observed that the local data D k is not accessed by the BS, so as to protect the privacy of users, as is required by FL.\nE T k = t k p k .\nAccording to the above FL model, the energy consumption of each user includes both local computing energy E C k and wireless transmission energy E T k . Given that the number of global iterations is I 0 in (9), the total energy consumption of all users that participate in FL will be:\nE = I 0 K k=1 (E C k + E T k ) = a 1 \u2212 \u03b7 K k=1 \u03baA k log 2 (1/\u03b7)f 2 k + t k p k .(15)\nHereinafter, the total time needed for completing the execution of the FL algorithm is called completion time. The completion time of each user includes the local computation time and transmission time, as shown in Fig. 3. Based on (9) and (12), the completion time T k of user k will be:\nT k = I 0 (\u03c4 k + t k ) = a 1 \u2212 \u03b7 A k log 2 (1/\u03b7) f k + t k .(16)\nLet T be the completion time for training the entire FL algorithm, which must satisfy:\nUser 1\nUser K\n\n\nUser 2\n\nComputing and Transmitting Downloading \nTime Frequency b 2 b K b 1 B \u03c4 2 t 2 \u03c4 1 t 1 t K \u03c4 K ComputationT \u2265 T k , \u2200k \u2208 K.(17)\nAccording to (15) and (17), there is a tradeoff between completion time T and total energy consumption E. For a small completion time T , each user may need to use a high computation capacity f k and a high transmission power p k , which leads to a high total energy E.\n\n\nC. Problem Formulation\n\nOur goal is to minimize the weighted sum of completion time and total energy consumption of all users. This energy efficient optimization problem can be posed as follows: min\nT,t,b,f ,p,\u03b7 \u03c1T + (1 \u2212 \u03c1) E,(18)s.t. a 1 \u2212 \u03b7 A k log 2 (1/\u03b7) f k + t k \u2264 T, \u2200k \u2208 K, (18a) t k b k log 2 1 + g k p k N 0 b k \u2265 s, \u2200k \u2208 K, (18b) K k=1 b k \u2264 B, (18c) 0 \u2264 f k \u2264 f max k , \u2200k \u2208 K, (18d) 0 \u2264 p k \u2264 p max k , \u2200k \u2208 K, (18e) 0 \u2264 \u03b7 \u2264 1,(18f)t k \u2265 0, b k \u2265 0, \u2200k \u2208 K, (18g) where t = [t 1 , \u00b7 \u00b7 \u00b7 , t K ] T , b = [b 1 , \u00b7 \u00b7 \u00b7 , b K ] T , f = [f 1 , \u00b7 \u00b7 \u00b7 , f K ] T , p = [p 1 , \u00b7 \u00b7 \u00b7 , p K ] T , f max k and p max k\nare respectively the maximum local computation capacity and maximum transmit power of user k, and \u03c1 \u2208 [0, 1] is a constant weight parameter. In the objective function (18), \u03c1 is used to characterize the tradeoff between the completion time T and the total energy consumption E.\n\n\nConstraint (18a) indicates that the execution time of the local tasks and transmission time for all\n\nusers should not exceed the completion time for the whole FL algorithm. The data transmission constraint is given by (18b), while the bandwidth constraint is given by (18c). Constraints (18d) and (18e) respectively represent the maximum local computation capacity and transmit power limits of all users. The local accuracy constraint is given by (18f).\n\n\nIII. RESOURCE ALLOCATION FOR WEIGHTED TIME AND ENERGY MINIMIZATION\n\nFor the general weighted time and energy minimization problem (18), it is challenging to obtain the globally optimal solution due to nonconvexity. To overcome this challenge, an iterative algorithm with low complexity is proposed in this section.\n\n\nA. Iterative Algorithm\n\nThe proposed iterative algorithm mainly contains two steps in each iteration. To optimize\n(T, t, b, f , p, \u03b7) in problem (18), we first optimize (t, \u03b7) with fixed (T, b, f , p), then (T, b, f , p)\nis updated based on the obtained (t, \u03b7) in the previous step. The advantage of this iterative algorithm lies in that we can obtain the optimal solution of (t, \u03b7) or (T, b, f , p) in each step.\n\nIn the first step, given (T, b, f , p), problem (18) becomes:\nmin t,\u03b7 a 1 \u2212 \u03b7 K k=1 \u03baA k log 2 (1/\u03b7)f 2 k + t k p k ,(19)s.t. a 1 \u2212 \u03b7 A k log 2 (1/\u03b7) f k + t k \u2264 T, \u2200k \u2208 K, (19a) t k \u2265 t min k , \u2200k \u2208 K, (19b) 0 \u2264 \u03b7 \u2264 1,(19c)\nwhere\nt min k = s b k log 2 1 + g k p k N 0 b k , \u2200k \u2208 K.(20)\nThe optimal solution of (19) can be derived using the following theorem.\n\nTheorem 2: The optimal solution (t * , \u03b7 * ) of problem (19) satisfies:\nt * k = t min k , \u2200k \u2208 K,(21)\nand \u03b7 * is the optimal solution to: min\n\u03b7 \u03b1 1 log 2 (1/\u03b7) + \u03b1 2 1 \u2212 \u03b7 (22) s.t. \u03b7 min \u2264 \u03b7 \u2264 \u03b7 max ,(22a)\nwhere Algorithm 2 The Dinkelbach Method 1: Initialize \u03b6 = \u03b6 (0) > 0, iteration number n = 0, and set the accuracy \u01eb 3 .\n\n\n2: repeat\n\n3:\n\nCalculate the optimal \u03b7 * = \u03b1 1 (ln 2)\u03b6 (n) of problem (24). 4:\nUpdate \u03b6 (n+1) = \u03b1 1 log 2 (1/\u03b7 * )+\u03b1 2 1\u2212\u03b7 *\n\n5:\n\nSet n = n + 1.\n6: until |H(\u03b6 (n+1) )|/|H(\u03b6 (n) )| < \u01eb 3 . \u03b7 min = max k\u2208K \u03b7 min k , \u03b7 max = min k\u2208K \u03b7 max k ,(23)\u03b2 k (\u03b7 min k ) = \u03b2 k (\u03b7 max k ) = t min k , t min k \u2264 t max k , \u03b1 1 , \u03b1 2 and \u03b2 k (\u03b7) are defined in (C.2). Proof: See Appendix C.\nTheorem 2 shows that it is optimal to transmit with the minimum time for each user. Based on this finding, problem (19) is equivalent to the problem (22) with only one variable. Obviously, the objective function (22) has a fractional form, which is generally hard to solve. By using the parametric approach in [30], we consider the following problem,\nH(\u03b6) = min \u03b7 min \u2264\u03b7\u2264\u03b7 max \u03b1 1 log 2 (1/\u03b7) + \u03b1 2 \u2212 \u03b6(1 \u2212 \u03b7).(24)\nIt has been proved [30] that solving (22) is equivalent to finding the root of the nonlinear function H(\u03b6). Since (24) with fixed \u03b6 is convex, the optimal solution \u03b7 * can be obtained by setting the first-order derivative to zero, yielding the optimal solution: \u03b7 * = \u03b1 1 (ln 2)\u03b6 . Thus, problem (22) can be solved by using the Dinkelbach method in [30] (shown as Algorithm 2).\n\nIn the second step, given (t, \u03b7) calculated in the first step, problem (18) can be simplified as:\nmin T,b,f ,p \u03c1T + a(1 \u2212 \u03c1) 1 \u2212 \u03b7 K k=1 \u03baA k log 2 (1/\u03b7)f 2 k + t k p k ,(25)s.t. a 1 \u2212 \u03b7 A k log 2 (1/\u03b7) f k + t k \u2264 T, \u2200k \u2208 K,(25a)t k b k log 2 1 + g k p k N 0 b k \u2265 s, \u2200k \u2208 K, (25b) K k=1 b k \u2264 B,(25c)0 \u2264 p k \u2264 p max k , \u2200k \u2208 K,(25d)0 \u2264 f k \u2264 f max k , \u2200k \u2208 K.(25e)\nSince both objective function and constraints can be decoupled, problem (25) can be decoupled into two subproblems:\nmin T,f \u03c1T + a(1 \u2212 \u03c1)\u03ba log 2 (1/\u03b7) 1 \u2212 \u03b7 K k=1 A k f 2 k ,(26)s.t. a 1 \u2212 \u03b7 A k log 2 (1/\u03b7) f k + t k \u2264 T, \u2200k \u2208 K, (26a) 0 \u2264 f k \u2264 f max k , \u2200k \u2208 K,(26b)\nand\nmin b,p a(1 \u2212 \u03c1) 1 \u2212 \u03b7 K k=1 t k p k ,(27)s.t. t k b k log 2 1 + g k p k N 0 b k \u2265 s, \u2200k \u2208 K, (27a) K k=1 b k \u2264 B, (27b) 0 \u2264 p k \u2264 p max k , \u2200k \u2208 K.(27c)\nWe can solve (26) using the following theorem.\n\nTheorem 3: The optimal solution (T * , f * ) of problem (26) satisfies:\nT * = \uf8f1 \uf8f4 \uf8f2 \uf8f4 \uf8f3 T min if \u03c1 > \u03bb K k=1 2a 2 A 3 k (1\u2212\u03b7) log 2 2 (1/\u03b7) (T min (1\u2212\u03b7)\u2212at min k ) 3 T otherwise,(28)\nand\nf * k = aA k log 2 (1/\u03b7) T * (1 \u2212 \u03b7) \u2212 at k , \u2200k \u2208 K,(29)\nwhere\nT min = a 1 \u2212 \u03b7 max k\u2208K A k log 2 (1/\u03b7) f max k + t k ,(30)\u03bb = a(1 \u2212 \u03c1)\u03ba log 2 (1/\u03b7) 1 \u2212 \u03b7 ,(31)\nandT is the unique solution to\n\u03c1 \u2212 \u03bb K k=1 2a 2 A 3 k (1 \u2212 \u03b7) log 2 2 (1/\u03b7) (T (1 \u2212 \u03b7) \u2212 at min k ) 3 = 0.(32)\nProof: See Appendix D.\n\nTheorem 3 provides the optimal solution of problem (26) in closed-form, which greatly simplifies the complexity of solving (26). We solve problem (27) using the following theorem.\n\nTheorem 4: The optimal solution (b * , p * ) of problem (27) satisfies: With given (T (l) , b (l) , f (l) , p (l) ), obtain the optimal (t (l+1) , \u03b7 (l+1) ) of problem (19). 4: With given (t (l+1) , \u03b7 (l+1) ), obtain the optimal (T (l) , b (l) , f (l) , p (l) ) of problem (25).\nb * k = max{b k (\u00b5), b min k },(33)\n\n5:\n\nSet l = l + 1.\n\n6: until objective value (18a) converges and\np * k = N 0 b * k g k 2 s t k b * k \u2212 1 ,(34)where b min k = \u2212 (ln 2)s t k W \u2212 (ln 2)N 0 s g k p max k t k e \u2212 (ln 2)N 0 s g k p max k t k + (ln 2)N 0 s g k p max k ,(35)b k (\u00b5) is the solution to N 0 g k t k e (ln 2)s t k b k (\u00b5) \u2212 1 \u2212 (ln 2)s t k b k (\u00b5) e (ln 2)s t k b k (\u00b5) + \u00b5 = 0,(36)\nand \u00b5 satisfies\nK k=1 max{b k (\u00b5), b min k } = B.(37)\nProof: See Appendix E.\n\nBy iteratively solving problem (19) and problem (25), the algorithm that solves problem (18) is given in Algorithm 3. Since the optimal solution of problem (19) or (25) \n\n\nB. Complexity Analysis\n\nTo solve the general energy efficient resource allocation problem (18) by using Algorithm 3, the major complexity in each step lies in solving problem (19) and problem (25). To solve problem (19), the major complexity lies in obtaining the optimal \u03b7 * according to Theorem 2, which involves complexity O(K log 2(1/\u01eb 1 )) with accuracy \u01eb 1 by using the Dinkelbach method.\n\nTo solve problem (25), two subproblems (26) and (27)  It should be noted that Algorithm 3 is done at the BS side before executing the FL scheme in Algorithm 1. To implement Algorithm 3, the BS needs to gather the information of g k , p max k , f max k , C k , D k , and s, which can be uploaded by all users before the FL process. Due to small data size, the transmission delay of these information can be neglected. The BS broadcasts the obtained solution to all users. Since the BS has high computation capacity, the latency of implementing Algorithm 3 at the BS will not affect the latency of the FL process.\n\n\nIV. RESOURCE ALLOCATION FOR FL COMPLETION TIME MINIMIZATION\n\nIn this section, we consider the special case of delay sensitive scenarios, where the completion time of the FL algorithm is more important than the energy consumption. Although the completion time minimization problem (18) with \u03c1 = 1 is still nonconvex due to constraints (18a)-(18b), we show that the globally optimal solution can be obtained by using the bisection method.\n\n\nA. Optimal Resource Allocation\n\nWe define (T * , t * , b * , f * , p * , \u03b7 * ) as the optimal solution of problem (18) with \u03c1 = 1. Proof: See Appendix F.\n\nAccording to Lemma 2, we can use the bisection method to obtain the optimal solution of problem (18) with \u03c1 = 1.\n\nWith a fixed T , we still need to check whether there exists a feasible solution satisfying constraints (18a)-(18g). From constraints (18a) and (18c), we can see that it is always efficient to utilize the maximum computation capacity, i.e., f * k = f max k , \u2200k \u2208 K. From (18b) and (18d),\n\nwe can see that minimizing the completion time occurs when p * k = p max k , \u2200k \u2208 K. Substituting the maximum computation capacity and maximum transmission power into (18), the completion time minimization problem becomes:\nmin T,t,b,\u03b7 T (38) s.t. t k \u2264 (1 \u2212 \u03b7)T a + A k log 2 \u03b7 f max k , \u2200k \u2208 K, (38a) s t k \u2264 b k log 2 1 + g k p max k N 0 b k , \u2200k \u2208 K, (38b) K k=1 b k \u2264 B,(38c)0 \u2264 \u03b7 \u2264 1, (38d) t k \u2265 0, b k \u2265 0, \u2200k \u2208 K.(38e)\nNext, we provide the sufficient and necessary condition for the feasibility of set (38a)-(38e).\n\n\nLemma 3: With a fixed T , set (38a)-(38e) is nonempty if an only if\nB \u2265 min 0\u2264\u03b7\u22641 K k=1 u k (v k (\u03b7)),(39)\nwhere\nu k (\u03b7) = \u2212 (ln 2)\u03b7 W \u2212 (ln 2)N 0 \u03b7 g k p max k e \u2212 (ln 2)N 0 \u03b7 g k p max k + (ln 2)N 0 \u03b7 g k p max k ,(40)\nand v k (\u03b7) = s\n(1\u2212\u03b7)T a + A k log 2 \u03b7 f max k . (41) Proof: See Appendix G.\nTo effectively solve (39) in Lemma 3, we provide the following lemma. Lemma 4 implies that the optimization problem in (39) is a convex problem, which can be effectively solved. By finding the optimal solution of (39), the sufficient and necessary condition for the feasibility of set (38a)-(38e) can be simplified using the following theorem.\n\n\nTheorem 5: Set (38a)-(38e) is nonempty if and only if\nB \u2265 K k=1 u k (v k (\u03b7 * )),(42)\nwhere \u03b7 * is the unique solution to K k=1 u \u2032 k (v k (\u03b7 * ))v \u2032 k (\u03b7 * ) = 0. Check the feasibility condition (42).\n\n\n5:\n\nIf set (38a)-(38e) has a feasible solution, set T max = T . Otherwise, set T = T min . 6: until (T max \u2212 T min )/T max \u2264 \u01eb 5 .\n\nTheorem 5 directly follows from Lemmas 3 and 4. Due to the convexity of function u k (v k (\u03b7)),\nK k=1 u \u2032 k (v k (\u03b7 * ))v \u2032 k (\u03b7 * )\nis an increasing function of \u03b7 * . As a result, the unique solution of \u03b7 * to K k=1 u \u2032 k (v k (\u03b7 * ))v \u2032 k (\u03b7 * ) = 0 can be effectively solved via the bisection method. Based on Theorem 5, the algorithm for obtaining the minimal completion time is summarized in Algorithm 4. Theorem 5 shows that the optimal FL accuracy level \u03b7 * meets the first-order\ncondition K k=1 u \u2032 k (v k (\u03b7 * ))v \u2032 k (\u03b7 * ) = 0, i.e.\n, the optimal \u03b7 * should not be too small or too large for FL. This is because, for small \u03b7, the local computation time (number of iterations) becomes high as shown in Lemma 1. For large \u03b7, the transmission time is long due to the fact that a large number of global iterations is required as shown in Theorem 1.\n\n\nB. Complexity Analysis\n\nThe major complexity of Algorithm 4 in each iteration lies in checking the feasibility condition (42). To check the inequality in (42), the optimal \u03b7 * needs to be obtained by using the bisection method, which involves the complexity of O(K log 2 (1/\u01eb 6 )) with accuracy \u01eb 6 . As a result, the total complexity of Algorithm 4 is O(K log 2 (1/\u01eb 5 ) log 2 (1/\u01eb 6 )), where \u01eb 5 is the accuracy of the bisection method used in the outer layer. The complexity of Algorithm 4 is low since O(K log 2 (1/\u01eb 5 ) log 2 (1/\u01eb 6 )) grows linearly with the total number of users. Similar to Algorithm 3 in Section III, Algorithm 4 is done at the BS side before executing the FL scheme in Algorithm 1, which will not affect the latency of the FL process.\n\n\nV. NUMERICAL RESULTS\n\nFor our simulations, we deploy K = 50 users uniformly in a square area of size 500 m \u00d7 500 m with the BS located at its center. The path loss model is 128.1 + 37.6 log 10 d (d is in km) and the standard deviation of shadow fading is 8 dB. In addition, the noise power spectral density is N 0 = \u2212174 dBm/Hz. The user training data D k of each user k follows uniform We compare the proposed FL scheme with the FL FDMA scheme with equal bandwidth b 1 = \u00b7 \u00b7 \u00b7 = b K (labelled as 'EB-FDMA'), the FL FDMA scheme with fixed local accuracy \u03b7 = 1/2 (labelled as 'FE-FDMA'), and the FL TDMA scheme in [27] (labelled as 'TDMA'). The completion time versus transmit data size of each user is depicted in Fig. 5. Clearly, the completion time monotonically increases with transmit data size. This is because the transmission time increases with the increase of the transmit data size, which consequently increases the completion time. It can be shown that the increase speed of completion time for TDMA is faster than that for FDMA. This is because FDMA is more spectrum efficient than TDMA. Fig. 6 shows the value u k (v k (\u03b7)) in (39) versus \u03b7. From this figure, it is found that u k (v k (\u03b7))\n\n\nA. Completion Time Minimization\n\nis always a convex function, which verifies the theoretical findings in Lemma 4. It is also found that the optimal \u03b7 decreases with the increase of transmit data size. This is because small \u03b7 leads to small number of global iterations, which can decrease the transmission time especially for large transmit data size. In Fig. 8, we show the weighted completion time and total energy versus transmit data size of each user. We can clearly see that the weighted completion time and total energy increases with the data size for all schemes since more data needs to be transmitted and more transmit energy must be used by the users for wireless transmission. Moreover, the slope of increase of the weighted completion time and total energy versus the data size of the proposed scheme is slower than that of the TDMA scheme. In Fig. 9, we present the weighted completion time and total energy versus maximum computation capacity of each user. Fig. 9 shows that the weighted completion time and total energy of all schemes decreases with maximum computation capacity of each user. This is because higher computation capacity decreases the local computation time, yielding a lower completion time. From Fig. 9, we can also see that the weighted completion time and total energy remains stable for high maximum computation capacity of each user. This is due to the fact that the local computation time is decreased with the increase of computation capacity, while the local computation energy increases when the computation capacity increases. As a result, to minimize the weighted completion time and total energy, it is optimal to choose a proper computation capacity for each user, which should not be too low nor too high. Moreover, from Fig. 9, we can see that the performance of the proposed FL scheme outperforms the conventional TDMA scheme. This is because users in FDMA can simultaneously transmit data. APPENDIX A PROOF OF THEOREM 1 Before proving Theorem 1, the following lemma is provided.\n\n\nB. Weighted Completion Time and Total Energy Minimization\n\nLemma 5: Under the assumption of F k (w) given in (8), the following conditions hold:\n1 L \u2207F k (w (n) + h (n) ) \u2212 \u2207F k (w (n) ) 2 \u2264 (\u2207F k (w (n) + h (n) ) \u2212 \u2207F k (w (n) )) T h (n) \u2264 1 \u03b3 \u2207F k (w (n) + h (n) ) \u2212 \u2207F k (w (n) ) 2 , (A.1)\nand\n\u2207F (w) 2 \u2265 \u03b3(F (w) \u2212 F (w * )). (A.2)\nProof: From the definition of second-order derivative, there always exists a w such that\n(\u2207F k (w (n) + h (n) ) \u2212 \u2207F k (w (n) )) = \u2207 2 F k (w)h (n) . (A.3)\nCombining (8)  For the optimal solution w * of F (w * ), we always have \u2207F (w * = 0. Combining (2) and (A.1), we also have \u03b3I \u2207 2 F (w), which indicates that\n\u2207F (w) \u2212 \u2207F (w * ) \u2265 \u03b3 w \u2212 w * , (A.4) F (w) \u2265 F (w * ) + \u2207F (w) T (w * \u2212 w) + \u03b3 2 w * \u2212 w 2 . (A.5)\nAs a result, we have:\n\u2207F (w) 2 = \u2207F (w) \u2212 \u2207F (w * ) 2 (A.4) \u2265 \u03b3 \u2207F (w) \u2212 \u2207F (w * ) w \u2212 w * \u2265 \u03b3(\u2207F (w) \u2212 \u2207F (w * )) T (w \u2212 w * ) = \u03b3\u2207F (w) T (w \u2212 w * ) (A.5) \u2265 \u03b3(F (w) \u2212 F (w * )), (A.6)\nwhich proves (A.2).\n\nFor the optimal solution of problem (5), the first-order derivative condition always holds, i.e.,\n\u2207F k (w (n) + h (n) * k ) \u2212 \u2207F k (w (n) ) + \u03be\u2207F (w (n) ) = 0. (A.7)\nWe are new ready to prove Theorem 1. With the above inequalities and equalities, we have:\nF (w (n+1) ) (4),(8) \u2264 F (w (n) ) + 1 K K k=1 \u2207F (w (n) ) T h (n) k + L 2K 2 K k=1 h (n) k 2 (5) = F (w (n) ) + 1 K\u03be K k=1 G k (w (n) , h (n) k ) + \u2207F k (w (n) )h (n) k \u2212 F k (w (n) + h (n) k ) + L 2K 2 K k=1 h (n) k 2 (8) \u2264 F (w (n) ) + 1 K\u03be K k=1 G k (w (n) , h (n) k ) \u2212 F k (w (n) ) \u2212 \u03b3 2 h (n) k 2 + L 2K 2 K k=1 h (n) k 2 . (A.8)\nAccording to the triangle inequality and mean inequality, we have\n1 K K k=1 h (n) k 2 \u2264 1 K K k=1 h (n) k 2 \u2264 1 K K k=1 h (n) k 2 . (A.9)\nCombining (A.8) and (A.9) yields:\nF (w (n+1) ) \u2264 F (w (n) ) + 1 K\u03be K k=1 G k (w (n) , h (n) k ) \u2212 F k (w (n) ) \u2212 \u03b3 \u2212 L\u03be 2 h (n) k 2 (5) = F (w (n) ) + 1 K\u03be K k=1 G k (w (n) , h (n) k ) \u2212 G k (w (n) , h (n) * k ) \u2212 (G k (w (n) , 0) \u2212 G k (w (n) , h (n) * k )) \u2212 \u03b3 \u2212 L\u03be 2 h (n) k 2 (6) \u2264 F (w (n) ) \u2212 1 K\u03be K k=1 \u03b3 \u2212 L\u03be 2 h (n) k 2 + (1 \u2212 \u03b7)(G k (w (n) , 0) \u2212 G k (w (n) , h (n) * k )) (5) = F (w (n) ) \u2212 1 K\u03be K k=1 \u03b3 \u2212 L\u03be 2 h (n) k 2 + (1 \u2212 \u03b7)(F k (w (n) ) \u2212 F k (w (n) + h (n) * k ) + (\u2207F k (w (n) ) \u2212 \u03be\u2207F (w (n) )) T h (n) * k ) (A.7) = F (w (n) ) \u2212 1 K\u03be K k=1 \u03b3 \u2212 L\u03be 2 h (n) k 2 + (1 \u2212 \u03b7)(F k (w (n) ) \u2212 F k (w (n) + h (n) * k ) + \u2207F k (w (n) + h (n) * k ) T h (n) * k ) . (A.10)\nBased on (8), we can obtain:\nF k (w (n) ) \u2265 F k (w (n) + h (n) * k ) + \u2207F k (w (n) + h (n) * k ) T (\u2212h (n) * k ) + \u03b3 2 h (n) * k 2 . (A.11)\nApplying (A.11) to (A.10), we can obtain:\nF (w (n+1) ) \u2264 F (w (n) ) \u2212 1 K\u03be K k=1 \u03b3 \u2212 L\u03be 2 h (n) k 2 + (1 \u2212 \u03b7)\u03b3 2 h (n) * k 2 . (A.12)\nFrom (A.1), the following relationship is obtained:\nh (n) * k 2 \u2265 1 L 2 \u2207F k (w (n) + h (n) * k )) \u2212 \u2207F k (w (n) ) 2 . (A.13)\nFor the constant parameter \u03be, we choose \u03b3 \u2212 L\u03be > 0.\n\n(A.14)\n\nAccording to (A.14) and (A.12), we can obtain:\nF (w (n+1) )\u2264F (w (n) ) \u2212 (1 \u2212 \u03b7)\u03b3 2K\u03be K k=1 h (n) * k 2 (A.13) \u2264 F (w (n) ) \u2212 (1 \u2212 \u03b7)\u03b3 2KL 2 \u03be K k=1 \u2207F k (w (n) + h (n) * k ) \u2212 \u2207F k (w (n) ) 2 (A.7) = F (w (n) ) \u2212 (1 \u2212 \u03b7)\u03b3\u03be 2L 2 \u2207F (w (n) ) 2 (A.2) \u2264 F (w (n) ) \u2212 (1 \u2212 \u03b7)\u03b3 2 \u03be 2L 2 (F (w (n) ) \u2212 F (w * )). (A.15)\nBased on (A.15), we get:\nF (w (n+1) ) \u2212 F (w * )\u2264 1 \u2212 (1 \u2212 \u03b7)\u03b3 2 \u03be 2L 2 (F (w (n) ) \u2212 F (w * )) \u2264 1 \u2212 (1 \u2212 \u03b7)\u03b3 2 \u03be 2L 2 n+1 (F (w (0) ) \u2212 F (w * )) \u2264 exp \u2212(n + 1) (1 \u2212 \u03b7)\u03b3 2 \u03be 2L 2 (F (w (0) ) \u2212 F (w * )), (A.16)\nwhere the last inequality follows from the fact that\n1\u2212x \u2264 exp(\u2212x). To ensure that F (w (n+1) )\u2212 F (w * ) \u2264 \u01eb 0 (F (w (0) ) \u2212 F (w * )), we have (9). APPENDIX B PROOF OF LEMMA 1\nBased on (10), we have:\nG k (w (n) , h (n),(i+1) k ) (8) \u2264 G k (w (n) , h (n),(i) k ) \u2212 \u03b4 \u2207G k (w (n) , h (n),(i) k ) 2 + L\u03b4 2 2 \u2207G k (w (n) , h (n),(i) k ) 2 = G k (w (n) , h (n),(i) k ) \u2212 (2 \u2212 L\u03b4)\u03b4 2 \u2207G k (w (n) , h (n),(i) k ) 2 . (B.1)\nSimilar to (A.2), we can prove that:\n\u2207G k (w (n) , h k ) 2 \u2265 \u03b3(G k (w (n) , h k ) \u2212 G k (w (n) , h (n) * k )), (B.2) where h (n) * k\nis the optimal solution of problem (5). Based on (B.1) and (B.2), we have:\nG k (w (n) , h (n),(i+1) k ) \u2212 G k (w (n) , h (n) * k ) \u2264 G k (w (n) , h (n),(i) k ) \u2212 G k (w (n) , h (n) * k ) \u2212 (2 \u2212 L\u03b4)\u03b4\u03b3 2 (G k (w (n) , h (n),(i) k ) \u2212 G k (w (n) , h (n) * k )) \u2264 1 \u2212 (2 \u2212 L\u03b4)\u03b4\u03b3 2 i+1 (G k (w (n) , 0) \u2212 G k (w (n) , h (n) * k )) \u2264 exp \u2212(i + 1) (2 \u2212 L\u03b4)\u03b4\u03b3 2 (G k (w (n) , 0) \u2212 G k (w (n) , h (n) * k )), (B.3)\nwhere the last inequality follows from the fact that 1\u2212x \u2264 exp(\u2212x). To ensure that G k (w (n) , h\n(n),(i) k )\u2212 G k (w (n) , h (n) * k ) \u2264 \u03b7(G k (w (n) , 0) \u2212 G k (w (n) , h (n) * k APPENDIX C PROOF OF THEOREM 2\nAccording to (19), transmitting with minimal time is always energy efficient, i.e., the optimal time allocation is t * k = t min k . Substituting t * k = t min k into problem (19) yields:\nmin \u03b7 \u03b1 1 log 2 (1/\u03b7) + \u03b1 2 1 \u2212 \u03b7 (C.1) s.t. t min k \u2264 \u03b2 k (\u03b7), \u2200k \u2208 K, (C.1a) 0 \u2264 \u03b7 \u2264 1, (C.1b) where \u03b1 1 = a K k=1 \u03baA k f 2 k , \u03b1 2 = a K k=1 t min k p k , \u03b2 k (\u03b7) = (1 \u2212 \u03b7)T a + A k log 2 \u03b7 f max k . (C.2)\nFrom (C.2), it can be verified that \u03b2 k (\u03b7) is a concave function. Due to the concavity of \u03b2 k (\u03b7), constraints (C.1a) can be equivalently transformed to:\n\u03b7 min k \u2264 \u03b7 \u2264 \u03b7 max k , (C.3) where \u03b2 k (\u03b7 min k ) = \u03b2 k (\u03b7 max k ) = t min k and t min k \u2264 t max k . Since \u03b2 k (1) = 0, lim \u03b7\u21920+ \u03b2 k (\u03b7) = \u2212\u221e and t min k > 0, we always have 0 < t min k \u2264 t max k < 1.\nWith the help of (C.3), problem (C.1) can be simplified as (22).\n\n\nAPPENDIX D PROOF OF THEOREM 3\n\nAccording to (26), it is always efficient to utilize the minimal computation capacity f k . To minimize (26), the optimal f * k can be obtained from (26a), which gives:\nf * k = aA k log 2 (1/\u03b7) T (1 \u2212 \u03b7) \u2212 at k , \u2200k \u2208 K. (D.1)\nCombining (26b) and (D.1), the constraint about the completion time T is given by\nT \u2265 T min ,\nwhere T min is defined in (30).\n\nSubstituting (D.1) into problem (26) yields:\nmin T wT + \u03bb K k=1 A k aA k log 2 (1/\u03b7) T (1 \u2212 \u03b7) \u2212 at k 2 , (D.2) s.t. T \u2265 T min , (D.2a)\nwhere \u03bb is defined in (31). By checking the second-order derivative of objective function (D.2),\n\nwe can see that problem (D.2) is a convex function. Setting the first-order derivative to zero, we obtain:\nw \u2212 \u03bb K k=1 2a 2 A 3 k (1 \u2212 \u03b7) log 2 2 (1/\u03b7) (T (1 \u2212 \u03b7) \u2212 at min k ) 3 = 0. (D.3)\nThe left hand side of (D. \n, +\u221e) if w \u2212 \u03bb K k=1 2a 2 A 3 k (1\u2212\u03b7) log 2 2 (1/\u03b7) (T min (1\u2212\u03b7)\u2212at min k ) 3 < 0,\ni.e., in this case, the optimal T * of (D.2) is T min . Otherwise, the optimal T * of (D.2) is the unique solution to (D.3).\n\n\nAPPENDIX E PROOF OF THEOREM 4\n\nTo minimize K k=1 t k p k , transmit power p k needs to be minimized. To minimize p k from (27a), we have:\np * k = N 0 b k g k 2 s t k b k \u2212 1 . (E.1)\nThe first order and second order derivatives of p * k can be respectively given by\n\u2202p * k \u2202b k = N 0 g k e (ln 2)s t k b k \u2212 1 \u2212 (ln 2)s t k b k e (ln 2)s t k b k , (E.2)\nand Substituting (E.1) into problem (27), we can obtain:\n\u2202 2 p * k \u2202b 2 k = N 0 (ln 2) 2 s 2 g k t 2 k b 3 k e (ln 2)s t k b k \u2265 0. (E.3) From (E.3), we can see that \u2202p * k \u2202b k is an increasing function of b k . Since lim b k \u21920+ \u2202p * k \u2202b k = 0, we have \u2202p * k \u2202b k < 0 for 0 < b k < \u221e, i.e., p * k in (E.1)min b K k=1 N 0 t k b k g k 2 s b k t k \u2212 1 , (E.5) s.t. K k=1 b k \u2264 B, (E.5a) b k \u2265 b min k , \u2200k \u2208 K, (E.5b)\nAccording to (E.3), problem (E.5) is a convex function, which can be effectively solved by using the Karush-Kuhn-Tucker conditions. The Lagrange function of (E.5) is:\nL(b, \u00b5) = K k=1 N 0 t k b k g k 2 s b k t k \u2212 1 + \u00b5 K k=1 b k \u2212 B , (E.6)\nwhere \u00b5 is the Lagrange multiplier associated with constraint (E.5a). The first order derivative of L(b, \u00b5) with respect to b k is:\n\u2202L(b, \u00b5) \u2202b k = N 0 g k t k e (ln 2)s t k b k \u2212 1 \u2212 (ln 2)s t k b k e (ln 2)s t k b k + \u00b5. (E.7)\nWe define b k (\u00b5) as the unique solution to \u2202L(b,\u00b5) \u2202b k = 0. Given constraint (E.5b), the optimal b * k can be founded from (33). Since the objective function (E.5) is a decreasing function of b k , constrain (E.5a) always holds with equality for the optimal solution, which shows that the optimal Lagrange multiplier is obtained by solving (37).\n\nAPPENDIX F PROOF OF LEMMA 2\n\nAssume that problem (18) with \u03c1 = 1 and T =T < T * is feasible, and the feasible solution is (T ,t,b,f ,p,\u03b7). Then, the solution (T ,t,b,f ,p,\u03b7) is feasible with lower value of the objective function than solution (T * , t * , b * , f * , p * , \u03b7 * ), which contradicts the fact that (T * , t * , b * , f * , p * , \u03b7 * ) is the optimal solution.\n\nFor problem (18) with \u03c1 = 1 and T =T > T * , we can always construct a feasible solution (T , t * , b * , f * , p * , \u03b7 * ) to problem (18) with \u03c1 = 1 by checking all constraints.\n\nAPPENDIX G PROOF OF LEMMA 3\n\nTo prove this, we first define function y = x ln 1 + 1\n\nx , x > 0.\n\n(G.1)\n\nThen, we have y \u2032 = ln 1 + 1\nx \u2212 1 x + 1 , y \u2032\u2032 = \u2212 1 x(x + 1) 2 < 0. (G.2)\nAccording to (G.2), y \u2032 is a decreasing function. Since lim t i \u2192+\u221e y \u2032 = 0, we can obtain that y \u2032 > 0 for all 0 < x < +\u221e. As a result, y is an increasing function, i.e., the right hand side of (38b) is an increasing function of bandwidth b k .\n\nTo ensure that the maximum bandwidth constraint (38c) can be satisfied, the left hand side of (38b) should be as small as possible, i.e., t k should be as long as possible. Based on (38a), the optimal time allocation should be:\nt * k = (1 \u2212 \u03b7)T a + A k log 2 \u03b7 f max k , \u2200k \u2208 K. (G.3)\nSubstituting (G.3) into (38b), we can construct the following problem:\nmin b,\u03b7 K k=1 b k (G.4) s.t. v k (\u03b7) \u2264 b k log 2 1 + g k p max k N 0 b k , \u2200k \u2208 K, (G.4a) 0 \u2264 \u03b7 \u2264 1, (G.4b) b k \u2265 0, \u2200k \u2208 K, (G.4c)\nwhere v k (\u03b7) is defined in (41).\n\nWe can observe that set (38a)-(38e) is nonempty if an only if the optimal objective value of (G.4) is less than B. Since the right hand side of (38b) is an increasing function, (38b) should hold with equality for the optimal solution of problem (G.4). Setting (38b) with equality, problem (G.4) reduces to (39).\n\n\nAPPENDIX H PROOF OF LEMMA 4\n\nWe first prove that v k (\u03b7) is a convex function. To show this, we define: According to (41), we have: v k (\u03b7) = \u03c6(\u03d5 k (\u03b7)). Then, the second-order derivative of v k (\u03b7) can be given by:\n\u03c6(\u03b7) = s \u03b7 , 0 \u2264 \u03b7 \u2264 1,\nv \u2032\u2032 k (\u03b7) = \u03c6 \u2032\u2032 (\u03d5 k (\u03b7))(\u03d5 \u2032 k (\u03b7)) 2 + \u03c6 \u2032 (\u03d5 k (\u03b7))\u03d5 \u2032\u2032 k (\u03b7). , we can find that v \u2032\u2032 k (\u03b7) \u2265 0, i.e., v k (\u03b7) is a convex function. Then, we can show that u k (\u03b7) is an increasing and convex function. According to Appendix B, u k (\u03b7) is the inverse function of the right hand side of (38b). If we further define function: z k (\u03b7) = \u03b7 log 2 1 + g k p max k N 0 \u03b7 , \u03b7 \u2265 0, (H.6) u k (\u03b7) is the inverse function of z k (\u03b7), which gives u k (z k (\u03b7)) = \u03b7.\n\nAccording to (G.1) and(G.2) in Appendix B, function z k (\u03b7) is an increasing and concave function, i.e., z \u2032 k (\u03b7) \u2265 0 and z \u2032\u2032 k (\u03b7) \u2264 0. Since z k (\u03b7) is an increasing function, its inverse function u k (\u03b7) is also an increasing function.\n\nBased on the definition of concave function, for any \u03b7 1 \u2265 0, \u03b7 2 \u2265 0 and 0 \u2264 \u03b8 \u2264 1, we have:\nz k (\u03b8\u03b7 1 + (1 \u2212 \u03b8)\u03b7 2 ) \u2265 \u03b8z k (\u03b7 1 ) + (1 \u2212 \u03b8)z k (\u03b7 2 ).\n(H.7)\n\nApplying the increasing function u k (\u03b7) on both sides of (H.7) yields:\n\n\u03b8\u03b7 1 + (1 \u2212 \u03b8)\u03b7 2 \u2265 u k (\u03b8z k (\u03b7 1 ) + (1 \u2212 \u03b8)z k (\u03b7 2 )).\n\n(H.8) Denote\u03b7 1 = z k (\u03b7 1 ) and\u03b7 2 = z k (\u03b7 2 ), i.e., we have \u03b7 1 = u k (\u03b7 1 ) and \u03b7 2 = u k (\u03b7 2 ). Thus, (H.8)\n\ncan be rewritten as:\n\u03b8u k (\u03b7 1 ) + (1 \u2212 \u03b8)u k (\u03b7 1 ) \u2265 u k (\u03b8\u03b7 1 + (1 \u2212 \u03b8)\u03b7 2 ), (H.9)\nwhich indicates that u k (\u03b7) is a convex function. As a result, we have proven that u k (\u03b7) is an increasing and convex function, which shows:\nu \u2032 k (\u03b7) \u2265 0, u \u2032\u2032 k (\u03b7) \u2265 0. (H.10)\nTo show the convexity of u k (v k (\u03b7)), we have:\nu \u2032\u2032 k (v k (\u03b7)) = u \u2032\u2032 k (v k (\u03b7))(v \u2032 k (\u03b7)) 2 + u \u2032 k (v k (\u03b7))v \u2032\u2032 k (\u03b7) \u2265 0, (H.11)\naccording to v \u2032\u2032 k (\u03b7) \u2265 0 and (H.10). As a result, u k (v k (\u03b7)) is a convex function.\n\nFig. 1 .\n1Illustration of the considered model for FL over wireless communication networks.\n\nFig. 2 .\n2From this figure, the FL procedure contains three steps at each iteration: Local computation at each user (using several local iterations), local FL parameter transmission for each user, and result aggregation and broadcast at the BS. The local computation step is essentially the phase during which each k K The FL procedure between users and the BS.\n\n3 )\n3Information Broadcast: In this step, the BS aggregates the global prediction model parameters. The BS broadcasts the global prediction model parameters to all users in the downlink.\n\n\na feasible solution (T (0) , t (0) , b (0) , f (0) , p (0) , \u03b7 (0) ) of problem(18) and set l = 0.\n\n\nis obtained in each step, the objective value of problem (18) is nonincreasing in each step. Moreover, the objective value of problem (18) is lower bounded by zero. Thus, Algorithm 3 always converges to a local optimal solution.\n\n\nneed to be optimized. For subproblem(26), the complexity is O(K log 2 (1/\u01eb 2 )), where \u01eb 2 is the accuracy of solving (32) with the bisection method. For subproblem(27), the complexity is O(K log 2 (1/\u01eb 3 ) log 2 (1/\u01eb 4 )), where \u01eb 3 and \u01eb 4 are respectively the accuracy of solving (35) and (36). As a result, the total complexity of the proposed Algorithm 3 is O(L it SK), where L it is the number of iterations for iteratively optimizing (t, \u03b7) and(T, b, f , p), and S = log 2(1/\u01eb 1 ) + log 2(1/\u01eb 2 ) + log 2(1/\u01eb 3 ) log 2(1/\u01eb 4 ).The conventional successive convex approximation (SCA) method can be used to solve problem(18). The complexity of SCA method is O(L sca K 3 )[31, Pages 487, 569], where L sca is the total number of iterations for SCA method. Compared to SCA, the proposed Algorithm 3 grows linearly with the number of users K.\n\nLemma 2 :\n2Problem (18) with \u03c1 = 1 and T < T * does not have a feasible solution (i.e., it is infeasible), while problem (18) with \u03c1 = 1 and T > T * always has a feasible solution (i.e., it is feasible).\n\nLemma 4 :\n4In (40), u k (v k (\u03b7)) is a convex function. Proof: See Appendix H.\n\nFig. 4 .\n4Completion time versus maximum transmit power of each user with \u03c1 = 1. distribution [5, 10] Mbits and parameter C k is uniformly distributed in [10, 30] cycles/bit. The effective switched capacitance in local computation is \u03ba = 10 \u221228 . In Algorithm 1, we set \u03b3 = 2, L = 4, \u03be = 1/3, \u03b4 = 1/4, and \u01eb 0 = 10 \u22123 . Unless specified otherwise, we choose an equal maximum transmit power p GHz, a transmit data size s = 100 kbits, weight parameter \u03c1 = 0.5, and a bandwidth B = 20 MHz. All statistical results are averaged over 1000 independent runs.\n\nFig. 4 Fig. 5 .Fig. 6 .\n456shows how the completion time changes as the maximum transmit power of each user varies. We can see that the completion time of all schemes decreases with the maximum transmission power of each user. This is because a large maximum transmit power can decrease the transmission time between users and the BS. We can clearly see that the proposed FL scheme achieves the best performance among all schemes. This is because the proposed approach jointly optimizes bandwidth and local accuracy \u03b7, while the bandwidth is fixed in EB-FDMA and \u03b7 is not optimized in FE-FDMA. Compared to TDMA, the proposed approach can reduce the delay by up to 25.6% due to the following two reasons. First, each user can directly transmit result data to the BS after local computation in FDMA, while the wireless transmission should be performed after the local computation for all users in TDMA, which needs a longer time Completion time versus transmit data size of each user with \u03c1 = 1. The total bandwidth u k (v k (\u03b7)) in (39) versus the accuracy \u03b7. compared to FDMA. Second, the noise power for users in FDMA is lower than in TDMA since each user is allocated to part of the bandwidth and each user occupies the whole bandwidth in TDMA, which indicates the transmission time in TDMA is longer than in FDMA.\n\nFig. 7 .\n7Weighted completion time and total energy versus maximum transmit power of each user.\n\nFig. 7\n7shows the weighted completion time and total energy as function of the maximum transmit power of each user. In this figure, the EXH-FDMA scheme is an exhaustive search method that can find a near optimal solution of problem(18), which refers to the proposed iterative algorithm with 1000 initial starting points. There are 1000 solutions obtained by using EXH-FDMA, and the solution with the best objective value is treated as the near optimal solution. From this figure, we can observe that the weighted completion time and total energy decreases with the maximum transmit power of each user.Fig. 7also shows that the proposed FL scheme outperforms the EB-FDMA, FE-FDMA, and TDMA schemes. Moreover, the EXH-FDMA scheme achieves almost the same performance as the proposed FL scheme, which shows that the proposed approach achieves the optimum solution.\n\nFig. 8 .Fig. 9 .\n89Weighted completion time and total energy versus transmit data size of each user. Weighted completion time and total energy versus maximum computation capacity of each user.\n\nFig. 10 .\n10Total energy versus completion time.\n\nFig. 10\n10shows the tradeoff between total energy consumption and completion time. This figure is obtained by changing the values of parameter \u03c1. We can see that FDMA outperforms TDMA in terms of total energy consumption especially for low completion time. This is because FDMA enables users to simultaneously transmit data to the BS and the transmission time in FDMA is larger than that in TDMA, which results in energy saving compared to TDMA. In particular, with given the same completion time, the proposed FL can reduce energy of up to 33.3%, 50.2%, and 37.6% compared to EB-FDMA, FE-FDMA, and TDMA, respectively.VI. CONCLUSIONSIn this paper, we have investigated the problem of energy efficient transmission and computation resource allocation of FL over wireless communication networks. We have derived the time and energy consumption models for FL based on the convergence rate. With these models, we have formulated a joint learning and communication problem so as to minimize a linear combination of the completion time and the total energy. To solve this problem, we have proposed an iterative algorithm with low complexity, for which, at each iteration, we have derived closed-form solutions for transmission and computation resources. For the special case with only minimizing completion time, we have obtained the optimal solution by using the bisection method. Numerical results have shown that the proposed scheme outperforms conventional schemes in terms of completion time and total energy consumption, especially for small maximal transmission power and large transmit data size.\n\n\nand (A.3) yields (A.1).\n\n\nis a decreasing function of b k . Thus, maximum transmit power constraint p * k \u2264 p\n\n\nis obtained. parameters from the BS for local computing, while the BS periodically gathers the local FL model parameters from all users and sends the updated global FL model parameters back to all users.\n\n\nAlgorithm 4 Completion Time Minimization1: Initialize T min , T max , and the tolerance \u01eb 5 .2: repeat \n\n3: \n\nSet T = T min +Tmax \n\n2 \n\n. \n\n4: \n\n\n\n\n3) is an increasing function of T , which shows that (D.3) has a unique solution. Considering constraint (D.2a), (D.3) does not have solution in [T min\nFor simplicity, we consider an FL algorithm with a single output. In future work, our approach will be extended to the case with multiple outputs.\n\nDelay minimization for federated learning over wireless communication networks. Z Yang, M Chen, W Saad, C S Hong, M Shikh-Bahaei, submitted to Proc. IEEE Int. Conf. Commun. Z. Yang, M. Chen, W. Saad, C. S. Hong, and M. Shikh-Bahaei, \"Delay minimization for federated learning over wireless communication networks,\" submitted to Proc. IEEE Int. Conf. Commun., 2020.\n\nWhen edge meets learning: Adaptive control for resource-constrained distributed machine learning. S Wang, T Tuor, T Salonidis, K K Leung, C Makaya, T He, K Chan, IEEE Conf. Honolulu, HI, USAS. Wang, T. Tuor, T. Salonidis, K. K. Leung, C. Makaya, T. He, and K. Chan, \"When edge meets learning: Adaptive control for resource-constrained distributed machine learning,\" in IEEE Conf. Computer Commun., Honolulu, HI, USA, Apr. 2018, pp. 63-71.\n\nA vision of 6G wireless systems: Applications, trends, technologies, and open research problems. W Saad, M Bennis, M Chen, IEEE Network. to appearW. Saad, M. Bennis, and M. Chen, \"A vision of 6G wireless systems: Applications, trends, technologies, and open research problems,\" IEEE Network, to appear, 2019.\n\nWireless network intelligence at the edge. J Park, S Samarakoon, M Bennis, M Debbah, abs/1812.02858CoRR. J. Park, S. Samarakoon, M. Bennis, and M. Debbah, \"Wireless network intelligence at the edge,\" CoRR, vol. abs/1812.02858, 2018. [Online]. Available: http://arxiv.org/abs/1812.02858\n\nFederated echo state learning for minimizing breaks in presence in wireless virtual reality networks. M Chen, O Semiari, W Saad, X Liu, C Yin, IEEE Trans. Wireless Commun. to appearM. Chen, O. Semiari, W. Saad, X. Liu, and C. Yin, \"Federated echo state learning for minimizing breaks in presence in wireless virtual reality networks,\" IEEE Trans. Wireless Commun., to appear, 2019.\n\nDistributed strategic learning for wireless engineers. H Tembine, CRC PressH. Tembine, Distributed strategic learning for wireless engineers. CRC Press, 2018.\n\nDistributed federated learning for ultra-reliable low-latency vehicular communications. S Samarakoon, M Bennis, W Saad, M Debbah, arXiv:1807.08127arXiv preprintS. Samarakoon, M. Bennis, W. Saad, and M. Debbah, \"Distributed federated learning for ultra-reliable low-latency vehicular communications,\" arXiv preprint arXiv:1807.08127, 2018.\n\nMachine learning in the air. D G\u00fcnd\u00fcz, P Kerret, N D Sidiropoulos, D Gesbert, C R Murthy, M Van Der Schaar, IEEE J. Sel. Areas Commun. 3710D. G\u00fcnd\u00fcz, P. de Kerret, N. D. Sidiropoulos, D. Gesbert, C. R. Murthy, and M. van der Schaar, \"Machine learning in the air,\" IEEE J. Sel. Areas Commun., vol. 37, no. 10, pp. 2184-2199, Oct. 2019.\n\nArtificial neural networks-based machine learning for wireless networks: A tutorial. M Chen, U Challita, W Saad, C Yin, M Debbah, IEEE Commun. Surveys Tut. M. Chen, U. Challita, W. Saad, C. Yin, and M. Debbah, \"Artificial neural networks-based machine learning for wireless networks: A tutorial,\" IEEE Commun. Surveys Tut., pp. 1-1, 2019.\n\nCommunication-efficient learning of deep networks from decentralized data. H B Mcmahan, E Moore, D Ramage, S Hampson, B A Y Arcas, arXiv:1602.05629arXiv preprintH. B. McMahan, E. Moore, D. Ramage, S. Hampson, and B. A. y. Arcas, \"Communication-efficient learning of deep networks from decentralized data,\" arXiv preprint arXiv:1602.05629, 2016.\n\nFederated multi-task learning. V Smith, C.-K Chiang, M Sanjabi, A S Talwalkar, Advances Neural Information Process. Syst. Curran Associates, IncV. Smith, C.-K. Chiang, M. Sanjabi, and A. S. Talwalkar, \"Federated multi-task learning,\" in Advances Neural Information Process. Syst. Curran Associates, Inc., 2017, pp. 4424-4434.\n\nScheduling policies for federated learning in wireless networks. H H Yang, Z Liu, T Q S Quek, H V Poor, IEEE Trans. Commun. to appearH. H. Yang, Z. Liu, T. Q. S. Quek, and H. V. Poor, \"Scheduling policies for federated learning in wireless networks,\" IEEE Trans. Commun., to appear, 2019.\n\nAdaptive federated learning in resource constrained edge computing systems. S Wang, T Tuor, T Salonidis, K K Leung, C Makaya, T He, K Chan, IEEE J. Sel. Areas Commun. 376S. Wang, T. Tuor, T. Salonidis, K. K. Leung, C. Makaya, T. He, and K. Chan, \"Adaptive federated learning in resource constrained edge computing systems,\" IEEE J. Sel. Areas Commun., vol. 37, no. 6, pp. 1205-1221, June 2019.\n\nMulti-hop federated private data augmentation with sample compression. E Jeong, S Oh, J Park, H Kim, M Bennis, S Kim, abs/1907.06426CoRR. E. Jeong, S. Oh, J. Park, H. Kim, M. Bennis, and S. Kim, \"Multi-hop federated private data augmentation with sample compression,\" CoRR, vol. abs/1907.06426, 2019. [Online]. Available: http://arxiv.org/abs/1907.06426\n\nWireless federated distillation for distributed edge learning with heterogeneous data. J.-H Ahn, O Simeone, J Kang, arXiv:1907.02745arXiv preprintJ.-H. Ahn, O. Simeone, and J. Kang, \"Wireless federated distillation for distributed edge learning with heterogeneous data,\" arXiv preprint arXiv:1907.02745, 2019.\n\nCaching in the sky: Proactive deployment of cache-enabled unmanned aerial vehicles for optimized quality-of-experience. M Chen, M Mozaffari, W Saad, C Yin, M Debbah, C S Hong, IEEE J. Sel. Areas Commun. 355M. Chen, M. Mozaffari, W. Saad, C. Yin, M. Debbah, and C. S. Hong, \"Caching in the sky: Proactive deployment of cache-enabled unmanned aerial vehicles for optimized quality-of-experience,\" IEEE J. Sel. Areas Commun., vol. 35, no. 5, pp. 1046-1061, May 2017.\n\nMobile unmanned aerial vehicles (uavs) for energy-efficient internet of things communications. M Mozaffari, W Saad, M Bennis, M Debbah, IEEE Trans. Wireless Commun. 1611M. Mozaffari, W. Saad, M. Bennis, and M. Debbah, \"Mobile unmanned aerial vehicles (uavs) for energy-efficient internet of things communications,\" IEEE Trans. Wireless Commun., vol. 16, no. 11, pp. 7574-7589, Nov. 2017.\n\nJoint blocklength and location optimization for URLLCenabled UAV relay systems. C Pan, H Ren, Y Deng, M Elkashlan, A Nallanathan, IEEE Commun. Lett. 233C. Pan, H. Ren, Y. Deng, M. Elkashlan, and A. Nallanathan, \"Joint blocklength and location optimization for URLLC- enabled UAV relay systems,\" IEEE Commun. Lett., vol. 23, no. 3, pp. 498-501, Mar. 2019.\n\nFederated optimization: Distributed machine learning for on-device intelligence. J Kone\u010dn\u1ef3, H B Mcmahan, D Ramage, P Richt\u00e1rik, arXiv:1610.02527arXiv preprintJ. Kone\u010dn\u1ef3, H. B. McMahan, D. Ramage, and P. Richt\u00e1rik, \"Federated optimization: Distributed machine learning for on-device intelligence,\" arXiv preprint arXiv:1610.02527, 2016.\n\nTowards an intelligent edge: Wireless communication meets machine learning. G Zhu, D Liu, Y Du, C You, J Zhang, K Huang, arXiv:1809.00343arXiv preprintG. Zhu, D. Liu, Y. Du, C. You, J. Zhang, and K. Huang, \"Towards an intelligent edge: Wireless communication meets machine learning,\" arXiv preprint arXiv:1809.00343, 2018.\n\nLow-latency broadband analog aggregation for federated edge learning. G Zhu, Y Wang, K Huang, arXiv:1812.11494arXiv preprintG. Zhu, Y. Wang, and K. Huang, \"Low-latency broadband analog aggregation for federated edge learning,\" arXiv preprint arXiv:1812.11494, 2018.\n\nCell-free massive mimo for wireless federated learning. T T Vu, D T Ngo, N H Tran, H Q Ngo, M N Dao, R H Middleton, T. T. Vu, D. T. Ngo, N. H. Tran, H. Q. Ngo, M. N. Dao, and R. H. Middleton, \"Cell-free massive mimo for wireless federated learning,\" 2019.\n\nEnergy-aware analog aggregation for federated learning with redundant data. Y Sun, S Zhou, D G\u00fcnd\u00fcz, Y. Sun, S. Zhou, and D. G\u00fcnd\u00fcz, \"Energy-aware analog aggregation for federated learning with redundant data,\" 2019.\n\nFederated learning via over-the-air computation. K Yang, T Jiang, Y Shi, Z Ding, arXiv:1812.11750arXiv preprintK. Yang, T. Jiang, Y. Shi, and Z. Ding, \"Federated learning via over-the-air computation,\" arXiv preprint arXiv:1812.11750, 2018.\n\nEnergy-efficient radio resource allocation for federated edge learning. Q Zeng, Y Du, K K Leung, K Huang, arXiv:1907.06040arXiv preprintQ. Zeng, Y. Du, K. K. Leung, and K. Huang, \"Energy-efficient radio resource allocation for federated edge learning,\" arXiv preprint arXiv:1907.06040, 2019.\n\nA joint learning and communications framework for federated learning over wireless networks. M Chen, Z Yang, W Saad, C Yin, H V Poor, S Cui, arXiv:1909.07972arXiv preprintM. Chen, Z. Yang, W. Saad, C. Yin, H. V. Poor, and S. Cui, \"A joint learning and communications framework for federated learning over wireless networks,\" arXiv preprint arXiv:1909.07972, 2019.\n\nFederated learning over wireless networks: Optimization model design and analysis. N H Tran, W Bao, A Zomaya, C S Hong, Proc. IEEE Conf. IEEE ConfParis, FranceN. H. Tran, W. Bao, A. Zomaya, and C. S. Hong, \"Federated learning over wireless networks: Optimization model design and analysis,\" in Proc. IEEE Conf. Computer Commun., Paris, France, June 2019, pp. 1387-1395.\n\nCommunication-efficient distributed optimization using an approximate newton-type method. O Shamir, N Srebro, T Zhang, Proc. Int. Conf. Machine Learning. Int. Conf. Machine LearningBeijing, ChinaO. Shamir, N. Srebro, and T. Zhang, \"Communication-efficient distributed optimization using an approximate newton-type method,\" in Proc. Int. Conf. Machine Learning, Beijing, China, June 2014, pp. 1000-1008.\n\nDynamic computation offloading for mobile-edge computing with energy harvesting devices. Y Mao, J Zhang, K B Letaief, IEEE J. Sel. Areas Commun. 3412Y. Mao, J. Zhang, and K. B. Letaief, \"Dynamic computation offloading for mobile-edge computing with energy harvesting devices,\" IEEE J. Sel. Areas Commun., vol. 34, no. 12, pp. 3590-3605, Dec. 2016.\n\nOn nonlinear fractional programming. W Dinkelbach, Management Science. 137W. Dinkelbach, \"On nonlinear fractional programming,\" Management Science, vol. 13, no. 7, pp. 492-498, 1967.\n\nS Boyd, L Vandenberghe, Convex Optimization. Cambridge University PressS. Boyd and L. Vandenberghe, Convex Optimization. Cambridge University Press, 2004.\n", "annotations": {"author": "[{\"end\":229,\"start\":86},{\"end\":374,\"start\":230},{\"end\":520,\"start\":375},{\"end\":640,\"start\":521},{\"end\":772,\"start\":641},{\"end\":921,\"start\":773},{\"end\":1024,\"start\":922},{\"end\":1135,\"start\":1025},{\"end\":1246,\"start\":1136},{\"end\":1338,\"start\":1247},{\"end\":1426,\"start\":1339}]", "publisher": null, "author_last_name": "[{\"end\":98,\"start\":94},{\"end\":242,\"start\":238},{\"end\":397,\"start\":393},{\"end\":532,\"start\":528},{\"end\":813,\"start\":801},{\"end\":928,\"start\":924},{\"end\":1039,\"start\":1027},{\"end\":1162,\"start\":1138},{\"end\":1345,\"start\":1341}]", "author_first_name": "[{\"end\":93,\"start\":86},{\"end\":237,\"start\":230},{\"end\":392,\"start\":387},{\"end\":527,\"start\":521},{\"end\":664,\"start\":660},{\"end\":800,\"start\":792},{\"end\":923,\"start\":922},{\"end\":1026,\"start\":1025},{\"end\":1137,\"start\":1136},{\"end\":1254,\"start\":1247},{\"end\":1340,\"start\":1339}]", "author_affiliation": "[{\"end\":228,\"start\":123},{\"end\":373,\"start\":268},{\"end\":519,\"start\":414},{\"end\":639,\"start\":534},{\"end\":771,\"start\":666},{\"end\":920,\"start\":815},{\"end\":1023,\"start\":930},{\"end\":1134,\"start\":1041},{\"end\":1245,\"start\":1164},{\"end\":1337,\"start\":1256},{\"end\":1425,\"start\":1366}]", "title": "[{\"end\":73,\"start\":1},{\"end\":1499,\"start\":1427}]", "venue": null, "abstract": "[{\"end\":3366,\"start\":1633}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3719,\"start\":3716},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3904,\"start\":3901},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":3909,\"start\":3906},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":4087,\"start\":4083},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":4093,\"start\":4089},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":4295,\"start\":4291},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":4425,\"start\":4421},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":4818,\"start\":4814},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":4824,\"start\":4820},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":4918,\"start\":4914},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":5063,\"start\":5059},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":5219,\"start\":5215},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":5374,\"start\":5370},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":5448,\"start\":5444},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":5580,\"start\":5576},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":5586,\"start\":5582},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":5749,\"start\":5745},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":5758,\"start\":5754},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":5831,\"start\":5827},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":6044,\"start\":6040},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":6222,\"start\":6218},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":6315,\"start\":6311},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":10173,\"start\":10170},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":10179,\"start\":10175},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":10185,\"start\":10181},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":10378,\"start\":10374},{\"end\":10574,\"start\":10572},{\"end\":10668,\"start\":10666},{\"end\":10792,\"start\":10789},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":11190,\"start\":11187},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":11778,\"start\":11775},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":12153,\"start\":12150},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":13081,\"start\":13077},{\"end\":13088,\"start\":13081},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":14115,\"start\":14112},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":14220,\"start\":14216},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":15006,\"start\":15002},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":15290,\"start\":15286},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":17679,\"start\":17675},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":19424,\"start\":19420},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":20443,\"start\":20439},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":20786,\"start\":20782},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":20789,\"start\":20788},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":21205,\"start\":21201},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":21400,\"start\":21396},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":21524,\"start\":21520},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":21801,\"start\":21797},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":21854,\"start\":21850},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":21955,\"start\":21951},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":22323,\"start\":22319},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":23260,\"start\":23256},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":23332,\"start\":23328},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":23355,\"start\":23351},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":23446,\"start\":23442},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":23558,\"start\":23554},{\"end\":23562,\"start\":23560},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":24172,\"start\":24168},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":24189,\"start\":24185},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":24297,\"start\":24293},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":24488,\"start\":24484},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":24505,\"start\":24501},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":24528,\"start\":24524},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":24726,\"start\":24722},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":27782,\"start\":27781},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":30062,\"start\":30058},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":32794,\"start\":32791},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":36627,\"start\":36624},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":37223,\"start\":37219},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":37385,\"start\":37381},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":38023,\"start\":38019},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":38075,\"start\":38071},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":38166,\"start\":38162},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":38409,\"start\":38405},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":38574,\"start\":38570},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":40716,\"start\":40712},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":41055,\"start\":41051},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":45060,\"start\":45056},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":45349,\"start\":45345},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":45477,\"start\":45473},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":45937,\"start\":45933},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":45988,\"start\":45984},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":48642,\"start\":48638}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":44423,\"start\":44331},{\"attributes\":{\"id\":\"fig_2\"},\"end\":44786,\"start\":44424},{\"attributes\":{\"id\":\"fig_3\"},\"end\":44974,\"start\":44787},{\"attributes\":{\"id\":\"fig_4\"},\"end\":45075,\"start\":44975},{\"attributes\":{\"id\":\"fig_5\"},\"end\":45306,\"start\":45076},{\"attributes\":{\"id\":\"fig_6\"},\"end\":46152,\"start\":45307},{\"attributes\":{\"id\":\"fig_7\"},\"end\":46357,\"start\":46153},{\"attributes\":{\"id\":\"fig_8\"},\"end\":46437,\"start\":46358},{\"attributes\":{\"id\":\"fig_9\"},\"end\":46990,\"start\":46438},{\"attributes\":{\"id\":\"fig_10\"},\"end\":48308,\"start\":46991},{\"attributes\":{\"id\":\"fig_11\"},\"end\":48405,\"start\":48309},{\"attributes\":{\"id\":\"fig_12\"},\"end\":49268,\"start\":48406},{\"attributes\":{\"id\":\"fig_13\"},\"end\":49462,\"start\":49269},{\"attributes\":{\"id\":\"fig_14\"},\"end\":49512,\"start\":49463},{\"attributes\":{\"id\":\"fig_15\"},\"end\":51112,\"start\":49513},{\"attributes\":{\"id\":\"fig_16\"},\"end\":51138,\"start\":51113},{\"attributes\":{\"id\":\"fig_17\"},\"end\":51224,\"start\":51139},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":51430,\"start\":51225},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":51578,\"start\":51431},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":51732,\"start\":51579}]", "paragraph": "[{\"end\":4529,\"start\":3385},{\"end\":4739,\"start\":4531},{\"end\":6364,\"start\":4741},{\"end\":6561,\"start\":6366},{\"end\":6965,\"start\":6563},{\"end\":7235,\"start\":6967},{\"end\":7491,\"start\":7237},{\"end\":7759,\"start\":7493},{\"end\":7974,\"start\":7761},{\"end\":8346,\"start\":7976},{\"end\":8678,\"start\":8391},{\"end\":9022,\"start\":8694},{\"end\":9539,\"start\":9024},{\"end\":9846,\"start\":9628},{\"end\":9939,\"start\":9848},{\"end\":10186,\"start\":9941},{\"end\":10415,\"start\":10263},{\"end\":10590,\"start\":10417},{\"end\":10708,\"start\":10633},{\"end\":10807,\"start\":10750},{\"end\":10972,\"start\":10809},{\"end\":11621,\"start\":11068},{\"end\":11779,\"start\":11724},{\"end\":12041,\"start\":11781},{\"end\":12154,\"start\":12098},{\"end\":12333,\"start\":12156},{\"end\":12457,\"start\":12364},{\"end\":12525,\"start\":12459},{\"end\":12724,\"start\":12599},{\"end\":13192,\"start\":12726},{\"end\":13267,\"start\":13194},{\"end\":13491,\"start\":13309},{\"end\":13586,\"start\":13517},{\"end\":13666,\"start\":13588},{\"end\":13834,\"start\":13731},{\"end\":14116,\"start\":13996},{\"end\":14299,\"start\":14147},{\"end\":14323,\"start\":14301},{\"end\":14741,\"start\":14325},{\"end\":15135,\"start\":14809},{\"end\":15291,\"start\":15202},{\"end\":15568,\"start\":15389},{\"end\":15616,\"start\":15570},{\"end\":15912,\"start\":15667},{\"end\":16252,\"start\":15960},{\"end\":16682,\"start\":16266},{\"end\":16985,\"start\":16701},{\"end\":17359,\"start\":17071},{\"end\":17511,\"start\":17425},{\"end\":17525,\"start\":17519},{\"end\":17575,\"start\":17536},{\"end\":17931,\"start\":17662},{\"end\":18132,\"start\":17958},{\"end\":18831,\"start\":18554},{\"end\":19287,\"start\":18935},{\"end\":19604,\"start\":19358},{\"end\":19720,\"start\":19631},{\"end\":20020,\"start\":19828},{\"end\":20083,\"start\":20022},{\"end\":20252,\"start\":20247},{\"end\":20381,\"start\":20309},{\"end\":20454,\"start\":20383},{\"end\":20524,\"start\":20485},{\"end\":20709,\"start\":20590},{\"end\":20725,\"start\":20723},{\"end\":20790,\"start\":20727},{\"end\":20856,\"start\":20842},{\"end\":21436,\"start\":21086},{\"end\":21878,\"start\":21501},{\"end\":21977,\"start\":21880},{\"end\":22362,\"start\":22247},{\"end\":22519,\"start\":22516},{\"end\":22720,\"start\":22674},{\"end\":22793,\"start\":22722},{\"end\":22908,\"start\":22905},{\"end\":22972,\"start\":22967},{\"end\":23100,\"start\":23070},{\"end\":23203,\"start\":23181},{\"end\":23384,\"start\":23205},{\"end\":23664,\"start\":23386},{\"end\":23720,\"start\":23706},{\"end\":23766,\"start\":23722},{\"end\":24074,\"start\":24059},{\"end\":24135,\"start\":24113},{\"end\":24306,\"start\":24137},{\"end\":24703,\"start\":24333},{\"end\":25316,\"start\":24705},{\"end\":25755,\"start\":25380},{\"end\":25911,\"start\":25790},{\"end\":26025,\"start\":25913},{\"end\":26315,\"start\":26027},{\"end\":26539,\"start\":26317},{\"end\":26839,\"start\":26744},{\"end\":26954,\"start\":26949},{\"end\":27078,\"start\":27063},{\"end\":27483,\"start\":27140},{\"end\":27687,\"start\":27572},{\"end\":27820,\"start\":27694},{\"end\":27917,\"start\":27822},{\"end\":28308,\"start\":27955},{\"end\":28677,\"start\":28366},{\"end\":29442,\"start\":28704},{\"end\":30648,\"start\":29467},{\"end\":32679,\"start\":30684},{\"end\":32826,\"start\":32741},{\"end\":32978,\"start\":32975},{\"end\":33105,\"start\":33017},{\"end\":33330,\"start\":33173},{\"end\":33453,\"start\":33432},{\"end\":33637,\"start\":33618},{\"end\":33736,\"start\":33639},{\"end\":33894,\"start\":33805},{\"end\":34296,\"start\":34231},{\"end\":34402,\"start\":34369},{\"end\":35078,\"start\":35050},{\"end\":35231,\"start\":35190},{\"end\":35375,\"start\":35324},{\"end\":35501,\"start\":35450},{\"end\":35509,\"start\":35503},{\"end\":35557,\"start\":35511},{\"end\":35849,\"start\":35825},{\"end\":36090,\"start\":36038},{\"end\":36239,\"start\":36216},{\"end\":36492,\"start\":36456},{\"end\":36663,\"start\":36589},{\"end\":37092,\"start\":36995},{\"end\":37393,\"start\":37206},{\"end\":37757,\"start\":37603},{\"end\":38024,\"start\":37960},{\"end\":38226,\"start\":38058},{\"end\":38366,\"start\":38285},{\"end\":38410,\"start\":38379},{\"end\":38456,\"start\":38412},{\"end\":38644,\"start\":38548},{\"end\":38752,\"start\":38646},{\"end\":38861,\"start\":38835},{\"end\":39069,\"start\":38945},{\"end\":39209,\"start\":39103},{\"end\":39336,\"start\":39254},{\"end\":39481,\"start\":39425},{\"end\":40010,\"start\":39844},{\"end\":40216,\"start\":40085},{\"end\":40661,\"start\":40314},{\"end\":40690,\"start\":40663},{\"end\":41037,\"start\":40692},{\"end\":41218,\"start\":41039},{\"end\":41247,\"start\":41220},{\"end\":41303,\"start\":41249},{\"end\":41315,\"start\":41305},{\"end\":41322,\"start\":41317},{\"end\":41352,\"start\":41324},{\"end\":41645,\"start\":41400},{\"end\":41874,\"start\":41647},{\"end\":42002,\"start\":41932},{\"end\":42168,\"start\":42135},{\"end\":42481,\"start\":42170},{\"end\":42699,\"start\":42513},{\"end\":43182,\"start\":42724},{\"end\":43424,\"start\":43184},{\"end\":43519,\"start\":43426},{\"end\":43585,\"start\":43580},{\"end\":43658,\"start\":43587},{\"end\":43718,\"start\":43660},{\"end\":43834,\"start\":43720},{\"end\":43856,\"start\":43836},{\"end\":44065,\"start\":43923},{\"end\":44152,\"start\":44104},{\"end\":44330,\"start\":44242}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":9627,\"start\":9540},{\"attributes\":{\"id\":\"formula_1\"},\"end\":10262,\"start\":10187},{\"attributes\":{\"id\":\"formula_2\"},\"end\":10632,\"start\":10591},{\"attributes\":{\"id\":\"formula_3\"},\"end\":10749,\"start\":10709},{\"attributes\":{\"id\":\"formula_4\"},\"end\":11067,\"start\":10973},{\"attributes\":{\"id\":\"formula_5\"},\"end\":11723,\"start\":11622},{\"attributes\":{\"id\":\"formula_6\"},\"end\":12097,\"start\":12042},{\"attributes\":{\"id\":\"formula_7\"},\"end\":12363,\"start\":12334},{\"attributes\":{\"id\":\"formula_8\"},\"end\":12598,\"start\":12526},{\"attributes\":{\"id\":\"formula_9\"},\"end\":13730,\"start\":13667},{\"attributes\":{\"id\":\"formula_10\"},\"end\":13995,\"start\":13835},{\"attributes\":{\"id\":\"formula_11\"},\"end\":14146,\"start\":14117},{\"attributes\":{\"id\":\"formula_12\"},\"end\":14808,\"start\":14742},{\"attributes\":{\"id\":\"formula_13\"},\"end\":15201,\"start\":15136},{\"attributes\":{\"id\":\"formula_14\"},\"end\":15666,\"start\":15617},{\"attributes\":{\"id\":\"formula_15\"},\"end\":15959,\"start\":15913},{\"attributes\":{\"id\":\"formula_16\"},\"end\":16265,\"start\":16253},{\"attributes\":{\"id\":\"formula_17\"},\"end\":16700,\"start\":16683},{\"attributes\":{\"id\":\"formula_18\"},\"end\":17070,\"start\":16986},{\"attributes\":{\"id\":\"formula_19\"},\"end\":17424,\"start\":17360},{\"attributes\":{\"id\":\"formula_20\"},\"end\":17518,\"start\":17512},{\"attributes\":{\"id\":\"formula_21\"},\"end\":17640,\"start\":17576},{\"attributes\":{\"id\":\"formula_22\"},\"end\":17661,\"start\":17640},{\"attributes\":{\"id\":\"formula_23\"},\"end\":18165,\"start\":18133},{\"attributes\":{\"id\":\"formula_24\"},\"end\":18380,\"start\":18165},{\"attributes\":{\"id\":\"formula_25\"},\"end\":18553,\"start\":18380},{\"attributes\":{\"id\":\"formula_26\"},\"end\":19827,\"start\":19721},{\"attributes\":{\"id\":\"formula_27\"},\"end\":20143,\"start\":20084},{\"attributes\":{\"id\":\"formula_28\"},\"end\":20246,\"start\":20143},{\"attributes\":{\"id\":\"formula_29\"},\"end\":20308,\"start\":20253},{\"attributes\":{\"id\":\"formula_30\"},\"end\":20484,\"start\":20455},{\"attributes\":{\"id\":\"formula_31\"},\"end\":20589,\"start\":20525},{\"attributes\":{\"id\":\"formula_32\"},\"end\":20836,\"start\":20791},{\"attributes\":{\"id\":\"formula_33\"},\"end\":20955,\"start\":20857},{\"attributes\":{\"id\":\"formula_34\"},\"end\":21085,\"start\":20955},{\"attributes\":{\"id\":\"formula_35\"},\"end\":21500,\"start\":21437},{\"attributes\":{\"id\":\"formula_36\"},\"end\":22054,\"start\":21978},{\"attributes\":{\"id\":\"formula_37\"},\"end\":22110,\"start\":22054},{\"attributes\":{\"id\":\"formula_38\"},\"end\":22182,\"start\":22110},{\"attributes\":{\"id\":\"formula_39\"},\"end\":22214,\"start\":22182},{\"attributes\":{\"id\":\"formula_40\"},\"end\":22246,\"start\":22214},{\"attributes\":{\"id\":\"formula_41\"},\"end\":22425,\"start\":22363},{\"attributes\":{\"id\":\"formula_42\"},\"end\":22515,\"start\":22425},{\"attributes\":{\"id\":\"formula_43\"},\"end\":22562,\"start\":22520},{\"attributes\":{\"id\":\"formula_44\"},\"end\":22673,\"start\":22562},{\"attributes\":{\"id\":\"formula_45\"},\"end\":22904,\"start\":22794},{\"attributes\":{\"id\":\"formula_46\"},\"end\":22966,\"start\":22909},{\"attributes\":{\"id\":\"formula_47\"},\"end\":23032,\"start\":22973},{\"attributes\":{\"id\":\"formula_48\"},\"end\":23069,\"start\":23032},{\"attributes\":{\"id\":\"formula_49\"},\"end\":23180,\"start\":23101},{\"attributes\":{\"id\":\"formula_50\"},\"end\":23700,\"start\":23665},{\"attributes\":{\"id\":\"formula_51\"},\"end\":23812,\"start\":23767},{\"attributes\":{\"id\":\"formula_52\"},\"end\":23937,\"start\":23812},{\"attributes\":{\"id\":\"formula_53\"},\"end\":24058,\"start\":23937},{\"attributes\":{\"id\":\"formula_54\"},\"end\":24112,\"start\":24075},{\"attributes\":{\"id\":\"formula_55\"},\"end\":26696,\"start\":26540},{\"attributes\":{\"id\":\"formula_56\"},\"end\":26743,\"start\":26696},{\"attributes\":{\"id\":\"formula_57\"},\"end\":26948,\"start\":26910},{\"attributes\":{\"id\":\"formula_58\"},\"end\":27062,\"start\":26955},{\"attributes\":{\"id\":\"formula_59\"},\"end\":27139,\"start\":27079},{\"attributes\":{\"id\":\"formula_60\"},\"end\":27571,\"start\":27540},{\"attributes\":{\"id\":\"formula_61\"},\"end\":27954,\"start\":27918},{\"attributes\":{\"id\":\"formula_62\"},\"end\":28365,\"start\":28309},{\"attributes\":{\"id\":\"formula_63\"},\"end\":32974,\"start\":32827},{\"attributes\":{\"id\":\"formula_64\"},\"end\":33016,\"start\":32979},{\"attributes\":{\"id\":\"formula_65\"},\"end\":33172,\"start\":33106},{\"attributes\":{\"id\":\"formula_66\"},\"end\":33431,\"start\":33331},{\"attributes\":{\"id\":\"formula_67\"},\"end\":33617,\"start\":33454},{\"attributes\":{\"id\":\"formula_68\"},\"end\":33804,\"start\":33737},{\"attributes\":{\"id\":\"formula_69\"},\"end\":34230,\"start\":33895},{\"attributes\":{\"id\":\"formula_70\"},\"end\":34368,\"start\":34297},{\"attributes\":{\"id\":\"formula_71\"},\"end\":35049,\"start\":34403},{\"attributes\":{\"id\":\"formula_72\"},\"end\":35189,\"start\":35079},{\"attributes\":{\"id\":\"formula_73\"},\"end\":35323,\"start\":35232},{\"attributes\":{\"id\":\"formula_74\"},\"end\":35449,\"start\":35376},{\"attributes\":{\"id\":\"formula_75\"},\"end\":35824,\"start\":35558},{\"attributes\":{\"id\":\"formula_76\"},\"end\":36037,\"start\":35850},{\"attributes\":{\"id\":\"formula_77\"},\"end\":36215,\"start\":36091},{\"attributes\":{\"id\":\"formula_78\"},\"end\":36455,\"start\":36240},{\"attributes\":{\"id\":\"formula_79\"},\"end\":36588,\"start\":36493},{\"attributes\":{\"id\":\"formula_80\"},\"end\":36994,\"start\":36664},{\"attributes\":{\"id\":\"formula_81\"},\"end\":37205,\"start\":37093},{\"attributes\":{\"id\":\"formula_82\"},\"end\":37602,\"start\":37394},{\"attributes\":{\"id\":\"formula_83\"},\"end\":37959,\"start\":37758},{\"attributes\":{\"id\":\"formula_84\"},\"end\":38284,\"start\":38227},{\"attributes\":{\"id\":\"formula_85\"},\"end\":38378,\"start\":38367},{\"attributes\":{\"id\":\"formula_86\"},\"end\":38547,\"start\":38457},{\"attributes\":{\"id\":\"formula_87\"},\"end\":38834,\"start\":38753},{\"attributes\":{\"id\":\"formula_88\"},\"end\":38944,\"start\":38862},{\"attributes\":{\"id\":\"formula_89\"},\"end\":39253,\"start\":39210},{\"attributes\":{\"id\":\"formula_90\"},\"end\":39424,\"start\":39337},{\"attributes\":{\"id\":\"formula_91\"},\"end\":39734,\"start\":39482},{\"attributes\":{\"id\":\"formula_92\"},\"end\":39843,\"start\":39734},{\"attributes\":{\"id\":\"formula_93\"},\"end\":40084,\"start\":40011},{\"attributes\":{\"id\":\"formula_94\"},\"end\":40313,\"start\":40217},{\"attributes\":{\"id\":\"formula_95\"},\"end\":41399,\"start\":41353},{\"attributes\":{\"id\":\"formula_96\"},\"end\":41931,\"start\":41875},{\"attributes\":{\"id\":\"formula_97\"},\"end\":42134,\"start\":42003},{\"attributes\":{\"id\":\"formula_98\"},\"end\":42723,\"start\":42700},{\"attributes\":{\"id\":\"formula_99\"},\"end\":43579,\"start\":43520},{\"attributes\":{\"id\":\"formula_100\"},\"end\":43922,\"start\":43857},{\"attributes\":{\"id\":\"formula_101\"},\"end\":44103,\"start\":44066},{\"attributes\":{\"id\":\"formula_102\"},\"end\":44241,\"start\":44153}]", "table_ref": null, "section_header": "[{\"end\":3383,\"start\":3368},{\"end\":8389,\"start\":8349},{\"end\":8692,\"start\":8681},{\"end\":13307,\"start\":13270},{\"end\":13515,\"start\":13494},{\"end\":15387,\"start\":15294},{\"end\":17534,\"start\":17528},{\"end\":17956,\"start\":17934},{\"end\":18933,\"start\":18834},{\"end\":19356,\"start\":19290},{\"end\":19629,\"start\":19607},{\"end\":20721,\"start\":20712},{\"end\":20840,\"start\":20838},{\"end\":23704,\"start\":23702},{\"end\":24331,\"start\":24309},{\"end\":25378,\"start\":25319},{\"end\":25788,\"start\":25758},{\"end\":26909,\"start\":26842},{\"end\":27539,\"start\":27486},{\"end\":27692,\"start\":27690},{\"end\":28702,\"start\":28680},{\"end\":29465,\"start\":29445},{\"end\":30682,\"start\":30651},{\"end\":32739,\"start\":32682},{\"end\":38056,\"start\":38027},{\"end\":39101,\"start\":39072},{\"end\":42511,\"start\":42484},{\"end\":44340,\"start\":44332},{\"end\":44433,\"start\":44425},{\"end\":44791,\"start\":44788},{\"end\":46163,\"start\":46154},{\"end\":46368,\"start\":46359},{\"end\":46447,\"start\":46439},{\"end\":47015,\"start\":46992},{\"end\":48318,\"start\":48310},{\"end\":48413,\"start\":48407},{\"end\":49286,\"start\":49270},{\"end\":49473,\"start\":49464},{\"end\":49521,\"start\":49514}]", "table": "[{\"end\":51578,\"start\":51526}]", "figure_caption": "[{\"end\":44423,\"start\":44342},{\"end\":44786,\"start\":44435},{\"end\":44974,\"start\":44793},{\"end\":45075,\"start\":44977},{\"end\":45306,\"start\":45078},{\"end\":46152,\"start\":45309},{\"end\":46357,\"start\":46165},{\"end\":46437,\"start\":46370},{\"end\":46990,\"start\":46449},{\"end\":48308,\"start\":47019},{\"end\":48405,\"start\":48320},{\"end\":49268,\"start\":48415},{\"end\":49462,\"start\":49289},{\"end\":49512,\"start\":49476},{\"end\":51112,\"start\":49524},{\"end\":51138,\"start\":51115},{\"end\":51224,\"start\":51141},{\"end\":51430,\"start\":51227},{\"end\":51526,\"start\":51433},{\"end\":51732,\"start\":51581}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":8489,\"start\":8483},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":13383,\"start\":13377},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":17292,\"start\":17286},{\"end\":30165,\"start\":30159},{\"end\":30551,\"start\":30545},{\"end\":31011,\"start\":31005},{\"end\":31514,\"start\":31508},{\"end\":31629,\"start\":31623},{\"end\":31887,\"start\":31876},{\"end\":32425,\"start\":32419}]", "bib_author_first_name": "[{\"end\":51962,\"start\":51961},{\"end\":51970,\"start\":51969},{\"end\":51978,\"start\":51977},{\"end\":51986,\"start\":51985},{\"end\":51988,\"start\":51987},{\"end\":51996,\"start\":51995},{\"end\":52346,\"start\":52345},{\"end\":52354,\"start\":52353},{\"end\":52362,\"start\":52361},{\"end\":52375,\"start\":52374},{\"end\":52377,\"start\":52376},{\"end\":52386,\"start\":52385},{\"end\":52396,\"start\":52395},{\"end\":52402,\"start\":52401},{\"end\":52785,\"start\":52784},{\"end\":52793,\"start\":52792},{\"end\":52803,\"start\":52802},{\"end\":53041,\"start\":53040},{\"end\":53049,\"start\":53048},{\"end\":53063,\"start\":53062},{\"end\":53073,\"start\":53072},{\"end\":53387,\"start\":53386},{\"end\":53395,\"start\":53394},{\"end\":53406,\"start\":53405},{\"end\":53414,\"start\":53413},{\"end\":53421,\"start\":53420},{\"end\":53723,\"start\":53722},{\"end\":53916,\"start\":53915},{\"end\":53930,\"start\":53929},{\"end\":53940,\"start\":53939},{\"end\":53948,\"start\":53947},{\"end\":54197,\"start\":54196},{\"end\":54207,\"start\":54206},{\"end\":54217,\"start\":54216},{\"end\":54219,\"start\":54218},{\"end\":54235,\"start\":54234},{\"end\":54246,\"start\":54245},{\"end\":54248,\"start\":54247},{\"end\":54258,\"start\":54257},{\"end\":54589,\"start\":54588},{\"end\":54597,\"start\":54596},{\"end\":54609,\"start\":54608},{\"end\":54617,\"start\":54616},{\"end\":54624,\"start\":54623},{\"end\":54919,\"start\":54918},{\"end\":54921,\"start\":54920},{\"end\":54932,\"start\":54931},{\"end\":54941,\"start\":54940},{\"end\":54951,\"start\":54950},{\"end\":54962,\"start\":54961},{\"end\":54966,\"start\":54963},{\"end\":55221,\"start\":55220},{\"end\":55233,\"start\":55229},{\"end\":55243,\"start\":55242},{\"end\":55254,\"start\":55253},{\"end\":55256,\"start\":55255},{\"end\":55582,\"start\":55581},{\"end\":55584,\"start\":55583},{\"end\":55592,\"start\":55591},{\"end\":55599,\"start\":55598},{\"end\":55603,\"start\":55600},{\"end\":55611,\"start\":55610},{\"end\":55613,\"start\":55612},{\"end\":55883,\"start\":55882},{\"end\":55891,\"start\":55890},{\"end\":55899,\"start\":55898},{\"end\":55912,\"start\":55911},{\"end\":55914,\"start\":55913},{\"end\":55923,\"start\":55922},{\"end\":55933,\"start\":55932},{\"end\":55939,\"start\":55938},{\"end\":56273,\"start\":56272},{\"end\":56282,\"start\":56281},{\"end\":56288,\"start\":56287},{\"end\":56296,\"start\":56295},{\"end\":56303,\"start\":56302},{\"end\":56313,\"start\":56312},{\"end\":56647,\"start\":56643},{\"end\":56654,\"start\":56653},{\"end\":56665,\"start\":56664},{\"end\":56988,\"start\":56987},{\"end\":56996,\"start\":56995},{\"end\":57009,\"start\":57008},{\"end\":57017,\"start\":57016},{\"end\":57024,\"start\":57023},{\"end\":57034,\"start\":57033},{\"end\":57036,\"start\":57035},{\"end\":57428,\"start\":57427},{\"end\":57441,\"start\":57440},{\"end\":57449,\"start\":57448},{\"end\":57459,\"start\":57458},{\"end\":57802,\"start\":57801},{\"end\":57809,\"start\":57808},{\"end\":57816,\"start\":57815},{\"end\":57824,\"start\":57823},{\"end\":57837,\"start\":57836},{\"end\":58159,\"start\":58158},{\"end\":58170,\"start\":58169},{\"end\":58172,\"start\":58171},{\"end\":58183,\"start\":58182},{\"end\":58193,\"start\":58192},{\"end\":58491,\"start\":58490},{\"end\":58498,\"start\":58497},{\"end\":58505,\"start\":58504},{\"end\":58511,\"start\":58510},{\"end\":58518,\"start\":58517},{\"end\":58527,\"start\":58526},{\"end\":58809,\"start\":58808},{\"end\":58816,\"start\":58815},{\"end\":58824,\"start\":58823},{\"end\":59062,\"start\":59061},{\"end\":59064,\"start\":59063},{\"end\":59070,\"start\":59069},{\"end\":59072,\"start\":59071},{\"end\":59079,\"start\":59078},{\"end\":59081,\"start\":59080},{\"end\":59089,\"start\":59088},{\"end\":59091,\"start\":59090},{\"end\":59098,\"start\":59097},{\"end\":59100,\"start\":59099},{\"end\":59107,\"start\":59106},{\"end\":59109,\"start\":59108},{\"end\":59339,\"start\":59338},{\"end\":59346,\"start\":59345},{\"end\":59354,\"start\":59353},{\"end\":59530,\"start\":59529},{\"end\":59538,\"start\":59537},{\"end\":59547,\"start\":59546},{\"end\":59554,\"start\":59553},{\"end\":59795,\"start\":59794},{\"end\":59803,\"start\":59802},{\"end\":59809,\"start\":59808},{\"end\":59811,\"start\":59810},{\"end\":59820,\"start\":59819},{\"end\":60109,\"start\":60108},{\"end\":60117,\"start\":60116},{\"end\":60125,\"start\":60124},{\"end\":60133,\"start\":60132},{\"end\":60140,\"start\":60139},{\"end\":60142,\"start\":60141},{\"end\":60150,\"start\":60149},{\"end\":60464,\"start\":60463},{\"end\":60466,\"start\":60465},{\"end\":60474,\"start\":60473},{\"end\":60481,\"start\":60480},{\"end\":60491,\"start\":60490},{\"end\":60493,\"start\":60492},{\"end\":60842,\"start\":60841},{\"end\":60852,\"start\":60851},{\"end\":60862,\"start\":60861},{\"end\":61245,\"start\":61244},{\"end\":61252,\"start\":61251},{\"end\":61261,\"start\":61260},{\"end\":61263,\"start\":61262},{\"end\":61542,\"start\":61541},{\"end\":61689,\"start\":61688},{\"end\":61697,\"start\":61696}]", "bib_author_last_name": "[{\"end\":51967,\"start\":51963},{\"end\":51975,\"start\":51971},{\"end\":51983,\"start\":51979},{\"end\":51993,\"start\":51989},{\"end\":52009,\"start\":51997},{\"end\":52351,\"start\":52347},{\"end\":52359,\"start\":52355},{\"end\":52372,\"start\":52363},{\"end\":52383,\"start\":52378},{\"end\":52393,\"start\":52387},{\"end\":52399,\"start\":52397},{\"end\":52407,\"start\":52403},{\"end\":52790,\"start\":52786},{\"end\":52800,\"start\":52794},{\"end\":52808,\"start\":52804},{\"end\":53046,\"start\":53042},{\"end\":53060,\"start\":53050},{\"end\":53070,\"start\":53064},{\"end\":53080,\"start\":53074},{\"end\":53392,\"start\":53388},{\"end\":53403,\"start\":53396},{\"end\":53411,\"start\":53407},{\"end\":53418,\"start\":53415},{\"end\":53425,\"start\":53422},{\"end\":53731,\"start\":53724},{\"end\":53927,\"start\":53917},{\"end\":53937,\"start\":53931},{\"end\":53945,\"start\":53941},{\"end\":53955,\"start\":53949},{\"end\":54204,\"start\":54198},{\"end\":54214,\"start\":54208},{\"end\":54232,\"start\":54220},{\"end\":54243,\"start\":54236},{\"end\":54255,\"start\":54249},{\"end\":54273,\"start\":54259},{\"end\":54594,\"start\":54590},{\"end\":54606,\"start\":54598},{\"end\":54614,\"start\":54610},{\"end\":54621,\"start\":54618},{\"end\":54631,\"start\":54625},{\"end\":54929,\"start\":54922},{\"end\":54938,\"start\":54933},{\"end\":54948,\"start\":54942},{\"end\":54959,\"start\":54952},{\"end\":54972,\"start\":54967},{\"end\":55227,\"start\":55222},{\"end\":55240,\"start\":55234},{\"end\":55251,\"start\":55244},{\"end\":55266,\"start\":55257},{\"end\":55589,\"start\":55585},{\"end\":55596,\"start\":55593},{\"end\":55608,\"start\":55604},{\"end\":55618,\"start\":55614},{\"end\":55888,\"start\":55884},{\"end\":55896,\"start\":55892},{\"end\":55909,\"start\":55900},{\"end\":55920,\"start\":55915},{\"end\":55930,\"start\":55924},{\"end\":55936,\"start\":55934},{\"end\":55944,\"start\":55940},{\"end\":56279,\"start\":56274},{\"end\":56285,\"start\":56283},{\"end\":56293,\"start\":56289},{\"end\":56300,\"start\":56297},{\"end\":56310,\"start\":56304},{\"end\":56317,\"start\":56314},{\"end\":56651,\"start\":56648},{\"end\":56662,\"start\":56655},{\"end\":56670,\"start\":56666},{\"end\":56993,\"start\":56989},{\"end\":57006,\"start\":56997},{\"end\":57014,\"start\":57010},{\"end\":57021,\"start\":57018},{\"end\":57031,\"start\":57025},{\"end\":57041,\"start\":57037},{\"end\":57438,\"start\":57429},{\"end\":57446,\"start\":57442},{\"end\":57456,\"start\":57450},{\"end\":57466,\"start\":57460},{\"end\":57806,\"start\":57803},{\"end\":57813,\"start\":57810},{\"end\":57821,\"start\":57817},{\"end\":57834,\"start\":57825},{\"end\":57849,\"start\":57838},{\"end\":58167,\"start\":58160},{\"end\":58180,\"start\":58173},{\"end\":58190,\"start\":58184},{\"end\":58203,\"start\":58194},{\"end\":58495,\"start\":58492},{\"end\":58502,\"start\":58499},{\"end\":58508,\"start\":58506},{\"end\":58515,\"start\":58512},{\"end\":58524,\"start\":58519},{\"end\":58533,\"start\":58528},{\"end\":58813,\"start\":58810},{\"end\":58821,\"start\":58817},{\"end\":58830,\"start\":58825},{\"end\":59067,\"start\":59065},{\"end\":59076,\"start\":59073},{\"end\":59086,\"start\":59082},{\"end\":59095,\"start\":59092},{\"end\":59104,\"start\":59101},{\"end\":59119,\"start\":59110},{\"end\":59343,\"start\":59340},{\"end\":59351,\"start\":59347},{\"end\":59361,\"start\":59355},{\"end\":59535,\"start\":59531},{\"end\":59544,\"start\":59539},{\"end\":59551,\"start\":59548},{\"end\":59559,\"start\":59555},{\"end\":59800,\"start\":59796},{\"end\":59806,\"start\":59804},{\"end\":59817,\"start\":59812},{\"end\":59826,\"start\":59821},{\"end\":60114,\"start\":60110},{\"end\":60122,\"start\":60118},{\"end\":60130,\"start\":60126},{\"end\":60137,\"start\":60134},{\"end\":60147,\"start\":60143},{\"end\":60154,\"start\":60151},{\"end\":60471,\"start\":60467},{\"end\":60478,\"start\":60475},{\"end\":60488,\"start\":60482},{\"end\":60498,\"start\":60494},{\"end\":60849,\"start\":60843},{\"end\":60859,\"start\":60853},{\"end\":60868,\"start\":60863},{\"end\":61249,\"start\":61246},{\"end\":61258,\"start\":61253},{\"end\":61271,\"start\":61264},{\"end\":61553,\"start\":61543},{\"end\":61694,\"start\":61690},{\"end\":61710,\"start\":61698}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":220381316},\"end\":52245,\"start\":51881},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":4883014},\"end\":52685,\"start\":52247},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":67856161},\"end\":52995,\"start\":52687},{\"attributes\":{\"doi\":\"abs/1812.02858\",\"id\":\"b3\",\"matched_paper_id\":54457410},\"end\":53282,\"start\":52997},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":54446260},\"end\":53665,\"start\":53284},{\"attributes\":{\"id\":\"b5\"},\"end\":53825,\"start\":53667},{\"attributes\":{\"doi\":\"arXiv:1807.08127\",\"id\":\"b6\"},\"end\":54165,\"start\":53827},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":139107046},\"end\":54501,\"start\":54167},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":195767238},\"end\":54841,\"start\":54503},{\"attributes\":{\"doi\":\"arXiv:1602.05629\",\"id\":\"b9\"},\"end\":55187,\"start\":54843},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":3586416},\"end\":55514,\"start\":55189},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":201070018},\"end\":55804,\"start\":55516},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":51921962},\"end\":56199,\"start\":55806},{\"attributes\":{\"doi\":\"abs/1907.06426\",\"id\":\"b13\",\"matched_paper_id\":196622537},\"end\":56554,\"start\":56201},{\"attributes\":{\"doi\":\"arXiv:1907.02745\",\"id\":\"b14\"},\"end\":56865,\"start\":56556},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":1730595},\"end\":57330,\"start\":56867},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":8834036},\"end\":57719,\"start\":57332},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":68034513},\"end\":58075,\"start\":57721},{\"attributes\":{\"doi\":\"arXiv:1610.02527\",\"id\":\"b18\"},\"end\":58412,\"start\":58077},{\"attributes\":{\"doi\":\"arXiv:1809.00343\",\"id\":\"b19\"},\"end\":58736,\"start\":58414},{\"attributes\":{\"doi\":\"arXiv:1812.11494\",\"id\":\"b20\"},\"end\":59003,\"start\":58738},{\"attributes\":{\"id\":\"b21\"},\"end\":59260,\"start\":59005},{\"attributes\":{\"id\":\"b22\"},\"end\":59478,\"start\":59262},{\"attributes\":{\"doi\":\"arXiv:1812.11750\",\"id\":\"b23\"},\"end\":59720,\"start\":59480},{\"attributes\":{\"doi\":\"arXiv:1907.06040\",\"id\":\"b24\"},\"end\":60013,\"start\":59722},{\"attributes\":{\"doi\":\"arXiv:1909.07972\",\"id\":\"b25\"},\"end\":60378,\"start\":60015},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":86439367},\"end\":60749,\"start\":60380},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":16103184},\"end\":61153,\"start\":60751},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":14777050},\"end\":61502,\"start\":61155},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":115907200},\"end\":61686,\"start\":61504},{\"attributes\":{\"id\":\"b30\"},\"end\":61842,\"start\":61688}]", "bib_title": "[{\"end\":51959,\"start\":51881},{\"end\":52343,\"start\":52247},{\"end\":52782,\"start\":52687},{\"end\":53038,\"start\":52997},{\"end\":53384,\"start\":53284},{\"end\":54194,\"start\":54167},{\"end\":54586,\"start\":54503},{\"end\":55218,\"start\":55189},{\"end\":55579,\"start\":55516},{\"end\":55880,\"start\":55806},{\"end\":56270,\"start\":56201},{\"end\":56985,\"start\":56867},{\"end\":57425,\"start\":57332},{\"end\":57799,\"start\":57721},{\"end\":60461,\"start\":60380},{\"end\":60839,\"start\":60751},{\"end\":61242,\"start\":61155},{\"end\":61539,\"start\":61504}]", "bib_author": "[{\"end\":51969,\"start\":51961},{\"end\":51977,\"start\":51969},{\"end\":51985,\"start\":51977},{\"end\":51995,\"start\":51985},{\"end\":52011,\"start\":51995},{\"end\":52353,\"start\":52345},{\"end\":52361,\"start\":52353},{\"end\":52374,\"start\":52361},{\"end\":52385,\"start\":52374},{\"end\":52395,\"start\":52385},{\"end\":52401,\"start\":52395},{\"end\":52409,\"start\":52401},{\"end\":52792,\"start\":52784},{\"end\":52802,\"start\":52792},{\"end\":52810,\"start\":52802},{\"end\":53048,\"start\":53040},{\"end\":53062,\"start\":53048},{\"end\":53072,\"start\":53062},{\"end\":53082,\"start\":53072},{\"end\":53394,\"start\":53386},{\"end\":53405,\"start\":53394},{\"end\":53413,\"start\":53405},{\"end\":53420,\"start\":53413},{\"end\":53427,\"start\":53420},{\"end\":53733,\"start\":53722},{\"end\":53929,\"start\":53915},{\"end\":53939,\"start\":53929},{\"end\":53947,\"start\":53939},{\"end\":53957,\"start\":53947},{\"end\":54206,\"start\":54196},{\"end\":54216,\"start\":54206},{\"end\":54234,\"start\":54216},{\"end\":54245,\"start\":54234},{\"end\":54257,\"start\":54245},{\"end\":54275,\"start\":54257},{\"end\":54596,\"start\":54588},{\"end\":54608,\"start\":54596},{\"end\":54616,\"start\":54608},{\"end\":54623,\"start\":54616},{\"end\":54633,\"start\":54623},{\"end\":54931,\"start\":54918},{\"end\":54940,\"start\":54931},{\"end\":54950,\"start\":54940},{\"end\":54961,\"start\":54950},{\"end\":54974,\"start\":54961},{\"end\":55229,\"start\":55220},{\"end\":55242,\"start\":55229},{\"end\":55253,\"start\":55242},{\"end\":55268,\"start\":55253},{\"end\":55591,\"start\":55581},{\"end\":55598,\"start\":55591},{\"end\":55610,\"start\":55598},{\"end\":55620,\"start\":55610},{\"end\":55890,\"start\":55882},{\"end\":55898,\"start\":55890},{\"end\":55911,\"start\":55898},{\"end\":55922,\"start\":55911},{\"end\":55932,\"start\":55922},{\"end\":55938,\"start\":55932},{\"end\":55946,\"start\":55938},{\"end\":56281,\"start\":56272},{\"end\":56287,\"start\":56281},{\"end\":56295,\"start\":56287},{\"end\":56302,\"start\":56295},{\"end\":56312,\"start\":56302},{\"end\":56319,\"start\":56312},{\"end\":56653,\"start\":56643},{\"end\":56664,\"start\":56653},{\"end\":56672,\"start\":56664},{\"end\":56995,\"start\":56987},{\"end\":57008,\"start\":56995},{\"end\":57016,\"start\":57008},{\"end\":57023,\"start\":57016},{\"end\":57033,\"start\":57023},{\"end\":57043,\"start\":57033},{\"end\":57440,\"start\":57427},{\"end\":57448,\"start\":57440},{\"end\":57458,\"start\":57448},{\"end\":57468,\"start\":57458},{\"end\":57808,\"start\":57801},{\"end\":57815,\"start\":57808},{\"end\":57823,\"start\":57815},{\"end\":57836,\"start\":57823},{\"end\":57851,\"start\":57836},{\"end\":58169,\"start\":58158},{\"end\":58182,\"start\":58169},{\"end\":58192,\"start\":58182},{\"end\":58205,\"start\":58192},{\"end\":58497,\"start\":58490},{\"end\":58504,\"start\":58497},{\"end\":58510,\"start\":58504},{\"end\":58517,\"start\":58510},{\"end\":58526,\"start\":58517},{\"end\":58535,\"start\":58526},{\"end\":58815,\"start\":58808},{\"end\":58823,\"start\":58815},{\"end\":58832,\"start\":58823},{\"end\":59069,\"start\":59061},{\"end\":59078,\"start\":59069},{\"end\":59088,\"start\":59078},{\"end\":59097,\"start\":59088},{\"end\":59106,\"start\":59097},{\"end\":59121,\"start\":59106},{\"end\":59345,\"start\":59338},{\"end\":59353,\"start\":59345},{\"end\":59363,\"start\":59353},{\"end\":59537,\"start\":59529},{\"end\":59546,\"start\":59537},{\"end\":59553,\"start\":59546},{\"end\":59561,\"start\":59553},{\"end\":59802,\"start\":59794},{\"end\":59808,\"start\":59802},{\"end\":59819,\"start\":59808},{\"end\":59828,\"start\":59819},{\"end\":60116,\"start\":60108},{\"end\":60124,\"start\":60116},{\"end\":60132,\"start\":60124},{\"end\":60139,\"start\":60132},{\"end\":60149,\"start\":60139},{\"end\":60156,\"start\":60149},{\"end\":60473,\"start\":60463},{\"end\":60480,\"start\":60473},{\"end\":60490,\"start\":60480},{\"end\":60500,\"start\":60490},{\"end\":60851,\"start\":60841},{\"end\":60861,\"start\":60851},{\"end\":60870,\"start\":60861},{\"end\":61251,\"start\":61244},{\"end\":61260,\"start\":61251},{\"end\":61273,\"start\":61260},{\"end\":61555,\"start\":61541},{\"end\":61696,\"start\":61688},{\"end\":61712,\"start\":61696}]", "bib_venue": "[{\"end\":52052,\"start\":52011},{\"end\":52418,\"start\":52409},{\"end\":52822,\"start\":52810},{\"end\":53100,\"start\":53096},{\"end\":53454,\"start\":53427},{\"end\":53720,\"start\":53667},{\"end\":53913,\"start\":53827},{\"end\":54300,\"start\":54275},{\"end\":54657,\"start\":54633},{\"end\":54916,\"start\":54843},{\"end\":55309,\"start\":55268},{\"end\":55638,\"start\":55620},{\"end\":55971,\"start\":55946},{\"end\":56337,\"start\":56333},{\"end\":56641,\"start\":56556},{\"end\":57068,\"start\":57043},{\"end\":57495,\"start\":57468},{\"end\":57868,\"start\":57851},{\"end\":58156,\"start\":58077},{\"end\":58488,\"start\":58414},{\"end\":58806,\"start\":58738},{\"end\":59059,\"start\":59005},{\"end\":59336,\"start\":59262},{\"end\":59527,\"start\":59480},{\"end\":59792,\"start\":59722},{\"end\":60106,\"start\":60015},{\"end\":60515,\"start\":60500},{\"end\":60903,\"start\":60870},{\"end\":61298,\"start\":61273},{\"end\":61573,\"start\":61555},{\"end\":61731,\"start\":61712},{\"end\":52437,\"start\":52420},{\"end\":60539,\"start\":60517},{\"end\":60946,\"start\":60905}]"}}}, "year": 2023, "month": 12, "day": 17}