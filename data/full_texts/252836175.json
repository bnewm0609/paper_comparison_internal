{"id": 252836175, "updated": "2023-10-05 10:00:35.789", "metadata": {"title": "Cloud and Snow Identi\ufb01cation Based on DeepLab V3+ and CRF Combined Model for GF-1 WFV Images", "authors": "[{\"first\":\"Zuo\",\"last\":\"Wang\",\"middle\":[]},{\"first\":\"Boyang\",\"last\":\"Fan\",\"middle\":[]},{\"first\":\"Zhengyang\",\"last\":\"Tu\",\"middle\":[]},{\"first\":\"Hu\",\"last\":\"Li\",\"middle\":[]},{\"first\":\"Donghua\",\"last\":\"Chen\",\"middle\":[]}]", "venue": "Remote Sensing", "journal": "Remote Sensing", "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": ": Cloud and snow identi\ufb01cation in remote sensing images is critical for snow mapping and snow hydrology research. Aimed at the problem that the semantic segmentation model is prone to producing blurred boundaries, slicing traces and isolated small patches for cloud and snow identi\ufb01cation in high-resolution remote sensing images, the feasibility of combining DeepLab v3+ and conditional random \ufb01eld (CRF) models for cloud and snow identi\ufb01cation based on GF-1 WFV images is studied. For GF-1 WFV images, the model training and testing experiments under the conditions of different sample numbers, sample sizes and loss functions are compared. The results show that, \ufb01rstly, when the number of samples is 10,000, the sample size is 256 \u00d7 256, and the loss function is the Focal function, the model accuracy is the optimal and the Mean Intersection over Union (MIoU) and the Mean Pixel Accuracy (MPA) reach 0.816 and 0.918, respectively. Secondly, after post-processing with the CRF model, the MIoU and the MPA are improved to 0.836 and 0.941, respectively, compared with those without post-processing. Moreover, the misclassi\ufb01cations such as blurred boundaries, slicing traces and isolated small patches are signi\ufb01cantly reduced, which indicates that the combination of the DeepLab v3+ and CRF models has high accuracy and strong feasibility for cloud and snow identi\ufb01cation in high-resolution remote sensing images. The conclusions can provide a reference for high-resolution snow mapping and hydrology applications using deep learning models.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/remotesensing/WangFTLC22", "doi": "10.3390/rs14194880"}}, "content": {"source": {"pdf_hash": "dec57c75a39046c899e3b3ce565a562525be29aa", "pdf_src": "ScienceParsePlus", "pdf_uri": null, "oa_url_match": false, "oa_info": {"license": "CCBY", "open_access_url": "https://www.mdpi.com/2072-4292/14/19/4880/pdf?version=1664524578", "status": "GOLD"}}, "grobid": {"id": "77732d3a02b7eae7fc0f924cc43439fda9af8b92", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/dec57c75a39046c899e3b3ce565a562525be29aa.txt", "contents": "\nCitation: Identification Based on DeepLab V3+ and CRF Combined Model for GF-1\nPublished: 30 September 2022\n\nZ ; Wang \nSchool of Geography and Tourism\nAnhui Normal University\n241002WuhuChina\n\nB ; Fan \nSchool of Geography and Tourism\nAnhui Normal University\n241002WuhuChina\n\nZ ; Tu \nSchool of Geography and Tourism\nAnhui Normal University\n241002WuhuChina\n\nH ; Li \nSchool of Geography and Tourism\nAnhui Normal University\n241002WuhuChina\n\nD Chen \nSchool of Geography and Tourism\nAnhui Normal University\n241002WuhuChina\n\nSnow Cloud \nSchool of Geography and Tourism\nAnhui Normal University\n241002WuhuChina\n\nHongyi Li \nEngineering Technology Research Center of Resources Environment and GIS\n241002WuhuChina\n\nXufeng Wang \nEngineering Technology Research Center of Resources Environment and GIS\n241002WuhuChina\n\nXiaodong Huang \nEngineering Technology Research Center of Resources Environment and GIS\n241002WuhuChina\n\nXiaohua Hao \nEngineering Technology Research Center of Resources Environment and GIS\n241002WuhuChina\n\nXiaoyan Wang \nEngineering Technology Research Center of Resources Environment and GIS\n241002WuhuChina\n\nJian Bi \nEngineering Technology Research Center of Resources Environment and GIS\n241002WuhuChina\n\nCitation: Identification Based on DeepLab V3+ and CRF Combined Model for GF-1\nPublished: 30 September 202210.3390/rs14194880Received: 1 September 2022 Accepted: 27 September 2022WFV Images. Remote Sens. 2022, 14, 4880. https://doi.org/10.3390/ rs14194880 Academic Editors:\n\n\nIntroduction\n\nAs an important part of the cryosphere, snow is one of the most active natural elements on the earth's surface [1]. Snow cover is the product of atmospheric circulation and plays an extremely important role in the Earth's climate system because its changes can, in turn, affect the climate by changing the surface energy balance, water cycle and atmospheric circulation [2]. Snow cover change also has a wide and profound impact on the future ecological security, environmental security and social economy [3]. With the rapid improvement in the spatial resolution of remote sensing images, high-resolution snow cover identification and mapping have attracted attention in the field of hydrology and water resources. Due to the lack of short-wave infrared bands, the commonly used spectrum-based cloud and snow identification algorithm is difficult to apply in high-resolution remote sensing images. This means that the study of cloud and snow identification methods for high-resolution remote sensing images has become one of the important directions of snow remote sensing research.\n\nThe current algorithms for cloud and snow identification in remote sensing images mainly include the spectral feature method, spatial texture method and pattern recognition method, and so on [4]. Among these, the spectral feature method is mature and widely used for cloud and snow identification in medium and low spatial resolution remote sensing images with a short-wave infrared band, but it cannot be used for cloud and snow\n\n\nData and Methodology\n\n\nGF-1 WFV Data\n\nThe high-resolution remote sensing image used in this paper is the Wide Field View (WFV) sensor data of China Gaofen-1 (GF-1) satellite. The orbit height of GF-1 satellite is 645 km. The image of WFV sensor contains four bands of red, green, blue and near-infrared, with a spatial resolution of 16 m and a width of 800 km. The specific parameters of GF-1 WFV are shown in Table 1. The specific data used in this paper are listed in Table 2. A total of ten GF-1 WFV data images from November 2017 to October 2020 were used. Among them, seven images were used for model training and validation, and the other three images were used for model testing. Radiometric calibration and atmospheric correction of these images was performed before sample labeling and model training. \n\n\nSample Labeling\n\nSince cloud and snow cover vary frequently with time, it is necessary to label samples by manual vectorization. The labeling categories are divided into three categories, which are snow, cloud and background. Considering the difficulty and limited accuracy of manual labeling for snow in shadows, both mountain shadows and cloud shadows are annotated as background samples in order to not affect the accuracy of model training and testing. Firstly, the regions with relatively concentrated cloud and snow in the seven training and validation images are manually vectorized and labeled, and the labeled regions are cropped to a total of 2000 pieces of sample with 256 \u00d7 256 pixel size and four bands. Secondly, in order to avoid overfitting of the model due to the small amount of training samples and to improve the robustness of the model, in this paper, the data augmentation methods such as rotation, Blur transform and adding Gaussian noise are used to increase the amount of samples. Here, the above 2000 pieces of sample are expanded to 10,000. These 10,000 pieces of sample with a size of 256 \u00d7 256 \u00d7 4 pixels are all used as the training and validation set of the cloud and snow identification neural network model, in which the training subset accounts for 75% and the validation subset accounts for 25%. At the same time, for the other three test images, the regions with relatively concentrated cloud and snow are only manually vectorized and annotated, without cropping and data augmentation, and the annotation results are directly used as the test data for the accuracy evaluation. Some labeled data are shown in Figure 1.\n\nThese 10,000 pieces of sample with a size of 256 \u00d7 256 \u00d7 4 pixels are all used as the training and validation set of the cloud and snow identification neural network model, in which the training subset accounts for 75% and the validation subset accounts for 25%. At the same time, for the other three test images, the regions with relatively concentrated cloud and snow are only manually vectorized and annotated, without cropping and data augmentation, and the annotation results are directly used as the test data for the accuracy evaluation. Some labeled data are shown in Figure 1. \n\n\nDeepLab V3+ Model\n\nDeepLab v3+ is the latest model in Google's DeepLab series, and the model structure is shown in Figure 2. Compared with the DeepLab v3 model, its biggest feature is to replace most of the convolutions in the network with dilated convolutions, which enhances the ability of the model to extract dense features of images without increasing the amount of calculated parameters while obtaining a larger sensory domain. \n\n\nDeepLab V3+ Model\n\nDeepLab v3+ is the latest model in Google's DeepLab series, and the model structure is shown in Figure 2. Compared with the DeepLab v3 model, its biggest feature is to replace most of the convolutions in the network with dilated convolutions, which enhances the ability of the model to extract dense features of images without increasing the amount of calculated parameters while obtaining a larger sensory domain.\n\nThe skeleton network of the DeepLab v3+ encoder part is an Xception network with atrous convolution. The network is developed based on Inception v3+, and the model structure is similar to the residual connection in ResNet. It is considered that spatial correlations and inter-channel correlations should be dealt with separately. Therefore, Depthwise separable convolution is used to divided the ordinary convolution into Depthwise convolution and Pointwise convolution. Deepwise convolution performs spatial convolution only for each channel eigenvalue independently, and Pointwise convolution only performs for different channel eigenvalues of each pixel, which can reduce parameters and computation, and reduce computational complexity and maintain similar performance [21]. Xception replaces all the maximum pooling layer operations with depth separation convolution with step size without modifying the entry flow, middle flow and exit flow structure of the traditional entry flow network. Finally, the same as DeepLab v3, the Atrous Spatial Pyramid Pooling (ASPP), is used to extract the context information of remote sensing images at four different scales in four different sensory domains, so as to achieve robust segmentation and thus improve the segmentation effect.\n\nRemote Sens. 2022, 14, x FOR PEER REVIEW 5 of 19 Figure 2. DeepLab v3+ structure [21]. It adopts encoder-decoder structure. The arrows in the figure represent the data flow. The red, blue and gray in the prediction map represent different ground objects.\n\nThe skeleton network of the DeepLab v3+ encoder part is an Xception network with atrous convolution. The network is developed based on Inception v3+, and the model structure is similar to the residual connection in ResNet. It is considered that spatial correlations and inter-channel correlations should be dealt with separately. Therefore, Depthwise separable convolution is used to divided the ordinary convolution into Depthwise convolution and Pointwise convolution. Deepwise convolution performs spatial convolution only for each channel eigenvalue independently, and Pointwise convolution only performs for different channel eigenvalues of each pixel, which can reduce parameters and computation, and reduce computational complexity and maintain similar performance [21]. Xception replaces all the maximum pooling layer operations with depth separation convolution with step size without modifying the entry flow, middle flow and exit flow structure of the traditional entry flow network. Finally, the same as DeepLab v3, the Atrous Spatial Pyramid Pooling (ASPP), is used to extract the context information of remote sensing images at four different scales in four different sensory domains, so as to achieve robust segmentation and thus improve the segmentation effect.\n\nThe decoding part of DeepLab v3+ model refers to the step-skipping connection mode of the Full Coiler Network (FCN), and fuses the low-level detail features in the encoder part with the high-level features' output from the encoder part by convolutional dimension reduction. Then the feature fusion image is restored to the original image size using 1 \u00d7 1 convolution and bilinear interpolation upsampling method. Finally, the Softmax activation function is also used to classify each pixel.\n\n\nLoss Function\n\nIn the training process of neural network, the loss function is used to calculate the difference between the model predicted value and the true label value, to optimally adjust the parameters and training process in the model, and to evaluate the training results of the model. It is inversely proportional to the accuracy of the model. Cross Entropy Loss (CE) is generally used as the loss function in image segmentation, examines each pixel one by one, but is prone to fitting difficulties caused by too small loss when the sample amount of different types is extremely unbalanced. In medical image processing, because the anatomical structure of interest usually occupies only a small area in the scanned image, the  [21]. It adopts encoder-decoder structure. The arrows in the figure represent the data flow. The red, blue and gray in the prediction map represent different ground objects.\n\nThe decoding part of DeepLab v3+ model refers to the step-skipping connection mode of the Full Coiler Network (FCN), and fuses the low-level detail features in the encoder part with the high-level features' output from the encoder part by convolutional dimension reduction. Then the feature fusion image is restored to the original image size using 1 \u00d7 1 convolution and bilinear interpolation upsampling method. Finally, the Softmax activation function is also used to classify each pixel.\n\n\nLoss Function\n\nIn the training process of neural network, the loss function is used to calculate the difference between the model predicted value and the true label value, to optimally adjust the parameters and training process in the model, and to evaluate the training results of the model. It is inversely proportional to the accuracy of the model. Cross Entropy Loss (CE) is generally used as the loss function in image segmentation, examines each pixel one by one, but is prone to fitting difficulties caused by too small loss when the sample amount of different types is extremely unbalanced. In medical image processing, because the anatomical structure of interest usually occupies only a small area in the scanned image, the Dice loss function is proposed in V-Net [22] to increase the weight of the foreground area, which prevents the model from falling into the local minimum of the loss function during the training process. In the field of target detection, the Focal loss function [23] is usually used to solve the problem of severe imbalance in the proportion of positive and negative samples. In the case of unbalanced categories, it can make the loss smaller for samples with high prediction probability and the loss larger for samples with low prediction probability, thus strengthening the attention of the model on the positive samples. In this study, because there are many more background samples and more cloud samples than snow samples in the labeled dataset, the Focal function is chosen as the loss function, which can effectively solve the problem that the proportion of foreground samples is too small. The formulas are as follows: \nCross Entropy : E = \u2212 \u2211 n i=1 P i log(Q i ),(1)Dice : E = 1 \u2212 \u2211 n i=1 P i Q i + \u03b5 \u2211 n i=1 P i + Q i + \u03b5 \u2212 \u2211 n i=1 (1 \u2212 P i )(1 \u2212 Q i ) + \u03b5 \u2211 n i=1 2 \u2212 P i \u2212 Q i + \u03b5 ,(2)Focal : E = \u2212 \u2211 n i=1 (1 \u2212 Q i ) \u03b3 P i log(Q i ),(3)\nwhere n is the number of categories; P i is the true probability distribution; Q i is the model prediction probability distribution; the value of \u03b5 in the Dice loss function formula is generally one to avoid the gradient explosion caused by denominator being zero or too small. \u03b3 in the Focal loss function is the parameter that controls the orientation of the sample tendency, generally takes the value of zero to five. In this paper, a triple classification (cloud, snow, background) problem is discussed, so n is three, P i and Q i are 256 \u00d7 256 matrices, where P i is the sample label image, Qi is the model classification image.\n\n\nConditional Random Field\n\nThe conditional random field model is a probabilistic graph model proposed by Lafferty et al. (2001) [24]. It combines the unary potential energy of a single pixel and the pairwise potential energy between neighboring pixels, so that the spatial pixels are assigned to the same label. It is usually applied to smooth the segmentation maps with edge noise. However, its structure cannot model the pixels far apart and is prone to over-smoothing of target object boundaries. To solve this problem, Kr\u00e4henb\u00fchl et al. (2011) proposed the concept of fully connected CRF based on CRF [25]. In fully connected CRF, the energy of predicted label value X is defined as\nE(X) = \u2211 i \u03c8 u (x i ) + \u2211 i<j \u03c8 p (x i , x j ),(4)\nwhere, i, j represent pixels; x i and x j are the labels assigned to pixels i and j, respectively; \u03c8 u (x i ) represents unary potential energy; \u03c8 p x i , x j represents pairwise potential energy. The unary potential energy represents the class probability distribution obtained from independent prediction of each pixel i in the classification image to be improved in accuracy, which contains much noise and is discontinuous. The pairwise potential energy represents a fully connected graph that connects all pixels of the image and classifies pixels with the same properties into the same category as much as possible. When the energy E(X) of fully connected CRF is smaller, the predicted pixel category label X is more accurate. The average field approximation is generally used to iterate and find the minimum energy function so as to obtain the result of improved boundary accuracy. In this paper, the pixel category distribution probability map output from DeepLab v3+ neural network model is taken as unary potential energy, and the original high-resolution remote sensing image is taken as pairwise potential energy.\n\n\nEvaluation Indicators\n\nIn order to explore the advantages and disadvantages of different neural network models in cloud and snow identification, the accuracy criteria in this paper are Mean Intersection over Union (MIoU) and the Mean Pixel Accuracy (MPA) [26,27]. The MIoU is the result of averaging the ratio of the intersection set to the union set of the true values derived from each class of prediction results, which can represent the accuracy of each class. MPA is the result of averaging the proportion of correctly classified pixels for each class. Both evaluation indicators take values in the range of zero to one, with closer to one representing better segmentation. Both of them are commonly used criteria to verify the accuracy of neural network model. Therefore, these two indicators are used as quantitative research criteria in this paper. The expressions are as follows where there are a total of K + 1 label categories (K classes of objects and one other category) in the classified image; n ii is the number of correct predictions of class i; n ij is the number of class i pixels predicted as class j; and n ji is the number of class j pixels predicted as class i.\nMIoU = 1 K + 1 \u2211 K I=0 ( n ii \u2211 K j=0 n ij + n ji \u2212 n ii ),(5)MPA = 1 K + 1 \u2211 K I=0 ( n ii \u2211 K j=0 n ij ),(6)\n\nExperimental Environment\n\nThe experimental platform in this paper is an Inter (R) Core (TM) i7-9700F @ 3.0 GHz CPU, NVIDIA GeForce RTX 2060 SUPPER 8 GB graphics card and 16.0 GB running memory. In terms of software environment, Python is used as the main programming language under Windows 10 system, and the high-performance computing library CUDA11.0 for the display card is installed. The deep learning framework adopts TensorFlow 2.5.0 and Keras 2.3.1. In the training process, Adam is selected as the optimizer to update the network gradient, and Softmax activation function is used to classify each pixel. The learning rate is set to 0.001, the batch size is 5 and the iteration number (epoch) is 200.\n\n\nExperiments and Results\n\nThe number of samples, sample size and loss function have a certain impact on the accuracy of the semantic segmentation neural network model, and the post-processing work will also affect the identification results. Generally, the smaller the sample number, the easier it is to cause overfitting. If the sample size is too small, it is impossible to learn to obtain more spatial semantic information, and it is easy to misclassify snow and cloud with similar spectral characteristics; if the sample size is too large, the model training time increases and the generalization ability decreases. At the same time, the model training accuracy will be different while using the different loss functions. Therefore, this study analyzed the effects of different sample numbers, sample sizes and loss functions on the DeepLab v3+ model for cloud and snow identification, as well as the impact of CRF postprocessing on the accuracy of cloud and snow identification, so as to provide a reference for the optimal parameter selection of the semantic segmentation neural network model for cloud and snow identification.\n\n\nSample Number Analysis\n\nIn order to investigate the optimal number of samples required for model training, 2000, 5000 and 10,000 samples were randomly taken from the 10,000 training and validation sets prepared above, respectively, and input to the DeepLab v3+ model, in turn, for training. Among them, 2000 samples were directly taken from those training and validation samples without data augmentation. The batch size was 5, epoch was 200 and neural network models for cloud and snow identification trained by different sample numbers were obtained. The curves of loss value and the accuracy of model training with each batch are shown in Figure 3.\n\nIt can be seen from Figure 3 that the larger the number of samples, the smaller the fluctuation in the training loss value and training accuracy, and the higher the stability of the model. When the number of samples is 2000, the training loss value and training accuracy fluctuate greatly, and the model stability is very low. When the number of samples is 5000 and the iteration times is more than 100, the training loss value and training accuracy are comparable to those when the number of samples is 10,000, but the stability of the model is still insufficient. When the number of samples is 10,000 and the time of iterations reaches 170, the model training accuracy is high and the stability is strong. Therefore, the number of 10,000 training samples is more suitable for training the cloud and snow identification model with high accuracy and stability. Figure 4 shows the prediction maps for the test data by using the models with different sample numbers. The prediction accuracies are shown in Table 3. As seen in Figure 4, when sample numbers are 2000 and 5000, there are more misclassified cloud and snow pixels. Snow IoU, Cloud IoU, Snow PA and Cloud PA, as well as MIoU and MPA, are relatively low. In addition, compared with the number of 2000 samples, the prediction accuracy of the model trained by 5000 samples has not improved, and even Cloud IoU, MIoU and Snow PA have some reduction. When the number of samples is 10,000, the misclassified pixels of cloud and snow are significantly reduced. The MIoU and MPA are 0.816 and 0.918, respectively, which are 0.066 and 0.061 higher than the accuracy of 5000 samples. This is a significant improvement. In summary, the model training accuracy, stability and prediction accuracy are optimal when the number of samples is 10,000. \n\n\nSample Number Analysis\n\nIn order to investigate the optimal number of samples required for model training, 2000, 5000 and 10,000 samples were randomly taken from the 10,000 training and validation sets prepared above, respectively, and input to the DeepLab v3+ model, in turn, for training. Among them, 2000 samples were directly taken from those training and validation samples without data augmentation. The batch size was 5, epoch was 200 and neural network models for cloud and snow identification trained by different sample numbers were obtained. The curves of loss value and the accuracy of model training with each batch are shown in Figure 3. It can be seen from Figure 3 that the larger the number of samples, the smaller the fluctuation in the training loss value and training accuracy, and the higher the stability of the model. When the number of samples is 2000, the training loss value and training accuracy fluctuate greatly, and the model stability is very low. When the number of samples is 5000 and the iteration times is more than 100, the training loss value and training accuracy are comparable to those when the number of samples is 10,000, but the stability of the model is still insufficient. When the number of samples is 10,000 and the time of iterations reaches 170, the model training accuracy is high and the stability is strong. Therefore, the number of 10,000 training samples is more suitable for training the cloud and snow identification model with high accuracy and stability. Figure 4 shows the prediction maps for the test data by using the models with different sample numbers. The prediction accuracies are shown in Table 3. As seen in Figure 4, when sample numbers are 2000 and 5000, there are more misclassified cloud and snow pixels. Snow IoU, Cloud IoU, Snow PA and Cloud PA, as well as MIoU and MPA, are relatively low. In addition, compared with the number of 2000 samples, the prediction accuracy of the model trained by 5000 samples has not improved, and even Cloud IoU, MIoU and Snow PA have some reduction. When the number of samples is 10,000, the misclassified pixels of cloud and snow are significantly reduced. The MIoU and MPA are 0.816 and 0.918, respectively, which are 0.066 and 0.061 higher than the accuracy of 5000 samples. This is a significant improvement. In summary, the model training accuracy, stability and prediction accuracy are optimal when the number of samples is 10,000.     \n\n\nSample Size Analysis\n\nIn order to analyze the appropriate sample size for cloud and snow identification in the GF-1 WFV image using the DeepLab v3+ model, the previous 10,000 samples of 256 \u00d7 256 size were cut into 10,000 samples of 64 \u00d7 64 size and 10,000 samples of 128 \u00d7 128 size, respectively. These samples with different sizes were input to the DeepLab v3+ model for training in turn. The loss function was set to the Focal function, the batch size was set to 5 and the epoch was set to 200. The variation curves of the loss value and accuracy of model training with the iteration times are shown in Figure 5. \n\n\nSample Size Analysis\n\nIn order to analyze the appropriate sample size for cloud and snow identification in the GF-1 WFV image using the DeepLab v3+ model, the previous 10,000 samples of 256 \u00d7 256 size were cut into 10,000 samples of 64 \u00d7 64 size and 10,000 samples of 128 \u00d7 128 size, respectively. These samples with different sizes were input to the DeepLab v3+ model for training in turn. The loss function was set to the Focal function, the batch size was set to 5 and the epoch was set to 200. The variation curves of the loss value and accuracy of model training with the iteration times are shown in Figure 5.\n\nAs seen in Figure 5, in the early stage of training, the larger the sample size, the faster the fitting speed is. As the number of iterations increases, the differences in model training loss between different sample sizes gradually decrease, as does the difference in model training accuracy. However, within 200 iterations, the training loss value of the model trained by the sample sizes of 256 \u00d7 256 is always better than those trained by the sample sizes of 64 \u00d7 64 and 128 \u00d7 128; the training accuracy of the model is always higher than that of the sample sizes of 64 \u00d7 64 and 128 \u00d7128 accuracy; and the model stability is better when the sample sizes is 256 \u00d7 256, and the model tends to be stable when the number of iterations reaches 170.  Figure 6 shows the prediction maps for the test data by using models with different sample sizes, and the prediction accuracies are shown in Table 4. As seen in Figure 6 and Table 4, when the training sample sizes are 64 \u00d7 64 and 128 \u00d7 128, the cloud and snow are seriously misclassified in the prediction maps, and Snow IoU, Cloud IoU, Snow PA and Cloud PA, as well as MIoU and MPA are relatively low. The MIoU and MPA are only 0.754 and 0.862, the prediction accuracy of the 128 \u00d7 128 size is not improved compared with that of the 64 \u00d7 64 size, and the Cloud IoU, MIoU, Cloud PA and MPA are even reduced to a certain extent; in addition, the classification map of 128 \u00d7 128 size shows serious slicing traces. When the training sample size is 256 \u00d7 256, the prediction accuracy of the model is greatly improved, and the misclassified pixels of cloud and snow are significantly reduced. The MIoU and MPA reach 0.816 and 0.918, respectively, and the Cloud PA even reaches 0.934. It can be seen that the appropriate increase in sample size can reduce some misclassification pixels and improve the accuracy of the model, but at the same time, it also makes the model training slower and less efficient. In summary, when the sample size is 256 \u00d7 256, the training accuracy, stability and prediction accuracy of the model are relatively better. As seen in Figure 5, in the early stage of training, the larger the sample size, the faster the fitting speed is. As the number of iterations increases, the differences in model training loss between different sample sizes gradually decrease, as does the difference in model training accuracy. However, within 200 iterations, the training loss value of the model trained by the sample sizes of 256 \u00d7 256 is always better than those trained by the sample sizes of 64 \u00d7 64 and 128 \u00d7 128; the training accuracy of the model is always higher than that of the sample sizes of 64 \u00d7 64 and 128 \u00d7128 accuracy; and the model stability is better when the sample sizes is 256 \u00d7 256, and the model tends to be stable when the number of iterations reaches 170. Figure 6 shows the prediction maps for the test data by using models with different sample sizes, and the prediction accuracies are shown in Table 4. As seen in Figure 6 and Table 4, when the training sample sizes are 64 \u00d7 64 and 128 \u00d7 128, the cloud and snow are seriously misclassified in the prediction maps, and Snow IoU, Cloud IoU, Snow PA and Cloud PA, as well as MIoU and MPA are relatively low. The MIoU and MPA are only 0.754 and 0.862, the prediction accuracy of the 128 \u00d7 128 size is not improved compared with that of the 64 \u00d7 64 size, and the Cloud IoU, MIoU, Cloud PA and MPA are even reduced to a certain extent; in addition, the classification map of 128 \u00d7 128 size shows serious slicing traces. When the training sample size is 256 \u00d7 256, the prediction accuracy of the model is greatly improved, and the misclassified pixels of cloud and snow are significantly reduced. The MIoU and MPA reach 0.816 and 0.918, respectively, and the Cloud PA even reaches 0.934. It can be seen that the appropriate increase in sample size can reduce some misclassification pixels and improve the accuracy of the model, but at the same time, it also makes the model training slower and less efficient. In summary, when the sample size is 256 \u00d7 256, the training accuracy, stability and prediction accuracy of the model are relatively better.     \n\n\nSelection of Loss Function\n\nTo investigate the accuracy differences of different loss functions on the DeepLab v3+ model for cloud and snow identification, the CE loss function, Dice loss function and Focal loss function were selected, respectively, in the experiment, and 10,000 pieces of 256 \u00d7 256 size samples were input to train the DeepLab v3+ models for cloud and snow identification. The batch size was set to five, and the epoch was 200. The changes in training loss value and training accuracy were recorded, as shown in Figure 7. \n\n\nSelection of Loss Function\n\nTo investigate the accuracy differences of different loss functions on the DeepLab v3+ model for cloud and snow identification, the CE loss function, Dice loss function and Focal loss function were selected, respectively, in the experiment, and 10,000 pieces of 256 \u00d7 256 size samples were input to train the DeepLab v3+ models for cloud and snow identification. The batch size was set to five, and the epoch was 200. The changes in training loss value and training accuracy were recorded, as shown in Figure 7. It can be seen from Figure 7 that the training loss curve of Dice converges faster and the loss value is smaller in the whole process of training, but the training accuracies of these three loss functions are relatively close. In terms of the stability of training accuracy, the CE function has the most stable performance, but the difference with the Dice and Focal functions is not obvious. Figure 8 shows the prediction maps for the test data by using models under different loss functions, and the prediction accuracies are shown in Table 5. From Figure 8 and Table 5, it can be seen that the model using the CE loss function has more snow pixels misclassified as cloud, and the slicing traces are obvious. Compared with the Dice function and Focal function, the prediction accuracy of the model using the CE function is also the lowest, with MIoU and MPA only 0.741 and 0.827, respectively. The model accuracy using the Dice or Focal loss functions improves somewhat. In particular, because the Focal function increases the focus of the model on snow and cloud samples, the problem of an unbalanced number of samples of each category in the training samples set improves. In the model prediction maps, the misclassified pixels of cloud and snow are significantly reduced, and the model prediction accuracy is significantly improved. The Cloud PA reaches 0.934 and the Snow PA reaches 0.891. The MIoU and MPA are higher than those of CE and the Dice loss function. In summary, the training accuracies of the models using the CE, Dice and Focal functions are comparable, but the model using the Focal loss function has higher prediction accuracy and stronger generalization ability.  It can be seen from Figure 7 that the training loss curve of Dice converges faster and the loss value is smaller in the whole process of training, but the training accuracies of these three loss functions are relatively close. In terms of the stability of training accuracy, the CE function has the most stable performance, but the difference with the Dice and Focal functions is not obvious. Figure 8 shows the prediction maps for the test data by using models under different loss functions, and the prediction accuracies are shown in Table 5. From Figure 8 and Table 5, it can be seen that the model using the CE loss function has more snow pixels misclassified as cloud, and the slicing traces are obvious. Compared with the Dice function and Focal function, the prediction accuracy of the model using the CE function is also the lowest, with MIoU and MPA only 0.741 and 0.827, respectively. The model accuracy using the Dice or Focal loss functions improves somewhat. In particular, because the Focal function increases the focus of the model on snow and cloud samples, the problem of an unbalanced number of samples of each category in the training samples set improves. In the model prediction maps, the misclassified pixels of cloud and snow are significantly reduced, and the model prediction accuracy is significantly improved. The Cloud PA reaches 0.934 and the Snow PA reaches 0.891. The MIoU and MPA are higher than those of CE and the Dice loss function. In summary, the training accuracies of the models using the CE, Dice and Focal functions are comparable, but the model using the Focal loss function has higher prediction accuracy and stronger generalization ability.   \n\n\nConditional Random Field Post-Processing\n\nIn order to investigate the effectiveness of CRF post-processing on the accuracy improvement of the DeepLab v3+ model for cloud and snow classification, the CRF model is used to post-process the cloud and snow classification results of DeepLab v3+ model. The cloud and snow classification map predicted by the DeepLab v3+ model on the test data is taken as the univariate potential energy of the conditional random field, and the GF-1 WFV image is used as the unary potential energy. The mean field approximation method is used to iteratively find the minimum energy function E(X). The smaller E(X) is, the more accurate the predicted pixel class label X is, resulting in a classification map with improved boundary accuracy, as shown in Figure 9. \n\n\nConditional Random Field Post-Processing\n\nIn order to investigate the effectiveness of CRF post-processing on the accuracy improvement of the DeepLab v3+ model for cloud and snow classification, the CRF model is used to post-process the cloud and snow classification results of DeepLab v3+ model. The cloud and snow classification map predicted by the DeepLab v3+ model on the test data is taken as the univariate potential energy of the conditional random field, and the GF-1 WFV image is used as the unary potential energy. The mean field approximation method is used to iteratively find the minimum energy function E(X). The smaller E(X) is, the more accurate the predicted pixel class label X is, resulting in a classification map with improved boundary accuracy, as shown in Figure 9.   Figure 9 shows the comparison of prediction maps before and after CRF post-processing, and Figure 10 shows the comparison of their local details before and after post-processing. From Figures 9 and 10, it is obvious that the DeepLab v3+ model misidentifies some isolated small patches of snow as clouds; and the boundaries of the snow are smoother and different from the true snow cover. In addition, the semantic segmentation neural network classifies the image after slicing, and then splices the classified slices. Different slices will take global consideration, respectively, so that different prediction results are generated at the boundaries of adjacent slices, thus leading to some slicing traces in the final spliced classification map. After the CRF post-processing, the misclassified clouds are correctly identified as snow again, and the boundaries of the snow cover are also finer and more closely match the true ground objects; at the same time, the slicing traces and isolated small patches are also eliminated.\n\nDeepLab v3+ prediction map and the prediction map of DeepLab v3+ & CRF at three different dates, respectively. Figure 9 shows the comparison of prediction maps before and after CRF post-processing, and Figure 10 shows the comparison of their local details before and after postprocessing. From Figures 9 and 10, it is obvious that the DeepLab v3+ model misidentifies some isolated small patches of snow as clouds; and the boundaries of the snow are smoother and different from the true snow cover. In addition, the semantic segmentation neural network classifies the image after slicing, and then splices the classified slices. Different slices will take global consideration, respectively, so that different prediction results are generated at the boundaries of adjacent slices, thus leading to some slicing traces in the final spliced classification map. After the CRF post-processing, the misclassified clouds are correctly identified as snow again, and the boundaries of the snow cover are also finer and more closely match the true ground objects; at the same time, the slicing traces and isolated small patches are also eliminated. In order to quantitatively analyze the effectiveness of CRF post-processing on the accuracy improvement of cloud and snow identification, The MIoU and MPA of the classification maps before and after CRF post-processing were calculated respectively and are shown in Table 6. It can be seen that Snow IoU, Cloud IoU and Cloud PA, as well as MIoU and MPA, are effectively improved, where MIoU and MPA are improved from 0.816 and 0.918 to 0.836 and 0.941, respectively, and the improvement compared with no post-processing is 0.020 and 0.023, respectively. In summary, the combined model of DeepLab v3+ and CRF can effectively correct the misclassification problems such as blurred boundaries, slicing traces and isolated small patches, thus further improving the cloud and snow identification accuracy. \n\n\nDiscussion\n\nWhen conducting image semantic segmentation experiments, it can be better to use authoritative public datasets. Tian et al. (2019) summarized some common public datasets for image semantic segmentation [28]. PASCAL VOC 2012 is one of the public standard datasets commonly used in the field of computer vision [29], and many scholars have studied the effectiveness and generalization of models using public datasets [30][31][32]. However, due to the frequent temporal changes in snow and cloud, there are few publicly available high spatial resolution cloud and snow labeling datasets. Therefore, the training datasets used in this paper are all completed by manual visual annotation. Since the annotation of deep learning datasets is time-consuming and labor-intensive, and the number of samples is relatively insufficient, many scholars have used data augmentation methods to increase the amount of sample data, including operations horizontal flips, vertical flips, diagonal mirroring and random scaling [33,34]. In this paper, various data augmentation operations are also used to increase the sample number of the labeled dataset, eliminate the overfitting caused by the small number of samples and improve the robustness of the model. The experimental results of different sample numbers in Section 3.1 also demonstrate that increasing the sample number by data augmentation can improve the identification accuracy of the model. Wieland et al. (2019) achieved an accuracy of 0.89 for cloud and snow identification in multi-spectral satellite images based on the improved U-Net convolutional neural network [35]. The Fmask 4.0 algorithm proposed by Qiu et al. (2019) has an overall accuracy of 0.924 for cloud identification in Landsat 4-7 images [36]. In the tests of this paper, the accuracy for cloud and snow identification using only the DeepLab v3+ neural network is 0.918. However, as seen from the prediction maps above, there are still some misclassification problems such as blurred boundaries, slicing traces and isolated small patches. The CRF model can capture fine-grained information and infer the output class of target pixels by combining the target pixels with the nearby pixels, which is not achieved by the convolutional neural network focusing on local information. Some scholars previously used the CRF to extract the target features in remote sensing images, and the results show that the CRF model can improve the accuracy of the segmentation results [37,38]. In this paper, CRF post-processing for the predicted maps of the DeepLab v3+ model is carried out to further improve the pixel accuracy. The accuracy reaches 0.941, which is 0.023 higher than the accuracy before CRF post-processing, and 0.051 and 0.017 higher than the accuracy of the U-Net and Fmask 4.0 models, respectively, and the misclassification problems of blurred boundaries, slicing traces and isolated small patches are corrected. This further demonstrates that the CRF post-processing method can effectively optimize the boundary of cloud and snow and improve the accuracy of the segmentation. Therefore, it is feasible to combine the DeepLab v3+ and CRF models for cloud and snow identification in high-resolution remote sensing images.\n\n\nConclusions\n\nAimed at the problem that it is difficult to use the snow index algorithm to identify cloud and snow in high-resolution remote sensing images lacking the short-wave infrared band, and the problem that the semantic segmentation neural network model is prone to producing blurred boundaries, slicing traces and isolated small patches, in this paper, the feasibility and the optimal parameter selection of the DeepLab v3+ and CRF combined model for cloud and snow identification in high-resolution remote sensing images are explored through the comparative experimental analysis of different sample numbers, sample sizes, loss functions and CRF post-processing using GF-1 WFV images. The main conclusions are as follows:\n\n(1) The DeepLab v3+ model is used to identify cloud and snow in a GF-1 WFV image.\n\nWhen the number of samples is 10,000, the sample size is 256 \u00d7 256, and the loss function is the Focal function, the model has the optimal accuracy and strong stability, where the MIoU and the MPA reach 0.816 and 0.918, respectively. (2) For the cloud and snow identification, CRF post-processing can significantly improve the misclassification problems such as blurred boundaries, slicing traces and isolated small patches caused by the semantic segmentation of neural network model. Compared with the prediction maps without post-processing, the prediction accuracy after CRF post-processing is effectively improved. The MIoU and MPA are improved to 0.836 and 0.941, respectively, which proves the effectiveness of the post-processing method. (3) The DeepLab v3+ and CRF combined model for cloud and snow identification in a high-resolution remote sensing image has high accuracy and strong feasibility. The conclusions can provide a technical reference for the application of deep learning algorithms in high-resolution snow mapping and hydrological application.\n\nThe sample accuracy is a key factor affecting the prediction results of the semantic segmentation model. The manual labeling accuracy of cloud and snow samples is greatly affected by human factors; in particular, the manual labeling of snow in shadows is more difficult and has limited accuracy. Therefore, this paper treats both mountain shadows and cloud shadows as background categories. This treatment has certain limitations, which reduces the accuracy of cloud and snow identification. Therefore, how to reduce the influence of human factors on the accuracy of samples and improve the accuracy of cloud and snow identification, especially to improve the accuracy of snow identification in shadow areas, is the direction of further research. The authors will next try to use a weakly supervised learning method to identify cloud and snow in high-resolution remote sensing images to reduce the impact of human factors.\n\nFigure 1 .\n1Examples of labeled dataset. Subfigures (a-f) are eight pairs of cloud and snow labels on different dates, each with remote sensing image on the left and corresponding labeled image on the right.\n\nFigure 1 .\n1Examples of labeled dataset. Subfigures (a-f) are eight pairs of cloud and snow labels on different dates, each with remote sensing image on the left and corresponding labeled image on the right.\n\nFigure 2 .\n2DeepLab v3+ structure\n\nFigure 3 .\n3The change curve of training loss value with the iterations times (a) and the change curve of training accuracy with the iterations times (b) under different sample numbers.\n\nFigure 3 .\n3The change curve of training loss value with the iterations times (a) and the change curve of training accuracy with the iterations times (b) under different sample numbers. Remote Sens. 2022, 14, x FOR PEER REVIEW 9 of 19\n\nFigure 4 .\n4Comparison of cloud and snow identification under different sample numbers. The three columns of subfigures (a-c) represent the original image, the label image, and the prediction maps under the sample number of 2000, 5000, and 10,000 at three different dates, respectively.\n\nFigure 4 .\n4Comparison of cloud and snow identification under different sample numbers. The three columns of subfigures (a-c) represent the original image, the label image, and the prediction maps under the sample number of 2000, 5000, and 10,000 at three different dates, respectively.\n\nFigure 5 .\n5The change curve of training loss value with the iterations times (a) and the change curve of training accuracy with the iterations times (b) under different sample sizes.\n\nFigure 5 .\n5The change curve of training loss value with the iterations times (a) and the change curve of training accuracy with the iterations times (b) under different sample sizes.\n\nFigure 6 .\n6Comparison of cloud and snow identification under different sample sizes. The three columns of subfigures (a-c) represent the original image, the label image, and the prediction maps under the sample size of 64 \u00d7 64, 128 \u00d7 128, and 256 \u00d7 256 at three different dates, respectively.\n\nFigure 6 .\n6Comparison of cloud and snow identification under different sample sizes. The three columns of subfigures (a-c) represent the original image, the label image, and the prediction maps under the sample size of 64 \u00d7 64, 128 \u00d7 128, and 256 \u00d7 256 at three different dates, respectively.\n\nFigure 7 .\n7The change curve of training loss value with the iterations times (a) and the change curve of training accuracy with the iterations times (b) under different loss functions.\n\nFigure 7 .\n7The change curve of training loss value with the iterations times (a) and the change curve of training accuracy with the iterations times (b) under different loss functions.\n\nFigure 8 .\n8Comparison of cloud and snow identification under different loss functions. The three columns of subfigures (a-c) represent the original image, the label image, and the prediction maps under CE, Dice, and Focal loss functions at three different dates, respectively.\n\nFigure 8 .\n8Comparison of cloud and snow identification under different loss functions. The three columns of subfigures (a-c) represent the original image, the label image, and the prediction maps under CE, Dice, and Focal loss functions at three different dates, respectively.\n\nFigure 9 .\n9Comparison of cloud and snow identification between DeepLab v3+ and CRF post-processing. The three columns of subfigures (a-c) represent the original image, the label image, the\n\nFigure 9 .\n9Comparison of cloud and snow identification between DeepLab v3+ and CRF postprocessing. The three columns of subfigures (a-c) represent the original image, the label image, the DeepLab v3+ prediction map and the prediction map of DeepLab v3+ & CRF at three different dates, respectively.\n\nFigure 10 .\n10Post-processing cloud and snow identification comparison map (local details). The four lines of subfigures (a-d) represent the significant improvements of isolated small patches, blurred boundaries and slicing traces, respectively. The inside black rectangles show the corresponding areas where improved.\n\nTable 1 .\n1GF-1 WFV parameters.Table 2. List of data used in the paper.Sensor \nBand \nBand Range \n(\u00b5m) \n\nRadiometric \nResolution \n(Bit) \n\nSpatial \nResolution \n(m) \n\nWide Field View \n(WFV) \n\n1 \n0.45~0.52 \n\n10 \n16 \n2 \n0.52~0.59 \n3 \n0.63~0.69 \n4 \n0.77~0.89 \n\nNumber \nSensor \nScene Serial Number \nImaging Time \nRemarks \n\n1 \nWFV1 \n6013180 \n22 January 2019 \n\nModel training and \nvalidation images \n\n2 \nWFV3 \n8348146 \n31 October 2020 \n3 \nWFV4 \n6252997 \n29 March 2019 \n4 \nWFV3 \n5848541 \n8 December 2018 \n5 \nWFV4 \n5416209 \n16 August 2018 \n6 \nWFV3 \n7050682 \n5 November 2019 \n7 \nWFV2 \n8155402 \n16 September 2020 \n\n8 \nWFV1 \n4330375 \n13 November 2017 \nModel test images \n9 \nWFV3 \n6658981 \n18 July 2019 \n10 \nWFV1 \n4314475 \n9 November 2017 \n\n\n\nTable 3 .\n3Comparison of model test accuracy under different sample numbers.Sample Number Snow IoU Cloud IoU MIoU \nSnow PA Cloud PA \nMPA \n2000 \n0.761 \n0.647 \n0.756 \n0.827 \n0.760 \n0.845 \n5000 \n0.766 \n0.619 \n0.750 \n0.808 \n0.810 \n0.857 \n10,000 \n0.804 \n0.757 \n0.816 \n0.891 \n0.934 \n0.918 \n\n\n\nTable 3 .\n3Comparison of model test accuracy under different sample numbers.Sample \nNumber \nSnow IoU \nCloud IoU \nMIoU \nSnow PA \nCloud PA \nMPA \n\n2000 \n0.761 \n0.647 \n0.756 \n0.827 \n0.760 \n0.845 \n5000 \n0.766 \n0.619 \n0.750 \n0.808 \n0.810 \n0.857 \n10,000 \n0.804 \n0.757 \n0.816 \n0.891 \n0.934 \n0.918 \n\n\n\nTable 4 .\n4Comparison of model test accuracy under different sample sizes.Sample Size Snow IoU Cloud IoU \nMIoU \nSnow PA Cloud PA \nMPA \n64 \u00d7 64 \n0.761 \n0.630 \n0.754 \n0.866 \n0.795 \n0.862 \n128 \u00d7 128 \n0.764 \n0.599 \n0.748 \n0.877 \n0.691 \n0.838 \n256 \u00d7 256 \n0.804 \n0.757 \n0.816 \n0.891 \n0.934 \n0.918 \n\n\n\nTable 4 .\n4Comparison of model test accuracy under different sample sizes.Sample Size \nSnow IoU \nCloud IoU \nMIoU \nSnow PA \nCloud PA \nMPA \n\n64 \u00d7 64 \n0.761 \n0.630 \n0.754 \n0.866 \n0.795 \n0.862 \n128 \u00d7 128 \n0.764 \n0.599 \n0.748 \n0.877 \n0.691 \n0.838 \n256 \u00d7 256 \n0.804 \n0.757 \n0.816 \n0.891 \n0.934 \n0.918 \n\n\nTable 5 .\n5Comparison of model test accuracy under different loss functions.Loss Function Snow IoU Cloud IoU \nMIoU \nSnow PA Cloud PA \nMPA \nCE \n0.759 \n0.595 \n0.741 \n0.846 \n0.683 \n0.827 \nDice \n0.777 \n0.763 \n0.803 \n0.845 \n0.917 \n0.899 \nFocal \n0.805 \n0.757 \n0.816 \n0.891 \n0.934 \n0.918 \n\n\n\nTable 5 .\n5Comparison of model test accuracy under different loss functions.Loss Function \nSnow IoU \nCloud IoU \nMIoU \nSnow PA \nCloud PA \nMPA \n\nCE \n0.759 \n0.595 \n0.741 \n0.846 \n0.683 \n0.827 \nDice \n0.777 \n0.763 \n0.803 \n0.845 \n0.917 \n0.899 \nFocal \n0.805 \n0.757 \n0.816 \n0.891 \n0.934 \n0.918 \n\n\nTable 6 .\n6Comparison results of different models.Model \nSnow IoU \nCloud IoU \nMIoU \nSnow PA \nCloud PA \nMPA \n\nDeepLab v3+ \n0.805 \n0.757 \n0.816 \n0.891 \n0.934 \n0.918 \nDeepLab v3+ and CRF \n0.829 \n0.787 \n0.836 \n0.890 \n0.997 \n0.941 \n\n\nRemote Sens. 2022,14, 4880   \nRemote Sens. 2022, 14, x FOR PEER REVIEW\nData Availability Statement: Not applicable.Conflicts of Interest:The authors declare no conflict of interest.Remote Sens. 2022,14,4880\nThe Cryosphere and Global Change. Y Shi, G Cheng, 10.16418/j.issn.1000-3045.1991.04.002Bull. Chin. Acad. Sci. 4Shi, Y.; Cheng, G. The Cryosphere and Global Change. Bull. Chin. Acad. Sci. 1991, 4, 287-291. [CrossRef]\n\nProgress in studies of cryospheric changes and their impacts on climate of China. D Qin, B Zhou, C Xiao, 10.1007/s13351-014-4029-zActa Meteorol. Sin. 72Qin, D.; Zhou, B.; Xiao, C. Progress in studies of cryospheric changes and their impacts on climate of China. Acta Meteorol. Sin. 2014, 72, 869-879. [CrossRef]\n\nCryospheric changes and their impacts on regional water cycle and ecological conditions in the Qinghai-Tibetan Plateau. T Yao, D Qin, Y Shen, L Zhao, N Wang, A Lu, Chin. J. Nat. 35Yao, T.; Qin, D.; Shen, Y.; Zhao, L.; Wang, N.; Lu, A. Cryospheric changes and their impacts on regional water cycle and ecological conditions in the Qinghai-Tibetan Plateau. Chin. J. Nat. 2013, 35, 179-186.\n\nResearch of Cloud and Snow Discrimination from Multispectral High-Resolution Satellite Images. H Wu, Wuhan, ChinaWuhan UniversityMaster's ThesisWu, H. Research of Cloud and Snow Discrimination from Multispectral High-Resolution Satellite Images. Master's Thesis, Wuhan University, Wuhan, China, 2018.\n\nResearch on Distinguishing between Cloud and Snow with NOAA Images. Q Ying, Y Yang, W Xu, Plateau Meteorol. 21Ying, Q.; Yang, Y.; Xu, W. Research on Distinguishing between Cloud and Snow with NOAA Images. Plateau Meteorol. 2002, 21, 526-528.\n\nAutomatic Identification of Cloud and Snow based on Fractal Dimension. H Ding, L Ma, Z Li, L Tang, Remote Sens. Technol. Appl. 28Ding, H.; Ma, L.; Li, Z.; Tang, L. Automatic Identification of Cloud and Snow based on Fractal Dimension. Remote Sens. Technol. Appl. 2013, 28, 52-57.\n\nCloud detection algorithm using SVM with SWIR2 and tasseled cap applied to Landsat 8. P P Joshi, R H Wynne, V A Thomas, 10.1016/j.jag.2019.101898Int. J. Appl. Earth Obs. Geoinf. 82Joshi, P.P.; Wynne, R.H.; Thomas, V.A. Cloud detection algorithm using SVM with SWIR2 and tasseled cap applied to Landsat 8. Int. J. Appl. Earth Obs. Geoinf. 2019, 82, 101898. [CrossRef]\n\nIntroducing two Random Forest based methods for cloud detection in remote sensing images. N Ghasemian, M Akhoondzadeh, 10.1016/j.asr.2018.04.030Adv. Space Res. 62Ghasemian, N.; Akhoondzadeh, M. Introducing two Random Forest based methods for cloud detection in remote sensing images. Adv. Space Res. 2018, 62, 288-303. [CrossRef]\n\nFully convolutional networks for semantic segmentation. J Long, E Shelhamer, T Darrell, Proceedings of the 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR). the 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)Boston, MA, USALong, J.; Shelhamer, E.; Darrell, T. Fully convolutional networks for semantic segmentation. In Proceedings of the 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), Boston, MA, USA, 7-12 June 2015; pp. 3431-3440.\n\nConvolutional neural networks for large-scale remote-sensing image classification. E Maggiori, Y Tarabalka, G Charpiat, P Alliez, 10.1109/TGRS.2016.2612821IEEE Trans. Geosci. Remote Sens. 55Maggiori, E.; Tarabalka, Y.; Charpiat, G.; Alliez, P. Convolutional neural networks for large-scale remote-sensing image classifica- tion. IEEE Trans. Geosci. Remote Sens. 2016, 55, 645-657. [CrossRef]\n\nCloud and Snow Classification in Plateau Area Based on Deep Learning Algorithms. W Liu, Nanjing, ChinaNanjing University of Information Science and TechnologyMaster's ThesisLiu, W. Cloud and Snow Classification in Plateau Area Based on Deep Learning Algorithms. Master's Thesis, Nanjing University of Information Science and Technology, Nanjing, China, 2019.\n\nTypical element extraction method of remote sensing image based on Deeplabv3+ and CRF. J Wang, J Li, H Zhou, X Zhang, 10.19678/j.issn.1000-3428.0053359Comput. Eng. 45Wang, J.; Li, J.; Zhou, H.; Zhang, X. Typical element extraction method of remote sensing image based on Deeplabv3+ and CRF. Comput. Eng. 2019, 45, 260-265, 271. [CrossRef]\n\nExtraction of snow cover from high-resolution remote sensing imagery using deep learning on a small dataset. X Guo, Y Chen, X Liu, Y Zhao, 10.1080/2150704X.2019.1686548Remote Sens. Lett. 11Guo, X.; Chen, Y.; Liu, X.; Zhao, Y. Extraction of snow cover from high-resolution remote sensing imagery using deep learning on a small dataset. Remote Sens. Lett. 2020, 11, 66-75. [CrossRef]\n\nSnow Coverage Mapping by Learning from Sentinel-2 Satellite Multispectral Images via Machine Learning Algorithms. Y Wang, J Su, X Zhai, F Meng, C Liu, 10.3390/rs14030782Remote Sens. 2022, 14, 782. [CrossRefWang, Y.; Su, J.; Zhai, X.; Meng, F.; Liu, C. Snow Coverage Mapping by Learning from Sentinel-2 Satellite Multispectral Images via Machine Learning Algorithms. Remote Sens. 2022, 14, 782. [CrossRef]\n\nControllably Deep Supervision and Multi-Scale Feature Fusion Network for Cloud and Snow Detection Based on Medium-and High-Resolution Imagery Dataset. G Zhang, X Gao, Y Yang, M Wang, S Ran, 10.3390/rs13234805Remote Sens. 2021, 13, 4805. [CrossRefZhang, G.; Gao, X.; Yang, Y.; Wang, M.; Ran, S. Controllably Deep Supervision and Multi-Scale Feature Fusion Network for Cloud and Snow Detection Based on Medium-and High-Resolution Imagery Dataset. Remote Sens. 2021, 13, 4805. [CrossRef]\n\nA Self-Trained Model for Cloud, Shadow and Snow Detection in Sentinel-2 Images of Snow-and Ice-Covered Regions. K G Nambiar, V I Morgenshtern, P Hochreuther, T Seehaus, M H Braun, 10.3390/rs14081825Remote Sens. 2022, 14, 1825. [CrossRefNambiar, K.G.; Morgenshtern, V.I.; Hochreuther, P.; Seehaus, T.; Braun, M.H. A Self-Trained Model for Cloud, Shadow and Snow Detection in Sentinel-2 Images of Snow-and Ice-Covered Regions. Remote Sens. 2022, 14, 1825. [CrossRef]\n\nPESSN: Precision Enhancement Method for Semantic Segmentation Network. J Park, C Shin, C Kim, Proceedings of the 2019 IEEE International Conference on Big Data and Smart Computing (BigComp). the 2019 IEEE International Conference on Big Data and Smart Computing (BigComp)Tokyo, JapanPark, J.; Shin, C.; Kim, C. PESSN: Precision Enhancement Method for Semantic Segmentation Network. In Proceedings of the 2019 IEEE International Conference on Big Data and Smart Computing (BigComp), Tokyo, Japan, 4 April 2019; pp. 1-4.\n\nImage Segmentation Algorithm for Semantic Segmentation with Sharp Boundaries using Image Processing and Deep Neural Network. H G Jeong, H W Jeong, B H Yoon, K S Choi, Proceedings of the 2020 IEEE International Conference on Consumer Electronics-Asia (ICCE-Asia). the 2020 IEEE International Conference on Consumer Electronics-Asia (ICCE-Asia)Seoul, KoreaJeong, H.G.; Jeong, H.W.; Yoon, B.H.; Choi, K.S. Image Segmentation Algorithm for Semantic Segmentation with Sharp Boundaries using Image Processing and Deep Neural Network. In Proceedings of the 2020 IEEE International Conference on Consumer Electronics-Asia (ICCE-Asia), Seoul, Korea, 1 November 2020; pp. 1-4.\n\nBAS 4 Net: Boundary-Aware Semi-Supervised Semantic Segmentation Network for Very High Resolution Remote Sensing Images. X Sun, A Shi, H Huang, H Mayer, 10.1109/JSTARS.2020.3021098IEEE J. Sel. Top. in Appl. Earth Obs. Remote Sens. 13Sun, X.; Shi, A.; Huang, H.; Mayer, H. BAS 4 Net: Boundary-Aware Semi-Supervised Semantic Segmentation Network for Very High Resolution Remote Sensing Images. IEEE J. Sel. Top. in Appl. Earth Obs. Remote Sens. 2020, 13, 5398-5413. [CrossRef]\n\nSemi-supervised Classification of Hyperspectral Images Combined with Convolutional Neural Network and Conditional Random Fields. K Li, 2021Beijing, ChinaChina University of GeosciencesMaster's ThesisLi, K. Semi-supervised Classification of Hyperspectral Images Combined with Convolutional Neural Network and Conditional Random Fields. Master's Thesis, China University of Geosciences, Beijing, China, 2021.\n\nEncoder-decoder with atrous separable convolution for semantic image segmentation. L Chen, Y Zhu, G Papandreou, F Schrof, H Adam, Proceedings of the European conference on computer vision (ECCV). the European conference on computer vision (ECCV)Munich, Germany, 8-Chen, L.; Zhu, Y.; Papandreou, G.; Schrof, F.; Adam, H. Encoder-decoder with atrous separable convolution for semantic image segmentation. In Proceedings of the European conference on computer vision (ECCV), Munich, Germany, 8-14 September 2018; pp. 801-818.\n\nNeural Architecture Search for Volumetric Medical Image Segmentation. Z Zhu, C Liu, D Yang, A Yuille, D Xu, V-Nas, Proceedings of the 2019 IEEE International Conference on 3D Vision (3DV). the 2019 IEEE International Conference on 3D Vision (3DV)Qu\u00e9bec City, QC, CanadaZhu, Z.; Liu, C.; Yang, D.; Yuille, A.; Xu, D. V-NAS: Neural Architecture Search for Volumetric Medical Image Segmentation. In Proceedings of the 2019 IEEE International Conference on 3D Vision (3DV), Qu\u00e9bec City, QC, Canada, 16-19 September 2019; pp. 240-248.\n\nFocal loss for dense object detection. T Y Lin, P Goyal, R Girshick, K He, P Dollar, Proceedings of the 2017 IEEE International Conference on Computer Vision (ICCV). the 2017 IEEE International Conference on Computer Vision (ICCV)Venice, ItalyLin, T.Y.; Goyal, P.; Girshick, R.; He, K.; Dollar, P. Focal loss for dense object detection. In Proceedings of the 2017 IEEE International Conference on Computer Vision (ICCV), Venice, Italy, 22-29 October 2017; pp. 2999-3007.\n\nConditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data. J Lafferty, A Mccallum, F Pereira, Proceedings of the Eighteenth International Conference on Machine Learning (ICML '01). the Eighteenth International Conference on Machine Learning (ICML '01)San Francisco, CA, USA28Lafferty, J.; Mccallum, A.; Pereira, F. Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data. In Proceedings of the Eighteenth International Conference on Machine Learning (ICML '01), San Francisco, CA, USA, 28\n\nEfficient inference in fully connected crfs with gaussian edge potentials. P Kr\u00e4henb\u00fchl, V Koltun, Proceedings of the 24th International Conference on Neural Information Processing Systems (NIPS'11). the 24th International Conference on Neural Information Processing Systems (NIPS'11)Red Hook, NY, USAKr\u00e4henb\u00fchl, P.; Koltun, V. Efficient inference in fully connected crfs with gaussian edge potentials. In Proceedings of the 24th International Conference on Neural Information Processing Systems (NIPS'11), Red Hook, NY, USA, 12-15 December 2011; pp. 109-117.\n\n. G G Alberto, O E Sergio, O Sergiu, V M Victor, G R Jose, arXiv:1704.06857A Review on Deep Learning Techniques Applied to Semantic Segmentation. Alberto, G.G.; Sergio, O.E.; Sergiu, O.; Victor, V.M.; Jose, G.R. A Review on Deep Learning Techniques Applied to Semantic Segmentation. arXiv 2017, arXiv:1704.06857.\n\nSurvey of Research in Image Semantic Segmentation Based on Deep Neural Network. Z W Jing, H Y Guan, D F Peng, Y T Yu, 10.19678/j.issn.1000-3428.0058018Comput. Eng. 46Jing, Z.W.; Guan, H.Y.; Peng, D.F.; Yu, Y.T. Survey of Research in Image Semantic Segmentation Based on Deep Neural Network. Comput. Eng. 2020, 46, 1-17. [CrossRef]\n\nReview of image semantic segmentation based on deep learning. X Tian, L Wang, Q Ding, 10.13328/j.cnki.jos.005659J. Softw. 30Tian, X.; Wang, L.; Ding, Q. Review of image semantic segmentation based on deep learning. J. Softw. 2019, 30, 440-468. [CrossRef]\n\nThe pascal visual object classes challenge: A retrospective. M Everingham, S M Eslami, L Gool, C K Williams, J Winn, A Zisserman, 10.1007/s11263-014-0733-5Int. J. Comput. Vis. 111Everingham, M.; Eslami, S.M.; Gool, L.; Williams, C.K.; Winn, J.; Zisserman, A. The pascal visual object classes challenge: A retrospective. Int. J. Comput. Vis. 2015, 111, 98-136. [CrossRef]\n\nSemantic image segmentation with deep convolutional nets, atrous convolution, and fully connected CRFs. L C Chen, G Papandreou, I Kokkinos, K Murphy, A L Yuille, Deeplab, 10.1109/TPAMI.2017.2699184IEEE Trans. Pattern Anal. Mach. Intell. 40Chen, L.C.; Papandreou, G.; Kokkinos, I.; Murphy, K.; Yuille, A.L. Deeplab: Semantic image segmentation with deep convolutional nets, atrous convolution, and fully connected CRFs. IEEE Trans. Pattern Anal. Mach. Intell. 2018, 40, 834-848. [CrossRef]\n\nRethinking atrous convolution for semantic image segmentation. L C Chen, G Papandreou, F Schroff, H Adam, arXiv:1706.05587Chen, L.C.; Papandreou, G.; Schroff, F.; Adam, H. Rethinking atrous convolution for semantic image segmentation. arXiv 2017, arXiv:1706.05587.\n\nResearch on optimization of image semantic segmentation algorithms based on Deeplab v3+. Laser Optoelectron. J Meng, L Zhang, Y Cao, L Zhang, Q Song, 59Meng, J.; Zhang, L.; Cao, Y.; Zhang, L.; Song, Q. Research on optimization of image semantic segmentation algorithms based on Deeplab v3+. Laser Optoelectron. Prog. 2022, 59, 161-170.\n\nCloud Detection of Remote Sensing Image Based on Multi-Scale Data and Dual-Channel Attention Mechanism. Q Yan, H Liu, J Zhang, X Sun, W Xiong, M Zou, Y Xia, L Xun, 10.3390/rs14153710Remote Sens. 2022, 14, 3710. [CrossRefYan, Q.; Liu, H.; Zhang, J.; Sun, X.; Xiong, W.; Zou, M.; Xia, Y.; Xun, L. Cloud Detection of Remote Sensing Image Based on Multi-Scale Data and Dual-Channel Attention Mechanism. Remote Sens. 2022, 14, 3710. [CrossRef]\n\nIdentifying Urban Functional Regions from High-Resolution Satellite Images Using a Context-Aware Segmentation Network. W Zhao, M Li, C Wu, W Zhou, G Chu, 10.3390/rs14163996Remote Sens. 2022, 14, 3996. [CrossRefZhao, W.; Li, M.; Wu, C.; Zhou, W.; Chu, G. Identifying Urban Functional Regions from High-Resolution Satellite Images Using a Context-Aware Segmentation Network. Remote Sens. 2022, 14, 3996. [CrossRef]\n\nMulti-sensor cloud and cloud shadow segmentation with a convolutional neural network. M Wieland, Y Li, S Martinis, 10.1016/j.rse.2019.05.022Remote Sens. Environ. 2019, 230, 111203. [CrossRefWieland, M.; Li, Y.; Martinis, S. Multi-sensor cloud and cloud shadow segmentation with a convolutional neural network. Remote Sens. Environ. 2019, 230, 111203. [CrossRef]\n\nFmask 4.0: Improved cloud and cloud shadow detection in Landsats 4-8 and Sentinel-2 imagery. S Qiu, Z Zhu, B B He, 10.1016/j.rse.2019.05.024Remote Sens. Environ. 2019, 231, 111205. [CrossRefQiu, S.; Zhu, Z.; He, B.B. Fmask 4.0: Improved cloud and cloud shadow detection in Landsats 4-8 and Sentinel-2 imagery. Remote Sens. Environ. 2019, 231, 111205. [CrossRef]\n\nGlobal-Local-Aware conditional random fields based building extraction for high spatial resolution remote sensing images. Q Zhu, Z Li, Y Zhang, J Li, Y Du, Q Guan, D Li, Natl. Remote Sens. Bull. 25Zhu, Q.; Li, Z.; Zhang, Y.; Li, J.; Du, Y.; Guan, Q.; Li, D. Global-Local-Aware conditional random fields based building extraction for high spatial resolution remote sensing images. Natl. Remote Sens. Bull. 2021, 25, 1422-1433.\n\nSAR airport runway extraction method based on semantic segmentation model and conditional random field. Q He, L Zhao, G Kuang, 10.16592/j.cnki.1004-7859.2021.10.01543Mod. Radar. 2021He, Q.; Zhao, L.; Kuang, G. SAR airport runway extraction method based on semantic segmentation model and conditional random field. Mod. Radar. 2021, 43, 91-100. [CrossRef]\n", "annotations": {"author": "[{\"end\":191,\"start\":109},{\"end\":273,\"start\":192},{\"end\":354,\"start\":274},{\"end\":435,\"start\":355},{\"end\":516,\"start\":436},{\"end\":601,\"start\":517},{\"end\":701,\"start\":602},{\"end\":803,\"start\":702},{\"end\":908,\"start\":804},{\"end\":1010,\"start\":909},{\"end\":1113,\"start\":1011},{\"end\":1211,\"start\":1114},{\"end\":191,\"start\":109},{\"end\":273,\"start\":192},{\"end\":354,\"start\":274},{\"end\":435,\"start\":355},{\"end\":516,\"start\":436},{\"end\":601,\"start\":517},{\"end\":701,\"start\":602},{\"end\":803,\"start\":702},{\"end\":908,\"start\":804},{\"end\":1010,\"start\":909},{\"end\":1113,\"start\":1011},{\"end\":1211,\"start\":1114}]", "publisher": null, "author_last_name": "[{\"end\":117,\"start\":113},{\"end\":199,\"start\":196},{\"end\":280,\"start\":278},{\"end\":361,\"start\":359},{\"end\":442,\"start\":438},{\"end\":527,\"start\":522},{\"end\":611,\"start\":609},{\"end\":713,\"start\":709},{\"end\":818,\"start\":813},{\"end\":920,\"start\":917},{\"end\":1023,\"start\":1019},{\"end\":1121,\"start\":1119},{\"end\":117,\"start\":113},{\"end\":199,\"start\":196},{\"end\":280,\"start\":278},{\"end\":361,\"start\":359},{\"end\":442,\"start\":438},{\"end\":527,\"start\":522},{\"end\":611,\"start\":609},{\"end\":713,\"start\":709},{\"end\":818,\"start\":813},{\"end\":920,\"start\":917},{\"end\":1023,\"start\":1019},{\"end\":1121,\"start\":1119}]", "author_first_name": "[{\"end\":110,\"start\":109},{\"end\":112,\"start\":111},{\"end\":193,\"start\":192},{\"end\":195,\"start\":194},{\"end\":275,\"start\":274},{\"end\":277,\"start\":276},{\"end\":356,\"start\":355},{\"end\":358,\"start\":357},{\"end\":437,\"start\":436},{\"end\":521,\"start\":517},{\"end\":608,\"start\":602},{\"end\":708,\"start\":702},{\"end\":812,\"start\":804},{\"end\":916,\"start\":909},{\"end\":1018,\"start\":1011},{\"end\":1118,\"start\":1114},{\"end\":110,\"start\":109},{\"end\":112,\"start\":111},{\"end\":193,\"start\":192},{\"end\":195,\"start\":194},{\"end\":275,\"start\":274},{\"end\":277,\"start\":276},{\"end\":356,\"start\":355},{\"end\":358,\"start\":357},{\"end\":437,\"start\":436},{\"end\":521,\"start\":517},{\"end\":608,\"start\":602},{\"end\":708,\"start\":702},{\"end\":812,\"start\":804},{\"end\":916,\"start\":909},{\"end\":1018,\"start\":1011},{\"end\":1118,\"start\":1114}]", "author_affiliation": "[{\"end\":190,\"start\":119},{\"end\":272,\"start\":201},{\"end\":353,\"start\":282},{\"end\":434,\"start\":363},{\"end\":515,\"start\":444},{\"end\":600,\"start\":529},{\"end\":700,\"start\":613},{\"end\":802,\"start\":715},{\"end\":907,\"start\":820},{\"end\":1009,\"start\":922},{\"end\":1112,\"start\":1025},{\"end\":1210,\"start\":1123},{\"end\":190,\"start\":119},{\"end\":272,\"start\":201},{\"end\":353,\"start\":282},{\"end\":434,\"start\":363},{\"end\":515,\"start\":444},{\"end\":600,\"start\":529},{\"end\":700,\"start\":613},{\"end\":802,\"start\":715},{\"end\":907,\"start\":820},{\"end\":1009,\"start\":922},{\"end\":1112,\"start\":1025},{\"end\":1210,\"start\":1123}]", "title": "[{\"end\":78,\"start\":1},{\"end\":1289,\"start\":1212},{\"end\":78,\"start\":1},{\"end\":1289,\"start\":1212}]", "venue": null, "abstract": null, "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":1615,\"start\":1612},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":1874,\"start\":1871},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2010,\"start\":2007},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2780,\"start\":2777},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":7724,\"start\":7720},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":8312,\"start\":8308},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":9259,\"start\":9255},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":10994,\"start\":10990},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":12436,\"start\":12432},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":12657,\"start\":12653},{\"end\":14303,\"start\":14281},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":14308,\"start\":14304},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":14723,\"start\":14699},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":14785,\"start\":14781},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":16300,\"start\":16296},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":16303,\"start\":16300},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":38739,\"start\":38735},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":38846,\"start\":38842},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":38952,\"start\":38948},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":38956,\"start\":38952},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":38960,\"start\":38956},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":39543,\"start\":39539},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":39546,\"start\":39543},{\"end\":39988,\"start\":39967},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":40148,\"start\":40144},{\"end\":40203,\"start\":40186},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":40288,\"start\":40284},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":41016,\"start\":41012},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":41019,\"start\":41016},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":51459,\"start\":51456},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":1615,\"start\":1612},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":1874,\"start\":1871},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2010,\"start\":2007},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2780,\"start\":2777},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":7724,\"start\":7720},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":8312,\"start\":8308},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":9259,\"start\":9255},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":10994,\"start\":10990},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":12436,\"start\":12432},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":12657,\"start\":12653},{\"end\":14303,\"start\":14281},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":14308,\"start\":14304},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":14723,\"start\":14699},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":14785,\"start\":14781},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":16300,\"start\":16296},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":16303,\"start\":16300},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":38739,\"start\":38735},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":38846,\"start\":38842},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":38952,\"start\":38948},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":38956,\"start\":38952},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":38960,\"start\":38956},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":39543,\"start\":39539},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":39546,\"start\":39543},{\"end\":39988,\"start\":39967},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":40148,\"start\":40144},{\"end\":40203,\"start\":40186},{\"attributes\":{\"ref_id\":\"b35\"},\"end\":40288,\"start\":40284},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":41016,\"start\":41012},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":41019,\"start\":41016},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":51459,\"start\":51456}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":44786,\"start\":44578},{\"attributes\":{\"id\":\"fig_1\"},\"end\":44995,\"start\":44787},{\"attributes\":{\"id\":\"fig_2\"},\"end\":45030,\"start\":44996},{\"attributes\":{\"id\":\"fig_3\"},\"end\":45217,\"start\":45031},{\"attributes\":{\"id\":\"fig_4\"},\"end\":45453,\"start\":45218},{\"attributes\":{\"id\":\"fig_5\"},\"end\":45741,\"start\":45454},{\"attributes\":{\"id\":\"fig_6\"},\"end\":46029,\"start\":45742},{\"attributes\":{\"id\":\"fig_8\"},\"end\":46214,\"start\":46030},{\"attributes\":{\"id\":\"fig_9\"},\"end\":46399,\"start\":46215},{\"attributes\":{\"id\":\"fig_10\"},\"end\":46694,\"start\":46400},{\"attributes\":{\"id\":\"fig_11\"},\"end\":46989,\"start\":46695},{\"attributes\":{\"id\":\"fig_12\"},\"end\":47176,\"start\":46990},{\"attributes\":{\"id\":\"fig_13\"},\"end\":47363,\"start\":47177},{\"attributes\":{\"id\":\"fig_14\"},\"end\":47642,\"start\":47364},{\"attributes\":{\"id\":\"fig_15\"},\"end\":47921,\"start\":47643},{\"attributes\":{\"id\":\"fig_17\"},\"end\":48112,\"start\":47922},{\"attributes\":{\"id\":\"fig_18\"},\"end\":48413,\"start\":48113},{\"attributes\":{\"id\":\"fig_19\"},\"end\":48733,\"start\":48414},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":49461,\"start\":48734},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":49748,\"start\":49462},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":50041,\"start\":49749},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":50336,\"start\":50042},{\"attributes\":{\"id\":\"tab_9\",\"type\":\"table\"},\"end\":50634,\"start\":50337},{\"attributes\":{\"id\":\"tab_11\",\"type\":\"table\"},\"end\":50919,\"start\":50635},{\"attributes\":{\"id\":\"tab_12\",\"type\":\"table\"},\"end\":51207,\"start\":50920},{\"attributes\":{\"id\":\"tab_13\",\"type\":\"table\"},\"end\":51437,\"start\":51208},{\"attributes\":{\"id\":\"fig_0\"},\"end\":44786,\"start\":44578},{\"attributes\":{\"id\":\"fig_1\"},\"end\":44995,\"start\":44787},{\"attributes\":{\"id\":\"fig_2\"},\"end\":45030,\"start\":44996},{\"attributes\":{\"id\":\"fig_3\"},\"end\":45217,\"start\":45031},{\"attributes\":{\"id\":\"fig_4\"},\"end\":45453,\"start\":45218},{\"attributes\":{\"id\":\"fig_5\"},\"end\":45741,\"start\":45454},{\"attributes\":{\"id\":\"fig_6\"},\"end\":46029,\"start\":45742},{\"attributes\":{\"id\":\"fig_8\"},\"end\":46214,\"start\":46030},{\"attributes\":{\"id\":\"fig_9\"},\"end\":46399,\"start\":46215},{\"attributes\":{\"id\":\"fig_10\"},\"end\":46694,\"start\":46400},{\"attributes\":{\"id\":\"fig_11\"},\"end\":46989,\"start\":46695},{\"attributes\":{\"id\":\"fig_12\"},\"end\":47176,\"start\":46990},{\"attributes\":{\"id\":\"fig_13\"},\"end\":47363,\"start\":47177},{\"attributes\":{\"id\":\"fig_14\"},\"end\":47642,\"start\":47364},{\"attributes\":{\"id\":\"fig_15\"},\"end\":47921,\"start\":47643},{\"attributes\":{\"id\":\"fig_17\"},\"end\":48112,\"start\":47922},{\"attributes\":{\"id\":\"fig_18\"},\"end\":48413,\"start\":48113},{\"attributes\":{\"id\":\"fig_19\"},\"end\":48733,\"start\":48414},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":49461,\"start\":48734},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":49748,\"start\":49462},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":50041,\"start\":49749},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":50336,\"start\":50042},{\"attributes\":{\"id\":\"tab_9\",\"type\":\"table\"},\"end\":50634,\"start\":50337},{\"attributes\":{\"id\":\"tab_11\",\"type\":\"table\"},\"end\":50919,\"start\":50635},{\"attributes\":{\"id\":\"tab_12\",\"type\":\"table\"},\"end\":51207,\"start\":50920},{\"attributes\":{\"id\":\"tab_13\",\"type\":\"table\"},\"end\":51437,\"start\":51208}]", "paragraph": "[{\"end\":2584,\"start\":1501},{\"end\":3015,\"start\":2586},{\"end\":3829,\"start\":3056},{\"end\":5485,\"start\":3849},{\"end\":6073,\"start\":5487},{\"end\":6510,\"start\":6095},{\"end\":6946,\"start\":6532},{\"end\":8225,\"start\":6948},{\"end\":8481,\"start\":8227},{\"end\":9760,\"start\":8483},{\"end\":10252,\"start\":9762},{\"end\":11163,\"start\":10270},{\"end\":11655,\"start\":11165},{\"end\":13318,\"start\":11673},{\"end\":14174,\"start\":13541},{\"end\":14862,\"start\":14203},{\"end\":16038,\"start\":14914},{\"end\":17225,\"start\":16064},{\"end\":18044,\"start\":17363},{\"end\":19179,\"start\":18072},{\"end\":19833,\"start\":19206},{\"end\":21628,\"start\":19835},{\"end\":24080,\"start\":21655},{\"end\":24699,\"start\":24105},{\"end\":25317,\"start\":24724},{\"end\":29502,\"start\":25319},{\"end\":30045,\"start\":29533},{\"end\":33963,\"start\":30076},{\"end\":34756,\"start\":34008},{\"end\":36578,\"start\":34801},{\"end\":38518,\"start\":36580},{\"end\":41770,\"start\":38533},{\"end\":42503,\"start\":41786},{\"end\":42586,\"start\":42505},{\"end\":43653,\"start\":42588},{\"end\":44577,\"start\":43655},{\"end\":2584,\"start\":1501},{\"end\":3015,\"start\":2586},{\"end\":3829,\"start\":3056},{\"end\":5485,\"start\":3849},{\"end\":6073,\"start\":5487},{\"end\":6510,\"start\":6095},{\"end\":6946,\"start\":6532},{\"end\":8225,\"start\":6948},{\"end\":8481,\"start\":8227},{\"end\":9760,\"start\":8483},{\"end\":10252,\"start\":9762},{\"end\":11163,\"start\":10270},{\"end\":11655,\"start\":11165},{\"end\":13318,\"start\":11673},{\"end\":14174,\"start\":13541},{\"end\":14862,\"start\":14203},{\"end\":16038,\"start\":14914},{\"end\":17225,\"start\":16064},{\"end\":18044,\"start\":17363},{\"end\":19179,\"start\":18072},{\"end\":19833,\"start\":19206},{\"end\":21628,\"start\":19835},{\"end\":24080,\"start\":21655},{\"end\":24699,\"start\":24105},{\"end\":25317,\"start\":24724},{\"end\":29502,\"start\":25319},{\"end\":30045,\"start\":29533},{\"end\":33963,\"start\":30076},{\"end\":34756,\"start\":34008},{\"end\":36578,\"start\":34801},{\"end\":38518,\"start\":36580},{\"end\":41770,\"start\":38533},{\"end\":42503,\"start\":41786},{\"end\":42586,\"start\":42505},{\"end\":43653,\"start\":42588},{\"end\":44577,\"start\":43655}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":13366,\"start\":13319},{\"attributes\":{\"id\":\"formula_1\"},\"end\":13488,\"start\":13366},{\"attributes\":{\"id\":\"formula_2\"},\"end\":13540,\"start\":13488},{\"attributes\":{\"id\":\"formula_3\"},\"end\":14913,\"start\":14863},{\"attributes\":{\"id\":\"formula_4\"},\"end\":17288,\"start\":17226},{\"attributes\":{\"id\":\"formula_5\"},\"end\":17335,\"start\":17288},{\"attributes\":{\"id\":\"formula_0\"},\"end\":13366,\"start\":13319},{\"attributes\":{\"id\":\"formula_1\"},\"end\":13488,\"start\":13366},{\"attributes\":{\"id\":\"formula_2\"},\"end\":13540,\"start\":13488},{\"attributes\":{\"id\":\"formula_3\"},\"end\":14913,\"start\":14863},{\"attributes\":{\"id\":\"formula_4\"},\"end\":17288,\"start\":17226},{\"attributes\":{\"id\":\"formula_5\"},\"end\":17335,\"start\":17288}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":3435,\"start\":3428},{\"end\":3495,\"start\":3488},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":20846,\"start\":20839},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":23294,\"start\":23287},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":26216,\"start\":26209},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":26249,\"start\":26242},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":28305,\"start\":28298},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":28338,\"start\":28331},{\"attributes\":{\"ref_id\":\"tab_11\"},\"end\":31132,\"start\":31125},{\"attributes\":{\"ref_id\":\"tab_11\"},\"end\":31159,\"start\":31152},{\"attributes\":{\"ref_id\":\"tab_11\"},\"end\":32819,\"start\":32812},{\"attributes\":{\"ref_id\":\"tab_11\"},\"end\":32846,\"start\":32839},{\"attributes\":{\"ref_id\":\"tab_13\"},\"end\":37990,\"start\":37983},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":3435,\"start\":3428},{\"end\":3495,\"start\":3488},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":20846,\"start\":20839},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":23294,\"start\":23287},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":26216,\"start\":26209},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":26249,\"start\":26242},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":28305,\"start\":28298},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":28338,\"start\":28331},{\"attributes\":{\"ref_id\":\"tab_11\"},\"end\":31132,\"start\":31125},{\"attributes\":{\"ref_id\":\"tab_11\"},\"end\":31159,\"start\":31152},{\"attributes\":{\"ref_id\":\"tab_11\"},\"end\":32819,\"start\":32812},{\"attributes\":{\"ref_id\":\"tab_11\"},\"end\":32846,\"start\":32839},{\"attributes\":{\"ref_id\":\"tab_13\"},\"end\":37990,\"start\":37983}]", "section_header": "[{\"attributes\":{\"n\":\"1.\"},\"end\":1499,\"start\":1487},{\"attributes\":{\"n\":\"2.\"},\"end\":3038,\"start\":3018},{\"attributes\":{\"n\":\"2.1.\"},\"end\":3054,\"start\":3041},{\"attributes\":{\"n\":\"2.2.\"},\"end\":3847,\"start\":3832},{\"attributes\":{\"n\":\"2.3.\"},\"end\":6093,\"start\":6076},{\"attributes\":{\"n\":\"2.3.\"},\"end\":6530,\"start\":6513},{\"attributes\":{\"n\":\"2.4.\"},\"end\":10268,\"start\":10255},{\"attributes\":{\"n\":\"2.4.\"},\"end\":11671,\"start\":11658},{\"attributes\":{\"n\":\"2.5.\"},\"end\":14201,\"start\":14177},{\"attributes\":{\"n\":\"2.6.\"},\"end\":16062,\"start\":16041},{\"attributes\":{\"n\":\"2.7.\"},\"end\":17361,\"start\":17337},{\"attributes\":{\"n\":\"3.\"},\"end\":18070,\"start\":18047},{\"attributes\":{\"n\":\"3.1.\"},\"end\":19204,\"start\":19182},{\"attributes\":{\"n\":\"3.1.\"},\"end\":21653,\"start\":21631},{\"attributes\":{\"n\":\"3.2.\"},\"end\":24103,\"start\":24083},{\"attributes\":{\"n\":\"3.2.\"},\"end\":24722,\"start\":24702},{\"attributes\":{\"n\":\"3.3.\"},\"end\":29531,\"start\":29505},{\"attributes\":{\"n\":\"3.3.\"},\"end\":30074,\"start\":30048},{\"attributes\":{\"n\":\"3.4.\"},\"end\":34006,\"start\":33966},{\"attributes\":{\"n\":\"3.4.\"},\"end\":34799,\"start\":34759},{\"attributes\":{\"n\":\"4.\"},\"end\":38531,\"start\":38521},{\"attributes\":{\"n\":\"5.\"},\"end\":41784,\"start\":41773},{\"end\":44589,\"start\":44579},{\"end\":44798,\"start\":44788},{\"end\":45007,\"start\":44997},{\"end\":45042,\"start\":45032},{\"end\":45229,\"start\":45219},{\"end\":45465,\"start\":45455},{\"end\":45753,\"start\":45743},{\"end\":46041,\"start\":46031},{\"end\":46226,\"start\":46216},{\"end\":46411,\"start\":46401},{\"end\":46706,\"start\":46696},{\"end\":47001,\"start\":46991},{\"end\":47188,\"start\":47178},{\"end\":47375,\"start\":47365},{\"end\":47654,\"start\":47644},{\"end\":47933,\"start\":47923},{\"end\":48124,\"start\":48114},{\"end\":48426,\"start\":48415},{\"end\":48744,\"start\":48735},{\"end\":49472,\"start\":49463},{\"end\":49759,\"start\":49750},{\"end\":50052,\"start\":50043},{\"end\":50347,\"start\":50338},{\"end\":50645,\"start\":50636},{\"end\":50930,\"start\":50921},{\"end\":51218,\"start\":51209},{\"attributes\":{\"n\":\"1.\"},\"end\":1499,\"start\":1487},{\"attributes\":{\"n\":\"2.\"},\"end\":3038,\"start\":3018},{\"attributes\":{\"n\":\"2.1.\"},\"end\":3054,\"start\":3041},{\"attributes\":{\"n\":\"2.2.\"},\"end\":3847,\"start\":3832},{\"attributes\":{\"n\":\"2.3.\"},\"end\":6093,\"start\":6076},{\"attributes\":{\"n\":\"2.3.\"},\"end\":6530,\"start\":6513},{\"attributes\":{\"n\":\"2.4.\"},\"end\":10268,\"start\":10255},{\"attributes\":{\"n\":\"2.4.\"},\"end\":11671,\"start\":11658},{\"attributes\":{\"n\":\"2.5.\"},\"end\":14201,\"start\":14177},{\"attributes\":{\"n\":\"2.6.\"},\"end\":16062,\"start\":16041},{\"attributes\":{\"n\":\"2.7.\"},\"end\":17361,\"start\":17337},{\"attributes\":{\"n\":\"3.\"},\"end\":18070,\"start\":18047},{\"attributes\":{\"n\":\"3.1.\"},\"end\":19204,\"start\":19182},{\"attributes\":{\"n\":\"3.1.\"},\"end\":21653,\"start\":21631},{\"attributes\":{\"n\":\"3.2.\"},\"end\":24103,\"start\":24083},{\"attributes\":{\"n\":\"3.2.\"},\"end\":24722,\"start\":24702},{\"attributes\":{\"n\":\"3.3.\"},\"end\":29531,\"start\":29505},{\"attributes\":{\"n\":\"3.3.\"},\"end\":30074,\"start\":30048},{\"attributes\":{\"n\":\"3.4.\"},\"end\":34006,\"start\":33966},{\"attributes\":{\"n\":\"3.4.\"},\"end\":34799,\"start\":34759},{\"attributes\":{\"n\":\"4.\"},\"end\":38531,\"start\":38521},{\"attributes\":{\"n\":\"5.\"},\"end\":41784,\"start\":41773},{\"end\":44589,\"start\":44579},{\"end\":44798,\"start\":44788},{\"end\":45007,\"start\":44997},{\"end\":45042,\"start\":45032},{\"end\":45229,\"start\":45219},{\"end\":45465,\"start\":45455},{\"end\":45753,\"start\":45743},{\"end\":46041,\"start\":46031},{\"end\":46226,\"start\":46216},{\"end\":46411,\"start\":46401},{\"end\":46706,\"start\":46696},{\"end\":47001,\"start\":46991},{\"end\":47188,\"start\":47178},{\"end\":47375,\"start\":47365},{\"end\":47654,\"start\":47644},{\"end\":47933,\"start\":47923},{\"end\":48124,\"start\":48114},{\"end\":48426,\"start\":48415},{\"end\":48744,\"start\":48735},{\"end\":49472,\"start\":49463},{\"end\":49759,\"start\":49750},{\"end\":50052,\"start\":50043},{\"end\":50347,\"start\":50338},{\"end\":50645,\"start\":50636},{\"end\":50930,\"start\":50921},{\"end\":51218,\"start\":51209}]", "table": "[{\"end\":49461,\"start\":48806},{\"end\":49748,\"start\":49539},{\"end\":50041,\"start\":49826},{\"end\":50336,\"start\":50117},{\"end\":50634,\"start\":50412},{\"end\":50919,\"start\":50712},{\"end\":51207,\"start\":50997},{\"end\":51437,\"start\":51259},{\"end\":49461,\"start\":48806},{\"end\":49748,\"start\":49539},{\"end\":50041,\"start\":49826},{\"end\":50336,\"start\":50117},{\"end\":50634,\"start\":50412},{\"end\":50919,\"start\":50712},{\"end\":51207,\"start\":50997},{\"end\":51437,\"start\":51259}]", "figure_caption": "[{\"end\":44786,\"start\":44591},{\"end\":44995,\"start\":44800},{\"end\":45030,\"start\":45009},{\"end\":45217,\"start\":45044},{\"end\":45453,\"start\":45231},{\"end\":45741,\"start\":45467},{\"end\":46029,\"start\":45755},{\"end\":46214,\"start\":46043},{\"end\":46399,\"start\":46228},{\"end\":46694,\"start\":46413},{\"end\":46989,\"start\":46708},{\"end\":47176,\"start\":47003},{\"end\":47363,\"start\":47190},{\"end\":47642,\"start\":47377},{\"end\":47921,\"start\":47656},{\"end\":48112,\"start\":47935},{\"end\":48413,\"start\":48126},{\"end\":48733,\"start\":48429},{\"end\":48806,\"start\":48746},{\"end\":49539,\"start\":49474},{\"end\":49826,\"start\":49761},{\"end\":50117,\"start\":50054},{\"end\":50412,\"start\":50349},{\"end\":50712,\"start\":50647},{\"end\":50997,\"start\":50932},{\"end\":51259,\"start\":51220},{\"end\":44786,\"start\":44591},{\"end\":44995,\"start\":44800},{\"end\":45030,\"start\":45009},{\"end\":45217,\"start\":45044},{\"end\":45453,\"start\":45231},{\"end\":45741,\"start\":45467},{\"end\":46029,\"start\":45755},{\"end\":46214,\"start\":46043},{\"end\":46399,\"start\":46228},{\"end\":46694,\"start\":46413},{\"end\":46989,\"start\":46708},{\"end\":47176,\"start\":47003},{\"end\":47363,\"start\":47190},{\"end\":47642,\"start\":47377},{\"end\":47921,\"start\":47656},{\"end\":48112,\"start\":47935},{\"end\":48413,\"start\":48126},{\"end\":48733,\"start\":48429},{\"end\":48806,\"start\":48746},{\"end\":49539,\"start\":49474},{\"end\":49826,\"start\":49761},{\"end\":50117,\"start\":50054},{\"end\":50412,\"start\":50349},{\"end\":50712,\"start\":50647},{\"end\":50997,\"start\":50932},{\"end\":51259,\"start\":51220}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":5484,\"start\":5476},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":6071,\"start\":6063},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":6199,\"start\":6191},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":6636,\"start\":6628},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":8284,\"start\":8276},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":19832,\"start\":19824},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":19863,\"start\":19855},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":20704,\"start\":20696},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":20867,\"start\":20859},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":22281,\"start\":22273},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":22311,\"start\":22303},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":23152,\"start\":23144},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":23315,\"start\":23307},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":24697,\"start\":24689},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":25316,\"start\":25308},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":25338,\"start\":25330},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":26076,\"start\":26068},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":26237,\"start\":26229},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":27428,\"start\":27420},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":28165,\"start\":28157},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":28326,\"start\":28318},{\"attributes\":{\"ref_id\":\"fig_12\"},\"end\":30043,\"start\":30035},{\"attributes\":{\"ref_id\":\"fig_12\"},\"end\":30586,\"start\":30578},{\"attributes\":{\"ref_id\":\"fig_12\"},\"end\":30616,\"start\":30608},{\"attributes\":{\"ref_id\":\"fig_14\"},\"end\":30989,\"start\":30981},{\"attributes\":{\"ref_id\":\"fig_14\"},\"end\":31147,\"start\":31139},{\"attributes\":{\"ref_id\":\"fig_12\"},\"end\":32303,\"start\":32295},{\"attributes\":{\"ref_id\":\"fig_14\"},\"end\":32676,\"start\":32668},{\"attributes\":{\"ref_id\":\"fig_14\"},\"end\":32834,\"start\":32826},{\"attributes\":{\"ref_id\":\"fig_17\"},\"end\":34754,\"start\":34746},{\"attributes\":{\"ref_id\":\"fig_17\"},\"end\":35547,\"start\":35539},{\"attributes\":{\"ref_id\":\"fig_17\"},\"end\":35559,\"start\":35551},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":35651,\"start\":35642},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":35751,\"start\":35735},{\"attributes\":{\"ref_id\":\"fig_17\"},\"end\":36699,\"start\":36691},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":36791,\"start\":36782},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":36890,\"start\":36869},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":5484,\"start\":5476},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":6071,\"start\":6063},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":6199,\"start\":6191},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":6636,\"start\":6628},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":8284,\"start\":8276},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":19832,\"start\":19824},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":19863,\"start\":19855},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":20704,\"start\":20696},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":20867,\"start\":20859},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":22281,\"start\":22273},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":22311,\"start\":22303},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":23152,\"start\":23144},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":23315,\"start\":23307},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":24697,\"start\":24689},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":25316,\"start\":25308},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":25338,\"start\":25330},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":26076,\"start\":26068},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":26237,\"start\":26229},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":27428,\"start\":27420},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":28165,\"start\":28157},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":28326,\"start\":28318},{\"attributes\":{\"ref_id\":\"fig_12\"},\"end\":30043,\"start\":30035},{\"attributes\":{\"ref_id\":\"fig_12\"},\"end\":30586,\"start\":30578},{\"attributes\":{\"ref_id\":\"fig_12\"},\"end\":30616,\"start\":30608},{\"attributes\":{\"ref_id\":\"fig_14\"},\"end\":30989,\"start\":30981},{\"attributes\":{\"ref_id\":\"fig_14\"},\"end\":31147,\"start\":31139},{\"attributes\":{\"ref_id\":\"fig_12\"},\"end\":32303,\"start\":32295},{\"attributes\":{\"ref_id\":\"fig_14\"},\"end\":32676,\"start\":32668},{\"attributes\":{\"ref_id\":\"fig_14\"},\"end\":32834,\"start\":32826},{\"attributes\":{\"ref_id\":\"fig_17\"},\"end\":34754,\"start\":34746},{\"attributes\":{\"ref_id\":\"fig_17\"},\"end\":35547,\"start\":35539},{\"attributes\":{\"ref_id\":\"fig_17\"},\"end\":35559,\"start\":35551},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":35651,\"start\":35642},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":35751,\"start\":35735},{\"attributes\":{\"ref_id\":\"fig_17\"},\"end\":36699,\"start\":36691},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":36791,\"start\":36782},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":36890,\"start\":36869}]", "bib_author_first_name": "[{\"end\":51680,\"start\":51679},{\"end\":51687,\"start\":51686},{\"end\":51945,\"start\":51944},{\"end\":51952,\"start\":51951},{\"end\":51960,\"start\":51959},{\"end\":52296,\"start\":52295},{\"end\":52303,\"start\":52302},{\"end\":52310,\"start\":52309},{\"end\":52318,\"start\":52317},{\"end\":52326,\"start\":52325},{\"end\":52334,\"start\":52333},{\"end\":52660,\"start\":52659},{\"end\":52935,\"start\":52934},{\"end\":52943,\"start\":52942},{\"end\":52951,\"start\":52950},{\"end\":53181,\"start\":53180},{\"end\":53189,\"start\":53188},{\"end\":53195,\"start\":53194},{\"end\":53201,\"start\":53200},{\"end\":53477,\"start\":53476},{\"end\":53479,\"start\":53478},{\"end\":53488,\"start\":53487},{\"end\":53490,\"start\":53489},{\"end\":53499,\"start\":53498},{\"end\":53501,\"start\":53500},{\"end\":53849,\"start\":53848},{\"end\":53862,\"start\":53861},{\"end\":54146,\"start\":54145},{\"end\":54154,\"start\":54153},{\"end\":54167,\"start\":54166},{\"end\":54677,\"start\":54676},{\"end\":54689,\"start\":54688},{\"end\":54702,\"start\":54701},{\"end\":54714,\"start\":54713},{\"end\":55068,\"start\":55067},{\"end\":55434,\"start\":55433},{\"end\":55442,\"start\":55441},{\"end\":55448,\"start\":55447},{\"end\":55456,\"start\":55455},{\"end\":55796,\"start\":55795},{\"end\":55803,\"start\":55802},{\"end\":55811,\"start\":55810},{\"end\":55818,\"start\":55817},{\"end\":56184,\"start\":56183},{\"end\":56192,\"start\":56191},{\"end\":56198,\"start\":56197},{\"end\":56206,\"start\":56205},{\"end\":56214,\"start\":56213},{\"end\":56627,\"start\":56626},{\"end\":56636,\"start\":56635},{\"end\":56643,\"start\":56642},{\"end\":56651,\"start\":56650},{\"end\":56659,\"start\":56658},{\"end\":57074,\"start\":57073},{\"end\":57076,\"start\":57075},{\"end\":57087,\"start\":57086},{\"end\":57089,\"start\":57088},{\"end\":57105,\"start\":57104},{\"end\":57120,\"start\":57119},{\"end\":57131,\"start\":57130},{\"end\":57133,\"start\":57132},{\"end\":57499,\"start\":57498},{\"end\":57507,\"start\":57506},{\"end\":57515,\"start\":57514},{\"end\":58073,\"start\":58072},{\"end\":58075,\"start\":58074},{\"end\":58084,\"start\":58083},{\"end\":58086,\"start\":58085},{\"end\":58095,\"start\":58094},{\"end\":58097,\"start\":58096},{\"end\":58105,\"start\":58104},{\"end\":58107,\"start\":58106},{\"end\":58736,\"start\":58735},{\"end\":58743,\"start\":58742},{\"end\":58750,\"start\":58749},{\"end\":58759,\"start\":58758},{\"end\":59220,\"start\":59219},{\"end\":59582,\"start\":59581},{\"end\":59590,\"start\":59589},{\"end\":59597,\"start\":59596},{\"end\":59611,\"start\":59610},{\"end\":59621,\"start\":59620},{\"end\":60093,\"start\":60092},{\"end\":60100,\"start\":60099},{\"end\":60107,\"start\":60106},{\"end\":60115,\"start\":60114},{\"end\":60125,\"start\":60124},{\"end\":60593,\"start\":60592},{\"end\":60595,\"start\":60594},{\"end\":60602,\"start\":60601},{\"end\":60611,\"start\":60610},{\"end\":60623,\"start\":60622},{\"end\":60629,\"start\":60628},{\"end\":61117,\"start\":61116},{\"end\":61129,\"start\":61128},{\"end\":61141,\"start\":61140},{\"end\":61657,\"start\":61656},{\"end\":61671,\"start\":61670},{\"end\":62145,\"start\":62144},{\"end\":62147,\"start\":62146},{\"end\":62158,\"start\":62157},{\"end\":62160,\"start\":62159},{\"end\":62170,\"start\":62169},{\"end\":62180,\"start\":62179},{\"end\":62182,\"start\":62181},{\"end\":62192,\"start\":62191},{\"end\":62194,\"start\":62193},{\"end\":62537,\"start\":62536},{\"end\":62539,\"start\":62538},{\"end\":62547,\"start\":62546},{\"end\":62549,\"start\":62548},{\"end\":62557,\"start\":62556},{\"end\":62559,\"start\":62558},{\"end\":62567,\"start\":62566},{\"end\":62569,\"start\":62568},{\"end\":62851,\"start\":62850},{\"end\":62859,\"start\":62858},{\"end\":62867,\"start\":62866},{\"end\":63106,\"start\":63105},{\"end\":63120,\"start\":63119},{\"end\":63122,\"start\":63121},{\"end\":63132,\"start\":63131},{\"end\":63140,\"start\":63139},{\"end\":63142,\"start\":63141},{\"end\":63154,\"start\":63153},{\"end\":63162,\"start\":63161},{\"end\":63521,\"start\":63520},{\"end\":63523,\"start\":63522},{\"end\":63531,\"start\":63530},{\"end\":63545,\"start\":63544},{\"end\":63557,\"start\":63556},{\"end\":63567,\"start\":63566},{\"end\":63569,\"start\":63568},{\"end\":63970,\"start\":63969},{\"end\":63972,\"start\":63971},{\"end\":63980,\"start\":63979},{\"end\":63994,\"start\":63993},{\"end\":64005,\"start\":64004},{\"end\":64282,\"start\":64281},{\"end\":64290,\"start\":64289},{\"end\":64299,\"start\":64298},{\"end\":64306,\"start\":64305},{\"end\":64315,\"start\":64314},{\"end\":64614,\"start\":64613},{\"end\":64621,\"start\":64620},{\"end\":64628,\"start\":64627},{\"end\":64637,\"start\":64636},{\"end\":64644,\"start\":64643},{\"end\":64653,\"start\":64652},{\"end\":64660,\"start\":64659},{\"end\":64667,\"start\":64666},{\"end\":65069,\"start\":65068},{\"end\":65077,\"start\":65076},{\"end\":65083,\"start\":65082},{\"end\":65089,\"start\":65088},{\"end\":65097,\"start\":65096},{\"end\":65450,\"start\":65449},{\"end\":65461,\"start\":65460},{\"end\":65467,\"start\":65466},{\"end\":65820,\"start\":65819},{\"end\":65827,\"start\":65826},{\"end\":65834,\"start\":65833},{\"end\":65836,\"start\":65835},{\"end\":66212,\"start\":66211},{\"end\":66219,\"start\":66218},{\"end\":66225,\"start\":66224},{\"end\":66234,\"start\":66233},{\"end\":66240,\"start\":66239},{\"end\":66246,\"start\":66245},{\"end\":66254,\"start\":66253},{\"end\":66621,\"start\":66620},{\"end\":66627,\"start\":66626},{\"end\":66635,\"start\":66634},{\"end\":51680,\"start\":51679},{\"end\":51687,\"start\":51686},{\"end\":51945,\"start\":51944},{\"end\":51952,\"start\":51951},{\"end\":51960,\"start\":51959},{\"end\":52296,\"start\":52295},{\"end\":52303,\"start\":52302},{\"end\":52310,\"start\":52309},{\"end\":52318,\"start\":52317},{\"end\":52326,\"start\":52325},{\"end\":52334,\"start\":52333},{\"end\":52660,\"start\":52659},{\"end\":52935,\"start\":52934},{\"end\":52943,\"start\":52942},{\"end\":52951,\"start\":52950},{\"end\":53181,\"start\":53180},{\"end\":53189,\"start\":53188},{\"end\":53195,\"start\":53194},{\"end\":53201,\"start\":53200},{\"end\":53477,\"start\":53476},{\"end\":53479,\"start\":53478},{\"end\":53488,\"start\":53487},{\"end\":53490,\"start\":53489},{\"end\":53499,\"start\":53498},{\"end\":53501,\"start\":53500},{\"end\":53849,\"start\":53848},{\"end\":53862,\"start\":53861},{\"end\":54146,\"start\":54145},{\"end\":54154,\"start\":54153},{\"end\":54167,\"start\":54166},{\"end\":54677,\"start\":54676},{\"end\":54689,\"start\":54688},{\"end\":54702,\"start\":54701},{\"end\":54714,\"start\":54713},{\"end\":55068,\"start\":55067},{\"end\":55434,\"start\":55433},{\"end\":55442,\"start\":55441},{\"end\":55448,\"start\":55447},{\"end\":55456,\"start\":55455},{\"end\":55796,\"start\":55795},{\"end\":55803,\"start\":55802},{\"end\":55811,\"start\":55810},{\"end\":55818,\"start\":55817},{\"end\":56184,\"start\":56183},{\"end\":56192,\"start\":56191},{\"end\":56198,\"start\":56197},{\"end\":56206,\"start\":56205},{\"end\":56214,\"start\":56213},{\"end\":56627,\"start\":56626},{\"end\":56636,\"start\":56635},{\"end\":56643,\"start\":56642},{\"end\":56651,\"start\":56650},{\"end\":56659,\"start\":56658},{\"end\":57074,\"start\":57073},{\"end\":57076,\"start\":57075},{\"end\":57087,\"start\":57086},{\"end\":57089,\"start\":57088},{\"end\":57105,\"start\":57104},{\"end\":57120,\"start\":57119},{\"end\":57131,\"start\":57130},{\"end\":57133,\"start\":57132},{\"end\":57499,\"start\":57498},{\"end\":57507,\"start\":57506},{\"end\":57515,\"start\":57514},{\"end\":58073,\"start\":58072},{\"end\":58075,\"start\":58074},{\"end\":58084,\"start\":58083},{\"end\":58086,\"start\":58085},{\"end\":58095,\"start\":58094},{\"end\":58097,\"start\":58096},{\"end\":58105,\"start\":58104},{\"end\":58107,\"start\":58106},{\"end\":58736,\"start\":58735},{\"end\":58743,\"start\":58742},{\"end\":58750,\"start\":58749},{\"end\":58759,\"start\":58758},{\"end\":59220,\"start\":59219},{\"end\":59582,\"start\":59581},{\"end\":59590,\"start\":59589},{\"end\":59597,\"start\":59596},{\"end\":59611,\"start\":59610},{\"end\":59621,\"start\":59620},{\"end\":60093,\"start\":60092},{\"end\":60100,\"start\":60099},{\"end\":60107,\"start\":60106},{\"end\":60115,\"start\":60114},{\"end\":60125,\"start\":60124},{\"end\":60593,\"start\":60592},{\"end\":60595,\"start\":60594},{\"end\":60602,\"start\":60601},{\"end\":60611,\"start\":60610},{\"end\":60623,\"start\":60622},{\"end\":60629,\"start\":60628},{\"end\":61117,\"start\":61116},{\"end\":61129,\"start\":61128},{\"end\":61141,\"start\":61140},{\"end\":61657,\"start\":61656},{\"end\":61671,\"start\":61670},{\"end\":62145,\"start\":62144},{\"end\":62147,\"start\":62146},{\"end\":62158,\"start\":62157},{\"end\":62160,\"start\":62159},{\"end\":62170,\"start\":62169},{\"end\":62180,\"start\":62179},{\"end\":62182,\"start\":62181},{\"end\":62192,\"start\":62191},{\"end\":62194,\"start\":62193},{\"end\":62537,\"start\":62536},{\"end\":62539,\"start\":62538},{\"end\":62547,\"start\":62546},{\"end\":62549,\"start\":62548},{\"end\":62557,\"start\":62556},{\"end\":62559,\"start\":62558},{\"end\":62567,\"start\":62566},{\"end\":62569,\"start\":62568},{\"end\":62851,\"start\":62850},{\"end\":62859,\"start\":62858},{\"end\":62867,\"start\":62866},{\"end\":63106,\"start\":63105},{\"end\":63120,\"start\":63119},{\"end\":63122,\"start\":63121},{\"end\":63132,\"start\":63131},{\"end\":63140,\"start\":63139},{\"end\":63142,\"start\":63141},{\"end\":63154,\"start\":63153},{\"end\":63162,\"start\":63161},{\"end\":63521,\"start\":63520},{\"end\":63523,\"start\":63522},{\"end\":63531,\"start\":63530},{\"end\":63545,\"start\":63544},{\"end\":63557,\"start\":63556},{\"end\":63567,\"start\":63566},{\"end\":63569,\"start\":63568},{\"end\":63970,\"start\":63969},{\"end\":63972,\"start\":63971},{\"end\":63980,\"start\":63979},{\"end\":63994,\"start\":63993},{\"end\":64005,\"start\":64004},{\"end\":64282,\"start\":64281},{\"end\":64290,\"start\":64289},{\"end\":64299,\"start\":64298},{\"end\":64306,\"start\":64305},{\"end\":64315,\"start\":64314},{\"end\":64614,\"start\":64613},{\"end\":64621,\"start\":64620},{\"end\":64628,\"start\":64627},{\"end\":64637,\"start\":64636},{\"end\":64644,\"start\":64643},{\"end\":64653,\"start\":64652},{\"end\":64660,\"start\":64659},{\"end\":64667,\"start\":64666},{\"end\":65069,\"start\":65068},{\"end\":65077,\"start\":65076},{\"end\":65083,\"start\":65082},{\"end\":65089,\"start\":65088},{\"end\":65097,\"start\":65096},{\"end\":65450,\"start\":65449},{\"end\":65461,\"start\":65460},{\"end\":65467,\"start\":65466},{\"end\":65820,\"start\":65819},{\"end\":65827,\"start\":65826},{\"end\":65834,\"start\":65833},{\"end\":65836,\"start\":65835},{\"end\":66212,\"start\":66211},{\"end\":66219,\"start\":66218},{\"end\":66225,\"start\":66224},{\"end\":66234,\"start\":66233},{\"end\":66240,\"start\":66239},{\"end\":66246,\"start\":66245},{\"end\":66254,\"start\":66253},{\"end\":66621,\"start\":66620},{\"end\":66627,\"start\":66626},{\"end\":66635,\"start\":66634}]", "bib_author_last_name": "[{\"end\":51684,\"start\":51681},{\"end\":51693,\"start\":51688},{\"end\":51949,\"start\":51946},{\"end\":51957,\"start\":51953},{\"end\":51965,\"start\":51961},{\"end\":52300,\"start\":52297},{\"end\":52307,\"start\":52304},{\"end\":52315,\"start\":52311},{\"end\":52323,\"start\":52319},{\"end\":52331,\"start\":52327},{\"end\":52337,\"start\":52335},{\"end\":52663,\"start\":52661},{\"end\":52940,\"start\":52936},{\"end\":52948,\"start\":52944},{\"end\":52954,\"start\":52952},{\"end\":53186,\"start\":53182},{\"end\":53192,\"start\":53190},{\"end\":53198,\"start\":53196},{\"end\":53206,\"start\":53202},{\"end\":53485,\"start\":53480},{\"end\":53496,\"start\":53491},{\"end\":53508,\"start\":53502},{\"end\":53859,\"start\":53850},{\"end\":53875,\"start\":53863},{\"end\":54151,\"start\":54147},{\"end\":54164,\"start\":54155},{\"end\":54175,\"start\":54168},{\"end\":54686,\"start\":54678},{\"end\":54699,\"start\":54690},{\"end\":54711,\"start\":54703},{\"end\":54721,\"start\":54715},{\"end\":55072,\"start\":55069},{\"end\":55439,\"start\":55435},{\"end\":55445,\"start\":55443},{\"end\":55453,\"start\":55449},{\"end\":55462,\"start\":55457},{\"end\":55800,\"start\":55797},{\"end\":55808,\"start\":55804},{\"end\":55815,\"start\":55812},{\"end\":55823,\"start\":55819},{\"end\":56189,\"start\":56185},{\"end\":56195,\"start\":56193},{\"end\":56203,\"start\":56199},{\"end\":56211,\"start\":56207},{\"end\":56218,\"start\":56215},{\"end\":56633,\"start\":56628},{\"end\":56640,\"start\":56637},{\"end\":56648,\"start\":56644},{\"end\":56656,\"start\":56652},{\"end\":56663,\"start\":56660},{\"end\":57084,\"start\":57077},{\"end\":57102,\"start\":57090},{\"end\":57117,\"start\":57106},{\"end\":57128,\"start\":57121},{\"end\":57139,\"start\":57134},{\"end\":57504,\"start\":57500},{\"end\":57512,\"start\":57508},{\"end\":57519,\"start\":57516},{\"end\":58081,\"start\":58076},{\"end\":58092,\"start\":58087},{\"end\":58102,\"start\":58098},{\"end\":58112,\"start\":58108},{\"end\":58740,\"start\":58737},{\"end\":58747,\"start\":58744},{\"end\":58756,\"start\":58751},{\"end\":58765,\"start\":58760},{\"end\":59223,\"start\":59221},{\"end\":59587,\"start\":59583},{\"end\":59594,\"start\":59591},{\"end\":59608,\"start\":59598},{\"end\":59618,\"start\":59612},{\"end\":59626,\"start\":59622},{\"end\":60097,\"start\":60094},{\"end\":60104,\"start\":60101},{\"end\":60112,\"start\":60108},{\"end\":60122,\"start\":60116},{\"end\":60128,\"start\":60126},{\"end\":60135,\"start\":60130},{\"end\":60599,\"start\":60596},{\"end\":60608,\"start\":60603},{\"end\":60620,\"start\":60612},{\"end\":60626,\"start\":60624},{\"end\":60636,\"start\":60630},{\"end\":61126,\"start\":61118},{\"end\":61138,\"start\":61130},{\"end\":61149,\"start\":61142},{\"end\":61668,\"start\":61658},{\"end\":61678,\"start\":61672},{\"end\":62155,\"start\":62148},{\"end\":62167,\"start\":62161},{\"end\":62177,\"start\":62171},{\"end\":62189,\"start\":62183},{\"end\":62199,\"start\":62195},{\"end\":62544,\"start\":62540},{\"end\":62554,\"start\":62550},{\"end\":62564,\"start\":62560},{\"end\":62572,\"start\":62570},{\"end\":62856,\"start\":62852},{\"end\":62864,\"start\":62860},{\"end\":62872,\"start\":62868},{\"end\":63117,\"start\":63107},{\"end\":63129,\"start\":63123},{\"end\":63137,\"start\":63133},{\"end\":63151,\"start\":63143},{\"end\":63159,\"start\":63155},{\"end\":63172,\"start\":63163},{\"end\":63528,\"start\":63524},{\"end\":63542,\"start\":63532},{\"end\":63554,\"start\":63546},{\"end\":63564,\"start\":63558},{\"end\":63576,\"start\":63570},{\"end\":63585,\"start\":63578},{\"end\":63977,\"start\":63973},{\"end\":63991,\"start\":63981},{\"end\":64002,\"start\":63995},{\"end\":64010,\"start\":64006},{\"end\":64287,\"start\":64283},{\"end\":64296,\"start\":64291},{\"end\":64303,\"start\":64300},{\"end\":64312,\"start\":64307},{\"end\":64320,\"start\":64316},{\"end\":64618,\"start\":64615},{\"end\":64625,\"start\":64622},{\"end\":64634,\"start\":64629},{\"end\":64641,\"start\":64638},{\"end\":64650,\"start\":64645},{\"end\":64657,\"start\":64654},{\"end\":64664,\"start\":64661},{\"end\":64671,\"start\":64668},{\"end\":65074,\"start\":65070},{\"end\":65080,\"start\":65078},{\"end\":65086,\"start\":65084},{\"end\":65094,\"start\":65090},{\"end\":65101,\"start\":65098},{\"end\":65458,\"start\":65451},{\"end\":65464,\"start\":65462},{\"end\":65476,\"start\":65468},{\"end\":65824,\"start\":65821},{\"end\":65831,\"start\":65828},{\"end\":65839,\"start\":65837},{\"end\":66216,\"start\":66213},{\"end\":66222,\"start\":66220},{\"end\":66231,\"start\":66226},{\"end\":66237,\"start\":66235},{\"end\":66243,\"start\":66241},{\"end\":66251,\"start\":66247},{\"end\":66257,\"start\":66255},{\"end\":66624,\"start\":66622},{\"end\":66632,\"start\":66628},{\"end\":66641,\"start\":66636},{\"end\":51684,\"start\":51681},{\"end\":51693,\"start\":51688},{\"end\":51949,\"start\":51946},{\"end\":51957,\"start\":51953},{\"end\":51965,\"start\":51961},{\"end\":52300,\"start\":52297},{\"end\":52307,\"start\":52304},{\"end\":52315,\"start\":52311},{\"end\":52323,\"start\":52319},{\"end\":52331,\"start\":52327},{\"end\":52337,\"start\":52335},{\"end\":52663,\"start\":52661},{\"end\":52940,\"start\":52936},{\"end\":52948,\"start\":52944},{\"end\":52954,\"start\":52952},{\"end\":53186,\"start\":53182},{\"end\":53192,\"start\":53190},{\"end\":53198,\"start\":53196},{\"end\":53206,\"start\":53202},{\"end\":53485,\"start\":53480},{\"end\":53496,\"start\":53491},{\"end\":53508,\"start\":53502},{\"end\":53859,\"start\":53850},{\"end\":53875,\"start\":53863},{\"end\":54151,\"start\":54147},{\"end\":54164,\"start\":54155},{\"end\":54175,\"start\":54168},{\"end\":54686,\"start\":54678},{\"end\":54699,\"start\":54690},{\"end\":54711,\"start\":54703},{\"end\":54721,\"start\":54715},{\"end\":55072,\"start\":55069},{\"end\":55439,\"start\":55435},{\"end\":55445,\"start\":55443},{\"end\":55453,\"start\":55449},{\"end\":55462,\"start\":55457},{\"end\":55800,\"start\":55797},{\"end\":55808,\"start\":55804},{\"end\":55815,\"start\":55812},{\"end\":55823,\"start\":55819},{\"end\":56189,\"start\":56185},{\"end\":56195,\"start\":56193},{\"end\":56203,\"start\":56199},{\"end\":56211,\"start\":56207},{\"end\":56218,\"start\":56215},{\"end\":56633,\"start\":56628},{\"end\":56640,\"start\":56637},{\"end\":56648,\"start\":56644},{\"end\":56656,\"start\":56652},{\"end\":56663,\"start\":56660},{\"end\":57084,\"start\":57077},{\"end\":57102,\"start\":57090},{\"end\":57117,\"start\":57106},{\"end\":57128,\"start\":57121},{\"end\":57139,\"start\":57134},{\"end\":57504,\"start\":57500},{\"end\":57512,\"start\":57508},{\"end\":57519,\"start\":57516},{\"end\":58081,\"start\":58076},{\"end\":58092,\"start\":58087},{\"end\":58102,\"start\":58098},{\"end\":58112,\"start\":58108},{\"end\":58740,\"start\":58737},{\"end\":58747,\"start\":58744},{\"end\":58756,\"start\":58751},{\"end\":58765,\"start\":58760},{\"end\":59223,\"start\":59221},{\"end\":59587,\"start\":59583},{\"end\":59594,\"start\":59591},{\"end\":59608,\"start\":59598},{\"end\":59618,\"start\":59612},{\"end\":59626,\"start\":59622},{\"end\":60097,\"start\":60094},{\"end\":60104,\"start\":60101},{\"end\":60112,\"start\":60108},{\"end\":60122,\"start\":60116},{\"end\":60128,\"start\":60126},{\"end\":60135,\"start\":60130},{\"end\":60599,\"start\":60596},{\"end\":60608,\"start\":60603},{\"end\":60620,\"start\":60612},{\"end\":60626,\"start\":60624},{\"end\":60636,\"start\":60630},{\"end\":61126,\"start\":61118},{\"end\":61138,\"start\":61130},{\"end\":61149,\"start\":61142},{\"end\":61668,\"start\":61658},{\"end\":61678,\"start\":61672},{\"end\":62155,\"start\":62148},{\"end\":62167,\"start\":62161},{\"end\":62177,\"start\":62171},{\"end\":62189,\"start\":62183},{\"end\":62199,\"start\":62195},{\"end\":62544,\"start\":62540},{\"end\":62554,\"start\":62550},{\"end\":62564,\"start\":62560},{\"end\":62572,\"start\":62570},{\"end\":62856,\"start\":62852},{\"end\":62864,\"start\":62860},{\"end\":62872,\"start\":62868},{\"end\":63117,\"start\":63107},{\"end\":63129,\"start\":63123},{\"end\":63137,\"start\":63133},{\"end\":63151,\"start\":63143},{\"end\":63159,\"start\":63155},{\"end\":63172,\"start\":63163},{\"end\":63528,\"start\":63524},{\"end\":63542,\"start\":63532},{\"end\":63554,\"start\":63546},{\"end\":63564,\"start\":63558},{\"end\":63576,\"start\":63570},{\"end\":63585,\"start\":63578},{\"end\":63977,\"start\":63973},{\"end\":63991,\"start\":63981},{\"end\":64002,\"start\":63995},{\"end\":64010,\"start\":64006},{\"end\":64287,\"start\":64283},{\"end\":64296,\"start\":64291},{\"end\":64303,\"start\":64300},{\"end\":64312,\"start\":64307},{\"end\":64320,\"start\":64316},{\"end\":64618,\"start\":64615},{\"end\":64625,\"start\":64622},{\"end\":64634,\"start\":64629},{\"end\":64641,\"start\":64638},{\"end\":64650,\"start\":64645},{\"end\":64657,\"start\":64654},{\"end\":64664,\"start\":64661},{\"end\":64671,\"start\":64668},{\"end\":65074,\"start\":65070},{\"end\":65080,\"start\":65078},{\"end\":65086,\"start\":65084},{\"end\":65094,\"start\":65090},{\"end\":65101,\"start\":65098},{\"end\":65458,\"start\":65451},{\"end\":65464,\"start\":65462},{\"end\":65476,\"start\":65468},{\"end\":65824,\"start\":65821},{\"end\":65831,\"start\":65828},{\"end\":65839,\"start\":65837},{\"end\":66216,\"start\":66213},{\"end\":66222,\"start\":66220},{\"end\":66231,\"start\":66226},{\"end\":66237,\"start\":66235},{\"end\":66243,\"start\":66241},{\"end\":66251,\"start\":66247},{\"end\":66257,\"start\":66255},{\"end\":66624,\"start\":66622},{\"end\":66632,\"start\":66628},{\"end\":66641,\"start\":66636}]", "bib_entry": "[{\"attributes\":{\"doi\":\"10.16418/j.issn.1000-3045.1991.04.002\",\"id\":\"b0\"},\"end\":51860,\"start\":51645},{\"attributes\":{\"doi\":\"10.1007/s13351-014-4029-z\",\"id\":\"b1\",\"matched_paper_id\":128650729},\"end\":52173,\"start\":51862},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":204234392},\"end\":52562,\"start\":52175},{\"attributes\":{\"id\":\"b3\"},\"end\":52864,\"start\":52564},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":130681793},\"end\":53107,\"start\":52866},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":134482215},\"end\":53388,\"start\":53109},{\"attributes\":{\"doi\":\"10.1016/j.jag.2019.101898\",\"id\":\"b6\",\"matched_paper_id\":199801742},\"end\":53756,\"start\":53390},{\"attributes\":{\"doi\":\"10.1016/j.asr.2018.04.030\",\"id\":\"b7\",\"matched_paper_id\":126347658},\"end\":54087,\"start\":53758},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":1629541},\"end\":54591,\"start\":54089},{\"attributes\":{\"doi\":\"10.1109/TGRS.2016.2612821\",\"id\":\"b9\",\"matched_paper_id\":23216142},\"end\":54984,\"start\":54593},{\"attributes\":{\"id\":\"b10\"},\"end\":55344,\"start\":54986},{\"attributes\":{\"doi\":\"10.19678/j.issn.1000-3428.0053359\",\"id\":\"b11\"},\"end\":55684,\"start\":55346},{\"attributes\":{\"doi\":\"10.1080/2150704X.2019.1686548\",\"id\":\"b12\",\"matched_paper_id\":209909120},\"end\":56067,\"start\":55686},{\"attributes\":{\"doi\":\"10.3390/rs14030782\",\"id\":\"b13\"},\"end\":56473,\"start\":56069},{\"attributes\":{\"doi\":\"10.3390/rs13234805\",\"id\":\"b14\"},\"end\":56959,\"start\":56475},{\"attributes\":{\"doi\":\"10.3390/rs14081825\",\"id\":\"b15\"},\"end\":57425,\"start\":56961},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":96432131},\"end\":57945,\"start\":57427},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":228093692},\"end\":58613,\"start\":57947},{\"attributes\":{\"doi\":\"10.1109/JSTARS.2020.3021098\",\"id\":\"b18\",\"matched_paper_id\":222070384},\"end\":59088,\"start\":58615},{\"attributes\":{\"id\":\"b19\"},\"end\":59496,\"start\":59090},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":3638670},\"end\":60020,\"start\":59498},{\"attributes\":{\"id\":\"b21\"},\"end\":60551,\"start\":60022},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":47252984},\"end\":61023,\"start\":60553},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":219683473},\"end\":61579,\"start\":61025},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":5574079},\"end\":62140,\"start\":61581},{\"attributes\":{\"doi\":\"arXiv:1704.06857\",\"id\":\"b25\"},\"end\":62454,\"start\":62142},{\"attributes\":{\"doi\":\"10.19678/j.issn.1000-3428.0058018\",\"id\":\"b26\"},\"end\":62786,\"start\":62456},{\"attributes\":{\"doi\":\"10.13328/j.cnki.jos.005659\",\"id\":\"b27\"},\"end\":63042,\"start\":62788},{\"attributes\":{\"doi\":\"10.1007/s11263-014-0733-5\",\"id\":\"b28\",\"matched_paper_id\":207252270},\"end\":63414,\"start\":63044},{\"attributes\":{\"doi\":\"10.1109/TPAMI.2017.2699184\",\"id\":\"b29\",\"matched_paper_id\":3429309},\"end\":63904,\"start\":63416},{\"attributes\":{\"doi\":\"arXiv:1706.05587\",\"id\":\"b30\"},\"end\":64170,\"start\":63906},{\"attributes\":{\"id\":\"b31\"},\"end\":64507,\"start\":64172},{\"attributes\":{\"doi\":\"10.3390/rs14153710\",\"id\":\"b32\"},\"end\":64947,\"start\":64509},{\"attributes\":{\"doi\":\"10.3390/rs14163996\",\"id\":\"b33\"},\"end\":65361,\"start\":64949},{\"attributes\":{\"doi\":\"10.1016/j.rse.2019.05.022\",\"id\":\"b34\"},\"end\":65724,\"start\":65363},{\"attributes\":{\"doi\":\"10.1016/j.rse.2019.05.024\",\"id\":\"b35\"},\"end\":66087,\"start\":65726},{\"attributes\":{\"id\":\"b36\"},\"end\":66514,\"start\":66089},{\"attributes\":{\"doi\":\"10.16592/j.cnki.1004-7859.2021.10.015\",\"id\":\"b37\"},\"end\":66870,\"start\":66516},{\"attributes\":{\"doi\":\"10.16418/j.issn.1000-3045.1991.04.002\",\"id\":\"b0\"},\"end\":51860,\"start\":51645},{\"attributes\":{\"doi\":\"10.1007/s13351-014-4029-z\",\"id\":\"b1\",\"matched_paper_id\":128650729},\"end\":52173,\"start\":51862},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":204234392},\"end\":52562,\"start\":52175},{\"attributes\":{\"id\":\"b3\"},\"end\":52864,\"start\":52564},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":130681793},\"end\":53107,\"start\":52866},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":134482215},\"end\":53388,\"start\":53109},{\"attributes\":{\"doi\":\"10.1016/j.jag.2019.101898\",\"id\":\"b6\",\"matched_paper_id\":199801742},\"end\":53756,\"start\":53390},{\"attributes\":{\"doi\":\"10.1016/j.asr.2018.04.030\",\"id\":\"b7\",\"matched_paper_id\":126347658},\"end\":54087,\"start\":53758},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":1629541},\"end\":54591,\"start\":54089},{\"attributes\":{\"doi\":\"10.1109/TGRS.2016.2612821\",\"id\":\"b9\",\"matched_paper_id\":23216142},\"end\":54984,\"start\":54593},{\"attributes\":{\"id\":\"b10\"},\"end\":55344,\"start\":54986},{\"attributes\":{\"doi\":\"10.19678/j.issn.1000-3428.0053359\",\"id\":\"b11\"},\"end\":55684,\"start\":55346},{\"attributes\":{\"doi\":\"10.1080/2150704X.2019.1686548\",\"id\":\"b12\",\"matched_paper_id\":209909120},\"end\":56067,\"start\":55686},{\"attributes\":{\"doi\":\"10.3390/rs14030782\",\"id\":\"b13\"},\"end\":56473,\"start\":56069},{\"attributes\":{\"doi\":\"10.3390/rs13234805\",\"id\":\"b14\"},\"end\":56959,\"start\":56475},{\"attributes\":{\"doi\":\"10.3390/rs14081825\",\"id\":\"b15\"},\"end\":57425,\"start\":56961},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":96432131},\"end\":57945,\"start\":57427},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":228093692},\"end\":58613,\"start\":57947},{\"attributes\":{\"doi\":\"10.1109/JSTARS.2020.3021098\",\"id\":\"b18\",\"matched_paper_id\":222070384},\"end\":59088,\"start\":58615},{\"attributes\":{\"id\":\"b19\"},\"end\":59496,\"start\":59090},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":3638670},\"end\":60020,\"start\":59498},{\"attributes\":{\"id\":\"b21\"},\"end\":60551,\"start\":60022},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":47252984},\"end\":61023,\"start\":60553},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":219683473},\"end\":61579,\"start\":61025},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":5574079},\"end\":62140,\"start\":61581},{\"attributes\":{\"doi\":\"arXiv:1704.06857\",\"id\":\"b25\"},\"end\":62454,\"start\":62142},{\"attributes\":{\"doi\":\"10.19678/j.issn.1000-3428.0058018\",\"id\":\"b26\"},\"end\":62786,\"start\":62456},{\"attributes\":{\"doi\":\"10.13328/j.cnki.jos.005659\",\"id\":\"b27\"},\"end\":63042,\"start\":62788},{\"attributes\":{\"doi\":\"10.1007/s11263-014-0733-5\",\"id\":\"b28\",\"matched_paper_id\":207252270},\"end\":63414,\"start\":63044},{\"attributes\":{\"doi\":\"10.1109/TPAMI.2017.2699184\",\"id\":\"b29\",\"matched_paper_id\":3429309},\"end\":63904,\"start\":63416},{\"attributes\":{\"doi\":\"arXiv:1706.05587\",\"id\":\"b30\"},\"end\":64170,\"start\":63906},{\"attributes\":{\"id\":\"b31\"},\"end\":64507,\"start\":64172},{\"attributes\":{\"doi\":\"10.3390/rs14153710\",\"id\":\"b32\"},\"end\":64947,\"start\":64509},{\"attributes\":{\"doi\":\"10.3390/rs14163996\",\"id\":\"b33\"},\"end\":65361,\"start\":64949},{\"attributes\":{\"doi\":\"10.1016/j.rse.2019.05.022\",\"id\":\"b34\"},\"end\":65724,\"start\":65363},{\"attributes\":{\"doi\":\"10.1016/j.rse.2019.05.024\",\"id\":\"b35\"},\"end\":66087,\"start\":65726},{\"attributes\":{\"id\":\"b36\"},\"end\":66514,\"start\":66089},{\"attributes\":{\"doi\":\"10.16592/j.cnki.1004-7859.2021.10.015\",\"id\":\"b37\"},\"end\":66870,\"start\":66516}]", "bib_title": "[{\"end\":51677,\"start\":51645},{\"end\":51942,\"start\":51862},{\"end\":52293,\"start\":52175},{\"end\":52932,\"start\":52866},{\"end\":53178,\"start\":53109},{\"end\":53474,\"start\":53390},{\"end\":53846,\"start\":53758},{\"end\":54143,\"start\":54089},{\"end\":54674,\"start\":54593},{\"end\":55431,\"start\":55346},{\"end\":55793,\"start\":55686},{\"end\":57496,\"start\":57427},{\"end\":58070,\"start\":57947},{\"end\":58733,\"start\":58615},{\"end\":59579,\"start\":59498},{\"end\":60090,\"start\":60022},{\"end\":60590,\"start\":60553},{\"end\":61114,\"start\":61025},{\"end\":61654,\"start\":61581},{\"end\":62534,\"start\":62456},{\"end\":62848,\"start\":62788},{\"end\":63103,\"start\":63044},{\"end\":63518,\"start\":63416},{\"end\":66209,\"start\":66089},{\"end\":51677,\"start\":51645},{\"end\":51942,\"start\":51862},{\"end\":52293,\"start\":52175},{\"end\":52932,\"start\":52866},{\"end\":53178,\"start\":53109},{\"end\":53474,\"start\":53390},{\"end\":53846,\"start\":53758},{\"end\":54143,\"start\":54089},{\"end\":54674,\"start\":54593},{\"end\":55431,\"start\":55346},{\"end\":55793,\"start\":55686},{\"end\":57496,\"start\":57427},{\"end\":58070,\"start\":57947},{\"end\":58733,\"start\":58615},{\"end\":59579,\"start\":59498},{\"end\":60090,\"start\":60022},{\"end\":60590,\"start\":60553},{\"end\":61114,\"start\":61025},{\"end\":61654,\"start\":61581},{\"end\":62534,\"start\":62456},{\"end\":62848,\"start\":62788},{\"end\":63103,\"start\":63044},{\"end\":63518,\"start\":63416},{\"end\":66209,\"start\":66089}]", "bib_author": "[{\"end\":51686,\"start\":51679},{\"end\":51695,\"start\":51686},{\"end\":51951,\"start\":51944},{\"end\":51959,\"start\":51951},{\"end\":51967,\"start\":51959},{\"end\":52302,\"start\":52295},{\"end\":52309,\"start\":52302},{\"end\":52317,\"start\":52309},{\"end\":52325,\"start\":52317},{\"end\":52333,\"start\":52325},{\"end\":52339,\"start\":52333},{\"end\":52665,\"start\":52659},{\"end\":52942,\"start\":52934},{\"end\":52950,\"start\":52942},{\"end\":52956,\"start\":52950},{\"end\":53188,\"start\":53180},{\"end\":53194,\"start\":53188},{\"end\":53200,\"start\":53194},{\"end\":53208,\"start\":53200},{\"end\":53487,\"start\":53476},{\"end\":53498,\"start\":53487},{\"end\":53510,\"start\":53498},{\"end\":53861,\"start\":53848},{\"end\":53877,\"start\":53861},{\"end\":54153,\"start\":54145},{\"end\":54166,\"start\":54153},{\"end\":54177,\"start\":54166},{\"end\":54688,\"start\":54676},{\"end\":54701,\"start\":54688},{\"end\":54713,\"start\":54701},{\"end\":54723,\"start\":54713},{\"end\":55074,\"start\":55067},{\"end\":55441,\"start\":55433},{\"end\":55447,\"start\":55441},{\"end\":55455,\"start\":55447},{\"end\":55464,\"start\":55455},{\"end\":55802,\"start\":55795},{\"end\":55810,\"start\":55802},{\"end\":55817,\"start\":55810},{\"end\":55825,\"start\":55817},{\"end\":56191,\"start\":56183},{\"end\":56197,\"start\":56191},{\"end\":56205,\"start\":56197},{\"end\":56213,\"start\":56205},{\"end\":56220,\"start\":56213},{\"end\":56635,\"start\":56626},{\"end\":56642,\"start\":56635},{\"end\":56650,\"start\":56642},{\"end\":56658,\"start\":56650},{\"end\":56665,\"start\":56658},{\"end\":57086,\"start\":57073},{\"end\":57104,\"start\":57086},{\"end\":57119,\"start\":57104},{\"end\":57130,\"start\":57119},{\"end\":57141,\"start\":57130},{\"end\":57506,\"start\":57498},{\"end\":57514,\"start\":57506},{\"end\":57521,\"start\":57514},{\"end\":58083,\"start\":58072},{\"end\":58094,\"start\":58083},{\"end\":58104,\"start\":58094},{\"end\":58114,\"start\":58104},{\"end\":58742,\"start\":58735},{\"end\":58749,\"start\":58742},{\"end\":58758,\"start\":58749},{\"end\":58767,\"start\":58758},{\"end\":59225,\"start\":59219},{\"end\":59589,\"start\":59581},{\"end\":59596,\"start\":59589},{\"end\":59610,\"start\":59596},{\"end\":59620,\"start\":59610},{\"end\":59628,\"start\":59620},{\"end\":60099,\"start\":60092},{\"end\":60106,\"start\":60099},{\"end\":60114,\"start\":60106},{\"end\":60124,\"start\":60114},{\"end\":60130,\"start\":60124},{\"end\":60137,\"start\":60130},{\"end\":60601,\"start\":60592},{\"end\":60610,\"start\":60601},{\"end\":60622,\"start\":60610},{\"end\":60628,\"start\":60622},{\"end\":60638,\"start\":60628},{\"end\":61128,\"start\":61116},{\"end\":61140,\"start\":61128},{\"end\":61151,\"start\":61140},{\"end\":61670,\"start\":61656},{\"end\":61680,\"start\":61670},{\"end\":62157,\"start\":62144},{\"end\":62169,\"start\":62157},{\"end\":62179,\"start\":62169},{\"end\":62191,\"start\":62179},{\"end\":62201,\"start\":62191},{\"end\":62546,\"start\":62536},{\"end\":62556,\"start\":62546},{\"end\":62566,\"start\":62556},{\"end\":62574,\"start\":62566},{\"end\":62858,\"start\":62850},{\"end\":62866,\"start\":62858},{\"end\":62874,\"start\":62866},{\"end\":63119,\"start\":63105},{\"end\":63131,\"start\":63119},{\"end\":63139,\"start\":63131},{\"end\":63153,\"start\":63139},{\"end\":63161,\"start\":63153},{\"end\":63174,\"start\":63161},{\"end\":63530,\"start\":63520},{\"end\":63544,\"start\":63530},{\"end\":63556,\"start\":63544},{\"end\":63566,\"start\":63556},{\"end\":63578,\"start\":63566},{\"end\":63587,\"start\":63578},{\"end\":63979,\"start\":63969},{\"end\":63993,\"start\":63979},{\"end\":64004,\"start\":63993},{\"end\":64012,\"start\":64004},{\"end\":64289,\"start\":64281},{\"end\":64298,\"start\":64289},{\"end\":64305,\"start\":64298},{\"end\":64314,\"start\":64305},{\"end\":64322,\"start\":64314},{\"end\":64620,\"start\":64613},{\"end\":64627,\"start\":64620},{\"end\":64636,\"start\":64627},{\"end\":64643,\"start\":64636},{\"end\":64652,\"start\":64643},{\"end\":64659,\"start\":64652},{\"end\":64666,\"start\":64659},{\"end\":64673,\"start\":64666},{\"end\":65076,\"start\":65068},{\"end\":65082,\"start\":65076},{\"end\":65088,\"start\":65082},{\"end\":65096,\"start\":65088},{\"end\":65103,\"start\":65096},{\"end\":65460,\"start\":65449},{\"end\":65466,\"start\":65460},{\"end\":65478,\"start\":65466},{\"end\":65826,\"start\":65819},{\"end\":65833,\"start\":65826},{\"end\":65841,\"start\":65833},{\"end\":66218,\"start\":66211},{\"end\":66224,\"start\":66218},{\"end\":66233,\"start\":66224},{\"end\":66239,\"start\":66233},{\"end\":66245,\"start\":66239},{\"end\":66253,\"start\":66245},{\"end\":66259,\"start\":66253},{\"end\":66626,\"start\":66620},{\"end\":66634,\"start\":66626},{\"end\":66643,\"start\":66634},{\"end\":51686,\"start\":51679},{\"end\":51695,\"start\":51686},{\"end\":51951,\"start\":51944},{\"end\":51959,\"start\":51951},{\"end\":51967,\"start\":51959},{\"end\":52302,\"start\":52295},{\"end\":52309,\"start\":52302},{\"end\":52317,\"start\":52309},{\"end\":52325,\"start\":52317},{\"end\":52333,\"start\":52325},{\"end\":52339,\"start\":52333},{\"end\":52665,\"start\":52659},{\"end\":52942,\"start\":52934},{\"end\":52950,\"start\":52942},{\"end\":52956,\"start\":52950},{\"end\":53188,\"start\":53180},{\"end\":53194,\"start\":53188},{\"end\":53200,\"start\":53194},{\"end\":53208,\"start\":53200},{\"end\":53487,\"start\":53476},{\"end\":53498,\"start\":53487},{\"end\":53510,\"start\":53498},{\"end\":53861,\"start\":53848},{\"end\":53877,\"start\":53861},{\"end\":54153,\"start\":54145},{\"end\":54166,\"start\":54153},{\"end\":54177,\"start\":54166},{\"end\":54688,\"start\":54676},{\"end\":54701,\"start\":54688},{\"end\":54713,\"start\":54701},{\"end\":54723,\"start\":54713},{\"end\":55074,\"start\":55067},{\"end\":55441,\"start\":55433},{\"end\":55447,\"start\":55441},{\"end\":55455,\"start\":55447},{\"end\":55464,\"start\":55455},{\"end\":55802,\"start\":55795},{\"end\":55810,\"start\":55802},{\"end\":55817,\"start\":55810},{\"end\":55825,\"start\":55817},{\"end\":56191,\"start\":56183},{\"end\":56197,\"start\":56191},{\"end\":56205,\"start\":56197},{\"end\":56213,\"start\":56205},{\"end\":56220,\"start\":56213},{\"end\":56635,\"start\":56626},{\"end\":56642,\"start\":56635},{\"end\":56650,\"start\":56642},{\"end\":56658,\"start\":56650},{\"end\":56665,\"start\":56658},{\"end\":57086,\"start\":57073},{\"end\":57104,\"start\":57086},{\"end\":57119,\"start\":57104},{\"end\":57130,\"start\":57119},{\"end\":57141,\"start\":57130},{\"end\":57506,\"start\":57498},{\"end\":57514,\"start\":57506},{\"end\":57521,\"start\":57514},{\"end\":58083,\"start\":58072},{\"end\":58094,\"start\":58083},{\"end\":58104,\"start\":58094},{\"end\":58114,\"start\":58104},{\"end\":58742,\"start\":58735},{\"end\":58749,\"start\":58742},{\"end\":58758,\"start\":58749},{\"end\":58767,\"start\":58758},{\"end\":59225,\"start\":59219},{\"end\":59589,\"start\":59581},{\"end\":59596,\"start\":59589},{\"end\":59610,\"start\":59596},{\"end\":59620,\"start\":59610},{\"end\":59628,\"start\":59620},{\"end\":60099,\"start\":60092},{\"end\":60106,\"start\":60099},{\"end\":60114,\"start\":60106},{\"end\":60124,\"start\":60114},{\"end\":60130,\"start\":60124},{\"end\":60137,\"start\":60130},{\"end\":60601,\"start\":60592},{\"end\":60610,\"start\":60601},{\"end\":60622,\"start\":60610},{\"end\":60628,\"start\":60622},{\"end\":60638,\"start\":60628},{\"end\":61128,\"start\":61116},{\"end\":61140,\"start\":61128},{\"end\":61151,\"start\":61140},{\"end\":61670,\"start\":61656},{\"end\":61680,\"start\":61670},{\"end\":62157,\"start\":62144},{\"end\":62169,\"start\":62157},{\"end\":62179,\"start\":62169},{\"end\":62191,\"start\":62179},{\"end\":62201,\"start\":62191},{\"end\":62546,\"start\":62536},{\"end\":62556,\"start\":62546},{\"end\":62566,\"start\":62556},{\"end\":62574,\"start\":62566},{\"end\":62858,\"start\":62850},{\"end\":62866,\"start\":62858},{\"end\":62874,\"start\":62866},{\"end\":63119,\"start\":63105},{\"end\":63131,\"start\":63119},{\"end\":63139,\"start\":63131},{\"end\":63153,\"start\":63139},{\"end\":63161,\"start\":63153},{\"end\":63174,\"start\":63161},{\"end\":63530,\"start\":63520},{\"end\":63544,\"start\":63530},{\"end\":63556,\"start\":63544},{\"end\":63566,\"start\":63556},{\"end\":63578,\"start\":63566},{\"end\":63587,\"start\":63578},{\"end\":63979,\"start\":63969},{\"end\":63993,\"start\":63979},{\"end\":64004,\"start\":63993},{\"end\":64012,\"start\":64004},{\"end\":64289,\"start\":64281},{\"end\":64298,\"start\":64289},{\"end\":64305,\"start\":64298},{\"end\":64314,\"start\":64305},{\"end\":64322,\"start\":64314},{\"end\":64620,\"start\":64613},{\"end\":64627,\"start\":64620},{\"end\":64636,\"start\":64627},{\"end\":64643,\"start\":64636},{\"end\":64652,\"start\":64643},{\"end\":64659,\"start\":64652},{\"end\":64666,\"start\":64659},{\"end\":64673,\"start\":64666},{\"end\":65076,\"start\":65068},{\"end\":65082,\"start\":65076},{\"end\":65088,\"start\":65082},{\"end\":65096,\"start\":65088},{\"end\":65103,\"start\":65096},{\"end\":65460,\"start\":65449},{\"end\":65466,\"start\":65460},{\"end\":65478,\"start\":65466},{\"end\":65826,\"start\":65819},{\"end\":65833,\"start\":65826},{\"end\":65841,\"start\":65833},{\"end\":66218,\"start\":66211},{\"end\":66224,\"start\":66218},{\"end\":66233,\"start\":66224},{\"end\":66239,\"start\":66233},{\"end\":66245,\"start\":66239},{\"end\":66253,\"start\":66245},{\"end\":66259,\"start\":66253},{\"end\":66626,\"start\":66620},{\"end\":66634,\"start\":66626},{\"end\":66643,\"start\":66634}]", "bib_venue": "[{\"end\":54357,\"start\":54268},{\"end\":57710,\"start\":57618},{\"end\":58301,\"start\":58210},{\"end\":59762,\"start\":59694},{\"end\":60291,\"start\":60211},{\"end\":60796,\"start\":60719},{\"end\":61330,\"start\":61238},{\"end\":61882,\"start\":61781},{\"end\":54357,\"start\":54268},{\"end\":57710,\"start\":57618},{\"end\":58301,\"start\":58210},{\"end\":59762,\"start\":59694},{\"end\":60291,\"start\":60211},{\"end\":60796,\"start\":60719},{\"end\":61330,\"start\":61238},{\"end\":61882,\"start\":61781},{\"end\":51753,\"start\":51732},{\"end\":52010,\"start\":51992},{\"end\":52351,\"start\":52339},{\"end\":52657,\"start\":52564},{\"end\":52972,\"start\":52956},{\"end\":53234,\"start\":53208},{\"end\":53566,\"start\":53535},{\"end\":53916,\"start\":53902},{\"end\":54266,\"start\":54177},{\"end\":54779,\"start\":54748},{\"end\":55065,\"start\":54986},{\"end\":55508,\"start\":55497},{\"end\":55871,\"start\":55854},{\"end\":56181,\"start\":56069},{\"end\":56624,\"start\":56475},{\"end\":57071,\"start\":56961},{\"end\":57616,\"start\":57521},{\"end\":58208,\"start\":58114},{\"end\":58843,\"start\":58794},{\"end\":59217,\"start\":59090},{\"end\":59692,\"start\":59628},{\"end\":60209,\"start\":60137},{\"end\":60717,\"start\":60638},{\"end\":61236,\"start\":61151},{\"end\":61779,\"start\":61680},{\"end\":62286,\"start\":62217},{\"end\":62618,\"start\":62607},{\"end\":62908,\"start\":62900},{\"end\":63218,\"start\":63199},{\"end\":63651,\"start\":63613},{\"end\":63967,\"start\":63906},{\"end\":64279,\"start\":64172},{\"end\":64611,\"start\":64509},{\"end\":65066,\"start\":64949},{\"end\":65447,\"start\":65363},{\"end\":65817,\"start\":65726},{\"end\":66282,\"start\":66259},{\"end\":66618,\"start\":66516},{\"end\":51753,\"start\":51732},{\"end\":52010,\"start\":51992},{\"end\":52351,\"start\":52339},{\"end\":52657,\"start\":52564},{\"end\":52972,\"start\":52956},{\"end\":53234,\"start\":53208},{\"end\":53566,\"start\":53535},{\"end\":53916,\"start\":53902},{\"end\":54266,\"start\":54177},{\"end\":54779,\"start\":54748},{\"end\":55065,\"start\":54986},{\"end\":55508,\"start\":55497},{\"end\":55871,\"start\":55854},{\"end\":56181,\"start\":56069},{\"end\":56624,\"start\":56475},{\"end\":57071,\"start\":56961},{\"end\":57616,\"start\":57521},{\"end\":58208,\"start\":58114},{\"end\":58843,\"start\":58794},{\"end\":59217,\"start\":59090},{\"end\":59692,\"start\":59628},{\"end\":60209,\"start\":60137},{\"end\":60717,\"start\":60638},{\"end\":61236,\"start\":61151},{\"end\":61779,\"start\":61680},{\"end\":62286,\"start\":62217},{\"end\":62618,\"start\":62607},{\"end\":62908,\"start\":62900},{\"end\":63218,\"start\":63199},{\"end\":63651,\"start\":63613},{\"end\":63967,\"start\":63906},{\"end\":64279,\"start\":64172},{\"end\":64611,\"start\":64509},{\"end\":65066,\"start\":64949},{\"end\":65447,\"start\":65363},{\"end\":65817,\"start\":65726},{\"end\":66282,\"start\":66259},{\"end\":66618,\"start\":66516}]"}}}, "year": 2023, "month": 12, "day": 17}