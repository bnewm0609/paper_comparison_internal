{"id": 134354772, "updated": "2022-02-19 11:36:33.852", "metadata": {"title": "A nowcasting model for the prediction of typhoon tracks based on a long short term memory neural network", "authors": "[{\"first\":\"Song\",\"last\":\"Gao\",\"middle\":[]},{\"first\":\"Peng\",\"last\":\"Zhao\",\"middle\":[]},{\"first\":\"Bin\",\"last\":\"Pan\",\"middle\":[]},{\"first\":\"Yaru\",\"last\":\"Li\",\"middle\":[]},{\"first\":\"Min\",\"last\":\"Zhou\",\"middle\":[]},{\"first\":\"Jiangling\",\"last\":\"Xu\",\"middle\":[]},{\"first\":\"Shan\",\"last\":\"Zhong\",\"middle\":[]},{\"first\":\"Zhenwei\",\"last\":\"Shi\",\"middle\":[]}]", "venue": "Acta Oceanologica Sinica", "journal": "Acta Oceanologica Sinica", "publication_date": {"year": 2018, "month": null, "day": null}, "abstract": "It is of vital importance to reduce injuries and economic losses by accurate forecasts of typhoon tracks. A huge amount of typhoon observations have been accumulated by the meteorological department, however, they are yet to be adequately utilized. It is an effective method to employ machine learning to perform forecasts. A long short term memory (LSTM) neural network is trained based on the typhoon observations during 1949\u20132011 in China\u2019s Mainland, combined with big data and data mining technologies, and a forecast model based on machine learning for the prediction of typhoon tracks is developed. The results show that the employed algorithm produces desirable 6\u201324 h nowcasting of typhoon tracks with an improved precision.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": "2799572365", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": null, "doi": "10.1007/s13131-018-1219-z"}}, "content": {"source": {"pdf_hash": "a080580f2bba04df6d19e60e4b2ae5dd28011197", "pdf_src": "MergedPDFExtraction", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "0515bba6a0455937720fc8916a8a2320a2ceadfa", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/a080580f2bba04df6d19e60e4b2ae5dd28011197.txt", "contents": "\nA nowcasting model for the prediction of typhoon tracks based on a long short term memory neural network\n\n\nGao Song \nNorth China Sea Marine Forecasting Center of State Oceanic Administration\nState Oceanic Administration\n266061QingdaoChina\n\nShandong Provincial Key Laboratory of Marine Ecological Environment and Disaster Prevention and Mitigation\n266061QingdaoChina\n\nZhao Peng \nNorth China Sea Marine Forecasting Center of State Oceanic Administration\nState Oceanic Administration\n266061QingdaoChina\n\nShandong Provincial Key Laboratory of Marine Ecological Environment and Disaster Prevention and Mitigation\n266061QingdaoChina\n\nYaru Li \nNorth China Sea Marine Forecasting Center of State Oceanic Administration\nState Oceanic Administration\n266061QingdaoChina\n\nShandong Provincial Key Laboratory of Marine Ecological Environment and Disaster Prevention and Mitigation\n266061QingdaoChina\n\nImage Processing Center\nSchool of Astronautics\nBeihang University\n100191BeijingChina\n\nMin Zhou \nImage Processing Center\nSchool of Astronautics\nBeihang University\n100191BeijingChina\n\nJiangling Xu \nNorth China Sea Marine Forecasting Center of State Oceanic Administration\nState Oceanic Administration\n266061QingdaoChina\n\nShan Zhong \nNorth China Sea Marine Forecasting Center of State Oceanic Administration\nState Oceanic Administration\n266061QingdaoChina\n\nShandong Provincial Key Laboratory of Marine Ecological Environment and Disaster Prevention and Mitigation\n266061QingdaoChina\n\nShi Zhenwei \nShandong Provincial Key Laboratory of Marine Ecological Environment and Disaster Prevention and Mitigation\n266061QingdaoChina\n\nImage Processing Center\nSchool of Astronautics\nBeihang University\n100191BeijingChina\n\nGao Song \nZhao Peng \nPan Bin \nLi Yaru \nZhou Min \nXu Jiangling \nZhong Shan \nShi Zhenwei \nA nowcasting model for the prediction of typhoon tracks based on a long short term memory neural network\n10.1007/s13131-018-1219-zReceived 16 July 2016; accepted 16 August 2017typhoon tracksmachine learningLSTMbig data\nIt is of vital importance to reduce injuries and economic losses by accurate forecasts of typhoon tracks. A huge amount of typhoon observations have been accumulated by the meteorological department, however, they are yet to be adequately utilized. It is an effective method to employ machine learning to perform forecasts. A long short term memory (LSTM) neural network is trained based on the typhoon observations during 1949-2011 in China's Mainland, combined with big data and data mining technologies, and a forecast model based on machine learning for the prediction of typhoon tracks is developed. The results show that the employed algorithm produces desirable 6-24 h nowcasting of typhoon tracks with an improved precision. . 2018. A nowcasting model for the prediction of typhoon tracks based on a long short term memory neural network. Acta Oceanologica Sinica, 37(5): 8-12,\n\nIntroduction\n\nTyphoons are typical tropical weather systems, which impose severe threats to people's lives, property security and the development of the regional economics in the coastal areas. Timely prediction and warnings of a typhoon can provide effective information support to disaster prevention departments, and reduce injuries and economic losses effectively. Therefore, it is an important research topic to accurately predict typhoon tracks. However, typhoon tracks are influenced by the typhoon background fields, the thermodynamics and kinetics of the typhoon system, etc. (Huang and Jin, 2013). In addition, after the landing of a typhoon, its tracks are influenced by the complex bathymetry and coastline of the coastal region and the topography of the inland, etc. (Yu et al., 2012). It is thus a rather complex and integrated challenge to resolve the typhoon tracks.\n\nThe existing forecasting operations mainly rely on the subjective empirical forecasts in the early stage. Chen and Ding (1979) summarized the track types of the typhoon happened in the Northwest Pacific, which provided an empirical reference to the prediction of typhoon tracks. With the development of monitoring methods and computer technology, numerical forecasts of typhoon tracks have been widely developed in recent years. Currently, the forecasting of typhoon tracks has formed a comprehensive system utilizing a wide range of data and methods, which is based on numerical forecasting and combined with human machine interface (Qian et al., 2012). Wang et al. (1996) proposed a scheme for the initial field for the numerical forecasting of typhoon based on artificial data and observations, and applied it to the forecast of typhoon tracks in the South China Sea. Qian et al. (2012) discussed the influence of different initial field and lateral boundary conditions on the accuracy of typhoon numerical forecasts. Li and Chen (2002) reviewed the operating application of the ensemble numerical forecast system in China. Xu et al. (2014) proposed a typhoon forecasting strategy based on GRAPES with an improved convective parameterization. However, although numerical forecasts have been widely applied, the accuracy is still lower than that of empirical forecasting methods . According to the published data by Shanghai Typhoon Institute of China Meteorological Administration, the current forecasting status of 24 h, 48 h and 72 h typhoon track errors based on subjective empirical methods are 84.2 km, 145.6 km and 205.4 km, respectively, and those based on regional numerical models are 97.4 km, 188.2 km and 302.7 km, respectively (Xu et al., 2010). It is still challenging to further improve the accuracy of the numerical forecasting models.\n\nCurrently, a three-dimensional typhoon observation system has been established preliminarily, including meteorological satellites, oceanic observation stations, and ground observation posts, which provides numerous data to operating departments and research institutes (Hochreiter and Schmidhuber, 1997). In addition, an enormous number of typhoon observations have been accumulated by typhoon forecasting institutes since 1949. In the era of big data, it is an urgent task to improve the numerical forecasting accuracy by utilizing these data. With the development of machine learning algorithms, especially recurrent neural networks (RNNs), long and short term memory neural networks (LSTM), etc., new ways to solve prediction and regression issues have become available. Inspired by the outstanding performance of LSTM models in image recognition and visual descriptions (Xu et al., 2015), a forecasting model for typhoon tracks is developed based on a deep learning algorithm in this paper, with a large number of observation samples to train the model.\n\nThe essence of deep learning algorithms is using a large number of samples to train an end-to-end network and then performing forecasts using test data by this trained network. As there are many parameters involved in the network, sufficient training data are needed to train the model. Research shows that deep learning algorithms can improve the accuracy remarkably with sufficient samples to train the network. A reasonable employment of a deep neural network to deal with the large number of big data can improve the forecast precision of typhoon tracks. RNNs are one of the most widely used regression prediction neural network algorithms. However, the gradient in RNN may disappear, i.e., errors cannot propagate backward to a far-away previous neuron (Donahue et al., 2015). The LSTM is a classic solution to this issue. In LSTM model, the normal neurons containing activation functions are replaced by a memory cell to resolve the disappearance of the gradient. Meanwhile, values of information can be stored in the network within any length of time due to this scheme. Ranzato et al. (2014) proposed a video interpretation algorithm based on the LSTM. Sutskever et al. (2014) employed the LSTM algorithm to predict a time series, and obtained reasonable results. Studies show that deep learning algorithms, especially LSTM, can be employed in weather forecasting and ocean remote sensing areas. Yin et al. (2015) predicted the atmosphere pollution levels using a deep belief network. You et al. (2016) adopted a traditional error back-propagation neural network based on phase space reconstruction to predict storm surges. Shi et al. (2015) proposed a prediction model for precipitation based on a convolutional LSTM algorithm. The aforementioned studies indicate that deep learning algorithms are effective tools to establish models and perform predictions using big data.\n\nA prediction model for typhoon tracks is proposed in this paper based on a deep learning algorithm. The observations of typhoon tracks from 1949 to 2012 provided by the North China Sea Marine Forecasting Center of State Oceanic Administration of China are used to train the LSTM neural network. Six to twenty-four hours typhoon tracks are predicted and compared to observations. The contributions of this paper are threefold.\n\n(1) The typhoon observations during 1949 and 2012 are analyzed comprehensively and a typhoon data set is established.\n\n(2) A deep learning model based on the LSTM is established to predict typhoon tracks using typhoon big data. The applicability of the deep learning algorithm to typhoon tracks prediction is validated.\n\n(3) Six to twenty-four hours typhoon tracks are predicted to provide information support to relevant personnel.\n\n\nPrediction model for typhoon tracks based on LSTM algorithm\n\nThe LSTM algorithm is developed based on the RNNs. The recurrent and error back propagation processes are retained in LSTM, with long and short-term memory cells used to replace the hidden neurons in a traditional RNN. An introduction of the RNN is presented firstly in this section, which leads to the introduction to the LSTM algorithm for clarity. Then the LSTM algorithm is applied to establish a prediction model of typhoon tracks.\n\n\nA brief introduction to RNN\n\nTraditional feedforward neural networks (FNNs) have promising performance in many fields. However, their performance is poor in dealing with time series such as videos. This is mainly due to the following two aspects. First, the input format of an FNN is a vector of a fixed length. Second, samples in an FNN are assumed to be independent, i.e., they are not related to either temporally or spatially. RNNs have fixed this problem and achieved satisfying performance in speech recognition, machine translation, image interpretation, etc., because an RNN can process each element in the input series one by one, and pass the filtered information in a series in the neural network to retain the correlation among elements in a series.\n\nCompared with an FNN, an RNN allows a series format for the input and output, and breaks the limit to only allow data propagate to a forward level one by one. The input and output of an FNN are normally a vector of a fixed length, while those of an RNN can be a time series like (x 1 , x 2 , ..., x t ) and (y 1 , y 2 , ..., y t ), the length of which can be finite or infinite, where x and y are vectors, and the superscripts are index number which can be taken as time for a time series. Every sample in an RNN is a couple of an input series and an output series.\n\nThe output of a hidden neuron only can be directed to neurons on the next layer in an FNN, while in an RNN, that can be passed on to neurons on the same layer and also itself, therefore, information can be passed without a \"time\" limit. As shown in the dashed lines represent the information flow without a \"time\" limit. With this scheme, it is hard to train an RNN using error back propagation (BP), and thus the back propagation through time (BPTT) method is used to unfold the network by time. The left column in Fig. 1 is an illustration of an RNN and the right column is its unfolded structure by the BPTT. The hidden neurons at time step t can get information of the input at the current time step x t , as well as the information of the hidden layer at the previous time step h t-1 , i.e., h t = \u03c3(W hx x t +W hh h t-1 +b h ). Unfolding an RNN by time makes it much easier to train the network as the temporally overlapped parts in an RNN is unfolded as a traditional FNN, which makes the RNN method widely applied.\n\n\nLSTM models\n\nAlthough time is introduced in an RNN, and the output of a current time step can be passed to the next time step, the information will be lost unless the value at the next time step is the same as the current one, i.e., the information in a series can only impact the neighboring elements, not any farther. Therefore, the impact is very short in time, the information cannot be stored in the network for a longer time during training, and disappearance or explosion of gradient can happen during error back propagation. Therefore, long and short term memory cells are introduced to store information for any time length to mitigate the disappearance or explosion of gradient remarkably, which is a temporally recurrent neural network called long-short term memory (LSTM).\ng t c = \u00be \u00a1 W t + W t\u00a11 + b \u00a2\nA special cell structure is used to replace the original hidden neurons in the LSTM. An illustration of the LSTM is shown in Fig.  2, where \u03c3 represents the sigmoid function, \u220f represents multiplication, the subscript c means that it is a single structure, and all the solid arrows mean that the connection weight is 1. s c is a memory cell, which is a linear element used to store information to guarantee that information can be stored for a long time to retain the correlation among elements in a sequence. g c is the input node, which denotes the comprehensive interaction of the input at time step t and the information of previous network status. Its value can be passed on to a memory cell through the control of an input gate i c . If W is the weight, b is the threshold, then\n\n. i c is the input gate, which receives the input at time step t and the network status information at previous time steps, and pass the input value of node g c into a memory cell s c after the control of the sigmoid function. f c is the forget gate, which determines whether the value of s c is stored or not: if the weight is 1, it is stored as it was, and if it is 0, it is cleared.\n\nO c is the output gate, which receives the input at the time step t and the network status information at previous time step. It controls the output of s c after the sigmoid function. v c is the output value.\n\nUse x and h vectors to denote the values of each layer, then\ng t = tanh \u00a1 W g t + W g t\u00a11 + b g \u00a2 ; i t = \u00be \u00a1 W i t + W i t\u00a11 + b i \u00a2 ; f t = \u00be \u00a1 W f t + W f t\u00a11 + b f \u00a2 ; o t = \u00be \u00a1 W o t + W o t\u00a11 + b o \u00a2 ; s t = g t\u00afit + s t\u00a11 \u00a2 f t ; t = tanh(s t )\u00afo t ;\nwhere \u2299 is dot product. is the coordinates of a two-dimensional vector, the subscript of represents its dimension, the superscript of represents its index in the series, and each two neighboring elements have a time difference of \u0394t. Considering that when performing predictions of the typhoon position after m\u00b7\u0394t, the typhoon positions at the previous n time steps are necessary to show the typhoon track and subsequently obtain a more accurate prediction, the input series of the LSTM should be and the corresponding output sequence is . One input sequence and the corresponding output series form a sample.\n\n\nPrediction model for typhoon tracks based on LSTM\n\u00b3 \u00a3 x 1 1 ; x 1 2 \u00a4 T ; \u00a3 x 2 1 ; x 2 2 \u00a4 T ; : : : ; \u00a3 x t 1 ; x t 2 \u00a4 T\u00b4\u00a3 x 1 1 ; x 1 2 \u00a4 T\nAn LSTM neural network for the prediction of typhoon tracks is designed in this way with three layers, i.e., an input layer, a hidden layer, and an output layer. There are 2n neurons on the input layer, i.e., the dimension of each element in the input sequence is 2n. The hidden layer consists of 20 long-short term memory cells. There are 2 neurons on the output layer, i.e., the dimension of each element in the output series is 2.\n\nWhen training the network, all the network parameters are initialized as random numbers between 0 and 1, and then optimized using the training samples. For each training sample, each element in the series is read one by one by the LSTM neural network. An output vector is derived after the hidden layer and the output layer, which is then compared with labels and the errors are back propagated backward by the BPTT algorithm. The test process follows the same way as the training process.\n\n\nExperiments\n\nTwo experiments were designed in this section. The first one was used to verify the feasibility of a typhoon-track-prediction LSTM network. In the second experiment, training data sets with different amount of samples were used to train the LSTM network, so as to discuss the effectiveness of big data. All the experimental data in this section were from CMA-STI optimal tracks data set of tropical cyclones, which recorded the tracks of the tropical cyclones happened in the Northwest Pacific during 1949 Fig. 2. A memory cell of the LSTM. and 2011, where the typhoon tracks were recorded using longitude-latitude coordinates with an average precision of 0.1\u00b0 at every 6 h. The test results were measured by the mean distance errors.\nS c t = g c t \u00b7 i c t + f c t \u00b7 S c t-1 v c t = S c t \u00b7 O c t i c t g c t f c t O c t \u03c3 \u03c3 \u03c3 \u03c3\n\nFeasibility experiment\n\nTo prove the feasibility of the LSTM neural network to predict typhoon tracks, typhoon positions in 6 h, 12 h, 18 h, 24 h, 48 h, and 72 h were predicted in this experiment, and six data set couples were generated with training set to test set ratio being 8:1. Test results are shown in Fig. 3. The results demonstrate that with the prediction time goes on, the prediction error increases. The prediction results are compared with subjective empirical methods and regional numerical modeling in Table 1. The LSTM network obtained relatively accurate results in 6, 12, and 18 prediction. The prediction error of the LSTM network is comparable to those of the subjective empirical methods and the regional numerical modeling for 24 h predictions, while it soars and becomes much higher than the latter two for 48 h and 72 h predictions. Therefore, it is only meaningful to perform predictions within 24 h using the LSTM network, which also contributes a new method for the prediction of typhoon tracks.\n\n\nExperiment with data sets of various samples\n\nTo examine whether the prediction accuracy can be improved with a larger training dataset, 6 h, 12 h, 18 h, and 24 h predictions were performed with the same dataset correspondingly, yet with the number ratio of samples in the training data set to test the data set being 2:1, 3:1, 4:1, 5:1, 6:1, 7:1 and 8:1, respectively. The experiment results are shown in Fig. 4 and Table 2. It can be seen that the prediction error decreases with a larger training data set, i.e., the prediction accuracy of a LSTM neural network will increase with a larger amount of typhoon tracks observations.\n\n\nConclusions\n\nA prediction method for typhoon tracks based on a LSTM neural network is proposed in this paper. The CMA-STI optimal tracks data set of tropical cyclones are used for training and testing. The results show that the 24 h prediction errors are reasonable and comparable to those of the traditional subjective empir-ical method and the regional numerical modeling. Therefore, it provides a new and feasible method for the prediction of typhoon tracks. It also indicates that the typhoon tracks prediction error of the LSTM neural network can be reduced by using a larger training data set. Therefore, with increasingly larger amount of typhoon observations, the prediction accuracy of the LSTM neural network will increase.\n\nIn this paper, only the typhoon tracks observations are used as the input for the prediction. More information can be included in future studies, such as the central pressure, topo-  graphy, etc., to improve the structure and accuracy of the model.\n\nFig. 1 ,Fig. 1 .\n11the solid lines denote the information flow in an RNNUnfolding an RNN by the BPTT.\n\nFig. 3 .Fig. 4 .\n34Prediction errors of the LSTM neural network with time. Results of the experiment with various number of samples in the training data set.\n\nTable 1 .\n1Prediction errors (km) of different methodsTable 2. Results of the experiment with various number of samples in the training data setPrediction time/h \nLSTM \nSubjective empirical methods \nRegional numerical modeling \n6 \n45.954 0 \n\u2212 \n\u2212 \n12 \n63.367 0 \n\u2212 \n\u2212 \n18 \n101.624 3 \n\u2212 \n\u2212 \n24 \n105.676 8 \n84.2 \n97.4 \n48 \n332.540 7 \n145.6 \n188.2 \n72 \n974.498 5 \n205.4 \n302.7 \n\nRatio of sample numbers in the training \ndata set to the test data set \n6 h errors/km \n12 h errors/km \n18 h errors/km \n24 h errors/km \n\n2 \n124.538 2 \n133.687 2 \n153.748 2 \n165.683 2 \n3 \n103.423 8 \n93.895 5 \n142.489 5 \n162.895 3 \n4 \n71.380 6 \n82.986 8 \n138.851 0 \n157.741 7 \n5 \n72.032 1 \n75.312 8 \n136.997 9 \n142.976 1 \n6 \n71.918 1 \n70.068 3 \n134.244 2 \n136.910 6 \n7 \n47.212 4 \n67.421 5 \n113.758 2 \n115.425 5 \n8 \n45.954 0 \n63.367 0 \n101.624 3 \n105.676 8 \n\n\n\nVerification on forecasts of tropical cyclones over western north Pacific in 2014. Meteorological Monthly. Chen Guomin, Cao Qing, Bai Lina, in ChineseChen Guomin, Cao Qing, Bai Lina. 2015. Verification on forecasts of tropical cyclones over western north Pacific in 2014. Meteorolo- gical Monthly (in Chinese), 41(12): 1554-1561\n\nLong-term recurrent convolutional networks for visual recognition and description. J Donahue, Anne Hendricks, L Guadarrama, S , 10.1109/CVPR.2015.7298878Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionBoston, MAIEEEDonahue J, Anne Hendricks L, Guadarrama S, et al. 2015. Long-term recurrent convolutional networks for visual recognition and de- scription. In: Proceedings of the IEEE Conference on Com- puter Vision and Pattern Recognition. Boston, MA: IEEE, 2625-2634, doi: 10.1109/CVPR.2015.7298878\n\nLong short-term memory. S Hochreiter, J Schmidhuber, Neural Computation. 98Hochreiter S, Schmidhuber J. 1997. Long short-term memory. Neural Computation, 9(8): 1735-1780\n\nAn artificial intelligence prediction model for typhoon tracks based on principal component analysis. Jin Huang Xiaoyan, Long, Chinese Journal of Atmospheric Sciences. 375in ChineseHuang Xiaoyan, Jin Long. 2013. An artificial intelligence prediction model for typhoon tracks based on principal component ana- lysis. Chinese Journal of Atmospheric Sciences (in Chinese), 37(5): 1154-1164\n\nThe development and application of the operational ensemble prediction system at national meteorological center. Li Zechun, Chen Dehui, Journal of Applied Meteorological Science. 131in ChineseLi Zechun, Chen Dehui. 2002. The development and application of the operational ensemble prediction system at national met- eorological center. Journal of Applied Meteorological Science (in Chinese), 13(1): 1-15\n\nThe current status and future development of China operational typhoon forecasting and its key technologies. Qian Chuanhai, Duan Rihong, Ma Suhong, Advances in Meteorological Science and Technology. 2in ChineseQian Chuanhai, Duan Rihong, Ma Suhong, et al. 2012. The current status and future development of China operational typhoon forecasting and its key technologies. Advances in Meteorologic- al Science and Technology (in Chinese), 2(5): 36-43\n\nConvolutional LSTM network: a machine learning approach for precipitation nowcasting. M A Ranzato, A Szlam, J Bruna, Proceedings of the 28th International Conference on Neural Information Processing Systems. the 28th International Conference on Neural Information Processing SystemsCambridgeMIT PressEprint Arxiv Shi XingjianVideo (language) modeling: a baseline for generative models of natural videosRanzato M A, Szlam A, Bruna J, et al. 2014. Video (language) model- ing: a baseline for generative models of natural videos. Eprint Arxiv Shi Xingjian, Chen Z, Wang H, et al. 2015. Convolutional LSTM net- work: a machine learning approach for precipitation nowcast- ing. In: Proceedings of the 28th International Conference on Neural Information Processing Systems. Cambridge: MIT Press, 802-810\n\nSequence to sequence learning with neural networks. I Sutskever, O Vinyals, Q V Le, Proceedings of the 27th International Conference on Neural Information Processing Systems. the 27th International Conference on Neural Information Processing SystemsMontreal, CanadaMIT PressSutskever I, Vinyals O, Le Q V. 2014. Sequence to sequence learning with neural networks. In: Proceedings of the 27th International Conference on Neural Information Processing Systems. Montreal, Canada: MIT Press, 3104-3112\n\nPreliminary test of typhoon trace numerical prediction for the South China Sea area. Wang Kangling, He Anguo, Xue Jishan, Journal of Tropical Meteorology (in Chinese). 122Wang Kangling, He Anguo, Xue Jishan. 1996. Preliminary test of typhoon trace numerical prediction for the South China Sea area. Journal of Tropical Meteorology (in Chinese), 12(2): 113-121\n\nThe influence of an improved cumulus parameterization scheme on typhoon forecast from GRAPES model. Xu Daosheng, Chen Zitong, Dai Guangfeng, Journal of Tropical Meteorology. 302in ChineseXu Daosheng, Chen Zitong, Dai Guangfeng, et al. 2014. The influ- ence of an improved cumulus parameterization scheme on typhoon forecast from GRAPES model. Journal of Tropical Met- eorology (in Chinese), 30(2): 210-218\n\nShow, attend and tell: neural image caption generation with visual attention. K Xu, J Ba, R Kiros, Computer Science. Xu K, Ba J, Kiros R, et al. 2015. Show, attend and tell: neural image caption generation with visual attention. Computer Science, 2048-2057\n\nThe advances and discussions on China operational typhoon forecasting. Meteorological Monthly. Xu Yinglong, Zhang Ling, Gao Shuanzhu, 36in ChineseXu Yinglong, Zhang Ling, Gao Shuanzhu. 2010. The advances and discussions on China operational typhoon forecasting. Meteor- ological Monthly (in Chinese), 36(7): 43-49\n\nDeep learning based air pollutant forecasting with big data. Yin Wenjun, Zhang Dawei, Yan Jinghai, Chinese Journal of Environmental Management. 76in ChineseYin Wenjun, Zhang Dawei, Yan Jinghai, et al. 2015. Deep learning based air pollutant forecasting with big data. Chinese Journal of Environmental Management (in Chinese), 7(6): 46-52\n\nStorm surge prediction method of neural network based on phase space reconstruction. You Cheng, Yu Fujiang, Yuan Ye, 33Marine Forecastsin ChineseYou Cheng, Yu Fujiang, Yuan Ye. 2016. Storm surge prediction meth- od of neural network based on phase space reconstruction. Marine Forecasts (in Chinese), 33(1): 59-64\n\nAnalyses in errors and their causes of Chinese typhoon track operational forecasts. Yu Jinhua, Tang Jiaxiang, Dai Yuhan, Meteorological Monthly (in Chinese). 38Yu Jinhua, Tang Jiaxiang, Dai Yuhan, et al. 2012. Analyses in errors and their causes of Chinese typhoon track operational fore- casts. Meteorological Monthly (in Chinese), 38(6): 695-700\n", "annotations": {"author": "[{\"end\":367,\"start\":108},{\"end\":628,\"start\":368},{\"end\":973,\"start\":629},{\"end\":1069,\"start\":974},{\"end\":1206,\"start\":1070},{\"end\":1468,\"start\":1207},{\"end\":1694,\"start\":1469},{\"end\":1704,\"start\":1695},{\"end\":1715,\"start\":1705},{\"end\":1724,\"start\":1716},{\"end\":1733,\"start\":1725},{\"end\":1743,\"start\":1734},{\"end\":1757,\"start\":1744},{\"end\":1769,\"start\":1758},{\"end\":1782,\"start\":1770}]", "publisher": null, "author_last_name": "[{\"end\":116,\"start\":112},{\"end\":377,\"start\":373},{\"end\":636,\"start\":634},{\"end\":982,\"start\":978},{\"end\":1082,\"start\":1080},{\"end\":1217,\"start\":1212},{\"end\":1480,\"start\":1473},{\"end\":1703,\"start\":1699},{\"end\":1714,\"start\":1710},{\"end\":1723,\"start\":1720},{\"end\":1732,\"start\":1728},{\"end\":1742,\"start\":1739},{\"end\":1756,\"start\":1747},{\"end\":1768,\"start\":1764},{\"end\":1781,\"start\":1774}]", "author_first_name": "[{\"end\":111,\"start\":108},{\"end\":372,\"start\":368},{\"end\":633,\"start\":629},{\"end\":977,\"start\":974},{\"end\":1079,\"start\":1070},{\"end\":1211,\"start\":1207},{\"end\":1472,\"start\":1469},{\"end\":1698,\"start\":1695},{\"end\":1709,\"start\":1705},{\"end\":1719,\"start\":1716},{\"end\":1727,\"start\":1725},{\"end\":1738,\"start\":1734},{\"end\":1746,\"start\":1744},{\"end\":1763,\"start\":1758},{\"end\":1773,\"start\":1770}]", "author_affiliation": "[{\"end\":239,\"start\":118},{\"end\":366,\"start\":241},{\"end\":500,\"start\":379},{\"end\":627,\"start\":502},{\"end\":759,\"start\":638},{\"end\":886,\"start\":761},{\"end\":972,\"start\":888},{\"end\":1068,\"start\":984},{\"end\":1205,\"start\":1084},{\"end\":1340,\"start\":1219},{\"end\":1467,\"start\":1342},{\"end\":1607,\"start\":1482},{\"end\":1693,\"start\":1609}]", "title": "[{\"end\":105,\"start\":1},{\"end\":1887,\"start\":1783}]", "venue": null, "abstract": "[{\"end\":2887,\"start\":2002}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3495,\"start\":3474},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":3686,\"start\":3669},{\"end\":3899,\"start\":3879},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":4426,\"start\":4407},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":4446,\"start\":4428},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":4662,\"start\":4644},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":4812,\"start\":4794},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":4916,\"start\":4900},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":5532,\"start\":5515},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":5931,\"start\":5897},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":6519,\"start\":6502},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":7467,\"start\":7445},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":7786,\"start\":7765},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":7871,\"start\":7848},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":8108,\"start\":8091},{\"end\":8336,\"start\":8319}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":20016,\"start\":19914},{\"attributes\":{\"id\":\"fig_1\"},\"end\":20175,\"start\":20017},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":21006,\"start\":20176}]", "paragraph": "[{\"end\":3771,\"start\":2903},{\"end\":5626,\"start\":3773},{\"end\":6685,\"start\":5628},{\"end\":8569,\"start\":6687},{\"end\":8996,\"start\":8571},{\"end\":9115,\"start\":8998},{\"end\":9317,\"start\":9117},{\"end\":9430,\"start\":9319},{\"end\":9930,\"start\":9494},{\"end\":10694,\"start\":9962},{\"end\":11261,\"start\":10696},{\"end\":12285,\"start\":11263},{\"end\":13072,\"start\":12301},{\"end\":13887,\"start\":13103},{\"end\":14274,\"start\":13889},{\"end\":14484,\"start\":14276},{\"end\":14546,\"start\":14486},{\"end\":15353,\"start\":14744},{\"end\":15933,\"start\":15500},{\"end\":16424,\"start\":15935},{\"end\":17174,\"start\":16440},{\"end\":18293,\"start\":17294},{\"end\":18927,\"start\":18342},{\"end\":19663,\"start\":18943},{\"end\":19913,\"start\":19665}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":13102,\"start\":13073},{\"attributes\":{\"id\":\"formula_1\"},\"end\":14743,\"start\":14547},{\"attributes\":{\"id\":\"formula_2\"},\"end\":15499,\"start\":15406},{\"attributes\":{\"id\":\"formula_3\"},\"end\":17268,\"start\":17175}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":17795,\"start\":17788},{\"end\":18720,\"start\":18713}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2901,\"start\":2889},{\"attributes\":{\"n\":\"2\"},\"end\":9492,\"start\":9433},{\"attributes\":{\"n\":\"2.1\"},\"end\":9960,\"start\":9933},{\"attributes\":{\"n\":\"2.2\"},\"end\":12299,\"start\":12288},{\"attributes\":{\"n\":\"2.3\"},\"end\":15405,\"start\":15356},{\"attributes\":{\"n\":\"3\"},\"end\":16438,\"start\":16427},{\"attributes\":{\"n\":\"3.1\"},\"end\":17292,\"start\":17270},{\"attributes\":{\"n\":\"3.2\"},\"end\":18340,\"start\":18296},{\"attributes\":{\"n\":\"4\"},\"end\":18941,\"start\":18930},{\"end\":19931,\"start\":19915},{\"end\":20034,\"start\":20018},{\"end\":20186,\"start\":20177}]", "table": "[{\"end\":21006,\"start\":20321}]", "figure_caption": "[{\"end\":20016,\"start\":19934},{\"end\":20175,\"start\":20037},{\"end\":20321,\"start\":20188}]", "figure_ref": "[{\"end\":11785,\"start\":11779},{\"end\":13235,\"start\":13228},{\"end\":16952,\"start\":16946},{\"end\":17586,\"start\":17580},{\"end\":18708,\"start\":18702}]", "bib_author_first_name": "[{\"end\":21119,\"start\":21115},{\"end\":21131,\"start\":21128},{\"end\":21141,\"start\":21138},{\"end\":21422,\"start\":21421},{\"end\":21436,\"start\":21432},{\"end\":21449,\"start\":21448},{\"end\":21463,\"start\":21462},{\"end\":21958,\"start\":21957},{\"end\":21972,\"start\":21971},{\"end\":22209,\"start\":22206},{\"end\":22607,\"start\":22605},{\"end\":22620,\"start\":22616},{\"end\":23010,\"start\":23006},{\"end\":23025,\"start\":23021},{\"end\":23036,\"start\":23034},{\"end\":23436,\"start\":23433},{\"end\":23447,\"start\":23446},{\"end\":23456,\"start\":23455},{\"end\":24199,\"start\":24198},{\"end\":24212,\"start\":24211},{\"end\":24223,\"start\":24222},{\"end\":24225,\"start\":24224},{\"end\":24734,\"start\":24730},{\"end\":24747,\"start\":24745},{\"end\":24758,\"start\":24755},{\"end\":25108,\"start\":25106},{\"end\":25123,\"start\":25119},{\"end\":25135,\"start\":25132},{\"end\":25492,\"start\":25491},{\"end\":25498,\"start\":25497},{\"end\":25504,\"start\":25503},{\"end\":25768,\"start\":25766},{\"end\":25784,\"start\":25779},{\"end\":25794,\"start\":25791},{\"end\":26050,\"start\":26047},{\"end\":26064,\"start\":26059},{\"end\":26075,\"start\":26072},{\"end\":26413,\"start\":26410},{\"end\":26423,\"start\":26421},{\"end\":26437,\"start\":26433},{\"end\":26726,\"start\":26724},{\"end\":26739,\"start\":26735}]", "bib_author_last_name": "[{\"end\":21126,\"start\":21120},{\"end\":21136,\"start\":21132},{\"end\":21146,\"start\":21142},{\"end\":21430,\"start\":21423},{\"end\":21446,\"start\":21437},{\"end\":21460,\"start\":21450},{\"end\":21969,\"start\":21959},{\"end\":21984,\"start\":21973},{\"end\":22223,\"start\":22210},{\"end\":22229,\"start\":22225},{\"end\":22614,\"start\":22608},{\"end\":22626,\"start\":22621},{\"end\":23019,\"start\":23011},{\"end\":23032,\"start\":23026},{\"end\":23043,\"start\":23037},{\"end\":23444,\"start\":23437},{\"end\":23453,\"start\":23448},{\"end\":23462,\"start\":23457},{\"end\":24209,\"start\":24200},{\"end\":24220,\"start\":24213},{\"end\":24228,\"start\":24226},{\"end\":24743,\"start\":24735},{\"end\":24753,\"start\":24748},{\"end\":24765,\"start\":24759},{\"end\":25117,\"start\":25109},{\"end\":25130,\"start\":25124},{\"end\":25145,\"start\":25136},{\"end\":25495,\"start\":25493},{\"end\":25501,\"start\":25499},{\"end\":25510,\"start\":25505},{\"end\":25777,\"start\":25769},{\"end\":25789,\"start\":25785},{\"end\":25803,\"start\":25795},{\"end\":26057,\"start\":26051},{\"end\":26070,\"start\":26065},{\"end\":26083,\"start\":26076},{\"end\":26419,\"start\":26414},{\"end\":26431,\"start\":26424},{\"end\":26440,\"start\":26438},{\"end\":26733,\"start\":26727},{\"end\":26748,\"start\":26740},{\"end\":26759,\"start\":26750}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":21336,\"start\":21008},{\"attributes\":{\"doi\":\"10.1109/CVPR.2015.7298878\",\"id\":\"b1\",\"matched_paper_id\":5736847},\"end\":21931,\"start\":21338},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":1915014},\"end\":22102,\"start\":21933},{\"attributes\":{\"id\":\"b3\"},\"end\":22490,\"start\":22104},{\"attributes\":{\"id\":\"b4\"},\"end\":22895,\"start\":22492},{\"attributes\":{\"id\":\"b5\"},\"end\":23345,\"start\":22897},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":6352419},\"end\":24144,\"start\":23347},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":7961699},\"end\":24643,\"start\":24146},{\"attributes\":{\"id\":\"b8\"},\"end\":25004,\"start\":24645},{\"attributes\":{\"id\":\"b9\"},\"end\":25411,\"start\":25006},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":1055111},\"end\":25669,\"start\":25413},{\"attributes\":{\"id\":\"b11\"},\"end\":25984,\"start\":25671},{\"attributes\":{\"id\":\"b12\"},\"end\":26323,\"start\":25986},{\"attributes\":{\"id\":\"b13\"},\"end\":26638,\"start\":26325},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":130704497},\"end\":26987,\"start\":26640}]", "bib_title": "[{\"end\":21419,\"start\":21338},{\"end\":21955,\"start\":21933},{\"end\":22204,\"start\":22104},{\"end\":22603,\"start\":22492},{\"end\":23004,\"start\":22897},{\"end\":23431,\"start\":23347},{\"end\":24196,\"start\":24146},{\"end\":24728,\"start\":24645},{\"end\":25104,\"start\":25006},{\"end\":25489,\"start\":25413},{\"end\":26045,\"start\":25986},{\"end\":26722,\"start\":26640}]", "bib_author": "[{\"end\":21128,\"start\":21115},{\"end\":21138,\"start\":21128},{\"end\":21148,\"start\":21138},{\"end\":21432,\"start\":21421},{\"end\":21448,\"start\":21432},{\"end\":21462,\"start\":21448},{\"end\":21466,\"start\":21462},{\"end\":21971,\"start\":21957},{\"end\":21986,\"start\":21971},{\"end\":22225,\"start\":22206},{\"end\":22231,\"start\":22225},{\"end\":22616,\"start\":22605},{\"end\":22628,\"start\":22616},{\"end\":23021,\"start\":23006},{\"end\":23034,\"start\":23021},{\"end\":23045,\"start\":23034},{\"end\":23446,\"start\":23433},{\"end\":23455,\"start\":23446},{\"end\":23464,\"start\":23455},{\"end\":24211,\"start\":24198},{\"end\":24222,\"start\":24211},{\"end\":24230,\"start\":24222},{\"end\":24745,\"start\":24730},{\"end\":24755,\"start\":24745},{\"end\":24767,\"start\":24755},{\"end\":25119,\"start\":25106},{\"end\":25132,\"start\":25119},{\"end\":25147,\"start\":25132},{\"end\":25497,\"start\":25491},{\"end\":25503,\"start\":25497},{\"end\":25512,\"start\":25503},{\"end\":25779,\"start\":25766},{\"end\":25791,\"start\":25779},{\"end\":25805,\"start\":25791},{\"end\":26059,\"start\":26047},{\"end\":26072,\"start\":26059},{\"end\":26085,\"start\":26072},{\"end\":26421,\"start\":26410},{\"end\":26433,\"start\":26421},{\"end\":26442,\"start\":26433},{\"end\":26735,\"start\":26724},{\"end\":26750,\"start\":26735},{\"end\":26761,\"start\":26750}]", "bib_venue": "[{\"end\":21113,\"start\":21008},{\"end\":21568,\"start\":21491},{\"end\":22004,\"start\":21986},{\"end\":22270,\"start\":22231},{\"end\":22669,\"start\":22628},{\"end\":23094,\"start\":23045},{\"end\":23553,\"start\":23464},{\"end\":24319,\"start\":24230},{\"end\":24811,\"start\":24767},{\"end\":25178,\"start\":25147},{\"end\":25528,\"start\":25512},{\"end\":25764,\"start\":25671},{\"end\":26128,\"start\":26085},{\"end\":26408,\"start\":26325},{\"end\":26796,\"start\":26761},{\"end\":21642,\"start\":21570},{\"end\":23638,\"start\":23555},{\"end\":24411,\"start\":24321}]"}}}, "year": 2023, "month": 12, "day": 17}