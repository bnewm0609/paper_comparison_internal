{"id": 248377287, "updated": "2023-10-06 15:10:43.053", "metadata": {"title": "Vertically Federated Graph Neural Network for Privacy-Preserving Node Classification", "authors": "[{\"first\":\"Chaochao\",\"last\":\"Chen\",\"middle\":[]},{\"first\":\"Jun\",\"last\":\"Zhou\",\"middle\":[]},{\"first\":\"Longfei\",\"last\":\"Zheng\",\"middle\":[]},{\"first\":\"Huiwen\",\"last\":\"Wu\",\"middle\":[]},{\"first\":\"Lingjuan\",\"last\":\"Lyu\",\"middle\":[]},{\"first\":\"Jia\",\"last\":\"Wu\",\"middle\":[]},{\"first\":\"Bingzhe\",\"last\":\"Wu\",\"middle\":[]},{\"first\":\"Ziqi\",\"last\":\"Liu\",\"middle\":[]},{\"first\":\"Li\",\"last\":\"Wang\",\"middle\":[]},{\"first\":\"Xiaolin\",\"last\":\"Zheng\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2020, "month": null, "day": null}, "abstract": "Recently, Graph Neural Network (GNN) has achieved remarkable progresses in various real-world tasks on graph data, consisting of node features and the adjacent information between different nodes. High-performance GNN models always depend on both rich features and complete edge information in graph. However, such information could possibly be isolated by different data holders in practice, which is the so-called data isolation problem. To solve this problem, in this paper, we propose VFGNN, a federated GNN learning paradigm for privacy-preserving node classification task under data vertically partitioned setting, which can be generalized to existing GNN models. Specifically, we split the computation graph into two parts. We leave the private data (i.e., features, edges, and labels) related computations on data holders, and delegate the rest of computations to a semi-honest server. We also propose to apply differential privacy to prevent potential information leakage from the server. We conduct experiments on three benchmarks and the results demonstrate the effectiveness of VFGNN.", "fields_of_study": "[\"Computer Science\",\"Mathematics\"]", "external_ids": {"arxiv": "2005.11903", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/ijcai/0001ZZWLWWLWZ22", "doi": "10.24963/ijcai.2022/272"}}, "content": {"source": {"pdf_hash": "f3872ef3743b744736da813249745545a9c1877f", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2005.11903v3.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "4c5fc45376ef8fffca20f01eed7708e31efb340f", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/f3872ef3743b744736da813249745545a9c1877f.txt", "contents": "\nVertically Federated Graph Neural Network for Privacy-Preserving Node Classification\n\n\nChaochao Chen \nZhejiang University\n\n\nJun Zhou jun.zhoujun@antgroup.com \nZhejiang University\n\n\nAnt Group\n3 Sony AI\n\nLongfei Zheng \nAnt Group\n3 Sony AI\n\nHuiwen Wu huiwen.whw@antgroup.com \nAnt Group\n3 Sony AI\n\nLingjuan Lyu lingjuan.lv@sony.com \nJia Wu jia.wu@mq.edu.au \nMacquarie University\n\n\nBingzhe Wu wubingzhe@pku.edu.cn \nPeking University\n\n\nZiqi Liu ziqiliu@antgroup.com \nAnt Group\n3 Sony AI\n\nLi Wang \nAnt Group\n3 Sony AI\n\nXiaolin Zheng xlzheng@zju.edu.cn \nZhejiang University\n\n\nJZTData Technology\n\n\nVertically Federated Graph Neural Network for Privacy-Preserving Node Classification\n\nGraph Neural Network (GNN) has achieved remarkable progresses in various real-world tasks on graph data. High-performance GNN models always depend on both rich features and complete edge information in graph. However, such information could possibly be isolated by different data holders in practice, which is the so-called data isolation problem. To solve this problem, in this paper, we propose Vertically Federated Graph Neural Network (VFGNN), a federated GNN learning paradigm for privacy-preserving node classification task under data vertically partitioned setting, which can be generalized to existing GNN models. Specifically, we split the computation graph into two parts. We leave the private data (i.e., features, edges, and labels) related computations on data holders, and delegate the rest of computations to a semi-honest server. We also propose to apply differential privacy to prevent potential information leakage from the server. We conduct experiments on three benchmarks and the results demonstrate the effectiveness of VFGNN.\n\nIntroduction\n\nGraph Neural Network (GNN) has gained increasing attentions from both academy and industry due to its ability to model high-dimensional feature information and high-order adjacent information on both homogeneous and heterogeneous graphs [Wu et al., 2019]. An important ingredient for high-performance GNN models is high-quality graph data including rich node features and complete adjacent information. However, in practice, such information could possibly be isolated by different data holders, which is the socalled data isolation problem. Such a data isolation problem presents a serious challenge for the development of Artificial Intelligence, which becomes a hot research topic recently. Problem. Figure 1 shows a privacy-preserving node classification problem under vertically partitioned data setting. Here, we assume there are three data holders (A, B, and C) and they * Corresponding Author have four same nodes. The node features are vertically split, i.e., A has f 1, f 2, and f 3, B has f 4 and f 5, and C has f 6 and f 7. Meanwhile, A, B, and C may have their own edges. For example, A has social relation between nodes while B and C have payment relation between nodes. We also assume A is the party who has the node labels. The problem is to build federated GNN models using the graph data of A, B, and C. Related work. To date, many kinds of privacy-preserving machine learning models have been proposed, e.g., logistic regression , decision tree [Fang et al., 2021], and neural network [Wagh et al., 2019]. There are also several work on studying the privacy issues in GNN, e.g., graph publishing [Sajadmanesh and Gatica-Perez, 2020], GNN inference [He et al., 2020], and federated GNN when data are horizontally partitioned [Zheng et al., 2021;. So far, few research has studied the problem of GNN when data are vertically partitioned, which popularly exists in practice. Unlike previous privacy-preserving machine learning models that assume only samples (nodes) are held by different parties and these samples have no relationship, our task is more challenging because GNN relies on the relationships between samples, which are also kept by different data holders. Naive solution. A direct way to build privacy-preserving GNN is employing advanced cryptographic algorithms, such as homomorphic encryption (HE) and secure multi party computation (MPC) [Mohassel and Zhang, 2017]. Such a pure cryptographic way can provide high security guarantees, however, it suffers high computation and communication costs, which limits their efficiency [Osia et al., 2019]. Our solution. Instead, we propose VFGNN, a federated GNN learning paradigm for privacy-preserving node classification task under data vertically partitioned setting. Motivated by the existing work in split learning [Vepakomma et al., 2018;Osia et al., 2019;Gu et al., 2018], we split the computation graph of GNN into two parts for privacy and efficiency concern, i.e., the private data related computations carried out by data holders and non-private data related computations conducted by a semi-honest server.\n\nSpecifically, data holders first apply MPC techniques to compute the initial layer of the GNN using private node feature information collaboratively, which acts as the feature extractor module, and then perform neighborhood aggregation using private edge information individually, similar as the existing GNNs [Veli\u010dkovi\u0107 et al., 2017], and finally get the local node embeddings. Next, we propose different combination strategies for a semi-honest server to combine local node embeddings from data holders and generate global node embeddings, based on which the server can conduct the successive non-private data related computations, e.g., the non-linear operations in deep network structures that are time-consuming for MPC techniques. Finally, the server returns the final hidden layer to the party who has labels to compute prediction and loss. Data holders and the server perform forward and back propagations to complete model training and prediction, during which the private data (i.e., features, edges, and labels) are always kept by data holders themselves. Here we assume data holders are honest-but-curious, and the server does not collude with data holders. We argue that this is a reasonable assumption since the server can be played by authorities such as governments or replaced by trusted execution environment [Costan and Devadas, 2016]. Moreover, we adopt differential privacy, on the exchanged information between server and data holders (e.g., local node embeddings and gradient update), to further protect potential information leakage from the server. Contributions. We summarize our main contributions as:\n\n\u2022 We propose a novel VFGNN learning paradigm, which not only can be generalized to most existing GNNs, but also enjoys good accuracy and efficiency. \u2022 We propose different combination strategies for the server to combine local node embeddings from data holders. \u2022 We evaluate our proposals on three real-world datasets, and the results demonstrate the effectiveness of VFGNN.\n\n\nPreliminaries\n\n\nSecurity Model\n\nIn this paper, we assume the adversary is honest-but-curious (semi-honest). That is, data holders and the server strictly follow the protocol, but they also use all intermediate computation results to infer as much information as possible. We also assume that the server does not collude with any data holders. This security setting is similar as most existing work [Mohassel and Zhang, 2017;Hardy et al., 2017].\n\n\nAdditive Secret Sharing\n\nAdditive Secret Sharing has two main procedures. [Shamir, 1979]. To additively share Shr(\u00b7) an -bit value a for party i \u2208 P = {1, ..., I}, party i generates {a j \u2208 Z 2 , j \u2208 P and j = i} uniformly at random, sends a j to party j, and keeps a i = a\u2212 j a j mod 2 . We use a i = a i to denote the share of party i. To reconstruct Rec(\u00b7, \u00b7) a shared value a , each party i sends a i to one who computes i a i mod 2 . For simplification, we denote additive sharing by \u00b7 . Addition in secret sharing can be done by participants locally. Multiplication in secret sharing usually relies on Beaver's triplet technique [Beaver, 1991].\n\n\nDifferential Privacy\n\nDefinition 1. (Differential Privacy [Dwork et al., 2014]). A randomized algorithm M that takes as input a dataset consisting of individuals is ( , \u03b4)\u2212differentially private (DP) if for any pair of neighbouring data x, y that differ in a single entry, and any event E,\nP [M(x) \u2208 E] \u2264 exp( )P [M(y) \u2208 E] + \u03b4,(1)\nand if \u03b4 = 0, we say that M is \u2212differentially private.\n\nIn [Dwork et al., 2014], the authors pointed out that the 2 \u2212sensitivity of a function f measures the magnitude by which a single individual's data can change the function in the worst case. Definition 2. ( 2 -sensitivity [Dwork et al., 2014]). Suppose x and y are neighbouring inputs that differ in one entry. The 2 -sensitivity of a function f : D \u2192 R d is:\n\u22062f = max x,y\u2208D, x\u2212y =1 f (x) \u2212 f (y) 2.(2)\nDefinition 3. (The Gaussian Mechanism [Dwork et al., 2014]) Given a function f : D \u2192 R d over a dataset D, the Gaussian mechanism is defined as:\nMG(x, f (\u00b7), ) = f (x) + (Y1, \u00b7 \u00b7 \u00b7 , Y k ),(3)\nwhere Y i are i.i.d. random variables drawn from N (0, \u03c3 2 \u2206 2 f 2 ) and \u03c3 = \u221a 2 ln(1.25/\u03b4) .\n\nTheorem 1. [Dwork et al., 2014] The Gaussian mechanism defined in Definition 3 preserves ( , \u03b4)\u2212DP for each publication step.\n\n\nThe Proposed Model\n\n3.1 Overview of VFGNN As described in Section 1, for the sake of privacy and efficiency, we design a vertically federated GNN (VFGNN) learning paradigm by splitting the computational graph of GNN into two parts. That is, we keep the private data related computations to data holders for privacy concern, and delegate the non-private data related computations to a semihonest server for efficiency concern. In the context of GNN, the private data refers to node features, labels, and edges (node relations). To be specific, we divide the computational graph into the following three sub-Computational Graphs (CG), as is shown in Figure 2. CG1: private feature and edge related computations. The first step of GNN is generating initial node embeddings using node's private features, e.g., user features in social networks.\n\nIn vertically data split setting, each data holder has partial node features, as shown in Figure 1. We will present how data holders collaboratively learn initial node embeddings later. In the next step, data holders generate local node embeddings by aggregating multi-hop neighbors' information using different aggregator functions. CG2: non-private data related computations. We delegate non-private data related computations to a semi-honest server for efficiency concern. First, the server combines the local node embeddings from data holders with different COM-BINE strategies, and obtains the global node embeddings. Next, the server can perform the successive computations using plaintext data. Note that this part has many non-linear computations such as max-pooling and activation functions, which are not cryptographically friendly. For example, existing works approximate the non-linear activations by using either piece-wise functions that need secure comparison protocols [Mohassel and Zhang, 2017] or high-order polynomials [Hardy et al., 2017]. Therefore, their accuracy and efficiency are limited. Delegating these plaintext computations to server will not only improve our model accuracy, but also significantly improve our model efficiency, as we will present in experiments. After this, the server gets a final hidden layer (z L ) and sends it back to the data holder who has label to calculate the prediction, where L is the total number of layers of the deep neural network. CG3: private label related computations. The data holder who has label can compute prediction using the final hidden layer it receives from the server. For node classification task, the Softmax activation function is used for the output layer [Kipf and Welling, 2016], which is defined as softmax(z c ) = 1 Z exp(z c ) with c \u2208 C be the node class and Z = c exp(z c ).\n\nIn the following subsections, we will describe three important components of VFGNN, i.e., initial node embeddings generation in CG1, local node embeddings generation in CG2, and global node embedding generation in CG3. (b) Collaboratively Figure 3: Methods of generating initial node embeddings.\n\n\nGenerate Initial Node Embeddings\n\nInitial node embeddings are generated by using node features. Under vertically partitioned data setting, each data holder has partial node features. There are two methods for data holders to generate initial node embeddings, i.e., individually and collaboratively, as shown in Figure 3.\n\nThe 'individually' method means that data holders generate initial node embeddings using their own node features, individually. For data holder i \u2208 P, this can be done by\nh i 0 = (x i ) T \u00b7 W i ,\nwhere x i and W i are node features and weight matrix of data holder i. As the example in Figure 3 (a), A, B, and C generate their initial node embeddings using their own features separately. Although this method is simple and data holders do not need to communicate with each other, it cannot capture the relationship between features of data holders and thus causes information loss.\n\nTo solve the shortcoming of 'individually' method, we propose a 'collaboratively' method. It indicates that data holders generate initial node embeddings using their node features, collaboratively, and meanwhile keep their private features secure. Technically, this can be done by using cryptographic methods such as secret sharing and homomorphic encryption [Acar et al., 2018]. In this paper, we choose additive secret sharing due to its high efficiency.\n\n\nGenerate Local Node Embeddings\n\nWe generate local node embeddings by using multi-hop neighborhood aggregation on graphs, based on initial node embeddings. Note that, neighborhood aggregation should be done by data holders separately, rather than cooperatively, to protect the private edge information. This is because one may infer the neighboorhoold information of v given the neighborhood aggregation results of k-hop (h k v (i)) and k + 1-hop (h k+1 v (i)), if neighborhood aggregation is done by data holders jointly. For \u2200v \u2208 V at each data holder, neighborhood aggregation is the same as the traditional GNN. Take Graph-SAGE [Hamilton et al., 2017] for example, it introduces aggregator functions to update hidden embeddings by sampling and aggregating features from a node's local neighborhood:\nh k N (v) \u2190 AGG k ({h k\u22121 u , \u2200u \u2208 N (v)}), h k v \u2190 (W k \u00b7 CONCAT(h k\u22121 v , h k N (v) )),(4)\nwhere we follow the same notations as GraphSAGE, and the aggregator functions AGG are of three types, i.e., Mean, LSTM, and Pooling. After it, data holders send local node embeddings to a semi-honest server for combination and further non-private data related computations.\n\n\nGenerate Global Node Embeddings\n\nThe server combines the local node embeddings from data holders and gets global node embeddings. The combination strategy (COMBINE) should be trainable and maintaining high representational capacity, and we design three of them.\n\nConcat. The concat operator can fully preserve local node embeddings learnt from different data holders. That is, Line 14 in Algorithm 2 becomes\nh K v \u2190 CONCAT(h K v (1), h K v (2), ..., h K v (I)).(5)\nAlgorithm 1 Information publishing mechanisms of data holders to server using differential privacy Input: Local information of data holders x, dimension of local information d, noise multiplier \u03c3, clipping value C. Output: Differentially private node embeddings. 1: Scale local informationx = min(1, C/ x )x; 2: Draw i.i.d. samples from N (0, \u03c3 2 C 2 ), which forms a d-dimension noise vector n; 3: # Gaussian Mechanism 4: Add noisex = x K + n; 5: # James-Stein Estimator 6: Compute James-Stein Estimator\nx JS = 1 \u2212 (d\u22122)\u03c3 2 C 2 x 2 x 7: returnx orx JS .\nMean. The mean operator takes the elementwise mean of the vectors in ({h K v (i), \u2200i \u2208 P}), assuming data holders contribute equally to the global node embeddings, i.e.,\nh K v \u2190 MEAN(h K v (1) \u222a h K v (2) \u222a ... \u222a h K v (I)).(6)\nRegression. The above two strategies treat data holders equally. In reality, the local node embeddings from different data holder may contribute diversely to the global node embeddings. We propose a Regression strategy to handle this kind of situation. Let \u03c9 i be the weight vector of local node embeddings from data holder i \u2208 P, then\nh K v \u2190 \u03c91 h K v (1) + \u03c92 h K v (2)... + \u03c9I h K v (I),(7)\nwhere is element-wise multiplication. These different combination operators can utilize local node embeddings in diverse ways, and we will empirically study their effects on model performances in experiments.\n\n\nEnhancing Privacy by Adopting DP\n\nData holders directly send the local information, e.g., local node embeddings during forward propagation and gradient update during back propagation, to the server may cause potential information leakage [Lyu et al., 2020], and we propose to apply differential privacy to further enhance privacy. In this section, we introduce two DP based data publishing mechanisms, to further enhance the privacy of our proposed VFGNN. Such that with a single entry modification in the local information of data holders, there is a large probability that the server cannot distinguish the difference before or after the modification. We present the two mechanisms, i.e., Gaussian Mechanism and James-Stein Estimator, in Algorithm 1. We have described Gaussian mechanism in Section 2.3, we present James-Stein Estimator as follows. Theorem 2. (James-Stein Estimator and its adaptivity [Balle and Wang, 2018]). Suppose d is the dimension of local information x. When d \u2265 3, substituting w inx Bayes with its maximum likelihood estimate under x \u223c N (0, w 2 I), x|x \u223c N (x, \u03c3 2 C 2 I), andx Bayes = argminx x \u2212 x 2 produces James-Stein Estimatorx JS = 1 \u2212 (d\u22122)\u03c3 2 C 2\n\nx 2\n\nx. Moreover, it has an Mean Squared Error (MSE) of\nE[ x JS \u2212 x 2 ] = d\u03c3 2 1 \u2212 (d \u2212 2) 2 d 2 \u03c3 2 C 2 w 2 + \u03c3 2 C 2 . (8)\nThe MSE of Gaussian Mechanismx to exact x is E x \u2212 x 2 = d\u03c3 2 C 2 , while the MSE of James-Stein Estimator is reduced with a factor of (1 \u2212 (d\u22122) 2 d 2 \u03c3 2 C 2 w 2 +\u03c3 2 C 2 ). Both methods preserve ( , \u03b4)-DP while James-Stein estimator shows reductions in MSE, thus improves utility. By the definition of Gaussian mechanism (Definition 3), we have the privacy loss for both information publishing mechanisms in Algorithm 1. By combining it with Moment Accountant (MA) [Abadi et al., 2016], we present the overall privacy for T iterations. Theorem 3. Suppose each iteration of Algorithm 1 is ( , \u03b4)\u2212DP. There exist constants c 1 and c 2 so that given the sampling probability q and the number of iterations T , and < c 1 q \u221a T , Algorithm 1 over T iteration is ( , \u03b4)\u2212DP, with = c 2 q \u221a T .\n\nProof. By Definition 3 and Theorem 1, to ensure one iteration ( , \u03b4)\u2212DP, we set \u03c3 = \u221a 2 ln(1.25/\u03b4) . By Theorem 1 in [Abadi et al., 2016], with \u03c3 = \u221a 2 ln(1.25/\u03b4) and the appropriate choice of , q, T , such that < c 1 q \u221a T , the privacy loss\nover T iterations is = c1q \u221a T log(1/\u03b4) \u03c3 = c 2 q \u221a T .\n\nPutting Together\n\nBy combining CG1-CG3 and the key components described above, we complete the forward propagation of VFGNN. To describe the procedures in details, without loss of generality, we take GraphSAGE [Hamilton et al., 2017] for example and present its forward propagation process in Algorithm 2. VFGNN can be learnt by gradient descent through minimizing the cross-entropy error over all labeled training examples. Specifically, the model weights of VFGNN are in four parts. (1) The weights for the initial node embeddings, i.e., W i , \u2200i \u2208 P, that are secretly shared by data holders, (2) the weights for neighborhoold aggregation on graphs, i.e., W k i , that are also kept by data holders, (3) the weights for the hidden layers of deep neural networks, i.e., W l , 0 \u2264 l < L, that are hold by server, (4) and the weights for the output layer of deep neural networks, i.e., W L , that are hold by the data holder who has label. As can be seen, in VFGNN, both private data and model are hold by data holders themselves, thus data privacy can be better guaranteed.\n\n\nExperiments\n\nWe conduct experiments to answer the following questions. Q1: whether VFGNN outperforms the GNN models that are trained on the isolated data. Q2: how does VFGNN behave comparing with the traditional insecure model trained on the plaintext mixed data. Q3: how does VFGNN perform comparing with the naive solution in Section 1. Q4: are our proposed combination strategies effective to VFGNN. Q5: what is the effect of the number of data holders on VFGNN. Q6: what is the effect of differential privacy on VFGNN.\n\n\nExperimental Setup\n\nDatasets. We use four benchmark datasets, i.e., Cora, Pubmed, Citeseer [Sen et al., 2008], and arXiv [Hu et al., Algorithm 2 Privacy-preserving GraphSAGE for node label prediction (forward propagation) Input: Data holder \u2200i \u2208 P; Graph G(V, E i ) and node features {x i v , \u2200v \u2208 V}; depth K; aggregator functions AGG k , \u2200k \u2208 {1, ..., K}; weight matrices W k i , \u2200k \u2208 {1, ..., K}; max layer L; weight matrices W l , \u2200l \u2208 {0, ..., L}; non-linearity \u03c3; neighborhood functions N i : v \u2192 2 V ; node labels on data holder p \u2208 P and c \u2208 C Output: Node label predictions {\u0177 vc , \u2200v \u2208 V, \u2200c \u2208 C} 1: # CG1: private feature and edge related computations 2: Data holders: jointly calculate initial node embeddings h 0 v (i) \u2190 x i v , \u2200i \u2208 P, \u2200v \u2208 V 3: for i \u2208 P in parallel do 4:\n\nfor k = 1 to K do 5:\n\nfor v \u2208 V do 6:\n\nData holder:\ncalculates h k N (v) (i) \u2190 AGG k ({h k\u22121 u (i), \u2200u \u2208 N i (v)}) 7:\nend for 8:\nData holder: calculates h k v (i) \u2190 \u03c3(W k i \u00b7 CONCAT (h k\u22121 v (i), h k N (v) (i)) 9:\nend for 10:\n\nData holder: calculates local node embeddings\nh K v (i) \u2190 h K v (i)/||h K v (i)|| 2 ,\n\u2200v \u2208 V and sends (publishes) it to server using differential privacy 11: end for 12: # CG2: non-private data related computations 13: for v \u2208 V do 14:\n\nServer: combines the local node embeddings from data holders h\nK v = COMBINE ({h K v (i), \u2200i \u2208 P})\n\n15:\n\nServer: forward propagation based on the global node embeddings z L = \u03c3(W L\u22121 \u00b7 \u03c3(...\u03c3(W 0 \u00b7 h K v )))\n\n\n16:\n\nServer: sends z L to data holder p 17: end for 18: # CG3: private label related computations 19: Data holder p: makes prediction by\u0177 vc \u2190 softmax(W L \u00b7 z L ), \u2200v \u2208 V, \u2200c \u2208 C 2020]. We use exactly the same dataset partition of training, validate, and test following the prior work [Kipf and Welling, 2016;Hu et al., 2020]. Besides, in data isolated GNN setting, both node features and edges are hold by different parties. For all the experiments, we use five-fold cross validation and adopt average accuracy as the evaluation metric. Comparison methods. We compare VFGNN with Graph-SAGE models [Hamilton et al., 2017] that are trained using isolated data and mixed plaintext data to answer Q1 and Q2. We also compare VFGNN with the naive solution described in Section 1 to answer Q3. To answer Q4, we vary the proportion of the data (features and edges) hold by A and B, and change VFGNN with different combination strategies. We vary the number of data holders in VFGNN to answer Q5, and vary the parameters of differential privacy to answer Q6. For all these models, we choose Mean operator as the aggregator function. Parameter settings. For all the models, we use TanH as the active function of neighbor propagation, and Sigmoid as the   , 2, 4, 8, 16, 32, 64, \u221e}, set \u03b4 = 1e \u22124 and the clip value C = 1 to study the effects of differential privacy on our model. Since we have many comparison and ablation models, and they achieve the best performance with different parameters, we cannot report all the best parameters. Instead, we report the range of the best parameters. We vary the propagation depth K \u2208 {2, 3, 4, 5}, L2 regularization in {10 \u22122 \u2212 10 \u22124 }, and learning rate in {10 \u22122 \u2212 10 \u22123 }. We tune parameters based on the validate dataset and evaluate model performance on the test dataset.\n\n\nComparison Results and Analysis\n\nTo answer Q1-Q3, we assume there are two data holders (A and B) who have equal number of node features and edges, i.e., the proportion of data held by A and B is 5:5, and compare our models with GraphSAGEs that are trained on isolated data individually and on mixed plaintext data. We also set = \u221e during comparison and will study its effects later. We summarize the results in Table 2, where VFGNN C, VFGNN M, and VFGNN R denote VFGNN with Concat, Mean, and Regression combination strategies. Result1: answer to Q1. We first compare VFGNNs with the GraphSAGEs that are trained on isolated feature and edge data, i.e., GraphSAGE A and GraphSAGE B . From Table 2, we find that, VFGNNs with different combination strategies significantly outperforms GraphSAGE A and GraphSAGE B on all the three datasets. Take Citeseer for example, our VFGNN R improves GraphSAGE A and GraphSAGE B by as high as 28.10% and 51.64%, in terms of accuracy. Analysis of Result1. The reason of result1 is straightforward. GraphSAGE A and GraphSAGE B can only use partial feature and edge information held by A and B. In contrast, VFGNNs provide a solution for A and B to jointly train GNNs without compromising their own data. By doing this, VFGNNs can use the information from the data of both A and B simultaneously, and therefore achieve better performance.\n\nResult2: answer to Q2. We then compare VFGNNs with GraphSAGE that is trained on the mixed plaintext  It is easy to explain why our proposal has comparable performance with the model that are trained on the mixed plaintext data. First, we propose a secret sharing based protocol for A and B to generate the initial node embeddings from their node features, which are the same as those generated by using mixed plaintext features. Second, although A and B generate local node embeddings by using their own edge data to do neighbor aggregation separately (for security concern), we propose different combination strategies to combine their local node embeddings. Eventually, the edge information from both A and B is used for training the classification model. Therefore, VFGNN achieves comparable performance with GraphSAGE A+B . Result3: answer to Q3. In VFGNN, we delegate the nonprivate data related computations to server. \n\n\nAblation Study\n\nWe now study the effects of different combination operators and different number of data holders on VFGNN.\n\nResult4: answer to Q4. Different combination operators can utilize local node embeddings in diverse ways and make our proposed VFGNN adaptable to different scenarios, we study this by varying the proportion (Prop.) of data (node features   Table 3. Analysis of Result4. From Table 3, we find that with the proportion of data hold by A and B being even, i.e., from {9 : 1} to {7 : 3}, the performances of most strategies tend to decrease. This is because the neighbor aggregation is done by data holders individually, and with a bigger proportion of data hold by a single holder, it is easier for this party to generate better local node embeddings. Moreover, we also find that Mean operator works well when data are evenly split, and Regression operator is good at handling the situations where data holders have different quatity of data, since it treats the local node embeddings from each data holder differently, and assigns weights to them intelligently. Result5: answer to Q5. We vary the number of data holders in {2, 3, 4} and study the performance of VFGNN. We report the results in Table 4, where we use the Cora dataset and assume data holders have even feature and edge data. Analysis of Result5. From Table 4, we find that, as the number of data holders increases, the accuracy of all the models decreases. This is because the neighborhood aggregation in VFGNN is done by each holder individually for privacy concern, and each data holder will have less edge data when there are more data holders, since they split the original edge information evenly. Therefore, when more participants are involved, more information will be lost during the neighborhood aggregation procedure. Result6: answer to Q6. We present the privacy loss of each iteration in Table 5 and the over all privacy in Theorem 3. We vary and set \u03b4 = 1e \u22124 to study the effects of DP on VFGNN. We report the results in Table 5, where we use Cora dataset, use MEAN as the combination operator, and assume data holders have even feature and edge data. Analysis of Result6. From Table 5, we can see that the accuracy of VFGNN increases with . In other words, there is a trade-off between accuracy and privacy. The smaller , the more noise will be added into the local node embeddings, which causes stronger privacy guarantee but lower accuracy. We also find James-Stein estimator consistently works better than Gaussian mechanism, since it can reduce MSE, as we have analyzed in Section 3.5.\n\n\nConclusion\n\nWe propose VFGNN, a vertically federated GNN learning paradigm for privacy-preserving node classification task. We finish this by splitting the computation graph of GNN. We leave the private data related computations on data holders and delegate the rest computations to a server. Experiments on real world datasets demonstrate that our model significantly outperforms the GNNs by using the isolated data and has comparable performance with the traditional GNN by using the mixed plaintext data insecurely.\n\n\nA Multiplication of Secret Sharing\n\nExisting research on secret sharing multiplication protocol is mainly based on Beaver's triplet technique [Beaver, 1991]. Specifically, to multiply two secretly shared values a and b between two parties P 0 and P 1 , they first need to collaboratively choose a shared triple u , w , and z , where u, w are uniformly random values in Z 2 and z = uw mod 2 . They then locally compute e i = a i \u2212 u i and f i = b i \u2212 w i , where i \u2208 {0, 1}. Next, they run Rec( e 0 , e 1 ) and Rec( f 0 , f 1 ). Finally, P i gets c i = \u2212i \u00b7 e \u00b7 f + f \u00b7 a i + e \u00b7 b i + z i as a share of the multiplication result, such that a b = c 0 + c 1 . It is easy to vectorize the addition and multiplication protocols under secret sharing setting. The above protocols work in finite field, and we adopt fixed-point representation to approximate decimal arithmetics efficiently [Mohassel and Zhang, 2017].\n\n\nB Related Work in Details\n\nWe review three kinds of existing Privacy-Preserving Neural Network (PPNN) models, including GNN models. PPNN based on cryptographic methods. These methods mainly use cryptographic techniques, e.g., secret sharing and homomorphic encryption, to build approximated neural networks models [Mohassel and Zhang, 2017;Wagh et al., 2019], since the nonlinear active functions are not cryptographically computable. Cryptograph based neural network models are difficult to scale to deep networks and large datasets due to its high communication and computation complexities. In this paper, we use cryptographic techniques for data holders to calculate the initial node embeddings securely.\n\nAlgorithm 3 Data holders P securely generate the initial node embeddings using secret sharing Input: {x i v \u2208 Z 2 , \u2200v \u2208 V, \u2200i \u2208 P}, and x i for short Output: The share of initial node embeddings for each data holder i {h 0 v (i), i \u2208 P, \u2200v \u2208 V} 1: for P i \u2208 P in parallel do P i sends h 0 v i to P j , \u2200j \u2208 P, j = i 15:\n\nP i reconstructs h 0 v , denote as h 0 v (i) 16: end for 17: return h 0 v (i) for each data holder i \u2208 P PPNN based on federated learning. The privacy issues in machine learning has boosted the development of federated learning. To date, federated neural networks have been extensively studied Bonawitz et al., 2019] and applied into real-world scenarios . There are also several work on federated GNN when data are horizontally partitioned [Zheng et al., 2021;. However, a mature solution for federated GNN models under vertically partitioned data is still missing. In this paper, we fill this gap by proposing VFGNN.\n\nPPNN based on split computation graph. These methods split the computation graph of neural networks into two parts, and let data holders calculate the private data related computations individually and get a hidden layer, and then let a server makes the rest computations [Vepakomma et al., 2018;Chi et al., 2018;Osia et al., 2019;Gu et al., 2018;Zheng et al., 2020]. Our model differs from them in mainly two aspects. First, we train a GNN rather than a neural network. Seconds, we use cryptographic techniques for data holders to calculate the initial node embeddings collaboratively rather than compute them based on their plaintext data individually.\n\n\nC Algorithm of Generating Initial Node Embeddings\n\nWe summarize the algorithm of generating initial node embeddings in Algorithm 1. Traditionally, the initial node embeddings can be generated by h 0 = x T \u00b7 W, where x is node features and W is weight matrix. When features are vertically partitioned, we calculate initial node embeddings as follows. First, we secretly share x among data holders (Lines 3-4). Then, data holders concat their received shares in order (Line 5). After it, we calculate x T \u00b7 W following distributive law (Lines 8-11). Take two data holders for example, x T \u00b7 W = ( x 1 + x 2 ) \u00b7 ( W 1 + W 2 ) = x 1 \u00b7 W 1 + x 1 \u00b7 W 2 + x 2 \u00b7 W 1 + x 2 \u00b7 W 2 . Finally, data holders reconstruct x T \u00b7 W by summing over all the shares (Lines 12-16).\n\nFigure 1 :\n1Problem description of vertically federated GNN.\n\nFigure 2 :\n2Overview of our proposed VFGNN.\n\n\nW i as i-share 7: end for 8: for P j \u2208 P and j = i do 9: P i and P j calculate i-share x end for 12: for P i \u2208 P in parallel do 13: P i locally calculates the summation of all i-shares, denoted as h 0 v i = x T \u00b7 w i 14:\n\nTable 2 :\n2Comparison results on three datasets (Q1 and Q2).active function of hidden layers. For the deep neural network \non server, we set the dropout rate to 0.5 and network struc-\nture as (d, d, |C|), where d \u2208 {32, 64, 128} is the dimen-\nsion of node embeddings and |C| the nubmer of classes. We \nvary \u2208 {1\n\nTable 3 :\n3Comparison of combination operators on Cora by varying the proportion of data hold by A and B (Q4).No. of DH VFGNN C VFGNN M VFGNN R \n\n2 \n0.790 \n0.809 \n0.802 \n3 \n0.749 \n0.774 \n0.760 \n4 \n0.712 \n0.733 \n0.722 \n\nTable 4: Comparison results on Cora by varying the number of data \nholders (Q5). \n\ndata, i.e., GraphSAGE A+B . It can be seen from Ta-\nble 2 that VFGNNs have comparable performance with \nGraphSAGE A+B , e.g., 0.8090 vs. 0.8150 on Cora dataset \nand 0.6950 vs. 0.7001 on Citeseer dataset. \nAnalysis of Result2. \n\nTable 5 :\n5Effect of DP on VFGNN using Cora dataset (Q6). and edges) hold by A and B in {9 : 1, 8 : 2, 7 : 3}. The results on Cora dataset are shown in\nAcknowledgementsThis work was supported in part by the National Natural Science Foundation of China (No. 62172362) and \"Leading Goose\" R&D Program of Zhejiang (No. 2022C01126).\nImproving the gaussian mechanism for differential privacy: Analytical calibration and optimal denoising. [ References, Abadi, arXiv:1805.06530arXiv:1902.01046Annual International Cryptology Conference. Springer51arXiv preprintCCS. et al. Towards federated learning at scale: System designReferences [Abadi et al., 2016] Martin Abadi, Andy Chu, Ian Goodfel- low, H Brendan McMahan, Ilya Mironov, Kunal Talwar, and Li Zhang. Deep learning with differential privacy. In CCS, pages 308-318. ACM, 2016. [Acar et al., 2018] Abbas Acar, Hidayet Aksu, A Selcuk Uluagac, and Mauro Conti. A survey on homomorphic encryption schemes: Theory and implementation. ACM Computing Surveys (CSUR), 51(4):79, 2018. [Balle and Wang, 2018] Borja Balle and Yu-Xiang Wang. Improving the gaussian mechanism for differential pri- vacy: Analytical calibration and optimal denoising. arXiv preprint arXiv:1805.06530, 2018. [Beaver, 1991] Donald Beaver. Efficient multiparty proto- cols using circuit randomization. In Annual International Cryptology Conference, pages 420-432. Springer, 1991. [Bonawitz et al., 2019] Keith Bonawitz, Hubert Eichner, Wolfgang Grieskamp, Dzmitry Huba, Alex Ingerman, Vladimir Ivanov, Chloe Kiddon, Jakub Kone\u010dn\u1ef3, Stefano Mazzocchi, H Brendan McMahan, et al. Towards fed- erated learning at scale: System design. arXiv preprint arXiv:1902.01046, 2019.\n\nWhen homomorphic encryption marries secret sharing: Secure large-scale sparse logistic regression and applications in risk control. SIGKDD. ACMet al., 2021] Chaochao Chen, Jun Zhou, Li Wang, Xibin Wu, Wenjing Fang, Jin Tan, Lei Wang, Alex X. Liu, Hao Wang, and Cheng Hong. When homomorphic en- cryption marries secret sharing: Secure large-scale sparse logistic regression and applications in risk control. In SIGKDD, pages 2652-2662. ACM, 2021.\n\nPrivate federated learning on vertically partitioned data via entity resolution and additively homomorphic encryption. Chi , arXiv:1812.02863arXiv:2005.02131Privacy partitioning: Protecting user data during the deep learning inference phase. Hamilton, Zhitao Ying, and Jure LeskovecMichael Backes9arXiv preprintNeil Zhenqiang Gong, and Yang Zhang. Stealing links from graph neural networksChi et al., 2018] Jianfeng Chi, Emmanuel Owusu, Xuwang Yin, Tong Yu, William Chan, Patrick Tague, and Yuan Tian. Privacy partitioning: Protecting user data dur- ing the deep learning inference phase. arXiv preprint arXiv:1812.02863, 2018. [Costan and Devadas, 2016] Victor Costan and Srinivas De- vadas. Intel sgx explained. IACR Cryptology ePrint Archive, 2016(086):1-118, 2016. [Dwork et al., 2014] Cynthia Dwork, Aaron Roth, et al. The algorithmic foundations of differential privacy. Founda- tions and Trends in Theoretical Computer Science, 9(3- 4):211-407, 2014. [Fang et al., 2021] Wenjing Fang, Derun Zhao, Jin Tan, Chaochao Chen, Chaofan Yu, Li Wang, Lei Wang, Jun Zhou, and Benyu Zhang. Large-scale secure XGB for ver- tical federated learning. In CIKM, pages 443-452. ACM, 2021. [Gu et al., 2018] Zhongshu Gu, Heqing Huang, Jialong Zhang, Dong Su, Ankita Lamba, Dimitrios Pendarakis, and Ian Molloy. Securing input data of deep learning in- ference systems via partitioned enclave execution. arXiv preprint arXiv:1807.00969, 2018. [Hamilton et al., 2017] Will Hamilton, Zhitao Ying, and Jure Leskovec. Inductive representation learning on large graphs. In NeurIPS, pages 1024-1034, 2017. [Hardy et al., 2017] Stephen Hardy, Wilko Henecka, Hamish Ivey-Law, Richard Nock, Giorgio Patrini, Guil- laume Smith, and Brian Thorne. Private federated learning on vertically partitioned data via entity resolution and additively homomorphic encryption. arXiv preprint arXiv:1711.10677, 2017. [He et al., 2020] Xinlei He, Jinyuan Jia, Michael Backes, Neil Zhenqiang Gong, and Yang Zhang. Stealing links from graph neural networks. arXiv preprint arXiv:2005.02131, 2020.\n\nOpen graph benchmark: Datasets for machine learning on graphs. [ Hu, arXiv:2005.00687arXiv preprint[Hu et al., 2020] Weihua Hu, Matthias Fey, Marinka Zit- nik, Yuxiao Dong, Hongyu Ren, Bowen Liu, Michele Catasta, and Jure Leskovec. Open graph benchmark: Datasets for machine learning on graphs. arXiv preprint arXiv:2005.00687, 2020.\n\nSemi-supervised classification with graph convolutional networks. Welling ; Kipf, N Thomas, Max Kipf, ; Welling, Kone\u010dn\u1ef3, arXiv:1609.02907arXiv:1610.05492Ananda Theertha Suresh, and Dave Bacon. Federated learning: Strategies for improving communication efficiency. arXiv preprint[Kipf and Welling, 2016] Thomas N Kipf and Max Welling. Semi-supervised classification with graph convolutional networks. arXiv preprint arXiv:1609.02907, 2016. [Kone\u010dn\u1ef3 et al., 2016] Jakub Kone\u010dn\u1ef3, H Brendan McMa- han, Felix X Yu, Peter Richt\u00e1rik, Ananda Theertha Suresh, and Dave Bacon. Federated learning: Strategies for improving communication efficiency. arXiv preprint arXiv:1610.05492, 2016.\n\nSecureml: A system for scalable privacypreserving machine learning. [ Li, arXiv:1703.02952hybrid deep learning architecture for privacy-preserving mobile analytics. Seyed Ali Osia, Ali Shahin Shamsabadi, Ali Taheri, Kleomenis Katevas, Sina Sajadmanesh, Hamid R Rabiee, Nicholas D Lane, and Hamed Haddadi. ASpringerarXiv preprintFederated Learning. Sajadmanesh and Gatica-Perez, 2020. Locally private graph neural networks. CoRR abs/2006.05535, 12[Li et al., 2020] Li Li, Yuxi Fan, Mike Tse, and Kuo-Yi Lin. A review of applications in federated learning. Computers & Industrial Engineering, page 106854, 2020. [Lyu et al., 2020] Lingjuan Lyu, Han Yu, Jun Zhao, and Qiang Yang. Threats to federated learning. In Federated Learning, pages 3-16. Springer, 2020. [Mohassel and Zhang, 2017] Payman Mohassel and Yupeng Zhang. Secureml: A system for scalable privacy- preserving machine learning. In S&P, pages 19-38, 2017. [Osia et al., 2019] Seyed Ali Osia, Ali Shahin Shamsabadi, Ali Taheri, Kleomenis Katevas, Sina Sajadmanesh, Hamid R Rabiee, Nicholas D Lane, and Hamed Haddadi. A hybrid deep learning architecture for privacy-preserving mobile analytics. arXiv preprint arXiv:1703.02952, 2019. [Sajadmanesh and Gatica-Perez, 2020] Sina Sajadmanesh and Daniel Gatica-Perez. Locally private graph neural networks. CoRR abs/2006.05535, 12, 2020.\n\nCollective classification in network data. [ Sen, AI magazine. 293[Sen et al., 2008] Prithviraj Sen, Galileo Namata, Mustafa Bilgic, Lise Getoor, Brian Galligher, and Tina Eliassi-Rad. Collective classification in network data. AI magazine, 29(3):93-93, 2008.\n\nPetar Veli\u010dkovi\u0107, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. Adi Shamir, Shamir, arXiv:1710.10903Graph attention networks. 22arXiv preprintHow to share a secretShamir, 1979] Adi Shamir. How to share a secret. Commu- nications of the ACM, 22(11):612-613, 1979. [Veli\u010dkovi\u0107 et al., 2017] Petar Veli\u010dkovi\u0107, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. Graph attention networks. arXiv preprint arXiv:1710.10903, 2017.\n\nSplit learning for health: Distributed deep learning without sharing raw patient data. [ Vepakomma, arXiv:1812.00564Sameer Wagh, Divya Gupta, and Nishanth Chandran. Securenn: 3-party secure computation for neural network training. PETs. 124arXiv preprintWagh et al., 2019[Vepakomma et al., 2018] Praneeth Vepakomma, Otkrist Gupta, Tristan Swedish, and Ramesh Raskar. Split learn- ing for health: Distributed deep learning without sharing raw patient data. arXiv preprint arXiv:1812.00564, 2018. [Wagh et al., 2019] Sameer Wagh, Divya Gupta, and Nis- hanth Chandran. Securenn: 3-party secure computation for neural network training. PETs, 1:24, 2019.\n\n[ Wu, arXiv:1901.00596A comprehensive survey on graph neural networks. arXiv preprint[Wu et al., 2019] Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and Philip S Yu. A comprehensive survey on graph neural networks. arXiv preprint arXiv:1901.00596, 2019.\n\nFedgnn: Federated graph neural network for privacy-preserving recommendation. [ Wu, arXiv:2102.04925arXiv preprint[Wu et al., 2021] Chuhan Wu, Fangzhao Wu, Yang Cao, Yongfeng Huang, and Xing Xie. Fedgnn: Federated graph neural network for privacy-preserving recommendation. arXiv preprint arXiv:2102.04925, 2021.\n\nAsfgnn: Automated separated-federated graph neural network. [ Zheng, arXiv:2003.05198Zhou, Chaochao Chen, Bingzhe Wu, Li Wang, and Benyu ZhangPPNAarXiv preprintIndustrial scale privacy preserving deep neural network[Zheng et al., 2020] Longfei Zheng, Chaochao Chen, Yingt- ing Liu, Bingzhe Wu, Xibin Wu, Li Wang, Lei Wang, Jun Zhou, and Shuang Yang. Industrial scale pri- vacy preserving deep neural network. arXiv preprint arXiv:2003.05198, 2020. [Zheng et al., 2021] Longfei Zheng, Jun Zhou, Chaochao Chen, Bingzhe Wu, Li Wang, and Benyu Zhang. As- fgnn: Automated separated-federated graph neural net- work. PPNA, pages 1-13, 2021.\n", "annotations": {"author": "[{\"end\":124,\"start\":88},{\"end\":202,\"start\":125},{\"end\":238,\"start\":203},{\"end\":294,\"start\":239},{\"end\":329,\"start\":295},{\"end\":377,\"start\":330},{\"end\":430,\"start\":378},{\"end\":482,\"start\":431},{\"end\":512,\"start\":483},{\"end\":589,\"start\":513}]", "publisher": null, "author_last_name": "[{\"end\":101,\"start\":97},{\"end\":133,\"start\":129},{\"end\":216,\"start\":211},{\"end\":248,\"start\":246},{\"end\":307,\"start\":304},{\"end\":336,\"start\":334},{\"end\":388,\"start\":386},{\"end\":439,\"start\":436},{\"end\":490,\"start\":486},{\"end\":526,\"start\":521}]", "author_first_name": "[{\"end\":96,\"start\":88},{\"end\":128,\"start\":125},{\"end\":210,\"start\":203},{\"end\":245,\"start\":239},{\"end\":303,\"start\":295},{\"end\":333,\"start\":330},{\"end\":385,\"start\":378},{\"end\":435,\"start\":431},{\"end\":485,\"start\":483},{\"end\":520,\"start\":513}]", "author_affiliation": "[{\"end\":123,\"start\":103},{\"end\":180,\"start\":160},{\"end\":201,\"start\":182},{\"end\":237,\"start\":218},{\"end\":293,\"start\":274},{\"end\":376,\"start\":355},{\"end\":429,\"start\":411},{\"end\":481,\"start\":462},{\"end\":511,\"start\":492},{\"end\":567,\"start\":547},{\"end\":588,\"start\":569}]", "title": "[{\"end\":85,\"start\":1},{\"end\":674,\"start\":590}]", "venue": null, "abstract": "[{\"end\":1724,\"start\":676}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b9\"},\"end\":1993,\"start\":1977},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3223,\"start\":3204},{\"end\":3263,\"start\":3244},{\"end\":3391,\"start\":3327},{\"end\":3424,\"start\":3393},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":3503,\"start\":3483},{\"end\":4138,\"start\":4112},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":4319,\"start\":4300},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":4560,\"start\":4536},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":4578,\"start\":4560},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":4594,\"start\":4578},{\"end\":5170,\"start\":5145},{\"end\":6189,\"start\":6163},{\"end\":7268,\"start\":7242},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":7287,\"start\":7268},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":7379,\"start\":7365},{\"end\":7939,\"start\":7925},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":8021,\"start\":8001},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":8355,\"start\":8335},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":8574,\"start\":8554},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":8794,\"start\":8774},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":9055,\"start\":9035},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":11052,\"start\":11032},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":11757,\"start\":11733},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":13441,\"start\":13422},{\"end\":14176,\"start\":14153},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":16802,\"start\":16784},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":17472,\"start\":17450},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":18345,\"start\":18325},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":18785,\"start\":18765},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":20659,\"start\":20641},{\"end\":20682,\"start\":20671},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":22323,\"start\":22299},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":22339,\"start\":22323},{\"end\":22635,\"start\":22612},{\"end\":23281,\"start\":23260},{\"end\":29394,\"start\":29380},{\"end\":30147,\"start\":30121},{\"end\":30491,\"start\":30465},{\"end\":30509,\"start\":30491},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":31499,\"start\":31477},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":31644,\"start\":31624},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":32099,\"start\":32075},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":32116,\"start\":32099},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":32134,\"start\":32116},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":32150,\"start\":32134},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":32169,\"start\":32150}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":33282,\"start\":33221},{\"attributes\":{\"id\":\"fig_1\"},\"end\":33327,\"start\":33283},{\"attributes\":{\"id\":\"fig_2\"},\"end\":33550,\"start\":33328},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":33863,\"start\":33551},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":34393,\"start\":33864},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":34546,\"start\":34394}]", "paragraph": "[{\"end\":4833,\"start\":1740},{\"end\":6464,\"start\":4835},{\"end\":6841,\"start\":6466},{\"end\":7288,\"start\":6876},{\"end\":7940,\"start\":7316},{\"end\":8232,\"start\":7965},{\"end\":8330,\"start\":8275},{\"end\":8691,\"start\":8332},{\"end\":8880,\"start\":8736},{\"end\":9022,\"start\":8929},{\"end\":9149,\"start\":9024},{\"end\":9992,\"start\":9172},{\"end\":11858,\"start\":9994},{\"end\":12155,\"start\":11860},{\"end\":12478,\"start\":12192},{\"end\":12650,\"start\":12480},{\"end\":13061,\"start\":12676},{\"end\":13519,\"start\":13063},{\"end\":14323,\"start\":13554},{\"end\":14690,\"start\":14417},{\"end\":14954,\"start\":14726},{\"end\":15100,\"start\":14956},{\"end\":15662,\"start\":15158},{\"end\":15882,\"start\":15713},{\"end\":16276,\"start\":15941},{\"end\":16543,\"start\":16335},{\"end\":17730,\"start\":16580},{\"end\":17735,\"start\":17732},{\"end\":17787,\"start\":17737},{\"end\":18646,\"start\":17857},{\"end\":18890,\"start\":18648},{\"end\":20022,\"start\":18966},{\"end\":20547,\"start\":20038},{\"end\":21337,\"start\":20570},{\"end\":21359,\"start\":21339},{\"end\":21376,\"start\":21361},{\"end\":21390,\"start\":21378},{\"end\":21467,\"start\":21457},{\"end\":21564,\"start\":21553},{\"end\":21611,\"start\":21566},{\"end\":21802,\"start\":21652},{\"end\":21866,\"start\":21804},{\"end\":22011,\"start\":21909},{\"end\":23822,\"start\":22019},{\"end\":25193,\"start\":23858},{\"end\":26120,\"start\":25195},{\"end\":26245,\"start\":26139},{\"end\":28714,\"start\":26247},{\"end\":29235,\"start\":28729},{\"end\":30148,\"start\":29274},{\"end\":30859,\"start\":30178},{\"end\":31181,\"start\":30861},{\"end\":31801,\"start\":31183},{\"end\":32457,\"start\":31803},{\"end\":33220,\"start\":32511}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":8274,\"start\":8233},{\"attributes\":{\"id\":\"formula_1\"},\"end\":8735,\"start\":8692},{\"attributes\":{\"id\":\"formula_2\"},\"end\":8928,\"start\":8881},{\"attributes\":{\"id\":\"formula_3\"},\"end\":12675,\"start\":12651},{\"attributes\":{\"id\":\"formula_4\"},\"end\":14416,\"start\":14324},{\"attributes\":{\"id\":\"formula_5\"},\"end\":15157,\"start\":15101},{\"attributes\":{\"id\":\"formula_6\"},\"end\":15712,\"start\":15663},{\"attributes\":{\"id\":\"formula_7\"},\"end\":15940,\"start\":15883},{\"attributes\":{\"id\":\"formula_8\"},\"end\":16334,\"start\":16277},{\"attributes\":{\"id\":\"formula_9\"},\"end\":17856,\"start\":17788},{\"attributes\":{\"id\":\"formula_10\"},\"end\":18946,\"start\":18891},{\"attributes\":{\"id\":\"formula_11\"},\"end\":21456,\"start\":21391},{\"attributes\":{\"id\":\"formula_12\"},\"end\":21552,\"start\":21468},{\"attributes\":{\"id\":\"formula_13\"},\"end\":21651,\"start\":21612},{\"attributes\":{\"id\":\"formula_14\"},\"end\":21902,\"start\":21867}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":24243,\"start\":24236},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":24519,\"start\":24512},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":26494,\"start\":26487},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":26529,\"start\":26522},{\"end\":27346,\"start\":27339},{\"end\":27468,\"start\":27461},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":28017,\"start\":28010},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":28152,\"start\":28145},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":28309,\"start\":28302}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1738,\"start\":1726},{\"attributes\":{\"n\":\"2\"},\"end\":6857,\"start\":6844},{\"attributes\":{\"n\":\"2.1\"},\"end\":6874,\"start\":6860},{\"attributes\":{\"n\":\"2.2\"},\"end\":7314,\"start\":7291},{\"attributes\":{\"n\":\"2.3\"},\"end\":7963,\"start\":7943},{\"attributes\":{\"n\":\"3\"},\"end\":9170,\"start\":9152},{\"attributes\":{\"n\":\"3.2\"},\"end\":12190,\"start\":12158},{\"attributes\":{\"n\":\"3.3\"},\"end\":13552,\"start\":13522},{\"attributes\":{\"n\":\"3.4\"},\"end\":14724,\"start\":14693},{\"attributes\":{\"n\":\"3.5\"},\"end\":16578,\"start\":16546},{\"attributes\":{\"n\":\"3.6\"},\"end\":18964,\"start\":18948},{\"attributes\":{\"n\":\"4\"},\"end\":20036,\"start\":20025},{\"attributes\":{\"n\":\"4.1\"},\"end\":20568,\"start\":20550},{\"end\":21907,\"start\":21904},{\"end\":22017,\"start\":22014},{\"attributes\":{\"n\":\"4.2\"},\"end\":23856,\"start\":23825},{\"attributes\":{\"n\":\"4.3\"},\"end\":26137,\"start\":26123},{\"attributes\":{\"n\":\"5\"},\"end\":28727,\"start\":28717},{\"end\":29272,\"start\":29238},{\"end\":30176,\"start\":30151},{\"end\":32509,\"start\":32460},{\"end\":33232,\"start\":33222},{\"end\":33294,\"start\":33284},{\"end\":33561,\"start\":33552},{\"end\":33874,\"start\":33865},{\"end\":34404,\"start\":34395}]", "table": "[{\"end\":33863,\"start\":33612},{\"end\":34393,\"start\":33975}]", "figure_caption": "[{\"end\":33282,\"start\":33234},{\"end\":33327,\"start\":33296},{\"end\":33550,\"start\":33330},{\"end\":33612,\"start\":33563},{\"end\":33975,\"start\":33876},{\"end\":34546,\"start\":34406}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":2451,\"start\":2443},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":9808,\"start\":9800},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":10092,\"start\":10084},{\"end\":12107,\"start\":12099},{\"end\":12477,\"start\":12469},{\"end\":12774,\"start\":12766}]", "bib_author_first_name": "[{\"end\":34830,\"start\":34829},{\"end\":36649,\"start\":36646},{\"end\":38651,\"start\":38650},{\"end\":38997,\"start\":38988},{\"end\":39005,\"start\":39004},{\"end\":39017,\"start\":39014},{\"end\":39025,\"start\":39024},{\"end\":39670,\"start\":39669},{\"end\":40988,\"start\":40987},{\"end\":41309,\"start\":41306},{\"end\":41786,\"start\":41785},{\"end\":42350,\"start\":42349},{\"end\":42704,\"start\":42703},{\"end\":43000,\"start\":42999}]", "bib_author_last_name": "[{\"end\":34841,\"start\":34831},{\"end\":34848,\"start\":34843},{\"end\":38654,\"start\":38652},{\"end\":39002,\"start\":38998},{\"end\":39012,\"start\":39006},{\"end\":39022,\"start\":39018},{\"end\":39033,\"start\":39026},{\"end\":39042,\"start\":39035},{\"end\":39673,\"start\":39671},{\"end\":40992,\"start\":40989},{\"end\":41316,\"start\":41310},{\"end\":41324,\"start\":41318},{\"end\":41796,\"start\":41787},{\"end\":42353,\"start\":42351},{\"end\":42707,\"start\":42705},{\"end\":43006,\"start\":43001}]", "bib_entry": "[{\"attributes\":{\"doi\":\"arXiv:1805.06530\",\"id\":\"b0\",\"matched_paper_id\":21713075},\"end\":36078,\"start\":34724},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":221186951},\"end\":36525,\"start\":36080},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":26233593},\"end\":38585,\"start\":36527},{\"attributes\":{\"id\":\"b3\"},\"end\":38920,\"start\":38587},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":3144218},\"end\":39599,\"start\":38922},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":11605311},\"end\":40942,\"start\":39601},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":62016134},\"end\":41203,\"start\":40944},{\"attributes\":{\"id\":\"b7\"},\"end\":41696,\"start\":41205},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":54439509},\"end\":42347,\"start\":41698},{\"attributes\":{\"id\":\"b9\"},\"end\":42623,\"start\":42349},{\"attributes\":{\"id\":\"b10\"},\"end\":42937,\"start\":42625},{\"attributes\":{\"id\":\"b11\"},\"end\":43573,\"start\":42939}]", "bib_title": "[{\"end\":34827,\"start\":34724},{\"end\":36210,\"start\":36080},{\"end\":36644,\"start\":36527},{\"end\":38986,\"start\":38922},{\"end\":39667,\"start\":39601},{\"end\":40985,\"start\":40944},{\"end\":41304,\"start\":41205},{\"end\":41783,\"start\":41698}]", "bib_author": "[{\"end\":34843,\"start\":34829},{\"end\":34850,\"start\":34843},{\"end\":36652,\"start\":36646},{\"end\":38656,\"start\":38650},{\"end\":39004,\"start\":38988},{\"end\":39014,\"start\":39004},{\"end\":39024,\"start\":39014},{\"end\":39035,\"start\":39024},{\"end\":39044,\"start\":39035},{\"end\":39675,\"start\":39669},{\"end\":40994,\"start\":40987},{\"end\":41318,\"start\":41306},{\"end\":41326,\"start\":41318},{\"end\":41798,\"start\":41785},{\"end\":42355,\"start\":42349},{\"end\":42709,\"start\":42703},{\"end\":43008,\"start\":42999}]", "bib_venue": "[{\"end\":34924,\"start\":34882},{\"end\":36218,\"start\":36212},{\"end\":36767,\"start\":36684},{\"end\":38648,\"start\":38587},{\"end\":39185,\"start\":39076},{\"end\":39764,\"start\":39691},{\"end\":41005,\"start\":40994},{\"end\":41366,\"start\":41342},{\"end\":41933,\"start\":41814},{\"end\":42418,\"start\":42371},{\"end\":42701,\"start\":42625},{\"end\":42997,\"start\":42939}]"}}}, "year": 2023, "month": 12, "day": 17}