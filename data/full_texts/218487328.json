{"id": 218487328, "updated": "2023-10-06 16:01:45.731", "metadata": {"title": "Open Graph Benchmark: Datasets for Machine Learning on Graphs", "authors": "[{\"first\":\"Weihua\",\"last\":\"Hu\",\"middle\":[]},{\"first\":\"Matthias\",\"last\":\"Fey\",\"middle\":[]},{\"first\":\"Marinka\",\"last\":\"Zitnik\",\"middle\":[]},{\"first\":\"Yuxiao\",\"last\":\"Dong\",\"middle\":[]},{\"first\":\"Hongyu\",\"last\":\"Ren\",\"middle\":[]},{\"first\":\"Bowen\",\"last\":\"Liu\",\"middle\":[]},{\"first\":\"Michele\",\"last\":\"Catasta\",\"middle\":[]},{\"first\":\"Jure\",\"last\":\"Leskovec\",\"middle\":[]}]", "venue": "ArXiv", "journal": "ArXiv", "publication_date": {"year": 2020, "month": 5, "day": 2}, "abstract": "We present the Open Graph Benchmark (OGB), a diverse set of challenging and realistic benchmark datasets to facilitate scalable, robust, and reproducible graph machine learning (ML) research. OGB datasets are large-scale, encompass multiple important graph ML tasks and cover a diverse range of domains, ranging from social and information networks to biological networks, molecular graphs, and knowledge graphs. For each dataset, we provide a unified evaluation protocol using application-specific data splits and evaluation metrics. Our empirical investigation reveals the challenges of existing graph methods in handling large-scale graphs and predicting out-of-distribution data. OGB presents an automated end-to-end graph ML pipeline that simplifies and standardizes the process of graph data loading, experimental setup, and model evaluation. OGB will be regularly updated and welcomes inputs from the community. OGB datasets as well as data loaders and evaluation scripts are available at https://ogb.stanford.edu .", "fields_of_study": "[\"Computer Science\",\"Mathematics\"]", "external_ids": {"arxiv": "2005.00687", "mag": "3100078588", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/nips/HuFZDRLCL20", "doi": null}}, "content": {"source": {"pdf_hash": "597bd2e45427563cdf025e53a3239006aa364cfc", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2005.00687v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "fa8b160d5ca94f3e53707cabc4c60edc765fd332", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/597bd2e45427563cdf025e53a3239006aa364cfc.txt", "contents": "\nOpen Graph Benchmark: Datasets for Machine Learning on Graphs Steering Committee\n\n\nWeihua Hu \nDepartment of Computer Science\nStanford University\n5 Chemistry\n\nMatthias Fey \nDepartment of Computer Graphics\nTU Dortmund University\n\n\nMarinka Zitnik \nDepartment of Biomedical Informatics\nHarvard University\n\n\nYuxiao Dong \nMicrosoft Research\nRedmond\n\nHongyu Ren \nDepartment of Computer Science\nStanford University\n5 Chemistry\n\nBowen Liu \nMichele Catasta \nDepartment of Computer Science\nStanford University\n5 Chemistry\n\nJure Leskovec \nDepartment of Computer Science\nStanford University\n5 Chemistry\n\nRegina Barzilay \nPeter Battaglia \nYoshua Bengio \nMichael Bronstein \nStephan G\u00fcnnemann \nWill Hamilton \nTommi Jaakkola \nStefanie Jegelka \nMaximilian Nickel \nChris Re \nLe Song \nJian Tang \nMax Welling \nRich Zemel \nOpen Graph Benchmark: Datasets for Machine Learning on Graphs Steering Committee\n\nWe present the OPEN GRAPH BENCHMARK (OGB), a diverse set of challenging and realistic benchmark datasets to facilitate scalable, robust, and reproducible graph machine learning (ML) research. OGB datasets are large-scale, encompass multiple important graph ML tasks and cover a diverse range of domains, ranging from social and information networks to biological networks, molecular graphs, and knowledge graphs. For each dataset, we provide a unified evaluation protocol using application-specific data splits and evaluation metrics. Our empirical investigation reveals the challenges of existing graph methods in handling large-scale graphs and predicting out-of-distribution data. OGB presents an automated end-to-end graph ML pipeline that simplifies and standardizes the process of graph data loading, experimental setup, and model evaluation. OGB will be regularly updated and welcomes inputs from the community. OGB datasets as well as data loaders and evaluation scripts are available at https://ogb.stanford.edu.\n\nIntroduction\n\nGraphs are widely used for abstracting complex systems of interacting objects, such as social networks (Easley et al., 2010), knowledge graphs (Nickel et al., 2015), molecular graphs (Wu et al., 2018), and biological networks (Barabasi & Oltvai, 2004), as well as for modeling 3D objects (Simonovsky & Komodakis, 2017), manifolds (Bronstein et al., 2017), and source code (Allamanis et al., 2017). Machine learning (ML), especially deep learning, on graphs is an emerging field (Hamilton et al., 2017b;Bronstein et al., 2017). Recently, significant methodological advances Ying et al., 2018;Veli\u010dkovi\u0107 et al., 2019; have been made in graph ML, which have produced promising results in applications from diverse domains.\n\nHow can we further advance research in graph ML? Historically, high-quality and large-scale datasets have played significant roles in advancing research, as exemplified by IMAGENET (Deng et al., 2009) and MS COCO (Lin et al., 2014) in computer vision, GLUE BENCHMARK (Wang et al., 2018) and SQUAD (Rajpurkar et al., 2016) in natural language processing, and LIBRISPEECH (Panayotov et al., 2015) and CHIME (Barker et al., 2015) in speech processing. However, in graph ML research, commonly-used datasets and evaluation procedures present issues that may negatively impact future progress.\n\nIssues with current benchmarks. Most of the frequently-used graph datasets, such as Cora, CiteSeer (Yang et al., 2016), and the TU datasets (Yanardag & Vishwanathan, 2015;Kersting et al., 2016), are far too small to fully leverage the power of data-hungry ML models, such as graph neural networks (GNNs). Additionally, data duplication and leakage issues have been identified in some widely-used graph datasets (Zou et al., 2020). These hinder the reliable evaluation and rigorous comparison for furthering graph ML. Furthermore, there is no unified and commonly-followed experimental protocol (Errica et al., 2019;Dwivedi et al., 2020). Different studies adopt their own dataset splits, evaluation metrics, and cross-validation protocol, making it challenging to compare performance reported across various studies (Shchur et al., 2018). In addition, many studies follow the convention of using random splits to generate training/test sets Bordes et al., 2013), which is not realistic or useful for real-world applications of graphs and generally leads to overly optimistic performance results (Lohr, 2009).\n\n\nS C A L E\n\nThus, there is a need for a comprehensive suite of realworld benchmarks that combine a diverse set of datasets of various sizes coming from different domains. Data splits as well as evaluation metrics are important so that progress can be measured in a consistent and reproducible way. Last but not least, benchmarks also need to provide different types of tasks, such as node classification, link prediction, and graph classification.  Figure 2: Overview of OGB: (a) OGB provides realistic graph benchmark datasets that cover different prediction tasks (node, link, graph), are from diverse application domains, and are at different scales. (b) OGB fully automates dataset processing and splitting. That is, the OGB data loaders automatically download and process graphs, provide graph objects (compatible with PYTORCH 1 (Paszke et al., 2019) and its associated graph libraries, PYTORCH GEOMETRIC 2 (Fey & Lenssen, 2019) and DEEP GRAPH LIBRARY 3 (Wang et al., 2019a)), and further split the datasets in a standardized manner. (c) After an ML model is developed, (d) OGB evaluates the model in a dataset-dependent manner, and outputs the model performance appropriate for the task at hand. Finally, (e) OGB provides leaderboards to help to keep track of recent advances. advancements in graph ML. As illustrated in Figure 1, the OGB datasets are designed to have the following three characteristics.\n\n1. Large scale. OGB datasets are orders-of-magnitude larger than existing benchmarks and can be categorized into three different scales (small, medium, and large). Even the \"small\" OGB graphs have more than 100,000 nodes, but are small enough to fit into the memory of a single GPU, making them suitable for testing computationally intensive algorithms. Additionally, OGB introduces \"medium\" (1-10 million nodes) and \"large\" (beyond 10 million nodes) datasets, which can facilitate the development of methods for addressing problems of sampling and partitioning, distributed training, and scalability.\n\n2. Diverse domains. The OGB datasets aim to include graphs that are representative of a wide range of domains, as shown in Table 1. The broad coverage of domains in OGB empowers the development and demonstration of general-purpose models and can be used to distinguish them from domain-specific techniques. Furthermore, for each dataset, OGB adopts domain-specific data splits (e.g., based on time, species, molecular structure, etc.) that are more realistic and meaningful than conventional random split. Such data splits are often much more challenging than the random split, and present a research opportunity to improve out-of-distribution generalization of graph ML models.\n\n3. Multiple task categories. In addition to data diversity, OGB supports three categories of fundamental graph ML tasks, i.e., node, link, and graph property predictions, each of which requires the models to make predictions at different levels of graphs, i.e.at the level of a node, link, and entire graph, respectively. Currently, OGB includes at least 3 graph datasets for each task category.\n\nThe currently-available OGB datasets are listed in Table 1 We will update the table as new datasets are released.\n\nIn addition to building graph datasets, OGB also presents an automated end-to-end graph ML pipeline that simplifies and standardizes the process of graph data loading, experimental setup, and model evaluation, as illustrated in Figure 2. Given the OGB datasets (a), the end-users can focus on developing their graph ML models (c) by using the OGB data loaders (b) and evaluators (d), both of which are provided by our OGB Python package 4 . OGB also hosts a public leaderboard 5 (e) for publicizing state-of-the-art, reproducible graph ML research. As a starting point, for each dataset, we include results from a suite of well-known baselines, particularly GNN-based methods, together with code to reproduce our results.\n\nOGB is an on-going open-source and community-driven initiative. Over time we plan to release new versions of the datasets and methods, and provide updates to the leaderboard. Our immediate future plan is to add more graph datasets to increase the coverage in Table 1. The OGB website (https: Small molhiv Medium molpcba, ppa Large //ogb.stanford.edu) provides the documentation, example scripts, and public leaderboard. We also welcome inputs from the community at ogb@cs.stanford.edu.\n\n\nShortcomings of Current Benchmarks\n\nWe first review commonly-used graph benchmarks and discuss the current state of the field. We organize the discussion around three categories of graph ML tasks: predictions at the level of nodes, links, and graphs.\n\nNode property prediction. Currently, the three graphs (Cora, CiteSeer and PubMed) proposed in Yang et al. (2016) have been widely used as semi-supervised node classification datasets, particularly for evaluating GNNs. The sizes of these graphs are rather small, ranging from 2,700 to 20,000 nodes. Recent studies suggest that datasets at this small scale can limit the capacity of advanced neural architectures (Shchur et al., 2018), as most recent performance improvements on these datasets are nearly statistically identical (Dwivedi et al., 2020). Furthermore, there is no consensus on the splitting procedures for these datasets, which results in reported performance metrics that are incomparable with each other for gauging model designs (Shchur et al., 2018). Finally, a recent study (Zou et al., 2020) shows that these datasets are hindered by some fundamental data quality issues. For example, in Cora, 42% of the nodes leak information between their features and labels, and 1% of the nodes are duplicated. The situation for CiteSeer is even worse, with leakage rates of 62% and duplication rates of 5%.\n\nSome recent works in graph ML have proposed relatively large datasets, such as PPI (56,944 nodes), Reddit (334,863 nodes) (Hamilton et al., 2017b) and Amazon2M (2,449,029 nodes) (Chiang et al., 2019). However, there exist some inherent issues with the proposed data splits. Specifically, 83%, 65% and 90% of the nodes are used for training in the PPI, Reddit and Amazon2M datasets, respectively, which results in an artificially small distribution shift across the training/validation/test sets. Consequently, as may be expected, the performance improvements on these benchmarks have quickly saturated. For example, recent GNN models (Chiang et al., 2019;Zeng et al., 2020) can already yield F1 scores of 99.5 for PPI and 97.0 for Reddit, and 90.4% accuracy for Amazon2M. To sum up, several factors (e.g., size, leakage, splits) associated with the current use of these datasets lead to very small generalization gaps, making them unsuitable as benchmark datasets for graph ML.\n\nLink property prediction. Broadly, there are two lines of efforts for the link-level task: link prediction in homogeneous networks (Liben-Nowell & Kleinberg, 2007;Zhang & Chen, 2018) and relation completion in (heterogeneous) knowledge graphs (Bordes et al., 2013;Hu et al., 2020b). There are several problems with the current benchmark datasets in this area. First, representative datasets for both types of tasks either do not come with input node features or are at a scale of only 1-100 thousand nodes. For example, while the well-known recommender system datasets used in (Berg et al., 2017) include node features, their sizes are very small, with the largest having only 6,000 nodes. On the other hand, though the Open Academic Graph (OAG) used in (Qiu et al., 2019) comprises tens of millions of nodes, there are no associated node features. Second, similar to the node-level task, random splits are also predominantly used in link-level prediction (Bordes et al., 2013;Grover & Leskovec, 2016). Finally, the existing datasets for this task are mostly oriented to applications in recommender systems, social media and knowledge graphs, in which the graphs are typically very sparse. This may result in techniques specialised for sparse link inference that are not generalizable to domains with dense graphs, such as the protein-protein interaction (PPI) graphs typically found in biology (Szklarczyk et al., 2019).\n\nGraph property prediction. Graph-level prediction tasks are found in important applications in natural sciences, such as predicting molecular properties in chemistry (Duvenaud et al., 2015;Gilmer et al., 2017;Hu et al., 2020a), where molecules are naturally represented as molecular graphs. Here, the most widely-used graph-level datasets from the TU collection (Kersting et al., 2016) are known to have many issues, such as small sizes (i.e., less than 1,000 graphs), unrealistic settings (e.g., no bond features for molecules), random data splits, inconsistent evaluation protocols, and isomorphism bias (Ivanov et al., 2019). A very recent attempt (Dwivedi et al., 2020) to address these issues mainly focuses on benchmarking ML models, specifically the building blocks of GNNs, rather than developing application-oriented realistic datasets. In fact, five out of six datasets considered are synthetic. Nevertheless, this effort is complementary to OGB. Recent work in graph ML (Hu et al., 2020a;Ishiguro et al., 2019) has started to adopt MOLECULENET (Wu et al., 2018) that contains a set of realistic and large-scale molecular property prediction datasets. However, there is limited consensus in the dataset splitting as well as choices in molecular graph features, making it hard to compare different models in a fair manner. OGB adopts the MOLECULENET datasets, while providing unified dataset splits as well as the molecular graph features that we found to provide favorable performance over na\u00efve features. Beyond molecular graphs, OGB also provides graphs from other domains, such as biological networks and ASTs of source code (to be included in the next release). Both of them exhibit distinct characteristics from molecular graphs, which enables evaluating the versatility of graph ML models.\n\n\nOGB: Overview\n\nThe goal of OGB is to support and catalyze research in the area of machine learning with graphs, which is a fast-growing and increasingly important area. OGB datasets cover a variety of real-world applications and span several important domains. Furthermore, OGB provides a common codebase using popular deep learning frameworks for loading, constructing, and representing graphs as well as code implementation of established performance metrics for fast model evaluation and comparison.\n\nIn the subsequent sections (Sections 4, 5, and 6), we describe in detail each of the datasets in OGB, focusing on the properties of the graph(s), the prediction task, and the dataset splitting scheme. The currently-available datasets are summarized in Table 2. We also compare datasets from diverse application domains by inspecting their basic graph statistics, e.g., node degree, clustering coefficient, and diameter. We show that they exhibit diverse graph characteristics, which is crucial to evaluate the versatility of graph ML models. The dataset statistics are summarized in Table 3. In the same sections, we additionally show our first individual benchmark analyses of the datasets, discuss our initial findings, and highlight research challenges and opportunities of scaling models to large graphs and improving generalization performance under the realistic data split scenarios. We repeat each experiment 10 times using different random seeds and report the mean and unbiased standard deviation of all training and test results corresponding to the best validation results. All code to reproduce our baseline experiments is publicly available at https: Table 2: Summary of currently-available OGB datasets. An OGB dataset, e.g., ogbg-molhiv, is identified by its prefix (ogbg-) and its name (molhiv). The prefix specifies the category of the graph ML task, i.e., node (ogbn-), link (ogbl-), or graph (ogbg-) property prediction. A realistic split scheme is adopted for each dataset, whose detail can be found in Sections 4, 5, and 6, for each dataset.  Table 3: Statistics of currently-available OGB datasets. All the directed graphs are first converted into undirected ones before the last three graph statistics are calculated using the SNAP library (Leskovec & Sosi\u010d, 2016). The diameter is approximated by performing BFS from 1,000 randomlysampled nodes. Finally, in Section 7, we briefly explain the usage of our OGB Python package that can be readily installed via pip. We demonstrate how the OGB package makes it easy to develop the pipeline of Figure 2 by providing the automatic data loaders and evaluators. The package is publicly available at https://github.com/snap-stanford/ogb, and its documentation can be found at https://ogb.stanford.edu.\n\n\nOGB Node Property Prediction\n\nWe currently provide three datasets, adopted from different application domains, for predicting the properties of individual nodes. Specifically, ogbn-products is an Amazon products co-purchasing network (Kush Bhatia, 2016) (cf. Section 4.1), ogbn-arxiv is an ARXIV paper citation network extracted from the Microsoft Academic Graph (MAG) (Wang et al., 2020) (cf. Section 4.2), and ogbn-proteins is a protein-protein association network (Szklarczyk et al., 2019) (cf. Section 4.3).\n\nThe three datasets show highly different graph statistics, as shown in Table 3. For example, the biological network-ogbn-proteins-is much denser than the social/information networks (ogbn-arxiv and ogbn-products) as can be observed from its large average node degree and small graph diameter. On the other hand, the co-purchasing network-ogbn-products-has more clustered graph structure than the other datasets, as can be seen from its large average clustering coefficient.\n\nBaselines. We consider the following representative models as our baselines unless otherwise specified.\n\n\u2022 MLP: An MLP predictor that uses the given raw node features directly as input. Graph structure information is not included. \u2022 NODE2VEC: An MLP predictor that uses as input the concatenation of the raw node features and NODE2VEC embeddings (Grover & Leskovec, 2016;Perozzi et al., 2014).  (Chiang et al., 2019) that partitions the graphs into a fixed number of subgraphs and draws mini-batches from them. \u2022 GRAPHSAINT (optional): A scalable training technique of GNNs (Zeng et al., 2020) that samples subgraphs via a random walk sampler.\n\nThe two scalable GNN variants, CLUSTERGCN and GRAPHSAINT, are experimented only for graph datasets where full-batch GCN/GRAPHSAGE did not fit into the common GPU memory size of 11GB. The scalable GNNs are more GPU memory-efficient than the full-batch GNNs because they first partition/sample the graph into subgraphs. Hence, in order to train the network, they require only a small amount of nodes to be put onto the GPU memory at each mini-batch. Inference is then performed on the whole graph without GPU usage. To choose the architecture for the scalable GNNs, we first run full-batch GCN and GRAPHSAGE on an NVIDIA Quadro RTX 8000 with 48GB of memory, and then adopt the best performing full-batch GNN architecture for the scalable GNNs. All models are trained with a fixed hidden dimensionality of 256, a fixed number of three layers, and a tuned dropout ratio \u2208 {0.0, 0.5}.\n\n\nogbn-products: Amazon Products Co-purchasing Network\n\nThe dataset ogbn-products is an undirected and unweighted graph, representing an Amazon product co-purchasing network (Kush Bhatia, 2016). Nodes represent products sold in Amazon, and edges between two products indicate that the products are purchased together. We follow Chiang et al. (2019) to process node features and target categories. Specifically, node features are generated by extracting bag-of-words features from the product descriptions followed by a Principal Component Analysis to reduce the dimension to 100. Prediction task. The task is to predict the category of a product in a multi-class classification setup, where the 47 top-level categories are used for target labels.\n\nDataset splitting. We consider a more challenging and realistic dataset splitting that differs from the one used in Chiang et al. (2019). Instead of randomly assigning 90% of the nodes for training and 10% of the nodes for testing (without use of a validation set), we use the sales ranking (popularity) to split nodes into training/validation/test sets. Specifically, we sort the products according to their sales ranking and use the top 10% for training, next top 2% for validation, and the rest for testing. This is a more challenging splitting procedure that closely matches the real-world application where labels are first assigned to important nodes in the network and ML models are subsequently used to make predictions on less important ones.\n\nDiscussion. Overall, our initial benchmarking results in Table 4 show that the highest test performances are attained by GNN architectures, while the MLP baseline that solely relies on a product's description is not sufficient for accurately predicting the category of a product. We also perform additional experiments on the conventional random split with the same split ratio as our sales rank split. We find that the generalization gap 6 of GNNs is much larger on the sales rank split (\u2248 14-23 percentage points) than the random split (\u2248 2-3 percentage points, with, e.g., 87.74\u00b10.06% test accuracy for GRAPHSAGE). Figure 3 illustrates that the sales rank splitting creates a significant distribution shift from training to test nodes, which explains the huge generalization gap. Furthermore, our scalable GNN experiments CLUSTERGCN and GRAPHSAINT perform slightly worse than  their full-batch counterpart, which raises a research opportunity to improve the existing mini-batch training techniques of GNNs. Overall, ogbn-products provides exciting opportunities for the development of scalable GNN models that robustly make predictions on out-of-distribution nodes.\n\n\nogbn-arxiv: Paper Citation Network\n\nThe dataset ogbn-arxiv is a directed graph, representing the citation network between all Computer Science (CS) ARXIV papers indexed by MAG (Wang et al., 2020). Each node is an ARXIV paper and each directed edge indicates that one paper cites another one. Each paper comes with a 128-dimensional feature vector obtained by averaging the embeddings of words in its title and abstract. The embeddings of individual words are computed by running the skip-gram model (Mikolov et al., 2013) over the MAG corpus. In addition, all papers are also associated with the year that the corresponding paper was published.\n\nPrediction task. The task is to predict the 40 subject areas of ARXIV CS papers 7 , e.g., cs.AI, cs.\n\nLG, and cs.OS, which are manually determined (i.e., labeled) by the paper's authors and ARXIV moderators. With the volume of scientific publications doubling every 12 years over the past century (Dong et al., 2017), it is practically critical to automatically classify each publication's areas and topics. Formally, this prediction task is formulated as a 40-class classification problem.\n\nDataset splitting. The previously-used Cora, CiteSeer, and PubMed citation networks are split randomly (Yang et al., 2016). In contrast, we consider a realistic data split based on the publication dates of the papers. The general setting is that the ML models are trained on existing papers and then used to predict the subject areas of newly-published papers, which supports the direct application of them into real-world scenarios, such as replacing the ARXIV moderators. Specifically, we propose to train on papers published until 2017, validate on those published in 2018, and test on those published in 2019.\n\nDiscussion. Our initial benchmarking results are shown in Table 5, where the directed graph is converted to an undirected one for simplicity. First, we observe that the na\u00efve MLP baseline that does not utilize any graph information is significantly outperformed by the other three models that utilize graph information. This suggests that graph information can dramatically improve the performance of predicting a paper's category. Comparing models that do utilize graph information, we find GNN models, i.e., GCN and GRAPHSAGE, slightly outperform the NODE2VEC model. We also conduct experiments on random split with the same split ratio. We find that GCN achieves 73.54\u00b10.13% test accuracy on the random split, suggesting that the realistic time split is indeed more challenging than the random split, providing an opportunity to improve the out-of-distribution generalization performance. Furthermore, it is a fruitful direction to explore how the direction of edges as well as temporal information on nodes (e.g., year in which papers are published) can be taken into account to improve the model performance.\n\n\nogbn-proteins: Protein-Protein Association Network\n\nThe dataset ogbn-proteins is an undirected, weighted, and typed (according to species) graph. Nodes represent proteins, and edges indicate different types of biologically meaningful associations between proteins, e.g., physical interactions, co-expression or homology (Szklarczyk et al., 2019;Consortium, 2018). All edges come with 8-dimensional features, where each dimension represents the strength of a single association type and takes values between 0 and 1 (the larger the value is, the stronger the association is). The proteins come from 8 species. Prediction task. The task is to predict the presence of protein functions in a multi-label binary classification setup, where there are 112 kinds of labels to predict in total. The performance is measured by the average of ROC-AUC scores across the 112 tasks.\n\nDataset splitting. We split the protein nodes into training/validation/test sets according to the species which the proteins come from. This enables the evaluation of the generalization performance of the model across different species.\n\nDiscussion. The dataset ogbn-proteins does not have input node features 8 , but has edge features on more than 30 million edges. In our baseline experiments, we opt for simplicity and use the average edge features of incoming edges as node features.\n\nBenchmarking results are shown in Table 6. Surprisingly, simple MLPs perform better than more sophisticated approaches like NODE2VEC and GCN. Only GRAPHSAGE is able to outperform the na\u00efve MLP approach which indicates that central node information (which is not explicitly modeled in GCN in its message-passing) already contains a lot of crucial information for making correct predictions.\n\nWe further evaluate the best performing GRAPHSAGE on conventional random split with the same split ratio as the species split. On the random split, the generalization gap is extremely low, with 87.83\u00b10.03% test ROC-AUC that is only 0.27 percentage points lower than the training ROC-AUC (88.10\u00b10.01%). This is in contrast to 10.18 percentage points of generalization gap (training AUC minus test AUC) in the species split, as calculated from the GRAPHSAGE experiment in Table 6. The result suggests the unique challenge of across-species generalization that needs to be tackled in future research.\n\nSince the number of nodes in ogbn-proteins is fairly small and easily fit onto common GPUs, we did not run the CLUSTERGCN and GRAPHSAINT experiments. Nonetheless, this dataset presents an interesting research question of how to utilize edge features in a more sophisticated way than just na\u00efve averaging, e.g., by the usage of attention or by treating the graph as a multi-relational graph (as there are 8 different association types between proteins). The challenge is to scalably handle the huge number of edge features efficiently on GPU, which might require clever graph partitioning based on the edge weights.\n\n\nOGB Link Property Prediction\n\nWe currently provide four datasets, adopted from diverse application domains, for predicting the properties of links (pairs of nodes). Specifically, ogbl-ppa is a protein-protein association network (Szklarczyk et al., 2019) (cf. Section 5.1), ogbl-collab is an author collaboration network (Wang et al., 2020) (cf. Section 5.2), ogbl-citation is a paper citation network (Wang et al., 2020) (cf. Section 5.3), and ogbl-wikikg is a Wikidata knowledge graph (Vrande\u010di\u0107 & Kr\u00f6tzsch, 2014) (cf. Section 5.4).\n\nThe different datasets are highly diverse in their graph structure, as shown in Table 3. For example, the biological network, ogbl-ppa, is much denser than the academic networks (ogbl-collab and ogbl-citation) as well as the knowledge graph (ogbl-wikikg), as can be seen from the large average node degree, small number of nodes, and the small graph diameter. On the other hand, the collaboration network, ogbl-collab, has more clustered graph structure than the other datasets, as can be seen from its high average clustering coefficient.\n\n\nBaselines. We implement different sets of baselines for link prediction datasets that only have a single edge type and KG completion datasets that have multiple edge/relation types.\n\nBaselines for link prediction datasets. We consider the following representative models as our baselines unless otherwise specified. For all models, edge features are obtained by using the Hadamard operator between pair-wise node embeddings, and are finally inputted to an MLP for the final prediction. During training, we randomly sample edges and use them as negative examples. We use the same number of negative edges as there are positive edges. Below, we describe how each model obtains node embeddings:\n\n\u2022 MLP: Input node features are directly used as node embeddings. Similar to the node property prediction baselines, the scalable GNN variants, CLUSTERGCN and GRAPHSAINT, are experimented only for graph datasets where full-batch GCN and GRAPHSAGE did not fit into the common GPU memory size of 11GB. To choose the GNN architecture for the scalable GNNs, we first run full-batch GCN and GRAPHSAGE on a NVIDIA Quadro RTX 8000 with 48GB of memory, and then adopt the best performing full-batch GNN architecture for the scalable GNNs. All models are trained with a fixed hidden dimensionality of 256, a fixed number of three layers, and a tuned dropout ratio \u2208 {0.0, 0.5}. Baselines for KG completion datasets. We consider the following representative KG embedding models as our baselines unless otherwise specified.\n\n\u2022 TRANSE: Translation-based KG embedding model by Bordes et al. (2013). For KG with many entities and relations, the embedding dimensionality can be limited by the available GPU memory, as all the embeddings need to be put on GPU at once. We therefore choose the dimensionality such that training can be performed on a fixed-budget of GPU memory. Our training procedure follows Sun et al. (2019), where we perform negative sampling and use margin-based logistic loss for the loss function.\n\n\nogbl-ppa: Protein-Protein Association Network\n\nThe dataset ogbl-ppa is an undirected, unweighted graph. Nodes represent proteins from 58 different species, and edges indicate biologically meaningful associations between proteins, e.g., physical interactions, co-expression, homology or genomic neighborhood (Szklarczyk et al., 2019). We provide a graph object constructed from training edges (no validation and test edges are contained). Each node contains a 58-dimensional one-hot feature vector that indicates the species that the corresponding protein comes from. Prediction task. The task is to predict new association edges given the training edges. The evaluation is based on how well a model ranks positive test edges over negative test edges. Specifically, we rank each positive edge in the validation/test set against 3,000,000 randomly-sampled negative edges, and count the ratio of positive edges that are ranked at K-th place or above (Hits@K). We found K = 100 to be a good threshold to rate a model's performance in our initial experiments. Overall, this metric is way more challenging than ROC-AUC because the model needs to consistently rank the positive edges higher than nearly all the negative edges.\n\nDataset splitting. We provide a biological throughput split of the edges into training/validation/test edges. Training edges are protein associations that are measured experimentally by a high-throughput technology (e.g., cost-effective, automated experiments that make large scale repetition feasible (Macarron et al., 2011;Bajorath, 2002;Younger et al., 2017)) or are obtained computationally (e.g., via text-mining). In contrast, validation and test edges contain protein associations that can only be measured by low-throughput, resource-intensive experiments performed in laboratories. In particular, the goal is to predict a particular type of protein association, e.g., physical protein-protein interaction, from other types of protein associations (e.g., co-expression, homology, or genomic neighborhood) that can be more easily measured and are known to correlate with associations that we are interested in.\n\nDiscussion. Our initial benchmarking results are shown in Table 7. First, the MLP baseline 9 performs extremely poorly, which is to be expected since the node features are not rich in this dataset. Surprisingly, both GNN baselines (GCN, GRAPHSAGE) and NODE2VEC fail to overfit on the training data and show similar performances across training/validation/test splits. The poor training performance of GNNs suggests that positional information, which cannot be captured by GNNs alone (You et al., 2019), might be crucial to fit training edges and obtain meaningful node embeddings. On the other hand, we see that MATRIXFACTORIZATION, which learns a distinct embedding for each node (thus, it can express any positional information of nodes), is indeed able to overfit on the training data, while also reaching better validation and test performance. However, the poor generalization performance still encourages the development of new research ideas to close this gap, e.g., by injecting positional information into GNNs or by developing more sophisticated negative sampling techniques.\n\n\nogbl-collab: Author Collaboration Network\n\nThe dataset ogbl-collab is an undirected graph, representing a subset of the collaboration network between authors indexed by MAG (Wang et al., 2020). Each node represents an author and edges indicate the collaboration between authors. All nodes come with 128-dimensional features, obtained by averaging the word embeddings of papers that are published by the authors. All edges are associated with two meta-information: the year and the edge weight, representing the number of co-authored papers published in that year. The graph can be viewed as a dynamic multi-graph since there can be multiple edges between two nodes if they collaborate in more than one year. Prediction task. The task is to predict the future author collaboration relationships given the past collaborations. The evaluation metric is similar to ogbl-ppa in Section 5.1, where we would like the model to rank true collaborations higher than false collaborations. Specifically, we rank each true collaboration among a set of 100,000 randomly-sampled negative collaborations, and count the ratio of positive edges that are ranked at K-place or above (Hits@K). We found K = 10 to be a good threshold in our preliminary experiments.\n\nDataset splitting. We split the data according to time, in order to simulate a realistic application in collaboration recommendation. Specifically, we use the collaborations until 2017 as training edges, those in 2018 as validation edges, and those in 2019 as test edges.\n\nDiscussion. Our initial benchmarking results are shown in Table 8. Here, NODE2VEC achieves the best results, followed by MATRIXFACTORIZATION and the two GNN models. This can be explained by the fact that positional information, i.e., past collaborations, is a much more indicative feature for predicting future collaboration than solely relying on the average paper representations of authors, i.e., the same research interest. Notably, MATRIXFACTORIZATION achieves nearly perfect training results, but cannot transfer the good results to the validation and test splits, even when heavy regularization is applied. Overall, it is fruitful to explore injecting positional information into GNNs, and develop better regularization methods. This dataset further provides a unique research opportunity for dynamic multi-graphs. One promising direction to explore is to treat edges at different timestamps differently, as recent collaborations may be more indicative about the future collaborations than the past ones.\n\n\nogbl-citation: Paper Citation Network\n\nThe dataset ogbl-citation is a directed graph, representing the citation network between a subset of papers extracted from MAG (Wang et al., 2020). Similar to ogbn-arxiv in Section 4.2, each node is a paper with 128-dimensional WORD2VEC features that summarizes its title and abstract, and each directed edge indicates that one paper cites another. All nodes also come with meta-information indicating the year the corresponding paper was published. Prediction task. The task is to predict missing citations given existing citations. Specifically, for each source paper, two of its references are randomly dropped, and we would like the model to rank the missing two references higher than 1,000 negative reference candidates. The negative references are randomly-sampled from all the previous papers that are not referenced by the source paper. The evaluation metric is Mean Reciprocal Rank (MRR), where the reciprocal rank of the true reference among the negative candidates is calculated for each source paper, and then the average is taken over all source papers.\n\nDataset splitting. We split the edges according to time, in order to simulate a realistic application in citation recommendation (e.g., a user is writing a new paper and has already cited several existing papers, but wants to be recommended additional references). To this end, we use the most recent papers (those published in 2019) as the source papers for which we want to recommend the references. For each source paper, we drop two papers from its references-the resulting two dropped edges (pointing from the source paper to the dropped papers) are used respectively for validation and testing. All the rest of the edges are used for training.\n\nDiscussion. Our initial benchmarking results are shown in Table 9, where the directed graph is converted to an undirected one for simplicity. Here, the GNN models achieve the best results, followed by MARIXFACTORIZATION and NODE2VEC. Among the GNNs, GCN performs better than GRAPHSAGE. However, these GNNs use full-batch training; thus, they are not scalable and require more than 40GB of GPU memory to train, which is intractable on most of today's GPU machines. Hence, we also experiment with the scalable mini-batch training techniques of GNNs, CLUSTERGCN and GRAPHSAINT, on top of the GCN architecture. We see from Table 9 that these techniques give significantly worse performance than the full-batch counterpart, suggesting a research opportunity to further improve the scalable mini-batch training techniques for the link prediction dataset. The significant performance degradation of the mini-batch methods might be explained by the biased sampling, i.e., intra-links within the same cluster partition are sampled more often than inter-links between different clusters. This limitation presents a unique set of challenges for applying the mini-batch techniques to link prediction tasks, differently from those pertaining to node prediction tasks.\n\n\nogbl-wikikg: Wikidata Knowledge Graph\n\nThe dataset ogbl-wikikg is a Knowledge Graph (KG) extracted from the Wikidata knowledge base (Vrande\u010di\u0107 & Kr\u00f6tzsch, 2014). It contains a set of triplet edges (head, relation, tail), capturing the different types of relations between entities in the world, e.g., Canada citizen \u2212\u2212\u2212\u2212\u2192 Hinton. We retrieve all the relational statements in Wikidata and filter out rare entities. Our KG contains 2,500,604 entities and 534 relation types. Prediction task. The task is to predict new triplet edges given the training edges. The evaluation metric follows the standard filtered metric widely used in KG (Bordes et al., 2013;Yang et al., 2015;Trouillon et al., 2016;Sun et al., 2019). Specifically, we corrupt each test triplet edges by replacing its head or tail with randomly-sampled 1,000 negative entities (500 for head and 500 for tail), while ensuring the resulting triplets do not appear in KG. The goal is to rank the true head (or tail) entities higher than the negative entities, which is measured by Mean Reciprocal Rank (MRR).\n\nDataset splitting. We split the triplets according to time, simulating a realistic KG completion scenario that aims to fill in missing triplets that are not present at a certain timestamp. Specifically,  (Wang et al., 2019b), which does not reflect the practical usage.\n\nDiscussion. Our benchmark results are provided in Table 10, where the upper-half baselines are implemented on a single commodity GPU with 11GB memory, while the bottom-half baselines are implemented on a high-end GPU with 48GB memory. 11\n\nFirst, we see from the upper-half of Table 10 that when the limited embedding dimensionality is used, COMPLEX performs the best among the four baselines. With the increased dimensionality, all four models are able to achieve higher MRR on training 12 , validation and test sets, as seen from the bottom-half of Table 10. This suggests the importance of using sufficient embedding dimensionality to achieve good performance in this dataset. Interestingly, although TRANSE performs the worst with the limited dimensionality, it obtains the best performance with the increased dimensionality. Nevertheless, the extremely low test MRR 13 suggests that our realistic KG completion dataset is highly non-trivial. It presents a realistic generalization challenge of discovering new triplets based on existing ones, which necessitates the development of KG models with more robust and generalizable reasoning capability. Furthermore, this dataset presents an important challenge of effectively scaling embedding models to large KGs -na\u00efvely training KG embedding models with reasonable dimensionality would require a high-end GPU, which is extremely costly and not scalable to even larger KGs. A promising approach to improve scalability is to distribute training across multiple commodity GPUs (Zheng et al., 2020;Zhu et al., 2019;. A different approach is to share parameters across entities and relations, so that a smaller number of embedding parameters need to be put onto the GPU memory at once.\n\n10 Available at https://archive.org/search.php?query=creator%3A%22Wikidata+ editors%22 11 Given a fixed 11GB GPU memory budget, we adopt 100-dimension embeddings for DISTMULT and TRANSE. Since ROTATE and COMPLEX require doubling the entity embedding dimensionality, we train these two models with dimensionality of 50. On the other hand, on the high-end GPU with 48GB memory, we are able to train models with sextupled embedding dimensionality. 12 The training MRR here is computed based on 500 randomly-sampled entities without filtering, as filtering is computationally costly. The unfiltered MRR has the systematic bias of being smaller than the filtered counterpart (Bordes et al., 2013). 13 Note that our test MRR on ogbl-wikikg is computed using only 500 negative entities per triplet, which is much less than the number of negative entities used to compute MRR in the existing KG datasets, such as FB15k and FB15k-237 (around 15,000 negative entities). Nevertheless, RotatE gives either lower or comparable test MRR on ogbl-wikikg compared to FB15k and FB15k-237 (Sun et al., 2019).\n\n\nOGB Graph Property Prediction\n\nWe currently provide three datasets, adopted from two distinct application domains, for predicting the properties of entire graphs or subgraphs. Specifically, ogbg-molhiv and ogbg-molpcba are molecular graphs (Wu et al., 2018) (cf. Section 6.1), and ogbg-ppa is a set of protein-protein association subgraphs (Zitnik et al., 2019) (cf. Section 6.2).\n\nThe different datasets are highly diverse in their graph structure, as shown in Table 3. For example, the molecular graphs (ogbg-molhiv and ogbg-molpcba) are tree-like graphs with small number of nodes per graph, small average node degrees, small average clustering coefficient, and large average graph diameter. This is in stark contrast to the biological subgraphs, ogbg-ppa, which has much larger number of nodes per graph, as well as much denser and clustered graph structure, as seen by the large average node degree, large average clustering coefficient, and large graph diameter.\n\nBaselines. We consider the following representative GNNs as our baselines unless otherwise specified. GNNs are used to obtain node embeddings, which are then pooled to give the embedding of the entire graph. Finally, a linear model is applied to the graph embedding to make predictions.\n\n\u2022 GCN: Graph Convolutioanl Networks (Kipf & Welling, 2016).\n\n\u2022 GCN+VIRTUAL NODE: GCN that performs message passing over augmented graphs with virtual nodes, i.e., additional nodes that are connected to all nodes in the original graphs (Gilmer et al., 2017;Li et al., 2017;Ishiguro et al., 2019). \u2022 GIN: Graph Isomorphism Network .\n\n\u2022 GIN+VIRTUAL NODE: GIN that performs message passing over augmented graphs with virtual nodes.\n\nTo include edge features, we follow Hu et al. (2020a) and simply add edge features into the incoming node features. For all the experiments, we use 5-layer GNNs, average graph pooling, a hidden dimensionality of 300, and the dropout ratio of 0.5.\n\n\nogbg-mol * : Molecular Graphs\n\nThe datasets ogbg-molhiv and ogbg-molpcba are two molecular property prediction datasets of different sizes: ogbg-molhiv (small) and ogbg-molpcba (medium). They are adopted from the MOLECULENET (Wu et al., 2018), and are among the largest of the MOLECULENET datasets. All the molecules are pre-processed using RDKIT (Landrum et al., 2006). Each graph represents a molecule, where nodes are atoms, and edges are chemical bonds. Input node features are 9-dimensional, containing atomic number and chirality, as well as other additional atom features such as formal charge and whether the atom is in the ring or not. Input edge features are 3-dimensional, containing bond type, bond stereochemistry as well as an additional bond feature indicating whether the bond is conjugated. Note that the above additional features are not needed to uniquely identify molecules. In the experiments, we perform ablation study on the molecule features and find that including the additional features improves performance.\n\nPrediction task. The task is to predict the target molecular properties as accurately as possible, where the molecular properties are cast as binary labels, e.g., whether a molecule inhibits HIV virus replication or not. For evaluation metric, we closely follow Wu et al. (2018). Specifically, for ogbg-molhiv, we use ROC-AUC for evaluation. For ogbg-molpcba, as the class balance is extremely skewed (only 1.4% of data is positive) and the dataset contains multiple classification tasks, we use the PRC-AUC averaged over the tasks as the evaluation metric.\n\nDataset splitting. We adopt the scaffold splitting procedure that splits the molecules based on their two-dimensional structural frameworks. The scaffold splitting attempts to separate structurally different molecules into different subsets, which provides a more realistic estimate of model performance in prospective experimental settings (Wu et al., 2018).\n\nDiscussion. Benchmarking results are given in Tables 11 and 12. We see that GIN with additional features and virtual nodes provides the best performance in the two datasets. In our preliminary experiments, we find this to be the case even for the other smaller MOLECULENET datasets. In OGB, we therefore include the additional node/edge features in our molecular graphs. Beside the two main molecule datasets, we also provide the ten other MOLECULENET datasets, together with their data loaders and splits. These datasets can be used to stress-test molecule-specific methods  and transfer learning (Hu et al., 2020a).  We further report the performance on the random splitting, keeping the split ratio the same as the scaffold splitting. We find the random split to be much easier than scaffold split. On random split of ogbg-molhiv and ogbg-molpcba, the best GIN achieves the ROC-AUC of 82.73\u00b12.02% (5.66 percentage points higher than scaffold) and PRC-AUC of 34.14\u00b10.49% (7.49 percentage points higher than scaffold), respectively. The same trend holds true for the other MOLECULENET datasets, e.g., the best GIN performance on the random split of ogbg-moltox21 is 86.03\u00b11.37%, which is 8.46 percentage points higher than that of the best GIN for the scaffold split (77.57\u00b10.62% ROC-AUC). These results highlight the challenges of the scaffold split compared to the random split, and opens up a fruitful research opportunity to increase the out-of-distribution generalization capability of GNNs.\n\n\nogbg-ppa: Protein-Protein Association Network\n\nThe dataset ogbg-ppa is a set of undirected protein association neighborhoods extracted from the protein-protein association networks of 1,581 different species (Szklarczyk et al., 2019) that cover 37 broad taxonomic groups (e.g., mammals, bacterial families, archaeans) and span the tree of life (Hug et al., 2016). To construct the neighborhoods, we randomly selected 100 proteins from each species and constructed 2-hop protein association neighborhoods centered on each of the selected proteins (Zitnik et al., 2019). We then removed the center node from each neighborhood and subsampled the neighborhood to ensure the final protein association graph is small enough (less than 300 nodes). Nodes in each protein association graph represent proteins, and edges indicate biologically meaningful associations between proteins. The edges are associated with 7-dimensional features, where each element takes a value between 0 and 1 and represents the strength of a particular type of protein protein association such as gene co-occurrence, gene fusion events, and co-expression.\n\nPrediction task. Given a protein association neighborhood graph, the task is a 37-way multi-class classification to predict what taxonomic group the graph originates from. The ability to successfully tackle this problem has implications for understanding the evolution of protein complexes across species (De Juan et al., 2013), the rewiring of protein interactions over time (Sharan et al., 2005;Zitnik et al., 2019), the discovery of functional associations between genes even for otherwise rarely-studied organisms (Cowen et al., 2017), and would give us insights into key bioinformatics tasks, such as biological network alignment (Malod-Dognin et al., 2017). Dataset splitting. Similar to ogbn-proteins in Section 4.3, we adopt the species split, where the neighborhood graphs in validation and test sets are extracted from protein association networks of species that are not seen during training but belong to one of the 37 taxonomic groups. This split stress-tests the model's capability to extract graph features that are essential to the prediction of the taxonomic groups, which is important for biological understanding of protein associations.\n\nDiscussion. Benchmarking results are given in Table 13. Interestingly, similar to the ogbg-mol * datasets, GIN with virtual nodes provides the best performance. Nevertheless, the generalization gap is huge (almost 30 percentage points). For reference, we also experiment with the random splitting scenario, where we use the same model (GIN + Virtual node) on the same split ratio. On the random split, the test accuracy is 92.91\u00b10.27%, which is more than 20 percentage points higher than the species split. This again encourages future research to improve the out-of-distribution generalization with more challenging and meaningful split procedures.\n\n\nOGB Package\n\nThe OGB package is designed to make the pipeline of Figure 2 easily accessible to researchers, by automating the data loading and the evaluation parts. OGB is fully compatible with PYTORCH and its associated graph libraries: PYTORCH GEOMETRIC and DEEP GRAPH LIBRARY. OGB additionally provides library-agnostic dataset objects that can be used by any other PYTORCH deep learning frameworks such as TENSORFLOW (Abadi et al., 2016) and MXNET . Below, we explain the data loading (cf. Section 7.1) and evaluation (cf. Section 7.2). For simplicity, we focus on the task of the graph property prediction (cf. Section 6) using PYTORCH GEOMETRIC. For the other tasks, libraries, and more details, refer to https://ogb.stanford.edu/.\n\n\nOGB Data Loaders\n\nThe OGB package makes it easy to obtain a dataset object that is fully compatible with PYTORCH GEOMETRIC. As shown in Code Snippet 1, it can be done with only a single line of code, with the end-users only needing to specify the name of the dataset. The OGB package will then download, process, store, and return the requested dataset object. Furthermore, the standardized dataset splitting can be readily obtained from the dataset object.\n\n>>> from ogb.graphproppred import PygGraphPropPredDataset >>> dataset = PygGraphPropPredDataset(name=\"ogbg-molhiv\") # Pytorch Geometric dataset object >>> split_idx = dataset.get_idx_split() # Dictionary containing train/valid/test indices. >>> train_idx = split_idx[\"train\"] # torch.tensor storing a list of training indices.\n\nCode Snippet 1: OGB Data Loader\n\n\nOGB Evaluators\n\nOGB also enables standardized and reliable evaluation with the ogb. * .Evaluator class. As shown in Code Snippet 2, the end-users first specify the dataset they want to evaluate their models on, after which the users can learn the format of the input they need to pass to the Evaluator object. The input format is dataset-dependent. For example, for ogbg-molpcba, the Evaluator object requires as input a dictionary with y_true (a matrix storing the ground-truth binary labels 14 ), and y_pred (a matrix storing the scores output by the model). Once the end-users pass the specified dictionary as input, the Evaluator object returns the model performance that is appropriate for the dataset at hand, e.g., PRC-AUC for ogbg-molpcba.\n\n>>> from ogb.graphproppred import Evaluator # Get Evaluator for ogbg-molhiv >>> evaluator = Evaluator(name = \"ogbg-molhiv\") # Learn about the specification of input to the Evaluator. >>> print(evaluator.expected_input_format) # Prepare input that follows input spec. >>> input_dict = {\"y_true\": y_true, \"y_pred\": y_pred} # Get the model performance. result_dict = evaluator.eval(input_dict)\n\nCode Snippet 2: OGB Evaluator\n\n\nConclusion and Future Plans\n\nTo enable scalable, robust, and reproducible graph ML research, we introduce the Open Graph Benchmark (OGB)-a diverse set of realistic graph datasets in terms of scales, domains, and task categories. We employ realistic splitting schemes for the given datasets, driven by application-specific use cases. Through extensive benchmark analysis, we highlight the challenges of scaling up ML models to large-scale graphs and making accurate prediction under the realistic data splitting scenarios. Altogether, our aim is for OGB to push the frontier of graph ML research.\n\nOur immediate future plan is to increase the coverage in Table 1 by adding large graph datasets with over 10 million nodes, as well as heterogeneous knowledge graphs. The paper will be updated as more datasets are included in OGB.\n\nFinally, OGB is an open-source initiative implemented in Python based on popular deep learning packages-PYTORCH, PYTORCH GEOMETRIC, and DEEP GRAPH LIBRARY-we hereby invite the community to develop and benchmark state-of-the-art graph ML models at https://ogb. stanford.edu.\n\nFigure 1 :\n1OGB provides datasets that are diverse in scale, domains, and task categories.\n\n\n\u2022 GCN: Full-batch Graph Convolutional Network (Kipf & Welling, 2017). \u2022 GRAPHSAGE: Full-batch GraphSAGE (Hamilton et al., 2017a), where we adopt its mean pooling variant and a simple skip connection to preserve central node features. \u2022 CLUSTERGCN (optional): A scalable training technique of GNNs\n\nFigure 3 :\n3T-SNE visualization of training/validation/test nodes in ogbn-products.\n\n\u2022 NODE2VEC :\nNODE2VECThe node embeddings are obtained by concatenating input features and NODE2VEC embeddings(Grover & Leskovec, 2016;Perozzi et al., 2014).\u2022 GCN: The node embeddings are obtained by full-batch Graph Convolutional Networks (GCN) (Kipf & Welling, 2017). \u2022 GRAPHSAGE: The node embeddings are obtained by full-batch GraphSAGE (Hamilton et al., 2017a), where we adopt its mean pooling variant and a simple skip connection to preserve central node features. \u2022 MATRIXFACTORIZATION: The distinct embeddings are assigned to different nodes and are learned in an end-to-end manner together with the MLP predictor. \u2022 CLUSTERGCN (optional): A scalable training technique of GNNs(Chiang et al., 2019) that partitions the graphs into a fixed number of subgraphs and draws mini-batches from them. \u2022 GRAPHSAINT (optional): A scalable training technique of GNNs(Zeng et al., 2020)  that samples subgraphs via a random walk sampler.\n\n\n\u2022 DISTMULT: Multiplication-based KG embedding model byYang et al. (2015).\u2022 COMPLEX: Complex-valued multiplication-based KG embedding model byTrouillon et al. (2016). \u2022 ROTATE: Rotation-based KG embedding model bySun et al. (2019).\n\n\nPresent work: OGB. Here, we present the OPEN GRAPH BENCHMARK (OGB) with the goal of facilitating scalable, robust, and reproducible graph ML research. The premise of OGB is to develop a diverse set of challenging and realistic benchmark datasets that can empower the rigorousOGB Graph \nDatasets \n\nOGB Data \nLoader \n\nYour ML \nModel \n\nOGB \nEvaluator \n\nOGB \nLeaderboards \n\n(a) \n(b) \n(c) \n(d) \n(e) \n\n\n\nTable 1 :\n1Overview of currently-available OGB datasets (denoted in green). Nature domain includes biological networks and molecular graphs, Society domain includes academic graphs and e-commerce networks, and Information domain includes knowledge graphs.Task \nNode property prediction \nogbn-\nDomain \nNature \nSociety \nInformation \n\nSmall \narxiv \nMedium \nproteins \nproducts \nLarge \n\nTask \nLink property prediction \nogbl-\nDomain \nNature \nSociety \nInformation \n\nSmall \ncollab \nMedium \nppa \ncitation \nwikikg \nLarge \n\nTask \nGraph property prediction \nogbg-\nDomain \nNature \nSociety \nInformation \n\n\n\n\n//github.com/snap-stanford/ogb/tree/master/examples and is meant as a starting point to accelerate further research on our proposed datasets. We refer the interested reader to our code base for a detailed overview of model architectures and hyperparameter settings.Category Name \n#Graphs \nAverage \nAverage \nAverage \nAverage \nAverage \n#Nodes \n#Edges Node Deg. Clust. Coeff. Diameter \n\nNode \nogbn-\n\nproducts \n1 2,449,029 61,859,140 \n50.5 \n0.411 \n29 \narxiv \n1 \n169,343 \n1,166,243 \n13.8 \n0.226 \n22 \nproteins \n1 \n132,534 39,561,252 \n597.0 \n0.280 \n8 \n\nLink \nogbl-\n\nppa \n1 \n576,289 30,326,273 \n73.7 \n0.223 \n14 \ncollab \n1 \n235,868 \n1,285,465 \n10.0 \n0.729 \n21 \ncitation \n1 2,927,963 30,561,187 \n20.8 \n0.178 \n21 \nwikikg \n1 2,500,604 17,137,181 \n12.9 \n0.168 \n26 \n\nGraph \nogbg-\n\nmolhiv \n41,127 \n25.5 \n27.5 \n2.2 \n0.002 \n12.0 \nmolpcba \n437,929 \n26.0 \n28.1 \n2.2 \n0.002 \n13.6 \nppa \n158,100 \n243.4 \n2,266.1 \n18.3 \n0.513 \n4.8 \n\n\n\nTable 4 :\n4Results for ogbn-products. \u2020 Requires a GPU with 48GB of memory. GRAPHSAGE \u2020 92.98\u00b10.16 91.59\u00b10.12 78.03\u00b10.22 CLUSTERGCN 92.79\u00b10.41 90.42\u00b10.33 75.18\u00b10.41 GRAPHSAINT 93.30\u00b10.05 91.75\u00b10.06 77.29\u00b10.19Method \nAccuracy (%) \nTraining \nValidation \nTest \n\nMLP \n84.24\u00b10.54 75.60\u00b10.13 61.12\u00b10.10 \nNODE2VEC \n94.24\u00b10.52 89.85\u00b10.12 72.12\u00b10.24 \nGCN  \u2020 \n92.86\u00b10.11 91.66\u00b10.06 75.65\u00b10.20 \nTrain \nValidation \nTest \n\n\n\nTable 5 :Table 6 :\n56Results for ogbn-arxiv. Results for ogbn-proteins.Method \nAccuracy (%) \nTraining \nValidation \nTest \n\nMLP \n63.58\u00b10.81 57.65\u00b10.12 55.50\u00b10.23 \nNODE2VEC \n76.43\u00b10.81 71.29\u00b10.13 70.07\u00b10.13 \nGCN \n78.87\u00b10.66 73.00\u00b10.17 71.74\u00b10.29 \nGRAPHSAGE 82.35\u00b11.51 72.77\u00b10.16 71.49\u00b10.27 \n\nMethod \nROC-AUC (%) \nTraining \nValidation \nTest \n\nMLP \n81.78\u00b10.48 77.06\u00b10.14 72.04\u00b10.48 \nNODE2VEC \n79.76\u00b11.88 70.07\u00b10.53 68.81\u00b10.65 \nGCN \n75.64\u00b10.36 72.60\u00b10.44 65.11\u00b11.52 \nGRAPHSAGE 87.86\u00b10.13 83.34\u00b10.13 77.68\u00b10.20 \n\n\n\nTable 7 :\n7Results for ogbl-ppa.Method \nHits@100 (%) \nTraining \nValidation \nTest \n\nMLP \n0.46\u00b10.00 \n0.46\u00b10.00 \n0.46\u00b10.00 \nNODE2VEC \n24.43\u00b10.92 22.53\u00b10.88 22.26\u00b10.83 \nGCN \n12.41\u00b11.55 12.13\u00b11.49 11.55\u00b11.53 \nGRAPHSAGE \n11.44\u00b12.68 10.86\u00b12.51 10.63\u00b12.44 \nMATRIXFACTORIZATION 81.65\u00b19.15 32.28\u00b14.28 32.29\u00b10.94 \n\n\n\nTable 8 :\n8Results for ogbl-collab.Method \nHits@10 (%) \nTraining \nValidation \nTest \n\nMLP \n30.04\u00b13.07 12.08\u00b11.84 9.20\u00b11.61 \nNODE2VEC \n90.13\u00b11.13 51.56\u00b11.44 42.81\u00b11.40 \nGCN \n59.95\u00b14.52 36.89\u00b12.27 33.29\u00b11.90 \nGRAPHSAGE \n69.21\u00b19.70 38.04\u00b16.26 31.21\u00b16.20 \nMATRIXFACTORIZATION 99.99\u00b10.02 48.05\u00b10.20 38.05\u00b10.18 \n\n\n\nTable 9 :\n9Results for ogbl-citation. \u2020 Requires a GPU with 48GB of memory. Repeated only for 5 times due to resource constraints.Method \nMRR \nTraining \nValidation \nTest \n\nMLP \n0.2885\u00b10.0011 0.2891\u00b10.0014 0.2897\u00b10.0011 \nNODE2VEC \n0.6918\u00b10.0007 0.5933\u00b10.0011 0.5960\u00b10.0013 \nGCN  \u2020 \n0.9083\u00b10.0036 0.8474\u00b10.0040 0.8480\u00b10.0040 \nGRAPHSAGE  \u2020 \n0.8840\u00b10.0100 0.8129\u00b10.0079 0.8167\u00b10.0110 \nMATRIXFACTORIZATION 0.9659\u00b10.0047 0.6143\u00b10.0117 0.6162\u00b10.0112 \n\nCLUSTERGCN \n0.8726\u00b10.0053 0.7980\u00b10.0040 0.7997\u00b10.0037 \nGRAPHSAINT \n0.8423\u00b10.0121 0.7855\u00b10.0058 0.7875\u00b10.0060 \n\n\n\nTable 10 :\n10Results for ogbl-wikikg. \u2020 Requires a GPU with 48GB of memory. Repeated only once due to resource constraints.Method \nMRR \nTraining \nValidation \nTest \n\nTRANSE \n0.3326\u00b10.0041 0.2314\u00b10.0035 0.2535\u00b10.0036 \nDISTMULT \n0.4131\u00b10.0057 0.3142\u00b10.0066 0.3434\u00b10.0079 \nCOMPLEX \n0.4605\u00b10.0020 0.3612\u00b10.0063 0.3877\u00b10.0051 \nROTATE \n0.3469\u00b10.0055 0.2366\u00b10.0043 0.2681\u00b10.0047 \n\nTRANSE (6\u00d7dim)  \u2020 \n0.6492 \n0.4588 \n0.4536 \nDISTMULT (6\u00d7dim)  \u2020 \n0.4337 \n0.3402 \n0.3609 \nCOMPLEX (6\u00d7dim)  \u2020 \n0.4714 \n0.3786 \n0.4024 \nROTATE (6\u00d7dim)  \u2020 \n0.6082 \n0.3610 \n0.3622 \n\nwe downloaded Wikidata at three different time stamps 10 (May, August, and November of 2015), and \nconstruct three KGs, where we only retain entities and relation types that appear in the earliest May \nKG. We use the triplets in the May KG for training, and use the additional triplets in the August and \nNovember KGs for validation and test, respectively. Note that our dataset split is different from the \nexisting Wikidata KG dataset that adopts conventional random split \n\nTable 11 :\n11Results for ogbg-molhiv.Method \nAdditional Virtual \nROC-AUC (%) \nFeatures \nNode \nTraining \nValidation \nTest \n\nGCN \n\n% \n\" 88.65\u00b11.01 83.73\u00b10.78 74.18\u00b11.22 \n\" \n% 88.65\u00b12.19 82.04\u00b11.41 76.06\u00b10.97 \n\" \n\" 90.07\u00b14.69 83.84\u00b10.91 75.99\u00b11.19 \n\nGIN \n\n% \n\" 93.89\u00b12.96 84.1\u00b11.05 75.2\u00b11.30 \n\" \n% 88.64\u00b12.54 82.32\u00b10.90 75.58\u00b11.40 \n\" \n\" 92.73\u00b13.80 84.79\u00b10.68 77.07\u00b11.49 \n\n\n\nTable 12 :\n12Results for ogbg-molpcba. 36.89\u00b10.35 22.32\u00b10.23 22.17\u00b10.23 \" \" 46.82\u00b10.58 27.54\u00b10.27 26.55\u00b10.27Method \nAdditional Virtual \nPRC-AUC (%) \nFeatures \nNode \nTraining \nValidation \nTest \n\nGCN \n\n% \n\" 36.05\u00b10.67 23.45\u00b10.13 22.58 \u00b10.32 \n\" \n% 27.93 \u00b10.12 20.39\u00b10.30 19.83\u00b10.16 \n\" \n\" 38.37\u00b10.44 24.72 \u00b10.23 23.97\u00b10.23 \n\nGIN \n\n% \n\" 45.17\u00b10.81 26.92\u00b10.24 26.0\u00b10.43 \n\" \n% \n\nTable 13 :\n13Results for ogbg-ppa. GCN % 97.68\u00b10.22 64.97\u00b10.34 68.39\u00b10.84 \" 97.00\u00b11.00 65.11\u00b10.48 68.57\u00b10.61 GIN % 97.55\u00b10.52 65.62\u00b11.07 68.92\u00b11.00 \" 98.28\u00b10.46 66.78\u00b11.05 70.37\u00b11.07Method \nVirtual \nAccuracy (%) \nNode \nTraining \nValidation \nTest \n\n\nhttps://pytorch.org 2 https://pytorch-geometric.readthedocs.io 3 https://www.dgl.ai 4 https://github.com/snap-stanford/ogb 5 https://ogb.stanford.edu/docs/leader_overview\nDefined by the difference between training and test accuracy.\nhttps://arxiv.org/corr/subjectclasses\nIn our preliminary experiments, we used one-hot encodings of species ID as node features, but that did not work well empirically, which can be explained by the fact that the species ID is used for dataset splitting.\nHere we obtain node embeddings by applying a linear layer to the raw one-hot node features.\nThe shape of the matrix is the number of data points times the number of tasks. The matrix can be either a PYTORCH tensor or NUMPY array.\nAcknowledgementsWe thank Adrijan Bradaschia and Rok Sosic for their help in setting up the server and website. Weihua The U.S. Government is authorized to reproduce and distribute reprints for Governmental purposes notwithstanding any copyright notation thereon. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and do not necessarily reflect the views, policies, or endorsements, either expressed or implied, of DARPA, NIH, ARO, or the U.S. Government.\nTensorflow: A system for large-scale machine learning. Mart\u00edn Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, Symposium on Operating Systems Design and Implementation OSDI). Mart\u00edn Abadi, Paul Barham, Jianmin Chen, Zhifeng Chen, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Geoffrey Irving, Michael Isard, et al. Tensorflow: A system for large-scale machine learning. In Symposium on Operating Systems Design and Implementation OSDI), pp. 265-283, 2016.\n\nLearning to represent programs with graphs. Miltiadis Allamanis, Marc Brockschmidt, Mahmoud Khademi, arXiv:1711.00740arXiv preprintMiltiadis Allamanis, Marc Brockschmidt, and Mahmoud Khademi. Learning to represent programs with graphs. arXiv preprint arXiv:1711.00740, 2017.\n\nIntegration of virtual and high-throughput screening. J\u00fcrgen Bajorath, Nature Reviews Drug Discovery. 111J\u00fcrgen Bajorath. Integration of virtual and high-throughput screening. Nature Reviews Drug Discovery, 1(11):882-894, 2002.\n\nNetwork biology: understanding the cell's functional organization. Albert-Laszlo Barabasi, N Zoltan, Oltvai, Nature reviews genetics. 52Albert-Laszlo Barabasi and Zoltan N Oltvai. Network biology: understanding the cell's functional organization. Nature reviews genetics, 5(2):101-113, 2004.\n\nThe third 'chime'speech separation and recognition challenge: Dataset, task and baselines. Jon Barker, Ricard Marxer, Emmanuel Vincent, Shinji Watanabe, 2015 IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU). IEEEJon Barker, Ricard Marxer, Emmanuel Vincent, and Shinji Watanabe. The third 'chime'speech separation and recognition challenge: Dataset, task and baselines. In 2015 IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU), pp. 504-511. IEEE, 2015.\n\nRianne Van Den, Thomas N Berg, Max Kipf, Welling, arXiv:1706.02263Graph convolutional matrix completion. arXiv preprintRianne van den Berg, Thomas N. Kipf, and Max Welling. Graph convolutional matrix completion. arXiv preprint arXiv:1706.02263, 2017.\n\nTranslating embeddings for modeling multi-relational data. Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran, Jason Weston, Oksana Yakhnenko, Advances in Neural Information Processing Systems (NIPS). Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran, Jason Weston, and Oksana Yakhnenko. Translating embeddings for modeling multi-relational data. In Advances in Neural Information Processing Systems (NIPS), pp. 2787-2795, 2013.\n\nGeometric deep learning: going beyond euclidean data. Joan Michael M Bronstein, Yann Bruna, Arthur Lecun, Pierre Szlam, Vandergheynst, IEEE Signal Processing Magazine. 344Michael M Bronstein, Joan Bruna, Yann LeCun, Arthur Szlam, and Pierre Vandergheynst. Geometric deep learning: going beyond euclidean data. IEEE Signal Processing Magazine, 34(4):18-42, 2017.\n\nMxnet: A flexible and efficient machine learning library for heterogeneous distributed systems. Tianqi Chen, Mu Li, Yutian Li, Min Lin, Naiyan Wang, Minjie Wang, Tianjun Xiao, Bing Xu, Chiyuan Zhang, Zheng Zhang, NeurIPS workshop on Machine Learning Systems. Tianqi Chen, Mu Li, Yutian Li, Min Lin, Naiyan Wang, Minjie Wang, Tianjun Xiao, Bing Xu, Chiyuan Zhang, and Zheng Zhang. Mxnet: A flexible and efficient machine learning library for heterogeneous distributed systems. In NeurIPS workshop on Machine Learning Systems, 2015.\n\nCluster-GCN: An efficient algorithm for training deep and large graph convolutional networks. Wei-Lin Chiang, Xuanqing Liu, Si Si, Yang Li, Samy Bengio, Cho-Jui Hsieh, ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD). Wei-Lin Chiang, Xuanqing Liu, Si Si, Yang Li, Samy Bengio, and Cho-Jui Hsieh. Cluster-GCN: An efficient algorithm for training deep and large graph convolutional networks. In ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD), pp. 257-266, 2019.\n\nThe gene ontology resource: 20 years and still going strong. Gene Ontology Consortium, Nucleic acids research. 47D1Gene Ontology Consortium. The gene ontology resource: 20 years and still going strong. Nucleic acids research, 47(D1):D330-D338, 2018.\n\nNetwork propagation: a universal amplifier of genetic associations. Lenore Cowen, Trey Ideker, J Benjamin, Roded Raphael, Sharan, Nature Reviews Genetics. 189551Lenore Cowen, Trey Ideker, Benjamin J Raphael, and Roded Sharan. Network propagation: a universal amplifier of genetic associations. Nature Reviews Genetics, 18(9):551, 2017.\n\nEmerging methods in protein co-evolution. Florencio David De Juan, Alfonso Pazos, Valencia, Nature Reviews Genetics. 144David De Juan, Florencio Pazos, and Alfonso Valencia. Emerging methods in protein co-evolution. Nature Reviews Genetics, 14(4):249-261, 2013.\n\nImagenet: A large-scale hierarchical image database. Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, Li Fei-Fei, cvpr. IeeeJia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A large-scale hierarchical image database. In cvpr, pp. 248-255. Ieee, 2009.\n\nA century of science: Globalization of scientific collaborations, citations, and innovations. Yuxiao Dong, Hao Ma, Zhihong Shen, Kuansan Wang, ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD). ACMYuxiao Dong, Hao Ma, Zhihong Shen, and Kuansan Wang. A century of science: Globalization of scientific collaborations, citations, and innovations. In ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD), pp. 1437-1446. ACM, 2017.\n\nConvolutional networks on graphs for learning molecular fingerprints. Dougal David K Duvenaud, Jorge Maclaurin, Rafael Iparraguirre, Timothy Bombarell, Al\u00e1n Hirzel, Ryan P Aspuru-Guzik, Adams, Advances in Neural Information Processing Systems (NIPS). David K Duvenaud, Dougal Maclaurin, Jorge Iparraguirre, Rafael Bombarell, Timothy Hirzel, Al\u00e1n Aspuru-Guzik, and Ryan P Adams. Convolutional networks on graphs for learning molecular fingerprints. In Advances in Neural Information Processing Systems (NIPS), pp. 2224-2232, 2015.\n\nVijay Prakash Dwivedi, K Chaitanya, Thomas Joshi, Yoshua Laurent, Xavier Bengio, Bresson, arXiv:2003.00982Benchmarking graph neural networks. arXiv preprintVijay Prakash Dwivedi, Chaitanya K Joshi, Thomas Laurent, Yoshua Bengio, and Xavier Bresson. Benchmarking graph neural networks. arXiv preprint arXiv:2003.00982, 2020.\n\n. David Easley, Jon Kleinberg, Cambridge university press Cambridge8David Easley, Jon Kleinberg, et al. Networks, crowds, and markets, volume 8. Cambridge university press Cambridge, 2010.\n\nA fair comparison of graph neural networks for graph classification. Federico Errica, Marco Podda, Davide Bacciu, Alessio Micheli, arXiv:1912.09893arXiv preprintFederico Errica, Marco Podda, Davide Bacciu, and Alessio Micheli. A fair comparison of graph neural networks for graph classification. arXiv preprint arXiv:1912.09893, 2019.\n\nFast graph representation learning with PyTorch Geometric. M Fey, J E Lenssen, ICLR Workshop on Representation Learning on Graphs and Manifolds. M. Fey and J. E. Lenssen. Fast graph representation learning with PyTorch Geometric. In ICLR Workshop on Representation Learning on Graphs and Manifolds, 2019.\n\nNeural message passing for quantum chemistry. Justin Gilmer, S Samuel, Schoenholz, F Patrick, Oriol Riley, George E Vinyals, Dahl, International Conference on Machine Learning (ICML). Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, and George E Dahl. Neural message passing for quantum chemistry. In International Conference on Machine Learning (ICML), pp. 1273-1272, 2017.\n\nnode2vec: Scalable feature learning for networks. Aditya Grover, Jure Leskovec, ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD). ACMAditya Grover and Jure Leskovec. node2vec: Scalable feature learning for networks. In ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD), pp. 855-864. ACM, 2016.\n\nInductive representation learning on large graphs. Rex William L Hamilton, Jure Ying, Leskovec, Advances in Neural Information Processing Systems (NIPS). William L Hamilton, Rex Ying, and Jure Leskovec. Inductive representation learning on large graphs. In Advances in Neural Information Processing Systems (NIPS), pp. 1025-1035, 2017a.\n\nRepresentation learning on graphs: Methods and applications. Rex William L Hamilton, Jure Ying, Leskovec, IEEE Data Engineering Bulletin. 403William L Hamilton, Rex Ying, and Jure Leskovec. Representation learning on graphs: Methods and applications. IEEE Data Engineering Bulletin, 40(3):52-74, 2017b.\n\nStrategies for pre-training graph neural networks. Weihua Hu, Bowen Liu, Joseph Gomes, Marinka Zitnik, Percy Liang, Vijay Pande, Jure Leskovec, International Conference on Learning Representations (ICLR). Weihua Hu, Bowen Liu, Joseph Gomes, Marinka Zitnik, Percy Liang, Vijay Pande, and Jure Leskovec. Strategies for pre-training graph neural networks. In International Conference on Learning Representations (ICLR), 2020a.\n\nHeterogeneous graph transformer. Ziniu Hu, Yuxiao Dong, Kuansan Wang, Yizhou Sun, Proceedings of the International World Wide Web Conference. the International World Wide Web ConferenceWWW2020Ziniu Hu, Yuxiao Dong, Kuansan Wang, and Yizhou Sun. Heterogeneous graph transformer. In Proceedings of the International World Wide Web Conference (WWW), pp. n/a, 2020b.\n\nA new view of the tree of life. A Laura, Hug, J Brett, Karthik Baker, Anantharaman, T Christopher, Alexander J Brown, Cindy J Probst, Cristina N Castelle, Alex W Butterfield, Yuki Hernsdorf, Kotaro Amano, Ise, Nature Microbiology. 1516048Laura A Hug, Brett J Baker, Karthik Anantharaman, Christopher T Brown, Alexander J Probst, Cindy J Castelle, Cristina N Butterfield, Alex W Hernsdorf, Yuki Amano, Kotaro Ise, et al. A new view of the tree of life. Nature Microbiology, 1(5):16048, 2016.\n\nGraph warp module: An auxiliary module for boosting the power of graph neural networks. Katsuhiko Ishiguro, Masanori Shin-Ichi Maeda, Koyama, arXiv:1902.01020arXiv preprintKatsuhiko Ishiguro, Shin-ichi Maeda, and Masanori Koyama. Graph warp module: An auxiliary module for boosting the power of graph neural networks. arXiv preprint arXiv:1902.01020, 2019.\n\nUnderstanding isomorphism bias in graph data sets. S Ivanov, S Sviridov, E Burnaev, arXiv:1910.12091arXiv preprintS. Ivanov, S. Sviridov, and E. Burnaev. Understanding isomorphism bias in graph data sets. arXiv preprint arXiv:1910.12091, 2019.\n\nHierarchical generation of molecular graphs using structural motifs. Wengong Jin, Regina Barzilay, Tommi Jaakkola, arXiv:2002.03230arXiv preprintWengong Jin, Regina Barzilay, and Tommi Jaakkola. Hierarchical generation of molecular graphs using structural motifs. arXiv preprint arXiv:2002.03230, 2020.\n\nBenchmark data sets for graph kernels. Kristian Kersting, M Nils, Christopher Kriege, Petra Morris, Marion Mutzel, Neumann, Kristian Kersting, Nils M Kriege, Christopher Morris, Petra Mutzel, and Marion Neumann. Bench- mark data sets for graph kernels, 2016. URL http://graphkernels. cs. tu-dortmund. de, 2016.\n\nVariational graph auto-encoders. N Thomas, Max Kipf, Welling, arXiv:1611.07308arXiv preprintThomas N. Kipf and Max Welling. Variational graph auto-encoders. arXiv preprint arXiv:1611.07308, 2016.\n\nSemi-supervised classification with graph convolutional networks. N Thomas, Max Kipf, Welling, International Conference on Learning Representations (ICLR. Thomas N. Kipf and Max Welling. Semi-supervised classification with graph convolutional networks. In International Conference on Learning Representations (ICLR), 2017.\n\nKunal Dahiya. The extreme classification repository: Multi-label datasets and code. Himanshu Jain Anshul Mittal Yashoteja Prabhu Manik Varma Kush BhatiaHimanshu Jain Anshul Mittal Yashoteja Prabhu Manik Varma Kush Bhatia, Kunal Dahiya. The extreme classification repository: Multi-label datasets and code, 2016. URL http: //manikvarma.org/downloads/XC/XMLRepository.html.\n\nGreg Landrum, Open-source cheminformatics. Greg Landrum et al. Rdkit: Open-source cheminformatics, 2006.\n\nPytorch-biggraph: A large-scale graph embedding system. Adam Lerer, Ledell Wu, Jiajun Shen, Timothee Lacroix, Luca Wehrstedt, Abhijit Bose, Alex Peysakhovich, arXiv:1903.12287arXiv preprintAdam Lerer, Ledell Wu, Jiajun Shen, Timothee Lacroix, Luca Wehrstedt, Abhijit Bose, and Alex Peysakhovich. Pytorch-biggraph: A large-scale graph embedding system. arXiv preprint arXiv:1903.12287, 2019.\n\nSnap: A general-purpose network analysis and graph-mining library. Jure Leskovec, Rok Sosi\u010d, ACM Transactions on Intelligent Systems and Technology (TIST). 81Jure Leskovec and Rok Sosi\u010d. Snap: A general-purpose network analysis and graph-mining library. ACM Transactions on Intelligent Systems and Technology (TIST), 8(1):1-20, 2016.\n\nLearning graph-level representation for drug discovery. Junying Li, Deng Cai, Xiaofei He, arXiv:1709.03741arXiv preprintJunying Li, Deng Cai, and Xiaofei He. Learning graph-level representation for drug discovery. arXiv preprint arXiv:1709.03741, 2017.\n\nThe link-prediction problem for social networks. David Liben, - Nowell, Jon M Kleinberg, Journal of the Association for Information Science and Technology. 587David Liben-Nowell and Jon M. Kleinberg. The link-prediction problem for social networks. Journal of the Association for Information Science and Technology, 58(7):1019-1031, 2007.\n\nMicrosoft coco: Common objects in context. Tsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll\u00e1r, C Lawrence Zitnick, eccv. SpringerTsung-Yi Lin, Michael Maire, Serge Belongie, James Hays, Pietro Perona, Deva Ramanan, Piotr Doll\u00e1r, and C Lawrence Zitnick. Microsoft coco: Common objects in context. In eccv, pp. 740-755. Springer, 2014.\n\nSampling: design and analysis. L Sharon, Lohr, Sharon L Lohr. Sampling: design and analysis. Nelson Education, 2009.\n\nImpact of high-throughput screening in biomedical research. Ricardo Macarron, Martyn N Banks, Dejan Bojanic, J David, Burns, A Dragan, Tina Cirovic, Garyantes, V S Darren, Green, P Robert, Hertzberg, P William, Jeff W Janzen, Paslay, Nature Reviews Drug discovery. 103Ricardo Macarron, Martyn N Banks, Dejan Bojanic, David J Burns, Dragan A Cirovic, Tina Garyantes, Darren VS Green, Robert P Hertzberg, William P Janzen, Jeff W Paslay, et al. Impact of high-throughput screening in biomedical research. Nature Reviews Drug discovery, 10(3):188-195, 2011.\n\nUnified alignment of protein-protein interaction networks. No\u00ebl Malod-Dognin, Kristina Ban, Nata\u0161a Pr\u017eulj, Scientific Reports. 71No\u00ebl Malod-Dognin, Kristina Ban, and Nata\u0161a Pr\u017eulj. Unified alignment of protein-protein interaction networks. Scientific Reports, 7(1):1-11, 2017.\n\nDistributed representations of words and phrases and their compositionality. Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, Jeff Dean, Advances in Neural Information Processing Systems (NIPS). Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. Distributed representations of words and phrases and their compositionality. In Advances in Neural Information Processing Systems (NIPS), pp. 3111-3119, 2013.\n\nA review of relational machine learning for knowledge graphs. Maximilian Nickel, Kevin Murphy, Volker Tresp, Evgeniy Gabrilovich, Proceedings of the IEEE. 1041Maximilian Nickel, Kevin Murphy, Volker Tresp, and Evgeniy Gabrilovich. A review of relational machine learning for knowledge graphs. Proceedings of the IEEE, 104(1):11-33, 2015.\n\nLibrispeech: an asr corpus based on public domain audio books. Vassil Panayotov, Guoguo Chen, Daniel Povey, Sanjeev Khudanpur, 2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). IEEEVassil Panayotov, Guoguo Chen, Daniel Povey, and Sanjeev Khudanpur. Librispeech: an asr corpus based on public domain audio books. In 2015 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp. 5206-5210. IEEE, 2015.\n\nPyTorch: An imperative style, high-performance deep learning library. Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Advances in Neural Information Processing Systems (NIPS). Adam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor Killeen, Zeming Lin, Natalia Gimelshein, Luca Antiga, et al. PyTorch: An imperative style, high-performance deep learning library. In Advances in Neural Information Processing Systems (NIPS), pp. 8024-8035, 2019.\n\nDeepwalk: Online learning of social representations. Bryan Perozzi, Rami Al-Rfou, Steven Skiena, ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD). ACMBryan Perozzi, Rami Al-Rfou, and Steven Skiena. Deepwalk: Online learning of social represen- tations. In ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD), pp. 701-710. ACM, 2014.\n\nNetsmf: Large-scale network embedding as sparse matrix factorization. Jiezhong Qiu, Yuxiao Dong, Hao Ma, Jian Li, Chi Wang, Kuansan Wang, Jie Tang, Proceedings of the International World Wide Web Conference (WWW). the International World Wide Web Conference (WWW)Jiezhong Qiu, Yuxiao Dong, Hao Ma, Jian Li, Chi Wang, Kuansan Wang, and Jie Tang. Netsmf: Large-scale network embedding as sparse matrix factorization. In Proceedings of the International World Wide Web Conference (WWW), pp. 1509-1520, 2019.\n\nSquad: 100,000+ questions for machine comprehension of text. Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, Percy Liang, arXiv:1606.05250arXiv preprintPranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. Squad: 100,000+ questions for machine comprehension of text. arXiv preprint arXiv:1606.05250, 2016.\n\nConserved patterns of protein interaction in multiple species. Roded Sharan, Silpa Suthram, M Ryan, Tanja Kelley, Scott Kuhn, Peter Mccuine, Taylor Uetz, Sittler, M Richard, Trey Karp, Ideker, Proceedings of the National Academy of Sciences. 1026Roded Sharan, Silpa Suthram, Ryan M Kelley, Tanja Kuhn, Scott McCuine, Peter Uetz, Taylor Sittler, Richard M Karp, and Trey Ideker. Conserved patterns of protein interaction in multiple species. Proceedings of the National Academy of Sciences, 102(6):1974-1979, 2005.\n\nPitfalls of graph neural network evaluation. Oleksandr Shchur, Maximilian Mumme, Aleksandar Bojchevski, Stephan G\u00fcnnemann, arXiv:1811.05868arXiv preprintOleksandr Shchur, Maximilian Mumme, Aleksandar Bojchevski, and Stephan G\u00fcnnemann. Pitfalls of graph neural network evaluation. arXiv preprint arXiv:1811.05868, 2018.\n\nDynamic edge-conditioned filters in convolutional neural networks on graphs. Martin Simonovsky, Nikos Komodakis, IEEE Conference on Computer Vision and Pattern Recognition (CVPR). Martin Simonovsky and Nikos Komodakis. Dynamic edge-conditioned filters in convolutional neural networks on graphs. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), pp. 3693-3702, 2017.\n\nRotate: Knowledge graph embedding by relational rotation in complex space. Zhiqing Sun, Zhi-Hong Deng, Jian-Yun Nie, Jian Tang, International Conference on Learning Representations (ICLR). Zhiqing Sun, Zhi-Hong Deng, Jian-Yun Nie, and Jian Tang. Rotate: Knowledge graph embedding by relational rotation in complex space. In International Conference on Learning Representations (ICLR), 2019.\n\nSTRING v11: protein-protein association networks with increased coverage, supporting functional discovery in genome-wide experimental datasets. Damian Szklarczyk, Annika L Gable, David Lyon, Alexander Junge, Stefan Wyder, Jaime Huerta-Cepas, Milan Simonovic, T Nadezhda, Doncheva, H John, Peer Morris, Bork, Nucleic Acids Research. 47D1Damian Szklarczyk, Annika L Gable, David Lyon, Alexander Junge, Stefan Wyder, Jaime Huerta- Cepas, Milan Simonovic, Nadezhda T Doncheva, John H Morris, Peer Bork, et al. STRING v11: protein-protein association networks with increased coverage, supporting functional discovery in genome-wide experimental datasets. Nucleic Acids Research, 47(D1):D607-D613, 2019.\n\nComplex embeddings for simple link prediction. Th\u00e9o Trouillon, Johannes Welbl, Sebastian Riedel, \u00c9ric Gaussier, Guillaume Bouchard, International Conference on Machine Learning (ICML). Th\u00e9o Trouillon, Johannes Welbl, Sebastian Riedel, \u00c9ric Gaussier, and Guillaume Bouchard. Complex embeddings for simple link prediction. In International Conference on Machine Learning (ICML), pp. 2071-2080, 2016.\n\nDeep graph infomax. Petar Veli\u010dkovi\u0107, William Fedus, L William, Pietro Hamilton, Yoshua Li\u00f2, R Devon Bengio, Hjelm, International Conference on Learning Representations (ICLR). Petar Veli\u010dkovi\u0107, William Fedus, William L Hamilton, Pietro Li\u00f2, Yoshua Bengio, and R Devon Hjelm. Deep graph infomax. In International Conference on Learning Representations (ICLR), 2019.\n\nWikidata: a free collaborative knowledgebase. Denny Vrande\u010di\u0107, Markus Kr\u00f6tzsch, Communications of the ACM. 5710Denny Vrande\u010di\u0107 and Markus Kr\u00f6tzsch. Wikidata: a free collaborative knowledgebase. Communica- tions of the ACM, 57(10):78-85, 2014.\n\nAlex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, Samuel R Bowman, arXiv:1804.07461Glue: A multi-task benchmark and analysis platform for natural language understanding. arXiv preprintAlex Wang, Amanpreet Singh, Julian Michael, Felix Hill, Omer Levy, and Samuel R Bowman. Glue: A multi-task benchmark and analysis platform for natural language understanding. arXiv preprint arXiv:1804.07461, 2018.\n\nMicrosoft academic graph: When experts are not enough. Kuansan Wang, Zhihong Shen, Chiyuan Huang, Chieh-Han Wu, Yuxiao Dong, Anshul Kanakia, Quantitative Science Studies. 11Kuansan Wang, Zhihong Shen, Chiyuan Huang, Chieh-Han Wu, Yuxiao Dong, and Anshul Kanakia. Microsoft academic graph: When experts are not enough. Quantitative Science Studies, 1(1): 396-413, 2020.\n\nDeep graph library: Towards efficient and scalable deep learning on graphs. Minjie Wang, Lingfan Yu, Da Zheng, Quan Gan, Yu Gai, Zihao Ye, Mufei Li, Jinjing Zhou, Qi Huang, Chao Ma, Ziyue Huang, Qipeng Guo, Hao Zhang, Haibin Lin, Junbo Zhao, Jinyang Li, Alexander J Smola, Zheng Zhang, Workshop on Representation Learning on Graphs and Manifolds. Minjie Wang, Lingfan Yu, Da Zheng, Quan Gan, Yu Gai, Zihao Ye, Mufei Li, Jinjing Zhou, Qi Huang, Chao Ma, Ziyue Huang, Qipeng Guo, Hao Zhang, Haibin Lin, Junbo Zhao, Jinyang Li, Alexander J Smola, and Zheng Zhang. Deep graph library: Towards efficient and scalable deep learning on graphs. ICLR Workshop on Representation Learning on Graphs and Manifolds, 2019a. URL https://arxiv.org/abs/1909.01315.\n\nKepler: A unified model for knowledge embedding and pre-trained language representation. Xiaozhi Wang, Tianyu Gao, Zhaocheng Zhu, Zhiyuan Liu, Juanzi Li, Jian Tang, arXiv:1911.06136arXiv preprintXiaozhi Wang, Tianyu Gao, Zhaocheng Zhu, Zhiyuan Liu, Juanzi Li, and Jian Tang. Kepler: A unified model for knowledge embedding and pre-trained language representation. arXiv preprint arXiv:1911.06136, 2019b.\n\nMoleculenet: a benchmark for molecular machine learning. Zhenqin Wu, Bharath Ramsundar, Evan N Feinberg, Joseph Gomes, Caleb Geniesse, S Aneesh, Karl Pappu, Vijay Leswing, Pande, Chemical science. 92Zhenqin Wu, Bharath Ramsundar, Evan N Feinberg, Joseph Gomes, Caleb Geniesse, Aneesh S Pappu, Karl Leswing, and Vijay Pande. Moleculenet: a benchmark for molecular machine learning. Chemical science, 9(2):513-530, 2018.\n\nHow powerful are graph neural networks?. Keyulu Xu, Weihua Hu, Jure Leskovec, Stefanie Jegelka, International Conference on Learning Representations (ICLR). Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. How powerful are graph neural networks? In International Conference on Learning Representations (ICLR), 2019.\n\nDeep graph kernels. Pinar Yanardag, Vishwanathan, ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD). ACMPinar Yanardag and SVN Vishwanathan. Deep graph kernels. In ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD), pp. 1365-1374. ACM, 2015.\n\nEmbedding entities and relations for learning and inference in knowledge bases. Bishan Yang, Wen-Tau Yih, Xiaodong He, Jianfeng Gao, Li Deng, International Conference on Learning Representations (ICLR). Bishan Yang, Wen-tau Yih, Xiaodong He, Jianfeng Gao, and Li Deng. Embedding entities and relations for learning and inference in knowledge bases. In International Conference on Learning Representations (ICLR), 2015.\n\nAnalyzing learned molecular representations for property prediction. Kevin Yang, Kyle Swanson, Wengong Jin, Connor Coley, Philipp Eiden, Hua Gao, Angel Guzman-Perez, Timothy Hopper, Brian Kelley, Miriam Mathea, Journal of chemical information and modeling. 598Kevin Yang, Kyle Swanson, Wengong Jin, Connor Coley, Philipp Eiden, Hua Gao, Angel Guzman- Perez, Timothy Hopper, Brian Kelley, Miriam Mathea, et al. Analyzing learned molecular representations for property prediction. Journal of chemical information and modeling, 59(8): 3370-3388, 2019.\n\nRevisiting semi-supervised learning with graph embeddings. Zhilin Yang, W William, Ruslan Cohen, Salakhutdinov, International Conference on Machine Learning (ICML). Zhilin Yang, William W Cohen, and Ruslan Salakhutdinov. Revisiting semi-supervised learning with graph embeddings. In International Conference on Machine Learning (ICML), pp. 40-48, 2016.\n\nHierarchical graph representation learning with differentiable pooling. Rex Ying, Jiaxuan You, Christopher Morris, Xiang Ren, L William, Jure Hamilton, Leskovec, Advances in Neural Information Processing Systems (NIPS). Rex Ying, Jiaxuan You, Christopher Morris, Xiang Ren, William L Hamilton, and Jure Leskovec. Hierarchical graph representation learning with differentiable pooling. In Advances in Neural Information Processing Systems (NIPS), 2018.\n\nPosition-aware graph neural networks. Jiaxuan You, Rex Ying, Jure Leskovec, International Conference on Machine Learning (ICML). Jiaxuan You, Rex Ying, and Jure Leskovec. Position-aware graph neural networks. In International Conference on Machine Learning (ICML), 2019.\n\nHigh-throughput characterization of protein-protein interactions by reprogramming yeast mating. David Younger, Stephanie Berger, David Baker, Eric Klavins, Proceedings of the National Academy of Sciences. 11446David Younger, Stephanie Berger, David Baker, and Eric Klavins. High-throughput characterization of protein-protein interactions by reprogramming yeast mating. Proceedings of the National Academy of Sciences, 114(46):12166-12171, 2017.\n\nGraph-Saint: Graph sampling based inductive learning method. Hanqing Zeng, Hongkuan Zhou, Ajitesh Srivastava, Rajgopal Kannan, Viktor Prasanna, International Conference on Learning Representations (ICLR). 2020Hanqing Zeng, Hongkuan Zhou, Ajitesh Srivastava, Rajgopal Kannan, and Viktor Prasanna. Graph- Saint: Graph sampling based inductive learning method. In International Conference on Learning Representations (ICLR), 2020.\n\nLink prediction based on graph neural networks. Muhan Zhang, Yixin Chen, Advances in Neural Information Processing Systems (NIPS). Muhan Zhang and Yixin Chen. Link prediction based on graph neural networks. In Advances in Neural Information Processing Systems (NIPS), pp. 5165-5175, 2018.\n\nDa Zheng, Xiang Song, Chao Ma, Zeyuan Tan, Zihao Ye, Jin Dong, Hao Xiong, Zheng Zhang, George Karypis, arXiv:2004.08532Dgl-ke: Training knowledge graph embeddings at scale. arXiv preprintDa Zheng, Xiang Song, Chao Ma, Zeyuan Tan, Zihao Ye, Jin Dong, Hao Xiong, Zheng Zhang, and George Karypis. Dgl-ke: Training knowledge graph embeddings at scale. arXiv preprint arXiv:2004.08532, 2020.\n\nGraphvite: A high-performance cpugpu hybrid system for node embedding. Zhaocheng Zhu, Shizhen Xu, Jian Tang, Meng Qu, Proceedings of the International World Wide Web Conference (WWW). the International World Wide Web Conference (WWW)Zhaocheng Zhu, Shizhen Xu, Jian Tang, and Meng Qu. Graphvite: A high-performance cpu- gpu hybrid system for node embedding. In Proceedings of the International World Wide Web Conference (WWW), pp. 2494-2504, 2019.\n\nEvolution of resilience in protein interactomes across the tree of life. Marinka Zitnik, W Marcus, Jure Feldman, Leskovec, Proceedings of the National Academy of Sciences. the National Academy of Sciences116Marinka Zitnik, Marcus W Feldman, Jure Leskovec, et al. Evolution of resilience in protein interactomes across the tree of life. Proceedings of the National Academy of Sciences, 116(10): 4426-4433, 2019.\n\nDimensional reweighting graph convolution networks. Xu Zou, Qiuye Jia, Jianwei Zhang, Chang Zhou, Zijun Yao, Hongxia Yang, Jie Tang, Xu Zou, Qiuye Jia, Jianwei Zhang, Chang Zhou, Zijun Yao, Hongxia Yang, and Jie Tang. Dimensional reweighting graph convolution networks, 2020. URL https://openreview.net/forum? id=SJeLO34KwS.\n", "annotations": {"author": "[{\"end\":158,\"start\":84},{\"end\":229,\"start\":159},{\"end\":303,\"start\":230},{\"end\":344,\"start\":304},{\"end\":420,\"start\":345},{\"end\":431,\"start\":421},{\"end\":512,\"start\":432},{\"end\":591,\"start\":513},{\"end\":608,\"start\":592},{\"end\":625,\"start\":609},{\"end\":640,\"start\":626},{\"end\":659,\"start\":641},{\"end\":678,\"start\":660},{\"end\":693,\"start\":679},{\"end\":709,\"start\":694},{\"end\":727,\"start\":710},{\"end\":746,\"start\":728},{\"end\":756,\"start\":747},{\"end\":765,\"start\":757},{\"end\":776,\"start\":766},{\"end\":789,\"start\":777},{\"end\":801,\"start\":790}]", "publisher": null, "author_last_name": "[{\"end\":93,\"start\":91},{\"end\":171,\"start\":168},{\"end\":244,\"start\":238},{\"end\":315,\"start\":311},{\"end\":355,\"start\":352},{\"end\":430,\"start\":427},{\"end\":447,\"start\":440},{\"end\":526,\"start\":518},{\"end\":607,\"start\":599},{\"end\":624,\"start\":615},{\"end\":639,\"start\":633},{\"end\":658,\"start\":649},{\"end\":677,\"start\":668},{\"end\":692,\"start\":684},{\"end\":708,\"start\":700},{\"end\":726,\"start\":719},{\"end\":745,\"start\":739},{\"end\":755,\"start\":753},{\"end\":764,\"start\":760},{\"end\":775,\"start\":771},{\"end\":788,\"start\":781},{\"end\":800,\"start\":795}]", "author_first_name": "[{\"end\":90,\"start\":84},{\"end\":167,\"start\":159},{\"end\":237,\"start\":230},{\"end\":310,\"start\":304},{\"end\":351,\"start\":345},{\"end\":426,\"start\":421},{\"end\":439,\"start\":432},{\"end\":517,\"start\":513},{\"end\":598,\"start\":592},{\"end\":614,\"start\":609},{\"end\":632,\"start\":626},{\"end\":648,\"start\":641},{\"end\":667,\"start\":660},{\"end\":683,\"start\":679},{\"end\":699,\"start\":694},{\"end\":718,\"start\":710},{\"end\":738,\"start\":728},{\"end\":752,\"start\":747},{\"end\":759,\"start\":757},{\"end\":770,\"start\":766},{\"end\":780,\"start\":777},{\"end\":794,\"start\":790}]", "author_affiliation": "[{\"end\":157,\"start\":95},{\"end\":228,\"start\":173},{\"end\":302,\"start\":246},{\"end\":343,\"start\":317},{\"end\":419,\"start\":357},{\"end\":511,\"start\":449},{\"end\":590,\"start\":528}]", "title": "[{\"end\":81,\"start\":1},{\"end\":882,\"start\":802}]", "venue": null, "abstract": "[{\"end\":1905,\"start\":884}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b17\"},\"end\":2045,\"start\":2024},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":2085,\"start\":2064},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":2121,\"start\":2104},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":2172,\"start\":2147},{\"attributes\":{\"ref_id\":\"b52\"},\"end\":2239,\"start\":2209},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":2275,\"start\":2251},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2317,\"start\":2293},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":2423,\"start\":2399},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":2446,\"start\":2423},{\"attributes\":{\"ref_id\":\"b68\"},\"end\":2512,\"start\":2494},{\"attributes\":{\"ref_id\":\"b56\"},\"end\":2536,\"start\":2512},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":2842,\"start\":2823},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":2873,\"start\":2855},{\"attributes\":{\"ref_id\":\"b58\"},\"end\":2928,\"start\":2909},{\"attributes\":{\"ref_id\":\"b49\"},\"end\":2963,\"start\":2939},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":3036,\"start\":3012},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":3068,\"start\":3047},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":3349,\"start\":3330},{\"attributes\":{\"ref_id\":\"b64\"},\"end\":3402,\"start\":3371},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":3424,\"start\":3402},{\"attributes\":{\"ref_id\":\"b76\"},\"end\":3660,\"start\":3642},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":3846,\"start\":3825},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":3867,\"start\":3846},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":4068,\"start\":4047},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":4192,\"start\":4172},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":4337,\"start\":4326},{\"end\":4926,\"start\":4907},{\"attributes\":{\"ref_id\":\"b46\"},\"end\":5196,\"start\":5175},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":5274,\"start\":5253},{\"attributes\":{\"ref_id\":\"b60\"},\"end\":5320,\"start\":5300},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":9124,\"start\":9106},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":9444,\"start\":9423},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":9561,\"start\":9539},{\"attributes\":{\"ref_id\":\"b51\"},\"end\":9777,\"start\":9756},{\"attributes\":{\"ref_id\":\"b76\"},\"end\":9821,\"start\":9803},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":10273,\"start\":10249},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":10326,\"start\":10305},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":10782,\"start\":10761},{\"end\":10800,\"start\":10782},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":11269,\"start\":11237},{\"attributes\":{\"ref_id\":\"b72\"},\"end\":11288,\"start\":11269},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":11370,\"start\":11349},{\"end\":11387,\"start\":11370},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":11702,\"start\":11683},{\"attributes\":{\"ref_id\":\"b48\"},\"end\":11878,\"start\":11860},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":12083,\"start\":12062},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":12107,\"start\":12083},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":12526,\"start\":12501},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":12718,\"start\":12695},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":12738,\"start\":12718},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":12755,\"start\":12738},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":12913,\"start\":12891},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":13156,\"start\":13135},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":13202,\"start\":13180},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":13528,\"start\":13510},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":13550,\"start\":13528},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":13601,\"start\":13584},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":16629,\"start\":16605},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":17498,\"start\":17480},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":17602,\"start\":17578},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":18470,\"start\":18445},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":18491,\"start\":18470},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":18515,\"start\":18494},{\"end\":18692,\"start\":18673},{\"end\":19817,\"start\":19798},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":19972,\"start\":19952},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":20508,\"start\":20488},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":22491,\"start\":22472},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":22817,\"start\":22795},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":23258,\"start\":23239},{\"attributes\":{\"ref_id\":\"b67\"},\"end\":23556,\"start\":23537},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":25510,\"start\":25485},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":25527,\"start\":25510},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":28384,\"start\":28360},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":28470,\"start\":28452},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":28552,\"start\":28533},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":28646,\"start\":28618},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":30785,\"start\":30765},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":31110,\"start\":31093},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":31539,\"start\":31514},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":32753,\"start\":32730},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":32768,\"start\":32753},{\"attributes\":{\"ref_id\":\"b70\"},\"end\":32789,\"start\":32768},{\"attributes\":{\"ref_id\":\"b69\"},\"end\":33848,\"start\":33830},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":34627,\"start\":34608},{\"attributes\":{\"ref_id\":\"b59\"},\"end\":37152,\"start\":37133},{\"attributes\":{\"ref_id\":\"b57\"},\"end\":40143,\"start\":40115},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":40638,\"start\":40617},{\"attributes\":{\"ref_id\":\"b65\"},\"end\":40656,\"start\":40638},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":40679,\"start\":40656},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":40696,\"start\":40679},{\"attributes\":{\"ref_id\":\"b61\"},\"end\":41277,\"start\":41257},{\"attributes\":{\"ref_id\":\"b73\"},\"end\":42870,\"start\":42850},{\"attributes\":{\"ref_id\":\"b74\"},\"end\":42887,\"start\":42870},{\"end\":43505,\"start\":43503},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":43749,\"start\":43728},{\"end\":43753,\"start\":43751},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":44146,\"start\":44128},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":44407,\"start\":44390},{\"attributes\":{\"ref_id\":\"b75\"},\"end\":44511,\"start\":44490},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":45466,\"start\":45444},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":45664,\"start\":45643},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":45680,\"start\":45664},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":45702,\"start\":45680},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":45890,\"start\":45873},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":46328,\"start\":46311},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":46455,\"start\":46433},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":47401,\"start\":47385},{\"attributes\":{\"ref_id\":\"b62\"},\"end\":48040,\"start\":48023},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":48659,\"start\":48641},{\"attributes\":{\"ref_id\":\"b54\"},\"end\":49775,\"start\":49751},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":49905,\"start\":49887},{\"attributes\":{\"ref_id\":\"b75\"},\"end\":50110,\"start\":50089},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":50996,\"start\":50974},{\"attributes\":{\"ref_id\":\"b50\"},\"end\":51066,\"start\":51045},{\"attributes\":{\"ref_id\":\"b75\"},\"end\":51086,\"start\":51066},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":51207,\"start\":51187},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":51331,\"start\":51304},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":52920,\"start\":52900},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":56927,\"start\":56902},{\"attributes\":{\"ref_id\":\"b47\"},\"end\":56948,\"start\":56927},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":57497,\"start\":57476},{\"attributes\":{\"ref_id\":\"b65\"},\"end\":57799,\"start\":57781},{\"attributes\":{\"ref_id\":\"b55\"},\"end\":57891,\"start\":57868},{\"attributes\":{\"ref_id\":\"b53\"},\"end\":57956,\"start\":57939}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":56407,\"start\":56316},{\"attributes\":{\"id\":\"fig_1\"},\"end\":56706,\"start\":56408},{\"attributes\":{\"id\":\"fig_2\"},\"end\":56791,\"start\":56707},{\"attributes\":{\"id\":\"fig_3\"},\"end\":57724,\"start\":56792},{\"attributes\":{\"id\":\"fig_4\"},\"end\":57957,\"start\":57725},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":58356,\"start\":57958},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":58949,\"start\":58357},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":59862,\"start\":58950},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":60274,\"start\":59863},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":60782,\"start\":60275},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":61088,\"start\":60783},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":61396,\"start\":61089},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":61954,\"start\":61397},{\"attributes\":{\"id\":\"tab_9\",\"type\":\"table\"},\"end\":62980,\"start\":61955},{\"attributes\":{\"id\":\"tab_10\",\"type\":\"table\"},\"end\":63351,\"start\":62981},{\"attributes\":{\"id\":\"tab_11\",\"type\":\"table\"},\"end\":63723,\"start\":63352},{\"attributes\":{\"id\":\"tab_12\",\"type\":\"table\"},\"end\":63973,\"start\":63724}]", "paragraph": "[{\"end\":2640,\"start\":1921},{\"end\":3229,\"start\":2642},{\"end\":4339,\"start\":3231},{\"end\":5752,\"start\":4353},{\"end\":6355,\"start\":5754},{\"end\":7035,\"start\":6357},{\"end\":7432,\"start\":7037},{\"end\":7547,\"start\":7434},{\"end\":8270,\"start\":7549},{\"end\":8757,\"start\":8272},{\"end\":9010,\"start\":8796},{\"end\":10125,\"start\":9012},{\"end\":11104,\"start\":10127},{\"end\":12527,\"start\":11106},{\"end\":14334,\"start\":12529},{\"end\":14839,\"start\":14352},{\"end\":17108,\"start\":14841},{\"end\":17622,\"start\":17141},{\"end\":18097,\"start\":17624},{\"end\":18202,\"start\":18099},{\"end\":18742,\"start\":18204},{\"end\":19623,\"start\":18744},{\"end\":20370,\"start\":19680},{\"end\":21123,\"start\":20372},{\"end\":22293,\"start\":21125},{\"end\":22940,\"start\":22332},{\"end\":23042,\"start\":22942},{\"end\":23432,\"start\":23044},{\"end\":24047,\"start\":23434},{\"end\":25162,\"start\":24049},{\"end\":26033,\"start\":25217},{\"end\":26271,\"start\":26035},{\"end\":26522,\"start\":26273},{\"end\":26913,\"start\":26524},{\"end\":27512,\"start\":26915},{\"end\":28128,\"start\":27514},{\"end\":28665,\"start\":28161},{\"end\":29206,\"start\":28667},{\"end\":29900,\"start\":29392},{\"end\":30713,\"start\":29902},{\"end\":31204,\"start\":30715},{\"end\":32426,\"start\":31254},{\"end\":33345,\"start\":32428},{\"end\":34432,\"start\":33347},{\"end\":35678,\"start\":34478},{\"end\":35951,\"start\":35680},{\"end\":36964,\"start\":35953},{\"end\":38073,\"start\":37006},{\"end\":38724,\"start\":38075},{\"end\":39980,\"start\":38726},{\"end\":41051,\"start\":40022},{\"end\":41322,\"start\":41053},{\"end\":41561,\"start\":41324},{\"end\":43056,\"start\":41563},{\"end\":44147,\"start\":43058},{\"end\":44530,\"start\":44181},{\"end\":45118,\"start\":44532},{\"end\":45406,\"start\":45120},{\"end\":45467,\"start\":45408},{\"end\":45738,\"start\":45469},{\"end\":45835,\"start\":45740},{\"end\":46083,\"start\":45837},{\"end\":47121,\"start\":46117},{\"end\":47680,\"start\":47123},{\"end\":48041,\"start\":47682},{\"end\":49540,\"start\":48043},{\"end\":50667,\"start\":49590},{\"end\":51825,\"start\":50669},{\"end\":52476,\"start\":51827},{\"end\":53216,\"start\":52492},{\"end\":53676,\"start\":53237},{\"end\":54004,\"start\":53678},{\"end\":54037,\"start\":54006},{\"end\":54787,\"start\":54056},{\"end\":55179,\"start\":54789},{\"end\":55210,\"start\":55181},{\"end\":55808,\"start\":55242},{\"end\":56040,\"start\":55810},{\"end\":56315,\"start\":56042}]", "formula": null, "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":6487,\"start\":6480},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":7492,\"start\":7485},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":8538,\"start\":8531},{\"end\":15100,\"start\":15093},{\"end\":15432,\"start\":15424},{\"end\":16013,\"start\":16006},{\"end\":16413,\"start\":16406},{\"end\":17702,\"start\":17695},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":21189,\"start\":21182},{\"end\":24114,\"start\":24107},{\"end\":26565,\"start\":26558},{\"end\":27392,\"start\":27385},{\"end\":28754,\"start\":28747},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":33412,\"start\":33405},{\"attributes\":{\"ref_id\":\"tab_7\"},\"end\":36018,\"start\":36011},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":38791,\"start\":38784},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":39352,\"start\":39345},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":41382,\"start\":41374},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":41608,\"start\":41600},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":41882,\"start\":41874},{\"end\":44619,\"start\":44612},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":48105,\"start\":48089},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":51881,\"start\":51873},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":55874,\"start\":55867}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1919,\"start\":1907},{\"end\":4351,\"start\":4342},{\"attributes\":{\"n\":\"2\"},\"end\":8794,\"start\":8760},{\"attributes\":{\"n\":\"3\"},\"end\":14350,\"start\":14337},{\"attributes\":{\"n\":\"4\"},\"end\":17139,\"start\":17111},{\"attributes\":{\"n\":\"4.1\"},\"end\":19678,\"start\":19626},{\"attributes\":{\"n\":\"4.2\"},\"end\":22330,\"start\":22296},{\"attributes\":{\"n\":\"4.3\"},\"end\":25215,\"start\":25165},{\"attributes\":{\"n\":\"5\"},\"end\":28159,\"start\":28131},{\"end\":29390,\"start\":29209},{\"attributes\":{\"n\":\"5.1\"},\"end\":31252,\"start\":31207},{\"attributes\":{\"n\":\"5.2\"},\"end\":34476,\"start\":34435},{\"attributes\":{\"n\":\"5.3\"},\"end\":37004,\"start\":36967},{\"attributes\":{\"n\":\"5.4\"},\"end\":40020,\"start\":39983},{\"attributes\":{\"n\":\"6\"},\"end\":44179,\"start\":44150},{\"attributes\":{\"n\":\"6.1\"},\"end\":46115,\"start\":46086},{\"attributes\":{\"n\":\"6.2\"},\"end\":49588,\"start\":49543},{\"attributes\":{\"n\":\"7\"},\"end\":52490,\"start\":52479},{\"attributes\":{\"n\":\"7.1\"},\"end\":53235,\"start\":53219},{\"attributes\":{\"n\":\"7.2\"},\"end\":54054,\"start\":54040},{\"attributes\":{\"n\":\"8\"},\"end\":55240,\"start\":55213},{\"end\":56327,\"start\":56317},{\"end\":56718,\"start\":56708},{\"end\":56805,\"start\":56793},{\"end\":58367,\"start\":58358},{\"end\":59873,\"start\":59864},{\"end\":60294,\"start\":60276},{\"end\":60793,\"start\":60784},{\"end\":61099,\"start\":61090},{\"end\":61407,\"start\":61398},{\"end\":61966,\"start\":61956},{\"end\":62992,\"start\":62982},{\"end\":63363,\"start\":63353},{\"end\":63735,\"start\":63725}]", "table": "[{\"end\":58356,\"start\":58235},{\"end\":58949,\"start\":58613},{\"end\":59862,\"start\":59217},{\"end\":60274,\"start\":60072},{\"end\":60782,\"start\":60347},{\"end\":61088,\"start\":60816},{\"end\":61396,\"start\":61125},{\"end\":61954,\"start\":61528},{\"end\":62980,\"start\":62079},{\"end\":63351,\"start\":63019},{\"end\":63723,\"start\":63461},{\"end\":63973,\"start\":63907}]", "figure_caption": "[{\"end\":56407,\"start\":56329},{\"end\":56706,\"start\":56410},{\"end\":56791,\"start\":56720},{\"end\":57724,\"start\":56814},{\"end\":57957,\"start\":57727},{\"end\":58235,\"start\":57960},{\"end\":58613,\"start\":58369},{\"end\":59217,\"start\":58952},{\"end\":60072,\"start\":59875},{\"end\":60347,\"start\":60297},{\"end\":60816,\"start\":60795},{\"end\":61125,\"start\":61101},{\"end\":61528,\"start\":61409},{\"end\":62079,\"start\":61969},{\"end\":63019,\"start\":62995},{\"end\":63461,\"start\":63366},{\"end\":63907,\"start\":63738}]", "figure_ref": "[{\"end\":4798,\"start\":4790},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":5676,\"start\":5668},{\"end\":7785,\"start\":7777},{\"end\":16913,\"start\":16905},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":21751,\"start\":21743},{\"end\":52552,\"start\":52544}]", "bib_author_first_name": "[{\"end\":65268,\"start\":65262},{\"end\":65280,\"start\":65276},{\"end\":65296,\"start\":65289},{\"end\":65310,\"start\":65303},{\"end\":65321,\"start\":65317},{\"end\":65336,\"start\":65329},{\"end\":65351,\"start\":65343},{\"end\":65365,\"start\":65359},{\"end\":65384,\"start\":65376},{\"end\":65400,\"start\":65393},{\"end\":65820,\"start\":65811},{\"end\":65836,\"start\":65832},{\"end\":65858,\"start\":65851},{\"end\":66103,\"start\":66097},{\"end\":66352,\"start\":66339},{\"end\":66364,\"start\":66363},{\"end\":66659,\"start\":66656},{\"end\":66674,\"start\":66668},{\"end\":66691,\"start\":66683},{\"end\":66707,\"start\":66701},{\"end\":67068,\"start\":67062},{\"end\":67084,\"start\":67078},{\"end\":67086,\"start\":67085},{\"end\":67096,\"start\":67093},{\"end\":67380,\"start\":67373},{\"end\":67396,\"start\":67389},{\"end\":67413,\"start\":67406},{\"end\":67433,\"start\":67428},{\"end\":67448,\"start\":67442},{\"end\":67809,\"start\":67805},{\"end\":67835,\"start\":67831},{\"end\":67849,\"start\":67843},{\"end\":67863,\"start\":67857},{\"end\":68216,\"start\":68210},{\"end\":68225,\"start\":68223},{\"end\":68236,\"start\":68230},{\"end\":68244,\"start\":68241},{\"end\":68256,\"start\":68250},{\"end\":68269,\"start\":68263},{\"end\":68283,\"start\":68276},{\"end\":68294,\"start\":68290},{\"end\":68306,\"start\":68299},{\"end\":68319,\"start\":68314},{\"end\":68747,\"start\":68740},{\"end\":68764,\"start\":68756},{\"end\":68772,\"start\":68770},{\"end\":68781,\"start\":68777},{\"end\":68790,\"start\":68786},{\"end\":68806,\"start\":68799},{\"end\":69210,\"start\":69206},{\"end\":69470,\"start\":69464},{\"end\":69482,\"start\":69478},{\"end\":69492,\"start\":69491},{\"end\":69508,\"start\":69503},{\"end\":69784,\"start\":69775},{\"end\":69807,\"start\":69800},{\"end\":70052,\"start\":70049},{\"end\":70062,\"start\":70059},{\"end\":70076,\"start\":70069},{\"end\":70091,\"start\":70085},{\"end\":70099,\"start\":70096},{\"end\":70106,\"start\":70104},{\"end\":70385,\"start\":70379},{\"end\":70395,\"start\":70392},{\"end\":70407,\"start\":70400},{\"end\":70421,\"start\":70414},{\"end\":70820,\"start\":70814},{\"end\":70844,\"start\":70839},{\"end\":70862,\"start\":70856},{\"end\":70884,\"start\":70877},{\"end\":70900,\"start\":70896},{\"end\":70915,\"start\":70909},{\"end\":71280,\"start\":71275},{\"end\":71299,\"start\":71298},{\"end\":71317,\"start\":71311},{\"end\":71331,\"start\":71325},{\"end\":71347,\"start\":71341},{\"end\":71607,\"start\":71602},{\"end\":71619,\"start\":71616},{\"end\":71867,\"start\":71859},{\"end\":71881,\"start\":71876},{\"end\":71895,\"start\":71889},{\"end\":71911,\"start\":71904},{\"end\":72186,\"start\":72185},{\"end\":72193,\"start\":72192},{\"end\":72195,\"start\":72194},{\"end\":72484,\"start\":72478},{\"end\":72494,\"start\":72493},{\"end\":72516,\"start\":72515},{\"end\":72531,\"start\":72526},{\"end\":72545,\"start\":72539},{\"end\":72547,\"start\":72546},{\"end\":72883,\"start\":72877},{\"end\":72896,\"start\":72892},{\"end\":73211,\"start\":73208},{\"end\":73236,\"start\":73232},{\"end\":73559,\"start\":73556},{\"end\":73584,\"start\":73580},{\"end\":73856,\"start\":73850},{\"end\":73866,\"start\":73861},{\"end\":73878,\"start\":73872},{\"end\":73893,\"start\":73886},{\"end\":73907,\"start\":73902},{\"end\":73920,\"start\":73915},{\"end\":73932,\"start\":73928},{\"end\":74262,\"start\":74257},{\"end\":74273,\"start\":74267},{\"end\":74287,\"start\":74280},{\"end\":74300,\"start\":74294},{\"end\":74621,\"start\":74620},{\"end\":74635,\"start\":74634},{\"end\":74650,\"start\":74643},{\"end\":74673,\"start\":74672},{\"end\":74696,\"start\":74687},{\"end\":74698,\"start\":74697},{\"end\":74711,\"start\":74706},{\"end\":74713,\"start\":74712},{\"end\":74730,\"start\":74722},{\"end\":74732,\"start\":74731},{\"end\":74747,\"start\":74743},{\"end\":74749,\"start\":74748},{\"end\":74767,\"start\":74763},{\"end\":74785,\"start\":74779},{\"end\":75177,\"start\":75168},{\"end\":75196,\"start\":75188},{\"end\":75490,\"start\":75489},{\"end\":75500,\"start\":75499},{\"end\":75512,\"start\":75511},{\"end\":75759,\"start\":75752},{\"end\":75771,\"start\":75765},{\"end\":75787,\"start\":75782},{\"end\":76034,\"start\":76026},{\"end\":76046,\"start\":76045},{\"end\":76064,\"start\":76053},{\"end\":76078,\"start\":76073},{\"end\":76093,\"start\":76087},{\"end\":76333,\"start\":76332},{\"end\":76345,\"start\":76342},{\"end\":76563,\"start\":76562},{\"end\":76575,\"start\":76572},{\"end\":77197,\"start\":77193},{\"end\":77359,\"start\":77355},{\"end\":77373,\"start\":77367},{\"end\":77384,\"start\":77378},{\"end\":77399,\"start\":77391},{\"end\":77413,\"start\":77409},{\"end\":77432,\"start\":77425},{\"end\":77443,\"start\":77439},{\"end\":77762,\"start\":77758},{\"end\":77776,\"start\":77773},{\"end\":78089,\"start\":78082},{\"end\":78098,\"start\":78094},{\"end\":78111,\"start\":78104},{\"end\":78334,\"start\":78329},{\"end\":78343,\"start\":78342},{\"end\":78355,\"start\":78352},{\"end\":78357,\"start\":78356},{\"end\":78671,\"start\":78663},{\"end\":78684,\"start\":78677},{\"end\":78697,\"start\":78692},{\"end\":78713,\"start\":78708},{\"end\":78726,\"start\":78720},{\"end\":78739,\"start\":78735},{\"end\":78754,\"start\":78749},{\"end\":78773,\"start\":78763},{\"end\":79035,\"start\":79034},{\"end\":79188,\"start\":79181},{\"end\":79205,\"start\":79199},{\"end\":79207,\"start\":79206},{\"end\":79220,\"start\":79215},{\"end\":79231,\"start\":79230},{\"end\":79247,\"start\":79246},{\"end\":79260,\"start\":79256},{\"end\":79282,\"start\":79281},{\"end\":79284,\"start\":79283},{\"end\":79301,\"start\":79300},{\"end\":79322,\"start\":79321},{\"end\":79336,\"start\":79332},{\"end\":79338,\"start\":79337},{\"end\":79740,\"start\":79736},{\"end\":79763,\"start\":79755},{\"end\":79775,\"start\":79769},{\"end\":80037,\"start\":80032},{\"end\":80051,\"start\":80047},{\"end\":80066,\"start\":80063},{\"end\":80077,\"start\":80073},{\"end\":80079,\"start\":80078},{\"end\":80093,\"start\":80089},{\"end\":80462,\"start\":80452},{\"end\":80476,\"start\":80471},{\"end\":80491,\"start\":80485},{\"end\":80506,\"start\":80499},{\"end\":80798,\"start\":80792},{\"end\":80816,\"start\":80810},{\"end\":80829,\"start\":80823},{\"end\":80844,\"start\":80837},{\"end\":81272,\"start\":81268},{\"end\":81284,\"start\":81281},{\"end\":81301,\"start\":81292},{\"end\":81313,\"start\":81309},{\"end\":81326,\"start\":81321},{\"end\":81344,\"start\":81337},{\"end\":81359,\"start\":81353},{\"end\":81375,\"start\":81369},{\"end\":81388,\"start\":81381},{\"end\":81405,\"start\":81401},{\"end\":81836,\"start\":81831},{\"end\":81850,\"start\":81846},{\"end\":81866,\"start\":81860},{\"end\":82223,\"start\":82215},{\"end\":82235,\"start\":82229},{\"end\":82245,\"start\":82242},{\"end\":82254,\"start\":82250},{\"end\":82262,\"start\":82259},{\"end\":82276,\"start\":82269},{\"end\":82286,\"start\":82283},{\"end\":82718,\"start\":82712},{\"end\":82734,\"start\":82730},{\"end\":82752,\"start\":82742},{\"end\":82767,\"start\":82762},{\"end\":83041,\"start\":83036},{\"end\":83055,\"start\":83050},{\"end\":83066,\"start\":83065},{\"end\":83078,\"start\":83073},{\"end\":83092,\"start\":83087},{\"end\":83104,\"start\":83099},{\"end\":83120,\"start\":83114},{\"end\":83137,\"start\":83136},{\"end\":83151,\"start\":83147},{\"end\":83542,\"start\":83533},{\"end\":83561,\"start\":83551},{\"end\":83579,\"start\":83569},{\"end\":83599,\"start\":83592},{\"end\":83891,\"start\":83885},{\"end\":83909,\"start\":83904},{\"end\":84278,\"start\":84271},{\"end\":84292,\"start\":84284},{\"end\":84307,\"start\":84299},{\"end\":84317,\"start\":84313},{\"end\":84738,\"start\":84732},{\"end\":84757,\"start\":84751},{\"end\":84759,\"start\":84758},{\"end\":84772,\"start\":84767},{\"end\":84788,\"start\":84779},{\"end\":84802,\"start\":84796},{\"end\":84815,\"start\":84810},{\"end\":84835,\"start\":84830},{\"end\":84848,\"start\":84847},{\"end\":84870,\"start\":84869},{\"end\":84881,\"start\":84877},{\"end\":85338,\"start\":85334},{\"end\":85358,\"start\":85350},{\"end\":85375,\"start\":85366},{\"end\":85388,\"start\":85384},{\"end\":85408,\"start\":85399},{\"end\":85711,\"start\":85706},{\"end\":85731,\"start\":85724},{\"end\":85740,\"start\":85739},{\"end\":85756,\"start\":85750},{\"end\":85773,\"start\":85767},{\"end\":85786,\"start\":85779},{\"end\":86104,\"start\":86099},{\"end\":86122,\"start\":86116},{\"end\":86301,\"start\":86297},{\"end\":86317,\"start\":86308},{\"end\":86331,\"start\":86325},{\"end\":86346,\"start\":86341},{\"end\":86357,\"start\":86353},{\"end\":86372,\"start\":86364},{\"end\":86775,\"start\":86768},{\"end\":86789,\"start\":86782},{\"end\":86803,\"start\":86796},{\"end\":86820,\"start\":86811},{\"end\":86831,\"start\":86825},{\"end\":86844,\"start\":86838},{\"end\":87165,\"start\":87159},{\"end\":87179,\"start\":87172},{\"end\":87186,\"start\":87184},{\"end\":87198,\"start\":87194},{\"end\":87206,\"start\":87204},{\"end\":87217,\"start\":87212},{\"end\":87227,\"start\":87222},{\"end\":87239,\"start\":87232},{\"end\":87248,\"start\":87246},{\"end\":87260,\"start\":87256},{\"end\":87270,\"start\":87265},{\"end\":87284,\"start\":87278},{\"end\":87293,\"start\":87290},{\"end\":87307,\"start\":87301},{\"end\":87318,\"start\":87313},{\"end\":87332,\"start\":87325},{\"end\":87346,\"start\":87337},{\"end\":87348,\"start\":87347},{\"end\":87361,\"start\":87356},{\"end\":87928,\"start\":87921},{\"end\":87941,\"start\":87935},{\"end\":87956,\"start\":87947},{\"end\":87969,\"start\":87962},{\"end\":87981,\"start\":87975},{\"end\":87990,\"start\":87986},{\"end\":88301,\"start\":88294},{\"end\":88313,\"start\":88306},{\"end\":88329,\"start\":88325},{\"end\":88331,\"start\":88330},{\"end\":88348,\"start\":88342},{\"end\":88361,\"start\":88356},{\"end\":88373,\"start\":88372},{\"end\":88386,\"start\":88382},{\"end\":88399,\"start\":88394},{\"end\":88704,\"start\":88698},{\"end\":88715,\"start\":88709},{\"end\":88724,\"start\":88720},{\"end\":88743,\"start\":88735},{\"end\":89009,\"start\":89004},{\"end\":89346,\"start\":89340},{\"end\":89360,\"start\":89353},{\"end\":89374,\"start\":89366},{\"end\":89387,\"start\":89379},{\"end\":89395,\"start\":89393},{\"end\":89754,\"start\":89749},{\"end\":89765,\"start\":89761},{\"end\":89782,\"start\":89775},{\"end\":89794,\"start\":89788},{\"end\":89809,\"start\":89802},{\"end\":89820,\"start\":89817},{\"end\":89831,\"start\":89826},{\"end\":89853,\"start\":89846},{\"end\":89867,\"start\":89862},{\"end\":89882,\"start\":89876},{\"end\":90295,\"start\":90289},{\"end\":90303,\"start\":90302},{\"end\":90319,\"start\":90313},{\"end\":90659,\"start\":90656},{\"end\":90673,\"start\":90666},{\"end\":90690,\"start\":90679},{\"end\":90704,\"start\":90699},{\"end\":90711,\"start\":90710},{\"end\":90725,\"start\":90721},{\"end\":91082,\"start\":91075},{\"end\":91091,\"start\":91088},{\"end\":91102,\"start\":91098},{\"end\":91410,\"start\":91405},{\"end\":91429,\"start\":91420},{\"end\":91443,\"start\":91438},{\"end\":91455,\"start\":91451},{\"end\":91824,\"start\":91817},{\"end\":91839,\"start\":91831},{\"end\":91853,\"start\":91846},{\"end\":91874,\"start\":91866},{\"end\":91889,\"start\":91883},{\"end\":92238,\"start\":92233},{\"end\":92251,\"start\":92246},{\"end\":92477,\"start\":92475},{\"end\":92490,\"start\":92485},{\"end\":92501,\"start\":92497},{\"end\":92512,\"start\":92506},{\"end\":92523,\"start\":92518},{\"end\":92531,\"start\":92528},{\"end\":92541,\"start\":92538},{\"end\":92554,\"start\":92549},{\"end\":92568,\"start\":92562},{\"end\":92943,\"start\":92934},{\"end\":92956,\"start\":92949},{\"end\":92965,\"start\":92961},{\"end\":92976,\"start\":92972},{\"end\":93391,\"start\":93384},{\"end\":93401,\"start\":93400},{\"end\":93414,\"start\":93410},{\"end\":93777,\"start\":93775},{\"end\":93788,\"start\":93783},{\"end\":93801,\"start\":93794},{\"end\":93814,\"start\":93809},{\"end\":93826,\"start\":93821},{\"end\":93839,\"start\":93832},{\"end\":93849,\"start\":93846}]", "bib_author_last_name": "[{\"end\":65274,\"start\":65269},{\"end\":65287,\"start\":65281},{\"end\":65301,\"start\":65297},{\"end\":65315,\"start\":65311},{\"end\":65327,\"start\":65322},{\"end\":65341,\"start\":65337},{\"end\":65357,\"start\":65352},{\"end\":65374,\"start\":65366},{\"end\":65391,\"start\":65385},{\"end\":65406,\"start\":65401},{\"end\":65830,\"start\":65821},{\"end\":65849,\"start\":65837},{\"end\":65866,\"start\":65859},{\"end\":66112,\"start\":66104},{\"end\":66361,\"start\":66353},{\"end\":66371,\"start\":66365},{\"end\":66379,\"start\":66373},{\"end\":66666,\"start\":66660},{\"end\":66681,\"start\":66675},{\"end\":66699,\"start\":66692},{\"end\":66716,\"start\":66708},{\"end\":67076,\"start\":67069},{\"end\":67091,\"start\":67087},{\"end\":67101,\"start\":67097},{\"end\":67110,\"start\":67103},{\"end\":67387,\"start\":67381},{\"end\":67404,\"start\":67397},{\"end\":67426,\"start\":67414},{\"end\":67440,\"start\":67434},{\"end\":67458,\"start\":67449},{\"end\":67829,\"start\":67810},{\"end\":67841,\"start\":67836},{\"end\":67855,\"start\":67850},{\"end\":67869,\"start\":67864},{\"end\":67884,\"start\":67871},{\"end\":68221,\"start\":68217},{\"end\":68228,\"start\":68226},{\"end\":68239,\"start\":68237},{\"end\":68248,\"start\":68245},{\"end\":68261,\"start\":68257},{\"end\":68274,\"start\":68270},{\"end\":68288,\"start\":68284},{\"end\":68297,\"start\":68295},{\"end\":68312,\"start\":68307},{\"end\":68325,\"start\":68320},{\"end\":68754,\"start\":68748},{\"end\":68768,\"start\":68765},{\"end\":68775,\"start\":68773},{\"end\":68784,\"start\":68782},{\"end\":68797,\"start\":68791},{\"end\":68812,\"start\":68807},{\"end\":69230,\"start\":69211},{\"end\":69476,\"start\":69471},{\"end\":69489,\"start\":69483},{\"end\":69501,\"start\":69493},{\"end\":69516,\"start\":69509},{\"end\":69524,\"start\":69518},{\"end\":69798,\"start\":69785},{\"end\":69813,\"start\":69808},{\"end\":69823,\"start\":69815},{\"end\":70057,\"start\":70053},{\"end\":70067,\"start\":70063},{\"end\":70083,\"start\":70077},{\"end\":70094,\"start\":70092},{\"end\":70102,\"start\":70100},{\"end\":70114,\"start\":70107},{\"end\":70390,\"start\":70386},{\"end\":70398,\"start\":70396},{\"end\":70412,\"start\":70408},{\"end\":70426,\"start\":70422},{\"end\":70837,\"start\":70821},{\"end\":70854,\"start\":70845},{\"end\":70875,\"start\":70863},{\"end\":70894,\"start\":70885},{\"end\":70907,\"start\":70901},{\"end\":70928,\"start\":70916},{\"end\":70935,\"start\":70930},{\"end\":71296,\"start\":71281},{\"end\":71309,\"start\":71300},{\"end\":71323,\"start\":71318},{\"end\":71339,\"start\":71332},{\"end\":71354,\"start\":71348},{\"end\":71363,\"start\":71356},{\"end\":71614,\"start\":71608},{\"end\":71629,\"start\":71620},{\"end\":71874,\"start\":71868},{\"end\":71887,\"start\":71882},{\"end\":71902,\"start\":71896},{\"end\":71919,\"start\":71912},{\"end\":72190,\"start\":72187},{\"end\":72203,\"start\":72196},{\"end\":72491,\"start\":72485},{\"end\":72501,\"start\":72495},{\"end\":72513,\"start\":72503},{\"end\":72524,\"start\":72517},{\"end\":72537,\"start\":72532},{\"end\":72555,\"start\":72548},{\"end\":72561,\"start\":72557},{\"end\":72890,\"start\":72884},{\"end\":72905,\"start\":72897},{\"end\":73230,\"start\":73212},{\"end\":73241,\"start\":73237},{\"end\":73251,\"start\":73243},{\"end\":73578,\"start\":73560},{\"end\":73589,\"start\":73585},{\"end\":73599,\"start\":73591},{\"end\":73859,\"start\":73857},{\"end\":73870,\"start\":73867},{\"end\":73884,\"start\":73879},{\"end\":73900,\"start\":73894},{\"end\":73913,\"start\":73908},{\"end\":73926,\"start\":73921},{\"end\":73941,\"start\":73933},{\"end\":74265,\"start\":74263},{\"end\":74278,\"start\":74274},{\"end\":74292,\"start\":74288},{\"end\":74304,\"start\":74301},{\"end\":74627,\"start\":74622},{\"end\":74632,\"start\":74629},{\"end\":74641,\"start\":74636},{\"end\":74656,\"start\":74651},{\"end\":74670,\"start\":74658},{\"end\":74685,\"start\":74674},{\"end\":74704,\"start\":74699},{\"end\":74720,\"start\":74714},{\"end\":74741,\"start\":74733},{\"end\":74761,\"start\":74750},{\"end\":74777,\"start\":74768},{\"end\":74791,\"start\":74786},{\"end\":74796,\"start\":74793},{\"end\":75186,\"start\":75178},{\"end\":75212,\"start\":75197},{\"end\":75220,\"start\":75214},{\"end\":75497,\"start\":75491},{\"end\":75509,\"start\":75501},{\"end\":75520,\"start\":75513},{\"end\":75763,\"start\":75760},{\"end\":75780,\"start\":75772},{\"end\":75796,\"start\":75788},{\"end\":76043,\"start\":76035},{\"end\":76051,\"start\":76047},{\"end\":76071,\"start\":76065},{\"end\":76085,\"start\":76079},{\"end\":76100,\"start\":76094},{\"end\":76109,\"start\":76102},{\"end\":76340,\"start\":76334},{\"end\":76350,\"start\":76346},{\"end\":76359,\"start\":76352},{\"end\":76570,\"start\":76564},{\"end\":76580,\"start\":76576},{\"end\":76589,\"start\":76582},{\"end\":77205,\"start\":77198},{\"end\":77365,\"start\":77360},{\"end\":77376,\"start\":77374},{\"end\":77389,\"start\":77385},{\"end\":77407,\"start\":77400},{\"end\":77423,\"start\":77414},{\"end\":77437,\"start\":77433},{\"end\":77456,\"start\":77444},{\"end\":77771,\"start\":77763},{\"end\":77782,\"start\":77777},{\"end\":78092,\"start\":78090},{\"end\":78102,\"start\":78099},{\"end\":78114,\"start\":78112},{\"end\":78340,\"start\":78335},{\"end\":78350,\"start\":78344},{\"end\":78367,\"start\":78358},{\"end\":78675,\"start\":78672},{\"end\":78690,\"start\":78685},{\"end\":78706,\"start\":78698},{\"end\":78718,\"start\":78714},{\"end\":78733,\"start\":78727},{\"end\":78747,\"start\":78740},{\"end\":78761,\"start\":78755},{\"end\":78781,\"start\":78774},{\"end\":79042,\"start\":79036},{\"end\":79048,\"start\":79044},{\"end\":79197,\"start\":79189},{\"end\":79213,\"start\":79208},{\"end\":79228,\"start\":79221},{\"end\":79237,\"start\":79232},{\"end\":79244,\"start\":79239},{\"end\":79254,\"start\":79248},{\"end\":79268,\"start\":79261},{\"end\":79279,\"start\":79270},{\"end\":79291,\"start\":79285},{\"end\":79298,\"start\":79293},{\"end\":79308,\"start\":79302},{\"end\":79319,\"start\":79310},{\"end\":79330,\"start\":79323},{\"end\":79345,\"start\":79339},{\"end\":79353,\"start\":79347},{\"end\":79753,\"start\":79741},{\"end\":79767,\"start\":79764},{\"end\":79782,\"start\":79776},{\"end\":80045,\"start\":80038},{\"end\":80061,\"start\":80052},{\"end\":80071,\"start\":80067},{\"end\":80087,\"start\":80080},{\"end\":80098,\"start\":80094},{\"end\":80469,\"start\":80463},{\"end\":80483,\"start\":80477},{\"end\":80497,\"start\":80492},{\"end\":80518,\"start\":80507},{\"end\":80808,\"start\":80799},{\"end\":80821,\"start\":80817},{\"end\":80835,\"start\":80830},{\"end\":80854,\"start\":80845},{\"end\":81279,\"start\":81273},{\"end\":81290,\"start\":81285},{\"end\":81307,\"start\":81302},{\"end\":81319,\"start\":81314},{\"end\":81335,\"start\":81327},{\"end\":81351,\"start\":81345},{\"end\":81367,\"start\":81360},{\"end\":81379,\"start\":81376},{\"end\":81399,\"start\":81389},{\"end\":81412,\"start\":81406},{\"end\":81844,\"start\":81837},{\"end\":81858,\"start\":81851},{\"end\":81873,\"start\":81867},{\"end\":82227,\"start\":82224},{\"end\":82240,\"start\":82236},{\"end\":82248,\"start\":82246},{\"end\":82257,\"start\":82255},{\"end\":82267,\"start\":82263},{\"end\":82281,\"start\":82277},{\"end\":82291,\"start\":82287},{\"end\":82728,\"start\":82719},{\"end\":82740,\"start\":82735},{\"end\":82760,\"start\":82753},{\"end\":82773,\"start\":82768},{\"end\":83048,\"start\":83042},{\"end\":83063,\"start\":83056},{\"end\":83071,\"start\":83067},{\"end\":83085,\"start\":83079},{\"end\":83097,\"start\":83093},{\"end\":83112,\"start\":83105},{\"end\":83125,\"start\":83121},{\"end\":83134,\"start\":83127},{\"end\":83145,\"start\":83138},{\"end\":83156,\"start\":83152},{\"end\":83164,\"start\":83158},{\"end\":83549,\"start\":83543},{\"end\":83567,\"start\":83562},{\"end\":83590,\"start\":83580},{\"end\":83609,\"start\":83600},{\"end\":83902,\"start\":83892},{\"end\":83919,\"start\":83910},{\"end\":84282,\"start\":84279},{\"end\":84297,\"start\":84293},{\"end\":84311,\"start\":84308},{\"end\":84322,\"start\":84318},{\"end\":84749,\"start\":84739},{\"end\":84765,\"start\":84760},{\"end\":84777,\"start\":84773},{\"end\":84794,\"start\":84789},{\"end\":84808,\"start\":84803},{\"end\":84828,\"start\":84816},{\"end\":84845,\"start\":84836},{\"end\":84857,\"start\":84849},{\"end\":84867,\"start\":84859},{\"end\":84875,\"start\":84871},{\"end\":84888,\"start\":84882},{\"end\":84894,\"start\":84890},{\"end\":85348,\"start\":85339},{\"end\":85364,\"start\":85359},{\"end\":85382,\"start\":85376},{\"end\":85397,\"start\":85389},{\"end\":85417,\"start\":85409},{\"end\":85722,\"start\":85712},{\"end\":85737,\"start\":85732},{\"end\":85748,\"start\":85741},{\"end\":85765,\"start\":85757},{\"end\":85777,\"start\":85774},{\"end\":85793,\"start\":85787},{\"end\":85800,\"start\":85795},{\"end\":86114,\"start\":86105},{\"end\":86131,\"start\":86123},{\"end\":86306,\"start\":86302},{\"end\":86323,\"start\":86318},{\"end\":86339,\"start\":86332},{\"end\":86351,\"start\":86347},{\"end\":86362,\"start\":86358},{\"end\":86379,\"start\":86373},{\"end\":86780,\"start\":86776},{\"end\":86794,\"start\":86790},{\"end\":86809,\"start\":86804},{\"end\":86823,\"start\":86821},{\"end\":86836,\"start\":86832},{\"end\":86852,\"start\":86845},{\"end\":87170,\"start\":87166},{\"end\":87182,\"start\":87180},{\"end\":87192,\"start\":87187},{\"end\":87202,\"start\":87199},{\"end\":87210,\"start\":87207},{\"end\":87220,\"start\":87218},{\"end\":87230,\"start\":87228},{\"end\":87244,\"start\":87240},{\"end\":87254,\"start\":87249},{\"end\":87263,\"start\":87261},{\"end\":87276,\"start\":87271},{\"end\":87288,\"start\":87285},{\"end\":87299,\"start\":87294},{\"end\":87311,\"start\":87308},{\"end\":87323,\"start\":87319},{\"end\":87335,\"start\":87333},{\"end\":87354,\"start\":87349},{\"end\":87367,\"start\":87362},{\"end\":87933,\"start\":87929},{\"end\":87945,\"start\":87942},{\"end\":87960,\"start\":87957},{\"end\":87973,\"start\":87970},{\"end\":87984,\"start\":87982},{\"end\":87995,\"start\":87991},{\"end\":88304,\"start\":88302},{\"end\":88323,\"start\":88314},{\"end\":88340,\"start\":88332},{\"end\":88354,\"start\":88349},{\"end\":88370,\"start\":88362},{\"end\":88380,\"start\":88374},{\"end\":88392,\"start\":88387},{\"end\":88407,\"start\":88400},{\"end\":88414,\"start\":88409},{\"end\":88707,\"start\":88705},{\"end\":88718,\"start\":88716},{\"end\":88733,\"start\":88725},{\"end\":88751,\"start\":88744},{\"end\":89018,\"start\":89010},{\"end\":89032,\"start\":89020},{\"end\":89351,\"start\":89347},{\"end\":89364,\"start\":89361},{\"end\":89377,\"start\":89375},{\"end\":89391,\"start\":89388},{\"end\":89400,\"start\":89396},{\"end\":89759,\"start\":89755},{\"end\":89773,\"start\":89766},{\"end\":89786,\"start\":89783},{\"end\":89800,\"start\":89795},{\"end\":89815,\"start\":89810},{\"end\":89824,\"start\":89821},{\"end\":89844,\"start\":89832},{\"end\":89860,\"start\":89854},{\"end\":89874,\"start\":89868},{\"end\":89889,\"start\":89883},{\"end\":90300,\"start\":90296},{\"end\":90311,\"start\":90304},{\"end\":90325,\"start\":90320},{\"end\":90340,\"start\":90327},{\"end\":90664,\"start\":90660},{\"end\":90677,\"start\":90674},{\"end\":90697,\"start\":90691},{\"end\":90708,\"start\":90705},{\"end\":90719,\"start\":90712},{\"end\":90734,\"start\":90726},{\"end\":90744,\"start\":90736},{\"end\":91086,\"start\":91083},{\"end\":91096,\"start\":91092},{\"end\":91111,\"start\":91103},{\"end\":91418,\"start\":91411},{\"end\":91436,\"start\":91430},{\"end\":91449,\"start\":91444},{\"end\":91463,\"start\":91456},{\"end\":91829,\"start\":91825},{\"end\":91844,\"start\":91840},{\"end\":91864,\"start\":91854},{\"end\":91881,\"start\":91875},{\"end\":91898,\"start\":91890},{\"end\":92244,\"start\":92239},{\"end\":92256,\"start\":92252},{\"end\":92483,\"start\":92478},{\"end\":92495,\"start\":92491},{\"end\":92504,\"start\":92502},{\"end\":92516,\"start\":92513},{\"end\":92526,\"start\":92524},{\"end\":92536,\"start\":92532},{\"end\":92547,\"start\":92542},{\"end\":92560,\"start\":92555},{\"end\":92576,\"start\":92569},{\"end\":92947,\"start\":92944},{\"end\":92959,\"start\":92957},{\"end\":92970,\"start\":92966},{\"end\":92979,\"start\":92977},{\"end\":93398,\"start\":93392},{\"end\":93408,\"start\":93402},{\"end\":93422,\"start\":93415},{\"end\":93432,\"start\":93424},{\"end\":93781,\"start\":93778},{\"end\":93792,\"start\":93789},{\"end\":93807,\"start\":93802},{\"end\":93819,\"start\":93815},{\"end\":93830,\"start\":93827},{\"end\":93844,\"start\":93840},{\"end\":93854,\"start\":93850}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":6287870},\"end\":65765,\"start\":65207},{\"attributes\":{\"doi\":\"arXiv:1711.00740\",\"id\":\"b1\"},\"end\":66041,\"start\":65767},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":8156515},\"end\":66270,\"start\":66043},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":10950726},\"end\":66563,\"start\":66272},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":13638584},\"end\":67060,\"start\":66565},{\"attributes\":{\"doi\":\"arXiv:1706.02263\",\"id\":\"b5\"},\"end\":67312,\"start\":67062},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":14941970},\"end\":67749,\"start\":67314},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":15195762},\"end\":68112,\"start\":67751},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":1507815},\"end\":68644,\"start\":68114},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":159042192},\"end\":69143,\"start\":68646},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":53222305},\"end\":69394,\"start\":69145},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":3393987},\"end\":69731,\"start\":69396},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":5692810},\"end\":69994,\"start\":69733},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":57246310},\"end\":70283,\"start\":69996},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":15168964},\"end\":70742,\"start\":70285},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":1690180},\"end\":71273,\"start\":70744},{\"attributes\":{\"doi\":\"arXiv:2003.00982\",\"id\":\"b16\"},\"end\":71598,\"start\":71275},{\"attributes\":{\"id\":\"b17\"},\"end\":71788,\"start\":71600},{\"attributes\":{\"doi\":\"arXiv:1912.09893\",\"id\":\"b18\"},\"end\":72124,\"start\":71790},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":70349949},\"end\":72430,\"start\":72126},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":9665943},\"end\":72825,\"start\":72432},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":207238980},\"end\":73155,\"start\":72827},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":4755450},\"end\":73493,\"start\":73157},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":3215337},\"end\":73797,\"start\":73495},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":213085920},\"end\":74222,\"start\":73799},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":211818229},\"end\":74586,\"start\":74224},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":3833474},\"end\":75078,\"start\":74588},{\"attributes\":{\"doi\":\"arXiv:1902.01020\",\"id\":\"b27\"},\"end\":75436,\"start\":75080},{\"attributes\":{\"doi\":\"arXiv:1910.12091\",\"id\":\"b28\"},\"end\":75681,\"start\":75438},{\"attributes\":{\"doi\":\"arXiv:2002.03230\",\"id\":\"b29\"},\"end\":75985,\"start\":75683},{\"attributes\":{\"id\":\"b30\"},\"end\":76297,\"start\":75987},{\"attributes\":{\"doi\":\"arXiv:1611.07308\",\"id\":\"b31\"},\"end\":76494,\"start\":76299},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":3144218},\"end\":76818,\"start\":76496},{\"attributes\":{\"id\":\"b33\"},\"end\":77191,\"start\":76820},{\"attributes\":{\"id\":\"b34\"},\"end\":77297,\"start\":77193},{\"attributes\":{\"doi\":\"arXiv:1903.12287\",\"id\":\"b35\"},\"end\":77689,\"start\":77299},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":2601163},\"end\":78024,\"start\":77691},{\"attributes\":{\"doi\":\"arXiv:1709.03741\",\"id\":\"b37\"},\"end\":78278,\"start\":78026},{\"attributes\":{\"id\":\"b38\",\"matched_paper_id\":33364366},\"end\":78618,\"start\":78280},{\"attributes\":{\"id\":\"b39\",\"matched_paper_id\":14113767},\"end\":79001,\"start\":78620},{\"attributes\":{\"id\":\"b40\"},\"end\":79119,\"start\":79003},{\"attributes\":{\"id\":\"b41\",\"matched_paper_id\":205477370},\"end\":79675,\"start\":79121},{\"attributes\":{\"id\":\"b42\",\"matched_paper_id\":4411891},\"end\":79953,\"start\":79677},{\"attributes\":{\"id\":\"b43\",\"matched_paper_id\":16447573},\"end\":80388,\"start\":79955},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":12161567},\"end\":80727,\"start\":80390},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":2191379},\"end\":81196,\"start\":80729},{\"attributes\":{\"id\":\"b46\",\"matched_paper_id\":202786778},\"end\":81776,\"start\":81198},{\"attributes\":{\"id\":\"b47\",\"matched_paper_id\":3051291},\"end\":82143,\"start\":81778},{\"attributes\":{\"id\":\"b48\",\"matched_paper_id\":84177611},\"end\":82649,\"start\":82145},{\"attributes\":{\"doi\":\"arXiv:1606.05250\",\"id\":\"b49\"},\"end\":82971,\"start\":82651},{\"attributes\":{\"id\":\"b50\",\"matched_paper_id\":14466231},\"end\":83486,\"start\":82973},{\"attributes\":{\"doi\":\"arXiv:1811.05868\",\"id\":\"b51\"},\"end\":83806,\"start\":83488},{\"attributes\":{\"id\":\"b52\",\"matched_paper_id\":17648673},\"end\":84194,\"start\":83808},{\"attributes\":{\"id\":\"b53\",\"matched_paper_id\":67855617},\"end\":84586,\"start\":84196},{\"attributes\":{\"id\":\"b54\",\"matched_paper_id\":53751796},\"end\":85285,\"start\":84588},{\"attributes\":{\"id\":\"b55\",\"matched_paper_id\":15150247},\"end\":85684,\"start\":85287},{\"attributes\":{\"id\":\"b56\",\"matched_paper_id\":52877454},\"end\":86051,\"start\":85686},{\"attributes\":{\"id\":\"b57\",\"matched_paper_id\":14494942},\"end\":86295,\"start\":86053},{\"attributes\":{\"doi\":\"arXiv:1804.07461\",\"id\":\"b58\"},\"end\":86711,\"start\":86297},{\"attributes\":{\"id\":\"b59\",\"matched_paper_id\":210872675},\"end\":87081,\"start\":86713},{\"attributes\":{\"id\":\"b60\",\"matched_paper_id\":202539732},\"end\":87830,\"start\":87083},{\"attributes\":{\"doi\":\"arXiv:1911.06136\",\"id\":\"b61\"},\"end\":88235,\"start\":87832},{\"attributes\":{\"id\":\"b62\",\"matched_paper_id\":217680306},\"end\":88655,\"start\":88237},{\"attributes\":{\"id\":\"b63\",\"matched_paper_id\":52895589},\"end\":88982,\"start\":88657},{\"attributes\":{\"id\":\"b64\",\"matched_paper_id\":207227372},\"end\":89258,\"start\":88984},{\"attributes\":{\"id\":\"b65\",\"matched_paper_id\":2768038},\"end\":89678,\"start\":89260},{\"attributes\":{\"id\":\"b66\",\"matched_paper_id\":198986021},\"end\":90228,\"start\":89680},{\"attributes\":{\"id\":\"b67\",\"matched_paper_id\":7008752},\"end\":90582,\"start\":90230},{\"attributes\":{\"id\":\"b68\",\"matched_paper_id\":49420315},\"end\":91035,\"start\":90584},{\"attributes\":{\"id\":\"b69\",\"matched_paper_id\":174800449},\"end\":91307,\"start\":91037},{\"attributes\":{\"id\":\"b70\",\"matched_paper_id\":11777596},\"end\":91754,\"start\":91309},{\"attributes\":{\"id\":\"b71\",\"matched_paper_id\":195886159},\"end\":92183,\"start\":91756},{\"attributes\":{\"id\":\"b72\",\"matched_paper_id\":3573161},\"end\":92473,\"start\":92185},{\"attributes\":{\"doi\":\"arXiv:2004.08532\",\"id\":\"b73\"},\"end\":92861,\"start\":92475},{\"attributes\":{\"id\":\"b74\",\"matched_paper_id\":67855614},\"end\":93309,\"start\":92863},{\"attributes\":{\"id\":\"b75\",\"matched_paper_id\":73454585},\"end\":93721,\"start\":93311},{\"attributes\":{\"id\":\"b76\"},\"end\":94047,\"start\":93723}]", "bib_title": "[{\"end\":65260,\"start\":65207},{\"end\":66095,\"start\":66043},{\"end\":66337,\"start\":66272},{\"end\":66654,\"start\":66565},{\"end\":67371,\"start\":67314},{\"end\":67803,\"start\":67751},{\"end\":68208,\"start\":68114},{\"end\":68738,\"start\":68646},{\"end\":69204,\"start\":69145},{\"end\":69462,\"start\":69396},{\"end\":69773,\"start\":69733},{\"end\":70047,\"start\":69996},{\"end\":70377,\"start\":70285},{\"end\":70812,\"start\":70744},{\"end\":72183,\"start\":72126},{\"end\":72476,\"start\":72432},{\"end\":72875,\"start\":72827},{\"end\":73206,\"start\":73157},{\"end\":73554,\"start\":73495},{\"end\":73848,\"start\":73799},{\"end\":74255,\"start\":74224},{\"end\":74618,\"start\":74588},{\"end\":76560,\"start\":76496},{\"end\":77756,\"start\":77691},{\"end\":78327,\"start\":78280},{\"end\":78661,\"start\":78620},{\"end\":79179,\"start\":79121},{\"end\":79734,\"start\":79677},{\"end\":80030,\"start\":79955},{\"end\":80450,\"start\":80390},{\"end\":80790,\"start\":80729},{\"end\":81266,\"start\":81198},{\"end\":81829,\"start\":81778},{\"end\":82213,\"start\":82145},{\"end\":83034,\"start\":82973},{\"end\":83883,\"start\":83808},{\"end\":84269,\"start\":84196},{\"end\":84730,\"start\":84588},{\"end\":85332,\"start\":85287},{\"end\":85704,\"start\":85686},{\"end\":86097,\"start\":86053},{\"end\":86766,\"start\":86713},{\"end\":87157,\"start\":87083},{\"end\":88292,\"start\":88237},{\"end\":88696,\"start\":88657},{\"end\":89002,\"start\":88984},{\"end\":89338,\"start\":89260},{\"end\":89747,\"start\":89680},{\"end\":90287,\"start\":90230},{\"end\":90654,\"start\":90584},{\"end\":91073,\"start\":91037},{\"end\":91403,\"start\":91309},{\"end\":91815,\"start\":91756},{\"end\":92231,\"start\":92185},{\"end\":92932,\"start\":92863},{\"end\":93382,\"start\":93311}]", "bib_author": "[{\"end\":65276,\"start\":65262},{\"end\":65289,\"start\":65276},{\"end\":65303,\"start\":65289},{\"end\":65317,\"start\":65303},{\"end\":65329,\"start\":65317},{\"end\":65343,\"start\":65329},{\"end\":65359,\"start\":65343},{\"end\":65376,\"start\":65359},{\"end\":65393,\"start\":65376},{\"end\":65408,\"start\":65393},{\"end\":65832,\"start\":65811},{\"end\":65851,\"start\":65832},{\"end\":65868,\"start\":65851},{\"end\":66114,\"start\":66097},{\"end\":66363,\"start\":66339},{\"end\":66373,\"start\":66363},{\"end\":66381,\"start\":66373},{\"end\":66668,\"start\":66656},{\"end\":66683,\"start\":66668},{\"end\":66701,\"start\":66683},{\"end\":66718,\"start\":66701},{\"end\":67078,\"start\":67062},{\"end\":67093,\"start\":67078},{\"end\":67103,\"start\":67093},{\"end\":67112,\"start\":67103},{\"end\":67389,\"start\":67373},{\"end\":67406,\"start\":67389},{\"end\":67428,\"start\":67406},{\"end\":67442,\"start\":67428},{\"end\":67460,\"start\":67442},{\"end\":67831,\"start\":67805},{\"end\":67843,\"start\":67831},{\"end\":67857,\"start\":67843},{\"end\":67871,\"start\":67857},{\"end\":67886,\"start\":67871},{\"end\":68223,\"start\":68210},{\"end\":68230,\"start\":68223},{\"end\":68241,\"start\":68230},{\"end\":68250,\"start\":68241},{\"end\":68263,\"start\":68250},{\"end\":68276,\"start\":68263},{\"end\":68290,\"start\":68276},{\"end\":68299,\"start\":68290},{\"end\":68314,\"start\":68299},{\"end\":68327,\"start\":68314},{\"end\":68756,\"start\":68740},{\"end\":68770,\"start\":68756},{\"end\":68777,\"start\":68770},{\"end\":68786,\"start\":68777},{\"end\":68799,\"start\":68786},{\"end\":68814,\"start\":68799},{\"end\":69232,\"start\":69206},{\"end\":69478,\"start\":69464},{\"end\":69491,\"start\":69478},{\"end\":69503,\"start\":69491},{\"end\":69518,\"start\":69503},{\"end\":69526,\"start\":69518},{\"end\":69800,\"start\":69775},{\"end\":69815,\"start\":69800},{\"end\":69825,\"start\":69815},{\"end\":70059,\"start\":70049},{\"end\":70069,\"start\":70059},{\"end\":70085,\"start\":70069},{\"end\":70096,\"start\":70085},{\"end\":70104,\"start\":70096},{\"end\":70116,\"start\":70104},{\"end\":70392,\"start\":70379},{\"end\":70400,\"start\":70392},{\"end\":70414,\"start\":70400},{\"end\":70428,\"start\":70414},{\"end\":70839,\"start\":70814},{\"end\":70856,\"start\":70839},{\"end\":70877,\"start\":70856},{\"end\":70896,\"start\":70877},{\"end\":70909,\"start\":70896},{\"end\":70930,\"start\":70909},{\"end\":70937,\"start\":70930},{\"end\":71298,\"start\":71275},{\"end\":71311,\"start\":71298},{\"end\":71325,\"start\":71311},{\"end\":71341,\"start\":71325},{\"end\":71356,\"start\":71341},{\"end\":71365,\"start\":71356},{\"end\":71616,\"start\":71602},{\"end\":71631,\"start\":71616},{\"end\":71876,\"start\":71859},{\"end\":71889,\"start\":71876},{\"end\":71904,\"start\":71889},{\"end\":71921,\"start\":71904},{\"end\":72192,\"start\":72185},{\"end\":72205,\"start\":72192},{\"end\":72493,\"start\":72478},{\"end\":72503,\"start\":72493},{\"end\":72515,\"start\":72503},{\"end\":72526,\"start\":72515},{\"end\":72539,\"start\":72526},{\"end\":72557,\"start\":72539},{\"end\":72563,\"start\":72557},{\"end\":72892,\"start\":72877},{\"end\":72907,\"start\":72892},{\"end\":73232,\"start\":73208},{\"end\":73243,\"start\":73232},{\"end\":73253,\"start\":73243},{\"end\":73580,\"start\":73556},{\"end\":73591,\"start\":73580},{\"end\":73601,\"start\":73591},{\"end\":73861,\"start\":73850},{\"end\":73872,\"start\":73861},{\"end\":73886,\"start\":73872},{\"end\":73902,\"start\":73886},{\"end\":73915,\"start\":73902},{\"end\":73928,\"start\":73915},{\"end\":73943,\"start\":73928},{\"end\":74267,\"start\":74257},{\"end\":74280,\"start\":74267},{\"end\":74294,\"start\":74280},{\"end\":74306,\"start\":74294},{\"end\":74629,\"start\":74620},{\"end\":74634,\"start\":74629},{\"end\":74643,\"start\":74634},{\"end\":74658,\"start\":74643},{\"end\":74672,\"start\":74658},{\"end\":74687,\"start\":74672},{\"end\":74706,\"start\":74687},{\"end\":74722,\"start\":74706},{\"end\":74743,\"start\":74722},{\"end\":74763,\"start\":74743},{\"end\":74779,\"start\":74763},{\"end\":74793,\"start\":74779},{\"end\":74798,\"start\":74793},{\"end\":75188,\"start\":75168},{\"end\":75214,\"start\":75188},{\"end\":75222,\"start\":75214},{\"end\":75499,\"start\":75489},{\"end\":75511,\"start\":75499},{\"end\":75522,\"start\":75511},{\"end\":75765,\"start\":75752},{\"end\":75782,\"start\":75765},{\"end\":75798,\"start\":75782},{\"end\":76045,\"start\":76026},{\"end\":76053,\"start\":76045},{\"end\":76073,\"start\":76053},{\"end\":76087,\"start\":76073},{\"end\":76102,\"start\":76087},{\"end\":76111,\"start\":76102},{\"end\":76342,\"start\":76332},{\"end\":76352,\"start\":76342},{\"end\":76361,\"start\":76352},{\"end\":76572,\"start\":76562},{\"end\":76582,\"start\":76572},{\"end\":76591,\"start\":76582},{\"end\":77207,\"start\":77193},{\"end\":77367,\"start\":77355},{\"end\":77378,\"start\":77367},{\"end\":77391,\"start\":77378},{\"end\":77409,\"start\":77391},{\"end\":77425,\"start\":77409},{\"end\":77439,\"start\":77425},{\"end\":77458,\"start\":77439},{\"end\":77773,\"start\":77758},{\"end\":77784,\"start\":77773},{\"end\":78094,\"start\":78082},{\"end\":78104,\"start\":78094},{\"end\":78116,\"start\":78104},{\"end\":78342,\"start\":78329},{\"end\":78352,\"start\":78342},{\"end\":78369,\"start\":78352},{\"end\":78677,\"start\":78663},{\"end\":78692,\"start\":78677},{\"end\":78708,\"start\":78692},{\"end\":78720,\"start\":78708},{\"end\":78735,\"start\":78720},{\"end\":78749,\"start\":78735},{\"end\":78763,\"start\":78749},{\"end\":78783,\"start\":78763},{\"end\":79044,\"start\":79034},{\"end\":79050,\"start\":79044},{\"end\":79199,\"start\":79181},{\"end\":79215,\"start\":79199},{\"end\":79230,\"start\":79215},{\"end\":79239,\"start\":79230},{\"end\":79246,\"start\":79239},{\"end\":79256,\"start\":79246},{\"end\":79270,\"start\":79256},{\"end\":79281,\"start\":79270},{\"end\":79293,\"start\":79281},{\"end\":79300,\"start\":79293},{\"end\":79310,\"start\":79300},{\"end\":79321,\"start\":79310},{\"end\":79332,\"start\":79321},{\"end\":79347,\"start\":79332},{\"end\":79355,\"start\":79347},{\"end\":79755,\"start\":79736},{\"end\":79769,\"start\":79755},{\"end\":79784,\"start\":79769},{\"end\":80047,\"start\":80032},{\"end\":80063,\"start\":80047},{\"end\":80073,\"start\":80063},{\"end\":80089,\"start\":80073},{\"end\":80100,\"start\":80089},{\"end\":80471,\"start\":80452},{\"end\":80485,\"start\":80471},{\"end\":80499,\"start\":80485},{\"end\":80520,\"start\":80499},{\"end\":80810,\"start\":80792},{\"end\":80823,\"start\":80810},{\"end\":80837,\"start\":80823},{\"end\":80856,\"start\":80837},{\"end\":81281,\"start\":81268},{\"end\":81292,\"start\":81281},{\"end\":81309,\"start\":81292},{\"end\":81321,\"start\":81309},{\"end\":81337,\"start\":81321},{\"end\":81353,\"start\":81337},{\"end\":81369,\"start\":81353},{\"end\":81381,\"start\":81369},{\"end\":81401,\"start\":81381},{\"end\":81414,\"start\":81401},{\"end\":81846,\"start\":81831},{\"end\":81860,\"start\":81846},{\"end\":81875,\"start\":81860},{\"end\":82229,\"start\":82215},{\"end\":82242,\"start\":82229},{\"end\":82250,\"start\":82242},{\"end\":82259,\"start\":82250},{\"end\":82269,\"start\":82259},{\"end\":82283,\"start\":82269},{\"end\":82293,\"start\":82283},{\"end\":82730,\"start\":82712},{\"end\":82742,\"start\":82730},{\"end\":82762,\"start\":82742},{\"end\":82775,\"start\":82762},{\"end\":83050,\"start\":83036},{\"end\":83065,\"start\":83050},{\"end\":83073,\"start\":83065},{\"end\":83087,\"start\":83073},{\"end\":83099,\"start\":83087},{\"end\":83114,\"start\":83099},{\"end\":83127,\"start\":83114},{\"end\":83136,\"start\":83127},{\"end\":83147,\"start\":83136},{\"end\":83158,\"start\":83147},{\"end\":83166,\"start\":83158},{\"end\":83551,\"start\":83533},{\"end\":83569,\"start\":83551},{\"end\":83592,\"start\":83569},{\"end\":83611,\"start\":83592},{\"end\":83904,\"start\":83885},{\"end\":83921,\"start\":83904},{\"end\":84284,\"start\":84271},{\"end\":84299,\"start\":84284},{\"end\":84313,\"start\":84299},{\"end\":84324,\"start\":84313},{\"end\":84751,\"start\":84732},{\"end\":84767,\"start\":84751},{\"end\":84779,\"start\":84767},{\"end\":84796,\"start\":84779},{\"end\":84810,\"start\":84796},{\"end\":84830,\"start\":84810},{\"end\":84847,\"start\":84830},{\"end\":84859,\"start\":84847},{\"end\":84869,\"start\":84859},{\"end\":84877,\"start\":84869},{\"end\":84890,\"start\":84877},{\"end\":84896,\"start\":84890},{\"end\":85350,\"start\":85334},{\"end\":85366,\"start\":85350},{\"end\":85384,\"start\":85366},{\"end\":85399,\"start\":85384},{\"end\":85419,\"start\":85399},{\"end\":85724,\"start\":85706},{\"end\":85739,\"start\":85724},{\"end\":85750,\"start\":85739},{\"end\":85767,\"start\":85750},{\"end\":85779,\"start\":85767},{\"end\":85795,\"start\":85779},{\"end\":85802,\"start\":85795},{\"end\":86116,\"start\":86099},{\"end\":86133,\"start\":86116},{\"end\":86308,\"start\":86297},{\"end\":86325,\"start\":86308},{\"end\":86341,\"start\":86325},{\"end\":86353,\"start\":86341},{\"end\":86364,\"start\":86353},{\"end\":86381,\"start\":86364},{\"end\":86782,\"start\":86768},{\"end\":86796,\"start\":86782},{\"end\":86811,\"start\":86796},{\"end\":86825,\"start\":86811},{\"end\":86838,\"start\":86825},{\"end\":86854,\"start\":86838},{\"end\":87172,\"start\":87159},{\"end\":87184,\"start\":87172},{\"end\":87194,\"start\":87184},{\"end\":87204,\"start\":87194},{\"end\":87212,\"start\":87204},{\"end\":87222,\"start\":87212},{\"end\":87232,\"start\":87222},{\"end\":87246,\"start\":87232},{\"end\":87256,\"start\":87246},{\"end\":87265,\"start\":87256},{\"end\":87278,\"start\":87265},{\"end\":87290,\"start\":87278},{\"end\":87301,\"start\":87290},{\"end\":87313,\"start\":87301},{\"end\":87325,\"start\":87313},{\"end\":87337,\"start\":87325},{\"end\":87356,\"start\":87337},{\"end\":87369,\"start\":87356},{\"end\":87935,\"start\":87921},{\"end\":87947,\"start\":87935},{\"end\":87962,\"start\":87947},{\"end\":87975,\"start\":87962},{\"end\":87986,\"start\":87975},{\"end\":87997,\"start\":87986},{\"end\":88306,\"start\":88294},{\"end\":88325,\"start\":88306},{\"end\":88342,\"start\":88325},{\"end\":88356,\"start\":88342},{\"end\":88372,\"start\":88356},{\"end\":88382,\"start\":88372},{\"end\":88394,\"start\":88382},{\"end\":88409,\"start\":88394},{\"end\":88416,\"start\":88409},{\"end\":88709,\"start\":88698},{\"end\":88720,\"start\":88709},{\"end\":88735,\"start\":88720},{\"end\":88753,\"start\":88735},{\"end\":89020,\"start\":89004},{\"end\":89034,\"start\":89020},{\"end\":89353,\"start\":89340},{\"end\":89366,\"start\":89353},{\"end\":89379,\"start\":89366},{\"end\":89393,\"start\":89379},{\"end\":89402,\"start\":89393},{\"end\":89761,\"start\":89749},{\"end\":89775,\"start\":89761},{\"end\":89788,\"start\":89775},{\"end\":89802,\"start\":89788},{\"end\":89817,\"start\":89802},{\"end\":89826,\"start\":89817},{\"end\":89846,\"start\":89826},{\"end\":89862,\"start\":89846},{\"end\":89876,\"start\":89862},{\"end\":89891,\"start\":89876},{\"end\":90302,\"start\":90289},{\"end\":90313,\"start\":90302},{\"end\":90327,\"start\":90313},{\"end\":90342,\"start\":90327},{\"end\":90666,\"start\":90656},{\"end\":90679,\"start\":90666},{\"end\":90699,\"start\":90679},{\"end\":90710,\"start\":90699},{\"end\":90721,\"start\":90710},{\"end\":90736,\"start\":90721},{\"end\":90746,\"start\":90736},{\"end\":91088,\"start\":91075},{\"end\":91098,\"start\":91088},{\"end\":91113,\"start\":91098},{\"end\":91420,\"start\":91405},{\"end\":91438,\"start\":91420},{\"end\":91451,\"start\":91438},{\"end\":91465,\"start\":91451},{\"end\":91831,\"start\":91817},{\"end\":91846,\"start\":91831},{\"end\":91866,\"start\":91846},{\"end\":91883,\"start\":91866},{\"end\":91900,\"start\":91883},{\"end\":92246,\"start\":92233},{\"end\":92258,\"start\":92246},{\"end\":92485,\"start\":92475},{\"end\":92497,\"start\":92485},{\"end\":92506,\"start\":92497},{\"end\":92518,\"start\":92506},{\"end\":92528,\"start\":92518},{\"end\":92538,\"start\":92528},{\"end\":92549,\"start\":92538},{\"end\":92562,\"start\":92549},{\"end\":92578,\"start\":92562},{\"end\":92949,\"start\":92934},{\"end\":92961,\"start\":92949},{\"end\":92972,\"start\":92961},{\"end\":92981,\"start\":92972},{\"end\":93400,\"start\":93384},{\"end\":93410,\"start\":93400},{\"end\":93424,\"start\":93410},{\"end\":93434,\"start\":93424},{\"end\":93783,\"start\":93775},{\"end\":93794,\"start\":93783},{\"end\":93809,\"start\":93794},{\"end\":93821,\"start\":93809},{\"end\":93832,\"start\":93821},{\"end\":93846,\"start\":93832},{\"end\":93856,\"start\":93846}]", "bib_venue": "[{\"end\":74409,\"start\":74366},{\"end\":82408,\"start\":82359},{\"end\":93096,\"start\":93047},{\"end\":93515,\"start\":93483},{\"end\":65470,\"start\":65408},{\"end\":65809,\"start\":65767},{\"end\":66143,\"start\":66114},{\"end\":66404,\"start\":66381},{\"end\":66793,\"start\":66718},{\"end\":67165,\"start\":67128},{\"end\":67516,\"start\":67460},{\"end\":67917,\"start\":67886},{\"end\":68371,\"start\":68327},{\"end\":68880,\"start\":68814},{\"end\":69254,\"start\":69232},{\"end\":69549,\"start\":69526},{\"end\":69848,\"start\":69825},{\"end\":70120,\"start\":70116},{\"end\":70494,\"start\":70428},{\"end\":70993,\"start\":70937},{\"end\":71415,\"start\":71381},{\"end\":71857,\"start\":71790},{\"end\":72269,\"start\":72205},{\"end\":72614,\"start\":72563},{\"end\":72973,\"start\":72907},{\"end\":73309,\"start\":73253},{\"end\":73631,\"start\":73601},{\"end\":74002,\"start\":73943},{\"end\":74364,\"start\":74306},{\"end\":74817,\"start\":74798},{\"end\":75166,\"start\":75080},{\"end\":75487,\"start\":75438},{\"end\":75750,\"start\":75683},{\"end\":76024,\"start\":75987},{\"end\":76330,\"start\":76299},{\"end\":76649,\"start\":76591},{\"end\":76902,\"start\":76820},{\"end\":77234,\"start\":77207},{\"end\":77353,\"start\":77299},{\"end\":77845,\"start\":77784},{\"end\":78080,\"start\":78026},{\"end\":78434,\"start\":78369},{\"end\":78787,\"start\":78783},{\"end\":79032,\"start\":79003},{\"end\":79384,\"start\":79355},{\"end\":79802,\"start\":79784},{\"end\":80156,\"start\":80100},{\"end\":80543,\"start\":80520},{\"end\":80942,\"start\":80856},{\"end\":81470,\"start\":81414},{\"end\":81941,\"start\":81875},{\"end\":82357,\"start\":82293},{\"end\":82710,\"start\":82651},{\"end\":83213,\"start\":83166},{\"end\":83531,\"start\":83488},{\"end\":83986,\"start\":83921},{\"end\":84383,\"start\":84324},{\"end\":84918,\"start\":84896},{\"end\":85470,\"start\":85419},{\"end\":85861,\"start\":85802},{\"end\":86158,\"start\":86133},{\"end\":86482,\"start\":86397},{\"end\":86882,\"start\":86854},{\"end\":87428,\"start\":87369},{\"end\":87919,\"start\":87832},{\"end\":88432,\"start\":88416},{\"end\":88812,\"start\":88753},{\"end\":89100,\"start\":89034},{\"end\":89461,\"start\":89402},{\"end\":89935,\"start\":89891},{\"end\":90393,\"start\":90342},{\"end\":90802,\"start\":90746},{\"end\":91164,\"start\":91113},{\"end\":91512,\"start\":91465},{\"end\":91959,\"start\":91900},{\"end\":92314,\"start\":92258},{\"end\":92646,\"start\":92594},{\"end\":93045,\"start\":92981},{\"end\":93481,\"start\":93434},{\"end\":93773,\"start\":93723}]"}}}, "year": 2023, "month": 12, "day": 17}