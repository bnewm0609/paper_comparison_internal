{"id": 235417446, "updated": "2023-10-06 01:50:35.331", "metadata": {"title": "To Beam Or Not To Beam: That is a Question of Cooperation for Language GANs", "authors": "[{\"first\":\"Thomas\",\"last\":\"Scialom\",\"middle\":[]},{\"first\":\"Paul-Alexis\",\"last\":\"Dray\",\"middle\":[]},{\"first\":\"Sylvain\",\"last\":\"Lamprier\",\"middle\":[]},{\"first\":\"Benjamin\",\"last\":\"Piwowarski\",\"middle\":[]},{\"first\":\"Jacopo\",\"last\":\"Staiano\",\"middle\":[]}]", "venue": "ArXiv", "journal": "ArXiv", "publication_date": {"year": 2021, "month": 6, "day": 11}, "abstract": "Due to the discrete nature of words, language GANs require to be optimized from rewards provided by discriminator networks, via reinforcement learning methods. This is a much harder setting than for continuous tasks, which enjoy gradient flows from discriminators to generators, usually leading to dramatic learning instabilities. However, we claim that this can be solved by making discriminator and generator networks cooperate to produce output sequences during training. These cooperative outputs, inherently built to obtain higher discrimination scores, not only provide denser rewards for training, but also form a more compact artificial set for discriminator training, hence improving its accuracy and stability. In this paper, we show that our SelfGAN framework, built on this cooperative principle, outperforms Teacher Forcing and obtains state-of-the-art results on two challenging tasks, Summarization and Question Generation.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2106.06363", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/nips/ScialomDSLP21", "doi": null}}, "content": {"source": {"pdf_hash": "5d7d34abbc14739e40b53ec3c33a3c698a37e70e", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2106.06363v1.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "38e9ef4729263ad55ca5a55bf81fd53cf79406af", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/5d7d34abbc14739e40b53ec3c33a3c698a37e70e.txt", "contents": "\na Question of Cooperation for Language GANs\n\n\nThomas Scialom thomas@recital.ai \nSorbonne Universit\u00e9\nCNRS\nFrance reciTALLIP6, F-75005Paris, ParisFrance\n\nPaul-Alexis Dray \nSylvain Lamprier \nSorbonne Universit\u00e9\nCNRS\nFrance reciTALLIP6, F-75005Paris, ParisFrance\n\nBenjamin Piwowarski \nSorbonne Universit\u00e9\nCNRS\nFrance reciTALLIP6, F-75005Paris, ParisFrance\n\nJacopo Staiano \n\nCNRS\nFrance\n\na Question of Cooperation for Language GANs\nTo Beam Or Not To Beam: That is\nDue to the discrete nature of words, language GANs require to be optimized from rewards provided by discriminator networks, via reinforcement learning methods. This is a much harder setting than for continuous tasks, which enjoy gradient flows from discriminators to generators, usually leading to dramatic learning instabilities. However, we claim that this can be solved by making discriminator and generator networks cooperate to produce output sequences during training. These cooperative outputs, inherently built to obtain higher discrimination scores, not only provide denser rewards for training, but also form a more compact artificial set for discriminator training, hence improving its accuracy and stability. In this paper, we show that our SelfGAN framework, built on this cooperative principle, outperforms Teacher Forcing and obtains state-of-the-art results on two challenging tasks, Summarization and Question Generation.Preprint. Under review.\n\nIntroduction\n\nNatural Language Generation encompasses tasks such as Machine Translation, Summarization or Data To Text generation. The real life applications are numerous, but require highly reliable and fluent models. Despite significant advances, state-of-the-art models are still known to be de-generated, with outputs containing repetitions and even nonfactual information i.e. hallucination [13].\n\nAmong the culprits is a limitation of Teacher Forcing [38]: the loss is computed at a token level while the aim is to produce complete sequences. Moreover, while a single ground-truth reference is considered correct, several realizations of the same content may exist. Finally, the model is subject to Exposure Bias [28], i.e. a mismatch between training and inference distributions -in the latter, the model has no access to ground truth for the previously generated tokens. The literature has considered this mismatch responsible for the lower quality observed when generating longer sequences [2,16].\n\nTo overcome such Teacher Forcing limitations, a consensus has emerged: a sequence level objective should be introduced [28,42]. A body of work has proposed to use Reinforcement Learning (RL) with standard NLG metrics like BLEU [40] or ROUGE [24]. However, NLG metrics are known to not reflect well human judgement [22], which explains why the resulting models tend to be qualitatively worse than their MLE baselines [3]. To move toward less biased metrics, a natural alternative is to evaluate the output with a learned discriminator. An ideal discriminator would not be biased w.r.t. to its training set, and could therefore be considered as a perfect metric that matches human consensus. Note that discriminators are already reported to be highly accurate to distinguish human written texts from machine generated ones [32,44].\n\nIn light of this observation, two concurrent approaches have been explored: i) at training time, using Generative Adversarial Networks [43]; and ii) at inference time, via cooperative decoding [11]: a discriminator guides the search algorithm, such that the generator and the discriminator cooperate to select the generated tokens. These approaches pursue the same objective: producing texts more similar to what a human writes.\n\nBoth methodologies suffer from specific limitations. Cooperative decoding algorithms rely on a discriminator that re-ranks a limited set of candidates selected by the generator. 1 Hence, cooperative decoding algorithms are limited by the generator ability to rank relevant tokens in a good enough position. On the other hand, language GANs are learned via reinforcement learning due to the discrete nature of text. This makes them particularly unstable to train, and usually fall short compared to Teacher Forcing [3]. In standard Language GANs, the discriminator provides a reward for the entire sequence, which can be difficult to exploit by the generator due to its sparsity [6].\n\nIn this paper, we propose SelfGAN, a framework to learn language GANs in a Self -training process where the signal from the discriminator is passed to the generator in a completely new way. We consider cooperative algorithms as a way to infuse the discriminator signal. We start from a simple observation: outputs obtained via cooperative decoding are more human-like, compared to their generator-only counterparts. Inspired by recent knowledge distillation approaches, we propose to consider cooperative outputs as targets in a Teacher Forcing training process: cooperative decoding stands as a teacher we attempt to imitate through the generator network. Just like a standard GAN, both the generator and the discriminator are trained at each step. While the generator improves, it becomes adversarial to the discriminator, which benefits from the cooperative generation. The discriminator, now trained on improved sequences, also contributes to improve the cooperative generation, and so forth. Note that in SelfGANs the discriminator is only used to drive the cooperative generation and never to provide a reward signal like in standard Language GANs.\n\nSelfGAN can be implemented with any cooperative decoding algorithm. Current cooperative approaches [7,32] rely on \"myopic\" algorithms like Beam Search or Sampling that generate the tokens left-to-right. The model has to always predict the next word, and can never look back and revise past choices. In some cases, despite all the candidates being judged to likely not be human by the discriminator, the model is locked in a dead-end. This behavior is quite unnatural for humans -who often proofread their texts. We refer to this phenomenon as the left-to-right curse.\n\nTo address this left-to-right curse, we introduce Coop-MCTS, a new decoding algorithm based on Monte Carlo Tree Search (MCTS) [5,14]. We compare Coop-MCTS to state-of-the-art cooperative decoding algorithms in two scenarios: i) inference time, as the decoding algorithm; and ii) during training, as the cooperative algorithm in SelfGAN. In both scenarios, we show that the respective resulting outputs are more likely to look like human texts and improve all the automatic metrics.\n\nAll in all, our contributions can be summarized as follows:  [2] proposed to condition the generation not only on the ground truth tokens, but also the generated ones. Given that only one reference is available, this introduces a new mismatch when computing the loss, this time between the generated tokens used to condition the model, and the target tokens. To take into account multiple possible references, using a sequence level metric is a potential alternative. In Mixer, Ranzato et al. [28] chose BLEU, the standard metric to evaluate Machine Translation. Since it is not differentiable, the task is framed in a Reinforcement Learning setup where the reward corresponds to the BLEU score given a sampled sequence of tokens. Paulus et al. [24] applied the same method to Summarization, using this time ROUGE. While the results improved in terms of ROUGE, the human evaluation found that the generated summaries were rated worse in term of fluency than the MLE baseline. The model learns to take advantage of metric biases, while being less correct according to human judgement.\n\nLanguage GANs In theory, a perfect discriminator would be able to judge if an output corresponds to the data distribution or not. Discriminators could therefore be an interesting alternative reward compared to other metrics. In practice, we need to train the discriminator jointly with the generator, framing the task as a GAN. Language GANs are known to underperform MLE [3], due to the unavoidable sparsity of a discriminator reward. A large body of works have proposed denser rewards: ranking or comparative discriminators [4,18,46], a sequential discriminator where the rewards are provided at each time step of the generation [35,6]. More recently, Scialom et al. [31] proposed to stabilize the GAN training by lowering the Softmax temperature to explore more structured outputs, and closer to the generator distribution.\n\nIn this work, our proposed framework allows to propagate the discriminator signal in a cooperative way, which can be seen as an alternative solution to the sparsity of the reward and the training stability.\n\nKnowledge Distillation SelfGAN has a connection with knowledge distillation [12], where a student is trained on outputs from the teacher. In particular, self distillation using only a generator has shown to improve generalisation on image GANs [45] by acting as label smoothing. To the best of our knowledge, this work is the first to propose the idea of augmenting the teacher by coupling a discriminator to a generator. Beyond GANs, SelfGAN could serve for other applications using distillation, e.g. in semi-supervised methods that use a teacher model to create synthetic labels for unlabeled examples [33,41].\n\nMonte Carlo Tree Search in NLG Despite important successes in games [30,37], very few works have attempted to apply MCTS to NLG. Kumagai et al. [15] proposed to employ context-free grammar rules combined with a n-gram language model and explore the space of grammatically correct texts via a MCTS. In the context of commercial e-commerce agents, Mukherjee [20] proposed to optimise with a MCTS a scoring function designed to reward grammatical correctness. The difficulty of GAN-based approaches for NLP tasks lies in the fact that no gradient flow can be propagated from the discriminator to the generator. As discussed above, approaches from the literature circumvent this difficulty by employing RL approaches, using discriminator scores as rewards to train the generator. However, such approaches induce great instabilities in the learning process, due to the use of a non-stationary reward function in addition to the high variance associated to monte-carlo estimations of RL.\n\nThe idea in our SelfGAN approach is to transfer the sparse signal of the discriminator, classically used as rewards for a RL procedure, to the sampling mechanism of sequences that have to be favored through MLE. In that way, SelfGAN starts from a pretrained generator, that we fine-tune using sequences S coop provided by a cooperative decoding process decod coop for each condition in the training set X. This process, detailed in the next section, uses both the generator and a discriminator network to output human-like sequences S coop , for which we improve the generator likelihood via classical maximization: max \u03b8 (x,s)\u2208(X,Scoop) \u03c0 \u03b8 (s|x), where \u03c0 \u03b8 (s|x) = |s| t=1 \u03c0 \u03b8 (s t |s 0:t\u22121 , x) stands for the generator probability of sequence s given the conditioning input x, with \u03c0 \u03b8 implemented as a neural architecture with a softmax output function.\n\nAt each iteration of the training procedure, the discriminator network is optimized as a binary classifier on i) the human references and ii) the machine generated via the cooperative sequences:\n1 |H| (x,s ref )\u2208H log(D(x, s ref )) + 1 |G| (x,scoop)\u2208G log(1 \u2212 D(x, s coop ))\nwhere x is the source input, H is the set of pairs associating x with a human written text s ref from the data distribution, and G is a set of pairs with generated outputs s coop . D(x, s) stands for the probability, provided by the discriminator network, that sequence s is a human reference for condition x. In order to effectively guide the cooperative process at each step, the discriminator needs to be sequential: consistently with [32], we use a left-to-right mask during training, allowing discriminator predictions for unfinished sequences.\n\nPlease note that, by construction of the cooperative decoding process, we have with high probability at each iteration D(x, s coop ) >= D(x, s gen ) for any condition x \u2208 X, with s coop a cooperative decoded sequence for x and s gen a sequence directly sampled from the generator according to \u03c0 \u03b8 (s|x).\n\nBased on this observation, and provided that the discriminator is sufficiently trained at each step, the generator is trained such that the probability of predicting human-like sequences is maximized. This process i) allows us to consider a sequence level metric, and ii) offers more stability compared to Reinforcement Learning, as we observe in our experiments (see section 6). Note also that, contrary to RL approaches which have to find a good balance between discriminator and generator capacities, our approach does not suffer from Vanishing Gradient [1], since discrimination is only used for decoding, in a cooperative process for generator training. We depict the SelfGAN in Algorithm 1. Sampling To obtain diverse outputs, it is common to sample tokens from the model distribution.\n\nIn particular, this is mandatory when there is no input at all, i.e. Unconditional NLG, for instance GPT [25]. However, the longer the sequence, the more likely to sample a token from the tail of the distribution, causing degeneration [13]. To mitigate this issue, common practices are to lower the Softmax Temperature and keeping only the Top K tokens [10] / the Top P probability mass [13].\n\nBeam Search is the standard algorithm to approximate the sequence maximising the output probability, by maintaining K candidates at each step. Its usage suits better conditional NLG tasks, where the diversity arises from the variety of conditioners inputs, e.g. in Summarization.\n\n\nCooperative Decoding: Combining a Discriminator and a Generator\n\nSubject to exposure bias, neither Sampling or Beam Search are satisfying: the outputs produced are easily identified by a discriminator [32], indicating that they differ from human written text. In light of this, two concurrent works have recently proposed to use the discriminator during the decoding.\n\n\nDAS local -Reranking Step By\n\nStep In Discriminative Adversarial Search [32] a discriminator re-ranks the sub-sequence candidates at each decoding step of a Beam Search, in order to favor human-like outputs.\n\nDAS global -Reranking Complete Sequences In a concurrent work [7] a very similar cooperative method is proposed: this time, N complete sequences are sampled from the auto-regressive model. The N sequences are scored by a discriminator, allowing to select the one with the highest probability to be human-like. Since the discriminator re-ranking is computed on a complete sequence, we refer to this method as DAS global , as opposed to DAS local .\n\n\nCoop-MCTS: Cooperative Decoding beyond the Left-To-Right Curse\n\nIt can happen that all sequence candidates are judged by the discriminator to be machine-like rather than human-like. In such case, the cooperative decoding is stuck in a dead end; such limitation is unsatisfactory. Neither DAS local or DAS global have the ability to revise their previous decisions.\n\nTo cope with those limitations of myopic decoding strategies, we propose to consider an adaptation of MCTS for NLG. Just like in the context of games [37], we consider a policy network \u03c0, the generator, that outputs a probability over all the possible actions (tokens) at each step of the sequence. The discriminator D corresponds to the value network. In MCTS, the trajectories are explored to build a tree following three steps:\n\n1. Selection starting from the root, children nodes tokens \u03c9 are selected among the vocabulary V recursively w.r.t. the PUCT algorithm [29,37]:\n\u03c9 = arg max \u03c9\u2208V Q(s, \u03c9) + c puct \u03c0 \u03c4 (\u03c9 | s) b N (s, b) 1 + N (s, \u03c9)(1)\nwhere Q is the value of taking action \u03c9 a in state s: in NLG, this corresponds to selecting a token among the vocabulary at step i given the source context and the sub-sequence \u03c9 0 , ..., \u03c9 i\u22121 . c puct is a constant, \u03c4 the temperature that scales the Softmax, and N (s, \u03c9) the number of times the token \u03c9 has been chosen in state s. We stop the loop when a node s o has not been expanded yet, i.e. the discriminator D has not calculated its value.\n\n\nExtension\n\nGiven the selected node, we calculate the distribution probability from the generator \u03c0(\u03c9 | s o ). We apply nucleus sampling [13] to filter out the less likely tokens and reduce the number of actions. The remaining tokens constitute the children nodes, associated to their corresponding probability. At the same time, we calculate the value of the current state D(s o ) that allows to compute the backup step.\n\n3. Backup we update Q for all the nodes that led to s o such that Q \u2190 max (Q, D (s o )). Note that we choose to use the max instead of the average for the following reason: the value network, i.e. a discriminator, becomes more accurate as the candidate sequence grows (see Figure 2 in [32]), hence if a long sequence is judged human by the discriminator, any of its sub-sequences should be considered human-like as well. In contrast, a long sequence can be machine-like despite starting in a very human-like manner: the beginning sub-sequence should keep its human-like score.\n\nThese three steps are computed for a restricted number of simulations. Then, the next token corresponds to the root child with the most visit counts. The process continues step by step to generate the next token, until reaching either the special token End Of Sentence, or the maximum length.\n\n\nExperimental Details\n\n\nDatasets\n\nTo measure the effectiveness of SelfGAN, we experiment on two standard conditional NLG tasks: Question Generation (QG) and Summarization, consistently with previous works [8,31]:\n\n\u2022 Question Generation: we used the SQuAD dataset [27], consisting of 100K triplets of Wikipedia paragraphs, factual questions, and their answers. \u2022 Summarization: we used the CNN/Daily Mail dataset (CNNDM) [21], consisting of 300K news articles, paired with their corresponding summaries. The summaries are formed of multiple sentences, making the amount of tokens to generate much larger than for Question Generation.\n\n\nModels Reported\n\nMLE the first baseline we consider is a standard model trained via teacher forcing. As for all our experiments, we initialised the seq2seq with T5 [26], as detailed in Section 5.4.\n\nColdGAN we consider as a second baseline the current state-of-the art for language GANs, ColdGAN [31]. The authors proposed to lower the temperature when sampling the sequences during training, with the objective of stabilizing the training process.\n\nSelfGAN can be based on any cooperative decoding algorithm. To train SelfGAN, we therefore experiment the three different cooperative algorithms described in Section 4 (DAS Local , DAS Global , and Coop-MCTS) and report the results for the corresponding SelfGAN: SelfGAN DAS-Local , SelfGAN DAS-Global , and SelfGAN Coop-MCTS .\n\nDecoding Method at inference time For each model, any decoding method can be applied at inference time, independently from the training scheme. Therefore, for all the models described above, we report the results given each decoding method previously described (Section 4): Beam Search, DAS Local , DAS Global , and Coop-MCTS.\n\nTo the best of our knowledge, GANs and Cooperative decoding have never been directly compared before this work. A fortiori, this is the first time that a GAN model is tested with a Cooperative decoding method at inference. We investigate possible distillation effects in Section 6.\n\n\nMetrics\n\nTo compare the different models, we report two type of metrics: n-gram based and discriminator.\n\nN-gram based We report the standard BLEU [23] and ROUGE [19]. Both measure an overlap of n-grams between the reference and the evaluated text. They differ in that BLEU is precision oriented while ROUGE is rather recall oriented.\n\nDiscriminators Both BLEU and ROUGE suffer from the aforementioned limitations. We therefore propose to consider discriminators for model evaluation. Intuitively, they measure how model outputs are similar to what a human would have written. We consider two different discriminators:\n\n\u2022 Base is a discriminator trained on the MLE baseline outputs generated via beam search. It allows to measure the corresponding improvement from the MLE baseline. Note that it corresponds to the initial discriminator in all the GANs experiments, and the discriminator used in the cooperative search for the MLE baseline.\n\n\u2022 Base+ Since the Base discriminator plays a role in all our experiments (except MLE+Beam Search), it is possible that a model that makes use of this Base obtains better Base results, despite bringing new biases and de-generation behaviors. For this reason, we also report Base+, a discriminator fine-tuned on all the different model outputs together. Base+ is never used by any model at training or inference time. It is thus more robust toward an undesirable adversarial generation mode, while still being comparable for the different experiments. We argue that a higher Base+ score indicates a real improvement beyond potential bias.\n\n\nImplementation Details\n\nFor all experiments, we used the T5-small [26] architecture. 2 Using 4 Nvidia V100 SXM2 GPUs, SelfGAN Coop-MCTS training and evaluation takes respectively 26 hours and 1 hour on CNN/DM; 6 and 0.5 hours on SQuAD. Compared to 2 (0.5) hours to train via MLE on CNN/DM (SQuAD), we identify in the computational cost the main limitation of our work.\n\n\nResults and discussion\n\nIn Table 1, we report the results for all the previously trained generators, with the different decoding algorithms presented in Section 4. By 'model', in the following, we refer to the couple composed by a trained generator and a decoding algorithm.\n\nWe report BLEU4, ROUGE-1, ROUGE-L along with scores for the discriminators Base and Base+, computed as the percentage of outputs considered as human by a given discriminator model. Base was only trained on MLE+Beam Search outputs. As expected, by further training on the outputs generated by all the different models, Base+ has a higher accuracy, which consistently results in lower scores compared to Base.\n\nWe start by focusing on the MLE results to compare the different decoding mechanisms. We observe that all the cooperative searches outperform Beam Search. Regarding Base and Base+ metrics,   Human-like features during training In NLG, various rules are often integrated into the Beam Search to improve the quality of the outputs, for instance a length penalty [34] or an interdiction for 3-grams repetitions [24,8]. Such a need to hard code these rules indicates a discrepancy between the human output characteristics and what the model has learned. In particular, Scialom et al. [32] reported the difference between DAS and the human reference for: i) Length: the average number of tokens per output; ii) Novelty: percentage of tokens in the output that were not present in the source text; iii) N-gram repetition: percentage of N-grams that occur more than once in the output. To measure how SelfGAN learns these features by itself, we report in Figure 1 the evolution of these statistics during training: we observe that SelfGAN constantly reach statistics more similar to human references than ColdGAN.\n\n\nHuman Evaluation\n\nWe conduct a human evaluation to measure the models performances beyond automatic metrics. We limit the evaluation to three generators (MLE, ColdGAN, and SelfGAN Coop-MCTS) and two decoding methods (Beam Search and Coop-MCTS), for a total of 6 different models. Three professional English speakers rated 300 sampled summaries and followed the same protocol from Fabbri et al. [9]. Four dimensions are evaluated on a Likert scale from 1 to 5 (the higher the better): 1. Consistency: the proportion of facts in the summary correct w.r.t. the source text; 2. Coherence: how well-structured and well-organized is the summary; 3. Fluency: how fluent the summary is to read; 4. Relevance: the ratio between important and excess information in the summary.\n\nFrom Table 2 we observe significantly better results for SelfGAN Coop-MCTS w.r.t. both MLE and ColdGAN. While Coop-MCTS decoding appears overall beneficial in terms of Coherence and Relevance, but scores lower on Consistency and Fluency, its combination with SelfGAN Coop-MCTS allows to obtain significant improvements on the former two dimensions while still maintaining comparable scores on the latter.\n\nAnalysis To further understand the benefits of selfGAN, we propose to analyze the evolution of the generator and discriminator networks through the learning process. In figure 2 (left), we first plot the average magnitude (L2 norm) of the discriminator gradients w.r.t. its parameters. We observe that ColdGAN induces important instabilities for its discriminator over time, with a highly fluctuating gradient magnitude. Conversely, thanks to its cooperative decoding process, SelfGAN produces sequences that form a more compact set for discriminator training, a variance of gradient magnitude twice lower than ColdGAN , for a comparable magnitude in average. This discriminator stability is a first explanation for the improvements of the proposed approach.\n\nIn a second plot, given on the right of Figure 2, we report the collinearity of generator gradients for the generated samples from the model with those for the corresponding human references. Higher values Step 01: What ...\n\nStep 16: What was the name of the game that would have been known as \"Super Bowl\n\nStep 17: How ...\n\nStep 46: How is called the American football game that determines the NFL champion? Table 3: Progressive results obtained by our Coop-MCTS decoding method on Question Generation during a simulation. Until the 16th step, the generation is left-to-right. Then, the cooperation mechanism kicks in, allowing the model to safely abort this beam, by restarting a new question with How. We report the cross-attention weights on the input context for step 16 (red) and 17 (blue).\n\nindicate sampling strategies that induce a useful gradient flow for the generator. For ablation purposes, we first report values for a \"SelfGAN BeamSearch \" approach, where we used a standard Beam Search to generate the training examples: note that it has no discriminator, hence it is not a GAN anymore. We can observe its divergence, as opposed to SelfGAN Coop-MCTS , which emphasizes the importance of the cooperative decoding for producing the example used to train the model. For SelfGAN Coop-MCTS and ColdGAN, the gradients become more co-linear with human references through time, indicating a convergence of the process towards the human distribution. We observe that SelfGAN Coop-MCTS produces more useful sequences for achieving this convergence.\n\nCoop-MCTS as an alternative to the dead-end search When analysing the behavior for the Coop-MCTS decoding, we observed in different examples that it provides an effective mean to revise generations that eventually ended up to be unlikely. To illustrate this, we report in Table 6 the different MCTS steps for an ambiguous example: the conditioned answer, Super Bowl, occurs at different places of the the input. Therefore, the model has to decide which specific mention of Super Bowl to focus on: at step 17, it considers its current generation as a dead end and decides to start on new node (How). The final output is a question that arguably sounds better than the initial one.\n\nSocietal Impact Reliable NLG models can have significant societal impact with beneficial applications such as efficient information access via automatic summarization or personalized student evaluation through question generation. Still, malicious actors can use the same technology to build tools detrimental to society, e.g. large scale creation of misleading (fake) news [25]. As argued by Zellers et al. [44], keeping this research open and under public scrutiny can be an effective defense.\n\n\nConclusion\n\nIn this paper we propose SelfGAN, a new framework to train Generative Adversarial Networks based on a cooperative decoding search. To overcome the left-to-right curse that limits standard search algorithms, we propose Coop-MCTS. We conducted extensive experiments on two challenging tasks: Summarization and Question Generation, obtaining state-of-the-art performance for SelfGAN both in terms of automatic metrics and within a human evaluation. As the stability of the discriminator looks to be crucial for language GANs, we plan for future works to still focus on increasing it through the definition of dynamic regularization mechanisms.\n\nWe tested on a validation set different values for our hyper parameter C puct \u2208 [1.0, 2.0, 3.0, 4.0] and found that 3.0 gives the best results. We thus only report the results with C puct = 3.0. For the budget allocated to the MCTS we tested different number of simulations per token for the MLE model with (n \u2208 [5, 10, 25, 50, 100] and observed no significant improvement between 50 and 100. We hence used n = 50 for all our experiments.\n\nWe used 4 Nvidia V100 SXM2 GPUs for this project. SelfGAN Coop-MCTS training and evaluation takes respectively 26 hours and 1 hour on CNN/DM; 6 and 0.5 hours on Question Generation.\n\nA.2 Differences with [17] In a concurrent work Leblond et al. [17] proposed MCTS as an alternative to Beam Search. There are two differences with our work.\n\nFirst, the authors limit their study to MCTS as a decoding algorithm at inference time, and use a standard generator trained via MLE.\n\nSecondly, for the value network in the MCTS, they proposed to optimise a static metric, the BERTScore. However, we argue that these metrics are not reflecting human judgement [22], and models that maximise them are found to perform poorly [24]. Therefore, in their setup, improving BERTScore does not mean that the resulting model is better. Conversely, we chose a dyanmic metric, i.e. A discriminator, for our value network in our proposed Coop-MCTS, or any other cooperative decoding algorithm.\n\n\nA.3 Cooperation VS Competition\n\nSelfGAN can be seen as an implicit solution for the reward sparsity problem, whereby the gradient from the reward is not tractable in language GANs. Conversely to prior works that have focused on denser rewards, in SelfGAN the sequence generation is directly driven by the discriminator to produce s coop .\n\nIn addition, standard GANs are known to be particularly unstable for several reasons. In particular, a fine balance has to be found between the generator and the discriminator performance. If the discriminator becomes too strong compared to the generator, the reward is null, a phenomenon known as the Vanishing Gradient [1]. We emphasize that our proposed approach does not suffer from Vanishing Gradient: while the discriminator improves, the cooperative generation improves as well.\n\nGiven that D(s coop ) >= D(s gen ), the generator will almost surely improve when trained on s coop , for a large number of training steps, as long as the discriminator has an advantage, without requiring it to be optimal.\n\n\nA.4 Beyond A Unique Reference\n\nIn NLG, given an input, there are arguably many different possible outputs. To illustrate this, we measure the score for human written summaries compared to other gold-references: in average it obtains a ROUGE-1 of only 29.5 (std: 5.2). 4 This indicates that humans are likely to produce different sequences when given the same input. In particular, the probability to write the same exact sequence than the only gold-reference available in the training set is very low.\n\nShould this behavior be penalized? Obviously not. And yet, this is what happens under Teacher Forcing, where, during training, any generated token that is different from the target will increase the loss. The model can therefore be exposed to contradictory information, which might limit its effectiveness. Note that this issue does not apply to a discriminator, as only two output categories (machine or human) are possible.\n\nWe argue that SelfGAN offers a theoretical solution to this multi-reference limitation. Lets denote S human the universe of possible correct outputs, where s ref \u2208 S human . Then, given a perfect discriminator (optimal to distinguish real data distribution from a different distribution), and an infinite computational capacity, we have s coop \u2208 S human . Indeed, given an infinite computational capacity, all the possible sequences can be explored. A perfect discriminator classifies a sequence s as human only if s \u2208 S human . It results that s coop \u2208 S human : the sequence generated via a cooperative mechanism is guaranteed to be indistinguishable from any human output, just like the reference.\n\nIn addition, since the generator probability is also taken into account in a cooperative decoding, we have s coop = argmax(P \u03c0 (S human )). We note that this is guaranteed only if all possible sequences are explored via an infinite computation. If we stop searching when one sequence is accepted by the decoder, it is pseudo-guaranteed since a Beam Search is only an approximation of the argmax. s coop is the sequence among all the human sequences that maximise the likelihood according to the generator \u03c0. Therefore, is the generator outputs a human-level sequence (i.e. s \u2208 S human ), is will actually correspond to s coop . It results that considering s coop as the gold-reference in Teacher Forcing, the generator will not be subject to an artificial loss.\n\nIn conclusion, SelfGAN can be interpreted as a generalisation of Teacher Forcing that takes into account the multiple possible references and trains the model on the reference the highest to its likelihood.\n\n\nA.5 Human Validation\n\nRaters for the human validation study devoted in average 5 hours to the task and were rewarded with vouchers.\n\n\nPractices: Generator-only At decoding time, two different approaches are commonly used in NLG: Sampling and Beam Search. They respectively correspond to two different objectives.\n\nFigure 2 :\n2Left: Moving Average of the magnitude of the discriminators gradients during training. Right: collinearity of the generators gradients between the sampled texts and their corresponding human reference for SelfGAN Coop-MCTS , ColdGAN and SelfGAN BeamSearch . Both on Summarization. Conditioned Answer: Super Bowl Context: Super Bowl 50 was an American football game to determine the champion of the National Football League (NFL) for the 2015 season. The American Football Conference (AFC) champion Denver Broncos defeated the National Football Conference (NFC) champion Carolina Panthers 24\u00e2\u20ac\"10 to earn their third Super Bowl title. The game was played on February 7, 2016,at Levi's Stadium in the San Francisco Bay Area at Santa Clara, California. As this was the 50th Super Bowl, the league emphasized the \"golden anniversary\" with various gold-themed initiatives, as well as temporarily suspending the tradition of naming each Super Bowl game with Roman numerals (under which the game would have been known as \"Super Bowl L\"), so that the logo could prominently feature the Arabic numerals\n\n1 .\n1SelfGAN We propose a new training framework based on cooperative decoding, wherein the generated sequences are used as ground truth; 2. Coop-MCTS We improve cooperative decoding with a new decoding algorithm, Coop-MCTS, offering a solution to the left-to-right limitation of current search methods; 3. We show that combining SelfGAN and Coop-MCTS compare favorably to prior state-of-theart results on two challenging tasks, Summarization and Question Generation. Beyond Teacher Forcing To mitigate the limitations inherent to Teacher Forcing, various alternatives have been proposed. In Scheduled Sampling, Bengio et al.2 Related Work \n\n\n\nTable 1 :\n1Results of our experiments on QG (left) and Summarization (right). For each generator, we report the results with the four different decoders. The reported metrics correspond to BLEU4, ROUGE-1, ROUGE-L and the discriminators Base and Base+ as described in Section 5.3. For Base and Base+ the scores correspond to the probability of being human, so higher is better for all the metrics. For SelfGAN MCTS , we experimented with 5 different seeds and the standard deviation is always inferior to 0.1 for BLEU4 and ROUGE, and inferior to 0.5% for Base and Base+. DAS Local compares favorably to DAS Global . We hypothesize that invoking the discriminator to rank at each step can have more impact than using it only once on fully decoded sequences. Finally, our proposed Coop-MCTS obtains the best results by a large margin.Regarding the different GANs, we first compare them given the default decoding mechanism, i.e. Beam Search. The three version of SelfGAN compare favorably to MLE and ColdGAN on both n-gram based metrics and discriminators metrics. Among SelfGANs, SelfGAN Coop-MCTS obtains the Both GAN at training time and Cooperative decoding at inference time pursue the same objective: to obtain better outputs that look like human texts. Would a generator trained via GAN, coupled with a Cooperative Decoding mechanism for inference result into a cumulative improvement from the two methods? First, on both ColdGAN and three SelfGANs, we can observe that adding a Cooperative Decoding method allows to gain significant improvement on Base and Base+. In particular, it is interesting to note that for SelfGAN an additional pattern seems to emerge: using the same cooperative decoding algorithm both during training and inference seems to provide additional gains. The best performance is achieved with the generator SelfGAN Coop-MCTS paired with the decoding Coop-MCTS. Compared to MLE via Beam Search, it obtains a final improvement superior to 1 point in term of ROUGE and BLEU. The relative improvement for Base+ is significant: from 15.2% to 26.2% on QG and from 8.6% to 15.3% on Summarization. This corresponds to almost twice more outputs that sound human according to the Discriminator metric.best results: given a Beam Search decoding, it obtains the best BLEU, ROUGE-1 and ROUGE-L \non the two tasks (respectively 17.2; 44.3; 40.6 on QG and 12.3; 38.6; 36.7 on Summarization). The \nperformance in term of Base and Base+ for SelfGAN Coop-MCTS is even more important in comparison \nto the other models (34.1%; 21.9% on QG and 20.2%; 12.7% on Summarization). \n\n\n\nTable 2 :\n2Human Evaluation on Summarization. Two tailed t-test results are reported for each model \ncompared to MLE+BeamSearch (*: p < .01, **: p < .001). \n\n\nOpposed to a generator that outputs probabilities for the entire vocabulary V at once, a discriminator outputs the likelihood for a specific sequence to be human-written or machine-generated. Calculating the discriminator probability for every possible sequence is therefore not realistic, as the computation grows exponentially at a pace of V l where V is the vocabulary size and l the sequence length.\nAs implemented in HuggingFace transformers[39].\nAs implemented in HuggingFace transformers[39].\nWe used a validation set of 100 articles from the CNN/DM corpus paired with 11 different gold-references released by Fabbri et al.[9].\nAcknowledgmentsThis work was partially performed using HPC resources from GENCI-IDRIS (Grant 2021-AD011012318).A AppendixA.1 Implementation DetailsIn MCTS, sequence lengths are not aligned as in a standard left-to-right decoding algorithm. Therefore, we used a simple trick to enable efficient batching of sequences, that can be applied to any Language Model benefiting from a relative positional embedding[36]. We used a custom left padding that shifts the start of each sequences from a batch, so that all of their last tokens are aligned. In all our experiments, we used the T5-small[26]generator, 3 in which the embedding is relative.For the discriminators, we frame the classification task as a text2text task where the model has to generate either the token human or machine. This allows to use again T5-small for all experiments, removing possible bias from architecture differences between the generator and the discriminator.We start by training via Teacher Forcing a model corresponding to the MLE baseline. All our GANs are initialized from this MLE model. During training, we used a learning rate fixed to 5e-6 for both the discriminator and the generator, and a number of epochs set to 5.\nTowards principled methods for training generative adversarial networks. M Arjovsky, L Bottou, arXiv:1701.04862arXiv preprintArjovsky, M. and Bottou, L. Towards principled methods for training generative adversarial networks. arXiv preprint arXiv:1701.04862, 2017.\n\nScheduled sampling for sequence prediction with recurrent neural networks. S Bengio, O Vinyals, N Jaitly, N Shazeer, Advances in Neural Information Processing Systems. Bengio, S., Vinyals, O., Jaitly, N., and Shazeer, N. Scheduled sampling for sequence prediction with recurrent neural networks. In Advances in Neural Information Processing Systems, pp. 1171-1179, 2015.\n\nLanguage gans falling short. M Caccia, L Caccia, W Fedus, H Larochelle, J Pineau, L Charlin, International Conference on Learning Representations. Caccia, M., Caccia, L., Fedus, W., Larochelle, H., Pineau, J., and Charlin, L. Language gans falling short. In International Conference on Learning Representations, 2020. URL https://openreview.net/forum?id=BJgza6VtPB.\n\nT Che, Y Li, R Zhang, R D Hjelm, W Li, Y Song, Y Bengio, arXiv:1702.07983Maximum-likelihood augmented discrete generative adversarial networks. arXiv preprintChe, T., Li, Y., Zhang, R., Hjelm, R. D., Li, W., Song, Y., and Bengio, Y. Maximum-likelihood augmented discrete generative adversarial networks. arXiv preprint arXiv:1702.07983, 2017.\n\nEfficient selectivity and backup operators in monte-carlo tree search. R Coulom, International conference on computers and games. SpringerCoulom, R. Efficient selectivity and backup operators in monte-carlo tree search. In Interna- tional conference on computers and games, pp. 72-83. Springer, 2006.\n\nTraining language gans from scratch. C De Masson D&apos;autume, S Mohamed, M Rosca, Rae , J , Advances in Neural Information Processing Systems. de Masson d'Autume, C., Mohamed, S., Rosca, M., and Rae, J. Training language gans from scratch. In Advances in Neural Information Processing Systems, pp. 4302-4313, 2019.\n\nResidual energy-based models for text generation. Y Deng, A Bakhtin, M Ott, A Szlam, M Ranzato, arXiv:2004.11714arXiv preprintDeng, Y., Bakhtin, A., Ott, M., Szlam, A., and Ranzato, M. Residual energy-based models for text generation. arXiv preprint arXiv:2004.11714, 2020.\n\nUnified language model pre-training for natural language understanding and generation. L Dong, N Yang, W Wang, F Wei, X Liu, Y Wang, J Gao, M Zhou, H.-W Hon, Advances in Neural Information Processing Systems. Dong, L., Yang, N., Wang, W., Wei, F., Liu, X., Wang, Y., Gao, J., Zhou, M., and Hon, H.-W. Unified language model pre-training for natural language understanding and generation. In Advances in Neural Information Processing Systems, pp. 13042-13054, 2019.\n\nA R Fabbri, W Kry\u015bci\u0144ski, B Mccann, C Xiong, R Socher, D Radev, Summeval, arXiv:2007.12626Re-evaluating summarization evaluation. arXiv preprintFabbri, A. R., Kry\u015bci\u0144ski, W., McCann, B., Xiong, C., Socher, R., and Radev, D. Summeval: Re-evaluating summarization evaluation. arXiv preprint arXiv:2007.12626, 2020.\n\nA Fan, M Lewis, Y Dauphin, arXiv:1805.04833Hierarchical neural story generation. arXiv preprintFan, A., Lewis, M., and Dauphin, Y. Hierarchical neural story generation. arXiv preprint arXiv:1805.04833, 2018.\n\nCooperative generator-discriminator networks for abstractive summarization with narrative flow. S Gabriel, A Bosselut, A Holtzman, K Lo, A \u00c7elikyilmaz, Y Choi, Gabriel, S., Bosselut, A., Holtzman, A., Lo, K., \u00c7elikyilmaz, A., and Choi, Y. Cooperative generator-discriminator networks for abstractive summarization with narrative flow. 2019.\n\nDistilling the knowledge in a neural network. G Hinton, O Vinyals, J Dean, arXiv:1503.02531arXiv preprintHinton, G., Vinyals, O., and Dean, J. Distilling the knowledge in a neural network. arXiv preprint arXiv:1503.02531, 2015.\n\nA Holtzman, J Buys, L Du, M Forbes, Y Choi, arXiv:1904.09751The curious case of neural text degeneration. arXiv preprintHoltzman, A., Buys, J., Du, L., Forbes, M., and Choi, Y. The curious case of neural text degeneration. arXiv preprint arXiv:1904.09751, 2019.\n\nBandit based monte-carlo planning. L Kocsis, C Szepesv\u00e1ri, European conference on machine learning. SpringerKocsis, L. and Szepesv\u00e1ri, C. Bandit based monte-carlo planning. In European conference on machine learning, pp. 282-293. Springer, 2006.\n\nHuman-like natural language generation using monte carlo tree search. K Kumagai, I Kobayashi, D Mochihashi, H Asoh, T Nakamura, T Nagai, Proceedings of the INLG 2016 Workshop on Computational Creativity in Natural Language Generation. the INLG 2016 Workshop on Computational Creativity in Natural Language GenerationKumagai, K., Kobayashi, I., Mochihashi, D., Asoh, H., Nakamura, T., and Nagai, T. Human-like natural language generation using monte carlo tree search. In Proceedings of the INLG 2016 Workshop on Computational Creativity in Natural Language Generation, pp. 11-18, 2016.\n\nA Lamb, A Goyal, Y Zhang, S Zhang, A Courville, Y Bengio, arXiv:1610.09038Professor forcing: A new algorithm for training recurrent networks. arXiv preprintLamb, A., Goyal, A., Zhang, Y., Zhang, S., Courville, A., and Bengio, Y. Professor forcing: A new algorithm for training recurrent networks. arXiv preprint arXiv:1610.09038, 2016.\n\nR Leblond, J.-B Alayrac, L Sifre, M Pislar, J.-B Lespiau, I Antonoglou, K Simonyan, O Vinyals, arXiv:2104.05336Machine translation decoding beyond beam search. arXiv preprintLeblond, R., Alayrac, J.-B., Sifre, L., Pislar, M., Lespiau, J.-B., Antonoglou, I., Simonyan, K., and Vinyals, O. Machine translation decoding beyond beam search. arXiv preprint arXiv:2104.05336, 2021.\n\nAdversarial learning for neural dialogue generation. J Li, W Monroe, T Shi, S Jean, A Ritter, Jurafsky , D , Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. the 2017 Conference on Empirical Methods in Natural Language ProcessingLi, J., Monroe, W., Shi, T., Jean, S., Ritter, A., and Jurafsky, D. Adversarial learning for neural dialogue generation. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pp. 2157-2169, 2017.\n\nRouge: A package for automatic evaluation of summaries. C.-Y Lin, Text summarization branches out. Lin, C.-Y. Rouge: A package for automatic evaluation of summaries. In Text summarization branches out, pp. 74-81, 2004.\n\nAn unsupervised approach to automatic response generation for conversational e-commerce agents using monte carlo tree search. S Mukherjee, Mukherjee, S. An unsupervised approach to automatic response generation for conversational e-commerce agents using monte carlo tree search. 2019.\n\nAbstractive text summarization using sequence-to-sequence rnns and beyond. R Nallapati, B Zhou, C Gulcehre, B Xiang, arXiv:1602.06023arXiv preprintNallapati, R., Zhou, B., Gulcehre, C., Xiang, B., et al. Abstractive text summarization using sequence-to-sequence rnns and beyond. arXiv preprint arXiv:1602.06023, 2016.\n\nWhy we need new evaluation metrics for NLG. J Novikova, O Du\u0161ek, A Cercas Curry, V Rieser, 10.18653/v1/D17-1238Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing. the 2017 Conference on Empirical Methods in Natural Language ProcessingCopenhagen, DenmarkAssociation for Computational LinguisticsNovikova, J., Du\u0161ek, O., Cercas Curry, A., and Rieser, V. Why we need new evaluation metrics for NLG. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, pp. 2241-2252, Copenhagen, Denmark, September 2017. Association for Computational Linguistics. doi: 10.18653/v1/D17-1238. URL https://www.aclweb.org/ anthology/D17-1238.\n\nBleu: a method for automatic evaluation of machine translation. K Papineni, S Roukos, T Ward, W.-J Zhu, Proceedings of the 40th annual meeting on association for computational linguistics. the 40th annual meeting on association for computational linguisticsAssociation for Computational LinguisticsPapineni, K., Roukos, S., Ward, T., and Zhu, W.-J. Bleu: a method for automatic evaluation of machine translation. In Proceedings of the 40th annual meeting on association for computational linguistics, pp. 311-318. Association for Computational Linguistics, 2002.\n\nA deep reinforced model for abstractive summarization. R Paulus, C Xiong, R Socher, arXiv:1705.04304arXiv preprintPaulus, R., Xiong, C., and Socher, R. A deep reinforced model for abstractive summarization. arXiv preprint arXiv:1705.04304, 2017.\n\nLanguage models are unsupervised multitask learners. A Radford, J Wu, R Child, D Luan, D Amodei, I Sutskever, OpenAI Blog. 189Radford, A., Wu, J., Child, R., Luan, D., Amodei, D., and Sutskever, I. Language models are unsupervised multitask learners. OpenAI Blog, 1(8):9, 2019.\n\nExploring the limits of transfer learning with a unified text-to-text transformer. C Raffel, N Shazeer, A Roberts, K Lee, S Narang, M Matena, Y Zhou, W Li, P J Liu, arXiv:1910.10683arXiv preprintRaffel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W., and Liu, P. J. Exploring the limits of transfer learning with a unified text-to-text transformer. arXiv preprint arXiv:1910.10683, 2019.\n\nSquad: 100,000+ questions for machine comprehension of text. P Rajpurkar, J Zhang, K Lopyrev, P Liang, Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing. the 2016 Conference on Empirical Methods in Natural Language ProcessingRajpurkar, P., Zhang, J., Lopyrev, K., and Liang, P. Squad: 100,000+ questions for machine comprehension of text. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing, pp. 2383-2392, 2016.\n\nM Ranzato, S Chopra, M Auli, W Zaremba, arXiv:1511.06732Sequence level training with recurrent neural networks. arXiv preprintRanzato, M., Chopra, S., Auli, M., and Zaremba, W. Sequence level training with recurrent neural networks. arXiv preprint arXiv:1511.06732, 2015.\n\nMulti-armed bandits with episode context. C D Rosin, Annals of Mathematics and Artificial Intelligence. 613Rosin, C. D. Multi-armed bandits with episode context. Annals of Mathematics and Artificial Intelligence, 61(3):203-230, 2011.\n\nMastering atari, go, chess and shogi by planning with a learned model. J Schrittwieser, I Antonoglou, T Hubert, K Simonyan, L Sifre, S Schmitt, A Guez, E Lockhart, D Hassabis, T Graepel, Nature. 5887839Schrittwieser, J., Antonoglou, I., Hubert, T., Simonyan, K., Sifre, L., Schmitt, S., Guez, A., Lockhart, E., Hassabis, D., Graepel, T., et al. Mastering atari, go, chess and shogi by planning with a learned model. Nature, 588(7839):604-609, 2020.\n\nColdgans: Taming language gans with cautious sampling strategies. T Scialom, P.-A Dray, S Lamprier, B Piwowarski, J Staiano, Advances in Neural Information Processing Systems. Scialom, T., Dray, P.-A., Lamprier, S., Piwowarski, B., and Staiano, J. Coldgans: Taming language gans with cautious sampling strategies. Advances in Neural Information Processing Systems, 2020.\n\nDiscriminative adversarial search for abstractive summarization. T Scialom, P.-A Dray, S Lamprier, B Piwowarski, J Staiano, arXiv:2002.10375arXiv preprintScialom, T., Dray, P.-A., Lamprier, S., Piwowarski, B., and Staiano, J. Discriminative adversarial search for abstractive summarization. arXiv preprint arXiv:2002.10375, 2020.\n\nProbability of error of some adaptive pattern-recognition machines. H Scudder, IEEE Transactions on Information Theory. 113Scudder, H. Probability of error of some adaptive pattern-recognition machines. IEEE Transac- tions on Information Theory, 11(3):363-371, 1965.\n\nGet to the point: Summarization with pointer-generator networks. A See, P J Liu, C D Manning, arXiv:1704.04368arXiv preprintSee, A., Liu, P. J., and Manning, C. D. Get to the point: Summarization with pointer-generator networks. arXiv preprint arXiv:1704.04368, 2017.\n\nOn accurate evaluation of gans for language generation. S Semeniuta, A Severyn, S Gelly, arXiv:1806.04936arXiv preprintSemeniuta, S., Severyn, A., and Gelly, S. On accurate evaluation of gans for language generation. arXiv preprint arXiv:1806.04936, 2018.\n\nSelf-attention with relative position representations. P Shaw, J Uszkoreit, A Vaswani, Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies2Short PapersShaw, P., Uszkoreit, J., and Vaswani, A. Self-attention with relative position representations. In Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers), pp. 464-468, 2018.\n\nMastering the game of go without human knowledge. D Silver, J Schrittwieser, K Simonyan, I Antonoglou, A Huang, A Guez, T Hubert, L Baker, M Lai, A Bolton, nature. 5507676Silver, D., Schrittwieser, J., Simonyan, K., Antonoglou, I., Huang, A., Guez, A., Hubert, T., Baker, L., Lai, M., Bolton, A., et al. Mastering the game of go without human knowledge. nature, 550(7676):354-359, 2017.\n\nA learning algorithm for continually running fully recurrent neural networks. R J Williams, D Zipser, Neural computation. 12Williams, R. J. and Zipser, D. A learning algorithm for continually running fully recurrent neural networks. Neural computation, 1(2):270-280, 1989.\n\nHuggingface's transformers: State-of-the-art natural language processing. T Wolf, L Debut, V Sanh, J Chaumond, C Delangue, A Moi, P Cistac, T Rault, R Louf, M Funtowicz, arXiv:1910.03771arXiv preprintWolf, T., Debut, L., Sanh, V., Chaumond, J., Delangue, C., Moi, A., Cistac, P., Rault, T., Louf, R., Funtowicz, M., et al. Huggingface's transformers: State-of-the-art natural language processing. arXiv preprint arXiv:1910.03771, 2019.\n\nGoogle's neural machine translation system. Y Wu, M Schuster, Z Chen, Q V Le, M Norouzi, W Macherey, M Krikun, Y Cao, Q Gao, K Macherey, arXiv:1609.08144Bridging the gap between human and machine translation. arXiv preprintWu, Y., Schuster, M., Chen, Z., Le, Q. V., Norouzi, M., Macherey, W., Krikun, M., Cao, Y., Gao, Q., Macherey, K., et al. Google's neural machine translation system: Bridging the gap between human and machine translation. arXiv preprint arXiv:1609.08144, 2016.\n\nUnsupervised word sense disambiguation rivaling supervised methods. D Yarowsky, 33rd annual meeting of the association for computational linguistics. Yarowsky, D. Unsupervised word sense disambiguation rivaling supervised methods. In 33rd annual meeting of the association for computational linguistics, pp. 189-196, 1995.\n\nL Yu, W Zhang, J Wang, Y Y Seqgan, arXiv:1609.05473Sequence generative adversarial nets with policy gradient. arxiv e-prints, page. arXiv preprintYu, L., Zhang, W., Wang, J., and SeqGAN, Y. Y. Sequence generative adversarial nets with policy gradient. arxiv e-prints, page. arXiv preprint arXiv:1609.05473, 2016.\n\nSequence generative adversarial nets with policy gradient. 489 in. L Yu, W Zhang, J Wang, Yu , Y S , AAAI conference on artificial intelligence. 490Yu, L., Zhang, W., Wang, J., and Yu, Y. S. Sequence generative adversarial nets with policy gradient. 489 in. In AAAI conference on artificial intelligence, volume 490, 2017.\n\nR Zellers, A Holtzman, H Rashkin, Y Bisk, A Farhadi, F Roesner, Y Choi, arXiv:1905.12616Defending against neural fake news. arXiv preprintZellers, R., Holtzman, A., Rashkin, H., Bisk, Y., Farhadi, A., Roesner, F., and Choi, Y. Defending against neural fake news. arXiv preprint arXiv:1905.12616, 2019.\n\nSelf-distillation as instance-specific label smoothing. Z Zhang, M Sabuncu, Advances in Neural Information Processing Systems. 33Zhang, Z. and Sabuncu, M. Self-distillation as instance-specific label smoothing. Advances in Neural Information Processing Systems, 33, 2020.\n\nSelf-adversarial learning with comparative discrimination for text generation. W Zhou, T Ge, K Xu, F Wei, M Zhou, International Conference on Learning Representations. Zhou, W., Ge, T., Xu, K., Wei, F., and Zhou, M. Self-adversarial learning with comparative discrimination for text generation. In International Conference on Learning Representations, 2020. URL https://openreview.net/forum?id=B1l8L6EtDS.\n", "annotations": {"author": "[{\"end\":152,\"start\":47},{\"end\":170,\"start\":153},{\"end\":260,\"start\":171},{\"end\":353,\"start\":261},{\"end\":369,\"start\":354},{\"end\":383,\"start\":370}]", "publisher": null, "author_last_name": "[{\"end\":61,\"start\":54},{\"end\":169,\"start\":165},{\"end\":187,\"start\":179},{\"end\":280,\"start\":270},{\"end\":368,\"start\":361}]", "author_first_name": "[{\"end\":53,\"start\":47},{\"end\":164,\"start\":153},{\"end\":178,\"start\":171},{\"end\":269,\"start\":261},{\"end\":360,\"start\":354}]", "author_affiliation": "[{\"end\":151,\"start\":81},{\"end\":259,\"start\":189},{\"end\":352,\"start\":282},{\"end\":382,\"start\":371}]", "title": "[{\"end\":44,\"start\":1},{\"end\":427,\"start\":384}]", "venue": null, "abstract": "[{\"end\":1421,\"start\":460}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b12\"},\"end\":1823,\"start\":1819},{\"attributes\":{\"ref_id\":\"b37\"},\"end\":1884,\"start\":1880},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":2146,\"start\":2142},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2425,\"start\":2422},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":2428,\"start\":2425},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":2554,\"start\":2550},{\"attributes\":{\"ref_id\":\"b41\"},\"end\":2557,\"start\":2554},{\"attributes\":{\"ref_id\":\"b39\"},\"end\":2662,\"start\":2658},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":2676,\"start\":2672},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":2749,\"start\":2745},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":2850,\"start\":2847},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":3256,\"start\":3252},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":3259,\"start\":3256},{\"attributes\":{\"ref_id\":\"b42\"},\"end\":3401,\"start\":3397},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":3459,\"start\":3455},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":3871,\"start\":3870},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":4209,\"start\":4206},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":4373,\"start\":4370},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":5634,\"start\":5631},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":5637,\"start\":5634},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":6230,\"start\":6227},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":6233,\"start\":6230},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":6648,\"start\":6645},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":7081,\"start\":7077},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":7333,\"start\":7329},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":8044,\"start\":8041},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":8198,\"start\":8195},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":8201,\"start\":8198},{\"attributes\":{\"ref_id\":\"b45\"},\"end\":8204,\"start\":8201},{\"attributes\":{\"ref_id\":\"b34\"},\"end\":8304,\"start\":8300},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":8306,\"start\":8304},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":8342,\"start\":8338},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":8785,\"start\":8781},{\"attributes\":{\"ref_id\":\"b44\"},\"end\":8953,\"start\":8949},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":9314,\"start\":9310},{\"attributes\":{\"ref_id\":\"b40\"},\"end\":9317,\"start\":9314},{\"attributes\":{\"ref_id\":\"b29\"},\"end\":9392,\"start\":9388},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":9395,\"start\":9392},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":9468,\"start\":9464},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":9680,\"start\":9676},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":11880,\"start\":11876},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":12854,\"start\":12851},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":13196,\"start\":13192},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":13326,\"start\":13322},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":13444,\"start\":13440},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":13478,\"start\":13474},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":13968,\"start\":13964},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":14209,\"start\":14205},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":14407,\"start\":14404},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":15311,\"start\":15307},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":15728,\"start\":15724},{\"attributes\":{\"ref_id\":\"b36\"},\"end\":15731,\"start\":15728},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":16396,\"start\":16392},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":16967,\"start\":16963},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":17758,\"start\":17755},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":17761,\"start\":17758},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":17817,\"start\":17813},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":17974,\"start\":17970},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":18353,\"start\":18349},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":18485,\"start\":18481},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":19727,\"start\":19723},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":19742,\"start\":19738},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":21227,\"start\":21223},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":22577,\"start\":22573},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":22625,\"start\":22621},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":22627,\"start\":22625},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":22797,\"start\":22793},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":23719,\"start\":23716},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":27872,\"start\":27868},{\"attributes\":{\"ref_id\":\"b43\"},\"end\":27906,\"start\":27902},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":29294,\"start\":29290},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":29335,\"start\":29331},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":29740,\"start\":29736},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":29804,\"start\":29800},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":30724,\"start\":30721},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":31381,\"start\":31380},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":38976,\"start\":38972},{\"attributes\":{\"ref_id\":\"b38\"},\"end\":39024,\"start\":39020},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":39159,\"start\":39156}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":34028,\"start\":33848},{\"attributes\":{\"id\":\"fig_1\"},\"end\":35135,\"start\":34029},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":35779,\"start\":35136},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":38365,\"start\":35780},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":38525,\"start\":38366}]", "paragraph": "[{\"end\":1824,\"start\":1437},{\"end\":2429,\"start\":1826},{\"end\":3260,\"start\":2431},{\"end\":3690,\"start\":3262},{\"end\":4374,\"start\":3692},{\"end\":5530,\"start\":4376},{\"end\":6099,\"start\":5532},{\"end\":6582,\"start\":6101},{\"end\":7667,\"start\":6584},{\"end\":8495,\"start\":7669},{\"end\":8703,\"start\":8497},{\"end\":9318,\"start\":8705},{\"end\":10301,\"start\":9320},{\"end\":11161,\"start\":10303},{\"end\":11357,\"start\":11163},{\"end\":11987,\"start\":11438},{\"end\":12292,\"start\":11989},{\"end\":13085,\"start\":12294},{\"end\":13479,\"start\":13087},{\"end\":13760,\"start\":13481},{\"end\":14130,\"start\":13828},{\"end\":14340,\"start\":14163},{\"end\":14788,\"start\":14342},{\"end\":15155,\"start\":14855},{\"end\":15587,\"start\":15157},{\"end\":15732,\"start\":15589},{\"end\":16253,\"start\":15805},{\"end\":16676,\"start\":16267},{\"end\":17254,\"start\":16678},{\"end\":17548,\"start\":17256},{\"end\":17762,\"start\":17584},{\"end\":18182,\"start\":17764},{\"end\":18382,\"start\":18202},{\"end\":18633,\"start\":18384},{\"end\":18962,\"start\":18635},{\"end\":19290,\"start\":18964},{\"end\":19573,\"start\":19292},{\"end\":19680,\"start\":19585},{\"end\":19910,\"start\":19682},{\"end\":20194,\"start\":19912},{\"end\":20516,\"start\":20196},{\"end\":21154,\"start\":20518},{\"end\":21525,\"start\":21181},{\"end\":21802,\"start\":21552},{\"end\":22211,\"start\":21804},{\"end\":23319,\"start\":22213},{\"end\":24089,\"start\":23340},{\"end\":24495,\"start\":24091},{\"end\":25255,\"start\":24497},{\"end\":25480,\"start\":25257},{\"end\":25562,\"start\":25482},{\"end\":25580,\"start\":25564},{\"end\":26053,\"start\":25582},{\"end\":26811,\"start\":26055},{\"end\":27492,\"start\":26813},{\"end\":27989,\"start\":27494},{\"end\":28644,\"start\":28004},{\"end\":29084,\"start\":28646},{\"end\":29267,\"start\":29086},{\"end\":29424,\"start\":29269},{\"end\":29559,\"start\":29426},{\"end\":30057,\"start\":29561},{\"end\":30398,\"start\":30092},{\"end\":30885,\"start\":30400},{\"end\":31109,\"start\":30887},{\"end\":31613,\"start\":31143},{\"end\":32040,\"start\":31615},{\"end\":32742,\"start\":32042},{\"end\":33505,\"start\":32744},{\"end\":33713,\"start\":33507},{\"end\":33847,\"start\":33738}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":11437,\"start\":11358},{\"attributes\":{\"id\":\"formula_1\"},\"end\":15804,\"start\":15733}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":21562,\"start\":21555},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":24103,\"start\":24096},{\"end\":25673,\"start\":25666},{\"end\":27092,\"start\":27085}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1435,\"start\":1423},{\"attributes\":{\"n\":\"4.2\"},\"end\":13826,\"start\":13763},{\"end\":14161,\"start\":14133},{\"attributes\":{\"n\":\"4.3\"},\"end\":14853,\"start\":14791},{\"attributes\":{\"n\":\"2.\"},\"end\":16265,\"start\":16256},{\"attributes\":{\"n\":\"5\"},\"end\":17571,\"start\":17551},{\"attributes\":{\"n\":\"5.1\"},\"end\":17582,\"start\":17574},{\"attributes\":{\"n\":\"5.2\"},\"end\":18200,\"start\":18185},{\"attributes\":{\"n\":\"5.3\"},\"end\":19583,\"start\":19576},{\"attributes\":{\"n\":\"5.4\"},\"end\":21179,\"start\":21157},{\"attributes\":{\"n\":\"6\"},\"end\":21550,\"start\":21528},{\"end\":23338,\"start\":23322},{\"attributes\":{\"n\":\"7\"},\"end\":28002,\"start\":27992},{\"end\":30090,\"start\":30060},{\"end\":31141,\"start\":31112},{\"end\":33736,\"start\":33716},{\"end\":34040,\"start\":34030},{\"end\":35140,\"start\":35137},{\"end\":35790,\"start\":35781},{\"end\":38376,\"start\":38367}]", "table": "[{\"end\":35779,\"start\":35762},{\"end\":38365,\"start\":37999},{\"end\":38525,\"start\":38378}]", "figure_caption": "[{\"end\":34028,\"start\":33850},{\"end\":35135,\"start\":34042},{\"end\":35762,\"start\":35142},{\"end\":37999,\"start\":35792}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":16959,\"start\":16951},{\"end\":23169,\"start\":23161},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":24674,\"start\":24666},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":25305,\"start\":25297}]", "bib_author_first_name": "[{\"end\":40437,\"start\":40436},{\"end\":40449,\"start\":40448},{\"end\":40705,\"start\":40704},{\"end\":40715,\"start\":40714},{\"end\":40726,\"start\":40725},{\"end\":40736,\"start\":40735},{\"end\":41031,\"start\":41030},{\"end\":41041,\"start\":41040},{\"end\":41051,\"start\":41050},{\"end\":41060,\"start\":41059},{\"end\":41074,\"start\":41073},{\"end\":41084,\"start\":41083},{\"end\":41369,\"start\":41368},{\"end\":41376,\"start\":41375},{\"end\":41382,\"start\":41381},{\"end\":41391,\"start\":41390},{\"end\":41393,\"start\":41392},{\"end\":41402,\"start\":41401},{\"end\":41408,\"start\":41407},{\"end\":41416,\"start\":41415},{\"end\":41784,\"start\":41783},{\"end\":42052,\"start\":42051},{\"end\":42079,\"start\":42078},{\"end\":42090,\"start\":42089},{\"end\":42101,\"start\":42098},{\"end\":42105,\"start\":42104},{\"end\":42383,\"start\":42382},{\"end\":42391,\"start\":42390},{\"end\":42402,\"start\":42401},{\"end\":42409,\"start\":42408},{\"end\":42418,\"start\":42417},{\"end\":42695,\"start\":42694},{\"end\":42703,\"start\":42702},{\"end\":42711,\"start\":42710},{\"end\":42719,\"start\":42718},{\"end\":42726,\"start\":42725},{\"end\":42733,\"start\":42732},{\"end\":42741,\"start\":42740},{\"end\":42748,\"start\":42747},{\"end\":42759,\"start\":42755},{\"end\":43074,\"start\":43073},{\"end\":43076,\"start\":43075},{\"end\":43086,\"start\":43085},{\"end\":43100,\"start\":43099},{\"end\":43110,\"start\":43109},{\"end\":43119,\"start\":43118},{\"end\":43129,\"start\":43128},{\"end\":43388,\"start\":43387},{\"end\":43395,\"start\":43394},{\"end\":43404,\"start\":43403},{\"end\":43693,\"start\":43692},{\"end\":43704,\"start\":43703},{\"end\":43716,\"start\":43715},{\"end\":43728,\"start\":43727},{\"end\":43734,\"start\":43733},{\"end\":43749,\"start\":43748},{\"end\":43985,\"start\":43984},{\"end\":43995,\"start\":43994},{\"end\":44006,\"start\":44005},{\"end\":44168,\"start\":44167},{\"end\":44180,\"start\":44179},{\"end\":44188,\"start\":44187},{\"end\":44194,\"start\":44193},{\"end\":44204,\"start\":44203},{\"end\":44466,\"start\":44465},{\"end\":44476,\"start\":44475},{\"end\":44748,\"start\":44747},{\"end\":44759,\"start\":44758},{\"end\":44772,\"start\":44771},{\"end\":44786,\"start\":44785},{\"end\":44794,\"start\":44793},{\"end\":44806,\"start\":44805},{\"end\":45265,\"start\":45264},{\"end\":45273,\"start\":45272},{\"end\":45282,\"start\":45281},{\"end\":45291,\"start\":45290},{\"end\":45300,\"start\":45299},{\"end\":45313,\"start\":45312},{\"end\":45602,\"start\":45601},{\"end\":45616,\"start\":45612},{\"end\":45627,\"start\":45626},{\"end\":45636,\"start\":45635},{\"end\":45649,\"start\":45645},{\"end\":45660,\"start\":45659},{\"end\":45674,\"start\":45673},{\"end\":45686,\"start\":45685},{\"end\":46032,\"start\":46031},{\"end\":46038,\"start\":46037},{\"end\":46048,\"start\":46047},{\"end\":46055,\"start\":46054},{\"end\":46063,\"start\":46062},{\"end\":46080,\"start\":46072},{\"end\":46084,\"start\":46083},{\"end\":46540,\"start\":46536},{\"end\":46827,\"start\":46826},{\"end\":47062,\"start\":47061},{\"end\":47075,\"start\":47074},{\"end\":47083,\"start\":47082},{\"end\":47095,\"start\":47094},{\"end\":47350,\"start\":47349},{\"end\":47362,\"start\":47361},{\"end\":47371,\"start\":47370},{\"end\":47387,\"start\":47386},{\"end\":48064,\"start\":48063},{\"end\":48076,\"start\":48075},{\"end\":48086,\"start\":48085},{\"end\":48097,\"start\":48093},{\"end\":48619,\"start\":48618},{\"end\":48629,\"start\":48628},{\"end\":48638,\"start\":48637},{\"end\":48864,\"start\":48863},{\"end\":48875,\"start\":48874},{\"end\":48881,\"start\":48880},{\"end\":48890,\"start\":48889},{\"end\":48898,\"start\":48897},{\"end\":48908,\"start\":48907},{\"end\":49173,\"start\":49172},{\"end\":49183,\"start\":49182},{\"end\":49194,\"start\":49193},{\"end\":49205,\"start\":49204},{\"end\":49212,\"start\":49211},{\"end\":49222,\"start\":49221},{\"end\":49232,\"start\":49231},{\"end\":49240,\"start\":49239},{\"end\":49246,\"start\":49245},{\"end\":49248,\"start\":49247},{\"end\":49573,\"start\":49572},{\"end\":49586,\"start\":49585},{\"end\":49595,\"start\":49594},{\"end\":49606,\"start\":49605},{\"end\":50001,\"start\":50000},{\"end\":50012,\"start\":50011},{\"end\":50022,\"start\":50021},{\"end\":50030,\"start\":50029},{\"end\":50316,\"start\":50315},{\"end\":50318,\"start\":50317},{\"end\":50580,\"start\":50579},{\"end\":50597,\"start\":50596},{\"end\":50611,\"start\":50610},{\"end\":50621,\"start\":50620},{\"end\":50633,\"start\":50632},{\"end\":50642,\"start\":50641},{\"end\":50653,\"start\":50652},{\"end\":50661,\"start\":50660},{\"end\":50673,\"start\":50672},{\"end\":50685,\"start\":50684},{\"end\":51025,\"start\":51024},{\"end\":51039,\"start\":51035},{\"end\":51047,\"start\":51046},{\"end\":51059,\"start\":51058},{\"end\":51073,\"start\":51072},{\"end\":51396,\"start\":51395},{\"end\":51410,\"start\":51406},{\"end\":51418,\"start\":51417},{\"end\":51430,\"start\":51429},{\"end\":51444,\"start\":51443},{\"end\":51730,\"start\":51729},{\"end\":51995,\"start\":51994},{\"end\":52002,\"start\":52001},{\"end\":52004,\"start\":52003},{\"end\":52011,\"start\":52010},{\"end\":52013,\"start\":52012},{\"end\":52255,\"start\":52254},{\"end\":52268,\"start\":52267},{\"end\":52279,\"start\":52278},{\"end\":52511,\"start\":52510},{\"end\":52519,\"start\":52518},{\"end\":52532,\"start\":52531},{\"end\":53165,\"start\":53164},{\"end\":53175,\"start\":53174},{\"end\":53192,\"start\":53191},{\"end\":53204,\"start\":53203},{\"end\":53218,\"start\":53217},{\"end\":53227,\"start\":53226},{\"end\":53235,\"start\":53234},{\"end\":53245,\"start\":53244},{\"end\":53254,\"start\":53253},{\"end\":53261,\"start\":53260},{\"end\":53581,\"start\":53580},{\"end\":53583,\"start\":53582},{\"end\":53595,\"start\":53594},{\"end\":53851,\"start\":53850},{\"end\":53859,\"start\":53858},{\"end\":53868,\"start\":53867},{\"end\":53876,\"start\":53875},{\"end\":53888,\"start\":53887},{\"end\":53900,\"start\":53899},{\"end\":53907,\"start\":53906},{\"end\":53917,\"start\":53916},{\"end\":53926,\"start\":53925},{\"end\":53934,\"start\":53933},{\"end\":54258,\"start\":54257},{\"end\":54264,\"start\":54263},{\"end\":54276,\"start\":54275},{\"end\":54284,\"start\":54283},{\"end\":54286,\"start\":54285},{\"end\":54292,\"start\":54291},{\"end\":54303,\"start\":54302},{\"end\":54315,\"start\":54314},{\"end\":54325,\"start\":54324},{\"end\":54332,\"start\":54331},{\"end\":54339,\"start\":54338},{\"end\":54766,\"start\":54765},{\"end\":55022,\"start\":55021},{\"end\":55028,\"start\":55027},{\"end\":55037,\"start\":55036},{\"end\":55045,\"start\":55044},{\"end\":55047,\"start\":55046},{\"end\":55403,\"start\":55402},{\"end\":55409,\"start\":55408},{\"end\":55418,\"start\":55417},{\"end\":55427,\"start\":55425},{\"end\":55431,\"start\":55430},{\"end\":55433,\"start\":55432},{\"end\":55660,\"start\":55659},{\"end\":55671,\"start\":55670},{\"end\":55683,\"start\":55682},{\"end\":55694,\"start\":55693},{\"end\":55702,\"start\":55701},{\"end\":55713,\"start\":55712},{\"end\":55724,\"start\":55723},{\"end\":56019,\"start\":56018},{\"end\":56028,\"start\":56027},{\"end\":56315,\"start\":56314},{\"end\":56323,\"start\":56322},{\"end\":56329,\"start\":56328},{\"end\":56335,\"start\":56334},{\"end\":56342,\"start\":56341}]", "bib_author_last_name": "[{\"end\":40446,\"start\":40438},{\"end\":40456,\"start\":40450},{\"end\":40712,\"start\":40706},{\"end\":40723,\"start\":40716},{\"end\":40733,\"start\":40727},{\"end\":40744,\"start\":40737},{\"end\":41038,\"start\":41032},{\"end\":41048,\"start\":41042},{\"end\":41057,\"start\":41052},{\"end\":41071,\"start\":41061},{\"end\":41081,\"start\":41075},{\"end\":41092,\"start\":41085},{\"end\":41373,\"start\":41370},{\"end\":41379,\"start\":41377},{\"end\":41388,\"start\":41383},{\"end\":41399,\"start\":41394},{\"end\":41405,\"start\":41403},{\"end\":41413,\"start\":41409},{\"end\":41423,\"start\":41417},{\"end\":41791,\"start\":41785},{\"end\":42076,\"start\":42053},{\"end\":42087,\"start\":42080},{\"end\":42096,\"start\":42091},{\"end\":42388,\"start\":42384},{\"end\":42399,\"start\":42392},{\"end\":42406,\"start\":42403},{\"end\":42415,\"start\":42410},{\"end\":42426,\"start\":42419},{\"end\":42700,\"start\":42696},{\"end\":42708,\"start\":42704},{\"end\":42716,\"start\":42712},{\"end\":42723,\"start\":42720},{\"end\":42730,\"start\":42727},{\"end\":42738,\"start\":42734},{\"end\":42745,\"start\":42742},{\"end\":42753,\"start\":42749},{\"end\":42763,\"start\":42760},{\"end\":43083,\"start\":43077},{\"end\":43097,\"start\":43087},{\"end\":43107,\"start\":43101},{\"end\":43116,\"start\":43111},{\"end\":43126,\"start\":43120},{\"end\":43135,\"start\":43130},{\"end\":43145,\"start\":43137},{\"end\":43392,\"start\":43389},{\"end\":43401,\"start\":43396},{\"end\":43412,\"start\":43405},{\"end\":43701,\"start\":43694},{\"end\":43713,\"start\":43705},{\"end\":43725,\"start\":43717},{\"end\":43731,\"start\":43729},{\"end\":43746,\"start\":43735},{\"end\":43754,\"start\":43750},{\"end\":43992,\"start\":43986},{\"end\":44003,\"start\":43996},{\"end\":44011,\"start\":44007},{\"end\":44177,\"start\":44169},{\"end\":44185,\"start\":44181},{\"end\":44191,\"start\":44189},{\"end\":44201,\"start\":44195},{\"end\":44209,\"start\":44205},{\"end\":44473,\"start\":44467},{\"end\":44487,\"start\":44477},{\"end\":44756,\"start\":44749},{\"end\":44769,\"start\":44760},{\"end\":44783,\"start\":44773},{\"end\":44791,\"start\":44787},{\"end\":44803,\"start\":44795},{\"end\":44812,\"start\":44807},{\"end\":45270,\"start\":45266},{\"end\":45279,\"start\":45274},{\"end\":45288,\"start\":45283},{\"end\":45297,\"start\":45292},{\"end\":45310,\"start\":45301},{\"end\":45320,\"start\":45314},{\"end\":45610,\"start\":45603},{\"end\":45624,\"start\":45617},{\"end\":45633,\"start\":45628},{\"end\":45643,\"start\":45637},{\"end\":45657,\"start\":45650},{\"end\":45671,\"start\":45661},{\"end\":45683,\"start\":45675},{\"end\":45694,\"start\":45687},{\"end\":46035,\"start\":46033},{\"end\":46045,\"start\":46039},{\"end\":46052,\"start\":46049},{\"end\":46060,\"start\":46056},{\"end\":46070,\"start\":46064},{\"end\":46544,\"start\":46541},{\"end\":46837,\"start\":46828},{\"end\":47072,\"start\":47063},{\"end\":47080,\"start\":47076},{\"end\":47092,\"start\":47084},{\"end\":47101,\"start\":47096},{\"end\":47359,\"start\":47351},{\"end\":47368,\"start\":47363},{\"end\":47384,\"start\":47372},{\"end\":47394,\"start\":47388},{\"end\":48073,\"start\":48065},{\"end\":48083,\"start\":48077},{\"end\":48091,\"start\":48087},{\"end\":48101,\"start\":48098},{\"end\":48626,\"start\":48620},{\"end\":48635,\"start\":48630},{\"end\":48645,\"start\":48639},{\"end\":48872,\"start\":48865},{\"end\":48878,\"start\":48876},{\"end\":48887,\"start\":48882},{\"end\":48895,\"start\":48891},{\"end\":48905,\"start\":48899},{\"end\":48918,\"start\":48909},{\"end\":49180,\"start\":49174},{\"end\":49191,\"start\":49184},{\"end\":49202,\"start\":49195},{\"end\":49209,\"start\":49206},{\"end\":49219,\"start\":49213},{\"end\":49229,\"start\":49223},{\"end\":49237,\"start\":49233},{\"end\":49243,\"start\":49241},{\"end\":49252,\"start\":49249},{\"end\":49583,\"start\":49574},{\"end\":49592,\"start\":49587},{\"end\":49603,\"start\":49596},{\"end\":49612,\"start\":49607},{\"end\":50009,\"start\":50002},{\"end\":50019,\"start\":50013},{\"end\":50027,\"start\":50023},{\"end\":50038,\"start\":50031},{\"end\":50324,\"start\":50319},{\"end\":50594,\"start\":50581},{\"end\":50608,\"start\":50598},{\"end\":50618,\"start\":50612},{\"end\":50630,\"start\":50622},{\"end\":50639,\"start\":50634},{\"end\":50650,\"start\":50643},{\"end\":50658,\"start\":50654},{\"end\":50670,\"start\":50662},{\"end\":50682,\"start\":50674},{\"end\":50693,\"start\":50686},{\"end\":51033,\"start\":51026},{\"end\":51044,\"start\":51040},{\"end\":51056,\"start\":51048},{\"end\":51070,\"start\":51060},{\"end\":51081,\"start\":51074},{\"end\":51404,\"start\":51397},{\"end\":51415,\"start\":51411},{\"end\":51427,\"start\":51419},{\"end\":51441,\"start\":51431},{\"end\":51452,\"start\":51445},{\"end\":51738,\"start\":51731},{\"end\":51999,\"start\":51996},{\"end\":52008,\"start\":52005},{\"end\":52021,\"start\":52014},{\"end\":52265,\"start\":52256},{\"end\":52276,\"start\":52269},{\"end\":52285,\"start\":52280},{\"end\":52516,\"start\":52512},{\"end\":52529,\"start\":52520},{\"end\":52540,\"start\":52533},{\"end\":53172,\"start\":53166},{\"end\":53189,\"start\":53176},{\"end\":53201,\"start\":53193},{\"end\":53215,\"start\":53205},{\"end\":53224,\"start\":53219},{\"end\":53232,\"start\":53228},{\"end\":53242,\"start\":53236},{\"end\":53251,\"start\":53246},{\"end\":53258,\"start\":53255},{\"end\":53268,\"start\":53262},{\"end\":53592,\"start\":53584},{\"end\":53602,\"start\":53596},{\"end\":53856,\"start\":53852},{\"end\":53865,\"start\":53860},{\"end\":53873,\"start\":53869},{\"end\":53885,\"start\":53877},{\"end\":53897,\"start\":53889},{\"end\":53904,\"start\":53901},{\"end\":53914,\"start\":53908},{\"end\":53923,\"start\":53918},{\"end\":53931,\"start\":53927},{\"end\":53944,\"start\":53935},{\"end\":54261,\"start\":54259},{\"end\":54273,\"start\":54265},{\"end\":54281,\"start\":54277},{\"end\":54289,\"start\":54287},{\"end\":54300,\"start\":54293},{\"end\":54312,\"start\":54304},{\"end\":54322,\"start\":54316},{\"end\":54329,\"start\":54326},{\"end\":54336,\"start\":54333},{\"end\":54348,\"start\":54340},{\"end\":54775,\"start\":54767},{\"end\":55025,\"start\":55023},{\"end\":55034,\"start\":55029},{\"end\":55042,\"start\":55038},{\"end\":55054,\"start\":55048},{\"end\":55406,\"start\":55404},{\"end\":55415,\"start\":55410},{\"end\":55423,\"start\":55419},{\"end\":55668,\"start\":55661},{\"end\":55680,\"start\":55672},{\"end\":55691,\"start\":55684},{\"end\":55699,\"start\":55695},{\"end\":55710,\"start\":55703},{\"end\":55721,\"start\":55714},{\"end\":55729,\"start\":55725},{\"end\":56025,\"start\":56020},{\"end\":56036,\"start\":56029},{\"end\":56320,\"start\":56316},{\"end\":56326,\"start\":56324},{\"end\":56332,\"start\":56330},{\"end\":56339,\"start\":56336},{\"end\":56347,\"start\":56343}]", "bib_entry": "[{\"attributes\":{\"doi\":\"arXiv:1701.04862\",\"id\":\"b0\"},\"end\":40627,\"start\":40363},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":1820089},\"end\":40999,\"start\":40629},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":53208122},\"end\":41366,\"start\":41001},{\"attributes\":{\"doi\":\"arXiv:1702.07983\",\"id\":\"b3\"},\"end\":41710,\"start\":41368},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":16724115},\"end\":42012,\"start\":41712},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":165163834},\"end\":42330,\"start\":42014},{\"attributes\":{\"doi\":\"arXiv:2004.11714\",\"id\":\"b6\"},\"end\":42605,\"start\":42332},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":147704286},\"end\":43071,\"start\":42607},{\"attributes\":{\"doi\":\"arXiv:2007.12626\",\"id\":\"b8\"},\"end\":43385,\"start\":43073},{\"attributes\":{\"doi\":\"arXiv:1805.04833\",\"id\":\"b9\"},\"end\":43594,\"start\":43387},{\"attributes\":{\"id\":\"b10\"},\"end\":43936,\"start\":43596},{\"attributes\":{\"doi\":\"arXiv:1503.02531\",\"id\":\"b11\"},\"end\":44165,\"start\":43938},{\"attributes\":{\"doi\":\"arXiv:1904.09751\",\"id\":\"b12\"},\"end\":44428,\"start\":44167},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":15184765},\"end\":44675,\"start\":44430},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":15652746},\"end\":45262,\"start\":44677},{\"attributes\":{\"doi\":\"arXiv:1610.09038\",\"id\":\"b15\"},\"end\":45599,\"start\":45264},{\"attributes\":{\"doi\":\"arXiv:2104.05336\",\"id\":\"b16\"},\"end\":45976,\"start\":45601},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":98180},\"end\":46478,\"start\":45978},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":964287},\"end\":46698,\"start\":46480},{\"attributes\":{\"id\":\"b19\"},\"end\":46984,\"start\":46700},{\"attributes\":{\"doi\":\"arXiv:1602.06023\",\"id\":\"b20\"},\"end\":47303,\"start\":46986},{\"attributes\":{\"doi\":\"10.18653/v1/D17-1238\",\"id\":\"b21\",\"matched_paper_id\":1929239},\"end\":47997,\"start\":47305},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":11080756},\"end\":48561,\"start\":47999},{\"attributes\":{\"doi\":\"arXiv:1705.04304\",\"id\":\"b23\"},\"end\":48808,\"start\":48563},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":160025533},\"end\":49087,\"start\":48810},{\"attributes\":{\"doi\":\"arXiv:1910.10683\",\"id\":\"b25\"},\"end\":49509,\"start\":49089},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":11816014},\"end\":49998,\"start\":49511},{\"attributes\":{\"doi\":\"arXiv:1511.06732\",\"id\":\"b27\"},\"end\":50271,\"start\":50000},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":207081359},\"end\":50506,\"start\":50273},{\"attributes\":{\"id\":\"b29\",\"matched_paper_id\":208158225},\"end\":50956,\"start\":50508},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":219530971},\"end\":51328,\"start\":50958},{\"attributes\":{\"doi\":\"arXiv:2002.10375\",\"id\":\"b31\"},\"end\":51659,\"start\":51330},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":30807376},\"end\":51927,\"start\":51661},{\"attributes\":{\"doi\":\"arXiv:1704.04368\",\"id\":\"b33\"},\"end\":52196,\"start\":51929},{\"attributes\":{\"doi\":\"arXiv:1806.04936\",\"id\":\"b34\"},\"end\":52453,\"start\":52198},{\"attributes\":{\"id\":\"b35\",\"matched_paper_id\":3725815},\"end\":53112,\"start\":52455},{\"attributes\":{\"id\":\"b36\",\"matched_paper_id\":205261034},\"end\":53500,\"start\":53114},{\"attributes\":{\"id\":\"b37\",\"matched_paper_id\":14711886},\"end\":53774,\"start\":53502},{\"attributes\":{\"doi\":\"arXiv:1910.03771\",\"id\":\"b38\"},\"end\":54211,\"start\":53776},{\"attributes\":{\"doi\":\"arXiv:1609.08144\",\"id\":\"b39\",\"matched_paper_id\":3603249},\"end\":54695,\"start\":54213},{\"attributes\":{\"id\":\"b40\",\"matched_paper_id\":1487550},\"end\":55019,\"start\":54697},{\"attributes\":{\"doi\":\"arXiv:1609.05473\",\"id\":\"b41\"},\"end\":55333,\"start\":55021},{\"attributes\":{\"id\":\"b42\"},\"end\":55657,\"start\":55335},{\"attributes\":{\"doi\":\"arXiv:1905.12616\",\"id\":\"b43\"},\"end\":55960,\"start\":55659},{\"attributes\":{\"id\":\"b44\",\"matched_paper_id\":219558831},\"end\":56233,\"start\":55962},{\"attributes\":{\"id\":\"b45\",\"matched_paper_id\":211003742},\"end\":56640,\"start\":56235}]", "bib_title": "[{\"end\":40702,\"start\":40629},{\"end\":41028,\"start\":41001},{\"end\":41781,\"start\":41712},{\"end\":42049,\"start\":42014},{\"end\":42692,\"start\":42607},{\"end\":44463,\"start\":44430},{\"end\":44745,\"start\":44677},{\"end\":46029,\"start\":45978},{\"end\":46534,\"start\":46480},{\"end\":47347,\"start\":47305},{\"end\":48061,\"start\":47999},{\"end\":48861,\"start\":48810},{\"end\":49570,\"start\":49511},{\"end\":50313,\"start\":50273},{\"end\":50577,\"start\":50508},{\"end\":51022,\"start\":50958},{\"end\":51727,\"start\":51661},{\"end\":52508,\"start\":52455},{\"end\":53162,\"start\":53114},{\"end\":53578,\"start\":53502},{\"end\":54255,\"start\":54213},{\"end\":54763,\"start\":54697},{\"end\":55400,\"start\":55335},{\"end\":56016,\"start\":55962},{\"end\":56312,\"start\":56235}]", "bib_author": "[{\"end\":40448,\"start\":40436},{\"end\":40458,\"start\":40448},{\"end\":40714,\"start\":40704},{\"end\":40725,\"start\":40714},{\"end\":40735,\"start\":40725},{\"end\":40746,\"start\":40735},{\"end\":41040,\"start\":41030},{\"end\":41050,\"start\":41040},{\"end\":41059,\"start\":41050},{\"end\":41073,\"start\":41059},{\"end\":41083,\"start\":41073},{\"end\":41094,\"start\":41083},{\"end\":41375,\"start\":41368},{\"end\":41381,\"start\":41375},{\"end\":41390,\"start\":41381},{\"end\":41401,\"start\":41390},{\"end\":41407,\"start\":41401},{\"end\":41415,\"start\":41407},{\"end\":41425,\"start\":41415},{\"end\":41793,\"start\":41783},{\"end\":42078,\"start\":42051},{\"end\":42089,\"start\":42078},{\"end\":42098,\"start\":42089},{\"end\":42104,\"start\":42098},{\"end\":42108,\"start\":42104},{\"end\":42390,\"start\":42382},{\"end\":42401,\"start\":42390},{\"end\":42408,\"start\":42401},{\"end\":42417,\"start\":42408},{\"end\":42428,\"start\":42417},{\"end\":42702,\"start\":42694},{\"end\":42710,\"start\":42702},{\"end\":42718,\"start\":42710},{\"end\":42725,\"start\":42718},{\"end\":42732,\"start\":42725},{\"end\":42740,\"start\":42732},{\"end\":42747,\"start\":42740},{\"end\":42755,\"start\":42747},{\"end\":42765,\"start\":42755},{\"end\":43085,\"start\":43073},{\"end\":43099,\"start\":43085},{\"end\":43109,\"start\":43099},{\"end\":43118,\"start\":43109},{\"end\":43128,\"start\":43118},{\"end\":43137,\"start\":43128},{\"end\":43147,\"start\":43137},{\"end\":43394,\"start\":43387},{\"end\":43403,\"start\":43394},{\"end\":43414,\"start\":43403},{\"end\":43703,\"start\":43692},{\"end\":43715,\"start\":43703},{\"end\":43727,\"start\":43715},{\"end\":43733,\"start\":43727},{\"end\":43748,\"start\":43733},{\"end\":43756,\"start\":43748},{\"end\":43994,\"start\":43984},{\"end\":44005,\"start\":43994},{\"end\":44013,\"start\":44005},{\"end\":44179,\"start\":44167},{\"end\":44187,\"start\":44179},{\"end\":44193,\"start\":44187},{\"end\":44203,\"start\":44193},{\"end\":44211,\"start\":44203},{\"end\":44475,\"start\":44465},{\"end\":44489,\"start\":44475},{\"end\":44758,\"start\":44747},{\"end\":44771,\"start\":44758},{\"end\":44785,\"start\":44771},{\"end\":44793,\"start\":44785},{\"end\":44805,\"start\":44793},{\"end\":44814,\"start\":44805},{\"end\":45272,\"start\":45264},{\"end\":45281,\"start\":45272},{\"end\":45290,\"start\":45281},{\"end\":45299,\"start\":45290},{\"end\":45312,\"start\":45299},{\"end\":45322,\"start\":45312},{\"end\":45612,\"start\":45601},{\"end\":45626,\"start\":45612},{\"end\":45635,\"start\":45626},{\"end\":45645,\"start\":45635},{\"end\":45659,\"start\":45645},{\"end\":45673,\"start\":45659},{\"end\":45685,\"start\":45673},{\"end\":45696,\"start\":45685},{\"end\":46037,\"start\":46031},{\"end\":46047,\"start\":46037},{\"end\":46054,\"start\":46047},{\"end\":46062,\"start\":46054},{\"end\":46072,\"start\":46062},{\"end\":46083,\"start\":46072},{\"end\":46087,\"start\":46083},{\"end\":46546,\"start\":46536},{\"end\":46839,\"start\":46826},{\"end\":47074,\"start\":47061},{\"end\":47082,\"start\":47074},{\"end\":47094,\"start\":47082},{\"end\":47103,\"start\":47094},{\"end\":47361,\"start\":47349},{\"end\":47370,\"start\":47361},{\"end\":47386,\"start\":47370},{\"end\":47396,\"start\":47386},{\"end\":48075,\"start\":48063},{\"end\":48085,\"start\":48075},{\"end\":48093,\"start\":48085},{\"end\":48103,\"start\":48093},{\"end\":48628,\"start\":48618},{\"end\":48637,\"start\":48628},{\"end\":48647,\"start\":48637},{\"end\":48874,\"start\":48863},{\"end\":48880,\"start\":48874},{\"end\":48889,\"start\":48880},{\"end\":48897,\"start\":48889},{\"end\":48907,\"start\":48897},{\"end\":48920,\"start\":48907},{\"end\":49182,\"start\":49172},{\"end\":49193,\"start\":49182},{\"end\":49204,\"start\":49193},{\"end\":49211,\"start\":49204},{\"end\":49221,\"start\":49211},{\"end\":49231,\"start\":49221},{\"end\":49239,\"start\":49231},{\"end\":49245,\"start\":49239},{\"end\":49254,\"start\":49245},{\"end\":49585,\"start\":49572},{\"end\":49594,\"start\":49585},{\"end\":49605,\"start\":49594},{\"end\":49614,\"start\":49605},{\"end\":50011,\"start\":50000},{\"end\":50021,\"start\":50011},{\"end\":50029,\"start\":50021},{\"end\":50040,\"start\":50029},{\"end\":50326,\"start\":50315},{\"end\":50596,\"start\":50579},{\"end\":50610,\"start\":50596},{\"end\":50620,\"start\":50610},{\"end\":50632,\"start\":50620},{\"end\":50641,\"start\":50632},{\"end\":50652,\"start\":50641},{\"end\":50660,\"start\":50652},{\"end\":50672,\"start\":50660},{\"end\":50684,\"start\":50672},{\"end\":50695,\"start\":50684},{\"end\":51035,\"start\":51024},{\"end\":51046,\"start\":51035},{\"end\":51058,\"start\":51046},{\"end\":51072,\"start\":51058},{\"end\":51083,\"start\":51072},{\"end\":51406,\"start\":51395},{\"end\":51417,\"start\":51406},{\"end\":51429,\"start\":51417},{\"end\":51443,\"start\":51429},{\"end\":51454,\"start\":51443},{\"end\":51740,\"start\":51729},{\"end\":52001,\"start\":51994},{\"end\":52010,\"start\":52001},{\"end\":52023,\"start\":52010},{\"end\":52267,\"start\":52254},{\"end\":52278,\"start\":52267},{\"end\":52287,\"start\":52278},{\"end\":52518,\"start\":52510},{\"end\":52531,\"start\":52518},{\"end\":52542,\"start\":52531},{\"end\":53174,\"start\":53164},{\"end\":53191,\"start\":53174},{\"end\":53203,\"start\":53191},{\"end\":53217,\"start\":53203},{\"end\":53226,\"start\":53217},{\"end\":53234,\"start\":53226},{\"end\":53244,\"start\":53234},{\"end\":53253,\"start\":53244},{\"end\":53260,\"start\":53253},{\"end\":53270,\"start\":53260},{\"end\":53594,\"start\":53580},{\"end\":53604,\"start\":53594},{\"end\":53858,\"start\":53850},{\"end\":53867,\"start\":53858},{\"end\":53875,\"start\":53867},{\"end\":53887,\"start\":53875},{\"end\":53899,\"start\":53887},{\"end\":53906,\"start\":53899},{\"end\":53916,\"start\":53906},{\"end\":53925,\"start\":53916},{\"end\":53933,\"start\":53925},{\"end\":53946,\"start\":53933},{\"end\":54263,\"start\":54257},{\"end\":54275,\"start\":54263},{\"end\":54283,\"start\":54275},{\"end\":54291,\"start\":54283},{\"end\":54302,\"start\":54291},{\"end\":54314,\"start\":54302},{\"end\":54324,\"start\":54314},{\"end\":54331,\"start\":54324},{\"end\":54338,\"start\":54331},{\"end\":54350,\"start\":54338},{\"end\":54777,\"start\":54765},{\"end\":55027,\"start\":55021},{\"end\":55036,\"start\":55027},{\"end\":55044,\"start\":55036},{\"end\":55056,\"start\":55044},{\"end\":55408,\"start\":55402},{\"end\":55417,\"start\":55408},{\"end\":55425,\"start\":55417},{\"end\":55430,\"start\":55425},{\"end\":55436,\"start\":55430},{\"end\":55670,\"start\":55659},{\"end\":55682,\"start\":55670},{\"end\":55693,\"start\":55682},{\"end\":55701,\"start\":55693},{\"end\":55712,\"start\":55701},{\"end\":55723,\"start\":55712},{\"end\":55731,\"start\":55723},{\"end\":56027,\"start\":56018},{\"end\":56038,\"start\":56027},{\"end\":56322,\"start\":56314},{\"end\":56328,\"start\":56322},{\"end\":56334,\"start\":56328},{\"end\":56341,\"start\":56334},{\"end\":56349,\"start\":56341}]", "bib_venue": "[{\"end\":40434,\"start\":40363},{\"end\":40795,\"start\":40746},{\"end\":41146,\"start\":41094},{\"end\":41510,\"start\":41441},{\"end\":41840,\"start\":41793},{\"end\":42157,\"start\":42108},{\"end\":42380,\"start\":42332},{\"end\":42814,\"start\":42765},{\"end\":43201,\"start\":43163},{\"end\":43466,\"start\":43430},{\"end\":43690,\"start\":43596},{\"end\":43982,\"start\":43938},{\"end\":44271,\"start\":44227},{\"end\":44528,\"start\":44489},{\"end\":44910,\"start\":44814},{\"end\":45404,\"start\":45338},{\"end\":45759,\"start\":45712},{\"end\":46173,\"start\":46087},{\"end\":46577,\"start\":46546},{\"end\":46824,\"start\":46700},{\"end\":47059,\"start\":46986},{\"end\":47502,\"start\":47416},{\"end\":48186,\"start\":48103},{\"end\":48616,\"start\":48563},{\"end\":48931,\"start\":48920},{\"end\":49170,\"start\":49089},{\"end\":49700,\"start\":49614},{\"end\":50110,\"start\":50056},{\"end\":50375,\"start\":50326},{\"end\":50701,\"start\":50695},{\"end\":51132,\"start\":51083},{\"end\":51393,\"start\":51330},{\"end\":51779,\"start\":51740},{\"end\":51992,\"start\":51929},{\"end\":52252,\"start\":52198},{\"end\":52684,\"start\":52542},{\"end\":53276,\"start\":53270},{\"end\":53622,\"start\":53604},{\"end\":53848,\"start\":53776},{\"end\":54420,\"start\":54366},{\"end\":54845,\"start\":54777},{\"end\":55151,\"start\":55072},{\"end\":55478,\"start\":55436},{\"end\":55781,\"start\":55747},{\"end\":56087,\"start\":56038},{\"end\":56401,\"start\":56349},{\"end\":44993,\"start\":44912},{\"end\":46246,\"start\":46175},{\"end\":47594,\"start\":47504},{\"end\":48256,\"start\":48188},{\"end\":49773,\"start\":49702},{\"end\":52813,\"start\":52686}]"}}}, "year": 2023, "month": 12, "day": 17}