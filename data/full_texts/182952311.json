{"id": 182952311, "updated": "2023-10-07 01:53:39.591", "metadata": {"title": "Time-Series Anomaly Detection Service at Microsoft", "authors": "[{\"first\":\"Hansheng\",\"last\":\"Ren\",\"middle\":[]},{\"first\":\"Bixiong\",\"last\":\"Xu\",\"middle\":[]},{\"first\":\"Yujing\",\"last\":\"Wang\",\"middle\":[]},{\"first\":\"Chao\",\"last\":\"Yi\",\"middle\":[]},{\"first\":\"Congrui\",\"last\":\"Huang\",\"middle\":[]},{\"first\":\"Xiaoyu\",\"last\":\"Kou\",\"middle\":[]},{\"first\":\"Tony\",\"last\":\"Xing\",\"middle\":[]},{\"first\":\"Mao\",\"last\":\"Yang\",\"middle\":[]},{\"first\":\"Jie\",\"last\":\"Tong\",\"middle\":[]},{\"first\":\"Qi\",\"last\":\"Zhang\",\"middle\":[]}]", "venue": null, "journal": "Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery & Data Mining", "publication_date": {"year": 2019, "month": 6, "day": 10}, "abstract": "Large companies need to monitor various metrics (for example, Page Views and Revenue) of their applications and services in real time. At Microsoft, we develop a time-series anomaly detection service which helps customers to monitor the time-series continuously and alert for potential incidents on time. In this paper, we introduce the pipeline and algorithm of our anomaly detection service, which is designed to be accurate, efficient and general. The pipeline consists of three major modules, including data ingestion, experimentation platform and online compute. To tackle the problem of time-series anomaly detection, we propose a novel algorithm based on Spectral Residual (SR) and Convolutional Neural Network (CNN). Our work is the first attempt to borrow the SR model from visual saliency detection domain to time-series anomaly detection. Moreover, we innovatively combine SR and CNN together to improve the performance of SR model. Our approach achieves superior experimental results compared with state-of-the-art baselines on both public datasets and Microsoft production data.", "fields_of_study": "[\"Computer Science\",\"Mathematics\"]", "external_ids": {"arxiv": "1906.03821", "mag": "3105931142", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/kdd/RenXWYHKXYTZ19", "doi": "10.1145/3292500.3330680"}}, "content": {"source": {"pdf_hash": "d87881a7a13db9252f8d73e5b1a62bb1933b392e", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/1906.03821v1.pdf\"]", "oa_url_match": true, "oa_info": {"license": null, "open_access_url": "http://arxiv.org/pdf/1906.03821", "status": "GREEN"}}, "grobid": {"id": "63ecaf676061ca47e8cda3b0bfabe223edc97370", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/d87881a7a13db9252f8d73e5b1a62bb1933b392e.txt", "contents": "\nTime-Series Anomaly Detection Service at Microsoft\n2019. August 4-8, 2019. August 4-8, 2019\n\nHansheng Ren \nACM Reference Format\nMicrosoft\nBeijingChina\n\nBixiong Xu \nACM Reference Format\nMicrosoft\nBeijingChina\n\nYujing Wang yujwang@microsoft.com \nACM Reference Format\nMicrosoft\nBeijingChina\n\nChao Yi \nACM Reference Format\nMicrosoft\nBeijingChina\n\nCongrui Huang \nACM Reference Format\nMicrosoft\nBeijingChina\n\nXiaoyu Kou \nACM Reference Format\nMicrosoft\nBeijingChina\n\nTony Xing tonyxin@microsoft.com \nACM Reference Format\nMicrosoft\nBeijingChina\n\nMao Yang maoyang@microsoft.com \nACM Reference Format\nMicrosoft\nBeijingChina\n\nJie Tong jietong@microsoft.com \nACM Reference Format\nMicrosoft\nBeijingChina\n\nQi Zhang qizhang@microsoft.com \nACM Reference Format\nMicrosoft\nBeijingChina\n\nHansheng Ren \nACM Reference Format\nMicrosoft\nBeijingChina\n\nBixiong Xu \nACM Reference Format\nMicrosoft\nBeijingChina\n\nYujing Wang \nACM Reference Format\nMicrosoft\nBeijingChina\n\nChao Yi \nACM Reference Format\nMicrosoft\nBeijingChina\n\nCongrui Huang \nACM Reference Format\nMicrosoft\nBeijingChina\n\nXi-Aoyu Kou \nACM Reference Format\nMicrosoft\nBeijingChina\n\nTony Xing \nACM Reference Format\nMicrosoft\nBeijingChina\n\nMao Yang \nACM Reference Format\nMicrosoft\nBeijingChina\n\nJie Tong \nACM Reference Format\nMicrosoft\nBeijingChina\n\nQi Zhang \nACM Reference Format\nMicrosoft\nBeijingChina\n\nTime-Series Anomaly Detection Service at Microsoft\n\nThe 25th ACM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD '19)\nAnchorage, AK, USA; Anchorage, AK, USA2019. August 4-8, 2019. August 4-8, 201910.1145/3292500.3330680. ACM, New York, NY, USA, 9 pages. https: //doi.org/10.1145/3292500.3330680 * Hansheng Ren is a student in University of Chinese Academy of Sciences; Chao Yi and Xiaoyu Kou are students in Peking University. The work was done when they worked as full-time interns at Microsoft. ACM ISBN 978-1-4503-6201-6/19/08. . . $15.00CCS CONCEPTS \u2022 Computing methodologies \u2192 Machine learningUnsuper- vised learningAnomaly detection\u2022 Mathematics of com- puting \u2192 Time series analysis\u2022 Information systems \u2192 Traffic analysis KEYWORDS anomaly detectiontime-seriesSpectral Residual\nLarge companies need to monitor various metrics (for example, Page Views and Revenue) of their applications and services in real time. At Microsoft, we develop a time-series anomaly detection service which helps customers to monitor the time-series continuously and alert for potential incidents on time. In this paper, we introduce the pipeline and algorithm of our anomaly detection service, which is designed to be accurate, efficient and general. The pipeline consists of three major modules, including data ingestion, experimentation platform and online compute. To tackle the problem of time-series anomaly detection, we propose a novel algorithm based on Spectral Residual (SR) and Convolutional Neural Network (CNN). Our work is the first attempt to borrow the SR model from visual saliency detection domain to time-series anomaly detection. Moreover, we innovatively combine SR and CNN together to improve the performance of SR model. Our approach achieves superior experimental results compared with state-of-the-art baselines on both public datasets and Microsoft production data.\n\nINTRODUCTION\n\nAnomaly detection aims to discover unexpected events or rare items in data. It is popular in many industrial applications and is an important research area in data mining. Accurate anomaly detection can trigger prompt troubleshooting, help to avoid loss in revenue, and maintain the reputation and branding for a company. For this purpose, large companies have built their own anomaly detection services to monitor their business, product and service health [11,20]. When anomalies are detected, alerts will be sent to the operators to make timely decisions related to incidents. For instance, Yahoo releases EGADS [11] to automatically monitor and raise alerts on millions of time-series of different Yahoo properties for various use-cases. At Microsoft, we build an anomaly detection service to monitor millions of metrics coming from Bing, Office and Azure, which enables engineers move faster in solving live site issues. In this paper, we focus on the pipeline and algorithm of our anomaly detection service specialized for time-series data.\n\nThere are many challenges in designing an industrial service for time-series anomaly detection:\n\nChallenge 1: Lack of Labels. To provide anomaly detection services for a single business scenario, the system must process millions of time-series simultaneously. There is no easy way for users to label each time-series manually. Moreover, the data distribution of time-series is constantly changing, which requires the system recognizing the anomalies even though similar patterns have not appeared before. That makes the supervised models insufficient in the industrial scenario.\n\nChallenge 2: Generalization. Various kinds of time-series from different business scenarios are required to be monitored. As shown in Figure 1, there are several typical categories of time-series patterns; and it is important for industrial anomaly detection services to work well on all kinds of patterns. However, existing approaches are not generalized enough for different patterns. For example, Holt winters [5] always shows poor results in (b) and (c); and Spot [19] always shows poor results in (a). Thus, we need to find a solution of better generality. Challenge 3: Efficiency. In business applications, a monitoring system must process millions, even billions of time-series in near real time. Especially for minute-level time-series, the anomaly detection procedure needs to be finished within limited time. Therefore, efficiency is one of the major prerequisites for online anomaly detection service. Even though the models with large time complexity are good at accuracy, they are often of little use in an online scenario.\n\nTo tackle the aforementioned problems, our goal is to develop an anomaly detection approach which is accurate, efficient and general. Traditional statistical models [5, 14-17, 19, 20, 24] can be easily adopted online, but their accuracies are not sufficient for industrial applications. Supervised models [13,18] are superior in accuracy, but they are insufficient in our scenario because of lacking labeled data. There are other unsupervised approaches, for instance, Luminol [1] and DONUT [23]. However, these methods are either too time-consuming or parameter-sensitive. Therefore, we aim to develop a more competitive method in the unsupervised manner which favors accuracy, efficiency and generality simultaneously.\n\nIn this paper, we borrow the Spectral Residual model [10] from the visual saliency detection domain to our anomaly detection application. Spectral Residual (SR) is an efficient unsupervised algorithm, which demonstrates outstanding performance and robustness in the visual saliency detection tasks. To the best of our knowledge, our work is the first attempt to borrow this idea for time-series anomaly detection. The motivation is that the time-series anomaly detection task is similar to the problem of visual saliency detection essentially. Saliency is what \"stands out\" in a photo or scene, enabling our eye-brain connection to quickly (and essentially unconsciously) focus on the most important regions. Meanwhile, when anomalies appear in time-series curves, they are always the most salient part in vision.\n\nMoreover, we propose a novel approach based on the combination of SR and CNN. CNN is a state-of-the-art method for supervised saliency detection when sufficient labeled data is available; while SR is a state-of-the-art approach in unsupervised setting. Our innovation is to unite these two models by applying CNN on the basis of SR output directly. As the problem of anomaly discrimination becomes much easier upon the output of SR model, we can train CNN through automatically generated anomalies and achieve significant performance enhancement over the original SR model. Because the anomalies used for CNN training is fully synthetic, the SR-CNN approach remains unsupervised and establishes a new state-of-the-art performance when no manually labeled data is available.\n\nAs shown in the experiments, our proposed algorithm is more accurate and general than state-of-the-art unsupervised models. Furthermore, we also apply it as an additional feature in the supervised learning model. The experimental results demonstrate that the performance can be further improved when labeled data is available; and the additional features do provide complementary information to existing anomaly detectors. Up to the date of paper submission, the F 1 -score of our unsupervised and supervised approaches are both the best ever achieved on the open datasets.\n\nThe contributions of this paper are highlighted as below:\n\n\u2022 For the first time in the anomaly detection field, we borrow the technique of visual saliency detection to detect anomalies in time-series data. The inspiring results prove the possibility of using computer vision technologies to solve anomaly detection problems. \u2022 We combine the SR and CNN model to improve the accuracy of time-series anomaly detection. The idea is innovative and the approach outperforms current state-of-the-art methods by a large margin. Especially, the F 1 -score is improved by more than 20% on Microsoft production data. \u2022 From the practical perspective, the proposed solution has good generality and efficiency. It can be easily integrated with online monitoring systems to provide quick alerts for important online metrics. This technique has enabled product teams to move faster in detecting issues, save manual efforts, and accelerate the process of diagnostics.\n\nThe rest of this paper is organized as follows. First, in Section 2, we describe the details of system design, including data ingestion, experimentation platform and online compute. Then, we share our experience of real applications in Section 3 and introduce the methodology in Section 4. Experimental results are analyzed in Section 5 and related works are presented in Section 6. Finally, we conclude our work and put forward future work in Section 7.\n\n\nSYSTEM OVERVIEW\n\nThe whole system consists of three major components: data ingestion, experimentation platform and online compute. Before going into more detail about these components, we will introduce the whole pipeline first. Users can register monitoring tasks by ingesting time-series to the system. Ingesting time-series from different data sources (including Azure storage, databases and online streaming data) is supported. The ingestion worker is responsible for updating each time-series according to the designated granularity, for example, minute, hour, or day. Time-series points enter the streaming pipeline through Kafka and is stored into the timeseries database. Anomaly detection processor calculates the anomaly status for incoming time-series points online. In a common scenario of monitoring business metrics, users ingest a collection of time-series simultaneously. As an example, Bing team ingests the time-series representing the the usage of different markets and platforms. When incident happens, alert service combines anomalies of related time-series and sends them to users through emails and paging services. The combined anomalies show the overall status of an incident and help users to shorten the time in diagnosing issues. Figure 2 illustrates the general pipeline of the system.\n\n\nData Ingestion\n\nUsers can register a monitor task by creating a Datafeed. Each datafeed is identified by Connect String and Granularity. Connect String is used to connect user's storage system to the anomaly detection service. Granularity indicates the update frequency of a datafeed; and the minimum granularity is one minute. An ingestion task will ingest the data points of time-series to the system according to the given granularity. For example, if a user sets minute as the granularity, ingestion module will create a task every minute \n\n\nOnline Compute\n\nThe online compute module processes each data point immediately after it enters the pipeline. To detect anomaly status of an incoming point, a sliding window of the time-series data points is required. Therefore, we use Flink 3 to manage the points in memory to optimize the computation efficiency. Currently, the streaming pipeline processes more than 4 million time-series every day in production. The maximum throughput can be 4 million every minute. Anomaly detection processor detects anomalies for each single time-series. In practice, a single anomaly is not enough for users to diagnose their service efficiently. Thus, smart alert processor correlates the anomalies from difference time-series and generates an incident report accordingly. As anomaly detection is the main topic in this paper, smart alert is not discussed in more detail.\n\n\nExperimentation Platform\n\nWe build an experimentation platform to evaluate the performance of anomaly detection models. Before we deploy a new model, offline experiments and online A/B tests will be conducted on the platform. Users can mark a point as anomaly or not on the portal. A labeling service is provided to human editors. Editors will first label true anomaly points of a single time-series and then label false anomaly points from anomaly detection results of a specific model. Labeled data is used to evaluate the accuracy of the anomaly detection model. We also evaluate the efficiency and generality of each model on the platform. In online experiments, we flight several datafeeds to the new model. A couple of metrics, such as click through rate of alerts, percentage of anomalies and false anomaly rate is used to decide whether the new model can be deployed to production. The experimentation platform is built on Azure machine learning service 4 . If a model is verified to be effective, the platform will expose it as a web service and host it on K8s 5 .\n\n\nAPPLICATIONS\n\nAt Microsoft, it is a common need to monitor business metrics and act quickly to address the issue if there is anything outside of the normal pattern. To tackle the problem, we build a scalable system with the ability to monitor minute-level time-series from various data sources. Automated diagnostic insights are provided to assist users to resolve their issues efficiently. The service has been used by more than 200 product teams within Microsoft, across Office 365, Windows, Bing and Azure organizations, with more than 4 million time-series ingested and monitored continuously.\n\nAs an example, Michael from Bing team would like to monitor the usage of their service in the global marketplace. In the anomaly detection system, he created a new datafeed to ingest thousands of time-series, each indicating the usage of a specific market (US, UK, etc.), device (PC, windows phone, etc.) or channel (PORE, QBRE, etc.). Within 5 minutes, Michael saw the ingested time-series on the portal. At 9am, Oct-14, 2017, the time-series associated to the UK market encountered an incident. Michael was notified through   Figure 3(a)) and started to investigate the problem. He opened the incident report where the top correlated time-series with anomalies are selected from a set of time-series around 9am. As shown in Figure 3(b), usage on PC devices and PORE channel can be found in the incident report. Michael brought this insight to the team and finally found that the problem was caused by a relevance issue which made users do lots of pagination requests (PORE) to get satisfactory search results.\n\n\nE-mail alerts (as shown in\n\nAs another example, the Outlook anti-spam team used to leverage a rule-based method to monitor the effectiveness of their spam detection system. However, this method was not easy to be maintained and usually showed bad cases on some Geo-locations. Therefore, they ingested key metrics to our anomaly detection service to monitor the effectiveness of their spam detection model across different Geo-locations. Through our API, they have integrated anomaly detection ability into the Office DevOps platform. By using this automatic detection service, they have covered more Geo-locations and received less false positive cases compared to the original rule-based solution.\n\n\nMETHODOLOGY\n\nThe problem of time-series anomaly detection is defined as below.\n\nProblem 1. Given a sequence of real values, i.e., x = x 1 , x 2 , ..., x n , the task of time-series anomaly detection is to produce an output sequence, y = y 1 , y 2 , ..., y n , where y i \u2208 {0, 1} denotes whether x i is an anomaly point.\n\nAs emphasized in the Introduction, our challenge is to develop a general and efficient algorithm with no labeled data. Inspired by the domain of visual computing, we adopt Spectral Residual (SR) [10], a simple yet powerful approach based on Fast Fourier Transform (FFT) [21]. The SR approach is unsupervised and has been proved to be efficient and effective in visual saliency detection applications. We believe that the visual saliency detection and timeseries anomaly detection tasks are similar essentially, because the anomaly points are usually salient in the visual perspective.\n\nFurthermore, recent saliency detection research has shown favor to end-to-end training with Convolutional Neural Networks (CNNs) when sufficient labeled data is available [25]. Nevertheless, it is prohibitive for our application as large-scale labeled data is difficult to be collected online. As a trade-off, we propose a novel method, SR-CNN, which applies CNN on the output of SR model directly. CNN is responsible to learn a discriminate rule to replace the single threshold adopted by the original SR solution. The problem becomes much easier to learn the CNN model on SR results than on the original input sequence. Specifically, we can use artificially generated anomaly labels to train the CNN-based discriminator. In the following sub-sections, we introduce the details of SR and SR-CNN methods respectively.\n\n\nSR (Spectral Residual)\n\nThe Spectral Residual (SR) algorithm consists of three major steps:\n\n(1) Fourier Transform to get the log amplitude spectrum; (2) calculation of spectral residual; and (3) Inverse Fourier Transform that transforms the sequence back to spatial domain. Mathematically, given a sequence x, we have\nA(f ) = Amplitude(F(x)) (1) P(f ) = Phrase(F(x)) (2) L(f ) = lo\u0434(A(f )) (3) AL(f ) = h q (f ) \u00b7 L(f ) (4) R(f ) = L(f ) \u2212 AL(f ) (5) S(x) = F \u22121 (exp(R(f ) + iP(f ))) (6)\nwhere F and F \u22121 denote Fourier Transform and Inverse Fourier Transform respectively. x is the input sequence with shape n \u00d7 1; where h q (f ) is an q \u00d7 q matrix defined as:\nA(f ) ish q (f ) = 1 q 2 \uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 1 1 1 . . . 1 1 1 1 . . . 1 . . . . . . . . . . . . . . . 1 1 1 . . . 1 \uf8f9 \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fa \uf8fb R(f )\nis the spectral residual, i.e., the log spectrum L(f ) subtracting the averaged log spectrum AL(f ). The spectral residual serves as a compressed representation of the sequence while the innovation part of the original sequence becomes more significant. At last, we transfer the sequence back to spatial domain via Inverse Fourier Transform. The result sequence S(x) is called the saliency map. Figure 4 shows an example of the original time-series and the corresponding saliency map after SR processing. As shown in the figure, the innovation point (shown in red) in the saliency map is much more significant than that in the original input. Based on the saliency map, it is easy to leverage a simple rule to annotate the anomaly points correctly. We adopt a simple threshold \u03c4 to annote anomaly points. Given the saliency map S(x), the output sequence O(x) is computed by:\nO(x i ) = \uf8f1 \uf8f4 \uf8f4 \uf8f2 \uf8f4 \uf8f4 \uf8f3 1, if S (x i )\u2212S (x i ) S (x i ) ) > \u03c4 , 0, otherwise,(7)\nwhere x i represents an arbitrary point in sequence x; S(x i ) is the corresponding point in the saliency map; and S(x i ) is the local average of the preceding z points of S(x i ).\n\nIn practice, the FFT operation is conducted within a sliding window of the sequence. Moreover, we expect the algorithm to discover the anomaly points with low latency. That is, given a stream x 1 , x 2 , ..., x n where x n is the recent point, we want to tell if x n is an anomaly point as soon as possible. However, the SR method works better if the target point locates in the center of the sliding window. Thus, we add several estimated points after x n before inputting the sequence to SR model. The value of estimated point x n+1 is calculated by:\n\u0434 = 1 m m i=1 \u0434(x n , x n\u2212i ) (8) x n+1 = x n\u2212m+1 + \u0434 \u00b7 m(9)\nwhere \u0434(x i , x j ) denotes the gradient of the straight line between point x i and x j ; and \u0434 represents the average gradient of the preceding points. m is the number of preceding points considered, and we set m = 5 in our implementation. We find that the first estimated To summarize, the SR algorithm contains only a few hyperparameters, i.e., sliding window size \u03c9, estimated points number \u03ba, and anomaly detection threshold \u03c4 . We set them empirically and show their robustness in our experiments. Therefore, the SR algorithm is a good choice for online anomaly detection service.\n\n\nSR-CNN\n\nThe original SR method utilizes a single threshold upon the saliency map to detect anomaly points, as defined in Equation (7). However, this rule is so na\u00efve that it is natural to seek for more sophisticated decision rules. Our philosophy is to train a discriminative model on well-designed synthetic data as the anomaly detector. The synthetic data can be generated by injecting anomaly points into a collection of saliency maps that are not included in the evaluated data. The injection points are labeled as anomalies while others are labeled as normal. Concretely, we randomly select several points in the time series, calculate the injection value to replace the original point and get its saliency map. The values of anomaly points are calculated by:\nx = (x + mean)(1 + var ) \u00b7 r + x(10)\nwhere x is the local average of the preceding points; mean and var are the mean and variance of all points within the current sliding window; and r \u223c N (0, 1) is randomly sampled. We choose CNN as our discrimative model architecture. CNN is a commonly used supervised model for saliency detection [25]. However, as we do not have enough labeled data in our scenario, we apply CNN on the basis of saliency map instead of raw input, which makes the problem of anomaly annotation to be much easier. In practice, we collect production time-series with synthetic anomalies as training data. The advantage is that the detector can be adaptive to the change of time-series distribution, while no manually labeled data is required. In our experiments, we use totally 65 million points for training. The architecture of SR-CNN is visualized in Figure 5. The network is composed of two 1-D convolutional layers (with filter size equals to the sliding window size \u03c9) and two fully connected layers. The channel size of the first convolutional layer is equal to \u03c9; while the channel size is doubled in the second convolutional layer. Two full connected layers are stacked before Sigmoid output. Cross entropy is adopted as the loss function; and SGD optimizer is utilized in the training process. \n\n\nEXPERIMENTS 5.1 Datasets\n\nWe use three datasets to evaluate our model. KPI and Yahoo are public datasets 6 that are commonly used for evaluating the performance of time-series anomaly detection; while Microsoft is an internal dataset collected in the production. These datasets cover time-series of different time intervals and cover a broad spectrum of time-series patterns. In these datasets, anomaly points are labeled as positive samples and normal points are labeled as negative. The statistics of these datasets are shown in Table 1. KPI is released by AIOPS data competition [2, 3]. The dataset consists of multiple KPI curves with anomaly labels collected from various Internet Companies, including Sogou, Tecent, eBay, etc. Most KPI curves have an interval of 1 minute between two adjacent data points, while some of them have an interval of 5 minutes.\n\nYahoo is an open data set for anomaly detection released by Yahoo lab 7 . Part of the time-series curves is synthetic (i.e., simulated); while the other part comes from the real traffic of Yahoo services. The anomaly points in the simulated curves are algorithmically generated and those in the real-traffic curves are labeled by editors manually. The interval of all time-series is one hour.\n\nMicrosoft is a dataset obtained from our internal anomaly detection service at Microsoft. We select a collection of time-series randomly for evaluation. The selected time-series reflect different KPIs, including revenues, active users, number of pageviews, etc. The anomaly points are labeled by customers or editors manually; and the interval of these time-series is one day.\n\n\nMetrics\n\nWe evaluate our model from three aspects, accuracy, efficiency and generality. We use precision, recall and F 1 -score to indicate the accuracy of our model. In real applications, the human operators do not care about the point-wise metrics. It is acceptable for an algorithm to trigger an alert for any point in a contiguous anomaly segment if the delay is not too long. Thus, we adopt the evaluation strategy 8 following [23]. We mark the whole segment of continuous anomalies as a positive sample which means no matter how many anomalies have been detected in this segment, only one effective detection will be counted. If any point in an anomaly segment can be detected by the algorithm, and the delay of this point is no more than k from the start point of the anomaly segment, we say this segment is detected correctly. Thus, all points in this segment are 6 These two datasets are used only for research purpose and do not leveraged in production. 7 https://yahooresearch.tumblr.com/post/114590420346/ a-benchmark-dataset-for-time-series-anomaly 8 The evaluation script is available at https://github.com/iopsai/iops/tree/master/evaluation treated as correct, and the points outside the anomaly segments are treated as normal.\n\nThe evaluation strategy is illustrated in Figure 6. As shown in the first row of Figure 6, there are 10 contiguous points and two anomaly segments in the example time-series. The prediction results are shown in the second row. In this case, if we allow the delay as one point, i.e., k = 1, the first segment is treated as correct and the second is treated as incorrect (because the delay is more than one point). Thus, the adjusted results are illustrated in the third row. Based on the adjusted results, the value of precision, recall and F 1 -score can be calculated accordingly. In our experiments, we set k = 7 for minutely time-series, k = 3 for hourly time-series and k = 1 for daily time-series following the requirement of real application.\n\nEfficiency is another key indicator of anomaly detection models, especially for those be applied in online services. In the system, we must complete hundreds of thousands of calculations per second. The latency of the model needs to be small enough so that it won't block the whole computation pipeline. In our experiments, we evaluate total execution time on the three datasets to compare the efficiency of different anomaly detection approaches.\n\nBesides accuracy and efficiency, we also emphasize generality in our evaluation. As illustrated previously, an industrial anomaly detection model should have the ability to handle different types of time-series. To evaluate generality, we group the time-series in Yahoo dataset into 3 major classes (for example, seasonal, stable and unstable as shown in Figure 1) manually and compare the F 1 -score on different classes separately.\n\n\nSR/SR-CNN Experiment\n\nWe compare SR and SR-CNN with state-of-the-art unsupervised time-series anomaly detection methods. The baseline models include FFT (Fast Fourier Transform) [16], Twitter-AD (Twitter Anomaly Detection) [20], Luminol (LinkedIn Anomaly Detection) [1], DONUT [23], SPOT and DSPOT [19]. Among these methods, FFT, Twitter-AD and Luminol do not need additional data to start, so we compare these models in a cold-start setting by treating all the time-series as test data. On the other hand, SPOT, DSPOT and DONUT need additional data to train their models. Therefore, we split the points of each time-series as two halves according to the time order. The first half is utilized for training those unsupervised   V ar indicates the standard deviation of the overall F 1 -scores for the three classes models while the second half is leveraged for evaluation. Note that DONUT can leverage additional labeled data to benefit the anomaly detection performance. However, as we are aiming to get a fair comparison in the fully unsupervised setting, we do not use additional labeled data in the implementation 9 . The experiments are conducted in a streaming pipeline. The points of a time-series are ingested to the evaluation pipeline sequentially. In each turn, we only detect if the recent point is anomaly or not while the succeeding points are invisible. In the setting of cold-start, recommended configurations are applied to the baseline models which come from papers or codes published by the authors. For SR and SR-CNN, we set the hyper-parameters empirically. In SR, shape of h q (f ) q is set as 3, number of local average of preceding points z is set as 21, threshold \u03c4 is set as 3, number of estimated points \u03ba is set as 5, and the sliding window size \u03c9 is set as 1440 on 9 https://github.com/haowen-xu/donut KPI, 64 on Yahoo and 30 on Microsoft. For SR-CNN, q, z, \u03ba and \u03c9 are set to the same value.\n\nWe report (1) F 1 -score; (2) Precision; (3) Recall; and (4) CPU execution times separately for each dataset. We can see that SR significantly outperforms current state-of-the-art unsupervised models. Furthermore, SR-CNN achieves further improvement on all three datasets, which shows the advantage of replacing the single threshold by a CNN discriminator. Table 2 shows comparison results of FFT, Twitter-AD and Luminol in the cold-start scenario. We improve the F 1 -score by 36.1% on KPI dataset, 68.8% on Yahoo dataset and 21.2% on Microsoft dataset compared to the best results achieved by baseline solutions. Table 3 demonstrates the comparison results of those unsupervised models which need to be trained on the first half of the dataset (labels are excluded). As shown in Table 3, the F 1 -score is improved by 48.0% on KPI dataset, 92.9% on Yahoo dataset and 57.0% on Microsoft dataset than the best state-of-the-art results.\n\nMoreover, SR is the most efficient method as indicated by the total CPU execution time in Table 2 and 3. SR-CNN achieves better accuracy with a reasonable latency increase. For generality comparison, we conduct the experiments on the second half of Yahoo dataset, which is classified into three classes manually. F 1 -score on different classes of Yahoo dataset is reported separately in Table 4. SR and SR-CNN achieve outstanding results on various patterns of time-series. SR is the most stable one across the three classes. SR-CNN also demonstrates good capability of generalization.\n\n\nSR+DNN\n\nIn the previous experiments, we can see that the SR model shows convincing results in the unsupervised anomaly detection scenario. However, when labels of anomalies are available, we can obtain more satisfactory results as illustrated in previous works [13]. Thus, we would like to know whether our methodology contributes to the Transformations Transformations to the value of each data point. We use logarithm as our transformation function and leverage the result value as a feature.\n\n\nStatistics\n\nWe applied sliding windows to the time-series and treat the statistics calculated in each sliding window as features.\n\nThe statistics we used include mean, exponential weighted mean, min, max, standard deviation, and the quantity of the data point values within a sliding window. We use multiple sizes of the sliding window to generate different features. The sizes are [10,50,100,200,500,1440] Ratios\n\nThe ratios of current point value against other statistics or transformations\n\n\nDifferences\n\nThe differences of current point value against other statistics or transformations  We adopt the DNN-based supervised model [4] which is the champion in the AIOPS data competition. The DNN architecture is composed by an input layer, an output layer and two hidden layers (shown in Figure 7). We add a dropout layer after the second hidden layer and set dropout ratio as 0.5. In addition, we apply L 1 = L 2 = 0.0001 regularization to the weights of all layers. Since the output of the model indicates the likelihood of a data point being an anomaly, we search for the optimal threshold on the training set.\n\nEach data point is associated with a feature vector, which consists of different types of features including transformations, statistics, ratios, and differences (Table 5). We follow the official train/test split of the dataset, where the statistics is shown in Table 6. We can see that the proportion of positive and negative samples is extremely imbalanced. Thus, we train our model by over-sampling anomalies to keep the positive/negative proportion to 1:2.\n\nExperimental results are shown in Table 7. We can see that the SR feature brings 1.6% improvement in F 1 -score to the vanilla DNN model. Especially, the SR-powered DNN model establishes a new state-of-the-art on the KPI dataset. To the best of our knowledge, it is the best-ever result reported on the KPI dataset up to the date of paper submission. Moreover, we draw the P-R curve of the SR+DNN and DNN methods. As illustrated in Figure 8, SR+DNN outperforms the vanilla DNN consistently on various threshold. Previous works can be categorized into statistical, supervised and unsupervised approaches. In the past years, several models were subsequently proposed in the statistics literature, including hypothesis testing [17], wavelet analysis [14], SVD [15] and auto-regressive integrated moving average (ARIMA) [24]. Fast Fourier Transform (FFT) [21] is another traditional method for time-series processing. For example, [16] highlighted the areas with high frequency change by FFT and reconfirmed it with Z-value test. In 2015, Twitter [20] proposed a model to detect anomalies in time-series of both application metrics (e.g., Tweets Per Sec) and system metrics (e.g., CPU utilization). In 2017, SPOT and DSPOT [19] were proposed on the basis of Extreme Value Theory [6], the threshold of which can be selected automatically.\n\nThe performances of traditional statistical models are not satisfactory in real applications. Thus, researchers have investigated supervised models to improve the anomaly detection accuracy. Opprentice [13] outperformed other traditional detectors by using statistical detectors as feature extractors and leveraged a Random Forest classifier [12] to detect anomalies. Yahoo EGADS [11] utilized a collection of anomaly detection and forecasting models with an anomaly filtering layer for scalable anomaly detection on timeseries data. In 2017, Google leveraged deep learning models to detect anomalies on their own dataset [18] and achieved promising results. However, continuous labels can not be obtained in industrial environment, which makes these supervised approaches insufficient in online applications.\n\nAs a result, advanced unsupervised approaches have been studied to tackle the problem in industrial application. In 2018, [23] proposed DONUT, an unsupervised anomaly detection method based on Variational Auto-Encoder (VAE) [7]. VAE was leveraged to model the reconstruction probabilities of normal time-series, while the abnormal points were reported if the reconstruction error was larger than a threshold. Besides, LinkedIn developed Luminol [1] based on [22], which segmented time-series into chunks and used the frequency of similar chunks to calculate anomaly scores.\n\n\nSaliency detection approaches\n\nOur work has been inspired by visual saliency detection models. Hou et al. [10] invented the Spectral Residual (SR) model for saliency detection and demonstrated impressive performance in their experiments. They assumed that an image can be divided into redundant part and innovation part, while people's vision is more sensitive to the innovation part. Meanwhile, the log amplitude spectrum of an image subtracting the average log amplitude spectrum captures the saliency part of the image. Guo et al. [8] argued that only phase spectrum was enough to detect the saliency part of an image and simplified the algorithm in [10]. Hou et al. [9] also proposed an image signature approach for highlighting sparse salient regions with theoretical proof. Although the latter two solutions showed improvement in their publications, we found that Spectral Residual (SR) was more effective in our time-series anomaly detection scenario. Moreover, supervised models based on neural networks are also used in saliency detection. For instance, Zhao et al. [25] tackled the problem of salient object detection by a multi-context deep learning framework based on CNN architecture.\n\n\nCONCLUSION & FUTURE WORK\n\nTime-series anomaly detection is a critical module to ensure the quality of online services. An efficient, general and accurate anomaly detection system is indispensable in real applications. In this paper, we have introduced a time-series anomaly detection service at Microsoft. The service has been used by more than 200 teams within Microsoft, including Bing, Office and Azure. Anomalies are detected from 4 million time-series per minute maximally in the production. Moreover, we for the first time apply the Spectral Residual (SR) model in the time-series anomaly detection task and innovatively combine the SR and CNN model to achieve an outstanding performance. In the future, we plan to ensemble the state-of-theart methods together to provide a more robust anomaly detection service to our customers. Besides internal serving, our time-series anomaly detection service will be published on Microsoft Azure as part of Cognitive Service 10 shortly to external customers.\n\nFigure 1 :\n1Different types of time-series.\n\nFigure 2 :\n2System Overview to ingest a new data point. Time-series points are ingested into in-fluxDB 1 and Kafka 2 . Throughput of this module varies from 10,000 to 100,000 data points per second.\n\nFigure 3 :\n3An illustration of example application from Microsoft Bing\n\nFigure 4 :\n4the amplitude spectrum of sequence x; P(f ) is the corresponding phase spectrum of sequence x; L(f ) is the log representation of A(f ); and AL(f ) is the average spectrum of L(f ) which can be approximated by convoluting the input sequence by h q (f ), Example of SR model results\n\nFigure 5 :\n5SR-CNN architecture point plays a decisive role. Thus, we just copy x n+1 for \u03ba times and add the points to the tail of the sequence.\n\nFigure 6 :\n6Illustration of the evaluation strategy. There are 10 contiguous points in the time-series, where the first row indicates ground truth; the second row shows the point-wise anomaly detection results; and the third row shows adjusted results according to the evaluation strategy.\n\nFigure 7\n7Figure 7: DNN architecture\n\nTable 1 :\n1Statistics of datasetsDataSet \nTotal Curves Total Points Anomaly Points \n\nKPI \n58 \n5922913 \n134114/2.26% \nYahoo \n367 \n572966 \n3896/0.68% \nMicrosoft \n372 \n66132 \n1871/2.83% \n\n\n\nTable 2 :\n2Result comparison of cold-startKPI \nYahoo \nMicrosoft \n\nModel \nF 1 -score Precision Recall Time(s) F 1 -score Precision Recall Time(s) F 1 -score Precision Recall T ime(s) \n\nFFT \n0.538 \n0.478 \n0.615 3756.63 \n0.291 \n0.202 \n0.517 \n356.56 \n0.349 \n0.812 \n0.218 \n8.38 \nTwitter-AD \n0.330 \n0.411 \n0.276 523232.0 \n0.245 \n0.166 \n0.462 301601.50 \n0.347 \n0.716 \n0.229 6698.80 \nLuminol \n0.417 \n0.306 \n0.650 14244.92 0.388 \n0.254 \n0.818 \n1071.25 \n0.443 \n0.776 \n0.310 \n16.26 \nSR \n0.666 \n0.637 \n0.697 1427.08 \n0.529 \n0.404 \n0.765 \n43.59 \n0.484 \n0.878 \n0.334 \n2.45 \nSR-CNN \n0.732 \n0.811 \n0.667 6805.13 \n0.655 \n0.786 \n0.561 \n279.97 \n0.537 \n0.468 \n0.630 \n25.26 \n\n\n\nTable 3 :\n3Result comparison on test data \n\nKPI \nYahoo \nMicrosoft \n\nModel \nF 1 -score Precision Recall Time(s) F 1 -score Precision Recall Time(s) F 1 -score Precision Recall T ime(s) \n\nSPOT \n0.217 \n0.786 \n0.126 \n9097.85 \n0.338 \n0.269 \n0.454 2893.08 \n0.244 \n0.702 \n0.147 \n9.43 \nDSPOT \n0.521 \n0.623 \n0.447 \n1634.41 \n0.316 \n0.241 \n0.458 \n339.62 \n0.190 \n0.394 \n0.125 \n1.37 \nDONUT \n0.347 \n0.371 \n0.326 24248.13 \n0.026 \n0.013 \n0.825 2572.76 \n0.323 \n0.241 \n0.490 \n288.36 \nSR \n0.622 \n0.647 \n0.598 \n724.02 \n0.563 \n0.451 \n0.747 \n22.71 \n0.440 \n0.814 \n0.301 \n1.55 \nSR-CNN \n0.771 \n0.797 \n0.747 \n2724.33 \n0.652 \n0.816 \n0.542 \n125.37 \n0.507 \n0.441 \n0.595 \n16.13 \n\n\n\nTable 4 :\n4Generality Comparison on Yahoo datasetSeasonal Stable Unstable Overall V ar \nFFT \n0.446 \n0.370 \n0.301 \n0.364 \n0.060 \nTwitter-AD \n0.397 \n0.924 \n0.438 \n0.466 \n0.268 \nLuminol \n0.374 \n0.763 \n0.428 \n0.430 \n0.195 \nSPOT \n0.199 \n0.879 \n0.356 \n0.338 \n0.322 \nDSPOT \n0.211 \n0.485 \n0.379 \n0.316 \n0.120 \nDONUT \n0.023 \n0.032 \n0.029 \n0.026 \n0.004 \nSR \n0.558 \n0.601 \n0.556 \n0.563 \n0.023 \nSR-CNN \n0.716 \n0.752 \n0.464 \n0.652 \n0.128 \n\n\n\nTable 5 :\n5Features used in the supervised DNN modelFeature \nDescription \n\n\n\nTable 6 :\n6Train and test split of KPI datasetDataSet Total points Anomaly points \n\nTrain \n3004066 \n79554/2.65% \n\nTest \n2918847 \n54560/1.87% \n\n\n\nTable 7 :\n7Supervised results on KPI dataset Model F 1 -score Precision Recall supervised scenario as well. Concretely, we treat the intermediate results of SR as an additional feature in the supervised anomaly detection model. We conduct the experiment on KPI dataset as it has been extensively studied in the AIOPS data competition [3].DNN \n0.798 \n0.849 \n0.753 \n\nSR+DNN \n0.811 \n0.915 \n0.728 \n\n\nhttps://www.influxdata.com/ 2 https://kafka.apache.org/ 3 https://flink.apache.org/\nhttps://azure.microsoft.com/en-us/services/machine-learning-service/ 5 https://kubernetes.io/docs/concepts/overview/what-is-kubernetes/\nhttps://azure.microsoft.com/en-us/services/cognitive-services/\n\nHolt-Winters forecasting Procedure. Chris Chatfield, Journal of the Royal Statistical Society, Applied Statistics. 27Chris Chatfield. 1978. Holt-Winters forecasting Procedure. Journal of the Royal Statistical Society, Applied Statistics 27, 3 (1978), 264\u00e2\u0102\u015e-279.\n\nExtreme value theory: an introduction. Laurens De Haan, Ana Ferreira, Springer Science & Business MediaLaurens De Haan and Ana Ferreira. 2007. Extreme value theory: an introduction. Springer Science & Business Media.\n\nCarl Doersch, arXiv:1606.05908Tutorial on variational autoencoders. arXiv preprintCarl Doersch. 2016. Tutorial on variational autoencoders. arXiv preprint arXiv:1606.05908 (2016).\n\nSpatio-temporal saliency detection using phase spectrum of quaternion fourier transform. Chenlei Guo, Qi Ma, Liming Zhang, Chenlei Guo, Qi Ma, and Liming Zhang. 2008. Spatio-temporal saliency detection using phase spectrum of quaternion fourier transform. (2008).\n\nImage signature: Highlighting sparse salient regions. Xiaodi Hou, Jonathan Harel, Christof Koch, IEEE transactions. 34Xiaodi Hou, Jonathan Harel, and Christof Koch. 2012. Image signature: High- lighting sparse salient regions. IEEE transactions on pattern analysis and machine intelligence 34, 1 (2012), 194-201.\n\nSaliency detection: A spectral residual approach. Xiaodi Hou, Liqing Zhang, Computer Vision and Pattern Recognition, 2007. CVPR'07. Xiaodi Hou and Liqing Zhang. 2007. Saliency detection: A spectral residual approach. In Computer Vision and Pattern Recognition, 2007. CVPR'07. IEEE Con- ference on. IEEE, 1-8.\n\nGeneric and Scalable Framework for Automated Time-series Anomaly Detection. Nikolay Laptev, Saeed Amizadeh, Ian Flint, Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data MiningNew York, NY, USAACMNikolay Laptev, Saeed Amizadeh, and Ian Flint. 2015. Generic and Scalable Framework for Automated Time-series Anomaly Detection. In Proceedings of the 21th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, New York, NY, USA, 1939-1947.\n\nClassification and regression by ran-domForest. Andy Liaw, Matthew Wiener, 2R newsAndy Liaw, Matthew Wiener, et al. 2002. Classification and regression by ran- domForest. R news 2, 3 (2002), 18-22.\n\nOpprentice: Towards practical and automatic anomaly detection through machine learning. Dapeng Liu, Youjian Zhao, Haowen Xu, Yongqian Sun, Dan Pei, Jiao Luo, Xiaowei Jing, Mei Feng, Proceedings of the 2015 Internet Measurement Conference. the 2015 Internet Measurement ConferenceACMDapeng Liu, Youjian Zhao, Haowen Xu, Yongqian Sun, Dan Pei, Jiao Luo, Xi- aowei Jing, and Mei Feng. 2015. Opprentice: Towards practical and automatic anomaly detection through machine learning. In Proceedings of the 2015 Internet Measurement Conference. ACM, 211-224.\n\nNetwork anomaly detection based on wavelet analysis. Wei Lu, Ali A Ghorbani, EURASIP Journal on Advances in Signal Processing. 4Wei Lu and Ali A Ghorbani. 2009. Network anomaly detection based on wavelet analysis. EURASIP Journal on Advances in Signal Processing 2009 (2009), 4.\n\nRapid detection of maintenance induced changes in service performance. Ajay Mahimkar, Zihui Ge, Jia Wang, Jennifer Yates, Yin Zhang, Joanne Emmons, Brian Huntley, Mark Stockert, Proceedings of the Seventh COnference on emerging Networking EXperiments and Technologies. the Seventh COnference on emerging Networking EXperiments and TechnologiesACM13Ajay Mahimkar, Zihui Ge, Jia Wang, Jennifer Yates, Yin Zhang, Joanne Emmons, Brian Huntley, and Mark Stockert. 2011. Rapid detection of maintenance induced changes in service performance. In Proceedings of the Seventh COnference on emerging Networking EXperiments and Technologies. ACM, 13.\n\nFourier transform based spatial outlier mining. Faraz Rasheed, Peter Peng, Reda Alhajj, Jon Rokne, International Conference on Intelligent Data Engineering and Automated Learning. SpringerFaraz Rasheed, Peter Peng, Reda Alhajj, and Jon Rokne. 2009. Fourier trans- form based spatial outlier mining. In International Conference on Intelligent Data Engineering and Automated Learning. Springer, 317-324.\n\nPercentage points for a generalized ESD many-outlier procedure. Bernard Rosner, Technometrics. 25Bernard Rosner. 1983. Percentage points for a generalized ESD many-outlier procedure. Technometrics 25, 2 (1983), 165-172.\n\nTime Series Anomaly Detection: Detection of Anomalous Drops with Limited Features and Sparse Examples in Noisy Periodic Data. Dominique Shipmon, Jason Gurevitch, Paolo M Piselli, Steve Edwards, Google IncTechnical ReportDominique Shipmon, Jason Gurevitch, Paolo M Piselli, and Steve Edwards. 2017. Time Series Anomaly Detection: Detection of Anomalous Drops with Limited Features and Sparse Examples in Noisy Periodic Data. Technical Report. Google Inc.\n\nAnomaly detection in streams with extreme value theory. Alban Siffer, Pierre-Alain Fouque, Alexandre Termier, Christine Largouet, Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data MiningACMAlban Siffer, Pierre-Alain Fouque, Alexandre Termier, and Christine Largouet. 2017. Anomaly detection in streams with extreme value theory. In Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 1067-1075.\n\nA Novel Technique for Long-Term Anomaly Detection in the Cloud. Owen Vallis, Jordan Hochenbaum, Arun Kejariwal, 6th USENIX Workshop on Hot Topics in Cloud Computing (HotCloud 14). USENIX Association. Philadelphia, PAOwen Vallis, Jordan Hochenbaum, and Arun Kejariwal. 2014. A Novel Technique for Long-Term Anomaly Detection in the Cloud. In 6th USENIX Workshop on Hot Topics in Cloud Computing (HotCloud 14). USENIX Association, Philadelphia, PA.\n\nComputational frameworks for the fast Fourier transform. Charles Van Loan, 10SiamCharles Van Loan. 1992. Computational frameworks for the fast Fourier transform. Vol. 10. Siam.\n\nAssumption-free Anomaly Detection in Time Series. Li Wei, Nitin Kumar, Venkata Lolla, J Eamonn, Stefano Keogh, Chotirat Lonardi, Ratanamahatana, Proceedings of the 17th International Conference on Scientific and Statistical Database Management (SSDBM'2005. the 17th International Conference on Scientific and Statistical Database Management (SSDBM'2005Li Wei, Nitin Kumar, Venkata Lolla, Eamonn J. Keogh, Stefano Lonardi, and Choti- rat Ratanamahatana. 2005. Assumption-free Anomaly Detection in Time Series. In Proceedings of the 17th International Conference on Scientific and Statistical Database Management (SSDBM'2005). 237-240.\n\nUnsupervised Anomaly Detection via Variational Auto-Encoder for Seasonal KPIs in Web Applications. Haowen Xu, Wenxiao Chen, Nengwen Zhao, Zeyan Li, Jiahao Bu, Zhihan Li, Ying Liu, Youjian Zhao, Dan Pei, Yang Feng, Proceedings of the 2018 World Wide Web Conference on World Wide Web. International World Wide Web Conferences Steering Committee. the 2018 World Wide Web Conference on World Wide Web. International World Wide Web Conferences Steering CommitteeHaowen Xu, Wenxiao Chen, Nengwen Zhao, Zeyan Li, Jiahao Bu, Zhihan Li, Ying Liu, Youjian Zhao, Dan Pei, Yang Feng, et al. 2018. Unsupervised Anomaly Detection via Variational Auto-Encoder for Seasonal KPIs in Web Applications. In Proceedings of the 2018 World Wide Web Conference on World Wide Web. Inter- national World Wide Web Conferences Steering Committee, 187-196.\n\nNetwork anomography. Yin Zhang, Zihui Ge, Albert Greenberg, Matthew Roughan, Proceedings of the 5th ACM SIGCOMM conference on Internet Measurement. USENIX Association. the 5th ACM SIGCOMM conference on Internet Measurement. USENIX AssociationYin Zhang, Zihui Ge, Albert Greenberg, and Matthew Roughan. 2005. Network anomography. In Proceedings of the 5th ACM SIGCOMM conference on Internet Measurement. USENIX Association, 30-30.\n\nSaliency detection by multi-context deep learning. Rui Zhao, Wanli Ouyang, Hongsheng Li, Xiaogang Wang, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. the IEEE Conference on Computer Vision and Pattern RecognitionRui Zhao, Wanli Ouyang, Hongsheng Li, and Xiaogang Wang. 2015. Saliency detection by multi-context deep learning. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 1265-1274.\n", "annotations": {"author": "[{\"end\":152,\"start\":94},{\"end\":209,\"start\":153},{\"end\":289,\"start\":210},{\"end\":343,\"start\":290},{\"end\":403,\"start\":344},{\"end\":460,\"start\":404},{\"end\":538,\"start\":461},{\"end\":615,\"start\":539},{\"end\":692,\"start\":616},{\"end\":769,\"start\":693},{\"end\":828,\"start\":770},{\"end\":885,\"start\":829},{\"end\":943,\"start\":886},{\"end\":997,\"start\":944},{\"end\":1057,\"start\":998},{\"end\":1115,\"start\":1058},{\"end\":1171,\"start\":1116},{\"end\":1226,\"start\":1172},{\"end\":1281,\"start\":1227},{\"end\":1336,\"start\":1282}]", "publisher": null, "author_last_name": "[{\"end\":106,\"start\":103},{\"end\":163,\"start\":161},{\"end\":221,\"start\":217},{\"end\":297,\"start\":295},{\"end\":357,\"start\":352},{\"end\":414,\"start\":411},{\"end\":470,\"start\":466},{\"end\":547,\"start\":543},{\"end\":624,\"start\":620},{\"end\":701,\"start\":696},{\"end\":782,\"start\":779},{\"end\":839,\"start\":837},{\"end\":897,\"start\":893},{\"end\":951,\"start\":949},{\"end\":1011,\"start\":1006},{\"end\":1069,\"start\":1066},{\"end\":1125,\"start\":1121},{\"end\":1180,\"start\":1176},{\"end\":1235,\"start\":1231},{\"end\":1290,\"start\":1285}]", "author_first_name": "[{\"end\":102,\"start\":94},{\"end\":160,\"start\":153},{\"end\":216,\"start\":210},{\"end\":294,\"start\":290},{\"end\":351,\"start\":344},{\"end\":410,\"start\":404},{\"end\":465,\"start\":461},{\"end\":542,\"start\":539},{\"end\":619,\"start\":616},{\"end\":695,\"start\":693},{\"end\":778,\"start\":770},{\"end\":836,\"start\":829},{\"end\":892,\"start\":886},{\"end\":948,\"start\":944},{\"end\":1005,\"start\":998},{\"end\":1065,\"start\":1058},{\"end\":1120,\"start\":1116},{\"end\":1175,\"start\":1172},{\"end\":1230,\"start\":1227},{\"end\":1284,\"start\":1282}]", "author_affiliation": "[{\"end\":151,\"start\":108},{\"end\":208,\"start\":165},{\"end\":288,\"start\":245},{\"end\":342,\"start\":299},{\"end\":402,\"start\":359},{\"end\":459,\"start\":416},{\"end\":537,\"start\":494},{\"end\":614,\"start\":571},{\"end\":691,\"start\":648},{\"end\":768,\"start\":725},{\"end\":827,\"start\":784},{\"end\":884,\"start\":841},{\"end\":942,\"start\":899},{\"end\":996,\"start\":953},{\"end\":1056,\"start\":1013},{\"end\":1114,\"start\":1071},{\"end\":1170,\"start\":1127},{\"end\":1225,\"start\":1182},{\"end\":1280,\"start\":1237},{\"end\":1335,\"start\":1292}]", "title": "[{\"end\":51,\"start\":1},{\"end\":1387,\"start\":1337}]", "venue": "[{\"end\":1468,\"start\":1389}]", "abstract": "[{\"end\":3227,\"start\":2136}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b6\"},\"end\":3705,\"start\":3701},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":3708,\"start\":3705},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":3862,\"start\":3858},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":5287,\"start\":5284},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":5343,\"start\":5339},{\"end\":6096,\"start\":6074},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":6218,\"start\":6214},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":6221,\"start\":6218},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":6404,\"start\":6400},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":6688,\"start\":6684},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":16846,\"start\":16842},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":16921,\"start\":16917},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":17408,\"start\":17404},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":22302,\"start\":22298},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":24223,\"start\":24222},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":25361,\"start\":25357},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":25798,\"start\":25797},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":25988,\"start\":25987},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":27986,\"start\":27982},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":28031,\"start\":28027},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":28085,\"start\":28081},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":28106,\"start\":28102},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":28923,\"start\":28922},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":31518,\"start\":31514},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":32136,\"start\":32132},{\"end\":32139,\"start\":32136},{\"end\":32143,\"start\":32139},{\"end\":32147,\"start\":32143},{\"end\":32151,\"start\":32147},{\"end\":32156,\"start\":32151},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":34056,\"start\":34052},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":34079,\"start\":34075},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":34089,\"start\":34085},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":34148,\"start\":34144},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":34183,\"start\":34179},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":34259,\"start\":34255},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":34375,\"start\":34371},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":34551,\"start\":34547},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":34606,\"start\":34603},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":34869,\"start\":34865},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":35009,\"start\":35005},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":35047,\"start\":35043},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":35289,\"start\":35285},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":35600,\"start\":35596},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":35701,\"start\":35698},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":35936,\"start\":35932},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":36160,\"start\":36156},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":36587,\"start\":36584},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":36707,\"start\":36703},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":36723,\"start\":36720},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":37129,\"start\":37125}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":38298,\"start\":38254},{\"attributes\":{\"id\":\"fig_1\"},\"end\":38498,\"start\":38299},{\"attributes\":{\"id\":\"fig_3\"},\"end\":38570,\"start\":38499},{\"attributes\":{\"id\":\"fig_4\"},\"end\":38865,\"start\":38571},{\"attributes\":{\"id\":\"fig_5\"},\"end\":39012,\"start\":38866},{\"attributes\":{\"id\":\"fig_6\"},\"end\":39303,\"start\":39013},{\"attributes\":{\"id\":\"fig_7\"},\"end\":39341,\"start\":39304},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":39528,\"start\":39342},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":40185,\"start\":39529},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":40837,\"start\":40186},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":41266,\"start\":40838},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":41343,\"start\":41267},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":41488,\"start\":41344},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":41885,\"start\":41489}]", "paragraph": "[{\"end\":4289,\"start\":3243},{\"end\":4386,\"start\":4291},{\"end\":4869,\"start\":4388},{\"end\":5907,\"start\":4871},{\"end\":6629,\"start\":5909},{\"end\":7444,\"start\":6631},{\"end\":8219,\"start\":7446},{\"end\":8794,\"start\":8221},{\"end\":8853,\"start\":8796},{\"end\":9748,\"start\":8855},{\"end\":10204,\"start\":9750},{\"end\":11521,\"start\":10224},{\"end\":12067,\"start\":11540},{\"end\":12933,\"start\":12086},{\"end\":14009,\"start\":12962},{\"end\":14609,\"start\":14026},{\"end\":15622,\"start\":14611},{\"end\":16323,\"start\":15653},{\"end\":16404,\"start\":16339},{\"end\":16645,\"start\":16406},{\"end\":17231,\"start\":16647},{\"end\":18050,\"start\":17233},{\"end\":18144,\"start\":18077},{\"end\":18371,\"start\":18146},{\"end\":18716,\"start\":18543},{\"end\":19730,\"start\":18856},{\"end\":19994,\"start\":19813},{\"end\":20548,\"start\":19996},{\"end\":21196,\"start\":20610},{\"end\":21963,\"start\":21207},{\"end\":23286,\"start\":22001},{\"end\":24150,\"start\":23315},{\"end\":24544,\"start\":24152},{\"end\":24922,\"start\":24546},{\"end\":26167,\"start\":24934},{\"end\":26917,\"start\":26169},{\"end\":27366,\"start\":26919},{\"end\":27801,\"start\":27368},{\"end\":29725,\"start\":27826},{\"end\":30662,\"start\":29727},{\"end\":31250,\"start\":30664},{\"end\":31747,\"start\":31261},{\"end\":31879,\"start\":31762},{\"end\":32163,\"start\":31881},{\"end\":32242,\"start\":32165},{\"end\":32864,\"start\":32258},{\"end\":33326,\"start\":32866},{\"end\":34661,\"start\":33328},{\"end\":35472,\"start\":34663},{\"end\":36047,\"start\":35474},{\"end\":37247,\"start\":36081},{\"end\":38253,\"start\":37276}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":18542,\"start\":18372},{\"attributes\":{\"id\":\"formula_1\"},\"end\":18725,\"start\":18717},{\"attributes\":{\"id\":\"formula_2\"},\"end\":18855,\"start\":18725},{\"attributes\":{\"id\":\"formula_3\"},\"end\":19812,\"start\":19731},{\"attributes\":{\"id\":\"formula_4\"},\"end\":20609,\"start\":20549},{\"attributes\":{\"id\":\"formula_5\"},\"end\":22000,\"start\":21964}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":23827,\"start\":23820},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":30091,\"start\":30084},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":30349,\"start\":30342},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":30515,\"start\":30508},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":30761,\"start\":30754},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":31059,\"start\":31052},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":33037,\"start\":33028},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":33135,\"start\":33128},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":33369,\"start\":33362}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":3241,\"start\":3229},{\"attributes\":{\"n\":\"2\"},\"end\":10222,\"start\":10207},{\"attributes\":{\"n\":\"2.1\"},\"end\":11538,\"start\":11524},{\"attributes\":{\"n\":\"2.2\"},\"end\":12084,\"start\":12070},{\"attributes\":{\"n\":\"2.3\"},\"end\":12960,\"start\":12936},{\"attributes\":{\"n\":\"3\"},\"end\":14024,\"start\":14012},{\"end\":15651,\"start\":15625},{\"attributes\":{\"n\":\"4\"},\"end\":16337,\"start\":16326},{\"attributes\":{\"n\":\"4.1\"},\"end\":18075,\"start\":18053},{\"attributes\":{\"n\":\"4.2\"},\"end\":21205,\"start\":21199},{\"attributes\":{\"n\":\"5\"},\"end\":23313,\"start\":23289},{\"attributes\":{\"n\":\"5.2\"},\"end\":24932,\"start\":24925},{\"attributes\":{\"n\":\"5.3\"},\"end\":27824,\"start\":27804},{\"attributes\":{\"n\":\"5.4\"},\"end\":31259,\"start\":31253},{\"end\":31760,\"start\":31750},{\"end\":32256,\"start\":32245},{\"attributes\":{\"n\":\"6.2\"},\"end\":36079,\"start\":36050},{\"attributes\":{\"n\":\"7\"},\"end\":37274,\"start\":37250},{\"end\":38265,\"start\":38255},{\"end\":38310,\"start\":38300},{\"end\":38510,\"start\":38500},{\"end\":38582,\"start\":38572},{\"end\":38877,\"start\":38867},{\"end\":39024,\"start\":39014},{\"end\":39313,\"start\":39305},{\"end\":39352,\"start\":39343},{\"end\":39539,\"start\":39530},{\"end\":40196,\"start\":40187},{\"end\":40848,\"start\":40839},{\"end\":41277,\"start\":41268},{\"end\":41354,\"start\":41345},{\"end\":41499,\"start\":41490}]", "table": "[{\"end\":39528,\"start\":39376},{\"end\":40185,\"start\":39572},{\"end\":40837,\"start\":40198},{\"end\":41266,\"start\":40888},{\"end\":41343,\"start\":41320},{\"end\":41488,\"start\":41391},{\"end\":41885,\"start\":41828}]", "figure_caption": "[{\"end\":38298,\"start\":38267},{\"end\":38498,\"start\":38312},{\"end\":38570,\"start\":38512},{\"end\":38865,\"start\":38584},{\"end\":39012,\"start\":38879},{\"end\":39303,\"start\":39026},{\"end\":39341,\"start\":39315},{\"end\":39376,\"start\":39354},{\"end\":39572,\"start\":39541},{\"end\":40888,\"start\":40850},{\"end\":41320,\"start\":41279},{\"end\":41391,\"start\":41356},{\"end\":41828,\"start\":41501}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":5013,\"start\":5005},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":11473,\"start\":11465},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":15147,\"start\":15139},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":15345,\"start\":15337},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":19259,\"start\":19251},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":22844,\"start\":22836},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":26219,\"start\":26211},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":26258,\"start\":26250},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":27731,\"start\":27723},{\"attributes\":{\"ref_id\":\"fig_7\"},\"end\":32547,\"start\":32539},{\"end\":33768,\"start\":33760}]", "bib_author_first_name": "[{\"end\":42211,\"start\":42206},{\"end\":42480,\"start\":42473},{\"end\":42493,\"start\":42490},{\"end\":42656,\"start\":42652},{\"end\":42929,\"start\":42922},{\"end\":42937,\"start\":42935},{\"end\":42948,\"start\":42942},{\"end\":43158,\"start\":43152},{\"end\":43172,\"start\":43164},{\"end\":43188,\"start\":43180},{\"end\":43468,\"start\":43462},{\"end\":43480,\"start\":43474},{\"end\":43805,\"start\":43798},{\"end\":43819,\"start\":43814},{\"end\":43833,\"start\":43830},{\"end\":44364,\"start\":44360},{\"end\":44378,\"start\":44371},{\"end\":44605,\"start\":44599},{\"end\":44618,\"start\":44611},{\"end\":44631,\"start\":44625},{\"end\":44644,\"start\":44636},{\"end\":44653,\"start\":44650},{\"end\":44663,\"start\":44659},{\"end\":44676,\"start\":44669},{\"end\":44686,\"start\":44683},{\"end\":45118,\"start\":45115},{\"end\":45126,\"start\":45123},{\"end\":45128,\"start\":45127},{\"end\":45417,\"start\":45413},{\"end\":45433,\"start\":45428},{\"end\":45441,\"start\":45438},{\"end\":45456,\"start\":45448},{\"end\":45467,\"start\":45464},{\"end\":45481,\"start\":45475},{\"end\":45495,\"start\":45490},{\"end\":45509,\"start\":45505},{\"end\":46035,\"start\":46030},{\"end\":46050,\"start\":46045},{\"end\":46061,\"start\":46057},{\"end\":46073,\"start\":46070},{\"end\":46456,\"start\":46449},{\"end\":46741,\"start\":46732},{\"end\":46756,\"start\":46751},{\"end\":46773,\"start\":46768},{\"end\":46775,\"start\":46774},{\"end\":46790,\"start\":46785},{\"end\":47122,\"start\":47117},{\"end\":47143,\"start\":47131},{\"end\":47161,\"start\":47152},{\"end\":47180,\"start\":47171},{\"end\":47705,\"start\":47701},{\"end\":47720,\"start\":47714},{\"end\":47737,\"start\":47733},{\"end\":48149,\"start\":48142},{\"end\":48315,\"start\":48313},{\"end\":48326,\"start\":48321},{\"end\":48341,\"start\":48334},{\"end\":48350,\"start\":48349},{\"end\":48366,\"start\":48359},{\"end\":48382,\"start\":48374},{\"end\":49003,\"start\":48997},{\"end\":49015,\"start\":49008},{\"end\":49029,\"start\":49022},{\"end\":49041,\"start\":49036},{\"end\":49052,\"start\":49046},{\"end\":49063,\"start\":49057},{\"end\":49072,\"start\":49068},{\"end\":49085,\"start\":49078},{\"end\":49095,\"start\":49092},{\"end\":49105,\"start\":49101},{\"end\":49751,\"start\":49748},{\"end\":49764,\"start\":49759},{\"end\":49775,\"start\":49769},{\"end\":49794,\"start\":49787},{\"end\":50212,\"start\":50209},{\"end\":50224,\"start\":50219},{\"end\":50242,\"start\":50233},{\"end\":50255,\"start\":50247}]", "bib_author_last_name": "[{\"end\":42221,\"start\":42212},{\"end\":42488,\"start\":42481},{\"end\":42502,\"start\":42494},{\"end\":42664,\"start\":42657},{\"end\":42933,\"start\":42930},{\"end\":42940,\"start\":42938},{\"end\":42954,\"start\":42949},{\"end\":43162,\"start\":43159},{\"end\":43178,\"start\":43173},{\"end\":43193,\"start\":43189},{\"end\":43472,\"start\":43469},{\"end\":43486,\"start\":43481},{\"end\":43812,\"start\":43806},{\"end\":43828,\"start\":43820},{\"end\":43839,\"start\":43834},{\"end\":44369,\"start\":44365},{\"end\":44385,\"start\":44379},{\"end\":44609,\"start\":44606},{\"end\":44623,\"start\":44619},{\"end\":44634,\"start\":44632},{\"end\":44648,\"start\":44645},{\"end\":44657,\"start\":44654},{\"end\":44667,\"start\":44664},{\"end\":44681,\"start\":44677},{\"end\":44691,\"start\":44687},{\"end\":45121,\"start\":45119},{\"end\":45137,\"start\":45129},{\"end\":45426,\"start\":45418},{\"end\":45436,\"start\":45434},{\"end\":45446,\"start\":45442},{\"end\":45462,\"start\":45457},{\"end\":45473,\"start\":45468},{\"end\":45488,\"start\":45482},{\"end\":45503,\"start\":45496},{\"end\":45518,\"start\":45510},{\"end\":46043,\"start\":46036},{\"end\":46055,\"start\":46051},{\"end\":46068,\"start\":46062},{\"end\":46079,\"start\":46074},{\"end\":46463,\"start\":46457},{\"end\":46749,\"start\":46742},{\"end\":46766,\"start\":46757},{\"end\":46783,\"start\":46776},{\"end\":46798,\"start\":46791},{\"end\":47129,\"start\":47123},{\"end\":47150,\"start\":47144},{\"end\":47169,\"start\":47162},{\"end\":47189,\"start\":47181},{\"end\":47712,\"start\":47706},{\"end\":47731,\"start\":47721},{\"end\":47747,\"start\":47738},{\"end\":48158,\"start\":48150},{\"end\":48319,\"start\":48316},{\"end\":48332,\"start\":48327},{\"end\":48347,\"start\":48342},{\"end\":48357,\"start\":48351},{\"end\":48372,\"start\":48367},{\"end\":48390,\"start\":48383},{\"end\":48406,\"start\":48392},{\"end\":49006,\"start\":49004},{\"end\":49020,\"start\":49016},{\"end\":49034,\"start\":49030},{\"end\":49044,\"start\":49042},{\"end\":49055,\"start\":49053},{\"end\":49066,\"start\":49064},{\"end\":49076,\"start\":49073},{\"end\":49090,\"start\":49086},{\"end\":49099,\"start\":49096},{\"end\":49110,\"start\":49106},{\"end\":49757,\"start\":49752},{\"end\":49767,\"start\":49765},{\"end\":49785,\"start\":49776},{\"end\":49802,\"start\":49795},{\"end\":50217,\"start\":50213},{\"end\":50231,\"start\":50225},{\"end\":50245,\"start\":50243},{\"end\":50260,\"start\":50256}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":61928572},\"end\":42432,\"start\":42170},{\"attributes\":{\"id\":\"b1\"},\"end\":42650,\"start\":42434},{\"attributes\":{\"doi\":\"arXiv:1606.05908\",\"id\":\"b2\"},\"end\":42831,\"start\":42652},{\"attributes\":{\"id\":\"b3\"},\"end\":43096,\"start\":42833},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":2938669},\"end\":43410,\"start\":43098},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":15611611},\"end\":43720,\"start\":43412},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":207227428},\"end\":44310,\"start\":43722},{\"attributes\":{\"id\":\"b7\"},\"end\":44509,\"start\":44312},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":2707750},\"end\":45060,\"start\":44511},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":14850912},\"end\":45340,\"start\":45062},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":1958648},\"end\":45980,\"start\":45342},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":36601456},\"end\":46383,\"start\":45982},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":120153383},\"end\":46604,\"start\":46385},{\"attributes\":{\"id\":\"b13\"},\"end\":47059,\"start\":46606},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":22057},\"end\":47635,\"start\":47061},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":2107118},\"end\":48083,\"start\":47637},{\"attributes\":{\"id\":\"b16\"},\"end\":48261,\"start\":48085},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":5102297},\"end\":48896,\"start\":48263},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":3636669},\"end\":49725,\"start\":48898},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":1986059},\"end\":50156,\"start\":49727},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":14102203},\"end\":50609,\"start\":50158}]", "bib_title": "[{\"end\":42204,\"start\":42170},{\"end\":43150,\"start\":43098},{\"end\":43460,\"start\":43412},{\"end\":43796,\"start\":43722},{\"end\":44597,\"start\":44511},{\"end\":45113,\"start\":45062},{\"end\":45411,\"start\":45342},{\"end\":46028,\"start\":45982},{\"end\":46447,\"start\":46385},{\"end\":47115,\"start\":47061},{\"end\":47699,\"start\":47637},{\"end\":48311,\"start\":48263},{\"end\":48995,\"start\":48898},{\"end\":49746,\"start\":49727},{\"end\":50207,\"start\":50158}]", "bib_author": "[{\"end\":42223,\"start\":42206},{\"end\":42490,\"start\":42473},{\"end\":42504,\"start\":42490},{\"end\":42666,\"start\":42652},{\"end\":42935,\"start\":42922},{\"end\":42942,\"start\":42935},{\"end\":42956,\"start\":42942},{\"end\":43164,\"start\":43152},{\"end\":43180,\"start\":43164},{\"end\":43195,\"start\":43180},{\"end\":43474,\"start\":43462},{\"end\":43488,\"start\":43474},{\"end\":43814,\"start\":43798},{\"end\":43830,\"start\":43814},{\"end\":43841,\"start\":43830},{\"end\":44371,\"start\":44360},{\"end\":44387,\"start\":44371},{\"end\":44611,\"start\":44599},{\"end\":44625,\"start\":44611},{\"end\":44636,\"start\":44625},{\"end\":44650,\"start\":44636},{\"end\":44659,\"start\":44650},{\"end\":44669,\"start\":44659},{\"end\":44683,\"start\":44669},{\"end\":44693,\"start\":44683},{\"end\":45123,\"start\":45115},{\"end\":45139,\"start\":45123},{\"end\":45428,\"start\":45413},{\"end\":45438,\"start\":45428},{\"end\":45448,\"start\":45438},{\"end\":45464,\"start\":45448},{\"end\":45475,\"start\":45464},{\"end\":45490,\"start\":45475},{\"end\":45505,\"start\":45490},{\"end\":45520,\"start\":45505},{\"end\":46045,\"start\":46030},{\"end\":46057,\"start\":46045},{\"end\":46070,\"start\":46057},{\"end\":46081,\"start\":46070},{\"end\":46465,\"start\":46449},{\"end\":46751,\"start\":46732},{\"end\":46768,\"start\":46751},{\"end\":46785,\"start\":46768},{\"end\":46800,\"start\":46785},{\"end\":47131,\"start\":47117},{\"end\":47152,\"start\":47131},{\"end\":47171,\"start\":47152},{\"end\":47191,\"start\":47171},{\"end\":47714,\"start\":47701},{\"end\":47733,\"start\":47714},{\"end\":47749,\"start\":47733},{\"end\":48160,\"start\":48142},{\"end\":48321,\"start\":48313},{\"end\":48334,\"start\":48321},{\"end\":48349,\"start\":48334},{\"end\":48359,\"start\":48349},{\"end\":48374,\"start\":48359},{\"end\":48392,\"start\":48374},{\"end\":48408,\"start\":48392},{\"end\":49008,\"start\":48997},{\"end\":49022,\"start\":49008},{\"end\":49036,\"start\":49022},{\"end\":49046,\"start\":49036},{\"end\":49057,\"start\":49046},{\"end\":49068,\"start\":49057},{\"end\":49078,\"start\":49068},{\"end\":49092,\"start\":49078},{\"end\":49101,\"start\":49092},{\"end\":49112,\"start\":49101},{\"end\":49759,\"start\":49748},{\"end\":49769,\"start\":49759},{\"end\":49787,\"start\":49769},{\"end\":49804,\"start\":49787},{\"end\":50219,\"start\":50209},{\"end\":50233,\"start\":50219},{\"end\":50247,\"start\":50233},{\"end\":50262,\"start\":50247}]", "bib_venue": "[{\"end\":42283,\"start\":42223},{\"end\":42471,\"start\":42434},{\"end\":42718,\"start\":42682},{\"end\":42920,\"start\":42833},{\"end\":43212,\"start\":43195},{\"end\":43542,\"start\":43488},{\"end\":43939,\"start\":43841},{\"end\":44358,\"start\":44312},{\"end\":44748,\"start\":44693},{\"end\":45187,\"start\":45139},{\"end\":45609,\"start\":45520},{\"end\":46160,\"start\":46081},{\"end\":46478,\"start\":46465},{\"end\":46730,\"start\":46606},{\"end\":47289,\"start\":47191},{\"end\":47835,\"start\":47749},{\"end\":48140,\"start\":48085},{\"end\":48518,\"start\":48408},{\"end\":49240,\"start\":49112},{\"end\":49893,\"start\":49804},{\"end\":50339,\"start\":50262},{\"end\":44041,\"start\":43941},{\"end\":44790,\"start\":44750},{\"end\":45685,\"start\":45611},{\"end\":47374,\"start\":47291},{\"end\":47853,\"start\":47837},{\"end\":48615,\"start\":48520},{\"end\":49355,\"start\":49242},{\"end\":49969,\"start\":49895},{\"end\":50403,\"start\":50341}]"}}}, "year": 2023, "month": 12, "day": 17}