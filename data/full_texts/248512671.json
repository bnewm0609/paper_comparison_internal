{"id": 248512671, "updated": "2023-10-05 14:30:04.011", "metadata": {"title": "Neuroevolutionary Multi-objective approaches to Trajectory Prediction in Autonomous Vehicles", "authors": "[{\"first\":\"Fergal\",\"last\":\"Stapleton\",\"middle\":[]},{\"first\":\"Edgar\",\"last\":\"Galv'an\",\"middle\":[]},{\"first\":\"Ganesh\",\"last\":\"Sistu\",\"middle\":[]},{\"first\":\"Senthil\",\"last\":\"Yogamani\",\"middle\":[]}]", "venue": "ArXiv", "journal": null, "publication_date": {"year": 2022, "month": null, "day": null}, "abstract": "The incentive for using Evolutionary Algorithms (EAs) for the automated optimization and training of deep neural networks (DNNs), a process referred to as neuroevolution, has gained momentum in recent years. The configuration and training of these networks can be posed as optimization problems. Indeed, most of the recent works on neuroevolution have focused their attention on single-objective optimization. Moreover, from the little research that has been done at the intersection of neuroevolution and evolutionary multi-objective optimization (EMO), all the research that has been carried out has focused predominantly on the use of one type of DNN: convolutional neural networks (CNNs), using well-established standard benchmark problems such as MNIST. In this work, we make a leap in the understanding of these two areas (neuroevolution and EMO), regarded in this work as neuroevolutionary multi-objective, by using and studying a rich DNN composed of a CNN and Long-short Term Memory network. Moreover, we use a robust and challenging vehicle trajectory prediction problem. By using the well-known Non-dominated Sorting Genetic Algorithm-II, we study the effects of five different objectives, tested in categories of three, allowing us to show how these objectives have either a positive or detrimental effect in neuroevolution for trajectory prediction in autonomous vehicles.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2205.02105", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/gecco/StapletonGSY22", "doi": "10.1145/3520304.3528984"}}, "content": {"source": {"pdf_hash": "c77953bc3963b461c395683c157c3be075de1ad5", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2205.02105v3.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "c21c092ea7ec2c41344b37d215cd21bdeb468dbf", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/c77953bc3963b461c395683c157c3be075de1ad5.txt", "contents": "\nNeuroevolutionary Multi-objective approaches to Trajectory Prediction in Autonomous Vehicles\n6 May 2022\n\nFergal Stapleton fergal.stapleton.2020@mumail.ie \nEdgar Galv\u00e1n edgar.galvan@mu.ie \nGanesh Sistu ganesh.sistu@valeo.com \nSenthil Yogamani senthil.yogamani@valeo.com \n\nDept. of CS\nDept. of CS, Hamilton Institute, IVI\nNaturally Inspired Computation Res. Group Ireland\nNaturally Inspired Computation Res. Group Ireland\nHamilton Institute\nMaynooth University\nMaynooth University\nValeo Vision Systems\nGalwayIreland\n\n\nValeo Vision Systems\nGalwayIreland\n\nNeuroevolutionary Multi-objective approaches to Trajectory Prediction in Autonomous Vehicles\n6 May 2022Autonomous VehiclesNeuroevolutionEMO\nThe incentive for using Evolutionary Algorithms (EAs) for the automated optimization and training of deep neural networks (DNNs), a process referred to as neuroevolution, has gained momentum in recent years. The configuration and training of these networks can be posed as optimization problems. Indeed, most of the recent works on neuroevolution have focused their attention on singleobjective optimization. Moreover, from the little research that has been done at the intersection of neuroevolution and evolutionary multi-objective optimization (EMO), all the research that has been carried out has focused predominantly on the use of one type of DNN: convolutional neural networks (CNNs), using well-established standard benchmark problems such as MNIST. In this work, we make a leap in the understanding of these two areas (neuroevolution and EMO), regarded in this work as neuroevolutionary multiobjective, by using and studying a rich DNN composed of a CNN and Long-short Term Memory network. Moreover, we use a robust and challenging vehicle trajectory prediction problem. By using the well-known Non-dominated Sorting Genetic Algorithm-II, we study the effects of five different objectives, tested in categories of three, allowing us to show how these objectives have either a positive or detrimental effect in neuroevolution for trajectory prediction in autonomous vehicles.CCS CONCEPTS\u2022 Computing methodologies \u2192 Bio-inspired approaches; Motion path planning.\n\nINTRODUCTION\n\nPredicting future trajectories in autonomous vehicles has the potential to produce safer driving environments for road users while alleviating the need for human interaction, which can be prone to error. As such, the automated trajectory of vehicles is a key area of research in autonomous driving and multiple works have emerged in recent years [1,14,20]. It remains a challenging problem in autonomous driving compared to other perception tasks where deep * Joint first/lead authors learning models have performed exceptionally well [2,11,15,16,19].\n\nDeep Neural Networks (DNNs) [12] can be effective machine learning techniques to generate perception models for planning, applied in different areas including in facial recognition [17] and studied from different perspectives [6]. The implementation of these models pose their own unique set of challenges, such as finding the correct set of hyperparameters' values for training the network, which is the focus of this work. This challenge is compounded when multiple objectives, in conflict or not, are considered. One can naturally tackle this using evolutionary multi-objective optimization (EMO) [3,4]. However, as articulated in a recent IEEE Trans. on AI article on neuroevolution in deep neural networks by Galv\u00e1n and Mooney, covering over 170 recent works on neuroevolution [7], little research has been done at the intersection of these two areas: neuroevolution and EMO, where all the research carried out by the research community has focused predominately on the use of one type of Deep Learning (DL) network.\n\nThe first contribution of this work is to use a rich DL network suitable for this task, as such, we use a network composed of a Convolutional Neural Network (CNN) [13] and Long-Short Term Memory (LSTM) network [10], using a larger hyperparameter search space than previously reported in multi-objective (MO) trajectory prediction [8,9]. The second contribution of this work is to shed light on the type of objectives that might be beneficial or detrimental in neuroevolution for trajectory prediction, as well as sharing insight into the conflicting nature of these objectives with respect to each other. The third contribution is to use a well-established EMO approach, the Non-dominated Sorting Genetic Algorithm II (NSGA-II) [5] to test and validate our approach, contrary to the works carried out in this area of autonomous vehicles that have limited their attention on the use of a more restrictive EMO approach [9]. These contributions will highlight the importance of certain objectives for the correct trajectory prediction in autonomous vehicles.\n\n\nMETHODOLOGY 2.1 Trajectory Prediction and Objective Optimization\n\nWe need input data to effectively carry out trajectory prediction. The input data consists of sequenced occupancy grids captured using the GridSim simulator [18]. We can define a sequence as consisting of number of images (or occupancy grids) as < \u2212 > at time . Using < \u2212 > , the aim is to predict future trajectory positions . The aim of this objective is to reduce the local travel path of the ego vehicle.\n< + > = { 0 , 0 , 1 , 1 , 2 , 2 , ..., , }(1)< + > 1 = 0 =1 || < + > \u2212 < + > || 2 2 (2)\nThe lateral velocity 2 is calculated from the angular velocity of the ego vehicle , as seen in Equations 3. The aim is to reduce sudden or rapid movements.\n< + > 2 = 0 =1 < + >(3)\nThe longitudinal velocity < + > 3 is calculated as the component of the velocity in the -direction, as defined in Equation 4. Lower and upper bounds have been set on the velocity of 80km for and 130km for . The aim of this objective is to help shorten the overall travel time for the passenger.\n< + > 3 = 0 =1 < + > \u2208 [ , ](4)\nThe root mean squared error ( ) was also tested as an objective and is given as the Euclidean distance between the predicted position\u02c6 of the ego vehicle for a given trajectory at a given time-step and the actual position of the ego vehicle at that time step as seen in Equation 5.\n= =1 (\u02c6 \u2212 ) 2(5)\nAnother consideration, when considering the highway data, is when a poor model incorrectly predicts that the trajectory should always veer to either in the left or right direction. Using the trajectory data, pre-scaled, it is possible to incorporate the sign as an indication of the direction (negative for left and positive for right). Furthermore, it is possible to penalize networks which calculate the ego vehicle to go straight all the time by taking the absolute value of the predicted away from the real trajectory. These two criteria are combined in Equation 6: \n= =1 ( \u02c6 \u2212 ) 2 ( (\u02c6 ) == ( ))(6)\n\nNetwork Topology\n\nBroadly speaking, the network is composed of two parts: (i) the Convolutional Neural Network (CNN) which takes the sequence of images as input and which is responsible for extracting important feature information from these images and (ii) the Long-Short Term Memory Network (LSTM) which predicts the trajectories based on the output of the CNN. LSTMs are particularly well suited for temporal prediction-based problems using sequenced input data. Since each position represents the location of the ego vehicle at future point in time, the aim is for our LSTM network to learn these future positions. A summary of the architecture topology is shown in Figure 1. A number of fixed hyperparameters are selected, primarily for the CNN section of the network, and these fixed parameters are derived from [8]. Just to note, for more complex temporal problems it is often more suitable to chain LSTM blocks, as such the LSTM Cells gene represents a variable number of chained LSTM cells up to size 4, denoted by LSTM Cell N in Figure 1. Table 1 lists the evolvable hyperparameters for each network.\n\n\nEXPERIMENTAL SETUP\n\nOver 30km of image data was captured from a highway scenario using the GridSim simulator [18]. Each network model is trained  Additionally, both the training and validation sets were shuffled prior to being split. When setting up our approach we used results from Grigorescu et. al. [9] as a baseline to ensure our approach was comparable to state-of-the-art results. The test data set was withheld for both training and optimization. All experiments were run on Nvidia Tesla V100 GPUs for 60 independent runs: 12 runs for each of the five experiments, requiring 25 GPU days. Notice that in the deep learning community, one run is the norm. A further summary of the parameters used for NSGA-II have been documented in Table 2. A summary of the objective combinations, as discussed in Table 3, combine an assortment of objectives including distance feedback, lateral velocity, longitudinal velocity, and (Equation 2 -Equation 6) for each experiment.\n\n\nSUMMARY OF RESULTS\n\nThe work undertook in this research set out to investigate, whether the inclusion of certain objectives could be beneficial or detrimental for the predictive capabilities of a neuroevolutionary approach  to trajectory prediction. To aid our analysis we test that the trajectories had a reasonable spread over the trajectory positions.\n\nIn other words, trajectories that consistently veer in one location, that fall short in terms of distance travelled or fail to ever change lane can be considered poor models. Table 4 denotes models that were deemed to have a 'good' spread in terms of the predicted trajectories.\n\nOur findings have demonstrated that the distance feedback function 1 , which aims to minimize localized travel path of the ego vehicle, is particularly detrimental when included as an objective. It was found that in the three experiments it was present (Experiments 3 -5, see Table 4), no experiment was capable of finding any more than 28 useful models out of 300. In the absence of a loss function as an objective, it fared even worse, only finding 5 out of 300 models. Furthermore, the RMSE and RMSE results were higher for these three experiments (Columns 4 -6, read left to right in Table 5) compared to the Experiments 1 and 2 which did not include feedback function 1 (columns 2 -3, Table 5), strengthening our analysis that the inclusion of the distance feedback function was detrimental.\n\nThis research highlights the need for the careful consideration of objectives to use in the context of neuroevolution in EMO, with a focus on trajectory prediction in autonomous vehicles. Our analysis showed that the distance feedback function 1 was not conflicting with the lateral velocity 2 and was highly conflicted with the longitudinal velocity 3 (see Table 6). A priori tests for correlation, as such, may be a useful tool for research practitioners, especially when the computational costs of running experiments are considered.\n\nA loss function , designed specifically to reduce the error in the -direction by incorporating the direction of the ego vehicle in terms of its sign, was also tested. Notably, as a nondifferentiable function it is unsuitable as a loss function for a gradient based neural network, as such it may be of interest to see what effect its inclusion in the EMO may have. With the inclusion of the weakly conflicting objectives it was found that the may help to reduce over-fitting on average (Experiment 2 versus Experiment 1). However, in the presence of highly conflicting objectives the performed worse than .  \n\n\nCONCLUSION\n\nUsing a robust and well-established EMO approach known as the Non-dominated Sorting Genetic Algorithm II (NSGA-II) we evolved the hyperparameters of deep learning networks, where each network was composed of a CNN network and LSTM network. Each network was tasked with predicting vehicle trajectories, a challenging problem domain of high relevance to the field of autonomous vehicles, EMO and DNNs. By analyzing the results of multiple combinations of network-specific and domain-specific objectives, we demonstrated how the inclusion of some objectives can be either detrimental or beneficial to the neuroevolutionary process. In particular the use of a distance feedback objective was particularly detrimental to the EMO optimizer finding meaningful or useful models. On the other hand, the lateral velocity objective was found to be beneficial in finding meaningful models. When no loss function was present as an objective (i.e when only domain-specific objective were considered), the EMO approach failed in the vast majority of cases to find any meaningful or useful models. A nondifferentiable objective was also explored, and it was found that in the presence of the weakly conflicting objectives that were tested (lateral and longitudinal velocity), it helped to alleviate overfitting on average, suggesting non-differentiable objectives may be worth exploring in future studies in EMO.\n\n\nwhere and represent the position of the ego vehicle. The distance feedback < + > 1 measures the distance between the current position of the ego vehicle and last position in the sequence and is expressed in Equation 2\n\nFigure 1 :\n1Diagram of network topology. On the top of the diagram, sequences of image of size are fed as input into the CNN. On the bottom is the outputted predicted trajectory.\n\nTable 1 :\n1Evolvable hyperparameters for deep neural network.Locus \nGene \nSet of possible alleles \n\n1 \nBatch Size \n{ 50, 75, 100, 125 } \n2 \nEpochs \n{ 10, 20, 30, 40, 50 } \n3 \nMomentum \n{ 0.8, 0.85, 0.9, 0.95 } \n4 \nLoss Function \n{ MSE, Log Cosh } \n5 \nOptimizer \n{ RMSprop, NAdam, SGD, \nAdaGrad, Adadelta, Adam, AdaMax } \n6 \nLSTM Cells \n{ 1, 2, 3, 4 } \n7 \nLSTM Dropout \n{ 0.2, 0.25, 0.3, 0.35, 0.4, 0.5 } \n8 \nHidden Units \n{ 100, 125, 150, 175, 200, 225, 250 } \n9 \nCNN Flattened 1 \n{ 256, 512, 768, 1024 } \n10 \nCNN Flattened 2 \n{ 256, 512, 768, 1024 } \n11 \nLSTM Flattened 1 \n{ 64, 128, 256, 512 } \n12 \nLSTM Flattened 2 \n{ 64, 128, 256, 512 } \n13 \nFlattened Dropout \n{ 0.05, 0.1, 0.15, 0.2, 0.25 } \n\n\n\nTable 2 :\n2Summary of parameters. ratio between training, validation and test, respectively. For the training set, there are 1500 sequences, and for both the validation and test, 500 sequences each. To increase the sample size, a sliding window approach was used to increase the number of sequences.Parameter \nValue \n\nPopulation Size \n25 \nGenerations \n20 \nType of Cross. and Mut. \nSingle point \nCrossover Rate \n1.00 \nMutation Rate \n0.50 \nSelection \nTournament (size = 3) \nTotal Independent Runs \n60 \n\non a sequence of images, consisting of images of 128 x 128 pixels \nwith three channels for RGB color. The data is split with 0.6 : 0.2: \n0.2 \n\nTable 3 :\n3Objective combinations for each experiment. We have separated the combinations into three categories. \n\nCode \nObjectives Category \n\nExperiment 1 \n, 2 , 3 \n1 \nExperiment 2 \n, 2 , 3 \n1 \nExperiment 3 \n, 1 , 3 \n2 \nExperiment 4 \n, 1 , 3 \n2 \nExperiment 5 \n1 , 2 , 3 \n3 \n\n\n\nTable 4 :\n4Analysis of trajectory spread denoting 'good' models in the final generation of each run.Experiment 1 Experiment 2 Experiment 3 Experiment 4 Experiment 5 \n\n168/300 \n132/300 \n26/300 \n28/300 \n5/300 \n\n\n\nTable 5 :\n5Metric mean and standard deviation (std) for all runs of a given experiment. Experiments 1 and 2 contain weakly conflicting domain-specific objectives, whereas Experiment 3, 4 and 5 contain strongly conflicting domain-specific objectives.Experiment 1 \nExperiment 2 \nExperiment 3 \nExperiment 4 \nExperiment 5 \nmetric \nmean \n\u00b1 std \nmean \n\u00b1 std \nmean \n\u00b1 std \nmean \n\u00b1 std \nmean \n\u00b1 std \n\nRMSE \n0.657413 0.032726 0.727919 0.057119 2.077965 0.351699 2.307763 0.234958 2.403594 0.201088 \nRMSE \n1.063261 0.007949 1.049083 0.010070 1.605857 0.204658 1.734267 0.152781 1.746888 0.131945 \n\n\n\nTable 6 :\n6Spearman rank-order correlation for distance feedback 1 , lateral velocity 2 , and longitudinal velocity 3 .Objectives Coefficient \nP -value \n\n1 & 2 \n0.1526 2.8454e-09 \n\n1 & 3 \n-0.8715 \n0.0 \n\n2 & 3 \n-0.1430 2.6771e-08 \n\n\nACKNOWLEDGMENTSThis publication has emanated from research conducted with the financial support of Science Foundation Ireland under Grant number 18/CRT/6049. The authors wish to acknowledge the Irish Centre for High-End Computing (ICHEC) for the provision of computational facilities and support.\nThibault Buhet, Emilie Wirbel, Andrei Bursuc, Xavier Perrotton, PLOP: Probabilistic poLynomial Objects trajectory Planning for autonomous driving. 4th Conference on Robot Learning. Cambridge, MA, USA2020CoRLThibault Buhet, Emilie Wirbel, Andrei Bursuc, and Xavier Perrotton. 2020. PLOP: Probabilistic poLynomial Objects trajectory Planning for autonomous driving. 4th Conference on Robot Learning, CoRL 2020, 16-18 November 2020, Virtual Event / Cambridge, MA, USA 155 (2020), 329-338.\n\nAuxNet: Auxiliary Tasks Enhanced Semantic Segmentation for Automated Driving. S Chennupati, Ganesh Sistu, Samir Senthil Yogamani, Rawashdeh, Proceedings of the International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications (VISAPP). the International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications (VISAPP)S. Chennupati, Ganesh Sistu., Senthil Yogamani., and Samir Rawashdeh. 2019. AuxNet: Auxiliary Tasks Enhanced Semantic Segmentation for Automated Driv- ing. In Proceedings of the International Joint Conference on Computer Vision, Imag- ing and Computer Graphics Theory and Applications (VISAPP). 645-652.\n\nA Comprehensive Survey of Evolutionary-Based Multiobjective Optimization Techniques. A Carlos, Coello Coello, 10.1007/BF03325101Knowledge and Information Systems. 1Carlos A. Coello Coello. 1999. A Comprehensive Survey of Evolutionary-Based Multiobjective Optimization Techniques. Knowledge and Information Systems 1, 3 (1999), 269-308. https://doi.org/10.1007/BF03325101\n\nEvolutionary multi-objective optimization: a historical view of the field. A Carlos, Coello Coello, 10.1109/MCI.2006.1597059IEEE Computational Intelligence Magazine. 11Carlos A. Coello Coello. 2006. Evolutionary multi-objective optimization: a his- torical view of the field. IEEE Computational Intelligence Magazine 1, 1 (Feb 2006), 28-36. https://doi.org/10.1109/MCI.2006.1597059\n\nA fast and elitist multiobjective genetic algorithm: NSGA-II. Kalyanmoy Deb, Amrit Pratap, Sameer Agarwal, Tamt Meyarivan, 10.1109/4235.996017IEEE Transactions on Evolutionary Computation. 6Kalyanmoy Deb, Amrit Pratap, Sameer Agarwal, and TAMT Meyari- van. 2002. A fast and elitist multiobjective genetic algorithm: NSGA- II. IEEE Transactions on Evolutionary Computation 6, 2 (2002), 182-197. https://doi.org/10.1109/4235.996017\n\nNeuroevolution in Deep Learning: The Role of Neutrality. Edgar Galv\u00e1n, arXiv:2102.08475Edgar Galv\u00e1n. 2021. Neuroevolution in Deep Learning: The Role of Neutrality. CoRR abs/2102.08475 (2021). arXiv:2102.08475 https://arxiv.org/abs/2102.08475\n\nNeuroevolution in Deep Neural Networks: Current Trends and Future Challenges. Edgar Galvan, Peter Mooney, 10.1109/TAI.2021.3067574IEEE Transactions on Artificial Intelligence. Edgar Galvan and Peter Mooney. 2021. Neuroevolution in Deep Neural Net- works: Current Trends and Future Challenges. IEEE Transactions on Artificial Intelligence (2021), 1-1. https://doi.org/10.1109/TAI.2021.3067574\n\n. Sorin Grigorescu, Bogdan Trasnea, Liviu Marina, Andrei Vasilcoi, Tiberiu Cocias, Sorin Grigorescu, Bogdan Trasnea, Liviu Marina, Andrei Vasilcoi, and Tiberiu Cocias. 2019. NeuroTrajectory. https://github.com/RovisLab/NeuroTrajectory.\n\nNeuroTrajectory: A Neuroevolutionary Approach to Local State Trajectory Learning for Autonomous Vehicles. Sorin Grigorescu, Bogdan Trasnea, Liviu Marina, Andrei Vasilcoi, Tiberiu Cocias, 10.1109/LRA.2019.2926224IEEE Robotics and Automation Letters PP. Sorin Grigorescu, Bogdan Trasnea, Liviu Marina, Andrei Vasilcoi, and Tiberiu Cocias. 2019. NeuroTrajectory: A Neuroevolutionary Approach to Local State Trajectory Learning for Autonomous Vehicles. IEEE Robotics and Automation Letters PP (07 2019), 1-1. https://doi.org/10.1109/LRA.2019.2926224\n\nLong Short-Term Memory. Sepp Hochreiter, J\u00fcrgen Schmidhuber, Neural Comput. 9Sepp Hochreiter and J\u00fcrgen Schmidhuber. 1997. Long Short- Term Memory. Neural Comput. 9, 8 (nov 1997), 1735-1780.\n\n. 10.1162/neco.1997.9.8.1735https://doi.org/10.1162/neco.1997.9.8.1735\n\nSVDistNet: Self-Supervised Near-Field Distance Estimation on Surround View Fisheye Cameras. Ravi Varun, Marvin Kumar, Senthil Klingner, Markus Yogamani, Stefan Bach, Tim Milz, Patrick Fingscheidt, M\u00e4der, IEEE Transactions on Intelligent Transportation Systems. Varun Ravi Kumar, Marvin Klingner, Senthil Yogamani, Markus Bach, Stefan Milz, Tim Fingscheidt, and Patrick M\u00e4der. 2021. SVDistNet: Self-Supervised Near-Field Distance Estimation on Surround View Fisheye Cameras. IEEE Trans- actions on Intelligent Transportation Systems (2021).\n\nDeep Learning. Y Yann Lecun, Geoffrey Bengio, Hinton, 10.1038/nature14539Nature. 521Yann LeCun, Y. Bengio, and Geoffrey Hinton. 2015. Deep Learning. Nature 521 (05 2015), 436-44. https://doi.org/10.1038/nature14539\n\nGradientbased learning applied to document recognition. Yann Lecun, L\u00e9on Bottou, Yoshua Bengio, Patrick Haffner, Proc. IEEE. 86Yann LeCun, L\u00e9on Bottou, Yoshua Bengio, and Patrick Haffner. 1998. Gradient- based learning applied to document recognition. Proc. IEEE 86, 11 (1998), 2278- 2324.\n\nInteraction-Aware Trajectory Prediction of Connected Vehicles using CNN-LSTM Networks. Xiaoyu Mo, Yang Xing, Chen Lv, IECON. 202046Xiaoyu Mo, Yang Xing, and Chen Lv. 2020. Interaction-Aware Trajectory Predic- tion of Connected Vehicles using CNN-LSTM Networks. IECON 2020 The 46th\n\n. Annual Conference of the IEEE Industrial Electronics Society. Annual Conference of the IEEE Industrial Electronics Society (2020), 5057-5062.\n\nSyndistnet: Self-supervised monocular fisheye camera distance estimation synergized with semantic segmentation for autonomous driving. Ravi Varun, Marvin Kumar, Senthil Klingner, Stefan Yogamani, Milz, Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision. the IEEE/CVF Winter Conference on Applications of Computer VisionTim Fingscheidt, and Patrick MaderVarun Ravi Kumar, Marvin Klingner, Senthil Yogamani, Stefan Milz, Tim Fin- gscheidt, and Patrick Mader. 2021. Syndistnet: Self-supervised monocular fish- eye camera distance estimation synergized with semantic segmentation for au- tonomous driving. In Proceedings of the IEEE/CVF Winter Conference on Applica- tions of Computer Vision. 61-71.\n\nOmnidet: Surround view cameras based multi-task visual perception network for autonomous driving. Senthil Varun Ravi Kumar, Hazem Yogamani, Ganesh Rashed, Christian Sitsu, Isabelle Witt, Stefan Leang, Patrick Milz, M\u00e4der, IEEE Robotics and Automation Letters. 6Varun Ravi Kumar, Senthil Yogamani, Hazem Rashed, Ganesh Sitsu, Christian Witt, Isabelle Leang, Stefan Milz, and Patrick M\u00e4der. 2021. Omnidet: Surround view cameras based multi-task visual perception network for autonomous driv- ing. IEEE Robotics and Automation Letters 6, 2 (2021), 2830-2837.\n\nNeural Architecture Search Using Genetic Algorithm for Facial Expression Recognition. Yanan Sun, Shuchao Deng, Edgar Galv\u00e1n, Proceedings of the Genetic and Evolutionary Computation Conference, GECCO 2022. the Genetic and Evolutionary Computation Conference, GECCO 2022Boston, USAACMYanan Sun Shuchao Deng and Edgar Galv\u00e1n. 2022. Neural Architecture Search Using Genetic Algorithm for Facial Expression Recognition. In Proceedings of the Genetic and Evolutionary Computation Conference, GECCO 2022, Boston, USA, July 9-13, 2022. ACM.\n\nBogdan Trasnea, Andrei Vasilcoi, Claudiu Pozna, Sorin Grigorescu, arXiv:1901.05195GridSim: A Vehicle Kinematics Engine for Deep Neuroevolutionary Control in Autonomous Driving. cs.ROBogdan Trasnea, Andrei Vasilcoi, Claudiu Pozna, and Sorin Grigorescu. 2019. GridSim: A Vehicle Kinematics Engine for Deep Neuroevolutionary Control in Autonomous Driving. arXiv:1901.05195 [cs.RO]\n\nUnRectDepthNet: Self-Supervised Monocular Depth Estimation using a Generic Framework for Handling Common Camera Distortion Models. Ravi Kumar Varun, Senthil Yogamani, Markus Bach, Christian Witt, Stefan Milz, Patrick M\u00e4der, 10.1109/iros45743.2020.9340732IEEE/RSJ International Conference on Intelligent Robots and Systems. Ravi Kumar Varun, Senthil Yogamani, Markus Bach, Christian Witt, Stefan Milz, and Patrick M\u00e4der. 2020. UnRectDepthNet: Self-Supervised Monocular Depth Estimation using a Generic Framework for Handling Common Camera Distor- tion Models. In IEEE/RSJ International Conference on Intelligent Robots and Sys- tems, IROS. https://doi.org/10.1109/iros45743.2020.9340732\n\nCongestion-aware Multi-agent Trajectory Prediction for Collision Avoidance. Xu Xie, Chi Zhang, Yixin Zhu, Ying Nian Wu, Song-Chun Zhu, 2021 IEEE International Conference on Robotics and Automation (ICRA). Xu Xie, Chi Zhang, Yixin Zhu, Ying Nian Wu, and Song-Chun Zhu. 2021. Congestion-aware Multi-agent Trajectory Prediction for Collision Avoidance. 2021 IEEE International Conference on Robotics and Automation (ICRA) (2021), 13693-13700.\n", "annotations": {"author": "[{\"end\":155,\"start\":106},{\"end\":188,\"start\":156},{\"end\":225,\"start\":189},{\"end\":270,\"start\":226},{\"end\":515,\"start\":271},{\"end\":552,\"start\":516}]", "publisher": null, "author_last_name": "[{\"end\":122,\"start\":113},{\"end\":168,\"start\":162},{\"end\":201,\"start\":196},{\"end\":242,\"start\":234}]", "author_first_name": "[{\"end\":112,\"start\":106},{\"end\":161,\"start\":156},{\"end\":195,\"start\":189},{\"end\":233,\"start\":226}]", "author_affiliation": "[{\"end\":514,\"start\":272},{\"end\":551,\"start\":517}]", "title": "[{\"end\":93,\"start\":1},{\"end\":645,\"start\":553}]", "venue": null, "abstract": "[{\"end\":2162,\"start\":693}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2527,\"start\":2524},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":2530,\"start\":2527},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":2533,\"start\":2530},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2716,\"start\":2713},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":2719,\"start\":2716},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":2722,\"start\":2719},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":2725,\"start\":2722},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":2728,\"start\":2725},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":2763,\"start\":2759},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":2916,\"start\":2912},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":2960,\"start\":2957},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3334,\"start\":3331},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3336,\"start\":3334},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":3516,\"start\":3513},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":3921,\"start\":3917},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3968,\"start\":3964},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":4087,\"start\":4084},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":4089,\"start\":4087},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":4485,\"start\":4482},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":4674,\"start\":4671},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":5039,\"start\":5035},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":5679,\"start\":5678},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":7607,\"start\":7604},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":8012,\"start\":8008},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":8205,\"start\":8202}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":13081,\"start\":12862},{\"attributes\":{\"id\":\"fig_1\"},\"end\":13261,\"start\":13082},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":13961,\"start\":13262},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":14605,\"start\":13962},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":14883,\"start\":14606},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":15094,\"start\":14884},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":15684,\"start\":15095},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":15917,\"start\":15685}]", "paragraph": "[{\"end\":2729,\"start\":2178},{\"end\":3752,\"start\":2731},{\"end\":4809,\"start\":3754},{\"end\":5286,\"start\":4878},{\"end\":5530,\"start\":5375},{\"end\":5849,\"start\":5555},{\"end\":6163,\"start\":5882},{\"end\":6751,\"start\":6181},{\"end\":7896,\"start\":6804},{\"end\":8867,\"start\":7919},{\"end\":9224,\"start\":8890},{\"end\":9504,\"start\":9226},{\"end\":10302,\"start\":9506},{\"end\":10840,\"start\":10304},{\"end\":11450,\"start\":10842},{\"end\":12861,\"start\":11465}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":5332,\"start\":5287},{\"attributes\":{\"id\":\"formula_1\"},\"end\":5374,\"start\":5332},{\"attributes\":{\"id\":\"formula_2\"},\"end\":5554,\"start\":5531},{\"attributes\":{\"id\":\"formula_3\"},\"end\":5881,\"start\":5850},{\"attributes\":{\"id\":\"formula_4\"},\"end\":6180,\"start\":6164},{\"attributes\":{\"id\":\"formula_5\"},\"end\":6784,\"start\":6752}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":7842,\"start\":7835},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":8644,\"start\":8637},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":8710,\"start\":8703},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":9408,\"start\":9401},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":9789,\"start\":9782},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":10101,\"start\":10094},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":10203,\"start\":10196},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":10669,\"start\":10662}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2176,\"start\":2164},{\"attributes\":{\"n\":\"2\"},\"end\":4876,\"start\":4812},{\"attributes\":{\"n\":\"2.2\"},\"end\":6802,\"start\":6786},{\"attributes\":{\"n\":\"3\"},\"end\":7917,\"start\":7899},{\"attributes\":{\"n\":\"4\"},\"end\":8888,\"start\":8870},{\"attributes\":{\"n\":\"5\"},\"end\":11463,\"start\":11453},{\"end\":13093,\"start\":13083},{\"end\":13272,\"start\":13263},{\"end\":13972,\"start\":13963},{\"end\":14616,\"start\":14607},{\"end\":14894,\"start\":14885},{\"end\":15105,\"start\":15096},{\"end\":15695,\"start\":15686}]", "table": "[{\"end\":13961,\"start\":13324},{\"end\":14605,\"start\":14262},{\"end\":14883,\"start\":14718},{\"end\":15094,\"start\":14985},{\"end\":15684,\"start\":15345},{\"end\":15917,\"start\":15805}]", "figure_caption": "[{\"end\":13081,\"start\":12864},{\"end\":13261,\"start\":13095},{\"end\":13324,\"start\":13274},{\"end\":14262,\"start\":13974},{\"end\":14718,\"start\":14618},{\"end\":14985,\"start\":14896},{\"end\":15345,\"start\":15107},{\"end\":15805,\"start\":15697}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":7464,\"start\":7456},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":7833,\"start\":7825}]", "bib_author_first_name": "[{\"end\":16223,\"start\":16215},{\"end\":16237,\"start\":16231},{\"end\":16252,\"start\":16246},{\"end\":16267,\"start\":16261},{\"end\":16781,\"start\":16780},{\"end\":16800,\"start\":16794},{\"end\":16813,\"start\":16808},{\"end\":17485,\"start\":17484},{\"end\":17847,\"start\":17846},{\"end\":18225,\"start\":18216},{\"end\":18236,\"start\":18231},{\"end\":18251,\"start\":18245},{\"end\":18265,\"start\":18261},{\"end\":18647,\"start\":18642},{\"end\":18911,\"start\":18906},{\"end\":18925,\"start\":18920},{\"end\":19228,\"start\":19223},{\"end\":19247,\"start\":19241},{\"end\":19262,\"start\":19257},{\"end\":19277,\"start\":19271},{\"end\":19295,\"start\":19288},{\"end\":19569,\"start\":19564},{\"end\":19588,\"start\":19582},{\"end\":19603,\"start\":19598},{\"end\":19618,\"start\":19612},{\"end\":19636,\"start\":19629},{\"end\":20033,\"start\":20029},{\"end\":20052,\"start\":20046},{\"end\":20365,\"start\":20361},{\"end\":20379,\"start\":20373},{\"end\":20394,\"start\":20387},{\"end\":20411,\"start\":20405},{\"end\":20428,\"start\":20422},{\"end\":20438,\"start\":20435},{\"end\":20452,\"start\":20445},{\"end\":20826,\"start\":20825},{\"end\":20847,\"start\":20839},{\"end\":21086,\"start\":21082},{\"end\":21098,\"start\":21094},{\"end\":21113,\"start\":21107},{\"end\":21129,\"start\":21122},{\"end\":21410,\"start\":21404},{\"end\":21419,\"start\":21415},{\"end\":21430,\"start\":21426},{\"end\":21883,\"start\":21879},{\"end\":21897,\"start\":21891},{\"end\":21912,\"start\":21905},{\"end\":21929,\"start\":21923},{\"end\":22576,\"start\":22569},{\"end\":22600,\"start\":22595},{\"end\":22617,\"start\":22611},{\"end\":22635,\"start\":22626},{\"end\":22651,\"start\":22643},{\"end\":22664,\"start\":22658},{\"end\":22679,\"start\":22672},{\"end\":23119,\"start\":23114},{\"end\":23132,\"start\":23125},{\"end\":23144,\"start\":23139},{\"end\":23568,\"start\":23562},{\"end\":23584,\"start\":23578},{\"end\":23602,\"start\":23595},{\"end\":23615,\"start\":23610},{\"end\":24076,\"start\":24072},{\"end\":24097,\"start\":24090},{\"end\":24114,\"start\":24108},{\"end\":24130,\"start\":24121},{\"end\":24143,\"start\":24137},{\"end\":24157,\"start\":24150},{\"end\":24706,\"start\":24704},{\"end\":24715,\"start\":24712},{\"end\":24728,\"start\":24723},{\"end\":24738,\"start\":24734},{\"end\":24743,\"start\":24739},{\"end\":24757,\"start\":24748}]", "bib_author_last_name": "[{\"end\":16229,\"start\":16224},{\"end\":16244,\"start\":16238},{\"end\":16259,\"start\":16253},{\"end\":16277,\"start\":16268},{\"end\":16792,\"start\":16782},{\"end\":16806,\"start\":16801},{\"end\":16830,\"start\":16814},{\"end\":16841,\"start\":16832},{\"end\":17492,\"start\":17486},{\"end\":17507,\"start\":17494},{\"end\":17854,\"start\":17848},{\"end\":17869,\"start\":17856},{\"end\":18229,\"start\":18226},{\"end\":18243,\"start\":18237},{\"end\":18259,\"start\":18252},{\"end\":18275,\"start\":18266},{\"end\":18654,\"start\":18648},{\"end\":18918,\"start\":18912},{\"end\":18932,\"start\":18926},{\"end\":19239,\"start\":19229},{\"end\":19255,\"start\":19248},{\"end\":19269,\"start\":19263},{\"end\":19286,\"start\":19278},{\"end\":19302,\"start\":19296},{\"end\":19580,\"start\":19570},{\"end\":19596,\"start\":19589},{\"end\":19610,\"start\":19604},{\"end\":19627,\"start\":19619},{\"end\":19643,\"start\":19637},{\"end\":20044,\"start\":20034},{\"end\":20064,\"start\":20053},{\"end\":20371,\"start\":20366},{\"end\":20385,\"start\":20380},{\"end\":20403,\"start\":20395},{\"end\":20420,\"start\":20412},{\"end\":20433,\"start\":20429},{\"end\":20443,\"start\":20439},{\"end\":20464,\"start\":20453},{\"end\":20471,\"start\":20466},{\"end\":20837,\"start\":20827},{\"end\":20854,\"start\":20848},{\"end\":20862,\"start\":20856},{\"end\":21092,\"start\":21087},{\"end\":21105,\"start\":21099},{\"end\":21120,\"start\":21114},{\"end\":21137,\"start\":21130},{\"end\":21413,\"start\":21411},{\"end\":21424,\"start\":21420},{\"end\":21433,\"start\":21431},{\"end\":21889,\"start\":21884},{\"end\":21903,\"start\":21898},{\"end\":21921,\"start\":21913},{\"end\":21938,\"start\":21930},{\"end\":21944,\"start\":21940},{\"end\":22593,\"start\":22577},{\"end\":22609,\"start\":22601},{\"end\":22624,\"start\":22618},{\"end\":22641,\"start\":22636},{\"end\":22656,\"start\":22652},{\"end\":22670,\"start\":22665},{\"end\":22684,\"start\":22680},{\"end\":22691,\"start\":22686},{\"end\":23123,\"start\":23120},{\"end\":23137,\"start\":23133},{\"end\":23151,\"start\":23145},{\"end\":23576,\"start\":23569},{\"end\":23593,\"start\":23585},{\"end\":23608,\"start\":23603},{\"end\":23626,\"start\":23616},{\"end\":24088,\"start\":24077},{\"end\":24106,\"start\":24098},{\"end\":24119,\"start\":24115},{\"end\":24135,\"start\":24131},{\"end\":24148,\"start\":24144},{\"end\":24163,\"start\":24158},{\"end\":24710,\"start\":24707},{\"end\":24721,\"start\":24716},{\"end\":24732,\"start\":24729},{\"end\":24746,\"start\":24744},{\"end\":24761,\"start\":24758}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\"},\"end\":16700,\"start\":16215},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":58014148},\"end\":17397,\"start\":16702},{\"attributes\":{\"doi\":\"10.1007/BF03325101\",\"id\":\"b2\",\"matched_paper_id\":195337963},\"end\":17769,\"start\":17399},{\"attributes\":{\"doi\":\"10.1109/MCI.2006.1597059\",\"id\":\"b3\",\"matched_paper_id\":15504020},\"end\":18152,\"start\":17771},{\"attributes\":{\"doi\":\"10.1109/4235.996017\",\"id\":\"b4\",\"matched_paper_id\":9914171},\"end\":18583,\"start\":18154},{\"attributes\":{\"doi\":\"arXiv:2102.08475\",\"id\":\"b5\"},\"end\":18826,\"start\":18585},{\"attributes\":{\"doi\":\"10.1109/TAI.2021.3067574\",\"id\":\"b6\",\"matched_paper_id\":219558595},\"end\":19219,\"start\":18828},{\"attributes\":{\"id\":\"b7\"},\"end\":19456,\"start\":19221},{\"attributes\":{\"doi\":\"10.1109/LRA.2019.2926224\",\"id\":\"b8\",\"matched_paper_id\":195658029},\"end\":20003,\"start\":19458},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":1915014},\"end\":20195,\"start\":20005},{\"attributes\":{\"doi\":\"10.1162/neco.1997.9.8.1735\",\"id\":\"b10\"},\"end\":20267,\"start\":20197},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":233204333},\"end\":20808,\"start\":20269},{\"attributes\":{\"doi\":\"10.1038/nature14539\",\"id\":\"b12\",\"matched_paper_id\":1779661},\"end\":21024,\"start\":20810},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":64294544},\"end\":21315,\"start\":21026},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":218870014},\"end\":21597,\"start\":21317},{\"attributes\":{\"id\":\"b15\"},\"end\":21742,\"start\":21599},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":221090701},\"end\":22469,\"start\":21744},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":231925197},\"end\":23026,\"start\":22471},{\"attributes\":{\"id\":\"b18\"},\"end\":23560,\"start\":23028},{\"attributes\":{\"doi\":\"arXiv:1901.05195\",\"id\":\"b19\"},\"end\":23939,\"start\":23562},{\"attributes\":{\"doi\":\"10.1109/iros45743.2020.9340732\",\"id\":\"b20\",\"matched_paper_id\":220514739},\"end\":24626,\"start\":23941},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":232379932},\"end\":25067,\"start\":24628}]", "bib_title": "[{\"end\":16778,\"start\":16702},{\"end\":17482,\"start\":17399},{\"end\":17844,\"start\":17771},{\"end\":18214,\"start\":18154},{\"end\":18904,\"start\":18828},{\"end\":19562,\"start\":19458},{\"end\":20027,\"start\":20005},{\"end\":20359,\"start\":20269},{\"end\":20823,\"start\":20810},{\"end\":21080,\"start\":21026},{\"end\":21402,\"start\":21317},{\"end\":21877,\"start\":21744},{\"end\":22567,\"start\":22471},{\"end\":23112,\"start\":23028},{\"end\":24070,\"start\":23941},{\"end\":24702,\"start\":24628}]", "bib_author": "[{\"end\":16231,\"start\":16215},{\"end\":16246,\"start\":16231},{\"end\":16261,\"start\":16246},{\"end\":16279,\"start\":16261},{\"end\":16794,\"start\":16780},{\"end\":16808,\"start\":16794},{\"end\":16832,\"start\":16808},{\"end\":16843,\"start\":16832},{\"end\":17494,\"start\":17484},{\"end\":17509,\"start\":17494},{\"end\":17856,\"start\":17846},{\"end\":17871,\"start\":17856},{\"end\":18231,\"start\":18216},{\"end\":18245,\"start\":18231},{\"end\":18261,\"start\":18245},{\"end\":18277,\"start\":18261},{\"end\":18656,\"start\":18642},{\"end\":18920,\"start\":18906},{\"end\":18934,\"start\":18920},{\"end\":19241,\"start\":19223},{\"end\":19257,\"start\":19241},{\"end\":19271,\"start\":19257},{\"end\":19288,\"start\":19271},{\"end\":19304,\"start\":19288},{\"end\":19582,\"start\":19564},{\"end\":19598,\"start\":19582},{\"end\":19612,\"start\":19598},{\"end\":19629,\"start\":19612},{\"end\":19645,\"start\":19629},{\"end\":20046,\"start\":20029},{\"end\":20066,\"start\":20046},{\"end\":20373,\"start\":20361},{\"end\":20387,\"start\":20373},{\"end\":20405,\"start\":20387},{\"end\":20422,\"start\":20405},{\"end\":20435,\"start\":20422},{\"end\":20445,\"start\":20435},{\"end\":20466,\"start\":20445},{\"end\":20473,\"start\":20466},{\"end\":20839,\"start\":20825},{\"end\":20856,\"start\":20839},{\"end\":20864,\"start\":20856},{\"end\":21094,\"start\":21082},{\"end\":21107,\"start\":21094},{\"end\":21122,\"start\":21107},{\"end\":21139,\"start\":21122},{\"end\":21415,\"start\":21404},{\"end\":21426,\"start\":21415},{\"end\":21435,\"start\":21426},{\"end\":21891,\"start\":21879},{\"end\":21905,\"start\":21891},{\"end\":21923,\"start\":21905},{\"end\":21940,\"start\":21923},{\"end\":21946,\"start\":21940},{\"end\":22595,\"start\":22569},{\"end\":22611,\"start\":22595},{\"end\":22626,\"start\":22611},{\"end\":22643,\"start\":22626},{\"end\":22658,\"start\":22643},{\"end\":22672,\"start\":22658},{\"end\":22686,\"start\":22672},{\"end\":22693,\"start\":22686},{\"end\":23125,\"start\":23114},{\"end\":23139,\"start\":23125},{\"end\":23153,\"start\":23139},{\"end\":23578,\"start\":23562},{\"end\":23595,\"start\":23578},{\"end\":23610,\"start\":23595},{\"end\":23628,\"start\":23610},{\"end\":24090,\"start\":24072},{\"end\":24108,\"start\":24090},{\"end\":24121,\"start\":24108},{\"end\":24137,\"start\":24121},{\"end\":24150,\"start\":24137},{\"end\":24165,\"start\":24150},{\"end\":24712,\"start\":24704},{\"end\":24723,\"start\":24712},{\"end\":24734,\"start\":24723},{\"end\":24748,\"start\":24734},{\"end\":24763,\"start\":24748}]", "bib_venue": "[{\"end\":16394,\"start\":16279},{\"end\":16975,\"start\":16843},{\"end\":17560,\"start\":17527},{\"end\":17935,\"start\":17895},{\"end\":18341,\"start\":18296},{\"end\":18640,\"start\":18585},{\"end\":19002,\"start\":18958},{\"end\":19708,\"start\":19669},{\"end\":20079,\"start\":20066},{\"end\":20528,\"start\":20473},{\"end\":20889,\"start\":20883},{\"end\":21149,\"start\":21139},{\"end\":21440,\"start\":21435},{\"end\":21661,\"start\":21601},{\"end\":22026,\"start\":21946},{\"end\":22729,\"start\":22693},{\"end\":23231,\"start\":23153},{\"end\":23737,\"start\":23644},{\"end\":24262,\"start\":24195},{\"end\":24831,\"start\":24763},{\"end\":16414,\"start\":16396},{\"end\":17094,\"start\":16977},{\"end\":22093,\"start\":22028},{\"end\":23307,\"start\":23233}]"}}}, "year": 2023, "month": 12, "day": 17}