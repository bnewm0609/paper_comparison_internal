{"id": 215778022, "updated": "2023-10-06 16:44:54.746", "metadata": {"title": "G1020: A Benchmark Retinal Fundus Image Dataset for Computer-Aided Glaucoma Detection", "authors": "[{\"first\":\"Muhammad\",\"last\":\"Bajwa\",\"middle\":[\"Naseer\"]},{\"first\":\"Gur\",\"last\":\"Singh\",\"middle\":[\"Amrit\",\"Pal\"]},{\"first\":\"Wolfgang\",\"last\":\"Neumeier\",\"middle\":[]},{\"first\":\"Muhammad\",\"last\":\"Malik\",\"middle\":[\"Imran\"]},{\"first\":\"Andreas\",\"last\":\"Dengel\",\"middle\":[]},{\"first\":\"Sheraz\",\"last\":\"Ahmed\",\"middle\":[]}]", "venue": "2020 International Joint Conference on Neural Networks (IJCNN)", "journal": "2020 International Joint Conference on Neural Networks (IJCNN)", "publication_date": {"year": 2020, "month": 5, "day": 28}, "abstract": "Scarcity of large publicly available retinal fundus image datasets for automated glaucoma detection has been the bottleneck for successful application of artificial intelligence towards practical Computer-Aided Diagnosis (CAD). A few small datasets that are available for research community usually suffer from impractical image capturing conditions and stringent inclusion criteria. These shortcomings in already limited choice of existing datasets make it challenging to mature a CAD system so that it can perform in real-world environment. In this paper we present a large publicly available retinal fundus image dataset for glaucoma classification called G1020. The dataset is curated by conforming to standard practices in routine ophthalmology and it is expected to serve as standard benchmark dataset for glaucoma detection. This database consists of 1020 high resolution colour fundus images and provides ground truth annotations for glaucoma diagnosis, optic disc and optic cup segmentation, vertical cup-to-disc ratio, size of neuroretinal rim in inferior, superior, nasal and temporal quadrants, and bounding box location for optic disc. We also report baseline results by conducting extensive experiments for automated glaucoma diagnosis and segmentation of optic disc and optic cup.", "fields_of_study": "[\"Engineering\",\"Computer Science\"]", "external_ids": {"arxiv": "2006.09158", "mag": "3133656575", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/ijcnn/BajwaSNM0A20", "doi": "10.1109/ijcnn48605.2020.9207664"}}, "content": {"source": {"pdf_hash": "101b2c0d317023a50c10fed7ab56da6b835ebe66", "pdf_src": "Arxiv", "pdf_uri": "[\"https://arxiv.org/pdf/2006.09158v1.pdf\"]", "oa_url_match": true, "oa_info": {"license": null, "open_access_url": "https://arxiv.org/pdf/2006.09158", "status": "GREEN"}}, "grobid": {"id": "66537abdfe94c37a7e96b5c7eeae60f17d6f30a0", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/101b2c0d317023a50c10fed7ab56da6b835ebe66.txt", "contents": "\nG1020: A Benchmark Retinal Fundus Image Dataset for Computer-Aided Glaucoma Detection\n\n\nMuhammad Naseer Bajwa \nGur Amrit \nPal Singh \nWolfgang Neumeier dr.neumeier-kl@web.de \nMuhammad Imran Malik \nAndreas Dengel \nSheraz Ahmed \n\nCenter for Artificial Intelligence GmbH (DFKI)\nTechnische Universit\u00e4t Kaiserslautern German Research\nKaiserslauternGermany\n\n\nGerman Research Center for Artificial Intelligence GmbH (DFKI)\nTechnische Universit\u00e4t Kaiserslautern\nKaiserslauternGermany\n\n\nNational University of Science and Technology (NUST) National Center of Artificial Intelligence Islamabad\nOpthalmology Clinic Kaiserslautern\nGermany, Pakistan\n\n\nGerman Research Center for Artificial Intelligence GmbH (DFKI)\nTechnische Universit\u00e4t Kaiserslautern\nKaiserslauternGermany\n\n\nSmart Data and Knowledge Services German Research Center for Artificial Intelligence GmbH (DFKI)\nKaiserslauternGermany\n\nG1020: A Benchmark Retinal Fundus Image Dataset for Computer-Aided Glaucoma Detection\nIndex Terms-Retinal Fundus ImagesGlaucoma DetectionComputer-Aided DiagnosisGlaucoma DatasetMedical Image AnalysisArtificial Intelligence in Medical Imaging\nScarcity of large publicly available retinal fundus image datasets for automated glaucoma detection has been the bottleneck for successful application of artificial intelligence towards practical Computer-Aided Diagnosis (CAD). A few small datasets that are available for research community usually suffer from impractical image capturing conditions and stringent inclusion criteria. These shortcomings in already limited choice of existing datasets make it challenging to mature a CAD system so that it can perform in real-world environment. In this paper we present a large publicly available retinal fundus image dataset for glaucoma classification called G1020. The dataset is curated by conforming to standard practices in routine ophthalmology and it is expected to serve as standard benchmark dataset for glaucoma detection. This database consists of 1020 high resolution colour fundus images and provides ground truth annotations for glaucoma diagnosis, optic disc and optic cup segmentation, vertical cup-to-disc ratio, size of neuroretinal rim in inferior, superior, nasal and temporal quadrants, and bounding box location for optic disc. We also report baseline results by conducting extensive experiments for automated glaucoma diagnosis and segmentation of optic disc and optic cup.\n\nI. INTRODUCTION\n\nComputer-Aided Diagnosis (CAD) of ocular diseases is receiving a lot of attention from research community due to its far-reaching benefits of providing swift and accurate large-scale screening as well as reducing physicians' workload in routine clinical setup [1]. Machine Leaning (ML) and Deep Learning (DL) based techniques are commonly used to automatically detect various ocular diseases like glaucoma [2], This work is partially funded by National University of Science and Technology (NUST), Pakistan through Prime Minister's Programme for Development of PhDs in Science and Technology, BMBF project DeFuseNN (01IW17002), and NVIDIA AI Lab (NVAIL) programme. diabetic retinopathy [3], Age-related Macular Degeneration (AMD) [4] and many other retinal disorders [5]. Recently, it has been shown that Retinal Fundus Images (RFIs) can be used to detect many non-ocular diseases as well like Type-II diabetics [6], anaemia [7], and cardiovascular risks [8]. For automated glaucoma detection, different image modalities and clinical tests are used, for instance, RFIs [9], Optical Coherence Tomography (OCT) [10], and Visual Field Tests (VFTs) [11]. However, fundus imaging is the most common and inexpensive imaging technique [12] for large-scale screening of various retinal diseases.\n\nMost of the publicly available RFI datasets have only a few hundred images (see section II). These datasets are collected with many imaging constraints like centralising Optic Disc (OD) [13] or macula and removing images containing certain artefacts [14]. Since the most important application of automated glaucoma detection is cost-effective and largescale screening [15] of general population, these automated solutions should be able to perform well in real-world scenarios with fundus images taken in day-to-day practice without many constraints [16]. Removing images that do not conform to strict inclusion criteria for example, from the available datasets might result in a CAD that works exceptionally well in controlled laboratory environment but might fail in routine screening or clinical workflow.\n\nIn this paper we present a new publicly available RFI dataset called G1020 1 for segmentation of OD and Optic Cup (OC) and detection of glaucoma. This dataset contains images taken under realistic conditions without many imaging constraints and, as a result, is fairly representative of real-world fundus imaging practices. We provide ground truth annotations for OD and OC segmentation, bounding box coordinates for OD localisation, vertical Cup-to-Disc Ratio (CDR), and size of neuroretinal rim in Inferior, Superior, Nasal and Temporal quadrants to see if ISNT rule is followed. We also provide gold standard clinical diagnosis for glaucoma and many other ocular disorders. We believe that this challenging dataset can be used as a benchmark dataset to train robust algorithms for glaucoma detection capable of performing in the field or in clinics.\n\n\nII. RELATED WORK\n\nIn this section we first present some of the largest publicly available RFI datasets for glaucoma detection and segmentation of OD and OC. Later, we survey a handful of contemporary works involving segmentation and classification tasks using these and other datasets. 2) RIM-ONE: This small dataset [17] consists of 169 high resolution RFIs collected at three Spanish hospitals. Each image is classified as healthy, early glaucoma, moderate glaucoma, deep glaucoma or ocular hypertension. Additionally, it provides OD segmentation annotations to evaluate OD detection algorithms.\n\n3) RIGA: Retinal fundus Images for Glaucoma Analysis (REGA) [18] consists of 750 images taken from Messidor dataset [19] and two clinic in Saudi Arabia. This dataset provides OD and OC boundary annotations; however, it does not provide any diagnosis with regards to glaucoma. 4) REFUGE: REtinal FUndus Glaucoma ChalengE (RIGA) [20] is the largest and one of the latest RFI datasets publicly available for glaucoma detection. It was made public in 2018 as a grand challenge and consists of 1200 fundus images with ground truth segmentation of OD and OC and clinical glaucoma labels. Despite large size of this dataset, this dataset is highly unbalanced towards healthy class as it contains only 120 glaucoma images. 5) ACRIMA: This new dataset [14] consists of a total of 705 fundus images with 396 glaucoma images and 309 normal images taken with centred optic disc. The dataset does not provide any annotations for OD and OC segmentation. Relatively balanced proportion of normal and glaucomatous images in this dataset makes it particularly suitable for training DL based classifiers.\n\n\nB. Optic Disc and Optic Cup Segmentation\n\nAlmazroa et al. [21] devised an image processing based heuristic algorithm for optic disc segmentation using RIGA dataset, which was later made public [18]. Their algorithm achieved an accuracy of 83.9% for marking the OD area and centroid. Al-Bander et al. [22] used a U-Net [23] like dense fully connected Convolutional Neural Network (CNN) for OD and OC segmentation and evaluated their method on 1129 RFIs from five public datasets. Their method was shown to be invariant to population demography, camera models, and other ocular diseases. They outperformed the state-ofthe-art on two datasets and gave competitive results on two datasets without training on these four datasets. Fu et al. [24] attempted to jointly segment OD and OC. They modified faster R-CNN [25] by replacing its Region Proposal Network (RPN) with two networks named Disc Proposal Network (DPN) and Cup Proposal Network (CPN). They tested their proposed network on publicly available ORIGA dataset and 1676 image of a private dataset called SCES [26], and outperformed stateof-the-art methods for joint segmentation of OD and OC.\n\n\nC. Glaucoma Classification\n\nRaghavendra et al. [27] used 1426 private RFIs to train and test an 18-layer Deep Neural Network (DNN) and achieved 95.6% accuracy, 95.5% sensitivity and 95.7% specificity for glaucoma classification. In a large and comprehensive study using around 40,000 RFIs, Li et al. [15] evaluated the performance of inception v3 for detecting referable Glaucomatous OpticNeuropathy (GON). They defined GON as vertical CDR greater than 0.7. They achieved 92.9% accuracy and 98.6% Area Under the Curve (AUC) with 95.6% sensitivity and 92.0% specificity. They found that the leading reason for false positive results was presence of other eye conditions in the fundus images. Al-Bander et al. [28] used 455 images of RIM-ONE v2 dataset and extracted discriminating features using DNN before classifying them using Support Vector Machine (SVM). They obtained 88.2% accuracy, 85% sensitivity and 90.8% specificity.\n\n\nIII. DATASET DESCRIPTION\n\nThe images in G1020 are collected at a private clinical practice in Kaiserslautern, Germany between year 2005 and 2017 with 45-degree field of view after using dilation drops. The records were subsequently anonymised and random unique patient identifiers were assigned to each record. Because the images are collected retrospectively and are fully anonymised the informed consent of the patients was not required. To achieve a dataset that reflects routine clinical practice at busy healthcare facilities, no specific imaging constraints, like centring of OD or macula, were imposed. Fig. 1 shows density map of OD in all images of G1020 as compared to corresponding density map of ORIGA. It can be seen that images in G1020 dataset have OD at a wider spatial area making post-processing of any segmentation algorithm significantly challenging. The images are stored in .JPG format. In the final dataset released, black background is truncated and only the fundus region is preserved resulting in images of size between 1944 \u00d7 2108 and 2426 \u00d7 3007 pixels. There are total of 1020 images from 432 patients. Each patient has a minimum of 1 image and maximum of 12 images. Out of 1020 images, 296 images from 110 patients were found to have glaucoma and 724 images from 322 patients were healthy. There was no patient with images belonging to both healthy and glaucomatous class.\n\nClinical diagnosis is provided for each patient with regards to presence or absence of glaucoma and any other ocular disorder observed. To provide segmentation ground truth, an expert marked OD and OC boundaries as well as bounding box annotations using labelme [29], which is an open source annotation tool developed by MIT. These manual annotations are verified and corrected (if required) by a veteran ophthalmologist with more than 25 years of clinical experience. The annotations are saved in JSON files corresponding to each image. Based on the ground truth annotations for OD and OC, vertical CDR is calculated and size of neuroretinal rim in four quadrants is measured to see if ISNT rule is followed.  In 60 glaucomatous images, OC was not visible whereas 170 healthy images also do not show any visible OC. Fig. 2 shows sample images with OD, OC, and bounding box annotations.\n\n\nIV. EXPERIMENTS AND EVALUATION RESULTS\n\nWe evaluated state-of-the-art segmentation algorithms and image classification networks on our G1020 dataset. For automated segmentation of OD and OC we used Mask R-CNN [30] with ResNet-50 [31] as convolutional backbone pre-trained on ImageNet [32]. We trained separate models for segmentation of OD and OC. We first trained using 80% random images from G1020 and tested on remaining 20% images. The names of images in both training and testing splits are given with the dataset. Secondly we trained Mask-RCNN using all images of ORIGA and evaluated their performance on all images of G1020. Table I summarises segmentation results. We employed multiple criteria to consider a detected OD and OC as correct or incorrect. Table I shows results for three such criteria, namely when Intersection Over Union (IOU) between predicted object and ground truth object is > 40, 50 or 60.\n\nTo refine our segmentation results, we employed Non-Maximum Suppression (NMS) and got rid of all but one contour with highest probability score. If the overlap (IOU) between a predicted object (OD or OC) and it's ground truth is less than the criterion (IOU > 0.4, for example), it's considered as both a False Negative (FN), since the actual object is not detected, and a False Positive (FP), since an object other than actual object is predicted. For training and testing on G1020 the network was able to predict OC and OD for each image. In this experiment there was only one image with IOU = 0.2689 below three criteria given in Table I. Second minimum IOU was found to be 0.6429. Therefore, precision, recall, and F-1 score for all three criteria are the same. Furthermore, since the only misclassified image resulted in 1 FP and 1 FN, therefore, the values of precision and recall are also the same. For experiment with training using ORIGA and testing on G1020, the network was able to detect 786 cups out of 791 actual  cups and 1005 discs out of 1020 discs. Therefore, precision and recall are different in that experiment for each criterion. Fig. 3 shows sample images with incorrectly detected OD and OC.\n\nUsing correctly predicted OD and OC we then calculate predicted CDR and size of neuroretinal rim in inferior, superior, nasal and temporal quadrants. Mean Absolute Percentage Error (MAPE) between various predicted values and ground truth values is given in Table II. All the values in this table are calculated using IOU> 0.5.\n\n\nA. Classification of Glaucoma\n\nAfter localising and extracting ODs from the whole fundus images, we used these extracted discs to train inception v3 for classification of healthy and glaucomatous images. We employed 6-fold cross validation with respect to patients to ensure that all images belonging to one patient are in either training set or validation set. The inception model with same experimentation setup was also used to classify ORIGA dataset using 5-fold cross validation. We also evaluated the performance of state-of-the-art method on ORIGA presented by Bajwa et al. [9] for detection of glaucoma in G1020 dataset. Table III shows performance metrics for both classifiers on both datasets. It is evident from the Table that both network were able to classify images from ORIGA with high precision and recall. However, the same networks struggled hard against G1020. We believe that the difference between the performance of inception network on these two datasets is correlated with the way these datasets are collected. ORIGA, and most other publicly available RFI datasets impose many constraints on imaging techniques and selection of images into final dataset that the resulting image set is no longer representative of realistic image capturing practices. A DL model trained on such carefully curated datasets could have the ability to perform well in laboratory conditions but is likely to be unsuccessful in the field.\n\n\nB. Segmentation of OD and OC\n\nTo provide deeper insight into the complexity of G1020 dataset and compare it with ORIGA, we analysed image  embeddings of both datasets from the final convolutional layer of inception model. We applied Principal Component Analysis (PCA) to obtain two of the most significant principal components and visualised them on 2D plane. Fig. 4 illustrates the results of PCA. We can see that glaucoma images (blue dots) and healthy images (red dots) are fairly separable in ORIGA dataset. However, both classes have huge overlap in latent representation of classifier trained on G1020 images. Fig. 5 shows Area under Receiver Operator Characteristic (ROC) curve for each individual fold and their mean for both datasets. The network was able to achieve competitive AUC compared to state-of-the-art AUC results on ORIGA classification by Bajwa et al. [9] (AUC = 0.874) and Fu et al. [24] (AUC = 0.851), but suffered from serious performance degradation on G1020.\n\n\nV. CONCLUSION\n\nMost of existing RFI datasets for glaucoma detection are very small in size (a few hundred images) and almost all of them are collected in a very controlled environment. These datasets do not consider practical limitations in imaging and usually exclude images that have other retinal artefacts [14]. It has been reported in the literature that presence of multiple eye diseases degrades the performance of DL algorithms trained on such datasets [22]. Due to these reasons, most of publicly available datasets for glaucoma detection are unable to train a robust CAD system that can perform equally well in real clinical environment. In this paper, we have presented a new large publicly available dataset of RFIs that closely represents fundus imaging in practical clinical routine and does not enforce strict inclusion criteria on the captured images. Our initial evaluation of various DL methods for OD and OC segmentation and glaucoma classification highlights challenges that need to be addresses to develop a practical CAD system for swift and reliable glaucoma screening. Our results set a baseline for comparison by future works in this domain. We invite research community to utilise this dataset and evaluate their segmentation and classification algorithms on it. \n\n\nOnline Retinal fundus Image database for Glaucoma Analysis and research (ORIGA) [13] is one of the largest and most commonly used dataset for glaucoma detection made public since 2010. This dataset consists of 650 images (168 glaucoma, 482 healthy) collected by Singapore Eye Research Institute between 2004 and 2007. The dataset provides class labels for healthy and glaucoma, OD and OC contours and CDR values for each image.\n\nFig. 1 :\n1Density Map of optic disc in G1020 and ORIGA. Optic disc in G1020 is not centralised, making post-processing of segmentation algorithms more challenging.\n\n\n(a) Sample image with all three annotations (b) Sample image without optic cup Fig. 2: Sample images with optic cup (black polygon), optic disc (white polygon) and bounding box (red rectangle) annotations.\n\n\n(a) Image with least IOU (= 0.2689) between prediction and GT of OD (b) Image with least IOU (= 0.308) between prediction and GT of OCFig. 3: Example images with incorrect OD and OC detection. Dotted annotations correspond to GT, whereas solid annotations represent prediction.\n\nFig. 4 :\n4Visualisation of image embeddings on 2D plane after dimensionality reduction using PCA for G1020 and ORIGA. Blue dots represent glaucoma images and red dots represent healthy images.\n\nFig. 5 :\n5ROC and AUC for 6-fold G1020 and 5-fold ORIGA datasets.\n\nTABLE I :\nISegmentation performance of Mask R-CNN on G1020 dataset.Train/Test Splits \nObject \nCriterion Average IOU Precision \nRecall \nF1-Score \n\nTrain: G1020 \n(random 80%) \nTest: G1020 \n(random 20%) \n\nOptic Disc \n\nIOU>0.4 \n0.8852 \n0.9951 \n0.9951 \n0.9951 \nIOU>0.5 \n0.8852 \n0.9951 \n0.9951 \n0.9951 \nIOU>0.6 \n0.8852 \n0.9951 \n0.9951 \n0.9951 \n\nOptic Cup \n\nIOU>0.4 \n0.7276 \n0.9810 \n0.9810 \n0.9810 \nIOU>0.5 \n0.7364 \n0.9494 \n0.9494 \n0.9494 \nIOU>0.6 \n0.7645 \n0.8228 \n0.8228 \n0.8228 \n\nTrain: ORIGA \n(all images) \nTest: G1020 \n(all images) \n\nOptic Disc \n\nIOU>0.4 \n0.8641 \n0.9920 \n0.9774 \n0.9847 \nIOU>0.5 \n0.8665 \n0.9861 \n0.9716 \n0.9786 \nIOU>0.6 \n0.8719 \n0.9692 \n0.9549 \n0.962 \n\nOptic Cup \n\nIOU>0.4 \n0.6496 \n0.9071 \n0.9014 \n0.9042 \nIOU>0.5 \n0.6809 \n0.7812 \n0.7762 \n0.7787 \nIOU>0.6 \n0.7256 \n0.5489 \n0.5752 \n0.5770 \n\n\n\nTABLE II :\nIIMean Absolute Percentage Error (MAPE) of various parameters for correctly detected optic disc and optic cup. STD stands for Standard Deviation.Train/Test Split \nParameters \nMean \nSTD \n\nTrain: G1020 \n(random 80%) \nTest: G1020 \n(random 20%) \n\nCup Diameter \n0.2242 0.1933 \nDisc Diameter \n0.0502 0.0664 \nCDR \n0.2304 0.1852 \n\nNeuroretinal \nRim \n\nInferior \n0.1226 0.1002 \nSuperior \n0.0206 0.0314 \nNasal \n0.0880 0.0881 \nTemporal 0.0669 0.0688 \n\nTrain: ORIGA \n(all images) \nTest: G1020 \n(all images) \n\nCup Diameter \n0.1396 0.1031 \nDisc Diameter \n0.0593 0.0692 \nCDR \n0.1674 0.1181 \n\nNeuroretinal \nRim \n\nInferior \n0.2102 0.2170 \nSuperior \n0.2066 0.1278 \nNasal \n0.2177 0.1933 \nTemporal 0.2150 0.1483 \n\n\n\nTABLE III :\nIIIPerformance metrics for glaucoma detection on G1020 and ORIGA.Method \nDateset \nClass \nPrecision \nRecall \nF1-Score \n\ninception v3 \n\nORIGA \n\nHealthy \n0.8578\u00b10.0383 \n0.9170\u00b10.0208 \n0.8861\u00b10.0252 \nGlaucoma \n0.6947\u00b10.0869 \n0.5581\u00b10.1408 \n0.6157\u00b10.1165 \nTotal \n0.8157\u00b10.0486 \n0.8246\u00b10.0419 \n0.8164\u00b10.0476 \n\nG1020 \n\nHealthy \n0.7150\u00b10.1053 \n0.8183\u00b10.0289 \n0.7587\u00b10.0619 \nGlaucoma \n0.2894\u00b10.0834 \n0.1920\u00b10.0637 \n0.2219\u00b10.0513 \nTotal \n0.6055\u00b10.094 \n0.6344\u00b10.0722 \n0.6080\u00b10.0988 \n\nBajwa et al. \n(2019) [9] \n\nORIGA \n\nHealthy \n0.8231\u00b10.0288 \n0.9186\u00b10.0229 \n0.8681\u00b10.246 \nGlaucoma \n0.6552\u00b10.0665 \n0.4366\u00b10.0495 \n0.5237\u00b10.534 \nTotal \n0.7797\u00b10.0378 \n0.7938\u00b10.0342 \n0.7788\u00b10.0366 \n\nG1020 \n\nHealthy \n0.4735\u00b10.3348 \n0.6667\u00b10.4714 \n0.5537\u00b10.3916 \nGlaucoma \n0.0970\u00b10.1373 \n0.3333\u00b10.4714 \n0.1503\u00b10.2126 \nTotal \n0.0.3646\u00b10.1979 0.0.5706\u00b10.1976 0.4371\u00b10.2162 \n\n\nAvailable at: https://www.dfki.uni-kl.de/g1020 arXiv:2006.09158v1 [eess.IV] 28 May 2020\n\nComputer-aided diagnosis of glaucoma using fundus images: A review. Y Hagiwara, J E W Koh, J H Tan, S V Bhandary, A Laude, E J Ciaccio, L Tong, U R Acharya, Computer methods and programs in biomedicine. 165Y. Hagiwara, J. E. W. Koh, J. H. Tan, S. V. Bhandary, A. Laude, E. J. Ciaccio, L. Tong, and U. R. Acharya, \"Computer-aided diagnosis of glaucoma using fundus images: A review,\" Computer methods and programs in biomedicine, vol. 165, pp. 1-12, 2018.\n\nEvaluation of an ai system for the automated detection of glaucoma from stereoscopic optic disc photographs: the european optic disc assessment study. T W Rogers, N Jaccard, F Carbonaro, H G Lemij, K A Vermeer, N J Reus, S Trikha, Eye. 3311T. W. Rogers, N. Jaccard, F. Carbonaro, H. G. Lemij, K. A. Vermeer, N. J. Reus, and S. Trikha, \"Evaluation of an ai system for the automated detection of glaucoma from stereoscopic optic disc photographs: the european optic disc assessment study,\" Eye, vol. 33, no. 11, pp. 1791- 1797, 2019.\n\nCombining fine-and coarse-grained classifiers for diabetic retinopathy detection. M N Bajwa, Y Taniguchi, M I Malik, W Neumeier, A Dengel, S Ahmed, Annual Conference on Medical Image Understanding and Analysis. SpringerM. N. Bajwa, Y. Taniguchi, M. I. Malik, W. Neumeier, A. Dengel, and S. Ahmed, \"Combining fine-and coarse-grained classifiers for diabetic retinopathy detection,\" in Annual Conference on Medical Image Under- standing and Analysis. Springer, 2019, pp. 242-253.\n\nAutomated detection of age-related macular degeneration in color fundus photography: a systematic review. E Pead, R Megaw, J Cameron, A Fleming, B Dhillon, E Trucco, T Macgillivray, survey of ophthalmology. 644E. Pead, R. Megaw, J. Cameron, A. Fleming, B. Dhillon, E. Trucco, and T. MacGillivray, \"Automated detection of age-related macular degeneration in color fundus photography: a systematic review,\" survey of ophthalmology, vol. 64, no. 4, pp. 498-511, 2019.\n\nDevelopment and validation of deep learning models for screening multiple abnormal findings in retinal fundus images. J Son, J Y Shin, H D Kim, K.-H Jung, K H Park, S J Park, Ophthalmology. 1271J. Son, J. Y. Shin, H. D. Kim, K.-H. Jung, K. H. Park, and S. J. Park, \"Development and validation of deep learning models for screening multiple abnormal findings in retinal fundus images,\" Ophthalmology, vol. 127, no. 1, pp. 85-94, 2020.\n\nDirect classification of type 2 diabetes from retinal fundus images in a population-based sample from the maastricht study. F G Heslinga, J P Pluim, A Houben, M T Schram, R Henry, C D Stehouwer, M J Van Greevenbroek, T T Berendschot, M Veta, arXiv:1911.10022arXiv preprintF. G. Heslinga, J. P. Pluim, A. Houben, M. T. Schram, R. Henry, C. D. Stehouwer, M. J. van Greevenbroek, T. T. Berendschot, and M. Veta, \"Direct classification of type 2 diabetes from retinal fundus images in a population-based sample from the maastricht study,\" arXiv preprint arXiv:1911.10022, 2019.\n\nDetection of anaemia from retinal fundus images via deep learning. A Mitani, A Huang, S Venugopalan, G S Corrado, L Peng, D R Webster, N Hammel, Y Liu, A V Varadarajan, Nature Biomedical Engineering. A. Mitani, A. Huang, S. Venugopalan, G. S. Corrado, L. Peng, D. R. Webster, N. Hammel, Y. Liu, and A. V. Varadarajan, \"Detection of anaemia from retinal fundus images via deep learning,\" Nature Biomed- ical Engineering, pp. 1-10, 2019.\n\nPrediction of cardiovascular risk factors from retinal fundus photographs via deep learning. R Poplin, A V Varadarajan, K Blumer, Y Liu, M V Mcconnell, G S Corrado, L Peng, D R Webster, Nature Biomedical Engineering. 23158R. Poplin, A. V. Varadarajan, K. Blumer, Y. Liu, M. V. McConnell, G. S. Corrado, L. Peng, and D. R. Webster, \"Prediction of cardiovascular risk factors from retinal fundus photographs via deep learning,\" Nature Biomedical Engineering, vol. 2, no. 3, p. 158, 2018.\n\nTwo-stage framework for optic disc localization and glaucoma classification in retinal fundus images using deep learning. M N Bajwa, M I Malik, S A Siddiqui, A Dengel, F Shafait, W Neumeier, S Ahmed, BMC medical informatics and decision making. 191136M. N. Bajwa, M. I. Malik, S. A. Siddiqui, A. Dengel, F. Shafait, W. Neumeier, and S. Ahmed, \"Two-stage framework for optic disc localization and glaucoma classification in retinal fundus images using deep learning,\" BMC medical informatics and decision making, vol. 19, no. 1, p. 136, 2019.\n\nGlaucoma diagnosis with machine learning based on optical coherence tomography and color fundus images. G An, K Omodaka, K Hashimoto, S Tsuda, Y Shiga, N Takada, T Kikawa, H Yokota, M Akiba, T Nakazawa, Journal of healthcare engineering. 2019G. An, K. Omodaka, K. Hashimoto, S. Tsuda, Y. Shiga, N. Takada, T. Kikawa, H. Yokota, M. Akiba, and T. Nakazawa, \"Glaucoma diag- nosis with machine learning based on optical coherence tomography and color fundus images,\" Journal of healthcare engineering, vol. 2019, 2019.\n\nA deep learning approach to automatic detection of early glaucoma from visual fields. \u015e S Kucur, G Hollo, R Sznitman, PloS one. 1311\u015e . S. Kucur, G. Hollo, and R. Sznitman, \"A deep learning approach to automatic detection of early glaucoma from visual fields,\" PloS one, vol. 13, no. 11, 2018.\n\nChapter 6 -image processing. M Abrmoff, C N Kay, ; , S J Ryan, S R Sadda, D R Hinton, A P Schachat, S R Sadda, C Wilkinson, P Wiedemann, Retina. London: W.B. SaundersFifth Edition. fifth edition edM. Abrmoff and C. N. Kay, \"Chapter 6 -image processing,\" in Retina (Fifth Edition), fifth edition ed., S. J. Ryan, S. R. Sadda, D. R. Hinton, A. P. Schachat, S. R. Sadda, C. Wilkinson, P. Wiedemann, and A. P. Schachat, Eds. London: W.B. Saunders, 2013, pp. 151 - 176. [Online]. Available: http://www.sciencedirect.com/science/article/ pii/B9781455707379000060\n\nOriga-light: An online retinal fundus image database for glaucoma analysis and research. Z Zhang, F S Yin, J Liu, W K Wong, N M Tan, B H Lee, J Cheng, T Y Wong, 2010 Annual International Conference of the IEEE Engineering in Medicine and Biology. IEEEZ. Zhang, F. S. Yin, J. Liu, W. K. Wong, N. M. Tan, B. H. Lee, J. Cheng, and T. Y. Wong, \"Origa-light: An online retinal fundus image database for glaucoma analysis and research,\" in 2010 Annual International Conference of the IEEE Engineering in Medicine and Biology. IEEE, 2010, pp. 3065-3068.\n\nCnns for automatic glaucoma assessment using fundus images: an extensive validation. A Diaz-Pinto, S Morales, V Naranjo, T K\u00f6hler, J M Mossi, A Navea, Biomedical engineering online. 18129A. Diaz-Pinto, S. Morales, V. Naranjo, T. K\u00f6hler, J. M. Mossi, and A. Navea, \"Cnns for automatic glaucoma assessment using fundus images: an extensive validation,\" Biomedical engineering online, vol. 18, no. 1, p. 29, 2019.\n\nEfficacy of a deep learning system for detecting glaucomatous optic neuropathy based on color fundus photographs. Z Li, Y He, S Keel, W Meng, R T Chang, M He, Ophthalmology. 1258Z. Li, Y. He, S. Keel, W. Meng, R. T. Chang, and M. He, \"Efficacy of a deep learning system for detecting glaucomatous optic neuropathy based on color fundus photographs,\" Ophthalmology, vol. 125, no. 8, pp. 1199-1206, 2018.\n\nEfficacy of a deep learning system for detecting glaucomatous optic neuropathy based on color fundus photographs. D C Hood, C G De Moraes, Ophthalmology. 1258D. C. Hood and C. G. De Moraes, \"Efficacy of a deep learning system for detecting glaucomatous optic neuropathy based on color fundus photographs,\" Ophthalmology, vol. 125, no. 8, pp. 1207-1208, 2018.\n\nRim-one: An open retinal image database for optic nerve evaluation. F Fumero, S Alay\u00f3n, J L Sanchez, J Sigut, M Gonzalez-Hernandez, 2011 24th international symposium on computer-based medical systems (CBMS). IEEEF. Fumero, S. Alay\u00f3n, J. L. Sanchez, J. Sigut, and M. Gonzalez- Hernandez, \"Rim-one: An open retinal image database for optic nerve evaluation,\" in 2011 24th international symposium on computer-based medical systems (CBMS). IEEE, 2011, pp. 1-6.\n\nRetinal fundus images for glaucoma analysis: the riga dataset. A Almazroa, S Alodhayb, E Osman, E Ramadan, M Hummadi, M Dlaim, M Alkatee, K Raahemifar, V Lakshminarayanan, Medical Imaging 2018: Imaging Informatics for Healthcare, Research, and Applications. 10579105790A. Almazroa, S. Alodhayb, E. Osman, E. Ramadan, M. Hummadi, M. Dlaim, M. Alkatee, K. Raahemifar, and V. Lakshminarayanan, \"Retinal fundus images for glaucoma analysis: the riga dataset,\" in Medical Imaging 2018: Imaging Informatics for Healthcare, Research, and Applications, vol. 10579. International Society for Optics and Photonics, 2018, p. 105790B.\n\nFeedback on a publicly distributed image database: the messidor database. E Decenci\u00e8re, X Zhang, G Cazuguel, B Lay, B Cochener, C Trone, P Gain, R Ordonez, P Massin, A Erginay, Image Analysis & Stereology. 333E. Decenci\u00e8re, X. Zhang, G. Cazuguel, B. Lay, B. Cochener, C. Trone, P. Gain, R. Ordonez, P. Massin, A. Erginay et al., \"Feedback on a publicly distributed image database: the messidor database,\" Image Analysis & Stereology, vol. 33, no. 3, pp. 231-234, 2014.\n\nRefuge challenge: A unified framework for evaluating automated methods for glaucoma assessment from fundus photographs. J I Orlando, H Fu, J B Breda, K Van Keer, D R Bathula, A Diaz-Pinto, R Fang, P.-A Heng, J Kim, J Lee, Medical image analysis. 59101570J. I. Orlando, H. Fu, J. B. Breda, K. van Keer, D. R. Bathula, A. Diaz- Pinto, R. Fang, P.-A. Heng, J. Kim, J. Lee et al., \"Refuge challenge: A unified framework for evaluating automated methods for glaucoma assessment from fundus photographs,\" Medical image analysis, vol. 59, p. 101570, 2020.\n\nOptic disc segmentation for glaucoma screening system using fundus images. A Almazroa, W Sun, S Alodhayb, K Raahemifar, V Lakshminarayanan, Clinical ophthalmology. 11A. Almazroa, W. Sun, S. Alodhayb, K. Raahemifar, and V. Lakshmi- narayanan, \"Optic disc segmentation for glaucoma screening system using fundus images,\" Clinical ophthalmology (Auckland, NZ), vol. 11, 2017.\n\nDense fully convolutional segmentation of the optic disc and cup in colour fundus for glaucoma diagnosis. B Al-Bander, B M Williams, W Al-Nuaimy, M A Al-Taee, H Pratt, Y Zheng, Symmetry. 10487B. Al-Bander, B. M. Williams, W. Al-Nuaimy, M. A. Al-Taee, H. Pratt, and Y. Zheng, \"Dense fully convolutional segmentation of the optic disc and cup in colour fundus for glaucoma diagnosis,\" Symmetry, vol. 10, no. 4, p. 87, 2018.\n\nU-net: Convolutional networks for biomedical image segmentation. O Ronneberger, P Fischer, T Brox, International Conference on Medical image computing and computer-assisted intervention. SpringerO. Ronneberger, P. Fischer, and T. Brox, \"U-net: Convolutional networks for biomedical image segmentation,\" in International Conference on Medical image computing and computer-assisted intervention. Springer, 2015, pp. 234-241.\n\nJoint optic disc and cup segmentation based on multi-label deep network and polar transformation. H Fu, J Cheng, Y Xu, D W K Wong, J Liu, X Cao, IEEE transactions on medical imaging. 377H. Fu, J. Cheng, Y. Xu, D. W. K. Wong, J. Liu, and X. Cao, \"Joint optic disc and cup segmentation based on multi-label deep network and polar transformation,\" IEEE transactions on medical imaging, vol. 37, no. 7, pp. 1597-1605, 2018.\n\nFaster r-cnn: Towards real-time object detection with region proposal networks. S Ren, K He, R Girshick, J Sun, Advances in neural information processing systems. S. Ren, K. He, R. Girshick, and J. Sun, \"Faster r-cnn: Towards real-time object detection with region proposal networks,\" in Advances in neural information processing systems, 2015, pp. 91-99.\n\n. M Baskaran, R C Foo, C.-Y Cheng, A K Narayanaswamy, Y.-F , M. Baskaran, R. C. Foo, C.-Y. Cheng, A. K. Narayanaswamy, Y.-F.\n\nThe prevalence and types of glaucoma in an urban chinese population: the singapore chinese eye study. R Zheng, S.-M Wu, P J Saw, T.-Y Foster, T Wong, Aung, JAMA ophthalmology. 1338Zheng, R. Wu, S.-M. Saw, P. J. Foster, T.-Y. Wong, and T. Aung, \"The prevalence and types of glaucoma in an urban chinese population: the singapore chinese eye study,\" JAMA ophthalmology, vol. 133, no. 8, pp. 874-880, 2015.\n\nDeep convolution neural network for accurate diagnosis of glaucoma using digital fundus images. U Raghavendra, H Fujita, S V Bhandary, A Gudigar, J H Tan, U R Acharya, Information Sciences. 441U. Raghavendra, H. Fujita, S. V. Bhandary, A. Gudigar, J. H. Tan, and U. R. Acharya, \"Deep convolution neural network for accurate diagnosis of glaucoma using digital fundus images,\" Information Sciences, vol. 441, pp. 41-49, 2018.\n\nAutomated glaucoma diagnosis using deep learning approach. B Al-Bander, W Al-Nuaimy, M A Al-Taee, Y Zheng, 2017 14th International Multi-Conference on Systems, Signals & Devices (SSD). B. Al-Bander, W. Al-Nuaimy, M. A. Al-Taee, and Y. Zheng, \"Auto- mated glaucoma diagnosis using deep learning approach,\" in 2017 14th International Multi-Conference on Systems, Signals & Devices (SSD).\n\n. IEEE. IEEE, 2017, pp. 207-210.\n\nLabelme: a database and web-based tool for image annotation. B C Russell, A Torralba, K P Murphy, W T Freeman, International journal of computer vision. 771-3B. C. Russell, A. Torralba, K. P. Murphy, and W. T. Freeman, \"Labelme: a database and web-based tool for image annotation,\" International journal of computer vision, vol. 77, no. 1-3, pp. 157-173, 2008.\n\nMask r-cnn. K He, G Gkioxari, P Doll\u00e1r, R Girshick, Proceedings of the IEEE international conference on computer vision. the IEEE international conference on computer visionK. He, G. Gkioxari, P. Doll\u00e1r, and R. Girshick, \"Mask r-cnn,\" in Proceedings of the IEEE international conference on computer vision, 2017, pp. 2961-2969.\n\nDeep residual learning for image recognition. K He, X Zhang, S Ren, J Sun, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionK. He, X. Zhang, S. Ren, and J. Sun, \"Deep residual learning for image recognition,\" in Proceedings of the IEEE conference on computer vision and pattern recognition, 2016, pp. 770-778.\n\nImagenet classification with deep convolutional neural networks. A Krizhevsky, I Sutskever, G E Hinton, Advances in neural information processing systems. A. Krizhevsky, I. Sutskever, and G. E. Hinton, \"Imagenet classification with deep convolutional neural networks,\" in Advances in neural infor- mation processing systems, 2012, pp. 1097-1105.\n", "annotations": {"author": "[{\"end\":111,\"start\":89},{\"end\":122,\"start\":112},{\"end\":133,\"start\":123},{\"end\":174,\"start\":134},{\"end\":196,\"start\":175},{\"end\":212,\"start\":197},{\"end\":226,\"start\":213},{\"end\":351,\"start\":227},{\"end\":476,\"start\":352},{\"end\":637,\"start\":477},{\"end\":762,\"start\":638},{\"end\":883,\"start\":763}]", "publisher": null, "author_last_name": "[{\"end\":110,\"start\":105},{\"end\":121,\"start\":116},{\"end\":132,\"start\":127},{\"end\":151,\"start\":143},{\"end\":195,\"start\":190},{\"end\":211,\"start\":205},{\"end\":225,\"start\":220}]", "author_first_name": "[{\"end\":97,\"start\":89},{\"end\":104,\"start\":98},{\"end\":115,\"start\":112},{\"end\":126,\"start\":123},{\"end\":142,\"start\":134},{\"end\":183,\"start\":175},{\"end\":189,\"start\":184},{\"end\":204,\"start\":197},{\"end\":219,\"start\":213}]", "author_affiliation": "[{\"end\":350,\"start\":228},{\"end\":475,\"start\":353},{\"end\":636,\"start\":478},{\"end\":761,\"start\":639},{\"end\":882,\"start\":764}]", "title": "[{\"end\":86,\"start\":1},{\"end\":969,\"start\":884}]", "venue": null, "abstract": "[{\"end\":2421,\"start\":1126}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":2703,\"start\":2700},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":2849,\"start\":2846},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3129,\"start\":3126},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":3173,\"start\":3170},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":3210,\"start\":3207},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3355,\"start\":3352},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":3368,\"start\":3365},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":3398,\"start\":3395},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":3512,\"start\":3509},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":3553,\"start\":3549},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":3589,\"start\":3585},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":3672,\"start\":3668},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":3919,\"start\":3915},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":3983,\"start\":3979},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":4101,\"start\":4097},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":4283,\"start\":4279},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":5715,\"start\":5711},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":6057,\"start\":6053},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":6113,\"start\":6109},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":6324,\"start\":6320},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":6740,\"start\":6736},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":7144,\"start\":7140},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":7279,\"start\":7275},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":7386,\"start\":7382},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":7404,\"start\":7400},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":7822,\"start\":7818},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":7894,\"start\":7890},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":8149,\"start\":8145},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":8282,\"start\":8278},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":8535,\"start\":8531},{\"attributes\":{\"ref_id\":\"b28\"},\"end\":8943,\"start\":8939},{\"attributes\":{\"ref_id\":\"b30\"},\"end\":10831,\"start\":10827},{\"attributes\":{\"ref_id\":\"b31\"},\"end\":11667,\"start\":11663},{\"attributes\":{\"ref_id\":\"b32\"},\"end\":11687,\"start\":11683},{\"attributes\":{\"ref_id\":\"b33\"},\"end\":11742,\"start\":11738},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":14503,\"start\":14500},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":16237,\"start\":16234},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":16270,\"start\":16266},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":16662,\"start\":16658},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":16813,\"start\":16809}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":18067,\"start\":17638},{\"attributes\":{\"id\":\"fig_1\"},\"end\":18232,\"start\":18068},{\"attributes\":{\"id\":\"fig_2\"},\"end\":18440,\"start\":18233},{\"attributes\":{\"id\":\"fig_3\"},\"end\":18720,\"start\":18441},{\"attributes\":{\"id\":\"fig_4\"},\"end\":18914,\"start\":18721},{\"attributes\":{\"id\":\"fig_5\"},\"end\":18981,\"start\":18915},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":19786,\"start\":18982},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":20492,\"start\":19787},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":21346,\"start\":20493}]", "paragraph": "[{\"end\":3727,\"start\":2440},{\"end\":4537,\"start\":3729},{\"end\":5391,\"start\":4539},{\"end\":5991,\"start\":5412},{\"end\":7079,\"start\":5993},{\"end\":8228,\"start\":7124},{\"end\":9158,\"start\":8259},{\"end\":10563,\"start\":9187},{\"end\":11451,\"start\":10565},{\"end\":12371,\"start\":11494},{\"end\":13588,\"start\":12373},{\"end\":13916,\"start\":13590},{\"end\":15358,\"start\":13950},{\"end\":16345,\"start\":15391},{\"end\":17637,\"start\":16363}]", "formula": null, "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":12093,\"start\":12086},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":12222,\"start\":12215},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":13013,\"start\":13006},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":13855,\"start\":13847},{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":14557,\"start\":14548}]", "section_header": "[{\"end\":2438,\"start\":2423},{\"end\":5410,\"start\":5394},{\"end\":7122,\"start\":7082},{\"end\":8257,\"start\":8231},{\"end\":9185,\"start\":9161},{\"end\":11492,\"start\":11454},{\"end\":13948,\"start\":13919},{\"end\":15389,\"start\":15361},{\"end\":16361,\"start\":16348},{\"end\":18077,\"start\":18069},{\"end\":18730,\"start\":18722},{\"end\":18924,\"start\":18916},{\"end\":18992,\"start\":18983},{\"end\":19798,\"start\":19788},{\"end\":20505,\"start\":20494}]", "table": "[{\"end\":19786,\"start\":19050},{\"end\":20492,\"start\":19944},{\"end\":21346,\"start\":20571}]", "figure_caption": "[{\"end\":18067,\"start\":17640},{\"end\":18232,\"start\":18079},{\"end\":18440,\"start\":18235},{\"end\":18720,\"start\":18443},{\"end\":18914,\"start\":18732},{\"end\":18981,\"start\":18926},{\"end\":19050,\"start\":18994},{\"end\":19944,\"start\":19801},{\"end\":20571,\"start\":20509}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":9777,\"start\":9771},{\"end\":11388,\"start\":11382},{\"end\":13531,\"start\":13525},{\"attributes\":{\"ref_id\":\"fig_4\"},\"end\":15727,\"start\":15721},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":15983,\"start\":15977}]", "bib_author_first_name": "[{\"end\":21505,\"start\":21504},{\"end\":21517,\"start\":21516},{\"end\":21521,\"start\":21518},{\"end\":21528,\"start\":21527},{\"end\":21530,\"start\":21529},{\"end\":21537,\"start\":21536},{\"end\":21539,\"start\":21538},{\"end\":21551,\"start\":21550},{\"end\":21560,\"start\":21559},{\"end\":21562,\"start\":21561},{\"end\":21573,\"start\":21572},{\"end\":21581,\"start\":21580},{\"end\":21583,\"start\":21582},{\"end\":22044,\"start\":22043},{\"end\":22046,\"start\":22045},{\"end\":22056,\"start\":22055},{\"end\":22067,\"start\":22066},{\"end\":22080,\"start\":22079},{\"end\":22082,\"start\":22081},{\"end\":22091,\"start\":22090},{\"end\":22093,\"start\":22092},{\"end\":22104,\"start\":22103},{\"end\":22106,\"start\":22105},{\"end\":22114,\"start\":22113},{\"end\":22508,\"start\":22507},{\"end\":22510,\"start\":22509},{\"end\":22519,\"start\":22518},{\"end\":22532,\"start\":22531},{\"end\":22534,\"start\":22533},{\"end\":22543,\"start\":22542},{\"end\":22555,\"start\":22554},{\"end\":22565,\"start\":22564},{\"end\":23011,\"start\":23010},{\"end\":23019,\"start\":23018},{\"end\":23028,\"start\":23027},{\"end\":23039,\"start\":23038},{\"end\":23050,\"start\":23049},{\"end\":23061,\"start\":23060},{\"end\":23071,\"start\":23070},{\"end\":23489,\"start\":23488},{\"end\":23496,\"start\":23495},{\"end\":23498,\"start\":23497},{\"end\":23506,\"start\":23505},{\"end\":23508,\"start\":23507},{\"end\":23518,\"start\":23514},{\"end\":23526,\"start\":23525},{\"end\":23528,\"start\":23527},{\"end\":23536,\"start\":23535},{\"end\":23538,\"start\":23537},{\"end\":23930,\"start\":23929},{\"end\":23932,\"start\":23931},{\"end\":23944,\"start\":23943},{\"end\":23946,\"start\":23945},{\"end\":23955,\"start\":23954},{\"end\":23965,\"start\":23964},{\"end\":23967,\"start\":23966},{\"end\":23977,\"start\":23976},{\"end\":23986,\"start\":23985},{\"end\":23988,\"start\":23987},{\"end\":24001,\"start\":24000},{\"end\":24003,\"start\":24002},{\"end\":24023,\"start\":24022},{\"end\":24025,\"start\":24024},{\"end\":24040,\"start\":24039},{\"end\":24448,\"start\":24447},{\"end\":24458,\"start\":24457},{\"end\":24467,\"start\":24466},{\"end\":24482,\"start\":24481},{\"end\":24484,\"start\":24483},{\"end\":24495,\"start\":24494},{\"end\":24503,\"start\":24502},{\"end\":24505,\"start\":24504},{\"end\":24516,\"start\":24515},{\"end\":24526,\"start\":24525},{\"end\":24533,\"start\":24532},{\"end\":24535,\"start\":24534},{\"end\":24911,\"start\":24910},{\"end\":24921,\"start\":24920},{\"end\":24923,\"start\":24922},{\"end\":24938,\"start\":24937},{\"end\":24948,\"start\":24947},{\"end\":24955,\"start\":24954},{\"end\":24957,\"start\":24956},{\"end\":24970,\"start\":24969},{\"end\":24972,\"start\":24971},{\"end\":24983,\"start\":24982},{\"end\":24991,\"start\":24990},{\"end\":24993,\"start\":24992},{\"end\":25427,\"start\":25426},{\"end\":25429,\"start\":25428},{\"end\":25438,\"start\":25437},{\"end\":25440,\"start\":25439},{\"end\":25449,\"start\":25448},{\"end\":25451,\"start\":25450},{\"end\":25463,\"start\":25462},{\"end\":25473,\"start\":25472},{\"end\":25484,\"start\":25483},{\"end\":25496,\"start\":25495},{\"end\":25952,\"start\":25951},{\"end\":25958,\"start\":25957},{\"end\":25969,\"start\":25968},{\"end\":25982,\"start\":25981},{\"end\":25991,\"start\":25990},{\"end\":26000,\"start\":25999},{\"end\":26010,\"start\":26009},{\"end\":26020,\"start\":26019},{\"end\":26030,\"start\":26029},{\"end\":26039,\"start\":26038},{\"end\":26450,\"start\":26449},{\"end\":26452,\"start\":26451},{\"end\":26461,\"start\":26460},{\"end\":26470,\"start\":26469},{\"end\":26688,\"start\":26687},{\"end\":26699,\"start\":26698},{\"end\":26701,\"start\":26700},{\"end\":26708,\"start\":26707},{\"end\":26712,\"start\":26711},{\"end\":26714,\"start\":26713},{\"end\":26722,\"start\":26721},{\"end\":26724,\"start\":26723},{\"end\":26733,\"start\":26732},{\"end\":26735,\"start\":26734},{\"end\":26745,\"start\":26744},{\"end\":26747,\"start\":26746},{\"end\":26759,\"start\":26758},{\"end\":26761,\"start\":26760},{\"end\":26770,\"start\":26769},{\"end\":26783,\"start\":26782},{\"end\":27306,\"start\":27305},{\"end\":27315,\"start\":27314},{\"end\":27317,\"start\":27316},{\"end\":27324,\"start\":27323},{\"end\":27331,\"start\":27330},{\"end\":27333,\"start\":27332},{\"end\":27341,\"start\":27340},{\"end\":27343,\"start\":27342},{\"end\":27350,\"start\":27349},{\"end\":27352,\"start\":27351},{\"end\":27359,\"start\":27358},{\"end\":27368,\"start\":27367},{\"end\":27370,\"start\":27369},{\"end\":27850,\"start\":27849},{\"end\":27864,\"start\":27863},{\"end\":27875,\"start\":27874},{\"end\":27886,\"start\":27885},{\"end\":27896,\"start\":27895},{\"end\":27898,\"start\":27897},{\"end\":27907,\"start\":27906},{\"end\":28291,\"start\":28290},{\"end\":28297,\"start\":28296},{\"end\":28303,\"start\":28302},{\"end\":28311,\"start\":28310},{\"end\":28319,\"start\":28318},{\"end\":28321,\"start\":28320},{\"end\":28330,\"start\":28329},{\"end\":28695,\"start\":28694},{\"end\":28697,\"start\":28696},{\"end\":28705,\"start\":28704},{\"end\":28707,\"start\":28706},{\"end\":29009,\"start\":29008},{\"end\":29019,\"start\":29018},{\"end\":29029,\"start\":29028},{\"end\":29031,\"start\":29030},{\"end\":29042,\"start\":29041},{\"end\":29051,\"start\":29050},{\"end\":29462,\"start\":29461},{\"end\":29474,\"start\":29473},{\"end\":29486,\"start\":29485},{\"end\":29495,\"start\":29494},{\"end\":29506,\"start\":29505},{\"end\":29517,\"start\":29516},{\"end\":29526,\"start\":29525},{\"end\":29537,\"start\":29536},{\"end\":29551,\"start\":29550},{\"end\":30097,\"start\":30096},{\"end\":30111,\"start\":30110},{\"end\":30120,\"start\":30119},{\"end\":30132,\"start\":30131},{\"end\":30139,\"start\":30138},{\"end\":30151,\"start\":30150},{\"end\":30160,\"start\":30159},{\"end\":30168,\"start\":30167},{\"end\":30179,\"start\":30178},{\"end\":30189,\"start\":30188},{\"end\":30613,\"start\":30612},{\"end\":30615,\"start\":30614},{\"end\":30626,\"start\":30625},{\"end\":30632,\"start\":30631},{\"end\":30634,\"start\":30633},{\"end\":30643,\"start\":30642},{\"end\":30655,\"start\":30654},{\"end\":30657,\"start\":30656},{\"end\":30668,\"start\":30667},{\"end\":30682,\"start\":30681},{\"end\":30693,\"start\":30689},{\"end\":30701,\"start\":30700},{\"end\":30708,\"start\":30707},{\"end\":31118,\"start\":31117},{\"end\":31130,\"start\":31129},{\"end\":31137,\"start\":31136},{\"end\":31149,\"start\":31148},{\"end\":31163,\"start\":31162},{\"end\":31523,\"start\":31522},{\"end\":31536,\"start\":31535},{\"end\":31538,\"start\":31537},{\"end\":31550,\"start\":31549},{\"end\":31563,\"start\":31562},{\"end\":31565,\"start\":31564},{\"end\":31576,\"start\":31575},{\"end\":31585,\"start\":31584},{\"end\":31905,\"start\":31904},{\"end\":31920,\"start\":31919},{\"end\":31931,\"start\":31930},{\"end\":32362,\"start\":32361},{\"end\":32368,\"start\":32367},{\"end\":32377,\"start\":32376},{\"end\":32383,\"start\":32382},{\"end\":32387,\"start\":32384},{\"end\":32395,\"start\":32394},{\"end\":32402,\"start\":32401},{\"end\":32765,\"start\":32764},{\"end\":32772,\"start\":32771},{\"end\":32778,\"start\":32777},{\"end\":32790,\"start\":32789},{\"end\":33044,\"start\":33043},{\"end\":33056,\"start\":33055},{\"end\":33058,\"start\":33057},{\"end\":33068,\"start\":33064},{\"end\":33077,\"start\":33076},{\"end\":33079,\"start\":33078},{\"end\":33099,\"start\":33095},{\"end\":33270,\"start\":33269},{\"end\":33282,\"start\":33278},{\"end\":33288,\"start\":33287},{\"end\":33290,\"start\":33289},{\"end\":33300,\"start\":33296},{\"end\":33310,\"start\":33309},{\"end\":33669,\"start\":33668},{\"end\":33684,\"start\":33683},{\"end\":33694,\"start\":33693},{\"end\":33696,\"start\":33695},{\"end\":33708,\"start\":33707},{\"end\":33719,\"start\":33718},{\"end\":33721,\"start\":33720},{\"end\":33728,\"start\":33727},{\"end\":33730,\"start\":33729},{\"end\":34058,\"start\":34057},{\"end\":34071,\"start\":34070},{\"end\":34084,\"start\":34083},{\"end\":34086,\"start\":34085},{\"end\":34097,\"start\":34096},{\"end\":34481,\"start\":34480},{\"end\":34483,\"start\":34482},{\"end\":34494,\"start\":34493},{\"end\":34506,\"start\":34505},{\"end\":34508,\"start\":34507},{\"end\":34518,\"start\":34517},{\"end\":34520,\"start\":34519},{\"end\":34794,\"start\":34793},{\"end\":34800,\"start\":34799},{\"end\":34812,\"start\":34811},{\"end\":34822,\"start\":34821},{\"end\":35157,\"start\":35156},{\"end\":35163,\"start\":35162},{\"end\":35172,\"start\":35171},{\"end\":35179,\"start\":35178},{\"end\":35579,\"start\":35578},{\"end\":35593,\"start\":35592},{\"end\":35606,\"start\":35605},{\"end\":35608,\"start\":35607}]", "bib_author_last_name": "[{\"end\":21514,\"start\":21506},{\"end\":21525,\"start\":21522},{\"end\":21534,\"start\":21531},{\"end\":21548,\"start\":21540},{\"end\":21557,\"start\":21552},{\"end\":21570,\"start\":21563},{\"end\":21578,\"start\":21574},{\"end\":21591,\"start\":21584},{\"end\":22053,\"start\":22047},{\"end\":22064,\"start\":22057},{\"end\":22077,\"start\":22068},{\"end\":22088,\"start\":22083},{\"end\":22101,\"start\":22094},{\"end\":22111,\"start\":22107},{\"end\":22121,\"start\":22115},{\"end\":22516,\"start\":22511},{\"end\":22529,\"start\":22520},{\"end\":22540,\"start\":22535},{\"end\":22552,\"start\":22544},{\"end\":22562,\"start\":22556},{\"end\":22571,\"start\":22566},{\"end\":23016,\"start\":23012},{\"end\":23025,\"start\":23020},{\"end\":23036,\"start\":23029},{\"end\":23047,\"start\":23040},{\"end\":23058,\"start\":23051},{\"end\":23068,\"start\":23062},{\"end\":23084,\"start\":23072},{\"end\":23493,\"start\":23490},{\"end\":23503,\"start\":23499},{\"end\":23512,\"start\":23509},{\"end\":23523,\"start\":23519},{\"end\":23533,\"start\":23529},{\"end\":23543,\"start\":23539},{\"end\":23941,\"start\":23933},{\"end\":23952,\"start\":23947},{\"end\":23962,\"start\":23956},{\"end\":23974,\"start\":23968},{\"end\":23983,\"start\":23978},{\"end\":23998,\"start\":23989},{\"end\":24020,\"start\":24004},{\"end\":24037,\"start\":24026},{\"end\":24045,\"start\":24041},{\"end\":24455,\"start\":24449},{\"end\":24464,\"start\":24459},{\"end\":24479,\"start\":24468},{\"end\":24492,\"start\":24485},{\"end\":24500,\"start\":24496},{\"end\":24513,\"start\":24506},{\"end\":24523,\"start\":24517},{\"end\":24530,\"start\":24527},{\"end\":24547,\"start\":24536},{\"end\":24918,\"start\":24912},{\"end\":24935,\"start\":24924},{\"end\":24945,\"start\":24939},{\"end\":24952,\"start\":24949},{\"end\":24967,\"start\":24958},{\"end\":24980,\"start\":24973},{\"end\":24988,\"start\":24984},{\"end\":25001,\"start\":24994},{\"end\":25435,\"start\":25430},{\"end\":25446,\"start\":25441},{\"end\":25460,\"start\":25452},{\"end\":25470,\"start\":25464},{\"end\":25481,\"start\":25474},{\"end\":25493,\"start\":25485},{\"end\":25502,\"start\":25497},{\"end\":25955,\"start\":25953},{\"end\":25966,\"start\":25959},{\"end\":25979,\"start\":25970},{\"end\":25988,\"start\":25983},{\"end\":25997,\"start\":25992},{\"end\":26007,\"start\":26001},{\"end\":26017,\"start\":26011},{\"end\":26027,\"start\":26021},{\"end\":26036,\"start\":26031},{\"end\":26048,\"start\":26040},{\"end\":26458,\"start\":26453},{\"end\":26467,\"start\":26462},{\"end\":26479,\"start\":26471},{\"end\":26696,\"start\":26689},{\"end\":26705,\"start\":26702},{\"end\":26719,\"start\":26715},{\"end\":26730,\"start\":26725},{\"end\":26742,\"start\":26736},{\"end\":26756,\"start\":26748},{\"end\":26767,\"start\":26762},{\"end\":26780,\"start\":26771},{\"end\":26793,\"start\":26784},{\"end\":27312,\"start\":27307},{\"end\":27321,\"start\":27318},{\"end\":27328,\"start\":27325},{\"end\":27338,\"start\":27334},{\"end\":27347,\"start\":27344},{\"end\":27356,\"start\":27353},{\"end\":27365,\"start\":27360},{\"end\":27375,\"start\":27371},{\"end\":27861,\"start\":27851},{\"end\":27872,\"start\":27865},{\"end\":27883,\"start\":27876},{\"end\":27893,\"start\":27887},{\"end\":27904,\"start\":27899},{\"end\":27913,\"start\":27908},{\"end\":28294,\"start\":28292},{\"end\":28300,\"start\":28298},{\"end\":28308,\"start\":28304},{\"end\":28316,\"start\":28312},{\"end\":28327,\"start\":28322},{\"end\":28333,\"start\":28331},{\"end\":28702,\"start\":28698},{\"end\":28717,\"start\":28708},{\"end\":29016,\"start\":29010},{\"end\":29026,\"start\":29020},{\"end\":29039,\"start\":29032},{\"end\":29048,\"start\":29043},{\"end\":29070,\"start\":29052},{\"end\":29471,\"start\":29463},{\"end\":29483,\"start\":29475},{\"end\":29492,\"start\":29487},{\"end\":29503,\"start\":29496},{\"end\":29514,\"start\":29507},{\"end\":29523,\"start\":29518},{\"end\":29534,\"start\":29527},{\"end\":29548,\"start\":29538},{\"end\":29568,\"start\":29552},{\"end\":30108,\"start\":30098},{\"end\":30117,\"start\":30112},{\"end\":30129,\"start\":30121},{\"end\":30136,\"start\":30133},{\"end\":30148,\"start\":30140},{\"end\":30157,\"start\":30152},{\"end\":30165,\"start\":30161},{\"end\":30176,\"start\":30169},{\"end\":30186,\"start\":30180},{\"end\":30197,\"start\":30190},{\"end\":30623,\"start\":30616},{\"end\":30629,\"start\":30627},{\"end\":30640,\"start\":30635},{\"end\":30652,\"start\":30644},{\"end\":30665,\"start\":30658},{\"end\":30679,\"start\":30669},{\"end\":30687,\"start\":30683},{\"end\":30698,\"start\":30694},{\"end\":30705,\"start\":30702},{\"end\":30712,\"start\":30709},{\"end\":31127,\"start\":31119},{\"end\":31134,\"start\":31131},{\"end\":31146,\"start\":31138},{\"end\":31160,\"start\":31150},{\"end\":31180,\"start\":31164},{\"end\":31533,\"start\":31524},{\"end\":31547,\"start\":31539},{\"end\":31560,\"start\":31551},{\"end\":31573,\"start\":31566},{\"end\":31582,\"start\":31577},{\"end\":31591,\"start\":31586},{\"end\":31917,\"start\":31906},{\"end\":31928,\"start\":31921},{\"end\":31936,\"start\":31932},{\"end\":32365,\"start\":32363},{\"end\":32374,\"start\":32369},{\"end\":32380,\"start\":32378},{\"end\":32392,\"start\":32388},{\"end\":32399,\"start\":32396},{\"end\":32406,\"start\":32403},{\"end\":32769,\"start\":32766},{\"end\":32775,\"start\":32773},{\"end\":32787,\"start\":32779},{\"end\":32794,\"start\":32791},{\"end\":33053,\"start\":33045},{\"end\":33062,\"start\":33059},{\"end\":33074,\"start\":33069},{\"end\":33093,\"start\":33080},{\"end\":33276,\"start\":33271},{\"end\":33285,\"start\":33283},{\"end\":33294,\"start\":33291},{\"end\":33307,\"start\":33301},{\"end\":33315,\"start\":33311},{\"end\":33321,\"start\":33317},{\"end\":33681,\"start\":33670},{\"end\":33691,\"start\":33685},{\"end\":33705,\"start\":33697},{\"end\":33716,\"start\":33709},{\"end\":33725,\"start\":33722},{\"end\":33738,\"start\":33731},{\"end\":34068,\"start\":34059},{\"end\":34081,\"start\":34072},{\"end\":34094,\"start\":34087},{\"end\":34103,\"start\":34098},{\"end\":34491,\"start\":34484},{\"end\":34503,\"start\":34495},{\"end\":34515,\"start\":34509},{\"end\":34528,\"start\":34521},{\"end\":34797,\"start\":34795},{\"end\":34809,\"start\":34801},{\"end\":34819,\"start\":34813},{\"end\":34831,\"start\":34823},{\"end\":35160,\"start\":35158},{\"end\":35169,\"start\":35164},{\"end\":35176,\"start\":35173},{\"end\":35183,\"start\":35180},{\"end\":35590,\"start\":35580},{\"end\":35603,\"start\":35594},{\"end\":35615,\"start\":35609}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":53013843},\"end\":21890,\"start\":21436},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":174797962},\"end\":22423,\"start\":21892},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":199516512},\"end\":22902,\"start\":22425},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":73496802},\"end\":23368,\"start\":22904},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":192523925},\"end\":23803,\"start\":23370},{\"attributes\":{\"doi\":\"arXiv:1911.10022\",\"id\":\"b5\"},\"end\":24378,\"start\":23805},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":209463082},\"end\":24815,\"start\":24380},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":3386122},\"end\":25302,\"start\":24817},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":197540952},\"end\":25845,\"start\":25304},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":85495842},\"end\":26361,\"start\":25847},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":54142132},\"end\":26656,\"start\":26363},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":63815004},\"end\":27214,\"start\":26658},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":23780456},\"end\":27762,\"start\":27216},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":84841586},\"end\":28174,\"start\":27764},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":3733964},\"end\":28578,\"start\":28176},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":3733964},\"end\":28938,\"start\":28580},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":14779650},\"end\":29396,\"start\":28940},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":80088512},\"end\":30020,\"start\":29398},{\"attributes\":{\"id\":\"b18\",\"matched_paper_id\":21755399},\"end\":30490,\"start\":30022},{\"attributes\":{\"id\":\"b19\",\"matched_paper_id\":203952960},\"end\":31040,\"start\":30492},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":30962517},\"end\":31414,\"start\":31042},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":21714037},\"end\":31837,\"start\":31416},{\"attributes\":{\"id\":\"b22\",\"matched_paper_id\":3719281},\"end\":32261,\"start\":31839},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":22910518},\"end\":32682,\"start\":32263},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":10328909},\"end\":33039,\"start\":32684},{\"attributes\":{\"id\":\"b25\"},\"end\":33165,\"start\":33041},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":19517613},\"end\":33570,\"start\":33167},{\"attributes\":{\"id\":\"b27\",\"matched_paper_id\":4778341},\"end\":33996,\"start\":33572},{\"attributes\":{\"id\":\"b28\",\"matched_paper_id\":26732502},\"end\":34383,\"start\":33998},{\"attributes\":{\"id\":\"b29\"},\"end\":34417,\"start\":34385},{\"attributes\":{\"id\":\"b30\",\"matched_paper_id\":1900911},\"end\":34779,\"start\":34419},{\"attributes\":{\"id\":\"b31\",\"matched_paper_id\":54465873},\"end\":35108,\"start\":34781},{\"attributes\":{\"id\":\"b32\",\"matched_paper_id\":206594692},\"end\":35511,\"start\":35110},{\"attributes\":{\"id\":\"b33\",\"matched_paper_id\":195908774},\"end\":35858,\"start\":35513}]", "bib_title": "[{\"end\":21502,\"start\":21436},{\"end\":22041,\"start\":21892},{\"end\":22505,\"start\":22425},{\"end\":23008,\"start\":22904},{\"end\":23486,\"start\":23370},{\"end\":24445,\"start\":24380},{\"end\":24908,\"start\":24817},{\"end\":25424,\"start\":25304},{\"end\":25949,\"start\":25847},{\"end\":26447,\"start\":26363},{\"end\":26685,\"start\":26658},{\"end\":27303,\"start\":27216},{\"end\":27847,\"start\":27764},{\"end\":28288,\"start\":28176},{\"end\":28692,\"start\":28580},{\"end\":29006,\"start\":28940},{\"end\":29459,\"start\":29398},{\"end\":30094,\"start\":30022},{\"end\":30610,\"start\":30492},{\"end\":31115,\"start\":31042},{\"end\":31520,\"start\":31416},{\"end\":31902,\"start\":31839},{\"end\":32359,\"start\":32263},{\"end\":32762,\"start\":32684},{\"end\":33267,\"start\":33167},{\"end\":33666,\"start\":33572},{\"end\":34055,\"start\":33998},{\"end\":34478,\"start\":34419},{\"end\":34791,\"start\":34781},{\"end\":35154,\"start\":35110},{\"end\":35576,\"start\":35513}]", "bib_author": "[{\"end\":21516,\"start\":21504},{\"end\":21527,\"start\":21516},{\"end\":21536,\"start\":21527},{\"end\":21550,\"start\":21536},{\"end\":21559,\"start\":21550},{\"end\":21572,\"start\":21559},{\"end\":21580,\"start\":21572},{\"end\":21593,\"start\":21580},{\"end\":22055,\"start\":22043},{\"end\":22066,\"start\":22055},{\"end\":22079,\"start\":22066},{\"end\":22090,\"start\":22079},{\"end\":22103,\"start\":22090},{\"end\":22113,\"start\":22103},{\"end\":22123,\"start\":22113},{\"end\":22518,\"start\":22507},{\"end\":22531,\"start\":22518},{\"end\":22542,\"start\":22531},{\"end\":22554,\"start\":22542},{\"end\":22564,\"start\":22554},{\"end\":22573,\"start\":22564},{\"end\":23018,\"start\":23010},{\"end\":23027,\"start\":23018},{\"end\":23038,\"start\":23027},{\"end\":23049,\"start\":23038},{\"end\":23060,\"start\":23049},{\"end\":23070,\"start\":23060},{\"end\":23086,\"start\":23070},{\"end\":23495,\"start\":23488},{\"end\":23505,\"start\":23495},{\"end\":23514,\"start\":23505},{\"end\":23525,\"start\":23514},{\"end\":23535,\"start\":23525},{\"end\":23545,\"start\":23535},{\"end\":23943,\"start\":23929},{\"end\":23954,\"start\":23943},{\"end\":23964,\"start\":23954},{\"end\":23976,\"start\":23964},{\"end\":23985,\"start\":23976},{\"end\":24000,\"start\":23985},{\"end\":24022,\"start\":24000},{\"end\":24039,\"start\":24022},{\"end\":24047,\"start\":24039},{\"end\":24457,\"start\":24447},{\"end\":24466,\"start\":24457},{\"end\":24481,\"start\":24466},{\"end\":24494,\"start\":24481},{\"end\":24502,\"start\":24494},{\"end\":24515,\"start\":24502},{\"end\":24525,\"start\":24515},{\"end\":24532,\"start\":24525},{\"end\":24549,\"start\":24532},{\"end\":24920,\"start\":24910},{\"end\":24937,\"start\":24920},{\"end\":24947,\"start\":24937},{\"end\":24954,\"start\":24947},{\"end\":24969,\"start\":24954},{\"end\":24982,\"start\":24969},{\"end\":24990,\"start\":24982},{\"end\":25003,\"start\":24990},{\"end\":25437,\"start\":25426},{\"end\":25448,\"start\":25437},{\"end\":25462,\"start\":25448},{\"end\":25472,\"start\":25462},{\"end\":25483,\"start\":25472},{\"end\":25495,\"start\":25483},{\"end\":25504,\"start\":25495},{\"end\":25957,\"start\":25951},{\"end\":25968,\"start\":25957},{\"end\":25981,\"start\":25968},{\"end\":25990,\"start\":25981},{\"end\":25999,\"start\":25990},{\"end\":26009,\"start\":25999},{\"end\":26019,\"start\":26009},{\"end\":26029,\"start\":26019},{\"end\":26038,\"start\":26029},{\"end\":26050,\"start\":26038},{\"end\":26460,\"start\":26449},{\"end\":26469,\"start\":26460},{\"end\":26481,\"start\":26469},{\"end\":26698,\"start\":26687},{\"end\":26707,\"start\":26698},{\"end\":26711,\"start\":26707},{\"end\":26721,\"start\":26711},{\"end\":26732,\"start\":26721},{\"end\":26744,\"start\":26732},{\"end\":26758,\"start\":26744},{\"end\":26769,\"start\":26758},{\"end\":26782,\"start\":26769},{\"end\":26795,\"start\":26782},{\"end\":27314,\"start\":27305},{\"end\":27323,\"start\":27314},{\"end\":27330,\"start\":27323},{\"end\":27340,\"start\":27330},{\"end\":27349,\"start\":27340},{\"end\":27358,\"start\":27349},{\"end\":27367,\"start\":27358},{\"end\":27377,\"start\":27367},{\"end\":27863,\"start\":27849},{\"end\":27874,\"start\":27863},{\"end\":27885,\"start\":27874},{\"end\":27895,\"start\":27885},{\"end\":27906,\"start\":27895},{\"end\":27915,\"start\":27906},{\"end\":28296,\"start\":28290},{\"end\":28302,\"start\":28296},{\"end\":28310,\"start\":28302},{\"end\":28318,\"start\":28310},{\"end\":28329,\"start\":28318},{\"end\":28335,\"start\":28329},{\"end\":28704,\"start\":28694},{\"end\":28719,\"start\":28704},{\"end\":29018,\"start\":29008},{\"end\":29028,\"start\":29018},{\"end\":29041,\"start\":29028},{\"end\":29050,\"start\":29041},{\"end\":29072,\"start\":29050},{\"end\":29473,\"start\":29461},{\"end\":29485,\"start\":29473},{\"end\":29494,\"start\":29485},{\"end\":29505,\"start\":29494},{\"end\":29516,\"start\":29505},{\"end\":29525,\"start\":29516},{\"end\":29536,\"start\":29525},{\"end\":29550,\"start\":29536},{\"end\":29570,\"start\":29550},{\"end\":30110,\"start\":30096},{\"end\":30119,\"start\":30110},{\"end\":30131,\"start\":30119},{\"end\":30138,\"start\":30131},{\"end\":30150,\"start\":30138},{\"end\":30159,\"start\":30150},{\"end\":30167,\"start\":30159},{\"end\":30178,\"start\":30167},{\"end\":30188,\"start\":30178},{\"end\":30199,\"start\":30188},{\"end\":30625,\"start\":30612},{\"end\":30631,\"start\":30625},{\"end\":30642,\"start\":30631},{\"end\":30654,\"start\":30642},{\"end\":30667,\"start\":30654},{\"end\":30681,\"start\":30667},{\"end\":30689,\"start\":30681},{\"end\":30700,\"start\":30689},{\"end\":30707,\"start\":30700},{\"end\":30714,\"start\":30707},{\"end\":31129,\"start\":31117},{\"end\":31136,\"start\":31129},{\"end\":31148,\"start\":31136},{\"end\":31162,\"start\":31148},{\"end\":31182,\"start\":31162},{\"end\":31535,\"start\":31522},{\"end\":31549,\"start\":31535},{\"end\":31562,\"start\":31549},{\"end\":31575,\"start\":31562},{\"end\":31584,\"start\":31575},{\"end\":31593,\"start\":31584},{\"end\":31919,\"start\":31904},{\"end\":31930,\"start\":31919},{\"end\":31938,\"start\":31930},{\"end\":32367,\"start\":32361},{\"end\":32376,\"start\":32367},{\"end\":32382,\"start\":32376},{\"end\":32394,\"start\":32382},{\"end\":32401,\"start\":32394},{\"end\":32408,\"start\":32401},{\"end\":32771,\"start\":32764},{\"end\":32777,\"start\":32771},{\"end\":32789,\"start\":32777},{\"end\":32796,\"start\":32789},{\"end\":33055,\"start\":33043},{\"end\":33064,\"start\":33055},{\"end\":33076,\"start\":33064},{\"end\":33095,\"start\":33076},{\"end\":33102,\"start\":33095},{\"end\":33278,\"start\":33269},{\"end\":33287,\"start\":33278},{\"end\":33296,\"start\":33287},{\"end\":33309,\"start\":33296},{\"end\":33317,\"start\":33309},{\"end\":33323,\"start\":33317},{\"end\":33683,\"start\":33668},{\"end\":33693,\"start\":33683},{\"end\":33707,\"start\":33693},{\"end\":33718,\"start\":33707},{\"end\":33727,\"start\":33718},{\"end\":33740,\"start\":33727},{\"end\":34070,\"start\":34057},{\"end\":34083,\"start\":34070},{\"end\":34096,\"start\":34083},{\"end\":34105,\"start\":34096},{\"end\":34493,\"start\":34480},{\"end\":34505,\"start\":34493},{\"end\":34517,\"start\":34505},{\"end\":34530,\"start\":34517},{\"end\":34799,\"start\":34793},{\"end\":34811,\"start\":34799},{\"end\":34821,\"start\":34811},{\"end\":34833,\"start\":34821},{\"end\":35162,\"start\":35156},{\"end\":35171,\"start\":35162},{\"end\":35178,\"start\":35171},{\"end\":35185,\"start\":35178},{\"end\":35592,\"start\":35578},{\"end\":35605,\"start\":35592},{\"end\":35617,\"start\":35605}]", "bib_venue": "[{\"end\":21637,\"start\":21593},{\"end\":22126,\"start\":22123},{\"end\":22634,\"start\":22573},{\"end\":23109,\"start\":23086},{\"end\":23558,\"start\":23545},{\"end\":23927,\"start\":23805},{\"end\":24578,\"start\":24549},{\"end\":25032,\"start\":25003},{\"end\":25547,\"start\":25504},{\"end\":26083,\"start\":26050},{\"end\":26489,\"start\":26481},{\"end\":26801,\"start\":26795},{\"end\":27461,\"start\":27377},{\"end\":27944,\"start\":27915},{\"end\":28348,\"start\":28335},{\"end\":28732,\"start\":28719},{\"end\":29146,\"start\":29072},{\"end\":29654,\"start\":29570},{\"end\":30226,\"start\":30199},{\"end\":30736,\"start\":30714},{\"end\":31204,\"start\":31182},{\"end\":31601,\"start\":31593},{\"end\":32024,\"start\":31938},{\"end\":32444,\"start\":32408},{\"end\":32845,\"start\":32796},{\"end\":33341,\"start\":33323},{\"end\":33760,\"start\":33740},{\"end\":34181,\"start\":34105},{\"end\":34391,\"start\":34387},{\"end\":34570,\"start\":34530},{\"end\":34900,\"start\":34833},{\"end\":35262,\"start\":35185},{\"end\":35666,\"start\":35617},{\"end\":34954,\"start\":34902},{\"end\":35326,\"start\":35264}]"}}}, "year": 2023, "month": 12, "day": 17}