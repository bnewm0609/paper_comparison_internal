{"id": 199465820, "updated": "2022-06-13 10:55:51.075", "metadata": {"title": "Correlation-Sensitive Next-Basket Recommendation", "authors": "[{\"first\":\"Duc-Trong\",\"last\":\"Le\",\"middle\":[]},{\"first\":\"Hady\",\"last\":\"Lauw\",\"middle\":[\"W.\"]},{\"first\":\"Yuan\",\"last\":\"Fang\",\"middle\":[]}]", "venue": "Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence", "journal": "Proceedings of the Twenty-Eighth International Joint Conference on Artificial Intelligence", "publication_date": {"year": 2019, "month": null, "day": null}, "abstract": "Items adopted by a user over time are indicative of the underlying preferences. We are concerned with learning such preferences from observed sequences of adoptions for recommendation. As multiple items are commonly adopted concurrently, e.g., a basket of grocery items or a sitting of media consumption, we deal with a sequence of baskets as input, and seek to recommend the next basket. Intuitively, a basket tends to contain groups of related items that support particular needs. Instead of recommending items independently for the next basket, we hypothesize that incorporating information on pairwise correlations among items would help to arrive at more coherent basket recommendations. Towards this objective, we develop a hierarchical network architecture codenamed Beacon to model basket sequences. Each basket is encoded taking into account the relative importance of items and correlations among item pairs. This encoding is utilized to infer sequential associations along the basket sequence. Extensive experiments on three public real-life datasets showcase the effectiveness of our approach for the next-basket recommendation problem.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": "2964648863", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/ijcai/LeLF19", "doi": "10.24963/ijcai.2019/389"}}, "content": {"source": {"pdf_hash": "d7ac721241c660d077fe029625612a07833d689b", "pdf_src": "Adhoc", "pdf_uri": "[\"https://web.archive.org/web/20200322134339/https:/ink.library.smu.edu.sg/cgi/viewcontent.cgi?article=5437&context=sis_research\"]", "oa_url_match": false, "oa_info": {"license": null, "open_access_url": "https://www.ijcai.org/proceedings/2019/0389.pdf", "status": "BRONZE"}}, "grobid": {"id": "a8099b6364237c58f987867381b504abfadb7364", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/d7ac721241c660d077fe029625612a07833d689b.txt", "contents": "\nCorrelation-sensitive next-basket recommendation Correlation-Sensitive Next-Basket Recommendation\n2019. 2019 August 10-16. 2808-2814\n\nDuc Trong \nL E \nWirawan Hady \nLauw \nYuan Fang yfang@smu.edu.sg \nDuc-Trong Le ductrong.le.2014@phdis.smu.edu.sg \nHady W Lauw hadywlauw@smu.edu.sg \nYuan Fang \n\nSchool Of Information Systems School of Information Systems\nSchool of Information Systems\nSingapore Management University Institutional Knowledge at Singapore Management University Research Collection\nSingapore Management University\nSingapore Management University\nSingapore Management University\nSingapore\n\n\nManagement University\nSingapore\n\nCorrelation-sensitive next-basket recommendation Correlation-Sensitive Next-Basket Recommendation\n\nProceedings of the 28th International Joint Conference on Artificial Intelligence\nthe 28th International Joint Conference on Artificial IntelligenceMacau, China2019. 2019 August 10-16. 2808-281410.24963/ijcai.2019/389Follow this and additional works at: https://ink.library.smu.edu.sg/sis_research Available at: https://ink.library.smu.edu.sg/sis_research/4434Citation LE, Duc TrongLAUW, Hady Wirawanand FANG, Yuan Correlation-sensitive next-basket recommendation\nItems adopted by a user over time are indicative of the underlying preferences. We are concerned with learning such preferences from observed sequences of adoptions for recommendation. As multiple items are commonly adopted concurrently, e.g., a basket of grocery items or a sitting of media consumption, we deal with a sequence of baskets as input, and seek to recommend the next basket. Intuitively, a basket tends to contain groups of related items that support particular needs. Instead of recommending items independently for the next basket, we hypothesize that incorporating information on pairwise correlations among items would help to arrive at more coherent basket recommendations. Towards this objective, we develop a hierarchical network architecture codenamed Beacon to model basket sequences. Each basket is encoded taking into account the relative importance of items and correlations among item pairs. This encoding is utilized to infer sequential associations along the basket sequence. Extensive experiments on three public real-life datasets showcase the effectiveness of our approach for the next-basket recommendation problem.\n\nIntroduction\n\nTo cope with the astounding and escalating number of options facing us, involving the selection of products, news, movies, music, points of interest, etc., a recommender system offers the most, if not the only, pragmatic way for finding an item of interest. In the literature, there are several major bases for recommendation. One is personalization, undergirded by userspecific parameters. Another is association among items, i.e., given items that have been adopted thus far, which other items shall be recommended. Our focus in this work is the latter.\n\nOne form of association among items is sequential [Quadrana et al., 2018]. A sequence of items adopted over time carries signals about the underlying preferences that bear clues for future adoptions. For instance, someone who has been listening to a music genre may likely be interested in new songs of that genre. Previous restaurant visits may have a bearing on future dining choices. The essence is thus preference driven by sequentiality, rather than personalization per se. In many scenarios we adopt more than one item at a time. We listen to a few songs in the same sitting, use several tags to label things, run a few errands in the same trip, purchase multiple products in the same shopping cart, etc. We refer to a collection of items adopted concurrently as a \"basket\". Frequently, some items within a basket are correlated to a certain extent. This is because these items may arise from the same underlying need, e.g., ingredients for the same recipe, tags describing the same object. Hence we are really dealing not with sequences of items, but rather with sequences of baskets.\n\nIn this work, we address the problem of next-basket recommendation. Given a sequence of baskets adopted by a user as input, our objective is to predict a set of items that are likely to belong in the next basket. Figure 1 illustrates this in the context of grocery shopping. In this case, each time step corresponds to a shopping session. In the first session (T = 1), the basket of {Salmon, Wasabi, Japanese rice} implies a latent intention of making sushi. The second session (T = 2) likely concerns a crab-based recipe with the combination of {Crab, Pepper, Melted Butter, Garlic}. The sequentiality hints at an underlying preference for a seafood diet. In Figure 1, the problem is to predict the basket at T = 3.\n\nThere have been active efforts towards next-basket recommendation. One is to rely only on the most recently purchased basket to predict the next basket [Rendle et al., 2010;Wang et al., 2015;Wan et al., 2018]. This may be applicable in short-term dependency scenarios, but it may not capture underlying preferences as well as a method that looks further back into history. Hence, another approach is to capture the long-term sequential dependencies using methods such as recurrent neural network (RNN) [Yu et al., 2016]. In any case, these existing approaches arrive at the recommended items for the next basket independently, based only on their respective associations with the past basket(s), disregarding the collective associations among items to be recommended.\n\nWe postulate that a basket tends to contain coalitions of related items, rather than independent items. Thus, if the objective is to predict items that belong in the next basket, then we should factor in the correlations among those items in our modeling as well as prediction. For example, while independent recommendations in Figure 1 may capture the long-term preference for seafood (predicting oyster), the other recommended items may be unrelated yet popular items such as milk and wasabi. In contrast, taking into account that purchasing an item, e.g., oysters, tends to inspire the purchase of other correlated items, then a correlation-sensitive nextbasket recommendation may favor items frequently eaten or purchased together with oysters, e.g., lemon and mint. Contributions. Towards realizing this intuition, we incorporate information on item correlations for next-basket recommendation. To our best knowledge, we are the first to consider correlations among predicted items for this problem, which is our first contribution. In Section 3, we formalize this problem, and discuss how item correlations may be obtained. As a second contribution, in Section 4 we further describe a novel hierarchical network architecture called Basket Sequence Correlation Network (codenamed Beacon), which learns the representations of each basket leading to the overall representation of a basket sequence that could be used for next-basket prediction. This model is built on a couple of principles in deriving the representations. For one, individual items in a basket are differentially important, depending on their frequencies as well as efficacies in drawing other items. For another, item pairs in a basket are differentially related, with some having stronger or more exclusive connections. As our final contribution, in Section 5 we conduct extensive experiments on three real-life datasets of different domains. The results show that Beacon's modeling of item correlations produce significant improvements over baselines.\n\n\nRelated Work\n\nHere we review several classes of previous work related to sequential as well as basket-oriented recommendations. Item Sequences. One class of approaches are concerned with sequential dependencies among individual items. Some rely on Markov chains to model short-term dependencies using either factorization [Rendle et al., 2010]  C item correlation matrix \u03c9 item importance parameters B t , x t basket at time t and its binary representation z t , b t intermediate and latent representations of B t h t recurrent hidden output at time t \u03a6, \u03c6 weight and bias parameters in basket encoder \u03a8, \u03a8 , \u03c8 weight and bias parameters in sequence encoder \u0393 weight parameters in predictor s (S) sequential signal given sequence S y (S) predicted item scores given sequence S , which are not directly comparable as we learn representations from sequences without the presumption of user-specific parameters. For completeness, we will compare to [Wan et al., 2018], focusing the comparison on the sequential and basket effects alone.\n\nBaskets. In an orthogonal direction to ours are a class of techniques focusing solely on basket-level associations. [Sarwar et al., 2000] relies on association rules. [Pathak et al., 2017] seek to recommend bundles. [Le et al., 2017; attempt basket completion, with existing basket items as context to predict the remaining item. [Li et al., 2009] applies random walks on user-item bipartite graph to generate basket-sensitive item recommendations. There are several works that exploit item-item associations [Ning and Karypis, 2011] and itemset-item associations [Christakopoulou and Karypis, 2014] for similarity-based recommendations, not in the complementary manner as ours.\n\n\nPreliminaries\n\nIn this section, we formalize our problem and introduce the formulation of correlation matrix. We summarize the main notations in Table 1, including those to be introduced later.\n\n\nProblem Statement\n\nWe first introduce some background concepts. Assume a set of items V = {1, 2, . . . , |V |}. Several items can form a basket, which is essentially a set of items, denoted as\nB = {i 1 , i 2 , . . . , i |B| } where i k 's are distinct integers in {1, .\n. . , |V |}. Note that baskets may have variable sizes. In real-world applications, a basket could be derived from products purchased in a retail transaction, websites surfed in a browser session, or places visited in a trip. In our problem, as the first input, we assume a set of sequences S. Each sequence S \u2208 S is a temporally ordered list of basket S = B (S) 1 , B (S) 2 , . . . , B (S) (S) such that B (S) t happens at time t and (S) is the length of the sequence. Hereafter, when the context is clear, for brevity we will omit the basket superscript (S) which indicates that the basket belongs to sequence S. Note that sequences may have variable lengths, and they are divided into train and test sets.\n\nAs the second input, we assume a correlation matrix C \u2208 R |V |\u00d7|V | . If two items i and j tend to co-occur with each other in a basket, C ij should be higher. We will elaborate on the construction of this matrix in Section 3.2.\n\nAs output, for a test sequence S = B 1 , . . . , B (S) , we aim to predict the next basket B (S)+1 as the recommendation. Ideally, some, if not most, of the predicted items should be related to form a coherent basket. Typically the groundtruth size of B (S)+1 is unknown, which is approximated as a basket of a given constant size K [Yu et al., 2016].\n\n\nCorrelation Matrix\n\nAs discussed above, our formulation requires a correlation matrix C, which can be constructed based on the co-occurring items in the observed training baskets. Specifically, let F \u2208 R |V |\u00d7|V | capture the frequency of co-occurrences, such that F ij is the number of times items i and j appear in a common basket, \u2200i = j. As F contains raw counts that can differ significantly due to the varying popularity of items, we normalize F to obtain the final correlation matrix C based on the Laplacian matrix [Kipf and Welling, 2017]:\nC = D \u2212 1 2 F D \u2212 1 2 ,(1)\nwhere D is the degree matrix such that D ii = j C ij . Note that by definition, F and C are both symmetric. Furthermore, in some cases, the correlation matrix could be too sparse to provide useful associations. We may consider higher-order correlations up to the N -th order, i.e., C + N n=2 \u00b5 n\u22121 Norm(C n ), where \u00b5 \u2208 (0, 1) is a discount factor for higher orders, and Norm(\u00b7) sets the diagonal to zero and applies the same normalization in Eq. (1).\n\n\nBasket-Sequence Correlation Networks\n\nIn this section, we propose Basket Sequence COrrelation Networks (Beacon) for correlation-sensitive next-basket recommendation, and discuss its learning strategy.\n\n\nProposed Framework: Beacon\n\nOur framework Beacon is outlined in Figure 2, which consists of three main components, namely, correlation-sensitive basket encoder, basket sequence encoder, and correlationsensitive predictor. Taking a basket sequence and correlation matrix as input, the basket encoder captures intra-basket item\n1 0 1 1 \" Correlation-Sensitive Basket Encoder \u2026 0 1 0 1 B \u2026 LSTM LSTM \u2026 \u2026 \u2113 (%) Sequence Encoder \" \u2113 (%) \" \u2113(% ) \u2113(%)\nBasket Sequence S\n\n\nCorrelation-Sensitive Score Predictor\n\nItem Scores (%)\n\nCorrelation Matrix correlations and produce correlation-sensitive basket representations. The sequence of basket representations is further fed into a sequence encoder to capture inter-basket sequential associations. The output from the sequence encoder, together with the correlation matrix, are employed by the predictor to produce the correlation-sensitive next basket. We further elaborate each component in the following.\n\n\nCorrelation-Sensitive Basket Encoder\n\nGiven a basket B t at time t, we can convert it to a binary vector x t \u2208 {0, 1} |V | , whereby its i-th element is zero if and only if i \u2208 B t . There are two primary factors that trigger the presence of an item in the basket B t , including not only the item's self-importance, but also its correlative associations with other items in B t . Simultaneously accounting for the two factors may enhance the representation of B t . Thus, we propose the following intermediate representation z t \u2208 R |V | for the basket B t :\nz t = x t \u2022 \u03c9 + x t C(2)\nwhere \u2022 denotes the Hadamard (i.e., element-wise) product, \u03c9 \u2208 R |V | entails the learnable item importance parameters and C is the input correlation matrix. Generally, not all correlative associations are useful-weak correlations are more likely to be noises that adversely impact the basket representation. Therefore, we introduce \u03b7 \u2208 R + , a learnable scalar parameter to filter out weak correlations, into the intermediate representation:\nz t = x t \u2022 \u03c9 + ReLU(x t C \u2212 \u03b71),(3)\nwhere 1 is a vector of ones and ReLU is applied in an element-wise manner. Subsequently, z t is fed into a fullyconnected layer to infer a latent L-dimension basket representation b t \u2208 R L , as follows:\nb t = ReLU(z t \u03a6 + \u03c6),(4)\nwhere \u03a6 \u2208 R |V |\u00d7L and \u03c6 \u2208 R L are weight and bias parameters to be learned, respectively.\n\n\nBasket Sequence Encoder\n\nThe sequence encoder employs a RNN to capture the sequential associations in basket sequences. Given a basket sequence S = B 1 , . . . , B (S) with corresponding latent basket representations b 1 , . . . , b (S) , the recurrent Hdimension hidden output h t \u2208 R H at time t is computed by:\nh t = tanh(b t \u03a8 + h t\u22121 \u03a8 + \u03c8)(5)\nwhere \u03a8 \u2208 R L\u00d7H , \u03a8 \u2208 R H\u00d7H and \u03c8 \u2208 R H are weight and bias parameters to be learnt. As shown in Figure 2, while Beacon adopts LSTM units [Le et al., 2018], it is flexible to plug in other recurrent units, e.g., GRU [Hidasi et al., 2016].\n\n\nCorrelation-Sensitive Score Predictor\n\nThe predictor aims to derive a score for each item based on both the inter-basket sequential associations and intra-basket correlation associations. Let h (S) be the last hidden output of sequence S via the sequence encoder. Thus, the sequential signal s (S) \u2208 R |V | for item recommendation given sequence S can be estimated by the following:\ns (S) = \u03c3(h (S) \u0393),(6)\nwhere \u03c3 is the sigmoid function applied in an element-wise manner, and \u0393 \u2208 R H\u00d7|V | is a weight matrix to be learned. In order to recommend a basket with correlated items, we further aggregate the sequential signal with item importance and correlative associations. Similar to Eq. (2), a straightforward solution is s (S) \u2022 \u03c9 + s (S) C. However, in this formulation, the intra-basket correlative association often dominates and masks the inter-basket sequential associations. Thus, we adopt the following predictor, such that the trade-off between correlative and sequential associations can be tuned:\ny (S) = \u03b1(s (S) \u2022 \u03c9 + s (S) C) + (1 \u2212 \u03b1)s (S) ,(7)\nwhere \u03b1 \u2208 [0, 1] is a hyperparameter to control the balance between correlative and sequential associations, and y (S) \u2208 R |V | contains the predicted scores such that its i-th element, y (S) i , indicates the score of item i. Next-Basket Recommendation. Given a test basket sequence S = B 1 , . . . , B (S) , we recommend the next basket B (S)+1 based on the predicted scores y (S) . The scores indicate how likely each item could form the next basket, accounting for both intra-basket correlative and inter-basket sequential associations. Since the size of the next basket is unknown and is often noncritical in a recommendation setting [Yu et al., 2016], in practice we form the next basket by taking K items with the highest scores in y (S) , where K is a small constant such as 5 or 10.\n\n\nLearning Strategy\n\nFor each training sequence S, we remove its last basket to obtain S = B 1 , . . . , B (S)\u22121 . The goal is to make sure that the predicted scores y (S ) based on S should align well with the ground truth next basket B (S) .\n\nTo this end, we favor the adopted items in the ground truth basket B (S) , and at the same time penalize other negative items in V \\ B (S) . In particular, we formulate the following  loss for sequence S, where we try to maximize the scores of the adopted items (first term), and minimize the scores of negative items with respect to the minimum score among adopted items (second term). Intuitively, the second term encourages the negative items to be ranked lower than all of the adopted items in y (S ) .\nL(S) = \u2212 1 |B (S) | i\u2208B (S) log \u03c3(y (S ) i ) (8) \u2212 1 |V \\ B (S) | j\u2208V \\B (S) log(1 \u2212 \u03c3(y (S ) j \u2212 y (S ) m )),\nwhere m = arg min i\u2208B (S) y (S ) i is the adopted item with minimum predicted score.\n\nGiven the set of training basket sequences S train , we seek to minimize the total loss to learn our parameter set \u0398 = (\u03c9, \u03b7, \u03a6, \u03c6, \u03a8, \u03a8 , \u03c8, \u0393):\n\u0398 * = arg min \u0398 S\u2208Strain L(S)(9)\nComplexity Analysis. According to Eq. (3) and Eq. (4), the complexity of the basket encoder is O(|V | 2 + |V | \u00b7 L). In the sequence encoder, the complexity of an LSTM unit is O(H 2 + H \u00b7 L) [Hochreiter and Schmidhuber, 1997]. Moreover, the correlation-sensitive predictor has the complexity O(|V | \u00b7 H + |V | 2 ). Thus, given a set of training sequences S train with an average sequence length ofS, and considering that H, L are generally much smaller than |V |, the overall complexity of Beacon on a training epoch can be simplified to O(|S train | \u00b7S \u00b7 |V | 2 ).\n\n\nExperiments\n\nWe investigate the efficacy of Beacon for the next-basket recommendation task, particularly through comparing with a series of classic and state-of-the-art baselines, and conducting both quantitative and qualitative analyses on our model.\n\n\nSetup\n\nDatasets. We conduct experiments on three publicly available real-life datasets of three different domains as follows.  Yuan et al., 2013]. We define a basket as the set of check-ins within the same day.\n\nPreprocessing. To cater sufficient information about each user and item for modeling, we ensure that each user adopts at least n items and each item is adopted by at least n users, with n being 10, 5, 5 for TaFeng, Delicious and Foursquare respectively. To get a sense of the extent of reduction, only 5.9% were removed out of a total of 817,741 adoptions in TaFeng. For Delicious, 11.8% out of 430,987 adoptions were removed. For Foursquare, 0.1% of 186,804 adoptions were removed. Additionally, we filter out basket sequences with fewer than 2 baskets. To create train/validation/test sets, sequences are chronologically split into three non-overlapping periods (t trainl , t val , t test ), i.e., (3, 0.5, 0.5) months for TaFeng, (80, 2, 2) months for Delicious and (10, 0.5, 0.5) months for Foursquare. For the train and validation sets, we generate all subsequences of the basket sequences with more than 3 baskets. Anything longer than 30 baskets is truncated with the prefix cut off. To facilitate new-item recommendations, as in [Rendle et al., 2010], we do not consider the item just adopted in the immediately preceding time step. The statistics after preprocessing are described in Table 2. Correlation Matrix. We construct the input correlation matrix according to Section 3.2. Based on the validation set, we choose the first-order correlation for Delicious and Foursquare whilst adopting the higher-order correlation for TaFeng with N = 5 and \u00b5 = 0.85. Evaluation Metrics. Given a test sequence S, we use the preceding baskets S = B 1 , . . . , B (S)\u22121 to predict the last basket at time (S). This prediction is then compared to the ground-truth basket B (S) on two well established metrics. One is F-measure (F1@K) [Yu et al., 2016], where K is the basket size to be predicted. The second metric, Half-life utility (HLU) a.k.a. \"Breese score\" [Breese et al., 1998]. For both metrics, performances are averaged across test baskets using 10 runs with different random initialization. Comparisons are supported by two-tailed paired-sample Student's ttest at 0.05 significance level. Learning Details. With the objective of minimizing the log loss in Eq. (9), our model is trained in 15 epochs of batchsize 32. We use the RMSProp optimizer with the learning rate 0.001. The LSTM layer is applied with a 0.3 dropout probability. \u03b7 is initialized by the mean of non-zero values in C. The model is further tuned on the validation set over the latent dimension L \u2208 {8, 16, 32, 64} and recurrent hidden unit H \u2208 {16, 32, 64} using a grid search. Lastly, we use \u03b1 = 0.5 as the default to control the trade-off between sequential or correlative associations. We will also vary \u03b1 and study its impact in Section 5.3. For our experiments on NVIDIA P100 GPU with 16GB memory, each mini-batch takes approximately 0.1 second.\n\n\nComparison to Baselines\n\nWe compare Beacon to a suite of classic and state-of-the-art baselines, as follows.  \u2022 POP ranks items based on their global popularity.\n\n\u2022 MC ranks items based on first-order Markov-chain transition probabilities from items in the previous basket. \u2022 MCN is similar to MC, but uses denser Markov-chain dependencies derived using neural networks. Yu et al., 2016] is a dynamic recurrent model, where a basket representation is aggregated by items' embedding via a pooling layer. The most recent basket representation is used to generate the next basket 4 . \u2022 BSEQ [Le et al., 2018] captures long-term dependencies.\n\u2022 DREAM [\nEach basket is encoded directly from a binary vector using a fully-connected layer. Next-basket predictions are based on the sequential signal at the last basket. \u2022 triple2vec [Wan et al., 2018] infers the embeddings of items and users from (user u, item i, item j) triplets, where i, j co-occur in the same basket. We use the author's implementation 5 with various initial loyalty values to derive sequence representations for a global user to focus the comparison on sequential effects.\n\nAll baselines, if applicable, are trained as well as tuned on the validation set in the same manner as Beacon outlined in Section 5.1.  \n\n\nQuantitative Model Analysis\n\nWe further analyze our model quantitatively in the context of two research questions listed below.\n\nAre item importance and correlation helpful? Our basket encoder accounts for two primary factors: item importance \u03c9 and correlation C, as shown in Eq.\n\n(3). To study the contribution of each factor, we compare two simpler variants with Beacon: (i) Beacon corr-, which ignores item correlation by setting C to a zero matrix; and (ii) Beacon corr-impt-, which ignores both item importance and correlation by further setting \u03c9 to a vector of one's. We report their results in Table 4. Specifically, the full model significantly outperforms Beacon corr-, demonstrating that item correlation plays a crucial role in next-basket recommendation. Likewise, Beacon corr-significantly beats Beacon corr-impt-to imply that item importance is another useful factor. In summary, our model benefits from both factors.\n\nWhat is the effect of hyper-parameter \u03b1? According to Eq. (7), \u03b1 tunes the relative weights of correlative and sequential associations. Higher \u03b1 emphasizes endogenous effects within baskets, while lower \u03b1 favors exogenous effects across baskets. In Figure 3, we plot the performance when varying \u03b1. There are some minor variations across datasets, but generally the range of \u03b1 \u2208 [0.2, 0.6] tends to do relatively well in most scenarios, indicating that some balance is useful.   \n\n\nQualitative Analysis\n\nFinally, we perform a qualitative analysis on Delicious, where the objective is to recommend a basket of tags for the next bookmark to visit. The other two datasets only contain item IDs and thus cannot be used for the qualitative study. In Table 5, Beacon is compared to the second best model MC and the popularity-based method POP, illustrating two examples of tag-basket prediction with respect to two bookmarks. POP keeps suggesting the same set of tags as it only leverages the global popularity, while MC recommends somehow general tags with limited relevance. In contrast, Beacon proposes more relevant baskets of correlated tags. The set of tags {web, programming, javascript, tools} are descriptive for jQuery, a Javascript library. Likewise, the second bookmark refers to a critical discussion on how to increase a site's revenue by maximizing user experience (i.e., ux) with an efficient design (e.g., propinquity between buttons and fields).\n\n\nConclusion\n\nIn this paper, we address the next-basket recommendation problem. Assuming baskets incorporate correlative dependencies among items, we propose Beacon that utilizes the correlation information to enhance the representation of individual baskets as well as the overall basket sequence. Experimental results on three public real-life datasets show the benefit of exploiting correlative dependencies.\n\nFigure 1 :\n1Motivating example for correlation-sensitive next-basket recommendation.\n\nFigure 2 :\n2Architecture of the proposed framework Beacon.\n\nFigure 3 :\n3Impact of \u03b1 on the performance of Beacon.\n\n\nor Euclidean embedding [Chen et al., 2012] techniques. Others model long-term dependencies using RNN [Hidasi et al., 2016; Li et al., 2017; Villatel et al., 2018], convolutional neural network or CNN [Tang and Wang, 2018], memory networks [Huang et al., 2018], translation-based method [He et al., 2017], or session graphs[Xiang et al., 2010;Wu et al., 2019;  Song et al., 2019]. These works are not comparable to ours, as they operate at item level and consider neither basket sequences nor next-basket recommendation.Symbol Description \nV \nthe set of items {1, 2, . . . , |V |} \nS \na temporal sequence of baskets B (S) \n1 , . . . , B (S) \n\n(S) \n\n\n\nTable 1 :\n1Summary of Main NotationsBasket Sequences. There have been efforts to model \nbasket-level adoptions for sequential recommendation, but in \ngeneral they do not incorporate item correlation information \nwithin their modeling nor prediction of baskets. For instance, \n[Yu et al., 2016] encodes each basket and learns the sequence \nrepresentation via a RNN-based approach. Later, [Bai et \nal., 2018] improves this approach by incorporating item at-\ntributes. In turn [Le et al., 2018] makes use of secondary \nsupporting sequences. To showcase the benefit of item corre-\nlation information, we will compare to [Yu et al., 2016] and \n[Le et al., 2018] (focusing on primary sequence) as baselines. \nThere are also personalized methods [Wang et al., 2015; \nYing et al., 2018; Wan et al., 2018]\n\nTable 2 :\n2Statistics for TaFeng, Delicious and Foursquare datasets\n\nTable 3 :\n3Performance comparison between Beacon versus baselines on TaFeng, Delicious and Foursquare. \u2020 represents statistically significant improvements of Beacon over the second best model.\n\nTable 3\n3shows the results in terms of F 1@5, F 1@10 and HLU. For TaFeng, popularity seems to be an important factor since POP performs better than MC, MCN, BSEQ and triple2vec. Beyond popularity, DREAM and Beacon showDataset \n\nModel \nF1@K (%) \nHLU \n@5 \n@10 \n\nTaFeng \n\nBeacon corr-impt-3.87 \n3.44 \n5.13 \nBeacon corr-\n5.78  \u2020 4.86  \u2020 7.18  \u2020 \nBeacon (full) \n6.36  \u00a7 5.26  \u00a7 7.83  \u00a7 \n\nDelicious \n\nBeacon corr-impt-4.02 \n4.43 \n6.38 \nBeacon corr-\n4.67  \u2020 5.10  \u2020 7.15  \u2020 \nBeacon (full) \n4.94  \u00a7 5.47  \u00a7 7.76  \u00a7 \n\nFoursquare \n\nBeacon corr-impt-2.98 \n3.29 \n5.39 \nBeacon corr-\n3.58  \u2020 3.52  \u2020 6.16  \u2020 \nBeacon (full) \n3.61 \n3.59  \u00a7 6.32  \u00a7 \n\n\n\nTable 4 :\n4Performance comparison between Beacon and its variants without item importance (impt) or correlation (corr). \u2020, \u00a7 represent statistically significant improvements from the previous row. advantages in capturing associations between basket items. Yet, Beacon is the best-performing model. For Delicious, Markov-based models (MC and MCN) do better than other baselines. It might imply that items in a testing basket are strongly dependent on the most recent basket. The modeling of basket-oriented associations in DREAM and triple2vec is not helpful to improve the performance. In contrast, Beacon shows a significant improvement over these models across the three measurements, which we attribute to the advantage of modeling correlations effectively. For Foursquare, we witness a similar observation as Delicious, where Beacon outperforms the baselines significantly.\n\nTable 5 :\n5Illustrations of tag basket prediction by Beacon, MC and POP on Delicious. Italics denote tags relevant to the bookmark.\nhttps://www.kaggle.com/chiranjivdas09/ ta-feng-grocery-dataset 2 https://grouplens.org/datasets/hetrec-2011\nhttps://github.com/LaceyChen17/DREAM 5 https://github.com/MengtingWan/grocery\nhttp://www.desarrolloweb.com/manuales/manual-jquery.html 7 https://articles.uie.com/three hund million button\nAcknowledgmentsThis research was supported by the Singapore Ministry of Education (MOE) Academic Research Fund (AcRF) Tier 1 grants (18-C220-SMU-004 and 18-C220-SMU-006).\nAn attribute-aware neural attentive model for next basket recommendation. [ References, Bai, Linas Baltrunas, and Domonkos Tikk. Sessionbased recommendations with recurrent neural networks. In ICLR. RecsysReferences [Bai et al., 2018] Ting Bai, Jian-Yun Nie, Wayne Xin Zhao, Yutao Zhu, Pan Du, and Ji-Rong Wen. An attribute-aware neural attentive model for next basket recommendation. In SIGIR, pages 1201-1204, 2018. [Breese et al., 1998] John S Breese, David Heckerman, and Carl Kadie. Empirical analysis of predictive algorithms for collaborative filtering. In UAI, pages 43-52, 1998. [Chen et al., 2012] Shuo Chen, Josh L Moore, Douglas Turnbull, and Thorsten Joachims. Playlist prediction via metric embedding. In KDD, pages 714-722, 2012. [Christakopoulou and Karypis, 2014] Evangelia Chris- takopoulou and George Karypis. Hoslim: Higher-order sparse linear method for top-n recommender systems. In PAKDD, pages 38-49, 2014. [He et al., 2017] Ruining He, Wang-Cheng Kang, and Julian McAuley. Translation-based recommendation. In Recsys, pages 161-169, 2017. [Hidasi et al., 2016] Bal\u00e1zs Hidasi, Alexandros Karat- zoglou, Linas Baltrunas, and Domonkos Tikk. Session- based recommendations with recurrent neural networks. In ICLR, 2016.\n\nImproving sequential recommendation with knowledge-enhanced memory networks. Sepp Hochreiter, J\u00fcrgen Schmidhuber, ; Huang, SIGIR. 9ICLRand Schmidhuber, 1997] Sepp Hochreiter and J\u00fcrgen Schmidhuber. Long short-term memory. Neural computation, 9(8):1735-1780, 1997. [Huang et al., 2018] Jin Huang, Wayne Xin Zhao, Hong- Jian Dou, Ji-Rong Wen, and Edward Y. Chang. Improv- ing sequential recommendation with knowledge-enhanced memory networks. In SIGIR, pages 505-514, 2018. [Kipf and Welling, 2017] Thomas N Kipf and Max Welling. Semi-supervised classification with graph convolutional networks. In ICLR, 2017.\n\nBasket-sensitive personalized item recommendation. IJCAI. et al., 2017] Duc Trong Le, Hady W Lauw, and Yuan Fang. Basket-sensitive personalized item recommenda- tion. In IJCAI, pages 2060-2066, 2017.\n\nModeling contemporaneous basket sequences with twin networks for next-item recommendation. IJ-CAI. et al., 2018] Duc Trong Le, Hady Wirawan Lauw, and Yuan Fang. Modeling contemporaneous basket sequences with twin networks for next-item recommendation. In IJ- CAI, pages 3414-3420, 2018.\n\nGrocery shopping recommendations based on basket-sensitive random walk. CIKM. KDDet al., 2009] Ming Li, Benjamin M Dias, Ian Jarman, Wael El-Deredy, and Paulo JG Lisboa. Grocery shopping recommendations based on basket-sensitive random walk. In KDD, pages 1215-1224, 2009. [Li et al., 2017] Jing Li, Pengjie Ren, Zhumin Chen, Zhaochun Ren, Tao Lian, and Jun Ma. Neural attentive session-based recommendation. In CIKM, pages 1419- 1428, 2017.\n\nMassimo Quadrana, Paolo Cremonesi, and Dietmar Jannach. Sequence-aware recommender systems. Karypis ; Xia Ning, George Karypis, ; Pathak, SIGIR. 5166Generating and personalizing bundle recommendations on steamand Karypis, 2011] Xia Ning and George Karypis. Slim: Sparse linear methods for top-n recommender sys- tems. In ICDM, pages 497-506, 2011. [Pathak et al., 2017] Apurva Pathak, Kshitiz Gupta, and Ju- lian McAuley. Generating and personalizing bundle rec- ommendations on steam. In SIGIR, pages 1073-1076, 2017. [Quadrana et al., 2018] Massimo Quadrana, Paolo Cre- monesi, and Dietmar Jannach. Sequence-aware rec- ommender systems. ACM Computing Surveys (CSUR), 51(4):66, 2018.\n\nSession-based social recommendation via dynamic graph a ention networks. Rendle, WSDM. Weiping SongWWWRendle et al., 2010] Steffen Rendle, Christoph Freuden- thaler, and Lars Schmidt-Thieme. Factorizing personal- ized markov chains for next-basket recommendation. In WWW, pages 811-820, 2010. [Sarwar et al., 2000] Badrul Sarwar, George Karypis, Joseph Konstan, and John Riedl. Analysis of recommendation algorithms for e-commerce. In EC, pages 158-167, 2000. [Song et al., 2019] Weiping Song, Zhiping Xiao, Yifan Wang, Laurent Charlin, Ming Zhang, and Jian Tang. Session-based social recommendation via dynamic graph a ention networks. In WSDM, 2019.\n\nKiewan Villatel, Elena Smirnova, J\u00e9r\u00e9mie Mary, and Philippe Preux. Recurrent neural networks for long and short-term sequential recommendation. Wang ; Jiaxi Tang, Ke Wang, ; Villatel, Recsys. WSDMand Wang, 2018] Jiaxi Tang and Ke Wang. Person- alized top-n sequential recommendation via convolutional sequence embedding. In WSDM, pages 565-573, 2018. [Villatel et al., 2018] Kiewan Villatel, Elena Smirnova, J\u00e9r\u00e9mie Mary, and Philippe Preux. Recurrent neural net- works for long and short-term sequential recommendation. In Recsys, 2018.\n\nRepresenting and recommending shopping baskets with complementarity, compatibility and loyalty. Aixin Sun, and Nadia Magnenat Thalmann. Time-aware point-of-interest recommendation. Ying, Fuzhen Zhuang, Fuzheng Zhang, Yanchi Liu, Guandong Xu, Xing Xie, Hui Xiong, and Jian WuGao Cong, Zongyang MaQuan YuanSIGIRet al., 2018] Mengting Wan, Di Wang, Jie Liu, Paul Bennett, and Julian McAuley. Representing and recom- mending shopping baskets with complementarity, compat- ibility and loyalty. In CIKM, pages 1133-1142, 2018. [Wang et al., 2015] Pengfei Wang, Jiafeng Guo, Yanyan Lan, Jun Xu, Shengxian Wan, and Xueqi Cheng. Learn- ing hierarchical representation model for nextbasket rec- ommendation. In SIGIR, pages 403-412, 2015. [Wang et al., 2018] Shoujin Wang, Liang Hu, Longbing Cao, Xiaoshui Huang, Defu Lian, and Wei Liu. Attention- based transactional context embedding for next-item rec- ommendation. In AAAI, 2018. [Wu et al., 2019] Shu Wu, Yuyuan Tang, Yanqiao Zhu, Liang Wang, Xing Xie, and Tieniu Tan. Session-based recommendation with graph neural networks. In AAAI, 2019. [Xiang et al., 2010] Liang Xiang, Quan Yuan, Shiwan Zhao, Li Chen, Xiatian Zhang, Qing Yang, and Jimeng Sun. Temporal recommendation on graphs via long-and short- term preference fusion. In KDD, pages 723-732, 2010. [Ying et al., 2018] Haochao Ying, Fuzhen Zhuang, Fuzheng Zhang, Yanchi Liu, Guandong Xu, Xing Xie, Hui Xiong, and Jian Wu. Sequential recommender system based on hi- erarchical attention networks. In IJCAI, pages 3926-3932, 2018. [Yu et al., 2016] Feng Yu, Qiang Liu, Shu Wu, Liang Wang, and Tieniu Tan. A dynamic recurrent model for next basket recommendation. In SIGIR, pages 729-732, 2016. [Yuan et al., 2013] Quan Yuan, Gao Cong, Zongyang Ma, Aixin Sun, and Nadia Magnenat Thalmann. Time-aware point-of-interest recommendation. In SIGIR, pages 363- 372, 2013.\n", "annotations": {"author": "[{\"end\":145,\"start\":135},{\"end\":150,\"start\":146},{\"end\":164,\"start\":151},{\"end\":170,\"start\":165},{\"end\":198,\"start\":171},{\"end\":246,\"start\":199},{\"end\":280,\"start\":247},{\"end\":291,\"start\":281},{\"end\":600,\"start\":292},{\"end\":634,\"start\":601},{\"end\":145,\"start\":135},{\"end\":150,\"start\":146},{\"end\":164,\"start\":151},{\"end\":170,\"start\":165},{\"end\":198,\"start\":171},{\"end\":246,\"start\":199},{\"end\":280,\"start\":247},{\"end\":291,\"start\":281},{\"end\":600,\"start\":292},{\"end\":634,\"start\":601}]", "publisher": null, "author_last_name": "[{\"end\":144,\"start\":139},{\"end\":163,\"start\":159},{\"end\":169,\"start\":165},{\"end\":180,\"start\":176},{\"end\":211,\"start\":209},{\"end\":258,\"start\":254},{\"end\":290,\"start\":286},{\"end\":144,\"start\":139},{\"end\":163,\"start\":159},{\"end\":169,\"start\":165},{\"end\":180,\"start\":176},{\"end\":211,\"start\":209},{\"end\":258,\"start\":254},{\"end\":290,\"start\":286}]", "author_first_name": "[{\"end\":138,\"start\":135},{\"end\":147,\"start\":146},{\"end\":149,\"start\":148},{\"end\":158,\"start\":151},{\"end\":175,\"start\":171},{\"end\":208,\"start\":199},{\"end\":251,\"start\":247},{\"end\":253,\"start\":252},{\"end\":285,\"start\":281},{\"end\":138,\"start\":135},{\"end\":147,\"start\":146},{\"end\":149,\"start\":148},{\"end\":158,\"start\":151},{\"end\":175,\"start\":171},{\"end\":208,\"start\":199},{\"end\":251,\"start\":247},{\"end\":253,\"start\":252},{\"end\":285,\"start\":281}]", "author_affiliation": "[{\"end\":599,\"start\":293},{\"end\":633,\"start\":602},{\"end\":599,\"start\":293},{\"end\":633,\"start\":602}]", "title": "[{\"end\":98,\"start\":1},{\"end\":732,\"start\":635},{\"end\":98,\"start\":1},{\"end\":732,\"start\":635}]", "venue": "[{\"end\":815,\"start\":734},{\"end\":815,\"start\":734}]", "abstract": "[{\"end\":2346,\"start\":1198},{\"end\":2346,\"start\":1198}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b5\"},\"end\":2992,\"start\":2969},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":4903,\"start\":4882},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":4921,\"start\":4903},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":4938,\"start\":4921},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":5249,\"start\":5232},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":7870,\"start\":7849},{\"end\":8223,\"start\":8220},{\"end\":8264,\"start\":8261},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":8491,\"start\":8473},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":8699,\"start\":8678},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":8750,\"start\":8729},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":8795,\"start\":8778},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":8909,\"start\":8892},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":9095,\"start\":9071},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":15078,\"start\":15061},{\"end\":15160,\"start\":15135},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":16879,\"start\":16862},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":18367,\"start\":18334},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":19110,\"start\":19092},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":20235,\"start\":20214},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":20924,\"start\":20907},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":21055,\"start\":21035},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":22391,\"start\":22375},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":22609,\"start\":22592},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":22847,\"start\":22829},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":26631,\"start\":26611},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":26647,\"start\":26631},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":2992,\"start\":2969},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":4903,\"start\":4882},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":4921,\"start\":4903},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":4938,\"start\":4921},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":5249,\"start\":5232},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":7870,\"start\":7849},{\"end\":8223,\"start\":8220},{\"end\":8264,\"start\":8261},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":8491,\"start\":8473},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":8699,\"start\":8678},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":8750,\"start\":8729},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":8795,\"start\":8778},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":8909,\"start\":8892},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":9095,\"start\":9071},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":15078,\"start\":15061},{\"end\":15160,\"start\":15135},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":16879,\"start\":16862},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":18367,\"start\":18334},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":19110,\"start\":19092},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":20235,\"start\":20214},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":20924,\"start\":20907},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":21055,\"start\":21035},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":22391,\"start\":22375},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":22609,\"start\":22592},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":22847,\"start\":22829},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":26631,\"start\":26611},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":26647,\"start\":26631}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":26171,\"start\":26086},{\"attributes\":{\"id\":\"fig_1\"},\"end\":26231,\"start\":26172},{\"attributes\":{\"id\":\"fig_2\"},\"end\":26286,\"start\":26232},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":26937,\"start\":26287},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":27735,\"start\":26938},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":27804,\"start\":27736},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":27998,\"start\":27805},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":28634,\"start\":27999},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":29513,\"start\":28635},{\"attributes\":{\"id\":\"tab_10\",\"type\":\"table\"},\"end\":29646,\"start\":29514},{\"attributes\":{\"id\":\"fig_0\"},\"end\":26171,\"start\":26086},{\"attributes\":{\"id\":\"fig_1\"},\"end\":26231,\"start\":26172},{\"attributes\":{\"id\":\"fig_2\"},\"end\":26286,\"start\":26232},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":26937,\"start\":26287},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":27735,\"start\":26938},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":27804,\"start\":27736},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":27998,\"start\":27805},{\"attributes\":{\"id\":\"tab_7\",\"type\":\"table\"},\"end\":28634,\"start\":27999},{\"attributes\":{\"id\":\"tab_8\",\"type\":\"table\"},\"end\":29513,\"start\":28635},{\"attributes\":{\"id\":\"tab_10\",\"type\":\"table\"},\"end\":29646,\"start\":29514}]", "paragraph": "[{\"end\":2917,\"start\":2362},{\"end\":4010,\"start\":2919},{\"end\":4728,\"start\":4012},{\"end\":5497,\"start\":4730},{\"end\":7524,\"start\":5499},{\"end\":8560,\"start\":7541},{\"end\":9240,\"start\":8562},{\"end\":9436,\"start\":9258},{\"end\":9631,\"start\":9458},{\"end\":10417,\"start\":9709},{\"end\":10647,\"start\":10419},{\"end\":11000,\"start\":10649},{\"end\":11551,\"start\":11023},{\"end\":12030,\"start\":11579},{\"end\":12233,\"start\":12071},{\"end\":12561,\"start\":12264},{\"end\":12698,\"start\":12681},{\"end\":12755,\"start\":12740},{\"end\":13183,\"start\":12757},{\"end\":13745,\"start\":13224},{\"end\":14213,\"start\":13771},{\"end\":14454,\"start\":14251},{\"end\":14571,\"start\":14481},{\"end\":14887,\"start\":14599},{\"end\":15161,\"start\":14923},{\"end\":15546,\"start\":15203},{\"end\":16171,\"start\":15570},{\"end\":17014,\"start\":16223},{\"end\":17258,\"start\":17036},{\"end\":17766,\"start\":17260},{\"end\":17962,\"start\":17878},{\"end\":18109,\"start\":17964},{\"end\":18708,\"start\":18143},{\"end\":18962,\"start\":18724},{\"end\":19175,\"start\":18972},{\"end\":22001,\"start\":19177},{\"end\":22165,\"start\":22029},{\"end\":22642,\"start\":22167},{\"end\":23141,\"start\":22653},{\"end\":23279,\"start\":23143},{\"end\":23409,\"start\":23311},{\"end\":23561,\"start\":23411},{\"end\":24214,\"start\":23563},{\"end\":24695,\"start\":24216},{\"end\":25673,\"start\":24720},{\"end\":26085,\"start\":25688},{\"end\":2917,\"start\":2362},{\"end\":4010,\"start\":2919},{\"end\":4728,\"start\":4012},{\"end\":5497,\"start\":4730},{\"end\":7524,\"start\":5499},{\"end\":8560,\"start\":7541},{\"end\":9240,\"start\":8562},{\"end\":9436,\"start\":9258},{\"end\":9631,\"start\":9458},{\"end\":10417,\"start\":9709},{\"end\":10647,\"start\":10419},{\"end\":11000,\"start\":10649},{\"end\":11551,\"start\":11023},{\"end\":12030,\"start\":11579},{\"end\":12233,\"start\":12071},{\"end\":12561,\"start\":12264},{\"end\":12698,\"start\":12681},{\"end\":12755,\"start\":12740},{\"end\":13183,\"start\":12757},{\"end\":13745,\"start\":13224},{\"end\":14213,\"start\":13771},{\"end\":14454,\"start\":14251},{\"end\":14571,\"start\":14481},{\"end\":14887,\"start\":14599},{\"end\":15161,\"start\":14923},{\"end\":15546,\"start\":15203},{\"end\":16171,\"start\":15570},{\"end\":17014,\"start\":16223},{\"end\":17258,\"start\":17036},{\"end\":17766,\"start\":17260},{\"end\":17962,\"start\":17878},{\"end\":18109,\"start\":17964},{\"end\":18708,\"start\":18143},{\"end\":18962,\"start\":18724},{\"end\":19175,\"start\":18972},{\"end\":22001,\"start\":19177},{\"end\":22165,\"start\":22029},{\"end\":22642,\"start\":22167},{\"end\":23141,\"start\":22653},{\"end\":23279,\"start\":23143},{\"end\":23409,\"start\":23311},{\"end\":23561,\"start\":23411},{\"end\":24214,\"start\":23563},{\"end\":24695,\"start\":24216},{\"end\":25673,\"start\":24720},{\"end\":26085,\"start\":25688}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":9708,\"start\":9632},{\"attributes\":{\"id\":\"formula_1\"},\"end\":11578,\"start\":11552},{\"attributes\":{\"id\":\"formula_2\"},\"end\":12680,\"start\":12562},{\"attributes\":{\"id\":\"formula_3\"},\"end\":13770,\"start\":13746},{\"attributes\":{\"id\":\"formula_4\"},\"end\":14250,\"start\":14214},{\"attributes\":{\"id\":\"formula_5\"},\"end\":14480,\"start\":14455},{\"attributes\":{\"id\":\"formula_6\"},\"end\":14922,\"start\":14888},{\"attributes\":{\"id\":\"formula_7\"},\"end\":15569,\"start\":15547},{\"attributes\":{\"id\":\"formula_8\"},\"end\":16222,\"start\":16172},{\"attributes\":{\"id\":\"formula_9\"},\"end\":17877,\"start\":17767},{\"attributes\":{\"id\":\"formula_10\"},\"end\":18142,\"start\":18110},{\"attributes\":{\"id\":\"formula_11\"},\"end\":22652,\"start\":22643},{\"attributes\":{\"id\":\"formula_0\"},\"end\":9708,\"start\":9632},{\"attributes\":{\"id\":\"formula_1\"},\"end\":11578,\"start\":11552},{\"attributes\":{\"id\":\"formula_2\"},\"end\":12680,\"start\":12562},{\"attributes\":{\"id\":\"formula_3\"},\"end\":13770,\"start\":13746},{\"attributes\":{\"id\":\"formula_4\"},\"end\":14250,\"start\":14214},{\"attributes\":{\"id\":\"formula_5\"},\"end\":14480,\"start\":14455},{\"attributes\":{\"id\":\"formula_6\"},\"end\":14922,\"start\":14888},{\"attributes\":{\"id\":\"formula_7\"},\"end\":15569,\"start\":15547},{\"attributes\":{\"id\":\"formula_8\"},\"end\":16222,\"start\":16172},{\"attributes\":{\"id\":\"formula_9\"},\"end\":17877,\"start\":17767},{\"attributes\":{\"id\":\"formula_10\"},\"end\":18142,\"start\":18110},{\"attributes\":{\"id\":\"formula_11\"},\"end\":22652,\"start\":22643}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":9395,\"start\":9388},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":20377,\"start\":20370},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":23891,\"start\":23884},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":9395,\"start\":9388},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":20377,\"start\":20370},{\"attributes\":{\"ref_id\":\"tab_8\"},\"end\":23891,\"start\":23884}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":2360,\"start\":2348},{\"attributes\":{\"n\":\"2\"},\"end\":7539,\"start\":7527},{\"attributes\":{\"n\":\"3\"},\"end\":9256,\"start\":9243},{\"attributes\":{\"n\":\"3.1\"},\"end\":9456,\"start\":9439},{\"attributes\":{\"n\":\"3.2\"},\"end\":11021,\"start\":11003},{\"attributes\":{\"n\":\"4\"},\"end\":12069,\"start\":12033},{\"attributes\":{\"n\":\"4.1\"},\"end\":12262,\"start\":12236},{\"end\":12738,\"start\":12701},{\"end\":13222,\"start\":13186},{\"end\":14597,\"start\":14574},{\"end\":15201,\"start\":15164},{\"attributes\":{\"n\":\"4.2\"},\"end\":17034,\"start\":17017},{\"attributes\":{\"n\":\"5\"},\"end\":18722,\"start\":18711},{\"attributes\":{\"n\":\"5.1\"},\"end\":18970,\"start\":18965},{\"attributes\":{\"n\":\"5.2\"},\"end\":22027,\"start\":22004},{\"attributes\":{\"n\":\"5.3\"},\"end\":23309,\"start\":23282},{\"attributes\":{\"n\":\"5.4\"},\"end\":24718,\"start\":24698},{\"attributes\":{\"n\":\"6\"},\"end\":25686,\"start\":25676},{\"end\":26097,\"start\":26087},{\"end\":26183,\"start\":26173},{\"end\":26243,\"start\":26233},{\"end\":26948,\"start\":26939},{\"end\":27746,\"start\":27737},{\"end\":27815,\"start\":27806},{\"end\":28007,\"start\":28000},{\"end\":28645,\"start\":28636},{\"end\":29524,\"start\":29515},{\"attributes\":{\"n\":\"1\"},\"end\":2360,\"start\":2348},{\"attributes\":{\"n\":\"2\"},\"end\":7539,\"start\":7527},{\"attributes\":{\"n\":\"3\"},\"end\":9256,\"start\":9243},{\"attributes\":{\"n\":\"3.1\"},\"end\":9456,\"start\":9439},{\"attributes\":{\"n\":\"3.2\"},\"end\":11021,\"start\":11003},{\"attributes\":{\"n\":\"4\"},\"end\":12069,\"start\":12033},{\"attributes\":{\"n\":\"4.1\"},\"end\":12262,\"start\":12236},{\"end\":12738,\"start\":12701},{\"end\":13222,\"start\":13186},{\"end\":14597,\"start\":14574},{\"end\":15201,\"start\":15164},{\"attributes\":{\"n\":\"4.2\"},\"end\":17034,\"start\":17017},{\"attributes\":{\"n\":\"5\"},\"end\":18722,\"start\":18711},{\"attributes\":{\"n\":\"5.1\"},\"end\":18970,\"start\":18965},{\"attributes\":{\"n\":\"5.2\"},\"end\":22027,\"start\":22004},{\"attributes\":{\"n\":\"5.3\"},\"end\":23309,\"start\":23282},{\"attributes\":{\"n\":\"5.4\"},\"end\":24718,\"start\":24698},{\"attributes\":{\"n\":\"6\"},\"end\":25686,\"start\":25676},{\"end\":26097,\"start\":26087},{\"end\":26183,\"start\":26173},{\"end\":26243,\"start\":26233},{\"end\":26948,\"start\":26939},{\"end\":27746,\"start\":27737},{\"end\":27815,\"start\":27806},{\"end\":28007,\"start\":28000},{\"end\":28645,\"start\":28636},{\"end\":29524,\"start\":29515}]", "table": "[{\"end\":26937,\"start\":26808},{\"end\":27735,\"start\":26975},{\"end\":28634,\"start\":28218},{\"end\":26937,\"start\":26808},{\"end\":27735,\"start\":26975},{\"end\":28634,\"start\":28218}]", "figure_caption": "[{\"end\":26171,\"start\":26099},{\"end\":26231,\"start\":26185},{\"end\":26286,\"start\":26245},{\"end\":26808,\"start\":26289},{\"end\":26975,\"start\":26950},{\"end\":27804,\"start\":27748},{\"end\":27998,\"start\":27817},{\"end\":28218,\"start\":28009},{\"end\":29513,\"start\":28647},{\"end\":29646,\"start\":29526},{\"end\":26171,\"start\":26099},{\"end\":26231,\"start\":26185},{\"end\":26286,\"start\":26245},{\"end\":26808,\"start\":26289},{\"end\":26975,\"start\":26950},{\"end\":27804,\"start\":27748},{\"end\":27998,\"start\":27817},{\"end\":28218,\"start\":28009},{\"end\":29513,\"start\":28647},{\"end\":29646,\"start\":29526}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":4233,\"start\":4225},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":4680,\"start\":4672},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":5835,\"start\":5827},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":12308,\"start\":12300},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":15028,\"start\":15020},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":24473,\"start\":24465},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":4233,\"start\":4225},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":4680,\"start\":4672},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":5835,\"start\":5827},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":12308,\"start\":12300},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":15028,\"start\":15020},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":24473,\"start\":24465}]", "bib_author_first_name": "[{\"end\":30189,\"start\":30188},{\"end\":31437,\"start\":31433},{\"end\":31456,\"start\":31450},{\"end\":31471,\"start\":31470},{\"end\":33003,\"start\":32990},{\"end\":33016,\"start\":33010},{\"end\":33027,\"start\":33026},{\"end\":34393,\"start\":34381},{\"end\":34402,\"start\":34400},{\"end\":34410,\"start\":34409},{\"end\":30189,\"start\":30188},{\"end\":31437,\"start\":31433},{\"end\":31456,\"start\":31450},{\"end\":31471,\"start\":31470},{\"end\":33003,\"start\":32990},{\"end\":33016,\"start\":33010},{\"end\":33027,\"start\":33026},{\"end\":34393,\"start\":34381},{\"end\":34402,\"start\":34400},{\"end\":34410,\"start\":34409}]", "bib_author_last_name": "[{\"end\":30200,\"start\":30190},{\"end\":30205,\"start\":30202},{\"end\":31448,\"start\":31438},{\"end\":31468,\"start\":31457},{\"end\":31477,\"start\":31472},{\"end\":33008,\"start\":33004},{\"end\":33024,\"start\":33017},{\"end\":33034,\"start\":33028},{\"end\":33663,\"start\":33657},{\"end\":34398,\"start\":34394},{\"end\":34407,\"start\":34403},{\"end\":34419,\"start\":34411},{\"end\":30200,\"start\":30190},{\"end\":30205,\"start\":30202},{\"end\":31448,\"start\":31438},{\"end\":31468,\"start\":31457},{\"end\":31477,\"start\":31472},{\"end\":33008,\"start\":33004},{\"end\":33024,\"start\":33017},{\"end\":33034,\"start\":33028},{\"end\":33663,\"start\":33657},{\"end\":34398,\"start\":34394},{\"end\":34407,\"start\":34403},{\"end\":34419,\"start\":34411}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":49648997},\"end\":31354,\"start\":30114},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":49644765},\"end\":31964,\"start\":31356},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":5414947},\"end\":32165,\"start\":31966},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":51609715},\"end\":32453,\"start\":32167},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":3037243},\"end\":32896,\"start\":32455},{\"attributes\":{\"id\":\"b5\"},\"end\":33582,\"start\":32898},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":59528321},\"end\":34235,\"start\":33584},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":50773944},\"end\":34774,\"start\":34237},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":53036978},\"end\":36640,\"start\":34776},{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":49648997},\"end\":31354,\"start\":30114},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":49644765},\"end\":31964,\"start\":31356},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":5414947},\"end\":32165,\"start\":31966},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":51609715},\"end\":32453,\"start\":32167},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":3037243},\"end\":32896,\"start\":32455},{\"attributes\":{\"id\":\"b5\"},\"end\":33582,\"start\":32898},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":59528321},\"end\":34235,\"start\":33584},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":50773944},\"end\":34774,\"start\":34237},{\"attributes\":{\"id\":\"b8\",\"matched_paper_id\":53036978},\"end\":36640,\"start\":34776}]", "bib_title": "[{\"end\":30186,\"start\":30114},{\"end\":31431,\"start\":31356},{\"end\":32015,\"start\":31966},{\"end\":32256,\"start\":32167},{\"end\":32525,\"start\":32455},{\"end\":32988,\"start\":32898},{\"end\":33655,\"start\":33584},{\"end\":34379,\"start\":34237},{\"end\":34870,\"start\":34776},{\"end\":30186,\"start\":30114},{\"end\":31431,\"start\":31356},{\"end\":32015,\"start\":31966},{\"end\":32256,\"start\":32167},{\"end\":32525,\"start\":32455},{\"end\":32988,\"start\":32898},{\"end\":33655,\"start\":33584},{\"end\":34379,\"start\":34237},{\"end\":34870,\"start\":34776}]", "bib_author": "[{\"end\":30202,\"start\":30188},{\"end\":30207,\"start\":30202},{\"end\":31450,\"start\":31433},{\"end\":31470,\"start\":31450},{\"end\":31479,\"start\":31470},{\"end\":33010,\"start\":32990},{\"end\":33026,\"start\":33010},{\"end\":33036,\"start\":33026},{\"end\":33665,\"start\":33657},{\"end\":34400,\"start\":34381},{\"end\":34409,\"start\":34400},{\"end\":34421,\"start\":34409},{\"end\":30202,\"start\":30188},{\"end\":30207,\"start\":30202},{\"end\":31450,\"start\":31433},{\"end\":31470,\"start\":31450},{\"end\":31479,\"start\":31470},{\"end\":33010,\"start\":32990},{\"end\":33026,\"start\":33010},{\"end\":33036,\"start\":33026},{\"end\":33665,\"start\":33657},{\"end\":34400,\"start\":34381},{\"end\":34409,\"start\":34400},{\"end\":34421,\"start\":34409}]", "bib_venue": "[{\"end\":35071,\"start\":35050},{\"end\":35071,\"start\":35050},{\"end\":30311,\"start\":30207},{\"end\":31484,\"start\":31479},{\"end\":32022,\"start\":32017},{\"end\":32264,\"start\":32258},{\"end\":32531,\"start\":32527},{\"end\":33041,\"start\":33036},{\"end\":33669,\"start\":33665},{\"end\":34427,\"start\":34421},{\"end\":34955,\"start\":34872},{\"end\":30311,\"start\":30207},{\"end\":31484,\"start\":31479},{\"end\":32022,\"start\":32017},{\"end\":32264,\"start\":32258},{\"end\":32531,\"start\":32527},{\"end\":33041,\"start\":33036},{\"end\":33669,\"start\":33665},{\"end\":34427,\"start\":34421},{\"end\":34955,\"start\":34872}]"}}}, "year": 2023, "month": 12, "day": 17}