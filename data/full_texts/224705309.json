{"id": 224705309, "updated": "2023-10-06 10:25:34.359", "metadata": {"title": "DIFER: Differentiable Automated Feature Engineering", "authors": "[{\"first\":\"Guanghui\",\"last\":\"Zhu\",\"middle\":[]},{\"first\":\"Zhuoer\",\"last\":\"Xu\",\"middle\":[]},{\"first\":\"Xu\",\"last\":\"Guo\",\"middle\":[]},{\"first\":\"Chunfeng\",\"last\":\"Yuan\",\"middle\":[]},{\"first\":\"Yihua\",\"last\":\"Huang\",\"middle\":[]}]", "venue": "ArXiv", "journal": "ArXiv", "publication_date": {"year": 2020, "month": null, "day": null}, "abstract": "Feature engineering, a crucial step of machine learning, aims to extract useful features from raw data to improve data quality. In recent years, great efforts have been devoted to Automated Feature Engineering (AutoFE) to replace expensive human labor. However, existing methods are computationally demanding due to treating AutoFE as a coarse-grained black-box optimization problem over a discrete space. In this work, we propose an efficient gradient-based method called DIFER to perform differentiable automated feature engineering in a continuous vector space. DIFER selects potential features based on evolutionary algorithm and leverages an encoder-predictor-decoder controller to optimize existing features. We map features into the continuous vector space via the encoder, optimize the embedding along the gradient direction induced by the predicted score, and recover better features from the optimized embedding by the decoder. Extensive experiments on classification and regression datasets demonstrate that DIFER can significantly improve the performance of various machine learning algorithms and outperform current state-of-the-art AutoFE methods in terms of both efficiency and performance.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": "2010.08784", "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/automl/ZhuXYH22", "doi": null}}, "content": {"source": {"pdf_hash": "9f523b5b5f25b41f2c0812a09f190413efb67d24", "pdf_src": "Arxiv", "pdf_uri": "[\"https://export.arxiv.org/pdf/2010.08784v3.pdf\"]", "oa_url_match": false, "oa_info": null}, "grobid": {"id": "f85b19040443083940e1b9f3d23c7a8ae4cd2da2", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/9f523b5b5f25b41f2c0812a09f190413efb67d24.txt", "contents": "\nDIFER: Di erentiable Automated Feature Engineering\n\n\nGuanghui Zhu \nState Key Laboratory for Novel Software Technology\nNanjing University\n\n\nZhuoer Xu \nState Key Laboratory for Novel Software Technology\nNanjing University\n\n\nChunfeng Yuan \nState Key Laboratory for Novel Software Technology\nNanjing University\n\n\nYihua Huang \nState Key Laboratory for Novel Software Technology\nNanjing University\n\n\nDIFER: Di erentiable Automated Feature Engineering\n\nFeature engineering, a crucial step of machine learning, aims to construct useful features from raw data to improve model performance. In recent years, great e orts have been devoted to Automated Feature Engineering (AutoFE) to replace expensive human labor. However, all existing methods treat AutoFE as an optimization problem over a discrete feature space, leading to the problems of feature explosion and computational ine ciency. Unlike previous work, we perform AutoFE in a continuous vector space and propose a di erentiable method called DIFER in this paper. Speci cally, we rst propose an evolutionary framework to search for better features iteratively. In each feature evolution step, we introduce a feature optimizer based on the encoder-predictor-decoder, which maps features into the continuous vector space via the encoder, optimizes the embedding along the gradient direction induced by the predictor, and recovers better features from the optimized embedding by the decoder. Extensive experiments on classi cation and regression datasets demonstrate that DIFER can signi cantly outperform the state-of-the-art AutoFE method in terms of both model performance and computational e ciency. The implementation of DIFER is avaialable on https://github.com/PasaLab/DIFER.\n\nIntroduction\n\nFeature engineering, the process of constructing features from raw data, directly determines the upper bound of various machine learning algorithms (e.g., Random Forest and Logistic Regression). However, it requires considerable domain knowledge to construct features. Also, huge computational resources are needed to evaluate and then lter features. Thus, it is a cost-intensive task to nd useful and meaningful features. Recently, the AutoFE (Automated Feature Engineering) methods that search for useful features without any human intervention have received more and more attention. AutoFE formalizes feature construction as applying transformations (e.g., arithmetic operators) to the raw features. The expansion-reduction algorithm (Kanter and Veeramachaneni, 2015;Lam et al., 2017) iteratively applies all transformations to each feature and selects the features based on the model performance. Without expert guidance, such method consumes signi cant computational resources for feature evaluation due to the exponentially growing feature space. To reduce the cost, learning-based AutoFE methods are proposed. TransGraph (Khurana et al., 2018) trains a Q-learning agent to decide the transformation. Due to applying each action (i.e., transformation) to all features, TransGraph also su ers from the feature explosion problem. LFE (Nargesian et al., 2017) trains an MLP (Multi-Layer Perceptron) to recommend the most likely useful transformation for each feature. However, it does not support the composition of transformations. NFS (Chen et al., 2019) generates a feature transformation sequence for each raw feature under the guidance of an RNN controller. Although NFS can achieve SOTA (state-of-the-art) performance, the computational e ciency is still low. An inherent cause of ine ciency for the existing approaches is the fact that AutoFE is treated as an optimization problem over a discrete space.\n\nIn this paper, we address the AutoFE problem from a di erent perspective and propose the rst gradient-based approach called DIFER (DI erentiable automated Feature EngineeRing). We rst propose an evolutionary framework to generate better features iteratively. Then, in each feature evolution step, we propose a tree-like structure called parse tree to represent constructed features exibly, and leverage a feature optimizer based on the encoder-predictor-decoder. Speci cally, instead of searching in the discrete feature space, the encoder maps the traversal string of the parse tree into a continuous vector space. Constructing a better feature is equivalent to generating better embedding in the continuous vector space. The following predictor takes the feature embedding as input, predicts its performance score, and directly optimizes the embedding by gradient ascent along the score direction. The optimized embedding is further decoded as a better feature in the discrete space.\n\nExtensive experimental results on both classi cation and regression tasks reveal that DIFER is not only e ective but also e cient. Compared to the SOTA approach, DIFER achieves better performance on 22 out of 25 datasets with 40 times fewer feature evaluations. Moreover, DIFER can be e ective when using di erent machine learning algorithms.\n\nTo summarize, our main contributions can be highlighted as follows: \u2022 We propose a feature evolution framework to search for better features iteratively. \u2022 To represent constructed features, we design the parse tree structure, which is more exible and expressive than the commonly-used sequence representation. \u2022 We introduce a novel feature optimizer based on the encoder-predictor-decoder for feature evolution and thus can achieve di erentiable AutoFE. To our best knowledge, DIFER is the rst di erentiable AutoFE method. \u2022 Extensive experimental results on a variety of tasks demonstrate that DIFER outperforms the stateof-the-art AutoFE approach in terms of both model performance and computational e ciency.\n\n\nRelated work\n\nFeature engineering aims to transform raw data into features that can better express the nature of the problem. Recently, feature engineering has gradually shifted from leveraging human knowledge to automated methods. Existing AutoFE approaches can be divided into three categories. Heuristic Approaches: Deep Feature Synthesis (DFS), the component of Data Science Machine (Kanter and Veeramachaneni, 2015), rst enumerates all transformations on all features and then performs feature selection directly based on the improvement of model performance. One Button Machine (Lam et al., 2017) adopts a similar approach. However, this expansion-reduction approach su ers from a severe computational performance bottleneck due to the huge feature evaluation overhead. To avoid enumerating the entire feature space, Cognito (Khurana et al., 2016) introduces a tree-like exploration of feature space and presents handcrafted heuristics traversal strategies such as breadth-rst search and depth-rst search. AutoFeat (Horn et al., 2019) iteratively subsamples features using beam search. However, heuristic approaches cannot learn from past experiences and thus has a low search e ciency.\n\nLearning-Based Approaches: To explore feature space e ciently, learning-based AutoFE methods have been proposed. LFE (Nargesian et al., 2017) trains an MLP and recommends the most likely useful transformation for each raw feature. However, it does not support transformation composition and works only for classi cation tasks. TransGraph (Khurana et al., 2018) trains a Q-learning agent to decide which transformation should be applied. Due to performing each transformation on all features, TransGraph su ers from feature explosion and low computational e ciency. NAS-Based Approaches: Neural Architecture Search (Elsken et al., 2019) has aroused signi cant research interests in the eld of AutoML (He et al., 2020). The reinforcement learning-based NAS method (Zoph and Le, 2017) views the structure of a neural network as a variable-length string. Then, it uses a recurrent network as the controller to generate such strings and trains the controller with policy gradient. This approach can be adopted into AutoFE. For instance, NFS (Chen et al., 2019), the current SOTA AutoFE method, utilizes several RNN-based controllers to generate transformation sequences for each raw feature. However, evaluating enormous sequences results in substantial computational overhead. Most importantly, due to the side e ects of reducing binary transformations to unary ones, NFS cannot generate complex features like + \u2212 . To improve the computational e ciency of NAS, di erentiable methods have been proposed. DARTS  relaxes the categorical choice to a softmax over all possible operations, leading to a di erentiable learning objective. NAO (Luo et al., 2018) maps the discrete architecture space to a continuous hidden space and optimizes existing architectures in the continuous space.\n\nThe di erentiable NAS methods bring more inspiration to AutoFE. In this paper, we propose the rst di erentiable AutoFE method called DIFER, which can e ciently construct useful low-order and high-order features with much fewer feature evaluations.\n\n\nMethodology\n\n\nProblem Formulation\n\nLet = , be a dataset with a target vector and -dimensional instances = { 1 , \u00b7 \u00b7 \u00b7 , }, where \u2208 R is the -th raw feature. We denote the performance of the machine learning model that is learned from and measured by an evaluation metric (e.g., F1-score or mean squared error) as ( , ). Without loss of generality, the higher indicates better model performance. Furthermore, we apply the composition of transformations \u2208 R \u00d7 \u00b7 \u00b7 \u00b7 \u00d7 R \u2192 R to features for constructing new features. Let denote the arity of the transformation , we construct a new feature\u02c6= \u02c61 , \u00b7 \u00b7 \u00b7 ,\u02c6 , where\u02c6denotes the -th input of to construct\u02c6for \u2208 {1, \u00b7 \u00b7 \u00b7 , }.\n\nGiven a set of transformations with di erent arities = { 1 , \u00b7 \u00b7 \u00b7 , }, we de ne the feature space as follows: \u2200\u02c6\u2208 ,\u02c6satis es any of the following conditions:\n\n\u2022\u02c6\u2208\n\n\u2022 \u2203 \u2208 ,\u02c6= \u02c61 , \u00b7 \u00b7 \u00b7 ,\u02c6 , where1, \u00b7 \u00b7 \u00b7 ,\u02c6\u2208 Formally, let (\u02c6) denote the order of the feature\u02c6\u2208 , (\u02c6) can be de ned as:\n(\u02c6) = 1 + max \u02c6 \u02c6= (1, \u00b7 \u00b7 \u00b7 ,\u02c6) 0\u02c6\u2208(1)\nFor example, we use the composition of the unary transformation square and the binary transformation divide to construct BMI (Body Mass Index), whose order is 2, by divide (weight, square (height)) with the raw features weight and height. Therefore, the goal of AutoFE is to nd the set of constructed features * that can achieve the best performance:\n* = arg max ( \u222a\u02c6, ), s.t.\u02c6\u2282(2)\nIn practice, we limit the order of features and search in the feature space = {\u02c6|\u02c6\u2208 \u2227 (\u02c6) \u2264 } since the size of the original space is in nite (i.e., | | = \u2135 0 ). we explore and search for top features ranked by the performance metric \u222a {\u02c6}, as * . Moreover, similar to most existing AutoFE methods (e.g., NFS (Chen et al., 2019), (Nargesian et al., 2017), and TransGraph (Khurana et al., 2018)), we also append the constructed features to to maximize the modeling performance for a given algorithm.\n\n\nOverview of DIFER\n\nAs shown in Figure 1, we propose an evolutionary framework to achieve AutoFE. The overall framework is divided into three phases: population initialization, feature evolution, and feature selection.  Figure 1: Overview of DIFER.\n\n\nFeature Evolution Framework\n\nThe population initialization phase constructs feature set cand by randomly sampling features from . We train a machine learner , which takes instances as input and predicts the labels , from scratch and evaluate its performance as the performance score of the feature ( \u222a {\u02c6}, ).\n\nThen, we can get the score set cand = { ( \u222a {\u02c6}, )|\u02c6\u2208 cand }.\n\nThe feature evolution phase aims to construct new features iteratively. In each iteration, we rst select top-features from cand according to cand . To enhance the diversity of evolution, we take two di erent approaches to generate new features at the same time. One way is to perform gradient-based optimization based on the feature optimizer and add /2 optimized features to cand (i.e., exploitation). The other way is to add /2 unduplicated randomly-generated features to cand for exploration. The process of feature evolution is repeated until a maximum number of feature evaluations is reached. In the feature optimization process, the two key components are the parse-tree-based feature representation and the gradient-directed feature optimizer that consists of an encoder, a predictor, and a decoder. Due to its exibility in the optimization of complex feature transformation, the encoder-predictor-decoder-based feature optimizer is suitable for the AutoFE problem.\n\nAfter the feature evolution phase, we select top features from cand and add them to the original dataset. The number of added features is adaptively determined with an early-stopping mechanism. When the model performance no longer increases, we stop adding features to the original dataset.\n\nCase Study. we show the process of DIFER using the dataset PimaIndian as an example. DIFER rst initializes the population , by random sampling and evaluating features from . Then, the feature optimizer is trained on the population. The detailed training process of feature optimizer is introduced in Section 3.4.\n\nIn the feature optimization process, taking the feature min_max(BloodPressure) Insulin as an example, we introduce how the input feature is optimized to get a better feature. As mentioned in Section 3.3, the feature is rst parsed as a tree and traversed to the string <Insulin,Reciprocal,BloodPressure,MinMax,Multiply>. The feature optimizer maps it into the continuous vector space as via the encoder , optimizes the embedding along the gradient direction induced by the predictor . The string <Insulin, Pregnancies, AbsRoot, Multiply, Reciprocal,BloodPressure,MinMax,Multiply> is recovered from the optimized embedding by the decoder . The recovered string is translated to min_max(BloodPressure) \u221a |Pregnancies| \u00b7Insulin .\n\n\nFeature Representation\n\nAs shown in Figure 2, we design a tree-like structure called parse tree to represent constructed features. Compared with the sequence representation in NFS (Chen et al., 2019) and NAO (Luo et al., 2018), the parse tree is more exible and expressive, which can represent complex -ary feature transformation operation like + \u2212 . The internal node in the parse tree indicates the transformation and the leaf node indicates the raw feature. We employ reversible post-order traversal to convert the  \n--''- --''- Parse\n\nFeature Optimization\nDecoder & + Encoder & ,\n\nTraversal string of feature parse tree\n\n\nContinuous Representation\n\n\nGradient descent on\n\nPredictor & -\n\n\nOptimized Representation\n\nOptimized feature parse tree (a) Feature optimization.  parse tree into equivalent traversal string as input to the encoder. The traversal string in Figure 2 shows an example where each word-based token (i.e., the original feature and the transformation) is separated by a comma. Let denote each token in the traversal string, where \u2208 {1 \u00b7 \u00b7 \u00b7 | |}. Note that the relationship between the parse tree and the traversal string is one-to-many. When there are transformations where the input order is meaningless (e.g. mul( , ) == mul( , )), the same parse tree can be converted into multiple equivalent strings. This nature can be viewed as a way of data augmentation when training the feature optimizer. Due to the xed arity of each transformation, the optimized traversal string can be recovered to a parse tree with no ambiguity. The translation process can be found in Appendix A.\n\n\nFeature Optimizer\n\nDIFER employs a feature optimizer to construct new features based on the existing features. The feature optimization process is shown in Figure 3a. Speci cally, the feature optimizer consists of an encoder , a performance predictor , and a decoder . After jointly-training the feature optimizer for convergence, maps features into the continuous vector space via , optimizes the embedding along the gradient direction induced by , and recovers better features from the optimized embedding by .\n\nEncoder. The encoder maps the post-order traversal string \u2208 X to a continuous embedding \u2208 E \u2282 R _ . Since the traversal string is a variable-length sequence, we use LSTM (Long Short-Term Memory) (Hochreiter and Schmidhuber, 1997) as the encoder. By the sum-pooling technique, the sum of all hidden states = {\u210e 1 , \u210e 2 , \u00b7 \u00b7 \u00b7 , \u210e | | } of the LSTM as the feature's continuous representation .\n\nPredictor. The predictor \u2208 E \u2192 R maps the continuous representation into its score measured by ( \u222a {\u02c6}, ). We employ a 5-layer fully-connected MLP as .\n\nDecoder. The decoder maps the embedding to the discrete feature space, i.e., the post-order traversal string of the optimized feature. According to the classical sequence-to-sequence method, we employ an LSTM with the attention mechanism (Bahdanau et al., 2015) as the decoder \u2208 E \u2192 X , which takes as the initial hidden state and all hidden states in the encoder as the input of each timestamp.\n\nJointly-Training. To train the optimizer e ciently, we propose a jointly-training method based on a joint loss. The training dataset is the initial evaluated population cand , cand . As shown in Figure 3b, we design a joint loss function that takes both the performance prediction loss L and the structure reconstruction loss L into account. The value of the hyperparameter that balances L and L is determined adaptively (see Appendix C).\nL = L + L , where L = \u2211\ufe01 \u2212 ( ( )) 2 and L = \u2212 \u2211\ufe01 | | \u2211\ufe01 =1 log ( | ( )) (3)\n\nFeature Optimization\n\nAfter the convergence of the feature optimizer, we directly optimize the feature embedding in the continuous space by performing gradient ascent and then decode the optimized embedding into a new feature . Starting from the constructed feature , we optimize its embedding to get a better embedding along the gradient direction induced by the predictor :\n= \u2211\ufe01 \u210e \u2208 \u210e + \u210e(4)\nHowever, due to the nature that the corresponding parse tree of a feature\u02c6may have several equivalent post-order traversal strings = { (1) , (2) , \u00b7 \u00b7 \u00b7 ( ) }, the strings in are highly similar in the continuous space. After one step of gradient ascent, the decoded string of may still be in . Thus, we may get the same parse tree. We call in Equation (4) the evolution rate. Increasing the evolution rate can solve this problem to some extent (Luo et al., 2018). However, a large evolution rate would violate the preconditions of gradient ascent, resulting in no guarantee that\n( + \u0394 ) > ( ).\nMulti-step gradient ascent. To address this problem, we propose a straightforward but e ective strategy. Speci cally, we apply the optimization process in Equation (4) multiple times with a small evolution rate until we get new parse trees. As a result, the number of times the optimization process (i.e., steps of gradient ascent) is adaptively determined. We refer to the overall process as feature optimization.\n\n\nExperiments\n\n\nExperimental Setting\n\nAs with the SOTA method NFS (Chen et al., 2019), we use 25 public datasets from OpenML ( Vanschoren et al., 2014), UCI repository (Dua and Gra , 2017), and Kaggle (2021). There are 15 classi cation (C) datasets and 10 regression (R) datasets that have various numbers of features (5 to 10936) and instances (100 to 30000). In all experiments, we set the max order to 5 except in RQ3 and utilize 9 transformation functions totally. Moreover, to ensure the fairness, all methods except LFE (Nargesian et al., 2017) have the same feature transformation space.\n\n\u2022 Unary transformation: logarithm, square root, min-max normalization, and reciprocal \u2022 Binary transformation: addition, subtraction, multiplication, division, and modulo All experiments are run using Tesla K80 (GPU) and Intel(R) Xeon(R) CPU E5-2630 v2 instances. To evaluate the AutoFE method, we use the performance metric (1 \u2212 (relative absolute error)) (Shcherbakov et al., 2013) for the regression task and f1-score for the classi cation task. 5-fold cross validation using random strati ed sampling is employed and the average result is reported. Except that di erent ML algorithms are used in RQ4, we utilize Random Forest as default. We use scikit-learn as the machine learning algorithm library and employ PyTorch to implement the feature optimizer, including LSTM-based encoder and decoder, MLP-based predictor.\n\nIn the initialization step of DIFER, we randomly select 512 features as the initial population. Both the encoder and decoder of the feature optimizer are implemented as a one-layer LSTM. We empirically set the embedding size of each token in the traversal string and the size of the hidden state to 512. The predictor is a 5-layer MLP where the number of hidden units in each layer is 1024. To train the feature optimizer, we choose the Adam optimizer (Kingma and Ba, 2014) with a learning rate of 0.001 and a weight decay of 0.0001. The number of epochs is 400, and the batch size is 128. Early stopping is employed with a patience of 10.\n\nIn each feature evolution iteration, the value of is empirically set to be the minimum between top 20% of the initial population size and the total number of original features. The feature evolution runs until the number of feature evaluations reaches the upper limit of 4096. When optimizing the feature embedding in Equation (4), we perform gradient ascent with an evolution rate of 0.0001. Moreover, we use the same hyperparameters for all datasets. The robustness experiments with di erent hyperparameters can be found in Appendix D.\n\n\nE ectiveness of DIFER (RQ1)\n\nIn this subsection, we demonstrate the e ectiveness of DIFER. We compare DIFER on 25 datasets with the SOTA and baseline methods, including: (a) Raw: raw dataset without any transformation; (b) Random: randomly applying transformations to each raw feature; (c) DFS (Kanter and Veeramachaneni, 2015): a well-known expansion-reduction method; (d) AutoFeat (Horn et al., 2019): a popular Python library for automated feature engineering and selection; (e) LFE (Nargesian et al., 2017): recommend the most promising transformation for each feature using MLP; (f) NFS (Chen et al., 2019): the SOTA AutoFE method that achieves better performance than other existing approaches (e.g., Khurana et al. (2018)). The experimental settings of these methods, such as the set of transformations, the max feature order, and the evaluation metrics are the same as DIFER. Table 1 shows the comparison results between DIFER and the existing methods. Moreover, since LEF can only deal with the classi cation task and the source code is not available, we directly use the best results reported in the original paper (Nargesian et al., 2017). The comparison results between DIFER and LEF are shown in Table 2. From Table 1 and Table 2, we can observe that: \u2022 DIFER achieves the best performance in all but four cases. Although NFS greatly outperforms the baseline methods, DIFER still achieves an average improvement of 2.57% over NFS. For regression tasks, DIFER can even achieve a maximum improvement of 11.42%. \u2022 DIFER can handle datasets with various numbers of instances and features for both regression and classi cation tasks and achieve performance improvement on all datasets with an average of 10.72% over Raw and an average of 9.55% over Random. \u2022 With the bene t of searching in the continuous vector space, DIFER addresses the feature explosion problem while preserving the entire space, and achieves highly competitive performance even on large datasets such as Credit Default (30000 \u00d7 25) and AP-omentum-ovary (275 \u00d7 10936). E ectiveness of the predictor . Since the accuracy of the predictor determines the quality of the optimized features, here we demonstrate the e ectiveness of . We train the feature optimizer using the data augmentation technique mentioned in Section 3.3 on an initialized population of 512 features. After convergence, the loss L (i.e., Mean-Squared Error) of the predictor in the training set is 0.00106. To test the predictor, we randomly sample 256 features from the feature space as the test set, which is di erent from the training set. The test loss of is 0.00132. Both the training loss and the test loss are small and close, demonstrating the e ectiveness of the predictor. Furthermore, we employ the pairwise accuracy metric to evaluate . Let denote the test set. ( ) and denote the predicted performance of and the real performance of the feature. The pairwise accuracy is de ned as follows:\n= 1 \u2208 , 2 \u2208 I ( 1 ) \u2265 ( 2 ) I 1 \u2265 2 | |(| | \u2212 1)/2(5)\nwhere I represents the 0-1 indicator function. The pairwise accuracy of is 0.918, which is close to the ideal value (i.e., 1) and much better than random guess (i.e., 0.5).\n\n\nE ciency of DIFER (RQ2)\n\nThe overhead of AutoFE can be divided into two parts: the process of feature evaluation and the training overhead of the controller (i.e., the feature optimizer). To verify the e ciency of DIFER, we conduct experiments in terms of the total runtime and the number of feature evaluations, respectively. Table 1  (a) Proportion of di erent order features generated by DIFER.   Table 1 and Figure 4, we can observe that: \u2022 In Table 1, DIFER achieves better performance than NFS by using 40 times fewer feature evaluations while still achieving signi cant performance improvement. \u2022 From the perspective of runtime, the overhead of DIFER is mainly in the training and inference of the feature optimizer compared to NFS which is dominated by feature evaluation. Therefore, the e ciency advantage of DIFER is more obvious on larger datasets that requires more evaluation time. For example, compared with NFS, DIFER can achieve 2.9\u00d7, 7.7\u00d7, 11.5\u00d7 speedup on APomentum-ovary, Credit Default, gisette, respectively.\n\n\u2022 The advantage of DIFER is more signi cant with a restricted number of feature evaluations measured by Wilcoxon signed-rank test with -value < 0.05. DIFER achieves an average performance improvement of 6.89%, doubling that in RQ1.\n\n\nE ectiveness of High-Order Features (RQ3)\n\nTo evaluate the ability of exploring the high-order feature space, we conduct two experiments:  (Hosmer Jr et al., 2013) 5.95\u00b14.12 1.01 / 15.94 LinearSVC (Cortes and Vapnik, 1995) 13.98\u00b19.23 3.17 / 22.32 XGBoost (Chen and Guestrin, 2016) 6.90\u00b16.92 0.30 / 27.98 LightGBM (Ke et al., 2017) 7.69\u00b18.09 0.16 / 32.63 Regression RandomForest 16.42\u00b16.19 5.36 / 25.80 LassoRegression (Tibshirani, 1996) 14.61\u00b18.92 1.22 / 66.66 LinearSVR (Smola and Sch\u00f6lkopf, 2004) 32.72\u00b119.79 13.21 / 96.98 XGBoost (Chen and Guestrin, 2016) 13.47\u00b19.35 3.20 / 67.06 LightGBM (Ke et al., 2017) 15.46\u00b110.48 4.75 / 71.92\n\n1. Analyze the features generated by DIFER during the search process and investigate whether DIFER can indeed search for the high-order features. 2. Choose the max order from 0 to 6, where = 0 means the raw dataset without any feature transformation. Then, we analyze the performance curve by varying . Figure 5a shows the number of each order features generated by DIFER with = 5 for each dataset. High-order features take a considerable average proportion of 80.9%, con rming that DIFER exploits the entire feature space instead of its subspace where < . Besides, we randomly choose 8 datasets, normalize the performance of DIFER, plot the performance curve with the increasing max order in Figure 5b, and draw the following conclusions:\n\n\u2022 The overall performance of DIFER stably increases with the max order . However, when increases to 5, performance improvement become insigni cant. \u2022 For most datasets, su cient performance improvement can be already achieved with = 2. There is no need to set an excessively large max order in practice.\n\n\nDi erent Machine Learning Algorithms (RQ4)\n\nTo further investigate the generalization ability of DIFER, we utilize the commonly-used classication and regression algorithms. We conduct experiments on all datasets and the performance statistics are shown in Table 3. Compared to the Raw method, DIFER achieves signi cant improvement under di erent algorithms. For instance, LinearSVR with DIFER even achieves an average improvement of 32.72% across 25 datasets and a max improvement of 96.98% in Airfoil.\n\n\nConclusion and Future Work\n\nIn this work, we proposed DIFER, to the best of our knowledge, the rst di erentiable AutoFE method. DIFER leverages an encoder-predictor-decoder-based feature optimizer, which maps features into the continuous vector space via the encoder, optimizes the embedding along the gradient direction induced by the predictor, and recovers better features from the optimized embedding by the decoder. Moreover, based on the feature optimizer, we proposed a feature evolution framework to search for better features iteratively. Experimental results show that DIFER is e ective on both classi cation and regression tasks and can outperform the existing AutoFE methods in terms of both prediction performance and computational e ciency. The transformation operations in DIFER are for numerical features. For future work, we plan to automatically search for transformations for di erent feature types (i.e., numerical and categorical). You must include a brief justi cation to your answer, either by referencing the appropriate section of your paper or providing a brief inline description. For example:\n\n\u2022 Did you include the license of the code and datasets? [Yes] See Section ??.\n\n\u2022 Did you include all the code for running experiments? [No] We include the code we wrote, but it depends on proprietary libraries for executing on a compute cluster and as such will not be runnable without modi cations. We also include a runnable sequential version of the code that we also report experiments in the paper with.\n\n\u2022 Did you include the license of the datasets? [N/A] Our experiments were conducted on publicly available datasets and we have not introduced new datasets.\n\nPlease note that if you answer a question with \\answerNo{}, we expect that you compensate for it (e.g., if you cannot provide the full evaluation code, you should at least provide code for a minimal reproduction of the main insights of your paper). Please do not modify the questions and only use the provided macros for your answers. Note that this section does not count towards the page limit. In your paper, please delete this instructions block and only keep the Checklist section heading above along with the questions/answers below.\n\n1. For all authors. . . (c) Did you discuss any potential negative societal impacts of your work? [No] (d) Have you read the ethics review guidelines and ensured that your paper conforms to them? [Yes] 2. If you are including theoretical results. . . (a) Did you include the code, data, and instructions needed to reproduce the main experimental results, including all requirements (e.g., requirements.txt with explicit version), an instructive README with installation, and execution commands (either in the supplemental material or as a )? [Yes] We use open-source datasets and provide source code to reproduce the results in supplemental material.\n\n(b) Did you include the raw results of running the given instructions on the given code and data? [Yes] (c) Did you include scripts and commands that can be used to generate the gures and tables in your paper based on the raw results of the code, data, and instructions given? [Yes] (d) Did you ensure su cient code quality such that your code can be safely executed and the code is properly documented? [Yes] (e) Did you specify all the training details (e.g., data splits, pre-processing, search spaces, xed hyperparameter settings, and how they were chosen)? [Yes] (f) Did you ensure that you compared di erent methods (including your own) exactly on the same benchmarks, including the same datasets, search space, code for training and hyperparameters for that code? [Yes] See Section 4.1.\n\n(g) Did you run ablation studies to assess the impact of di erent components of your approach?\n\n[Yes]\n\n(h) Did you use the same evaluation protocol for the methods being compared? [Yes] (i) Did you compare performance over time? [No] (j) Did you perform multiple runs of your experiments and report random seeds? [No] We use 5-fold cross-validation to reduce randomness.\n\n(k) Did you report error bars (e.g., with respect to the random seed after running experiments multiple times)? [No] We use 5-fold cross-validation to reduce randomness.\n\n(l) Did you use tabular or surrogate benchmarks for in-depth evaluations? [Yes] (m) Did you include the total amount of compute and the type of resources used (e.g., type of s, internal cluster, or cloud provider)? [Yes] Also see Section 4.1.\n\n(n) Did you report how you tuned hyperparameters, and what time and resources this required (if they were not automatically tuned by your AutoML method, e.g. in a approach; and also hyperparameters of your own method)? [Yes] 4. If you are using existing assets (e.g., code, data, models) or curating/releasing new assets. . . (c) Did you include any new assets either in the supplemental material or as a ? [No] (d) Did you discuss whether and how consent was obtained from people whose data you're using/curating? [No] We use open-source data and follow protocols.\n\n(e) Did you discuss whether the data you are using/curating contains personally identi able information or o ensive content? [No] 5. If you used crowdsourcing or conducted research with human subjects. . . \n\n\nA Translation Between Three Forms of Features\n\nAs mentioned in Section 3.3, there are three forms of features (i.e., original form, parse tree form and traversal string form). To generate parse trees from the original features, we design the following context-free grammar in BNF (Backus Normal Form):\n\n\u2022 ParseTree 1,..., | UnaryOp ParseTree | BinaryOp ParseTree ParseTree\n\u2022 UnaryOp logarithm | abs | root | min-max | normalization | reciprocal \u2022 BinaryOp addition | subtraction | multiplication | division | modulo\nThrough such syntax parser, the features are parsed into the form of parse tree, and then the corresponding strings is derived through post-order traversal. Similarly, due to the many-to-one relationship between traversing strings and parse trees, strings can be reduced to parse trees. With features as leaf nodes, the constructed features are nally obtained from the bottom up at the root node through the internal nodes with the operators.\n\n\nB Neighborhood of Constructed Features\n\nThe duplicated post-order traversal strings = { (1) , (2) , \u00b7 \u00b7 \u00b7 ( ) } of the feature\u02c6are highly similar in the continuous space:\n\u2203 , \u2200 ( ) \u2208 , ( ) \u2212 1 \u2211\ufe01 ( ) \u2208 ( ) 2 \u2264(6)\nwhere is just a variable used to inscribe the property, not a hyperparameter. The neighborhood of in the continuous space can be represented as\n= { | \u2212 1 ( ) \u2208 ( ) 2 \u2264 }.\nAfter one step of gradient ascent, the decoded string of \u2208 may still be in . Thus, the same parse tree is got. To escape the neighborhood., we use multi-step gradient ascent as mentioned in Section 3.5.\n\n\nC Adaptive Loss Weight Setting\n\nWe use the parameter \u2208 R + to balance L and L and is determined adaptively. Inspired by (Goyal et al., 2017), the rst epochs are used to warm up the jointly-training of the feature optimizer with = 1. After the rst epochs, we assign = =1 L / =1 L according to the sum of losses. This is mainly to make the two losses in the same order of magnitude. In practice, is empirically set to 5.\n\n\nD Robustness\n\nWe further evaluate whether DIFER is sensitive to di erent hyperparameters, including evolution rate and population size . Figure 6a and Figure 6b show the experimental results on 5 randomlyselected datasets that represent both classi cation and regression tasks. Figure 6a demonstrates that DIFER is robust to di erent settings of . Empirically, should not be too large in gradient ascent. A small can get the same or even better results than the large by performing multiple times of gradient ascent. Moreover, a larger allows the feature optimizer to be fully trained, and a smaller allows more features to be optimized in the case of a limited number of feature evaluations. As shown in Figure 6b, the performance of DIFER remains stable across di erent settings of .\n\n\nE Statistics Comparison\n\nTo further statistically evaluate the di erence between the AutoFE methods in Table 1, we perform the Friedman test Dem\u0161ar (2006), which is a non-parametric equivalent of the repeated-measures ANOVA. It is used to determine whether or not there is a statistically signi cant di erence.   For the comparison results in Table 1, we rst calculate the Friedman statistic. Let be the rank of the -th of AutoFE methods ( = 4, i.e., DFS, AutoFeat, NFS, and DIFER) on the -th of datasets. The Friedman test compares the average ranks of models, = 1 . The nullhypothesis states that all the tree models are equivalent and so their ranks should be equal. We employ the scipy tool 1 to calculate the Friedman statistic. The corresponding Friedman -value is 1.17e-10. Since the -value is less than 0.05, we can reject the null hypothesis that the performance is the same for all four types of AutoFE methods. In other words, we have su cient evidence to conclude that the AutoFE method lead to statistically signi cant di erences in terms of performance. Since the -value of the Friedman test is statistically signi cant, we perform the Nemenyi post-hoc test Nemenyi (1963) to further determine exactly which AutoFE method has di erent means. Table 4 shows the -values for each pairwise comparison. We can conclude that DIFER is signi cantly di erent from other trees for a con dence level of = 0.05 and show the result by '*' in Table1.\n\n\nF Numbers of Added Features\n\nIn the formal de nition, | * |is de ned as the set of added features, which does not contain the raw features. Table 5 shows the number of features nally added by AutoFeat, NFS and DIFER. For NFS, it is the number of original features. Bene ting from feature selection, | * | in AutoFeat and DIFER is adaptive. \n\nFigure 2 :\n2Parse tree and post-order traversal strings of the feature min_max(BloodPressure) \u221a |Pregnancies | \u00b7Insulin in PimaIndian.\n\n\nAttention (b) Jointly-training of feature optimizer.\n\nFigure 3 :\n3Feature Optimizer of DIFER.\n\n\n, where the datasets are sorted in ascending order of model evaluation time, shows the total runtime T and the average number of feature evaluations for AutoFE,\n\n\n) E ect of the high-order feature space.\n\nFigure 5 :\n5E ectiveness of high-order features. 4 shows the comparison results between NFS and DIFER with a restricted number of feature evaluations. From\n\n\nmust include a section with the AutoML-Conf Reproducibility Checklist in their manuscripts, both at submission and camera-ready time. The reproducibility checklist is a combination of the NeurIPS '21 checklist and the checklist. For each question, change the default \\answerTODO{} (typeset [TODO]) to \\answerYes{[justification]} (typeset [Yes]), \\answerNo{[justification]} (typeset [No]), or \\answerNA{[justification]} (typeset [N/A]).\n\n\n(a) Do the main claims made in the abstract and introduction accurately re ect the paper's contributions and scope?[Yes]    (b) Did you describe the limitations of your work? [Yes] We discuss its limitations in Section 5 for further work.\n\n( a )\naDid you state the full set of assumptions of all theoretical results? [N/A] (b) Did you include complete proofs of all theoretical results? [N/A] 3. If you ran experiments. . .\n\n\n(a) If your work uses existing assets, did you cite the creators?[Yes]  We use open-source data with citations.(b) Did you mention the license of the assets?[No]    \n\n( a )\naDid you include the full text of instructions given to participants and screenshots, if applicable? [N/A] (b) Did you describe any potential participant risks, with links to Institutional Review Board ( ) approvals, if applicable? [N/A] (c) Did you include the estimated hourly wage paid to participants and the total amount spent on participant compensation? [N/A]\n\n\nresults of DIFER with di erent settings of the population size .\n\nFigure 6 :\n6Robustness of DIFER.\n\nTable 1 :\n1Comparison between DIFER and the existing AutoFE methods (The datasets are sorted based on the evaluation time. \u2020 the results obtained using the open-sourced code, * denotes statistically signi cant improvement measured by Friedman test and Nemenyi post-hoc test with -value < 0.05. T indicates the total runtime. Inst. is short for Instance, Feat. is short for Feature, Err.indicates failure due to out of memory when running the open-source code).Dataset \nC/R Inst.\\Feat. \nRaw Random \nDFS  \u2020 AutoFeat  \u2020 \nNFS  \u2020 DIFER  *  \nT \nT \n\nHousing Boston \nR \n506\\13 \n0.4336 \n0.4446 0.3412 \n0.4688 0.5013 \n0.4944 \n566.42 \n982.15 \nBikeshare DC \nR \n10886\\11 0.8200 \n0.8436 0.8214 \n0.8498 \n0.9746 0.9813 \n595.57 1040.96 \nAirfoil \nR \n1503\\5 \n0.4962 \n0.5733 0.4346 \n0.5955 \n0.6163 0.6242 \n603.80 1066.93 \nOpenml_586 \nR \n1000\\25 \n0.6617 \n0.6511 0.6501 \n0.7278 \n0.7401 0.7683 \n1722.49 1013.57 \nOpenml_589 \nR \n1000\\25 \n0.6484 \n0.6422 0.6356 \n0.6864 \n0.7141 0.7727 \n1726.04 1005.18 \nOpenml_637 \nR \n1000\\25 \n0.5136 \n0.5268 0.5191 \n0.5763 \n0.5693 0.6343 \n1411.79 1028.14 \nOpenml_618 \nR \n1000\\50 \n0.6267 \n0.6167 0.6343 \n0.6324 \n0.6400 0.6603 \n3159.47 1020.72 \nOpenml_607 \nR \n1000\\50 \n0.6344 \n0.6285 0.6388 \n0.6699 \n0.6870 0.6918 \n2990.91 1032.40 \nOpenml_616 \nR \n500\\ 50 \n0.5747 \n0.5714 0.5717 \n0.6027 \n0.5915 0.6554 \n1511.58 1030.57 \nOpenml_620 \nR \n1000\\25 \n0.6336 \n0.6178 0.6263 \n0.6874 \n0.6749 0.7442 \n1686.78 1047.37 \n\nHepatitis \nC \n155\\6 \n0.7860 \n0.8300 0.8258 \n0.7677 \n0.8774 0.8839 \n355.76 1045.77 \nFertility \nC \n100\\9 \n0.8530 \n0.8300 0.7500 \n0.7900 \n0.8700 0.9098 \n362.38 1054.51 \nSpectF \nC \n267\\44 \n0.7750 \n0.8277 0.7906 \n0.8161 \n0.8501 0.8612 \n386.39 \n933.45 \nMegawatt1 \nC \n253\\37 \n0.8890 \n0.8973 0.8773 \n0.8893 \n0.9130 0.9171 \n404.33 1024.95 \nIonosphere \nC \n351\\34 \n0.9233 \n0.9344 0.9175 \n0.9117 \n0.9516 0.9770 \n421.50 1036.01 \nGerman Credit \nC \n1001\\24 \n0.7410 \n0.7550 0.7490 \n0.7600 0.7818 \n0.7770 \n433.39 1043.06 \nCredit-a \nC \n690\\6 \n0.8377 \n0.8449 0.8188 \n0.8391 \n0.8652 0.8826 \n435.14 \n992.91 \nPimaIndian \nC \n768\\8 \n0.7566 \n0.7566 0.7501 \n0.7631 \n0.7839 0.7865 \n435.10 1007.30 \nMessidor_features \nC \n1150\\19 \n0.6584 \n0.6878 0.6724 \n0.7359 \n0.7461 0.7576 \n555.62 1069.04 \nWine Quality Red \nC \n999\\12 \n0.5317 \n0.5641 0.5478 \n0.5241 0.5841 \n0.5824 \n587.77 1033.29 \nWine Quality White \nC \n4900\\12 \n0.4941 \n0.4930 0.4882 \n0.5023 \n0.5150 0.5155 \n1278.61 1016.35 \nSpamBase \nC \n4601\\57 \n0.9102 \n0.9237 0.9102 \n0.9237 \n0.9296 0.9339 \n993.92 \n959.03 \nAP-omentum-ovary \nC \n275\\10936 0.7636 \n0.7100 0.7250 \nErr. \n0.8640 0.8726 \n4183.75 1441.01 \nCredit Default \nC \n30000\\25 0.8037 \n0.8060 0.8059 \n0.8060 \n0.8049 0.8096 \n9253.70 1204.99 \ngisette \nC \n2100\\5000 0.9261 \n0.8710 0.7410 \nErr. \n0.9590 0.9635 18877.07 1646.19 \n\nUpper Limit of Eval. Num. \n160,000 \n4,096 \n\n\n\nTable 2 :\n2Comparison between DIFER, LFE, and NFS ( * the results reported in the paper).SpectF \nOpenML_618 \nHepatitis \n\nWine Quality Red \n\nIonosphere \nOpenML_616 \n\nCredit Default \nPimaIndian \n\nWine Quality White \n\nOpenML_637 \nFertility \nOpenML_586 \nOpenML_620 \nSpamBase \nOpenML_589 \nMegawatt1 \nOpenML_607 \nBikeshare DC \nHousing Boston \nMessidor_features \nAirfoil \nCredit-a \n\nGerman Credit \nAP-omentum-ovary \ngisette \n\n0.00 \n\n0.02 \n\n0.04 \n\n0.06 \n\n0.08 \n\n0.10 \n\n0.12 \n\n0.14 \n\n0.16 \n\nPerformance Improvement Compared To Raw \n\nNFS \nDIFER \n\nFigure 4: Comparison between NFS and DIFER. The \nnumber of feature evaluations is restricted to 3500. \n\n\n\nTable 3 :\n3Statistics on the performance of DIFER with di erent ML algorithms.Task \nAlgorithm \nAvg Impr\u00b1Std (%) Min/Max Impr (%) \n\nClassi cation \nRandomForest \n6.59\u00b14.23 \n0.73 / 15.06 \nLogisticRegression \n\nTable 4 :\n4-values for each pairwise comparison using the Nemenyi post-hoc test for the AutoFE methods (Con dence level = 0.05).DFS \nAutoFeat NFS \nDIFER \n\nDFS \n1.0000 0.2967 \n0.0010 0.0010 \nAutoFeat 0.2967 1.0000 \n0.0313 0.0010 \nNFS \n0.0010 0.0313 \n1.0000 0.0046 \nDIFER \n0.0010 0.0010 \n0.0046 1.0000 \n\n\n\nTable 5 :\n5The number of features | * | added into the original dataset by AutoFE methods (Err. indicates failure due to out of memory when running the open-source code).Dataset \nC/R Inst.\\Feat. |  *  | \n|  *  | \n|  *  | \n\nHousing Boston \nR \n506\\13 \n21 \n13 \n1 \nBikeshare DC \nR \n10886\\11 \n17 \n11 \n6 \nAirfoil \nR \n1503\\5 \n4 \n5 \n4 \nOpenml_586 \nR \n1000\\25 \n37 \n25 \n20 \nOpenml_589 \nR \n1000\\25 \n21 \n25 \n20 \nOpenml_637 \nR \n1000\\25 \n30 \n25 \n13 \nOpenml_618 \nR \n1000\\50 \n49 \n50 \n32 \nOpenml_607 \nR \n1000\\50 \n51 \n50 \n38 \nOpenml_616 \nR \n1000\\50 \n41 \n50 \n8 \nOpenml_620 \nR \n1000\\50 \n32 \n50 \n12 \n\nHepatitis \nC \n155\\6 \n7 \n6 \n6 \nFertility \nC \n100\\9 \n12 \n9 \n3 \nSpectF \nC \n267\\44 \n37 \n44 \n9 \nMegawatt1 \nC \n253\\37 \n48 \n37 \n29 \nIonosphere \nC \n351\\34 \n52 \n34 \n1 \nGerman Credit \nC \n1001\\24 \n22 \n24 \n1 \nCredit-a \nC \n690\\6 \n4 \n6 \n5 \nPimaIndian \nC \n768\\8 \n12 \n8 \n1 \nMessidor_features \nC \n1150\\19 \n29 \n19 \n10 \nWine Quality Red \nC \n999\\12 \n8 \n12 \n6 \nWine Quality White \nC \n4900\\12 \n11 \n12 \n9 \nSpamBase \nC \n4601\\57 \n46 \n57 \n1 \nAP-omentum-ovary \nC \n275\\10936 \nErr. \n10936 \n491 \nCredit Default \nC \n30000\\25 \n30 \n25 \n5 \ngisette \nC \n2100\\5000 \nErr. \n5000 \n19 \n\nhttps://github.com/scipy/scipy\nAcknowledgements. This work was supported in part by the National Natural Science Foundation of China (#62102177 and #U1811461), the Natural Science Foundation of Jiangsu Province\nNeural machine translation by jointly learning to align and translate. D Bahdanau, K Cho, Y Bengio, 3rd International Conference on Learning Representations. Bahdanau, D., Cho, K., and Bengio, Y. (2015). Neural machine translation by jointly learning to align and translate. In 3rd International Conference on Learning Representations, ICLR 2015.\n\nXgboost: A scalable tree boosting system. T Chen, C Guestrin, Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining. the 22nd acm sigkdd international conference on knowledge discovery and data miningChen, T. and Guestrin, C. (2016). Xgboost: A scalable tree boosting system. In Proceedings of the 22nd acm sigkdd international conference on knowledge discovery and data mining, pages 785-794.\n\nNeural feature search: A neural architecture for automated feature engineering. X Chen, Q Lin, C Luo, X Li, H Zhang, Y Xu, Y Dang, K Sui, X Zhang, B Qiao, 2019 IEEE International Conference on Data Mining (ICDM). IEEEChen, X., Lin, Q., Luo, C., Li, X., Zhang, H., Xu, Y., Dang, Y., Sui, K., Zhang, X., Qiao, B., et al. (2019). Neural feature search: A neural architecture for automated feature engineering. In 2019 IEEE International Conference on Data Mining (ICDM), pages 71-80. IEEE.\n\nSupport-vector networks. C Cortes, V Vapnik, Machine learning. 203Cortes, C. and Vapnik, V. (1995). Support-vector networks. Machine learning, 20(3):273-297.\n\nStatistical comparisons of classi ers over multiple data sets. J Dem\u0161ar, Journal of Machine Learning Research. 71Dem\u0161ar, J. (2006). Statistical comparisons of classi ers over multiple data sets. Journal of Machine Learning Research, 7(1):1-30.\n\nUCI machine learning repository. D Dua, C Gra, Dua, D. and Gra , C. (2017). UCI machine learning repository.\n\nNeural architecture search: A survey. T Elsken, J H Metzen, F Hutter, J. Mach. Learn. Res. 2055Elsken, T., Metzen, J. H., Hutter, F., et al. (2019). Neural architecture search: A survey. J. Mach. Learn. Res., 20(55):1-21.\n\nP Goyal, P Doll\u00e1r, R Girshick, P Noordhuis, L Wesolowski, A Kyrola, A Tulloch, Y Jia, K He, arXiv:1706.02677Accurate, large minibatch sgd: Training imagenet in 1 hour. arXiv preprintGoyal, P., Doll\u00e1r, P., Girshick, R., Noordhuis, P., Wesolowski, L., Kyrola, A., Tulloch, A., Jia, Y., and He, K. (2017). Accurate, large minibatch sgd: Training imagenet in 1 hour. arXiv preprint arXiv:1706.02677.\n\nAutoml: A survey of the state-of-the-art. Knowledge-Based Systems. X He, K Zhao, Chu , X , 106622He, X., Zhao, K., and Chu, X. (2020). Automl: A survey of the state-of-the-art. Knowledge-Based Systems, page 106622.\n\nLong short-term memory. S Hochreiter, J Schmidhuber, Neural computation. 98Hochreiter, S. and Schmidhuber, J. (1997). Long short-term memory. Neural computation, 9(8):1735- 1780.\n\nThe autofeat python library for automated feature engineering and selection. F Horn, R Pack, M Rieger, Joint European Conference on Machine Learning and Knowledge Discovery in Databases. SpringerHorn, F., Pack, R., and Rieger, M. (2019). The autofeat python library for automated feature engineering and selection. In Joint European Conference on Machine Learning and Knowledge Discovery in Databases, pages 111-120. Springer.\n\nApplied logistic regression. D W HosmerJr, S Lemeshow, R X Sturdivant, John Wiley & Sons398Hosmer Jr, D. W., Lemeshow, S., and Sturdivant, R. X. (2013). Applied logistic regression, volume 398. John Wiley & Sons.\n\n. Kaggle, Kaggle datasetsKaggle (2021). Kaggle datasets.\n\nDeep feature synthesis: Towards automating data science endeavors. J M Kanter, K Veeramachaneni, 2015 IEEE international conference on data science and advanced analytics (DSAA). IEEEKanter, J. M. and Veeramachaneni, K. (2015). Deep feature synthesis: Towards automating data science endeavors. In 2015 IEEE international conference on data science and advanced analytics (DSAA), pages 1-10. IEEE.\n\nLightgbm: A highly e cient gradient boosting decision tree. G Ke, Q Meng, T Finley, T Wang, W Chen, W Ma, Q Ye, T.-Y Liu, Advances in neural information processing systems. Ke, G., Meng, Q., Finley, T., Wang, T., Chen, W., Ma, W., Ye, Q., and Liu, T.-Y. (2017). Lightgbm: A highly e cient gradient boosting decision tree. In Advances in neural information processing systems, pages 3146-3154.\n\nAutomating feature engineering. U Khurana, F Nargesian, H Samulowitz, E Khalil, D Turaga, Transformation. 101010Khurana, U., Nargesian, F., Samulowitz, H., Khalil, E., and Turaga, D. (2016). Automating feature engineering. Transformation, 10(10):10.\n\nFeature engineering for predictive modeling using reinforcement learning. U Khurana, H Samulowitz, D Turaga, Thirty-Second AAAI Conference on Arti cial Intelligence. Khurana, U., Samulowitz, H., and Turaga, D. (2018). Feature engineering for predictive modeling using reinforcement learning. In Thirty-Second AAAI Conference on Arti cial Intelligence.\n\nAdam: A method for stochastic optimization. D Kingma, J Ba, International Conference on Learning Representations. Kingma, D. and Ba, J. (2014). Adam: A method for stochastic optimization. International Conference on Learning Representations.\n\nOne button machine for automating feature engineering in relational databases. H T Lam, J.-M Thiebaut, M Sinn, B Chen, T Mai, Alkan , O , arXiv:1706.00327arXiv preprintLam, H. T., Thiebaut, J.-M., Sinn, M., Chen, B., Mai, T., and Alkan, O. (2017). One button machine for automating feature engineering in relational databases. arXiv preprint arXiv:1706.00327.\n\nDarts: Di erentiable architecture search. H Liu, K Simonyan, Yang , Y , International Conference on Learning Representations. Liu, H., Simonyan, K., and Yang, Y. (2018). Darts: Di erentiable architecture search. In International Conference on Learning Representations.\n\nNeural architecture optimization. R Luo, F Tian, T Qin, E Chen, T.-Y Liu, Advances in neural information processing systems. Luo, R., Tian, F., Qin, T., Chen, E., and Liu, T.-Y. (2018). Neural architecture optimization. In Advances in neural information processing systems, pages 7816-7827.\n\nLearning feature engineering for classi cation. F Nargesian, H Samulowitz, U Khurana, E B Khalil, D S Turaga, IJCAI. Nargesian, F., Samulowitz, H., Khurana, U., Khalil, E. B., and Turaga, D. S. (2017). Learning feature engineering for classi cation. In IJCAI, pages 2529-2535.\n\nDistribution-free Multiple Comparisons. P Nemenyi, Princeton UniversityNemenyi, P. (1963). Distribution-free Multiple Comparisons. Princeton University.\n\nA survey of forecast error measures. M V Shcherbakov, A Brebels, N L Shcherbakova, A P Tyukov, T A Janovsky, V A Kamaev, World Applied Sciences Journal. 24Shcherbakov, M. V., Brebels, A., Shcherbakova, N. L., Tyukov, A. P., Janovsky, T. A., and Kamaev, V. A. (2013). A survey of forecast error measures. World Applied Sciences Journal, 24(24):171-176.\n\nA tutorial on support vector regression. A J Smola, B Sch\u00f6lkopf, Statistics and computing. 143Smola, A. J. and Sch\u00f6lkopf, B. (2004). A tutorial on support vector regression. Statistics and computing, 14(3):199-222.\n\nRegression shrinkage and selection via the lasso. R Tibshirani, Journal of the Royal Statistical Society: Series B (Methodological). 581Tibshirani, R. (1996). Regression shrinkage and selection via the lasso. Journal of the Royal Statistical Society: Series B (Methodological), 58(1):267-288.\n\nOpenml: Networked science in machine learning. J Vanschoren, J N Van Rijn, B Bischl, L Torgo, SIGKDD Exploration Newsletter. 152Vanschoren, J., van Rijn, J. N., Bischl, B., and Torgo, L. (2014). Openml: Networked science in machine learning. SIGKDD Exploration Newsletter, 15(2):49-60.\n\nNeural architecture search with reinforcement learning. B Zoph, Q V Le, Zoph, B. and Le, Q. V. (2017). Neural architecture search with reinforcement learning. In ICLR 2017.\n", "annotations": {"author": "[{\"end\":139,\"start\":54},{\"end\":222,\"start\":140},{\"end\":309,\"start\":223},{\"end\":394,\"start\":310}]", "publisher": null, "author_last_name": "[{\"end\":66,\"start\":63},{\"end\":149,\"start\":147},{\"end\":236,\"start\":232},{\"end\":321,\"start\":316}]", "author_first_name": "[{\"end\":62,\"start\":54},{\"end\":146,\"start\":140},{\"end\":231,\"start\":223},{\"end\":315,\"start\":310}]", "author_affiliation": "[{\"end\":138,\"start\":68},{\"end\":221,\"start\":151},{\"end\":308,\"start\":238},{\"end\":393,\"start\":323}]", "title": "[{\"end\":51,\"start\":1},{\"end\":445,\"start\":395}]", "venue": null, "abstract": "[{\"end\":1729,\"start\":447}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b13\"},\"end\":2515,\"start\":2482},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":2532,\"start\":2515},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":2895,\"start\":2873},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":3107,\"start\":3083},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":3304,\"start\":3285},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":6127,\"start\":6094},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":6309,\"start\":6291},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":6560,\"start\":6538},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":6747,\"start\":6728},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":7042,\"start\":7018},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":7261,\"start\":7239},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":7536,\"start\":7515},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":7617,\"start\":7600},{\"attributes\":{\"ref_id\":\"b27\"},\"end\":7682,\"start\":7663},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":7956,\"start\":7937},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":8551,\"start\":8533},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":10637,\"start\":10618},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":10663,\"start\":10639},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":10702,\"start\":10680},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":13942,\"start\":13923},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":13969,\"start\":13951},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":16087,\"start\":16053},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":16666,\"start\":16643},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":18174,\"start\":18156},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":18806,\"start\":18787},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":18872,\"start\":18848},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":18909,\"start\":18889},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":18928,\"start\":18915},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":19271,\"start\":19247},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":19700,\"start\":19674},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":20613,\"start\":20592},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":21648,\"start\":21615},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":21723,\"start\":21704},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":21831,\"start\":21807},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":21932,\"start\":21913},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":22049,\"start\":22028},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":22470,\"start\":22446},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":25929,\"start\":25905},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":25988,\"start\":25963},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":26046,\"start\":26021},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":26096,\"start\":26079},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":26202,\"start\":26184},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":26264,\"start\":26237},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":26324,\"start\":26299},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":26375,\"start\":26358},{\"end\":29215,\"start\":29211},{\"end\":30286,\"start\":30282},{\"end\":30385,\"start\":30380},{\"end\":30731,\"start\":30726},{\"end\":30939,\"start\":30934},{\"end\":31118,\"start\":31113},{\"end\":31245,\"start\":31240},{\"end\":31403,\"start\":31398},{\"end\":31816,\"start\":31811},{\"end\":31864,\"start\":31860},{\"end\":31948,\"start\":31944},{\"end\":32119,\"start\":32115},{\"end\":32253,\"start\":32248},{\"end\":32642,\"start\":32637},{\"end\":32829,\"start\":32825},{\"end\":32937,\"start\":32933},{\"end\":33114,\"start\":33110},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":34884,\"start\":34864},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":36107,\"start\":36094},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":37139,\"start\":37125}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":37882,\"start\":37747},{\"attributes\":{\"id\":\"fig_1\"},\"end\":37937,\"start\":37883},{\"attributes\":{\"id\":\"fig_2\"},\"end\":37978,\"start\":37938},{\"attributes\":{\"id\":\"fig_3\"},\"end\":38141,\"start\":37979},{\"attributes\":{\"id\":\"fig_4\"},\"end\":38184,\"start\":38142},{\"attributes\":{\"id\":\"fig_5\"},\"end\":38341,\"start\":38185},{\"attributes\":{\"id\":\"fig_6\"},\"end\":38779,\"start\":38342},{\"attributes\":{\"id\":\"fig_7\"},\"end\":39020,\"start\":38780},{\"attributes\":{\"id\":\"fig_8\"},\"end\":39205,\"start\":39021},{\"attributes\":{\"id\":\"fig_9\"},\"end\":39373,\"start\":39206},{\"attributes\":{\"id\":\"fig_10\"},\"end\":39747,\"start\":39374},{\"attributes\":{\"id\":\"fig_11\"},\"end\":39814,\"start\":39748},{\"attributes\":{\"id\":\"fig_12\"},\"end\":39848,\"start\":39815},{\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"},\"end\":42607,\"start\":39849},{\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"},\"end\":43250,\"start\":42608},{\"attributes\":{\"id\":\"tab_4\",\"type\":\"table\"},\"end\":43456,\"start\":43251},{\"attributes\":{\"id\":\"tab_5\",\"type\":\"table\"},\"end\":43760,\"start\":43457},{\"attributes\":{\"id\":\"tab_6\",\"type\":\"table\"},\"end\":44887,\"start\":43761}]", "paragraph": "[{\"end\":3658,\"start\":1745},{\"end\":4645,\"start\":3660},{\"end\":4989,\"start\":4647},{\"end\":5704,\"start\":4991},{\"end\":6899,\"start\":5721},{\"end\":8679,\"start\":6901},{\"end\":8928,\"start\":8681},{\"end\":9600,\"start\":8966},{\"end\":9760,\"start\":9602},{\"end\":9765,\"start\":9762},{\"end\":9886,\"start\":9767},{\"end\":10277,\"start\":9927},{\"end\":10807,\"start\":10309},{\"end\":11057,\"start\":10829},{\"end\":11369,\"start\":11089},{\"end\":11432,\"start\":11371},{\"end\":12407,\"start\":11434},{\"end\":12699,\"start\":12409},{\"end\":13013,\"start\":12701},{\"end\":13740,\"start\":13015},{\"end\":14262,\"start\":13767},{\"end\":14431,\"start\":14418},{\"end\":15341,\"start\":14460},{\"end\":15856,\"start\":15363},{\"end\":16250,\"start\":15858},{\"end\":16403,\"start\":16252},{\"end\":16800,\"start\":16405},{\"end\":17240,\"start\":16802},{\"end\":17693,\"start\":17340},{\"end\":18290,\"start\":17712},{\"end\":18720,\"start\":18306},{\"end\":19315,\"start\":18759},{\"end\":20138,\"start\":19317},{\"end\":20779,\"start\":20140},{\"end\":21318,\"start\":20781},{\"end\":24270,\"start\":21350},{\"end\":24497,\"start\":24325},{\"end\":25530,\"start\":24525},{\"end\":25763,\"start\":25532},{\"end\":26400,\"start\":25809},{\"end\":27141,\"start\":26402},{\"end\":27446,\"start\":27143},{\"end\":27951,\"start\":27493},{\"end\":29074,\"start\":27982},{\"end\":29153,\"start\":29076},{\"end\":29484,\"start\":29155},{\"end\":29641,\"start\":29486},{\"end\":30182,\"start\":29643},{\"end\":30834,\"start\":30184},{\"end\":31629,\"start\":30836},{\"end\":31725,\"start\":31631},{\"end\":31732,\"start\":31727},{\"end\":32001,\"start\":31734},{\"end\":32172,\"start\":32003},{\"end\":32416,\"start\":32174},{\"end\":32983,\"start\":32418},{\"end\":33191,\"start\":32985},{\"end\":33495,\"start\":33241},{\"end\":33566,\"start\":33497},{\"end\":34152,\"start\":33710},{\"end\":34325,\"start\":34195},{\"end\":34511,\"start\":34368},{\"end\":34741,\"start\":34539},{\"end\":35162,\"start\":34776},{\"end\":35950,\"start\":35179},{\"end\":37403,\"start\":35978},{\"end\":37746,\"start\":37435}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":9926,\"start\":9887},{\"attributes\":{\"id\":\"formula_1\"},\"end\":10308,\"start\":10278},{\"attributes\":{\"id\":\"formula_2\"},\"end\":14280,\"start\":14263},{\"attributes\":{\"id\":\"formula_3\"},\"end\":14326,\"start\":14303},{\"attributes\":{\"id\":\"formula_4\"},\"end\":17316,\"start\":17241},{\"attributes\":{\"id\":\"formula_5\"},\"end\":17711,\"start\":17694},{\"attributes\":{\"id\":\"formula_6\"},\"end\":18305,\"start\":18291},{\"attributes\":{\"id\":\"formula_7\"},\"end\":24324,\"start\":24271},{\"attributes\":{\"id\":\"formula_8\"},\"end\":33709,\"start\":33567},{\"attributes\":{\"id\":\"formula_9\"},\"end\":34367,\"start\":34326},{\"attributes\":{\"id\":\"formula_10\"},\"end\":34538,\"start\":34512}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":22212,\"start\":22205},{\"attributes\":{\"ref_id\":\"tab_3\"},\"end\":22537,\"start\":22530},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":22563,\"start\":22544},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":24834,\"start\":24827},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":24907,\"start\":24900},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":24955,\"start\":24948},{\"attributes\":{\"ref_id\":\"tab_4\"},\"end\":27712,\"start\":27705},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":36063,\"start\":36056},{\"attributes\":{\"ref_id\":\"tab_2\"},\"end\":36303,\"start\":36296},{\"attributes\":{\"ref_id\":\"tab_5\"},\"end\":37216,\"start\":37209},{\"attributes\":{\"ref_id\":\"tab_6\"},\"end\":37553,\"start\":37546}]", "section_header": "[{\"attributes\":{\"n\":\"1\"},\"end\":1743,\"start\":1731},{\"attributes\":{\"n\":\"2\"},\"end\":5719,\"start\":5707},{\"attributes\":{\"n\":\"3\"},\"end\":8942,\"start\":8931},{\"attributes\":{\"n\":\"3.1\"},\"end\":8964,\"start\":8945},{\"attributes\":{\"n\":\"3.2\"},\"end\":10827,\"start\":10810},{\"end\":11087,\"start\":11060},{\"attributes\":{\"n\":\"3.3\"},\"end\":13765,\"start\":13743},{\"end\":14302,\"start\":14282},{\"end\":14366,\"start\":14328},{\"end\":14394,\"start\":14369},{\"end\":14416,\"start\":14397},{\"end\":14458,\"start\":14434},{\"attributes\":{\"n\":\"3.4\"},\"end\":15361,\"start\":15344},{\"attributes\":{\"n\":\"3.5\"},\"end\":17338,\"start\":17318},{\"attributes\":{\"n\":\"4\"},\"end\":18734,\"start\":18723},{\"attributes\":{\"n\":\"4.1\"},\"end\":18757,\"start\":18737},{\"attributes\":{\"n\":\"4.2\"},\"end\":21348,\"start\":21321},{\"attributes\":{\"n\":\"4.3\"},\"end\":24523,\"start\":24500},{\"attributes\":{\"n\":\"4.4\"},\"end\":25807,\"start\":25766},{\"attributes\":{\"n\":\"4.5\"},\"end\":27491,\"start\":27449},{\"attributes\":{\"n\":\"5\"},\"end\":27980,\"start\":27954},{\"end\":33239,\"start\":33194},{\"end\":34193,\"start\":34155},{\"end\":34774,\"start\":34744},{\"end\":35177,\"start\":35165},{\"end\":35976,\"start\":35953},{\"end\":37433,\"start\":37406},{\"end\":37758,\"start\":37748},{\"end\":37949,\"start\":37939},{\"end\":38196,\"start\":38186},{\"end\":39027,\"start\":39022},{\"end\":39380,\"start\":39375},{\"end\":39826,\"start\":39816},{\"end\":39859,\"start\":39850},{\"end\":42618,\"start\":42609},{\"end\":43261,\"start\":43252},{\"end\":43467,\"start\":43458},{\"end\":43771,\"start\":43762}]", "table": "[{\"end\":42607,\"start\":40310},{\"end\":43250,\"start\":42698},{\"end\":43456,\"start\":43330},{\"end\":43760,\"start\":43586},{\"end\":44887,\"start\":43932}]", "figure_caption": "[{\"end\":37882,\"start\":37760},{\"end\":37937,\"start\":37885},{\"end\":37978,\"start\":37951},{\"end\":38141,\"start\":37981},{\"end\":38184,\"start\":38144},{\"end\":38341,\"start\":38198},{\"end\":38779,\"start\":38344},{\"end\":39020,\"start\":38782},{\"end\":39205,\"start\":39029},{\"end\":39373,\"start\":39208},{\"end\":39747,\"start\":39382},{\"end\":39814,\"start\":39750},{\"end\":39848,\"start\":39828},{\"end\":40310,\"start\":39861},{\"end\":42698,\"start\":42620},{\"end\":43330,\"start\":43263},{\"end\":43586,\"start\":43469},{\"end\":43932,\"start\":43773}]", "figure_ref": "[{\"end\":10849,\"start\":10841},{\"end\":11037,\"start\":11029},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":13787,\"start\":13779},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":14617,\"start\":14609},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":15509,\"start\":15500},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":17006,\"start\":16997},{\"end\":24920,\"start\":24912},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":26714,\"start\":26705},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":27104,\"start\":27095},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":35311,\"start\":35302},{\"attributes\":{\"ref_id\":\"fig_12\"},\"end\":35325,\"start\":35316},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":35452,\"start\":35443},{\"attributes\":{\"ref_id\":\"fig_12\"},\"end\":35879,\"start\":35870}]", "bib_author_first_name": "[{\"end\":45171,\"start\":45170},{\"end\":45183,\"start\":45182},{\"end\":45190,\"start\":45189},{\"end\":45490,\"start\":45489},{\"end\":45498,\"start\":45497},{\"end\":45968,\"start\":45967},{\"end\":45976,\"start\":45975},{\"end\":45983,\"start\":45982},{\"end\":45990,\"start\":45989},{\"end\":45996,\"start\":45995},{\"end\":46005,\"start\":46004},{\"end\":46011,\"start\":46010},{\"end\":46019,\"start\":46018},{\"end\":46026,\"start\":46025},{\"end\":46035,\"start\":46034},{\"end\":46401,\"start\":46400},{\"end\":46411,\"start\":46410},{\"end\":46598,\"start\":46597},{\"end\":46813,\"start\":46812},{\"end\":46820,\"start\":46819},{\"end\":46928,\"start\":46927},{\"end\":46938,\"start\":46937},{\"end\":46940,\"start\":46939},{\"end\":46950,\"start\":46949},{\"end\":47113,\"start\":47112},{\"end\":47122,\"start\":47121},{\"end\":47132,\"start\":47131},{\"end\":47144,\"start\":47143},{\"end\":47157,\"start\":47156},{\"end\":47171,\"start\":47170},{\"end\":47181,\"start\":47180},{\"end\":47192,\"start\":47191},{\"end\":47199,\"start\":47198},{\"end\":47577,\"start\":47576},{\"end\":47583,\"start\":47582},{\"end\":47593,\"start\":47590},{\"end\":47597,\"start\":47596},{\"end\":47750,\"start\":47749},{\"end\":47764,\"start\":47763},{\"end\":47983,\"start\":47982},{\"end\":47991,\"start\":47990},{\"end\":47999,\"start\":47998},{\"end\":48363,\"start\":48362},{\"end\":48365,\"start\":48364},{\"end\":48377,\"start\":48376},{\"end\":48389,\"start\":48388},{\"end\":48391,\"start\":48390},{\"end\":48673,\"start\":48672},{\"end\":48675,\"start\":48674},{\"end\":48685,\"start\":48684},{\"end\":49065,\"start\":49064},{\"end\":49071,\"start\":49070},{\"end\":49079,\"start\":49078},{\"end\":49089,\"start\":49088},{\"end\":49097,\"start\":49096},{\"end\":49105,\"start\":49104},{\"end\":49111,\"start\":49110},{\"end\":49120,\"start\":49116},{\"end\":49431,\"start\":49430},{\"end\":49442,\"start\":49441},{\"end\":49455,\"start\":49454},{\"end\":49469,\"start\":49468},{\"end\":49479,\"start\":49478},{\"end\":49724,\"start\":49723},{\"end\":49735,\"start\":49734},{\"end\":49749,\"start\":49748},{\"end\":50047,\"start\":50046},{\"end\":50057,\"start\":50056},{\"end\":50325,\"start\":50324},{\"end\":50327,\"start\":50326},{\"end\":50337,\"start\":50333},{\"end\":50349,\"start\":50348},{\"end\":50357,\"start\":50356},{\"end\":50365,\"start\":50364},{\"end\":50376,\"start\":50371},{\"end\":50380,\"start\":50379},{\"end\":50649,\"start\":50648},{\"end\":50656,\"start\":50655},{\"end\":50671,\"start\":50667},{\"end\":50675,\"start\":50674},{\"end\":50911,\"start\":50910},{\"end\":50918,\"start\":50917},{\"end\":50926,\"start\":50925},{\"end\":50933,\"start\":50932},{\"end\":50944,\"start\":50940},{\"end\":51217,\"start\":51216},{\"end\":51230,\"start\":51229},{\"end\":51244,\"start\":51243},{\"end\":51255,\"start\":51254},{\"end\":51257,\"start\":51256},{\"end\":51267,\"start\":51266},{\"end\":51269,\"start\":51268},{\"end\":51487,\"start\":51486},{\"end\":51638,\"start\":51637},{\"end\":51640,\"start\":51639},{\"end\":51655,\"start\":51654},{\"end\":51666,\"start\":51665},{\"end\":51668,\"start\":51667},{\"end\":51684,\"start\":51683},{\"end\":51686,\"start\":51685},{\"end\":51696,\"start\":51695},{\"end\":51698,\"start\":51697},{\"end\":51710,\"start\":51709},{\"end\":51712,\"start\":51711},{\"end\":51995,\"start\":51994},{\"end\":51997,\"start\":51996},{\"end\":52006,\"start\":52005},{\"end\":52220,\"start\":52219},{\"end\":52511,\"start\":52510},{\"end\":52525,\"start\":52524},{\"end\":52527,\"start\":52526},{\"end\":52539,\"start\":52538},{\"end\":52549,\"start\":52548},{\"end\":52807,\"start\":52806},{\"end\":52815,\"start\":52814},{\"end\":52817,\"start\":52816}]", "bib_author_last_name": "[{\"end\":45180,\"start\":45172},{\"end\":45187,\"start\":45184},{\"end\":45197,\"start\":45191},{\"end\":45495,\"start\":45491},{\"end\":45507,\"start\":45499},{\"end\":45973,\"start\":45969},{\"end\":45980,\"start\":45977},{\"end\":45987,\"start\":45984},{\"end\":45993,\"start\":45991},{\"end\":46002,\"start\":45997},{\"end\":46008,\"start\":46006},{\"end\":46016,\"start\":46012},{\"end\":46023,\"start\":46020},{\"end\":46032,\"start\":46027},{\"end\":46040,\"start\":46036},{\"end\":46408,\"start\":46402},{\"end\":46418,\"start\":46412},{\"end\":46605,\"start\":46599},{\"end\":46817,\"start\":46814},{\"end\":46824,\"start\":46821},{\"end\":46935,\"start\":46929},{\"end\":46947,\"start\":46941},{\"end\":46957,\"start\":46951},{\"end\":47119,\"start\":47114},{\"end\":47129,\"start\":47123},{\"end\":47141,\"start\":47133},{\"end\":47154,\"start\":47145},{\"end\":47168,\"start\":47158},{\"end\":47178,\"start\":47172},{\"end\":47189,\"start\":47182},{\"end\":47196,\"start\":47193},{\"end\":47202,\"start\":47200},{\"end\":47580,\"start\":47578},{\"end\":47588,\"start\":47584},{\"end\":47761,\"start\":47751},{\"end\":47776,\"start\":47765},{\"end\":47988,\"start\":47984},{\"end\":47996,\"start\":47992},{\"end\":48006,\"start\":48000},{\"end\":48372,\"start\":48366},{\"end\":48386,\"start\":48378},{\"end\":48402,\"start\":48392},{\"end\":48555,\"start\":48549},{\"end\":48682,\"start\":48676},{\"end\":48700,\"start\":48686},{\"end\":49068,\"start\":49066},{\"end\":49076,\"start\":49072},{\"end\":49086,\"start\":49080},{\"end\":49094,\"start\":49090},{\"end\":49102,\"start\":49098},{\"end\":49108,\"start\":49106},{\"end\":49114,\"start\":49112},{\"end\":49124,\"start\":49121},{\"end\":49439,\"start\":49432},{\"end\":49452,\"start\":49443},{\"end\":49466,\"start\":49456},{\"end\":49476,\"start\":49470},{\"end\":49486,\"start\":49480},{\"end\":49732,\"start\":49725},{\"end\":49746,\"start\":49736},{\"end\":49756,\"start\":49750},{\"end\":50054,\"start\":50048},{\"end\":50060,\"start\":50058},{\"end\":50331,\"start\":50328},{\"end\":50346,\"start\":50338},{\"end\":50354,\"start\":50350},{\"end\":50362,\"start\":50358},{\"end\":50369,\"start\":50366},{\"end\":50653,\"start\":50650},{\"end\":50665,\"start\":50657},{\"end\":50915,\"start\":50912},{\"end\":50923,\"start\":50919},{\"end\":50930,\"start\":50927},{\"end\":50938,\"start\":50934},{\"end\":50948,\"start\":50945},{\"end\":51227,\"start\":51218},{\"end\":51241,\"start\":51231},{\"end\":51252,\"start\":51245},{\"end\":51264,\"start\":51258},{\"end\":51276,\"start\":51270},{\"end\":51495,\"start\":51488},{\"end\":51652,\"start\":51641},{\"end\":51663,\"start\":51656},{\"end\":51681,\"start\":51669},{\"end\":51693,\"start\":51687},{\"end\":51707,\"start\":51699},{\"end\":51719,\"start\":51713},{\"end\":52003,\"start\":51998},{\"end\":52016,\"start\":52007},{\"end\":52231,\"start\":52221},{\"end\":52522,\"start\":52512},{\"end\":52536,\"start\":52528},{\"end\":52546,\"start\":52540},{\"end\":52555,\"start\":52550},{\"end\":52812,\"start\":52808},{\"end\":52820,\"start\":52818}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":11212020},\"end\":45445,\"start\":45099},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":4650265},\"end\":45885,\"start\":45447},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":208102475},\"end\":46373,\"start\":45887},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":52874011},\"end\":46532,\"start\":46375},{\"attributes\":{\"id\":\"b4\"},\"end\":46777,\"start\":46534},{\"attributes\":{\"id\":\"b5\"},\"end\":46887,\"start\":46779},{\"attributes\":{\"id\":\"b6\",\"matched_paper_id\":52016139},\"end\":47110,\"start\":46889},{\"attributes\":{\"doi\":\"arXiv:1706.02677\",\"id\":\"b7\"},\"end\":47507,\"start\":47112},{\"attributes\":{\"id\":\"b8\"},\"end\":47723,\"start\":47509},{\"attributes\":{\"id\":\"b9\",\"matched_paper_id\":1915014},\"end\":47903,\"start\":47725},{\"attributes\":{\"id\":\"b10\",\"matched_paper_id\":58981501},\"end\":48331,\"start\":47905},{\"attributes\":{\"id\":\"b11\"},\"end\":48545,\"start\":48333},{\"attributes\":{\"id\":\"b12\"},\"end\":48603,\"start\":48547},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":206610380},\"end\":49002,\"start\":48605},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":3815895},\"end\":49396,\"start\":49004},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":24758072},\"end\":49647,\"start\":49398},{\"attributes\":{\"id\":\"b16\",\"matched_paper_id\":8175458},\"end\":50000,\"start\":49649},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":6628106},\"end\":50243,\"start\":50002},{\"attributes\":{\"doi\":\"arXiv:1706.00327\",\"id\":\"b18\"},\"end\":50604,\"start\":50245},{\"attributes\":{\"id\":\"b19\"},\"end\":50874,\"start\":50606},{\"attributes\":{\"id\":\"b20\",\"matched_paper_id\":52071151},\"end\":51166,\"start\":50876},{\"attributes\":{\"id\":\"b21\",\"matched_paper_id\":19165886},\"end\":51444,\"start\":51168},{\"attributes\":{\"id\":\"b22\"},\"end\":51598,\"start\":51446},{\"attributes\":{\"id\":\"b23\",\"matched_paper_id\":6986236},\"end\":51951,\"start\":51600},{\"attributes\":{\"id\":\"b24\",\"matched_paper_id\":15475},\"end\":52167,\"start\":51953},{\"attributes\":{\"id\":\"b25\",\"matched_paper_id\":16162039},\"end\":52461,\"start\":52169},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":4977460},\"end\":52748,\"start\":52463},{\"attributes\":{\"id\":\"b27\"},\"end\":52922,\"start\":52750}]", "bib_title": "[{\"end\":45168,\"start\":45099},{\"end\":45487,\"start\":45447},{\"end\":45965,\"start\":45887},{\"end\":46398,\"start\":46375},{\"end\":46595,\"start\":46534},{\"end\":46925,\"start\":46889},{\"end\":47747,\"start\":47725},{\"end\":47980,\"start\":47905},{\"end\":48670,\"start\":48605},{\"end\":49062,\"start\":49004},{\"end\":49428,\"start\":49398},{\"end\":49721,\"start\":49649},{\"end\":50044,\"start\":50002},{\"end\":50646,\"start\":50606},{\"end\":50908,\"start\":50876},{\"end\":51214,\"start\":51168},{\"end\":51635,\"start\":51600},{\"end\":51992,\"start\":51953},{\"end\":52217,\"start\":52169},{\"end\":52508,\"start\":52463}]", "bib_author": "[{\"end\":45182,\"start\":45170},{\"end\":45189,\"start\":45182},{\"end\":45199,\"start\":45189},{\"end\":45497,\"start\":45489},{\"end\":45509,\"start\":45497},{\"end\":45975,\"start\":45967},{\"end\":45982,\"start\":45975},{\"end\":45989,\"start\":45982},{\"end\":45995,\"start\":45989},{\"end\":46004,\"start\":45995},{\"end\":46010,\"start\":46004},{\"end\":46018,\"start\":46010},{\"end\":46025,\"start\":46018},{\"end\":46034,\"start\":46025},{\"end\":46042,\"start\":46034},{\"end\":46410,\"start\":46400},{\"end\":46420,\"start\":46410},{\"end\":46607,\"start\":46597},{\"end\":46819,\"start\":46812},{\"end\":46826,\"start\":46819},{\"end\":46937,\"start\":46927},{\"end\":46949,\"start\":46937},{\"end\":46959,\"start\":46949},{\"end\":47121,\"start\":47112},{\"end\":47131,\"start\":47121},{\"end\":47143,\"start\":47131},{\"end\":47156,\"start\":47143},{\"end\":47170,\"start\":47156},{\"end\":47180,\"start\":47170},{\"end\":47191,\"start\":47180},{\"end\":47198,\"start\":47191},{\"end\":47204,\"start\":47198},{\"end\":47582,\"start\":47576},{\"end\":47590,\"start\":47582},{\"end\":47596,\"start\":47590},{\"end\":47600,\"start\":47596},{\"end\":47763,\"start\":47749},{\"end\":47778,\"start\":47763},{\"end\":47990,\"start\":47982},{\"end\":47998,\"start\":47990},{\"end\":48008,\"start\":47998},{\"end\":48376,\"start\":48362},{\"end\":48388,\"start\":48376},{\"end\":48404,\"start\":48388},{\"end\":48557,\"start\":48549},{\"end\":48684,\"start\":48672},{\"end\":48702,\"start\":48684},{\"end\":49070,\"start\":49064},{\"end\":49078,\"start\":49070},{\"end\":49088,\"start\":49078},{\"end\":49096,\"start\":49088},{\"end\":49104,\"start\":49096},{\"end\":49110,\"start\":49104},{\"end\":49116,\"start\":49110},{\"end\":49126,\"start\":49116},{\"end\":49441,\"start\":49430},{\"end\":49454,\"start\":49441},{\"end\":49468,\"start\":49454},{\"end\":49478,\"start\":49468},{\"end\":49488,\"start\":49478},{\"end\":49734,\"start\":49723},{\"end\":49748,\"start\":49734},{\"end\":49758,\"start\":49748},{\"end\":50056,\"start\":50046},{\"end\":50062,\"start\":50056},{\"end\":50333,\"start\":50324},{\"end\":50348,\"start\":50333},{\"end\":50356,\"start\":50348},{\"end\":50364,\"start\":50356},{\"end\":50371,\"start\":50364},{\"end\":50379,\"start\":50371},{\"end\":50383,\"start\":50379},{\"end\":50655,\"start\":50648},{\"end\":50667,\"start\":50655},{\"end\":50674,\"start\":50667},{\"end\":50678,\"start\":50674},{\"end\":50917,\"start\":50910},{\"end\":50925,\"start\":50917},{\"end\":50932,\"start\":50925},{\"end\":50940,\"start\":50932},{\"end\":50950,\"start\":50940},{\"end\":51229,\"start\":51216},{\"end\":51243,\"start\":51229},{\"end\":51254,\"start\":51243},{\"end\":51266,\"start\":51254},{\"end\":51278,\"start\":51266},{\"end\":51497,\"start\":51486},{\"end\":51654,\"start\":51637},{\"end\":51665,\"start\":51654},{\"end\":51683,\"start\":51665},{\"end\":51695,\"start\":51683},{\"end\":51709,\"start\":51695},{\"end\":51721,\"start\":51709},{\"end\":52005,\"start\":51994},{\"end\":52018,\"start\":52005},{\"end\":52233,\"start\":52219},{\"end\":52524,\"start\":52510},{\"end\":52538,\"start\":52524},{\"end\":52548,\"start\":52538},{\"end\":52557,\"start\":52548},{\"end\":52814,\"start\":52806},{\"end\":52822,\"start\":52814}]", "bib_venue": "[{\"end\":45692,\"start\":45609},{\"end\":45255,\"start\":45199},{\"end\":45607,\"start\":45509},{\"end\":46098,\"start\":46042},{\"end\":46436,\"start\":46420},{\"end\":46643,\"start\":46607},{\"end\":46810,\"start\":46779},{\"end\":46978,\"start\":46959},{\"end\":47278,\"start\":47220},{\"end\":47574,\"start\":47509},{\"end\":47796,\"start\":47778},{\"end\":48090,\"start\":48008},{\"end\":48360,\"start\":48333},{\"end\":48782,\"start\":48702},{\"end\":49175,\"start\":49126},{\"end\":49502,\"start\":49488},{\"end\":49813,\"start\":49758},{\"end\":50114,\"start\":50062},{\"end\":50322,\"start\":50245},{\"end\":50730,\"start\":50678},{\"end\":50999,\"start\":50950},{\"end\":51283,\"start\":51278},{\"end\":51484,\"start\":51446},{\"end\":51751,\"start\":51721},{\"end\":52042,\"start\":52018},{\"end\":52300,\"start\":52233},{\"end\":52586,\"start\":52557},{\"end\":52804,\"start\":52750}]"}}}, "year": 2023, "month": 12, "day": 17}