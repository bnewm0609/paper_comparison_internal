{"id": 222305243, "updated": "2022-01-21 04:13:49.461", "metadata": {"title": "DUAL: Acceleration of Clustering Algorithms using Digital-based Processing In-Memory", "authors": "[{\"middle\":[],\"last\":\"Imani\",\"first\":\"Mohsen\"},{\"middle\":[],\"last\":\"Pampana\",\"first\":\"Saikishan\"},{\"middle\":[],\"last\":\"Gupta\",\"first\":\"Saransh\"},{\"middle\":[],\"last\":\"Zhou\",\"first\":\"Minxuan\"},{\"middle\":[],\"last\":\"Kim\",\"first\":\"Yeseong\"},{\"middle\":[],\"last\":\"Rosing\",\"first\":\"Tajana\"}]", "venue": "2020 53rd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)", "journal": "2020 53rd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO)", "publication_date": {"year": 2020, "month": null, "day": null}, "abstract": "Today\u2019s applications generate a large amount of data that need to be processed by learning algorithms. In practice, the majority of the data are not associated with any labels. Unsupervised learning, i.e., clustering methods, are the most commonly used algorithms for data analysis. However, running clustering algorithms on traditional cores results in high energy consumption and slow processing speed due to a large amount of data movement between memory and processing units. In this paper, we propose DUAL, a Digital-based Unsupervised learning AcceLeration, which supports a wide range of popular algorithms on conventional crossbar memory. Instead of working with the original data, DUAL maps all data points into high-dimensional space, replacing complex clustering operations with memory-friendly operations. We accordingly design a PIM-based architecture that supports all essential operations in a highly parallel and scalable way. DUAL supports a wide range of essential operations and enables in-place computations, allowing data points to remain in memory. We have evaluated DUAL on several popular clustering algorithms for a wide range of large-scale datasets. Our evaluation shows that DUAL provides a comparable quality to existing clustering algorithms while using a binary representation and a simplified distance metric. DUAL also provides 58.8\u00d7 speedup and 251.2\u00d7 energy efficiency improvement as compared to the state-of-the-art solution running on GPU.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": "3103415979", "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "conf/micro/ImaniPGZKR20", "doi": "10.1109/micro50266.2020.00039"}}, "content": {"source": {"pdf_hash": "529cdb76e1d5ad36379324a9e8b63f763acc9b75", "pdf_src": "IEEE", "pdf_uri": null, "oa_url_match": false, "oa_info": null}, "grobid": {"id": "a1c9a025a2e4a933ee6184a3434e328f3804cb03", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/529cdb76e1d5ad36379324a9e8b63f763acc9b75.txt", "contents": "\nDUAL: Acceleration of Clustering Algorithms using Digital-based Processing In-Memory\n\n\nMohsen Imani m.imani@uci.edu \nDepartment of Computer Science\nUC Irvine\n\n\nSaikishan Pampana spampana@ucsd.edu \nDepartment of Computer Science and Engineering\nUC San Diego\n\n\nSaransh Gupta sgupta@ucsd.edu \nDepartment of Computer Science and Engineering\nUC San Diego\n\n\nMinxuan Zhou \nDepartment of Computer Science and Engineering\nUC San Diego\n\n\nYeseong Kim yeseongkim@dgist.ac.kr \nDepartment of Information and Communication Engineering\nDGIST\n\n\nTajana Rosing tajana@ucsd.edu \nDepartment of Computer Science and Engineering\nUC San Diego\n\n\nDUAL: Acceleration of Clustering Algorithms using Digital-based Processing In-Memory\n10.1109/MICRO50266.2020.00039Index Terms-Processing in-memoryUnsupervised learningHyperdimensional computingAlgorithm-hardware co-design\nToday's applications generate a large amount of data that need to be processed by learning algorithms. In practice, the majority of the data are not associated with any labels. Unsupervised learning, i.e., clustering methods, are the most commonly used algorithms for data analysis. However, running clustering algorithms on traditional cores results in high energy consumption and slow processing speed due to a large amount of data movement between memory and processing units. In this paper, we propose DUAL, a Digital-based Unsupervised learning AcceLeration, which supports a wide range of popular algorithms on conventional crossbar memory. Instead of working with the original data, DUAL maps all data points into highdimensional space, replacing complex clustering operations with memory-friendly operations. We accordingly design a PIM-based architecture that supports all essential operations in a highly parallel and scalable way. DUAL supports a wide range of essential operations and enables in-place computations, allowing data points to remain in memory. We have evaluated DUAL on several popular clustering algorithms for a wide range of large-scale datasets. Our evaluation shows that DUAL provides a comparable quality to existing clustering algorithms while using a binary representation and a simplified distance metric. DUAL also provides 58.8\u00d7 speedup and 251.2\u00d7 energy efficiency improvement as compared to the state-of-the-art solution running on GPU.\n\nI. INTRODUCTION\n\nWith the emergence of the Internet of Things (IoT), sensory and embedded devices generate massive data streams and demand services that pose huge technical challenges due to limited device resources. Today IoT applications analyze raw data by running machine learning algorithms. Since the majority of data generated are not associated with any labels, clustering algorithms are the most popular learning methods used for data analysis [1]. Clustering algorithms are unsupervised and have applications in many fields including machine learning, pattern recognition, image analysis, information retrieval, bioinformatics, data compression, and computer graphics [2]- [5]. These algorithms are used to group a set of objects into different classes, so that objects within the same class are similar to each other. The process of clustering datasets involves heavy computations as most algorithms need to calculate pairwise distances between all the points in the dataset [6]- [8].\n\nRunning clustering algorithms with large datasets on conventional processors results in high energy consumption and slow processing speed. Although new processor technology has evolved to serve computationally complex tasks more efficiently, data movement costs between the processor and memory still hinder the higher efficiency of application performance. Processing in-memory (PIM) is a promising solution to accelerate applications with a large amount of parallelism [9]- [16]. Several recent works have explored the advantage of PIMbased architectures to accelerate supervised learning algorithms such as Deep Neural Networks (DNNs) [17], [18]. These approaches mostly use PIM architecture as a dot product engine to perform the vector-matrix multiplication involved in the DNN computation.\n\nThere are three main challenges in using existing PIM architectures to accelerate clustering algorithms: (i) the main operations involved in clustering algorithms are pairwise distance computation, e.g., Euclidean distance, and similarity search which cannot be supported entirely by existing PIM architectures [16]. (ii) Most existing PIM architectures are analog-based [15], [17], [18]; thus they use Digital-to-Analog Converter (DAC) blocks to transfer data to the analog domain for the computation and Analog-to-Digital Converter (ADC) to transfer it back to the digital domain. In the existing PIM architectures, the DAC/ADC blocks are dominating the total chip power/area, e.g., 98% of DNN accelerators [18], resulting in very low throughput/area. (iii) They require separate storage and computing memory units, resulting in a large amount of internal data movements. This not only reduces the computation efficiency but also affects the design scalability.\n\nIn this work, we present a digital-based PIM architecture, called DUAL, which accelerates a wide range of popular clustering algorithms on conventional crossbar memory. DUAL supports all essential clustering operations in memory, in a parallel and scalable way. DUAL eliminates the necessity of using any ADC/DAC blocks and addresses the internal data movement. The main contributions are listed as follows:\n\n\u2022 To the best of our knowledge, DUAL is the first digitalbased processing in-memory architecture that accelerates unsupervised learning tasks. In contrast to the existing PIM designs, DUAL enables all PIM computation on digital data stored in memory. This eliminates the necessity of using ADC/DAC blocks, providing high throughput/area. DUAL is also the first PIM architecture that support digital searchbased Hamming distance computing. \u2022 Instead of working on the original data, DUAL maps all data points into high-dimensional space enabling the main clustering operations to process in a hardware- friendly way. DUAL proposes a novel non-linear encoder that preserves the similarity of the neighbor values in high dimensional space. This encoding simplifies the distance similarity metric from Euclidean to Hamming distance. \u2022 We design a PIM architecture that accelerates various clustering algorithms on conventional crossbar memory. DUAL performs in-place computation in a highly parallel and scalable way, where the data points can be processed without transferring between the storage and computing blocks. Therefore, it eliminates internal data movements between memory blocks. The proposed solution supports a wide range of essential clustering operations, e.g., in-memory distance computations and the nearest search, which can be programmed in high-level languages. We have evaluated DUAL efficiency on several popular clustering algorithms and a wide range of large-scale datasets. Our evaluations show that DUAL provides a comparable quality of clustering to the baseline clustering algorithms. In terms of efficiency, DUAL provides 58.8\u00d7 speedup and 251.2\u00d7 energy efficiency improvement as compared to the state-of-the-art solution running on NVIDIA GTX 1080 GPU. Enabling 1% and 2% lower quality of clustering, DUAL speeds up the computation to 72.5\u00d7 and 87.4\u00d7 respectively.\n\n\nII. BACKGROUND\n\nClustering algorithms categorize data points based on the similarity between them in the space. These algorithms use different metrics to compute pairwise distance. Euclidean distance is a commonly used metric in most of the clustering algorithms such as K-means and hierarchical clustering [19]- [21]. Here we provide a detailed explanation of hierarchical clustering, one of the most popular and complex clustering algorithms [22]- [26] as an example. In Section VI-C, we explain how DUAL accelerates other popular clustering algorithms.\n\nHierarchical clustering is a class of clustering algorithms that start out with each data point being their own cluster [27] and then iterates over the data until only one cluster remains. In each iteration, two clusters are combined, hence reducing the number of clusters by one and so we have to iterate n (size of data set) times to finish clustering. This method of clustering has a time complexity of O(n 3 ) with space complexity of O(n 2 ) and hence is both compute and memory-bound as the size of the data set used in clustering increases. Figure 1 presents a high-level overview of hierarchical clustering. The first part of the algorithm uses a distance metric to find pairwise distances between all points in the dataset. State-of-theart implementations of hierarchical clustering use Euclidean distance for pairwise distance computation [24], [28], [29]. After creating the pairwise distance matrix, we iterate through all values in the matrix and find the pair of data points with the minimum distance. Then, it merges these selected data points into a single cluster. Finally, the algorithm updates the distance of the merged data points with respect to all other clusters based on an updated policy.\n\nThere are several different linkages to update the distance matrix: single-linkage, complete-linkage, average-linkage, and ward-linkage [30]. For disjoint clusters a i , a j , and a k with sizes s i , s j , and s k , the linkages are defined as follows:\nSingle \u2212 linkage : d(a i \u222a a j , a k ) = Min[d(a i , a k ), d(a j , a k )] Complete \u2212 linkage : d(a i \u222a a j , a k ) = Max[d(a i , a k ), d(a j , a k )] Average\u2212linkage : d(a i \u222aa j , a k ) = s i \u00d7 d(a i , a k ) + s j \u00d7 d(a j , a k ) s i + s j\nThe state-of-the-art algorithms are using Ward-linkage to update the pairwise distance matrix [31].\nd(a i \u222a a j , a k ) = C 1 \u00d7 d(a i , a k ) +C 2 \u00d7 d(a j , a k ) \u2212C 3 \u00d7 d(a i , a j ) C 1 = s i + s k s i + s j + s k ; C 2 = s j + s k s i + s j + s k ; C 3 = s k s i + s j + s k\nWe call C 1 , C 2 , and C 3 as Ward's coefficients. The clustering algorithm continues by iteratively finding the next two closet clusters in the distance matrix and merging them into a cluster.\n\n\nIII. DUAL OVERVIEW\n\nIn this paper, we propose DUAL, a novel platform to accelerate unsupervised learning in a fully digital PIM architecture. Figure 2a shows an overview of DUAL framework consisting of an HD-Mapper and a digital-based PIM accelerator. Instead of working on original data, our architecture maps all data points to long-size binary vectors. This data mapping replaces complex clustering operations with hardware friendly operations. DUAL also exploits the resistive characteristics of Non-Volatile Memory (NVM), in particular memristor devices [32], [33], to support all necessary clustering operations in memory.\n\n\nA. HD-Mapper\n\nThe goal of the HD-Mapper is to encode data points into high-dimensional vectors, called hypervector, such that the data can keep their similarity using a PIM-friendly Hamming distance metric. The HD-Mapper can be a Locality Sensitive Hashing (LSH) or any other encoding function [34]- [37]. There are several approaches based on Hyperdimensional (HD) computing to perform the encoding functionality. However, all existing approaches linearly map each input feature into the hyperspace [38]- [40]. In contrast, we propose HD-mapper that explicitly considers non-linear interactions between input features. The proposed encoding is inspired by the Radial Basis Function (RBF) kernel trick method [41], [42]. The underlying idea of HD-mapper is that data that is not linearly separable in original dimensions, might be linearly separable in higher dimensions. Consider certain functions K(x, y) which are equivalent to the dot product in a different space, such that\nK(x, y) = \u03a6(x) \u00b7 \u03a6(y), where \u03a6(\u00b7)\nis often a function for high dimensional projection. The RBF or Gaussian Kernel is the most popular kernel:\nK(x, y) = e \u2212||x\u2212y|| 2 2\u03c3 2\nWe can take advantage of this implicit mapping by replacing their decision function with a weighted sum of kernels:\nf (\u00b7) = N \u2211 i=0 c i K(\u00b7, x i )\nwhere (x i , y i ) is the training data sample, and the c i s are constant weights. The study in [41] showed that the inner product can efficiently approximate Radial Basis Function kernel:\nK(x, y) = \u03a6(x) \u00b7 \u03a6(y) \u2248 z(x) \u00b7 z(y)\nThe Gaussian kernel function can now be approximated by the dot product of two vectors, z(x) and z(y). Figure 3 shows our encoding procedure. Let us consider an encoding function that maps a feature vector\nF = { f 1 , f 2 , . . . , f m }, with m features ( f i \u2208 R) to a hypervector H = {h 1 , h 2 , . . . , h D } with D dimensions (h i \u2208 {0, 1}).\nWe generate each dimension of encoded data by calculating a dot product of feature vector with a randomly generated vector as h i = cos(B i \u00b7 F), where B i is a randomly generated vector from a Gaussian distribution (mean \u00b5 = 0 and standard deviation \u03c3 = 1) with the same dimensionality of the feature vector. The random vectors {B 1 , B 2 , \u00b7 \u00b7 \u00b7 , B D } can be generated once offline and then can be used for the rest of the classification task (B i \u2208 R m ). After this step, each element, h i of a hypervector H, has a non-binary value. We prefer binary hypervectors for computation efficiency. We thus obtain the final encoded hypervector by binarizing it with a sign function (H = sign(H)) where the sign function assigns all positive hypervector dimensions to '1' and zero/negative dimensions to '0'. The encoded hypervector stores the information of each original data point with D bits. HD-Mapper gives an analytical model to estimate the required dimensionality of the encoder depending on the number of data points and the number of clusters. The discussion about this estimation is out of the scope of our paper. More information can be found by looking at the amount of orthogonal information that each hypervector can store in the HD space [43].\n\n\nB. DUAL Accelerator\n\nThe second module is a digital-based PIM architecture that enables parallel encoding and clustering computation over the encoded hypervectors stored in memory. Unlike prior PIM designs that use large ADC/DAC blocks for analog computing [15], [17], [18], DUAL performs all clustering computations on the digital data stored in memory. This eliminates ADC/DAC blocks, resulting in high throughput/area and scalability. DUAL uses two blocks for performing the computation; a data block and a distance block. The data block stores the encoded data points and computes pairwise similarity using a row-parallel Hamming distance computation. Each distance/data block supports the following set of operations (shown in Figure 2b): (i) search-based operations: row parallel Hamming distance computation and nearest search. (ii) Arithmetic operations: row-parallel addition, multiplication and division. Figure 2c,d shows how DUAL maps hierarchical clustering into PIM acceleration. In each iteration, DUAL computes the Hamming distance of each data point with all stored data points in all data blocks using the row-parallel search operation and the result is written in a distance memory. After computing all pairwise distances, DUAL performs the search for the nearest value over the distance matrix. Our design supports the nearest search operation in a row-parallel way. Next, DUAL clusters the two data points with the highest similarity and then updates the relative distance of all other data points with the clustered nodes. The distance update is computed using linear arithmetic operations, e.g., addition, multiplication, which can be performed in a row-parallel way in the update block (Figure 2c,d). The updated distance vectors will be written back into the corresponding row/column of the distance block. DUAL continues computation by iteratively finding and clustering data points with the closest distance. DUAL exploits the supported PIM operations to perform clustering tasks where data is already stored in memory. DUAL also uses interconnects to enable bitserial/row-parallel data transfer between the data and distance blocks. This eliminates the overhead of internal data movement between the data and distance blocks (Figure 2c,d).\n\nIV. DUAL SUPPORTED OPERATIONS\n\n\nA. Search/Similarity Computation\n\nThe exact search is one of the native operations supported by crossbar memory. During the search, the crossbar memory gets the configuration of a Content Addressable Memory (CAM), where each CAM cell is represented using two memristor devices (0T-2R) [44], [45]. These devices store complementary values. During the search, a row-driver of the CAM block precharges all CAM rows (match-lines:MLs) to supply voltage (V dd ). The search operation starts by loading the input query into the vertical bit-lines (BLs) connected to all CAM rows. Similar to CAM cells, each input query is represented using two complementary bits. Consider a CAM cell (shown in Figure 4a), if a query input matches with the stored value in the CAM cell, the ML will stay charged. However, in case of a mismatch between the CAM cell and the query data, the CAM starts discharging the ML. Conventionally, CAM blocks exploit the ML discharging current to enable the exact search operation. Here, we modify the CAM block to enable Hamming distance computation and nearest search in a parallelized way. Note that although there are several work used NVM-based CAM to support the nearest absolute search functionalities [39], [46], DUAL is the first digital-based PIM architecture that supports Hamming computing without using costly ADC blocks. Figure 4b shows the architecture of the modified CAM block. Our design exploits the timing characteristic of ML discharging current in order to detect the Hamming distance of each CAM row with an input query. The search sense amplifier, \"CAM SA\" shown in Figure 4b, samples the ML current in different time stamps and finds the number of mismatches depending on the cycle that the ML voltage is dropped. Note that during Hamming computing, the detector circuit, shown in Figure 4b, is deactivated (En = 0). More mismatches between a query and CAM row results in a faster-discharging current of ML. ML discharging current does not change linearly with the number of mismatches when the search is performed on a long row with too many cells. As Figure 4c shows, when we search on a row with a 4-bit length, we can detect the difference between 2-bits, 3-bits, and 4-bits mismatching by sampling ML in linear time (200ps). However, considering a 7-bit CAM row, the mismatches of 6-bits and 7bits are happening much faster than 2-bits to 3-bits. This limits the maximum possible bit-search parallelism to 4-bits using linear search. In contrast, we propose a non-linear sampling time, shown in Figure 4c, which enables DUAL to search up to 7-bits in parallel.\n\n\n1) Hamming Distance Computation:\n\nTo enable fast Hamming distance computation, the distance result should be written in a row-parallel way on the distance memory block. This requires translating sampling time to a Hamming distance and writing it into the distance block. However, this approach requires an extra processing step. Here, we present an approach that enables the result of the 7-bit Hamming distance search to be written in the distance memory in a single cycle. Our approach assigns a single 3-bit counter to each memory block, where the counter value increments with the same clock used for the search sampling. Depending on the discharge CAM rows in each sampling time, DUAL activates corresponding rows of the distance memory. Finally, DUAL writes the counter value on all selected rows in the distance block. Write operation happens in a row-parallel way, where all activated rows will get counter values in a single write cycle.\n\nThe write latency in the non-volatile memory is slower than the search operation frequency (1ns write latency vs. 200ps/100ps search sample). Therefore, to provide high throughput, we use a 7-bit register next to each data block in order to store the sampling time that each row has been discharged. After the Hamming distance computation, DUAL sequentially activates the rows of distance block (depending on the values stored in each column of the buffer), and accordingly writes the counter values to them. DUAL performs the Hamming distance computation serially on 7-bits windows. The result of distance computation will be written as D/7 values of 3-bits on the distance memory (shown in Figure 4b).\n\n2) Nearest Value Search: In the Hamming distance operation, DUAL computes the actual distance value of query, rather than finding a row with the nearest Hamming distance. However, the second popular clustering operation is to find a row that has the nearest distance to query data. In this search, the memory stores integer/fixed-point values, thus bits in different positions have different weights. To consider the impact of each bit indices, we weight different bitlines by connecting them to different bitline voltages. During the search, the most significant bits (MSBs) are assigned to a higher voltage than bits in lower positions (shown in Figure 4d,\nV 1 = 0.8V , V 2 = 0.4V , V 3 = 0.2V , V 4 = 0.1V ).\nBy adjusting the bitline voltages, we enable a 4-bit parallel search operation. In a nominal voltage/process technology, we can increase the number of bits up to 8-bits. However, considering variations in voltage and process technology, 4-bit parallel search provides enough noise margin, ensuring exact nearest search computation over 5000 Monte-carlo simulations (considering 10% variations in technology and memristor values).\n\nAssume a CAM block storing m bit integer numbers. The search for the nearest value starts from four MSBs. The first row that discharges the ML is the row which has the highest similarity with query data. Each discharging match-line flows a current into a detector circuit (shown in Figure 4b). In this mode, the detector circuit is activated (En = 1), and it has two responsibilities: (i) it stops the search operation by pre-charging all match-lines to V dd voltage, and (ii) it transfers the discharged rows to the output stage. The activated rows at the end of the search cycle (500ps) have the nearest distance to the query data. Depending on the row with the highest matches, DUAL activated those rows of the memory and continues the search operation on the next 4-bits. This sequential search increases the weight of the bits in the MSB as compared to the bit located in a lower stage. The search continues over all the bits, ending up with a single activated row in the last stage.\n\n\nB. Row-Parallel PIM-based Arithmetic\n\nDUAL supports arithmetic operations directly on digital data stored in memory without reading them out of sense amplifiers [16], [47]- [52]. Our design exploits the memristor switching characteristic to implement NOR gates in digital memory [16], [48]. DUAL selects two or more columns of the memory as input NOR operands by connecting them to ground voltage (Shown in Figure 4e). Next, DUAL connects the bitline corresponding to the output of NOR operation to a write voltage (V 0 ). In addition, all output memristors located in the output column are initialized to R ON in the beginning. To execute NOR in a row, an execution voltage, V 0 , is applied at the p terminals of the inputs while the p terminal of the output memristor is grounded, as shown in Figure 4e. During NOR computation, the output memristor is switched from R ON to R OFF when one or more inputs stored '1.' value (R ON ). In fact, the low resistance input passes a current through an output memristor resulting in writing R o f f value on it. This NOR computation performs in row-parallel on all the activated memory rows by the row-driver.\n\nSince NOR is a universal logic gate, it can be used to implement other logic operations like addition [53] and multiplication [54]. Our approach also supports division by approximately modeling it with the multiplication of numerator and the inverse of denominator [55]. The inversion is computed by filliping all denominator bits, adding it with 1, and left shifting of the result [55]. For example, 1-bit addition (inputs being A, B,C) can be represented in the form of NOR as,\nC out = ((A + B) + (B +C) + (C + A) ) . (1a) S = (((A + B +C ) + ((A + B +C) +C out ) ) ) .(1b)\nHere, C out and S are the generated carry and sum bits of addition. Also, (A + B + C) , (A + B) , and A represent NOR(A, B,C), NOR(A, B), and NOR(A, A) respectively. We need to reserve extra memory columns for DUAL arithmetic operations to store intermediate results (discussed in Section V and Table III). Note that DUAL can also support floating point arithmetic operations using the same approach shown in [16]. Note that arithmetic operations in DUAL are in general slower than the corresponding CMOS-based implementations. This is because memristor devices are slow in switching. However, this PIM architecture can provide significant speedup with massive parallelism. For example, DUAL takes the same amount of time for addition in a single row or all memory rows. However, the processing time in conventional cores highly depends on the data size. \n\n\nV. DUAL IMPLEMENTATION\n\n\nA. Encoding Implementation\n\nThe computation of the HD-Mapper is vector-matrix multiplication between the feature vector and the base vectors. This is followed by applying the cosine function on the dot-product result (as explained in Section III-A). DUAL accelerates the encoding module by performing a row-parallel in-memory multiplication and addition. Figure 5a shows the structure of DUAL accelerating encoding module on two crossbar memories: the first block computes the dot product of the input data with the base vectors, and the second block applies cosine functionality on the dot product result. These two blocks are working in a pipeline, meaning that when the first block computes the dot product of the i th data point, the second block computes the cosine similarity of the dot product result of the i \u2212 1 th data point. Figure 5b shows the layout of vectors stored in memory, implementing encoding computation.\n\nDot product Implementation: DUAL supports row-parallel arithmetic operations in memory. To execute the encoding using those operations, we perform multiplication of the input vector with the transposed base vectors stored in the same memory block. Figure 5 shows the overview of DUAL accelerating encoding module. Our design performs a row-parallel write operation to store multiple copies of a data point in different memory rows ({ f 1 , f 2 , \u00b7 \u00b7 \u00b7 , f m }), where features can be an integer or fixed-point number with any bitwidth. The rowparallel write can be performed by activating all memory rows during the write operation. The same memory block stores all base vectors ({B 1 , B 2 , \u00b7 \u00b7 \u00b7 , B D }) horizontally in different rows. For an application, base vectors are fixed; thus they need to be written in memory block only once. The encoding computation starts by multiplying each feature column with a corresponding column of base vectors. We use the reserved memory, shown in Figure 5b, to perform intermediate arithmetic operations and store the multiplication results. After covering the multiplication of all m features, DUAL performs a row-parallel in-memory addition to accumulate all multiplication results (Y = F \u00b7 B).\n\nCosine Implementation: Next, we apply the cosine function on the dot product (Y ). DUAL approximates cosine function by using the first three terms of Taylor expansion. DUAL sends two copies of the dot product vector to the next memory block (Block 2 shown in Figure 5b) in a row-parallel/bit-serial way. Then, it exploits in-memory multiplication to compute different powers of the product vector (Y 2 and Y 4 shown in Figure 5). DUAL multiplies the result vectors with the Taylor expansion coefficients, which are already pre-stored in the second memory block. Finally, our model computes the result of Taylor explanation by performing row-parallel addition/subtraction between different memory columns. We consider the inverse of output vector sign-bit as encoded data with binary representation. Note that DUAL uses the reserved memory to compute the intermediate results of Taylor's expansion.\n\nDUAL is a scalable architecture. If the number of base vectors exceeds the number of memory rows (D > 1k), we store the rest of the base vectors in another memory block.If the number of features exceeds the size of a block bitline, we compute the dot product results in two neighbor blocks and aggregate the dot product results before passing it through cosine function.\n\n\nB. Pairwise Distance Computation\n\nEncoding is a single-pass process. After encoding, DUAL starts the clustering task on the encoded data points stored in memory. DUAL exploits two types of memory blocks for clustering: (i) data blocks that store the encoded data points and are responsible for pairwise distance computation, (ii) distance blocks that store the pairwise distance matrix and perform the clustering task. DUAL assigns a column of the distance memory to store a flag bit and another column to store the size of the cluster ({s 1 , s 2 , \u00b7 \u00b7 \u00b7 , s n }). These sizes are initially set to 1, as each data point is a separate cluster. Figure 6 shows an overview of mapping Hierarchical clustering to DUAL hardware. Figure 7 also shows the layout of DUAL operations performing clustering in memory. Each data block supports a row-parallel Hamming distance computation (explained in Section IV-A1). DUAL first computes the distance of the first encoded data point (a 1 ) with all data stored in the data block ( Figure 6 \u2022 A ). The Hamming distance computation is performed serially over 7-bits windows. The distance results will be written as a 3-bit value in the distance memory. Assuming a data point with D dimensions, the distance memory stores D/7 3-bit values. DUAL exploits in-memory addition (explained in Section IV-B) to accumulate all the partial distance values in a row-parallel way. The results of accumulation are stored in the same memory block, only using log D bits. Note that when we compute the Hamming distance of a i to all data points, we write the maximum value on the diagonal distance well (d(a i , a i ) = D). This write happens after the accumulation of all 3-bits counters. We continue a similar search operation for all data points in order to find all pairwise distances.\n\n\nC. Nearest Cluster\n\nThe next step is to compare all distance values stored in the distance memory and find data points with the highest similarity. We exploit nearest search functionality (explained in Section IV-A2) to implement row-parallel minimum search. Our design starts the search operation in the first column of the distance memory with valid flag bit set by searching for a query which is actually the lowest value, i.e., 000...0. Any row which has the highest similarity to query data is the smallest value in the column (Figure 6 \u2022 B ). Next, we perform the same search operation on other columns of the distance memory with a valid flag bit set. After each search, DUAL writes a selected row along with its index in another memory block. Finally, the nearest search in that memory determines indices of the closest points.\n\n\nD. Distance Update\n\nAfter clustering two data points with the closest distance, the relative distances of all data points with the merged nodes need to be updated. DUAL supports all popular linkage distance update used for clustering algorithms. Here, we first explain the implementation of the Ward method, which is a popular and complex update method. Then, we explain how DUAL supports other linkages using the same operations. Ward Update: Ward update requires all data points to update their similarity with the new cluster data points (a i and a j ). Ward update has three coefficients and three distance values (explained in Section II). Our design first computes the numerator and denominator of the coefficients by: (i) performing a row-parallel write of the size of s i and s j on two columns of the coefficient block ( Figure 6 \u2022 C ). This write in all rows is performed in a single cycle. (ii) since the weight corresponding to each data point is already stored in the memory (s K column), we perform row-parallel inmemory addition to compute X : s i + s k and Y : s j + s k , and Z : s i + s j + s k , the numerator and denominator of the Ward coefficients ( Figure 6 \u2022 D ). (iii) Next, we compute the coefficients by performing row-parallel in-memory division of X, Y , and s k with the denominator (Figure 6 \u2022 E ) (explained in Section IV-B) .\n\nTo compute new distance of all data points to a i \u222a a j , we multiply each coefficient column with corresponding column of the distance memory storing d(a i , a k ), d(a j , a k ) (Figure 6 \u2022 F ).\n\nWe also multiply the third coefficient (C 3 ), with the distance of the clustered nodes, d(a i , a j ) which has been written in a row-parallel write on another column of the distance memory ( Figure 6 \u2022 C ). Finally, we add the first two terms of the Ward metric and subtract from it the third term stored in the same memory ( Figure 6 \u2022 G ). The result of this operation is stored in i th and j th columns of the distance memory. We also update i t h and j t h rows of the distance memory. Since these two nodes are clustered, we only update one of the rows (i th rows if s i > s j ), setting s i to s i + s j and unset the valid flag of s j ( Figure 6 \u2022 H ). Figure 7 shows the layout of DUAL operations performing hierarchical clustering in memory. All DUAL operations can perform column-wise using row-parallel search-based or arithmetic operations. Ideally, two memory blocks, i.e., data and distance blocks, can compute the entire clustering tasks. In section VI-A, we talk about the scalability of DUAL when the data size is much larger to fit into those memories. Other Linkage Updates: DUAL supports single and complete linkage by performing compare operation between two columns of the distance memory (d(a i , a k ) and d(a j , a k )). This comparison is performed by subtracting the distance vectors in a row parallel way and looking at the sign bit of the subtracted vector. Depending on the sign bit, we select one of the distance values as a relative distance to clustered data points. DUAL supports average linkage using a similar approach as Ward linkage. We perform row-parallel write of the s i and s j values and multiply them with the corresponding columns of the  DUAL consists of 64 tiles. Each tile consists of 256 crossbar memories. Due to the existing challenges of crossbar memory [56], [57], each memory block is assumed to have a size of 1k \u00d7 1k. The memory blocks located in each row of a tile are connected together using an interconnect. This interconnect sends the signals from the CAM sense amplifier of the data block to row drivers of all distance blocks. The interconnect enables the Hamming distance computation of the data block to be written in any distance block located in the same row. To minimize the cost of the interconnect, we enable bit-serial/rowparallel data transfer which limits the interconnect bandwidth to 1K-bits. A single 3-bit counter is located at the top of each crossbar memory. During each sampling cycle of Hamming distance computation, the interconnects transfer the activate rows to a destination distance block, and the counter values will be written in parallel on all the activated rows (Figure 8 \u2022 B ). do not fit in a single memory. DUAL assigns the first block of each tile row to a data block while others are assigned to distance block storing the pair-wise distances. DUAL provides both row-level and block-level parallelism. To enable fast Hamming computing, our design exploits interconnects to write the result of distance computation in any distance block located in the same row. In addition, the bit-serial/row-parallel data transfer between the neighbor blocks accelerates DUAL computation (Figure 8 \u2022 D ). To enable parallelism, DUAL stores multiple copies of the data blocks in other tiles to perform the distance computation and clustering in parallel. Although this approach speeds up the computation, it adds two overheads: (i) during the clustering, data located in different tiles need to be aggregated into a single memory block, this results in a large internal data movement. (ii) In this configuration, DUAL also requires a larger memory to store repeated data blocks. In Section VIII-F, we explore the impact of parallelism on DUAL computation efficiency.\n\n\nA. Scalability & Parallelism\n\n\nB. DUAL Pipeline\n\nWe design a pipeline that enables DUAL to work with maximum throughput. DUAL has two main phases: Hamming computing, and clustering. The Hamming computation happens only once, while the clustering phase repeats iteratively.\n\nHamming Computing Pipeline: Our pipeline initially assigns each distance block to store the relative Hamming distances corresponding to a single point. This starts by writing the Hamming distances relative to the first data point in the first distance memory. To maximize the throughput, DUAL continues the Hamming computing relative of the second data point and writes the results in the second distance block. At the same time, the first block accumulates all D/7 partial distances in order to represent them using log D bits. Typically, this accumulation is slow; thus the distance computation continues sequentially in multiple distance blocks until the first block becomes available. DUAL again uses the remaining bitlines of the first distance block (1k \u2212 log D bits) for distance computation of the next data points (Figure 8 \u2022 E ).\n\nClustering Pipeline: After creating a pairwise distance matrix, DUAL searches for the index with least Hamming distance in all distance blocks with valid flag bit set (\"Nearest\"). These indices along with the hamming distance are sent to another memory block which performs a comparison among the hamming distance to find the minimum distance (\"Comp\"). Based on the comparison result, DUAL first computes Ward coefficients and then transfers the corresponding vectors of the distance matrix into another block (\"Data Transfer\"). Finally, DUAL updates the distance vectors using the moved distance vectors and the computed Ward coefficients (\"Distance Update\"). This process continues iteratively until having one cluster.\n\n\nC. Other Clustering on DUAL\n\nDUAL is a general platform that can be used to accelerate a wide range of unsupervised learning algorithms. A similarity check is a common operation in most clustering problems. Here, we explain how DUAL can accelerate other popular algorithms by using Hamming similarity on the encoded data.\n\nDBSCAN: is another popular clustering algorithm [58]- [60]. DBSCAN starts the clustering from an initial data point. For the selected data point, it computes the Hamming distance with all encoded data points and clusters it to the data point  with the closest similarity. This clustering happens if the point with the maximum similarity is within a pre-defined \u03b5 distance. If it is not, DBSCAN selects another initial point and continues the clustering until merging all close enough points.\n\nWe map DBSCAN to DUAL in a very similar way to hierarchical clustering. Figure 9a shows the computation steps of DUAL accelerating DBSCAN. Our design stores all encoded data points in a data block. Then, it computes the Hamming distance of an initially selected data with all other data points in a row-parallel way. The partial Hamming distance values will be written in a distance memory and then accumulates in order to represent using a single logD bits value. Similar to hierarchical clustering, DUAL searches for the minimum Hamming distance value in a distance memory. The controller checks the distance of the selected point with \u03b5 and clusters selected points if their distance is within an acceptable range. The clustering happens by simply activating the flag bit of the clustered point, indicating that the point does not need to be involved in future similarity checks. The same procedure repeats by considering the recently clustered data point as a new clustering query.\n\nK-means: algorithm starts the clustering with a set of generated cluster centers [61]. The clustering continues by checking the similarity of each data point with all cluster centers and assigning it to a cluster with the highest similarity. The k-means stops the clustering if the changes between the centers in two consecutive iterations is less than a pre-defined \u03b5. Figure 9b shows the computation steps of DUAL accelerating k-means. DUAL exploits the same hardware to compute the distance of centers {c 1 1 , c 1 2 , \u00b7 \u00b7 \u00b7 , c 1 2 } to all data points stored in the data block. The result of distance computation will be written in all distance blocks (k columns each storing the distance relative to a center). Since the cluster centers are usually small, even a single distance block might be enough to store Hamming distances of all centers with data points (if k \u00d7 logD < 1k, where k is the number of centers). For each data point, DUAL compares the distance values over all centers using a series of row-parallel subtraction and writes the index of a center with the minimum distance on the index buffer. This minimum functionality is implemented in a rowparallel way by comparing the distance values two-by-two, starting from their most significant bits. After finding the index corresponding to all data points, we activate all rows of the data block corresponding to center 1. DUAL performs in-memory addition to accumulate the activated rows. In the next iterations, DUAL accumulates data points corresponding to other centers. The k accumulated values are the new centers. To stay in the binary, the controller binarizes the new centers and repeaters the clustering using the new centers. The controller also checks for the converges and stops the algorithm if the number of bit changes of cluster centers in two consecutive iterations is less than a pre-defined value.\n\n\nVII. PROGRAMMING SUPPORT\n\n\nA. Variable-Length Column Array\n\nAll DUAL operations (i.e., search and arithmetic) are columnwise. So, we introduce a family of data structures, Variable  \n\n\nB. Built-in Functions\n\nWe define several built-int functions as C library for implementing operations in DUAL using VLCAs as main operators. Row-Parallel Data Transfer: We copy the value of a vector to another vector by normal assignment statements a = b, with the same vector dimensionality. Data movements between VLCAs are processed by the PIM hardware in a row-parallel way, resulting in a single bit movement for all memory rows.\n\n\nC. PIM Interface\n\nAlgorithm 1 shows the DBSCAN implementation using DUAL interface. We implement a runtime library to transform the function calls into DUAL instructions issued through a custom device driver (listed in Table I). There are several specialized registers required for these PIM instructions. Registers starting with b, r, and c store values indicating the memory location in terms of the block, row, and column respectively. Register q stores query data. nr and nc represent the number of rows and columns for the current instruction.\n\nThe mapping of the function to the PIM instruction is straightforward; to allocate a VLCA, we should find enough space to store the vectors in consecutive rows. In our implementation, we exploit a simple management scheme that uses a list of free blocks with a global allocation table. Once an allocation is issued, it checks the free block list to return one or multiple pages with consecutive rows and adds an allocation entry into the allocation table to store the allocation information including the address, bit-width, and the number of elements. When an address is reclaimed, it returns the corresponding blocks to the list and merges the list items if needed. The more advanced management scheme (e.g., handling memory fragmentation) is out of our scope; there exist many solutions for similar problems, e.g., SSD and persistent memory [62], [63].\n\n\nD. Application Mapping\n\nIn DUAL, a register is located next to each memory that stores the sequence of operations that needs to be computed on the memory block. Each register, which acts as a controller for each memory block, is initialized once using the tile's controller. This initialization happens depending on several parameters including: clustering algorithm, number of pipeline stages, dimensionality, number of clusters, number of data points, and computation precision. Depending on these factors, our software interface estimates the worst-case memory requirement for each pipeline stage and decides the suitable data layout that results in maximum parallelism. We pre-evaluate each clustering algorithm once offline. This enables our software interface to find an optimal data layout and register/instructor values using a very limited algorithm and workload parameters.\n\nVIII. RESULTS\n\n\nA. Experimental Setup\n\nWe have designed a cycle-accurate simulator based on scikit-learn [64], [65] that emulates DUAL functionality during different clustering algorithms. For the hardware design, we use HSPICE for circuit-level simulations to measure the energy consumption and performance of all the DUAL operations in 28nm technology. Energy consumption and performance are also cross-validated using NVSim [66]. We used system Verilog and Synopsys Design Compiler [67] to implement and synthesize the DUAL controller. For parasitics, we used the same simulation setup considered by work in [53]. In DUAL, the interconnects are model in both circuit and architecture levels. In circuit-level, we simulate the cost of inter-tile communication while in architecture we model and evaluate intra-tile communications. The robustness of all proposed circuits, i.e., interconnect, has been verified by considering 10% process variations on the size and threshold voltage of transistors using 5000 Monte Carlo simulations. DUAL works with any bipolar resistive technology which is the most commonly used in existing NVMs. In order to have the highest similarity to commercially available 3D Xpoint, we adopt the memristor device with a VTEAM model [68]. The model parameters of the memristor are chosen to produce a switching delay of 1ns, a voltage pulse of 1V and 2V for RESET and SET operations in order to fit practical devices [48], [49]. Table II shows detailed configurations of DUAL consisting of 64 tiles. Each tile has 256 crossbar memory blocks. In each tile, the crossbar memory takes the majority of the area and power consumption, while the counters are taking less than 0.7% and 3.1% of the tile area and power. Each tile takes 0.84mm 2 area and consumes 1.76W power. The total DUAL area and average power consumption are 53.57mm 2 and 113.51W respectively. Table III lists the energy consumption, execution time, and the required memory of each DUAL operation. All results are  reported for a row-parallel case in 28nm technology node when we perform the computation on a single block with 1k rows. In contrast to conventional CAM architectures that consume a huge amount of power, DUAL enables the search operation in 4-bi/7-bit granularity's, resulting in very lower power density.\n\n\nB. Workloads\n\nWe evaluate DUAL efficiency on three popular clustering algorithms: hierarchical clustering, K-means, and DBSCAN. The evaluations are performed on several large-scale datasets including actual and synthetic datasets. Table IV lists 7 popular datasets selected from UCI machine learning website [69]. We also evaluated DUAL efficiency on large-scaled synthetic data consisting of 10k, 1 million, and 10 million data points. The synthetic data is generated random data with 100 cluster centers, radius range of [r l , r h ] = [0.. \u221a 2, \u221a 2.. \u221a 32], and noise rate of 0-10%. Synthetic data has differet sizes, from 400 MB (Synthetic 1) to 40 GB (Synthetic 3). To measure cluster quality, we rely on correct labels of data points and find out how many points were classified in a cluster that does not reflect the label associated with the point. For assigning a label to a cluster, we find a label that is repeated the maximum number of times in a cluster and assign that label to the cluster. We set the number of clusters formed to be the same as the number of labels available in the data set.\n\nWe compare DUAL with the efficient implementation of clustering algorithms running on GPU. For hierarchical clustering, we used the NVIDIA Graph Analytics library (nvGRAPH) [70]. We used [71] and [72] for GPU implementation of k-means and DBSCAN algorithms, respectively. The experiments are performed on an NVIDIA GTX 1080 GPU. The performance and energy of GPU are measured by the nvidia-smi tool. Figure 10a compares the quality of DUAL on three clustering algorithms. For DUAL, each data point is encoded to D = 4, 000 dimensions. The results are compared to the baseline algorithms working with original data and using Euclidean distance. Our result shows that DUAL provides comparable accuracy to the  baseline clustering algorithms. For example, over hierarchical and DBSCAN (and k-means) DUAL provides on average 1.2% and 0.4% higher (1.3% lower) average quality of clustering as compared to the baseline algorithms. We also compare the quality of DUAL with the clustering algorithm using Locality-Sensitive Hashing (LSH) [34], [80], [81]. Similar to DUAL, LSH can map data points to binary vectors with large dimensionality in order to replace Euclidean to hardware-friendly Hamming distance metric [24], [82], [83]. Figure 10b-d compares the quality of clustering in DUAL and LSH-based approaches. The results are shown for the MNIST dataset. Our evaluation shows that in the same dimensionality, DUAL provides a significantly higher quality of clustering than LSH-based approaches. For example, DUAL using D = 4, 000 provides 5.9%, 5.2%, and 3.3% higher quality of clustering than LSH-based approach implementing hierarchical, k-means, and DBSCAN clustering. This higher quality comes from the non-linearity of the HD-mapper that keeps the similarity of the original data in high-dimensional space, while LSH tries to keep approximate distances in a linear way. In addition, we observe that algorithms have different sensitivities to dimension reduction. For example, DUAL accelerating hierarchical clustering can provide a high quality of clustering even when dimensionality reduces to D = 2, 000. In contrast, k-means is more sensitive to dimension reduction. Figure 11 visualizes the clustering of UCIHAR dataset using the baseline hierarchical clustering and DUAL using D = 4, 000 and 1, 000. For visualization, we used t-SNE technique [84] which represents high-dimensional data in 2-dimensional space. In the UCIHAR dataset, the clustering space is 561-dimensional. The true cluster labels are indicated by different colors. The visualization indicates that DUAL using D = 4, 000 results in a more clustering-friendly space compared to clustering in the original space. As we decrease the dimensionality of the mapped hypervectors, DUAL quality of clustering reduces. For example, DUAL using D = 1, 000 provides 5.7% lower quality as compared to DUAL using D = 4, 000 dimensionality. D. DUAL Efficiency Figure 12 compares DUAL energy efficiency and performance with the baseline clustering algorithms running on GPU. Our evaluation shows that DUAL running all clustering algorithms provides on average 58.8\u00d7 speedup and 251.3\u00d7 energy efficiency improvement as compared to the baseline GPU-based approach. The higher DUAL efficiency comes from: (i) enabling a large amount of parallelism, supported by ensuring the data availability in each block. The GPU has resources/cores to parallelize up to four thousand operations. Due to the weakness of the existing von-Neumann architectures, even these small number of cores are usually underutilized (28% utilization running hierarchical clustering). In contrast, DUAL can perform up to 8 million parallel operations by enabling row-level and block-level parallelisms. We also maximize DUAL utilization using the proposed pipelined that ensures data availability in each core, i.e., memory block. (ii) DUAL addresses the overhead of data movement by not only eliminating the external data movement (between the processing cores and memory), but also eliminating the internal data movement between the memory blocks. This internal data transfer is minimized by exploiting the interconnects and bitserial/row-parallel data transfers between the neighbor blocks.\n\n\nC. Quality of Clustering\n\nDUAL is an algorithm-hardware co-design. Without HDmapper, DUAL cannot support euclidean distance entirely in PIM. Similarly, without DUAL Hamming computing hardware, using HD-mapper does not provide computation efficiency. We run DUAL code (high-dimensional clustering) on the same GPU as the baseline. We observe that clustering in high-dimensional space using HD mapper (LSH mapper) runs on average 12.8\u00d7 and 3.1\u00d7 (2.8\u00d7 and 1.06\u00d7) slower and less energy efficient than clustering on the original space running on the same GPU. This is because GPUs have lower parallelism (# of cores) than PIM architecture, thus they get higher benefit running arithmetic operations on low-dimensional vectors, rather than binary computation over long vectors. In other words, DUAL efficiency comes from revisiting clustering algorithms based on the hardware/technology requirements.\n\nAlgorithms Efficiency: DUAL efficiency depends on the operations involved in each algorithm; a portion of search-based and arithmetic operations. In search-based operations, DUAL is significantly faster and more efficient than the equivalent CMOS-based logic. In terms of arithmetic operations, DUAL efficiency highly depends on the amount of parallelism. In fact, in a single arithmetic operation, e.g., 32-bit multiplication, DUAL is about 60\u00d7 slower than CMOS-based logic. This is because our approach supports arithmetic using a series of NORbased operations. However, the large amount of parallelism supported by DUAL results in a higher overall DUAL efficiency. Looking at different algorithms, DUAL provides the maximum efficiency over hierarchical clustering and DBSCAN as these algorithms are mostly involved in search-based operations. For example, DUAL running hierarchical clustering (DBSCAN) provides on average 67.1\u00d7 (71.7\u00d7) speedup and 328.7\u00d7 (293.3\u00d7) energy efficiency as compared to a GPU-based approach. In contrast, k-means involves a large amount of slow arithmetic operation (during cluster update), thus providing only 37.5\u00d7 speedup and 131.6\u00d7 energy efficiency as compared to GPU.\n\nDUAL Configurations: To show the impact of each optimization, Figure 12 shows the DUAL efficiency without using the proposed interconnects and counters. Our evaluation shows that DUAL without interconnects can still outperform GPU efficiency. The impact of the interconnects is more crucial on the hierarchical clustering algorithm (3.9\u00d7 slow down without interconnect), as it requires interconnects to write all pairwise computations on different distance blocks located in the same row. In k-means, DUAL computes the distance to a limited amount of cluster centers; thus, datasets with more number of cluster centers are more affected by interconnect elimination. DBSCAN has the least sensitivity to interconnects (1.6\u00d7 slow down without interconnect), as it computes the Hamming distance to a single data point at each iteration. Therefore, it uses very few neighbor distance blocks to store the distance vector.\n\nFigure12 also shows DUAL efficiency without counter blocks. As NVMs are slow in the write operation, without the counter, the Hamming computing will be significantly slow down. This slow down in more obvious on hierarchical clustering as Hamming computing takes 41% of the total GPU execution. For example, the results show that without counters DUAL works on average 2.7\u00d7, 2.1\u00d7, and 2.4\u00d7 slower than the baseline DUAL running hierarchical, k-means, and DBSCAN algorithms.\n\n\nE. DUAL Quality-Efficiency Tradeoff\n\nAs we explained in Section VIII-C, DUAL quality of clustering depends on the dimensionality of the encoded data. We exploit the robustness of DUAL to dimension reduction in order to improve the computation efficiency. DUAL using lower dimension provides: (i) faster computations, e.g., fewer iterations for Hamming computing and nearest search, and accordingly lower bit-width to perform distance update. (ii) In addition, a lower D reduces the amount of memory requirement and internal data movement between the blocks during the cluster update. Figure 13 shows the impact of dimension reduction on DUAL computation efficiency. The results are reported when we ensure less than 1% and 2% quality loss on all tested datasets as compared to DUAL using full dimensionality (D = 4, 000). Our evaluation shows that DUAL computation efficiency depends on the clustering algorithm. Hierarchical clustering has high robustness to dimension reduction (as shown in Figure 10b), thus provides 90.6\u00d7 and 443.9\u00d7 (116.7\u00d7 and 572.2\u00d7) speedup and energy efficiency while providing only 1% (2%) quality loss. In contrast, k- means quality changes significantly with dimension reduction (as shown in Figure 10c), resulting in only 42.2\u00d7 and 139.5\u00d7 (46.5\u00d7 and 146.4\u00d7) average speedup and energy efficiency improvement with 1% (2%) quality loss.\n\n\nF. Parallelism & Scalability\n\nFigure14 shows the energy consumption and execution time of DUAL providing different levels of parallelism. The results are normalized to DUAL using a single copy of encoded data (parallelism:1). In this low-power mode, DUAL saves the encoded data in the data blocks, enabling serially Hamming distance computation over data points. The clustering task can be also performed without significant data transfer between the blocks and tiles. In high-performance mode, DUAL saves multiple copies of the encoded data points into a single or different tile, providing a parallel Hamming computing. However, this parallelism comes at the expense of increasing the number of data transfer between the blocks, especially during the clustering phase. We evaluate the efficiency of parallelism over two different dataset sizes: 1K and 100K data points. Our results show that using small datasets, DUAL computation speeds up linearly with the level of parallelism. However, using large datasets, the overhead of internal data transfer saturates the DUAL speedup. We also observe that hierarchical clustering requires a lower amount of parallelism for performance saturation. This is because hierarchical clustering stores all pairwise distance values, requiring more blocks/tiles to cluster the same number of data points. In contrast, k-means and DBSCAN only store k (number of cluster centers) and one distance similarity, providing higher computation density. Figure 14 shows DUAL computation speedup for hierarichal clsutering when using synthetic datasets with 100K, 10M, and 100M data points (listed in Table IV). Similar to parallelism, increasing the number of chips results in higher performance, but increases the cost of data transfer between different chips. For example, increasing the level of parallelism by a factor of two, only results in 1.6\u00d7 and 1.4\u00d7 speedup over 100k and 10M data point. The lower improvement in larger datasets comes from the overhead of a large amount of data movement. In a fair comparison, DUAL using 16 chips provide the same area as an NVIDIA GPU. In this configuration, DUAL using 10M data points provides 621.1\u00d7 and 4.6\u00d7 speedup as compared to GPU and DUAL using 1-chip, respectively. G. Breakdown Figure 15a shows the average DUAL computation efficiency with In-Memory data-parallel Processor (IMP) [15]. IMP offloads the PIM-compatible operations of a program into analog-PIM. These operations are the addition, multiplication, and dot product. For hierarchical clustering and DBSCAN, IMP can only offload/accelerate the similarity search (Euclidean distance), which only takes 24.5% and 29% of total GPU execution ( Figure 15b). This results in about 1.6\u00d7 and 1.3\u00d7 speedup over GPU. In contrast, in k-means, IMP operations can be used to accelerate both similarity check and cluster update (92% of GPU execution as shown in Figure 15b), resulting in 12.1\u00d7 speedup and 27.2\u00d7 energy efficiency improvement as compared to GPU. DUAL using a 4-chips provides a similar chip area as IMP. In this configuration, DUAL provides 136.2\u00d7, 9.8\u00d7, and 168.1\u00d7 speedup than IMP over hierarchical clustering, k-means, and DBSCAN, respectively. This efficiency mainly comes from DUAL capability in processing all clustering operations in a parallel. Figure 15b shows the breakdown of the DUAL operations running different clustering applications. Our evaluation shows that DUAL encoding module takes less than 5% of the total execution time. For hierarchical clustering, clustering (nearest search) dominates the execution, as DUAL performs clustering functionality multiple times over the distance matrix. For k-means, the center update takes the majority of the execution time, as DUAL arithmetic operations are slower than search-based operations. For DBSCAN, the center update is computationally simple; thus the Hamming computing and nearest search take the majority of the execution time.\n\n\nH. DUAL Lifetime and Device Variability\n\nWe evaluate the lifetime of DUAL depending on the number of write operations in the memory devices. one of the main advantages of DUAL is its high robustness to noise and failure. DUAL store information as holographic distribution of patterns in high-dimensional space. In this representation, all dimensions are equally contributing to storing information. Therefore, failures on a dimension may not result in losing the entire data. Prior work shows that the endurance of the memristor device has ranged between 10 9 to 10 11 [85]. During the lifetime of DUAL, the number of write operations affects the functionality of the device. Here, we manage the DUAL endurance by uniformly distributing the number of writes to all bitlines. Since all memory blocks support the same functionality, in a long time period, DUAL uses different blocks as data blocks. In addition, DUAL exploits different columns of each memory to perform arithmetic operations. Our evaluation shows that assuming the arrays are continuously used, DUAL can work accurately for 13.5 years. Considering a Gaussian distribution for device failure (endurance distribution), DUAL will still work with less than 1% and 2% quality loss after 17.2 and 19.6 years. In DUAL, each tile controller keeps track of the number of times that each memory block is used for computation. This provides an estimation of the number of writes in the memory without paying significant cost for endurance management.\n\nIn practice, the memristor devices might have variation due to thermal or process variations. Here, we consider the impact of up to 50% variations on the OFF/ON memristor values. Our evaluation shows that decreasing the R o f f /R on slows down the arithmetic and search-based operations. In 50% variations (R o f f /R on \u223c 50), DUAL ensures the exact computation by using 350ps and 1.8ns clock frequency for the search and NOR-based operations. In architecture-level, this variation results in 1.83\u00d7 slower and 1.45\u00d7 less energy efficiency of DUAL. However, DUAL efficiency is still much higher than the GPU.\n\nIX. RELATED WORK Clustering Acceleration: Several prior works tried to accelerate clustering algorithms on GPU, FPGA, and ASIC designs [72], [86]- [90]. To accelerate computation, prior works tried to simplify clustering operations [35]- [37]. For example, Locality Sensitive Hashing (LSH) was introduced in order to give an efficient algorithm for nearest neighbor search in high-dimensional space. This approach simplifies the similarity search of hashed data to the Hamming distance metric which can be implemented more efficiently in the hardware [91], [92]. However, the current computing systems are still significantly slow in processing large datasets, as the main computation still relies on CMOS-based cores, thus has limited parallelism.\n\nProcessing in-memory: To address the data movement issue, work in [93] proposed a neural cache architecture that re-purposes caches for parallel in-memory computing. Work in [94], [95] modified DRAM architecture to accelerate DNN inference by supporting matrix multiplication in memory. In contrast, DUAL performs a row-parallel and non-destructive bitwise operation inside non-volatile memory without using any sense amplifiers. In addition, these approaches do not support Hamming computing and the nearest search which are essential for clustering applications. The capability of non-volatile memories (NVMs) to act as both storage and processing units has encouraged research in Processing In-Memory (PIM) [16], [17], [96]. NVM-based PIMs have been used to accelerate a wide range of big data applications such as supervised learning [14], [17], [18], [96]- [99], graph processing [9], [11], [100]. Work in [101], [102] designed NVM-based Boltzmann machine capable of solving a broad class of deep learning and optimization problems. Work in [18] and [17] designed new architectures to accelerate Deep Neural Network (DNN) inference using analog-PIM. Work in [14], extended PIM functionality to support the training phase of DNN algorithms. Work in [15] exploited analog-PIM to accelerate general data-intensive workloads by offloading the PIM-compatible operations into the PIM accelerator. However, these architectures: (i) do not support the majority of operations involved in clustering algorithms [16], [18], e.g., similarity/nearest search, (ii) require ADC/DAC blocks that dominate total chip area/power, e.g., 98% of chip area and 87% of total power in [18].\n\nIn addition, work in [16] proposed a PIM architecture that supports floating-point arithmetic operations over digital data. However, all existing clustering algorithms are based on the search-based operations that cannot be supported by arithmetic operations. Prior works also exploited digital PIM operations to accelerate different applications such as DNNs [46], [103], [104], brain-inspired computing [39], [105], [106], object recognition [107], graph processing [108], [109], and database applications [45], [110]. However, the designs do not support high-level operations used in clustering. In contrast, DUAL supports all operations involved in clustering algorithms using parallelized in-memory operations. It also removes the necessity of ADC/DAC blocks; thus providing high throughput/area.\n\nSearch-based PIMs: There are several work used NVMbased CAM to support the nearest absolute [46] or Hamming distance [39] search. These approximate analog searches cannot be used to perform clustering that required actual distance value. In contrast, DUAL is the first digital-based architecture that computes Hamming distance without using costly ADC/DAC blocks. There are recent work used other NVM technologies, e.g., FeFET and STT-RAMs or multi-level cells (MLCs), to design CAM blocks [111]- [113]. For example, work in [114] designed CAM with exact search capability using MLCs. DUAL idea is orthogonal to NVM technology as it can exploit the same peripherals to support Hamming computing on any CAMs.\n\n\nX. CONCLUSION\n\nIn this paper, we propose the first digital-based processing in-memory architecture (DUAL) to accelerate a wide range of popular unsupervised learning algorithms. DUAL maps all data points into high-dimensional space, replacing complex clustering operations with memory-friendly operations. We accordingly designed a PIM-based architecture that supports all essential operations in a highly parallel and scalable way. Our evaluation shows that DUAL provides a comparable quality of clustering to existing clustering algorithms while providing a 58.8\u00d7 speedup and a 251.2\u00d7 energy efficiency improvement as compared to the existing NVIDIA GTX 1080 GPU.\n\nFig. 1 .\n1Hierarchical Clustering Overview.\n\nFig. 2 .\n2Overview of DUAL platform accelerating clustering algorithms.\n\nFig. 3 .\n3HD-mapper: encoding data points into high-dimensional space.\n\nFig. 4 .\n4DUAL operations: search-based and arithmetic\n\nFig. 5 .\n5(a) DUAL encoding in-memory implementation, (b) computation layout.\n\nFig. 6 .\n6Overview of DUAL functionalities supporting hierarchical clustering.\n\nFig. 7 .Figure 8 \u2022\n78memory Layout performing clustering.distance values (d(a i , a k ) and d(a j , a k )). Then, DUAL adds the multiplied vectors and divides the results by s i + s j .VI. DUAL ARCHITECTURE A shows an overview of the DUAL architecture.\n\nFigure 8 \u2022\n8C shows DUAL configuration when the data points\n\nFig. 8 .\n8DUAL architectural details, and the pipeline stage supporting Hamming computing and clustering.\n\nFig. 9 .\n9DUAL computation flow accelerating DBSCAN and K-means algorithm.\n\nAlgorithm 1 :\n1The implementation of DBSCAN 0: centers = vlca\u00a110000\u00bf[N] 0: (cur p, cur err) = (0, in f inite) 0: while cur err > thres do 0: h dist = hamming(centers[cur p]p, cur err) = (idx, vec \u2212 centers[cur p]) 0: end while=0\n\n\n-Length Column Array (VLCA), to represent all operation values used in DUAL programs. Here, we denote a D-bit VLCA with N elements as vlca D [N]. We enable two-dimensional indexing in VLCA where vlca D [i][ j] represents j th bit of i i row in a D-bit vector. VLCA supports slicing indexing which\n\n\nHamming Computing: hamming(input, re f s) function computes the Hamming distance between an input vector (input) and an array of reference vectors (refs). The function has two parameters, where input is a D-bit vector and re f s has a format of vlca D [N]. Calculations of the Hamming distance is completed by comparing the vectors in a 7-bit windows. Each 7-bit comparison generates 3-bit distance result. The output of hamming() function has a format of vlca 3 [ D 7 ][N]. Row-Parallel Arithmetic: For each of the arithmetic operations, we use a row-parallel computation in memory. (e.g. addition(input1, input2)) has two parameters, where both inputs and the output have the format of vlca D [N]. Nearest Search: The function near_search(input, target) is used to finish the nearest search operation. The nearest search finds the entry in a vlca D [N] (input) with a value which is closest to a target D-bit vector (target). The output of near_search() function consists of the index of the matched entry as well as the value of the entry.\n\nFig. 10 .\n10(a) The quality of DUAL clustering and the baseline algorithm. (b-d) comparison of DUAL and LSH when mapping data to different dimensionality.\n\nFig. 11 .\n11t-SNE visualizations of the baseline hierarchical learning and DUAL with different dimensionalities.\n\nFig. 12 .\n12Efficiency in different configurations.\n\nFig. 13 .\n13Efficiency in different levels of quality loss.\n\nFig. 14 .\n14(a) DUAL speedup in different level of parallelism, (b) scalability using different # of chips.\n\nFig. 15 .\n15(a) DUAL vs. IMP [15] efficiency. (b) Computation breakdown of GPU and DUAL.\n\nTABLE I PIM\nIINSTRUCTIONS OF DUAL.Instruction \nR. Reg. \nW. Reg. \n\nset_qinput \nb, <addr>, <size> \nq \nhamm_7 \nb, c1, c2 \n-\nadd/sub/mul/div \nb, d, c1, c2, c3 \n-\nnear_search \nb, nc, c, q \nrst, idx \nrow_mv \nb1,r1,c1,b2,r2,c2,nr,nc \n-\n\nenable programmers to extract specific rows/columns from the \nwhole data. For instance, vlca D [i : j][n : m] denotes data slice \nof n th \u2212 m th columns in the i th \u2212 j th rows. A VLCA, which \ncannot fit in one memory block, is stored across multiple blocks. \nOperations on long VLCAs can be broken into multiple parallel \noperations over all blocks storing the vector. \n\n\n\nTABLE II DUAL\nIIPARAMETERS.Components \nParam \nSpec \nArea \nPower \n\nCrossbar array \nsize \n1Mb \n3136\u00b5m 2 \n6.14mW \nSense Amp \nnumber \n1K \n57.13\u00b5m 2 \n2.38mW \nCounter \nnumber \n1 \n24.06\u00b5m 2 \n0.27mW \nMemory Block \nnumber \n1 \n3217.19 \u00b5m 2 \n8.79mW \nTile Memory \nnum block \n256 \n0.82mm 2 \n1.57W \nInterconnect \nnum wire \n1k/row \n0.01mm 2 \n62.08mW \nController \nnumber \n1 \n289.2\u00b5m 2 \n131.75mW \nTile \nsize \n32MB \n0.84mm 2 \n1.76W \n\nTotal \nnumber \n64 Tiles \n53.57mm 2 \n113.51W \nsize \n2GB \n\n\n\nTABLE III DETAILS\nIIIOF DUAL SUPPORTED OPERATIONS.Operations \nSize \n\nEnergy \nConsumption \n\nExecution \nTime \n\nRequired \nMemory \n\nHamming Computing \n7-bits \n1632fJ \n200/100 ps \n3-bits/row \nNearest Search \n4-bits \n1214fJ \n200 ps \n1-bit/row \nAddition \n8-bit \n2.3pJ \n98.4ns \n12-bits/row \nMultiplication \n8-bit \n67.7pJ \n448.3ns \n155-bits/row \nDivision \n8-bit \n72.5pJ \n561.4ns \n168-bits/row \nData Transfer \n1-bit \n748fJ \n1.1ns \n1bit/row \n\n\n\nTABLE IV WORKLOADS.\nIVDatasets \n# Data Point \n# Features # Clusters \nDescription \n\nMNIST \n60000 \n784 \n10 \nHandwritten Digits [73] \nFACIAL \n27965 \n300 \n2 \nGrammatical Facial Expressions [74] \nUCIHAR \n7667 \n561 \n12 \nHuman Activity Using Smartphones [75] \nSEIZURE \n11500 \n178 \n5 \nEpileptic Seizure [76] \nSENSOR \n13910 \n129 \n6 \nGas Sensor Array Drift [77] \nGESTURE \n9880 \n50 \n5 \nGesture Phase Segmentation [78] \nISOLET \n7797 \n617 \n26 \nSpeech data [79] \n\nSynthetic 1 \n100k \n1000 \n50 \n100k data points \nSynthetic 2 \n1M \n1000 \n50 \n1 Millions data \nSynthetic 3 \n10M \n1000 \n50 \n10 Millions data \n\n\nACKNOWLEDGEMENTSThis work was partially supported in part by SRC-Global Research Collaboration grant AIHW 2020, in part by SRC JUMP CRISP program, and also NSF grants #1527034, #1730158, #1826967, and #1911095. Mohsen Imani and Yeseong Kim are co-corresponding authors of the paper.\nA survey on platforms for big data analytics. D Singh, C K Reddy, Journal of big data. 21D. Singh and C. K. Reddy, \"A survey on platforms for big data analytics,\" Journal of big data, vol. 2, no. 1, p. 8, 2015.\n\nData clustering: 50 years beyond k-means. A K Jain, Pattern recognition letters. 318A. K. Jain, \"Data clustering: 50 years beyond k-means,\" Pattern recognition letters, vol. 31, no. 8, pp. 651-666, 2010.\n\nData stream clustering: A survey. J A Silva, E R Faria, R C Barros, E R Hruschka, A C De Carvalho, J Gama, ACM Computing Surveys (CSUR). 46113J. A. Silva, E. R. Faria, R. C. Barros, E. R. Hruschka, A. C. De Carvalho, and J. Gama, \"Data stream clustering: A survey,\" ACM Computing Surveys (CSUR), vol. 46, no. 1, p. 13, 2013.\n\nDistance metric learning with application to clustering with side-information. E P Xing, M I Jordan, S J Russell, A Y Ng, Advances in neural information processing systems. E. P. Xing, M. I. Jordan, S. J. Russell, and A. Y. Ng, \"Distance metric learning with application to clustering with side-information,\" in Advances in neural information processing systems, pp. 521-528, 2003.\n\nMining text data. C C Aggarwal, C Zhai, Springer Science & Business MediaC. C. Aggarwal and C. Zhai, Mining text data. Springer Science & Business Media, 2012.\n\nCd-hit: accelerated for clustering the next-generation sequencing data. L Fu, B Niu, Z Zhu, S Wu, W Li, Bioinformatics. 2823L. Fu, B. Niu, Z. Zhu, S. Wu, and W. Li, \"Cd-hit: accelerated for clustering the next-generation sequencing data,\" Bioinformatics, vol. 28, no. 23, pp. 3150-3152, 2012.\n\nMulti-view k-means clustering on big data. X Cai, F Nie, H Huang, Twenty-Third International Joint conference on artificial intelligence. X. Cai, F. Nie, and H. Huang, \"Multi-view k-means clustering on big data,\" in Twenty-Third International Joint conference on artificial intelligence, 2013.\n\nA survey of clustering algorithms for big data: Taxonomy and empirical analysis. A Fahad, N Alshatri, Z Tari, A Alamri, I Khalil, A Y Zomaya, S Foufou, A Bouras, IEEE transactions on emerging topics in computing. 23A. Fahad, N. Alshatri, Z. Tari, A. Alamri, I. Khalil, A. Y. Zomaya, S. Foufou, and A. Bouras, \"A survey of clustering algorithms for big data: Taxonomy and empirical analysis,\" IEEE transactions on emerging topics in computing, vol. 2, no. 3, pp. 267-279, 2014.\n\nA scalable processingin-memory accelerator for parallel graph processing. J Ahn, S Hong, S Yoo, O Mutlu, K Choi, ACM SIGARCH Computer Architecture News. 433J. Ahn, S. Hong, S. Yoo, O. Mutlu, and K. Choi, \"A scalable processing- in-memory accelerator for parallel graph processing,\" ACM SIGARCH Computer Architecture News, vol. 43, no. 3, pp. 105-117, 2016.\n\nProcessing in memory: The terasys massively parallel pim array. M Gokhale, B Holmes, K Iobst, Computer. 284M. Gokhale, B. Holmes, and K. Iobst, \"Processing in memory: The terasys massively parallel pim array,\" Computer, vol. 28, no. 4, pp. 23- 31, 1995.\n\nPim-enabled instructions: a low-overhead, locality-aware processing-in-memory architecture. J Ahn, S Yoo, O Mutlu, K Choi, 2015 ACM/IEEE 42nd Annual International Symposium on Computer Architecture (ISCA). IEEEJ. Ahn, S. Yoo, O. Mutlu, and K. Choi, \"Pim-enabled instructions: a low-overhead, locality-aware processing-in-memory architecture,\" in 2015 ACM/IEEE 42nd Annual International Symposium on Computer Architecture (ISCA), pp. 336-348, IEEE, 2015.\n\nTop-pim: throughput-oriented programmable processing in memory. D Zhang, N Jayasena, A Lyashevsky, J L Greathouse, L Xu, M Ignatowski, Proceedings of the 23rd international symposium on High-performance parallel and distributed computing. the 23rd international symposium on High-performance parallel and distributed computingACMD. Zhang, N. Jayasena, A. Lyashevsky, J. L. Greathouse, L. Xu, and M. Ignatowski, \"Top-pim: throughput-oriented programmable processing in memory,\" in Proceedings of the 23rd international symposium on High-performance parallel and distributed computing, pp. 85-98, ACM, 2014.\n\nThe architecture of the diva processing-in-memory chip. J Draper, J Chame, M Hall, C Steele, T Barrett, J Lacoss, J Granacki, J Shin, C Chen, C W Kang, Proceedings of the 16th international conference on Supercomputing. the 16th international conference on SupercomputingACMJ. Draper, J. Chame, M. Hall, C. Steele, T. Barrett, J. LaCoss, J. Granacki, J. Shin, C. Chen, C. W. Kang, et al., \"The architecture of the diva processing-in-memory chip,\" in Proceedings of the 16th international conference on Supercomputing, pp. 14-25, ACM, 2002.\n\nPipelayer: A pipelined rerambased accelerator for deep learning. L Song, X Qian, H Li, Y Chen, 2017 IEEE International Symposium on High Performance Computer Architecture (HPCA). IEEEL. Song, X. Qian, H. Li, and Y. Chen, \"Pipelayer: A pipelined reram- based accelerator for deep learning,\" in 2017 IEEE International Symposium on High Performance Computer Architecture (HPCA), pp. 541-552, IEEE, 2017.\n\nIn-memory data parallel processor. D Fujiki, S Mahlke, R Das, Proceedings of the Twenty-Third International Conference on Architectural Support for Programming Languages and Operating Systems. the Twenty-Third International Conference on Architectural Support for Programming Languages and Operating SystemsACMD. Fujiki, S. Mahlke, and R. Das, \"In-memory data parallel processor,\" in Proceedings of the Twenty-Third International Conference on Architectural Support for Programming Languages and Operating Systems, pp. 1-14, ACM, 2018.\n\nFloatpim: In-memory acceleration of deep neural network training with high precision. M Imani, S Gupta, Y Kim, T Rosing, Proceedings of the 46th International Symposium on Computer Architecture. the 46th International Symposium on Computer ArchitectureACMM. Imani, S. Gupta, Y. Kim, and T. Rosing, \"Floatpim: In-memory acceleration of deep neural network training with high precision,\" in Proceedings of the 46th International Symposium on Computer Architecture, pp. 802-815, ACM, 2019.\n\nPrime: A novel processing-in-memory architecture for neural network computation in reram-based main memory. P Chi, S Li, C Xu, T Zhang, J Zhao, Y Liu, Y Wang, Y Xie, ACM SIGARCH Computer Architecture News. 44IEEE PressP. Chi, S. Li, C. Xu, T. Zhang, J. Zhao, Y. Liu, Y. Wang, and Y. Xie, \"Prime: A novel processing-in-memory architecture for neural network computation in reram-based main memory,\" in ACM SIGARCH Computer Architecture News, vol. 44, pp. 27-39, IEEE Press, 2016.\n\nIsaac: A convolutional neural network accelerator with in-situ analog arithmetic in crossbars. A Shafiee, A Nag, N Muralimanohar, R Balasubramonian, J P Strachan, M Hu, R S Williams, V Srikumar, ACM SIGARCH Computer Architecture News. 443A. Shafiee, A. Nag, N. Muralimanohar, R. Balasubramonian, J. P. Stra- chan, M. Hu, R. S. Williams, and V. Srikumar, \"Isaac: A convolutional neural network accelerator with in-situ analog arithmetic in crossbars,\" ACM SIGARCH Computer Architecture News, vol. 44, no. 3, pp. 14-26, 2016.\n\nClassification and related methods of data analysis. V Batagelj, Generalized ward and related clustering problemsV. Batagelj, \"Generalized ward and related clustering problems,\" Classification and related methods of data analysis, pp. 67-74, 1988.\n\nGenetic algorithm-based clustering technique. U Maulik, S Bandyopadhyay, Pattern recognition. 339U. Maulik and S. Bandyopadhyay, \"Genetic algorithm-based clustering technique,\" Pattern recognition, vol. 33, no. 9, pp. 1455-1465, 2000.\n\nThe global k-means clustering algorithm. A Likas, N Vlassis, J J Verbeek, Pattern recognition. 362A. Likas, N. Vlassis, and J. J. Verbeek, \"The global k-means clustering algorithm,\" Pattern recognition, vol. 36, no. 2, pp. 451-461, 2003.\n\nHierarchical clustering: Objective functions and algorithms. V Cohen-Addad, V Kanade, F Mallmann-Trenn, C Mathieu, Proceedings of the Twenty-Ninth Annual ACM-SIAM Symposium on Discrete Algorithms. the Twenty-Ninth Annual ACM-SIAM Symposium on Discrete AlgorithmsSIAMV. Cohen-Addad, V. Kanade, F. Mallmann-Trenn, and C. Mathieu, \"Hierarchical clustering: Objective functions and algorithms,\" in Pro- ceedings of the Twenty-Ninth Annual ACM-SIAM Symposium on Discrete Algorithms, pp. 378-397, SIAM, 2018.\n\nHierarchical clustering multi-task learning for joint human action grouping and recognition. A.-A Liu, Y.-T Su, W.-Z Nie, M Kankanhalli, IEEE transactions on pattern analysis and machine intelligence. 39A.-A. Liu, Y.-T. Su, W.-Z. Nie, and M. Kankanhalli, \"Hierarchical clustering multi-task learning for joint human action grouping and recognition,\" IEEE transactions on pattern analysis and machine intelligence, vol. 39, no. 1, pp. 102-114, 2017.\n\nFast agglomerative hierarchical clustering algorithm using locality-sensitive hashing. H Koga, T Ishibashi, T Watanabe, Knowledge and Information Systems. 121H. Koga, T. Ishibashi, and T. Watanabe, \"Fast agglomerative hierarchical clustering algorithm using locality-sensitive hashing,\" Knowledge and Information Systems, vol. 12, no. 1, pp. 25-53, 2007.\n\nA survey of recent advances in hierarchical clustering algorithms. F Murtagh, The Computer Journal. 264F. Murtagh, \"A survey of recent advances in hierarchical clustering algorithms,\" The Computer Journal, vol. 26, no. 4, pp. 354-359, 1983.\n\nParallel algorithms for hierarchical clustering. C F Olson, Parallel computing. 218C. F. Olson, \"Parallel algorithms for hierarchical clustering,\" Parallel computing, vol. 21, no. 8, pp. 1313-1325, 1995.\n\nAn energy efficient hierarchical clustering algorithm for wireless sensor networks. S Bandyopadhyay, E J Coyle, IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies. IEEE3S. Bandyopadhyay and E. J. Coyle, \"An energy efficient hierarchical clustering algorithm for wireless sensor networks,\" in IEEE INFOCOM 2003. Twenty-second Annual Joint Conference of the IEEE Computer and Communications Societies (IEEE Cat. No. 03CH37428), vol. 3, pp. 1713-1723, IEEE, 2003.\n\nImage segmentation using k-means clustering algorithm and subtractive clustering algorithm. N Dhanachandra, K Manglem, Y J Chanu, Procedia Computer Science. 54N. Dhanachandra, K. Manglem, and Y. J. Chanu, \"Image segmentation using k-means clustering algorithm and subtractive clustering algorithm,\" Procedia Computer Science, vol. 54, pp. 764-771, 2015.\n\nHierarchical cluster analysis: comparison of three linkage measures and application to psychological data. O Yim, K T Ramdeen, The quantitative methods for psychology. 11O. Yim and K. T. Ramdeen, \"Hierarchical cluster analysis: comparison of three linkage measures and application to psychological data,\" The quantitative methods for psychology, vol. 11, no. 1, pp. 8-21, 2015.\n\nWikipedia linkage. \"Wikipedia linkage.\" https://en.wikipedia.org/wiki/Hierarchical clustering.\n\nWard method. \"Ward method.\" https://en.wikipedia.org/wiki/Ward's method.\n\nMemristive devices for computing. J J Yang, D B Strukov, D R Stewart, Nature nanotechnology. 8113J. J. Yang, D. B. Strukov, and D. R. Stewart, \"Memristive devices for computing,\" Nature nanotechnology, vol. 8, no. 1, p. 13, 2013.\n\nMemristor-based computing. L K John, E E Swartzlander, IEEE Micro. 5L. K. John and E. E. Swartzlander, \"Memristor-based computing,\" IEEE Micro, no. 5, pp. 5-6, 2018.\n\nLsh clustering. \"Lsh clustering.\" https://github.com/usc-isi-i2/dig-lsh-clustering.\n\nLocality sensitive hashing: A comparison of hash function types and querying mechanisms. L Paulev\u00e9, H J\u00e9gou, L Amsaleg, Pattern Recognition Letters. 3111L. Paulev\u00e9, H. J\u00e9gou, and L. Amsaleg, \"Locality sensitive hashing: A comparison of hash function types and querying mechanisms,\" Pattern Recognition Letters, vol. 31, no. 11, pp. 1348-1358, 2010.\n\nShared nearest neighbor clustering in a locality sensitive hashing framework. S Kanj, T Br\u00fcls, S Gazut, Journal of Computational Biology. 252S. Kanj, T. Br\u00fcls, and S. Gazut, \"Shared nearest neighbor clustering in a locality sensitive hashing framework,\" Journal of Computational Biology, vol. 25, no. 2, pp. 236-250, 2018.\n\nHashing-based clustering in high dimensional data. J Zamora, M Mendoza, H Allende, Expert Systems with Applications. 62J. Zamora, M. Mendoza, and H. Allende, \"Hashing-based clustering in high dimensional data,\" Expert Systems with Applications, vol. 62, pp. 202-211, 2016.\n\nSemihd: Semi-supervised learning using hyperdimensional computing. M Imani, S Bosch, M Javaheripi, B Rouhani, X Wu, F Koushanfar, T Rosing, IEEE/ACM International Conference On Computer Aided Design (ICCAD). M. Imani, S. Bosch, M. Javaheripi, B. Rouhani, X. Wu, F. Koushanfar, and T. Rosing, \"Semihd: Semi-supervised learning using hyperdi- mensional computing,\" in IEEE/ACM International Conference On Computer Aided Design (ICCAD), pp. 1-8, 2019.\n\nExploring hyperdimensional associative memory. M Imani, HPCA. IEEEM. Imani et al., \"Exploring hyperdimensional associative memory,\" in HPCA, pp. 445-456, IEEE, 2017.\n\nA robust and energyefficient classifier using brain-inspired hyperdimensional computing. A Rahimi, P Kanerva, J M Rabaey, Proceedings of the 2016 International Symposium on Low Power Electronics and Design. the 2016 International Symposium on Low Power Electronics and DesignA. Rahimi, P. Kanerva, and J. M. Rabaey, \"A robust and energy- efficient classifier using brain-inspired hyperdimensional computing,\" in Proceedings of the 2016 International Symposium on Low Power Electronics and Design, pp. 64-69, 2016.\n\nRandom features for large-scale kernel machines. A Rahimi, B Recht, Advances in neural information processing systems. A. Rahimi and B. Recht, \"Random features for large-scale kernel machines,\" in Advances in neural information processing systems, pp. 1177-1184, 2008.\n\nThe kernel trick for distances. B Sch\u00f6lkopf, Advances in neural information processing systems. B. Sch\u00f6lkopf, \"The kernel trick for distances,\" in Advances in neural information processing systems, pp. 301-307, 2001.\n\nHyperdimensional computing: An introduction to computing in distributed representation with high-dimensional random vectors. P Kanerva, Cognitive Computation. 12P. Kanerva, \"Hyperdimensional computing: An introduction to comput- ing in distributed representation with high-dimensional random vectors,\" Cognitive Computation, vol. 1, no. 2, pp. 139-159, 2009.\n\n1 mb 0.41 \u00b5m 2 2t-2r cell nonvolatile tcam with two-bit encoding and clocked self-referenced sensing. J Li, R K Montoye, M Ishii, L Chang, IEEE Journal of Solid-State Circuits. 494J. Li, R. K. Montoye, M. Ishii, and L. Chang, \"1 mb 0.41 \u00b5m 2 2t-2r cell nonvolatile tcam with two-bit encoding and clocked self-referenced sensing,\" IEEE Journal of Solid-State Circuits, vol. 49, no. 4, pp. 896- 907, 2013.\n\nEfficient query processing in crossbar memory. M Imani, S Gupta, A Arredondo, T Rosing, 2017 IEEE/ACM International Symposium on Low Power Electronics and Design (ISLPED). IEEEM. Imani, S. Gupta, A. Arredondo, and T. Rosing, \"Efficient query processing in crossbar memory,\" in 2017 IEEE/ACM International Symposium on Low Power Electronics and Design (ISLPED), pp. 1-6, IEEE, 2017.\n\nRapidnn: In-memory deep neural network acceleration framework. M Imani, M Samragh, Y Kim, S Gupta, F Koushanfar, T Rosing, arXiv:1806.05794arXiv preprintM. Imani, M. Samragh, Y. Kim, S. Gupta, F. Koushanfar, and T. Rosing, \"Rapidnn: In-memory deep neural network acceleration framework,\" arXiv preprint arXiv:1806.05794, 2018.\n\nDigitalpim: Digital-based processing in-memory for big data acceleration. M Imani, S Gupta, Y Kim, M Zhou, T Rosing, Proceedings of the 2019 on Great Lakes Symposium on VLSI. the 2019 on Great Lakes Symposium on VLSIM. Imani, S. Gupta, Y. Kim, M. Zhou, and T. Rosing, \"Digitalpim: Digital-based processing in-memory for big data acceleration,\" in Proceedings of the 2019 on Great Lakes Symposium on VLSI, pp. 429- 434, 2019.\n\nMagic-memristor-aided logic. S Kvatinsky, D Belousov, S Liman, G Satat, N Wald, E G Friedman, A Kolodny, U C Weiser, IEEE Transactions on Circuits and Systems II: Express Briefs. 6111S. Kvatinsky, D. Belousov, S. Liman, G. Satat, N. Wald, E. G. Friedman, A. Kolodny, and U. C. Weiser, \"Magic-memristor-aided logic,\" IEEE Transactions on Circuits and Systems II: Express Briefs, vol. 61, no. 11, pp. 895-899, 2014.\n\nSimpler magic: synthesis and mapping of inmemory logic executed in a single row to improve throughput. R Ben-Hur, R Ronen, A Haj-Ali, D Bhattacharjee, A Eliahu, N Peled, S Kvatinsky, IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems. R. Ben-Hur, R. Ronen, A. Haj-Ali, D. Bhattacharjee, A. Eliahu, N. Peled, and S. Kvatinsky, \"Simpler magic: synthesis and mapping of in- memory logic executed in a single row to improve throughput,\" IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, 2019.\n\nA complementary resistive switch-based crossbar array adder. A Siemon, S Menzel, R Waser, E Linn, IEEE journal on emerging and selected topics in circuits and systems. 51A. Siemon, S. Menzel, R. Waser, and E. Linn, \"A complementary resistive switch-based crossbar array adder,\" IEEE journal on emerging and selected topics in circuits and systems, vol. 5, no. 1, pp. 64-74, 2015.\n\nMemristor-based material implication (IMPLY) logic: design principles and methodologies. S Kvatinsky, G Satat, N Wald, E G Friedman, A Kolodny, U C Weiser, TVLSI. 2210S. Kvatinsky, G. Satat, N. Wald, E. G. Friedman, A. Kolodny, and U. C. Weiser, \"Memristor-based material implication (IMPLY) logic: design principles and methodologies,\" TVLSI, vol. 22, no. 10, pp. 2054-2066, 2014.\n\nMemristive switches enable stateful logic operations via material implication. J Borghetti, G S Snider, P J Kuekes, J J Yang, D R Stewart, R S Williams, Nature. 4647290J. Borghetti, G. S. Snider, P. J. Kuekes, J. J. Yang, D. R. Stewart, and R. S. Williams, \"Memristive switches enable stateful logic operations via material implication,\" Nature, vol. 464, no. 7290, pp. 873-876, 2010.\n\nLogic design within memristive memories using memristor-aided logic (magic). N Talati, S Gupta, P Mane, S Kvatinsky, IEEE Transactions on Nanotechnology. 154N. Talati, S. Gupta, P. Mane, and S. Kvatinsky, \"Logic design within memristive memories using memristor-aided logic (magic),\" IEEE Transactions on Nanotechnology, vol. 15, no. 4, pp. 635-650, 2016.\n\nEfficient algorithms for in-memory fixed point multiplication using magic. A Haj-Ali, R Ben-Hur, N Wald, S Kvatinsky, 2018 IEEE International Symposium on Circuits and Systems (ISCAS). IEEEA. Haj-Ali, R. Ben-Hur, N. Wald, and S. Kvatinsky, \"Efficient algorithms for in-memory fixed point multiplication using magic,\" in 2018 IEEE International Symposium on Circuits and Systems (ISCAS), pp. 1-5, IEEE, 2018.\n\nTruncapp: A truncation-based approximate divider for energy efficient dsp applications. S Vahdat, M Kamal, A Afzali-Kusha, M Pedram, Z Navabi, Proceedings of the Conference on Design, Automation & Test in Europe. the Conference on Design, Automation & Test in EuropeEuropeS. Vahdat, M. Kamal, A. Afzali-Kusha, M. Pedram, and Z. Navabi, \"Truncapp: A truncation-based approximate divider for energy efficient dsp applications,\" in Proceedings of the Conference on Design, Automa- tion & Test in Europe, pp. 1639-1642, Europe, 2017.\n\nOvercoming the challenges of crossbar resistive memory architectures. C Xu, D Niu, N Muralimanohar, R Balasubramonian, T Zhang, S Yu, Y Xie, 2015 IEEE 21st International Symposium on High Performance Computer Architecture (HPCA). IEEEC. Xu, D. Niu, N. Muralimanohar, R. Balasubramonian, T. Zhang, S. Yu, and Y. Xie, \"Overcoming the challenges of crossbar resistive memory architectures,\" in 2015 IEEE 21st International Symposium on High Performance Computer Architecture (HPCA), pp. 476-488, IEEE, 2015.\n\nNewton: Gravitating towards the physical limits of crossbar acceleration. A Nag, R Balasubramonian, V Srikumar, R Walker, A Shafiee, J P Strachan, N Muralimanohar, IEEE Micro. 385A. Nag, R. Balasubramonian, V. Srikumar, R. Walker, A. Shafiee, J. P. Strachan, and N. Muralimanohar, \"Newton: Gravitating towards the physical limits of crossbar acceleration,\" IEEE Micro, vol. 38, no. 5, pp. 41-49, 2018.\n\nA density-based algorithm for discovering clusters in large spatial databases with noise. M Ester, H.-P Kriegel, J Sander, X Xu, in Kdd. 96M. Ester, H.-P. Kriegel, J. Sander, and X. Xu, \"A density-based algorithm for discovering clusters in large spatial databases with noise.,\" in Kdd, vol. 96, pp. 226-231, 1996.\n\nSt-dbscan: An algorithm for clustering spatialtemporal data. D Birant, A Kut, Data & Knowledge Engineering. 601D. Birant and A. Kut, \"St-dbscan: An algorithm for clustering spatial- temporal data,\" Data & Knowledge Engineering, vol. 60, no. 1, pp. 208- 221, 2007.\n\nAn improved sampling-based dbscan for large spatial databases. B Borah, D Bhattacharyya, International Conference on Intelligent Sensing and Information Processing. IEEEProceedings ofB. Borah and D. Bhattacharyya, \"An improved sampling-based dbscan for large spatial databases,\" in International Conference on Intelligent Sensing and Information Processing, 2004. Proceedings of, pp. 92-96, IEEE, 2004.\n\nAn efficient k-means clustering algorithm: Analysis and implementation. T Kanungo, D M Mount, N S Netanyahu, C D Piatko, R Silverman, A Y Wu, IEEE Transactions on Pattern Analysis & Machine Intelligence. 7T. Kanungo, D. M. Mount, N. S. Netanyahu, C. D. Piatko, R. Silverman, and A. Y. Wu, \"An efficient k-means clustering algorithm: Analysis and implementation,\" IEEE Transactions on Pattern Analysis & Machine Intelligence, no. 7, pp. 881-892, 2002.\n\n{NOVA}: A log-structured file system for hybrid volatile/non-volatile main memories. J Xu, S Swanson, 14th {USENIX} Conference on File and Storage Technologies ({FAST} 16). J. Xu and S. Swanson, \"{NOVA}: A log-structured file system for hybrid volatile/non-volatile main memories,\" in 14th {USENIX} Conference on File and Storage Technologies ({FAST} 16), pp. 323-338, 2016.\n\nMemory management techniques for large-scale persistentmain-memory systems. I Oukid, D Booss, A Lespinasse, W Lehner, T Willhalm, G Gomes, Proceedings of the VLDB Endowment. the VLDB Endowment10I. Oukid, D. Booss, A. Lespinasse, W. Lehner, T. Willhalm, and G. Gomes, \"Memory management techniques for large-scale persistent- main-memory systems,\" Proceedings of the VLDB Endowment, vol. 10, no. 11, pp. 1166-1177, 2017.\n\nScikit-learn: Machine learning in python. F Pedregosa, G Varoquaux, A Gramfort, V Michel, B Thirion, O Grisel, M Blondel, P Prettenhofer, R Weiss, V Dubourg, Journal of machine learning research. 12F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, and V. Dubourg, \"Scikit-learn: Machine learning in python,\" Journal of machine learning research, vol. 12, no. Oct, pp. 2825-2830, 2011.\n\nScikit-learn library. \"Scikit-learn library.\" https://scikit-learn.org.\n\nNvsim: A circuit-level performance, energy, and area model for emerging non-volatile memory. X Dong, C Xu, N Jouppi, Y Xie, Emerging Memory Technologies. SpringerX. Dong, C. Xu, N. Jouppi, and Y. Xie, \"Nvsim: A circuit-level performance, energy, and area model for emerging non-volatile memory,\" in Emerging Memory Technologies, pp. 15-50, Springer, 2014.\n\nSynopsys. D Compiler, R User, M Guide, D. Compiler, R. User, and M. Guide, \"Synopsys,\" Inc., see http://www. synopsys. com, 2000.\n\nVteam: A general model for voltage-controlled memristors. S Kvatinsky, M Ramadan, E G Friedman, A Kolodny, IEEE Transactions on Circuits and Systems II: Express Briefs. 628S. Kvatinsky, M. Ramadan, E. G. Friedman, and A. Kolodny, \"Vteam: A general model for voltage-controlled memristors,\" IEEE Transactions on Circuits and Systems II: Express Briefs, vol. 62, no. 8, pp. 786-790, 2015.\n\nUci machine learning repository. \"Uci machine learning repository.\" https://archive.ics.uci.edu/ml/index. php.\n\nk-means gpu. \"k-means gpu.\" https://github.com/NVIDIA/kmeans.\n\nG-dbscan: A gpu accelerated algorithm for density-based clustering. G Andrade, G Ramos, D Madeira, R Sachetto, R Ferreira, L Rocha, Procedia Computer Science. 18G. Andrade, G. Ramos, D. Madeira, R. Sachetto, R. Ferreira, and L. Rocha, \"G-dbscan: A gpu accelerated algorithm for density-based clustering,\" Procedia Computer Science, vol. 18, pp. 369-378, 2013.\n\nGradient-based learning applied to document recognition. Y Lecun, L Bottou, Y Bengio, P Haffner, Proceedings of the IEEE. 8611Y. LeCun, L. Bottou, Y. Bengio, and P. Haffner, \"Gradient-based learning applied to document recognition,\" Proceedings of the IEEE, vol. 86, no. 11, pp. 2278-2324, 1998.\n\nGrammatical facial expressions. \"Grammatical facial expressions.\" https://archive.ics.uci.edu/ml/datasets/ Grammatical+Facial+Expressions.\n\nHuman activity recognition on smartphones using a multiclass hardware-friendly support vector machine. D Anguita, A Ghio, L Oneto, X Parra, J L Reyes-Ortiz, SpringerInternational workshop on ambient assisted livingD. Anguita, A. Ghio, L. Oneto, X. Parra, and J. L. Reyes-Ortiz, \"Human activity recognition on smartphones using a multiclass hardware-friendly support vector machine,\" in International workshop on ambient assisted living, pp. 216-223, Springer, 2012.\n\nIndications of nonlinear deterministic and finite-dimensional structures in time series of brain electrical activity: Dependence on recording region and brain state. R G Andrzejak, K Lehnertz, F Mormann, C Rieke, P David, C E Elger, Physical Review E. 64661907R. G. Andrzejak, K. Lehnertz, F. Mormann, C. Rieke, P. David, and C. E. Elger, \"Indications of nonlinear deterministic and finite-dimensional structures in time series of brain electrical activity: Dependence on recording region and brain state,\" Physical Review E, vol. 64, no. 6, p. 061907, 2001.\n\nChemical gas sensor drift compensation using classifier ensembles. A Vergara, S Vembu, T Ayhan, M A Ryan, M L Homer, R Huerta, Sensors and Actuators B: Chemical. 166A. Vergara, S. Vembu, T. Ayhan, M. A. Ryan, M. L. Homer, and R. Huerta, \"Chemical gas sensor drift compensation using classifier ensembles,\" Sensors and Actuators B: Chemical, vol. 166, pp. 320-329, 2012.\n\nGesture unit segmentation using support vector machines: segmenting gestures from rest positions. R C Madeo, C A Lima, S M Peres, Proceedings of the 28th Annual ACM Symposium on Applied Computing. the 28th Annual ACM Symposium on Applied ComputingACMR. C. Madeo, C. A. Lima, and S. M. Peres, \"Gesture unit segmentation using support vector machines: segmenting gestures from rest positions,\" in Proceedings of the 28th Annual ACM Symposium on Applied Computing, pp. 46-52, ACM, 2013.\n\nUci machine learning repository. \"Uci machine learning repository.\" http://archive.ics.uci.edu/ml/datasets/ ISOLET.\n\nFast agglomerative hierarchical clustering algorithm using locality-sensitive hashing. H Koga, T Ishibashi, T Watanabe, Knowledge and Information Systems. 121H. Koga, T. Ishibashi, and T. Watanabe, \"Fast agglomerative hierarchical clustering algorithm using locality-sensitive hashing,\" Knowledge and Information Systems, vol. 12, no. 1, pp. 25-53, 2007.\n\nCompressed kmeans for large-scale clustering. X Shen, W Liu, I Tsang, F Shen, Q.-S Sun, Thirty-First AAAI Conference on Artificial Intelligence. X. Shen, W. Liu, I. Tsang, F. Shen, and Q.-S. Sun, \"Compressed k- means for large-scale clustering,\" in Thirty-First AAAI Conference on Artificial Intelligence, 2017.\n\nA comparative study on distance measuring approaches for clustering. S Pandit, S Gupta, International Journal of Research in Computer Science. 21S. Pandit, S. Gupta, et al., \"A comparative study on distance measuring approaches for clustering,\" International Journal of Research in Computer Science, vol. 2, no. 1, pp. 29-31, 2011.\n\nHamming distance metric learning. M Norouzi, D J Fleet, R R Salakhutdinov, Advances in neural information processing systems. M. Norouzi, D. J. Fleet, and R. R. Salakhutdinov, \"Hamming distance metric learning,\" in Advances in neural information processing systems, pp. 1061-1069, 2012.\n\nVisualizing data using t-sne. L V D Maaten, G Hinton, Journal of machine learning research. 9L. v. d. Maaten and G. Hinton, \"Visualizing data using t-sne,\" Journal of machine learning research, vol. 9, no. Nov, pp. 2579-2605, 2008.\n\nRe-nuca: A practical nuca architecture for reram based last-level caches. J B Kotra, M Arjomand, D Guttman, M T Kandemir, C R Das, 2016 IEEE International Parallel and Distributed Processing Symposium (IPDPS). IEEEJ. B. Kotra, M. Arjomand, D. Guttman, M. T. Kandemir, and C. R. Das, \"Re-nuca: A practical nuca architecture for reram based last-level caches,\" in 2016 IEEE International Parallel and Distributed Processing Symposium (IPDPS), pp. 576-585, IEEE, 2016.\n\nGpu acceleration of iterative clustering. J D Hall, J C Hart, The ACM Workshop on General Purpose Computing on Graphics Processors. J. D. Hall and J. C. Hart, \"Gpu acceleration of iterative clustering,\" in The ACM Workshop on General Purpose Computing on Graphics Processors, pp. 45-52, 2004.\n\nClustering billions of data points using gpus. R Wu, B Zhang, M Hsu, Proceedings of the combined workshops on UnConventional high performance computing workshop plus memory access workshop. the combined workshops on UnConventional high performance computing workshop plus memory access workshopACMR. Wu, B. Zhang, and M. Hsu, \"Clustering billions of data points using gpus,\" in Proceedings of the combined workshops on UnConventional high performance computing workshop plus memory access workshop, pp. 1-6, ACM, 2009.\n\nAccelerating k-means clustering with parallel implementations and gpu computing. J Bhimani, M Leeser, N Mi, 2015 IEEE High Performance Extreme Computing Conference (HPEC). IEEEJ. Bhimani, M. Leeser, and N. Mi, \"Accelerating k-means clustering with parallel implementations and gpu computing,\" in 2015 IEEE High Performance Extreme Computing Conference (HPEC), pp. 1-6, IEEE, 2015.\n\nMulti-core for k-means clustering on fpga. J Canilho, M V\u00e9stias, H Neto, 2016 26th International Conference on Field Programmable Logic and Applications (FPL). IEEEJ. Canilho, M. V\u00e9stias, and H. Neto, \"Multi-core for k-means clustering on fpga,\" in 2016 26th International Conference on Field Programmable Logic and Applications (FPL), pp. 1-4, IEEE, 2016.\n\nFpga-based k-means clustering using tree-based data structures. F Winterstein, S Bayliss, G A Constantinides, 2013 23rd International Conference on Field programmable Logic and Applications. IEEEF. Winterstein, S. Bayliss, and G. A. Constantinides, \"Fpga-based k-means clustering using tree-based data structures,\" in 2013 23rd In- ternational Conference on Field programmable Logic and Applications, pp. 1-6, IEEE, 2013.\n\nK-means hashing: An affinity-preserving quantization method for learning binary compact codes. K He, F Wen, J Sun, Proceedings of the IEEE conference on computer vision and pattern recognition. the IEEE conference on computer vision and pattern recognitionK. He, F. Wen, and J. Sun, \"K-means hashing: An affinity-preserving quantization method for learning binary compact codes,\" in Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 2938-2945, 2013.\n\nHashing for similarity search: A survey. J Wang, H T Shen, J Song, J Ji, arXiv:1408.2927arXiv preprintJ. Wang, H. T. Shen, J. Song, and J. Ji, \"Hashing for similarity search: A survey,\" arXiv preprint arXiv:1408.2927, 2014.\n\nNeural cache: Bit-serial in-cache acceleration of deep neural networks. C Eckert, X Wang, J Wang, A Subramaniyan, R Iyer, D Sylvester, D Blaauw, R Das, arXiv:1805.03718arXiv preprintC. Eckert, X. Wang, J. Wang, A. Subramaniyan, R. Iyer, D. Sylvester, D. Blaauw, and R. Das, \"Neural cache: Bit-serial in-cache acceleration of deep neural networks,\" arXiv preprint arXiv:1805.03718, 2018.\n\nDrisa: A dram-based reconfigurable in-situ accelerator. S Li, D Niu, K T Malladi, H Zheng, B Brennan, Y Xie, Proceedings of the 50th Annual IEEE/ACM International Symposium on Microarchitecture. the 50th Annual IEEE/ACM International Symposium on MicroarchitectureACMS. Li, D. Niu, K. T. Malladi, H. Zheng, B. Brennan, and Y. Xie, \"Drisa: A dram-based reconfigurable in-situ accelerator,\" in Proceedings of the 50th Annual IEEE/ACM International Symposium on Microarchitecture, pp. 288-301, ACM, 2017.\n\nAmbit: Inmemory accelerator for bulk bitwise operations using commodity dram technology. V Seshadri, D Lee, T Mullins, H Hassan, A Boroumand, J Kim, M A Kozuch, O Mutlu, P B Gibbons, T C Mowry, 2017 50th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO). IEEEV. Seshadri, D. Lee, T. Mullins, H. Hassan, A. Boroumand, J. Kim, M. A. Kozuch, O. Mutlu, P. B. Gibbons, and T. C. Mowry, \"Ambit: In- memory accelerator for bulk bitwise operations using commodity dram technology,\" in 2017 50th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO), pp. 273-287, IEEE, 2017.\n\nLiquid silicon: A nonvolatile fully programmable processing-in-memory processor with monolithically integrated reram. Y Zha, E Nowak, J Li, IEEE Journal of Solid-State Circuits. 554Y. Zha, E. Nowak, and J. Li, \"Liquid silicon: A nonvolatile fully programmable processing-in-memory processor with monolithically integrated reram,\" IEEE Journal of Solid-State Circuits, vol. 55, no. 4, pp. 908-919, 2020.\n\nDima: a depthwise cnn in-memory accelerator. S Angizi, Z He, D Fan, 2018 IEEE/ACM International Conference on Computer-Aided Design (ICCAD). IEEES. Angizi, Z. He, and D. Fan, \"Dima: a depthwise cnn in-memory accelerator,\" in 2018 IEEE/ACM International Conference on Computer- Aided Design (ICCAD), pp. 1-8, IEEE, 2018.\n\nParapim: a parallel processing-in-memory accelerator for binary-weight deep neural networks. S Angizi, Z He, D Fan, Proceedings of the 24th Asia and South Pacific Design Automation Conference. the 24th Asia and South Pacific Design Automation ConferenceACMS. Angizi, Z. He, and D. Fan, \"Parapim: a parallel processing-in-memory accelerator for binary-weight deep neural networks,\" in Proceedings of the 24th Asia and South Pacific Design Automation Conference, pp. 127-132, ACM, 2019.\n\nPima-logic: a novel processing-inmemory architecture for highly flexible and energy-efficient logic computation. S Angizi, Z He, D Fan, Proceedings of the 55th Annual Design Automation Conference. the 55th Annual Design Automation ConferenceACM162S. Angizi, Z. He, and D. Fan, \"Pima-logic: a novel processing-in- memory architecture for highly flexible and energy-efficient logic computation,\" in Proceedings of the 55th Annual Design Automation Conference, p. 162, ACM, 2018.\n\nGraphr: Accelerating graph processing using reram. L Song, Y Zhuo, X Qian, H Li, Y Chen, 2018 IEEE International Symposium on High Performance Computer Architecture (HPCA). IEEEL. Song, Y. Zhuo, X. Qian, H. Li, and Y. Chen, \"Graphr: Accelerating graph processing using reram,\" in 2018 IEEE International Symposium on High Performance Computer Architecture (HPCA), pp. 531-543, IEEE, 2018.\n\nMemristive boltzmann machine: A hardware accelerator for combinatorial optimization and deep learning. M N Bojnordi, E Ipek, High Performance Computer Architecture (HPCA), 2016 IEEE International Symposium on. IEEEM. N. Bojnordi and E. Ipek, \"Memristive boltzmann machine: A hardware accelerator for combinatorial optimization and deep learning,\" in High Performance Computer Architecture (HPCA), 2016 IEEE International Symposium on, pp. 1-13, IEEE, 2016.\n\nThe memristive boltzmann machines. M N Bojnordi, E Ipek, IEEE Micro. 373M. N. Bojnordi and E. Ipek, \"The memristive boltzmann machines,\" IEEE Micro, vol. 37, no. 3, pp. 22-29, 2017.\n\nNnpim: A processing in-memory architecture for neural network acceleration. K Ni, X Yin, A F Laguna, S Joshi, S D\u00fcnkel, M Trentzsch, J M\u00fceller, S Beyer, M Niemier, X S Hu, IEEE Transactions on Computers. 689Ferroelectric ternaryK. Ni, X. Yin, A. F. Laguna, S. Joshi, S. D\u00fcnkel, M. Trentzsch, J. M\u00fceller, S. Beyer, M. Niemier, X. S. Hu, et al., \"Ferroelectric ternary [103] S. Gupta, M. Imani, H. Kaur, and T. S. Rosing, \"Nnpim: A process- ing in-memory architecture for neural network acceleration,\" IEEE Transactions on Computers, vol. 68, no. 9, pp. 1325-1337, 2019.\n\nDeep learning acceleration with neuron-to-memory transformation. M Imani, M S Razlighi, Y Kim, S Gupta, F Koushanfar, T Rosing, 2020 IEEE International Symposium on High Performance Computer Architecture (HPCA). IEEEM. Imani, M. S. Razlighi, Y. Kim, S. Gupta, F. Koushanfar, and T. Ros- ing, \"Deep learning acceleration with neuron-to-memory transformation,\" in 2020 IEEE International Symposium on High Performance Computer Architecture (HPCA), pp. 1-14, IEEE, 2020.\n\nFelix: fast and energy-efficient logic in memory. S Gupta, ICCAD. ACM55S. Gupta et al., \"Felix: fast and energy-efficient logic in memory,\" in ICCAD, p. 55, ACM, 2018.\n\nSearchd: A memory-centric hyperdimensional computing with stochastic training. M Imani, X Yin, J Messerly, S Gupta, M Niemier, X S Hu, T Rosing, IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems. M. Imani, X. Yin, J. Messerly, S. Gupta, M. Niemier, X. S. Hu, and T. Rosing, \"Searchd: A memory-centric hyperdimensional computing with stochastic training,\" IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, 2019.\n\nOrchard: Visual object recognition accelerator based on approximate in-memory processing. Y Kim, M Imani, T Rosing, 2017 IEEE/ACM International Conference on Computer-Aided Design (ICCAD). IEEEY. Kim, M. Imani, and T. Rosing, \"Orchard: Visual object recog- nition accelerator based on approximate in-memory processing,\" in 2017 IEEE/ACM International Conference on Computer-Aided Design (ICCAD), pp. 25-32, IEEE, 2017.\n\nGas: A heterogeneous memory architecture for graph processing. M Zhou, M Imani, S Gupta, T Rosing, Proceedings of the International Symposium on Low Power Electronics and Design. the International Symposium on Low Power Electronics and DesignM. Zhou, M. Imani, S. Gupta, and T. Rosing, \"Gas: A heterogeneous memory architecture for graph processing,\" in Proceedings of the International Symposium on Low Power Electronics and Design, pp. 1-6, 2018.\n\nGram: graph processing in a reram-based computational memory. M Zhou, M Imani, S Gupta, Y Kim, T Rosing, ASP-DAC. M. Zhou, M. Imani, S. Gupta, Y. Kim, and T. Rosing, \"Gram: graph processing in a reram-based computational memory.,\" in ASP-DAC, pp. 591-596, 2019.\n\nNvquery: Efficient query processing in non-volatile memory. M Imani, S Gupta, S Sharma, T Rosing, IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems. M. Imani, S. Gupta, S. Sharma, and T. Rosing, \"Nvquery: Efficient query processing in non-volatile memory,\" IEEE Transactions on Computer- Aided Design of Integrated Circuits and Systems, 2018.\n\nFinder: Accelerating fm-indexbased exact pattern matching in genomic sequences through reram technology. F Zokaee, M Zhang, L Jiang, 2019 28th International Conference on Parallel Architectures and Compilation Techniques (PACT). IEEE2content-addressable memory for one-shot learningF. Zokaee, M. Zhang, and L. Jiang, \"Finder: Accelerating fm-index- based exact pattern matching in genomic sequences through reram technology,\" in 2019 28th International Conference on Parallel Ar- chitectures and Compilation Techniques (PACT), pp. 284-295, IEEE, 2019. content-addressable memory for one-shot learning,\" Nature Electronics, vol. 2, no. 11, pp. 521-529, 2019.\n\nEmerging trends in design and applications of memory-based computing and content-addressable memories. R Karam, R Puri, S Ghosh, S Bhunia, Proceedings of the IEEE. 1038R. Karam, R. Puri, S. Ghosh, and S. Bhunia, \"Emerging trends in design and applications of memory-based computing and content-addressable memories,\" Proceedings of the IEEE, vol. 103, no. 8, pp. 1311-1330, 2015.\n\nAnalog content-addressable memories with memristors. C Li, C E Graves, X Sheng, D Miller, M Foltin, G Pedretti, J P Strachan, Nature communications. 111C. Li, C. E. Graves, X. Sheng, D. Miller, M. Foltin, G. Pedretti, and J. P. Strachan, \"Analog content-addressable memories with memristors,\" Nature communications, vol. 11, no. 1, pp. 1-8, 2020.\n", "annotations": {"author": "[{\"start\":\"88\",\"end\":\"160\"},{\"start\":\"161\",\"end\":\"259\"},{\"start\":\"260\",\"end\":\"352\"},{\"start\":\"353\",\"end\":\"428\"},{\"start\":\"429\",\"end\":\"528\"},{\"start\":\"529\",\"end\":\"621\"}]", "publisher": null, "author_last_name": "[{\"start\":\"95\",\"end\":\"100\"},{\"start\":\"171\",\"end\":\"178\"},{\"start\":\"268\",\"end\":\"273\"},{\"start\":\"361\",\"end\":\"365\"},{\"start\":\"437\",\"end\":\"440\"},{\"start\":\"536\",\"end\":\"542\"}]", "author_first_name": "[{\"start\":\"88\",\"end\":\"94\"},{\"start\":\"161\",\"end\":\"170\"},{\"start\":\"260\",\"end\":\"267\"},{\"start\":\"353\",\"end\":\"360\"},{\"start\":\"429\",\"end\":\"436\"},{\"start\":\"529\",\"end\":\"535\"}]", "author_affiliation": "[{\"start\":\"118\",\"end\":\"159\"},{\"start\":\"198\",\"end\":\"258\"},{\"start\":\"291\",\"end\":\"351\"},{\"start\":\"367\",\"end\":\"427\"},{\"start\":\"465\",\"end\":\"527\"},{\"start\":\"560\",\"end\":\"620\"}]", "title": "[{\"start\":\"1\",\"end\":\"85\"},{\"start\":\"622\",\"end\":\"706\"}]", "venue": null, "abstract": "[{\"start\":\"844\",\"end\":\"2319\"}]", "bib_ref": "[{\"start\":\"2774\",\"end\":\"2777\",\"attributes\":{\"ref_id\":\"b0\"}},{\"start\":\"2999\",\"end\":\"3002\",\"attributes\":{\"ref_id\":\"b1\"}},{\"start\":\"3004\",\"end\":\"3007\",\"attributes\":{\"ref_id\":\"b4\"}},{\"start\":\"3307\",\"end\":\"3310\",\"attributes\":{\"ref_id\":\"b5\"}},{\"start\":\"3312\",\"end\":\"3315\",\"attributes\":{\"ref_id\":\"b7\"}},{\"start\":\"3789\",\"end\":\"3792\",\"attributes\":{\"ref_id\":\"b8\"}},{\"start\":\"3794\",\"end\":\"3798\",\"attributes\":{\"ref_id\":\"b15\"}},{\"start\":\"3956\",\"end\":\"3960\",\"attributes\":{\"ref_id\":\"b16\"}},{\"start\":\"3962\",\"end\":\"3966\",\"attributes\":{\"ref_id\":\"b17\"}},{\"start\":\"4426\",\"end\":\"4430\",\"attributes\":{\"ref_id\":\"b15\"}},{\"start\":\"4486\",\"end\":\"4490\",\"attributes\":{\"ref_id\":\"b14\"}},{\"start\":\"4492\",\"end\":\"4496\",\"attributes\":{\"ref_id\":\"b16\"}},{\"start\":\"4498\",\"end\":\"4502\",\"attributes\":{\"ref_id\":\"b17\"}},{\"start\":\"4824\",\"end\":\"4828\",\"attributes\":{\"ref_id\":\"b17\"}},{\"start\":\"6318\",\"end\":\"6319\"},{\"start\":\"7690\",\"end\":\"7694\",\"attributes\":{\"ref_id\":\"b18\"}},{\"start\":\"7696\",\"end\":\"7700\",\"attributes\":{\"ref_id\":\"b20\"}},{\"start\":\"7827\",\"end\":\"7831\",\"attributes\":{\"ref_id\":\"b21\"}},{\"start\":\"7833\",\"end\":\"7837\",\"attributes\":{\"ref_id\":\"b25\"}},{\"start\":\"8060\",\"end\":\"8064\",\"attributes\":{\"ref_id\":\"b26\"}},{\"start\":\"8789\",\"end\":\"8793\",\"attributes\":{\"ref_id\":\"b23\"}},{\"start\":\"8795\",\"end\":\"8799\",\"attributes\":{\"ref_id\":\"b27\"}},{\"start\":\"8801\",\"end\":\"8805\",\"attributes\":{\"ref_id\":\"b28\"}},{\"start\":\"9292\",\"end\":\"9296\",\"attributes\":{\"ref_id\":\"b29\"}},{\"start\":\"9747\",\"end\":\"9751\",\"attributes\":{\"ref_id\":\"b30\"}},{\"start\":\"10687\",\"end\":\"10691\",\"attributes\":{\"ref_id\":\"b31\"}},{\"start\":\"10693\",\"end\":\"10697\",\"attributes\":{\"ref_id\":\"b32\"}},{\"start\":\"11053\",\"end\":\"11057\",\"attributes\":{\"ref_id\":\"b33\"}},{\"start\":\"11059\",\"end\":\"11063\",\"attributes\":{\"ref_id\":\"b36\"}},{\"start\":\"11259\",\"end\":\"11263\",\"attributes\":{\"ref_id\":\"b37\"}},{\"start\":\"11265\",\"end\":\"11269\",\"attributes\":{\"ref_id\":\"b39\"}},{\"start\":\"11468\",\"end\":\"11472\",\"attributes\":{\"ref_id\":\"b40\"}},{\"start\":\"11474\",\"end\":\"11478\",\"attributes\":{\"ref_id\":\"b41\"}},{\"start\":\"12152\",\"end\":\"12156\",\"attributes\":{\"ref_id\":\"b40\"}},{\"start\":\"13882\",\"end\":\"13886\",\"attributes\":{\"ref_id\":\"b42\"}},{\"start\":\"14147\",\"end\":\"14151\",\"attributes\":{\"ref_id\":\"b14\"}},{\"start\":\"14153\",\"end\":\"14157\",\"attributes\":{\"ref_id\":\"b16\"}},{\"start\":\"14159\",\"end\":\"14163\",\"attributes\":{\"ref_id\":\"b17\"}},{\"start\":\"16476\",\"end\":\"16480\",\"attributes\":{\"ref_id\":\"b43\"}},{\"start\":\"16482\",\"end\":\"16486\",\"attributes\":{\"ref_id\":\"b44\"}},{\"start\":\"17414\",\"end\":\"17418\",\"attributes\":{\"ref_id\":\"b38\"}},{\"start\":\"17420\",\"end\":\"17424\",\"attributes\":{\"ref_id\":\"b45\"}},{\"start\":\"22746\",\"end\":\"22750\",\"attributes\":{\"ref_id\":\"b15\"}},{\"start\":\"22752\",\"end\":\"22756\",\"attributes\":{\"ref_id\":\"b46\"}},{\"start\":\"22758\",\"end\":\"22762\",\"attributes\":{\"ref_id\":\"b51\"}},{\"start\":\"22864\",\"end\":\"22868\",\"attributes\":{\"ref_id\":\"b15\"}},{\"start\":\"22870\",\"end\":\"22874\",\"attributes\":{\"ref_id\":\"b47\"}},{\"start\":\"23841\",\"end\":\"23845\",\"attributes\":{\"ref_id\":\"b52\"}},{\"start\":\"23865\",\"end\":\"23869\",\"attributes\":{\"ref_id\":\"b53\"}},{\"start\":\"24004\",\"end\":\"24008\",\"attributes\":{\"ref_id\":\"b54\"}},{\"start\":\"24121\",\"end\":\"24125\",\"attributes\":{\"ref_id\":\"b54\"}},{\"start\":\"24724\",\"end\":\"24728\",\"attributes\":{\"ref_id\":\"b15\"}},{\"start\":\"34657\",\"end\":\"34661\",\"attributes\":{\"ref_id\":\"b55\"}},{\"start\":\"34663\",\"end\":\"34667\",\"attributes\":{\"ref_id\":\"b56\"}},{\"start\":\"38810\",\"end\":\"38814\",\"attributes\":{\"ref_id\":\"b57\"}},{\"start\":\"38816\",\"end\":\"38820\",\"attributes\":{\"ref_id\":\"b59\"}},{\"start\":\"40323\",\"end\":\"40327\",\"attributes\":{\"ref_id\":\"b60\"}},{\"start\":\"44145\",\"end\":\"44149\",\"attributes\":{\"ref_id\":\"b61\"}},{\"start\":\"44151\",\"end\":\"44155\",\"attributes\":{\"ref_id\":\"b62\"}},{\"start\":\"45149\",\"end\":\"45153\",\"attributes\":{\"ref_id\":\"b63\"}},{\"start\":\"45155\",\"end\":\"45159\",\"attributes\":{\"ref_id\":\"b64\"}},{\"start\":\"45471\",\"end\":\"45475\",\"attributes\":{\"ref_id\":\"b65\"}},{\"start\":\"45529\",\"end\":\"45533\",\"attributes\":{\"ref_id\":\"b66\"}},{\"start\":\"45655\",\"end\":\"45659\",\"attributes\":{\"ref_id\":\"b52\"}},{\"start\":\"46304\",\"end\":\"46308\",\"attributes\":{\"ref_id\":\"b67\"}},{\"start\":\"46488\",\"end\":\"46492\",\"attributes\":{\"ref_id\":\"b47\"}},{\"start\":\"46494\",\"end\":\"46498\",\"attributes\":{\"ref_id\":\"b48\"}},{\"start\":\"47666\",\"end\":\"47670\",\"attributes\":{\"ref_id\":\"b68\"}},{\"start\":\"48654\",\"end\":\"48658\",\"attributes\":{\"ref_id\":\"b69\"}},{\"start\":\"48663\",\"end\":\"48667\",\"attributes\":{\"ref_id\":\"b70\"}},{\"start\":\"49497\",\"end\":\"49501\",\"attributes\":{\"ref_id\":\"b33\"}},{\"start\":\"49503\",\"end\":\"49507\",\"attributes\":{\"ref_id\":\"b78\"}},{\"start\":\"49509\",\"end\":\"49513\",\"attributes\":{\"ref_id\":\"b79\"}},{\"start\":\"49675\",\"end\":\"49679\",\"attributes\":{\"ref_id\":\"b23\"}},{\"start\":\"49681\",\"end\":\"49685\",\"attributes\":{\"ref_id\":\"b80\"}},{\"start\":\"49687\",\"end\":\"49691\",\"attributes\":{\"ref_id\":\"b81\"}},{\"start\":\"50818\",\"end\":\"50822\",\"attributes\":{\"ref_id\":\"b82\"}},{\"start\":\"59913\",\"end\":\"59917\",\"attributes\":{\"ref_id\":\"b14\"}},{\"start\":\"62063\",\"end\":\"62067\",\"attributes\":{\"ref_id\":\"b83\"}},{\"start\":\"63746\",\"end\":\"63750\",\"attributes\":{\"ref_id\":\"b70\"}},{\"start\":\"63752\",\"end\":\"63756\",\"attributes\":{\"ref_id\":\"b84\"}},{\"start\":\"63758\",\"end\":\"63762\",\"attributes\":{\"ref_id\":\"b88\"}},{\"start\":\"63843\",\"end\":\"63847\",\"attributes\":{\"ref_id\":\"b34\"}},{\"start\":\"63849\",\"end\":\"63853\",\"attributes\":{\"ref_id\":\"b36\"}},{\"start\":\"64162\",\"end\":\"64166\",\"attributes\":{\"ref_id\":\"b89\"}},{\"start\":\"64168\",\"end\":\"64172\",\"attributes\":{\"ref_id\":\"b90\"}},{\"start\":\"64427\",\"end\":\"64431\",\"attributes\":{\"ref_id\":\"b91\"}},{\"start\":\"64535\",\"end\":\"64539\",\"attributes\":{\"ref_id\":\"b92\"}},{\"start\":\"64541\",\"end\":\"64545\",\"attributes\":{\"ref_id\":\"b93\"}},{\"start\":\"65071\",\"end\":\"65075\",\"attributes\":{\"ref_id\":\"b15\"}},{\"start\":\"65077\",\"end\":\"65081\",\"attributes\":{\"ref_id\":\"b16\"}},{\"start\":\"65083\",\"end\":\"65087\",\"attributes\":{\"ref_id\":\"b94\"}},{\"start\":\"65199\",\"end\":\"65203\",\"attributes\":{\"ref_id\":\"b13\"}},{\"start\":\"65205\",\"end\":\"65209\",\"attributes\":{\"ref_id\":\"b16\"}},{\"start\":\"65211\",\"end\":\"65215\",\"attributes\":{\"ref_id\":\"b17\"}},{\"start\":\"65217\",\"end\":\"65221\",\"attributes\":{\"ref_id\":\"b94\"}},{\"start\":\"65223\",\"end\":\"65227\",\"attributes\":{\"ref_id\":\"b97\"}},{\"start\":\"65246\",\"end\":\"65249\",\"attributes\":{\"ref_id\":\"b8\"}},{\"start\":\"65251\",\"end\":\"65255\",\"attributes\":{\"ref_id\":\"b10\"}},{\"start\":\"65257\",\"end\":\"65262\",\"attributes\":{\"ref_id\":\"b98\"}},{\"start\":\"65272\",\"end\":\"65277\",\"attributes\":{\"ref_id\":\"b99\"}},{\"start\":\"65279\",\"end\":\"65284\",\"attributes\":{\"ref_id\":\"b100\"}},{\"start\":\"65407\",\"end\":\"65411\",\"attributes\":{\"ref_id\":\"b17\"}},{\"start\":\"65416\",\"end\":\"65420\",\"attributes\":{\"ref_id\":\"b16\"}},{\"start\":\"65524\",\"end\":\"65528\",\"attributes\":{\"ref_id\":\"b13\"}},{\"start\":\"65614\",\"end\":\"65618\",\"attributes\":{\"ref_id\":\"b14\"}},{\"start\":\"65867\",\"end\":\"65871\",\"attributes\":{\"ref_id\":\"b15\"}},{\"start\":\"65873\",\"end\":\"65877\",\"attributes\":{\"ref_id\":\"b17\"}},{\"start\":\"66026\",\"end\":\"66030\",\"attributes\":{\"ref_id\":\"b17\"}},{\"start\":\"66054\",\"end\":\"66058\",\"attributes\":{\"ref_id\":\"b15\"}},{\"start\":\"66393\",\"end\":\"66397\",\"attributes\":{\"ref_id\":\"b45\"}},{\"start\":\"66406\",\"end\":\"66411\",\"attributes\":{\"ref_id\":\"b102\"}},{\"start\":\"66438\",\"end\":\"66442\",\"attributes\":{\"ref_id\":\"b38\"}},{\"start\":\"66444\",\"end\":\"66449\",\"attributes\":{\"ref_id\":\"b103\"}},{\"start\":\"66451\",\"end\":\"66456\",\"attributes\":{\"ref_id\":\"b104\"}},{\"start\":\"66477\",\"end\":\"66482\",\"attributes\":{\"ref_id\":\"b105\"}},{\"start\":\"66501\",\"end\":\"66506\",\"attributes\":{\"ref_id\":\"b106\"}},{\"start\":\"66508\",\"end\":\"66513\",\"attributes\":{\"ref_id\":\"b107\"}},{\"start\":\"66541\",\"end\":\"66545\",\"attributes\":{\"ref_id\":\"b44\"}},{\"start\":\"66547\",\"end\":\"66552\",\"attributes\":{\"ref_id\":\"b108\"}},{\"start\":\"66928\",\"end\":\"66932\",\"attributes\":{\"ref_id\":\"b45\"}},{\"start\":\"66953\",\"end\":\"66957\",\"attributes\":{\"ref_id\":\"b38\"}},{\"start\":\"67326\",\"end\":\"67331\",\"attributes\":{\"ref_id\":\"b109\"}},{\"start\":\"67333\",\"end\":\"67338\",\"attributes\":{\"ref_id\":\"b110\"}},{\"start\":\"67361\",\"end\":\"67366\",\"attributes\":{\"ref_id\":\"b111\"}}]", "figure": "[{\"start\":\"68212\",\"end\":\"68256\",\"attributes\":{\"id\":\"fig_0\"}},{\"start\":\"68257\",\"end\":\"68329\",\"attributes\":{\"id\":\"fig_1\"}},{\"start\":\"68330\",\"end\":\"68401\",\"attributes\":{\"id\":\"fig_2\"}},{\"start\":\"68402\",\"end\":\"68457\",\"attributes\":{\"id\":\"fig_3\"}},{\"start\":\"68458\",\"end\":\"68536\",\"attributes\":{\"id\":\"fig_4\"}},{\"start\":\"68537\",\"end\":\"68616\",\"attributes\":{\"id\":\"fig_5\"}},{\"start\":\"68617\",\"end\":\"68870\",\"attributes\":{\"id\":\"fig_6\"}},{\"start\":\"68871\",\"end\":\"68931\",\"attributes\":{\"id\":\"fig_7\"}},{\"start\":\"68932\",\"end\":\"69038\",\"attributes\":{\"id\":\"fig_8\"}},{\"start\":\"69039\",\"end\":\"69114\",\"attributes\":{\"id\":\"fig_9\"}},{\"start\":\"69115\",\"end\":\"69344\",\"attributes\":{\"id\":\"fig_10\"}},{\"start\":\"69345\",\"end\":\"69643\",\"attributes\":{\"id\":\"fig_11\"}},{\"start\":\"69644\",\"end\":\"70688\",\"attributes\":{\"id\":\"fig_12\"}},{\"start\":\"70689\",\"end\":\"70844\",\"attributes\":{\"id\":\"fig_13\"}},{\"start\":\"70845\",\"end\":\"70958\",\"attributes\":{\"id\":\"fig_14\"}},{\"start\":\"70959\",\"end\":\"71011\",\"attributes\":{\"id\":\"fig_15\"}},{\"start\":\"71012\",\"end\":\"71072\",\"attributes\":{\"id\":\"fig_16\"}},{\"start\":\"71073\",\"end\":\"71181\",\"attributes\":{\"id\":\"fig_17\"}},{\"start\":\"71182\",\"end\":\"71271\",\"attributes\":{\"id\":\"fig_18\"}},{\"start\":\"71272\",\"end\":\"71875\",\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"}},{\"start\":\"71876\",\"end\":\"72350\",\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"}},{\"start\":\"72351\",\"end\":\"72784\",\"attributes\":{\"id\":\"tab_2\",\"type\":\"table\"}},{\"start\":\"72785\",\"end\":\"73374\",\"attributes\":{\"id\":\"tab_3\",\"type\":\"table\"}}]", "paragraph": "[{\"start\":\"2338\",\"end\":\"3316\"},{\"start\":\"3318\",\"end\":\"4113\"},{\"start\":\"4115\",\"end\":\"5078\"},{\"start\":\"5080\",\"end\":\"5487\"},{\"start\":\"5489\",\"end\":\"7380\"},{\"start\":\"7399\",\"end\":\"7938\"},{\"start\":\"7940\",\"end\":\"9154\"},{\"start\":\"9156\",\"end\":\"9409\"},{\"start\":\"9653\",\"end\":\"9752\"},{\"start\":\"9931\",\"end\":\"10125\"},{\"start\":\"10148\",\"end\":\"10756\"},{\"start\":\"10773\",\"end\":\"11737\"},{\"start\":\"11772\",\"end\":\"11879\"},{\"start\":\"11908\",\"end\":\"12023\"},{\"start\":\"12055\",\"end\":\"12244\"},{\"start\":\"12281\",\"end\":\"12486\"},{\"start\":\"12629\",\"end\":\"13887\"},{\"start\":\"13911\",\"end\":\"16157\"},{\"start\":\"16159\",\"end\":\"16188\"},{\"start\":\"16225\",\"end\":\"18795\"},{\"start\":\"18832\",\"end\":\"19744\"},{\"start\":\"19746\",\"end\":\"20449\"},{\"start\":\"20451\",\"end\":\"21109\"},{\"start\":\"21163\",\"end\":\"21592\"},{\"start\":\"21594\",\"end\":\"22582\"},{\"start\":\"22623\",\"end\":\"23737\"},{\"start\":\"23739\",\"end\":\"24218\"},{\"start\":\"24315\",\"end\":\"25170\"},{\"start\":\"25226\",\"end\":\"26124\"},{\"start\":\"26126\",\"end\":\"27364\"},{\"start\":\"27366\",\"end\":\"28264\"},{\"start\":\"28266\",\"end\":\"28636\"},{\"start\":\"28673\",\"end\":\"30449\"},{\"start\":\"30472\",\"end\":\"31287\"},{\"start\":\"31310\",\"end\":\"32648\"},{\"start\":\"32650\",\"end\":\"32846\"},{\"start\":\"32848\",\"end\":\"36597\"},{\"start\":\"36649\",\"end\":\"36872\"},{\"start\":\"36874\",\"end\":\"37713\"},{\"start\":\"37715\",\"end\":\"38436\"},{\"start\":\"38468\",\"end\":\"38760\"},{\"start\":\"38762\",\"end\":\"39253\"},{\"start\":\"39255\",\"end\":\"40240\"},{\"start\":\"40242\",\"end\":\"42126\"},{\"start\":\"42189\",\"end\":\"42311\"},{\"start\":\"42337\",\"end\":\"42748\"},{\"start\":\"42769\",\"end\":\"43299\"},{\"start\":\"43301\",\"end\":\"44156\"},{\"start\":\"44183\",\"end\":\"45042\"},{\"start\":\"45044\",\"end\":\"45057\"},{\"start\":\"45083\",\"end\":\"47355\"},{\"start\":\"47372\",\"end\":\"48465\"},{\"start\":\"48467\",\"end\":\"52687\"},{\"start\":\"52716\",\"end\":\"53585\"},{\"start\":\"53587\",\"end\":\"54790\"},{\"start\":\"54792\",\"end\":\"55707\"},{\"start\":\"55709\",\"end\":\"56181\"},{\"start\":\"56221\",\"end\":\"57547\"},{\"start\":\"57580\",\"end\":\"61491\"},{\"start\":\"61535\",\"end\":\"62998\"},{\"start\":\"63000\",\"end\":\"63609\"},{\"start\":\"63611\",\"end\":\"64359\"},{\"start\":\"64361\",\"end\":\"66031\"},{\"start\":\"66033\",\"end\":\"66834\"},{\"start\":\"66836\",\"end\":\"67543\"},{\"start\":\"67561\",\"end\":\"68211\"}]", "formula": "[{\"start\":\"9410\",\"end\":\"9652\",\"attributes\":{\"id\":\"formula_0\"}},{\"start\":\"9753\",\"end\":\"9930\",\"attributes\":{\"id\":\"formula_1\"}},{\"start\":\"11738\",\"end\":\"11771\",\"attributes\":{\"id\":\"formula_2\"}},{\"start\":\"11880\",\"end\":\"11907\",\"attributes\":{\"id\":\"formula_3\"}},{\"start\":\"12024\",\"end\":\"12054\",\"attributes\":{\"id\":\"formula_4\"}},{\"start\":\"12245\",\"end\":\"12280\",\"attributes\":{\"id\":\"formula_5\"}},{\"start\":\"12487\",\"end\":\"12628\",\"attributes\":{\"id\":\"formula_6\"}},{\"start\":\"21110\",\"end\":\"21162\",\"attributes\":{\"id\":\"formula_7\"}},{\"start\":\"24219\",\"end\":\"24314\",\"attributes\":{\"id\":\"formula_8\"}}]", "table_ref": "[{\"start\":\"24610\",\"end\":\"24619\",\"attributes\":{\"ref_id\":\"tab_0\"}},{\"start\":\"42970\",\"end\":\"42977\",\"attributes\":{\"ref_id\":\"tab_0\"}},{\"start\":\"46500\",\"end\":\"46508\",\"attributes\":{\"ref_id\":\"tab_0\"}},{\"start\":\"46929\",\"end\":\"46938\",\"attributes\":{\"ref_id\":\"tab_0\"}},{\"start\":\"47589\",\"end\":\"47597\",\"attributes\":{\"ref_id\":\"tab_0\"}},{\"start\":\"59177\",\"end\":\"59185\",\"attributes\":{\"ref_id\":\"tab_0\"}}]", "section_header": "[{\"start\":\"2321\",\"end\":\"2336\"},{\"start\":\"7383\",\"end\":\"7397\"},{\"start\":\"10128\",\"end\":\"10146\"},{\"start\":\"10759\",\"end\":\"10771\"},{\"start\":\"13890\",\"end\":\"13909\"},{\"start\":\"16191\",\"end\":\"16223\"},{\"start\":\"18798\",\"end\":\"18830\"},{\"start\":\"22585\",\"end\":\"22621\"},{\"start\":\"25173\",\"end\":\"25195\"},{\"start\":\"25198\",\"end\":\"25224\"},{\"start\":\"28639\",\"end\":\"28671\"},{\"start\":\"30452\",\"end\":\"30470\"},{\"start\":\"31290\",\"end\":\"31308\"},{\"start\":\"36600\",\"end\":\"36628\"},{\"start\":\"36631\",\"end\":\"36647\"},{\"start\":\"38439\",\"end\":\"38466\"},{\"start\":\"42129\",\"end\":\"42153\"},{\"start\":\"42156\",\"end\":\"42187\"},{\"start\":\"42314\",\"end\":\"42335\"},{\"start\":\"42751\",\"end\":\"42767\"},{\"start\":\"44159\",\"end\":\"44181\"},{\"start\":\"45060\",\"end\":\"45081\"},{\"start\":\"47358\",\"end\":\"47370\"},{\"start\":\"52690\",\"end\":\"52714\"},{\"start\":\"56184\",\"end\":\"56219\"},{\"start\":\"57550\",\"end\":\"57578\"},{\"start\":\"61494\",\"end\":\"61533\"},{\"start\":\"67546\",\"end\":\"67559\"},{\"start\":\"68213\",\"end\":\"68221\"},{\"start\":\"68258\",\"end\":\"68266\"},{\"start\":\"68331\",\"end\":\"68339\"},{\"start\":\"68403\",\"end\":\"68411\"},{\"start\":\"68459\",\"end\":\"68467\"},{\"start\":\"68538\",\"end\":\"68546\"},{\"start\":\"68618\",\"end\":\"68636\"},{\"start\":\"68872\",\"end\":\"68882\"},{\"start\":\"68933\",\"end\":\"68941\"},{\"start\":\"69040\",\"end\":\"69048\"},{\"start\":\"69116\",\"end\":\"69129\"},{\"start\":\"70690\",\"end\":\"70699\"},{\"start\":\"70846\",\"end\":\"70855\"},{\"start\":\"70960\",\"end\":\"70969\"},{\"start\":\"71013\",\"end\":\"71022\"},{\"start\":\"71074\",\"end\":\"71083\"},{\"start\":\"71183\",\"end\":\"71192\"},{\"start\":\"71273\",\"end\":\"71284\"},{\"start\":\"71877\",\"end\":\"71890\"},{\"start\":\"72352\",\"end\":\"72369\"},{\"start\":\"72786\",\"end\":\"72805\"}]", "table": "[{\"start\":\"71307\",\"end\":\"71875\"},{\"start\":\"71904\",\"end\":\"72350\"},{\"start\":\"72402\",\"end\":\"72784\"},{\"start\":\"72808\",\"end\":\"73374\"}]", "figure_caption": "[{\"start\":\"68223\",\"end\":\"68256\"},{\"start\":\"68268\",\"end\":\"68329\"},{\"start\":\"68341\",\"end\":\"68401\"},{\"start\":\"68413\",\"end\":\"68457\"},{\"start\":\"68469\",\"end\":\"68536\"},{\"start\":\"68548\",\"end\":\"68616\"},{\"start\":\"68639\",\"end\":\"68870\"},{\"start\":\"68884\",\"end\":\"68931\"},{\"start\":\"68943\",\"end\":\"69038\"},{\"start\":\"69050\",\"end\":\"69114\"},{\"start\":\"69131\",\"end\":\"69344\"},{\"start\":\"69347\",\"end\":\"69643\"},{\"start\":\"69646\",\"end\":\"70688\"},{\"start\":\"70702\",\"end\":\"70844\"},{\"start\":\"70858\",\"end\":\"70958\"},{\"start\":\"70972\",\"end\":\"71011\"},{\"start\":\"71025\",\"end\":\"71072\"},{\"start\":\"71086\",\"end\":\"71181\"},{\"start\":\"71195\",\"end\":\"71271\"},{\"start\":\"71286\",\"end\":\"71307\"},{\"start\":\"71893\",\"end\":\"71904\"},{\"start\":\"72373\",\"end\":\"72402\"}]", "figure_ref": "[{\"start\":\"8488\",\"end\":\"8496\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"10270\",\"end\":\"10279\",\"attributes\":{\"ref_id\":\"fig_1\"}},{\"start\":\"12384\",\"end\":\"12392\",\"attributes\":{\"ref_id\":\"fig_2\"}},{\"start\":\"14622\",\"end\":\"14631\",\"attributes\":{\"ref_id\":\"fig_1\"}},{\"start\":\"14805\",\"end\":\"14814\",\"attributes\":{\"ref_id\":\"fig_1\"}},{\"start\":\"15600\",\"end\":\"15610\",\"attributes\":{\"ref_id\":\"fig_1\"}},{\"start\":\"16143\",\"end\":\"16156\",\"attributes\":{\"ref_id\":\"fig_1\"}},{\"start\":\"16878\",\"end\":\"16887\",\"attributes\":{\"ref_id\":\"fig_3\"}},{\"start\":\"17540\",\"end\":\"17549\",\"attributes\":{\"ref_id\":\"fig_3\"}},{\"start\":\"17795\",\"end\":\"17804\",\"attributes\":{\"ref_id\":\"fig_3\"}},{\"start\":\"18011\",\"end\":\"18020\",\"attributes\":{\"ref_id\":\"fig_3\"}},{\"start\":\"18283\",\"end\":\"18292\",\"attributes\":{\"ref_id\":\"fig_3\"}},{\"start\":\"18730\",\"end\":\"18739\",\"attributes\":{\"ref_id\":\"fig_3\"}},{\"start\":\"20438\",\"end\":\"20447\",\"attributes\":{\"ref_id\":\"fig_3\"}},{\"start\":\"21099\",\"end\":\"21108\",\"attributes\":{\"ref_id\":\"fig_3\"}},{\"start\":\"21876\",\"end\":\"21885\",\"attributes\":{\"ref_id\":\"fig_3\"}},{\"start\":\"22992\",\"end\":\"23001\",\"attributes\":{\"ref_id\":\"fig_3\"}},{\"start\":\"23381\",\"end\":\"23390\",\"attributes\":{\"ref_id\":\"fig_3\"}},{\"start\":\"25553\",\"end\":\"25562\",\"attributes\":{\"ref_id\":\"fig_4\"}},{\"start\":\"26034\",\"end\":\"26043\",\"attributes\":{\"ref_id\":\"fig_4\"}},{\"start\":\"26374\",\"end\":\"26382\",\"attributes\":{\"ref_id\":\"fig_4\"}},{\"start\":\"27115\",\"end\":\"27124\",\"attributes\":{\"ref_id\":\"fig_4\"}},{\"start\":\"27626\",\"end\":\"27635\",\"attributes\":{\"ref_id\":\"fig_4\"}},{\"start\":\"27786\",\"end\":\"27794\",\"attributes\":{\"ref_id\":\"fig_4\"}},{\"start\":\"29283\",\"end\":\"29291\",\"attributes\":{\"ref_id\":\"fig_5\"}},{\"start\":\"29363\",\"end\":\"29371\"},{\"start\":\"29658\",\"end\":\"29666\",\"attributes\":{\"ref_id\":\"fig_5\"}},{\"start\":\"30984\",\"end\":\"30993\",\"attributes\":{\"ref_id\":\"fig_5\"}},{\"start\":\"32120\",\"end\":\"32128\",\"attributes\":{\"ref_id\":\"fig_5\"}},{\"start\":\"32462\",\"end\":\"32470\",\"attributes\":{\"ref_id\":\"fig_5\"}},{\"start\":\"32603\",\"end\":\"32612\",\"attributes\":{\"ref_id\":\"fig_5\"}},{\"start\":\"32830\",\"end\":\"32839\",\"attributes\":{\"ref_id\":\"fig_5\"}},{\"start\":\"33041\",\"end\":\"33049\",\"attributes\":{\"ref_id\":\"fig_5\"}},{\"start\":\"33176\",\"end\":\"33184\",\"attributes\":{\"ref_id\":\"fig_5\"}},{\"start\":\"33494\",\"end\":\"33502\",\"attributes\":{\"ref_id\":\"fig_5\"}},{\"start\":\"33510\",\"end\":\"33518\"},{\"start\":\"34054\",\"end\":\"34093\"},{\"start\":\"35504\",\"end\":\"35513\",\"attributes\":{\"ref_id\":\"fig_7\"}},{\"start\":\"36020\",\"end\":\"36035\",\"attributes\":{\"ref_id\":\"fig_7\"}},{\"start\":\"37697\",\"end\":\"37706\",\"attributes\":{\"ref_id\":\"fig_7\"}},{\"start\":\"39327\",\"end\":\"39336\",\"attributes\":{\"ref_id\":\"fig_9\"}},{\"start\":\"40612\",\"end\":\"40621\",\"attributes\":{\"ref_id\":\"fig_9\"}},{\"start\":\"48867\",\"end\":\"48877\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"49693\",\"end\":\"49703\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"50640\",\"end\":\"50649\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"51387\",\"end\":\"51396\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"54854\",\"end\":\"54863\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"56768\",\"end\":\"56777\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"57177\",\"end\":\"57187\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"57404\",\"end\":\"57414\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"59031\",\"end\":\"59040\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"59811\",\"end\":\"59821\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"60232\",\"end\":\"60242\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"60440\",\"end\":\"60450\",\"attributes\":{\"ref_id\":\"fig_0\"}},{\"start\":\"60847\",\"end\":\"60857\",\"attributes\":{\"ref_id\":\"fig_0\"}}]", "bib_author_first_name": "[{\"start\":\"73704\",\"end\":\"73705\"},{\"start\":\"73713\",\"end\":\"73714\"},{\"start\":\"73715\",\"end\":\"73716\"},{\"start\":\"73912\",\"end\":\"73913\"},{\"start\":\"73914\",\"end\":\"73915\"},{\"start\":\"74109\",\"end\":\"74110\"},{\"start\":\"74111\",\"end\":\"74112\"},{\"start\":\"74120\",\"end\":\"74121\"},{\"start\":\"74122\",\"end\":\"74123\"},{\"start\":\"74131\",\"end\":\"74132\"},{\"start\":\"74133\",\"end\":\"74134\"},{\"start\":\"74143\",\"end\":\"74144\"},{\"start\":\"74145\",\"end\":\"74146\"},{\"start\":\"74157\",\"end\":\"74158\"},{\"start\":\"74159\",\"end\":\"74160\"},{\"start\":\"74174\",\"end\":\"74175\"},{\"start\":\"74480\",\"end\":\"74481\"},{\"start\":\"74482\",\"end\":\"74483\"},{\"start\":\"74490\",\"end\":\"74491\"},{\"start\":\"74492\",\"end\":\"74493\"},{\"start\":\"74502\",\"end\":\"74503\"},{\"start\":\"74504\",\"end\":\"74505\"},{\"start\":\"74515\",\"end\":\"74516\"},{\"start\":\"74517\",\"end\":\"74518\"},{\"start\":\"74802\",\"end\":\"74803\"},{\"start\":\"74804\",\"end\":\"74805\"},{\"start\":\"74816\",\"end\":\"74817\"},{\"start\":\"75017\",\"end\":\"75018\"},{\"start\":\"75023\",\"end\":\"75024\"},{\"start\":\"75030\",\"end\":\"75031\"},{\"start\":\"75037\",\"end\":\"75038\"},{\"start\":\"75043\",\"end\":\"75044\"},{\"start\":\"75282\",\"end\":\"75283\"},{\"start\":\"75289\",\"end\":\"75290\"},{\"start\":\"75296\",\"end\":\"75297\"},{\"start\":\"75615\",\"end\":\"75616\"},{\"start\":\"75624\",\"end\":\"75625\"},{\"start\":\"75636\",\"end\":\"75637\"},{\"start\":\"75644\",\"end\":\"75645\"},{\"start\":\"75654\",\"end\":\"75655\"},{\"start\":\"75664\",\"end\":\"75665\"},{\"start\":\"75666\",\"end\":\"75667\"},{\"start\":\"75676\",\"end\":\"75677\"},{\"start\":\"75686\",\"end\":\"75687\"},{\"start\":\"76086\",\"end\":\"76087\"},{\"start\":\"76093\",\"end\":\"76094\"},{\"start\":\"76101\",\"end\":\"76102\"},{\"start\":\"76108\",\"end\":\"76109\"},{\"start\":\"76117\",\"end\":\"76118\"},{\"start\":\"76434\",\"end\":\"76435\"},{\"start\":\"76445\",\"end\":\"76446\"},{\"start\":\"76455\",\"end\":\"76456\"},{\"start\":\"76717\",\"end\":\"76718\"},{\"start\":\"76724\",\"end\":\"76725\"},{\"start\":\"76731\",\"end\":\"76732\"},{\"start\":\"76740\",\"end\":\"76741\"},{\"start\":\"77144\",\"end\":\"77145\"},{\"start\":\"77153\",\"end\":\"77154\"},{\"start\":\"77165\",\"end\":\"77166\"},{\"start\":\"77179\",\"end\":\"77180\"},{\"start\":\"77181\",\"end\":\"77182\"},{\"start\":\"77195\",\"end\":\"77196\"},{\"start\":\"77201\",\"end\":\"77202\"},{\"start\":\"77743\",\"end\":\"77744\"},{\"start\":\"77753\",\"end\":\"77754\"},{\"start\":\"77762\",\"end\":\"77763\"},{\"start\":\"77770\",\"end\":\"77771\"},{\"start\":\"77780\",\"end\":\"77781\"},{\"start\":\"77791\",\"end\":\"77792\"},{\"start\":\"77801\",\"end\":\"77802\"},{\"start\":\"77813\",\"end\":\"77814\"},{\"start\":\"77821\",\"end\":\"77822\"},{\"start\":\"77829\",\"end\":\"77830\"},{\"start\":\"77831\",\"end\":\"77832\"},{\"start\":\"78293\",\"end\":\"78294\"},{\"start\":\"78301\",\"end\":\"78302\"},{\"start\":\"78309\",\"end\":\"78310\"},{\"start\":\"78315\",\"end\":\"78316\"},{\"start\":\"78666\",\"end\":\"78667\"},{\"start\":\"78676\",\"end\":\"78677\"},{\"start\":\"78686\",\"end\":\"78687\"},{\"start\":\"79254\",\"end\":\"79255\"},{\"start\":\"79263\",\"end\":\"79264\"},{\"start\":\"79272\",\"end\":\"79273\"},{\"start\":\"79279\",\"end\":\"79280\"},{\"start\":\"79764\",\"end\":\"79765\"},{\"start\":\"79771\",\"end\":\"79772\"},{\"start\":\"79777\",\"end\":\"79778\"},{\"start\":\"79783\",\"end\":\"79784\"},{\"start\":\"79792\",\"end\":\"79793\"},{\"start\":\"79800\",\"end\":\"79801\"},{\"start\":\"79807\",\"end\":\"79808\"},{\"start\":\"79815\",\"end\":\"79816\"},{\"start\":\"80231\",\"end\":\"80232\"},{\"start\":\"80242\",\"end\":\"80243\"},{\"start\":\"80249\",\"end\":\"80250\"},{\"start\":\"80266\",\"end\":\"80267\"},{\"start\":\"80285\",\"end\":\"80286\"},{\"start\":\"80287\",\"end\":\"80288\"},{\"start\":\"80299\",\"end\":\"80300\"},{\"start\":\"80305\",\"end\":\"80306\"},{\"start\":\"80307\",\"end\":\"80308\"},{\"start\":\"80319\",\"end\":\"80320\"},{\"start\":\"80714\",\"end\":\"80715\"},{\"start\":\"80956\",\"end\":\"80957\"},{\"start\":\"80966\",\"end\":\"80967\"},{\"start\":\"81187\",\"end\":\"81188\"},{\"start\":\"81196\",\"end\":\"81197\"},{\"start\":\"81207\",\"end\":\"81208\"},{\"start\":\"81209\",\"end\":\"81210\"},{\"start\":\"81446\",\"end\":\"81447\"},{\"start\":\"81461\",\"end\":\"81462\"},{\"start\":\"81471\",\"end\":\"81472\"},{\"start\":\"81489\",\"end\":\"81490\"},{\"start\":\"81982\",\"end\":\"81986\"},{\"start\":\"81992\",\"end\":\"81996\"},{\"start\":\"82001\",\"end\":\"82005\"},{\"start\":\"82011\",\"end\":\"82012\"},{\"start\":\"82426\",\"end\":\"82427\"},{\"start\":\"82434\",\"end\":\"82435\"},{\"start\":\"82447\",\"end\":\"82448\"},{\"start\":\"82762\",\"end\":\"82763\"},{\"start\":\"82986\",\"end\":\"82987\"},{\"start\":\"82988\",\"end\":\"82989\"},{\"start\":\"83226\",\"end\":\"83227\"},{\"start\":\"83243\",\"end\":\"83244\"},{\"start\":\"83245\",\"end\":\"83246\"},{\"start\":\"83752\",\"end\":\"83753\"},{\"start\":\"83768\",\"end\":\"83769\"},{\"start\":\"83779\",\"end\":\"83780\"},{\"start\":\"83781\",\"end\":\"83782\"},{\"start\":\"84122\",\"end\":\"84123\"},{\"start\":\"84129\",\"end\":\"84130\"},{\"start\":\"84131\",\"end\":\"84132\"},{\"start\":\"84598\",\"end\":\"84599\"},{\"start\":\"84600\",\"end\":\"84601\"},{\"start\":\"84608\",\"end\":\"84609\"},{\"start\":\"84610\",\"end\":\"84611\"},{\"start\":\"84621\",\"end\":\"84622\"},{\"start\":\"84623\",\"end\":\"84624\"},{\"start\":\"84822\",\"end\":\"84823\"},{\"start\":\"84824\",\"end\":\"84825\"},{\"start\":\"84832\",\"end\":\"84833\"},{\"start\":\"84834\",\"end\":\"84835\"},{\"start\":\"85136\",\"end\":\"85137\"},{\"start\":\"85147\",\"end\":\"85148\"},{\"start\":\"85156\",\"end\":\"85157\"},{\"start\":\"85475\",\"end\":\"85476\"},{\"start\":\"85483\",\"end\":\"85484\"},{\"start\":\"85492\",\"end\":\"85493\"},{\"start\":\"85772\",\"end\":\"85773\"},{\"start\":\"85782\",\"end\":\"85783\"},{\"start\":\"85793\",\"end\":\"85794\"},{\"start\":\"86062\",\"end\":\"86063\"},{\"start\":\"86071\",\"end\":\"86072\"},{\"start\":\"86080\",\"end\":\"86081\"},{\"start\":\"86094\",\"end\":\"86095\"},{\"start\":\"86105\",\"end\":\"86106\"},{\"start\":\"86111\",\"end\":\"86112\"},{\"start\":\"86125\",\"end\":\"86126\"},{\"start\":\"86492\",\"end\":\"86493\"},{\"start\":\"86701\",\"end\":\"86702\"},{\"start\":\"86711\",\"end\":\"86712\"},{\"start\":\"86722\",\"end\":\"86723\"},{\"start\":\"86724\",\"end\":\"86725\"},{\"start\":\"87176\",\"end\":\"87177\"},{\"start\":\"87186\",\"end\":\"87187\"},{\"start\":\"87429\",\"end\":\"87430\"},{\"start\":\"87740\",\"end\":\"87741\"},{\"start\":\"88077\",\"end\":\"88078\"},{\"start\":\"88083\",\"end\":\"88084\"},{\"start\":\"88085\",\"end\":\"88086\"},{\"start\":\"88096\",\"end\":\"88097\"},{\"start\":\"88105\",\"end\":\"88106\"},{\"start\":\"88427\",\"end\":\"88428\"},{\"start\":\"88436\",\"end\":\"88437\"},{\"start\":\"88445\",\"end\":\"88446\"},{\"start\":\"88458\",\"end\":\"88459\"},{\"start\":\"88826\",\"end\":\"88827\"},{\"start\":\"88835\",\"end\":\"88836\"},{\"start\":\"88846\",\"end\":\"88847\"},{\"start\":\"88853\",\"end\":\"88854\"},{\"start\":\"88862\",\"end\":\"88863\"},{\"start\":\"88876\",\"end\":\"88877\"},{\"start\":\"89165\",\"end\":\"89166\"},{\"start\":\"89174\",\"end\":\"89175\"},{\"start\":\"89183\",\"end\":\"89184\"},{\"start\":\"89190\",\"end\":\"89191\"},{\"start\":\"89198\",\"end\":\"89199\"},{\"start\":\"89546\",\"end\":\"89547\"},{\"start\":\"89559\",\"end\":\"89560\"},{\"start\":\"89571\",\"end\":\"89572\"},{\"start\":\"89580\",\"end\":\"89581\"},{\"start\":\"89589\",\"end\":\"89590\"},{\"start\":\"89597\",\"end\":\"89598\"},{\"start\":\"89599\",\"end\":\"89600\"},{\"start\":\"89611\",\"end\":\"89612\"},{\"start\":\"89622\",\"end\":\"89623\"},{\"start\":\"89624\",\"end\":\"89625\"},{\"start\":\"90035\",\"end\":\"90036\"},{\"start\":\"90046\",\"end\":\"90047\"},{\"start\":\"90055\",\"end\":\"90056\"},{\"start\":\"90066\",\"end\":\"90067\"},{\"start\":\"90083\",\"end\":\"90084\"},{\"start\":\"90093\",\"end\":\"90094\"},{\"start\":\"90102\",\"end\":\"90103\"},{\"start\":\"90539\",\"end\":\"90540\"},{\"start\":\"90549\",\"end\":\"90550\"},{\"start\":\"90559\",\"end\":\"90560\"},{\"start\":\"90568\",\"end\":\"90569\"},{\"start\":\"90948\",\"end\":\"90949\"},{\"start\":\"90961\",\"end\":\"90962\"},{\"start\":\"90970\",\"end\":\"90971\"},{\"start\":\"90978\",\"end\":\"90979\"},{\"start\":\"90980\",\"end\":\"90981\"},{\"start\":\"90992\",\"end\":\"90993\"},{\"start\":\"91003\",\"end\":\"91004\"},{\"start\":\"91005\",\"end\":\"91006\"},{\"start\":\"91321\",\"end\":\"91322\"},{\"start\":\"91334\",\"end\":\"91335\"},{\"start\":\"91336\",\"end\":\"91337\"},{\"start\":\"91346\",\"end\":\"91347\"},{\"start\":\"91348\",\"end\":\"91349\"},{\"start\":\"91358\",\"end\":\"91359\"},{\"start\":\"91360\",\"end\":\"91361\"},{\"start\":\"91368\",\"end\":\"91369\"},{\"start\":\"91370\",\"end\":\"91371\"},{\"start\":\"91381\",\"end\":\"91382\"},{\"start\":\"91383\",\"end\":\"91384\"},{\"start\":\"91705\",\"end\":\"91706\"},{\"start\":\"91715\",\"end\":\"91716\"},{\"start\":\"91724\",\"end\":\"91725\"},{\"start\":\"91732\",\"end\":\"91733\"},{\"start\":\"92060\",\"end\":\"92061\"},{\"start\":\"92071\",\"end\":\"92072\"},{\"start\":\"92082\",\"end\":\"92083\"},{\"start\":\"92090\",\"end\":\"92091\"},{\"start\":\"92482\",\"end\":\"92483\"},{\"start\":\"92492\",\"end\":\"92493\"},{\"start\":\"92501\",\"end\":\"92502\"},{\"start\":\"92517\",\"end\":\"92518\"},{\"start\":\"92527\",\"end\":\"92528\"},{\"start\":\"92995\",\"end\":\"92996\"},{\"start\":\"93001\",\"end\":\"93002\"},{\"start\":\"93008\",\"end\":\"93009\"},{\"start\":\"93025\",\"end\":\"93026\"},{\"start\":\"93044\",\"end\":\"93045\"},{\"start\":\"93053\",\"end\":\"93054\"},{\"start\":\"93059\",\"end\":\"93060\"},{\"start\":\"93505\",\"end\":\"93506\"},{\"start\":\"93512\",\"end\":\"93513\"},{\"start\":\"93531\",\"end\":\"93532\"},{\"start\":\"93543\",\"end\":\"93544\"},{\"start\":\"93553\",\"end\":\"93554\"},{\"start\":\"93564\",\"end\":\"93565\"},{\"start\":\"93566\",\"end\":\"93567\"},{\"start\":\"93578\",\"end\":\"93579\"},{\"start\":\"93924\",\"end\":\"93925\"},{\"start\":\"93933\",\"end\":\"93937\"},{\"start\":\"93947\",\"end\":\"93948\"},{\"start\":\"93957\",\"end\":\"93958\"},{\"start\":\"94211\",\"end\":\"94212\"},{\"start\":\"94221\",\"end\":\"94222\"},{\"start\":\"94478\",\"end\":\"94479\"},{\"start\":\"94487\",\"end\":\"94488\"},{\"start\":\"94891\",\"end\":\"94892\"},{\"start\":\"94902\",\"end\":\"94903\"},{\"start\":\"94904\",\"end\":\"94905\"},{\"start\":\"94913\",\"end\":\"94914\"},{\"start\":\"94915\",\"end\":\"94916\"},{\"start\":\"94928\",\"end\":\"94929\"},{\"start\":\"94930\",\"end\":\"94931\"},{\"start\":\"94940\",\"end\":\"94941\"},{\"start\":\"94953\",\"end\":\"94954\"},{\"start\":\"94955\",\"end\":\"94956\"},{\"start\":\"95356\",\"end\":\"95357\"},{\"start\":\"95362\",\"end\":\"95363\"},{\"start\":\"95723\",\"end\":\"95724\"},{\"start\":\"95732\",\"end\":\"95733\"},{\"start\":\"95741\",\"end\":\"95742\"},{\"start\":\"95755\",\"end\":\"95756\"},{\"start\":\"95765\",\"end\":\"95766\"},{\"start\":\"95777\",\"end\":\"95778\"},{\"start\":\"96110\",\"end\":\"96111\"},{\"start\":\"96123\",\"end\":\"96124\"},{\"start\":\"96136\",\"end\":\"96137\"},{\"start\":\"96148\",\"end\":\"96149\"},{\"start\":\"96158\",\"end\":\"96159\"},{\"start\":\"96169\",\"end\":\"96170\"},{\"start\":\"96179\",\"end\":\"96180\"},{\"start\":\"96190\",\"end\":\"96191\"},{\"start\":\"96206\",\"end\":\"96207\"},{\"start\":\"96215\",\"end\":\"96216\"},{\"start\":\"96684\",\"end\":\"96685\"},{\"start\":\"96692\",\"end\":\"96693\"},{\"start\":\"96698\",\"end\":\"96699\"},{\"start\":\"96708\",\"end\":\"96709\"},{\"start\":\"96958\",\"end\":\"96959\"},{\"start\":\"96970\",\"end\":\"96971\"},{\"start\":\"96978\",\"end\":\"96979\"},{\"start\":\"97137\",\"end\":\"97138\"},{\"start\":\"97150\",\"end\":\"97151\"},{\"start\":\"97161\",\"end\":\"97162\"},{\"start\":\"97163\",\"end\":\"97164\"},{\"start\":\"97175\",\"end\":\"97176\"},{\"start\":\"97710\",\"end\":\"97711\"},{\"start\":\"97721\",\"end\":\"97722\"},{\"start\":\"97730\",\"end\":\"97731\"},{\"start\":\"97741\",\"end\":\"97742\"},{\"start\":\"97753\",\"end\":\"97754\"},{\"start\":\"97765\",\"end\":\"97766\"},{\"start\":\"98060\",\"end\":\"98061\"},{\"start\":\"98069\",\"end\":\"98070\"},{\"start\":\"98079\",\"end\":\"98080\"},{\"start\":\"98089\",\"end\":\"98090\"},{\"start\":\"98543\",\"end\":\"98544\"},{\"start\":\"98554\",\"end\":\"98555\"},{\"start\":\"98562\",\"end\":\"98563\"},{\"start\":\"98571\",\"end\":\"98572\"},{\"start\":\"98580\",\"end\":\"98581\"},{\"start\":\"98582\",\"end\":\"98583\"},{\"start\":\"99073\",\"end\":\"99074\"},{\"start\":\"99075\",\"end\":\"99076\"},{\"start\":\"99088\",\"end\":\"99089\"},{\"start\":\"99100\",\"end\":\"99101\"},{\"start\":\"99111\",\"end\":\"99112\"},{\"start\":\"99120\",\"end\":\"99121\"},{\"start\":\"99129\",\"end\":\"99130\"},{\"start\":\"99131\",\"end\":\"99132\"},{\"start\":\"99534\",\"end\":\"99535\"},{\"start\":\"99545\",\"end\":\"99546\"},{\"start\":\"99554\",\"end\":\"99555\"},{\"start\":\"99563\",\"end\":\"99564\"},{\"start\":\"99565\",\"end\":\"99566\"},{\"start\":\"99573\",\"end\":\"99574\"},{\"start\":\"99575\",\"end\":\"99576\"},{\"start\":\"99584\",\"end\":\"99585\"},{\"start\":\"99936\",\"end\":\"99937\"},{\"start\":\"99938\",\"end\":\"99939\"},{\"start\":\"99947\",\"end\":\"99948\"},{\"start\":\"99949\",\"end\":\"99950\"},{\"start\":\"99957\",\"end\":\"99958\"},{\"start\":\"99959\",\"end\":\"99960\"},{\"start\":\"100527\",\"end\":\"100528\"},{\"start\":\"100535\",\"end\":\"100536\"},{\"start\":\"100548\",\"end\":\"100549\"},{\"start\":\"100842\",\"end\":\"100843\"},{\"start\":\"100850\",\"end\":\"100851\"},{\"start\":\"100857\",\"end\":\"100858\"},{\"start\":\"100866\",\"end\":\"100867\"},{\"start\":\"100874\",\"end\":\"100878\"},{\"start\":\"101178\",\"end\":\"101179\"},{\"start\":\"101188\",\"end\":\"101189\"},{\"start\":\"101476\",\"end\":\"101477\"},{\"start\":\"101487\",\"end\":\"101488\"},{\"start\":\"101489\",\"end\":\"101490\"},{\"start\":\"101498\",\"end\":\"101499\"},{\"start\":\"101500\",\"end\":\"101501\"},{\"start\":\"101760\",\"end\":\"101761\"},{\"start\":\"101762\",\"end\":\"101765\"},{\"start\":\"101774\",\"end\":\"101775\"},{\"start\":\"102037\",\"end\":\"102038\"},{\"start\":\"102039\",\"end\":\"102040\"},{\"start\":\"102048\",\"end\":\"102049\"},{\"start\":\"102060\",\"end\":\"102061\"},{\"start\":\"102071\",\"end\":\"102072\"},{\"start\":\"102073\",\"end\":\"102074\"},{\"start\":\"102085\",\"end\":\"102086\"},{\"start\":\"102087\",\"end\":\"102088\"},{\"start\":\"102472\",\"end\":\"102473\"},{\"start\":\"102474\",\"end\":\"102475\"},{\"start\":\"102482\",\"end\":\"102483\"},{\"start\":\"102484\",\"end\":\"102485\"},{\"start\":\"102771\",\"end\":\"102772\"},{\"start\":\"102777\",\"end\":\"102778\"},{\"start\":\"102786\",\"end\":\"102787\"},{\"start\":\"103325\",\"end\":\"103326\"},{\"start\":\"103336\",\"end\":\"103337\"},{\"start\":\"103346\",\"end\":\"103347\"},{\"start\":\"103669\",\"end\":\"103670\"},{\"start\":\"103680\",\"end\":\"103681\"},{\"start\":\"103691\",\"end\":\"103692\"},{\"start\":\"104048\",\"end\":\"104049\"},{\"start\":\"104063\",\"end\":\"104064\"},{\"start\":\"104074\",\"end\":\"104075\"},{\"start\":\"104076\",\"end\":\"104077\"},{\"start\":\"104502\",\"end\":\"104503\"},{\"start\":\"104508\",\"end\":\"104509\"},{\"start\":\"104515\",\"end\":\"104516\"},{\"start\":\"104932\",\"end\":\"104933\"},{\"start\":\"104940\",\"end\":\"104941\"},{\"start\":\"104942\",\"end\":\"104943\"},{\"start\":\"104950\",\"end\":\"104951\"},{\"start\":\"104958\",\"end\":\"104959\"},{\"start\":\"105188\",\"end\":\"105189\"},{\"start\":\"105198\",\"end\":\"105199\"},{\"start\":\"105206\",\"end\":\"105207\"},{\"start\":\"105214\",\"end\":\"105215\"},{\"start\":\"105230\",\"end\":\"105231\"},{\"start\":\"105238\",\"end\":\"105239\"},{\"start\":\"105251\",\"end\":\"105252\"},{\"start\":\"105261\",\"end\":\"105262\"},{\"start\":\"105560\",\"end\":\"105561\"},{\"start\":\"105566\",\"end\":\"105567\"},{\"start\":\"105573\",\"end\":\"105574\"},{\"start\":\"105575\",\"end\":\"105576\"},{\"start\":\"105586\",\"end\":\"105587\"},{\"start\":\"105595\",\"end\":\"105596\"},{\"start\":\"105606\",\"end\":\"105607\"},{\"start\":\"106096\",\"end\":\"106097\"},{\"start\":\"106108\",\"end\":\"106109\"},{\"start\":\"106115\",\"end\":\"106116\"},{\"start\":\"106126\",\"end\":\"106127\"},{\"start\":\"106136\",\"end\":\"106137\"},{\"start\":\"106149\",\"end\":\"106150\"},{\"start\":\"106156\",\"end\":\"106157\"},{\"start\":\"106158\",\"end\":\"106159\"},{\"start\":\"106168\",\"end\":\"106169\"},{\"start\":\"106177\",\"end\":\"106178\"},{\"start\":\"106179\",\"end\":\"106180\"},{\"start\":\"106190\",\"end\":\"106191\"},{\"start\":\"106192\",\"end\":\"106193\"},{\"start\":\"106727\",\"end\":\"106728\"},{\"start\":\"106734\",\"end\":\"106735\"},{\"start\":\"106743\",\"end\":\"106744\"},{\"start\":\"107058\",\"end\":\"107059\"},{\"start\":\"107068\",\"end\":\"107069\"},{\"start\":\"107074\",\"end\":\"107075\"},{\"start\":\"107427\",\"end\":\"107428\"},{\"start\":\"107437\",\"end\":\"107438\"},{\"start\":\"107443\",\"end\":\"107444\"},{\"start\":\"107933\",\"end\":\"107934\"},{\"start\":\"107943\",\"end\":\"107944\"},{\"start\":\"107949\",\"end\":\"107950\"},{\"start\":\"108349\",\"end\":\"108350\"},{\"start\":\"108357\",\"end\":\"108358\"},{\"start\":\"108365\",\"end\":\"108366\"},{\"start\":\"108373\",\"end\":\"108374\"},{\"start\":\"108379\",\"end\":\"108380\"},{\"start\":\"108791\",\"end\":\"108792\"},{\"start\":\"108793\",\"end\":\"108794\"},{\"start\":\"108805\",\"end\":\"108806\"},{\"start\":\"109181\",\"end\":\"109182\"},{\"start\":\"109183\",\"end\":\"109184\"},{\"start\":\"109195\",\"end\":\"109196\"},{\"start\":\"109405\",\"end\":\"109406\"},{\"start\":\"109411\",\"end\":\"109412\"},{\"start\":\"109418\",\"end\":\"109419\"},{\"start\":\"109420\",\"end\":\"109421\"},{\"start\":\"109430\",\"end\":\"109431\"},{\"start\":\"109439\",\"end\":\"109440\"},{\"start\":\"109449\",\"end\":\"109450\"},{\"start\":\"109462\",\"end\":\"109463\"},{\"start\":\"109473\",\"end\":\"109474\"},{\"start\":\"109482\",\"end\":\"109483\"},{\"start\":\"109493\",\"end\":\"109494\"},{\"start\":\"109495\",\"end\":\"109496\"},{\"start\":\"109964\",\"end\":\"109965\"},{\"start\":\"109973\",\"end\":\"109974\"},{\"start\":\"109975\",\"end\":\"109976\"},{\"start\":\"109987\",\"end\":\"109988\"},{\"start\":\"109994\",\"end\":\"109995\"},{\"start\":\"110003\",\"end\":\"110004\"},{\"start\":\"110017\",\"end\":\"110018\"},{\"start\":\"110418\",\"end\":\"110419\"},{\"start\":\"110616\",\"end\":\"110617\"},{\"start\":\"110625\",\"end\":\"110626\"},{\"start\":\"110632\",\"end\":\"110633\"},{\"start\":\"110644\",\"end\":\"110645\"},{\"start\":\"110653\",\"end\":\"110654\"},{\"start\":\"110664\",\"end\":\"110665\"},{\"start\":\"110666\",\"end\":\"110667\"},{\"start\":\"110672\",\"end\":\"110673\"},{\"start\":\"111096\",\"end\":\"111097\"},{\"start\":\"111103\",\"end\":\"111104\"},{\"start\":\"111112\",\"end\":\"111113\"},{\"start\":\"111489\",\"end\":\"111490\"},{\"start\":\"111497\",\"end\":\"111498\"},{\"start\":\"111506\",\"end\":\"111507\"},{\"start\":\"111515\",\"end\":\"111516\"},{\"start\":\"111938\",\"end\":\"111939\"},{\"start\":\"111946\",\"end\":\"111947\"},{\"start\":\"111955\",\"end\":\"111956\"},{\"start\":\"111964\",\"end\":\"111965\"},{\"start\":\"111971\",\"end\":\"111972\"},{\"start\":\"112199\",\"end\":\"112200\"},{\"start\":\"112208\",\"end\":\"112209\"},{\"start\":\"112217\",\"end\":\"112218\"},{\"start\":\"112227\",\"end\":\"112228\"},{\"start\":\"112616\",\"end\":\"112617\"},{\"start\":\"112626\",\"end\":\"112627\"},{\"start\":\"112635\",\"end\":\"112636\"},{\"start\":\"113273\",\"end\":\"113274\"},{\"start\":\"113282\",\"end\":\"113283\"},{\"start\":\"113290\",\"end\":\"113291\"},{\"start\":\"113299\",\"end\":\"113300\"},{\"start\":\"113604\",\"end\":\"113605\"},{\"start\":\"113610\",\"end\":\"113611\"},{\"start\":\"113612\",\"end\":\"113613\"},{\"start\":\"113622\",\"end\":\"113623\"},{\"start\":\"113631\",\"end\":\"113632\"},{\"start\":\"113641\",\"end\":\"113642\"},{\"start\":\"113651\",\"end\":\"113652\"},{\"start\":\"113663\",\"end\":\"113664\"},{\"start\":\"113665\",\"end\":\"113666\"}]", "bib_author_last_name": "[{\"start\":\"73706\",\"end\":\"73711\"},{\"start\":\"73717\",\"end\":\"73722\"},{\"start\":\"73916\",\"end\":\"73920\"},{\"start\":\"74113\",\"end\":\"74118\"},{\"start\":\"74124\",\"end\":\"74129\"},{\"start\":\"74135\",\"end\":\"74141\"},{\"start\":\"74147\",\"end\":\"74155\"},{\"start\":\"74161\",\"end\":\"74172\"},{\"start\":\"74176\",\"end\":\"74180\"},{\"start\":\"74484\",\"end\":\"74488\"},{\"start\":\"74494\",\"end\":\"74500\"},{\"start\":\"74506\",\"end\":\"74513\"},{\"start\":\"74519\",\"end\":\"74521\"},{\"start\":\"74806\",\"end\":\"74814\"},{\"start\":\"74818\",\"end\":\"74822\"},{\"start\":\"75019\",\"end\":\"75021\"},{\"start\":\"75025\",\"end\":\"75028\"},{\"start\":\"75032\",\"end\":\"75035\"},{\"start\":\"75039\",\"end\":\"75041\"},{\"start\":\"75045\",\"end\":\"75047\"},{\"start\":\"75284\",\"end\":\"75287\"},{\"start\":\"75291\",\"end\":\"75294\"},{\"start\":\"75298\",\"end\":\"75303\"},{\"start\":\"75617\",\"end\":\"75622\"},{\"start\":\"75626\",\"end\":\"75634\"},{\"start\":\"75638\",\"end\":\"75642\"},{\"start\":\"75646\",\"end\":\"75652\"},{\"start\":\"75656\",\"end\":\"75662\"},{\"start\":\"75668\",\"end\":\"75674\"},{\"start\":\"75678\",\"end\":\"75684\"},{\"start\":\"75688\",\"end\":\"75694\"},{\"start\":\"76088\",\"end\":\"76091\"},{\"start\":\"76095\",\"end\":\"76099\"},{\"start\":\"76103\",\"end\":\"76106\"},{\"start\":\"76110\",\"end\":\"76115\"},{\"start\":\"76119\",\"end\":\"76123\"},{\"start\":\"76436\",\"end\":\"76443\"},{\"start\":\"76447\",\"end\":\"76453\"},{\"start\":\"76457\",\"end\":\"76462\"},{\"start\":\"76719\",\"end\":\"76722\"},{\"start\":\"76726\",\"end\":\"76729\"},{\"start\":\"76733\",\"end\":\"76738\"},{\"start\":\"76742\",\"end\":\"76746\"},{\"start\":\"77146\",\"end\":\"77151\"},{\"start\":\"77155\",\"end\":\"77163\"},{\"start\":\"77167\",\"end\":\"77177\"},{\"start\":\"77183\",\"end\":\"77193\"},{\"start\":\"77197\",\"end\":\"77199\"},{\"start\":\"77203\",\"end\":\"77213\"},{\"start\":\"77745\",\"end\":\"77751\"},{\"start\":\"77755\",\"end\":\"77760\"},{\"start\":\"77764\",\"end\":\"77768\"},{\"start\":\"77772\",\"end\":\"77778\"},{\"start\":\"77782\",\"end\":\"77789\"},{\"start\":\"77793\",\"end\":\"77799\"},{\"start\":\"77803\",\"end\":\"77811\"},{\"start\":\"77815\",\"end\":\"77819\"},{\"start\":\"77823\",\"end\":\"77827\"},{\"start\":\"77833\",\"end\":\"77837\"},{\"start\":\"78295\",\"end\":\"78299\"},{\"start\":\"78303\",\"end\":\"78307\"},{\"start\":\"78311\",\"end\":\"78313\"},{\"start\":\"78317\",\"end\":\"78321\"},{\"start\":\"78668\",\"end\":\"78674\"},{\"start\":\"78678\",\"end\":\"78684\"},{\"start\":\"78688\",\"end\":\"78691\"},{\"start\":\"79256\",\"end\":\"79261\"},{\"start\":\"79265\",\"end\":\"79270\"},{\"start\":\"79274\",\"end\":\"79277\"},{\"start\":\"79281\",\"end\":\"79287\"},{\"start\":\"79766\",\"end\":\"79769\"},{\"start\":\"79773\",\"end\":\"79775\"},{\"start\":\"79779\",\"end\":\"79781\"},{\"start\":\"79785\",\"end\":\"79790\"},{\"start\":\"79794\",\"end\":\"79798\"},{\"start\":\"79802\",\"end\":\"79805\"},{\"start\":\"79809\",\"end\":\"79813\"},{\"start\":\"79817\",\"end\":\"79820\"},{\"start\":\"80233\",\"end\":\"80240\"},{\"start\":\"80244\",\"end\":\"80247\"},{\"start\":\"80251\",\"end\":\"80264\"},{\"start\":\"80268\",\"end\":\"80283\"},{\"start\":\"80289\",\"end\":\"80297\"},{\"start\":\"80301\",\"end\":\"80303\"},{\"start\":\"80309\",\"end\":\"80317\"},{\"start\":\"80321\",\"end\":\"80329\"},{\"start\":\"80716\",\"end\":\"80724\"},{\"start\":\"80958\",\"end\":\"80964\"},{\"start\":\"80968\",\"end\":\"80981\"},{\"start\":\"81189\",\"end\":\"81194\"},{\"start\":\"81198\",\"end\":\"81205\"},{\"start\":\"81211\",\"end\":\"81218\"},{\"start\":\"81448\",\"end\":\"81459\"},{\"start\":\"81463\",\"end\":\"81469\"},{\"start\":\"81473\",\"end\":\"81487\"},{\"start\":\"81491\",\"end\":\"81498\"},{\"start\":\"81987\",\"end\":\"81990\"},{\"start\":\"81997\",\"end\":\"81999\"},{\"start\":\"82006\",\"end\":\"82009\"},{\"start\":\"82013\",\"end\":\"82024\"},{\"start\":\"82428\",\"end\":\"82432\"},{\"start\":\"82436\",\"end\":\"82445\"},{\"start\":\"82449\",\"end\":\"82457\"},{\"start\":\"82764\",\"end\":\"82771\"},{\"start\":\"82990\",\"end\":\"82995\"},{\"start\":\"83228\",\"end\":\"83241\"},{\"start\":\"83247\",\"end\":\"83252\"},{\"start\":\"83754\",\"end\":\"83766\"},{\"start\":\"83770\",\"end\":\"83777\"},{\"start\":\"83783\",\"end\":\"83788\"},{\"start\":\"84124\",\"end\":\"84127\"},{\"start\":\"84133\",\"end\":\"84140\"},{\"start\":\"84602\",\"end\":\"84606\"},{\"start\":\"84612\",\"end\":\"84619\"},{\"start\":\"84625\",\"end\":\"84632\"},{\"start\":\"84826\",\"end\":\"84830\"},{\"start\":\"84836\",\"end\":\"84848\"},{\"start\":\"85138\",\"end\":\"85145\"},{\"start\":\"85149\",\"end\":\"85154\"},{\"start\":\"85158\",\"end\":\"85165\"},{\"start\":\"85477\",\"end\":\"85481\"},{\"start\":\"85485\",\"end\":\"85490\"},{\"start\":\"85494\",\"end\":\"85499\"},{\"start\":\"85774\",\"end\":\"85780\"},{\"start\":\"85784\",\"end\":\"85791\"},{\"start\":\"85795\",\"end\":\"85802\"},{\"start\":\"86064\",\"end\":\"86069\"},{\"start\":\"86073\",\"end\":\"86078\"},{\"start\":\"86082\",\"end\":\"86092\"},{\"start\":\"86096\",\"end\":\"86103\"},{\"start\":\"86107\",\"end\":\"86109\"},{\"start\":\"86113\",\"end\":\"86123\"},{\"start\":\"86127\",\"end\":\"86133\"},{\"start\":\"86494\",\"end\":\"86499\"},{\"start\":\"86703\",\"end\":\"86709\"},{\"start\":\"86713\",\"end\":\"86720\"},{\"start\":\"86726\",\"end\":\"86732\"},{\"start\":\"87178\",\"end\":\"87184\"},{\"start\":\"87188\",\"end\":\"87193\"},{\"start\":\"87431\",\"end\":\"87440\"},{\"start\":\"87742\",\"end\":\"87749\"},{\"start\":\"88079\",\"end\":\"88081\"},{\"start\":\"88087\",\"end\":\"88094\"},{\"start\":\"88098\",\"end\":\"88103\"},{\"start\":\"88107\",\"end\":\"88112\"},{\"start\":\"88429\",\"end\":\"88434\"},{\"start\":\"88438\",\"end\":\"88443\"},{\"start\":\"88447\",\"end\":\"88456\"},{\"start\":\"88460\",\"end\":\"88466\"},{\"start\":\"88828\",\"end\":\"88833\"},{\"start\":\"88837\",\"end\":\"88844\"},{\"start\":\"88848\",\"end\":\"88851\"},{\"start\":\"88855\",\"end\":\"88860\"},{\"start\":\"88864\",\"end\":\"88874\"},{\"start\":\"88878\",\"end\":\"88884\"},{\"start\":\"89167\",\"end\":\"89172\"},{\"start\":\"89176\",\"end\":\"89181\"},{\"start\":\"89185\",\"end\":\"89188\"},{\"start\":\"89192\",\"end\":\"89196\"},{\"start\":\"89200\",\"end\":\"89206\"},{\"start\":\"89548\",\"end\":\"89557\"},{\"start\":\"89561\",\"end\":\"89569\"},{\"start\":\"89573\",\"end\":\"89578\"},{\"start\":\"89582\",\"end\":\"89587\"},{\"start\":\"89591\",\"end\":\"89595\"},{\"start\":\"89601\",\"end\":\"89609\"},{\"start\":\"89613\",\"end\":\"89620\"},{\"start\":\"89626\",\"end\":\"89632\"},{\"start\":\"90037\",\"end\":\"90044\"},{\"start\":\"90048\",\"end\":\"90053\"},{\"start\":\"90057\",\"end\":\"90064\"},{\"start\":\"90068\",\"end\":\"90081\"},{\"start\":\"90085\",\"end\":\"90091\"},{\"start\":\"90095\",\"end\":\"90100\"},{\"start\":\"90104\",\"end\":\"90113\"},{\"start\":\"90541\",\"end\":\"90547\"},{\"start\":\"90551\",\"end\":\"90557\"},{\"start\":\"90561\",\"end\":\"90566\"},{\"start\":\"90570\",\"end\":\"90574\"},{\"start\":\"90950\",\"end\":\"90959\"},{\"start\":\"90963\",\"end\":\"90968\"},{\"start\":\"90972\",\"end\":\"90976\"},{\"start\":\"90982\",\"end\":\"90990\"},{\"start\":\"90994\",\"end\":\"91001\"},{\"start\":\"91007\",\"end\":\"91013\"},{\"start\":\"91323\",\"end\":\"91332\"},{\"start\":\"91338\",\"end\":\"91344\"},{\"start\":\"91350\",\"end\":\"91356\"},{\"start\":\"91362\",\"end\":\"91366\"},{\"start\":\"91372\",\"end\":\"91379\"},{\"start\":\"91385\",\"end\":\"91393\"},{\"start\":\"91707\",\"end\":\"91713\"},{\"start\":\"91717\",\"end\":\"91722\"},{\"start\":\"91726\",\"end\":\"91730\"},{\"start\":\"91734\",\"end\":\"91743\"},{\"start\":\"92062\",\"end\":\"92069\"},{\"start\":\"92073\",\"end\":\"92080\"},{\"start\":\"92084\",\"end\":\"92088\"},{\"start\":\"92092\",\"end\":\"92101\"},{\"start\":\"92484\",\"end\":\"92490\"},{\"start\":\"92494\",\"end\":\"92499\"},{\"start\":\"92503\",\"end\":\"92515\"},{\"start\":\"92519\",\"end\":\"92525\"},{\"start\":\"92529\",\"end\":\"92535\"},{\"start\":\"92997\",\"end\":\"92999\"},{\"start\":\"93003\",\"end\":\"93006\"},{\"start\":\"93010\",\"end\":\"93023\"},{\"start\":\"93027\",\"end\":\"93042\"},{\"start\":\"93046\",\"end\":\"93051\"},{\"start\":\"93055\",\"end\":\"93057\"},{\"start\":\"93061\",\"end\":\"93064\"},{\"start\":\"93507\",\"end\":\"93510\"},{\"start\":\"93514\",\"end\":\"93529\"},{\"start\":\"93533\",\"end\":\"93541\"},{\"start\":\"93545\",\"end\":\"93551\"},{\"start\":\"93555\",\"end\":\"93562\"},{\"start\":\"93568\",\"end\":\"93576\"},{\"start\":\"93580\",\"end\":\"93593\"},{\"start\":\"93926\",\"end\":\"93931\"},{\"start\":\"93938\",\"end\":\"93945\"},{\"start\":\"93949\",\"end\":\"93955\"},{\"start\":\"93959\",\"end\":\"93961\"},{\"start\":\"94213\",\"end\":\"94219\"},{\"start\":\"94223\",\"end\":\"94226\"},{\"start\":\"94480\",\"end\":\"94485\"},{\"start\":\"94489\",\"end\":\"94502\"},{\"start\":\"94893\",\"end\":\"94900\"},{\"start\":\"94906\",\"end\":\"94911\"},{\"start\":\"94917\",\"end\":\"94926\"},{\"start\":\"94932\",\"end\":\"94938\"},{\"start\":\"94942\",\"end\":\"94951\"},{\"start\":\"94957\",\"end\":\"94959\"},{\"start\":\"95358\",\"end\":\"95360\"},{\"start\":\"95364\",\"end\":\"95371\"},{\"start\":\"95725\",\"end\":\"95730\"},{\"start\":\"95734\",\"end\":\"95739\"},{\"start\":\"95743\",\"end\":\"95753\"},{\"start\":\"95757\",\"end\":\"95763\"},{\"start\":\"95767\",\"end\":\"95775\"},{\"start\":\"95779\",\"end\":\"95784\"},{\"start\":\"96112\",\"end\":\"96121\"},{\"start\":\"96125\",\"end\":\"96134\"},{\"start\":\"96138\",\"end\":\"96146\"},{\"start\":\"96150\",\"end\":\"96156\"},{\"start\":\"96160\",\"end\":\"96167\"},{\"start\":\"96171\",\"end\":\"96177\"},{\"start\":\"96181\",\"end\":\"96188\"},{\"start\":\"96192\",\"end\":\"96204\"},{\"start\":\"96208\",\"end\":\"96213\"},{\"start\":\"96217\",\"end\":\"96224\"},{\"start\":\"96686\",\"end\":\"96690\"},{\"start\":\"96694\",\"end\":\"96696\"},{\"start\":\"96700\",\"end\":\"96706\"},{\"start\":\"96710\",\"end\":\"96713\"},{\"start\":\"96960\",\"end\":\"96968\"},{\"start\":\"96972\",\"end\":\"96976\"},{\"start\":\"96980\",\"end\":\"96985\"},{\"start\":\"97139\",\"end\":\"97148\"},{\"start\":\"97152\",\"end\":\"97159\"},{\"start\":\"97165\",\"end\":\"97173\"},{\"start\":\"97177\",\"end\":\"97184\"},{\"start\":\"97712\",\"end\":\"97719\"},{\"start\":\"97723\",\"end\":\"97728\"},{\"start\":\"97732\",\"end\":\"97739\"},{\"start\":\"97743\",\"end\":\"97751\"},{\"start\":\"97755\",\"end\":\"97763\"},{\"start\":\"97767\",\"end\":\"97772\"},{\"start\":\"98062\",\"end\":\"98067\"},{\"start\":\"98071\",\"end\":\"98077\"},{\"start\":\"98081\",\"end\":\"98087\"},{\"start\":\"98091\",\"end\":\"98098\"},{\"start\":\"98545\",\"end\":\"98552\"},{\"start\":\"98556\",\"end\":\"98560\"},{\"start\":\"98564\",\"end\":\"98569\"},{\"start\":\"98573\",\"end\":\"98578\"},{\"start\":\"98584\",\"end\":\"98595\"},{\"start\":\"99077\",\"end\":\"99086\"},{\"start\":\"99090\",\"end\":\"99098\"},{\"start\":\"99102\",\"end\":\"99109\"},{\"start\":\"99113\",\"end\":\"99118\"},{\"start\":\"99122\",\"end\":\"99127\"},{\"start\":\"99133\",\"end\":\"99138\"},{\"start\":\"99536\",\"end\":\"99543\"},{\"start\":\"99547\",\"end\":\"99552\"},{\"start\":\"99556\",\"end\":\"99561\"},{\"start\":\"99567\",\"end\":\"99571\"},{\"start\":\"99577\",\"end\":\"99582\"},{\"start\":\"99586\",\"end\":\"99592\"},{\"start\":\"99940\",\"end\":\"99945\"},{\"start\":\"99951\",\"end\":\"99955\"},{\"start\":\"99961\",\"end\":\"99966\"},{\"start\":\"100529\",\"end\":\"100533\"},{\"start\":\"100537\",\"end\":\"100546\"},{\"start\":\"100550\",\"end\":\"100558\"},{\"start\":\"100844\",\"end\":\"100848\"},{\"start\":\"100852\",\"end\":\"100855\"},{\"start\":\"100859\",\"end\":\"100864\"},{\"start\":\"100868\",\"end\":\"100872\"},{\"start\":\"100879\",\"end\":\"100882\"},{\"start\":\"101180\",\"end\":\"101186\"},{\"start\":\"101190\",\"end\":\"101195\"},{\"start\":\"101478\",\"end\":\"101485\"},{\"start\":\"101491\",\"end\":\"101496\"},{\"start\":\"101502\",\"end\":\"101515\"},{\"start\":\"101766\",\"end\":\"101772\"},{\"start\":\"101776\",\"end\":\"101782\"},{\"start\":\"102041\",\"end\":\"102046\"},{\"start\":\"102050\",\"end\":\"102058\"},{\"start\":\"102062\",\"end\":\"102069\"},{\"start\":\"102075\",\"end\":\"102083\"},{\"start\":\"102089\",\"end\":\"102092\"},{\"start\":\"102476\",\"end\":\"102480\"},{\"start\":\"102486\",\"end\":\"102490\"},{\"start\":\"102773\",\"end\":\"102775\"},{\"start\":\"102779\",\"end\":\"102784\"},{\"start\":\"102788\",\"end\":\"102791\"},{\"start\":\"103327\",\"end\":\"103334\"},{\"start\":\"103338\",\"end\":\"103344\"},{\"start\":\"103348\",\"end\":\"103350\"},{\"start\":\"103671\",\"end\":\"103678\"},{\"start\":\"103682\",\"end\":\"103689\"},{\"start\":\"103693\",\"end\":\"103697\"},{\"start\":\"104050\",\"end\":\"104061\"},{\"start\":\"104065\",\"end\":\"104072\"},{\"start\":\"104078\",\"end\":\"104092\"},{\"start\":\"104504\",\"end\":\"104506\"},{\"start\":\"104510\",\"end\":\"104513\"},{\"start\":\"104517\",\"end\":\"104520\"},{\"start\":\"104934\",\"end\":\"104938\"},{\"start\":\"104944\",\"end\":\"104948\"},{\"start\":\"104952\",\"end\":\"104956\"},{\"start\":\"104960\",\"end\":\"104962\"},{\"start\":\"105190\",\"end\":\"105196\"},{\"start\":\"105200\",\"end\":\"105204\"},{\"start\":\"105208\",\"end\":\"105212\"},{\"start\":\"105216\",\"end\":\"105228\"},{\"start\":\"105232\",\"end\":\"105236\"},{\"start\":\"105240\",\"end\":\"105249\"},{\"start\":\"105253\",\"end\":\"105259\"},{\"start\":\"105263\",\"end\":\"105266\"},{\"start\":\"105562\",\"end\":\"105564\"},{\"start\":\"105568\",\"end\":\"105571\"},{\"start\":\"105577\",\"end\":\"105584\"},{\"start\":\"105588\",\"end\":\"105593\"},{\"start\":\"105597\",\"end\":\"105604\"},{\"start\":\"105608\",\"end\":\"105611\"},{\"start\":\"106098\",\"end\":\"106106\"},{\"start\":\"106110\",\"end\":\"106113\"},{\"start\":\"106117\",\"end\":\"106124\"},{\"start\":\"106128\",\"end\":\"106134\"},{\"start\":\"106138\",\"end\":\"106147\"},{\"start\":\"106151\",\"end\":\"106154\"},{\"start\":\"106160\",\"end\":\"106166\"},{\"start\":\"106170\",\"end\":\"106175\"},{\"start\":\"106181\",\"end\":\"106188\"},{\"start\":\"106194\",\"end\":\"106199\"},{\"start\":\"106729\",\"end\":\"106732\"},{\"start\":\"106736\",\"end\":\"106741\"},{\"start\":\"106745\",\"end\":\"106747\"},{\"start\":\"107060\",\"end\":\"107066\"},{\"start\":\"107070\",\"end\":\"107072\"},{\"start\":\"107076\",\"end\":\"107079\"},{\"start\":\"107429\",\"end\":\"107435\"},{\"start\":\"107439\",\"end\":\"107441\"},{\"start\":\"107445\",\"end\":\"107448\"},{\"start\":\"107935\",\"end\":\"107941\"},{\"start\":\"107945\",\"end\":\"107947\"},{\"start\":\"107951\",\"end\":\"107954\"},{\"start\":\"108351\",\"end\":\"108355\"},{\"start\":\"108359\",\"end\":\"108363\"},{\"start\":\"108367\",\"end\":\"108371\"},{\"start\":\"108375\",\"end\":\"108377\"},{\"start\":\"108381\",\"end\":\"108385\"},{\"start\":\"108795\",\"end\":\"108803\"},{\"start\":\"108807\",\"end\":\"108811\"},{\"start\":\"109185\",\"end\":\"109193\"},{\"start\":\"109197\",\"end\":\"109201\"},{\"start\":\"109407\",\"end\":\"109409\"},{\"start\":\"109413\",\"end\":\"109416\"},{\"start\":\"109422\",\"end\":\"109428\"},{\"start\":\"109432\",\"end\":\"109437\"},{\"start\":\"109441\",\"end\":\"109447\"},{\"start\":\"109451\",\"end\":\"109460\"},{\"start\":\"109464\",\"end\":\"109471\"},{\"start\":\"109475\",\"end\":\"109480\"},{\"start\":\"109484\",\"end\":\"109491\"},{\"start\":\"109497\",\"end\":\"109499\"},{\"start\":\"109966\",\"end\":\"109971\"},{\"start\":\"109977\",\"end\":\"109985\"},{\"start\":\"109989\",\"end\":\"109992\"},{\"start\":\"109996\",\"end\":\"110001\"},{\"start\":\"110005\",\"end\":\"110015\"},{\"start\":\"110019\",\"end\":\"110025\"},{\"start\":\"110420\",\"end\":\"110425\"},{\"start\":\"110618\",\"end\":\"110623\"},{\"start\":\"110627\",\"end\":\"110630\"},{\"start\":\"110634\",\"end\":\"110642\"},{\"start\":\"110646\",\"end\":\"110651\"},{\"start\":\"110655\",\"end\":\"110662\"},{\"start\":\"110668\",\"end\":\"110670\"},{\"start\":\"110674\",\"end\":\"110680\"},{\"start\":\"111098\",\"end\":\"111101\"},{\"start\":\"111105\",\"end\":\"111110\"},{\"start\":\"111114\",\"end\":\"111120\"},{\"start\":\"111491\",\"end\":\"111495\"},{\"start\":\"111499\",\"end\":\"111504\"},{\"start\":\"111508\",\"end\":\"111513\"},{\"start\":\"111517\",\"end\":\"111523\"},{\"start\":\"111940\",\"end\":\"111944\"},{\"start\":\"111948\",\"end\":\"111953\"},{\"start\":\"111957\",\"end\":\"111962\"},{\"start\":\"111966\",\"end\":\"111969\"},{\"start\":\"111973\",\"end\":\"111979\"},{\"start\":\"112201\",\"end\":\"112206\"},{\"start\":\"112210\",\"end\":\"112215\"},{\"start\":\"112219\",\"end\":\"112225\"},{\"start\":\"112229\",\"end\":\"112235\"},{\"start\":\"112618\",\"end\":\"112624\"},{\"start\":\"112628\",\"end\":\"112633\"},{\"start\":\"112637\",\"end\":\"112642\"},{\"start\":\"113275\",\"end\":\"113280\"},{\"start\":\"113284\",\"end\":\"113288\"},{\"start\":\"113292\",\"end\":\"113297\"},{\"start\":\"113301\",\"end\":\"113307\"},{\"start\":\"113606\",\"end\":\"113608\"},{\"start\":\"113614\",\"end\":\"113620\"},{\"start\":\"113624\",\"end\":\"113629\"},{\"start\":\"113633\",\"end\":\"113639\"},{\"start\":\"113643\",\"end\":\"113649\"},{\"start\":\"113653\",\"end\":\"113661\"},{\"start\":\"113667\",\"end\":\"113675\"}]", "bib_entry": "[{\"start\":\"73658\",\"end\":\"73868\",\"attributes\":{\"matched_paper_id\":\"3750204\",\"id\":\"b0\"}},{\"start\":\"73870\",\"end\":\"74073\",\"attributes\":{\"matched_paper_id\":\"11152703\",\"id\":\"b1\"}},{\"start\":\"74075\",\"end\":\"74399\",\"attributes\":{\"matched_paper_id\":\"3346652\",\"id\":\"b2\"}},{\"start\":\"74401\",\"end\":\"74782\",\"attributes\":{\"matched_paper_id\":\"2643381\",\"id\":\"b3\"}},{\"start\":\"74784\",\"end\":\"74943\",\"attributes\":{\"id\":\"b4\"}},{\"start\":\"74945\",\"end\":\"75237\",\"attributes\":{\"matched_paper_id\":\"1818957\",\"id\":\"b5\"}},{\"start\":\"75239\",\"end\":\"75532\",\"attributes\":{\"matched_paper_id\":\"9556502\",\"id\":\"b6\"}},{\"start\":\"75534\",\"end\":\"76010\",\"attributes\":{\"matched_paper_id\":\"16494521\",\"id\":\"b7\"}},{\"start\":\"76012\",\"end\":\"76368\",\"attributes\":{\"matched_paper_id\":\"215852931\",\"id\":\"b8\"}},{\"start\":\"76370\",\"end\":\"76623\",\"attributes\":{\"matched_paper_id\":\"11433762\",\"id\":\"b9\"}},{\"start\":\"76625\",\"end\":\"77078\",\"attributes\":{\"matched_paper_id\":\"980581\",\"id\":\"b10\"}},{\"start\":\"77080\",\"end\":\"77685\",\"attributes\":{\"matched_paper_id\":\"2385670\",\"id\":\"b11\"}},{\"start\":\"77687\",\"end\":\"78226\",\"attributes\":{\"matched_paper_id\":\"14466366\",\"id\":\"b12\"}},{\"start\":\"78228\",\"end\":\"78629\",\"attributes\":{\"matched_paper_id\":\"15281419\",\"id\":\"b13\"}},{\"start\":\"78631\",\"end\":\"79166\",\"attributes\":{\"matched_paper_id\":\"3976946\",\"id\":\"b14\"}},{\"start\":\"79168\",\"end\":\"79654\",\"attributes\":{\"matched_paper_id\":\"189818835\",\"id\":\"b15\"}},{\"start\":\"79656\",\"end\":\"80134\",\"attributes\":{\"matched_paper_id\":\"52824162\",\"id\":\"b16\"}},{\"start\":\"80136\",\"end\":\"80659\",\"attributes\":{\"matched_paper_id\":\"6329628\",\"id\":\"b17\"}},{\"start\":\"80661\",\"end\":\"80908\",\"attributes\":{\"id\":\"b18\"}},{\"start\":\"80910\",\"end\":\"81144\",\"attributes\":{\"matched_paper_id\":\"684904\",\"id\":\"b19\"}},{\"start\":\"81146\",\"end\":\"81383\",\"attributes\":{\"matched_paper_id\":\"353032\",\"id\":\"b20\"}},{\"start\":\"81385\",\"end\":\"81887\",\"attributes\":{\"matched_paper_id\":\"4677450\",\"id\":\"b21\"}},{\"start\":\"81889\",\"end\":\"82337\",\"attributes\":{\"matched_paper_id\":\"17610729\",\"id\":\"b22\"}},{\"start\":\"82339\",\"end\":\"82693\",\"attributes\":{\"matched_paper_id\":\"4613827\",\"id\":\"b23\"}},{\"start\":\"82695\",\"end\":\"82935\",\"attributes\":{\"matched_paper_id\":\"39555041\",\"id\":\"b24\"}},{\"start\":\"82937\",\"end\":\"83140\",\"attributes\":{\"matched_paper_id\":\"2788276\",\"id\":\"b25\"}},{\"start\":\"83142\",\"end\":\"83658\",\"attributes\":{\"matched_paper_id\":\"3042109\",\"id\":\"b26\"}},{\"start\":\"83660\",\"end\":\"84013\",\"attributes\":{\"matched_paper_id\":\"61066084\",\"id\":\"b27\"}},{\"start\":\"84015\",\"end\":\"84392\",\"attributes\":{\"matched_paper_id\":\"744188\",\"id\":\"b28\"}},{\"start\":\"84394\",\"end\":\"84488\",\"attributes\":{\"id\":\"b29\"}},{\"start\":\"84490\",\"end\":\"84562\",\"attributes\":{\"id\":\"b30\"}},{\"start\":\"84564\",\"end\":\"84793\",\"attributes\":{\"matched_paper_id\":\"38314993\",\"id\":\"b31\"}},{\"start\":\"84795\",\"end\":\"84960\",\"attributes\":{\"matched_paper_id\":\"52977443\",\"id\":\"b32\"}},{\"start\":\"84962\",\"end\":\"85045\",\"attributes\":{\"id\":\"b33\"}},{\"start\":\"85047\",\"end\":\"85395\",\"attributes\":{\"matched_paper_id\":\"2666044\",\"id\":\"b34\"}},{\"start\":\"85397\",\"end\":\"85719\",\"attributes\":{\"matched_paper_id\":\"3685568\",\"id\":\"b35\"}},{\"start\":\"85721\",\"end\":\"85993\",\"attributes\":{\"matched_paper_id\":\"44772356\",\"id\":\"b36\"}},{\"start\":\"85995\",\"end\":\"86443\",\"attributes\":{\"matched_paper_id\":\"209497828\",\"id\":\"b37\"}},{\"start\":\"86445\",\"end\":\"86610\",\"attributes\":{\"matched_paper_id\":\"1677864\",\"id\":\"b38\"}},{\"start\":\"86612\",\"end\":\"87125\",\"attributes\":{\"matched_paper_id\":\"9812826\",\"id\":\"b39\"}},{\"start\":\"87127\",\"end\":\"87395\",\"attributes\":{\"matched_paper_id\":\"877929\",\"id\":\"b40\"}},{\"start\":\"87397\",\"end\":\"87613\",\"attributes\":{\"matched_paper_id\":\"7728339\",\"id\":\"b41\"}},{\"start\":\"87615\",\"end\":\"87973\",\"attributes\":{\"matched_paper_id\":\"733980\",\"id\":\"b42\"}},{\"start\":\"87975\",\"end\":\"88378\",\"attributes\":{\"matched_paper_id\":\"9995754\",\"id\":\"b43\"}},{\"start\":\"88380\",\"end\":\"88761\",\"attributes\":{\"matched_paper_id\":\"27760507\",\"id\":\"b44\"}},{\"start\":\"88763\",\"end\":\"89089\",\"attributes\":{\"id\":\"b45\",\"doi\":\"arXiv:1806.05794\"}},{\"start\":\"89091\",\"end\":\"89515\",\"attributes\":{\"matched_paper_id\":\"155100847\",\"id\":\"b46\"}},{\"start\":\"89517\",\"end\":\"89930\",\"attributes\":{\"matched_paper_id\":\"206655274\",\"id\":\"b47\"}},{\"start\":\"89932\",\"end\":\"90476\",\"attributes\":{\"matched_paper_id\":\"201128119\",\"id\":\"b48\"}},{\"start\":\"90478\",\"end\":\"90857\",\"attributes\":{\"matched_paper_id\":\"16829375\",\"id\":\"b49\"}},{\"start\":\"90859\",\"end\":\"91240\",\"attributes\":{\"matched_paper_id\":\"166787\",\"id\":\"b50\"}},{\"start\":\"91242\",\"end\":\"91626\",\"attributes\":{\"matched_paper_id\":\"4430199\",\"id\":\"b51\"}},{\"start\":\"91628\",\"end\":\"91983\",\"attributes\":{\"matched_paper_id\":\"14637261\",\"id\":\"b52\"}},{\"start\":\"91985\",\"end\":\"92392\",\"attributes\":{\"matched_paper_id\":\"52062175\",\"id\":\"b53\"}},{\"start\":\"92394\",\"end\":\"92923\",\"attributes\":{\"matched_paper_id\":\"11079735\",\"id\":\"b54\"}},{\"start\":\"92925\",\"end\":\"93429\",\"attributes\":{\"matched_paper_id\":\"15419565\",\"id\":\"b55\"}},{\"start\":\"93431\",\"end\":\"93832\",\"attributes\":{\"matched_paper_id\":\"3986108\",\"id\":\"b56\"}},{\"start\":\"93834\",\"end\":\"94148\",\"attributes\":{\"matched_paper_id\":\"355163\",\"id\":\"b57\"}},{\"start\":\"94150\",\"end\":\"94413\",\"attributes\":{\"matched_paper_id\":\"22091296\",\"id\":\"b58\"}},{\"start\":\"94415\",\"end\":\"94817\",\"attributes\":{\"matched_paper_id\":\"2444928\",\"id\":\"b59\"}},{\"start\":\"94819\",\"end\":\"95269\",\"attributes\":{\"matched_paper_id\":\"12003435\",\"id\":\"b60\"}},{\"start\":\"95271\",\"end\":\"95645\",\"attributes\":{\"matched_paper_id\":\"17878325\",\"id\":\"b61\"}},{\"start\":\"95647\",\"end\":\"96066\",\"attributes\":{\"matched_paper_id\":\"216021787\",\"id\":\"b62\"}},{\"start\":\"96068\",\"end\":\"96516\",\"attributes\":{\"matched_paper_id\":\"10659969\",\"id\":\"b63\"}},{\"start\":\"96518\",\"end\":\"96589\",\"attributes\":{\"id\":\"b64\"}},{\"start\":\"96591\",\"end\":\"96946\",\"attributes\":{\"matched_paper_id\":\"1096997\",\"id\":\"b65\"}},{\"start\":\"96948\",\"end\":\"97077\",\"attributes\":{\"id\":\"b66\"}},{\"start\":\"97079\",\"end\":\"97465\",\"attributes\":{\"matched_paper_id\":\"206655679\",\"id\":\"b67\"}},{\"start\":\"97467\",\"end\":\"97577\",\"attributes\":{\"id\":\"b68\"}},{\"start\":\"97579\",\"end\":\"97640\",\"attributes\":{\"id\":\"b69\"}},{\"start\":\"97642\",\"end\":\"98001\",\"attributes\":{\"matched_paper_id\":\"15919858\",\"id\":\"b70\"}},{\"start\":\"98003\",\"end\":\"98298\",\"attributes\":{\"matched_paper_id\":\"14542261\",\"id\":\"b71\"}},{\"start\":\"98300\",\"end\":\"98438\",\"attributes\":{\"id\":\"b72\"}},{\"start\":\"98440\",\"end\":\"98905\",\"attributes\":{\"id\":\"b73\"}},{\"start\":\"98907\",\"end\":\"99465\",\"attributes\":{\"matched_paper_id\":\"8582357\",\"id\":\"b74\"}},{\"start\":\"99467\",\"end\":\"99836\",\"attributes\":{\"matched_paper_id\":\"95666827\",\"id\":\"b75\"}},{\"start\":\"99838\",\"end\":\"100321\",\"attributes\":{\"matched_paper_id\":\"15877155\",\"id\":\"b76\"}},{\"start\":\"100323\",\"end\":\"100438\",\"attributes\":{\"id\":\"b77\"}},{\"start\":\"100440\",\"end\":\"100794\",\"attributes\":{\"matched_paper_id\":\"4613827\",\"id\":\"b78\"}},{\"start\":\"100796\",\"end\":\"101107\",\"attributes\":{\"matched_paper_id\":\"7531692\",\"id\":\"b79\"}},{\"start\":\"101109\",\"end\":\"101440\",\"attributes\":{\"matched_paper_id\":\"15126287\",\"id\":\"b80\"}},{\"start\":\"101442\",\"end\":\"101728\",\"attributes\":{\"matched_paper_id\":\"8180104\",\"id\":\"b81\"}},{\"start\":\"101730\",\"end\":\"101961\",\"attributes\":{\"matched_paper_id\":\"5855042\",\"id\":\"b82\"}},{\"start\":\"101963\",\"end\":\"102428\",\"attributes\":{\"matched_paper_id\":\"14440627\",\"id\":\"b83\"}},{\"start\":\"102430\",\"end\":\"102722\",\"attributes\":{\"matched_paper_id\":\"249632\",\"id\":\"b84\"}},{\"start\":\"102724\",\"end\":\"103242\",\"attributes\":{\"matched_paper_id\":\"14210790\",\"id\":\"b85\"}},{\"start\":\"103244\",\"end\":\"103624\",\"attributes\":{\"matched_paper_id\":\"8967361\",\"id\":\"b86\"}},{\"start\":\"103626\",\"end\":\"103982\",\"attributes\":{\"matched_paper_id\":\"206657373\",\"id\":\"b87\"}},{\"start\":\"103984\",\"end\":\"104405\",\"attributes\":{\"matched_paper_id\":\"5550280\",\"id\":\"b88\"}},{\"start\":\"104407\",\"end\":\"104889\",\"attributes\":{\"matched_paper_id\":\"2361503\",\"id\":\"b89\"}},{\"start\":\"104891\",\"end\":\"105114\",\"attributes\":{\"id\":\"b90\",\"doi\":\"arXiv:1408.2927\"}},{\"start\":\"105116\",\"end\":\"105502\",\"attributes\":{\"id\":\"b91\",\"doi\":\"arXiv:1805.03718\"}},{\"start\":\"105504\",\"end\":\"106005\",\"attributes\":{\"matched_paper_id\":\"207673185\",\"id\":\"b92\"}},{\"start\":\"106007\",\"end\":\"106607\",\"attributes\":{\"matched_paper_id\":\"26102636\",\"id\":\"b93\"}},{\"start\":\"106609\",\"end\":\"107011\",\"attributes\":{\"matched_paper_id\":\"214394579\",\"id\":\"b94\"}},{\"start\":\"107013\",\"end\":\"107332\",\"attributes\":{\"matched_paper_id\":\"53223494\",\"id\":\"b95\"}},{\"start\":\"107334\",\"end\":\"107818\",\"attributes\":{\"matched_paper_id\":\"58027666\",\"id\":\"b96\"}},{\"start\":\"107820\",\"end\":\"108296\",\"attributes\":{\"matched_paper_id\":\"49292274\",\"id\":\"b97\"}},{\"start\":\"108298\",\"end\":\"108686\",\"attributes\":{\"matched_paper_id\":\"51618\",\"id\":\"b98\"}},{\"start\":\"108688\",\"end\":\"109144\",\"attributes\":{\"matched_paper_id\":\"2397189\",\"id\":\"b99\"}},{\"start\":\"109146\",\"end\":\"109327\",\"attributes\":{\"matched_paper_id\":\"12609978\",\"id\":\"b100\"}},{\"start\":\"109329\",\"end\":\"109897\",\"attributes\":{\"matched_paper_id\":\"86547212\",\"id\":\"b101\"}},{\"start\":\"109899\",\"end\":\"110366\",\"attributes\":{\"matched_paper_id\":\"208154666\",\"id\":\"b102\"}},{\"start\":\"110368\",\"end\":\"110535\",\"attributes\":{\"matched_paper_id\":\"53235957\",\"id\":\"b103\"}},{\"start\":\"110537\",\"end\":\"111004\",\"attributes\":{\"matched_paper_id\":\"209093915\",\"id\":\"b104\"}},{\"start\":\"111006\",\"end\":\"111424\",\"attributes\":{\"matched_paper_id\":\"4701912\",\"id\":\"b105\"}},{\"start\":\"111426\",\"end\":\"111874\",\"attributes\":{\"matched_paper_id\":\"50768158\",\"id\":\"b106\"}},{\"start\":\"111876\",\"end\":\"112137\",\"attributes\":{\"matched_paper_id\":\"58027891\",\"id\":\"b107\"}},{\"start\":\"112139\",\"end\":\"112509\",\"attributes\":{\"matched_paper_id\":\"4568612\",\"id\":\"b108\"}},{\"start\":\"112511\",\"end\":\"113168\",\"attributes\":{\"matched_paper_id\":\"195886417\",\"id\":\"b109\"}},{\"start\":\"113170\",\"end\":\"113549\",\"attributes\":{\"matched_paper_id\":\"1353882\",\"id\":\"b110\"}},{\"start\":\"113551\",\"end\":\"113897\",\"attributes\":{\"matched_paper_id\":\"197545084\",\"id\":\"b111\"}}]", "bib_title": "[{\"start\":\"73658\",\"end\":\"73702\"},{\"start\":\"73870\",\"end\":\"73910\"},{\"start\":\"74075\",\"end\":\"74107\"},{\"start\":\"74401\",\"end\":\"74478\"},{\"start\":\"74945\",\"end\":\"75015\"},{\"start\":\"75239\",\"end\":\"75280\"},{\"start\":\"75534\",\"end\":\"75613\"},{\"start\":\"76012\",\"end\":\"76084\"},{\"start\":\"76370\",\"end\":\"76432\"},{\"start\":\"76625\",\"end\":\"76715\"},{\"start\":\"77080\",\"end\":\"77142\"},{\"start\":\"77687\",\"end\":\"77741\"},{\"start\":\"78228\",\"end\":\"78291\"},{\"start\":\"78631\",\"end\":\"78664\"},{\"start\":\"79168\",\"end\":\"79252\"},{\"start\":\"79656\",\"end\":\"79762\"},{\"start\":\"80136\",\"end\":\"80229\"},{\"start\":\"80910\",\"end\":\"80954\"},{\"start\":\"81146\",\"end\":\"81185\"},{\"start\":\"81385\",\"end\":\"81444\"},{\"start\":\"81889\",\"end\":\"81980\"},{\"start\":\"82339\",\"end\":\"82424\"},{\"start\":\"82695\",\"end\":\"82760\"},{\"start\":\"82937\",\"end\":\"82984\"},{\"start\":\"83142\",\"end\":\"83224\"},{\"start\":\"83660\",\"end\":\"83750\"},{\"start\":\"84015\",\"end\":\"84120\"},{\"start\":\"84564\",\"end\":\"84596\"},{\"start\":\"84795\",\"end\":\"84820\"},{\"start\":\"85047\",\"end\":\"85134\"},{\"start\":\"85397\",\"end\":\"85473\"},{\"start\":\"85721\",\"end\":\"85770\"},{\"start\":\"85995\",\"end\":\"86060\"},{\"start\":\"86445\",\"end\":\"86490\"},{\"start\":\"86612\",\"end\":\"86699\"},{\"start\":\"87127\",\"end\":\"87174\"},{\"start\":\"87397\",\"end\":\"87427\"},{\"start\":\"87615\",\"end\":\"87738\"},{\"start\":\"87975\",\"end\":\"88075\"},{\"start\":\"88380\",\"end\":\"88425\"},{\"start\":\"89091\",\"end\":\"89163\"},{\"start\":\"89517\",\"end\":\"89544\"},{\"start\":\"89932\",\"end\":\"90033\"},{\"start\":\"90478\",\"end\":\"90537\"},{\"start\":\"90859\",\"end\":\"90946\"},{\"start\":\"91242\",\"end\":\"91319\"},{\"start\":\"91628\",\"end\":\"91703\"},{\"start\":\"91985\",\"end\":\"92058\"},{\"start\":\"92394\",\"end\":\"92480\"},{\"start\":\"92925\",\"end\":\"92993\"},{\"start\":\"93431\",\"end\":\"93503\"},{\"start\":\"93834\",\"end\":\"93922\"},{\"start\":\"94150\",\"end\":\"94209\"},{\"start\":\"94415\",\"end\":\"94476\"},{\"start\":\"94819\",\"end\":\"94889\"},{\"start\":\"95271\",\"end\":\"95354\"},{\"start\":\"95647\",\"end\":\"95721\"},{\"start\":\"96068\",\"end\":\"96108\"},{\"start\":\"96591\",\"end\":\"96682\"},{\"start\":\"97079\",\"end\":\"97135\"},{\"start\":\"97642\",\"end\":\"97708\"},{\"start\":\"98003\",\"end\":\"98058\"},{\"start\":\"98907\",\"end\":\"99071\"},{\"start\":\"99467\",\"end\":\"99532\"},{\"start\":\"99838\",\"end\":\"99934\"},{\"start\":\"100440\",\"end\":\"100525\"},{\"start\":\"100796\",\"end\":\"100840\"},{\"start\":\"101109\",\"end\":\"101176\"},{\"start\":\"101442\",\"end\":\"101474\"},{\"start\":\"101730\",\"end\":\"101758\"},{\"start\":\"101963\",\"end\":\"102035\"},{\"start\":\"102430\",\"end\":\"102470\"},{\"start\":\"102724\",\"end\":\"102769\"},{\"start\":\"103244\",\"end\":\"103323\"},{\"start\":\"103626\",\"end\":\"103667\"},{\"start\":\"103984\",\"end\":\"104046\"},{\"start\":\"104407\",\"end\":\"104500\"},{\"start\":\"105504\",\"end\":\"105558\"},{\"start\":\"106007\",\"end\":\"106094\"},{\"start\":\"106609\",\"end\":\"106725\"},{\"start\":\"107013\",\"end\":\"107056\"},{\"start\":\"107334\",\"end\":\"107425\"},{\"start\":\"107820\",\"end\":\"107931\"},{\"start\":\"108298\",\"end\":\"108347\"},{\"start\":\"108688\",\"end\":\"108789\"},{\"start\":\"109146\",\"end\":\"109179\"},{\"start\":\"109329\",\"end\":\"109403\"},{\"start\":\"109899\",\"end\":\"109962\"},{\"start\":\"110368\",\"end\":\"110416\"},{\"start\":\"110537\",\"end\":\"110614\"},{\"start\":\"111006\",\"end\":\"111094\"},{\"start\":\"111426\",\"end\":\"111487\"},{\"start\":\"111876\",\"end\":\"111936\"},{\"start\":\"112139\",\"end\":\"112197\"},{\"start\":\"112511\",\"end\":\"112614\"},{\"start\":\"113170\",\"end\":\"113271\"},{\"start\":\"113551\",\"end\":\"113602\"}]", "bib_author": "[{\"start\":\"73704\",\"end\":\"73713\"},{\"start\":\"73713\",\"end\":\"73724\"},{\"start\":\"73912\",\"end\":\"73922\"},{\"start\":\"74109\",\"end\":\"74120\"},{\"start\":\"74120\",\"end\":\"74131\"},{\"start\":\"74131\",\"end\":\"74143\"},{\"start\":\"74143\",\"end\":\"74157\"},{\"start\":\"74157\",\"end\":\"74174\"},{\"start\":\"74174\",\"end\":\"74182\"},{\"start\":\"74480\",\"end\":\"74490\"},{\"start\":\"74490\",\"end\":\"74502\"},{\"start\":\"74502\",\"end\":\"74515\"},{\"start\":\"74515\",\"end\":\"74523\"},{\"start\":\"74802\",\"end\":\"74816\"},{\"start\":\"74816\",\"end\":\"74824\"},{\"start\":\"75017\",\"end\":\"75023\"},{\"start\":\"75023\",\"end\":\"75030\"},{\"start\":\"75030\",\"end\":\"75037\"},{\"start\":\"75037\",\"end\":\"75043\"},{\"start\":\"75043\",\"end\":\"75049\"},{\"start\":\"75282\",\"end\":\"75289\"},{\"start\":\"75289\",\"end\":\"75296\"},{\"start\":\"75296\",\"end\":\"75305\"},{\"start\":\"75615\",\"end\":\"75624\"},{\"start\":\"75624\",\"end\":\"75636\"},{\"start\":\"75636\",\"end\":\"75644\"},{\"start\":\"75644\",\"end\":\"75654\"},{\"start\":\"75654\",\"end\":\"75664\"},{\"start\":\"75664\",\"end\":\"75676\"},{\"start\":\"75676\",\"end\":\"75686\"},{\"start\":\"75686\",\"end\":\"75696\"},{\"start\":\"76086\",\"end\":\"76093\"},{\"start\":\"76093\",\"end\":\"76101\"},{\"start\":\"76101\",\"end\":\"76108\"},{\"start\":\"76108\",\"end\":\"76117\"},{\"start\":\"76117\",\"end\":\"76125\"},{\"start\":\"76434\",\"end\":\"76445\"},{\"start\":\"76445\",\"end\":\"76455\"},{\"start\":\"76455\",\"end\":\"76464\"},{\"start\":\"76717\",\"end\":\"76724\"},{\"start\":\"76724\",\"end\":\"76731\"},{\"start\":\"76731\",\"end\":\"76740\"},{\"start\":\"76740\",\"end\":\"76748\"},{\"start\":\"77144\",\"end\":\"77153\"},{\"start\":\"77153\",\"end\":\"77165\"},{\"start\":\"77165\",\"end\":\"77179\"},{\"start\":\"77179\",\"end\":\"77195\"},{\"start\":\"77195\",\"end\":\"77201\"},{\"start\":\"77201\",\"end\":\"77215\"},{\"start\":\"77743\",\"end\":\"77753\"},{\"start\":\"77753\",\"end\":\"77762\"},{\"start\":\"77762\",\"end\":\"77770\"},{\"start\":\"77770\",\"end\":\"77780\"},{\"start\":\"77780\",\"end\":\"77791\"},{\"start\":\"77791\",\"end\":\"77801\"},{\"start\":\"77801\",\"end\":\"77813\"},{\"start\":\"77813\",\"end\":\"77821\"},{\"start\":\"77821\",\"end\":\"77829\"},{\"start\":\"77829\",\"end\":\"77839\"},{\"start\":\"78293\",\"end\":\"78301\"},{\"start\":\"78301\",\"end\":\"78309\"},{\"start\":\"78309\",\"end\":\"78315\"},{\"start\":\"78315\",\"end\":\"78323\"},{\"start\":\"78666\",\"end\":\"78676\"},{\"start\":\"78676\",\"end\":\"78686\"},{\"start\":\"78686\",\"end\":\"78693\"},{\"start\":\"79254\",\"end\":\"79263\"},{\"start\":\"79263\",\"end\":\"79272\"},{\"start\":\"79272\",\"end\":\"79279\"},{\"start\":\"79279\",\"end\":\"79289\"},{\"start\":\"79764\",\"end\":\"79771\"},{\"start\":\"79771\",\"end\":\"79777\"},{\"start\":\"79777\",\"end\":\"79783\"},{\"start\":\"79783\",\"end\":\"79792\"},{\"start\":\"79792\",\"end\":\"79800\"},{\"start\":\"79800\",\"end\":\"79807\"},{\"start\":\"79807\",\"end\":\"79815\"},{\"start\":\"79815\",\"end\":\"79822\"},{\"start\":\"80231\",\"end\":\"80242\"},{\"start\":\"80242\",\"end\":\"80249\"},{\"start\":\"80249\",\"end\":\"80266\"},{\"start\":\"80266\",\"end\":\"80285\"},{\"start\":\"80285\",\"end\":\"80299\"},{\"start\":\"80299\",\"end\":\"80305\"},{\"start\":\"80305\",\"end\":\"80319\"},{\"start\":\"80319\",\"end\":\"80331\"},{\"start\":\"80714\",\"end\":\"80726\"},{\"start\":\"80956\",\"end\":\"80966\"},{\"start\":\"80966\",\"end\":\"80983\"},{\"start\":\"81187\",\"end\":\"81196\"},{\"start\":\"81196\",\"end\":\"81207\"},{\"start\":\"81207\",\"end\":\"81220\"},{\"start\":\"81446\",\"end\":\"81461\"},{\"start\":\"81461\",\"end\":\"81471\"},{\"start\":\"81471\",\"end\":\"81489\"},{\"start\":\"81489\",\"end\":\"81500\"},{\"start\":\"81982\",\"end\":\"81992\"},{\"start\":\"81992\",\"end\":\"82001\"},{\"start\":\"82001\",\"end\":\"82011\"},{\"start\":\"82011\",\"end\":\"82026\"},{\"start\":\"82426\",\"end\":\"82434\"},{\"start\":\"82434\",\"end\":\"82447\"},{\"start\":\"82447\",\"end\":\"82459\"},{\"start\":\"82762\",\"end\":\"82773\"},{\"start\":\"82986\",\"end\":\"82997\"},{\"start\":\"83226\",\"end\":\"83243\"},{\"start\":\"83243\",\"end\":\"83254\"},{\"start\":\"83752\",\"end\":\"83768\"},{\"start\":\"83768\",\"end\":\"83779\"},{\"start\":\"83779\",\"end\":\"83790\"},{\"start\":\"84122\",\"end\":\"84129\"},{\"start\":\"84129\",\"end\":\"84142\"},{\"start\":\"84598\",\"end\":\"84608\"},{\"start\":\"84608\",\"end\":\"84621\"},{\"start\":\"84621\",\"end\":\"84634\"},{\"start\":\"84822\",\"end\":\"84832\"},{\"start\":\"84832\",\"end\":\"84850\"},{\"start\":\"85136\",\"end\":\"85147\"},{\"start\":\"85147\",\"end\":\"85156\"},{\"start\":\"85156\",\"end\":\"85167\"},{\"start\":\"85475\",\"end\":\"85483\"},{\"start\":\"85483\",\"end\":\"85492\"},{\"start\":\"85492\",\"end\":\"85501\"},{\"start\":\"85772\",\"end\":\"85782\"},{\"start\":\"85782\",\"end\":\"85793\"},{\"start\":\"85793\",\"end\":\"85804\"},{\"start\":\"86062\",\"end\":\"86071\"},{\"start\":\"86071\",\"end\":\"86080\"},{\"start\":\"86080\",\"end\":\"86094\"},{\"start\":\"86094\",\"end\":\"86105\"},{\"start\":\"86105\",\"end\":\"86111\"},{\"start\":\"86111\",\"end\":\"86125\"},{\"start\":\"86125\",\"end\":\"86135\"},{\"start\":\"86492\",\"end\":\"86501\"},{\"start\":\"86701\",\"end\":\"86711\"},{\"start\":\"86711\",\"end\":\"86722\"},{\"start\":\"86722\",\"end\":\"86734\"},{\"start\":\"87176\",\"end\":\"87186\"},{\"start\":\"87186\",\"end\":\"87195\"},{\"start\":\"87429\",\"end\":\"87442\"},{\"start\":\"87740\",\"end\":\"87751\"},{\"start\":\"88077\",\"end\":\"88083\"},{\"start\":\"88083\",\"end\":\"88096\"},{\"start\":\"88096\",\"end\":\"88105\"},{\"start\":\"88105\",\"end\":\"88114\"},{\"start\":\"88427\",\"end\":\"88436\"},{\"start\":\"88436\",\"end\":\"88445\"},{\"start\":\"88445\",\"end\":\"88458\"},{\"start\":\"88458\",\"end\":\"88468\"},{\"start\":\"88826\",\"end\":\"88835\"},{\"start\":\"88835\",\"end\":\"88846\"},{\"start\":\"88846\",\"end\":\"88853\"},{\"start\":\"88853\",\"end\":\"88862\"},{\"start\":\"88862\",\"end\":\"88876\"},{\"start\":\"88876\",\"end\":\"88886\"},{\"start\":\"89165\",\"end\":\"89174\"},{\"start\":\"89174\",\"end\":\"89183\"},{\"start\":\"89183\",\"end\":\"89190\"},{\"start\":\"89190\",\"end\":\"89198\"},{\"start\":\"89198\",\"end\":\"89208\"},{\"start\":\"89546\",\"end\":\"89559\"},{\"start\":\"89559\",\"end\":\"89571\"},{\"start\":\"89571\",\"end\":\"89580\"},{\"start\":\"89580\",\"end\":\"89589\"},{\"start\":\"89589\",\"end\":\"89597\"},{\"start\":\"89597\",\"end\":\"89611\"},{\"start\":\"89611\",\"end\":\"89622\"},{\"start\":\"89622\",\"end\":\"89634\"},{\"start\":\"90035\",\"end\":\"90046\"},{\"start\":\"90046\",\"end\":\"90055\"},{\"start\":\"90055\",\"end\":\"90066\"},{\"start\":\"90066\",\"end\":\"90083\"},{\"start\":\"90083\",\"end\":\"90093\"},{\"start\":\"90093\",\"end\":\"90102\"},{\"start\":\"90102\",\"end\":\"90115\"},{\"start\":\"90539\",\"end\":\"90549\"},{\"start\":\"90549\",\"end\":\"90559\"},{\"start\":\"90559\",\"end\":\"90568\"},{\"start\":\"90568\",\"end\":\"90576\"},{\"start\":\"90948\",\"end\":\"90961\"},{\"start\":\"90961\",\"end\":\"90970\"},{\"start\":\"90970\",\"end\":\"90978\"},{\"start\":\"90978\",\"end\":\"90992\"},{\"start\":\"90992\",\"end\":\"91003\"},{\"start\":\"91003\",\"end\":\"91015\"},{\"start\":\"91321\",\"end\":\"91334\"},{\"start\":\"91334\",\"end\":\"91346\"},{\"start\":\"91346\",\"end\":\"91358\"},{\"start\":\"91358\",\"end\":\"91368\"},{\"start\":\"91368\",\"end\":\"91381\"},{\"start\":\"91381\",\"end\":\"91395\"},{\"start\":\"91705\",\"end\":\"91715\"},{\"start\":\"91715\",\"end\":\"91724\"},{\"start\":\"91724\",\"end\":\"91732\"},{\"start\":\"91732\",\"end\":\"91745\"},{\"start\":\"92060\",\"end\":\"92071\"},{\"start\":\"92071\",\"end\":\"92082\"},{\"start\":\"92082\",\"end\":\"92090\"},{\"start\":\"92090\",\"end\":\"92103\"},{\"start\":\"92482\",\"end\":\"92492\"},{\"start\":\"92492\",\"end\":\"92501\"},{\"start\":\"92501\",\"end\":\"92517\"},{\"start\":\"92517\",\"end\":\"92527\"},{\"start\":\"92527\",\"end\":\"92537\"},{\"start\":\"92995\",\"end\":\"93001\"},{\"start\":\"93001\",\"end\":\"93008\"},{\"start\":\"93008\",\"end\":\"93025\"},{\"start\":\"93025\",\"end\":\"93044\"},{\"start\":\"93044\",\"end\":\"93053\"},{\"start\":\"93053\",\"end\":\"93059\"},{\"start\":\"93059\",\"end\":\"93066\"},{\"start\":\"93505\",\"end\":\"93512\"},{\"start\":\"93512\",\"end\":\"93531\"},{\"start\":\"93531\",\"end\":\"93543\"},{\"start\":\"93543\",\"end\":\"93553\"},{\"start\":\"93553\",\"end\":\"93564\"},{\"start\":\"93564\",\"end\":\"93578\"},{\"start\":\"93578\",\"end\":\"93595\"},{\"start\":\"93924\",\"end\":\"93933\"},{\"start\":\"93933\",\"end\":\"93947\"},{\"start\":\"93947\",\"end\":\"93957\"},{\"start\":\"93957\",\"end\":\"93963\"},{\"start\":\"94211\",\"end\":\"94221\"},{\"start\":\"94221\",\"end\":\"94228\"},{\"start\":\"94478\",\"end\":\"94487\"},{\"start\":\"94487\",\"end\":\"94504\"},{\"start\":\"94891\",\"end\":\"94902\"},{\"start\":\"94902\",\"end\":\"94913\"},{\"start\":\"94913\",\"end\":\"94928\"},{\"start\":\"94928\",\"end\":\"94940\"},{\"start\":\"94940\",\"end\":\"94953\"},{\"start\":\"94953\",\"end\":\"94961\"},{\"start\":\"95356\",\"end\":\"95362\"},{\"start\":\"95362\",\"end\":\"95373\"},{\"start\":\"95723\",\"end\":\"95732\"},{\"start\":\"95732\",\"end\":\"95741\"},{\"start\":\"95741\",\"end\":\"95755\"},{\"start\":\"95755\",\"end\":\"95765\"},{\"start\":\"95765\",\"end\":\"95777\"},{\"start\":\"95777\",\"end\":\"95786\"},{\"start\":\"96110\",\"end\":\"96123\"},{\"start\":\"96123\",\"end\":\"96136\"},{\"start\":\"96136\",\"end\":\"96148\"},{\"start\":\"96148\",\"end\":\"96158\"},{\"start\":\"96158\",\"end\":\"96169\"},{\"start\":\"96169\",\"end\":\"96179\"},{\"start\":\"96179\",\"end\":\"96190\"},{\"start\":\"96190\",\"end\":\"96206\"},{\"start\":\"96206\",\"end\":\"96215\"},{\"start\":\"96215\",\"end\":\"96226\"},{\"start\":\"96684\",\"end\":\"96692\"},{\"start\":\"96692\",\"end\":\"96698\"},{\"start\":\"96698\",\"end\":\"96708\"},{\"start\":\"96708\",\"end\":\"96715\"},{\"start\":\"96958\",\"end\":\"96970\"},{\"start\":\"96970\",\"end\":\"96978\"},{\"start\":\"96978\",\"end\":\"96987\"},{\"start\":\"97137\",\"end\":\"97150\"},{\"start\":\"97150\",\"end\":\"97161\"},{\"start\":\"97161\",\"end\":\"97175\"},{\"start\":\"97175\",\"end\":\"97186\"},{\"start\":\"97710\",\"end\":\"97721\"},{\"start\":\"97721\",\"end\":\"97730\"},{\"start\":\"97730\",\"end\":\"97741\"},{\"start\":\"97741\",\"end\":\"97753\"},{\"start\":\"97753\",\"end\":\"97765\"},{\"start\":\"97765\",\"end\":\"97774\"},{\"start\":\"98060\",\"end\":\"98069\"},{\"start\":\"98069\",\"end\":\"98079\"},{\"start\":\"98079\",\"end\":\"98089\"},{\"start\":\"98089\",\"end\":\"98100\"},{\"start\":\"98543\",\"end\":\"98554\"},{\"start\":\"98554\",\"end\":\"98562\"},{\"start\":\"98562\",\"end\":\"98571\"},{\"start\":\"98571\",\"end\":\"98580\"},{\"start\":\"98580\",\"end\":\"98597\"},{\"start\":\"99073\",\"end\":\"99088\"},{\"start\":\"99088\",\"end\":\"99100\"},{\"start\":\"99100\",\"end\":\"99111\"},{\"start\":\"99111\",\"end\":\"99120\"},{\"start\":\"99120\",\"end\":\"99129\"},{\"start\":\"99129\",\"end\":\"99140\"},{\"start\":\"99534\",\"end\":\"99545\"},{\"start\":\"99545\",\"end\":\"99554\"},{\"start\":\"99554\",\"end\":\"99563\"},{\"start\":\"99563\",\"end\":\"99573\"},{\"start\":\"99573\",\"end\":\"99584\"},{\"start\":\"99584\",\"end\":\"99594\"},{\"start\":\"99936\",\"end\":\"99947\"},{\"start\":\"99947\",\"end\":\"99957\"},{\"start\":\"99957\",\"end\":\"99968\"},{\"start\":\"100527\",\"end\":\"100535\"},{\"start\":\"100535\",\"end\":\"100548\"},{\"start\":\"100548\",\"end\":\"100560\"},{\"start\":\"100842\",\"end\":\"100850\"},{\"start\":\"100850\",\"end\":\"100857\"},{\"start\":\"100857\",\"end\":\"100866\"},{\"start\":\"100866\",\"end\":\"100874\"},{\"start\":\"100874\",\"end\":\"100884\"},{\"start\":\"101178\",\"end\":\"101188\"},{\"start\":\"101188\",\"end\":\"101197\"},{\"start\":\"101476\",\"end\":\"101487\"},{\"start\":\"101487\",\"end\":\"101498\"},{\"start\":\"101498\",\"end\":\"101517\"},{\"start\":\"101760\",\"end\":\"101774\"},{\"start\":\"101774\",\"end\":\"101784\"},{\"start\":\"102037\",\"end\":\"102048\"},{\"start\":\"102048\",\"end\":\"102060\"},{\"start\":\"102060\",\"end\":\"102071\"},{\"start\":\"102071\",\"end\":\"102085\"},{\"start\":\"102085\",\"end\":\"102094\"},{\"start\":\"102472\",\"end\":\"102482\"},{\"start\":\"102482\",\"end\":\"102492\"},{\"start\":\"102771\",\"end\":\"102777\"},{\"start\":\"102777\",\"end\":\"102786\"},{\"start\":\"102786\",\"end\":\"102793\"},{\"start\":\"103325\",\"end\":\"103336\"},{\"start\":\"103336\",\"end\":\"103346\"},{\"start\":\"103346\",\"end\":\"103352\"},{\"start\":\"103669\",\"end\":\"103680\"},{\"start\":\"103680\",\"end\":\"103691\"},{\"start\":\"103691\",\"end\":\"103699\"},{\"start\":\"104048\",\"end\":\"104063\"},{\"start\":\"104063\",\"end\":\"104074\"},{\"start\":\"104074\",\"end\":\"104094\"},{\"start\":\"104502\",\"end\":\"104508\"},{\"start\":\"104508\",\"end\":\"104515\"},{\"start\":\"104515\",\"end\":\"104522\"},{\"start\":\"104932\",\"end\":\"104940\"},{\"start\":\"104940\",\"end\":\"104950\"},{\"start\":\"104950\",\"end\":\"104958\"},{\"start\":\"104958\",\"end\":\"104964\"},{\"start\":\"105188\",\"end\":\"105198\"},{\"start\":\"105198\",\"end\":\"105206\"},{\"start\":\"105206\",\"end\":\"105214\"},{\"start\":\"105214\",\"end\":\"105230\"},{\"start\":\"105230\",\"end\":\"105238\"},{\"start\":\"105238\",\"end\":\"105251\"},{\"start\":\"105251\",\"end\":\"105261\"},{\"start\":\"105261\",\"end\":\"105268\"},{\"start\":\"105560\",\"end\":\"105566\"},{\"start\":\"105566\",\"end\":\"105573\"},{\"start\":\"105573\",\"end\":\"105586\"},{\"start\":\"105586\",\"end\":\"105595\"},{\"start\":\"105595\",\"end\":\"105606\"},{\"start\":\"105606\",\"end\":\"105613\"},{\"start\":\"106096\",\"end\":\"106108\"},{\"start\":\"106108\",\"end\":\"106115\"},{\"start\":\"106115\",\"end\":\"106126\"},{\"start\":\"106126\",\"end\":\"106136\"},{\"start\":\"106136\",\"end\":\"106149\"},{\"start\":\"106149\",\"end\":\"106156\"},{\"start\":\"106156\",\"end\":\"106168\"},{\"start\":\"106168\",\"end\":\"106177\"},{\"start\":\"106177\",\"end\":\"106190\"},{\"start\":\"106190\",\"end\":\"106201\"},{\"start\":\"106727\",\"end\":\"106734\"},{\"start\":\"106734\",\"end\":\"106743\"},{\"start\":\"106743\",\"end\":\"106749\"},{\"start\":\"107058\",\"end\":\"107068\"},{\"start\":\"107068\",\"end\":\"107074\"},{\"start\":\"107074\",\"end\":\"107081\"},{\"start\":\"107427\",\"end\":\"107437\"},{\"start\":\"107437\",\"end\":\"107443\"},{\"start\":\"107443\",\"end\":\"107450\"},{\"start\":\"107933\",\"end\":\"107943\"},{\"start\":\"107943\",\"end\":\"107949\"},{\"start\":\"107949\",\"end\":\"107956\"},{\"start\":\"108349\",\"end\":\"108357\"},{\"start\":\"108357\",\"end\":\"108365\"},{\"start\":\"108365\",\"end\":\"108373\"},{\"start\":\"108373\",\"end\":\"108379\"},{\"start\":\"108379\",\"end\":\"108387\"},{\"start\":\"108791\",\"end\":\"108805\"},{\"start\":\"108805\",\"end\":\"108813\"},{\"start\":\"109181\",\"end\":\"109195\"},{\"start\":\"109195\",\"end\":\"109203\"},{\"start\":\"109405\",\"end\":\"109411\"},{\"start\":\"109411\",\"end\":\"109418\"},{\"start\":\"109418\",\"end\":\"109430\"},{\"start\":\"109430\",\"end\":\"109439\"},{\"start\":\"109439\",\"end\":\"109449\"},{\"start\":\"109449\",\"end\":\"109462\"},{\"start\":\"109462\",\"end\":\"109473\"},{\"start\":\"109473\",\"end\":\"109482\"},{\"start\":\"109482\",\"end\":\"109493\"},{\"start\":\"109493\",\"end\":\"109501\"},{\"start\":\"109964\",\"end\":\"109973\"},{\"start\":\"109973\",\"end\":\"109987\"},{\"start\":\"109987\",\"end\":\"109994\"},{\"start\":\"109994\",\"end\":\"110003\"},{\"start\":\"110003\",\"end\":\"110017\"},{\"start\":\"110017\",\"end\":\"110027\"},{\"start\":\"110418\",\"end\":\"110427\"},{\"start\":\"110616\",\"end\":\"110625\"},{\"start\":\"110625\",\"end\":\"110632\"},{\"start\":\"110632\",\"end\":\"110644\"},{\"start\":\"110644\",\"end\":\"110653\"},{\"start\":\"110653\",\"end\":\"110664\"},{\"start\":\"110664\",\"end\":\"110672\"},{\"start\":\"110672\",\"end\":\"110682\"},{\"start\":\"111096\",\"end\":\"111103\"},{\"start\":\"111103\",\"end\":\"111112\"},{\"start\":\"111112\",\"end\":\"111122\"},{\"start\":\"111489\",\"end\":\"111497\"},{\"start\":\"111497\",\"end\":\"111506\"},{\"start\":\"111506\",\"end\":\"111515\"},{\"start\":\"111515\",\"end\":\"111525\"},{\"start\":\"111938\",\"end\":\"111946\"},{\"start\":\"111946\",\"end\":\"111955\"},{\"start\":\"111955\",\"end\":\"111964\"},{\"start\":\"111964\",\"end\":\"111971\"},{\"start\":\"111971\",\"end\":\"111981\"},{\"start\":\"112199\",\"end\":\"112208\"},{\"start\":\"112208\",\"end\":\"112217\"},{\"start\":\"112217\",\"end\":\"112227\"},{\"start\":\"112227\",\"end\":\"112237\"},{\"start\":\"112616\",\"end\":\"112626\"},{\"start\":\"112626\",\"end\":\"112635\"},{\"start\":\"112635\",\"end\":\"112644\"},{\"start\":\"113273\",\"end\":\"113282\"},{\"start\":\"113282\",\"end\":\"113290\"},{\"start\":\"113290\",\"end\":\"113299\"},{\"start\":\"113299\",\"end\":\"113309\"},{\"start\":\"113604\",\"end\":\"113610\"},{\"start\":\"113610\",\"end\":\"113622\"},{\"start\":\"113622\",\"end\":\"113631\"},{\"start\":\"113631\",\"end\":\"113641\"},{\"start\":\"113641\",\"end\":\"113651\"},{\"start\":\"113651\",\"end\":\"113663\"},{\"start\":\"113663\",\"end\":\"113677\"}]", "bib_venue": "[{\"start\":\"73724\",\"end\":\"73743\"},{\"start\":\"73922\",\"end\":\"73949\"},{\"start\":\"74182\",\"end\":\"74210\"},{\"start\":\"74523\",\"end\":\"74572\"},{\"start\":\"74784\",\"end\":\"74800\"},{\"start\":\"75049\",\"end\":\"75063\"},{\"start\":\"75305\",\"end\":\"75375\"},{\"start\":\"75696\",\"end\":\"75745\"},{\"start\":\"76125\",\"end\":\"76163\"},{\"start\":\"76464\",\"end\":\"76472\"},{\"start\":\"76748\",\"end\":\"76829\"},{\"start\":\"77215\",\"end\":\"77317\"},{\"start\":\"77839\",\"end\":\"77905\"},{\"start\":\"78323\",\"end\":\"78405\"},{\"start\":\"78693\",\"end\":\"78822\"},{\"start\":\"79289\",\"end\":\"79361\"},{\"start\":\"79822\",\"end\":\"79860\"},{\"start\":\"80331\",\"end\":\"80369\"},{\"start\":\"80661\",\"end\":\"80712\"},{\"start\":\"80983\",\"end\":\"81002\"},{\"start\":\"81220\",\"end\":\"81239\"},{\"start\":\"81500\",\"end\":\"81580\"},{\"start\":\"82026\",\"end\":\"82088\"},{\"start\":\"82459\",\"end\":\"82492\"},{\"start\":\"82773\",\"end\":\"82793\"},{\"start\":\"82997\",\"end\":\"83015\"},{\"start\":\"83254\",\"end\":\"83360\"},{\"start\":\"83790\",\"end\":\"83815\"},{\"start\":\"84142\",\"end\":\"84181\"},{\"start\":\"84394\",\"end\":\"84411\"},{\"start\":\"84490\",\"end\":\"84501\"},{\"start\":\"84634\",\"end\":\"84655\"},{\"start\":\"84850\",\"end\":\"84860\"},{\"start\":\"84962\",\"end\":\"84976\"},{\"start\":\"85167\",\"end\":\"85194\"},{\"start\":\"85501\",\"end\":\"85533\"},{\"start\":\"85804\",\"end\":\"85836\"},{\"start\":\"86135\",\"end\":\"86201\"},{\"start\":\"86501\",\"end\":\"86505\"},{\"start\":\"86734\",\"end\":\"86817\"},{\"start\":\"87195\",\"end\":\"87244\"},{\"start\":\"87442\",\"end\":\"87491\"},{\"start\":\"87751\",\"end\":\"87772\"},{\"start\":\"88114\",\"end\":\"88150\"},{\"start\":\"88468\",\"end\":\"88550\"},{\"start\":\"88763\",\"end\":\"88824\"},{\"start\":\"89208\",\"end\":\"89264\"},{\"start\":\"89634\",\"end\":\"89694\"},{\"start\":\"90115\",\"end\":\"90192\"},{\"start\":\"90576\",\"end\":\"90644\"},{\"start\":\"91015\",\"end\":\"91020\"},{\"start\":\"91395\",\"end\":\"91401\"},{\"start\":\"91745\",\"end\":\"91780\"},{\"start\":\"92103\",\"end\":\"92168\"},{\"start\":\"92537\",\"end\":\"92605\"},{\"start\":\"93066\",\"end\":\"93153\"},{\"start\":\"93595\",\"end\":\"93605\"},{\"start\":\"93963\",\"end\":\"93969\"},{\"start\":\"94228\",\"end\":\"94256\"},{\"start\":\"94504\",\"end\":\"94578\"},{\"start\":\"94961\",\"end\":\"95021\"},{\"start\":\"95373\",\"end\":\"95442\"},{\"start\":\"95786\",\"end\":\"95819\"},{\"start\":\"96226\",\"end\":\"96262\"},{\"start\":\"96518\",\"end\":\"96538\"},{\"start\":\"96715\",\"end\":\"96743\"},{\"start\":\"96948\",\"end\":\"96956\"},{\"start\":\"97186\",\"end\":\"97246\"},{\"start\":\"97467\",\"end\":\"97498\"},{\"start\":\"97579\",\"end\":\"97590\"},{\"start\":\"97774\",\"end\":\"97799\"},{\"start\":\"98100\",\"end\":\"98123\"},{\"start\":\"98300\",\"end\":\"98330\"},{\"start\":\"98440\",\"end\":\"98541\"},{\"start\":\"99140\",\"end\":\"99157\"},{\"start\":\"99594\",\"end\":\"99627\"},{\"start\":\"99968\",\"end\":\"100033\"},{\"start\":\"100323\",\"end\":\"100354\"},{\"start\":\"100560\",\"end\":\"100593\"},{\"start\":\"100884\",\"end\":\"100939\"},{\"start\":\"101197\",\"end\":\"101250\"},{\"start\":\"101517\",\"end\":\"101566\"},{\"start\":\"101784\",\"end\":\"101820\"},{\"start\":\"102094\",\"end\":\"102171\"},{\"start\":\"102492\",\"end\":\"102560\"},{\"start\":\"102793\",\"end\":\"102912\"},{\"start\":\"103352\",\"end\":\"103414\"},{\"start\":\"103699\",\"end\":\"103784\"},{\"start\":\"104094\",\"end\":\"104173\"},{\"start\":\"104522\",\"end\":\"104599\"},{\"start\":\"104891\",\"end\":\"104930\"},{\"start\":\"105116\",\"end\":\"105186\"},{\"start\":\"105613\",\"end\":\"105697\"},{\"start\":\"106201\",\"end\":\"106279\"},{\"start\":\"106749\",\"end\":\"106785\"},{\"start\":\"107081\",\"end\":\"107152\"},{\"start\":\"107450\",\"end\":\"107525\"},{\"start\":\"107956\",\"end\":\"108015\"},{\"start\":\"108387\",\"end\":\"108469\"},{\"start\":\"108813\",\"end\":\"108896\"},{\"start\":\"109203\",\"end\":\"109213\"},{\"start\":\"109501\",\"end\":\"109531\"},{\"start\":\"110027\",\"end\":\"110109\"},{\"start\":\"110427\",\"end\":\"110432\"},{\"start\":\"110682\",\"end\":\"110759\"},{\"start\":\"111122\",\"end\":\"111193\"},{\"start\":\"111525\",\"end\":\"111603\"},{\"start\":\"111981\",\"end\":\"111988\"},{\"start\":\"112237\",\"end\":\"112314\"},{\"start\":\"112644\",\"end\":\"112738\"},{\"start\":\"113309\",\"end\":\"113332\"},{\"start\":\"113677\",\"end\":\"113698\"},{\"start\":\"77319\",\"end\":\"77406\"},{\"start\":\"77907\",\"end\":\"77958\"},{\"start\":\"78824\",\"end\":\"78938\"},{\"start\":\"79363\",\"end\":\"79420\"},{\"start\":\"81582\",\"end\":\"81651\"},{\"start\":\"86819\",\"end\":\"86887\"},{\"start\":\"89266\",\"end\":\"89307\"},{\"start\":\"92607\",\"end\":\"92666\"},{\"start\":\"95821\",\"end\":\"95839\"},{\"start\":\"100035\",\"end\":\"100085\"},{\"start\":\"102914\",\"end\":\"103018\"},{\"start\":\"104601\",\"end\":\"104663\"},{\"start\":\"105699\",\"end\":\"105768\"},{\"start\":\"107527\",\"end\":\"107587\"},{\"start\":\"108017\",\"end\":\"108061\"},{\"start\":\"111605\",\"end\":\"111668\"}]"}}}, "year": 2023, "month": 12, "day": 17}