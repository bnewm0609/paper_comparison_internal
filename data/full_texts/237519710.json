{"id": 237519710, "updated": "2022-09-30 01:14:42.764", "metadata": {"title": "Intrusion Detection Method Using Bi-Directional GPT for in-Vehicle Controller Area Networks", "authors": "[{\"first\":\"Minki\",\"last\":\"Nam\",\"middle\":[]},{\"first\":\"Seungyoung\",\"last\":\"Park\",\"middle\":[]},{\"first\":\"Duk\",\"last\":\"Kim\",\"middle\":[\"Soo\"]}]", "venue": "IEEE Access", "journal": "IEEE Access", "publication_date": {"year": 2021, "month": null, "day": null}, "abstract": "The controller area network (CAN) bus protocol is exposed to threats from various attacks because it is designed without consideration of security. In a normal vehicle operation situation, controllers connected to a CAN bus transmit periodic and nonperiodic signals. Thus, if a CAN identifier (ID) sequence is configured by collecting the identifiers of CAN signals in their order of occurrence, it will have a certain pattern. However, if only a very small number of attack IDs are included in a CAN ID sequence, it will be difficult to detect the corresponding pattern change. Thus, a detection method that is different from the conventional one is required to detect such attacks. Since a CAN ID sequence can be regarded as a sentence consisting of words in the form of CAN IDs, a generative pretrained transformer (GPT) model can learn the pattern of a normal CAN ID sequence. Therefore, such a model is expected to be able to detect CAN ID sequences that contain a very small number of attack IDs better than the existing long short-term memory (LSTM)-based method. In this paper, we propose an intrusion detection model that combines two GPT networks in a bi-directional manner to allow both past and future CAN IDs (relative to the time of detection) to be used. The proposed model is trained to minimize the negative log-likelihood (NLL) value of the bi-directional GPT network for a normal sequence. When the NLL value for a CAN ID sequence is larger than a prespecified threshold, it is deemed an intrusion. The proposed model outperforms a single uni-directional GPT model with the same degree of complexity as other existing LSTM-based models because the bi-directional structure of the proposed model maintains the estimation performance for most CAN IDs, regardless of their positions in the sequence.", "fields_of_study": "[\"Computer Science\"]", "external_ids": {"arxiv": null, "mag": null, "acl": null, "pubmed": null, "pubmedcentral": null, "dblp": "journals/access/NamPK21", "doi": "10.1109/access.2021.3110524"}}, "content": {"source": {"pdf_hash": "0ee17c9a630fe064f7d99650f0c15dca3f7a103e", "pdf_src": "IEEE", "pdf_uri": null, "oa_url_match": false, "oa_info": {"license": "CCBY", "open_access_url": "https://ieeexplore.ieee.org/ielx7/6287639/6514899/09530394.pdf", "status": "GOLD"}}, "grobid": {"id": "852f5ab38b0cb442afbd84bddbe8187f9b257674", "type": "plain-text", "url": "s3://ai2-s2-pdf-extraction-prod/parse-results/s2orc_worker/0ee17c9a630fe064f7d99650f0c15dca3f7a103e.txt", "contents": "\nIntrusion Detection Method Using Bi-Directional GPT for In-Vehicle Controller Area Networks\n\n\nNam Minki \nInterdisciplinary Graduate Program\nBIT Medical Convergence\nKangwon National University\n24341ChuncheonRepublic of Korea\n\nSeungyoung Park s.young.park@kangwon.ac.kr \nDepartment of Electrical and Electronics Engineering\nKangwon National University\n24341ChuncheonRepublic of Korea\n\nSenior Member, IEEEDuk Soo Kim \nAutocrypt Company Ltd\n07241SeoulRepublic of Korea\n\nIntrusion Detection Method Using Bi-Directional GPT for In-Vehicle Controller Area Networks\n10.1109/ACCESS.2021.3110524Received August 22, 2021, accepted August 29, 2021, date of publication September 6, 2021, date of current version September 15, 2021.Corresponding author: Seungyoung Park\nThe controller area network (CAN) bus protocol is exposed to threats from various attacks because it is designed without consideration of security. In a normal vehicle operation situation, controllers connected to a CAN bus transmit periodic and nonperiodic signals. Thus, if a CAN identifier (ID) sequence is configured by collecting the identifiers of CAN signals in their order of occurrence, it will have a certain pattern. However, if only a very small number of attack IDs are included in a CAN ID sequence, it will be difficult to detect the corresponding pattern change. Thus, a detection method that is different from the conventional one is required to detect such attacks. Since a CAN ID sequence can be regarded as a sentence consisting of words in the form of CAN IDs, a generative pretrained transformer (GPT) model can learn the pattern of a normal CAN ID sequence. Therefore, such a model is expected to be able to detect CAN ID sequences that contain a very small number of attack IDs better than the existing long short-term memory (LSTM)-based method. In this paper, we propose an intrusion detection model that combines two GPT networks in a bi-directional manner to allow both past and future CAN IDs (relative to the time of detection) to be used. The proposed model is trained to minimize the negative log-likelihood (NLL) value of the bi-directional GPT network for a normal sequence. When the NLL value for a CAN ID sequence is larger than a prespecified threshold, it is deemed an intrusion. The proposed model outperforms a single unidirectional GPT model with the same degree of complexity as other existing LSTM-based models because the bi-directional structure of the proposed model maintains the estimation performance for most CAN IDs, regardless of their positions in the sequence.INDEX TERMSIntrusion detection, generative pretrained transformer, GPT, controller area network, CAN, CAN ID, in-vehicle network, negative log-likelihood, NLL, spoofing attack. SEUNGYOUNG PARK (Senior Member, IEEE) received the B.S., M.S., and Ph.D. degrees in electrical engineering from Korea University, Seoul,\n\nI. INTRODUCTION\n\nController area network (CAN) bus communication is designed for in-vehicle communication. Specifically, an arbitrary electrical control unit (ECU) can broadcast a CAN data frame containing a CAN identifier (ID) and a message from any device connected to the bus [1]. As attacks against CAN bus communication have become more advanced and intelligent, increasingly sophisticated defense techniques against them have been proposed [2]- [6]. Existing methods detect the pattern changes caused by an attack after learning The associate editor coordinating the review of this manuscript and approving it for publication was Hosam El-Ocla . the normal pattern of a CAN ID sequence, which is composed of CAN IDs extracted only from CAN data frames. Hence, if the target sequence for detection contains only a very small number of attack IDs, the difference with respect to the normal pattern will be very small, making it difficult to detect. Therefore, a new detection method is required to detect such attacks.\n\nFor machine translation, long short-term memory (LSTM) models are commonly used because this task involves sequence data composed of words [7]. However, these models have the problem that the translation quality degrades in general as the sequence becomes longer. To solve this problem, the transformer network model was proposed [8]. In this VOLUME 9, 2021 This work is licensed under a Creative Commons Attribution 4.0 License. For more information, see https://creativecommons.org/licenses/by/4.0/ model, the words comprising a sentence and their positions in the sentence are converted into vectors through word token embedding and positional embedding, respectively, and they are processed through a multihead attention structure, thus solving the problem of performance degradation in the translation of long sentences.\n\nEmploying the decoder structure of the transformer network, the sentence generation technique known as generative pretrained transformer (GPT) was proposed by OpenAI [9], [10]. GPT predicts words that may appear at the current time point based on the words generated at the previous time points and then applies the same procedure again to predict the word that is to appear at the next time point. Thus, sentences can be generated using this autoregressive method. In other words, GPT has an excellent advantage in predicting the words that will appear after given words. GPT was trained for sentence generation using text data collected from an enormous corpus of 40 GB, which is called WebText, and the internet as the training data. It was shown that high-quality poems in English could be created using the GPT-2 model with 774 million parameters, and emotional reactions to/from readers were drawn [11]. In [12], it was shown that poems could be created in various languages, including English, Spanish, Ukrainian, Hindi, Bengali, and Assamese, also using a model of 774 million parameters, and they were difficult to distinguish from poems written by humans.\n\nSince an ECU may send CAN data frames containing CAN IDs either regularly or irregularly, a CAN ID sequence will have a certain pattern that is difficult for humans to understand. If CAN IDs are treated as words, a CAN ID sequence can be regarded as a sentence composed of words in the form of CAN IDs. Hence, a GPT model can learn the normal patterns of CAN ID sequences. Considering the excellent sentence generation performance of GPT, it is expected to be able to detect even the fine pattern changes in a CAN ID sequence caused by a small number of attack IDs relatively well. Nevertheless, recalling that GPT will predict the CAN ID at the current time point using the previously generated CAN IDs, it may have difficulty generating predictions in the initial period due to the small number of CAN IDs to be used for prediction. To alleviate this problem, this paper proposes a CAN ID intrusion detection method that combines two GPT networks in a bi-directional manner [13].\n\nOur research contributes the following findings: 1) Combining two GPT networks in a bi-directional manner is shown to significantly improve the detection performance compared to that of a single uni-directional GPT network with the same degree of complexity, even when the target sequence for detection contains a very small number of attack IDs. 2) The proposed method outperforms other existing methods, including a structure in which two LSTM networks are bi-directionally combined, for various attack types. Moreover, the performance shows further improvement with an increasing amount of training data compared to other existing methods. This paper is organized as follows. Section II discusses the composition and security vulnerabilities of the CAN bus protocol and explains the overall CAN data frame structure, including the CAN IDs to be used for detection. Section III introduces existing methods of detecting abnormal patterns of CAN traffic in in-vehicle networks. Section IV describes the structure of the GPT model to be used in the proposed intrusion detection method. Section V proposes the bi-directionally combined GPT structure for detecting anomalies in a CAN ID sequence and explains the corresponding intrusion detection method. Section VI describes the experimental setup and conditions, evaluates the performance of the proposed method in this experimental environment and compares it with the performance of other methods. Finally, Section VII presents the conclusion.\n\n\nII. OVERVIEW OF CAN BUS PROTOCOL\n\nThe CAN bus protocol is a standard communication protocol designed for efficient communication between ECUs without a host computer in the vehicle. Developed in 1983 by Bosch, the CAN bus protocol was established as the ISO 11898 standard in 1993 because of its simple yet efficient structure [1]. A CAN bus operates by means of a broadcasting method such that when one device transmits a message, every device connected to the bus can receive it. At this time, a CAN data frame composed of a CAN ID and the message is transmitted, and arbitrary devices connected to the CAN bus receive the CAN data frame corresponding to a specific CAN ID. Fig. 1 shows the CAN data frame structure used in the CAN bus protocol. The frame structure is composed of a start-of-frame (SOF) delimiter, an identifier (ID) field, a remote transmission request (RTR), a control field, a data field, a cyclic redundancy code (CRC), an acknowledgment (ACK), and an end-of-frame (EOF) delimiter. For a CAN ID, 11 bits of the ID field in the data frame are used. Hence, it can support up to 2, 048 CAN IDs, from '0 \u00d7 000' to '0 \u00d7 7FF'.\n\nBecause many devices sharing one physical bus may start a transmission on the bus while it is in an idle state, message arbitration (the process by which two or more devices agree on which is to use the bus) is of great importance for data transmission. The arbitration process is performed based on the CAN ID as follows. Consider the case in which two or more devices transmit CAN frames simultaneously. In this case, the transmitting devices monitor the bus during the period in which the CAN ID is transmitted while they are sending. If a device detects a dominant level when it is sending a recessive level itself, it refrains from transmission, switches to the receiving mode, and waits until the bus returns to the idle state. As a result, the transmission priority is determined by the CAN ID of the data frame, with a lower ID having a higher priority for transmission.\n\nUnfortunately, the CAN bus protocol was developed without encryption or authentication features because no consideration was given to security at the time of its development [14]. Since many devices, such as Bluetooth devices, 3rd generation/4th generation (3G/4G) devices, Wi-Fi devices, wireless communication sensors, global positioning system (GPS) receivers, and vehicle controllers, as well as ECUs, may be connected in parallel to a single physical bus without security considerations, ECUs can be easily attacked from the outside [15]. As an example, Fig. 2 shows a situation in which ECUs for controlling speed and direction, which are critical to safety, are connected through one CAN bus along with external devices that control universal serial bus (USB) and Wi-Fi communication. If an attacker can access the CAN bus by gaining control of the devices responsible for external communication, he or she can interfere with the normal operation of the ECUs by sending malicious messages or saving normal frames and resending them. Moreover, some ECUs can be shut down by sending repetitive error messages, and intentional accidents can be caused by changing the information about the driving direction and velocity of a vehicle [16]. Such attacks are possible because the CAN data frame does not include the sender information and thus is easily spoofed.\n\n\nIII. RELATED WORK\n\nThis section introduces various existing methods of detecting abnormal patterns of CAN traffic in in-vehicle networks. Reference [2] proposed a method that generates a first-order transition matrix for the CAN IDs constituting a CAN ID sequence and identifies the sequence as an attack if a CAN ID transition is not observed in the training period. However, this method is known to be vulnerable to replay attacks because attacks containing transitions related to a CAN ID that occurs frequently are not detected well.\n\nA method of detecting whether a CAN ID sequence is abnormal using a generative adversarial network (GAN), which consists of a generator and a discriminator, after converting the CAN ID sequence into a binary image has been suggested [3]. The goal of the generator is to artificially create fake images that could be easily mistaken for real images, while the goal of the discriminator is to identify which images it receives have been artificially created [17]. This method demonstrated its ability to detect a CAN ID sequence that includes an attack by employing a discriminator trained using only normal CAN ID sequences. As an extension to this research, a convolutional neural network (CNN)based intrusion method was proposed in which the CAN ID sequences were converted into binary images and the CNN was trained using both normal and attack CAN ID sequence images in a supervised manner [4].\n\nReference [5] suggested a method of detecting an attack by measuring the entropy of each bit comprising a CAN ID for a certain period. It showed its ability to detect attacks by sensing the change in the entropy for each CAN ID bit caused by an injection attack. However, when the number of attacks during the measurement period is small, it is difficult to detect the attack behavior because the entropy change is negligible.\n\nReference [6] proposed a method of detecting attacks using a forward-direction prediction technique based on an LSTM network. Specifically, it predicts the log probability of the CAN ID appearing immediately after a given CAN ID sequence. After performing this process sequentially for a certain period, it identifies an attack by comparing the sum of the log probability values against a threshold.\n\nA method of detecting whether an attack is performed through a given CAN ID using an LSTM-based autoencoder has been suggested [18]. The main idea of this method is to create a reconstructed time series of messages in CAN data frames for each CAN ID that minimizes the reconstruction error. This method demonstrated its ability to detect attacks by sensing the change in the Mahalanobis distance between the original and reconstructed time series of messages from the monitored CAN ID. However, considering the fact that messages from different CAN IDs affect each other interactively, the detection performance would be limited because this method considers messages from only one target CAN ID.\n\nReference [19] proposed a method of detecting attacks by employing a time-series analysis technique to capture the deterministic behavior of CAN traffic dynamics. To accomplish this, in this method, the CAN traffic is modeled as a time series of bytes extracted from the messages of consecutive CAN data frames. After the squared weighted Euclidean distance from the centroid, which is determined in advance using the normal traffic, is calculated for a given CAN traffic value, it identifies the attack by comparing the distance with the prespecified threshold. However, when the number of attacks is small in the target CAN traffic, it is difficult to detect the attack because its distance from the centroid would not be sufficiently large.\n\n\nIV. DESCRIPTION OF GPT NETWORK\n\nA typical machine translation tool uses a sequence-tosequence model composed of an LSTM-based encoder and decoder. Specifically, the sentence to be translated is divided into word tokens, which are converted into word embedding vectors. Then, these tokens are sequentially provided to the encoder and compressed into a single-vector representation. Unfortunately, this structure causes some loss of information in the process of compressing a sentence into a singlevector representation. To mitigate this problem, an attention mechanism that refers back to the entire sentence to be translated as input into the encoder at each point in time at which the decoder predicts the output word has been proposed [20]. More specifically, in the attention mechanism, an attention function is employed to allocate higher weights to the words input to the encoder that are strongly related to the given output word to be predicted at the decoder. However, if the encoder and decoder are configured based on the LSTM structure, the translation performance will still be limited for long sentences even if this attention mechanism is used. To overcome this problem, the transformer method, which uses only an attention structure without LSTM, has been proposed [8].\n\nGPT is a sentence generation method developed by OpenAI, a U.S. nonprofit artificial intelligence (AI) research institute, using the decoder structure from the transformer model [9]. Specifically, it is an autoregressive model using a masked self-attention structure in which the previous predicted output word is employed as the next input word during the sentence generation process because it has a good next-word prediction ability based on given input words [21]. Fig. 3 shows the details of the sentence generation process using the GPT network in an autoregressive manner. When the word '<s>', representing the start (or end) of a sentence, is provided to the GPT network, the probabilities\nP(\u00b7 '< s>')\nfor all words that can occur after (or before) '<s>' are estimated to guess the word that will appear next. To determine the next word, a top-k sampling technique is employed [10]. In top-k sampling, the probability mass function (PMF) is redistributed over the k most probable tokens, and the next word is sampled from those tokens in accordance with the redistributed PMF. For example, if the word 'A' is one of the top k tokens and is chosen in accordance with their redistributed PMF, it is provided to the GPT network. Then, the GPT network estimates the probabilities\nP(\u00b7 '< s> A')\nfor all words that can occur after (or before) '<s> A' to guess the next word. For example, if the word 'robot' is one of the top-k tokens and is chosen, it is, in turn, provided to the GPT network. This process is repeated until the word '<s>', indicating the end (or start) of the sentence, is selected. Fig. 4 shows the concrete structure of the GPT network for estimating the probability of a given sentence. It can be seen from this figure that the GPT network is composed of a stacked word and positional embedding layer, G transformer decoder blocks, a linear layer, and a softmax layer. In particular, each transformer decoder block is composed of a masked multihead self-attention layer, a layer normalization layer, a feedforward layer, and a second layer normalization layer. The specific operations performed by these components are explained as follows.\n\n\nA. WORD AND POSITIONAL EMBEDDING LAYER\n\nFirst, consider the case in which a sentence composed of L word tokens, expressed as\nx = [x 0 \u00b7 \u00b7 \u00b7 x (L\u22121) ] ,(1)\nis provided to the GPT network and assume that the total number of word tokens that can be generated is K . Under this assumption, x l is an integer that satisfies\n0 \u2264 x l \u2264 (K \u2212 1).\nBecause the GPT network predicts the next word corresponding to the input words [9], it will estimate the probability of a sentence of the form if x is provided. Note thatx is the same sentence with a delay of one word token relative to x.\nx = [x 1 \u00b7 \u00b7 \u00b7 x L ](2)\nIn this configuration, each word token x l is converted into an E-dimensional word embedding vector. Then, it becomes an E-dimensional vector y l after the addition of an Edimensional positional vector that depends on the position of the word in the sentence [8]. Specifically, for the positional encoding vector, the vector corresponding to the position of the given word token is selected from a vector set composed of L different vectors [9]. Consequently, the sentence x is converted into a matrix with dimensions of E \u00d7 L,\nY = y 0 \u00b7 \u00b7 \u00b7 y (L\u22121) .(3)\nThen, these L vectors are simultaneously provided to the masked multihead self-attention layer, which is composed of H heads.\n\n\nB. MASKED MULTIHEAD SELF-ATTENTION LAYER\n\nFor the h th head of the masked multihead self-attention layer, Y is transformed into a query matrix\nQ (h) = W (h) Q Y,\na key matrix VOLUME 9, 2021 and a value matrix\nK (h) = W (h) K Y,V (h) = W (h) V Y, where W (h) Q , W (h) Q , and W (h)\nQ are all E \u00d7 p matrices, with p being an integer that satisfies p \u00d7 H = E. Then, these matrices are used to construct an attention value matrix with dimensions of p \u00d7 L as follows:\nZ (h) = z (h) 0 \u00b7 \u00b7 \u00b7 z (h) (L\u22121) = V (h) \u00b7 softmax 1 \u221a p Q (h) K (h) + M ,(4)\nwhere M is a mask matrix with dimensions of L \u00d7 L. In (4), the (i, j) th element of M, m i,j , is defined as\nm i,j = 0 if j \u2264 i, \u2212\u221e if j > i.(5)\nIn addition, for the matrix input The H attention value matrices Z (h) (H \u22121) h=0 that were generated from the masked multihead self-attention layer are concatenated in a row to produce a matrix with dimensions of E \u00d7 L, which is then provided to the linear layer to produce a matrix with dimensions of E \u00d7 L as follows:\nA = 1 \u221a p Q (h) K (h) + M with dimensions of L \u00d7 L, softmax(\u00b7) is given as softmax (A) = \uf8ee \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8ef \uf8f0 exp(a 0,0 ) (L\u22121) l=0 exp(a l,0) \u00b7 \u00b7 \u00b7 exp(a 0,(L\u22121)) (L\u22121)T = W O \uf8ee \uf8ef \uf8f0 Z (0)\n. . .\nZ (H \u22121) \uf8f9 \uf8fa \uf8fb ,(6)\nwhere W O is a matrix with dimensions of E \u00d7 E that constitutes the linear layer.\n\n\nC. FEEDFORWARD LAYER\n\nThe matrix T is produced by adding the residual input Y [22] and applying layer normalization [23] as follows:\nT = layernorm (T + Y) ,(7)\nas shown in Fig. 4. This matrix is provided to the feedforward layer, which consists of a linear layer, an activation function, and a second linear layer, to produce a matrix with dimensions of E \u00d7 L as follows:\nT = W F 1 GELU W F 0 T ,(8)\nwhere W F 0 and W F 1 are matrices with dimensions of E \u00d7 4E and 4E \u00d7 E, respectively, and GELU(\u00b7) is the Gaussian error linear unit activation function [24]. The matrix T is then added to the residual input matrix T and subjected to layer normalization to produce a matrix with dimensions of E \u00d7 L, expressed as\nP (0) = layernorm(T + T ),(9)\nas the output of the first transformer decoder block.\n\n\nD. SENTENCE PROBABILITY ESTIMATION\n\nSince the GPT network has a stacked structure with G transformer decoder blocks, the above process is repeated G times, and a matrix with dimensions of E \u00d7 L, P (G\u22121) is finally produced, as shown in Fig. 4. The top linear layer takes the matrix P (G\u22121) as input and produces a matrix with dimensions of K \u00d7 L as follows:\nU = W D P (G\u22121) = [u 0 \u00b7 \u00b7 \u00b7 u (L\u22121) ],(10)\nwhere W D is a matrix with dimensions of E \u00d7 K that constitutes the top linear layer. Using the column vector u l = u 0,l \u00b7 \u00b7 \u00b7 u (K \u22121),l , the softmax layer produces\nsoftmax(u l ) = \uf8ee \uf8ef \uf8ef \uf8f0 exp ( u 0,l ) (K \u22121) k=0 exp ( u k,l ) \u00b7\u00b7\u00b7 exp ( u (K \u22121),l ) (K \u22121) k=0 exp ( u k,l ) \uf8f9 \uf8fa \uf8fa \uf8fb .(11)\nBecause i) the GPT network predicts the next word corresponding to the given input words as discussed in Section IV-A, and ii) u l is generated from the input word tokens\n{x l } l l =0\ndue to the introduction of the mask matrix M in (4), (11) can be regarded as a conditional probability estimate for the word token x (l+1) given the input word tokens up to point l, expressed asP\nx (l+1) {x l } l l =0 .\n124936 VOLUME 9, 2021 As a result, the estimated probability forx in (2) become\u015d\nP x = (L\u22121) l=0P x (l+1) = y (l+1) {x l } l l =0 ,\nwhere y (l+1) is the ground truth for x (l+1) [9].\n\n\nV. PROPOSED METHOD FOR INTRUSION DETECTION\n\nIn this section, the proposed CAN bus intrusion detection method based on a bi-directional GPT network is explained. Each ID in the input CAN ID sequence is converted into an integer and provided to the bi-directional GPT network to evaluate the negative log-likelihood (NLL) value for the sequence, and whether it is an attack is determined by comparing it against a prespecified threshold value.\n\n\nA. DESCRIPTION OF THE BI-DIRECTIONAL GPT NETWORK\n\nSuppose that the CAN ID sequence has a length of L and comprises (K \u2212 1) valid CAN IDs. In addition, suppose that for each CAN ID in the given CAN ID sequence, the CAN ID values are mapped to integers in ascending order from 0 to (K \u2212 2), and CAN IDs that do not exist among the normal CAN signals are converted into the integer (K \u2212 1). Consequently, the CAN ID sequence is expressed as\nx = x 0 \u00b7 \u00b7 \u00b7 x (L\u22121) ,(12)\nsatisfying 0 \u2264 x l \u2264 (K \u2212 1). Fig. 5 shows the bi-directional GPT network structure, which combines forward and backward GPT networks. Note that the forward and backward GPT networks are each composed of a stacked word and positional embedding layer and G transformer decoder blocks. The intrusion detection process for the given CAN ID sequence x using the bidirectional GPT network structure is explained as follows. The given CAN ID sequence x is converted into\nf = x 0 \u00b7 \u00b7 \u00b7 x (L\u22122) (13) and b = x (L\u22121) \u00b7 \u00b7 \u00b7 x 1 ,(14)\nwhich are then provided to the forward and backward GPT networks, respectively. The forward GPT network is provided with f and produces the following E \u00d7 (L \u2212 1) matrix:\nF = f 0 \u00b7 \u00b7 \u00b7f (L\u22122) ,(15)\nwheref l is the E-dimensional vector containing information related to P x (l+1) x 0 , \u00b7 \u00b7 \u00b7 , x l , as discussed in Section IV-D. Similarly, the backward GPT network uses b to produce the following E \u00d7 (L \u2212 1) matrix:\nB = b 0 \u00b7 \u00b7 \u00b7b (L\u22122) ,(16)\nwhereb l is the E-dimensional vector containing information related to P x (L\u2212l\u22122) x (L\u2212l\u22121) , \u00b7 \u00b7 \u00b7 , x (L\u22121) . As mentioned above, at early prediction points, the number of observed CAN IDs that can be used is small. To alleviate this problem, F and B are combined to produce a combined matrix with dimensions of 2E \u00d7 L as follows:\nC = 0 E F BG 0 E = [c 0 \u00b7 \u00b7 \u00b7 c (L\u22121) ],(17)\nwhere G is an exchange matrix to match the sequence of column vectors comprising B with the column vector sequence of F [25] and 0 E is an E-dimensional zero vector. The top linear layer takes C as input and produces a matrix with dimensions of K \u00d7 L as follows:\nU = W C = [u 0 \u00b7 \u00b7 \u00b7 u (L\u22121) ],(18)\nwhere W is a matrix with dimensions of 2E \u00d7 K that constitutes the top linear layer. Then, u l is passed to the softmax layer. Considering that the output matrices of the forward and backward GPT networks are combined, as shown in (17), the softmax layer output can be regarded as the conditional probability estimate of x l for all given CAN IDs in x except for itself, expressed a\u015d\nP x l {x l } (L\u22121) l =0,l = l .(19)\nFinally, the estimated probability for the CAN ID sequence x in (12) become\u015d\nP (x) = (L\u22121) l=0P x l = y l {x l } (L\u22121) l =0, l = l ,(20)\nwhere y l is the ground-truth value for x l . VOLUME 9, 2021 \n\n\nB. DETECTION METHOD\n\nSuppose that N normal CAN ID sequences have been collected for training. Using the collected training data, training is performed such that the output of the bi-directional GPT network should minimize the NLL loss function, defined as\nNLL = \u2212 1 NL N \u22121 n=0 L\u22121 l=0 logP x (n) l = y (n) l x (n) l (L\u22121) l =0, l = l , where x (n) l\nis the l th CAN ID in the n th normal CAN ID sequence used for training and y (m) l is the ground-truth value for x (n) l . After training is completed, to detect whether a given CAN ID sequence x shows evidence of attack behavior, x is provided as input to the bi-directional GPT network to evaluate\nNLL x = \u2212 1 L L\u22121 l=0 logP x l = y l {x l } (L\u22121) l =0, l = l . (21)\nFinally, an attack is identified if the value of NLL x is greater than a prespecified threshold , that is, if\nNLL x >(22)\nis satisfied.\n\n\nVI. EXPERIMENTAL SETUP AND RESULTS\n\nThis section describes the composition of the attacks used in the experiments and compares the performance of the proposed method with the performance of existing methods under these experimental conditions.\n\n\nA. EXPERIMENTAL SETTINGS AND PERFORMANCE METRICS\n\nIn this paper, we collected and used CAN bus signals from the 2020 Hyundai Avante CN7. A normal CAN bus signal comprises a total of 90 valid CAN IDs. For training purposes, the vehicle was driven around downtown for approximately 1.8 hours, and approximately 15, 900, 000 CAN ID sequences were collected unless otherwise stated. For evaluation purposes, attacks were conducted for approximately 0.34 hours, and approximately 3, 300, 000 CAN ID sequences were obtained. In the process of collecting evaluation data, flooding, spoofing, replay, and fuzzing attacks were conducted as attacks on the target vehicle. The detailed methods of conducting the attacks were as follows.\n\nIn the flooding attacks, approximately 154, 200 instances of CAN ID '0 \u00d7 000', the ID with the highest priority, were injected into the CAN bus. In the spoofing attacks, 2 valid CAN IDs were selected from the group of suitable CAN IDs, and approximately 7, 800 of them were injected. In the replay attacks, approximately 47, 600 normal CAN bus signals were recorded for a set period of time, and they were then reinjected. In the fuzzing attacks, CAN IDs were randomly generated, and approximately 89, 900 of them were injected. Table 1    was performed using only training data consisting of the aforementioned normal CAN bus signals. In this process, the minibatch size was set to 32, and training was performed for 10 epochs using the adaptive moment estimation (Adam) optimization algorithm [26]. If one or more attack CAN IDs were identified to exist within a CAN ID sequence with a length of L in the evaluation process, this sequence was considered an attack sequence.\n\nThe true positive rate (TPR) and false positive rate (FPR) were used as metrics to evaluate the performance. The TPR is the ratio of the number of CAN ID sequences correctly determined to be attacks (i.e., true positives) to the total number of attack CAN ID sequences, and the FPR is the ratio of the number of CAN ID sequences falsely determined to be attacks (i.e., false positives) to the total number of normal CAN ID sequences. Furthermore, based on these performance metrics, we used the receiver operating characteristic (ROC) curve to visually illustrate the performance of intrusion detection systems utilizing various threshold values. The ROC curve is constructed by plotting the FPR and TPR values corresponding to each threshold value on the horizontal and vertical axes, respectively, of a two-dimensional graph. To compare the ROC performance of different methods, the area under the curve (AUC) was used. The AUC value was calculated by normalizing the area underneath the given ROC curve, resulting in an AUC value of 1 for perfect performance. A typical performance detector may exhibit various AUC values ranging between 0 and 1. Therefore, we can deduce that the higher the AUC value of the detector under consideration is, the higher its performance. In addition, we used the F-measure, the harmonic mean of precision and recall (i.e., TPR), which is defined as\nF-measure = 2 1 Precision + 1 Recall ,\nwhere the precision is the ratio of the number of actual attack CAN ID sequences to the total number of CAN ID sequences identified as attacks. A higher F-measure value is considered to correspond to a higher detection capability. Fig. 6 illustrates the empirical cumulative density function (ECDF) of the injection intervals of attack CAN IDs. For example, in the case of flooding attacks, the injection interval was set to 3, which means that one out of every three CAN data frames transmitted through the CAN bus originated from a flooding attack. For flooding, fuzzing, and replay attacks, we can see that most injection intervals of attack CAN IDs are below 10 due to the nature of these attacks. Therefore, these attacks are expected to be readily noticeable, leading to reasonable detection performance, as there will be a sufficient number of attack IDs even if the length of the CAN ID sequence, L, is not large. In contrast, spoofing attacks are conducted by using only 2 valid CAN IDs, meaning that the injection interval of attack IDs is relatively large. Specifically, approximately 12% of the spoofing attacks had an injection interval of more than 100. Therefore, when L = 100, approximately 12% of spoofing attacks will produce only one attack ID within the corresponding CAN ID sequence. Fig. 7 shows the ECDF regarding the number of attack IDs within one CAN ID sequence for L = 256. We can see that for spoofing attacks, very few attack IDs indeed exist within one CAN ID sequence, with a minimum of 1 to a maximum of 11. Specifically, in approximately 5% of all spoofing CAN ID sequences, 2 or fewer spoofing attacks are present. In other words, too few spoofing attacks appear in a substantial number of spoofing CAN ID sequences, which is expected to cause the detection performance to deteriorate for this type of attack.\n\n\nB. STATISTICAL CHARACTERISTICS OF ATTACKS\n\n\nC. PERFORMANCE OF THE PROPOSED METHOD\n\nTo determine the most suitable length L of a CAN ID sequence, Fig. 8 shows the ROC performance of the proposed method for spoofing attacks as a function of L. As predicted in the previous subsection, when L = 64 or 128, the number of spoofing attacks within a single sequence is too small, meaning that the detection performance is low. On the other hand, when L = 256, the detection performance is enhanced because two or more spoofing attacks are present per sequence in most cases. Furthermore, the AUC performance when L = 256 is higher by approximately 6.9% and 1.5%, respectively, than the cases of L = 64 and L = 128. Therefore, unless otherwise noted, L = 256 for all subsequent results. Fig. 9 shows the ECDF of the NLL values for attacks with L = 256. In the cases of flooding, fuzzing, and replay attacks, the NLL value tends to be very large compared to its normal level because there are so many attack IDs within one CAN ID sequence. However, since spoofing attacks produce a relatively small number of attack IDs, the corresponding NLL value is lower.\n\n\nD. PERFORMANCE COMPARISONS\n\nIn this subsection, we compare the performance of the proposed method with that of existing intrusion detection methods. The first intrusion detection method considered for comparison is the bi-directional Markov method, in which second-order Markov-chain models are combined in a bidirectional manner [27]. In this method, the training data are used to estimate the second-order transition probability of a CAN ID sequence in the forward and backward directions, and this value can be used to calculate the log probability of the evaluated sequence to determine the attack status.\n\nTo investigate the performance gain due to the bidirectional structure of the proposed method, in the second considered method, a GPT network is applied only in the forward direction (that is, a uni-directional GPT network) [9]. Because this method uses only a one-way GPT network, the number of transformer decoder blocks in the unidirectional GPT network, G, is set to 12 to maintain a complexity similar to that of the proposed method.\n\nTo compare the performance achieved with a GPT model to that of an LSTM model, the third considered method is a bidirectional LSTM method using two LSTM networks instead of GPT networks as used in the proposed method. In this method, word embedding vectors of the same dimensionality (E = 128) as in the proposed method are passed to the forward and backward LSTM networks, and each LSTM network with layer normalization is composed of a stack  For comparison with the performance of other existing methods, the GAN-based method proposed in [3] and the LSTM-based prediction method proposed in [6] were selected as the fourth and fifth methods, respectively. To ensure fair comparisons, the GAN was trained using binary images converted from CAN ID sequences with a length of 256. In this method, a CAN ID sequence was identified as an attack sequence if the discriminator output was less than a prespecified threshold. The LSTM-based prediction method, as introduced in Section III, predicts the log probability of the next CAN ID for a given CAN ID sequence by means of an LSTM network. To ensure fair comparisons, a word embedding vector of the same dimensionality (E = 128) as in the proposed method was employed, and the LSTM network with layer normalization was composed of a stack of 12 LSTM cells with hidden state and cell state dimensions of 128. The LSTM network was used to predict the next CAN ID for an input CAN ID sequence with a length of 256. Accordingly, in this method, an attack was identified by comparing the sum of the log probabilities of 256 consecutive CAN IDs against a prespecified threshold [6]. Fig. 10 compares the ROC performance for spoofing attacks of the intrusion detection methods with L = 256.\n\nAs expected, the AUC performance of the proposed method is improved compared to the other methods. In particular, compared to the uni-directional GPT model, the proposed model combining GPT networks in both the forward and backward directions can achieve higher performance with the same degree of complexity. Additionally, the GAN-based method fails to detect spoofing attacks because the binary images converted from CAN ID sequences containing only a small number of spoofing attacks look very similar to those corresponding to normal CAN ID sequences. Table 2 compares the TPR performance of the different intrusion detection methods for spoofing attacks. The proposed method also shows an increase in the TPR compared to the other methods. For example, at an FPR of 0.5%, the TPR performance of the proposed method is improved by approximately 207.4% compared to that of the bi-directional Markov method. Table 3 summarizes the performance of the different intrusion detection methods in terms of the false negative rate (FNR) and the F-measure at an FPR of 0.5%. Here, the FNR is the ratio of the number of attacks falsely determined to be normal to the total number of actual attacks (i.e., 1\u2212TPR), and a lower FNR value corresponds to better performance. We can see that both the FNR and F-measure of the proposed method are universally improved compared to those of the other methods regardless of the attack type.  In particular, the performance improvement for spoofing attacks is significant. This means that the proposed method can detect slight changes in the pattern of a CAN ID sequence containing only a small number of attacks. The reason is explained as follows. Fig. 11 shows the mean NLL values for the CAN IDs in a normal CAN ID sequence with L = 256. Note that the mean NLL values should be lower for normal CAN ID sequences. This figure indicates that the mean NLL performance of the uni-directional GPT method tends to be degraded at earlier positions in a sequence because the NLLs of CAN IDs at earlier positions are estimated using fewer CAN IDs. On the other hand, in the proposed method, the NLL performance is maintained for all CAN IDs regardless of their positions. The  reason is that the NLL of a given CAN ID is estimated using both past and future CAN IDs. However, the performance for early and late positions is still slightly degraded because the first and last positions in the combined matrix in (17) are padded with zero values. Additionally, the bi-directional LSTM method shows a performance trend similar to that of the proposed method because it also employs a network structure combining two networks in a bi-directional manner. However, its overall performance is slightly lower. This implies that GPT itself is superior to LSTM for the prediction task. Consequently, the ability to achieve stable CAN ID estimation improves the overall detection performance.\n\nTo obtain all of the results discussed above, we evaluated the performance after training on 1.8 hours of recorded normal CAN ID sequences. To investigate the effect of the training data size on the performance, Fig. 12 shows the F-measure performance for spoofing attacks achieved with training data corresponding to different recording time lengths for an FPR of 0.5% and L = 256. From this figure, we see that the performance of the proposed method improves as the recording time length increases. Additionally, the proposed method leads to universally better performance regardless of the recording time. This demonstrates that the proposed method is still more efficient than the other methods when a large volume of recorded data is available for training.\n\n\nVII. CONCLUSION\n\nThis paper has proposed a bi-directional GPT-based method for intrusion detection based on CAN ID sequences. This method can serve to identify an attack against the CAN bus protocol, which lacks security. Because the existing intrusion detection methods underperform in detecting a CAN ID sequence that contains very few attacks, this paper has suggested a model comprising two GPT networks connected bi-directionally. The proposed method computes the NLL value for a CAN ID sequence and compares it against a prespecified threshold to identify any attack. In experiments, the proposed bi-directional GPT network proved to achieve superior performance compared with a uni-directional GPT network of the same complexity. The reason for this performance improvement is that the bidirectional structure of the proposed method allows the prediction performance for each CAN ID to be maintained regardless of its position in the CAN ID sequence.\n\nIn this paper, we considered only the case in which malicious CAN packets are injected into the CAN bus. Thus, the proposed method was designed to detect the change in the CAN ID sequence due to this injection. However, when an intended ECU is reprogrammed by an attacker, the message in a CAN data frame can be maliciously manipulated and sent without affecting the normal pattern of the CAN ID sequence. Therefore, in future work, it will be necessary to extend the proposed method to detect abnormal patterns in the messages.\n\nFIGURE 1 .\n1Structure of a data frame in the CAN bus protocol.\n\nFIGURE 2 .\n2Illustration of automotive devices attacked via a CAN bus.\n\nFIGURE 3 .\n3Example of generating a sentence using a GPT network.\n\nFIGURE 4 .\n4Block diagram of the GPT network.\n\n\na i,j is the (i, j) th element of A. Due to the mask matrix M, the attention value vector at point l, z (h) l (that is, the l th column vector in the attention value matrix in (4)), can use only the attention for the input word tokens {x l } l l =0 up to the corresponding point and cannot use the attention for the future input word tokens {x l } (L\u22121) l =(l+1) .\n\nFIGURE 5 .\n5Block diagram of the bi-directional GPT network.\n\nFIGURE 6 .\n6ECDF for the injection interval of attack CAN IDs.\n\n\nsummarizes the composition of the training and evaluation data. Unless otherwise noted, the following settings were applied in the proposed method: CAN ID sequence length, L = 256; dimensionality of word and positional embedding vectors, E = 128; number of attention heads in the forward and backward GPT networks, H = 8; number of transformer decoder blocks in the forward and backward GPT networks, G = 6; and dropout probability in each layer, 0.1. Training\n\nFIGURE 7 .\n7ECDF for the number of attack IDs in a CAN ID sequence.\n\nFIGURE 8 .\n8ROC performance of the proposed method against spoofing attacks.\n\nFIGURE 9 .\n9ECDF of the NLL values for attacks when using the proposed method.\n\nFIGURE 10 .\n10Comparison of different attack detection methods in terms of the ROC performance against spoofing attacks.\n\nFIGURE 11 .\n11Mean NLLs of the CAN IDs in a normal CAN ID sequence.\n\nTABLE 3 .\n3Performance comparison for various attacks.\n\nFIGURE 12 .\n12F-measure performance against spoofing attacks as a function of the recording time length of the training data.\n\nTABLE 1 .\n1Summary of the training and evaluation data for the experiments.\n\nTABLE 2 .\n2TPR performance comparison for spoofing attacks.6 LSTM cells with hidden state and cell state dimensions of 128.\nVOLUME 9, 2021   \n\nResearch on the controller area network. H Chen, J Tian, Proc. Int. Conf. Netw. Digit. Soc. Int. Conf. Netw. Digit. SocH. Chen and J. Tian, ''Research on the controller area network,'' in Proc. Int. Conf. Netw. Digit. Soc., May 2009, pp. 251-254.\n\nAnomaly detection of CAN bus messages through analysis of ID sequences. M Marchetti, D Stabili, Proc. IEEE Intell. Vehicles Symp. (IV). IEEE Intell. Vehicles Symp. (IV)M. Marchetti and D. Stabili, ''Anomaly detection of CAN bus messages through analysis of ID sequences,'' in Proc. IEEE Intell. Vehicles Symp. (IV), Jun. 2017, pp. 1577-1583.\n\nGIDS: GAN based intrusion detection system for in-vehicle network. E Seo, H M Song, H K Kim, Proc. 16th Annu. Conf. Privacy, Secur. Trust (PST). 16th Annu. Conf. Privacy, Secur. Trust (PST)E. Seo, H. M. Song, and H. K. Kim, ''GIDS: GAN based intrusion detection system for in-vehicle network,'' in Proc. 16th Annu. Conf. Privacy, Secur. Trust (PST), Aug. 2018, pp. 1-6.\n\nIn-vehicle network intrusion detection using deep convolutional neural network. H M Song, J Woo, H K Kim, Veh. Commun. 1H. M. Song, J. Woo, and H. K. Kim, ''In-vehicle network intrusion detection using deep convolutional neural network,'' Veh. Commun., no. 1, pp. 1-13, Jan. 2020.\n\nAn entropy analysis based intrusion detection system for controller area network in vehicles. Q Wang, Z Lu, G Qu, Proc. 31st IEEE Int. Syst. Chip Conf. (SOCC). 31st IEEE Int. Syst. Chip Conf. (SOCC)Q. Wang, Z. Lu, and G. Qu, ''An entropy analysis based intrusion detection system for controller area network in vehicles,'' in Proc. 31st IEEE Int. Syst. Chip Conf. (SOCC), Sep. 2018, pp. 90-95.\n\nID sequence analysis for intrusion detection in the CAN bus using long short term memory networks. A K Desta, S Ohira, I Arai, K Fujikawa, Proc. IEEE Int. Conf. Pervas. Comput. Commun. Workshops (PerCom Workshops). IEEE Int. Conf. Pervas. Comput. Commun. Workshops (PerCom Workshops)A. K. Desta, S. Ohira, I. Arai, and K. Fujikawa, ''ID sequence analysis for intrusion detection in the CAN bus using long short term memory networks,'' in Proc. IEEE Int. Conf. Pervas. Comput. Commun. Workshops (PerCom Workshops), Mar. 2020, pp. 1-6.\n\nComparative study of CNN and RNN for natural language processing. W Yin, K Kann, M Yu, H Sch\u00fctze, arXiv:1702.01923W. Yin, K. Kann, M. Yu, and H. Sch\u00fctze, ''Comparative study of CNN and RNN for natural language processing,'' 2017, arXiv:1702.01923. [Online]. Available: http://arxiv.org/abs/1702.01923\n\nAttention is all you need. A Vaswani, N Shazeer, N Parmar, J Uszkoreit, L Jones, A N Gomez, L L Kaiser, I Polosukhin, Proc. Int. Conf. Neural Inf. Process. Syst. Int. Conf. Neural Inf. ess. SystLong Beach, CA, USAA. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. L. Kaiser, and I. Polosukhin, ''Attention is all you need,'' in Proc. Int. Conf. Neural Inf. Process. Syst., Long Beach, CA, USA, Dec. 2017, pp. 6000-6010.\n\nImproving Language Understanding by Generative Pre-Training. A Radford, K Narasimhan, T Salimans, I Sutskever, A. Radford, K. Narasimhan, T. Salimans, and I. Sutskever. (2018). Improving Language Understanding by Generative Pre- Training. [Online]. Available: https://cdn.openai.com/research-covers/ language-unsupervised/language_understanding_paper.pdf\n\nLanguage models are unsupervised multitask learners. A Radford, J Wu, R Child, D Luan, D Amodei, I Sutskever, A. Radford, J. Wu, R. Child, D. Luan, D. Amodei, and I. Sutskever. Language models are unsupervised multitask learners. 2019. [Online].\n\nIntroducing aspects of creativity in automatic poetry generation. B Bena, J Kalita, arXiv:2002.025112020B. Bena and J. Kalita, ''Introducing aspects of creativity in auto- matic poetry generation,'' 2020, arXiv:2002.02511. [Online]. Available: http://arxiv.org/abs/2002.02511\n\nA survey of the usages of deep learning for natural language processing. D W Otter, J R Medina, J K Kalita, IEEE Trans. Neural Netw. Learn. Syst. 322D. W. Otter, J. R. Medina, and J. K. Kalita, ''A survey of the usages of deep learning for natural language processing,'' IEEE Trans. Neural Netw. Learn. Syst., vol. 32, no. 2, pp. 604-624, Feb. 2021.\n\nBidirectional recurrent neural netowrks. M Schuster, K K Paliwal, IEEE Trans. Signal Process. 4511M. Schuster and K. K. Paliwal, ''Bidirectional recurrent neural netowrks,'' IEEE Trans. Signal Process., vol. 45, no. 11, pp. 2673-2681, Nov. 1997.\n\nCyber-security for the controller area network (CAN) communication protocol. C.-W Lin, A Sangiovanni-Vincentelli, Proc. Int. Conf. Cyber Secur. Int. Conf. Cyber SecurC.-W. Lin and A. Sangiovanni-Vincentelli, ''Cyber-security for the controller area network (CAN) communication protocol,'' in Proc. Int. Conf. Cyber Secur., Dec. 2012, pp. 1-7.\n\nA practical wireless attack on the connected car and security protocol for in-vehicle CAN. S Woo, H Jin Jo, D. Hoon Lee, IEEE Trans. Intell. Transp. Syst. 162S. Woo, H. Jin Jo, and D. Hoon Lee, ''A practical wireless attack on the connected car and security protocol for in-vehicle CAN,'' IEEE Trans. Intell. Transp. Syst., vol. 16, no. 2, pp. 993-1006, Apr. 2015.\n\nSecurity solutions for the controller area network: Bringing authentication to in-vehicle networks. B Groza, P.-S Murvay, IEEE Veh. Technol. Mag. 131B. Groza and P.-S. Murvay, ''Security solutions for the controller area network: Bringing authentication to in-vehicle networks,'' IEEE Veh. Technol. Mag., vol. 13, no. 1, pp. 40-47, Mar. 2018.\n\nGenerative adversarial nets,'' in Proc. I Goodfellow, J Pouget-Abadie, M Mirza, B Xu, D Warde-Farley, S Ozair, A Courville, Y Bengio, Adv. Neural Inf. Process. Syst. I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio, ''Generative adversarial nets,'' in Proc. Adv. Neural Inf. Process. Syst., 2014, pp. 2672-2680.\n\nCANnolo: An anomaly detection system based on LSTM autoencoders for controller area network. S Longari, D H Valcarcel, M Zago, M Carminati, S Zanero, IEEE Trans. Netw. Service Manage. 182S. Longari, D. H. Nova Valcarcel, M. Zago, M. Carminati, and S. Zanero, ''CANnolo: An anomaly detection system based on LSTM autoencoders for controller area network,'' IEEE Trans. Netw. Service Manage., vol. 18, no. 2, pp. 1913-1924, Jun. 2021.\n\nCASAD: CAN-aware stealthy-attack detection for in-vehicle networks. N Nowdehi, W Aoudi, M Almgren, T Olovsson, arXiv:1909.08407N. Nowdehi, W. Aoudi, M. Almgren, and T. Olovsson, ''CASAD: CAN-aware stealthy-attack detection for in-vehicle networks,'' 2019, arXiv:1909.08407. [Online]. Available: http://arxiv.org/abs/1909.08407\n\nNeural machine translation by jointly learning to align and translate. D Bahdanau, K Cho, Y Bengio, arXiv:1409.0473D. Bahdanau, K. Cho, and Y. Bengio, ''Neural machine translation by jointly learning to align and translate,'' 2014, arXiv:1409.0473. [Online]. Available: http://arxiv.org/abs/1409.0473\n\nXLNet: Generalized autoregressive pretraining for language understanding. Z Yang, Z Dai, Y Yang, J Carbonell, R Salakhutdinov, Q V Le, arXiv:1906.08237Z. Yang, Z. Dai, Y. Yang, J. Carbonell, R. Salakhutdinov, and Q. V. Le, ''XLNet: Generalized autoregressive pretraining for language under- standing,'' 2019, arXiv:1906.08237. [Online]. Available: http://arxiv. org/abs/1906.08237\n\nIdentity mappings in deep residual networks. K He, X Zhang, S Ren, J Sun, arXiv:1603.05027K. He, X. Zhang, S. Ren, and J. Sun, ''Identity mappings in deep residual networks,'' 2016, arXiv:1603.05027. [Online]. Available: http://arxiv.org/abs/1603.05027\n\nLayer normalization. J Ba, J R Kiros, G E Hinton, arXiv:1607.06450J. Lei Ba, J. R. Kiros, and G. E. Hinton, ''Layer normalization,'' 2016, arXiv:1607.06450. [Online]. Available: http://arxiv.org/abs/1607.06450\n\nGaussian error linear units (GELUs). D Hendrycks, K Gimpel, arXiv:1606.08415D. Hendrycks and K. Gimpel, ''Gaussian error linear units (GELUs),'' 2016, arXiv:1606.08415. [Online]. Available: http://arxiv.org/abs/ 1606.08415\n\nR A Horn, C R Johnson, Matrix Analysis. Cambridge, U.K.Cambridge Univ. Press2nd ed.R. A. Horn and C. R. Johnson, Matrix Analysis, 2nd ed. Cambridge, U.K.: Cambridge Univ. Press, 2012.\n\nAdam: A method for stochastic optimization. D P Kingma, J Ba, arXiv:1412.6980D. P. Kingma and J. Ba, ''Adam: A method for stochastic optimiza- tion,'' 2014, arXiv:1412.6980. [Online]. Available: http://arxiv.org/abs/ 1412.6980\n\nRobustness of the Markovchain model for cyber-attack detection. N Ye, Y Zhang, C M Borror, IEEE Trans. Rel. 5N. Ye, Y. Zhang, and C. M. Borror, ''Robustness of the Markov- chain model for cyber-attack detection,'' IEEE Trans. Rel., no. 5, no. 1, pp. 116-123, Mar. 2004.\n\n2021, where he is currently pursuing the M.S. degree with the Interdisciplinary Graduate Program in BIT Medical Convergence. His research interests include deep learning and natural language processing. Chuncheon, Republic of KoreaMINKI NAM received the B.S. degree in electrical and electronics engineering from Kangwon National UniversityMINKI NAM received the B.S. degree in elec- trical and electronics engineering from Kang- won National University, Chuncheon, Republic of Korea, in 2021, where he is currently pur- suing the M.S. degree with the Interdisciplinary Graduate Program in BIT Medical Convergence. His research interests include deep learning and natural language processing.\n", "annotations": {"author": "[{\"end\":225,\"start\":95},{\"end\":383,\"start\":226},{\"end\":466,\"start\":384}]", "publisher": null, "author_last_name": "[{\"end\":104,\"start\":99},{\"end\":241,\"start\":237},{\"end\":414,\"start\":411}]", "author_first_name": "[{\"end\":98,\"start\":95},{\"end\":236,\"start\":226},{\"end\":406,\"start\":403},{\"end\":410,\"start\":407}]", "author_affiliation": "[{\"end\":224,\"start\":106},{\"end\":382,\"start\":270},{\"end\":465,\"start\":416}]", "title": "[{\"end\":92,\"start\":1},{\"end\":558,\"start\":467}]", "venue": null, "abstract": "[{\"end\":2885,\"start\":758}]", "bib_ref": "[{\"attributes\":{\"ref_id\":\"b0\"},\"end\":3169,\"start\":3166},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":3336,\"start\":3333},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":3341,\"start\":3338},{\"attributes\":{\"ref_id\":\"b6\"},\"end\":4053,\"start\":4050},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":4244,\"start\":4241},{\"end\":4268,\"start\":4254},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":4907,\"start\":4904},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":4913,\"start\":4909},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":5646,\"start\":5642},{\"attributes\":{\"ref_id\":\"b11\"},\"end\":5655,\"start\":5651},{\"attributes\":{\"ref_id\":\"b12\"},\"end\":6885,\"start\":6881},{\"attributes\":{\"ref_id\":\"b0\"},\"end\":8715,\"start\":8712},{\"attributes\":{\"ref_id\":\"b13\"},\"end\":10588,\"start\":10584},{\"attributes\":{\"ref_id\":\"b14\"},\"end\":10952,\"start\":10948},{\"attributes\":{\"ref_id\":\"b15\"},\"end\":11651,\"start\":11647},{\"attributes\":{\"ref_id\":\"b1\"},\"end\":11927,\"start\":11924},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":12551,\"start\":12548},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":12775,\"start\":12771},{\"attributes\":{\"ref_id\":\"b3\"},\"end\":13211,\"start\":13208},{\"attributes\":{\"ref_id\":\"b4\"},\"end\":13227,\"start\":13224},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":13655,\"start\":13652},{\"attributes\":{\"ref_id\":\"b17\"},\"end\":14174,\"start\":14170},{\"attributes\":{\"ref_id\":\"b18\"},\"end\":14755,\"start\":14751},{\"attributes\":{\"ref_id\":\"b19\"},\"end\":16229,\"start\":16225},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":16771,\"start\":16768},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":16955,\"start\":16952},{\"attributes\":{\"ref_id\":\"b20\"},\"end\":17241,\"start\":17237},{\"attributes\":{\"ref_id\":\"b9\"},\"end\":17663,\"start\":17659},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":19362,\"start\":19359},{\"attributes\":{\"ref_id\":\"b7\"},\"end\":19805,\"start\":19802},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":19987,\"start\":19984},{\"end\":20415,\"start\":20401},{\"attributes\":{\"ref_id\":\"b21\"},\"end\":21613,\"start\":21609},{\"attributes\":{\"ref_id\":\"b22\"},\"end\":21651,\"start\":21647},{\"attributes\":{\"ref_id\":\"b23\"},\"end\":22088,\"start\":22084},{\"attributes\":{\"ref_id\":\"b10\"},\"end\":23267,\"start\":23263},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":23611,\"start\":23608},{\"attributes\":{\"ref_id\":\"b24\"},\"end\":25995,\"start\":25991},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":26405,\"start\":26401},{\"attributes\":{\"ref_id\":\"b25\"},\"end\":29422,\"start\":29418},{\"attributes\":{\"ref_id\":\"b26\"},\"end\":34356,\"start\":34352},{\"attributes\":{\"ref_id\":\"b8\"},\"end\":34860,\"start\":34857},{\"attributes\":{\"ref_id\":\"b2\"},\"end\":35617,\"start\":35614},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":35670,\"start\":35667},{\"attributes\":{\"ref_id\":\"b5\"},\"end\":36697,\"start\":36694},{\"attributes\":{\"ref_id\":\"b16\"},\"end\":39249,\"start\":39245}]", "figure": "[{\"attributes\":{\"id\":\"fig_0\"},\"end\":42033,\"start\":41970},{\"attributes\":{\"id\":\"fig_1\"},\"end\":42105,\"start\":42034},{\"attributes\":{\"id\":\"fig_2\"},\"end\":42172,\"start\":42106},{\"attributes\":{\"id\":\"fig_3\"},\"end\":42219,\"start\":42173},{\"attributes\":{\"id\":\"fig_4\"},\"end\":42586,\"start\":42220},{\"attributes\":{\"id\":\"fig_5\"},\"end\":42648,\"start\":42587},{\"attributes\":{\"id\":\"fig_6\"},\"end\":42712,\"start\":42649},{\"attributes\":{\"id\":\"fig_7\"},\"end\":43175,\"start\":42713},{\"attributes\":{\"id\":\"fig_8\"},\"end\":43244,\"start\":43176},{\"attributes\":{\"id\":\"fig_9\"},\"end\":43322,\"start\":43245},{\"attributes\":{\"id\":\"fig_10\"},\"end\":43402,\"start\":43323},{\"attributes\":{\"id\":\"fig_11\"},\"end\":43524,\"start\":43403},{\"attributes\":{\"id\":\"fig_12\"},\"end\":43593,\"start\":43525},{\"attributes\":{\"id\":\"fig_13\"},\"end\":43649,\"start\":43594},{\"attributes\":{\"id\":\"fig_14\"},\"end\":43776,\"start\":43650},{\"attributes\":{\"id\":\"tab_0\",\"type\":\"table\"},\"end\":43853,\"start\":43777},{\"attributes\":{\"id\":\"tab_1\",\"type\":\"table\"},\"end\":43978,\"start\":43854}]", "paragraph": "[{\"end\":3909,\"start\":2904},{\"end\":4736,\"start\":3911},{\"end\":5903,\"start\":4738},{\"end\":6886,\"start\":5905},{\"end\":8382,\"start\":6888},{\"end\":9528,\"start\":8419},{\"end\":10408,\"start\":9530},{\"end\":11773,\"start\":10410},{\"end\":12313,\"start\":11795},{\"end\":13212,\"start\":12315},{\"end\":13640,\"start\":13214},{\"end\":14041,\"start\":13642},{\"end\":14739,\"start\":14043},{\"end\":15484,\"start\":14741},{\"end\":16772,\"start\":15519},{\"end\":17471,\"start\":16774},{\"end\":18057,\"start\":17484},{\"end\":18938,\"start\":18072},{\"end\":19065,\"start\":18981},{\"end\":19259,\"start\":19096},{\"end\":19518,\"start\":19279},{\"end\":20070,\"start\":19543},{\"end\":20223,\"start\":20098},{\"end\":20368,\"start\":20268},{\"end\":20434,\"start\":20388},{\"end\":20689,\"start\":20508},{\"end\":20877,\"start\":20769},{\"end\":21234,\"start\":20914},{\"end\":21426,\"start\":21421},{\"end\":21528,\"start\":21447},{\"end\":21663,\"start\":21553},{\"end\":21902,\"start\":21691},{\"end\":22243,\"start\":21931},{\"end\":22327,\"start\":22274},{\"end\":22687,\"start\":22366},{\"end\":22899,\"start\":22732},{\"end\":23195,\"start\":23025},{\"end\":23405,\"start\":23210},{\"end\":23510,\"start\":23430},{\"end\":23612,\"start\":23562},{\"end\":24056,\"start\":23659},{\"end\":24496,\"start\":24109},{\"end\":24989,\"start\":24525},{\"end\":25218,\"start\":25049},{\"end\":25464,\"start\":25246},{\"end\":25825,\"start\":25492},{\"end\":26133,\"start\":25871},{\"end\":26553,\"start\":26170},{\"end\":26666,\"start\":26590},{\"end\":26788,\"start\":26727},{\"end\":27046,\"start\":26812},{\"end\":27442,\"start\":27142},{\"end\":27621,\"start\":27512},{\"end\":27647,\"start\":27634},{\"end\":27893,\"start\":27686},{\"end\":28621,\"start\":27946},{\"end\":29598,\"start\":28623},{\"end\":30983,\"start\":29600},{\"end\":32867,\"start\":31023},{\"end\":34019,\"start\":32953},{\"end\":34631,\"start\":34050},{\"end\":35071,\"start\":34633},{\"end\":36805,\"start\":35073},{\"end\":39715,\"start\":36807},{\"end\":40479,\"start\":39717},{\"end\":41439,\"start\":40499},{\"end\":41969,\"start\":41441}]", "formula": "[{\"attributes\":{\"id\":\"formula_0\"},\"end\":17483,\"start\":17472},{\"attributes\":{\"id\":\"formula_1\"},\"end\":18071,\"start\":18058},{\"attributes\":{\"id\":\"formula_2\"},\"end\":19095,\"start\":19066},{\"attributes\":{\"id\":\"formula_3\"},\"end\":19278,\"start\":19260},{\"attributes\":{\"id\":\"formula_4\"},\"end\":19542,\"start\":19519},{\"attributes\":{\"id\":\"formula_5\"},\"end\":20097,\"start\":20071},{\"attributes\":{\"id\":\"formula_6\"},\"end\":20387,\"start\":20369},{\"attributes\":{\"id\":\"formula_7\"},\"end\":20453,\"start\":20435},{\"attributes\":{\"id\":\"formula_8\"},\"end\":20507,\"start\":20453},{\"attributes\":{\"id\":\"formula_9\"},\"end\":20768,\"start\":20690},{\"attributes\":{\"id\":\"formula_10\"},\"end\":20913,\"start\":20878},{\"attributes\":{\"id\":\"formula_11\"},\"end\":21401,\"start\":21235},{\"attributes\":{\"id\":\"formula_12\"},\"end\":21420,\"start\":21401},{\"attributes\":{\"id\":\"formula_13\"},\"end\":21446,\"start\":21427},{\"attributes\":{\"id\":\"formula_14\"},\"end\":21690,\"start\":21664},{\"attributes\":{\"id\":\"formula_15\"},\"end\":21930,\"start\":21903},{\"attributes\":{\"id\":\"formula_16\"},\"end\":22273,\"start\":22244},{\"attributes\":{\"id\":\"formula_17\"},\"end\":22731,\"start\":22688},{\"attributes\":{\"id\":\"formula_18\"},\"end\":23024,\"start\":22900},{\"attributes\":{\"id\":\"formula_19\"},\"end\":23209,\"start\":23196},{\"attributes\":{\"id\":\"formula_20\"},\"end\":23429,\"start\":23406},{\"attributes\":{\"id\":\"formula_21\"},\"end\":23561,\"start\":23511},{\"attributes\":{\"id\":\"formula_22\"},\"end\":24524,\"start\":24497},{\"attributes\":{\"id\":\"formula_23\"},\"end\":25048,\"start\":24990},{\"attributes\":{\"id\":\"formula_24\"},\"end\":25245,\"start\":25219},{\"attributes\":{\"id\":\"formula_25\"},\"end\":25491,\"start\":25465},{\"attributes\":{\"id\":\"formula_26\"},\"end\":25870,\"start\":25826},{\"attributes\":{\"id\":\"formula_27\"},\"end\":26169,\"start\":26134},{\"attributes\":{\"id\":\"formula_28\"},\"end\":26589,\"start\":26554},{\"attributes\":{\"id\":\"formula_29\"},\"end\":26726,\"start\":26667},{\"attributes\":{\"id\":\"formula_30\"},\"end\":27141,\"start\":27047},{\"attributes\":{\"id\":\"formula_31\"},\"end\":27511,\"start\":27443},{\"attributes\":{\"id\":\"formula_32\"},\"end\":27633,\"start\":27622},{\"attributes\":{\"id\":\"formula_33\"},\"end\":31022,\"start\":30984}]", "table_ref": "[{\"attributes\":{\"ref_id\":\"tab_0\"},\"end\":29159,\"start\":29152},{\"attributes\":{\"ref_id\":\"tab_1\"},\"end\":37370,\"start\":37363},{\"end\":37724,\"start\":37717}]", "section_header": "[{\"end\":2902,\"start\":2887},{\"end\":8417,\"start\":8385},{\"end\":11793,\"start\":11776},{\"end\":15517,\"start\":15487},{\"end\":18979,\"start\":18941},{\"end\":20266,\"start\":20226},{\"end\":21551,\"start\":21531},{\"end\":22364,\"start\":22330},{\"end\":23657,\"start\":23615},{\"end\":24107,\"start\":24059},{\"end\":26810,\"start\":26791},{\"end\":27684,\"start\":27650},{\"end\":27944,\"start\":27896},{\"end\":32911,\"start\":32870},{\"end\":32951,\"start\":32914},{\"end\":34048,\"start\":34022},{\"end\":40497,\"start\":40482},{\"end\":41981,\"start\":41971},{\"end\":42045,\"start\":42035},{\"end\":42117,\"start\":42107},{\"end\":42184,\"start\":42174},{\"end\":42598,\"start\":42588},{\"end\":42660,\"start\":42650},{\"end\":43187,\"start\":43177},{\"end\":43256,\"start\":43246},{\"end\":43334,\"start\":43324},{\"end\":43415,\"start\":43404},{\"end\":43537,\"start\":43526},{\"end\":43604,\"start\":43595},{\"end\":43662,\"start\":43651},{\"end\":43787,\"start\":43778},{\"end\":43864,\"start\":43855}]", "table": null, "figure_caption": "[{\"end\":42033,\"start\":41983},{\"end\":42105,\"start\":42047},{\"end\":42172,\"start\":42119},{\"end\":42219,\"start\":42186},{\"end\":42586,\"start\":42222},{\"end\":42648,\"start\":42600},{\"end\":42712,\"start\":42662},{\"end\":43175,\"start\":42715},{\"end\":43244,\"start\":43189},{\"end\":43322,\"start\":43258},{\"end\":43402,\"start\":43336},{\"end\":43524,\"start\":43418},{\"end\":43593,\"start\":43540},{\"end\":43649,\"start\":43606},{\"end\":43776,\"start\":43665},{\"end\":43853,\"start\":43789},{\"end\":43978,\"start\":43866}]", "figure_ref": "[{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":9067,\"start\":9061},{\"attributes\":{\"ref_id\":\"fig_1\"},\"end\":10975,\"start\":10969},{\"attributes\":{\"ref_id\":\"fig_2\"},\"end\":17249,\"start\":17243},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":18384,\"start\":18378},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":21709,\"start\":21703},{\"attributes\":{\"ref_id\":\"fig_3\"},\"end\":22572,\"start\":22566},{\"attributes\":{\"ref_id\":\"fig_5\"},\"end\":24561,\"start\":24555},{\"attributes\":{\"ref_id\":\"fig_6\"},\"end\":31260,\"start\":31254},{\"attributes\":{\"ref_id\":\"fig_8\"},\"end\":32334,\"start\":32328},{\"attributes\":{\"ref_id\":\"fig_9\"},\"end\":33021,\"start\":33015},{\"attributes\":{\"ref_id\":\"fig_10\"},\"end\":33655,\"start\":33649},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":36706,\"start\":36699},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":38496,\"start\":38489},{\"attributes\":{\"ref_id\":\"fig_0\"},\"end\":39936,\"start\":39929}]", "bib_author_first_name": "[{\"end\":44040,\"start\":44039},{\"end\":44048,\"start\":44047},{\"end\":44319,\"start\":44318},{\"end\":44332,\"start\":44331},{\"end\":44657,\"start\":44656},{\"end\":44664,\"start\":44663},{\"end\":44666,\"start\":44665},{\"end\":44674,\"start\":44673},{\"end\":44676,\"start\":44675},{\"end\":45041,\"start\":45040},{\"end\":45043,\"start\":45042},{\"end\":45051,\"start\":45050},{\"end\":45058,\"start\":45057},{\"end\":45060,\"start\":45059},{\"end\":45337,\"start\":45336},{\"end\":45345,\"start\":45344},{\"end\":45351,\"start\":45350},{\"end\":45737,\"start\":45736},{\"end\":45739,\"start\":45738},{\"end\":45748,\"start\":45747},{\"end\":45757,\"start\":45756},{\"end\":45765,\"start\":45764},{\"end\":46239,\"start\":46238},{\"end\":46246,\"start\":46245},{\"end\":46254,\"start\":46253},{\"end\":46260,\"start\":46259},{\"end\":46502,\"start\":46501},{\"end\":46513,\"start\":46512},{\"end\":46524,\"start\":46523},{\"end\":46534,\"start\":46533},{\"end\":46547,\"start\":46546},{\"end\":46556,\"start\":46555},{\"end\":46558,\"start\":46557},{\"end\":46567,\"start\":46566},{\"end\":46569,\"start\":46568},{\"end\":46579,\"start\":46578},{\"end\":46981,\"start\":46980},{\"end\":46992,\"start\":46991},{\"end\":47006,\"start\":47005},{\"end\":47018,\"start\":47017},{\"end\":47329,\"start\":47328},{\"end\":47340,\"start\":47339},{\"end\":47346,\"start\":47345},{\"end\":47355,\"start\":47354},{\"end\":47363,\"start\":47362},{\"end\":47373,\"start\":47372},{\"end\":47589,\"start\":47588},{\"end\":47597,\"start\":47596},{\"end\":47873,\"start\":47872},{\"end\":47875,\"start\":47874},{\"end\":47884,\"start\":47883},{\"end\":47886,\"start\":47885},{\"end\":47896,\"start\":47895},{\"end\":47898,\"start\":47897},{\"end\":48192,\"start\":48191},{\"end\":48204,\"start\":48203},{\"end\":48206,\"start\":48205},{\"end\":48478,\"start\":48474},{\"end\":48485,\"start\":48484},{\"end\":48833,\"start\":48832},{\"end\":48840,\"start\":48839},{\"end\":48844,\"start\":48841},{\"end\":48856,\"start\":48849},{\"end\":49208,\"start\":49207},{\"end\":49220,\"start\":49216},{\"end\":49492,\"start\":49491},{\"end\":49506,\"start\":49505},{\"end\":49523,\"start\":49522},{\"end\":49532,\"start\":49531},{\"end\":49538,\"start\":49537},{\"end\":49554,\"start\":49553},{\"end\":49563,\"start\":49562},{\"end\":49576,\"start\":49575},{\"end\":49914,\"start\":49913},{\"end\":49925,\"start\":49924},{\"end\":49927,\"start\":49926},{\"end\":49940,\"start\":49939},{\"end\":49948,\"start\":49947},{\"end\":49961,\"start\":49960},{\"end\":50323,\"start\":50322},{\"end\":50334,\"start\":50333},{\"end\":50343,\"start\":50342},{\"end\":50354,\"start\":50353},{\"end\":50654,\"start\":50653},{\"end\":50666,\"start\":50665},{\"end\":50673,\"start\":50672},{\"end\":50959,\"start\":50958},{\"end\":50967,\"start\":50966},{\"end\":50974,\"start\":50973},{\"end\":50982,\"start\":50981},{\"end\":50995,\"start\":50994},{\"end\":51012,\"start\":51011},{\"end\":51014,\"start\":51013},{\"end\":51312,\"start\":51311},{\"end\":51318,\"start\":51317},{\"end\":51327,\"start\":51326},{\"end\":51334,\"start\":51333},{\"end\":51542,\"start\":51541},{\"end\":51548,\"start\":51547},{\"end\":51550,\"start\":51549},{\"end\":51559,\"start\":51558},{\"end\":51561,\"start\":51560},{\"end\":51769,\"start\":51768},{\"end\":51782,\"start\":51781},{\"end\":51956,\"start\":51955},{\"end\":51958,\"start\":51957},{\"end\":51966,\"start\":51965},{\"end\":51968,\"start\":51967},{\"end\":52185,\"start\":52184},{\"end\":52187,\"start\":52186},{\"end\":52197,\"start\":52196},{\"end\":52433,\"start\":52432},{\"end\":52439,\"start\":52438},{\"end\":52448,\"start\":52447},{\"end\":52450,\"start\":52449}]", "bib_author_last_name": "[{\"end\":44045,\"start\":44041},{\"end\":44053,\"start\":44049},{\"end\":44329,\"start\":44320},{\"end\":44340,\"start\":44333},{\"end\":44661,\"start\":44658},{\"end\":44671,\"start\":44667},{\"end\":44680,\"start\":44677},{\"end\":45048,\"start\":45044},{\"end\":45055,\"start\":45052},{\"end\":45064,\"start\":45061},{\"end\":45342,\"start\":45338},{\"end\":45348,\"start\":45346},{\"end\":45354,\"start\":45352},{\"end\":45745,\"start\":45740},{\"end\":45754,\"start\":45749},{\"end\":45762,\"start\":45758},{\"end\":45774,\"start\":45766},{\"end\":46243,\"start\":46240},{\"end\":46251,\"start\":46247},{\"end\":46257,\"start\":46255},{\"end\":46268,\"start\":46261},{\"end\":46510,\"start\":46503},{\"end\":46521,\"start\":46514},{\"end\":46531,\"start\":46525},{\"end\":46544,\"start\":46535},{\"end\":46553,\"start\":46548},{\"end\":46564,\"start\":46559},{\"end\":46576,\"start\":46570},{\"end\":46590,\"start\":46580},{\"end\":46989,\"start\":46982},{\"end\":47003,\"start\":46993},{\"end\":47015,\"start\":47007},{\"end\":47028,\"start\":47019},{\"end\":47337,\"start\":47330},{\"end\":47343,\"start\":47341},{\"end\":47352,\"start\":47347},{\"end\":47360,\"start\":47356},{\"end\":47370,\"start\":47364},{\"end\":47383,\"start\":47374},{\"end\":47594,\"start\":47590},{\"end\":47604,\"start\":47598},{\"end\":47881,\"start\":47876},{\"end\":47893,\"start\":47887},{\"end\":47905,\"start\":47899},{\"end\":48201,\"start\":48193},{\"end\":48214,\"start\":48207},{\"end\":48482,\"start\":48479},{\"end\":48509,\"start\":48486},{\"end\":48837,\"start\":48834},{\"end\":48847,\"start\":48845},{\"end\":48860,\"start\":48857},{\"end\":49214,\"start\":49209},{\"end\":49227,\"start\":49221},{\"end\":49503,\"start\":49493},{\"end\":49520,\"start\":49507},{\"end\":49529,\"start\":49524},{\"end\":49535,\"start\":49533},{\"end\":49551,\"start\":49539},{\"end\":49560,\"start\":49555},{\"end\":49573,\"start\":49564},{\"end\":49583,\"start\":49577},{\"end\":49922,\"start\":49915},{\"end\":49937,\"start\":49928},{\"end\":49945,\"start\":49941},{\"end\":49958,\"start\":49949},{\"end\":49968,\"start\":49962},{\"end\":50331,\"start\":50324},{\"end\":50340,\"start\":50335},{\"end\":50351,\"start\":50344},{\"end\":50363,\"start\":50355},{\"end\":50663,\"start\":50655},{\"end\":50670,\"start\":50667},{\"end\":50680,\"start\":50674},{\"end\":50964,\"start\":50960},{\"end\":50971,\"start\":50968},{\"end\":50979,\"start\":50975},{\"end\":50992,\"start\":50983},{\"end\":51009,\"start\":50996},{\"end\":51017,\"start\":51015},{\"end\":51315,\"start\":51313},{\"end\":51324,\"start\":51319},{\"end\":51331,\"start\":51328},{\"end\":51338,\"start\":51335},{\"end\":51545,\"start\":51543},{\"end\":51556,\"start\":51551},{\"end\":51568,\"start\":51562},{\"end\":51779,\"start\":51770},{\"end\":51789,\"start\":51783},{\"end\":51963,\"start\":51959},{\"end\":51976,\"start\":51969},{\"end\":52194,\"start\":52188},{\"end\":52200,\"start\":52198},{\"end\":52436,\"start\":52434},{\"end\":52445,\"start\":52440},{\"end\":52457,\"start\":52451}]", "bib_entry": "[{\"attributes\":{\"id\":\"b0\",\"matched_paper_id\":18038684},\"end\":44244,\"start\":43998},{\"attributes\":{\"id\":\"b1\",\"matched_paper_id\":25832817},\"end\":44587,\"start\":44246},{\"attributes\":{\"id\":\"b2\",\"matched_paper_id\":53234493},\"end\":44958,\"start\":44589},{\"attributes\":{\"id\":\"b3\",\"matched_paper_id\":208091240},\"end\":45240,\"start\":44960},{\"attributes\":{\"id\":\"b4\",\"matched_paper_id\":51975517},\"end\":45635,\"start\":45242},{\"attributes\":{\"id\":\"b5\",\"matched_paper_id\":221087896},\"end\":46170,\"start\":45637},{\"attributes\":{\"doi\":\"arXiv:1702.01923\",\"id\":\"b6\"},\"end\":46472,\"start\":46172},{\"attributes\":{\"id\":\"b7\",\"matched_paper_id\":13756489},\"end\":46917,\"start\":46474},{\"attributes\":{\"id\":\"b8\"},\"end\":47273,\"start\":46919},{\"attributes\":{\"id\":\"b9\"},\"end\":47520,\"start\":47275},{\"attributes\":{\"doi\":\"arXiv:2002.02511\",\"id\":\"b10\"},\"end\":47797,\"start\":47522},{\"attributes\":{\"id\":\"b11\",\"matched_paper_id\":51872504},\"end\":48148,\"start\":47799},{\"attributes\":{\"id\":\"b12\",\"matched_paper_id\":18375389},\"end\":48395,\"start\":48150},{\"attributes\":{\"id\":\"b13\",\"matched_paper_id\":2107498},\"end\":48739,\"start\":48397},{\"attributes\":{\"id\":\"b14\",\"matched_paper_id\":206740341},\"end\":49105,\"start\":48741},{\"attributes\":{\"id\":\"b15\",\"matched_paper_id\":3687828},\"end\":49449,\"start\":49107},{\"attributes\":{\"id\":\"b16\"},\"end\":49818,\"start\":49451},{\"attributes\":{\"id\":\"b17\",\"matched_paper_id\":229202841},\"end\":50252,\"start\":49820},{\"attributes\":{\"doi\":\"arXiv:1909.08407\",\"id\":\"b18\"},\"end\":50580,\"start\":50254},{\"attributes\":{\"doi\":\"arXiv:1409.0473\",\"id\":\"b19\"},\"end\":50882,\"start\":50582},{\"attributes\":{\"doi\":\"arXiv:1906.08237\",\"id\":\"b20\"},\"end\":51264,\"start\":50884},{\"attributes\":{\"doi\":\"arXiv:1603.05027\",\"id\":\"b21\"},\"end\":51518,\"start\":51266},{\"attributes\":{\"doi\":\"arXiv:1607.06450\",\"id\":\"b22\"},\"end\":51729,\"start\":51520},{\"attributes\":{\"doi\":\"arXiv:1606.08415\",\"id\":\"b23\"},\"end\":51953,\"start\":51731},{\"attributes\":{\"id\":\"b24\"},\"end\":52138,\"start\":51955},{\"attributes\":{\"doi\":\"arXiv:1412.6980\",\"id\":\"b25\"},\"end\":52366,\"start\":52140},{\"attributes\":{\"id\":\"b26\",\"matched_paper_id\":22230419},\"end\":52637,\"start\":52368},{\"attributes\":{\"id\":\"b27\"},\"end\":53331,\"start\":52639}]", "bib_title": "[{\"end\":44037,\"start\":43998},{\"end\":44316,\"start\":44246},{\"end\":44654,\"start\":44589},{\"end\":45038,\"start\":44960},{\"end\":45334,\"start\":45242},{\"end\":45734,\"start\":45637},{\"end\":46499,\"start\":46474},{\"end\":47870,\"start\":47799},{\"end\":48189,\"start\":48150},{\"end\":48472,\"start\":48397},{\"end\":48830,\"start\":48741},{\"end\":49205,\"start\":49107},{\"end\":49489,\"start\":49451},{\"end\":49911,\"start\":49820},{\"end\":52430,\"start\":52368}]", "bib_author": "[{\"end\":44047,\"start\":44039},{\"end\":44055,\"start\":44047},{\"end\":44331,\"start\":44318},{\"end\":44342,\"start\":44331},{\"end\":44663,\"start\":44656},{\"end\":44673,\"start\":44663},{\"end\":44682,\"start\":44673},{\"end\":45050,\"start\":45040},{\"end\":45057,\"start\":45050},{\"end\":45066,\"start\":45057},{\"end\":45344,\"start\":45336},{\"end\":45350,\"start\":45344},{\"end\":45356,\"start\":45350},{\"end\":45747,\"start\":45736},{\"end\":45756,\"start\":45747},{\"end\":45764,\"start\":45756},{\"end\":45776,\"start\":45764},{\"end\":46245,\"start\":46238},{\"end\":46253,\"start\":46245},{\"end\":46259,\"start\":46253},{\"end\":46270,\"start\":46259},{\"end\":46512,\"start\":46501},{\"end\":46523,\"start\":46512},{\"end\":46533,\"start\":46523},{\"end\":46546,\"start\":46533},{\"end\":46555,\"start\":46546},{\"end\":46566,\"start\":46555},{\"end\":46578,\"start\":46566},{\"end\":46592,\"start\":46578},{\"end\":46991,\"start\":46980},{\"end\":47005,\"start\":46991},{\"end\":47017,\"start\":47005},{\"end\":47030,\"start\":47017},{\"end\":47339,\"start\":47328},{\"end\":47345,\"start\":47339},{\"end\":47354,\"start\":47345},{\"end\":47362,\"start\":47354},{\"end\":47372,\"start\":47362},{\"end\":47385,\"start\":47372},{\"end\":47596,\"start\":47588},{\"end\":47606,\"start\":47596},{\"end\":47883,\"start\":47872},{\"end\":47895,\"start\":47883},{\"end\":47907,\"start\":47895},{\"end\":48203,\"start\":48191},{\"end\":48216,\"start\":48203},{\"end\":48484,\"start\":48474},{\"end\":48511,\"start\":48484},{\"end\":48839,\"start\":48832},{\"end\":48849,\"start\":48839},{\"end\":48862,\"start\":48849},{\"end\":49216,\"start\":49207},{\"end\":49229,\"start\":49216},{\"end\":49505,\"start\":49491},{\"end\":49522,\"start\":49505},{\"end\":49531,\"start\":49522},{\"end\":49537,\"start\":49531},{\"end\":49553,\"start\":49537},{\"end\":49562,\"start\":49553},{\"end\":49575,\"start\":49562},{\"end\":49585,\"start\":49575},{\"end\":49924,\"start\":49913},{\"end\":49939,\"start\":49924},{\"end\":49947,\"start\":49939},{\"end\":49960,\"start\":49947},{\"end\":49970,\"start\":49960},{\"end\":50333,\"start\":50322},{\"end\":50342,\"start\":50333},{\"end\":50353,\"start\":50342},{\"end\":50365,\"start\":50353},{\"end\":50665,\"start\":50653},{\"end\":50672,\"start\":50665},{\"end\":50682,\"start\":50672},{\"end\":50966,\"start\":50958},{\"end\":50973,\"start\":50966},{\"end\":50981,\"start\":50973},{\"end\":50994,\"start\":50981},{\"end\":51011,\"start\":50994},{\"end\":51019,\"start\":51011},{\"end\":51317,\"start\":51311},{\"end\":51326,\"start\":51317},{\"end\":51333,\"start\":51326},{\"end\":51340,\"start\":51333},{\"end\":51547,\"start\":51541},{\"end\":51558,\"start\":51547},{\"end\":51570,\"start\":51558},{\"end\":51781,\"start\":51768},{\"end\":51791,\"start\":51781},{\"end\":51965,\"start\":51955},{\"end\":51978,\"start\":51965},{\"end\":52196,\"start\":52184},{\"end\":52202,\"start\":52196},{\"end\":52438,\"start\":52432},{\"end\":52447,\"start\":52438},{\"end\":52459,\"start\":52447}]", "bib_venue": "[{\"end\":44117,\"start\":44090},{\"end\":44414,\"start\":44382},{\"end\":44778,\"start\":44734},{\"end\":45440,\"start\":45402},{\"end\":45920,\"start\":45852},{\"end\":46687,\"start\":46636},{\"end\":48563,\"start\":48541},{\"end\":52010,\"start\":51995},{\"end\":52870,\"start\":52842},{\"end\":44088,\"start\":44055},{\"end\":44380,\"start\":44342},{\"end\":44732,\"start\":44682},{\"end\":45077,\"start\":45066},{\"end\":45400,\"start\":45356},{\"end\":45850,\"start\":45776},{\"end\":46236,\"start\":46172},{\"end\":46634,\"start\":46592},{\"end\":46978,\"start\":46919},{\"end\":47326,\"start\":47275},{\"end\":47586,\"start\":47522},{\"end\":47943,\"start\":47907},{\"end\":48242,\"start\":48216},{\"end\":48539,\"start\":48511},{\"end\":48894,\"start\":48862},{\"end\":49251,\"start\":49229},{\"end\":49615,\"start\":49585},{\"end\":50002,\"start\":49970},{\"end\":50320,\"start\":50254},{\"end\":50651,\"start\":50582},{\"end\":50956,\"start\":50884},{\"end\":51309,\"start\":51266},{\"end\":51539,\"start\":51520},{\"end\":51766,\"start\":51731},{\"end\":51993,\"start\":51978},{\"end\":52182,\"start\":52140},{\"end\":52474,\"start\":52459},{\"end\":52840,\"start\":52639}]"}}}, "year": 2023, "month": 12, "day": 17}